Epoch: 1| Step: 0
Training loss: 7.591761589050293
Validation loss: 8.525896256969821

Epoch: 6| Step: 1
Training loss: 8.342161178588867
Validation loss: 8.521438485832624

Epoch: 6| Step: 2
Training loss: 9.21500015258789
Validation loss: 8.521337170754709

Epoch: 6| Step: 3
Training loss: 8.716856956481934
Validation loss: 8.5168184362432

Epoch: 6| Step: 4
Training loss: 7.6694207191467285
Validation loss: 8.512863302743563

Epoch: 6| Step: 5
Training loss: 8.41808032989502
Validation loss: 8.512234052022299

Epoch: 6| Step: 6
Training loss: 7.61471700668335
Validation loss: 8.50904252452235

Epoch: 6| Step: 7
Training loss: 8.03084945678711
Validation loss: 8.50506276981805

Epoch: 6| Step: 8
Training loss: 8.853845596313477
Validation loss: 8.502408899286742

Epoch: 6| Step: 9
Training loss: 8.758687019348145
Validation loss: 8.500270494850733

Epoch: 6| Step: 10
Training loss: 7.912202835083008
Validation loss: 8.495571208256548

Epoch: 6| Step: 11
Training loss: 8.702432632446289
Validation loss: 8.494164036166284

Epoch: 6| Step: 12
Training loss: 8.261869430541992
Validation loss: 8.491046290243826

Epoch: 6| Step: 13
Training loss: 8.021209716796875
Validation loss: 8.487258695786998

Epoch: 2| Step: 0
Training loss: 8.815753936767578
Validation loss: 8.486589298453382

Epoch: 6| Step: 1
Training loss: 6.805051803588867
Validation loss: 8.482267482306368

Epoch: 6| Step: 2
Training loss: 8.3875732421875
Validation loss: 8.477912523413217

Epoch: 6| Step: 3
Training loss: 9.051666259765625
Validation loss: 8.47663454855642

Epoch: 6| Step: 4
Training loss: 7.057594299316406
Validation loss: 8.471408454320764

Epoch: 6| Step: 5
Training loss: 8.052353858947754
Validation loss: 8.47292362746372

Epoch: 6| Step: 6
Training loss: 8.058839797973633
Validation loss: 8.466031033505676

Epoch: 6| Step: 7
Training loss: 9.023128509521484
Validation loss: 8.4626831136724

Epoch: 6| Step: 8
Training loss: 9.077007293701172
Validation loss: 8.461136243676627

Epoch: 6| Step: 9
Training loss: 7.946486473083496
Validation loss: 8.458579740216654

Epoch: 6| Step: 10
Training loss: 8.08238410949707
Validation loss: 8.455526075055522

Epoch: 6| Step: 11
Training loss: 8.52667236328125
Validation loss: 8.452092611661522

Epoch: 6| Step: 12
Training loss: 8.69666576385498
Validation loss: 8.449124654134115

Epoch: 6| Step: 13
Training loss: 7.891512393951416
Validation loss: 8.44621112782468

Epoch: 3| Step: 0
Training loss: 7.069008827209473
Validation loss: 8.442643319406818

Epoch: 6| Step: 1
Training loss: 9.055570602416992
Validation loss: 8.438077403653052

Epoch: 6| Step: 2
Training loss: 8.503710746765137
Validation loss: 8.436283398700017

Epoch: 6| Step: 3
Training loss: 9.433018684387207
Validation loss: 8.43300941938995

Epoch: 6| Step: 4
Training loss: 7.5794525146484375
Validation loss: 8.42944698949014

Epoch: 6| Step: 5
Training loss: 7.965047836303711
Validation loss: 8.426501684291388

Epoch: 6| Step: 6
Training loss: 6.856825828552246
Validation loss: 8.420786483313448

Epoch: 6| Step: 7
Training loss: 8.552755355834961
Validation loss: 8.418847027645317

Epoch: 6| Step: 8
Training loss: 8.8763427734375
Validation loss: 8.414721478698073

Epoch: 6| Step: 9
Training loss: 8.25599479675293
Validation loss: 8.41235702268539

Epoch: 6| Step: 10
Training loss: 7.6492462158203125
Validation loss: 8.408611912881174

Epoch: 6| Step: 11
Training loss: 8.592816352844238
Validation loss: 8.404873232687674

Epoch: 6| Step: 12
Training loss: 8.19729995727539
Validation loss: 8.401324179864698

Epoch: 6| Step: 13
Training loss: 8.555266380310059
Validation loss: 8.400321252884403

Epoch: 4| Step: 0
Training loss: 8.61795425415039
Validation loss: 8.395604564297583

Epoch: 6| Step: 1
Training loss: 7.84764289855957
Validation loss: 8.392052583797003

Epoch: 6| Step: 2
Training loss: 8.110282897949219
Validation loss: 8.386206780710529

Epoch: 6| Step: 3
Training loss: 8.714113235473633
Validation loss: 8.383380572001139

Epoch: 6| Step: 4
Training loss: 8.310850143432617
Validation loss: 8.38122328378821

Epoch: 6| Step: 5
Training loss: 8.557111740112305
Validation loss: 8.377558236481041

Epoch: 6| Step: 6
Training loss: 8.360616683959961
Validation loss: 8.373795263228878

Epoch: 6| Step: 7
Training loss: 7.026155948638916
Validation loss: 8.368340799885411

Epoch: 6| Step: 8
Training loss: 7.724961280822754
Validation loss: 8.365498230021487

Epoch: 6| Step: 9
Training loss: 8.865785598754883
Validation loss: 8.362566424954322

Epoch: 6| Step: 10
Training loss: 8.048388481140137
Validation loss: 8.357762885350054

Epoch: 6| Step: 11
Training loss: 8.093822479248047
Validation loss: 8.353588504175987

Epoch: 6| Step: 12
Training loss: 8.636699676513672
Validation loss: 8.347960092688119

Epoch: 6| Step: 13
Training loss: 6.688689708709717
Validation loss: 8.347106379847373

Epoch: 5| Step: 0
Training loss: 8.158170700073242
Validation loss: 8.344383762728784

Epoch: 6| Step: 1
Training loss: 7.489745616912842
Validation loss: 8.34122496779247

Epoch: 6| Step: 2
Training loss: 9.325044631958008
Validation loss: 8.335290621685726

Epoch: 6| Step: 3
Training loss: 7.195441722869873
Validation loss: 8.32993886804068

Epoch: 6| Step: 4
Training loss: 7.874386787414551
Validation loss: 8.327810431039461

Epoch: 6| Step: 5
Training loss: 8.14813232421875
Validation loss: 8.32245227854739

Epoch: 6| Step: 6
Training loss: 9.070232391357422
Validation loss: 8.318664545653968

Epoch: 6| Step: 7
Training loss: 8.842693328857422
Validation loss: 8.31603644996561

Epoch: 6| Step: 8
Training loss: 8.64668083190918
Validation loss: 8.311051922459756

Epoch: 6| Step: 9
Training loss: 7.254419803619385
Validation loss: 8.307217874834615

Epoch: 6| Step: 10
Training loss: 8.294059753417969
Validation loss: 8.303115701162687

Epoch: 6| Step: 11
Training loss: 8.408560752868652
Validation loss: 8.297176207265546

Epoch: 6| Step: 12
Training loss: 7.215341567993164
Validation loss: 8.294330771251392

Epoch: 6| Step: 13
Training loss: 7.133862018585205
Validation loss: 8.288756585890248

Epoch: 6| Step: 0
Training loss: 7.120758533477783
Validation loss: 8.284970216853644

Epoch: 6| Step: 1
Training loss: 7.262337684631348
Validation loss: 8.280649390271915

Epoch: 6| Step: 2
Training loss: 7.581563949584961
Validation loss: 8.277099917011876

Epoch: 6| Step: 3
Training loss: 8.720927238464355
Validation loss: 8.27044020416916

Epoch: 6| Step: 4
Training loss: 8.596744537353516
Validation loss: 8.267907963004163

Epoch: 6| Step: 5
Training loss: 7.664431571960449
Validation loss: 8.26474920395882

Epoch: 6| Step: 6
Training loss: 7.403977394104004
Validation loss: 8.2596402424638

Epoch: 6| Step: 7
Training loss: 8.776731491088867
Validation loss: 8.25638242947158

Epoch: 6| Step: 8
Training loss: 9.219077110290527
Validation loss: 8.251957047370173

Epoch: 6| Step: 9
Training loss: 7.6148223876953125
Validation loss: 8.243315558279715

Epoch: 6| Step: 10
Training loss: 9.050870895385742
Validation loss: 8.238387733377436

Epoch: 6| Step: 11
Training loss: 7.823057174682617
Validation loss: 8.233331546988538

Epoch: 6| Step: 12
Training loss: 8.675103187561035
Validation loss: 8.22928802941435

Epoch: 6| Step: 13
Training loss: 6.306329727172852
Validation loss: 8.226450350976759

Epoch: 7| Step: 0
Training loss: 7.4977827072143555
Validation loss: 8.219595478427026

Epoch: 6| Step: 1
Training loss: 7.799230575561523
Validation loss: 8.21450791307675

Epoch: 6| Step: 2
Training loss: 8.004005432128906
Validation loss: 8.212058118594591

Epoch: 6| Step: 3
Training loss: 6.494123458862305
Validation loss: 8.201693714305918

Epoch: 6| Step: 4
Training loss: 8.728198051452637
Validation loss: 8.198919778229088

Epoch: 6| Step: 5
Training loss: 8.259350776672363
Validation loss: 8.192452738361974

Epoch: 6| Step: 6
Training loss: 7.8744611740112305
Validation loss: 8.190391073944749

Epoch: 6| Step: 7
Training loss: 7.0239081382751465
Validation loss: 8.182626601188414

Epoch: 6| Step: 8
Training loss: 8.102875709533691
Validation loss: 8.177694730861212

Epoch: 6| Step: 9
Training loss: 8.774459838867188
Validation loss: 8.174124328039026

Epoch: 6| Step: 10
Training loss: 8.078100204467773
Validation loss: 8.167427155279345

Epoch: 6| Step: 11
Training loss: 9.182252883911133
Validation loss: 8.160165253505912

Epoch: 6| Step: 12
Training loss: 8.369115829467773
Validation loss: 8.155153879555323

Epoch: 6| Step: 13
Training loss: 6.920353412628174
Validation loss: 8.150015041392336

Epoch: 8| Step: 0
Training loss: 7.455336570739746
Validation loss: 8.144096671894033

Epoch: 6| Step: 1
Training loss: 7.618842124938965
Validation loss: 8.135464324746081

Epoch: 6| Step: 2
Training loss: 8.56114673614502
Validation loss: 8.13193965214555

Epoch: 6| Step: 3
Training loss: 8.203548431396484
Validation loss: 8.126213073730469

Epoch: 6| Step: 4
Training loss: 7.48736572265625
Validation loss: 8.121547550283452

Epoch: 6| Step: 5
Training loss: 8.42648696899414
Validation loss: 8.114420931826356

Epoch: 6| Step: 6
Training loss: 6.9490509033203125
Validation loss: 8.108382717255623

Epoch: 6| Step: 7
Training loss: 8.20693302154541
Validation loss: 8.099686314982753

Epoch: 6| Step: 8
Training loss: 6.543501853942871
Validation loss: 8.09635469990392

Epoch: 6| Step: 9
Training loss: 9.405317306518555
Validation loss: 8.090893622367613

Epoch: 6| Step: 10
Training loss: 7.219196319580078
Validation loss: 8.08107206898351

Epoch: 6| Step: 11
Training loss: 8.136523246765137
Validation loss: 8.075724714545794

Epoch: 6| Step: 12
Training loss: 7.798113822937012
Validation loss: 8.069503415015436

Epoch: 6| Step: 13
Training loss: 8.685276985168457
Validation loss: 8.056615306485083

Epoch: 9| Step: 0
Training loss: 7.319108009338379
Validation loss: 8.05495059618386

Epoch: 6| Step: 1
Training loss: 8.633597373962402
Validation loss: 8.047535096445392

Epoch: 6| Step: 2
Training loss: 7.949814319610596
Validation loss: 8.038070248019311

Epoch: 6| Step: 3
Training loss: 6.787158966064453
Validation loss: 8.03240922702256

Epoch: 6| Step: 4
Training loss: 8.384598731994629
Validation loss: 8.023624225329327

Epoch: 6| Step: 5
Training loss: 7.302637100219727
Validation loss: 8.018550749747984

Epoch: 6| Step: 6
Training loss: 8.27896785736084
Validation loss: 8.008070566320932

Epoch: 6| Step: 7
Training loss: 8.69154167175293
Validation loss: 7.9999922885689685

Epoch: 6| Step: 8
Training loss: 8.405784606933594
Validation loss: 7.996775093898978

Epoch: 6| Step: 9
Training loss: 6.108918190002441
Validation loss: 7.987080907308927

Epoch: 6| Step: 10
Training loss: 8.426048278808594
Validation loss: 7.976816197877289

Epoch: 6| Step: 11
Training loss: 7.627945899963379
Validation loss: 7.968102598703036

Epoch: 6| Step: 12
Training loss: 6.541290283203125
Validation loss: 7.963688563275081

Epoch: 6| Step: 13
Training loss: 9.126847267150879
Validation loss: 7.952858001955094

Epoch: 10| Step: 0
Training loss: 7.072731018066406
Validation loss: 7.941161924792874

Epoch: 6| Step: 1
Training loss: 6.488262176513672
Validation loss: 7.939552409674532

Epoch: 6| Step: 2
Training loss: 8.500772476196289
Validation loss: 7.92762597914665

Epoch: 6| Step: 3
Training loss: 9.419805526733398
Validation loss: 7.918326388123215

Epoch: 6| Step: 4
Training loss: 7.120070457458496
Validation loss: 7.913407089889691

Epoch: 6| Step: 5
Training loss: 7.93172550201416
Validation loss: 7.901381384941839

Epoch: 6| Step: 6
Training loss: 7.981784820556641
Validation loss: 7.888756757141442

Epoch: 6| Step: 7
Training loss: 7.926291465759277
Validation loss: 7.883979448708155

Epoch: 6| Step: 8
Training loss: 7.8989105224609375
Validation loss: 7.873632374630179

Epoch: 6| Step: 9
Training loss: 6.599362373352051
Validation loss: 7.860585797217585

Epoch: 6| Step: 10
Training loss: 7.9517412185668945
Validation loss: 7.851910334761425

Epoch: 6| Step: 11
Training loss: 7.697510719299316
Validation loss: 7.8402343411599436

Epoch: 6| Step: 12
Training loss: 7.939983367919922
Validation loss: 7.829799441881077

Epoch: 6| Step: 13
Training loss: 6.0365142822265625
Validation loss: 7.817575167584163

Epoch: 11| Step: 0
Training loss: 8.510337829589844
Validation loss: 7.813010661832748

Epoch: 6| Step: 1
Training loss: 6.4432196617126465
Validation loss: 7.803826168019285

Epoch: 6| Step: 2
Training loss: 6.541568756103516
Validation loss: 7.788849030771563

Epoch: 6| Step: 3
Training loss: 7.562010765075684
Validation loss: 7.780237782386042

Epoch: 6| Step: 4
Training loss: 7.378111839294434
Validation loss: 7.768740418136761

Epoch: 6| Step: 5
Training loss: 7.8914899826049805
Validation loss: 7.7620780801260345

Epoch: 6| Step: 6
Training loss: 6.45931339263916
Validation loss: 7.7434490778112925

Epoch: 6| Step: 7
Training loss: 8.365594863891602
Validation loss: 7.738181755106936

Epoch: 6| Step: 8
Training loss: 7.031691551208496
Validation loss: 7.722744972475113

Epoch: 6| Step: 9
Training loss: 7.6617231369018555
Validation loss: 7.706670309907647

Epoch: 6| Step: 10
Training loss: 7.697942733764648
Validation loss: 7.703473665380991

Epoch: 6| Step: 11
Training loss: 6.570401191711426
Validation loss: 7.692068869067777

Epoch: 6| Step: 12
Training loss: 9.083126068115234
Validation loss: 7.678319890012023

Epoch: 6| Step: 13
Training loss: 8.254782676696777
Validation loss: 7.667703669558289

Epoch: 12| Step: 0
Training loss: 7.236037731170654
Validation loss: 7.651977451898718

Epoch: 6| Step: 1
Training loss: 7.48295783996582
Validation loss: 7.638874946102019

Epoch: 6| Step: 2
Training loss: 7.804663181304932
Validation loss: 7.622159793812742

Epoch: 6| Step: 3
Training loss: 8.337632179260254
Validation loss: 7.619028701577135

Epoch: 6| Step: 4
Training loss: 8.420695304870605
Validation loss: 7.602482144550611

Epoch: 6| Step: 5
Training loss: 7.285823822021484
Validation loss: 7.592498123004872

Epoch: 6| Step: 6
Training loss: 7.251711845397949
Validation loss: 7.580130761669528

Epoch: 6| Step: 7
Training loss: 7.2922282218933105
Validation loss: 7.567993707554315

Epoch: 6| Step: 8
Training loss: 6.439985752105713
Validation loss: 7.554060792410246

Epoch: 6| Step: 9
Training loss: 6.768295764923096
Validation loss: 7.532595952351888

Epoch: 6| Step: 10
Training loss: 6.262548446655273
Validation loss: 7.528080781300862

Epoch: 6| Step: 11
Training loss: 6.480133056640625
Validation loss: 7.507490004262617

Epoch: 6| Step: 12
Training loss: 8.525228500366211
Validation loss: 7.490695076604044

Epoch: 6| Step: 13
Training loss: 6.945510387420654
Validation loss: 7.480649399501021

Epoch: 13| Step: 0
Training loss: 7.485211372375488
Validation loss: 7.469982167725922

Epoch: 6| Step: 1
Training loss: 6.965362071990967
Validation loss: 7.450197835122386

Epoch: 6| Step: 2
Training loss: 6.818418979644775
Validation loss: 7.444880311207105

Epoch: 6| Step: 3
Training loss: 7.835781097412109
Validation loss: 7.428104308343703

Epoch: 6| Step: 4
Training loss: 6.923061847686768
Validation loss: 7.415084772212531

Epoch: 6| Step: 5
Training loss: 6.57053279876709
Validation loss: 7.405814391310497

Epoch: 6| Step: 6
Training loss: 7.280811309814453
Validation loss: 7.380700808699413

Epoch: 6| Step: 7
Training loss: 6.322430610656738
Validation loss: 7.369046744479928

Epoch: 6| Step: 8
Training loss: 7.778785228729248
Validation loss: 7.353557073941794

Epoch: 6| Step: 9
Training loss: 7.061379432678223
Validation loss: 7.334494795850528

Epoch: 6| Step: 10
Training loss: 7.575860023498535
Validation loss: 7.319983882288779

Epoch: 6| Step: 11
Training loss: 6.997086524963379
Validation loss: 7.302932339329874

Epoch: 6| Step: 12
Training loss: 8.21979808807373
Validation loss: 7.293544620595952

Epoch: 6| Step: 13
Training loss: 5.201038360595703
Validation loss: 7.276753676834927

Epoch: 14| Step: 0
Training loss: 7.018742561340332
Validation loss: 7.253950965019964

Epoch: 6| Step: 1
Training loss: 7.625664234161377
Validation loss: 7.245262212650751

Epoch: 6| Step: 2
Training loss: 6.695039749145508
Validation loss: 7.225793356536537

Epoch: 6| Step: 3
Training loss: 6.407639503479004
Validation loss: 7.206791616255237

Epoch: 6| Step: 4
Training loss: 7.443265914916992
Validation loss: 7.1846631675638175

Epoch: 6| Step: 5
Training loss: 6.769553184509277
Validation loss: 7.186787072048392

Epoch: 6| Step: 6
Training loss: 7.300726890563965
Validation loss: 7.152135520853022

Epoch: 6| Step: 7
Training loss: 6.493183135986328
Validation loss: 7.149147125982469

Epoch: 6| Step: 8
Training loss: 6.693070888519287
Validation loss: 7.130094220561366

Epoch: 6| Step: 9
Training loss: 6.26077938079834
Validation loss: 7.107583794542538

Epoch: 6| Step: 10
Training loss: 7.2956318855285645
Validation loss: 7.092734439398653

Epoch: 6| Step: 11
Training loss: 6.155913829803467
Validation loss: 7.07695181651782

Epoch: 6| Step: 12
Training loss: 7.635320663452148
Validation loss: 7.054311557482648

Epoch: 6| Step: 13
Training loss: 6.915608882904053
Validation loss: 7.031372916313909

Epoch: 15| Step: 0
Training loss: 6.9918060302734375
Validation loss: 7.020888856662217

Epoch: 6| Step: 1
Training loss: 6.686554908752441
Validation loss: 7.003122857821885

Epoch: 6| Step: 2
Training loss: 6.734795570373535
Validation loss: 6.983351328039682

Epoch: 6| Step: 3
Training loss: 6.360626220703125
Validation loss: 6.970051903878489

Epoch: 6| Step: 4
Training loss: 7.502774238586426
Validation loss: 6.951906922043011

Epoch: 6| Step: 5
Training loss: 4.911144256591797
Validation loss: 6.932368360539918

Epoch: 6| Step: 6
Training loss: 6.459470272064209
Validation loss: 6.901171376628261

Epoch: 6| Step: 7
Training loss: 6.952937602996826
Validation loss: 6.888496137434436

Epoch: 6| Step: 8
Training loss: 5.920189380645752
Validation loss: 6.867401851120816

Epoch: 6| Step: 9
Training loss: 7.727921962738037
Validation loss: 6.8473898262105966

Epoch: 6| Step: 10
Training loss: 6.245734691619873
Validation loss: 6.827754128363825

Epoch: 6| Step: 11
Training loss: 6.56719446182251
Validation loss: 6.807941862331924

Epoch: 6| Step: 12
Training loss: 6.325634479522705
Validation loss: 6.791936541116366

Epoch: 6| Step: 13
Training loss: 8.489898681640625
Validation loss: 6.76899851522138

Epoch: 16| Step: 0
Training loss: 6.837560653686523
Validation loss: 6.7518577985866095

Epoch: 6| Step: 1
Training loss: 7.102598667144775
Validation loss: 6.724244322828067

Epoch: 6| Step: 2
Training loss: 6.221937656402588
Validation loss: 6.704860010454731

Epoch: 6| Step: 3
Training loss: 6.698756694793701
Validation loss: 6.687017379268523

Epoch: 6| Step: 4
Training loss: 6.4028730392456055
Validation loss: 6.657196260267688

Epoch: 6| Step: 5
Training loss: 6.7864603996276855
Validation loss: 6.632464593456637

Epoch: 6| Step: 6
Training loss: 6.673671722412109
Validation loss: 6.615270665896836

Epoch: 6| Step: 7
Training loss: 6.137889862060547
Validation loss: 6.596437741351384

Epoch: 6| Step: 8
Training loss: 6.709912300109863
Validation loss: 6.576025660319995

Epoch: 6| Step: 9
Training loss: 4.272717475891113
Validation loss: 6.556550805286695

Epoch: 6| Step: 10
Training loss: 7.022064208984375
Validation loss: 6.527256411890829

Epoch: 6| Step: 11
Training loss: 6.576811790466309
Validation loss: 6.514986433008666

Epoch: 6| Step: 12
Training loss: 5.957950592041016
Validation loss: 6.4938042189485286

Epoch: 6| Step: 13
Training loss: 4.827797889709473
Validation loss: 6.466388799810923

Epoch: 17| Step: 0
Training loss: 6.6994476318359375
Validation loss: 6.438777251910138

Epoch: 6| Step: 1
Training loss: 6.092933177947998
Validation loss: 6.416257171220677

Epoch: 6| Step: 2
Training loss: 5.505911350250244
Validation loss: 6.378187307747462

Epoch: 6| Step: 3
Training loss: 6.339962959289551
Validation loss: 6.3717514622596

Epoch: 6| Step: 4
Training loss: 6.232634544372559
Validation loss: 6.343770098942582

Epoch: 6| Step: 5
Training loss: 5.7851409912109375
Validation loss: 6.314855821671024

Epoch: 6| Step: 6
Training loss: 5.034526824951172
Validation loss: 6.285598247281967

Epoch: 6| Step: 7
Training loss: 5.650771141052246
Validation loss: 6.268856607457643

Epoch: 6| Step: 8
Training loss: 6.678956508636475
Validation loss: 6.2441527766566125

Epoch: 6| Step: 9
Training loss: 6.7934064865112305
Validation loss: 6.220025431725286

Epoch: 6| Step: 10
Training loss: 5.931661128997803
Validation loss: 6.183451473072011

Epoch: 6| Step: 11
Training loss: 7.1130290031433105
Validation loss: 6.155449703175535

Epoch: 6| Step: 12
Training loss: 5.28164529800415
Validation loss: 6.137181584553052

Epoch: 6| Step: 13
Training loss: 4.389106273651123
Validation loss: 6.094911370226132

Epoch: 18| Step: 0
Training loss: 5.0293288230896
Validation loss: 6.073730248276905

Epoch: 6| Step: 1
Training loss: 5.904009819030762
Validation loss: 6.052394472142701

Epoch: 6| Step: 2
Training loss: 6.415298938751221
Validation loss: 6.020664163815078

Epoch: 6| Step: 3
Training loss: 5.869479179382324
Validation loss: 5.993406916177401

Epoch: 6| Step: 4
Training loss: 6.179178237915039
Validation loss: 5.9539565322219685

Epoch: 6| Step: 5
Training loss: 6.1004533767700195
Validation loss: 5.932750850595454

Epoch: 6| Step: 6
Training loss: 4.878350734710693
Validation loss: 5.899509250476796

Epoch: 6| Step: 7
Training loss: 4.179366588592529
Validation loss: 5.880892035781696

Epoch: 6| Step: 8
Training loss: 5.05970573425293
Validation loss: 5.844152650525493

Epoch: 6| Step: 9
Training loss: 5.784989356994629
Validation loss: 5.825280117732222

Epoch: 6| Step: 10
Training loss: 6.158418655395508
Validation loss: 5.786247853309877

Epoch: 6| Step: 11
Training loss: 5.923087120056152
Validation loss: 5.743945624238702

Epoch: 6| Step: 12
Training loss: 5.461360454559326
Validation loss: 5.716344448827928

Epoch: 6| Step: 13
Training loss: 5.395651340484619
Validation loss: 5.6894742699079615

Epoch: 19| Step: 0
Training loss: 5.707088470458984
Validation loss: 5.662454251320131

Epoch: 6| Step: 1
Training loss: 4.349777698516846
Validation loss: 5.620917484324465

Epoch: 6| Step: 2
Training loss: 5.221992492675781
Validation loss: 5.579914672400362

Epoch: 6| Step: 3
Training loss: 4.705044746398926
Validation loss: 5.542621510003203

Epoch: 6| Step: 4
Training loss: 6.377779006958008
Validation loss: 5.515319075635684

Epoch: 6| Step: 5
Training loss: 4.169503211975098
Validation loss: 5.485872678859259

Epoch: 6| Step: 6
Training loss: 5.445591926574707
Validation loss: 5.453899475835985

Epoch: 6| Step: 7
Training loss: 5.514889717102051
Validation loss: 5.399635489268969

Epoch: 6| Step: 8
Training loss: 4.188819885253906
Validation loss: 5.370102154311313

Epoch: 6| Step: 9
Training loss: 5.348862171173096
Validation loss: 5.335227156198153

Epoch: 6| Step: 10
Training loss: 5.670592308044434
Validation loss: 5.3072889645894366

Epoch: 6| Step: 11
Training loss: 5.697784423828125
Validation loss: 5.258108333874774

Epoch: 6| Step: 12
Training loss: 4.667185306549072
Validation loss: 5.221081728576332

Epoch: 6| Step: 13
Training loss: 4.745328426361084
Validation loss: 5.180626048836657

Epoch: 20| Step: 0
Training loss: 5.0268940925598145
Validation loss: 5.1416499845443235

Epoch: 6| Step: 1
Training loss: 4.175384521484375
Validation loss: 5.101008845913794

Epoch: 6| Step: 2
Training loss: 6.11311674118042
Validation loss: 5.068011242856262

Epoch: 6| Step: 3
Training loss: 4.295677185058594
Validation loss: 5.023966414954073

Epoch: 6| Step: 4
Training loss: 5.338062286376953
Validation loss: 4.9904571092256935

Epoch: 6| Step: 5
Training loss: 5.125334739685059
Validation loss: 4.94529910754132

Epoch: 6| Step: 6
Training loss: 5.116010665893555
Validation loss: 4.914656905717747

Epoch: 6| Step: 7
Training loss: 4.872709274291992
Validation loss: 4.862307502377417

Epoch: 6| Step: 8
Training loss: 4.346802234649658
Validation loss: 4.8255538991702505

Epoch: 6| Step: 9
Training loss: 3.0246777534484863
Validation loss: 4.777981435098956

Epoch: 6| Step: 10
Training loss: 4.947103977203369
Validation loss: 4.747524651147986

Epoch: 6| Step: 11
Training loss: 4.944245338439941
Validation loss: 4.7191720726669475

Epoch: 6| Step: 12
Training loss: 2.5820541381835938
Validation loss: 4.641363020866148

Epoch: 6| Step: 13
Training loss: 4.626630783081055
Validation loss: 4.616676099838749

Epoch: 21| Step: 0
Training loss: 5.260918617248535
Validation loss: 4.574301709410965

Epoch: 6| Step: 1
Training loss: 4.804904937744141
Validation loss: 4.5299573124095955

Epoch: 6| Step: 2
Training loss: 4.011399269104004
Validation loss: 4.50850579046434

Epoch: 6| Step: 3
Training loss: 5.697910308837891
Validation loss: 4.445851428534395

Epoch: 6| Step: 4
Training loss: 3.644920825958252
Validation loss: 4.409877233607794

Epoch: 6| Step: 5
Training loss: 4.7182440757751465
Validation loss: 4.371928445754513

Epoch: 6| Step: 6
Training loss: 3.9101133346557617
Validation loss: 4.312050214377782

Epoch: 6| Step: 7
Training loss: 3.949361801147461
Validation loss: 4.286527813121837

Epoch: 6| Step: 8
Training loss: 3.6166818141937256
Validation loss: 4.237751606971987

Epoch: 6| Step: 9
Training loss: 3.568410634994507
Validation loss: 4.17692437735937

Epoch: 6| Step: 10
Training loss: 3.9836387634277344
Validation loss: 4.155540358635687

Epoch: 6| Step: 11
Training loss: 3.7217259407043457
Validation loss: 4.095823928874026

Epoch: 6| Step: 12
Training loss: 2.6542768478393555
Validation loss: 4.063851961525538

Epoch: 6| Step: 13
Training loss: 3.202199697494507
Validation loss: 4.036071249233779

Epoch: 22| Step: 0
Training loss: 4.039011001586914
Validation loss: 3.978054000485328

Epoch: 6| Step: 1
Training loss: 3.0049068927764893
Validation loss: 3.954183732309649

Epoch: 6| Step: 2
Training loss: 3.3087658882141113
Validation loss: 3.906694217394757

Epoch: 6| Step: 3
Training loss: 3.3313660621643066
Validation loss: 3.836827234555316

Epoch: 6| Step: 4
Training loss: 3.5258214473724365
Validation loss: 3.838230158693047

Epoch: 6| Step: 5
Training loss: 3.7611708641052246
Validation loss: 3.767705420012115

Epoch: 6| Step: 6
Training loss: 4.270892143249512
Validation loss: 3.7359354880548294

Epoch: 6| Step: 7
Training loss: 3.720496654510498
Validation loss: 3.7272908764500774

Epoch: 6| Step: 8
Training loss: 3.856914520263672
Validation loss: 3.6725538033311085

Epoch: 6| Step: 9
Training loss: 3.195612668991089
Validation loss: 3.6423339023384997

Epoch: 6| Step: 10
Training loss: 2.9044854640960693
Validation loss: 3.592883979120562

Epoch: 6| Step: 11
Training loss: 4.198585510253906
Validation loss: 3.5644371125005905

Epoch: 6| Step: 12
Training loss: 3.0278091430664062
Validation loss: 3.4839968014788885

Epoch: 6| Step: 13
Training loss: 4.046745300292969
Validation loss: 3.4705579614126556

Epoch: 23| Step: 0
Training loss: 3.1322338581085205
Validation loss: 3.4462592576139714

Epoch: 6| Step: 1
Training loss: 3.2523932456970215
Validation loss: 3.394118450021231

Epoch: 6| Step: 2
Training loss: 2.9007606506347656
Validation loss: 3.3823526931065384

Epoch: 6| Step: 3
Training loss: 3.5748841762542725
Validation loss: 3.346067779807634

Epoch: 6| Step: 4
Training loss: 3.0456972122192383
Validation loss: 3.2945933726526078

Epoch: 6| Step: 5
Training loss: 3.276285171508789
Validation loss: 3.2830131541016283

Epoch: 6| Step: 6
Training loss: 3.6521177291870117
Validation loss: 3.2385067683394237

Epoch: 6| Step: 7
Training loss: 3.6958703994750977
Validation loss: 3.191149757754418

Epoch: 6| Step: 8
Training loss: 2.898179054260254
Validation loss: 3.1460444901579168

Epoch: 6| Step: 9
Training loss: 3.922880172729492
Validation loss: 3.1560202926717777

Epoch: 6| Step: 10
Training loss: 3.1950831413269043
Validation loss: 3.1116755905971734

Epoch: 6| Step: 11
Training loss: 2.939960479736328
Validation loss: 3.095640408095493

Epoch: 6| Step: 12
Training loss: 2.398739814758301
Validation loss: 3.0514499654052076

Epoch: 6| Step: 13
Training loss: 1.9502511024475098
Validation loss: 3.0257860819498696

Epoch: 24| Step: 0
Training loss: 3.507598400115967
Validation loss: 2.9924344247387302

Epoch: 6| Step: 1
Training loss: 2.8395509719848633
Validation loss: 2.9637047193383657

Epoch: 6| Step: 2
Training loss: 2.4983155727386475
Validation loss: 2.9343484370939192

Epoch: 6| Step: 3
Training loss: 4.01962947845459
Validation loss: 2.9323129243748163

Epoch: 6| Step: 4
Training loss: 1.7714390754699707
Validation loss: 2.866028367832143

Epoch: 6| Step: 5
Training loss: 2.6931653022766113
Validation loss: 2.8795056804533927

Epoch: 6| Step: 6
Training loss: 2.717306613922119
Validation loss: 2.858499244977069

Epoch: 6| Step: 7
Training loss: 2.721867799758911
Validation loss: 2.7956143092083674

Epoch: 6| Step: 8
Training loss: 2.9729294776916504
Validation loss: 2.8335639763903875

Epoch: 6| Step: 9
Training loss: 2.8395960330963135
Validation loss: 2.8150927969204482

Epoch: 6| Step: 10
Training loss: 3.165229320526123
Validation loss: 2.786025208811606

Epoch: 6| Step: 11
Training loss: 3.220261812210083
Validation loss: 2.7492388166407102

Epoch: 6| Step: 12
Training loss: 2.7477786540985107
Validation loss: 2.716990988741639

Epoch: 6| Step: 13
Training loss: 2.776869773864746
Validation loss: 2.7122433621396302

Epoch: 25| Step: 0
Training loss: 2.4279561042785645
Validation loss: 2.715221728048017

Epoch: 6| Step: 1
Training loss: 2.974189043045044
Validation loss: 2.691180277896184

Epoch: 6| Step: 2
Training loss: 2.7046022415161133
Validation loss: 2.655495330851565

Epoch: 6| Step: 3
Training loss: 2.8598968982696533
Validation loss: 2.6568907794132026

Epoch: 6| Step: 4
Training loss: 2.9495339393615723
Validation loss: 2.66091255218752

Epoch: 6| Step: 5
Training loss: 2.87815260887146
Validation loss: 2.5923738197613786

Epoch: 6| Step: 6
Training loss: 2.6038384437561035
Validation loss: 2.6088004112243652

Epoch: 6| Step: 7
Training loss: 2.2692711353302
Validation loss: 2.6099832109225694

Epoch: 6| Step: 8
Training loss: 2.6099143028259277
Validation loss: 2.5802396420509583

Epoch: 6| Step: 9
Training loss: 2.7126708030700684
Validation loss: 2.569866439347626

Epoch: 6| Step: 10
Training loss: 2.1697463989257812
Validation loss: 2.571560885316582

Epoch: 6| Step: 11
Training loss: 2.5184123516082764
Validation loss: 2.5581226605241016

Epoch: 6| Step: 12
Training loss: 3.472334623336792
Validation loss: 2.53905229414663

Epoch: 6| Step: 13
Training loss: 2.444871664047241
Validation loss: 2.5209628638400825

Epoch: 26| Step: 0
Training loss: 2.9810805320739746
Validation loss: 2.528628449286184

Epoch: 6| Step: 1
Training loss: 2.342015266418457
Validation loss: 2.5447909908909954

Epoch: 6| Step: 2
Training loss: 3.2477164268493652
Validation loss: 2.5423873701403217

Epoch: 6| Step: 3
Training loss: 2.1786699295043945
Validation loss: 2.4653411783197874

Epoch: 6| Step: 4
Training loss: 2.3742568492889404
Validation loss: 2.4920768455792497

Epoch: 6| Step: 5
Training loss: 2.806288719177246
Validation loss: 2.476938839881651

Epoch: 6| Step: 6
Training loss: 2.4626364707946777
Validation loss: 2.4699917993237896

Epoch: 6| Step: 7
Training loss: 2.6986312866210938
Validation loss: 2.45706376465418

Epoch: 6| Step: 8
Training loss: 2.815385103225708
Validation loss: 2.4472676810397895

Epoch: 6| Step: 9
Training loss: 2.3333539962768555
Validation loss: 2.4568920814862816

Epoch: 6| Step: 10
Training loss: 2.477327346801758
Validation loss: 2.490687818937404

Epoch: 6| Step: 11
Training loss: 2.5819168090820312
Validation loss: 2.454489936110794

Epoch: 6| Step: 12
Training loss: 2.566807270050049
Validation loss: 2.4824326627997944

Epoch: 6| Step: 13
Training loss: 3.238816261291504
Validation loss: 2.4471870801782094

Epoch: 27| Step: 0
Training loss: 2.9188647270202637
Validation loss: 2.4508467540946057

Epoch: 6| Step: 1
Training loss: 2.4483728408813477
Validation loss: 2.4569053701175156

Epoch: 6| Step: 2
Training loss: 2.684051990509033
Validation loss: 2.4312853120988414

Epoch: 6| Step: 3
Training loss: 2.2134461402893066
Validation loss: 2.419956276493688

Epoch: 6| Step: 4
Training loss: 3.1139302253723145
Validation loss: 2.4613275502317693

Epoch: 6| Step: 5
Training loss: 3.4395294189453125
Validation loss: 2.435457734651463

Epoch: 6| Step: 6
Training loss: 2.27781343460083
Validation loss: 2.4175021097224247

Epoch: 6| Step: 7
Training loss: 1.8059523105621338
Validation loss: 2.4498953716729277

Epoch: 6| Step: 8
Training loss: 2.993722438812256
Validation loss: 2.4462206389314387

Epoch: 6| Step: 9
Training loss: 2.677152395248413
Validation loss: 2.4314552173819592

Epoch: 6| Step: 10
Training loss: 2.9698164463043213
Validation loss: 2.382739532378412

Epoch: 6| Step: 11
Training loss: 2.5886335372924805
Validation loss: 2.4421997480495

Epoch: 6| Step: 12
Training loss: 2.331082344055176
Validation loss: 2.44151658140203

Epoch: 6| Step: 13
Training loss: 1.8467519283294678
Validation loss: 2.4327528066532587

Epoch: 28| Step: 0
Training loss: 2.420527935028076
Validation loss: 2.436528880109069

Epoch: 6| Step: 1
Training loss: 2.6955809593200684
Validation loss: 2.3964736948731127

Epoch: 6| Step: 2
Training loss: 2.2172539234161377
Validation loss: 2.3950727344841085

Epoch: 6| Step: 3
Training loss: 1.9077413082122803
Validation loss: 2.4212664096586165

Epoch: 6| Step: 4
Training loss: 2.247605800628662
Validation loss: 2.4041688416593816

Epoch: 6| Step: 5
Training loss: 2.5989341735839844
Validation loss: 2.4125853994841218

Epoch: 6| Step: 6
Training loss: 3.3864946365356445
Validation loss: 2.39823813848598

Epoch: 6| Step: 7
Training loss: 2.424038887023926
Validation loss: 2.416525674122636

Epoch: 6| Step: 8
Training loss: 2.8523507118225098
Validation loss: 2.42762283355959

Epoch: 6| Step: 9
Training loss: 3.3030757904052734
Validation loss: 2.390142907378494

Epoch: 6| Step: 10
Training loss: 2.9104318618774414
Validation loss: 2.4083086905940885

Epoch: 6| Step: 11
Training loss: 2.00893497467041
Validation loss: 2.363665608949559

Epoch: 6| Step: 12
Training loss: 2.3324787616729736
Validation loss: 2.4109541549477527

Epoch: 6| Step: 13
Training loss: 3.3582119941711426
Validation loss: 2.423870458397814

Epoch: 29| Step: 0
Training loss: 2.7083325386047363
Validation loss: 2.3877813534070085

Epoch: 6| Step: 1
Training loss: 2.3975908756256104
Validation loss: 2.396516628162835

Epoch: 6| Step: 2
Training loss: 2.696103572845459
Validation loss: 2.3835914929707847

Epoch: 6| Step: 3
Training loss: 2.9416496753692627
Validation loss: 2.4093214850271902

Epoch: 6| Step: 4
Training loss: 2.7416677474975586
Validation loss: 2.3853165077906784

Epoch: 6| Step: 5
Training loss: 3.1621768474578857
Validation loss: 2.4167154014751477

Epoch: 6| Step: 6
Training loss: 3.0659308433532715
Validation loss: 2.4091337778234996

Epoch: 6| Step: 7
Training loss: 2.4040746688842773
Validation loss: 2.390614709546489

Epoch: 6| Step: 8
Training loss: 2.5121076107025146
Validation loss: 2.4208407376402166

Epoch: 6| Step: 9
Training loss: 2.476407527923584
Validation loss: 2.4231681400729763

Epoch: 6| Step: 10
Training loss: 2.2206668853759766
Validation loss: 2.3659901401048065

Epoch: 6| Step: 11
Training loss: 1.7226002216339111
Validation loss: 2.4212965349997244

Epoch: 6| Step: 12
Training loss: 2.5655317306518555
Validation loss: 2.3598285785285373

Epoch: 6| Step: 13
Training loss: 2.3440332412719727
Validation loss: 2.405374898705431

Epoch: 30| Step: 0
Training loss: 2.5505428314208984
Validation loss: 2.3742375578931583

Epoch: 6| Step: 1
Training loss: 2.5560073852539062
Validation loss: 2.3715180325251755

Epoch: 6| Step: 2
Training loss: 3.5201311111450195
Validation loss: 2.3636976134392524

Epoch: 6| Step: 3
Training loss: 2.55334210395813
Validation loss: 2.3946083745648785

Epoch: 6| Step: 4
Training loss: 2.5938196182250977
Validation loss: 2.3546627695842455

Epoch: 6| Step: 5
Training loss: 2.7066831588745117
Validation loss: 2.3593554266037478

Epoch: 6| Step: 6
Training loss: 2.493417501449585
Validation loss: 2.3765272837813183

Epoch: 6| Step: 7
Training loss: 2.444201946258545
Validation loss: 2.3777498481094197

Epoch: 6| Step: 8
Training loss: 2.749394178390503
Validation loss: 2.3402783511787333

Epoch: 6| Step: 9
Training loss: 2.8899688720703125
Validation loss: 2.3759009145921275

Epoch: 6| Step: 10
Training loss: 2.0925583839416504
Validation loss: 2.408655438371884

Epoch: 6| Step: 11
Training loss: 2.2217495441436768
Validation loss: 2.391352612485168

Epoch: 6| Step: 12
Training loss: 2.60782527923584
Validation loss: 2.37778337155619

Epoch: 6| Step: 13
Training loss: 1.2414946556091309
Validation loss: 2.3906830690240346

Epoch: 31| Step: 0
Training loss: 3.2082910537719727
Validation loss: 2.3877205028328845

Epoch: 6| Step: 1
Training loss: 2.546505928039551
Validation loss: 2.3855332302790817

Epoch: 6| Step: 2
Training loss: 2.7966880798339844
Validation loss: 2.391233264759023

Epoch: 6| Step: 3
Training loss: 2.6010615825653076
Validation loss: 2.4055461524635233

Epoch: 6| Step: 4
Training loss: 2.5783894062042236
Validation loss: 2.405208565855539

Epoch: 6| Step: 5
Training loss: 2.0140342712402344
Validation loss: 2.409166920569635

Epoch: 6| Step: 6
Training loss: 2.9691617488861084
Validation loss: 2.37662087973728

Epoch: 6| Step: 7
Training loss: 2.5506045818328857
Validation loss: 2.3486474611425914

Epoch: 6| Step: 8
Training loss: 2.3526124954223633
Validation loss: 2.3618175214336765

Epoch: 6| Step: 9
Training loss: 2.4674429893493652
Validation loss: 2.405903018930907

Epoch: 6| Step: 10
Training loss: 2.726255416870117
Validation loss: 2.394802834398003

Epoch: 6| Step: 11
Training loss: 2.4212260246276855
Validation loss: 2.3648414329815934

Epoch: 6| Step: 12
Training loss: 2.091989040374756
Validation loss: 2.365666389465332

Epoch: 6| Step: 13
Training loss: 2.9442033767700195
Validation loss: 2.354911532453311

Epoch: 32| Step: 0
Training loss: 2.516317129135132
Validation loss: 2.3497076624183246

Epoch: 6| Step: 1
Training loss: 1.9261422157287598
Validation loss: 2.4112696852735294

Epoch: 6| Step: 2
Training loss: 2.862567186355591
Validation loss: 2.3670406828644457

Epoch: 6| Step: 3
Training loss: 2.290492534637451
Validation loss: 2.3889065711728987

Epoch: 6| Step: 4
Training loss: 2.2186315059661865
Validation loss: 2.3456910874253962

Epoch: 6| Step: 5
Training loss: 2.7275631427764893
Validation loss: 2.3617519332516577

Epoch: 6| Step: 6
Training loss: 2.803460121154785
Validation loss: 2.3609838626718007

Epoch: 6| Step: 7
Training loss: 2.1943445205688477
Validation loss: 2.3546112993712067

Epoch: 6| Step: 8
Training loss: 2.4014809131622314
Validation loss: 2.3849906049748903

Epoch: 6| Step: 9
Training loss: 2.8027772903442383
Validation loss: 2.3119366656067553

Epoch: 6| Step: 10
Training loss: 2.7339534759521484
Validation loss: 2.4030669453323528

Epoch: 6| Step: 11
Training loss: 3.1122615337371826
Validation loss: 2.367220301781931

Epoch: 6| Step: 12
Training loss: 2.6882569789886475
Validation loss: 2.3317226671403453

Epoch: 6| Step: 13
Training loss: 2.200192451477051
Validation loss: 2.359804954580081

Epoch: 33| Step: 0
Training loss: 2.4210333824157715
Validation loss: 2.351994163246565

Epoch: 6| Step: 1
Training loss: 2.9763851165771484
Validation loss: 2.332978338323614

Epoch: 6| Step: 2
Training loss: 2.0111465454101562
Validation loss: 2.3632508836766726

Epoch: 6| Step: 3
Training loss: 2.7828779220581055
Validation loss: 2.3598578719682592

Epoch: 6| Step: 4
Training loss: 3.183990955352783
Validation loss: 2.314071955219392

Epoch: 6| Step: 5
Training loss: 2.0916764736175537
Validation loss: 2.3440153547512588

Epoch: 6| Step: 6
Training loss: 2.444753408432007
Validation loss: 2.3412630583650325

Epoch: 6| Step: 7
Training loss: 2.0996334552764893
Validation loss: 2.3355089554222683

Epoch: 6| Step: 8
Training loss: 2.5032765865325928
Validation loss: 2.2998048310638755

Epoch: 6| Step: 9
Training loss: 2.781432628631592
Validation loss: 2.2863590742952082

Epoch: 6| Step: 10
Training loss: 2.090488910675049
Validation loss: 2.3369929508496354

Epoch: 6| Step: 11
Training loss: 2.9160962104797363
Validation loss: 2.3502685716075282

Epoch: 6| Step: 12
Training loss: 2.2741286754608154
Validation loss: 2.3215980247784684

Epoch: 6| Step: 13
Training loss: 3.4423255920410156
Validation loss: 2.376717869953443

Epoch: 34| Step: 0
Training loss: 2.331265926361084
Validation loss: 2.3280999827128586

Epoch: 6| Step: 1
Training loss: 2.5123753547668457
Validation loss: 2.3151075147813365

Epoch: 6| Step: 2
Training loss: 2.3386757373809814
Validation loss: 2.3374316641079482

Epoch: 6| Step: 3
Training loss: 3.229095458984375
Validation loss: 2.3956108426535003

Epoch: 6| Step: 4
Training loss: 2.342592716217041
Validation loss: 2.346810221672058

Epoch: 6| Step: 5
Training loss: 2.0215654373168945
Validation loss: 2.3221415550478044

Epoch: 6| Step: 6
Training loss: 2.806051731109619
Validation loss: 2.333606981462048

Epoch: 6| Step: 7
Training loss: 2.009087085723877
Validation loss: 2.3002260423475698

Epoch: 6| Step: 8
Training loss: 2.5135319232940674
Validation loss: 2.306539858541181

Epoch: 6| Step: 9
Training loss: 2.1479785442352295
Validation loss: 2.303553860674622

Epoch: 6| Step: 10
Training loss: 2.2093982696533203
Validation loss: 2.344651840066397

Epoch: 6| Step: 11
Training loss: 3.6674036979675293
Validation loss: 2.3289897006045104

Epoch: 6| Step: 12
Training loss: 2.2862653732299805
Validation loss: 2.314154745430075

Epoch: 6| Step: 13
Training loss: 3.283003568649292
Validation loss: 2.3078942119434314

Epoch: 35| Step: 0
Training loss: 1.3993802070617676
Validation loss: 2.3595154234158096

Epoch: 6| Step: 1
Training loss: 1.3680816888809204
Validation loss: 2.327146186623522

Epoch: 6| Step: 2
Training loss: 1.7759640216827393
Validation loss: 2.3411964242176344

Epoch: 6| Step: 3
Training loss: 1.914299726486206
Validation loss: 2.3271353501145557

Epoch: 6| Step: 4
Training loss: 2.740598201751709
Validation loss: 2.331545845154793

Epoch: 6| Step: 5
Training loss: 3.008425235748291
Validation loss: 2.3400024355098767

Epoch: 6| Step: 6
Training loss: 2.4972381591796875
Validation loss: 2.3311286818596626

Epoch: 6| Step: 7
Training loss: 2.6844749450683594
Validation loss: 2.303873654334776

Epoch: 6| Step: 8
Training loss: 3.3043148517608643
Validation loss: 2.350717862447103

Epoch: 6| Step: 9
Training loss: 3.79453706741333
Validation loss: 2.3068947958689865

Epoch: 6| Step: 10
Training loss: 2.0600123405456543
Validation loss: 2.316421160133936

Epoch: 6| Step: 11
Training loss: 2.7046940326690674
Validation loss: 2.3285007810079925

Epoch: 6| Step: 12
Training loss: 2.654198408126831
Validation loss: 2.3304247163957164

Epoch: 6| Step: 13
Training loss: 3.7387826442718506
Validation loss: 2.316446868322229

Epoch: 36| Step: 0
Training loss: 1.9519567489624023
Validation loss: 2.2664837145036265

Epoch: 6| Step: 1
Training loss: 2.9705471992492676
Validation loss: 2.3022653723275788

Epoch: 6| Step: 2
Training loss: 2.475144863128662
Validation loss: 2.3011150180652575

Epoch: 6| Step: 3
Training loss: 2.5730438232421875
Validation loss: 2.3055902322133384

Epoch: 6| Step: 4
Training loss: 2.3104145526885986
Validation loss: 2.3232133055246003

Epoch: 6| Step: 5
Training loss: 2.4998726844787598
Validation loss: 2.333664283957533

Epoch: 6| Step: 6
Training loss: 2.047144651412964
Validation loss: 2.3338854697442826

Epoch: 6| Step: 7
Training loss: 3.875840425491333
Validation loss: 2.359872523174491

Epoch: 6| Step: 8
Training loss: 2.5963640213012695
Validation loss: 2.3398050454355057

Epoch: 6| Step: 9
Training loss: 2.8293092250823975
Validation loss: 2.3482195510659167

Epoch: 6| Step: 10
Training loss: 2.300967216491699
Validation loss: 2.3054167609060965

Epoch: 6| Step: 11
Training loss: 1.9301791191101074
Validation loss: 2.332052634608361

Epoch: 6| Step: 12
Training loss: 2.221245765686035
Validation loss: 2.3653570528953307

Epoch: 6| Step: 13
Training loss: 2.3691296577453613
Validation loss: 2.3664873594878824

Epoch: 37| Step: 0
Training loss: 2.8979434967041016
Validation loss: 2.301481887858401

Epoch: 6| Step: 1
Training loss: 2.7408738136291504
Validation loss: 2.3300915559132895

Epoch: 6| Step: 2
Training loss: 2.339139938354492
Validation loss: 2.3124632399569274

Epoch: 6| Step: 3
Training loss: 3.239880084991455
Validation loss: 2.286496793070147

Epoch: 6| Step: 4
Training loss: 1.6456724405288696
Validation loss: 2.3291995063904793

Epoch: 6| Step: 5
Training loss: 1.912414312362671
Validation loss: 2.3795877400264946

Epoch: 6| Step: 6
Training loss: 2.2472822666168213
Validation loss: 2.323096929057952

Epoch: 6| Step: 7
Training loss: 1.3191684484481812
Validation loss: 2.3174518128877044

Epoch: 6| Step: 8
Training loss: 3.010237455368042
Validation loss: 2.280139846186484

Epoch: 6| Step: 9
Training loss: 2.629648208618164
Validation loss: 2.263707553186724

Epoch: 6| Step: 10
Training loss: 2.7537546157836914
Validation loss: 2.232863606945161

Epoch: 6| Step: 11
Training loss: 3.4952354431152344
Validation loss: 2.2434550767303794

Epoch: 6| Step: 12
Training loss: 2.0557241439819336
Validation loss: 2.2504774473046743

Epoch: 6| Step: 13
Training loss: 2.457152843475342
Validation loss: 2.2621192675764843

Epoch: 38| Step: 0
Training loss: 2.5053577423095703
Validation loss: 2.287464968619808

Epoch: 6| Step: 1
Training loss: 2.3760881423950195
Validation loss: 2.2948104002142466

Epoch: 6| Step: 2
Training loss: 2.6074702739715576
Validation loss: 2.290714422861735

Epoch: 6| Step: 3
Training loss: 1.7896747589111328
Validation loss: 2.2767880603831303

Epoch: 6| Step: 4
Training loss: 3.025468349456787
Validation loss: 2.2828100778723277

Epoch: 6| Step: 5
Training loss: 3.0573911666870117
Validation loss: 2.3316590375797723

Epoch: 6| Step: 6
Training loss: 2.8330109119415283
Validation loss: 2.2581707610878894

Epoch: 6| Step: 7
Training loss: 3.368499279022217
Validation loss: 2.267849827325472

Epoch: 6| Step: 8
Training loss: 1.8929314613342285
Validation loss: 2.288129929573305

Epoch: 6| Step: 9
Training loss: 2.0419187545776367
Validation loss: 2.319486815442321

Epoch: 6| Step: 10
Training loss: 2.828674793243408
Validation loss: 2.261996248716949

Epoch: 6| Step: 11
Training loss: 2.1515300273895264
Validation loss: 2.304297452331871

Epoch: 6| Step: 12
Training loss: 2.4344515800476074
Validation loss: 2.271575750843171

Epoch: 6| Step: 13
Training loss: 1.7895857095718384
Validation loss: 2.3338809756822485

Epoch: 39| Step: 0
Training loss: 2.2912449836730957
Validation loss: 2.2796266130221787

Epoch: 6| Step: 1
Training loss: 2.978087902069092
Validation loss: 2.302473473292525

Epoch: 6| Step: 2
Training loss: 2.565056800842285
Validation loss: 2.302367389843028

Epoch: 6| Step: 3
Training loss: 2.439387083053589
Validation loss: 2.3040447696562736

Epoch: 6| Step: 4
Training loss: 1.9345886707305908
Validation loss: 2.240730239499

Epoch: 6| Step: 5
Training loss: 2.719841718673706
Validation loss: 2.2132583792491625

Epoch: 6| Step: 6
Training loss: 1.8004552125930786
Validation loss: 2.2272628891852593

Epoch: 6| Step: 7
Training loss: 2.9091601371765137
Validation loss: 2.2715326483531664

Epoch: 6| Step: 8
Training loss: 2.542088031768799
Validation loss: 2.2660017949278637

Epoch: 6| Step: 9
Training loss: 2.659200668334961
Validation loss: 2.3094687692580687

Epoch: 6| Step: 10
Training loss: 2.5424280166625977
Validation loss: 2.320198997374504

Epoch: 6| Step: 11
Training loss: 2.0923032760620117
Validation loss: 2.3164647048519504

Epoch: 6| Step: 12
Training loss: 2.321014404296875
Validation loss: 2.2784840560728505

Epoch: 6| Step: 13
Training loss: 2.831578493118286
Validation loss: 2.274974548688499

Epoch: 40| Step: 0
Training loss: 1.984994649887085
Validation loss: 2.280046575812883

Epoch: 6| Step: 1
Training loss: 2.9350452423095703
Validation loss: 2.2504317478467057

Epoch: 6| Step: 2
Training loss: 1.9858179092407227
Validation loss: 2.2886246904250114

Epoch: 6| Step: 3
Training loss: 2.566457986831665
Validation loss: 2.275708213929207

Epoch: 6| Step: 4
Training loss: 2.173445463180542
Validation loss: 2.261476784624079

Epoch: 6| Step: 5
Training loss: 2.7311317920684814
Validation loss: 2.327835939263785

Epoch: 6| Step: 6
Training loss: 2.8612866401672363
Validation loss: 2.2567461741867887

Epoch: 6| Step: 7
Training loss: 1.7700002193450928
Validation loss: 2.2490505608179236

Epoch: 6| Step: 8
Training loss: 2.6110827922821045
Validation loss: 2.223611600937382

Epoch: 6| Step: 9
Training loss: 3.321564197540283
Validation loss: 2.241426767841462

Epoch: 6| Step: 10
Training loss: 2.3967409133911133
Validation loss: 2.2862590718012985

Epoch: 6| Step: 11
Training loss: 1.8841161727905273
Validation loss: 2.281009060080333

Epoch: 6| Step: 12
Training loss: 3.285679340362549
Validation loss: 2.213192832085394

Epoch: 6| Step: 13
Training loss: 1.9720145463943481
Validation loss: 2.221305242148779

Epoch: 41| Step: 0
Training loss: 2.5717694759368896
Validation loss: 2.267798839076873

Epoch: 6| Step: 1
Training loss: 2.632110357284546
Validation loss: 2.2184166805718535

Epoch: 6| Step: 2
Training loss: 2.2791221141815186
Validation loss: 2.325532926026211

Epoch: 6| Step: 3
Training loss: 2.7043848037719727
Validation loss: 2.251647831291281

Epoch: 6| Step: 4
Training loss: 1.8649929761886597
Validation loss: 2.3025543946091847

Epoch: 6| Step: 5
Training loss: 2.236264944076538
Validation loss: 2.2908014635885916

Epoch: 6| Step: 6
Training loss: 2.9747509956359863
Validation loss: 2.2710378503286712

Epoch: 6| Step: 7
Training loss: 2.4643561840057373
Validation loss: 2.2899269224495016

Epoch: 6| Step: 8
Training loss: 2.1775076389312744
Validation loss: 2.2422561722417034

Epoch: 6| Step: 9
Training loss: 2.2465596199035645
Validation loss: 2.278424547564599

Epoch: 6| Step: 10
Training loss: 2.6564788818359375
Validation loss: 2.2751742204030356

Epoch: 6| Step: 11
Training loss: 2.36035418510437
Validation loss: 2.218134310937697

Epoch: 6| Step: 12
Training loss: 2.5560803413391113
Validation loss: 2.293331787150393

Epoch: 6| Step: 13
Training loss: 2.026273488998413
Validation loss: 2.1949130181343324

Epoch: 42| Step: 0
Training loss: 1.96561861038208
Validation loss: 2.2979832310830393

Epoch: 6| Step: 1
Training loss: 3.057617664337158
Validation loss: 2.308453470148066

Epoch: 6| Step: 2
Training loss: 2.5679283142089844
Validation loss: 2.2454325640073387

Epoch: 6| Step: 3
Training loss: 2.241271495819092
Validation loss: 2.245739435636869

Epoch: 6| Step: 4
Training loss: 2.505075216293335
Validation loss: 2.2872593787408646

Epoch: 6| Step: 5
Training loss: 3.1837801933288574
Validation loss: 2.2676446002016784

Epoch: 6| Step: 6
Training loss: 3.1206703186035156
Validation loss: 2.3150718365946124

Epoch: 6| Step: 7
Training loss: 2.1367180347442627
Validation loss: 2.2870354126858454

Epoch: 6| Step: 8
Training loss: 2.2703356742858887
Validation loss: 2.271628395203621

Epoch: 6| Step: 9
Training loss: 2.1012425422668457
Validation loss: 2.2723302366913005

Epoch: 6| Step: 10
Training loss: 2.4186174869537354
Validation loss: 2.2527612665648102

Epoch: 6| Step: 11
Training loss: 1.9975695610046387
Validation loss: 2.264963403824837

Epoch: 6| Step: 12
Training loss: 1.9874106645584106
Validation loss: 2.2192504944339877

Epoch: 6| Step: 13
Training loss: 1.6170483827590942
Validation loss: 2.286181629344981

Epoch: 43| Step: 0
Training loss: 1.9182220697402954
Validation loss: 2.2948153249679075

Epoch: 6| Step: 1
Training loss: 2.7199478149414062
Validation loss: 2.301603377506297

Epoch: 6| Step: 2
Training loss: 2.108002185821533
Validation loss: 2.2257560119833997

Epoch: 6| Step: 3
Training loss: 2.5135788917541504
Validation loss: 2.2662904826543664

Epoch: 6| Step: 4
Training loss: 2.5754027366638184
Validation loss: 2.266604300468199

Epoch: 6| Step: 5
Training loss: 1.9544708728790283
Validation loss: 2.285399167768417

Epoch: 6| Step: 6
Training loss: 2.602665901184082
Validation loss: 2.2553935845692954

Epoch: 6| Step: 7
Training loss: 3.3294520378112793
Validation loss: 2.2904805983266523

Epoch: 6| Step: 8
Training loss: 2.4727284908294678
Validation loss: 2.235627597378146

Epoch: 6| Step: 9
Training loss: 2.8040120601654053
Validation loss: 2.252236376526535

Epoch: 6| Step: 10
Training loss: 1.7106094360351562
Validation loss: 2.2464229470940045

Epoch: 6| Step: 11
Training loss: 2.4119861125946045
Validation loss: 2.2637014799220587

Epoch: 6| Step: 12
Training loss: 2.8664941787719727
Validation loss: 2.2780515660521803

Epoch: 6| Step: 13
Training loss: 2.8294057846069336
Validation loss: 2.2512823894459713

Epoch: 44| Step: 0
Training loss: 2.869109630584717
Validation loss: 2.2313117019591795

Epoch: 6| Step: 1
Training loss: 3.25868558883667
Validation loss: 2.2675520886657057

Epoch: 6| Step: 2
Training loss: 1.6558942794799805
Validation loss: 2.2402218362336517

Epoch: 6| Step: 3
Training loss: 2.1676695346832275
Validation loss: 2.265458422322427

Epoch: 6| Step: 4
Training loss: 2.1992740631103516
Validation loss: 2.277673036821427

Epoch: 6| Step: 5
Training loss: 2.417302370071411
Validation loss: 2.2381568980473343

Epoch: 6| Step: 6
Training loss: 2.597480297088623
Validation loss: 2.2509496852915776

Epoch: 6| Step: 7
Training loss: 3.161386489868164
Validation loss: 2.2488645661261772

Epoch: 6| Step: 8
Training loss: 2.0129523277282715
Validation loss: 2.25238706732309

Epoch: 6| Step: 9
Training loss: 2.5354371070861816
Validation loss: 2.2042594776358655

Epoch: 6| Step: 10
Training loss: 2.191112756729126
Validation loss: 2.2348853875232

Epoch: 6| Step: 11
Training loss: 2.039106607437134
Validation loss: 2.2129793705478793

Epoch: 6| Step: 12
Training loss: 2.1999282836914062
Validation loss: 2.2138407230377197

Epoch: 6| Step: 13
Training loss: 2.851839780807495
Validation loss: 2.2497695210159465

Epoch: 45| Step: 0
Training loss: 2.000950813293457
Validation loss: 2.24178950120044

Epoch: 6| Step: 1
Training loss: 1.465040922164917
Validation loss: 2.2354385724631687

Epoch: 6| Step: 2
Training loss: 2.5421481132507324
Validation loss: 2.194935573044644

Epoch: 6| Step: 3
Training loss: 2.7075655460357666
Validation loss: 2.2046263576835714

Epoch: 6| Step: 4
Training loss: 2.783254623413086
Validation loss: 2.251519395459083

Epoch: 6| Step: 5
Training loss: 2.5460832118988037
Validation loss: 2.2123649940695813

Epoch: 6| Step: 6
Training loss: 2.299410104751587
Validation loss: 2.251019177898284

Epoch: 6| Step: 7
Training loss: 2.676832675933838
Validation loss: 2.2457759893068703

Epoch: 6| Step: 8
Training loss: 2.755230188369751
Validation loss: 2.225769621069713

Epoch: 6| Step: 9
Training loss: 2.323589563369751
Validation loss: 2.218155330227267

Epoch: 6| Step: 10
Training loss: 2.9105939865112305
Validation loss: 2.2491377604904996

Epoch: 6| Step: 11
Training loss: 2.094085693359375
Validation loss: 2.164837916692098

Epoch: 6| Step: 12
Training loss: 2.308675765991211
Validation loss: 2.2675011824536067

Epoch: 6| Step: 13
Training loss: 2.132594585418701
Validation loss: 2.218703503249794

Epoch: 46| Step: 0
Training loss: 2.7380905151367188
Validation loss: 2.2203881612388034

Epoch: 6| Step: 1
Training loss: 1.961240291595459
Validation loss: 2.2461216962465675

Epoch: 6| Step: 2
Training loss: 2.6648287773132324
Validation loss: 2.341164694037489

Epoch: 6| Step: 3
Training loss: 2.4887185096740723
Validation loss: 2.213434120660187

Epoch: 6| Step: 4
Training loss: 2.201476812362671
Validation loss: 2.255617500633322

Epoch: 6| Step: 5
Training loss: 2.2390284538269043
Validation loss: 2.2879539048799904

Epoch: 6| Step: 6
Training loss: 2.958171844482422
Validation loss: 2.2564136828145673

Epoch: 6| Step: 7
Training loss: 2.656352996826172
Validation loss: 2.221488703963577

Epoch: 6| Step: 8
Training loss: 1.8831892013549805
Validation loss: 2.2743562370218258

Epoch: 6| Step: 9
Training loss: 2.6615519523620605
Validation loss: 2.278473197772939

Epoch: 6| Step: 10
Training loss: 1.8318636417388916
Validation loss: 2.2140531181007304

Epoch: 6| Step: 11
Training loss: 2.791166305541992
Validation loss: 2.235749178035285

Epoch: 6| Step: 12
Training loss: 2.597996234893799
Validation loss: 2.2190565255380448

Epoch: 6| Step: 13
Training loss: 2.30383563041687
Validation loss: 2.2388957828603764

Epoch: 47| Step: 0
Training loss: 2.5558083057403564
Validation loss: 2.2087224016907396

Epoch: 6| Step: 1
Training loss: 2.590789318084717
Validation loss: 2.272658558302028

Epoch: 6| Step: 2
Training loss: 2.2879538536071777
Validation loss: 2.2836789418292303

Epoch: 6| Step: 3
Training loss: 2.248805522918701
Validation loss: 2.247029104540425

Epoch: 6| Step: 4
Training loss: 2.8829259872436523
Validation loss: 2.2112438089104107

Epoch: 6| Step: 5
Training loss: 2.0514538288116455
Validation loss: 2.2418997903023996

Epoch: 6| Step: 6
Training loss: 3.030917167663574
Validation loss: 2.2542659992812784

Epoch: 6| Step: 7
Training loss: 2.223356246948242
Validation loss: 2.2806830406188965

Epoch: 6| Step: 8
Training loss: 2.188408613204956
Validation loss: 2.2624521281129573

Epoch: 6| Step: 9
Training loss: 2.2886033058166504
Validation loss: 2.2555095072715514

Epoch: 6| Step: 10
Training loss: 2.2345945835113525
Validation loss: 2.2767104743629374

Epoch: 6| Step: 11
Training loss: 2.5338237285614014
Validation loss: 2.261338713348553

Epoch: 6| Step: 12
Training loss: 1.8049604892730713
Validation loss: 2.3107888544759443

Epoch: 6| Step: 13
Training loss: 2.7284185886383057
Validation loss: 2.174164895088442

Epoch: 48| Step: 0
Training loss: 2.8221685886383057
Validation loss: 2.254924294769123

Epoch: 6| Step: 1
Training loss: 2.498318672180176
Validation loss: 2.231550347420477

Epoch: 6| Step: 2
Training loss: 3.0284976959228516
Validation loss: 2.2319156739019577

Epoch: 6| Step: 3
Training loss: 2.0925145149230957
Validation loss: 2.1925504207611084

Epoch: 6| Step: 4
Training loss: 2.5514485836029053
Validation loss: 2.195775132025442

Epoch: 6| Step: 5
Training loss: 2.381922483444214
Validation loss: 2.2816600389378046

Epoch: 6| Step: 6
Training loss: 2.214468002319336
Validation loss: 2.2412271038178475

Epoch: 6| Step: 7
Training loss: 2.585308313369751
Validation loss: 2.2072077694759575

Epoch: 6| Step: 8
Training loss: 1.6213018894195557
Validation loss: 2.2800738862765733

Epoch: 6| Step: 9
Training loss: 2.715940475463867
Validation loss: 2.2577673568520495

Epoch: 6| Step: 10
Training loss: 2.3608317375183105
Validation loss: 2.2205465685936714

Epoch: 6| Step: 11
Training loss: 1.9011924266815186
Validation loss: 2.257880682586342

Epoch: 6| Step: 12
Training loss: 1.983629822731018
Validation loss: 2.2233593040897

Epoch: 6| Step: 13
Training loss: 2.3859703540802
Validation loss: 2.2594157136896604

Epoch: 49| Step: 0
Training loss: 2.466552495956421
Validation loss: 2.2164850581076836

Epoch: 6| Step: 1
Training loss: 1.9859371185302734
Validation loss: 2.219156285767914

Epoch: 6| Step: 2
Training loss: 2.2916107177734375
Validation loss: 2.262190762386527

Epoch: 6| Step: 3
Training loss: 2.9779276847839355
Validation loss: 2.2209271128459642

Epoch: 6| Step: 4
Training loss: 2.330216884613037
Validation loss: 2.2549366002441733

Epoch: 6| Step: 5
Training loss: 2.3258914947509766
Validation loss: 2.2094672520955405

Epoch: 6| Step: 6
Training loss: 2.8106303215026855
Validation loss: 2.2366348492201937

Epoch: 6| Step: 7
Training loss: 2.002218246459961
Validation loss: 2.244914649635233

Epoch: 6| Step: 8
Training loss: 2.074310779571533
Validation loss: 2.1917115693451255

Epoch: 6| Step: 9
Training loss: 1.922924280166626
Validation loss: 2.230417843787901

Epoch: 6| Step: 10
Training loss: 2.7085583209991455
Validation loss: 2.1984237009479153

Epoch: 6| Step: 11
Training loss: 1.8009288311004639
Validation loss: 2.2552366282350276

Epoch: 6| Step: 12
Training loss: 3.2899250984191895
Validation loss: 2.218981992813849

Epoch: 6| Step: 13
Training loss: 2.970831871032715
Validation loss: 2.197298942073699

Epoch: 50| Step: 0
Training loss: 2.1784682273864746
Validation loss: 2.230541585594095

Epoch: 6| Step: 1
Training loss: 3.060819387435913
Validation loss: 2.233817551725654

Epoch: 6| Step: 2
Training loss: 2.3129053115844727
Validation loss: 2.2578355958384853

Epoch: 6| Step: 3
Training loss: 2.7110037803649902
Validation loss: 2.2250697510216826

Epoch: 6| Step: 4
Training loss: 2.3404176235198975
Validation loss: 2.2434718147400887

Epoch: 6| Step: 5
Training loss: 1.9037744998931885
Validation loss: 2.27122559085969

Epoch: 6| Step: 6
Training loss: 2.8189821243286133
Validation loss: 2.2399482060504217

Epoch: 6| Step: 7
Training loss: 2.275691270828247
Validation loss: 2.2247513468547533

Epoch: 6| Step: 8
Training loss: 2.6035377979278564
Validation loss: 2.172638213762673

Epoch: 6| Step: 9
Training loss: 2.4394726753234863
Validation loss: 2.1896476284150155

Epoch: 6| Step: 10
Training loss: 2.225620985031128
Validation loss: 2.2281334733450286

Epoch: 6| Step: 11
Training loss: 2.502260208129883
Validation loss: 2.208950350361486

Epoch: 6| Step: 12
Training loss: 1.5938777923583984
Validation loss: 2.2427786934760308

Epoch: 6| Step: 13
Training loss: 3.058002471923828
Validation loss: 2.25904167339366

Epoch: 51| Step: 0
Training loss: 2.9747345447540283
Validation loss: 2.2625159191828903

Epoch: 6| Step: 1
Training loss: 2.3434553146362305
Validation loss: 2.1996321485888575

Epoch: 6| Step: 2
Training loss: 2.2608749866485596
Validation loss: 2.177820528707197

Epoch: 6| Step: 3
Training loss: 2.8208632469177246
Validation loss: 2.2595224611220823

Epoch: 6| Step: 4
Training loss: 2.5600736141204834
Validation loss: 2.243376047380509

Epoch: 6| Step: 5
Training loss: 1.9723223447799683
Validation loss: 2.259676694869995

Epoch: 6| Step: 6
Training loss: 1.908778190612793
Validation loss: 2.1784723574115383

Epoch: 6| Step: 7
Training loss: 1.6650652885437012
Validation loss: 2.2016256291379213

Epoch: 6| Step: 8
Training loss: 2.4041502475738525
Validation loss: 2.1970147291819253

Epoch: 6| Step: 9
Training loss: 2.553581714630127
Validation loss: 2.20321975984881

Epoch: 6| Step: 10
Training loss: 2.7414586544036865
Validation loss: 2.190780581966523

Epoch: 6| Step: 11
Training loss: 2.097675323486328
Validation loss: 2.1668194519576205

Epoch: 6| Step: 12
Training loss: 2.5916671752929688
Validation loss: 2.1982498707309848

Epoch: 6| Step: 13
Training loss: 2.367001533508301
Validation loss: 2.183510967480239

Epoch: 52| Step: 0
Training loss: 3.1767501831054688
Validation loss: 2.263420386980939

Epoch: 6| Step: 1
Training loss: 3.077284336090088
Validation loss: 2.215714026522893

Epoch: 6| Step: 2
Training loss: 2.4872570037841797
Validation loss: 2.2307150235740085

Epoch: 6| Step: 3
Training loss: 1.4803696870803833
Validation loss: 2.2742841551380772

Epoch: 6| Step: 4
Training loss: 2.6320574283599854
Validation loss: 2.2045415652695524

Epoch: 6| Step: 5
Training loss: 2.0178489685058594
Validation loss: 2.157057128926759

Epoch: 6| Step: 6
Training loss: 2.711798667907715
Validation loss: 2.2345802066146687

Epoch: 6| Step: 7
Training loss: 2.7948646545410156
Validation loss: 2.233351335730604

Epoch: 6| Step: 8
Training loss: 2.0394091606140137
Validation loss: 2.235413756421817

Epoch: 6| Step: 9
Training loss: 2.137463331222534
Validation loss: 2.2163283786466046

Epoch: 6| Step: 10
Training loss: 1.9919588565826416
Validation loss: 2.1736962974712415

Epoch: 6| Step: 11
Training loss: 2.044919967651367
Validation loss: 2.2118665120934926

Epoch: 6| Step: 12
Training loss: 2.5693740844726562
Validation loss: 2.2550397431978615

Epoch: 6| Step: 13
Training loss: 1.6156363487243652
Validation loss: 2.1145904512815576

Epoch: 53| Step: 0
Training loss: 2.054720640182495
Validation loss: 2.1991848586707987

Epoch: 6| Step: 1
Training loss: 2.3780908584594727
Validation loss: 2.1980914902943436

Epoch: 6| Step: 2
Training loss: 1.3674077987670898
Validation loss: 2.220154017530462

Epoch: 6| Step: 3
Training loss: 3.158153533935547
Validation loss: 2.2312310305974816

Epoch: 6| Step: 4
Training loss: 2.6818971633911133
Validation loss: 2.1506361474273024

Epoch: 6| Step: 5
Training loss: 2.6037423610687256
Validation loss: 2.211524965942547

Epoch: 6| Step: 6
Training loss: 1.7120610475540161
Validation loss: 2.209271123332362

Epoch: 6| Step: 7
Training loss: 1.5902725458145142
Validation loss: 2.1878155187893937

Epoch: 6| Step: 8
Training loss: 2.412465810775757
Validation loss: 2.254557622376309

Epoch: 6| Step: 9
Training loss: 3.0992379188537598
Validation loss: 2.2104694381836922

Epoch: 6| Step: 10
Training loss: 2.499300956726074
Validation loss: 2.164857769525179

Epoch: 6| Step: 11
Training loss: 2.223041534423828
Validation loss: 2.175326426823934

Epoch: 6| Step: 12
Training loss: 2.8215949535369873
Validation loss: 2.2390501012084303

Epoch: 6| Step: 13
Training loss: 2.9142301082611084
Validation loss: 2.1964213617386354

Epoch: 54| Step: 0
Training loss: 2.8865723609924316
Validation loss: 2.1656652060888146

Epoch: 6| Step: 1
Training loss: 1.6298696994781494
Validation loss: 2.1981637247147097

Epoch: 6| Step: 2
Training loss: 1.5975261926651
Validation loss: 2.1283451921196392

Epoch: 6| Step: 3
Training loss: 2.8441991806030273
Validation loss: 2.1532553985554683

Epoch: 6| Step: 4
Training loss: 2.582030773162842
Validation loss: 2.202377224481234

Epoch: 6| Step: 5
Training loss: 2.5108866691589355
Validation loss: 2.222865096984371

Epoch: 6| Step: 6
Training loss: 3.0475149154663086
Validation loss: 2.2261892287961897

Epoch: 6| Step: 7
Training loss: 2.7969441413879395
Validation loss: 2.176552305939377

Epoch: 6| Step: 8
Training loss: 2.0616273880004883
Validation loss: 2.152963264014131

Epoch: 6| Step: 9
Training loss: 2.1038646697998047
Validation loss: 2.1961031293356292

Epoch: 6| Step: 10
Training loss: 2.7522330284118652
Validation loss: 2.2643067042032876

Epoch: 6| Step: 11
Training loss: 1.5729632377624512
Validation loss: 2.21218712611865

Epoch: 6| Step: 12
Training loss: 1.9579672813415527
Validation loss: 2.180556478038911

Epoch: 6| Step: 13
Training loss: 3.0449838638305664
Validation loss: 2.210044526284741

Epoch: 55| Step: 0
Training loss: 2.0243887901306152
Validation loss: 2.2211051525608188

Epoch: 6| Step: 1
Training loss: 2.0229687690734863
Validation loss: 2.139487135794855

Epoch: 6| Step: 2
Training loss: 2.8758416175842285
Validation loss: 2.1863771330925728

Epoch: 6| Step: 3
Training loss: 2.847343921661377
Validation loss: 2.1325924217060046

Epoch: 6| Step: 4
Training loss: 1.5244145393371582
Validation loss: 2.18895064374452

Epoch: 6| Step: 5
Training loss: 2.779423952102661
Validation loss: 2.2252241514062368

Epoch: 6| Step: 6
Training loss: 2.6317520141601562
Validation loss: 2.2033563788219164

Epoch: 6| Step: 7
Training loss: 2.75167179107666
Validation loss: 2.1859767283162763

Epoch: 6| Step: 8
Training loss: 2.354316234588623
Validation loss: 2.1475735659240396

Epoch: 6| Step: 9
Training loss: 2.0639729499816895
Validation loss: 2.1545065705494215

Epoch: 6| Step: 10
Training loss: 1.456627368927002
Validation loss: 2.2128940448966077

Epoch: 6| Step: 11
Training loss: 2.5339417457580566
Validation loss: 2.2242687863688313

Epoch: 6| Step: 12
Training loss: 2.6288340091705322
Validation loss: 2.2628141295525337

Epoch: 6| Step: 13
Training loss: 2.9749271869659424
Validation loss: 2.194951759871616

Epoch: 56| Step: 0
Training loss: 2.1812031269073486
Validation loss: 2.1814136940945863

Epoch: 6| Step: 1
Training loss: 2.0147247314453125
Validation loss: 2.2331503219501947

Epoch: 6| Step: 2
Training loss: 2.574662685394287
Validation loss: 2.187581785263554

Epoch: 6| Step: 3
Training loss: 2.6142802238464355
Validation loss: 2.2251591259433376

Epoch: 6| Step: 4
Training loss: 2.0456554889678955
Validation loss: 2.1364950877363964

Epoch: 6| Step: 5
Training loss: 2.0235729217529297
Validation loss: 2.1962671049179567

Epoch: 6| Step: 6
Training loss: 1.8247941732406616
Validation loss: 2.2171875866510535

Epoch: 6| Step: 7
Training loss: 3.093477725982666
Validation loss: 2.264849844799247

Epoch: 6| Step: 8
Training loss: 1.4660040140151978
Validation loss: 2.219774785862174

Epoch: 6| Step: 9
Training loss: 2.2422280311584473
Validation loss: 2.2384852286308043

Epoch: 6| Step: 10
Training loss: 2.426241636276245
Validation loss: 2.1846458040257937

Epoch: 6| Step: 11
Training loss: 2.574009895324707
Validation loss: 2.154215684501074

Epoch: 6| Step: 12
Training loss: 3.2979817390441895
Validation loss: 2.1691014330874205

Epoch: 6| Step: 13
Training loss: 2.6035070419311523
Validation loss: 2.183807989602448

Epoch: 57| Step: 0
Training loss: 2.2368574142456055
Validation loss: 2.251887324035809

Epoch: 6| Step: 1
Training loss: 2.374286651611328
Validation loss: 2.2166937423008743

Epoch: 6| Step: 2
Training loss: 2.071624755859375
Validation loss: 2.2525576981165076

Epoch: 6| Step: 3
Training loss: 2.1191513538360596
Validation loss: 2.265074009536415

Epoch: 6| Step: 4
Training loss: 2.7088825702667236
Validation loss: 2.1155444306711995

Epoch: 6| Step: 5
Training loss: 2.7411949634552
Validation loss: 2.196255971026677

Epoch: 6| Step: 6
Training loss: 2.6141881942749023
Validation loss: 2.2186124145343737

Epoch: 6| Step: 7
Training loss: 2.5561013221740723
Validation loss: 2.205487101308761

Epoch: 6| Step: 8
Training loss: 2.4013407230377197
Validation loss: 2.196645180384318

Epoch: 6| Step: 9
Training loss: 1.4728730916976929
Validation loss: 2.2067412881441015

Epoch: 6| Step: 10
Training loss: 2.192002773284912
Validation loss: 2.1782606391496557

Epoch: 6| Step: 11
Training loss: 2.6434452533721924
Validation loss: 2.187997833375008

Epoch: 6| Step: 12
Training loss: 2.9598708152770996
Validation loss: 2.1892348361271683

Epoch: 6| Step: 13
Training loss: 1.972859263420105
Validation loss: 2.2291526384251092

Epoch: 58| Step: 0
Training loss: 2.5417754650115967
Validation loss: 2.2213960770637757

Epoch: 6| Step: 1
Training loss: 2.5122225284576416
Validation loss: 2.2052630403990388

Epoch: 6| Step: 2
Training loss: 2.346139907836914
Validation loss: 2.1996073748475764

Epoch: 6| Step: 3
Training loss: 1.9652804136276245
Validation loss: 2.157420059686066

Epoch: 6| Step: 4
Training loss: 2.631463050842285
Validation loss: 2.1687596792815835

Epoch: 6| Step: 5
Training loss: 2.318392753601074
Validation loss: 2.2865919015740834

Epoch: 6| Step: 6
Training loss: 2.3143911361694336
Validation loss: 2.1501880140714746

Epoch: 6| Step: 7
Training loss: 2.1724047660827637
Validation loss: 2.173057431815773

Epoch: 6| Step: 8
Training loss: 1.89096200466156
Validation loss: 2.2134313557737615

Epoch: 6| Step: 9
Training loss: 2.9422574043273926
Validation loss: 2.2280788242176013

Epoch: 6| Step: 10
Training loss: 1.8601703643798828
Validation loss: 2.2363597936527704

Epoch: 6| Step: 11
Training loss: 2.2826926708221436
Validation loss: 2.2474258240833076

Epoch: 6| Step: 12
Training loss: 1.993893027305603
Validation loss: 2.214297907326811

Epoch: 6| Step: 13
Training loss: 2.0829052925109863
Validation loss: 2.2100098850906535

Epoch: 59| Step: 0
Training loss: 2.2513349056243896
Validation loss: 2.259236656209474

Epoch: 6| Step: 1
Training loss: 2.3961095809936523
Validation loss: 2.2062172120617283

Epoch: 6| Step: 2
Training loss: 2.802278995513916
Validation loss: 2.2307711647402857

Epoch: 6| Step: 3
Training loss: 2.4591407775878906
Validation loss: 2.3176032317582

Epoch: 6| Step: 4
Training loss: 2.5845861434936523
Validation loss: 2.159949815401467

Epoch: 6| Step: 5
Training loss: 2.3595290184020996
Validation loss: 2.199102162032999

Epoch: 6| Step: 6
Training loss: 1.778731346130371
Validation loss: 2.1911171149182063

Epoch: 6| Step: 7
Training loss: 2.871828079223633
Validation loss: 2.226694363419728

Epoch: 6| Step: 8
Training loss: 2.1617588996887207
Validation loss: 2.13281617113339

Epoch: 6| Step: 9
Training loss: 2.0659964084625244
Validation loss: 2.1909025125606085

Epoch: 6| Step: 10
Training loss: 2.6807947158813477
Validation loss: 2.1254435329027075

Epoch: 6| Step: 11
Training loss: 2.2961795330047607
Validation loss: 2.212870431202714

Epoch: 6| Step: 12
Training loss: 1.920506477355957
Validation loss: 2.2307351609712005

Epoch: 6| Step: 13
Training loss: 1.4121184349060059
Validation loss: 2.2339307774779615

Epoch: 60| Step: 0
Training loss: 2.77162766456604
Validation loss: 2.2401543971030944

Epoch: 6| Step: 1
Training loss: 2.532088279724121
Validation loss: 2.2597671119115685

Epoch: 6| Step: 2
Training loss: 2.1282873153686523
Validation loss: 2.246913247211005

Epoch: 6| Step: 3
Training loss: 2.012850761413574
Validation loss: 2.2066066483015656

Epoch: 6| Step: 4
Training loss: 2.1618549823760986
Validation loss: 2.2599934224159486

Epoch: 6| Step: 5
Training loss: 3.2764663696289062
Validation loss: 2.227899488582406

Epoch: 6| Step: 6
Training loss: 3.221024513244629
Validation loss: 2.2068030577833935

Epoch: 6| Step: 7
Training loss: 1.8612840175628662
Validation loss: 2.239762508740989

Epoch: 6| Step: 8
Training loss: 1.9630706310272217
Validation loss: 2.236879356445805

Epoch: 6| Step: 9
Training loss: 2.176295280456543
Validation loss: 2.183535702766911

Epoch: 6| Step: 10
Training loss: 2.2806546688079834
Validation loss: 2.194744158816594

Epoch: 6| Step: 11
Training loss: 2.2314610481262207
Validation loss: 2.2139668695388304

Epoch: 6| Step: 12
Training loss: 1.6746766567230225
Validation loss: 2.159213154546676

Epoch: 6| Step: 13
Training loss: 2.5228025913238525
Validation loss: 2.2308673602278515

Epoch: 61| Step: 0
Training loss: 2.495197296142578
Validation loss: 2.139940923260104

Epoch: 6| Step: 1
Training loss: 1.8363986015319824
Validation loss: 2.232368274401593

Epoch: 6| Step: 2
Training loss: 1.7089791297912598
Validation loss: 2.2297192632511096

Epoch: 6| Step: 3
Training loss: 2.7160825729370117
Validation loss: 2.210746631827406

Epoch: 6| Step: 4
Training loss: 1.822350263595581
Validation loss: 2.1851423594259445

Epoch: 6| Step: 5
Training loss: 2.3109052181243896
Validation loss: 2.16723661012547

Epoch: 6| Step: 6
Training loss: 2.974745273590088
Validation loss: 2.219468432088052

Epoch: 6| Step: 7
Training loss: 2.4154324531555176
Validation loss: 2.1598979234695435

Epoch: 6| Step: 8
Training loss: 2.8407931327819824
Validation loss: 2.1200464771639917

Epoch: 6| Step: 9
Training loss: 1.8813436031341553
Validation loss: 2.196551504955497

Epoch: 6| Step: 10
Training loss: 1.821755051612854
Validation loss: 2.1708265196892524

Epoch: 6| Step: 11
Training loss: 2.4432244300842285
Validation loss: 2.1927932141929545

Epoch: 6| Step: 12
Training loss: 3.107506275177002
Validation loss: 2.223048879254249

Epoch: 6| Step: 13
Training loss: 2.3684656620025635
Validation loss: 2.1909766530477874

Epoch: 62| Step: 0
Training loss: 2.267305850982666
Validation loss: 2.1599215512634604

Epoch: 6| Step: 1
Training loss: 2.118140697479248
Validation loss: 2.238949627004644

Epoch: 6| Step: 2
Training loss: 2.365605592727661
Validation loss: 2.0985777608809935

Epoch: 6| Step: 3
Training loss: 2.1053054332733154
Validation loss: 2.1902760408257924

Epoch: 6| Step: 4
Training loss: 2.5616602897644043
Validation loss: 2.205909687985656

Epoch: 6| Step: 5
Training loss: 2.746857166290283
Validation loss: 2.189645808230164

Epoch: 6| Step: 6
Training loss: 2.5366785526275635
Validation loss: 2.2060802444334953

Epoch: 6| Step: 7
Training loss: 1.9478788375854492
Validation loss: 2.1892778399170085

Epoch: 6| Step: 8
Training loss: 3.06105899810791
Validation loss: 2.1976440029759563

Epoch: 6| Step: 9
Training loss: 1.7470858097076416
Validation loss: 2.2115967504439817

Epoch: 6| Step: 10
Training loss: 1.8079595565795898
Validation loss: 2.2274631043916107

Epoch: 6| Step: 11
Training loss: 2.6069915294647217
Validation loss: 2.26342515278888

Epoch: 6| Step: 12
Training loss: 2.5680994987487793
Validation loss: 2.2154097044339744

Epoch: 6| Step: 13
Training loss: 2.806833267211914
Validation loss: 2.2024960851156585

Epoch: 63| Step: 0
Training loss: 2.155766248703003
Validation loss: 2.1870716912772066

Epoch: 6| Step: 1
Training loss: 2.518556833267212
Validation loss: 2.195073043146441

Epoch: 6| Step: 2
Training loss: 2.3962652683258057
Validation loss: 2.1972424919887255

Epoch: 6| Step: 3
Training loss: 2.4771199226379395
Validation loss: 2.242112846784694

Epoch: 6| Step: 4
Training loss: 1.8931571245193481
Validation loss: 2.2446892287141536

Epoch: 6| Step: 5
Training loss: 1.7999460697174072
Validation loss: 2.2272483315519107

Epoch: 6| Step: 6
Training loss: 2.4915149211883545
Validation loss: 2.202177852712652

Epoch: 6| Step: 7
Training loss: 2.538848876953125
Validation loss: 2.2508538935774114

Epoch: 6| Step: 8
Training loss: 3.0770320892333984
Validation loss: 2.1882333101764804

Epoch: 6| Step: 9
Training loss: 2.582535982131958
Validation loss: 2.3059362672990367

Epoch: 6| Step: 10
Training loss: 2.1627449989318848
Validation loss: 2.232552400199316

Epoch: 6| Step: 11
Training loss: 2.4598805904388428
Validation loss: 2.2116515854353547

Epoch: 6| Step: 12
Training loss: 1.8670685291290283
Validation loss: 2.2122853943096694

Epoch: 6| Step: 13
Training loss: 2.778637647628784
Validation loss: 2.2058012613686184

Epoch: 64| Step: 0
Training loss: 2.0097575187683105
Validation loss: 2.2275799218044487

Epoch: 6| Step: 1
Training loss: 1.2999227046966553
Validation loss: 2.277860790170649

Epoch: 6| Step: 2
Training loss: 2.3634564876556396
Validation loss: 2.2112207271719493

Epoch: 6| Step: 3
Training loss: 2.456430435180664
Validation loss: 2.2175510262930267

Epoch: 6| Step: 4
Training loss: 2.1887831687927246
Validation loss: 2.2637948425867225

Epoch: 6| Step: 5
Training loss: 2.772224187850952
Validation loss: 2.1556879704998386

Epoch: 6| Step: 6
Training loss: 1.907546043395996
Validation loss: 2.2279090445528746

Epoch: 6| Step: 7
Training loss: 1.9284777641296387
Validation loss: 2.250346435013638

Epoch: 6| Step: 8
Training loss: 3.331214427947998
Validation loss: 2.2610435332021406

Epoch: 6| Step: 9
Training loss: 2.2862555980682373
Validation loss: 2.1910509012078725

Epoch: 6| Step: 10
Training loss: 2.5988783836364746
Validation loss: 2.1897977270105833

Epoch: 6| Step: 11
Training loss: 2.485485553741455
Validation loss: 2.2876348213482927

Epoch: 6| Step: 12
Training loss: 2.202354907989502
Validation loss: 2.1191492849780666

Epoch: 6| Step: 13
Training loss: 2.601804494857788
Validation loss: 2.2067251974536526

Epoch: 65| Step: 0
Training loss: 2.1944737434387207
Validation loss: 2.182519233354958

Epoch: 6| Step: 1
Training loss: 1.7517898082733154
Validation loss: 2.253749846130289

Epoch: 6| Step: 2
Training loss: 1.5640296936035156
Validation loss: 2.2117146086949173

Epoch: 6| Step: 3
Training loss: 2.3766841888427734
Validation loss: 2.246748101326727

Epoch: 6| Step: 4
Training loss: 2.7150330543518066
Validation loss: 2.171648871514105

Epoch: 6| Step: 5
Training loss: 1.9208730459213257
Validation loss: 2.204522543056037

Epoch: 6| Step: 6
Training loss: 2.954993724822998
Validation loss: 2.2217889037183536

Epoch: 6| Step: 7
Training loss: 3.174367904663086
Validation loss: 2.1997608753942672

Epoch: 6| Step: 8
Training loss: 2.377931594848633
Validation loss: 2.1924091821075766

Epoch: 6| Step: 9
Training loss: 2.98288893699646
Validation loss: 2.2317021687825522

Epoch: 6| Step: 10
Training loss: 1.8680484294891357
Validation loss: 2.2057442665100098

Epoch: 6| Step: 11
Training loss: 2.195683240890503
Validation loss: 2.139210788152551

Epoch: 6| Step: 12
Training loss: 3.08426833152771
Validation loss: 2.1746710038954213

Epoch: 6| Step: 13
Training loss: 1.2984331846237183
Validation loss: 2.169165272866526

Epoch: 66| Step: 0
Training loss: 2.1925415992736816
Validation loss: 2.1876244647528535

Epoch: 6| Step: 1
Training loss: 1.8877637386322021
Validation loss: 2.2983568586328977

Epoch: 6| Step: 2
Training loss: 1.831239104270935
Validation loss: 2.226641070458197

Epoch: 6| Step: 3
Training loss: 2.813951253890991
Validation loss: 2.199244737625122

Epoch: 6| Step: 4
Training loss: 2.8575806617736816
Validation loss: 2.2452803222081994

Epoch: 6| Step: 5
Training loss: 2.554701805114746
Validation loss: 2.211781709424911

Epoch: 6| Step: 6
Training loss: 2.4282383918762207
Validation loss: 2.2201791245450258

Epoch: 6| Step: 7
Training loss: 2.081399440765381
Validation loss: 2.2718722512645106

Epoch: 6| Step: 8
Training loss: 2.186835289001465
Validation loss: 2.1599008883199384

Epoch: 6| Step: 9
Training loss: 2.69525146484375
Validation loss: 2.311156972762077

Epoch: 6| Step: 10
Training loss: 1.7606236934661865
Validation loss: 2.2329022884368896

Epoch: 6| Step: 11
Training loss: 2.079129219055176
Validation loss: 2.2303274677645777

Epoch: 6| Step: 12
Training loss: 2.615522861480713
Validation loss: 2.2132397825999925

Epoch: 6| Step: 13
Training loss: 2.896605968475342
Validation loss: 2.2510208673374628

Epoch: 67| Step: 0
Training loss: 2.3831424713134766
Validation loss: 2.1850368438228482

Epoch: 6| Step: 1
Training loss: 2.048445224761963
Validation loss: 2.2252582939722205

Epoch: 6| Step: 2
Training loss: 2.3420231342315674
Validation loss: 2.1872681622864096

Epoch: 6| Step: 3
Training loss: 2.6736068725585938
Validation loss: 2.234786387412779

Epoch: 6| Step: 4
Training loss: 2.4845216274261475
Validation loss: 2.2127988671743744

Epoch: 6| Step: 5
Training loss: 1.616866946220398
Validation loss: 2.1589470422396095

Epoch: 6| Step: 6
Training loss: 2.1444509029388428
Validation loss: 2.145633679564281

Epoch: 6| Step: 7
Training loss: 1.9812231063842773
Validation loss: 2.1618103122198455

Epoch: 6| Step: 8
Training loss: 2.474472999572754
Validation loss: 2.1784996268569783

Epoch: 6| Step: 9
Training loss: 2.916738986968994
Validation loss: 2.1920446119000836

Epoch: 6| Step: 10
Training loss: 2.052572250366211
Validation loss: 2.2087931197176696

Epoch: 6| Step: 11
Training loss: 2.8142030239105225
Validation loss: 2.236285845438639

Epoch: 6| Step: 12
Training loss: 2.0024356842041016
Validation loss: 2.2119589133929183

Epoch: 6| Step: 13
Training loss: 1.9690876007080078
Validation loss: 2.1849698264111757

Epoch: 68| Step: 0
Training loss: 2.980003833770752
Validation loss: 2.236560936897032

Epoch: 6| Step: 1
Training loss: 2.3491992950439453
Validation loss: 2.183537910061498

Epoch: 6| Step: 2
Training loss: 2.3211166858673096
Validation loss: 2.255353964785094

Epoch: 6| Step: 3
Training loss: 2.6233811378479004
Validation loss: 2.205744876656481

Epoch: 6| Step: 4
Training loss: 2.400336265563965
Validation loss: 2.249300706771112

Epoch: 6| Step: 5
Training loss: 1.1146507263183594
Validation loss: 2.2154336757557367

Epoch: 6| Step: 6
Training loss: 2.177962303161621
Validation loss: 2.2868933011126775

Epoch: 6| Step: 7
Training loss: 2.6147661209106445
Validation loss: 2.1661430994669595

Epoch: 6| Step: 8
Training loss: 1.810091495513916
Validation loss: 2.1942922838272585

Epoch: 6| Step: 9
Training loss: 1.810502290725708
Validation loss: 2.1907916684304514

Epoch: 6| Step: 10
Training loss: 2.7078747749328613
Validation loss: 2.182155119475498

Epoch: 6| Step: 11
Training loss: 2.2122092247009277
Validation loss: 2.2742751798322125

Epoch: 6| Step: 12
Training loss: 2.724395513534546
Validation loss: 2.218631095783685

Epoch: 6| Step: 13
Training loss: 2.8223671913146973
Validation loss: 2.1969569165219545

Epoch: 69| Step: 0
Training loss: 2.196065902709961
Validation loss: 2.1630097614821566

Epoch: 6| Step: 1
Training loss: 2.614415168762207
Validation loss: 2.258237954108946

Epoch: 6| Step: 2
Training loss: 2.200636863708496
Validation loss: 2.1929137527301745

Epoch: 6| Step: 3
Training loss: 2.399352788925171
Validation loss: 2.172974492913933

Epoch: 6| Step: 4
Training loss: 2.364556312561035
Validation loss: 2.2506492701909875

Epoch: 6| Step: 5
Training loss: 1.876661777496338
Validation loss: 2.1691596315753077

Epoch: 6| Step: 6
Training loss: 2.2188353538513184
Validation loss: 2.2585510297488143

Epoch: 6| Step: 7
Training loss: 2.9681358337402344
Validation loss: 2.1527713626943608

Epoch: 6| Step: 8
Training loss: 2.5843334197998047
Validation loss: 2.1846570635354645

Epoch: 6| Step: 9
Training loss: 1.5784187316894531
Validation loss: 2.2134387082951044

Epoch: 6| Step: 10
Training loss: 1.9951817989349365
Validation loss: 2.243461803723407

Epoch: 6| Step: 11
Training loss: 1.8329530954360962
Validation loss: 2.177805805719027

Epoch: 6| Step: 12
Training loss: 2.0495424270629883
Validation loss: 2.1468298896666496

Epoch: 6| Step: 13
Training loss: 4.3007493019104
Validation loss: 2.221888093538182

Epoch: 70| Step: 0
Training loss: 2.095130681991577
Validation loss: 2.221108575021067

Epoch: 6| Step: 1
Training loss: 1.961205005645752
Validation loss: 2.1852111278041715

Epoch: 6| Step: 2
Training loss: 2.2046632766723633
Validation loss: 2.2378444133266324

Epoch: 6| Step: 3
Training loss: 2.6235222816467285
Validation loss: 2.2173006739667667

Epoch: 6| Step: 4
Training loss: 2.276578187942505
Validation loss: 2.1659871160343127

Epoch: 6| Step: 5
Training loss: 2.4946627616882324
Validation loss: 2.197387231293545

Epoch: 6| Step: 6
Training loss: 2.420139789581299
Validation loss: 2.212730133405296

Epoch: 6| Step: 7
Training loss: 3.0816917419433594
Validation loss: 2.2153920563318397

Epoch: 6| Step: 8
Training loss: 1.5845685005187988
Validation loss: 2.1734959515192176

Epoch: 6| Step: 9
Training loss: 2.8421897888183594
Validation loss: 2.2163200711691253

Epoch: 6| Step: 10
Training loss: 2.1450469493865967
Validation loss: 2.184611725550826

Epoch: 6| Step: 11
Training loss: 2.8230791091918945
Validation loss: 2.1451727062143306

Epoch: 6| Step: 12
Training loss: 2.057511329650879
Validation loss: 2.191797330815305

Epoch: 6| Step: 13
Training loss: 2.6538641452789307
Validation loss: 2.1633763518384708

Epoch: 71| Step: 0
Training loss: 2.321920156478882
Validation loss: 2.1704219502787434

Epoch: 6| Step: 1
Training loss: 2.8636653423309326
Validation loss: 2.1738230336096978

Epoch: 6| Step: 2
Training loss: 2.7815804481506348
Validation loss: 2.131137999155188

Epoch: 6| Step: 3
Training loss: 1.7647438049316406
Validation loss: 2.1502561441031833

Epoch: 6| Step: 4
Training loss: 2.831404685974121
Validation loss: 2.1519066108170377

Epoch: 6| Step: 5
Training loss: 2.2123429775238037
Validation loss: 2.2489999084062475

Epoch: 6| Step: 6
Training loss: 1.8431919813156128
Validation loss: 2.287304242451986

Epoch: 6| Step: 7
Training loss: 1.8405063152313232
Validation loss: 2.225763423468477

Epoch: 6| Step: 8
Training loss: 2.7425365447998047
Validation loss: 2.1850143504399124

Epoch: 6| Step: 9
Training loss: 2.3356871604919434
Validation loss: 2.2582443145013626

Epoch: 6| Step: 10
Training loss: 2.432171583175659
Validation loss: 2.240099914612309

Epoch: 6| Step: 11
Training loss: 2.525704860687256
Validation loss: 2.288176285323276

Epoch: 6| Step: 12
Training loss: 1.3282018899917603
Validation loss: 2.1611741512052474

Epoch: 6| Step: 13
Training loss: 1.805389642715454
Validation loss: 2.2440162397200063

Epoch: 72| Step: 0
Training loss: 3.484856128692627
Validation loss: 2.1569096490901005

Epoch: 6| Step: 1
Training loss: 1.7863645553588867
Validation loss: 2.2441870909865185

Epoch: 6| Step: 2
Training loss: 2.153047561645508
Validation loss: 2.1623550409911783

Epoch: 6| Step: 3
Training loss: 1.9873242378234863
Validation loss: 2.2003642641088015

Epoch: 6| Step: 4
Training loss: 2.356161594390869
Validation loss: 2.217174248028827

Epoch: 6| Step: 5
Training loss: 1.8064124584197998
Validation loss: 2.2069846545496294

Epoch: 6| Step: 6
Training loss: 2.3119077682495117
Validation loss: 2.2095690491378948

Epoch: 6| Step: 7
Training loss: 3.08613920211792
Validation loss: 2.17507952772161

Epoch: 6| Step: 8
Training loss: 2.6079766750335693
Validation loss: 2.223865452633109

Epoch: 6| Step: 9
Training loss: 1.9773879051208496
Validation loss: 2.247680814035477

Epoch: 6| Step: 10
Training loss: 2.1417884826660156
Validation loss: 2.2845853618396226

Epoch: 6| Step: 11
Training loss: 2.0268592834472656
Validation loss: 2.2328599550390757

Epoch: 6| Step: 12
Training loss: 2.4620163440704346
Validation loss: 2.179937962562807

Epoch: 6| Step: 13
Training loss: 1.79530930519104
Validation loss: 2.187772281708256

Epoch: 73| Step: 0
Training loss: 2.181899070739746
Validation loss: 2.211748376969368

Epoch: 6| Step: 1
Training loss: 2.533113956451416
Validation loss: 2.2167210361009

Epoch: 6| Step: 2
Training loss: 2.956162452697754
Validation loss: 2.1718513273423716

Epoch: 6| Step: 3
Training loss: 2.4797842502593994
Validation loss: 2.2353015381802797

Epoch: 6| Step: 4
Training loss: 1.764055609703064
Validation loss: 2.2213740246270293

Epoch: 6| Step: 5
Training loss: 2.263302803039551
Validation loss: 2.166410861476775

Epoch: 6| Step: 6
Training loss: 2.62601900100708
Validation loss: 2.1798719872710524

Epoch: 6| Step: 7
Training loss: 2.5100643634796143
Validation loss: 2.245771381162828

Epoch: 6| Step: 8
Training loss: 2.670403480529785
Validation loss: 2.189735763816423

Epoch: 6| Step: 9
Training loss: 2.1525638103485107
Validation loss: 2.19422939772247

Epoch: 6| Step: 10
Training loss: 2.2103474140167236
Validation loss: 2.1856464724386893

Epoch: 6| Step: 11
Training loss: 2.050912380218506
Validation loss: 2.1795929221696753

Epoch: 6| Step: 12
Training loss: 1.5500516891479492
Validation loss: 2.2439963843232844

Epoch: 6| Step: 13
Training loss: 2.7537057399749756
Validation loss: 2.115650038565359

Epoch: 74| Step: 0
Training loss: 2.660562515258789
Validation loss: 2.123741880539925

Epoch: 6| Step: 1
Training loss: 2.932269811630249
Validation loss: 2.1988417256262993

Epoch: 6| Step: 2
Training loss: 2.5188634395599365
Validation loss: 2.162316231317418

Epoch: 6| Step: 3
Training loss: 2.2377893924713135
Validation loss: 2.190199754571402

Epoch: 6| Step: 4
Training loss: 2.7066845893859863
Validation loss: 2.216213644191783

Epoch: 6| Step: 5
Training loss: 2.076627254486084
Validation loss: 2.253934975593321

Epoch: 6| Step: 6
Training loss: 2.238894462585449
Validation loss: 2.1606555074773808

Epoch: 6| Step: 7
Training loss: 1.6694839000701904
Validation loss: 2.195114779215987

Epoch: 6| Step: 8
Training loss: 2.293070077896118
Validation loss: 2.2050748589218303

Epoch: 6| Step: 9
Training loss: 2.3413443565368652
Validation loss: 2.1155185225189372

Epoch: 6| Step: 10
Training loss: 1.5618829727172852
Validation loss: 2.174874658225685

Epoch: 6| Step: 11
Training loss: 2.7672958374023438
Validation loss: 2.20608865317478

Epoch: 6| Step: 12
Training loss: 2.1322765350341797
Validation loss: 2.1629245614492767

Epoch: 6| Step: 13
Training loss: 1.5999575853347778
Validation loss: 2.3389963975516697

Epoch: 75| Step: 0
Training loss: 1.961011528968811
Validation loss: 2.1857861165077455

Epoch: 6| Step: 1
Training loss: 2.7172670364379883
Validation loss: 2.245098296032157

Epoch: 6| Step: 2
Training loss: 1.9167869091033936
Validation loss: 2.178252738009217

Epoch: 6| Step: 3
Training loss: 2.647710084915161
Validation loss: 2.253056695384364

Epoch: 6| Step: 4
Training loss: 2.2958908081054688
Validation loss: 2.2196605308081514

Epoch: 6| Step: 5
Training loss: 1.7339521646499634
Validation loss: 2.182330790386405

Epoch: 6| Step: 6
Training loss: 2.354792594909668
Validation loss: 2.3009650527790027

Epoch: 6| Step: 7
Training loss: 2.3017635345458984
Validation loss: 2.142669314979225

Epoch: 6| Step: 8
Training loss: 2.1618168354034424
Validation loss: 2.18284894317709

Epoch: 6| Step: 9
Training loss: 2.907230854034424
Validation loss: 2.137860982648788

Epoch: 6| Step: 10
Training loss: 2.908176898956299
Validation loss: 2.170287775736983

Epoch: 6| Step: 11
Training loss: 1.7263184785842896
Validation loss: 2.258629269497369

Epoch: 6| Step: 12
Training loss: 1.8080053329467773
Validation loss: 2.2780181438692155

Epoch: 6| Step: 13
Training loss: 2.074610710144043
Validation loss: 2.192688088263235

Epoch: 76| Step: 0
Training loss: 2.4982047080993652
Validation loss: 2.2328068748597176

Epoch: 6| Step: 1
Training loss: 2.406452178955078
Validation loss: 2.2271399164712555

Epoch: 6| Step: 2
Training loss: 1.9379088878631592
Validation loss: 2.224613474261376

Epoch: 6| Step: 3
Training loss: 2.9529407024383545
Validation loss: 2.2457557262912875

Epoch: 6| Step: 4
Training loss: 2.0079188346862793
Validation loss: 2.218910253176125

Epoch: 6| Step: 5
Training loss: 1.817142367362976
Validation loss: 2.2338138523922173

Epoch: 6| Step: 6
Training loss: 2.6505203247070312
Validation loss: 2.1861550269588346

Epoch: 6| Step: 7
Training loss: 1.4286710023880005
Validation loss: 2.0851667516974994

Epoch: 6| Step: 8
Training loss: 2.3093485832214355
Validation loss: 2.2373252607161

Epoch: 6| Step: 9
Training loss: 2.4629697799682617
Validation loss: 2.0976717382348995

Epoch: 6| Step: 10
Training loss: 1.4585158824920654
Validation loss: 2.2463955648483767

Epoch: 6| Step: 11
Training loss: 3.0622315406799316
Validation loss: 2.2126636735854612

Epoch: 6| Step: 12
Training loss: 2.574367046356201
Validation loss: 2.2081004163270355

Epoch: 6| Step: 13
Training loss: 1.8562995195388794
Validation loss: 2.167437220132479

Epoch: 77| Step: 0
Training loss: 1.7235841751098633
Validation loss: 2.187730925057524

Epoch: 6| Step: 1
Training loss: 1.764194130897522
Validation loss: 2.127090274646718

Epoch: 6| Step: 2
Training loss: 2.2339701652526855
Validation loss: 2.198758325269145

Epoch: 6| Step: 3
Training loss: 2.0881972312927246
Validation loss: 2.2055383625850884

Epoch: 6| Step: 4
Training loss: 2.5406594276428223
Validation loss: 2.2260530661511164

Epoch: 6| Step: 5
Training loss: 2.1136298179626465
Validation loss: 2.184722864499656

Epoch: 6| Step: 6
Training loss: 2.504084348678589
Validation loss: 2.1694008406772407

Epoch: 6| Step: 7
Training loss: 2.543361186981201
Validation loss: 2.2229402578005226

Epoch: 6| Step: 8
Training loss: 3.0596697330474854
Validation loss: 2.2909084827669206

Epoch: 6| Step: 9
Training loss: 2.008556842803955
Validation loss: 2.245577855776715

Epoch: 6| Step: 10
Training loss: 2.1452317237854004
Validation loss: 2.153782162615048

Epoch: 6| Step: 11
Training loss: 2.733427047729492
Validation loss: 2.2395995457967124

Epoch: 6| Step: 12
Training loss: 2.261404037475586
Validation loss: 2.275747065903038

Epoch: 6| Step: 13
Training loss: 1.9768180847167969
Validation loss: 2.2192287637341406

Epoch: 78| Step: 0
Training loss: 2.249811887741089
Validation loss: 2.2440422068360033

Epoch: 6| Step: 1
Training loss: 3.088627338409424
Validation loss: 2.256701636058028

Epoch: 6| Step: 2
Training loss: 2.4804649353027344
Validation loss: 2.213514745876353

Epoch: 6| Step: 3
Training loss: 1.8378797769546509
Validation loss: 2.186727311021538

Epoch: 6| Step: 4
Training loss: 1.6529085636138916
Validation loss: 2.2009831243945706

Epoch: 6| Step: 5
Training loss: 2.9110589027404785
Validation loss: 2.1155738061474216

Epoch: 6| Step: 6
Training loss: 1.6024318933486938
Validation loss: 2.172996458186898

Epoch: 6| Step: 7
Training loss: 2.3147053718566895
Validation loss: 2.141881263384255

Epoch: 6| Step: 8
Training loss: 1.96321439743042
Validation loss: 2.254113825418616

Epoch: 6| Step: 9
Training loss: 2.318294048309326
Validation loss: 2.157495717848501

Epoch: 6| Step: 10
Training loss: 1.6765705347061157
Validation loss: 2.1868342340633435

Epoch: 6| Step: 11
Training loss: 2.7982683181762695
Validation loss: 2.1106919729581444

Epoch: 6| Step: 12
Training loss: 2.1596755981445312
Validation loss: 2.1576712567319154

Epoch: 6| Step: 13
Training loss: 2.355053663253784
Validation loss: 2.2001452894620996

Epoch: 79| Step: 0
Training loss: 2.5689949989318848
Validation loss: 2.2004409964366625

Epoch: 6| Step: 1
Training loss: 2.7608675956726074
Validation loss: 2.165157433479063

Epoch: 6| Step: 2
Training loss: 2.881059408187866
Validation loss: 2.1452921423860776

Epoch: 6| Step: 3
Training loss: 2.5123023986816406
Validation loss: 2.1638512098661034

Epoch: 6| Step: 4
Training loss: 2.5004019737243652
Validation loss: 2.181964938358594

Epoch: 6| Step: 5
Training loss: 2.688941478729248
Validation loss: 2.2156643226582515

Epoch: 6| Step: 6
Training loss: 2.1962549686431885
Validation loss: 2.1992928494689283

Epoch: 6| Step: 7
Training loss: 1.8074109554290771
Validation loss: 2.196908022767754

Epoch: 6| Step: 8
Training loss: 1.4231669902801514
Validation loss: 2.2412833116387807

Epoch: 6| Step: 9
Training loss: 1.551854133605957
Validation loss: 2.181183963693598

Epoch: 6| Step: 10
Training loss: 1.903043270111084
Validation loss: 2.2049032026721584

Epoch: 6| Step: 11
Training loss: 1.9755511283874512
Validation loss: 2.179619432777487

Epoch: 6| Step: 12
Training loss: 2.8344626426696777
Validation loss: 2.2053533779677523

Epoch: 6| Step: 13
Training loss: 3.027764320373535
Validation loss: 2.1720229887193248

Epoch: 80| Step: 0
Training loss: 2.0658059120178223
Validation loss: 2.2257979351987123

Epoch: 6| Step: 1
Training loss: 1.953668475151062
Validation loss: 2.1731373212670766

Epoch: 6| Step: 2
Training loss: 2.0219576358795166
Validation loss: 2.1769319324083227

Epoch: 6| Step: 3
Training loss: 2.3294789791107178
Validation loss: 2.2194481357451408

Epoch: 6| Step: 4
Training loss: 3.1185033321380615
Validation loss: 2.2112213411638812

Epoch: 6| Step: 5
Training loss: 2.0233805179595947
Validation loss: 2.2193256270500923

Epoch: 6| Step: 6
Training loss: 1.9788074493408203
Validation loss: 2.2472291377282914

Epoch: 6| Step: 7
Training loss: 2.5144450664520264
Validation loss: 2.191305042594992

Epoch: 6| Step: 8
Training loss: 1.775010108947754
Validation loss: 2.1909039071811143

Epoch: 6| Step: 9
Training loss: 2.558598279953003
Validation loss: 2.1621397438869683

Epoch: 6| Step: 10
Training loss: 1.6024720668792725
Validation loss: 2.2330322650171097

Epoch: 6| Step: 11
Training loss: 2.6035118103027344
Validation loss: 2.1663224902204288

Epoch: 6| Step: 12
Training loss: 2.762007236480713
Validation loss: 2.2471106257489932

Epoch: 6| Step: 13
Training loss: 2.275160551071167
Validation loss: 2.222070114586943

Epoch: 81| Step: 0
Training loss: 1.5482654571533203
Validation loss: 2.223839606008222

Epoch: 6| Step: 1
Training loss: 1.9445358514785767
Validation loss: 2.172154434265629

Epoch: 6| Step: 2
Training loss: 2.433523654937744
Validation loss: 2.1817507243925527

Epoch: 6| Step: 3
Training loss: 2.1398658752441406
Validation loss: 2.1801232394351753

Epoch: 6| Step: 4
Training loss: 1.4644346237182617
Validation loss: 2.172672161491968

Epoch: 6| Step: 5
Training loss: 3.441507339477539
Validation loss: 2.20012076439396

Epoch: 6| Step: 6
Training loss: 1.7448110580444336
Validation loss: 2.207295838222709

Epoch: 6| Step: 7
Training loss: 2.333946704864502
Validation loss: 2.2437741218074674

Epoch: 6| Step: 8
Training loss: 2.185997486114502
Validation loss: 2.127971943988595

Epoch: 6| Step: 9
Training loss: 2.072866916656494
Validation loss: 2.1850540689242783

Epoch: 6| Step: 10
Training loss: 2.771679401397705
Validation loss: 2.18773155314948

Epoch: 6| Step: 11
Training loss: 2.60886287689209
Validation loss: 2.239837029928802

Epoch: 6| Step: 12
Training loss: 2.2228317260742188
Validation loss: 2.2041844680745113

Epoch: 6| Step: 13
Training loss: 2.133551597595215
Validation loss: 2.2030674975405455

Epoch: 82| Step: 0
Training loss: 2.0526328086853027
Validation loss: 2.192657609139719

Epoch: 6| Step: 1
Training loss: 2.3008954524993896
Validation loss: 2.1344179414933726

Epoch: 6| Step: 2
Training loss: 2.2829952239990234
Validation loss: 2.2418305322688115

Epoch: 6| Step: 3
Training loss: 2.127490282058716
Validation loss: 2.188749646627775

Epoch: 6| Step: 4
Training loss: 2.7982287406921387
Validation loss: 2.1726645910611717

Epoch: 6| Step: 5
Training loss: 1.9064531326293945
Validation loss: 2.198658968812676

Epoch: 6| Step: 6
Training loss: 2.51046085357666
Validation loss: 2.202891247246855

Epoch: 6| Step: 7
Training loss: 1.8553062677383423
Validation loss: 2.1941059661167923

Epoch: 6| Step: 8
Training loss: 2.8546857833862305
Validation loss: 2.1940947565981137

Epoch: 6| Step: 9
Training loss: 1.9887868165969849
Validation loss: 2.228803457752351

Epoch: 6| Step: 10
Training loss: 2.538257122039795
Validation loss: 2.152961548938546

Epoch: 6| Step: 11
Training loss: 1.7568130493164062
Validation loss: 2.1979988877491285

Epoch: 6| Step: 12
Training loss: 2.4370217323303223
Validation loss: 2.1652174662518244

Epoch: 6| Step: 13
Training loss: 2.663973093032837
Validation loss: 2.135176397139026

Epoch: 83| Step: 0
Training loss: 2.777085542678833
Validation loss: 2.273460186937804

Epoch: 6| Step: 1
Training loss: 3.215775966644287
Validation loss: 2.220263765704247

Epoch: 6| Step: 2
Training loss: 2.073115110397339
Validation loss: 2.1974837908180813

Epoch: 6| Step: 3
Training loss: 2.9717631340026855
Validation loss: 2.1685384114583335

Epoch: 6| Step: 4
Training loss: 2.2370381355285645
Validation loss: 2.260367311457152

Epoch: 6| Step: 5
Training loss: 2.034614324569702
Validation loss: 2.2791015025108092

Epoch: 6| Step: 6
Training loss: 1.7332649230957031
Validation loss: 2.2389805445107083

Epoch: 6| Step: 7
Training loss: 2.9770307540893555
Validation loss: 2.2242745430238786

Epoch: 6| Step: 8
Training loss: 1.562654972076416
Validation loss: 2.1382667736340593

Epoch: 6| Step: 9
Training loss: 2.335446357727051
Validation loss: 2.267664176161571

Epoch: 6| Step: 10
Training loss: 2.448214054107666
Validation loss: 2.1743116917148715

Epoch: 6| Step: 11
Training loss: 2.237888813018799
Validation loss: 2.2467625166780207

Epoch: 6| Step: 12
Training loss: 1.5202813148498535
Validation loss: 2.172070716017036

Epoch: 6| Step: 13
Training loss: 1.8359088897705078
Validation loss: 2.2179050701920704

Epoch: 84| Step: 0
Training loss: 2.4712443351745605
Validation loss: 2.1941744691582135

Epoch: 6| Step: 1
Training loss: 2.122205972671509
Validation loss: 2.2014574389303885

Epoch: 6| Step: 2
Training loss: 2.0682754516601562
Validation loss: 2.1780833941633984

Epoch: 6| Step: 3
Training loss: 2.530026912689209
Validation loss: 2.2361202803991174

Epoch: 6| Step: 4
Training loss: 1.8060071468353271
Validation loss: 2.181918846663608

Epoch: 6| Step: 5
Training loss: 1.4581656455993652
Validation loss: 2.2522520942072712

Epoch: 6| Step: 6
Training loss: 2.15740966796875
Validation loss: 2.2511419634665213

Epoch: 6| Step: 7
Training loss: 1.9032247066497803
Validation loss: 2.1877986987431846

Epoch: 6| Step: 8
Training loss: 3.9054641723632812
Validation loss: 2.190025785917877

Epoch: 6| Step: 9
Training loss: 2.506537675857544
Validation loss: 2.1954403179948048

Epoch: 6| Step: 10
Training loss: 2.71860671043396
Validation loss: 2.1590924416818926

Epoch: 6| Step: 11
Training loss: 2.325766086578369
Validation loss: 2.1100625581638788

Epoch: 6| Step: 12
Training loss: 2.0340113639831543
Validation loss: 2.1560497053207888

Epoch: 6| Step: 13
Training loss: 1.4204707145690918
Validation loss: 2.18967927399502

Epoch: 85| Step: 0
Training loss: 1.8387178182601929
Validation loss: 2.1721089604080364

Epoch: 6| Step: 1
Training loss: 2.7267026901245117
Validation loss: 2.1525429948683708

Epoch: 6| Step: 2
Training loss: 2.5090456008911133
Validation loss: 2.2735517550540227

Epoch: 6| Step: 3
Training loss: 2.2100770473480225
Validation loss: 2.2181755163336314

Epoch: 6| Step: 4
Training loss: 1.9678372144699097
Validation loss: 2.1761673881161596

Epoch: 6| Step: 5
Training loss: 2.471015214920044
Validation loss: 2.1701690714846373

Epoch: 6| Step: 6
Training loss: 2.2991669178009033
Validation loss: 2.2216878296226583

Epoch: 6| Step: 7
Training loss: 2.32417631149292
Validation loss: 2.197987925621771

Epoch: 6| Step: 8
Training loss: 2.6117019653320312
Validation loss: 2.189576143859535

Epoch: 6| Step: 9
Training loss: 2.422842502593994
Validation loss: 2.2708765242689397

Epoch: 6| Step: 10
Training loss: 1.5134645700454712
Validation loss: 2.2053264751229236

Epoch: 6| Step: 11
Training loss: 1.9258588552474976
Validation loss: 2.265852371851603

Epoch: 6| Step: 12
Training loss: 3.0098965167999268
Validation loss: 2.1365381235717447

Epoch: 6| Step: 13
Training loss: 2.2036585807800293
Validation loss: 2.1914272680077502

Epoch: 86| Step: 0
Training loss: 1.811004638671875
Validation loss: 2.2627865204247097

Epoch: 6| Step: 1
Training loss: 1.9436513185501099
Validation loss: 2.1814383922084684

Epoch: 6| Step: 2
Training loss: 2.1806957721710205
Validation loss: 2.188077370325724

Epoch: 6| Step: 3
Training loss: 2.540012836456299
Validation loss: 2.1992419509477514

Epoch: 6| Step: 4
Training loss: 2.4238452911376953
Validation loss: 2.155014873832785

Epoch: 6| Step: 5
Training loss: 2.4600348472595215
Validation loss: 2.23459896990048

Epoch: 6| Step: 6
Training loss: 2.7421746253967285
Validation loss: 2.2194064842757357

Epoch: 6| Step: 7
Training loss: 1.907045841217041
Validation loss: 2.218887457283594

Epoch: 6| Step: 8
Training loss: 1.9035444259643555
Validation loss: 2.2057340375838743

Epoch: 6| Step: 9
Training loss: 2.3532800674438477
Validation loss: 2.1939095886804725

Epoch: 6| Step: 10
Training loss: 2.3494555950164795
Validation loss: 2.1714720008193806

Epoch: 6| Step: 11
Training loss: 3.066847562789917
Validation loss: 2.1563138731064333

Epoch: 6| Step: 12
Training loss: 1.9242905378341675
Validation loss: 2.185067448564755

Epoch: 6| Step: 13
Training loss: 2.5807178020477295
Validation loss: 2.1747046362969185

Epoch: 87| Step: 0
Training loss: 1.8230022192001343
Validation loss: 2.1839592854181924

Epoch: 6| Step: 1
Training loss: 2.378242015838623
Validation loss: 2.168675361141082

Epoch: 6| Step: 2
Training loss: 2.494187116622925
Validation loss: 2.1655241263810026

Epoch: 6| Step: 3
Training loss: 1.9966232776641846
Validation loss: 2.1415259094648462

Epoch: 6| Step: 4
Training loss: 2.377460241317749
Validation loss: 2.1964882753228627

Epoch: 6| Step: 5
Training loss: 2.0928642749786377
Validation loss: 2.1537226476976947

Epoch: 6| Step: 6
Training loss: 2.0138046741485596
Validation loss: 2.2352769477393037

Epoch: 6| Step: 7
Training loss: 1.2711766958236694
Validation loss: 2.184285763771303

Epoch: 6| Step: 8
Training loss: 1.7665892839431763
Validation loss: 2.2268696626027427

Epoch: 6| Step: 9
Training loss: 2.6392033100128174
Validation loss: 2.181328676080191

Epoch: 6| Step: 10
Training loss: 2.3176980018615723
Validation loss: 2.2901566336231847

Epoch: 6| Step: 11
Training loss: 3.1666221618652344
Validation loss: 2.2379628048148206

Epoch: 6| Step: 12
Training loss: 2.698725700378418
Validation loss: 2.2332111789334204

Epoch: 6| Step: 13
Training loss: 2.7820234298706055
Validation loss: 2.206731201500021

Epoch: 88| Step: 0
Training loss: 2.840615749359131
Validation loss: 2.224956632942282

Epoch: 6| Step: 1
Training loss: 1.7596828937530518
Validation loss: 2.2150703450684905

Epoch: 6| Step: 2
Training loss: 2.002964735031128
Validation loss: 2.252004525994742

Epoch: 6| Step: 3
Training loss: 1.5674891471862793
Validation loss: 2.2407257121096373

Epoch: 6| Step: 4
Training loss: 3.0191848278045654
Validation loss: 2.2610246955707507

Epoch: 6| Step: 5
Training loss: 2.483914375305176
Validation loss: 2.193347264361638

Epoch: 6| Step: 6
Training loss: 2.848949909210205
Validation loss: 2.2010987548417944

Epoch: 6| Step: 7
Training loss: 2.2676899433135986
Validation loss: 2.2069053906266407

Epoch: 6| Step: 8
Training loss: 2.1466569900512695
Validation loss: 2.2166590703430997

Epoch: 6| Step: 9
Training loss: 3.0903990268707275
Validation loss: 2.17305895205467

Epoch: 6| Step: 10
Training loss: 1.6603842973709106
Validation loss: 2.245744325781381

Epoch: 6| Step: 11
Training loss: 2.3631539344787598
Validation loss: 2.171484806204355

Epoch: 6| Step: 12
Training loss: 1.884633183479309
Validation loss: 2.274199624215403

Epoch: 6| Step: 13
Training loss: 2.6802146434783936
Validation loss: 2.2745233223002446

Epoch: 89| Step: 0
Training loss: 1.9276933670043945
Validation loss: 2.3018854689854447

Epoch: 6| Step: 1
Training loss: 1.85438871383667
Validation loss: 2.1649196558101202

Epoch: 6| Step: 2
Training loss: 2.7994203567504883
Validation loss: 2.225468570186246

Epoch: 6| Step: 3
Training loss: 1.6594451665878296
Validation loss: 2.2543622652689614

Epoch: 6| Step: 4
Training loss: 1.9938781261444092
Validation loss: 2.1999865449884886

Epoch: 6| Step: 5
Training loss: 2.595571756362915
Validation loss: 2.1611556468471402

Epoch: 6| Step: 6
Training loss: 2.129382610321045
Validation loss: 2.219648184314851

Epoch: 6| Step: 7
Training loss: 3.76827073097229
Validation loss: 2.234782152278449

Epoch: 6| Step: 8
Training loss: 2.003214120864868
Validation loss: 2.219909805123524

Epoch: 6| Step: 9
Training loss: 1.6200156211853027
Validation loss: 2.1526084894775064

Epoch: 6| Step: 10
Training loss: 2.1043014526367188
Validation loss: 2.150627495140158

Epoch: 6| Step: 11
Training loss: 2.7277159690856934
Validation loss: 2.2188946354773735

Epoch: 6| Step: 12
Training loss: 2.3563692569732666
Validation loss: 2.1748273244468113

Epoch: 6| Step: 13
Training loss: 2.5362794399261475
Validation loss: 2.193269909069102

Epoch: 90| Step: 0
Training loss: 2.146160364151001
Validation loss: 2.1368387655545305

Epoch: 6| Step: 1
Training loss: 2.4367551803588867
Validation loss: 2.1534409164100565

Epoch: 6| Step: 2
Training loss: 1.8631947040557861
Validation loss: 2.1316833957549064

Epoch: 6| Step: 3
Training loss: 2.1068291664123535
Validation loss: 2.2009946377046647

Epoch: 6| Step: 4
Training loss: 2.6339080333709717
Validation loss: 2.2269332280722995

Epoch: 6| Step: 5
Training loss: 2.5474047660827637
Validation loss: 2.1848303374423774

Epoch: 6| Step: 6
Training loss: 2.9406347274780273
Validation loss: 2.1666605831474386

Epoch: 6| Step: 7
Training loss: 2.060796022415161
Validation loss: 2.2659588116471485

Epoch: 6| Step: 8
Training loss: 2.566831111907959
Validation loss: 2.267910603554018

Epoch: 6| Step: 9
Training loss: 1.6590981483459473
Validation loss: 2.1835485914702057

Epoch: 6| Step: 10
Training loss: 2.204890727996826
Validation loss: 2.129950484921855

Epoch: 6| Step: 11
Training loss: 2.4469900131225586
Validation loss: 2.19809789042319

Epoch: 6| Step: 12
Training loss: 1.8371062278747559
Validation loss: 2.1970202538274948

Epoch: 6| Step: 13
Training loss: 1.693972110748291
Validation loss: 2.2485305955333095

Epoch: 91| Step: 0
Training loss: 1.7493183612823486
Validation loss: 2.2634586544447046

Epoch: 6| Step: 1
Training loss: 2.2149112224578857
Validation loss: 2.2752422671164236

Epoch: 6| Step: 2
Training loss: 2.2945380210876465
Validation loss: 2.2398096079467447

Epoch: 6| Step: 3
Training loss: 2.4630017280578613
Validation loss: 2.2557457339379097

Epoch: 6| Step: 4
Training loss: 2.4462859630584717
Validation loss: 2.268776855161113

Epoch: 6| Step: 5
Training loss: 1.9905626773834229
Validation loss: 2.2975517729277253

Epoch: 6| Step: 6
Training loss: 2.403026580810547
Validation loss: 2.1890036265055337

Epoch: 6| Step: 7
Training loss: 2.279952049255371
Validation loss: 2.311467432206677

Epoch: 6| Step: 8
Training loss: 2.8850865364074707
Validation loss: 2.2260750775696128

Epoch: 6| Step: 9
Training loss: 2.133836507797241
Validation loss: 2.2675536858138217

Epoch: 6| Step: 10
Training loss: 1.9671740531921387
Validation loss: 2.230826034340807

Epoch: 6| Step: 11
Training loss: 2.691532611846924
Validation loss: 2.24464758493567

Epoch: 6| Step: 12
Training loss: 2.445112705230713
Validation loss: 2.255511503065786

Epoch: 6| Step: 13
Training loss: 1.6538408994674683
Validation loss: 2.2316320557748117

Epoch: 92| Step: 0
Training loss: 1.9622822999954224
Validation loss: 2.219993598999516

Epoch: 6| Step: 1
Training loss: 1.5920960903167725
Validation loss: 2.2978867741041284

Epoch: 6| Step: 2
Training loss: 1.987472653388977
Validation loss: 2.2656573505811792

Epoch: 6| Step: 3
Training loss: 2.372119903564453
Validation loss: 2.2082268755923034

Epoch: 6| Step: 4
Training loss: 1.8367774486541748
Validation loss: 2.186984354449857

Epoch: 6| Step: 5
Training loss: 2.0425100326538086
Validation loss: 2.187533001745901

Epoch: 6| Step: 6
Training loss: 2.1709938049316406
Validation loss: 2.139673391977946

Epoch: 6| Step: 7
Training loss: 2.0586719512939453
Validation loss: 2.1598605571254605

Epoch: 6| Step: 8
Training loss: 2.716435432434082
Validation loss: 2.1966880803467124

Epoch: 6| Step: 9
Training loss: 3.3995308876037598
Validation loss: 2.232633794507673

Epoch: 6| Step: 10
Training loss: 2.5324201583862305
Validation loss: 2.2220572886928434

Epoch: 6| Step: 11
Training loss: 2.4916319847106934
Validation loss: 2.307366250663675

Epoch: 6| Step: 12
Training loss: 2.335820198059082
Validation loss: 2.232431645034462

Epoch: 6| Step: 13
Training loss: 2.3628909587860107
Validation loss: 2.2075424296881563

Epoch: 93| Step: 0
Training loss: 2.6070024967193604
Validation loss: 2.186628354493008

Epoch: 6| Step: 1
Training loss: 2.422621250152588
Validation loss: 2.1837950188626527

Epoch: 6| Step: 2
Training loss: 2.366270065307617
Validation loss: 2.150574384197112

Epoch: 6| Step: 3
Training loss: 1.6748864650726318
Validation loss: 2.177781638278756

Epoch: 6| Step: 4
Training loss: 1.516478419303894
Validation loss: 2.2312168139283375

Epoch: 6| Step: 5
Training loss: 2.0779740810394287
Validation loss: 2.1361313494302894

Epoch: 6| Step: 6
Training loss: 2.6514320373535156
Validation loss: 2.184621808349445

Epoch: 6| Step: 7
Training loss: 2.107614278793335
Validation loss: 2.22783935710948

Epoch: 6| Step: 8
Training loss: 2.1292262077331543
Validation loss: 2.1790067072837584

Epoch: 6| Step: 9
Training loss: 2.7536959648132324
Validation loss: 2.190085252126058

Epoch: 6| Step: 10
Training loss: 2.2704319953918457
Validation loss: 2.1560584165716685

Epoch: 6| Step: 11
Training loss: 1.8566911220550537
Validation loss: 2.1335332496191866

Epoch: 6| Step: 12
Training loss: 1.6971497535705566
Validation loss: 2.1476263923029744

Epoch: 6| Step: 13
Training loss: 3.5381875038146973
Validation loss: 2.1654544338103263

Epoch: 94| Step: 0
Training loss: 1.6432523727416992
Validation loss: 2.171492202307588

Epoch: 6| Step: 1
Training loss: 2.1086602210998535
Validation loss: 2.1094828728706605

Epoch: 6| Step: 2
Training loss: 2.5874886512756348
Validation loss: 2.251677959196029

Epoch: 6| Step: 3
Training loss: 2.369687080383301
Validation loss: 2.207223612775085

Epoch: 6| Step: 4
Training loss: 1.7629923820495605
Validation loss: 2.1397773476057154

Epoch: 6| Step: 5
Training loss: 1.8435380458831787
Validation loss: 2.196538830316195

Epoch: 6| Step: 6
Training loss: 2.4652462005615234
Validation loss: 2.190477753198275

Epoch: 6| Step: 7
Training loss: 2.7952065467834473
Validation loss: 2.186552773239792

Epoch: 6| Step: 8
Training loss: 1.7829762697219849
Validation loss: 2.216610993108442

Epoch: 6| Step: 9
Training loss: 2.264486789703369
Validation loss: 2.15043584633899

Epoch: 6| Step: 10
Training loss: 2.3282570838928223
Validation loss: 2.1762484606876167

Epoch: 6| Step: 11
Training loss: 3.264014720916748
Validation loss: 2.2250916304126864

Epoch: 6| Step: 12
Training loss: 2.256624221801758
Validation loss: 2.18589682861041

Epoch: 6| Step: 13
Training loss: 2.097661256790161
Validation loss: 2.1729326094350507

Epoch: 95| Step: 0
Training loss: 2.210946559906006
Validation loss: 2.1861177234239477

Epoch: 6| Step: 1
Training loss: 2.7532825469970703
Validation loss: 2.1671456572830037

Epoch: 6| Step: 2
Training loss: 2.4743285179138184
Validation loss: 2.186845674309679

Epoch: 6| Step: 3
Training loss: 2.252746105194092
Validation loss: 2.246824067126038

Epoch: 6| Step: 4
Training loss: 2.347754955291748
Validation loss: 2.1571948528289795

Epoch: 6| Step: 5
Training loss: 2.834968090057373
Validation loss: 2.207017083321848

Epoch: 6| Step: 6
Training loss: 2.082476854324341
Validation loss: 2.1707631823837117

Epoch: 6| Step: 7
Training loss: 1.3748098611831665
Validation loss: 2.165511695287561

Epoch: 6| Step: 8
Training loss: 2.7553043365478516
Validation loss: 2.120031972085276

Epoch: 6| Step: 9
Training loss: 1.6120946407318115
Validation loss: 2.2152818813118884

Epoch: 6| Step: 10
Training loss: 2.31516170501709
Validation loss: 2.157108137684484

Epoch: 6| Step: 11
Training loss: 1.4988529682159424
Validation loss: 2.1249908401120092

Epoch: 6| Step: 12
Training loss: 2.3146004676818848
Validation loss: 2.1697844125891246

Epoch: 6| Step: 13
Training loss: 2.4239423274993896
Validation loss: 2.1976634276810514

Epoch: 96| Step: 0
Training loss: 2.081463575363159
Validation loss: 2.1735249078401955

Epoch: 6| Step: 1
Training loss: 2.563619375228882
Validation loss: 2.1831415596828667

Epoch: 6| Step: 2
Training loss: 2.0618300437927246
Validation loss: 2.205425863624901

Epoch: 6| Step: 3
Training loss: 2.4453771114349365
Validation loss: 2.2172921806253414

Epoch: 6| Step: 4
Training loss: 2.4954283237457275
Validation loss: 2.1647021603840653

Epoch: 6| Step: 5
Training loss: 2.2970540523529053
Validation loss: 2.1433584279911493

Epoch: 6| Step: 6
Training loss: 2.0669941902160645
Validation loss: 2.1836067168943343

Epoch: 6| Step: 7
Training loss: 2.2325186729431152
Validation loss: 2.222882136221855

Epoch: 6| Step: 8
Training loss: 1.7117263078689575
Validation loss: 2.1653896403569046

Epoch: 6| Step: 9
Training loss: 3.009009838104248
Validation loss: 2.153860160099563

Epoch: 6| Step: 10
Training loss: 2.48576021194458
Validation loss: 2.1934646175753687

Epoch: 6| Step: 11
Training loss: 1.5089915990829468
Validation loss: 2.1988448750588203

Epoch: 6| Step: 12
Training loss: 2.844536781311035
Validation loss: 2.1602022596584853

Epoch: 6| Step: 13
Training loss: 1.5872007608413696
Validation loss: 2.2592641461280083

Epoch: 97| Step: 0
Training loss: 2.082658290863037
Validation loss: 2.193217804355006

Epoch: 6| Step: 1
Training loss: 1.742743968963623
Validation loss: 2.2324993738564114

Epoch: 6| Step: 2
Training loss: 1.8884305953979492
Validation loss: 2.1924514937144455

Epoch: 6| Step: 3
Training loss: 2.9903578758239746
Validation loss: 2.138448735719086

Epoch: 6| Step: 4
Training loss: 2.587893486022949
Validation loss: 2.2099733557752383

Epoch: 6| Step: 5
Training loss: 2.452730178833008
Validation loss: 2.143887935146209

Epoch: 6| Step: 6
Training loss: 1.906762719154358
Validation loss: 2.255326541521216

Epoch: 6| Step: 7
Training loss: 2.733715057373047
Validation loss: 2.207978856179022

Epoch: 6| Step: 8
Training loss: 2.667736053466797
Validation loss: 2.1867131699797926

Epoch: 6| Step: 9
Training loss: 1.61732816696167
Validation loss: 2.173141699965282

Epoch: 6| Step: 10
Training loss: 1.63176429271698
Validation loss: 2.1934818683132047

Epoch: 6| Step: 11
Training loss: 2.6942238807678223
Validation loss: 2.1936234171672533

Epoch: 6| Step: 12
Training loss: 2.1546967029571533
Validation loss: 2.1754925507371143

Epoch: 6| Step: 13
Training loss: 2.6918728351593018
Validation loss: 2.178562944935214

Epoch: 98| Step: 0
Training loss: 2.0670580863952637
Validation loss: 2.2096830055277836

Epoch: 6| Step: 1
Training loss: 2.366737127304077
Validation loss: 2.1048928922222507

Epoch: 6| Step: 2
Training loss: 2.1848320960998535
Validation loss: 2.17151588906524

Epoch: 6| Step: 3
Training loss: 2.3621585369110107
Validation loss: 2.168900466734363

Epoch: 6| Step: 4
Training loss: 2.459351062774658
Validation loss: 2.078178495489141

Epoch: 6| Step: 5
Training loss: 2.129438877105713
Validation loss: 2.1882801901909614

Epoch: 6| Step: 6
Training loss: 2.285459041595459
Validation loss: 2.240755036313047

Epoch: 6| Step: 7
Training loss: 2.1200623512268066
Validation loss: 2.1070652828421643

Epoch: 6| Step: 8
Training loss: 2.5007479190826416
Validation loss: 2.1006791976190384

Epoch: 6| Step: 9
Training loss: 2.369678020477295
Validation loss: 2.1449684148193686

Epoch: 6| Step: 10
Training loss: 2.4490761756896973
Validation loss: 2.1185513504089846

Epoch: 6| Step: 11
Training loss: 2.2568893432617188
Validation loss: 2.158522718696184

Epoch: 6| Step: 12
Training loss: 2.0537052154541016
Validation loss: 2.124339254953528

Epoch: 6| Step: 13
Training loss: 1.584167242050171
Validation loss: 2.218933656651487

Epoch: 99| Step: 0
Training loss: 1.8325657844543457
Validation loss: 2.1792618382361626

Epoch: 6| Step: 1
Training loss: 2.5452799797058105
Validation loss: 2.159402685780679

Epoch: 6| Step: 2
Training loss: 1.9418869018554688
Validation loss: 2.1851746266888035

Epoch: 6| Step: 3
Training loss: 2.0197134017944336
Validation loss: 2.21941307539581

Epoch: 6| Step: 4
Training loss: 1.797036051750183
Validation loss: 2.2081320413979153

Epoch: 6| Step: 5
Training loss: 3.008866310119629
Validation loss: 2.227882082744311

Epoch: 6| Step: 6
Training loss: 1.880995273590088
Validation loss: 2.1915051757648425

Epoch: 6| Step: 7
Training loss: 2.6492202281951904
Validation loss: 2.179818868637085

Epoch: 6| Step: 8
Training loss: 2.1988589763641357
Validation loss: 2.1613528677212295

Epoch: 6| Step: 9
Training loss: 2.0059010982513428
Validation loss: 2.1485425887569303

Epoch: 6| Step: 10
Training loss: 2.457785129547119
Validation loss: 2.1942710632918985

Epoch: 6| Step: 11
Training loss: 2.5600295066833496
Validation loss: 2.193806004780595

Epoch: 6| Step: 12
Training loss: 2.4897141456604004
Validation loss: 2.200609791663385

Epoch: 6| Step: 13
Training loss: 2.151841402053833
Validation loss: 2.159749127203418

Epoch: 100| Step: 0
Training loss: 2.0792417526245117
Validation loss: 2.193003157133697

Epoch: 6| Step: 1
Training loss: 3.3194832801818848
Validation loss: 2.247500496525918

Epoch: 6| Step: 2
Training loss: 2.40653657913208
Validation loss: 2.173640133232199

Epoch: 6| Step: 3
Training loss: 1.4262820482254028
Validation loss: 2.12900552698361

Epoch: 6| Step: 4
Training loss: 1.9974758625030518
Validation loss: 2.2434466090253604

Epoch: 6| Step: 5
Training loss: 2.352121114730835
Validation loss: 2.1845258743532243

Epoch: 6| Step: 6
Training loss: 2.1473560333251953
Validation loss: 2.121434279667434

Epoch: 6| Step: 7
Training loss: 2.166836738586426
Validation loss: 2.172228841371434

Epoch: 6| Step: 8
Training loss: 1.700321912765503
Validation loss: 2.211507599840882

Epoch: 6| Step: 9
Training loss: 2.0957207679748535
Validation loss: 2.157925395555394

Epoch: 6| Step: 10
Training loss: 2.1031928062438965
Validation loss: 2.222865814803749

Epoch: 6| Step: 11
Training loss: 2.554800033569336
Validation loss: 2.1796396047838273

Epoch: 6| Step: 12
Training loss: 2.633143901824951
Validation loss: 2.1931337028421383

Epoch: 6| Step: 13
Training loss: 2.4410505294799805
Validation loss: 2.187480954713719

Epoch: 101| Step: 0
Training loss: 1.863031268119812
Validation loss: 2.1811321217526674

Epoch: 6| Step: 1
Training loss: 2.3621463775634766
Validation loss: 2.221254179554601

Epoch: 6| Step: 2
Training loss: 2.9760971069335938
Validation loss: 2.1829365402139644

Epoch: 6| Step: 3
Training loss: 2.215498685836792
Validation loss: 2.1206585361111547

Epoch: 6| Step: 4
Training loss: 2.4932644367218018
Validation loss: 2.170300905422498

Epoch: 6| Step: 5
Training loss: 1.8385034799575806
Validation loss: 2.2109049648366947

Epoch: 6| Step: 6
Training loss: 1.969984769821167
Validation loss: 2.150636283300256

Epoch: 6| Step: 7
Training loss: 1.5327938795089722
Validation loss: 2.0934159473706315

Epoch: 6| Step: 8
Training loss: 2.1645116806030273
Validation loss: 2.212380245167722

Epoch: 6| Step: 9
Training loss: 2.034369468688965
Validation loss: 2.1787484204897316

Epoch: 6| Step: 10
Training loss: 3.4075064659118652
Validation loss: 2.113097278020715

Epoch: 6| Step: 11
Training loss: 2.182257890701294
Validation loss: 2.2356317530396166

Epoch: 6| Step: 12
Training loss: 2.0525901317596436
Validation loss: 2.235859905519793

Epoch: 6| Step: 13
Training loss: 2.1822142601013184
Validation loss: 2.0630809991590437

Epoch: 102| Step: 0
Training loss: 1.9128292798995972
Validation loss: 2.1440170798250424

Epoch: 6| Step: 1
Training loss: 2.32020902633667
Validation loss: 2.184669843284033

Epoch: 6| Step: 2
Training loss: 2.9271457195281982
Validation loss: 2.163651056187127

Epoch: 6| Step: 3
Training loss: 2.0053391456604004
Validation loss: 2.20476270234713

Epoch: 6| Step: 4
Training loss: 2.3481197357177734
Validation loss: 2.145986303206413

Epoch: 6| Step: 5
Training loss: 2.900233745574951
Validation loss: 2.1543782064991612

Epoch: 6| Step: 6
Training loss: 2.0573313236236572
Validation loss: 2.1499539459905317

Epoch: 6| Step: 7
Training loss: 2.637139320373535
Validation loss: 2.210898196825417

Epoch: 6| Step: 8
Training loss: 2.623772382736206
Validation loss: 2.1578898404234197

Epoch: 6| Step: 9
Training loss: 2.5208632946014404
Validation loss: 2.1546296983636837

Epoch: 6| Step: 10
Training loss: 1.3328511714935303
Validation loss: 2.1156625452861992

Epoch: 6| Step: 11
Training loss: 1.7671692371368408
Validation loss: 2.1348386682489866

Epoch: 6| Step: 12
Training loss: 2.1433255672454834
Validation loss: 2.2001344285985476

Epoch: 6| Step: 13
Training loss: 2.0070621967315674
Validation loss: 2.1709190773707565

Epoch: 103| Step: 0
Training loss: 2.1172075271606445
Validation loss: 2.1672237419313

Epoch: 6| Step: 1
Training loss: 1.7206242084503174
Validation loss: 2.1406999787976666

Epoch: 6| Step: 2
Training loss: 2.288747787475586
Validation loss: 2.2279166303655153

Epoch: 6| Step: 3
Training loss: 1.9908438920974731
Validation loss: 2.174142247887068

Epoch: 6| Step: 4
Training loss: 2.737751007080078
Validation loss: 2.1518197572359474

Epoch: 6| Step: 5
Training loss: 1.911075234413147
Validation loss: 2.19223855515962

Epoch: 6| Step: 6
Training loss: 1.6849485635757446
Validation loss: 2.140691162437521

Epoch: 6| Step: 7
Training loss: 2.5405004024505615
Validation loss: 2.17133266182356

Epoch: 6| Step: 8
Training loss: 2.397634983062744
Validation loss: 2.167374672428254

Epoch: 6| Step: 9
Training loss: 2.6021480560302734
Validation loss: 2.131722909148021

Epoch: 6| Step: 10
Training loss: 2.29415225982666
Validation loss: 2.181745748366079

Epoch: 6| Step: 11
Training loss: 1.9757040739059448
Validation loss: 2.2460888380645425

Epoch: 6| Step: 12
Training loss: 2.5270304679870605
Validation loss: 2.142790704645136

Epoch: 6| Step: 13
Training loss: 2.0168263912200928
Validation loss: 2.2099713868992303

Epoch: 104| Step: 0
Training loss: 2.2981276512145996
Validation loss: 2.1577313817957395

Epoch: 6| Step: 1
Training loss: 1.783765435218811
Validation loss: 2.187588296910768

Epoch: 6| Step: 2
Training loss: 2.2687716484069824
Validation loss: 2.134794981248917

Epoch: 6| Step: 3
Training loss: 2.2345893383026123
Validation loss: 2.1904585258935088

Epoch: 6| Step: 4
Training loss: 2.5957775115966797
Validation loss: 2.1071069984025854

Epoch: 6| Step: 5
Training loss: 2.007744550704956
Validation loss: 2.093298504429479

Epoch: 6| Step: 6
Training loss: 2.5440258979797363
Validation loss: 2.128519577364768

Epoch: 6| Step: 7
Training loss: 1.7320300340652466
Validation loss: 2.176555719426883

Epoch: 6| Step: 8
Training loss: 2.9314308166503906
Validation loss: 2.16355231244077

Epoch: 6| Step: 9
Training loss: 1.919161081314087
Validation loss: 2.1710204949942966

Epoch: 6| Step: 10
Training loss: 2.498102903366089
Validation loss: 2.224268836359824

Epoch: 6| Step: 11
Training loss: 2.069962501525879
Validation loss: 2.203691504334891

Epoch: 6| Step: 12
Training loss: 3.034763813018799
Validation loss: 2.235893113638765

Epoch: 6| Step: 13
Training loss: 1.7610669136047363
Validation loss: 2.1286393186097503

Epoch: 105| Step: 0
Training loss: 1.965148687362671
Validation loss: 2.235570820428992

Epoch: 6| Step: 1
Training loss: 2.187587022781372
Validation loss: 2.159052405306088

Epoch: 6| Step: 2
Training loss: 2.111246109008789
Validation loss: 2.186005797437442

Epoch: 6| Step: 3
Training loss: 2.087979793548584
Validation loss: 2.168441912179352

Epoch: 6| Step: 4
Training loss: 2.285818576812744
Validation loss: 2.1743508308164534

Epoch: 6| Step: 5
Training loss: 1.9772411584854126
Validation loss: 2.1785335028043358

Epoch: 6| Step: 6
Training loss: 3.1804378032684326
Validation loss: 2.202078374483252

Epoch: 6| Step: 7
Training loss: 1.7698018550872803
Validation loss: 2.143980863273785

Epoch: 6| Step: 8
Training loss: 1.736504316329956
Validation loss: 2.163232757199195

Epoch: 6| Step: 9
Training loss: 2.8564634323120117
Validation loss: 2.2044342217906827

Epoch: 6| Step: 10
Training loss: 2.433548927307129
Validation loss: 2.203163751991846

Epoch: 6| Step: 11
Training loss: 2.594984531402588
Validation loss: 2.229870729548957

Epoch: 6| Step: 12
Training loss: 1.5461843013763428
Validation loss: 2.263618248765187

Epoch: 6| Step: 13
Training loss: 2.377875566482544
Validation loss: 2.150599956512451

Epoch: 106| Step: 0
Training loss: 1.9820034503936768
Validation loss: 2.17529688214743

Epoch: 6| Step: 1
Training loss: 1.6563055515289307
Validation loss: 2.204936276199997

Epoch: 6| Step: 2
Training loss: 3.004732847213745
Validation loss: 2.201535701751709

Epoch: 6| Step: 3
Training loss: 2.223405361175537
Validation loss: 2.1425462666378228

Epoch: 6| Step: 4
Training loss: 2.29799222946167
Validation loss: 2.2096727766016477

Epoch: 6| Step: 5
Training loss: 2.569995641708374
Validation loss: 2.228391473011304

Epoch: 6| Step: 6
Training loss: 1.981705665588379
Validation loss: 2.2819924252007597

Epoch: 6| Step: 7
Training loss: 2.158504009246826
Validation loss: 2.20877492812372

Epoch: 6| Step: 8
Training loss: 1.5083110332489014
Validation loss: 2.210423920744209

Epoch: 6| Step: 9
Training loss: 2.975790023803711
Validation loss: 2.1639542066922752

Epoch: 6| Step: 10
Training loss: 2.735792875289917
Validation loss: 2.1790689396601852

Epoch: 6| Step: 11
Training loss: 2.2832252979278564
Validation loss: 2.203726335238385

Epoch: 6| Step: 12
Training loss: 2.453652858734131
Validation loss: 2.2225400965700866

Epoch: 6| Step: 13
Training loss: 0.7056384682655334
Validation loss: 2.2532208799034037

Epoch: 107| Step: 0
Training loss: 2.6945571899414062
Validation loss: 2.1739451833950576

Epoch: 6| Step: 1
Training loss: 2.0275778770446777
Validation loss: 2.187619129816691

Epoch: 6| Step: 2
Training loss: 2.9909861087799072
Validation loss: 2.219142454926686

Epoch: 6| Step: 3
Training loss: 1.873372197151184
Validation loss: 2.1625454143811296

Epoch: 6| Step: 4
Training loss: 1.8617689609527588
Validation loss: 2.12441820995782

Epoch: 6| Step: 5
Training loss: 2.7762997150421143
Validation loss: 2.081050626693233

Epoch: 6| Step: 6
Training loss: 3.168997049331665
Validation loss: 2.133255463774486

Epoch: 6| Step: 7
Training loss: 1.869722604751587
Validation loss: 2.1230860679380354

Epoch: 6| Step: 8
Training loss: 1.3086742162704468
Validation loss: 2.159269609758931

Epoch: 6| Step: 9
Training loss: 2.015000820159912
Validation loss: 2.134311232515561

Epoch: 6| Step: 10
Training loss: 2.2974400520324707
Validation loss: 2.1872258442704395

Epoch: 6| Step: 11
Training loss: 2.390679359436035
Validation loss: 2.166540358656196

Epoch: 6| Step: 12
Training loss: 1.5360904932022095
Validation loss: 2.126700060341948

Epoch: 6| Step: 13
Training loss: 2.631039619445801
Validation loss: 2.189861906472073

Epoch: 108| Step: 0
Training loss: 2.3010482788085938
Validation loss: 2.1810014427349134

Epoch: 6| Step: 1
Training loss: 1.5132663249969482
Validation loss: 2.1783413271750174

Epoch: 6| Step: 2
Training loss: 2.517247200012207
Validation loss: 2.1369135841246574

Epoch: 6| Step: 3
Training loss: 2.3960776329040527
Validation loss: 2.160296642652122

Epoch: 6| Step: 4
Training loss: 2.5415091514587402
Validation loss: 2.18060673821357

Epoch: 6| Step: 5
Training loss: 2.426717758178711
Validation loss: 2.223953971298792

Epoch: 6| Step: 6
Training loss: 2.15130615234375
Validation loss: 2.216485725936069

Epoch: 6| Step: 7
Training loss: 1.5991699695587158
Validation loss: 2.177547549688688

Epoch: 6| Step: 8
Training loss: 2.362508773803711
Validation loss: 2.2176115461575088

Epoch: 6| Step: 9
Training loss: 2.4992218017578125
Validation loss: 2.2218542150271836

Epoch: 6| Step: 10
Training loss: 1.9487810134887695
Validation loss: 2.243875898340697

Epoch: 6| Step: 11
Training loss: 2.046520471572876
Validation loss: 2.2245316428522908

Epoch: 6| Step: 12
Training loss: 2.5660507678985596
Validation loss: 2.258039019441092

Epoch: 6| Step: 13
Training loss: 2.651146173477173
Validation loss: 2.196450751314881

Epoch: 109| Step: 0
Training loss: 2.826873779296875
Validation loss: 2.1879626192072386

Epoch: 6| Step: 1
Training loss: 1.5776233673095703
Validation loss: 2.1493826707204184

Epoch: 6| Step: 2
Training loss: 1.9972652196884155
Validation loss: 2.231321927039854

Epoch: 6| Step: 3
Training loss: 2.6128435134887695
Validation loss: 2.2268137226822557

Epoch: 6| Step: 4
Training loss: 2.1612303256988525
Validation loss: 2.1315267419302337

Epoch: 6| Step: 5
Training loss: 2.6502890586853027
Validation loss: 2.19161392283696

Epoch: 6| Step: 6
Training loss: 2.345090389251709
Validation loss: 2.2207728508980042

Epoch: 6| Step: 7
Training loss: 2.2401516437530518
Validation loss: 2.1624951157518613

Epoch: 6| Step: 8
Training loss: 2.016932487487793
Validation loss: 2.1774188292923795

Epoch: 6| Step: 9
Training loss: 1.7901701927185059
Validation loss: 2.204849789219518

Epoch: 6| Step: 10
Training loss: 1.803515076637268
Validation loss: 2.1787025864406298

Epoch: 6| Step: 11
Training loss: 2.2664356231689453
Validation loss: 2.1432327314089705

Epoch: 6| Step: 12
Training loss: 2.7315239906311035
Validation loss: 2.169175140319332

Epoch: 6| Step: 13
Training loss: 1.6535296440124512
Validation loss: 2.1976596206747074

Epoch: 110| Step: 0
Training loss: 1.8086955547332764
Validation loss: 2.1150664155201246

Epoch: 6| Step: 1
Training loss: 2.5862531661987305
Validation loss: 2.167684314071491

Epoch: 6| Step: 2
Training loss: 2.8626272678375244
Validation loss: 2.185572193514916

Epoch: 6| Step: 3
Training loss: 3.1120264530181885
Validation loss: 2.2075733036123295

Epoch: 6| Step: 4
Training loss: 2.3846521377563477
Validation loss: 2.217732914032475

Epoch: 6| Step: 5
Training loss: 2.0566086769104004
Validation loss: 2.1526619824030067

Epoch: 6| Step: 6
Training loss: 1.329721212387085
Validation loss: 2.1963647052805912

Epoch: 6| Step: 7
Training loss: 2.296311140060425
Validation loss: 2.2311506758454027

Epoch: 6| Step: 8
Training loss: 2.5230865478515625
Validation loss: 2.1250963916060743

Epoch: 6| Step: 9
Training loss: 1.8830355405807495
Validation loss: 2.190194288889567

Epoch: 6| Step: 10
Training loss: 1.7610411643981934
Validation loss: 2.131627111024754

Epoch: 6| Step: 11
Training loss: 2.5393805503845215
Validation loss: 2.19033472512358

Epoch: 6| Step: 12
Training loss: 1.791677713394165
Validation loss: 2.0908127433510235

Epoch: 6| Step: 13
Training loss: 2.2055861949920654
Validation loss: 2.234505307289862

Epoch: 111| Step: 0
Training loss: 1.8865317106246948
Validation loss: 2.122136365982794

Epoch: 6| Step: 1
Training loss: 2.2591426372528076
Validation loss: 2.1893806431883123

Epoch: 6| Step: 2
Training loss: 2.2596993446350098
Validation loss: 2.1939833343669934

Epoch: 6| Step: 3
Training loss: 1.3726608753204346
Validation loss: 2.1947241880560435

Epoch: 6| Step: 4
Training loss: 2.0458502769470215
Validation loss: 2.209164498954691

Epoch: 6| Step: 5
Training loss: 2.4114511013031006
Validation loss: 2.1633303306436025

Epoch: 6| Step: 6
Training loss: 1.9001185894012451
Validation loss: 2.1301436398618963

Epoch: 6| Step: 7
Training loss: 2.835075616836548
Validation loss: 2.1342663124043453

Epoch: 6| Step: 8
Training loss: 1.7720226049423218
Validation loss: 2.1183693178238405

Epoch: 6| Step: 9
Training loss: 2.907501220703125
Validation loss: 2.1294917778302263

Epoch: 6| Step: 10
Training loss: 2.3292369842529297
Validation loss: 2.1267357154559066

Epoch: 6| Step: 11
Training loss: 2.1825499534606934
Validation loss: 2.1381211280822754

Epoch: 6| Step: 12
Training loss: 2.9438443183898926
Validation loss: 2.2510130379789617

Epoch: 6| Step: 13
Training loss: 1.2878185510635376
Validation loss: 2.1985007383490123

Epoch: 112| Step: 0
Training loss: 1.6844267845153809
Validation loss: 2.2002084229582097

Epoch: 6| Step: 1
Training loss: 2.2989628314971924
Validation loss: 2.1911750249965216

Epoch: 6| Step: 2
Training loss: 2.076876640319824
Validation loss: 2.158742150952739

Epoch: 6| Step: 3
Training loss: 1.7124223709106445
Validation loss: 2.1429720155654417

Epoch: 6| Step: 4
Training loss: 2.26210618019104
Validation loss: 2.2024950635048652

Epoch: 6| Step: 5
Training loss: 2.45444393157959
Validation loss: 2.2652312196711057

Epoch: 6| Step: 6
Training loss: 2.0117690563201904
Validation loss: 2.1913172532153387

Epoch: 6| Step: 7
Training loss: 2.945680856704712
Validation loss: 2.236841037709226

Epoch: 6| Step: 8
Training loss: 2.8013391494750977
Validation loss: 2.1674693528042046

Epoch: 6| Step: 9
Training loss: 2.3173601627349854
Validation loss: 2.1612364412635885

Epoch: 6| Step: 10
Training loss: 1.9157758951187134
Validation loss: 2.237928987831198

Epoch: 6| Step: 11
Training loss: 2.372551441192627
Validation loss: 2.182651868430517

Epoch: 6| Step: 12
Training loss: 2.2572884559631348
Validation loss: 2.176703687637083

Epoch: 6| Step: 13
Training loss: 1.996544361114502
Validation loss: 2.1996239205842376

Epoch: 113| Step: 0
Training loss: 2.2183728218078613
Validation loss: 2.143614461345057

Epoch: 6| Step: 1
Training loss: 2.3015198707580566
Validation loss: 2.222640550264748

Epoch: 6| Step: 2
Training loss: 2.2702410221099854
Validation loss: 2.1337525780482958

Epoch: 6| Step: 3
Training loss: 1.6543991565704346
Validation loss: 2.2271941502889

Epoch: 6| Step: 4
Training loss: 2.0855417251586914
Validation loss: 2.152389552003594

Epoch: 6| Step: 5
Training loss: 1.8288326263427734
Validation loss: 2.198702073866321

Epoch: 6| Step: 6
Training loss: 2.2499918937683105
Validation loss: 2.199825135610437

Epoch: 6| Step: 7
Training loss: 2.268022060394287
Validation loss: 2.1537301745466007

Epoch: 6| Step: 8
Training loss: 2.6627373695373535
Validation loss: 2.202396051858061

Epoch: 6| Step: 9
Training loss: 1.9872933626174927
Validation loss: 2.237393666339177

Epoch: 6| Step: 10
Training loss: 2.2901461124420166
Validation loss: 2.1743080000723563

Epoch: 6| Step: 11
Training loss: 2.6388816833496094
Validation loss: 2.124110770481889

Epoch: 6| Step: 12
Training loss: 2.2471327781677246
Validation loss: 2.121123226740027

Epoch: 6| Step: 13
Training loss: 1.7861396074295044
Validation loss: 2.1592873911703787

Epoch: 114| Step: 0
Training loss: 3.4405179023742676
Validation loss: 2.184523641422231

Epoch: 6| Step: 1
Training loss: 2.0784878730773926
Validation loss: 2.1879918370195615

Epoch: 6| Step: 2
Training loss: 1.7203649282455444
Validation loss: 2.1277732644029843

Epoch: 6| Step: 3
Training loss: 2.3529603481292725
Validation loss: 2.126247746970064

Epoch: 6| Step: 4
Training loss: 1.986095905303955
Validation loss: 2.1765670289275465

Epoch: 6| Step: 5
Training loss: 2.2683091163635254
Validation loss: 2.1384173080485356

Epoch: 6| Step: 6
Training loss: 2.034043550491333
Validation loss: 2.182285770293205

Epoch: 6| Step: 7
Training loss: 2.3413281440734863
Validation loss: 2.245798387835103

Epoch: 6| Step: 8
Training loss: 2.7460522651672363
Validation loss: 2.1986039966665287

Epoch: 6| Step: 9
Training loss: 2.5635108947753906
Validation loss: 2.2292427939753376

Epoch: 6| Step: 10
Training loss: 2.231151580810547
Validation loss: 2.190895898367769

Epoch: 6| Step: 11
Training loss: 1.6075363159179688
Validation loss: 2.1630203826453096

Epoch: 6| Step: 12
Training loss: 1.401550531387329
Validation loss: 2.148713537441787

Epoch: 6| Step: 13
Training loss: 3.1462366580963135
Validation loss: 2.1518476688733665

Epoch: 115| Step: 0
Training loss: 2.4191348552703857
Validation loss: 2.1921958513157342

Epoch: 6| Step: 1
Training loss: 1.896278738975525
Validation loss: 2.184142927969656

Epoch: 6| Step: 2
Training loss: 1.720829725265503
Validation loss: 2.1237272934247087

Epoch: 6| Step: 3
Training loss: 2.0612010955810547
Validation loss: 2.1304492232620076

Epoch: 6| Step: 4
Training loss: 1.569740891456604
Validation loss: 2.1588499981869935

Epoch: 6| Step: 5
Training loss: 1.9567270278930664
Validation loss: 2.184236272688835

Epoch: 6| Step: 6
Training loss: 2.322166919708252
Validation loss: 2.1590724811759046

Epoch: 6| Step: 7
Training loss: 2.1014304161071777
Validation loss: 2.1489535852145125

Epoch: 6| Step: 8
Training loss: 3.2509400844573975
Validation loss: 2.0858093307864283

Epoch: 6| Step: 9
Training loss: 2.6725962162017822
Validation loss: 2.1334831817175752

Epoch: 6| Step: 10
Training loss: 2.1821298599243164
Validation loss: 2.158055269589988

Epoch: 6| Step: 11
Training loss: 2.0014734268188477
Validation loss: 2.1808390822461856

Epoch: 6| Step: 12
Training loss: 2.7287867069244385
Validation loss: 2.20098106579114

Epoch: 6| Step: 13
Training loss: 2.172696113586426
Validation loss: 2.161310056204437

Epoch: 116| Step: 0
Training loss: 1.9778294563293457
Validation loss: 2.158885399500529

Epoch: 6| Step: 1
Training loss: 1.92763090133667
Validation loss: 2.1062624095588602

Epoch: 6| Step: 2
Training loss: 1.9349360466003418
Validation loss: 2.1669956022693264

Epoch: 6| Step: 3
Training loss: 2.585434913635254
Validation loss: 2.2195018427346342

Epoch: 6| Step: 4
Training loss: 1.704634189605713
Validation loss: 2.175833588005394

Epoch: 6| Step: 5
Training loss: 1.7319085597991943
Validation loss: 2.1891121761773222

Epoch: 6| Step: 6
Training loss: 2.9709787368774414
Validation loss: 2.1842865431180565

Epoch: 6| Step: 7
Training loss: 1.3489655256271362
Validation loss: 2.1627193035617953

Epoch: 6| Step: 8
Training loss: 3.531275749206543
Validation loss: 2.1890693249241

Epoch: 6| Step: 9
Training loss: 2.293811321258545
Validation loss: 2.1757728976588093

Epoch: 6| Step: 10
Training loss: 2.1730408668518066
Validation loss: 2.233145965042935

Epoch: 6| Step: 11
Training loss: 2.1099555492401123
Validation loss: 2.2421400252208916

Epoch: 6| Step: 12
Training loss: 3.022770881652832
Validation loss: 2.1375145924988614

Epoch: 6| Step: 13
Training loss: 1.9264577627182007
Validation loss: 2.2492451898513304

Epoch: 117| Step: 0
Training loss: 1.4147086143493652
Validation loss: 2.1523134131585397

Epoch: 6| Step: 1
Training loss: 2.2900729179382324
Validation loss: 2.1354551340944026

Epoch: 6| Step: 2
Training loss: 2.240940570831299
Validation loss: 2.1746237790712746

Epoch: 6| Step: 3
Training loss: 2.2327561378479004
Validation loss: 2.198200907758487

Epoch: 6| Step: 4
Training loss: 2.2912020683288574
Validation loss: 2.0815051832506732

Epoch: 6| Step: 5
Training loss: 1.8890973329544067
Validation loss: 2.1439973692740164

Epoch: 6| Step: 6
Training loss: 3.0352869033813477
Validation loss: 2.1430545929939515

Epoch: 6| Step: 7
Training loss: 2.363043785095215
Validation loss: 2.152041781333185

Epoch: 6| Step: 8
Training loss: 2.507965564727783
Validation loss: 2.1530957042530017

Epoch: 6| Step: 9
Training loss: 1.4169983863830566
Validation loss: 2.174760559553741

Epoch: 6| Step: 10
Training loss: 2.3697094917297363
Validation loss: 2.143753018430484

Epoch: 6| Step: 11
Training loss: 2.8082053661346436
Validation loss: 2.177104816641859

Epoch: 6| Step: 12
Training loss: 1.821945309638977
Validation loss: 2.1073239913550754

Epoch: 6| Step: 13
Training loss: 2.2878236770629883
Validation loss: 2.1473052501678467

Epoch: 118| Step: 0
Training loss: 2.7706642150878906
Validation loss: 2.162964520915862

Epoch: 6| Step: 1
Training loss: 2.544332265853882
Validation loss: 2.1816102356039067

Epoch: 6| Step: 2
Training loss: 2.1166064739227295
Validation loss: 2.1132029397513277

Epoch: 6| Step: 3
Training loss: 1.9298604726791382
Validation loss: 2.1192670535015803

Epoch: 6| Step: 4
Training loss: 1.8598346710205078
Validation loss: 2.153848058433943

Epoch: 6| Step: 5
Training loss: 2.6785616874694824
Validation loss: 2.199059460752754

Epoch: 6| Step: 6
Training loss: 2.417508840560913
Validation loss: 2.1699458540126844

Epoch: 6| Step: 7
Training loss: 1.7521014213562012
Validation loss: 2.234205840736307

Epoch: 6| Step: 8
Training loss: 2.643341541290283
Validation loss: 2.2098355011273454

Epoch: 6| Step: 9
Training loss: 2.3767104148864746
Validation loss: 2.1225916621505574

Epoch: 6| Step: 10
Training loss: 2.127429246902466
Validation loss: 2.17228308416182

Epoch: 6| Step: 11
Training loss: 1.739129900932312
Validation loss: 2.173532716689571

Epoch: 6| Step: 12
Training loss: 2.395660161972046
Validation loss: 2.220286967933819

Epoch: 6| Step: 13
Training loss: 1.2586826086044312
Validation loss: 2.2038284347903345

Epoch: 119| Step: 0
Training loss: 2.388040065765381
Validation loss: 2.178491366806851

Epoch: 6| Step: 1
Training loss: 2.437498092651367
Validation loss: 2.1632842222849527

Epoch: 6| Step: 2
Training loss: 2.0188097953796387
Validation loss: 2.177888657457085

Epoch: 6| Step: 3
Training loss: 2.0509819984436035
Validation loss: 2.1396705245458953

Epoch: 6| Step: 4
Training loss: 1.7648723125457764
Validation loss: 2.173229081656343

Epoch: 6| Step: 5
Training loss: 2.623131275177002
Validation loss: 2.139490981255808

Epoch: 6| Step: 6
Training loss: 1.903160572052002
Validation loss: 2.2421239729850524

Epoch: 6| Step: 7
Training loss: 1.5875380039215088
Validation loss: 2.2005127886290192

Epoch: 6| Step: 8
Training loss: 2.6586310863494873
Validation loss: 2.1549173388429868

Epoch: 6| Step: 9
Training loss: 2.4670121669769287
Validation loss: 2.152838368569651

Epoch: 6| Step: 10
Training loss: 2.6021018028259277
Validation loss: 2.1266236228327595

Epoch: 6| Step: 11
Training loss: 2.7996878623962402
Validation loss: 2.1901415214743665

Epoch: 6| Step: 12
Training loss: 1.82150137424469
Validation loss: 2.1581019868132887

Epoch: 6| Step: 13
Training loss: 2.285099506378174
Validation loss: 2.1638314236876783

Epoch: 120| Step: 0
Training loss: 1.3771793842315674
Validation loss: 2.107445538684886

Epoch: 6| Step: 1
Training loss: 1.8669075965881348
Validation loss: 2.1955651173027615

Epoch: 6| Step: 2
Training loss: 1.9366686344146729
Validation loss: 2.1841730661289667

Epoch: 6| Step: 3
Training loss: 2.082094669342041
Validation loss: 2.1693652675997828

Epoch: 6| Step: 4
Training loss: 2.1811914443969727
Validation loss: 2.222846879754015

Epoch: 6| Step: 5
Training loss: 2.4035511016845703
Validation loss: 2.08800035266466

Epoch: 6| Step: 6
Training loss: 1.8963000774383545
Validation loss: 2.164377400952001

Epoch: 6| Step: 7
Training loss: 2.558537483215332
Validation loss: 2.1678737030234387

Epoch: 6| Step: 8
Training loss: 3.4237780570983887
Validation loss: 2.128934598738147

Epoch: 6| Step: 9
Training loss: 2.6227095127105713
Validation loss: 2.1273752386851976

Epoch: 6| Step: 10
Training loss: 2.661191463470459
Validation loss: 2.1199143214892318

Epoch: 6| Step: 11
Training loss: 1.8818564414978027
Validation loss: 2.1906078579605266

Epoch: 6| Step: 12
Training loss: 1.8615970611572266
Validation loss: 2.2040738315992456

Epoch: 6| Step: 13
Training loss: 1.9121311902999878
Validation loss: 2.1257983740939888

Epoch: 121| Step: 0
Training loss: 2.1049070358276367
Validation loss: 2.138682852509201

Epoch: 6| Step: 1
Training loss: 1.5198084115982056
Validation loss: 2.1101117723731586

Epoch: 6| Step: 2
Training loss: 2.5939645767211914
Validation loss: 2.17511147837485

Epoch: 6| Step: 3
Training loss: 1.9440076351165771
Validation loss: 2.1727166098933064

Epoch: 6| Step: 4
Training loss: 2.5227396488189697
Validation loss: 2.167616767268027

Epoch: 6| Step: 5
Training loss: 2.333024263381958
Validation loss: 2.099330163771106

Epoch: 6| Step: 6
Training loss: 2.1987247467041016
Validation loss: 2.1404507083277546

Epoch: 6| Step: 7
Training loss: 2.5746262073516846
Validation loss: 2.153824096084923

Epoch: 6| Step: 8
Training loss: 2.3081679344177246
Validation loss: 2.2044870058695474

Epoch: 6| Step: 9
Training loss: 2.2641780376434326
Validation loss: 2.140754679197906

Epoch: 6| Step: 10
Training loss: 1.803997278213501
Validation loss: 2.1877066896807764

Epoch: 6| Step: 11
Training loss: 2.049586534500122
Validation loss: 2.0977076202310543

Epoch: 6| Step: 12
Training loss: 2.214022636413574
Validation loss: 2.1798331634972685

Epoch: 6| Step: 13
Training loss: 2.5432658195495605
Validation loss: 2.2576874584280033

Epoch: 122| Step: 0
Training loss: 1.9036989212036133
Validation loss: 2.196011192055159

Epoch: 6| Step: 1
Training loss: 1.9237440824508667
Validation loss: 2.2260615825653076

Epoch: 6| Step: 2
Training loss: 2.553300142288208
Validation loss: 2.239188522420904

Epoch: 6| Step: 3
Training loss: 1.6243281364440918
Validation loss: 2.2130821545918784

Epoch: 6| Step: 4
Training loss: 2.1952919960021973
Validation loss: 2.2703102506617063

Epoch: 6| Step: 5
Training loss: 2.4115471839904785
Validation loss: 2.1909135131425757

Epoch: 6| Step: 6
Training loss: 2.183034896850586
Validation loss: 2.1445985442848614

Epoch: 6| Step: 7
Training loss: 2.566753387451172
Validation loss: 2.1993933775091685

Epoch: 6| Step: 8
Training loss: 2.9713354110717773
Validation loss: 2.1615363782452

Epoch: 6| Step: 9
Training loss: 1.9731031656265259
Validation loss: 2.1856579626760175

Epoch: 6| Step: 10
Training loss: 2.776332139968872
Validation loss: 2.130076926241639

Epoch: 6| Step: 11
Training loss: 1.8789680004119873
Validation loss: 2.097762659031858

Epoch: 6| Step: 12
Training loss: 2.079841136932373
Validation loss: 2.132411978578055

Epoch: 6| Step: 13
Training loss: 2.290497303009033
Validation loss: 2.1639145817807925

Epoch: 123| Step: 0
Training loss: 2.0719587802886963
Validation loss: 2.1338653615725938

Epoch: 6| Step: 1
Training loss: 2.0265116691589355
Validation loss: 2.161192447908463

Epoch: 6| Step: 2
Training loss: 2.3833436965942383
Validation loss: 2.1863762037728423

Epoch: 6| Step: 3
Training loss: 2.0657474994659424
Validation loss: 2.1863179565757833

Epoch: 6| Step: 4
Training loss: 1.7690702676773071
Validation loss: 2.1451419425267044

Epoch: 6| Step: 5
Training loss: 3.351747989654541
Validation loss: 2.144903531638525

Epoch: 6| Step: 6
Training loss: 1.7932342290878296
Validation loss: 2.157956879626038

Epoch: 6| Step: 7
Training loss: 1.9292430877685547
Validation loss: 2.1552004186055993

Epoch: 6| Step: 8
Training loss: 2.810914993286133
Validation loss: 2.1601469247571883

Epoch: 6| Step: 9
Training loss: 1.6746153831481934
Validation loss: 2.140627425204041

Epoch: 6| Step: 10
Training loss: 2.444490909576416
Validation loss: 2.1584255810706847

Epoch: 6| Step: 11
Training loss: 2.2431466579437256
Validation loss: 2.1763733253684094

Epoch: 6| Step: 12
Training loss: 2.0177533626556396
Validation loss: 2.1567627588907876

Epoch: 6| Step: 13
Training loss: 2.27443528175354
Validation loss: 2.1177177095925934

Epoch: 124| Step: 0
Training loss: 2.390254497528076
Validation loss: 2.1341289743300407

Epoch: 6| Step: 1
Training loss: 1.829526424407959
Validation loss: 2.178556065405569

Epoch: 6| Step: 2
Training loss: 2.838407039642334
Validation loss: 2.1499235296762116

Epoch: 6| Step: 3
Training loss: 2.338266372680664
Validation loss: 2.2125526910187094

Epoch: 6| Step: 4
Training loss: 2.5423529148101807
Validation loss: 2.141184082595251

Epoch: 6| Step: 5
Training loss: 2.3130078315734863
Validation loss: 2.1310573085661857

Epoch: 6| Step: 6
Training loss: 1.3465626239776611
Validation loss: 2.184682389741303

Epoch: 6| Step: 7
Training loss: 1.9826078414916992
Validation loss: 2.1774851788756666

Epoch: 6| Step: 8
Training loss: 1.5421462059020996
Validation loss: 2.223830150019738

Epoch: 6| Step: 9
Training loss: 2.6515400409698486
Validation loss: 2.1877503036170878

Epoch: 6| Step: 10
Training loss: 2.063502788543701
Validation loss: 2.1593235949034333

Epoch: 6| Step: 11
Training loss: 2.8978824615478516
Validation loss: 2.1390359683703353

Epoch: 6| Step: 12
Training loss: 2.4620361328125
Validation loss: 2.1749378814492175

Epoch: 6| Step: 13
Training loss: 1.5115495920181274
Validation loss: 2.1751884529667516

Epoch: 125| Step: 0
Training loss: 2.5166125297546387
Validation loss: 2.1340956636654433

Epoch: 6| Step: 1
Training loss: 2.8548431396484375
Validation loss: 2.1434846539651193

Epoch: 6| Step: 2
Training loss: 1.269159197807312
Validation loss: 2.1300902571729434

Epoch: 6| Step: 3
Training loss: 2.6430611610412598
Validation loss: 2.192328086463354

Epoch: 6| Step: 4
Training loss: 1.7422962188720703
Validation loss: 2.151283597433439

Epoch: 6| Step: 5
Training loss: 2.147543430328369
Validation loss: 2.1700296273795505

Epoch: 6| Step: 6
Training loss: 1.6405971050262451
Validation loss: 2.1597714167769237

Epoch: 6| Step: 7
Training loss: 3.118703842163086
Validation loss: 2.1337251996481292

Epoch: 6| Step: 8
Training loss: 2.213026285171509
Validation loss: 2.1465455742292505

Epoch: 6| Step: 9
Training loss: 1.832190752029419
Validation loss: 2.1237568906558457

Epoch: 6| Step: 10
Training loss: 2.7905163764953613
Validation loss: 2.2211754014415126

Epoch: 6| Step: 11
Training loss: 2.218151807785034
Validation loss: 2.154415762552651

Epoch: 6| Step: 12
Training loss: 1.635182499885559
Validation loss: 2.1602144805333947

Epoch: 6| Step: 13
Training loss: 1.9569710493087769
Validation loss: 2.211301165242349

Epoch: 126| Step: 0
Training loss: 2.8104257583618164
Validation loss: 2.1851167858287854

Epoch: 6| Step: 1
Training loss: 2.8233819007873535
Validation loss: 2.058626495381837

Epoch: 6| Step: 2
Training loss: 2.7820241451263428
Validation loss: 2.197293475110044

Epoch: 6| Step: 3
Training loss: 1.802438497543335
Validation loss: 2.1878214830993326

Epoch: 6| Step: 4
Training loss: 2.3014864921569824
Validation loss: 2.1415995884967107

Epoch: 6| Step: 5
Training loss: 2.1536197662353516
Validation loss: 2.1902525988958215

Epoch: 6| Step: 6
Training loss: 2.307075023651123
Validation loss: 2.253870825613699

Epoch: 6| Step: 7
Training loss: 2.0932321548461914
Validation loss: 2.2058679057705786

Epoch: 6| Step: 8
Training loss: 2.8922646045684814
Validation loss: 2.1818719628036662

Epoch: 6| Step: 9
Training loss: 1.992850422859192
Validation loss: 2.1535102244346374

Epoch: 6| Step: 10
Training loss: 1.6472445726394653
Validation loss: 2.19703770196566

Epoch: 6| Step: 11
Training loss: 1.9965263605117798
Validation loss: 2.20571336694943

Epoch: 6| Step: 12
Training loss: 1.735490083694458
Validation loss: 2.1723189341124667

Epoch: 6| Step: 13
Training loss: 1.6964157819747925
Validation loss: 2.123839178392964

Epoch: 127| Step: 0
Training loss: 2.2996816635131836
Validation loss: 2.114335362629224

Epoch: 6| Step: 1
Training loss: 2.0452749729156494
Validation loss: 2.1284780707410587

Epoch: 6| Step: 2
Training loss: 2.531752586364746
Validation loss: 2.1510239032007035

Epoch: 6| Step: 3
Training loss: 1.521722435951233
Validation loss: 2.0914132095152334

Epoch: 6| Step: 4
Training loss: 1.6310019493103027
Validation loss: 2.0817752012642483

Epoch: 6| Step: 5
Training loss: 2.455625295639038
Validation loss: 2.124866211286155

Epoch: 6| Step: 6
Training loss: 2.2398953437805176
Validation loss: 2.087318430664719

Epoch: 6| Step: 7
Training loss: 3.3878402709960938
Validation loss: 2.2329757905775502

Epoch: 6| Step: 8
Training loss: 2.774935245513916
Validation loss: 2.1453016304200694

Epoch: 6| Step: 9
Training loss: 2.329056739807129
Validation loss: 2.1772260076256207

Epoch: 6| Step: 10
Training loss: 1.8077095746994019
Validation loss: 2.1348175605138144

Epoch: 6| Step: 11
Training loss: 2.0094432830810547
Validation loss: 2.0937754915606592

Epoch: 6| Step: 12
Training loss: 1.8652739524841309
Validation loss: 2.1754819744376728

Epoch: 6| Step: 13
Training loss: 1.9809712171554565
Validation loss: 2.111597325212212

Epoch: 128| Step: 0
Training loss: 2.067620277404785
Validation loss: 2.1145537976295716

Epoch: 6| Step: 1
Training loss: 2.2383344173431396
Validation loss: 2.1358140848016225

Epoch: 6| Step: 2
Training loss: 2.130828857421875
Validation loss: 2.108740319487869

Epoch: 6| Step: 3
Training loss: 2.0565993785858154
Validation loss: 2.1850247895845802

Epoch: 6| Step: 4
Training loss: 2.358682155609131
Validation loss: 2.205117863993491

Epoch: 6| Step: 5
Training loss: 2.0510032176971436
Validation loss: 2.118617093691262

Epoch: 6| Step: 6
Training loss: 2.0694007873535156
Validation loss: 2.1613614315627725

Epoch: 6| Step: 7
Training loss: 2.384446382522583
Validation loss: 2.1485699684389177

Epoch: 6| Step: 8
Training loss: 1.8104313611984253
Validation loss: 2.1179910193207445

Epoch: 6| Step: 9
Training loss: 1.9713060855865479
Validation loss: 2.1770422561194307

Epoch: 6| Step: 10
Training loss: 1.936261773109436
Validation loss: 2.170801674166033

Epoch: 6| Step: 11
Training loss: 3.0139379501342773
Validation loss: 2.2149238560789373

Epoch: 6| Step: 12
Training loss: 2.27260422706604
Validation loss: 2.0543595898535942

Epoch: 6| Step: 13
Training loss: 2.2332756519317627
Validation loss: 2.215270894829945

Epoch: 129| Step: 0
Training loss: 2.721951723098755
Validation loss: 2.175662309892716

Epoch: 6| Step: 1
Training loss: 1.6034796237945557
Validation loss: 2.176680172643354

Epoch: 6| Step: 2
Training loss: 2.2697625160217285
Validation loss: 2.1878431330444994

Epoch: 6| Step: 3
Training loss: 2.2549984455108643
Validation loss: 2.2471258204470397

Epoch: 6| Step: 4
Training loss: 2.298065662384033
Validation loss: 2.235563962690292

Epoch: 6| Step: 5
Training loss: 2.64823842048645
Validation loss: 2.26245774761323

Epoch: 6| Step: 6
Training loss: 2.872912883758545
Validation loss: 2.204489836128809

Epoch: 6| Step: 7
Training loss: 2.3026235103607178
Validation loss: 2.229588354787519

Epoch: 6| Step: 8
Training loss: 2.05586576461792
Validation loss: 2.2195105014308805

Epoch: 6| Step: 9
Training loss: 2.3896052837371826
Validation loss: 2.241553032270042

Epoch: 6| Step: 10
Training loss: 1.7010834217071533
Validation loss: 2.232673147673248

Epoch: 6| Step: 11
Training loss: 2.303530216217041
Validation loss: 2.2060418846786662

Epoch: 6| Step: 12
Training loss: 1.448024034500122
Validation loss: 2.278339938450885

Epoch: 6| Step: 13
Training loss: 2.3913521766662598
Validation loss: 2.1770031400906142

Epoch: 130| Step: 0
Training loss: 2.304314136505127
Validation loss: 2.1942347788041636

Epoch: 6| Step: 1
Training loss: 2.2000010013580322
Validation loss: 2.1518878449675856

Epoch: 6| Step: 2
Training loss: 2.2133700847625732
Validation loss: 2.1127820425136115

Epoch: 6| Step: 3
Training loss: 2.043703079223633
Validation loss: 2.1750827399633264

Epoch: 6| Step: 4
Training loss: 1.8256404399871826
Validation loss: 2.1719814244137017

Epoch: 6| Step: 5
Training loss: 2.1110026836395264
Validation loss: 2.2305235657640683

Epoch: 6| Step: 6
Training loss: 2.42435622215271
Validation loss: 2.179317682020126

Epoch: 6| Step: 7
Training loss: 2.9356985092163086
Validation loss: 2.1709873419935986

Epoch: 6| Step: 8
Training loss: 2.236201047897339
Validation loss: 2.249344810362785

Epoch: 6| Step: 9
Training loss: 2.1548805236816406
Validation loss: 2.1597600470307055

Epoch: 6| Step: 10
Training loss: 2.3129971027374268
Validation loss: 2.188862557052284

Epoch: 6| Step: 11
Training loss: 2.703979253768921
Validation loss: 2.2027732133865356

Epoch: 6| Step: 12
Training loss: 1.8587877750396729
Validation loss: 2.223151824807608

Epoch: 6| Step: 13
Training loss: 1.1074872016906738
Validation loss: 2.2192232467794932

Epoch: 131| Step: 0
Training loss: 2.489215850830078
Validation loss: 2.164416513135356

Epoch: 6| Step: 1
Training loss: 1.630815029144287
Validation loss: 2.188211626903985

Epoch: 6| Step: 2
Training loss: 1.9192196130752563
Validation loss: 2.0979569265919347

Epoch: 6| Step: 3
Training loss: 2.4664602279663086
Validation loss: 2.1968678300098707

Epoch: 6| Step: 4
Training loss: 2.653118133544922
Validation loss: 2.1870661807316605

Epoch: 6| Step: 5
Training loss: 2.470717430114746
Validation loss: 2.1182271485687583

Epoch: 6| Step: 6
Training loss: 2.262144088745117
Validation loss: 2.087290310090588

Epoch: 6| Step: 7
Training loss: 2.5596096515655518
Validation loss: 2.135038470709196

Epoch: 6| Step: 8
Training loss: 2.1519594192504883
Validation loss: 2.156052645816598

Epoch: 6| Step: 9
Training loss: 1.5703892707824707
Validation loss: 2.1004365746692946

Epoch: 6| Step: 10
Training loss: 1.7767596244812012
Validation loss: 2.1550509698929323

Epoch: 6| Step: 11
Training loss: 1.801861047744751
Validation loss: 2.123346297971664

Epoch: 6| Step: 12
Training loss: 2.5265238285064697
Validation loss: 2.106052916537049

Epoch: 6| Step: 13
Training loss: 1.8946105241775513
Validation loss: 2.097345257318148

Epoch: 132| Step: 0
Training loss: 2.433980941772461
Validation loss: 2.108550719035569

Epoch: 6| Step: 1
Training loss: 2.3353219032287598
Validation loss: 2.1096833188046693

Epoch: 6| Step: 2
Training loss: 2.350987434387207
Validation loss: 2.145475072245444

Epoch: 6| Step: 3
Training loss: 1.2734723091125488
Validation loss: 2.1394416773191063

Epoch: 6| Step: 4
Training loss: 2.5447492599487305
Validation loss: 2.144831029317712

Epoch: 6| Step: 5
Training loss: 2.06795072555542
Validation loss: 2.1520445321195867

Epoch: 6| Step: 6
Training loss: 1.6129814386367798
Validation loss: 2.143476643869954

Epoch: 6| Step: 7
Training loss: 1.79036545753479
Validation loss: 2.178753276025095

Epoch: 6| Step: 8
Training loss: 1.978947639465332
Validation loss: 2.2201912531288723

Epoch: 6| Step: 9
Training loss: 3.125247001647949
Validation loss: 2.188347529339534

Epoch: 6| Step: 10
Training loss: 2.3454442024230957
Validation loss: 2.1735245232941

Epoch: 6| Step: 11
Training loss: 1.7573235034942627
Validation loss: 2.2509342034657798

Epoch: 6| Step: 12
Training loss: 2.5832550525665283
Validation loss: 2.18611450605495

Epoch: 6| Step: 13
Training loss: 1.9617151021957397
Validation loss: 2.1576198531735327

Epoch: 133| Step: 0
Training loss: 1.7730472087860107
Validation loss: 2.161556966843144

Epoch: 6| Step: 1
Training loss: 1.8187432289123535
Validation loss: 2.1454015572865806

Epoch: 6| Step: 2
Training loss: 2.1597304344177246
Validation loss: 2.1723740690497944

Epoch: 6| Step: 3
Training loss: 1.528576374053955
Validation loss: 2.1745905542886383

Epoch: 6| Step: 4
Training loss: 2.070010185241699
Validation loss: 2.1226516974869596

Epoch: 6| Step: 5
Training loss: 2.8060202598571777
Validation loss: 2.175656823701756

Epoch: 6| Step: 6
Training loss: 2.1636507511138916
Validation loss: 2.1611013566294024

Epoch: 6| Step: 7
Training loss: 2.1214771270751953
Validation loss: 2.1954927777731292

Epoch: 6| Step: 8
Training loss: 1.3753430843353271
Validation loss: 2.113975391593031

Epoch: 6| Step: 9
Training loss: 3.4287781715393066
Validation loss: 2.174147322613706

Epoch: 6| Step: 10
Training loss: 1.516190767288208
Validation loss: 2.129583235709898

Epoch: 6| Step: 11
Training loss: 2.3227100372314453
Validation loss: 2.172522191078432

Epoch: 6| Step: 12
Training loss: 2.4744620323181152
Validation loss: 2.1587710072917323

Epoch: 6| Step: 13
Training loss: 2.939734935760498
Validation loss: 2.139986839345706

Epoch: 134| Step: 0
Training loss: 2.1729321479797363
Validation loss: 2.1415924346575173

Epoch: 6| Step: 1
Training loss: 1.871854543685913
Validation loss: 2.1398626348023773

Epoch: 6| Step: 2
Training loss: 2.975567102432251
Validation loss: 2.1306460185717513

Epoch: 6| Step: 3
Training loss: 2.207780361175537
Validation loss: 2.1253440098095964

Epoch: 6| Step: 4
Training loss: 1.4896612167358398
Validation loss: 2.1197354793548584

Epoch: 6| Step: 5
Training loss: 3.1512014865875244
Validation loss: 2.182078961403139

Epoch: 6| Step: 6
Training loss: 2.32094144821167
Validation loss: 2.110027269650531

Epoch: 6| Step: 7
Training loss: 3.1921274662017822
Validation loss: 2.1574072376374276

Epoch: 6| Step: 8
Training loss: 1.9213299751281738
Validation loss: 2.1730268206647647

Epoch: 6| Step: 9
Training loss: 1.7273821830749512
Validation loss: 2.181099783989691

Epoch: 6| Step: 10
Training loss: 1.5653431415557861
Validation loss: 2.0906905153746247

Epoch: 6| Step: 11
Training loss: 2.1720516681671143
Validation loss: 2.1100938256068895

Epoch: 6| Step: 12
Training loss: 2.0125718116760254
Validation loss: 2.1035082801695792

Epoch: 6| Step: 13
Training loss: 2.687411308288574
Validation loss: 2.0970110662521853

Epoch: 135| Step: 0
Training loss: 3.3569540977478027
Validation loss: 2.1704627595922

Epoch: 6| Step: 1
Training loss: 1.9526768922805786
Validation loss: 2.2405794692295853

Epoch: 6| Step: 2
Training loss: 3.007187604904175
Validation loss: 2.1496617063399284

Epoch: 6| Step: 3
Training loss: 1.7868657112121582
Validation loss: 2.156144816388366

Epoch: 6| Step: 4
Training loss: 1.430729866027832
Validation loss: 2.17673445517017

Epoch: 6| Step: 5
Training loss: 2.594921588897705
Validation loss: 2.174620912921044

Epoch: 6| Step: 6
Training loss: 2.210869312286377
Validation loss: 2.166907379704137

Epoch: 6| Step: 7
Training loss: 2.964886426925659
Validation loss: 2.153967267723494

Epoch: 6| Step: 8
Training loss: 2.490642547607422
Validation loss: 2.2344035422930153

Epoch: 6| Step: 9
Training loss: 1.4986485242843628
Validation loss: 2.260422391276206

Epoch: 6| Step: 10
Training loss: 1.9122865200042725
Validation loss: 2.2667522507329143

Epoch: 6| Step: 11
Training loss: 1.7123321294784546
Validation loss: 2.2278679250389017

Epoch: 6| Step: 12
Training loss: 1.4035733938217163
Validation loss: 2.21678053691823

Epoch: 6| Step: 13
Training loss: 3.7707154750823975
Validation loss: 2.162251541691442

Epoch: 136| Step: 0
Training loss: 1.9798550605773926
Validation loss: 2.223341841851511

Epoch: 6| Step: 1
Training loss: 2.0099003314971924
Validation loss: 2.1812632981167046

Epoch: 6| Step: 2
Training loss: 2.705082893371582
Validation loss: 2.1743409364454207

Epoch: 6| Step: 3
Training loss: 1.937408685684204
Validation loss: 2.191682413060178

Epoch: 6| Step: 4
Training loss: 2.2352311611175537
Validation loss: 2.1792207943495883

Epoch: 6| Step: 5
Training loss: 2.7470664978027344
Validation loss: 2.2050527718759354

Epoch: 6| Step: 6
Training loss: 2.3992457389831543
Validation loss: 2.154338885379094

Epoch: 6| Step: 7
Training loss: 1.8955199718475342
Validation loss: 2.207680615045691

Epoch: 6| Step: 8
Training loss: 1.8790333271026611
Validation loss: 2.188015530186315

Epoch: 6| Step: 9
Training loss: 1.730643630027771
Validation loss: 2.1926532765870452

Epoch: 6| Step: 10
Training loss: 2.798161506652832
Validation loss: 2.1792855980575725

Epoch: 6| Step: 11
Training loss: 2.3182997703552246
Validation loss: 2.1049701757328485

Epoch: 6| Step: 12
Training loss: 2.4923949241638184
Validation loss: 2.1925357439184703

Epoch: 6| Step: 13
Training loss: 1.1316237449645996
Validation loss: 2.15056437061679

Epoch: 137| Step: 0
Training loss: 1.717391014099121
Validation loss: 2.1432072167755454

Epoch: 6| Step: 1
Training loss: 1.8796278238296509
Validation loss: 2.1351202969909995

Epoch: 6| Step: 2
Training loss: 1.5691649913787842
Validation loss: 2.0852405627568564

Epoch: 6| Step: 3
Training loss: 1.6916871070861816
Validation loss: 2.120812325067418

Epoch: 6| Step: 4
Training loss: 1.5172455310821533
Validation loss: 2.1014004022844377

Epoch: 6| Step: 5
Training loss: 2.418278694152832
Validation loss: 2.1507512177190473

Epoch: 6| Step: 6
Training loss: 2.758340358734131
Validation loss: 2.121536274110117

Epoch: 6| Step: 7
Training loss: 2.0804386138916016
Validation loss: 2.1396042544354676

Epoch: 6| Step: 8
Training loss: 2.3194665908813477
Validation loss: 2.1556151195238997

Epoch: 6| Step: 9
Training loss: 2.723480224609375
Validation loss: 2.079178858828801

Epoch: 6| Step: 10
Training loss: 3.235321521759033
Validation loss: 2.1739817306559575

Epoch: 6| Step: 11
Training loss: 2.4791011810302734
Validation loss: 2.132695626187068

Epoch: 6| Step: 12
Training loss: 2.397285223007202
Validation loss: 2.198578614060597

Epoch: 6| Step: 13
Training loss: 1.7220832109451294
Validation loss: 2.1277119933917956

Epoch: 138| Step: 0
Training loss: 2.4649033546447754
Validation loss: 2.12370724831858

Epoch: 6| Step: 1
Training loss: 2.267977714538574
Validation loss: 2.1225823689532537

Epoch: 6| Step: 2
Training loss: 2.1989245414733887
Validation loss: 2.154603636392983

Epoch: 6| Step: 3
Training loss: 1.4548702239990234
Validation loss: 2.0846714717085644

Epoch: 6| Step: 4
Training loss: 2.4512100219726562
Validation loss: 2.226559600522441

Epoch: 6| Step: 5
Training loss: 2.0836145877838135
Validation loss: 2.148467307449669

Epoch: 6| Step: 6
Training loss: 2.0861611366271973
Validation loss: 2.2660639029677196

Epoch: 6| Step: 7
Training loss: 2.4690470695495605
Validation loss: 2.144365938760901

Epoch: 6| Step: 8
Training loss: 2.8823843002319336
Validation loss: 2.199031954170555

Epoch: 6| Step: 9
Training loss: 2.4038689136505127
Validation loss: 2.1201619512291363

Epoch: 6| Step: 10
Training loss: 2.2428030967712402
Validation loss: 2.2005573293214202

Epoch: 6| Step: 11
Training loss: 1.650020956993103
Validation loss: 2.1373647002763647

Epoch: 6| Step: 12
Training loss: 1.5929830074310303
Validation loss: 2.242166637092508

Epoch: 6| Step: 13
Training loss: 3.0013554096221924
Validation loss: 2.154249582239377

Epoch: 139| Step: 0
Training loss: 3.1148009300231934
Validation loss: 2.2042474362158004

Epoch: 6| Step: 1
Training loss: 2.0031051635742188
Validation loss: 2.1948164227188274

Epoch: 6| Step: 2
Training loss: 2.65718936920166
Validation loss: 2.205524267688874

Epoch: 6| Step: 3
Training loss: 2.7669246196746826
Validation loss: 2.237543782880229

Epoch: 6| Step: 4
Training loss: 1.8762180805206299
Validation loss: 2.1401699614781204

Epoch: 6| Step: 5
Training loss: 2.2152099609375
Validation loss: 2.180613483152082

Epoch: 6| Step: 6
Training loss: 1.5263053178787231
Validation loss: 2.1552284033067766

Epoch: 6| Step: 7
Training loss: 1.7175689935684204
Validation loss: 2.1409860426379788

Epoch: 6| Step: 8
Training loss: 1.9228184223175049
Validation loss: 2.1329927393185195

Epoch: 6| Step: 9
Training loss: 2.0694828033447266
Validation loss: 2.1452775924436507

Epoch: 6| Step: 10
Training loss: 1.8911933898925781
Validation loss: 2.1513416587665515

Epoch: 6| Step: 11
Training loss: 2.1776390075683594
Validation loss: 2.1303209258664038

Epoch: 6| Step: 12
Training loss: 2.4367547035217285
Validation loss: 2.110275532609673

Epoch: 6| Step: 13
Training loss: 1.7633252143859863
Validation loss: 2.0811950622066373

Epoch: 140| Step: 0
Training loss: 1.908494472503662
Validation loss: 2.094682260226178

Epoch: 6| Step: 1
Training loss: 2.2813310623168945
Validation loss: 2.1836609584029003

Epoch: 6| Step: 2
Training loss: 2.0609707832336426
Validation loss: 2.1503223026952436

Epoch: 6| Step: 3
Training loss: 2.1260695457458496
Validation loss: 2.148496550898398

Epoch: 6| Step: 4
Training loss: 1.6379883289337158
Validation loss: 2.2027350420592935

Epoch: 6| Step: 5
Training loss: 2.396740198135376
Validation loss: 2.133124805265857

Epoch: 6| Step: 6
Training loss: 1.5096516609191895
Validation loss: 2.085403839747111

Epoch: 6| Step: 7
Training loss: 2.3526952266693115
Validation loss: 2.200484621909357

Epoch: 6| Step: 8
Training loss: 1.896990418434143
Validation loss: 2.2104891987257105

Epoch: 6| Step: 9
Training loss: 2.8265738487243652
Validation loss: 2.1249947855549474

Epoch: 6| Step: 10
Training loss: 1.959743618965149
Validation loss: 2.1405883681389595

Epoch: 6| Step: 11
Training loss: 2.3440303802490234
Validation loss: 2.1294195831462903

Epoch: 6| Step: 12
Training loss: 2.4003119468688965
Validation loss: 2.1709444035765944

Epoch: 6| Step: 13
Training loss: 2.378950595855713
Validation loss: 2.136795582309846

Epoch: 141| Step: 0
Training loss: 2.4744441509246826
Validation loss: 2.190977173466836

Epoch: 6| Step: 1
Training loss: 1.7131849527359009
Validation loss: 2.2558355049420427

Epoch: 6| Step: 2
Training loss: 2.3863699436187744
Validation loss: 2.1265110302996892

Epoch: 6| Step: 3
Training loss: 1.4994385242462158
Validation loss: 2.1538020821027857

Epoch: 6| Step: 4
Training loss: 1.5824337005615234
Validation loss: 2.1074935543921685

Epoch: 6| Step: 5
Training loss: 1.935354232788086
Validation loss: 2.1532371928614955

Epoch: 6| Step: 6
Training loss: 1.5799258947372437
Validation loss: 2.1641551243361605

Epoch: 6| Step: 7
Training loss: 2.3531763553619385
Validation loss: 2.187937134055681

Epoch: 6| Step: 8
Training loss: 2.809673309326172
Validation loss: 2.1991487421015257

Epoch: 6| Step: 9
Training loss: 2.7195489406585693
Validation loss: 2.080082110179368

Epoch: 6| Step: 10
Training loss: 2.346977710723877
Validation loss: 2.1645804630812777

Epoch: 6| Step: 11
Training loss: 2.6093392372131348
Validation loss: 2.1291165351867676

Epoch: 6| Step: 12
Training loss: 2.6369194984436035
Validation loss: 2.099973855480071

Epoch: 6| Step: 13
Training loss: 1.3796457052230835
Validation loss: 2.0480927075109174

Epoch: 142| Step: 0
Training loss: 1.739227294921875
Validation loss: 2.106476265897033

Epoch: 6| Step: 1
Training loss: 1.5328959226608276
Validation loss: 2.1887561198203795

Epoch: 6| Step: 2
Training loss: 2.021940231323242
Validation loss: 2.198181620208166

Epoch: 6| Step: 3
Training loss: 2.6261801719665527
Validation loss: 2.141084378765475

Epoch: 6| Step: 4
Training loss: 1.3258132934570312
Validation loss: 2.222217836687642

Epoch: 6| Step: 5
Training loss: 1.3612446784973145
Validation loss: 2.197030372517083

Epoch: 6| Step: 6
Training loss: 2.556598663330078
Validation loss: 2.0709358466568815

Epoch: 6| Step: 7
Training loss: 2.2476329803466797
Validation loss: 2.1942845416325394

Epoch: 6| Step: 8
Training loss: 2.806450843811035
Validation loss: 2.1039580581008748

Epoch: 6| Step: 9
Training loss: 2.8752355575561523
Validation loss: 2.1723392240462767

Epoch: 6| Step: 10
Training loss: 1.882230520248413
Validation loss: 2.1659208497693463

Epoch: 6| Step: 11
Training loss: 2.5938992500305176
Validation loss: 2.1766039274072133

Epoch: 6| Step: 12
Training loss: 2.6794443130493164
Validation loss: 2.162703989654459

Epoch: 6| Step: 13
Training loss: 1.6052985191345215
Validation loss: 2.116238929892099

Epoch: 143| Step: 0
Training loss: 2.1470348834991455
Validation loss: 2.1935794866213234

Epoch: 6| Step: 1
Training loss: 1.9133923053741455
Validation loss: 2.191556002504082

Epoch: 6| Step: 2
Training loss: 1.9400793313980103
Validation loss: 2.1983479761308238

Epoch: 6| Step: 3
Training loss: 2.226256847381592
Validation loss: 2.1860119219749206

Epoch: 6| Step: 4
Training loss: 1.6991050243377686
Validation loss: 2.1302686224701586

Epoch: 6| Step: 5
Training loss: 2.0931828022003174
Validation loss: 2.112612183376025

Epoch: 6| Step: 6
Training loss: 2.346907615661621
Validation loss: 2.1434031096837853

Epoch: 6| Step: 7
Training loss: 2.2874643802642822
Validation loss: 2.2121651916093725

Epoch: 6| Step: 8
Training loss: 2.5249133110046387
Validation loss: 2.150058315646264

Epoch: 6| Step: 9
Training loss: 2.5587596893310547
Validation loss: 2.126153240921677

Epoch: 6| Step: 10
Training loss: 1.6517895460128784
Validation loss: 2.1301724705644833

Epoch: 6| Step: 11
Training loss: 2.4237513542175293
Validation loss: 2.1546579919835573

Epoch: 6| Step: 12
Training loss: 2.3542544841766357
Validation loss: 2.14090153478807

Epoch: 6| Step: 13
Training loss: 1.7556887865066528
Validation loss: 2.1513242234465895

Epoch: 144| Step: 0
Training loss: 2.1811490058898926
Validation loss: 2.1373329085688435

Epoch: 6| Step: 1
Training loss: 2.0715177059173584
Validation loss: 2.079492774060977

Epoch: 6| Step: 2
Training loss: 2.0977368354797363
Validation loss: 2.1154289873697425

Epoch: 6| Step: 3
Training loss: 2.69453763961792
Validation loss: 2.1355488864324426

Epoch: 6| Step: 4
Training loss: 2.3304240703582764
Validation loss: 2.147427746044692

Epoch: 6| Step: 5
Training loss: 1.999866008758545
Validation loss: 2.1332814372995847

Epoch: 6| Step: 6
Training loss: 2.2293732166290283
Validation loss: 2.148678248928439

Epoch: 6| Step: 7
Training loss: 2.388817071914673
Validation loss: 2.161612761917935

Epoch: 6| Step: 8
Training loss: 2.240675926208496
Validation loss: 2.072626618928807

Epoch: 6| Step: 9
Training loss: 2.229027271270752
Validation loss: 2.157233202329246

Epoch: 6| Step: 10
Training loss: 1.9669132232666016
Validation loss: 2.165747745062715

Epoch: 6| Step: 11
Training loss: 1.2032675743103027
Validation loss: 2.1221054497585503

Epoch: 6| Step: 12
Training loss: 1.7319658994674683
Validation loss: 2.128837190648561

Epoch: 6| Step: 13
Training loss: 2.6152379512786865
Validation loss: 2.0944947760592223

Epoch: 145| Step: 0
Training loss: 2.469120740890503
Validation loss: 2.2063626576495428

Epoch: 6| Step: 1
Training loss: 1.745980143547058
Validation loss: 2.1433128926061813

Epoch: 6| Step: 2
Training loss: 2.11834454536438
Validation loss: 2.1578834210672686

Epoch: 6| Step: 3
Training loss: 2.421653985977173
Validation loss: 2.1420884055476033

Epoch: 6| Step: 4
Training loss: 2.2236270904541016
Validation loss: 2.2070943027414303

Epoch: 6| Step: 5
Training loss: 1.7450642585754395
Validation loss: 2.1923806769873506

Epoch: 6| Step: 6
Training loss: 2.339094638824463
Validation loss: 2.206791784173699

Epoch: 6| Step: 7
Training loss: 1.7266427278518677
Validation loss: 2.1700833561599895

Epoch: 6| Step: 8
Training loss: 2.0331733226776123
Validation loss: 2.1186800515779884

Epoch: 6| Step: 9
Training loss: 1.8435242176055908
Validation loss: 2.1785165058669222

Epoch: 6| Step: 10
Training loss: 1.7530252933502197
Validation loss: 2.1989966284844185

Epoch: 6| Step: 11
Training loss: 2.3920974731445312
Validation loss: 2.137950487034295

Epoch: 6| Step: 12
Training loss: 2.9842822551727295
Validation loss: 2.1190340236950944

Epoch: 6| Step: 13
Training loss: 2.0587985515594482
Validation loss: 2.1373281043062926

Epoch: 146| Step: 0
Training loss: 1.8094151020050049
Validation loss: 2.1244745126334568

Epoch: 6| Step: 1
Training loss: 1.6615971326828003
Validation loss: 2.1663557457667526

Epoch: 6| Step: 2
Training loss: 2.2458114624023438
Validation loss: 2.2178363748776015

Epoch: 6| Step: 3
Training loss: 2.4281201362609863
Validation loss: 2.125712275505066

Epoch: 6| Step: 4
Training loss: 1.8413188457489014
Validation loss: 2.117367527818167

Epoch: 6| Step: 5
Training loss: 2.176997184753418
Validation loss: 2.168227682831467

Epoch: 6| Step: 6
Training loss: 1.5672218799591064
Validation loss: 2.2000058594570366

Epoch: 6| Step: 7
Training loss: 2.2961244583129883
Validation loss: 2.2122766881860714

Epoch: 6| Step: 8
Training loss: 2.1684951782226562
Validation loss: 2.1456186899574856

Epoch: 6| Step: 9
Training loss: 1.8464651107788086
Validation loss: 2.181513976025325

Epoch: 6| Step: 10
Training loss: 2.358468532562256
Validation loss: 2.1551526515714583

Epoch: 6| Step: 11
Training loss: 2.09211802482605
Validation loss: 2.184282492565852

Epoch: 6| Step: 12
Training loss: 3.0292205810546875
Validation loss: 2.233944813410441

Epoch: 6| Step: 13
Training loss: 3.7500414848327637
Validation loss: 2.156540096447032

Epoch: 147| Step: 0
Training loss: 1.9689387083053589
Validation loss: 2.169005637527794

Epoch: 6| Step: 1
Training loss: 1.8635776042938232
Validation loss: 2.176827141033706

Epoch: 6| Step: 2
Training loss: 2.4454493522644043
Validation loss: 2.1233779268880046

Epoch: 6| Step: 3
Training loss: 2.5299510955810547
Validation loss: 2.110379616419474

Epoch: 6| Step: 4
Training loss: 2.042937994003296
Validation loss: 2.1086763822904198

Epoch: 6| Step: 5
Training loss: 2.2194900512695312
Validation loss: 2.1374868949254355

Epoch: 6| Step: 6
Training loss: 2.2028470039367676
Validation loss: 2.1337129659550165

Epoch: 6| Step: 7
Training loss: 2.0005316734313965
Validation loss: 2.1233134423532793

Epoch: 6| Step: 8
Training loss: 2.422837734222412
Validation loss: 2.1909476095630276

Epoch: 6| Step: 9
Training loss: 2.2592830657958984
Validation loss: 2.1503317509928057

Epoch: 6| Step: 10
Training loss: 2.0208728313446045
Validation loss: 2.142466305404581

Epoch: 6| Step: 11
Training loss: 2.1883726119995117
Validation loss: 2.1777652591787358

Epoch: 6| Step: 12
Training loss: 2.0870962142944336
Validation loss: 2.160326288592431

Epoch: 6| Step: 13
Training loss: 1.9549018144607544
Validation loss: 2.2131680250167847

Epoch: 148| Step: 0
Training loss: 1.8440169095993042
Validation loss: 2.1521321650474303

Epoch: 6| Step: 1
Training loss: 2.2670352458953857
Validation loss: 2.145668395103947

Epoch: 6| Step: 2
Training loss: 1.9904924631118774
Validation loss: 2.186055411574661

Epoch: 6| Step: 3
Training loss: 2.0878329277038574
Validation loss: 2.1304605135353665

Epoch: 6| Step: 4
Training loss: 1.9428215026855469
Validation loss: 2.188863472271991

Epoch: 6| Step: 5
Training loss: 2.735203266143799
Validation loss: 2.1721587975819907

Epoch: 6| Step: 6
Training loss: 2.7740092277526855
Validation loss: 2.2353358717374903

Epoch: 6| Step: 7
Training loss: 1.9233312606811523
Validation loss: 2.0959067934302875

Epoch: 6| Step: 8
Training loss: 1.7922810316085815
Validation loss: 2.184441296003198

Epoch: 6| Step: 9
Training loss: 2.1960864067077637
Validation loss: 2.2081153495337373

Epoch: 6| Step: 10
Training loss: 2.649003267288208
Validation loss: 2.172176416202258

Epoch: 6| Step: 11
Training loss: 2.2665843963623047
Validation loss: 2.2093016357832056

Epoch: 6| Step: 12
Training loss: 2.438710927963257
Validation loss: 2.2254656873723513

Epoch: 6| Step: 13
Training loss: 1.531434416770935
Validation loss: 2.2991028780578286

Epoch: 149| Step: 0
Training loss: 2.2727880477905273
Validation loss: 2.2012519451879684

Epoch: 6| Step: 1
Training loss: 1.7445504665374756
Validation loss: 2.2124964857614167

Epoch: 6| Step: 2
Training loss: 2.112456798553467
Validation loss: 2.1617912310425953

Epoch: 6| Step: 3
Training loss: 1.6299867630004883
Validation loss: 2.1719588797579528

Epoch: 6| Step: 4
Training loss: 2.9241580963134766
Validation loss: 2.2135454326547603

Epoch: 6| Step: 5
Training loss: 2.535970687866211
Validation loss: 2.1757740256606892

Epoch: 6| Step: 6
Training loss: 2.1754581928253174
Validation loss: 2.169219431056771

Epoch: 6| Step: 7
Training loss: 2.1982736587524414
Validation loss: 2.131454321645921

Epoch: 6| Step: 8
Training loss: 2.1650631427764893
Validation loss: 2.1446688213656024

Epoch: 6| Step: 9
Training loss: 2.116755485534668
Validation loss: 2.10872830114057

Epoch: 6| Step: 10
Training loss: 2.1328125
Validation loss: 2.206011895210512

Epoch: 6| Step: 11
Training loss: 2.2366063594818115
Validation loss: 2.134534764033492

Epoch: 6| Step: 12
Training loss: 1.971245288848877
Validation loss: 2.1798283951256865

Epoch: 6| Step: 13
Training loss: 2.1524438858032227
Validation loss: 2.153052629963044

Epoch: 150| Step: 0
Training loss: 2.0718507766723633
Validation loss: 2.1240048075235016

Epoch: 6| Step: 1
Training loss: 1.5366381406784058
Validation loss: 2.200897405224462

Epoch: 6| Step: 2
Training loss: 2.317002534866333
Validation loss: 2.1212568308717463

Epoch: 6| Step: 3
Training loss: 2.9830269813537598
Validation loss: 2.138077874337473

Epoch: 6| Step: 4
Training loss: 3.0109078884124756
Validation loss: 2.1552526720108522

Epoch: 6| Step: 5
Training loss: 1.0584200620651245
Validation loss: 2.115132816376225

Epoch: 6| Step: 6
Training loss: 2.829606533050537
Validation loss: 2.1396359166791363

Epoch: 6| Step: 7
Training loss: 2.904184579849243
Validation loss: 2.09279949690706

Epoch: 6| Step: 8
Training loss: 1.259536623954773
Validation loss: 2.0639614623080016

Epoch: 6| Step: 9
Training loss: 1.456682562828064
Validation loss: 2.1071759141901487

Epoch: 6| Step: 10
Training loss: 2.9763994216918945
Validation loss: 2.1817134862305014

Epoch: 6| Step: 11
Training loss: 2.418729305267334
Validation loss: 2.1671154409326534

Epoch: 6| Step: 12
Training loss: 2.0330584049224854
Validation loss: 2.155081643853136

Epoch: 6| Step: 13
Training loss: 2.0854365825653076
Validation loss: 2.0718789100646973

Epoch: 151| Step: 0
Training loss: 2.7883963584899902
Validation loss: 2.097615388131911

Epoch: 6| Step: 1
Training loss: 1.6180496215820312
Validation loss: 2.1475226699665027

Epoch: 6| Step: 2
Training loss: 2.1783652305603027
Validation loss: 2.2080311877753145

Epoch: 6| Step: 3
Training loss: 1.9038171768188477
Validation loss: 2.128047558569139

Epoch: 6| Step: 4
Training loss: 2.620306968688965
Validation loss: 2.1855389661686395

Epoch: 6| Step: 5
Training loss: 1.8822546005249023
Validation loss: 2.1475545667832896

Epoch: 6| Step: 6
Training loss: 1.9053053855895996
Validation loss: 2.165607706193001

Epoch: 6| Step: 7
Training loss: 2.334747314453125
Validation loss: 2.15557449863803

Epoch: 6| Step: 8
Training loss: 2.6729984283447266
Validation loss: 2.252110832480974

Epoch: 6| Step: 9
Training loss: 2.268462657928467
Validation loss: 2.1519316216950775

Epoch: 6| Step: 10
Training loss: 2.1041433811187744
Validation loss: 2.134081432896276

Epoch: 6| Step: 11
Training loss: 2.0915286540985107
Validation loss: 2.199921904071685

Epoch: 6| Step: 12
Training loss: 2.5782134532928467
Validation loss: 2.212252083645072

Epoch: 6| Step: 13
Training loss: 1.3775947093963623
Validation loss: 2.11035369929447

Epoch: 152| Step: 0
Training loss: 2.537172317504883
Validation loss: 2.2049402024156306

Epoch: 6| Step: 1
Training loss: 1.8393713235855103
Validation loss: 2.15560156555586

Epoch: 6| Step: 2
Training loss: 1.431427240371704
Validation loss: 2.194348613421122

Epoch: 6| Step: 3
Training loss: 2.0387587547302246
Validation loss: 2.227300210665631

Epoch: 6| Step: 4
Training loss: 1.9769110679626465
Validation loss: 2.183342120980704

Epoch: 6| Step: 5
Training loss: 2.750487804412842
Validation loss: 2.141487824019565

Epoch: 6| Step: 6
Training loss: 1.7649435997009277
Validation loss: 2.14489342576714

Epoch: 6| Step: 7
Training loss: 2.8647584915161133
Validation loss: 2.177107018809165

Epoch: 6| Step: 8
Training loss: 2.196438789367676
Validation loss: 2.128410271418992

Epoch: 6| Step: 9
Training loss: 2.1249725818634033
Validation loss: 2.096441343266477

Epoch: 6| Step: 10
Training loss: 2.294308662414551
Validation loss: 2.14440768764865

Epoch: 6| Step: 11
Training loss: 2.01004695892334
Validation loss: 2.183660912257369

Epoch: 6| Step: 12
Training loss: 2.4863362312316895
Validation loss: 2.2046554473138626

Epoch: 6| Step: 13
Training loss: 2.5255119800567627
Validation loss: 2.137580966436735

Epoch: 153| Step: 0
Training loss: 2.090066909790039
Validation loss: 2.0964144352943666

Epoch: 6| Step: 1
Training loss: 1.8017890453338623
Validation loss: 2.1202913843175417

Epoch: 6| Step: 2
Training loss: 2.77042555809021
Validation loss: 2.1146796223937825

Epoch: 6| Step: 3
Training loss: 1.7672113180160522
Validation loss: 2.1777758521418416

Epoch: 6| Step: 4
Training loss: 1.6438343524932861
Validation loss: 2.2636481561968402

Epoch: 6| Step: 5
Training loss: 2.8078885078430176
Validation loss: 2.2375192719121135

Epoch: 6| Step: 6
Training loss: 2.3198556900024414
Validation loss: 2.162043684272356

Epoch: 6| Step: 7
Training loss: 1.8603758811950684
Validation loss: 2.1290373904730684

Epoch: 6| Step: 8
Training loss: 2.2832489013671875
Validation loss: 2.213878808483001

Epoch: 6| Step: 9
Training loss: 2.384087562561035
Validation loss: 2.202004685196825

Epoch: 6| Step: 10
Training loss: 2.309152603149414
Validation loss: 2.2315488963998775

Epoch: 6| Step: 11
Training loss: 2.674518346786499
Validation loss: 2.2103660465568624

Epoch: 6| Step: 12
Training loss: 1.9586851596832275
Validation loss: 2.135936954970001

Epoch: 6| Step: 13
Training loss: 1.6652162075042725
Validation loss: 2.2298083818087013

Epoch: 154| Step: 0
Training loss: 2.185864210128784
Validation loss: 2.1733611911855717

Epoch: 6| Step: 1
Training loss: 2.1792681217193604
Validation loss: 2.1689281912260157

Epoch: 6| Step: 2
Training loss: 2.3306527137756348
Validation loss: 2.1289663878820275

Epoch: 6| Step: 3
Training loss: 2.1216671466827393
Validation loss: 2.1637269014953286

Epoch: 6| Step: 4
Training loss: 1.9911065101623535
Validation loss: 2.1550144867230485

Epoch: 6| Step: 5
Training loss: 2.4421424865722656
Validation loss: 2.241392922657792

Epoch: 6| Step: 6
Training loss: 1.8107846975326538
Validation loss: 2.180033194121494

Epoch: 6| Step: 7
Training loss: 2.6401822566986084
Validation loss: 2.1375761371786877

Epoch: 6| Step: 8
Training loss: 2.2482948303222656
Validation loss: 2.166448467521257

Epoch: 6| Step: 9
Training loss: 1.688557505607605
Validation loss: 2.143281364953646

Epoch: 6| Step: 10
Training loss: 1.9583702087402344
Validation loss: 2.0725313053336194

Epoch: 6| Step: 11
Training loss: 1.8333513736724854
Validation loss: 2.1401180682643766

Epoch: 6| Step: 12
Training loss: 2.440413475036621
Validation loss: 2.1785737122258833

Epoch: 6| Step: 13
Training loss: 2.1189846992492676
Validation loss: 2.1514759730267268

Epoch: 155| Step: 0
Training loss: 1.530259609222412
Validation loss: 2.1587221443012194

Epoch: 6| Step: 1
Training loss: 1.5726972818374634
Validation loss: 2.1391769506598033

Epoch: 6| Step: 2
Training loss: 2.175281524658203
Validation loss: 2.15989807087888

Epoch: 6| Step: 3
Training loss: 2.6723055839538574
Validation loss: 2.0898066912927935

Epoch: 6| Step: 4
Training loss: 1.8732311725616455
Validation loss: 2.249911421088762

Epoch: 6| Step: 5
Training loss: 1.8314964771270752
Validation loss: 2.1187725643957815

Epoch: 6| Step: 6
Training loss: 1.8146682977676392
Validation loss: 2.1317030101694088

Epoch: 6| Step: 7
Training loss: 1.8482669591903687
Validation loss: 2.09882701084178

Epoch: 6| Step: 8
Training loss: 2.599355936050415
Validation loss: 2.1486694582047

Epoch: 6| Step: 9
Training loss: 2.3887550830841064
Validation loss: 2.2409024853860178

Epoch: 6| Step: 10
Training loss: 2.823878765106201
Validation loss: 2.190258972106441

Epoch: 6| Step: 11
Training loss: 2.563868522644043
Validation loss: 2.177887543555229

Epoch: 6| Step: 12
Training loss: 1.9907526969909668
Validation loss: 2.117922315033533

Epoch: 6| Step: 13
Training loss: 2.514054298400879
Validation loss: 2.096640343307167

Epoch: 156| Step: 0
Training loss: 1.9837121963500977
Validation loss: 2.184177721700361

Epoch: 6| Step: 1
Training loss: 2.1177937984466553
Validation loss: 2.2364264252365276

Epoch: 6| Step: 2
Training loss: 1.9823992252349854
Validation loss: 2.141448300371888

Epoch: 6| Step: 3
Training loss: 2.120309829711914
Validation loss: 2.218485774532441

Epoch: 6| Step: 4
Training loss: 1.8355079889297485
Validation loss: 2.255084632545389

Epoch: 6| Step: 5
Training loss: 2.7256507873535156
Validation loss: 2.201047606365655

Epoch: 6| Step: 6
Training loss: 1.7633029222488403
Validation loss: 2.220930384051415

Epoch: 6| Step: 7
Training loss: 1.658820629119873
Validation loss: 2.1764117825415825

Epoch: 6| Step: 8
Training loss: 2.1146552562713623
Validation loss: 2.149141867955526

Epoch: 6| Step: 9
Training loss: 2.717784881591797
Validation loss: 2.165444799648818

Epoch: 6| Step: 10
Training loss: 2.0078186988830566
Validation loss: 2.1651434693285214

Epoch: 6| Step: 11
Training loss: 2.1655969619750977
Validation loss: 2.1291816952408

Epoch: 6| Step: 12
Training loss: 3.0473408699035645
Validation loss: 2.13717233750128

Epoch: 6| Step: 13
Training loss: 2.9618406295776367
Validation loss: 2.1872655742911884

Epoch: 157| Step: 0
Training loss: 2.443197011947632
Validation loss: 2.1927281938573366

Epoch: 6| Step: 1
Training loss: 2.0551774501800537
Validation loss: 2.157400215825727

Epoch: 6| Step: 2
Training loss: 1.9134876728057861
Validation loss: 2.1939250269243793

Epoch: 6| Step: 3
Training loss: 1.7702322006225586
Validation loss: 2.1572236322587535

Epoch: 6| Step: 4
Training loss: 2.77017879486084
Validation loss: 2.1457270896562965

Epoch: 6| Step: 5
Training loss: 1.322174310684204
Validation loss: 2.1521007604496454

Epoch: 6| Step: 6
Training loss: 2.2842066287994385
Validation loss: 2.113121250624298

Epoch: 6| Step: 7
Training loss: 1.766040563583374
Validation loss: 2.188865702639344

Epoch: 6| Step: 8
Training loss: 2.2692370414733887
Validation loss: 2.1847931787531865

Epoch: 6| Step: 9
Training loss: 2.442519426345825
Validation loss: 2.043289734471229

Epoch: 6| Step: 10
Training loss: 2.736743450164795
Validation loss: 2.0901027456406625

Epoch: 6| Step: 11
Training loss: 2.8436713218688965
Validation loss: 2.12354576587677

Epoch: 6| Step: 12
Training loss: 2.62707781791687
Validation loss: 2.1295129855473838

Epoch: 6| Step: 13
Training loss: 1.3658720254898071
Validation loss: 2.1692309328304824

Epoch: 158| Step: 0
Training loss: 2.534658908843994
Validation loss: 2.084532465986026

Epoch: 6| Step: 1
Training loss: 2.1399145126342773
Validation loss: 2.0650322668014036

Epoch: 6| Step: 2
Training loss: 2.2410900592803955
Validation loss: 2.1789850291385444

Epoch: 6| Step: 3
Training loss: 2.3308632373809814
Validation loss: 2.1685093628462924

Epoch: 6| Step: 4
Training loss: 2.7170472145080566
Validation loss: 2.1547900412672307

Epoch: 6| Step: 5
Training loss: 1.9851561784744263
Validation loss: 2.1517223106917513

Epoch: 6| Step: 6
Training loss: 2.3542399406433105
Validation loss: 2.1440091543300177

Epoch: 6| Step: 7
Training loss: 1.9111515283584595
Validation loss: 2.1837602046228226

Epoch: 6| Step: 8
Training loss: 2.5351743698120117
Validation loss: 2.1640369763938327

Epoch: 6| Step: 9
Training loss: 2.2311811447143555
Validation loss: 2.17762763269486

Epoch: 6| Step: 10
Training loss: 1.7344391345977783
Validation loss: 2.165380765033025

Epoch: 6| Step: 11
Training loss: 1.7479445934295654
Validation loss: 2.1833869641827

Epoch: 6| Step: 12
Training loss: 1.420818567276001
Validation loss: 2.214421231259582

Epoch: 6| Step: 13
Training loss: 2.144728899002075
Validation loss: 2.1707878176883986

Epoch: 159| Step: 0
Training loss: 1.9766552448272705
Validation loss: 2.159776092857443

Epoch: 6| Step: 1
Training loss: 2.954070806503296
Validation loss: 2.178028791181503

Epoch: 6| Step: 2
Training loss: 2.071420907974243
Validation loss: 2.203617662511846

Epoch: 6| Step: 3
Training loss: 2.171706438064575
Validation loss: 2.172846617237214

Epoch: 6| Step: 4
Training loss: 1.9488499164581299
Validation loss: 2.2036508603762557

Epoch: 6| Step: 5
Training loss: 1.8574542999267578
Validation loss: 2.164925898275068

Epoch: 6| Step: 6
Training loss: 2.246001958847046
Validation loss: 2.246023931810933

Epoch: 6| Step: 7
Training loss: 2.3877339363098145
Validation loss: 2.258230483660134

Epoch: 6| Step: 8
Training loss: 2.5314364433288574
Validation loss: 2.1966079358131654

Epoch: 6| Step: 9
Training loss: 2.220284938812256
Validation loss: 2.18711793550881

Epoch: 6| Step: 10
Training loss: 1.8226743936538696
Validation loss: 2.270111237802813

Epoch: 6| Step: 11
Training loss: 2.3303627967834473
Validation loss: 2.1889843786916425

Epoch: 6| Step: 12
Training loss: 1.9615716934204102
Validation loss: 2.1919879067328667

Epoch: 6| Step: 13
Training loss: 1.4010826349258423
Validation loss: 2.2543049935371644

Epoch: 160| Step: 0
Training loss: 2.3046979904174805
Validation loss: 2.175283826807494

Epoch: 6| Step: 1
Training loss: 2.557004928588867
Validation loss: 2.2124474304978565

Epoch: 6| Step: 2
Training loss: 1.8084142208099365
Validation loss: 2.127635737901093

Epoch: 6| Step: 3
Training loss: 1.8916325569152832
Validation loss: 2.1057909201550227

Epoch: 6| Step: 4
Training loss: 1.7274765968322754
Validation loss: 2.149018622213794

Epoch: 6| Step: 5
Training loss: 2.9023852348327637
Validation loss: 2.068984793078515

Epoch: 6| Step: 6
Training loss: 1.7861595153808594
Validation loss: 2.16866014593391

Epoch: 6| Step: 7
Training loss: 1.965993046760559
Validation loss: 2.184907918335289

Epoch: 6| Step: 8
Training loss: 2.1624703407287598
Validation loss: 2.1008022933877926

Epoch: 6| Step: 9
Training loss: 2.401397943496704
Validation loss: 2.190853491906197

Epoch: 6| Step: 10
Training loss: 1.7742500305175781
Validation loss: 2.1223776930121967

Epoch: 6| Step: 11
Training loss: 1.4060899019241333
Validation loss: 2.0673750241597495

Epoch: 6| Step: 12
Training loss: 2.723641872406006
Validation loss: 2.098673916632129

Epoch: 6| Step: 13
Training loss: 2.666804313659668
Validation loss: 2.157817937994516

Epoch: 161| Step: 0
Training loss: 2.384662628173828
Validation loss: 2.14831079077977

Epoch: 6| Step: 1
Training loss: 1.9083341360092163
Validation loss: 2.1127791225269275

Epoch: 6| Step: 2
Training loss: 2.434192419052124
Validation loss: 2.1502710978190103

Epoch: 6| Step: 3
Training loss: 2.323129177093506
Validation loss: 2.1773708058941748

Epoch: 6| Step: 4
Training loss: 1.9244931936264038
Validation loss: 2.122187637513684

Epoch: 6| Step: 5
Training loss: 2.6529603004455566
Validation loss: 2.125726379374022

Epoch: 6| Step: 6
Training loss: 2.7021257877349854
Validation loss: 2.117395608655868

Epoch: 6| Step: 7
Training loss: 2.4049081802368164
Validation loss: 2.1182500290614303

Epoch: 6| Step: 8
Training loss: 1.9405443668365479
Validation loss: 2.172770707837997

Epoch: 6| Step: 9
Training loss: 1.8634748458862305
Validation loss: 2.1648408353969617

Epoch: 6| Step: 10
Training loss: 1.4370568990707397
Validation loss: 2.075662512933054

Epoch: 6| Step: 11
Training loss: 2.33479905128479
Validation loss: 2.103315971230948

Epoch: 6| Step: 12
Training loss: 2.341510772705078
Validation loss: 2.0654838238993

Epoch: 6| Step: 13
Training loss: 0.9434382319450378
Validation loss: 2.1541637541145406

Epoch: 162| Step: 0
Training loss: 2.308506488800049
Validation loss: 2.206540294872817

Epoch: 6| Step: 1
Training loss: 2.2031195163726807
Validation loss: 2.0865004421562277

Epoch: 6| Step: 2
Training loss: 1.4999481439590454
Validation loss: 2.136839105236915

Epoch: 6| Step: 3
Training loss: 2.3376340866088867
Validation loss: 2.0888657492976033

Epoch: 6| Step: 4
Training loss: 1.595811367034912
Validation loss: 2.11259735784223

Epoch: 6| Step: 5
Training loss: 2.0641698837280273
Validation loss: 2.1053653917004986

Epoch: 6| Step: 6
Training loss: 1.8129546642303467
Validation loss: 2.0914471098171767

Epoch: 6| Step: 7
Training loss: 2.1516666412353516
Validation loss: 2.1423765331186275

Epoch: 6| Step: 8
Training loss: 3.3701834678649902
Validation loss: 2.189453927419519

Epoch: 6| Step: 9
Training loss: 2.6987216472625732
Validation loss: 2.1605085044778805

Epoch: 6| Step: 10
Training loss: 2.673067569732666
Validation loss: 2.1189284837374123

Epoch: 6| Step: 11
Training loss: 1.2652415037155151
Validation loss: 2.1737742808557328

Epoch: 6| Step: 12
Training loss: 1.9681792259216309
Validation loss: 2.1586591607780865

Epoch: 6| Step: 13
Training loss: 2.388472557067871
Validation loss: 2.1362136615219938

Epoch: 163| Step: 0
Training loss: 2.6316287517547607
Validation loss: 2.1926588807054745

Epoch: 6| Step: 1
Training loss: 2.9374516010284424
Validation loss: 2.1709174520225933

Epoch: 6| Step: 2
Training loss: 2.2344555854797363
Validation loss: 2.1677978448970343

Epoch: 6| Step: 3
Training loss: 1.7453434467315674
Validation loss: 2.143522339482461

Epoch: 6| Step: 4
Training loss: 2.1768033504486084
Validation loss: 2.147737464597148

Epoch: 6| Step: 5
Training loss: 2.5161707401275635
Validation loss: 2.1162340179566415

Epoch: 6| Step: 6
Training loss: 2.4104971885681152
Validation loss: 2.197985255590049

Epoch: 6| Step: 7
Training loss: 1.6496472358703613
Validation loss: 2.211948948521768

Epoch: 6| Step: 8
Training loss: 2.1682839393615723
Validation loss: 2.165466785430908

Epoch: 6| Step: 9
Training loss: 2.018960475921631
Validation loss: 2.166204075659475

Epoch: 6| Step: 10
Training loss: 1.4730470180511475
Validation loss: 2.1582698873294297

Epoch: 6| Step: 11
Training loss: 2.154305934906006
Validation loss: 2.1690907901333225

Epoch: 6| Step: 12
Training loss: 1.8881127834320068
Validation loss: 2.1593156527447444

Epoch: 6| Step: 13
Training loss: 1.996747374534607
Validation loss: 2.202421265263711

Epoch: 164| Step: 0
Training loss: 1.7853195667266846
Validation loss: 2.115163372408959

Epoch: 6| Step: 1
Training loss: 1.5576775074005127
Validation loss: 2.1142804622650146

Epoch: 6| Step: 2
Training loss: 3.0085058212280273
Validation loss: 2.144301099161948

Epoch: 6| Step: 3
Training loss: 1.9218697547912598
Validation loss: 2.1393395495671097

Epoch: 6| Step: 4
Training loss: 1.97152578830719
Validation loss: 2.120440206220073

Epoch: 6| Step: 5
Training loss: 2.3707590103149414
Validation loss: 2.2064544564934185

Epoch: 6| Step: 6
Training loss: 1.6360056400299072
Validation loss: 2.220021883646647

Epoch: 6| Step: 7
Training loss: 2.6832079887390137
Validation loss: 2.120434068864392

Epoch: 6| Step: 8
Training loss: 1.8967002630233765
Validation loss: 2.1601832066812823

Epoch: 6| Step: 9
Training loss: 2.478661298751831
Validation loss: 2.2060753004525298

Epoch: 6| Step: 10
Training loss: 2.669268846511841
Validation loss: 2.1320035624247726

Epoch: 6| Step: 11
Training loss: 1.729772686958313
Validation loss: 2.162220537021596

Epoch: 6| Step: 12
Training loss: 2.192481517791748
Validation loss: 2.159001660603349

Epoch: 6| Step: 13
Training loss: 2.3973515033721924
Validation loss: 2.1688761070210445

Epoch: 165| Step: 0
Training loss: 1.942293405532837
Validation loss: 2.187452575211884

Epoch: 6| Step: 1
Training loss: 1.9642658233642578
Validation loss: 2.1434123567355576

Epoch: 6| Step: 2
Training loss: 1.9328205585479736
Validation loss: 2.203161798497682

Epoch: 6| Step: 3
Training loss: 2.344191551208496
Validation loss: 2.192396451068181

Epoch: 6| Step: 4
Training loss: 1.8186582326889038
Validation loss: 2.108512968145391

Epoch: 6| Step: 5
Training loss: 2.046931743621826
Validation loss: 2.271306250685005

Epoch: 6| Step: 6
Training loss: 1.5909031629562378
Validation loss: 2.186876194451445

Epoch: 6| Step: 7
Training loss: 2.951993227005005
Validation loss: 2.0884572575169225

Epoch: 6| Step: 8
Training loss: 2.188174247741699
Validation loss: 2.1449635900476927

Epoch: 6| Step: 9
Training loss: 2.765265464782715
Validation loss: 2.0822267429803007

Epoch: 6| Step: 10
Training loss: 1.957528829574585
Validation loss: 2.1543178507076797

Epoch: 6| Step: 11
Training loss: 2.372741937637329
Validation loss: 2.164761006191213

Epoch: 6| Step: 12
Training loss: 1.6799440383911133
Validation loss: 2.1533985740395

Epoch: 6| Step: 13
Training loss: 1.9684796333312988
Validation loss: 2.1700235797512915

Epoch: 166| Step: 0
Training loss: 1.756062626838684
Validation loss: 2.1272496946396364

Epoch: 6| Step: 1
Training loss: 1.8698885440826416
Validation loss: 2.0921652650320404

Epoch: 6| Step: 2
Training loss: 2.1012978553771973
Validation loss: 2.0771056195741058

Epoch: 6| Step: 3
Training loss: 1.737255573272705
Validation loss: 2.1573786094624507

Epoch: 6| Step: 4
Training loss: 2.034951686859131
Validation loss: 2.1335731270492717

Epoch: 6| Step: 5
Training loss: 1.822657823562622
Validation loss: 2.171754753717812

Epoch: 6| Step: 6
Training loss: 1.871350646018982
Validation loss: 2.077685663777013

Epoch: 6| Step: 7
Training loss: 2.1885228157043457
Validation loss: 2.1426774096745316

Epoch: 6| Step: 8
Training loss: 2.8624672889709473
Validation loss: 2.135588215243432

Epoch: 6| Step: 9
Training loss: 2.7801926136016846
Validation loss: 2.1194244943639284

Epoch: 6| Step: 10
Training loss: 2.42500376701355
Validation loss: 2.2690956746378252

Epoch: 6| Step: 11
Training loss: 2.3388478755950928
Validation loss: 2.1407406304472234

Epoch: 6| Step: 12
Training loss: 1.9055085182189941
Validation loss: 2.140023467361286

Epoch: 6| Step: 13
Training loss: 1.8455939292907715
Validation loss: 2.115781003429044

Epoch: 167| Step: 0
Training loss: 0.9745633602142334
Validation loss: 2.177795966466268

Epoch: 6| Step: 1
Training loss: 3.090172529220581
Validation loss: 2.158097054368706

Epoch: 6| Step: 2
Training loss: 1.2693313360214233
Validation loss: 2.2146250855538154

Epoch: 6| Step: 3
Training loss: 2.045844316482544
Validation loss: 2.091851790746053

Epoch: 6| Step: 4
Training loss: 2.220447540283203
Validation loss: 2.1069006522496543

Epoch: 6| Step: 5
Training loss: 2.2433972358703613
Validation loss: 2.105307476494902

Epoch: 6| Step: 6
Training loss: 2.0966944694519043
Validation loss: 2.0820531729728944

Epoch: 6| Step: 7
Training loss: 2.150567054748535
Validation loss: 2.2025220676134993

Epoch: 6| Step: 8
Training loss: 1.9342904090881348
Validation loss: 2.0909371376037598

Epoch: 6| Step: 9
Training loss: 2.6721575260162354
Validation loss: 2.135639734165643

Epoch: 6| Step: 10
Training loss: 2.655604839324951
Validation loss: 2.124440359812911

Epoch: 6| Step: 11
Training loss: 1.8572328090667725
Validation loss: 2.137211412511846

Epoch: 6| Step: 12
Training loss: 2.7747669219970703
Validation loss: 2.0501307415705856

Epoch: 6| Step: 13
Training loss: 2.64155912399292
Validation loss: 2.0792396991483626

Epoch: 168| Step: 0
Training loss: 1.5232815742492676
Validation loss: 2.133700547679778

Epoch: 6| Step: 1
Training loss: 2.2500619888305664
Validation loss: 2.0690205661199426

Epoch: 6| Step: 2
Training loss: 2.2351644039154053
Validation loss: 2.207191228866577

Epoch: 6| Step: 3
Training loss: 2.707879066467285
Validation loss: 2.167791276849726

Epoch: 6| Step: 4
Training loss: 2.6955037117004395
Validation loss: 2.1547757553797897

Epoch: 6| Step: 5
Training loss: 2.367218017578125
Validation loss: 2.217526606334153

Epoch: 6| Step: 6
Training loss: 2.447519302368164
Validation loss: 2.1630741729531238

Epoch: 6| Step: 7
Training loss: 2.3965229988098145
Validation loss: 2.175009545459542

Epoch: 6| Step: 8
Training loss: 1.7778770923614502
Validation loss: 2.1456221995815152

Epoch: 6| Step: 9
Training loss: 1.8472694158554077
Validation loss: 2.1730204218177387

Epoch: 6| Step: 10
Training loss: 1.8792483806610107
Validation loss: 2.1668222335077103

Epoch: 6| Step: 11
Training loss: 1.933035135269165
Validation loss: 2.2272348403930664

Epoch: 6| Step: 12
Training loss: 2.5261263847351074
Validation loss: 2.13307882637106

Epoch: 6| Step: 13
Training loss: 1.931782603263855
Validation loss: 2.1696316196072485

Epoch: 169| Step: 0
Training loss: 2.2549796104431152
Validation loss: 2.1703626263526177

Epoch: 6| Step: 1
Training loss: 2.2336783409118652
Validation loss: 2.15353202050732

Epoch: 6| Step: 2
Training loss: 1.8060938119888306
Validation loss: 2.1990569740213375

Epoch: 6| Step: 3
Training loss: 2.012503147125244
Validation loss: 2.1943000003855717

Epoch: 6| Step: 4
Training loss: 1.4186567068099976
Validation loss: 2.102752403546405

Epoch: 6| Step: 5
Training loss: 2.2892661094665527
Validation loss: 2.0643440228636547

Epoch: 6| Step: 6
Training loss: 2.8890061378479004
Validation loss: 2.2018635452434583

Epoch: 6| Step: 7
Training loss: 2.2288265228271484
Validation loss: 2.1592750498043594

Epoch: 6| Step: 8
Training loss: 2.0391106605529785
Validation loss: 2.1964410428077943

Epoch: 6| Step: 9
Training loss: 2.670090675354004
Validation loss: 2.154526956619755

Epoch: 6| Step: 10
Training loss: 1.9381699562072754
Validation loss: 2.192499460712556

Epoch: 6| Step: 11
Training loss: 2.0016496181488037
Validation loss: 2.156541451331108

Epoch: 6| Step: 12
Training loss: 1.9702401161193848
Validation loss: 2.217862788067069

Epoch: 6| Step: 13
Training loss: 2.02052903175354
Validation loss: 2.1435767399367465

Epoch: 170| Step: 0
Training loss: 2.616340398788452
Validation loss: 2.210562088156259

Epoch: 6| Step: 1
Training loss: 1.4054713249206543
Validation loss: 2.1280557058190785

Epoch: 6| Step: 2
Training loss: 3.068408966064453
Validation loss: 2.1726782193747898

Epoch: 6| Step: 3
Training loss: 1.7287876605987549
Validation loss: 2.1048737495176253

Epoch: 6| Step: 4
Training loss: 2.798305034637451
Validation loss: 2.131000321398499

Epoch: 6| Step: 5
Training loss: 2.0966408252716064
Validation loss: 2.144279528689641

Epoch: 6| Step: 6
Training loss: 1.8899967670440674
Validation loss: 2.22013416341556

Epoch: 6| Step: 7
Training loss: 1.4974722862243652
Validation loss: 2.1410415454577376

Epoch: 6| Step: 8
Training loss: 2.1403443813323975
Validation loss: 2.121585435764764

Epoch: 6| Step: 9
Training loss: 2.6296422481536865
Validation loss: 2.112344677730273

Epoch: 6| Step: 10
Training loss: 2.043593645095825
Validation loss: 2.1842242979234263

Epoch: 6| Step: 11
Training loss: 1.7689905166625977
Validation loss: 2.1325892850916874

Epoch: 6| Step: 12
Training loss: 2.2353415489196777
Validation loss: 2.157990312063566

Epoch: 6| Step: 13
Training loss: 1.9516135454177856
Validation loss: 2.1669324008367394

Epoch: 171| Step: 0
Training loss: 1.9989538192749023
Validation loss: 2.0412950259383007

Epoch: 6| Step: 1
Training loss: 2.558448314666748
Validation loss: 2.1311229941665486

Epoch: 6| Step: 2
Training loss: 2.487090587615967
Validation loss: 2.152391859280166

Epoch: 6| Step: 3
Training loss: 2.155344247817993
Validation loss: 2.115029493967692

Epoch: 6| Step: 4
Training loss: 1.521923303604126
Validation loss: 2.1006296193727882

Epoch: 6| Step: 5
Training loss: 2.2527599334716797
Validation loss: 2.0953217962736725

Epoch: 6| Step: 6
Training loss: 2.9225845336914062
Validation loss: 2.0961517492930093

Epoch: 6| Step: 7
Training loss: 2.0732204914093018
Validation loss: 2.1183001302903697

Epoch: 6| Step: 8
Training loss: 1.4829943180084229
Validation loss: 2.173023872478034

Epoch: 6| Step: 9
Training loss: 2.4932754039764404
Validation loss: 2.174048558358223

Epoch: 6| Step: 10
Training loss: 2.3303751945495605
Validation loss: 2.036877432177144

Epoch: 6| Step: 11
Training loss: 2.4036059379577637
Validation loss: 2.1343599596331195

Epoch: 6| Step: 12
Training loss: 1.369372844696045
Validation loss: 2.104432326491161

Epoch: 6| Step: 13
Training loss: 2.3634438514709473
Validation loss: 2.034586227068337

Epoch: 172| Step: 0
Training loss: 2.124305009841919
Validation loss: 2.1426779608572684

Epoch: 6| Step: 1
Training loss: 1.6322567462921143
Validation loss: 2.098297413959298

Epoch: 6| Step: 2
Training loss: 2.236252784729004
Validation loss: 2.091312892975346

Epoch: 6| Step: 3
Training loss: 2.217158555984497
Validation loss: 2.112808970994847

Epoch: 6| Step: 4
Training loss: 1.5690457820892334
Validation loss: 2.1608574492957002

Epoch: 6| Step: 5
Training loss: 2.0469350814819336
Validation loss: 2.1500760637303835

Epoch: 6| Step: 6
Training loss: 2.044613838195801
Validation loss: 2.2426370523309194

Epoch: 6| Step: 7
Training loss: 1.5566346645355225
Validation loss: 2.158203422382314

Epoch: 6| Step: 8
Training loss: 1.650965929031372
Validation loss: 2.1425458795280865

Epoch: 6| Step: 9
Training loss: 2.4257264137268066
Validation loss: 2.1456732339756464

Epoch: 6| Step: 10
Training loss: 2.595202684402466
Validation loss: 2.238511893057054

Epoch: 6| Step: 11
Training loss: 2.9003703594207764
Validation loss: 2.195498676710231

Epoch: 6| Step: 12
Training loss: 2.4753682613372803
Validation loss: 2.1570869312491467

Epoch: 6| Step: 13
Training loss: 2.5552968978881836
Validation loss: 2.1386880913088397

Epoch: 173| Step: 0
Training loss: 1.4963133335113525
Validation loss: 2.1437531363579536

Epoch: 6| Step: 1
Training loss: 1.7295005321502686
Validation loss: 2.225849615630283

Epoch: 6| Step: 2
Training loss: 2.479243278503418
Validation loss: 2.201610706185782

Epoch: 6| Step: 3
Training loss: 2.956923007965088
Validation loss: 2.224026944047661

Epoch: 6| Step: 4
Training loss: 1.7738393545150757
Validation loss: 2.242036259302529

Epoch: 6| Step: 5
Training loss: 1.6028515100479126
Validation loss: 2.2673223275010304

Epoch: 6| Step: 6
Training loss: 2.240854501724243
Validation loss: 2.316880274844426

Epoch: 6| Step: 7
Training loss: 1.8409111499786377
Validation loss: 2.23965435899714

Epoch: 6| Step: 8
Training loss: 1.8377153873443604
Validation loss: 2.2326049394505

Epoch: 6| Step: 9
Training loss: 2.6628050804138184
Validation loss: 2.2117209972873813

Epoch: 6| Step: 10
Training loss: 2.2758145332336426
Validation loss: 2.257996984707412

Epoch: 6| Step: 11
Training loss: 2.687145709991455
Validation loss: 2.2321011943201863

Epoch: 6| Step: 12
Training loss: 2.1191530227661133
Validation loss: 2.195398880589393

Epoch: 6| Step: 13
Training loss: 3.1859140396118164
Validation loss: 2.247049912329643

Epoch: 174| Step: 0
Training loss: 2.084336996078491
Validation loss: 2.2529940848709433

Epoch: 6| Step: 1
Training loss: 2.3270316123962402
Validation loss: 2.1380829426550094

Epoch: 6| Step: 2
Training loss: 3.171360969543457
Validation loss: 2.230042255052956

Epoch: 6| Step: 3
Training loss: 1.9670422077178955
Validation loss: 2.1855154883476997

Epoch: 6| Step: 4
Training loss: 2.184688091278076
Validation loss: 2.1156702759445354

Epoch: 6| Step: 5
Training loss: 2.4325273036956787
Validation loss: 2.121033767218231

Epoch: 6| Step: 6
Training loss: 1.428586721420288
Validation loss: 2.2036768928650887

Epoch: 6| Step: 7
Training loss: 2.2270514965057373
Validation loss: 2.0379690124142553

Epoch: 6| Step: 8
Training loss: 2.0259342193603516
Validation loss: 2.2014098090510212

Epoch: 6| Step: 9
Training loss: 2.3307361602783203
Validation loss: 2.1727149640360186

Epoch: 6| Step: 10
Training loss: 1.3198117017745972
Validation loss: 2.129687291319652

Epoch: 6| Step: 11
Training loss: 1.9598785638809204
Validation loss: 2.0941336924029934

Epoch: 6| Step: 12
Training loss: 2.361063241958618
Validation loss: 2.203310412745322

Epoch: 6| Step: 13
Training loss: 1.71956205368042
Validation loss: 2.1837715564235562

Epoch: 175| Step: 0
Training loss: 2.196380138397217
Validation loss: 2.1259922647988923

Epoch: 6| Step: 1
Training loss: 2.5151445865631104
Validation loss: 2.084535519282023

Epoch: 6| Step: 2
Training loss: 2.0118629932403564
Validation loss: 2.1922472215467885

Epoch: 6| Step: 3
Training loss: 2.0979349613189697
Validation loss: 2.1760027818782355

Epoch: 6| Step: 4
Training loss: 2.8162145614624023
Validation loss: 2.150146935575752

Epoch: 6| Step: 5
Training loss: 1.8774640560150146
Validation loss: 2.1843285752880957

Epoch: 6| Step: 6
Training loss: 1.8773753643035889
Validation loss: 2.1137510422737367

Epoch: 6| Step: 7
Training loss: 1.861375093460083
Validation loss: 2.174618982499646

Epoch: 6| Step: 8
Training loss: 1.631543517112732
Validation loss: 2.0739460145273516

Epoch: 6| Step: 9
Training loss: 2.4472057819366455
Validation loss: 2.1141525571064284

Epoch: 6| Step: 10
Training loss: 2.1152453422546387
Validation loss: 2.1389734975753294

Epoch: 6| Step: 11
Training loss: 2.0828492641448975
Validation loss: 2.100791565833553

Epoch: 6| Step: 12
Training loss: 2.7538819313049316
Validation loss: 2.182742066280816

Epoch: 6| Step: 13
Training loss: 1.8989518880844116
Validation loss: 2.116623450351018

Epoch: 176| Step: 0
Training loss: 1.9429317712783813
Validation loss: 2.0371539285106044

Epoch: 6| Step: 1
Training loss: 2.0614516735076904
Validation loss: 2.1889279824431225

Epoch: 6| Step: 2
Training loss: 2.1246790885925293
Validation loss: 2.1284463585063977

Epoch: 6| Step: 3
Training loss: 2.0846452713012695
Validation loss: 2.1481151452628513

Epoch: 6| Step: 4
Training loss: 1.6605730056762695
Validation loss: 2.1060724873696604

Epoch: 6| Step: 5
Training loss: 2.892486572265625
Validation loss: 2.127608588946763

Epoch: 6| Step: 6
Training loss: 1.8233733177185059
Validation loss: 2.1456407154760053

Epoch: 6| Step: 7
Training loss: 1.7629833221435547
Validation loss: 2.2071241717184744

Epoch: 6| Step: 8
Training loss: 2.2104454040527344
Validation loss: 2.2037790231807257

Epoch: 6| Step: 9
Training loss: 1.5815733671188354
Validation loss: 2.156699413894325

Epoch: 6| Step: 10
Training loss: 2.407707691192627
Validation loss: 2.2171542926501204

Epoch: 6| Step: 11
Training loss: 2.4978322982788086
Validation loss: 2.1273351920548307

Epoch: 6| Step: 12
Training loss: 2.3371059894561768
Validation loss: 2.205004125513056

Epoch: 6| Step: 13
Training loss: 3.153903007507324
Validation loss: 2.197764681231591

Epoch: 177| Step: 0
Training loss: 1.7953596115112305
Validation loss: 2.0942759257490917

Epoch: 6| Step: 1
Training loss: 1.475343942642212
Validation loss: 2.151696817849272

Epoch: 6| Step: 2
Training loss: 2.3827409744262695
Validation loss: 2.1869458639493553

Epoch: 6| Step: 3
Training loss: 2.2477807998657227
Validation loss: 2.173200656008977

Epoch: 6| Step: 4
Training loss: 1.747523546218872
Validation loss: 2.1754759639822026

Epoch: 6| Step: 5
Training loss: 2.4937477111816406
Validation loss: 2.180849931573355

Epoch: 6| Step: 6
Training loss: 2.149813175201416
Validation loss: 2.171906481507004

Epoch: 6| Step: 7
Training loss: 2.137712001800537
Validation loss: 2.219184870361

Epoch: 6| Step: 8
Training loss: 2.699155807495117
Validation loss: 2.120602960227638

Epoch: 6| Step: 9
Training loss: 2.3361763954162598
Validation loss: 2.1475393387579147

Epoch: 6| Step: 10
Training loss: 2.483363389968872
Validation loss: 2.118317219518846

Epoch: 6| Step: 11
Training loss: 2.1432905197143555
Validation loss: 2.132687735301192

Epoch: 6| Step: 12
Training loss: 2.312810182571411
Validation loss: 2.123749748353035

Epoch: 6| Step: 13
Training loss: 1.8188735246658325
Validation loss: 2.163794325244042

Epoch: 178| Step: 0
Training loss: 2.0125021934509277
Validation loss: 2.1203872567863873

Epoch: 6| Step: 1
Training loss: 1.9321238994598389
Validation loss: 2.1604882465895785

Epoch: 6| Step: 2
Training loss: 2.3033411502838135
Validation loss: 2.0880006346651303

Epoch: 6| Step: 3
Training loss: 2.195427894592285
Validation loss: 2.1833363143346642

Epoch: 6| Step: 4
Training loss: 1.4771153926849365
Validation loss: 2.116386371274148

Epoch: 6| Step: 5
Training loss: 2.081024169921875
Validation loss: 2.063342020075808

Epoch: 6| Step: 6
Training loss: 2.9169421195983887
Validation loss: 2.1808105860987017

Epoch: 6| Step: 7
Training loss: 2.184328317642212
Validation loss: 2.1623940160197597

Epoch: 6| Step: 8
Training loss: 1.6542820930480957
Validation loss: 2.175293799369566

Epoch: 6| Step: 9
Training loss: 2.3798482418060303
Validation loss: 2.188635072400493

Epoch: 6| Step: 10
Training loss: 2.1498289108276367
Validation loss: 2.1572325588554464

Epoch: 6| Step: 11
Training loss: 1.8914859294891357
Validation loss: 2.1438240030760407

Epoch: 6| Step: 12
Training loss: 2.3132920265197754
Validation loss: 2.1481552482933126

Epoch: 6| Step: 13
Training loss: 2.267153739929199
Validation loss: 2.1173557004620953

Epoch: 179| Step: 0
Training loss: 1.809187889099121
Validation loss: 2.12944697308284

Epoch: 6| Step: 1
Training loss: 2.41257381439209
Validation loss: 2.1004951333486908

Epoch: 6| Step: 2
Training loss: 2.5482401847839355
Validation loss: 2.1139418643007994

Epoch: 6| Step: 3
Training loss: 2.5643577575683594
Validation loss: 2.1193834171500257

Epoch: 6| Step: 4
Training loss: 2.1454548835754395
Validation loss: 2.1281998439501693

Epoch: 6| Step: 5
Training loss: 1.5292835235595703
Validation loss: 2.1697189115708873

Epoch: 6| Step: 6
Training loss: 2.637042760848999
Validation loss: 2.056980094602031

Epoch: 6| Step: 7
Training loss: 2.1687824726104736
Validation loss: 2.0768445461027083

Epoch: 6| Step: 8
Training loss: 2.5330193042755127
Validation loss: 2.215984006081858

Epoch: 6| Step: 9
Training loss: 2.3710527420043945
Validation loss: 2.164381604040823

Epoch: 6| Step: 10
Training loss: 1.8387197256088257
Validation loss: 2.107459440026232

Epoch: 6| Step: 11
Training loss: 1.5598013401031494
Validation loss: 2.1724473173900316

Epoch: 6| Step: 12
Training loss: 1.8472659587860107
Validation loss: 2.105022548347391

Epoch: 6| Step: 13
Training loss: 2.3209383487701416
Validation loss: 2.1976458154698855

Epoch: 180| Step: 0
Training loss: 1.7108877897262573
Validation loss: 2.1948895685134397

Epoch: 6| Step: 1
Training loss: 1.8853508234024048
Validation loss: 2.1594496362952778

Epoch: 6| Step: 2
Training loss: 2.6746673583984375
Validation loss: 2.2087968139238257

Epoch: 6| Step: 3
Training loss: 2.4050753116607666
Validation loss: 2.146614650244354

Epoch: 6| Step: 4
Training loss: 2.0989158153533936
Validation loss: 2.1334108409061225

Epoch: 6| Step: 5
Training loss: 2.8135013580322266
Validation loss: 2.1929655049436834

Epoch: 6| Step: 6
Training loss: 2.5551185607910156
Validation loss: 2.064627775581934

Epoch: 6| Step: 7
Training loss: 2.0686304569244385
Validation loss: 2.1639741851437475

Epoch: 6| Step: 8
Training loss: 1.8646644353866577
Validation loss: 2.185221915603966

Epoch: 6| Step: 9
Training loss: 2.068244218826294
Validation loss: 2.1685371091288905

Epoch: 6| Step: 10
Training loss: 2.156538724899292
Validation loss: 2.2172611477554485

Epoch: 6| Step: 11
Training loss: 1.9949156045913696
Validation loss: 2.1504547121704265

Epoch: 6| Step: 12
Training loss: 2.2284719944000244
Validation loss: 2.192901826673938

Epoch: 6| Step: 13
Training loss: 0.9635729193687439
Validation loss: 2.205686696114079

Epoch: 181| Step: 0
Training loss: 2.219241142272949
Validation loss: 2.1614741240778277

Epoch: 6| Step: 1
Training loss: 2.3874619007110596
Validation loss: 2.221559250226585

Epoch: 6| Step: 2
Training loss: 2.087999105453491
Validation loss: 2.0790614005058043

Epoch: 6| Step: 3
Training loss: 2.273164749145508
Validation loss: 2.13209835303727

Epoch: 6| Step: 4
Training loss: 2.123204231262207
Validation loss: 2.1534253525477585

Epoch: 6| Step: 5
Training loss: 2.1386799812316895
Validation loss: 2.1786378506691224

Epoch: 6| Step: 6
Training loss: 1.9410895109176636
Validation loss: 2.131758148952197

Epoch: 6| Step: 7
Training loss: 1.550692081451416
Validation loss: 2.153173026218209

Epoch: 6| Step: 8
Training loss: 2.3569774627685547
Validation loss: 2.1790428981986096

Epoch: 6| Step: 9
Training loss: 2.3520612716674805
Validation loss: 2.0861895340745167

Epoch: 6| Step: 10
Training loss: 2.1101529598236084
Validation loss: 2.218167389592817

Epoch: 6| Step: 11
Training loss: 1.3658678531646729
Validation loss: 2.1837522932278213

Epoch: 6| Step: 12
Training loss: 2.1870434284210205
Validation loss: 2.1841887299732496

Epoch: 6| Step: 13
Training loss: 2.646132230758667
Validation loss: 2.1587982946826565

Epoch: 182| Step: 0
Training loss: 1.7714132070541382
Validation loss: 2.1444494365363993

Epoch: 6| Step: 1
Training loss: 2.002321720123291
Validation loss: 2.200128029751521

Epoch: 6| Step: 2
Training loss: 2.2759451866149902
Validation loss: 2.1053336102475404

Epoch: 6| Step: 3
Training loss: 1.6958422660827637
Validation loss: 2.0847409617516304

Epoch: 6| Step: 4
Training loss: 1.879129409790039
Validation loss: 2.144715973125991

Epoch: 6| Step: 5
Training loss: 1.8516719341278076
Validation loss: 2.1222908099492392

Epoch: 6| Step: 6
Training loss: 2.2991576194763184
Validation loss: 2.17997734777389

Epoch: 6| Step: 7
Training loss: 2.292534589767456
Validation loss: 2.114663836776569

Epoch: 6| Step: 8
Training loss: 2.4461140632629395
Validation loss: 2.1013980039986233

Epoch: 6| Step: 9
Training loss: 2.5158329010009766
Validation loss: 2.121133755612117

Epoch: 6| Step: 10
Training loss: 2.745347499847412
Validation loss: 2.151488474620286

Epoch: 6| Step: 11
Training loss: 1.7869305610656738
Validation loss: 2.213015571717293

Epoch: 6| Step: 12
Training loss: 1.72084379196167
Validation loss: 2.131974938095257

Epoch: 6| Step: 13
Training loss: 1.9728150367736816
Validation loss: 2.1305572243146997

Epoch: 183| Step: 0
Training loss: 1.9271717071533203
Validation loss: 2.1494556216783423

Epoch: 6| Step: 1
Training loss: 1.5392463207244873
Validation loss: 2.058643320555328

Epoch: 6| Step: 2
Training loss: 2.2128865718841553
Validation loss: 2.1798401545452815

Epoch: 6| Step: 3
Training loss: 1.688298225402832
Validation loss: 2.196759118828722

Epoch: 6| Step: 4
Training loss: 3.575021266937256
Validation loss: 2.2483933689773723

Epoch: 6| Step: 5
Training loss: 2.0143003463745117
Validation loss: 2.167031685511271

Epoch: 6| Step: 6
Training loss: 1.866701364517212
Validation loss: 2.12815047079517

Epoch: 6| Step: 7
Training loss: 1.3180079460144043
Validation loss: 2.1345273961303053

Epoch: 6| Step: 8
Training loss: 2.7924740314483643
Validation loss: 2.1924940386126117

Epoch: 6| Step: 9
Training loss: 1.1903690099716187
Validation loss: 2.1509524237725044

Epoch: 6| Step: 10
Training loss: 2.954679250717163
Validation loss: 2.175305874116959

Epoch: 6| Step: 11
Training loss: 2.2565903663635254
Validation loss: 2.1709360819990917

Epoch: 6| Step: 12
Training loss: 2.0256829261779785
Validation loss: 2.1079621532911896

Epoch: 6| Step: 13
Training loss: 3.080824613571167
Validation loss: 2.1477102682154667

Epoch: 184| Step: 0
Training loss: 1.3908650875091553
Validation loss: 2.1638084047584125

Epoch: 6| Step: 1
Training loss: 2.1651344299316406
Validation loss: 2.2213500725325717

Epoch: 6| Step: 2
Training loss: 2.5854244232177734
Validation loss: 2.1002919058645926

Epoch: 6| Step: 3
Training loss: 2.767639398574829
Validation loss: 2.2098692629926946

Epoch: 6| Step: 4
Training loss: 1.9397141933441162
Validation loss: 2.1137714244986094

Epoch: 6| Step: 5
Training loss: 1.6311674118041992
Validation loss: 2.1483534971872964

Epoch: 6| Step: 6
Training loss: 2.094428539276123
Validation loss: 2.231321391238961

Epoch: 6| Step: 7
Training loss: 2.0674543380737305
Validation loss: 2.0995358215865267

Epoch: 6| Step: 8
Training loss: 2.001704216003418
Validation loss: 2.122322584993096

Epoch: 6| Step: 9
Training loss: 2.179117202758789
Validation loss: 2.092843214670817

Epoch: 6| Step: 10
Training loss: 2.0840792655944824
Validation loss: 2.1528001805787444

Epoch: 6| Step: 11
Training loss: 2.327194929122925
Validation loss: 2.1801133066095333

Epoch: 6| Step: 12
Training loss: 2.511101484298706
Validation loss: 2.149204998887995

Epoch: 6| Step: 13
Training loss: 2.260531425476074
Validation loss: 2.1314746666980047

Epoch: 185| Step: 0
Training loss: 1.651438593864441
Validation loss: 2.1573525039098596

Epoch: 6| Step: 1
Training loss: 2.1515018939971924
Validation loss: 2.1760382331827635

Epoch: 6| Step: 2
Training loss: 2.497870922088623
Validation loss: 2.139969962899403

Epoch: 6| Step: 3
Training loss: 1.5349055528640747
Validation loss: 2.161331899704472

Epoch: 6| Step: 4
Training loss: 2.995195150375366
Validation loss: 2.1895092046389015

Epoch: 6| Step: 5
Training loss: 1.899735927581787
Validation loss: 2.134012229980961

Epoch: 6| Step: 6
Training loss: 1.6235125064849854
Validation loss: 2.1213581792769896

Epoch: 6| Step: 7
Training loss: 2.318800210952759
Validation loss: 2.126083352232492

Epoch: 6| Step: 8
Training loss: 1.2282174825668335
Validation loss: 2.136062750252344

Epoch: 6| Step: 9
Training loss: 1.5388293266296387
Validation loss: 2.2024017803130613

Epoch: 6| Step: 10
Training loss: 2.5641582012176514
Validation loss: 2.1639624090604883

Epoch: 6| Step: 11
Training loss: 2.735267162322998
Validation loss: 2.0986889331571517

Epoch: 6| Step: 12
Training loss: 2.862370014190674
Validation loss: 2.176939695112167

Epoch: 6| Step: 13
Training loss: 2.3605618476867676
Validation loss: 2.1130870696037047

Epoch: 186| Step: 0
Training loss: 1.8917081356048584
Validation loss: 2.0911797528625815

Epoch: 6| Step: 1
Training loss: 2.0186784267425537
Validation loss: 2.1971129012364212

Epoch: 6| Step: 2
Training loss: 2.246037006378174
Validation loss: 2.1247967545704176

Epoch: 6| Step: 3
Training loss: 2.420860767364502
Validation loss: 2.1421990368955877

Epoch: 6| Step: 4
Training loss: 2.0045299530029297
Validation loss: 2.1408326651460383

Epoch: 6| Step: 5
Training loss: 2.1336610317230225
Validation loss: 2.1150405688952376

Epoch: 6| Step: 6
Training loss: 2.2125465869903564
Validation loss: 2.1889695993033786

Epoch: 6| Step: 7
Training loss: 2.4286909103393555
Validation loss: 2.1429124160479476

Epoch: 6| Step: 8
Training loss: 1.6559425592422485
Validation loss: 2.155996358522805

Epoch: 6| Step: 9
Training loss: 1.5818123817443848
Validation loss: 2.122412327797182

Epoch: 6| Step: 10
Training loss: 2.1774299144744873
Validation loss: 2.1577356400028354

Epoch: 6| Step: 11
Training loss: 2.2654035091400146
Validation loss: 2.152197245628603

Epoch: 6| Step: 12
Training loss: 2.149942398071289
Validation loss: 2.0854993917608775

Epoch: 6| Step: 13
Training loss: 2.6418535709381104
Validation loss: 2.0619034664605254

Epoch: 187| Step: 0
Training loss: 1.9974355697631836
Validation loss: 2.1781462033589682

Epoch: 6| Step: 1
Training loss: 1.5837640762329102
Validation loss: 2.0737985167452084

Epoch: 6| Step: 2
Training loss: 2.197521924972534
Validation loss: 2.0890009146864696

Epoch: 6| Step: 3
Training loss: 2.3085951805114746
Validation loss: 2.0705026118986067

Epoch: 6| Step: 4
Training loss: 1.6807224750518799
Validation loss: 2.184879977216003

Epoch: 6| Step: 5
Training loss: 2.4251389503479004
Validation loss: 2.1499496442015453

Epoch: 6| Step: 6
Training loss: 2.0423378944396973
Validation loss: 2.1076902907381774

Epoch: 6| Step: 7
Training loss: 2.867945432662964
Validation loss: 2.138543164858254

Epoch: 6| Step: 8
Training loss: 2.421924591064453
Validation loss: 2.113506911903299

Epoch: 6| Step: 9
Training loss: 2.2295894622802734
Validation loss: 2.053117894357251

Epoch: 6| Step: 10
Training loss: 1.7756747007369995
Validation loss: 2.1623194781682824

Epoch: 6| Step: 11
Training loss: 1.5162990093231201
Validation loss: 2.1353337341739285

Epoch: 6| Step: 12
Training loss: 1.7153985500335693
Validation loss: 2.124857826899457

Epoch: 6| Step: 13
Training loss: 2.1784324645996094
Validation loss: 2.138596293746784

Epoch: 188| Step: 0
Training loss: 2.2909367084503174
Validation loss: 2.198681089185899

Epoch: 6| Step: 1
Training loss: 1.9667441844940186
Validation loss: 2.166988029274889

Epoch: 6| Step: 2
Training loss: 2.080202102661133
Validation loss: 2.1125258040684525

Epoch: 6| Step: 3
Training loss: 2.2325987815856934
Validation loss: 2.1768740197663665

Epoch: 6| Step: 4
Training loss: 2.290609836578369
Validation loss: 2.1688434308575046

Epoch: 6| Step: 5
Training loss: 1.8300046920776367
Validation loss: 2.110454205543764

Epoch: 6| Step: 6
Training loss: 1.9809942245483398
Validation loss: 2.1169832778233353

Epoch: 6| Step: 7
Training loss: 2.2049548625946045
Validation loss: 2.1931968248018654

Epoch: 6| Step: 8
Training loss: 2.8505640029907227
Validation loss: 2.134124514877155

Epoch: 6| Step: 9
Training loss: 1.8881077766418457
Validation loss: 2.0891076672461724

Epoch: 6| Step: 10
Training loss: 2.35752534866333
Validation loss: 2.160116426406368

Epoch: 6| Step: 11
Training loss: 2.1562976837158203
Validation loss: 2.247409894902219

Epoch: 6| Step: 12
Training loss: 1.7428945302963257
Validation loss: 2.143458422794137

Epoch: 6| Step: 13
Training loss: 1.6504974365234375
Validation loss: 2.226655388391146

Epoch: 189| Step: 0
Training loss: 2.6205952167510986
Validation loss: 2.1452572397006455

Epoch: 6| Step: 1
Training loss: 1.907472014427185
Validation loss: 2.1275905742440173

Epoch: 6| Step: 2
Training loss: 1.8042068481445312
Validation loss: 2.18641157304087

Epoch: 6| Step: 3
Training loss: 2.3951022624969482
Validation loss: 2.107903249802128

Epoch: 6| Step: 4
Training loss: 2.1840755939483643
Validation loss: 2.04244395994371

Epoch: 6| Step: 5
Training loss: 1.8005716800689697
Validation loss: 2.152003244687152

Epoch: 6| Step: 6
Training loss: 2.8316237926483154
Validation loss: 2.0894247306290494

Epoch: 6| Step: 7
Training loss: 1.093178391456604
Validation loss: 2.1567948736170286

Epoch: 6| Step: 8
Training loss: 2.0878329277038574
Validation loss: 2.164618918972631

Epoch: 6| Step: 9
Training loss: 2.0706048011779785
Validation loss: 2.1434958134928057

Epoch: 6| Step: 10
Training loss: 2.9861433506011963
Validation loss: 2.125625028405138

Epoch: 6| Step: 11
Training loss: 1.773085117340088
Validation loss: 2.127124829958844

Epoch: 6| Step: 12
Training loss: 2.0593183040618896
Validation loss: 2.1106216753682783

Epoch: 6| Step: 13
Training loss: 2.246249198913574
Validation loss: 2.1344748978973715

Epoch: 190| Step: 0
Training loss: 1.793304681777954
Validation loss: 2.1501812447783766

Epoch: 6| Step: 1
Training loss: 2.1291472911834717
Validation loss: 2.14210339771804

Epoch: 6| Step: 2
Training loss: 2.0359160900115967
Validation loss: 2.165272182033908

Epoch: 6| Step: 3
Training loss: 2.4597768783569336
Validation loss: 2.151624060446216

Epoch: 6| Step: 4
Training loss: 1.8736588954925537
Validation loss: 2.0729463356797413

Epoch: 6| Step: 5
Training loss: 2.186638355255127
Validation loss: 2.1738963665500766

Epoch: 6| Step: 6
Training loss: 1.7286099195480347
Validation loss: 2.0922786061481764

Epoch: 6| Step: 7
Training loss: 2.171276092529297
Validation loss: 2.1236034747092956

Epoch: 6| Step: 8
Training loss: 2.4019088745117188
Validation loss: 2.184379641727735

Epoch: 6| Step: 9
Training loss: 2.365525245666504
Validation loss: 2.2049098348104827

Epoch: 6| Step: 10
Training loss: 2.1467771530151367
Validation loss: 2.1497273124674314

Epoch: 6| Step: 11
Training loss: 2.8488008975982666
Validation loss: 2.1204125983740694

Epoch: 6| Step: 12
Training loss: 1.704935073852539
Validation loss: 2.149773123443768

Epoch: 6| Step: 13
Training loss: 2.0315332412719727
Validation loss: 2.1633453087140153

Epoch: 191| Step: 0
Training loss: 2.1808366775512695
Validation loss: 2.1955571072075957

Epoch: 6| Step: 1
Training loss: 1.9009429216384888
Validation loss: 2.232489360276089

Epoch: 6| Step: 2
Training loss: 1.766042709350586
Validation loss: 2.0913114675911526

Epoch: 6| Step: 3
Training loss: 1.7484774589538574
Validation loss: 2.1153070183210474

Epoch: 6| Step: 4
Training loss: 2.5155200958251953
Validation loss: 2.1937971320203555

Epoch: 6| Step: 5
Training loss: 2.8730483055114746
Validation loss: 2.110248347764374

Epoch: 6| Step: 6
Training loss: 2.0472986698150635
Validation loss: 2.082450246298185

Epoch: 6| Step: 7
Training loss: 1.7373840808868408
Validation loss: 2.158270792294574

Epoch: 6| Step: 8
Training loss: 2.12760066986084
Validation loss: 2.1125154418330037

Epoch: 6| Step: 9
Training loss: 2.0262045860290527
Validation loss: 2.1161584008124565

Epoch: 6| Step: 10
Training loss: 1.8321435451507568
Validation loss: 2.1757161950552337

Epoch: 6| Step: 11
Training loss: 2.7127463817596436
Validation loss: 2.1431585537490023

Epoch: 6| Step: 12
Training loss: 2.022703170776367
Validation loss: 2.1636700502005954

Epoch: 6| Step: 13
Training loss: 2.287125825881958
Validation loss: 2.1257694164911904

Epoch: 192| Step: 0
Training loss: 1.6044180393218994
Validation loss: 2.129068689961587

Epoch: 6| Step: 1
Training loss: 1.9445420503616333
Validation loss: 2.1668693096407

Epoch: 6| Step: 2
Training loss: 2.4899532794952393
Validation loss: 2.1148728247611754

Epoch: 6| Step: 3
Training loss: 2.31356143951416
Validation loss: 2.170250141492454

Epoch: 6| Step: 4
Training loss: 2.3235602378845215
Validation loss: 2.2057310663243777

Epoch: 6| Step: 5
Training loss: 2.532968521118164
Validation loss: 2.217053815882693

Epoch: 6| Step: 6
Training loss: 1.6464736461639404
Validation loss: 2.1964783860791113

Epoch: 6| Step: 7
Training loss: 2.3063912391662598
Validation loss: 2.2096902683217037

Epoch: 6| Step: 8
Training loss: 2.0512804985046387
Validation loss: 2.249009052912394

Epoch: 6| Step: 9
Training loss: 2.032508373260498
Validation loss: 2.1467239984902005

Epoch: 6| Step: 10
Training loss: 1.3723191022872925
Validation loss: 2.1167896614279798

Epoch: 6| Step: 11
Training loss: 2.2818596363067627
Validation loss: 2.180974006652832

Epoch: 6| Step: 12
Training loss: 2.73138427734375
Validation loss: 2.1202605591025403

Epoch: 6| Step: 13
Training loss: 2.161918878555298
Validation loss: 2.177295382304858

Epoch: 193| Step: 0
Training loss: 2.2663652896881104
Validation loss: 2.136100871588594

Epoch: 6| Step: 1
Training loss: 1.8479764461517334
Validation loss: 2.1671189390203005

Epoch: 6| Step: 2
Training loss: 2.2383837699890137
Validation loss: 2.112851926075515

Epoch: 6| Step: 3
Training loss: 2.350721597671509
Validation loss: 2.0855988071810816

Epoch: 6| Step: 4
Training loss: 2.2356107234954834
Validation loss: 2.154223249804589

Epoch: 6| Step: 5
Training loss: 2.3637399673461914
Validation loss: 2.0525919416899323

Epoch: 6| Step: 6
Training loss: 2.219040870666504
Validation loss: 2.1634859449119976

Epoch: 6| Step: 7
Training loss: 1.712947130203247
Validation loss: 2.1435340912111345

Epoch: 6| Step: 8
Training loss: 1.9312217235565186
Validation loss: 2.1078235718511764

Epoch: 6| Step: 9
Training loss: 1.5213258266448975
Validation loss: 2.1063448831599247

Epoch: 6| Step: 10
Training loss: 2.283535957336426
Validation loss: 2.172592237431516

Epoch: 6| Step: 11
Training loss: 2.6106202602386475
Validation loss: 2.102968362069899

Epoch: 6| Step: 12
Training loss: 1.8628244400024414
Validation loss: 2.117416856109455

Epoch: 6| Step: 13
Training loss: 2.1702051162719727
Validation loss: 2.134404915635304

Epoch: 194| Step: 0
Training loss: 1.4818696975708008
Validation loss: 2.0912048278316373

Epoch: 6| Step: 1
Training loss: 2.1106505393981934
Validation loss: 2.1784459801130396

Epoch: 6| Step: 2
Training loss: 3.0546364784240723
Validation loss: 2.1202272676652476

Epoch: 6| Step: 3
Training loss: 2.121246814727783
Validation loss: 2.1348625280523814

Epoch: 6| Step: 4
Training loss: 2.461082696914673
Validation loss: 2.150898923156082

Epoch: 6| Step: 5
Training loss: 1.3460195064544678
Validation loss: 2.0844179276497132

Epoch: 6| Step: 6
Training loss: 1.9176652431488037
Validation loss: 2.1677656994071057

Epoch: 6| Step: 7
Training loss: 1.5210037231445312
Validation loss: 2.185974935049652

Epoch: 6| Step: 8
Training loss: 2.6882333755493164
Validation loss: 2.188072237917172

Epoch: 6| Step: 9
Training loss: 2.3806467056274414
Validation loss: 2.0697171277897333

Epoch: 6| Step: 10
Training loss: 2.1432390213012695
Validation loss: 2.1336619777064167

Epoch: 6| Step: 11
Training loss: 1.8498846292495728
Validation loss: 2.104261193224179

Epoch: 6| Step: 12
Training loss: 2.8794302940368652
Validation loss: 2.1664605755959787

Epoch: 6| Step: 13
Training loss: 1.9958343505859375
Validation loss: 2.1864152416106193

Epoch: 195| Step: 0
Training loss: 1.6998624801635742
Validation loss: 2.143940330833517

Epoch: 6| Step: 1
Training loss: 1.884346604347229
Validation loss: 2.2675163412606842

Epoch: 6| Step: 2
Training loss: 1.798569679260254
Validation loss: 2.18491042301219

Epoch: 6| Step: 3
Training loss: 2.5264639854431152
Validation loss: 2.1776397535877843

Epoch: 6| Step: 4
Training loss: 2.2900614738464355
Validation loss: 2.15320344637799

Epoch: 6| Step: 5
Training loss: 2.279611349105835
Validation loss: 2.129378141895417

Epoch: 6| Step: 6
Training loss: 1.9672483205795288
Validation loss: 2.1718752794368292

Epoch: 6| Step: 7
Training loss: 1.8700180053710938
Validation loss: 2.1807188398094586

Epoch: 6| Step: 8
Training loss: 1.7784762382507324
Validation loss: 2.122980849717253

Epoch: 6| Step: 9
Training loss: 1.6818650960922241
Validation loss: 2.143611579812983

Epoch: 6| Step: 10
Training loss: 2.663172721862793
Validation loss: 2.047671748745826

Epoch: 6| Step: 11
Training loss: 2.3163533210754395
Validation loss: 2.1078783465969946

Epoch: 6| Step: 12
Training loss: 2.8985979557037354
Validation loss: 2.155743537410613

Epoch: 6| Step: 13
Training loss: 1.735285997390747
Validation loss: 2.1561906568465696

Epoch: 196| Step: 0
Training loss: 3.0617055892944336
Validation loss: 2.085581269315494

Epoch: 6| Step: 1
Training loss: 1.9339735507965088
Validation loss: 2.1666361337066977

Epoch: 6| Step: 2
Training loss: 2.1240410804748535
Validation loss: 2.0920726432595202

Epoch: 6| Step: 3
Training loss: 1.4491441249847412
Validation loss: 2.1644100425063924

Epoch: 6| Step: 4
Training loss: 1.7996532917022705
Validation loss: 2.1035388669660016

Epoch: 6| Step: 5
Training loss: 2.576010227203369
Validation loss: 2.1354930990485737

Epoch: 6| Step: 6
Training loss: 2.5717175006866455
Validation loss: 2.1286626964487056

Epoch: 6| Step: 7
Training loss: 2.150503158569336
Validation loss: 2.0674977994734243

Epoch: 6| Step: 8
Training loss: 2.0797693729400635
Validation loss: 2.091284037918173

Epoch: 6| Step: 9
Training loss: 1.7852909564971924
Validation loss: 2.121327671953427

Epoch: 6| Step: 10
Training loss: 1.809321641921997
Validation loss: 2.068742284210779

Epoch: 6| Step: 11
Training loss: 1.8297138214111328
Validation loss: 2.130015883394467

Epoch: 6| Step: 12
Training loss: 2.603684902191162
Validation loss: 2.141754981010191

Epoch: 6| Step: 13
Training loss: 2.1932013034820557
Validation loss: 2.1709301753710677

Epoch: 197| Step: 0
Training loss: 1.9319485425949097
Validation loss: 2.1049012163633942

Epoch: 6| Step: 1
Training loss: 2.1472854614257812
Validation loss: 2.1816398200168403

Epoch: 6| Step: 2
Training loss: 2.0333662033081055
Validation loss: 2.2240879125492548

Epoch: 6| Step: 3
Training loss: 1.9764118194580078
Validation loss: 2.1195942612104517

Epoch: 6| Step: 4
Training loss: 1.668269395828247
Validation loss: 2.152295115173504

Epoch: 6| Step: 5
Training loss: 2.0003042221069336
Validation loss: 2.2479330442285024

Epoch: 6| Step: 6
Training loss: 1.8558545112609863
Validation loss: 2.1274744105595413

Epoch: 6| Step: 7
Training loss: 2.5595788955688477
Validation loss: 2.244157765501289

Epoch: 6| Step: 8
Training loss: 2.002580165863037
Validation loss: 2.166961439194218

Epoch: 6| Step: 9
Training loss: 2.162949800491333
Validation loss: 2.1853582371947584

Epoch: 6| Step: 10
Training loss: 2.7873189449310303
Validation loss: 2.1865417060031684

Epoch: 6| Step: 11
Training loss: 2.4059340953826904
Validation loss: 2.1488539659848778

Epoch: 6| Step: 12
Training loss: 1.6092023849487305
Validation loss: 2.171958592630202

Epoch: 6| Step: 13
Training loss: 1.9934533834457397
Validation loss: 2.2296266401967695

Epoch: 198| Step: 0
Training loss: 1.9856914281845093
Validation loss: 2.152576764424642

Epoch: 6| Step: 1
Training loss: 1.4750356674194336
Validation loss: 2.1149343085545365

Epoch: 6| Step: 2
Training loss: 2.2032809257507324
Validation loss: 2.15832386350119

Epoch: 6| Step: 3
Training loss: 2.617469072341919
Validation loss: 2.1081298525615404

Epoch: 6| Step: 4
Training loss: 2.158061981201172
Validation loss: 2.1360322429287817

Epoch: 6| Step: 5
Training loss: 1.8302944898605347
Validation loss: 2.042698320522103

Epoch: 6| Step: 6
Training loss: 1.77458918094635
Validation loss: 2.1661505929885374

Epoch: 6| Step: 7
Training loss: 2.424266815185547
Validation loss: 2.0920192900524346

Epoch: 6| Step: 8
Training loss: 2.415212392807007
Validation loss: 2.16395051504976

Epoch: 6| Step: 9
Training loss: 2.4877638816833496
Validation loss: 2.1713215766414518

Epoch: 6| Step: 10
Training loss: 1.4755518436431885
Validation loss: 2.2028739324180027

Epoch: 6| Step: 11
Training loss: 1.6720685958862305
Validation loss: 2.202164529472269

Epoch: 6| Step: 12
Training loss: 2.3388924598693848
Validation loss: 2.1443195266108357

Epoch: 6| Step: 13
Training loss: 1.6716853380203247
Validation loss: 2.0651599617414576

Epoch: 199| Step: 0
Training loss: 1.8307846784591675
Validation loss: 2.1417903054145073

Epoch: 6| Step: 1
Training loss: 2.491755247116089
Validation loss: 2.139438026694841

Epoch: 6| Step: 2
Training loss: 1.7059173583984375
Validation loss: 2.1116317702877905

Epoch: 6| Step: 3
Training loss: 2.0558786392211914
Validation loss: 2.0880256955341627

Epoch: 6| Step: 4
Training loss: 2.262057304382324
Validation loss: 2.1608958949324903

Epoch: 6| Step: 5
Training loss: 1.9749908447265625
Validation loss: 2.1269431498742875

Epoch: 6| Step: 6
Training loss: 2.723517656326294
Validation loss: 2.1023350505418676

Epoch: 6| Step: 7
Training loss: 2.145819664001465
Validation loss: 2.1684079721409786

Epoch: 6| Step: 8
Training loss: 1.826961874961853
Validation loss: 2.1962687533388854

Epoch: 6| Step: 9
Training loss: 1.4269901514053345
Validation loss: 2.1696068138204594

Epoch: 6| Step: 10
Training loss: 2.291236162185669
Validation loss: 2.138445938787153

Epoch: 6| Step: 11
Training loss: 2.0625481605529785
Validation loss: 2.134159068907461

Epoch: 6| Step: 12
Training loss: 2.729736089706421
Validation loss: 2.1573937144330753

Epoch: 6| Step: 13
Training loss: 1.7849990129470825
Validation loss: 2.1485963790647444

Epoch: 200| Step: 0
Training loss: 2.409986972808838
Validation loss: 2.104467302240351

Epoch: 6| Step: 1
Training loss: 2.071091890335083
Validation loss: 2.154793229154361

Epoch: 6| Step: 2
Training loss: 2.315549850463867
Validation loss: 2.1441608859646704

Epoch: 6| Step: 3
Training loss: 2.107494354248047
Validation loss: 2.2028036617463633

Epoch: 6| Step: 4
Training loss: 2.3488388061523438
Validation loss: 2.1556658411538727

Epoch: 6| Step: 5
Training loss: 2.1736693382263184
Validation loss: 2.124788511183954

Epoch: 6| Step: 6
Training loss: 2.2385950088500977
Validation loss: 2.1085959544745823

Epoch: 6| Step: 7
Training loss: 1.821804404258728
Validation loss: 2.1679111296130764

Epoch: 6| Step: 8
Training loss: 1.6814204454421997
Validation loss: 2.1032983872198288

Epoch: 6| Step: 9
Training loss: 1.849979043006897
Validation loss: 2.147050779352906

Epoch: 6| Step: 10
Training loss: 2.4461636543273926
Validation loss: 2.1439173426679385

Epoch: 6| Step: 11
Training loss: 1.9862815141677856
Validation loss: 2.1456233301470355

Epoch: 6| Step: 12
Training loss: 1.5378968715667725
Validation loss: 2.076302597599645

Epoch: 6| Step: 13
Training loss: 2.041141986846924
Validation loss: 2.0732426617735173

Epoch: 201| Step: 0
Training loss: 2.0740652084350586
Validation loss: 2.155632806080644

Epoch: 6| Step: 1
Training loss: 2.520810127258301
Validation loss: 2.142247933213429

Epoch: 6| Step: 2
Training loss: 1.9720234870910645
Validation loss: 2.1061747433036886

Epoch: 6| Step: 3
Training loss: 1.9317972660064697
Validation loss: 2.0946756050150883

Epoch: 6| Step: 4
Training loss: 2.1296520233154297
Validation loss: 2.1346478128945954

Epoch: 6| Step: 5
Training loss: 1.5571587085723877
Validation loss: 2.1128090376495035

Epoch: 6| Step: 6
Training loss: 1.939168930053711
Validation loss: 2.1320369833259174

Epoch: 6| Step: 7
Training loss: 2.3377883434295654
Validation loss: 2.187224413758965

Epoch: 6| Step: 8
Training loss: 1.7968921661376953
Validation loss: 2.1900530707451606

Epoch: 6| Step: 9
Training loss: 1.952068567276001
Validation loss: 2.0372640189304145

Epoch: 6| Step: 10
Training loss: 2.2239837646484375
Validation loss: 2.2099204165961153

Epoch: 6| Step: 11
Training loss: 1.6809055805206299
Validation loss: 2.0979419344214985

Epoch: 6| Step: 12
Training loss: 2.350184440612793
Validation loss: 2.07065148122849

Epoch: 6| Step: 13
Training loss: 2.4539577960968018
Validation loss: 2.1357589588370374

Epoch: 202| Step: 0
Training loss: 1.3785966634750366
Validation loss: 2.1686721476175452

Epoch: 6| Step: 1
Training loss: 2.7059149742126465
Validation loss: 2.1432785987854004

Epoch: 6| Step: 2
Training loss: 2.5492990016937256
Validation loss: 2.0662367574630247

Epoch: 6| Step: 3
Training loss: 2.0040175914764404
Validation loss: 2.1300606445599626

Epoch: 6| Step: 4
Training loss: 2.1269819736480713
Validation loss: 2.206520688149237

Epoch: 6| Step: 5
Training loss: 2.059879779815674
Validation loss: 2.0594471423856673

Epoch: 6| Step: 6
Training loss: 1.9522181749343872
Validation loss: 2.191616365986486

Epoch: 6| Step: 7
Training loss: 1.3690197467803955
Validation loss: 2.1049287985729914

Epoch: 6| Step: 8
Training loss: 2.05010986328125
Validation loss: 2.0900755569499028

Epoch: 6| Step: 9
Training loss: 1.4442304372787476
Validation loss: 2.168089682056058

Epoch: 6| Step: 10
Training loss: 2.3721675872802734
Validation loss: 2.160979906717936

Epoch: 6| Step: 11
Training loss: 1.8606617450714111
Validation loss: 2.093752919986684

Epoch: 6| Step: 12
Training loss: 2.8135433197021484
Validation loss: 2.023447036743164

Epoch: 6| Step: 13
Training loss: 2.249340295791626
Validation loss: 2.1460281020851544

Epoch: 203| Step: 0
Training loss: 2.319423198699951
Validation loss: 2.087807301552065

Epoch: 6| Step: 1
Training loss: 1.8211003541946411
Validation loss: 2.1200069919709237

Epoch: 6| Step: 2
Training loss: 2.6234354972839355
Validation loss: 2.084833747597151

Epoch: 6| Step: 3
Training loss: 2.2473249435424805
Validation loss: 2.1432605174279984

Epoch: 6| Step: 4
Training loss: 2.0866756439208984
Validation loss: 2.1947016100729666

Epoch: 6| Step: 5
Training loss: 2.4157490730285645
Validation loss: 2.14929719637799

Epoch: 6| Step: 6
Training loss: 2.8391151428222656
Validation loss: 2.1308781062403033

Epoch: 6| Step: 7
Training loss: 1.8765907287597656
Validation loss: 2.1625100540858444

Epoch: 6| Step: 8
Training loss: 1.9656857252120972
Validation loss: 2.176803071011779

Epoch: 6| Step: 9
Training loss: 1.731210470199585
Validation loss: 2.2194396949583486

Epoch: 6| Step: 10
Training loss: 1.7160885334014893
Validation loss: 2.158793698074997

Epoch: 6| Step: 11
Training loss: 1.5459564924240112
Validation loss: 2.1739271738195933

Epoch: 6| Step: 12
Training loss: 2.0116803646087646
Validation loss: 2.2091975955552954

Epoch: 6| Step: 13
Training loss: 2.335498332977295
Validation loss: 2.1090492048571186

Epoch: 204| Step: 0
Training loss: 2.195250988006592
Validation loss: 2.1127755911119523

Epoch: 6| Step: 1
Training loss: 2.487117290496826
Validation loss: 2.220866121271605

Epoch: 6| Step: 2
Training loss: 1.8691747188568115
Validation loss: 2.1547228931098856

Epoch: 6| Step: 3
Training loss: 1.872337818145752
Validation loss: 2.104773872642107

Epoch: 6| Step: 4
Training loss: 2.748220920562744
Validation loss: 2.1170116932161394

Epoch: 6| Step: 5
Training loss: 1.7709524631500244
Validation loss: 2.1146236004367953

Epoch: 6| Step: 6
Training loss: 2.758090019226074
Validation loss: 2.0961199447672856

Epoch: 6| Step: 7
Training loss: 1.8644628524780273
Validation loss: 2.1434388596524476

Epoch: 6| Step: 8
Training loss: 2.1467080116271973
Validation loss: 2.0955446368904522

Epoch: 6| Step: 9
Training loss: 1.763260006904602
Validation loss: 2.152393810210689

Epoch: 6| Step: 10
Training loss: 1.9419993162155151
Validation loss: 2.1207598575981716

Epoch: 6| Step: 11
Training loss: 1.6005167961120605
Validation loss: 2.079368286235358

Epoch: 6| Step: 12
Training loss: 2.1676931381225586
Validation loss: 2.153410227068009

Epoch: 6| Step: 13
Training loss: 1.8864167928695679
Validation loss: 2.1358093010481967

Epoch: 205| Step: 0
Training loss: 2.4633777141571045
Validation loss: 2.135953982671102

Epoch: 6| Step: 1
Training loss: 2.0963592529296875
Validation loss: 2.156956475268128

Epoch: 6| Step: 2
Training loss: 2.3915913105010986
Validation loss: 2.191966446497107

Epoch: 6| Step: 3
Training loss: 2.2071239948272705
Validation loss: 2.137402508848457

Epoch: 6| Step: 4
Training loss: 2.1842193603515625
Validation loss: 2.140264934109103

Epoch: 6| Step: 5
Training loss: 1.8616091012954712
Validation loss: 2.1187009555037304

Epoch: 6| Step: 6
Training loss: 1.7267305850982666
Validation loss: 2.0740378261894308

Epoch: 6| Step: 7
Training loss: 3.3187456130981445
Validation loss: 2.1821664097488567

Epoch: 6| Step: 8
Training loss: 1.6061973571777344
Validation loss: 2.1917729147018923

Epoch: 6| Step: 9
Training loss: 1.4792791604995728
Validation loss: 2.1532908255054104

Epoch: 6| Step: 10
Training loss: 3.1140875816345215
Validation loss: 2.1495517864022204

Epoch: 6| Step: 11
Training loss: 1.3445055484771729
Validation loss: 2.135500333642447

Epoch: 6| Step: 12
Training loss: 1.7417094707489014
Validation loss: 2.14266445303476

Epoch: 6| Step: 13
Training loss: 2.4483821392059326
Validation loss: 2.179589315127301

Epoch: 206| Step: 0
Training loss: 1.9044064283370972
Validation loss: 2.1270179299898047

Epoch: 6| Step: 1
Training loss: 1.4998756647109985
Validation loss: 2.1420454402123728

Epoch: 6| Step: 2
Training loss: 2.390676975250244
Validation loss: 2.170500792482848

Epoch: 6| Step: 3
Training loss: 1.9505889415740967
Validation loss: 2.1937413856547368

Epoch: 6| Step: 4
Training loss: 2.572497844696045
Validation loss: 2.067018726820587

Epoch: 6| Step: 5
Training loss: 1.3978302478790283
Validation loss: 2.1204663489454534

Epoch: 6| Step: 6
Training loss: 2.3618788719177246
Validation loss: 2.219872020906018

Epoch: 6| Step: 7
Training loss: 2.3410894870758057
Validation loss: 2.1452805329394597

Epoch: 6| Step: 8
Training loss: 1.6762112379074097
Validation loss: 2.169013111822067

Epoch: 6| Step: 9
Training loss: 2.9615471363067627
Validation loss: 2.226347308005056

Epoch: 6| Step: 10
Training loss: 1.819434404373169
Validation loss: 2.0764201456500637

Epoch: 6| Step: 11
Training loss: 1.6266956329345703
Validation loss: 2.134073939374698

Epoch: 6| Step: 12
Training loss: 1.9069573879241943
Validation loss: 2.08101749420166

Epoch: 6| Step: 13
Training loss: 2.5441806316375732
Validation loss: 2.1321364320734495

Epoch: 207| Step: 0
Training loss: 2.2373766899108887
Validation loss: 2.1945729768404396

Epoch: 6| Step: 1
Training loss: 2.220442295074463
Validation loss: 2.2003388071572907

Epoch: 6| Step: 2
Training loss: 2.124828338623047
Validation loss: 2.1090743208444245

Epoch: 6| Step: 3
Training loss: 1.7180694341659546
Validation loss: 2.1128459181836856

Epoch: 6| Step: 4
Training loss: 2.906623125076294
Validation loss: 2.05859834788948

Epoch: 6| Step: 5
Training loss: 2.0667290687561035
Validation loss: 2.154486520316011

Epoch: 6| Step: 6
Training loss: 2.162357807159424
Validation loss: 2.1526492385454077

Epoch: 6| Step: 7
Training loss: 2.1345863342285156
Validation loss: 2.14912575034685

Epoch: 6| Step: 8
Training loss: 1.9810881614685059
Validation loss: 2.1881947209758144

Epoch: 6| Step: 9
Training loss: 2.404771327972412
Validation loss: 2.0416449603214057

Epoch: 6| Step: 10
Training loss: 1.7537503242492676
Validation loss: 2.1436833720053396

Epoch: 6| Step: 11
Training loss: 1.9290826320648193
Validation loss: 2.118855402033816

Epoch: 6| Step: 12
Training loss: 2.144756317138672
Validation loss: 2.101840862663843

Epoch: 6| Step: 13
Training loss: 1.7473455667495728
Validation loss: 2.165535544836393

Epoch: 208| Step: 0
Training loss: 1.9934303760528564
Validation loss: 2.1215951801628194

Epoch: 6| Step: 1
Training loss: 2.05976939201355
Validation loss: 2.097521928048903

Epoch: 6| Step: 2
Training loss: 2.8033533096313477
Validation loss: 2.155629047783472

Epoch: 6| Step: 3
Training loss: 1.9611601829528809
Validation loss: 2.144544409167382

Epoch: 6| Step: 4
Training loss: 2.1736862659454346
Validation loss: 2.1296724657858572

Epoch: 6| Step: 5
Training loss: 2.2294111251831055
Validation loss: 2.127379894256592

Epoch: 6| Step: 6
Training loss: 3.0919394493103027
Validation loss: 2.116180485294711

Epoch: 6| Step: 7
Training loss: 1.6053175926208496
Validation loss: 2.095812051526962

Epoch: 6| Step: 8
Training loss: 2.2211709022521973
Validation loss: 2.184574532252486

Epoch: 6| Step: 9
Training loss: 2.096281051635742
Validation loss: 2.171231782564553

Epoch: 6| Step: 10
Training loss: 1.7366371154785156
Validation loss: 2.19197174297866

Epoch: 6| Step: 11
Training loss: 1.405064344406128
Validation loss: 2.0996334104127783

Epoch: 6| Step: 12
Training loss: 2.0242538452148438
Validation loss: 2.1055683371841267

Epoch: 6| Step: 13
Training loss: 1.7271108627319336
Validation loss: 2.153295409294867

Epoch: 209| Step: 0
Training loss: 2.7179386615753174
Validation loss: 2.161951052245273

Epoch: 6| Step: 1
Training loss: 2.686713218688965
Validation loss: 2.2186174418336604

Epoch: 6| Step: 2
Training loss: 2.3785367012023926
Validation loss: 2.181839548131471

Epoch: 6| Step: 3
Training loss: 1.6083122491836548
Validation loss: 2.087387574616299

Epoch: 6| Step: 4
Training loss: 1.790274977684021
Validation loss: 2.1279477432209957

Epoch: 6| Step: 5
Training loss: 1.8695701360702515
Validation loss: 2.190519461067774

Epoch: 6| Step: 6
Training loss: 2.4054651260375977
Validation loss: 2.137652317682902

Epoch: 6| Step: 7
Training loss: 2.2415122985839844
Validation loss: 2.1320746701250792

Epoch: 6| Step: 8
Training loss: 1.3979665040969849
Validation loss: 2.1210832365097536

Epoch: 6| Step: 9
Training loss: 2.0033695697784424
Validation loss: 2.1535320563982894

Epoch: 6| Step: 10
Training loss: 2.357091188430786
Validation loss: 2.0507026654417797

Epoch: 6| Step: 11
Training loss: 1.885881781578064
Validation loss: 2.055462867982926

Epoch: 6| Step: 12
Training loss: 2.0346481800079346
Validation loss: 2.1707946279997468

Epoch: 6| Step: 13
Training loss: 1.4979984760284424
Validation loss: 2.0747454576594855

Epoch: 210| Step: 0
Training loss: 1.896798849105835
Validation loss: 2.176451954790341

Epoch: 6| Step: 1
Training loss: 1.901465892791748
Validation loss: 2.073703060867966

Epoch: 6| Step: 2
Training loss: 2.168665885925293
Validation loss: 2.1253496498189945

Epoch: 6| Step: 3
Training loss: 2.01694393157959
Validation loss: 2.197122889180337

Epoch: 6| Step: 4
Training loss: 1.7547597885131836
Validation loss: 2.1714183809936687

Epoch: 6| Step: 5
Training loss: 1.4793305397033691
Validation loss: 2.104073175819971

Epoch: 6| Step: 6
Training loss: 2.3591628074645996
Validation loss: 2.1670795999547487

Epoch: 6| Step: 7
Training loss: 2.5971550941467285
Validation loss: 2.16055025592927

Epoch: 6| Step: 8
Training loss: 2.2811012268066406
Validation loss: 2.2017231525913363

Epoch: 6| Step: 9
Training loss: 1.8732457160949707
Validation loss: 2.171742667434036

Epoch: 6| Step: 10
Training loss: 1.4728877544403076
Validation loss: 2.1876153151194253

Epoch: 6| Step: 11
Training loss: 2.315459728240967
Validation loss: 2.1889060851066344

Epoch: 6| Step: 12
Training loss: 2.482356071472168
Validation loss: 2.1258094490215345

Epoch: 6| Step: 13
Training loss: 2.4763526916503906
Validation loss: 2.1766188939412436

Epoch: 211| Step: 0
Training loss: 2.33245849609375
Validation loss: 2.1771372313140542

Epoch: 6| Step: 1
Training loss: 2.2068889141082764
Validation loss: 2.2145045162529073

Epoch: 6| Step: 2
Training loss: 2.0846354961395264
Validation loss: 2.1593683381234445

Epoch: 6| Step: 3
Training loss: 1.386638879776001
Validation loss: 2.197203383650831

Epoch: 6| Step: 4
Training loss: 1.6138865947723389
Validation loss: 2.132578460119104

Epoch: 6| Step: 5
Training loss: 2.064053535461426
Validation loss: 2.156230139475997

Epoch: 6| Step: 6
Training loss: 1.7304320335388184
Validation loss: 2.1287713666116037

Epoch: 6| Step: 7
Training loss: 2.1542816162109375
Validation loss: 2.249858481909639

Epoch: 6| Step: 8
Training loss: 2.84318470954895
Validation loss: 2.165700935548352

Epoch: 6| Step: 9
Training loss: 1.7963746786117554
Validation loss: 2.170406990153815

Epoch: 6| Step: 10
Training loss: 2.293876886367798
Validation loss: 2.1582749530833256

Epoch: 6| Step: 11
Training loss: 2.189035654067993
Validation loss: 2.0726615728870517

Epoch: 6| Step: 12
Training loss: 1.7383222579956055
Validation loss: 2.104458870426301

Epoch: 6| Step: 13
Training loss: 1.734126329421997
Validation loss: 2.109656799224115

Epoch: 212| Step: 0
Training loss: 1.9254710674285889
Validation loss: 2.1001671373203235

Epoch: 6| Step: 1
Training loss: 1.7197989225387573
Validation loss: 2.2094537314548286

Epoch: 6| Step: 2
Training loss: 1.2281005382537842
Validation loss: 2.117489307157455

Epoch: 6| Step: 3
Training loss: 2.3696401119232178
Validation loss: 2.1480531769414104

Epoch: 6| Step: 4
Training loss: 2.278120994567871
Validation loss: 2.183556910484068

Epoch: 6| Step: 5
Training loss: 1.8484759330749512
Validation loss: 2.0567333454726846

Epoch: 6| Step: 6
Training loss: 2.3997275829315186
Validation loss: 2.122593836117816

Epoch: 6| Step: 7
Training loss: 2.7820241451263428
Validation loss: 2.0678878779052408

Epoch: 6| Step: 8
Training loss: 2.3618221282958984
Validation loss: 2.1408424454350627

Epoch: 6| Step: 9
Training loss: 1.4894931316375732
Validation loss: 2.131843134921084

Epoch: 6| Step: 10
Training loss: 2.690256357192993
Validation loss: 2.1042025717355872

Epoch: 6| Step: 11
Training loss: 1.7455240488052368
Validation loss: 2.1464313896753455

Epoch: 6| Step: 12
Training loss: 2.367579460144043
Validation loss: 2.1550362212683565

Epoch: 6| Step: 13
Training loss: 2.1199944019317627
Validation loss: 2.1573061661053727

Epoch: 213| Step: 0
Training loss: 1.7517226934432983
Validation loss: 2.0839242294270504

Epoch: 6| Step: 1
Training loss: 1.9319781064987183
Validation loss: 2.1544229663828367

Epoch: 6| Step: 2
Training loss: 2.132528781890869
Validation loss: 2.0793535196652977

Epoch: 6| Step: 3
Training loss: 2.7481184005737305
Validation loss: 2.112231754487561

Epoch: 6| Step: 4
Training loss: 1.9677098989486694
Validation loss: 2.076905649195435

Epoch: 6| Step: 5
Training loss: 2.3677656650543213
Validation loss: 2.0882261876137025

Epoch: 6| Step: 6
Training loss: 1.6893349885940552
Validation loss: 2.1206114907418527

Epoch: 6| Step: 7
Training loss: 1.3120825290679932
Validation loss: 2.1446556609164

Epoch: 6| Step: 8
Training loss: 2.290586233139038
Validation loss: 2.148638786808137

Epoch: 6| Step: 9
Training loss: 2.2699639797210693
Validation loss: 2.148060872990598

Epoch: 6| Step: 10
Training loss: 1.8120145797729492
Validation loss: 2.179465563066544

Epoch: 6| Step: 11
Training loss: 2.6089954376220703
Validation loss: 2.1215161315856443

Epoch: 6| Step: 12
Training loss: 2.4118142127990723
Validation loss: 2.166352048996956

Epoch: 6| Step: 13
Training loss: 1.991068959236145
Validation loss: 2.18471428912173

Epoch: 214| Step: 0
Training loss: 1.3744665384292603
Validation loss: 2.0004036362453173

Epoch: 6| Step: 1
Training loss: 1.6413066387176514
Validation loss: 2.101470285846341

Epoch: 6| Step: 2
Training loss: 2.607607841491699
Validation loss: 2.2230837896306026

Epoch: 6| Step: 3
Training loss: 1.3867347240447998
Validation loss: 2.168260584595383

Epoch: 6| Step: 4
Training loss: 1.9015421867370605
Validation loss: 2.1620108055812057

Epoch: 6| Step: 5
Training loss: 2.2732338905334473
Validation loss: 2.2038278989894415

Epoch: 6| Step: 6
Training loss: 2.6987345218658447
Validation loss: 2.121786094480945

Epoch: 6| Step: 7
Training loss: 2.3209521770477295
Validation loss: 2.1582339143240326

Epoch: 6| Step: 8
Training loss: 2.087721824645996
Validation loss: 2.199062132066296

Epoch: 6| Step: 9
Training loss: 2.3000316619873047
Validation loss: 2.1595743010121007

Epoch: 6| Step: 10
Training loss: 2.0241470336914062
Validation loss: 2.15010925005841

Epoch: 6| Step: 11
Training loss: 2.3349015712738037
Validation loss: 2.112364463908698

Epoch: 6| Step: 12
Training loss: 1.9365860223770142
Validation loss: 2.068549891953827

Epoch: 6| Step: 13
Training loss: 2.022336483001709
Validation loss: 2.1772562688396824

Epoch: 215| Step: 0
Training loss: 1.6328612565994263
Validation loss: 2.137852309852518

Epoch: 6| Step: 1
Training loss: 2.081434965133667
Validation loss: 2.139126621266847

Epoch: 6| Step: 2
Training loss: 2.0351552963256836
Validation loss: 2.104918287646386

Epoch: 6| Step: 3
Training loss: 2.0663928985595703
Validation loss: 2.18521346071715

Epoch: 6| Step: 4
Training loss: 2.6457207202911377
Validation loss: 2.183820178431849

Epoch: 6| Step: 5
Training loss: 2.006744861602783
Validation loss: 2.0674629313971407

Epoch: 6| Step: 6
Training loss: 1.5360311269760132
Validation loss: 2.185879374063143

Epoch: 6| Step: 7
Training loss: 1.8023967742919922
Validation loss: 2.140091952457223

Epoch: 6| Step: 8
Training loss: 2.696572780609131
Validation loss: 2.24546568880799

Epoch: 6| Step: 9
Training loss: 1.6963419914245605
Validation loss: 2.12721275642354

Epoch: 6| Step: 10
Training loss: 1.920455813407898
Validation loss: 2.118339818011048

Epoch: 6| Step: 11
Training loss: 1.6906768083572388
Validation loss: 2.1568450927734375

Epoch: 6| Step: 12
Training loss: 2.4648165702819824
Validation loss: 2.1433598251752954

Epoch: 6| Step: 13
Training loss: 2.4062345027923584
Validation loss: 2.1509094956100627

Epoch: 216| Step: 0
Training loss: 1.4636645317077637
Validation loss: 2.0521950542285876

Epoch: 6| Step: 1
Training loss: 2.217118501663208
Validation loss: 2.078995768741895

Epoch: 6| Step: 2
Training loss: 2.4652516841888428
Validation loss: 2.1031082355847923

Epoch: 6| Step: 3
Training loss: 2.22995924949646
Validation loss: 2.1786474784215293

Epoch: 6| Step: 4
Training loss: 1.1772717237472534
Validation loss: 2.1115312076384023

Epoch: 6| Step: 5
Training loss: 2.229982376098633
Validation loss: 2.12309278211286

Epoch: 6| Step: 6
Training loss: 2.105492353439331
Validation loss: 2.0883499755654285

Epoch: 6| Step: 7
Training loss: 3.0718164443969727
Validation loss: 2.136890951023307

Epoch: 6| Step: 8
Training loss: 1.612813949584961
Validation loss: 2.2559596261670514

Epoch: 6| Step: 9
Training loss: 2.1086854934692383
Validation loss: 2.1443743808295137

Epoch: 6| Step: 10
Training loss: 2.4885032176971436
Validation loss: 2.192540616117498

Epoch: 6| Step: 11
Training loss: 2.6508021354675293
Validation loss: 2.143644097030804

Epoch: 6| Step: 12
Training loss: 2.0189034938812256
Validation loss: 2.18982219952409

Epoch: 6| Step: 13
Training loss: 1.4807274341583252
Validation loss: 2.1203684858096543

Epoch: 217| Step: 0
Training loss: 1.9255211353302002
Validation loss: 2.1598307009666198

Epoch: 6| Step: 1
Training loss: 3.255352258682251
Validation loss: 2.1577560542732157

Epoch: 6| Step: 2
Training loss: 1.8528861999511719
Validation loss: 2.2338363239842076

Epoch: 6| Step: 3
Training loss: 2.2859222888946533
Validation loss: 2.182388259518531

Epoch: 6| Step: 4
Training loss: 2.377490282058716
Validation loss: 2.193628582903134

Epoch: 6| Step: 5
Training loss: 1.1633150577545166
Validation loss: 2.1575149618169314

Epoch: 6| Step: 6
Training loss: 1.8939374685287476
Validation loss: 2.1290056308110556

Epoch: 6| Step: 7
Training loss: 1.858222246170044
Validation loss: 2.20572058744328

Epoch: 6| Step: 8
Training loss: 2.808595657348633
Validation loss: 2.124510326693135

Epoch: 6| Step: 9
Training loss: 2.2182774543762207
Validation loss: 2.1144603349829234

Epoch: 6| Step: 10
Training loss: 2.4814329147338867
Validation loss: 2.0569788281635573

Epoch: 6| Step: 11
Training loss: 1.364044427871704
Validation loss: 2.0637037702786025

Epoch: 6| Step: 12
Training loss: 1.5923106670379639
Validation loss: 2.2018616391766455

Epoch: 6| Step: 13
Training loss: 1.8445042371749878
Validation loss: 2.0932730551688903

Epoch: 218| Step: 0
Training loss: 2.2121241092681885
Validation loss: 2.131932727752193

Epoch: 6| Step: 1
Training loss: 1.5579700469970703
Validation loss: 2.1079123148354153

Epoch: 6| Step: 2
Training loss: 2.0264029502868652
Validation loss: 2.155598707096551

Epoch: 6| Step: 3
Training loss: 2.443117618560791
Validation loss: 2.1863991829656784

Epoch: 6| Step: 4
Training loss: 2.1367855072021484
Validation loss: 2.126189371590973

Epoch: 6| Step: 5
Training loss: 1.9580316543579102
Validation loss: 2.208941403255668

Epoch: 6| Step: 6
Training loss: 2.2534003257751465
Validation loss: 2.190554852126747

Epoch: 6| Step: 7
Training loss: 1.2273292541503906
Validation loss: 2.137128436437217

Epoch: 6| Step: 8
Training loss: 2.3939735889434814
Validation loss: 2.1051401425433416

Epoch: 6| Step: 9
Training loss: 2.6934728622436523
Validation loss: 2.141080960150688

Epoch: 6| Step: 10
Training loss: 2.3548851013183594
Validation loss: 2.109917122830627

Epoch: 6| Step: 11
Training loss: 2.8839924335479736
Validation loss: 2.1742314189992924

Epoch: 6| Step: 12
Training loss: 1.3836915493011475
Validation loss: 2.1328336295261177

Epoch: 6| Step: 13
Training loss: 1.5307124853134155
Validation loss: 2.1913576331189883

Epoch: 219| Step: 0
Training loss: 1.9969427585601807
Validation loss: 2.182672385246523

Epoch: 6| Step: 1
Training loss: 1.5030181407928467
Validation loss: 2.0866989140869467

Epoch: 6| Step: 2
Training loss: 2.3217806816101074
Validation loss: 2.146677153084868

Epoch: 6| Step: 3
Training loss: 1.8615164756774902
Validation loss: 2.1200799813834568

Epoch: 6| Step: 4
Training loss: 2.415058135986328
Validation loss: 2.1231289448276645

Epoch: 6| Step: 5
Training loss: 1.5751813650131226
Validation loss: 2.2372829004000594

Epoch: 6| Step: 6
Training loss: 2.1594409942626953
Validation loss: 2.1455151804031862

Epoch: 6| Step: 7
Training loss: 2.069542407989502
Validation loss: 2.14808383551977

Epoch: 6| Step: 8
Training loss: 2.3976666927337646
Validation loss: 2.1552412407372588

Epoch: 6| Step: 9
Training loss: 2.1671783924102783
Validation loss: 2.1908949498207337

Epoch: 6| Step: 10
Training loss: 1.9650715589523315
Validation loss: 2.158530840309717

Epoch: 6| Step: 11
Training loss: 2.6150999069213867
Validation loss: 2.1233321851299656

Epoch: 6| Step: 12
Training loss: 1.7133498191833496
Validation loss: 2.0981975191382953

Epoch: 6| Step: 13
Training loss: 1.226847529411316
Validation loss: 2.1208851004159577

Epoch: 220| Step: 0
Training loss: 1.9658414125442505
Validation loss: 2.115144027176724

Epoch: 6| Step: 1
Training loss: 1.8971887826919556
Validation loss: 2.1370536999035905

Epoch: 6| Step: 2
Training loss: 2.0217080116271973
Validation loss: 2.0619856119155884

Epoch: 6| Step: 3
Training loss: 1.986600637435913
Validation loss: 2.1325981129882154

Epoch: 6| Step: 4
Training loss: 1.1929346323013306
Validation loss: 2.1211636066436768

Epoch: 6| Step: 5
Training loss: 2.732792377471924
Validation loss: 2.0871724005668395

Epoch: 6| Step: 6
Training loss: 1.8756651878356934
Validation loss: 2.0986260496160036

Epoch: 6| Step: 7
Training loss: 2.100139617919922
Validation loss: 2.1336667396688975

Epoch: 6| Step: 8
Training loss: 2.4310591220855713
Validation loss: 2.109681038446324

Epoch: 6| Step: 9
Training loss: 2.207883358001709
Validation loss: 2.1307922473517795

Epoch: 6| Step: 10
Training loss: 1.6533154249191284
Validation loss: 2.1466481467728973

Epoch: 6| Step: 11
Training loss: 2.422178030014038
Validation loss: 2.115104147182998

Epoch: 6| Step: 12
Training loss: 2.0314128398895264
Validation loss: 2.1247711335459063

Epoch: 6| Step: 13
Training loss: 1.9780938625335693
Validation loss: 2.074722020856796

Epoch: 221| Step: 0
Training loss: 2.0376627445220947
Validation loss: 2.1022495608175955

Epoch: 6| Step: 1
Training loss: 2.641098976135254
Validation loss: 2.128860492860117

Epoch: 6| Step: 2
Training loss: 2.126859426498413
Validation loss: 2.093619651691888

Epoch: 6| Step: 3
Training loss: 1.61522376537323
Validation loss: 2.197761385671554

Epoch: 6| Step: 4
Training loss: 1.7500858306884766
Validation loss: 2.089827979764631

Epoch: 6| Step: 5
Training loss: 1.9454927444458008
Validation loss: 2.1090462746158725

Epoch: 6| Step: 6
Training loss: 1.6447036266326904
Validation loss: 2.0686682680601716

Epoch: 6| Step: 7
Training loss: 2.5593414306640625
Validation loss: 2.1616122286806823

Epoch: 6| Step: 8
Training loss: 2.106901168823242
Validation loss: 2.1452248032375048

Epoch: 6| Step: 9
Training loss: 2.21600341796875
Validation loss: 2.12176933339847

Epoch: 6| Step: 10
Training loss: 1.6236283779144287
Validation loss: 2.1198329233354136

Epoch: 6| Step: 11
Training loss: 2.011932134628296
Validation loss: 2.0956269130911878

Epoch: 6| Step: 12
Training loss: 2.1667091846466064
Validation loss: 2.1041119816482707

Epoch: 6| Step: 13
Training loss: 3.3094630241394043
Validation loss: 2.14491129818783

Epoch: 222| Step: 0
Training loss: 1.456475019454956
Validation loss: 2.1779169754315446

Epoch: 6| Step: 1
Training loss: 1.9171477556228638
Validation loss: 2.148135078850613

Epoch: 6| Step: 2
Training loss: 2.706414222717285
Validation loss: 2.1490365138617893

Epoch: 6| Step: 3
Training loss: 1.9137481451034546
Validation loss: 2.141338650898267

Epoch: 6| Step: 4
Training loss: 2.0815768241882324
Validation loss: 2.134848899738763

Epoch: 6| Step: 5
Training loss: 2.0206940174102783
Validation loss: 2.109109555521319

Epoch: 6| Step: 6
Training loss: 2.597118616104126
Validation loss: 2.1057155952658704

Epoch: 6| Step: 7
Training loss: 2.490349531173706
Validation loss: 2.1508314917164464

Epoch: 6| Step: 8
Training loss: 1.8993232250213623
Validation loss: 2.1019633175224386

Epoch: 6| Step: 9
Training loss: 2.177680492401123
Validation loss: 2.148976351625176

Epoch: 6| Step: 10
Training loss: 2.0996057987213135
Validation loss: 2.2203127491858696

Epoch: 6| Step: 11
Training loss: 1.1440390348434448
Validation loss: 2.1428980596603884

Epoch: 6| Step: 12
Training loss: 2.376091480255127
Validation loss: 2.145489426069362

Epoch: 6| Step: 13
Training loss: 2.0097923278808594
Validation loss: 2.13873464574096

Epoch: 223| Step: 0
Training loss: 2.3937206268310547
Validation loss: 2.111786033517571

Epoch: 6| Step: 1
Training loss: 2.4740610122680664
Validation loss: 2.2197334958660986

Epoch: 6| Step: 2
Training loss: 2.098606824874878
Validation loss: 2.1379440215326126

Epoch: 6| Step: 3
Training loss: 1.66591477394104
Validation loss: 2.0666917383029895

Epoch: 6| Step: 4
Training loss: 3.0281593799591064
Validation loss: 2.127996242174538

Epoch: 6| Step: 5
Training loss: 1.5842831134796143
Validation loss: 2.099914135471467

Epoch: 6| Step: 6
Training loss: 2.128486156463623
Validation loss: 2.0762565033410185

Epoch: 6| Step: 7
Training loss: 1.7968356609344482
Validation loss: 2.0314099878393193

Epoch: 6| Step: 8
Training loss: 2.853811025619507
Validation loss: 2.1524896711431523

Epoch: 6| Step: 9
Training loss: 1.6313984394073486
Validation loss: 2.0923944019502208

Epoch: 6| Step: 10
Training loss: 2.4330198764801025
Validation loss: 2.081919374004487

Epoch: 6| Step: 11
Training loss: 1.2603752613067627
Validation loss: 2.061318084757815

Epoch: 6| Step: 12
Training loss: 2.069075584411621
Validation loss: 2.115606660483986

Epoch: 6| Step: 13
Training loss: 1.9807486534118652
Validation loss: 2.057517241406184

Epoch: 224| Step: 0
Training loss: 2.152522563934326
Validation loss: 2.1270534223125828

Epoch: 6| Step: 1
Training loss: 1.47727370262146
Validation loss: 2.1225816306247505

Epoch: 6| Step: 2
Training loss: 2.311211347579956
Validation loss: 2.1464332854875954

Epoch: 6| Step: 3
Training loss: 1.5177159309387207
Validation loss: 2.110965421122889

Epoch: 6| Step: 4
Training loss: 2.3861231803894043
Validation loss: 2.14179975499389

Epoch: 6| Step: 5
Training loss: 2.0429000854492188
Validation loss: 2.15146271259554

Epoch: 6| Step: 6
Training loss: 2.541076183319092
Validation loss: 2.125937572089575

Epoch: 6| Step: 7
Training loss: 2.7566847801208496
Validation loss: 2.1755721671606905

Epoch: 6| Step: 8
Training loss: 1.8589203357696533
Validation loss: 2.1591378873394382

Epoch: 6| Step: 9
Training loss: 2.1117630004882812
Validation loss: 2.1651076732143277

Epoch: 6| Step: 10
Training loss: 1.9981043338775635
Validation loss: 2.1406681588900986

Epoch: 6| Step: 11
Training loss: 1.4850223064422607
Validation loss: 2.1672804381257746

Epoch: 6| Step: 12
Training loss: 2.049480438232422
Validation loss: 2.1910755800944504

Epoch: 6| Step: 13
Training loss: 2.7542755603790283
Validation loss: 2.0940923229340584

Epoch: 225| Step: 0
Training loss: 2.036240577697754
Validation loss: 2.2606870307717273

Epoch: 6| Step: 1
Training loss: 1.6940689086914062
Validation loss: 2.130835158850557

Epoch: 6| Step: 2
Training loss: 2.5289149284362793
Validation loss: 2.2212485959452968

Epoch: 6| Step: 3
Training loss: 2.3344340324401855
Validation loss: 2.121664748396925

Epoch: 6| Step: 4
Training loss: 2.2114005088806152
Validation loss: 2.1527311750637588

Epoch: 6| Step: 5
Training loss: 2.7814598083496094
Validation loss: 2.1221025784810386

Epoch: 6| Step: 6
Training loss: 2.574352264404297
Validation loss: 2.157736865423059

Epoch: 6| Step: 7
Training loss: 1.8570046424865723
Validation loss: 2.1432929039001465

Epoch: 6| Step: 8
Training loss: 1.267276644706726
Validation loss: 2.096868541932875

Epoch: 6| Step: 9
Training loss: 1.7752227783203125
Validation loss: 2.128264275930261

Epoch: 6| Step: 10
Training loss: 1.8208858966827393
Validation loss: 2.1021282160153953

Epoch: 6| Step: 11
Training loss: 2.4993882179260254
Validation loss: 2.1375362475713096

Epoch: 6| Step: 12
Training loss: 1.8581993579864502
Validation loss: 2.123422143279865

Epoch: 6| Step: 13
Training loss: 1.0125423669815063
Validation loss: 2.1776796745997604

Epoch: 226| Step: 0
Training loss: 1.6118063926696777
Validation loss: 2.1081597574295534

Epoch: 6| Step: 1
Training loss: 1.854209065437317
Validation loss: 2.0786908570156304

Epoch: 6| Step: 2
Training loss: 2.591582775115967
Validation loss: 2.1045685532272502

Epoch: 6| Step: 3
Training loss: 2.0347025394439697
Validation loss: 2.0722905564051803

Epoch: 6| Step: 4
Training loss: 1.9862871170043945
Validation loss: 2.1584551539472354

Epoch: 6| Step: 5
Training loss: 2.0300183296203613
Validation loss: 2.111448423836821

Epoch: 6| Step: 6
Training loss: 3.226321220397949
Validation loss: 2.141903705494378

Epoch: 6| Step: 7
Training loss: 1.701754093170166
Validation loss: 2.1833518294877905

Epoch: 6| Step: 8
Training loss: 2.0272269248962402
Validation loss: 2.1175869946838706

Epoch: 6| Step: 9
Training loss: 2.0753536224365234
Validation loss: 2.1277800477961057

Epoch: 6| Step: 10
Training loss: 1.5443203449249268
Validation loss: 2.1381170544573056

Epoch: 6| Step: 11
Training loss: 1.7610770463943481
Validation loss: 2.1073564534546225

Epoch: 6| Step: 12
Training loss: 2.6313834190368652
Validation loss: 2.1155599932516775

Epoch: 6| Step: 13
Training loss: 1.9540159702301025
Validation loss: 2.1049772436900804

Epoch: 227| Step: 0
Training loss: 2.491372585296631
Validation loss: 2.1313717416537705

Epoch: 6| Step: 1
Training loss: 1.7676771879196167
Validation loss: 2.1078952807252125

Epoch: 6| Step: 2
Training loss: 1.8242788314819336
Validation loss: 2.138032818353304

Epoch: 6| Step: 3
Training loss: 1.9997535943984985
Validation loss: 2.1499344982126707

Epoch: 6| Step: 4
Training loss: 2.152064800262451
Validation loss: 2.1722734974276636

Epoch: 6| Step: 5
Training loss: 1.7730408906936646
Validation loss: 2.0982800247848674

Epoch: 6| Step: 6
Training loss: 2.109679698944092
Validation loss: 2.1199460721785024

Epoch: 6| Step: 7
Training loss: 1.2786540985107422
Validation loss: 2.170841646450822

Epoch: 6| Step: 8
Training loss: 1.8597726821899414
Validation loss: 2.1337777619720786

Epoch: 6| Step: 9
Training loss: 1.8108893632888794
Validation loss: 2.0993853410085044

Epoch: 6| Step: 10
Training loss: 2.617776870727539
Validation loss: 2.1349131599549325

Epoch: 6| Step: 11
Training loss: 2.2665114402770996
Validation loss: 2.168614269584738

Epoch: 6| Step: 12
Training loss: 2.274017333984375
Validation loss: 2.139504612133067

Epoch: 6| Step: 13
Training loss: 2.517275810241699
Validation loss: 2.1281475482448453

Epoch: 228| Step: 0
Training loss: 1.4346824884414673
Validation loss: 2.1687470661696566

Epoch: 6| Step: 1
Training loss: 2.564431667327881
Validation loss: 2.078107069897395

Epoch: 6| Step: 2
Training loss: 1.5896390676498413
Validation loss: 2.14090972305626

Epoch: 6| Step: 3
Training loss: 1.820003867149353
Validation loss: 2.182493056020429

Epoch: 6| Step: 4
Training loss: 2.293017864227295
Validation loss: 2.154972877553714

Epoch: 6| Step: 5
Training loss: 2.7609567642211914
Validation loss: 2.1586456939738285

Epoch: 6| Step: 6
Training loss: 1.672341227531433
Validation loss: 2.0894801514123076

Epoch: 6| Step: 7
Training loss: 2.628530502319336
Validation loss: 2.1025588473966046

Epoch: 6| Step: 8
Training loss: 1.8423411846160889
Validation loss: 2.145725175898562

Epoch: 6| Step: 9
Training loss: 2.4430150985717773
Validation loss: 2.1562552657178653

Epoch: 6| Step: 10
Training loss: 1.8948712348937988
Validation loss: 2.1006824662608485

Epoch: 6| Step: 11
Training loss: 1.6971938610076904
Validation loss: 2.1504905454574095

Epoch: 6| Step: 12
Training loss: 2.3880231380462646
Validation loss: 2.092306033257515

Epoch: 6| Step: 13
Training loss: 2.2224960327148438
Validation loss: 2.166553371696062

Epoch: 229| Step: 0
Training loss: 1.9318456649780273
Validation loss: 2.1617963903693744

Epoch: 6| Step: 1
Training loss: 2.3546266555786133
Validation loss: 2.12666073665824

Epoch: 6| Step: 2
Training loss: 2.3295912742614746
Validation loss: 2.086174900813769

Epoch: 6| Step: 3
Training loss: 1.8939143419265747
Validation loss: 2.13017294099254

Epoch: 6| Step: 4
Training loss: 2.257411479949951
Validation loss: 2.1112656708686584

Epoch: 6| Step: 5
Training loss: 1.4760912656784058
Validation loss: 2.1269785575969244

Epoch: 6| Step: 6
Training loss: 3.0791940689086914
Validation loss: 2.091159261682982

Epoch: 6| Step: 7
Training loss: 2.085113286972046
Validation loss: 2.1865003929343274

Epoch: 6| Step: 8
Training loss: 1.703270673751831
Validation loss: 2.10949590001055

Epoch: 6| Step: 9
Training loss: 1.3434104919433594
Validation loss: 2.149938074491357

Epoch: 6| Step: 10
Training loss: 2.2006893157958984
Validation loss: 2.1413024035833215

Epoch: 6| Step: 11
Training loss: 2.0632991790771484
Validation loss: 2.1338662075740036

Epoch: 6| Step: 12
Training loss: 2.1688992977142334
Validation loss: 2.0921352601820424

Epoch: 6| Step: 13
Training loss: 1.8177380561828613
Validation loss: 2.0975012830508653

Epoch: 230| Step: 0
Training loss: 1.7024824619293213
Validation loss: 2.0617968241373696

Epoch: 6| Step: 1
Training loss: 2.8578145503997803
Validation loss: 2.1803924268291843

Epoch: 6| Step: 2
Training loss: 1.9153424501419067
Validation loss: 2.150509444616174

Epoch: 6| Step: 3
Training loss: 1.8244671821594238
Validation loss: 2.1265672624752088

Epoch: 6| Step: 4
Training loss: 2.2746219635009766
Validation loss: 2.166880933187341

Epoch: 6| Step: 5
Training loss: 1.615541696548462
Validation loss: 2.1196688170074136

Epoch: 6| Step: 6
Training loss: 2.18941593170166
Validation loss: 2.0670394359096402

Epoch: 6| Step: 7
Training loss: 1.6547248363494873
Validation loss: 2.113289274195189

Epoch: 6| Step: 8
Training loss: 2.060138463973999
Validation loss: 2.0412125279826503

Epoch: 6| Step: 9
Training loss: 2.0671019554138184
Validation loss: 2.106899807530065

Epoch: 6| Step: 10
Training loss: 1.9738655090332031
Validation loss: 2.1113652311345583

Epoch: 6| Step: 11
Training loss: 2.1516692638397217
Validation loss: 2.1215350256171277

Epoch: 6| Step: 12
Training loss: 1.798133134841919
Validation loss: 2.1194131630723194

Epoch: 6| Step: 13
Training loss: 2.6686410903930664
Validation loss: 2.102079886262135

Epoch: 231| Step: 0
Training loss: 2.794088840484619
Validation loss: 2.122030600424736

Epoch: 6| Step: 1
Training loss: 2.497281074523926
Validation loss: 2.128538836715042

Epoch: 6| Step: 2
Training loss: 1.7713816165924072
Validation loss: 2.1359108032718783

Epoch: 6| Step: 3
Training loss: 1.289407730102539
Validation loss: 2.0379775724103375

Epoch: 6| Step: 4
Training loss: 1.7537105083465576
Validation loss: 2.093591574699648

Epoch: 6| Step: 5
Training loss: 1.98259699344635
Validation loss: 2.117032274123161

Epoch: 6| Step: 6
Training loss: 1.7931222915649414
Validation loss: 2.101214983130014

Epoch: 6| Step: 7
Training loss: 2.8072268962860107
Validation loss: 2.069653449519988

Epoch: 6| Step: 8
Training loss: 1.3938562870025635
Validation loss: 2.110786061133108

Epoch: 6| Step: 9
Training loss: 2.273019790649414
Validation loss: 2.1216634037674114

Epoch: 6| Step: 10
Training loss: 1.9052488803863525
Validation loss: 2.1782899851440103

Epoch: 6| Step: 11
Training loss: 1.6841762065887451
Validation loss: 2.1162569933040167

Epoch: 6| Step: 12
Training loss: 2.3682963848114014
Validation loss: 2.093545400968162

Epoch: 6| Step: 13
Training loss: 2.1404948234558105
Validation loss: 2.169706747096072

Epoch: 232| Step: 0
Training loss: 1.8001775741577148
Validation loss: 2.185935720320671

Epoch: 6| Step: 1
Training loss: 2.4173288345336914
Validation loss: 2.0969391433141564

Epoch: 6| Step: 2
Training loss: 2.3195881843566895
Validation loss: 2.158573001943609

Epoch: 6| Step: 3
Training loss: 2.072101593017578
Validation loss: 2.19828797412175

Epoch: 6| Step: 4
Training loss: 2.4191677570343018
Validation loss: 2.1439927226753643

Epoch: 6| Step: 5
Training loss: 2.316603899002075
Validation loss: 2.1206275647686375

Epoch: 6| Step: 6
Training loss: 2.1675143241882324
Validation loss: 2.0860462586085

Epoch: 6| Step: 7
Training loss: 2.230393409729004
Validation loss: 2.171513477961222

Epoch: 6| Step: 8
Training loss: 2.259220838546753
Validation loss: 2.1343850538294804

Epoch: 6| Step: 9
Training loss: 1.7963225841522217
Validation loss: 2.122855350535403

Epoch: 6| Step: 10
Training loss: 1.3819019794464111
Validation loss: 2.115664302661855

Epoch: 6| Step: 11
Training loss: 1.309687614440918
Validation loss: 2.1429570451859505

Epoch: 6| Step: 12
Training loss: 2.564805507659912
Validation loss: 2.079805520273024

Epoch: 6| Step: 13
Training loss: 1.3046866655349731
Validation loss: 2.10355939275475

Epoch: 233| Step: 0
Training loss: 2.455991744995117
Validation loss: 2.1477660594447965

Epoch: 6| Step: 1
Training loss: 1.8394109010696411
Validation loss: 2.126366784495692

Epoch: 6| Step: 2
Training loss: 1.6245288848876953
Validation loss: 2.1985526418173187

Epoch: 6| Step: 3
Training loss: 1.9414925575256348
Validation loss: 2.1369683268249675

Epoch: 6| Step: 4
Training loss: 2.7864856719970703
Validation loss: 2.0644838630512194

Epoch: 6| Step: 5
Training loss: 2.3092846870422363
Validation loss: 2.100597216236976

Epoch: 6| Step: 6
Training loss: 2.510538339614868
Validation loss: 2.150172447645536

Epoch: 6| Step: 7
Training loss: 1.6134190559387207
Validation loss: 2.1081209900558635

Epoch: 6| Step: 8
Training loss: 2.2238211631774902
Validation loss: 2.064966788855932

Epoch: 6| Step: 9
Training loss: 2.4951119422912598
Validation loss: 2.10995130385122

Epoch: 6| Step: 10
Training loss: 1.2856926918029785
Validation loss: 2.039207785360275

Epoch: 6| Step: 11
Training loss: 2.0292775630950928
Validation loss: 2.2006040670538463

Epoch: 6| Step: 12
Training loss: 1.4594218730926514
Validation loss: 2.1357608174764984

Epoch: 6| Step: 13
Training loss: 1.9695614576339722
Validation loss: 2.1409174370509323

Epoch: 234| Step: 0
Training loss: 2.067415952682495
Validation loss: 2.182118051795549

Epoch: 6| Step: 1
Training loss: 2.8561739921569824
Validation loss: 2.13494893171454

Epoch: 6| Step: 2
Training loss: 1.8368103504180908
Validation loss: 2.099473237991333

Epoch: 6| Step: 3
Training loss: 2.1850242614746094
Validation loss: 2.1803535594735095

Epoch: 6| Step: 4
Training loss: 1.3803222179412842
Validation loss: 2.1011628643158944

Epoch: 6| Step: 5
Training loss: 1.844920039176941
Validation loss: 2.0872458578437887

Epoch: 6| Step: 6
Training loss: 2.2331159114837646
Validation loss: 2.164747816260143

Epoch: 6| Step: 7
Training loss: 2.204017400741577
Validation loss: 2.0339254563854587

Epoch: 6| Step: 8
Training loss: 1.8504750728607178
Validation loss: 2.220670482163788

Epoch: 6| Step: 9
Training loss: 1.8728386163711548
Validation loss: 2.0849804365506737

Epoch: 6| Step: 10
Training loss: 2.389763355255127
Validation loss: 2.153480472103242

Epoch: 6| Step: 11
Training loss: 1.3803507089614868
Validation loss: 2.071736151172269

Epoch: 6| Step: 12
Training loss: 2.547102689743042
Validation loss: 2.0745002761963875

Epoch: 6| Step: 13
Training loss: 1.3795490264892578
Validation loss: 2.0876876666981685

Epoch: 235| Step: 0
Training loss: 2.0219173431396484
Validation loss: 2.112332013345534

Epoch: 6| Step: 1
Training loss: 2.5858521461486816
Validation loss: 2.062999935560329

Epoch: 6| Step: 2
Training loss: 2.022613525390625
Validation loss: 2.1170388472977506

Epoch: 6| Step: 3
Training loss: 2.850558042526245
Validation loss: 2.108403121271441

Epoch: 6| Step: 4
Training loss: 1.3162809610366821
Validation loss: 2.078644326938096

Epoch: 6| Step: 5
Training loss: 2.277855396270752
Validation loss: 2.0925285252191688

Epoch: 6| Step: 6
Training loss: 2.2335658073425293
Validation loss: 2.227765417868091

Epoch: 6| Step: 7
Training loss: 1.668081283569336
Validation loss: 2.1330466385810607

Epoch: 6| Step: 8
Training loss: 1.7967376708984375
Validation loss: 2.1441394334198325

Epoch: 6| Step: 9
Training loss: 2.8928616046905518
Validation loss: 2.093724602012224

Epoch: 6| Step: 10
Training loss: 1.7483322620391846
Validation loss: 2.1169684676713842

Epoch: 6| Step: 11
Training loss: 1.7896080017089844
Validation loss: 2.073178493848411

Epoch: 6| Step: 12
Training loss: 1.838145136833191
Validation loss: 2.137728447555214

Epoch: 6| Step: 13
Training loss: 1.8277840614318848
Validation loss: 2.157197695906444

Epoch: 236| Step: 0
Training loss: 2.1008071899414062
Validation loss: 2.098573059164068

Epoch: 6| Step: 1
Training loss: 2.235769271850586
Validation loss: 2.1528928664422806

Epoch: 6| Step: 2
Training loss: 2.074582576751709
Validation loss: 2.1257267754565

Epoch: 6| Step: 3
Training loss: 1.8766322135925293
Validation loss: 2.143686350955758

Epoch: 6| Step: 4
Training loss: 2.349062919616699
Validation loss: 2.111825312337568

Epoch: 6| Step: 5
Training loss: 2.3028640747070312
Validation loss: 2.1017112731933594

Epoch: 6| Step: 6
Training loss: 1.7003638744354248
Validation loss: 2.1118077103809645

Epoch: 6| Step: 7
Training loss: 2.253481864929199
Validation loss: 2.1037705380429506

Epoch: 6| Step: 8
Training loss: 1.9296298027038574
Validation loss: 2.1492145933130735

Epoch: 6| Step: 9
Training loss: 1.9413042068481445
Validation loss: 2.1256722199019564

Epoch: 6| Step: 10
Training loss: 1.6382055282592773
Validation loss: 2.2049455591427383

Epoch: 6| Step: 11
Training loss: 2.6446714401245117
Validation loss: 2.1439756065286617

Epoch: 6| Step: 12
Training loss: 2.099017858505249
Validation loss: 2.1380930562173166

Epoch: 6| Step: 13
Training loss: 1.4200892448425293
Validation loss: 2.1555567633721138

Epoch: 237| Step: 0
Training loss: 1.853951096534729
Validation loss: 2.1096081874703847

Epoch: 6| Step: 1
Training loss: 2.294175863265991
Validation loss: 2.1541114186727874

Epoch: 6| Step: 2
Training loss: 1.7109684944152832
Validation loss: 2.124113614841174

Epoch: 6| Step: 3
Training loss: 2.2541890144348145
Validation loss: 2.1575778684308453

Epoch: 6| Step: 4
Training loss: 1.3827853202819824
Validation loss: 2.122371530020109

Epoch: 6| Step: 5
Training loss: 2.0236258506774902
Validation loss: 2.1251212986566688

Epoch: 6| Step: 6
Training loss: 1.5859334468841553
Validation loss: 2.1690723972935833

Epoch: 6| Step: 7
Training loss: 1.8660110235214233
Validation loss: 2.1223413534061883

Epoch: 6| Step: 8
Training loss: 2.0066428184509277
Validation loss: 2.150881998000606

Epoch: 6| Step: 9
Training loss: 2.8846206665039062
Validation loss: 2.1682462025714178

Epoch: 6| Step: 10
Training loss: 2.208129644393921
Validation loss: 2.1262993607469785

Epoch: 6| Step: 11
Training loss: 2.376957654953003
Validation loss: 2.16895894850454

Epoch: 6| Step: 12
Training loss: 1.3704869747161865
Validation loss: 2.1437940110442457

Epoch: 6| Step: 13
Training loss: 2.6770219802856445
Validation loss: 2.1683685600116687

Epoch: 238| Step: 0
Training loss: 1.8859156370162964
Validation loss: 2.1793375143440823

Epoch: 6| Step: 1
Training loss: 1.4700021743774414
Validation loss: 2.1224373361115814

Epoch: 6| Step: 2
Training loss: 2.9261202812194824
Validation loss: 2.2051045022984987

Epoch: 6| Step: 3
Training loss: 2.4017677307128906
Validation loss: 2.105231446604575

Epoch: 6| Step: 4
Training loss: 2.429133415222168
Validation loss: 2.187163063274917

Epoch: 6| Step: 5
Training loss: 2.234556198120117
Validation loss: 2.139716384231403

Epoch: 6| Step: 6
Training loss: 2.4615883827209473
Validation loss: 2.130586580563617

Epoch: 6| Step: 7
Training loss: 1.7138173580169678
Validation loss: 2.0880427257989043

Epoch: 6| Step: 8
Training loss: 1.9781825542449951
Validation loss: 2.105047598961861

Epoch: 6| Step: 9
Training loss: 2.0017812252044678
Validation loss: 2.1659408718027096

Epoch: 6| Step: 10
Training loss: 1.940746784210205
Validation loss: 2.0776530799045356

Epoch: 6| Step: 11
Training loss: 1.7777619361877441
Validation loss: 2.0914363271446637

Epoch: 6| Step: 12
Training loss: 1.515011191368103
Validation loss: 2.08230774376982

Epoch: 6| Step: 13
Training loss: 1.7486042976379395
Validation loss: 2.09866238153109

Epoch: 239| Step: 0
Training loss: 2.5944621562957764
Validation loss: 2.0326855541557394

Epoch: 6| Step: 1
Training loss: 2.1645309925079346
Validation loss: 2.081256635727421

Epoch: 6| Step: 2
Training loss: 2.3420376777648926
Validation loss: 2.076437698897495

Epoch: 6| Step: 3
Training loss: 2.1279306411743164
Validation loss: 2.1079880152979205

Epoch: 6| Step: 4
Training loss: 2.4294936656951904
Validation loss: 2.084745378904445

Epoch: 6| Step: 5
Training loss: 1.774613857269287
Validation loss: 2.15733773990344

Epoch: 6| Step: 6
Training loss: 2.084754467010498
Validation loss: 2.1153993580930974

Epoch: 6| Step: 7
Training loss: 2.0864968299865723
Validation loss: 2.1312938069784515

Epoch: 6| Step: 8
Training loss: 2.1606688499450684
Validation loss: 2.1843896283898303

Epoch: 6| Step: 9
Training loss: 1.899977207183838
Validation loss: 2.1843444224326842

Epoch: 6| Step: 10
Training loss: 2.1153063774108887
Validation loss: 2.1342174763320596

Epoch: 6| Step: 11
Training loss: 1.6548762321472168
Validation loss: 2.117371295088081

Epoch: 6| Step: 12
Training loss: 1.5113897323608398
Validation loss: 2.1534341317351147

Epoch: 6| Step: 13
Training loss: 1.799702525138855
Validation loss: 2.1084874060846146

Epoch: 240| Step: 0
Training loss: 1.4508112668991089
Validation loss: 2.1229853527520293

Epoch: 6| Step: 1
Training loss: 2.5308480262756348
Validation loss: 2.11781475364521

Epoch: 6| Step: 2
Training loss: 1.7321778535842896
Validation loss: 2.1308920332180556

Epoch: 6| Step: 3
Training loss: 2.055454730987549
Validation loss: 2.18501272765539

Epoch: 6| Step: 4
Training loss: 2.3247718811035156
Validation loss: 2.1221354776813137

Epoch: 6| Step: 5
Training loss: 1.705237627029419
Validation loss: 2.1336156014473207

Epoch: 6| Step: 6
Training loss: 2.3400521278381348
Validation loss: 2.1097121623254593

Epoch: 6| Step: 7
Training loss: 1.9122388362884521
Validation loss: 2.171186311270601

Epoch: 6| Step: 8
Training loss: 2.2200090885162354
Validation loss: 2.056851238332769

Epoch: 6| Step: 9
Training loss: 1.5030781030654907
Validation loss: 2.1659786137201453

Epoch: 6| Step: 10
Training loss: 1.645369529724121
Validation loss: 2.1157241264979043

Epoch: 6| Step: 11
Training loss: 1.9933526515960693
Validation loss: 2.0881350937710015

Epoch: 6| Step: 12
Training loss: 2.3574724197387695
Validation loss: 2.0979145201303626

Epoch: 6| Step: 13
Training loss: 3.0156383514404297
Validation loss: 2.1143874558069373

Epoch: 241| Step: 0
Training loss: 1.3753979206085205
Validation loss: 2.111000055907875

Epoch: 6| Step: 1
Training loss: 2.2307887077331543
Validation loss: 2.1728066987888788

Epoch: 6| Step: 2
Training loss: 2.4157772064208984
Validation loss: 2.0645749709939443

Epoch: 6| Step: 3
Training loss: 2.7714955806732178
Validation loss: 2.1007703119708645

Epoch: 6| Step: 4
Training loss: 1.711501121520996
Validation loss: 2.053659136577319

Epoch: 6| Step: 5
Training loss: 2.030691623687744
Validation loss: 2.1639297290514876

Epoch: 6| Step: 6
Training loss: 1.8132737874984741
Validation loss: 2.0404979695555983

Epoch: 6| Step: 7
Training loss: 1.9730370044708252
Validation loss: 2.071283282772187

Epoch: 6| Step: 8
Training loss: 2.4554977416992188
Validation loss: 2.0701876686465357

Epoch: 6| Step: 9
Training loss: 2.2019104957580566
Validation loss: 1.9831350541883899

Epoch: 6| Step: 10
Training loss: 2.4160430431365967
Validation loss: 2.1059736487685994

Epoch: 6| Step: 11
Training loss: 0.9351680278778076
Validation loss: 2.1321284950420423

Epoch: 6| Step: 12
Training loss: 2.531954526901245
Validation loss: 2.0571009215488227

Epoch: 6| Step: 13
Training loss: 1.8724716901779175
Validation loss: 2.184056476880145

Epoch: 242| Step: 0
Training loss: 1.754211187362671
Validation loss: 2.085582105062341

Epoch: 6| Step: 1
Training loss: 2.2927803993225098
Validation loss: 2.0835307118713216

Epoch: 6| Step: 2
Training loss: 1.925626277923584
Validation loss: 2.179829264199862

Epoch: 6| Step: 3
Training loss: 1.680685043334961
Validation loss: 2.0768011898122807

Epoch: 6| Step: 4
Training loss: 1.96536386013031
Validation loss: 2.1808698446519914

Epoch: 6| Step: 5
Training loss: 1.785539984703064
Validation loss: 2.1982501809315016

Epoch: 6| Step: 6
Training loss: 2.357142925262451
Validation loss: 2.164805098246503

Epoch: 6| Step: 7
Training loss: 2.032543182373047
Validation loss: 2.227667857241887

Epoch: 6| Step: 8
Training loss: 2.4426753520965576
Validation loss: 2.145798055074548

Epoch: 6| Step: 9
Training loss: 2.1401941776275635
Validation loss: 2.1956210059504353

Epoch: 6| Step: 10
Training loss: 1.9362890720367432
Validation loss: 2.187587332981889

Epoch: 6| Step: 11
Training loss: 2.3772196769714355
Validation loss: 2.2271823075509842

Epoch: 6| Step: 12
Training loss: 2.225097417831421
Validation loss: 2.169974342469246

Epoch: 6| Step: 13
Training loss: 1.3358607292175293
Validation loss: 2.1774941785361177

Epoch: 243| Step: 0
Training loss: 1.7363765239715576
Validation loss: 2.199893582251764

Epoch: 6| Step: 1
Training loss: 2.1671109199523926
Validation loss: 2.1923230758277317

Epoch: 6| Step: 2
Training loss: 2.8570237159729004
Validation loss: 2.1906305692529164

Epoch: 6| Step: 3
Training loss: 1.9774895906448364
Validation loss: 2.1680008185807096

Epoch: 6| Step: 4
Training loss: 1.9328380823135376
Validation loss: 2.1683281903625815

Epoch: 6| Step: 5
Training loss: 1.9496898651123047
Validation loss: 2.14248635051071

Epoch: 6| Step: 6
Training loss: 1.8975225687026978
Validation loss: 2.117219630108085

Epoch: 6| Step: 7
Training loss: 1.2858041524887085
Validation loss: 2.102839054599885

Epoch: 6| Step: 8
Training loss: 1.807104468345642
Validation loss: 2.117002502564461

Epoch: 6| Step: 9
Training loss: 1.913889765739441
Validation loss: 2.180207834448866

Epoch: 6| Step: 10
Training loss: 1.3850923776626587
Validation loss: 2.1440663799162833

Epoch: 6| Step: 11
Training loss: 2.567747116088867
Validation loss: 2.1824101735186834

Epoch: 6| Step: 12
Training loss: 2.583951473236084
Validation loss: 2.11306809097208

Epoch: 6| Step: 13
Training loss: 2.4212534427642822
Validation loss: 2.1247608559105986

Epoch: 244| Step: 0
Training loss: 2.9814443588256836
Validation loss: 2.067856429725565

Epoch: 6| Step: 1
Training loss: 1.799239158630371
Validation loss: 2.149796752519505

Epoch: 6| Step: 2
Training loss: 1.910391092300415
Validation loss: 2.1507800253488685

Epoch: 6| Step: 3
Training loss: 1.044123649597168
Validation loss: 2.087383149772562

Epoch: 6| Step: 4
Training loss: 1.5844179391860962
Validation loss: 2.170935373152456

Epoch: 6| Step: 5
Training loss: 2.249790668487549
Validation loss: 2.096552529642659

Epoch: 6| Step: 6
Training loss: 1.346663475036621
Validation loss: 2.0950008771752797

Epoch: 6| Step: 7
Training loss: 1.9311811923980713
Validation loss: 2.161747327414892

Epoch: 6| Step: 8
Training loss: 2.999297618865967
Validation loss: 2.086436456249606

Epoch: 6| Step: 9
Training loss: 1.7931149005889893
Validation loss: 2.1136878382775093

Epoch: 6| Step: 10
Training loss: 1.9651169776916504
Validation loss: 2.157158124831415

Epoch: 6| Step: 11
Training loss: 2.4626426696777344
Validation loss: 2.1724088986714682

Epoch: 6| Step: 12
Training loss: 2.0537171363830566
Validation loss: 2.14807802631009

Epoch: 6| Step: 13
Training loss: 1.9423819780349731
Validation loss: 2.146517913828614

Epoch: 245| Step: 0
Training loss: 2.640955924987793
Validation loss: 2.2086236528171006

Epoch: 6| Step: 1
Training loss: 2.0937604904174805
Validation loss: 2.1134088718762962

Epoch: 6| Step: 2
Training loss: 2.1515562534332275
Validation loss: 2.1826651942345405

Epoch: 6| Step: 3
Training loss: 2.020556926727295
Validation loss: 2.1531303082743

Epoch: 6| Step: 4
Training loss: 2.4835703372955322
Validation loss: 2.129641607243528

Epoch: 6| Step: 5
Training loss: 1.3910243511199951
Validation loss: 2.151758555443056

Epoch: 6| Step: 6
Training loss: 2.114534378051758
Validation loss: 2.10772959134912

Epoch: 6| Step: 7
Training loss: 2.1336755752563477
Validation loss: 2.2016386114140993

Epoch: 6| Step: 8
Training loss: 2.071779251098633
Validation loss: 2.114415676363053

Epoch: 6| Step: 9
Training loss: 1.928971529006958
Validation loss: 2.130392543731197

Epoch: 6| Step: 10
Training loss: 1.9012655019760132
Validation loss: 2.1155594779599096

Epoch: 6| Step: 11
Training loss: 2.4518234729766846
Validation loss: 2.146391009771696

Epoch: 6| Step: 12
Training loss: 1.7898685932159424
Validation loss: 2.171990309992144

Epoch: 6| Step: 13
Training loss: 1.5484579801559448
Validation loss: 2.1620652611537645

Epoch: 246| Step: 0
Training loss: 2.1249094009399414
Validation loss: 2.2192765153864378

Epoch: 6| Step: 1
Training loss: 1.9811619520187378
Validation loss: 2.136852269531578

Epoch: 6| Step: 2
Training loss: 1.7417705059051514
Validation loss: 2.149737032510901

Epoch: 6| Step: 3
Training loss: 2.244500160217285
Validation loss: 2.136929383841894

Epoch: 6| Step: 4
Training loss: 1.9181360006332397
Validation loss: 2.177004075819446

Epoch: 6| Step: 5
Training loss: 2.206587314605713
Validation loss: 2.166868358530024

Epoch: 6| Step: 6
Training loss: 1.8730690479278564
Validation loss: 2.073474153395622

Epoch: 6| Step: 7
Training loss: 1.4992254972457886
Validation loss: 2.1027452804708995

Epoch: 6| Step: 8
Training loss: 2.397489309310913
Validation loss: 2.10403250878857

Epoch: 6| Step: 9
Training loss: 2.0392651557922363
Validation loss: 2.12464205936719

Epoch: 6| Step: 10
Training loss: 2.4059975147247314
Validation loss: 2.0759243144783923

Epoch: 6| Step: 11
Training loss: 2.1752877235412598
Validation loss: 2.1197375418037496

Epoch: 6| Step: 12
Training loss: 2.0503666400909424
Validation loss: 2.0902939150410313

Epoch: 6| Step: 13
Training loss: 1.9727513790130615
Validation loss: 2.1056161080637286

Epoch: 247| Step: 0
Training loss: 2.0090041160583496
Validation loss: 2.1317335354384555

Epoch: 6| Step: 1
Training loss: 2.633625030517578
Validation loss: 2.0942464515727055

Epoch: 6| Step: 2
Training loss: 2.390183925628662
Validation loss: 2.1544275591450353

Epoch: 6| Step: 3
Training loss: 2.0742907524108887
Validation loss: 2.10211334946335

Epoch: 6| Step: 4
Training loss: 2.083223581314087
Validation loss: 2.142211097542958

Epoch: 6| Step: 5
Training loss: 2.063887119293213
Validation loss: 2.071013314749605

Epoch: 6| Step: 6
Training loss: 1.9149264097213745
Validation loss: 2.1234091917673745

Epoch: 6| Step: 7
Training loss: 1.8125115633010864
Validation loss: 2.161381827887668

Epoch: 6| Step: 8
Training loss: 2.1911416053771973
Validation loss: 2.0456719078043455

Epoch: 6| Step: 9
Training loss: 2.4914841651916504
Validation loss: 2.1481204455898655

Epoch: 6| Step: 10
Training loss: 2.0305986404418945
Validation loss: 2.0948107909130793

Epoch: 6| Step: 11
Training loss: 1.1295307874679565
Validation loss: 2.0871154415991997

Epoch: 6| Step: 12
Training loss: 2.00115704536438
Validation loss: 2.1509103749388006

Epoch: 6| Step: 13
Training loss: 1.15725576877594
Validation loss: 2.1638556885462936

Epoch: 248| Step: 0
Training loss: 2.2137579917907715
Validation loss: 2.0886059243191957

Epoch: 6| Step: 1
Training loss: 2.6987149715423584
Validation loss: 2.2063025428402807

Epoch: 6| Step: 2
Training loss: 2.163296699523926
Validation loss: 2.153351403051807

Epoch: 6| Step: 3
Training loss: 1.9002087116241455
Validation loss: 2.151769043296896

Epoch: 6| Step: 4
Training loss: 2.0953450202941895
Validation loss: 2.1040564429375435

Epoch: 6| Step: 5
Training loss: 2.230283260345459
Validation loss: 2.1566744081435667

Epoch: 6| Step: 6
Training loss: 1.989576816558838
Validation loss: 2.1448833570685437

Epoch: 6| Step: 7
Training loss: 2.2401623725891113
Validation loss: 2.2068986661972536

Epoch: 6| Step: 8
Training loss: 1.6520456075668335
Validation loss: 2.1522772876165246

Epoch: 6| Step: 9
Training loss: 1.992596983909607
Validation loss: 2.0822700608161187

Epoch: 6| Step: 10
Training loss: 1.9276924133300781
Validation loss: 2.14504433960043

Epoch: 6| Step: 11
Training loss: 1.3386298418045044
Validation loss: 2.1485695249290875

Epoch: 6| Step: 12
Training loss: 2.431995153427124
Validation loss: 2.068719917728055

Epoch: 6| Step: 13
Training loss: 1.593433141708374
Validation loss: 2.1083338747742357

Epoch: 249| Step: 0
Training loss: 2.81984281539917
Validation loss: 2.1843101670665126

Epoch: 6| Step: 1
Training loss: 2.0596020221710205
Validation loss: 1.9895417305731005

Epoch: 6| Step: 2
Training loss: 2.6086339950561523
Validation loss: 2.0356732030068674

Epoch: 6| Step: 3
Training loss: 1.8433550596237183
Validation loss: 2.0356496764767553

Epoch: 6| Step: 4
Training loss: 2.0815234184265137
Validation loss: 2.1411135273595012

Epoch: 6| Step: 5
Training loss: 1.9923679828643799
Validation loss: 2.1338909736243625

Epoch: 6| Step: 6
Training loss: 1.7104620933532715
Validation loss: 2.11719770585337

Epoch: 6| Step: 7
Training loss: 1.888126015663147
Validation loss: 2.1267217179780364

Epoch: 6| Step: 8
Training loss: 1.9139795303344727
Validation loss: 2.1431045314317108

Epoch: 6| Step: 9
Training loss: 2.1664695739746094
Validation loss: 2.1388014977978123

Epoch: 6| Step: 10
Training loss: 1.665574073791504
Validation loss: 2.0762514580962477

Epoch: 6| Step: 11
Training loss: 1.7666590213775635
Validation loss: 2.0880022074586604

Epoch: 6| Step: 12
Training loss: 2.093724012374878
Validation loss: 2.117453936607607

Epoch: 6| Step: 13
Training loss: 1.5089035034179688
Validation loss: 2.0800493327520226

Epoch: 250| Step: 0
Training loss: 1.8134101629257202
Validation loss: 2.1588197267183693

Epoch: 6| Step: 1
Training loss: 1.9504632949829102
Validation loss: 2.092035790925385

Epoch: 6| Step: 2
Training loss: 1.3673593997955322
Validation loss: 2.12167497604124

Epoch: 6| Step: 3
Training loss: 1.8675734996795654
Validation loss: 2.1348293007061048

Epoch: 6| Step: 4
Training loss: 1.8937041759490967
Validation loss: 2.141405261972899

Epoch: 6| Step: 5
Training loss: 2.0296568870544434
Validation loss: 2.135899507871238

Epoch: 6| Step: 6
Training loss: 2.510939359664917
Validation loss: 2.1528315774856077

Epoch: 6| Step: 7
Training loss: 2.3263134956359863
Validation loss: 2.0787104765574136

Epoch: 6| Step: 8
Training loss: 2.283374547958374
Validation loss: 2.100100281418011

Epoch: 6| Step: 9
Training loss: 1.6955788135528564
Validation loss: 2.1420850612783946

Epoch: 6| Step: 10
Training loss: 1.856689453125
Validation loss: 2.104490828770463

Epoch: 6| Step: 11
Training loss: 2.4307446479797363
Validation loss: 2.1374534970970562

Epoch: 6| Step: 12
Training loss: 1.887039303779602
Validation loss: 2.174945621080296

Epoch: 6| Step: 13
Training loss: 2.5997610092163086
Validation loss: 2.153441208665089

Epoch: 251| Step: 0
Training loss: 1.976704716682434
Validation loss: 2.1897595851652083

Epoch: 6| Step: 1
Training loss: 1.864183783531189
Validation loss: 2.0675853760011735

Epoch: 6| Step: 2
Training loss: 1.61173415184021
Validation loss: 2.1833230987671883

Epoch: 6| Step: 3
Training loss: 2.4855709075927734
Validation loss: 2.1321570001622683

Epoch: 6| Step: 4
Training loss: 1.9007399082183838
Validation loss: 2.1519908020573277

Epoch: 6| Step: 5
Training loss: 2.121717929840088
Validation loss: 2.13633390139508

Epoch: 6| Step: 6
Training loss: 2.169059991836548
Validation loss: 2.1493688603883148

Epoch: 6| Step: 7
Training loss: 2.1612367630004883
Validation loss: 2.1087532940731255

Epoch: 6| Step: 8
Training loss: 2.009758472442627
Validation loss: 2.1508676826312976

Epoch: 6| Step: 9
Training loss: 2.179442882537842
Validation loss: 2.133817812447907

Epoch: 6| Step: 10
Training loss: 2.2479257583618164
Validation loss: 2.1548817209018174

Epoch: 6| Step: 11
Training loss: 1.6422758102416992
Validation loss: 2.1480446707817817

Epoch: 6| Step: 12
Training loss: 2.225163698196411
Validation loss: 2.0789996526574575

Epoch: 6| Step: 13
Training loss: 2.097795248031616
Validation loss: 2.0709297272466842

Epoch: 252| Step: 0
Training loss: 1.640972375869751
Validation loss: 2.041796027973134

Epoch: 6| Step: 1
Training loss: 1.6525887250900269
Validation loss: 2.1473847999367663

Epoch: 6| Step: 2
Training loss: 1.8947803974151611
Validation loss: 2.211663423045989

Epoch: 6| Step: 3
Training loss: 2.7091405391693115
Validation loss: 2.0612652840152865

Epoch: 6| Step: 4
Training loss: 2.360529899597168
Validation loss: 2.0442558360356156

Epoch: 6| Step: 5
Training loss: 1.9153919219970703
Validation loss: 2.129869008576998

Epoch: 6| Step: 6
Training loss: 2.672786235809326
Validation loss: 2.10751256122384

Epoch: 6| Step: 7
Training loss: 1.6375211477279663
Validation loss: 2.1344397375660558

Epoch: 6| Step: 8
Training loss: 1.4304450750350952
Validation loss: 2.079017810924079

Epoch: 6| Step: 9
Training loss: 2.1363296508789062
Validation loss: 2.0730111675877727

Epoch: 6| Step: 10
Training loss: 2.0143518447875977
Validation loss: 2.1039116767144974

Epoch: 6| Step: 11
Training loss: 2.503448963165283
Validation loss: 2.216783577396024

Epoch: 6| Step: 12
Training loss: 1.3800246715545654
Validation loss: 2.126560699555182

Epoch: 6| Step: 13
Training loss: 2.462695837020874
Validation loss: 2.0773239007560154

Epoch: 253| Step: 0
Training loss: 2.4416344165802
Validation loss: 2.082645212450335

Epoch: 6| Step: 1
Training loss: 1.9870414733886719
Validation loss: 2.0641248764530307

Epoch: 6| Step: 2
Training loss: 2.2287039756774902
Validation loss: 2.1728658855602307

Epoch: 6| Step: 3
Training loss: 1.907586693763733
Validation loss: 2.144553789528467

Epoch: 6| Step: 4
Training loss: 1.726218819618225
Validation loss: 2.113489476583337

Epoch: 6| Step: 5
Training loss: 1.9010206460952759
Validation loss: 2.1855286141877532

Epoch: 6| Step: 6
Training loss: 1.3859217166900635
Validation loss: 2.128096167759229

Epoch: 6| Step: 7
Training loss: 2.127559185028076
Validation loss: 2.1025394675552205

Epoch: 6| Step: 8
Training loss: 1.8616970777511597
Validation loss: 2.1651849644158476

Epoch: 6| Step: 9
Training loss: 1.8621137142181396
Validation loss: 2.164557392879199

Epoch: 6| Step: 10
Training loss: 2.2801311016082764
Validation loss: 2.0893768661765644

Epoch: 6| Step: 11
Training loss: 1.7878282070159912
Validation loss: 2.110057791074117

Epoch: 6| Step: 12
Training loss: 2.5165979862213135
Validation loss: 2.0980016621210242

Epoch: 6| Step: 13
Training loss: 1.6460673809051514
Validation loss: 2.085311723011796

Epoch: 254| Step: 0
Training loss: 1.712507724761963
Validation loss: 2.105578835292529

Epoch: 6| Step: 1
Training loss: 2.236104726791382
Validation loss: 2.147170615452592

Epoch: 6| Step: 2
Training loss: 2.7202391624450684
Validation loss: 2.0710545983365787

Epoch: 6| Step: 3
Training loss: 1.6330658197402954
Validation loss: 2.1470272592318955

Epoch: 6| Step: 4
Training loss: 1.3705158233642578
Validation loss: 2.173992686374213

Epoch: 6| Step: 5
Training loss: 2.8791871070861816
Validation loss: 2.126613963034845

Epoch: 6| Step: 6
Training loss: 1.863396167755127
Validation loss: 2.1647930427264144

Epoch: 6| Step: 7
Training loss: 1.7959263324737549
Validation loss: 2.122538806289755

Epoch: 6| Step: 8
Training loss: 1.6810178756713867
Validation loss: 2.076248353527438

Epoch: 6| Step: 9
Training loss: 2.178635597229004
Validation loss: 2.092372526404678

Epoch: 6| Step: 10
Training loss: 2.084632635116577
Validation loss: 2.151422426264773

Epoch: 6| Step: 11
Training loss: 1.5408467054367065
Validation loss: 2.115741152917185

Epoch: 6| Step: 12
Training loss: 2.458641529083252
Validation loss: 2.157489476665374

Epoch: 6| Step: 13
Training loss: 2.2284998893737793
Validation loss: 2.0702813389480754

Epoch: 255| Step: 0
Training loss: 2.099977493286133
Validation loss: 2.157950649979294

Epoch: 6| Step: 1
Training loss: 1.7704298496246338
Validation loss: 2.1258212097229494

Epoch: 6| Step: 2
Training loss: 1.449338436126709
Validation loss: 2.1393624300597818

Epoch: 6| Step: 3
Training loss: 1.4271161556243896
Validation loss: 2.143582428655317

Epoch: 6| Step: 4
Training loss: 2.3837690353393555
Validation loss: 2.1476290405437513

Epoch: 6| Step: 5
Training loss: 2.5115509033203125
Validation loss: 2.1568343383009716

Epoch: 6| Step: 6
Training loss: 1.5992603302001953
Validation loss: 2.1639104466284476

Epoch: 6| Step: 7
Training loss: 2.489489793777466
Validation loss: 2.1647171563999628

Epoch: 6| Step: 8
Training loss: 2.2449138164520264
Validation loss: 2.0974328210276942

Epoch: 6| Step: 9
Training loss: 1.821904182434082
Validation loss: 2.1549703792859147

Epoch: 6| Step: 10
Training loss: 2.115532398223877
Validation loss: 2.1396663060752292

Epoch: 6| Step: 11
Training loss: 1.7488633394241333
Validation loss: 2.1965309612212645

Epoch: 6| Step: 12
Training loss: 2.3453540802001953
Validation loss: 2.1946599265580535

Epoch: 6| Step: 13
Training loss: 2.5754969120025635
Validation loss: 2.193090451660977

Epoch: 256| Step: 0
Training loss: 2.3016788959503174
Validation loss: 2.1348550178671397

Epoch: 6| Step: 1
Training loss: 2.3080217838287354
Validation loss: 2.127095627528365

Epoch: 6| Step: 2
Training loss: 1.9785089492797852
Validation loss: 2.073916312186949

Epoch: 6| Step: 3
Training loss: 2.4269661903381348
Validation loss: 2.107119555114418

Epoch: 6| Step: 4
Training loss: 1.432157278060913
Validation loss: 2.105895480801982

Epoch: 6| Step: 5
Training loss: 2.781315803527832
Validation loss: 2.097524126370748

Epoch: 6| Step: 6
Training loss: 2.4806602001190186
Validation loss: 2.1437794316199517

Epoch: 6| Step: 7
Training loss: 1.7555649280548096
Validation loss: 2.1973618871422222

Epoch: 6| Step: 8
Training loss: 1.9058732986450195
Validation loss: 2.0586229267940728

Epoch: 6| Step: 9
Training loss: 1.2685390710830688
Validation loss: 2.1092965282419676

Epoch: 6| Step: 10
Training loss: 2.1426079273223877
Validation loss: 2.09889397569882

Epoch: 6| Step: 11
Training loss: 1.4512300491333008
Validation loss: 2.0225614963039273

Epoch: 6| Step: 12
Training loss: 2.218568801879883
Validation loss: 2.1149510824552147

Epoch: 6| Step: 13
Training loss: 1.9836926460266113
Validation loss: 2.149107784353277

Epoch: 257| Step: 0
Training loss: 1.1271543502807617
Validation loss: 2.183832460834134

Epoch: 6| Step: 1
Training loss: 1.7886744737625122
Validation loss: 2.064058501233337

Epoch: 6| Step: 2
Training loss: 2.361842632293701
Validation loss: 2.1175199682994554

Epoch: 6| Step: 3
Training loss: 2.1695752143859863
Validation loss: 2.111312081736903

Epoch: 6| Step: 4
Training loss: 1.4632041454315186
Validation loss: 2.1186915725790043

Epoch: 6| Step: 5
Training loss: 1.8885838985443115
Validation loss: 2.085032770710607

Epoch: 6| Step: 6
Training loss: 2.165365695953369
Validation loss: 2.068092297482234

Epoch: 6| Step: 7
Training loss: 3.0100579261779785
Validation loss: 2.104646785284883

Epoch: 6| Step: 8
Training loss: 1.8750016689300537
Validation loss: 2.143287040854013

Epoch: 6| Step: 9
Training loss: 2.2262985706329346
Validation loss: 2.1378637693261586

Epoch: 6| Step: 10
Training loss: 2.7070701122283936
Validation loss: 2.1579128414072017

Epoch: 6| Step: 11
Training loss: 1.9005415439605713
Validation loss: 2.2160516759400726

Epoch: 6| Step: 12
Training loss: 1.6146150827407837
Validation loss: 2.0642660215336788

Epoch: 6| Step: 13
Training loss: 1.7932794094085693
Validation loss: 2.1034513763202134

Epoch: 258| Step: 0
Training loss: 2.329556941986084
Validation loss: 2.101733951158421

Epoch: 6| Step: 1
Training loss: 2.606051206588745
Validation loss: 2.102976709283808

Epoch: 6| Step: 2
Training loss: 1.7401069402694702
Validation loss: 2.137606570797582

Epoch: 6| Step: 3
Training loss: 1.3320614099502563
Validation loss: 2.113835278377738

Epoch: 6| Step: 4
Training loss: 2.4770593643188477
Validation loss: 2.1268114838548886

Epoch: 6| Step: 5
Training loss: 1.4311254024505615
Validation loss: 2.2099714689357306

Epoch: 6| Step: 6
Training loss: 2.0138063430786133
Validation loss: 2.1213597097704486

Epoch: 6| Step: 7
Training loss: 1.2300350666046143
Validation loss: 2.101641280676729

Epoch: 6| Step: 8
Training loss: 3.1617188453674316
Validation loss: 2.036793114036642

Epoch: 6| Step: 9
Training loss: 2.0473122596740723
Validation loss: 2.1889197928931123

Epoch: 6| Step: 10
Training loss: 1.7339189052581787
Validation loss: 2.146025929399716

Epoch: 6| Step: 11
Training loss: 2.203742742538452
Validation loss: 2.1222399537281325

Epoch: 6| Step: 12
Training loss: 1.962796926498413
Validation loss: 2.081986645216583

Epoch: 6| Step: 13
Training loss: 1.2150434255599976
Validation loss: 2.069213819760148

Epoch: 259| Step: 0
Training loss: 1.9980696439743042
Validation loss: 2.154628033279091

Epoch: 6| Step: 1
Training loss: 2.717007875442505
Validation loss: 2.17000905159981

Epoch: 6| Step: 2
Training loss: 2.444988965988159
Validation loss: 2.083366414552094

Epoch: 6| Step: 3
Training loss: 1.6378092765808105
Validation loss: 2.0905626691797727

Epoch: 6| Step: 4
Training loss: 1.5440990924835205
Validation loss: 2.0470920429434827

Epoch: 6| Step: 5
Training loss: 1.394161581993103
Validation loss: 2.102880682996524

Epoch: 6| Step: 6
Training loss: 2.3011398315429688
Validation loss: 2.1535132264578216

Epoch: 6| Step: 7
Training loss: 1.754786491394043
Validation loss: 2.11498688626033

Epoch: 6| Step: 8
Training loss: 2.099508285522461
Validation loss: 2.0867693103769773

Epoch: 6| Step: 9
Training loss: 1.8581535816192627
Validation loss: 2.1475034785527054

Epoch: 6| Step: 10
Training loss: 2.0732955932617188
Validation loss: 2.1450174393192416

Epoch: 6| Step: 11
Training loss: 2.2721619606018066
Validation loss: 2.1059367823344406

Epoch: 6| Step: 12
Training loss: 1.5131123065948486
Validation loss: 2.168901886991275

Epoch: 6| Step: 13
Training loss: 2.2096049785614014
Validation loss: 2.145600844455022

Epoch: 260| Step: 0
Training loss: 2.307776927947998
Validation loss: 2.1762685327119726

Epoch: 6| Step: 1
Training loss: 2.4482524394989014
Validation loss: 2.1508787780679683

Epoch: 6| Step: 2
Training loss: 1.9415093660354614
Validation loss: 2.119723241816285

Epoch: 6| Step: 3
Training loss: 1.7451887130737305
Validation loss: 2.1488217461493706

Epoch: 6| Step: 4
Training loss: 1.8231488466262817
Validation loss: 2.094465764619971

Epoch: 6| Step: 5
Training loss: 2.052525758743286
Validation loss: 2.1648216016830935

Epoch: 6| Step: 6
Training loss: 2.415356397628784
Validation loss: 2.0911065134950864

Epoch: 6| Step: 7
Training loss: 1.668835997581482
Validation loss: 2.1100649692678966

Epoch: 6| Step: 8
Training loss: 2.0271549224853516
Validation loss: 2.145327170689901

Epoch: 6| Step: 9
Training loss: 1.7268002033233643
Validation loss: 2.165828457442663

Epoch: 6| Step: 10
Training loss: 1.6342710256576538
Validation loss: 2.152263331156905

Epoch: 6| Step: 11
Training loss: 2.389190196990967
Validation loss: 2.1295504134188414

Epoch: 6| Step: 12
Training loss: 1.9391576051712036
Validation loss: 2.0873018208370415

Epoch: 6| Step: 13
Training loss: 1.6139945983886719
Validation loss: 2.117947227211409

Epoch: 261| Step: 0
Training loss: 2.18333101272583
Validation loss: 2.017818461182297

Epoch: 6| Step: 1
Training loss: 2.215188980102539
Validation loss: 2.1861364713279148

Epoch: 6| Step: 2
Training loss: 2.333677291870117
Validation loss: 2.1575652425007155

Epoch: 6| Step: 3
Training loss: 1.2550240755081177
Validation loss: 2.16273533785215

Epoch: 6| Step: 4
Training loss: 3.0664615631103516
Validation loss: 2.1326784395402476

Epoch: 6| Step: 5
Training loss: 2.2593955993652344
Validation loss: 2.130505483637574

Epoch: 6| Step: 6
Training loss: 1.9942026138305664
Validation loss: 2.1277108576989945

Epoch: 6| Step: 7
Training loss: 2.0500307083129883
Validation loss: 2.105518335937172

Epoch: 6| Step: 8
Training loss: 1.4447704553604126
Validation loss: 2.1093627381068405

Epoch: 6| Step: 9
Training loss: 2.321640729904175
Validation loss: 2.1944944294550086

Epoch: 6| Step: 10
Training loss: 1.7395800352096558
Validation loss: 2.057504418075726

Epoch: 6| Step: 11
Training loss: 2.013249635696411
Validation loss: 2.108314184732335

Epoch: 6| Step: 12
Training loss: 1.5634362697601318
Validation loss: 2.2181313191690752

Epoch: 6| Step: 13
Training loss: 1.819704532623291
Validation loss: 2.109091797182637

Epoch: 262| Step: 0
Training loss: 1.9540441036224365
Validation loss: 2.0985939733443724

Epoch: 6| Step: 1
Training loss: 2.1935434341430664
Validation loss: 2.0950355042693434

Epoch: 6| Step: 2
Training loss: 2.1229522228240967
Validation loss: 2.088163255363382

Epoch: 6| Step: 3
Training loss: 2.3380932807922363
Validation loss: 2.1204566788929764

Epoch: 6| Step: 4
Training loss: 2.39947509765625
Validation loss: 2.080502994598881

Epoch: 6| Step: 5
Training loss: 1.7734829187393188
Validation loss: 2.1603015212602514

Epoch: 6| Step: 6
Training loss: 1.8114957809448242
Validation loss: 2.1444134417400567

Epoch: 6| Step: 7
Training loss: 1.3352980613708496
Validation loss: 2.149020471880513

Epoch: 6| Step: 8
Training loss: 2.4628701210021973
Validation loss: 2.1228187955835813

Epoch: 6| Step: 9
Training loss: 1.5914685726165771
Validation loss: 2.0970381382972962

Epoch: 6| Step: 10
Training loss: 2.274822473526001
Validation loss: 2.1447439578271683

Epoch: 6| Step: 11
Training loss: 1.702655553817749
Validation loss: 2.1143107824428107

Epoch: 6| Step: 12
Training loss: 2.411813735961914
Validation loss: 2.105029421467935

Epoch: 6| Step: 13
Training loss: 1.5113999843597412
Validation loss: 2.1112200316562446

Epoch: 263| Step: 0
Training loss: 2.2292423248291016
Validation loss: 2.0914671190323366

Epoch: 6| Step: 1
Training loss: 1.9115643501281738
Validation loss: 2.0860268710761942

Epoch: 6| Step: 2
Training loss: 2.4379124641418457
Validation loss: 2.123316826358918

Epoch: 6| Step: 3
Training loss: 1.6830053329467773
Validation loss: 2.0934205003964004

Epoch: 6| Step: 4
Training loss: 2.27163028717041
Validation loss: 2.136709770848674

Epoch: 6| Step: 5
Training loss: 1.5189664363861084
Validation loss: 2.111509152638015

Epoch: 6| Step: 6
Training loss: 2.55220365524292
Validation loss: 2.131546692181659

Epoch: 6| Step: 7
Training loss: 1.9558556079864502
Validation loss: 2.1209034817193144

Epoch: 6| Step: 8
Training loss: 1.3140970468521118
Validation loss: 2.1208179637949955

Epoch: 6| Step: 9
Training loss: 1.386794924736023
Validation loss: 2.108741752562984

Epoch: 6| Step: 10
Training loss: 2.1825852394104004
Validation loss: 2.0842721641704602

Epoch: 6| Step: 11
Training loss: 2.4562759399414062
Validation loss: 2.160081507057272

Epoch: 6| Step: 12
Training loss: 1.5504660606384277
Validation loss: 2.0929700636094615

Epoch: 6| Step: 13
Training loss: 2.8373758792877197
Validation loss: 2.1094433146138347

Epoch: 264| Step: 0
Training loss: 1.6287083625793457
Validation loss: 2.0926973204458914

Epoch: 6| Step: 1
Training loss: 2.0159645080566406
Validation loss: 2.105196883601527

Epoch: 6| Step: 2
Training loss: 2.131343126296997
Validation loss: 2.0913602716179303

Epoch: 6| Step: 3
Training loss: 2.5448484420776367
Validation loss: 2.083550476258801

Epoch: 6| Step: 4
Training loss: 1.7167350053787231
Validation loss: 2.1552211751220045

Epoch: 6| Step: 5
Training loss: 2.3562231063842773
Validation loss: 2.140519336987567

Epoch: 6| Step: 6
Training loss: 1.8405208587646484
Validation loss: 2.1541801883328344

Epoch: 6| Step: 7
Training loss: 2.2833080291748047
Validation loss: 2.0870605335440686

Epoch: 6| Step: 8
Training loss: 2.2869834899902344
Validation loss: 2.0610657430464223

Epoch: 6| Step: 9
Training loss: 1.4294538497924805
Validation loss: 2.1270750479031633

Epoch: 6| Step: 10
Training loss: 2.20574951171875
Validation loss: 2.108653745343608

Epoch: 6| Step: 11
Training loss: 1.9195590019226074
Validation loss: 2.0718448879898235

Epoch: 6| Step: 12
Training loss: 2.2572145462036133
Validation loss: 2.1436963773542836

Epoch: 6| Step: 13
Training loss: 1.598982572555542
Validation loss: 2.0498786767323813

Epoch: 265| Step: 0
Training loss: 1.713625192642212
Validation loss: 2.1473907155375325

Epoch: 6| Step: 1
Training loss: 2.2407729625701904
Validation loss: 2.1380049900342057

Epoch: 6| Step: 2
Training loss: 1.64823579788208
Validation loss: 2.1147990636928107

Epoch: 6| Step: 3
Training loss: 1.9219110012054443
Validation loss: 2.109019330752793

Epoch: 6| Step: 4
Training loss: 2.153397560119629
Validation loss: 2.0582717900635092

Epoch: 6| Step: 5
Training loss: 1.7646379470825195
Validation loss: 2.1252969336766068

Epoch: 6| Step: 6
Training loss: 2.2770867347717285
Validation loss: 2.065129003217143

Epoch: 6| Step: 7
Training loss: 1.7418713569641113
Validation loss: 2.1733502931492303

Epoch: 6| Step: 8
Training loss: 2.5845746994018555
Validation loss: 2.1480099257602485

Epoch: 6| Step: 9
Training loss: 2.327850341796875
Validation loss: 2.154229502524099

Epoch: 6| Step: 10
Training loss: 1.6189919710159302
Validation loss: 2.127593242993919

Epoch: 6| Step: 11
Training loss: 2.3687400817871094
Validation loss: 2.1298602319532827

Epoch: 6| Step: 12
Training loss: 2.1983022689819336
Validation loss: 2.1984187428669264

Epoch: 6| Step: 13
Training loss: 2.3104820251464844
Validation loss: 2.101242567903252

Epoch: 266| Step: 0
Training loss: 1.971354365348816
Validation loss: 2.0729350082335936

Epoch: 6| Step: 1
Training loss: 2.184504985809326
Validation loss: 2.1434478913584063

Epoch: 6| Step: 2
Training loss: 2.1239359378814697
Validation loss: 2.1663727170677594

Epoch: 6| Step: 3
Training loss: 0.8557900190353394
Validation loss: 2.1729463941307476

Epoch: 6| Step: 4
Training loss: 2.5661780834198
Validation loss: 2.1131227952177807

Epoch: 6| Step: 5
Training loss: 2.1929399967193604
Validation loss: 2.162273291618593

Epoch: 6| Step: 6
Training loss: 1.876311182975769
Validation loss: 2.163256986166841

Epoch: 6| Step: 7
Training loss: 1.780328392982483
Validation loss: 2.144196633369692

Epoch: 6| Step: 8
Training loss: 1.8278210163116455
Validation loss: 2.1351552201855566

Epoch: 6| Step: 9
Training loss: 1.563383936882019
Validation loss: 2.08863571382338

Epoch: 6| Step: 10
Training loss: 2.398045063018799
Validation loss: 2.095107704080561

Epoch: 6| Step: 11
Training loss: 1.679868221282959
Validation loss: 2.093418898121003

Epoch: 6| Step: 12
Training loss: 2.443958282470703
Validation loss: 2.129175296393774

Epoch: 6| Step: 13
Training loss: 1.9412659406661987
Validation loss: 2.1788485050201416

Epoch: 267| Step: 0
Training loss: 1.4578920602798462
Validation loss: 2.1127060818415817

Epoch: 6| Step: 1
Training loss: 2.0710034370422363
Validation loss: 2.1495972756416566

Epoch: 6| Step: 2
Training loss: 2.030344009399414
Validation loss: 2.0611511097159436

Epoch: 6| Step: 3
Training loss: 2.715471029281616
Validation loss: 2.126302570425054

Epoch: 6| Step: 4
Training loss: 1.547763705253601
Validation loss: 2.0953097958718576

Epoch: 6| Step: 5
Training loss: 1.6231191158294678
Validation loss: 2.100335927419765

Epoch: 6| Step: 6
Training loss: 1.6123875379562378
Validation loss: 2.173223856956728

Epoch: 6| Step: 7
Training loss: 2.913266658782959
Validation loss: 2.140385643128426

Epoch: 6| Step: 8
Training loss: 1.897573709487915
Validation loss: 2.129117704206897

Epoch: 6| Step: 9
Training loss: 1.8309340476989746
Validation loss: 2.1293886194946947

Epoch: 6| Step: 10
Training loss: 1.5384893417358398
Validation loss: 2.1382404399174515

Epoch: 6| Step: 11
Training loss: 2.086258888244629
Validation loss: 2.1606658581764466

Epoch: 6| Step: 12
Training loss: 2.4326577186584473
Validation loss: 2.1170713850246963

Epoch: 6| Step: 13
Training loss: 2.1002752780914307
Validation loss: 2.1742038572988203

Epoch: 268| Step: 0
Training loss: 2.525509834289551
Validation loss: 2.1711666430196455

Epoch: 6| Step: 1
Training loss: 1.8833039999008179
Validation loss: 2.1249293588822886

Epoch: 6| Step: 2
Training loss: 2.611154556274414
Validation loss: 2.174763992268552

Epoch: 6| Step: 3
Training loss: 2.4969677925109863
Validation loss: 2.1317709133189213

Epoch: 6| Step: 4
Training loss: 1.379673957824707
Validation loss: 2.0771941215761247

Epoch: 6| Step: 5
Training loss: 2.398118019104004
Validation loss: 2.142718102342339

Epoch: 6| Step: 6
Training loss: 2.6636219024658203
Validation loss: 2.0409118436997935

Epoch: 6| Step: 7
Training loss: 1.724628210067749
Validation loss: 2.002321722686932

Epoch: 6| Step: 8
Training loss: 1.8460229635238647
Validation loss: 2.064847405238818

Epoch: 6| Step: 9
Training loss: 2.1265435218811035
Validation loss: 2.1113809167697863

Epoch: 6| Step: 10
Training loss: 1.3487319946289062
Validation loss: 2.1412273068581857

Epoch: 6| Step: 11
Training loss: 1.252683401107788
Validation loss: 2.212399464781566

Epoch: 6| Step: 12
Training loss: 1.6655666828155518
Validation loss: 2.1231755723235426

Epoch: 6| Step: 13
Training loss: 1.7424159049987793
Validation loss: 2.1157772118045437

Epoch: 269| Step: 0
Training loss: 2.080523729324341
Validation loss: 2.133126897196616

Epoch: 6| Step: 1
Training loss: 1.2733722925186157
Validation loss: 2.1737506492163545

Epoch: 6| Step: 2
Training loss: 2.878885507583618
Validation loss: 2.13965606176725

Epoch: 6| Step: 3
Training loss: 1.4621578454971313
Validation loss: 2.1755634418097873

Epoch: 6| Step: 4
Training loss: 1.703772783279419
Validation loss: 2.1258004865338727

Epoch: 6| Step: 5
Training loss: 2.2520735263824463
Validation loss: 2.0966966818737727

Epoch: 6| Step: 6
Training loss: 1.4382778406143188
Validation loss: 2.0662101084186184

Epoch: 6| Step: 7
Training loss: 2.270359516143799
Validation loss: 2.0840347249020814

Epoch: 6| Step: 8
Training loss: 1.9586715698242188
Validation loss: 2.062428659008395

Epoch: 6| Step: 9
Training loss: 1.6859245300292969
Validation loss: 2.1445823484851467

Epoch: 6| Step: 10
Training loss: 2.1633172035217285
Validation loss: 2.126794010080317

Epoch: 6| Step: 11
Training loss: 2.336092233657837
Validation loss: 2.1026483351184475

Epoch: 6| Step: 12
Training loss: 1.6539932489395142
Validation loss: 2.1069291740335445

Epoch: 6| Step: 13
Training loss: 1.83542001247406
Validation loss: 2.0047312154564807

Epoch: 270| Step: 0
Training loss: 1.4783053398132324
Validation loss: 2.083454103880031

Epoch: 6| Step: 1
Training loss: 2.2390217781066895
Validation loss: 2.142504234467783

Epoch: 6| Step: 2
Training loss: 1.880219578742981
Validation loss: 2.089853225215789

Epoch: 6| Step: 3
Training loss: 2.057299852371216
Validation loss: 2.09391942972778

Epoch: 6| Step: 4
Training loss: 1.6304688453674316
Validation loss: 2.1107734518666423

Epoch: 6| Step: 5
Training loss: 2.314746379852295
Validation loss: 2.1411961752881288

Epoch: 6| Step: 6
Training loss: 1.7937915325164795
Validation loss: 2.0656426927094818

Epoch: 6| Step: 7
Training loss: 1.992408275604248
Validation loss: 2.102406121069385

Epoch: 6| Step: 8
Training loss: 1.7111234664916992
Validation loss: 2.104748705381988

Epoch: 6| Step: 9
Training loss: 2.516519069671631
Validation loss: 2.2019740355912076

Epoch: 6| Step: 10
Training loss: 2.3476738929748535
Validation loss: 2.1635433678985923

Epoch: 6| Step: 11
Training loss: 2.2142767906188965
Validation loss: 2.146605130164854

Epoch: 6| Step: 12
Training loss: 2.229797124862671
Validation loss: 2.0899073205968386

Epoch: 6| Step: 13
Training loss: 1.5203291177749634
Validation loss: 2.193272388109597

Epoch: 271| Step: 0
Training loss: 2.5338664054870605
Validation loss: 2.10039545002804

Epoch: 6| Step: 1
Training loss: 2.6743550300598145
Validation loss: 2.1649643823664677

Epoch: 6| Step: 2
Training loss: 1.7823991775512695
Validation loss: 2.1729192861946682

Epoch: 6| Step: 3
Training loss: 1.461118221282959
Validation loss: 2.223355254819316

Epoch: 6| Step: 4
Training loss: 1.7668554782867432
Validation loss: 2.18326654741841

Epoch: 6| Step: 5
Training loss: 2.5803909301757812
Validation loss: 2.1548648675282798

Epoch: 6| Step: 6
Training loss: 1.998450756072998
Validation loss: 2.1295698496603195

Epoch: 6| Step: 7
Training loss: 2.002263307571411
Validation loss: 2.225389611336493

Epoch: 6| Step: 8
Training loss: 1.9274626970291138
Validation loss: 2.0744120869585263

Epoch: 6| Step: 9
Training loss: 1.6314547061920166
Validation loss: 2.0249894742042787

Epoch: 6| Step: 10
Training loss: 2.0391831398010254
Validation loss: 2.1605580340149584

Epoch: 6| Step: 11
Training loss: 1.937283992767334
Validation loss: 2.1287553502667333

Epoch: 6| Step: 12
Training loss: 1.8283843994140625
Validation loss: 2.0908259371275544

Epoch: 6| Step: 13
Training loss: 1.9520848989486694
Validation loss: 2.084830040572792

Epoch: 272| Step: 0
Training loss: 2.246678590774536
Validation loss: 2.1475013738037436

Epoch: 6| Step: 1
Training loss: 1.9345695972442627
Validation loss: 2.152901759711645

Epoch: 6| Step: 2
Training loss: 2.604464292526245
Validation loss: 2.1210943652737524

Epoch: 6| Step: 3
Training loss: 1.8376505374908447
Validation loss: 2.188279897935929

Epoch: 6| Step: 4
Training loss: 1.6540170907974243
Validation loss: 2.1438010764378372

Epoch: 6| Step: 5
Training loss: 2.2248330116271973
Validation loss: 2.218161367600964

Epoch: 6| Step: 6
Training loss: 1.7952637672424316
Validation loss: 2.06146579147667

Epoch: 6| Step: 7
Training loss: 1.7746797800064087
Validation loss: 2.1840672800617833

Epoch: 6| Step: 8
Training loss: 1.8815728425979614
Validation loss: 2.1498511299010246

Epoch: 6| Step: 9
Training loss: 2.2623343467712402
Validation loss: 2.1493629255602436

Epoch: 6| Step: 10
Training loss: 1.7743756771087646
Validation loss: 2.0892939362474667

Epoch: 6| Step: 11
Training loss: 2.5482287406921387
Validation loss: 2.0679877278625325

Epoch: 6| Step: 12
Training loss: 1.980654001235962
Validation loss: 2.1551939479766355

Epoch: 6| Step: 13
Training loss: 1.388837456703186
Validation loss: 2.180130920102519

Epoch: 273| Step: 0
Training loss: 1.7796876430511475
Validation loss: 2.071661221083774

Epoch: 6| Step: 1
Training loss: 2.624680519104004
Validation loss: 2.11662011120909

Epoch: 6| Step: 2
Training loss: 2.090526580810547
Validation loss: 2.0854065572061846

Epoch: 6| Step: 3
Training loss: 1.9642770290374756
Validation loss: 2.1272807044367634

Epoch: 6| Step: 4
Training loss: 1.9026217460632324
Validation loss: 2.0977788458588305

Epoch: 6| Step: 5
Training loss: 1.7341125011444092
Validation loss: 2.0495377843097975

Epoch: 6| Step: 6
Training loss: 2.0359156131744385
Validation loss: 2.0580124265404156

Epoch: 6| Step: 7
Training loss: 1.26613187789917
Validation loss: 2.1149867234691495

Epoch: 6| Step: 8
Training loss: 2.396697998046875
Validation loss: 2.0484321322492374

Epoch: 6| Step: 9
Training loss: 0.9061309099197388
Validation loss: 2.138060421072027

Epoch: 6| Step: 10
Training loss: 2.467362880706787
Validation loss: 2.06173720154711

Epoch: 6| Step: 11
Training loss: 2.642542839050293
Validation loss: 2.1398188426930416

Epoch: 6| Step: 12
Training loss: 2.2913684844970703
Validation loss: 2.0349500307472805

Epoch: 6| Step: 13
Training loss: 1.7663919925689697
Validation loss: 2.1077805924159225

Epoch: 274| Step: 0
Training loss: 2.2841074466705322
Validation loss: 2.113089225625479

Epoch: 6| Step: 1
Training loss: 2.735506057739258
Validation loss: 2.1116338263275805

Epoch: 6| Step: 2
Training loss: 1.854370355606079
Validation loss: 2.110840912788145

Epoch: 6| Step: 3
Training loss: 2.234670877456665
Validation loss: 2.1157834017148582

Epoch: 6| Step: 4
Training loss: 2.202747106552124
Validation loss: 2.1524081794164514

Epoch: 6| Step: 5
Training loss: 1.681616187095642
Validation loss: 2.0316560986221477

Epoch: 6| Step: 6
Training loss: 1.969483494758606
Validation loss: 2.127372408425936

Epoch: 6| Step: 7
Training loss: 1.9060304164886475
Validation loss: 2.111975733951856

Epoch: 6| Step: 8
Training loss: 1.634838581085205
Validation loss: 2.068008538215391

Epoch: 6| Step: 9
Training loss: 2.17334246635437
Validation loss: 2.1469522753069477

Epoch: 6| Step: 10
Training loss: 1.184921145439148
Validation loss: 2.1581126669401764

Epoch: 6| Step: 11
Training loss: 1.515108585357666
Validation loss: 2.09355648615027

Epoch: 6| Step: 12
Training loss: 1.90565025806427
Validation loss: 2.0988646322681057

Epoch: 6| Step: 13
Training loss: 1.9702777862548828
Validation loss: 2.0973456675006497

Epoch: 275| Step: 0
Training loss: 1.9408912658691406
Validation loss: 2.070869054845584

Epoch: 6| Step: 1
Training loss: 2.050286293029785
Validation loss: 2.120387036313293

Epoch: 6| Step: 2
Training loss: 1.6747386455535889
Validation loss: 2.184619644636749

Epoch: 6| Step: 3
Training loss: 1.9704833030700684
Validation loss: 2.194028639024304

Epoch: 6| Step: 4
Training loss: 1.7021713256835938
Validation loss: 2.134858872300835

Epoch: 6| Step: 5
Training loss: 1.9881393909454346
Validation loss: 2.135403431871886

Epoch: 6| Step: 6
Training loss: 1.9072725772857666
Validation loss: 2.1402980384006294

Epoch: 6| Step: 7
Training loss: 1.9786076545715332
Validation loss: 2.1334387192162136

Epoch: 6| Step: 8
Training loss: 2.044440746307373
Validation loss: 2.08336748871752

Epoch: 6| Step: 9
Training loss: 2.255613327026367
Validation loss: 2.0739307634292112

Epoch: 6| Step: 10
Training loss: 1.631589412689209
Validation loss: 2.1437763731966735

Epoch: 6| Step: 11
Training loss: 1.910017728805542
Validation loss: 2.080603264993237

Epoch: 6| Step: 12
Training loss: 1.9440747499465942
Validation loss: 2.147275963137227

Epoch: 6| Step: 13
Training loss: 2.08048677444458
Validation loss: 2.1724748290995115

Epoch: 276| Step: 0
Training loss: 1.7647881507873535
Validation loss: 2.1254361419267553

Epoch: 6| Step: 1
Training loss: 1.787211537361145
Validation loss: 2.0842751969573317

Epoch: 6| Step: 2
Training loss: 1.278478980064392
Validation loss: 2.1131875502165927

Epoch: 6| Step: 3
Training loss: 1.6242530345916748
Validation loss: 2.0788099099231023

Epoch: 6| Step: 4
Training loss: 1.8837014436721802
Validation loss: 2.0926605065663657

Epoch: 6| Step: 5
Training loss: 1.7115216255187988
Validation loss: 2.1005854401537167

Epoch: 6| Step: 6
Training loss: 2.1328482627868652
Validation loss: 2.1694117515317854

Epoch: 6| Step: 7
Training loss: 2.133082628250122
Validation loss: 2.12782306824961

Epoch: 6| Step: 8
Training loss: 2.7454352378845215
Validation loss: 2.103536782726165

Epoch: 6| Step: 9
Training loss: 1.697597622871399
Validation loss: 2.0580927761652137

Epoch: 6| Step: 10
Training loss: 1.8748998641967773
Validation loss: 2.1631245972007833

Epoch: 6| Step: 11
Training loss: 2.0662174224853516
Validation loss: 2.134196842870405

Epoch: 6| Step: 12
Training loss: 3.022454261779785
Validation loss: 2.149719991991597

Epoch: 6| Step: 13
Training loss: 1.6593897342681885
Validation loss: 2.1000935441704205

Epoch: 277| Step: 0
Training loss: 2.1447482109069824
Validation loss: 2.1365508981930312

Epoch: 6| Step: 1
Training loss: 2.696382999420166
Validation loss: 2.149978119839904

Epoch: 6| Step: 2
Training loss: 2.6362266540527344
Validation loss: 2.1753893283105667

Epoch: 6| Step: 3
Training loss: 1.6464736461639404
Validation loss: 2.1559537661972867

Epoch: 6| Step: 4
Training loss: 1.813022255897522
Validation loss: 2.076936606437929

Epoch: 6| Step: 5
Training loss: 2.094209909439087
Validation loss: 2.116180831386197

Epoch: 6| Step: 6
Training loss: 1.76918625831604
Validation loss: 2.1222902472301195

Epoch: 6| Step: 7
Training loss: 1.942873239517212
Validation loss: 2.140202300522917

Epoch: 6| Step: 8
Training loss: 2.3448421955108643
Validation loss: 2.1804583764845327

Epoch: 6| Step: 9
Training loss: 1.3523058891296387
Validation loss: 2.193146969682427

Epoch: 6| Step: 10
Training loss: 1.5133378505706787
Validation loss: 2.1211085447701077

Epoch: 6| Step: 11
Training loss: 1.7524523735046387
Validation loss: 2.0920063910945768

Epoch: 6| Step: 12
Training loss: 1.8072651624679565
Validation loss: 2.169372107392998

Epoch: 6| Step: 13
Training loss: 2.0236434936523438
Validation loss: 2.163657478106919

Epoch: 278| Step: 0
Training loss: 1.4028871059417725
Validation loss: 2.173127592250865

Epoch: 6| Step: 1
Training loss: 1.7416359186172485
Validation loss: 2.1410999785187426

Epoch: 6| Step: 2
Training loss: 3.0833258628845215
Validation loss: 2.153490069091961

Epoch: 6| Step: 3
Training loss: 1.5268490314483643
Validation loss: 2.189414717817819

Epoch: 6| Step: 4
Training loss: 2.0196049213409424
Validation loss: 2.204210900491284

Epoch: 6| Step: 5
Training loss: 2.2085890769958496
Validation loss: 2.192393065780722

Epoch: 6| Step: 6
Training loss: 1.6492353677749634
Validation loss: 2.1533917944918395

Epoch: 6| Step: 7
Training loss: 2.5640177726745605
Validation loss: 2.155200533969428

Epoch: 6| Step: 8
Training loss: 1.8989506959915161
Validation loss: 2.138129770114858

Epoch: 6| Step: 9
Training loss: 2.1439318656921387
Validation loss: 2.0616433466634443

Epoch: 6| Step: 10
Training loss: 1.5687462091445923
Validation loss: 2.044554924452177

Epoch: 6| Step: 11
Training loss: 1.5841727256774902
Validation loss: 2.1444989506916334

Epoch: 6| Step: 12
Training loss: 2.5640869140625
Validation loss: 2.1892804253485894

Epoch: 6| Step: 13
Training loss: 2.0671567916870117
Validation loss: 2.0685501944634224

Epoch: 279| Step: 0
Training loss: 2.1818246841430664
Validation loss: 2.1719484662496917

Epoch: 6| Step: 1
Training loss: 1.9745206832885742
Validation loss: 2.1166809451195503

Epoch: 6| Step: 2
Training loss: 1.6997475624084473
Validation loss: 2.104038726898932

Epoch: 6| Step: 3
Training loss: 2.1796813011169434
Validation loss: 2.040970653615972

Epoch: 6| Step: 4
Training loss: 2.051438808441162
Validation loss: 2.0923513802148963

Epoch: 6| Step: 5
Training loss: 1.63958740234375
Validation loss: 2.0722822476458806

Epoch: 6| Step: 6
Training loss: 1.6177138090133667
Validation loss: 2.181586866737694

Epoch: 6| Step: 7
Training loss: 1.834476351737976
Validation loss: 2.136167800554665

Epoch: 6| Step: 8
Training loss: 2.2191250324249268
Validation loss: 2.0643842938125774

Epoch: 6| Step: 9
Training loss: 2.1678643226623535
Validation loss: 2.121152740652843

Epoch: 6| Step: 10
Training loss: 2.2626211643218994
Validation loss: 2.1013922460617556

Epoch: 6| Step: 11
Training loss: 1.8818084001541138
Validation loss: 2.124737670344691

Epoch: 6| Step: 12
Training loss: 2.71299409866333
Validation loss: 2.1594348697252173

Epoch: 6| Step: 13
Training loss: 1.2119371891021729
Validation loss: 2.0765630878427976

Epoch: 280| Step: 0
Training loss: 1.697249412536621
Validation loss: 2.1155057132885022

Epoch: 6| Step: 1
Training loss: 1.6918374300003052
Validation loss: 2.156436686874718

Epoch: 6| Step: 2
Training loss: 2.425110101699829
Validation loss: 2.1312762357855357

Epoch: 6| Step: 3
Training loss: 2.1965363025665283
Validation loss: 2.148531606120448

Epoch: 6| Step: 4
Training loss: 1.4964959621429443
Validation loss: 2.135091079178677

Epoch: 6| Step: 5
Training loss: 1.9703700542449951
Validation loss: 2.138347989769392

Epoch: 6| Step: 6
Training loss: 2.51739501953125
Validation loss: 2.0635306886447373

Epoch: 6| Step: 7
Training loss: 1.8765732049942017
Validation loss: 2.1125346460650043

Epoch: 6| Step: 8
Training loss: 1.902672290802002
Validation loss: 2.1535001365087365

Epoch: 6| Step: 9
Training loss: 1.8704110383987427
Validation loss: 2.1095897997579267

Epoch: 6| Step: 10
Training loss: 1.465900182723999
Validation loss: 2.094176951275077

Epoch: 6| Step: 11
Training loss: 2.1284892559051514
Validation loss: 2.076445319319284

Epoch: 6| Step: 12
Training loss: 1.5884249210357666
Validation loss: 2.119376036428636

Epoch: 6| Step: 13
Training loss: 3.030649423599243
Validation loss: 2.138610780880015

Epoch: 281| Step: 0
Training loss: 2.4652366638183594
Validation loss: 2.076172677419519

Epoch: 6| Step: 1
Training loss: 2.2842330932617188
Validation loss: 2.1558111995779057

Epoch: 6| Step: 2
Training loss: 1.8810147047042847
Validation loss: 2.098667380630329

Epoch: 6| Step: 3
Training loss: 1.9558448791503906
Validation loss: 2.0923945250049716

Epoch: 6| Step: 4
Training loss: 2.171243190765381
Validation loss: 2.103698222867904

Epoch: 6| Step: 5
Training loss: 2.14785099029541
Validation loss: 2.12130412491419

Epoch: 6| Step: 6
Training loss: 2.0384132862091064
Validation loss: 2.0482716021999234

Epoch: 6| Step: 7
Training loss: 2.825800657272339
Validation loss: 2.182446534915637

Epoch: 6| Step: 8
Training loss: 1.7895652055740356
Validation loss: 2.1736966576627506

Epoch: 6| Step: 9
Training loss: 1.7194491624832153
Validation loss: 2.1149799849397395

Epoch: 6| Step: 10
Training loss: 1.659430980682373
Validation loss: 2.122106590578633

Epoch: 6| Step: 11
Training loss: 1.456231713294983
Validation loss: 2.1816626095002696

Epoch: 6| Step: 12
Training loss: 1.2316334247589111
Validation loss: 2.1367484087585122

Epoch: 6| Step: 13
Training loss: 1.8384795188903809
Validation loss: 2.072819653377738

Epoch: 282| Step: 0
Training loss: 1.637761116027832
Validation loss: 2.142348212580527

Epoch: 6| Step: 1
Training loss: 0.8682148456573486
Validation loss: 2.1245448461142917

Epoch: 6| Step: 2
Training loss: 2.0080695152282715
Validation loss: 2.160155939799483

Epoch: 6| Step: 3
Training loss: 2.145477294921875
Validation loss: 2.200883665392476

Epoch: 6| Step: 4
Training loss: 1.6182955503463745
Validation loss: 2.122849387507285

Epoch: 6| Step: 5
Training loss: 2.428983688354492
Validation loss: 2.1844921419697423

Epoch: 6| Step: 6
Training loss: 1.6475917100906372
Validation loss: 2.1659940981095835

Epoch: 6| Step: 7
Training loss: 2.135006904602051
Validation loss: 2.0770274669893327

Epoch: 6| Step: 8
Training loss: 2.3617806434631348
Validation loss: 2.1392444513177358

Epoch: 6| Step: 9
Training loss: 2.802318572998047
Validation loss: 2.134355169470592

Epoch: 6| Step: 10
Training loss: 1.5004421472549438
Validation loss: 2.089964682056058

Epoch: 6| Step: 11
Training loss: 2.3312292098999023
Validation loss: 2.0905107939115135

Epoch: 6| Step: 12
Training loss: 2.085775136947632
Validation loss: 2.2476756675269014

Epoch: 6| Step: 13
Training loss: 1.7184159755706787
Validation loss: 2.1859070485638035

Epoch: 283| Step: 0
Training loss: 1.469062089920044
Validation loss: 2.1165811118259223

Epoch: 6| Step: 1
Training loss: 1.8476192951202393
Validation loss: 2.1234692950402536

Epoch: 6| Step: 2
Training loss: 1.3632397651672363
Validation loss: 2.1756375707605833

Epoch: 6| Step: 3
Training loss: 2.150801658630371
Validation loss: 2.174934902498799

Epoch: 6| Step: 4
Training loss: 1.8993632793426514
Validation loss: 2.050054625798297

Epoch: 6| Step: 5
Training loss: 1.4466962814331055
Validation loss: 2.0645401298358874

Epoch: 6| Step: 6
Training loss: 2.6534676551818848
Validation loss: 2.1077467869686823

Epoch: 6| Step: 7
Training loss: 1.8685979843139648
Validation loss: 2.108566850744268

Epoch: 6| Step: 8
Training loss: 2.789027214050293
Validation loss: 2.118127102492958

Epoch: 6| Step: 9
Training loss: 1.6557048559188843
Validation loss: 2.053680848049861

Epoch: 6| Step: 10
Training loss: 2.1956279277801514
Validation loss: 2.1115356337639595

Epoch: 6| Step: 11
Training loss: 2.4233908653259277
Validation loss: 2.06880174913714

Epoch: 6| Step: 12
Training loss: 1.6723628044128418
Validation loss: 2.105684172722601

Epoch: 6| Step: 13
Training loss: 2.7704367637634277
Validation loss: 2.119616021392166

Epoch: 284| Step: 0
Training loss: 2.636099338531494
Validation loss: 2.088732668148574

Epoch: 6| Step: 1
Training loss: 2.434581756591797
Validation loss: 2.1067315750224616

Epoch: 6| Step: 2
Training loss: 2.166074275970459
Validation loss: 2.111849977124122

Epoch: 6| Step: 3
Training loss: 2.3489866256713867
Validation loss: 2.175564273711174

Epoch: 6| Step: 4
Training loss: 1.3479052782058716
Validation loss: 2.168635706747732

Epoch: 6| Step: 5
Training loss: 2.1632986068725586
Validation loss: 2.1099322290830713

Epoch: 6| Step: 6
Training loss: 2.1990432739257812
Validation loss: 2.230589105236915

Epoch: 6| Step: 7
Training loss: 2.4193766117095947
Validation loss: 2.1227238306435208

Epoch: 6| Step: 8
Training loss: 1.3683475255966187
Validation loss: 2.101038343162947

Epoch: 6| Step: 9
Training loss: 2.0616202354431152
Validation loss: 2.1163802992913032

Epoch: 6| Step: 10
Training loss: 1.9595928192138672
Validation loss: 2.115240575164877

Epoch: 6| Step: 11
Training loss: 1.384386658668518
Validation loss: 2.0632805747370564

Epoch: 6| Step: 12
Training loss: 2.001347541809082
Validation loss: 2.1187871143382084

Epoch: 6| Step: 13
Training loss: 1.1338156461715698
Validation loss: 2.18115899896109

Epoch: 285| Step: 0
Training loss: 1.8828508853912354
Validation loss: 2.1302428860818186

Epoch: 6| Step: 1
Training loss: 2.162932872772217
Validation loss: 2.106854987400834

Epoch: 6| Step: 2
Training loss: 1.7084652185440063
Validation loss: 2.1391833623250327

Epoch: 6| Step: 3
Training loss: 2.029038906097412
Validation loss: 2.1370313334208664

Epoch: 6| Step: 4
Training loss: 2.003859281539917
Validation loss: 2.0820993351679977

Epoch: 6| Step: 5
Training loss: 2.3327317237854004
Validation loss: 2.175841018717776

Epoch: 6| Step: 6
Training loss: 1.5495762825012207
Validation loss: 2.1415156907932733

Epoch: 6| Step: 7
Training loss: 2.1942310333251953
Validation loss: 2.2073320624648884

Epoch: 6| Step: 8
Training loss: 2.06992769241333
Validation loss: 2.1142055501220045

Epoch: 6| Step: 9
Training loss: 1.3738913536071777
Validation loss: 2.050275633412023

Epoch: 6| Step: 10
Training loss: 3.0243606567382812
Validation loss: 2.1781967468159174

Epoch: 6| Step: 11
Training loss: 1.6826691627502441
Validation loss: 2.120067237525858

Epoch: 6| Step: 12
Training loss: 2.0780751705169678
Validation loss: 2.1352538754863124

Epoch: 6| Step: 13
Training loss: 1.8294713497161865
Validation loss: 2.128366111427225

Epoch: 286| Step: 0
Training loss: 1.9580048322677612
Validation loss: 2.125338731273528

Epoch: 6| Step: 1
Training loss: 1.994845986366272
Validation loss: 2.1452567269725185

Epoch: 6| Step: 2
Training loss: 1.3091243505477905
Validation loss: 2.128841620619579

Epoch: 6| Step: 3
Training loss: 1.9556591510772705
Validation loss: 2.1477392488910305

Epoch: 6| Step: 4
Training loss: 2.6697378158569336
Validation loss: 2.1368187332666047

Epoch: 6| Step: 5
Training loss: 1.6512846946716309
Validation loss: 2.119172780744491

Epoch: 6| Step: 6
Training loss: 3.2053000926971436
Validation loss: 2.1578629644968177

Epoch: 6| Step: 7
Training loss: 2.6046576499938965
Validation loss: 2.164338555387271

Epoch: 6| Step: 8
Training loss: 1.6841130256652832
Validation loss: 2.2101161146676667

Epoch: 6| Step: 9
Training loss: 1.824671983718872
Validation loss: 2.1530308518358456

Epoch: 6| Step: 10
Training loss: 1.609525203704834
Validation loss: 2.1589327614794493

Epoch: 6| Step: 11
Training loss: 1.8010411262512207
Validation loss: 2.1540268005863314

Epoch: 6| Step: 12
Training loss: 1.674675464630127
Validation loss: 2.1401634626491095

Epoch: 6| Step: 13
Training loss: 1.573689579963684
Validation loss: 2.0826715807760916

Epoch: 287| Step: 0
Training loss: 2.0662894248962402
Validation loss: 2.18920450697663

Epoch: 6| Step: 1
Training loss: 1.973573088645935
Validation loss: 2.1443080235553045

Epoch: 6| Step: 2
Training loss: 1.603050708770752
Validation loss: 2.1324476785557245

Epoch: 6| Step: 3
Training loss: 2.271177291870117
Validation loss: 2.078352746143136

Epoch: 6| Step: 4
Training loss: 1.70125150680542
Validation loss: 2.146597562297698

Epoch: 6| Step: 5
Training loss: 2.148331880569458
Validation loss: 2.1222459859745477

Epoch: 6| Step: 6
Training loss: 1.9411852359771729
Validation loss: 2.151293698177543

Epoch: 6| Step: 7
Training loss: 1.4387011528015137
Validation loss: 2.084208632028231

Epoch: 6| Step: 8
Training loss: 2.154287099838257
Validation loss: 2.1676649931938416

Epoch: 6| Step: 9
Training loss: 1.5600091218948364
Validation loss: 2.168168899833515

Epoch: 6| Step: 10
Training loss: 1.8517696857452393
Validation loss: 2.062342838574481

Epoch: 6| Step: 11
Training loss: 2.4205257892608643
Validation loss: 2.0557667888620847

Epoch: 6| Step: 12
Training loss: 2.354827404022217
Validation loss: 2.107483793330449

Epoch: 6| Step: 13
Training loss: 2.4073824882507324
Validation loss: 2.0727115138884513

Epoch: 288| Step: 0
Training loss: 1.6470905542373657
Validation loss: 2.039355239560527

Epoch: 6| Step: 1
Training loss: 1.3963346481323242
Validation loss: 2.118118473278579

Epoch: 6| Step: 2
Training loss: 1.887528896331787
Validation loss: 2.0898348721124793

Epoch: 6| Step: 3
Training loss: 1.7523915767669678
Validation loss: 2.031716287776988

Epoch: 6| Step: 4
Training loss: 1.954782485961914
Validation loss: 2.135039112901175

Epoch: 6| Step: 5
Training loss: 1.6518632173538208
Validation loss: 2.2001405710815103

Epoch: 6| Step: 6
Training loss: 2.730140209197998
Validation loss: 2.0760467372914797

Epoch: 6| Step: 7
Training loss: 2.302426815032959
Validation loss: 2.024802170773988

Epoch: 6| Step: 8
Training loss: 1.804985761642456
Validation loss: 2.071369445452126

Epoch: 6| Step: 9
Training loss: 2.361809730529785
Validation loss: 2.1564734879360405

Epoch: 6| Step: 10
Training loss: 1.8128349781036377
Validation loss: 2.1349614525354035

Epoch: 6| Step: 11
Training loss: 2.1656854152679443
Validation loss: 2.1058847224840553

Epoch: 6| Step: 12
Training loss: 2.0839879512786865
Validation loss: 2.160553591225737

Epoch: 6| Step: 13
Training loss: 1.5543694496154785
Validation loss: 2.0647019622146443

Epoch: 289| Step: 0
Training loss: 1.9734867811203003
Validation loss: 2.1319895585378013

Epoch: 6| Step: 1
Training loss: 1.4502711296081543
Validation loss: 2.1386841445840816

Epoch: 6| Step: 2
Training loss: 1.371552586555481
Validation loss: 2.1403421919832946

Epoch: 6| Step: 3
Training loss: 2.184591293334961
Validation loss: 2.0881088472181752

Epoch: 6| Step: 4
Training loss: 2.096827983856201
Validation loss: 2.0732946677874495

Epoch: 6| Step: 5
Training loss: 2.333115577697754
Validation loss: 2.1383117975727206

Epoch: 6| Step: 6
Training loss: 1.9962611198425293
Validation loss: 2.087683698182465

Epoch: 6| Step: 7
Training loss: 2.1212306022644043
Validation loss: 2.0795891156760593

Epoch: 6| Step: 8
Training loss: 2.1064648628234863
Validation loss: 2.0772482092662523

Epoch: 6| Step: 9
Training loss: 2.3503384590148926
Validation loss: 2.2051422724159817

Epoch: 6| Step: 10
Training loss: 2.2388968467712402
Validation loss: 2.078315181116904

Epoch: 6| Step: 11
Training loss: 2.3607213497161865
Validation loss: 2.109256434184249

Epoch: 6| Step: 12
Training loss: 1.830540657043457
Validation loss: 2.2096246980851695

Epoch: 6| Step: 13
Training loss: 1.5346952676773071
Validation loss: 2.200416277813655

Epoch: 290| Step: 0
Training loss: 2.6349470615386963
Validation loss: 2.1897796405259

Epoch: 6| Step: 1
Training loss: 1.4987547397613525
Validation loss: 2.1691712858856365

Epoch: 6| Step: 2
Training loss: 2.1596224308013916
Validation loss: 2.0555863918796664

Epoch: 6| Step: 3
Training loss: 2.0921308994293213
Validation loss: 2.079619756308935

Epoch: 6| Step: 4
Training loss: 1.7549426555633545
Validation loss: 2.111914309122229

Epoch: 6| Step: 5
Training loss: 1.4221220016479492
Validation loss: 2.147989111561929

Epoch: 6| Step: 6
Training loss: 1.4968616962432861
Validation loss: 2.137658311474708

Epoch: 6| Step: 7
Training loss: 1.5860955715179443
Validation loss: 2.094381520825048

Epoch: 6| Step: 8
Training loss: 1.3772995471954346
Validation loss: 2.1366670029137724

Epoch: 6| Step: 9
Training loss: 2.8875739574432373
Validation loss: 2.1611183138303858

Epoch: 6| Step: 10
Training loss: 1.9470274448394775
Validation loss: 2.111454011291586

Epoch: 6| Step: 11
Training loss: 2.2387959957122803
Validation loss: 2.1726701695431947

Epoch: 6| Step: 12
Training loss: 1.4602174758911133
Validation loss: 2.177697717502553

Epoch: 6| Step: 13
Training loss: 2.132887363433838
Validation loss: 2.133766037161632

Epoch: 291| Step: 0
Training loss: 1.2588756084442139
Validation loss: 2.148531761220706

Epoch: 6| Step: 1
Training loss: 1.6461502313613892
Validation loss: 2.094716595065209

Epoch: 6| Step: 2
Training loss: 2.2834463119506836
Validation loss: 2.1835528419863794

Epoch: 6| Step: 3
Training loss: 1.9964900016784668
Validation loss: 2.0521123101634364

Epoch: 6| Step: 4
Training loss: 1.36572265625
Validation loss: 2.043087767016503

Epoch: 6| Step: 5
Training loss: 2.1780154705047607
Validation loss: 2.040183257031184

Epoch: 6| Step: 6
Training loss: 1.1854534149169922
Validation loss: 2.135285641557427

Epoch: 6| Step: 7
Training loss: 2.069606304168701
Validation loss: 2.117811614467252

Epoch: 6| Step: 8
Training loss: 2.6110424995422363
Validation loss: 2.0962490061277985

Epoch: 6| Step: 9
Training loss: 2.147601842880249
Validation loss: 2.063875226564305

Epoch: 6| Step: 10
Training loss: 2.4343249797821045
Validation loss: 2.1912154459184214

Epoch: 6| Step: 11
Training loss: 2.0062355995178223
Validation loss: 2.0484723839708554

Epoch: 6| Step: 12
Training loss: 1.5245243310928345
Validation loss: 2.1485841684443976

Epoch: 6| Step: 13
Training loss: 2.2438759803771973
Validation loss: 2.144842727209932

Epoch: 292| Step: 0
Training loss: 1.8985902070999146
Validation loss: 2.051333878629951

Epoch: 6| Step: 1
Training loss: 2.0583484172821045
Validation loss: 2.102227589135529

Epoch: 6| Step: 2
Training loss: 1.3490428924560547
Validation loss: 2.0745839226630425

Epoch: 6| Step: 3
Training loss: 2.383122444152832
Validation loss: 2.1090828052131076

Epoch: 6| Step: 4
Training loss: 1.8780508041381836
Validation loss: 2.116665094129501

Epoch: 6| Step: 5
Training loss: 2.012749671936035
Validation loss: 2.213164206474058

Epoch: 6| Step: 6
Training loss: 1.4093961715698242
Validation loss: 2.0842065875248244

Epoch: 6| Step: 7
Training loss: 2.292743682861328
Validation loss: 2.2583886577237036

Epoch: 6| Step: 8
Training loss: 1.8247257471084595
Validation loss: 2.169422713659143

Epoch: 6| Step: 9
Training loss: 2.208864212036133
Validation loss: 2.1065443869559997

Epoch: 6| Step: 10
Training loss: 1.6299800872802734
Validation loss: 2.096355137004647

Epoch: 6| Step: 11
Training loss: 1.6576309204101562
Validation loss: 2.131744255301773

Epoch: 6| Step: 12
Training loss: 2.4056191444396973
Validation loss: 2.0840510732384137

Epoch: 6| Step: 13
Training loss: 2.3855974674224854
Validation loss: 2.107465690182101

Epoch: 293| Step: 0
Training loss: 1.801323413848877
Validation loss: 2.0905412268894974

Epoch: 6| Step: 1
Training loss: 2.1333048343658447
Validation loss: 2.1747378008339995

Epoch: 6| Step: 2
Training loss: 2.1369709968566895
Validation loss: 2.1908805703604095

Epoch: 6| Step: 3
Training loss: 2.1321496963500977
Validation loss: 2.063976242978086

Epoch: 6| Step: 4
Training loss: 1.8098900318145752
Validation loss: 2.095550278181671

Epoch: 6| Step: 5
Training loss: 2.26517915725708
Validation loss: 2.0803072247453915

Epoch: 6| Step: 6
Training loss: 1.4898680448532104
Validation loss: 2.1296170834572083

Epoch: 6| Step: 7
Training loss: 1.842639684677124
Validation loss: 2.2504287560780845

Epoch: 6| Step: 8
Training loss: 2.0522332191467285
Validation loss: 2.1133020488164758

Epoch: 6| Step: 9
Training loss: 2.551372766494751
Validation loss: 2.1500162668125604

Epoch: 6| Step: 10
Training loss: 1.747079610824585
Validation loss: 2.160456031881353

Epoch: 6| Step: 11
Training loss: 1.7443166971206665
Validation loss: 2.132362063213061

Epoch: 6| Step: 12
Training loss: 1.7786173820495605
Validation loss: 2.1046753801325315

Epoch: 6| Step: 13
Training loss: 1.4254580736160278
Validation loss: 2.1054791224900113

Epoch: 294| Step: 0
Training loss: 2.6532135009765625
Validation loss: 2.1369796940075454

Epoch: 6| Step: 1
Training loss: 1.4386012554168701
Validation loss: 2.152890051564863

Epoch: 6| Step: 2
Training loss: 2.0067427158355713
Validation loss: 2.11508959339511

Epoch: 6| Step: 3
Training loss: 1.762694239616394
Validation loss: 2.16432459251855

Epoch: 6| Step: 4
Training loss: 1.654647707939148
Validation loss: 2.1236245683444444

Epoch: 6| Step: 5
Training loss: 1.822508454322815
Validation loss: 2.14257828650936

Epoch: 6| Step: 6
Training loss: 2.504336357116699
Validation loss: 2.1239971806926112

Epoch: 6| Step: 7
Training loss: 1.6650559902191162
Validation loss: 2.1086189362310592

Epoch: 6| Step: 8
Training loss: 1.9817007780075073
Validation loss: 2.150546896842218

Epoch: 6| Step: 9
Training loss: 1.5295939445495605
Validation loss: 2.1532589773977957

Epoch: 6| Step: 10
Training loss: 2.0003342628479004
Validation loss: 2.1865327896610385

Epoch: 6| Step: 11
Training loss: 2.4929890632629395
Validation loss: 2.1827169490116898

Epoch: 6| Step: 12
Training loss: 1.5635895729064941
Validation loss: 2.1903539024373537

Epoch: 6| Step: 13
Training loss: 1.5274766683578491
Validation loss: 2.1530934379946802

Epoch: 295| Step: 0
Training loss: 1.8080461025238037
Validation loss: 2.1835999078648065

Epoch: 6| Step: 1
Training loss: 1.6871066093444824
Validation loss: 2.131949217088761

Epoch: 6| Step: 2
Training loss: 1.6954339742660522
Validation loss: 2.2254097179699968

Epoch: 6| Step: 3
Training loss: 1.759284257888794
Validation loss: 2.1650073092470885

Epoch: 6| Step: 4
Training loss: 2.039585590362549
Validation loss: 2.179640166221126

Epoch: 6| Step: 5
Training loss: 2.2043259143829346
Validation loss: 2.108495726380297

Epoch: 6| Step: 6
Training loss: 2.0710678100585938
Validation loss: 2.097788573593222

Epoch: 6| Step: 7
Training loss: 1.6821166276931763
Validation loss: 2.110355310542609

Epoch: 6| Step: 8
Training loss: 3.229954242706299
Validation loss: 2.0924064202975203

Epoch: 6| Step: 9
Training loss: 1.9368014335632324
Validation loss: 2.1757389037839827

Epoch: 6| Step: 10
Training loss: 2.0094821453094482
Validation loss: 2.1586741016757105

Epoch: 6| Step: 11
Training loss: 1.4317086935043335
Validation loss: 2.1645342021860103

Epoch: 6| Step: 12
Training loss: 1.9345173835754395
Validation loss: 2.1486236126192155

Epoch: 6| Step: 13
Training loss: 2.07466983795166
Validation loss: 2.1564708012406544

Epoch: 296| Step: 0
Training loss: 2.2531495094299316
Validation loss: 2.157612230188103

Epoch: 6| Step: 1
Training loss: 1.0987818241119385
Validation loss: 2.1924055942925076

Epoch: 6| Step: 2
Training loss: 1.9055016040802002
Validation loss: 2.1569420586350145

Epoch: 6| Step: 3
Training loss: 2.0769269466400146
Validation loss: 2.068521556033883

Epoch: 6| Step: 4
Training loss: 2.483402729034424
Validation loss: 2.048737915613318

Epoch: 6| Step: 5
Training loss: 1.427410364151001
Validation loss: 2.113367654943979

Epoch: 6| Step: 6
Training loss: 2.0843894481658936
Validation loss: 2.1169666167228454

Epoch: 6| Step: 7
Training loss: 1.548614740371704
Validation loss: 2.145723066022319

Epoch: 6| Step: 8
Training loss: 2.295698642730713
Validation loss: 2.1460121472676597

Epoch: 6| Step: 9
Training loss: 1.7149666547775269
Validation loss: 2.1973106938023723

Epoch: 6| Step: 10
Training loss: 2.5327863693237305
Validation loss: 2.125242546040525

Epoch: 6| Step: 11
Training loss: 1.9835634231567383
Validation loss: 2.05457365769212

Epoch: 6| Step: 12
Training loss: 1.6595373153686523
Validation loss: 2.160286973881465

Epoch: 6| Step: 13
Training loss: 2.110927104949951
Validation loss: 2.137477413300545

Epoch: 297| Step: 0
Training loss: 1.6918575763702393
Validation loss: 2.1668285605727986

Epoch: 6| Step: 1
Training loss: 2.0979204177856445
Validation loss: 2.1553690792411886

Epoch: 6| Step: 2
Training loss: 1.7165729999542236
Validation loss: 2.097073619083692

Epoch: 6| Step: 3
Training loss: 1.997319221496582
Validation loss: 2.132502576356293

Epoch: 6| Step: 4
Training loss: 2.0369129180908203
Validation loss: 2.100894897214828

Epoch: 6| Step: 5
Training loss: 1.955043077468872
Validation loss: 2.162994659075173

Epoch: 6| Step: 6
Training loss: 1.4333274364471436
Validation loss: 2.080167555039929

Epoch: 6| Step: 7
Training loss: 2.0592193603515625
Validation loss: 2.051811954026581

Epoch: 6| Step: 8
Training loss: 2.0475668907165527
Validation loss: 2.1131202738772155

Epoch: 6| Step: 9
Training loss: 1.930379867553711
Validation loss: 2.137448920998522

Epoch: 6| Step: 10
Training loss: 2.2305514812469482
Validation loss: 2.092717996207617

Epoch: 6| Step: 11
Training loss: 1.43756103515625
Validation loss: 2.0865513227319203

Epoch: 6| Step: 12
Training loss: 2.6235365867614746
Validation loss: 2.195894791233924

Epoch: 6| Step: 13
Training loss: 2.0784904956817627
Validation loss: 2.106977169231702

Epoch: 298| Step: 0
Training loss: 1.4294949769973755
Validation loss: 2.1243493223703034

Epoch: 6| Step: 1
Training loss: 2.219259738922119
Validation loss: 2.107800534976426

Epoch: 6| Step: 2
Training loss: 1.8201411962509155
Validation loss: 2.142670669863301

Epoch: 6| Step: 3
Training loss: 1.9798012971878052
Validation loss: 2.14266901118781

Epoch: 6| Step: 4
Training loss: 1.178075909614563
Validation loss: 2.1200647918126916

Epoch: 6| Step: 5
Training loss: 2.052927017211914
Validation loss: 2.1431587793493785

Epoch: 6| Step: 6
Training loss: 2.310469627380371
Validation loss: 2.151596784591675

Epoch: 6| Step: 7
Training loss: 2.536442518234253
Validation loss: 2.1400052911491803

Epoch: 6| Step: 8
Training loss: 1.3039681911468506
Validation loss: 2.095918457995179

Epoch: 6| Step: 9
Training loss: 1.8288471698760986
Validation loss: 2.187369567091747

Epoch: 6| Step: 10
Training loss: 2.9904346466064453
Validation loss: 2.128106023675652

Epoch: 6| Step: 11
Training loss: 1.943343162536621
Validation loss: 2.1183705868259555

Epoch: 6| Step: 12
Training loss: 1.9707849025726318
Validation loss: 2.1454716010760237

Epoch: 6| Step: 13
Training loss: 1.628275752067566
Validation loss: 2.136603986063311

Epoch: 299| Step: 0
Training loss: 1.5360409021377563
Validation loss: 2.140895382050545

Epoch: 6| Step: 1
Training loss: 2.289623737335205
Validation loss: 2.1513306363936393

Epoch: 6| Step: 2
Training loss: 2.3576745986938477
Validation loss: 2.108623786639142

Epoch: 6| Step: 3
Training loss: 1.9794397354125977
Validation loss: 2.2124245192414973

Epoch: 6| Step: 4
Training loss: 1.9818360805511475
Validation loss: 2.1407500607993013

Epoch: 6| Step: 5
Training loss: 2.3660383224487305
Validation loss: 2.0368451790143083

Epoch: 6| Step: 6
Training loss: 2.1475515365600586
Validation loss: 2.2492010388323056

Epoch: 6| Step: 7
Training loss: 2.2953057289123535
Validation loss: 2.085415317166236

Epoch: 6| Step: 8
Training loss: 1.0478687286376953
Validation loss: 2.0764209685787076

Epoch: 6| Step: 9
Training loss: 1.751936674118042
Validation loss: 2.130092377303749

Epoch: 6| Step: 10
Training loss: 1.7781150341033936
Validation loss: 2.1161088123116443

Epoch: 6| Step: 11
Training loss: 1.6260671615600586
Validation loss: 2.0471107934110906

Epoch: 6| Step: 12
Training loss: 1.876274585723877
Validation loss: 2.115139040895688

Epoch: 6| Step: 13
Training loss: 2.6115434169769287
Validation loss: 2.114048824515394

Epoch: 300| Step: 0
Training loss: 1.6668133735656738
Validation loss: 2.1409560326606996

Epoch: 6| Step: 1
Training loss: 2.1204850673675537
Validation loss: 2.1357287847867577

Epoch: 6| Step: 2
Training loss: 1.574437141418457
Validation loss: 2.178853269546263

Epoch: 6| Step: 3
Training loss: 2.3395450115203857
Validation loss: 2.0143563516678347

Epoch: 6| Step: 4
Training loss: 1.891421914100647
Validation loss: 2.146512649392569

Epoch: 6| Step: 5
Training loss: 1.979774832725525
Validation loss: 2.112881552788519

Epoch: 6| Step: 6
Training loss: 1.7636547088623047
Validation loss: 2.1185007069700506

Epoch: 6| Step: 7
Training loss: 1.993517279624939
Validation loss: 2.088159006129029

Epoch: 6| Step: 8
Training loss: 1.5021101236343384
Validation loss: 2.1143907270123883

Epoch: 6| Step: 9
Training loss: 2.7142333984375
Validation loss: 2.0564040304512106

Epoch: 6| Step: 10
Training loss: 2.6960694789886475
Validation loss: 2.045922153739519

Epoch: 6| Step: 11
Training loss: 1.2279012203216553
Validation loss: 2.1568655429347867

Epoch: 6| Step: 12
Training loss: 2.1135897636413574
Validation loss: 2.1171357900865617

Epoch: 6| Step: 13
Training loss: 1.080578327178955
Validation loss: 2.121952099184836

Epoch: 301| Step: 0
Training loss: 2.215601682662964
Validation loss: 2.146639903386434

Epoch: 6| Step: 1
Training loss: 1.9305049180984497
Validation loss: 2.1345678503795336

Epoch: 6| Step: 2
Training loss: 1.7259151935577393
Validation loss: 2.2356947980901247

Epoch: 6| Step: 3
Training loss: 1.727257490158081
Validation loss: 2.090873254242764

Epoch: 6| Step: 4
Training loss: 2.336351156234741
Validation loss: 2.136222416354764

Epoch: 6| Step: 5
Training loss: 2.282996892929077
Validation loss: 2.169356876803983

Epoch: 6| Step: 6
Training loss: 1.4635717868804932
Validation loss: 2.2201506835158153

Epoch: 6| Step: 7
Training loss: 2.0527052879333496
Validation loss: 2.1565078099568686

Epoch: 6| Step: 8
Training loss: 1.880937099456787
Validation loss: 2.1370052188955326

Epoch: 6| Step: 9
Training loss: 2.0076208114624023
Validation loss: 2.1888922209380777

Epoch: 6| Step: 10
Training loss: 1.8040149211883545
Validation loss: 2.0978352472346318

Epoch: 6| Step: 11
Training loss: 1.5239747762680054
Validation loss: 2.1326438509007937

Epoch: 6| Step: 12
Training loss: 1.636023759841919
Validation loss: 2.1922857197382117

Epoch: 6| Step: 13
Training loss: 2.37668514251709
Validation loss: 2.1728746609021257

Epoch: 302| Step: 0
Training loss: 1.9983561038970947
Validation loss: 2.203708561517859

Epoch: 6| Step: 1
Training loss: 2.1982007026672363
Validation loss: 2.1047053606279436

Epoch: 6| Step: 2
Training loss: 1.7280926704406738
Validation loss: 2.1168657015728694

Epoch: 6| Step: 3
Training loss: 2.306366205215454
Validation loss: 2.1478780174768097

Epoch: 6| Step: 4
Training loss: 1.55183744430542
Validation loss: 2.1789482152590187

Epoch: 6| Step: 5
Training loss: 1.847078800201416
Validation loss: 2.2041460801196355

Epoch: 6| Step: 6
Training loss: 2.012434959411621
Validation loss: 2.1346855637847737

Epoch: 6| Step: 7
Training loss: 1.970710277557373
Validation loss: 2.060331836823494

Epoch: 6| Step: 8
Training loss: 1.7378323078155518
Validation loss: 2.0720347025061168

Epoch: 6| Step: 9
Training loss: 2.6551597118377686
Validation loss: 2.1188294041541313

Epoch: 6| Step: 10
Training loss: 1.3252859115600586
Validation loss: 2.0406460505659862

Epoch: 6| Step: 11
Training loss: 1.7378978729248047
Validation loss: 2.126039271713585

Epoch: 6| Step: 12
Training loss: 1.6459318399429321
Validation loss: 2.1283232909376903

Epoch: 6| Step: 13
Training loss: 2.9799811840057373
Validation loss: 2.1322753967777377

Epoch: 303| Step: 0
Training loss: 1.4436063766479492
Validation loss: 2.2442102816797074

Epoch: 6| Step: 1
Training loss: 2.290815830230713
Validation loss: 2.0682886595367105

Epoch: 6| Step: 2
Training loss: 1.4461898803710938
Validation loss: 2.06757088117702

Epoch: 6| Step: 3
Training loss: 1.5422132015228271
Validation loss: 2.1316265034419235

Epoch: 6| Step: 4
Training loss: 1.7535443305969238
Validation loss: 2.180781126022339

Epoch: 6| Step: 5
Training loss: 2.3559110164642334
Validation loss: 2.1331098797500774

Epoch: 6| Step: 6
Training loss: 1.7043743133544922
Validation loss: 2.1086035351599417

Epoch: 6| Step: 7
Training loss: 2.2761754989624023
Validation loss: 2.2041244301744687

Epoch: 6| Step: 8
Training loss: 1.8165785074234009
Validation loss: 2.237475679766747

Epoch: 6| Step: 9
Training loss: 2.0560264587402344
Validation loss: 2.1700494750853507

Epoch: 6| Step: 10
Training loss: 2.124527931213379
Validation loss: 2.164748054678722

Epoch: 6| Step: 11
Training loss: 1.483416199684143
Validation loss: 2.2515790847039994

Epoch: 6| Step: 12
Training loss: 2.5548624992370605
Validation loss: 2.188366882262691

Epoch: 6| Step: 13
Training loss: 1.9214376211166382
Validation loss: 2.152296627721479

Epoch: 304| Step: 0
Training loss: 1.4645206928253174
Validation loss: 2.2088836469957904

Epoch: 6| Step: 1
Training loss: 2.614910125732422
Validation loss: 2.126635411734222

Epoch: 6| Step: 2
Training loss: 1.581578016281128
Validation loss: 2.1520129839579263

Epoch: 6| Step: 3
Training loss: 2.0828030109405518
Validation loss: 2.1120218743560133

Epoch: 6| Step: 4
Training loss: 2.3667538166046143
Validation loss: 2.138750894095308

Epoch: 6| Step: 5
Training loss: 1.6434824466705322
Validation loss: 2.07446115504029

Epoch: 6| Step: 6
Training loss: 1.3912525177001953
Validation loss: 2.174076170049688

Epoch: 6| Step: 7
Training loss: 1.5591226816177368
Validation loss: 2.1164150391855547

Epoch: 6| Step: 8
Training loss: 1.3715771436691284
Validation loss: 2.1377012447644304

Epoch: 6| Step: 9
Training loss: 2.5904409885406494
Validation loss: 2.1321649243754726

Epoch: 6| Step: 10
Training loss: 2.1143486499786377
Validation loss: 2.1268200271873066

Epoch: 6| Step: 11
Training loss: 2.5574371814727783
Validation loss: 2.144948083867309

Epoch: 6| Step: 12
Training loss: 1.9780356884002686
Validation loss: 2.100486450297858

Epoch: 6| Step: 13
Training loss: 1.2447994947433472
Validation loss: 2.063126253825362

Epoch: 305| Step: 0
Training loss: 1.7420300245285034
Validation loss: 2.155923271691927

Epoch: 6| Step: 1
Training loss: 2.3063316345214844
Validation loss: 2.1515069648783696

Epoch: 6| Step: 2
Training loss: 1.692971110343933
Validation loss: 2.162848522586207

Epoch: 6| Step: 3
Training loss: 2.0897812843322754
Validation loss: 2.143781074913599

Epoch: 6| Step: 4
Training loss: 2.064606189727783
Validation loss: 2.1876737045985397

Epoch: 6| Step: 5
Training loss: 1.4292429685592651
Validation loss: 2.0882067680358887

Epoch: 6| Step: 6
Training loss: 1.7637594938278198
Validation loss: 2.1367660260969594

Epoch: 6| Step: 7
Training loss: 1.497615933418274
Validation loss: 2.147034006734048

Epoch: 6| Step: 8
Training loss: 1.7949059009552002
Validation loss: 2.0788734997472456

Epoch: 6| Step: 9
Training loss: 1.366882085800171
Validation loss: 2.1510422075948408

Epoch: 6| Step: 10
Training loss: 1.7435822486877441
Validation loss: 2.1822831656343196

Epoch: 6| Step: 11
Training loss: 2.1252434253692627
Validation loss: 2.1846445119509132

Epoch: 6| Step: 12
Training loss: 3.056332588195801
Validation loss: 2.1507095957315094

Epoch: 6| Step: 13
Training loss: 2.001383066177368
Validation loss: 2.174997898840135

Epoch: 306| Step: 0
Training loss: 1.8639743328094482
Validation loss: 2.1401397053913405

Epoch: 6| Step: 1
Training loss: 2.816159248352051
Validation loss: 2.1533753461735223

Epoch: 6| Step: 2
Training loss: 1.2777471542358398
Validation loss: 2.0986382525454284

Epoch: 6| Step: 3
Training loss: 1.9467507600784302
Validation loss: 2.196520034984876

Epoch: 6| Step: 4
Training loss: 1.2621643543243408
Validation loss: 2.134140896540816

Epoch: 6| Step: 5
Training loss: 2.2468838691711426
Validation loss: 2.1412657383949525

Epoch: 6| Step: 6
Training loss: 1.71089768409729
Validation loss: 2.077949495725734

Epoch: 6| Step: 7
Training loss: 1.573314905166626
Validation loss: 2.109734196816721

Epoch: 6| Step: 8
Training loss: 2.066859006881714
Validation loss: 2.1118514114810574

Epoch: 6| Step: 9
Training loss: 2.2541189193725586
Validation loss: 2.101468942498648

Epoch: 6| Step: 10
Training loss: 1.6996314525604248
Validation loss: 1.9902663282168809

Epoch: 6| Step: 11
Training loss: 1.5024253129959106
Validation loss: 2.080662958083614

Epoch: 6| Step: 12
Training loss: 1.867636799812317
Validation loss: 2.093030152782317

Epoch: 6| Step: 13
Training loss: 2.8289637565612793
Validation loss: 2.087184565041655

Epoch: 307| Step: 0
Training loss: 1.5531591176986694
Validation loss: 2.16659685104124

Epoch: 6| Step: 1
Training loss: 2.1616945266723633
Validation loss: 2.140875768917863

Epoch: 6| Step: 2
Training loss: 1.4945080280303955
Validation loss: 2.1345269756932415

Epoch: 6| Step: 3
Training loss: 2.1150455474853516
Validation loss: 2.1661218673952165

Epoch: 6| Step: 4
Training loss: 2.11383056640625
Validation loss: 2.068657580242362

Epoch: 6| Step: 5
Training loss: 2.3410258293151855
Validation loss: 2.102692555355769

Epoch: 6| Step: 6
Training loss: 2.2666478157043457
Validation loss: 2.093224743361114

Epoch: 6| Step: 7
Training loss: 1.7633613348007202
Validation loss: 2.0820998337961014

Epoch: 6| Step: 8
Training loss: 1.5057194232940674
Validation loss: 2.182603928350633

Epoch: 6| Step: 9
Training loss: 1.52100670337677
Validation loss: 2.2266395681647846

Epoch: 6| Step: 10
Training loss: 2.0421206951141357
Validation loss: 2.201049244532021

Epoch: 6| Step: 11
Training loss: 1.855173110961914
Validation loss: 2.1311065548209736

Epoch: 6| Step: 12
Training loss: 1.6689311265945435
Validation loss: 2.1925736678543912

Epoch: 6| Step: 13
Training loss: 2.6396896839141846
Validation loss: 2.1036214290126676

Epoch: 308| Step: 0
Training loss: 1.595180869102478
Validation loss: 2.164337327403407

Epoch: 6| Step: 1
Training loss: 2.7161614894866943
Validation loss: 2.192511986660701

Epoch: 6| Step: 2
Training loss: 1.6924883127212524
Validation loss: 2.1196702244461223

Epoch: 6| Step: 3
Training loss: 2.5264034271240234
Validation loss: 2.162618629394039

Epoch: 6| Step: 4
Training loss: 1.8206144571304321
Validation loss: 2.1452962249837895

Epoch: 6| Step: 5
Training loss: 1.6323304176330566
Validation loss: 2.136640441033148

Epoch: 6| Step: 6
Training loss: 1.9163830280303955
Validation loss: 2.1842570420234435

Epoch: 6| Step: 7
Training loss: 1.659208059310913
Validation loss: 2.1604822553614134

Epoch: 6| Step: 8
Training loss: 1.7004740238189697
Validation loss: 2.031782786051432

Epoch: 6| Step: 9
Training loss: 2.38828706741333
Validation loss: 2.1044131440501057

Epoch: 6| Step: 10
Training loss: 1.4471909999847412
Validation loss: 2.181275278009394

Epoch: 6| Step: 11
Training loss: 1.7250324487686157
Validation loss: 2.1715370865278345

Epoch: 6| Step: 12
Training loss: 1.9477756023406982
Validation loss: 2.1550873453899095

Epoch: 6| Step: 13
Training loss: 1.6097850799560547
Validation loss: 2.0483778189587336

Epoch: 309| Step: 0
Training loss: 2.16054630279541
Validation loss: 2.0551489963326404

Epoch: 6| Step: 1
Training loss: 1.8447691202163696
Validation loss: 2.1311065432845906

Epoch: 6| Step: 2
Training loss: 1.851027250289917
Validation loss: 2.13017136948083

Epoch: 6| Step: 3
Training loss: 1.8633646965026855
Validation loss: 2.119771252396286

Epoch: 6| Step: 4
Training loss: 1.4590697288513184
Validation loss: 2.191174543032082

Epoch: 6| Step: 5
Training loss: 1.4788658618927002
Validation loss: 2.1016152135787474

Epoch: 6| Step: 6
Training loss: 2.0354623794555664
Validation loss: 2.1522056466789654

Epoch: 6| Step: 7
Training loss: 2.313337802886963
Validation loss: 2.1112620304989558

Epoch: 6| Step: 8
Training loss: 1.909074306488037
Validation loss: 2.1100145719384633

Epoch: 6| Step: 9
Training loss: 2.2619636058807373
Validation loss: 2.0278013777989212

Epoch: 6| Step: 10
Training loss: 2.067563533782959
Validation loss: 2.1402998291036135

Epoch: 6| Step: 11
Training loss: 2.424975633621216
Validation loss: 2.1360407926703013

Epoch: 6| Step: 12
Training loss: 1.602542519569397
Validation loss: 2.1388546882137174

Epoch: 6| Step: 13
Training loss: 1.4429306983947754
Validation loss: 2.157764511723672

Epoch: 310| Step: 0
Training loss: 2.735830783843994
Validation loss: 2.1371397331196773

Epoch: 6| Step: 1
Training loss: 1.3721396923065186
Validation loss: 2.1111409741063274

Epoch: 6| Step: 2
Training loss: 1.3461793661117554
Validation loss: 2.142174369545393

Epoch: 6| Step: 3
Training loss: 1.5156588554382324
Validation loss: 2.094447317943778

Epoch: 6| Step: 4
Training loss: 1.8428442478179932
Validation loss: 2.1065871279726744

Epoch: 6| Step: 5
Training loss: 3.257923126220703
Validation loss: 2.250501102016818

Epoch: 6| Step: 6
Training loss: 1.9027035236358643
Validation loss: 2.2141844918650966

Epoch: 6| Step: 7
Training loss: 1.7357655763626099
Validation loss: 2.180727656169604

Epoch: 6| Step: 8
Training loss: 1.5776951313018799
Validation loss: 2.1904939682252946

Epoch: 6| Step: 9
Training loss: 1.646482229232788
Validation loss: 2.163465953642322

Epoch: 6| Step: 10
Training loss: 2.0213871002197266
Validation loss: 2.122684412105109

Epoch: 6| Step: 11
Training loss: 1.827951192855835
Validation loss: 2.108749025611467

Epoch: 6| Step: 12
Training loss: 1.8247392177581787
Validation loss: 2.1200215585770144

Epoch: 6| Step: 13
Training loss: 2.4869673252105713
Validation loss: 2.140811763783937

Epoch: 311| Step: 0
Training loss: 2.4750235080718994
Validation loss: 2.1109508468258764

Epoch: 6| Step: 1
Training loss: 1.7621774673461914
Validation loss: 2.1569633150613434

Epoch: 6| Step: 2
Training loss: 2.1333446502685547
Validation loss: 2.1023294438597975

Epoch: 6| Step: 3
Training loss: 1.8080148696899414
Validation loss: 2.139678324422529

Epoch: 6| Step: 4
Training loss: 1.239919900894165
Validation loss: 2.1233796573454335

Epoch: 6| Step: 5
Training loss: 1.5912330150604248
Validation loss: 2.013208794337447

Epoch: 6| Step: 6
Training loss: 1.7925012111663818
Validation loss: 2.1051289112337175

Epoch: 6| Step: 7
Training loss: 2.240917682647705
Validation loss: 2.203978612858762

Epoch: 6| Step: 8
Training loss: 2.018254280090332
Validation loss: 2.189206423298005

Epoch: 6| Step: 9
Training loss: 2.009456157684326
Validation loss: 2.1766164251553115

Epoch: 6| Step: 10
Training loss: 2.032515525817871
Validation loss: 2.1386982471712175

Epoch: 6| Step: 11
Training loss: 1.9931719303131104
Validation loss: 2.1439782957876883

Epoch: 6| Step: 12
Training loss: 2.152771472930908
Validation loss: 2.1051846088901645

Epoch: 6| Step: 13
Training loss: 2.0630431175231934
Validation loss: 2.0310158011733845

Epoch: 312| Step: 0
Training loss: 2.8129169940948486
Validation loss: 2.135707357878326

Epoch: 6| Step: 1
Training loss: 2.3553924560546875
Validation loss: 2.2313529624733874

Epoch: 6| Step: 2
Training loss: 1.8993637561798096
Validation loss: 2.142664802971707

Epoch: 6| Step: 3
Training loss: 1.5728955268859863
Validation loss: 2.0705950337071575

Epoch: 6| Step: 4
Training loss: 2.5615687370300293
Validation loss: 2.113627585031653

Epoch: 6| Step: 5
Training loss: 1.2864151000976562
Validation loss: 2.072161202789635

Epoch: 6| Step: 6
Training loss: 1.9407687187194824
Validation loss: 2.200899600982666

Epoch: 6| Step: 7
Training loss: 1.9101195335388184
Validation loss: 2.1805285433287263

Epoch: 6| Step: 8
Training loss: 1.972754955291748
Validation loss: 2.128714748608169

Epoch: 6| Step: 9
Training loss: 1.7356321811676025
Validation loss: 2.1134174087996125

Epoch: 6| Step: 10
Training loss: 1.555837631225586
Validation loss: 2.109540988040227

Epoch: 6| Step: 11
Training loss: 1.0608755350112915
Validation loss: 2.0102163322510256

Epoch: 6| Step: 12
Training loss: 2.1723673343658447
Validation loss: 2.0202582600296184

Epoch: 6| Step: 13
Training loss: 0.9027128219604492
Validation loss: 2.1251004665128645

Epoch: 313| Step: 0
Training loss: 2.3423357009887695
Validation loss: 2.1735557676643453

Epoch: 6| Step: 1
Training loss: 1.6178884506225586
Validation loss: 2.1686260328497937

Epoch: 6| Step: 2
Training loss: 1.5122997760772705
Validation loss: 2.1405707405459498

Epoch: 6| Step: 3
Training loss: 1.9447286128997803
Validation loss: 2.1400907321642806

Epoch: 6| Step: 4
Training loss: 1.48318350315094
Validation loss: 2.132225985168129

Epoch: 6| Step: 5
Training loss: 1.274875283241272
Validation loss: 2.164284445906198

Epoch: 6| Step: 6
Training loss: 2.4559085369110107
Validation loss: 2.184494579991987

Epoch: 6| Step: 7
Training loss: 1.582483172416687
Validation loss: 2.1863593837266326

Epoch: 6| Step: 8
Training loss: 1.9009157419204712
Validation loss: 2.1258242412280013

Epoch: 6| Step: 9
Training loss: 1.775870442390442
Validation loss: 2.0934736703031804

Epoch: 6| Step: 10
Training loss: 1.238857388496399
Validation loss: 2.168843925640147

Epoch: 6| Step: 11
Training loss: 2.1274163722991943
Validation loss: 2.172444594803677

Epoch: 6| Step: 12
Training loss: 2.7230172157287598
Validation loss: 2.0933724270072034

Epoch: 6| Step: 13
Training loss: 2.0494346618652344
Validation loss: 2.118227970215582

Epoch: 314| Step: 0
Training loss: 1.5471365451812744
Validation loss: 2.237268845240275

Epoch: 6| Step: 1
Training loss: 2.365229606628418
Validation loss: 2.0758444211816274

Epoch: 6| Step: 2
Training loss: 1.5355538129806519
Validation loss: 2.136210713335263

Epoch: 6| Step: 3
Training loss: 2.050854206085205
Validation loss: 2.111096961523897

Epoch: 6| Step: 4
Training loss: 1.0287957191467285
Validation loss: 2.1156127465668546

Epoch: 6| Step: 5
Training loss: 2.3132646083831787
Validation loss: 2.0948556828242477

Epoch: 6| Step: 6
Training loss: 1.703955888748169
Validation loss: 2.161500036075551

Epoch: 6| Step: 7
Training loss: 1.9754588603973389
Validation loss: 2.069380689692754

Epoch: 6| Step: 8
Training loss: 1.5098637342453003
Validation loss: 2.0677962149343183

Epoch: 6| Step: 9
Training loss: 2.4921298027038574
Validation loss: 2.0934035393499557

Epoch: 6| Step: 10
Training loss: 1.37743079662323
Validation loss: 2.1216527749133367

Epoch: 6| Step: 11
Training loss: 2.3329954147338867
Validation loss: 2.158074830168037

Epoch: 6| Step: 12
Training loss: 1.7827491760253906
Validation loss: 2.0987728052241827

Epoch: 6| Step: 13
Training loss: 2.525998115539551
Validation loss: 2.1039080517266386

Epoch: 315| Step: 0
Training loss: 1.5373814105987549
Validation loss: 2.2112623722322526

Epoch: 6| Step: 1
Training loss: 2.2671380043029785
Validation loss: 2.0827038454753097

Epoch: 6| Step: 2
Training loss: 2.5410799980163574
Validation loss: 2.1566988973207373

Epoch: 6| Step: 3
Training loss: 2.0930569171905518
Validation loss: 2.154031217739146

Epoch: 6| Step: 4
Training loss: 2.0263452529907227
Validation loss: 2.0873905920213267

Epoch: 6| Step: 5
Training loss: 1.6687953472137451
Validation loss: 2.179883490326584

Epoch: 6| Step: 6
Training loss: 0.9662145972251892
Validation loss: 2.133727435142763

Epoch: 6| Step: 7
Training loss: 1.675058364868164
Validation loss: 2.1073718840076077

Epoch: 6| Step: 8
Training loss: 1.6500707864761353
Validation loss: 2.0876248754480833

Epoch: 6| Step: 9
Training loss: 1.6583794355392456
Validation loss: 2.1311970090353363

Epoch: 6| Step: 10
Training loss: 1.8817193508148193
Validation loss: 2.1619287767717914

Epoch: 6| Step: 11
Training loss: 2.038879632949829
Validation loss: 2.134386472804572

Epoch: 6| Step: 12
Training loss: 1.7258144617080688
Validation loss: 2.1646628097821305

Epoch: 6| Step: 13
Training loss: 2.9735939502716064
Validation loss: 2.086660747886986

Epoch: 316| Step: 0
Training loss: 1.6934592723846436
Validation loss: 2.1064277836071548

Epoch: 6| Step: 1
Training loss: 2.4247336387634277
Validation loss: 2.1809296915608067

Epoch: 6| Step: 2
Training loss: 1.6902650594711304
Validation loss: 2.1072797800904963

Epoch: 6| Step: 3
Training loss: 2.5214805603027344
Validation loss: 2.174025624029098

Epoch: 6| Step: 4
Training loss: 1.2741055488586426
Validation loss: 2.119089772624354

Epoch: 6| Step: 5
Training loss: 1.5944337844848633
Validation loss: 2.1904745268565353

Epoch: 6| Step: 6
Training loss: 2.211472272872925
Validation loss: 2.1764441792682936

Epoch: 6| Step: 7
Training loss: 2.0688018798828125
Validation loss: 2.0655389332002208

Epoch: 6| Step: 8
Training loss: 2.1353960037231445
Validation loss: 2.195111914347577

Epoch: 6| Step: 9
Training loss: 1.627558946609497
Validation loss: 2.1500831803967877

Epoch: 6| Step: 10
Training loss: 1.5404090881347656
Validation loss: 2.123954862676641

Epoch: 6| Step: 11
Training loss: 2.045384168624878
Validation loss: 2.1323188427955873

Epoch: 6| Step: 12
Training loss: 1.4002735614776611
Validation loss: 2.1535635968690277

Epoch: 6| Step: 13
Training loss: 2.1042704582214355
Validation loss: 2.05884967055372

Epoch: 317| Step: 0
Training loss: 2.0949435234069824
Validation loss: 2.140119392384765

Epoch: 6| Step: 1
Training loss: 1.9373196363449097
Validation loss: 2.186276134624276

Epoch: 6| Step: 2
Training loss: 2.0359137058258057
Validation loss: 2.066012676044177

Epoch: 6| Step: 3
Training loss: 1.8764595985412598
Validation loss: 2.1512663210591962

Epoch: 6| Step: 4
Training loss: 1.5800566673278809
Validation loss: 2.0693153130110873

Epoch: 6| Step: 5
Training loss: 2.649834632873535
Validation loss: 2.15788673585461

Epoch: 6| Step: 6
Training loss: 2.4926912784576416
Validation loss: 1.9911831399445892

Epoch: 6| Step: 7
Training loss: 1.5667061805725098
Validation loss: 2.1223306245701288

Epoch: 6| Step: 8
Training loss: 2.2988812923431396
Validation loss: 2.0909272368236254

Epoch: 6| Step: 9
Training loss: 1.7042715549468994
Validation loss: 2.1183605399183048

Epoch: 6| Step: 10
Training loss: 1.9100710153579712
Validation loss: 2.1556050777435303

Epoch: 6| Step: 11
Training loss: 1.3006889820098877
Validation loss: 2.1053249938513643

Epoch: 6| Step: 12
Training loss: 1.6405510902404785
Validation loss: 2.088087656164682

Epoch: 6| Step: 13
Training loss: 1.3285386562347412
Validation loss: 2.195592395720943

Epoch: 318| Step: 0
Training loss: 2.1433258056640625
Validation loss: 2.048369167953409

Epoch: 6| Step: 1
Training loss: 1.8804144859313965
Validation loss: 2.1177487680988927

Epoch: 6| Step: 2
Training loss: 2.279819965362549
Validation loss: 2.0401655961108465

Epoch: 6| Step: 3
Training loss: 1.9224568605422974
Validation loss: 2.1155728986186366

Epoch: 6| Step: 4
Training loss: 1.6874873638153076
Validation loss: 2.1668424888323714

Epoch: 6| Step: 5
Training loss: 2.5823628902435303
Validation loss: 2.0786552967563754

Epoch: 6| Step: 6
Training loss: 2.1670007705688477
Validation loss: 2.0565755418551865

Epoch: 6| Step: 7
Training loss: 1.790415644645691
Validation loss: 2.152472739578575

Epoch: 6| Step: 8
Training loss: 1.156468152999878
Validation loss: 2.0504725658765404

Epoch: 6| Step: 9
Training loss: 1.2170100212097168
Validation loss: 2.134808078888924

Epoch: 6| Step: 10
Training loss: 1.8189632892608643
Validation loss: 2.1129134137143373

Epoch: 6| Step: 11
Training loss: 2.160292148590088
Validation loss: 2.171653373267061

Epoch: 6| Step: 12
Training loss: 1.5927138328552246
Validation loss: 2.154465936845349

Epoch: 6| Step: 13
Training loss: 2.836512565612793
Validation loss: 2.1313618485645582

Epoch: 319| Step: 0
Training loss: 2.2034971714019775
Validation loss: 2.140449757217079

Epoch: 6| Step: 1
Training loss: 1.95478355884552
Validation loss: 2.1471218088621735

Epoch: 6| Step: 2
Training loss: 2.2715418338775635
Validation loss: 2.110950989107932

Epoch: 6| Step: 3
Training loss: 1.9807238578796387
Validation loss: 2.1969708217087613

Epoch: 6| Step: 4
Training loss: 1.9596900939941406
Validation loss: 2.097954939770442

Epoch: 6| Step: 5
Training loss: 1.430263638496399
Validation loss: 2.138505910032539

Epoch: 6| Step: 6
Training loss: 1.9644999504089355
Validation loss: 2.09958238755503

Epoch: 6| Step: 7
Training loss: 1.6862211227416992
Validation loss: 2.085498907232797

Epoch: 6| Step: 8
Training loss: 1.5968654155731201
Validation loss: 2.126849559045607

Epoch: 6| Step: 9
Training loss: 2.386331081390381
Validation loss: 2.147764282841836

Epoch: 6| Step: 10
Training loss: 1.539583444595337
Validation loss: 2.1833252214616343

Epoch: 6| Step: 11
Training loss: 1.924426794052124
Validation loss: 2.0776164300980104

Epoch: 6| Step: 12
Training loss: 2.1046576499938965
Validation loss: 2.0436800628580074

Epoch: 6| Step: 13
Training loss: 1.2228695154190063
Validation loss: 2.194988432750907

Epoch: 320| Step: 0
Training loss: 2.089747905731201
Validation loss: 2.1948437216461345

Epoch: 6| Step: 1
Training loss: 1.6577774286270142
Validation loss: 2.157881526536839

Epoch: 6| Step: 2
Training loss: 1.5222234725952148
Validation loss: 2.1018291724625455

Epoch: 6| Step: 3
Training loss: 2.2369863986968994
Validation loss: 2.1406335100050895

Epoch: 6| Step: 4
Training loss: 1.7047511339187622
Validation loss: 2.073795131457749

Epoch: 6| Step: 5
Training loss: 2.2787790298461914
Validation loss: 2.1368145199232202

Epoch: 6| Step: 6
Training loss: 2.091493844985962
Validation loss: 2.1138369703805573

Epoch: 6| Step: 7
Training loss: 2.3056159019470215
Validation loss: 2.0937353308482836

Epoch: 6| Step: 8
Training loss: 0.8989114165306091
Validation loss: 2.0736092521298315

Epoch: 6| Step: 9
Training loss: 1.9289937019348145
Validation loss: 2.0808004922764276

Epoch: 6| Step: 10
Training loss: 2.1697192192077637
Validation loss: 2.137644329378682

Epoch: 6| Step: 11
Training loss: 1.5096714496612549
Validation loss: 2.1329298275773243

Epoch: 6| Step: 12
Training loss: 2.2016890048980713
Validation loss: 2.0609361099940475

Epoch: 6| Step: 13
Training loss: 1.7052881717681885
Validation loss: 2.1982983466117614

Epoch: 321| Step: 0
Training loss: 2.377626895904541
Validation loss: 2.099692121628792

Epoch: 6| Step: 1
Training loss: 2.4000656604766846
Validation loss: 2.095371384774485

Epoch: 6| Step: 2
Training loss: 1.9138057231903076
Validation loss: 2.0927407357000534

Epoch: 6| Step: 3
Training loss: 1.8844013214111328
Validation loss: 2.1577259648230767

Epoch: 6| Step: 4
Training loss: 2.4859085083007812
Validation loss: 2.088337754690519

Epoch: 6| Step: 5
Training loss: 1.2608119249343872
Validation loss: 2.0762847469699

Epoch: 6| Step: 6
Training loss: 1.8423904180526733
Validation loss: 2.162323187756282

Epoch: 6| Step: 7
Training loss: 1.601239562034607
Validation loss: 2.1089325592082035

Epoch: 6| Step: 8
Training loss: 2.0789384841918945
Validation loss: 2.109021523947357

Epoch: 6| Step: 9
Training loss: 2.2886500358581543
Validation loss: 2.070734229139102

Epoch: 6| Step: 10
Training loss: 1.9516868591308594
Validation loss: 2.0924997175893476

Epoch: 6| Step: 11
Training loss: 1.741715431213379
Validation loss: 2.1886503593896025

Epoch: 6| Step: 12
Training loss: 1.2691798210144043
Validation loss: 2.132187374176518

Epoch: 6| Step: 13
Training loss: 2.061718463897705
Validation loss: 2.086874051760602

Epoch: 322| Step: 0
Training loss: 1.9044506549835205
Validation loss: 2.2170533569910194

Epoch: 6| Step: 1
Training loss: 1.6222331523895264
Validation loss: 2.1203192305821243

Epoch: 6| Step: 2
Training loss: 1.7635903358459473
Validation loss: 2.093736320413569

Epoch: 6| Step: 3
Training loss: 1.7400696277618408
Validation loss: 2.130040450762677

Epoch: 6| Step: 4
Training loss: 1.7340664863586426
Validation loss: 2.1454265079190655

Epoch: 6| Step: 5
Training loss: 2.008308172225952
Validation loss: 2.142477297013806

Epoch: 6| Step: 6
Training loss: 1.8192334175109863
Validation loss: 2.0880308023063083

Epoch: 6| Step: 7
Training loss: 2.1017866134643555
Validation loss: 2.172706437367265

Epoch: 6| Step: 8
Training loss: 2.0179901123046875
Validation loss: 2.1397083805453394

Epoch: 6| Step: 9
Training loss: 1.7774738073349
Validation loss: 2.0641755186101443

Epoch: 6| Step: 10
Training loss: 2.330608367919922
Validation loss: 2.12834503317392

Epoch: 6| Step: 11
Training loss: 1.6230370998382568
Validation loss: 2.2203514550321843

Epoch: 6| Step: 12
Training loss: 1.641695499420166
Validation loss: 2.0900198874935025

Epoch: 6| Step: 13
Training loss: 2.3853442668914795
Validation loss: 2.1526205693521807

Epoch: 323| Step: 0
Training loss: 1.787158727645874
Validation loss: 2.101421061382499

Epoch: 6| Step: 1
Training loss: 1.6407371759414673
Validation loss: 2.1220238375407394

Epoch: 6| Step: 2
Training loss: 1.5986826419830322
Validation loss: 2.1580026431750228

Epoch: 6| Step: 3
Training loss: 1.8107188940048218
Validation loss: 2.1841585072137977

Epoch: 6| Step: 4
Training loss: 1.9890484809875488
Validation loss: 2.0317127807165987

Epoch: 6| Step: 5
Training loss: 1.2053873538970947
Validation loss: 2.1277843213850454

Epoch: 6| Step: 6
Training loss: 2.4201619625091553
Validation loss: 2.194761076281148

Epoch: 6| Step: 7
Training loss: 1.586998462677002
Validation loss: 2.1215315134294572

Epoch: 6| Step: 8
Training loss: 2.020914077758789
Validation loss: 2.0956233573216263

Epoch: 6| Step: 9
Training loss: 2.2058463096618652
Validation loss: 2.204027775795229

Epoch: 6| Step: 10
Training loss: 1.7439197301864624
Validation loss: 2.1302475083258843

Epoch: 6| Step: 11
Training loss: 1.9129005670547485
Validation loss: 2.1485935077872327

Epoch: 6| Step: 12
Training loss: 2.4651763439178467
Validation loss: 2.0840312447599185

Epoch: 6| Step: 13
Training loss: 2.189621686935425
Validation loss: 2.089529719403995

Epoch: 324| Step: 0
Training loss: 1.661542534828186
Validation loss: 2.07316699335652

Epoch: 6| Step: 1
Training loss: 2.0107171535491943
Validation loss: 2.128722572839388

Epoch: 6| Step: 2
Training loss: 2.881751537322998
Validation loss: 2.0924713932057863

Epoch: 6| Step: 3
Training loss: 1.8417012691497803
Validation loss: 2.1350325871539373

Epoch: 6| Step: 4
Training loss: 1.791609287261963
Validation loss: 2.115505662015689

Epoch: 6| Step: 5
Training loss: 1.7700120210647583
Validation loss: 2.1532311336968535

Epoch: 6| Step: 6
Training loss: 1.558459758758545
Validation loss: 2.1736224261663293

Epoch: 6| Step: 7
Training loss: 1.8298721313476562
Validation loss: 2.127748986726166

Epoch: 6| Step: 8
Training loss: 1.5521535873413086
Validation loss: 2.0973942356724895

Epoch: 6| Step: 9
Training loss: 2.5897088050842285
Validation loss: 2.1259373939165505

Epoch: 6| Step: 10
Training loss: 1.1113789081573486
Validation loss: 2.132569843722928

Epoch: 6| Step: 11
Training loss: 1.8691539764404297
Validation loss: 2.134546423471102

Epoch: 6| Step: 12
Training loss: 2.350740909576416
Validation loss: 2.131311032079881

Epoch: 6| Step: 13
Training loss: 1.8640332221984863
Validation loss: 2.148069284295523

Epoch: 325| Step: 0
Training loss: 1.782488226890564
Validation loss: 2.1208976161095405

Epoch: 6| Step: 1
Training loss: 1.5971406698226929
Validation loss: 2.1403665581057147

Epoch: 6| Step: 2
Training loss: 2.03916597366333
Validation loss: 2.1688714514496508

Epoch: 6| Step: 3
Training loss: 1.7565507888793945
Validation loss: 2.2003230612765075

Epoch: 6| Step: 4
Training loss: 2.091034412384033
Validation loss: 2.079983498460503

Epoch: 6| Step: 5
Training loss: 1.5444395542144775
Validation loss: 2.0797528605307303

Epoch: 6| Step: 6
Training loss: 2.3305439949035645
Validation loss: 2.153667752460767

Epoch: 6| Step: 7
Training loss: 1.822864055633545
Validation loss: 2.151800796549807

Epoch: 6| Step: 8
Training loss: 1.467111587524414
Validation loss: 2.020082922391994

Epoch: 6| Step: 9
Training loss: 2.4952213764190674
Validation loss: 2.0737043375610025

Epoch: 6| Step: 10
Training loss: 2.466545581817627
Validation loss: 2.117465329426591

Epoch: 6| Step: 11
Training loss: 2.0351061820983887
Validation loss: 2.166197790894457

Epoch: 6| Step: 12
Training loss: 1.5600799322128296
Validation loss: 2.1155778400359617

Epoch: 6| Step: 13
Training loss: 1.9349206686019897
Validation loss: 2.099189676264281

Epoch: 326| Step: 0
Training loss: 1.4442377090454102
Validation loss: 2.1372177549587783

Epoch: 6| Step: 1
Training loss: 1.6726462841033936
Validation loss: 2.1601529711036274

Epoch: 6| Step: 2
Training loss: 2.4544694423675537
Validation loss: 2.1358271747507076

Epoch: 6| Step: 3
Training loss: 3.029874563217163
Validation loss: 2.1699282353924167

Epoch: 6| Step: 4
Training loss: 1.648513674736023
Validation loss: 2.0895936783923896

Epoch: 6| Step: 5
Training loss: 2.4829297065734863
Validation loss: 2.0842222423963648

Epoch: 6| Step: 6
Training loss: 1.7165472507476807
Validation loss: 2.135191850764777

Epoch: 6| Step: 7
Training loss: 2.3136911392211914
Validation loss: 2.0845213449129494

Epoch: 6| Step: 8
Training loss: 1.6290580034255981
Validation loss: 2.0817350931065057

Epoch: 6| Step: 9
Training loss: 1.6582722663879395
Validation loss: 2.1997559378224034

Epoch: 6| Step: 10
Training loss: 1.8943004608154297
Validation loss: 2.120027372913976

Epoch: 6| Step: 11
Training loss: 1.6876375675201416
Validation loss: 2.150925931110177

Epoch: 6| Step: 12
Training loss: 1.0620198249816895
Validation loss: 2.173832808771441

Epoch: 6| Step: 13
Training loss: 1.9985504150390625
Validation loss: 2.163059421764907

Epoch: 327| Step: 0
Training loss: 1.6265549659729004
Validation loss: 2.1206729770988546

Epoch: 6| Step: 1
Training loss: 1.0923192501068115
Validation loss: 2.1762305510941373

Epoch: 6| Step: 2
Training loss: 2.111377716064453
Validation loss: 2.1781546479912213

Epoch: 6| Step: 3
Training loss: 2.1144115924835205
Validation loss: 2.0678003936685543

Epoch: 6| Step: 4
Training loss: 2.1230030059814453
Validation loss: 2.1283772709549114

Epoch: 6| Step: 5
Training loss: 1.59543776512146
Validation loss: 2.104358858959649

Epoch: 6| Step: 6
Training loss: 2.2878596782684326
Validation loss: 2.124385436375936

Epoch: 6| Step: 7
Training loss: 2.0232183933258057
Validation loss: 2.17709461463395

Epoch: 6| Step: 8
Training loss: 2.2727060317993164
Validation loss: 2.112365020218716

Epoch: 6| Step: 9
Training loss: 1.7173936367034912
Validation loss: 2.152176921085645

Epoch: 6| Step: 10
Training loss: 1.6142640113830566
Validation loss: 2.1077801245515064

Epoch: 6| Step: 11
Training loss: 1.9606584310531616
Validation loss: 2.206277298670943

Epoch: 6| Step: 12
Training loss: 2.21876859664917
Validation loss: 2.146346943352812

Epoch: 6| Step: 13
Training loss: 1.1202406883239746
Validation loss: 2.1332606448922107

Epoch: 328| Step: 0
Training loss: 1.8158929347991943
Validation loss: 2.131836075936594

Epoch: 6| Step: 1
Training loss: 1.7852058410644531
Validation loss: 2.1427485686476513

Epoch: 6| Step: 2
Training loss: 1.5418927669525146
Validation loss: 2.1127328795771443

Epoch: 6| Step: 3
Training loss: 2.2562384605407715
Validation loss: 2.154453367315313

Epoch: 6| Step: 4
Training loss: 1.1660581827163696
Validation loss: 2.1673122477787796

Epoch: 6| Step: 5
Training loss: 2.268136978149414
Validation loss: 2.1265035111417054

Epoch: 6| Step: 6
Training loss: 2.6610939502716064
Validation loss: 2.0971649641631753

Epoch: 6| Step: 7
Training loss: 1.6666233539581299
Validation loss: 2.1338266018898255

Epoch: 6| Step: 8
Training loss: 1.9839502573013306
Validation loss: 2.0415116792084067

Epoch: 6| Step: 9
Training loss: 1.6518455743789673
Validation loss: 2.0998409230221986

Epoch: 6| Step: 10
Training loss: 1.8174786567687988
Validation loss: 2.0742857956117198

Epoch: 6| Step: 11
Training loss: 1.9032005071640015
Validation loss: 2.1559202594141804

Epoch: 6| Step: 12
Training loss: 2.036288261413574
Validation loss: 2.1122915334598993

Epoch: 6| Step: 13
Training loss: 1.9734216928482056
Validation loss: 2.0720178581053212

Epoch: 329| Step: 0
Training loss: 2.3159241676330566
Validation loss: 2.1145062754231114

Epoch: 6| Step: 1
Training loss: 1.8195712566375732
Validation loss: 2.061158378918966

Epoch: 6| Step: 2
Training loss: 2.137265920639038
Validation loss: 2.103547824326382

Epoch: 6| Step: 3
Training loss: 1.5942952632904053
Validation loss: 2.1791884950412217

Epoch: 6| Step: 4
Training loss: 1.9279391765594482
Validation loss: 2.037425551363217

Epoch: 6| Step: 5
Training loss: 1.841095209121704
Validation loss: 2.046785916051557

Epoch: 6| Step: 6
Training loss: 2.0396220684051514
Validation loss: 2.0560667578892042

Epoch: 6| Step: 7
Training loss: 1.8649370670318604
Validation loss: 2.1610971291859946

Epoch: 6| Step: 8
Training loss: 1.5745916366577148
Validation loss: 2.1028594970703125

Epoch: 6| Step: 9
Training loss: 2.0294764041900635
Validation loss: 2.143763093538182

Epoch: 6| Step: 10
Training loss: 1.5619218349456787
Validation loss: 2.12360639725962

Epoch: 6| Step: 11
Training loss: 2.219835042953491
Validation loss: 2.1550667183373564

Epoch: 6| Step: 12
Training loss: 1.692285418510437
Validation loss: 2.075112981180991

Epoch: 6| Step: 13
Training loss: 0.9666523337364197
Validation loss: 2.1679727133884223

Epoch: 330| Step: 0
Training loss: 1.9435361623764038
Validation loss: 2.132362029885733

Epoch: 6| Step: 1
Training loss: 1.373685359954834
Validation loss: 2.1269768873850503

Epoch: 6| Step: 2
Training loss: 1.633016586303711
Validation loss: 2.138407221404455

Epoch: 6| Step: 3
Training loss: 1.750443458557129
Validation loss: 2.115775162173856

Epoch: 6| Step: 4
Training loss: 2.2329039573669434
Validation loss: 2.105211211789039

Epoch: 6| Step: 5
Training loss: 2.2071938514709473
Validation loss: 2.085643345309842

Epoch: 6| Step: 6
Training loss: 2.4374301433563232
Validation loss: 2.128177269812553

Epoch: 6| Step: 7
Training loss: 1.930367112159729
Validation loss: 2.175576461258755

Epoch: 6| Step: 8
Training loss: 1.7653319835662842
Validation loss: 2.2346843250336184

Epoch: 6| Step: 9
Training loss: 1.5598134994506836
Validation loss: 2.1603801532458236

Epoch: 6| Step: 10
Training loss: 1.6834161281585693
Validation loss: 2.1854124094850276

Epoch: 6| Step: 11
Training loss: 1.9058059453964233
Validation loss: 2.215161354311051

Epoch: 6| Step: 12
Training loss: 1.8242411613464355
Validation loss: 2.072402923337875

Epoch: 6| Step: 13
Training loss: 2.0874781608581543
Validation loss: 2.1658094031836397

Epoch: 331| Step: 0
Training loss: 2.0345726013183594
Validation loss: 2.1773030809176865

Epoch: 6| Step: 1
Training loss: 1.3364551067352295
Validation loss: 2.1700002942033993

Epoch: 6| Step: 2
Training loss: 2.2528209686279297
Validation loss: 2.1300389971784366

Epoch: 6| Step: 3
Training loss: 1.8694205284118652
Validation loss: 2.1096897586699455

Epoch: 6| Step: 4
Training loss: 1.8721568584442139
Validation loss: 2.124120150842974

Epoch: 6| Step: 5
Training loss: 1.690321922302246
Validation loss: 2.0410715803023307

Epoch: 6| Step: 6
Training loss: 2.0829384326934814
Validation loss: 2.1054471782458726

Epoch: 6| Step: 7
Training loss: 2.2482759952545166
Validation loss: 2.080279824554279

Epoch: 6| Step: 8
Training loss: 1.7681957483291626
Validation loss: 2.0784964766553653

Epoch: 6| Step: 9
Training loss: 1.557930827140808
Validation loss: 2.0374124357777257

Epoch: 6| Step: 10
Training loss: 1.7556884288787842
Validation loss: 2.049497990198033

Epoch: 6| Step: 11
Training loss: 1.4575371742248535
Validation loss: 2.0705447209778653

Epoch: 6| Step: 12
Training loss: 2.184093952178955
Validation loss: 2.1172552865038634

Epoch: 6| Step: 13
Training loss: 1.8041248321533203
Validation loss: 2.072582547382642

Epoch: 332| Step: 0
Training loss: 1.7255523204803467
Validation loss: 2.150804095370795

Epoch: 6| Step: 1
Training loss: 1.724050760269165
Validation loss: 2.105469852365473

Epoch: 6| Step: 2
Training loss: 1.6048552989959717
Validation loss: 2.0597118011084934

Epoch: 6| Step: 3
Training loss: 1.7500224113464355
Validation loss: 2.05859056339469

Epoch: 6| Step: 4
Training loss: 1.8996589183807373
Validation loss: 2.1029446868486303

Epoch: 6| Step: 5
Training loss: 2.313570976257324
Validation loss: 2.133887724209857

Epoch: 6| Step: 6
Training loss: 1.6379377841949463
Validation loss: 2.1574833418733332

Epoch: 6| Step: 7
Training loss: 1.1090059280395508
Validation loss: 2.164118884712137

Epoch: 6| Step: 8
Training loss: 2.147353410720825
Validation loss: 2.1534063739161335

Epoch: 6| Step: 9
Training loss: 2.1688990592956543
Validation loss: 2.138753360317599

Epoch: 6| Step: 10
Training loss: 2.172624111175537
Validation loss: 2.10867678606382

Epoch: 6| Step: 11
Training loss: 1.5928945541381836
Validation loss: 2.1161229777079757

Epoch: 6| Step: 12
Training loss: 2.5694732666015625
Validation loss: 2.0782701276963755

Epoch: 6| Step: 13
Training loss: 1.6324870586395264
Validation loss: 2.110759932507751

Epoch: 333| Step: 0
Training loss: 1.6323531866073608
Validation loss: 2.104831903211532

Epoch: 6| Step: 1
Training loss: 1.9178416728973389
Validation loss: 2.1133198789370957

Epoch: 6| Step: 2
Training loss: 2.142545700073242
Validation loss: 2.072523549038877

Epoch: 6| Step: 3
Training loss: 1.662048101425171
Validation loss: 2.1890477288153862

Epoch: 6| Step: 4
Training loss: 1.5462381839752197
Validation loss: 2.105148923012518

Epoch: 6| Step: 5
Training loss: 2.7410454750061035
Validation loss: 2.1141081753597466

Epoch: 6| Step: 6
Training loss: 1.843072772026062
Validation loss: 2.1046870216246574

Epoch: 6| Step: 7
Training loss: 1.38570237159729
Validation loss: 2.1270917410491617

Epoch: 6| Step: 8
Training loss: 1.327056646347046
Validation loss: 2.1184826089489843

Epoch: 6| Step: 9
Training loss: 2.213503122329712
Validation loss: 2.2076985323300926

Epoch: 6| Step: 10
Training loss: 2.066183090209961
Validation loss: 2.1666002760651293

Epoch: 6| Step: 11
Training loss: 2.0683393478393555
Validation loss: 2.068271852308704

Epoch: 6| Step: 12
Training loss: 1.304099440574646
Validation loss: 2.1078780992056734

Epoch: 6| Step: 13
Training loss: 1.9976251125335693
Validation loss: 2.153602700079641

Epoch: 334| Step: 0
Training loss: 1.8721184730529785
Validation loss: 2.180118994046283

Epoch: 6| Step: 1
Training loss: 1.7757549285888672
Validation loss: 2.10509148464408

Epoch: 6| Step: 2
Training loss: 2.2545647621154785
Validation loss: 2.0784517206171507

Epoch: 6| Step: 3
Training loss: 2.513606548309326
Validation loss: 2.1207953396663872

Epoch: 6| Step: 4
Training loss: 1.9834721088409424
Validation loss: 2.1084779231779036

Epoch: 6| Step: 5
Training loss: 1.11869215965271
Validation loss: 2.123007285979486

Epoch: 6| Step: 6
Training loss: 2.103712558746338
Validation loss: 2.1984150358425674

Epoch: 6| Step: 7
Training loss: 1.8807569742202759
Validation loss: 2.124048930342479

Epoch: 6| Step: 8
Training loss: 1.384969711303711
Validation loss: 2.1083046159436627

Epoch: 6| Step: 9
Training loss: 1.7626909017562866
Validation loss: 2.1573185523351035

Epoch: 6| Step: 10
Training loss: 2.282679319381714
Validation loss: 2.0594717584630495

Epoch: 6| Step: 11
Training loss: 1.5410200357437134
Validation loss: 2.0170545116547616

Epoch: 6| Step: 12
Training loss: 1.4213230609893799
Validation loss: 2.1420346844580864

Epoch: 6| Step: 13
Training loss: 2.0280568599700928
Validation loss: 2.163004614973581

Epoch: 335| Step: 0
Training loss: 1.562020182609558
Validation loss: 2.170344809050201

Epoch: 6| Step: 1
Training loss: 1.6130540370941162
Validation loss: 2.112097587636722

Epoch: 6| Step: 2
Training loss: 2.341045379638672
Validation loss: 2.1622626473826747

Epoch: 6| Step: 3
Training loss: 2.226386070251465
Validation loss: 2.028127667724445

Epoch: 6| Step: 4
Training loss: 2.276719570159912
Validation loss: 2.045059368174563

Epoch: 6| Step: 5
Training loss: 1.2967431545257568
Validation loss: 2.1679916176744687

Epoch: 6| Step: 6
Training loss: 1.315496563911438
Validation loss: 2.105115939212102

Epoch: 6| Step: 7
Training loss: 1.8844218254089355
Validation loss: 2.172287351341658

Epoch: 6| Step: 8
Training loss: 3.257293224334717
Validation loss: 2.0957015791246967

Epoch: 6| Step: 9
Training loss: 1.593632459640503
Validation loss: 2.226890061491279

Epoch: 6| Step: 10
Training loss: 1.5149037837982178
Validation loss: 2.077301395836697

Epoch: 6| Step: 11
Training loss: 1.270904541015625
Validation loss: 2.109859617807532

Epoch: 6| Step: 12
Training loss: 2.0929195880889893
Validation loss: 2.2366282606637604

Epoch: 6| Step: 13
Training loss: 1.8156545162200928
Validation loss: 2.102464481066632

Epoch: 336| Step: 0
Training loss: 1.347672939300537
Validation loss: 2.156247038995066

Epoch: 6| Step: 1
Training loss: 1.949707269668579
Validation loss: 2.1106909692928357

Epoch: 6| Step: 2
Training loss: 1.3348320722579956
Validation loss: 2.1588305657909763

Epoch: 6| Step: 3
Training loss: 1.647695541381836
Validation loss: 2.0830137037461802

Epoch: 6| Step: 4
Training loss: 2.2903170585632324
Validation loss: 2.1166891000604116

Epoch: 6| Step: 5
Training loss: 1.8976670503616333
Validation loss: 2.133972990897394

Epoch: 6| Step: 6
Training loss: 1.580554723739624
Validation loss: 2.241559044007332

Epoch: 6| Step: 7
Training loss: 2.2398324012756348
Validation loss: 2.051422284495446

Epoch: 6| Step: 8
Training loss: 1.4011045694351196
Validation loss: 2.1265440371728714

Epoch: 6| Step: 9
Training loss: 2.353663921356201
Validation loss: 2.1468324712527695

Epoch: 6| Step: 10
Training loss: 2.228325366973877
Validation loss: 2.1397425974569013

Epoch: 6| Step: 11
Training loss: 1.7944010496139526
Validation loss: 2.082546200803531

Epoch: 6| Step: 12
Training loss: 2.4228570461273193
Validation loss: 2.0775890068341325

Epoch: 6| Step: 13
Training loss: 1.4456355571746826
Validation loss: 2.0930711530870005

Epoch: 337| Step: 0
Training loss: 1.3999923467636108
Validation loss: 2.0897900827469362

Epoch: 6| Step: 1
Training loss: 1.7813117504119873
Validation loss: 2.0644706474837435

Epoch: 6| Step: 2
Training loss: 2.4269540309906006
Validation loss: 2.1950531621133127

Epoch: 6| Step: 3
Training loss: 2.224000930786133
Validation loss: 2.059873564268953

Epoch: 6| Step: 4
Training loss: 1.3792235851287842
Validation loss: 2.1408519091144687

Epoch: 6| Step: 5
Training loss: 1.8417233228683472
Validation loss: 2.160975448546871

Epoch: 6| Step: 6
Training loss: 1.9402772188186646
Validation loss: 2.1365541899076073

Epoch: 6| Step: 7
Training loss: 1.38130784034729
Validation loss: 2.155933754418486

Epoch: 6| Step: 8
Training loss: 2.183346748352051
Validation loss: 2.161398164687618

Epoch: 6| Step: 9
Training loss: 1.537821650505066
Validation loss: 2.166965300037015

Epoch: 6| Step: 10
Training loss: 1.3264639377593994
Validation loss: 2.1921745243892876

Epoch: 6| Step: 11
Training loss: 2.0644798278808594
Validation loss: 2.1831648785580873

Epoch: 6| Step: 12
Training loss: 2.498838424682617
Validation loss: 2.256638030852041

Epoch: 6| Step: 13
Training loss: 1.5926587581634521
Validation loss: 2.14720489645517

Epoch: 338| Step: 0
Training loss: 2.441439151763916
Validation loss: 2.1205556572124524

Epoch: 6| Step: 1
Training loss: 1.55597722530365
Validation loss: 2.221778841428859

Epoch: 6| Step: 2
Training loss: 1.4771625995635986
Validation loss: 2.0927410202641643

Epoch: 6| Step: 3
Training loss: 1.840055227279663
Validation loss: 2.105193814923686

Epoch: 6| Step: 4
Training loss: 1.787243366241455
Validation loss: 2.157649394004576

Epoch: 6| Step: 5
Training loss: 1.9782394170761108
Validation loss: 2.1231271348973757

Epoch: 6| Step: 6
Training loss: 1.919472336769104
Validation loss: 2.1030643768208

Epoch: 6| Step: 7
Training loss: 2.6152844429016113
Validation loss: 2.1059878744104856

Epoch: 6| Step: 8
Training loss: 2.1698622703552246
Validation loss: 2.1277165989721976

Epoch: 6| Step: 9
Training loss: 2.116741180419922
Validation loss: 2.136039359595186

Epoch: 6| Step: 10
Training loss: 1.3328150510787964
Validation loss: 2.0866108504674767

Epoch: 6| Step: 11
Training loss: 2.082287311553955
Validation loss: 2.137585138761869

Epoch: 6| Step: 12
Training loss: 1.0937590599060059
Validation loss: 2.01891811560559

Epoch: 6| Step: 13
Training loss: 1.5305880308151245
Validation loss: 2.0866533722928775

Epoch: 339| Step: 0
Training loss: 1.7267659902572632
Validation loss: 2.1289738711490425

Epoch: 6| Step: 1
Training loss: 1.9625437259674072
Validation loss: 2.0478848859828007

Epoch: 6| Step: 2
Training loss: 1.8081704378128052
Validation loss: 2.150941656481835

Epoch: 6| Step: 3
Training loss: 1.719736099243164
Validation loss: 2.1099948011418825

Epoch: 6| Step: 4
Training loss: 2.2999987602233887
Validation loss: 2.1705734652857624

Epoch: 6| Step: 5
Training loss: 1.7288209199905396
Validation loss: 2.140449257307155

Epoch: 6| Step: 6
Training loss: 2.2884206771850586
Validation loss: 2.093975028684062

Epoch: 6| Step: 7
Training loss: 1.1031992435455322
Validation loss: 2.178133918393043

Epoch: 6| Step: 8
Training loss: 1.6858677864074707
Validation loss: 2.127006096224631

Epoch: 6| Step: 9
Training loss: 1.938920021057129
Validation loss: 2.145649110117266

Epoch: 6| Step: 10
Training loss: 1.76587975025177
Validation loss: 2.125650595593196

Epoch: 6| Step: 11
Training loss: 2.314995527267456
Validation loss: 2.109854236725838

Epoch: 6| Step: 12
Training loss: 1.5293843746185303
Validation loss: 2.0961803595225015

Epoch: 6| Step: 13
Training loss: 1.9459936618804932
Validation loss: 2.120642392866073

Epoch: 340| Step: 0
Training loss: 1.9433202743530273
Validation loss: 2.125138677576537

Epoch: 6| Step: 1
Training loss: 1.379001259803772
Validation loss: 2.126400504060971

Epoch: 6| Step: 2
Training loss: 1.8465240001678467
Validation loss: 2.170848020943262

Epoch: 6| Step: 3
Training loss: 1.3001911640167236
Validation loss: 2.1552289698713567

Epoch: 6| Step: 4
Training loss: 2.025315523147583
Validation loss: 2.071381820145474

Epoch: 6| Step: 5
Training loss: 2.097719430923462
Validation loss: 2.1354279184854157

Epoch: 6| Step: 6
Training loss: 1.7258442640304565
Validation loss: 2.1647213864070114

Epoch: 6| Step: 7
Training loss: 1.994168758392334
Validation loss: 2.144978571963567

Epoch: 6| Step: 8
Training loss: 2.0727357864379883
Validation loss: 2.157765826871318

Epoch: 6| Step: 9
Training loss: 0.9660728573799133
Validation loss: 2.108913488285516

Epoch: 6| Step: 10
Training loss: 1.6204754114151
Validation loss: 2.1849382846586165

Epoch: 6| Step: 11
Training loss: 2.1499555110931396
Validation loss: 2.107968271419566

Epoch: 6| Step: 12
Training loss: 1.8722248077392578
Validation loss: 2.135164855628885

Epoch: 6| Step: 13
Training loss: 3.941051959991455
Validation loss: 2.1046954893296763

Epoch: 341| Step: 0
Training loss: 1.344531536102295
Validation loss: 2.1802437523359894

Epoch: 6| Step: 1
Training loss: 1.4417561292648315
Validation loss: 2.142557294138016

Epoch: 6| Step: 2
Training loss: 1.5351881980895996
Validation loss: 2.1602173723200315

Epoch: 6| Step: 3
Training loss: 2.3569247722625732
Validation loss: 2.1642341101041405

Epoch: 6| Step: 4
Training loss: 1.923468828201294
Validation loss: 2.15928344444562

Epoch: 6| Step: 5
Training loss: 2.4071106910705566
Validation loss: 2.128820724384759

Epoch: 6| Step: 6
Training loss: 2.0835278034210205
Validation loss: 2.1037262280782065

Epoch: 6| Step: 7
Training loss: 1.5759572982788086
Validation loss: 2.179432956121301

Epoch: 6| Step: 8
Training loss: 1.4807342290878296
Validation loss: 2.170293556746616

Epoch: 6| Step: 9
Training loss: 1.4013934135437012
Validation loss: 2.108961154055852

Epoch: 6| Step: 10
Training loss: 2.093526840209961
Validation loss: 2.0966413661997807

Epoch: 6| Step: 11
Training loss: 2.054727077484131
Validation loss: 2.0764888691645798

Epoch: 6| Step: 12
Training loss: 1.6020333766937256
Validation loss: 2.0765781735861175

Epoch: 6| Step: 13
Training loss: 3.7664103507995605
Validation loss: 2.0657853426471835

Epoch: 342| Step: 0
Training loss: 2.076930046081543
Validation loss: 2.141055739054116

Epoch: 6| Step: 1
Training loss: 1.7648675441741943
Validation loss: 2.1276393603253108

Epoch: 6| Step: 2
Training loss: 1.895253300666809
Validation loss: 2.0540285597565355

Epoch: 6| Step: 3
Training loss: 2.1357715129852295
Validation loss: 2.134252522581367

Epoch: 6| Step: 4
Training loss: 1.5575178861618042
Validation loss: 2.067917787900535

Epoch: 6| Step: 5
Training loss: 1.84619140625
Validation loss: 2.078202055346581

Epoch: 6| Step: 6
Training loss: 1.769392967224121
Validation loss: 2.0875672730066444

Epoch: 6| Step: 7
Training loss: 2.289921998977661
Validation loss: 2.13269902301091

Epoch: 6| Step: 8
Training loss: 1.2125144004821777
Validation loss: 2.192517904825108

Epoch: 6| Step: 9
Training loss: 2.3012452125549316
Validation loss: 2.124625482866841

Epoch: 6| Step: 10
Training loss: 1.7473254203796387
Validation loss: 2.0805006578404415

Epoch: 6| Step: 11
Training loss: 1.8721586465835571
Validation loss: 2.1502595434906664

Epoch: 6| Step: 12
Training loss: 2.029165267944336
Validation loss: 2.1211311714623564

Epoch: 6| Step: 13
Training loss: 2.3931219577789307
Validation loss: 2.1609845392165647

Epoch: 343| Step: 0
Training loss: 1.233811855316162
Validation loss: 2.142074510615359

Epoch: 6| Step: 1
Training loss: 2.2913553714752197
Validation loss: 2.132038644565049

Epoch: 6| Step: 2
Training loss: 1.7064132690429688
Validation loss: 2.1867786812525924

Epoch: 6| Step: 3
Training loss: 2.0875608921051025
Validation loss: 2.1328911742856427

Epoch: 6| Step: 4
Training loss: 1.9220705032348633
Validation loss: 2.1771209419414563

Epoch: 6| Step: 5
Training loss: 1.872542381286621
Validation loss: 2.119668222242786

Epoch: 6| Step: 6
Training loss: 1.6549930572509766
Validation loss: 2.1032759886915966

Epoch: 6| Step: 7
Training loss: 1.5278642177581787
Validation loss: 2.12544233311889

Epoch: 6| Step: 8
Training loss: 2.601170063018799
Validation loss: 2.1340175879898893

Epoch: 6| Step: 9
Training loss: 1.1070538759231567
Validation loss: 2.022714086758193

Epoch: 6| Step: 10
Training loss: 1.4854307174682617
Validation loss: 2.1083661023006646

Epoch: 6| Step: 11
Training loss: 1.8834059238433838
Validation loss: 2.1475251656706615

Epoch: 6| Step: 12
Training loss: 2.315845489501953
Validation loss: 2.135230818102437

Epoch: 6| Step: 13
Training loss: 1.95610511302948
Validation loss: 2.1059945257761146

Epoch: 344| Step: 0
Training loss: 1.7475337982177734
Validation loss: 2.1591876168404855

Epoch: 6| Step: 1
Training loss: 1.594227910041809
Validation loss: 2.130898819174818

Epoch: 6| Step: 2
Training loss: 1.7721834182739258
Validation loss: 2.0607995615210584

Epoch: 6| Step: 3
Training loss: 1.5053433179855347
Validation loss: 2.0963621165162776

Epoch: 6| Step: 4
Training loss: 1.5874674320220947
Validation loss: 2.2137275921401156

Epoch: 6| Step: 5
Training loss: 1.9536941051483154
Validation loss: 2.1878551103735484

Epoch: 6| Step: 6
Training loss: 1.8881949186325073
Validation loss: 2.1525702181682793

Epoch: 6| Step: 7
Training loss: 2.073666572570801
Validation loss: 2.1798715296611992

Epoch: 6| Step: 8
Training loss: 1.736476182937622
Validation loss: 2.090764646889061

Epoch: 6| Step: 9
Training loss: 1.8987834453582764
Validation loss: 2.1209118981515207

Epoch: 6| Step: 10
Training loss: 2.8119497299194336
Validation loss: 2.13472415554908

Epoch: 6| Step: 11
Training loss: 1.736112356185913
Validation loss: 2.119623314949774

Epoch: 6| Step: 12
Training loss: 2.0629541873931885
Validation loss: 2.0839840314721547

Epoch: 6| Step: 13
Training loss: 1.076353907585144
Validation loss: 2.1098067632285495

Epoch: 345| Step: 0
Training loss: 1.5982043743133545
Validation loss: 2.1648050815828386

Epoch: 6| Step: 1
Training loss: 2.167412757873535
Validation loss: 2.1652202272927887

Epoch: 6| Step: 2
Training loss: 1.525475263595581
Validation loss: 2.0890058125219038

Epoch: 6| Step: 3
Training loss: 1.7427867650985718
Validation loss: 2.155010679716705

Epoch: 6| Step: 4
Training loss: 1.6112799644470215
Validation loss: 2.047017874256257

Epoch: 6| Step: 5
Training loss: 1.4317569732666016
Validation loss: 2.1325349987194104

Epoch: 6| Step: 6
Training loss: 1.980270266532898
Validation loss: 2.0827790870461413

Epoch: 6| Step: 7
Training loss: 1.4670767784118652
Validation loss: 2.102504886606688

Epoch: 6| Step: 8
Training loss: 1.986539602279663
Validation loss: 2.218688613624983

Epoch: 6| Step: 9
Training loss: 2.3104777336120605
Validation loss: 2.1562623439296598

Epoch: 6| Step: 10
Training loss: 2.7180302143096924
Validation loss: 2.213219599057269

Epoch: 6| Step: 11
Training loss: 1.9770619869232178
Validation loss: 2.195644679889884

Epoch: 6| Step: 12
Training loss: 1.864000916481018
Validation loss: 2.172049742872997

Epoch: 6| Step: 13
Training loss: 2.3211610317230225
Validation loss: 2.100248179128093

Epoch: 346| Step: 0
Training loss: 1.4942195415496826
Validation loss: 2.211148031296269

Epoch: 6| Step: 1
Training loss: 1.8237576484680176
Validation loss: 2.177116750389017

Epoch: 6| Step: 2
Training loss: 1.416515827178955
Validation loss: 2.1560076603325466

Epoch: 6| Step: 3
Training loss: 1.8114519119262695
Validation loss: 2.193343690646592

Epoch: 6| Step: 4
Training loss: 1.9507968425750732
Validation loss: 2.1121474260924966

Epoch: 6| Step: 5
Training loss: 2.8687584400177
Validation loss: 2.124964678159324

Epoch: 6| Step: 6
Training loss: 1.7880849838256836
Validation loss: 2.1985602609572874

Epoch: 6| Step: 7
Training loss: 1.447964072227478
Validation loss: 2.2264229636038504

Epoch: 6| Step: 8
Training loss: 1.6924035549163818
Validation loss: 2.0389844025335004

Epoch: 6| Step: 9
Training loss: 1.4926304817199707
Validation loss: 2.1503198377547728

Epoch: 6| Step: 10
Training loss: 2.417604446411133
Validation loss: 2.1299507310313563

Epoch: 6| Step: 11
Training loss: 1.6407091617584229
Validation loss: 2.016986631578015

Epoch: 6| Step: 12
Training loss: 2.016502857208252
Validation loss: 2.1570927135406004

Epoch: 6| Step: 13
Training loss: 1.8762874603271484
Validation loss: 2.171678567445406

Epoch: 347| Step: 0
Training loss: 1.9963914155960083
Validation loss: 2.1276427520218717

Epoch: 6| Step: 1
Training loss: 0.838480532169342
Validation loss: 2.13240005893092

Epoch: 6| Step: 2
Training loss: 2.3733632564544678
Validation loss: 2.0684273396768877

Epoch: 6| Step: 3
Training loss: 1.9926100969314575
Validation loss: 2.160500664864817

Epoch: 6| Step: 4
Training loss: 2.2586114406585693
Validation loss: 2.1287114517663115

Epoch: 6| Step: 5
Training loss: 1.2562247514724731
Validation loss: 2.0881334812410417

Epoch: 6| Step: 6
Training loss: 2.0158908367156982
Validation loss: 2.0674482494272213

Epoch: 6| Step: 7
Training loss: 1.878819227218628
Validation loss: 2.117774901851531

Epoch: 6| Step: 8
Training loss: 2.0983777046203613
Validation loss: 2.0369632269746516

Epoch: 6| Step: 9
Training loss: 1.3506784439086914
Validation loss: 2.162718419105776

Epoch: 6| Step: 10
Training loss: 1.6989562511444092
Validation loss: 2.1955148161098523

Epoch: 6| Step: 11
Training loss: 1.3522100448608398
Validation loss: 2.105227074315471

Epoch: 6| Step: 12
Training loss: 1.4082280397415161
Validation loss: 2.1272883530585998

Epoch: 6| Step: 13
Training loss: 2.1440536975860596
Validation loss: 2.237523017391082

Epoch: 348| Step: 0
Training loss: 2.033184289932251
Validation loss: 2.16060798270728

Epoch: 6| Step: 1
Training loss: 2.38785719871521
Validation loss: 2.0943468911673433

Epoch: 6| Step: 2
Training loss: 1.7617690563201904
Validation loss: 2.0730956985104467

Epoch: 6| Step: 3
Training loss: 1.540149450302124
Validation loss: 2.171776174217142

Epoch: 6| Step: 4
Training loss: 2.107320785522461
Validation loss: 2.089937963793355

Epoch: 6| Step: 5
Training loss: 2.161045789718628
Validation loss: 2.1109701933399325

Epoch: 6| Step: 6
Training loss: 1.6682980060577393
Validation loss: 2.0798424854073474

Epoch: 6| Step: 7
Training loss: 2.162785053253174
Validation loss: 2.160761146135228

Epoch: 6| Step: 8
Training loss: 1.9384962320327759
Validation loss: 2.1319497605805755

Epoch: 6| Step: 9
Training loss: 1.8328049182891846
Validation loss: 2.052603911328059

Epoch: 6| Step: 10
Training loss: 1.4043545722961426
Validation loss: 2.1449781694719867

Epoch: 6| Step: 11
Training loss: 1.407585859298706
Validation loss: 2.0741280919762066

Epoch: 6| Step: 12
Training loss: 2.368882894515991
Validation loss: 2.041924097204721

Epoch: 6| Step: 13
Training loss: 2.8606083393096924
Validation loss: 2.2007339051974717

Epoch: 349| Step: 0
Training loss: 2.0567708015441895
Validation loss: 2.0895365220244213

Epoch: 6| Step: 1
Training loss: 2.1534061431884766
Validation loss: 2.1620109773451284

Epoch: 6| Step: 2
Training loss: 2.396387815475464
Validation loss: 2.0745173641430434

Epoch: 6| Step: 3
Training loss: 1.596667766571045
Validation loss: 2.0904428087255007

Epoch: 6| Step: 4
Training loss: 1.5549439191818237
Validation loss: 2.1980022845729703

Epoch: 6| Step: 5
Training loss: 2.140470027923584
Validation loss: 2.150406442662721

Epoch: 6| Step: 6
Training loss: 1.610743761062622
Validation loss: 2.073698644996971

Epoch: 6| Step: 7
Training loss: 2.0087924003601074
Validation loss: 2.155622228499382

Epoch: 6| Step: 8
Training loss: 2.241083860397339
Validation loss: 2.13640147255313

Epoch: 6| Step: 9
Training loss: 1.5025116205215454
Validation loss: 2.1131202341407858

Epoch: 6| Step: 10
Training loss: 1.831300139427185
Validation loss: 2.161122309264316

Epoch: 6| Step: 11
Training loss: 1.9579541683197021
Validation loss: 2.105767009078815

Epoch: 6| Step: 12
Training loss: 0.9808678030967712
Validation loss: 2.160760297570177

Epoch: 6| Step: 13
Training loss: 1.4199644327163696
Validation loss: 2.071252146074849

Epoch: 350| Step: 0
Training loss: 1.4937729835510254
Validation loss: 2.118661980475149

Epoch: 6| Step: 1
Training loss: 1.202463150024414
Validation loss: 2.1373362925744828

Epoch: 6| Step: 2
Training loss: 2.059398651123047
Validation loss: 2.227821483406969

Epoch: 6| Step: 3
Training loss: 1.4712114334106445
Validation loss: 2.1024067632613646

Epoch: 6| Step: 4
Training loss: 2.685835361480713
Validation loss: 2.0645397927171443

Epoch: 6| Step: 5
Training loss: 1.9213571548461914
Validation loss: 2.0968399252942813

Epoch: 6| Step: 6
Training loss: 1.2436497211456299
Validation loss: 2.1141047580267793

Epoch: 6| Step: 7
Training loss: 1.696129322052002
Validation loss: 2.108185368199502

Epoch: 6| Step: 8
Training loss: 2.9619483947753906
Validation loss: 2.160743062214185

Epoch: 6| Step: 9
Training loss: 2.4163169860839844
Validation loss: 2.1505696850438274

Epoch: 6| Step: 10
Training loss: 1.8404861688613892
Validation loss: 2.1635680762670373

Epoch: 6| Step: 11
Training loss: 1.3686388731002808
Validation loss: 2.026612404854067

Epoch: 6| Step: 12
Training loss: 2.089921474456787
Validation loss: 2.18005855237284

Epoch: 6| Step: 13
Training loss: 1.2727820873260498
Validation loss: 2.0399726795893844

Epoch: 351| Step: 0
Training loss: 1.9018943309783936
Validation loss: 2.1577316073961157

Epoch: 6| Step: 1
Training loss: 2.065682888031006
Validation loss: 2.1277134546669583

Epoch: 6| Step: 2
Training loss: 1.6473920345306396
Validation loss: 2.1276250552105647

Epoch: 6| Step: 3
Training loss: 1.9582315683364868
Validation loss: 2.1444954782403927

Epoch: 6| Step: 4
Training loss: 2.263984441757202
Validation loss: 2.0156940401241346

Epoch: 6| Step: 5
Training loss: 1.2470617294311523
Validation loss: 2.0953211399816696

Epoch: 6| Step: 6
Training loss: 1.8260124921798706
Validation loss: 2.1893334170823455

Epoch: 6| Step: 7
Training loss: 1.5496121644973755
Validation loss: 2.102131120620235

Epoch: 6| Step: 8
Training loss: 1.5653400421142578
Validation loss: 2.0914903533074165

Epoch: 6| Step: 9
Training loss: 2.031005382537842
Validation loss: 2.1205525552072833

Epoch: 6| Step: 10
Training loss: 1.396138072013855
Validation loss: 2.1285162074591524

Epoch: 6| Step: 11
Training loss: 1.7758539915084839
Validation loss: 2.0935253943166425

Epoch: 6| Step: 12
Training loss: 1.895422339439392
Validation loss: 2.1279697956577426

Epoch: 6| Step: 13
Training loss: 2.7305216789245605
Validation loss: 2.1129990867389146

Epoch: 352| Step: 0
Training loss: 1.9319396018981934
Validation loss: 2.095468126317506

Epoch: 6| Step: 1
Training loss: 1.9436393976211548
Validation loss: 2.139633297920227

Epoch: 6| Step: 2
Training loss: 1.9211595058441162
Validation loss: 2.1104346321475123

Epoch: 6| Step: 3
Training loss: 0.7930037975311279
Validation loss: 2.1725735100366736

Epoch: 6| Step: 4
Training loss: 1.9928174018859863
Validation loss: 2.137450151546027

Epoch: 6| Step: 5
Training loss: 1.7538188695907593
Validation loss: 2.186600600519488

Epoch: 6| Step: 6
Training loss: 2.2318737506866455
Validation loss: 2.171974297492735

Epoch: 6| Step: 7
Training loss: 1.8278892040252686
Validation loss: 2.1699139174594673

Epoch: 6| Step: 8
Training loss: 1.5957331657409668
Validation loss: 2.1169879923584642

Epoch: 6| Step: 9
Training loss: 1.9291040897369385
Validation loss: 2.2047301979475122

Epoch: 6| Step: 10
Training loss: 1.858397364616394
Validation loss: 2.1481659104747157

Epoch: 6| Step: 11
Training loss: 1.7774837017059326
Validation loss: 2.1489070384733138

Epoch: 6| Step: 12
Training loss: 2.30110502243042
Validation loss: 2.129810716516228

Epoch: 6| Step: 13
Training loss: 2.4711127281188965
Validation loss: 2.127562058869229

Epoch: 353| Step: 0
Training loss: 1.565770149230957
Validation loss: 2.1538880704551615

Epoch: 6| Step: 1
Training loss: 1.8374030590057373
Validation loss: 2.147339533734065

Epoch: 6| Step: 2
Training loss: 1.3374361991882324
Validation loss: 2.1778410814141713

Epoch: 6| Step: 3
Training loss: 1.6898140907287598
Validation loss: 2.1884653568267822

Epoch: 6| Step: 4
Training loss: 1.6664074659347534
Validation loss: 2.146112370234664

Epoch: 6| Step: 5
Training loss: 2.0729987621307373
Validation loss: 2.0726021194970734

Epoch: 6| Step: 6
Training loss: 0.960889458656311
Validation loss: 2.1165772561104066

Epoch: 6| Step: 7
Training loss: 2.1274924278259277
Validation loss: 2.1100445332065707

Epoch: 6| Step: 8
Training loss: 1.9833890199661255
Validation loss: 2.194359838321645

Epoch: 6| Step: 9
Training loss: 1.5631370544433594
Validation loss: 2.0993361037264586

Epoch: 6| Step: 10
Training loss: 1.9960495233535767
Validation loss: 2.1420328719641573

Epoch: 6| Step: 11
Training loss: 2.0998263359069824
Validation loss: 2.0946030693669475

Epoch: 6| Step: 12
Training loss: 2.0153939723968506
Validation loss: 2.1616455354998187

Epoch: 6| Step: 13
Training loss: 2.4969727993011475
Validation loss: 2.1122619234105593

Epoch: 354| Step: 0
Training loss: 2.2301366329193115
Validation loss: 2.117474594423848

Epoch: 6| Step: 1
Training loss: 1.852582335472107
Validation loss: 2.142696044778311

Epoch: 6| Step: 2
Training loss: 2.2746691703796387
Validation loss: 2.117501801060092

Epoch: 6| Step: 3
Training loss: 1.2810677289962769
Validation loss: 2.140691667474726

Epoch: 6| Step: 4
Training loss: 1.4522857666015625
Validation loss: 2.1209251291008404

Epoch: 6| Step: 5
Training loss: 1.7460856437683105
Validation loss: 2.1109659466692197

Epoch: 6| Step: 6
Training loss: 2.094899892807007
Validation loss: 2.147180031704646

Epoch: 6| Step: 7
Training loss: 1.604827880859375
Validation loss: 2.136035075751684

Epoch: 6| Step: 8
Training loss: 1.7159610986709595
Validation loss: 2.085130355691397

Epoch: 6| Step: 9
Training loss: 1.901618242263794
Validation loss: 2.1853227256446757

Epoch: 6| Step: 10
Training loss: 1.581661343574524
Validation loss: 2.1622740145652526

Epoch: 6| Step: 11
Training loss: 1.8212134838104248
Validation loss: 2.1602818466001943

Epoch: 6| Step: 12
Training loss: 2.1144533157348633
Validation loss: 2.1126335615752847

Epoch: 6| Step: 13
Training loss: 2.523077964782715
Validation loss: 2.1012992192340154

Epoch: 355| Step: 0
Training loss: 1.2356412410736084
Validation loss: 2.1492940302818053

Epoch: 6| Step: 1
Training loss: 1.8576666116714478
Validation loss: 2.121203822474326

Epoch: 6| Step: 2
Training loss: 1.8817952871322632
Validation loss: 2.0777268666093067

Epoch: 6| Step: 3
Training loss: 2.405946969985962
Validation loss: 2.099257153849448

Epoch: 6| Step: 4
Training loss: 1.5175755023956299
Validation loss: 2.1585803237012637

Epoch: 6| Step: 5
Training loss: 2.2880029678344727
Validation loss: 2.143522856056049

Epoch: 6| Step: 6
Training loss: 1.220993995666504
Validation loss: 2.1582734200262252

Epoch: 6| Step: 7
Training loss: 2.187222719192505
Validation loss: 2.1997980571562246

Epoch: 6| Step: 8
Training loss: 2.022395133972168
Validation loss: 2.1796396945112493

Epoch: 6| Step: 9
Training loss: 1.6047979593276978
Validation loss: 2.119755409097159

Epoch: 6| Step: 10
Training loss: 2.1062240600585938
Validation loss: 2.185525930056008

Epoch: 6| Step: 11
Training loss: 2.111334800720215
Validation loss: 2.193471790641867

Epoch: 6| Step: 12
Training loss: 0.901102602481842
Validation loss: 2.177641155899212

Epoch: 6| Step: 13
Training loss: 2.1382598876953125
Validation loss: 2.174375396902843

Epoch: 356| Step: 0
Training loss: 1.7253023386001587
Validation loss: 2.074629017101821

Epoch: 6| Step: 1
Training loss: 1.9068776369094849
Validation loss: 2.1221939056150374

Epoch: 6| Step: 2
Training loss: 1.821140170097351
Validation loss: 2.1450492899904967

Epoch: 6| Step: 3
Training loss: 2.213533401489258
Validation loss: 2.18985757776486

Epoch: 6| Step: 4
Training loss: 1.1875998973846436
Validation loss: 2.0985014387356338

Epoch: 6| Step: 5
Training loss: 1.4369574785232544
Validation loss: 2.0702901053172287

Epoch: 6| Step: 6
Training loss: 2.5955357551574707
Validation loss: 2.114704798626643

Epoch: 6| Step: 7
Training loss: 1.2227916717529297
Validation loss: 2.122553925360403

Epoch: 6| Step: 8
Training loss: 1.8705626726150513
Validation loss: 2.0770228972998996

Epoch: 6| Step: 9
Training loss: 2.0304460525512695
Validation loss: 2.1065270413634596

Epoch: 6| Step: 10
Training loss: 2.0251777172088623
Validation loss: 2.109685649154007

Epoch: 6| Step: 11
Training loss: 2.220808267593384
Validation loss: 2.1873444818681285

Epoch: 6| Step: 12
Training loss: 1.7717585563659668
Validation loss: 2.166844835845373

Epoch: 6| Step: 13
Training loss: 1.7797465324401855
Validation loss: 2.1015477334299395

Epoch: 357| Step: 0
Training loss: 1.6851904392242432
Validation loss: 2.1038545946921072

Epoch: 6| Step: 1
Training loss: 1.7526211738586426
Validation loss: 2.0725077275306947

Epoch: 6| Step: 2
Training loss: 2.38224720954895
Validation loss: 2.138596083528252

Epoch: 6| Step: 3
Training loss: 1.5351831912994385
Validation loss: 2.118917547246461

Epoch: 6| Step: 4
Training loss: 1.85147225856781
Validation loss: 2.1477052268161567

Epoch: 6| Step: 5
Training loss: 2.400115966796875
Validation loss: 2.1443410470921505

Epoch: 6| Step: 6
Training loss: 2.1000304222106934
Validation loss: 2.101621614989414

Epoch: 6| Step: 7
Training loss: 1.227522611618042
Validation loss: 2.221249503474082

Epoch: 6| Step: 8
Training loss: 1.8408112525939941
Validation loss: 2.112725552692208

Epoch: 6| Step: 9
Training loss: 1.7439714670181274
Validation loss: 2.2114852500218216

Epoch: 6| Step: 10
Training loss: 2.734605073928833
Validation loss: 2.107280003127231

Epoch: 6| Step: 11
Training loss: 1.8080129623413086
Validation loss: 2.179638470372846

Epoch: 6| Step: 12
Training loss: 1.0351532697677612
Validation loss: 2.083360739933547

Epoch: 6| Step: 13
Training loss: 0.9626477360725403
Validation loss: 2.144205007501828

Epoch: 358| Step: 0
Training loss: 2.542843818664551
Validation loss: 2.1143896400287585

Epoch: 6| Step: 1
Training loss: 1.5390955209732056
Validation loss: 2.1488585907925843

Epoch: 6| Step: 2
Training loss: 1.4454584121704102
Validation loss: 2.0872078249531407

Epoch: 6| Step: 3
Training loss: 2.3710665702819824
Validation loss: 2.140898487901175

Epoch: 6| Step: 4
Training loss: 1.7711565494537354
Validation loss: 2.0743242425303303

Epoch: 6| Step: 5
Training loss: 1.2851524353027344
Validation loss: 2.158834813743509

Epoch: 6| Step: 6
Training loss: 2.2255711555480957
Validation loss: 2.1600967427735687

Epoch: 6| Step: 7
Training loss: 1.3489537239074707
Validation loss: 2.1659522594944125

Epoch: 6| Step: 8
Training loss: 2.234743356704712
Validation loss: 2.129161439916139

Epoch: 6| Step: 9
Training loss: 1.9869940280914307
Validation loss: 2.1513757244233163

Epoch: 6| Step: 10
Training loss: 1.6009907722473145
Validation loss: 2.070106283310921

Epoch: 6| Step: 11
Training loss: 1.7564079761505127
Validation loss: 2.1862868544875935

Epoch: 6| Step: 12
Training loss: 2.2638309001922607
Validation loss: 2.179733363530969

Epoch: 6| Step: 13
Training loss: 1.0706801414489746
Validation loss: 2.205173146340155

Epoch: 359| Step: 0
Training loss: 2.1256279945373535
Validation loss: 2.1204818064166653

Epoch: 6| Step: 1
Training loss: 2.142444133758545
Validation loss: 2.1038230362758843

Epoch: 6| Step: 2
Training loss: 2.0355236530303955
Validation loss: 2.0916468020408385

Epoch: 6| Step: 3
Training loss: 1.9087958335876465
Validation loss: 2.161762979722792

Epoch: 6| Step: 4
Training loss: 2.4716808795928955
Validation loss: 2.131891281374039

Epoch: 6| Step: 5
Training loss: 1.6916570663452148
Validation loss: 2.147394503316572

Epoch: 6| Step: 6
Training loss: 1.570744276046753
Validation loss: 2.1552852020468762

Epoch: 6| Step: 7
Training loss: 1.7378103733062744
Validation loss: 2.126519815896147

Epoch: 6| Step: 8
Training loss: 2.2089474201202393
Validation loss: 2.130627106594783

Epoch: 6| Step: 9
Training loss: 0.8582395315170288
Validation loss: 2.0462183644694667

Epoch: 6| Step: 10
Training loss: 1.5889372825622559
Validation loss: 2.095469590156309

Epoch: 6| Step: 11
Training loss: 1.827383041381836
Validation loss: 2.1528384634243545

Epoch: 6| Step: 12
Training loss: 1.5012805461883545
Validation loss: 2.0991299870193645

Epoch: 6| Step: 13
Training loss: 2.251164436340332
Validation loss: 2.085302059368421

Epoch: 360| Step: 0
Training loss: 1.7343134880065918
Validation loss: 2.064237294658538

Epoch: 6| Step: 1
Training loss: 2.0329642295837402
Validation loss: 2.1048585266195317

Epoch: 6| Step: 2
Training loss: 1.6370455026626587
Validation loss: 2.1413453432821457

Epoch: 6| Step: 3
Training loss: 2.061923027038574
Validation loss: 2.173454115467687

Epoch: 6| Step: 4
Training loss: 1.844639778137207
Validation loss: 2.122168720409434

Epoch: 6| Step: 5
Training loss: 1.9215980768203735
Validation loss: 2.09765560396256

Epoch: 6| Step: 6
Training loss: 2.0140957832336426
Validation loss: 2.2078126604839037

Epoch: 6| Step: 7
Training loss: 1.7118816375732422
Validation loss: 2.178178516767358

Epoch: 6| Step: 8
Training loss: 3.1131441593170166
Validation loss: 2.19947898516091

Epoch: 6| Step: 9
Training loss: 1.7765130996704102
Validation loss: 2.085631352598949

Epoch: 6| Step: 10
Training loss: 1.9943017959594727
Validation loss: 2.0884335258955598

Epoch: 6| Step: 11
Training loss: 1.4400956630706787
Validation loss: 2.1809698561186432

Epoch: 6| Step: 12
Training loss: 1.4818942546844482
Validation loss: 2.0807054683726323

Epoch: 6| Step: 13
Training loss: 0.9809302091598511
Validation loss: 2.1763910670434274

Epoch: 361| Step: 0
Training loss: 2.4852454662323
Validation loss: 2.1136796871821084

Epoch: 6| Step: 1
Training loss: 1.6832811832427979
Validation loss: 2.1526343540478776

Epoch: 6| Step: 2
Training loss: 2.3635337352752686
Validation loss: 2.108956701012068

Epoch: 6| Step: 3
Training loss: 1.2625863552093506
Validation loss: 2.1052497074168217

Epoch: 6| Step: 4
Training loss: 1.0516362190246582
Validation loss: 2.1171752868160123

Epoch: 6| Step: 5
Training loss: 1.7156593799591064
Validation loss: 2.0722464297407415

Epoch: 6| Step: 6
Training loss: 1.8523837327957153
Validation loss: 2.1023372680910173

Epoch: 6| Step: 7
Training loss: 1.4383516311645508
Validation loss: 2.0828373752614504

Epoch: 6| Step: 8
Training loss: 1.7062854766845703
Validation loss: 2.104755518256977

Epoch: 6| Step: 9
Training loss: 1.9735068082809448
Validation loss: 2.1144443327380764

Epoch: 6| Step: 10
Training loss: 1.8686842918395996
Validation loss: 2.160907919688891

Epoch: 6| Step: 11
Training loss: 2.479088544845581
Validation loss: 2.07283253054465

Epoch: 6| Step: 12
Training loss: 2.0252397060394287
Validation loss: 2.0183573025529102

Epoch: 6| Step: 13
Training loss: 1.831758975982666
Validation loss: 2.157897792836671

Epoch: 362| Step: 0
Training loss: 1.6455210447311401
Validation loss: 2.0925555331732637

Epoch: 6| Step: 1
Training loss: 2.315011978149414
Validation loss: 2.1480182191377044

Epoch: 6| Step: 2
Training loss: 2.1047396659851074
Validation loss: 2.1069542746390066

Epoch: 6| Step: 3
Training loss: 1.9170385599136353
Validation loss: 2.1699978625902565

Epoch: 6| Step: 4
Training loss: 1.8882356882095337
Validation loss: 2.162287140405306

Epoch: 6| Step: 5
Training loss: 1.9930989742279053
Validation loss: 2.098476835476455

Epoch: 6| Step: 6
Training loss: 1.4732756614685059
Validation loss: 2.10024251860957

Epoch: 6| Step: 7
Training loss: 1.3678749799728394
Validation loss: 2.225634918417982

Epoch: 6| Step: 8
Training loss: 2.023491859436035
Validation loss: 2.2234331305309007

Epoch: 6| Step: 9
Training loss: 1.449447512626648
Validation loss: 2.0993822146487493

Epoch: 6| Step: 10
Training loss: 1.9974244832992554
Validation loss: 2.1695681284832697

Epoch: 6| Step: 11
Training loss: 1.440089464187622
Validation loss: 2.1937670656429824

Epoch: 6| Step: 12
Training loss: 1.8019487857818604
Validation loss: 2.1060046560020855

Epoch: 6| Step: 13
Training loss: 2.027245044708252
Validation loss: 2.147361381079561

Epoch: 363| Step: 0
Training loss: 1.3302509784698486
Validation loss: 2.1680049447603125

Epoch: 6| Step: 1
Training loss: 1.9558775424957275
Validation loss: 2.1864842086709957

Epoch: 6| Step: 2
Training loss: 1.8804680109024048
Validation loss: 2.120556123795048

Epoch: 6| Step: 3
Training loss: 1.7595033645629883
Validation loss: 2.1913623053540467

Epoch: 6| Step: 4
Training loss: 1.6616555452346802
Validation loss: 2.0841830609947123

Epoch: 6| Step: 5
Training loss: 1.6828608512878418
Validation loss: 2.190178657090792

Epoch: 6| Step: 6
Training loss: 1.9359210729599
Validation loss: 2.205719878596644

Epoch: 6| Step: 7
Training loss: 2.6907525062561035
Validation loss: 2.1745028726516233

Epoch: 6| Step: 8
Training loss: 1.5643589496612549
Validation loss: 2.097243106493386

Epoch: 6| Step: 9
Training loss: 1.0666589736938477
Validation loss: 2.1164076687187277

Epoch: 6| Step: 10
Training loss: 1.9852590560913086
Validation loss: 2.109828850274445

Epoch: 6| Step: 11
Training loss: 2.2250704765319824
Validation loss: 2.1155575731749177

Epoch: 6| Step: 12
Training loss: 1.8856101036071777
Validation loss: 2.174778853693316

Epoch: 6| Step: 13
Training loss: 1.4307438135147095
Validation loss: 2.188773447467435

Epoch: 364| Step: 0
Training loss: 1.5326409339904785
Validation loss: 2.10408486986673

Epoch: 6| Step: 1
Training loss: 1.579530954360962
Validation loss: 2.07714065172339

Epoch: 6| Step: 2
Training loss: 1.9322848320007324
Validation loss: 2.0619758252174623

Epoch: 6| Step: 3
Training loss: 1.4563603401184082
Validation loss: 2.2013973497575328

Epoch: 6| Step: 4
Training loss: 2.5209364891052246
Validation loss: 2.1668259918048816

Epoch: 6| Step: 5
Training loss: 2.379894733428955
Validation loss: 2.1113210314063617

Epoch: 6| Step: 6
Training loss: 1.8612785339355469
Validation loss: 2.126980121417712

Epoch: 6| Step: 7
Training loss: 2.059621810913086
Validation loss: 2.164888451176305

Epoch: 6| Step: 8
Training loss: 1.3710047006607056
Validation loss: 2.143303653245331

Epoch: 6| Step: 9
Training loss: 1.2788681983947754
Validation loss: 2.081883672744997

Epoch: 6| Step: 10
Training loss: 1.6076762676239014
Validation loss: 2.145787592857115

Epoch: 6| Step: 11
Training loss: 1.8692551851272583
Validation loss: 2.174769457950387

Epoch: 6| Step: 12
Training loss: 1.6733980178833008
Validation loss: 2.206166046921925

Epoch: 6| Step: 13
Training loss: 1.6337674856185913
Validation loss: 2.174436307722522

Epoch: 365| Step: 0
Training loss: 2.5252623558044434
Validation loss: 2.071362292894753

Epoch: 6| Step: 1
Training loss: 2.142017364501953
Validation loss: 2.0870359738667807

Epoch: 6| Step: 2
Training loss: 1.502023696899414
Validation loss: 2.0599770917687366

Epoch: 6| Step: 3
Training loss: 1.98439621925354
Validation loss: 2.1551660696665444

Epoch: 6| Step: 4
Training loss: 1.628000259399414
Validation loss: 2.109345022068229

Epoch: 6| Step: 5
Training loss: 1.8173744678497314
Validation loss: 2.159699116983721

Epoch: 6| Step: 6
Training loss: 1.5193358659744263
Validation loss: 2.1879691462362967

Epoch: 6| Step: 7
Training loss: 2.6726276874542236
Validation loss: 2.1830467229248374

Epoch: 6| Step: 8
Training loss: 1.3952240943908691
Validation loss: 2.0977286831025155

Epoch: 6| Step: 9
Training loss: 1.8709838390350342
Validation loss: 2.067253271738688

Epoch: 6| Step: 10
Training loss: 1.241112470626831
Validation loss: 2.1816270838501635

Epoch: 6| Step: 11
Training loss: 1.8214049339294434
Validation loss: 2.1084869420656593

Epoch: 6| Step: 12
Training loss: 1.3329296112060547
Validation loss: 2.111956862993138

Epoch: 6| Step: 13
Training loss: 2.1356914043426514
Validation loss: 2.120575037053836

Epoch: 366| Step: 0
Training loss: 2.0004453659057617
Validation loss: 2.083608235082319

Epoch: 6| Step: 1
Training loss: 2.141850471496582
Validation loss: 2.128413801552147

Epoch: 6| Step: 2
Training loss: 1.4364650249481201
Validation loss: 2.1564446931244223

Epoch: 6| Step: 3
Training loss: 2.017155170440674
Validation loss: 2.134374077602099

Epoch: 6| Step: 4
Training loss: 1.160369634628296
Validation loss: 2.0772407362538

Epoch: 6| Step: 5
Training loss: 2.3371801376342773
Validation loss: 2.0898328763182445

Epoch: 6| Step: 6
Training loss: 1.8287063837051392
Validation loss: 2.2156401141997306

Epoch: 6| Step: 7
Training loss: 1.7776648998260498
Validation loss: 2.1287705744466474

Epoch: 6| Step: 8
Training loss: 1.8923624753952026
Validation loss: 2.1913054707229778

Epoch: 6| Step: 9
Training loss: 1.912251353263855
Validation loss: 2.1862409294292493

Epoch: 6| Step: 10
Training loss: 1.2903026342391968
Validation loss: 2.0797807080771333

Epoch: 6| Step: 11
Training loss: 1.7656372785568237
Validation loss: 2.1440359059200493

Epoch: 6| Step: 12
Training loss: 1.2539236545562744
Validation loss: 2.145343569017226

Epoch: 6| Step: 13
Training loss: 2.151336669921875
Validation loss: 2.1152402431734147

Epoch: 367| Step: 0
Training loss: 1.482024073600769
Validation loss: 2.1559020934566373

Epoch: 6| Step: 1
Training loss: 2.2988719940185547
Validation loss: 2.1251243263162594

Epoch: 6| Step: 2
Training loss: 1.7534186840057373
Validation loss: 2.1452257223026727

Epoch: 6| Step: 3
Training loss: 1.5876092910766602
Validation loss: 2.148020940442239

Epoch: 6| Step: 4
Training loss: 1.7091490030288696
Validation loss: 2.14134205284939

Epoch: 6| Step: 5
Training loss: 1.9567358493804932
Validation loss: 2.1436886479777675

Epoch: 6| Step: 6
Training loss: 1.499985694885254
Validation loss: 2.178039276471702

Epoch: 6| Step: 7
Training loss: 2.5508172512054443
Validation loss: 2.1658523441642843

Epoch: 6| Step: 8
Training loss: 2.294182300567627
Validation loss: 2.0661879175452778

Epoch: 6| Step: 9
Training loss: 1.9940664768218994
Validation loss: 2.138221561267812

Epoch: 6| Step: 10
Training loss: 1.4266977310180664
Validation loss: 2.158643550770257

Epoch: 6| Step: 11
Training loss: 1.7408586740493774
Validation loss: 2.1229274490828156

Epoch: 6| Step: 12
Training loss: 1.6627137660980225
Validation loss: 2.1705418658512894

Epoch: 6| Step: 13
Training loss: 1.357742190361023
Validation loss: 2.1395185109107726

Epoch: 368| Step: 0
Training loss: 1.9685288667678833
Validation loss: 2.135523914009012

Epoch: 6| Step: 1
Training loss: 1.3625736236572266
Validation loss: 2.1368108821171585

Epoch: 6| Step: 2
Training loss: 1.356181025505066
Validation loss: 2.105979706651421

Epoch: 6| Step: 3
Training loss: 1.748842716217041
Validation loss: 2.0703189026924873

Epoch: 6| Step: 4
Training loss: 1.2989377975463867
Validation loss: 2.104062875111898

Epoch: 6| Step: 5
Training loss: 2.0310091972351074
Validation loss: 2.0853801901622484

Epoch: 6| Step: 6
Training loss: 2.102283477783203
Validation loss: 2.057267690217623

Epoch: 6| Step: 7
Training loss: 2.1804404258728027
Validation loss: 2.1646418071562246

Epoch: 6| Step: 8
Training loss: 1.8060684204101562
Validation loss: 2.1281093666630406

Epoch: 6| Step: 9
Training loss: 2.0616307258605957
Validation loss: 2.0835565854144353

Epoch: 6| Step: 10
Training loss: 1.850074291229248
Validation loss: 2.089366005313012

Epoch: 6| Step: 11
Training loss: 2.155069351196289
Validation loss: 2.1715028362889446

Epoch: 6| Step: 12
Training loss: 2.099762201309204
Validation loss: 2.091273743619201

Epoch: 6| Step: 13
Training loss: 1.2557493448257446
Validation loss: 2.1918964565441175

Epoch: 369| Step: 0
Training loss: 1.726353645324707
Validation loss: 2.1376602816325363

Epoch: 6| Step: 1
Training loss: 2.5886545181274414
Validation loss: 2.093546382842525

Epoch: 6| Step: 2
Training loss: 2.3811662197113037
Validation loss: 2.097895883744763

Epoch: 6| Step: 3
Training loss: 1.5391584634780884
Validation loss: 2.1797034253356276

Epoch: 6| Step: 4
Training loss: 1.4698048830032349
Validation loss: 2.1747984322168494

Epoch: 6| Step: 5
Training loss: 1.8267757892608643
Validation loss: 2.1524783385697233

Epoch: 6| Step: 6
Training loss: 1.924438714981079
Validation loss: 2.1410485493239535

Epoch: 6| Step: 7
Training loss: 1.8116124868392944
Validation loss: 2.095927748628842

Epoch: 6| Step: 8
Training loss: 1.521214246749878
Validation loss: 2.188282633340487

Epoch: 6| Step: 9
Training loss: 1.1897835731506348
Validation loss: 2.175189902705531

Epoch: 6| Step: 10
Training loss: 1.9274722337722778
Validation loss: 2.207306702931722

Epoch: 6| Step: 11
Training loss: 1.5231208801269531
Validation loss: 2.20454930233699

Epoch: 6| Step: 12
Training loss: 1.8395490646362305
Validation loss: 2.2404173010139057

Epoch: 6| Step: 13
Training loss: 2.4971511363983154
Validation loss: 2.167046880209318

Epoch: 370| Step: 0
Training loss: 1.6904577016830444
Validation loss: 2.1524998782783427

Epoch: 6| Step: 1
Training loss: 1.433401346206665
Validation loss: 2.1500357402268278

Epoch: 6| Step: 2
Training loss: 2.0774803161621094
Validation loss: 2.157690732709823

Epoch: 6| Step: 3
Training loss: 1.670717716217041
Validation loss: 2.1169382013300413

Epoch: 6| Step: 4
Training loss: 1.6867345571517944
Validation loss: 2.117486471770912

Epoch: 6| Step: 5
Training loss: 2.20082426071167
Validation loss: 2.0689338227753997

Epoch: 6| Step: 6
Training loss: 1.6284619569778442
Validation loss: 2.097607943319505

Epoch: 6| Step: 7
Training loss: 1.2216770648956299
Validation loss: 2.244268559640454

Epoch: 6| Step: 8
Training loss: 1.610857605934143
Validation loss: 2.121092927071356

Epoch: 6| Step: 9
Training loss: 1.4883763790130615
Validation loss: 2.13327185825635

Epoch: 6| Step: 10
Training loss: 1.6919732093811035
Validation loss: 2.0643247276224117

Epoch: 6| Step: 11
Training loss: 2.326719284057617
Validation loss: 2.204193584380611

Epoch: 6| Step: 12
Training loss: 1.9937775135040283
Validation loss: 2.0921601339053084

Epoch: 6| Step: 13
Training loss: 2.3312180042266846
Validation loss: 2.2329357977836364

Epoch: 371| Step: 0
Training loss: 1.586169719696045
Validation loss: 2.169738023511825

Epoch: 6| Step: 1
Training loss: 1.6609597206115723
Validation loss: 2.142013854877923

Epoch: 6| Step: 2
Training loss: 1.372013807296753
Validation loss: 2.099887890200461

Epoch: 6| Step: 3
Training loss: 1.722062587738037
Validation loss: 2.127505002483245

Epoch: 6| Step: 4
Training loss: 1.5102579593658447
Validation loss: 2.1244316857348204

Epoch: 6| Step: 5
Training loss: 1.8288328647613525
Validation loss: 2.136898681681643

Epoch: 6| Step: 6
Training loss: 2.256575584411621
Validation loss: 2.226589584863314

Epoch: 6| Step: 7
Training loss: 1.6660332679748535
Validation loss: 2.1507222101252568

Epoch: 6| Step: 8
Training loss: 1.7258920669555664
Validation loss: 2.1566896207870974

Epoch: 6| Step: 9
Training loss: 1.5238620042800903
Validation loss: 2.209774209607032

Epoch: 6| Step: 10
Training loss: 2.280838966369629
Validation loss: 2.1821708833017657

Epoch: 6| Step: 11
Training loss: 2.0168230533599854
Validation loss: 2.136486380330978

Epoch: 6| Step: 12
Training loss: 1.8105545043945312
Validation loss: 2.0611185002070602

Epoch: 6| Step: 13
Training loss: 2.2044177055358887
Validation loss: 2.186729754171064

Epoch: 372| Step: 0
Training loss: 2.0109755992889404
Validation loss: 2.1733436533199844

Epoch: 6| Step: 1
Training loss: 1.659934163093567
Validation loss: 2.223465565712221

Epoch: 6| Step: 2
Training loss: 2.013530731201172
Validation loss: 2.1833460177144697

Epoch: 6| Step: 3
Training loss: 1.2699285745620728
Validation loss: 2.111507369625953

Epoch: 6| Step: 4
Training loss: 1.0753529071807861
Validation loss: 2.1466067247493292

Epoch: 6| Step: 5
Training loss: 1.537612795829773
Validation loss: 2.16473295868084

Epoch: 6| Step: 6
Training loss: 1.6919595003128052
Validation loss: 2.1746962660102436

Epoch: 6| Step: 7
Training loss: 1.6709084510803223
Validation loss: 2.1436525672994633

Epoch: 6| Step: 8
Training loss: 1.9213505983352661
Validation loss: 2.1362089149413572

Epoch: 6| Step: 9
Training loss: 1.9031472206115723
Validation loss: 2.109904122608964

Epoch: 6| Step: 10
Training loss: 2.1887688636779785
Validation loss: 2.092888186054845

Epoch: 6| Step: 11
Training loss: 2.0701427459716797
Validation loss: 2.15321486226974

Epoch: 6| Step: 12
Training loss: 2.107334852218628
Validation loss: 2.0412961142037505

Epoch: 6| Step: 13
Training loss: 2.18442440032959
Validation loss: 2.1270258606121106

Epoch: 373| Step: 0
Training loss: 1.8236442804336548
Validation loss: 2.111235796764333

Epoch: 6| Step: 1
Training loss: 2.2237296104431152
Validation loss: 2.104483699285856

Epoch: 6| Step: 2
Training loss: 1.8460693359375
Validation loss: 2.0851127332256687

Epoch: 6| Step: 3
Training loss: 1.7229233980178833
Validation loss: 2.1191907621199086

Epoch: 6| Step: 4
Training loss: 2.076477527618408
Validation loss: 2.16654699079452

Epoch: 6| Step: 5
Training loss: 1.7571938037872314
Validation loss: 2.1258484022591704

Epoch: 6| Step: 6
Training loss: 1.7774968147277832
Validation loss: 2.2143769520585255

Epoch: 6| Step: 7
Training loss: 1.918269157409668
Validation loss: 2.1320491760007796

Epoch: 6| Step: 8
Training loss: 1.6555206775665283
Validation loss: 2.0729568799336753

Epoch: 6| Step: 9
Training loss: 1.575993299484253
Validation loss: 2.1149161502879155

Epoch: 6| Step: 10
Training loss: 1.857954978942871
Validation loss: 2.231234842731107

Epoch: 6| Step: 11
Training loss: 1.2361689805984497
Validation loss: 2.118329244275247

Epoch: 6| Step: 12
Training loss: 1.9668844938278198
Validation loss: 2.1491939226786294

Epoch: 6| Step: 13
Training loss: 2.1799190044403076
Validation loss: 2.0878438475311443

Epoch: 374| Step: 0
Training loss: 1.6020917892456055
Validation loss: 2.1720406573305846

Epoch: 6| Step: 1
Training loss: 2.1990747451782227
Validation loss: 2.102361782904594

Epoch: 6| Step: 2
Training loss: 1.4499192237854004
Validation loss: 2.1508071576395342

Epoch: 6| Step: 3
Training loss: 1.9609836339950562
Validation loss: 2.1820523700406476

Epoch: 6| Step: 4
Training loss: 1.7183113098144531
Validation loss: 2.138943783698543

Epoch: 6| Step: 5
Training loss: 2.2699482440948486
Validation loss: 2.1890712925182876

Epoch: 6| Step: 6
Training loss: 1.2963447570800781
Validation loss: 2.1900258205270253

Epoch: 6| Step: 7
Training loss: 1.7204350233078003
Validation loss: 2.1976485560017247

Epoch: 6| Step: 8
Training loss: 1.9270777702331543
Validation loss: 2.167650879070323

Epoch: 6| Step: 9
Training loss: 1.230265736579895
Validation loss: 2.1708134938311834

Epoch: 6| Step: 10
Training loss: 1.0712826251983643
Validation loss: 2.100335339064239

Epoch: 6| Step: 11
Training loss: 1.92490553855896
Validation loss: 2.0662346245140157

Epoch: 6| Step: 12
Training loss: 1.9999011754989624
Validation loss: 2.17459838492896

Epoch: 6| Step: 13
Training loss: 2.8456430435180664
Validation loss: 2.112231475050731

Epoch: 375| Step: 0
Training loss: 2.298285484313965
Validation loss: 2.1374655385171213

Epoch: 6| Step: 1
Training loss: 1.5058866739273071
Validation loss: 2.1995111306508384

Epoch: 6| Step: 2
Training loss: 1.7013654708862305
Validation loss: 2.1712777794048352

Epoch: 6| Step: 3
Training loss: 1.8810151815414429
Validation loss: 2.1090614077865437

Epoch: 6| Step: 4
Training loss: 1.1808905601501465
Validation loss: 2.0818600064964703

Epoch: 6| Step: 5
Training loss: 1.2484508752822876
Validation loss: 2.2999884902790027

Epoch: 6| Step: 6
Training loss: 2.2924118041992188
Validation loss: 2.160832481999551

Epoch: 6| Step: 7
Training loss: 1.522099256515503
Validation loss: 2.1512501060321765

Epoch: 6| Step: 8
Training loss: 2.20434832572937
Validation loss: 2.1447977609531854

Epoch: 6| Step: 9
Training loss: 1.3170180320739746
Validation loss: 2.058862090110779

Epoch: 6| Step: 10
Training loss: 2.203731060028076
Validation loss: 2.149398030773286

Epoch: 6| Step: 11
Training loss: 2.4297409057617188
Validation loss: 2.079578458621938

Epoch: 6| Step: 12
Training loss: 1.6934349536895752
Validation loss: 2.1170448692896033

Epoch: 6| Step: 13
Training loss: 1.507865071296692
Validation loss: 2.1886681331101285

Epoch: 376| Step: 0
Training loss: 2.0066614151000977
Validation loss: 2.07971792323615

Epoch: 6| Step: 1
Training loss: 1.6534039974212646
Validation loss: 2.1384889733406807

Epoch: 6| Step: 2
Training loss: 1.504940390586853
Validation loss: 2.140212417930685

Epoch: 6| Step: 3
Training loss: 1.5058116912841797
Validation loss: 2.1012692912932365

Epoch: 6| Step: 4
Training loss: 1.0567744970321655
Validation loss: 2.1359651844988585

Epoch: 6| Step: 5
Training loss: 2.01430344581604
Validation loss: 2.164347643493324

Epoch: 6| Step: 6
Training loss: 1.795373558998108
Validation loss: 2.1298262316693544

Epoch: 6| Step: 7
Training loss: 1.9368830919265747
Validation loss: 2.0647776331952823

Epoch: 6| Step: 8
Training loss: 2.053219795227051
Validation loss: 2.129082992512693

Epoch: 6| Step: 9
Training loss: 1.9717475175857544
Validation loss: 2.1125718675633913

Epoch: 6| Step: 10
Training loss: 1.4684300422668457
Validation loss: 2.193517052999107

Epoch: 6| Step: 11
Training loss: 1.5295014381408691
Validation loss: 2.1078863502830587

Epoch: 6| Step: 12
Training loss: 2.432889223098755
Validation loss: 2.1217566536318873

Epoch: 6| Step: 13
Training loss: 1.6735577583312988
Validation loss: 2.1504634708486576

Epoch: 377| Step: 0
Training loss: 2.0584986209869385
Validation loss: 2.0689433185003137

Epoch: 6| Step: 1
Training loss: 1.5813567638397217
Validation loss: 2.080260676722373

Epoch: 6| Step: 2
Training loss: 1.6756020784378052
Validation loss: 2.094091382077945

Epoch: 6| Step: 3
Training loss: 1.470258116722107
Validation loss: 2.2390261106593634

Epoch: 6| Step: 4
Training loss: 1.7671228647232056
Validation loss: 2.1396166663016043

Epoch: 6| Step: 5
Training loss: 1.3434443473815918
Validation loss: 2.1123411424698366

Epoch: 6| Step: 6
Training loss: 1.9798293113708496
Validation loss: 2.0545381884421072

Epoch: 6| Step: 7
Training loss: 2.5301756858825684
Validation loss: 2.1410431682422595

Epoch: 6| Step: 8
Training loss: 2.542257785797119
Validation loss: 2.1036306145370647

Epoch: 6| Step: 9
Training loss: 1.0257266759872437
Validation loss: 2.1431343542632235

Epoch: 6| Step: 10
Training loss: 1.620449423789978
Validation loss: 2.1443194650834605

Epoch: 6| Step: 11
Training loss: 1.9819352626800537
Validation loss: 2.2051630866143013

Epoch: 6| Step: 12
Training loss: 1.2321747541427612
Validation loss: 2.067102610424001

Epoch: 6| Step: 13
Training loss: 2.2394068241119385
Validation loss: 2.2508519529014506

Epoch: 378| Step: 0
Training loss: 2.4456279277801514
Validation loss: 2.1083979388718963

Epoch: 6| Step: 1
Training loss: 1.9938173294067383
Validation loss: 2.1100522420739614

Epoch: 6| Step: 2
Training loss: 1.5491430759429932
Validation loss: 2.279765852036015

Epoch: 6| Step: 3
Training loss: 2.035524606704712
Validation loss: 2.2135026326743503

Epoch: 6| Step: 4
Training loss: 1.9146318435668945
Validation loss: 2.176057432287483

Epoch: 6| Step: 5
Training loss: 1.6483213901519775
Validation loss: 2.158049891071935

Epoch: 6| Step: 6
Training loss: 1.7282541990280151
Validation loss: 2.1796232602929555

Epoch: 6| Step: 7
Training loss: 1.7921884059906006
Validation loss: 2.1335868412448513

Epoch: 6| Step: 8
Training loss: 1.6450932025909424
Validation loss: 2.2026077111562095

Epoch: 6| Step: 9
Training loss: 1.2243001461029053
Validation loss: 2.1427872078393095

Epoch: 6| Step: 10
Training loss: 1.9608403444290161
Validation loss: 2.0777304685243996

Epoch: 6| Step: 11
Training loss: 1.6203802824020386
Validation loss: 2.1618229522499988

Epoch: 6| Step: 12
Training loss: 2.277189016342163
Validation loss: 2.2319267257567375

Epoch: 6| Step: 13
Training loss: 0.9314826130867004
Validation loss: 2.1369015221954673

Epoch: 379| Step: 0
Training loss: 1.600893259048462
Validation loss: 2.1786857266579904

Epoch: 6| Step: 1
Training loss: 2.8121047019958496
Validation loss: 2.1406366338012037

Epoch: 6| Step: 2
Training loss: 1.805773377418518
Validation loss: 2.1996902240219938

Epoch: 6| Step: 3
Training loss: 1.6766489744186401
Validation loss: 2.157699102996498

Epoch: 6| Step: 4
Training loss: 1.571871042251587
Validation loss: 2.1184178654865553

Epoch: 6| Step: 5
Training loss: 1.9956626892089844
Validation loss: 2.1368030886496268

Epoch: 6| Step: 6
Training loss: 1.520519495010376
Validation loss: 2.2022312123288392

Epoch: 6| Step: 7
Training loss: 2.0441064834594727
Validation loss: 2.1797304935352777

Epoch: 6| Step: 8
Training loss: 2.075221061706543
Validation loss: 2.0676759571157475

Epoch: 6| Step: 9
Training loss: 1.7861719131469727
Validation loss: 2.1669073668859338

Epoch: 6| Step: 10
Training loss: 1.7478092908859253
Validation loss: 2.1061075784826793

Epoch: 6| Step: 11
Training loss: 1.6148545742034912
Validation loss: 2.0855923647521646

Epoch: 6| Step: 12
Training loss: 1.7115685939788818
Validation loss: 2.1173963495480117

Epoch: 6| Step: 13
Training loss: 1.523789644241333
Validation loss: 2.2006802943445023

Epoch: 380| Step: 0
Training loss: 2.2261407375335693
Validation loss: 2.197035433143698

Epoch: 6| Step: 1
Training loss: 2.3365631103515625
Validation loss: 2.153981363901528

Epoch: 6| Step: 2
Training loss: 2.54099178314209
Validation loss: 2.1350683089225524

Epoch: 6| Step: 3
Training loss: 1.5366113185882568
Validation loss: 2.2404123070419475

Epoch: 6| Step: 4
Training loss: 1.050751805305481
Validation loss: 2.2296127914100565

Epoch: 6| Step: 5
Training loss: 2.341832160949707
Validation loss: 2.09901092385733

Epoch: 6| Step: 6
Training loss: 1.9502228498458862
Validation loss: 2.2333244277584936

Epoch: 6| Step: 7
Training loss: 1.1837900876998901
Validation loss: 2.164790784159014

Epoch: 6| Step: 8
Training loss: 1.7068573236465454
Validation loss: 2.115497978784705

Epoch: 6| Step: 9
Training loss: 1.7335304021835327
Validation loss: 2.111788635612816

Epoch: 6| Step: 10
Training loss: 1.3289787769317627
Validation loss: 2.1609595667931343

Epoch: 6| Step: 11
Training loss: 1.9823212623596191
Validation loss: 2.165213352890425

Epoch: 6| Step: 12
Training loss: 1.451171636581421
Validation loss: 2.137499693901308

Epoch: 6| Step: 13
Training loss: 1.5683460235595703
Validation loss: 2.0351245967290734

Epoch: 381| Step: 0
Training loss: 1.955509901046753
Validation loss: 2.1611667858657015

Epoch: 6| Step: 1
Training loss: 1.3508121967315674
Validation loss: 2.148701872876895

Epoch: 6| Step: 2
Training loss: 1.8959407806396484
Validation loss: 2.102735222026866

Epoch: 6| Step: 3
Training loss: 2.171628952026367
Validation loss: 2.0974869215360252

Epoch: 6| Step: 4
Training loss: 1.8705384731292725
Validation loss: 2.154002312690981

Epoch: 6| Step: 5
Training loss: 1.6850545406341553
Validation loss: 2.131997928824476

Epoch: 6| Step: 6
Training loss: 1.5046911239624023
Validation loss: 2.1652010999700075

Epoch: 6| Step: 7
Training loss: 1.5656671524047852
Validation loss: 2.1532680219219578

Epoch: 6| Step: 8
Training loss: 2.1776540279388428
Validation loss: 2.1578878587292087

Epoch: 6| Step: 9
Training loss: 1.9259471893310547
Validation loss: 2.106566103555823

Epoch: 6| Step: 10
Training loss: 2.277519464492798
Validation loss: 2.1446960254382064

Epoch: 6| Step: 11
Training loss: 1.6251678466796875
Validation loss: 2.162668252504

Epoch: 6| Step: 12
Training loss: 1.2047691345214844
Validation loss: 2.1790113910551994

Epoch: 6| Step: 13
Training loss: 1.758993148803711
Validation loss: 2.159887288206367

Epoch: 382| Step: 0
Training loss: 2.218136787414551
Validation loss: 2.0791824556166127

Epoch: 6| Step: 1
Training loss: 1.5497379302978516
Validation loss: 2.165301089645714

Epoch: 6| Step: 2
Training loss: 1.5145843029022217
Validation loss: 2.080691317076324

Epoch: 6| Step: 3
Training loss: 1.7475664615631104
Validation loss: 2.10498837501772

Epoch: 6| Step: 4
Training loss: 1.7976068258285522
Validation loss: 2.1466723642041607

Epoch: 6| Step: 5
Training loss: 2.2288124561309814
Validation loss: 2.2428112414575394

Epoch: 6| Step: 6
Training loss: 1.2474710941314697
Validation loss: 2.1688832057419645

Epoch: 6| Step: 7
Training loss: 1.5811153650283813
Validation loss: 2.162113804971018

Epoch: 6| Step: 8
Training loss: 2.085437536239624
Validation loss: 2.124617294598651

Epoch: 6| Step: 9
Training loss: 1.8149380683898926
Validation loss: 2.1418200885095904

Epoch: 6| Step: 10
Training loss: 2.3134050369262695
Validation loss: 2.0667064702639015

Epoch: 6| Step: 11
Training loss: 1.8461499214172363
Validation loss: 2.046676212741483

Epoch: 6| Step: 12
Training loss: 1.2995918989181519
Validation loss: 2.0824585499302035

Epoch: 6| Step: 13
Training loss: 1.0636992454528809
Validation loss: 2.1094588361760622

Epoch: 383| Step: 0
Training loss: 1.7710871696472168
Validation loss: 2.1452437805873092

Epoch: 6| Step: 1
Training loss: 1.485802412033081
Validation loss: 2.118658673378729

Epoch: 6| Step: 2
Training loss: 1.8961542844772339
Validation loss: 2.1435671352571055

Epoch: 6| Step: 3
Training loss: 1.923058032989502
Validation loss: 2.1079908942663543

Epoch: 6| Step: 4
Training loss: 1.7065856456756592
Validation loss: 2.2145105356811197

Epoch: 6| Step: 5
Training loss: 1.3661798238754272
Validation loss: 2.211434801419576

Epoch: 6| Step: 6
Training loss: 1.7066755294799805
Validation loss: 2.1530729339968775

Epoch: 6| Step: 7
Training loss: 1.2528176307678223
Validation loss: 2.1185306554199546

Epoch: 6| Step: 8
Training loss: 1.6385383605957031
Validation loss: 2.152289270072855

Epoch: 6| Step: 9
Training loss: 1.502816915512085
Validation loss: 2.114207280579434

Epoch: 6| Step: 10
Training loss: 2.178377151489258
Validation loss: 2.111416397556182

Epoch: 6| Step: 11
Training loss: 1.7829196453094482
Validation loss: 2.1339354873985372

Epoch: 6| Step: 12
Training loss: 2.6624159812927246
Validation loss: 2.191317997952943

Epoch: 6| Step: 13
Training loss: 1.834653377532959
Validation loss: 2.162918334366173

Epoch: 384| Step: 0
Training loss: 1.263714075088501
Validation loss: 2.1518173576683126

Epoch: 6| Step: 1
Training loss: 1.7982615232467651
Validation loss: 2.096322464686568

Epoch: 6| Step: 2
Training loss: 1.7686612606048584
Validation loss: 2.2044340025994087

Epoch: 6| Step: 3
Training loss: 1.2679334878921509
Validation loss: 2.065156962281914

Epoch: 6| Step: 4
Training loss: 2.748067855834961
Validation loss: 2.1404819334706953

Epoch: 6| Step: 5
Training loss: 2.2207560539245605
Validation loss: 2.152398032526816

Epoch: 6| Step: 6
Training loss: 1.6688518524169922
Validation loss: 2.1053724596577306

Epoch: 6| Step: 7
Training loss: 1.5200581550598145
Validation loss: 2.104747692743937

Epoch: 6| Step: 8
Training loss: 1.4862635135650635
Validation loss: 2.1222996506639706

Epoch: 6| Step: 9
Training loss: 1.510986328125
Validation loss: 2.2150494795973583

Epoch: 6| Step: 10
Training loss: 1.712242841720581
Validation loss: 2.211047282782934

Epoch: 6| Step: 11
Training loss: 1.539939284324646
Validation loss: 2.134381565996396

Epoch: 6| Step: 12
Training loss: 2.2085907459259033
Validation loss: 2.121136739689817

Epoch: 6| Step: 13
Training loss: 1.5746500492095947
Validation loss: 2.1059673832308863

Epoch: 385| Step: 0
Training loss: 1.136196494102478
Validation loss: 2.1569586159080587

Epoch: 6| Step: 1
Training loss: 1.8299860954284668
Validation loss: 2.2106801258620394

Epoch: 6| Step: 2
Training loss: 2.2186837196350098
Validation loss: 2.0626175057503486

Epoch: 6| Step: 3
Training loss: 1.1833668947219849
Validation loss: 2.149960417901316

Epoch: 6| Step: 4
Training loss: 2.2383153438568115
Validation loss: 2.225841527344078

Epoch: 6| Step: 5
Training loss: 2.013101577758789
Validation loss: 2.16085111453969

Epoch: 6| Step: 6
Training loss: 1.4488213062286377
Validation loss: 2.110069454357188

Epoch: 6| Step: 7
Training loss: 1.7372896671295166
Validation loss: 2.17042141063239

Epoch: 6| Step: 8
Training loss: 2.184088945388794
Validation loss: 2.157044497869348

Epoch: 6| Step: 9
Training loss: 2.328146457672119
Validation loss: 2.1611422095247494

Epoch: 6| Step: 10
Training loss: 1.893828272819519
Validation loss: 2.143201602402554

Epoch: 6| Step: 11
Training loss: 1.4917991161346436
Validation loss: 2.0904087251232517

Epoch: 6| Step: 12
Training loss: 1.9721869230270386
Validation loss: 2.0650898846246863

Epoch: 6| Step: 13
Training loss: 1.1709067821502686
Validation loss: 2.2242156984985515

Epoch: 386| Step: 0
Training loss: 1.9182929992675781
Validation loss: 2.0799385501492407

Epoch: 6| Step: 1
Training loss: 1.7862882614135742
Validation loss: 2.172119245734266

Epoch: 6| Step: 2
Training loss: 1.4868321418762207
Validation loss: 2.1016212740252094

Epoch: 6| Step: 3
Training loss: 2.2697837352752686
Validation loss: 2.2025347473800823

Epoch: 6| Step: 4
Training loss: 1.3641822338104248
Validation loss: 2.1740566709990143

Epoch: 6| Step: 5
Training loss: 1.4312572479248047
Validation loss: 2.1409075721617667

Epoch: 6| Step: 6
Training loss: 1.5938067436218262
Validation loss: 2.1983094740939397

Epoch: 6| Step: 7
Training loss: 1.8572452068328857
Validation loss: 2.1736933159571823

Epoch: 6| Step: 8
Training loss: 1.9424479007720947
Validation loss: 2.084951795557494

Epoch: 6| Step: 9
Training loss: 2.3692164421081543
Validation loss: 2.183180142474431

Epoch: 6| Step: 10
Training loss: 1.5166821479797363
Validation loss: 2.218400078435098

Epoch: 6| Step: 11
Training loss: 1.8119585514068604
Validation loss: 2.172455110857564

Epoch: 6| Step: 12
Training loss: 2.070943832397461
Validation loss: 2.0351743031573553

Epoch: 6| Step: 13
Training loss: 1.2455586194992065
Validation loss: 2.1756366837409233

Epoch: 387| Step: 0
Training loss: 2.0481021404266357
Validation loss: 2.180180508603332

Epoch: 6| Step: 1
Training loss: 2.083218574523926
Validation loss: 2.1265050800897742

Epoch: 6| Step: 2
Training loss: 1.7521865367889404
Validation loss: 2.1902830869920793

Epoch: 6| Step: 3
Training loss: 2.0586185455322266
Validation loss: 2.21687682982414

Epoch: 6| Step: 4
Training loss: 1.1493887901306152
Validation loss: 2.178619246329031

Epoch: 6| Step: 5
Training loss: 1.9535949230194092
Validation loss: 2.2092931039871706

Epoch: 6| Step: 6
Training loss: 1.6557362079620361
Validation loss: 2.15930433939862

Epoch: 6| Step: 7
Training loss: 2.004758358001709
Validation loss: 2.1969823529643397

Epoch: 6| Step: 8
Training loss: 1.6322393417358398
Validation loss: 2.1045515332170712

Epoch: 6| Step: 9
Training loss: 2.23954701423645
Validation loss: 2.1021143467195573

Epoch: 6| Step: 10
Training loss: 1.0923926830291748
Validation loss: 2.1680144494579685

Epoch: 6| Step: 11
Training loss: 1.574852466583252
Validation loss: 2.209215235966508

Epoch: 6| Step: 12
Training loss: 1.6562310457229614
Validation loss: 2.150866772538872

Epoch: 6| Step: 13
Training loss: 1.1736218929290771
Validation loss: 2.2277734882088116

Epoch: 388| Step: 0
Training loss: 1.6448047161102295
Validation loss: 2.1592684022841917

Epoch: 6| Step: 1
Training loss: 1.932539939880371
Validation loss: 2.0875572414808374

Epoch: 6| Step: 2
Training loss: 1.8862098455429077
Validation loss: 2.158368838730679

Epoch: 6| Step: 3
Training loss: 1.7389225959777832
Validation loss: 2.095309958663038

Epoch: 6| Step: 4
Training loss: 1.7279925346374512
Validation loss: 2.1707049826140046

Epoch: 6| Step: 5
Training loss: 1.5432851314544678
Validation loss: 2.208657310855004

Epoch: 6| Step: 6
Training loss: 1.9770735502243042
Validation loss: 2.1736065521035144

Epoch: 6| Step: 7
Training loss: 1.8314893245697021
Validation loss: 2.163005949348532

Epoch: 6| Step: 8
Training loss: 1.8900408744812012
Validation loss: 2.101336782978427

Epoch: 6| Step: 9
Training loss: 1.797553539276123
Validation loss: 2.174798714217319

Epoch: 6| Step: 10
Training loss: 1.9995105266571045
Validation loss: 2.1380397696648874

Epoch: 6| Step: 11
Training loss: 1.9970424175262451
Validation loss: 2.0572071203621487

Epoch: 6| Step: 12
Training loss: 1.1024494171142578
Validation loss: 2.212611139461558

Epoch: 6| Step: 13
Training loss: 0.6066200137138367
Validation loss: 2.1563507613315376

Epoch: 389| Step: 0
Training loss: 1.6967852115631104
Validation loss: 2.1808004225454023

Epoch: 6| Step: 1
Training loss: 1.934047818183899
Validation loss: 2.0989873575907882

Epoch: 6| Step: 2
Training loss: 1.3392547369003296
Validation loss: 2.111217652597735

Epoch: 6| Step: 3
Training loss: 2.2398178577423096
Validation loss: 2.140057110017346

Epoch: 6| Step: 4
Training loss: 1.841457724571228
Validation loss: 2.1371348955297984

Epoch: 6| Step: 5
Training loss: 1.9874053001403809
Validation loss: 2.1867512528614332

Epoch: 6| Step: 6
Training loss: 1.5579724311828613
Validation loss: 2.0417455191253335

Epoch: 6| Step: 7
Training loss: 1.6823139190673828
Validation loss: 2.151058231630633

Epoch: 6| Step: 8
Training loss: 2.138374090194702
Validation loss: 2.19075095909898

Epoch: 6| Step: 9
Training loss: 1.505658745765686
Validation loss: 2.141536425518733

Epoch: 6| Step: 10
Training loss: 1.582245945930481
Validation loss: 2.098285649412422

Epoch: 6| Step: 11
Training loss: 1.847701072692871
Validation loss: 2.1106351344816145

Epoch: 6| Step: 12
Training loss: 1.3874545097351074
Validation loss: 2.1195525969228437

Epoch: 6| Step: 13
Training loss: 1.7503864765167236
Validation loss: 2.1301880216085785

Epoch: 390| Step: 0
Training loss: 1.3912276029586792
Validation loss: 2.1989254643840175

Epoch: 6| Step: 1
Training loss: 2.045285940170288
Validation loss: 2.088699274165656

Epoch: 6| Step: 2
Training loss: 1.809819221496582
Validation loss: 2.1490607620567403

Epoch: 6| Step: 3
Training loss: 1.752540111541748
Validation loss: 2.1475615539858417

Epoch: 6| Step: 4
Training loss: 2.294158458709717
Validation loss: 2.0495509934681717

Epoch: 6| Step: 5
Training loss: 1.1298117637634277
Validation loss: 2.0990999847330074

Epoch: 6| Step: 6
Training loss: 1.6166940927505493
Validation loss: 2.0659264826005503

Epoch: 6| Step: 7
Training loss: 1.348331332206726
Validation loss: 2.1672780949582338

Epoch: 6| Step: 8
Training loss: 1.8548657894134521
Validation loss: 2.0984778019689743

Epoch: 6| Step: 9
Training loss: 1.6950281858444214
Validation loss: 2.217958507999297

Epoch: 6| Step: 10
Training loss: 2.0051536560058594
Validation loss: 2.1743142245918192

Epoch: 6| Step: 11
Training loss: 1.1363394260406494
Validation loss: 2.1621009380586687

Epoch: 6| Step: 12
Training loss: 1.8084096908569336
Validation loss: 2.0935890636136456

Epoch: 6| Step: 13
Training loss: 2.3592185974121094
Validation loss: 2.1445556712406937

Epoch: 391| Step: 0
Training loss: 2.018199920654297
Validation loss: 2.059683253688197

Epoch: 6| Step: 1
Training loss: 1.7879400253295898
Validation loss: 2.2442442383817447

Epoch: 6| Step: 2
Training loss: 1.4649455547332764
Validation loss: 2.178028855272519

Epoch: 6| Step: 3
Training loss: 1.2443430423736572
Validation loss: 2.13309928037787

Epoch: 6| Step: 4
Training loss: 1.6099133491516113
Validation loss: 2.187161550726942

Epoch: 6| Step: 5
Training loss: 1.6706901788711548
Validation loss: 2.2088425313272784

Epoch: 6| Step: 6
Training loss: 1.4715269804000854
Validation loss: 2.152705823221514

Epoch: 6| Step: 7
Training loss: 1.27030611038208
Validation loss: 2.2088365618900587

Epoch: 6| Step: 8
Training loss: 2.000091075897217
Validation loss: 2.170550923193655

Epoch: 6| Step: 9
Training loss: 1.382285237312317
Validation loss: 2.157057972364528

Epoch: 6| Step: 10
Training loss: 2.06070876121521
Validation loss: 2.148330646176492

Epoch: 6| Step: 11
Training loss: 2.3267436027526855
Validation loss: 2.2243765707938903

Epoch: 6| Step: 12
Training loss: 2.12973690032959
Validation loss: 2.1378724254587644

Epoch: 6| Step: 13
Training loss: 2.3014156818389893
Validation loss: 2.1043690250765894

Epoch: 392| Step: 0
Training loss: 1.5351381301879883
Validation loss: 2.2023883981089436

Epoch: 6| Step: 1
Training loss: 1.9422980546951294
Validation loss: 2.2017825880358295

Epoch: 6| Step: 2
Training loss: 1.258027195930481
Validation loss: 2.145372224110429

Epoch: 6| Step: 3
Training loss: 2.040109872817993
Validation loss: 2.1576187738808255

Epoch: 6| Step: 4
Training loss: 1.7028144598007202
Validation loss: 2.0860315945840653

Epoch: 6| Step: 5
Training loss: 1.501655101776123
Validation loss: 2.183083839313958

Epoch: 6| Step: 6
Training loss: 2.0645811557769775
Validation loss: 2.1524805227915444

Epoch: 6| Step: 7
Training loss: 1.6319563388824463
Validation loss: 2.220476092830781

Epoch: 6| Step: 8
Training loss: 1.7286133766174316
Validation loss: 2.1936305569064234

Epoch: 6| Step: 9
Training loss: 2.254507541656494
Validation loss: 2.234490604810817

Epoch: 6| Step: 10
Training loss: 1.408045768737793
Validation loss: 2.1622491600692912

Epoch: 6| Step: 11
Training loss: 1.9523004293441772
Validation loss: 2.182072949665849

Epoch: 6| Step: 12
Training loss: 1.5461912155151367
Validation loss: 2.1449180597900064

Epoch: 6| Step: 13
Training loss: 2.361943244934082
Validation loss: 2.158980159349339

Epoch: 393| Step: 0
Training loss: 1.8573410511016846
Validation loss: 2.1500366964647846

Epoch: 6| Step: 1
Training loss: 1.9609647989273071
Validation loss: 2.2556822505048526

Epoch: 6| Step: 2
Training loss: 2.0941567420959473
Validation loss: 2.2209709998100036

Epoch: 6| Step: 3
Training loss: 1.7352391481399536
Validation loss: 2.169684556222731

Epoch: 6| Step: 4
Training loss: 1.824610948562622
Validation loss: 2.164537743855548

Epoch: 6| Step: 5
Training loss: 2.087354898452759
Validation loss: 2.153983687841764

Epoch: 6| Step: 6
Training loss: 1.7587125301361084
Validation loss: 2.1809672950416483

Epoch: 6| Step: 7
Training loss: 1.5510298013687134
Validation loss: 2.1571548138895342

Epoch: 6| Step: 8
Training loss: 1.2459542751312256
Validation loss: 2.1132287517670663

Epoch: 6| Step: 9
Training loss: 1.5879101753234863
Validation loss: 2.1356716848188833

Epoch: 6| Step: 10
Training loss: 1.5187792778015137
Validation loss: 2.158858301819012

Epoch: 6| Step: 11
Training loss: 1.6701548099517822
Validation loss: 2.1245679111890894

Epoch: 6| Step: 12
Training loss: 1.3622015714645386
Validation loss: 2.1517804540613645

Epoch: 6| Step: 13
Training loss: 1.7254496812820435
Validation loss: 2.1306834041431384

Epoch: 394| Step: 0
Training loss: 1.5212998390197754
Validation loss: 2.211504678572378

Epoch: 6| Step: 1
Training loss: 2.079035997390747
Validation loss: 2.196013282704097

Epoch: 6| Step: 2
Training loss: 2.271407127380371
Validation loss: 2.1231977760150866

Epoch: 6| Step: 3
Training loss: 1.4090259075164795
Validation loss: 2.143504245306856

Epoch: 6| Step: 4
Training loss: 1.1767432689666748
Validation loss: 2.116300743113282

Epoch: 6| Step: 5
Training loss: 1.3462533950805664
Validation loss: 2.074094937693688

Epoch: 6| Step: 6
Training loss: 2.0129294395446777
Validation loss: 2.0975559424328547

Epoch: 6| Step: 7
Training loss: 2.7541656494140625
Validation loss: 2.1040960229853147

Epoch: 6| Step: 8
Training loss: 1.992195725440979
Validation loss: 2.112421279312462

Epoch: 6| Step: 9
Training loss: 1.7730039358139038
Validation loss: 2.2289878899051296

Epoch: 6| Step: 10
Training loss: 1.1257731914520264
Validation loss: 2.1147206316712084

Epoch: 6| Step: 11
Training loss: 1.4896882772445679
Validation loss: 2.1626047421527166

Epoch: 6| Step: 12
Training loss: 1.755110502243042
Validation loss: 2.1731241800451793

Epoch: 6| Step: 13
Training loss: 1.8663033246994019
Validation loss: 2.0571698706637145

Epoch: 395| Step: 0
Training loss: 1.8509974479675293
Validation loss: 2.110394024079846

Epoch: 6| Step: 1
Training loss: 1.6876776218414307
Validation loss: 2.192342383887178

Epoch: 6| Step: 2
Training loss: 1.0388468503952026
Validation loss: 2.2358124076679187

Epoch: 6| Step: 3
Training loss: 2.0153660774230957
Validation loss: 2.126028945369105

Epoch: 6| Step: 4
Training loss: 1.6491367816925049
Validation loss: 2.144998565796883

Epoch: 6| Step: 5
Training loss: 1.435986042022705
Validation loss: 2.1417653022273893

Epoch: 6| Step: 6
Training loss: 1.4725112915039062
Validation loss: 2.162346177203681

Epoch: 6| Step: 7
Training loss: 1.8984246253967285
Validation loss: 2.2118245170962427

Epoch: 6| Step: 8
Training loss: 2.5932750701904297
Validation loss: 2.15606201335948

Epoch: 6| Step: 9
Training loss: 1.9583637714385986
Validation loss: 2.1681107654366443

Epoch: 6| Step: 10
Training loss: 2.065373420715332
Validation loss: 2.1932146433861024

Epoch: 6| Step: 11
Training loss: 1.6274042129516602
Validation loss: 2.1656060539266115

Epoch: 6| Step: 12
Training loss: 1.4798694849014282
Validation loss: 2.2013801502925094

Epoch: 6| Step: 13
Training loss: 1.9905247688293457
Validation loss: 2.172758709999823

Epoch: 396| Step: 0
Training loss: 1.4612576961517334
Validation loss: 2.137055484197473

Epoch: 6| Step: 1
Training loss: 1.9254555702209473
Validation loss: 2.170982604385704

Epoch: 6| Step: 2
Training loss: 1.7374653816223145
Validation loss: 2.139687333055722

Epoch: 6| Step: 3
Training loss: 1.748863935470581
Validation loss: 2.1263104869473364

Epoch: 6| Step: 4
Training loss: 2.159426689147949
Validation loss: 2.214216729646088

Epoch: 6| Step: 5
Training loss: 1.5029571056365967
Validation loss: 2.146703662410859

Epoch: 6| Step: 6
Training loss: 1.5361618995666504
Validation loss: 2.206701722196353

Epoch: 6| Step: 7
Training loss: 2.116060256958008
Validation loss: 2.108743797066391

Epoch: 6| Step: 8
Training loss: 1.377050757408142
Validation loss: 2.170391530118963

Epoch: 6| Step: 9
Training loss: 2.272329807281494
Validation loss: 2.0954112442590858

Epoch: 6| Step: 10
Training loss: 1.7519447803497314
Validation loss: 2.123292338463568

Epoch: 6| Step: 11
Training loss: 2.1028714179992676
Validation loss: 2.0144265338938725

Epoch: 6| Step: 12
Training loss: 1.4643878936767578
Validation loss: 2.103375842494349

Epoch: 6| Step: 13
Training loss: 2.1116960048675537
Validation loss: 2.1890705144533547

Epoch: 397| Step: 0
Training loss: 1.2606632709503174
Validation loss: 2.177552330878473

Epoch: 6| Step: 1
Training loss: 1.7223963737487793
Validation loss: 2.0848553847241145

Epoch: 6| Step: 2
Training loss: 1.6325362920761108
Validation loss: 2.1068127437304427

Epoch: 6| Step: 3
Training loss: 1.5085868835449219
Validation loss: 2.12133163662367

Epoch: 6| Step: 4
Training loss: 2.8419554233551025
Validation loss: 2.1644462334212435

Epoch: 6| Step: 5
Training loss: 1.8437278270721436
Validation loss: 2.166171173895559

Epoch: 6| Step: 6
Training loss: 1.6800885200500488
Validation loss: 2.122692390154767

Epoch: 6| Step: 7
Training loss: 1.3518608808517456
Validation loss: 2.1321456329796904

Epoch: 6| Step: 8
Training loss: 1.4161653518676758
Validation loss: 2.129044104647893

Epoch: 6| Step: 9
Training loss: 2.361417770385742
Validation loss: 2.2137982922215618

Epoch: 6| Step: 10
Training loss: 2.1670987606048584
Validation loss: 2.1961650925297893

Epoch: 6| Step: 11
Training loss: 2.057182550430298
Validation loss: 2.1996077235027025

Epoch: 6| Step: 12
Training loss: 1.893795132637024
Validation loss: 2.2519856601633053

Epoch: 6| Step: 13
Training loss: 1.7469068765640259
Validation loss: 2.1748477130807857

Epoch: 398| Step: 0
Training loss: 1.493008017539978
Validation loss: 2.1678534553896998

Epoch: 6| Step: 1
Training loss: 2.0803213119506836
Validation loss: 2.2268782149079027

Epoch: 6| Step: 2
Training loss: 2.4225480556488037
Validation loss: 2.1968535454042497

Epoch: 6| Step: 3
Training loss: 1.588913083076477
Validation loss: 2.2202152872598298

Epoch: 6| Step: 4
Training loss: 1.8531675338745117
Validation loss: 2.1362164007720126

Epoch: 6| Step: 5
Training loss: 1.2311348915100098
Validation loss: 2.1901033514289447

Epoch: 6| Step: 6
Training loss: 2.0767998695373535
Validation loss: 2.1020808412182714

Epoch: 6| Step: 7
Training loss: 1.1277083158493042
Validation loss: 2.16880008738528

Epoch: 6| Step: 8
Training loss: 1.733067512512207
Validation loss: 2.1670362744280087

Epoch: 6| Step: 9
Training loss: 1.495368480682373
Validation loss: 2.1357233678140948

Epoch: 6| Step: 10
Training loss: 1.20615816116333
Validation loss: 2.1641675810660086

Epoch: 6| Step: 11
Training loss: 2.3120672702789307
Validation loss: 2.0837801528233353

Epoch: 6| Step: 12
Training loss: 1.7670462131500244
Validation loss: 2.100883387750195

Epoch: 6| Step: 13
Training loss: 0.9905910491943359
Validation loss: 2.1812258420451993

Epoch: 399| Step: 0
Training loss: 1.5935221910476685
Validation loss: 2.07188017137589

Epoch: 6| Step: 1
Training loss: 2.188786029815674
Validation loss: 2.0759994214580906

Epoch: 6| Step: 2
Training loss: 2.201009750366211
Validation loss: 2.146307204359321

Epoch: 6| Step: 3
Training loss: 1.7718441486358643
Validation loss: 2.1026152308269213

Epoch: 6| Step: 4
Training loss: 2.1197621822357178
Validation loss: 2.1765270745882423

Epoch: 6| Step: 5
Training loss: 1.2286889553070068
Validation loss: 2.08152860723516

Epoch: 6| Step: 6
Training loss: 1.257906198501587
Validation loss: 2.202450559985253

Epoch: 6| Step: 7
Training loss: 1.164050817489624
Validation loss: 2.111211963879165

Epoch: 6| Step: 8
Training loss: 1.2829530239105225
Validation loss: 2.1523770004190426

Epoch: 6| Step: 9
Training loss: 1.7536965608596802
Validation loss: 2.1507259491951234

Epoch: 6| Step: 10
Training loss: 2.0483198165893555
Validation loss: 2.1478703457822084

Epoch: 6| Step: 11
Training loss: 2.0500071048736572
Validation loss: 2.14561935394041

Epoch: 6| Step: 12
Training loss: 1.6758075952529907
Validation loss: 2.1690177609843593

Epoch: 6| Step: 13
Training loss: 2.36838436126709
Validation loss: 2.1596321841721893

Epoch: 400| Step: 0
Training loss: 1.674276351928711
Validation loss: 2.1487265594543947

Epoch: 6| Step: 1
Training loss: 1.7413612604141235
Validation loss: 2.1612183393970614

Epoch: 6| Step: 2
Training loss: 1.890224575996399
Validation loss: 2.1179209601494575

Epoch: 6| Step: 3
Training loss: 2.0728015899658203
Validation loss: 2.1667842480444137

Epoch: 6| Step: 4
Training loss: 1.4949517250061035
Validation loss: 2.169560765707365

Epoch: 6| Step: 5
Training loss: 1.8951621055603027
Validation loss: 2.1678886772483907

Epoch: 6| Step: 6
Training loss: 1.715813398361206
Validation loss: 2.108131121563655

Epoch: 6| Step: 7
Training loss: 1.7779207229614258
Validation loss: 2.149565350624823

Epoch: 6| Step: 8
Training loss: 2.114917755126953
Validation loss: 2.1849032191820044

Epoch: 6| Step: 9
Training loss: 1.604210376739502
Validation loss: 2.151949326197306

Epoch: 6| Step: 10
Training loss: 2.1723294258117676
Validation loss: 2.1333794119537517

Epoch: 6| Step: 11
Training loss: 1.5293724536895752
Validation loss: 2.156413693581858

Epoch: 6| Step: 12
Training loss: 1.4302809238433838
Validation loss: 2.1286817237895024

Epoch: 6| Step: 13
Training loss: 1.8193525075912476
Validation loss: 2.118860908733901

Epoch: 401| Step: 0
Training loss: 1.8871815204620361
Validation loss: 2.1686650937603367

Epoch: 6| Step: 1
Training loss: 1.5906424522399902
Validation loss: 2.1627826139491093

Epoch: 6| Step: 2
Training loss: 1.6579830646514893
Validation loss: 2.1542282489038285

Epoch: 6| Step: 3
Training loss: 1.5341076850891113
Validation loss: 2.1412200966188983

Epoch: 6| Step: 4
Training loss: 1.603790521621704
Validation loss: 2.212384400829192

Epoch: 6| Step: 5
Training loss: 1.7363322973251343
Validation loss: 2.0829551014848935

Epoch: 6| Step: 6
Training loss: 2.179128646850586
Validation loss: 2.187653951747443

Epoch: 6| Step: 7
Training loss: 1.7359998226165771
Validation loss: 2.1159982655638006

Epoch: 6| Step: 8
Training loss: 2.2125842571258545
Validation loss: 2.149238578734859

Epoch: 6| Step: 9
Training loss: 2.125441074371338
Validation loss: 2.1925162038495465

Epoch: 6| Step: 10
Training loss: 1.4127063751220703
Validation loss: 2.1205803463535924

Epoch: 6| Step: 11
Training loss: 2.1386587619781494
Validation loss: 2.1877784959731565

Epoch: 6| Step: 12
Training loss: 1.5909439325332642
Validation loss: 2.108265987006567

Epoch: 6| Step: 13
Training loss: 1.1360169649124146
Validation loss: 2.2006584085443968

Epoch: 402| Step: 0
Training loss: 1.5246098041534424
Validation loss: 2.177182924362921

Epoch: 6| Step: 1
Training loss: 1.8479790687561035
Validation loss: 2.1903412957345285

Epoch: 6| Step: 2
Training loss: 1.323573112487793
Validation loss: 2.2152479310189523

Epoch: 6| Step: 3
Training loss: 1.8813822269439697
Validation loss: 2.166345747568274

Epoch: 6| Step: 4
Training loss: 1.6259101629257202
Validation loss: 2.161625292993361

Epoch: 6| Step: 5
Training loss: 1.62971830368042
Validation loss: 2.1531340024804555

Epoch: 6| Step: 6
Training loss: 1.875699520111084
Validation loss: 2.194762140192011

Epoch: 6| Step: 7
Training loss: 2.169870376586914
Validation loss: 2.106807751040305

Epoch: 6| Step: 8
Training loss: 1.7927510738372803
Validation loss: 2.2126173883356075

Epoch: 6| Step: 9
Training loss: 1.4735300540924072
Validation loss: 2.158037840679128

Epoch: 6| Step: 10
Training loss: 2.0389254093170166
Validation loss: 2.183097272790888

Epoch: 6| Step: 11
Training loss: 1.3617079257965088
Validation loss: 2.1674201821768158

Epoch: 6| Step: 12
Training loss: 2.1198010444641113
Validation loss: 2.2292122712699314

Epoch: 6| Step: 13
Training loss: 2.121816635131836
Validation loss: 2.1415899825352493

Epoch: 403| Step: 0
Training loss: 1.3605669736862183
Validation loss: 2.1629502106738347

Epoch: 6| Step: 1
Training loss: 1.4589234590530396
Validation loss: 2.170746023936938

Epoch: 6| Step: 2
Training loss: 2.2717158794403076
Validation loss: 2.217702568218272

Epoch: 6| Step: 3
Training loss: 2.105494499206543
Validation loss: 2.2228958273446686

Epoch: 6| Step: 4
Training loss: 1.5767762660980225
Validation loss: 2.090998157378166

Epoch: 6| Step: 5
Training loss: 1.687598466873169
Validation loss: 2.1827541820464598

Epoch: 6| Step: 6
Training loss: 2.111135721206665
Validation loss: 2.226218569663263

Epoch: 6| Step: 7
Training loss: 2.1434688568115234
Validation loss: 2.173927839084338

Epoch: 6| Step: 8
Training loss: 1.6162116527557373
Validation loss: 2.1841007637721237

Epoch: 6| Step: 9
Training loss: 1.8218994140625
Validation loss: 2.1989874198872554

Epoch: 6| Step: 10
Training loss: 1.194446086883545
Validation loss: 2.054540512382343

Epoch: 6| Step: 11
Training loss: 2.223989248275757
Validation loss: 2.131959180678091

Epoch: 6| Step: 12
Training loss: 1.5269790887832642
Validation loss: 2.1346387927250197

Epoch: 6| Step: 13
Training loss: 1.166135311126709
Validation loss: 2.1147402268584057

Epoch: 404| Step: 0
Training loss: 2.0237984657287598
Validation loss: 2.1452098020943264

Epoch: 6| Step: 1
Training loss: 1.7712717056274414
Validation loss: 2.124133176701043

Epoch: 6| Step: 2
Training loss: 1.3481255769729614
Validation loss: 2.1843303788092827

Epoch: 6| Step: 3
Training loss: 1.410053014755249
Validation loss: 2.0824671227444886

Epoch: 6| Step: 4
Training loss: 2.252656936645508
Validation loss: 2.0995463773768437

Epoch: 6| Step: 5
Training loss: 1.7392206192016602
Validation loss: 2.1333334625408216

Epoch: 6| Step: 6
Training loss: 1.7665281295776367
Validation loss: 2.104070814706946

Epoch: 6| Step: 7
Training loss: 1.5887901782989502
Validation loss: 2.186037487881158

Epoch: 6| Step: 8
Training loss: 1.6279246807098389
Validation loss: 2.1283021203933226

Epoch: 6| Step: 9
Training loss: 1.4421619176864624
Validation loss: 2.0605812252208753

Epoch: 6| Step: 10
Training loss: 1.9386699199676514
Validation loss: 2.108024993250447

Epoch: 6| Step: 11
Training loss: 2.3017525672912598
Validation loss: 2.1703340315049693

Epoch: 6| Step: 12
Training loss: 1.3379278182983398
Validation loss: 2.0725703265077327

Epoch: 6| Step: 13
Training loss: 2.001919746398926
Validation loss: 2.1330265575839626

Epoch: 405| Step: 0
Training loss: 1.7353975772857666
Validation loss: 2.117080537221765

Epoch: 6| Step: 1
Training loss: 1.752861499786377
Validation loss: 2.1808205894244614

Epoch: 6| Step: 2
Training loss: 2.2071588039398193
Validation loss: 2.1111764497654413

Epoch: 6| Step: 3
Training loss: 1.9106767177581787
Validation loss: 2.2639671500011156

Epoch: 6| Step: 4
Training loss: 1.6473743915557861
Validation loss: 2.130719982167726

Epoch: 6| Step: 5
Training loss: 0.9522650837898254
Validation loss: 2.1696930380277735

Epoch: 6| Step: 6
Training loss: 2.091174602508545
Validation loss: 2.237568381012127

Epoch: 6| Step: 7
Training loss: 1.8345963954925537
Validation loss: 2.1157143641543645

Epoch: 6| Step: 8
Training loss: 1.9308624267578125
Validation loss: 2.1176949803547194

Epoch: 6| Step: 9
Training loss: 1.450154185295105
Validation loss: 2.129654972783981

Epoch: 6| Step: 10
Training loss: 1.5650303363800049
Validation loss: 2.1966029367139264

Epoch: 6| Step: 11
Training loss: 2.0660109519958496
Validation loss: 2.1458628062278993

Epoch: 6| Step: 12
Training loss: 1.246100664138794
Validation loss: 2.1899908665687806

Epoch: 6| Step: 13
Training loss: 1.3916343450546265
Validation loss: 2.1613558082170385

Epoch: 406| Step: 0
Training loss: 1.9927496910095215
Validation loss: 2.2091180368136336

Epoch: 6| Step: 1
Training loss: 1.4392774105072021
Validation loss: 2.123554793737268

Epoch: 6| Step: 2
Training loss: 1.8057564496994019
Validation loss: 2.147553490054223

Epoch: 6| Step: 3
Training loss: 1.4927221536636353
Validation loss: 2.127546830843854

Epoch: 6| Step: 4
Training loss: 1.0704231262207031
Validation loss: 2.21152594525327

Epoch: 6| Step: 5
Training loss: 2.042285919189453
Validation loss: 2.15591384262167

Epoch: 6| Step: 6
Training loss: 1.4351304769515991
Validation loss: 2.095338595810757

Epoch: 6| Step: 7
Training loss: 1.9062870740890503
Validation loss: 2.1740858016475553

Epoch: 6| Step: 8
Training loss: 2.6435904502868652
Validation loss: 2.1415226100593485

Epoch: 6| Step: 9
Training loss: 1.3475275039672852
Validation loss: 2.1766713216740596

Epoch: 6| Step: 10
Training loss: 1.5840301513671875
Validation loss: 2.1618779769507785

Epoch: 6| Step: 11
Training loss: 1.8294832706451416
Validation loss: 2.120364632657779

Epoch: 6| Step: 12
Training loss: 1.8977904319763184
Validation loss: 2.1899284983194

Epoch: 6| Step: 13
Training loss: 3.0565361976623535
Validation loss: 2.173550308391612

Epoch: 407| Step: 0
Training loss: 1.604809045791626
Validation loss: 2.150752129093293

Epoch: 6| Step: 1
Training loss: 1.738311767578125
Validation loss: 2.110508948244074

Epoch: 6| Step: 2
Training loss: 2.403428316116333
Validation loss: 2.1634044711307814

Epoch: 6| Step: 3
Training loss: 2.820355176925659
Validation loss: 2.085705118794595

Epoch: 6| Step: 4
Training loss: 2.159602403640747
Validation loss: 2.0956782448676323

Epoch: 6| Step: 5
Training loss: 1.2798852920532227
Validation loss: 2.2155911768636396

Epoch: 6| Step: 6
Training loss: 1.4517974853515625
Validation loss: 2.1348049538109892

Epoch: 6| Step: 7
Training loss: 1.5878729820251465
Validation loss: 2.177163741921866

Epoch: 6| Step: 8
Training loss: 1.11927330493927
Validation loss: 2.1410220092342747

Epoch: 6| Step: 9
Training loss: 1.9555656909942627
Validation loss: 2.15147154818299

Epoch: 6| Step: 10
Training loss: 1.7493700981140137
Validation loss: 2.132796017072534

Epoch: 6| Step: 11
Training loss: 2.307941436767578
Validation loss: 2.1872618121485554

Epoch: 6| Step: 12
Training loss: 1.746000051498413
Validation loss: 2.1209538034213486

Epoch: 6| Step: 13
Training loss: 0.795365571975708
Validation loss: 2.1987700205977245

Epoch: 408| Step: 0
Training loss: 1.17238187789917
Validation loss: 2.1490256747891827

Epoch: 6| Step: 1
Training loss: 2.3170294761657715
Validation loss: 2.082224921513629

Epoch: 6| Step: 2
Training loss: 1.815351128578186
Validation loss: 2.1451230677225257

Epoch: 6| Step: 3
Training loss: 1.7924470901489258
Validation loss: 2.0192243514522428

Epoch: 6| Step: 4
Training loss: 1.6816685199737549
Validation loss: 2.1146971576957294

Epoch: 6| Step: 5
Training loss: 1.2916618585586548
Validation loss: 2.2118335206021547

Epoch: 6| Step: 6
Training loss: 0.9633436799049377
Validation loss: 2.1574603665259575

Epoch: 6| Step: 7
Training loss: 2.2208971977233887
Validation loss: 2.1023754868456113

Epoch: 6| Step: 8
Training loss: 0.9867639541625977
Validation loss: 2.132630127732472

Epoch: 6| Step: 9
Training loss: 1.6015374660491943
Validation loss: 2.1109531182114796

Epoch: 6| Step: 10
Training loss: 2.207679510116577
Validation loss: 2.1052567753740536

Epoch: 6| Step: 11
Training loss: 1.661075234413147
Validation loss: 2.15723676835337

Epoch: 6| Step: 12
Training loss: 2.218467950820923
Validation loss: 2.1466624864967923

Epoch: 6| Step: 13
Training loss: 2.552539348602295
Validation loss: 2.2111830916455997

Epoch: 409| Step: 0
Training loss: 1.5238988399505615
Validation loss: 2.140404560232675

Epoch: 6| Step: 1
Training loss: 0.9075977206230164
Validation loss: 2.157987927877775

Epoch: 6| Step: 2
Training loss: 1.4829955101013184
Validation loss: 2.0749850683314826

Epoch: 6| Step: 3
Training loss: 1.8171627521514893
Validation loss: 2.1618343835235923

Epoch: 6| Step: 4
Training loss: 1.555872917175293
Validation loss: 2.0849970848329606

Epoch: 6| Step: 5
Training loss: 1.66956627368927
Validation loss: 2.193478456107519

Epoch: 6| Step: 6
Training loss: 2.030320167541504
Validation loss: 2.1167842547098794

Epoch: 6| Step: 7
Training loss: 1.3610072135925293
Validation loss: 2.2037911312554472

Epoch: 6| Step: 8
Training loss: 1.4554284811019897
Validation loss: 2.1446274518966675

Epoch: 6| Step: 9
Training loss: 2.2094099521636963
Validation loss: 2.1383367046233146

Epoch: 6| Step: 10
Training loss: 2.3653783798217773
Validation loss: 2.1828667322794595

Epoch: 6| Step: 11
Training loss: 1.5913876295089722
Validation loss: 2.1472366112534718

Epoch: 6| Step: 12
Training loss: 2.379206418991089
Validation loss: 2.1338841633130143

Epoch: 6| Step: 13
Training loss: 1.488761305809021
Validation loss: 2.0643970863793486

Epoch: 410| Step: 0
Training loss: 1.887511968612671
Validation loss: 2.1350757280985513

Epoch: 6| Step: 1
Training loss: 1.7048492431640625
Validation loss: 2.066512835923062

Epoch: 6| Step: 2
Training loss: 2.057305335998535
Validation loss: 2.2109049802185385

Epoch: 6| Step: 3
Training loss: 1.7426142692565918
Validation loss: 2.160573151803786

Epoch: 6| Step: 4
Training loss: 2.7552404403686523
Validation loss: 2.064659913380941

Epoch: 6| Step: 5
Training loss: 1.5366277694702148
Validation loss: 2.1865564879550727

Epoch: 6| Step: 6
Training loss: 1.727901577949524
Validation loss: 2.1216842871840282

Epoch: 6| Step: 7
Training loss: 1.400989055633545
Validation loss: 2.151650949191022

Epoch: 6| Step: 8
Training loss: 1.7589824199676514
Validation loss: 2.0982562495816137

Epoch: 6| Step: 9
Training loss: 1.2040379047393799
Validation loss: 2.206692990436349

Epoch: 6| Step: 10
Training loss: 1.4401054382324219
Validation loss: 2.14647166703337

Epoch: 6| Step: 11
Training loss: 1.0438563823699951
Validation loss: 2.160436390548624

Epoch: 6| Step: 12
Training loss: 2.274524688720703
Validation loss: 2.2238796180294407

Epoch: 6| Step: 13
Training loss: 1.2820359468460083
Validation loss: 2.1628042215942056

Epoch: 411| Step: 0
Training loss: 2.367250680923462
Validation loss: 2.1558131094901793

Epoch: 6| Step: 1
Training loss: 1.5843546390533447
Validation loss: 2.1907332917695403

Epoch: 6| Step: 2
Training loss: 1.752608060836792
Validation loss: 2.2154996446383897

Epoch: 6| Step: 3
Training loss: 1.7207151651382446
Validation loss: 2.179327577672979

Epoch: 6| Step: 4
Training loss: 1.3716422319412231
Validation loss: 2.16973534194372

Epoch: 6| Step: 5
Training loss: 1.7147202491760254
Validation loss: 2.1604098760953514

Epoch: 6| Step: 6
Training loss: 2.0605216026306152
Validation loss: 2.118288085024844

Epoch: 6| Step: 7
Training loss: 1.6615395545959473
Validation loss: 2.1301176035276024

Epoch: 6| Step: 8
Training loss: 1.4421660900115967
Validation loss: 2.219308809567523

Epoch: 6| Step: 9
Training loss: 1.9728869199752808
Validation loss: 2.219160872121011

Epoch: 6| Step: 10
Training loss: 1.3075761795043945
Validation loss: 2.18815323229759

Epoch: 6| Step: 11
Training loss: 1.2407660484313965
Validation loss: 2.221662231670913

Epoch: 6| Step: 12
Training loss: 2.0934455394744873
Validation loss: 2.2080767282875637

Epoch: 6| Step: 13
Training loss: 1.0267587900161743
Validation loss: 2.1253950390764462

Epoch: 412| Step: 0
Training loss: 1.1585400104522705
Validation loss: 2.1532639585515505

Epoch: 6| Step: 1
Training loss: 2.091501474380493
Validation loss: 2.083062300118067

Epoch: 6| Step: 2
Training loss: 1.0459281206130981
Validation loss: 2.178050036071449

Epoch: 6| Step: 3
Training loss: 1.5197060108184814
Validation loss: 2.0876888626365253

Epoch: 6| Step: 4
Training loss: 2.1521668434143066
Validation loss: 2.1535853878144295

Epoch: 6| Step: 5
Training loss: 1.1027207374572754
Validation loss: 2.170196158911592

Epoch: 6| Step: 6
Training loss: 2.101888656616211
Validation loss: 2.1727417502351987

Epoch: 6| Step: 7
Training loss: 2.127114772796631
Validation loss: 2.0999391155858196

Epoch: 6| Step: 8
Training loss: 1.771719217300415
Validation loss: 2.0987503220958095

Epoch: 6| Step: 9
Training loss: 1.67287278175354
Validation loss: 2.1498409522477018

Epoch: 6| Step: 10
Training loss: 1.8667309284210205
Validation loss: 2.0735152626550324

Epoch: 6| Step: 11
Training loss: 2.224466562271118
Validation loss: 2.113676753095401

Epoch: 6| Step: 12
Training loss: 2.217069149017334
Validation loss: 2.156780646693322

Epoch: 6| Step: 13
Training loss: 1.212721586227417
Validation loss: 2.1213063783543085

Epoch: 413| Step: 0
Training loss: 2.0677905082702637
Validation loss: 2.1603885491689048

Epoch: 6| Step: 1
Training loss: 2.0218772888183594
Validation loss: 2.0485042987331266

Epoch: 6| Step: 2
Training loss: 1.1634516716003418
Validation loss: 2.1369749230723225

Epoch: 6| Step: 3
Training loss: 1.563706874847412
Validation loss: 2.138592553395097

Epoch: 6| Step: 4
Training loss: 2.169506549835205
Validation loss: 2.281616218628422

Epoch: 6| Step: 5
Training loss: 1.719639539718628
Validation loss: 2.110470497480003

Epoch: 6| Step: 6
Training loss: 1.3226590156555176
Validation loss: 2.063798230181458

Epoch: 6| Step: 7
Training loss: 1.4365487098693848
Validation loss: 2.1400539413575204

Epoch: 6| Step: 8
Training loss: 1.849003553390503
Validation loss: 2.1175889507416756

Epoch: 6| Step: 9
Training loss: 1.7811830043792725
Validation loss: 2.1669220411649315

Epoch: 6| Step: 10
Training loss: 2.231333017349243
Validation loss: 2.133625051026703

Epoch: 6| Step: 11
Training loss: 1.2935161590576172
Validation loss: 2.1870067709235737

Epoch: 6| Step: 12
Training loss: 1.7496570348739624
Validation loss: 2.191371851069953

Epoch: 6| Step: 13
Training loss: 1.5874069929122925
Validation loss: 2.2001765466505483

Epoch: 414| Step: 0
Training loss: 1.5201947689056396
Validation loss: 2.2566224246896724

Epoch: 6| Step: 1
Training loss: 1.5147950649261475
Validation loss: 2.203927151618465

Epoch: 6| Step: 2
Training loss: 1.080992579460144
Validation loss: 2.1297568441719137

Epoch: 6| Step: 3
Training loss: 1.6363437175750732
Validation loss: 2.1321721333329395

Epoch: 6| Step: 4
Training loss: 1.7684653997421265
Validation loss: 2.203831195831299

Epoch: 6| Step: 5
Training loss: 1.3457159996032715
Validation loss: 2.1567536605301725

Epoch: 6| Step: 6
Training loss: 1.734183430671692
Validation loss: 2.2054698390345417

Epoch: 6| Step: 7
Training loss: 2.202545166015625
Validation loss: 2.1311481306629796

Epoch: 6| Step: 8
Training loss: 2.0208423137664795
Validation loss: 2.1977501735892346

Epoch: 6| Step: 9
Training loss: 1.6201694011688232
Validation loss: 2.17468523979187

Epoch: 6| Step: 10
Training loss: 2.355527639389038
Validation loss: 2.126770688641456

Epoch: 6| Step: 11
Training loss: 1.2428613901138306
Validation loss: 2.130177605536676

Epoch: 6| Step: 12
Training loss: 1.6768882274627686
Validation loss: 2.119043316892398

Epoch: 6| Step: 13
Training loss: 2.4727487564086914
Validation loss: 2.200053375254395

Epoch: 415| Step: 0
Training loss: 1.8418594598770142
Validation loss: 2.0907780867750927

Epoch: 6| Step: 1
Training loss: 1.643460750579834
Validation loss: 2.073254664738973

Epoch: 6| Step: 2
Training loss: 1.8472387790679932
Validation loss: 2.0806864448772964

Epoch: 6| Step: 3
Training loss: 2.269932746887207
Validation loss: 2.1607716775709584

Epoch: 6| Step: 4
Training loss: 1.3377773761749268
Validation loss: 2.1924129647593342

Epoch: 6| Step: 5
Training loss: 1.0193157196044922
Validation loss: 2.1146883362083027

Epoch: 6| Step: 6
Training loss: 1.4480406045913696
Validation loss: 2.1522567285004484

Epoch: 6| Step: 7
Training loss: 1.4538242816925049
Validation loss: 2.183842397505237

Epoch: 6| Step: 8
Training loss: 1.9019112586975098
Validation loss: 2.160041409154092

Epoch: 6| Step: 9
Training loss: 2.200289011001587
Validation loss: 2.1840481347935174

Epoch: 6| Step: 10
Training loss: 2.1498796939849854
Validation loss: 2.1287161355377524

Epoch: 6| Step: 11
Training loss: 1.9114048480987549
Validation loss: 2.2544642968844344

Epoch: 6| Step: 12
Training loss: 1.6445165872573853
Validation loss: 2.17830002948802

Epoch: 6| Step: 13
Training loss: 1.774245262145996
Validation loss: 2.159878432109792

Epoch: 416| Step: 0
Training loss: 1.6402268409729004
Validation loss: 2.1681134008592173

Epoch: 6| Step: 1
Training loss: 1.9693317413330078
Validation loss: 2.1197223560784453

Epoch: 6| Step: 2
Training loss: 1.877753496170044
Validation loss: 2.1642642944089827

Epoch: 6| Step: 3
Training loss: 2.032787799835205
Validation loss: 2.224375870919997

Epoch: 6| Step: 4
Training loss: 2.1076135635375977
Validation loss: 2.12219928156945

Epoch: 6| Step: 5
Training loss: 1.9723329544067383
Validation loss: 2.057085193613524

Epoch: 6| Step: 6
Training loss: 0.9876188039779663
Validation loss: 2.130318849317489

Epoch: 6| Step: 7
Training loss: 1.6957483291625977
Validation loss: 2.0981110654851443

Epoch: 6| Step: 8
Training loss: 1.4234333038330078
Validation loss: 2.145315908616589

Epoch: 6| Step: 9
Training loss: 1.8756033182144165
Validation loss: 2.194688297087146

Epoch: 6| Step: 10
Training loss: 2.066086530685425
Validation loss: 2.196056091657249

Epoch: 6| Step: 11
Training loss: 1.8717491626739502
Validation loss: 2.118274527211343

Epoch: 6| Step: 12
Training loss: 1.075908899307251
Validation loss: 2.138731118171446

Epoch: 6| Step: 13
Training loss: 1.1670278310775757
Validation loss: 2.169391708989297

Epoch: 417| Step: 0
Training loss: 1.551088571548462
Validation loss: 2.1809599822567356

Epoch: 6| Step: 1
Training loss: 1.9020758867263794
Validation loss: 2.128470859219951

Epoch: 6| Step: 2
Training loss: 1.452518343925476
Validation loss: 2.1541375216617378

Epoch: 6| Step: 3
Training loss: 1.5639406442642212
Validation loss: 2.178987133887506

Epoch: 6| Step: 4
Training loss: 1.7541875839233398
Validation loss: 2.173525356477307

Epoch: 6| Step: 5
Training loss: 1.2735648155212402
Validation loss: 2.191662157735517

Epoch: 6| Step: 6
Training loss: 1.719749927520752
Validation loss: 2.1111716429392495

Epoch: 6| Step: 7
Training loss: 1.8952109813690186
Validation loss: 2.11473871174679

Epoch: 6| Step: 8
Training loss: 2.462212085723877
Validation loss: 2.095450332087855

Epoch: 6| Step: 9
Training loss: 1.737032413482666
Validation loss: 2.211974383682333

Epoch: 6| Step: 10
Training loss: 1.6570205688476562
Validation loss: 2.1733894425053752

Epoch: 6| Step: 11
Training loss: 1.5834131240844727
Validation loss: 2.1699257499428204

Epoch: 6| Step: 12
Training loss: 1.8700060844421387
Validation loss: 2.2044129320370254

Epoch: 6| Step: 13
Training loss: 1.363210916519165
Validation loss: 2.0937160266342985

Epoch: 418| Step: 0
Training loss: 0.9724242091178894
Validation loss: 2.162727940467096

Epoch: 6| Step: 1
Training loss: 2.4870786666870117
Validation loss: 2.124536750137165

Epoch: 6| Step: 2
Training loss: 1.297644019126892
Validation loss: 2.0274132015884563

Epoch: 6| Step: 3
Training loss: 1.3741278648376465
Validation loss: 2.109043703284315

Epoch: 6| Step: 4
Training loss: 1.5163975954055786
Validation loss: 2.1152865732869794

Epoch: 6| Step: 5
Training loss: 1.362188696861267
Validation loss: 2.15027367684149

Epoch: 6| Step: 6
Training loss: 1.8081738948822021
Validation loss: 2.133346273053077

Epoch: 6| Step: 7
Training loss: 1.875301718711853
Validation loss: 2.1920702380518757

Epoch: 6| Step: 8
Training loss: 2.3038527965545654
Validation loss: 2.129258800578374

Epoch: 6| Step: 9
Training loss: 1.6700137853622437
Validation loss: 2.1670983363223333

Epoch: 6| Step: 10
Training loss: 1.5852750539779663
Validation loss: 2.1797232627868652

Epoch: 6| Step: 11
Training loss: 1.8339802026748657
Validation loss: 2.193099332112138

Epoch: 6| Step: 12
Training loss: 2.163221836090088
Validation loss: 2.2045887285663235

Epoch: 6| Step: 13
Training loss: 1.2534013986587524
Validation loss: 2.1527817044206845

Epoch: 419| Step: 0
Training loss: 1.1308385133743286
Validation loss: 2.1916000407229186

Epoch: 6| Step: 1
Training loss: 2.0381383895874023
Validation loss: 2.097570219347554

Epoch: 6| Step: 2
Training loss: 1.687560796737671
Validation loss: 2.137207761887581

Epoch: 6| Step: 3
Training loss: 2.1502890586853027
Validation loss: 2.175202259453394

Epoch: 6| Step: 4
Training loss: 2.1395089626312256
Validation loss: 2.107479028804328

Epoch: 6| Step: 5
Training loss: 1.7613959312438965
Validation loss: 2.2122100809569

Epoch: 6| Step: 6
Training loss: 1.7561068534851074
Validation loss: 2.207961497768279

Epoch: 6| Step: 7
Training loss: 1.2668920755386353
Validation loss: 2.2023281692176737

Epoch: 6| Step: 8
Training loss: 1.9874072074890137
Validation loss: 2.160814103259835

Epoch: 6| Step: 9
Training loss: 1.673278570175171
Validation loss: 2.1576768813594693

Epoch: 6| Step: 10
Training loss: 1.52528977394104
Validation loss: 2.178229990825858

Epoch: 6| Step: 11
Training loss: 1.457150936126709
Validation loss: 2.1632854682143017

Epoch: 6| Step: 12
Training loss: 1.6075160503387451
Validation loss: 2.204800587828441

Epoch: 6| Step: 13
Training loss: 2.0108814239501953
Validation loss: 2.0748220361689085

Epoch: 420| Step: 0
Training loss: 1.5859136581420898
Validation loss: 2.1150118791928856

Epoch: 6| Step: 1
Training loss: 1.5200209617614746
Validation loss: 2.1104711858175134

Epoch: 6| Step: 2
Training loss: 0.9181489944458008
Validation loss: 2.057195641661203

Epoch: 6| Step: 3
Training loss: 1.7134099006652832
Validation loss: 2.1512876928493543

Epoch: 6| Step: 4
Training loss: 2.4217827320098877
Validation loss: 2.105288956754951

Epoch: 6| Step: 5
Training loss: 2.127824306488037
Validation loss: 2.1227141118818715

Epoch: 6| Step: 6
Training loss: 2.240161418914795
Validation loss: 2.141406830920968

Epoch: 6| Step: 7
Training loss: 1.7654953002929688
Validation loss: 2.190665775729764

Epoch: 6| Step: 8
Training loss: 1.6346359252929688
Validation loss: 2.1270730674907727

Epoch: 6| Step: 9
Training loss: 1.4060503244400024
Validation loss: 2.1104147152234147

Epoch: 6| Step: 10
Training loss: 2.1092495918273926
Validation loss: 2.1916177554797103

Epoch: 6| Step: 11
Training loss: 1.7084221839904785
Validation loss: 2.173553038668889

Epoch: 6| Step: 12
Training loss: 1.9241528511047363
Validation loss: 2.1358637168843257

Epoch: 6| Step: 13
Training loss: 1.190134048461914
Validation loss: 2.240344678201983

Epoch: 421| Step: 0
Training loss: 1.1217986345291138
Validation loss: 2.097021149050805

Epoch: 6| Step: 1
Training loss: 1.4873920679092407
Validation loss: 2.110137777943765

Epoch: 6| Step: 2
Training loss: 2.1179425716400146
Validation loss: 2.231040181652192

Epoch: 6| Step: 3
Training loss: 1.3522307872772217
Validation loss: 2.182153135217646

Epoch: 6| Step: 4
Training loss: 1.4595263004302979
Validation loss: 2.1608092400335495

Epoch: 6| Step: 5
Training loss: 2.001718282699585
Validation loss: 2.1626259921699442

Epoch: 6| Step: 6
Training loss: 1.3779933452606201
Validation loss: 2.0921938598796888

Epoch: 6| Step: 7
Training loss: 2.000351905822754
Validation loss: 2.1161271013239378

Epoch: 6| Step: 8
Training loss: 1.5911757946014404
Validation loss: 2.165828504870015

Epoch: 6| Step: 9
Training loss: 1.4590792655944824
Validation loss: 2.162332210489499

Epoch: 6| Step: 10
Training loss: 1.6969780921936035
Validation loss: 2.128629743411977

Epoch: 6| Step: 11
Training loss: 1.702817678451538
Validation loss: 2.1435926857814995

Epoch: 6| Step: 12
Training loss: 3.038553237915039
Validation loss: 2.158835047034807

Epoch: 6| Step: 13
Training loss: 1.5924290418624878
Validation loss: 2.1467098164302048

Epoch: 422| Step: 0
Training loss: 2.0139331817626953
Validation loss: 2.173003560753279

Epoch: 6| Step: 1
Training loss: 1.9661779403686523
Validation loss: 2.1936912472530077

Epoch: 6| Step: 2
Training loss: 1.6239579916000366
Validation loss: 2.1416491667429605

Epoch: 6| Step: 3
Training loss: 1.2460792064666748
Validation loss: 2.194958168973205

Epoch: 6| Step: 4
Training loss: 2.025972843170166
Validation loss: 2.145903943687357

Epoch: 6| Step: 5
Training loss: 1.5313092470169067
Validation loss: 2.1680274342977874

Epoch: 6| Step: 6
Training loss: 1.6552602052688599
Validation loss: 2.1805177042561192

Epoch: 6| Step: 7
Training loss: 1.6171681880950928
Validation loss: 2.132290368439049

Epoch: 6| Step: 8
Training loss: 1.469996452331543
Validation loss: 2.118682171708794

Epoch: 6| Step: 9
Training loss: 1.6140762567520142
Validation loss: 2.162456117650514

Epoch: 6| Step: 10
Training loss: 2.216215133666992
Validation loss: 2.1474847434669413

Epoch: 6| Step: 11
Training loss: 1.9966949224472046
Validation loss: 2.1586997098820184

Epoch: 6| Step: 12
Training loss: 1.7334532737731934
Validation loss: 2.152861664372106

Epoch: 6| Step: 13
Training loss: 1.392946720123291
Validation loss: 2.1085769912248016

Epoch: 423| Step: 0
Training loss: 1.0452830791473389
Validation loss: 2.294457697099255

Epoch: 6| Step: 1
Training loss: 1.937476396560669
Validation loss: 2.1664173654330674

Epoch: 6| Step: 2
Training loss: 2.071678638458252
Validation loss: 2.1689096163677912

Epoch: 6| Step: 3
Training loss: 1.9591739177703857
Validation loss: 2.1455508803808563

Epoch: 6| Step: 4
Training loss: 1.8803247213363647
Validation loss: 2.2223431064236547

Epoch: 6| Step: 5
Training loss: 1.5082552433013916
Validation loss: 2.1083200131693194

Epoch: 6| Step: 6
Training loss: 1.4830024242401123
Validation loss: 2.130919438536449

Epoch: 6| Step: 7
Training loss: 2.166219711303711
Validation loss: 2.147282797803161

Epoch: 6| Step: 8
Training loss: 1.7382521629333496
Validation loss: 2.0752587254329393

Epoch: 6| Step: 9
Training loss: 1.6005148887634277
Validation loss: 2.1501283901993946

Epoch: 6| Step: 10
Training loss: 1.3957512378692627
Validation loss: 2.165861698888963

Epoch: 6| Step: 11
Training loss: 1.8189064264297485
Validation loss: 2.1210733921297136

Epoch: 6| Step: 12
Training loss: 1.157137155532837
Validation loss: 2.1038022784776587

Epoch: 6| Step: 13
Training loss: 1.5737473964691162
Validation loss: 2.142262266528222

Epoch: 424| Step: 0
Training loss: 1.9227309226989746
Validation loss: 2.131061069426998

Epoch: 6| Step: 1
Training loss: 1.4043108224868774
Validation loss: 2.133965887049193

Epoch: 6| Step: 2
Training loss: 1.6494545936584473
Validation loss: 2.1133552648687877

Epoch: 6| Step: 3
Training loss: 2.5109987258911133
Validation loss: 2.2098383621502946

Epoch: 6| Step: 4
Training loss: 1.8418257236480713
Validation loss: 2.1002377361379643

Epoch: 6| Step: 5
Training loss: 1.9898908138275146
Validation loss: 2.1259291120754775

Epoch: 6| Step: 6
Training loss: 1.514726161956787
Validation loss: 2.0992409029314594

Epoch: 6| Step: 7
Training loss: 1.4478747844696045
Validation loss: 2.131867116497409

Epoch: 6| Step: 8
Training loss: 0.9784426093101501
Validation loss: 2.1295532718781502

Epoch: 6| Step: 9
Training loss: 1.8039964437484741
Validation loss: 2.1714212996985323

Epoch: 6| Step: 10
Training loss: 1.4072518348693848
Validation loss: 2.1515935159498647

Epoch: 6| Step: 11
Training loss: 1.4344441890716553
Validation loss: 2.237164515320973

Epoch: 6| Step: 12
Training loss: 1.4046226739883423
Validation loss: 2.1958649927569973

Epoch: 6| Step: 13
Training loss: 1.8121275901794434
Validation loss: 2.109593988746725

Epoch: 425| Step: 0
Training loss: 1.9528179168701172
Validation loss: 2.144868066233973

Epoch: 6| Step: 1
Training loss: 1.6009337902069092
Validation loss: 2.1869903123506935

Epoch: 6| Step: 2
Training loss: 1.4047884941101074
Validation loss: 2.1795558057805544

Epoch: 6| Step: 3
Training loss: 2.09732723236084
Validation loss: 2.1467719078063965

Epoch: 6| Step: 4
Training loss: 2.070509433746338
Validation loss: 2.232612020225935

Epoch: 6| Step: 5
Training loss: 1.7202764749526978
Validation loss: 2.191594507104607

Epoch: 6| Step: 6
Training loss: 2.210625648498535
Validation loss: 2.1743017896529166

Epoch: 6| Step: 7
Training loss: 1.314683198928833
Validation loss: 2.198502681588614

Epoch: 6| Step: 8
Training loss: 1.6009880304336548
Validation loss: 2.1242565519066265

Epoch: 6| Step: 9
Training loss: 1.7091643810272217
Validation loss: 2.1907574451097878

Epoch: 6| Step: 10
Training loss: 1.6382924318313599
Validation loss: 2.2017456331560687

Epoch: 6| Step: 11
Training loss: 1.770357608795166
Validation loss: 2.151243644375955

Epoch: 6| Step: 12
Training loss: 1.177187204360962
Validation loss: 2.132326013298445

Epoch: 6| Step: 13
Training loss: 0.8823542594909668
Validation loss: 2.140865300291328

Epoch: 426| Step: 0
Training loss: 1.729048490524292
Validation loss: 2.1790785815126155

Epoch: 6| Step: 1
Training loss: 2.0001306533813477
Validation loss: 2.116824168030934

Epoch: 6| Step: 2
Training loss: 2.093799114227295
Validation loss: 2.1518245076620452

Epoch: 6| Step: 3
Training loss: 1.690566062927246
Validation loss: 2.1950636422762306

Epoch: 6| Step: 4
Training loss: 1.510787010192871
Validation loss: 2.168422425946882

Epoch: 6| Step: 5
Training loss: 2.116525173187256
Validation loss: 2.2171642011211765

Epoch: 6| Step: 6
Training loss: 1.3816320896148682
Validation loss: 2.22646991924573

Epoch: 6| Step: 7
Training loss: 1.3684985637664795
Validation loss: 2.138264266393518

Epoch: 6| Step: 8
Training loss: 0.9000281691551208
Validation loss: 2.158256066742764

Epoch: 6| Step: 9
Training loss: 2.121572971343994
Validation loss: 2.1807025504368607

Epoch: 6| Step: 10
Training loss: 1.5097038745880127
Validation loss: 2.128431015117194

Epoch: 6| Step: 11
Training loss: 1.6408865451812744
Validation loss: 2.158543695685684

Epoch: 6| Step: 12
Training loss: 1.4471551179885864
Validation loss: 2.1610946501455

Epoch: 6| Step: 13
Training loss: 1.7506558895111084
Validation loss: 2.1899183975752963

Epoch: 427| Step: 0
Training loss: 1.843271255493164
Validation loss: 2.1839494141199256

Epoch: 6| Step: 1
Training loss: 1.163938283920288
Validation loss: 2.220615863800049

Epoch: 6| Step: 2
Training loss: 1.2031214237213135
Validation loss: 2.183566954828078

Epoch: 6| Step: 3
Training loss: 1.5176050662994385
Validation loss: 2.195155379592731

Epoch: 6| Step: 4
Training loss: 1.8094134330749512
Validation loss: 2.127991500721183

Epoch: 6| Step: 5
Training loss: 1.7340874671936035
Validation loss: 2.136155746316397

Epoch: 6| Step: 6
Training loss: 1.1181963682174683
Validation loss: 2.1056451848758164

Epoch: 6| Step: 7
Training loss: 1.7754966020584106
Validation loss: 2.163983348877199

Epoch: 6| Step: 8
Training loss: 1.6888608932495117
Validation loss: 2.0963222211407078

Epoch: 6| Step: 9
Training loss: 2.154362678527832
Validation loss: 2.084660485226621

Epoch: 6| Step: 10
Training loss: 1.8953760862350464
Validation loss: 2.1373630390372327

Epoch: 6| Step: 11
Training loss: 1.7247753143310547
Validation loss: 2.1458834499441166

Epoch: 6| Step: 12
Training loss: 1.9568281173706055
Validation loss: 2.183307993796564

Epoch: 6| Step: 13
Training loss: 1.5129179954528809
Validation loss: 2.125121098692699

Epoch: 428| Step: 0
Training loss: 1.2708024978637695
Validation loss: 2.1833341352401243

Epoch: 6| Step: 1
Training loss: 1.4457868337631226
Validation loss: 2.1254522390263055

Epoch: 6| Step: 2
Training loss: 1.638885259628296
Validation loss: 2.1649076348991803

Epoch: 6| Step: 3
Training loss: 1.8110158443450928
Validation loss: 2.24372882996836

Epoch: 6| Step: 4
Training loss: 2.2312870025634766
Validation loss: 2.2041817454881567

Epoch: 6| Step: 5
Training loss: 1.8288547992706299
Validation loss: 2.2392462581716557

Epoch: 6| Step: 6
Training loss: 1.9580339193344116
Validation loss: 2.2428804828274633

Epoch: 6| Step: 7
Training loss: 2.1474523544311523
Validation loss: 2.250078014148179

Epoch: 6| Step: 8
Training loss: 1.3142943382263184
Validation loss: 2.2237177638597387

Epoch: 6| Step: 9
Training loss: 1.5177839994430542
Validation loss: 2.088124188043738

Epoch: 6| Step: 10
Training loss: 1.2345805168151855
Validation loss: 2.1399136102327736

Epoch: 6| Step: 11
Training loss: 1.9867335557937622
Validation loss: 2.2218195751149166

Epoch: 6| Step: 12
Training loss: 1.5291271209716797
Validation loss: 2.204660500249555

Epoch: 6| Step: 13
Training loss: 1.7795720100402832
Validation loss: 2.1807037194569907

Epoch: 429| Step: 0
Training loss: 1.938607096672058
Validation loss: 2.099628210067749

Epoch: 6| Step: 1
Training loss: 1.6252434253692627
Validation loss: 2.163518036565473

Epoch: 6| Step: 2
Training loss: 1.511866807937622
Validation loss: 2.188278603297408

Epoch: 6| Step: 3
Training loss: 1.2711961269378662
Validation loss: 2.1821058616843274

Epoch: 6| Step: 4
Training loss: 2.695159435272217
Validation loss: 2.1399825798567904

Epoch: 6| Step: 5
Training loss: 1.3540730476379395
Validation loss: 2.1468507692378056

Epoch: 6| Step: 6
Training loss: 1.3970438241958618
Validation loss: 2.18432609240214

Epoch: 6| Step: 7
Training loss: 1.6435234546661377
Validation loss: 2.1421987292587117

Epoch: 6| Step: 8
Training loss: 1.4415795803070068
Validation loss: 2.2047563522092757

Epoch: 6| Step: 9
Training loss: 1.48384690284729
Validation loss: 2.178699865136095

Epoch: 6| Step: 10
Training loss: 1.4361979961395264
Validation loss: 2.1543220704601658

Epoch: 6| Step: 11
Training loss: 1.4537742137908936
Validation loss: 2.164106845855713

Epoch: 6| Step: 12
Training loss: 2.8220438957214355
Validation loss: 2.167538565974082

Epoch: 6| Step: 13
Training loss: 1.3670949935913086
Validation loss: 2.2025931906956497

Epoch: 430| Step: 0
Training loss: 1.2991609573364258
Validation loss: 2.1380716575089322

Epoch: 6| Step: 1
Training loss: 1.2021772861480713
Validation loss: 2.1680282661991734

Epoch: 6| Step: 2
Training loss: 1.0024298429489136
Validation loss: 2.1264813253956456

Epoch: 6| Step: 3
Training loss: 1.995941400527954
Validation loss: 2.20481381365048

Epoch: 6| Step: 4
Training loss: 2.0812981128692627
Validation loss: 2.188943229695802

Epoch: 6| Step: 5
Training loss: 1.379763126373291
Validation loss: 2.1687329251279115

Epoch: 6| Step: 6
Training loss: 1.7900285720825195
Validation loss: 2.123159662369759

Epoch: 6| Step: 7
Training loss: 1.422769546508789
Validation loss: 2.144849761839836

Epoch: 6| Step: 8
Training loss: 2.2118473052978516
Validation loss: 2.1346910666393977

Epoch: 6| Step: 9
Training loss: 1.7925699949264526
Validation loss: 2.2568111445314143

Epoch: 6| Step: 10
Training loss: 1.672128677368164
Validation loss: 2.1368471883958384

Epoch: 6| Step: 11
Training loss: 1.4881747961044312
Validation loss: 2.254260378499185

Epoch: 6| Step: 12
Training loss: 2.325334310531616
Validation loss: 2.161521147656184

Epoch: 6| Step: 13
Training loss: 1.3914440870285034
Validation loss: 2.12832659803411

Epoch: 431| Step: 0
Training loss: 1.6667773723602295
Validation loss: 2.1539441898304927

Epoch: 6| Step: 1
Training loss: 1.630338191986084
Validation loss: 2.1379062385969263

Epoch: 6| Step: 2
Training loss: 1.868138074874878
Validation loss: 2.217799543052591

Epoch: 6| Step: 3
Training loss: 1.616436243057251
Validation loss: 2.221663978792006

Epoch: 6| Step: 4
Training loss: 1.8137593269348145
Validation loss: 2.104206767133487

Epoch: 6| Step: 5
Training loss: 1.9157097339630127
Validation loss: 2.1394455343164425

Epoch: 6| Step: 6
Training loss: 1.6286096572875977
Validation loss: 2.2339181130932224

Epoch: 6| Step: 7
Training loss: 2.1297335624694824
Validation loss: 2.071101656524084

Epoch: 6| Step: 8
Training loss: 2.2601218223571777
Validation loss: 2.137939199324577

Epoch: 6| Step: 9
Training loss: 1.3957374095916748
Validation loss: 2.147416219916395

Epoch: 6| Step: 10
Training loss: 1.0478157997131348
Validation loss: 2.0990564541150163

Epoch: 6| Step: 11
Training loss: 2.27703857421875
Validation loss: 2.1425957756657756

Epoch: 6| Step: 12
Training loss: 1.3069449663162231
Validation loss: 2.2078629309131252

Epoch: 6| Step: 13
Training loss: 1.610044240951538
Validation loss: 2.1934780305431736

Epoch: 432| Step: 0
Training loss: 2.0356063842773438
Validation loss: 2.145014856451301

Epoch: 6| Step: 1
Training loss: 1.8997313976287842
Validation loss: 2.1795143722206034

Epoch: 6| Step: 2
Training loss: 1.524186134338379
Validation loss: 2.151406370183473

Epoch: 6| Step: 3
Training loss: 1.4617112874984741
Validation loss: 2.1663796722248034

Epoch: 6| Step: 4
Training loss: 1.755596399307251
Validation loss: 2.1189504259376117

Epoch: 6| Step: 5
Training loss: 1.2745401859283447
Validation loss: 2.1263558569774834

Epoch: 6| Step: 6
Training loss: 1.691518783569336
Validation loss: 2.222536502345916

Epoch: 6| Step: 7
Training loss: 1.407201886177063
Validation loss: 2.162628368664813

Epoch: 6| Step: 8
Training loss: 1.2134844064712524
Validation loss: 2.139633652984455

Epoch: 6| Step: 9
Training loss: 1.6148481369018555
Validation loss: 2.173595948885846

Epoch: 6| Step: 10
Training loss: 1.4158201217651367
Validation loss: 2.087530148926602

Epoch: 6| Step: 11
Training loss: 1.5251095294952393
Validation loss: 2.140066341687274

Epoch: 6| Step: 12
Training loss: 2.718508243560791
Validation loss: 2.218677641243063

Epoch: 6| Step: 13
Training loss: 1.9517759084701538
Validation loss: 2.225726648043561

Epoch: 433| Step: 0
Training loss: 1.3427400588989258
Validation loss: 2.183354849456459

Epoch: 6| Step: 1
Training loss: 1.8162662982940674
Validation loss: 2.1160236635515766

Epoch: 6| Step: 2
Training loss: 1.1832941770553589
Validation loss: 2.148859066347922

Epoch: 6| Step: 3
Training loss: 1.8625271320343018
Validation loss: 2.2228423985101844

Epoch: 6| Step: 4
Training loss: 1.5256338119506836
Validation loss: 2.2527323153711136

Epoch: 6| Step: 5
Training loss: 1.7592095136642456
Validation loss: 2.110318958118398

Epoch: 6| Step: 6
Training loss: 1.5186175107955933
Validation loss: 2.2415311862063665

Epoch: 6| Step: 7
Training loss: 1.6648797988891602
Validation loss: 2.1445007144763903

Epoch: 6| Step: 8
Training loss: 2.088149070739746
Validation loss: 2.1205605409478627

Epoch: 6| Step: 9
Training loss: 1.4472869634628296
Validation loss: 2.1876590969741985

Epoch: 6| Step: 10
Training loss: 2.1257715225219727
Validation loss: 2.111951205038255

Epoch: 6| Step: 11
Training loss: 1.7154093980789185
Validation loss: 2.1374891291382494

Epoch: 6| Step: 12
Training loss: 1.1383490562438965
Validation loss: 2.2262700219308176

Epoch: 6| Step: 13
Training loss: 1.7200055122375488
Validation loss: 2.1514564662851314

Epoch: 434| Step: 0
Training loss: 1.9063647985458374
Validation loss: 2.1331079813741867

Epoch: 6| Step: 1
Training loss: 2.465414524078369
Validation loss: 2.163500439736151

Epoch: 6| Step: 2
Training loss: 2.2749428749084473
Validation loss: 2.143618768261325

Epoch: 6| Step: 3
Training loss: 1.8917696475982666
Validation loss: 2.222500522931417

Epoch: 6| Step: 4
Training loss: 1.2972508668899536
Validation loss: 2.2461391879666235

Epoch: 6| Step: 5
Training loss: 2.1622815132141113
Validation loss: 2.1979251369353263

Epoch: 6| Step: 6
Training loss: 1.3920469284057617
Validation loss: 2.1203808605030017

Epoch: 6| Step: 7
Training loss: 1.4150617122650146
Validation loss: 2.199539510152673

Epoch: 6| Step: 8
Training loss: 1.5252279043197632
Validation loss: 2.1371219196627216

Epoch: 6| Step: 9
Training loss: 1.5943043231964111
Validation loss: 2.1238565778219574

Epoch: 6| Step: 10
Training loss: 1.733398199081421
Validation loss: 2.133179813302973

Epoch: 6| Step: 11
Training loss: 1.4181742668151855
Validation loss: 2.1611953935315533

Epoch: 6| Step: 12
Training loss: 1.015709638595581
Validation loss: 2.126623079340945

Epoch: 6| Step: 13
Training loss: 1.1016356945037842
Validation loss: 2.162683081883256

Epoch: 435| Step: 0
Training loss: 1.5325562953948975
Validation loss: 2.0510356016056512

Epoch: 6| Step: 1
Training loss: 1.9254623651504517
Validation loss: 2.174334713207778

Epoch: 6| Step: 2
Training loss: 1.6725313663482666
Validation loss: 2.077830168508714

Epoch: 6| Step: 3
Training loss: 1.050512433052063
Validation loss: 2.110937323621524

Epoch: 6| Step: 4
Training loss: 1.4663819074630737
Validation loss: 2.0911880129127094

Epoch: 6| Step: 5
Training loss: 2.0262269973754883
Validation loss: 2.1948182223945536

Epoch: 6| Step: 6
Training loss: 1.323420524597168
Validation loss: 2.213717128640862

Epoch: 6| Step: 7
Training loss: 1.5677887201309204
Validation loss: 2.070401378857192

Epoch: 6| Step: 8
Training loss: 1.5017106533050537
Validation loss: 2.179678996404012

Epoch: 6| Step: 9
Training loss: 1.1822296380996704
Validation loss: 2.2189720881882535

Epoch: 6| Step: 10
Training loss: 1.8221845626831055
Validation loss: 2.1768467810846146

Epoch: 6| Step: 11
Training loss: 1.8163414001464844
Validation loss: 2.2295271863219557

Epoch: 6| Step: 12
Training loss: 2.32614803314209
Validation loss: 2.118936438714304

Epoch: 6| Step: 13
Training loss: 1.949352741241455
Validation loss: 2.217389219550676

Epoch: 436| Step: 0
Training loss: 1.5261210203170776
Validation loss: 2.2658219875827914

Epoch: 6| Step: 1
Training loss: 1.4990572929382324
Validation loss: 2.1760819240282943

Epoch: 6| Step: 2
Training loss: 1.5706678628921509
Validation loss: 2.1993069571833455

Epoch: 6| Step: 3
Training loss: 1.5010454654693604
Validation loss: 2.1832628788486605

Epoch: 6| Step: 4
Training loss: 1.3314509391784668
Validation loss: 2.1255393797351467

Epoch: 6| Step: 5
Training loss: 1.941624402999878
Validation loss: 2.2118555756025415

Epoch: 6| Step: 6
Training loss: 1.6162538528442383
Validation loss: 2.123604264310611

Epoch: 6| Step: 7
Training loss: 1.4181840419769287
Validation loss: 2.154149780991257

Epoch: 6| Step: 8
Training loss: 1.7086714506149292
Validation loss: 2.165929117510396

Epoch: 6| Step: 9
Training loss: 1.7949926853179932
Validation loss: 2.0841221399204706

Epoch: 6| Step: 10
Training loss: 1.4181199073791504
Validation loss: 2.142586179958877

Epoch: 6| Step: 11
Training loss: 1.4675447940826416
Validation loss: 2.1499681421505508

Epoch: 6| Step: 12
Training loss: 2.2255048751831055
Validation loss: 2.1477994354822303

Epoch: 6| Step: 13
Training loss: 1.4292367696762085
Validation loss: 2.133094567124562

Epoch: 437| Step: 0
Training loss: 2.1646595001220703
Validation loss: 2.232667930664555

Epoch: 6| Step: 1
Training loss: 1.3947811126708984
Validation loss: 2.144109672115695

Epoch: 6| Step: 2
Training loss: 2.025991439819336
Validation loss: 2.173186053511917

Epoch: 6| Step: 3
Training loss: 1.7074406147003174
Validation loss: 2.160767509091285

Epoch: 6| Step: 4
Training loss: 1.3147647380828857
Validation loss: 2.1399117208296254

Epoch: 6| Step: 5
Training loss: 1.7219552993774414
Validation loss: 2.233328852602231

Epoch: 6| Step: 6
Training loss: 1.2792035341262817
Validation loss: 2.15065755767207

Epoch: 6| Step: 7
Training loss: 1.6544785499572754
Validation loss: 2.1760092319980746

Epoch: 6| Step: 8
Training loss: 0.7874994277954102
Validation loss: 2.206402765807285

Epoch: 6| Step: 9
Training loss: 2.181025505065918
Validation loss: 2.147846906415878

Epoch: 6| Step: 10
Training loss: 1.1612694263458252
Validation loss: 2.1736541666010374

Epoch: 6| Step: 11
Training loss: 2.255220413208008
Validation loss: 2.1392652526978524

Epoch: 6| Step: 12
Training loss: 2.0382609367370605
Validation loss: 2.2594635537875596

Epoch: 6| Step: 13
Training loss: 2.280184507369995
Validation loss: 2.2308627533656296

Epoch: 438| Step: 0
Training loss: 1.4689147472381592
Validation loss: 2.2014424365053893

Epoch: 6| Step: 1
Training loss: 1.5550782680511475
Validation loss: 2.140852899961574

Epoch: 6| Step: 2
Training loss: 1.523228645324707
Validation loss: 2.1406668745061403

Epoch: 6| Step: 3
Training loss: 0.8512946367263794
Validation loss: 2.2554225793448825

Epoch: 6| Step: 4
Training loss: 2.408566951751709
Validation loss: 2.1326236442853044

Epoch: 6| Step: 5
Training loss: 1.4110689163208008
Validation loss: 2.2391440022376274

Epoch: 6| Step: 6
Training loss: 1.6868921518325806
Validation loss: 2.186782304958631

Epoch: 6| Step: 7
Training loss: 1.2258713245391846
Validation loss: 2.24151812958461

Epoch: 6| Step: 8
Training loss: 1.6437535285949707
Validation loss: 2.1529957197045766

Epoch: 6| Step: 9
Training loss: 1.8991528749465942
Validation loss: 2.2050483483140186

Epoch: 6| Step: 10
Training loss: 1.7656495571136475
Validation loss: 2.2576865380810154

Epoch: 6| Step: 11
Training loss: 1.335619568824768
Validation loss: 2.1524813816111577

Epoch: 6| Step: 12
Training loss: 2.7603068351745605
Validation loss: 2.200475710694508

Epoch: 6| Step: 13
Training loss: 1.6944489479064941
Validation loss: 2.211623769934459

Epoch: 439| Step: 0
Training loss: 1.660506010055542
Validation loss: 2.2221688839697067

Epoch: 6| Step: 1
Training loss: 1.7954871654510498
Validation loss: 2.173524328457412

Epoch: 6| Step: 2
Training loss: 1.920923113822937
Validation loss: 2.1861446416506203

Epoch: 6| Step: 3
Training loss: 1.1561576128005981
Validation loss: 2.124297716284311

Epoch: 6| Step: 4
Training loss: 1.4948997497558594
Validation loss: 2.138248287221437

Epoch: 6| Step: 5
Training loss: 1.6361887454986572
Validation loss: 2.175187107055418

Epoch: 6| Step: 6
Training loss: 1.8811068534851074
Validation loss: 2.204655207613463

Epoch: 6| Step: 7
Training loss: 1.704352855682373
Validation loss: 2.163653773646201

Epoch: 6| Step: 8
Training loss: 1.4770349264144897
Validation loss: 2.1038693394712222

Epoch: 6| Step: 9
Training loss: 1.5658082962036133
Validation loss: 2.0958113311439432

Epoch: 6| Step: 10
Training loss: 0.972044825553894
Validation loss: 2.14461176882508

Epoch: 6| Step: 11
Training loss: 1.3898568153381348
Validation loss: 2.185491979763072

Epoch: 6| Step: 12
Training loss: 2.189722776412964
Validation loss: 2.1956549485524497

Epoch: 6| Step: 13
Training loss: 2.6350793838500977
Validation loss: 2.1417871034273537

Epoch: 440| Step: 0
Training loss: 1.661191701889038
Validation loss: 2.1558585269476778

Epoch: 6| Step: 1
Training loss: 1.9019813537597656
Validation loss: 2.209489537823585

Epoch: 6| Step: 2
Training loss: 2.048239231109619
Validation loss: 2.1716664529615834

Epoch: 6| Step: 3
Training loss: 1.099942684173584
Validation loss: 2.217267028747066

Epoch: 6| Step: 4
Training loss: 2.0289077758789062
Validation loss: 2.173270765171256

Epoch: 6| Step: 5
Training loss: 1.6783051490783691
Validation loss: 2.104860019940202

Epoch: 6| Step: 6
Training loss: 1.0975172519683838
Validation loss: 2.285158139403148

Epoch: 6| Step: 7
Training loss: 1.349054217338562
Validation loss: 2.118887669296675

Epoch: 6| Step: 8
Training loss: 1.3254408836364746
Validation loss: 2.1724832673226633

Epoch: 6| Step: 9
Training loss: 2.6140079498291016
Validation loss: 2.2273137441245456

Epoch: 6| Step: 10
Training loss: 1.7450668811798096
Validation loss: 2.1617663060465167

Epoch: 6| Step: 11
Training loss: 1.672708511352539
Validation loss: 2.212544979587678

Epoch: 6| Step: 12
Training loss: 1.2295321226119995
Validation loss: 2.1608835433119085

Epoch: 6| Step: 13
Training loss: 1.8043303489685059
Validation loss: 2.183800143580283

Epoch: 441| Step: 0
Training loss: 1.4983623027801514
Validation loss: 2.1688986196312854

Epoch: 6| Step: 1
Training loss: 1.7566897869110107
Validation loss: 2.2646132976778093

Epoch: 6| Step: 2
Training loss: 1.781531572341919
Validation loss: 2.140472965855752

Epoch: 6| Step: 3
Training loss: 1.41904878616333
Validation loss: 2.2321524825147403

Epoch: 6| Step: 4
Training loss: 1.8793272972106934
Validation loss: 2.145696214450303

Epoch: 6| Step: 5
Training loss: 1.782573938369751
Validation loss: 2.2059366728669856

Epoch: 6| Step: 6
Training loss: 1.6231451034545898
Validation loss: 2.186845821719016

Epoch: 6| Step: 7
Training loss: 1.5901782512664795
Validation loss: 2.1760836006492696

Epoch: 6| Step: 8
Training loss: 1.5775502920150757
Validation loss: 2.1228425284867645

Epoch: 6| Step: 9
Training loss: 1.7576061487197876
Validation loss: 2.2126239576647357

Epoch: 6| Step: 10
Training loss: 1.4964381456375122
Validation loss: 2.213666336510771

Epoch: 6| Step: 11
Training loss: 1.0590273141860962
Validation loss: 2.163099214594851

Epoch: 6| Step: 12
Training loss: 1.9616426229476929
Validation loss: 2.1394492541590044

Epoch: 6| Step: 13
Training loss: 2.3973991870880127
Validation loss: 2.1801125875083347

Epoch: 442| Step: 0
Training loss: 2.263096809387207
Validation loss: 2.206549770088606

Epoch: 6| Step: 1
Training loss: 1.606015920639038
Validation loss: 2.1799049941442346

Epoch: 6| Step: 2
Training loss: 1.811867356300354
Validation loss: 2.069155800727106

Epoch: 6| Step: 3
Training loss: 1.8895031213760376
Validation loss: 2.0788147603311846

Epoch: 6| Step: 4
Training loss: 1.7844008207321167
Validation loss: 2.0519535310806765

Epoch: 6| Step: 5
Training loss: 1.2660232782363892
Validation loss: 2.226399626783145

Epoch: 6| Step: 6
Training loss: 2.273482322692871
Validation loss: 2.151618924192203

Epoch: 6| Step: 7
Training loss: 1.26310396194458
Validation loss: 2.1692170250800347

Epoch: 6| Step: 8
Training loss: 1.7493377923965454
Validation loss: 2.0851263564120055

Epoch: 6| Step: 9
Training loss: 1.5597885847091675
Validation loss: 2.106131112703713

Epoch: 6| Step: 10
Training loss: 1.7421112060546875
Validation loss: 2.112487559677452

Epoch: 6| Step: 11
Training loss: 1.518713116645813
Validation loss: 2.189615313724805

Epoch: 6| Step: 12
Training loss: 1.3202569484710693
Validation loss: 2.1768279947260374

Epoch: 6| Step: 13
Training loss: 1.1858566999435425
Validation loss: 2.1548324451651624

Epoch: 443| Step: 0
Training loss: 1.670569896697998
Validation loss: 2.1621096634095713

Epoch: 6| Step: 1
Training loss: 1.4110398292541504
Validation loss: 2.125178372988137

Epoch: 6| Step: 2
Training loss: 1.2684043645858765
Validation loss: 2.158220286010414

Epoch: 6| Step: 3
Training loss: 1.6501479148864746
Validation loss: 2.2027833538670696

Epoch: 6| Step: 4
Training loss: 1.4265525341033936
Validation loss: 2.1345117886861167

Epoch: 6| Step: 5
Training loss: 1.5594227313995361
Validation loss: 2.1799833261838524

Epoch: 6| Step: 6
Training loss: 1.8155524730682373
Validation loss: 2.130221192554761

Epoch: 6| Step: 7
Training loss: 1.5096356868743896
Validation loss: 2.12850236123608

Epoch: 6| Step: 8
Training loss: 2.041348457336426
Validation loss: 2.1146019556189097

Epoch: 6| Step: 9
Training loss: 1.7255771160125732
Validation loss: 2.1117718386393722

Epoch: 6| Step: 10
Training loss: 1.6319949626922607
Validation loss: 2.2305105488787413

Epoch: 6| Step: 11
Training loss: 2.0957603454589844
Validation loss: 2.1589744680671283

Epoch: 6| Step: 12
Training loss: 2.1680657863616943
Validation loss: 2.24386267892776

Epoch: 6| Step: 13
Training loss: 2.2682712078094482
Validation loss: 2.1714550654093423

Epoch: 444| Step: 0
Training loss: 1.423011302947998
Validation loss: 2.177118473155524

Epoch: 6| Step: 1
Training loss: 1.3628592491149902
Validation loss: 2.1588973178658435

Epoch: 6| Step: 2
Training loss: 2.3634097576141357
Validation loss: 2.1770568663074124

Epoch: 6| Step: 3
Training loss: 1.8823790550231934
Validation loss: 2.1547662314548286

Epoch: 6| Step: 4
Training loss: 2.5614190101623535
Validation loss: 2.247061055193665

Epoch: 6| Step: 5
Training loss: 1.4610215425491333
Validation loss: 2.1731923498133177

Epoch: 6| Step: 6
Training loss: 1.6002938747406006
Validation loss: 2.1021156054671093

Epoch: 6| Step: 7
Training loss: 2.0872514247894287
Validation loss: 2.136786973604592

Epoch: 6| Step: 8
Training loss: 1.6003530025482178
Validation loss: 2.246165390937559

Epoch: 6| Step: 9
Training loss: 1.3985087871551514
Validation loss: 2.144349093078285

Epoch: 6| Step: 10
Training loss: 1.1715840101242065
Validation loss: 2.2525892590963714

Epoch: 6| Step: 11
Training loss: 1.9444618225097656
Validation loss: 2.143634585924046

Epoch: 6| Step: 12
Training loss: 1.6377372741699219
Validation loss: 2.1251341348053305

Epoch: 6| Step: 13
Training loss: 1.1445997953414917
Validation loss: 2.1602891824578725

Epoch: 445| Step: 0
Training loss: 2.094600200653076
Validation loss: 2.149588754100184

Epoch: 6| Step: 1
Training loss: 1.2473195791244507
Validation loss: 2.0918084549647507

Epoch: 6| Step: 2
Training loss: 2.567601203918457
Validation loss: 2.220145299870481

Epoch: 6| Step: 3
Training loss: 1.959396481513977
Validation loss: 2.0896139042351836

Epoch: 6| Step: 4
Training loss: 1.897526741027832
Validation loss: 2.1567746182923675

Epoch: 6| Step: 5
Training loss: 1.4988152980804443
Validation loss: 2.072001721269341

Epoch: 6| Step: 6
Training loss: 1.7042522430419922
Validation loss: 2.11125510995106

Epoch: 6| Step: 7
Training loss: 1.356952428817749
Validation loss: 2.1976180409872406

Epoch: 6| Step: 8
Training loss: 1.2787679433822632
Validation loss: 2.182538476041568

Epoch: 6| Step: 9
Training loss: 1.056872010231018
Validation loss: 2.2035902123297415

Epoch: 6| Step: 10
Training loss: 1.4913192987442017
Validation loss: 2.181168535704254

Epoch: 6| Step: 11
Training loss: 2.1500651836395264
Validation loss: 2.2200131672684864

Epoch: 6| Step: 12
Training loss: 1.5541189908981323
Validation loss: 2.1807338345435356

Epoch: 6| Step: 13
Training loss: 1.0799670219421387
Validation loss: 2.2047727364365772

Epoch: 446| Step: 0
Training loss: 1.1343950033187866
Validation loss: 2.173808228585028

Epoch: 6| Step: 1
Training loss: 1.869871973991394
Validation loss: 2.1710888749809674

Epoch: 6| Step: 2
Training loss: 1.6978094577789307
Validation loss: 2.1106599223229194

Epoch: 6| Step: 3
Training loss: 2.087233781814575
Validation loss: 2.179628631120087

Epoch: 6| Step: 4
Training loss: 1.8364310264587402
Validation loss: 2.0927773521792505

Epoch: 6| Step: 5
Training loss: 1.603161096572876
Validation loss: 2.1795495658792476

Epoch: 6| Step: 6
Training loss: 1.3760885000228882
Validation loss: 2.2104914444749073

Epoch: 6| Step: 7
Training loss: 1.1690024137496948
Validation loss: 2.11802936625737

Epoch: 6| Step: 8
Training loss: 1.9165679216384888
Validation loss: 2.1384040078809186

Epoch: 6| Step: 9
Training loss: 1.551405429840088
Validation loss: 2.1659146867772585

Epoch: 6| Step: 10
Training loss: 2.522212505340576
Validation loss: 2.1468528265594156

Epoch: 6| Step: 11
Training loss: 1.1903831958770752
Validation loss: 2.1011254889990694

Epoch: 6| Step: 12
Training loss: 1.895764708518982
Validation loss: 2.1597908107183312

Epoch: 6| Step: 13
Training loss: 1.1703238487243652
Validation loss: 2.126271406809489

Epoch: 447| Step: 0
Training loss: 1.5739916563034058
Validation loss: 2.1328353446017028

Epoch: 6| Step: 1
Training loss: 2.1934168338775635
Validation loss: 2.1231546709614415

Epoch: 6| Step: 2
Training loss: 1.5083543062210083
Validation loss: 2.1299472649892173

Epoch: 6| Step: 3
Training loss: 1.1791913509368896
Validation loss: 2.12317398799363

Epoch: 6| Step: 4
Training loss: 2.5470356941223145
Validation loss: 2.122612222548454

Epoch: 6| Step: 5
Training loss: 2.3733205795288086
Validation loss: 2.117263614490468

Epoch: 6| Step: 6
Training loss: 1.5890679359436035
Validation loss: 2.0967388050530547

Epoch: 6| Step: 7
Training loss: 0.9734984040260315
Validation loss: 2.1766859921075965

Epoch: 6| Step: 8
Training loss: 1.501641869544983
Validation loss: 2.1619827208980436

Epoch: 6| Step: 9
Training loss: 1.9475897550582886
Validation loss: 2.142793692568297

Epoch: 6| Step: 10
Training loss: 1.5041437149047852
Validation loss: 2.096929483516242

Epoch: 6| Step: 11
Training loss: 1.58148193359375
Validation loss: 2.1608528155152515

Epoch: 6| Step: 12
Training loss: 1.6171083450317383
Validation loss: 2.038997780892157

Epoch: 6| Step: 13
Training loss: 1.802743673324585
Validation loss: 2.1524567911701817

Epoch: 448| Step: 0
Training loss: 2.1767773628234863
Validation loss: 2.1177176006378664

Epoch: 6| Step: 1
Training loss: 1.7330055236816406
Validation loss: 2.1058413315844793

Epoch: 6| Step: 2
Training loss: 1.5733630657196045
Validation loss: 2.180116391951038

Epoch: 6| Step: 3
Training loss: 1.5092582702636719
Validation loss: 2.170929797234074

Epoch: 6| Step: 4
Training loss: 1.8256763219833374
Validation loss: 2.1707246483013196

Epoch: 6| Step: 5
Training loss: 1.325140118598938
Validation loss: 2.2541579431103123

Epoch: 6| Step: 6
Training loss: 1.8628041744232178
Validation loss: 2.192380897460445

Epoch: 6| Step: 7
Training loss: 1.0911924839019775
Validation loss: 2.215964683922388

Epoch: 6| Step: 8
Training loss: 2.0728282928466797
Validation loss: 2.167263779588925

Epoch: 6| Step: 9
Training loss: 1.6472089290618896
Validation loss: 2.1065792088867514

Epoch: 6| Step: 10
Training loss: 2.0143489837646484
Validation loss: 2.1249074141184487

Epoch: 6| Step: 11
Training loss: 1.2643206119537354
Validation loss: 2.1227907109004196

Epoch: 6| Step: 12
Training loss: 1.6196333169937134
Validation loss: 2.1643803555478334

Epoch: 6| Step: 13
Training loss: 1.4704669713974
Validation loss: 2.2218955806506577

Epoch: 449| Step: 0
Training loss: 1.6914430856704712
Validation loss: 2.1654177814401607

Epoch: 6| Step: 1
Training loss: 1.6962461471557617
Validation loss: 2.1487889469310804

Epoch: 6| Step: 2
Training loss: 2.1562604904174805
Validation loss: 2.13241256436994

Epoch: 6| Step: 3
Training loss: 1.0516910552978516
Validation loss: 2.193369188616353

Epoch: 6| Step: 4
Training loss: 2.366476058959961
Validation loss: 2.1623141381048385

Epoch: 6| Step: 5
Training loss: 1.8701889514923096
Validation loss: 2.181316352659656

Epoch: 6| Step: 6
Training loss: 1.6201860904693604
Validation loss: 2.0992024957492785

Epoch: 6| Step: 7
Training loss: 1.3191838264465332
Validation loss: 2.142852014110934

Epoch: 6| Step: 8
Training loss: 1.1802746057510376
Validation loss: 2.2122196074455016

Epoch: 6| Step: 9
Training loss: 1.6666736602783203
Validation loss: 2.19240568530175

Epoch: 6| Step: 10
Training loss: 1.646836519241333
Validation loss: 2.1117704529916086

Epoch: 6| Step: 11
Training loss: 1.3699951171875
Validation loss: 2.095055810866817

Epoch: 6| Step: 12
Training loss: 1.6318862438201904
Validation loss: 2.1386890488286174

Epoch: 6| Step: 13
Training loss: 1.8398594856262207
Validation loss: 2.19200462166981

Epoch: 450| Step: 0
Training loss: 1.7950549125671387
Validation loss: 2.1058687933029665

Epoch: 6| Step: 1
Training loss: 1.896674394607544
Validation loss: 2.160050551096598

Epoch: 6| Step: 2
Training loss: 1.2448309659957886
Validation loss: 2.147258241971334

Epoch: 6| Step: 3
Training loss: 2.139326572418213
Validation loss: 2.1881432199990876

Epoch: 6| Step: 4
Training loss: 1.9315119981765747
Validation loss: 2.167062110798333

Epoch: 6| Step: 5
Training loss: 1.6010560989379883
Validation loss: 2.128433305730102

Epoch: 6| Step: 6
Training loss: 1.2528107166290283
Validation loss: 2.196021890127531

Epoch: 6| Step: 7
Training loss: 1.2717809677124023
Validation loss: 2.161831614791706

Epoch: 6| Step: 8
Training loss: 1.7710278034210205
Validation loss: 2.1309463708631453

Epoch: 6| Step: 9
Training loss: 1.934739589691162
Validation loss: 2.2121917432354343

Epoch: 6| Step: 10
Training loss: 2.1972908973693848
Validation loss: 2.1431664779622066

Epoch: 6| Step: 11
Training loss: 1.1432526111602783
Validation loss: 2.1392814702885126

Epoch: 6| Step: 12
Training loss: 1.4033052921295166
Validation loss: 2.131893793741862

Epoch: 6| Step: 13
Training loss: 2.8220815658569336
Validation loss: 2.1873676648703952

Epoch: 451| Step: 0
Training loss: 1.7543542385101318
Validation loss: 2.1344192848410657

Epoch: 6| Step: 1
Training loss: 1.3075621128082275
Validation loss: 2.168394386127431

Epoch: 6| Step: 2
Training loss: 1.9067602157592773
Validation loss: 2.152617727556536

Epoch: 6| Step: 3
Training loss: 2.1257882118225098
Validation loss: 2.200127575987129

Epoch: 6| Step: 4
Training loss: 1.639927625656128
Validation loss: 2.1945277670378327

Epoch: 6| Step: 5
Training loss: 1.5438706874847412
Validation loss: 2.151801586151123

Epoch: 6| Step: 6
Training loss: 1.3567099571228027
Validation loss: 2.1112130200991066

Epoch: 6| Step: 7
Training loss: 1.752206802368164
Validation loss: 2.160675525665283

Epoch: 6| Step: 8
Training loss: 1.260949969291687
Validation loss: 2.1968898721920547

Epoch: 6| Step: 9
Training loss: 1.4745473861694336
Validation loss: 2.154240221105596

Epoch: 6| Step: 10
Training loss: 1.1115288734436035
Validation loss: 2.1215732866717922

Epoch: 6| Step: 11
Training loss: 2.081866502761841
Validation loss: 2.1658526312920356

Epoch: 6| Step: 12
Training loss: 1.7089227437973022
Validation loss: 2.0698856717796734

Epoch: 6| Step: 13
Training loss: 2.0346102714538574
Validation loss: 2.1365919664341915

Epoch: 452| Step: 0
Training loss: 1.4009407758712769
Validation loss: 2.225994502344439

Epoch: 6| Step: 1
Training loss: 1.216576337814331
Validation loss: 2.178951942792503

Epoch: 6| Step: 2
Training loss: 1.425476312637329
Validation loss: 2.2077396505622455

Epoch: 6| Step: 3
Training loss: 1.9996716976165771
Validation loss: 2.1423669604844946

Epoch: 6| Step: 4
Training loss: 2.027928352355957
Validation loss: 2.1935243504021757

Epoch: 6| Step: 5
Training loss: 1.1153289079666138
Validation loss: 2.1179902130557644

Epoch: 6| Step: 6
Training loss: 1.419835090637207
Validation loss: 2.1955840459433933

Epoch: 6| Step: 7
Training loss: 1.5012480020523071
Validation loss: 2.1788747579820695

Epoch: 6| Step: 8
Training loss: 1.8464443683624268
Validation loss: 2.133160339888706

Epoch: 6| Step: 9
Training loss: 1.9099822044372559
Validation loss: 2.1536557738498976

Epoch: 6| Step: 10
Training loss: 2.2443575859069824
Validation loss: 2.163047162435388

Epoch: 6| Step: 11
Training loss: 1.5200365781784058
Validation loss: 2.1683707365425686

Epoch: 6| Step: 12
Training loss: 1.440255045890808
Validation loss: 2.1314365325435514

Epoch: 6| Step: 13
Training loss: 1.540433645248413
Validation loss: 2.1392087167309177

Epoch: 453| Step: 0
Training loss: 1.6374040842056274
Validation loss: 2.210338597656578

Epoch: 6| Step: 1
Training loss: 1.1095950603485107
Validation loss: 2.1367597054409724

Epoch: 6| Step: 2
Training loss: 1.916764497756958
Validation loss: 2.1474366136776504

Epoch: 6| Step: 3
Training loss: 2.2468647956848145
Validation loss: 2.1700877143490698

Epoch: 6| Step: 4
Training loss: 1.3670458793640137
Validation loss: 2.2993007039511077

Epoch: 6| Step: 5
Training loss: 2.2940759658813477
Validation loss: 2.144263611044935

Epoch: 6| Step: 6
Training loss: 1.7298426628112793
Validation loss: 2.17051104832721

Epoch: 6| Step: 7
Training loss: 1.252135992050171
Validation loss: 2.192770319600259

Epoch: 6| Step: 8
Training loss: 1.6666845083236694
Validation loss: 2.2143284633595455

Epoch: 6| Step: 9
Training loss: 1.2557469606399536
Validation loss: 2.1554693047718336

Epoch: 6| Step: 10
Training loss: 2.0259690284729004
Validation loss: 2.218007105653004

Epoch: 6| Step: 11
Training loss: 1.289168357849121
Validation loss: 2.258381228293142

Epoch: 6| Step: 12
Training loss: 1.9353539943695068
Validation loss: 2.2222456983340684

Epoch: 6| Step: 13
Training loss: 2.0884883403778076
Validation loss: 2.1868598627787765

Epoch: 454| Step: 0
Training loss: 1.4709315299987793
Validation loss: 2.109891353114959

Epoch: 6| Step: 1
Training loss: 1.8319494724273682
Validation loss: 2.1064405543829805

Epoch: 6| Step: 2
Training loss: 1.5277864933013916
Validation loss: 2.102630370406694

Epoch: 6| Step: 3
Training loss: 1.5960705280303955
Validation loss: 2.1822884134067

Epoch: 6| Step: 4
Training loss: 1.4553974866867065
Validation loss: 2.1941786504560903

Epoch: 6| Step: 5
Training loss: 1.4863593578338623
Validation loss: 2.127928251861244

Epoch: 6| Step: 6
Training loss: 1.3499597311019897
Validation loss: 2.1721577259802047

Epoch: 6| Step: 7
Training loss: 1.6966288089752197
Validation loss: 2.162222872498215

Epoch: 6| Step: 8
Training loss: 1.765923261642456
Validation loss: 2.121263814228837

Epoch: 6| Step: 9
Training loss: 2.225128650665283
Validation loss: 2.1057103462116693

Epoch: 6| Step: 10
Training loss: 1.6835960149765015
Validation loss: 2.1079803423214982

Epoch: 6| Step: 11
Training loss: 1.563236951828003
Validation loss: 2.1739375745096514

Epoch: 6| Step: 12
Training loss: 1.780095100402832
Validation loss: 2.245086359721358

Epoch: 6| Step: 13
Training loss: 1.6790969371795654
Validation loss: 2.2041443445349254

Epoch: 455| Step: 0
Training loss: 1.761061191558838
Validation loss: 2.2158246142889864

Epoch: 6| Step: 1
Training loss: 1.3774731159210205
Validation loss: 2.1573936554693405

Epoch: 6| Step: 2
Training loss: 1.2252676486968994
Validation loss: 2.152400293657857

Epoch: 6| Step: 3
Training loss: 1.3880962133407593
Validation loss: 2.1248425181194017

Epoch: 6| Step: 4
Training loss: 1.8336166143417358
Validation loss: 2.168960564879961

Epoch: 6| Step: 5
Training loss: 2.144897937774658
Validation loss: 2.1207820651351765

Epoch: 6| Step: 6
Training loss: 1.3487739562988281
Validation loss: 2.1977545266510337

Epoch: 6| Step: 7
Training loss: 1.4326634407043457
Validation loss: 2.1086543708719234

Epoch: 6| Step: 8
Training loss: 1.566220760345459
Validation loss: 2.1732710894717964

Epoch: 6| Step: 9
Training loss: 1.2442052364349365
Validation loss: 2.229657378247989

Epoch: 6| Step: 10
Training loss: 1.2096893787384033
Validation loss: 2.1641557819099835

Epoch: 6| Step: 11
Training loss: 1.7563796043395996
Validation loss: 2.148484327459848

Epoch: 6| Step: 12
Training loss: 2.760672092437744
Validation loss: 2.2119740645090737

Epoch: 6| Step: 13
Training loss: 2.104724884033203
Validation loss: 2.1427157694293606

Epoch: 456| Step: 0
Training loss: 1.2833621501922607
Validation loss: 2.169895795083815

Epoch: 6| Step: 1
Training loss: 1.1565746068954468
Validation loss: 2.177451741310858

Epoch: 6| Step: 2
Training loss: 1.6708250045776367
Validation loss: 2.165079293712493

Epoch: 6| Step: 3
Training loss: 1.3535189628601074
Validation loss: 2.2019624210173085

Epoch: 6| Step: 4
Training loss: 1.1874234676361084
Validation loss: 2.155018050183532

Epoch: 6| Step: 5
Training loss: 2.141672134399414
Validation loss: 2.1246242625738985

Epoch: 6| Step: 6
Training loss: 1.3095897436141968
Validation loss: 2.1829460564480034

Epoch: 6| Step: 7
Training loss: 1.8772763013839722
Validation loss: 2.119709558384393

Epoch: 6| Step: 8
Training loss: 2.0110952854156494
Validation loss: 2.1847220056800434

Epoch: 6| Step: 9
Training loss: 1.334531545639038
Validation loss: 2.146846918649571

Epoch: 6| Step: 10
Training loss: 1.9778881072998047
Validation loss: 2.172412259604341

Epoch: 6| Step: 11
Training loss: 2.030649423599243
Validation loss: 2.142460746149863

Epoch: 6| Step: 12
Training loss: 1.7271628379821777
Validation loss: 2.2308958602207962

Epoch: 6| Step: 13
Training loss: 1.8063284158706665
Validation loss: 2.211904061737881

Epoch: 457| Step: 0
Training loss: 2.0532541275024414
Validation loss: 2.0887417267727595

Epoch: 6| Step: 1
Training loss: 1.049952745437622
Validation loss: 2.133618297115449

Epoch: 6| Step: 2
Training loss: 1.1401021480560303
Validation loss: 2.1642802530719387

Epoch: 6| Step: 3
Training loss: 1.2264232635498047
Validation loss: 2.216574268956338

Epoch: 6| Step: 4
Training loss: 2.7943971157073975
Validation loss: 2.180540910331152

Epoch: 6| Step: 5
Training loss: 2.4080214500427246
Validation loss: 2.1879152585101385

Epoch: 6| Step: 6
Training loss: 1.447359323501587
Validation loss: 2.2102433827615555

Epoch: 6| Step: 7
Training loss: 1.5401248931884766
Validation loss: 2.156508393185113

Epoch: 6| Step: 8
Training loss: 1.423966407775879
Validation loss: 2.2100966771443686

Epoch: 6| Step: 9
Training loss: 1.8549346923828125
Validation loss: 2.2449473770715858

Epoch: 6| Step: 10
Training loss: 1.5304560661315918
Validation loss: 2.2067876759395806

Epoch: 6| Step: 11
Training loss: 1.664827585220337
Validation loss: 2.2712467639676985

Epoch: 6| Step: 12
Training loss: 1.4621174335479736
Validation loss: 2.208547615235852

Epoch: 6| Step: 13
Training loss: 1.2857935428619385
Validation loss: 2.248356391024846

Epoch: 458| Step: 0
Training loss: 1.4478940963745117
Validation loss: 2.2209226072475476

Epoch: 6| Step: 1
Training loss: 1.7507973909378052
Validation loss: 2.131984797857141

Epoch: 6| Step: 2
Training loss: 1.384960651397705
Validation loss: 2.137127204607892

Epoch: 6| Step: 3
Training loss: 2.235546112060547
Validation loss: 2.0859443859387468

Epoch: 6| Step: 4
Training loss: 1.4986367225646973
Validation loss: 2.234883557083786

Epoch: 6| Step: 5
Training loss: 1.7615728378295898
Validation loss: 2.1778921516992713

Epoch: 6| Step: 6
Training loss: 1.7846503257751465
Validation loss: 2.1961448987325034

Epoch: 6| Step: 7
Training loss: 1.6682556867599487
Validation loss: 2.228951915617912

Epoch: 6| Step: 8
Training loss: 1.8950815200805664
Validation loss: 2.1583842308290544

Epoch: 6| Step: 9
Training loss: 1.5256285667419434
Validation loss: 2.1161793534473707

Epoch: 6| Step: 10
Training loss: 1.3072805404663086
Validation loss: 2.1187944976232385

Epoch: 6| Step: 11
Training loss: 1.0687553882598877
Validation loss: 2.1620370264976256

Epoch: 6| Step: 12
Training loss: 1.9169936180114746
Validation loss: 2.137634320925641

Epoch: 6| Step: 13
Training loss: 2.5411274433135986
Validation loss: 2.1168445874285955

Epoch: 459| Step: 0
Training loss: 2.165437698364258
Validation loss: 2.161725016050441

Epoch: 6| Step: 1
Training loss: 1.8304681777954102
Validation loss: 2.2131763824852566

Epoch: 6| Step: 2
Training loss: 1.5108087062835693
Validation loss: 2.149344613475184

Epoch: 6| Step: 3
Training loss: 1.1681036949157715
Validation loss: 2.1587474705070577

Epoch: 6| Step: 4
Training loss: 1.5343255996704102
Validation loss: 2.2489954297260573

Epoch: 6| Step: 5
Training loss: 1.2658674716949463
Validation loss: 2.1645695214630454

Epoch: 6| Step: 6
Training loss: 2.170954704284668
Validation loss: 2.165525900420322

Epoch: 6| Step: 7
Training loss: 1.135817050933838
Validation loss: 2.35475492477417

Epoch: 6| Step: 8
Training loss: 2.0075550079345703
Validation loss: 2.2609875202178955

Epoch: 6| Step: 9
Training loss: 1.8853486776351929
Validation loss: 2.2289612280425204

Epoch: 6| Step: 10
Training loss: 1.8928234577178955
Validation loss: 2.182878207134944

Epoch: 6| Step: 11
Training loss: 1.302695870399475
Validation loss: 2.2167282027582966

Epoch: 6| Step: 12
Training loss: 1.5250191688537598
Validation loss: 2.289181096579439

Epoch: 6| Step: 13
Training loss: 1.6932451725006104
Validation loss: 2.2190479924601894

Epoch: 460| Step: 0
Training loss: 1.5557434558868408
Validation loss: 2.258983104459701

Epoch: 6| Step: 1
Training loss: 2.2024025917053223
Validation loss: 2.1792562418086554

Epoch: 6| Step: 2
Training loss: 1.577113389968872
Validation loss: 2.1848587143805718

Epoch: 6| Step: 3
Training loss: 1.076531171798706
Validation loss: 2.2966436083598802

Epoch: 6| Step: 4
Training loss: 1.7771146297454834
Validation loss: 2.1675244210868754

Epoch: 6| Step: 5
Training loss: 1.879150629043579
Validation loss: 2.2414966373033423

Epoch: 6| Step: 6
Training loss: 1.24949049949646
Validation loss: 2.2582282353472967

Epoch: 6| Step: 7
Training loss: 2.2265186309814453
Validation loss: 2.1898512763361775

Epoch: 6| Step: 8
Training loss: 1.4286980628967285
Validation loss: 2.1975954168586322

Epoch: 6| Step: 9
Training loss: 1.0367751121520996
Validation loss: 2.1755004787957795

Epoch: 6| Step: 10
Training loss: 2.335975170135498
Validation loss: 2.155032229679887

Epoch: 6| Step: 11
Training loss: 1.5878758430480957
Validation loss: 2.3285148041222685

Epoch: 6| Step: 12
Training loss: 1.0009995698928833
Validation loss: 2.2048136470138386

Epoch: 6| Step: 13
Training loss: 1.051981806755066
Validation loss: 2.1661700305118354

Epoch: 461| Step: 0
Training loss: 1.496993899345398
Validation loss: 2.189300371754554

Epoch: 6| Step: 1
Training loss: 1.1837984323501587
Validation loss: 2.2447712011234735

Epoch: 6| Step: 2
Training loss: 2.263465404510498
Validation loss: 2.1452928204690256

Epoch: 6| Step: 3
Training loss: 1.5616008043289185
Validation loss: 2.1279433491409465

Epoch: 6| Step: 4
Training loss: 1.6037237644195557
Validation loss: 2.184420875323716

Epoch: 6| Step: 5
Training loss: 1.8838266134262085
Validation loss: 2.178417549338392

Epoch: 6| Step: 6
Training loss: 1.7827413082122803
Validation loss: 2.179987968937043

Epoch: 6| Step: 7
Training loss: 1.458309292793274
Validation loss: 2.2217021014100764

Epoch: 6| Step: 8
Training loss: 1.7073049545288086
Validation loss: 2.2336277961730957

Epoch: 6| Step: 9
Training loss: 2.193267822265625
Validation loss: 2.1943204761833273

Epoch: 6| Step: 10
Training loss: 1.7345794439315796
Validation loss: 2.1511537131442817

Epoch: 6| Step: 11
Training loss: 1.4747154712677002
Validation loss: 2.0751066746250277

Epoch: 6| Step: 12
Training loss: 1.3950940370559692
Validation loss: 2.1998542765135407

Epoch: 6| Step: 13
Training loss: 1.1126034259796143
Validation loss: 2.1333122612327657

Epoch: 462| Step: 0
Training loss: 1.2873464822769165
Validation loss: 2.0936952560178694

Epoch: 6| Step: 1
Training loss: 1.6414897441864014
Validation loss: 2.219870933922388

Epoch: 6| Step: 2
Training loss: 2.0369949340820312
Validation loss: 2.1264528279663413

Epoch: 6| Step: 3
Training loss: 1.4192087650299072
Validation loss: 2.1746129758896364

Epoch: 6| Step: 4
Training loss: 1.5198416709899902
Validation loss: 2.2262574524007817

Epoch: 6| Step: 5
Training loss: 1.163585901260376
Validation loss: 2.1593355773597636

Epoch: 6| Step: 6
Training loss: 1.4015107154846191
Validation loss: 2.1423880156650337

Epoch: 6| Step: 7
Training loss: 2.518561363220215
Validation loss: 2.165429545987037

Epoch: 6| Step: 8
Training loss: 1.3607741594314575
Validation loss: 2.2443012575949393

Epoch: 6| Step: 9
Training loss: 1.8204147815704346
Validation loss: 2.1406383283676638

Epoch: 6| Step: 10
Training loss: 1.6931997537612915
Validation loss: 2.177076170521398

Epoch: 6| Step: 11
Training loss: 1.8499126434326172
Validation loss: 2.17399577940664

Epoch: 6| Step: 12
Training loss: 1.7409508228302002
Validation loss: 2.26656166456079

Epoch: 6| Step: 13
Training loss: 1.4618430137634277
Validation loss: 2.1334699776864823

Epoch: 463| Step: 0
Training loss: 1.2915364503860474
Validation loss: 2.172346199712446

Epoch: 6| Step: 1
Training loss: 1.4023792743682861
Validation loss: 2.181999406506938

Epoch: 6| Step: 2
Training loss: 1.5920953750610352
Validation loss: 2.1972197563417497

Epoch: 6| Step: 3
Training loss: 2.0457653999328613
Validation loss: 2.2635274946048694

Epoch: 6| Step: 4
Training loss: 1.5970523357391357
Validation loss: 2.202643758507185

Epoch: 6| Step: 5
Training loss: 1.884321689605713
Validation loss: 2.1649927093136694

Epoch: 6| Step: 6
Training loss: 1.8845123052597046
Validation loss: 2.233342794961827

Epoch: 6| Step: 7
Training loss: 1.7779898643493652
Validation loss: 2.187680317509559

Epoch: 6| Step: 8
Training loss: 1.7679616212844849
Validation loss: 2.163246762367987

Epoch: 6| Step: 9
Training loss: 1.3380060195922852
Validation loss: 2.200442757657779

Epoch: 6| Step: 10
Training loss: 1.3677414655685425
Validation loss: 2.153299395756055

Epoch: 6| Step: 11
Training loss: 1.1567926406860352
Validation loss: 2.1611193315957182

Epoch: 6| Step: 12
Training loss: 2.4130659103393555
Validation loss: 2.2409492474730297

Epoch: 6| Step: 13
Training loss: 1.969594120979309
Validation loss: 2.1489149755047214

Epoch: 464| Step: 0
Training loss: 1.7453393936157227
Validation loss: 2.2779533811794814

Epoch: 6| Step: 1
Training loss: 1.6645002365112305
Validation loss: 2.32606961137505

Epoch: 6| Step: 2
Training loss: 1.437291145324707
Validation loss: 2.196064031252297

Epoch: 6| Step: 3
Training loss: 1.2923601865768433
Validation loss: 2.27501077805796

Epoch: 6| Step: 4
Training loss: 1.6739118099212646
Validation loss: 2.1872037610700055

Epoch: 6| Step: 5
Training loss: 1.3180701732635498
Validation loss: 2.1683230220630603

Epoch: 6| Step: 6
Training loss: 1.6981408596038818
Validation loss: 2.199760954867127

Epoch: 6| Step: 7
Training loss: 2.063812255859375
Validation loss: 2.216811039114511

Epoch: 6| Step: 8
Training loss: 1.8783998489379883
Validation loss: 2.1260862260736446

Epoch: 6| Step: 9
Training loss: 1.927869200706482
Validation loss: 2.182557459800474

Epoch: 6| Step: 10
Training loss: 1.485227346420288
Validation loss: 2.1409661026411158

Epoch: 6| Step: 11
Training loss: 1.539107084274292
Validation loss: 2.212787943501626

Epoch: 6| Step: 12
Training loss: 1.4849178791046143
Validation loss: 2.33647398794851

Epoch: 6| Step: 13
Training loss: 1.6115230321884155
Validation loss: 2.1575781632495183

Epoch: 465| Step: 0
Training loss: 1.651174783706665
Validation loss: 2.2396284341812134

Epoch: 6| Step: 1
Training loss: 1.4042584896087646
Validation loss: 2.1741731295021633

Epoch: 6| Step: 2
Training loss: 1.5952503681182861
Validation loss: 2.2268178488618586

Epoch: 6| Step: 3
Training loss: 1.7241051197052002
Validation loss: 2.1529597620810232

Epoch: 6| Step: 4
Training loss: 2.018124580383301
Validation loss: 2.2191629589244886

Epoch: 6| Step: 5
Training loss: 2.2168354988098145
Validation loss: 2.18186512044681

Epoch: 6| Step: 6
Training loss: 1.5462262630462646
Validation loss: 2.1481283121211554

Epoch: 6| Step: 7
Training loss: 1.3568246364593506
Validation loss: 2.137150378637416

Epoch: 6| Step: 8
Training loss: 1.7065227031707764
Validation loss: 2.1919948157443794

Epoch: 6| Step: 9
Training loss: 1.7796159982681274
Validation loss: 2.1737100103850007

Epoch: 6| Step: 10
Training loss: 1.5543088912963867
Validation loss: 2.13843705320871

Epoch: 6| Step: 11
Training loss: 1.1535820960998535
Validation loss: 2.1975655658270723

Epoch: 6| Step: 12
Training loss: 1.382340669631958
Validation loss: 2.1417808173805155

Epoch: 6| Step: 13
Training loss: 1.4870597124099731
Validation loss: 2.188016095469075

Epoch: 466| Step: 0
Training loss: 0.9698843955993652
Validation loss: 2.2715704364161335

Epoch: 6| Step: 1
Training loss: 1.2698132991790771
Validation loss: 2.1517800618243474

Epoch: 6| Step: 2
Training loss: 1.761146068572998
Validation loss: 2.074340051220309

Epoch: 6| Step: 3
Training loss: 1.5283045768737793
Validation loss: 2.171942295566682

Epoch: 6| Step: 4
Training loss: 2.0167436599731445
Validation loss: 2.139141792892128

Epoch: 6| Step: 5
Training loss: 2.090198516845703
Validation loss: 2.136835810958698

Epoch: 6| Step: 6
Training loss: 1.8761168718338013
Validation loss: 2.1664908137372745

Epoch: 6| Step: 7
Training loss: 1.2772831916809082
Validation loss: 2.1821452212590042

Epoch: 6| Step: 8
Training loss: 2.0149056911468506
Validation loss: 2.17784083402285

Epoch: 6| Step: 9
Training loss: 1.4272059202194214
Validation loss: 2.1942798424792547

Epoch: 6| Step: 10
Training loss: 1.7741419076919556
Validation loss: 2.111472693822717

Epoch: 6| Step: 11
Training loss: 1.3791192770004272
Validation loss: 2.134776044917363

Epoch: 6| Step: 12
Training loss: 1.2266249656677246
Validation loss: 2.228543968610866

Epoch: 6| Step: 13
Training loss: 2.217379093170166
Validation loss: 2.2231207611740276

Epoch: 467| Step: 0
Training loss: 1.2892366647720337
Validation loss: 2.1739849736613612

Epoch: 6| Step: 1
Training loss: 1.8447117805480957
Validation loss: 2.2216121112146685

Epoch: 6| Step: 2
Training loss: 1.7898340225219727
Validation loss: 2.19017090207787

Epoch: 6| Step: 3
Training loss: 1.66819429397583
Validation loss: 2.1725438807600286

Epoch: 6| Step: 4
Training loss: 1.5900706052780151
Validation loss: 2.2188398274042274

Epoch: 6| Step: 5
Training loss: 1.8574334383010864
Validation loss: 2.1422317310046126

Epoch: 6| Step: 6
Training loss: 1.1253752708435059
Validation loss: 2.1107200422594623

Epoch: 6| Step: 7
Training loss: 1.961573839187622
Validation loss: 2.242998617951588

Epoch: 6| Step: 8
Training loss: 1.2615344524383545
Validation loss: 2.1342264119014946

Epoch: 6| Step: 9
Training loss: 1.8283472061157227
Validation loss: 2.196263667075865

Epoch: 6| Step: 10
Training loss: 1.342620849609375
Validation loss: 2.0822367386151384

Epoch: 6| Step: 11
Training loss: 1.8074665069580078
Validation loss: 2.114297843748523

Epoch: 6| Step: 12
Training loss: 2.090965509414673
Validation loss: 2.1767608555414344

Epoch: 6| Step: 13
Training loss: 1.754575252532959
Validation loss: 2.1937397603065736

Epoch: 468| Step: 0
Training loss: 1.5904736518859863
Validation loss: 2.155478374932402

Epoch: 6| Step: 1
Training loss: 1.6761075258255005
Validation loss: 2.2129804280496415

Epoch: 6| Step: 2
Training loss: 1.7373440265655518
Validation loss: 2.112464561257311

Epoch: 6| Step: 3
Training loss: 1.4065132141113281
Validation loss: 2.165735754915463

Epoch: 6| Step: 4
Training loss: 1.2280092239379883
Validation loss: 2.1349451388082197

Epoch: 6| Step: 5
Training loss: 1.4082510471343994
Validation loss: 2.1779128877065514

Epoch: 6| Step: 6
Training loss: 2.3492143154144287
Validation loss: 2.1505206195257043

Epoch: 6| Step: 7
Training loss: 1.8015758991241455
Validation loss: 2.131554267739737

Epoch: 6| Step: 8
Training loss: 1.6439478397369385
Validation loss: 2.1973764896392822

Epoch: 6| Step: 9
Training loss: 0.9955207109451294
Validation loss: 2.1608777623022757

Epoch: 6| Step: 10
Training loss: 1.8114843368530273
Validation loss: 2.1875460352948917

Epoch: 6| Step: 11
Training loss: 2.003101348876953
Validation loss: 2.1622085032924527

Epoch: 6| Step: 12
Training loss: 1.4214314222335815
Validation loss: 2.2131879714227494

Epoch: 6| Step: 13
Training loss: 1.753783106803894
Validation loss: 2.217081812120253

Epoch: 469| Step: 0
Training loss: 1.2498441934585571
Validation loss: 2.2216415200182187

Epoch: 6| Step: 1
Training loss: 1.316429853439331
Validation loss: 2.2266839473478255

Epoch: 6| Step: 2
Training loss: 1.2469849586486816
Validation loss: 2.1730731994875017

Epoch: 6| Step: 3
Training loss: 1.9860913753509521
Validation loss: 2.182908711894866

Epoch: 6| Step: 4
Training loss: 1.0987319946289062
Validation loss: 2.1982948369877313

Epoch: 6| Step: 5
Training loss: 1.795921802520752
Validation loss: 2.1238366070614068

Epoch: 6| Step: 6
Training loss: 2.148277759552002
Validation loss: 2.1786077560917025

Epoch: 6| Step: 7
Training loss: 1.949491262435913
Validation loss: 2.162759424537741

Epoch: 6| Step: 8
Training loss: 1.3906923532485962
Validation loss: 2.1887206851795153

Epoch: 6| Step: 9
Training loss: 1.3138539791107178
Validation loss: 2.1521416517996017

Epoch: 6| Step: 10
Training loss: 1.5405552387237549
Validation loss: 2.2375198730858425

Epoch: 6| Step: 11
Training loss: 1.713496446609497
Validation loss: 2.1806474680541665

Epoch: 6| Step: 12
Training loss: 1.4681675434112549
Validation loss: 2.215840590897427

Epoch: 6| Step: 13
Training loss: 2.0873489379882812
Validation loss: 2.143496891503693

Epoch: 470| Step: 0
Training loss: 1.994644045829773
Validation loss: 2.1939465845784833

Epoch: 6| Step: 1
Training loss: 1.992008924484253
Validation loss: 2.175562568890151

Epoch: 6| Step: 2
Training loss: 2.155461311340332
Validation loss: 2.1355809011766986

Epoch: 6| Step: 3
Training loss: 1.4098515510559082
Validation loss: 2.200547827187405

Epoch: 6| Step: 4
Training loss: 1.8883718252182007
Validation loss: 2.1613835186086674

Epoch: 6| Step: 5
Training loss: 1.4874181747436523
Validation loss: 2.267754558593996

Epoch: 6| Step: 6
Training loss: 1.4872918128967285
Validation loss: 2.1189460216029996

Epoch: 6| Step: 7
Training loss: 1.5214054584503174
Validation loss: 2.2040159586937196

Epoch: 6| Step: 8
Training loss: 1.9000580310821533
Validation loss: 2.084657443467007

Epoch: 6| Step: 9
Training loss: 1.3063766956329346
Validation loss: 2.2118676554772163

Epoch: 6| Step: 10
Training loss: 1.562225103378296
Validation loss: 2.17539821645265

Epoch: 6| Step: 11
Training loss: 0.9697924256324768
Validation loss: 2.15664828208185

Epoch: 6| Step: 12
Training loss: 1.5097922086715698
Validation loss: 2.0850398617406047

Epoch: 6| Step: 13
Training loss: 1.5648881196975708
Validation loss: 2.222217257304858

Epoch: 471| Step: 0
Training loss: 1.4386025667190552
Validation loss: 2.1436179927600327

Epoch: 6| Step: 1
Training loss: 1.306021809577942
Validation loss: 2.1575003388107463

Epoch: 6| Step: 2
Training loss: 1.7669596672058105
Validation loss: 2.1899479384063394

Epoch: 6| Step: 3
Training loss: 1.9659078121185303
Validation loss: 2.1938213891880487

Epoch: 6| Step: 4
Training loss: 1.661118984222412
Validation loss: 2.1628604037787325

Epoch: 6| Step: 5
Training loss: 1.7023472785949707
Validation loss: 2.2157841203033284

Epoch: 6| Step: 6
Training loss: 1.7190918922424316
Validation loss: 2.2210931303680583

Epoch: 6| Step: 7
Training loss: 1.268096923828125
Validation loss: 2.1593869270816928

Epoch: 6| Step: 8
Training loss: 1.4429452419281006
Validation loss: 2.117049365915278

Epoch: 6| Step: 9
Training loss: 2.009148597717285
Validation loss: 2.120277294548609

Epoch: 6| Step: 10
Training loss: 1.8353379964828491
Validation loss: 2.2030276252377416

Epoch: 6| Step: 11
Training loss: 1.3783206939697266
Validation loss: 2.178372365172191

Epoch: 6| Step: 12
Training loss: 1.5443599224090576
Validation loss: 2.2302462183019167

Epoch: 6| Step: 13
Training loss: 1.9690721035003662
Validation loss: 2.1859217407882854

Epoch: 472| Step: 0
Training loss: 2.1175901889801025
Validation loss: 2.1523056337910313

Epoch: 6| Step: 1
Training loss: 1.7799999713897705
Validation loss: 2.20993302201712

Epoch: 6| Step: 2
Training loss: 1.7495088577270508
Validation loss: 2.1455672889627437

Epoch: 6| Step: 3
Training loss: 1.4027762413024902
Validation loss: 2.179544605234618

Epoch: 6| Step: 4
Training loss: 1.470674753189087
Validation loss: 2.1992222698785926

Epoch: 6| Step: 5
Training loss: 1.545362949371338
Validation loss: 2.1604877338614514

Epoch: 6| Step: 6
Training loss: 2.0973241329193115
Validation loss: 2.2398853866002892

Epoch: 6| Step: 7
Training loss: 1.192321538925171
Validation loss: 2.112821361070038

Epoch: 6| Step: 8
Training loss: 1.5499433279037476
Validation loss: 2.2338096903216456

Epoch: 6| Step: 9
Training loss: 1.1868467330932617
Validation loss: 2.160218820776991

Epoch: 6| Step: 10
Training loss: 1.4897862672805786
Validation loss: 2.1531986087881108

Epoch: 6| Step: 11
Training loss: 2.2621467113494873
Validation loss: 2.1276736733733967

Epoch: 6| Step: 12
Training loss: 1.6571487188339233
Validation loss: 2.211206557930157

Epoch: 6| Step: 13
Training loss: 1.368390679359436
Validation loss: 2.1241773546382947

Epoch: 473| Step: 0
Training loss: 1.9441986083984375
Validation loss: 2.154485922987743

Epoch: 6| Step: 1
Training loss: 1.2975918054580688
Validation loss: 2.19007448996267

Epoch: 6| Step: 2
Training loss: 1.3157339096069336
Validation loss: 2.1518679011252617

Epoch: 6| Step: 3
Training loss: 1.4087083339691162
Validation loss: 2.180540871876542

Epoch: 6| Step: 4
Training loss: 1.6951104402542114
Validation loss: 2.219873438599289

Epoch: 6| Step: 5
Training loss: 1.2399356365203857
Validation loss: 2.1318108830400693

Epoch: 6| Step: 6
Training loss: 1.1124577522277832
Validation loss: 2.077406526893698

Epoch: 6| Step: 7
Training loss: 2.2469093799591064
Validation loss: 2.081056130829678

Epoch: 6| Step: 8
Training loss: 1.4391565322875977
Validation loss: 2.185850097287086

Epoch: 6| Step: 9
Training loss: 2.1674747467041016
Validation loss: 2.1941333496442406

Epoch: 6| Step: 10
Training loss: 1.485459804534912
Validation loss: 2.1887402765212522

Epoch: 6| Step: 11
Training loss: 1.7217763662338257
Validation loss: 2.106753387758809

Epoch: 6| Step: 12
Training loss: 1.8510268926620483
Validation loss: 2.18085495374536

Epoch: 6| Step: 13
Training loss: 1.946723461151123
Validation loss: 2.1721121752133934

Epoch: 474| Step: 0
Training loss: 1.5509215593338013
Validation loss: 2.1865115678438576

Epoch: 6| Step: 1
Training loss: 0.9615768790245056
Validation loss: 2.1885585118365545

Epoch: 6| Step: 2
Training loss: 1.6484346389770508
Validation loss: 2.1923317755422285

Epoch: 6| Step: 3
Training loss: 1.8137609958648682
Validation loss: 2.1732017071016374

Epoch: 6| Step: 4
Training loss: 1.26693856716156
Validation loss: 2.171098570669851

Epoch: 6| Step: 5
Training loss: 2.0869317054748535
Validation loss: 2.139500935872396

Epoch: 6| Step: 6
Training loss: 1.7006741762161255
Validation loss: 2.250923128538234

Epoch: 6| Step: 7
Training loss: 2.01285457611084
Validation loss: 2.1539911800815212

Epoch: 6| Step: 8
Training loss: 2.1646904945373535
Validation loss: 2.1469569462601856

Epoch: 6| Step: 9
Training loss: 1.9373536109924316
Validation loss: 2.1805860329699773

Epoch: 6| Step: 10
Training loss: 1.0594828128814697
Validation loss: 2.206188976123769

Epoch: 6| Step: 11
Training loss: 2.1307756900787354
Validation loss: 2.105593264743846

Epoch: 6| Step: 12
Training loss: 0.8554925918579102
Validation loss: 2.136837313252111

Epoch: 6| Step: 13
Training loss: 1.3417751789093018
Validation loss: 2.1333870874938143

Epoch: 475| Step: 0
Training loss: 1.6967394351959229
Validation loss: 2.1744678584478234

Epoch: 6| Step: 1
Training loss: 2.6183462142944336
Validation loss: 2.236559614058464

Epoch: 6| Step: 2
Training loss: 2.0211801528930664
Validation loss: 2.2554753108691146

Epoch: 6| Step: 3
Training loss: 1.3544433116912842
Validation loss: 2.105205907616564

Epoch: 6| Step: 4
Training loss: 1.7144360542297363
Validation loss: 2.180463880620977

Epoch: 6| Step: 5
Training loss: 0.9253983497619629
Validation loss: 2.1754270343370337

Epoch: 6| Step: 6
Training loss: 1.950890064239502
Validation loss: 2.201182557690528

Epoch: 6| Step: 7
Training loss: 0.7696774005889893
Validation loss: 2.1637880981609388

Epoch: 6| Step: 8
Training loss: 1.529770851135254
Validation loss: 2.108122318021713

Epoch: 6| Step: 9
Training loss: 0.9438928961753845
Validation loss: 2.1251916603375505

Epoch: 6| Step: 10
Training loss: 1.2970552444458008
Validation loss: 2.1014342192680604

Epoch: 6| Step: 11
Training loss: 1.251552939414978
Validation loss: 2.1436180530055875

Epoch: 6| Step: 12
Training loss: 2.406663656234741
Validation loss: 2.2279015382130942

Epoch: 6| Step: 13
Training loss: 1.931650996208191
Validation loss: 2.1862307620304886

Epoch: 476| Step: 0
Training loss: 1.205440640449524
Validation loss: 2.192733887703188

Epoch: 6| Step: 1
Training loss: 1.6000938415527344
Validation loss: 2.256209965675108

Epoch: 6| Step: 2
Training loss: 1.4570980072021484
Validation loss: 2.09724743904606

Epoch: 6| Step: 3
Training loss: 2.060671329498291
Validation loss: 2.1383971065603276

Epoch: 6| Step: 4
Training loss: 1.0930209159851074
Validation loss: 2.1486506000641854

Epoch: 6| Step: 5
Training loss: 1.5162842273712158
Validation loss: 2.0846094649325133

Epoch: 6| Step: 6
Training loss: 1.5840466022491455
Validation loss: 2.115135952990542

Epoch: 6| Step: 7
Training loss: 1.8746705055236816
Validation loss: 2.1578490708463933

Epoch: 6| Step: 8
Training loss: 1.2392734289169312
Validation loss: 2.176834146181742

Epoch: 6| Step: 9
Training loss: 1.9209182262420654
Validation loss: 2.2114691657404744

Epoch: 6| Step: 10
Training loss: 1.101257562637329
Validation loss: 2.0812248824745097

Epoch: 6| Step: 11
Training loss: 2.275047779083252
Validation loss: 2.1422010608898696

Epoch: 6| Step: 12
Training loss: 1.6184293031692505
Validation loss: 2.1522820970063568

Epoch: 6| Step: 13
Training loss: 1.4882705211639404
Validation loss: 2.114175732417773

Epoch: 477| Step: 0
Training loss: 1.6601930856704712
Validation loss: 2.114086381850704

Epoch: 6| Step: 1
Training loss: 1.7786537408828735
Validation loss: 2.274365440491707

Epoch: 6| Step: 2
Training loss: 1.713884711265564
Validation loss: 2.200746044035881

Epoch: 6| Step: 3
Training loss: 1.5465385913848877
Validation loss: 2.1379977041675198

Epoch: 6| Step: 4
Training loss: 1.346091628074646
Validation loss: 2.188087245469452

Epoch: 6| Step: 5
Training loss: 1.4021506309509277
Validation loss: 2.169413605043965

Epoch: 6| Step: 6
Training loss: 1.2692534923553467
Validation loss: 2.183551655020765

Epoch: 6| Step: 7
Training loss: 2.3187294006347656
Validation loss: 2.2135648496689333

Epoch: 6| Step: 8
Training loss: 1.5442938804626465
Validation loss: 2.106543310226933

Epoch: 6| Step: 9
Training loss: 1.4737765789031982
Validation loss: 2.230596157812303

Epoch: 6| Step: 10
Training loss: 1.598813533782959
Validation loss: 2.112369477107961

Epoch: 6| Step: 11
Training loss: 1.8668876886367798
Validation loss: 2.2183483159670265

Epoch: 6| Step: 12
Training loss: 1.6923836469650269
Validation loss: 2.2173359804255988

Epoch: 6| Step: 13
Training loss: 1.2522871494293213
Validation loss: 2.0957597468488958

Epoch: 478| Step: 0
Training loss: 1.2357522249221802
Validation loss: 2.1351493199666343

Epoch: 6| Step: 1
Training loss: 1.8737692832946777
Validation loss: 2.1552316475940008

Epoch: 6| Step: 2
Training loss: 1.3227810859680176
Validation loss: 2.168625670094644

Epoch: 6| Step: 3
Training loss: 2.4597296714782715
Validation loss: 2.184740839465972

Epoch: 6| Step: 4
Training loss: 1.5799293518066406
Validation loss: 2.206959011734173

Epoch: 6| Step: 5
Training loss: 1.8183671236038208
Validation loss: 2.171385319002213

Epoch: 6| Step: 6
Training loss: 1.7249951362609863
Validation loss: 2.094806913406618

Epoch: 6| Step: 7
Training loss: 2.0440850257873535
Validation loss: 2.14549700162744

Epoch: 6| Step: 8
Training loss: 1.6594676971435547
Validation loss: 2.1996130276751775

Epoch: 6| Step: 9
Training loss: 1.2185425758361816
Validation loss: 2.210668243387694

Epoch: 6| Step: 10
Training loss: 1.2376255989074707
Validation loss: 2.153991840218985

Epoch: 6| Step: 11
Training loss: 1.4679654836654663
Validation loss: 2.1654347604320896

Epoch: 6| Step: 12
Training loss: 2.163097381591797
Validation loss: 2.1479257947655133

Epoch: 6| Step: 13
Training loss: 1.1298986673355103
Validation loss: 2.182380440414593

Epoch: 479| Step: 0
Training loss: 2.147315502166748
Validation loss: 2.1948392673205306

Epoch: 6| Step: 1
Training loss: 1.810765266418457
Validation loss: 2.2095667931341354

Epoch: 6| Step: 2
Training loss: 1.3099656105041504
Validation loss: 2.2604787272791707

Epoch: 6| Step: 3
Training loss: 1.3697401285171509
Validation loss: 2.168767018984723

Epoch: 6| Step: 4
Training loss: 1.6364691257476807
Validation loss: 2.174040917427309

Epoch: 6| Step: 5
Training loss: 1.8225178718566895
Validation loss: 2.216555853043833

Epoch: 6| Step: 6
Training loss: 1.5051164627075195
Validation loss: 2.2092909120744273

Epoch: 6| Step: 7
Training loss: 2.18369460105896
Validation loss: 2.2366084847398984

Epoch: 6| Step: 8
Training loss: 1.3546080589294434
Validation loss: 2.16653879996269

Epoch: 6| Step: 9
Training loss: 1.234933614730835
Validation loss: 2.1878464016863095

Epoch: 6| Step: 10
Training loss: 1.6191881895065308
Validation loss: 2.1978255574421217

Epoch: 6| Step: 11
Training loss: 1.262528657913208
Validation loss: 2.174030944865237

Epoch: 6| Step: 12
Training loss: 1.2482972145080566
Validation loss: 2.1421330026400986

Epoch: 6| Step: 13
Training loss: 1.823397159576416
Validation loss: 2.2285444736480713

Epoch: 480| Step: 0
Training loss: 1.2116190195083618
Validation loss: 2.188381484759751

Epoch: 6| Step: 1
Training loss: 1.058169960975647
Validation loss: 2.1506038917008268

Epoch: 6| Step: 2
Training loss: 2.5042011737823486
Validation loss: 2.1449978223410984

Epoch: 6| Step: 3
Training loss: 1.5741931200027466
Validation loss: 2.1247062426741405

Epoch: 6| Step: 4
Training loss: 1.7563258409500122
Validation loss: 2.1297867195580595

Epoch: 6| Step: 5
Training loss: 1.8373754024505615
Validation loss: 2.2113110916588896

Epoch: 6| Step: 6
Training loss: 1.6344014406204224
Validation loss: 2.1707083986651514

Epoch: 6| Step: 7
Training loss: 1.6894443035125732
Validation loss: 2.1720330945907103

Epoch: 6| Step: 8
Training loss: 1.239858865737915
Validation loss: 2.1583769911079

Epoch: 6| Step: 9
Training loss: 1.5346412658691406
Validation loss: 2.157126647169872

Epoch: 6| Step: 10
Training loss: 2.002354145050049
Validation loss: 2.169667966904179

Epoch: 6| Step: 11
Training loss: 1.686478853225708
Validation loss: 2.143090150689566

Epoch: 6| Step: 12
Training loss: 1.2626502513885498
Validation loss: 2.229589481507578

Epoch: 6| Step: 13
Training loss: 1.4241433143615723
Validation loss: 2.117565965139738

Epoch: 481| Step: 0
Training loss: 1.3051033020019531
Validation loss: 2.1623371237067768

Epoch: 6| Step: 1
Training loss: 1.827052116394043
Validation loss: 2.163630408625449

Epoch: 6| Step: 2
Training loss: 1.6542444229125977
Validation loss: 2.1771675079099593

Epoch: 6| Step: 3
Training loss: 1.9279381036758423
Validation loss: 2.2722932446387505

Epoch: 6| Step: 4
Training loss: 1.8719382286071777
Validation loss: 2.203144395223228

Epoch: 6| Step: 5
Training loss: 1.7864370346069336
Validation loss: 2.2092329507232993

Epoch: 6| Step: 6
Training loss: 1.2108612060546875
Validation loss: 2.2033920236813125

Epoch: 6| Step: 7
Training loss: 1.989768624305725
Validation loss: 2.1919805478024226

Epoch: 6| Step: 8
Training loss: 1.4678363800048828
Validation loss: 2.0981866287928757

Epoch: 6| Step: 9
Training loss: 1.6786322593688965
Validation loss: 2.1262628083587973

Epoch: 6| Step: 10
Training loss: 1.476921796798706
Validation loss: 2.145268460755707

Epoch: 6| Step: 11
Training loss: 1.168544054031372
Validation loss: 2.1355216682598157

Epoch: 6| Step: 12
Training loss: 1.6906800270080566
Validation loss: 2.2098004587234987

Epoch: 6| Step: 13
Training loss: 1.418115258216858
Validation loss: 2.1837038378561697

Epoch: 482| Step: 0
Training loss: 1.7484288215637207
Validation loss: 2.1684180844214653

Epoch: 6| Step: 1
Training loss: 1.2935504913330078
Validation loss: 2.203202957748085

Epoch: 6| Step: 2
Training loss: 1.4791758060455322
Validation loss: 2.161806465477072

Epoch: 6| Step: 3
Training loss: 1.7710137367248535
Validation loss: 2.1377285949645506

Epoch: 6| Step: 4
Training loss: 1.1080808639526367
Validation loss: 2.1800465455619236

Epoch: 6| Step: 5
Training loss: 1.6913853883743286
Validation loss: 2.2048165029095066

Epoch: 6| Step: 6
Training loss: 2.2037339210510254
Validation loss: 2.1711502152104534

Epoch: 6| Step: 7
Training loss: 1.7679179906845093
Validation loss: 2.2056266479594733

Epoch: 6| Step: 8
Training loss: 1.353772521018982
Validation loss: 2.1486330147712462

Epoch: 6| Step: 9
Training loss: 1.3192452192306519
Validation loss: 2.143039687987297

Epoch: 6| Step: 10
Training loss: 2.1721370220184326
Validation loss: 2.1595735985745668

Epoch: 6| Step: 11
Training loss: 1.4836626052856445
Validation loss: 2.151537113292243

Epoch: 6| Step: 12
Training loss: 1.7691006660461426
Validation loss: 2.1488013857154438

Epoch: 6| Step: 13
Training loss: 1.2305471897125244
Validation loss: 2.2380709904496388

Epoch: 483| Step: 0
Training loss: 1.4857091903686523
Validation loss: 2.1899479025153705

Epoch: 6| Step: 1
Training loss: 2.606688976287842
Validation loss: 2.161421509199245

Epoch: 6| Step: 2
Training loss: 2.262735366821289
Validation loss: 2.188648772496049

Epoch: 6| Step: 3
Training loss: 1.6534101963043213
Validation loss: 2.254374252852573

Epoch: 6| Step: 4
Training loss: 0.8203091025352478
Validation loss: 2.256161227021166

Epoch: 6| Step: 5
Training loss: 1.2359590530395508
Validation loss: 2.2418428544075257

Epoch: 6| Step: 6
Training loss: 1.8443282842636108
Validation loss: 2.2389306740094255

Epoch: 6| Step: 7
Training loss: 1.0957348346710205
Validation loss: 2.1673305726820424

Epoch: 6| Step: 8
Training loss: 1.44562828540802
Validation loss: 2.15104845775071

Epoch: 6| Step: 9
Training loss: 1.7569183111190796
Validation loss: 2.1112497237420853

Epoch: 6| Step: 10
Training loss: 1.7117509841918945
Validation loss: 2.1605957297868628

Epoch: 6| Step: 11
Training loss: 1.4894471168518066
Validation loss: 2.171446598986144

Epoch: 6| Step: 12
Training loss: 1.8943676948547363
Validation loss: 2.137729679384539

Epoch: 6| Step: 13
Training loss: 1.4191548824310303
Validation loss: 2.2004702373217513

Epoch: 484| Step: 0
Training loss: 1.2785029411315918
Validation loss: 2.1770624704258417

Epoch: 6| Step: 1
Training loss: 1.3364136219024658
Validation loss: 2.1018593759946924

Epoch: 6| Step: 2
Training loss: 1.286359429359436
Validation loss: 2.17039829684842

Epoch: 6| Step: 3
Training loss: 1.5679597854614258
Validation loss: 2.1715253835083335

Epoch: 6| Step: 4
Training loss: 1.7906532287597656
Validation loss: 2.0622655230183757

Epoch: 6| Step: 5
Training loss: 2.506838321685791
Validation loss: 2.1700943285419094

Epoch: 6| Step: 6
Training loss: 1.6681134700775146
Validation loss: 2.24031800095753

Epoch: 6| Step: 7
Training loss: 2.0535271167755127
Validation loss: 2.210055487130278

Epoch: 6| Step: 8
Training loss: 1.832502007484436
Validation loss: 2.1535862133067143

Epoch: 6| Step: 9
Training loss: 1.207444190979004
Validation loss: 2.2211692563949095

Epoch: 6| Step: 10
Training loss: 1.2492156028747559
Validation loss: 2.129471509687362

Epoch: 6| Step: 11
Training loss: 1.9400995969772339
Validation loss: 2.234838283190163

Epoch: 6| Step: 12
Training loss: 1.9913444519042969
Validation loss: 2.1654699002542803

Epoch: 6| Step: 13
Training loss: 0.800055980682373
Validation loss: 2.2008150085326164

Epoch: 485| Step: 0
Training loss: 1.7740156650543213
Validation loss: 2.160270264071803

Epoch: 6| Step: 1
Training loss: 2.141369581222534
Validation loss: 2.1609963114543627

Epoch: 6| Step: 2
Training loss: 1.217354655265808
Validation loss: 2.239471721392806

Epoch: 6| Step: 3
Training loss: 1.7132927179336548
Validation loss: 2.100421625439839

Epoch: 6| Step: 4
Training loss: 1.5932124853134155
Validation loss: 2.121031330477807

Epoch: 6| Step: 5
Training loss: 1.330885410308838
Validation loss: 2.146541909504962

Epoch: 6| Step: 6
Training loss: 1.5522477626800537
Validation loss: 2.1414018664308774

Epoch: 6| Step: 7
Training loss: 1.8419480323791504
Validation loss: 2.156232841553227

Epoch: 6| Step: 8
Training loss: 1.7043699026107788
Validation loss: 2.156230652204124

Epoch: 6| Step: 9
Training loss: 0.9255602359771729
Validation loss: 2.2029640879682315

Epoch: 6| Step: 10
Training loss: 1.0557103157043457
Validation loss: 2.2496989542438137

Epoch: 6| Step: 11
Training loss: 1.6262826919555664
Validation loss: 2.232401596602573

Epoch: 6| Step: 12
Training loss: 1.9400720596313477
Validation loss: 2.1977070403355423

Epoch: 6| Step: 13
Training loss: 1.4134303331375122
Validation loss: 2.1123086739611883

Epoch: 486| Step: 0
Training loss: 1.178002119064331
Validation loss: 2.1607130445459837

Epoch: 6| Step: 1
Training loss: 2.000183582305908
Validation loss: 2.206669174214845

Epoch: 6| Step: 2
Training loss: 1.5996239185333252
Validation loss: 2.170323407778176

Epoch: 6| Step: 3
Training loss: 1.637081503868103
Validation loss: 2.222081353587489

Epoch: 6| Step: 4
Training loss: 2.0920169353485107
Validation loss: 2.1898353369005266

Epoch: 6| Step: 5
Training loss: 1.6279271841049194
Validation loss: 2.139656982114238

Epoch: 6| Step: 6
Training loss: 1.4846936464309692
Validation loss: 2.1391688687826997

Epoch: 6| Step: 7
Training loss: 1.6750255823135376
Validation loss: 2.2134288049513295

Epoch: 6| Step: 8
Training loss: 1.57255220413208
Validation loss: 2.127005172032182

Epoch: 6| Step: 9
Training loss: 1.2199013233184814
Validation loss: 2.1336712016854236

Epoch: 6| Step: 10
Training loss: 1.2511024475097656
Validation loss: 2.1589324141061432

Epoch: 6| Step: 11
Training loss: 1.6485224962234497
Validation loss: 2.123152989213185

Epoch: 6| Step: 12
Training loss: 1.4001660346984863
Validation loss: 2.1100546172870103

Epoch: 6| Step: 13
Training loss: 2.8353521823883057
Validation loss: 2.1999615828196206

Epoch: 487| Step: 0
Training loss: 1.5255333185195923
Validation loss: 2.203394361721572

Epoch: 6| Step: 1
Training loss: 1.9312798976898193
Validation loss: 2.0843045621789913

Epoch: 6| Step: 2
Training loss: 1.777860403060913
Validation loss: 2.210858101485878

Epoch: 6| Step: 3
Training loss: 1.750800371170044
Validation loss: 2.2062843076644407

Epoch: 6| Step: 4
Training loss: 1.9051868915557861
Validation loss: 2.1672579934520106

Epoch: 6| Step: 5
Training loss: 1.637628197669983
Validation loss: 2.246649307589377

Epoch: 6| Step: 6
Training loss: 1.8020362854003906
Validation loss: 2.124452393542054

Epoch: 6| Step: 7
Training loss: 1.2416424751281738
Validation loss: 2.2008123961828088

Epoch: 6| Step: 8
Training loss: 1.451169729232788
Validation loss: 2.1882102758653703

Epoch: 6| Step: 9
Training loss: 1.8988306522369385
Validation loss: 2.1381130731233986

Epoch: 6| Step: 10
Training loss: 1.1017224788665771
Validation loss: 2.1877500369984615

Epoch: 6| Step: 11
Training loss: 1.8612734079360962
Validation loss: 2.2017076092381633

Epoch: 6| Step: 12
Training loss: 0.9295946359634399
Validation loss: 2.1538751561154603

Epoch: 6| Step: 13
Training loss: 1.3602527379989624
Validation loss: 2.172391181351036

Epoch: 488| Step: 0
Training loss: 1.0269200801849365
Validation loss: 2.1338770274193055

Epoch: 6| Step: 1
Training loss: 1.261078119277954
Validation loss: 2.180116697024274

Epoch: 6| Step: 2
Training loss: 2.3820478916168213
Validation loss: 2.106242004261222

Epoch: 6| Step: 3
Training loss: 1.850597620010376
Validation loss: 2.139048845537247

Epoch: 6| Step: 4
Training loss: 1.130359411239624
Validation loss: 2.1335984994006414

Epoch: 6| Step: 5
Training loss: 2.0125350952148438
Validation loss: 2.156119454291559

Epoch: 6| Step: 6
Training loss: 1.7960489988327026
Validation loss: 2.214091275327949

Epoch: 6| Step: 7
Training loss: 1.9325093030929565
Validation loss: 2.187401997145786

Epoch: 6| Step: 8
Training loss: 1.718801736831665
Validation loss: 2.1415855320551063

Epoch: 6| Step: 9
Training loss: 1.8670696020126343
Validation loss: 2.110628125488117

Epoch: 6| Step: 10
Training loss: 1.6369248628616333
Validation loss: 2.1737381309591313

Epoch: 6| Step: 11
Training loss: 1.2147897481918335
Validation loss: 2.2631544067013647

Epoch: 6| Step: 12
Training loss: 1.6700940132141113
Validation loss: 2.1277769842455463

Epoch: 6| Step: 13
Training loss: 2.1207115650177
Validation loss: 2.2058648832382692

Epoch: 489| Step: 0
Training loss: 1.639638066291809
Validation loss: 2.184851896378302

Epoch: 6| Step: 1
Training loss: 1.2088308334350586
Validation loss: 2.2266370160605318

Epoch: 6| Step: 2
Training loss: 1.4308322668075562
Validation loss: 2.1999576155857374

Epoch: 6| Step: 3
Training loss: 1.8171842098236084
Validation loss: 2.1684656322643323

Epoch: 6| Step: 4
Training loss: 0.8280543684959412
Validation loss: 2.2516842170428206

Epoch: 6| Step: 5
Training loss: 1.7862682342529297
Validation loss: 2.303175894162988

Epoch: 6| Step: 6
Training loss: 2.386488914489746
Validation loss: 2.282419434157751

Epoch: 6| Step: 7
Training loss: 1.4637558460235596
Validation loss: 2.3510329492630495

Epoch: 6| Step: 8
Training loss: 2.0491089820861816
Validation loss: 2.311598400915823

Epoch: 6| Step: 9
Training loss: 2.3444225788116455
Validation loss: 2.289068527119134

Epoch: 6| Step: 10
Training loss: 1.4633967876434326
Validation loss: 2.2650258259106706

Epoch: 6| Step: 11
Training loss: 2.06201171875
Validation loss: 2.2811793127367572

Epoch: 6| Step: 12
Training loss: 1.3883267641067505
Validation loss: 2.258412020180815

Epoch: 6| Step: 13
Training loss: 1.1112070083618164
Validation loss: 2.1988341782682683

Epoch: 490| Step: 0
Training loss: 1.2914924621582031
Validation loss: 2.22687465401106

Epoch: 6| Step: 1
Training loss: 0.9667766094207764
Validation loss: 2.150464821887273

Epoch: 6| Step: 2
Training loss: 2.3295795917510986
Validation loss: 2.2304536117020475

Epoch: 6| Step: 3
Training loss: 1.3364390134811401
Validation loss: 2.164852157715828

Epoch: 6| Step: 4
Training loss: 1.6981606483459473
Validation loss: 2.1446050226047473

Epoch: 6| Step: 5
Training loss: 1.4596400260925293
Validation loss: 2.1385116500239216

Epoch: 6| Step: 6
Training loss: 1.8255952596664429
Validation loss: 2.187886634180623

Epoch: 6| Step: 7
Training loss: 1.1683142185211182
Validation loss: 2.174922823905945

Epoch: 6| Step: 8
Training loss: 1.6746975183486938
Validation loss: 2.0970328853976343

Epoch: 6| Step: 9
Training loss: 1.5116560459136963
Validation loss: 2.2080169313697406

Epoch: 6| Step: 10
Training loss: 2.160130023956299
Validation loss: 2.172183367513841

Epoch: 6| Step: 11
Training loss: 1.87965989112854
Validation loss: 2.2282647932729414

Epoch: 6| Step: 12
Training loss: 1.5304189920425415
Validation loss: 2.1815546968931794

Epoch: 6| Step: 13
Training loss: 1.7985466718673706
Validation loss: 2.2109742600430726

Epoch: 491| Step: 0
Training loss: 1.1746643781661987
Validation loss: 2.1736578941345215

Epoch: 6| Step: 1
Training loss: 1.794825792312622
Validation loss: 2.201419150957497

Epoch: 6| Step: 2
Training loss: 2.1411685943603516
Validation loss: 2.214176603542861

Epoch: 6| Step: 3
Training loss: 1.497424840927124
Validation loss: 2.2108215926795878

Epoch: 6| Step: 4
Training loss: 1.631245493888855
Validation loss: 2.114014123075752

Epoch: 6| Step: 5
Training loss: 2.1988577842712402
Validation loss: 2.197733207415509

Epoch: 6| Step: 6
Training loss: 1.2356252670288086
Validation loss: 2.2544250001189527

Epoch: 6| Step: 7
Training loss: 1.675213098526001
Validation loss: 2.1668800833404704

Epoch: 6| Step: 8
Training loss: 0.9571431279182434
Validation loss: 2.177707561882593

Epoch: 6| Step: 9
Training loss: 1.3764418363571167
Validation loss: 2.2108550404989593

Epoch: 6| Step: 10
Training loss: 1.1811131238937378
Validation loss: 2.2184629235216367

Epoch: 6| Step: 11
Training loss: 1.698033094406128
Validation loss: 2.251916634139194

Epoch: 6| Step: 12
Training loss: 2.2825684547424316
Validation loss: 2.246026642860905

Epoch: 6| Step: 13
Training loss: 2.0309839248657227
Validation loss: 2.2000880574667327

Epoch: 492| Step: 0
Training loss: 1.709108829498291
Validation loss: 2.1914049374159945

Epoch: 6| Step: 1
Training loss: 1.0227925777435303
Validation loss: 2.2673159286540043

Epoch: 6| Step: 2
Training loss: 2.427827835083008
Validation loss: 2.215479184222478

Epoch: 6| Step: 3
Training loss: 1.183013916015625
Validation loss: 2.1394332121777278

Epoch: 6| Step: 4
Training loss: 1.5779759883880615
Validation loss: 2.182542772703273

Epoch: 6| Step: 5
Training loss: 1.642767071723938
Validation loss: 2.193156829444311

Epoch: 6| Step: 6
Training loss: 1.7039225101470947
Validation loss: 2.1971983883970525

Epoch: 6| Step: 7
Training loss: 2.2600626945495605
Validation loss: 2.145681283807242

Epoch: 6| Step: 8
Training loss: 1.538211703300476
Validation loss: 2.120979755155502

Epoch: 6| Step: 9
Training loss: 1.7703967094421387
Validation loss: 2.1546619181991904

Epoch: 6| Step: 10
Training loss: 1.8354015350341797
Validation loss: 2.1765247903844362

Epoch: 6| Step: 11
Training loss: 1.3615138530731201
Validation loss: 2.206381338898854

Epoch: 6| Step: 12
Training loss: 1.0931520462036133
Validation loss: 2.1358575077467066

Epoch: 6| Step: 13
Training loss: 1.9510623216629028
Validation loss: 2.1809924725563294

Epoch: 493| Step: 0
Training loss: 1.4755220413208008
Validation loss: 2.253040998212753

Epoch: 6| Step: 1
Training loss: 1.3143081665039062
Validation loss: 2.1393250880702848

Epoch: 6| Step: 2
Training loss: 1.5372071266174316
Validation loss: 2.2090961446044264

Epoch: 6| Step: 3
Training loss: 1.3514955043792725
Validation loss: 2.0987539727200746

Epoch: 6| Step: 4
Training loss: 1.6227917671203613
Validation loss: 2.1452165688237836

Epoch: 6| Step: 5
Training loss: 2.151947498321533
Validation loss: 2.148192944065217

Epoch: 6| Step: 6
Training loss: 1.8207521438598633
Validation loss: 2.192363979995892

Epoch: 6| Step: 7
Training loss: 0.936486005783081
Validation loss: 2.210249726490308

Epoch: 6| Step: 8
Training loss: 1.2196769714355469
Validation loss: 2.147655754960993

Epoch: 6| Step: 9
Training loss: 1.6940184831619263
Validation loss: 2.208650417225335

Epoch: 6| Step: 10
Training loss: 1.5688955783843994
Validation loss: 2.2408419450124106

Epoch: 6| Step: 11
Training loss: 1.470684289932251
Validation loss: 2.1545789216154363

Epoch: 6| Step: 12
Training loss: 1.697852373123169
Validation loss: 2.1933365355255785

Epoch: 6| Step: 13
Training loss: 1.7823892831802368
Validation loss: 2.168829579507151

Epoch: 494| Step: 0
Training loss: 1.545320749282837
Validation loss: 2.1424824806951706

Epoch: 6| Step: 1
Training loss: 2.510429859161377
Validation loss: 2.2613324555017615

Epoch: 6| Step: 2
Training loss: 1.857475757598877
Validation loss: 2.1958633238269436

Epoch: 6| Step: 3
Training loss: 2.032362222671509
Validation loss: 2.2100601452653126

Epoch: 6| Step: 4
Training loss: 1.1173056364059448
Validation loss: 2.1912013792222544

Epoch: 6| Step: 5
Training loss: 1.333742380142212
Validation loss: 2.2663733754106747

Epoch: 6| Step: 6
Training loss: 0.9627291560173035
Validation loss: 2.2011392219092256

Epoch: 6| Step: 7
Training loss: 1.6493099927902222
Validation loss: 2.1838783679469937

Epoch: 6| Step: 8
Training loss: 1.7573280334472656
Validation loss: 2.22436959000044

Epoch: 6| Step: 9
Training loss: 1.4445624351501465
Validation loss: 2.163875696479633

Epoch: 6| Step: 10
Training loss: 1.3453662395477295
Validation loss: 2.193889558956187

Epoch: 6| Step: 11
Training loss: 1.7042651176452637
Validation loss: 2.2063717252464703

Epoch: 6| Step: 12
Training loss: 1.53922700881958
Validation loss: 2.1926100971878215

Epoch: 6| Step: 13
Training loss: 1.5943812131881714
Validation loss: 2.231741864194152

Epoch: 495| Step: 0
Training loss: 1.684431552886963
Validation loss: 2.127399648389509

Epoch: 6| Step: 1
Training loss: 1.693346619606018
Validation loss: 2.1303296204536193

Epoch: 6| Step: 2
Training loss: 1.7056523561477661
Validation loss: 2.136064875510431

Epoch: 6| Step: 3
Training loss: 2.2542924880981445
Validation loss: 2.2004580959197013

Epoch: 6| Step: 4
Training loss: 1.608914852142334
Validation loss: 2.216629974303707

Epoch: 6| Step: 5
Training loss: 0.8983198404312134
Validation loss: 2.1191420144932245

Epoch: 6| Step: 6
Training loss: 1.4791964292526245
Validation loss: 2.096918413715978

Epoch: 6| Step: 7
Training loss: 1.8388937711715698
Validation loss: 2.1525586176944036

Epoch: 6| Step: 8
Training loss: 1.2365710735321045
Validation loss: 2.190793211742114

Epoch: 6| Step: 9
Training loss: 1.3389331102371216
Validation loss: 2.2109979647462086

Epoch: 6| Step: 10
Training loss: 1.5730432271957397
Validation loss: 2.142053128570639

Epoch: 6| Step: 11
Training loss: 1.5942213535308838
Validation loss: 2.1602987922647947

Epoch: 6| Step: 12
Training loss: 1.1817783117294312
Validation loss: 2.2174648033675326

Epoch: 6| Step: 13
Training loss: 1.899864673614502
Validation loss: 2.1395171073175248

Epoch: 496| Step: 0
Training loss: 1.2766554355621338
Validation loss: 2.2333630284955426

Epoch: 6| Step: 1
Training loss: 2.111527442932129
Validation loss: 2.1675836732310634

Epoch: 6| Step: 2
Training loss: 1.7868032455444336
Validation loss: 2.173646741015937

Epoch: 6| Step: 3
Training loss: 1.1580474376678467
Validation loss: 2.099919262752738

Epoch: 6| Step: 4
Training loss: 1.289888620376587
Validation loss: 2.1727149076359247

Epoch: 6| Step: 5
Training loss: 1.720916986465454
Validation loss: 2.1072443467314526

Epoch: 6| Step: 6
Training loss: 1.691892147064209
Validation loss: 2.143700876543599

Epoch: 6| Step: 7
Training loss: 2.177733898162842
Validation loss: 2.1426016053845807

Epoch: 6| Step: 8
Training loss: 0.9075174331665039
Validation loss: 2.1879191603711856

Epoch: 6| Step: 9
Training loss: 1.971563696861267
Validation loss: 2.157900151386056

Epoch: 6| Step: 10
Training loss: 1.9272456169128418
Validation loss: 2.15683554321207

Epoch: 6| Step: 11
Training loss: 1.4293909072875977
Validation loss: 2.193171270432011

Epoch: 6| Step: 12
Training loss: 1.781984806060791
Validation loss: 2.17960948072454

Epoch: 6| Step: 13
Training loss: 1.3015331029891968
Validation loss: 2.2317166251520955

Epoch: 497| Step: 0
Training loss: 1.6398420333862305
Validation loss: 2.168361694582047

Epoch: 6| Step: 1
Training loss: 0.9234778881072998
Validation loss: 2.1802684055861605

Epoch: 6| Step: 2
Training loss: 1.269322156906128
Validation loss: 2.256672433627549

Epoch: 6| Step: 3
Training loss: 1.8465954065322876
Validation loss: 2.233428947387203

Epoch: 6| Step: 4
Training loss: 2.095813512802124
Validation loss: 2.173541194649153

Epoch: 6| Step: 5
Training loss: 1.8491430282592773
Validation loss: 2.2538684850097983

Epoch: 6| Step: 6
Training loss: 1.7366173267364502
Validation loss: 2.23108281307323

Epoch: 6| Step: 7
Training loss: 0.9920250773429871
Validation loss: 2.163140986555366

Epoch: 6| Step: 8
Training loss: 1.4857497215270996
Validation loss: 2.2241968275398336

Epoch: 6| Step: 9
Training loss: 1.5513848066329956
Validation loss: 2.1625668874350925

Epoch: 6| Step: 10
Training loss: 1.4320483207702637
Validation loss: 2.151633201106902

Epoch: 6| Step: 11
Training loss: 1.696485161781311
Validation loss: 2.196112286659979

Epoch: 6| Step: 12
Training loss: 2.4590535163879395
Validation loss: 2.1608798914058234

Epoch: 6| Step: 13
Training loss: 1.7816696166992188
Validation loss: 2.2715808422334733

Epoch: 498| Step: 0
Training loss: 0.8769398331642151
Validation loss: 2.1565513175020934

Epoch: 6| Step: 1
Training loss: 1.9513030052185059
Validation loss: 2.1645382373563704

Epoch: 6| Step: 2
Training loss: 1.2701853513717651
Validation loss: 2.156853311805315

Epoch: 6| Step: 3
Training loss: 1.3389205932617188
Validation loss: 2.210301376158191

Epoch: 6| Step: 4
Training loss: 1.743924617767334
Validation loss: 2.206424099142833

Epoch: 6| Step: 5
Training loss: 1.9377623796463013
Validation loss: 2.166001231439652

Epoch: 6| Step: 6
Training loss: 1.4957964420318604
Validation loss: 2.185127058336812

Epoch: 6| Step: 7
Training loss: 1.3103958368301392
Validation loss: 2.1984746917601554

Epoch: 6| Step: 8
Training loss: 1.4285175800323486
Validation loss: 2.2070359670987694

Epoch: 6| Step: 9
Training loss: 1.0309083461761475
Validation loss: 2.11067291485366

Epoch: 6| Step: 10
Training loss: 2.395155906677246
Validation loss: 2.17072654539539

Epoch: 6| Step: 11
Training loss: 1.753967523574829
Validation loss: 2.1490891492494972

Epoch: 6| Step: 12
Training loss: 1.0291635990142822
Validation loss: 2.192893671733077

Epoch: 6| Step: 13
Training loss: 2.9770913124084473
Validation loss: 2.1757811602725776

Epoch: 499| Step: 0
Training loss: 1.1903181076049805
Validation loss: 2.096560908902076

Epoch: 6| Step: 1
Training loss: 0.8895283341407776
Validation loss: 2.141256211906351

Epoch: 6| Step: 2
Training loss: 1.523655891418457
Validation loss: 2.115969737370809

Epoch: 6| Step: 3
Training loss: 1.3132296800613403
Validation loss: 2.1797708003751692

Epoch: 6| Step: 4
Training loss: 1.8131296634674072
Validation loss: 2.258221774972895

Epoch: 6| Step: 5
Training loss: 2.633756160736084
Validation loss: 2.200621594664871

Epoch: 6| Step: 6
Training loss: 2.008236885070801
Validation loss: 2.161243531011766

Epoch: 6| Step: 7
Training loss: 2.0387136936187744
Validation loss: 2.277740027314873

Epoch: 6| Step: 8
Training loss: 1.2720175981521606
Validation loss: 2.279614535711145

Epoch: 6| Step: 9
Training loss: 1.6828738451004028
Validation loss: 2.2065362212478474

Epoch: 6| Step: 10
Training loss: 1.8722470998764038
Validation loss: 2.1926692634500484

Epoch: 6| Step: 11
Training loss: 1.2689446210861206
Validation loss: 2.22708628254552

Epoch: 6| Step: 12
Training loss: 1.9383755922317505
Validation loss: 2.224200548664216

Epoch: 6| Step: 13
Training loss: 1.6925026178359985
Validation loss: 2.2391683004235707

Epoch: 500| Step: 0
Training loss: 1.240944504737854
Validation loss: 2.2158848060074674

Epoch: 6| Step: 1
Training loss: 1.6949679851531982
Validation loss: 2.140236231588548

Epoch: 6| Step: 2
Training loss: 2.416750192642212
Validation loss: 2.1476969360023417

Epoch: 6| Step: 3
Training loss: 1.1426198482513428
Validation loss: 2.1092391552463656

Epoch: 6| Step: 4
Training loss: 1.403635025024414
Validation loss: 2.152606938474922

Epoch: 6| Step: 5
Training loss: 1.8342680931091309
Validation loss: 2.1684215081635343

Epoch: 6| Step: 6
Training loss: 1.1364176273345947
Validation loss: 2.178564146000852

Epoch: 6| Step: 7
Training loss: 1.5916601419448853
Validation loss: 2.1484627018692675

Epoch: 6| Step: 8
Training loss: 1.5402358770370483
Validation loss: 2.086903641300817

Epoch: 6| Step: 9
Training loss: 2.2270822525024414
Validation loss: 2.1824788867786364

Epoch: 6| Step: 10
Training loss: 1.286945104598999
Validation loss: 2.139204655924151

Epoch: 6| Step: 11
Training loss: 1.3610508441925049
Validation loss: 2.1845603527561313

Epoch: 6| Step: 12
Training loss: 1.9085808992385864
Validation loss: 2.162017132646294

Epoch: 6| Step: 13
Training loss: 1.1144084930419922
Validation loss: 2.200764133084205

Epoch: 501| Step: 0
Training loss: 1.818459153175354
Validation loss: 2.1206691367651826

Epoch: 6| Step: 1
Training loss: 1.5012078285217285
Validation loss: 2.159530629393875

Epoch: 6| Step: 2
Training loss: 1.804508090019226
Validation loss: 2.1546454019443964

Epoch: 6| Step: 3
Training loss: 1.423656702041626
Validation loss: 2.1701679088736094

Epoch: 6| Step: 4
Training loss: 0.9490589499473572
Validation loss: 2.2161061994491087

Epoch: 6| Step: 5
Training loss: 2.0751538276672363
Validation loss: 2.1701852467752274

Epoch: 6| Step: 6
Training loss: 1.0805796384811401
Validation loss: 2.1757717286386797

Epoch: 6| Step: 7
Training loss: 1.642202377319336
Validation loss: 2.2372595597338933

Epoch: 6| Step: 8
Training loss: 2.154963970184326
Validation loss: 2.2499501371896393

Epoch: 6| Step: 9
Training loss: 1.3313263654708862
Validation loss: 2.208276980666704

Epoch: 6| Step: 10
Training loss: 1.4676673412322998
Validation loss: 2.1948588432804232

Epoch: 6| Step: 11
Training loss: 1.9093937873840332
Validation loss: 2.2793527982568227

Epoch: 6| Step: 12
Training loss: 1.1574134826660156
Validation loss: 2.1624642110640004

Epoch: 6| Step: 13
Training loss: 1.236342430114746
Validation loss: 2.217995894852505

Epoch: 502| Step: 0
Training loss: 0.9373568296432495
Validation loss: 2.19229224676727

Epoch: 6| Step: 1
Training loss: 0.634883463382721
Validation loss: 2.21746015420524

Epoch: 6| Step: 2
Training loss: 1.5291528701782227
Validation loss: 2.20117155198128

Epoch: 6| Step: 3
Training loss: 1.7675694227218628
Validation loss: 2.112549662590027

Epoch: 6| Step: 4
Training loss: 2.6592366695404053
Validation loss: 2.1550764652990524

Epoch: 6| Step: 5
Training loss: 2.0777077674865723
Validation loss: 2.2160223966003745

Epoch: 6| Step: 6
Training loss: 1.984480857849121
Validation loss: 2.156397465736635

Epoch: 6| Step: 7
Training loss: 1.0157703161239624
Validation loss: 2.175478196913196

Epoch: 6| Step: 8
Training loss: 1.4573781490325928
Validation loss: 2.1478627574059272

Epoch: 6| Step: 9
Training loss: 1.352151870727539
Validation loss: 2.1652740637461343

Epoch: 6| Step: 10
Training loss: 1.6984955072402954
Validation loss: 2.224902319651778

Epoch: 6| Step: 11
Training loss: 1.6466318368911743
Validation loss: 2.1318711362859255

Epoch: 6| Step: 12
Training loss: 1.1814017295837402
Validation loss: 2.217814419859199

Epoch: 6| Step: 13
Training loss: 1.359755039215088
Validation loss: 2.203195171971475

Epoch: 503| Step: 0
Training loss: 0.929980993270874
Validation loss: 2.1761424323563934

Epoch: 6| Step: 1
Training loss: 1.552973985671997
Validation loss: 2.1874856846306914

Epoch: 6| Step: 2
Training loss: 1.349273443222046
Validation loss: 2.208858954009189

Epoch: 6| Step: 3
Training loss: 1.9735503196716309
Validation loss: 2.1943140337544103

Epoch: 6| Step: 4
Training loss: 2.282125949859619
Validation loss: 2.167136210267262

Epoch: 6| Step: 5
Training loss: 1.5991077423095703
Validation loss: 2.1672164919555827

Epoch: 6| Step: 6
Training loss: 1.2931184768676758
Validation loss: 2.1819197465014715

Epoch: 6| Step: 7
Training loss: 1.8351552486419678
Validation loss: 2.1785384044852307

Epoch: 6| Step: 8
Training loss: 1.7034589052200317
Validation loss: 2.2005662046453005

Epoch: 6| Step: 9
Training loss: 1.5895805358886719
Validation loss: 2.1786178952904156

Epoch: 6| Step: 10
Training loss: 1.5213825702667236
Validation loss: 2.2062242108006633

Epoch: 6| Step: 11
Training loss: 1.119490146636963
Validation loss: 2.2356309839474258

Epoch: 6| Step: 12
Training loss: 1.248929738998413
Validation loss: 2.2719883188124625

Epoch: 6| Step: 13
Training loss: 1.4770090579986572
Validation loss: 2.2887557732161654

Epoch: 504| Step: 0
Training loss: 1.5102241039276123
Validation loss: 2.111338605162918

Epoch: 6| Step: 1
Training loss: 1.440520167350769
Validation loss: 2.180236316496326

Epoch: 6| Step: 2
Training loss: 1.7119743824005127
Validation loss: 2.1792573313559256

Epoch: 6| Step: 3
Training loss: 1.4817824363708496
Validation loss: 2.2251321423438286

Epoch: 6| Step: 4
Training loss: 1.4227831363677979
Validation loss: 2.1963839505308416

Epoch: 6| Step: 5
Training loss: 1.8034358024597168
Validation loss: 2.2521946032842

Epoch: 6| Step: 6
Training loss: 1.3379279375076294
Validation loss: 2.241011623413332

Epoch: 6| Step: 7
Training loss: 1.9269306659698486
Validation loss: 2.146127870005946

Epoch: 6| Step: 8
Training loss: 1.0916032791137695
Validation loss: 2.249786489753313

Epoch: 6| Step: 9
Training loss: 1.7199187278747559
Validation loss: 2.2083976166222685

Epoch: 6| Step: 10
Training loss: 1.5921818017959595
Validation loss: 2.28313087647961

Epoch: 6| Step: 11
Training loss: 2.0442497730255127
Validation loss: 2.2289100359844904

Epoch: 6| Step: 12
Training loss: 1.5486998558044434
Validation loss: 2.2279565283047256

Epoch: 6| Step: 13
Training loss: 1.2072715759277344
Validation loss: 2.168951480619369

Epoch: 505| Step: 0
Training loss: 1.7342889308929443
Validation loss: 2.1838466659668954

Epoch: 6| Step: 1
Training loss: 1.861616849899292
Validation loss: 2.1970552552130913

Epoch: 6| Step: 2
Training loss: 1.4390654563903809
Validation loss: 2.1750841602202384

Epoch: 6| Step: 3
Training loss: 2.153181552886963
Validation loss: 2.1843977205214964

Epoch: 6| Step: 4
Training loss: 1.2764298915863037
Validation loss: 2.1789727800635883

Epoch: 6| Step: 5
Training loss: 2.092331886291504
Validation loss: 2.186227736934539

Epoch: 6| Step: 6
Training loss: 0.9638627171516418
Validation loss: 2.1717968294697423

Epoch: 6| Step: 7
Training loss: 1.4092724323272705
Validation loss: 2.2243593328742572

Epoch: 6| Step: 8
Training loss: 1.7150366306304932
Validation loss: 2.1740881525060183

Epoch: 6| Step: 9
Training loss: 1.9350345134735107
Validation loss: 2.1956419855035763

Epoch: 6| Step: 10
Training loss: 1.1432340145111084
Validation loss: 2.160090543890512

Epoch: 6| Step: 11
Training loss: 1.927778959274292
Validation loss: 2.2354789510849984

Epoch: 6| Step: 12
Training loss: 1.2236332893371582
Validation loss: 2.2150097905948596

Epoch: 6| Step: 13
Training loss: 1.1294842958450317
Validation loss: 2.1859555116263767

Epoch: 506| Step: 0
Training loss: 1.8913429975509644
Validation loss: 2.1677503534542617

Epoch: 6| Step: 1
Training loss: 1.2328317165374756
Validation loss: 2.2465601621135587

Epoch: 6| Step: 2
Training loss: 1.6756670475006104
Validation loss: 2.155407703051003

Epoch: 6| Step: 3
Training loss: 1.1775121688842773
Validation loss: 2.154174571396202

Epoch: 6| Step: 4
Training loss: 2.0058131217956543
Validation loss: 2.1657011637123684

Epoch: 6| Step: 5
Training loss: 1.9599168300628662
Validation loss: 2.187342882156372

Epoch: 6| Step: 6
Training loss: 1.4210935831069946
Validation loss: 2.1474806826601744

Epoch: 6| Step: 7
Training loss: 1.2498843669891357
Validation loss: 2.11703932926219

Epoch: 6| Step: 8
Training loss: 1.636023998260498
Validation loss: 2.140334131897137

Epoch: 6| Step: 9
Training loss: 2.1702098846435547
Validation loss: 2.199521428795271

Epoch: 6| Step: 10
Training loss: 1.840193748474121
Validation loss: 2.125080467552267

Epoch: 6| Step: 11
Training loss: 1.7907850742340088
Validation loss: 2.184240396304797

Epoch: 6| Step: 12
Training loss: 1.1595039367675781
Validation loss: 2.174272375722085

Epoch: 6| Step: 13
Training loss: 0.4126169681549072
Validation loss: 2.1419680092924382

Epoch: 507| Step: 0
Training loss: 1.407926321029663
Validation loss: 2.195123358439374

Epoch: 6| Step: 1
Training loss: 2.1626977920532227
Validation loss: 2.1458996906075427

Epoch: 6| Step: 2
Training loss: 1.3248136043548584
Validation loss: 2.121252026609195

Epoch: 6| Step: 3
Training loss: 1.3345787525177002
Validation loss: 2.1698236593636135

Epoch: 6| Step: 4
Training loss: 0.9958952069282532
Validation loss: 2.175595519363239

Epoch: 6| Step: 5
Training loss: 1.787435531616211
Validation loss: 2.1350793671864334

Epoch: 6| Step: 6
Training loss: 2.3634471893310547
Validation loss: 2.2178302554674048

Epoch: 6| Step: 7
Training loss: 2.1581506729125977
Validation loss: 2.2474724092791156

Epoch: 6| Step: 8
Training loss: 1.1800296306610107
Validation loss: 2.2147863680316555

Epoch: 6| Step: 9
Training loss: 1.9919569492340088
Validation loss: 2.2266320131158315

Epoch: 6| Step: 10
Training loss: 1.3276920318603516
Validation loss: 2.135165709321217

Epoch: 6| Step: 11
Training loss: 1.7415566444396973
Validation loss: 2.1272013110499226

Epoch: 6| Step: 12
Training loss: 1.1281709671020508
Validation loss: 2.2271559597343527

Epoch: 6| Step: 13
Training loss: 1.1325206756591797
Validation loss: 2.2326171372526433

Epoch: 508| Step: 0
Training loss: 1.5353535413742065
Validation loss: 2.0846544004255727

Epoch: 6| Step: 1
Training loss: 1.7292693853378296
Validation loss: 2.1849079311534925

Epoch: 6| Step: 2
Training loss: 1.755814552307129
Validation loss: 2.1773959769997546

Epoch: 6| Step: 3
Training loss: 1.5928767919540405
Validation loss: 2.1547656366902013

Epoch: 6| Step: 4
Training loss: 0.9833298921585083
Validation loss: 2.190953036790253

Epoch: 6| Step: 5
Training loss: 1.872545599937439
Validation loss: 2.1499211275449364

Epoch: 6| Step: 6
Training loss: 2.1405534744262695
Validation loss: 2.231403845612721

Epoch: 6| Step: 7
Training loss: 2.0528573989868164
Validation loss: 2.1685636094821397

Epoch: 6| Step: 8
Training loss: 1.4715274572372437
Validation loss: 2.2617799761474773

Epoch: 6| Step: 9
Training loss: 1.468827486038208
Validation loss: 2.1552089106652046

Epoch: 6| Step: 10
Training loss: 1.078980565071106
Validation loss: 2.2562845970994685

Epoch: 6| Step: 11
Training loss: 1.2283074855804443
Validation loss: 2.1850547226526404

Epoch: 6| Step: 12
Training loss: 1.3809659481048584
Validation loss: 2.2317822825524116

Epoch: 6| Step: 13
Training loss: 1.1046373844146729
Validation loss: 2.265917895942606

Epoch: 509| Step: 0
Training loss: 2.059495210647583
Validation loss: 2.2061033428356214

Epoch: 6| Step: 1
Training loss: 1.5769349336624146
Validation loss: 2.1667079643536638

Epoch: 6| Step: 2
Training loss: 1.6598761081695557
Validation loss: 2.274454305248876

Epoch: 6| Step: 3
Training loss: 1.71550452709198
Validation loss: 2.196326414744059

Epoch: 6| Step: 4
Training loss: 1.1211045980453491
Validation loss: 2.273193620866345

Epoch: 6| Step: 5
Training loss: 1.5799063444137573
Validation loss: 2.18384995255419

Epoch: 6| Step: 6
Training loss: 1.4392402172088623
Validation loss: 2.2495881485682663

Epoch: 6| Step: 7
Training loss: 1.0694124698638916
Validation loss: 2.198549211666148

Epoch: 6| Step: 8
Training loss: 1.8255245685577393
Validation loss: 2.1773898575895574

Epoch: 6| Step: 9
Training loss: 1.4174129962921143
Validation loss: 2.162588245125227

Epoch: 6| Step: 10
Training loss: 1.0303287506103516
Validation loss: 2.156847507722916

Epoch: 6| Step: 11
Training loss: 1.980543613433838
Validation loss: 2.1510502420445925

Epoch: 6| Step: 12
Training loss: 2.317091941833496
Validation loss: 2.1946460726440593

Epoch: 6| Step: 13
Training loss: 0.7097398042678833
Validation loss: 2.1988964824266333

Epoch: 510| Step: 0
Training loss: 1.7041447162628174
Validation loss: 2.125084638595581

Epoch: 6| Step: 1
Training loss: 1.8392305374145508
Validation loss: 2.119793289451189

Epoch: 6| Step: 2
Training loss: 1.5098495483398438
Validation loss: 2.1630776159224974

Epoch: 6| Step: 3
Training loss: 1.4449620246887207
Validation loss: 2.0742837203446256

Epoch: 6| Step: 4
Training loss: 1.5318562984466553
Validation loss: 2.1539483070373535

Epoch: 6| Step: 5
Training loss: 1.4766409397125244
Validation loss: 2.1564638947927826

Epoch: 6| Step: 6
Training loss: 1.2576420307159424
Validation loss: 2.184530932416198

Epoch: 6| Step: 7
Training loss: 1.8660813570022583
Validation loss: 2.1537935118521414

Epoch: 6| Step: 8
Training loss: 1.1319948434829712
Validation loss: 2.198387525414908

Epoch: 6| Step: 9
Training loss: 1.5114119052886963
Validation loss: 2.171814715990456

Epoch: 6| Step: 10
Training loss: 1.6701183319091797
Validation loss: 2.2022840515259774

Epoch: 6| Step: 11
Training loss: 1.6896600723266602
Validation loss: 2.196557726911319

Epoch: 6| Step: 12
Training loss: 1.620358943939209
Validation loss: 2.2773480364071426

Epoch: 6| Step: 13
Training loss: 1.9168455600738525
Validation loss: 2.1726684442130466

Epoch: 511| Step: 0
Training loss: 1.85382080078125
Validation loss: 2.2624200877322944

Epoch: 6| Step: 1
Training loss: 0.9577871561050415
Validation loss: 2.2593060924160864

Epoch: 6| Step: 2
Training loss: 1.4512132406234741
Validation loss: 2.142303192487327

Epoch: 6| Step: 3
Training loss: 1.1849716901779175
Validation loss: 2.2215426916717202

Epoch: 6| Step: 4
Training loss: 2.3454465866088867
Validation loss: 2.2525699497551046

Epoch: 6| Step: 5
Training loss: 2.0628442764282227
Validation loss: 2.222000252815985

Epoch: 6| Step: 6
Training loss: 1.914370059967041
Validation loss: 2.2101122935613

Epoch: 6| Step: 7
Training loss: 1.9696745872497559
Validation loss: 2.2795681697066112

Epoch: 6| Step: 8
Training loss: 1.8842276334762573
Validation loss: 2.2313580743728147

Epoch: 6| Step: 9
Training loss: 1.2346086502075195
Validation loss: 2.263490899916618

Epoch: 6| Step: 10
Training loss: 1.0427109003067017
Validation loss: 2.220358189716134

Epoch: 6| Step: 11
Training loss: 1.351770281791687
Validation loss: 2.1697171452224895

Epoch: 6| Step: 12
Training loss: 1.6637372970581055
Validation loss: 2.1269218075659966

Epoch: 6| Step: 13
Training loss: 2.186628580093384
Validation loss: 2.2262212384131645

Epoch: 512| Step: 0
Training loss: 1.3989017009735107
Validation loss: 2.1081437654392694

Epoch: 6| Step: 1
Training loss: 1.925523281097412
Validation loss: 2.1342965044001097

Epoch: 6| Step: 2
Training loss: 1.913588047027588
Validation loss: 2.177716347479051

Epoch: 6| Step: 3
Training loss: 1.7369221448898315
Validation loss: 2.2113318981662875

Epoch: 6| Step: 4
Training loss: 1.656285047531128
Validation loss: 2.147768561558057

Epoch: 6| Step: 5
Training loss: 1.2755985260009766
Validation loss: 2.292603149208971

Epoch: 6| Step: 6
Training loss: 1.1972407102584839
Validation loss: 2.187456830855339

Epoch: 6| Step: 7
Training loss: 1.928863286972046
Validation loss: 2.1513712970159387

Epoch: 6| Step: 8
Training loss: 1.3528578281402588
Validation loss: 2.1556435784985943

Epoch: 6| Step: 9
Training loss: 0.9912686347961426
Validation loss: 2.150904752874887

Epoch: 6| Step: 10
Training loss: 2.033097743988037
Validation loss: 2.2568869590759277

Epoch: 6| Step: 11
Training loss: 1.2997586727142334
Validation loss: 2.239217096759427

Epoch: 6| Step: 12
Training loss: 1.7700031995773315
Validation loss: 2.205998730915849

Epoch: 6| Step: 13
Training loss: 1.1682591438293457
Validation loss: 2.150281129344817

Epoch: 513| Step: 0
Training loss: 1.847495436668396
Validation loss: 2.1241776302296627

Epoch: 6| Step: 1
Training loss: 1.5895099639892578
Validation loss: 2.1566060743024273

Epoch: 6| Step: 2
Training loss: 1.9320614337921143
Validation loss: 2.1478986355566208

Epoch: 6| Step: 3
Training loss: 1.4489109516143799
Validation loss: 2.222741388505505

Epoch: 6| Step: 4
Training loss: 1.0510218143463135
Validation loss: 2.17450370839847

Epoch: 6| Step: 5
Training loss: 2.0169854164123535
Validation loss: 2.2102199805680143

Epoch: 6| Step: 6
Training loss: 2.0655689239501953
Validation loss: 2.2498405928252847

Epoch: 6| Step: 7
Training loss: 2.085327386856079
Validation loss: 2.209588143133348

Epoch: 6| Step: 8
Training loss: 1.628889560699463
Validation loss: 2.1939924122184835

Epoch: 6| Step: 9
Training loss: 1.7846012115478516
Validation loss: 2.2222842119073354

Epoch: 6| Step: 10
Training loss: 1.3380358219146729
Validation loss: 2.1654516830239245

Epoch: 6| Step: 11
Training loss: 1.2487118244171143
Validation loss: 2.098401261914161

Epoch: 6| Step: 12
Training loss: 1.5420336723327637
Validation loss: 2.2455440900659047

Epoch: 6| Step: 13
Training loss: 0.8276932835578918
Validation loss: 2.2401768161404516

Epoch: 514| Step: 0
Training loss: 1.1902449131011963
Validation loss: 2.169032827500374

Epoch: 6| Step: 1
Training loss: 1.733598232269287
Validation loss: 2.151890382971815

Epoch: 6| Step: 2
Training loss: 1.687119722366333
Validation loss: 2.164791355850876

Epoch: 6| Step: 3
Training loss: 1.549121618270874
Validation loss: 2.1219010058269707

Epoch: 6| Step: 4
Training loss: 1.6923205852508545
Validation loss: 2.1767258195466894

Epoch: 6| Step: 5
Training loss: 1.049140453338623
Validation loss: 2.107628204489267

Epoch: 6| Step: 6
Training loss: 2.07191801071167
Validation loss: 2.2481481106050554

Epoch: 6| Step: 7
Training loss: 1.5131964683532715
Validation loss: 2.182207566435619

Epoch: 6| Step: 8
Training loss: 1.4194896221160889
Validation loss: 2.220290762121959

Epoch: 6| Step: 9
Training loss: 1.3092652559280396
Validation loss: 2.2005543247345956

Epoch: 6| Step: 10
Training loss: 1.117897391319275
Validation loss: 2.1462838367749284

Epoch: 6| Step: 11
Training loss: 2.039292335510254
Validation loss: 2.2825704466912056

Epoch: 6| Step: 12
Training loss: 1.1971361637115479
Validation loss: 2.224071551394719

Epoch: 6| Step: 13
Training loss: 2.651841163635254
Validation loss: 2.1881286046838246

Epoch: 515| Step: 0
Training loss: 1.8158855438232422
Validation loss: 2.275019262426643

Epoch: 6| Step: 1
Training loss: 1.335671305656433
Validation loss: 2.1853559094090618

Epoch: 6| Step: 2
Training loss: 1.598992109298706
Validation loss: 2.2340317131370626

Epoch: 6| Step: 3
Training loss: 1.5304901599884033
Validation loss: 2.2034781773885093

Epoch: 6| Step: 4
Training loss: 1.398430585861206
Validation loss: 2.1873854103908745

Epoch: 6| Step: 5
Training loss: 2.0785717964172363
Validation loss: 2.229559208757134

Epoch: 6| Step: 6
Training loss: 1.4088038206100464
Validation loss: 2.1528507201902327

Epoch: 6| Step: 7
Training loss: 1.7261934280395508
Validation loss: 2.119804702779298

Epoch: 6| Step: 8
Training loss: 0.688919723033905
Validation loss: 2.27211780189186

Epoch: 6| Step: 9
Training loss: 1.1638896465301514
Validation loss: 2.2283030966276764

Epoch: 6| Step: 10
Training loss: 1.927894115447998
Validation loss: 2.1817725320016184

Epoch: 6| Step: 11
Training loss: 1.9507215023040771
Validation loss: 2.1423361019421647

Epoch: 6| Step: 12
Training loss: 1.3626527786254883
Validation loss: 2.1410019243917158

Epoch: 6| Step: 13
Training loss: 1.4774386882781982
Validation loss: 2.1368130355752926

Epoch: 516| Step: 0
Training loss: 1.5394415855407715
Validation loss: 2.2088021642418316

Epoch: 6| Step: 1
Training loss: 1.3574235439300537
Validation loss: 2.15876462382655

Epoch: 6| Step: 2
Training loss: 2.0403029918670654
Validation loss: 2.1892189261733845

Epoch: 6| Step: 3
Training loss: 1.701654076576233
Validation loss: 2.1915812697461856

Epoch: 6| Step: 4
Training loss: 1.5674147605895996
Validation loss: 2.0936684582823064

Epoch: 6| Step: 5
Training loss: 1.4349035024642944
Validation loss: 2.2252748512452647

Epoch: 6| Step: 6
Training loss: 1.506672978401184
Validation loss: 2.208205735811623

Epoch: 6| Step: 7
Training loss: 1.3327412605285645
Validation loss: 2.1720376091618694

Epoch: 6| Step: 8
Training loss: 1.3837099075317383
Validation loss: 2.1157203464097876

Epoch: 6| Step: 9
Training loss: 0.9943925142288208
Validation loss: 2.2218900726687525

Epoch: 6| Step: 10
Training loss: 2.0332083702087402
Validation loss: 2.151502759225907

Epoch: 6| Step: 11
Training loss: 1.9972755908966064
Validation loss: 2.1728890403624503

Epoch: 6| Step: 12
Training loss: 1.464524507522583
Validation loss: 2.1698873812152493

Epoch: 6| Step: 13
Training loss: 1.8696047067642212
Validation loss: 2.1868064377897527

Epoch: 517| Step: 0
Training loss: 1.814079761505127
Validation loss: 2.165982189998832

Epoch: 6| Step: 1
Training loss: 2.0803205966949463
Validation loss: 2.189814152256135

Epoch: 6| Step: 2
Training loss: 1.629908561706543
Validation loss: 2.1737629290549987

Epoch: 6| Step: 3
Training loss: 1.2967780828475952
Validation loss: 2.1892647640679472

Epoch: 6| Step: 4
Training loss: 1.7384276390075684
Validation loss: 2.140916152666974

Epoch: 6| Step: 5
Training loss: 2.136537790298462
Validation loss: 2.1436489500025266

Epoch: 6| Step: 6
Training loss: 1.141046404838562
Validation loss: 2.2226726470455045

Epoch: 6| Step: 7
Training loss: 1.0199793577194214
Validation loss: 2.164789204956383

Epoch: 6| Step: 8
Training loss: 1.42042875289917
Validation loss: 2.2411223278250745

Epoch: 6| Step: 9
Training loss: 1.8603153228759766
Validation loss: 2.188392987815283

Epoch: 6| Step: 10
Training loss: 1.6861858367919922
Validation loss: 2.2154809633890786

Epoch: 6| Step: 11
Training loss: 0.4051080346107483
Validation loss: 2.173536112231593

Epoch: 6| Step: 12
Training loss: 1.0977656841278076
Validation loss: 2.2614281228793565

Epoch: 6| Step: 13
Training loss: 2.700737476348877
Validation loss: 2.1409851710001626

Epoch: 518| Step: 0
Training loss: 1.885045051574707
Validation loss: 2.2638770123963714

Epoch: 6| Step: 1
Training loss: 1.9377260208129883
Validation loss: 2.2864989285827964

Epoch: 6| Step: 2
Training loss: 2.041354179382324
Validation loss: 2.184259637709587

Epoch: 6| Step: 3
Training loss: 1.1224689483642578
Validation loss: 2.15499625923813

Epoch: 6| Step: 4
Training loss: 1.9260817766189575
Validation loss: 2.2189386301143195

Epoch: 6| Step: 5
Training loss: 1.4381508827209473
Validation loss: 2.1142536952931392

Epoch: 6| Step: 6
Training loss: 1.361846685409546
Validation loss: 2.1580265004147767

Epoch: 6| Step: 7
Training loss: 1.5047211647033691
Validation loss: 2.131912257081719

Epoch: 6| Step: 8
Training loss: 1.231479525566101
Validation loss: 2.268058564073296

Epoch: 6| Step: 9
Training loss: 1.4914405345916748
Validation loss: 2.1827492175563687

Epoch: 6| Step: 10
Training loss: 1.2820115089416504
Validation loss: 2.1837008832603373

Epoch: 6| Step: 11
Training loss: 1.652355432510376
Validation loss: 2.1584470425882647

Epoch: 6| Step: 12
Training loss: 1.286392331123352
Validation loss: 2.2207716972597185

Epoch: 6| Step: 13
Training loss: 0.7959232926368713
Validation loss: 2.1950736020200994

Epoch: 519| Step: 0
Training loss: 1.3715535402297974
Validation loss: 2.2055363091089393

Epoch: 6| Step: 1
Training loss: 1.1094927787780762
Validation loss: 2.1331752936045327

Epoch: 6| Step: 2
Training loss: 1.516613245010376
Validation loss: 2.186834239190625

Epoch: 6| Step: 3
Training loss: 1.2512555122375488
Validation loss: 2.1140201860858547

Epoch: 6| Step: 4
Training loss: 1.9308770895004272
Validation loss: 2.09201745704938

Epoch: 6| Step: 5
Training loss: 1.5072977542877197
Validation loss: 2.1894626873795704

Epoch: 6| Step: 6
Training loss: 1.3973653316497803
Validation loss: 2.198068582883445

Epoch: 6| Step: 7
Training loss: 1.0893354415893555
Validation loss: 2.2181508528288973

Epoch: 6| Step: 8
Training loss: 1.653638482093811
Validation loss: 2.2542699485696773

Epoch: 6| Step: 9
Training loss: 1.5277340412139893
Validation loss: 2.261539307973718

Epoch: 6| Step: 10
Training loss: 2.4512884616851807
Validation loss: 2.2354004075450282

Epoch: 6| Step: 11
Training loss: 1.5603084564208984
Validation loss: 2.232069638467604

Epoch: 6| Step: 12
Training loss: 2.0806188583374023
Validation loss: 2.1989923856591664

Epoch: 6| Step: 13
Training loss: 1.3480255603790283
Validation loss: 2.243354558944702

Epoch: 520| Step: 0
Training loss: 1.4427196979522705
Validation loss: 2.2102329064440984

Epoch: 6| Step: 1
Training loss: 1.489235520362854
Validation loss: 2.195897131837824

Epoch: 6| Step: 2
Training loss: 1.5694360733032227
Validation loss: 2.1986711461056947

Epoch: 6| Step: 3
Training loss: 1.799058198928833
Validation loss: 2.210338049037482

Epoch: 6| Step: 4
Training loss: 1.3937265872955322
Validation loss: 2.216602812531174

Epoch: 6| Step: 5
Training loss: 1.1623979806900024
Validation loss: 2.265559550254576

Epoch: 6| Step: 6
Training loss: 1.3377693891525269
Validation loss: 2.1997609292307208

Epoch: 6| Step: 7
Training loss: 1.4415171146392822
Validation loss: 2.223840992937806

Epoch: 6| Step: 8
Training loss: 1.5558710098266602
Validation loss: 2.1747466594942155

Epoch: 6| Step: 9
Training loss: 2.1574060916900635
Validation loss: 2.209448427282354

Epoch: 6| Step: 10
Training loss: 1.272733449935913
Validation loss: 2.1435028814500376

Epoch: 6| Step: 11
Training loss: 1.3545491695404053
Validation loss: 2.194350060596261

Epoch: 6| Step: 12
Training loss: 2.2380337715148926
Validation loss: 2.222552550736294

Epoch: 6| Step: 13
Training loss: 1.468763828277588
Validation loss: 2.1289927741532684

Epoch: 521| Step: 0
Training loss: 1.863820195198059
Validation loss: 2.1962336109530542

Epoch: 6| Step: 1
Training loss: 1.2756373882293701
Validation loss: 2.1742614764039234

Epoch: 6| Step: 2
Training loss: 1.7772610187530518
Validation loss: 2.1697674643608833

Epoch: 6| Step: 3
Training loss: 1.8651707172393799
Validation loss: 2.1403417818007933

Epoch: 6| Step: 4
Training loss: 1.90872323513031
Validation loss: 2.1798254033570648

Epoch: 6| Step: 5
Training loss: 1.788895845413208
Validation loss: 2.1998725783440376

Epoch: 6| Step: 6
Training loss: 1.4202232360839844
Validation loss: 2.1723428208340883

Epoch: 6| Step: 7
Training loss: 1.1401177644729614
Validation loss: 2.251231360179122

Epoch: 6| Step: 8
Training loss: 1.5955309867858887
Validation loss: 2.183555254372217

Epoch: 6| Step: 9
Training loss: 1.6527886390686035
Validation loss: 2.1983412209377495

Epoch: 6| Step: 10
Training loss: 1.7820897102355957
Validation loss: 2.190334553359657

Epoch: 6| Step: 11
Training loss: 1.198534607887268
Validation loss: 2.0933945089258175

Epoch: 6| Step: 12
Training loss: 1.5315945148468018
Validation loss: 2.195833767614057

Epoch: 6| Step: 13
Training loss: 1.7097150087356567
Validation loss: 2.100543475920154

Epoch: 522| Step: 0
Training loss: 1.714767575263977
Validation loss: 2.1297610626425794

Epoch: 6| Step: 1
Training loss: 1.6355513334274292
Validation loss: 2.2846624005225395

Epoch: 6| Step: 2
Training loss: 1.6464991569519043
Validation loss: 2.155222297996603

Epoch: 6| Step: 3
Training loss: 1.1798765659332275
Validation loss: 2.130143960316976

Epoch: 6| Step: 4
Training loss: 2.3577721118927
Validation loss: 2.2657366414223947

Epoch: 6| Step: 5
Training loss: 1.1976628303527832
Validation loss: 2.2405098715136127

Epoch: 6| Step: 6
Training loss: 1.9373435974121094
Validation loss: 2.2538327068410893

Epoch: 6| Step: 7
Training loss: 1.1446926593780518
Validation loss: 2.184256024258111

Epoch: 6| Step: 8
Training loss: 1.5141323804855347
Validation loss: 2.222440702940828

Epoch: 6| Step: 9
Training loss: 2.031766653060913
Validation loss: 2.241203905433737

Epoch: 6| Step: 10
Training loss: 1.0410051345825195
Validation loss: 2.294824648928899

Epoch: 6| Step: 11
Training loss: 1.6029837131500244
Validation loss: 2.206742214900191

Epoch: 6| Step: 12
Training loss: 1.3292076587677002
Validation loss: 2.2084621767843924

Epoch: 6| Step: 13
Training loss: 1.2963203191757202
Validation loss: 2.141039389435963

Epoch: 523| Step: 0
Training loss: 1.2180577516555786
Validation loss: 2.3501594707530034

Epoch: 6| Step: 1
Training loss: 1.5237154960632324
Validation loss: 2.1129235606039725

Epoch: 6| Step: 2
Training loss: 1.3855905532836914
Validation loss: 2.1621872096933346

Epoch: 6| Step: 3
Training loss: 1.3969762325286865
Validation loss: 2.090250348532072

Epoch: 6| Step: 4
Training loss: 1.0529944896697998
Validation loss: 2.104598004330871

Epoch: 6| Step: 5
Training loss: 2.4574475288391113
Validation loss: 2.1929890353192567

Epoch: 6| Step: 6
Training loss: 1.180942177772522
Validation loss: 2.110759291597592

Epoch: 6| Step: 7
Training loss: 1.6817508935928345
Validation loss: 2.084321721907585

Epoch: 6| Step: 8
Training loss: 1.4585908651351929
Validation loss: 2.1737336240788943

Epoch: 6| Step: 9
Training loss: 1.3032629489898682
Validation loss: 2.1615825109584357

Epoch: 6| Step: 10
Training loss: 2.0784101486206055
Validation loss: 2.1950508253548735

Epoch: 6| Step: 11
Training loss: 1.353771448135376
Validation loss: 2.1868305078116794

Epoch: 6| Step: 12
Training loss: 1.8989994525909424
Validation loss: 2.1513521414931103

Epoch: 6| Step: 13
Training loss: 1.631689190864563
Validation loss: 2.1959306604118756

Epoch: 524| Step: 0
Training loss: 1.3985940217971802
Validation loss: 2.16172860130187

Epoch: 6| Step: 1
Training loss: 1.5153815746307373
Validation loss: 2.162524743746686

Epoch: 6| Step: 2
Training loss: 1.4771203994750977
Validation loss: 2.1992435839868363

Epoch: 6| Step: 3
Training loss: 2.3128275871276855
Validation loss: 2.2233705084810973

Epoch: 6| Step: 4
Training loss: 1.5778541564941406
Validation loss: 2.2013415136644916

Epoch: 6| Step: 5
Training loss: 1.2652206420898438
Validation loss: 2.193005079864174

Epoch: 6| Step: 6
Training loss: 2.149026393890381
Validation loss: 2.2048101284170665

Epoch: 6| Step: 7
Training loss: 1.3550735712051392
Validation loss: 2.210728271033174

Epoch: 6| Step: 8
Training loss: 1.7851896286010742
Validation loss: 2.1716428315767677

Epoch: 6| Step: 9
Training loss: 1.5479772090911865
Validation loss: 2.2600621972032773

Epoch: 6| Step: 10
Training loss: 1.5792219638824463
Validation loss: 2.246344840654763

Epoch: 6| Step: 11
Training loss: 1.2816996574401855
Validation loss: 2.170109910349692

Epoch: 6| Step: 12
Training loss: 1.0975706577301025
Validation loss: 2.303095227928572

Epoch: 6| Step: 13
Training loss: 1.7304158210754395
Validation loss: 2.178735602286554

Epoch: 525| Step: 0
Training loss: 1.9254188537597656
Validation loss: 2.107006331925751

Epoch: 6| Step: 1
Training loss: 1.436201810836792
Validation loss: 2.1688661459953553

Epoch: 6| Step: 2
Training loss: 2.1489410400390625
Validation loss: 2.182197704110094

Epoch: 6| Step: 3
Training loss: 1.5906307697296143
Validation loss: 2.1579501449420886

Epoch: 6| Step: 4
Training loss: 1.6570230722427368
Validation loss: 2.1783750518675773

Epoch: 6| Step: 5
Training loss: 1.625579833984375
Validation loss: 2.137210431919303

Epoch: 6| Step: 6
Training loss: 1.0713286399841309
Validation loss: 2.1964947536427486

Epoch: 6| Step: 7
Training loss: 1.7124621868133545
Validation loss: 2.21621004227669

Epoch: 6| Step: 8
Training loss: 1.5808264017105103
Validation loss: 2.170357829780989

Epoch: 6| Step: 9
Training loss: 1.4055975675582886
Validation loss: 2.1065940010932183

Epoch: 6| Step: 10
Training loss: 1.9863553047180176
Validation loss: 2.2013829151789346

Epoch: 6| Step: 11
Training loss: 1.3478624820709229
Validation loss: 2.037145414660054

Epoch: 6| Step: 12
Training loss: 1.4043995141983032
Validation loss: 2.113103961431852

Epoch: 6| Step: 13
Training loss: 0.6308419704437256
Validation loss: 2.1685115714227

Epoch: 526| Step: 0
Training loss: 1.7204489707946777
Validation loss: 2.127969821294149

Epoch: 6| Step: 1
Training loss: 1.617130160331726
Validation loss: 2.0981297044343847

Epoch: 6| Step: 2
Training loss: 1.818192958831787
Validation loss: 2.165003862432254

Epoch: 6| Step: 3
Training loss: 2.3310465812683105
Validation loss: 2.1334876783432497

Epoch: 6| Step: 4
Training loss: 1.6146306991577148
Validation loss: 2.1270711973149288

Epoch: 6| Step: 5
Training loss: 1.5473042726516724
Validation loss: 2.1498988033622823

Epoch: 6| Step: 6
Training loss: 0.7760027647018433
Validation loss: 2.2503876327186503

Epoch: 6| Step: 7
Training loss: 1.9771077632904053
Validation loss: 2.2152219767211587

Epoch: 6| Step: 8
Training loss: 1.5686228275299072
Validation loss: 2.1676373430477676

Epoch: 6| Step: 9
Training loss: 1.3124310970306396
Validation loss: 2.1409242678714056

Epoch: 6| Step: 10
Training loss: 1.3605046272277832
Validation loss: 2.1382906436920166

Epoch: 6| Step: 11
Training loss: 1.7459018230438232
Validation loss: 2.1275831294316117

Epoch: 6| Step: 12
Training loss: 0.8272779583930969
Validation loss: 2.2138978306965162

Epoch: 6| Step: 13
Training loss: 1.4298739433288574
Validation loss: 2.200825568168394

Epoch: 527| Step: 0
Training loss: 1.5407397747039795
Validation loss: 2.2543979690920923

Epoch: 6| Step: 1
Training loss: 1.638608455657959
Validation loss: 2.131572646479453

Epoch: 6| Step: 2
Training loss: 1.197188377380371
Validation loss: 2.237512203954881

Epoch: 6| Step: 3
Training loss: 1.781254529953003
Validation loss: 2.1409372360475603

Epoch: 6| Step: 4
Training loss: 1.3854433298110962
Validation loss: 2.1697872838666363

Epoch: 6| Step: 5
Training loss: 2.0357515811920166
Validation loss: 2.170430193665207

Epoch: 6| Step: 6
Training loss: 1.2748656272888184
Validation loss: 2.2185730934143066

Epoch: 6| Step: 7
Training loss: 1.5108366012573242
Validation loss: 2.2170728637326147

Epoch: 6| Step: 8
Training loss: 1.6448973417282104
Validation loss: 2.2382994697939966

Epoch: 6| Step: 9
Training loss: 1.958543062210083
Validation loss: 2.235674870911465

Epoch: 6| Step: 10
Training loss: 1.3462408781051636
Validation loss: 2.158676678134549

Epoch: 6| Step: 11
Training loss: 1.0489916801452637
Validation loss: 2.1761969417654057

Epoch: 6| Step: 12
Training loss: 1.589898943901062
Validation loss: 2.1538440873545985

Epoch: 6| Step: 13
Training loss: 1.521277666091919
Validation loss: 2.1658669697341097

Epoch: 528| Step: 0
Training loss: 1.4580203294754028
Validation loss: 2.122430015635747

Epoch: 6| Step: 1
Training loss: 1.860819935798645
Validation loss: 2.190811005971765

Epoch: 6| Step: 2
Training loss: 1.4916162490844727
Validation loss: 2.263631784787742

Epoch: 6| Step: 3
Training loss: 1.6017094850540161
Validation loss: 2.2160121369105514

Epoch: 6| Step: 4
Training loss: 1.5360870361328125
Validation loss: 2.245954421258742

Epoch: 6| Step: 5
Training loss: 1.6885319948196411
Validation loss: 2.1168066916927213

Epoch: 6| Step: 6
Training loss: 1.013846516609192
Validation loss: 2.237369114352811

Epoch: 6| Step: 7
Training loss: 1.3223766088485718
Validation loss: 2.098208009555776

Epoch: 6| Step: 8
Training loss: 1.0409719944000244
Validation loss: 2.2546376618005897

Epoch: 6| Step: 9
Training loss: 1.8766508102416992
Validation loss: 2.2288622035775134

Epoch: 6| Step: 10
Training loss: 2.0814008712768555
Validation loss: 2.1560142424798783

Epoch: 6| Step: 11
Training loss: 1.416325569152832
Validation loss: 2.234636281126289

Epoch: 6| Step: 12
Training loss: 1.4948680400848389
Validation loss: 2.219106756230836

Epoch: 6| Step: 13
Training loss: 2.098855495452881
Validation loss: 2.182265922587405

Epoch: 529| Step: 0
Training loss: 1.5396697521209717
Validation loss: 2.2270862594727547

Epoch: 6| Step: 1
Training loss: 1.2547345161437988
Validation loss: 2.144947003292781

Epoch: 6| Step: 2
Training loss: 1.1650240421295166
Validation loss: 2.218677887352564

Epoch: 6| Step: 3
Training loss: 1.7305140495300293
Validation loss: 2.180352585290068

Epoch: 6| Step: 4
Training loss: 1.5559046268463135
Validation loss: 2.21836563464134

Epoch: 6| Step: 5
Training loss: 1.7706152200698853
Validation loss: 2.1543162599686654

Epoch: 6| Step: 6
Training loss: 1.711331844329834
Validation loss: 2.2571375934026574

Epoch: 6| Step: 7
Training loss: 1.6154413223266602
Validation loss: 2.232340928046934

Epoch: 6| Step: 8
Training loss: 1.1588116884231567
Validation loss: 2.2805163373229322

Epoch: 6| Step: 9
Training loss: 1.3993861675262451
Validation loss: 2.207892740926435

Epoch: 6| Step: 10
Training loss: 1.4856566190719604
Validation loss: 2.2346254523082445

Epoch: 6| Step: 11
Training loss: 2.2200405597686768
Validation loss: 2.22087679114393

Epoch: 6| Step: 12
Training loss: 1.9003432989120483
Validation loss: 2.1793641159611363

Epoch: 6| Step: 13
Training loss: 2.000229597091675
Validation loss: 2.2222971582925446

Epoch: 530| Step: 0
Training loss: 1.5621798038482666
Validation loss: 2.184310044011762

Epoch: 6| Step: 1
Training loss: 1.3217532634735107
Validation loss: 2.121417651894272

Epoch: 6| Step: 2
Training loss: 1.6008830070495605
Validation loss: 2.168709701107394

Epoch: 6| Step: 3
Training loss: 1.2516000270843506
Validation loss: 2.149623417085217

Epoch: 6| Step: 4
Training loss: 1.3730156421661377
Validation loss: 2.1259849020229873

Epoch: 6| Step: 5
Training loss: 1.5874178409576416
Validation loss: 2.190050022576445

Epoch: 6| Step: 6
Training loss: 1.2415950298309326
Validation loss: 2.120858310371317

Epoch: 6| Step: 7
Training loss: 1.503525733947754
Validation loss: 2.199353841043288

Epoch: 6| Step: 8
Training loss: 1.8098373413085938
Validation loss: 2.1248253109634563

Epoch: 6| Step: 9
Training loss: 1.9262189865112305
Validation loss: 2.216498992776358

Epoch: 6| Step: 10
Training loss: 2.266329288482666
Validation loss: 2.184240464241274

Epoch: 6| Step: 11
Training loss: 2.647118091583252
Validation loss: 2.18885798095375

Epoch: 6| Step: 12
Training loss: 1.0251774787902832
Validation loss: 2.135837826677548

Epoch: 6| Step: 13
Training loss: 0.8975173234939575
Validation loss: 2.1371655438535955

Epoch: 531| Step: 0
Training loss: 1.3026487827301025
Validation loss: 2.1817742957863757

Epoch: 6| Step: 1
Training loss: 1.9088187217712402
Validation loss: 2.1793466127046974

Epoch: 6| Step: 2
Training loss: 2.099980592727661
Validation loss: 2.1938220916255826

Epoch: 6| Step: 3
Training loss: 1.1161603927612305
Validation loss: 2.243431829637097

Epoch: 6| Step: 4
Training loss: 1.1801941394805908
Validation loss: 2.235416422608078

Epoch: 6| Step: 5
Training loss: 1.6048879623413086
Validation loss: 2.17288201855075

Epoch: 6| Step: 6
Training loss: 2.203946352005005
Validation loss: 2.1707305626202653

Epoch: 6| Step: 7
Training loss: 1.8935590982437134
Validation loss: 2.2518026649311023

Epoch: 6| Step: 8
Training loss: 1.743642807006836
Validation loss: 2.1428200506394908

Epoch: 6| Step: 9
Training loss: 0.906413197517395
Validation loss: 2.22383689495825

Epoch: 6| Step: 10
Training loss: 1.3999271392822266
Validation loss: 2.2068091977027153

Epoch: 6| Step: 11
Training loss: 1.4358787536621094
Validation loss: 2.1324915078378495

Epoch: 6| Step: 12
Training loss: 1.1664364337921143
Validation loss: 2.1903748460995254

Epoch: 6| Step: 13
Training loss: 1.4507906436920166
Validation loss: 2.151420888080392

Epoch: 532| Step: 0
Training loss: 2.1939568519592285
Validation loss: 2.129919795579808

Epoch: 6| Step: 1
Training loss: 1.5982463359832764
Validation loss: 2.218079766919536

Epoch: 6| Step: 2
Training loss: 0.8551915287971497
Validation loss: 2.0853140918157433

Epoch: 6| Step: 3
Training loss: 2.057009696960449
Validation loss: 2.1667219490133305

Epoch: 6| Step: 4
Training loss: 1.5149966478347778
Validation loss: 2.1824255066533245

Epoch: 6| Step: 5
Training loss: 1.3904719352722168
Validation loss: 2.228946126917357

Epoch: 6| Step: 6
Training loss: 2.0012528896331787
Validation loss: 2.258407772228282

Epoch: 6| Step: 7
Training loss: 1.4152286052703857
Validation loss: 2.2442397327833277

Epoch: 6| Step: 8
Training loss: 1.37782883644104
Validation loss: 2.2323935416436966

Epoch: 6| Step: 9
Training loss: 1.915824294090271
Validation loss: 2.2326948488912275

Epoch: 6| Step: 10
Training loss: 0.8129952549934387
Validation loss: 2.2131843618167344

Epoch: 6| Step: 11
Training loss: 1.320307970046997
Validation loss: 2.1376808202394875

Epoch: 6| Step: 12
Training loss: 1.1119606494903564
Validation loss: 2.226557908519622

Epoch: 6| Step: 13
Training loss: 1.286994457244873
Validation loss: 2.253782054429413

Epoch: 533| Step: 0
Training loss: 2.1511237621307373
Validation loss: 2.1372925107197096

Epoch: 6| Step: 1
Training loss: 1.7019598484039307
Validation loss: 2.187770874269547

Epoch: 6| Step: 2
Training loss: 0.871259331703186
Validation loss: 2.2431144099081717

Epoch: 6| Step: 3
Training loss: 2.0933637619018555
Validation loss: 2.1586894322467107

Epoch: 6| Step: 4
Training loss: 1.5333565473556519
Validation loss: 2.1561553708968626

Epoch: 6| Step: 5
Training loss: 1.232732892036438
Validation loss: 2.1588825115593533

Epoch: 6| Step: 6
Training loss: 1.1428568363189697
Validation loss: 2.1473051732586277

Epoch: 6| Step: 7
Training loss: 1.8070757389068604
Validation loss: 2.185911786171698

Epoch: 6| Step: 8
Training loss: 1.9699674844741821
Validation loss: 2.197335466261833

Epoch: 6| Step: 9
Training loss: 1.377107858657837
Validation loss: 2.203163457173173

Epoch: 6| Step: 10
Training loss: 1.995606780052185
Validation loss: 2.1681211661267024

Epoch: 6| Step: 11
Training loss: 1.571838140487671
Validation loss: 2.1423313745888333

Epoch: 6| Step: 12
Training loss: 1.1088021993637085
Validation loss: 2.268365075511317

Epoch: 6| Step: 13
Training loss: 0.6801634430885315
Validation loss: 2.2141650466508764

Epoch: 534| Step: 0
Training loss: 1.354567050933838
Validation loss: 2.153764227385162

Epoch: 6| Step: 1
Training loss: 1.5128023624420166
Validation loss: 2.175982726517544

Epoch: 6| Step: 2
Training loss: 1.718050479888916
Validation loss: 2.1567780266525927

Epoch: 6| Step: 3
Training loss: 1.473041296005249
Validation loss: 2.221753506250279

Epoch: 6| Step: 4
Training loss: 1.373767375946045
Validation loss: 2.1328045706595145

Epoch: 6| Step: 5
Training loss: 1.73378586769104
Validation loss: 2.1570881515420894

Epoch: 6| Step: 6
Training loss: 1.1527925729751587
Validation loss: 2.1965184442458616

Epoch: 6| Step: 7
Training loss: 2.031829595565796
Validation loss: 2.224661542523292

Epoch: 6| Step: 8
Training loss: 1.0333943367004395
Validation loss: 2.23609426970123

Epoch: 6| Step: 9
Training loss: 1.0922236442565918
Validation loss: 2.1780226179348525

Epoch: 6| Step: 10
Training loss: 1.931610345840454
Validation loss: 2.2170465428342103

Epoch: 6| Step: 11
Training loss: 1.3822243213653564
Validation loss: 2.224751200727237

Epoch: 6| Step: 12
Training loss: 2.5780701637268066
Validation loss: 2.1994444977852607

Epoch: 6| Step: 13
Training loss: 1.2377599477767944
Validation loss: 2.162864003130185

Epoch: 535| Step: 0
Training loss: 1.9808218479156494
Validation loss: 2.2458015218857796

Epoch: 6| Step: 1
Training loss: 1.6941159963607788
Validation loss: 2.259177084892027

Epoch: 6| Step: 2
Training loss: 1.046123743057251
Validation loss: 2.2826021307258197

Epoch: 6| Step: 3
Training loss: 1.599423885345459
Validation loss: 2.206564695604386

Epoch: 6| Step: 4
Training loss: 1.5416134595870972
Validation loss: 2.269525547181406

Epoch: 6| Step: 5
Training loss: 1.107913613319397
Validation loss: 2.156899848291951

Epoch: 6| Step: 6
Training loss: 1.0970301628112793
Validation loss: 2.1718270368473505

Epoch: 6| Step: 7
Training loss: 2.3121540546417236
Validation loss: 2.037490088452575

Epoch: 6| Step: 8
Training loss: 2.0828566551208496
Validation loss: 2.1071947518215386

Epoch: 6| Step: 9
Training loss: 1.951509952545166
Validation loss: 2.160264063906926

Epoch: 6| Step: 10
Training loss: 1.3272664546966553
Validation loss: 2.1991709688658356

Epoch: 6| Step: 11
Training loss: 1.3365464210510254
Validation loss: 2.2001004103691346

Epoch: 6| Step: 12
Training loss: 1.0527000427246094
Validation loss: 2.1689254942760674

Epoch: 6| Step: 13
Training loss: 1.59183931350708
Validation loss: 2.2314286103812595

Epoch: 536| Step: 0
Training loss: 1.3314048051834106
Validation loss: 2.1723057608450613

Epoch: 6| Step: 1
Training loss: 1.7226192951202393
Validation loss: 2.2150328543878373

Epoch: 6| Step: 2
Training loss: 1.6028814315795898
Validation loss: 2.1886476534669117

Epoch: 6| Step: 3
Training loss: 1.6653707027435303
Validation loss: 2.118971488809073

Epoch: 6| Step: 4
Training loss: 0.9429107308387756
Validation loss: 2.1176468505654285

Epoch: 6| Step: 5
Training loss: 1.4654505252838135
Validation loss: 2.106888437783846

Epoch: 6| Step: 6
Training loss: 1.7992770671844482
Validation loss: 2.2010067842339955

Epoch: 6| Step: 7
Training loss: 1.3285033702850342
Validation loss: 2.15526177806239

Epoch: 6| Step: 8
Training loss: 1.5269222259521484
Validation loss: 2.166097107753959

Epoch: 6| Step: 9
Training loss: 1.7078828811645508
Validation loss: 2.209222608996976

Epoch: 6| Step: 10
Training loss: 2.0844619274139404
Validation loss: 2.1795156745500464

Epoch: 6| Step: 11
Training loss: 1.3333754539489746
Validation loss: 2.1314047562178744

Epoch: 6| Step: 12
Training loss: 1.68999183177948
Validation loss: 2.199289664145439

Epoch: 6| Step: 13
Training loss: 1.855933666229248
Validation loss: 2.169133376049739

Epoch: 537| Step: 0
Training loss: 1.5627150535583496
Validation loss: 2.199168961535218

Epoch: 6| Step: 1
Training loss: 2.3843321800231934
Validation loss: 2.2321341037750244

Epoch: 6| Step: 2
Training loss: 1.3940742015838623
Validation loss: 2.25606285115724

Epoch: 6| Step: 3
Training loss: 2.1571900844573975
Validation loss: 2.2347042317031534

Epoch: 6| Step: 4
Training loss: 1.2995785474777222
Validation loss: 2.1622484960863666

Epoch: 6| Step: 5
Training loss: 0.9027726650238037
Validation loss: 2.1717584248512023

Epoch: 6| Step: 6
Training loss: 0.8396453857421875
Validation loss: 2.1658520185819237

Epoch: 6| Step: 7
Training loss: 1.4914577007293701
Validation loss: 2.173377506194576

Epoch: 6| Step: 8
Training loss: 1.7747584581375122
Validation loss: 2.2712623098845124

Epoch: 6| Step: 9
Training loss: 1.2011421918869019
Validation loss: 2.231879465041622

Epoch: 6| Step: 10
Training loss: 2.060098171234131
Validation loss: 2.1693124566026913

Epoch: 6| Step: 11
Training loss: 1.5714709758758545
Validation loss: 2.1740964920290056

Epoch: 6| Step: 12
Training loss: 1.4999632835388184
Validation loss: 2.2327318370983167

Epoch: 6| Step: 13
Training loss: 1.0965148210525513
Validation loss: 2.2055217348119265

Epoch: 538| Step: 0
Training loss: 2.2093629837036133
Validation loss: 2.1861652276849233

Epoch: 6| Step: 1
Training loss: 2.2956271171569824
Validation loss: 2.2081084174494587

Epoch: 6| Step: 2
Training loss: 1.4479883909225464
Validation loss: 2.2056519908289753

Epoch: 6| Step: 3
Training loss: 1.7590501308441162
Validation loss: 2.1253731058489893

Epoch: 6| Step: 4
Training loss: 1.669053316116333
Validation loss: 2.2557787664474978

Epoch: 6| Step: 5
Training loss: 1.234547734260559
Validation loss: 2.160901423423521

Epoch: 6| Step: 6
Training loss: 1.3192949295043945
Validation loss: 2.175213554854034

Epoch: 6| Step: 7
Training loss: 1.2623628377914429
Validation loss: 2.166284015101771

Epoch: 6| Step: 8
Training loss: 1.4367189407348633
Validation loss: 2.165655835982292

Epoch: 6| Step: 9
Training loss: 1.4099295139312744
Validation loss: 2.225965215313819

Epoch: 6| Step: 10
Training loss: 1.5077955722808838
Validation loss: 2.1730109491655902

Epoch: 6| Step: 11
Training loss: 1.9917367696762085
Validation loss: 2.1602714241191907

Epoch: 6| Step: 12
Training loss: 1.1104023456573486
Validation loss: 2.1123822158382786

Epoch: 6| Step: 13
Training loss: 1.4846867322921753
Validation loss: 2.1709260658551286

Epoch: 539| Step: 0
Training loss: 2.0361478328704834
Validation loss: 2.204474628612559

Epoch: 6| Step: 1
Training loss: 1.7020453214645386
Validation loss: 2.1961078989890312

Epoch: 6| Step: 2
Training loss: 1.3677027225494385
Validation loss: 2.2032925287882485

Epoch: 6| Step: 3
Training loss: 1.7872775793075562
Validation loss: 2.2071680868825605

Epoch: 6| Step: 4
Training loss: 1.3170042037963867
Validation loss: 2.152974551723849

Epoch: 6| Step: 5
Training loss: 1.755120038986206
Validation loss: 2.239839187232397

Epoch: 6| Step: 6
Training loss: 2.3019232749938965
Validation loss: 2.2305850623756327

Epoch: 6| Step: 7
Training loss: 1.3438489437103271
Validation loss: 2.131291840666084

Epoch: 6| Step: 8
Training loss: 1.1719748973846436
Validation loss: 2.186680060560985

Epoch: 6| Step: 9
Training loss: 1.4424526691436768
Validation loss: 2.1819578524558776

Epoch: 6| Step: 10
Training loss: 1.6440967321395874
Validation loss: 2.2769580630845923

Epoch: 6| Step: 11
Training loss: 0.7535400390625
Validation loss: 2.2384872308341404

Epoch: 6| Step: 12
Training loss: 1.173397421836853
Validation loss: 2.244696447926183

Epoch: 6| Step: 13
Training loss: 2.0943245887756348
Validation loss: 2.1815841095421904

Epoch: 540| Step: 0
Training loss: 1.1788805723190308
Validation loss: 2.2809035854954876

Epoch: 6| Step: 1
Training loss: 1.3588354587554932
Validation loss: 2.1682125253062092

Epoch: 6| Step: 2
Training loss: 1.8592867851257324
Validation loss: 2.1939354827327113

Epoch: 6| Step: 3
Training loss: 1.4339370727539062
Validation loss: 2.2394031581058296

Epoch: 6| Step: 4
Training loss: 1.4629926681518555
Validation loss: 2.1721442066213137

Epoch: 6| Step: 5
Training loss: 0.9473885297775269
Validation loss: 2.149278647156172

Epoch: 6| Step: 6
Training loss: 1.5022482872009277
Validation loss: 2.222187690837409

Epoch: 6| Step: 7
Training loss: 1.7573862075805664
Validation loss: 2.190333902194936

Epoch: 6| Step: 8
Training loss: 1.5418615341186523
Validation loss: 2.1853136170294976

Epoch: 6| Step: 9
Training loss: 1.3945789337158203
Validation loss: 2.1421484370385446

Epoch: 6| Step: 10
Training loss: 2.3903472423553467
Validation loss: 2.1452290422172955

Epoch: 6| Step: 11
Training loss: 1.2602946758270264
Validation loss: 2.1026644552907636

Epoch: 6| Step: 12
Training loss: 1.2574713230133057
Validation loss: 2.228719196011943

Epoch: 6| Step: 13
Training loss: 1.7560585737228394
Validation loss: 2.1242622419070174

Epoch: 541| Step: 0
Training loss: 1.0695927143096924
Validation loss: 2.1564675261897426

Epoch: 6| Step: 1
Training loss: 1.0591645240783691
Validation loss: 2.087622745062715

Epoch: 6| Step: 2
Training loss: 1.8606065511703491
Validation loss: 2.1527200155360724

Epoch: 6| Step: 3
Training loss: 1.8904293775558472
Validation loss: 2.1953702049870647

Epoch: 6| Step: 4
Training loss: 1.7081389427185059
Validation loss: 2.12782379375991

Epoch: 6| Step: 5
Training loss: 1.0092509984970093
Validation loss: 2.1943892458433747

Epoch: 6| Step: 6
Training loss: 1.4473987817764282
Validation loss: 2.1920779623011106

Epoch: 6| Step: 7
Training loss: 1.3384140729904175
Validation loss: 2.1615943447236092

Epoch: 6| Step: 8
Training loss: 1.539292335510254
Validation loss: 2.246194131912724

Epoch: 6| Step: 9
Training loss: 1.6682648658752441
Validation loss: 2.20839548367326

Epoch: 6| Step: 10
Training loss: 1.6962872743606567
Validation loss: 2.1517878886192077

Epoch: 6| Step: 11
Training loss: 1.6005609035491943
Validation loss: 2.1813863503035678

Epoch: 6| Step: 12
Training loss: 3.0787625312805176
Validation loss: 2.173134555098831

Epoch: 6| Step: 13
Training loss: 0.6464312076568604
Validation loss: 2.222700044672976

Epoch: 542| Step: 0
Training loss: 1.4726817607879639
Validation loss: 2.156850181600099

Epoch: 6| Step: 1
Training loss: 1.7083522081375122
Validation loss: 2.0959484897634035

Epoch: 6| Step: 2
Training loss: 1.6087646484375
Validation loss: 2.165714716398588

Epoch: 6| Step: 3
Training loss: 1.445370078086853
Validation loss: 2.1846820128861295

Epoch: 6| Step: 4
Training loss: 1.2215518951416016
Validation loss: 2.2271125290983464

Epoch: 6| Step: 5
Training loss: 2.0381007194519043
Validation loss: 2.1954466758235807

Epoch: 6| Step: 6
Training loss: 1.3045833110809326
Validation loss: 2.270537103376081

Epoch: 6| Step: 7
Training loss: 1.3289616107940674
Validation loss: 2.1555941579162434

Epoch: 6| Step: 8
Training loss: 1.5028295516967773
Validation loss: 2.134780015996707

Epoch: 6| Step: 9
Training loss: 1.493535041809082
Validation loss: 2.1931364638831026

Epoch: 6| Step: 10
Training loss: 1.8911112546920776
Validation loss: 2.2075792768950104

Epoch: 6| Step: 11
Training loss: 1.0735280513763428
Validation loss: 2.157481719088811

Epoch: 6| Step: 12
Training loss: 1.902766227722168
Validation loss: 2.1901431237497637

Epoch: 6| Step: 13
Training loss: 1.5513181686401367
Validation loss: 2.2396347522735596

Epoch: 543| Step: 0
Training loss: 1.8773428201675415
Validation loss: 2.1361678351638136

Epoch: 6| Step: 1
Training loss: 1.9941942691802979
Validation loss: 2.225649320951072

Epoch: 6| Step: 2
Training loss: 1.6018664836883545
Validation loss: 2.2689525799084733

Epoch: 6| Step: 3
Training loss: 1.264531135559082
Validation loss: 2.219393468672229

Epoch: 6| Step: 4
Training loss: 1.3887910842895508
Validation loss: 2.166837585869656

Epoch: 6| Step: 5
Training loss: 1.6564245223999023
Validation loss: 2.276312833191246

Epoch: 6| Step: 6
Training loss: 1.718761682510376
Validation loss: 2.2024184196226058

Epoch: 6| Step: 7
Training loss: 1.336595058441162
Validation loss: 2.2455293311867663

Epoch: 6| Step: 8
Training loss: 1.584520936012268
Validation loss: 2.187416233042235

Epoch: 6| Step: 9
Training loss: 1.2308411598205566
Validation loss: 2.241496718058022

Epoch: 6| Step: 10
Training loss: 1.3199729919433594
Validation loss: 2.2460422644051175

Epoch: 6| Step: 11
Training loss: 1.6112982034683228
Validation loss: 2.2748368158135364

Epoch: 6| Step: 12
Training loss: 1.0325407981872559
Validation loss: 2.0982180615907073

Epoch: 6| Step: 13
Training loss: 1.8456594944000244
Validation loss: 2.1965214385781238

Epoch: 544| Step: 0
Training loss: 1.5393270254135132
Validation loss: 2.2019036059738486

Epoch: 6| Step: 1
Training loss: 1.1710096597671509
Validation loss: 2.1983342721898067

Epoch: 6| Step: 2
Training loss: 1.7124706506729126
Validation loss: 2.1447614726199897

Epoch: 6| Step: 3
Training loss: 1.076884150505066
Validation loss: 2.1668672625736525

Epoch: 6| Step: 4
Training loss: 2.364143133163452
Validation loss: 2.1516966947945217

Epoch: 6| Step: 5
Training loss: 1.6963484287261963
Validation loss: 2.1868055623064757

Epoch: 6| Step: 6
Training loss: 1.2164127826690674
Validation loss: 2.147104104359945

Epoch: 6| Step: 7
Training loss: 1.8841309547424316
Validation loss: 2.1560613339947117

Epoch: 6| Step: 8
Training loss: 1.4063538312911987
Validation loss: 2.2004773462972333

Epoch: 6| Step: 9
Training loss: 1.6437668800354004
Validation loss: 2.2108198904222056

Epoch: 6| Step: 10
Training loss: 1.660719633102417
Validation loss: 2.1871010103533344

Epoch: 6| Step: 11
Training loss: 1.4599452018737793
Validation loss: 2.1554180716955536

Epoch: 6| Step: 12
Training loss: 1.5964672565460205
Validation loss: 2.1809424713093746

Epoch: 6| Step: 13
Training loss: 0.7709166407585144
Validation loss: 2.139734255370273

Epoch: 545| Step: 0
Training loss: 1.3528926372528076
Validation loss: 2.179066232455674

Epoch: 6| Step: 1
Training loss: 1.8509838581085205
Validation loss: 2.1819075102447183

Epoch: 6| Step: 2
Training loss: 1.1670024394989014
Validation loss: 2.1120440242111043

Epoch: 6| Step: 3
Training loss: 1.3548569679260254
Validation loss: 2.2547392140152636

Epoch: 6| Step: 4
Training loss: 1.7480030059814453
Validation loss: 2.201840466068637

Epoch: 6| Step: 5
Training loss: 1.395499587059021
Validation loss: 2.150648142701836

Epoch: 6| Step: 6
Training loss: 1.5411198139190674
Validation loss: 2.222037714014771

Epoch: 6| Step: 7
Training loss: 1.9136950969696045
Validation loss: 2.248164141049949

Epoch: 6| Step: 8
Training loss: 1.595064401626587
Validation loss: 2.1450866358254546

Epoch: 6| Step: 9
Training loss: 1.9596688747406006
Validation loss: 2.209022234844905

Epoch: 6| Step: 10
Training loss: 0.8952738046646118
Validation loss: 2.1756782262556014

Epoch: 6| Step: 11
Training loss: 1.1323366165161133
Validation loss: 2.2446749184721257

Epoch: 6| Step: 12
Training loss: 1.6702754497528076
Validation loss: 2.202561333615293

Epoch: 6| Step: 13
Training loss: 1.977406620979309
Validation loss: 2.2233135072133874

Epoch: 546| Step: 0
Training loss: 0.9366431832313538
Validation loss: 2.2467797135794036

Epoch: 6| Step: 1
Training loss: 1.271047592163086
Validation loss: 2.2496720770353913

Epoch: 6| Step: 2
Training loss: 1.2480642795562744
Validation loss: 2.2696374077950754

Epoch: 6| Step: 3
Training loss: 1.4819912910461426
Validation loss: 2.1745096150264946

Epoch: 6| Step: 4
Training loss: 1.3590123653411865
Validation loss: 2.174599188630299

Epoch: 6| Step: 5
Training loss: 1.6802257299423218
Validation loss: 2.2320001381699757

Epoch: 6| Step: 6
Training loss: 1.3051564693450928
Validation loss: 2.149188321123841

Epoch: 6| Step: 7
Training loss: 1.282977819442749
Validation loss: 2.1687706516635035

Epoch: 6| Step: 8
Training loss: 2.0981504917144775
Validation loss: 2.2111858578138452

Epoch: 6| Step: 9
Training loss: 1.5794894695281982
Validation loss: 2.199779798907618

Epoch: 6| Step: 10
Training loss: 2.100895881652832
Validation loss: 2.173716750196231

Epoch: 6| Step: 11
Training loss: 1.1787540912628174
Validation loss: 2.153601327250081

Epoch: 6| Step: 12
Training loss: 1.5620843172073364
Validation loss: 2.1664366081196773

Epoch: 6| Step: 13
Training loss: 1.9478925466537476
Validation loss: 2.2398960398089502

Epoch: 547| Step: 0
Training loss: 1.3002269268035889
Validation loss: 2.2632505739888837

Epoch: 6| Step: 1
Training loss: 1.469956636428833
Validation loss: 2.2537633565164383

Epoch: 6| Step: 2
Training loss: 1.9007560014724731
Validation loss: 2.218423192219068

Epoch: 6| Step: 3
Training loss: 1.1616194248199463
Validation loss: 2.1481499543754

Epoch: 6| Step: 4
Training loss: 1.761327862739563
Validation loss: 2.1814220746358237

Epoch: 6| Step: 5
Training loss: 1.9425432682037354
Validation loss: 2.142957745059844

Epoch: 6| Step: 6
Training loss: 1.20504629611969
Validation loss: 2.1908936705640567

Epoch: 6| Step: 7
Training loss: 1.8099573850631714
Validation loss: 2.1064008000076457

Epoch: 6| Step: 8
Training loss: 1.3167208433151245
Validation loss: 2.1506655434126496

Epoch: 6| Step: 9
Training loss: 1.704310655593872
Validation loss: 2.0652225043184016

Epoch: 6| Step: 10
Training loss: 1.522559642791748
Validation loss: 2.199600622218142

Epoch: 6| Step: 11
Training loss: 1.1382756233215332
Validation loss: 2.160145410927393

Epoch: 6| Step: 12
Training loss: 1.384925127029419
Validation loss: 2.2203895686775126

Epoch: 6| Step: 13
Training loss: 1.27512526512146
Validation loss: 2.164898098156016

Epoch: 548| Step: 0
Training loss: 1.394923210144043
Validation loss: 2.111232893441313

Epoch: 6| Step: 1
Training loss: 1.5642695426940918
Validation loss: 2.1849236488342285

Epoch: 6| Step: 2
Training loss: 1.798019289970398
Validation loss: 2.1108733197694183

Epoch: 6| Step: 3
Training loss: 1.6779253482818604
Validation loss: 2.1869759264812676

Epoch: 6| Step: 4
Training loss: 1.367732048034668
Validation loss: 2.176539500554403

Epoch: 6| Step: 5
Training loss: 2.416299819946289
Validation loss: 2.1705017192389375

Epoch: 6| Step: 6
Training loss: 1.3342620134353638
Validation loss: 2.221218442404142

Epoch: 6| Step: 7
Training loss: 1.226426362991333
Validation loss: 2.2275310947049047

Epoch: 6| Step: 8
Training loss: 1.6458886861801147
Validation loss: 2.201436017149238

Epoch: 6| Step: 9
Training loss: 1.435276746749878
Validation loss: 2.194920237346362

Epoch: 6| Step: 10
Training loss: 1.3602402210235596
Validation loss: 2.123842285525414

Epoch: 6| Step: 11
Training loss: 1.2710497379302979
Validation loss: 2.195973486028692

Epoch: 6| Step: 12
Training loss: 1.635917067527771
Validation loss: 2.1744256634866037

Epoch: 6| Step: 13
Training loss: 0.89500892162323
Validation loss: 2.3019738863873225

Epoch: 549| Step: 0
Training loss: 1.4453849792480469
Validation loss: 2.2377312414107786

Epoch: 6| Step: 1
Training loss: 1.6255048513412476
Validation loss: 2.1485398328432472

Epoch: 6| Step: 2
Training loss: 0.9903577566146851
Validation loss: 2.154443394753241

Epoch: 6| Step: 3
Training loss: 1.5455033779144287
Validation loss: 2.159476021284698

Epoch: 6| Step: 4
Training loss: 1.1232011318206787
Validation loss: 2.0841945986593924

Epoch: 6| Step: 5
Training loss: 1.7592946290969849
Validation loss: 2.1491083227178103

Epoch: 6| Step: 6
Training loss: 1.1824508905410767
Validation loss: 2.276265219975543

Epoch: 6| Step: 7
Training loss: 1.7545393705368042
Validation loss: 2.244359626564928

Epoch: 6| Step: 8
Training loss: 1.1413344144821167
Validation loss: 2.215149817928191

Epoch: 6| Step: 9
Training loss: 1.9537677764892578
Validation loss: 2.2957923130322526

Epoch: 6| Step: 10
Training loss: 2.673306941986084
Validation loss: 2.192481271682247

Epoch: 6| Step: 11
Training loss: 1.1050317287445068
Validation loss: 2.154287399784211

Epoch: 6| Step: 12
Training loss: 1.2330639362335205
Validation loss: 2.221001822461364

Epoch: 6| Step: 13
Training loss: 1.686108112335205
Validation loss: 2.2149544095480316

Epoch: 550| Step: 0
Training loss: 1.4511542320251465
Validation loss: 2.211466463663245

Epoch: 6| Step: 1
Training loss: 1.3111753463745117
Validation loss: 2.1996565390658636

Epoch: 6| Step: 2
Training loss: 1.9485526084899902
Validation loss: 2.1727060925575996

Epoch: 6| Step: 3
Training loss: 1.019329309463501
Validation loss: 2.177892828500399

Epoch: 6| Step: 4
Training loss: 1.3425374031066895
Validation loss: 2.190520060959683

Epoch: 6| Step: 5
Training loss: 0.9400712847709656
Validation loss: 2.223887664015575

Epoch: 6| Step: 6
Training loss: 1.6134649515151978
Validation loss: 2.20177548931491

Epoch: 6| Step: 7
Training loss: 1.686482310295105
Validation loss: 2.173098987148654

Epoch: 6| Step: 8
Training loss: 1.5992896556854248
Validation loss: 2.209420034962316

Epoch: 6| Step: 9
Training loss: 1.812807321548462
Validation loss: 2.2366061902815297

Epoch: 6| Step: 10
Training loss: 1.366638422012329
Validation loss: 2.278284110048766

Epoch: 6| Step: 11
Training loss: 1.3879743814468384
Validation loss: 2.120715762979241

Epoch: 6| Step: 12
Training loss: 1.6013364791870117
Validation loss: 2.143602576307071

Epoch: 6| Step: 13
Training loss: 1.4247270822525024
Validation loss: 2.2895268547919487

Epoch: 551| Step: 0
Training loss: 1.833380103111267
Validation loss: 2.222142611780474

Epoch: 6| Step: 1
Training loss: 2.477003574371338
Validation loss: 2.1336793463717223

Epoch: 6| Step: 2
Training loss: 1.8275725841522217
Validation loss: 2.226188216158139

Epoch: 6| Step: 3
Training loss: 1.657094120979309
Validation loss: 2.171614711002637

Epoch: 6| Step: 4
Training loss: 1.3551768064498901
Validation loss: 2.2450508456076346

Epoch: 6| Step: 5
Training loss: 1.1572754383087158
Validation loss: 2.195791011215538

Epoch: 6| Step: 6
Training loss: 1.2192950248718262
Validation loss: 2.1331031194297214

Epoch: 6| Step: 7
Training loss: 1.8377290964126587
Validation loss: 2.178070322159798

Epoch: 6| Step: 8
Training loss: 0.9665580987930298
Validation loss: 2.164284957352505

Epoch: 6| Step: 9
Training loss: 1.3480736017227173
Validation loss: 2.1588333896411362

Epoch: 6| Step: 10
Training loss: 1.3351503610610962
Validation loss: 2.192460037046863

Epoch: 6| Step: 11
Training loss: 1.5216374397277832
Validation loss: 2.1841644446055093

Epoch: 6| Step: 12
Training loss: 1.5800025463104248
Validation loss: 2.161381261323088

Epoch: 6| Step: 13
Training loss: 1.6768296957015991
Validation loss: 2.1566829681396484

Epoch: 552| Step: 0
Training loss: 1.0114412307739258
Validation loss: 2.2021845168964838

Epoch: 6| Step: 1
Training loss: 1.2880616188049316
Validation loss: 2.2498218628668014

Epoch: 6| Step: 2
Training loss: 1.7876851558685303
Validation loss: 2.186090482178555

Epoch: 6| Step: 3
Training loss: 1.6691665649414062
Validation loss: 2.2195782379437516

Epoch: 6| Step: 4
Training loss: 1.9297269582748413
Validation loss: 2.0770983849802325

Epoch: 6| Step: 5
Training loss: 1.674267053604126
Validation loss: 2.1391747074742473

Epoch: 6| Step: 6
Training loss: 1.0658466815948486
Validation loss: 2.191388121215246

Epoch: 6| Step: 7
Training loss: 2.606837034225464
Validation loss: 2.21282426516215

Epoch: 6| Step: 8
Training loss: 1.420034646987915
Validation loss: 2.2011550395719466

Epoch: 6| Step: 9
Training loss: 1.172742486000061
Validation loss: 2.20730520063831

Epoch: 6| Step: 10
Training loss: 1.2626097202301025
Validation loss: 2.2093174970278175

Epoch: 6| Step: 11
Training loss: 1.422471523284912
Validation loss: 2.169424100588727

Epoch: 6| Step: 12
Training loss: 1.2147048711776733
Validation loss: 2.2585562429120465

Epoch: 6| Step: 13
Training loss: 1.1067719459533691
Validation loss: 2.163143765541815

Epoch: 553| Step: 0
Training loss: 1.5110771656036377
Validation loss: 2.1490245249963578

Epoch: 6| Step: 1
Training loss: 1.4068447351455688
Validation loss: 2.228692605931272

Epoch: 6| Step: 2
Training loss: 1.4099326133728027
Validation loss: 2.1043592191511586

Epoch: 6| Step: 3
Training loss: 1.6105008125305176
Validation loss: 2.174273972870201

Epoch: 6| Step: 4
Training loss: 1.4006601572036743
Validation loss: 2.21162768589553

Epoch: 6| Step: 5
Training loss: 0.8883233666419983
Validation loss: 2.148135849224624

Epoch: 6| Step: 6
Training loss: 2.1870131492614746
Validation loss: 2.1595567836556384

Epoch: 6| Step: 7
Training loss: 1.8012354373931885
Validation loss: 2.121637828888432

Epoch: 6| Step: 8
Training loss: 1.1911895275115967
Validation loss: 2.1675412834331556

Epoch: 6| Step: 9
Training loss: 2.0193357467651367
Validation loss: 2.1896771205368863

Epoch: 6| Step: 10
Training loss: 1.3022924661636353
Validation loss: 2.153480774612837

Epoch: 6| Step: 11
Training loss: 1.417744517326355
Validation loss: 2.2176018222685783

Epoch: 6| Step: 12
Training loss: 1.1771697998046875
Validation loss: 2.179044573537765

Epoch: 6| Step: 13
Training loss: 1.3011082410812378
Validation loss: 2.1850237820738103

Epoch: 554| Step: 0
Training loss: 1.9555444717407227
Validation loss: 2.242810533892724

Epoch: 6| Step: 1
Training loss: 1.3048088550567627
Validation loss: 2.2466271949070755

Epoch: 6| Step: 2
Training loss: 1.697127342224121
Validation loss: 2.1519751164220993

Epoch: 6| Step: 3
Training loss: 1.1498581171035767
Validation loss: 2.182527338304827

Epoch: 6| Step: 4
Training loss: 1.2020938396453857
Validation loss: 2.2393190963293916

Epoch: 6| Step: 5
Training loss: 1.2746864557266235
Validation loss: 2.2330059595005487

Epoch: 6| Step: 6
Training loss: 1.5592424869537354
Validation loss: 2.1689498001529324

Epoch: 6| Step: 7
Training loss: 1.2915120124816895
Validation loss: 2.1709605724580827

Epoch: 6| Step: 8
Training loss: 1.5464982986450195
Validation loss: 2.1228646873145975

Epoch: 6| Step: 9
Training loss: 1.5406122207641602
Validation loss: 2.1530342589142504

Epoch: 6| Step: 10
Training loss: 1.697692632675171
Validation loss: 2.235266931595341

Epoch: 6| Step: 11
Training loss: 1.642611026763916
Validation loss: 2.1367135432458695

Epoch: 6| Step: 12
Training loss: 1.707205057144165
Validation loss: 2.2515055338541665

Epoch: 6| Step: 13
Training loss: 1.510805606842041
Validation loss: 2.194191123849602

Epoch: 555| Step: 0
Training loss: 1.3531606197357178
Validation loss: 2.134618325900006

Epoch: 6| Step: 1
Training loss: 1.8368130922317505
Validation loss: 2.098543115841445

Epoch: 6| Step: 2
Training loss: 1.6414220333099365
Validation loss: 2.1945854527975923

Epoch: 6| Step: 3
Training loss: 1.0614700317382812
Validation loss: 2.1670866422755743

Epoch: 6| Step: 4
Training loss: 1.9688353538513184
Validation loss: 2.2237588654282274

Epoch: 6| Step: 5
Training loss: 1.5250611305236816
Validation loss: 2.2101785085534535

Epoch: 6| Step: 6
Training loss: 1.3877586126327515
Validation loss: 2.233497791392829

Epoch: 6| Step: 7
Training loss: 1.1332329511642456
Validation loss: 2.2135235007091234

Epoch: 6| Step: 8
Training loss: 1.4530426263809204
Validation loss: 2.2008906141404183

Epoch: 6| Step: 9
Training loss: 2.230898141860962
Validation loss: 2.1574726117554532

Epoch: 6| Step: 10
Training loss: 2.134580612182617
Validation loss: 2.1755485047576246

Epoch: 6| Step: 11
Training loss: 1.1213922500610352
Validation loss: 2.165907636765511

Epoch: 6| Step: 12
Training loss: 1.395668864250183
Validation loss: 2.1864607667410247

Epoch: 6| Step: 13
Training loss: 1.526811122894287
Validation loss: 2.122029668541365

Epoch: 556| Step: 0
Training loss: 1.1967558860778809
Validation loss: 2.1674821851074055

Epoch: 6| Step: 1
Training loss: 1.2032057046890259
Validation loss: 2.1542545441658265

Epoch: 6| Step: 2
Training loss: 2.1295130252838135
Validation loss: 2.2501504267415693

Epoch: 6| Step: 3
Training loss: 1.245977759361267
Validation loss: 2.207184217309439

Epoch: 6| Step: 4
Training loss: 1.6943631172180176
Validation loss: 2.137815538273063

Epoch: 6| Step: 5
Training loss: 1.7120003700256348
Validation loss: 2.173942547972484

Epoch: 6| Step: 6
Training loss: 0.9355378150939941
Validation loss: 2.144625976521482

Epoch: 6| Step: 7
Training loss: 1.6628369092941284
Validation loss: 2.28707556827094

Epoch: 6| Step: 8
Training loss: 1.913696050643921
Validation loss: 2.1720320550344323

Epoch: 6| Step: 9
Training loss: 1.2463876008987427
Validation loss: 2.1613673471635386

Epoch: 6| Step: 10
Training loss: 1.0555603504180908
Validation loss: 2.093460500881236

Epoch: 6| Step: 11
Training loss: 1.376695156097412
Validation loss: 2.254675490881807

Epoch: 6| Step: 12
Training loss: 1.8419177532196045
Validation loss: 2.1383880389634

Epoch: 6| Step: 13
Training loss: 2.211040735244751
Validation loss: 2.2038510627644037

Epoch: 557| Step: 0
Training loss: 1.1701377630233765
Validation loss: 2.130219740252341

Epoch: 6| Step: 1
Training loss: 2.199345111846924
Validation loss: 2.185963316630292

Epoch: 6| Step: 2
Training loss: 1.6008974313735962
Validation loss: 2.225359530859096

Epoch: 6| Step: 3
Training loss: 1.1382311582565308
Validation loss: 2.2365036164560625

Epoch: 6| Step: 4
Training loss: 2.062504768371582
Validation loss: 2.2347880896701606

Epoch: 6| Step: 5
Training loss: 1.7009813785552979
Validation loss: 2.171779486440843

Epoch: 6| Step: 6
Training loss: 1.9428986310958862
Validation loss: 2.2050571621105237

Epoch: 6| Step: 7
Training loss: 1.392573356628418
Validation loss: 2.15453702147289

Epoch: 6| Step: 8
Training loss: 1.855563759803772
Validation loss: 2.1377451471103135

Epoch: 6| Step: 9
Training loss: 1.189921259880066
Validation loss: 2.1643492073141117

Epoch: 6| Step: 10
Training loss: 1.2285934686660767
Validation loss: 2.280999029836347

Epoch: 6| Step: 11
Training loss: 0.783315122127533
Validation loss: 2.1755811142665085

Epoch: 6| Step: 12
Training loss: 1.2318609952926636
Validation loss: 2.1672109967918805

Epoch: 6| Step: 13
Training loss: 1.5868570804595947
Validation loss: 2.255001647498018

Epoch: 558| Step: 0
Training loss: 1.7822308540344238
Validation loss: 2.177155061434674

Epoch: 6| Step: 1
Training loss: 1.4588406085968018
Validation loss: 2.202623939001432

Epoch: 6| Step: 2
Training loss: 1.4743821620941162
Validation loss: 2.157605125058082

Epoch: 6| Step: 3
Training loss: 1.3096742630004883
Validation loss: 2.237477482006114

Epoch: 6| Step: 4
Training loss: 1.2802109718322754
Validation loss: 2.2099281177725842

Epoch: 6| Step: 5
Training loss: 1.902847409248352
Validation loss: 2.2366610855184574

Epoch: 6| Step: 6
Training loss: 1.97591233253479
Validation loss: 2.184380959439021

Epoch: 6| Step: 7
Training loss: 1.6129685640335083
Validation loss: 2.1866918238260413

Epoch: 6| Step: 8
Training loss: 1.0971163511276245
Validation loss: 2.179685290141772

Epoch: 6| Step: 9
Training loss: 1.1778559684753418
Validation loss: 2.20995601530998

Epoch: 6| Step: 10
Training loss: 1.589221715927124
Validation loss: 2.1699013146021033

Epoch: 6| Step: 11
Training loss: 1.5560331344604492
Validation loss: 2.2027346241858696

Epoch: 6| Step: 12
Training loss: 0.8212040662765503
Validation loss: 2.1823387940724692

Epoch: 6| Step: 13
Training loss: 1.4827213287353516
Validation loss: 2.1937117474053496

Epoch: 559| Step: 0
Training loss: 1.3289930820465088
Validation loss: 2.1773711917220906

Epoch: 6| Step: 1
Training loss: 1.025557518005371
Validation loss: 2.1263600857027116

Epoch: 6| Step: 2
Training loss: 1.1755855083465576
Validation loss: 2.1779048314658542

Epoch: 6| Step: 3
Training loss: 1.3566625118255615
Validation loss: 2.1508447636840162

Epoch: 6| Step: 4
Training loss: 1.344881296157837
Validation loss: 2.106639982551657

Epoch: 6| Step: 5
Training loss: 1.6081736087799072
Validation loss: 2.1757320075906734

Epoch: 6| Step: 6
Training loss: 1.2774698734283447
Validation loss: 2.1253964926606868

Epoch: 6| Step: 7
Training loss: 1.8948326110839844
Validation loss: 2.164080942830732

Epoch: 6| Step: 8
Training loss: 1.5683143138885498
Validation loss: 2.1724610738856818

Epoch: 6| Step: 9
Training loss: 2.025872230529785
Validation loss: 2.1268599238446964

Epoch: 6| Step: 10
Training loss: 1.9845378398895264
Validation loss: 2.237195872491406

Epoch: 6| Step: 11
Training loss: 1.3993890285491943
Validation loss: 2.1420202819249963

Epoch: 6| Step: 12
Training loss: 1.1772183179855347
Validation loss: 2.0890228363775436

Epoch: 6| Step: 13
Training loss: 1.9415065050125122
Validation loss: 2.2301923023757113

Epoch: 560| Step: 0
Training loss: 1.4658682346343994
Validation loss: 2.1633562323867634

Epoch: 6| Step: 1
Training loss: 1.5462019443511963
Validation loss: 2.1423373299260295

Epoch: 6| Step: 2
Training loss: 1.881009578704834
Validation loss: 2.059829483750046

Epoch: 6| Step: 3
Training loss: 0.9341341257095337
Validation loss: 2.148324235793083

Epoch: 6| Step: 4
Training loss: 1.054835319519043
Validation loss: 2.2255225079033965

Epoch: 6| Step: 5
Training loss: 1.6536695957183838
Validation loss: 2.231639918460641

Epoch: 6| Step: 6
Training loss: 1.0423414707183838
Validation loss: 2.1508070038210962

Epoch: 6| Step: 7
Training loss: 1.7443126440048218
Validation loss: 2.1635880829185568

Epoch: 6| Step: 8
Training loss: 1.8516391515731812
Validation loss: 2.1713629435467463

Epoch: 6| Step: 9
Training loss: 1.6246516704559326
Validation loss: 2.2315499462107176

Epoch: 6| Step: 10
Training loss: 2.1081929206848145
Validation loss: 2.2052332560221353

Epoch: 6| Step: 11
Training loss: 2.1443943977355957
Validation loss: 2.1838052452251477

Epoch: 6| Step: 12
Training loss: 1.3597774505615234
Validation loss: 2.212111493592621

Epoch: 6| Step: 13
Training loss: 1.574210524559021
Validation loss: 2.179601518056726

Epoch: 561| Step: 0
Training loss: 0.7590782642364502
Validation loss: 2.165375949234091

Epoch: 6| Step: 1
Training loss: 2.0386314392089844
Validation loss: 2.2525154570097565

Epoch: 6| Step: 2
Training loss: 1.2192668914794922
Validation loss: 2.195111956647647

Epoch: 6| Step: 3
Training loss: 1.9476914405822754
Validation loss: 2.1205590950545443

Epoch: 6| Step: 4
Training loss: 1.849122166633606
Validation loss: 2.1167590656588153

Epoch: 6| Step: 5
Training loss: 1.755582571029663
Validation loss: 2.141731180170531

Epoch: 6| Step: 6
Training loss: 2.0290634632110596
Validation loss: 2.1217928932559107

Epoch: 6| Step: 7
Training loss: 1.1206512451171875
Validation loss: 2.1759194712485037

Epoch: 6| Step: 8
Training loss: 1.2709033489227295
Validation loss: 2.207110039649471

Epoch: 6| Step: 9
Training loss: 1.0699710845947266
Validation loss: 2.0744769406575028

Epoch: 6| Step: 10
Training loss: 1.1727849245071411
Validation loss: 2.2101163915408555

Epoch: 6| Step: 11
Training loss: 1.737084150314331
Validation loss: 2.2272119599003948

Epoch: 6| Step: 12
Training loss: 1.1340692043304443
Validation loss: 2.2192818272498345

Epoch: 6| Step: 13
Training loss: 1.619673490524292
Validation loss: 2.1626453092021327

Epoch: 562| Step: 0
Training loss: 1.454664945602417
Validation loss: 2.2216614548878004

Epoch: 6| Step: 1
Training loss: 1.8413314819335938
Validation loss: 2.1728760965408815

Epoch: 6| Step: 2
Training loss: 1.0932525396347046
Validation loss: 2.1998105946407525

Epoch: 6| Step: 3
Training loss: 1.7942938804626465
Validation loss: 2.087572254160399

Epoch: 6| Step: 4
Training loss: 2.064480781555176
Validation loss: 2.167396563355641

Epoch: 6| Step: 5
Training loss: 2.0724856853485107
Validation loss: 2.167025931419865

Epoch: 6| Step: 6
Training loss: 1.5598199367523193
Validation loss: 2.146156185416765

Epoch: 6| Step: 7
Training loss: 1.1937265396118164
Validation loss: 2.1866296209314817

Epoch: 6| Step: 8
Training loss: 1.2779487371444702
Validation loss: 2.1535456308754544

Epoch: 6| Step: 9
Training loss: 0.9989050626754761
Validation loss: 2.162860116650981

Epoch: 6| Step: 10
Training loss: 1.5089167356491089
Validation loss: 2.209082034326369

Epoch: 6| Step: 11
Training loss: 1.5926998853683472
Validation loss: 2.1629483840798818

Epoch: 6| Step: 12
Training loss: 0.8525897264480591
Validation loss: 2.2028526336916032

Epoch: 6| Step: 13
Training loss: 0.6340667009353638
Validation loss: 2.24271063394444

Epoch: 563| Step: 0
Training loss: 1.6782560348510742
Validation loss: 2.146840439047865

Epoch: 6| Step: 1
Training loss: 1.1185249090194702
Validation loss: 2.1702037883061234

Epoch: 6| Step: 2
Training loss: 0.9365469813346863
Validation loss: 2.1783208385590584

Epoch: 6| Step: 3
Training loss: 1.1908771991729736
Validation loss: 2.2138630587567567

Epoch: 6| Step: 4
Training loss: 1.0266613960266113
Validation loss: 2.129593356963127

Epoch: 6| Step: 5
Training loss: 1.2372243404388428
Validation loss: 2.1688209118381625

Epoch: 6| Step: 6
Training loss: 1.4837265014648438
Validation loss: 2.1283593523886895

Epoch: 6| Step: 7
Training loss: 1.7583191394805908
Validation loss: 2.1597069783877303

Epoch: 6| Step: 8
Training loss: 1.3502883911132812
Validation loss: 2.284583230172434

Epoch: 6| Step: 9
Training loss: 1.9286351203918457
Validation loss: 2.2293493516983522

Epoch: 6| Step: 10
Training loss: 1.4793975353240967
Validation loss: 2.199973475548529

Epoch: 6| Step: 11
Training loss: 2.2158241271972656
Validation loss: 2.177911807132024

Epoch: 6| Step: 12
Training loss: 1.3855217695236206
Validation loss: 2.2432797621655207

Epoch: 6| Step: 13
Training loss: 2.7128801345825195
Validation loss: 2.1809973050189275

Epoch: 564| Step: 0
Training loss: 2.0850720405578613
Validation loss: 2.210777780061127

Epoch: 6| Step: 1
Training loss: 1.8336915969848633
Validation loss: 2.173002589133478

Epoch: 6| Step: 2
Training loss: 1.3780517578125
Validation loss: 2.202028000226585

Epoch: 6| Step: 3
Training loss: 1.8262815475463867
Validation loss: 2.1694533466010966

Epoch: 6| Step: 4
Training loss: 1.7211614847183228
Validation loss: 2.1790586389521116

Epoch: 6| Step: 5
Training loss: 1.471635103225708
Validation loss: 2.180433834752729

Epoch: 6| Step: 6
Training loss: 1.2086420059204102
Validation loss: 2.1693365086791334

Epoch: 6| Step: 7
Training loss: 1.589869737625122
Validation loss: 2.135704481473533

Epoch: 6| Step: 8
Training loss: 1.2975047826766968
Validation loss: 2.2239863513618388

Epoch: 6| Step: 9
Training loss: 1.3304861783981323
Validation loss: 2.1806773652312574

Epoch: 6| Step: 10
Training loss: 1.7076127529144287
Validation loss: 2.214790495493079

Epoch: 6| Step: 11
Training loss: 1.0755925178527832
Validation loss: 2.2002736753033054

Epoch: 6| Step: 12
Training loss: 1.3927438259124756
Validation loss: 2.2255003606119463

Epoch: 6| Step: 13
Training loss: 1.222305178642273
Validation loss: 2.17358834000044

Epoch: 565| Step: 0
Training loss: 1.6736329793930054
Validation loss: 2.089800702628269

Epoch: 6| Step: 1
Training loss: 1.3941717147827148
Validation loss: 2.2375186361292356

Epoch: 6| Step: 2
Training loss: 1.4960496425628662
Validation loss: 2.2005975618157336

Epoch: 6| Step: 3
Training loss: 1.028549313545227
Validation loss: 2.1393947293681483

Epoch: 6| Step: 4
Training loss: 1.6526795625686646
Validation loss: 2.2120852803671234

Epoch: 6| Step: 5
Training loss: 1.7181384563446045
Validation loss: 2.185027648043889

Epoch: 6| Step: 6
Training loss: 1.076172113418579
Validation loss: 2.2077536582946777

Epoch: 6| Step: 7
Training loss: 1.7246696949005127
Validation loss: 2.1486392239088654

Epoch: 6| Step: 8
Training loss: 1.195401906967163
Validation loss: 2.1980861822764077

Epoch: 6| Step: 9
Training loss: 1.2846674919128418
Validation loss: 2.152380194715274

Epoch: 6| Step: 10
Training loss: 2.2806477546691895
Validation loss: 2.1600127117608183

Epoch: 6| Step: 11
Training loss: 1.264206051826477
Validation loss: 2.187287316527418

Epoch: 6| Step: 12
Training loss: 1.7704217433929443
Validation loss: 2.1712415525990147

Epoch: 6| Step: 13
Training loss: 1.8778051137924194
Validation loss: 2.1780215014693556

Epoch: 566| Step: 0
Training loss: 0.9042355418205261
Validation loss: 2.199573237408874

Epoch: 6| Step: 1
Training loss: 1.7083302736282349
Validation loss: 2.1437879839251117

Epoch: 6| Step: 2
Training loss: 1.4663777351379395
Validation loss: 2.2169849513679423

Epoch: 6| Step: 3
Training loss: 0.8803207874298096
Validation loss: 2.2077446368432816

Epoch: 6| Step: 4
Training loss: 2.607665538787842
Validation loss: 2.216410231846635

Epoch: 6| Step: 5
Training loss: 1.5063681602478027
Validation loss: 2.2242468736504994

Epoch: 6| Step: 6
Training loss: 1.2041606903076172
Validation loss: 2.199517475661411

Epoch: 6| Step: 7
Training loss: 1.7191531658172607
Validation loss: 2.2050630200293755

Epoch: 6| Step: 8
Training loss: 1.7077968120574951
Validation loss: 2.234293173718196

Epoch: 6| Step: 9
Training loss: 1.7041723728179932
Validation loss: 2.2084957938040457

Epoch: 6| Step: 10
Training loss: 1.8485047817230225
Validation loss: 2.2498047890201693

Epoch: 6| Step: 11
Training loss: 1.4158687591552734
Validation loss: 2.2123031872575

Epoch: 6| Step: 12
Training loss: 0.9445180892944336
Validation loss: 2.2558278601656676

Epoch: 6| Step: 13
Training loss: 0.7597058415412903
Validation loss: 2.203664405371553

Epoch: 567| Step: 0
Training loss: 1.2341701984405518
Validation loss: 2.230847766322474

Epoch: 6| Step: 1
Training loss: 1.8671642541885376
Validation loss: 2.2697996939382246

Epoch: 6| Step: 2
Training loss: 1.4363619089126587
Validation loss: 2.1706798743176203

Epoch: 6| Step: 3
Training loss: 1.3153984546661377
Validation loss: 2.1032936611483173

Epoch: 6| Step: 4
Training loss: 1.1202622652053833
Validation loss: 2.1499846443053214

Epoch: 6| Step: 5
Training loss: 1.1180362701416016
Validation loss: 2.156533328435754

Epoch: 6| Step: 6
Training loss: 1.656270980834961
Validation loss: 2.1443973613041702

Epoch: 6| Step: 7
Training loss: 1.5636637210845947
Validation loss: 2.2251470576050463

Epoch: 6| Step: 8
Training loss: 1.706692099571228
Validation loss: 2.1265597061444352

Epoch: 6| Step: 9
Training loss: 1.7114787101745605
Validation loss: 2.1638285319010415

Epoch: 6| Step: 10
Training loss: 1.5270400047302246
Validation loss: 2.1764082101083573

Epoch: 6| Step: 11
Training loss: 2.426562547683716
Validation loss: 2.1923596269340924

Epoch: 6| Step: 12
Training loss: 1.427628755569458
Validation loss: 2.209373974031018

Epoch: 6| Step: 13
Training loss: 1.7999348640441895
Validation loss: 2.1271112247179915

Epoch: 568| Step: 0
Training loss: 1.097093939781189
Validation loss: 2.1226336622750885

Epoch: 6| Step: 1
Training loss: 1.1373023986816406
Validation loss: 2.19918062866375

Epoch: 6| Step: 2
Training loss: 1.5822454690933228
Validation loss: 2.1574367092501734

Epoch: 6| Step: 3
Training loss: 1.2346405982971191
Validation loss: 2.193199044914656

Epoch: 6| Step: 4
Training loss: 1.4238874912261963
Validation loss: 2.263370442134078

Epoch: 6| Step: 5
Training loss: 1.5732789039611816
Validation loss: 2.181356970981885

Epoch: 6| Step: 6
Training loss: 1.5461676120758057
Validation loss: 2.181778407865955

Epoch: 6| Step: 7
Training loss: 2.027041435241699
Validation loss: 2.1982720013587707

Epoch: 6| Step: 8
Training loss: 1.3032593727111816
Validation loss: 2.2378179386097896

Epoch: 6| Step: 9
Training loss: 1.808966040611267
Validation loss: 2.1876206808192755

Epoch: 6| Step: 10
Training loss: 1.5994830131530762
Validation loss: 2.168696311212355

Epoch: 6| Step: 11
Training loss: 1.5893559455871582
Validation loss: 2.2272612048733618

Epoch: 6| Step: 12
Training loss: 1.6084692478179932
Validation loss: 2.207969509145265

Epoch: 6| Step: 13
Training loss: 1.461252212524414
Validation loss: 2.2809704144795737

Epoch: 569| Step: 0
Training loss: 1.061456561088562
Validation loss: 2.208898039274318

Epoch: 6| Step: 1
Training loss: 1.2983343601226807
Validation loss: 2.1949633193272415

Epoch: 6| Step: 2
Training loss: 1.575010895729065
Validation loss: 2.2082207408002628

Epoch: 6| Step: 3
Training loss: 1.780681848526001
Validation loss: 2.217824570594295

Epoch: 6| Step: 4
Training loss: 1.487375020980835
Validation loss: 2.2096566564293316

Epoch: 6| Step: 5
Training loss: 1.5859198570251465
Validation loss: 2.156946784706526

Epoch: 6| Step: 6
Training loss: 1.5382158756256104
Validation loss: 2.203036308288574

Epoch: 6| Step: 7
Training loss: 1.2433080673217773
Validation loss: 2.16212280847693

Epoch: 6| Step: 8
Training loss: 1.09244966506958
Validation loss: 2.253494744659752

Epoch: 6| Step: 9
Training loss: 1.3573510646820068
Validation loss: 2.214028130295456

Epoch: 6| Step: 10
Training loss: 1.8279085159301758
Validation loss: 2.22758089726971

Epoch: 6| Step: 11
Training loss: 1.4308395385742188
Validation loss: 2.1787568061582503

Epoch: 6| Step: 12
Training loss: 2.082043170928955
Validation loss: 2.198573273997153

Epoch: 6| Step: 13
Training loss: 1.097334384918213
Validation loss: 2.199675897116302

Epoch: 570| Step: 0
Training loss: 1.3412532806396484
Validation loss: 2.1698289968634166

Epoch: 6| Step: 1
Training loss: 1.150933027267456
Validation loss: 2.162442563682474

Epoch: 6| Step: 2
Training loss: 1.721290946006775
Validation loss: 2.223717999714677

Epoch: 6| Step: 3
Training loss: 1.6106336116790771
Validation loss: 2.231776700224928

Epoch: 6| Step: 4
Training loss: 1.6255544424057007
Validation loss: 2.2062478475673224

Epoch: 6| Step: 5
Training loss: 1.9737663269042969
Validation loss: 2.153894583384196

Epoch: 6| Step: 6
Training loss: 1.2958600521087646
Validation loss: 2.2248805338336575

Epoch: 6| Step: 7
Training loss: 1.5258913040161133
Validation loss: 2.078527030124459

Epoch: 6| Step: 8
Training loss: 0.8018225431442261
Validation loss: 2.23327797971746

Epoch: 6| Step: 9
Training loss: 1.2024576663970947
Validation loss: 2.1857182723219677

Epoch: 6| Step: 10
Training loss: 1.3822590112686157
Validation loss: 2.177026817875524

Epoch: 6| Step: 11
Training loss: 1.5507874488830566
Validation loss: 2.1765281820809967

Epoch: 6| Step: 12
Training loss: 1.6341845989227295
Validation loss: 2.195725599924723

Epoch: 6| Step: 13
Training loss: 1.7368237972259521
Validation loss: 2.1374904442858953

Epoch: 571| Step: 0
Training loss: 1.8092067241668701
Validation loss: 2.23977558330823

Epoch: 6| Step: 1
Training loss: 1.3978362083435059
Validation loss: 2.2042594571267404

Epoch: 6| Step: 2
Training loss: 0.913001537322998
Validation loss: 2.152918715630808

Epoch: 6| Step: 3
Training loss: 1.7073686122894287
Validation loss: 2.179941672150807

Epoch: 6| Step: 4
Training loss: 1.0181950330734253
Validation loss: 2.1387412932611283

Epoch: 6| Step: 5
Training loss: 0.9419375658035278
Validation loss: 2.2072752060428744

Epoch: 6| Step: 6
Training loss: 1.8073034286499023
Validation loss: 2.1377783821475123

Epoch: 6| Step: 7
Training loss: 1.5453269481658936
Validation loss: 2.1576639272833384

Epoch: 6| Step: 8
Training loss: 2.209322452545166
Validation loss: 2.203280387386199

Epoch: 6| Step: 9
Training loss: 2.0137686729431152
Validation loss: 2.1705483005892847

Epoch: 6| Step: 10
Training loss: 1.4780954122543335
Validation loss: 2.2224642794619323

Epoch: 6| Step: 11
Training loss: 1.5069386959075928
Validation loss: 2.2130418439065256

Epoch: 6| Step: 12
Training loss: 1.0256452560424805
Validation loss: 2.169086681899204

Epoch: 6| Step: 13
Training loss: 2.186758518218994
Validation loss: 2.146223311783165

Epoch: 572| Step: 0
Training loss: 1.7509922981262207
Validation loss: 2.1612248830897833

Epoch: 6| Step: 1
Training loss: 1.2657804489135742
Validation loss: 2.1972752130159767

Epoch: 6| Step: 2
Training loss: 1.1594915390014648
Validation loss: 2.126331784391916

Epoch: 6| Step: 3
Training loss: 1.8988198041915894
Validation loss: 2.2263652739986295

Epoch: 6| Step: 4
Training loss: 1.657991886138916
Validation loss: 2.197961348359303

Epoch: 6| Step: 5
Training loss: 2.0009477138519287
Validation loss: 2.1433987822583926

Epoch: 6| Step: 6
Training loss: 1.438019037246704
Validation loss: 2.132900854592682

Epoch: 6| Step: 7
Training loss: 1.8722808361053467
Validation loss: 2.1974264370497836

Epoch: 6| Step: 8
Training loss: 1.2428637742996216
Validation loss: 2.127148805126067

Epoch: 6| Step: 9
Training loss: 0.9398326277732849
Validation loss: 2.136817938538008

Epoch: 6| Step: 10
Training loss: 1.2512731552124023
Validation loss: 2.1909729434597875

Epoch: 6| Step: 11
Training loss: 1.522692322731018
Validation loss: 2.174251021877412

Epoch: 6| Step: 12
Training loss: 1.41389799118042
Validation loss: 2.165159447218782

Epoch: 6| Step: 13
Training loss: 1.6339869499206543
Validation loss: 2.1085545042509675

Epoch: 573| Step: 0
Training loss: 1.4149510860443115
Validation loss: 2.1175781911419285

Epoch: 6| Step: 1
Training loss: 0.7937238216400146
Validation loss: 2.203574139584777

Epoch: 6| Step: 2
Training loss: 1.6783171892166138
Validation loss: 2.1715887849048903

Epoch: 6| Step: 3
Training loss: 1.5442670583724976
Validation loss: 2.181309166774955

Epoch: 6| Step: 4
Training loss: 1.6862409114837646
Validation loss: 2.1512092877459783

Epoch: 6| Step: 5
Training loss: 1.2768912315368652
Validation loss: 2.260496372817665

Epoch: 6| Step: 6
Training loss: 1.9120244979858398
Validation loss: 2.1734444889971005

Epoch: 6| Step: 7
Training loss: 1.1179081201553345
Validation loss: 2.1779902045444777

Epoch: 6| Step: 8
Training loss: 1.2792502641677856
Validation loss: 2.1851141837335404

Epoch: 6| Step: 9
Training loss: 1.9420928955078125
Validation loss: 2.137506264512257

Epoch: 6| Step: 10
Training loss: 1.1551744937896729
Validation loss: 2.2185465981883388

Epoch: 6| Step: 11
Training loss: 1.369124174118042
Validation loss: 2.247784332562518

Epoch: 6| Step: 12
Training loss: 1.295243740081787
Validation loss: 2.169731914356191

Epoch: 6| Step: 13
Training loss: 2.1889965534210205
Validation loss: 2.258486060686009

Epoch: 574| Step: 0
Training loss: 1.8394328355789185
Validation loss: 2.257785850955594

Epoch: 6| Step: 1
Training loss: 2.269174098968506
Validation loss: 2.222834664006387

Epoch: 6| Step: 2
Training loss: 1.7148728370666504
Validation loss: 2.1318882203871206

Epoch: 6| Step: 3
Training loss: 1.3252888917922974
Validation loss: 2.212852881800744

Epoch: 6| Step: 4
Training loss: 1.3667705059051514
Validation loss: 2.2468654340313328

Epoch: 6| Step: 5
Training loss: 1.1534366607666016
Validation loss: 2.2159482381677114

Epoch: 6| Step: 6
Training loss: 1.4596357345581055
Validation loss: 2.2707252092258905

Epoch: 6| Step: 7
Training loss: 1.2750070095062256
Validation loss: 2.235596882399692

Epoch: 6| Step: 8
Training loss: 1.4780497550964355
Validation loss: 2.1701585426125476

Epoch: 6| Step: 9
Training loss: 0.8870108127593994
Validation loss: 2.183462537744994

Epoch: 6| Step: 10
Training loss: 1.1353522539138794
Validation loss: 2.0967973560415287

Epoch: 6| Step: 11
Training loss: 1.45505690574646
Validation loss: 2.220087302628384

Epoch: 6| Step: 12
Training loss: 1.937015414237976
Validation loss: 2.189327962936894

Epoch: 6| Step: 13
Training loss: 1.2041833400726318
Validation loss: 2.2020979363431215

Epoch: 575| Step: 0
Training loss: 1.5614372491836548
Validation loss: 2.109789389435963

Epoch: 6| Step: 1
Training loss: 1.4107909202575684
Validation loss: 2.215165353590442

Epoch: 6| Step: 2
Training loss: 1.5291334390640259
Validation loss: 2.145400445948365

Epoch: 6| Step: 3
Training loss: 1.6913517713546753
Validation loss: 2.1677397476729525

Epoch: 6| Step: 4
Training loss: 1.9129093885421753
Validation loss: 2.1231352283108618

Epoch: 6| Step: 5
Training loss: 1.5029200315475464
Validation loss: 2.1535332510548253

Epoch: 6| Step: 6
Training loss: 1.1454408168792725
Validation loss: 2.146894585701727

Epoch: 6| Step: 7
Training loss: 1.1250381469726562
Validation loss: 2.2156505097625074

Epoch: 6| Step: 8
Training loss: 1.6975312232971191
Validation loss: 2.2231483703018515

Epoch: 6| Step: 9
Training loss: 1.5040940046310425
Validation loss: 2.1553723453193583

Epoch: 6| Step: 10
Training loss: 1.586855411529541
Validation loss: 2.203418081806552

Epoch: 6| Step: 11
Training loss: 1.0305811166763306
Validation loss: 2.097460066118548

Epoch: 6| Step: 12
Training loss: 1.5328267812728882
Validation loss: 2.098393960665631

Epoch: 6| Step: 13
Training loss: 1.6250683069229126
Validation loss: 2.197643969648628

Epoch: 576| Step: 0
Training loss: 1.1641675233840942
Validation loss: 2.178121882100259

Epoch: 6| Step: 1
Training loss: 1.68368399143219
Validation loss: 2.174871888211978

Epoch: 6| Step: 2
Training loss: 1.7413570880889893
Validation loss: 2.2063424343703897

Epoch: 6| Step: 3
Training loss: 1.107327938079834
Validation loss: 2.280326456151983

Epoch: 6| Step: 4
Training loss: 1.090984582901001
Validation loss: 2.301131397165278

Epoch: 6| Step: 5
Training loss: 1.6608035564422607
Validation loss: 2.184851948932935

Epoch: 6| Step: 6
Training loss: 1.4548746347427368
Validation loss: 2.1762916887960126

Epoch: 6| Step: 7
Training loss: 1.1114672422409058
Validation loss: 2.2332288526719615

Epoch: 6| Step: 8
Training loss: 1.9530611038208008
Validation loss: 2.184411871817804

Epoch: 6| Step: 9
Training loss: 1.8848352432250977
Validation loss: 2.234470252067812

Epoch: 6| Step: 10
Training loss: 1.9403884410858154
Validation loss: 2.2356854126017582

Epoch: 6| Step: 11
Training loss: 1.1441322565078735
Validation loss: 2.181729729457568

Epoch: 6| Step: 12
Training loss: 1.7118606567382812
Validation loss: 2.247908671696981

Epoch: 6| Step: 13
Training loss: 1.4383456707000732
Validation loss: 2.179439877951017

Epoch: 577| Step: 0
Training loss: 1.4083855152130127
Validation loss: 2.190419694428803

Epoch: 6| Step: 1
Training loss: 1.2233608961105347
Validation loss: 2.2144349403278802

Epoch: 6| Step: 2
Training loss: 1.0978565216064453
Validation loss: 2.209792926747312

Epoch: 6| Step: 3
Training loss: 1.2887730598449707
Validation loss: 2.2124278878652923

Epoch: 6| Step: 4
Training loss: 1.6904971599578857
Validation loss: 2.1142494640042706

Epoch: 6| Step: 5
Training loss: 0.819168746471405
Validation loss: 2.1896307032595397

Epoch: 6| Step: 6
Training loss: 1.923330545425415
Validation loss: 2.246914585431417

Epoch: 6| Step: 7
Training loss: 1.7459983825683594
Validation loss: 2.1937252193368892

Epoch: 6| Step: 8
Training loss: 1.7587693929672241
Validation loss: 2.1309595287487073

Epoch: 6| Step: 9
Training loss: 1.0593397617340088
Validation loss: 2.1310856752498175

Epoch: 6| Step: 10
Training loss: 1.5911985635757446
Validation loss: 2.209151448742036

Epoch: 6| Step: 11
Training loss: 1.673053503036499
Validation loss: 2.1328941314451155

Epoch: 6| Step: 12
Training loss: 1.0781402587890625
Validation loss: 2.2098096147660287

Epoch: 6| Step: 13
Training loss: 2.476149559020996
Validation loss: 2.1857031711968045

Epoch: 578| Step: 0
Training loss: 1.3433443307876587
Validation loss: 2.139943507409865

Epoch: 6| Step: 1
Training loss: 1.3584140539169312
Validation loss: 2.1948402312494095

Epoch: 6| Step: 2
Training loss: 1.6790058612823486
Validation loss: 2.168053084804166

Epoch: 6| Step: 3
Training loss: 1.429621696472168
Validation loss: 2.146788736825348

Epoch: 6| Step: 4
Training loss: 1.3803069591522217
Validation loss: 2.167829675059165

Epoch: 6| Step: 5
Training loss: 1.3739598989486694
Validation loss: 2.140952830673546

Epoch: 6| Step: 6
Training loss: 1.5620906352996826
Validation loss: 2.2061854741906606

Epoch: 6| Step: 7
Training loss: 1.718583345413208
Validation loss: 2.162715850337859

Epoch: 6| Step: 8
Training loss: 1.394286870956421
Validation loss: 2.2378148724955897

Epoch: 6| Step: 9
Training loss: 1.5194509029388428
Validation loss: 2.2609257954423145

Epoch: 6| Step: 10
Training loss: 1.465562343597412
Validation loss: 2.2606607150006037

Epoch: 6| Step: 11
Training loss: 0.9898128509521484
Validation loss: 2.17488512685222

Epoch: 6| Step: 12
Training loss: 1.4872047901153564
Validation loss: 2.185932454242501

Epoch: 6| Step: 13
Training loss: 1.6561063528060913
Validation loss: 2.2138046500503377

Epoch: 579| Step: 0
Training loss: 2.0218076705932617
Validation loss: 2.2619998608866045

Epoch: 6| Step: 1
Training loss: 1.2242164611816406
Validation loss: 2.202949534180344

Epoch: 6| Step: 2
Training loss: 1.5221710205078125
Validation loss: 2.177751256573585

Epoch: 6| Step: 3
Training loss: 1.367659330368042
Validation loss: 2.191463011567311

Epoch: 6| Step: 4
Training loss: 1.103592872619629
Validation loss: 2.126871762737151

Epoch: 6| Step: 5
Training loss: 1.4250210523605347
Validation loss: 2.182124703161178

Epoch: 6| Step: 6
Training loss: 1.6479172706604004
Validation loss: 2.2121759614636822

Epoch: 6| Step: 7
Training loss: 0.9129658341407776
Validation loss: 2.1904823985151065

Epoch: 6| Step: 8
Training loss: 1.617063045501709
Validation loss: 2.152858705930812

Epoch: 6| Step: 9
Training loss: 1.6227362155914307
Validation loss: 2.262790081321552

Epoch: 6| Step: 10
Training loss: 1.7791298627853394
Validation loss: 2.194503617543046

Epoch: 6| Step: 11
Training loss: 1.8569681644439697
Validation loss: 2.1879449300868536

Epoch: 6| Step: 12
Training loss: 0.8365717530250549
Validation loss: 2.1417548143735496

Epoch: 6| Step: 13
Training loss: 2.1759839057922363
Validation loss: 2.2654654441341275

Epoch: 580| Step: 0
Training loss: 1.3866243362426758
Validation loss: 2.169746886017502

Epoch: 6| Step: 1
Training loss: 1.5994141101837158
Validation loss: 2.246156928359821

Epoch: 6| Step: 2
Training loss: 1.7658497095108032
Validation loss: 2.151308906975613

Epoch: 6| Step: 3
Training loss: 1.41493821144104
Validation loss: 2.1750733378112956

Epoch: 6| Step: 4
Training loss: 0.8652423024177551
Validation loss: 2.1175342490596156

Epoch: 6| Step: 5
Training loss: 1.0201892852783203
Validation loss: 2.1800558951593216

Epoch: 6| Step: 6
Training loss: 1.6559739112854004
Validation loss: 2.152876662951644

Epoch: 6| Step: 7
Training loss: 1.713085651397705
Validation loss: 2.188288986041982

Epoch: 6| Step: 8
Training loss: 1.2471085786819458
Validation loss: 2.1461035333653933

Epoch: 6| Step: 9
Training loss: 1.2040208578109741
Validation loss: 2.2307212711662374

Epoch: 6| Step: 10
Training loss: 1.9915095567703247
Validation loss: 2.2202099805237143

Epoch: 6| Step: 11
Training loss: 1.919381022453308
Validation loss: 2.202257902391495

Epoch: 6| Step: 12
Training loss: 1.488674521446228
Validation loss: 2.1687089653425318

Epoch: 6| Step: 13
Training loss: 1.2134767770767212
Validation loss: 2.291390984289108

Epoch: 581| Step: 0
Training loss: 0.9182429313659668
Validation loss: 2.165153644418204

Epoch: 6| Step: 1
Training loss: 1.7206412553787231
Validation loss: 2.2533191737308296

Epoch: 6| Step: 2
Training loss: 1.5246014595031738
Validation loss: 2.2092453677167176

Epoch: 6| Step: 3
Training loss: 1.5567814111709595
Validation loss: 2.210928658003448

Epoch: 6| Step: 4
Training loss: 1.4136470556259155
Validation loss: 2.20958278512442

Epoch: 6| Step: 5
Training loss: 2.3335366249084473
Validation loss: 2.2162541843229726

Epoch: 6| Step: 6
Training loss: 1.4141309261322021
Validation loss: 2.195857330035138

Epoch: 6| Step: 7
Training loss: 1.71113920211792
Validation loss: 2.141174711206908

Epoch: 6| Step: 8
Training loss: 1.4074491262435913
Validation loss: 2.1224541894851194

Epoch: 6| Step: 9
Training loss: 0.9527590274810791
Validation loss: 2.1647027102849816

Epoch: 6| Step: 10
Training loss: 1.8882899284362793
Validation loss: 2.176842120385939

Epoch: 6| Step: 11
Training loss: 1.1050106287002563
Validation loss: 2.1778174497747935

Epoch: 6| Step: 12
Training loss: 1.587932825088501
Validation loss: 2.1205682395606913

Epoch: 6| Step: 13
Training loss: 1.7390795946121216
Validation loss: 2.160047094027201

Epoch: 582| Step: 0
Training loss: 1.803196907043457
Validation loss: 2.229309694741362

Epoch: 6| Step: 1
Training loss: 1.68687105178833
Validation loss: 2.1917033195495605

Epoch: 6| Step: 2
Training loss: 1.6998186111450195
Validation loss: 2.2173678567332606

Epoch: 6| Step: 3
Training loss: 1.3981308937072754
Validation loss: 2.178709113469688

Epoch: 6| Step: 4
Training loss: 1.2645251750946045
Validation loss: 2.125606188210108

Epoch: 6| Step: 5
Training loss: 1.5257644653320312
Validation loss: 2.1746464903636644

Epoch: 6| Step: 6
Training loss: 1.653773546218872
Validation loss: 2.189917024745736

Epoch: 6| Step: 7
Training loss: 1.5293198823928833
Validation loss: 2.1287482874367827

Epoch: 6| Step: 8
Training loss: 1.2095210552215576
Validation loss: 2.1613280439889557

Epoch: 6| Step: 9
Training loss: 1.1827876567840576
Validation loss: 2.2298580984915457

Epoch: 6| Step: 10
Training loss: 1.7065675258636475
Validation loss: 2.191681244040048

Epoch: 6| Step: 11
Training loss: 1.8800878524780273
Validation loss: 2.1449004206606137

Epoch: 6| Step: 12
Training loss: 1.3894388675689697
Validation loss: 2.1526459032489407

Epoch: 6| Step: 13
Training loss: 1.1746881008148193
Validation loss: 2.0985404035096527

Epoch: 583| Step: 0
Training loss: 1.995165467262268
Validation loss: 2.150820205288549

Epoch: 6| Step: 1
Training loss: 1.5870548486709595
Validation loss: 2.1562758773885746

Epoch: 6| Step: 2
Training loss: 1.8152213096618652
Validation loss: 2.160897252380207

Epoch: 6| Step: 3
Training loss: 1.2644667625427246
Validation loss: 2.2339305646957888

Epoch: 6| Step: 4
Training loss: 1.3190011978149414
Validation loss: 2.152624386613087

Epoch: 6| Step: 5
Training loss: 1.9327754974365234
Validation loss: 2.259655316670736

Epoch: 6| Step: 6
Training loss: 1.553018569946289
Validation loss: 2.1774274943977274

Epoch: 6| Step: 7
Training loss: 1.5557996034622192
Validation loss: 2.128109701218144

Epoch: 6| Step: 8
Training loss: 0.9398984909057617
Validation loss: 2.102783937608042

Epoch: 6| Step: 9
Training loss: 1.251175880432129
Validation loss: 2.1174745534055974

Epoch: 6| Step: 10
Training loss: 1.5471851825714111
Validation loss: 2.235243425574354

Epoch: 6| Step: 11
Training loss: 2.2078464031219482
Validation loss: 2.1208887459129415

Epoch: 6| Step: 12
Training loss: 0.795646071434021
Validation loss: 2.11602347640581

Epoch: 6| Step: 13
Training loss: 0.8019366264343262
Validation loss: 2.1311611039664156

Epoch: 584| Step: 0
Training loss: 1.7609424591064453
Validation loss: 2.2151892685121104

Epoch: 6| Step: 1
Training loss: 1.2449564933776855
Validation loss: 2.161959332804526

Epoch: 6| Step: 2
Training loss: 1.3582004308700562
Validation loss: 2.156309953299902

Epoch: 6| Step: 3
Training loss: 1.0955034494400024
Validation loss: 2.2300062230838242

Epoch: 6| Step: 4
Training loss: 1.4986562728881836
Validation loss: 2.1361547144510413

Epoch: 6| Step: 5
Training loss: 1.8384677171707153
Validation loss: 2.1166691985181583

Epoch: 6| Step: 6
Training loss: 1.212594747543335
Validation loss: 2.158702975960188

Epoch: 6| Step: 7
Training loss: 1.8213189840316772
Validation loss: 2.2551966662048013

Epoch: 6| Step: 8
Training loss: 1.3648394346237183
Validation loss: 2.188975316221996

Epoch: 6| Step: 9
Training loss: 1.1020240783691406
Validation loss: 2.129738127031634

Epoch: 6| Step: 10
Training loss: 1.8840813636779785
Validation loss: 2.2153222945428666

Epoch: 6| Step: 11
Training loss: 1.7209913730621338
Validation loss: 2.1574208403146393

Epoch: 6| Step: 12
Training loss: 1.5614205598831177
Validation loss: 2.247225478131284

Epoch: 6| Step: 13
Training loss: 1.2143056392669678
Validation loss: 2.215662767810206

Epoch: 585| Step: 0
Training loss: 2.018885374069214
Validation loss: 2.218201293740221

Epoch: 6| Step: 1
Training loss: 1.2366807460784912
Validation loss: 2.1870213426569456

Epoch: 6| Step: 2
Training loss: 1.4414560794830322
Validation loss: 2.1173373012132544

Epoch: 6| Step: 3
Training loss: 1.4548516273498535
Validation loss: 2.1629058276453326

Epoch: 6| Step: 4
Training loss: 1.399263620376587
Validation loss: 2.1608663092377367

Epoch: 6| Step: 5
Training loss: 1.286993384361267
Validation loss: 2.184848100908341

Epoch: 6| Step: 6
Training loss: 2.018054962158203
Validation loss: 2.2178215903620564

Epoch: 6| Step: 7
Training loss: 1.3209797143936157
Validation loss: 2.188244855532082

Epoch: 6| Step: 8
Training loss: 1.1591973304748535
Validation loss: 2.1666707608007614

Epoch: 6| Step: 9
Training loss: 2.0331926345825195
Validation loss: 2.1274745156688075

Epoch: 6| Step: 10
Training loss: 1.1014113426208496
Validation loss: 2.1119817713255524

Epoch: 6| Step: 11
Training loss: 0.9173951745033264
Validation loss: 2.1154008578228694

Epoch: 6| Step: 12
Training loss: 1.4807795286178589
Validation loss: 2.154275930056008

Epoch: 6| Step: 13
Training loss: 0.9514124989509583
Validation loss: 2.2107430581123597

Epoch: 586| Step: 0
Training loss: 1.8740503787994385
Validation loss: 2.1012999678170807

Epoch: 6| Step: 1
Training loss: 1.3544726371765137
Validation loss: 2.164802433342062

Epoch: 6| Step: 2
Training loss: 1.8050733804702759
Validation loss: 2.135323980803131

Epoch: 6| Step: 3
Training loss: 1.6632294654846191
Validation loss: 2.2307621125252015

Epoch: 6| Step: 4
Training loss: 1.354637861251831
Validation loss: 2.2410308596908406

Epoch: 6| Step: 5
Training loss: 1.3194894790649414
Validation loss: 2.175139304130308

Epoch: 6| Step: 6
Training loss: 0.7648966908454895
Validation loss: 2.180368464480164

Epoch: 6| Step: 7
Training loss: 1.8841029405593872
Validation loss: 2.2102543769344205

Epoch: 6| Step: 8
Training loss: 1.7561856508255005
Validation loss: 2.1864187537982898

Epoch: 6| Step: 9
Training loss: 1.543656349182129
Validation loss: 2.106331036936852

Epoch: 6| Step: 10
Training loss: 1.3390204906463623
Validation loss: 2.201156170137467

Epoch: 6| Step: 11
Training loss: 0.8025945425033569
Validation loss: 2.1359464776131416

Epoch: 6| Step: 12
Training loss: 1.422442078590393
Validation loss: 2.1827344227862615

Epoch: 6| Step: 13
Training loss: 1.2393591403961182
Validation loss: 2.1769780625579176

Epoch: 587| Step: 0
Training loss: 1.5902575254440308
Validation loss: 2.192850507715697

Epoch: 6| Step: 1
Training loss: 1.7332215309143066
Validation loss: 2.1807265845678185

Epoch: 6| Step: 2
Training loss: 1.6842286586761475
Validation loss: 2.238417363935901

Epoch: 6| Step: 3
Training loss: 1.3241088390350342
Validation loss: 2.202048094041886

Epoch: 6| Step: 4
Training loss: 1.2903012037277222
Validation loss: 2.1320263031990296

Epoch: 6| Step: 5
Training loss: 1.2864089012145996
Validation loss: 2.2028664465873473

Epoch: 6| Step: 6
Training loss: 1.528023600578308
Validation loss: 2.2460533470235844

Epoch: 6| Step: 7
Training loss: 1.3161425590515137
Validation loss: 2.2080735493731756

Epoch: 6| Step: 8
Training loss: 1.8401825428009033
Validation loss: 2.188782033099923

Epoch: 6| Step: 9
Training loss: 0.9937586784362793
Validation loss: 2.172124478124803

Epoch: 6| Step: 10
Training loss: 1.6678467988967896
Validation loss: 2.2661967482618106

Epoch: 6| Step: 11
Training loss: 1.5641226768493652
Validation loss: 2.1926498002903436

Epoch: 6| Step: 12
Training loss: 1.0894826650619507
Validation loss: 2.1300279248145317

Epoch: 6| Step: 13
Training loss: 1.0188623666763306
Validation loss: 2.2394096594984814

Epoch: 588| Step: 0
Training loss: 1.6051840782165527
Validation loss: 2.1943276979589976

Epoch: 6| Step: 1
Training loss: 1.4588385820388794
Validation loss: 2.2175861661152174

Epoch: 6| Step: 2
Training loss: 1.3776746988296509
Validation loss: 2.1734705202041136

Epoch: 6| Step: 3
Training loss: 1.469101905822754
Validation loss: 2.2206416437702794

Epoch: 6| Step: 4
Training loss: 0.9839388728141785
Validation loss: 2.224627746048794

Epoch: 6| Step: 5
Training loss: 1.255875587463379
Validation loss: 2.2157812682531213

Epoch: 6| Step: 6
Training loss: 2.104764461517334
Validation loss: 2.145374592914376

Epoch: 6| Step: 7
Training loss: 1.8768892288208008
Validation loss: 2.2102414792583835

Epoch: 6| Step: 8
Training loss: 0.7889522910118103
Validation loss: 2.174350512925015

Epoch: 6| Step: 9
Training loss: 1.3696999549865723
Validation loss: 2.2189443701057026

Epoch: 6| Step: 10
Training loss: 1.1154913902282715
Validation loss: 2.221962739062566

Epoch: 6| Step: 11
Training loss: 1.8333749771118164
Validation loss: 2.14423607882633

Epoch: 6| Step: 12
Training loss: 1.446808099746704
Validation loss: 2.2290887935187227

Epoch: 6| Step: 13
Training loss: 1.549184799194336
Validation loss: 2.1988195873075917

Epoch: 589| Step: 0
Training loss: 1.8687140941619873
Validation loss: 2.295883212038266

Epoch: 6| Step: 1
Training loss: 1.6982147693634033
Validation loss: 2.2068807899311023

Epoch: 6| Step: 2
Training loss: 1.4545328617095947
Validation loss: 2.270810468222505

Epoch: 6| Step: 3
Training loss: 2.0509557723999023
Validation loss: 2.233449298848388

Epoch: 6| Step: 4
Training loss: 1.575714111328125
Validation loss: 2.280322080017418

Epoch: 6| Step: 5
Training loss: 1.2128398418426514
Validation loss: 2.2571532136650494

Epoch: 6| Step: 6
Training loss: 1.6840698719024658
Validation loss: 2.2615434918352353

Epoch: 6| Step: 7
Training loss: 1.5783863067626953
Validation loss: 2.2471977869669595

Epoch: 6| Step: 8
Training loss: 1.189835548400879
Validation loss: 2.1953369853317097

Epoch: 6| Step: 9
Training loss: 1.4509403705596924
Validation loss: 2.19517324560432

Epoch: 6| Step: 10
Training loss: 0.9577540159225464
Validation loss: 2.2356151880756503

Epoch: 6| Step: 11
Training loss: 1.3367893695831299
Validation loss: 2.1925439219320975

Epoch: 6| Step: 12
Training loss: 1.5124891996383667
Validation loss: 2.165793562448153

Epoch: 6| Step: 13
Training loss: 0.8752970695495605
Validation loss: 2.163534461811025

Epoch: 590| Step: 0
Training loss: 2.173685073852539
Validation loss: 2.1880289021358696

Epoch: 6| Step: 1
Training loss: 1.414973497390747
Validation loss: 2.121813799745293

Epoch: 6| Step: 2
Training loss: 1.1813772916793823
Validation loss: 2.1350183871484574

Epoch: 6| Step: 3
Training loss: 1.001657247543335
Validation loss: 2.232518808816069

Epoch: 6| Step: 4
Training loss: 1.5747870206832886
Validation loss: 2.2278264594334427

Epoch: 6| Step: 5
Training loss: 1.2939436435699463
Validation loss: 2.2411338975352626

Epoch: 6| Step: 6
Training loss: 2.0796091556549072
Validation loss: 2.105975453571607

Epoch: 6| Step: 7
Training loss: 1.4946879148483276
Validation loss: 2.214832094407851

Epoch: 6| Step: 8
Training loss: 1.3719538450241089
Validation loss: 2.1967274168486237

Epoch: 6| Step: 9
Training loss: 1.571906566619873
Validation loss: 2.197950400331969

Epoch: 6| Step: 10
Training loss: 1.1677742004394531
Validation loss: 2.1822786715722855

Epoch: 6| Step: 11
Training loss: 1.2587772607803345
Validation loss: 2.1009160690410162

Epoch: 6| Step: 12
Training loss: 1.6316298246383667
Validation loss: 2.2320158904598606

Epoch: 6| Step: 13
Training loss: 1.693861961364746
Validation loss: 2.1454655611386864

Epoch: 591| Step: 0
Training loss: 1.813951015472412
Validation loss: 2.1933014597944034

Epoch: 6| Step: 1
Training loss: 1.9613512754440308
Validation loss: 2.2832205500653995

Epoch: 6| Step: 2
Training loss: 2.148083209991455
Validation loss: 2.177686704102383

Epoch: 6| Step: 3
Training loss: 1.424257755279541
Validation loss: 2.1854526919703328

Epoch: 6| Step: 4
Training loss: 1.7102794647216797
Validation loss: 2.198469574733447

Epoch: 6| Step: 5
Training loss: 1.003077507019043
Validation loss: 2.117720662906606

Epoch: 6| Step: 6
Training loss: 1.025424599647522
Validation loss: 2.189070991290513

Epoch: 6| Step: 7
Training loss: 0.8849385380744934
Validation loss: 2.1651380344103743

Epoch: 6| Step: 8
Training loss: 1.34415864944458
Validation loss: 2.201788551063948

Epoch: 6| Step: 9
Training loss: 1.2521960735321045
Validation loss: 2.182314234395181

Epoch: 6| Step: 10
Training loss: 1.9559160470962524
Validation loss: 2.201997157066099

Epoch: 6| Step: 11
Training loss: 1.06048583984375
Validation loss: 2.194358259119013

Epoch: 6| Step: 12
Training loss: 1.6702638864517212
Validation loss: 2.218189770175565

Epoch: 6| Step: 13
Training loss: 1.2095141410827637
Validation loss: 2.1397533852566957

Epoch: 592| Step: 0
Training loss: 1.8264927864074707
Validation loss: 2.197461079525691

Epoch: 6| Step: 1
Training loss: 1.2472467422485352
Validation loss: 2.181995064981522

Epoch: 6| Step: 2
Training loss: 1.8677266836166382
Validation loss: 2.160249815192274

Epoch: 6| Step: 3
Training loss: 1.7997833490371704
Validation loss: 2.172235494018883

Epoch: 6| Step: 4
Training loss: 1.2800917625427246
Validation loss: 2.2170624989335255

Epoch: 6| Step: 5
Training loss: 1.1847288608551025
Validation loss: 2.139497292939053

Epoch: 6| Step: 6
Training loss: 1.9837367534637451
Validation loss: 2.2128522831906556

Epoch: 6| Step: 7
Training loss: 1.3908464908599854
Validation loss: 2.2059173532711562

Epoch: 6| Step: 8
Training loss: 1.5375030040740967
Validation loss: 2.2414825680435344

Epoch: 6| Step: 9
Training loss: 0.9537484049797058
Validation loss: 2.167199665500272

Epoch: 6| Step: 10
Training loss: 1.1485356092453003
Validation loss: 2.2071742473110074

Epoch: 6| Step: 11
Training loss: 1.3400555849075317
Validation loss: 2.1713802378664733

Epoch: 6| Step: 12
Training loss: 1.2773370742797852
Validation loss: 2.216624347112512

Epoch: 6| Step: 13
Training loss: 0.761654257774353
Validation loss: 2.206643863390851

Epoch: 593| Step: 0
Training loss: 1.546640396118164
Validation loss: 2.131921324678647

Epoch: 6| Step: 1
Training loss: 1.5265822410583496
Validation loss: 2.2517770003247004

Epoch: 6| Step: 2
Training loss: 1.3372201919555664
Validation loss: 2.195571235431138

Epoch: 6| Step: 3
Training loss: 1.8989877700805664
Validation loss: 2.1284071245501117

Epoch: 6| Step: 4
Training loss: 1.5439910888671875
Validation loss: 2.218533892785349

Epoch: 6| Step: 5
Training loss: 1.2609798908233643
Validation loss: 2.202851800508397

Epoch: 6| Step: 6
Training loss: 1.1862103939056396
Validation loss: 2.3043507029933314

Epoch: 6| Step: 7
Training loss: 1.8565618991851807
Validation loss: 2.198451477994201

Epoch: 6| Step: 8
Training loss: 1.4116640090942383
Validation loss: 2.2476115842019357

Epoch: 6| Step: 9
Training loss: 1.567781925201416
Validation loss: 2.173584463775799

Epoch: 6| Step: 10
Training loss: 0.7796999216079712
Validation loss: 2.224920285645352

Epoch: 6| Step: 11
Training loss: 1.8498542308807373
Validation loss: 2.2387640924863916

Epoch: 6| Step: 12
Training loss: 1.951194405555725
Validation loss: 2.2215850660877843

Epoch: 6| Step: 13
Training loss: 0.6563738584518433
Validation loss: 2.1987583175782235

Epoch: 594| Step: 0
Training loss: 1.191623568534851
Validation loss: 2.2155595287199943

Epoch: 6| Step: 1
Training loss: 1.1015443801879883
Validation loss: 2.2397208547079437

Epoch: 6| Step: 2
Training loss: 1.5904340744018555
Validation loss: 2.1640486089132165

Epoch: 6| Step: 3
Training loss: 1.4679409265518188
Validation loss: 2.198942301093891

Epoch: 6| Step: 4
Training loss: 1.3140995502471924
Validation loss: 2.165107327122842

Epoch: 6| Step: 5
Training loss: 1.4899284839630127
Validation loss: 2.2227043054437123

Epoch: 6| Step: 6
Training loss: 2.0672597885131836
Validation loss: 2.1822202103112334

Epoch: 6| Step: 7
Training loss: 1.7277146577835083
Validation loss: 2.175226640957658

Epoch: 6| Step: 8
Training loss: 1.586796760559082
Validation loss: 2.1930863780360066

Epoch: 6| Step: 9
Training loss: 1.5115448236465454
Validation loss: 2.2011273009802705

Epoch: 6| Step: 10
Training loss: 1.4276524782180786
Validation loss: 2.1346867879231772

Epoch: 6| Step: 11
Training loss: 1.1208704710006714
Validation loss: 2.1345970592191144

Epoch: 6| Step: 12
Training loss: 1.5259952545166016
Validation loss: 2.1856214448969853

Epoch: 6| Step: 13
Training loss: 0.5781705379486084
Validation loss: 2.152488244477139

Epoch: 595| Step: 0
Training loss: 1.3076294660568237
Validation loss: 2.1675555013841197

Epoch: 6| Step: 1
Training loss: 1.6526072025299072
Validation loss: 2.167017798269949

Epoch: 6| Step: 2
Training loss: 1.0822830200195312
Validation loss: 2.234894029555782

Epoch: 6| Step: 3
Training loss: 1.5722733736038208
Validation loss: 2.2563303670575543

Epoch: 6| Step: 4
Training loss: 1.4222792387008667
Validation loss: 2.1834055915955575

Epoch: 6| Step: 5
Training loss: 1.0514869689941406
Validation loss: 2.2049630149718253

Epoch: 6| Step: 6
Training loss: 0.7143754959106445
Validation loss: 2.2181787029389413

Epoch: 6| Step: 7
Training loss: 1.6694693565368652
Validation loss: 2.16571016721828

Epoch: 6| Step: 8
Training loss: 1.86801016330719
Validation loss: 2.1512438122944166

Epoch: 6| Step: 9
Training loss: 1.031890630722046
Validation loss: 2.2214995122724965

Epoch: 6| Step: 10
Training loss: 1.7638897895812988
Validation loss: 2.1662746296134046

Epoch: 6| Step: 11
Training loss: 1.959150791168213
Validation loss: 2.1765020226919525

Epoch: 6| Step: 12
Training loss: 1.2744858264923096
Validation loss: 2.1992780803352274

Epoch: 6| Step: 13
Training loss: 1.488578200340271
Validation loss: 2.192580933211952

Epoch: 596| Step: 0
Training loss: 1.6266601085662842
Validation loss: 2.1489313789593276

Epoch: 6| Step: 1
Training loss: 1.467013955116272
Validation loss: 2.165293493578511

Epoch: 6| Step: 2
Training loss: 1.2375825643539429
Validation loss: 2.132118546834556

Epoch: 6| Step: 3
Training loss: 1.9991400241851807
Validation loss: 2.2099718675818494

Epoch: 6| Step: 4
Training loss: 1.1739346981048584
Validation loss: 2.1292787034024476

Epoch: 6| Step: 5
Training loss: 1.6557772159576416
Validation loss: 2.213075286598616

Epoch: 6| Step: 6
Training loss: 1.7323071956634521
Validation loss: 2.212971736026067

Epoch: 6| Step: 7
Training loss: 1.1611601114273071
Validation loss: 2.269010282331897

Epoch: 6| Step: 8
Training loss: 1.4852585792541504
Validation loss: 2.181777120918356

Epoch: 6| Step: 9
Training loss: 1.809140920639038
Validation loss: 2.2228396400328605

Epoch: 6| Step: 10
Training loss: 1.459288477897644
Validation loss: 2.1329975999811643

Epoch: 6| Step: 11
Training loss: 1.4653904438018799
Validation loss: 2.166129563444404

Epoch: 6| Step: 12
Training loss: 1.1756548881530762
Validation loss: 2.1418541862118627

Epoch: 6| Step: 13
Training loss: 0.8167345523834229
Validation loss: 2.138397806434221

Epoch: 597| Step: 0
Training loss: 1.5214581489562988
Validation loss: 2.1696642291161323

Epoch: 6| Step: 1
Training loss: 0.9567831754684448
Validation loss: 2.1900599361747823

Epoch: 6| Step: 2
Training loss: 1.3505358695983887
Validation loss: 2.145245828936177

Epoch: 6| Step: 3
Training loss: 1.686760425567627
Validation loss: 2.246505284822115

Epoch: 6| Step: 4
Training loss: 1.200596809387207
Validation loss: 2.195880138745872

Epoch: 6| Step: 5
Training loss: 1.8825623989105225
Validation loss: 2.1934550808322046

Epoch: 6| Step: 6
Training loss: 1.3119826316833496
Validation loss: 2.232648680287023

Epoch: 6| Step: 7
Training loss: 1.4515736103057861
Validation loss: 2.234025909054664

Epoch: 6| Step: 8
Training loss: 2.246100425720215
Validation loss: 2.190283913766184

Epoch: 6| Step: 9
Training loss: 1.1630058288574219
Validation loss: 2.1815750650180283

Epoch: 6| Step: 10
Training loss: 0.8022675514221191
Validation loss: 2.22406034059422

Epoch: 6| Step: 11
Training loss: 1.6326392889022827
Validation loss: 2.209122610348527

Epoch: 6| Step: 12
Training loss: 1.79741632938385
Validation loss: 2.228508682661159

Epoch: 6| Step: 13
Training loss: 1.5783239603042603
Validation loss: 2.1588454131157166

Epoch: 598| Step: 0
Training loss: 1.3825485706329346
Validation loss: 2.2048700676169446

Epoch: 6| Step: 1
Training loss: 1.637211799621582
Validation loss: 2.2089282312700824

Epoch: 6| Step: 2
Training loss: 0.7957080006599426
Validation loss: 2.199805655787068

Epoch: 6| Step: 3
Training loss: 1.494051218032837
Validation loss: 2.1774726324183966

Epoch: 6| Step: 4
Training loss: 1.4715005159378052
Validation loss: 2.136993699176337

Epoch: 6| Step: 5
Training loss: 2.236567497253418
Validation loss: 2.209028805455854

Epoch: 6| Step: 6
Training loss: 0.752822995185852
Validation loss: 2.1887344801297752

Epoch: 6| Step: 7
Training loss: 1.4065258502960205
Validation loss: 2.1565070831647484

Epoch: 6| Step: 8
Training loss: 1.283698320388794
Validation loss: 2.139637308736001

Epoch: 6| Step: 9
Training loss: 0.9977996945381165
Validation loss: 2.1766137397417458

Epoch: 6| Step: 10
Training loss: 1.9338715076446533
Validation loss: 2.2157983497906755

Epoch: 6| Step: 11
Training loss: 1.5965471267700195
Validation loss: 2.2228894284976426

Epoch: 6| Step: 12
Training loss: 1.6865277290344238
Validation loss: 2.191606270369663

Epoch: 6| Step: 13
Training loss: 1.846396565437317
Validation loss: 2.186799705669444

Epoch: 599| Step: 0
Training loss: 1.5368766784667969
Validation loss: 2.1607179410995974

Epoch: 6| Step: 1
Training loss: 0.9524484872817993
Validation loss: 2.219980496232228

Epoch: 6| Step: 2
Training loss: 2.0726699829101562
Validation loss: 2.238134084209319

Epoch: 6| Step: 3
Training loss: 1.2933616638183594
Validation loss: 2.2400797400423276

Epoch: 6| Step: 4
Training loss: 1.22555673122406
Validation loss: 2.1727427051913355

Epoch: 6| Step: 5
Training loss: 1.0256590843200684
Validation loss: 2.1452097136487245

Epoch: 6| Step: 6
Training loss: 1.868290662765503
Validation loss: 2.172591450393841

Epoch: 6| Step: 7
Training loss: 1.3605111837387085
Validation loss: 2.175687002879317

Epoch: 6| Step: 8
Training loss: 1.576614499092102
Validation loss: 2.1770341627059446

Epoch: 6| Step: 9
Training loss: 1.5881152153015137
Validation loss: 2.193664986600158

Epoch: 6| Step: 10
Training loss: 1.6010854244232178
Validation loss: 2.196146712508253

Epoch: 6| Step: 11
Training loss: 1.3118715286254883
Validation loss: 2.176758466228362

Epoch: 6| Step: 12
Training loss: 1.1758334636688232
Validation loss: 2.160564645644157

Epoch: 6| Step: 13
Training loss: 1.5083770751953125
Validation loss: 2.1265918490707234

Epoch: 600| Step: 0
Training loss: 1.0122616291046143
Validation loss: 2.2215169322106147

Epoch: 6| Step: 1
Training loss: 2.2081027030944824
Validation loss: 2.1742294783233316

Epoch: 6| Step: 2
Training loss: 1.7774392366409302
Validation loss: 2.1366208625096146

Epoch: 6| Step: 3
Training loss: 1.2591359615325928
Validation loss: 2.2400583964522167

Epoch: 6| Step: 4
Training loss: 1.5274436473846436
Validation loss: 2.2185093997627177

Epoch: 6| Step: 5
Training loss: 1.9337801933288574
Validation loss: 2.15097116654919

Epoch: 6| Step: 6
Training loss: 1.074117660522461
Validation loss: 2.1300141273006314

Epoch: 6| Step: 7
Training loss: 1.5035429000854492
Validation loss: 2.167224166213825

Epoch: 6| Step: 8
Training loss: 1.725060224533081
Validation loss: 2.21966359179507

Epoch: 6| Step: 9
Training loss: 1.5069663524627686
Validation loss: 2.1587846150962253

Epoch: 6| Step: 10
Training loss: 1.300394058227539
Validation loss: 2.156993668566468

Epoch: 6| Step: 11
Training loss: 1.2569398880004883
Validation loss: 2.218961241424725

Epoch: 6| Step: 12
Training loss: 1.23685622215271
Validation loss: 2.218697560730801

Epoch: 6| Step: 13
Training loss: 1.6276975870132446
Validation loss: 2.2173184246145268

Epoch: 601| Step: 0
Training loss: 1.2719790935516357
Validation loss: 2.1555955076730378

Epoch: 6| Step: 1
Training loss: 2.3143234252929688
Validation loss: 2.2144733372554986

Epoch: 6| Step: 2
Training loss: 1.9198960065841675
Validation loss: 2.1655486424764

Epoch: 6| Step: 3
Training loss: 0.8560948967933655
Validation loss: 2.255215670472832

Epoch: 6| Step: 4
Training loss: 0.8934289216995239
Validation loss: 2.173985996553975

Epoch: 6| Step: 5
Training loss: 1.9255704879760742
Validation loss: 2.202331225077311

Epoch: 6| Step: 6
Training loss: 1.2444641590118408
Validation loss: 2.2368830993611324

Epoch: 6| Step: 7
Training loss: 0.8967708349227905
Validation loss: 2.2015958473246586

Epoch: 6| Step: 8
Training loss: 1.179931640625
Validation loss: 2.1555085720554477

Epoch: 6| Step: 9
Training loss: 1.2520822286605835
Validation loss: 2.1390928658105994

Epoch: 6| Step: 10
Training loss: 1.790395736694336
Validation loss: 2.133976464630455

Epoch: 6| Step: 11
Training loss: 1.0972782373428345
Validation loss: 2.078899574536149

Epoch: 6| Step: 12
Training loss: 2.1544318199157715
Validation loss: 2.192859685549172

Epoch: 6| Step: 13
Training loss: 1.3606425523757935
Validation loss: 2.2374844833086898

Epoch: 602| Step: 0
Training loss: 1.5289254188537598
Validation loss: 2.107616070778139

Epoch: 6| Step: 1
Training loss: 1.5219287872314453
Validation loss: 2.211885893216697

Epoch: 6| Step: 2
Training loss: 1.4761230945587158
Validation loss: 2.301922259792205

Epoch: 6| Step: 3
Training loss: 0.7816702127456665
Validation loss: 2.2691568072124193

Epoch: 6| Step: 4
Training loss: 0.8943077921867371
Validation loss: 2.213099246383995

Epoch: 6| Step: 5
Training loss: 1.4451738595962524
Validation loss: 2.2366336468727357

Epoch: 6| Step: 6
Training loss: 1.4571306705474854
Validation loss: 2.26244427311805

Epoch: 6| Step: 7
Training loss: 1.2928235530853271
Validation loss: 2.181192559580649

Epoch: 6| Step: 8
Training loss: 1.3596724271774292
Validation loss: 2.183710951958933

Epoch: 6| Step: 9
Training loss: 1.7874152660369873
Validation loss: 2.1461754306670158

Epoch: 6| Step: 10
Training loss: 1.3616366386413574
Validation loss: 2.21614089832511

Epoch: 6| Step: 11
Training loss: 1.955748438835144
Validation loss: 2.2373291523225847

Epoch: 6| Step: 12
Training loss: 1.9834165573120117
Validation loss: 2.1712466875712075

Epoch: 6| Step: 13
Training loss: 2.0511832237243652
Validation loss: 2.195722124909842

Epoch: 603| Step: 0
Training loss: 1.147093415260315
Validation loss: 2.276833257367534

Epoch: 6| Step: 1
Training loss: 1.1872042417526245
Validation loss: 2.1850101178692234

Epoch: 6| Step: 2
Training loss: 1.1472952365875244
Validation loss: 2.1897049642378286

Epoch: 6| Step: 3
Training loss: 2.410996437072754
Validation loss: 2.278049410030406

Epoch: 6| Step: 4
Training loss: 1.7715137004852295
Validation loss: 2.0648861098033127

Epoch: 6| Step: 5
Training loss: 1.0877758264541626
Validation loss: 2.168841870882178

Epoch: 6| Step: 6
Training loss: 1.6825648546218872
Validation loss: 2.217852751413981

Epoch: 6| Step: 7
Training loss: 0.9749430418014526
Validation loss: 2.268355231131277

Epoch: 6| Step: 8
Training loss: 2.2129340171813965
Validation loss: 2.1991285752224665

Epoch: 6| Step: 9
Training loss: 1.1811403036117554
Validation loss: 2.123704477023053

Epoch: 6| Step: 10
Training loss: 1.652005910873413
Validation loss: 2.261455753798126

Epoch: 6| Step: 11
Training loss: 1.245364785194397
Validation loss: 2.1819963814109884

Epoch: 6| Step: 12
Training loss: 0.6930817365646362
Validation loss: 2.222970849724226

Epoch: 6| Step: 13
Training loss: 2.0309929847717285
Validation loss: 2.187113191491814

Epoch: 604| Step: 0
Training loss: 1.7692937850952148
Validation loss: 2.1770101285749868

Epoch: 6| Step: 1
Training loss: 1.5151238441467285
Validation loss: 2.1800691235450005

Epoch: 6| Step: 2
Training loss: 1.0382659435272217
Validation loss: 2.1574761636795534

Epoch: 6| Step: 3
Training loss: 1.6235675811767578
Validation loss: 2.209184943988759

Epoch: 6| Step: 4
Training loss: 1.4115056991577148
Validation loss: 2.1905390575367916

Epoch: 6| Step: 5
Training loss: 1.3361189365386963
Validation loss: 2.112433241259667

Epoch: 6| Step: 6
Training loss: 1.2006092071533203
Validation loss: 2.161499604102104

Epoch: 6| Step: 7
Training loss: 2.098203659057617
Validation loss: 2.223240319118705

Epoch: 6| Step: 8
Training loss: 1.2876726388931274
Validation loss: 2.2862379499661025

Epoch: 6| Step: 9
Training loss: 1.386306881904602
Validation loss: 2.226088698192309

Epoch: 6| Step: 10
Training loss: 1.4526009559631348
Validation loss: 2.1977373605133383

Epoch: 6| Step: 11
Training loss: 1.3563743829727173
Validation loss: 2.217030066315846

Epoch: 6| Step: 12
Training loss: 1.3416286706924438
Validation loss: 2.1608871170269546

Epoch: 6| Step: 13
Training loss: 0.9717250466346741
Validation loss: 2.2209032607334915

Epoch: 605| Step: 0
Training loss: 1.2150753736495972
Validation loss: 2.207086500301156

Epoch: 6| Step: 1
Training loss: 1.0299344062805176
Validation loss: 2.164787389898813

Epoch: 6| Step: 2
Training loss: 1.0043613910675049
Validation loss: 2.2274544187771377

Epoch: 6| Step: 3
Training loss: 1.1262431144714355
Validation loss: 2.2048846496048795

Epoch: 6| Step: 4
Training loss: 1.2343944311141968
Validation loss: 2.1755402318892942

Epoch: 6| Step: 5
Training loss: 1.6075842380523682
Validation loss: 2.1868451333815053

Epoch: 6| Step: 6
Training loss: 1.4314489364624023
Validation loss: 2.213479749618038

Epoch: 6| Step: 7
Training loss: 1.01762855052948
Validation loss: 2.2594594634989256

Epoch: 6| Step: 8
Training loss: 1.8636353015899658
Validation loss: 2.2849920539445776

Epoch: 6| Step: 9
Training loss: 2.2171173095703125
Validation loss: 2.2222447626052366

Epoch: 6| Step: 10
Training loss: 1.4479464292526245
Validation loss: 2.176836198376071

Epoch: 6| Step: 11
Training loss: 1.745976209640503
Validation loss: 2.160326329610681

Epoch: 6| Step: 12
Training loss: 1.6022223234176636
Validation loss: 2.144251000496649

Epoch: 6| Step: 13
Training loss: 1.686332106590271
Validation loss: 2.120884713306222

Epoch: 606| Step: 0
Training loss: 1.098360538482666
Validation loss: 2.28411772430584

Epoch: 6| Step: 1
Training loss: 2.0109386444091797
Validation loss: 2.1901958078466435

Epoch: 6| Step: 2
Training loss: 0.952211856842041
Validation loss: 2.1547921575525755

Epoch: 6| Step: 3
Training loss: 1.332349181175232
Validation loss: 2.1782336619592484

Epoch: 6| Step: 4
Training loss: 1.749908685684204
Validation loss: 2.1275940069588284

Epoch: 6| Step: 5
Training loss: 2.3269753456115723
Validation loss: 2.089853427743399

Epoch: 6| Step: 6
Training loss: 1.7549173831939697
Validation loss: 2.137005299650213

Epoch: 6| Step: 7
Training loss: 0.9749794602394104
Validation loss: 2.159006445638595

Epoch: 6| Step: 8
Training loss: 1.9678783416748047
Validation loss: 2.176175179020051

Epoch: 6| Step: 9
Training loss: 1.2308392524719238
Validation loss: 2.1456173184097453

Epoch: 6| Step: 10
Training loss: 1.3661506175994873
Validation loss: 2.174196586813978

Epoch: 6| Step: 11
Training loss: 1.4817607402801514
Validation loss: 2.116689532033859

Epoch: 6| Step: 12
Training loss: 1.1277027130126953
Validation loss: 2.202894478715876

Epoch: 6| Step: 13
Training loss: 0.49720489978790283
Validation loss: 2.1806439635574177

Epoch: 607| Step: 0
Training loss: 1.690538763999939
Validation loss: 2.2063813901716665

Epoch: 6| Step: 1
Training loss: 1.1003193855285645
Validation loss: 2.1441552536461943

Epoch: 6| Step: 2
Training loss: 1.8774727582931519
Validation loss: 2.1667166268953713

Epoch: 6| Step: 3
Training loss: 1.494518518447876
Validation loss: 2.1591962460548646

Epoch: 6| Step: 4
Training loss: 1.1504497528076172
Validation loss: 2.233801326444072

Epoch: 6| Step: 5
Training loss: 1.4953773021697998
Validation loss: 2.206486202055408

Epoch: 6| Step: 6
Training loss: 1.2254455089569092
Validation loss: 2.2584950590646393

Epoch: 6| Step: 7
Training loss: 1.0497469902038574
Validation loss: 2.2539051219981205

Epoch: 6| Step: 8
Training loss: 1.307731032371521
Validation loss: 2.206867315435922

Epoch: 6| Step: 9
Training loss: 1.1987636089324951
Validation loss: 2.259100216691212

Epoch: 6| Step: 10
Training loss: 1.6395072937011719
Validation loss: 2.2335648716136975

Epoch: 6| Step: 11
Training loss: 1.576951265335083
Validation loss: 2.198926785940765

Epoch: 6| Step: 12
Training loss: 1.6712281703948975
Validation loss: 2.1952000946126957

Epoch: 6| Step: 13
Training loss: 1.9282069206237793
Validation loss: 2.2463537185422835

Epoch: 608| Step: 0
Training loss: 1.248795509338379
Validation loss: 2.1998275018507436

Epoch: 6| Step: 1
Training loss: 1.6942806243896484
Validation loss: 2.1818342580590198

Epoch: 6| Step: 2
Training loss: 1.1034742593765259
Validation loss: 2.1626896114759546

Epoch: 6| Step: 3
Training loss: 1.3763751983642578
Validation loss: 2.2212927956734934

Epoch: 6| Step: 4
Training loss: 0.911959707736969
Validation loss: 2.2241028816469255

Epoch: 6| Step: 5
Training loss: 1.3489879369735718
Validation loss: 2.1836542801190446

Epoch: 6| Step: 6
Training loss: 1.9107246398925781
Validation loss: 2.1610204942764772

Epoch: 6| Step: 7
Training loss: 0.6866236925125122
Validation loss: 2.1433209757651053

Epoch: 6| Step: 8
Training loss: 1.537687063217163
Validation loss: 2.108325601905905

Epoch: 6| Step: 9
Training loss: 1.9491528272628784
Validation loss: 2.2353697797303558

Epoch: 6| Step: 10
Training loss: 0.9737550020217896
Validation loss: 2.133813736259296

Epoch: 6| Step: 11
Training loss: 2.017740249633789
Validation loss: 2.1273637369114864

Epoch: 6| Step: 12
Training loss: 1.7140227556228638
Validation loss: 2.160299849766557

Epoch: 6| Step: 13
Training loss: 2.2337281703948975
Validation loss: 2.120477568718695

Epoch: 609| Step: 0
Training loss: 1.662816047668457
Validation loss: 2.169946719241399

Epoch: 6| Step: 1
Training loss: 1.3875079154968262
Validation loss: 2.1440574763923563

Epoch: 6| Step: 2
Training loss: 1.1040433645248413
Validation loss: 2.2122563777431363

Epoch: 6| Step: 3
Training loss: 1.3977302312850952
Validation loss: 2.166692926037696

Epoch: 6| Step: 4
Training loss: 1.5219147205352783
Validation loss: 2.1363273846205844

Epoch: 6| Step: 5
Training loss: 1.303763747215271
Validation loss: 2.1716715969065183

Epoch: 6| Step: 6
Training loss: 1.3295334577560425
Validation loss: 2.1867729976613033

Epoch: 6| Step: 7
Training loss: 1.3835606575012207
Validation loss: 2.229093619572219

Epoch: 6| Step: 8
Training loss: 1.7242136001586914
Validation loss: 2.140896958689536

Epoch: 6| Step: 9
Training loss: 1.1255483627319336
Validation loss: 2.23472430885479

Epoch: 6| Step: 10
Training loss: 1.3649473190307617
Validation loss: 2.2044519045019664

Epoch: 6| Step: 11
Training loss: 2.0211260318756104
Validation loss: 2.170006282867924

Epoch: 6| Step: 12
Training loss: 1.521032691001892
Validation loss: 2.232648270104521

Epoch: 6| Step: 13
Training loss: 1.7169244289398193
Validation loss: 2.1427807628467517

Epoch: 610| Step: 0
Training loss: 1.6734850406646729
Validation loss: 2.184443962189459

Epoch: 6| Step: 1
Training loss: 1.0595951080322266
Validation loss: 2.165366938037257

Epoch: 6| Step: 2
Training loss: 1.632393717765808
Validation loss: 2.1851465304692588

Epoch: 6| Step: 3
Training loss: 1.3145798444747925
Validation loss: 2.2326265611956195

Epoch: 6| Step: 4
Training loss: 1.6463308334350586
Validation loss: 2.117800718994551

Epoch: 6| Step: 5
Training loss: 0.7363973259925842
Validation loss: 2.111252430946596

Epoch: 6| Step: 6
Training loss: 1.449202537536621
Validation loss: 2.197889188284515

Epoch: 6| Step: 7
Training loss: 0.8921364545822144
Validation loss: 2.231765693233859

Epoch: 6| Step: 8
Training loss: 1.3267571926116943
Validation loss: 2.168238027121431

Epoch: 6| Step: 9
Training loss: 1.1927975416183472
Validation loss: 2.220803858131491

Epoch: 6| Step: 10
Training loss: 1.4291725158691406
Validation loss: 2.2509090092874344

Epoch: 6| Step: 11
Training loss: 1.728621006011963
Validation loss: 2.1833106881828717

Epoch: 6| Step: 12
Training loss: 2.398238182067871
Validation loss: 2.1267531148848997

Epoch: 6| Step: 13
Training loss: 2.5051043033599854
Validation loss: 2.2072841146940827

Epoch: 611| Step: 0
Training loss: 1.6279956102371216
Validation loss: 2.191775752652076

Epoch: 6| Step: 1
Training loss: 2.4452319145202637
Validation loss: 2.217096072371288

Epoch: 6| Step: 2
Training loss: 1.3321709632873535
Validation loss: 2.2610858396817277

Epoch: 6| Step: 3
Training loss: 1.3945696353912354
Validation loss: 2.198555504122088

Epoch: 6| Step: 4
Training loss: 1.9136912822723389
Validation loss: 2.138407673887027

Epoch: 6| Step: 5
Training loss: 1.1104402542114258
Validation loss: 2.145193140993836

Epoch: 6| Step: 6
Training loss: 1.0786900520324707
Validation loss: 2.1760805627351165

Epoch: 6| Step: 7
Training loss: 1.451736569404602
Validation loss: 2.1837269977856706

Epoch: 6| Step: 8
Training loss: 1.1382310390472412
Validation loss: 2.2268680423818608

Epoch: 6| Step: 9
Training loss: 1.6152762174606323
Validation loss: 2.1669041264441704

Epoch: 6| Step: 10
Training loss: 1.2680234909057617
Validation loss: 2.1866055701368596

Epoch: 6| Step: 11
Training loss: 0.8123235106468201
Validation loss: 2.1975285827472644

Epoch: 6| Step: 12
Training loss: 0.9249781370162964
Validation loss: 2.17846582781884

Epoch: 6| Step: 13
Training loss: 2.0475611686706543
Validation loss: 2.2215366671162267

Epoch: 612| Step: 0
Training loss: 1.2962346076965332
Validation loss: 2.1690244905410276

Epoch: 6| Step: 1
Training loss: 1.7519471645355225
Validation loss: 2.1556906802679903

Epoch: 6| Step: 2
Training loss: 1.764829158782959
Validation loss: 2.1849867374666276

Epoch: 6| Step: 3
Training loss: 1.246224284172058
Validation loss: 2.2356544079319125

Epoch: 6| Step: 4
Training loss: 1.0693557262420654
Validation loss: 2.171664978868218

Epoch: 6| Step: 5
Training loss: 1.2831220626831055
Validation loss: 2.2600845777860252

Epoch: 6| Step: 6
Training loss: 2.091749429702759
Validation loss: 2.2206691234342513

Epoch: 6| Step: 7
Training loss: 1.4783705472946167
Validation loss: 2.201903575210161

Epoch: 6| Step: 8
Training loss: 1.498755931854248
Validation loss: 2.1572956949151973

Epoch: 6| Step: 9
Training loss: 1.6216942071914673
Validation loss: 2.161588894423618

Epoch: 6| Step: 10
Training loss: 1.3199687004089355
Validation loss: 2.1299173831939697

Epoch: 6| Step: 11
Training loss: 1.4325294494628906
Validation loss: 2.150827137372827

Epoch: 6| Step: 12
Training loss: 0.8838508725166321
Validation loss: 2.2157527041691605

Epoch: 6| Step: 13
Training loss: 1.480141520500183
Validation loss: 2.2135794008931806

Epoch: 613| Step: 0
Training loss: 1.179652214050293
Validation loss: 2.175162499950778

Epoch: 6| Step: 1
Training loss: 1.2536019086837769
Validation loss: 2.1787471976331485

Epoch: 6| Step: 2
Training loss: 1.807587742805481
Validation loss: 2.1478943132585093

Epoch: 6| Step: 3
Training loss: 1.2027785778045654
Validation loss: 2.162228356125534

Epoch: 6| Step: 4
Training loss: 1.8973050117492676
Validation loss: 2.140171040770828

Epoch: 6| Step: 5
Training loss: 0.9837160706520081
Validation loss: 2.235589914424445

Epoch: 6| Step: 6
Training loss: 1.5174763202667236
Validation loss: 2.240513388828565

Epoch: 6| Step: 7
Training loss: 1.910060167312622
Validation loss: 2.2231575032716155

Epoch: 6| Step: 8
Training loss: 1.0678483247756958
Validation loss: 2.140520554716869

Epoch: 6| Step: 9
Training loss: 2.0334603786468506
Validation loss: 2.2348257572420183

Epoch: 6| Step: 10
Training loss: 1.5849584341049194
Validation loss: 2.2047423931860153

Epoch: 6| Step: 11
Training loss: 0.7552984356880188
Validation loss: 2.155829806481638

Epoch: 6| Step: 12
Training loss: 1.70894193649292
Validation loss: 2.186989766295238

Epoch: 6| Step: 13
Training loss: 1.2737926244735718
Validation loss: 2.0693539470754643

Epoch: 614| Step: 0
Training loss: 1.1831223964691162
Validation loss: 2.2128914722832302

Epoch: 6| Step: 1
Training loss: 1.2666817903518677
Validation loss: 2.1803222061485372

Epoch: 6| Step: 2
Training loss: 2.4266357421875
Validation loss: 2.1400324657399166

Epoch: 6| Step: 3
Training loss: 1.2100300788879395
Validation loss: 2.176804102877135

Epoch: 6| Step: 4
Training loss: 1.4110913276672363
Validation loss: 2.1730855677717473

Epoch: 6| Step: 5
Training loss: 1.7512218952178955
Validation loss: 2.1797969225914247

Epoch: 6| Step: 6
Training loss: 1.6019227504730225
Validation loss: 2.1633260186000536

Epoch: 6| Step: 7
Training loss: 0.9148117899894714
Validation loss: 2.2035915197864657

Epoch: 6| Step: 8
Training loss: 1.3360426425933838
Validation loss: 2.1706169343763784

Epoch: 6| Step: 9
Training loss: 1.3531365394592285
Validation loss: 2.0427287099181966

Epoch: 6| Step: 10
Training loss: 1.6313669681549072
Validation loss: 2.279237852301649

Epoch: 6| Step: 11
Training loss: 1.6117960214614868
Validation loss: 2.1894175160315728

Epoch: 6| Step: 12
Training loss: 1.190664291381836
Validation loss: 2.218980553329632

Epoch: 6| Step: 13
Training loss: 1.124559998512268
Validation loss: 2.1183277176272486

Epoch: 615| Step: 0
Training loss: 1.6395223140716553
Validation loss: 2.225466916638036

Epoch: 6| Step: 1
Training loss: 0.9019038677215576
Validation loss: 2.2309173319929387

Epoch: 6| Step: 2
Training loss: 1.732116460800171
Validation loss: 2.196372337238763

Epoch: 6| Step: 3
Training loss: 1.7580540180206299
Validation loss: 2.1951326119002474

Epoch: 6| Step: 4
Training loss: 1.6173481941223145
Validation loss: 2.279791952461325

Epoch: 6| Step: 5
Training loss: 1.4718503952026367
Validation loss: 2.2141578812753

Epoch: 6| Step: 6
Training loss: 0.7080022692680359
Validation loss: 2.2019305562460296

Epoch: 6| Step: 7
Training loss: 1.3368594646453857
Validation loss: 2.2436827664734214

Epoch: 6| Step: 8
Training loss: 0.8051371574401855
Validation loss: 2.1805876557544996

Epoch: 6| Step: 9
Training loss: 1.3716530799865723
Validation loss: 2.2184439423263713

Epoch: 6| Step: 10
Training loss: 0.8680829405784607
Validation loss: 2.1619921986774733

Epoch: 6| Step: 11
Training loss: 2.548983573913574
Validation loss: 2.1483972867329917

Epoch: 6| Step: 12
Training loss: 1.8637886047363281
Validation loss: 2.2207968568289154

Epoch: 6| Step: 13
Training loss: 1.1324950456619263
Validation loss: 2.169519060401506

Epoch: 616| Step: 0
Training loss: 1.3946012258529663
Validation loss: 2.151860321721723

Epoch: 6| Step: 1
Training loss: 1.4780775308609009
Validation loss: 2.168995908511582

Epoch: 6| Step: 2
Training loss: 1.4821773767471313
Validation loss: 2.1491852011731876

Epoch: 6| Step: 3
Training loss: 1.6836769580841064
Validation loss: 2.185715998372724

Epoch: 6| Step: 4
Training loss: 1.5853543281555176
Validation loss: 2.181384869801101

Epoch: 6| Step: 5
Training loss: 1.4192042350769043
Validation loss: 2.166799173560194

Epoch: 6| Step: 6
Training loss: 1.2730882167816162
Validation loss: 2.2049572442167547

Epoch: 6| Step: 7
Training loss: 1.4159092903137207
Validation loss: 2.123125404439947

Epoch: 6| Step: 8
Training loss: 1.1423578262329102
Validation loss: 2.2700965917238625

Epoch: 6| Step: 9
Training loss: 1.2028707265853882
Validation loss: 2.23673875101151

Epoch: 6| Step: 10
Training loss: 1.6651147603988647
Validation loss: 2.179453070445727

Epoch: 6| Step: 11
Training loss: 1.3921281099319458
Validation loss: 2.1429205043341524

Epoch: 6| Step: 12
Training loss: 1.898667812347412
Validation loss: 2.1492517379022416

Epoch: 6| Step: 13
Training loss: 0.9085362553596497
Validation loss: 2.2311872538699897

Epoch: 617| Step: 0
Training loss: 1.5722159147262573
Validation loss: 2.202475699045325

Epoch: 6| Step: 1
Training loss: 1.5787296295166016
Validation loss: 2.216408911571708

Epoch: 6| Step: 2
Training loss: 2.028324604034424
Validation loss: 2.179405771276002

Epoch: 6| Step: 3
Training loss: 2.2493906021118164
Validation loss: 2.2181391459639355

Epoch: 6| Step: 4
Training loss: 0.9761742949485779
Validation loss: 2.1826403089748916

Epoch: 6| Step: 5
Training loss: 1.9615201950073242
Validation loss: 2.15560265638495

Epoch: 6| Step: 6
Training loss: 1.2054555416107178
Validation loss: 2.144168834532461

Epoch: 6| Step: 7
Training loss: 1.1121214628219604
Validation loss: 2.180905351074793

Epoch: 6| Step: 8
Training loss: 0.7749979496002197
Validation loss: 2.1830029103063766

Epoch: 6| Step: 9
Training loss: 1.2953345775604248
Validation loss: 2.211685594692025

Epoch: 6| Step: 10
Training loss: 1.5310349464416504
Validation loss: 2.212321400642395

Epoch: 6| Step: 11
Training loss: 1.5409010648727417
Validation loss: 2.19567508082236

Epoch: 6| Step: 12
Training loss: 1.5235034227371216
Validation loss: 2.2343906535897204

Epoch: 6| Step: 13
Training loss: 1.6736174821853638
Validation loss: 2.135953149487895

Epoch: 618| Step: 0
Training loss: 0.6511691808700562
Validation loss: 2.1585479795291858

Epoch: 6| Step: 1
Training loss: 1.7881441116333008
Validation loss: 2.1345238736880723

Epoch: 6| Step: 2
Training loss: 1.7901264429092407
Validation loss: 2.172679683213593

Epoch: 6| Step: 3
Training loss: 1.0998036861419678
Validation loss: 2.202150155139226

Epoch: 6| Step: 4
Training loss: 1.5710577964782715
Validation loss: 2.2150856218030377

Epoch: 6| Step: 5
Training loss: 1.165377140045166
Validation loss: 2.1482763854406213

Epoch: 6| Step: 6
Training loss: 1.8624916076660156
Validation loss: 2.168132911446274

Epoch: 6| Step: 7
Training loss: 1.580888271331787
Validation loss: 2.185768873460831

Epoch: 6| Step: 8
Training loss: 0.952063798904419
Validation loss: 2.1608310745608423

Epoch: 6| Step: 9
Training loss: 1.9825893640518188
Validation loss: 2.09862510875989

Epoch: 6| Step: 10
Training loss: 1.1531544923782349
Validation loss: 2.1870021063794374

Epoch: 6| Step: 11
Training loss: 1.504895806312561
Validation loss: 2.116696221854097

Epoch: 6| Step: 12
Training loss: 1.4375042915344238
Validation loss: 2.237847392277051

Epoch: 6| Step: 13
Training loss: 1.3902734518051147
Validation loss: 2.1675524621881466

Epoch: 619| Step: 0
Training loss: 1.4886428117752075
Validation loss: 2.165285123291836

Epoch: 6| Step: 1
Training loss: 1.6410784721374512
Validation loss: 2.1662601091528453

Epoch: 6| Step: 2
Training loss: 1.243626594543457
Validation loss: 2.168217656432941

Epoch: 6| Step: 3
Training loss: 1.0414189100265503
Validation loss: 2.2310317126653527

Epoch: 6| Step: 4
Training loss: 1.484987497329712
Validation loss: 2.171022535652243

Epoch: 6| Step: 5
Training loss: 1.0101879835128784
Validation loss: 2.2342979113260903

Epoch: 6| Step: 6
Training loss: 1.3659758567810059
Validation loss: 2.1827550165114866

Epoch: 6| Step: 7
Training loss: 1.6804084777832031
Validation loss: 2.2493843237559

Epoch: 6| Step: 8
Training loss: 2.2487311363220215
Validation loss: 2.1040455948921943

Epoch: 6| Step: 9
Training loss: 0.8456026315689087
Validation loss: 2.2374726110889065

Epoch: 6| Step: 10
Training loss: 1.2488371133804321
Validation loss: 2.1902540396618586

Epoch: 6| Step: 11
Training loss: 1.0078290700912476
Validation loss: 2.167526114371515

Epoch: 6| Step: 12
Training loss: 1.7702598571777344
Validation loss: 2.2244852640295543

Epoch: 6| Step: 13
Training loss: 1.81370210647583
Validation loss: 2.2562869851307203

Epoch: 620| Step: 0
Training loss: 1.6135703325271606
Validation loss: 2.1786548181246688

Epoch: 6| Step: 1
Training loss: 1.7200899124145508
Validation loss: 2.1795848467016734

Epoch: 6| Step: 2
Training loss: 1.6288211345672607
Validation loss: 2.2066591144889913

Epoch: 6| Step: 3
Training loss: 0.8415093421936035
Validation loss: 2.1382711138776553

Epoch: 6| Step: 4
Training loss: 0.9643223285675049
Validation loss: 2.1576086013547835

Epoch: 6| Step: 5
Training loss: 2.055412769317627
Validation loss: 2.1554280814304145

Epoch: 6| Step: 6
Training loss: 1.7492327690124512
Validation loss: 2.1161565165365896

Epoch: 6| Step: 7
Training loss: 1.5229079723358154
Validation loss: 2.1600173955322592

Epoch: 6| Step: 8
Training loss: 1.041489601135254
Validation loss: 2.1743770184055453

Epoch: 6| Step: 9
Training loss: 1.1595649719238281
Validation loss: 2.1264458164092033

Epoch: 6| Step: 10
Training loss: 1.4521944522857666
Validation loss: 2.1479604423687024

Epoch: 6| Step: 11
Training loss: 1.274230718612671
Validation loss: 2.1371469292589413

Epoch: 6| Step: 12
Training loss: 1.3504139184951782
Validation loss: 2.089393131194576

Epoch: 6| Step: 13
Training loss: 1.5612144470214844
Validation loss: 2.1813540561224825

Epoch: 621| Step: 0
Training loss: 1.2948026657104492
Validation loss: 2.19627199890793

Epoch: 6| Step: 1
Training loss: 1.6772587299346924
Validation loss: 2.1917951171116163

Epoch: 6| Step: 2
Training loss: 1.4178528785705566
Validation loss: 2.203902180476855

Epoch: 6| Step: 3
Training loss: 1.1081416606903076
Validation loss: 2.1447615315837245

Epoch: 6| Step: 4
Training loss: 1.6013994216918945
Validation loss: 2.1457921228101178

Epoch: 6| Step: 5
Training loss: 1.2887868881225586
Validation loss: 2.1457573982977096

Epoch: 6| Step: 6
Training loss: 1.5306837558746338
Validation loss: 2.1494174772693264

Epoch: 6| Step: 7
Training loss: 1.49501371383667
Validation loss: 2.1942081297597578

Epoch: 6| Step: 8
Training loss: 0.9795771837234497
Validation loss: 2.2338313492395545

Epoch: 6| Step: 9
Training loss: 1.2288060188293457
Validation loss: 2.2413656967942432

Epoch: 6| Step: 10
Training loss: 1.2501338720321655
Validation loss: 2.2256708452778478

Epoch: 6| Step: 11
Training loss: 1.9066625833511353
Validation loss: 2.2590735291921966

Epoch: 6| Step: 12
Training loss: 1.07314133644104
Validation loss: 2.122989272558561

Epoch: 6| Step: 13
Training loss: 1.0936150550842285
Validation loss: 2.225319109937196

Epoch: 622| Step: 0
Training loss: 1.5295374393463135
Validation loss: 2.1763881432112826

Epoch: 6| Step: 1
Training loss: 1.6641262769699097
Validation loss: 2.1977265573317006

Epoch: 6| Step: 2
Training loss: 1.3508007526397705
Validation loss: 2.207631616182225

Epoch: 6| Step: 3
Training loss: 1.6330876350402832
Validation loss: 2.156421684449719

Epoch: 6| Step: 4
Training loss: 1.574407935142517
Validation loss: 2.2191025967239053

Epoch: 6| Step: 5
Training loss: 1.6614488363265991
Validation loss: 2.141735440941267

Epoch: 6| Step: 6
Training loss: 1.6003222465515137
Validation loss: 2.192310030742358

Epoch: 6| Step: 7
Training loss: 0.8242957592010498
Validation loss: 2.168454013844972

Epoch: 6| Step: 8
Training loss: 1.2101349830627441
Validation loss: 2.1889202005119732

Epoch: 6| Step: 9
Training loss: 1.5021045207977295
Validation loss: 2.1389371425874772

Epoch: 6| Step: 10
Training loss: 1.8073203563690186
Validation loss: 2.2183894752174296

Epoch: 6| Step: 11
Training loss: 1.3023468255996704
Validation loss: 2.1800946035692768

Epoch: 6| Step: 12
Training loss: 1.4975740909576416
Validation loss: 2.1974285212896203

Epoch: 6| Step: 13
Training loss: 0.8251574039459229
Validation loss: 2.112253531332939

Epoch: 623| Step: 0
Training loss: 0.8899177312850952
Validation loss: 2.200213893767326

Epoch: 6| Step: 1
Training loss: 2.013024091720581
Validation loss: 2.1545846667341007

Epoch: 6| Step: 2
Training loss: 0.824545681476593
Validation loss: 2.201690758428266

Epoch: 6| Step: 3
Training loss: 1.6156606674194336
Validation loss: 2.168248972585124

Epoch: 6| Step: 4
Training loss: 1.4406507015228271
Validation loss: 2.166305504819398

Epoch: 6| Step: 5
Training loss: 1.206632137298584
Validation loss: 2.1584570689867904

Epoch: 6| Step: 6
Training loss: 1.2471097707748413
Validation loss: 2.1509335938320366

Epoch: 6| Step: 7
Training loss: 1.8073160648345947
Validation loss: 2.201058077555831

Epoch: 6| Step: 8
Training loss: 2.0262579917907715
Validation loss: 2.198333873543688

Epoch: 6| Step: 9
Training loss: 1.18792724609375
Validation loss: 2.1589101053053334

Epoch: 6| Step: 10
Training loss: 1.7007161378860474
Validation loss: 2.093653763494184

Epoch: 6| Step: 11
Training loss: 1.2018229961395264
Validation loss: 2.242355792753158

Epoch: 6| Step: 12
Training loss: 1.5067651271820068
Validation loss: 2.2235840469278316

Epoch: 6| Step: 13
Training loss: 1.750403881072998
Validation loss: 2.1540466841831

Epoch: 624| Step: 0
Training loss: 1.1954290866851807
Validation loss: 2.235425644023444

Epoch: 6| Step: 1
Training loss: 1.5178548097610474
Validation loss: 2.167366522614674

Epoch: 6| Step: 2
Training loss: 1.246694803237915
Validation loss: 2.165772423949293

Epoch: 6| Step: 3
Training loss: 1.608967900276184
Validation loss: 2.2097317403362644

Epoch: 6| Step: 4
Training loss: 0.9540413618087769
Validation loss: 2.172361945593229

Epoch: 6| Step: 5
Training loss: 1.9773613214492798
Validation loss: 2.245729495120305

Epoch: 6| Step: 6
Training loss: 1.306659460067749
Validation loss: 2.186950234956639

Epoch: 6| Step: 7
Training loss: 2.1156716346740723
Validation loss: 2.1963521331869145

Epoch: 6| Step: 8
Training loss: 1.5442219972610474
Validation loss: 2.1628211775133686

Epoch: 6| Step: 9
Training loss: 1.280194878578186
Validation loss: 2.129093840558042

Epoch: 6| Step: 10
Training loss: 0.9766353368759155
Validation loss: 2.1794431876110774

Epoch: 6| Step: 11
Training loss: 1.1409506797790527
Validation loss: 2.173576126816452

Epoch: 6| Step: 12
Training loss: 1.1999638080596924
Validation loss: 2.170273547531456

Epoch: 6| Step: 13
Training loss: 1.1125102043151855
Validation loss: 2.2093554260910198

Epoch: 625| Step: 0
Training loss: 1.8837952613830566
Validation loss: 2.193022189601775

Epoch: 6| Step: 1
Training loss: 0.7510924339294434
Validation loss: 2.191723756892707

Epoch: 6| Step: 2
Training loss: 1.7281702756881714
Validation loss: 2.3131461810040217

Epoch: 6| Step: 3
Training loss: 1.3768339157104492
Validation loss: 2.1839402311591694

Epoch: 6| Step: 4
Training loss: 0.941815197467804
Validation loss: 2.2362926313954015

Epoch: 6| Step: 5
Training loss: 1.2054049968719482
Validation loss: 2.178303328893518

Epoch: 6| Step: 6
Training loss: 1.8014980554580688
Validation loss: 2.236337520742929

Epoch: 6| Step: 7
Training loss: 1.1248481273651123
Validation loss: 2.2093642193783998

Epoch: 6| Step: 8
Training loss: 1.6864831447601318
Validation loss: 2.116204943708194

Epoch: 6| Step: 9
Training loss: 1.2338128089904785
Validation loss: 2.184466964455061

Epoch: 6| Step: 10
Training loss: 1.5797128677368164
Validation loss: 2.0959660673654206

Epoch: 6| Step: 11
Training loss: 1.0705933570861816
Validation loss: 2.182154796456778

Epoch: 6| Step: 12
Training loss: 1.7266223430633545
Validation loss: 2.1383047334609495

Epoch: 6| Step: 13
Training loss: 1.4203916788101196
Validation loss: 2.243745121904599

Epoch: 626| Step: 0
Training loss: 1.5124832391738892
Validation loss: 2.1373118174973356

Epoch: 6| Step: 1
Training loss: 1.3423597812652588
Validation loss: 2.1981661960642827

Epoch: 6| Step: 2
Training loss: 0.9263075590133667
Validation loss: 2.050369570332189

Epoch: 6| Step: 3
Training loss: 1.8715572357177734
Validation loss: 2.127974215374198

Epoch: 6| Step: 4
Training loss: 1.363372564315796
Validation loss: 2.1591384846677064

Epoch: 6| Step: 5
Training loss: 1.5548510551452637
Validation loss: 2.1244474098246586

Epoch: 6| Step: 6
Training loss: 1.5482265949249268
Validation loss: 2.214215863135553

Epoch: 6| Step: 7
Training loss: 0.7470847964286804
Validation loss: 2.2888990550912838

Epoch: 6| Step: 8
Training loss: 1.1884534358978271
Validation loss: 2.197075222128181

Epoch: 6| Step: 9
Training loss: 1.7193430662155151
Validation loss: 2.2220127044185514

Epoch: 6| Step: 10
Training loss: 1.7524454593658447
Validation loss: 2.2065090569116736

Epoch: 6| Step: 11
Training loss: 1.3338263034820557
Validation loss: 2.1888273787754837

Epoch: 6| Step: 12
Training loss: 1.223233938217163
Validation loss: 2.2611453456263386

Epoch: 6| Step: 13
Training loss: 1.1378321647644043
Validation loss: 2.2096886801463302

Epoch: 627| Step: 0
Training loss: 1.782875418663025
Validation loss: 2.205296713818786

Epoch: 6| Step: 1
Training loss: 1.8749345541000366
Validation loss: 2.197192871442405

Epoch: 6| Step: 2
Training loss: 1.7765849828720093
Validation loss: 2.2204417208189606

Epoch: 6| Step: 3
Training loss: 1.4215991497039795
Validation loss: 2.101631869551956

Epoch: 6| Step: 4
Training loss: 1.565521478652954
Validation loss: 2.1986778064440657

Epoch: 6| Step: 5
Training loss: 1.196133017539978
Validation loss: 2.1405537000266452

Epoch: 6| Step: 6
Training loss: 1.604851484298706
Validation loss: 2.163179425783055

Epoch: 6| Step: 7
Training loss: 1.0534722805023193
Validation loss: 2.2032859351045344

Epoch: 6| Step: 8
Training loss: 1.410821795463562
Validation loss: 2.199183448668449

Epoch: 6| Step: 9
Training loss: 0.9672759771347046
Validation loss: 2.211670175675423

Epoch: 6| Step: 10
Training loss: 1.1912205219268799
Validation loss: 2.1872822520553425

Epoch: 6| Step: 11
Training loss: 1.3792273998260498
Validation loss: 2.2081755027976087

Epoch: 6| Step: 12
Training loss: 1.3657739162445068
Validation loss: 2.204670380520564

Epoch: 6| Step: 13
Training loss: 1.2602953910827637
Validation loss: 2.2149865217106317

Epoch: 628| Step: 0
Training loss: 0.950743556022644
Validation loss: 2.2302209074779222

Epoch: 6| Step: 1
Training loss: 1.2860186100006104
Validation loss: 2.1721667602498043

Epoch: 6| Step: 2
Training loss: 2.110992670059204
Validation loss: 2.1503290514792166

Epoch: 6| Step: 3
Training loss: 1.1064921617507935
Validation loss: 2.1675707973459715

Epoch: 6| Step: 4
Training loss: 1.077392816543579
Validation loss: 2.2133329735007337

Epoch: 6| Step: 5
Training loss: 1.5864019393920898
Validation loss: 2.230694527267128

Epoch: 6| Step: 6
Training loss: 1.1864347457885742
Validation loss: 2.2251104462531304

Epoch: 6| Step: 7
Training loss: 1.4269425868988037
Validation loss: 2.1924175600851736

Epoch: 6| Step: 8
Training loss: 1.7949144840240479
Validation loss: 2.3505177395318144

Epoch: 6| Step: 9
Training loss: 1.0989387035369873
Validation loss: 2.2166807497701337

Epoch: 6| Step: 10
Training loss: 1.517049789428711
Validation loss: 2.1333224875952608

Epoch: 6| Step: 11
Training loss: 1.8324469327926636
Validation loss: 2.1974613102533485

Epoch: 6| Step: 12
Training loss: 0.8867940902709961
Validation loss: 2.1384086442250076

Epoch: 6| Step: 13
Training loss: 1.2952158451080322
Validation loss: 2.1356527625873523

Epoch: 629| Step: 0
Training loss: 2.1886768341064453
Validation loss: 2.264216282034433

Epoch: 6| Step: 1
Training loss: 1.7715489864349365
Validation loss: 2.1855538993753414

Epoch: 6| Step: 2
Training loss: 1.0940513610839844
Validation loss: 2.176635039749966

Epoch: 6| Step: 3
Training loss: 1.090054988861084
Validation loss: 2.2115337746117705

Epoch: 6| Step: 4
Training loss: 1.0138444900512695
Validation loss: 2.1729289536835044

Epoch: 6| Step: 5
Training loss: 1.3186224699020386
Validation loss: 2.1340489977149555

Epoch: 6| Step: 6
Training loss: 1.161755084991455
Validation loss: 2.1775092540248746

Epoch: 6| Step: 7
Training loss: 1.1572139263153076
Validation loss: 2.0792023879225536

Epoch: 6| Step: 8
Training loss: 1.008482575416565
Validation loss: 2.2765636828637894

Epoch: 6| Step: 9
Training loss: 1.979170322418213
Validation loss: 2.255170460670225

Epoch: 6| Step: 10
Training loss: 1.1330773830413818
Validation loss: 2.170117732017271

Epoch: 6| Step: 11
Training loss: 1.4172425270080566
Validation loss: 2.172020290487556

Epoch: 6| Step: 12
Training loss: 2.1721107959747314
Validation loss: 2.14997604585463

Epoch: 6| Step: 13
Training loss: 1.2693272829055786
Validation loss: 2.2038572142201085

Epoch: 630| Step: 0
Training loss: 2.350430488586426
Validation loss: 2.2304398936610066

Epoch: 6| Step: 1
Training loss: 1.7365754842758179
Validation loss: 2.1182469552563084

Epoch: 6| Step: 2
Training loss: 1.1091915369033813
Validation loss: 2.1287489091196368

Epoch: 6| Step: 3
Training loss: 1.538149118423462
Validation loss: 2.2590781129816526

Epoch: 6| Step: 4
Training loss: 1.9254546165466309
Validation loss: 2.172664911516251

Epoch: 6| Step: 5
Training loss: 1.348844051361084
Validation loss: 2.1769631562694425

Epoch: 6| Step: 6
Training loss: 1.3672175407409668
Validation loss: 2.1839522777065152

Epoch: 6| Step: 7
Training loss: 1.3581185340881348
Validation loss: 2.1990814567894064

Epoch: 6| Step: 8
Training loss: 1.1213676929473877
Validation loss: 2.1865165131066435

Epoch: 6| Step: 9
Training loss: 1.138516902923584
Validation loss: 2.1092422828879407

Epoch: 6| Step: 10
Training loss: 1.588944435119629
Validation loss: 2.1861203614101616

Epoch: 6| Step: 11
Training loss: 1.0062671899795532
Validation loss: 2.2337997421141593

Epoch: 6| Step: 12
Training loss: 1.2348690032958984
Validation loss: 2.215189515903432

Epoch: 6| Step: 13
Training loss: 1.384217381477356
Validation loss: 2.2101473782652166

Epoch: 631| Step: 0
Training loss: 1.4441968202590942
Validation loss: 2.1413141553119948

Epoch: 6| Step: 1
Training loss: 1.1087985038757324
Validation loss: 2.159875044258692

Epoch: 6| Step: 2
Training loss: 0.7733471989631653
Validation loss: 2.1401198551219

Epoch: 6| Step: 3
Training loss: 1.5415923595428467
Validation loss: 2.168312621373002

Epoch: 6| Step: 4
Training loss: 1.4657795429229736
Validation loss: 2.212834858125256

Epoch: 6| Step: 5
Training loss: 1.307766079902649
Validation loss: 2.1998354337548696

Epoch: 6| Step: 6
Training loss: 1.6475279331207275
Validation loss: 2.2629139115733485

Epoch: 6| Step: 7
Training loss: 2.081178665161133
Validation loss: 2.1658294559806905

Epoch: 6| Step: 8
Training loss: 1.0705077648162842
Validation loss: 2.1957798875788206

Epoch: 6| Step: 9
Training loss: 1.6939587593078613
Validation loss: 2.2072529792785645

Epoch: 6| Step: 10
Training loss: 1.4406278133392334
Validation loss: 2.19925102110832

Epoch: 6| Step: 11
Training loss: 1.5788944959640503
Validation loss: 2.1750642817507506

Epoch: 6| Step: 12
Training loss: 1.0880792140960693
Validation loss: 2.2287992854272165

Epoch: 6| Step: 13
Training loss: 1.6882972717285156
Validation loss: 2.1359684492952082

Epoch: 632| Step: 0
Training loss: 1.1162198781967163
Validation loss: 2.178460690283006

Epoch: 6| Step: 1
Training loss: 0.7966001629829407
Validation loss: 2.202493968830314

Epoch: 6| Step: 2
Training loss: 1.1719732284545898
Validation loss: 2.1406021451437347

Epoch: 6| Step: 3
Training loss: 1.5617834329605103
Validation loss: 2.2165357989649617

Epoch: 6| Step: 4
Training loss: 1.417421579360962
Validation loss: 2.186754245911875

Epoch: 6| Step: 5
Training loss: 2.22621750831604
Validation loss: 2.182553122120519

Epoch: 6| Step: 6
Training loss: 1.56423020362854
Validation loss: 2.1266838735149753

Epoch: 6| Step: 7
Training loss: 0.970628023147583
Validation loss: 2.1210096638689757

Epoch: 6| Step: 8
Training loss: 1.7856135368347168
Validation loss: 2.1749554231602657

Epoch: 6| Step: 9
Training loss: 1.9186688661575317
Validation loss: 2.1892112788333686

Epoch: 6| Step: 10
Training loss: 1.9343687295913696
Validation loss: 2.18663094505187

Epoch: 6| Step: 11
Training loss: 1.1979928016662598
Validation loss: 2.11512146201185

Epoch: 6| Step: 12
Training loss: 1.2515053749084473
Validation loss: 2.115599124662338

Epoch: 6| Step: 13
Training loss: 1.4182219505310059
Validation loss: 2.1782179058239026

Epoch: 633| Step: 0
Training loss: 1.4606691598892212
Validation loss: 2.1210350964659

Epoch: 6| Step: 1
Training loss: 0.8653801679611206
Validation loss: 2.17904128566865

Epoch: 6| Step: 2
Training loss: 1.7448581457138062
Validation loss: 2.235889337396109

Epoch: 6| Step: 3
Training loss: 1.0911836624145508
Validation loss: 2.211381914795086

Epoch: 6| Step: 4
Training loss: 1.2911858558654785
Validation loss: 2.2041654432973554

Epoch: 6| Step: 5
Training loss: 1.1029484272003174
Validation loss: 2.1833609483575307

Epoch: 6| Step: 6
Training loss: 1.2859556674957275
Validation loss: 2.252179786723147

Epoch: 6| Step: 7
Training loss: 1.0507012605667114
Validation loss: 2.2990498824786116

Epoch: 6| Step: 8
Training loss: 1.4430623054504395
Validation loss: 2.2099461658026582

Epoch: 6| Step: 9
Training loss: 1.8935679197311401
Validation loss: 2.1875337605835288

Epoch: 6| Step: 10
Training loss: 1.0669138431549072
Validation loss: 2.208268578334521

Epoch: 6| Step: 11
Training loss: 1.5636203289031982
Validation loss: 2.143912101304659

Epoch: 6| Step: 12
Training loss: 2.3746519088745117
Validation loss: 2.254752012991136

Epoch: 6| Step: 13
Training loss: 1.5061001777648926
Validation loss: 2.143884966450353

Epoch: 634| Step: 0
Training loss: 1.2341225147247314
Validation loss: 2.179009734943349

Epoch: 6| Step: 1
Training loss: 1.0133614540100098
Validation loss: 2.2162878820973058

Epoch: 6| Step: 2
Training loss: 1.1098029613494873
Validation loss: 2.122923861267746

Epoch: 6| Step: 3
Training loss: 1.581166386604309
Validation loss: 2.1444173859011744

Epoch: 6| Step: 4
Training loss: 1.6997244358062744
Validation loss: 2.3085671189010784

Epoch: 6| Step: 5
Training loss: 1.307309627532959
Validation loss: 2.1494937635237172

Epoch: 6| Step: 6
Training loss: 1.6620187759399414
Validation loss: 2.1539126993507467

Epoch: 6| Step: 7
Training loss: 0.8110228776931763
Validation loss: 2.1180078957670476

Epoch: 6| Step: 8
Training loss: 1.9539241790771484
Validation loss: 2.2195690062738236

Epoch: 6| Step: 9
Training loss: 1.942860722541809
Validation loss: 2.195659440050843

Epoch: 6| Step: 10
Training loss: 1.4236762523651123
Validation loss: 2.166777405687558

Epoch: 6| Step: 11
Training loss: 1.3058308362960815
Validation loss: 2.209412996486951

Epoch: 6| Step: 12
Training loss: 1.4083847999572754
Validation loss: 2.2240830595775316

Epoch: 6| Step: 13
Training loss: 1.016442894935608
Validation loss: 2.1802641448154243

Epoch: 635| Step: 0
Training loss: 1.3332934379577637
Validation loss: 2.1927738984425864

Epoch: 6| Step: 1
Training loss: 1.5643117427825928
Validation loss: 2.220028705494378

Epoch: 6| Step: 2
Training loss: 1.212954044342041
Validation loss: 2.204502450522556

Epoch: 6| Step: 3
Training loss: 1.0348669290542603
Validation loss: 2.2076048543376308

Epoch: 6| Step: 4
Training loss: 1.2081172466278076
Validation loss: 2.2402670767999466

Epoch: 6| Step: 5
Training loss: 2.255060911178589
Validation loss: 2.1955293596431775

Epoch: 6| Step: 6
Training loss: 1.8048361539840698
Validation loss: 2.210921641319029

Epoch: 6| Step: 7
Training loss: 1.8020281791687012
Validation loss: 2.189719864117202

Epoch: 6| Step: 8
Training loss: 1.4983673095703125
Validation loss: 2.1880557972897767

Epoch: 6| Step: 9
Training loss: 0.9760629534721375
Validation loss: 2.2380862774387484

Epoch: 6| Step: 10
Training loss: 1.4078419208526611
Validation loss: 2.170159282222871

Epoch: 6| Step: 11
Training loss: 1.1533347368240356
Validation loss: 2.1813029999374063

Epoch: 6| Step: 12
Training loss: 1.2033621072769165
Validation loss: 2.1233655227127897

Epoch: 6| Step: 13
Training loss: 1.501344084739685
Validation loss: 2.1916218162864767

Epoch: 636| Step: 0
Training loss: 2.152039051055908
Validation loss: 2.2046817784668296

Epoch: 6| Step: 1
Training loss: 1.8790481090545654
Validation loss: 2.208413016411566

Epoch: 6| Step: 2
Training loss: 1.334794044494629
Validation loss: 2.20982087555752

Epoch: 6| Step: 3
Training loss: 1.5796725749969482
Validation loss: 2.182864699312436

Epoch: 6| Step: 4
Training loss: 1.3064662218093872
Validation loss: 2.1769873070460495

Epoch: 6| Step: 5
Training loss: 1.9844787120819092
Validation loss: 2.1640559345163326

Epoch: 6| Step: 6
Training loss: 1.1363224983215332
Validation loss: 2.19485052170292

Epoch: 6| Step: 7
Training loss: 1.5225707292556763
Validation loss: 2.1337178522540676

Epoch: 6| Step: 8
Training loss: 0.5994627475738525
Validation loss: 2.192064792879166

Epoch: 6| Step: 9
Training loss: 1.3092541694641113
Validation loss: 2.1492040875137493

Epoch: 6| Step: 10
Training loss: 1.4176321029663086
Validation loss: 2.1485533201566307

Epoch: 6| Step: 11
Training loss: 1.0665535926818848
Validation loss: 2.172336119477467

Epoch: 6| Step: 12
Training loss: 0.9379796385765076
Validation loss: 2.1776590385744647

Epoch: 6| Step: 13
Training loss: 1.2526144981384277
Validation loss: 2.197840141993697

Epoch: 637| Step: 0
Training loss: 1.583804965019226
Validation loss: 2.133355176577004

Epoch: 6| Step: 1
Training loss: 1.5560569763183594
Validation loss: 2.176887824971189

Epoch: 6| Step: 2
Training loss: 1.6231365203857422
Validation loss: 2.1456659519544212

Epoch: 6| Step: 3
Training loss: 1.4338103532791138
Validation loss: 2.19023790923498

Epoch: 6| Step: 4
Training loss: 1.6135990619659424
Validation loss: 2.1868374052868096

Epoch: 6| Step: 5
Training loss: 1.4805423021316528
Validation loss: 2.1770926803670902

Epoch: 6| Step: 6
Training loss: 1.1966472864151
Validation loss: 2.1743969481478453

Epoch: 6| Step: 7
Training loss: 1.9931515455245972
Validation loss: 2.1745723729492514

Epoch: 6| Step: 8
Training loss: 0.7515806555747986
Validation loss: 2.072653006481868

Epoch: 6| Step: 9
Training loss: 1.0228323936462402
Validation loss: 2.105875285722876

Epoch: 6| Step: 10
Training loss: 1.028166651725769
Validation loss: 2.1919376439945673

Epoch: 6| Step: 11
Training loss: 1.0632548332214355
Validation loss: 2.1908691237049718

Epoch: 6| Step: 12
Training loss: 1.3878049850463867
Validation loss: 2.1612335020496

Epoch: 6| Step: 13
Training loss: 1.1979780197143555
Validation loss: 2.2423746265390867

Epoch: 638| Step: 0
Training loss: 1.711444616317749
Validation loss: 2.1645286749768

Epoch: 6| Step: 1
Training loss: 1.0733654499053955
Validation loss: 2.1231745186672417

Epoch: 6| Step: 2
Training loss: 1.114676833152771
Validation loss: 2.2455749383536716

Epoch: 6| Step: 3
Training loss: 1.2178752422332764
Validation loss: 2.2273560057404223

Epoch: 6| Step: 4
Training loss: 1.314133644104004
Validation loss: 2.1701854505846576

Epoch: 6| Step: 5
Training loss: 1.450897455215454
Validation loss: 2.258764046494679

Epoch: 6| Step: 6
Training loss: 1.3450757265090942
Validation loss: 2.2595109913938787

Epoch: 6| Step: 7
Training loss: 1.2615611553192139
Validation loss: 2.1824707869560487

Epoch: 6| Step: 8
Training loss: 1.5456805229187012
Validation loss: 2.1928777028155584

Epoch: 6| Step: 9
Training loss: 1.0542340278625488
Validation loss: 2.1176898735825733

Epoch: 6| Step: 10
Training loss: 1.5982484817504883
Validation loss: 2.254203955332438

Epoch: 6| Step: 11
Training loss: 1.7942060232162476
Validation loss: 2.1526384122910036

Epoch: 6| Step: 12
Training loss: 1.3358649015426636
Validation loss: 2.273024980739881

Epoch: 6| Step: 13
Training loss: 1.9485443830490112
Validation loss: 2.2225836810245307

Epoch: 639| Step: 0
Training loss: 1.1991631984710693
Validation loss: 2.1765403029739216

Epoch: 6| Step: 1
Training loss: 1.0802280902862549
Validation loss: 2.2025887927701397

Epoch: 6| Step: 2
Training loss: 1.1085716485977173
Validation loss: 2.123781891279323

Epoch: 6| Step: 3
Training loss: 1.3928771018981934
Validation loss: 2.161175707335113

Epoch: 6| Step: 4
Training loss: 1.3169915676116943
Validation loss: 2.317046908922093

Epoch: 6| Step: 5
Training loss: 1.3737671375274658
Validation loss: 2.1309660942323747

Epoch: 6| Step: 6
Training loss: 1.232683777809143
Validation loss: 2.204754724297472

Epoch: 6| Step: 7
Training loss: 1.7538180351257324
Validation loss: 2.234007663624261

Epoch: 6| Step: 8
Training loss: 1.3491301536560059
Validation loss: 2.227761448070567

Epoch: 6| Step: 9
Training loss: 1.4674698114395142
Validation loss: 2.1665001889710784

Epoch: 6| Step: 10
Training loss: 1.4948227405548096
Validation loss: 2.137212594350179

Epoch: 6| Step: 11
Training loss: 2.047311782836914
Validation loss: 2.2016435797496507

Epoch: 6| Step: 12
Training loss: 1.2663322687149048
Validation loss: 2.175732256263815

Epoch: 6| Step: 13
Training loss: 1.1576027870178223
Validation loss: 2.2044446955444994

Epoch: 640| Step: 0
Training loss: 1.122096300125122
Validation loss: 2.2223577730117308

Epoch: 6| Step: 1
Training loss: 1.7122790813446045
Validation loss: 2.1653039327231784

Epoch: 6| Step: 2
Training loss: 0.960266649723053
Validation loss: 2.26263621289243

Epoch: 6| Step: 3
Training loss: 1.2577980756759644
Validation loss: 2.153063284453525

Epoch: 6| Step: 4
Training loss: 1.4713852405548096
Validation loss: 2.1511826810016426

Epoch: 6| Step: 5
Training loss: 1.343827247619629
Validation loss: 2.1154754995017924

Epoch: 6| Step: 6
Training loss: 1.5782016515731812
Validation loss: 2.2608844054642545

Epoch: 6| Step: 7
Training loss: 1.3646750450134277
Validation loss: 2.1362117695552048

Epoch: 6| Step: 8
Training loss: 2.1805429458618164
Validation loss: 2.1285582178382465

Epoch: 6| Step: 9
Training loss: 1.3927247524261475
Validation loss: 2.1785253401725524

Epoch: 6| Step: 10
Training loss: 1.201735019683838
Validation loss: 2.1503652654668337

Epoch: 6| Step: 11
Training loss: 1.3156070709228516
Validation loss: 2.1985478042274393

Epoch: 6| Step: 12
Training loss: 1.0762889385223389
Validation loss: 2.116061479814591

Epoch: 6| Step: 13
Training loss: 0.848682701587677
Validation loss: 2.1869914813708236

Epoch: 641| Step: 0
Training loss: 1.0919122695922852
Validation loss: 2.1778651886088873

Epoch: 6| Step: 1
Training loss: 2.206162691116333
Validation loss: 2.1347947556485414

Epoch: 6| Step: 2
Training loss: 1.0259805917739868
Validation loss: 2.2074112430695565

Epoch: 6| Step: 3
Training loss: 0.7667620182037354
Validation loss: 2.222777517892981

Epoch: 6| Step: 4
Training loss: 1.6971213817596436
Validation loss: 2.2102907178222493

Epoch: 6| Step: 5
Training loss: 1.373396873474121
Validation loss: 2.281693189374862

Epoch: 6| Step: 6
Training loss: 1.2830491065979004
Validation loss: 2.3143902286406486

Epoch: 6| Step: 7
Training loss: 1.609327793121338
Validation loss: 2.173734546989523

Epoch: 6| Step: 8
Training loss: 1.2542872428894043
Validation loss: 2.2881958587195284

Epoch: 6| Step: 9
Training loss: 1.3391603231430054
Validation loss: 2.212732917519026

Epoch: 6| Step: 10
Training loss: 1.5044244527816772
Validation loss: 2.1592746908946703

Epoch: 6| Step: 11
Training loss: 1.400527834892273
Validation loss: 2.2336549579456286

Epoch: 6| Step: 12
Training loss: 1.2538970708847046
Validation loss: 2.241610728284364

Epoch: 6| Step: 13
Training loss: 1.412724256515503
Validation loss: 2.101514665029382

Epoch: 642| Step: 0
Training loss: 0.8925063610076904
Validation loss: 2.1790940812838975

Epoch: 6| Step: 1
Training loss: 2.212225914001465
Validation loss: 2.174901893061976

Epoch: 6| Step: 2
Training loss: 0.8305719494819641
Validation loss: 2.144882784094862

Epoch: 6| Step: 3
Training loss: 1.5843359231948853
Validation loss: 2.2177555689247708

Epoch: 6| Step: 4
Training loss: 0.6242402791976929
Validation loss: 2.1096927196748796

Epoch: 6| Step: 5
Training loss: 1.5683075189590454
Validation loss: 2.2200893996864237

Epoch: 6| Step: 6
Training loss: 1.457533836364746
Validation loss: 2.178706248601278

Epoch: 6| Step: 7
Training loss: 1.5870345830917358
Validation loss: 2.1270379558686288

Epoch: 6| Step: 8
Training loss: 1.1670563220977783
Validation loss: 2.2167542903654036

Epoch: 6| Step: 9
Training loss: 0.8065694570541382
Validation loss: 2.198439280192057

Epoch: 6| Step: 10
Training loss: 1.9036943912506104
Validation loss: 2.21856003679255

Epoch: 6| Step: 11
Training loss: 1.1212824583053589
Validation loss: 2.151061274672067

Epoch: 6| Step: 12
Training loss: 1.514500617980957
Validation loss: 2.2339628358041086

Epoch: 6| Step: 13
Training loss: 2.063819408416748
Validation loss: 2.1168109601543796

Epoch: 643| Step: 0
Training loss: 1.4600751399993896
Validation loss: 2.206473610734427

Epoch: 6| Step: 1
Training loss: 1.4763288497924805
Validation loss: 2.146986246109009

Epoch: 6| Step: 2
Training loss: 1.764875054359436
Validation loss: 2.149785577609975

Epoch: 6| Step: 3
Training loss: 0.8883289098739624
Validation loss: 2.1644885591281358

Epoch: 6| Step: 4
Training loss: 1.389864444732666
Validation loss: 2.0994977707503946

Epoch: 6| Step: 5
Training loss: 1.299360990524292
Validation loss: 2.157555475029894

Epoch: 6| Step: 6
Training loss: 1.6931769847869873
Validation loss: 2.1710731214092625

Epoch: 6| Step: 7
Training loss: 1.4926230907440186
Validation loss: 2.1265579795324676

Epoch: 6| Step: 8
Training loss: 2.237414836883545
Validation loss: 2.1539362489536242

Epoch: 6| Step: 9
Training loss: 1.0096149444580078
Validation loss: 2.226122838194652

Epoch: 6| Step: 10
Training loss: 0.9388882517814636
Validation loss: 2.1762989810718003

Epoch: 6| Step: 11
Training loss: 1.3038803339004517
Validation loss: 2.163801702119971

Epoch: 6| Step: 12
Training loss: 1.589820146560669
Validation loss: 2.1459074892023557

Epoch: 6| Step: 13
Training loss: 0.8248754739761353
Validation loss: 2.16585418357644

Epoch: 644| Step: 0
Training loss: 1.2992210388183594
Validation loss: 2.1804465683557654

Epoch: 6| Step: 1
Training loss: 1.2838605642318726
Validation loss: 2.1443323448140132

Epoch: 6| Step: 2
Training loss: 1.8626806735992432
Validation loss: 2.17575047093053

Epoch: 6| Step: 3
Training loss: 1.4656115770339966
Validation loss: 2.168855328713694

Epoch: 6| Step: 4
Training loss: 1.6535625457763672
Validation loss: 2.116579068604336

Epoch: 6| Step: 5
Training loss: 1.611138105392456
Validation loss: 2.19837757079832

Epoch: 6| Step: 6
Training loss: 1.13472580909729
Validation loss: 2.090625834721391

Epoch: 6| Step: 7
Training loss: 2.092935562133789
Validation loss: 2.2648895530290503

Epoch: 6| Step: 8
Training loss: 1.2573784589767456
Validation loss: 2.19664530856635

Epoch: 6| Step: 9
Training loss: 1.3041290044784546
Validation loss: 2.166624476832728

Epoch: 6| Step: 10
Training loss: 1.3938353061676025
Validation loss: 2.1444031153955767

Epoch: 6| Step: 11
Training loss: 0.8051972389221191
Validation loss: 2.2194315310447448

Epoch: 6| Step: 12
Training loss: 0.9628820419311523
Validation loss: 2.2265281677246094

Epoch: 6| Step: 13
Training loss: 1.8953653573989868
Validation loss: 2.2379865261816208

Epoch: 645| Step: 0
Training loss: 1.848228931427002
Validation loss: 2.2149649948202152

Epoch: 6| Step: 1
Training loss: 1.3318867683410645
Validation loss: 2.217077780795354

Epoch: 6| Step: 2
Training loss: 1.197817325592041
Validation loss: 2.2304341844333115

Epoch: 6| Step: 3
Training loss: 0.9060522317886353
Validation loss: 2.2019380882222164

Epoch: 6| Step: 4
Training loss: 1.980589509010315
Validation loss: 2.250614015004968

Epoch: 6| Step: 5
Training loss: 1.349761962890625
Validation loss: 2.199951764075987

Epoch: 6| Step: 6
Training loss: 1.434809684753418
Validation loss: 2.18172683254365

Epoch: 6| Step: 7
Training loss: 1.0690762996673584
Validation loss: 2.1195500461004113

Epoch: 6| Step: 8
Training loss: 1.9631508588790894
Validation loss: 2.109936656490449

Epoch: 6| Step: 9
Training loss: 0.9611775875091553
Validation loss: 2.154485243622975

Epoch: 6| Step: 10
Training loss: 1.5241527557373047
Validation loss: 2.0986780966481855

Epoch: 6| Step: 11
Training loss: 1.0933020114898682
Validation loss: 2.1323208129534157

Epoch: 6| Step: 12
Training loss: 1.6151604652404785
Validation loss: 2.208166786419448

Epoch: 6| Step: 13
Training loss: 1.203713059425354
Validation loss: 2.2049474126549176

Epoch: 646| Step: 0
Training loss: 1.9027092456817627
Validation loss: 2.1712919640284714

Epoch: 6| Step: 1
Training loss: 1.6890878677368164
Validation loss: 2.1334789312014015

Epoch: 6| Step: 2
Training loss: 1.1522831916809082
Validation loss: 2.139039949704242

Epoch: 6| Step: 3
Training loss: 0.8831357359886169
Validation loss: 2.153414313511182

Epoch: 6| Step: 4
Training loss: 1.1049787998199463
Validation loss: 2.2177076288448867

Epoch: 6| Step: 5
Training loss: 1.7962384223937988
Validation loss: 2.1915517045605566

Epoch: 6| Step: 6
Training loss: 1.1907453536987305
Validation loss: 2.1584177273575977

Epoch: 6| Step: 7
Training loss: 1.4534684419631958
Validation loss: 2.1817847554401686

Epoch: 6| Step: 8
Training loss: 0.9468386173248291
Validation loss: 2.1551133483968754

Epoch: 6| Step: 9
Training loss: 0.9689656496047974
Validation loss: 2.156702108280633

Epoch: 6| Step: 10
Training loss: 2.0443649291992188
Validation loss: 2.1235781420943556

Epoch: 6| Step: 11
Training loss: 1.7469714879989624
Validation loss: 2.1190946307233585

Epoch: 6| Step: 12
Training loss: 1.1205108165740967
Validation loss: 2.21877912552126

Epoch: 6| Step: 13
Training loss: 1.5796501636505127
Validation loss: 2.166656788959298

Epoch: 647| Step: 0
Training loss: 1.845886468887329
Validation loss: 2.1777263892594205

Epoch: 6| Step: 1
Training loss: 1.4149951934814453
Validation loss: 2.272127802653979

Epoch: 6| Step: 2
Training loss: 1.3943661451339722
Validation loss: 2.1904634045016382

Epoch: 6| Step: 3
Training loss: 1.1358709335327148
Validation loss: 2.1607016517269995

Epoch: 6| Step: 4
Training loss: 1.7392239570617676
Validation loss: 2.193349225546724

Epoch: 6| Step: 5
Training loss: 1.2592828273773193
Validation loss: 2.142213052318942

Epoch: 6| Step: 6
Training loss: 1.3187286853790283
Validation loss: 2.2349230397132134

Epoch: 6| Step: 7
Training loss: 1.6237796545028687
Validation loss: 2.1631926644232964

Epoch: 6| Step: 8
Training loss: 1.0467454195022583
Validation loss: 2.189546154391381

Epoch: 6| Step: 9
Training loss: 1.5626217126846313
Validation loss: 2.1959808821319253

Epoch: 6| Step: 10
Training loss: 1.2158246040344238
Validation loss: 2.0932107087104552

Epoch: 6| Step: 11
Training loss: 1.4569602012634277
Validation loss: 2.167132476324676

Epoch: 6| Step: 12
Training loss: 2.1077756881713867
Validation loss: 2.1018163683593913

Epoch: 6| Step: 13
Training loss: 0.3897036015987396
Validation loss: 2.1803498409127675

Epoch: 648| Step: 0
Training loss: 1.4532480239868164
Validation loss: 2.2120820860708914

Epoch: 6| Step: 1
Training loss: 1.5208187103271484
Validation loss: 2.178396035266179

Epoch: 6| Step: 2
Training loss: 1.1306498050689697
Validation loss: 2.1600869291572162

Epoch: 6| Step: 3
Training loss: 1.8888596296310425
Validation loss: 2.134319859166299

Epoch: 6| Step: 4
Training loss: 1.0197826623916626
Validation loss: 2.1934377967670398

Epoch: 6| Step: 5
Training loss: 1.4094693660736084
Validation loss: 2.15727602025514

Epoch: 6| Step: 6
Training loss: 2.4595701694488525
Validation loss: 2.162825322920276

Epoch: 6| Step: 7
Training loss: 1.2613310813903809
Validation loss: 2.1619761515689153

Epoch: 6| Step: 8
Training loss: 1.5599522590637207
Validation loss: 2.2137912857917046

Epoch: 6| Step: 9
Training loss: 1.2581825256347656
Validation loss: 2.2049412727355957

Epoch: 6| Step: 10
Training loss: 1.0113319158554077
Validation loss: 2.1830014541584957

Epoch: 6| Step: 11
Training loss: 1.1510770320892334
Validation loss: 2.220755451469011

Epoch: 6| Step: 12
Training loss: 1.1988000869750977
Validation loss: 2.189310530180572

Epoch: 6| Step: 13
Training loss: 1.6026232242584229
Validation loss: 2.174718367156162

Epoch: 649| Step: 0
Training loss: 1.6547987461090088
Validation loss: 2.21821923922467

Epoch: 6| Step: 1
Training loss: 0.752668023109436
Validation loss: 2.1507504063267864

Epoch: 6| Step: 2
Training loss: 1.649710774421692
Validation loss: 2.1782755236471854

Epoch: 6| Step: 3
Training loss: 1.6203649044036865
Validation loss: 2.203782122622254

Epoch: 6| Step: 4
Training loss: 1.3484939336776733
Validation loss: 2.1624683103253766

Epoch: 6| Step: 5
Training loss: 1.5969953536987305
Validation loss: 2.0951352375809864

Epoch: 6| Step: 6
Training loss: 1.4315379858016968
Validation loss: 2.2206333016836517

Epoch: 6| Step: 7
Training loss: 1.6313018798828125
Validation loss: 2.1285004372237832

Epoch: 6| Step: 8
Training loss: 0.9516967535018921
Validation loss: 2.15568390200215

Epoch: 6| Step: 9
Training loss: 1.2953927516937256
Validation loss: 2.253432645592638

Epoch: 6| Step: 10
Training loss: 0.997515857219696
Validation loss: 2.1197567344993673

Epoch: 6| Step: 11
Training loss: 0.785860538482666
Validation loss: 2.155939209845758

Epoch: 6| Step: 12
Training loss: 1.4713640213012695
Validation loss: 2.123602769708121

Epoch: 6| Step: 13
Training loss: 1.2288278341293335
Validation loss: 2.1400011893241637

Epoch: 650| Step: 0
Training loss: 1.441545009613037
Validation loss: 2.159539671354396

Epoch: 6| Step: 1
Training loss: 1.4568755626678467
Validation loss: 2.1894245506614767

Epoch: 6| Step: 2
Training loss: 1.2743394374847412
Validation loss: 2.0639724103353356

Epoch: 6| Step: 3
Training loss: 1.1522822380065918
Validation loss: 2.2040899466442805

Epoch: 6| Step: 4
Training loss: 1.25139582157135
Validation loss: 2.233547302984422

Epoch: 6| Step: 5
Training loss: 1.2452749013900757
Validation loss: 2.213832316860076

Epoch: 6| Step: 6
Training loss: 1.5251669883728027
Validation loss: 2.1250838618124686

Epoch: 6| Step: 7
Training loss: 1.0840548276901245
Validation loss: 2.2579403333766486

Epoch: 6| Step: 8
Training loss: 1.288484811782837
Validation loss: 2.1563367510354645

Epoch: 6| Step: 9
Training loss: 1.459127426147461
Validation loss: 2.1651723820676088

Epoch: 6| Step: 10
Training loss: 1.1122773885726929
Validation loss: 2.1559305652495353

Epoch: 6| Step: 11
Training loss: 1.105743169784546
Validation loss: 2.1481159117914017

Epoch: 6| Step: 12
Training loss: 1.9125880002975464
Validation loss: 2.151505844567412

Epoch: 6| Step: 13
Training loss: 2.481736183166504
Validation loss: 2.2266226609547934

Epoch: 651| Step: 0
Training loss: 1.559197187423706
Validation loss: 2.154922705824657

Epoch: 6| Step: 1
Training loss: 1.2508713006973267
Validation loss: 2.203163625091635

Epoch: 6| Step: 2
Training loss: 1.0913745164871216
Validation loss: 2.261685061198409

Epoch: 6| Step: 3
Training loss: 1.6719298362731934
Validation loss: 2.1679618781612766

Epoch: 6| Step: 4
Training loss: 1.4661805629730225
Validation loss: 2.1538907609960085

Epoch: 6| Step: 5
Training loss: 1.3683782815933228
Validation loss: 2.3010272441371793

Epoch: 6| Step: 6
Training loss: 1.3612756729125977
Validation loss: 2.1883165144151255

Epoch: 6| Step: 7
Training loss: 1.1584901809692383
Validation loss: 2.2748303541573147

Epoch: 6| Step: 8
Training loss: 1.106247901916504
Validation loss: 2.1517947617397515

Epoch: 6| Step: 9
Training loss: 1.5046840906143188
Validation loss: 2.2139909421243975

Epoch: 6| Step: 10
Training loss: 1.412968397140503
Validation loss: 2.2074134375459407

Epoch: 6| Step: 11
Training loss: 1.4972798824310303
Validation loss: 2.2868580202902518

Epoch: 6| Step: 12
Training loss: 1.6264514923095703
Validation loss: 2.207156676118092

Epoch: 6| Step: 13
Training loss: 1.905230164527893
Validation loss: 2.2542247080033824

Epoch: 652| Step: 0
Training loss: 1.1511106491088867
Validation loss: 2.162890047155401

Epoch: 6| Step: 1
Training loss: 1.7161115407943726
Validation loss: 2.1849076619712253

Epoch: 6| Step: 2
Training loss: 0.8977574110031128
Validation loss: 2.1725090037110033

Epoch: 6| Step: 3
Training loss: 1.7842916250228882
Validation loss: 2.2123392563994213

Epoch: 6| Step: 4
Training loss: 1.644554615020752
Validation loss: 2.19290429289623

Epoch: 6| Step: 5
Training loss: 0.8245210647583008
Validation loss: 2.1622170094520814

Epoch: 6| Step: 6
Training loss: 2.233808994293213
Validation loss: 2.1788791584712204

Epoch: 6| Step: 7
Training loss: 1.0976154804229736
Validation loss: 2.2274601074957077

Epoch: 6| Step: 8
Training loss: 1.0195881128311157
Validation loss: 2.188062101282099

Epoch: 6| Step: 9
Training loss: 1.2046747207641602
Validation loss: 2.1825967450295725

Epoch: 6| Step: 10
Training loss: 1.5471558570861816
Validation loss: 2.2295239048619426

Epoch: 6| Step: 11
Training loss: 1.9234007596969604
Validation loss: 2.148545718962146

Epoch: 6| Step: 12
Training loss: 1.3328466415405273
Validation loss: 2.1068710306639313

Epoch: 6| Step: 13
Training loss: 1.0450870990753174
Validation loss: 2.146582600890949

Epoch: 653| Step: 0
Training loss: 1.6685352325439453
Validation loss: 2.165197285272742

Epoch: 6| Step: 1
Training loss: 1.276681900024414
Validation loss: 2.163829029247325

Epoch: 6| Step: 2
Training loss: 1.0081870555877686
Validation loss: 2.1935511353195354

Epoch: 6| Step: 3
Training loss: 2.237497329711914
Validation loss: 2.149697849827428

Epoch: 6| Step: 4
Training loss: 0.8812427520751953
Validation loss: 2.2104328575954644

Epoch: 6| Step: 5
Training loss: 0.8807580471038818
Validation loss: 2.2639182767560406

Epoch: 6| Step: 6
Training loss: 1.3649672269821167
Validation loss: 2.1866780968122583

Epoch: 6| Step: 7
Training loss: 0.7074705362319946
Validation loss: 2.1720252959958968

Epoch: 6| Step: 8
Training loss: 1.9796178340911865
Validation loss: 2.199351087693245

Epoch: 6| Step: 9
Training loss: 1.2238041162490845
Validation loss: 2.0902910617090042

Epoch: 6| Step: 10
Training loss: 1.414135456085205
Validation loss: 2.254370420209823

Epoch: 6| Step: 11
Training loss: 1.4398012161254883
Validation loss: 2.1525837811090613

Epoch: 6| Step: 12
Training loss: 1.7196522951126099
Validation loss: 2.228233406620641

Epoch: 6| Step: 13
Training loss: 2.0578556060791016
Validation loss: 2.1573071300342517

Epoch: 654| Step: 0
Training loss: 1.9327471256256104
Validation loss: 2.096468751148511

Epoch: 6| Step: 1
Training loss: 1.5267229080200195
Validation loss: 2.179722269376119

Epoch: 6| Step: 2
Training loss: 1.3796721696853638
Validation loss: 2.187262660713606

Epoch: 6| Step: 3
Training loss: 1.8029897212982178
Validation loss: 2.208826570100682

Epoch: 6| Step: 4
Training loss: 1.2184107303619385
Validation loss: 2.1525704130049674

Epoch: 6| Step: 5
Training loss: 1.2963507175445557
Validation loss: 2.154434786047987

Epoch: 6| Step: 6
Training loss: 1.079022765159607
Validation loss: 2.181926299166936

Epoch: 6| Step: 7
Training loss: 1.3898448944091797
Validation loss: 2.2135604094433528

Epoch: 6| Step: 8
Training loss: 1.1126644611358643
Validation loss: 2.23845277806764

Epoch: 6| Step: 9
Training loss: 1.4413410425186157
Validation loss: 2.1976208456100954

Epoch: 6| Step: 10
Training loss: 1.3761320114135742
Validation loss: 2.1741127019287436

Epoch: 6| Step: 11
Training loss: 0.8806358575820923
Validation loss: 2.2034108433672177

Epoch: 6| Step: 12
Training loss: 1.486986756324768
Validation loss: 2.1798705644505

Epoch: 6| Step: 13
Training loss: 1.4539085626602173
Validation loss: 2.2109008040479434

Epoch: 655| Step: 0
Training loss: 1.5986857414245605
Validation loss: 2.114960209015877

Epoch: 6| Step: 1
Training loss: 1.4203139543533325
Validation loss: 2.2373209179088636

Epoch: 6| Step: 2
Training loss: 1.5196188688278198
Validation loss: 2.1999899777032996

Epoch: 6| Step: 3
Training loss: 2.4887733459472656
Validation loss: 2.1511394234113794

Epoch: 6| Step: 4
Training loss: 1.132434368133545
Validation loss: 2.2038835376821537

Epoch: 6| Step: 5
Training loss: 0.7726931571960449
Validation loss: 2.1915170915665163

Epoch: 6| Step: 6
Training loss: 1.0273041725158691
Validation loss: 2.162875553613068

Epoch: 6| Step: 7
Training loss: 1.470411777496338
Validation loss: 2.1477197677858415

Epoch: 6| Step: 8
Training loss: 1.1336091756820679
Validation loss: 2.156185757729315

Epoch: 6| Step: 9
Training loss: 1.6107215881347656
Validation loss: 2.1562164419440815

Epoch: 6| Step: 10
Training loss: 1.473591923713684
Validation loss: 2.1561591676486436

Epoch: 6| Step: 11
Training loss: 1.340320348739624
Validation loss: 2.211898954965735

Epoch: 6| Step: 12
Training loss: 1.4450905323028564
Validation loss: 2.1610840212914253

Epoch: 6| Step: 13
Training loss: 0.9485013484954834
Validation loss: 2.235535278115221

Epoch: 656| Step: 0
Training loss: 1.0400714874267578
Validation loss: 2.181234951942198

Epoch: 6| Step: 1
Training loss: 1.0774731636047363
Validation loss: 2.16652839414535

Epoch: 6| Step: 2
Training loss: 1.80906081199646
Validation loss: 2.1376269453315326

Epoch: 6| Step: 3
Training loss: 1.2217456102371216
Validation loss: 2.1409126622702486

Epoch: 6| Step: 4
Training loss: 1.0942504405975342
Validation loss: 2.17146280119496

Epoch: 6| Step: 5
Training loss: 2.221966505050659
Validation loss: 2.134982350052044

Epoch: 6| Step: 6
Training loss: 1.1669007539749146
Validation loss: 2.125222582970896

Epoch: 6| Step: 7
Training loss: 1.5587401390075684
Validation loss: 2.1363277512211956

Epoch: 6| Step: 8
Training loss: 1.2753126621246338
Validation loss: 2.152058780834239

Epoch: 6| Step: 9
Training loss: 1.6255903244018555
Validation loss: 2.176764649729575

Epoch: 6| Step: 10
Training loss: 1.6552326679229736
Validation loss: 2.180066317640325

Epoch: 6| Step: 11
Training loss: 0.9430243968963623
Validation loss: 2.165416050982732

Epoch: 6| Step: 12
Training loss: 1.458003044128418
Validation loss: 2.216354130416788

Epoch: 6| Step: 13
Training loss: 0.9795650839805603
Validation loss: 2.2173545437474407

Epoch: 657| Step: 0
Training loss: 1.3674243688583374
Validation loss: 2.2548268738613335

Epoch: 6| Step: 1
Training loss: 1.4434947967529297
Validation loss: 2.315022905667623

Epoch: 6| Step: 2
Training loss: 1.5847032070159912
Validation loss: 2.23693387867302

Epoch: 6| Step: 3
Training loss: 0.9017297029495239
Validation loss: 2.183784693799993

Epoch: 6| Step: 4
Training loss: 1.591098666191101
Validation loss: 2.276778810767717

Epoch: 6| Step: 5
Training loss: 1.158359169960022
Validation loss: 2.2172932394089235

Epoch: 6| Step: 6
Training loss: 1.0642592906951904
Validation loss: 2.223245604063875

Epoch: 6| Step: 7
Training loss: 1.0530695915222168
Validation loss: 2.229736187124765

Epoch: 6| Step: 8
Training loss: 1.5483320951461792
Validation loss: 2.266318940347241

Epoch: 6| Step: 9
Training loss: 0.8376525044441223
Validation loss: 2.1855371331655853

Epoch: 6| Step: 10
Training loss: 1.3644195795059204
Validation loss: 2.1841605799172514

Epoch: 6| Step: 11
Training loss: 1.6857590675354004
Validation loss: 2.1411853233973184

Epoch: 6| Step: 12
Training loss: 1.218049168586731
Validation loss: 2.208304184739308

Epoch: 6| Step: 13
Training loss: 2.433695077896118
Validation loss: 2.1898382222780617

Epoch: 658| Step: 0
Training loss: 1.538043737411499
Validation loss: 2.100142632761309

Epoch: 6| Step: 1
Training loss: 1.3216254711151123
Validation loss: 2.1842597607643373

Epoch: 6| Step: 2
Training loss: 1.2702174186706543
Validation loss: 2.147965424804277

Epoch: 6| Step: 3
Training loss: 1.480264663696289
Validation loss: 2.1642824052482523

Epoch: 6| Step: 4
Training loss: 2.1881513595581055
Validation loss: 2.1853471135580413

Epoch: 6| Step: 5
Training loss: 1.5244166851043701
Validation loss: 2.155647316286641

Epoch: 6| Step: 6
Training loss: 1.239747166633606
Validation loss: 2.169593467507311

Epoch: 6| Step: 7
Training loss: 1.6001392602920532
Validation loss: 2.159489021506361

Epoch: 6| Step: 8
Training loss: 1.151922583580017
Validation loss: 2.191682046459567

Epoch: 6| Step: 9
Training loss: 0.7450382709503174
Validation loss: 2.188093316170477

Epoch: 6| Step: 10
Training loss: 0.9007066488265991
Validation loss: 2.2405708733425347

Epoch: 6| Step: 11
Training loss: 1.4282993078231812
Validation loss: 2.1191915094211535

Epoch: 6| Step: 12
Training loss: 1.2665126323699951
Validation loss: 2.214282120427778

Epoch: 6| Step: 13
Training loss: 1.9080365896224976
Validation loss: 2.2170267771649104

Epoch: 659| Step: 0
Training loss: 1.7518553733825684
Validation loss: 2.2653258410833215

Epoch: 6| Step: 1
Training loss: 1.2522380352020264
Validation loss: 2.1975751871703775

Epoch: 6| Step: 2
Training loss: 1.6133430004119873
Validation loss: 2.1454241480878604

Epoch: 6| Step: 3
Training loss: 1.5022149085998535
Validation loss: 2.1774624060559016

Epoch: 6| Step: 4
Training loss: 1.6821610927581787
Validation loss: 2.2049358378174486

Epoch: 6| Step: 5
Training loss: 1.9353876113891602
Validation loss: 2.1644116575999925

Epoch: 6| Step: 6
Training loss: 0.9684463739395142
Validation loss: 2.2268143187287035

Epoch: 6| Step: 7
Training loss: 1.6476473808288574
Validation loss: 2.209175043208625

Epoch: 6| Step: 8
Training loss: 0.8058518171310425
Validation loss: 2.23207260716346

Epoch: 6| Step: 9
Training loss: 1.6048864126205444
Validation loss: 2.1764550106499785

Epoch: 6| Step: 10
Training loss: 1.4284467697143555
Validation loss: 2.1193073282959642

Epoch: 6| Step: 11
Training loss: 1.3426203727722168
Validation loss: 2.162691452169931

Epoch: 6| Step: 12
Training loss: 1.0237232446670532
Validation loss: 2.2185036020894207

Epoch: 6| Step: 13
Training loss: 0.8434531688690186
Validation loss: 2.128546617364371

Epoch: 660| Step: 0
Training loss: 1.5291171073913574
Validation loss: 2.149361164339127

Epoch: 6| Step: 1
Training loss: 1.380753517150879
Validation loss: 2.144551310487973

Epoch: 6| Step: 2
Training loss: 0.9249361157417297
Validation loss: 2.201869877435828

Epoch: 6| Step: 3
Training loss: 1.605278491973877
Validation loss: 2.1465731666934107

Epoch: 6| Step: 4
Training loss: 1.6635262966156006
Validation loss: 2.2204967647470455

Epoch: 6| Step: 5
Training loss: 1.4974339008331299
Validation loss: 2.1826505558465117

Epoch: 6| Step: 6
Training loss: 1.2624655961990356
Validation loss: 2.218428232336557

Epoch: 6| Step: 7
Training loss: 1.482429027557373
Validation loss: 2.186454480694186

Epoch: 6| Step: 8
Training loss: 1.5605013370513916
Validation loss: 2.1194735496274886

Epoch: 6| Step: 9
Training loss: 1.036272644996643
Validation loss: 2.2482050605999526

Epoch: 6| Step: 10
Training loss: 1.6304917335510254
Validation loss: 2.161970985833035

Epoch: 6| Step: 11
Training loss: 1.0110418796539307
Validation loss: 2.1899431725983978

Epoch: 6| Step: 12
Training loss: 1.102225661277771
Validation loss: 2.184836446598012

Epoch: 6| Step: 13
Training loss: 0.8878663778305054
Validation loss: 2.197210620808345

Epoch: 661| Step: 0
Training loss: 1.1650432348251343
Validation loss: 2.17107262790844

Epoch: 6| Step: 1
Training loss: 1.9307940006256104
Validation loss: 2.171012088816653

Epoch: 6| Step: 2
Training loss: 2.1161439418792725
Validation loss: 2.2456817268043436

Epoch: 6| Step: 3
Training loss: 1.546595573425293
Validation loss: 2.2171419974296325

Epoch: 6| Step: 4
Training loss: 1.1202455759048462
Validation loss: 2.213593434262019

Epoch: 6| Step: 5
Training loss: 0.7852113246917725
Validation loss: 2.123949537995041

Epoch: 6| Step: 6
Training loss: 1.3194687366485596
Validation loss: 2.2225230560507825

Epoch: 6| Step: 7
Training loss: 1.5039433240890503
Validation loss: 2.1993201535235167

Epoch: 6| Step: 8
Training loss: 1.8515195846557617
Validation loss: 2.158978849328974

Epoch: 6| Step: 9
Training loss: 0.4067811965942383
Validation loss: 2.1519612881445114

Epoch: 6| Step: 10
Training loss: 1.488850712776184
Validation loss: 2.215848881711242

Epoch: 6| Step: 11
Training loss: 1.8776724338531494
Validation loss: 2.1168608844921155

Epoch: 6| Step: 12
Training loss: 0.7853484153747559
Validation loss: 2.1936666504029305

Epoch: 6| Step: 13
Training loss: 1.3815535306930542
Validation loss: 2.1746870420312368

Epoch: 662| Step: 0
Training loss: 0.8847249746322632
Validation loss: 2.18847248887503

Epoch: 6| Step: 1
Training loss: 1.649151086807251
Validation loss: 2.1954754783261206

Epoch: 6| Step: 2
Training loss: 1.6892781257629395
Validation loss: 2.153557769713863

Epoch: 6| Step: 3
Training loss: 1.7678139209747314
Validation loss: 2.10436015231635

Epoch: 6| Step: 4
Training loss: 1.3066365718841553
Validation loss: 2.1500069659243346

Epoch: 6| Step: 5
Training loss: 0.9836405515670776
Validation loss: 2.1503437988219725

Epoch: 6| Step: 6
Training loss: 1.8311259746551514
Validation loss: 2.1895085855196883

Epoch: 6| Step: 7
Training loss: 1.368814468383789
Validation loss: 2.1747432677976546

Epoch: 6| Step: 8
Training loss: 0.9197929501533508
Validation loss: 2.1537946090903333

Epoch: 6| Step: 9
Training loss: 0.8493484258651733
Validation loss: 2.260203138474495

Epoch: 6| Step: 10
Training loss: 1.836150050163269
Validation loss: 2.1425983931428645

Epoch: 6| Step: 11
Training loss: 1.2452757358551025
Validation loss: 2.241833525319253

Epoch: 6| Step: 12
Training loss: 1.5589680671691895
Validation loss: 2.2159365236118274

Epoch: 6| Step: 13
Training loss: 1.4275896549224854
Validation loss: 2.1319453908551123

Epoch: 663| Step: 0
Training loss: 1.3029075860977173
Validation loss: 2.251170050713324

Epoch: 6| Step: 1
Training loss: 0.7851302027702332
Validation loss: 2.201450294063937

Epoch: 6| Step: 2
Training loss: 2.082944869995117
Validation loss: 2.153251119839248

Epoch: 6| Step: 3
Training loss: 0.8735679388046265
Validation loss: 2.139314320779616

Epoch: 6| Step: 4
Training loss: 1.3406381607055664
Validation loss: 2.1750186797111266

Epoch: 6| Step: 5
Training loss: 0.9134302735328674
Validation loss: 2.1825328206503265

Epoch: 6| Step: 6
Training loss: 1.3509926795959473
Validation loss: 2.1548686668437016

Epoch: 6| Step: 7
Training loss: 1.6401562690734863
Validation loss: 2.2107981661314606

Epoch: 6| Step: 8
Training loss: 1.6260124444961548
Validation loss: 2.1880089262480378

Epoch: 6| Step: 9
Training loss: 1.2249243259429932
Validation loss: 2.253366462645992

Epoch: 6| Step: 10
Training loss: 1.7471133470535278
Validation loss: 2.158777702239252

Epoch: 6| Step: 11
Training loss: 1.6951849460601807
Validation loss: 2.187627697503695

Epoch: 6| Step: 12
Training loss: 1.073418140411377
Validation loss: 2.182613529184813

Epoch: 6| Step: 13
Training loss: 1.298298954963684
Validation loss: 2.2103873709196686

Epoch: 664| Step: 0
Training loss: 1.5471184253692627
Validation loss: 2.1661126741798977

Epoch: 6| Step: 1
Training loss: 2.16526198387146
Validation loss: 2.1824119065397527

Epoch: 6| Step: 2
Training loss: 1.1899174451828003
Validation loss: 2.204756393227526

Epoch: 6| Step: 3
Training loss: 2.031402826309204
Validation loss: 2.252282072139043

Epoch: 6| Step: 4
Training loss: 1.1166670322418213
Validation loss: 2.181981914786882

Epoch: 6| Step: 5
Training loss: 1.5826897621154785
Validation loss: 2.2847541545027044

Epoch: 6| Step: 6
Training loss: 1.0391252040863037
Validation loss: 2.3223995470231578

Epoch: 6| Step: 7
Training loss: 1.538327693939209
Validation loss: 2.17797710305901

Epoch: 6| Step: 8
Training loss: 1.4922362565994263
Validation loss: 2.2281995934824788

Epoch: 6| Step: 9
Training loss: 1.2975895404815674
Validation loss: 2.1992580480473016

Epoch: 6| Step: 10
Training loss: 0.9029223918914795
Validation loss: 2.233554196614091

Epoch: 6| Step: 11
Training loss: 1.022587537765503
Validation loss: 2.170511434155126

Epoch: 6| Step: 12
Training loss: 0.8666126132011414
Validation loss: 2.174566673976119

Epoch: 6| Step: 13
Training loss: 0.9573691487312317
Validation loss: 2.2464573767877396

Epoch: 665| Step: 0
Training loss: 1.0326498746871948
Validation loss: 2.145290287592078

Epoch: 6| Step: 1
Training loss: 1.8971433639526367
Validation loss: 2.1948121696390133

Epoch: 6| Step: 2
Training loss: 1.606924057006836
Validation loss: 2.116719966934573

Epoch: 6| Step: 3
Training loss: 1.9193356037139893
Validation loss: 2.226226314421623

Epoch: 6| Step: 4
Training loss: 1.0630792379379272
Validation loss: 2.185738948083693

Epoch: 6| Step: 5
Training loss: 0.9870643615722656
Validation loss: 2.1563535903089788

Epoch: 6| Step: 6
Training loss: 1.0342509746551514
Validation loss: 2.199966924164885

Epoch: 6| Step: 7
Training loss: 1.4055956602096558
Validation loss: 2.1052770230077926

Epoch: 6| Step: 8
Training loss: 0.9485998153686523
Validation loss: 2.1797401546150126

Epoch: 6| Step: 9
Training loss: 1.681666612625122
Validation loss: 2.1818842349513883

Epoch: 6| Step: 10
Training loss: 1.2140864133834839
Validation loss: 2.1330693562825522

Epoch: 6| Step: 11
Training loss: 1.6541476249694824
Validation loss: 2.2095976375764415

Epoch: 6| Step: 12
Training loss: 1.410304069519043
Validation loss: 2.096832906046221

Epoch: 6| Step: 13
Training loss: 1.110026478767395
Validation loss: 2.2602190663737636

Epoch: 666| Step: 0
Training loss: 2.1235547065734863
Validation loss: 2.11082092408211

Epoch: 6| Step: 1
Training loss: 1.1811280250549316
Validation loss: 2.2024519571693997

Epoch: 6| Step: 2
Training loss: 1.7155512571334839
Validation loss: 2.1245362874000304

Epoch: 6| Step: 3
Training loss: 1.0317261219024658
Validation loss: 2.204575761671989

Epoch: 6| Step: 4
Training loss: 0.9852157831192017
Validation loss: 2.1830921993460706

Epoch: 6| Step: 5
Training loss: 0.982094407081604
Validation loss: 2.1657833014765093

Epoch: 6| Step: 6
Training loss: 1.3360772132873535
Validation loss: 2.1490325645733903

Epoch: 6| Step: 7
Training loss: 1.3812682628631592
Validation loss: 2.1751863982087825

Epoch: 6| Step: 8
Training loss: 1.3266860246658325
Validation loss: 2.1879793405532837

Epoch: 6| Step: 9
Training loss: 1.2388992309570312
Validation loss: 2.249741674751364

Epoch: 6| Step: 10
Training loss: 1.6482144594192505
Validation loss: 2.1850956473299252

Epoch: 6| Step: 11
Training loss: 1.3109252452850342
Validation loss: 2.211834360194463

Epoch: 6| Step: 12
Training loss: 0.9486362934112549
Validation loss: 2.1409005708591913

Epoch: 6| Step: 13
Training loss: 0.641587495803833
Validation loss: 2.149479837827785

Epoch: 667| Step: 0
Training loss: 1.3479875326156616
Validation loss: 2.1472570870512273

Epoch: 6| Step: 1
Training loss: 1.05631422996521
Validation loss: 2.272315384239279

Epoch: 6| Step: 2
Training loss: 1.349043846130371
Validation loss: 2.113364960557671

Epoch: 6| Step: 3
Training loss: 0.9378261566162109
Validation loss: 2.122462175225699

Epoch: 6| Step: 4
Training loss: 1.4692530632019043
Validation loss: 2.222647872022403

Epoch: 6| Step: 5
Training loss: 1.847083568572998
Validation loss: 2.155150571177083

Epoch: 6| Step: 6
Training loss: 1.288173794746399
Validation loss: 2.200794868571784

Epoch: 6| Step: 7
Training loss: 1.9827548265457153
Validation loss: 2.115880743149788

Epoch: 6| Step: 8
Training loss: 1.3889063596725464
Validation loss: 2.1153646848535024

Epoch: 6| Step: 9
Training loss: 1.141505479812622
Validation loss: 2.2024336348297777

Epoch: 6| Step: 10
Training loss: 0.902275800704956
Validation loss: 2.1456416883776264

Epoch: 6| Step: 11
Training loss: 1.5364909172058105
Validation loss: 2.243421441765242

Epoch: 6| Step: 12
Training loss: 1.6095272302627563
Validation loss: 2.0966074876887824

Epoch: 6| Step: 13
Training loss: 1.2261837720870972
Validation loss: 2.250772806905931

Epoch: 668| Step: 0
Training loss: 1.3457589149475098
Validation loss: 2.0940096647508684

Epoch: 6| Step: 1
Training loss: 0.6785047054290771
Validation loss: 2.1132790170690066

Epoch: 6| Step: 2
Training loss: 0.9067507982254028
Validation loss: 2.1933749760350874

Epoch: 6| Step: 3
Training loss: 1.468355655670166
Validation loss: 2.181283417568412

Epoch: 6| Step: 4
Training loss: 2.2078163623809814
Validation loss: 2.1566915614630586

Epoch: 6| Step: 5
Training loss: 1.3472483158111572
Validation loss: 2.224575601598268

Epoch: 6| Step: 6
Training loss: 1.1631619930267334
Validation loss: 2.1838507652282715

Epoch: 6| Step: 7
Training loss: 1.933549165725708
Validation loss: 2.167780767204941

Epoch: 6| Step: 8
Training loss: 1.3862055540084839
Validation loss: 2.196622138382286

Epoch: 6| Step: 9
Training loss: 1.4404032230377197
Validation loss: 2.148670211915047

Epoch: 6| Step: 10
Training loss: 1.1870355606079102
Validation loss: 2.1739488545284478

Epoch: 6| Step: 11
Training loss: 1.5960296392440796
Validation loss: 2.1802442740368586

Epoch: 6| Step: 12
Training loss: 1.6134893894195557
Validation loss: 2.2050173897897043

Epoch: 6| Step: 13
Training loss: 0.886605978012085
Validation loss: 2.21751755796453

Epoch: 669| Step: 0
Training loss: 1.0304542779922485
Validation loss: 2.115320928635136

Epoch: 6| Step: 1
Training loss: 0.9523755311965942
Validation loss: 2.1208205146174275

Epoch: 6| Step: 2
Training loss: 1.6730623245239258
Validation loss: 2.0798612486931587

Epoch: 6| Step: 3
Training loss: 1.5697712898254395
Validation loss: 2.1629837200205815

Epoch: 6| Step: 4
Training loss: 1.1278940439224243
Validation loss: 2.192487896129649

Epoch: 6| Step: 5
Training loss: 1.5196187496185303
Validation loss: 2.1204949258476176

Epoch: 6| Step: 6
Training loss: 1.4259397983551025
Validation loss: 2.128912356591994

Epoch: 6| Step: 7
Training loss: 1.391616940498352
Validation loss: 2.2037263198565413

Epoch: 6| Step: 8
Training loss: 0.8781511187553406
Validation loss: 2.203941886143018

Epoch: 6| Step: 9
Training loss: 1.2376246452331543
Validation loss: 2.127319333373859

Epoch: 6| Step: 10
Training loss: 2.050752878189087
Validation loss: 2.1863073764308805

Epoch: 6| Step: 11
Training loss: 1.6077673435211182
Validation loss: 2.217901481095181

Epoch: 6| Step: 12
Training loss: 1.4196414947509766
Validation loss: 2.1905845929217596

Epoch: 6| Step: 13
Training loss: 1.020237684249878
Validation loss: 2.1938772637356996

Epoch: 670| Step: 0
Training loss: 1.1227377653121948
Validation loss: 2.191568466924852

Epoch: 6| Step: 1
Training loss: 1.7205220460891724
Validation loss: 2.1924938771032516

Epoch: 6| Step: 2
Training loss: 1.9260292053222656
Validation loss: 2.2551828994545886

Epoch: 6| Step: 3
Training loss: 1.0408439636230469
Validation loss: 2.2410684452261975

Epoch: 6| Step: 4
Training loss: 1.7220853567123413
Validation loss: 2.1140658829801824

Epoch: 6| Step: 5
Training loss: 1.4690310955047607
Validation loss: 2.1400431099758355

Epoch: 6| Step: 6
Training loss: 1.2973600625991821
Validation loss: 2.149584936839278

Epoch: 6| Step: 7
Training loss: 1.2127621173858643
Validation loss: 2.1494552038049184

Epoch: 6| Step: 8
Training loss: 1.125175952911377
Validation loss: 2.09938641261029

Epoch: 6| Step: 9
Training loss: 1.361325979232788
Validation loss: 2.1678906973972114

Epoch: 6| Step: 10
Training loss: 1.180600881576538
Validation loss: 2.144425852324373

Epoch: 6| Step: 11
Training loss: 0.9286259412765503
Validation loss: 2.148294343743273

Epoch: 6| Step: 12
Training loss: 1.276444673538208
Validation loss: 2.1079439399062947

Epoch: 6| Step: 13
Training loss: 1.8148972988128662
Validation loss: 2.1986834515807447

Epoch: 671| Step: 0
Training loss: 1.1227402687072754
Validation loss: 2.2490224069164646

Epoch: 6| Step: 1
Training loss: 1.1194398403167725
Validation loss: 2.317837998431216

Epoch: 6| Step: 2
Training loss: 1.6226122379302979
Validation loss: 2.1412995028239425

Epoch: 6| Step: 3
Training loss: 1.1098871231079102
Validation loss: 2.1686018923277497

Epoch: 6| Step: 4
Training loss: 1.9116103649139404
Validation loss: 2.263523027461062

Epoch: 6| Step: 5
Training loss: 0.9043214321136475
Validation loss: 2.268922964731852

Epoch: 6| Step: 6
Training loss: 1.4962162971496582
Validation loss: 2.1779145874002928

Epoch: 6| Step: 7
Training loss: 1.5017309188842773
Validation loss: 2.167171511598813

Epoch: 6| Step: 8
Training loss: 1.0879216194152832
Validation loss: 2.161071308197514

Epoch: 6| Step: 9
Training loss: 1.549365520477295
Validation loss: 2.2295608520507812

Epoch: 6| Step: 10
Training loss: 1.939361810684204
Validation loss: 2.240498294112503

Epoch: 6| Step: 11
Training loss: 1.4467912912368774
Validation loss: 2.1439149020820536

Epoch: 6| Step: 12
Training loss: 1.3548129796981812
Validation loss: 2.146386677219022

Epoch: 6| Step: 13
Training loss: 0.9520251750946045
Validation loss: 2.1786753874953075

Epoch: 672| Step: 0
Training loss: 1.1204887628555298
Validation loss: 2.1552331037418817

Epoch: 6| Step: 1
Training loss: 1.1997833251953125
Validation loss: 2.2315427616078365

Epoch: 6| Step: 2
Training loss: 1.1285591125488281
Validation loss: 2.1096762329019527

Epoch: 6| Step: 3
Training loss: 1.8218514919281006
Validation loss: 2.255045219134259

Epoch: 6| Step: 4
Training loss: 1.2982949018478394
Validation loss: 2.1119149449051067

Epoch: 6| Step: 5
Training loss: 0.9905287027359009
Validation loss: 2.12644180943889

Epoch: 6| Step: 6
Training loss: 1.8551325798034668
Validation loss: 2.0939020777261383

Epoch: 6| Step: 7
Training loss: 1.5815091133117676
Validation loss: 2.129887821853802

Epoch: 6| Step: 8
Training loss: 1.5150063037872314
Validation loss: 2.1807907858202533

Epoch: 6| Step: 9
Training loss: 1.2733733654022217
Validation loss: 2.2598719917317873

Epoch: 6| Step: 10
Training loss: 1.282558798789978
Validation loss: 2.1898276780241277

Epoch: 6| Step: 11
Training loss: 1.0712106227874756
Validation loss: 2.255132657225414

Epoch: 6| Step: 12
Training loss: 1.5524141788482666
Validation loss: 2.1929123581096692

Epoch: 6| Step: 13
Training loss: 1.0691871643066406
Validation loss: 2.245785906750669

Epoch: 673| Step: 0
Training loss: 1.463770866394043
Validation loss: 2.214735428492228

Epoch: 6| Step: 1
Training loss: 1.5349200963974
Validation loss: 2.17670795225328

Epoch: 6| Step: 2
Training loss: 1.2153129577636719
Validation loss: 2.2400419455702587

Epoch: 6| Step: 3
Training loss: 1.227187156677246
Validation loss: 2.186873253955636

Epoch: 6| Step: 4
Training loss: 1.8800100088119507
Validation loss: 2.1757828215117097

Epoch: 6| Step: 5
Training loss: 0.8941158652305603
Validation loss: 2.197315390392016

Epoch: 6| Step: 6
Training loss: 1.326646327972412
Validation loss: 2.2065705586505193

Epoch: 6| Step: 7
Training loss: 2.0915024280548096
Validation loss: 2.198341026101061

Epoch: 6| Step: 8
Training loss: 0.7107314467430115
Validation loss: 2.2516844426431963

Epoch: 6| Step: 9
Training loss: 1.052751064300537
Validation loss: 2.1506918655928744

Epoch: 6| Step: 10
Training loss: 1.2549176216125488
Validation loss: 2.2007902309458744

Epoch: 6| Step: 11
Training loss: 1.5157723426818848
Validation loss: 2.1435585380882345

Epoch: 6| Step: 12
Training loss: 1.4827109575271606
Validation loss: 2.1473953441907

Epoch: 6| Step: 13
Training loss: 1.0247955322265625
Validation loss: 2.1751759898278022

Epoch: 674| Step: 0
Training loss: 1.4049086570739746
Validation loss: 2.1647547932081324

Epoch: 6| Step: 1
Training loss: 1.7397346496582031
Validation loss: 2.1890399071478073

Epoch: 6| Step: 2
Training loss: 1.2237193584442139
Validation loss: 2.1943399329339304

Epoch: 6| Step: 3
Training loss: 1.213645100593567
Validation loss: 2.091559810023154

Epoch: 6| Step: 4
Training loss: 1.093867301940918
Validation loss: 2.26460515299151

Epoch: 6| Step: 5
Training loss: 1.213742733001709
Validation loss: 2.1395613967731433

Epoch: 6| Step: 6
Training loss: 0.6362621784210205
Validation loss: 2.219654808762253

Epoch: 6| Step: 7
Training loss: 1.8059802055358887
Validation loss: 2.106287366600447

Epoch: 6| Step: 8
Training loss: 1.2702991962432861
Validation loss: 2.2172436265535254

Epoch: 6| Step: 9
Training loss: 1.9253599643707275
Validation loss: 2.2057613583021265

Epoch: 6| Step: 10
Training loss: 1.5431711673736572
Validation loss: 2.2150166265426146

Epoch: 6| Step: 11
Training loss: 1.4385623931884766
Validation loss: 2.193863748222269

Epoch: 6| Step: 12
Training loss: 0.9339320659637451
Validation loss: 2.22125147235009

Epoch: 6| Step: 13
Training loss: 0.9392869472503662
Validation loss: 2.1613976904141006

Epoch: 675| Step: 0
Training loss: 1.2442865371704102
Validation loss: 2.2032908752400386

Epoch: 6| Step: 1
Training loss: 1.6642519235610962
Validation loss: 2.1881110963001045

Epoch: 6| Step: 2
Training loss: 1.0910683870315552
Validation loss: 2.1728558232707362

Epoch: 6| Step: 3
Training loss: 1.0755904912948608
Validation loss: 2.170187429715228

Epoch: 6| Step: 4
Training loss: 1.2928390502929688
Validation loss: 2.2079285895952614

Epoch: 6| Step: 5
Training loss: 1.646627426147461
Validation loss: 2.111665828253633

Epoch: 6| Step: 6
Training loss: 1.295186996459961
Validation loss: 2.1462723234648347

Epoch: 6| Step: 7
Training loss: 1.4957088232040405
Validation loss: 2.1168140262685795

Epoch: 6| Step: 8
Training loss: 1.6588363647460938
Validation loss: 2.149775246138214

Epoch: 6| Step: 9
Training loss: 1.4319968223571777
Validation loss: 2.234014723890571

Epoch: 6| Step: 10
Training loss: 1.1114294528961182
Validation loss: 2.2723134820179274

Epoch: 6| Step: 11
Training loss: 0.8586376905441284
Validation loss: 2.1796748791971514

Epoch: 6| Step: 12
Training loss: 1.4720218181610107
Validation loss: 2.2136544053272535

Epoch: 6| Step: 13
Training loss: 1.7944378852844238
Validation loss: 2.1812332471211753

Epoch: 676| Step: 0
Training loss: 1.410940408706665
Validation loss: 2.1695680579831524

Epoch: 6| Step: 1
Training loss: 1.2504621744155884
Validation loss: 2.2143977021658294

Epoch: 6| Step: 2
Training loss: 1.0559903383255005
Validation loss: 2.179971871837493

Epoch: 6| Step: 3
Training loss: 1.8703809976577759
Validation loss: 2.1679603169041295

Epoch: 6| Step: 4
Training loss: 1.8546133041381836
Validation loss: 2.0945570263811337

Epoch: 6| Step: 5
Training loss: 1.417935848236084
Validation loss: 2.171956992918445

Epoch: 6| Step: 6
Training loss: 0.9152179956436157
Validation loss: 2.243494790087464

Epoch: 6| Step: 7
Training loss: 1.2819771766662598
Validation loss: 2.178888302977367

Epoch: 6| Step: 8
Training loss: 1.2335230112075806
Validation loss: 2.170769517139722

Epoch: 6| Step: 9
Training loss: 1.3009107112884521
Validation loss: 2.146637280782064

Epoch: 6| Step: 10
Training loss: 1.4616738557815552
Validation loss: 2.1317031832151514

Epoch: 6| Step: 11
Training loss: 1.7549338340759277
Validation loss: 2.2262219152142926

Epoch: 6| Step: 12
Training loss: 1.1645259857177734
Validation loss: 2.2060019918667373

Epoch: 6| Step: 13
Training loss: 0.5131732225418091
Validation loss: 2.196354371245189

Epoch: 677| Step: 0
Training loss: 1.5350637435913086
Validation loss: 2.162427886839836

Epoch: 6| Step: 1
Training loss: 1.3845908641815186
Validation loss: 2.1521178035325903

Epoch: 6| Step: 2
Training loss: 1.4438586235046387
Validation loss: 2.1620579227324455

Epoch: 6| Step: 3
Training loss: 1.4290199279785156
Validation loss: 2.226138000847191

Epoch: 6| Step: 4
Training loss: 0.6804934740066528
Validation loss: 2.1661364750195573

Epoch: 6| Step: 5
Training loss: 1.3174505233764648
Validation loss: 2.1432763479089223

Epoch: 6| Step: 6
Training loss: 1.3451566696166992
Validation loss: 2.145507551008655

Epoch: 6| Step: 7
Training loss: 1.2177577018737793
Validation loss: 2.2168401543812086

Epoch: 6| Step: 8
Training loss: 1.9360253810882568
Validation loss: 2.1836070681131012

Epoch: 6| Step: 9
Training loss: 2.321882724761963
Validation loss: 2.138651431247752

Epoch: 6| Step: 10
Training loss: 1.2474374771118164
Validation loss: 2.133516779509924

Epoch: 6| Step: 11
Training loss: 1.2689263820648193
Validation loss: 2.15057711960167

Epoch: 6| Step: 12
Training loss: 1.0009796619415283
Validation loss: 2.1618642576279177

Epoch: 6| Step: 13
Training loss: 1.5696923732757568
Validation loss: 2.17004721395431

Epoch: 678| Step: 0
Training loss: 1.0765939950942993
Validation loss: 2.138549235559279

Epoch: 6| Step: 1
Training loss: 1.2670059204101562
Validation loss: 2.0860998169068368

Epoch: 6| Step: 2
Training loss: 0.726925253868103
Validation loss: 2.1887774313649824

Epoch: 6| Step: 3
Training loss: 1.5957863330841064
Validation loss: 2.10254321816147

Epoch: 6| Step: 4
Training loss: 1.4260432720184326
Validation loss: 2.144460234590756

Epoch: 6| Step: 5
Training loss: 1.3562579154968262
Validation loss: 2.15806225551072

Epoch: 6| Step: 6
Training loss: 0.7971270084381104
Validation loss: 2.17744339922423

Epoch: 6| Step: 7
Training loss: 1.7875192165374756
Validation loss: 2.219421793055791

Epoch: 6| Step: 8
Training loss: 1.4789351224899292
Validation loss: 2.154016448605445

Epoch: 6| Step: 9
Training loss: 1.6741414070129395
Validation loss: 2.1423807400529102

Epoch: 6| Step: 10
Training loss: 1.13950777053833
Validation loss: 2.214755335161763

Epoch: 6| Step: 11
Training loss: 1.702706217765808
Validation loss: 2.1881808568072576

Epoch: 6| Step: 12
Training loss: 1.6486167907714844
Validation loss: 2.1988766321571926

Epoch: 6| Step: 13
Training loss: 1.278997540473938
Validation loss: 2.2373700859726116

Epoch: 679| Step: 0
Training loss: 1.4364314079284668
Validation loss: 2.195117082647098

Epoch: 6| Step: 1
Training loss: 0.9842942953109741
Validation loss: 2.2424336915375083

Epoch: 6| Step: 2
Training loss: 0.980789065361023
Validation loss: 2.182782378247989

Epoch: 6| Step: 3
Training loss: 0.8419257402420044
Validation loss: 2.252025681157266

Epoch: 6| Step: 4
Training loss: 1.830802321434021
Validation loss: 2.1465192020580335

Epoch: 6| Step: 5
Training loss: 1.256901741027832
Validation loss: 2.1659261077962895

Epoch: 6| Step: 6
Training loss: 0.7859326004981995
Validation loss: 2.1454012342678603

Epoch: 6| Step: 7
Training loss: 1.0779141187667847
Validation loss: 2.196550210316976

Epoch: 6| Step: 8
Training loss: 1.4391014575958252
Validation loss: 2.1701638339668192

Epoch: 6| Step: 9
Training loss: 1.3687288761138916
Validation loss: 2.2113710693133775

Epoch: 6| Step: 10
Training loss: 1.2191131114959717
Validation loss: 2.135543805296703

Epoch: 6| Step: 11
Training loss: 2.4690346717834473
Validation loss: 2.2569172613082396

Epoch: 6| Step: 12
Training loss: 1.7158010005950928
Validation loss: 2.1241094502069617

Epoch: 6| Step: 13
Training loss: 1.1598916053771973
Validation loss: 2.189361726084063

Epoch: 680| Step: 0
Training loss: 1.637034296989441
Validation loss: 2.1812046984190583

Epoch: 6| Step: 1
Training loss: 1.4792871475219727
Validation loss: 2.1591273071945354

Epoch: 6| Step: 2
Training loss: 0.7236849069595337
Validation loss: 2.1749116118236254

Epoch: 6| Step: 3
Training loss: 1.2594473361968994
Validation loss: 2.226305261734993

Epoch: 6| Step: 4
Training loss: 1.475825548171997
Validation loss: 2.1759198493854974

Epoch: 6| Step: 5
Training loss: 1.4021403789520264
Validation loss: 2.163713617991376

Epoch: 6| Step: 6
Training loss: 1.6253156661987305
Validation loss: 2.237782298877675

Epoch: 6| Step: 7
Training loss: 1.1816800832748413
Validation loss: 2.1678821938012236

Epoch: 6| Step: 8
Training loss: 0.9622560143470764
Validation loss: 2.205565414121074

Epoch: 6| Step: 9
Training loss: 1.7431766986846924
Validation loss: 2.243358791515391

Epoch: 6| Step: 10
Training loss: 1.4427320957183838
Validation loss: 2.1978998889205275

Epoch: 6| Step: 11
Training loss: 1.1486339569091797
Validation loss: 2.2037408813353507

Epoch: 6| Step: 12
Training loss: 1.5022343397140503
Validation loss: 2.192294123352215

Epoch: 6| Step: 13
Training loss: 1.096406102180481
Validation loss: 2.2514374576589113

Epoch: 681| Step: 0
Training loss: 1.5483832359313965
Validation loss: 2.1999502335825274

Epoch: 6| Step: 1
Training loss: 1.7314118146896362
Validation loss: 2.168717407411145

Epoch: 6| Step: 2
Training loss: 0.9398530721664429
Validation loss: 2.180014355208284

Epoch: 6| Step: 3
Training loss: 1.0436575412750244
Validation loss: 2.238039885797808

Epoch: 6| Step: 4
Training loss: 1.2030103206634521
Validation loss: 2.1534647005860523

Epoch: 6| Step: 5
Training loss: 1.7531756162643433
Validation loss: 2.127995939664943

Epoch: 6| Step: 6
Training loss: 1.4598021507263184
Validation loss: 2.2532214477498043

Epoch: 6| Step: 7
Training loss: 1.478737473487854
Validation loss: 2.200996703999017

Epoch: 6| Step: 8
Training loss: 1.4442112445831299
Validation loss: 2.248150675527511

Epoch: 6| Step: 9
Training loss: 1.789429783821106
Validation loss: 2.213949618800994

Epoch: 6| Step: 10
Training loss: 0.6281536817550659
Validation loss: 2.2299524584124164

Epoch: 6| Step: 11
Training loss: 1.0874767303466797
Validation loss: 2.168703216378407

Epoch: 6| Step: 12
Training loss: 1.1369373798370361
Validation loss: 2.1699912778792845

Epoch: 6| Step: 13
Training loss: 0.7450947165489197
Validation loss: 2.2478825456352642

Epoch: 682| Step: 0
Training loss: 1.2730400562286377
Validation loss: 2.1957010787020446

Epoch: 6| Step: 1
Training loss: 1.1703546047210693
Validation loss: 2.2332711450515257

Epoch: 6| Step: 2
Training loss: 1.451011300086975
Validation loss: 2.1141723176484466

Epoch: 6| Step: 3
Training loss: 1.2536036968231201
Validation loss: 2.1629064480463662

Epoch: 6| Step: 4
Training loss: 1.5256474018096924
Validation loss: 2.1786934509072253

Epoch: 6| Step: 5
Training loss: 1.7439744472503662
Validation loss: 2.1616380112145537

Epoch: 6| Step: 6
Training loss: 1.3653119802474976
Validation loss: 2.1570760511582896

Epoch: 6| Step: 7
Training loss: 1.4599502086639404
Validation loss: 2.2036029882328485

Epoch: 6| Step: 8
Training loss: 0.7561802864074707
Validation loss: 2.1437309980392456

Epoch: 6| Step: 9
Training loss: 1.7145237922668457
Validation loss: 2.203104281938204

Epoch: 6| Step: 10
Training loss: 1.4178154468536377
Validation loss: 2.1054223557954193

Epoch: 6| Step: 11
Training loss: 0.9375128149986267
Validation loss: 2.2128468021269767

Epoch: 6| Step: 12
Training loss: 1.4780347347259521
Validation loss: 2.1965071821725495

Epoch: 6| Step: 13
Training loss: 1.4971071481704712
Validation loss: 2.163733641306559

Epoch: 683| Step: 0
Training loss: 1.8418450355529785
Validation loss: 2.192118872878372

Epoch: 6| Step: 1
Training loss: 1.3575762510299683
Validation loss: 2.164358365920282

Epoch: 6| Step: 2
Training loss: 1.6341643333435059
Validation loss: 2.206805606042185

Epoch: 6| Step: 3
Training loss: 1.8765240907669067
Validation loss: 2.1948427602808964

Epoch: 6| Step: 4
Training loss: 1.4321986436843872
Validation loss: 2.1869254522426154

Epoch: 6| Step: 5
Training loss: 0.827398419380188
Validation loss: 2.213405388657765

Epoch: 6| Step: 6
Training loss: 1.3178141117095947
Validation loss: 2.214314901700584

Epoch: 6| Step: 7
Training loss: 1.696350336074829
Validation loss: 2.0903365765848467

Epoch: 6| Step: 8
Training loss: 0.9670264720916748
Validation loss: 2.16153428118716

Epoch: 6| Step: 9
Training loss: 1.142064094543457
Validation loss: 2.1718443247579757

Epoch: 6| Step: 10
Training loss: 1.4059466123580933
Validation loss: 2.2086906356196248

Epoch: 6| Step: 11
Training loss: 0.8534454703330994
Validation loss: 2.190130426037696

Epoch: 6| Step: 12
Training loss: 0.8684297800064087
Validation loss: 2.1387807117995394

Epoch: 6| Step: 13
Training loss: 1.1409459114074707
Validation loss: 2.2432788366912515

Epoch: 684| Step: 0
Training loss: 0.9286609292030334
Validation loss: 2.1740144516832087

Epoch: 6| Step: 1
Training loss: 1.955509901046753
Validation loss: 2.106563191260061

Epoch: 6| Step: 2
Training loss: 1.4238712787628174
Validation loss: 2.2202357143484135

Epoch: 6| Step: 3
Training loss: 1.7521268129348755
Validation loss: 2.1598816405060473

Epoch: 6| Step: 4
Training loss: 0.9184750318527222
Validation loss: 2.1471475734505603

Epoch: 6| Step: 5
Training loss: 1.9058383703231812
Validation loss: 2.140670414893858

Epoch: 6| Step: 6
Training loss: 1.0377813577651978
Validation loss: 2.048440928100258

Epoch: 6| Step: 7
Training loss: 1.2810194492340088
Validation loss: 2.2199139107940016

Epoch: 6| Step: 8
Training loss: 0.9143272638320923
Validation loss: 2.0888379671240367

Epoch: 6| Step: 9
Training loss: 1.2730225324630737
Validation loss: 2.1648250664434125

Epoch: 6| Step: 10
Training loss: 1.2698252201080322
Validation loss: 2.2389073051432127

Epoch: 6| Step: 11
Training loss: 1.1630423069000244
Validation loss: 2.1165217789270545

Epoch: 6| Step: 12
Training loss: 0.9579328894615173
Validation loss: 2.172811682506274

Epoch: 6| Step: 13
Training loss: 2.140091896057129
Validation loss: 2.195396056739233

Epoch: 685| Step: 0
Training loss: 1.3269877433776855
Validation loss: 2.2637790902968375

Epoch: 6| Step: 1
Training loss: 0.9783027768135071
Validation loss: 2.145069099241687

Epoch: 6| Step: 2
Training loss: 1.1802568435668945
Validation loss: 2.1368096951515443

Epoch: 6| Step: 3
Training loss: 1.3331230878829956
Validation loss: 2.198172389820058

Epoch: 6| Step: 4
Training loss: 1.3924973011016846
Validation loss: 2.1708889263932423

Epoch: 6| Step: 5
Training loss: 1.2641730308532715
Validation loss: 2.2205904427395073

Epoch: 6| Step: 6
Training loss: 1.5203948020935059
Validation loss: 2.1649465586549494

Epoch: 6| Step: 7
Training loss: 1.3669183254241943
Validation loss: 2.1656242647478656

Epoch: 6| Step: 8
Training loss: 1.9544354677200317
Validation loss: 2.1768761116971254

Epoch: 6| Step: 9
Training loss: 0.9847290515899658
Validation loss: 2.226626994789288

Epoch: 6| Step: 10
Training loss: 1.2238283157348633
Validation loss: 2.294856230417887

Epoch: 6| Step: 11
Training loss: 1.702054500579834
Validation loss: 2.204869007551542

Epoch: 6| Step: 12
Training loss: 1.0123546123504639
Validation loss: 2.253374958551058

Epoch: 6| Step: 13
Training loss: 1.3402355909347534
Validation loss: 2.227736867884154

Epoch: 686| Step: 0
Training loss: 1.3735051155090332
Validation loss: 2.167081512430663

Epoch: 6| Step: 1
Training loss: 0.8649756908416748
Validation loss: 2.162018252957252

Epoch: 6| Step: 2
Training loss: 1.3919456005096436
Validation loss: 2.1526495051640335

Epoch: 6| Step: 3
Training loss: 1.5289080142974854
Validation loss: 2.13734487436151

Epoch: 6| Step: 4
Training loss: 1.3679360151290894
Validation loss: 2.171448992144677

Epoch: 6| Step: 5
Training loss: 1.21139395236969
Validation loss: 2.206229653409732

Epoch: 6| Step: 6
Training loss: 1.3194658756256104
Validation loss: 2.1464302257824968

Epoch: 6| Step: 7
Training loss: 1.1089112758636475
Validation loss: 2.178229234551871

Epoch: 6| Step: 8
Training loss: 1.0418082475662231
Validation loss: 2.232412794584869

Epoch: 6| Step: 9
Training loss: 2.5035104751586914
Validation loss: 2.136235035875792

Epoch: 6| Step: 10
Training loss: 0.9716655015945435
Validation loss: 2.138376533344228

Epoch: 6| Step: 11
Training loss: 1.4787859916687012
Validation loss: 2.179406476277177

Epoch: 6| Step: 12
Training loss: 2.121044635772705
Validation loss: 2.189214119347193

Epoch: 6| Step: 13
Training loss: 0.5283189415931702
Validation loss: 2.113743935861895

Epoch: 687| Step: 0
Training loss: 1.1355884075164795
Validation loss: 2.262460808600149

Epoch: 6| Step: 1
Training loss: 1.419907569885254
Validation loss: 2.1518042702828684

Epoch: 6| Step: 2
Training loss: 0.9849953651428223
Validation loss: 2.2649821645470074

Epoch: 6| Step: 3
Training loss: 1.3407914638519287
Validation loss: 2.14919097961918

Epoch: 6| Step: 4
Training loss: 1.9684700965881348
Validation loss: 2.2168152524578955

Epoch: 6| Step: 5
Training loss: 1.0618174076080322
Validation loss: 2.275472001362872

Epoch: 6| Step: 6
Training loss: 1.2682629823684692
Validation loss: 2.2152365920364216

Epoch: 6| Step: 7
Training loss: 0.9772676825523376
Validation loss: 2.0975130296522573

Epoch: 6| Step: 8
Training loss: 1.1488401889801025
Validation loss: 2.1526400940392607

Epoch: 6| Step: 9
Training loss: 1.761626958847046
Validation loss: 2.1819831581525904

Epoch: 6| Step: 10
Training loss: 0.9226429462432861
Validation loss: 2.2156723904353317

Epoch: 6| Step: 11
Training loss: 2.004889488220215
Validation loss: 2.157993096177296

Epoch: 6| Step: 12
Training loss: 1.6259938478469849
Validation loss: 2.06724101625463

Epoch: 6| Step: 13
Training loss: 1.702360987663269
Validation loss: 2.231637498383881

Epoch: 688| Step: 0
Training loss: 1.606130838394165
Validation loss: 2.195167943995486

Epoch: 6| Step: 1
Training loss: 1.6148102283477783
Validation loss: 2.2419839597517446

Epoch: 6| Step: 2
Training loss: 1.2120203971862793
Validation loss: 2.174671705051135

Epoch: 6| Step: 3
Training loss: 1.4590142965316772
Validation loss: 2.222325535230739

Epoch: 6| Step: 4
Training loss: 1.0938770771026611
Validation loss: 2.123878263658093

Epoch: 6| Step: 5
Training loss: 1.0118467807769775
Validation loss: 2.1238065176112677

Epoch: 6| Step: 6
Training loss: 2.193401336669922
Validation loss: 2.23022735247048

Epoch: 6| Step: 7
Training loss: 1.5525002479553223
Validation loss: 2.1901824717880576

Epoch: 6| Step: 8
Training loss: 1.3173186779022217
Validation loss: 2.2276520100972985

Epoch: 6| Step: 9
Training loss: 1.7200469970703125
Validation loss: 2.2187792537032918

Epoch: 6| Step: 10
Training loss: 0.9361175894737244
Validation loss: 2.1488647807028984

Epoch: 6| Step: 11
Training loss: 0.994293749332428
Validation loss: 2.1815063107398247

Epoch: 6| Step: 12
Training loss: 0.9886487722396851
Validation loss: 2.2538333067329983

Epoch: 6| Step: 13
Training loss: 1.1509853601455688
Validation loss: 2.1513295763282367

Epoch: 689| Step: 0
Training loss: 1.7156314849853516
Validation loss: 2.10504380221008

Epoch: 6| Step: 1
Training loss: 1.3926746845245361
Validation loss: 2.1995581247473277

Epoch: 6| Step: 2
Training loss: 0.9239017963409424
Validation loss: 2.132673822423463

Epoch: 6| Step: 3
Training loss: 1.287786602973938
Validation loss: 2.2838291916795956

Epoch: 6| Step: 4
Training loss: 1.409796953201294
Validation loss: 2.170978969143283

Epoch: 6| Step: 5
Training loss: 1.2225472927093506
Validation loss: 2.1630165653844036

Epoch: 6| Step: 6
Training loss: 1.694824457168579
Validation loss: 2.1700877861310075

Epoch: 6| Step: 7
Training loss: 0.8693174123764038
Validation loss: 2.1019863031243764

Epoch: 6| Step: 8
Training loss: 0.9944603443145752
Validation loss: 2.1479528437378588

Epoch: 6| Step: 9
Training loss: 1.0218143463134766
Validation loss: 2.2081194218768867

Epoch: 6| Step: 10
Training loss: 1.186159372329712
Validation loss: 2.1556787003753004

Epoch: 6| Step: 11
Training loss: 1.7200576066970825
Validation loss: 2.155202764336781

Epoch: 6| Step: 12
Training loss: 1.4429130554199219
Validation loss: 2.204684408762122

Epoch: 6| Step: 13
Training loss: 1.3976986408233643
Validation loss: 2.1153040009160198

Epoch: 690| Step: 0
Training loss: 1.7711849212646484
Validation loss: 2.1747347103652133

Epoch: 6| Step: 1
Training loss: 1.0542514324188232
Validation loss: 2.145471113984303

Epoch: 6| Step: 2
Training loss: 1.0756373405456543
Validation loss: 2.227091157308189

Epoch: 6| Step: 3
Training loss: 1.9461743831634521
Validation loss: 2.1165343215388637

Epoch: 6| Step: 4
Training loss: 1.0588407516479492
Validation loss: 2.1292443095996814

Epoch: 6| Step: 5
Training loss: 1.255030870437622
Validation loss: 2.1426598602725613

Epoch: 6| Step: 6
Training loss: 1.2155499458312988
Validation loss: 2.210328091857254

Epoch: 6| Step: 7
Training loss: 1.1982626914978027
Validation loss: 2.162045084020143

Epoch: 6| Step: 8
Training loss: 1.5469577312469482
Validation loss: 2.075937009626819

Epoch: 6| Step: 9
Training loss: 0.8182300925254822
Validation loss: 2.143793154788274

Epoch: 6| Step: 10
Training loss: 1.3729312419891357
Validation loss: 2.1288318634033203

Epoch: 6| Step: 11
Training loss: 1.1417491436004639
Validation loss: 2.166865151415589

Epoch: 6| Step: 12
Training loss: 1.400159239768982
Validation loss: 2.1191912748480357

Epoch: 6| Step: 13
Training loss: 1.3523701429367065
Validation loss: 2.2091579629528906

Epoch: 691| Step: 0
Training loss: 1.6819947957992554
Validation loss: 2.175243044412264

Epoch: 6| Step: 1
Training loss: 1.070688247680664
Validation loss: 2.1708023804490284

Epoch: 6| Step: 2
Training loss: 1.1513643264770508
Validation loss: 2.2125467523451774

Epoch: 6| Step: 3
Training loss: 1.7789440155029297
Validation loss: 2.199533993198026

Epoch: 6| Step: 4
Training loss: 1.9620654582977295
Validation loss: 2.195321895742929

Epoch: 6| Step: 5
Training loss: 1.827571988105774
Validation loss: 2.2024168327290523

Epoch: 6| Step: 6
Training loss: 1.1738252639770508
Validation loss: 2.117960406887916

Epoch: 6| Step: 7
Training loss: 1.0226645469665527
Validation loss: 2.15335500624872

Epoch: 6| Step: 8
Training loss: 0.9461098313331604
Validation loss: 2.1828671527165238

Epoch: 6| Step: 9
Training loss: 1.8424303531646729
Validation loss: 2.1651624453965055

Epoch: 6| Step: 10
Training loss: 0.7328671813011169
Validation loss: 2.0835933044392574

Epoch: 6| Step: 11
Training loss: 1.2889649868011475
Validation loss: 2.087308014592817

Epoch: 6| Step: 12
Training loss: 1.3747673034667969
Validation loss: 2.1613603561155257

Epoch: 6| Step: 13
Training loss: 0.9909707307815552
Validation loss: 2.179593445152365

Epoch: 692| Step: 0
Training loss: 1.4394160509109497
Validation loss: 2.1826420278959375

Epoch: 6| Step: 1
Training loss: 1.5154775381088257
Validation loss: 2.154825001634577

Epoch: 6| Step: 2
Training loss: 0.7686359882354736
Validation loss: 2.1058585131040184

Epoch: 6| Step: 3
Training loss: 1.565418004989624
Validation loss: 2.103099176960607

Epoch: 6| Step: 4
Training loss: 1.2971071004867554
Validation loss: 2.1127311286105903

Epoch: 6| Step: 5
Training loss: 1.78844153881073
Validation loss: 2.152549756470547

Epoch: 6| Step: 6
Training loss: 0.964648425579071
Validation loss: 2.2188519816244803

Epoch: 6| Step: 7
Training loss: 1.3569750785827637
Validation loss: 2.2150784564274613

Epoch: 6| Step: 8
Training loss: 1.4267545938491821
Validation loss: 2.1478862018995386

Epoch: 6| Step: 9
Training loss: 1.4380046129226685
Validation loss: 2.2493284940719604

Epoch: 6| Step: 10
Training loss: 1.5144307613372803
Validation loss: 2.197950781032603

Epoch: 6| Step: 11
Training loss: 1.0169373750686646
Validation loss: 2.2252095694183023

Epoch: 6| Step: 12
Training loss: 1.446825385093689
Validation loss: 2.1110521939492997

Epoch: 6| Step: 13
Training loss: 1.3262394666671753
Validation loss: 2.218122789936681

Epoch: 693| Step: 0
Training loss: 1.3201913833618164
Validation loss: 2.2453899139999063

Epoch: 6| Step: 1
Training loss: 1.4207661151885986
Validation loss: 2.2338367277576077

Epoch: 6| Step: 2
Training loss: 1.4727702140808105
Validation loss: 2.255369000537421

Epoch: 6| Step: 3
Training loss: 2.1846981048583984
Validation loss: 2.266460080300608

Epoch: 6| Step: 4
Training loss: 1.2656348943710327
Validation loss: 2.23851881488677

Epoch: 6| Step: 5
Training loss: 1.3739371299743652
Validation loss: 2.195030138056765

Epoch: 6| Step: 6
Training loss: 1.2818548679351807
Validation loss: 2.187022416822372

Epoch: 6| Step: 7
Training loss: 0.794202446937561
Validation loss: 2.223860581715902

Epoch: 6| Step: 8
Training loss: 1.3595808744430542
Validation loss: 2.137499306791572

Epoch: 6| Step: 9
Training loss: 0.9032291173934937
Validation loss: 2.2024325247733825

Epoch: 6| Step: 10
Training loss: 1.1055006980895996
Validation loss: 2.097911903935094

Epoch: 6| Step: 11
Training loss: 0.8723492622375488
Validation loss: 2.1497430493754726

Epoch: 6| Step: 12
Training loss: 1.48185133934021
Validation loss: 2.09456625036014

Epoch: 6| Step: 13
Training loss: 0.7469473481178284
Validation loss: 2.1912770822484005

Epoch: 694| Step: 0
Training loss: 0.6231483817100525
Validation loss: 2.1767200282824937

Epoch: 6| Step: 1
Training loss: 1.5247294902801514
Validation loss: 2.132801259717634

Epoch: 6| Step: 2
Training loss: 1.4315764904022217
Validation loss: 2.097580414946361

Epoch: 6| Step: 3
Training loss: 0.9289501905441284
Validation loss: 2.1436940572595082

Epoch: 6| Step: 4
Training loss: 1.282638430595398
Validation loss: 2.21337112047339

Epoch: 6| Step: 5
Training loss: 1.340132713317871
Validation loss: 2.128425116180092

Epoch: 6| Step: 6
Training loss: 1.5736576318740845
Validation loss: 2.106349165721606

Epoch: 6| Step: 7
Training loss: 1.6859790086746216
Validation loss: 2.148722275610893

Epoch: 6| Step: 8
Training loss: 1.118782639503479
Validation loss: 2.1632088140774797

Epoch: 6| Step: 9
Training loss: 0.889595627784729
Validation loss: 2.1913730047082387

Epoch: 6| Step: 10
Training loss: 2.5875916481018066
Validation loss: 2.1290801276442823

Epoch: 6| Step: 11
Training loss: 1.1147823333740234
Validation loss: 2.138218720753988

Epoch: 6| Step: 12
Training loss: 1.3310128450393677
Validation loss: 2.1125940199821227

Epoch: 6| Step: 13
Training loss: 1.0045580863952637
Validation loss: 2.110932537304458

Epoch: 695| Step: 0
Training loss: 1.0959272384643555
Validation loss: 2.149327096118722

Epoch: 6| Step: 1
Training loss: 1.591728687286377
Validation loss: 2.2478389227262108

Epoch: 6| Step: 2
Training loss: 1.7696611881256104
Validation loss: 2.1985297638882875

Epoch: 6| Step: 3
Training loss: 0.6824748516082764
Validation loss: 2.244366761176817

Epoch: 6| Step: 4
Training loss: 1.1569087505340576
Validation loss: 2.182545315834784

Epoch: 6| Step: 5
Training loss: 1.393893837928772
Validation loss: 2.150849409000848

Epoch: 6| Step: 6
Training loss: 1.2734642028808594
Validation loss: 2.224285578214994

Epoch: 6| Step: 7
Training loss: 1.1208233833312988
Validation loss: 2.2209927587098974

Epoch: 6| Step: 8
Training loss: 1.0258221626281738
Validation loss: 2.239614443112445

Epoch: 6| Step: 9
Training loss: 1.504582405090332
Validation loss: 2.1886739013015584

Epoch: 6| Step: 10
Training loss: 1.4738547801971436
Validation loss: 2.163328884750284

Epoch: 6| Step: 11
Training loss: 1.1718451976776123
Validation loss: 2.156747002755442

Epoch: 6| Step: 12
Training loss: 1.306753396987915
Validation loss: 2.192735254123647

Epoch: 6| Step: 13
Training loss: 1.4066096544265747
Validation loss: 2.141819897518363

Epoch: 696| Step: 0
Training loss: 1.349489688873291
Validation loss: 2.176732634985319

Epoch: 6| Step: 1
Training loss: 0.9808304905891418
Validation loss: 2.1922772315240677

Epoch: 6| Step: 2
Training loss: 1.1050385236740112
Validation loss: 2.1429844120497346

Epoch: 6| Step: 3
Training loss: 1.156551480293274
Validation loss: 2.1269651151472524

Epoch: 6| Step: 4
Training loss: 1.3803365230560303
Validation loss: 2.1753676322198685

Epoch: 6| Step: 5
Training loss: 1.7504056692123413
Validation loss: 2.1745422668354486

Epoch: 6| Step: 6
Training loss: 1.4888882637023926
Validation loss: 2.221995871554139

Epoch: 6| Step: 7
Training loss: 1.7711844444274902
Validation loss: 2.2081972578520417

Epoch: 6| Step: 8
Training loss: 1.927917718887329
Validation loss: 2.164158126359345

Epoch: 6| Step: 9
Training loss: 1.3892430067062378
Validation loss: 2.126860450672847

Epoch: 6| Step: 10
Training loss: 1.3934214115142822
Validation loss: 2.11293056959747

Epoch: 6| Step: 11
Training loss: 1.1901297569274902
Validation loss: 2.154544331694162

Epoch: 6| Step: 12
Training loss: 1.2692410945892334
Validation loss: 2.2147382818242556

Epoch: 6| Step: 13
Training loss: 1.3426107168197632
Validation loss: 2.168736985934678

Epoch: 697| Step: 0
Training loss: 1.9218106269836426
Validation loss: 2.1715921919832946

Epoch: 6| Step: 1
Training loss: 1.2229629755020142
Validation loss: 2.2002413388221496

Epoch: 6| Step: 2
Training loss: 1.0865801572799683
Validation loss: 2.2473724977944487

Epoch: 6| Step: 3
Training loss: 1.7848621606826782
Validation loss: 2.1628194060376895

Epoch: 6| Step: 4
Training loss: 1.6862449645996094
Validation loss: 2.233318377566594

Epoch: 6| Step: 5
Training loss: 1.2194160223007202
Validation loss: 2.205074869176393

Epoch: 6| Step: 6
Training loss: 1.1188571453094482
Validation loss: 2.264513008056148

Epoch: 6| Step: 7
Training loss: 0.9532141089439392
Validation loss: 2.201866606230377

Epoch: 6| Step: 8
Training loss: 0.9421823024749756
Validation loss: 2.2038954060564757

Epoch: 6| Step: 9
Training loss: 2.315525531768799
Validation loss: 2.2388127375674505

Epoch: 6| Step: 10
Training loss: 1.3756725788116455
Validation loss: 2.132458097191267

Epoch: 6| Step: 11
Training loss: 1.0440962314605713
Validation loss: 2.230784018834432

Epoch: 6| Step: 12
Training loss: 0.9358298778533936
Validation loss: 2.197695559070956

Epoch: 6| Step: 13
Training loss: 1.3873939514160156
Validation loss: 2.1385217020588536

Epoch: 698| Step: 0
Training loss: 1.6479415893554688
Validation loss: 2.1546908219655356

Epoch: 6| Step: 1
Training loss: 1.329087257385254
Validation loss: 2.185941626948695

Epoch: 6| Step: 2
Training loss: 1.131983995437622
Validation loss: 2.228006857697682

Epoch: 6| Step: 3
Training loss: 1.356116533279419
Validation loss: 2.1873801856912594

Epoch: 6| Step: 4
Training loss: 1.5041964054107666
Validation loss: 2.1763202118617233

Epoch: 6| Step: 5
Training loss: 1.9308514595031738
Validation loss: 2.069627256803615

Epoch: 6| Step: 6
Training loss: 1.3198795318603516
Validation loss: 2.1078108754209293

Epoch: 6| Step: 7
Training loss: 1.3786766529083252
Validation loss: 2.0983809963349374

Epoch: 6| Step: 8
Training loss: 0.9464238286018372
Validation loss: 2.161985861357822

Epoch: 6| Step: 9
Training loss: 1.0848581790924072
Validation loss: 2.1548285509950373

Epoch: 6| Step: 10
Training loss: 1.426326870918274
Validation loss: 2.1991741400893017

Epoch: 6| Step: 11
Training loss: 1.5198689699172974
Validation loss: 2.1003557879437684

Epoch: 6| Step: 12
Training loss: 1.0224571228027344
Validation loss: 2.1645920456096692

Epoch: 6| Step: 13
Training loss: 1.300872802734375
Validation loss: 2.120236417298676

Epoch: 699| Step: 0
Training loss: 0.948082447052002
Validation loss: 2.1933444520478607

Epoch: 6| Step: 1
Training loss: 1.2657887935638428
Validation loss: 2.172069767470001

Epoch: 6| Step: 2
Training loss: 1.231749415397644
Validation loss: 2.166423643788984

Epoch: 6| Step: 3
Training loss: 1.1357091665267944
Validation loss: 2.2799496022603845

Epoch: 6| Step: 4
Training loss: 1.5324045419692993
Validation loss: 2.292791438359086

Epoch: 6| Step: 5
Training loss: 0.8964661359786987
Validation loss: 2.17791239676937

Epoch: 6| Step: 6
Training loss: 1.1762338876724243
Validation loss: 2.200166425397319

Epoch: 6| Step: 7
Training loss: 1.81050443649292
Validation loss: 2.2510321909381497

Epoch: 6| Step: 8
Training loss: 1.1859782934188843
Validation loss: 2.168681316478278

Epoch: 6| Step: 9
Training loss: 2.039566993713379
Validation loss: 2.1562705104069044

Epoch: 6| Step: 10
Training loss: 1.3569027185440063
Validation loss: 2.1388543011039816

Epoch: 6| Step: 11
Training loss: 1.8499106168746948
Validation loss: 2.1686594101690475

Epoch: 6| Step: 12
Training loss: 1.6290863752365112
Validation loss: 2.197701815635927

Epoch: 6| Step: 13
Training loss: 0.6948617100715637
Validation loss: 2.1742581808438866

Epoch: 700| Step: 0
Training loss: 0.9667917490005493
Validation loss: 2.1638027262944046

Epoch: 6| Step: 1
Training loss: 0.6497147083282471
Validation loss: 2.2456265982761177

Epoch: 6| Step: 2
Training loss: 2.481667995452881
Validation loss: 2.181813629724646

Epoch: 6| Step: 3
Training loss: 1.1168756484985352
Validation loss: 2.160537924817813

Epoch: 6| Step: 4
Training loss: 1.2503256797790527
Validation loss: 2.1581494295468895

Epoch: 6| Step: 5
Training loss: 1.7613765001296997
Validation loss: 2.1524778924962527

Epoch: 6| Step: 6
Training loss: 2.0109517574310303
Validation loss: 2.218805715601931

Epoch: 6| Step: 7
Training loss: 0.9491316676139832
Validation loss: 2.184155756427396

Epoch: 6| Step: 8
Training loss: 1.5411412715911865
Validation loss: 2.1844142534399547

Epoch: 6| Step: 9
Training loss: 0.997957706451416
Validation loss: 2.2294412325787287

Epoch: 6| Step: 10
Training loss: 1.0096166133880615
Validation loss: 2.1864632278360348

Epoch: 6| Step: 11
Training loss: 1.6317156553268433
Validation loss: 2.0742997969350507

Epoch: 6| Step: 12
Training loss: 0.6721335649490356
Validation loss: 2.25959369444078

Epoch: 6| Step: 13
Training loss: 0.869090735912323
Validation loss: 2.2338568215729087

Epoch: 701| Step: 0
Training loss: 1.3433191776275635
Validation loss: 2.138136443271432

Epoch: 6| Step: 1
Training loss: 1.5765609741210938
Validation loss: 2.1012788575182677

Epoch: 6| Step: 2
Training loss: 1.103288173675537
Validation loss: 2.1255492292424685

Epoch: 6| Step: 3
Training loss: 1.4514145851135254
Validation loss: 2.160570119016914

Epoch: 6| Step: 4
Training loss: 0.9947312474250793
Validation loss: 2.1573411316000004

Epoch: 6| Step: 5
Training loss: 1.3048765659332275
Validation loss: 2.177502452686269

Epoch: 6| Step: 6
Training loss: 1.6537528038024902
Validation loss: 2.1651429950550036

Epoch: 6| Step: 7
Training loss: 1.270951271057129
Validation loss: 2.1269022239151822

Epoch: 6| Step: 8
Training loss: 1.7439262866973877
Validation loss: 2.093258500099182

Epoch: 6| Step: 9
Training loss: 1.335069179534912
Validation loss: 2.176306970657841

Epoch: 6| Step: 10
Training loss: 1.2838280200958252
Validation loss: 2.082514900033192

Epoch: 6| Step: 11
Training loss: 1.367901086807251
Validation loss: 2.2449678426147788

Epoch: 6| Step: 12
Training loss: 0.8943077325820923
Validation loss: 2.111495630715483

Epoch: 6| Step: 13
Training loss: 0.810836911201477
Validation loss: 2.2459664293514785

Epoch: 702| Step: 0
Training loss: 1.2991079092025757
Validation loss: 2.1822419986929944

Epoch: 6| Step: 1
Training loss: 1.204827904701233
Validation loss: 2.1847163361887776

Epoch: 6| Step: 2
Training loss: 0.5411756038665771
Validation loss: 2.139552995722781

Epoch: 6| Step: 3
Training loss: 1.4963115453720093
Validation loss: 2.1885000736482683

Epoch: 6| Step: 4
Training loss: 1.368360161781311
Validation loss: 2.2467272461101575

Epoch: 6| Step: 5
Training loss: 1.1193718910217285
Validation loss: 2.177175957669494

Epoch: 6| Step: 6
Training loss: 1.5375280380249023
Validation loss: 2.1709517009796633

Epoch: 6| Step: 7
Training loss: 1.060328483581543
Validation loss: 2.2047551242254113

Epoch: 6| Step: 8
Training loss: 1.7378394603729248
Validation loss: 2.250344407173895

Epoch: 6| Step: 9
Training loss: 1.5914361476898193
Validation loss: 2.1850178241729736

Epoch: 6| Step: 10
Training loss: 1.3594260215759277
Validation loss: 2.1848831586940314

Epoch: 6| Step: 11
Training loss: 1.181145429611206
Validation loss: 2.162839771598898

Epoch: 6| Step: 12
Training loss: 1.3701691627502441
Validation loss: 2.1432861384525093

Epoch: 6| Step: 13
Training loss: 1.9067933559417725
Validation loss: 2.2268774714521182

Epoch: 703| Step: 0
Training loss: 1.109694480895996
Validation loss: 2.279190153203985

Epoch: 6| Step: 1
Training loss: 1.8343889713287354
Validation loss: 2.213814681576144

Epoch: 6| Step: 2
Training loss: 1.0714759826660156
Validation loss: 2.1989255464205177

Epoch: 6| Step: 3
Training loss: 1.4325790405273438
Validation loss: 2.100360361478662

Epoch: 6| Step: 4
Training loss: 0.871286153793335
Validation loss: 2.1672770028473227

Epoch: 6| Step: 5
Training loss: 1.8581974506378174
Validation loss: 2.1345686117808023

Epoch: 6| Step: 6
Training loss: 1.5332070589065552
Validation loss: 2.1755654478585846

Epoch: 6| Step: 7
Training loss: 1.7119483947753906
Validation loss: 2.1145210240476873

Epoch: 6| Step: 8
Training loss: 1.5889283418655396
Validation loss: 2.2072473597782913

Epoch: 6| Step: 9
Training loss: 0.8299000859260559
Validation loss: 2.168643074650918

Epoch: 6| Step: 10
Training loss: 1.3334167003631592
Validation loss: 2.197745203971863

Epoch: 6| Step: 11
Training loss: 1.0626511573791504
Validation loss: 2.109202710531091

Epoch: 6| Step: 12
Training loss: 1.4588871002197266
Validation loss: 2.235569877009238

Epoch: 6| Step: 13
Training loss: 0.7590070366859436
Validation loss: 2.1229932564561085

Epoch: 704| Step: 0
Training loss: 1.4350723028182983
Validation loss: 2.1776325702667236

Epoch: 6| Step: 1
Training loss: 1.410731315612793
Validation loss: 2.126506051709575

Epoch: 6| Step: 2
Training loss: 1.0915985107421875
Validation loss: 2.14210852243567

Epoch: 6| Step: 3
Training loss: 1.077134370803833
Validation loss: 2.154459148324946

Epoch: 6| Step: 4
Training loss: 1.8176968097686768
Validation loss: 2.2463749583049486

Epoch: 6| Step: 5
Training loss: 1.288781762123108
Validation loss: 2.162578111053795

Epoch: 6| Step: 6
Training loss: 1.147353172302246
Validation loss: 2.1862288457091137

Epoch: 6| Step: 7
Training loss: 1.097299337387085
Validation loss: 2.2033851685062533

Epoch: 6| Step: 8
Training loss: 1.896923303604126
Validation loss: 2.1649211017034387

Epoch: 6| Step: 9
Training loss: 0.9129034280776978
Validation loss: 2.2027821720287366

Epoch: 6| Step: 10
Training loss: 1.2976715564727783
Validation loss: 2.1993737041309314

Epoch: 6| Step: 11
Training loss: 1.6235522031784058
Validation loss: 2.209682851709345

Epoch: 6| Step: 12
Training loss: 1.2566951513290405
Validation loss: 2.10866827477691

Epoch: 6| Step: 13
Training loss: 0.7353331446647644
Validation loss: 2.207875451733989

Epoch: 705| Step: 0
Training loss: 1.597364902496338
Validation loss: 2.1126084584061817

Epoch: 6| Step: 1
Training loss: 1.1931415796279907
Validation loss: 2.192478697787049

Epoch: 6| Step: 2
Training loss: 1.3377764225006104
Validation loss: 2.2171176838618454

Epoch: 6| Step: 3
Training loss: 1.620851993560791
Validation loss: 2.188957829629221

Epoch: 6| Step: 4
Training loss: 1.4576345682144165
Validation loss: 2.1722934246063232

Epoch: 6| Step: 5
Training loss: 1.4532318115234375
Validation loss: 2.110208962553291

Epoch: 6| Step: 6
Training loss: 1.5778493881225586
Validation loss: 2.137810786565145

Epoch: 6| Step: 7
Training loss: 0.7438321113586426
Validation loss: 2.2022734995811217

Epoch: 6| Step: 8
Training loss: 1.1829293966293335
Validation loss: 2.1446753522401214

Epoch: 6| Step: 9
Training loss: 1.058948040008545
Validation loss: 2.2074386253151843

Epoch: 6| Step: 10
Training loss: 1.035098671913147
Validation loss: 2.1762091934040027

Epoch: 6| Step: 11
Training loss: 1.3515902757644653
Validation loss: 2.1552061521878807

Epoch: 6| Step: 12
Training loss: 1.3837120532989502
Validation loss: 2.1233538889115855

Epoch: 6| Step: 13
Training loss: 1.908491611480713
Validation loss: 2.1583349345832743

Epoch: 706| Step: 0
Training loss: 1.1604477167129517
Validation loss: 2.2029975409148843

Epoch: 6| Step: 1
Training loss: 1.5414689779281616
Validation loss: 2.1480625367933706

Epoch: 6| Step: 2
Training loss: 1.5141932964324951
Validation loss: 2.1354143414446103

Epoch: 6| Step: 3
Training loss: 1.0652867555618286
Validation loss: 2.1616557528895717

Epoch: 6| Step: 4
Training loss: 0.9678587913513184
Validation loss: 2.182268370864212

Epoch: 6| Step: 5
Training loss: 1.234243392944336
Validation loss: 2.199045814493651

Epoch: 6| Step: 6
Training loss: 1.4055334329605103
Validation loss: 2.1270349384636007

Epoch: 6| Step: 7
Training loss: 1.0106492042541504
Validation loss: 2.1640996445891676

Epoch: 6| Step: 8
Training loss: 1.8854198455810547
Validation loss: 2.11531227378435

Epoch: 6| Step: 9
Training loss: 1.6910121440887451
Validation loss: 2.1387524861161427

Epoch: 6| Step: 10
Training loss: 1.1878186464309692
Validation loss: 2.1876786267885597

Epoch: 6| Step: 11
Training loss: 1.0429692268371582
Validation loss: 2.0967143017758607

Epoch: 6| Step: 12
Training loss: 1.203594446182251
Validation loss: 2.2177484240583194

Epoch: 6| Step: 13
Training loss: 1.5807433128356934
Validation loss: 2.142753247291811

Epoch: 707| Step: 0
Training loss: 1.4916882514953613
Validation loss: 2.1609331459127445

Epoch: 6| Step: 1
Training loss: 1.0365291833877563
Validation loss: 2.0948503812154136

Epoch: 6| Step: 2
Training loss: 1.0014734268188477
Validation loss: 2.147730194112306

Epoch: 6| Step: 3
Training loss: 1.8545777797698975
Validation loss: 2.0969028806173675

Epoch: 6| Step: 4
Training loss: 1.1542351245880127
Validation loss: 2.219048915370818

Epoch: 6| Step: 5
Training loss: 1.5352883338928223
Validation loss: 2.1555689329742105

Epoch: 6| Step: 6
Training loss: 0.913133442401886
Validation loss: 2.1891247072527484

Epoch: 6| Step: 7
Training loss: 1.1011989116668701
Validation loss: 2.137123318128688

Epoch: 6| Step: 8
Training loss: 1.2291315793991089
Validation loss: 2.1803383058117283

Epoch: 6| Step: 9
Training loss: 1.1154823303222656
Validation loss: 2.216745312495898

Epoch: 6| Step: 10
Training loss: 1.2640780210494995
Validation loss: 2.1969111017001572

Epoch: 6| Step: 11
Training loss: 1.6432313919067383
Validation loss: 2.188794587248115

Epoch: 6| Step: 12
Training loss: 1.6527161598205566
Validation loss: 2.2499913938583864

Epoch: 6| Step: 13
Training loss: 1.5004162788391113
Validation loss: 2.1822715549058813

Epoch: 708| Step: 0
Training loss: 1.1580651998519897
Validation loss: 2.1831249062732985

Epoch: 6| Step: 1
Training loss: 1.8887676000595093
Validation loss: 2.150118566328479

Epoch: 6| Step: 2
Training loss: 1.4000320434570312
Validation loss: 2.2048226582106722

Epoch: 6| Step: 3
Training loss: 1.1968679428100586
Validation loss: 2.1814632261953046

Epoch: 6| Step: 4
Training loss: 1.3899552822113037
Validation loss: 2.229029901566044

Epoch: 6| Step: 5
Training loss: 1.436185359954834
Validation loss: 2.129501221000507

Epoch: 6| Step: 6
Training loss: 1.500368595123291
Validation loss: 2.1313401191465315

Epoch: 6| Step: 7
Training loss: 1.675724983215332
Validation loss: 2.215785398278185

Epoch: 6| Step: 8
Training loss: 1.6873023509979248
Validation loss: 2.1425964293941373

Epoch: 6| Step: 9
Training loss: 1.2646055221557617
Validation loss: 2.2343515888337167

Epoch: 6| Step: 10
Training loss: 1.1968326568603516
Validation loss: 2.135850111643473

Epoch: 6| Step: 11
Training loss: 0.7136430740356445
Validation loss: 2.1887572580768215

Epoch: 6| Step: 12
Training loss: 0.9551739692687988
Validation loss: 2.1388461077085106

Epoch: 6| Step: 13
Training loss: 1.5843441486358643
Validation loss: 2.1376464584822297

Epoch: 709| Step: 0
Training loss: 1.5214544534683228
Validation loss: 2.216895757182952

Epoch: 6| Step: 1
Training loss: 1.2152005434036255
Validation loss: 2.2168382495962162

Epoch: 6| Step: 2
Training loss: 1.1281697750091553
Validation loss: 2.1230199619006087

Epoch: 6| Step: 3
Training loss: 1.3953380584716797
Validation loss: 2.155205329259237

Epoch: 6| Step: 4
Training loss: 1.748523473739624
Validation loss: 2.0984191945804063

Epoch: 6| Step: 5
Training loss: 1.5195634365081787
Validation loss: 2.1448833891140517

Epoch: 6| Step: 6
Training loss: 1.7277209758758545
Validation loss: 2.136821703244281

Epoch: 6| Step: 7
Training loss: 0.8488457798957825
Validation loss: 2.277318517367045

Epoch: 6| Step: 8
Training loss: 0.8132492899894714
Validation loss: 2.131238822014101

Epoch: 6| Step: 9
Training loss: 1.734713077545166
Validation loss: 2.2039716807744836

Epoch: 6| Step: 10
Training loss: 1.0347180366516113
Validation loss: 2.2271756946399646

Epoch: 6| Step: 11
Training loss: 1.4250143766403198
Validation loss: 2.1372487442467802

Epoch: 6| Step: 12
Training loss: 1.1736981868743896
Validation loss: 2.1593701121627644

Epoch: 6| Step: 13
Training loss: 1.1331441402435303
Validation loss: 2.2317324325602543

Epoch: 710| Step: 0
Training loss: 0.8373677730560303
Validation loss: 2.160879736305565

Epoch: 6| Step: 1
Training loss: 1.4144173860549927
Validation loss: 2.1429095114431074

Epoch: 6| Step: 2
Training loss: 1.06769597530365
Validation loss: 2.15105503348894

Epoch: 6| Step: 3
Training loss: 1.2707598209381104
Validation loss: 2.2690086390382502

Epoch: 6| Step: 4
Training loss: 0.9782372713088989
Validation loss: 2.174910242839526

Epoch: 6| Step: 5
Training loss: 0.9426456093788147
Validation loss: 2.155789498359926

Epoch: 6| Step: 6
Training loss: 1.3009393215179443
Validation loss: 2.1330583685187885

Epoch: 6| Step: 7
Training loss: 1.1616665124893188
Validation loss: 2.181483253355949

Epoch: 6| Step: 8
Training loss: 2.225182056427002
Validation loss: 2.183895795576034

Epoch: 6| Step: 9
Training loss: 1.0398184061050415
Validation loss: 2.1286736085850704

Epoch: 6| Step: 10
Training loss: 1.6071921586990356
Validation loss: 2.110092391249954

Epoch: 6| Step: 11
Training loss: 1.6173155307769775
Validation loss: 2.207202067939184

Epoch: 6| Step: 12
Training loss: 1.7982286214828491
Validation loss: 2.1489374381239696

Epoch: 6| Step: 13
Training loss: 1.235229730606079
Validation loss: 2.189319984887236

Epoch: 711| Step: 0
Training loss: 0.9980486631393433
Validation loss: 2.084484774579284

Epoch: 6| Step: 1
Training loss: 1.4126899242401123
Validation loss: 2.2247610361345354

Epoch: 6| Step: 2
Training loss: 0.9768807888031006
Validation loss: 2.235483287483133

Epoch: 6| Step: 3
Training loss: 1.4897441864013672
Validation loss: 2.1506028021535566

Epoch: 6| Step: 4
Training loss: 1.996761679649353
Validation loss: 2.2396789494381157

Epoch: 6| Step: 5
Training loss: 1.091090440750122
Validation loss: 2.1517788069222563

Epoch: 6| Step: 6
Training loss: 1.2669262886047363
Validation loss: 2.192449085174068

Epoch: 6| Step: 7
Training loss: 1.4369362592697144
Validation loss: 2.1648122495220554

Epoch: 6| Step: 8
Training loss: 1.907392978668213
Validation loss: 2.2267546038473807

Epoch: 6| Step: 9
Training loss: 1.2585456371307373
Validation loss: 2.08865878915274

Epoch: 6| Step: 10
Training loss: 0.8822022676467896
Validation loss: 2.2548857517139886

Epoch: 6| Step: 11
Training loss: 1.265492558479309
Validation loss: 2.1442244719433528

Epoch: 6| Step: 12
Training loss: 1.4796243906021118
Validation loss: 2.1254850484991588

Epoch: 6| Step: 13
Training loss: 0.8559212684631348
Validation loss: 2.180114961439563

Epoch: 712| Step: 0
Training loss: 1.3395919799804688
Validation loss: 2.149191056528399

Epoch: 6| Step: 1
Training loss: 0.7166863679885864
Validation loss: 2.1472878584297757

Epoch: 6| Step: 2
Training loss: 1.4753953218460083
Validation loss: 2.1536242513246435

Epoch: 6| Step: 3
Training loss: 1.3300353288650513
Validation loss: 2.1641582506959156

Epoch: 6| Step: 4
Training loss: 1.4056756496429443
Validation loss: 2.147483456519342

Epoch: 6| Step: 5
Training loss: 1.8825232982635498
Validation loss: 2.1368452989926903

Epoch: 6| Step: 6
Training loss: 1.2173850536346436
Validation loss: 2.1256363404694425

Epoch: 6| Step: 7
Training loss: 1.5326566696166992
Validation loss: 2.2372583573864353

Epoch: 6| Step: 8
Training loss: 1.0529050827026367
Validation loss: 2.1314714954745386

Epoch: 6| Step: 9
Training loss: 1.5232864618301392
Validation loss: 2.21499898100412

Epoch: 6| Step: 10
Training loss: 0.8173093199729919
Validation loss: 2.152733423376596

Epoch: 6| Step: 11
Training loss: 1.2417094707489014
Validation loss: 2.2773036213331324

Epoch: 6| Step: 12
Training loss: 1.360405683517456
Validation loss: 2.1814415147227626

Epoch: 6| Step: 13
Training loss: 1.3704631328582764
Validation loss: 2.14968438558681

Epoch: 713| Step: 0
Training loss: 1.3774727582931519
Validation loss: 2.1886262547585273

Epoch: 6| Step: 1
Training loss: 0.772498369216919
Validation loss: 2.251108964284261

Epoch: 6| Step: 2
Training loss: 1.3236602544784546
Validation loss: 2.185016051415474

Epoch: 6| Step: 3
Training loss: 1.9231414794921875
Validation loss: 2.2092298000089583

Epoch: 6| Step: 4
Training loss: 1.1586843729019165
Validation loss: 2.1731939187613865

Epoch: 6| Step: 5
Training loss: 0.9668086171150208
Validation loss: 2.1613643682131203

Epoch: 6| Step: 6
Training loss: 1.821199893951416
Validation loss: 2.180771481606268

Epoch: 6| Step: 7
Training loss: 0.8358961343765259
Validation loss: 2.165615943170363

Epoch: 6| Step: 8
Training loss: 1.3491662740707397
Validation loss: 2.1092438338905253

Epoch: 6| Step: 9
Training loss: 1.5991480350494385
Validation loss: 2.2130545544367966

Epoch: 6| Step: 10
Training loss: 0.6105090379714966
Validation loss: 2.11328956132294

Epoch: 6| Step: 11
Training loss: 1.402367353439331
Validation loss: 2.170825860833609

Epoch: 6| Step: 12
Training loss: 1.4359071254730225
Validation loss: 2.2069549291364607

Epoch: 6| Step: 13
Training loss: 0.7929545640945435
Validation loss: 2.2047091248214885

Epoch: 714| Step: 0
Training loss: 1.5206328630447388
Validation loss: 2.15533620824096

Epoch: 6| Step: 1
Training loss: 0.8710826635360718
Validation loss: 2.1318467586271224

Epoch: 6| Step: 2
Training loss: 0.8465687036514282
Validation loss: 2.184303081163796

Epoch: 6| Step: 3
Training loss: 1.248487949371338
Validation loss: 2.158992603260984

Epoch: 6| Step: 4
Training loss: 1.4333081245422363
Validation loss: 2.2146267685838925

Epoch: 6| Step: 5
Training loss: 1.00431227684021
Validation loss: 2.2432698511308238

Epoch: 6| Step: 6
Training loss: 1.4287983179092407
Validation loss: 2.139970325654553

Epoch: 6| Step: 7
Training loss: 1.6708018779754639
Validation loss: 2.190794999881457

Epoch: 6| Step: 8
Training loss: 1.7010385990142822
Validation loss: 2.153197253904035

Epoch: 6| Step: 9
Training loss: 1.1059287786483765
Validation loss: 2.169650152165403

Epoch: 6| Step: 10
Training loss: 1.1834444999694824
Validation loss: 2.179739870050902

Epoch: 6| Step: 11
Training loss: 1.7935099601745605
Validation loss: 2.164858771908668

Epoch: 6| Step: 12
Training loss: 0.8955448269844055
Validation loss: 2.2248774356739496

Epoch: 6| Step: 13
Training loss: 1.458371639251709
Validation loss: 2.1981163101811565

Epoch: 715| Step: 0
Training loss: 1.9944959878921509
Validation loss: 2.1195900594034502

Epoch: 6| Step: 1
Training loss: 1.2893365621566772
Validation loss: 2.1751971731903734

Epoch: 6| Step: 2
Training loss: 1.708130121231079
Validation loss: 2.173449936733451

Epoch: 6| Step: 3
Training loss: 1.3331949710845947
Validation loss: 2.2056111417790896

Epoch: 6| Step: 4
Training loss: 1.1025536060333252
Validation loss: 2.1945251739153298

Epoch: 6| Step: 5
Training loss: 0.5851250886917114
Validation loss: 2.1565447738093715

Epoch: 6| Step: 6
Training loss: 1.0348929166793823
Validation loss: 2.122561090735979

Epoch: 6| Step: 7
Training loss: 0.7582863569259644
Validation loss: 2.203629929532287

Epoch: 6| Step: 8
Training loss: 1.8079901933670044
Validation loss: 2.144418262666272

Epoch: 6| Step: 9
Training loss: 1.061795711517334
Validation loss: 2.1566390939938125

Epoch: 6| Step: 10
Training loss: 1.2312350273132324
Validation loss: 2.1087575266438146

Epoch: 6| Step: 11
Training loss: 1.5770483016967773
Validation loss: 2.1839236520951792

Epoch: 6| Step: 12
Training loss: 1.2299549579620361
Validation loss: 2.188106729138282

Epoch: 6| Step: 13
Training loss: 1.3634713888168335
Validation loss: 2.231113718402001

Epoch: 716| Step: 0
Training loss: 1.4831385612487793
Validation loss: 2.2015803526806574

Epoch: 6| Step: 1
Training loss: 0.852649986743927
Validation loss: 2.200584162947952

Epoch: 6| Step: 2
Training loss: 1.2290146350860596
Validation loss: 2.283966697672362

Epoch: 6| Step: 3
Training loss: 1.5440680980682373
Validation loss: 2.2131978440028366

Epoch: 6| Step: 4
Training loss: 1.281898021697998
Validation loss: 2.2000516255696616

Epoch: 6| Step: 5
Training loss: 0.6168879270553589
Validation loss: 2.1881811952078216

Epoch: 6| Step: 6
Training loss: 1.8508045673370361
Validation loss: 2.2269960013769006

Epoch: 6| Step: 7
Training loss: 1.4402445554733276
Validation loss: 2.1993002250630367

Epoch: 6| Step: 8
Training loss: 1.1567343473434448
Validation loss: 2.280360637172576

Epoch: 6| Step: 9
Training loss: 1.785221815109253
Validation loss: 2.0979190744379514

Epoch: 6| Step: 10
Training loss: 1.5919723510742188
Validation loss: 2.2265687142649004

Epoch: 6| Step: 11
Training loss: 0.782406747341156
Validation loss: 2.191612616662056

Epoch: 6| Step: 12
Training loss: 0.8972312211990356
Validation loss: 2.193915231253511

Epoch: 6| Step: 13
Training loss: 1.6774131059646606
Validation loss: 2.138724514233169

Epoch: 717| Step: 0
Training loss: 1.512355089187622
Validation loss: 2.194240035549287

Epoch: 6| Step: 1
Training loss: 2.6364035606384277
Validation loss: 2.236133334457233

Epoch: 6| Step: 2
Training loss: 0.47855132818222046
Validation loss: 2.2628720139944427

Epoch: 6| Step: 3
Training loss: 1.0042364597320557
Validation loss: 2.135086199288727

Epoch: 6| Step: 4
Training loss: 0.75165855884552
Validation loss: 2.200251599793793

Epoch: 6| Step: 5
Training loss: 1.2291404008865356
Validation loss: 2.143440306827586

Epoch: 6| Step: 6
Training loss: 1.69091796875
Validation loss: 2.1959734578286447

Epoch: 6| Step: 7
Training loss: 0.9993258118629456
Validation loss: 2.2248161954264485

Epoch: 6| Step: 8
Training loss: 1.177364468574524
Validation loss: 2.202888197796319

Epoch: 6| Step: 9
Training loss: 1.6708062887191772
Validation loss: 2.1826048666431057

Epoch: 6| Step: 10
Training loss: 1.3135285377502441
Validation loss: 2.1971522223564888

Epoch: 6| Step: 11
Training loss: 1.1624021530151367
Validation loss: 2.0796954298532135

Epoch: 6| Step: 12
Training loss: 1.1514029502868652
Validation loss: 2.2022134975720475

Epoch: 6| Step: 13
Training loss: 1.5998812913894653
Validation loss: 2.1469303100339827

Epoch: 718| Step: 0
Training loss: 1.608105182647705
Validation loss: 2.228862388159639

Epoch: 6| Step: 1
Training loss: 1.197043776512146
Validation loss: 2.1824505867496615

Epoch: 6| Step: 2
Training loss: 1.4813214540481567
Validation loss: 2.170965950976136

Epoch: 6| Step: 3
Training loss: 0.9243164658546448
Validation loss: 2.26580370882506

Epoch: 6| Step: 4
Training loss: 1.2010002136230469
Validation loss: 2.171924155245545

Epoch: 6| Step: 5
Training loss: 1.1100573539733887
Validation loss: 2.2364647285912627

Epoch: 6| Step: 6
Training loss: 1.1461098194122314
Validation loss: 2.17817921023215

Epoch: 6| Step: 7
Training loss: 1.9618990421295166
Validation loss: 2.1563963684984433

Epoch: 6| Step: 8
Training loss: 1.4552195072174072
Validation loss: 2.1958978829845304

Epoch: 6| Step: 9
Training loss: 1.507657527923584
Validation loss: 2.2031224696866927

Epoch: 6| Step: 10
Training loss: 1.1451730728149414
Validation loss: 2.193133497750887

Epoch: 6| Step: 11
Training loss: 1.4463688135147095
Validation loss: 2.163111827706778

Epoch: 6| Step: 12
Training loss: 1.0289329290390015
Validation loss: 2.1372867732919674

Epoch: 6| Step: 13
Training loss: 0.8517014980316162
Validation loss: 2.18384277179677

Epoch: 719| Step: 0
Training loss: 0.9663600325584412
Validation loss: 2.1608662195103143

Epoch: 6| Step: 1
Training loss: 1.3705283403396606
Validation loss: 2.1958647684384416

Epoch: 6| Step: 2
Training loss: 1.206700086593628
Validation loss: 2.1852921029572845

Epoch: 6| Step: 3
Training loss: 1.6190197467803955
Validation loss: 2.117272328304988

Epoch: 6| Step: 4
Training loss: 0.8387941122055054
Validation loss: 2.20684152777477

Epoch: 6| Step: 5
Training loss: 1.0001177787780762
Validation loss: 2.2094279502027776

Epoch: 6| Step: 6
Training loss: 1.2819740772247314
Validation loss: 2.201284691851626

Epoch: 6| Step: 7
Training loss: 0.96857750415802
Validation loss: 2.2259687390378726

Epoch: 6| Step: 8
Training loss: 1.4880532026290894
Validation loss: 2.2189124655979935

Epoch: 6| Step: 9
Training loss: 1.9299325942993164
Validation loss: 2.277474570017989

Epoch: 6| Step: 10
Training loss: 1.29857337474823
Validation loss: 2.178464238361646

Epoch: 6| Step: 11
Training loss: 1.1044329404830933
Validation loss: 2.2372751287234727

Epoch: 6| Step: 12
Training loss: 1.5455539226531982
Validation loss: 2.1749968631293184

Epoch: 6| Step: 13
Training loss: 1.3310656547546387
Validation loss: 2.183082422902507

Epoch: 720| Step: 0
Training loss: 1.8251399993896484
Validation loss: 2.1479437505045245

Epoch: 6| Step: 1
Training loss: 1.4511529207229614
Validation loss: 2.113864550026514

Epoch: 6| Step: 2
Training loss: 1.3504031896591187
Validation loss: 2.11733950338056

Epoch: 6| Step: 3
Training loss: 1.3723883628845215
Validation loss: 2.1926057466896633

Epoch: 6| Step: 4
Training loss: 0.6130234003067017
Validation loss: 2.186434266387775

Epoch: 6| Step: 5
Training loss: 1.254125714302063
Validation loss: 2.143551375276299

Epoch: 6| Step: 6
Training loss: 1.1965925693511963
Validation loss: 2.160085326881819

Epoch: 6| Step: 7
Training loss: 2.0169272422790527
Validation loss: 2.1868707031332035

Epoch: 6| Step: 8
Training loss: 0.8005902767181396
Validation loss: 2.1663193189969627

Epoch: 6| Step: 9
Training loss: 0.9405623078346252
Validation loss: 2.2539470452134327

Epoch: 6| Step: 10
Training loss: 1.0694212913513184
Validation loss: 2.161146745886854

Epoch: 6| Step: 11
Training loss: 1.0204461812973022
Validation loss: 2.210715277220613

Epoch: 6| Step: 12
Training loss: 1.572751760482788
Validation loss: 2.1885341957051265

Epoch: 6| Step: 13
Training loss: 1.6205015182495117
Validation loss: 2.1517545305272585

Epoch: 721| Step: 0
Training loss: 0.8322019577026367
Validation loss: 2.132576924498363

Epoch: 6| Step: 1
Training loss: 1.4872314929962158
Validation loss: 2.1428631172385266

Epoch: 6| Step: 2
Training loss: 1.2669084072113037
Validation loss: 2.221186250768682

Epoch: 6| Step: 3
Training loss: 1.2290148735046387
Validation loss: 2.1082225025341077

Epoch: 6| Step: 4
Training loss: 0.9809337258338928
Validation loss: 2.132782252885962

Epoch: 6| Step: 5
Training loss: 1.362414836883545
Validation loss: 2.2109730064228015

Epoch: 6| Step: 6
Training loss: 1.2853256464004517
Validation loss: 2.171020419366898

Epoch: 6| Step: 7
Training loss: 1.5991580486297607
Validation loss: 2.1505546698006253

Epoch: 6| Step: 8
Training loss: 1.4050683975219727
Validation loss: 2.2194909152164253

Epoch: 6| Step: 9
Training loss: 1.151749610900879
Validation loss: 2.2112290115766626

Epoch: 6| Step: 10
Training loss: 0.6786618828773499
Validation loss: 2.130089662408316

Epoch: 6| Step: 11
Training loss: 1.875298261642456
Validation loss: 2.199178029132146

Epoch: 6| Step: 12
Training loss: 1.3389003276824951
Validation loss: 2.243004181051767

Epoch: 6| Step: 13
Training loss: 1.3741966485977173
Validation loss: 2.1403658915591497

Epoch: 722| Step: 0
Training loss: 0.9386012554168701
Validation loss: 2.17551818970711

Epoch: 6| Step: 1
Training loss: 1.3426551818847656
Validation loss: 2.1981546417359383

Epoch: 6| Step: 2
Training loss: 0.8622759580612183
Validation loss: 2.2053401188183854

Epoch: 6| Step: 3
Training loss: 1.5364481210708618
Validation loss: 2.268996733491139

Epoch: 6| Step: 4
Training loss: 1.5044171810150146
Validation loss: 2.1731075009992047

Epoch: 6| Step: 5
Training loss: 0.9145290851593018
Validation loss: 2.2274018372258833

Epoch: 6| Step: 6
Training loss: 1.4226813316345215
Validation loss: 2.0996907910993023

Epoch: 6| Step: 7
Training loss: 1.028802514076233
Validation loss: 2.23362107687099

Epoch: 6| Step: 8
Training loss: 1.0052008628845215
Validation loss: 2.145274999321148

Epoch: 6| Step: 9
Training loss: 1.4715521335601807
Validation loss: 2.184742177686384

Epoch: 6| Step: 10
Training loss: 1.6402919292449951
Validation loss: 2.1481109460194907

Epoch: 6| Step: 11
Training loss: 1.3621681928634644
Validation loss: 2.1438160711719143

Epoch: 6| Step: 12
Training loss: 1.048728108406067
Validation loss: 2.079983716369957

Epoch: 6| Step: 13
Training loss: 1.8247320652008057
Validation loss: 2.140258491680186

Epoch: 723| Step: 0
Training loss: 1.087127447128296
Validation loss: 2.155087794027021

Epoch: 6| Step: 1
Training loss: 1.1628453731536865
Validation loss: 2.1545220895480086

Epoch: 6| Step: 2
Training loss: 1.5054590702056885
Validation loss: 2.2061966439729095

Epoch: 6| Step: 3
Training loss: 1.9751338958740234
Validation loss: 2.151446262995402

Epoch: 6| Step: 4
Training loss: 1.4345588684082031
Validation loss: 2.181384592927912

Epoch: 6| Step: 5
Training loss: 1.6117119789123535
Validation loss: 2.1053767563194357

Epoch: 6| Step: 6
Training loss: 0.996509313583374
Validation loss: 2.2604662449129167

Epoch: 6| Step: 7
Training loss: 0.9351074695587158
Validation loss: 2.2343722184499106

Epoch: 6| Step: 8
Training loss: 1.0922131538391113
Validation loss: 2.1498739437390397

Epoch: 6| Step: 9
Training loss: 1.0632874965667725
Validation loss: 2.180441218037759

Epoch: 6| Step: 10
Training loss: 1.268763542175293
Validation loss: 2.241995847353371

Epoch: 6| Step: 11
Training loss: 1.5054301023483276
Validation loss: 2.189185651399756

Epoch: 6| Step: 12
Training loss: 0.701728343963623
Validation loss: 2.258057302044284

Epoch: 6| Step: 13
Training loss: 1.7229351997375488
Validation loss: 2.2193033079947195

Epoch: 724| Step: 0
Training loss: 1.0109246969223022
Validation loss: 2.1209420568199566

Epoch: 6| Step: 1
Training loss: 1.19087553024292
Validation loss: 2.1979952858340357

Epoch: 6| Step: 2
Training loss: 1.4180799722671509
Validation loss: 2.1098440488179526

Epoch: 6| Step: 3
Training loss: 0.8826652765274048
Validation loss: 2.220722290777391

Epoch: 6| Step: 4
Training loss: 1.4656846523284912
Validation loss: 2.1952177914240028

Epoch: 6| Step: 5
Training loss: 1.0820527076721191
Validation loss: 2.153610796056768

Epoch: 6| Step: 6
Training loss: 1.3261137008666992
Validation loss: 2.122161370451732

Epoch: 6| Step: 7
Training loss: 1.7927472591400146
Validation loss: 2.2026389670628372

Epoch: 6| Step: 8
Training loss: 1.4836176633834839
Validation loss: 2.1010109583536782

Epoch: 6| Step: 9
Training loss: 1.6600685119628906
Validation loss: 2.181514952772407

Epoch: 6| Step: 10
Training loss: 1.9010250568389893
Validation loss: 2.1301948357653875

Epoch: 6| Step: 11
Training loss: 1.1634483337402344
Validation loss: 2.1730181350502917

Epoch: 6| Step: 12
Training loss: 1.1318106651306152
Validation loss: 2.211430780349239

Epoch: 6| Step: 13
Training loss: 1.3890554904937744
Validation loss: 2.2253839456906883

Epoch: 725| Step: 0
Training loss: 0.7718724012374878
Validation loss: 2.2157610462557886

Epoch: 6| Step: 1
Training loss: 1.4865269660949707
Validation loss: 2.216090465104708

Epoch: 6| Step: 2
Training loss: 1.3170561790466309
Validation loss: 2.2595347691607732

Epoch: 6| Step: 3
Training loss: 1.5110000371932983
Validation loss: 2.169959654090225

Epoch: 6| Step: 4
Training loss: 1.0541417598724365
Validation loss: 2.2795426435368036

Epoch: 6| Step: 5
Training loss: 1.844888687133789
Validation loss: 2.2287363019040836

Epoch: 6| Step: 6
Training loss: 1.3883652687072754
Validation loss: 2.2202024844384964

Epoch: 6| Step: 7
Training loss: 1.3899104595184326
Validation loss: 2.194213236531904

Epoch: 6| Step: 8
Training loss: 1.3845179080963135
Validation loss: 2.1778133274406515

Epoch: 6| Step: 9
Training loss: 1.189605951309204
Validation loss: 2.1915406257875505

Epoch: 6| Step: 10
Training loss: 1.4647884368896484
Validation loss: 2.186112544869864

Epoch: 6| Step: 11
Training loss: 1.3016363382339478
Validation loss: 2.148985018012344

Epoch: 6| Step: 12
Training loss: 1.3498039245605469
Validation loss: 2.152480492027857

Epoch: 6| Step: 13
Training loss: 1.0611238479614258
Validation loss: 2.0762199586437595

Epoch: 726| Step: 0
Training loss: 1.1792147159576416
Validation loss: 2.2627925103710544

Epoch: 6| Step: 1
Training loss: 1.2348172664642334
Validation loss: 2.182420907482024

Epoch: 6| Step: 2
Training loss: 1.0595909357070923
Validation loss: 2.0938252736163396

Epoch: 6| Step: 3
Training loss: 1.6105241775512695
Validation loss: 2.1455162981505036

Epoch: 6| Step: 4
Training loss: 1.1774877309799194
Validation loss: 2.0944387400022118

Epoch: 6| Step: 5
Training loss: 1.235029935836792
Validation loss: 2.2331152846736293

Epoch: 6| Step: 6
Training loss: 1.637072205543518
Validation loss: 2.12987990661334

Epoch: 6| Step: 7
Training loss: 1.5428707599639893
Validation loss: 2.208008720028785

Epoch: 6| Step: 8
Training loss: 0.9965605139732361
Validation loss: 2.1807640444847847

Epoch: 6| Step: 9
Training loss: 1.1568126678466797
Validation loss: 2.2118668940759476

Epoch: 6| Step: 10
Training loss: 1.6787328720092773
Validation loss: 2.237885534122426

Epoch: 6| Step: 11
Training loss: 1.3206932544708252
Validation loss: 2.156885234258508

Epoch: 6| Step: 12
Training loss: 1.4167582988739014
Validation loss: 2.1607436903061403

Epoch: 6| Step: 13
Training loss: 1.0825884342193604
Validation loss: 2.2225228535231722

Epoch: 727| Step: 0
Training loss: 2.1981091499328613
Validation loss: 2.1378695041902605

Epoch: 6| Step: 1
Training loss: 1.1174930334091187
Validation loss: 2.246943945525795

Epoch: 6| Step: 2
Training loss: 0.7242689728736877
Validation loss: 2.236239666579872

Epoch: 6| Step: 3
Training loss: 0.9458581805229187
Validation loss: 2.1673989116504626

Epoch: 6| Step: 4
Training loss: 0.9942996501922607
Validation loss: 2.1861394784783803

Epoch: 6| Step: 5
Training loss: 1.321799874305725
Validation loss: 2.1722483096584195

Epoch: 6| Step: 6
Training loss: 1.4308679103851318
Validation loss: 2.2552763159557054

Epoch: 6| Step: 7
Training loss: 0.9307888746261597
Validation loss: 2.188424346267536

Epoch: 6| Step: 8
Training loss: 1.119417428970337
Validation loss: 2.1539453742324666

Epoch: 6| Step: 9
Training loss: 1.2524755001068115
Validation loss: 2.126185988867155

Epoch: 6| Step: 10
Training loss: 1.5056428909301758
Validation loss: 2.179602481985605

Epoch: 6| Step: 11
Training loss: 1.818819522857666
Validation loss: 2.162198861440023

Epoch: 6| Step: 12
Training loss: 1.3077938556671143
Validation loss: 2.1130696701747116

Epoch: 6| Step: 13
Training loss: 1.1171258687973022
Validation loss: 2.127891957118947

Epoch: 728| Step: 0
Training loss: 0.7415910959243774
Validation loss: 2.146826796634223

Epoch: 6| Step: 1
Training loss: 1.3724366426467896
Validation loss: 2.1767975079116

Epoch: 6| Step: 2
Training loss: 1.7762199640274048
Validation loss: 2.1527882673407115

Epoch: 6| Step: 3
Training loss: 1.4704508781433105
Validation loss: 2.220071751584289

Epoch: 6| Step: 4
Training loss: 1.1506394147872925
Validation loss: 2.2282036042982534

Epoch: 6| Step: 5
Training loss: 1.351283073425293
Validation loss: 2.21618216781206

Epoch: 6| Step: 6
Training loss: 1.191103458404541
Validation loss: 2.1831212992309244

Epoch: 6| Step: 7
Training loss: 0.9933465719223022
Validation loss: 2.1541614699107345

Epoch: 6| Step: 8
Training loss: 1.5572612285614014
Validation loss: 2.051932427190965

Epoch: 6| Step: 9
Training loss: 1.7488234043121338
Validation loss: 2.143818953985809

Epoch: 6| Step: 10
Training loss: 1.13273286819458
Validation loss: 2.1368984483903453

Epoch: 6| Step: 11
Training loss: 1.1318585872650146
Validation loss: 2.1493367123347458

Epoch: 6| Step: 12
Training loss: 1.4685823917388916
Validation loss: 2.1157245020712576

Epoch: 6| Step: 13
Training loss: 0.9693624973297119
Validation loss: 2.207082272857748

Epoch: 729| Step: 0
Training loss: 1.282684564590454
Validation loss: 2.253855883434255

Epoch: 6| Step: 1
Training loss: 1.326643943786621
Validation loss: 2.1549095158935874

Epoch: 6| Step: 2
Training loss: 1.287036657333374
Validation loss: 2.1756535191689768

Epoch: 6| Step: 3
Training loss: 1.3613574504852295
Validation loss: 2.219632238470098

Epoch: 6| Step: 4
Training loss: 1.4472752809524536
Validation loss: 2.169136106327016

Epoch: 6| Step: 5
Training loss: 0.724511981010437
Validation loss: 2.178687023860152

Epoch: 6| Step: 6
Training loss: 0.7815680503845215
Validation loss: 2.1125752182417017

Epoch: 6| Step: 7
Training loss: 1.403883934020996
Validation loss: 2.232962344282417

Epoch: 6| Step: 8
Training loss: 1.5192240476608276
Validation loss: 2.144437848880727

Epoch: 6| Step: 9
Training loss: 1.1828839778900146
Validation loss: 2.2082829372857207

Epoch: 6| Step: 10
Training loss: 1.2777111530303955
Validation loss: 2.183821460252167

Epoch: 6| Step: 11
Training loss: 1.2428362369537354
Validation loss: 2.1661663670693674

Epoch: 6| Step: 12
Training loss: 1.6893665790557861
Validation loss: 2.1426774276200162

Epoch: 6| Step: 13
Training loss: 1.356881856918335
Validation loss: 2.2242226677556194

Epoch: 730| Step: 0
Training loss: 0.8742626905441284
Validation loss: 2.2365044983484412

Epoch: 6| Step: 1
Training loss: 1.2531170845031738
Validation loss: 2.1995387782332716

Epoch: 6| Step: 2
Training loss: 1.41460120677948
Validation loss: 2.204358297009622

Epoch: 6| Step: 3
Training loss: 0.8982672691345215
Validation loss: 2.1858511740161526

Epoch: 6| Step: 4
Training loss: 0.8875861763954163
Validation loss: 2.211709749314093

Epoch: 6| Step: 5
Training loss: 1.4992594718933105
Validation loss: 2.21788421241186

Epoch: 6| Step: 6
Training loss: 1.0854804515838623
Validation loss: 2.0607674057765673

Epoch: 6| Step: 7
Training loss: 1.1813364028930664
Validation loss: 2.225666235851985

Epoch: 6| Step: 8
Training loss: 1.8524670600891113
Validation loss: 2.214518818804013

Epoch: 6| Step: 9
Training loss: 1.720523476600647
Validation loss: 2.2159098655946794

Epoch: 6| Step: 10
Training loss: 1.8680171966552734
Validation loss: 2.1774264663778324

Epoch: 6| Step: 11
Training loss: 1.3335075378417969
Validation loss: 2.1554430723190308

Epoch: 6| Step: 12
Training loss: 0.9891625642776489
Validation loss: 2.135372233647172

Epoch: 6| Step: 13
Training loss: 1.4749836921691895
Validation loss: 2.10044595503038

Epoch: 731| Step: 0
Training loss: 1.0198668241500854
Validation loss: 2.165679757313062

Epoch: 6| Step: 1
Training loss: 1.483917236328125
Validation loss: 2.189421034628345

Epoch: 6| Step: 2
Training loss: 1.0865920782089233
Validation loss: 2.2078807251427763

Epoch: 6| Step: 3
Training loss: 1.6767864227294922
Validation loss: 2.2439829405917915

Epoch: 6| Step: 4
Training loss: 1.533860206604004
Validation loss: 2.1673020239799254

Epoch: 6| Step: 5
Training loss: 0.8351690769195557
Validation loss: 2.1234731904921995

Epoch: 6| Step: 6
Training loss: 1.3306884765625
Validation loss: 2.1939847353966004

Epoch: 6| Step: 7
Training loss: 0.8180509805679321
Validation loss: 2.1861530939737954

Epoch: 6| Step: 8
Training loss: 1.374537467956543
Validation loss: 2.191666341597034

Epoch: 6| Step: 9
Training loss: 1.3758959770202637
Validation loss: 2.1110986125084663

Epoch: 6| Step: 10
Training loss: 1.6673438549041748
Validation loss: 2.0847805648721676

Epoch: 6| Step: 11
Training loss: 1.0395314693450928
Validation loss: 2.1484330251652706

Epoch: 6| Step: 12
Training loss: 1.3858356475830078
Validation loss: 2.1813048239677184

Epoch: 6| Step: 13
Training loss: 1.7745217084884644
Validation loss: 2.1209121468246623

Epoch: 732| Step: 0
Training loss: 0.8153108358383179
Validation loss: 2.187275973699426

Epoch: 6| Step: 1
Training loss: 1.1121439933776855
Validation loss: 2.142498162484938

Epoch: 6| Step: 2
Training loss: 1.0243940353393555
Validation loss: 2.170649789994763

Epoch: 6| Step: 3
Training loss: 1.625784158706665
Validation loss: 2.21058302797297

Epoch: 6| Step: 4
Training loss: 0.8488032817840576
Validation loss: 2.1508824210013113

Epoch: 6| Step: 5
Training loss: 1.2305023670196533
Validation loss: 2.1496950939137447

Epoch: 6| Step: 6
Training loss: 1.3958486318588257
Validation loss: 2.181002219518026

Epoch: 6| Step: 7
Training loss: 1.0405983924865723
Validation loss: 2.085900374638137

Epoch: 6| Step: 8
Training loss: 1.8143830299377441
Validation loss: 2.151094954500916

Epoch: 6| Step: 9
Training loss: 0.9547156095504761
Validation loss: 2.166172699261737

Epoch: 6| Step: 10
Training loss: 1.4058196544647217
Validation loss: 2.2070542509837816

Epoch: 6| Step: 11
Training loss: 1.1759049892425537
Validation loss: 2.1829668039916665

Epoch: 6| Step: 12
Training loss: 2.0098018646240234
Validation loss: 2.2563906151761293

Epoch: 6| Step: 13
Training loss: 1.955176830291748
Validation loss: 2.284079369678292

Epoch: 733| Step: 0
Training loss: 1.0027453899383545
Validation loss: 2.203344980875651

Epoch: 6| Step: 1
Training loss: 0.9788147211074829
Validation loss: 2.1229045416719172

Epoch: 6| Step: 2
Training loss: 1.0975397825241089
Validation loss: 2.1229507615489345

Epoch: 6| Step: 3
Training loss: 1.9878334999084473
Validation loss: 2.2259348848814606

Epoch: 6| Step: 4
Training loss: 0.7932276725769043
Validation loss: 2.092022934267598

Epoch: 6| Step: 5
Training loss: 1.3911054134368896
Validation loss: 2.1819607365515923

Epoch: 6| Step: 6
Training loss: 1.0849628448486328
Validation loss: 2.183441936328847

Epoch: 6| Step: 7
Training loss: 1.1884331703186035
Validation loss: 2.179979255122523

Epoch: 6| Step: 8
Training loss: 1.9434069395065308
Validation loss: 2.169196282663653

Epoch: 6| Step: 9
Training loss: 1.2797784805297852
Validation loss: 2.237009527862713

Epoch: 6| Step: 10
Training loss: 1.164209008216858
Validation loss: 2.174760498026366

Epoch: 6| Step: 11
Training loss: 1.5724494457244873
Validation loss: 2.1610221324428434

Epoch: 6| Step: 12
Training loss: 1.1021931171417236
Validation loss: 2.2467495754200923

Epoch: 6| Step: 13
Training loss: 1.4026342630386353
Validation loss: 2.214782412334155

Epoch: 734| Step: 0
Training loss: 1.3357012271881104
Validation loss: 2.181834110649683

Epoch: 6| Step: 1
Training loss: 0.739627480506897
Validation loss: 2.2245833976294405

Epoch: 6| Step: 2
Training loss: 1.2433760166168213
Validation loss: 2.1968569089007635

Epoch: 6| Step: 3
Training loss: 1.5184650421142578
Validation loss: 2.115671347546321

Epoch: 6| Step: 4
Training loss: 1.0114083290100098
Validation loss: 2.1804565486087593

Epoch: 6| Step: 5
Training loss: 1.024129867553711
Validation loss: 2.188791762116135

Epoch: 6| Step: 6
Training loss: 1.9037410020828247
Validation loss: 2.2188427935364428

Epoch: 6| Step: 7
Training loss: 1.006416916847229
Validation loss: 2.1475341960948002

Epoch: 6| Step: 8
Training loss: 0.9029651880264282
Validation loss: 2.1874651114145913

Epoch: 6| Step: 9
Training loss: 1.5427136421203613
Validation loss: 2.1140597430608605

Epoch: 6| Step: 10
Training loss: 1.2721489667892456
Validation loss: 2.1235885812390234

Epoch: 6| Step: 11
Training loss: 0.9898489117622375
Validation loss: 2.2012792992335495

Epoch: 6| Step: 12
Training loss: 1.3630445003509521
Validation loss: 2.2039949394041494

Epoch: 6| Step: 13
Training loss: 1.3889288902282715
Validation loss: 2.1474797905132337

Epoch: 735| Step: 0
Training loss: 0.8343847393989563
Validation loss: 2.2152617528874385

Epoch: 6| Step: 1
Training loss: 1.3443933725357056
Validation loss: 2.2016867706852574

Epoch: 6| Step: 2
Training loss: 1.0648951530456543
Validation loss: 2.2549998657677763

Epoch: 6| Step: 3
Training loss: 1.756139874458313
Validation loss: 2.1999881780275734

Epoch: 6| Step: 4
Training loss: 1.6277836561203003
Validation loss: 2.159637988254588

Epoch: 6| Step: 5
Training loss: 0.9779942035675049
Validation loss: 2.1728244058547483

Epoch: 6| Step: 6
Training loss: 0.9837428331375122
Validation loss: 2.1318699185566237

Epoch: 6| Step: 7
Training loss: 1.495631456375122
Validation loss: 2.1484322342821347

Epoch: 6| Step: 8
Training loss: 0.9558980464935303
Validation loss: 2.145677706246735

Epoch: 6| Step: 9
Training loss: 1.3715593814849854
Validation loss: 2.1519671640088482

Epoch: 6| Step: 10
Training loss: 1.3381822109222412
Validation loss: 2.160999708278205

Epoch: 6| Step: 11
Training loss: 1.4367417097091675
Validation loss: 2.1837259915567215

Epoch: 6| Step: 12
Training loss: 1.2653393745422363
Validation loss: 2.114537501847872

Epoch: 6| Step: 13
Training loss: 1.3802845478057861
Validation loss: 2.1731970515302432

Epoch: 736| Step: 0
Training loss: 1.047082543373108
Validation loss: 2.176286369241694

Epoch: 6| Step: 1
Training loss: 1.6540889739990234
Validation loss: 2.244114222065095

Epoch: 6| Step: 2
Training loss: 0.5939162969589233
Validation loss: 2.1275448324859783

Epoch: 6| Step: 3
Training loss: 1.3089414834976196
Validation loss: 2.2000670868863343

Epoch: 6| Step: 4
Training loss: 1.7646939754486084
Validation loss: 2.1315968228924658

Epoch: 6| Step: 5
Training loss: 1.2425532341003418
Validation loss: 2.1538730231664514

Epoch: 6| Step: 6
Training loss: 1.8135733604431152
Validation loss: 2.1662511441015426

Epoch: 6| Step: 7
Training loss: 1.002122402191162
Validation loss: 2.1766921756088093

Epoch: 6| Step: 8
Training loss: 1.1209651231765747
Validation loss: 2.182911196062642

Epoch: 6| Step: 9
Training loss: 1.863885760307312
Validation loss: 2.2206846514055805

Epoch: 6| Step: 10
Training loss: 0.6587361097335815
Validation loss: 2.149063615388768

Epoch: 6| Step: 11
Training loss: 1.1535193920135498
Validation loss: 2.163898411617484

Epoch: 6| Step: 12
Training loss: 1.0192052125930786
Validation loss: 2.1605986010643745

Epoch: 6| Step: 13
Training loss: 1.5642988681793213
Validation loss: 2.206039427429117

Epoch: 737| Step: 0
Training loss: 1.070988655090332
Validation loss: 2.15904430420168

Epoch: 6| Step: 1
Training loss: 0.9078408479690552
Validation loss: 2.2284690462132937

Epoch: 6| Step: 2
Training loss: 0.9634828567504883
Validation loss: 2.1675600749190136

Epoch: 6| Step: 3
Training loss: 0.9386286735534668
Validation loss: 2.1227753931476223

Epoch: 6| Step: 4
Training loss: 1.006995677947998
Validation loss: 2.1634877394604426

Epoch: 6| Step: 5
Training loss: 1.161909580230713
Validation loss: 2.2034382435583297

Epoch: 6| Step: 6
Training loss: 1.4946990013122559
Validation loss: 2.160369957647016

Epoch: 6| Step: 7
Training loss: 1.3702471256256104
Validation loss: 2.206901366992663

Epoch: 6| Step: 8
Training loss: 1.1857753992080688
Validation loss: 2.167100050116098

Epoch: 6| Step: 9
Training loss: 1.7570130825042725
Validation loss: 2.2529822049602384

Epoch: 6| Step: 10
Training loss: 1.382328748703003
Validation loss: 2.2106196111248386

Epoch: 6| Step: 11
Training loss: 1.5682942867279053
Validation loss: 2.146513713303433

Epoch: 6| Step: 12
Training loss: 1.5240455865859985
Validation loss: 2.22379913637715

Epoch: 6| Step: 13
Training loss: 2.0540876388549805
Validation loss: 2.1018359379101823

Epoch: 738| Step: 0
Training loss: 1.1732664108276367
Validation loss: 2.128358124404825

Epoch: 6| Step: 1
Training loss: 0.8507009744644165
Validation loss: 2.0929440670115973

Epoch: 6| Step: 2
Training loss: 1.6505403518676758
Validation loss: 2.2312920272991223

Epoch: 6| Step: 3
Training loss: 1.3410990238189697
Validation loss: 2.0954499206235333

Epoch: 6| Step: 4
Training loss: 1.0589312314987183
Validation loss: 2.204789588528295

Epoch: 6| Step: 5
Training loss: 2.505187511444092
Validation loss: 2.1401039656772407

Epoch: 6| Step: 6
Training loss: 0.6132502555847168
Validation loss: 2.1192458316844

Epoch: 6| Step: 7
Training loss: 2.192150115966797
Validation loss: 2.1461589182576826

Epoch: 6| Step: 8
Training loss: 1.007922887802124
Validation loss: 2.2173165557205037

Epoch: 6| Step: 9
Training loss: 1.280311942100525
Validation loss: 2.171418002856675

Epoch: 6| Step: 10
Training loss: 1.239209771156311
Validation loss: 2.150925463245761

Epoch: 6| Step: 11
Training loss: 1.3143528699874878
Validation loss: 2.1223369413806545

Epoch: 6| Step: 12
Training loss: 1.1362676620483398
Validation loss: 2.1430167741672967

Epoch: 6| Step: 13
Training loss: 0.9172348380088806
Validation loss: 2.107443312162994

Epoch: 739| Step: 0
Training loss: 1.804834246635437
Validation loss: 2.2688727378845215

Epoch: 6| Step: 1
Training loss: 0.870591938495636
Validation loss: 2.163379233370545

Epoch: 6| Step: 2
Training loss: 1.4314188957214355
Validation loss: 2.2046273857034664

Epoch: 6| Step: 3
Training loss: 1.1376113891601562
Validation loss: 2.207329744933754

Epoch: 6| Step: 4
Training loss: 2.0342390537261963
Validation loss: 2.1242442836043653

Epoch: 6| Step: 5
Training loss: 1.514150857925415
Validation loss: 2.127605207504765

Epoch: 6| Step: 6
Training loss: 0.87419593334198
Validation loss: 2.1146413228845082

Epoch: 6| Step: 7
Training loss: 1.1505951881408691
Validation loss: 2.190188700152982

Epoch: 6| Step: 8
Training loss: 0.861444890499115
Validation loss: 2.317817188078357

Epoch: 6| Step: 9
Training loss: 1.8288512229919434
Validation loss: 2.1652648936035814

Epoch: 6| Step: 10
Training loss: 1.3011648654937744
Validation loss: 2.231726964314779

Epoch: 6| Step: 11
Training loss: 1.0184787511825562
Validation loss: 2.214842196433775

Epoch: 6| Step: 12
Training loss: 1.053169846534729
Validation loss: 2.222524853162868

Epoch: 6| Step: 13
Training loss: 0.9821497797966003
Validation loss: 2.1749571677177184

Epoch: 740| Step: 0
Training loss: 0.8479350805282593
Validation loss: 2.1642512993146013

Epoch: 6| Step: 1
Training loss: 1.3349635601043701
Validation loss: 2.1371123790740967

Epoch: 6| Step: 2
Training loss: 0.9675841331481934
Validation loss: 2.1515815924572688

Epoch: 6| Step: 3
Training loss: 0.8231662511825562
Validation loss: 2.0958001305980067

Epoch: 6| Step: 4
Training loss: 1.0787487030029297
Validation loss: 2.150556783522329

Epoch: 6| Step: 5
Training loss: 1.5575262308120728
Validation loss: 2.133912509487521

Epoch: 6| Step: 6
Training loss: 1.4830427169799805
Validation loss: 2.159884081091932

Epoch: 6| Step: 7
Training loss: 1.320875644683838
Validation loss: 2.2037389637321554

Epoch: 6| Step: 8
Training loss: 0.6627635955810547
Validation loss: 2.1631587577122513

Epoch: 6| Step: 9
Training loss: 1.3071885108947754
Validation loss: 2.140578027694456

Epoch: 6| Step: 10
Training loss: 1.2274587154388428
Validation loss: 2.1925947871259464

Epoch: 6| Step: 11
Training loss: 1.2816829681396484
Validation loss: 2.16924911673351

Epoch: 6| Step: 12
Training loss: 1.8260420560836792
Validation loss: 2.1449896366365495

Epoch: 6| Step: 13
Training loss: 1.8573487997055054
Validation loss: 2.1889926771963797

Epoch: 741| Step: 0
Training loss: 1.46549391746521
Validation loss: 2.2090897149937128

Epoch: 6| Step: 1
Training loss: 1.6831674575805664
Validation loss: 2.192591110865275

Epoch: 6| Step: 2
Training loss: 1.5937151908874512
Validation loss: 2.27058478324644

Epoch: 6| Step: 3
Training loss: 0.6400090456008911
Validation loss: 2.1412914401741436

Epoch: 6| Step: 4
Training loss: 1.2530198097229004
Validation loss: 2.2006915230904855

Epoch: 6| Step: 5
Training loss: 0.9701805114746094
Validation loss: 2.121001515337216

Epoch: 6| Step: 6
Training loss: 1.5867958068847656
Validation loss: 2.1853399738188712

Epoch: 6| Step: 7
Training loss: 0.9351022243499756
Validation loss: 2.1511165083095594

Epoch: 6| Step: 8
Training loss: 1.6548049449920654
Validation loss: 2.197235520168017

Epoch: 6| Step: 9
Training loss: 1.2177973985671997
Validation loss: 2.1486540507244807

Epoch: 6| Step: 10
Training loss: 1.1475803852081299
Validation loss: 2.1343822479248047

Epoch: 6| Step: 11
Training loss: 0.9552805423736572
Validation loss: 2.1702046753257833

Epoch: 6| Step: 12
Training loss: 1.355966567993164
Validation loss: 2.1892913977305093

Epoch: 6| Step: 13
Training loss: 0.7487439513206482
Validation loss: 2.1015158750677623

Epoch: 742| Step: 0
Training loss: 0.9793793559074402
Validation loss: 2.1525199285117527

Epoch: 6| Step: 1
Training loss: 0.826457679271698
Validation loss: 2.2046071688334146

Epoch: 6| Step: 2
Training loss: 0.9689682722091675
Validation loss: 2.1115381922773135

Epoch: 6| Step: 3
Training loss: 1.7438666820526123
Validation loss: 2.1665128277194117

Epoch: 6| Step: 4
Training loss: 1.0213520526885986
Validation loss: 2.1530931316396242

Epoch: 6| Step: 5
Training loss: 0.9159318208694458
Validation loss: 2.280341743141092

Epoch: 6| Step: 6
Training loss: 1.7363576889038086
Validation loss: 2.20561977612075

Epoch: 6| Step: 7
Training loss: 1.5714443922042847
Validation loss: 2.175178184304186

Epoch: 6| Step: 8
Training loss: 1.1729309558868408
Validation loss: 2.1853959227121003

Epoch: 6| Step: 9
Training loss: 1.39420485496521
Validation loss: 2.2306339356207077

Epoch: 6| Step: 10
Training loss: 1.0129971504211426
Validation loss: 2.1791586055550525

Epoch: 6| Step: 11
Training loss: 1.2288497686386108
Validation loss: 2.161337924259965

Epoch: 6| Step: 12
Training loss: 2.122246742248535
Validation loss: 2.2183699095120994

Epoch: 6| Step: 13
Training loss: 1.3574926853179932
Validation loss: 2.1668214080154256

Epoch: 743| Step: 0
Training loss: 1.2584987878799438
Validation loss: 2.1646997813255555

Epoch: 6| Step: 1
Training loss: 1.1654045581817627
Validation loss: 2.1646272905411257

Epoch: 6| Step: 2
Training loss: 0.9294047355651855
Validation loss: 2.1110206521967405

Epoch: 6| Step: 3
Training loss: 0.8145250678062439
Validation loss: 2.207079364407447

Epoch: 6| Step: 4
Training loss: 1.0861868858337402
Validation loss: 2.196863769203104

Epoch: 6| Step: 5
Training loss: 1.3720052242279053
Validation loss: 2.173389844996955

Epoch: 6| Step: 6
Training loss: 1.5987473726272583
Validation loss: 2.2078861267335954

Epoch: 6| Step: 7
Training loss: 1.5382684469223022
Validation loss: 2.2059518688468525

Epoch: 6| Step: 8
Training loss: 0.5959969162940979
Validation loss: 2.085695469251243

Epoch: 6| Step: 9
Training loss: 1.1565666198730469
Validation loss: 2.156708364845604

Epoch: 6| Step: 10
Training loss: 1.980380892753601
Validation loss: 2.099601318759303

Epoch: 6| Step: 11
Training loss: 1.3725485801696777
Validation loss: 2.167997790921119

Epoch: 6| Step: 12
Training loss: 1.1300098896026611
Validation loss: 2.1945766761738765

Epoch: 6| Step: 13
Training loss: 0.9965900778770447
Validation loss: 2.269748474961968

Epoch: 744| Step: 0
Training loss: 0.6220695972442627
Validation loss: 2.1762031970485562

Epoch: 6| Step: 1
Training loss: 1.4693124294281006
Validation loss: 2.1823608260000906

Epoch: 6| Step: 2
Training loss: 1.3780725002288818
Validation loss: 2.1187108075746925

Epoch: 6| Step: 3
Training loss: 1.3668941259384155
Validation loss: 2.1514354623774046

Epoch: 6| Step: 4
Training loss: 0.8959798216819763
Validation loss: 2.161214892582227

Epoch: 6| Step: 5
Training loss: 1.3695003986358643
Validation loss: 2.14977623826714

Epoch: 6| Step: 6
Training loss: 1.1348639726638794
Validation loss: 2.167988522078401

Epoch: 6| Step: 7
Training loss: 1.1228501796722412
Validation loss: 2.267818171490905

Epoch: 6| Step: 8
Training loss: 1.223421335220337
Validation loss: 2.151477897039024

Epoch: 6| Step: 9
Training loss: 1.1517236232757568
Validation loss: 2.1843287816611667

Epoch: 6| Step: 10
Training loss: 1.1980857849121094
Validation loss: 2.140893095283098

Epoch: 6| Step: 11
Training loss: 1.542562484741211
Validation loss: 2.0801889345210087

Epoch: 6| Step: 12
Training loss: 1.226011037826538
Validation loss: 2.190706406870196

Epoch: 6| Step: 13
Training loss: 1.9863152503967285
Validation loss: 2.2142783800760903

Epoch: 745| Step: 0
Training loss: 1.2818315029144287
Validation loss: 2.199423174704275

Epoch: 6| Step: 1
Training loss: 0.810286283493042
Validation loss: 2.0285118395282375

Epoch: 6| Step: 2
Training loss: 1.0839184522628784
Validation loss: 2.1988233135592554

Epoch: 6| Step: 3
Training loss: 1.167372703552246
Validation loss: 2.19107045665864

Epoch: 6| Step: 4
Training loss: 1.3122493028640747
Validation loss: 2.1920108538801952

Epoch: 6| Step: 5
Training loss: 1.0348118543624878
Validation loss: 2.1862450004905782

Epoch: 6| Step: 6
Training loss: 1.2584755420684814
Validation loss: 2.1693896593586093

Epoch: 6| Step: 7
Training loss: 1.470426321029663
Validation loss: 2.1808494239725094

Epoch: 6| Step: 8
Training loss: 1.4463684558868408
Validation loss: 2.170510812472272

Epoch: 6| Step: 9
Training loss: 1.5346958637237549
Validation loss: 2.2429628141464724

Epoch: 6| Step: 10
Training loss: 0.9878255724906921
Validation loss: 2.2191545399286414

Epoch: 6| Step: 11
Training loss: 1.1819756031036377
Validation loss: 2.237343439491846

Epoch: 6| Step: 12
Training loss: 1.4388608932495117
Validation loss: 2.153897762298584

Epoch: 6| Step: 13
Training loss: 1.5520861148834229
Validation loss: 2.124446238240888

Epoch: 746| Step: 0
Training loss: 1.6789312362670898
Validation loss: 2.159553772659712

Epoch: 6| Step: 1
Training loss: 1.2759010791778564
Validation loss: 2.153842303060716

Epoch: 6| Step: 2
Training loss: 0.7941433787345886
Validation loss: 2.230814121102774

Epoch: 6| Step: 3
Training loss: 1.3437352180480957
Validation loss: 2.200478917808943

Epoch: 6| Step: 4
Training loss: 1.3446846008300781
Validation loss: 2.1238299800503637

Epoch: 6| Step: 5
Training loss: 1.2780416011810303
Validation loss: 2.169434114169049

Epoch: 6| Step: 6
Training loss: 1.4410419464111328
Validation loss: 2.2129792628749723

Epoch: 6| Step: 7
Training loss: 1.019535779953003
Validation loss: 2.131899385042088

Epoch: 6| Step: 8
Training loss: 1.4317930936813354
Validation loss: 2.158963398266864

Epoch: 6| Step: 9
Training loss: 1.454869031906128
Validation loss: 2.2088641569178593

Epoch: 6| Step: 10
Training loss: 0.9407908916473389
Validation loss: 2.189558990540043

Epoch: 6| Step: 11
Training loss: 1.439582347869873
Validation loss: 2.1151214158663185

Epoch: 6| Step: 12
Training loss: 0.8938997983932495
Validation loss: 2.1533878644307456

Epoch: 6| Step: 13
Training loss: 0.495233416557312
Validation loss: 2.240196056263421

Epoch: 747| Step: 0
Training loss: 1.4370979070663452
Validation loss: 2.1775174371657835

Epoch: 6| Step: 1
Training loss: 1.3849613666534424
Validation loss: 2.259749907319264

Epoch: 6| Step: 2
Training loss: 2.0076422691345215
Validation loss: 2.2646104264002975

Epoch: 6| Step: 3
Training loss: 0.9754749536514282
Validation loss: 2.198529315251176

Epoch: 6| Step: 4
Training loss: 0.9255249500274658
Validation loss: 2.183910392945813

Epoch: 6| Step: 5
Training loss: 1.2657499313354492
Validation loss: 2.267927021108648

Epoch: 6| Step: 6
Training loss: 1.449418067932129
Validation loss: 2.190357874798518

Epoch: 6| Step: 7
Training loss: 1.4207044839859009
Validation loss: 2.1546342398530696

Epoch: 6| Step: 8
Training loss: 0.9650103449821472
Validation loss: 2.2599328435877317

Epoch: 6| Step: 9
Training loss: 1.6857116222381592
Validation loss: 2.18491538365682

Epoch: 6| Step: 10
Training loss: 0.7407312393188477
Validation loss: 2.2269944606288785

Epoch: 6| Step: 11
Training loss: 1.4501855373382568
Validation loss: 2.148492941292383

Epoch: 6| Step: 12
Training loss: 1.256248950958252
Validation loss: 2.1952693462371826

Epoch: 6| Step: 13
Training loss: 1.149175763130188
Validation loss: 2.2127312857617616

Epoch: 748| Step: 0
Training loss: 1.0159239768981934
Validation loss: 2.1803129129512335

Epoch: 6| Step: 1
Training loss: 1.3892048597335815
Validation loss: 2.2250863582857194

Epoch: 6| Step: 2
Training loss: 1.0974112749099731
Validation loss: 2.2196157645153742

Epoch: 6| Step: 3
Training loss: 1.426281213760376
Validation loss: 2.1669359540426605

Epoch: 6| Step: 4
Training loss: 1.5198159217834473
Validation loss: 2.1531131857184955

Epoch: 6| Step: 5
Training loss: 1.4492820501327515
Validation loss: 2.1534147634301135

Epoch: 6| Step: 6
Training loss: 1.0627681016921997
Validation loss: 2.2189494538050827

Epoch: 6| Step: 7
Training loss: 1.2887136936187744
Validation loss: 2.150414874476771

Epoch: 6| Step: 8
Training loss: 1.5741679668426514
Validation loss: 2.159902875141431

Epoch: 6| Step: 9
Training loss: 1.131190538406372
Validation loss: 2.1992721788344847

Epoch: 6| Step: 10
Training loss: 1.4346297979354858
Validation loss: 2.1668291566192464

Epoch: 6| Step: 11
Training loss: 0.7526432275772095
Validation loss: 2.174075690648889

Epoch: 6| Step: 12
Training loss: 1.0262829065322876
Validation loss: 2.151484425349902

Epoch: 6| Step: 13
Training loss: 0.9570009708404541
Validation loss: 2.141118798204648

Epoch: 749| Step: 0
Training loss: 1.2180153131484985
Validation loss: 2.172154889311842

Epoch: 6| Step: 1
Training loss: 1.4779963493347168
Validation loss: 2.1864534501106507

Epoch: 6| Step: 2
Training loss: 1.366712212562561
Validation loss: 2.2102122178641697

Epoch: 6| Step: 3
Training loss: 0.9421788454055786
Validation loss: 2.1226676202589467

Epoch: 6| Step: 4
Training loss: 1.6118134260177612
Validation loss: 2.102763419510216

Epoch: 6| Step: 5
Training loss: 1.5590260028839111
Validation loss: 2.199814634938394

Epoch: 6| Step: 6
Training loss: 0.6578348278999329
Validation loss: 2.1353357222772416

Epoch: 6| Step: 7
Training loss: 0.9930567741394043
Validation loss: 2.136999007194273

Epoch: 6| Step: 8
Training loss: 1.3564951419830322
Validation loss: 2.1476784726624847

Epoch: 6| Step: 9
Training loss: 1.7727487087249756
Validation loss: 2.2598749142821117

Epoch: 6| Step: 10
Training loss: 1.122235894203186
Validation loss: 2.171365935315368

Epoch: 6| Step: 11
Training loss: 0.869108259677887
Validation loss: 2.2039198644699587

Epoch: 6| Step: 12
Training loss: 1.5632262229919434
Validation loss: 2.207488836780671

Epoch: 6| Step: 13
Training loss: 1.2722128629684448
Validation loss: 2.244242811715731

Epoch: 750| Step: 0
Training loss: 0.6430234909057617
Validation loss: 2.1078734372251775

Epoch: 6| Step: 1
Training loss: 1.434927225112915
Validation loss: 2.258355056085894

Epoch: 6| Step: 2
Training loss: 1.2543959617614746
Validation loss: 2.1587533309895504

Epoch: 6| Step: 3
Training loss: 1.373162865638733
Validation loss: 2.129772147824687

Epoch: 6| Step: 4
Training loss: 0.8599152565002441
Validation loss: 2.1879685155807005

Epoch: 6| Step: 5
Training loss: 2.1434178352355957
Validation loss: 2.176772097105621

Epoch: 6| Step: 6
Training loss: 0.7757760286331177
Validation loss: 2.2588139708324144

Epoch: 6| Step: 7
Training loss: 1.060854196548462
Validation loss: 2.2079886005770777

Epoch: 6| Step: 8
Training loss: 1.4083120822906494
Validation loss: 2.085846713794175

Epoch: 6| Step: 9
Training loss: 1.3644685745239258
Validation loss: 2.1169683856348835

Epoch: 6| Step: 10
Training loss: 1.0263402462005615
Validation loss: 2.189688303137338

Epoch: 6| Step: 11
Training loss: 1.5980851650238037
Validation loss: 2.1919131381537325

Epoch: 6| Step: 12
Training loss: 0.7885719537734985
Validation loss: 2.141589908189671

Epoch: 6| Step: 13
Training loss: 0.7841724157333374
Validation loss: 2.2170969696455103

Testing loss: 1.9586462762620713
