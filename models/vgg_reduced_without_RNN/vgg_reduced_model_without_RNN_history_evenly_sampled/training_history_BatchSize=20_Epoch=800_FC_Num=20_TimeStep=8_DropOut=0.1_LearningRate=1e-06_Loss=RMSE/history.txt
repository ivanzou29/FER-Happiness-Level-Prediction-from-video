Epoch: 1| Step: 0
Training loss: 6.782238303738037
Validation loss: 6.399626895068188

Epoch: 5| Step: 1
Training loss: 5.616140551881365
Validation loss: 6.394052021012514

Epoch: 5| Step: 2
Training loss: 7.376698443859599
Validation loss: 6.39283985041681

Epoch: 5| Step: 3
Training loss: 5.883198313834265
Validation loss: 6.390508716515262

Epoch: 5| Step: 4
Training loss: 6.469441694789833
Validation loss: 6.386875047540228

Epoch: 5| Step: 5
Training loss: 5.99928947056327
Validation loss: 6.385604396609143

Epoch: 5| Step: 6
Training loss: 6.118841072004822
Validation loss: 6.382937587869342

Epoch: 5| Step: 7
Training loss: 6.594280782009697
Validation loss: 6.381280185118295

Epoch: 5| Step: 8
Training loss: 5.559300220280336
Validation loss: 6.378331239948426

Epoch: 5| Step: 9
Training loss: 7.653096947203843
Validation loss: 6.376019349096934

Epoch: 5| Step: 10
Training loss: 5.831959299204525
Validation loss: 6.373944659449585

Epoch: 2| Step: 0
Training loss: 5.998256747997086
Validation loss: 6.370097022410847

Epoch: 5| Step: 1
Training loss: 6.648079742596054
Validation loss: 6.3697260371282995

Epoch: 5| Step: 2
Training loss: 6.7998004098659885
Validation loss: 6.36423882763689

Epoch: 5| Step: 3
Training loss: 7.391296485252784
Validation loss: 6.362998212239499

Epoch: 5| Step: 4
Training loss: 5.530664790171271
Validation loss: 6.360208749016021

Epoch: 5| Step: 5
Training loss: 6.638503797243444
Validation loss: 6.359261903918418

Epoch: 5| Step: 6
Training loss: 5.625295165053095
Validation loss: 6.355706478961756

Epoch: 5| Step: 7
Training loss: 6.529870576612867
Validation loss: 6.353710463870642

Epoch: 5| Step: 8
Training loss: 6.67233381994159
Validation loss: 6.352727496323243

Epoch: 5| Step: 9
Training loss: 5.917823714188099
Validation loss: 6.347444407522747

Epoch: 5| Step: 10
Training loss: 6.010397485165811
Validation loss: 6.344755754042528

Epoch: 3| Step: 0
Training loss: 6.560749220048663
Validation loss: 6.342789532851484

Epoch: 5| Step: 1
Training loss: 6.380142232331906
Validation loss: 6.342132709745316

Epoch: 5| Step: 2
Training loss: 5.969499630813721
Validation loss: 6.333231626685963

Epoch: 5| Step: 3
Training loss: 6.224979826500005
Validation loss: 6.334060265618853

Epoch: 5| Step: 4
Training loss: 7.502192113317744
Validation loss: 6.3315802297491395

Epoch: 5| Step: 5
Training loss: 6.373488003810535
Validation loss: 6.322359387488147

Epoch: 5| Step: 6
Training loss: 5.54257129752381
Validation loss: 6.32222330101893

Epoch: 5| Step: 7
Training loss: 6.484535601362062
Validation loss: 6.317901561572458

Epoch: 5| Step: 8
Training loss: 6.107994294309418
Validation loss: 6.313874598513774

Epoch: 5| Step: 9
Training loss: 6.292717178591939
Validation loss: 6.3101165407718325

Epoch: 5| Step: 10
Training loss: 6.0300288570086815
Validation loss: 6.305381430016831

Epoch: 4| Step: 0
Training loss: 6.1891427990009875
Validation loss: 6.302670143880811

Epoch: 5| Step: 1
Training loss: 6.31667227765776
Validation loss: 6.29780649444432

Epoch: 5| Step: 2
Training loss: 5.662829539834021
Validation loss: 6.293065640930028

Epoch: 5| Step: 3
Training loss: 6.4416629700775525
Validation loss: 6.290217011404355

Epoch: 5| Step: 4
Training loss: 6.093604139880947
Validation loss: 6.286700691806412

Epoch: 5| Step: 5
Training loss: 7.159304037953782
Validation loss: 6.281715874947046

Epoch: 5| Step: 6
Training loss: 6.8164683691653725
Validation loss: 6.2773134436935285

Epoch: 5| Step: 7
Training loss: 6.746999002848125
Validation loss: 6.272140958019488

Epoch: 5| Step: 8
Training loss: 4.850113558668747
Validation loss: 6.268892855147213

Epoch: 5| Step: 9
Training loss: 6.070888732503785
Validation loss: 6.263394250986363

Epoch: 5| Step: 10
Training loss: 6.599716018578293
Validation loss: 6.260276995032038

Epoch: 5| Step: 0
Training loss: 6.463363099891198
Validation loss: 6.254160727068189

Epoch: 5| Step: 1
Training loss: 6.468597262878283
Validation loss: 6.250693544034014

Epoch: 5| Step: 2
Training loss: 6.0270782432002825
Validation loss: 6.248858167470622

Epoch: 5| Step: 3
Training loss: 6.247989789028836
Validation loss: 6.24052583332617

Epoch: 5| Step: 4
Training loss: 5.724053596997396
Validation loss: 6.232374027818057

Epoch: 5| Step: 5
Training loss: 6.674172499437372
Validation loss: 6.232151770538245

Epoch: 5| Step: 6
Training loss: 6.5950405792306706
Validation loss: 6.22671600620707

Epoch: 5| Step: 7
Training loss: 6.079921584376559
Validation loss: 6.225886271712798

Epoch: 5| Step: 8
Training loss: 6.364775293163986
Validation loss: 6.216214352370267

Epoch: 5| Step: 9
Training loss: 5.590214981558318
Validation loss: 6.211856699776024

Epoch: 5| Step: 10
Training loss: 6.355645213054198
Validation loss: 6.206930646931195

Epoch: 6| Step: 0
Training loss: 4.528554601410267
Validation loss: 6.20129192215103

Epoch: 5| Step: 1
Training loss: 5.722188280780625
Validation loss: 6.200340180884102

Epoch: 5| Step: 2
Training loss: 6.691345250196273
Validation loss: 6.191994630678624

Epoch: 5| Step: 3
Training loss: 5.970128404523969
Validation loss: 6.1873159835928595

Epoch: 5| Step: 4
Training loss: 6.7341909007246255
Validation loss: 6.181688609401364

Epoch: 5| Step: 5
Training loss: 6.440641358941045
Validation loss: 6.180582438274471

Epoch: 5| Step: 6
Training loss: 5.8347183036634656
Validation loss: 6.175771398555199

Epoch: 5| Step: 7
Training loss: 6.222644295833621
Validation loss: 6.1677251847962555

Epoch: 5| Step: 8
Training loss: 5.653068195519435
Validation loss: 6.163190816042145

Epoch: 5| Step: 9
Training loss: 7.977707559293668
Validation loss: 6.156689110318093

Epoch: 5| Step: 10
Training loss: 5.615259850485689
Validation loss: 6.152610134615348

Epoch: 7| Step: 0
Training loss: 6.952109684911834
Validation loss: 6.148337369205818

Epoch: 5| Step: 1
Training loss: 5.691542310273104
Validation loss: 6.142197668360497

Epoch: 5| Step: 2
Training loss: 6.773630669643162
Validation loss: 6.138417481510339

Epoch: 5| Step: 3
Training loss: 6.234282911189389
Validation loss: 6.1313172778567955

Epoch: 5| Step: 4
Training loss: 6.0759019095845
Validation loss: 6.1261144582239115

Epoch: 5| Step: 5
Training loss: 6.0751895827864395
Validation loss: 6.1194715464239415

Epoch: 5| Step: 6
Training loss: 6.436758054179672
Validation loss: 6.117186417076191

Epoch: 5| Step: 7
Training loss: 5.098291350224353
Validation loss: 6.109282755868064

Epoch: 5| Step: 8
Training loss: 5.728790307832298
Validation loss: 6.106172257854875

Epoch: 5| Step: 9
Training loss: 6.14701499139569
Validation loss: 6.09902903647715

Epoch: 5| Step: 10
Training loss: 6.0307756148443765
Validation loss: 6.094594833249914

Epoch: 8| Step: 0
Training loss: 6.111483549078268
Validation loss: 6.088240394797279

Epoch: 5| Step: 1
Training loss: 6.047814269145674
Validation loss: 6.081632560405683

Epoch: 5| Step: 2
Training loss: 5.338156645001826
Validation loss: 6.074528383629442

Epoch: 5| Step: 3
Training loss: 6.92287381029099
Validation loss: 6.070270628932612

Epoch: 5| Step: 4
Training loss: 6.548949284034311
Validation loss: 6.065737212789787

Epoch: 5| Step: 5
Training loss: 5.197733150241848
Validation loss: 6.05861200259135

Epoch: 5| Step: 6
Training loss: 6.518498726936761
Validation loss: 6.052791875986816

Epoch: 5| Step: 7
Training loss: 6.028572713739443
Validation loss: 6.045990586088949

Epoch: 5| Step: 8
Training loss: 6.126485216333834
Validation loss: 6.039552673348727

Epoch: 5| Step: 9
Training loss: 6.07430855540526
Validation loss: 6.034370667043766

Epoch: 5| Step: 10
Training loss: 5.611522210466131
Validation loss: 6.033444363683935

Epoch: 9| Step: 0
Training loss: 6.199587334466366
Validation loss: 6.024503344785462

Epoch: 5| Step: 1
Training loss: 6.359471275856764
Validation loss: 6.016989697326481

Epoch: 5| Step: 2
Training loss: 5.458957122024995
Validation loss: 6.012275389485912

Epoch: 5| Step: 3
Training loss: 6.046134962588897
Validation loss: 6.004785984047315

Epoch: 5| Step: 4
Training loss: 5.864817134156004
Validation loss: 5.9961380715652925

Epoch: 5| Step: 5
Training loss: 6.509782618864707
Validation loss: 5.9868519622798075

Epoch: 5| Step: 6
Training loss: 5.860949983636899
Validation loss: 5.9825942199826

Epoch: 5| Step: 7
Training loss: 5.38235715315975
Validation loss: 5.977547587749552

Epoch: 5| Step: 8
Training loss: 5.359434255378055
Validation loss: 5.969064146001144

Epoch: 5| Step: 9
Training loss: 5.2431803415478795
Validation loss: 5.962434683040592

Epoch: 5| Step: 10
Training loss: 7.6502188458025095
Validation loss: 5.956064386710984

Epoch: 10| Step: 0
Training loss: 5.701076860933167
Validation loss: 5.950380615541156

Epoch: 5| Step: 1
Training loss: 6.543389678624385
Validation loss: 5.942314971904094

Epoch: 5| Step: 2
Training loss: 6.254731485410852
Validation loss: 5.934888886252359

Epoch: 5| Step: 3
Training loss: 5.689713937980092
Validation loss: 5.9300223983405

Epoch: 5| Step: 4
Training loss: 5.133377299595267
Validation loss: 5.918923989739077

Epoch: 5| Step: 5
Training loss: 5.419637696660315
Validation loss: 5.914515643164521

Epoch: 5| Step: 6
Training loss: 6.028544871814788
Validation loss: 5.904465421753917

Epoch: 5| Step: 7
Training loss: 5.933692434066633
Validation loss: 5.896054311753761

Epoch: 5| Step: 8
Training loss: 6.375454157191409
Validation loss: 5.897539544217623

Epoch: 5| Step: 9
Training loss: 6.6427624662013205
Validation loss: 5.883386885215601

Epoch: 5| Step: 10
Training loss: 5.191154020337502
Validation loss: 5.873201463670726

Epoch: 11| Step: 0
Training loss: 6.167236748540535
Validation loss: 5.866945374814595

Epoch: 5| Step: 1
Training loss: 5.0850707456755595
Validation loss: 5.85958382314378

Epoch: 5| Step: 2
Training loss: 6.023917845734469
Validation loss: 5.851115345653431

Epoch: 5| Step: 3
Training loss: 5.743568140249531
Validation loss: 5.846760653662925

Epoch: 5| Step: 4
Training loss: 6.421784114890637
Validation loss: 5.834922794892373

Epoch: 5| Step: 5
Training loss: 5.470447037193868
Validation loss: 5.825837072414769

Epoch: 5| Step: 6
Training loss: 5.294151663826756
Validation loss: 5.8163126176662905

Epoch: 5| Step: 7
Training loss: 5.845853212866104
Validation loss: 5.807107361644013

Epoch: 5| Step: 8
Training loss: 6.327825393177578
Validation loss: 5.800028285267692

Epoch: 5| Step: 9
Training loss: 5.713348672876646
Validation loss: 5.794070727183771

Epoch: 5| Step: 10
Training loss: 6.084030773298196
Validation loss: 5.782204003125013

Epoch: 12| Step: 0
Training loss: 5.82784943530007
Validation loss: 5.774226577264684

Epoch: 5| Step: 1
Training loss: 4.929418589758496
Validation loss: 5.765989022477319

Epoch: 5| Step: 2
Training loss: 6.333425454256104
Validation loss: 5.7557082374523

Epoch: 5| Step: 3
Training loss: 5.298731835710547
Validation loss: 5.744011860895698

Epoch: 5| Step: 4
Training loss: 5.269660648371869
Validation loss: 5.740784624572783

Epoch: 5| Step: 5
Training loss: 5.543974297941446
Validation loss: 5.724429076589052

Epoch: 5| Step: 6
Training loss: 6.5159651486827075
Validation loss: 5.720934651349998

Epoch: 5| Step: 7
Training loss: 5.048593140082868
Validation loss: 5.709843188498639

Epoch: 5| Step: 8
Training loss: 6.0388237238533
Validation loss: 5.701897932792021

Epoch: 5| Step: 9
Training loss: 6.735466180539358
Validation loss: 5.693221567771644

Epoch: 5| Step: 10
Training loss: 5.28656605076782
Validation loss: 5.674782026350339

Epoch: 13| Step: 0
Training loss: 6.217257986845969
Validation loss: 5.664985674630627

Epoch: 5| Step: 1
Training loss: 5.268798053201037
Validation loss: 5.660122454257924

Epoch: 5| Step: 2
Training loss: 6.227154597102974
Validation loss: 5.650097549559018

Epoch: 5| Step: 3
Training loss: 4.786906766864519
Validation loss: 5.641823120148386

Epoch: 5| Step: 4
Training loss: 5.2564269191437285
Validation loss: 5.629697397450299

Epoch: 5| Step: 5
Training loss: 5.1488653766386285
Validation loss: 5.61917330582866

Epoch: 5| Step: 6
Training loss: 5.762873957285427
Validation loss: 5.6084820738241286

Epoch: 5| Step: 7
Training loss: 5.9180693060763865
Validation loss: 5.59483523487724

Epoch: 5| Step: 8
Training loss: 5.8241339305736926
Validation loss: 5.583678950983072

Epoch: 5| Step: 9
Training loss: 5.731560372338218
Validation loss: 5.568763126119216

Epoch: 5| Step: 10
Training loss: 5.7125066644475275
Validation loss: 5.560241177907514

Epoch: 14| Step: 0
Training loss: 5.712346728916863
Validation loss: 5.545181914957171

Epoch: 5| Step: 1
Training loss: 5.204914690210883
Validation loss: 5.533781760353119

Epoch: 5| Step: 2
Training loss: 5.004846322275513
Validation loss: 5.52760314761756

Epoch: 5| Step: 3
Training loss: 5.776515692432755
Validation loss: 5.513775456107951

Epoch: 5| Step: 4
Training loss: 5.902218366057376
Validation loss: 5.5090156413454245

Epoch: 5| Step: 5
Training loss: 4.436783423794563
Validation loss: 5.484543460651654

Epoch: 5| Step: 6
Training loss: 5.699872319983258
Validation loss: 5.469457497017981

Epoch: 5| Step: 7
Training loss: 5.742621289949839
Validation loss: 5.464947738689545

Epoch: 5| Step: 8
Training loss: 6.296164650049831
Validation loss: 5.451425933799109

Epoch: 5| Step: 9
Training loss: 5.411543355010131
Validation loss: 5.441829143798909

Epoch: 5| Step: 10
Training loss: 5.2788280825087135
Validation loss: 5.427361382393917

Epoch: 15| Step: 0
Training loss: 5.724954876451197
Validation loss: 5.415781821903511

Epoch: 5| Step: 1
Training loss: 4.903023989471499
Validation loss: 5.40217185665478

Epoch: 5| Step: 2
Training loss: 5.874187981511885
Validation loss: 5.390479677871125

Epoch: 5| Step: 3
Training loss: 4.392120432468872
Validation loss: 5.375281343492114

Epoch: 5| Step: 4
Training loss: 6.480488469586483
Validation loss: 5.3521477175929135

Epoch: 5| Step: 5
Training loss: 4.902482645567233
Validation loss: 5.340773366475096

Epoch: 5| Step: 6
Training loss: 4.797420507968155
Validation loss: 5.326921667243755

Epoch: 5| Step: 7
Training loss: 5.872045545146712
Validation loss: 5.318694593473724

Epoch: 5| Step: 8
Training loss: 5.09000001259075
Validation loss: 5.29730872156194

Epoch: 5| Step: 9
Training loss: 5.3880593206457785
Validation loss: 5.289564362169593

Epoch: 5| Step: 10
Training loss: 5.393778091658089
Validation loss: 5.2776339289878855

Epoch: 16| Step: 0
Training loss: 4.610628636459441
Validation loss: 5.266677193860247

Epoch: 5| Step: 1
Training loss: 4.895496611141933
Validation loss: 5.24453247119376

Epoch: 5| Step: 2
Training loss: 4.265191024670374
Validation loss: 5.229927894294279

Epoch: 5| Step: 3
Training loss: 5.12576920854305
Validation loss: 5.215576043768569

Epoch: 5| Step: 4
Training loss: 6.021815377194133
Validation loss: 5.206839414233973

Epoch: 5| Step: 5
Training loss: 5.427077026754024
Validation loss: 5.184263150337687

Epoch: 5| Step: 6
Training loss: 5.72408925104302
Validation loss: 5.170715634325921

Epoch: 5| Step: 7
Training loss: 4.2027894066913545
Validation loss: 5.1472875280627175

Epoch: 5| Step: 8
Training loss: 6.248176919168697
Validation loss: 5.135174409995946

Epoch: 5| Step: 9
Training loss: 5.562758364731444
Validation loss: 5.11846405416188

Epoch: 5| Step: 10
Training loss: 4.809931874893166
Validation loss: 5.110563161810948

Epoch: 17| Step: 0
Training loss: 5.509782414510488
Validation loss: 5.090692146488083

Epoch: 5| Step: 1
Training loss: 4.70518149598464
Validation loss: 5.075400798834187

Epoch: 5| Step: 2
Training loss: 4.301528463842143
Validation loss: 5.0571406618284165

Epoch: 5| Step: 3
Training loss: 5.212624981523038
Validation loss: 5.043049214519452

Epoch: 5| Step: 4
Training loss: 4.610934960142578
Validation loss: 5.018222544481861

Epoch: 5| Step: 5
Training loss: 5.108634871792649
Validation loss: 4.999444434361707

Epoch: 5| Step: 6
Training loss: 5.232690705288428
Validation loss: 4.996048307088284

Epoch: 5| Step: 7
Training loss: 5.627037188065238
Validation loss: 4.973744622885711

Epoch: 5| Step: 8
Training loss: 4.332253590580277
Validation loss: 4.949364659121232

Epoch: 5| Step: 9
Training loss: 5.140314805895738
Validation loss: 4.937408502493431

Epoch: 5| Step: 10
Training loss: 5.576986586717574
Validation loss: 4.92603804969009

Epoch: 18| Step: 0
Training loss: 5.191973124970883
Validation loss: 4.903790343008512

Epoch: 5| Step: 1
Training loss: 2.799687340854862
Validation loss: 4.886391352672218

Epoch: 5| Step: 2
Training loss: 5.209069507705613
Validation loss: 4.872456455255328

Epoch: 5| Step: 3
Training loss: 4.376315109958422
Validation loss: 4.839607987643831

Epoch: 5| Step: 4
Training loss: 6.070476200837265
Validation loss: 4.820822206646847

Epoch: 5| Step: 5
Training loss: 3.7725232519364766
Validation loss: 4.809887687772636

Epoch: 5| Step: 6
Training loss: 4.764592293332105
Validation loss: 4.798775535876074

Epoch: 5| Step: 7
Training loss: 5.473887444595798
Validation loss: 4.76714589155077

Epoch: 5| Step: 8
Training loss: 4.770432745539121
Validation loss: 4.751942257460978

Epoch: 5| Step: 9
Training loss: 5.440953352921882
Validation loss: 4.737782976435007

Epoch: 5| Step: 10
Training loss: 4.694104234354866
Validation loss: 4.709758521429788

Epoch: 19| Step: 0
Training loss: 4.024903024962411
Validation loss: 4.69512442544049

Epoch: 5| Step: 1
Training loss: 5.705577584265098
Validation loss: 4.674136726184441

Epoch: 5| Step: 2
Training loss: 4.005225821044736
Validation loss: 4.657299838735295

Epoch: 5| Step: 3
Training loss: 5.5246998424900315
Validation loss: 4.639182988607093

Epoch: 5| Step: 4
Training loss: 3.10137277786786
Validation loss: 4.612339838938216

Epoch: 5| Step: 5
Training loss: 4.209834646207982
Validation loss: 4.582550028132293

Epoch: 5| Step: 6
Training loss: 5.4388261252186885
Validation loss: 4.574783720313616

Epoch: 5| Step: 7
Training loss: 4.370785017931405
Validation loss: 4.555214927855057

Epoch: 5| Step: 8
Training loss: 4.3381685033127475
Validation loss: 4.53777251878805

Epoch: 5| Step: 9
Training loss: 4.986594157550247
Validation loss: 4.509397983032671

Epoch: 5| Step: 10
Training loss: 4.829550128465319
Validation loss: 4.499446550013427

Epoch: 20| Step: 0
Training loss: 3.8248953761334046
Validation loss: 4.479102726580368

Epoch: 5| Step: 1
Training loss: 4.626903863775865
Validation loss: 4.4513858688525385

Epoch: 5| Step: 2
Training loss: 3.687751114910341
Validation loss: 4.430262823535939

Epoch: 5| Step: 3
Training loss: 4.887394724929185
Validation loss: 4.411046743112299

Epoch: 5| Step: 4
Training loss: 5.181141460832564
Validation loss: 4.384433091888827

Epoch: 5| Step: 5
Training loss: 5.205611817444795
Validation loss: 4.360137582244967

Epoch: 5| Step: 6
Training loss: 3.7818441633519098
Validation loss: 4.344299980374321

Epoch: 5| Step: 7
Training loss: 4.330491063065486
Validation loss: 4.318657491659669

Epoch: 5| Step: 8
Training loss: 3.828567790678366
Validation loss: 4.287375439182496

Epoch: 5| Step: 9
Training loss: 4.421765221624832
Validation loss: 4.279119328005155

Epoch: 5| Step: 10
Training loss: 4.5999655680819025
Validation loss: 4.255297973683108

Epoch: 21| Step: 0
Training loss: 4.482978842711531
Validation loss: 4.2298916948363985

Epoch: 5| Step: 1
Training loss: 4.697024625119554
Validation loss: 4.202913097732715

Epoch: 5| Step: 2
Training loss: 4.4089342963621805
Validation loss: 4.182609375120193

Epoch: 5| Step: 3
Training loss: 3.285342035471963
Validation loss: 4.155066780122406

Epoch: 5| Step: 4
Training loss: 3.959640019556406
Validation loss: 4.137826925686446

Epoch: 5| Step: 5
Training loss: 4.211306865395392
Validation loss: 4.115963242487227

Epoch: 5| Step: 6
Training loss: 4.529188015819348
Validation loss: 4.083501330584849

Epoch: 5| Step: 7
Training loss: 3.7190727286185727
Validation loss: 4.069894028722929

Epoch: 5| Step: 8
Training loss: 4.678134972734339
Validation loss: 4.0428432193651815

Epoch: 5| Step: 9
Training loss: 3.6045898159699172
Validation loss: 4.013914930094489

Epoch: 5| Step: 10
Training loss: 4.604126298592239
Validation loss: 3.993718523176883

Epoch: 22| Step: 0
Training loss: 4.23001110246793
Validation loss: 3.9750499634231784

Epoch: 5| Step: 1
Training loss: 4.050156606778152
Validation loss: 3.956142548972998

Epoch: 5| Step: 2
Training loss: 3.890676352533525
Validation loss: 3.9144369667575925

Epoch: 5| Step: 3
Training loss: 3.8232867125041436
Validation loss: 3.9006376143346304

Epoch: 5| Step: 4
Training loss: 3.3599476880588037
Validation loss: 3.8687273662356385

Epoch: 5| Step: 5
Training loss: 4.158978018671178
Validation loss: 3.8666187539772534

Epoch: 5| Step: 6
Training loss: 2.770768549646991
Validation loss: 3.8443607379022207

Epoch: 5| Step: 7
Training loss: 4.18070614959982
Validation loss: 3.816591878047992

Epoch: 5| Step: 8
Training loss: 4.172600500908941
Validation loss: 3.7867959204874695

Epoch: 5| Step: 9
Training loss: 4.588818452636775
Validation loss: 3.773207826137748

Epoch: 5| Step: 10
Training loss: 4.101972635744238
Validation loss: 3.7361781004289982

Epoch: 23| Step: 0
Training loss: 4.000162598166177
Validation loss: 3.7235191911817114

Epoch: 5| Step: 1
Training loss: 3.097591134886627
Validation loss: 3.69579021778635

Epoch: 5| Step: 2
Training loss: 4.188108029987958
Validation loss: 3.6641756589464065

Epoch: 5| Step: 3
Training loss: 3.5090853074739283
Validation loss: 3.6515389925950896

Epoch: 5| Step: 4
Training loss: 3.4755750989838727
Validation loss: 3.618996315801504

Epoch: 5| Step: 5
Training loss: 4.5632724891843655
Validation loss: 3.6035755366696693

Epoch: 5| Step: 6
Training loss: 2.8452389350946117
Validation loss: 3.5531452181807053

Epoch: 5| Step: 7
Training loss: 3.768681089362738
Validation loss: 3.5502682871746756

Epoch: 5| Step: 8
Training loss: 3.901589016104328
Validation loss: 3.546751947451682

Epoch: 5| Step: 9
Training loss: 3.803952500553187
Validation loss: 3.5085209709484135

Epoch: 5| Step: 10
Training loss: 3.8082148749850786
Validation loss: 3.4914826211704586

Epoch: 24| Step: 0
Training loss: 4.012701135270477
Validation loss: 3.4670716456232182

Epoch: 5| Step: 1
Training loss: 4.209675162643263
Validation loss: 3.4403234377168728

Epoch: 5| Step: 2
Training loss: 4.029173796896295
Validation loss: 3.418467243554525

Epoch: 5| Step: 3
Training loss: 3.534342803943349
Validation loss: 3.403544331014311

Epoch: 5| Step: 4
Training loss: 3.0989591881673366
Validation loss: 3.353022557125255

Epoch: 5| Step: 5
Training loss: 3.473123353796763
Validation loss: 3.3402257975572107

Epoch: 5| Step: 6
Training loss: 2.297881133103664
Validation loss: 3.3185242512326543

Epoch: 5| Step: 7
Training loss: 3.5434735494761918
Validation loss: 3.286424474836085

Epoch: 5| Step: 8
Training loss: 2.9819113263788095
Validation loss: 3.2877351894850513

Epoch: 5| Step: 9
Training loss: 3.3375557541208556
Validation loss: 3.2611227698372556

Epoch: 5| Step: 10
Training loss: 3.9526813243024357
Validation loss: 3.236343437123598

Epoch: 25| Step: 0
Training loss: 4.1712801505631845
Validation loss: 3.219209578674592

Epoch: 5| Step: 1
Training loss: 3.929863442336774
Validation loss: 3.212913809378879

Epoch: 5| Step: 2
Training loss: 3.17717506818233
Validation loss: 3.1891485459556925

Epoch: 5| Step: 3
Training loss: 3.765895089874636
Validation loss: 3.1865783523556757

Epoch: 5| Step: 4
Training loss: 3.016893189357424
Validation loss: 3.157213734634709

Epoch: 5| Step: 5
Training loss: 3.4454333225785216
Validation loss: 3.1373667154410962

Epoch: 5| Step: 6
Training loss: 2.215741441515827
Validation loss: 3.094566349377537

Epoch: 5| Step: 7
Training loss: 3.832412747399563
Validation loss: 3.0966532800681956

Epoch: 5| Step: 8
Training loss: 2.8260438965224908
Validation loss: 3.0833809828686265

Epoch: 5| Step: 9
Training loss: 3.0458857568768583
Validation loss: 3.068432937308094

Epoch: 5| Step: 10
Training loss: 2.804002598520509
Validation loss: 3.047397330006261

Epoch: 26| Step: 0
Training loss: 3.611701116698316
Validation loss: 3.046659653728423

Epoch: 5| Step: 1
Training loss: 2.9901189202482503
Validation loss: 3.0127093003157484

Epoch: 5| Step: 2
Training loss: 2.9919723552915896
Validation loss: 3.0175849521282427

Epoch: 5| Step: 3
Training loss: 3.014104904738722
Validation loss: 2.975206117701553

Epoch: 5| Step: 4
Training loss: 3.230400850442715
Validation loss: 2.9687131023434805

Epoch: 5| Step: 5
Training loss: 3.2704729663248884
Validation loss: 2.9517126561034224

Epoch: 5| Step: 6
Training loss: 3.6701150775298603
Validation loss: 2.9432163686776738

Epoch: 5| Step: 7
Training loss: 2.372571808157401
Validation loss: 2.925664585417915

Epoch: 5| Step: 8
Training loss: 3.237865536353594
Validation loss: 2.928160001307184

Epoch: 5| Step: 9
Training loss: 2.8244451534964994
Validation loss: 2.9115105867397544

Epoch: 5| Step: 10
Training loss: 3.861085211638775
Validation loss: 2.8677572979724304

Epoch: 27| Step: 0
Training loss: 3.4838075731746696
Validation loss: 2.8896173593891747

Epoch: 5| Step: 1
Training loss: 3.1306488861129282
Validation loss: 2.879786885892376

Epoch: 5| Step: 2
Training loss: 2.942415061898028
Validation loss: 2.858093288256621

Epoch: 5| Step: 3
Training loss: 2.827179977425537
Validation loss: 2.8539851635218603

Epoch: 5| Step: 4
Training loss: 2.9109351018382834
Validation loss: 2.8550946282762677

Epoch: 5| Step: 5
Training loss: 3.362701614178114
Validation loss: 2.8292481458369863

Epoch: 5| Step: 6
Training loss: 2.923770391777201
Validation loss: 2.82871496038631

Epoch: 5| Step: 7
Training loss: 3.6607631640211578
Validation loss: 2.813665818811426

Epoch: 5| Step: 8
Training loss: 2.9441087119513925
Validation loss: 2.8157557740342214

Epoch: 5| Step: 9
Training loss: 2.5475142911111464
Validation loss: 2.774689603675622

Epoch: 5| Step: 10
Training loss: 3.464265553636274
Validation loss: 2.7758753002780896

Epoch: 28| Step: 0
Training loss: 2.718282023525857
Validation loss: 2.7759439888740163

Epoch: 5| Step: 1
Training loss: 3.1816581599136966
Validation loss: 2.7574613948937716

Epoch: 5| Step: 2
Training loss: 2.988780978435949
Validation loss: 2.7585391704997217

Epoch: 5| Step: 3
Training loss: 3.4979661754370857
Validation loss: 2.7700569159260557

Epoch: 5| Step: 4
Training loss: 2.6625236474361573
Validation loss: 2.753341388103146

Epoch: 5| Step: 5
Training loss: 2.3740269524796584
Validation loss: 2.7388360357908845

Epoch: 5| Step: 6
Training loss: 2.750739258324052
Validation loss: 2.742152549890909

Epoch: 5| Step: 7
Training loss: 3.2005458962204365
Validation loss: 2.738604627449746

Epoch: 5| Step: 8
Training loss: 2.9510212827643456
Validation loss: 2.753125408748462

Epoch: 5| Step: 9
Training loss: 3.117509485886496
Validation loss: 2.709115591422392

Epoch: 5| Step: 10
Training loss: 4.0215465064712275
Validation loss: 2.724391296670866

Epoch: 29| Step: 0
Training loss: 2.3717766018888833
Validation loss: 2.7041947728450006

Epoch: 5| Step: 1
Training loss: 3.063808395221443
Validation loss: 2.7290337035526027

Epoch: 5| Step: 2
Training loss: 2.6804720339064243
Validation loss: 2.7100121216437993

Epoch: 5| Step: 3
Training loss: 3.2008404283776803
Validation loss: 2.7086969199395514

Epoch: 5| Step: 4
Training loss: 2.6075942307559528
Validation loss: 2.697165963721226

Epoch: 5| Step: 5
Training loss: 2.7303208296060313
Validation loss: 2.683943552811202

Epoch: 5| Step: 6
Training loss: 3.871966743767791
Validation loss: 2.703518793937409

Epoch: 5| Step: 7
Training loss: 3.134918342269111
Validation loss: 2.67287329558006

Epoch: 5| Step: 8
Training loss: 3.652778999383204
Validation loss: 2.6931366881544365

Epoch: 5| Step: 9
Training loss: 3.0382417879805823
Validation loss: 2.6925324724347495

Epoch: 5| Step: 10
Training loss: 2.4403213409759994
Validation loss: 2.662695997858819

Epoch: 30| Step: 0
Training loss: 2.853625410971983
Validation loss: 2.6759714816904783

Epoch: 5| Step: 1
Training loss: 2.8807147077023876
Validation loss: 2.6730599991390522

Epoch: 5| Step: 2
Training loss: 3.1594660020469947
Validation loss: 2.690685384818171

Epoch: 5| Step: 3
Training loss: 3.0027068959528718
Validation loss: 2.6552644555289406

Epoch: 5| Step: 4
Training loss: 2.8405663411847777
Validation loss: 2.6700803904982164

Epoch: 5| Step: 5
Training loss: 4.027113100360568
Validation loss: 2.6551416921204707

Epoch: 5| Step: 6
Training loss: 2.4801693232476607
Validation loss: 2.673402347910033

Epoch: 5| Step: 7
Training loss: 2.6113928570709506
Validation loss: 2.674491501189502

Epoch: 5| Step: 8
Training loss: 2.552546079034755
Validation loss: 2.661499983147363

Epoch: 5| Step: 9
Training loss: 3.2376144330041643
Validation loss: 2.6592948617215737

Epoch: 5| Step: 10
Training loss: 3.2103245653675643
Validation loss: 2.649233645483467

Epoch: 31| Step: 0
Training loss: 2.3076827935487296
Validation loss: 2.6596518991260947

Epoch: 5| Step: 1
Training loss: 3.434767868438651
Validation loss: 2.639491804626613

Epoch: 5| Step: 2
Training loss: 2.869581839107477
Validation loss: 2.6816542479239383

Epoch: 5| Step: 3
Training loss: 3.0228083150537524
Validation loss: 2.652144910233836

Epoch: 5| Step: 4
Training loss: 2.9283077805833027
Validation loss: 2.6659566205708134

Epoch: 5| Step: 5
Training loss: 3.088888336504819
Validation loss: 2.665863811923371

Epoch: 5| Step: 6
Training loss: 2.914800719161067
Validation loss: 2.6496895756683547

Epoch: 5| Step: 7
Training loss: 3.383772011365769
Validation loss: 2.668251925451633

Epoch: 5| Step: 8
Training loss: 2.83178238400074
Validation loss: 2.6678284795115723

Epoch: 5| Step: 9
Training loss: 3.2465225101820336
Validation loss: 2.631559895617567

Epoch: 5| Step: 10
Training loss: 2.8893428123904243
Validation loss: 2.6532606315278473

Epoch: 32| Step: 0
Training loss: 2.8616104142961194
Validation loss: 2.646940349682528

Epoch: 5| Step: 1
Training loss: 2.9430295155659225
Validation loss: 2.6599205468853273

Epoch: 5| Step: 2
Training loss: 3.56024111692002
Validation loss: 2.6682988204374527

Epoch: 5| Step: 3
Training loss: 2.3723577558446594
Validation loss: 2.6371691748015604

Epoch: 5| Step: 4
Training loss: 3.214333179668373
Validation loss: 2.65400391210367

Epoch: 5| Step: 5
Training loss: 2.8287145516487646
Validation loss: 2.638079639810243

Epoch: 5| Step: 6
Training loss: 3.077819654162239
Validation loss: 2.6215948451091773

Epoch: 5| Step: 7
Training loss: 2.877316081038056
Validation loss: 2.645620200057647

Epoch: 5| Step: 8
Training loss: 2.965958095612067
Validation loss: 2.632147527958973

Epoch: 5| Step: 9
Training loss: 2.614738206468613
Validation loss: 2.637357713338844

Epoch: 5| Step: 10
Training loss: 3.7777519755012134
Validation loss: 2.659084194455434

Epoch: 33| Step: 0
Training loss: 3.0195896789503758
Validation loss: 2.6427519120047056

Epoch: 5| Step: 1
Training loss: 2.788748587245062
Validation loss: 2.648538342476669

Epoch: 5| Step: 2
Training loss: 2.381639035302436
Validation loss: 2.6604728694014494

Epoch: 5| Step: 3
Training loss: 2.9232132238973203
Validation loss: 2.6456478691130605

Epoch: 5| Step: 4
Training loss: 2.9042144537943355
Validation loss: 2.6575767827568213

Epoch: 5| Step: 5
Training loss: 2.8048518140684466
Validation loss: 2.6627469352073803

Epoch: 5| Step: 6
Training loss: 3.120461945448257
Validation loss: 2.664016434061886

Epoch: 5| Step: 7
Training loss: 3.069507755491579
Validation loss: 2.651129596732412

Epoch: 5| Step: 8
Training loss: 3.72035772367417
Validation loss: 2.644286797559023

Epoch: 5| Step: 9
Training loss: 3.4221823915693026
Validation loss: 2.642483908310626

Epoch: 5| Step: 10
Training loss: 2.868270627861555
Validation loss: 2.654374603174332

Epoch: 34| Step: 0
Training loss: 2.9524488532847113
Validation loss: 2.644657339397443

Epoch: 5| Step: 1
Training loss: 2.8280977700961647
Validation loss: 2.6466233386403353

Epoch: 5| Step: 2
Training loss: 2.4796369945283905
Validation loss: 2.6410273627481335

Epoch: 5| Step: 3
Training loss: 2.5030538979860473
Validation loss: 2.6585120696473172

Epoch: 5| Step: 4
Training loss: 3.0406061875642503
Validation loss: 2.6531365124885458

Epoch: 5| Step: 5
Training loss: 3.3422309063005016
Validation loss: 2.6563115980810386

Epoch: 5| Step: 6
Training loss: 3.147841782923631
Validation loss: 2.656141630467835

Epoch: 5| Step: 7
Training loss: 3.4706549010524954
Validation loss: 2.6570572853872174

Epoch: 5| Step: 8
Training loss: 3.4455562167997553
Validation loss: 2.6549873376684223

Epoch: 5| Step: 9
Training loss: 2.780524084103839
Validation loss: 2.6558476953512526

Epoch: 5| Step: 10
Training loss: 2.959833991318525
Validation loss: 2.653281168511729

Epoch: 35| Step: 0
Training loss: 2.5124022887099393
Validation loss: 2.6602102195916397

Epoch: 5| Step: 1
Training loss: 3.530565853855878
Validation loss: 2.651146665183252

Epoch: 5| Step: 2
Training loss: 2.6673119380194223
Validation loss: 2.6409001059953288

Epoch: 5| Step: 3
Training loss: 2.9154612275438554
Validation loss: 2.6618061094113856

Epoch: 5| Step: 4
Training loss: 2.4996301377404793
Validation loss: 2.66513928066111

Epoch: 5| Step: 5
Training loss: 2.788765258336954
Validation loss: 2.659857536523783

Epoch: 5| Step: 6
Training loss: 2.8899845547906846
Validation loss: 2.6304755813534926

Epoch: 5| Step: 7
Training loss: 3.601926044643213
Validation loss: 2.6583205567220465

Epoch: 5| Step: 8
Training loss: 3.091777905076438
Validation loss: 2.668410320143536

Epoch: 5| Step: 9
Training loss: 2.9555311946135814
Validation loss: 2.6332157595789267

Epoch: 5| Step: 10
Training loss: 3.3711805984431233
Validation loss: 2.645463619380061

Epoch: 36| Step: 0
Training loss: 3.3491815677516037
Validation loss: 2.6564673222065367

Epoch: 5| Step: 1
Training loss: 3.4238398236751078
Validation loss: 2.663435138000724

Epoch: 5| Step: 2
Training loss: 3.1330194951877592
Validation loss: 2.637964912515633

Epoch: 5| Step: 3
Training loss: 2.6973828311677264
Validation loss: 2.651592882394314

Epoch: 5| Step: 4
Training loss: 3.199129618054003
Validation loss: 2.637273118455502

Epoch: 5| Step: 5
Training loss: 3.0001279485756447
Validation loss: 2.6541001443022996

Epoch: 5| Step: 6
Training loss: 2.598234505216552
Validation loss: 2.6547213726404033

Epoch: 5| Step: 7
Training loss: 3.061708932030061
Validation loss: 2.6345567076372354

Epoch: 5| Step: 8
Training loss: 2.8979291033026593
Validation loss: 2.6481218337741095

Epoch: 5| Step: 9
Training loss: 2.630125854004719
Validation loss: 2.652372934052593

Epoch: 5| Step: 10
Training loss: 2.8344685767224087
Validation loss: 2.668296619296009

Epoch: 37| Step: 0
Training loss: 2.9361140451343433
Validation loss: 2.628066820903875

Epoch: 5| Step: 1
Training loss: 3.402205419520369
Validation loss: 2.642991561470868

Epoch: 5| Step: 2
Training loss: 3.2567877678690405
Validation loss: 2.663535151824831

Epoch: 5| Step: 3
Training loss: 3.5443415395320663
Validation loss: 2.652724531510126

Epoch: 5| Step: 4
Training loss: 2.711218475819813
Validation loss: 2.633379245491257

Epoch: 5| Step: 5
Training loss: 3.07693752872301
Validation loss: 2.649524352095407

Epoch: 5| Step: 6
Training loss: 3.1438384815300577
Validation loss: 2.655300084897401

Epoch: 5| Step: 7
Training loss: 2.9738903316243537
Validation loss: 2.637587162302487

Epoch: 5| Step: 8
Training loss: 2.522873003387833
Validation loss: 2.6373833976615764

Epoch: 5| Step: 9
Training loss: 2.4075033713502343
Validation loss: 2.6546985156008476

Epoch: 5| Step: 10
Training loss: 2.8674495899455508
Validation loss: 2.634202119812577

Epoch: 38| Step: 0
Training loss: 2.802452876080193
Validation loss: 2.6585067003410665

Epoch: 5| Step: 1
Training loss: 2.645898823165387
Validation loss: 2.654455446637401

Epoch: 5| Step: 2
Training loss: 3.305232731275961
Validation loss: 2.62837659142638

Epoch: 5| Step: 3
Training loss: 3.8749921244879646
Validation loss: 2.632230235473103

Epoch: 5| Step: 4
Training loss: 2.755070693118122
Validation loss: 2.6482482749631386

Epoch: 5| Step: 5
Training loss: 3.150249253357005
Validation loss: 2.6623219974137173

Epoch: 5| Step: 6
Training loss: 2.559702765375369
Validation loss: 2.6328419920784056

Epoch: 5| Step: 7
Training loss: 2.8069034418853582
Validation loss: 2.6334928388978938

Epoch: 5| Step: 8
Training loss: 3.1549223571993106
Validation loss: 2.6279484626033267

Epoch: 5| Step: 9
Training loss: 2.74825023123734
Validation loss: 2.6232834382968604

Epoch: 5| Step: 10
Training loss: 3.081360796006137
Validation loss: 2.6390624637077127

Epoch: 39| Step: 0
Training loss: 3.4884458291592426
Validation loss: 2.6283032396252786

Epoch: 5| Step: 1
Training loss: 2.7301201550098515
Validation loss: 2.6251022340444745

Epoch: 5| Step: 2
Training loss: 2.8907201802847617
Validation loss: 2.6533817930872545

Epoch: 5| Step: 3
Training loss: 2.7323588758708643
Validation loss: 2.6215285362440492

Epoch: 5| Step: 4
Training loss: 3.4547864964456125
Validation loss: 2.6591323487340732

Epoch: 5| Step: 5
Training loss: 3.2126770505096807
Validation loss: 2.6174365264790262

Epoch: 5| Step: 6
Training loss: 3.005250468804393
Validation loss: 2.647331277557706

Epoch: 5| Step: 7
Training loss: 2.475009371036552
Validation loss: 2.634974978209987

Epoch: 5| Step: 8
Training loss: 3.1122144453205838
Validation loss: 2.635407314813291

Epoch: 5| Step: 9
Training loss: 2.809017908062995
Validation loss: 2.653461046565846

Epoch: 5| Step: 10
Training loss: 2.7760765736707085
Validation loss: 2.6452710435351774

Epoch: 40| Step: 0
Training loss: 2.88253327958415
Validation loss: 2.626521506065278

Epoch: 5| Step: 1
Training loss: 2.8843067297496807
Validation loss: 2.64754948097062

Epoch: 5| Step: 2
Training loss: 3.094984790721493
Validation loss: 2.6287902349075662

Epoch: 5| Step: 3
Training loss: 2.8640741808997
Validation loss: 2.63771371582576

Epoch: 5| Step: 4
Training loss: 2.2788661886570796
Validation loss: 2.65504580665616

Epoch: 5| Step: 5
Training loss: 2.562561034429381
Validation loss: 2.644996950444094

Epoch: 5| Step: 6
Training loss: 3.4645808828730966
Validation loss: 2.655301788970058

Epoch: 5| Step: 7
Training loss: 3.3105354961548548
Validation loss: 2.6530348871813447

Epoch: 5| Step: 8
Training loss: 3.2701306084263657
Validation loss: 2.6583370235202897

Epoch: 5| Step: 9
Training loss: 3.2382772742455237
Validation loss: 2.6320993343595456

Epoch: 5| Step: 10
Training loss: 2.8860961077384495
Validation loss: 2.6305384388670565

Epoch: 41| Step: 0
Training loss: 2.389884684506099
Validation loss: 2.6420849063336616

Epoch: 5| Step: 1
Training loss: 3.061914037582924
Validation loss: 2.6373115454727625

Epoch: 5| Step: 2
Training loss: 2.452808529795567
Validation loss: 2.6424105454916447

Epoch: 5| Step: 3
Training loss: 3.1966854214507596
Validation loss: 2.6414564565986787

Epoch: 5| Step: 4
Training loss: 2.6587163806649556
Validation loss: 2.6224629573946383

Epoch: 5| Step: 5
Training loss: 2.403364557000801
Validation loss: 2.6538956411547767

Epoch: 5| Step: 6
Training loss: 2.9757025970936843
Validation loss: 2.6477611018128626

Epoch: 5| Step: 7
Training loss: 3.3117309253322134
Validation loss: 2.6322037509241536

Epoch: 5| Step: 8
Training loss: 3.3377271939217743
Validation loss: 2.6530517945644654

Epoch: 5| Step: 9
Training loss: 3.35269338028721
Validation loss: 2.6530924705985717

Epoch: 5| Step: 10
Training loss: 3.472075509256672
Validation loss: 2.6228170767260526

Epoch: 42| Step: 0
Training loss: 3.0887674610442533
Validation loss: 2.636941308184896

Epoch: 5| Step: 1
Training loss: 2.6555286998889387
Validation loss: 2.6290676421695776

Epoch: 5| Step: 2
Training loss: 3.745752981396937
Validation loss: 2.6318904362029083

Epoch: 5| Step: 3
Training loss: 2.3738271929506976
Validation loss: 2.6479603540280343

Epoch: 5| Step: 4
Training loss: 3.3814089640764284
Validation loss: 2.6193416359542825

Epoch: 5| Step: 5
Training loss: 2.7121124799409255
Validation loss: 2.633158186421177

Epoch: 5| Step: 6
Training loss: 3.1750184066118763
Validation loss: 2.655550752371325

Epoch: 5| Step: 7
Training loss: 3.4976944823110774
Validation loss: 2.636412301191243

Epoch: 5| Step: 8
Training loss: 3.0710246495382107
Validation loss: 2.6463480041796275

Epoch: 5| Step: 9
Training loss: 2.4717126766491697
Validation loss: 2.642694904561129

Epoch: 5| Step: 10
Training loss: 2.3457557742191995
Validation loss: 2.6363812795848403

Epoch: 43| Step: 0
Training loss: 3.5710354997402747
Validation loss: 2.6627193013401276

Epoch: 5| Step: 1
Training loss: 2.7252473036512392
Validation loss: 2.625379578882221

Epoch: 5| Step: 2
Training loss: 3.212021099567589
Validation loss: 2.6247800069760108

Epoch: 5| Step: 3
Training loss: 2.7895689432363207
Validation loss: 2.662502659868507

Epoch: 5| Step: 4
Training loss: 2.940204430563606
Validation loss: 2.6435551801432307

Epoch: 5| Step: 5
Training loss: 2.896327975906485
Validation loss: 2.637901169734197

Epoch: 5| Step: 6
Training loss: 2.018670435421112
Validation loss: 2.6299338317018686

Epoch: 5| Step: 7
Training loss: 2.934287729478845
Validation loss: 2.6503260860933557

Epoch: 5| Step: 8
Training loss: 3.362107837597316
Validation loss: 2.6282293541704114

Epoch: 5| Step: 9
Training loss: 2.741872220512948
Validation loss: 2.628927565263654

Epoch: 5| Step: 10
Training loss: 3.49382987434376
Validation loss: 2.677840651984963

Epoch: 44| Step: 0
Training loss: 2.822490918100104
Validation loss: 2.614722450463275

Epoch: 5| Step: 1
Training loss: 3.1388034377568186
Validation loss: 2.6426486320364293

Epoch: 5| Step: 2
Training loss: 3.3659281842916795
Validation loss: 2.6535665219324183

Epoch: 5| Step: 3
Training loss: 3.5009396517841562
Validation loss: 2.6401544724389017

Epoch: 5| Step: 4
Training loss: 3.2230927142881667
Validation loss: 2.628286661715623

Epoch: 5| Step: 5
Training loss: 2.9509503466346603
Validation loss: 2.649439321275928

Epoch: 5| Step: 6
Training loss: 2.8636001471779333
Validation loss: 2.6336607249640513

Epoch: 5| Step: 7
Training loss: 2.610614139752565
Validation loss: 2.649012792647819

Epoch: 5| Step: 8
Training loss: 2.7926107110435314
Validation loss: 2.631704693360617

Epoch: 5| Step: 9
Training loss: 2.680796935743802
Validation loss: 2.615124468531978

Epoch: 5| Step: 10
Training loss: 2.690249877016511
Validation loss: 2.5940816078953977

Epoch: 45| Step: 0
Training loss: 3.1602602117575804
Validation loss: 2.6291884911193995

Epoch: 5| Step: 1
Training loss: 2.7779105207727044
Validation loss: 2.6206979114792293

Epoch: 5| Step: 2
Training loss: 3.3266979614600163
Validation loss: 2.645746148413598

Epoch: 5| Step: 3
Training loss: 2.9112941488650406
Validation loss: 2.6387478483282263

Epoch: 5| Step: 4
Training loss: 2.373307176920883
Validation loss: 2.629167788369308

Epoch: 5| Step: 5
Training loss: 3.120367507564323
Validation loss: 2.612368185371624

Epoch: 5| Step: 6
Training loss: 3.352744438710065
Validation loss: 2.6485518394736216

Epoch: 5| Step: 7
Training loss: 3.264942444648928
Validation loss: 2.6221622885611287

Epoch: 5| Step: 8
Training loss: 3.0703721368253962
Validation loss: 2.634425421933776

Epoch: 5| Step: 9
Training loss: 2.984945192840273
Validation loss: 2.6293415822724637

Epoch: 5| Step: 10
Training loss: 2.298156795826413
Validation loss: 2.645546042383681

Epoch: 46| Step: 0
Training loss: 2.518397633631902
Validation loss: 2.6147463207253008

Epoch: 5| Step: 1
Training loss: 3.6918492934360603
Validation loss: 2.6456176079463307

Epoch: 5| Step: 2
Training loss: 2.4319491638780724
Validation loss: 2.6326984429376665

Epoch: 5| Step: 3
Training loss: 2.6810347392852623
Validation loss: 2.6317135365604813

Epoch: 5| Step: 4
Training loss: 2.647707137955198
Validation loss: 2.6334960221607027

Epoch: 5| Step: 5
Training loss: 3.1608225116566278
Validation loss: 2.6324503499136864

Epoch: 5| Step: 6
Training loss: 2.8262867722951412
Validation loss: 2.626016018800945

Epoch: 5| Step: 7
Training loss: 3.07446908476866
Validation loss: 2.6384774664717567

Epoch: 5| Step: 8
Training loss: 2.7932935405831456
Validation loss: 2.6339880143960235

Epoch: 5| Step: 9
Training loss: 3.4424664772634346
Validation loss: 2.641298043614783

Epoch: 5| Step: 10
Training loss: 3.1066310410919535
Validation loss: 2.6387213874193214

Epoch: 47| Step: 0
Training loss: 2.632196643011397
Validation loss: 2.6179444987720415

Epoch: 5| Step: 1
Training loss: 2.828687580277972
Validation loss: 2.62152044102416

Epoch: 5| Step: 2
Training loss: 2.4424895057726097
Validation loss: 2.631453293637746

Epoch: 5| Step: 3
Training loss: 3.3991302836432533
Validation loss: 2.6262562124493134

Epoch: 5| Step: 4
Training loss: 3.1544648211384914
Validation loss: 2.641294886255093

Epoch: 5| Step: 5
Training loss: 2.6481521137606023
Validation loss: 2.607838352664839

Epoch: 5| Step: 6
Training loss: 3.6463512525077775
Validation loss: 2.636750817690675

Epoch: 5| Step: 7
Training loss: 2.65457755900146
Validation loss: 2.6281109007653907

Epoch: 5| Step: 8
Training loss: 3.4336699910210897
Validation loss: 2.642862052808394

Epoch: 5| Step: 9
Training loss: 2.9793097366089403
Validation loss: 2.6609400738734803

Epoch: 5| Step: 10
Training loss: 2.686920103451903
Validation loss: 2.6471992754002915

Epoch: 48| Step: 0
Training loss: 2.7588049640028447
Validation loss: 2.623042777936375

Epoch: 5| Step: 1
Training loss: 3.367163142494558
Validation loss: 2.6272441180280817

Epoch: 5| Step: 2
Training loss: 3.8328078918802557
Validation loss: 2.6336754010769616

Epoch: 5| Step: 3
Training loss: 2.931701944155933
Validation loss: 2.648004465785665

Epoch: 5| Step: 4
Training loss: 2.817352855397493
Validation loss: 2.646028084370403

Epoch: 5| Step: 5
Training loss: 3.2953279309478978
Validation loss: 2.628349140459476

Epoch: 5| Step: 6
Training loss: 2.7043851880700873
Validation loss: 2.6412424578088567

Epoch: 5| Step: 7
Training loss: 3.138840201421314
Validation loss: 2.6120543414454795

Epoch: 5| Step: 8
Training loss: 2.988153911196187
Validation loss: 2.6384723663475858

Epoch: 5| Step: 9
Training loss: 2.3550752782432722
Validation loss: 2.621090139902459

Epoch: 5| Step: 10
Training loss: 2.138386244839014
Validation loss: 2.645997228787337

Epoch: 49| Step: 0
Training loss: 3.1678444194737865
Validation loss: 2.621986413330165

Epoch: 5| Step: 1
Training loss: 2.3366263404156262
Validation loss: 2.634912085454997

Epoch: 5| Step: 2
Training loss: 3.014858484442243
Validation loss: 2.6192104778120786

Epoch: 5| Step: 3
Training loss: 3.4398471101895636
Validation loss: 2.620695801440124

Epoch: 5| Step: 4
Training loss: 3.459766473992924
Validation loss: 2.6327926164194353

Epoch: 5| Step: 5
Training loss: 3.3613135134142764
Validation loss: 2.6237941058146204

Epoch: 5| Step: 6
Training loss: 2.5946487340428317
Validation loss: 2.6417471354583157

Epoch: 5| Step: 7
Training loss: 2.7891995265435656
Validation loss: 2.6236801110622268

Epoch: 5| Step: 8
Training loss: 2.470655357894228
Validation loss: 2.6413011262346813

Epoch: 5| Step: 9
Training loss: 3.4063229334311282
Validation loss: 2.6424624171681015

Epoch: 5| Step: 10
Training loss: 2.3097089471803183
Validation loss: 2.613475576820932

Epoch: 50| Step: 0
Training loss: 2.6594028386273796
Validation loss: 2.63250634340203

Epoch: 5| Step: 1
Training loss: 3.075132978091643
Validation loss: 2.645165203467005

Epoch: 5| Step: 2
Training loss: 3.20868003920524
Validation loss: 2.6399870459449137

Epoch: 5| Step: 3
Training loss: 2.9173356151932204
Validation loss: 2.623322445990613

Epoch: 5| Step: 4
Training loss: 2.522308569488348
Validation loss: 2.6372165632027533

Epoch: 5| Step: 5
Training loss: 2.759034747771474
Validation loss: 2.622969404033779

Epoch: 5| Step: 6
Training loss: 2.923090391282471
Validation loss: 2.6382306796998045

Epoch: 5| Step: 7
Training loss: 2.6723960680686734
Validation loss: 2.620523050287146

Epoch: 5| Step: 8
Training loss: 3.360700478879401
Validation loss: 2.634521857435408

Epoch: 5| Step: 9
Training loss: 3.0080158907998142
Validation loss: 2.6332987051613705

Epoch: 5| Step: 10
Training loss: 3.572661247058062
Validation loss: 2.6418762116417636

Epoch: 51| Step: 0
Training loss: 2.6611091598719496
Validation loss: 2.623793154144508

Epoch: 5| Step: 1
Training loss: 3.3196736517761614
Validation loss: 2.6338950842539406

Epoch: 5| Step: 2
Training loss: 2.8002741100471122
Validation loss: 2.6273982172222086

Epoch: 5| Step: 3
Training loss: 3.121753226684164
Validation loss: 2.6219433691102005

Epoch: 5| Step: 4
Training loss: 2.5669152903175467
Validation loss: 2.6163257623179357

Epoch: 5| Step: 5
Training loss: 3.3482990159712442
Validation loss: 2.619652355525585

Epoch: 5| Step: 6
Training loss: 3.0481683578051286
Validation loss: 2.637601059411847

Epoch: 5| Step: 7
Training loss: 3.2023248929252373
Validation loss: 2.6288459816147376

Epoch: 5| Step: 8
Training loss: 2.9302512478434815
Validation loss: 2.636462939275266

Epoch: 5| Step: 9
Training loss: 2.3797682028979055
Validation loss: 2.6202018069518296

Epoch: 5| Step: 10
Training loss: 3.250825337003528
Validation loss: 2.6215410653029094

Epoch: 52| Step: 0
Training loss: 2.7178453716225826
Validation loss: 2.628992370093004

Epoch: 5| Step: 1
Training loss: 3.22365322528375
Validation loss: 2.6275218924440313

Epoch: 5| Step: 2
Training loss: 3.5060268011466893
Validation loss: 2.6353135343916385

Epoch: 5| Step: 3
Training loss: 2.9697585149649846
Validation loss: 2.627629112473954

Epoch: 5| Step: 4
Training loss: 2.722314361604559
Validation loss: 2.63095718164101

Epoch: 5| Step: 5
Training loss: 2.713718977179338
Validation loss: 2.628637172111141

Epoch: 5| Step: 6
Training loss: 2.2345679139840504
Validation loss: 2.639351773930526

Epoch: 5| Step: 7
Training loss: 3.4967703223221216
Validation loss: 2.635502379796962

Epoch: 5| Step: 8
Training loss: 2.7564037496368274
Validation loss: 2.6383580001053057

Epoch: 5| Step: 9
Training loss: 2.877676671468269
Validation loss: 2.6324339763383775

Epoch: 5| Step: 10
Training loss: 3.2331254544894747
Validation loss: 2.608322394974936

Epoch: 53| Step: 0
Training loss: 2.9687726471689633
Validation loss: 2.6262908863236456

Epoch: 5| Step: 1
Training loss: 3.693480345925082
Validation loss: 2.653274162475953

Epoch: 5| Step: 2
Training loss: 2.9094293083260303
Validation loss: 2.6516921160108016

Epoch: 5| Step: 3
Training loss: 2.689558527147786
Validation loss: 2.624713676998425

Epoch: 5| Step: 4
Training loss: 3.049270705284535
Validation loss: 2.6224948259770633

Epoch: 5| Step: 5
Training loss: 2.8752806153388506
Validation loss: 2.6211434223246335

Epoch: 5| Step: 6
Training loss: 2.7377153320625576
Validation loss: 2.6005293671264353

Epoch: 5| Step: 7
Training loss: 3.0347188391376867
Validation loss: 2.617235105225746

Epoch: 5| Step: 8
Training loss: 3.494498970672373
Validation loss: 2.622893565985654

Epoch: 5| Step: 9
Training loss: 2.5638659488491617
Validation loss: 2.619044032305491

Epoch: 5| Step: 10
Training loss: 2.3843462901055577
Validation loss: 2.5964670628932884

Epoch: 54| Step: 0
Training loss: 2.9192525753615226
Validation loss: 2.609076287513239

Epoch: 5| Step: 1
Training loss: 2.822980300542708
Validation loss: 2.61753837720213

Epoch: 5| Step: 2
Training loss: 3.406939935368037
Validation loss: 2.6148597353183907

Epoch: 5| Step: 3
Training loss: 3.228993827542206
Validation loss: 2.6181588356589596

Epoch: 5| Step: 4
Training loss: 3.769710366534622
Validation loss: 2.6213048953781652

Epoch: 5| Step: 5
Training loss: 2.7693389266240303
Validation loss: 2.6271351911705487

Epoch: 5| Step: 6
Training loss: 2.5646499360704538
Validation loss: 2.624200842838695

Epoch: 5| Step: 7
Training loss: 2.928732591773481
Validation loss: 2.613068426144206

Epoch: 5| Step: 8
Training loss: 2.990413129709728
Validation loss: 2.6214507504933775

Epoch: 5| Step: 9
Training loss: 2.034471744516458
Validation loss: 2.630225877064706

Epoch: 5| Step: 10
Training loss: 2.905713759962255
Validation loss: 2.613643451977593

Epoch: 55| Step: 0
Training loss: 3.381174726230053
Validation loss: 2.624170048109515

Epoch: 5| Step: 1
Training loss: 2.9085849693180146
Validation loss: 2.6415266650551974

Epoch: 5| Step: 2
Training loss: 2.4885500009705095
Validation loss: 2.6316832710289946

Epoch: 5| Step: 3
Training loss: 2.8884224413205084
Validation loss: 2.6078355902873347

Epoch: 5| Step: 4
Training loss: 3.2206203618933253
Validation loss: 2.6334925244653036

Epoch: 5| Step: 5
Training loss: 3.4782196553006854
Validation loss: 2.625712928313076

Epoch: 5| Step: 6
Training loss: 2.2295786990784876
Validation loss: 2.634621090844307

Epoch: 5| Step: 7
Training loss: 3.208085996003141
Validation loss: 2.6195207466057875

Epoch: 5| Step: 8
Training loss: 2.4294813258773704
Validation loss: 2.6176361752398973

Epoch: 5| Step: 9
Training loss: 3.3515297770292114
Validation loss: 2.610821968292864

Epoch: 5| Step: 10
Training loss: 2.804710366838581
Validation loss: 2.6450209342146254

Epoch: 56| Step: 0
Training loss: 2.5881370571051843
Validation loss: 2.6220103905222403

Epoch: 5| Step: 1
Training loss: 2.9494788857231478
Validation loss: 2.6449223274934757

Epoch: 5| Step: 2
Training loss: 3.37589195615526
Validation loss: 2.6137146561784315

Epoch: 5| Step: 3
Training loss: 3.3841132995360366
Validation loss: 2.6177871029494573

Epoch: 5| Step: 4
Training loss: 3.7918079615385984
Validation loss: 2.6462688350856323

Epoch: 5| Step: 5
Training loss: 2.370974391591414
Validation loss: 2.6103880828197816

Epoch: 5| Step: 6
Training loss: 2.9198248703577363
Validation loss: 2.6119620349681965

Epoch: 5| Step: 7
Training loss: 3.308949709212968
Validation loss: 2.6372528174572007

Epoch: 5| Step: 8
Training loss: 2.5477994399553063
Validation loss: 2.5948968578937053

Epoch: 5| Step: 9
Training loss: 2.081990941213932
Validation loss: 2.6203635669645715

Epoch: 5| Step: 10
Training loss: 3.077441764175181
Validation loss: 2.626573890643328

Epoch: 57| Step: 0
Training loss: 2.600272560505151
Validation loss: 2.642933282679094

Epoch: 5| Step: 1
Training loss: 2.6085857179877374
Validation loss: 2.605718772465567

Epoch: 5| Step: 2
Training loss: 2.698269844258595
Validation loss: 2.604263662849402

Epoch: 5| Step: 3
Training loss: 3.48807537842591
Validation loss: 2.6286982176827243

Epoch: 5| Step: 4
Training loss: 3.058038536921721
Validation loss: 2.625586048263614

Epoch: 5| Step: 5
Training loss: 2.3835878205202183
Validation loss: 2.621112910526588

Epoch: 5| Step: 6
Training loss: 3.0380562732098055
Validation loss: 2.6406802328019707

Epoch: 5| Step: 7
Training loss: 2.8948032184455905
Validation loss: 2.6246630671656765

Epoch: 5| Step: 8
Training loss: 2.804351361461811
Validation loss: 2.622604745175869

Epoch: 5| Step: 9
Training loss: 3.2572747022192914
Validation loss: 2.6395099380438753

Epoch: 5| Step: 10
Training loss: 3.4809880923467778
Validation loss: 2.6063734690513227

Epoch: 58| Step: 0
Training loss: 2.884375006612693
Validation loss: 2.620816863286848

Epoch: 5| Step: 1
Training loss: 2.992893384732896
Validation loss: 2.6287796040467604

Epoch: 5| Step: 2
Training loss: 3.207263933445724
Validation loss: 2.623135603396198

Epoch: 5| Step: 3
Training loss: 2.8975387783928
Validation loss: 2.626679251049727

Epoch: 5| Step: 4
Training loss: 2.25817012924427
Validation loss: 2.635365769498207

Epoch: 5| Step: 5
Training loss: 2.901680584355047
Validation loss: 2.606993155717512

Epoch: 5| Step: 6
Training loss: 3.1522216773239036
Validation loss: 2.6080375629958694

Epoch: 5| Step: 7
Training loss: 3.068094709553398
Validation loss: 2.613694559633159

Epoch: 5| Step: 8
Training loss: 2.462051188044487
Validation loss: 2.6016746703013984

Epoch: 5| Step: 9
Training loss: 3.032105944410565
Validation loss: 2.628382863050345

Epoch: 5| Step: 10
Training loss: 3.4160228836043522
Validation loss: 2.6452041729298075

Epoch: 59| Step: 0
Training loss: 2.852424721154961
Validation loss: 2.61674502775125

Epoch: 5| Step: 1
Training loss: 2.690399291598941
Validation loss: 2.6252656793407287

Epoch: 5| Step: 2
Training loss: 2.467829472306043
Validation loss: 2.615265467077672

Epoch: 5| Step: 3
Training loss: 3.365907359343773
Validation loss: 2.6237809191926655

Epoch: 5| Step: 4
Training loss: 2.47747824311928
Validation loss: 2.627999109643726

Epoch: 5| Step: 5
Training loss: 3.1213809610497574
Validation loss: 2.628071809531128

Epoch: 5| Step: 6
Training loss: 3.2911926765245436
Validation loss: 2.5875292448959537

Epoch: 5| Step: 7
Training loss: 3.19549470489259
Validation loss: 2.612947410507166

Epoch: 5| Step: 8
Training loss: 2.4760273737341754
Validation loss: 2.6068906599266723

Epoch: 5| Step: 9
Training loss: 3.4185236714709504
Validation loss: 2.6309470574635285

Epoch: 5| Step: 10
Training loss: 2.959753922208618
Validation loss: 2.604145128386654

Epoch: 60| Step: 0
Training loss: 2.7607577323138592
Validation loss: 2.614025956833128

Epoch: 5| Step: 1
Training loss: 1.660687242747742
Validation loss: 2.611055520353987

Epoch: 5| Step: 2
Training loss: 3.606971898539753
Validation loss: 2.593650269373216

Epoch: 5| Step: 3
Training loss: 2.710263918873719
Validation loss: 2.61345959837815

Epoch: 5| Step: 4
Training loss: 3.001084926248857
Validation loss: 2.6106809408872174

Epoch: 5| Step: 5
Training loss: 3.079213526003142
Validation loss: 2.617462897959551

Epoch: 5| Step: 6
Training loss: 3.1039762161169544
Validation loss: 2.610399650853031

Epoch: 5| Step: 7
Training loss: 3.3556598790971246
Validation loss: 2.621229030688723

Epoch: 5| Step: 8
Training loss: 2.8221786960823105
Validation loss: 2.611171770653045

Epoch: 5| Step: 9
Training loss: 2.8312477027597436
Validation loss: 2.6018490236752148

Epoch: 5| Step: 10
Training loss: 3.0766686416845572
Validation loss: 2.588230657018819

Epoch: 61| Step: 0
Training loss: 2.60137095619706
Validation loss: 2.6320157402684505

Epoch: 5| Step: 1
Training loss: 2.6439524796236515
Validation loss: 2.61901514248688

Epoch: 5| Step: 2
Training loss: 3.028450685983525
Validation loss: 2.6004871709483157

Epoch: 5| Step: 3
Training loss: 2.8210482073657035
Validation loss: 2.625204395749195

Epoch: 5| Step: 4
Training loss: 3.3913850415877547
Validation loss: 2.6282259918782627

Epoch: 5| Step: 5
Training loss: 2.7985359247003387
Validation loss: 2.6216360590859016

Epoch: 5| Step: 6
Training loss: 3.243061876166041
Validation loss: 2.6183901716466655

Epoch: 5| Step: 7
Training loss: 2.948408124056678
Validation loss: 2.617476142855831

Epoch: 5| Step: 8
Training loss: 3.7988463256713736
Validation loss: 2.606459564497182

Epoch: 5| Step: 9
Training loss: 2.4187150583035115
Validation loss: 2.6051849054666216

Epoch: 5| Step: 10
Training loss: 2.54794186205089
Validation loss: 2.6250957885625628

Epoch: 62| Step: 0
Training loss: 3.635188287740967
Validation loss: 2.6143974545680924

Epoch: 5| Step: 1
Training loss: 3.0521107608400366
Validation loss: 2.608332655129896

Epoch: 5| Step: 2
Training loss: 3.8050130904545223
Validation loss: 2.611758316216063

Epoch: 5| Step: 3
Training loss: 2.9837789689293013
Validation loss: 2.6037881585144937

Epoch: 5| Step: 4
Training loss: 2.2312591808995728
Validation loss: 2.609040939741541

Epoch: 5| Step: 5
Training loss: 2.7883671767359806
Validation loss: 2.6164889837738534

Epoch: 5| Step: 6
Training loss: 2.62812909319873
Validation loss: 2.60750440917265

Epoch: 5| Step: 7
Training loss: 2.0406046330368808
Validation loss: 2.6414344577494098

Epoch: 5| Step: 8
Training loss: 3.0154633948157343
Validation loss: 2.61433467377903

Epoch: 5| Step: 9
Training loss: 2.871885686113569
Validation loss: 2.6073135447492004

Epoch: 5| Step: 10
Training loss: 3.1160286874295284
Validation loss: 2.6050139560340972

Epoch: 63| Step: 0
Training loss: 3.173774038000675
Validation loss: 2.6231104724914145

Epoch: 5| Step: 1
Training loss: 2.5910377569359024
Validation loss: 2.6169815112202723

Epoch: 5| Step: 2
Training loss: 3.0330853755617855
Validation loss: 2.5863101835539073

Epoch: 5| Step: 3
Training loss: 2.5711414426624355
Validation loss: 2.6049450471934765

Epoch: 5| Step: 4
Training loss: 2.8194656580067945
Validation loss: 2.611833156917799

Epoch: 5| Step: 5
Training loss: 2.6850153060562065
Validation loss: 2.6110468850505635

Epoch: 5| Step: 6
Training loss: 2.464104833342061
Validation loss: 2.603390743373163

Epoch: 5| Step: 7
Training loss: 2.847463677152036
Validation loss: 2.6172278763398196

Epoch: 5| Step: 8
Training loss: 3.4868225259998282
Validation loss: 2.5986051134263195

Epoch: 5| Step: 9
Training loss: 3.5429738642982658
Validation loss: 2.616933923912952

Epoch: 5| Step: 10
Training loss: 3.137912470844688
Validation loss: 2.6177941569526637

Epoch: 64| Step: 0
Training loss: 3.181249136634215
Validation loss: 2.596879336736024

Epoch: 5| Step: 1
Training loss: 2.6797051165032273
Validation loss: 2.59523617840026

Epoch: 5| Step: 2
Training loss: 3.1937029452506134
Validation loss: 2.6122855183056477

Epoch: 5| Step: 3
Training loss: 2.762631364003392
Validation loss: 2.61759648489292

Epoch: 5| Step: 4
Training loss: 2.3676175271402635
Validation loss: 2.6127724191620936

Epoch: 5| Step: 5
Training loss: 2.6558609621469924
Validation loss: 2.6224875793300537

Epoch: 5| Step: 6
Training loss: 3.2864665390532877
Validation loss: 2.6332332469268676

Epoch: 5| Step: 7
Training loss: 3.705917657422214
Validation loss: 2.61521246583241

Epoch: 5| Step: 8
Training loss: 3.429026894175519
Validation loss: 2.6182920571193447

Epoch: 5| Step: 9
Training loss: 2.268243578672701
Validation loss: 2.624482511578699

Epoch: 5| Step: 10
Training loss: 2.446465071325328
Validation loss: 2.614128008105022

Epoch: 65| Step: 0
Training loss: 3.0988182399509867
Validation loss: 2.608971386537218

Epoch: 5| Step: 1
Training loss: 3.1336340076844027
Validation loss: 2.6086367321137485

Epoch: 5| Step: 2
Training loss: 3.4044636933363828
Validation loss: 2.626620162330238

Epoch: 5| Step: 3
Training loss: 2.397870422323913
Validation loss: 2.5999142710748435

Epoch: 5| Step: 4
Training loss: 2.6884903081230065
Validation loss: 2.6076025147141806

Epoch: 5| Step: 5
Training loss: 2.823537910673029
Validation loss: 2.6201350831984516

Epoch: 5| Step: 6
Training loss: 2.882535926350133
Validation loss: 2.625955637220963

Epoch: 5| Step: 7
Training loss: 3.1392757117404853
Validation loss: 2.6125191063488176

Epoch: 5| Step: 8
Training loss: 3.4216573288894336
Validation loss: 2.6216014106781116

Epoch: 5| Step: 9
Training loss: 2.672635867998137
Validation loss: 2.6118710974137764

Epoch: 5| Step: 10
Training loss: 2.5968538579527745
Validation loss: 2.599222316343924

Epoch: 66| Step: 0
Training loss: 2.8545424684995973
Validation loss: 2.594956157223153

Epoch: 5| Step: 1
Training loss: 2.850125721617964
Validation loss: 2.6025738090509427

Epoch: 5| Step: 2
Training loss: 2.9924266908823642
Validation loss: 2.63410755486808

Epoch: 5| Step: 3
Training loss: 3.7830460751637065
Validation loss: 2.5953258970939097

Epoch: 5| Step: 4
Training loss: 2.8371784448127264
Validation loss: 2.6081730171332698

Epoch: 5| Step: 5
Training loss: 3.0387777082277627
Validation loss: 2.603648713480813

Epoch: 5| Step: 6
Training loss: 2.5397275083161586
Validation loss: 2.605427429842725

Epoch: 5| Step: 7
Training loss: 2.5967553433647645
Validation loss: 2.6200028889294225

Epoch: 5| Step: 8
Training loss: 2.3005464236461464
Validation loss: 2.596943315426508

Epoch: 5| Step: 9
Training loss: 3.147318676731874
Validation loss: 2.6404805642378046

Epoch: 5| Step: 10
Training loss: 3.2817598945803863
Validation loss: 2.618732388368382

Epoch: 67| Step: 0
Training loss: 2.985959256670311
Validation loss: 2.627795791740561

Epoch: 5| Step: 1
Training loss: 3.4048523441514513
Validation loss: 2.5951620015187777

Epoch: 5| Step: 2
Training loss: 2.8637418493573654
Validation loss: 2.6028868538292094

Epoch: 5| Step: 3
Training loss: 3.351659528843889
Validation loss: 2.6141210785634375

Epoch: 5| Step: 4
Training loss: 2.7201594941275835
Validation loss: 2.6179228331095468

Epoch: 5| Step: 5
Training loss: 2.7611885479106704
Validation loss: 2.5994520771164766

Epoch: 5| Step: 6
Training loss: 3.4577045711699053
Validation loss: 2.626688894894367

Epoch: 5| Step: 7
Training loss: 1.8732510356994396
Validation loss: 2.6283493472401447

Epoch: 5| Step: 8
Training loss: 2.8502028476738603
Validation loss: 2.6079462187608407

Epoch: 5| Step: 9
Training loss: 2.793656783287603
Validation loss: 2.615326046456071

Epoch: 5| Step: 10
Training loss: 3.0729174252956337
Validation loss: 2.6058481949320575

Epoch: 68| Step: 0
Training loss: 2.7507475790505285
Validation loss: 2.6021010294067133

Epoch: 5| Step: 1
Training loss: 3.0482348415285996
Validation loss: 2.604601406767056

Epoch: 5| Step: 2
Training loss: 3.1084200672256403
Validation loss: 2.6135256548583854

Epoch: 5| Step: 3
Training loss: 3.274724083845444
Validation loss: 2.6180311263354286

Epoch: 5| Step: 4
Training loss: 2.636018696853251
Validation loss: 2.6337203478066122

Epoch: 5| Step: 5
Training loss: 3.5619032510579873
Validation loss: 2.602914697426416

Epoch: 5| Step: 6
Training loss: 2.823497126023046
Validation loss: 2.6117735899928203

Epoch: 5| Step: 7
Training loss: 3.1464937708387026
Validation loss: 2.6109694340859355

Epoch: 5| Step: 8
Training loss: 2.8895144417014547
Validation loss: 2.6015265988059753

Epoch: 5| Step: 9
Training loss: 2.316074701418866
Validation loss: 2.5970421782540294

Epoch: 5| Step: 10
Training loss: 2.417205838095031
Validation loss: 2.592609174891523

Epoch: 69| Step: 0
Training loss: 2.958998556071629
Validation loss: 2.605354458225946

Epoch: 5| Step: 1
Training loss: 2.4978217171850083
Validation loss: 2.6102735526942067

Epoch: 5| Step: 2
Training loss: 3.027014378503752
Validation loss: 2.6255571054473577

Epoch: 5| Step: 3
Training loss: 2.11365509957132
Validation loss: 2.6233375053626933

Epoch: 5| Step: 4
Training loss: 2.873367343562644
Validation loss: 2.605177625430613

Epoch: 5| Step: 5
Training loss: 3.5175931719469262
Validation loss: 2.6197651359607383

Epoch: 5| Step: 6
Training loss: 3.6360857911600863
Validation loss: 2.608384546481327

Epoch: 5| Step: 7
Training loss: 2.6713705200083493
Validation loss: 2.5925486075725894

Epoch: 5| Step: 8
Training loss: 3.110082497928455
Validation loss: 2.5987621814265687

Epoch: 5| Step: 9
Training loss: 3.0873741958254475
Validation loss: 2.6194202247275093

Epoch: 5| Step: 10
Training loss: 2.5311644739843264
Validation loss: 2.60364139764109

Epoch: 70| Step: 0
Training loss: 3.2738026708886228
Validation loss: 2.5827685300069967

Epoch: 5| Step: 1
Training loss: 2.9089451260234904
Validation loss: 2.6112577294935404

Epoch: 5| Step: 2
Training loss: 2.2590726615834473
Validation loss: 2.602569399020837

Epoch: 5| Step: 3
Training loss: 3.380166796569636
Validation loss: 2.609709630481156

Epoch: 5| Step: 4
Training loss: 2.9314574731471232
Validation loss: 2.592229032230431

Epoch: 5| Step: 5
Training loss: 2.7606140258101117
Validation loss: 2.611039521210416

Epoch: 5| Step: 6
Training loss: 3.24831596172836
Validation loss: 2.6087061340564475

Epoch: 5| Step: 7
Training loss: 3.6044211472357977
Validation loss: 2.6089095747589384

Epoch: 5| Step: 8
Training loss: 2.0485779179471986
Validation loss: 2.604626098139787

Epoch: 5| Step: 9
Training loss: 2.9220130602200736
Validation loss: 2.6102633463288463

Epoch: 5| Step: 10
Training loss: 2.6660520222732957
Validation loss: 2.6187631736191226

Epoch: 71| Step: 0
Training loss: 2.771994029761156
Validation loss: 2.6094093588215723

Epoch: 5| Step: 1
Training loss: 3.5497826576861127
Validation loss: 2.60078211877354

Epoch: 5| Step: 2
Training loss: 3.067192064418885
Validation loss: 2.611444601715628

Epoch: 5| Step: 3
Training loss: 2.7117214333650925
Validation loss: 2.613197872117429

Epoch: 5| Step: 4
Training loss: 2.6533222893464297
Validation loss: 2.6240743400593853

Epoch: 5| Step: 5
Training loss: 3.1466512227352914
Validation loss: 2.6205321082908974

Epoch: 5| Step: 6
Training loss: 3.122816161985072
Validation loss: 2.6118410328502217

Epoch: 5| Step: 7
Training loss: 2.4214140422592525
Validation loss: 2.609961508817277

Epoch: 5| Step: 8
Training loss: 3.5315791964053984
Validation loss: 2.610031720247915

Epoch: 5| Step: 9
Training loss: 2.517992788987746
Validation loss: 2.6221857469559535

Epoch: 5| Step: 10
Training loss: 2.4793280434110536
Validation loss: 2.612445763654325

Epoch: 72| Step: 0
Training loss: 2.587255044298031
Validation loss: 2.61713054792761

Epoch: 5| Step: 1
Training loss: 2.962954033290688
Validation loss: 2.6083698248791483

Epoch: 5| Step: 2
Training loss: 3.2900619619268374
Validation loss: 2.6070101787917968

Epoch: 5| Step: 3
Training loss: 2.897132271182749
Validation loss: 2.588721461322451

Epoch: 5| Step: 4
Training loss: 2.789246454236467
Validation loss: 2.5833983146865123

Epoch: 5| Step: 5
Training loss: 2.8743849386668385
Validation loss: 2.6044585611151034

Epoch: 5| Step: 6
Training loss: 3.0318701984632503
Validation loss: 2.5943722414045087

Epoch: 5| Step: 7
Training loss: 3.4476013193048525
Validation loss: 2.5957107200009286

Epoch: 5| Step: 8
Training loss: 1.7896880010061627
Validation loss: 2.5968931871224052

Epoch: 5| Step: 9
Training loss: 3.3898556447309462
Validation loss: 2.5880574218095127

Epoch: 5| Step: 10
Training loss: 2.7662897550309262
Validation loss: 2.5949919635892402

Epoch: 73| Step: 0
Training loss: 2.3457564856870423
Validation loss: 2.6120959886109913

Epoch: 5| Step: 1
Training loss: 3.378720952063313
Validation loss: 2.5892631802966766

Epoch: 5| Step: 2
Training loss: 2.789596805630193
Validation loss: 2.6017964812271335

Epoch: 5| Step: 3
Training loss: 2.8075975712629946
Validation loss: 2.6036077366364

Epoch: 5| Step: 4
Training loss: 3.4827988142974298
Validation loss: 2.61940425807947

Epoch: 5| Step: 5
Training loss: 3.248331375186722
Validation loss: 2.6059903338290686

Epoch: 5| Step: 6
Training loss: 2.828744388428102
Validation loss: 2.6023863776586325

Epoch: 5| Step: 7
Training loss: 3.2053457609825386
Validation loss: 2.5901665800099805

Epoch: 5| Step: 8
Training loss: 2.621139412267589
Validation loss: 2.613707671594512

Epoch: 5| Step: 9
Training loss: 3.0006218901421247
Validation loss: 2.591576040890179

Epoch: 5| Step: 10
Training loss: 2.36971387351209
Validation loss: 2.5953675618012793

Epoch: 74| Step: 0
Training loss: 2.443321709529329
Validation loss: 2.608514301056101

Epoch: 5| Step: 1
Training loss: 3.4402263580190735
Validation loss: 2.617446691161373

Epoch: 5| Step: 2
Training loss: 2.9559699992514488
Validation loss: 2.588462801813255

Epoch: 5| Step: 3
Training loss: 3.353490030660921
Validation loss: 2.6110412414053332

Epoch: 5| Step: 4
Training loss: 2.9432048187481854
Validation loss: 2.6062359280069987

Epoch: 5| Step: 5
Training loss: 2.9386297447818266
Validation loss: 2.6140497226342867

Epoch: 5| Step: 6
Training loss: 2.505879545539436
Validation loss: 2.590695562066829

Epoch: 5| Step: 7
Training loss: 2.673249276077171
Validation loss: 2.6360816050245726

Epoch: 5| Step: 8
Training loss: 2.557136132093691
Validation loss: 2.598532627508254

Epoch: 5| Step: 9
Training loss: 2.6819922320191543
Validation loss: 2.596933710184312

Epoch: 5| Step: 10
Training loss: 3.6678690383894406
Validation loss: 2.6059206864136133

Epoch: 75| Step: 0
Training loss: 1.9749799582514742
Validation loss: 2.608081216142442

Epoch: 5| Step: 1
Training loss: 2.3603709562970323
Validation loss: 2.607002921553456

Epoch: 5| Step: 2
Training loss: 2.9892222400182504
Validation loss: 2.5844892766396357

Epoch: 5| Step: 3
Training loss: 2.8959186642010457
Validation loss: 2.6067214037833986

Epoch: 5| Step: 4
Training loss: 3.2819769644385044
Validation loss: 2.6217664842521926

Epoch: 5| Step: 5
Training loss: 3.046477932610751
Validation loss: 2.6071786619964747

Epoch: 5| Step: 6
Training loss: 2.3919528439954556
Validation loss: 2.592906312090935

Epoch: 5| Step: 7
Training loss: 3.0474442952723657
Validation loss: 2.6164251969188626

Epoch: 5| Step: 8
Training loss: 3.5838688886366223
Validation loss: 2.6042836077285467

Epoch: 5| Step: 9
Training loss: 3.110999061822213
Validation loss: 2.6163286470328204

Epoch: 5| Step: 10
Training loss: 3.0974876867854695
Validation loss: 2.6025994692297627

Epoch: 76| Step: 0
Training loss: 2.868775803526807
Validation loss: 2.6158889284308744

Epoch: 5| Step: 1
Training loss: 2.568183086422571
Validation loss: 2.6177540988149364

Epoch: 5| Step: 2
Training loss: 3.5777386452592843
Validation loss: 2.6168528715583537

Epoch: 5| Step: 3
Training loss: 3.409365008345665
Validation loss: 2.5844401973043487

Epoch: 5| Step: 4
Training loss: 3.090990473445946
Validation loss: 2.6014066900360837

Epoch: 5| Step: 5
Training loss: 3.251105780653264
Validation loss: 2.5924784368669878

Epoch: 5| Step: 6
Training loss: 2.824714585461485
Validation loss: 2.6080467631517825

Epoch: 5| Step: 7
Training loss: 2.8580254043186804
Validation loss: 2.608551746344685

Epoch: 5| Step: 8
Training loss: 2.896811962573475
Validation loss: 2.612536938302094

Epoch: 5| Step: 9
Training loss: 2.1215218521204675
Validation loss: 2.599159414607826

Epoch: 5| Step: 10
Training loss: 2.4083614250929473
Validation loss: 2.596776942279237

Epoch: 77| Step: 0
Training loss: 2.904957966065419
Validation loss: 2.5994205034735947

Epoch: 5| Step: 1
Training loss: 2.776228497047057
Validation loss: 2.591172401975098

Epoch: 5| Step: 2
Training loss: 2.3399353518888693
Validation loss: 2.6042729221119316

Epoch: 5| Step: 3
Training loss: 2.8030088708950176
Validation loss: 2.5880134581539433

Epoch: 5| Step: 4
Training loss: 3.3552587085926646
Validation loss: 2.6058451835100818

Epoch: 5| Step: 5
Training loss: 3.0428538857793743
Validation loss: 2.592444090985801

Epoch: 5| Step: 6
Training loss: 2.7867188423997304
Validation loss: 2.590509580048924

Epoch: 5| Step: 7
Training loss: 2.7791833807477446
Validation loss: 2.5997260306281973

Epoch: 5| Step: 8
Training loss: 3.132341230529116
Validation loss: 2.6125949099536667

Epoch: 5| Step: 9
Training loss: 3.2301361761529033
Validation loss: 2.606339628902914

Epoch: 5| Step: 10
Training loss: 2.988748112529955
Validation loss: 2.5957683089402743

Epoch: 78| Step: 0
Training loss: 3.2666730887161757
Validation loss: 2.6110199421312146

Epoch: 5| Step: 1
Training loss: 2.683071835335718
Validation loss: 2.5834135928936273

Epoch: 5| Step: 2
Training loss: 2.7552034393632447
Validation loss: 2.5780499847327394

Epoch: 5| Step: 3
Training loss: 3.015041472749166
Validation loss: 2.595092281812723

Epoch: 5| Step: 4
Training loss: 2.7544137040775936
Validation loss: 2.587262839482561

Epoch: 5| Step: 5
Training loss: 2.6779477892081567
Validation loss: 2.589356182094632

Epoch: 5| Step: 6
Training loss: 3.1308992779545446
Validation loss: 2.6133442797592714

Epoch: 5| Step: 7
Training loss: 2.7176017528810146
Validation loss: 2.6105923155439377

Epoch: 5| Step: 8
Training loss: 3.2064673872454637
Validation loss: 2.577669639310278

Epoch: 5| Step: 9
Training loss: 3.2048625420240793
Validation loss: 2.594440463683159

Epoch: 5| Step: 10
Training loss: 2.5152535490089267
Validation loss: 2.5818970879188705

Epoch: 79| Step: 0
Training loss: 2.3045350105140643
Validation loss: 2.596722796567203

Epoch: 5| Step: 1
Training loss: 3.139089484167633
Validation loss: 2.5804813518883765

Epoch: 5| Step: 2
Training loss: 2.814892662400501
Validation loss: 2.587310137229697

Epoch: 5| Step: 3
Training loss: 3.5796577469027593
Validation loss: 2.607006459705512

Epoch: 5| Step: 4
Training loss: 2.4427123459469198
Validation loss: 2.615202019947218

Epoch: 5| Step: 5
Training loss: 3.3814497178301894
Validation loss: 2.584997451573737

Epoch: 5| Step: 6
Training loss: 2.9384793211498352
Validation loss: 2.588374702313131

Epoch: 5| Step: 7
Training loss: 2.420205112781425
Validation loss: 2.575451767296078

Epoch: 5| Step: 8
Training loss: 3.3667566860237677
Validation loss: 2.5909651132355673

Epoch: 5| Step: 9
Training loss: 2.5849196168070687
Validation loss: 2.570847768585651

Epoch: 5| Step: 10
Training loss: 2.623395156745834
Validation loss: 2.589236599819927

Epoch: 80| Step: 0
Training loss: 2.723273186861862
Validation loss: 2.5683804581068976

Epoch: 5| Step: 1
Training loss: 3.6735974756062704
Validation loss: 2.5905962848490716

Epoch: 5| Step: 2
Training loss: 3.0989619578278873
Validation loss: 2.5644395772578616

Epoch: 5| Step: 3
Training loss: 2.681878887130136
Validation loss: 2.5929379111715023

Epoch: 5| Step: 4
Training loss: 3.6148831172635516
Validation loss: 2.60885080288301

Epoch: 5| Step: 5
Training loss: 2.0316709815780887
Validation loss: 2.6203081671386137

Epoch: 5| Step: 6
Training loss: 2.796598282236738
Validation loss: 2.581217033590665

Epoch: 5| Step: 7
Training loss: 3.1951617739320617
Validation loss: 2.6004642897122188

Epoch: 5| Step: 8
Training loss: 2.5924483560625307
Validation loss: 2.597979724576395

Epoch: 5| Step: 9
Training loss: 1.9897995942769013
Validation loss: 2.5946795441984625

Epoch: 5| Step: 10
Training loss: 3.213323370362767
Validation loss: 2.5960707548325836

Epoch: 81| Step: 0
Training loss: 2.4563295851377016
Validation loss: 2.5786301153769635

Epoch: 5| Step: 1
Training loss: 2.5260027905386084
Validation loss: 2.615813433935295

Epoch: 5| Step: 2
Training loss: 3.0093313370465493
Validation loss: 2.5926315173298384

Epoch: 5| Step: 3
Training loss: 2.7200295079257533
Validation loss: 2.5951631326111277

Epoch: 5| Step: 4
Training loss: 2.8584116162255984
Validation loss: 2.5878406413183717

Epoch: 5| Step: 5
Training loss: 2.8053806479123997
Validation loss: 2.586736555808736

Epoch: 5| Step: 6
Training loss: 3.298818295759483
Validation loss: 2.5860467138036682

Epoch: 5| Step: 7
Training loss: 2.892848299070158
Validation loss: 2.5826749852585484

Epoch: 5| Step: 8
Training loss: 3.6348234783899995
Validation loss: 2.5959718066204474

Epoch: 5| Step: 9
Training loss: 2.6642837208828434
Validation loss: 2.5942355710948974

Epoch: 5| Step: 10
Training loss: 2.955024229618403
Validation loss: 2.5731911820224

Epoch: 82| Step: 0
Training loss: 2.644420446782079
Validation loss: 2.607583525278906

Epoch: 5| Step: 1
Training loss: 3.3055004806275856
Validation loss: 2.604634331498133

Epoch: 5| Step: 2
Training loss: 2.5281980977848764
Validation loss: 2.580306668443538

Epoch: 5| Step: 3
Training loss: 2.8215913277257254
Validation loss: 2.599895535106594

Epoch: 5| Step: 4
Training loss: 3.323825691913553
Validation loss: 2.6196110026897808

Epoch: 5| Step: 5
Training loss: 2.7880796095046403
Validation loss: 2.5832645163630588

Epoch: 5| Step: 6
Training loss: 2.9762025149873934
Validation loss: 2.589584030452096

Epoch: 5| Step: 7
Training loss: 3.0466480659679434
Validation loss: 2.591458983762471

Epoch: 5| Step: 8
Training loss: 2.646551400212141
Validation loss: 2.604223595437898

Epoch: 5| Step: 9
Training loss: 2.3306125945592004
Validation loss: 2.599281629923489

Epoch: 5| Step: 10
Training loss: 3.4723806540054096
Validation loss: 2.601315715604033

Epoch: 83| Step: 0
Training loss: 2.5459935822027666
Validation loss: 2.5817805581140747

Epoch: 5| Step: 1
Training loss: 2.4329537274107125
Validation loss: 2.581447340256278

Epoch: 5| Step: 2
Training loss: 3.074555937174575
Validation loss: 2.5738211955670707

Epoch: 5| Step: 3
Training loss: 3.2070128130179536
Validation loss: 2.583335394830374

Epoch: 5| Step: 4
Training loss: 2.592970581605729
Validation loss: 2.5955559780881567

Epoch: 5| Step: 5
Training loss: 2.6752651190174124
Validation loss: 2.6014627446593326

Epoch: 5| Step: 6
Training loss: 3.2844841413575288
Validation loss: 2.5968808688707816

Epoch: 5| Step: 7
Training loss: 2.459701276025008
Validation loss: 2.5994702787930284

Epoch: 5| Step: 8
Training loss: 2.87799629312983
Validation loss: 2.590416232207289

Epoch: 5| Step: 9
Training loss: 3.197938171380684
Validation loss: 2.5774355048719215

Epoch: 5| Step: 10
Training loss: 3.490543533235142
Validation loss: 2.5969009894083928

Epoch: 84| Step: 0
Training loss: 2.796494015792809
Validation loss: 2.568088296625837

Epoch: 5| Step: 1
Training loss: 2.3632092173293935
Validation loss: 2.594737811078479

Epoch: 5| Step: 2
Training loss: 3.1603431976435865
Validation loss: 2.6046096638259466

Epoch: 5| Step: 3
Training loss: 3.409186820790661
Validation loss: 2.584782398090995

Epoch: 5| Step: 4
Training loss: 2.8783188612735535
Validation loss: 2.567212157926524

Epoch: 5| Step: 5
Training loss: 2.607709067312232
Validation loss: 2.572650602893092

Epoch: 5| Step: 6
Training loss: 2.8218626374811393
Validation loss: 2.591722473564784

Epoch: 5| Step: 7
Training loss: 2.488240815078155
Validation loss: 2.5987257532293557

Epoch: 5| Step: 8
Training loss: 2.9531111136619614
Validation loss: 2.581777355771354

Epoch: 5| Step: 9
Training loss: 3.4177688278584837
Validation loss: 2.6064361819352464

Epoch: 5| Step: 10
Training loss: 2.796854626458835
Validation loss: 2.567724480994512

Epoch: 85| Step: 0
Training loss: 2.797866901135965
Validation loss: 2.584959363588817

Epoch: 5| Step: 1
Training loss: 3.457617413671051
Validation loss: 2.576031480413457

Epoch: 5| Step: 2
Training loss: 2.602389642315952
Validation loss: 2.5823741790172354

Epoch: 5| Step: 3
Training loss: 2.836834390017203
Validation loss: 2.585812438651156

Epoch: 5| Step: 4
Training loss: 2.9091693612920966
Validation loss: 2.5903298009696387

Epoch: 5| Step: 5
Training loss: 2.3385100727170225
Validation loss: 2.6055637831862346

Epoch: 5| Step: 6
Training loss: 2.658297389234891
Validation loss: 2.5853686999493086

Epoch: 5| Step: 7
Training loss: 3.090339399049619
Validation loss: 2.575081179372926

Epoch: 5| Step: 8
Training loss: 3.0315864612217136
Validation loss: 2.590256411946624

Epoch: 5| Step: 9
Training loss: 3.1956319859094657
Validation loss: 2.576856556801177

Epoch: 5| Step: 10
Training loss: 2.934733772485786
Validation loss: 2.5678301724507495

Epoch: 86| Step: 0
Training loss: 3.3597792271335516
Validation loss: 2.5888500005640385

Epoch: 5| Step: 1
Training loss: 2.5458456194175865
Validation loss: 2.5926594112403265

Epoch: 5| Step: 2
Training loss: 2.5831093434676857
Validation loss: 2.6007581341455603

Epoch: 5| Step: 3
Training loss: 2.875747915093914
Validation loss: 2.59141774491805

Epoch: 5| Step: 4
Training loss: 2.8454454000272316
Validation loss: 2.600335848401634

Epoch: 5| Step: 5
Training loss: 3.1574656345554164
Validation loss: 2.604233252545701

Epoch: 5| Step: 6
Training loss: 3.0639766325096915
Validation loss: 2.569468097491058

Epoch: 5| Step: 7
Training loss: 2.9957235373660738
Validation loss: 2.5954693648923146

Epoch: 5| Step: 8
Training loss: 2.0017170687811268
Validation loss: 2.59011650563957

Epoch: 5| Step: 9
Training loss: 3.177000517886236
Validation loss: 2.609356976469506

Epoch: 5| Step: 10
Training loss: 2.9923133923214347
Validation loss: 2.603687143456045

Epoch: 87| Step: 0
Training loss: 2.5590020472766937
Validation loss: 2.593435055603342

Epoch: 5| Step: 1
Training loss: 2.3574942867658852
Validation loss: 2.5958763803065765

Epoch: 5| Step: 2
Training loss: 2.7390789442771046
Validation loss: 2.6173187218065364

Epoch: 5| Step: 3
Training loss: 3.802623149575565
Validation loss: 2.57530571850773

Epoch: 5| Step: 4
Training loss: 2.9032137197154038
Validation loss: 2.585160960224634

Epoch: 5| Step: 5
Training loss: 2.0451669336658216
Validation loss: 2.610202704452869

Epoch: 5| Step: 6
Training loss: 3.6523702528700857
Validation loss: 2.5717216773246343

Epoch: 5| Step: 7
Training loss: 2.264712130040351
Validation loss: 2.5750296299001545

Epoch: 5| Step: 8
Training loss: 2.9970941775687177
Validation loss: 2.594930152742601

Epoch: 5| Step: 9
Training loss: 2.404302428151589
Validation loss: 2.575116187904257

Epoch: 5| Step: 10
Training loss: 3.68490211657021
Validation loss: 2.588629395376651

Epoch: 88| Step: 0
Training loss: 2.8782486183880867
Validation loss: 2.5815849944331317

Epoch: 5| Step: 1
Training loss: 2.7179402866611087
Validation loss: 2.5845509146316785

Epoch: 5| Step: 2
Training loss: 2.7575957561616304
Validation loss: 2.586595783168942

Epoch: 5| Step: 3
Training loss: 2.703698422684682
Validation loss: 2.5847950140192557

Epoch: 5| Step: 4
Training loss: 2.6367105215438738
Validation loss: 2.5937616175284997

Epoch: 5| Step: 5
Training loss: 2.936347248258202
Validation loss: 2.598760810211669

Epoch: 5| Step: 6
Training loss: 3.2100650688065
Validation loss: 2.588411997219695

Epoch: 5| Step: 7
Training loss: 2.711660942707769
Validation loss: 2.5917317662568142

Epoch: 5| Step: 8
Training loss: 2.655775050168208
Validation loss: 2.5756993083807864

Epoch: 5| Step: 9
Training loss: 2.977958451984857
Validation loss: 2.5877324443821057

Epoch: 5| Step: 10
Training loss: 3.568686618008265
Validation loss: 2.606351062444826

Epoch: 89| Step: 0
Training loss: 2.3590348358492905
Validation loss: 2.5782349782725653

Epoch: 5| Step: 1
Training loss: 2.7856117935329787
Validation loss: 2.5787293561999345

Epoch: 5| Step: 2
Training loss: 2.613439170273992
Validation loss: 2.598774577571019

Epoch: 5| Step: 3
Training loss: 2.6463822123385237
Validation loss: 2.5783529320693765

Epoch: 5| Step: 4
Training loss: 2.8504977812143633
Validation loss: 2.5833244196221634

Epoch: 5| Step: 5
Training loss: 3.0469108383809753
Validation loss: 2.5915545915292264

Epoch: 5| Step: 6
Training loss: 3.307545537541419
Validation loss: 2.5876135955093207

Epoch: 5| Step: 7
Training loss: 3.461048821925791
Validation loss: 2.58844320349687

Epoch: 5| Step: 8
Training loss: 3.0162855620645312
Validation loss: 2.565316683869698

Epoch: 5| Step: 9
Training loss: 2.5004469471997397
Validation loss: 2.5867795025405314

Epoch: 5| Step: 10
Training loss: 2.9059282350336058
Validation loss: 2.586735730246123

Epoch: 90| Step: 0
Training loss: 3.1836783743066497
Validation loss: 2.6026596805109374

Epoch: 5| Step: 1
Training loss: 2.113490970380205
Validation loss: 2.5795414011687265

Epoch: 5| Step: 2
Training loss: 2.919052474300057
Validation loss: 2.5903474937155995

Epoch: 5| Step: 3
Training loss: 2.820041971097239
Validation loss: 2.5571315955795724

Epoch: 5| Step: 4
Training loss: 3.1166991805014295
Validation loss: 2.585966652286782

Epoch: 5| Step: 5
Training loss: 2.9086256264726034
Validation loss: 2.578724620070812

Epoch: 5| Step: 6
Training loss: 3.2165771854057614
Validation loss: 2.5843891777332857

Epoch: 5| Step: 7
Training loss: 2.510750638872639
Validation loss: 2.6145916356754566

Epoch: 5| Step: 8
Training loss: 3.6699221348622846
Validation loss: 2.568762678939379

Epoch: 5| Step: 9
Training loss: 2.347931044454705
Validation loss: 2.602607362269589

Epoch: 5| Step: 10
Training loss: 2.639603366389399
Validation loss: 2.5997220269797854

Epoch: 91| Step: 0
Training loss: 2.8166877933891157
Validation loss: 2.6034531588406105

Epoch: 5| Step: 1
Training loss: 2.6520860234976342
Validation loss: 2.5918542868083034

Epoch: 5| Step: 2
Training loss: 2.440038581761989
Validation loss: 2.6053460884004105

Epoch: 5| Step: 3
Training loss: 3.7709869578279367
Validation loss: 2.5926987269105624

Epoch: 5| Step: 4
Training loss: 2.7044297966586104
Validation loss: 2.582166956896825

Epoch: 5| Step: 5
Training loss: 2.2805221650682177
Validation loss: 2.598291472859934

Epoch: 5| Step: 6
Training loss: 3.0272890935086245
Validation loss: 2.5883591859682458

Epoch: 5| Step: 7
Training loss: 3.119583623930337
Validation loss: 2.584208398476258

Epoch: 5| Step: 8
Training loss: 3.152558538028019
Validation loss: 2.619372242278658

Epoch: 5| Step: 9
Training loss: 2.431561106411905
Validation loss: 2.5884274270811174

Epoch: 5| Step: 10
Training loss: 3.178191861899996
Validation loss: 2.5772964294599614

Epoch: 92| Step: 0
Training loss: 2.8296626005125165
Validation loss: 2.559306983885881

Epoch: 5| Step: 1
Training loss: 3.280276344799992
Validation loss: 2.617252898191214

Epoch: 5| Step: 2
Training loss: 2.668562235246041
Validation loss: 2.6082273350150404

Epoch: 5| Step: 3
Training loss: 2.5908593305345
Validation loss: 2.619653781372561

Epoch: 5| Step: 4
Training loss: 3.3336984593369636
Validation loss: 2.587383523619738

Epoch: 5| Step: 5
Training loss: 3.209854425950033
Validation loss: 2.6045776896002586

Epoch: 5| Step: 6
Training loss: 3.050271982041718
Validation loss: 2.588217885489427

Epoch: 5| Step: 7
Training loss: 2.3063703179957225
Validation loss: 2.592355941858537

Epoch: 5| Step: 8
Training loss: 2.591392088774617
Validation loss: 2.59734738752993

Epoch: 5| Step: 9
Training loss: 2.8785950118501447
Validation loss: 2.608717968003594

Epoch: 5| Step: 10
Training loss: 2.9473990984625202
Validation loss: 2.5919303396948745

Epoch: 93| Step: 0
Training loss: 2.8369327196568084
Validation loss: 2.569704197934567

Epoch: 5| Step: 1
Training loss: 2.186586025580888
Validation loss: 2.5925510302529604

Epoch: 5| Step: 2
Training loss: 2.9756242369643005
Validation loss: 2.5768238790512226

Epoch: 5| Step: 3
Training loss: 2.7305793794369
Validation loss: 2.5984933877736376

Epoch: 5| Step: 4
Training loss: 2.962525276687888
Validation loss: 2.5915245573772876

Epoch: 5| Step: 5
Training loss: 3.547023417186629
Validation loss: 2.572871033707783

Epoch: 5| Step: 6
Training loss: 2.9995507857647343
Validation loss: 2.596368827872644

Epoch: 5| Step: 7
Training loss: 2.8869027581111975
Validation loss: 2.5956851082652186

Epoch: 5| Step: 8
Training loss: 2.8311370490240217
Validation loss: 2.581006836093855

Epoch: 5| Step: 9
Training loss: 3.051334814434541
Validation loss: 2.5868066909992

Epoch: 5| Step: 10
Training loss: 2.455578785590316
Validation loss: 2.5783307910373736

Epoch: 94| Step: 0
Training loss: 2.8897891924045402
Validation loss: 2.5744931102515487

Epoch: 5| Step: 1
Training loss: 2.682073926266663
Validation loss: 2.593135942422529

Epoch: 5| Step: 2
Training loss: 2.89476055518846
Validation loss: 2.562977495982851

Epoch: 5| Step: 3
Training loss: 3.313645362770428
Validation loss: 2.5765898846631194

Epoch: 5| Step: 4
Training loss: 3.019534566267988
Validation loss: 2.5782535604204115

Epoch: 5| Step: 5
Training loss: 3.463492868791973
Validation loss: 2.5828545775430656

Epoch: 5| Step: 6
Training loss: 2.6030316028120053
Validation loss: 2.5609699776791577

Epoch: 5| Step: 7
Training loss: 2.921733832391532
Validation loss: 2.5981680303689734

Epoch: 5| Step: 8
Training loss: 2.638278347349279
Validation loss: 2.5818079700052423

Epoch: 5| Step: 9
Training loss: 2.5574298103970365
Validation loss: 2.601782408637352

Epoch: 5| Step: 10
Training loss: 2.574960789798603
Validation loss: 2.5965468337176336

Epoch: 95| Step: 0
Training loss: 2.626678202824828
Validation loss: 2.580243172439901

Epoch: 5| Step: 1
Training loss: 3.067692305949926
Validation loss: 2.596650003877381

Epoch: 5| Step: 2
Training loss: 3.1037969347707786
Validation loss: 2.608321016008605

Epoch: 5| Step: 3
Training loss: 2.5518199447384586
Validation loss: 2.586277239655796

Epoch: 5| Step: 4
Training loss: 2.7310563357062536
Validation loss: 2.5653058669187474

Epoch: 5| Step: 5
Training loss: 2.824748009439691
Validation loss: 2.5907131404957324

Epoch: 5| Step: 6
Training loss: 2.8776400510641995
Validation loss: 2.5620991783292584

Epoch: 5| Step: 7
Training loss: 2.9390209399889207
Validation loss: 2.5890350393216246

Epoch: 5| Step: 8
Training loss: 2.903496370902207
Validation loss: 2.5821080876435296

Epoch: 5| Step: 9
Training loss: 2.6968503241443345
Validation loss: 2.584243676204801

Epoch: 5| Step: 10
Training loss: 3.3114023369279244
Validation loss: 2.5564672407117266

Epoch: 96| Step: 0
Training loss: 3.137336945571257
Validation loss: 2.5837375041541764

Epoch: 5| Step: 1
Training loss: 2.6424852849718437
Validation loss: 2.601874461425886

Epoch: 5| Step: 2
Training loss: 2.104991058910527
Validation loss: 2.590404425988553

Epoch: 5| Step: 3
Training loss: 2.8341421954893034
Validation loss: 2.6109764358135776

Epoch: 5| Step: 4
Training loss: 2.2724118360617074
Validation loss: 2.5868883636721423

Epoch: 5| Step: 5
Training loss: 3.0374243079279526
Validation loss: 2.5835057028095942

Epoch: 5| Step: 6
Training loss: 2.830755369924337
Validation loss: 2.582038729335092

Epoch: 5| Step: 7
Training loss: 2.569999606210404
Validation loss: 2.568767089623228

Epoch: 5| Step: 8
Training loss: 3.300766225927346
Validation loss: 2.578843800067628

Epoch: 5| Step: 9
Training loss: 3.560011412784413
Validation loss: 2.5745751446686578

Epoch: 5| Step: 10
Training loss: 3.1150516085689257
Validation loss: 2.5820702300749416

Epoch: 97| Step: 0
Training loss: 2.722711767782694
Validation loss: 2.5847096182566913

Epoch: 5| Step: 1
Training loss: 3.0277781316385637
Validation loss: 2.5803666796130975

Epoch: 5| Step: 2
Training loss: 2.8074792765041896
Validation loss: 2.579943709816263

Epoch: 5| Step: 3
Training loss: 3.32955357511822
Validation loss: 2.5767834954016835

Epoch: 5| Step: 4
Training loss: 2.3551241747602267
Validation loss: 2.592699618306702

Epoch: 5| Step: 5
Training loss: 2.654032241395477
Validation loss: 2.5970090792851335

Epoch: 5| Step: 6
Training loss: 3.044636534998722
Validation loss: 2.5713930700914474

Epoch: 5| Step: 7
Training loss: 2.7047513798883727
Validation loss: 2.5722441421857383

Epoch: 5| Step: 8
Training loss: 3.154745215331537
Validation loss: 2.5784396151445006

Epoch: 5| Step: 9
Training loss: 2.4648538096565717
Validation loss: 2.575657590272059

Epoch: 5| Step: 10
Training loss: 3.286795589273313
Validation loss: 2.5747455999713567

Epoch: 98| Step: 0
Training loss: 2.9268733228686403
Validation loss: 2.57608938638255

Epoch: 5| Step: 1
Training loss: 3.1171616479093247
Validation loss: 2.5743555090559394

Epoch: 5| Step: 2
Training loss: 2.5633415142998612
Validation loss: 2.5794133333000775

Epoch: 5| Step: 3
Training loss: 2.594417072599207
Validation loss: 2.581143148087212

Epoch: 5| Step: 4
Training loss: 2.8000234432601445
Validation loss: 2.5685481655531386

Epoch: 5| Step: 5
Training loss: 3.3061574998690593
Validation loss: 2.562907051793142

Epoch: 5| Step: 6
Training loss: 2.617020877829196
Validation loss: 2.5621345683641863

Epoch: 5| Step: 7
Training loss: 2.808371417035455
Validation loss: 2.5779443612305286

Epoch: 5| Step: 8
Training loss: 2.538194901349928
Validation loss: 2.5829708415328057

Epoch: 5| Step: 9
Training loss: 3.3227276085591417
Validation loss: 2.632676517459241

Epoch: 5| Step: 10
Training loss: 2.7678793646979543
Validation loss: 2.5725888940274704

Epoch: 99| Step: 0
Training loss: 2.8647513785345193
Validation loss: 2.5788096801818203

Epoch: 5| Step: 1
Training loss: 3.0005050869774474
Validation loss: 2.5589377331014824

Epoch: 5| Step: 2
Training loss: 2.9068461801350653
Validation loss: 2.5800201649715255

Epoch: 5| Step: 3
Training loss: 3.255183561103658
Validation loss: 2.584362980622854

Epoch: 5| Step: 4
Training loss: 2.398786090780099
Validation loss: 2.586188790127487

Epoch: 5| Step: 5
Training loss: 3.2255778068604006
Validation loss: 2.5922627420938102

Epoch: 5| Step: 6
Training loss: 2.6876490352026585
Validation loss: 2.5821544983987263

Epoch: 5| Step: 7
Training loss: 2.8359944992012083
Validation loss: 2.5692601731960067

Epoch: 5| Step: 8
Training loss: 2.7473850822539694
Validation loss: 2.5406751919577633

Epoch: 5| Step: 9
Training loss: 2.7134211263895183
Validation loss: 2.5465823393601634

Epoch: 5| Step: 10
Training loss: 2.6956582552518906
Validation loss: 2.569872441481687

Epoch: 100| Step: 0
Training loss: 2.6669977300496233
Validation loss: 2.5808590469632438

Epoch: 5| Step: 1
Training loss: 2.877634417114518
Validation loss: 2.551986744408776

Epoch: 5| Step: 2
Training loss: 2.8126569068373475
Validation loss: 2.545931615903212

Epoch: 5| Step: 3
Training loss: 2.9862380678458242
Validation loss: 2.591394941888028

Epoch: 5| Step: 4
Training loss: 3.251191434351083
Validation loss: 2.5632433359646405

Epoch: 5| Step: 5
Training loss: 2.1088228986674857
Validation loss: 2.582800577691762

Epoch: 5| Step: 6
Training loss: 3.3114426562784254
Validation loss: 2.5725892836674222

Epoch: 5| Step: 7
Training loss: 2.792074847390409
Validation loss: 2.565036787579925

Epoch: 5| Step: 8
Training loss: 3.0573845003884172
Validation loss: 2.568238248089534

Epoch: 5| Step: 9
Training loss: 2.7302650299259366
Validation loss: 2.574828886843337

Epoch: 5| Step: 10
Training loss: 2.847026069728099
Validation loss: 2.5723703515240333

Epoch: 101| Step: 0
Training loss: 3.0567520072557905
Validation loss: 2.5946956135902597

Epoch: 5| Step: 1
Training loss: 2.3919879294381143
Validation loss: 2.556900587646379

Epoch: 5| Step: 2
Training loss: 3.3057074810202494
Validation loss: 2.5609651496450345

Epoch: 5| Step: 3
Training loss: 2.3854656519850663
Validation loss: 2.5911836447110654

Epoch: 5| Step: 4
Training loss: 2.9666535052175425
Validation loss: 2.571842922272358

Epoch: 5| Step: 5
Training loss: 2.998198604161358
Validation loss: 2.579817415355398

Epoch: 5| Step: 6
Training loss: 2.7773760271946517
Validation loss: 2.590873602961505

Epoch: 5| Step: 7
Training loss: 3.3179238018371313
Validation loss: 2.5946696578766137

Epoch: 5| Step: 8
Training loss: 2.820631437152708
Validation loss: 2.560296283342536

Epoch: 5| Step: 9
Training loss: 2.5998789062177203
Validation loss: 2.565275933187663

Epoch: 5| Step: 10
Training loss: 2.7427661426525685
Validation loss: 2.5820943892844874

Epoch: 102| Step: 0
Training loss: 3.119065715580605
Validation loss: 2.57363099083955

Epoch: 5| Step: 1
Training loss: 3.108632368033403
Validation loss: 2.5643352816393965

Epoch: 5| Step: 2
Training loss: 2.6152250761247116
Validation loss: 2.5853139950157735

Epoch: 5| Step: 3
Training loss: 2.617743316388298
Validation loss: 2.582549750534183

Epoch: 5| Step: 4
Training loss: 3.0007602999789382
Validation loss: 2.578317458401282

Epoch: 5| Step: 5
Training loss: 2.780208950011689
Validation loss: 2.5622652733177507

Epoch: 5| Step: 6
Training loss: 2.872646861492851
Validation loss: 2.588235862087369

Epoch: 5| Step: 7
Training loss: 3.3053912772880127
Validation loss: 2.5544083378681908

Epoch: 5| Step: 8
Training loss: 2.4442785837757897
Validation loss: 2.5509248864658507

Epoch: 5| Step: 9
Training loss: 2.9321841575378276
Validation loss: 2.569010044778926

Epoch: 5| Step: 10
Training loss: 2.4026797672144613
Validation loss: 2.5911922997096686

Epoch: 103| Step: 0
Training loss: 2.7381442004420715
Validation loss: 2.57659786384691

Epoch: 5| Step: 1
Training loss: 2.795661364599643
Validation loss: 2.5819239698436967

Epoch: 5| Step: 2
Training loss: 2.41888390695299
Validation loss: 2.5820329915064817

Epoch: 5| Step: 3
Training loss: 3.4890412018634547
Validation loss: 2.5991457972378673

Epoch: 5| Step: 4
Training loss: 2.621801152968235
Validation loss: 2.5670135459282837

Epoch: 5| Step: 5
Training loss: 3.532847220491908
Validation loss: 2.5827927432323774

Epoch: 5| Step: 6
Training loss: 2.8173553095223887
Validation loss: 2.5707843366264336

Epoch: 5| Step: 7
Training loss: 2.3063129447472837
Validation loss: 2.5834417813257073

Epoch: 5| Step: 8
Training loss: 2.279187877307599
Validation loss: 2.5673588473701736

Epoch: 5| Step: 9
Training loss: 3.529234859764016
Validation loss: 2.541640773932467

Epoch: 5| Step: 10
Training loss: 2.4632010570554828
Validation loss: 2.57627733732417

Epoch: 104| Step: 0
Training loss: 2.3466986862981964
Validation loss: 2.584804331120455

Epoch: 5| Step: 1
Training loss: 3.058089525308212
Validation loss: 2.5597322705268524

Epoch: 5| Step: 2
Training loss: 2.704074582578027
Validation loss: 2.582942125891898

Epoch: 5| Step: 3
Training loss: 2.551752393375895
Validation loss: 2.5677340537274027

Epoch: 5| Step: 4
Training loss: 3.0030028890976297
Validation loss: 2.551551526034632

Epoch: 5| Step: 5
Training loss: 2.6855788350370986
Validation loss: 2.563909243678482

Epoch: 5| Step: 6
Training loss: 3.2447258629818516
Validation loss: 2.5845291322070127

Epoch: 5| Step: 7
Training loss: 2.6469967504466263
Validation loss: 2.5528914042257775

Epoch: 5| Step: 8
Training loss: 2.969696857638761
Validation loss: 2.5848281662428874

Epoch: 5| Step: 9
Training loss: 2.837687307216924
Validation loss: 2.572252863901068

Epoch: 5| Step: 10
Training loss: 3.269905169217271
Validation loss: 2.5624121043860093

Epoch: 105| Step: 0
Training loss: 2.352473491231521
Validation loss: 2.555940211343113

Epoch: 5| Step: 1
Training loss: 2.896791386555
Validation loss: 2.5779520015900768

Epoch: 5| Step: 2
Training loss: 2.5502587991171337
Validation loss: 2.5740061504147973

Epoch: 5| Step: 3
Training loss: 2.664009250321237
Validation loss: 2.5937478838527848

Epoch: 5| Step: 4
Training loss: 3.2194304996861742
Validation loss: 2.567577376110109

Epoch: 5| Step: 5
Training loss: 2.9849389626861575
Validation loss: 2.559605989897176

Epoch: 5| Step: 6
Training loss: 3.005390728065941
Validation loss: 2.5588358101014865

Epoch: 5| Step: 7
Training loss: 3.381344800596718
Validation loss: 2.57705162825924

Epoch: 5| Step: 8
Training loss: 2.632211678883127
Validation loss: 2.5707214570720316

Epoch: 5| Step: 9
Training loss: 2.900986694326463
Validation loss: 2.572465853541461

Epoch: 5| Step: 10
Training loss: 2.668193131892969
Validation loss: 2.5614521826635235

Epoch: 106| Step: 0
Training loss: 2.6011002963394994
Validation loss: 2.573132804835196

Epoch: 5| Step: 1
Training loss: 2.531041737218731
Validation loss: 2.585959904046405

Epoch: 5| Step: 2
Training loss: 2.7684013095466242
Validation loss: 2.5628405428989502

Epoch: 5| Step: 3
Training loss: 2.879768397767479
Validation loss: 2.564273618606074

Epoch: 5| Step: 4
Training loss: 2.448315224092567
Validation loss: 2.574774178020065

Epoch: 5| Step: 5
Training loss: 2.744438095531593
Validation loss: 2.579492463235055

Epoch: 5| Step: 6
Training loss: 3.128001183375454
Validation loss: 2.553122978748359

Epoch: 5| Step: 7
Training loss: 2.9531853886641346
Validation loss: 2.5753941227264088

Epoch: 5| Step: 8
Training loss: 3.1244141601745623
Validation loss: 2.575364016576874

Epoch: 5| Step: 9
Training loss: 2.641727555913988
Validation loss: 2.5824135668917654

Epoch: 5| Step: 10
Training loss: 3.4180650098052383
Validation loss: 2.56314827046927

Epoch: 107| Step: 0
Training loss: 2.820772846724781
Validation loss: 2.5723477444061733

Epoch: 5| Step: 1
Training loss: 2.734683558901812
Validation loss: 2.590093522889748

Epoch: 5| Step: 2
Training loss: 2.5501476394697744
Validation loss: 2.5705523495725013

Epoch: 5| Step: 3
Training loss: 2.9516680317435258
Validation loss: 2.5734573107772514

Epoch: 5| Step: 4
Training loss: 2.6868347409150033
Validation loss: 2.5603795486125756

Epoch: 5| Step: 5
Training loss: 2.8250036560305003
Validation loss: 2.579640094134198

Epoch: 5| Step: 6
Training loss: 2.5540653136048945
Validation loss: 2.5499360641725777

Epoch: 5| Step: 7
Training loss: 3.354270285828294
Validation loss: 2.566569364845122

Epoch: 5| Step: 8
Training loss: 3.722810724021522
Validation loss: 2.558571153916865

Epoch: 5| Step: 9
Training loss: 2.1933424177049305
Validation loss: 2.5582777664687826

Epoch: 5| Step: 10
Training loss: 2.5838866615417952
Validation loss: 2.5851577432275015

Epoch: 108| Step: 0
Training loss: 3.5330108033529823
Validation loss: 2.548064690262325

Epoch: 5| Step: 1
Training loss: 2.701715708371231
Validation loss: 2.577860041303366

Epoch: 5| Step: 2
Training loss: 3.5754280420956737
Validation loss: 2.581865415273608

Epoch: 5| Step: 3
Training loss: 2.8241343294350147
Validation loss: 2.568114031848617

Epoch: 5| Step: 4
Training loss: 2.7022712550015977
Validation loss: 2.5639775406128624

Epoch: 5| Step: 5
Training loss: 2.775419316958922
Validation loss: 2.5704873819056475

Epoch: 5| Step: 6
Training loss: 2.105698270442905
Validation loss: 2.55129164034431

Epoch: 5| Step: 7
Training loss: 3.152630534120351
Validation loss: 2.596955171385615

Epoch: 5| Step: 8
Training loss: 2.4753251218624475
Validation loss: 2.5671454320170084

Epoch: 5| Step: 9
Training loss: 2.5311057909164507
Validation loss: 2.5527318331853315

Epoch: 5| Step: 10
Training loss: 2.498795314452357
Validation loss: 2.553836383317576

Epoch: 109| Step: 0
Training loss: 2.3097423916800923
Validation loss: 2.568958810574293

Epoch: 5| Step: 1
Training loss: 2.4760615567211004
Validation loss: 2.543410893087966

Epoch: 5| Step: 2
Training loss: 2.619072625218364
Validation loss: 2.5462277071322457

Epoch: 5| Step: 3
Training loss: 3.130011850157904
Validation loss: 2.559706034394649

Epoch: 5| Step: 4
Training loss: 3.0761233565122157
Validation loss: 2.571161673390699

Epoch: 5| Step: 5
Training loss: 3.046222323423815
Validation loss: 2.5663403951972685

Epoch: 5| Step: 6
Training loss: 2.9660269043847496
Validation loss: 2.5832772935259642

Epoch: 5| Step: 7
Training loss: 2.4707836997422223
Validation loss: 2.5742736359416516

Epoch: 5| Step: 8
Training loss: 2.111018240151872
Validation loss: 2.578444677913946

Epoch: 5| Step: 9
Training loss: 3.140713211263141
Validation loss: 2.563437087669695

Epoch: 5| Step: 10
Training loss: 3.72559233698664
Validation loss: 2.5756000174954945

Epoch: 110| Step: 0
Training loss: 2.1257562974434783
Validation loss: 2.566344147243258

Epoch: 5| Step: 1
Training loss: 3.5001354191331666
Validation loss: 2.5674362119959713

Epoch: 5| Step: 2
Training loss: 2.5204331787126817
Validation loss: 2.561097284139005

Epoch: 5| Step: 3
Training loss: 2.755516501332814
Validation loss: 2.556977056048414

Epoch: 5| Step: 4
Training loss: 3.01748615606209
Validation loss: 2.5649302373926597

Epoch: 5| Step: 5
Training loss: 3.5677105460426914
Validation loss: 2.5990991074433896

Epoch: 5| Step: 6
Training loss: 2.4573956872760183
Validation loss: 2.586156071689302

Epoch: 5| Step: 7
Training loss: 2.8538939259845457
Validation loss: 2.5761234492507934

Epoch: 5| Step: 8
Training loss: 2.5470535122147893
Validation loss: 2.5386102290941346

Epoch: 5| Step: 9
Training loss: 2.777994200434718
Validation loss: 2.5909474583487944

Epoch: 5| Step: 10
Training loss: 2.692125288055769
Validation loss: 2.5578777584869052

Epoch: 111| Step: 0
Training loss: 2.7125243014464404
Validation loss: 2.5795035009614247

Epoch: 5| Step: 1
Training loss: 2.366825894475194
Validation loss: 2.569527209441025

Epoch: 5| Step: 2
Training loss: 2.734043210199509
Validation loss: 2.557201132188778

Epoch: 5| Step: 3
Training loss: 3.7257130292460725
Validation loss: 2.579933716845532

Epoch: 5| Step: 4
Training loss: 2.8182325645251924
Validation loss: 2.549414743318016

Epoch: 5| Step: 5
Training loss: 2.6153027480676676
Validation loss: 2.5714169557500806

Epoch: 5| Step: 6
Training loss: 2.777001039201915
Validation loss: 2.5669168303499306

Epoch: 5| Step: 7
Training loss: 2.972746879008173
Validation loss: 2.5607917267903986

Epoch: 5| Step: 8
Training loss: 2.964721033826057
Validation loss: 2.5692963790765235

Epoch: 5| Step: 9
Training loss: 2.6889828871313326
Validation loss: 2.555168568925567

Epoch: 5| Step: 10
Training loss: 2.7787721718998832
Validation loss: 2.5769990950343544

Epoch: 112| Step: 0
Training loss: 3.383409830616028
Validation loss: 2.5844655217149617

Epoch: 5| Step: 1
Training loss: 2.389074483458439
Validation loss: 2.548739590928477

Epoch: 5| Step: 2
Training loss: 2.2692858354832692
Validation loss: 2.576886353024379

Epoch: 5| Step: 3
Training loss: 2.762754772054783
Validation loss: 2.58048694812027

Epoch: 5| Step: 4
Training loss: 2.857997875343638
Validation loss: 2.570615729912202

Epoch: 5| Step: 5
Training loss: 2.833751161471593
Validation loss: 2.560036221893353

Epoch: 5| Step: 6
Training loss: 3.057806973459652
Validation loss: 2.573611469837414

Epoch: 5| Step: 7
Training loss: 2.6567614792195027
Validation loss: 2.56801614977824

Epoch: 5| Step: 8
Training loss: 3.296457417876581
Validation loss: 2.5754403244895117

Epoch: 5| Step: 9
Training loss: 2.222449643365933
Validation loss: 2.5557608177206803

Epoch: 5| Step: 10
Training loss: 3.3639078475903705
Validation loss: 2.5745498305142918

Epoch: 113| Step: 0
Training loss: 2.8803758532259582
Validation loss: 2.55634054406758

Epoch: 5| Step: 1
Training loss: 3.699583396139716
Validation loss: 2.5817810029663306

Epoch: 5| Step: 2
Training loss: 2.518743820750795
Validation loss: 2.582123335756812

Epoch: 5| Step: 3
Training loss: 3.0016590934910643
Validation loss: 2.5662528988462125

Epoch: 5| Step: 4
Training loss: 2.525686389806648
Validation loss: 2.5751310772124287

Epoch: 5| Step: 5
Training loss: 2.838910858689724
Validation loss: 2.560612839756547

Epoch: 5| Step: 6
Training loss: 2.140161394468314
Validation loss: 2.5533491265734813

Epoch: 5| Step: 7
Training loss: 3.026144545749191
Validation loss: 2.5654147758628083

Epoch: 5| Step: 8
Training loss: 3.320650689348608
Validation loss: 2.5940954524659454

Epoch: 5| Step: 9
Training loss: 2.7142596817202316
Validation loss: 2.526125494062183

Epoch: 5| Step: 10
Training loss: 2.040911658162435
Validation loss: 2.567943181279367

Epoch: 114| Step: 0
Training loss: 3.5449315599041253
Validation loss: 2.5744979826210685

Epoch: 5| Step: 1
Training loss: 2.744550941715891
Validation loss: 2.5675776826393824

Epoch: 5| Step: 2
Training loss: 2.4866492460354834
Validation loss: 2.5739521516780717

Epoch: 5| Step: 3
Training loss: 2.543716906582999
Validation loss: 2.5578156551308773

Epoch: 5| Step: 4
Training loss: 3.424582607703792
Validation loss: 2.5826487221208336

Epoch: 5| Step: 5
Training loss: 2.922568499020977
Validation loss: 2.5245955937036246

Epoch: 5| Step: 6
Training loss: 2.4612022620783565
Validation loss: 2.565401312144877

Epoch: 5| Step: 7
Training loss: 2.1479561561286866
Validation loss: 2.572453116357006

Epoch: 5| Step: 8
Training loss: 3.129254458669357
Validation loss: 2.5615249657616688

Epoch: 5| Step: 9
Training loss: 2.2750958558733005
Validation loss: 2.545095105009039

Epoch: 5| Step: 10
Training loss: 3.350578252505031
Validation loss: 2.5641504970492366

Epoch: 115| Step: 0
Training loss: 2.495385775508392
Validation loss: 2.5677530892622977

Epoch: 5| Step: 1
Training loss: 3.4735920420804582
Validation loss: 2.5674590870264824

Epoch: 5| Step: 2
Training loss: 2.7112313147077303
Validation loss: 2.5647999706118205

Epoch: 5| Step: 3
Training loss: 3.2536994712678386
Validation loss: 2.5743296101708983

Epoch: 5| Step: 4
Training loss: 2.7792442890481555
Validation loss: 2.518196763822123

Epoch: 5| Step: 5
Training loss: 2.8345345213559825
Validation loss: 2.5415831780266753

Epoch: 5| Step: 6
Training loss: 2.591204669738076
Validation loss: 2.5668237895627137

Epoch: 5| Step: 7
Training loss: 3.048380318500817
Validation loss: 2.5766915262446743

Epoch: 5| Step: 8
Training loss: 3.153187238307719
Validation loss: 2.5807251954678554

Epoch: 5| Step: 9
Training loss: 2.585684219357164
Validation loss: 2.5717772884255927

Epoch: 5| Step: 10
Training loss: 1.6930098123328026
Validation loss: 2.570291352947899

Epoch: 116| Step: 0
Training loss: 2.832704156317641
Validation loss: 2.5642094786403757

Epoch: 5| Step: 1
Training loss: 2.5469748822618574
Validation loss: 2.5907217000905858

Epoch: 5| Step: 2
Training loss: 2.83047808972807
Validation loss: 2.5529482579806237

Epoch: 5| Step: 3
Training loss: 2.6886019554507348
Validation loss: 2.5613968087955694

Epoch: 5| Step: 4
Training loss: 3.8097912280136565
Validation loss: 2.5576413371274467

Epoch: 5| Step: 5
Training loss: 2.750172956403036
Validation loss: 2.562353928847432

Epoch: 5| Step: 6
Training loss: 2.920555755297235
Validation loss: 2.5633649739297524

Epoch: 5| Step: 7
Training loss: 2.973383770616111
Validation loss: 2.563987773247702

Epoch: 5| Step: 8
Training loss: 2.514822506111247
Validation loss: 2.546717529340875

Epoch: 5| Step: 9
Training loss: 2.2976472555462446
Validation loss: 2.5825933173204474

Epoch: 5| Step: 10
Training loss: 2.7965824251214277
Validation loss: 2.5691779486148794

Epoch: 117| Step: 0
Training loss: 3.371399265559109
Validation loss: 2.540271423145067

Epoch: 5| Step: 1
Training loss: 2.5885292733482297
Validation loss: 2.587571577580479

Epoch: 5| Step: 2
Training loss: 2.5653068242966968
Validation loss: 2.5565232458094203

Epoch: 5| Step: 3
Training loss: 2.4356599366988796
Validation loss: 2.5262021080513692

Epoch: 5| Step: 4
Training loss: 3.058738734291198
Validation loss: 2.5677515377506794

Epoch: 5| Step: 5
Training loss: 3.341227783403271
Validation loss: 2.5678139928406356

Epoch: 5| Step: 6
Training loss: 2.5419037400875055
Validation loss: 2.525373195895163

Epoch: 5| Step: 7
Training loss: 3.2044505284193288
Validation loss: 2.5496286252477502

Epoch: 5| Step: 8
Training loss: 2.4507960057931624
Validation loss: 2.5516672692206717

Epoch: 5| Step: 9
Training loss: 2.7911336779070215
Validation loss: 2.5552687560564524

Epoch: 5| Step: 10
Training loss: 2.4268067383775267
Validation loss: 2.553079185707882

Epoch: 118| Step: 0
Training loss: 2.0803997238918854
Validation loss: 2.5610746585926814

Epoch: 5| Step: 1
Training loss: 3.1687084609098544
Validation loss: 2.554954229638069

Epoch: 5| Step: 2
Training loss: 2.7981849032447057
Validation loss: 2.531475873881059

Epoch: 5| Step: 3
Training loss: 2.69328669836568
Validation loss: 2.551003792628911

Epoch: 5| Step: 4
Training loss: 2.799883966085248
Validation loss: 2.568414754468185

Epoch: 5| Step: 5
Training loss: 2.980900204528476
Validation loss: 2.537136739046004

Epoch: 5| Step: 6
Training loss: 2.685551402695047
Validation loss: 2.567268676564869

Epoch: 5| Step: 7
Training loss: 3.0969514562136027
Validation loss: 2.544375330070845

Epoch: 5| Step: 8
Training loss: 2.583776948637885
Validation loss: 2.569442713566088

Epoch: 5| Step: 9
Training loss: 3.03499568480133
Validation loss: 2.5455651452175343

Epoch: 5| Step: 10
Training loss: 3.0765562755856917
Validation loss: 2.5565486201301186

Epoch: 119| Step: 0
Training loss: 2.724703179388809
Validation loss: 2.557388340594467

Epoch: 5| Step: 1
Training loss: 2.874751868113604
Validation loss: 2.5658193419649917

Epoch: 5| Step: 2
Training loss: 2.5030336094244614
Validation loss: 2.562469995474562

Epoch: 5| Step: 3
Training loss: 2.638447331969672
Validation loss: 2.5517653916190444

Epoch: 5| Step: 4
Training loss: 2.8431270042709227
Validation loss: 2.5722511855387657

Epoch: 5| Step: 5
Training loss: 2.3026120943664834
Validation loss: 2.537681896124476

Epoch: 5| Step: 6
Training loss: 2.817955152004463
Validation loss: 2.5792335083590747

Epoch: 5| Step: 7
Training loss: 3.0556223967976677
Validation loss: 2.567458480929171

Epoch: 5| Step: 8
Training loss: 2.7174626075677755
Validation loss: 2.5628906780555214

Epoch: 5| Step: 9
Training loss: 3.275197432296261
Validation loss: 2.5597629320881783

Epoch: 5| Step: 10
Training loss: 3.1151010514671995
Validation loss: 2.5869636141775105

Epoch: 120| Step: 0
Training loss: 3.693070293956772
Validation loss: 2.5375984578934436

Epoch: 5| Step: 1
Training loss: 2.97064630277264
Validation loss: 2.5321958358002234

Epoch: 5| Step: 2
Training loss: 2.2295311127789
Validation loss: 2.5655057592841968

Epoch: 5| Step: 3
Training loss: 2.3599921423571106
Validation loss: 2.5657765020145242

Epoch: 5| Step: 4
Training loss: 3.0378264828640615
Validation loss: 2.559944970972872

Epoch: 5| Step: 5
Training loss: 3.0602371263565917
Validation loss: 2.5589909351465963

Epoch: 5| Step: 6
Training loss: 2.654015622315067
Validation loss: 2.576294554399917

Epoch: 5| Step: 7
Training loss: 2.8338056806386915
Validation loss: 2.5534552885532564

Epoch: 5| Step: 8
Training loss: 3.1289902198372883
Validation loss: 2.5801369730043544

Epoch: 5| Step: 9
Training loss: 2.2427411077159607
Validation loss: 2.5597481967575106

Epoch: 5| Step: 10
Training loss: 2.5354995847719364
Validation loss: 2.5674855604585582

Epoch: 121| Step: 0
Training loss: 2.388246237885331
Validation loss: 2.5572330321184285

Epoch: 5| Step: 1
Training loss: 2.969637125883199
Validation loss: 2.5667222706040604

Epoch: 5| Step: 2
Training loss: 2.996924254138964
Validation loss: 2.5414180872770533

Epoch: 5| Step: 3
Training loss: 2.9937587029125523
Validation loss: 2.557781456197607

Epoch: 5| Step: 4
Training loss: 2.490944866475335
Validation loss: 2.539134678978205

Epoch: 5| Step: 5
Training loss: 2.701945141092097
Validation loss: 2.573136350703764

Epoch: 5| Step: 6
Training loss: 3.1628099010748203
Validation loss: 2.5646553799214393

Epoch: 5| Step: 7
Training loss: 2.5933759488557135
Validation loss: 2.549636984925348

Epoch: 5| Step: 8
Training loss: 3.23998036461049
Validation loss: 2.580546977946703

Epoch: 5| Step: 9
Training loss: 3.2587201434407653
Validation loss: 2.556714227915886

Epoch: 5| Step: 10
Training loss: 2.092349594708554
Validation loss: 2.5481601786440096

Epoch: 122| Step: 0
Training loss: 2.789152256138478
Validation loss: 2.553642866939946

Epoch: 5| Step: 1
Training loss: 2.528617148951996
Validation loss: 2.557043429210595

Epoch: 5| Step: 2
Training loss: 3.3999191386761147
Validation loss: 2.567646197503838

Epoch: 5| Step: 3
Training loss: 2.809210570279082
Validation loss: 2.5561604709764207

Epoch: 5| Step: 4
Training loss: 3.2443560965657334
Validation loss: 2.541913197256611

Epoch: 5| Step: 5
Training loss: 2.1974435691835397
Validation loss: 2.570240474434466

Epoch: 5| Step: 6
Training loss: 2.484370777438432
Validation loss: 2.5436775776302984

Epoch: 5| Step: 7
Training loss: 2.724345970410458
Validation loss: 2.5370340200398154

Epoch: 5| Step: 8
Training loss: 2.394755566095211
Validation loss: 2.5429307145192

Epoch: 5| Step: 9
Training loss: 2.9932564601358536
Validation loss: 2.5672246305200552

Epoch: 5| Step: 10
Training loss: 3.2952301116382543
Validation loss: 2.580457061339442

Epoch: 123| Step: 0
Training loss: 2.2370662886885073
Validation loss: 2.5574552468947864

Epoch: 5| Step: 1
Training loss: 2.3542078290283337
Validation loss: 2.556244323268452

Epoch: 5| Step: 2
Training loss: 3.4819050746119427
Validation loss: 2.5326146263453566

Epoch: 5| Step: 3
Training loss: 2.8687478790607797
Validation loss: 2.56333940505289

Epoch: 5| Step: 4
Training loss: 2.683951763498484
Validation loss: 2.5471531962467537

Epoch: 5| Step: 5
Training loss: 3.0290478444745985
Validation loss: 2.5577671915562026

Epoch: 5| Step: 6
Training loss: 2.9141858767657256
Validation loss: 2.5547968214581127

Epoch: 5| Step: 7
Training loss: 2.359511516739372
Validation loss: 2.5694844093603324

Epoch: 5| Step: 8
Training loss: 3.3690491948644787
Validation loss: 2.568497403223961

Epoch: 5| Step: 9
Training loss: 2.9621067607012397
Validation loss: 2.5635488921087544

Epoch: 5| Step: 10
Training loss: 2.334483022373581
Validation loss: 2.565069037813679

Epoch: 124| Step: 0
Training loss: 2.4378432985787444
Validation loss: 2.558841924554021

Epoch: 5| Step: 1
Training loss: 2.937264453291003
Validation loss: 2.5531023279426686

Epoch: 5| Step: 2
Training loss: 3.081433991361041
Validation loss: 2.5406927996292263

Epoch: 5| Step: 3
Training loss: 2.2226576444758916
Validation loss: 2.5472223797503397

Epoch: 5| Step: 4
Training loss: 3.281912745801925
Validation loss: 2.558897992891545

Epoch: 5| Step: 5
Training loss: 3.082551977457247
Validation loss: 2.5587260249893693

Epoch: 5| Step: 6
Training loss: 2.3576026979895026
Validation loss: 2.5545615952044347

Epoch: 5| Step: 7
Training loss: 3.2258390118893785
Validation loss: 2.543232464898091

Epoch: 5| Step: 8
Training loss: 2.9156025353125377
Validation loss: 2.547971903839512

Epoch: 5| Step: 9
Training loss: 2.5310384402933663
Validation loss: 2.5696240472552607

Epoch: 5| Step: 10
Training loss: 2.783723995256857
Validation loss: 2.5595672456288576

Epoch: 125| Step: 0
Training loss: 2.271582931781425
Validation loss: 2.5704862918167297

Epoch: 5| Step: 1
Training loss: 2.9487674595217697
Validation loss: 2.5568456827082855

Epoch: 5| Step: 2
Training loss: 3.2597565556532015
Validation loss: 2.559242424940711

Epoch: 5| Step: 3
Training loss: 2.784626400747853
Validation loss: 2.5669578885509727

Epoch: 5| Step: 4
Training loss: 3.1358349458796924
Validation loss: 2.557488991088544

Epoch: 5| Step: 5
Training loss: 2.391873102439046
Validation loss: 2.5652635770396386

Epoch: 5| Step: 6
Training loss: 2.3924121036148747
Validation loss: 2.5427699049033827

Epoch: 5| Step: 7
Training loss: 2.4013428626703646
Validation loss: 2.562441971524764

Epoch: 5| Step: 8
Training loss: 3.021426456145345
Validation loss: 2.5589593296285336

Epoch: 5| Step: 9
Training loss: 2.793233706837941
Validation loss: 2.5604566164885996

Epoch: 5| Step: 10
Training loss: 3.3122783082876257
Validation loss: 2.587958762567625

Epoch: 126| Step: 0
Training loss: 3.3958646308689224
Validation loss: 2.5639564552971135

Epoch: 5| Step: 1
Training loss: 3.045706500445016
Validation loss: 2.5613915561928478

Epoch: 5| Step: 2
Training loss: 2.379043049003109
Validation loss: 2.554498155750981

Epoch: 5| Step: 3
Training loss: 2.899242525817863
Validation loss: 2.5674796852633905

Epoch: 5| Step: 4
Training loss: 2.9466912156660388
Validation loss: 2.5362883001649066

Epoch: 5| Step: 5
Training loss: 2.6985398582920306
Validation loss: 2.5531183356954483

Epoch: 5| Step: 6
Training loss: 2.696124233801966
Validation loss: 2.5808738703606635

Epoch: 5| Step: 7
Training loss: 2.5673989708625222
Validation loss: 2.5517531900702424

Epoch: 5| Step: 8
Training loss: 2.7913215955340624
Validation loss: 2.5735917673909428

Epoch: 5| Step: 9
Training loss: 3.006975329923015
Validation loss: 2.5629254449903582

Epoch: 5| Step: 10
Training loss: 2.4006939441063793
Validation loss: 2.551696073588334

Epoch: 127| Step: 0
Training loss: 2.7846932688471275
Validation loss: 2.568032676517824

Epoch: 5| Step: 1
Training loss: 3.3014186988490057
Validation loss: 2.5498315523486124

Epoch: 5| Step: 2
Training loss: 2.648676318538557
Validation loss: 2.553855077743392

Epoch: 5| Step: 3
Training loss: 3.0818341365001234
Validation loss: 2.5656370683901577

Epoch: 5| Step: 4
Training loss: 2.4953071417419577
Validation loss: 2.531220060551502

Epoch: 5| Step: 5
Training loss: 2.5304260796779574
Validation loss: 2.588478023386867

Epoch: 5| Step: 6
Training loss: 2.6916363843350153
Validation loss: 2.54871549375148

Epoch: 5| Step: 7
Training loss: 3.5788123124507414
Validation loss: 2.522370643519842

Epoch: 5| Step: 8
Training loss: 2.620931287753365
Validation loss: 2.5520789519107687

Epoch: 5| Step: 9
Training loss: 2.739637966602397
Validation loss: 2.5421266585023705

Epoch: 5| Step: 10
Training loss: 2.2825286626112913
Validation loss: 2.571183415512914

Epoch: 128| Step: 0
Training loss: 2.618181364463998
Validation loss: 2.5529983564406993

Epoch: 5| Step: 1
Training loss: 2.761749396902754
Validation loss: 2.579042544747767

Epoch: 5| Step: 2
Training loss: 3.761241339853902
Validation loss: 2.547103544442274

Epoch: 5| Step: 3
Training loss: 3.1078946217330734
Validation loss: 2.5469683779704115

Epoch: 5| Step: 4
Training loss: 2.547974331677078
Validation loss: 2.5374689955095

Epoch: 5| Step: 5
Training loss: 2.25428628609999
Validation loss: 2.558763854230563

Epoch: 5| Step: 6
Training loss: 2.9305649727604255
Validation loss: 2.5722082513830395

Epoch: 5| Step: 7
Training loss: 2.5946969750971163
Validation loss: 2.5393395138205563

Epoch: 5| Step: 8
Training loss: 2.950030446299536
Validation loss: 2.5444582538875125

Epoch: 5| Step: 9
Training loss: 2.513757996169413
Validation loss: 2.5584447904245957

Epoch: 5| Step: 10
Training loss: 2.502843098476619
Validation loss: 2.5473227370013096

Epoch: 129| Step: 0
Training loss: 3.2224456903277385
Validation loss: 2.567687816138952

Epoch: 5| Step: 1
Training loss: 2.7558668151365726
Validation loss: 2.553520287972007

Epoch: 5| Step: 2
Training loss: 2.941803559602268
Validation loss: 2.563397323204086

Epoch: 5| Step: 3
Training loss: 2.7999984945565672
Validation loss: 2.5448748622994963

Epoch: 5| Step: 4
Training loss: 2.611488354488425
Validation loss: 2.5829971669007152

Epoch: 5| Step: 5
Training loss: 2.7016779383479728
Validation loss: 2.566383637294497

Epoch: 5| Step: 6
Training loss: 3.0473191157696236
Validation loss: 2.5527625557318068

Epoch: 5| Step: 7
Training loss: 3.121207109858594
Validation loss: 2.550079972430455

Epoch: 5| Step: 8
Training loss: 2.595001562187886
Validation loss: 2.5345276931044296

Epoch: 5| Step: 9
Training loss: 1.9242745902864336
Validation loss: 2.559570784248958

Epoch: 5| Step: 10
Training loss: 2.7212268464939386
Validation loss: 2.5641153098058584

Epoch: 130| Step: 0
Training loss: 3.829805464622268
Validation loss: 2.5677233987183348

Epoch: 5| Step: 1
Training loss: 2.8460836372122524
Validation loss: 2.535184856686774

Epoch: 5| Step: 2
Training loss: 2.47022695664714
Validation loss: 2.5478891849347955

Epoch: 5| Step: 3
Training loss: 2.8844594825283396
Validation loss: 2.553585136149523

Epoch: 5| Step: 4
Training loss: 2.8326310989195043
Validation loss: 2.5951004367520842

Epoch: 5| Step: 5
Training loss: 2.211885498401382
Validation loss: 2.5640849812419866

Epoch: 5| Step: 6
Training loss: 2.196130783327912
Validation loss: 2.5589175580116525

Epoch: 5| Step: 7
Training loss: 3.201668608262921
Validation loss: 2.55016999000807

Epoch: 5| Step: 8
Training loss: 2.295205683913694
Validation loss: 2.5347418450898482

Epoch: 5| Step: 9
Training loss: 3.1977944283416058
Validation loss: 2.5279021542601967

Epoch: 5| Step: 10
Training loss: 2.4378511224842976
Validation loss: 2.516202247553305

Epoch: 131| Step: 0
Training loss: 2.739080772186629
Validation loss: 2.540037094380198

Epoch: 5| Step: 1
Training loss: 2.4049958763166512
Validation loss: 2.5461177348122908

Epoch: 5| Step: 2
Training loss: 2.8281110057168437
Validation loss: 2.5268303730337545

Epoch: 5| Step: 3
Training loss: 3.304323577682772
Validation loss: 2.5624860077362657

Epoch: 5| Step: 4
Training loss: 2.4296148847418553
Validation loss: 2.539286400804374

Epoch: 5| Step: 5
Training loss: 2.872534648530255
Validation loss: 2.522231697981878

Epoch: 5| Step: 6
Training loss: 2.9446458947546827
Validation loss: 2.569439068313498

Epoch: 5| Step: 7
Training loss: 2.6284924843288673
Validation loss: 2.555496396336659

Epoch: 5| Step: 8
Training loss: 3.3761976024596803
Validation loss: 2.5509806544705715

Epoch: 5| Step: 9
Training loss: 2.629273795611872
Validation loss: 2.5654456023443317

Epoch: 5| Step: 10
Training loss: 2.413898845174567
Validation loss: 2.5562548626537733

Epoch: 132| Step: 0
Training loss: 2.69466182207669
Validation loss: 2.536507837077303

Epoch: 5| Step: 1
Training loss: 2.8724474978649694
Validation loss: 2.557796750106088

Epoch: 5| Step: 2
Training loss: 2.7859268299525324
Validation loss: 2.5622783578040287

Epoch: 5| Step: 3
Training loss: 3.1074068367604375
Validation loss: 2.549290741219302

Epoch: 5| Step: 4
Training loss: 2.923576308461348
Validation loss: 2.542167546305232

Epoch: 5| Step: 5
Training loss: 3.107774945814218
Validation loss: 2.5399225905820533

Epoch: 5| Step: 6
Training loss: 1.8292109206747247
Validation loss: 2.5677068040926385

Epoch: 5| Step: 7
Training loss: 3.121310077374738
Validation loss: 2.5520948385080184

Epoch: 5| Step: 8
Training loss: 2.709170950451361
Validation loss: 2.565969206222707

Epoch: 5| Step: 9
Training loss: 3.0293179676691526
Validation loss: 2.5585929524297475

Epoch: 5| Step: 10
Training loss: 2.1500749486235327
Validation loss: 2.5653309764856775

Epoch: 133| Step: 0
Training loss: 2.93956537887818
Validation loss: 2.5653722939100105

Epoch: 5| Step: 1
Training loss: 2.5195343727269894
Validation loss: 2.556514900627257

Epoch: 5| Step: 2
Training loss: 3.24376108979845
Validation loss: 2.5670800865191383

Epoch: 5| Step: 3
Training loss: 2.877208193409058
Validation loss: 2.545070352830801

Epoch: 5| Step: 4
Training loss: 2.8788913431389846
Validation loss: 2.549466878591617

Epoch: 5| Step: 5
Training loss: 2.607663078438596
Validation loss: 2.5532988743478398

Epoch: 5| Step: 6
Training loss: 2.5315813389307795
Validation loss: 2.5589080174169556

Epoch: 5| Step: 7
Training loss: 2.5207314168541495
Validation loss: 2.5652604620097508

Epoch: 5| Step: 8
Training loss: 2.434543577338914
Validation loss: 2.557513864653828

Epoch: 5| Step: 9
Training loss: 2.7679083929283257
Validation loss: 2.5261644518566757

Epoch: 5| Step: 10
Training loss: 3.4810497342759184
Validation loss: 2.564358477249359

Epoch: 134| Step: 0
Training loss: 2.946747690729531
Validation loss: 2.5642696725773426

Epoch: 5| Step: 1
Training loss: 2.1442477346316924
Validation loss: 2.547080227930104

Epoch: 5| Step: 2
Training loss: 2.814130522368113
Validation loss: 2.552758393065336

Epoch: 5| Step: 3
Training loss: 3.2765000613425204
Validation loss: 2.542921177962059

Epoch: 5| Step: 4
Training loss: 2.6240215294408302
Validation loss: 2.5423603741822682

Epoch: 5| Step: 5
Training loss: 3.278082344934071
Validation loss: 2.5588942289255807

Epoch: 5| Step: 6
Training loss: 2.6854208954826384
Validation loss: 2.554911813568439

Epoch: 5| Step: 7
Training loss: 1.882232323368856
Validation loss: 2.5628917623724936

Epoch: 5| Step: 8
Training loss: 2.874997180439769
Validation loss: 2.564969091553209

Epoch: 5| Step: 9
Training loss: 3.0499221041378406
Validation loss: 2.5603715268959766

Epoch: 5| Step: 10
Training loss: 2.7877739673316646
Validation loss: 2.549573462151056

Epoch: 135| Step: 0
Training loss: 2.647096637692596
Validation loss: 2.5656983299508087

Epoch: 5| Step: 1
Training loss: 2.951934574518678
Validation loss: 2.5429216901011387

Epoch: 5| Step: 2
Training loss: 2.5185918905077487
Validation loss: 2.5777492026812183

Epoch: 5| Step: 3
Training loss: 3.11757831465942
Validation loss: 2.5500753952146757

Epoch: 5| Step: 4
Training loss: 2.3706398141339258
Validation loss: 2.5724714044267776

Epoch: 5| Step: 5
Training loss: 2.5934232942656594
Validation loss: 2.552255492004934

Epoch: 5| Step: 6
Training loss: 2.8610053078883193
Validation loss: 2.5559225888497457

Epoch: 5| Step: 7
Training loss: 3.2028436304582515
Validation loss: 2.5648973487258595

Epoch: 5| Step: 8
Training loss: 2.7822166220426143
Validation loss: 2.5688730440590115

Epoch: 5| Step: 9
Training loss: 2.5946721655240785
Validation loss: 2.556719042920475

Epoch: 5| Step: 10
Training loss: 2.9362520854320566
Validation loss: 2.5444030164798046

Epoch: 136| Step: 0
Training loss: 2.5242380106647757
Validation loss: 2.5471224845478773

Epoch: 5| Step: 1
Training loss: 2.714985839638217
Validation loss: 2.5385032422834377

Epoch: 5| Step: 2
Training loss: 2.8353760218644317
Validation loss: 2.553206283161676

Epoch: 5| Step: 3
Training loss: 2.90491709343006
Validation loss: 2.5543245688267513

Epoch: 5| Step: 4
Training loss: 2.3592512085630477
Validation loss: 2.542183964773977

Epoch: 5| Step: 5
Training loss: 2.0375049239959195
Validation loss: 2.56013232120538

Epoch: 5| Step: 6
Training loss: 3.5801290039176497
Validation loss: 2.5528642321504744

Epoch: 5| Step: 7
Training loss: 3.0786490212165143
Validation loss: 2.5690260352378886

Epoch: 5| Step: 8
Training loss: 2.7299281991871664
Validation loss: 2.51990619072193

Epoch: 5| Step: 9
Training loss: 2.8641337833805114
Validation loss: 2.589814025642007

Epoch: 5| Step: 10
Training loss: 2.7666506831921547
Validation loss: 2.581592273472716

Epoch: 137| Step: 0
Training loss: 3.0155321808598345
Validation loss: 2.553710799967294

Epoch: 5| Step: 1
Training loss: 3.123192378812231
Validation loss: 2.5734594206970924

Epoch: 5| Step: 2
Training loss: 3.8882381364004552
Validation loss: 2.5767649046423866

Epoch: 5| Step: 3
Training loss: 2.318450591711999
Validation loss: 2.5666251415185166

Epoch: 5| Step: 4
Training loss: 2.6544867553610447
Validation loss: 2.565185613210024

Epoch: 5| Step: 5
Training loss: 2.4612428505998563
Validation loss: 2.548324382927252

Epoch: 5| Step: 6
Training loss: 2.553498064143857
Validation loss: 2.574904792452031

Epoch: 5| Step: 7
Training loss: 2.692908765956459
Validation loss: 2.5575930336350665

Epoch: 5| Step: 8
Training loss: 3.166394539902477
Validation loss: 2.574958996715613

Epoch: 5| Step: 9
Training loss: 2.3744987159543993
Validation loss: 2.5419216982907167

Epoch: 5| Step: 10
Training loss: 1.9839686781233559
Validation loss: 2.5743455436873632

Epoch: 138| Step: 0
Training loss: 2.404212584517079
Validation loss: 2.5643272098138374

Epoch: 5| Step: 1
Training loss: 2.9078794443991622
Validation loss: 2.5371652036660985

Epoch: 5| Step: 2
Training loss: 2.6478841648062956
Validation loss: 2.549029413124459

Epoch: 5| Step: 3
Training loss: 2.5496231885266694
Validation loss: 2.5629491664983073

Epoch: 5| Step: 4
Training loss: 2.8441249055327167
Validation loss: 2.554810914034666

Epoch: 5| Step: 5
Training loss: 2.6469110011295034
Validation loss: 2.555219299071615

Epoch: 5| Step: 6
Training loss: 2.6767600392468394
Validation loss: 2.5619555804655283

Epoch: 5| Step: 7
Training loss: 2.9808618128859936
Validation loss: 2.5683925048058867

Epoch: 5| Step: 8
Training loss: 2.784433493122885
Validation loss: 2.5571378985750224

Epoch: 5| Step: 9
Training loss: 3.014301859683921
Validation loss: 2.540261064700339

Epoch: 5| Step: 10
Training loss: 3.213757986313264
Validation loss: 2.5759868606856986

Epoch: 139| Step: 0
Training loss: 2.8467693020307028
Validation loss: 2.5604771459037527

Epoch: 5| Step: 1
Training loss: 3.353779661862822
Validation loss: 2.564471989951758

Epoch: 5| Step: 2
Training loss: 3.2138797988110968
Validation loss: 2.5383105809321016

Epoch: 5| Step: 3
Training loss: 2.242557721027736
Validation loss: 2.5299735730615054

Epoch: 5| Step: 4
Training loss: 2.9032835228286302
Validation loss: 2.565518573929139

Epoch: 5| Step: 5
Training loss: 2.151412956453967
Validation loss: 2.5500165938992208

Epoch: 5| Step: 6
Training loss: 2.9629018905314837
Validation loss: 2.5112681176545006

Epoch: 5| Step: 7
Training loss: 2.2448977794187117
Validation loss: 2.5475813440244015

Epoch: 5| Step: 8
Training loss: 2.467236501582779
Validation loss: 2.5523588177931433

Epoch: 5| Step: 9
Training loss: 3.4297528445334016
Validation loss: 2.5534920463284174

Epoch: 5| Step: 10
Training loss: 2.6571591784742132
Validation loss: 2.560412005694243

Epoch: 140| Step: 0
Training loss: 2.839411517678202
Validation loss: 2.5393566835171058

Epoch: 5| Step: 1
Training loss: 2.9277719974963436
Validation loss: 2.5229253624800707

Epoch: 5| Step: 2
Training loss: 2.6831489649710276
Validation loss: 2.5476976771247943

Epoch: 5| Step: 3
Training loss: 3.2213725544623917
Validation loss: 2.5364205740263586

Epoch: 5| Step: 4
Training loss: 2.4110487610020845
Validation loss: 2.527409623310144

Epoch: 5| Step: 5
Training loss: 2.4574049042379653
Validation loss: 2.5402552587453386

Epoch: 5| Step: 6
Training loss: 1.9592387831944742
Validation loss: 2.5525969848321544

Epoch: 5| Step: 7
Training loss: 2.9703201157393493
Validation loss: 2.535107512013233

Epoch: 5| Step: 8
Training loss: 2.653149579297125
Validation loss: 2.5720824108500646

Epoch: 5| Step: 9
Training loss: 3.665102032416017
Validation loss: 2.540075055609689

Epoch: 5| Step: 10
Training loss: 2.2882163921944367
Validation loss: 2.520039793437037

Epoch: 141| Step: 0
Training loss: 2.514640473288359
Validation loss: 2.5340104004914488

Epoch: 5| Step: 1
Training loss: 2.818069199859676
Validation loss: 2.5598390260568413

Epoch: 5| Step: 2
Training loss: 2.5629724206649893
Validation loss: 2.5240370155320413

Epoch: 5| Step: 3
Training loss: 3.0005058815721593
Validation loss: 2.556107173912779

Epoch: 5| Step: 4
Training loss: 2.7193977198246757
Validation loss: 2.5325581360592335

Epoch: 5| Step: 5
Training loss: 2.738805527500677
Validation loss: 2.552030100130184

Epoch: 5| Step: 6
Training loss: 2.449099110384088
Validation loss: 2.5426908818547447

Epoch: 5| Step: 7
Training loss: 3.2487406124553253
Validation loss: 2.532332655334082

Epoch: 5| Step: 8
Training loss: 3.198686604380303
Validation loss: 2.5400838585129057

Epoch: 5| Step: 9
Training loss: 2.6026488089548128
Validation loss: 2.5585994091345525

Epoch: 5| Step: 10
Training loss: 2.6065336736263447
Validation loss: 2.5655468920289377

Epoch: 142| Step: 0
Training loss: 3.3748232477316757
Validation loss: 2.5593362762351597

Epoch: 5| Step: 1
Training loss: 2.854309264099122
Validation loss: 2.56397464399189

Epoch: 5| Step: 2
Training loss: 3.1729239998271623
Validation loss: 2.5427375099698826

Epoch: 5| Step: 3
Training loss: 2.808281341282756
Validation loss: 2.5507788348844884

Epoch: 5| Step: 4
Training loss: 2.4114708676983962
Validation loss: 2.555573103875535

Epoch: 5| Step: 5
Training loss: 2.7396586786118027
Validation loss: 2.560263690617088

Epoch: 5| Step: 6
Training loss: 2.6410643985094295
Validation loss: 2.585073763707573

Epoch: 5| Step: 7
Training loss: 2.921579601022759
Validation loss: 2.5530972992664553

Epoch: 5| Step: 8
Training loss: 2.3992873683546216
Validation loss: 2.556687846503223

Epoch: 5| Step: 9
Training loss: 2.6678672313225866
Validation loss: 2.5573161715703554

Epoch: 5| Step: 10
Training loss: 2.3472127130480076
Validation loss: 2.557438641777241

Epoch: 143| Step: 0
Training loss: 3.1347723179445683
Validation loss: 2.56797586721435

Epoch: 5| Step: 1
Training loss: 2.761300623210806
Validation loss: 2.562346603160159

Epoch: 5| Step: 2
Training loss: 2.934156747324705
Validation loss: 2.566975989065699

Epoch: 5| Step: 3
Training loss: 2.8789494794604584
Validation loss: 2.5805649245322284

Epoch: 5| Step: 4
Training loss: 2.255339538657394
Validation loss: 2.543717250253867

Epoch: 5| Step: 5
Training loss: 2.3253848957059753
Validation loss: 2.5587287932948364

Epoch: 5| Step: 6
Training loss: 3.210287580591131
Validation loss: 2.554547689921669

Epoch: 5| Step: 7
Training loss: 2.629376804359348
Validation loss: 2.557850783206524

Epoch: 5| Step: 8
Training loss: 2.987547461479855
Validation loss: 2.5239056731650535

Epoch: 5| Step: 9
Training loss: 2.575112727392115
Validation loss: 2.540876461053128

Epoch: 5| Step: 10
Training loss: 2.666286938174909
Validation loss: 2.5867005231746623

Epoch: 144| Step: 0
Training loss: 2.5673062910572337
Validation loss: 2.5580056908774997

Epoch: 5| Step: 1
Training loss: 2.0895739229648975
Validation loss: 2.550137946434907

Epoch: 5| Step: 2
Training loss: 2.315908549010334
Validation loss: 2.551131599435657

Epoch: 5| Step: 3
Training loss: 2.897253735587207
Validation loss: 2.55373237845717

Epoch: 5| Step: 4
Training loss: 1.821832963252406
Validation loss: 2.5240637707116544

Epoch: 5| Step: 5
Training loss: 3.3605628464073276
Validation loss: 2.559651251730481

Epoch: 5| Step: 6
Training loss: 2.925387795327614
Validation loss: 2.531402879010455

Epoch: 5| Step: 7
Training loss: 2.943816677885293
Validation loss: 2.5374943522454054

Epoch: 5| Step: 8
Training loss: 2.8129590825408086
Validation loss: 2.5713955904686023

Epoch: 5| Step: 9
Training loss: 3.3557718515333335
Validation loss: 2.5303105745907506

Epoch: 5| Step: 10
Training loss: 3.1038889579377686
Validation loss: 2.53956506493018

Epoch: 145| Step: 0
Training loss: 2.580986515664692
Validation loss: 2.5254871483295145

Epoch: 5| Step: 1
Training loss: 2.426967361582811
Validation loss: 2.5481185348410897

Epoch: 5| Step: 2
Training loss: 2.808211384133772
Validation loss: 2.5539636438474003

Epoch: 5| Step: 3
Training loss: 2.5197196476014043
Validation loss: 2.5527774729855293

Epoch: 5| Step: 4
Training loss: 3.0583022016418493
Validation loss: 2.538501168952868

Epoch: 5| Step: 5
Training loss: 2.468717357564557
Validation loss: 2.5374064199255093

Epoch: 5| Step: 6
Training loss: 2.799661196919263
Validation loss: 2.579247039025576

Epoch: 5| Step: 7
Training loss: 3.4355341058247633
Validation loss: 2.569073073493827

Epoch: 5| Step: 8
Training loss: 2.764659562218213
Validation loss: 2.5744150544910713

Epoch: 5| Step: 9
Training loss: 2.6569167254071573
Validation loss: 2.5754687853345732

Epoch: 5| Step: 10
Training loss: 3.0288151666083163
Validation loss: 2.566349602484577

Epoch: 146| Step: 0
Training loss: 2.6521265674152588
Validation loss: 2.562414908728354

Epoch: 5| Step: 1
Training loss: 1.8023192484644945
Validation loss: 2.558239113319026

Epoch: 5| Step: 2
Training loss: 2.660722445423346
Validation loss: 2.5495650710940323

Epoch: 5| Step: 3
Training loss: 2.991272470188191
Validation loss: 2.5482289349043374

Epoch: 5| Step: 4
Training loss: 3.098503853091765
Validation loss: 2.552488764355818

Epoch: 5| Step: 5
Training loss: 3.6071614665586007
Validation loss: 2.541364044243198

Epoch: 5| Step: 6
Training loss: 3.308374390879831
Validation loss: 2.5465765125825466

Epoch: 5| Step: 7
Training loss: 2.2245473208325532
Validation loss: 2.5571182506623216

Epoch: 5| Step: 8
Training loss: 2.6202349328859094
Validation loss: 2.5517518146923295

Epoch: 5| Step: 9
Training loss: 2.6783470604795405
Validation loss: 2.560249160436091

Epoch: 5| Step: 10
Training loss: 2.1700127391177566
Validation loss: 2.5370130968036784

Epoch: 147| Step: 0
Training loss: 1.977274348119791
Validation loss: 2.5610590699424303

Epoch: 5| Step: 1
Training loss: 2.9610041708976436
Validation loss: 2.571669395592655

Epoch: 5| Step: 2
Training loss: 2.6778096105689295
Validation loss: 2.555943653179068

Epoch: 5| Step: 3
Training loss: 2.4573291300825466
Validation loss: 2.5445069910992992

Epoch: 5| Step: 4
Training loss: 2.8314907215848155
Validation loss: 2.5416588167028644

Epoch: 5| Step: 5
Training loss: 2.5518032205704406
Validation loss: 2.572105817168883

Epoch: 5| Step: 6
Training loss: 2.9435051753454005
Validation loss: 2.5803464236894564

Epoch: 5| Step: 7
Training loss: 2.8728042178499877
Validation loss: 2.5433584799590703

Epoch: 5| Step: 8
Training loss: 2.7312843512637963
Validation loss: 2.5496759695790088

Epoch: 5| Step: 9
Training loss: 3.641335348483738
Validation loss: 2.5712814462113047

Epoch: 5| Step: 10
Training loss: 2.709673936097445
Validation loss: 2.574527652792392

Epoch: 148| Step: 0
Training loss: 2.9625608478204417
Validation loss: 2.5578442559567516

Epoch: 5| Step: 1
Training loss: 2.5036930463600857
Validation loss: 2.557731602773288

Epoch: 5| Step: 2
Training loss: 2.5576483224646522
Validation loss: 2.541686017793056

Epoch: 5| Step: 3
Training loss: 2.478296869963602
Validation loss: 2.553961772784002

Epoch: 5| Step: 4
Training loss: 2.387052571977475
Validation loss: 2.560164314788614

Epoch: 5| Step: 5
Training loss: 2.5490201563496524
Validation loss: 2.5689498681094998

Epoch: 5| Step: 6
Training loss: 3.190669858432209
Validation loss: 2.5354923543939734

Epoch: 5| Step: 7
Training loss: 2.9532410936898628
Validation loss: 2.5546030687460064

Epoch: 5| Step: 8
Training loss: 2.843793260853122
Validation loss: 2.5667891693153133

Epoch: 5| Step: 9
Training loss: 3.3416788692362553
Validation loss: 2.5523368038217047

Epoch: 5| Step: 10
Training loss: 2.5962329607915464
Validation loss: 2.5464795996783973

Epoch: 149| Step: 0
Training loss: 2.786722264609809
Validation loss: 2.5500426411908945

Epoch: 5| Step: 1
Training loss: 2.688955223519313
Validation loss: 2.570943815271528

Epoch: 5| Step: 2
Training loss: 3.0122611303320914
Validation loss: 2.539566175358151

Epoch: 5| Step: 3
Training loss: 2.7104416099610598
Validation loss: 2.558175163781458

Epoch: 5| Step: 4
Training loss: 2.782875100598481
Validation loss: 2.5429104865311456

Epoch: 5| Step: 5
Training loss: 2.7361683223657627
Validation loss: 2.54135462235499

Epoch: 5| Step: 6
Training loss: 2.5184875692333795
Validation loss: 2.5629172676960597

Epoch: 5| Step: 7
Training loss: 2.6732379493281226
Validation loss: 2.5516504887935363

Epoch: 5| Step: 8
Training loss: 3.3773995805405885
Validation loss: 2.566634541558067

Epoch: 5| Step: 9
Training loss: 1.7224579781332654
Validation loss: 2.54416780616603

Epoch: 5| Step: 10
Training loss: 3.3800353175919544
Validation loss: 2.5280976663449346

Epoch: 150| Step: 0
Training loss: 3.4356054460435046
Validation loss: 2.5405073408294725

Epoch: 5| Step: 1
Training loss: 2.160616558346466
Validation loss: 2.53014002965205

Epoch: 5| Step: 2
Training loss: 3.0804655983986384
Validation loss: 2.532479791990533

Epoch: 5| Step: 3
Training loss: 3.6674383102876624
Validation loss: 2.559001323967854

Epoch: 5| Step: 4
Training loss: 2.8627516190328826
Validation loss: 2.564678782551355

Epoch: 5| Step: 5
Training loss: 2.546563158661302
Validation loss: 2.544942932165192

Epoch: 5| Step: 6
Training loss: 2.0305388159293103
Validation loss: 2.516850215104601

Epoch: 5| Step: 7
Training loss: 2.86154959280501
Validation loss: 2.5378129649417476

Epoch: 5| Step: 8
Training loss: 2.908798413039762
Validation loss: 2.544048277466815

Epoch: 5| Step: 9
Training loss: 2.067067723685946
Validation loss: 2.5566779165532094

Epoch: 5| Step: 10
Training loss: 2.2539033939336868
Validation loss: 2.544741807892394

Epoch: 151| Step: 0
Training loss: 2.8007153619015113
Validation loss: 2.560749705749096

Epoch: 5| Step: 1
Training loss: 2.595466689111912
Validation loss: 2.5716132009660093

Epoch: 5| Step: 2
Training loss: 3.0155166843707333
Validation loss: 2.565775840565517

Epoch: 5| Step: 3
Training loss: 2.384756627171293
Validation loss: 2.570252931335144

Epoch: 5| Step: 4
Training loss: 2.581901789433665
Validation loss: 2.536823937096706

Epoch: 5| Step: 5
Training loss: 2.539726663435138
Validation loss: 2.5524160841657615

Epoch: 5| Step: 6
Training loss: 2.9148494690752322
Validation loss: 2.5430848727242448

Epoch: 5| Step: 7
Training loss: 2.485071816279737
Validation loss: 2.56038597778276

Epoch: 5| Step: 8
Training loss: 2.516180131210354
Validation loss: 2.5407245602301565

Epoch: 5| Step: 9
Training loss: 2.9666724715729687
Validation loss: 2.547583294240304

Epoch: 5| Step: 10
Training loss: 3.4579497588056176
Validation loss: 2.540799634712673

Epoch: 152| Step: 0
Training loss: 2.7285063626699446
Validation loss: 2.5615256913603734

Epoch: 5| Step: 1
Training loss: 2.384772023435315
Validation loss: 2.5308857580643602

Epoch: 5| Step: 2
Training loss: 2.9478129086695857
Validation loss: 2.529484938490815

Epoch: 5| Step: 3
Training loss: 3.134069785017302
Validation loss: 2.5696629770993282

Epoch: 5| Step: 4
Training loss: 2.6529347992961316
Validation loss: 2.522497829835244

Epoch: 5| Step: 5
Training loss: 2.6597713690572613
Validation loss: 2.570752099753262

Epoch: 5| Step: 6
Training loss: 2.9393066369748753
Validation loss: 2.5622214889540733

Epoch: 5| Step: 7
Training loss: 3.0297995961204047
Validation loss: 2.536046031876513

Epoch: 5| Step: 8
Training loss: 2.423509108016094
Validation loss: 2.5607661402290187

Epoch: 5| Step: 9
Training loss: 2.56113751173261
Validation loss: 2.5511927892753006

Epoch: 5| Step: 10
Training loss: 3.017002878017652
Validation loss: 2.5428066699458665

Epoch: 153| Step: 0
Training loss: 2.7529281286023433
Validation loss: 2.575171246854183

Epoch: 5| Step: 1
Training loss: 3.0860858350425056
Validation loss: 2.605565318577561

Epoch: 5| Step: 2
Training loss: 3.092013709922489
Validation loss: 2.5493007039660913

Epoch: 5| Step: 3
Training loss: 2.188328722241733
Validation loss: 2.566938413676745

Epoch: 5| Step: 4
Training loss: 2.7909636869730057
Validation loss: 2.566457946709176

Epoch: 5| Step: 5
Training loss: 2.827507668239405
Validation loss: 2.5728356065187308

Epoch: 5| Step: 6
Training loss: 2.5833542012838215
Validation loss: 2.5390331726652278

Epoch: 5| Step: 7
Training loss: 2.710990443523453
Validation loss: 2.565001375620611

Epoch: 5| Step: 8
Training loss: 2.6136536382775257
Validation loss: 2.567750499415482

Epoch: 5| Step: 9
Training loss: 3.3149331711236822
Validation loss: 2.53741188888456

Epoch: 5| Step: 10
Training loss: 2.2595118690916767
Validation loss: 2.545123250460426

Epoch: 154| Step: 0
Training loss: 2.9353470724793493
Validation loss: 2.541854284278791

Epoch: 5| Step: 1
Training loss: 3.1042631676200996
Validation loss: 2.5436382893919167

Epoch: 5| Step: 2
Training loss: 2.2661058639079483
Validation loss: 2.541569725244197

Epoch: 5| Step: 3
Training loss: 2.468038625473644
Validation loss: 2.544285251564277

Epoch: 5| Step: 4
Training loss: 3.5327084660554906
Validation loss: 2.577314133096532

Epoch: 5| Step: 5
Training loss: 3.131043959975151
Validation loss: 2.5577686929956447

Epoch: 5| Step: 6
Training loss: 2.3191975698857705
Validation loss: 2.558279227524743

Epoch: 5| Step: 7
Training loss: 1.9157724021966787
Validation loss: 2.559491149589858

Epoch: 5| Step: 8
Training loss: 2.648910345217122
Validation loss: 2.5686677149145463

Epoch: 5| Step: 9
Training loss: 2.673963210355687
Validation loss: 2.5505125772416277

Epoch: 5| Step: 10
Training loss: 3.1517156379347333
Validation loss: 2.553968138810628

Epoch: 155| Step: 0
Training loss: 3.5087352465083956
Validation loss: 2.5296353398952705

Epoch: 5| Step: 1
Training loss: 2.904874086261098
Validation loss: 2.5498044612790776

Epoch: 5| Step: 2
Training loss: 2.1987028719571984
Validation loss: 2.572701134799657

Epoch: 5| Step: 3
Training loss: 3.2630197454492817
Validation loss: 2.550263730855356

Epoch: 5| Step: 4
Training loss: 3.40137629982809
Validation loss: 2.554025332963509

Epoch: 5| Step: 5
Training loss: 2.9555090913331052
Validation loss: 2.576799895273009

Epoch: 5| Step: 6
Training loss: 2.375146158639999
Validation loss: 2.565336340943001

Epoch: 5| Step: 7
Training loss: 2.7232465719770342
Validation loss: 2.5205265883314536

Epoch: 5| Step: 8
Training loss: 1.9901639347507574
Validation loss: 2.566818656930528

Epoch: 5| Step: 9
Training loss: 1.9516196591487365
Validation loss: 2.5507754810561174

Epoch: 5| Step: 10
Training loss: 2.534750601785259
Validation loss: 2.558177343427358

Epoch: 156| Step: 0
Training loss: 2.40282543284567
Validation loss: 2.5471033371048084

Epoch: 5| Step: 1
Training loss: 2.809681645886756
Validation loss: 2.5377398927265347

Epoch: 5| Step: 2
Training loss: 2.3599895157015403
Validation loss: 2.5581889260846205

Epoch: 5| Step: 3
Training loss: 2.6493629481569516
Validation loss: 2.524358689635142

Epoch: 5| Step: 4
Training loss: 2.5728288293174577
Validation loss: 2.5384092277138306

Epoch: 5| Step: 5
Training loss: 2.582549765920694
Validation loss: 2.5202921723209473

Epoch: 5| Step: 6
Training loss: 2.544036125568389
Validation loss: 2.5259227126318167

Epoch: 5| Step: 7
Training loss: 2.8730047185256935
Validation loss: 2.55138399354397

Epoch: 5| Step: 8
Training loss: 2.6386431417870257
Validation loss: 2.543728022951471

Epoch: 5| Step: 9
Training loss: 3.537230297361865
Validation loss: 2.5362854052767467

Epoch: 5| Step: 10
Training loss: 3.251584767050438
Validation loss: 2.5611416717910918

Epoch: 157| Step: 0
Training loss: 2.632277346593331
Validation loss: 2.563807957290019

Epoch: 5| Step: 1
Training loss: 2.9288670726240826
Validation loss: 2.5576023465873092

Epoch: 5| Step: 2
Training loss: 2.8204754811374033
Validation loss: 2.5550658965681077

Epoch: 5| Step: 3
Training loss: 1.9552989610151748
Validation loss: 2.537668995463373

Epoch: 5| Step: 4
Training loss: 2.4176050753870264
Validation loss: 2.5595705508784654

Epoch: 5| Step: 5
Training loss: 2.967292990273207
Validation loss: 2.5736733245181873

Epoch: 5| Step: 6
Training loss: 2.2387373161702087
Validation loss: 2.542584882953487

Epoch: 5| Step: 7
Training loss: 2.665591877667805
Validation loss: 2.555295429021498

Epoch: 5| Step: 8
Training loss: 3.014003337400091
Validation loss: 2.5192315936721723

Epoch: 5| Step: 9
Training loss: 3.3327521453271345
Validation loss: 2.5506246597509286

Epoch: 5| Step: 10
Training loss: 3.3356275928209196
Validation loss: 2.5509913241381983

Epoch: 158| Step: 0
Training loss: 2.470578639094632
Validation loss: 2.541231845098637

Epoch: 5| Step: 1
Training loss: 2.5725844525264585
Validation loss: 2.535609228990448

Epoch: 5| Step: 2
Training loss: 2.9449195498502725
Validation loss: 2.5335712026772788

Epoch: 5| Step: 3
Training loss: 2.288397682694727
Validation loss: 2.56325917236997

Epoch: 5| Step: 4
Training loss: 3.133510445262835
Validation loss: 2.549290332933905

Epoch: 5| Step: 5
Training loss: 2.7114037544266703
Validation loss: 2.5330351967265967

Epoch: 5| Step: 6
Training loss: 2.9347058256980767
Validation loss: 2.5297091792709585

Epoch: 5| Step: 7
Training loss: 2.9249880929036154
Validation loss: 2.5567085595950316

Epoch: 5| Step: 8
Training loss: 2.512069084450603
Validation loss: 2.582195070577271

Epoch: 5| Step: 9
Training loss: 2.996309871910905
Validation loss: 2.5496630350896154

Epoch: 5| Step: 10
Training loss: 2.5336268062593583
Validation loss: 2.565859782277883

Epoch: 159| Step: 0
Training loss: 2.6460027164897975
Validation loss: 2.5267607006904598

Epoch: 5| Step: 1
Training loss: 2.9569220781015444
Validation loss: 2.5514576295365603

Epoch: 5| Step: 2
Training loss: 3.154037153103809
Validation loss: 2.55348345831699

Epoch: 5| Step: 3
Training loss: 2.2499499845243958
Validation loss: 2.5272440717845135

Epoch: 5| Step: 4
Training loss: 3.0165486082576964
Validation loss: 2.5402165523759503

Epoch: 5| Step: 5
Training loss: 2.5569917045819732
Validation loss: 2.55032281446884

Epoch: 5| Step: 6
Training loss: 2.3308560526884734
Validation loss: 2.5151678480248933

Epoch: 5| Step: 7
Training loss: 2.8787003628571295
Validation loss: 2.534920908337339

Epoch: 5| Step: 8
Training loss: 2.570058236111706
Validation loss: 2.5573071001753074

Epoch: 5| Step: 9
Training loss: 3.128809171354097
Validation loss: 2.5234988310630504

Epoch: 5| Step: 10
Training loss: 2.803727434588787
Validation loss: 2.5520636990771113

Epoch: 160| Step: 0
Training loss: 2.7776519132285116
Validation loss: 2.5382747567206314

Epoch: 5| Step: 1
Training loss: 2.7263068923715874
Validation loss: 2.561995620971059

Epoch: 5| Step: 2
Training loss: 2.999737092260031
Validation loss: 2.551852720655418

Epoch: 5| Step: 3
Training loss: 2.0797920137736465
Validation loss: 2.562361086429874

Epoch: 5| Step: 4
Training loss: 2.4491134207190948
Validation loss: 2.559358603625679

Epoch: 5| Step: 5
Training loss: 3.763113870317581
Validation loss: 2.584747808113339

Epoch: 5| Step: 6
Training loss: 2.7365597961070898
Validation loss: 2.5568909783646814

Epoch: 5| Step: 7
Training loss: 3.0781174093240002
Validation loss: 2.555476333020494

Epoch: 5| Step: 8
Training loss: 2.1933075243968703
Validation loss: 2.5592764450803154

Epoch: 5| Step: 9
Training loss: 2.0359353827394497
Validation loss: 2.5310101696151124

Epoch: 5| Step: 10
Training loss: 3.2015846084121806
Validation loss: 2.5708755677833675

Epoch: 161| Step: 0
Training loss: 2.6280340190293923
Validation loss: 2.5518144343245686

Epoch: 5| Step: 1
Training loss: 2.9558651437724532
Validation loss: 2.5276745776226455

Epoch: 5| Step: 2
Training loss: 2.4477553185931242
Validation loss: 2.558889144507083

Epoch: 5| Step: 3
Training loss: 1.931584155855114
Validation loss: 2.523424258308968

Epoch: 5| Step: 4
Training loss: 2.9065896112686707
Validation loss: 2.5631795762906258

Epoch: 5| Step: 5
Training loss: 2.3683325890422013
Validation loss: 2.5676948520218548

Epoch: 5| Step: 6
Training loss: 3.191926463205064
Validation loss: 2.562763969857516

Epoch: 5| Step: 7
Training loss: 2.9388674535933124
Validation loss: 2.5445614640777867

Epoch: 5| Step: 8
Training loss: 3.0761307970967633
Validation loss: 2.541892381755997

Epoch: 5| Step: 9
Training loss: 2.66169020108699
Validation loss: 2.556262308093052

Epoch: 5| Step: 10
Training loss: 3.1077709565375535
Validation loss: 2.5577769088005358

Epoch: 162| Step: 0
Training loss: 2.7838150368995365
Validation loss: 2.5586099708817596

Epoch: 5| Step: 1
Training loss: 3.1204157965481407
Validation loss: 2.541083867353967

Epoch: 5| Step: 2
Training loss: 2.5575854928353072
Validation loss: 2.5411392389554632

Epoch: 5| Step: 3
Training loss: 3.113295647218122
Validation loss: 2.559510443245797

Epoch: 5| Step: 4
Training loss: 2.4669618528746686
Validation loss: 2.570458404133166

Epoch: 5| Step: 5
Training loss: 3.0228318191773837
Validation loss: 2.5401800092192715

Epoch: 5| Step: 6
Training loss: 2.7042352237641563
Validation loss: 2.55035037449188

Epoch: 5| Step: 7
Training loss: 2.6039612854395733
Validation loss: 2.5467023974072873

Epoch: 5| Step: 8
Training loss: 2.4813180986183054
Validation loss: 2.554118707477567

Epoch: 5| Step: 9
Training loss: 2.5601855735275203
Validation loss: 2.53370978337125

Epoch: 5| Step: 10
Training loss: 2.791891933481184
Validation loss: 2.5303704473006485

Epoch: 163| Step: 0
Training loss: 2.983203438287678
Validation loss: 2.5238931845685375

Epoch: 5| Step: 1
Training loss: 2.843681921510832
Validation loss: 2.544856913350893

Epoch: 5| Step: 2
Training loss: 2.615674666248798
Validation loss: 2.542181882344005

Epoch: 5| Step: 3
Training loss: 2.3219255690888696
Validation loss: 2.5691044203771134

Epoch: 5| Step: 4
Training loss: 2.729811167631434
Validation loss: 2.545101529475969

Epoch: 5| Step: 5
Training loss: 2.528001466804996
Validation loss: 2.5418430346524445

Epoch: 5| Step: 6
Training loss: 2.8838262662157406
Validation loss: 2.555696356777785

Epoch: 5| Step: 7
Training loss: 2.9424622199291615
Validation loss: 2.565722720258016

Epoch: 5| Step: 8
Training loss: 2.8764651338508807
Validation loss: 2.5574764529717497

Epoch: 5| Step: 9
Training loss: 3.0029654151838043
Validation loss: 2.5444420062635564

Epoch: 5| Step: 10
Training loss: 2.4293604198241066
Validation loss: 2.5539790700303056

Epoch: 164| Step: 0
Training loss: 2.3185178450275474
Validation loss: 2.5557310560700572

Epoch: 5| Step: 1
Training loss: 2.5798245463483376
Validation loss: 2.5263302471483318

Epoch: 5| Step: 2
Training loss: 2.6007600297001994
Validation loss: 2.5653434862068494

Epoch: 5| Step: 3
Training loss: 2.3499462365026833
Validation loss: 2.559469841011426

Epoch: 5| Step: 4
Training loss: 3.561287389139213
Validation loss: 2.5677734824675085

Epoch: 5| Step: 5
Training loss: 2.6398648403710454
Validation loss: 2.5932417607728486

Epoch: 5| Step: 6
Training loss: 2.338344698783387
Validation loss: 2.582579892533109

Epoch: 5| Step: 7
Training loss: 2.998509672647065
Validation loss: 2.5590347261968462

Epoch: 5| Step: 8
Training loss: 2.9366164806406228
Validation loss: 2.5539261139081786

Epoch: 5| Step: 9
Training loss: 2.185180742483179
Validation loss: 2.5654278487825004

Epoch: 5| Step: 10
Training loss: 3.4500804615313014
Validation loss: 2.5538910598365128

Epoch: 165| Step: 0
Training loss: 2.7852756640501055
Validation loss: 2.5751971980010966

Epoch: 5| Step: 1
Training loss: 2.9703228448148864
Validation loss: 2.5755735876544477

Epoch: 5| Step: 2
Training loss: 2.4794889181866
Validation loss: 2.555177297756887

Epoch: 5| Step: 3
Training loss: 2.863840420651272
Validation loss: 2.564469619719297

Epoch: 5| Step: 4
Training loss: 2.3124404074748734
Validation loss: 2.5502285158640348

Epoch: 5| Step: 5
Training loss: 2.9049533699744776
Validation loss: 2.5737891067950533

Epoch: 5| Step: 6
Training loss: 2.8744713670436193
Validation loss: 2.5964062666448635

Epoch: 5| Step: 7
Training loss: 3.293996123468542
Validation loss: 2.503585819755135

Epoch: 5| Step: 8
Training loss: 2.855651933088425
Validation loss: 2.5544944384917607

Epoch: 5| Step: 9
Training loss: 2.28239621146844
Validation loss: 2.5479997046044462

Epoch: 5| Step: 10
Training loss: 2.4201190120027323
Validation loss: 2.567618525590492

Epoch: 166| Step: 0
Training loss: 2.8924249766914567
Validation loss: 2.5624355520152005

Epoch: 5| Step: 1
Training loss: 2.4398836072145227
Validation loss: 2.55228345905422

Epoch: 5| Step: 2
Training loss: 2.4793202542299104
Validation loss: 2.564390522076252

Epoch: 5| Step: 3
Training loss: 2.6960821407380995
Validation loss: 2.559721928739556

Epoch: 5| Step: 4
Training loss: 3.1646033307553463
Validation loss: 2.5741688573818244

Epoch: 5| Step: 5
Training loss: 2.479770640257621
Validation loss: 2.5371196533506217

Epoch: 5| Step: 6
Training loss: 2.4025154362558743
Validation loss: 2.5739657245491236

Epoch: 5| Step: 7
Training loss: 2.564349181835304
Validation loss: 2.5714098363355955

Epoch: 5| Step: 8
Training loss: 2.7443301098113966
Validation loss: 2.5477153560065777

Epoch: 5| Step: 9
Training loss: 3.30541854239633
Validation loss: 2.5353066152857684

Epoch: 5| Step: 10
Training loss: 2.9783875484758555
Validation loss: 2.569069389797054

Epoch: 167| Step: 0
Training loss: 2.901316238823954
Validation loss: 2.559081846421335

Epoch: 5| Step: 1
Training loss: 2.3417473947676077
Validation loss: 2.537123936658059

Epoch: 5| Step: 2
Training loss: 2.49146004227289
Validation loss: 2.5743162030362354

Epoch: 5| Step: 3
Training loss: 3.1618187754922285
Validation loss: 2.527799396707168

Epoch: 5| Step: 4
Training loss: 2.5567068349309654
Validation loss: 2.568332369565046

Epoch: 5| Step: 5
Training loss: 3.160868070615866
Validation loss: 2.593425296009954

Epoch: 5| Step: 6
Training loss: 2.9353623424202384
Validation loss: 2.5607232297563103

Epoch: 5| Step: 7
Training loss: 2.7501146119249547
Validation loss: 2.5299064458836464

Epoch: 5| Step: 8
Training loss: 2.193551874587781
Validation loss: 2.552994335746694

Epoch: 5| Step: 9
Training loss: 2.6145282957406515
Validation loss: 2.5833610198422488

Epoch: 5| Step: 10
Training loss: 3.0801174473353905
Validation loss: 2.550284721296134

Epoch: 168| Step: 0
Training loss: 2.702882524320489
Validation loss: 2.569049623577713

Epoch: 5| Step: 1
Training loss: 2.872497796571582
Validation loss: 2.55875375399712

Epoch: 5| Step: 2
Training loss: 3.5660828091713848
Validation loss: 2.541744585690365

Epoch: 5| Step: 3
Training loss: 2.1729740134035764
Validation loss: 2.533464236822718

Epoch: 5| Step: 4
Training loss: 2.158124799731146
Validation loss: 2.5223802867401655

Epoch: 5| Step: 5
Training loss: 2.6960540193754694
Validation loss: 2.5491088355546685

Epoch: 5| Step: 6
Training loss: 3.1563512200469694
Validation loss: 2.5356145461236292

Epoch: 5| Step: 7
Training loss: 2.4214685898924926
Validation loss: 2.5501731475976746

Epoch: 5| Step: 8
Training loss: 3.127909107360879
Validation loss: 2.5806181615268184

Epoch: 5| Step: 9
Training loss: 2.4740090669482773
Validation loss: 2.5503549853912615

Epoch: 5| Step: 10
Training loss: 2.6372824737374945
Validation loss: 2.576590820933736

Epoch: 169| Step: 0
Training loss: 2.874030405827434
Validation loss: 2.5436398777845737

Epoch: 5| Step: 1
Training loss: 2.481934218150497
Validation loss: 2.586385377036497

Epoch: 5| Step: 2
Training loss: 2.912500694176587
Validation loss: 2.582896717367694

Epoch: 5| Step: 3
Training loss: 2.559910465999369
Validation loss: 2.557680182737617

Epoch: 5| Step: 4
Training loss: 2.5955757241884387
Validation loss: 2.5414284188136667

Epoch: 5| Step: 5
Training loss: 2.508995561427801
Validation loss: 2.5272710653762944

Epoch: 5| Step: 6
Training loss: 2.5009987743364004
Validation loss: 2.5544465381521593

Epoch: 5| Step: 7
Training loss: 3.312932687966225
Validation loss: 2.5497576592576014

Epoch: 5| Step: 8
Training loss: 2.817652581322041
Validation loss: 2.535543741095059

Epoch: 5| Step: 9
Training loss: 2.9131992073813295
Validation loss: 2.536471813056844

Epoch: 5| Step: 10
Training loss: 2.465717336185174
Validation loss: 2.545203455533567

Epoch: 170| Step: 0
Training loss: 2.6544062779260935
Validation loss: 2.541082577000174

Epoch: 5| Step: 1
Training loss: 3.3414255779814215
Validation loss: 2.5569348565133527

Epoch: 5| Step: 2
Training loss: 3.272352671618126
Validation loss: 2.5560948190773436

Epoch: 5| Step: 3
Training loss: 2.194337349973121
Validation loss: 2.5487256045954

Epoch: 5| Step: 4
Training loss: 2.0274756945412604
Validation loss: 2.5550290345086912

Epoch: 5| Step: 5
Training loss: 1.7323168665768993
Validation loss: 2.5510723938641515

Epoch: 5| Step: 6
Training loss: 2.7036225847687363
Validation loss: 2.577937965905003

Epoch: 5| Step: 7
Training loss: 3.0373442433300566
Validation loss: 2.529224378780803

Epoch: 5| Step: 8
Training loss: 3.0436235342835722
Validation loss: 2.5447686798481453

Epoch: 5| Step: 9
Training loss: 2.7862746038501487
Validation loss: 2.5681619477904363

Epoch: 5| Step: 10
Training loss: 3.012816707694007
Validation loss: 2.557364804084775

Epoch: 171| Step: 0
Training loss: 2.4420329273825137
Validation loss: 2.585554041393347

Epoch: 5| Step: 1
Training loss: 2.4928182443526525
Validation loss: 2.545593821243538

Epoch: 5| Step: 2
Training loss: 2.7283510828887554
Validation loss: 2.5447583779914735

Epoch: 5| Step: 3
Training loss: 2.754068486189756
Validation loss: 2.569899461657509

Epoch: 5| Step: 4
Training loss: 2.733289405035568
Validation loss: 2.5548272321859016

Epoch: 5| Step: 5
Training loss: 2.2199889471449077
Validation loss: 2.5456612228327207

Epoch: 5| Step: 6
Training loss: 3.1439674014083168
Validation loss: 2.538260059254789

Epoch: 5| Step: 7
Training loss: 2.576739962211015
Validation loss: 2.567176229727946

Epoch: 5| Step: 8
Training loss: 3.44440197320274
Validation loss: 2.5483931971282656

Epoch: 5| Step: 9
Training loss: 3.0326157472162003
Validation loss: 2.5214766153899744

Epoch: 5| Step: 10
Training loss: 2.531986082451583
Validation loss: 2.5616194910269328

Epoch: 172| Step: 0
Training loss: 2.077974242284808
Validation loss: 2.5718537695439085

Epoch: 5| Step: 1
Training loss: 3.190607986629009
Validation loss: 2.5590681840899157

Epoch: 5| Step: 2
Training loss: 2.7867594808730516
Validation loss: 2.5599827741900913

Epoch: 5| Step: 3
Training loss: 2.2611852883125376
Validation loss: 2.5624997638949396

Epoch: 5| Step: 4
Training loss: 3.2716362488068316
Validation loss: 2.5567724656001416

Epoch: 5| Step: 5
Training loss: 2.956664532557093
Validation loss: 2.542689148186839

Epoch: 5| Step: 6
Training loss: 2.882317229114958
Validation loss: 2.555783742080391

Epoch: 5| Step: 7
Training loss: 2.326263400310311
Validation loss: 2.5743831224953735

Epoch: 5| Step: 8
Training loss: 2.6277795335505263
Validation loss: 2.5746608934963793

Epoch: 5| Step: 9
Training loss: 2.661270781973866
Validation loss: 2.519388890646512

Epoch: 5| Step: 10
Training loss: 2.686326502602162
Validation loss: 2.5731614964407274

Epoch: 173| Step: 0
Training loss: 2.852119286930314
Validation loss: 2.5798173626877348

Epoch: 5| Step: 1
Training loss: 2.9847201003022774
Validation loss: 2.573167920574699

Epoch: 5| Step: 2
Training loss: 2.2505668349987715
Validation loss: 2.5719394974640526

Epoch: 5| Step: 3
Training loss: 2.477149388422066
Validation loss: 2.5588111938470375

Epoch: 5| Step: 4
Training loss: 2.4383861202628427
Validation loss: 2.524028780299335

Epoch: 5| Step: 5
Training loss: 2.375106206828103
Validation loss: 2.5542040731231674

Epoch: 5| Step: 6
Training loss: 3.529496829559852
Validation loss: 2.573500695282501

Epoch: 5| Step: 7
Training loss: 2.878874282969994
Validation loss: 2.538210153693591

Epoch: 5| Step: 8
Training loss: 2.4080361016757776
Validation loss: 2.5673761532119936

Epoch: 5| Step: 9
Training loss: 2.714446509409885
Validation loss: 2.547288945692633

Epoch: 5| Step: 10
Training loss: 3.02681541508676
Validation loss: 2.5197963851412934

Epoch: 174| Step: 0
Training loss: 2.845945747206879
Validation loss: 2.534881117766242

Epoch: 5| Step: 1
Training loss: 2.955740764219859
Validation loss: 2.5471675424709095

Epoch: 5| Step: 2
Training loss: 2.752024772149971
Validation loss: 2.5550436440423794

Epoch: 5| Step: 3
Training loss: 2.5059166512964133
Validation loss: 2.557227349909931

Epoch: 5| Step: 4
Training loss: 2.5639188606528154
Validation loss: 2.547360609786654

Epoch: 5| Step: 5
Training loss: 3.0116457602516435
Validation loss: 2.559669674332436

Epoch: 5| Step: 6
Training loss: 2.4782407832186433
Validation loss: 2.5621466624405906

Epoch: 5| Step: 7
Training loss: 2.341133590060856
Validation loss: 2.58949329407554

Epoch: 5| Step: 8
Training loss: 2.734323119625014
Validation loss: 2.538664690253583

Epoch: 5| Step: 9
Training loss: 3.422810047893748
Validation loss: 2.549529916840005

Epoch: 5| Step: 10
Training loss: 2.783127483210044
Validation loss: 2.526495972707348

Epoch: 175| Step: 0
Training loss: 2.3845221717781144
Validation loss: 2.556386681029669

Epoch: 5| Step: 1
Training loss: 2.6073959977941104
Validation loss: 2.4911641836525518

Epoch: 5| Step: 2
Training loss: 2.7543600371360974
Validation loss: 2.5413463353013164

Epoch: 5| Step: 3
Training loss: 2.956205184629093
Validation loss: 2.5558430391246767

Epoch: 5| Step: 4
Training loss: 2.8977815034792975
Validation loss: 2.511109112411378

Epoch: 5| Step: 5
Training loss: 2.5423255962619042
Validation loss: 2.539745828134302

Epoch: 5| Step: 6
Training loss: 3.0946649296679123
Validation loss: 2.5514788673756534

Epoch: 5| Step: 7
Training loss: 3.5564956928786455
Validation loss: 2.5462726525192685

Epoch: 5| Step: 8
Training loss: 2.653843586260214
Validation loss: 2.5634939075514067

Epoch: 5| Step: 9
Training loss: 2.172681260882314
Validation loss: 2.550595771920461

Epoch: 5| Step: 10
Training loss: 2.4079814477820523
Validation loss: 2.575652936084139

Epoch: 176| Step: 0
Training loss: 2.9117271740512365
Validation loss: 2.567445330479461

Epoch: 5| Step: 1
Training loss: 2.7474947702151535
Validation loss: 2.518812560665345

Epoch: 5| Step: 2
Training loss: 1.6796761445837092
Validation loss: 2.542785499814929

Epoch: 5| Step: 3
Training loss: 2.6916174286707646
Validation loss: 2.5331367915805214

Epoch: 5| Step: 4
Training loss: 2.9337585646736337
Validation loss: 2.583945028928343

Epoch: 5| Step: 5
Training loss: 2.248322391280725
Validation loss: 2.567053320289721

Epoch: 5| Step: 6
Training loss: 3.3009021624026356
Validation loss: 2.5262999743897545

Epoch: 5| Step: 7
Training loss: 3.46742470657463
Validation loss: 2.5370938108787926

Epoch: 5| Step: 8
Training loss: 2.465621511169209
Validation loss: 2.521582412240429

Epoch: 5| Step: 9
Training loss: 2.9092872090108535
Validation loss: 2.5531149236888138

Epoch: 5| Step: 10
Training loss: 2.1439587327416016
Validation loss: 2.5610652151232127

Epoch: 177| Step: 0
Training loss: 3.3495579840718785
Validation loss: 2.547463794972543

Epoch: 5| Step: 1
Training loss: 2.7959448263921454
Validation loss: 2.553442837053195

Epoch: 5| Step: 2
Training loss: 1.650248323885548
Validation loss: 2.568344400518895

Epoch: 5| Step: 3
Training loss: 2.844111157633882
Validation loss: 2.546636871634339

Epoch: 5| Step: 4
Training loss: 2.843934440919489
Validation loss: 2.5859908910834126

Epoch: 5| Step: 5
Training loss: 2.726393380153034
Validation loss: 2.533470232389014

Epoch: 5| Step: 6
Training loss: 2.783651707956165
Validation loss: 2.5606659619462913

Epoch: 5| Step: 7
Training loss: 2.6117026175349607
Validation loss: 2.538353506700838

Epoch: 5| Step: 8
Training loss: 3.0671937745195788
Validation loss: 2.550584043715678

Epoch: 5| Step: 9
Training loss: 2.7004390006448236
Validation loss: 2.5470371120509148

Epoch: 5| Step: 10
Training loss: 2.260231490981016
Validation loss: 2.5708543022094243

Epoch: 178| Step: 0
Training loss: 2.538466257366605
Validation loss: 2.5128125138767277

Epoch: 5| Step: 1
Training loss: 2.959265083116638
Validation loss: 2.551654543755385

Epoch: 5| Step: 2
Training loss: 2.4873849161641406
Validation loss: 2.5888633591684145

Epoch: 5| Step: 3
Training loss: 3.088375779704445
Validation loss: 2.5394394219171366

Epoch: 5| Step: 4
Training loss: 2.976631223831395
Validation loss: 2.567075705393234

Epoch: 5| Step: 5
Training loss: 2.200969642752178
Validation loss: 2.6013169174416317

Epoch: 5| Step: 6
Training loss: 2.491383198547424
Validation loss: 2.5528589112783764

Epoch: 5| Step: 7
Training loss: 2.8316641734087744
Validation loss: 2.5540722384602117

Epoch: 5| Step: 8
Training loss: 2.9731513875480355
Validation loss: 2.5394853026284765

Epoch: 5| Step: 9
Training loss: 2.498027977413372
Validation loss: 2.553357433909087

Epoch: 5| Step: 10
Training loss: 2.7810232520093305
Validation loss: 2.5377688137557355

Epoch: 179| Step: 0
Training loss: 2.986375547622567
Validation loss: 2.5517153593724746

Epoch: 5| Step: 1
Training loss: 2.3307939630519603
Validation loss: 2.570332348268127

Epoch: 5| Step: 2
Training loss: 2.430986553912871
Validation loss: 2.543027615989362

Epoch: 5| Step: 3
Training loss: 3.223478529091616
Validation loss: 2.5705369121461596

Epoch: 5| Step: 4
Training loss: 2.9278070136711123
Validation loss: 2.5495609997371806

Epoch: 5| Step: 5
Training loss: 3.0277198607089857
Validation loss: 2.5548374221973464

Epoch: 5| Step: 6
Training loss: 2.079347408697529
Validation loss: 2.586721619328452

Epoch: 5| Step: 7
Training loss: 2.219590041480631
Validation loss: 2.57831678127772

Epoch: 5| Step: 8
Training loss: 3.021115379759168
Validation loss: 2.6031713743773883

Epoch: 5| Step: 9
Training loss: 2.761491693338129
Validation loss: 2.5390213148186067

Epoch: 5| Step: 10
Training loss: 2.7618399543550094
Validation loss: 2.567150917511827

Epoch: 180| Step: 0
Training loss: 2.69695207788468
Validation loss: 2.5756845169131823

Epoch: 5| Step: 1
Training loss: 2.927820857159579
Validation loss: 2.585702318665524

Epoch: 5| Step: 2
Training loss: 2.1571663277791875
Validation loss: 2.5457234263257527

Epoch: 5| Step: 3
Training loss: 3.088592546032136
Validation loss: 2.546821007331474

Epoch: 5| Step: 4
Training loss: 2.685546697443176
Validation loss: 2.546683188419559

Epoch: 5| Step: 5
Training loss: 2.9172218520967146
Validation loss: 2.5452693294389133

Epoch: 5| Step: 6
Training loss: 2.1867250432192735
Validation loss: 2.538765041953254

Epoch: 5| Step: 7
Training loss: 3.1861322497777347
Validation loss: 2.552890970406757

Epoch: 5| Step: 8
Training loss: 2.739066584094975
Validation loss: 2.5625957838275486

Epoch: 5| Step: 9
Training loss: 2.3706543969429354
Validation loss: 2.535735005169265

Epoch: 5| Step: 10
Training loss: 2.615158889057154
Validation loss: 2.5602400623840103

Epoch: 181| Step: 0
Training loss: 2.632292019706031
Validation loss: 2.5451300626564217

Epoch: 5| Step: 1
Training loss: 2.678718769925662
Validation loss: 2.5302117488459106

Epoch: 5| Step: 2
Training loss: 3.059688133603579
Validation loss: 2.5356422296140715

Epoch: 5| Step: 3
Training loss: 2.5551214287078206
Validation loss: 2.5405255510870686

Epoch: 5| Step: 4
Training loss: 2.9999672570031195
Validation loss: 2.538786267824888

Epoch: 5| Step: 5
Training loss: 2.8549941225542543
Validation loss: 2.5599181621859852

Epoch: 5| Step: 6
Training loss: 2.2707851183144454
Validation loss: 2.5392777849403685

Epoch: 5| Step: 7
Training loss: 2.5613547766623728
Validation loss: 2.5369201396081174

Epoch: 5| Step: 8
Training loss: 2.739511515518496
Validation loss: 2.545215967486445

Epoch: 5| Step: 9
Training loss: 2.642244372892167
Validation loss: 2.568428077622629

Epoch: 5| Step: 10
Training loss: 2.885917005068587
Validation loss: 2.5583064523160957

Epoch: 182| Step: 0
Training loss: 2.488168758801909
Validation loss: 2.5334899685799344

Epoch: 5| Step: 1
Training loss: 2.58644251199575
Validation loss: 2.581575533637093

Epoch: 5| Step: 2
Training loss: 2.9101172527798185
Validation loss: 2.554412228877716

Epoch: 5| Step: 3
Training loss: 3.114150171342553
Validation loss: 2.5457198875911984

Epoch: 5| Step: 4
Training loss: 2.4834287748835147
Validation loss: 2.5317599938531608

Epoch: 5| Step: 5
Training loss: 2.5213205061185646
Validation loss: 2.538822384721988

Epoch: 5| Step: 6
Training loss: 2.8740041915555055
Validation loss: 2.5747792659189632

Epoch: 5| Step: 7
Training loss: 2.763448084744426
Validation loss: 2.5449842657954322

Epoch: 5| Step: 8
Training loss: 3.022332041122695
Validation loss: 2.5366194964143514

Epoch: 5| Step: 9
Training loss: 3.085942444616292
Validation loss: 2.527694678545518

Epoch: 5| Step: 10
Training loss: 1.80823534716156
Validation loss: 2.559956966236808

Epoch: 183| Step: 0
Training loss: 3.0789126245354748
Validation loss: 2.5555012778396953

Epoch: 5| Step: 1
Training loss: 2.5964692350783776
Validation loss: 2.592103855085256

Epoch: 5| Step: 2
Training loss: 2.8864975613521473
Validation loss: 2.5371079522757523

Epoch: 5| Step: 3
Training loss: 2.825405604859277
Validation loss: 2.545538391444804

Epoch: 5| Step: 4
Training loss: 3.0958548427431842
Validation loss: 2.5362496373671055

Epoch: 5| Step: 5
Training loss: 2.38291275563936
Validation loss: 2.5405177588161587

Epoch: 5| Step: 6
Training loss: 2.6557482077157926
Validation loss: 2.563422970509952

Epoch: 5| Step: 7
Training loss: 2.2730693715724906
Validation loss: 2.5502428327251385

Epoch: 5| Step: 8
Training loss: 3.3590368766066443
Validation loss: 2.5464166313947674

Epoch: 5| Step: 9
Training loss: 2.4359029771121445
Validation loss: 2.5472109148000257

Epoch: 5| Step: 10
Training loss: 1.9526026523191111
Validation loss: 2.5652541579851733

Epoch: 184| Step: 0
Training loss: 2.608841161885249
Validation loss: 2.6002569988192388

Epoch: 5| Step: 1
Training loss: 3.008496333080236
Validation loss: 2.5552664425002103

Epoch: 5| Step: 2
Training loss: 2.991332566954575
Validation loss: 2.544647263177608

Epoch: 5| Step: 3
Training loss: 2.397712722267401
Validation loss: 2.5968651901140185

Epoch: 5| Step: 4
Training loss: 2.9554982816393984
Validation loss: 2.5661403290795324

Epoch: 5| Step: 5
Training loss: 2.591829071189907
Validation loss: 2.5546917508419122

Epoch: 5| Step: 6
Training loss: 2.481194337465527
Validation loss: 2.5664820291307016

Epoch: 5| Step: 7
Training loss: 2.775630717727967
Validation loss: 2.5586068427414617

Epoch: 5| Step: 8
Training loss: 3.401566952171093
Validation loss: 2.5684480118192345

Epoch: 5| Step: 9
Training loss: 2.185510329962837
Validation loss: 2.5282114817848136

Epoch: 5| Step: 10
Training loss: 2.532906167088634
Validation loss: 2.5407454947760693

Epoch: 185| Step: 0
Training loss: 2.4070538255721785
Validation loss: 2.5471045524443214

Epoch: 5| Step: 1
Training loss: 2.466931216341402
Validation loss: 2.5623113591279947

Epoch: 5| Step: 2
Training loss: 2.8868596477476105
Validation loss: 2.516253594172598

Epoch: 5| Step: 3
Training loss: 2.0306606905058806
Validation loss: 2.537293313996241

Epoch: 5| Step: 4
Training loss: 2.8003437546479106
Validation loss: 2.567634348989177

Epoch: 5| Step: 5
Training loss: 2.582269377700082
Validation loss: 2.5866681590846103

Epoch: 5| Step: 6
Training loss: 3.6494916744824475
Validation loss: 2.552942760044052

Epoch: 5| Step: 7
Training loss: 3.163604326394876
Validation loss: 2.567663007683648

Epoch: 5| Step: 8
Training loss: 2.505430522326127
Validation loss: 2.533377584379636

Epoch: 5| Step: 9
Training loss: 2.1631447949808478
Validation loss: 2.550967907490697

Epoch: 5| Step: 10
Training loss: 2.888587852427024
Validation loss: 2.548730019275813

Epoch: 186| Step: 0
Training loss: 3.286142824789725
Validation loss: 2.555382701627278

Epoch: 5| Step: 1
Training loss: 2.560496780056783
Validation loss: 2.571539753325817

Epoch: 5| Step: 2
Training loss: 2.5114390927978913
Validation loss: 2.5458527972309426

Epoch: 5| Step: 3
Training loss: 2.05798550908925
Validation loss: 2.582185275451113

Epoch: 5| Step: 4
Training loss: 1.662082407426644
Validation loss: 2.558328295672647

Epoch: 5| Step: 5
Training loss: 3.1415689292970184
Validation loss: 2.570612177574858

Epoch: 5| Step: 6
Training loss: 2.5705855668018525
Validation loss: 2.5576181116712364

Epoch: 5| Step: 7
Training loss: 2.6942584201879036
Validation loss: 2.5468384950056073

Epoch: 5| Step: 8
Training loss: 2.6161905240198373
Validation loss: 2.5525769343804137

Epoch: 5| Step: 9
Training loss: 3.045505783343613
Validation loss: 2.5616222101692308

Epoch: 5| Step: 10
Training loss: 3.35613602030913
Validation loss: 2.536515700287082

Epoch: 187| Step: 0
Training loss: 2.3347330209498836
Validation loss: 2.552597407653549

Epoch: 5| Step: 1
Training loss: 3.241304796772975
Validation loss: 2.5576141714117213

Epoch: 5| Step: 2
Training loss: 2.294499836525794
Validation loss: 2.55461159980624

Epoch: 5| Step: 3
Training loss: 2.7173575858636427
Validation loss: 2.5421605607849003

Epoch: 5| Step: 4
Training loss: 2.5340028087356523
Validation loss: 2.534190896285061

Epoch: 5| Step: 5
Training loss: 2.9745598411318137
Validation loss: 2.5556156012584914

Epoch: 5| Step: 6
Training loss: 2.9741612959157973
Validation loss: 2.5221047981040967

Epoch: 5| Step: 7
Training loss: 2.4714010949028906
Validation loss: 2.5585574833474936

Epoch: 5| Step: 8
Training loss: 2.8786801543150236
Validation loss: 2.558652781532192

Epoch: 5| Step: 9
Training loss: 2.4918226016783103
Validation loss: 2.5414348969340246

Epoch: 5| Step: 10
Training loss: 2.900535461714034
Validation loss: 2.541546251042488

Epoch: 188| Step: 0
Training loss: 3.067816032414629
Validation loss: 2.556422953407643

Epoch: 5| Step: 1
Training loss: 2.8855364576094615
Validation loss: 2.553636008684727

Epoch: 5| Step: 2
Training loss: 2.430493972240351
Validation loss: 2.54926354182731

Epoch: 5| Step: 3
Training loss: 2.6023253276153406
Validation loss: 2.548036521965079

Epoch: 5| Step: 4
Training loss: 3.0649619035702407
Validation loss: 2.544488729741237

Epoch: 5| Step: 5
Training loss: 2.1984776388162888
Validation loss: 2.5280529246441317

Epoch: 5| Step: 6
Training loss: 2.1747340861912496
Validation loss: 2.5413956103404436

Epoch: 5| Step: 7
Training loss: 2.5760529485615633
Validation loss: 2.564631308336482

Epoch: 5| Step: 8
Training loss: 2.8532260170776533
Validation loss: 2.529798151836991

Epoch: 5| Step: 9
Training loss: 2.999632177056353
Validation loss: 2.551618526104797

Epoch: 5| Step: 10
Training loss: 2.8331456589718735
Validation loss: 2.5361340416888822

Epoch: 189| Step: 0
Training loss: 2.9916154996982263
Validation loss: 2.5458092547413007

Epoch: 5| Step: 1
Training loss: 3.306275908110846
Validation loss: 2.5424112278034925

Epoch: 5| Step: 2
Training loss: 1.9149402085175573
Validation loss: 2.525246545253794

Epoch: 5| Step: 3
Training loss: 2.6702163634341076
Validation loss: 2.567797666366558

Epoch: 5| Step: 4
Training loss: 2.5919070763002465
Validation loss: 2.5365439454834813

Epoch: 5| Step: 5
Training loss: 2.6672710886071607
Validation loss: 2.5578204039164403

Epoch: 5| Step: 6
Training loss: 2.705607074018149
Validation loss: 2.5458324318446786

Epoch: 5| Step: 7
Training loss: 2.807792283942248
Validation loss: 2.5430074840388412

Epoch: 5| Step: 8
Training loss: 2.9141017716857776
Validation loss: 2.547515719093339

Epoch: 5| Step: 9
Training loss: 2.627746053947307
Validation loss: 2.5561977454645635

Epoch: 5| Step: 10
Training loss: 2.514347012425943
Validation loss: 2.552320703781424

Epoch: 190| Step: 0
Training loss: 2.9251579568060295
Validation loss: 2.5591712829015227

Epoch: 5| Step: 1
Training loss: 2.820297875194725
Validation loss: 2.554052644252946

Epoch: 5| Step: 2
Training loss: 1.9318458131864207
Validation loss: 2.5379350772671208

Epoch: 5| Step: 3
Training loss: 2.374512471805479
Validation loss: 2.546358151828601

Epoch: 5| Step: 4
Training loss: 2.229378829794488
Validation loss: 2.5610661240361408

Epoch: 5| Step: 5
Training loss: 2.7440212454571156
Validation loss: 2.536691961179183

Epoch: 5| Step: 6
Training loss: 2.82894919172436
Validation loss: 2.5380626765261067

Epoch: 5| Step: 7
Training loss: 3.450998609561911
Validation loss: 2.5594256807866835

Epoch: 5| Step: 8
Training loss: 3.142646708193514
Validation loss: 2.571184809411387

Epoch: 5| Step: 9
Training loss: 2.210106575583959
Validation loss: 2.5251446969098295

Epoch: 5| Step: 10
Training loss: 2.8924658609945673
Validation loss: 2.543232539491903

Epoch: 191| Step: 0
Training loss: 2.706713461009452
Validation loss: 2.562613099826474

Epoch: 5| Step: 1
Training loss: 2.281765291726364
Validation loss: 2.5127580066067434

Epoch: 5| Step: 2
Training loss: 2.943998089033004
Validation loss: 2.5593524373187213

Epoch: 5| Step: 3
Training loss: 2.2538548402526226
Validation loss: 2.4984613975338275

Epoch: 5| Step: 4
Training loss: 2.960730714044083
Validation loss: 2.5232751000930604

Epoch: 5| Step: 5
Training loss: 2.2793855756091204
Validation loss: 2.5445132155477013

Epoch: 5| Step: 6
Training loss: 2.4444063597900874
Validation loss: 2.5213285458240033

Epoch: 5| Step: 7
Training loss: 2.5183520965920687
Validation loss: 2.5538711349844805

Epoch: 5| Step: 8
Training loss: 2.96038942120923
Validation loss: 2.541677126635151

Epoch: 5| Step: 9
Training loss: 3.3733722858919135
Validation loss: 2.5542370979723628

Epoch: 5| Step: 10
Training loss: 2.851302628890619
Validation loss: 2.556524562464488

Epoch: 192| Step: 0
Training loss: 2.470272512190682
Validation loss: 2.582116225508655

Epoch: 5| Step: 1
Training loss: 2.69848640543362
Validation loss: 2.530017589733465

Epoch: 5| Step: 2
Training loss: 2.697912051713647
Validation loss: 2.5504206317523446

Epoch: 5| Step: 3
Training loss: 2.114473073806402
Validation loss: 2.5502017014396046

Epoch: 5| Step: 4
Training loss: 3.342319788728989
Validation loss: 2.5453704913795936

Epoch: 5| Step: 5
Training loss: 3.0579978391591056
Validation loss: 2.5305544931886566

Epoch: 5| Step: 6
Training loss: 2.649613111072388
Validation loss: 2.5798152241809493

Epoch: 5| Step: 7
Training loss: 2.990732979892896
Validation loss: 2.5435129544245423

Epoch: 5| Step: 8
Training loss: 2.117232206090786
Validation loss: 2.530385211868431

Epoch: 5| Step: 9
Training loss: 3.094811767868934
Validation loss: 2.542904577744619

Epoch: 5| Step: 10
Training loss: 2.4384860465186513
Validation loss: 2.5430678431210554

Epoch: 193| Step: 0
Training loss: 1.9967540984946912
Validation loss: 2.5451355140117236

Epoch: 5| Step: 1
Training loss: 2.763779795126762
Validation loss: 2.531482140497613

Epoch: 5| Step: 2
Training loss: 2.289236120728697
Validation loss: 2.5370449777403414

Epoch: 5| Step: 3
Training loss: 3.0226844815858183
Validation loss: 2.5435056787916963

Epoch: 5| Step: 4
Training loss: 2.820935970300488
Validation loss: 2.5297113753363765

Epoch: 5| Step: 5
Training loss: 2.885175857869839
Validation loss: 2.5626250065711793

Epoch: 5| Step: 6
Training loss: 2.9473293694440232
Validation loss: 2.5332568123553587

Epoch: 5| Step: 7
Training loss: 2.8170117958696674
Validation loss: 2.53928936092339

Epoch: 5| Step: 8
Training loss: 2.5668493437059547
Validation loss: 2.5392929035715235

Epoch: 5| Step: 9
Training loss: 2.4609475756242154
Validation loss: 2.5314772977452

Epoch: 5| Step: 10
Training loss: 2.9027340858817645
Validation loss: 2.5705525231046433

Epoch: 194| Step: 0
Training loss: 2.4828610395676556
Validation loss: 2.513384619413672

Epoch: 5| Step: 1
Training loss: 3.340362544227779
Validation loss: 2.586006270952957

Epoch: 5| Step: 2
Training loss: 2.206617252376662
Validation loss: 2.567952300957634

Epoch: 5| Step: 3
Training loss: 2.322014078772789
Validation loss: 2.543843752245565

Epoch: 5| Step: 4
Training loss: 3.0205594344218754
Validation loss: 2.564165620996747

Epoch: 5| Step: 5
Training loss: 2.5828907700325683
Validation loss: 2.5563579676227923

Epoch: 5| Step: 6
Training loss: 2.3708472838658983
Validation loss: 2.530501817823416

Epoch: 5| Step: 7
Training loss: 2.1748653107078746
Validation loss: 2.5635023160188695

Epoch: 5| Step: 8
Training loss: 2.4131211108828694
Validation loss: 2.5712920396162713

Epoch: 5| Step: 9
Training loss: 3.0470242977243966
Validation loss: 2.5590097882713714

Epoch: 5| Step: 10
Training loss: 3.519891616713248
Validation loss: 2.5996242655375106

Epoch: 195| Step: 0
Training loss: 2.314743809211446
Validation loss: 2.5461841881705176

Epoch: 5| Step: 1
Training loss: 2.8411105136558246
Validation loss: 2.5643609575536526

Epoch: 5| Step: 2
Training loss: 3.0734992730391317
Validation loss: 2.5437828683665926

Epoch: 5| Step: 3
Training loss: 2.6622266064899467
Validation loss: 2.573436756401528

Epoch: 5| Step: 4
Training loss: 2.634014274181945
Validation loss: 2.543994714558281

Epoch: 5| Step: 5
Training loss: 2.77864098064329
Validation loss: 2.5691230306462414

Epoch: 5| Step: 6
Training loss: 2.7573800328737637
Validation loss: 2.5339944581826863

Epoch: 5| Step: 7
Training loss: 2.5909825463658587
Validation loss: 2.564031051022246

Epoch: 5| Step: 8
Training loss: 2.3135830173177796
Validation loss: 2.5677937077824815

Epoch: 5| Step: 9
Training loss: 2.860890471542232
Validation loss: 2.549206865354801

Epoch: 5| Step: 10
Training loss: 2.893082517426131
Validation loss: 2.548662518791657

Epoch: 196| Step: 0
Training loss: 2.554477974701697
Validation loss: 2.572646098719147

Epoch: 5| Step: 1
Training loss: 1.8708339184234088
Validation loss: 2.546083293166686

Epoch: 5| Step: 2
Training loss: 2.3873789571865807
Validation loss: 2.5608656453685734

Epoch: 5| Step: 3
Training loss: 2.464385701948859
Validation loss: 2.53673472939667

Epoch: 5| Step: 4
Training loss: 3.2793851366826106
Validation loss: 2.5746483095597488

Epoch: 5| Step: 5
Training loss: 3.3939523148342334
Validation loss: 2.5506008165848355

Epoch: 5| Step: 6
Training loss: 2.6140422083767687
Validation loss: 2.557706438648037

Epoch: 5| Step: 7
Training loss: 2.8818452034119084
Validation loss: 2.5798819115677794

Epoch: 5| Step: 8
Training loss: 3.3981504121734933
Validation loss: 2.5378299530338033

Epoch: 5| Step: 9
Training loss: 1.9128238329016483
Validation loss: 2.5516732154855335

Epoch: 5| Step: 10
Training loss: 2.554987525237623
Validation loss: 2.5524440444335115

Epoch: 197| Step: 0
Training loss: 2.2328686738472636
Validation loss: 2.5702223380606117

Epoch: 5| Step: 1
Training loss: 2.8688617360413975
Validation loss: 2.5516765405050164

Epoch: 5| Step: 2
Training loss: 2.4180549273440484
Validation loss: 2.567319108697718

Epoch: 5| Step: 3
Training loss: 3.1281368533585363
Validation loss: 2.5295778334587573

Epoch: 5| Step: 4
Training loss: 2.417110161262255
Validation loss: 2.5684606196458515

Epoch: 5| Step: 5
Training loss: 2.5224955309402
Validation loss: 2.5698819872596346

Epoch: 5| Step: 6
Training loss: 2.9156687709716005
Validation loss: 2.559297890247606

Epoch: 5| Step: 7
Training loss: 2.6065360518347256
Validation loss: 2.5518789953347745

Epoch: 5| Step: 8
Training loss: 2.722978920335602
Validation loss: 2.5603639016610735

Epoch: 5| Step: 9
Training loss: 2.8931164700968917
Validation loss: 2.565171824482717

Epoch: 5| Step: 10
Training loss: 2.837194075036353
Validation loss: 2.5665229594391326

Epoch: 198| Step: 0
Training loss: 2.7885946955369048
Validation loss: 2.552633534018195

Epoch: 5| Step: 1
Training loss: 2.67365879054856
Validation loss: 2.562906467125773

Epoch: 5| Step: 2
Training loss: 2.542362638980902
Validation loss: 2.5553401742865565

Epoch: 5| Step: 3
Training loss: 2.7633672431764116
Validation loss: 2.5630634797824308

Epoch: 5| Step: 4
Training loss: 2.535642791753327
Validation loss: 2.5464946987069803

Epoch: 5| Step: 5
Training loss: 3.0176903169880047
Validation loss: 2.5399474312805

Epoch: 5| Step: 6
Training loss: 2.369949089662382
Validation loss: 2.56354200685311

Epoch: 5| Step: 7
Training loss: 3.0731593321767137
Validation loss: 2.5549865369014806

Epoch: 5| Step: 8
Training loss: 2.833420658635809
Validation loss: 2.5618521138700663

Epoch: 5| Step: 9
Training loss: 3.03823048791244
Validation loss: 2.544998088348971

Epoch: 5| Step: 10
Training loss: 2.224383763904033
Validation loss: 2.548086710456137

Epoch: 199| Step: 0
Training loss: 2.6309424757488453
Validation loss: 2.576241350458111

Epoch: 5| Step: 1
Training loss: 3.02306211837157
Validation loss: 2.5459484440931126

Epoch: 5| Step: 2
Training loss: 2.4910386645403286
Validation loss: 2.560783365485057

Epoch: 5| Step: 3
Training loss: 2.6337680610721828
Validation loss: 2.539070144275804

Epoch: 5| Step: 4
Training loss: 2.7556695582109065
Validation loss: 2.521085189757569

Epoch: 5| Step: 5
Training loss: 2.2203392462089244
Validation loss: 2.553416544329645

Epoch: 5| Step: 6
Training loss: 2.8008824626771944
Validation loss: 2.5224238779454007

Epoch: 5| Step: 7
Training loss: 2.9429318143442256
Validation loss: 2.527965797692696

Epoch: 5| Step: 8
Training loss: 2.890739314937663
Validation loss: 2.532854868071863

Epoch: 5| Step: 9
Training loss: 3.187868284005315
Validation loss: 2.5426759492841384

Epoch: 5| Step: 10
Training loss: 2.0263769531014684
Validation loss: 2.547586736800439

Epoch: 200| Step: 0
Training loss: 2.886250252705097
Validation loss: 2.5479888724941837

Epoch: 5| Step: 1
Training loss: 2.9574032427324672
Validation loss: 2.565726153467404

Epoch: 5| Step: 2
Training loss: 3.2659395057322387
Validation loss: 2.54742280398743

Epoch: 5| Step: 3
Training loss: 2.348405918256696
Validation loss: 2.546310910924306

Epoch: 5| Step: 4
Training loss: 2.8592350826529698
Validation loss: 2.5589232555019907

Epoch: 5| Step: 5
Training loss: 2.5944227701934097
Validation loss: 2.5209640235824384

Epoch: 5| Step: 6
Training loss: 3.044889615067242
Validation loss: 2.545974738420625

Epoch: 5| Step: 7
Training loss: 2.3202255695126737
Validation loss: 2.5769394023821706

Epoch: 5| Step: 8
Training loss: 2.229499993997776
Validation loss: 2.5466278799799587

Epoch: 5| Step: 9
Training loss: 2.4339221224585965
Validation loss: 2.566624591159168

Epoch: 5| Step: 10
Training loss: 2.4796722815466663
Validation loss: 2.5516772005854196

Epoch: 201| Step: 0
Training loss: 3.3536108911009834
Validation loss: 2.5661661807423655

Epoch: 5| Step: 1
Training loss: 2.2683262999474847
Validation loss: 2.5540073082960393

Epoch: 5| Step: 2
Training loss: 2.810856996224222
Validation loss: 2.5490523165580594

Epoch: 5| Step: 3
Training loss: 2.545579077411556
Validation loss: 2.553013309470657

Epoch: 5| Step: 4
Training loss: 2.6897928082963007
Validation loss: 2.606820829060645

Epoch: 5| Step: 5
Training loss: 2.4367220688699747
Validation loss: 2.56953430912905

Epoch: 5| Step: 6
Training loss: 2.5354543548850503
Validation loss: 2.5446878032080154

Epoch: 5| Step: 7
Training loss: 2.734638659163475
Validation loss: 2.5659645994029705

Epoch: 5| Step: 8
Training loss: 2.5948827636931906
Validation loss: 2.5260436582076444

Epoch: 5| Step: 9
Training loss: 2.96942452246709
Validation loss: 2.5466252706627577

Epoch: 5| Step: 10
Training loss: 2.564362012257089
Validation loss: 2.5700295956478327

Epoch: 202| Step: 0
Training loss: 2.1389249190341246
Validation loss: 2.5562825572916155

Epoch: 5| Step: 1
Training loss: 2.746584505207219
Validation loss: 2.524496652895179

Epoch: 5| Step: 2
Training loss: 2.3807947840077164
Validation loss: 2.5512240830322273

Epoch: 5| Step: 3
Training loss: 2.522473035806256
Validation loss: 2.5189985389543215

Epoch: 5| Step: 4
Training loss: 2.742254707404026
Validation loss: 2.563054935844686

Epoch: 5| Step: 5
Training loss: 2.690712893442733
Validation loss: 2.5575269238303155

Epoch: 5| Step: 6
Training loss: 2.494602289093296
Validation loss: 2.556578016282639

Epoch: 5| Step: 7
Training loss: 2.5359791976123653
Validation loss: 2.5420336674382797

Epoch: 5| Step: 8
Training loss: 2.9788905373675894
Validation loss: 2.5338278177210425

Epoch: 5| Step: 9
Training loss: 2.547584107332974
Validation loss: 2.55875014411332

Epoch: 5| Step: 10
Training loss: 3.6933859708686785
Validation loss: 2.5780798099220354

Epoch: 203| Step: 0
Training loss: 2.277763314963638
Validation loss: 2.589863285254638

Epoch: 5| Step: 1
Training loss: 2.902132296143449
Validation loss: 2.544759105348652

Epoch: 5| Step: 2
Training loss: 3.142716048529063
Validation loss: 2.5417273605122834

Epoch: 5| Step: 3
Training loss: 2.5692780334837813
Validation loss: 2.5256685526689298

Epoch: 5| Step: 4
Training loss: 2.7498474078758557
Validation loss: 2.532761512804849

Epoch: 5| Step: 5
Training loss: 2.5923836107898737
Validation loss: 2.5558476501454592

Epoch: 5| Step: 6
Training loss: 2.245769125658129
Validation loss: 2.537501304137548

Epoch: 5| Step: 7
Training loss: 3.156521624972796
Validation loss: 2.544992983219882

Epoch: 5| Step: 8
Training loss: 3.0478468689886964
Validation loss: 2.5599017893599303

Epoch: 5| Step: 9
Training loss: 2.6425307580462443
Validation loss: 2.5379294740779654

Epoch: 5| Step: 10
Training loss: 1.8733672344402907
Validation loss: 2.509228402968923

Epoch: 204| Step: 0
Training loss: 2.4069951872830995
Validation loss: 2.5484357760156913

Epoch: 5| Step: 1
Training loss: 3.3381007593214327
Validation loss: 2.5268627547855127

Epoch: 5| Step: 2
Training loss: 3.6146320849089095
Validation loss: 2.5500768089448935

Epoch: 5| Step: 3
Training loss: 2.328780933119397
Validation loss: 2.5377400604207625

Epoch: 5| Step: 4
Training loss: 2.2853901539611905
Validation loss: 2.5497326295913543

Epoch: 5| Step: 5
Training loss: 2.0029637311983692
Validation loss: 2.534990077283998

Epoch: 5| Step: 6
Training loss: 2.189001276656293
Validation loss: 2.566267028409726

Epoch: 5| Step: 7
Training loss: 2.589204136733144
Validation loss: 2.5477602937650956

Epoch: 5| Step: 8
Training loss: 2.6257846204604967
Validation loss: 2.543278412255826

Epoch: 5| Step: 9
Training loss: 3.3558191687113923
Validation loss: 2.57177705715959

Epoch: 5| Step: 10
Training loss: 2.67613843775295
Validation loss: 2.546501221826086

Epoch: 205| Step: 0
Training loss: 2.76622649295298
Validation loss: 2.5705502522262025

Epoch: 5| Step: 1
Training loss: 2.3241255028235366
Validation loss: 2.5312112739180193

Epoch: 5| Step: 2
Training loss: 2.65580665029961
Validation loss: 2.529138278965738

Epoch: 5| Step: 3
Training loss: 2.437485719296608
Validation loss: 2.5258150351504267

Epoch: 5| Step: 4
Training loss: 2.867339335482832
Validation loss: 2.5329477431908627

Epoch: 5| Step: 5
Training loss: 2.5477685589500405
Validation loss: 2.545379509633582

Epoch: 5| Step: 6
Training loss: 2.133904369739163
Validation loss: 2.5436113722343143

Epoch: 5| Step: 7
Training loss: 3.3705112135185225
Validation loss: 2.531038760363728

Epoch: 5| Step: 8
Training loss: 3.06503922429586
Validation loss: 2.5488265901311915

Epoch: 5| Step: 9
Training loss: 2.242131674467
Validation loss: 2.510357823680273

Epoch: 5| Step: 10
Training loss: 2.9961276493865308
Validation loss: 2.558471143700507

Epoch: 206| Step: 0
Training loss: 2.5763038445277786
Validation loss: 2.571378815158651

Epoch: 5| Step: 1
Training loss: 3.131800157409816
Validation loss: 2.5271656583324726

Epoch: 5| Step: 2
Training loss: 2.519960730564595
Validation loss: 2.545017206301592

Epoch: 5| Step: 3
Training loss: 2.6885483050101224
Validation loss: 2.531670076086743

Epoch: 5| Step: 4
Training loss: 2.4279411884582
Validation loss: 2.5661702287513135

Epoch: 5| Step: 5
Training loss: 1.8911552001026368
Validation loss: 2.542371265566304

Epoch: 5| Step: 6
Training loss: 3.4589184798388786
Validation loss: 2.529946461880013

Epoch: 5| Step: 7
Training loss: 3.0519821792522226
Validation loss: 2.538258315995567

Epoch: 5| Step: 8
Training loss: 2.7195159885380455
Validation loss: 2.5323401032799033

Epoch: 5| Step: 9
Training loss: 2.4398570279930585
Validation loss: 2.5615503195597693

Epoch: 5| Step: 10
Training loss: 1.949593914981874
Validation loss: 2.531873320645251

Epoch: 207| Step: 0
Training loss: 2.5616627697820893
Validation loss: 2.5083944500131805

Epoch: 5| Step: 1
Training loss: 2.4326899091523764
Validation loss: 2.5556534093313408

Epoch: 5| Step: 2
Training loss: 2.5930537013073542
Validation loss: 2.537743730497079

Epoch: 5| Step: 3
Training loss: 3.3390175673121782
Validation loss: 2.5311328846160546

Epoch: 5| Step: 4
Training loss: 2.814639909252355
Validation loss: 2.5423298990330956

Epoch: 5| Step: 5
Training loss: 2.6952856090144057
Validation loss: 2.565979308027272

Epoch: 5| Step: 6
Training loss: 2.383339045146509
Validation loss: 2.5092553957373793

Epoch: 5| Step: 7
Training loss: 2.1662081331058283
Validation loss: 2.528230927447391

Epoch: 5| Step: 8
Training loss: 2.622599094144196
Validation loss: 2.5417896648147447

Epoch: 5| Step: 9
Training loss: 3.041256149668342
Validation loss: 2.5417510529187934

Epoch: 5| Step: 10
Training loss: 2.896413914137915
Validation loss: 2.548847699022409

Epoch: 208| Step: 0
Training loss: 2.750087649942624
Validation loss: 2.542864630317834

Epoch: 5| Step: 1
Training loss: 2.5881891042494303
Validation loss: 2.56222126082778

Epoch: 5| Step: 2
Training loss: 2.8443249131790407
Validation loss: 2.551774802193242

Epoch: 5| Step: 3
Training loss: 2.877333316167785
Validation loss: 2.5104203627316664

Epoch: 5| Step: 4
Training loss: 2.842087815325982
Validation loss: 2.5356086152799295

Epoch: 5| Step: 5
Training loss: 2.7669821819728484
Validation loss: 2.526617364685161

Epoch: 5| Step: 6
Training loss: 2.524869907918109
Validation loss: 2.525040986483728

Epoch: 5| Step: 7
Training loss: 2.8740980972718555
Validation loss: 2.5566466765164995

Epoch: 5| Step: 8
Training loss: 2.2462092361614907
Validation loss: 2.5449939784589533

Epoch: 5| Step: 9
Training loss: 2.9718216916346307
Validation loss: 2.516945700839215

Epoch: 5| Step: 10
Training loss: 2.1931455513052946
Validation loss: 2.543910701364234

Epoch: 209| Step: 0
Training loss: 1.9223784120800897
Validation loss: 2.5134548002342

Epoch: 5| Step: 1
Training loss: 2.2367121071138913
Validation loss: 2.572473098590467

Epoch: 5| Step: 2
Training loss: 3.2227879352830002
Validation loss: 2.520288067916505

Epoch: 5| Step: 3
Training loss: 2.691004220642386
Validation loss: 2.5198644187727646

Epoch: 5| Step: 4
Training loss: 3.2628493491025545
Validation loss: 2.5650796828604

Epoch: 5| Step: 5
Training loss: 2.579016051776065
Validation loss: 2.542929420565899

Epoch: 5| Step: 6
Training loss: 2.679355255972511
Validation loss: 2.5780403916343237

Epoch: 5| Step: 7
Training loss: 2.802331301318792
Validation loss: 2.5768530240107648

Epoch: 5| Step: 8
Training loss: 2.8390215453499006
Validation loss: 2.5713726208482837

Epoch: 5| Step: 9
Training loss: 2.757760628274566
Validation loss: 2.552049771143252

Epoch: 5| Step: 10
Training loss: 2.3421198961758436
Validation loss: 2.553042135805393

Epoch: 210| Step: 0
Training loss: 2.5147170803738
Validation loss: 2.5751470973588004

Epoch: 5| Step: 1
Training loss: 3.0700504880350863
Validation loss: 2.5506104314724087

Epoch: 5| Step: 2
Training loss: 2.6458516958805984
Validation loss: 2.5705864254755517

Epoch: 5| Step: 3
Training loss: 2.201310079817217
Validation loss: 2.542318107990762

Epoch: 5| Step: 4
Training loss: 2.7055448604566434
Validation loss: 2.5563077996170476

Epoch: 5| Step: 5
Training loss: 2.5950621078203167
Validation loss: 2.5269995617623406

Epoch: 5| Step: 6
Training loss: 2.766057643347662
Validation loss: 2.54892774667042

Epoch: 5| Step: 7
Training loss: 2.723175130736834
Validation loss: 2.553227742413822

Epoch: 5| Step: 8
Training loss: 2.199894477741103
Validation loss: 2.558907843095142

Epoch: 5| Step: 9
Training loss: 3.0310313352389144
Validation loss: 2.5328514981009733

Epoch: 5| Step: 10
Training loss: 3.0300507680334916
Validation loss: 2.539408010192551

Epoch: 211| Step: 0
Training loss: 2.642326935123676
Validation loss: 2.530148655354688

Epoch: 5| Step: 1
Training loss: 2.491146240829848
Validation loss: 2.5323385057748156

Epoch: 5| Step: 2
Training loss: 2.266067146040419
Validation loss: 2.520932994863373

Epoch: 5| Step: 3
Training loss: 2.53250938451446
Validation loss: 2.5704403331276673

Epoch: 5| Step: 4
Training loss: 2.851434908585997
Validation loss: 2.5481528855948063

Epoch: 5| Step: 5
Training loss: 2.3142814991086755
Validation loss: 2.5419196332954272

Epoch: 5| Step: 6
Training loss: 2.6023534540403728
Validation loss: 2.5720223967671183

Epoch: 5| Step: 7
Training loss: 3.199596415341994
Validation loss: 2.5321151448002306

Epoch: 5| Step: 8
Training loss: 2.702342807739835
Validation loss: 2.5367980845383338

Epoch: 5| Step: 9
Training loss: 2.83099371484876
Validation loss: 2.544299069854573

Epoch: 5| Step: 10
Training loss: 2.9822282509696247
Validation loss: 2.569034079327176

Epoch: 212| Step: 0
Training loss: 2.5332812412661716
Validation loss: 2.5338903390247816

Epoch: 5| Step: 1
Training loss: 2.8788214454945034
Validation loss: 2.574399428117665

Epoch: 5| Step: 2
Training loss: 2.2293938018972757
Validation loss: 2.530793541177933

Epoch: 5| Step: 3
Training loss: 3.084222012545215
Validation loss: 2.5559839378116846

Epoch: 5| Step: 4
Training loss: 2.2321376669687147
Validation loss: 2.525600924584572

Epoch: 5| Step: 5
Training loss: 2.5418882638187985
Validation loss: 2.5417074562994335

Epoch: 5| Step: 6
Training loss: 2.8598585710035693
Validation loss: 2.5580394217969773

Epoch: 5| Step: 7
Training loss: 2.511643855044688
Validation loss: 2.513572035042528

Epoch: 5| Step: 8
Training loss: 2.3551127352934005
Validation loss: 2.5768570005137392

Epoch: 5| Step: 9
Training loss: 2.8212359916261485
Validation loss: 2.5113458586435065

Epoch: 5| Step: 10
Training loss: 3.3169335978327394
Validation loss: 2.568496704547495

Epoch: 213| Step: 0
Training loss: 2.997442267771075
Validation loss: 2.5553058408932565

Epoch: 5| Step: 1
Training loss: 2.748980072926178
Validation loss: 2.55178504156582

Epoch: 5| Step: 2
Training loss: 2.535192645124683
Validation loss: 2.567985438011835

Epoch: 5| Step: 3
Training loss: 3.0160937957850624
Validation loss: 2.5199277677241434

Epoch: 5| Step: 4
Training loss: 3.4949205870331257
Validation loss: 2.568170859058773

Epoch: 5| Step: 5
Training loss: 2.6180904823444653
Validation loss: 2.5637856116510713

Epoch: 5| Step: 6
Training loss: 2.265804309984112
Validation loss: 2.5177215561026176

Epoch: 5| Step: 7
Training loss: 2.326876619242623
Validation loss: 2.519172774595306

Epoch: 5| Step: 8
Training loss: 2.3317325982276467
Validation loss: 2.5513261332638266

Epoch: 5| Step: 9
Training loss: 2.1561051472093733
Validation loss: 2.553468333849039

Epoch: 5| Step: 10
Training loss: 2.845868673333219
Validation loss: 2.5631546436853685

Epoch: 214| Step: 0
Training loss: 2.5600869517162694
Validation loss: 2.546254281494643

Epoch: 5| Step: 1
Training loss: 2.620091981656386
Validation loss: 2.566833295741706

Epoch: 5| Step: 2
Training loss: 2.5117775063294303
Validation loss: 2.543874258639791

Epoch: 5| Step: 3
Training loss: 2.508209292195249
Validation loss: 2.560908216595958

Epoch: 5| Step: 4
Training loss: 2.253255079009104
Validation loss: 2.548878028854766

Epoch: 5| Step: 5
Training loss: 2.734260425892004
Validation loss: 2.5248460682729625

Epoch: 5| Step: 6
Training loss: 3.1965475889852573
Validation loss: 2.5338114796722775

Epoch: 5| Step: 7
Training loss: 3.013693077027655
Validation loss: 2.576381981874345

Epoch: 5| Step: 8
Training loss: 3.4438458216467716
Validation loss: 2.5226975716271745

Epoch: 5| Step: 9
Training loss: 2.07860829175978
Validation loss: 2.5448165346795215

Epoch: 5| Step: 10
Training loss: 2.2126869855413096
Validation loss: 2.5368305937189746

Epoch: 215| Step: 0
Training loss: 1.885620871878541
Validation loss: 2.540005015831025

Epoch: 5| Step: 1
Training loss: 2.712938609018138
Validation loss: 2.5541424540676716

Epoch: 5| Step: 2
Training loss: 2.984334416138485
Validation loss: 2.5427246914193757

Epoch: 5| Step: 3
Training loss: 2.6751484589067505
Validation loss: 2.5371653304756934

Epoch: 5| Step: 4
Training loss: 3.109575734775594
Validation loss: 2.5487378679129487

Epoch: 5| Step: 5
Training loss: 2.4674996215448988
Validation loss: 2.5572323283593454

Epoch: 5| Step: 6
Training loss: 3.2922395779003475
Validation loss: 2.5445803324307397

Epoch: 5| Step: 7
Training loss: 2.6842893007252018
Validation loss: 2.5467019685739047

Epoch: 5| Step: 8
Training loss: 2.171298163126336
Validation loss: 2.58205732481626

Epoch: 5| Step: 9
Training loss: 3.011231062573417
Validation loss: 2.539454447719289

Epoch: 5| Step: 10
Training loss: 2.1770511119836975
Validation loss: 2.5291608785186748

Epoch: 216| Step: 0
Training loss: 2.807302207195662
Validation loss: 2.562317102099357

Epoch: 5| Step: 1
Training loss: 2.6125558436507816
Validation loss: 2.552981208196928

Epoch: 5| Step: 2
Training loss: 2.387757919520458
Validation loss: 2.5285585405969324

Epoch: 5| Step: 3
Training loss: 3.5009604907232217
Validation loss: 2.5359135160734323

Epoch: 5| Step: 4
Training loss: 2.5262401594586605
Validation loss: 2.5400699466417795

Epoch: 5| Step: 5
Training loss: 2.95081654901982
Validation loss: 2.5369718520789766

Epoch: 5| Step: 6
Training loss: 2.09707377780693
Validation loss: 2.5353075243326284

Epoch: 5| Step: 7
Training loss: 2.6115932515465414
Validation loss: 2.570339681117157

Epoch: 5| Step: 8
Training loss: 3.2653856691699388
Validation loss: 2.576624240895555

Epoch: 5| Step: 9
Training loss: 2.136220368279693
Validation loss: 2.542330695655039

Epoch: 5| Step: 10
Training loss: 2.1861451449149047
Validation loss: 2.546505466702011

Epoch: 217| Step: 0
Training loss: 2.9014961986947423
Validation loss: 2.531903347547315

Epoch: 5| Step: 1
Training loss: 2.447573168306739
Validation loss: 2.544974588351551

Epoch: 5| Step: 2
Training loss: 2.523122100488236
Validation loss: 2.5338832482283657

Epoch: 5| Step: 3
Training loss: 2.595569661701241
Validation loss: 2.5438667799662458

Epoch: 5| Step: 4
Training loss: 1.8969853502631904
Validation loss: 2.5418078996731426

Epoch: 5| Step: 5
Training loss: 2.1960065837268075
Validation loss: 2.524452834461242

Epoch: 5| Step: 6
Training loss: 2.8775616718911707
Validation loss: 2.5228354153786827

Epoch: 5| Step: 7
Training loss: 2.722009743509785
Validation loss: 2.5281635032796483

Epoch: 5| Step: 8
Training loss: 2.920919496695648
Validation loss: 2.544999168704988

Epoch: 5| Step: 9
Training loss: 2.966399215758219
Validation loss: 2.5460361105980875

Epoch: 5| Step: 10
Training loss: 3.1647558135559266
Validation loss: 2.5735981436327333

Epoch: 218| Step: 0
Training loss: 2.632581842206298
Validation loss: 2.554803879797613

Epoch: 5| Step: 1
Training loss: 2.9380666308030823
Validation loss: 2.5476568941763804

Epoch: 5| Step: 2
Training loss: 2.4149461628854194
Validation loss: 2.5356504463385936

Epoch: 5| Step: 3
Training loss: 2.836629315528954
Validation loss: 2.523238625527125

Epoch: 5| Step: 4
Training loss: 2.2784102021956
Validation loss: 2.5524922786405955

Epoch: 5| Step: 5
Training loss: 2.2129378149618626
Validation loss: 2.5223075429376713

Epoch: 5| Step: 6
Training loss: 2.8074123566586766
Validation loss: 2.56897252658426

Epoch: 5| Step: 7
Training loss: 3.120232416690699
Validation loss: 2.5446145415423707

Epoch: 5| Step: 8
Training loss: 3.019791329103003
Validation loss: 2.559613436605956

Epoch: 5| Step: 9
Training loss: 2.3726693814655038
Validation loss: 2.5123984520249496

Epoch: 5| Step: 10
Training loss: 2.742647485653288
Validation loss: 2.568922096473407

Epoch: 219| Step: 0
Training loss: 2.6137882761476408
Validation loss: 2.505967380023334

Epoch: 5| Step: 1
Training loss: 2.0413757298579016
Validation loss: 2.554045294755361

Epoch: 5| Step: 2
Training loss: 2.8534044979110007
Validation loss: 2.579086846209473

Epoch: 5| Step: 3
Training loss: 2.298417799377033
Validation loss: 2.509999370515224

Epoch: 5| Step: 4
Training loss: 3.3386978057357783
Validation loss: 2.555633154144679

Epoch: 5| Step: 5
Training loss: 2.6640023591085535
Validation loss: 2.499445782008714

Epoch: 5| Step: 6
Training loss: 3.5864604493835808
Validation loss: 2.535470988713883

Epoch: 5| Step: 7
Training loss: 2.0531900845551125
Validation loss: 2.52888421763205

Epoch: 5| Step: 8
Training loss: 2.688309924486303
Validation loss: 2.549696884421044

Epoch: 5| Step: 9
Training loss: 2.213692717540732
Validation loss: 2.5060078000180512

Epoch: 5| Step: 10
Training loss: 3.055591654323462
Validation loss: 2.5482708284109794

Epoch: 220| Step: 0
Training loss: 2.886678114670863
Validation loss: 2.516330620796824

Epoch: 5| Step: 1
Training loss: 3.034781689404322
Validation loss: 2.5648657040429823

Epoch: 5| Step: 2
Training loss: 3.4606065441188547
Validation loss: 2.5282323452804993

Epoch: 5| Step: 3
Training loss: 2.4936914958162233
Validation loss: 2.5520142422620475

Epoch: 5| Step: 4
Training loss: 1.9218419390059993
Validation loss: 2.5593147830579617

Epoch: 5| Step: 5
Training loss: 2.7731889640235274
Validation loss: 2.543870551050574

Epoch: 5| Step: 6
Training loss: 2.793572377952534
Validation loss: 2.5734811105329154

Epoch: 5| Step: 7
Training loss: 2.1622035446266374
Validation loss: 2.5609900435040864

Epoch: 5| Step: 8
Training loss: 2.4254633745909118
Validation loss: 2.5722507171120372

Epoch: 5| Step: 9
Training loss: 2.889614279062639
Validation loss: 2.5547298836683328

Epoch: 5| Step: 10
Training loss: 2.3061233444377476
Validation loss: 2.54623376074283

Epoch: 221| Step: 0
Training loss: 2.9933531559866235
Validation loss: 2.5283663848434803

Epoch: 5| Step: 1
Training loss: 2.522115071532525
Validation loss: 2.5439441248757304

Epoch: 5| Step: 2
Training loss: 2.43329541381484
Validation loss: 2.5851604157947596

Epoch: 5| Step: 3
Training loss: 2.572662577779143
Validation loss: 2.53200848699377

Epoch: 5| Step: 4
Training loss: 3.093415829884827
Validation loss: 2.5329232356601312

Epoch: 5| Step: 5
Training loss: 3.152843185246744
Validation loss: 2.53443562997388

Epoch: 5| Step: 6
Training loss: 2.73959210373861
Validation loss: 2.5378843885111646

Epoch: 5| Step: 7
Training loss: 2.6158546811784507
Validation loss: 2.5533744039225503

Epoch: 5| Step: 8
Training loss: 1.994890720175698
Validation loss: 2.554108325897062

Epoch: 5| Step: 9
Training loss: 2.7493425797209237
Validation loss: 2.5460169992894617

Epoch: 5| Step: 10
Training loss: 2.2343540857576696
Validation loss: 2.580904040375092

Epoch: 222| Step: 0
Training loss: 2.6814054537437904
Validation loss: 2.5370894689135133

Epoch: 5| Step: 1
Training loss: 2.7889682956889112
Validation loss: 2.5232092885190784

Epoch: 5| Step: 2
Training loss: 2.6177083422388474
Validation loss: 2.5619157754931026

Epoch: 5| Step: 3
Training loss: 3.153375506397959
Validation loss: 2.5692612204003056

Epoch: 5| Step: 4
Training loss: 2.105517781382068
Validation loss: 2.551243726094768

Epoch: 5| Step: 5
Training loss: 2.90378129355178
Validation loss: 2.542697739384456

Epoch: 5| Step: 6
Training loss: 2.8647716853323635
Validation loss: 2.563108828590774

Epoch: 5| Step: 7
Training loss: 2.2220929174420987
Validation loss: 2.5568763959299816

Epoch: 5| Step: 8
Training loss: 2.6680300525419667
Validation loss: 2.526478288418181

Epoch: 5| Step: 9
Training loss: 2.743054027530121
Validation loss: 2.5247551081961634

Epoch: 5| Step: 10
Training loss: 2.6986403114605046
Validation loss: 2.5524831901016776

Epoch: 223| Step: 0
Training loss: 2.437725545767369
Validation loss: 2.5523463237802746

Epoch: 5| Step: 1
Training loss: 2.9537851715899692
Validation loss: 2.534525818819186

Epoch: 5| Step: 2
Training loss: 2.0123940528798436
Validation loss: 2.54111142669287

Epoch: 5| Step: 3
Training loss: 3.062901995997417
Validation loss: 2.5339103815338655

Epoch: 5| Step: 4
Training loss: 2.9260420027330114
Validation loss: 2.570485442085615

Epoch: 5| Step: 5
Training loss: 2.7600576971077118
Validation loss: 2.541762193014019

Epoch: 5| Step: 6
Training loss: 2.9829964374721736
Validation loss: 2.5619642216307157

Epoch: 5| Step: 7
Training loss: 2.578236987831721
Validation loss: 2.5100594100716136

Epoch: 5| Step: 8
Training loss: 2.769941506714999
Validation loss: 2.560214093806141

Epoch: 5| Step: 9
Training loss: 2.4091052665086323
Validation loss: 2.5474499576200578

Epoch: 5| Step: 10
Training loss: 2.3071633698649476
Validation loss: 2.5649563621178872

Epoch: 224| Step: 0
Training loss: 2.16675639578057
Validation loss: 2.5559287413650056

Epoch: 5| Step: 1
Training loss: 3.207374693756166
Validation loss: 2.5618747255453624

Epoch: 5| Step: 2
Training loss: 2.306386134153797
Validation loss: 2.545084747058074

Epoch: 5| Step: 3
Training loss: 2.4029393395979843
Validation loss: 2.5291535671741143

Epoch: 5| Step: 4
Training loss: 2.862268037017998
Validation loss: 2.5347721717697627

Epoch: 5| Step: 5
Training loss: 2.589784095042586
Validation loss: 2.5502628437262227

Epoch: 5| Step: 6
Training loss: 2.4347023191748938
Validation loss: 2.576046610241808

Epoch: 5| Step: 7
Training loss: 3.108340143872965
Validation loss: 2.562090246943467

Epoch: 5| Step: 8
Training loss: 2.6599609482558835
Validation loss: 2.5864948777028336

Epoch: 5| Step: 9
Training loss: 3.263406684552469
Validation loss: 2.5607484032800154

Epoch: 5| Step: 10
Training loss: 2.034517565066642
Validation loss: 2.5407159083776887

Epoch: 225| Step: 0
Training loss: 2.804040265647205
Validation loss: 2.558145273884402

Epoch: 5| Step: 1
Training loss: 2.0487059346755703
Validation loss: 2.5157517080434775

Epoch: 5| Step: 2
Training loss: 2.633073471220693
Validation loss: 2.574097753401783

Epoch: 5| Step: 3
Training loss: 2.6228888059979116
Validation loss: 2.586650437207502

Epoch: 5| Step: 4
Training loss: 3.057486810039725
Validation loss: 2.5405427501044406

Epoch: 5| Step: 5
Training loss: 2.3363262350626135
Validation loss: 2.5320153425739678

Epoch: 5| Step: 6
Training loss: 3.0150742101946606
Validation loss: 2.5252755586049744

Epoch: 5| Step: 7
Training loss: 2.7949971122931507
Validation loss: 2.5242147104392574

Epoch: 5| Step: 8
Training loss: 2.825569389148723
Validation loss: 2.5268685468719987

Epoch: 5| Step: 9
Training loss: 2.331079336674505
Validation loss: 2.541090091107506

Epoch: 5| Step: 10
Training loss: 2.6847561868684586
Validation loss: 2.512056619672225

Epoch: 226| Step: 0
Training loss: 2.1678192911953165
Validation loss: 2.528917798685408

Epoch: 5| Step: 1
Training loss: 2.670775427069063
Validation loss: 2.5362180304711015

Epoch: 5| Step: 2
Training loss: 2.9582012487305054
Validation loss: 2.542911261800019

Epoch: 5| Step: 3
Training loss: 2.146398402011773
Validation loss: 2.5143174865327205

Epoch: 5| Step: 4
Training loss: 2.601406058341757
Validation loss: 2.5376319589880265

Epoch: 5| Step: 5
Training loss: 2.0919331881063927
Validation loss: 2.5100510707628

Epoch: 5| Step: 6
Training loss: 2.2690639310180036
Validation loss: 2.550385570712259

Epoch: 5| Step: 7
Training loss: 3.4008788711975053
Validation loss: 2.5147637852466143

Epoch: 5| Step: 8
Training loss: 2.770682242344512
Validation loss: 2.532666367005452

Epoch: 5| Step: 9
Training loss: 3.1495244348392366
Validation loss: 2.5545776319478213

Epoch: 5| Step: 10
Training loss: 2.768129497084299
Validation loss: 2.518486682617375

Epoch: 227| Step: 0
Training loss: 2.6399385361307828
Validation loss: 2.5402807935450884

Epoch: 5| Step: 1
Training loss: 2.161691737307791
Validation loss: 2.5264225112699488

Epoch: 5| Step: 2
Training loss: 2.2571835813418346
Validation loss: 2.557070004460912

Epoch: 5| Step: 3
Training loss: 2.630187404033118
Validation loss: 2.526974694220056

Epoch: 5| Step: 4
Training loss: 2.771446007321193
Validation loss: 2.5239916513357343

Epoch: 5| Step: 5
Training loss: 2.3508113028778554
Validation loss: 2.548611086783302

Epoch: 5| Step: 6
Training loss: 2.611586952364313
Validation loss: 2.530531591519238

Epoch: 5| Step: 7
Training loss: 3.0629144504916024
Validation loss: 2.535162150553743

Epoch: 5| Step: 8
Training loss: 2.2964400314251905
Validation loss: 2.5441846349383095

Epoch: 5| Step: 9
Training loss: 3.3618597732882773
Validation loss: 2.555601596380386

Epoch: 5| Step: 10
Training loss: 2.8317103131728523
Validation loss: 2.5301446034160446

Epoch: 228| Step: 0
Training loss: 2.092609151639034
Validation loss: 2.554416733589491

Epoch: 5| Step: 1
Training loss: 3.4725447509167022
Validation loss: 2.5482707278078314

Epoch: 5| Step: 2
Training loss: 2.9188402705150334
Validation loss: 2.5280521113541483

Epoch: 5| Step: 3
Training loss: 2.783255636154851
Validation loss: 2.5729772281547962

Epoch: 5| Step: 4
Training loss: 2.4564078166241585
Validation loss: 2.5369801827266665

Epoch: 5| Step: 5
Training loss: 2.5679917453145964
Validation loss: 2.532924297381397

Epoch: 5| Step: 6
Training loss: 2.717600173718186
Validation loss: 2.5502219133131705

Epoch: 5| Step: 7
Training loss: 2.231688585104887
Validation loss: 2.5342199377332677

Epoch: 5| Step: 8
Training loss: 2.3742957827895754
Validation loss: 2.5420606252533684

Epoch: 5| Step: 9
Training loss: 2.7718906440852487
Validation loss: 2.5356394077944504

Epoch: 5| Step: 10
Training loss: 2.8107858308392912
Validation loss: 2.5379294760982267

Epoch: 229| Step: 0
Training loss: 1.9506879326649178
Validation loss: 2.532108238867593

Epoch: 5| Step: 1
Training loss: 2.3853580073400202
Validation loss: 2.5540951694440506

Epoch: 5| Step: 2
Training loss: 2.724105996286471
Validation loss: 2.551569156110436

Epoch: 5| Step: 3
Training loss: 3.2408061934224324
Validation loss: 2.5371360761930917

Epoch: 5| Step: 4
Training loss: 1.8489869308051061
Validation loss: 2.534355648577816

Epoch: 5| Step: 5
Training loss: 2.7027412980133367
Validation loss: 2.553764610829973

Epoch: 5| Step: 6
Training loss: 2.8652338757348748
Validation loss: 2.5623320817891733

Epoch: 5| Step: 7
Training loss: 2.2764081390768918
Validation loss: 2.5427169119372044

Epoch: 5| Step: 8
Training loss: 2.852863506187515
Validation loss: 2.5729231893905045

Epoch: 5| Step: 9
Training loss: 3.140062727817925
Validation loss: 2.5536867045243685

Epoch: 5| Step: 10
Training loss: 2.9565850227319808
Validation loss: 2.555094210113509

Epoch: 230| Step: 0
Training loss: 2.9018242064218134
Validation loss: 2.5412962976685396

Epoch: 5| Step: 1
Training loss: 2.9768556465514537
Validation loss: 2.5619743212151342

Epoch: 5| Step: 2
Training loss: 2.51923542503872
Validation loss: 2.54322869085156

Epoch: 5| Step: 3
Training loss: 1.9215800361372857
Validation loss: 2.522777352540582

Epoch: 5| Step: 4
Training loss: 2.6246073292904386
Validation loss: 2.5522548742614566

Epoch: 5| Step: 5
Training loss: 2.215917148886659
Validation loss: 2.553968223128755

Epoch: 5| Step: 6
Training loss: 2.782495369851646
Validation loss: 2.539197410867647

Epoch: 5| Step: 7
Training loss: 2.968707275083186
Validation loss: 2.5643740348458905

Epoch: 5| Step: 8
Training loss: 2.54006684613313
Validation loss: 2.533234440611728

Epoch: 5| Step: 9
Training loss: 2.3838930775391667
Validation loss: 2.529177768627024

Epoch: 5| Step: 10
Training loss: 3.045804349149955
Validation loss: 2.5365442744606215

Epoch: 231| Step: 0
Training loss: 2.635677420239816
Validation loss: 2.546018342523111

Epoch: 5| Step: 1
Training loss: 2.7124219012993156
Validation loss: 2.57249871420948

Epoch: 5| Step: 2
Training loss: 2.967040041312299
Validation loss: 2.5584992692604343

Epoch: 5| Step: 3
Training loss: 2.122337693118221
Validation loss: 2.5293777268553135

Epoch: 5| Step: 4
Training loss: 2.6608722636211053
Validation loss: 2.536205699540652

Epoch: 5| Step: 5
Training loss: 3.0482507974064665
Validation loss: 2.5594342749021086

Epoch: 5| Step: 6
Training loss: 2.913663535125985
Validation loss: 2.5571176571522516

Epoch: 5| Step: 7
Training loss: 2.9026652552096444
Validation loss: 2.524834227057146

Epoch: 5| Step: 8
Training loss: 2.4691793334031797
Validation loss: 2.560202047677079

Epoch: 5| Step: 9
Training loss: 2.3556163229191682
Validation loss: 2.513069876570001

Epoch: 5| Step: 10
Training loss: 2.2298891079277428
Validation loss: 2.5606414874309085

Epoch: 232| Step: 0
Training loss: 2.7543472261632065
Validation loss: 2.5167988834584865

Epoch: 5| Step: 1
Training loss: 2.5001141522095285
Validation loss: 2.5245084652293617

Epoch: 5| Step: 2
Training loss: 2.8258596378303196
Validation loss: 2.5515967478840356

Epoch: 5| Step: 3
Training loss: 2.328402304295676
Validation loss: 2.550442818065177

Epoch: 5| Step: 4
Training loss: 2.744571269172765
Validation loss: 2.522289331249383

Epoch: 5| Step: 5
Training loss: 2.8747721042700514
Validation loss: 2.558804005295009

Epoch: 5| Step: 6
Training loss: 2.9765338245522446
Validation loss: 2.574390313353258

Epoch: 5| Step: 7
Training loss: 2.601410182583538
Validation loss: 2.5712431131745346

Epoch: 5| Step: 8
Training loss: 2.360694263786392
Validation loss: 2.57601587479261

Epoch: 5| Step: 9
Training loss: 2.318902200397538
Validation loss: 2.555769725083613

Epoch: 5| Step: 10
Training loss: 2.7296757890507948
Validation loss: 2.559971670322792

Epoch: 233| Step: 0
Training loss: 2.85266760745757
Validation loss: 2.5662619815751286

Epoch: 5| Step: 1
Training loss: 3.2098850279566395
Validation loss: 2.562393425366723

Epoch: 5| Step: 2
Training loss: 2.5102836816368943
Validation loss: 2.5671591662039797

Epoch: 5| Step: 3
Training loss: 2.7785455649296775
Validation loss: 2.52253660584205

Epoch: 5| Step: 4
Training loss: 2.763545143268084
Validation loss: 2.5857768244156767

Epoch: 5| Step: 5
Training loss: 2.4586103789691753
Validation loss: 2.5400076834236476

Epoch: 5| Step: 6
Training loss: 1.7104775145746876
Validation loss: 2.531140791870273

Epoch: 5| Step: 7
Training loss: 2.630786149918226
Validation loss: 2.525378319368075

Epoch: 5| Step: 8
Training loss: 2.7120832061494053
Validation loss: 2.550412460602907

Epoch: 5| Step: 9
Training loss: 2.7219808389296203
Validation loss: 2.505751857433624

Epoch: 5| Step: 10
Training loss: 2.6266209275318437
Validation loss: 2.5231727362908765

Epoch: 234| Step: 0
Training loss: 2.789854562311684
Validation loss: 2.5619201859567418

Epoch: 5| Step: 1
Training loss: 2.5519741009022847
Validation loss: 2.5470660291707357

Epoch: 5| Step: 2
Training loss: 3.040197792896719
Validation loss: 2.5542081471159817

Epoch: 5| Step: 3
Training loss: 2.4070536274722554
Validation loss: 2.555686789111389

Epoch: 5| Step: 4
Training loss: 2.0895708422859562
Validation loss: 2.5526173675558192

Epoch: 5| Step: 5
Training loss: 3.1041365927107742
Validation loss: 2.561957357132698

Epoch: 5| Step: 6
Training loss: 2.341037655807399
Validation loss: 2.5266010682860274

Epoch: 5| Step: 7
Training loss: 2.2655812226374024
Validation loss: 2.5691976559723977

Epoch: 5| Step: 8
Training loss: 2.576381856994995
Validation loss: 2.5532727227184258

Epoch: 5| Step: 9
Training loss: 3.715475868973228
Validation loss: 2.5409159090330014

Epoch: 5| Step: 10
Training loss: 1.824288801853577
Validation loss: 2.5539044386816134

Epoch: 235| Step: 0
Training loss: 3.497662308521319
Validation loss: 2.5670856630314702

Epoch: 5| Step: 1
Training loss: 3.3242213319797553
Validation loss: 2.5425696397120263

Epoch: 5| Step: 2
Training loss: 3.1446836446476696
Validation loss: 2.5246492625347967

Epoch: 5| Step: 3
Training loss: 2.5355724586720587
Validation loss: 2.531907462486018

Epoch: 5| Step: 4
Training loss: 2.2205431502267734
Validation loss: 2.528931579297757

Epoch: 5| Step: 5
Training loss: 2.222617955204759
Validation loss: 2.5647017721386343

Epoch: 5| Step: 6
Training loss: 2.390419346559257
Validation loss: 2.5362210295497203

Epoch: 5| Step: 7
Training loss: 2.6579634581523215
Validation loss: 2.5219586038110124

Epoch: 5| Step: 8
Training loss: 2.156587657198555
Validation loss: 2.5420318299508438

Epoch: 5| Step: 9
Training loss: 1.9391012035752309
Validation loss: 2.5259202889722387

Epoch: 5| Step: 10
Training loss: 2.987069396585404
Validation loss: 2.5025703639856114

Epoch: 236| Step: 0
Training loss: 2.3938697286996673
Validation loss: 2.5784643223993045

Epoch: 5| Step: 1
Training loss: 2.607642963765755
Validation loss: 2.527762318057189

Epoch: 5| Step: 2
Training loss: 1.9749559952867537
Validation loss: 2.547978146989458

Epoch: 5| Step: 3
Training loss: 2.877536815470768
Validation loss: 2.5249154319884592

Epoch: 5| Step: 4
Training loss: 2.7043925053396025
Validation loss: 2.526311554026593

Epoch: 5| Step: 5
Training loss: 2.400142498554346
Validation loss: 2.5165830100219093

Epoch: 5| Step: 6
Training loss: 2.8947992651200107
Validation loss: 2.5494956168173277

Epoch: 5| Step: 7
Training loss: 3.1939963169255816
Validation loss: 2.5504818763426313

Epoch: 5| Step: 8
Training loss: 3.0152824879363567
Validation loss: 2.5775853322771836

Epoch: 5| Step: 9
Training loss: 2.4800563679718794
Validation loss: 2.514969297177736

Epoch: 5| Step: 10
Training loss: 2.7974989211120436
Validation loss: 2.5932249933236853

Epoch: 237| Step: 0
Training loss: 2.6105252774338528
Validation loss: 2.54558183282271

Epoch: 5| Step: 1
Training loss: 3.0131425670846768
Validation loss: 2.5322876827200065

Epoch: 5| Step: 2
Training loss: 2.468635266692116
Validation loss: 2.522239385136312

Epoch: 5| Step: 3
Training loss: 2.7770315174516256
Validation loss: 2.5675341800782565

Epoch: 5| Step: 4
Training loss: 2.5764951235611955
Validation loss: 2.556902291124414

Epoch: 5| Step: 5
Training loss: 2.4270361266777583
Validation loss: 2.5187778621895305

Epoch: 5| Step: 6
Training loss: 2.447135270308727
Validation loss: 2.5337672243590617

Epoch: 5| Step: 7
Training loss: 2.6157282618622264
Validation loss: 2.5361093061696858

Epoch: 5| Step: 8
Training loss: 2.7844362331383303
Validation loss: 2.527166505384016

Epoch: 5| Step: 9
Training loss: 2.60167072976003
Validation loss: 2.5298293510057133

Epoch: 5| Step: 10
Training loss: 2.974371636972532
Validation loss: 2.537671764514483

Epoch: 238| Step: 0
Training loss: 2.440766029337315
Validation loss: 2.560449205273223

Epoch: 5| Step: 1
Training loss: 2.7914550093698334
Validation loss: 2.525429085550296

Epoch: 5| Step: 2
Training loss: 2.5333102283762643
Validation loss: 2.525576106712884

Epoch: 5| Step: 3
Training loss: 2.473857087857704
Validation loss: 2.5449205201067095

Epoch: 5| Step: 4
Training loss: 2.201489646469677
Validation loss: 2.554345129460012

Epoch: 5| Step: 5
Training loss: 2.573466583254376
Validation loss: 2.56771363824394

Epoch: 5| Step: 6
Training loss: 2.5644763675284312
Validation loss: 2.523789562385021

Epoch: 5| Step: 7
Training loss: 2.2372593968776253
Validation loss: 2.560030199919538

Epoch: 5| Step: 8
Training loss: 2.929195759512564
Validation loss: 2.5407110206658663

Epoch: 5| Step: 9
Training loss: 3.6211358883740212
Validation loss: 2.5294019464341773

Epoch: 5| Step: 10
Training loss: 2.069841324073428
Validation loss: 2.5409077910604894

Epoch: 239| Step: 0
Training loss: 3.511008660784116
Validation loss: 2.579227580407894

Epoch: 5| Step: 1
Training loss: 2.1556831388743225
Validation loss: 2.5565518550771844

Epoch: 5| Step: 2
Training loss: 2.3838570728469035
Validation loss: 2.523304618705338

Epoch: 5| Step: 3
Training loss: 2.157002525041612
Validation loss: 2.5617574210588825

Epoch: 5| Step: 4
Training loss: 2.6102861652395353
Validation loss: 2.5485048904995384

Epoch: 5| Step: 5
Training loss: 2.3113872840921723
Validation loss: 2.534191894754755

Epoch: 5| Step: 6
Training loss: 2.910291589239713
Validation loss: 2.5493145202111474

Epoch: 5| Step: 7
Training loss: 2.475998775210717
Validation loss: 2.5489333568615082

Epoch: 5| Step: 8
Training loss: 3.130771343019242
Validation loss: 2.543160685484532

Epoch: 5| Step: 9
Training loss: 2.3884302174558094
Validation loss: 2.535359400134168

Epoch: 5| Step: 10
Training loss: 2.8135774032279754
Validation loss: 2.5297175946400463

Epoch: 240| Step: 0
Training loss: 2.5845834927023565
Validation loss: 2.5272410650961414

Epoch: 5| Step: 1
Training loss: 2.145929933120499
Validation loss: 2.541482626917201

Epoch: 5| Step: 2
Training loss: 3.0091164672968915
Validation loss: 2.559616894034867

Epoch: 5| Step: 3
Training loss: 2.98940488346962
Validation loss: 2.547229865178138

Epoch: 5| Step: 4
Training loss: 2.6719618219914616
Validation loss: 2.509376729345177

Epoch: 5| Step: 5
Training loss: 2.08347028917917
Validation loss: 2.511304637456031

Epoch: 5| Step: 6
Training loss: 2.4956878666419517
Validation loss: 2.5288343368913684

Epoch: 5| Step: 7
Training loss: 2.92404371752327
Validation loss: 2.550164355394812

Epoch: 5| Step: 8
Training loss: 2.5625701522528677
Validation loss: 2.516530456828354

Epoch: 5| Step: 9
Training loss: 2.8249792655251422
Validation loss: 2.5440428338588252

Epoch: 5| Step: 10
Training loss: 2.3027683349383046
Validation loss: 2.5363883931361566

Epoch: 241| Step: 0
Training loss: 2.588951267760674
Validation loss: 2.550119061900556

Epoch: 5| Step: 1
Training loss: 2.373093190938189
Validation loss: 2.5470714200183053

Epoch: 5| Step: 2
Training loss: 2.3210432655085405
Validation loss: 2.578197946818483

Epoch: 5| Step: 3
Training loss: 2.567172094427728
Validation loss: 2.5641290792193865

Epoch: 5| Step: 4
Training loss: 2.8821458329968546
Validation loss: 2.5301952547157445

Epoch: 5| Step: 5
Training loss: 2.141434453801465
Validation loss: 2.56314320249092

Epoch: 5| Step: 6
Training loss: 2.5974794714871883
Validation loss: 2.535693994432943

Epoch: 5| Step: 7
Training loss: 2.768081694604654
Validation loss: 2.5258143469968752

Epoch: 5| Step: 8
Training loss: 3.4512511817960503
Validation loss: 2.5361326750248905

Epoch: 5| Step: 9
Training loss: 2.5154746822204532
Validation loss: 2.5344145962715627

Epoch: 5| Step: 10
Training loss: 2.7398403806206115
Validation loss: 2.5400878199103274

Epoch: 242| Step: 0
Training loss: 2.6362398291907585
Validation loss: 2.5445029489275015

Epoch: 5| Step: 1
Training loss: 2.0421266880919227
Validation loss: 2.5405048604462603

Epoch: 5| Step: 2
Training loss: 2.0139548309170494
Validation loss: 2.5418183859560397

Epoch: 5| Step: 3
Training loss: 2.929088480427294
Validation loss: 2.532413109604318

Epoch: 5| Step: 4
Training loss: 3.2292820735530814
Validation loss: 2.5316141642132117

Epoch: 5| Step: 5
Training loss: 2.2293559436716213
Validation loss: 2.5465357459069793

Epoch: 5| Step: 6
Training loss: 2.6814935675833205
Validation loss: 2.5282109656518768

Epoch: 5| Step: 7
Training loss: 2.668758604942582
Validation loss: 2.5578705161965356

Epoch: 5| Step: 8
Training loss: 2.5877389769836694
Validation loss: 2.5605518184609233

Epoch: 5| Step: 9
Training loss: 2.220953156445723
Validation loss: 2.505617311768858

Epoch: 5| Step: 10
Training loss: 3.3856085307210306
Validation loss: 2.524519482374659

Epoch: 243| Step: 0
Training loss: 3.0763972511684945
Validation loss: 2.535884197813413

Epoch: 5| Step: 1
Training loss: 2.4762079123435066
Validation loss: 2.538232300284919

Epoch: 5| Step: 2
Training loss: 2.72842570916515
Validation loss: 2.5776218195482414

Epoch: 5| Step: 3
Training loss: 2.4386107041598235
Validation loss: 2.542908916837787

Epoch: 5| Step: 4
Training loss: 1.8888886099547137
Validation loss: 2.542010725979605

Epoch: 5| Step: 5
Training loss: 2.4826579368115493
Validation loss: 2.5587811831365554

Epoch: 5| Step: 6
Training loss: 3.4818689203628654
Validation loss: 2.520968334847922

Epoch: 5| Step: 7
Training loss: 2.7758979306873366
Validation loss: 2.559807285792881

Epoch: 5| Step: 8
Training loss: 2.6297513558516354
Validation loss: 2.5455809657144775

Epoch: 5| Step: 9
Training loss: 2.5812035877405615
Validation loss: 2.567109484908885

Epoch: 5| Step: 10
Training loss: 1.921258098557925
Validation loss: 2.541833925182113

Epoch: 244| Step: 0
Training loss: 2.525581511963488
Validation loss: 2.5574570682886826

Epoch: 5| Step: 1
Training loss: 2.840611497030699
Validation loss: 2.5495340103682196

Epoch: 5| Step: 2
Training loss: 2.3823848152937193
Validation loss: 2.5387472351074996

Epoch: 5| Step: 3
Training loss: 2.604429755590778
Validation loss: 2.555068119000627

Epoch: 5| Step: 4
Training loss: 1.7926501155120895
Validation loss: 2.5650730495752776

Epoch: 5| Step: 5
Training loss: 2.454130513346445
Validation loss: 2.5629123297980057

Epoch: 5| Step: 6
Training loss: 2.762871012219639
Validation loss: 2.5388340950614205

Epoch: 5| Step: 7
Training loss: 3.172228112320146
Validation loss: 2.5474295164422625

Epoch: 5| Step: 8
Training loss: 2.999753782976844
Validation loss: 2.572102072032646

Epoch: 5| Step: 9
Training loss: 2.6550718499643096
Validation loss: 2.535507280233369

Epoch: 5| Step: 10
Training loss: 2.4416158113185142
Validation loss: 2.549845959914667

Epoch: 245| Step: 0
Training loss: 2.6778509224556784
Validation loss: 2.5531749524501373

Epoch: 5| Step: 1
Training loss: 2.5407111346856754
Validation loss: 2.521422303551618

Epoch: 5| Step: 2
Training loss: 2.3603659058444
Validation loss: 2.5613589438746622

Epoch: 5| Step: 3
Training loss: 2.2244106669512673
Validation loss: 2.5158406438254155

Epoch: 5| Step: 4
Training loss: 3.1783715976704827
Validation loss: 2.5200466164699553

Epoch: 5| Step: 5
Training loss: 2.553136138704952
Validation loss: 2.546315316702747

Epoch: 5| Step: 6
Training loss: 2.788992231750065
Validation loss: 2.5320569631714083

Epoch: 5| Step: 7
Training loss: 2.9814366760028856
Validation loss: 2.506275314003954

Epoch: 5| Step: 8
Training loss: 2.551667928298781
Validation loss: 2.522686586158317

Epoch: 5| Step: 9
Training loss: 2.7027314180704485
Validation loss: 2.528481339984116

Epoch: 5| Step: 10
Training loss: 2.0876577763123234
Validation loss: 2.5383271344355705

Epoch: 246| Step: 0
Training loss: 2.947634320616065
Validation loss: 2.55316588039878

Epoch: 5| Step: 1
Training loss: 2.7163025812922177
Validation loss: 2.5441268225361364

Epoch: 5| Step: 2
Training loss: 3.1378808630068806
Validation loss: 2.5376484754983126

Epoch: 5| Step: 3
Training loss: 2.389417056412781
Validation loss: 2.52102101263886

Epoch: 5| Step: 4
Training loss: 2.3820445339674485
Validation loss: 2.53910406414685

Epoch: 5| Step: 5
Training loss: 2.701053244412333
Validation loss: 2.539794095563931

Epoch: 5| Step: 6
Training loss: 2.7660958271873204
Validation loss: 2.5168459841292425

Epoch: 5| Step: 7
Training loss: 2.4515087853619923
Validation loss: 2.487165698131494

Epoch: 5| Step: 8
Training loss: 3.065515551620804
Validation loss: 2.52878979881538

Epoch: 5| Step: 9
Training loss: 2.0897640034799334
Validation loss: 2.523103795104908

Epoch: 5| Step: 10
Training loss: 1.9594715611758715
Validation loss: 2.512765155486314

Epoch: 247| Step: 0
Training loss: 2.705649195135739
Validation loss: 2.5004894413269048

Epoch: 5| Step: 1
Training loss: 2.6558042264392085
Validation loss: 2.554804196890599

Epoch: 5| Step: 2
Training loss: 2.7686387360478486
Validation loss: 2.5319839987218837

Epoch: 5| Step: 3
Training loss: 2.6257391297748174
Validation loss: 2.5575689557224477

Epoch: 5| Step: 4
Training loss: 2.674526393712364
Validation loss: 2.5434384272124624

Epoch: 5| Step: 5
Training loss: 2.0629275485697973
Validation loss: 2.555218481385457

Epoch: 5| Step: 6
Training loss: 3.189555683344205
Validation loss: 2.5220278187366953

Epoch: 5| Step: 7
Training loss: 2.388411750260356
Validation loss: 2.5769084209099162

Epoch: 5| Step: 8
Training loss: 2.1149812020262297
Validation loss: 2.529688142752605

Epoch: 5| Step: 9
Training loss: 3.359894752216456
Validation loss: 2.577523486933488

Epoch: 5| Step: 10
Training loss: 2.0211766400350535
Validation loss: 2.5463754755559513

Epoch: 248| Step: 0
Training loss: 2.778485156165317
Validation loss: 2.5467754399664546

Epoch: 5| Step: 1
Training loss: 2.1564463650397077
Validation loss: 2.524849841366936

Epoch: 5| Step: 2
Training loss: 2.687579042913521
Validation loss: 2.559050967324671

Epoch: 5| Step: 3
Training loss: 2.3811995253131997
Validation loss: 2.5397941107047686

Epoch: 5| Step: 4
Training loss: 2.7736818017951994
Validation loss: 2.536309518462175

Epoch: 5| Step: 5
Training loss: 2.646238060781496
Validation loss: 2.5277864953053437

Epoch: 5| Step: 6
Training loss: 2.7718709470424674
Validation loss: 2.54571956131036

Epoch: 5| Step: 7
Training loss: 2.586984658637047
Validation loss: 2.5607907186699017

Epoch: 5| Step: 8
Training loss: 2.548248388780346
Validation loss: 2.5360752330265526

Epoch: 5| Step: 9
Training loss: 2.136703463260845
Validation loss: 2.5421711605758643

Epoch: 5| Step: 10
Training loss: 3.2719653331160585
Validation loss: 2.5471750980091246

Epoch: 249| Step: 0
Training loss: 2.385248558639732
Validation loss: 2.5732864294198707

Epoch: 5| Step: 1
Training loss: 2.539407841598927
Validation loss: 2.567849235227223

Epoch: 5| Step: 2
Training loss: 2.292502880697822
Validation loss: 2.556874155016287

Epoch: 5| Step: 3
Training loss: 2.6079336971326814
Validation loss: 2.5476524051845635

Epoch: 5| Step: 4
Training loss: 2.949916165987186
Validation loss: 2.531243495813802

Epoch: 5| Step: 5
Training loss: 2.5987852927009176
Validation loss: 2.5429080962013106

Epoch: 5| Step: 6
Training loss: 3.184473283652937
Validation loss: 2.527058387864998

Epoch: 5| Step: 7
Training loss: 2.8578228515971453
Validation loss: 2.55162140661122

Epoch: 5| Step: 8
Training loss: 2.5150691774838516
Validation loss: 2.5221099831057074

Epoch: 5| Step: 9
Training loss: 2.2102979402239207
Validation loss: 2.580609068727106

Epoch: 5| Step: 10
Training loss: 2.7101599377947667
Validation loss: 2.5676645817134998

Epoch: 250| Step: 0
Training loss: 3.302377168275582
Validation loss: 2.559058743234035

Epoch: 5| Step: 1
Training loss: 2.920775670794319
Validation loss: 2.544372980412502

Epoch: 5| Step: 2
Training loss: 2.7282975149939688
Validation loss: 2.542900762885215

Epoch: 5| Step: 3
Training loss: 2.657109379594102
Validation loss: 2.523872827871397

Epoch: 5| Step: 4
Training loss: 2.6061738988802787
Validation loss: 2.5778418421814266

Epoch: 5| Step: 5
Training loss: 2.2336742662806137
Validation loss: 2.527638606724122

Epoch: 5| Step: 6
Training loss: 2.3973891362084205
Validation loss: 2.568510789828347

Epoch: 5| Step: 7
Training loss: 2.4091349560095403
Validation loss: 2.569888759762585

Epoch: 5| Step: 8
Training loss: 2.3546627050966236
Validation loss: 2.5449202173962515

Epoch: 5| Step: 9
Training loss: 2.521435962451583
Validation loss: 2.558059270587104

Epoch: 5| Step: 10
Training loss: 2.7699737840919876
Validation loss: 2.5271325206417257

Epoch: 251| Step: 0
Training loss: 2.596834210420903
Validation loss: 2.5710701033972554

Epoch: 5| Step: 1
Training loss: 2.7223076179846495
Validation loss: 2.54103830102342

Epoch: 5| Step: 2
Training loss: 2.8427353610362225
Validation loss: 2.571963586371728

Epoch: 5| Step: 3
Training loss: 2.526487509063397
Validation loss: 2.5579208620181384

Epoch: 5| Step: 4
Training loss: 2.8618901765066482
Validation loss: 2.542807920105245

Epoch: 5| Step: 5
Training loss: 2.1007567495419
Validation loss: 2.544623252173641

Epoch: 5| Step: 6
Training loss: 2.452613242642847
Validation loss: 2.519425688561912

Epoch: 5| Step: 7
Training loss: 2.6756014352788626
Validation loss: 2.5494811730825924

Epoch: 5| Step: 8
Training loss: 3.048934318848449
Validation loss: 2.529303693332589

Epoch: 5| Step: 9
Training loss: 2.4251711165628285
Validation loss: 2.5320687751662203

Epoch: 5| Step: 10
Training loss: 2.4369834939540906
Validation loss: 2.5405078867556394

Epoch: 252| Step: 0
Training loss: 2.6309729242211177
Validation loss: 2.548972941648761

Epoch: 5| Step: 1
Training loss: 2.068161447941083
Validation loss: 2.5481385569912156

Epoch: 5| Step: 2
Training loss: 2.443353813036985
Validation loss: 2.5622836646184926

Epoch: 5| Step: 3
Training loss: 2.6697839953882503
Validation loss: 2.5630979268061056

Epoch: 5| Step: 4
Training loss: 2.050508026814278
Validation loss: 2.549834417781703

Epoch: 5| Step: 5
Training loss: 2.621942828895788
Validation loss: 2.5464158944434008

Epoch: 5| Step: 6
Training loss: 2.4543506451887787
Validation loss: 2.519998521171197

Epoch: 5| Step: 7
Training loss: 2.9803951549318115
Validation loss: 2.530080859761319

Epoch: 5| Step: 8
Training loss: 3.348750858000631
Validation loss: 2.519549739051511

Epoch: 5| Step: 9
Training loss: 2.250931229207282
Validation loss: 2.5340998447161796

Epoch: 5| Step: 10
Training loss: 3.024954797075987
Validation loss: 2.5366380802229966

Epoch: 253| Step: 0
Training loss: 3.1762115449765593
Validation loss: 2.5303853000118215

Epoch: 5| Step: 1
Training loss: 2.982756650230969
Validation loss: 2.5302237644972183

Epoch: 5| Step: 2
Training loss: 2.4635317737039295
Validation loss: 2.5528937219428145

Epoch: 5| Step: 3
Training loss: 2.809505479135515
Validation loss: 2.5445012693891256

Epoch: 5| Step: 4
Training loss: 2.4696383266291178
Validation loss: 2.558360157999308

Epoch: 5| Step: 5
Training loss: 2.031173587242117
Validation loss: 2.521286489350041

Epoch: 5| Step: 6
Training loss: 2.731940357244197
Validation loss: 2.5319799598453914

Epoch: 5| Step: 7
Training loss: 2.5904765787161073
Validation loss: 2.5500457632489306

Epoch: 5| Step: 8
Training loss: 2.531594806310082
Validation loss: 2.549530809754605

Epoch: 5| Step: 9
Training loss: 1.7492993859688795
Validation loss: 2.50379676868098

Epoch: 5| Step: 10
Training loss: 3.2728260716543267
Validation loss: 2.562198699237145

Epoch: 254| Step: 0
Training loss: 2.7156434123267763
Validation loss: 2.541047221656651

Epoch: 5| Step: 1
Training loss: 2.791883222996114
Validation loss: 2.5382720590269487

Epoch: 5| Step: 2
Training loss: 2.712267634551492
Validation loss: 2.528030503299524

Epoch: 5| Step: 3
Training loss: 2.4748199782743234
Validation loss: 2.547905576595585

Epoch: 5| Step: 4
Training loss: 2.8502565502676687
Validation loss: 2.53975312109913

Epoch: 5| Step: 5
Training loss: 2.047205541581006
Validation loss: 2.5414409513691725

Epoch: 5| Step: 6
Training loss: 2.871798847836757
Validation loss: 2.551364685158802

Epoch: 5| Step: 7
Training loss: 1.9691672110129674
Validation loss: 2.5623449083040972

Epoch: 5| Step: 8
Training loss: 2.497788595607556
Validation loss: 2.5230105916575862

Epoch: 5| Step: 9
Training loss: 2.973222435506798
Validation loss: 2.543962483358648

Epoch: 5| Step: 10
Training loss: 2.698995887399871
Validation loss: 2.54997575554531

Epoch: 255| Step: 0
Training loss: 2.7882494342385757
Validation loss: 2.556152782531626

Epoch: 5| Step: 1
Training loss: 2.6222197932251854
Validation loss: 2.5390224476976946

Epoch: 5| Step: 2
Training loss: 2.783305919154344
Validation loss: 2.5593515277972045

Epoch: 5| Step: 3
Training loss: 2.782467179289057
Validation loss: 2.582584271181487

Epoch: 5| Step: 4
Training loss: 3.1114829121297753
Validation loss: 2.5163214108171954

Epoch: 5| Step: 5
Training loss: 2.696404012173026
Validation loss: 2.5511238315211022

Epoch: 5| Step: 6
Training loss: 2.1995103551261423
Validation loss: 2.551399812123029

Epoch: 5| Step: 7
Training loss: 2.57878927285064
Validation loss: 2.547768044766563

Epoch: 5| Step: 8
Training loss: 2.3412403148444687
Validation loss: 2.5234384813900177

Epoch: 5| Step: 9
Training loss: 1.8526624800332887
Validation loss: 2.541445071039891

Epoch: 5| Step: 10
Training loss: 2.71778931580544
Validation loss: 2.5262643817182666

Epoch: 256| Step: 0
Training loss: 3.1821588383417514
Validation loss: 2.5290313754931417

Epoch: 5| Step: 1
Training loss: 2.4998345320301736
Validation loss: 2.512183308701392

Epoch: 5| Step: 2
Training loss: 2.0849453856270106
Validation loss: 2.548489781752914

Epoch: 5| Step: 3
Training loss: 2.929273733802279
Validation loss: 2.528945447014869

Epoch: 5| Step: 4
Training loss: 2.4992688063402095
Validation loss: 2.5512166691134666

Epoch: 5| Step: 5
Training loss: 2.137386015591188
Validation loss: 2.569426993595614

Epoch: 5| Step: 6
Training loss: 2.6531341229069634
Validation loss: 2.539138376318582

Epoch: 5| Step: 7
Training loss: 3.192980523924264
Validation loss: 2.5221389989952248

Epoch: 5| Step: 8
Training loss: 2.5150024401916435
Validation loss: 2.538929591332786

Epoch: 5| Step: 9
Training loss: 2.4672020030546653
Validation loss: 2.5433237973340597

Epoch: 5| Step: 10
Training loss: 2.575583945421331
Validation loss: 2.528901485684572

Epoch: 257| Step: 0
Training loss: 2.207013965640283
Validation loss: 2.5724571624454375

Epoch: 5| Step: 1
Training loss: 2.533713566537437
Validation loss: 2.539148461690726

Epoch: 5| Step: 2
Training loss: 2.5079180258536873
Validation loss: 2.5485567144445156

Epoch: 5| Step: 3
Training loss: 2.289353179702685
Validation loss: 2.5258732443454335

Epoch: 5| Step: 4
Training loss: 2.977218595670504
Validation loss: 2.5270945151338258

Epoch: 5| Step: 5
Training loss: 2.8104826579866145
Validation loss: 2.5388127049956206

Epoch: 5| Step: 6
Training loss: 2.5350858093726467
Validation loss: 2.5376158575853265

Epoch: 5| Step: 7
Training loss: 2.687658704463055
Validation loss: 2.5357194270516814

Epoch: 5| Step: 8
Training loss: 2.518682955093314
Validation loss: 2.5623819587625807

Epoch: 5| Step: 9
Training loss: 2.1534000304121395
Validation loss: 2.566691378551857

Epoch: 5| Step: 10
Training loss: 3.570193499495557
Validation loss: 2.5067351625660534

Epoch: 258| Step: 0
Training loss: 2.4703409404432475
Validation loss: 2.555554833314724

Epoch: 5| Step: 1
Training loss: 2.8539500653203094
Validation loss: 2.546611837468931

Epoch: 5| Step: 2
Training loss: 2.525062061717958
Validation loss: 2.540397121887335

Epoch: 5| Step: 3
Training loss: 1.9299247070805639
Validation loss: 2.5279620870538975

Epoch: 5| Step: 4
Training loss: 2.2551337061656294
Validation loss: 2.554698372949108

Epoch: 5| Step: 5
Training loss: 2.835329100868097
Validation loss: 2.543126169013208

Epoch: 5| Step: 6
Training loss: 3.0132246989807867
Validation loss: 2.5354434519885514

Epoch: 5| Step: 7
Training loss: 2.8535117815789484
Validation loss: 2.5202058950106987

Epoch: 5| Step: 8
Training loss: 2.7786264797252915
Validation loss: 2.5512222179985793

Epoch: 5| Step: 9
Training loss: 2.685335396502907
Validation loss: 2.554894231644265

Epoch: 5| Step: 10
Training loss: 2.5779277379256684
Validation loss: 2.5408116588143557

Epoch: 259| Step: 0
Training loss: 2.4859059732812914
Validation loss: 2.558963946054147

Epoch: 5| Step: 1
Training loss: 2.7898511439438827
Validation loss: 2.5482200866967744

Epoch: 5| Step: 2
Training loss: 2.978585264298603
Validation loss: 2.538416252845708

Epoch: 5| Step: 3
Training loss: 2.5927068611979696
Validation loss: 2.543595742071012

Epoch: 5| Step: 4
Training loss: 2.564165829953948
Validation loss: 2.5247257974404764

Epoch: 5| Step: 5
Training loss: 2.1327376020645987
Validation loss: 2.520422760096737

Epoch: 5| Step: 6
Training loss: 3.049051769003517
Validation loss: 2.5267641239341576

Epoch: 5| Step: 7
Training loss: 2.744560931724194
Validation loss: 2.5067509939280237

Epoch: 5| Step: 8
Training loss: 2.2804741781287103
Validation loss: 2.537355283123004

Epoch: 5| Step: 9
Training loss: 2.4934964464589515
Validation loss: 2.545273317011155

Epoch: 5| Step: 10
Training loss: 2.4625215790863275
Validation loss: 2.564229726067742

Epoch: 260| Step: 0
Training loss: 1.8330968429738854
Validation loss: 2.528856321276962

Epoch: 5| Step: 1
Training loss: 2.260582620414906
Validation loss: 2.522685353465811

Epoch: 5| Step: 2
Training loss: 3.0815667598932057
Validation loss: 2.5322557560628227

Epoch: 5| Step: 3
Training loss: 2.278022782658094
Validation loss: 2.5227646845877922

Epoch: 5| Step: 4
Training loss: 2.7594566739222244
Validation loss: 2.56332058977303

Epoch: 5| Step: 5
Training loss: 2.5464014654564604
Validation loss: 2.561359586946929

Epoch: 5| Step: 6
Training loss: 3.0009538405725387
Validation loss: 2.5616947072231007

Epoch: 5| Step: 7
Training loss: 2.9932338389093642
Validation loss: 2.5754210620764066

Epoch: 5| Step: 8
Training loss: 2.189262334182702
Validation loss: 2.531575454334927

Epoch: 5| Step: 9
Training loss: 2.605123013687237
Validation loss: 2.5480534459202686

Epoch: 5| Step: 10
Training loss: 2.897556716061055
Validation loss: 2.5353464583318193

Epoch: 261| Step: 0
Training loss: 2.167761000568263
Validation loss: 2.5414240660966145

Epoch: 5| Step: 1
Training loss: 3.0479020955138783
Validation loss: 2.5309462932903117

Epoch: 5| Step: 2
Training loss: 2.6521429286432956
Validation loss: 2.5587270489521456

Epoch: 5| Step: 3
Training loss: 2.667607965831729
Validation loss: 2.525630772803471

Epoch: 5| Step: 4
Training loss: 2.399288362060223
Validation loss: 2.550797075834551

Epoch: 5| Step: 5
Training loss: 2.9945702689336002
Validation loss: 2.518231579743293

Epoch: 5| Step: 6
Training loss: 2.5789468091232726
Validation loss: 2.5313448871069073

Epoch: 5| Step: 7
Training loss: 2.6197124087489496
Validation loss: 2.5556832621664074

Epoch: 5| Step: 8
Training loss: 2.399614573365483
Validation loss: 2.5348694179887157

Epoch: 5| Step: 9
Training loss: 2.477464481564927
Validation loss: 2.495696054663482

Epoch: 5| Step: 10
Training loss: 2.3929943236535958
Validation loss: 2.5407904448179575

Epoch: 262| Step: 0
Training loss: 2.2899521280473922
Validation loss: 2.54015202699301

Epoch: 5| Step: 1
Training loss: 2.3406428785876345
Validation loss: 2.539985060776688

Epoch: 5| Step: 2
Training loss: 2.1473931010843628
Validation loss: 2.5225429932462835

Epoch: 5| Step: 3
Training loss: 2.5391268208499587
Validation loss: 2.529683648223763

Epoch: 5| Step: 4
Training loss: 2.8160122451624363
Validation loss: 2.546768875774785

Epoch: 5| Step: 5
Training loss: 2.5562244889681516
Validation loss: 2.542935204285054

Epoch: 5| Step: 6
Training loss: 2.6434758614609954
Validation loss: 2.5316615426541094

Epoch: 5| Step: 7
Training loss: 2.3139237840740168
Validation loss: 2.539299970680423

Epoch: 5| Step: 8
Training loss: 2.8360661248917136
Validation loss: 2.533673278916895

Epoch: 5| Step: 9
Training loss: 3.3288195248031904
Validation loss: 2.5413105326995837

Epoch: 5| Step: 10
Training loss: 2.5650950062131535
Validation loss: 2.552570729595405

Epoch: 263| Step: 0
Training loss: 3.2234448017254005
Validation loss: 2.5889423141434316

Epoch: 5| Step: 1
Training loss: 2.847897031465684
Validation loss: 2.5578363430535025

Epoch: 5| Step: 2
Training loss: 2.751953558180635
Validation loss: 2.548257621195678

Epoch: 5| Step: 3
Training loss: 2.476173731376986
Validation loss: 2.5769235077853807

Epoch: 5| Step: 4
Training loss: 2.8391780781458262
Validation loss: 2.5394915949083603

Epoch: 5| Step: 5
Training loss: 2.105491737141155
Validation loss: 2.525587785084896

Epoch: 5| Step: 6
Training loss: 2.6530864950919812
Validation loss: 2.540114175914128

Epoch: 5| Step: 7
Training loss: 2.190783515887105
Validation loss: 2.547840884714908

Epoch: 5| Step: 8
Training loss: 2.2384514602466528
Validation loss: 2.5259661635412

Epoch: 5| Step: 9
Training loss: 2.489364316449524
Validation loss: 2.5115431086873685

Epoch: 5| Step: 10
Training loss: 2.96732770077335
Validation loss: 2.5323598644762324

Epoch: 264| Step: 0
Training loss: 2.271978690235513
Validation loss: 2.5427811716013946

Epoch: 5| Step: 1
Training loss: 2.365805445935912
Validation loss: 2.52521219254394

Epoch: 5| Step: 2
Training loss: 3.0244828026374537
Validation loss: 2.553766837406544

Epoch: 5| Step: 3
Training loss: 2.4628123090182705
Validation loss: 2.5736013013657497

Epoch: 5| Step: 4
Training loss: 2.545941515266546
Validation loss: 2.5947534720616066

Epoch: 5| Step: 5
Training loss: 2.5252474975150565
Validation loss: 2.5696407043243625

Epoch: 5| Step: 6
Training loss: 2.918186409427269
Validation loss: 2.5404518565606224

Epoch: 5| Step: 7
Training loss: 3.258034092527469
Validation loss: 2.542312043039667

Epoch: 5| Step: 8
Training loss: 2.475181700076739
Validation loss: 2.5233295061608

Epoch: 5| Step: 9
Training loss: 2.3708408478504377
Validation loss: 2.587676040814071

Epoch: 5| Step: 10
Training loss: 2.4467763206100686
Validation loss: 2.546599444117028

Epoch: 265| Step: 0
Training loss: 2.3391357777341666
Validation loss: 2.5160988292841546

Epoch: 5| Step: 1
Training loss: 3.309150297697133
Validation loss: 2.5468970521210874

Epoch: 5| Step: 2
Training loss: 2.609484824422085
Validation loss: 2.532822353915771

Epoch: 5| Step: 3
Training loss: 2.7067481659456423
Validation loss: 2.545359141467732

Epoch: 5| Step: 4
Training loss: 2.998555153371787
Validation loss: 2.542170748121691

Epoch: 5| Step: 5
Training loss: 2.7121576646925663
Validation loss: 2.551032431637973

Epoch: 5| Step: 6
Training loss: 2.286223020733324
Validation loss: 2.553148178007628

Epoch: 5| Step: 7
Training loss: 2.839826791075136
Validation loss: 2.5270515279675023

Epoch: 5| Step: 8
Training loss: 2.0240521178716215
Validation loss: 2.530377657867159

Epoch: 5| Step: 9
Training loss: 2.169249889796264
Validation loss: 2.5389738172468292

Epoch: 5| Step: 10
Training loss: 2.536743889517552
Validation loss: 2.527060027258034

Epoch: 266| Step: 0
Training loss: 2.2615359533885897
Validation loss: 2.576436340633894

Epoch: 5| Step: 1
Training loss: 2.9897318591573803
Validation loss: 2.5563635329264005

Epoch: 5| Step: 2
Training loss: 2.555047619370284
Validation loss: 2.534172568681796

Epoch: 5| Step: 3
Training loss: 2.3036854780147857
Validation loss: 2.537426615511179

Epoch: 5| Step: 4
Training loss: 2.5317626245665488
Validation loss: 2.5481071448527106

Epoch: 5| Step: 5
Training loss: 2.5953865862887553
Validation loss: 2.5262562151417556

Epoch: 5| Step: 6
Training loss: 1.8787165365582825
Validation loss: 2.571694221722455

Epoch: 5| Step: 7
Training loss: 1.8311071607064613
Validation loss: 2.5445627587124124

Epoch: 5| Step: 8
Training loss: 3.1615859146812135
Validation loss: 2.538773759527052

Epoch: 5| Step: 9
Training loss: 3.437433415548311
Validation loss: 2.531280199379938

Epoch: 5| Step: 10
Training loss: 2.7149522059889826
Validation loss: 2.549448246008805

Epoch: 267| Step: 0
Training loss: 2.6541713884232787
Validation loss: 2.535053782949852

Epoch: 5| Step: 1
Training loss: 2.805228093574999
Validation loss: 2.528821005862632

Epoch: 5| Step: 2
Training loss: 2.885796881091255
Validation loss: 2.5317333863321863

Epoch: 5| Step: 3
Training loss: 2.835322373779891
Validation loss: 2.5310170400540533

Epoch: 5| Step: 4
Training loss: 2.5231769061094242
Validation loss: 2.533279753648934

Epoch: 5| Step: 5
Training loss: 2.384460379695508
Validation loss: 2.540699067729008

Epoch: 5| Step: 6
Training loss: 2.2877499720002636
Validation loss: 2.5356108517333595

Epoch: 5| Step: 7
Training loss: 2.180835927228754
Validation loss: 2.496280648597437

Epoch: 5| Step: 8
Training loss: 2.4516367680403284
Validation loss: 2.568737985157561

Epoch: 5| Step: 9
Training loss: 2.7494402229011348
Validation loss: 2.535278426581938

Epoch: 5| Step: 10
Training loss: 2.623086958839534
Validation loss: 2.533794696841268

Epoch: 268| Step: 0
Training loss: 3.0849580007009605
Validation loss: 2.5381981172679047

Epoch: 5| Step: 1
Training loss: 2.449216608414634
Validation loss: 2.5430014121628917

Epoch: 5| Step: 2
Training loss: 2.236076720653156
Validation loss: 2.554606788857766

Epoch: 5| Step: 3
Training loss: 2.4633425631455608
Validation loss: 2.5267167043924785

Epoch: 5| Step: 4
Training loss: 2.8024823969374086
Validation loss: 2.55150533379425

Epoch: 5| Step: 5
Training loss: 2.232672943388138
Validation loss: 2.500868129742444

Epoch: 5| Step: 6
Training loss: 2.4291154488539823
Validation loss: 2.5346210940731133

Epoch: 5| Step: 7
Training loss: 2.3115834662278347
Validation loss: 2.5329982766994266

Epoch: 5| Step: 8
Training loss: 2.8971887247846047
Validation loss: 2.5241917466794725

Epoch: 5| Step: 9
Training loss: 2.94845874416863
Validation loss: 2.560962376749665

Epoch: 5| Step: 10
Training loss: 2.561325548434536
Validation loss: 2.5458551495514556

Epoch: 269| Step: 0
Training loss: 2.6478899274346843
Validation loss: 2.5313453003122746

Epoch: 5| Step: 1
Training loss: 1.7304250741790042
Validation loss: 2.5429832952441394

Epoch: 5| Step: 2
Training loss: 2.530679709158043
Validation loss: 2.516736853319712

Epoch: 5| Step: 3
Training loss: 2.8606997896918798
Validation loss: 2.5093527307611425

Epoch: 5| Step: 4
Training loss: 2.1841214929261183
Validation loss: 2.53885916451828

Epoch: 5| Step: 5
Training loss: 3.583662387613883
Validation loss: 2.5363126852212154

Epoch: 5| Step: 6
Training loss: 2.454960907510253
Validation loss: 2.530717695266965

Epoch: 5| Step: 7
Training loss: 2.509653621801646
Validation loss: 2.5286641202254216

Epoch: 5| Step: 8
Training loss: 2.429049589063165
Validation loss: 2.5251406958259466

Epoch: 5| Step: 9
Training loss: 2.6785035478982504
Validation loss: 2.5207318501057085

Epoch: 5| Step: 10
Training loss: 2.2428789833678504
Validation loss: 2.5513710084298817

Epoch: 270| Step: 0
Training loss: 2.439021491537465
Validation loss: 2.553443329010083

Epoch: 5| Step: 1
Training loss: 2.293728704119785
Validation loss: 2.5853142786181453

Epoch: 5| Step: 2
Training loss: 2.3062211445809795
Validation loss: 2.520879197082696

Epoch: 5| Step: 3
Training loss: 2.9619528607230583
Validation loss: 2.5129706329546293

Epoch: 5| Step: 4
Training loss: 2.468971049395907
Validation loss: 2.5393096616739195

Epoch: 5| Step: 5
Training loss: 3.2213467983612847
Validation loss: 2.569240486773346

Epoch: 5| Step: 6
Training loss: 2.482515514897694
Validation loss: 2.5656476851004206

Epoch: 5| Step: 7
Training loss: 2.8701293155898058
Validation loss: 2.5760436316540654

Epoch: 5| Step: 8
Training loss: 2.422737411030171
Validation loss: 2.5374080566741424

Epoch: 5| Step: 9
Training loss: 2.008926498169813
Validation loss: 2.549297305956799

Epoch: 5| Step: 10
Training loss: 2.8480984484448024
Validation loss: 2.5484487127101154

Epoch: 271| Step: 0
Training loss: 3.1616599674854347
Validation loss: 2.5131513677826676

Epoch: 5| Step: 1
Training loss: 2.770794019683116
Validation loss: 2.538940266206132

Epoch: 5| Step: 2
Training loss: 2.768286507348468
Validation loss: 2.554594264694087

Epoch: 5| Step: 3
Training loss: 2.5458438400659436
Validation loss: 2.554106332484239

Epoch: 5| Step: 4
Training loss: 1.6904692488194584
Validation loss: 2.5246587548900177

Epoch: 5| Step: 5
Training loss: 2.134862117558492
Validation loss: 2.502230229849278

Epoch: 5| Step: 6
Training loss: 2.6201019002302814
Validation loss: 2.5430219584938794

Epoch: 5| Step: 7
Training loss: 3.06523928456541
Validation loss: 2.5045111788387975

Epoch: 5| Step: 8
Training loss: 2.6445086209161532
Validation loss: 2.529129017809183

Epoch: 5| Step: 9
Training loss: 2.6796094699542516
Validation loss: 2.531090684153895

Epoch: 5| Step: 10
Training loss: 2.1926006251420462
Validation loss: 2.5576423745549706

Epoch: 272| Step: 0
Training loss: 2.6409539012243917
Validation loss: 2.5509230493530475

Epoch: 5| Step: 1
Training loss: 2.5113119742235654
Validation loss: 2.5401239556437845

Epoch: 5| Step: 2
Training loss: 2.2225087524173066
Validation loss: 2.5267206786300553

Epoch: 5| Step: 3
Training loss: 2.2829112444754807
Validation loss: 2.5674752848492304

Epoch: 5| Step: 4
Training loss: 2.867874936216758
Validation loss: 2.5382661303527345

Epoch: 5| Step: 5
Training loss: 2.900595794510977
Validation loss: 2.4940691328592215

Epoch: 5| Step: 6
Training loss: 3.165883084440375
Validation loss: 2.5207546648648895

Epoch: 5| Step: 7
Training loss: 2.9254190910911393
Validation loss: 2.541109082087465

Epoch: 5| Step: 8
Training loss: 2.3899903296430622
Validation loss: 2.5404435423429352

Epoch: 5| Step: 9
Training loss: 2.5711954101939325
Validation loss: 2.555511126589785

Epoch: 5| Step: 10
Training loss: 1.8736335225513028
Validation loss: 2.510595725196691

Epoch: 273| Step: 0
Training loss: 2.308737296919891
Validation loss: 2.5371602186799094

Epoch: 5| Step: 1
Training loss: 2.3329245231901736
Validation loss: 2.5295692873939197

Epoch: 5| Step: 2
Training loss: 2.144659653451868
Validation loss: 2.5089495104176174

Epoch: 5| Step: 3
Training loss: 3.0755130122788117
Validation loss: 2.5842381525901184

Epoch: 5| Step: 4
Training loss: 2.5125135051307397
Validation loss: 2.5405392702492855

Epoch: 5| Step: 5
Training loss: 3.076570999652984
Validation loss: 2.5428634890687816

Epoch: 5| Step: 6
Training loss: 2.5312905014000324
Validation loss: 2.5608361237431727

Epoch: 5| Step: 7
Training loss: 2.6245942483390277
Validation loss: 2.5198628642271825

Epoch: 5| Step: 8
Training loss: 3.121163263609103
Validation loss: 2.5612340802027074

Epoch: 5| Step: 9
Training loss: 2.445716995080509
Validation loss: 2.515598399651515

Epoch: 5| Step: 10
Training loss: 2.023675970805221
Validation loss: 2.511284664638818

Epoch: 274| Step: 0
Training loss: 2.6692332989294454
Validation loss: 2.5652320717908026

Epoch: 5| Step: 1
Training loss: 2.3201906319926864
Validation loss: 2.5496792956948733

Epoch: 5| Step: 2
Training loss: 2.395562054299524
Validation loss: 2.5400819307988045

Epoch: 5| Step: 3
Training loss: 2.183762108824359
Validation loss: 2.6010474105557924

Epoch: 5| Step: 4
Training loss: 2.876467454656874
Validation loss: 2.5344192700493466

Epoch: 5| Step: 5
Training loss: 2.0674495839403217
Validation loss: 2.5570021536608905

Epoch: 5| Step: 6
Training loss: 2.5892282620525124
Validation loss: 2.5547703399679067

Epoch: 5| Step: 7
Training loss: 2.829015939224664
Validation loss: 2.550144681901747

Epoch: 5| Step: 8
Training loss: 2.9306043487231235
Validation loss: 2.540022498958019

Epoch: 5| Step: 9
Training loss: 2.6486696574766087
Validation loss: 2.5160766789177758

Epoch: 5| Step: 10
Training loss: 2.68355616913847
Validation loss: 2.5549264724378387

Epoch: 275| Step: 0
Training loss: 2.2891095778275354
Validation loss: 2.5438924840983224

Epoch: 5| Step: 1
Training loss: 3.1246642886082827
Validation loss: 2.5258734615451974

Epoch: 5| Step: 2
Training loss: 2.5507156340263615
Validation loss: 2.519271904648052

Epoch: 5| Step: 3
Training loss: 1.998793058999167
Validation loss: 2.5222034058398957

Epoch: 5| Step: 4
Training loss: 3.098260077447877
Validation loss: 2.5247851791385063

Epoch: 5| Step: 5
Training loss: 2.5337913847800677
Validation loss: 2.5466306634500286

Epoch: 5| Step: 6
Training loss: 2.621755320348913
Validation loss: 2.502563352449327

Epoch: 5| Step: 7
Training loss: 2.8905732021330386
Validation loss: 2.506896568228035

Epoch: 5| Step: 8
Training loss: 2.3837646583142447
Validation loss: 2.505305966122832

Epoch: 5| Step: 9
Training loss: 2.6206176143426623
Validation loss: 2.523047929131341

Epoch: 5| Step: 10
Training loss: 1.99257832601756
Validation loss: 2.5309439843430575

Epoch: 276| Step: 0
Training loss: 3.018459272897535
Validation loss: 2.5695098941415506

Epoch: 5| Step: 1
Training loss: 2.3042331053644336
Validation loss: 2.4933245411666793

Epoch: 5| Step: 2
Training loss: 2.3772687616220702
Validation loss: 2.5350363206705757

Epoch: 5| Step: 3
Training loss: 2.248318997906039
Validation loss: 2.516739412133914

Epoch: 5| Step: 4
Training loss: 2.8086654802481807
Validation loss: 2.556706594280073

Epoch: 5| Step: 5
Training loss: 2.816772352489333
Validation loss: 2.5452355451144446

Epoch: 5| Step: 6
Training loss: 3.1588169650250824
Validation loss: 2.4882460428273507

Epoch: 5| Step: 7
Training loss: 2.292396799008942
Validation loss: 2.5430807224431344

Epoch: 5| Step: 8
Training loss: 2.864798816321245
Validation loss: 2.5552825420391843

Epoch: 5| Step: 9
Training loss: 2.2210255089419504
Validation loss: 2.559982329555638

Epoch: 5| Step: 10
Training loss: 2.0496934894207306
Validation loss: 2.5681245764272855

Epoch: 277| Step: 0
Training loss: 2.1300041517476913
Validation loss: 2.5195123863674653

Epoch: 5| Step: 1
Training loss: 2.623972101138831
Validation loss: 2.5432490125744596

Epoch: 5| Step: 2
Training loss: 2.673443161174191
Validation loss: 2.5386836660526817

Epoch: 5| Step: 3
Training loss: 2.887373131280951
Validation loss: 2.5354850886067304

Epoch: 5| Step: 4
Training loss: 2.647243444387259
Validation loss: 2.5142791914690465

Epoch: 5| Step: 5
Training loss: 2.0160583503392595
Validation loss: 2.5483779051324045

Epoch: 5| Step: 6
Training loss: 2.6945950202773
Validation loss: 2.5143707599324623

Epoch: 5| Step: 7
Training loss: 2.2868585489728597
Validation loss: 2.5740492985915613

Epoch: 5| Step: 8
Training loss: 3.1610213369960563
Validation loss: 2.5418377769428724

Epoch: 5| Step: 9
Training loss: 2.4324042044396395
Validation loss: 2.537327585990965

Epoch: 5| Step: 10
Training loss: 2.7011525449247342
Validation loss: 2.533767795008623

Epoch: 278| Step: 0
Training loss: 2.66971898232381
Validation loss: 2.5268025067619577

Epoch: 5| Step: 1
Training loss: 2.4354093339960308
Validation loss: 2.5632954655133973

Epoch: 5| Step: 2
Training loss: 2.03059552726362
Validation loss: 2.5580144310737656

Epoch: 5| Step: 3
Training loss: 2.610804183542352
Validation loss: 2.52932792375602

Epoch: 5| Step: 4
Training loss: 2.8322656153025267
Validation loss: 2.5484529659107027

Epoch: 5| Step: 5
Training loss: 2.8610531411167366
Validation loss: 2.5562380922839814

Epoch: 5| Step: 6
Training loss: 2.9151566729310407
Validation loss: 2.5171236376597816

Epoch: 5| Step: 7
Training loss: 2.2672405928133617
Validation loss: 2.5219094140669145

Epoch: 5| Step: 8
Training loss: 2.3413432670627286
Validation loss: 2.5004252338747786

Epoch: 5| Step: 9
Training loss: 2.5911764222964138
Validation loss: 2.5237059233757653

Epoch: 5| Step: 10
Training loss: 2.8034624489871196
Validation loss: 2.524812495001998

Epoch: 279| Step: 0
Training loss: 2.5996054313280097
Validation loss: 2.527989071457635

Epoch: 5| Step: 1
Training loss: 2.419979017813021
Validation loss: 2.493456054983004

Epoch: 5| Step: 2
Training loss: 2.4849333705450904
Validation loss: 2.529583596018761

Epoch: 5| Step: 3
Training loss: 1.9571203032617104
Validation loss: 2.5160258707559673

Epoch: 5| Step: 4
Training loss: 2.2598987695083363
Validation loss: 2.551280953845429

Epoch: 5| Step: 5
Training loss: 2.985418806232787
Validation loss: 2.528584251305746

Epoch: 5| Step: 6
Training loss: 3.1760635156694215
Validation loss: 2.563054190674333

Epoch: 5| Step: 7
Training loss: 2.566059431682651
Validation loss: 2.520993725860562

Epoch: 5| Step: 8
Training loss: 1.6838311472754002
Validation loss: 2.5159571881874245

Epoch: 5| Step: 9
Training loss: 3.0390078973645562
Validation loss: 2.529940226925833

Epoch: 5| Step: 10
Training loss: 3.125256794868945
Validation loss: 2.574995819380708

Epoch: 280| Step: 0
Training loss: 3.002459630385109
Validation loss: 2.5369502078289767

Epoch: 5| Step: 1
Training loss: 2.64477628082652
Validation loss: 2.5499393085139492

Epoch: 5| Step: 2
Training loss: 2.256558291013052
Validation loss: 2.532740166600353

Epoch: 5| Step: 3
Training loss: 3.2606983164726175
Validation loss: 2.501474348756621

Epoch: 5| Step: 4
Training loss: 2.601056573835519
Validation loss: 2.537066511040137

Epoch: 5| Step: 5
Training loss: 2.3007241518872688
Validation loss: 2.5548027388646135

Epoch: 5| Step: 6
Training loss: 2.47848051390492
Validation loss: 2.535180992795623

Epoch: 5| Step: 7
Training loss: 2.282038931097459
Validation loss: 2.552894264215994

Epoch: 5| Step: 8
Training loss: 2.0971103860146156
Validation loss: 2.5578507055310964

Epoch: 5| Step: 9
Training loss: 2.472201674681961
Validation loss: 2.581573171163564

Epoch: 5| Step: 10
Training loss: 2.6569781034785556
Validation loss: 2.559129775202571

Epoch: 281| Step: 0
Training loss: 2.830153607085182
Validation loss: 2.564447744699522

Epoch: 5| Step: 1
Training loss: 2.19616074651564
Validation loss: 2.59504257514969

Epoch: 5| Step: 2
Training loss: 2.7506511957593647
Validation loss: 2.545708483849679

Epoch: 5| Step: 3
Training loss: 2.7479372090768917
Validation loss: 2.58205570247036

Epoch: 5| Step: 4
Training loss: 2.582612542121758
Validation loss: 2.534969306066309

Epoch: 5| Step: 5
Training loss: 2.801982712386698
Validation loss: 2.523082290986953

Epoch: 5| Step: 6
Training loss: 2.2763843642101844
Validation loss: 2.5248693535339264

Epoch: 5| Step: 7
Training loss: 3.241475737243634
Validation loss: 2.5591300136220716

Epoch: 5| Step: 8
Training loss: 2.4358853592103493
Validation loss: 2.556476948857981

Epoch: 5| Step: 9
Training loss: 1.8623027031362331
Validation loss: 2.4986594256479355

Epoch: 5| Step: 10
Training loss: 2.2206039205249066
Validation loss: 2.50744385147377

Epoch: 282| Step: 0
Training loss: 2.3846441514478474
Validation loss: 2.5252021708004904

Epoch: 5| Step: 1
Training loss: 2.4627310862284926
Validation loss: 2.5422566223599756

Epoch: 5| Step: 2
Training loss: 2.485305995560918
Validation loss: 2.569397952978308

Epoch: 5| Step: 3
Training loss: 3.0123550000255945
Validation loss: 2.544209459214703

Epoch: 5| Step: 4
Training loss: 2.537977814435375
Validation loss: 2.543232297566018

Epoch: 5| Step: 5
Training loss: 2.3476744284536943
Validation loss: 2.5416526447745196

Epoch: 5| Step: 6
Training loss: 2.793576986600856
Validation loss: 2.527917568090657

Epoch: 5| Step: 7
Training loss: 2.362605024960221
Validation loss: 2.505688469302126

Epoch: 5| Step: 8
Training loss: 2.6219869305585366
Validation loss: 2.5371178385760516

Epoch: 5| Step: 9
Training loss: 2.4378151323108423
Validation loss: 2.5372044097585578

Epoch: 5| Step: 10
Training loss: 3.0544906513759806
Validation loss: 2.5011971673388773

Epoch: 283| Step: 0
Training loss: 2.344086686428992
Validation loss: 2.523521791477257

Epoch: 5| Step: 1
Training loss: 2.2983083599228498
Validation loss: 2.5580128105167543

Epoch: 5| Step: 2
Training loss: 3.2006004247036652
Validation loss: 2.51227091360793

Epoch: 5| Step: 3
Training loss: 2.5374063108088962
Validation loss: 2.5338238576661336

Epoch: 5| Step: 4
Training loss: 2.8734104904058717
Validation loss: 2.551440627683493

Epoch: 5| Step: 5
Training loss: 2.3295145688261516
Validation loss: 2.540564448510883

Epoch: 5| Step: 6
Training loss: 2.920276551410628
Validation loss: 2.5102434413005046

Epoch: 5| Step: 7
Training loss: 2.3020706061332175
Validation loss: 2.5704492564442902

Epoch: 5| Step: 8
Training loss: 2.6815670972997405
Validation loss: 2.5236142557995254

Epoch: 5| Step: 9
Training loss: 2.206472248413748
Validation loss: 2.554995063671173

Epoch: 5| Step: 10
Training loss: 2.393091761671301
Validation loss: 2.5284994766571036

Epoch: 284| Step: 0
Training loss: 2.541477029531879
Validation loss: 2.5408077419318964

Epoch: 5| Step: 1
Training loss: 2.246434459552937
Validation loss: 2.5242725117064757

Epoch: 5| Step: 2
Training loss: 3.2974422021157466
Validation loss: 2.529746251680433

Epoch: 5| Step: 3
Training loss: 2.5384318815735267
Validation loss: 2.545380545008475

Epoch: 5| Step: 4
Training loss: 2.457748720732344
Validation loss: 2.511148387904075

Epoch: 5| Step: 5
Training loss: 1.9740134829531275
Validation loss: 2.555156373594634

Epoch: 5| Step: 6
Training loss: 2.3951355512323005
Validation loss: 2.5655174757333628

Epoch: 5| Step: 7
Training loss: 2.600707775761438
Validation loss: 2.524196756261214

Epoch: 5| Step: 8
Training loss: 2.5918508723828286
Validation loss: 2.505668820558787

Epoch: 5| Step: 9
Training loss: 2.4403202662794405
Validation loss: 2.5428667182376996

Epoch: 5| Step: 10
Training loss: 2.861572255210333
Validation loss: 2.5094975953345546

Epoch: 285| Step: 0
Training loss: 1.790987736309073
Validation loss: 2.552671243648775

Epoch: 5| Step: 1
Training loss: 2.4580132443076654
Validation loss: 2.5627534982552476

Epoch: 5| Step: 2
Training loss: 2.7247682805363813
Validation loss: 2.533418114505907

Epoch: 5| Step: 3
Training loss: 2.4289376920307317
Validation loss: 2.5418961668635847

Epoch: 5| Step: 4
Training loss: 2.7858029078964446
Validation loss: 2.5442895117247777

Epoch: 5| Step: 5
Training loss: 2.6532340486759214
Validation loss: 2.520154083668239

Epoch: 5| Step: 6
Training loss: 2.5279341277883915
Validation loss: 2.5540275693504237

Epoch: 5| Step: 7
Training loss: 3.0012107631115645
Validation loss: 2.545622384153762

Epoch: 5| Step: 8
Training loss: 3.1064525269583783
Validation loss: 2.527850234952355

Epoch: 5| Step: 9
Training loss: 2.5909666270996508
Validation loss: 2.555199515006344

Epoch: 5| Step: 10
Training loss: 2.1314232182517703
Validation loss: 2.5085979339959903

Epoch: 286| Step: 0
Training loss: 3.459510526268111
Validation loss: 2.50920639475913

Epoch: 5| Step: 1
Training loss: 2.894593190548463
Validation loss: 2.5237550105536757

Epoch: 5| Step: 2
Training loss: 2.0202094881565125
Validation loss: 2.5148610620222906

Epoch: 5| Step: 3
Training loss: 2.65391671417572
Validation loss: 2.514583013384165

Epoch: 5| Step: 4
Training loss: 3.0489455792458213
Validation loss: 2.517159577533197

Epoch: 5| Step: 5
Training loss: 2.236758048364876
Validation loss: 2.5485576569900816

Epoch: 5| Step: 6
Training loss: 1.5977291472949489
Validation loss: 2.529901756928787

Epoch: 5| Step: 7
Training loss: 2.523619843027389
Validation loss: 2.5410252458896077

Epoch: 5| Step: 8
Training loss: 2.497429670808034
Validation loss: 2.552166919122147

Epoch: 5| Step: 9
Training loss: 2.648020933806084
Validation loss: 2.5513503072702046

Epoch: 5| Step: 10
Training loss: 2.458816631676801
Validation loss: 2.569899175356463

Epoch: 287| Step: 0
Training loss: 2.326541336403963
Validation loss: 2.5492726136869446

Epoch: 5| Step: 1
Training loss: 2.009108069741615
Validation loss: 2.540749055574064

Epoch: 5| Step: 2
Training loss: 2.6186018580958703
Validation loss: 2.5323812574171964

Epoch: 5| Step: 3
Training loss: 1.9447075696053937
Validation loss: 2.587180376992047

Epoch: 5| Step: 4
Training loss: 2.426956457224495
Validation loss: 2.542304352545916

Epoch: 5| Step: 5
Training loss: 2.6845362089730878
Validation loss: 2.5432300985594747

Epoch: 5| Step: 6
Training loss: 2.6968241557503476
Validation loss: 2.545646334373232

Epoch: 5| Step: 7
Training loss: 3.2083588801436145
Validation loss: 2.5100080633889843

Epoch: 5| Step: 8
Training loss: 2.2671118757174384
Validation loss: 2.549069081905941

Epoch: 5| Step: 9
Training loss: 2.959412838976925
Validation loss: 2.5662678315867633

Epoch: 5| Step: 10
Training loss: 2.8591715422406865
Validation loss: 2.5340577058038325

Epoch: 288| Step: 0
Training loss: 2.6052183748702755
Validation loss: 2.506132508539103

Epoch: 5| Step: 1
Training loss: 2.435079889259824
Validation loss: 2.5651664207045433

Epoch: 5| Step: 2
Training loss: 2.1608168297296895
Validation loss: 2.517812596165471

Epoch: 5| Step: 3
Training loss: 2.813116811296723
Validation loss: 2.5391480941796205

Epoch: 5| Step: 4
Training loss: 2.2953596241413203
Validation loss: 2.520559867793063

Epoch: 5| Step: 5
Training loss: 2.626880970924738
Validation loss: 2.514562171470247

Epoch: 5| Step: 6
Training loss: 2.6074878927152736
Validation loss: 2.4905696862393967

Epoch: 5| Step: 7
Training loss: 2.914379112900121
Validation loss: 2.5505357467850374

Epoch: 5| Step: 8
Training loss: 3.148176840316902
Validation loss: 2.5356600319780327

Epoch: 5| Step: 9
Training loss: 2.1062463233983584
Validation loss: 2.521705975398134

Epoch: 5| Step: 10
Training loss: 2.279636491776145
Validation loss: 2.5429868266975024

Epoch: 289| Step: 0
Training loss: 2.6623381910272217
Validation loss: 2.540646256587463

Epoch: 5| Step: 1
Training loss: 2.8763311870179535
Validation loss: 2.5118484066819287

Epoch: 5| Step: 2
Training loss: 2.426988482497856
Validation loss: 2.5236827645176616

Epoch: 5| Step: 3
Training loss: 2.268599248244013
Validation loss: 2.5391455266486256

Epoch: 5| Step: 4
Training loss: 2.903378780839961
Validation loss: 2.519457214086797

Epoch: 5| Step: 5
Training loss: 2.861241299610567
Validation loss: 2.5053102649371146

Epoch: 5| Step: 6
Training loss: 2.5038199804146726
Validation loss: 2.5541066371171652

Epoch: 5| Step: 7
Training loss: 2.5879702228324764
Validation loss: 2.507191768240446

Epoch: 5| Step: 8
Training loss: 2.1574679266003196
Validation loss: 2.5156064770072084

Epoch: 5| Step: 9
Training loss: 1.8491885905995407
Validation loss: 2.536428813497655

Epoch: 5| Step: 10
Training loss: 2.5263584108793724
Validation loss: 2.5041318046378063

Epoch: 290| Step: 0
Training loss: 2.833240245711082
Validation loss: 2.5352679688642152

Epoch: 5| Step: 1
Training loss: 2.8000415798914653
Validation loss: 2.524117831722471

Epoch: 5| Step: 2
Training loss: 2.4974644200384337
Validation loss: 2.51595010034449

Epoch: 5| Step: 3
Training loss: 2.6877176950688533
Validation loss: 2.5494933905327217

Epoch: 5| Step: 4
Training loss: 2.472001939834525
Validation loss: 2.5036488320822

Epoch: 5| Step: 5
Training loss: 2.127650347192519
Validation loss: 2.5067335078352393

Epoch: 5| Step: 6
Training loss: 2.2408266623177706
Validation loss: 2.5657176104029404

Epoch: 5| Step: 7
Training loss: 3.0126978449138466
Validation loss: 2.522630929440479

Epoch: 5| Step: 8
Training loss: 2.6754464712731956
Validation loss: 2.538302728332454

Epoch: 5| Step: 9
Training loss: 2.0524301639250253
Validation loss: 2.5367613860245672

Epoch: 5| Step: 10
Training loss: 2.8034845604251135
Validation loss: 2.535664193394021

Epoch: 291| Step: 0
Training loss: 2.454196477254522
Validation loss: 2.5077296811242156

Epoch: 5| Step: 1
Training loss: 2.875599176746505
Validation loss: 2.502462187762025

Epoch: 5| Step: 2
Training loss: 2.727946282789206
Validation loss: 2.470205517354719

Epoch: 5| Step: 3
Training loss: 2.407491685609335
Validation loss: 2.5267068474040357

Epoch: 5| Step: 4
Training loss: 2.2135075704903113
Validation loss: 2.5413412238452415

Epoch: 5| Step: 5
Training loss: 2.4956390492048355
Validation loss: 2.543274059680943

Epoch: 5| Step: 6
Training loss: 2.956305834382053
Validation loss: 2.539405717520209

Epoch: 5| Step: 7
Training loss: 2.6460348838473133
Validation loss: 2.550395116047756

Epoch: 5| Step: 8
Training loss: 2.491031294820216
Validation loss: 2.5470961064517765

Epoch: 5| Step: 9
Training loss: 2.5487261638490266
Validation loss: 2.501714675733798

Epoch: 5| Step: 10
Training loss: 2.5147260872416624
Validation loss: 2.5148338562205903

Epoch: 292| Step: 0
Training loss: 2.5214301944883366
Validation loss: 2.566519511313572

Epoch: 5| Step: 1
Training loss: 2.3077923050024594
Validation loss: 2.548616404956

Epoch: 5| Step: 2
Training loss: 3.060276392004321
Validation loss: 2.5161264019613974

Epoch: 5| Step: 3
Training loss: 2.310007659602161
Validation loss: 2.5105841067706924

Epoch: 5| Step: 4
Training loss: 2.3932816448137872
Validation loss: 2.503668584226411

Epoch: 5| Step: 5
Training loss: 3.0085785918149854
Validation loss: 2.5255322197099876

Epoch: 5| Step: 6
Training loss: 2.4536339298726917
Validation loss: 2.512274810694005

Epoch: 5| Step: 7
Training loss: 2.2875565402021394
Validation loss: 2.5113199255117777

Epoch: 5| Step: 8
Training loss: 2.630938397801694
Validation loss: 2.5557258660520836

Epoch: 5| Step: 9
Training loss: 2.5973663856719287
Validation loss: 2.5394270389902465

Epoch: 5| Step: 10
Training loss: 2.332097293806749
Validation loss: 2.5324883530350384

Epoch: 293| Step: 0
Training loss: 2.7768657289050163
Validation loss: 2.525327089247051

Epoch: 5| Step: 1
Training loss: 2.1476734259214503
Validation loss: 2.5134867596730417

Epoch: 5| Step: 2
Training loss: 2.987490321187577
Validation loss: 2.5562413311341543

Epoch: 5| Step: 3
Training loss: 1.8293413207743534
Validation loss: 2.541837236345223

Epoch: 5| Step: 4
Training loss: 2.0600419858709254
Validation loss: 2.5475042137003188

Epoch: 5| Step: 5
Training loss: 3.3842880167398612
Validation loss: 2.5406162129371936

Epoch: 5| Step: 6
Training loss: 2.467929172470229
Validation loss: 2.5357354126042257

Epoch: 5| Step: 7
Training loss: 1.6720310031444017
Validation loss: 2.528992075642219

Epoch: 5| Step: 8
Training loss: 3.0589264241773244
Validation loss: 2.5000291268897694

Epoch: 5| Step: 9
Training loss: 2.7158389236597107
Validation loss: 2.5558467373706333

Epoch: 5| Step: 10
Training loss: 2.551820785615521
Validation loss: 2.4890388273978137

Epoch: 294| Step: 0
Training loss: 2.9156687709716005
Validation loss: 2.5519975183627697

Epoch: 5| Step: 1
Training loss: 3.035565637106636
Validation loss: 2.5494383703176684

Epoch: 5| Step: 2
Training loss: 2.757450587918487
Validation loss: 2.539342826217104

Epoch: 5| Step: 3
Training loss: 2.554121788920877
Validation loss: 2.5398482386215093

Epoch: 5| Step: 4
Training loss: 2.727968394535478
Validation loss: 2.539802986248115

Epoch: 5| Step: 5
Training loss: 2.1475127848376734
Validation loss: 2.5709427443221746

Epoch: 5| Step: 6
Training loss: 2.5205515133876206
Validation loss: 2.5101548234785587

Epoch: 5| Step: 7
Training loss: 2.516802020780379
Validation loss: 2.5682846195080176

Epoch: 5| Step: 8
Training loss: 1.8769373739258453
Validation loss: 2.534276035909998

Epoch: 5| Step: 9
Training loss: 2.675118067622477
Validation loss: 2.5319382291361467

Epoch: 5| Step: 10
Training loss: 1.9588041213104597
Validation loss: 2.541491253463483

Epoch: 295| Step: 0
Training loss: 3.46587658339604
Validation loss: 2.5293433065995194

Epoch: 5| Step: 1
Training loss: 2.672279728803594
Validation loss: 2.5427207467328743

Epoch: 5| Step: 2
Training loss: 2.7468440413222246
Validation loss: 2.5601347365095593

Epoch: 5| Step: 3
Training loss: 2.423871995158485
Validation loss: 2.5426154528485925

Epoch: 5| Step: 4
Training loss: 2.648244214952161
Validation loss: 2.5764830232056806

Epoch: 5| Step: 5
Training loss: 1.8977334557662522
Validation loss: 2.553775817979267

Epoch: 5| Step: 6
Training loss: 2.2603628149224693
Validation loss: 2.5459971487509443

Epoch: 5| Step: 7
Training loss: 2.2729455999064907
Validation loss: 2.506967304951059

Epoch: 5| Step: 8
Training loss: 2.456817860274887
Validation loss: 2.56511765426472

Epoch: 5| Step: 9
Training loss: 2.3644034251421076
Validation loss: 2.531813755857085

Epoch: 5| Step: 10
Training loss: 2.4582137278108878
Validation loss: 2.5568191362091035

Epoch: 296| Step: 0
Training loss: 2.3384565466758023
Validation loss: 2.5207912730043183

Epoch: 5| Step: 1
Training loss: 2.340483461793828
Validation loss: 2.543709858800381

Epoch: 5| Step: 2
Training loss: 2.0160579955599447
Validation loss: 2.523927415059781

Epoch: 5| Step: 3
Training loss: 2.899059629892234
Validation loss: 2.5190692615099115

Epoch: 5| Step: 4
Training loss: 2.7085431433374048
Validation loss: 2.508809902303056

Epoch: 5| Step: 5
Training loss: 2.836750344888685
Validation loss: 2.544532449984407

Epoch: 5| Step: 6
Training loss: 2.2801586310097726
Validation loss: 2.512845945491973

Epoch: 5| Step: 7
Training loss: 3.0408338861176594
Validation loss: 2.5173980623804604

Epoch: 5| Step: 8
Training loss: 2.451653203021782
Validation loss: 2.519649199700891

Epoch: 5| Step: 9
Training loss: 2.105730312994048
Validation loss: 2.545319624364037

Epoch: 5| Step: 10
Training loss: 2.660325637331465
Validation loss: 2.54208322968147

Epoch: 297| Step: 0
Training loss: 2.7617589793856534
Validation loss: 2.5383277030500317

Epoch: 5| Step: 1
Training loss: 2.4602280335842623
Validation loss: 2.567855068644159

Epoch: 5| Step: 2
Training loss: 2.1483419501124668
Validation loss: 2.4902954624250877

Epoch: 5| Step: 3
Training loss: 2.45200628539333
Validation loss: 2.518152127191065

Epoch: 5| Step: 4
Training loss: 2.5173891882956636
Validation loss: 2.522871258641868

Epoch: 5| Step: 5
Training loss: 2.0074765410424336
Validation loss: 2.5383483599291656

Epoch: 5| Step: 6
Training loss: 2.2098197133331468
Validation loss: 2.515485699184678

Epoch: 5| Step: 7
Training loss: 2.884754715513393
Validation loss: 2.5311097410439847

Epoch: 5| Step: 8
Training loss: 3.0766568628101916
Validation loss: 2.5381000905402495

Epoch: 5| Step: 9
Training loss: 2.3129649339286353
Validation loss: 2.596557089555951

Epoch: 5| Step: 10
Training loss: 2.759189856118889
Validation loss: 2.5322476224760417

Epoch: 298| Step: 0
Training loss: 2.6279232460263398
Validation loss: 2.5330801327917327

Epoch: 5| Step: 1
Training loss: 2.707814905481431
Validation loss: 2.550206691593778

Epoch: 5| Step: 2
Training loss: 2.374008574099913
Validation loss: 2.5325417452791337

Epoch: 5| Step: 3
Training loss: 2.6492343480273357
Validation loss: 2.5516791908724814

Epoch: 5| Step: 4
Training loss: 2.632915189194983
Validation loss: 2.5297670394350376

Epoch: 5| Step: 5
Training loss: 3.0031791372510437
Validation loss: 2.5455437784777777

Epoch: 5| Step: 6
Training loss: 2.344458511073302
Validation loss: 2.5368757162038107

Epoch: 5| Step: 7
Training loss: 2.1934354638126767
Validation loss: 2.5446375612803194

Epoch: 5| Step: 8
Training loss: 2.7303438826620963
Validation loss: 2.550755291157357

Epoch: 5| Step: 9
Training loss: 2.174047686926793
Validation loss: 2.5033571462425908

Epoch: 5| Step: 10
Training loss: 2.5904241173399645
Validation loss: 2.5441068846965904

Epoch: 299| Step: 0
Training loss: 2.0681096863720074
Validation loss: 2.5615950456379237

Epoch: 5| Step: 1
Training loss: 2.617755611876701
Validation loss: 2.5211953174697057

Epoch: 5| Step: 2
Training loss: 2.940480931449026
Validation loss: 2.5328106309638994

Epoch: 5| Step: 3
Training loss: 2.3998287775633274
Validation loss: 2.5391322053313092

Epoch: 5| Step: 4
Training loss: 2.8862170453212
Validation loss: 2.553093056815262

Epoch: 5| Step: 5
Training loss: 2.2197442849119287
Validation loss: 2.538535602381281

Epoch: 5| Step: 6
Training loss: 2.8880965438197075
Validation loss: 2.522297970586596

Epoch: 5| Step: 7
Training loss: 2.433134130484781
Validation loss: 2.508673916248585

Epoch: 5| Step: 8
Training loss: 2.256581112560751
Validation loss: 2.563079667375658

Epoch: 5| Step: 9
Training loss: 2.310393121139029
Validation loss: 2.5259948083362405

Epoch: 5| Step: 10
Training loss: 3.014448974258513
Validation loss: 2.5148725985063396

Epoch: 300| Step: 0
Training loss: 2.664971876013904
Validation loss: 2.5753219635380886

Epoch: 5| Step: 1
Training loss: 2.66956064031117
Validation loss: 2.5150932708503477

Epoch: 5| Step: 2
Training loss: 2.769534435189679
Validation loss: 2.5170956629081345

Epoch: 5| Step: 3
Training loss: 2.1555652360381967
Validation loss: 2.490658463091571

Epoch: 5| Step: 4
Training loss: 2.4606688337658427
Validation loss: 2.5243920962984063

Epoch: 5| Step: 5
Training loss: 2.0400728375390424
Validation loss: 2.552289871453752

Epoch: 5| Step: 6
Training loss: 2.5111666201567457
Validation loss: 2.5703237666538215

Epoch: 5| Step: 7
Training loss: 2.564370751782998
Validation loss: 2.5046521401866286

Epoch: 5| Step: 8
Training loss: 2.5441700431567256
Validation loss: 2.5404013280192155

Epoch: 5| Step: 9
Training loss: 3.137305179945722
Validation loss: 2.540830251311358

Epoch: 5| Step: 10
Training loss: 2.5939352130255258
Validation loss: 2.5334339319272194

Epoch: 301| Step: 0
Training loss: 2.3593338716471672
Validation loss: 2.526525107679238

Epoch: 5| Step: 1
Training loss: 2.2009558855182805
Validation loss: 2.5244343569474474

Epoch: 5| Step: 2
Training loss: 2.579507630406611
Validation loss: 2.5488373930332013

Epoch: 5| Step: 3
Training loss: 2.866561280760448
Validation loss: 2.5498848086612576

Epoch: 5| Step: 4
Training loss: 1.7541185688060472
Validation loss: 2.492678613138741

Epoch: 5| Step: 5
Training loss: 2.96809845852065
Validation loss: 2.5486241996248515

Epoch: 5| Step: 6
Training loss: 2.4503039035322796
Validation loss: 2.523429895230358

Epoch: 5| Step: 7
Training loss: 2.326862274389232
Validation loss: 2.528834994823971

Epoch: 5| Step: 8
Training loss: 3.0272122262256183
Validation loss: 2.5124909634795736

Epoch: 5| Step: 9
Training loss: 3.1737527034307793
Validation loss: 2.5196972345163666

Epoch: 5| Step: 10
Training loss: 2.159217782376798
Validation loss: 2.545619135317635

Epoch: 302| Step: 0
Training loss: 2.6306602668890595
Validation loss: 2.5220861102574474

Epoch: 5| Step: 1
Training loss: 2.6560194925259366
Validation loss: 2.5274640494170284

Epoch: 5| Step: 2
Training loss: 2.4121474290077707
Validation loss: 2.552875734475321

Epoch: 5| Step: 3
Training loss: 2.2447166931896607
Validation loss: 2.5346140483077604

Epoch: 5| Step: 4
Training loss: 2.9845202345734925
Validation loss: 2.5429767283206783

Epoch: 5| Step: 5
Training loss: 2.6666734715215963
Validation loss: 2.561018687960053

Epoch: 5| Step: 6
Training loss: 1.860100997110615
Validation loss: 2.4819650826548663

Epoch: 5| Step: 7
Training loss: 2.049075509001402
Validation loss: 2.562945371471898

Epoch: 5| Step: 8
Training loss: 3.3169491237065745
Validation loss: 2.531336712108419

Epoch: 5| Step: 9
Training loss: 2.542314905351501
Validation loss: 2.5342520945679126

Epoch: 5| Step: 10
Training loss: 2.0868071268519706
Validation loss: 2.501475994668164

Epoch: 303| Step: 0
Training loss: 2.7396560678629394
Validation loss: 2.5410362675948934

Epoch: 5| Step: 1
Training loss: 2.790711073279559
Validation loss: 2.5558196448616988

Epoch: 5| Step: 2
Training loss: 3.079644307492173
Validation loss: 2.5492918604841055

Epoch: 5| Step: 3
Training loss: 2.7292241000667223
Validation loss: 2.553538798980097

Epoch: 5| Step: 4
Training loss: 2.7943019859281515
Validation loss: 2.5255203908471233

Epoch: 5| Step: 5
Training loss: 2.087197027091866
Validation loss: 2.5217871377232073

Epoch: 5| Step: 6
Training loss: 2.0051842494030208
Validation loss: 2.520208760050321

Epoch: 5| Step: 7
Training loss: 2.6653700497559867
Validation loss: 2.5242217938646294

Epoch: 5| Step: 8
Training loss: 2.3014911793355997
Validation loss: 2.5061954987755053

Epoch: 5| Step: 9
Training loss: 2.0885425545428156
Validation loss: 2.5194394590231983

Epoch: 5| Step: 10
Training loss: 2.572225583401327
Validation loss: 2.527066047148835

Epoch: 304| Step: 0
Training loss: 2.146138018362254
Validation loss: 2.5509387310983387

Epoch: 5| Step: 1
Training loss: 2.041707745612396
Validation loss: 2.532456454215549

Epoch: 5| Step: 2
Training loss: 3.417248808106297
Validation loss: 2.533556855354632

Epoch: 5| Step: 3
Training loss: 2.998759649085501
Validation loss: 2.502357319041123

Epoch: 5| Step: 4
Training loss: 2.427398388324098
Validation loss: 2.5308869229474618

Epoch: 5| Step: 5
Training loss: 2.315725396949022
Validation loss: 2.565444820894403

Epoch: 5| Step: 6
Training loss: 1.973379957941334
Validation loss: 2.5326199113001433

Epoch: 5| Step: 7
Training loss: 2.5272430918722995
Validation loss: 2.5117895070796985

Epoch: 5| Step: 8
Training loss: 2.4005700984001206
Validation loss: 2.5351665706510715

Epoch: 5| Step: 9
Training loss: 2.4211579276457385
Validation loss: 2.5450937925140353

Epoch: 5| Step: 10
Training loss: 2.446291206648262
Validation loss: 2.553106765178889

Epoch: 305| Step: 0
Training loss: 2.41402329101325
Validation loss: 2.5016843300395086

Epoch: 5| Step: 1
Training loss: 2.6225126379997685
Validation loss: 2.5101351336087565

Epoch: 5| Step: 2
Training loss: 2.845582308852203
Validation loss: 2.5590805290784346

Epoch: 5| Step: 3
Training loss: 2.2179744600798283
Validation loss: 2.4869898391199996

Epoch: 5| Step: 4
Training loss: 2.100798968052084
Validation loss: 2.5302727687963658

Epoch: 5| Step: 5
Training loss: 2.882867745384434
Validation loss: 2.5120081458532804

Epoch: 5| Step: 6
Training loss: 1.975461268580918
Validation loss: 2.547740001988408

Epoch: 5| Step: 7
Training loss: 2.378167800417914
Validation loss: 2.533543183886392

Epoch: 5| Step: 8
Training loss: 2.964650747176533
Validation loss: 2.5283575512834524

Epoch: 5| Step: 9
Training loss: 2.795075844842868
Validation loss: 2.514186843701973

Epoch: 5| Step: 10
Training loss: 2.6102951163579995
Validation loss: 2.4985292128050953

Epoch: 306| Step: 0
Training loss: 2.625458904298523
Validation loss: 2.5654362239301802

Epoch: 5| Step: 1
Training loss: 1.98493799348164
Validation loss: 2.5551175979750913

Epoch: 5| Step: 2
Training loss: 2.8813457944754406
Validation loss: 2.490873573878486

Epoch: 5| Step: 3
Training loss: 2.2535191671310892
Validation loss: 2.5515613573764786

Epoch: 5| Step: 4
Training loss: 2.630270163435671
Validation loss: 2.4896380332291925

Epoch: 5| Step: 5
Training loss: 2.399470700071774
Validation loss: 2.535444148650965

Epoch: 5| Step: 6
Training loss: 2.8055485755741256
Validation loss: 2.5423707946593583

Epoch: 5| Step: 7
Training loss: 2.2353175382745345
Validation loss: 2.544452463554944

Epoch: 5| Step: 8
Training loss: 2.549410722000177
Validation loss: 2.534935364241915

Epoch: 5| Step: 9
Training loss: 3.110100129652948
Validation loss: 2.513871412485208

Epoch: 5| Step: 10
Training loss: 2.2553275930632495
Validation loss: 2.553175847102266

Epoch: 307| Step: 0
Training loss: 2.284448132472807
Validation loss: 2.52691270183726

Epoch: 5| Step: 1
Training loss: 3.123662891432743
Validation loss: 2.5471392404554467

Epoch: 5| Step: 2
Training loss: 2.4168017996353575
Validation loss: 2.562232290910922

Epoch: 5| Step: 3
Training loss: 2.3847456297789917
Validation loss: 2.541748023046513

Epoch: 5| Step: 4
Training loss: 3.081259279063028
Validation loss: 2.509929072648481

Epoch: 5| Step: 5
Training loss: 2.1888752565212206
Validation loss: 2.5469019254449825

Epoch: 5| Step: 6
Training loss: 2.223621983223246
Validation loss: 2.536561085085147

Epoch: 5| Step: 7
Training loss: 2.7072961630838317
Validation loss: 2.507504665845744

Epoch: 5| Step: 8
Training loss: 2.3976264104045963
Validation loss: 2.4916612895935404

Epoch: 5| Step: 9
Training loss: 2.5325413930057685
Validation loss: 2.5423582203024435

Epoch: 5| Step: 10
Training loss: 2.3659596295947383
Validation loss: 2.489818318029895

Epoch: 308| Step: 0
Training loss: 2.0641236127979137
Validation loss: 2.542728866478985

Epoch: 5| Step: 1
Training loss: 3.1462367390719557
Validation loss: 2.5025247171952008

Epoch: 5| Step: 2
Training loss: 2.6637669732185403
Validation loss: 2.5354125994595433

Epoch: 5| Step: 3
Training loss: 2.8639243367818787
Validation loss: 2.5216375654724708

Epoch: 5| Step: 4
Training loss: 1.9386954157589682
Validation loss: 2.543405866417475

Epoch: 5| Step: 5
Training loss: 2.4032815234895475
Validation loss: 2.5294341847906763

Epoch: 5| Step: 6
Training loss: 2.69711614881008
Validation loss: 2.560616036530113

Epoch: 5| Step: 7
Training loss: 2.604907660284644
Validation loss: 2.5557873581601873

Epoch: 5| Step: 8
Training loss: 1.7445378892347705
Validation loss: 2.524262755874085

Epoch: 5| Step: 9
Training loss: 2.6847903764045293
Validation loss: 2.5303223577573974

Epoch: 5| Step: 10
Training loss: 2.925393989307386
Validation loss: 2.5042593143008856

Epoch: 309| Step: 0
Training loss: 2.538317667945551
Validation loss: 2.529551872385475

Epoch: 5| Step: 1
Training loss: 2.42603835065677
Validation loss: 2.547452841833693

Epoch: 5| Step: 2
Training loss: 3.000507629679785
Validation loss: 2.56669211367695

Epoch: 5| Step: 3
Training loss: 2.5685983060797195
Validation loss: 2.5085322703217208

Epoch: 5| Step: 4
Training loss: 2.2760288636802617
Validation loss: 2.5336694805131152

Epoch: 5| Step: 5
Training loss: 2.6179712744609303
Validation loss: 2.5656281193436006

Epoch: 5| Step: 6
Training loss: 2.360931388397688
Validation loss: 2.543142662441946

Epoch: 5| Step: 7
Training loss: 2.319868565486591
Validation loss: 2.5684137772877453

Epoch: 5| Step: 8
Training loss: 2.0857110632817406
Validation loss: 2.5423916778364384

Epoch: 5| Step: 9
Training loss: 2.739773113992472
Validation loss: 2.5346289064951746

Epoch: 5| Step: 10
Training loss: 2.600731060979622
Validation loss: 2.5237548901808893

Epoch: 310| Step: 0
Training loss: 3.053794008204132
Validation loss: 2.51004330185208

Epoch: 5| Step: 1
Training loss: 2.870601274461662
Validation loss: 2.5779574621012937

Epoch: 5| Step: 2
Training loss: 2.1633598205912
Validation loss: 2.5133974340926386

Epoch: 5| Step: 3
Training loss: 2.123395313913349
Validation loss: 2.480097738470986

Epoch: 5| Step: 4
Training loss: 3.099929802622789
Validation loss: 2.5172830359704523

Epoch: 5| Step: 5
Training loss: 2.228958500444569
Validation loss: 2.5016479844055572

Epoch: 5| Step: 6
Training loss: 2.758703417503565
Validation loss: 2.489058509057529

Epoch: 5| Step: 7
Training loss: 1.8751695556270276
Validation loss: 2.531123713304603

Epoch: 5| Step: 8
Training loss: 2.641767717307995
Validation loss: 2.5115800511548048

Epoch: 5| Step: 9
Training loss: 2.4808511754595544
Validation loss: 2.485794510072897

Epoch: 5| Step: 10
Training loss: 2.0391248203853465
Validation loss: 2.5123324601260486

Epoch: 311| Step: 0
Training loss: 2.179272574579689
Validation loss: 2.5392710943494556

Epoch: 5| Step: 1
Training loss: 2.1380690190921365
Validation loss: 2.522092643141855

Epoch: 5| Step: 2
Training loss: 3.133352180857145
Validation loss: 2.5717967087146327

Epoch: 5| Step: 3
Training loss: 2.140241491114801
Validation loss: 2.549351681606812

Epoch: 5| Step: 4
Training loss: 2.323872413796736
Validation loss: 2.5353552958538197

Epoch: 5| Step: 5
Training loss: 2.7619986169743926
Validation loss: 2.5268583769779314

Epoch: 5| Step: 6
Training loss: 2.858185901305816
Validation loss: 2.569565279243335

Epoch: 5| Step: 7
Training loss: 2.6100953529741844
Validation loss: 2.5161799111361254

Epoch: 5| Step: 8
Training loss: 2.441101934158855
Validation loss: 2.555162146693966

Epoch: 5| Step: 9
Training loss: 2.8514170152313705
Validation loss: 2.544308946349453

Epoch: 5| Step: 10
Training loss: 2.017666278401494
Validation loss: 2.522010964098098

Epoch: 312| Step: 0
Training loss: 1.5468829376325306
Validation loss: 2.569130974645537

Epoch: 5| Step: 1
Training loss: 2.412104828247233
Validation loss: 2.5579374169005096

Epoch: 5| Step: 2
Training loss: 1.8895684434780051
Validation loss: 2.5646154973975794

Epoch: 5| Step: 3
Training loss: 2.380780063024742
Validation loss: 2.537223228750664

Epoch: 5| Step: 4
Training loss: 2.412438596428283
Validation loss: 2.540610009213156

Epoch: 5| Step: 5
Training loss: 2.6886123307016625
Validation loss: 2.5027693484099824

Epoch: 5| Step: 6
Training loss: 2.69174196671387
Validation loss: 2.545761272552565

Epoch: 5| Step: 7
Training loss: 2.860258372447028
Validation loss: 2.585203097162395

Epoch: 5| Step: 8
Training loss: 2.568333382710682
Validation loss: 2.536521970623529

Epoch: 5| Step: 9
Training loss: 3.0550436997604944
Validation loss: 2.543812748642827

Epoch: 5| Step: 10
Training loss: 2.8332925868376875
Validation loss: 2.5544594393879674

Epoch: 313| Step: 0
Training loss: 2.557740326866939
Validation loss: 2.5361506609514666

Epoch: 5| Step: 1
Training loss: 2.1984482494489996
Validation loss: 2.506357008233769

Epoch: 5| Step: 2
Training loss: 2.1699339611358957
Validation loss: 2.514208149614158

Epoch: 5| Step: 3
Training loss: 2.4816924193177368
Validation loss: 2.5648271441793167

Epoch: 5| Step: 4
Training loss: 2.3883735177208245
Validation loss: 2.499613289508481

Epoch: 5| Step: 5
Training loss: 2.641471952689118
Validation loss: 2.56154506727183

Epoch: 5| Step: 6
Training loss: 2.864267301755079
Validation loss: 2.498099654892301

Epoch: 5| Step: 7
Training loss: 2.385644649177844
Validation loss: 2.52303315718974

Epoch: 5| Step: 8
Training loss: 2.550738908261466
Validation loss: 2.5298330507987887

Epoch: 5| Step: 9
Training loss: 2.5566986287227507
Validation loss: 2.5194828121320727

Epoch: 5| Step: 10
Training loss: 2.9835991774732156
Validation loss: 2.5395124679436814

Epoch: 314| Step: 0
Training loss: 2.354224437803721
Validation loss: 2.5434367590664606

Epoch: 5| Step: 1
Training loss: 2.8095360290748066
Validation loss: 2.5285205575370417

Epoch: 5| Step: 2
Training loss: 2.728365763628994
Validation loss: 2.5419643563309617

Epoch: 5| Step: 3
Training loss: 2.298196217976882
Validation loss: 2.4914808448968433

Epoch: 5| Step: 4
Training loss: 2.259724793852432
Validation loss: 2.5023122451628366

Epoch: 5| Step: 5
Training loss: 2.429573080919729
Validation loss: 2.501971212157778

Epoch: 5| Step: 6
Training loss: 2.503042563082242
Validation loss: 2.5409517030700632

Epoch: 5| Step: 7
Training loss: 2.078814743419258
Validation loss: 2.550264721021787

Epoch: 5| Step: 8
Training loss: 3.1009757690467117
Validation loss: 2.579461522365845

Epoch: 5| Step: 9
Training loss: 2.451882697761115
Validation loss: 2.5443366924246136

Epoch: 5| Step: 10
Training loss: 2.3928017274340814
Validation loss: 2.5285835497117355

Epoch: 315| Step: 0
Training loss: 2.0722676959373487
Validation loss: 2.558042293068716

Epoch: 5| Step: 1
Training loss: 2.2697511129854484
Validation loss: 2.5383519119703073

Epoch: 5| Step: 2
Training loss: 2.530679803369323
Validation loss: 2.5615290181027004

Epoch: 5| Step: 3
Training loss: 2.66669904172636
Validation loss: 2.5274348715095467

Epoch: 5| Step: 4
Training loss: 2.3082367028715134
Validation loss: 2.4970254727493946

Epoch: 5| Step: 5
Training loss: 2.185629999047601
Validation loss: 2.5689149322227625

Epoch: 5| Step: 6
Training loss: 2.499023628309391
Validation loss: 2.5025168721614937

Epoch: 5| Step: 7
Training loss: 2.5308390154213205
Validation loss: 2.6015457536603757

Epoch: 5| Step: 8
Training loss: 3.216550353192311
Validation loss: 2.566065686773339

Epoch: 5| Step: 9
Training loss: 2.6392957964825707
Validation loss: 2.5301664061942097

Epoch: 5| Step: 10
Training loss: 2.2845680457918673
Validation loss: 2.5340421006822638

Epoch: 316| Step: 0
Training loss: 2.110679957493577
Validation loss: 2.4866640701924805

Epoch: 5| Step: 1
Training loss: 2.266091555207881
Validation loss: 2.5073997565021333

Epoch: 5| Step: 2
Training loss: 3.027717655840982
Validation loss: 2.5303712598454924

Epoch: 5| Step: 3
Training loss: 2.433998135543272
Validation loss: 2.5268001945354714

Epoch: 5| Step: 4
Training loss: 2.0928211714035325
Validation loss: 2.542774389408044

Epoch: 5| Step: 5
Training loss: 2.9950530272615206
Validation loss: 2.557326828839531

Epoch: 5| Step: 6
Training loss: 2.3437665811587953
Validation loss: 2.5215494746661076

Epoch: 5| Step: 7
Training loss: 2.8536504756701513
Validation loss: 2.5491849237254796

Epoch: 5| Step: 8
Training loss: 2.836691848009573
Validation loss: 2.5262109308817724

Epoch: 5| Step: 9
Training loss: 2.037162860522985
Validation loss: 2.5128468198152265

Epoch: 5| Step: 10
Training loss: 2.628668809798771
Validation loss: 2.5414124211548303

Epoch: 317| Step: 0
Training loss: 2.0348169552821957
Validation loss: 2.519001838407405

Epoch: 5| Step: 1
Training loss: 2.6064902252066666
Validation loss: 2.5179349036352994

Epoch: 5| Step: 2
Training loss: 2.635767515045965
Validation loss: 2.5011912051078524

Epoch: 5| Step: 3
Training loss: 2.85510769295214
Validation loss: 2.4822400625483185

Epoch: 5| Step: 4
Training loss: 2.5103801761576303
Validation loss: 2.5209892534569223

Epoch: 5| Step: 5
Training loss: 2.836327055770784
Validation loss: 2.5210385023393123

Epoch: 5| Step: 6
Training loss: 2.413102733842293
Validation loss: 2.523971474198954

Epoch: 5| Step: 7
Training loss: 2.308773750220192
Validation loss: 2.56088697486777

Epoch: 5| Step: 8
Training loss: 2.6563227924021775
Validation loss: 2.5280701745441734

Epoch: 5| Step: 9
Training loss: 2.455390904182079
Validation loss: 2.555569842610572

Epoch: 5| Step: 10
Training loss: 2.1696973902572925
Validation loss: 2.5112059228242245

Epoch: 318| Step: 0
Training loss: 2.2195220463691836
Validation loss: 2.525088914670072

Epoch: 5| Step: 1
Training loss: 2.1143859119680597
Validation loss: 2.53490919711312

Epoch: 5| Step: 2
Training loss: 2.6692261532401322
Validation loss: 2.530213314257801

Epoch: 5| Step: 3
Training loss: 2.8958993991112587
Validation loss: 2.545304580811424

Epoch: 5| Step: 4
Training loss: 2.38167066888315
Validation loss: 2.5211263252610356

Epoch: 5| Step: 5
Training loss: 3.113532272806266
Validation loss: 2.5606168384761285

Epoch: 5| Step: 6
Training loss: 2.187975586554475
Validation loss: 2.5578067408608054

Epoch: 5| Step: 7
Training loss: 2.0914334819447196
Validation loss: 2.5292491674427615

Epoch: 5| Step: 8
Training loss: 2.6565127972022307
Validation loss: 2.533049391144116

Epoch: 5| Step: 9
Training loss: 1.969200082829838
Validation loss: 2.4907098566574972

Epoch: 5| Step: 10
Training loss: 3.0226207487536207
Validation loss: 2.536408588741745

Epoch: 319| Step: 0
Training loss: 2.467262495953357
Validation loss: 2.5287779061151534

Epoch: 5| Step: 1
Training loss: 2.4486996528002414
Validation loss: 2.5388606650224874

Epoch: 5| Step: 2
Training loss: 2.3792443747670897
Validation loss: 2.5677075439190995

Epoch: 5| Step: 3
Training loss: 2.163732179847117
Validation loss: 2.5380072277023746

Epoch: 5| Step: 4
Training loss: 2.600158129064957
Validation loss: 2.5282000335462014

Epoch: 5| Step: 5
Training loss: 2.1336143020539584
Validation loss: 2.5228361216197563

Epoch: 5| Step: 6
Training loss: 2.5821078890739386
Validation loss: 2.5629824082488053

Epoch: 5| Step: 7
Training loss: 2.3891202890955117
Validation loss: 2.5226524099673266

Epoch: 5| Step: 8
Training loss: 2.245464734442897
Validation loss: 2.4852404076157284

Epoch: 5| Step: 9
Training loss: 3.2831660897766173
Validation loss: 2.5102989473154227

Epoch: 5| Step: 10
Training loss: 2.456457996055104
Validation loss: 2.5777770423192687

Epoch: 320| Step: 0
Training loss: 1.9822913817503887
Validation loss: 2.556534057803767

Epoch: 5| Step: 1
Training loss: 2.515321227504145
Validation loss: 2.5198658848060376

Epoch: 5| Step: 2
Training loss: 2.418544324858685
Validation loss: 2.504961584212248

Epoch: 5| Step: 3
Training loss: 2.8303534227082885
Validation loss: 2.5694399213838848

Epoch: 5| Step: 4
Training loss: 2.228831637390871
Validation loss: 2.468504339342278

Epoch: 5| Step: 5
Training loss: 2.3025210785703445
Validation loss: 2.5063656937947907

Epoch: 5| Step: 6
Training loss: 2.6530891011643467
Validation loss: 2.530137777217164

Epoch: 5| Step: 7
Training loss: 2.85146099589249
Validation loss: 2.5027879069994317

Epoch: 5| Step: 8
Training loss: 2.4973907205465022
Validation loss: 2.5152509509713026

Epoch: 5| Step: 9
Training loss: 2.4261153969235374
Validation loss: 2.5075070981036762

Epoch: 5| Step: 10
Training loss: 2.53669821187814
Validation loss: 2.5562224651127066

Epoch: 321| Step: 0
Training loss: 2.0901444548554737
Validation loss: 2.551598785455661

Epoch: 5| Step: 1
Training loss: 2.7753248213632054
Validation loss: 2.515681152083927

Epoch: 5| Step: 2
Training loss: 2.557102380235843
Validation loss: 2.4943186582804904

Epoch: 5| Step: 3
Training loss: 2.128351037657052
Validation loss: 2.4926992605804004

Epoch: 5| Step: 4
Training loss: 2.2737562867130654
Validation loss: 2.523173905750916

Epoch: 5| Step: 5
Training loss: 2.1474008729591665
Validation loss: 2.5208913263701027

Epoch: 5| Step: 6
Training loss: 2.7116550518303737
Validation loss: 2.562080278895807

Epoch: 5| Step: 7
Training loss: 2.7347072726408785
Validation loss: 2.555732450371505

Epoch: 5| Step: 8
Training loss: 2.7671340015308217
Validation loss: 2.526555436084301

Epoch: 5| Step: 9
Training loss: 2.7725375582435916
Validation loss: 2.5239239107726608

Epoch: 5| Step: 10
Training loss: 2.545382758775559
Validation loss: 2.515604061752168

Epoch: 322| Step: 0
Training loss: 2.5774129173153444
Validation loss: 2.5217120721177584

Epoch: 5| Step: 1
Training loss: 2.5337254229173674
Validation loss: 2.5434721719080544

Epoch: 5| Step: 2
Training loss: 2.469018655959108
Validation loss: 2.5065438636409465

Epoch: 5| Step: 3
Training loss: 2.4247727317102434
Validation loss: 2.5267969336736367

Epoch: 5| Step: 4
Training loss: 1.8694402281191045
Validation loss: 2.523457342087786

Epoch: 5| Step: 5
Training loss: 2.704929609387635
Validation loss: 2.5461621057106165

Epoch: 5| Step: 6
Training loss: 3.0364213072066266
Validation loss: 2.495453083649671

Epoch: 5| Step: 7
Training loss: 2.2681571753399052
Validation loss: 2.517164348021912

Epoch: 5| Step: 8
Training loss: 2.1128178509736286
Validation loss: 2.5483713712242113

Epoch: 5| Step: 9
Training loss: 3.1285144117650443
Validation loss: 2.528057873335646

Epoch: 5| Step: 10
Training loss: 2.278962124625707
Validation loss: 2.543365567018302

Epoch: 323| Step: 0
Training loss: 2.4638288678649154
Validation loss: 2.517535622987851

Epoch: 5| Step: 1
Training loss: 2.8631137106722218
Validation loss: 2.5089334446296854

Epoch: 5| Step: 2
Training loss: 2.5411314061943675
Validation loss: 2.5174458112223848

Epoch: 5| Step: 3
Training loss: 2.3435125612150567
Validation loss: 2.5589074193127535

Epoch: 5| Step: 4
Training loss: 2.7185687300662447
Validation loss: 2.5591212541952504

Epoch: 5| Step: 5
Training loss: 2.5152449231875225
Validation loss: 2.5406271531696394

Epoch: 5| Step: 6
Training loss: 2.5263464255524926
Validation loss: 2.5586367277474658

Epoch: 5| Step: 7
Training loss: 1.9858503489126182
Validation loss: 2.510893160243099

Epoch: 5| Step: 8
Training loss: 2.301763820195278
Validation loss: 2.4968106147477185

Epoch: 5| Step: 9
Training loss: 2.757735902408728
Validation loss: 2.5643730521268355

Epoch: 5| Step: 10
Training loss: 2.19728700076408
Validation loss: 2.501263580117309

Epoch: 324| Step: 0
Training loss: 1.8288750047389746
Validation loss: 2.540382466975167

Epoch: 5| Step: 1
Training loss: 2.9535767547775538
Validation loss: 2.569560673383466

Epoch: 5| Step: 2
Training loss: 3.0266706345934073
Validation loss: 2.5261256381710013

Epoch: 5| Step: 3
Training loss: 1.9171590863572965
Validation loss: 2.5256784614159686

Epoch: 5| Step: 4
Training loss: 2.4237972383583037
Validation loss: 2.5480051362374225

Epoch: 5| Step: 5
Training loss: 1.8150893821460814
Validation loss: 2.529001775724094

Epoch: 5| Step: 6
Training loss: 2.625792338362903
Validation loss: 2.5246252563025995

Epoch: 5| Step: 7
Training loss: 2.7175656951010296
Validation loss: 2.516657766138854

Epoch: 5| Step: 8
Training loss: 2.7360560018429716
Validation loss: 2.529800678692633

Epoch: 5| Step: 9
Training loss: 2.3475649493802804
Validation loss: 2.5147017579200575

Epoch: 5| Step: 10
Training loss: 2.70517401680218
Validation loss: 2.5367757101702977

Epoch: 325| Step: 0
Training loss: 1.9529525070314584
Validation loss: 2.532942926519292

Epoch: 5| Step: 1
Training loss: 2.4162809678020785
Validation loss: 2.4950492055107643

Epoch: 5| Step: 2
Training loss: 2.3534884755954812
Validation loss: 2.563893807249377

Epoch: 5| Step: 3
Training loss: 1.9550166620583522
Validation loss: 2.522261648580845

Epoch: 5| Step: 4
Training loss: 2.4642125211630566
Validation loss: 2.529526319480819

Epoch: 5| Step: 5
Training loss: 2.3605063044022057
Validation loss: 2.553971408143584

Epoch: 5| Step: 6
Training loss: 2.7672242966138065
Validation loss: 2.5395674170179436

Epoch: 5| Step: 7
Training loss: 2.6777880640302802
Validation loss: 2.5646419561996945

Epoch: 5| Step: 8
Training loss: 2.7556023319010254
Validation loss: 2.5050072710285685

Epoch: 5| Step: 9
Training loss: 2.4438364857543156
Validation loss: 2.49224308258092

Epoch: 5| Step: 10
Training loss: 3.07212019259048
Validation loss: 2.542467497150221

Epoch: 326| Step: 0
Training loss: 3.203491785402395
Validation loss: 2.5323102283506587

Epoch: 5| Step: 1
Training loss: 2.174873971028197
Validation loss: 2.5482664521703478

Epoch: 5| Step: 2
Training loss: 2.6834011314151445
Validation loss: 2.4930603317586857

Epoch: 5| Step: 3
Training loss: 1.3485841072452898
Validation loss: 2.542550742825677

Epoch: 5| Step: 4
Training loss: 2.440888323969188
Validation loss: 2.5838167437551984

Epoch: 5| Step: 5
Training loss: 2.4941587873139612
Validation loss: 2.5254332526584466

Epoch: 5| Step: 6
Training loss: 2.4270474236141673
Validation loss: 2.554748859554858

Epoch: 5| Step: 7
Training loss: 2.6790836643712126
Validation loss: 2.5216127040181506

Epoch: 5| Step: 8
Training loss: 2.792979505825006
Validation loss: 2.5463898674395025

Epoch: 5| Step: 9
Training loss: 2.226179444674521
Validation loss: 2.4941637035531103

Epoch: 5| Step: 10
Training loss: 2.307448876208246
Validation loss: 2.502867784801657

Epoch: 327| Step: 0
Training loss: 2.2400879284086046
Validation loss: 2.518897112757308

Epoch: 5| Step: 1
Training loss: 2.503008653315645
Validation loss: 2.504259074752236

Epoch: 5| Step: 2
Training loss: 2.072889803867309
Validation loss: 2.5288006432141867

Epoch: 5| Step: 3
Training loss: 2.394374126612405
Validation loss: 2.5256118430715824

Epoch: 5| Step: 4
Training loss: 2.729396713306737
Validation loss: 2.5199723912149463

Epoch: 5| Step: 5
Training loss: 1.4053077932138576
Validation loss: 2.5107718085325788

Epoch: 5| Step: 6
Training loss: 3.0785277437190097
Validation loss: 2.5385362396215214

Epoch: 5| Step: 7
Training loss: 2.896686858124005
Validation loss: 2.5481763301232894

Epoch: 5| Step: 8
Training loss: 2.5187827247784464
Validation loss: 2.545988210218597

Epoch: 5| Step: 9
Training loss: 2.1554260891228414
Validation loss: 2.528008103052055

Epoch: 5| Step: 10
Training loss: 3.1607680512443634
Validation loss: 2.5177016830663677

Epoch: 328| Step: 0
Training loss: 1.811298893175812
Validation loss: 2.571359674860922

Epoch: 5| Step: 1
Training loss: 2.439792923973536
Validation loss: 2.471057998882942

Epoch: 5| Step: 2
Training loss: 1.9420634026750427
Validation loss: 2.519509455923716

Epoch: 5| Step: 3
Training loss: 2.6564223289687483
Validation loss: 2.5213933648219213

Epoch: 5| Step: 4
Training loss: 2.7091639101015788
Validation loss: 2.5311696535943162

Epoch: 5| Step: 5
Training loss: 2.5905958553648887
Validation loss: 2.5566801506198487

Epoch: 5| Step: 6
Training loss: 2.2701323824356496
Validation loss: 2.5694066005433815

Epoch: 5| Step: 7
Training loss: 2.672444333102468
Validation loss: 2.528745110926426

Epoch: 5| Step: 8
Training loss: 2.1883959434057507
Validation loss: 2.5264750981706

Epoch: 5| Step: 9
Training loss: 2.8747502094059394
Validation loss: 2.5691281816255978

Epoch: 5| Step: 10
Training loss: 2.699304162535883
Validation loss: 2.5453599169979735

Epoch: 329| Step: 0
Training loss: 2.7673956596188845
Validation loss: 2.560336890994923

Epoch: 5| Step: 1
Training loss: 2.4271523352598057
Validation loss: 2.5681239405394076

Epoch: 5| Step: 2
Training loss: 2.634771687788382
Validation loss: 2.5487914206625213

Epoch: 5| Step: 3
Training loss: 2.187622284877237
Validation loss: 2.5412186134062282

Epoch: 5| Step: 4
Training loss: 2.3363359296496458
Validation loss: 2.5386531891800277

Epoch: 5| Step: 5
Training loss: 2.708959291942951
Validation loss: 2.530717912050952

Epoch: 5| Step: 6
Training loss: 2.261884666774275
Validation loss: 2.5250555578369998

Epoch: 5| Step: 7
Training loss: 2.484067597954467
Validation loss: 2.5297930064072838

Epoch: 5| Step: 8
Training loss: 2.1447305777768966
Validation loss: 2.5441174657978305

Epoch: 5| Step: 9
Training loss: 2.2595452124505395
Validation loss: 2.520901343895111

Epoch: 5| Step: 10
Training loss: 2.990848729804427
Validation loss: 2.5675414110859225

Epoch: 330| Step: 0
Training loss: 2.2466254890283026
Validation loss: 2.4995548303139667

Epoch: 5| Step: 1
Training loss: 2.6487533696051027
Validation loss: 2.5632895052039695

Epoch: 5| Step: 2
Training loss: 1.6964239177783438
Validation loss: 2.5338983833643582

Epoch: 5| Step: 3
Training loss: 2.7483534652068236
Validation loss: 2.486705175089679

Epoch: 5| Step: 4
Training loss: 2.6706840136163503
Validation loss: 2.536854165115569

Epoch: 5| Step: 5
Training loss: 2.00739292852105
Validation loss: 2.543654546181053

Epoch: 5| Step: 6
Training loss: 2.38255813992022
Validation loss: 2.5258251199278745

Epoch: 5| Step: 7
Training loss: 2.866295116949532
Validation loss: 2.5324095138015763

Epoch: 5| Step: 8
Training loss: 1.8563258711083284
Validation loss: 2.533697714942299

Epoch: 5| Step: 9
Training loss: 2.5286105487743753
Validation loss: 2.5385834277762243

Epoch: 5| Step: 10
Training loss: 2.9638869760974487
Validation loss: 2.5511887938723694

Epoch: 331| Step: 0
Training loss: 2.4408141860219583
Validation loss: 2.509446104348928

Epoch: 5| Step: 1
Training loss: 2.0865822699219967
Validation loss: 2.524498863650029

Epoch: 5| Step: 2
Training loss: 2.5478106693189657
Validation loss: 2.5785838266072165

Epoch: 5| Step: 3
Training loss: 2.566135990306408
Validation loss: 2.539864639783419

Epoch: 5| Step: 4
Training loss: 2.6781000267475785
Validation loss: 2.543225234328069

Epoch: 5| Step: 5
Training loss: 3.1633342140231364
Validation loss: 2.529032165153469

Epoch: 5| Step: 6
Training loss: 2.3687216442494443
Validation loss: 2.558356280509688

Epoch: 5| Step: 7
Training loss: 1.9587890284191467
Validation loss: 2.518458353493918

Epoch: 5| Step: 8
Training loss: 2.0535362122163887
Validation loss: 2.5173870609140194

Epoch: 5| Step: 9
Training loss: 2.7840327368269433
Validation loss: 2.5664524457485514

Epoch: 5| Step: 10
Training loss: 2.3641540428938836
Validation loss: 2.500934435937808

Epoch: 332| Step: 0
Training loss: 2.8279148255542634
Validation loss: 2.5559904592807365

Epoch: 5| Step: 1
Training loss: 3.219894205807737
Validation loss: 2.4730129899898503

Epoch: 5| Step: 2
Training loss: 2.2988859961784303
Validation loss: 2.481243140499244

Epoch: 5| Step: 3
Training loss: 1.9362449272586775
Validation loss: 2.490575667206767

Epoch: 5| Step: 4
Training loss: 2.496893096590886
Validation loss: 2.5271457297145394

Epoch: 5| Step: 5
Training loss: 1.8859128632789106
Validation loss: 2.546335963150196

Epoch: 5| Step: 6
Training loss: 1.849170733506537
Validation loss: 2.526016596187754

Epoch: 5| Step: 7
Training loss: 2.594611427012499
Validation loss: 2.516349097707403

Epoch: 5| Step: 8
Training loss: 2.1612616637198148
Validation loss: 2.526031010694813

Epoch: 5| Step: 9
Training loss: 3.031502939269692
Validation loss: 2.5360317895347406

Epoch: 5| Step: 10
Training loss: 2.2100578148645673
Validation loss: 2.555547272456393

Epoch: 333| Step: 0
Training loss: 2.8226082458552963
Validation loss: 2.513891461630785

Epoch: 5| Step: 1
Training loss: 2.394075384509917
Validation loss: 2.511167806437931

Epoch: 5| Step: 2
Training loss: 2.70130197428244
Validation loss: 2.51547053224695

Epoch: 5| Step: 3
Training loss: 2.2136783931616693
Validation loss: 2.536556226762433

Epoch: 5| Step: 4
Training loss: 2.3078312526346476
Validation loss: 2.517868480554405

Epoch: 5| Step: 5
Training loss: 2.2155599092249223
Validation loss: 2.544696007851293

Epoch: 5| Step: 6
Training loss: 2.2338873057547044
Validation loss: 2.5551679408498877

Epoch: 5| Step: 7
Training loss: 2.7618046467978097
Validation loss: 2.5422165785309323

Epoch: 5| Step: 8
Training loss: 2.2351519960951634
Validation loss: 2.51086787895023

Epoch: 5| Step: 9
Training loss: 2.8118722003041863
Validation loss: 2.5481500554957357

Epoch: 5| Step: 10
Training loss: 2.347687427485105
Validation loss: 2.456586352255589

Epoch: 334| Step: 0
Training loss: 2.372216852655024
Validation loss: 2.5287279137863177

Epoch: 5| Step: 1
Training loss: 2.543643984823171
Validation loss: 2.5696070648351492

Epoch: 5| Step: 2
Training loss: 3.2894376780898447
Validation loss: 2.5137234431123407

Epoch: 5| Step: 3
Training loss: 2.679574502503211
Validation loss: 2.5302416607106055

Epoch: 5| Step: 4
Training loss: 2.208026276839813
Validation loss: 2.517536460041449

Epoch: 5| Step: 5
Training loss: 2.3864715997623285
Validation loss: 2.54627593626366

Epoch: 5| Step: 6
Training loss: 2.5277044637293007
Validation loss: 2.514267018047834

Epoch: 5| Step: 7
Training loss: 2.1433558065483096
Validation loss: 2.5589531643631096

Epoch: 5| Step: 8
Training loss: 2.202656039925096
Validation loss: 2.6277611406505765

Epoch: 5| Step: 9
Training loss: 2.407291632772919
Validation loss: 2.5578655169395734

Epoch: 5| Step: 10
Training loss: 2.2042141650249487
Validation loss: 2.5657926365214805

Epoch: 335| Step: 0
Training loss: 2.809232551604032
Validation loss: 2.4875838116114872

Epoch: 5| Step: 1
Training loss: 2.2956435866503124
Validation loss: 2.561334967923469

Epoch: 5| Step: 2
Training loss: 2.537234449350406
Validation loss: 2.512889859200056

Epoch: 5| Step: 3
Training loss: 2.4985817701185997
Validation loss: 2.53952714150456

Epoch: 5| Step: 4
Training loss: 2.2058219905148992
Validation loss: 2.5418467936105915

Epoch: 5| Step: 5
Training loss: 2.3178119993421453
Validation loss: 2.52557846269302

Epoch: 5| Step: 6
Training loss: 2.5501379162760607
Validation loss: 2.5104082063404634

Epoch: 5| Step: 7
Training loss: 2.6272297426387112
Validation loss: 2.5158471409585412

Epoch: 5| Step: 8
Training loss: 2.1488558275260523
Validation loss: 2.525419717906676

Epoch: 5| Step: 9
Training loss: 2.2601276922020563
Validation loss: 2.5297475488299677

Epoch: 5| Step: 10
Training loss: 2.524406695770199
Validation loss: 2.5160905522766246

Epoch: 336| Step: 0
Training loss: 2.3870503746185996
Validation loss: 2.5241249474128518

Epoch: 5| Step: 1
Training loss: 1.8963861253394587
Validation loss: 2.4890366912346886

Epoch: 5| Step: 2
Training loss: 2.2967545873517885
Validation loss: 2.5139111842863393

Epoch: 5| Step: 3
Training loss: 2.291423738492864
Validation loss: 2.5183524416884184

Epoch: 5| Step: 4
Training loss: 2.055960953174696
Validation loss: 2.5225115794604056

Epoch: 5| Step: 5
Training loss: 2.364742111275167
Validation loss: 2.538393370598712

Epoch: 5| Step: 6
Training loss: 2.6447434671243584
Validation loss: 2.484297848375024

Epoch: 5| Step: 7
Training loss: 3.0668615306918405
Validation loss: 2.5220786676073517

Epoch: 5| Step: 8
Training loss: 3.084440462138561
Validation loss: 2.508319139983824

Epoch: 5| Step: 9
Training loss: 2.261660771129161
Validation loss: 2.5128302764862664

Epoch: 5| Step: 10
Training loss: 2.71484743845298
Validation loss: 2.551058720795505

Epoch: 337| Step: 0
Training loss: 2.148073033716198
Validation loss: 2.533878544121258

Epoch: 5| Step: 1
Training loss: 2.37778891395425
Validation loss: 2.5167144258945755

Epoch: 5| Step: 2
Training loss: 2.3160994070787333
Validation loss: 2.5398519510729947

Epoch: 5| Step: 3
Training loss: 2.343994534769294
Validation loss: 2.559723363932949

Epoch: 5| Step: 4
Training loss: 1.8356827579460548
Validation loss: 2.532162869230817

Epoch: 5| Step: 5
Training loss: 2.333345844598561
Validation loss: 2.485409571331315

Epoch: 5| Step: 6
Training loss: 2.036734234656267
Validation loss: 2.5299367390738055

Epoch: 5| Step: 7
Training loss: 2.4024981689446148
Validation loss: 2.549933896584285

Epoch: 5| Step: 8
Training loss: 3.0018791035725974
Validation loss: 2.5415918587001323

Epoch: 5| Step: 9
Training loss: 3.4662474806756136
Validation loss: 2.545051528402894

Epoch: 5| Step: 10
Training loss: 2.6310615490188254
Validation loss: 2.513776143205397

Epoch: 338| Step: 0
Training loss: 2.1344910887485047
Validation loss: 2.5249264981246564

Epoch: 5| Step: 1
Training loss: 2.180544011543747
Validation loss: 2.5416728489836076

Epoch: 5| Step: 2
Training loss: 2.2348442385201652
Validation loss: 2.5627129479022632

Epoch: 5| Step: 3
Training loss: 2.8655721911241296
Validation loss: 2.536359413914852

Epoch: 5| Step: 4
Training loss: 2.3464557542447753
Validation loss: 2.5295897761116124

Epoch: 5| Step: 5
Training loss: 2.534584580491743
Validation loss: 2.512376288932085

Epoch: 5| Step: 6
Training loss: 2.501241375757207
Validation loss: 2.49447274317363

Epoch: 5| Step: 7
Training loss: 2.8194430799642767
Validation loss: 2.5267870668523162

Epoch: 5| Step: 8
Training loss: 2.106947455686584
Validation loss: 2.57843201997743

Epoch: 5| Step: 9
Training loss: 2.1958566446050174
Validation loss: 2.5667294549580104

Epoch: 5| Step: 10
Training loss: 2.7942004495640163
Validation loss: 2.4903813862460558

Epoch: 339| Step: 0
Training loss: 1.8321582611889642
Validation loss: 2.5663888227410143

Epoch: 5| Step: 1
Training loss: 1.7851961828394003
Validation loss: 2.520402661190418

Epoch: 5| Step: 2
Training loss: 2.2226307202098172
Validation loss: 2.544980345261552

Epoch: 5| Step: 3
Training loss: 2.7626233379741674
Validation loss: 2.5271025648747125

Epoch: 5| Step: 4
Training loss: 2.4660000514628333
Validation loss: 2.514068562270826

Epoch: 5| Step: 5
Training loss: 2.2749372955735514
Validation loss: 2.567383449569982

Epoch: 5| Step: 6
Training loss: 2.6695322395660024
Validation loss: 2.499857810294035

Epoch: 5| Step: 7
Training loss: 2.3693569804728725
Validation loss: 2.561121734279047

Epoch: 5| Step: 8
Training loss: 2.9776731006133312
Validation loss: 2.537068992763929

Epoch: 5| Step: 9
Training loss: 2.332402543202
Validation loss: 2.592903508098851

Epoch: 5| Step: 10
Training loss: 2.965778992396143
Validation loss: 2.4970128784609793

Epoch: 340| Step: 0
Training loss: 2.5195292628080828
Validation loss: 2.5284686265935776

Epoch: 5| Step: 1
Training loss: 2.1576977720705335
Validation loss: 2.531576597634693

Epoch: 5| Step: 2
Training loss: 2.513723661871844
Validation loss: 2.500437653083111

Epoch: 5| Step: 3
Training loss: 2.704305754749884
Validation loss: 2.524592369597461

Epoch: 5| Step: 4
Training loss: 3.0030295651581365
Validation loss: 2.5123544317678053

Epoch: 5| Step: 5
Training loss: 2.1927427408474216
Validation loss: 2.537113893760927

Epoch: 5| Step: 6
Training loss: 1.961105157136509
Validation loss: 2.5273543865741246

Epoch: 5| Step: 7
Training loss: 2.1478721290901754
Validation loss: 2.5383300391148564

Epoch: 5| Step: 8
Training loss: 2.7928114199841696
Validation loss: 2.476470089463466

Epoch: 5| Step: 9
Training loss: 2.515452313863802
Validation loss: 2.5197207962806316

Epoch: 5| Step: 10
Training loss: 2.2807229883412714
Validation loss: 2.474002551129981

Epoch: 341| Step: 0
Training loss: 2.7473485475541772
Validation loss: 2.531358686914377

Epoch: 5| Step: 1
Training loss: 2.5191804390279597
Validation loss: 2.5071838795265196

Epoch: 5| Step: 2
Training loss: 2.584186156821743
Validation loss: 2.494297862879297

Epoch: 5| Step: 3
Training loss: 2.2255841163537413
Validation loss: 2.5417369968629724

Epoch: 5| Step: 4
Training loss: 2.231316667517129
Validation loss: 2.513410708209448

Epoch: 5| Step: 5
Training loss: 1.7498167486974792
Validation loss: 2.5188214714649866

Epoch: 5| Step: 6
Training loss: 2.5519357963007536
Validation loss: 2.5409216953174867

Epoch: 5| Step: 7
Training loss: 2.525273366803563
Validation loss: 2.5797417139198924

Epoch: 5| Step: 8
Training loss: 3.3256993296890416
Validation loss: 2.531998365588188

Epoch: 5| Step: 9
Training loss: 2.0999840690371823
Validation loss: 2.557158843617071

Epoch: 5| Step: 10
Training loss: 2.314163022430521
Validation loss: 2.529394811128713

Epoch: 342| Step: 0
Training loss: 2.3446328089987145
Validation loss: 2.519964756150299

Epoch: 5| Step: 1
Training loss: 2.486842819124532
Validation loss: 2.5588547445188192

Epoch: 5| Step: 2
Training loss: 2.484628724391491
Validation loss: 2.5502346610060194

Epoch: 5| Step: 3
Training loss: 2.1342816445528334
Validation loss: 2.5255505927587873

Epoch: 5| Step: 4
Training loss: 1.8091839019057507
Validation loss: 2.517665142011449

Epoch: 5| Step: 5
Training loss: 2.648511497341534
Validation loss: 2.5147592375386814

Epoch: 5| Step: 6
Training loss: 2.622501273941298
Validation loss: 2.5704363217641086

Epoch: 5| Step: 7
Training loss: 1.9321974519722882
Validation loss: 2.5398946176319805

Epoch: 5| Step: 8
Training loss: 2.8368883456773273
Validation loss: 2.548143131649636

Epoch: 5| Step: 9
Training loss: 2.8197824925890074
Validation loss: 2.520061409987049

Epoch: 5| Step: 10
Training loss: 2.6344812917025178
Validation loss: 2.5273544920672926

Epoch: 343| Step: 0
Training loss: 2.6001608798798053
Validation loss: 2.5250307158221625

Epoch: 5| Step: 1
Training loss: 2.535672598098926
Validation loss: 2.5177615063672043

Epoch: 5| Step: 2
Training loss: 2.1546081705407114
Validation loss: 2.569087316772289

Epoch: 5| Step: 3
Training loss: 2.9881267831809413
Validation loss: 2.5351264244373013

Epoch: 5| Step: 4
Training loss: 1.9198859862410567
Validation loss: 2.543154803488757

Epoch: 5| Step: 5
Training loss: 2.7583411037032137
Validation loss: 2.524193661138139

Epoch: 5| Step: 6
Training loss: 2.1878015582809947
Validation loss: 2.5795316138550346

Epoch: 5| Step: 7
Training loss: 2.4632590348838694
Validation loss: 2.553388351739362

Epoch: 5| Step: 8
Training loss: 2.2877128710480443
Validation loss: 2.560189356623271

Epoch: 5| Step: 9
Training loss: 2.3166701373982215
Validation loss: 2.5245259612338558

Epoch: 5| Step: 10
Training loss: 2.1459571531058836
Validation loss: 2.486836351364632

Epoch: 344| Step: 0
Training loss: 2.1747022929279796
Validation loss: 2.5482641423170898

Epoch: 5| Step: 1
Training loss: 2.4767334695520264
Validation loss: 2.5402984130329602

Epoch: 5| Step: 2
Training loss: 2.405849373894672
Validation loss: 2.5222504650462323

Epoch: 5| Step: 3
Training loss: 2.142218115300524
Validation loss: 2.5187274286245116

Epoch: 5| Step: 4
Training loss: 2.299202913572606
Validation loss: 2.5154175568056147

Epoch: 5| Step: 5
Training loss: 2.1923311563026386
Validation loss: 2.5034561744583574

Epoch: 5| Step: 6
Training loss: 2.228349256532318
Validation loss: 2.548139127440603

Epoch: 5| Step: 7
Training loss: 2.6197520885675805
Validation loss: 2.494190697983975

Epoch: 5| Step: 8
Training loss: 2.2131817214621927
Validation loss: 2.557136141116584

Epoch: 5| Step: 9
Training loss: 2.834914682439997
Validation loss: 2.550688229716711

Epoch: 5| Step: 10
Training loss: 2.973287547946454
Validation loss: 2.4957080218025656

Epoch: 345| Step: 0
Training loss: 2.5084907351393646
Validation loss: 2.4917132324675553

Epoch: 5| Step: 1
Training loss: 2.3533058167957055
Validation loss: 2.539626987709328

Epoch: 5| Step: 2
Training loss: 2.7759845052610985
Validation loss: 2.5327857136909664

Epoch: 5| Step: 3
Training loss: 3.1977417905295176
Validation loss: 2.52233660940606

Epoch: 5| Step: 4
Training loss: 2.177639891623294
Validation loss: 2.54179659739462

Epoch: 5| Step: 5
Training loss: 2.5553031902743113
Validation loss: 2.54915831957345

Epoch: 5| Step: 6
Training loss: 2.167129931685709
Validation loss: 2.542584379821099

Epoch: 5| Step: 7
Training loss: 2.0786323788432943
Validation loss: 2.5483217974794106

Epoch: 5| Step: 8
Training loss: 2.201498635247661
Validation loss: 2.507032717156806

Epoch: 5| Step: 9
Training loss: 2.28602685238744
Validation loss: 2.4704726213834203

Epoch: 5| Step: 10
Training loss: 2.0061818191494
Validation loss: 2.5180399289217825

Epoch: 346| Step: 0
Training loss: 1.761867068659538
Validation loss: 2.543696254498956

Epoch: 5| Step: 1
Training loss: 2.2249544460476725
Validation loss: 2.5345468000130653

Epoch: 5| Step: 2
Training loss: 2.4261604049625225
Validation loss: 2.4863346621340567

Epoch: 5| Step: 3
Training loss: 2.2720869844333738
Validation loss: 2.541679254867498

Epoch: 5| Step: 4
Training loss: 2.8879989655299987
Validation loss: 2.5468314010015796

Epoch: 5| Step: 5
Training loss: 2.0553188731851786
Validation loss: 2.510543873802551

Epoch: 5| Step: 6
Training loss: 2.450834334640359
Validation loss: 2.5292127861259996

Epoch: 5| Step: 7
Training loss: 2.518022046781198
Validation loss: 2.5010931342588707

Epoch: 5| Step: 8
Training loss: 2.7927205862487687
Validation loss: 2.509956874992529

Epoch: 5| Step: 9
Training loss: 2.356258026028429
Validation loss: 2.506685432212422

Epoch: 5| Step: 10
Training loss: 2.8676777350394547
Validation loss: 2.54934822332909

Epoch: 347| Step: 0
Training loss: 2.252040467632139
Validation loss: 2.5394738259664966

Epoch: 5| Step: 1
Training loss: 2.380611916904448
Validation loss: 2.546174093413004

Epoch: 5| Step: 2
Training loss: 2.1135004462265794
Validation loss: 2.5531556084079705

Epoch: 5| Step: 3
Training loss: 2.54145263854691
Validation loss: 2.5259796973948143

Epoch: 5| Step: 4
Training loss: 2.508277445917222
Validation loss: 2.5469863447517573

Epoch: 5| Step: 5
Training loss: 1.7371541344529344
Validation loss: 2.516162444720565

Epoch: 5| Step: 6
Training loss: 2.1369406743541637
Validation loss: 2.5130190014958687

Epoch: 5| Step: 7
Training loss: 2.500996391101599
Validation loss: 2.500795667941287

Epoch: 5| Step: 8
Training loss: 2.7961569775458983
Validation loss: 2.5211199790096863

Epoch: 5| Step: 9
Training loss: 2.541396632207103
Validation loss: 2.5265493677942437

Epoch: 5| Step: 10
Training loss: 2.9839387744625743
Validation loss: 2.540256551537788

Epoch: 348| Step: 0
Training loss: 2.42051136635592
Validation loss: 2.4998424459873636

Epoch: 5| Step: 1
Training loss: 2.319510786994772
Validation loss: 2.542282668989572

Epoch: 5| Step: 2
Training loss: 2.538631555225621
Validation loss: 2.579827766020965

Epoch: 5| Step: 3
Training loss: 2.343503710204016
Validation loss: 2.488818636395078

Epoch: 5| Step: 4
Training loss: 2.733601487969989
Validation loss: 2.5150963307943246

Epoch: 5| Step: 5
Training loss: 2.8899122854471075
Validation loss: 2.5165889164318718

Epoch: 5| Step: 6
Training loss: 2.1489379299993163
Validation loss: 2.547309927434788

Epoch: 5| Step: 7
Training loss: 2.9787168541143454
Validation loss: 2.496745348530797

Epoch: 5| Step: 8
Training loss: 2.3013280144376203
Validation loss: 2.515393369213484

Epoch: 5| Step: 9
Training loss: 1.928599309467436
Validation loss: 2.534896555402763

Epoch: 5| Step: 10
Training loss: 2.1142634508440983
Validation loss: 2.5086260208822284

Epoch: 349| Step: 0
Training loss: 2.9136951204726134
Validation loss: 2.552567630210259

Epoch: 5| Step: 1
Training loss: 2.175154809813608
Validation loss: 2.558392590096411

Epoch: 5| Step: 2
Training loss: 2.3593083050124215
Validation loss: 2.499726724557856

Epoch: 5| Step: 3
Training loss: 2.2483351163901837
Validation loss: 2.5257886913212997

Epoch: 5| Step: 4
Training loss: 2.4265686821106556
Validation loss: 2.5599918250881437

Epoch: 5| Step: 5
Training loss: 2.235406170832538
Validation loss: 2.527077924572481

Epoch: 5| Step: 6
Training loss: 2.5516522309409675
Validation loss: 2.5371817257409326

Epoch: 5| Step: 7
Training loss: 2.580367159482227
Validation loss: 2.524937995726856

Epoch: 5| Step: 8
Training loss: 2.9239753884820456
Validation loss: 2.5111525317487016

Epoch: 5| Step: 9
Training loss: 2.007601953295213
Validation loss: 2.5552247349221484

Epoch: 5| Step: 10
Training loss: 1.8728594959714384
Validation loss: 2.520452491130354

Epoch: 350| Step: 0
Training loss: 2.399210056797229
Validation loss: 2.516790532866417

Epoch: 5| Step: 1
Training loss: 2.16918998894285
Validation loss: 2.5498304021528098

Epoch: 5| Step: 2
Training loss: 2.646693102498795
Validation loss: 2.561970275582363

Epoch: 5| Step: 3
Training loss: 2.9580840601245084
Validation loss: 2.5457490986201234

Epoch: 5| Step: 4
Training loss: 2.38356251403887
Validation loss: 2.5126133932712817

Epoch: 5| Step: 5
Training loss: 1.8400305391970027
Validation loss: 2.5498137715102365

Epoch: 5| Step: 6
Training loss: 2.1548775990856224
Validation loss: 2.54029523307715

Epoch: 5| Step: 7
Training loss: 2.6186898090300748
Validation loss: 2.536912488853876

Epoch: 5| Step: 8
Training loss: 2.3252447348144294
Validation loss: 2.497908600351458

Epoch: 5| Step: 9
Training loss: 2.4083118274964876
Validation loss: 2.555043102225376

Epoch: 5| Step: 10
Training loss: 2.4272082273468314
Validation loss: 2.54976919972715

Epoch: 351| Step: 0
Training loss: 2.517758240926523
Validation loss: 2.5373628153407815

Epoch: 5| Step: 1
Training loss: 1.8196660150369677
Validation loss: 2.5446983269880525

Epoch: 5| Step: 2
Training loss: 2.3665176299901507
Validation loss: 2.515712831533676

Epoch: 5| Step: 3
Training loss: 2.584731267245582
Validation loss: 2.545104579530791

Epoch: 5| Step: 4
Training loss: 2.3164188069458347
Validation loss: 2.544304169322795

Epoch: 5| Step: 5
Training loss: 2.6064126565430397
Validation loss: 2.5221535332424803

Epoch: 5| Step: 6
Training loss: 2.0819826961388235
Validation loss: 2.572882141689387

Epoch: 5| Step: 7
Training loss: 1.9451474652125298
Validation loss: 2.5593969433776214

Epoch: 5| Step: 8
Training loss: 2.7982145543323935
Validation loss: 2.5472402657346813

Epoch: 5| Step: 9
Training loss: 1.7835620798782252
Validation loss: 2.5221107444390984

Epoch: 5| Step: 10
Training loss: 3.4728858279708956
Validation loss: 2.532409384223004

Epoch: 352| Step: 0
Training loss: 2.2425210418904733
Validation loss: 2.5507067120291707

Epoch: 5| Step: 1
Training loss: 2.4075264455703502
Validation loss: 2.552546717799028

Epoch: 5| Step: 2
Training loss: 2.0265367257766713
Validation loss: 2.5607038115850216

Epoch: 5| Step: 3
Training loss: 2.293224417942689
Validation loss: 2.502386535283061

Epoch: 5| Step: 4
Training loss: 2.916801249714226
Validation loss: 2.5232653617403504

Epoch: 5| Step: 5
Training loss: 3.001834626300594
Validation loss: 2.526096615300979

Epoch: 5| Step: 6
Training loss: 2.209704051678006
Validation loss: 2.510837550456252

Epoch: 5| Step: 7
Training loss: 2.2673552121807306
Validation loss: 2.567819499869813

Epoch: 5| Step: 8
Training loss: 2.110250220806832
Validation loss: 2.5676705563286517

Epoch: 5| Step: 9
Training loss: 2.5503809849981507
Validation loss: 2.5664057295613882

Epoch: 5| Step: 10
Training loss: 2.4072092299388688
Validation loss: 2.502191127888088

Epoch: 353| Step: 0
Training loss: 2.565866631340027
Validation loss: 2.5009146914141955

Epoch: 5| Step: 1
Training loss: 2.641992429348468
Validation loss: 2.5623573875810584

Epoch: 5| Step: 2
Training loss: 2.5900089907398076
Validation loss: 2.5102046995695044

Epoch: 5| Step: 3
Training loss: 2.3843770878333954
Validation loss: 2.5627237037718547

Epoch: 5| Step: 4
Training loss: 2.4514467366435064
Validation loss: 2.5717004441673135

Epoch: 5| Step: 5
Training loss: 2.8574155336780285
Validation loss: 2.556956598291672

Epoch: 5| Step: 6
Training loss: 2.1578268284083704
Validation loss: 2.510067969962843

Epoch: 5| Step: 7
Training loss: 2.5755858893642882
Validation loss: 2.5264143081667663

Epoch: 5| Step: 8
Training loss: 1.801370983415509
Validation loss: 2.4924191654528784

Epoch: 5| Step: 9
Training loss: 2.3892134943687187
Validation loss: 2.5566875757689562

Epoch: 5| Step: 10
Training loss: 1.9528088122971112
Validation loss: 2.4783490691464114

Epoch: 354| Step: 0
Training loss: 2.5086935521852074
Validation loss: 2.5044494851536334

Epoch: 5| Step: 1
Training loss: 2.5553118674795425
Validation loss: 2.5528682028384027

Epoch: 5| Step: 2
Training loss: 2.4116242079126735
Validation loss: 2.5867735720609013

Epoch: 5| Step: 3
Training loss: 2.2574332687636955
Validation loss: 2.5030842398790334

Epoch: 5| Step: 4
Training loss: 2.008762001519234
Validation loss: 2.561773486810218

Epoch: 5| Step: 5
Training loss: 1.412147067715845
Validation loss: 2.5012542459875453

Epoch: 5| Step: 6
Training loss: 3.0537379513415797
Validation loss: 2.523179586413127

Epoch: 5| Step: 7
Training loss: 2.4204249809631486
Validation loss: 2.5166444551590192

Epoch: 5| Step: 8
Training loss: 2.1042598162387316
Validation loss: 2.510279254491056

Epoch: 5| Step: 9
Training loss: 2.1914146273583746
Validation loss: 2.512572128598457

Epoch: 5| Step: 10
Training loss: 3.2813185911729668
Validation loss: 2.4992147268590843

Epoch: 355| Step: 0
Training loss: 2.6649885162335116
Validation loss: 2.5179264234324243

Epoch: 5| Step: 1
Training loss: 2.0474786232378515
Validation loss: 2.5072129280719815

Epoch: 5| Step: 2
Training loss: 2.027164517456578
Validation loss: 2.524700662277512

Epoch: 5| Step: 3
Training loss: 1.832156179109313
Validation loss: 2.5188259110772115

Epoch: 5| Step: 4
Training loss: 2.8738880494996892
Validation loss: 2.5183285810656852

Epoch: 5| Step: 5
Training loss: 2.455718692070853
Validation loss: 2.554801053052389

Epoch: 5| Step: 6
Training loss: 2.7883901774131505
Validation loss: 2.5724776030673198

Epoch: 5| Step: 7
Training loss: 1.5062855316656512
Validation loss: 2.5209405415727533

Epoch: 5| Step: 8
Training loss: 2.8123055284870957
Validation loss: 2.521955167436974

Epoch: 5| Step: 9
Training loss: 2.6046411209233664
Validation loss: 2.554285272726671

Epoch: 5| Step: 10
Training loss: 2.6475318102776186
Validation loss: 2.5905625265814014

Epoch: 356| Step: 0
Training loss: 2.7800405208461236
Validation loss: 2.5594307160603758

Epoch: 5| Step: 1
Training loss: 2.2106299304340955
Validation loss: 2.526856605054352

Epoch: 5| Step: 2
Training loss: 2.3024202218249936
Validation loss: 2.5443633036663362

Epoch: 5| Step: 3
Training loss: 2.753371685983263
Validation loss: 2.5274190946476587

Epoch: 5| Step: 4
Training loss: 2.1585837740534726
Validation loss: 2.5240678232708817

Epoch: 5| Step: 5
Training loss: 2.454627482010143
Validation loss: 2.498039120582378

Epoch: 5| Step: 6
Training loss: 2.0068970014280305
Validation loss: 2.508566247474015

Epoch: 5| Step: 7
Training loss: 2.4182038077386525
Validation loss: 2.5217687204807384

Epoch: 5| Step: 8
Training loss: 2.601069956482921
Validation loss: 2.499281487732738

Epoch: 5| Step: 9
Training loss: 2.566080894342779
Validation loss: 2.527110659225989

Epoch: 5| Step: 10
Training loss: 2.2081650243954547
Validation loss: 2.542898085221496

Epoch: 357| Step: 0
Training loss: 1.908846728079242
Validation loss: 2.5233152458901733

Epoch: 5| Step: 1
Training loss: 2.0561870716054753
Validation loss: 2.5192541564193904

Epoch: 5| Step: 2
Training loss: 2.7755172453633
Validation loss: 2.537182688679077

Epoch: 5| Step: 3
Training loss: 1.8465690398088335
Validation loss: 2.5141746596368724

Epoch: 5| Step: 4
Training loss: 2.532330882685329
Validation loss: 2.5222083822712733

Epoch: 5| Step: 5
Training loss: 2.0781362432878416
Validation loss: 2.5444772444133443

Epoch: 5| Step: 6
Training loss: 2.3278626159689244
Validation loss: 2.5437063938601963

Epoch: 5| Step: 7
Training loss: 2.5299485239815813
Validation loss: 2.501644127127934

Epoch: 5| Step: 8
Training loss: 3.0786817018194923
Validation loss: 2.545251033261381

Epoch: 5| Step: 9
Training loss: 2.340302844216732
Validation loss: 2.5231107561652495

Epoch: 5| Step: 10
Training loss: 2.930233184857335
Validation loss: 2.5005740501335905

Epoch: 358| Step: 0
Training loss: 2.3985289515850745
Validation loss: 2.527285559458343

Epoch: 5| Step: 1
Training loss: 3.0479931466934174
Validation loss: 2.482579208663699

Epoch: 5| Step: 2
Training loss: 2.5576414243315155
Validation loss: 2.4960873195625637

Epoch: 5| Step: 3
Training loss: 2.1607294408633786
Validation loss: 2.5654286202445684

Epoch: 5| Step: 4
Training loss: 2.284802114319558
Validation loss: 2.5528345552301484

Epoch: 5| Step: 5
Training loss: 2.1909956113840128
Validation loss: 2.50552334631025

Epoch: 5| Step: 6
Training loss: 2.5022396545958547
Validation loss: 2.5187737904320304

Epoch: 5| Step: 7
Training loss: 1.8931800664510412
Validation loss: 2.551043110133487

Epoch: 5| Step: 8
Training loss: 1.9284632579299168
Validation loss: 2.526164123050046

Epoch: 5| Step: 9
Training loss: 2.874960691763804
Validation loss: 2.496011346505742

Epoch: 5| Step: 10
Training loss: 2.210686443619256
Validation loss: 2.522017120054183

Epoch: 359| Step: 0
Training loss: 2.4396527882849384
Validation loss: 2.5538719209796237

Epoch: 5| Step: 1
Training loss: 2.0226549675304932
Validation loss: 2.524759283524512

Epoch: 5| Step: 2
Training loss: 1.9113050879254307
Validation loss: 2.5041443313859184

Epoch: 5| Step: 3
Training loss: 2.848247785836746
Validation loss: 2.5143164138954988

Epoch: 5| Step: 4
Training loss: 2.16000580910502
Validation loss: 2.5685483182608086

Epoch: 5| Step: 5
Training loss: 2.478912778617949
Validation loss: 2.546275776179331

Epoch: 5| Step: 6
Training loss: 3.282058180326463
Validation loss: 2.55507270483101

Epoch: 5| Step: 7
Training loss: 2.162913433972258
Validation loss: 2.551661743406655

Epoch: 5| Step: 8
Training loss: 2.0937470393373423
Validation loss: 2.5547400991551665

Epoch: 5| Step: 9
Training loss: 2.577964731494563
Validation loss: 2.4885488296618807

Epoch: 5| Step: 10
Training loss: 2.3718037429982046
Validation loss: 2.4977312509586125

Epoch: 360| Step: 0
Training loss: 2.4200397059438354
Validation loss: 2.544600004615152

Epoch: 5| Step: 1
Training loss: 2.9868087032581108
Validation loss: 2.5546093920295925

Epoch: 5| Step: 2
Training loss: 1.7939790692421431
Validation loss: 2.530656983876615

Epoch: 5| Step: 3
Training loss: 1.9896774935452008
Validation loss: 2.52646531634311

Epoch: 5| Step: 4
Training loss: 2.77392109697776
Validation loss: 2.4942309583350886

Epoch: 5| Step: 5
Training loss: 2.128731312694946
Validation loss: 2.533105135723344

Epoch: 5| Step: 6
Training loss: 2.638105556160624
Validation loss: 2.5586346622149714

Epoch: 5| Step: 7
Training loss: 2.5317635662762195
Validation loss: 2.523408357825382

Epoch: 5| Step: 8
Training loss: 2.665177187584935
Validation loss: 2.585549526977552

Epoch: 5| Step: 9
Training loss: 2.300137233786386
Validation loss: 2.5629875045522406

Epoch: 5| Step: 10
Training loss: 1.9731451958247148
Validation loss: 2.5467789943468784

Epoch: 361| Step: 0
Training loss: 2.1472868456320215
Validation loss: 2.5415510746091967

Epoch: 5| Step: 1
Training loss: 2.5429984704784454
Validation loss: 2.5625333106044104

Epoch: 5| Step: 2
Training loss: 2.3113001210713215
Validation loss: 2.558736330725198

Epoch: 5| Step: 3
Training loss: 3.1416908087844178
Validation loss: 2.5070561699113543

Epoch: 5| Step: 4
Training loss: 2.6805669381312316
Validation loss: 2.4870002565722915

Epoch: 5| Step: 5
Training loss: 2.328815127499667
Validation loss: 2.5486742472887847

Epoch: 5| Step: 6
Training loss: 2.3511553947402253
Validation loss: 2.4920738549966446

Epoch: 5| Step: 7
Training loss: 1.8527479923655892
Validation loss: 2.5354743739086483

Epoch: 5| Step: 8
Training loss: 2.140542578676708
Validation loss: 2.5723532786039374

Epoch: 5| Step: 9
Training loss: 2.0383708847883
Validation loss: 2.5311767373065797

Epoch: 5| Step: 10
Training loss: 2.684326693685289
Validation loss: 2.5540108405667294

Epoch: 362| Step: 0
Training loss: 2.635395356545718
Validation loss: 2.4888221921709075

Epoch: 5| Step: 1
Training loss: 1.5093459795892705
Validation loss: 2.524652327143753

Epoch: 5| Step: 2
Training loss: 2.8809090302924028
Validation loss: 2.5394066826436488

Epoch: 5| Step: 3
Training loss: 2.6488174571025134
Validation loss: 2.503685856217341

Epoch: 5| Step: 4
Training loss: 2.2185966546164364
Validation loss: 2.5912876655312886

Epoch: 5| Step: 5
Training loss: 2.4736420653449134
Validation loss: 2.557156695184171

Epoch: 5| Step: 6
Training loss: 2.5075057843370745
Validation loss: 2.5673373025275046

Epoch: 5| Step: 7
Training loss: 2.014584413177716
Validation loss: 2.5333976542198515

Epoch: 5| Step: 8
Training loss: 2.8621815733395826
Validation loss: 2.551247056195861

Epoch: 5| Step: 9
Training loss: 2.0152631331312683
Validation loss: 2.5374858414304313

Epoch: 5| Step: 10
Training loss: 1.703796884139349
Validation loss: 2.528646960046541

Epoch: 363| Step: 0
Training loss: 2.2583748404241577
Validation loss: 2.4921201674398965

Epoch: 5| Step: 1
Training loss: 2.5093883661315592
Validation loss: 2.4970537277894516

Epoch: 5| Step: 2
Training loss: 2.654253489832377
Validation loss: 2.549053362509803

Epoch: 5| Step: 3
Training loss: 2.460516127584866
Validation loss: 2.527945315588183

Epoch: 5| Step: 4
Training loss: 2.606504403191643
Validation loss: 2.5368996641129025

Epoch: 5| Step: 5
Training loss: 2.7880200914400595
Validation loss: 2.4945702778364858

Epoch: 5| Step: 6
Training loss: 2.158947459844472
Validation loss: 2.5255707562646963

Epoch: 5| Step: 7
Training loss: 2.1191010220953843
Validation loss: 2.5827316995427423

Epoch: 5| Step: 8
Training loss: 2.2396755702224094
Validation loss: 2.5571086772879785

Epoch: 5| Step: 9
Training loss: 2.395428487877158
Validation loss: 2.5102063908210037

Epoch: 5| Step: 10
Training loss: 1.955049466924389
Validation loss: 2.5374606664666137

Epoch: 364| Step: 0
Training loss: 2.170650329002707
Validation loss: 2.526911030898047

Epoch: 5| Step: 1
Training loss: 2.438275042828179
Validation loss: 2.558580886644412

Epoch: 5| Step: 2
Training loss: 2.2354101170861345
Validation loss: 2.555036763961271

Epoch: 5| Step: 3
Training loss: 2.480018683024758
Validation loss: 2.5516016298145137

Epoch: 5| Step: 4
Training loss: 2.376280088279343
Validation loss: 2.539581957515571

Epoch: 5| Step: 5
Training loss: 2.4145598161642137
Validation loss: 2.566016264047898

Epoch: 5| Step: 6
Training loss: 2.175448325418221
Validation loss: 2.5030165736245267

Epoch: 5| Step: 7
Training loss: 2.3622958059723493
Validation loss: 2.4927406238563035

Epoch: 5| Step: 8
Training loss: 2.189235217014997
Validation loss: 2.5698052100291706

Epoch: 5| Step: 9
Training loss: 2.3069374610549698
Validation loss: 2.564924831106512

Epoch: 5| Step: 10
Training loss: 2.876771298299913
Validation loss: 2.4477445937721347

Epoch: 365| Step: 0
Training loss: 2.1410772583735653
Validation loss: 2.503027155847327

Epoch: 5| Step: 1
Training loss: 1.9206901557613285
Validation loss: 2.534753854437803

Epoch: 5| Step: 2
Training loss: 2.407720933642293
Validation loss: 2.5561950155374484

Epoch: 5| Step: 3
Training loss: 2.817405660923383
Validation loss: 2.499937417672409

Epoch: 5| Step: 4
Training loss: 2.3953373160572884
Validation loss: 2.4822625979934547

Epoch: 5| Step: 5
Training loss: 1.8547538584766599
Validation loss: 2.526693023204664

Epoch: 5| Step: 6
Training loss: 2.6522098108555325
Validation loss: 2.5368694588683445

Epoch: 5| Step: 7
Training loss: 2.1215956851006266
Validation loss: 2.5251415242670783

Epoch: 5| Step: 8
Training loss: 2.6193180351279852
Validation loss: 2.5174694480304445

Epoch: 5| Step: 9
Training loss: 2.713081589329312
Validation loss: 2.552559595493717

Epoch: 5| Step: 10
Training loss: 2.24985249353725
Validation loss: 2.571257271149957

Epoch: 366| Step: 0
Training loss: 2.08739292075724
Validation loss: 2.483424231732178

Epoch: 5| Step: 1
Training loss: 2.299410711344496
Validation loss: 2.5232244521203984

Epoch: 5| Step: 2
Training loss: 2.5940657274129406
Validation loss: 2.5271685028014423

Epoch: 5| Step: 3
Training loss: 2.9465248587592354
Validation loss: 2.5124471581018915

Epoch: 5| Step: 4
Training loss: 2.0333085412978993
Validation loss: 2.539969412335497

Epoch: 5| Step: 5
Training loss: 2.1224275613921275
Validation loss: 2.5022895849770714

Epoch: 5| Step: 6
Training loss: 2.882544528322793
Validation loss: 2.5348773095418657

Epoch: 5| Step: 7
Training loss: 1.9414496618440786
Validation loss: 2.5400827079402672

Epoch: 5| Step: 8
Training loss: 2.5401304845259363
Validation loss: 2.5333708863019773

Epoch: 5| Step: 9
Training loss: 2.1538573549052735
Validation loss: 2.5233760861697605

Epoch: 5| Step: 10
Training loss: 2.4945895777477047
Validation loss: 2.5567991248835837

Epoch: 367| Step: 0
Training loss: 2.3390864450659907
Validation loss: 2.560967564163756

Epoch: 5| Step: 1
Training loss: 2.1646864229191056
Validation loss: 2.520339334347335

Epoch: 5| Step: 2
Training loss: 2.945568609865471
Validation loss: 2.5023165685857656

Epoch: 5| Step: 3
Training loss: 1.8558343466915979
Validation loss: 2.5524670297177177

Epoch: 5| Step: 4
Training loss: 2.079539455816388
Validation loss: 2.4929507597598994

Epoch: 5| Step: 5
Training loss: 1.876249977533695
Validation loss: 2.529551661582415

Epoch: 5| Step: 6
Training loss: 2.7012649045689248
Validation loss: 2.5457025916279994

Epoch: 5| Step: 7
Training loss: 2.2469716355044893
Validation loss: 2.5313855095305695

Epoch: 5| Step: 8
Training loss: 2.4790872406190836
Validation loss: 2.5363782861763235

Epoch: 5| Step: 9
Training loss: 2.3834088689220527
Validation loss: 2.4872698808474625

Epoch: 5| Step: 10
Training loss: 2.5995933251347614
Validation loss: 2.4961791075833273

Epoch: 368| Step: 0
Training loss: 2.536560798053234
Validation loss: 2.509440260811789

Epoch: 5| Step: 1
Training loss: 1.9406191421887236
Validation loss: 2.5810828882853043

Epoch: 5| Step: 2
Training loss: 2.7834212154136053
Validation loss: 2.5495947951202695

Epoch: 5| Step: 3
Training loss: 2.2449190202478806
Validation loss: 2.5581098176360086

Epoch: 5| Step: 4
Training loss: 2.213463839490424
Validation loss: 2.586924953604457

Epoch: 5| Step: 5
Training loss: 2.1638691399189565
Validation loss: 2.5284085998506187

Epoch: 5| Step: 6
Training loss: 2.6199259992151545
Validation loss: 2.5556446625651743

Epoch: 5| Step: 7
Training loss: 2.2876816057335048
Validation loss: 2.5146900972968917

Epoch: 5| Step: 8
Training loss: 2.4114258820977836
Validation loss: 2.4997791474731996

Epoch: 5| Step: 9
Training loss: 2.0850262312302483
Validation loss: 2.557944579825547

Epoch: 5| Step: 10
Training loss: 2.794556322590514
Validation loss: 2.4995646723253553

Epoch: 369| Step: 0
Training loss: 2.8965856183313017
Validation loss: 2.527504554683492

Epoch: 5| Step: 1
Training loss: 2.4277805314774636
Validation loss: 2.56861824444458

Epoch: 5| Step: 2
Training loss: 1.9988181675492769
Validation loss: 2.56130998032854

Epoch: 5| Step: 3
Training loss: 2.203626643215776
Validation loss: 2.563111191079765

Epoch: 5| Step: 4
Training loss: 2.8312834074563082
Validation loss: 2.538885623144454

Epoch: 5| Step: 5
Training loss: 2.2411361515640706
Validation loss: 2.5395439626685223

Epoch: 5| Step: 6
Training loss: 2.1001903493079896
Validation loss: 2.539023659332523

Epoch: 5| Step: 7
Training loss: 2.289265698472308
Validation loss: 2.545603898160449

Epoch: 5| Step: 8
Training loss: 2.839216370262747
Validation loss: 2.494049568861196

Epoch: 5| Step: 9
Training loss: 1.980039772058098
Validation loss: 2.5653555281799103

Epoch: 5| Step: 10
Training loss: 1.9885949747311544
Validation loss: 2.5312366513095625

Epoch: 370| Step: 0
Training loss: 2.539579462095903
Validation loss: 2.579446167081276

Epoch: 5| Step: 1
Training loss: 2.1563859979615407
Validation loss: 2.5110194883596186

Epoch: 5| Step: 2
Training loss: 2.707880588738623
Validation loss: 2.540103575613546

Epoch: 5| Step: 3
Training loss: 1.7234773992656298
Validation loss: 2.5263808287981417

Epoch: 5| Step: 4
Training loss: 3.399984774835942
Validation loss: 2.4956293560723197

Epoch: 5| Step: 5
Training loss: 2.1044740609718198
Validation loss: 2.5413647332300124

Epoch: 5| Step: 6
Training loss: 2.331575333135975
Validation loss: 2.510027439676848

Epoch: 5| Step: 7
Training loss: 1.6779386420461142
Validation loss: 2.5504773003507095

Epoch: 5| Step: 8
Training loss: 2.3762206905831
Validation loss: 2.5196083554991793

Epoch: 5| Step: 9
Training loss: 2.491055892372417
Validation loss: 2.4938007422872137

Epoch: 5| Step: 10
Training loss: 1.943834654997654
Validation loss: 2.554647861261126

Epoch: 371| Step: 0
Training loss: 2.1601149708561564
Validation loss: 2.541272122850178

Epoch: 5| Step: 1
Training loss: 2.034744543214243
Validation loss: 2.5290340658111403

Epoch: 5| Step: 2
Training loss: 2.010419763223375
Validation loss: 2.6097053386032334

Epoch: 5| Step: 3
Training loss: 2.78432979868153
Validation loss: 2.5842605604566535

Epoch: 5| Step: 4
Training loss: 2.165801853813712
Validation loss: 2.5393251950508726

Epoch: 5| Step: 5
Training loss: 2.84701719295347
Validation loss: 2.521682167856578

Epoch: 5| Step: 6
Training loss: 2.427182196921612
Validation loss: 2.5480475440293926

Epoch: 5| Step: 7
Training loss: 1.8153907480316573
Validation loss: 2.529751762534568

Epoch: 5| Step: 8
Training loss: 2.8327915197185716
Validation loss: 2.5409961187766594

Epoch: 5| Step: 9
Training loss: 2.1313063225337676
Validation loss: 2.5316880349850366

Epoch: 5| Step: 10
Training loss: 2.5680835648306637
Validation loss: 2.5266066692021356

Epoch: 372| Step: 0
Training loss: 2.763106843051304
Validation loss: 2.5544790565681477

Epoch: 5| Step: 1
Training loss: 2.1896643694089692
Validation loss: 2.5462551493804106

Epoch: 5| Step: 2
Training loss: 2.317542275184128
Validation loss: 2.549737343158593

Epoch: 5| Step: 3
Training loss: 2.94576933780925
Validation loss: 2.5375163100970353

Epoch: 5| Step: 4
Training loss: 1.980479704997746
Validation loss: 2.5199525491547785

Epoch: 5| Step: 5
Training loss: 2.190211985531296
Validation loss: 2.536878365865437

Epoch: 5| Step: 6
Training loss: 2.2843880168997934
Validation loss: 2.5044275465251733

Epoch: 5| Step: 7
Training loss: 2.6244702485822464
Validation loss: 2.564356691748693

Epoch: 5| Step: 8
Training loss: 2.352266124000713
Validation loss: 2.5770822076092625

Epoch: 5| Step: 9
Training loss: 1.7993767613054183
Validation loss: 2.543063008318001

Epoch: 5| Step: 10
Training loss: 2.0922869224941496
Validation loss: 2.516868354869283

Epoch: 373| Step: 0
Training loss: 2.4265981579461617
Validation loss: 2.5394831241008595

Epoch: 5| Step: 1
Training loss: 1.9835097461535038
Validation loss: 2.569731172990829

Epoch: 5| Step: 2
Training loss: 2.1632607417376124
Validation loss: 2.5569169225402817

Epoch: 5| Step: 3
Training loss: 2.707839118663795
Validation loss: 2.5107350920825424

Epoch: 5| Step: 4
Training loss: 2.1708018993169045
Validation loss: 2.583506655427796

Epoch: 5| Step: 5
Training loss: 2.2927514254310077
Validation loss: 2.578691872542023

Epoch: 5| Step: 6
Training loss: 2.4027781024067782
Validation loss: 2.5654431810479355

Epoch: 5| Step: 7
Training loss: 2.2548884164138356
Validation loss: 2.559932268630101

Epoch: 5| Step: 8
Training loss: 3.048735221898922
Validation loss: 2.5261904203414245

Epoch: 5| Step: 9
Training loss: 2.557418623270042
Validation loss: 2.5548642130537265

Epoch: 5| Step: 10
Training loss: 2.247790523333055
Validation loss: 2.54783308865584

Epoch: 374| Step: 0
Training loss: 2.6037755036627335
Validation loss: 2.5345087913850586

Epoch: 5| Step: 1
Training loss: 2.328841950284892
Validation loss: 2.5490844743493004

Epoch: 5| Step: 2
Training loss: 2.494141580914558
Validation loss: 2.5192345274920194

Epoch: 5| Step: 3
Training loss: 2.392193846691042
Validation loss: 2.5553120596037093

Epoch: 5| Step: 4
Training loss: 2.275973449196843
Validation loss: 2.5723990376813592

Epoch: 5| Step: 5
Training loss: 2.494575910589583
Validation loss: 2.56260125805281

Epoch: 5| Step: 6
Training loss: 2.0901468502819145
Validation loss: 2.5459270956745628

Epoch: 5| Step: 7
Training loss: 2.1101915827550295
Validation loss: 2.4953158513814224

Epoch: 5| Step: 8
Training loss: 2.5296593837106243
Validation loss: 2.5507201256677505

Epoch: 5| Step: 9
Training loss: 1.9892238338753974
Validation loss: 2.529387043352835

Epoch: 5| Step: 10
Training loss: 2.673559093106924
Validation loss: 2.565410894545894

Epoch: 375| Step: 0
Training loss: 1.9363064935371317
Validation loss: 2.5765732177952434

Epoch: 5| Step: 1
Training loss: 3.2223751061077435
Validation loss: 2.523462162642108

Epoch: 5| Step: 2
Training loss: 1.8240639990571192
Validation loss: 2.573622351492017

Epoch: 5| Step: 3
Training loss: 2.426205903506988
Validation loss: 2.5184336174194493

Epoch: 5| Step: 4
Training loss: 1.7453624038596927
Validation loss: 2.5317485576100727

Epoch: 5| Step: 5
Training loss: 1.9776564876402243
Validation loss: 2.496589979648451

Epoch: 5| Step: 6
Training loss: 2.405958480020087
Validation loss: 2.506426606947224

Epoch: 5| Step: 7
Training loss: 2.2432162486787095
Validation loss: 2.5285268801445318

Epoch: 5| Step: 8
Training loss: 2.6374437479827306
Validation loss: 2.545038834325977

Epoch: 5| Step: 9
Training loss: 2.2720597014978305
Validation loss: 2.5277959910923613

Epoch: 5| Step: 10
Training loss: 2.653640991645766
Validation loss: 2.486104249749021

Epoch: 376| Step: 0
Training loss: 1.802882162630418
Validation loss: 2.5415253422577355

Epoch: 5| Step: 1
Training loss: 3.0721299710793653
Validation loss: 2.56052947093798

Epoch: 5| Step: 2
Training loss: 2.2232329520461236
Validation loss: 2.5227443411411272

Epoch: 5| Step: 3
Training loss: 2.6793059586247097
Validation loss: 2.5327817919879663

Epoch: 5| Step: 4
Training loss: 2.1145642910806193
Validation loss: 2.5170537424658037

Epoch: 5| Step: 5
Training loss: 2.3882096998323945
Validation loss: 2.50351324358768

Epoch: 5| Step: 6
Training loss: 2.062922001061746
Validation loss: 2.5345679054441352

Epoch: 5| Step: 7
Training loss: 2.083476125274154
Validation loss: 2.5229582516082374

Epoch: 5| Step: 8
Training loss: 2.262491940647334
Validation loss: 2.48891563556195

Epoch: 5| Step: 9
Training loss: 2.3894209478711548
Validation loss: 2.5452444198130175

Epoch: 5| Step: 10
Training loss: 2.49409215965172
Validation loss: 2.496589071393362

Epoch: 377| Step: 0
Training loss: 1.9932118493743223
Validation loss: 2.580525201462757

Epoch: 5| Step: 1
Training loss: 2.38968116229636
Validation loss: 2.56289346486925

Epoch: 5| Step: 2
Training loss: 2.256476300585712
Validation loss: 2.4992235711053232

Epoch: 5| Step: 3
Training loss: 2.4089744304156664
Validation loss: 2.5488527300479227

Epoch: 5| Step: 4
Training loss: 2.7180074795921096
Validation loss: 2.5532066586900983

Epoch: 5| Step: 5
Training loss: 1.9659861586113572
Validation loss: 2.5685506018881497

Epoch: 5| Step: 6
Training loss: 2.4639888193632333
Validation loss: 2.5968270560445457

Epoch: 5| Step: 7
Training loss: 2.9746369468929
Validation loss: 2.578669811965635

Epoch: 5| Step: 8
Training loss: 2.523712615614333
Validation loss: 2.5428986114794228

Epoch: 5| Step: 9
Training loss: 2.472226266702875
Validation loss: 2.4803942323498105

Epoch: 5| Step: 10
Training loss: 1.5851652774017913
Validation loss: 2.5724326316909347

Epoch: 378| Step: 0
Training loss: 2.4548683532099633
Validation loss: 2.5559214494191447

Epoch: 5| Step: 1
Training loss: 1.9339741034130005
Validation loss: 2.5242297415569674

Epoch: 5| Step: 2
Training loss: 2.338418618910666
Validation loss: 2.497593418683233

Epoch: 5| Step: 3
Training loss: 2.0522961062450857
Validation loss: 2.543877077371441

Epoch: 5| Step: 4
Training loss: 2.193959970016915
Validation loss: 2.5555124532965348

Epoch: 5| Step: 5
Training loss: 2.025130340714173
Validation loss: 2.5610764974325373

Epoch: 5| Step: 6
Training loss: 2.641404979110904
Validation loss: 2.5577172275991

Epoch: 5| Step: 7
Training loss: 2.5918987055812766
Validation loss: 2.5334147882913145

Epoch: 5| Step: 8
Training loss: 2.778556719813534
Validation loss: 2.57811442969956

Epoch: 5| Step: 9
Training loss: 1.923144719689411
Validation loss: 2.5726597880950575

Epoch: 5| Step: 10
Training loss: 2.509320432608857
Validation loss: 2.518397797524261

Epoch: 379| Step: 0
Training loss: 2.650225280686741
Validation loss: 2.5494580019996924

Epoch: 5| Step: 1
Training loss: 2.376544550540112
Validation loss: 2.535903199978695

Epoch: 5| Step: 2
Training loss: 2.206366352763063
Validation loss: 2.531595943525161

Epoch: 5| Step: 3
Training loss: 2.0209108580305952
Validation loss: 2.5015705097830643

Epoch: 5| Step: 4
Training loss: 2.5223246385093354
Validation loss: 2.5989317310124314

Epoch: 5| Step: 5
Training loss: 2.687595277028874
Validation loss: 2.537624391200047

Epoch: 5| Step: 6
Training loss: 2.1350097516661304
Validation loss: 2.5977125957582277

Epoch: 5| Step: 7
Training loss: 2.3002427512063894
Validation loss: 2.514729931079636

Epoch: 5| Step: 8
Training loss: 2.204998761650309
Validation loss: 2.5071378514789564

Epoch: 5| Step: 9
Training loss: 2.1437733462650033
Validation loss: 2.5731689367978965

Epoch: 5| Step: 10
Training loss: 2.574744950783373
Validation loss: 2.6059426982949634

Epoch: 380| Step: 0
Training loss: 2.3366414416044954
Validation loss: 2.51127361699441

Epoch: 5| Step: 1
Training loss: 2.2389197379238475
Validation loss: 2.519687201521017

Epoch: 5| Step: 2
Training loss: 2.014046694247402
Validation loss: 2.487028055473432

Epoch: 5| Step: 3
Training loss: 1.9315058368986704
Validation loss: 2.509354706600958

Epoch: 5| Step: 4
Training loss: 1.9573994973448345
Validation loss: 2.4754025842125165

Epoch: 5| Step: 5
Training loss: 2.8997419768678845
Validation loss: 2.5493712249610376

Epoch: 5| Step: 6
Training loss: 2.2535919552110673
Validation loss: 2.5266043628843797

Epoch: 5| Step: 7
Training loss: 1.9740155361882101
Validation loss: 2.537518628218392

Epoch: 5| Step: 8
Training loss: 2.5450888144953674
Validation loss: 2.531601352125235

Epoch: 5| Step: 9
Training loss: 2.894637503584973
Validation loss: 2.538619414763035

Epoch: 5| Step: 10
Training loss: 2.580559800355192
Validation loss: 2.5585985093650585

Epoch: 381| Step: 0
Training loss: 2.2177984856921578
Validation loss: 2.537345657411215

Epoch: 5| Step: 1
Training loss: 2.110864184254903
Validation loss: 2.5318952330792035

Epoch: 5| Step: 2
Training loss: 2.1030108484631413
Validation loss: 2.544730305069262

Epoch: 5| Step: 3
Training loss: 2.0255020979072595
Validation loss: 2.5148371703123713

Epoch: 5| Step: 4
Training loss: 2.5405071198352975
Validation loss: 2.5397586950298945

Epoch: 5| Step: 5
Training loss: 2.2208216492117105
Validation loss: 2.554862440986581

Epoch: 5| Step: 6
Training loss: 2.036047566410959
Validation loss: 2.4774606042262

Epoch: 5| Step: 7
Training loss: 2.4745447260263322
Validation loss: 2.5530320661560792

Epoch: 5| Step: 8
Training loss: 2.6756142668585636
Validation loss: 2.5797243489228485

Epoch: 5| Step: 9
Training loss: 2.8990142330729545
Validation loss: 2.531910651963925

Epoch: 5| Step: 10
Training loss: 2.1776657298948447
Validation loss: 2.5151564087071145

Epoch: 382| Step: 0
Training loss: 2.223827730463912
Validation loss: 2.583264098064968

Epoch: 5| Step: 1
Training loss: 2.433003508628388
Validation loss: 2.553088495042717

Epoch: 5| Step: 2
Training loss: 2.305550313532537
Validation loss: 2.5322701968102352

Epoch: 5| Step: 3
Training loss: 3.253608167900599
Validation loss: 2.559422479521393

Epoch: 5| Step: 4
Training loss: 2.1734078027491255
Validation loss: 2.5177372043409054

Epoch: 5| Step: 5
Training loss: 2.232421554605456
Validation loss: 2.5039509808661413

Epoch: 5| Step: 6
Training loss: 2.3563995799540693
Validation loss: 2.543587542949651

Epoch: 5| Step: 7
Training loss: 2.336465527107728
Validation loss: 2.5401905885116456

Epoch: 5| Step: 8
Training loss: 2.275993980996431
Validation loss: 2.570431796754988

Epoch: 5| Step: 9
Training loss: 1.9907305607137036
Validation loss: 2.540227023025294

Epoch: 5| Step: 10
Training loss: 2.1089891999258916
Validation loss: 2.5915762763246923

Epoch: 383| Step: 0
Training loss: 2.7214473629314497
Validation loss: 2.5134336200228384

Epoch: 5| Step: 1
Training loss: 1.7917637983503796
Validation loss: 2.5106629860244523

Epoch: 5| Step: 2
Training loss: 1.8788980019878085
Validation loss: 2.5187219313094684

Epoch: 5| Step: 3
Training loss: 2.154829580202192
Validation loss: 2.576476217290427

Epoch: 5| Step: 4
Training loss: 2.664139822008398
Validation loss: 2.5310400426705315

Epoch: 5| Step: 5
Training loss: 2.3388996034418557
Validation loss: 2.5197158006922247

Epoch: 5| Step: 6
Training loss: 2.0980956116482576
Validation loss: 2.512673344859301

Epoch: 5| Step: 7
Training loss: 2.3390592301115882
Validation loss: 2.514465750774411

Epoch: 5| Step: 8
Training loss: 2.2914291489943213
Validation loss: 2.5255509074341496

Epoch: 5| Step: 9
Training loss: 2.8611614712559668
Validation loss: 2.525682304318464

Epoch: 5| Step: 10
Training loss: 2.2585342468002843
Validation loss: 2.5394411724417965

Epoch: 384| Step: 0
Training loss: 1.8428578562117301
Validation loss: 2.5499840819135247

Epoch: 5| Step: 1
Training loss: 2.540349921505667
Validation loss: 2.509547258723952

Epoch: 5| Step: 2
Training loss: 2.034076074533533
Validation loss: 2.536819822048365

Epoch: 5| Step: 3
Training loss: 2.170931823995409
Validation loss: 2.567194007148929

Epoch: 5| Step: 4
Training loss: 2.1352575351379808
Validation loss: 2.521830970961387

Epoch: 5| Step: 5
Training loss: 2.5528391646553343
Validation loss: 2.50750902734568

Epoch: 5| Step: 6
Training loss: 3.0532480736313095
Validation loss: 2.5381234047040975

Epoch: 5| Step: 7
Training loss: 2.5456100786363245
Validation loss: 2.541977588175662

Epoch: 5| Step: 8
Training loss: 2.2619197670479507
Validation loss: 2.545818547359184

Epoch: 5| Step: 9
Training loss: 2.152694424345205
Validation loss: 2.538068798599961

Epoch: 5| Step: 10
Training loss: 2.2466548848998777
Validation loss: 2.5338059867537206

Epoch: 385| Step: 0
Training loss: 1.9769021447314357
Validation loss: 2.5782507593849724

Epoch: 5| Step: 1
Training loss: 2.5343056590499167
Validation loss: 2.5356707236489284

Epoch: 5| Step: 2
Training loss: 1.585934042339596
Validation loss: 2.5710044338674227

Epoch: 5| Step: 3
Training loss: 2.169672995508813
Validation loss: 2.524362840230185

Epoch: 5| Step: 4
Training loss: 2.8079987852088495
Validation loss: 2.5437566980194792

Epoch: 5| Step: 5
Training loss: 2.1769775170219696
Validation loss: 2.524891294261163

Epoch: 5| Step: 6
Training loss: 2.4436987283698905
Validation loss: 2.555516438930136

Epoch: 5| Step: 7
Training loss: 2.3725139254934113
Validation loss: 2.488601325792825

Epoch: 5| Step: 8
Training loss: 2.235630776235505
Validation loss: 2.5021463256025704

Epoch: 5| Step: 9
Training loss: 2.470419982849596
Validation loss: 2.520328281637152

Epoch: 5| Step: 10
Training loss: 2.435050614005248
Validation loss: 2.5476141181201073

Epoch: 386| Step: 0
Training loss: 2.348062438862492
Validation loss: 2.5771193227401117

Epoch: 5| Step: 1
Training loss: 1.8708973186173774
Validation loss: 2.544556479980203

Epoch: 5| Step: 2
Training loss: 2.5466447971896233
Validation loss: 2.5317076184943903

Epoch: 5| Step: 3
Training loss: 1.923973550479883
Validation loss: 2.551384344220514

Epoch: 5| Step: 4
Training loss: 2.1328854950091802
Validation loss: 2.5327735472316077

Epoch: 5| Step: 5
Training loss: 2.8477046423464465
Validation loss: 2.543779400502433

Epoch: 5| Step: 6
Training loss: 2.2137555067703625
Validation loss: 2.5659879111646537

Epoch: 5| Step: 7
Training loss: 2.66278582547601
Validation loss: 2.53923097062603

Epoch: 5| Step: 8
Training loss: 1.9665016778608506
Validation loss: 2.5137806865728485

Epoch: 5| Step: 9
Training loss: 2.11382925434296
Validation loss: 2.5358429003548024

Epoch: 5| Step: 10
Training loss: 2.772998012053654
Validation loss: 2.5063876860346346

Epoch: 387| Step: 0
Training loss: 2.5772165258389
Validation loss: 2.5436575757980946

Epoch: 5| Step: 1
Training loss: 2.397537509915162
Validation loss: 2.564138685371154

Epoch: 5| Step: 2
Training loss: 2.838418175113809
Validation loss: 2.5471699630234235

Epoch: 5| Step: 3
Training loss: 2.5410183460124265
Validation loss: 2.562516473276496

Epoch: 5| Step: 4
Training loss: 2.1979311058208943
Validation loss: 2.538235121241975

Epoch: 5| Step: 5
Training loss: 1.9760564224048836
Validation loss: 2.544783806154141

Epoch: 5| Step: 6
Training loss: 1.9862375004292845
Validation loss: 2.508047159414037

Epoch: 5| Step: 7
Training loss: 2.3704009450104007
Validation loss: 2.5484870395452806

Epoch: 5| Step: 8
Training loss: 2.152985022082146
Validation loss: 2.528883748268638

Epoch: 5| Step: 9
Training loss: 2.1655402801368115
Validation loss: 2.5845763371474293

Epoch: 5| Step: 10
Training loss: 1.876239430539466
Validation loss: 2.600385270511422

Epoch: 388| Step: 0
Training loss: 2.133815878693051
Validation loss: 2.5208816571147667

Epoch: 5| Step: 1
Training loss: 2.908107041205731
Validation loss: 2.529207474793118

Epoch: 5| Step: 2
Training loss: 2.88528229071173
Validation loss: 2.5791063704991792

Epoch: 5| Step: 3
Training loss: 1.5981826474649896
Validation loss: 2.544559702970639

Epoch: 5| Step: 4
Training loss: 1.9324258379011696
Validation loss: 2.5494188682040932

Epoch: 5| Step: 5
Training loss: 2.150439629962166
Validation loss: 2.519941542563159

Epoch: 5| Step: 6
Training loss: 2.3334693755499853
Validation loss: 2.528587414559561

Epoch: 5| Step: 7
Training loss: 2.6142625548612197
Validation loss: 2.538433293456445

Epoch: 5| Step: 8
Training loss: 2.7397678056888974
Validation loss: 2.489419374041023

Epoch: 5| Step: 9
Training loss: 1.5183518252762842
Validation loss: 2.5311583939554003

Epoch: 5| Step: 10
Training loss: 2.068436604067523
Validation loss: 2.559870281214426

Epoch: 389| Step: 0
Training loss: 2.2319706071059957
Validation loss: 2.5053282531590026

Epoch: 5| Step: 1
Training loss: 2.2251699275588934
Validation loss: 2.5619066133122628

Epoch: 5| Step: 2
Training loss: 3.3729050810255408
Validation loss: 2.589387490849394

Epoch: 5| Step: 3
Training loss: 2.063459924359093
Validation loss: 2.5797398068963435

Epoch: 5| Step: 4
Training loss: 2.1662607424074
Validation loss: 2.5813340526338444

Epoch: 5| Step: 5
Training loss: 2.139161883790817
Validation loss: 2.550057093306686

Epoch: 5| Step: 6
Training loss: 1.8374123351276312
Validation loss: 2.6067176498634987

Epoch: 5| Step: 7
Training loss: 2.3557511345424307
Validation loss: 2.563972805230797

Epoch: 5| Step: 8
Training loss: 2.460791205039014
Validation loss: 2.5139949457206514

Epoch: 5| Step: 9
Training loss: 2.4161862411020127
Validation loss: 2.588201364817475

Epoch: 5| Step: 10
Training loss: 2.146962384218235
Validation loss: 2.5019506074195754

Epoch: 390| Step: 0
Training loss: 2.180270646819745
Validation loss: 2.524298593088235

Epoch: 5| Step: 1
Training loss: 2.227295871890383
Validation loss: 2.5930766073997

Epoch: 5| Step: 2
Training loss: 2.211251280392308
Validation loss: 2.542440766239956

Epoch: 5| Step: 3
Training loss: 1.9509241750696869
Validation loss: 2.5907393278191493

Epoch: 5| Step: 4
Training loss: 1.97878342649044
Validation loss: 2.570855441503384

Epoch: 5| Step: 5
Training loss: 2.3510216379277318
Validation loss: 2.5303944739996225

Epoch: 5| Step: 6
Training loss: 2.334111651537531
Validation loss: 2.5462419458055567

Epoch: 5| Step: 7
Training loss: 2.3833900627196036
Validation loss: 2.508056690072095

Epoch: 5| Step: 8
Training loss: 2.39353217585548
Validation loss: 2.541608484638809

Epoch: 5| Step: 9
Training loss: 2.748260901818922
Validation loss: 2.5154684501235787

Epoch: 5| Step: 10
Training loss: 2.4153842702442017
Validation loss: 2.5611895850478286

Epoch: 391| Step: 0
Training loss: 2.6047323807738216
Validation loss: 2.5286184669577523

Epoch: 5| Step: 1
Training loss: 2.466713946980482
Validation loss: 2.5204017615164958

Epoch: 5| Step: 2
Training loss: 1.8805058068751508
Validation loss: 2.5698324862950854

Epoch: 5| Step: 3
Training loss: 2.3537651214681117
Validation loss: 2.5463410686071417

Epoch: 5| Step: 4
Training loss: 2.255548417759184
Validation loss: 2.479335785003588

Epoch: 5| Step: 5
Training loss: 2.485998810612094
Validation loss: 2.591691156912676

Epoch: 5| Step: 6
Training loss: 1.995958835051182
Validation loss: 2.526097927517804

Epoch: 5| Step: 7
Training loss: 2.262301407839395
Validation loss: 2.511056914289008

Epoch: 5| Step: 8
Training loss: 2.2298311568177174
Validation loss: 2.5568205660132195

Epoch: 5| Step: 9
Training loss: 2.232003507351598
Validation loss: 2.5240072728893703

Epoch: 5| Step: 10
Training loss: 2.549546414593391
Validation loss: 2.5494876287302026

Epoch: 392| Step: 0
Training loss: 1.8751069356306187
Validation loss: 2.547651096019578

Epoch: 5| Step: 1
Training loss: 2.0049551139240243
Validation loss: 2.5507647853594384

Epoch: 5| Step: 2
Training loss: 2.704904400586959
Validation loss: 2.580044546080599

Epoch: 5| Step: 3
Training loss: 1.9979503380805739
Validation loss: 2.582226232849882

Epoch: 5| Step: 4
Training loss: 2.470911841943771
Validation loss: 2.5236407472767546

Epoch: 5| Step: 5
Training loss: 2.3702152642138135
Validation loss: 2.562920482601175

Epoch: 5| Step: 6
Training loss: 2.998900052920201
Validation loss: 2.539545967512056

Epoch: 5| Step: 7
Training loss: 2.390936239090401
Validation loss: 2.546522974664044

Epoch: 5| Step: 8
Training loss: 2.020669937082478
Validation loss: 2.5151950063857154

Epoch: 5| Step: 9
Training loss: 2.0337861880486625
Validation loss: 2.570338881207275

Epoch: 5| Step: 10
Training loss: 2.233073675898802
Validation loss: 2.543401926315292

Epoch: 393| Step: 0
Training loss: 2.5233560554895695
Validation loss: 2.5488459443971214

Epoch: 5| Step: 1
Training loss: 2.0342471971814837
Validation loss: 2.5764301967918253

Epoch: 5| Step: 2
Training loss: 2.7350529293538703
Validation loss: 2.5528915638952596

Epoch: 5| Step: 3
Training loss: 2.3268485442324414
Validation loss: 2.556874015648435

Epoch: 5| Step: 4
Training loss: 2.5151416006098275
Validation loss: 2.536256389500806

Epoch: 5| Step: 5
Training loss: 1.8321790818553412
Validation loss: 2.527960452302308

Epoch: 5| Step: 6
Training loss: 2.3717242287222504
Validation loss: 2.5339688974688013

Epoch: 5| Step: 7
Training loss: 2.156821133812277
Validation loss: 2.5039690904505254

Epoch: 5| Step: 8
Training loss: 2.495832689271397
Validation loss: 2.534302356507783

Epoch: 5| Step: 9
Training loss: 2.2020302074692193
Validation loss: 2.5164768287834596

Epoch: 5| Step: 10
Training loss: 1.600404572001293
Validation loss: 2.553597470499506

Epoch: 394| Step: 0
Training loss: 2.8278451011785926
Validation loss: 2.566160986853812

Epoch: 5| Step: 1
Training loss: 1.9420388493998066
Validation loss: 2.5773545124104142

Epoch: 5| Step: 2
Training loss: 2.1997287626389097
Validation loss: 2.49378514225644

Epoch: 5| Step: 3
Training loss: 2.1283119422038763
Validation loss: 2.52717877289029

Epoch: 5| Step: 4
Training loss: 1.4880757828303528
Validation loss: 2.5102473165130528

Epoch: 5| Step: 5
Training loss: 2.492462238725917
Validation loss: 2.5491762226475676

Epoch: 5| Step: 6
Training loss: 1.8529195842143786
Validation loss: 2.5397404055868784

Epoch: 5| Step: 7
Training loss: 2.362793523729657
Validation loss: 2.5485823370746252

Epoch: 5| Step: 8
Training loss: 2.250041855316805
Validation loss: 2.544575192208768

Epoch: 5| Step: 9
Training loss: 2.6233509878738324
Validation loss: 2.5191603352981713

Epoch: 5| Step: 10
Training loss: 2.299398994704252
Validation loss: 2.538466374516993

Epoch: 395| Step: 0
Training loss: 2.707671382900728
Validation loss: 2.5057194345985625

Epoch: 5| Step: 1
Training loss: 2.213873218314459
Validation loss: 2.578907047212743

Epoch: 5| Step: 2
Training loss: 2.154705212958036
Validation loss: 2.575486660798267

Epoch: 5| Step: 3
Training loss: 2.0853107096468437
Validation loss: 2.5583506729448513

Epoch: 5| Step: 4
Training loss: 2.1984539972159425
Validation loss: 2.518765211271885

Epoch: 5| Step: 5
Training loss: 1.631296357413281
Validation loss: 2.5597686176817707

Epoch: 5| Step: 6
Training loss: 2.6567068268130853
Validation loss: 2.5190497664961016

Epoch: 5| Step: 7
Training loss: 2.0166346660418535
Validation loss: 2.594930471847866

Epoch: 5| Step: 8
Training loss: 2.502903682530484
Validation loss: 2.510227011537951

Epoch: 5| Step: 9
Training loss: 2.3532373287549126
Validation loss: 2.51854487185655

Epoch: 5| Step: 10
Training loss: 2.6975142621926333
Validation loss: 2.5386209275272194

Epoch: 396| Step: 0
Training loss: 2.7873969567929806
Validation loss: 2.577456957347073

Epoch: 5| Step: 1
Training loss: 1.9611525702604353
Validation loss: 2.495401448747814

Epoch: 5| Step: 2
Training loss: 2.244373173363712
Validation loss: 2.554974255413362

Epoch: 5| Step: 3
Training loss: 1.9010908634317192
Validation loss: 2.5561919235554944

Epoch: 5| Step: 4
Training loss: 1.952642396430699
Validation loss: 2.560926118614057

Epoch: 5| Step: 5
Training loss: 2.3246009320102723
Validation loss: 2.5746171621104046

Epoch: 5| Step: 6
Training loss: 2.4074565290129155
Validation loss: 2.51316012320008

Epoch: 5| Step: 7
Training loss: 2.015856825633973
Validation loss: 2.5228642085145494

Epoch: 5| Step: 8
Training loss: 1.7903114190733422
Validation loss: 2.528529772762604

Epoch: 5| Step: 9
Training loss: 2.8827324419354476
Validation loss: 2.5287489684307416

Epoch: 5| Step: 10
Training loss: 2.2496660832475786
Validation loss: 2.595550113096062

Epoch: 397| Step: 0
Training loss: 1.9920107295578466
Validation loss: 2.5612575120917387

Epoch: 5| Step: 1
Training loss: 2.2771605324695945
Validation loss: 2.5155321105467348

Epoch: 5| Step: 2
Training loss: 2.4486662562461956
Validation loss: 2.531090985986172

Epoch: 5| Step: 3
Training loss: 2.0891252369900797
Validation loss: 2.5154127514097433

Epoch: 5| Step: 4
Training loss: 1.8664723068050897
Validation loss: 2.6052067139631467

Epoch: 5| Step: 5
Training loss: 1.5390954958094534
Validation loss: 2.5830302042424496

Epoch: 5| Step: 6
Training loss: 2.4460154732552395
Validation loss: 2.5187360659295583

Epoch: 5| Step: 7
Training loss: 2.23637524684252
Validation loss: 2.545272164755509

Epoch: 5| Step: 8
Training loss: 2.0792374465708363
Validation loss: 2.5451329746808193

Epoch: 5| Step: 9
Training loss: 3.3381903230910472
Validation loss: 2.542086581867486

Epoch: 5| Step: 10
Training loss: 1.9113992028787452
Validation loss: 2.541908029453091

Epoch: 398| Step: 0
Training loss: 2.5746813345454593
Validation loss: 2.519546795423697

Epoch: 5| Step: 1
Training loss: 2.4779527294031447
Validation loss: 2.5512965067812003

Epoch: 5| Step: 2
Training loss: 2.449989404460806
Validation loss: 2.547447062333233

Epoch: 5| Step: 3
Training loss: 2.376231727429509
Validation loss: 2.513776975391834

Epoch: 5| Step: 4
Training loss: 2.0718146866294878
Validation loss: 2.5354813333614663

Epoch: 5| Step: 5
Training loss: 1.8038227602214605
Validation loss: 2.560206842103316

Epoch: 5| Step: 6
Training loss: 2.761246831088236
Validation loss: 2.561619324895952

Epoch: 5| Step: 7
Training loss: 1.3595276670120457
Validation loss: 2.508570213676403

Epoch: 5| Step: 8
Training loss: 1.9816526828055379
Validation loss: 2.55386967943728

Epoch: 5| Step: 9
Training loss: 2.9640460844897474
Validation loss: 2.5305649055486015

Epoch: 5| Step: 10
Training loss: 1.9415852945765022
Validation loss: 2.5747324728009287

Epoch: 399| Step: 0
Training loss: 1.8194068325642816
Validation loss: 2.5282027896459387

Epoch: 5| Step: 1
Training loss: 2.5602855883682873
Validation loss: 2.54970886103438

Epoch: 5| Step: 2
Training loss: 1.8107763184116459
Validation loss: 2.5651101865562973

Epoch: 5| Step: 3
Training loss: 2.1231086392090908
Validation loss: 2.481930589498267

Epoch: 5| Step: 4
Training loss: 2.1029771772698047
Validation loss: 2.605020265205752

Epoch: 5| Step: 5
Training loss: 2.4446022050214835
Validation loss: 2.5643286204356674

Epoch: 5| Step: 6
Training loss: 2.343379894280579
Validation loss: 2.5061310712982094

Epoch: 5| Step: 7
Training loss: 2.4502730587194517
Validation loss: 2.5600157530329404

Epoch: 5| Step: 8
Training loss: 2.6236673332810923
Validation loss: 2.55769208137428

Epoch: 5| Step: 9
Training loss: 2.5792551973480395
Validation loss: 2.5058952820486016

Epoch: 5| Step: 10
Training loss: 2.0110895746997
Validation loss: 2.53442075952655

Epoch: 400| Step: 0
Training loss: 2.0650063515997275
Validation loss: 2.4998183871516484

Epoch: 5| Step: 1
Training loss: 2.0616518068304894
Validation loss: 2.5230438972879297

Epoch: 5| Step: 2
Training loss: 2.577115410307271
Validation loss: 2.523985475818425

Epoch: 5| Step: 3
Training loss: 2.19335524438892
Validation loss: 2.47834232216754

Epoch: 5| Step: 4
Training loss: 2.808184046036437
Validation loss: 2.564494724478449

Epoch: 5| Step: 5
Training loss: 1.7621939075432627
Validation loss: 2.453675660195633

Epoch: 5| Step: 6
Training loss: 2.2983589828015254
Validation loss: 2.5372948012810923

Epoch: 5| Step: 7
Training loss: 2.104058240860413
Validation loss: 2.5546615683062455

Epoch: 5| Step: 8
Training loss: 2.1823802435355457
Validation loss: 2.493990751053169

Epoch: 5| Step: 9
Training loss: 2.5895791587478816
Validation loss: 2.5014786644040745

Epoch: 5| Step: 10
Training loss: 2.125791402313765
Validation loss: 2.6025921445304316

Epoch: 401| Step: 0
Training loss: 2.7356279390845266
Validation loss: 2.549608777690751

Epoch: 5| Step: 1
Training loss: 2.221061898995046
Validation loss: 2.5193235580898174

Epoch: 5| Step: 2
Training loss: 1.6733379202598735
Validation loss: 2.550124131635168

Epoch: 5| Step: 3
Training loss: 1.6236289916492017
Validation loss: 2.5162276270577677

Epoch: 5| Step: 4
Training loss: 2.3643816443200447
Validation loss: 2.569091143638916

Epoch: 5| Step: 5
Training loss: 2.4795514190197765
Validation loss: 2.5549628387940913

Epoch: 5| Step: 6
Training loss: 2.3061165210171626
Validation loss: 2.5427824822654834

Epoch: 5| Step: 7
Training loss: 2.094063237230962
Validation loss: 2.517605678930366

Epoch: 5| Step: 8
Training loss: 2.474519386251021
Validation loss: 2.51786163940088

Epoch: 5| Step: 9
Training loss: 2.504337172540289
Validation loss: 2.557155833504673

Epoch: 5| Step: 10
Training loss: 2.308531268156953
Validation loss: 2.545429598936483

Epoch: 402| Step: 0
Training loss: 2.740068448318572
Validation loss: 2.5720908909121647

Epoch: 5| Step: 1
Training loss: 2.681295107304232
Validation loss: 2.5169750930290595

Epoch: 5| Step: 2
Training loss: 2.1189260629065605
Validation loss: 2.5368726148228995

Epoch: 5| Step: 3
Training loss: 2.0162168121917463
Validation loss: 2.541063251881208

Epoch: 5| Step: 4
Training loss: 2.65645481890715
Validation loss: 2.5297219117621674

Epoch: 5| Step: 5
Training loss: 2.459639337044145
Validation loss: 2.587570057271729

Epoch: 5| Step: 6
Training loss: 1.8600403052239205
Validation loss: 2.5545089953844693

Epoch: 5| Step: 7
Training loss: 1.6453508160686043
Validation loss: 2.571552836978934

Epoch: 5| Step: 8
Training loss: 2.2885638530375183
Validation loss: 2.526157403816301

Epoch: 5| Step: 9
Training loss: 1.8100571448436338
Validation loss: 2.5006545522540193

Epoch: 5| Step: 10
Training loss: 2.2295352833041893
Validation loss: 2.551335554501631

Epoch: 403| Step: 0
Training loss: 1.929351221351416
Validation loss: 2.6112946455484707

Epoch: 5| Step: 1
Training loss: 2.530282765897268
Validation loss: 2.6002050285810303

Epoch: 5| Step: 2
Training loss: 2.113909559222616
Validation loss: 2.517164119886022

Epoch: 5| Step: 3
Training loss: 2.835871083556386
Validation loss: 2.527445450898226

Epoch: 5| Step: 4
Training loss: 2.100125072932669
Validation loss: 2.519087892357533

Epoch: 5| Step: 5
Training loss: 2.1335722858993353
Validation loss: 2.548755613508927

Epoch: 5| Step: 6
Training loss: 2.1574122295892706
Validation loss: 2.571729105897715

Epoch: 5| Step: 7
Training loss: 2.634042062230937
Validation loss: 2.5279881790470697

Epoch: 5| Step: 8
Training loss: 2.0283457020257343
Validation loss: 2.5566135529368994

Epoch: 5| Step: 9
Training loss: 1.9203061158808965
Validation loss: 2.546091776249871

Epoch: 5| Step: 10
Training loss: 2.494086519638773
Validation loss: 2.5736187973279425

Epoch: 404| Step: 0
Training loss: 2.680118092454501
Validation loss: 2.506889535556004

Epoch: 5| Step: 1
Training loss: 1.6800285525393348
Validation loss: 2.5163286229268937

Epoch: 5| Step: 2
Training loss: 2.863059749596704
Validation loss: 2.579342371905155

Epoch: 5| Step: 3
Training loss: 2.1857575152277886
Validation loss: 2.6011770398227183

Epoch: 5| Step: 4
Training loss: 2.0882507527497416
Validation loss: 2.5718870606729802

Epoch: 5| Step: 5
Training loss: 1.9426100623372213
Validation loss: 2.5374644359579928

Epoch: 5| Step: 6
Training loss: 2.837292056089371
Validation loss: 2.5256618047107726

Epoch: 5| Step: 7
Training loss: 1.990810741340551
Validation loss: 2.5703598583127536

Epoch: 5| Step: 8
Training loss: 2.223581131714426
Validation loss: 2.5571501075142224

Epoch: 5| Step: 9
Training loss: 2.1104387779872518
Validation loss: 2.5500992231872015

Epoch: 5| Step: 10
Training loss: 2.273071993780644
Validation loss: 2.553651658209349

Epoch: 405| Step: 0
Training loss: 2.053986752609427
Validation loss: 2.5352705271766363

Epoch: 5| Step: 1
Training loss: 2.0236729076232502
Validation loss: 2.5685358061826618

Epoch: 5| Step: 2
Training loss: 2.1980607285375697
Validation loss: 2.5356771851371147

Epoch: 5| Step: 3
Training loss: 1.6329629637097647
Validation loss: 2.5215107332978164

Epoch: 5| Step: 4
Training loss: 2.5275157180131376
Validation loss: 2.5068239140585047

Epoch: 5| Step: 5
Training loss: 2.333797431386158
Validation loss: 2.5447429825515604

Epoch: 5| Step: 6
Training loss: 2.1300696317726215
Validation loss: 2.5626752239738027

Epoch: 5| Step: 7
Training loss: 2.3789178757156404
Validation loss: 2.5924936180523903

Epoch: 5| Step: 8
Training loss: 2.2823803335284505
Validation loss: 2.547702659102244

Epoch: 5| Step: 9
Training loss: 2.0823753315953786
Validation loss: 2.597253061000004

Epoch: 5| Step: 10
Training loss: 3.3020840393129833
Validation loss: 2.581326754989435

Epoch: 406| Step: 0
Training loss: 1.9960520641057562
Validation loss: 2.5080861956313547

Epoch: 5| Step: 1
Training loss: 1.7775782168491494
Validation loss: 2.5931283428462324

Epoch: 5| Step: 2
Training loss: 2.1737591371788425
Validation loss: 2.519008645932822

Epoch: 5| Step: 3
Training loss: 2.080867134138493
Validation loss: 2.5609040581603773

Epoch: 5| Step: 4
Training loss: 2.393921219003543
Validation loss: 2.5347409398857215

Epoch: 5| Step: 5
Training loss: 2.2517020887087096
Validation loss: 2.4904693174835533

Epoch: 5| Step: 6
Training loss: 1.580003432499501
Validation loss: 2.5602437813143344

Epoch: 5| Step: 7
Training loss: 3.153900480607647
Validation loss: 2.595906133017222

Epoch: 5| Step: 8
Training loss: 2.5549487992324265
Validation loss: 2.532620377946646

Epoch: 5| Step: 9
Training loss: 2.1664866837304237
Validation loss: 2.57995764366823

Epoch: 5| Step: 10
Training loss: 2.5780413989759716
Validation loss: 2.514863234355354

Epoch: 407| Step: 0
Training loss: 2.0699968205303154
Validation loss: 2.538151430506097

Epoch: 5| Step: 1
Training loss: 2.118983896674067
Validation loss: 2.5442664576017244

Epoch: 5| Step: 2
Training loss: 2.4846045430022503
Validation loss: 2.553097658744836

Epoch: 5| Step: 3
Training loss: 1.8236948441341507
Validation loss: 2.5310152421745165

Epoch: 5| Step: 4
Training loss: 2.123213072784125
Validation loss: 2.570151775746025

Epoch: 5| Step: 5
Training loss: 1.8089008111831606
Validation loss: 2.5894789783999044

Epoch: 5| Step: 6
Training loss: 2.270386841535443
Validation loss: 2.563533596515751

Epoch: 5| Step: 7
Training loss: 2.3641143087192638
Validation loss: 2.5064774920705366

Epoch: 5| Step: 8
Training loss: 1.8468757900488078
Validation loss: 2.53199680077366

Epoch: 5| Step: 9
Training loss: 2.7449294073203183
Validation loss: 2.5371942135955945

Epoch: 5| Step: 10
Training loss: 2.6646394971744947
Validation loss: 2.591603729029342

Epoch: 408| Step: 0
Training loss: 2.0968459285079555
Validation loss: 2.522127331082022

Epoch: 5| Step: 1
Training loss: 1.6931011350631853
Validation loss: 2.5768558569091216

Epoch: 5| Step: 2
Training loss: 2.472197817087857
Validation loss: 2.58298332735755

Epoch: 5| Step: 3
Training loss: 2.195325749584683
Validation loss: 2.512679540016654

Epoch: 5| Step: 4
Training loss: 2.0807414398658945
Validation loss: 2.5995100240027553

Epoch: 5| Step: 5
Training loss: 2.5477723021221292
Validation loss: 2.55559881866856

Epoch: 5| Step: 6
Training loss: 2.6205306379204547
Validation loss: 2.5259407885120173

Epoch: 5| Step: 7
Training loss: 2.190488898692575
Validation loss: 2.6448339122254554

Epoch: 5| Step: 8
Training loss: 1.8093788634474757
Validation loss: 2.5445208313582404

Epoch: 5| Step: 9
Training loss: 2.3696703086771738
Validation loss: 2.4747262160455894

Epoch: 5| Step: 10
Training loss: 2.4578627981967425
Validation loss: 2.5700117311065878

Epoch: 409| Step: 0
Training loss: 2.5278667869779645
Validation loss: 2.519645627398583

Epoch: 5| Step: 1
Training loss: 2.4948852670162913
Validation loss: 2.5844062683552576

Epoch: 5| Step: 2
Training loss: 2.219392817690805
Validation loss: 2.5822054424892293

Epoch: 5| Step: 3
Training loss: 1.7153718521877628
Validation loss: 2.5751532228582277

Epoch: 5| Step: 4
Training loss: 2.4941694934581267
Validation loss: 2.578608399258059

Epoch: 5| Step: 5
Training loss: 2.249786578758834
Validation loss: 2.579899875697783

Epoch: 5| Step: 6
Training loss: 2.3791937693462355
Validation loss: 2.4990500357782177

Epoch: 5| Step: 7
Training loss: 2.1150508670687063
Validation loss: 2.5461412292932315

Epoch: 5| Step: 8
Training loss: 2.3227980944103255
Validation loss: 2.5466906517757812

Epoch: 5| Step: 9
Training loss: 1.8212954769072702
Validation loss: 2.511142323728881

Epoch: 5| Step: 10
Training loss: 2.2047082068689505
Validation loss: 2.5246329381998844

Epoch: 410| Step: 0
Training loss: 2.3473712665656756
Validation loss: 2.5812337598602877

Epoch: 5| Step: 1
Training loss: 1.2179841789946912
Validation loss: 2.5613856940432873

Epoch: 5| Step: 2
Training loss: 2.7768212536494383
Validation loss: 2.533628883578739

Epoch: 5| Step: 3
Training loss: 2.091197265397891
Validation loss: 2.4847435528558073

Epoch: 5| Step: 4
Training loss: 2.87460092179675
Validation loss: 2.5391640026164803

Epoch: 5| Step: 5
Training loss: 2.1358065985729064
Validation loss: 2.5328405647691397

Epoch: 5| Step: 6
Training loss: 1.9874650820177924
Validation loss: 2.5089446538050457

Epoch: 5| Step: 7
Training loss: 1.7895786257213036
Validation loss: 2.5584922867475366

Epoch: 5| Step: 8
Training loss: 2.4552255372286407
Validation loss: 2.5500570450510014

Epoch: 5| Step: 9
Training loss: 2.167735374192813
Validation loss: 2.5355653149486113

Epoch: 5| Step: 10
Training loss: 2.5238928605447555
Validation loss: 2.5304415176459547

Epoch: 411| Step: 0
Training loss: 2.362471411799479
Validation loss: 2.5320907496937126

Epoch: 5| Step: 1
Training loss: 2.254178617472767
Validation loss: 2.5128122802446002

Epoch: 5| Step: 2
Training loss: 2.2393458632315193
Validation loss: 2.57313375830469

Epoch: 5| Step: 3
Training loss: 2.333956283336437
Validation loss: 2.497875063236688

Epoch: 5| Step: 4
Training loss: 2.319207233271088
Validation loss: 2.571661494325514

Epoch: 5| Step: 5
Training loss: 2.0825045908205277
Validation loss: 2.501487851143416

Epoch: 5| Step: 6
Training loss: 1.53664041076097
Validation loss: 2.5389394988122693

Epoch: 5| Step: 7
Training loss: 2.2584170683742455
Validation loss: 2.5474863371167236

Epoch: 5| Step: 8
Training loss: 2.7683028710434914
Validation loss: 2.5124201414628207

Epoch: 5| Step: 9
Training loss: 2.285509704903056
Validation loss: 2.5009106054371903

Epoch: 5| Step: 10
Training loss: 2.016062252907602
Validation loss: 2.556460380506816

Epoch: 412| Step: 0
Training loss: 2.2464467708310485
Validation loss: 2.587697732353339

Epoch: 5| Step: 1
Training loss: 2.159585998207709
Validation loss: 2.5465660609932996

Epoch: 5| Step: 2
Training loss: 2.047641756136705
Validation loss: 2.5755708921995373

Epoch: 5| Step: 3
Training loss: 1.9450662602609248
Validation loss: 2.632461580454368

Epoch: 5| Step: 4
Training loss: 2.627575292261652
Validation loss: 2.614349255397183

Epoch: 5| Step: 5
Training loss: 1.8392508618548646
Validation loss: 2.58876763765043

Epoch: 5| Step: 6
Training loss: 2.6888542311863253
Validation loss: 2.5477339439068203

Epoch: 5| Step: 7
Training loss: 2.0861009398019266
Validation loss: 2.5362681885080574

Epoch: 5| Step: 8
Training loss: 2.6212810330061527
Validation loss: 2.5851340787386907

Epoch: 5| Step: 9
Training loss: 2.4406531064885395
Validation loss: 2.6144573353064104

Epoch: 5| Step: 10
Training loss: 2.132636317986478
Validation loss: 2.551335984565837

Epoch: 413| Step: 0
Training loss: 2.21121235679039
Validation loss: 2.6114178680759084

Epoch: 5| Step: 1
Training loss: 1.6393834093571176
Validation loss: 2.571993565866934

Epoch: 5| Step: 2
Training loss: 2.5710544616794633
Validation loss: 2.5965974179332667

Epoch: 5| Step: 3
Training loss: 2.4667444895590664
Validation loss: 2.5202684033016762

Epoch: 5| Step: 4
Training loss: 2.055400652103556
Validation loss: 2.5335199469769507

Epoch: 5| Step: 5
Training loss: 1.800554968793842
Validation loss: 2.5277678555487633

Epoch: 5| Step: 6
Training loss: 1.5277050010609783
Validation loss: 2.59061724339275

Epoch: 5| Step: 7
Training loss: 2.7016759968839104
Validation loss: 2.5601634956777612

Epoch: 5| Step: 8
Training loss: 2.1846613312928596
Validation loss: 2.567469050666633

Epoch: 5| Step: 9
Training loss: 2.3527773130382132
Validation loss: 2.563047047030238

Epoch: 5| Step: 10
Training loss: 2.912604000215744
Validation loss: 2.5266970786491925

Epoch: 414| Step: 0
Training loss: 1.9081893186352827
Validation loss: 2.519907170943845

Epoch: 5| Step: 1
Training loss: 2.593919403794684
Validation loss: 2.5630617984033486

Epoch: 5| Step: 2
Training loss: 1.7458110128112387
Validation loss: 2.5611740871837565

Epoch: 5| Step: 3
Training loss: 3.0760849132053414
Validation loss: 2.5099411384133528

Epoch: 5| Step: 4
Training loss: 2.305392193145255
Validation loss: 2.572971002321269

Epoch: 5| Step: 5
Training loss: 1.9257982729145895
Validation loss: 2.5559559771504934

Epoch: 5| Step: 6
Training loss: 2.1123778268370903
Validation loss: 2.52833945313691

Epoch: 5| Step: 7
Training loss: 2.1655349954945144
Validation loss: 2.542000853666064

Epoch: 5| Step: 8
Training loss: 1.8249191475294273
Validation loss: 2.5315396654494067

Epoch: 5| Step: 9
Training loss: 2.1906269068036237
Validation loss: 2.5767370262112883

Epoch: 5| Step: 10
Training loss: 2.2401134721080362
Validation loss: 2.571924542830667

Epoch: 415| Step: 0
Training loss: 1.4189791691751859
Validation loss: 2.5038398847912857

Epoch: 5| Step: 1
Training loss: 1.4845587365725832
Validation loss: 2.560548474930271

Epoch: 5| Step: 2
Training loss: 3.0405641586944365
Validation loss: 2.5605351127785565

Epoch: 5| Step: 3
Training loss: 2.0038650835653393
Validation loss: 2.543411022106047

Epoch: 5| Step: 4
Training loss: 2.8920508914548253
Validation loss: 2.5260545214998396

Epoch: 5| Step: 5
Training loss: 2.204801097730632
Validation loss: 2.5625651821727247

Epoch: 5| Step: 6
Training loss: 1.9144791130227667
Validation loss: 2.5437662566395876

Epoch: 5| Step: 7
Training loss: 2.0840124040772645
Validation loss: 2.530997682648408

Epoch: 5| Step: 8
Training loss: 2.502495664427028
Validation loss: 2.5729670492055807

Epoch: 5| Step: 9
Training loss: 1.6997676971138178
Validation loss: 2.535628414699388

Epoch: 5| Step: 10
Training loss: 2.716447403217261
Validation loss: 2.5770081926131136

Epoch: 416| Step: 0
Training loss: 2.5947046016959727
Validation loss: 2.6079644368458634

Epoch: 5| Step: 1
Training loss: 2.4707955686139482
Validation loss: 2.5611038806748474

Epoch: 5| Step: 2
Training loss: 2.0694944672935685
Validation loss: 2.542191218474353

Epoch: 5| Step: 3
Training loss: 2.2785876689935165
Validation loss: 2.5484200376235497

Epoch: 5| Step: 4
Training loss: 1.5814437717328005
Validation loss: 2.5362245299865083

Epoch: 5| Step: 5
Training loss: 2.6269140985135464
Validation loss: 2.5131159173641717

Epoch: 5| Step: 6
Training loss: 2.080002245168208
Validation loss: 2.5355506032939505

Epoch: 5| Step: 7
Training loss: 1.9680178052748054
Validation loss: 2.6137847020582825

Epoch: 5| Step: 8
Training loss: 2.7666312935494353
Validation loss: 2.609845480634718

Epoch: 5| Step: 9
Training loss: 2.1992710032785445
Validation loss: 2.5427147492853277

Epoch: 5| Step: 10
Training loss: 1.5800365541551342
Validation loss: 2.534419516356843

Epoch: 417| Step: 0
Training loss: 2.181542267114714
Validation loss: 2.5135355022875623

Epoch: 5| Step: 1
Training loss: 2.2716336254572624
Validation loss: 2.5701291386398544

Epoch: 5| Step: 2
Training loss: 2.521380929871182
Validation loss: 2.5030580854452062

Epoch: 5| Step: 3
Training loss: 2.705184328493929
Validation loss: 2.602877540389717

Epoch: 5| Step: 4
Training loss: 2.2881694001863093
Validation loss: 2.575930877682727

Epoch: 5| Step: 5
Training loss: 2.269146097038397
Validation loss: 2.5636383267492966

Epoch: 5| Step: 6
Training loss: 2.2771869167025076
Validation loss: 2.535735691641531

Epoch: 5| Step: 7
Training loss: 1.8317565061261816
Validation loss: 2.5057339464281694

Epoch: 5| Step: 8
Training loss: 2.075486537469713
Validation loss: 2.54740489563496

Epoch: 5| Step: 9
Training loss: 1.6439159991204864
Validation loss: 2.5423652022545715

Epoch: 5| Step: 10
Training loss: 1.9633631199237904
Validation loss: 2.555758442418655

Epoch: 418| Step: 0
Training loss: 2.230878962592939
Validation loss: 2.5382967143861754

Epoch: 5| Step: 1
Training loss: 1.8269733159497386
Validation loss: 2.57235042828927

Epoch: 5| Step: 2
Training loss: 1.8677959009575074
Validation loss: 2.5692406534093513

Epoch: 5| Step: 3
Training loss: 2.207766790112562
Validation loss: 2.545132689622888

Epoch: 5| Step: 4
Training loss: 2.812595450582991
Validation loss: 2.4990738024667456

Epoch: 5| Step: 5
Training loss: 1.8921132811048404
Validation loss: 2.588335072357591

Epoch: 5| Step: 6
Training loss: 2.080625707340321
Validation loss: 2.5219184155787002

Epoch: 5| Step: 7
Training loss: 2.3573255922239307
Validation loss: 2.5522665762059753

Epoch: 5| Step: 8
Training loss: 2.4286924820870976
Validation loss: 2.5279754530353036

Epoch: 5| Step: 9
Training loss: 2.4988086722938996
Validation loss: 2.5646683247649085

Epoch: 5| Step: 10
Training loss: 2.0468542665785563
Validation loss: 2.5913496330074657

Epoch: 419| Step: 0
Training loss: 1.851434952732893
Validation loss: 2.547699333424579

Epoch: 5| Step: 1
Training loss: 2.886795889478043
Validation loss: 2.6325745532109806

Epoch: 5| Step: 2
Training loss: 2.0865900397729282
Validation loss: 2.4704415012234215

Epoch: 5| Step: 3
Training loss: 2.4304688598672026
Validation loss: 2.5654730099011545

Epoch: 5| Step: 4
Training loss: 2.2663136455101354
Validation loss: 2.552957928295126

Epoch: 5| Step: 5
Training loss: 2.058697287111074
Validation loss: 2.5522092286315803

Epoch: 5| Step: 6
Training loss: 2.3471313499100277
Validation loss: 2.555627002924082

Epoch: 5| Step: 7
Training loss: 1.8311373679249685
Validation loss: 2.5454990412855354

Epoch: 5| Step: 8
Training loss: 1.6715572447381284
Validation loss: 2.486380631930168

Epoch: 5| Step: 9
Training loss: 2.596608987672823
Validation loss: 2.552001225195165

Epoch: 5| Step: 10
Training loss: 2.299869687079067
Validation loss: 2.572992509455865

Epoch: 420| Step: 0
Training loss: 1.9694892464213682
Validation loss: 2.558038800439318

Epoch: 5| Step: 1
Training loss: 2.1617536105649338
Validation loss: 2.5653825959306213

Epoch: 5| Step: 2
Training loss: 2.163536255679269
Validation loss: 2.5587271461384153

Epoch: 5| Step: 3
Training loss: 1.9461545538850253
Validation loss: 2.5842932810687684

Epoch: 5| Step: 4
Training loss: 2.2443965437260642
Validation loss: 2.6189913258151445

Epoch: 5| Step: 5
Training loss: 2.022554772086855
Validation loss: 2.5848118668990514

Epoch: 5| Step: 6
Training loss: 2.433103263987186
Validation loss: 2.5784428072158283

Epoch: 5| Step: 7
Training loss: 2.1377723788001357
Validation loss: 2.5718295769356034

Epoch: 5| Step: 8
Training loss: 2.6876507206725706
Validation loss: 2.557988263512492

Epoch: 5| Step: 9
Training loss: 2.8290567285884842
Validation loss: 2.5114785489102758

Epoch: 5| Step: 10
Training loss: 2.0443726597267875
Validation loss: 2.5913365028901394

Epoch: 421| Step: 0
Training loss: 2.4490561788773575
Validation loss: 2.638399988994321

Epoch: 5| Step: 1
Training loss: 2.265481668081984
Validation loss: 2.549327414232987

Epoch: 5| Step: 2
Training loss: 2.035023866180761
Validation loss: 2.505492675832363

Epoch: 5| Step: 3
Training loss: 2.1628211692500723
Validation loss: 2.5714242356575183

Epoch: 5| Step: 4
Training loss: 2.455488779081582
Validation loss: 2.552891910347875

Epoch: 5| Step: 5
Training loss: 2.685486238662044
Validation loss: 2.531292698119106

Epoch: 5| Step: 6
Training loss: 2.303943992556547
Validation loss: 2.587529919608732

Epoch: 5| Step: 7
Training loss: 1.5240022052839048
Validation loss: 2.503543606537716

Epoch: 5| Step: 8
Training loss: 1.9962837740931934
Validation loss: 2.5636243476985947

Epoch: 5| Step: 9
Training loss: 2.2825026534901767
Validation loss: 2.5584415328201935

Epoch: 5| Step: 10
Training loss: 2.1478701310492485
Validation loss: 2.575280514069121

Epoch: 422| Step: 0
Training loss: 2.2740001703159938
Validation loss: 2.588416391753431

Epoch: 5| Step: 1
Training loss: 2.3892660828915555
Validation loss: 2.5658956309957563

Epoch: 5| Step: 2
Training loss: 1.9042098587891552
Validation loss: 2.5622508560425175

Epoch: 5| Step: 3
Training loss: 2.507478590747415
Validation loss: 2.6239380160539674

Epoch: 5| Step: 4
Training loss: 2.5613999215180905
Validation loss: 2.5693733900230993

Epoch: 5| Step: 5
Training loss: 1.791161850479299
Validation loss: 2.5917950371839136

Epoch: 5| Step: 6
Training loss: 1.9065751595757583
Validation loss: 2.5795866411722352

Epoch: 5| Step: 7
Training loss: 1.8726521096882032
Validation loss: 2.5312263921145446

Epoch: 5| Step: 8
Training loss: 1.852845467750093
Validation loss: 2.5389066107186418

Epoch: 5| Step: 9
Training loss: 2.4747707491963533
Validation loss: 2.5985868504428566

Epoch: 5| Step: 10
Training loss: 2.5661585672314353
Validation loss: 2.5167524149851497

Epoch: 423| Step: 0
Training loss: 2.4095786714868788
Validation loss: 2.536215026334868

Epoch: 5| Step: 1
Training loss: 2.44128300470171
Validation loss: 2.5798474923904386

Epoch: 5| Step: 2
Training loss: 2.625797513884751
Validation loss: 2.5446578173491

Epoch: 5| Step: 3
Training loss: 1.7575102821798152
Validation loss: 2.5436494171904176

Epoch: 5| Step: 4
Training loss: 2.009115189861042
Validation loss: 2.563230926011374

Epoch: 5| Step: 5
Training loss: 1.922141266032516
Validation loss: 2.6142539742799267

Epoch: 5| Step: 6
Training loss: 1.7698671809434012
Validation loss: 2.6009008193171614

Epoch: 5| Step: 7
Training loss: 2.1453241157634024
Validation loss: 2.534170967273724

Epoch: 5| Step: 8
Training loss: 2.2056443979907967
Validation loss: 2.5373202880752204

Epoch: 5| Step: 9
Training loss: 2.0238678816921736
Validation loss: 2.553595500782303

Epoch: 5| Step: 10
Training loss: 3.0984883098889617
Validation loss: 2.551481166280499

Epoch: 424| Step: 0
Training loss: 2.409666534083286
Validation loss: 2.555575308813315

Epoch: 5| Step: 1
Training loss: 1.3331130660426511
Validation loss: 2.5483914502379132

Epoch: 5| Step: 2
Training loss: 1.89359321574715
Validation loss: 2.5674968654784656

Epoch: 5| Step: 3
Training loss: 2.3185557898447384
Validation loss: 2.5204369797727186

Epoch: 5| Step: 4
Training loss: 1.9975647405223504
Validation loss: 2.546126394991396

Epoch: 5| Step: 5
Training loss: 2.3220588457272178
Validation loss: 2.5246188112082857

Epoch: 5| Step: 6
Training loss: 2.639346383129573
Validation loss: 2.524926507262651

Epoch: 5| Step: 7
Training loss: 1.9472784809082269
Validation loss: 2.56381124907306

Epoch: 5| Step: 8
Training loss: 2.926210664780527
Validation loss: 2.526386116645967

Epoch: 5| Step: 9
Training loss: 1.9496298071788611
Validation loss: 2.541162733058509

Epoch: 5| Step: 10
Training loss: 2.1136832991802246
Validation loss: 2.5546858803430763

Epoch: 425| Step: 0
Training loss: 2.123717874931764
Validation loss: 2.5418670628418294

Epoch: 5| Step: 1
Training loss: 2.205021359952202
Validation loss: 2.5730489170666515

Epoch: 5| Step: 2
Training loss: 2.0365548919914933
Validation loss: 2.5825633814578386

Epoch: 5| Step: 3
Training loss: 2.0645869707010704
Validation loss: 2.5423414328844207

Epoch: 5| Step: 4
Training loss: 1.8598630889628083
Validation loss: 2.586233499502363

Epoch: 5| Step: 5
Training loss: 2.6308380783113985
Validation loss: 2.58314583309974

Epoch: 5| Step: 6
Training loss: 2.321322340159028
Validation loss: 2.533354868119985

Epoch: 5| Step: 7
Training loss: 2.5980848374702608
Validation loss: 2.5373721500059383

Epoch: 5| Step: 8
Training loss: 1.8568525113567542
Validation loss: 2.520504164113921

Epoch: 5| Step: 9
Training loss: 2.101639416503105
Validation loss: 2.60778977174998

Epoch: 5| Step: 10
Training loss: 2.3227966574102057
Validation loss: 2.543348084696227

Epoch: 426| Step: 0
Training loss: 2.07900030302529
Validation loss: 2.541634215139851

Epoch: 5| Step: 1
Training loss: 2.340195872920216
Validation loss: 2.5724978442153996

Epoch: 5| Step: 2
Training loss: 2.459562080761507
Validation loss: 2.5767976000534265

Epoch: 5| Step: 3
Training loss: 1.888348177890503
Validation loss: 2.5379296134760065

Epoch: 5| Step: 4
Training loss: 2.619466398661109
Validation loss: 2.6066076439397543

Epoch: 5| Step: 5
Training loss: 2.0365612137377616
Validation loss: 2.5814202383591724

Epoch: 5| Step: 6
Training loss: 2.2449689354053564
Validation loss: 2.5319546217981204

Epoch: 5| Step: 7
Training loss: 1.7493662367775358
Validation loss: 2.597797693359694

Epoch: 5| Step: 8
Training loss: 1.974087518844774
Validation loss: 2.5843383952328733

Epoch: 5| Step: 9
Training loss: 2.131935582123546
Validation loss: 2.558290740576434

Epoch: 5| Step: 10
Training loss: 2.970904241271203
Validation loss: 2.52656509986067

Epoch: 427| Step: 0
Training loss: 1.8434607068709383
Validation loss: 2.518882210625326

Epoch: 5| Step: 1
Training loss: 1.9863236838922205
Validation loss: 2.527181564594307

Epoch: 5| Step: 2
Training loss: 2.3722041890483574
Validation loss: 2.619265271510446

Epoch: 5| Step: 3
Training loss: 2.4969183047935286
Validation loss: 2.5615610572925083

Epoch: 5| Step: 4
Training loss: 2.061776930323113
Validation loss: 2.50102644942016

Epoch: 5| Step: 5
Training loss: 2.7558920768457518
Validation loss: 2.582791081645006

Epoch: 5| Step: 6
Training loss: 2.4316350362322825
Validation loss: 2.5630467199544853

Epoch: 5| Step: 7
Training loss: 1.7396849718687073
Validation loss: 2.5356500904529593

Epoch: 5| Step: 8
Training loss: 1.9027681915091224
Validation loss: 2.5422149610130065

Epoch: 5| Step: 9
Training loss: 2.251634639772934
Validation loss: 2.5772277618135977

Epoch: 5| Step: 10
Training loss: 2.0230304794693077
Validation loss: 2.5328951530217045

Epoch: 428| Step: 0
Training loss: 2.360691031940629
Validation loss: 2.566624227582328

Epoch: 5| Step: 1
Training loss: 2.2065906726317435
Validation loss: 2.589218427195089

Epoch: 5| Step: 2
Training loss: 1.8020334916765286
Validation loss: 2.5832276483115555

Epoch: 5| Step: 3
Training loss: 1.9943683729596615
Validation loss: 2.5837717375633757

Epoch: 5| Step: 4
Training loss: 2.125618115452938
Validation loss: 2.5988254202824277

Epoch: 5| Step: 5
Training loss: 2.5775616579423244
Validation loss: 2.5831013997810395

Epoch: 5| Step: 6
Training loss: 1.6676416724100516
Validation loss: 2.57422900566249

Epoch: 5| Step: 7
Training loss: 2.594600859652722
Validation loss: 2.5677534506825017

Epoch: 5| Step: 8
Training loss: 2.5311111600498326
Validation loss: 2.5341770147841842

Epoch: 5| Step: 9
Training loss: 1.870529440119171
Validation loss: 2.6167322621517717

Epoch: 5| Step: 10
Training loss: 2.13501756861871
Validation loss: 2.555736328331099

Epoch: 429| Step: 0
Training loss: 1.9716147515542033
Validation loss: 2.515881385137952

Epoch: 5| Step: 1
Training loss: 1.987579101811765
Validation loss: 2.5766558267339126

Epoch: 5| Step: 2
Training loss: 1.7891106744801843
Validation loss: 2.6086676409270675

Epoch: 5| Step: 3
Training loss: 2.058497967744741
Validation loss: 2.61693790514745

Epoch: 5| Step: 4
Training loss: 2.1195978049470443
Validation loss: 2.5775200584971643

Epoch: 5| Step: 5
Training loss: 2.449842650362599
Validation loss: 2.5766704419929325

Epoch: 5| Step: 6
Training loss: 2.3129585430092963
Validation loss: 2.568438340436909

Epoch: 5| Step: 7
Training loss: 2.5977431662797
Validation loss: 2.607036587888603

Epoch: 5| Step: 8
Training loss: 1.9703191528692015
Validation loss: 2.5933466534813285

Epoch: 5| Step: 9
Training loss: 2.7403634028057766
Validation loss: 2.585119611986447

Epoch: 5| Step: 10
Training loss: 1.9831149087836084
Validation loss: 2.5877643463845925

Epoch: 430| Step: 0
Training loss: 2.0196972304706953
Validation loss: 2.587578838293265

Epoch: 5| Step: 1
Training loss: 1.9410583061489608
Validation loss: 2.5076923384380896

Epoch: 5| Step: 2
Training loss: 2.5469774096909603
Validation loss: 2.5877137044223546

Epoch: 5| Step: 3
Training loss: 1.8265905216570497
Validation loss: 2.5988083465546086

Epoch: 5| Step: 4
Training loss: 2.036554423713211
Validation loss: 2.6052946270599433

Epoch: 5| Step: 5
Training loss: 2.721225619892465
Validation loss: 2.5797845843117164

Epoch: 5| Step: 6
Training loss: 1.9922010234298966
Validation loss: 2.5919045595484604

Epoch: 5| Step: 7
Training loss: 2.05054662906414
Validation loss: 2.5791746775118574

Epoch: 5| Step: 8
Training loss: 2.0055875213250056
Validation loss: 2.5340078125793815

Epoch: 5| Step: 9
Training loss: 2.0187910187985745
Validation loss: 2.555877376335143

Epoch: 5| Step: 10
Training loss: 2.7837537147281357
Validation loss: 2.5683668382519764

Epoch: 431| Step: 0
Training loss: 2.2501790717179295
Validation loss: 2.545264100965819

Epoch: 5| Step: 1
Training loss: 1.563060659909396
Validation loss: 2.5782719117509045

Epoch: 5| Step: 2
Training loss: 2.2045775690930434
Validation loss: 2.504632570827673

Epoch: 5| Step: 3
Training loss: 2.2097922010814615
Validation loss: 2.566479662252922

Epoch: 5| Step: 4
Training loss: 2.235325004449867
Validation loss: 2.5808244451291587

Epoch: 5| Step: 5
Training loss: 2.171614377418658
Validation loss: 2.569913005555902

Epoch: 5| Step: 6
Training loss: 2.0261546857703006
Validation loss: 2.5400135414189546

Epoch: 5| Step: 7
Training loss: 2.2818461645096826
Validation loss: 2.5617736959625392

Epoch: 5| Step: 8
Training loss: 2.0229221704043456
Validation loss: 2.5813970793689855

Epoch: 5| Step: 9
Training loss: 2.566380052127987
Validation loss: 2.557340779158816

Epoch: 5| Step: 10
Training loss: 2.4636139378555524
Validation loss: 2.5565903843257467

Epoch: 432| Step: 0
Training loss: 2.0968753774901274
Validation loss: 2.5439631484638174

Epoch: 5| Step: 1
Training loss: 1.338267386075709
Validation loss: 2.5881855720698344

Epoch: 5| Step: 2
Training loss: 1.8342803618731158
Validation loss: 2.5765889185429236

Epoch: 5| Step: 3
Training loss: 2.238509401207516
Validation loss: 2.559065344022863

Epoch: 5| Step: 4
Training loss: 2.366506648586468
Validation loss: 2.535220697257741

Epoch: 5| Step: 5
Training loss: 2.306972805979051
Validation loss: 2.5795738208831818

Epoch: 5| Step: 6
Training loss: 1.8200557675044389
Validation loss: 2.5752728657837616

Epoch: 5| Step: 7
Training loss: 2.1592059675158946
Validation loss: 2.5364566963087594

Epoch: 5| Step: 8
Training loss: 2.4178198551314107
Validation loss: 2.5709328165804917

Epoch: 5| Step: 9
Training loss: 2.5441202817408395
Validation loss: 2.58893374866553

Epoch: 5| Step: 10
Training loss: 2.2960045650848837
Validation loss: 2.6068247106784157

Epoch: 433| Step: 0
Training loss: 1.9647662714400789
Validation loss: 2.555474696307611

Epoch: 5| Step: 1
Training loss: 2.514040145632388
Validation loss: 2.5765795936237095

Epoch: 5| Step: 2
Training loss: 2.408295987729532
Validation loss: 2.5790897715821184

Epoch: 5| Step: 3
Training loss: 1.893879760728147
Validation loss: 2.558534398471175

Epoch: 5| Step: 4
Training loss: 2.1320502068224427
Validation loss: 2.5802685802689274

Epoch: 5| Step: 5
Training loss: 1.9698417300824187
Validation loss: 2.5421568396033924

Epoch: 5| Step: 6
Training loss: 1.9154858337930014
Validation loss: 2.5080436738254153

Epoch: 5| Step: 7
Training loss: 2.3368533581295003
Validation loss: 2.565423807596583

Epoch: 5| Step: 8
Training loss: 2.3104608153747868
Validation loss: 2.583353449068007

Epoch: 5| Step: 9
Training loss: 1.8131579158705153
Validation loss: 2.595133215299498

Epoch: 5| Step: 10
Training loss: 2.582583462159505
Validation loss: 2.582031463468646

Epoch: 434| Step: 0
Training loss: 2.3636400691250117
Validation loss: 2.619198349674638

Epoch: 5| Step: 1
Training loss: 1.900954787128539
Validation loss: 2.570656529580745

Epoch: 5| Step: 2
Training loss: 2.2338374631694067
Validation loss: 2.5435627398167013

Epoch: 5| Step: 3
Training loss: 2.1244635185257077
Validation loss: 2.5212205440128046

Epoch: 5| Step: 4
Training loss: 2.4237550390937757
Validation loss: 2.5350701559711863

Epoch: 5| Step: 5
Training loss: 2.2724064851998356
Validation loss: 2.6265220233766344

Epoch: 5| Step: 6
Training loss: 2.4201457094825827
Validation loss: 2.5308896720694567

Epoch: 5| Step: 7
Training loss: 2.117567753163875
Validation loss: 2.5907056317781407

Epoch: 5| Step: 8
Training loss: 1.9579991671021728
Validation loss: 2.5684801189104935

Epoch: 5| Step: 9
Training loss: 2.1533023755630487
Validation loss: 2.5820381033275894

Epoch: 5| Step: 10
Training loss: 1.4377233083015384
Validation loss: 2.541872646256941

Epoch: 435| Step: 0
Training loss: 2.6380238559676714
Validation loss: 2.581906731227843

Epoch: 5| Step: 1
Training loss: 2.8596453095955616
Validation loss: 2.586445018699068

Epoch: 5| Step: 2
Training loss: 1.7073726356334138
Validation loss: 2.5414645647389063

Epoch: 5| Step: 3
Training loss: 2.3400254218848007
Validation loss: 2.5885421592157485

Epoch: 5| Step: 4
Training loss: 1.8867603242136006
Validation loss: 2.5702681779647842

Epoch: 5| Step: 5
Training loss: 1.8607476561189584
Validation loss: 2.5865963808174555

Epoch: 5| Step: 6
Training loss: 1.9290757541643007
Validation loss: 2.5459270342501483

Epoch: 5| Step: 7
Training loss: 2.3056799869076294
Validation loss: 2.6425458709373615

Epoch: 5| Step: 8
Training loss: 2.2138249713387785
Validation loss: 2.5355948679231783

Epoch: 5| Step: 9
Training loss: 2.1910748290633926
Validation loss: 2.517274852986778

Epoch: 5| Step: 10
Training loss: 1.7956574668830363
Validation loss: 2.5554731162742597

Epoch: 436| Step: 0
Training loss: 2.1322933026189324
Validation loss: 2.5656364568663084

Epoch: 5| Step: 1
Training loss: 2.0489646204309113
Validation loss: 2.574731243120962

Epoch: 5| Step: 2
Training loss: 2.2057402759498927
Validation loss: 2.461385621215677

Epoch: 5| Step: 3
Training loss: 2.0917311087277644
Validation loss: 2.493232474282939

Epoch: 5| Step: 4
Training loss: 1.9076974095176933
Validation loss: 2.5582747501571985

Epoch: 5| Step: 5
Training loss: 2.0764036004414628
Validation loss: 2.5418716230688

Epoch: 5| Step: 6
Training loss: 2.066136362374474
Validation loss: 2.5371229332795413

Epoch: 5| Step: 7
Training loss: 1.8455767229989286
Validation loss: 2.5779402471813926

Epoch: 5| Step: 8
Training loss: 2.029581999000712
Validation loss: 2.5326250079660717

Epoch: 5| Step: 9
Training loss: 2.2431250549299393
Validation loss: 2.6135456546119076

Epoch: 5| Step: 10
Training loss: 3.182943191054925
Validation loss: 2.5654119058473652

Epoch: 437| Step: 0
Training loss: 2.5424801405409574
Validation loss: 2.5572138801782325

Epoch: 5| Step: 1
Training loss: 2.3005825921968737
Validation loss: 2.592429704582029

Epoch: 5| Step: 2
Training loss: 2.3542655541460222
Validation loss: 2.627902760610865

Epoch: 5| Step: 3
Training loss: 2.0675371100751945
Validation loss: 2.613675956777999

Epoch: 5| Step: 4
Training loss: 2.003868177026233
Validation loss: 2.5726327635278374

Epoch: 5| Step: 5
Training loss: 2.0380844167384717
Validation loss: 2.610771799117251

Epoch: 5| Step: 6
Training loss: 2.2887875128129727
Validation loss: 2.5767385364955375

Epoch: 5| Step: 7
Training loss: 1.7254774041145788
Validation loss: 2.611232346825877

Epoch: 5| Step: 8
Training loss: 2.243490020226458
Validation loss: 2.498576587593683

Epoch: 5| Step: 9
Training loss: 2.130247369111667
Validation loss: 2.5306866382363764

Epoch: 5| Step: 10
Training loss: 1.5925824245519287
Validation loss: 2.5580979991113915

Epoch: 438| Step: 0
Training loss: 1.8530974001702722
Validation loss: 2.5163854622673667

Epoch: 5| Step: 1
Training loss: 2.1754981906386233
Validation loss: 2.605563484569489

Epoch: 5| Step: 2
Training loss: 2.2185159479186605
Validation loss: 2.5450557590762615

Epoch: 5| Step: 3
Training loss: 2.3579705713068018
Validation loss: 2.579319228548672

Epoch: 5| Step: 4
Training loss: 2.0355652967346707
Validation loss: 2.49387563958011

Epoch: 5| Step: 5
Training loss: 1.8307417701370559
Validation loss: 2.586939048548098

Epoch: 5| Step: 6
Training loss: 2.1943108387875356
Validation loss: 2.6256887154539448

Epoch: 5| Step: 7
Training loss: 2.158205886770009
Validation loss: 2.601702922990343

Epoch: 5| Step: 8
Training loss: 2.3900861943236245
Validation loss: 2.5560164767877223

Epoch: 5| Step: 9
Training loss: 2.01447458483243
Validation loss: 2.587140536503947

Epoch: 5| Step: 10
Training loss: 2.4709942431319147
Validation loss: 2.571238197746527

Epoch: 439| Step: 0
Training loss: 2.1441022933783302
Validation loss: 2.6214858399849454

Epoch: 5| Step: 1
Training loss: 2.332150863570292
Validation loss: 2.602680918182015

Epoch: 5| Step: 2
Training loss: 1.743915128921971
Validation loss: 2.5812982614034787

Epoch: 5| Step: 3
Training loss: 1.9228774146981333
Validation loss: 2.590074131902028

Epoch: 5| Step: 4
Training loss: 2.2868167419602767
Validation loss: 2.5566541679431807

Epoch: 5| Step: 5
Training loss: 1.8228170167843143
Validation loss: 2.5559884031441817

Epoch: 5| Step: 6
Training loss: 2.028113305479874
Validation loss: 2.5778681045672482

Epoch: 5| Step: 7
Training loss: 1.939488528755411
Validation loss: 2.512012141320064

Epoch: 5| Step: 8
Training loss: 2.2873043039129555
Validation loss: 2.5729571930429276

Epoch: 5| Step: 9
Training loss: 2.0933081317202618
Validation loss: 2.5522012716385865

Epoch: 5| Step: 10
Training loss: 3.009902505404621
Validation loss: 2.494483132459016

Epoch: 440| Step: 0
Training loss: 1.673040963856517
Validation loss: 2.5636926062235545

Epoch: 5| Step: 1
Training loss: 1.9775212793374801
Validation loss: 2.596245260393546

Epoch: 5| Step: 2
Training loss: 2.352122699508357
Validation loss: 2.6179072181902874

Epoch: 5| Step: 3
Training loss: 2.17743941563306
Validation loss: 2.635825644928743

Epoch: 5| Step: 4
Training loss: 1.8366619872064167
Validation loss: 2.6142905950238537

Epoch: 5| Step: 5
Training loss: 2.8754758026479323
Validation loss: 2.5834141128829784

Epoch: 5| Step: 6
Training loss: 2.4610613110596073
Validation loss: 2.606363178069075

Epoch: 5| Step: 7
Training loss: 1.3901842254571295
Validation loss: 2.562529660025

Epoch: 5| Step: 8
Training loss: 2.0046781425227946
Validation loss: 2.5885102083662423

Epoch: 5| Step: 9
Training loss: 2.5181293224487926
Validation loss: 2.63741492459978

Epoch: 5| Step: 10
Training loss: 2.1603030384264317
Validation loss: 2.589611277573324

Epoch: 441| Step: 0
Training loss: 2.186463791790589
Validation loss: 2.5802008452082363

Epoch: 5| Step: 1
Training loss: 2.4475821300282536
Validation loss: 2.6105845389561075

Epoch: 5| Step: 2
Training loss: 3.287787908558738
Validation loss: 2.5778662607989693

Epoch: 5| Step: 3
Training loss: 1.3636916015736753
Validation loss: 2.5788981332794814

Epoch: 5| Step: 4
Training loss: 1.9064160884356
Validation loss: 2.6120437680986597

Epoch: 5| Step: 5
Training loss: 1.878627256748063
Validation loss: 2.575420104476585

Epoch: 5| Step: 6
Training loss: 1.8151926888361936
Validation loss: 2.5896373938723842

Epoch: 5| Step: 7
Training loss: 2.304433621146424
Validation loss: 2.5755941379169824

Epoch: 5| Step: 8
Training loss: 1.715043736225446
Validation loss: 2.58373333285043

Epoch: 5| Step: 9
Training loss: 2.2052367350161295
Validation loss: 2.638202290535538

Epoch: 5| Step: 10
Training loss: 1.7015702736977356
Validation loss: 2.547064294958011

Epoch: 442| Step: 0
Training loss: 1.776207864840113
Validation loss: 2.5693551028512305

Epoch: 5| Step: 1
Training loss: 2.4793524685858332
Validation loss: 2.59199616744234

Epoch: 5| Step: 2
Training loss: 2.862488432615138
Validation loss: 2.574337535115977

Epoch: 5| Step: 3
Training loss: 1.9757592902541323
Validation loss: 2.6075086653461828

Epoch: 5| Step: 4
Training loss: 1.937421920187526
Validation loss: 2.5534410750435654

Epoch: 5| Step: 5
Training loss: 1.7144008055721995
Validation loss: 2.5137607681034724

Epoch: 5| Step: 6
Training loss: 2.1700337241228684
Validation loss: 2.514145505944587

Epoch: 5| Step: 7
Training loss: 2.270567875549645
Validation loss: 2.5200696887032503

Epoch: 5| Step: 8
Training loss: 2.2900724819323215
Validation loss: 2.5552337655519275

Epoch: 5| Step: 9
Training loss: 2.231709844823456
Validation loss: 2.6074575760573264

Epoch: 5| Step: 10
Training loss: 1.7907283972800894
Validation loss: 2.5707912837585214

Epoch: 443| Step: 0
Training loss: 1.7466336979314683
Validation loss: 2.5049565330924253

Epoch: 5| Step: 1
Training loss: 1.4279018570007949
Validation loss: 2.545637217364353

Epoch: 5| Step: 2
Training loss: 2.9604263065690346
Validation loss: 2.5046285216227435

Epoch: 5| Step: 3
Training loss: 1.8797098768873084
Validation loss: 2.6063374354355084

Epoch: 5| Step: 4
Training loss: 2.684512407296565
Validation loss: 2.5273133838865203

Epoch: 5| Step: 5
Training loss: 1.5500568071845844
Validation loss: 2.556477204572522

Epoch: 5| Step: 6
Training loss: 2.076241349415267
Validation loss: 2.567251727495012

Epoch: 5| Step: 7
Training loss: 2.5256322994376856
Validation loss: 2.5958935839269905

Epoch: 5| Step: 8
Training loss: 2.013873973513504
Validation loss: 2.553400039453186

Epoch: 5| Step: 9
Training loss: 2.3493319353163704
Validation loss: 2.573349424624079

Epoch: 5| Step: 10
Training loss: 1.9266945799067228
Validation loss: 2.5952171617007003

Epoch: 444| Step: 0
Training loss: 1.825227250360117
Validation loss: 2.6035221613253494

Epoch: 5| Step: 1
Training loss: 2.0140952285936606
Validation loss: 2.579549158045614

Epoch: 5| Step: 2
Training loss: 1.8519034413816429
Validation loss: 2.5499053246626775

Epoch: 5| Step: 3
Training loss: 1.992802184773476
Validation loss: 2.588001847511349

Epoch: 5| Step: 4
Training loss: 2.530800390932461
Validation loss: 2.5855464899303806

Epoch: 5| Step: 5
Training loss: 1.4218569743931677
Validation loss: 2.5913839785550525

Epoch: 5| Step: 6
Training loss: 2.7708664703299806
Validation loss: 2.6007725582663195

Epoch: 5| Step: 7
Training loss: 1.8713477485929602
Validation loss: 2.644213901657873

Epoch: 5| Step: 8
Training loss: 2.3277233212498705
Validation loss: 2.627070343455693

Epoch: 5| Step: 9
Training loss: 1.7948823577880948
Validation loss: 2.568758738808562

Epoch: 5| Step: 10
Training loss: 2.683066059409737
Validation loss: 2.585368321159701

Epoch: 445| Step: 0
Training loss: 1.6920103619711375
Validation loss: 2.60832119095947

Epoch: 5| Step: 1
Training loss: 1.521782078344244
Validation loss: 2.588603896794023

Epoch: 5| Step: 2
Training loss: 1.9363005832593423
Validation loss: 2.544560736664113

Epoch: 5| Step: 3
Training loss: 2.3278032118875354
Validation loss: 2.576035109868641

Epoch: 5| Step: 4
Training loss: 2.160950444004131
Validation loss: 2.535577063079562

Epoch: 5| Step: 5
Training loss: 2.4636234218803907
Validation loss: 2.6333394770033314

Epoch: 5| Step: 6
Training loss: 2.8431904001150103
Validation loss: 2.5272578250050866

Epoch: 5| Step: 7
Training loss: 1.9937092074343725
Validation loss: 2.6054315152482332

Epoch: 5| Step: 8
Training loss: 2.016175660609361
Validation loss: 2.5679125265437857

Epoch: 5| Step: 9
Training loss: 2.1302099873008618
Validation loss: 2.5705688260979485

Epoch: 5| Step: 10
Training loss: 2.233995738886882
Validation loss: 2.5384643011563104

Epoch: 446| Step: 0
Training loss: 1.7898419943392538
Validation loss: 2.5253136331101005

Epoch: 5| Step: 1
Training loss: 2.1803410688499336
Validation loss: 2.5588125198446376

Epoch: 5| Step: 2
Training loss: 2.1643007884024446
Validation loss: 2.54378704168944

Epoch: 5| Step: 3
Training loss: 1.8291461407574976
Validation loss: 2.5925349950333545

Epoch: 5| Step: 4
Training loss: 2.1108282663811875
Validation loss: 2.5263454706611643

Epoch: 5| Step: 5
Training loss: 2.880233976078681
Validation loss: 2.543800865709481

Epoch: 5| Step: 6
Training loss: 2.3467990624222574
Validation loss: 2.5597109789786847

Epoch: 5| Step: 7
Training loss: 1.8876272348125838
Validation loss: 2.5576653411881214

Epoch: 5| Step: 8
Training loss: 1.7468011093207756
Validation loss: 2.5671270271125985

Epoch: 5| Step: 9
Training loss: 2.1416922922741204
Validation loss: 2.5296619786048313

Epoch: 5| Step: 10
Training loss: 2.348376983857785
Validation loss: 2.604843520935933

Epoch: 447| Step: 0
Training loss: 1.7667837476021269
Validation loss: 2.573531086215306

Epoch: 5| Step: 1
Training loss: 1.7741442377056276
Validation loss: 2.578136085841911

Epoch: 5| Step: 2
Training loss: 1.9838689924871065
Validation loss: 2.5590423118141583

Epoch: 5| Step: 3
Training loss: 2.1568021205636985
Validation loss: 2.535116354413217

Epoch: 5| Step: 4
Training loss: 2.233166774782873
Validation loss: 2.631579232253646

Epoch: 5| Step: 5
Training loss: 2.1041996515792065
Validation loss: 2.556073214896596

Epoch: 5| Step: 6
Training loss: 2.4439410669117203
Validation loss: 2.5839283003663214

Epoch: 5| Step: 7
Training loss: 1.7952496682801422
Validation loss: 2.586463152330625

Epoch: 5| Step: 8
Training loss: 2.0494225642439567
Validation loss: 2.57673279780865

Epoch: 5| Step: 9
Training loss: 2.2444510382166194
Validation loss: 2.605344591747607

Epoch: 5| Step: 10
Training loss: 2.9086875947520983
Validation loss: 2.5609784434843834

Epoch: 448| Step: 0
Training loss: 1.786819984894043
Validation loss: 2.643159517326017

Epoch: 5| Step: 1
Training loss: 2.7588296802872745
Validation loss: 2.5975687623355097

Epoch: 5| Step: 2
Training loss: 2.6651309379488946
Validation loss: 2.5236104940644157

Epoch: 5| Step: 3
Training loss: 2.031391197578969
Validation loss: 2.613634604528392

Epoch: 5| Step: 4
Training loss: 2.2040352530386085
Validation loss: 2.594483905402052

Epoch: 5| Step: 5
Training loss: 2.1661571735055585
Validation loss: 2.571862145695553

Epoch: 5| Step: 6
Training loss: 1.674170228768574
Validation loss: 2.5786095425825275

Epoch: 5| Step: 7
Training loss: 2.1576330200067475
Validation loss: 2.638792384170757

Epoch: 5| Step: 8
Training loss: 1.869368169600527
Validation loss: 2.590232837587773

Epoch: 5| Step: 9
Training loss: 1.9842963616115805
Validation loss: 2.6151773264772684

Epoch: 5| Step: 10
Training loss: 1.8262659385241518
Validation loss: 2.5329926575291624

Epoch: 449| Step: 0
Training loss: 2.0148552896110754
Validation loss: 2.5857330876947127

Epoch: 5| Step: 1
Training loss: 2.2494251788521233
Validation loss: 2.6318994356031156

Epoch: 5| Step: 2
Training loss: 2.512883178946589
Validation loss: 2.6598967032445784

Epoch: 5| Step: 3
Training loss: 2.0676734082197514
Validation loss: 2.582150581184708

Epoch: 5| Step: 4
Training loss: 2.192558108248088
Validation loss: 2.5712899558346485

Epoch: 5| Step: 5
Training loss: 1.8896473650473378
Validation loss: 2.594816970644182

Epoch: 5| Step: 6
Training loss: 2.354595674117792
Validation loss: 2.606231653032803

Epoch: 5| Step: 7
Training loss: 2.077012187181843
Validation loss: 2.6116772323198774

Epoch: 5| Step: 8
Training loss: 2.178100226766288
Validation loss: 2.5742098785899334

Epoch: 5| Step: 9
Training loss: 1.5863504858632007
Validation loss: 2.605407953233311

Epoch: 5| Step: 10
Training loss: 2.2418842177019433
Validation loss: 2.599183328178086

Epoch: 450| Step: 0
Training loss: 2.1333136895387965
Validation loss: 2.6188513589706526

Epoch: 5| Step: 1
Training loss: 1.9281883439551242
Validation loss: 2.628918745848047

Epoch: 5| Step: 2
Training loss: 2.2432474960335282
Validation loss: 2.5498095537585397

Epoch: 5| Step: 3
Training loss: 1.9951453297964705
Validation loss: 2.5984419130568

Epoch: 5| Step: 4
Training loss: 1.913475289090784
Validation loss: 2.6066033282674486

Epoch: 5| Step: 5
Training loss: 2.208386246629094
Validation loss: 2.518907913236597

Epoch: 5| Step: 6
Training loss: 1.9290371312374024
Validation loss: 2.6690496870623734

Epoch: 5| Step: 7
Training loss: 2.412001930963556
Validation loss: 2.585161232935366

Epoch: 5| Step: 8
Training loss: 2.800366656956034
Validation loss: 2.6185114047067346

Epoch: 5| Step: 9
Training loss: 1.9080558727848678
Validation loss: 2.556181544377563

Epoch: 5| Step: 10
Training loss: 1.7405823981449586
Validation loss: 2.590787731713941

Epoch: 451| Step: 0
Training loss: 2.3880475679576847
Validation loss: 2.6023542076600625

Epoch: 5| Step: 1
Training loss: 1.6375976242201007
Validation loss: 2.5628953534189707

Epoch: 5| Step: 2
Training loss: 2.251964876751373
Validation loss: 2.5714586429608537

Epoch: 5| Step: 3
Training loss: 2.8082559565478666
Validation loss: 2.5578226419965753

Epoch: 5| Step: 4
Training loss: 1.8371034207208021
Validation loss: 2.5621739321871217

Epoch: 5| Step: 5
Training loss: 1.9493367803458765
Validation loss: 2.587746264470595

Epoch: 5| Step: 6
Training loss: 1.3532216467051468
Validation loss: 2.5854542930782762

Epoch: 5| Step: 7
Training loss: 2.3554602475748285
Validation loss: 2.557320802991821

Epoch: 5| Step: 8
Training loss: 1.98383810634894
Validation loss: 2.5371191258940042

Epoch: 5| Step: 9
Training loss: 1.776283501262825
Validation loss: 2.5196428527814754

Epoch: 5| Step: 10
Training loss: 2.2564171303853344
Validation loss: 2.519006017165657

Epoch: 452| Step: 0
Training loss: 2.0889734470328833
Validation loss: 2.5120669168449856

Epoch: 5| Step: 1
Training loss: 1.9418962501171044
Validation loss: 2.5694624652875437

Epoch: 5| Step: 2
Training loss: 2.151721788326249
Validation loss: 2.5326170537210944

Epoch: 5| Step: 3
Training loss: 2.2130102140429666
Validation loss: 2.5944087178837285

Epoch: 5| Step: 4
Training loss: 2.8371596212033126
Validation loss: 2.6155735368699196

Epoch: 5| Step: 5
Training loss: 2.0238100393812877
Validation loss: 2.601791873797493

Epoch: 5| Step: 6
Training loss: 1.74489393551339
Validation loss: 2.542268486796968

Epoch: 5| Step: 7
Training loss: 2.27938923652707
Validation loss: 2.535158195616839

Epoch: 5| Step: 8
Training loss: 1.8111558731504955
Validation loss: 2.6337275421323403

Epoch: 5| Step: 9
Training loss: 2.061026769502156
Validation loss: 2.5507310456803385

Epoch: 5| Step: 10
Training loss: 2.1169665457091793
Validation loss: 2.610110391424273

Epoch: 453| Step: 0
Training loss: 1.6953978626892507
Validation loss: 2.598585490974067

Epoch: 5| Step: 1
Training loss: 1.7831326624307549
Validation loss: 2.596754909963006

Epoch: 5| Step: 2
Training loss: 2.039985184896191
Validation loss: 2.636446731615822

Epoch: 5| Step: 3
Training loss: 2.303202522453472
Validation loss: 2.582645192290295

Epoch: 5| Step: 4
Training loss: 2.2108684839051373
Validation loss: 2.592695391217465

Epoch: 5| Step: 5
Training loss: 2.126560647866972
Validation loss: 2.602431425430545

Epoch: 5| Step: 6
Training loss: 2.258589666911142
Validation loss: 2.6065296538787917

Epoch: 5| Step: 7
Training loss: 2.0437989161992376
Validation loss: 2.6167936716582294

Epoch: 5| Step: 8
Training loss: 2.261968358419761
Validation loss: 2.533297643453275

Epoch: 5| Step: 9
Training loss: 2.1923216949303996
Validation loss: 2.5194103540425705

Epoch: 5| Step: 10
Training loss: 2.3436981195429833
Validation loss: 2.5730287300712433

Epoch: 454| Step: 0
Training loss: 1.9865870724271915
Validation loss: 2.5456781847344

Epoch: 5| Step: 1
Training loss: 2.774059644953101
Validation loss: 2.6086009557971312

Epoch: 5| Step: 2
Training loss: 2.562499255668718
Validation loss: 2.551511602460071

Epoch: 5| Step: 3
Training loss: 1.7832090747479123
Validation loss: 2.615262777242315

Epoch: 5| Step: 4
Training loss: 1.7440473268850583
Validation loss: 2.5969859423321853

Epoch: 5| Step: 5
Training loss: 2.238039546252389
Validation loss: 2.491797213321128

Epoch: 5| Step: 6
Training loss: 1.6773854648926858
Validation loss: 2.5989335361620927

Epoch: 5| Step: 7
Training loss: 2.141553913913617
Validation loss: 2.5350186924193543

Epoch: 5| Step: 8
Training loss: 1.7920913045221487
Validation loss: 2.671203381108478

Epoch: 5| Step: 9
Training loss: 1.4787185509530674
Validation loss: 2.503548533019895

Epoch: 5| Step: 10
Training loss: 2.368007001879367
Validation loss: 2.5608241366017346

Epoch: 455| Step: 0
Training loss: 1.9372363372569052
Validation loss: 2.602661336308877

Epoch: 5| Step: 1
Training loss: 2.526459670466105
Validation loss: 2.584991861139642

Epoch: 5| Step: 2
Training loss: 2.1563576934015587
Validation loss: 2.5638555367431173

Epoch: 5| Step: 3
Training loss: 2.2370966627699977
Validation loss: 2.5928192860741572

Epoch: 5| Step: 4
Training loss: 2.5336663286633545
Validation loss: 2.6024887691142506

Epoch: 5| Step: 5
Training loss: 1.6982728627413948
Validation loss: 2.575408192183758

Epoch: 5| Step: 6
Training loss: 1.8089649322130494
Validation loss: 2.52033487298865

Epoch: 5| Step: 7
Training loss: 1.928333502428492
Validation loss: 2.5681865912101296

Epoch: 5| Step: 8
Training loss: 2.187448555477666
Validation loss: 2.6399527995885927

Epoch: 5| Step: 9
Training loss: 2.262834395676869
Validation loss: 2.558570129390707

Epoch: 5| Step: 10
Training loss: 1.5484326159480082
Validation loss: 2.555565996499451

Epoch: 456| Step: 0
Training loss: 2.02093445305324
Validation loss: 2.5754448118316593

Epoch: 5| Step: 1
Training loss: 1.5863431965990966
Validation loss: 2.520730583912562

Epoch: 5| Step: 2
Training loss: 2.439558382718407
Validation loss: 2.6533957852484615

Epoch: 5| Step: 3
Training loss: 2.219231136969386
Validation loss: 2.608185626075377

Epoch: 5| Step: 4
Training loss: 2.3717249324001006
Validation loss: 2.598597486436464

Epoch: 5| Step: 5
Training loss: 2.6074082506373917
Validation loss: 2.590588176096517

Epoch: 5| Step: 6
Training loss: 2.0919680627751913
Validation loss: 2.549687436013339

Epoch: 5| Step: 7
Training loss: 1.705050508640366
Validation loss: 2.5831247231259034

Epoch: 5| Step: 8
Training loss: 2.4548285333922886
Validation loss: 2.6554831182571332

Epoch: 5| Step: 9
Training loss: 1.9757431804930752
Validation loss: 2.54888295521827

Epoch: 5| Step: 10
Training loss: 1.4191937160247454
Validation loss: 2.5790954145698604

Epoch: 457| Step: 0
Training loss: 1.9700646022912365
Validation loss: 2.5883809203141666

Epoch: 5| Step: 1
Training loss: 1.9024650644711463
Validation loss: 2.5686151225042924

Epoch: 5| Step: 2
Training loss: 2.31112939580792
Validation loss: 2.6185582701949555

Epoch: 5| Step: 3
Training loss: 2.5231734099243104
Validation loss: 2.5230104793781143

Epoch: 5| Step: 4
Training loss: 1.8090267445794603
Validation loss: 2.552808332564073

Epoch: 5| Step: 5
Training loss: 2.8051798183853673
Validation loss: 2.61064391991858

Epoch: 5| Step: 6
Training loss: 1.6080049775838912
Validation loss: 2.6093329193571453

Epoch: 5| Step: 7
Training loss: 1.9769403752321162
Validation loss: 2.5623463490318716

Epoch: 5| Step: 8
Training loss: 1.5595164997369089
Validation loss: 2.5595648978974523

Epoch: 5| Step: 9
Training loss: 2.179623073049574
Validation loss: 2.56457920294216

Epoch: 5| Step: 10
Training loss: 1.6894380954669268
Validation loss: 2.57423740495789

Epoch: 458| Step: 0
Training loss: 2.1113423533141065
Validation loss: 2.5897032046691697

Epoch: 5| Step: 1
Training loss: 2.007558131154209
Validation loss: 2.6113284980604985

Epoch: 5| Step: 2
Training loss: 1.7553065769611087
Validation loss: 2.692704598686504

Epoch: 5| Step: 3
Training loss: 2.483582568195967
Validation loss: 2.582278433877207

Epoch: 5| Step: 4
Training loss: 2.5455865701893003
Validation loss: 2.5399716681635587

Epoch: 5| Step: 5
Training loss: 1.7486550748855108
Validation loss: 2.522972328962968

Epoch: 5| Step: 6
Training loss: 1.9535772181554898
Validation loss: 2.581880818725047

Epoch: 5| Step: 7
Training loss: 2.3949092796839424
Validation loss: 2.596958726188452

Epoch: 5| Step: 8
Training loss: 2.0523048190986652
Validation loss: 2.566962496584212

Epoch: 5| Step: 9
Training loss: 1.8903998248727776
Validation loss: 2.5803907097200653

Epoch: 5| Step: 10
Training loss: 1.864793208012267
Validation loss: 2.625741534523988

Epoch: 459| Step: 0
Training loss: 2.442230622538701
Validation loss: 2.5659014308875716

Epoch: 5| Step: 1
Training loss: 1.7781675337010079
Validation loss: 2.6577908953659195

Epoch: 5| Step: 2
Training loss: 2.0248892153352744
Validation loss: 2.6012725722723333

Epoch: 5| Step: 3
Training loss: 1.5472363907176518
Validation loss: 2.558202653239347

Epoch: 5| Step: 4
Training loss: 1.816180996617789
Validation loss: 2.5759209054706957

Epoch: 5| Step: 5
Training loss: 1.9929794831624326
Validation loss: 2.578945327966069

Epoch: 5| Step: 6
Training loss: 2.10711299976689
Validation loss: 2.624979564042243

Epoch: 5| Step: 7
Training loss: 2.757080413215716
Validation loss: 2.5932547982027656

Epoch: 5| Step: 8
Training loss: 2.05901632007358
Validation loss: 2.64919632668533

Epoch: 5| Step: 9
Training loss: 1.8350774820376896
Validation loss: 2.60690909681987

Epoch: 5| Step: 10
Training loss: 2.321051894009231
Validation loss: 2.565707450613926

Epoch: 460| Step: 0
Training loss: 2.185047300512017
Validation loss: 2.594597717596353

Epoch: 5| Step: 1
Training loss: 2.4606191277815417
Validation loss: 2.600857386209931

Epoch: 5| Step: 2
Training loss: 1.9380489310080184
Validation loss: 2.5292547331005157

Epoch: 5| Step: 3
Training loss: 1.785513476933808
Validation loss: 2.6467280985184365

Epoch: 5| Step: 4
Training loss: 1.5008129460067192
Validation loss: 2.5461839143056912

Epoch: 5| Step: 5
Training loss: 2.4121075958368943
Validation loss: 2.574044841683225

Epoch: 5| Step: 6
Training loss: 1.5836866971607086
Validation loss: 2.614645455470593

Epoch: 5| Step: 7
Training loss: 2.2455440478832487
Validation loss: 2.6261442320657435

Epoch: 5| Step: 8
Training loss: 2.1285003555150595
Validation loss: 2.557679449031649

Epoch: 5| Step: 9
Training loss: 2.1575810843532817
Validation loss: 2.5986677375557683

Epoch: 5| Step: 10
Training loss: 2.236827544705268
Validation loss: 2.629258257367831

Epoch: 461| Step: 0
Training loss: 2.243848975928666
Validation loss: 2.599252236891393

Epoch: 5| Step: 1
Training loss: 1.5509525848214638
Validation loss: 2.5820689353819515

Epoch: 5| Step: 2
Training loss: 2.0024606349852494
Validation loss: 2.6126463437776173

Epoch: 5| Step: 3
Training loss: 2.3664181910176088
Validation loss: 2.5750935093194576

Epoch: 5| Step: 4
Training loss: 2.170552791203908
Validation loss: 2.5656313678231317

Epoch: 5| Step: 5
Training loss: 2.7332026120848187
Validation loss: 2.557367700172807

Epoch: 5| Step: 6
Training loss: 1.800938001583307
Validation loss: 2.5518725412160173

Epoch: 5| Step: 7
Training loss: 1.9157328887975753
Validation loss: 2.5580528541096035

Epoch: 5| Step: 8
Training loss: 1.9142998373063729
Validation loss: 2.5653425248452355

Epoch: 5| Step: 9
Training loss: 2.1269835022437618
Validation loss: 2.5988896923719844

Epoch: 5| Step: 10
Training loss: 1.9825896995426937
Validation loss: 2.582356343287972

Epoch: 462| Step: 0
Training loss: 2.1146129988169524
Validation loss: 2.5733180368010697

Epoch: 5| Step: 1
Training loss: 2.4516294743742093
Validation loss: 2.549875550970187

Epoch: 5| Step: 2
Training loss: 2.405673663984351
Validation loss: 2.5803607393623866

Epoch: 5| Step: 3
Training loss: 2.404008688493664
Validation loss: 2.627666468788085

Epoch: 5| Step: 4
Training loss: 2.2043211375038108
Validation loss: 2.5674220029936126

Epoch: 5| Step: 5
Training loss: 1.7094981789011598
Validation loss: 2.5530457447226933

Epoch: 5| Step: 6
Training loss: 2.1093521682068745
Validation loss: 2.609752894652639

Epoch: 5| Step: 7
Training loss: 1.4320817920779
Validation loss: 2.546129154844633

Epoch: 5| Step: 8
Training loss: 2.283542578453724
Validation loss: 2.490448989708502

Epoch: 5| Step: 9
Training loss: 1.968228043892964
Validation loss: 2.5725463900331738

Epoch: 5| Step: 10
Training loss: 1.8685298547602853
Validation loss: 2.5869341951512634

Epoch: 463| Step: 0
Training loss: 2.146305760596274
Validation loss: 2.5417593174721578

Epoch: 5| Step: 1
Training loss: 1.9931261431887228
Validation loss: 2.5378288974055416

Epoch: 5| Step: 2
Training loss: 2.267130805160461
Validation loss: 2.590114389493093

Epoch: 5| Step: 3
Training loss: 1.8131912491801618
Validation loss: 2.644033401292119

Epoch: 5| Step: 4
Training loss: 2.465207225763098
Validation loss: 2.555762120725372

Epoch: 5| Step: 5
Training loss: 1.7672637491278214
Validation loss: 2.6107401664713907

Epoch: 5| Step: 6
Training loss: 1.9221686162193126
Validation loss: 2.588176992201284

Epoch: 5| Step: 7
Training loss: 2.0893410336503275
Validation loss: 2.576192464275624

Epoch: 5| Step: 8
Training loss: 1.7658592001277744
Validation loss: 2.581649584517237

Epoch: 5| Step: 9
Training loss: 2.5657335674254393
Validation loss: 2.5793190983449623

Epoch: 5| Step: 10
Training loss: 2.015110985323788
Validation loss: 2.562351848802601

Epoch: 464| Step: 0
Training loss: 2.2121211142399417
Validation loss: 2.6308492153658025

Epoch: 5| Step: 1
Training loss: 2.0499449559707124
Validation loss: 2.617507004585143

Epoch: 5| Step: 2
Training loss: 2.1404376539682026
Validation loss: 2.593624834978662

Epoch: 5| Step: 3
Training loss: 1.8919938861756207
Validation loss: 2.578547267446036

Epoch: 5| Step: 4
Training loss: 1.7488668042562707
Validation loss: 2.5789859352229776

Epoch: 5| Step: 5
Training loss: 2.4771706589518168
Validation loss: 2.569306079657356

Epoch: 5| Step: 6
Training loss: 2.437788041530869
Validation loss: 2.5472180047277653

Epoch: 5| Step: 7
Training loss: 1.7125088517454496
Validation loss: 2.5608432295067223

Epoch: 5| Step: 8
Training loss: 1.823349870342926
Validation loss: 2.5495629293338906

Epoch: 5| Step: 9
Training loss: 1.939681762863827
Validation loss: 2.621214839434971

Epoch: 5| Step: 10
Training loss: 1.9761236857148607
Validation loss: 2.5823166348694246

Epoch: 465| Step: 0
Training loss: 1.9229057463242514
Validation loss: 2.5758750586746126

Epoch: 5| Step: 1
Training loss: 1.780180358964539
Validation loss: 2.664403615279941

Epoch: 5| Step: 2
Training loss: 2.036191007299361
Validation loss: 2.607877727531276

Epoch: 5| Step: 3
Training loss: 2.1046417254006355
Validation loss: 2.5767156891232794

Epoch: 5| Step: 4
Training loss: 1.5260407726645429
Validation loss: 2.582070038452477

Epoch: 5| Step: 5
Training loss: 1.8856694243511345
Validation loss: 2.5816112445593795

Epoch: 5| Step: 6
Training loss: 2.2611373127641037
Validation loss: 2.581214298342153

Epoch: 5| Step: 7
Training loss: 2.0839009719647934
Validation loss: 2.5493143733906822

Epoch: 5| Step: 8
Training loss: 2.511139371266567
Validation loss: 2.5778297590868737

Epoch: 5| Step: 9
Training loss: 2.3721067976236387
Validation loss: 2.515362553073941

Epoch: 5| Step: 10
Training loss: 2.405467810387473
Validation loss: 2.5516630384575953

Epoch: 466| Step: 0
Training loss: 1.6940754539052179
Validation loss: 2.6036819426916615

Epoch: 5| Step: 1
Training loss: 2.3133591782759595
Validation loss: 2.5962350615827035

Epoch: 5| Step: 2
Training loss: 1.7526690701109924
Validation loss: 2.54024164553026

Epoch: 5| Step: 3
Training loss: 2.5651011407256634
Validation loss: 2.608533966754589

Epoch: 5| Step: 4
Training loss: 2.2189306266224142
Validation loss: 2.555102132512219

Epoch: 5| Step: 5
Training loss: 1.7713007216638208
Validation loss: 2.609416511121454

Epoch: 5| Step: 6
Training loss: 1.6627864332760138
Validation loss: 2.60902992675035

Epoch: 5| Step: 7
Training loss: 1.5391368557546101
Validation loss: 2.553286793585416

Epoch: 5| Step: 8
Training loss: 2.320838021000272
Validation loss: 2.6075023435151232

Epoch: 5| Step: 9
Training loss: 1.817123697986177
Validation loss: 2.5313074684481065

Epoch: 5| Step: 10
Training loss: 2.499677160398815
Validation loss: 2.5784274811609285

Epoch: 467| Step: 0
Training loss: 2.2918952365519654
Validation loss: 2.614377247561447

Epoch: 5| Step: 1
Training loss: 1.5149108147887504
Validation loss: 2.5956538468299333

Epoch: 5| Step: 2
Training loss: 2.2942912822133943
Validation loss: 2.6265998609817385

Epoch: 5| Step: 3
Training loss: 2.0358189768629176
Validation loss: 2.572654403532849

Epoch: 5| Step: 4
Training loss: 2.122318370942296
Validation loss: 2.569124618250627

Epoch: 5| Step: 5
Training loss: 1.9545652648615424
Validation loss: 2.616049648829883

Epoch: 5| Step: 6
Training loss: 2.117333551415657
Validation loss: 2.59026199497739

Epoch: 5| Step: 7
Training loss: 2.5070520121379496
Validation loss: 2.599597990700273

Epoch: 5| Step: 8
Training loss: 1.980879641312437
Validation loss: 2.586325641814284

Epoch: 5| Step: 9
Training loss: 1.774523835048717
Validation loss: 2.6263499092420974

Epoch: 5| Step: 10
Training loss: 1.618090022988371
Validation loss: 2.645751179285336

Epoch: 468| Step: 0
Training loss: 2.0497158225734866
Validation loss: 2.5621976416420758

Epoch: 5| Step: 1
Training loss: 1.444669508313487
Validation loss: 2.655629367696143

Epoch: 5| Step: 2
Training loss: 2.1072338398648554
Validation loss: 2.5758812610675244

Epoch: 5| Step: 3
Training loss: 1.9205415643406698
Validation loss: 2.5613782354719854

Epoch: 5| Step: 4
Training loss: 1.6729531065256764
Validation loss: 2.5552195428724684

Epoch: 5| Step: 5
Training loss: 1.7963011779077944
Validation loss: 2.6027209640328586

Epoch: 5| Step: 6
Training loss: 2.5915194192578657
Validation loss: 2.6273758991735323

Epoch: 5| Step: 7
Training loss: 2.67572903547367
Validation loss: 2.6003835728435165

Epoch: 5| Step: 8
Training loss: 1.9029197995660043
Validation loss: 2.5783128199521714

Epoch: 5| Step: 9
Training loss: 1.887724740499084
Validation loss: 2.595216730017731

Epoch: 5| Step: 10
Training loss: 2.233704473013386
Validation loss: 2.648891709011551

Epoch: 469| Step: 0
Training loss: 1.8490369609895494
Validation loss: 2.6231579565443566

Epoch: 5| Step: 1
Training loss: 2.183382573433959
Validation loss: 2.521692100400814

Epoch: 5| Step: 2
Training loss: 2.1096860303098124
Validation loss: 2.5330301069585093

Epoch: 5| Step: 3
Training loss: 2.2593927364259963
Validation loss: 2.6220843133586778

Epoch: 5| Step: 4
Training loss: 1.6418636913803162
Validation loss: 2.6427642793320505

Epoch: 5| Step: 5
Training loss: 1.9179808078239229
Validation loss: 2.6289047131255594

Epoch: 5| Step: 6
Training loss: 2.2376858383661378
Validation loss: 2.594567377783336

Epoch: 5| Step: 7
Training loss: 2.1088977415093093
Validation loss: 2.6738285027633757

Epoch: 5| Step: 8
Training loss: 1.7224263494107048
Validation loss: 2.5989531244213464

Epoch: 5| Step: 9
Training loss: 2.4561655432859957
Validation loss: 2.511924379403384

Epoch: 5| Step: 10
Training loss: 1.4456463402452389
Validation loss: 2.5303944284083792

Epoch: 470| Step: 0
Training loss: 1.991748776465761
Validation loss: 2.600918580118552

Epoch: 5| Step: 1
Training loss: 2.5355799810199096
Validation loss: 2.609095229728537

Epoch: 5| Step: 2
Training loss: 1.7564690775680853
Validation loss: 2.604520797441625

Epoch: 5| Step: 3
Training loss: 1.8982329081742149
Validation loss: 2.553461248224108

Epoch: 5| Step: 4
Training loss: 1.8440788105157844
Validation loss: 2.5977907617052804

Epoch: 5| Step: 5
Training loss: 2.1332218210560265
Validation loss: 2.5877497576224946

Epoch: 5| Step: 6
Training loss: 2.3997513840968723
Validation loss: 2.616199955671092

Epoch: 5| Step: 7
Training loss: 2.265784422428506
Validation loss: 2.579174449891085

Epoch: 5| Step: 8
Training loss: 2.0249436123379323
Validation loss: 2.6317118785845373

Epoch: 5| Step: 9
Training loss: 1.894202197886076
Validation loss: 2.58233179736652

Epoch: 5| Step: 10
Training loss: 1.770820535351751
Validation loss: 2.600640946165433

Epoch: 471| Step: 0
Training loss: 1.8300105095650157
Validation loss: 2.5579879999313286

Epoch: 5| Step: 1
Training loss: 2.449668538774097
Validation loss: 2.580168349910395

Epoch: 5| Step: 2
Training loss: 2.5960457075588756
Validation loss: 2.606416779133046

Epoch: 5| Step: 3
Training loss: 2.1160049795946687
Validation loss: 2.669067984656061

Epoch: 5| Step: 4
Training loss: 2.233114140225516
Validation loss: 2.5988464397142548

Epoch: 5| Step: 5
Training loss: 1.560541833289337
Validation loss: 2.6188775331483254

Epoch: 5| Step: 6
Training loss: 2.321016249876321
Validation loss: 2.659656788026539

Epoch: 5| Step: 7
Training loss: 1.3425127587875372
Validation loss: 2.6582797244086254

Epoch: 5| Step: 8
Training loss: 1.766185435244188
Validation loss: 2.59384508103214

Epoch: 5| Step: 9
Training loss: 2.1156889056382258
Validation loss: 2.5961616553274527

Epoch: 5| Step: 10
Training loss: 1.6649400429913328
Validation loss: 2.6128347971878134

Epoch: 472| Step: 0
Training loss: 1.7125256975014014
Validation loss: 2.558881503333427

Epoch: 5| Step: 1
Training loss: 1.9174191062206891
Validation loss: 2.5758069886205934

Epoch: 5| Step: 2
Training loss: 1.8820160886946393
Validation loss: 2.6624501521915116

Epoch: 5| Step: 3
Training loss: 2.060224838764203
Validation loss: 2.596701385770584

Epoch: 5| Step: 4
Training loss: 1.57614245381366
Validation loss: 2.592570442268506

Epoch: 5| Step: 5
Training loss: 1.9326632023403405
Validation loss: 2.6243827648872586

Epoch: 5| Step: 6
Training loss: 2.229382145054487
Validation loss: 2.675628376542805

Epoch: 5| Step: 7
Training loss: 2.720467824954927
Validation loss: 2.6010048206429746

Epoch: 5| Step: 8
Training loss: 1.7045483722083812
Validation loss: 2.6722198649481106

Epoch: 5| Step: 9
Training loss: 2.5640482063522696
Validation loss: 2.5770783737081437

Epoch: 5| Step: 10
Training loss: 2.18612017028474
Validation loss: 2.6064160932031757

Epoch: 473| Step: 0
Training loss: 2.0678726502539893
Validation loss: 2.6230296393373163

Epoch: 5| Step: 1
Training loss: 1.6735162967541455
Validation loss: 2.5892805862719483

Epoch: 5| Step: 2
Training loss: 2.3890559214469596
Validation loss: 2.55959261481264

Epoch: 5| Step: 3
Training loss: 1.8453374591273195
Validation loss: 2.4944760072370897

Epoch: 5| Step: 4
Training loss: 1.9687367998921939
Validation loss: 2.575210418371279

Epoch: 5| Step: 5
Training loss: 2.170571574161315
Validation loss: 2.6596089868794883

Epoch: 5| Step: 6
Training loss: 1.971602900815638
Validation loss: 2.636224908678161

Epoch: 5| Step: 7
Training loss: 1.9629306466496768
Validation loss: 2.6549608913572653

Epoch: 5| Step: 8
Training loss: 2.3388571975908783
Validation loss: 2.587170183569352

Epoch: 5| Step: 9
Training loss: 1.9279261284007836
Validation loss: 2.5982533064431035

Epoch: 5| Step: 10
Training loss: 2.4822989372587694
Validation loss: 2.5723901181385003

Epoch: 474| Step: 0
Training loss: 1.864128959602955
Validation loss: 2.6696264955731737

Epoch: 5| Step: 1
Training loss: 1.6610978631363469
Validation loss: 2.636430191299085

Epoch: 5| Step: 2
Training loss: 1.9343340448779969
Validation loss: 2.597365619747861

Epoch: 5| Step: 3
Training loss: 2.7011196216927083
Validation loss: 2.61143151373261

Epoch: 5| Step: 4
Training loss: 2.277417242261312
Validation loss: 2.626654471252541

Epoch: 5| Step: 5
Training loss: 1.9142181333211283
Validation loss: 2.5906415752387946

Epoch: 5| Step: 6
Training loss: 2.302043367847346
Validation loss: 2.581496657232802

Epoch: 5| Step: 7
Training loss: 1.8709206391532602
Validation loss: 2.6547894722988823

Epoch: 5| Step: 8
Training loss: 1.9059926469026571
Validation loss: 2.5483891067974636

Epoch: 5| Step: 9
Training loss: 2.333470192937314
Validation loss: 2.575517135798789

Epoch: 5| Step: 10
Training loss: 2.0019399056347082
Validation loss: 2.5660694002579145

Epoch: 475| Step: 0
Training loss: 2.2876750399631627
Validation loss: 2.564747020010423

Epoch: 5| Step: 1
Training loss: 2.6933291892060733
Validation loss: 2.6155832608677763

Epoch: 5| Step: 2
Training loss: 1.541637068112084
Validation loss: 2.604015915639888

Epoch: 5| Step: 3
Training loss: 2.24615064465985
Validation loss: 2.64959730411483

Epoch: 5| Step: 4
Training loss: 1.6086367052520756
Validation loss: 2.552782278343233

Epoch: 5| Step: 5
Training loss: 1.9069082655704184
Validation loss: 2.628197263467201

Epoch: 5| Step: 6
Training loss: 1.9440147636622183
Validation loss: 2.648227640865669

Epoch: 5| Step: 7
Training loss: 2.436513847989646
Validation loss: 2.6147757302827146

Epoch: 5| Step: 8
Training loss: 1.679299669070425
Validation loss: 2.5645291697714323

Epoch: 5| Step: 9
Training loss: 1.9274665932537276
Validation loss: 2.6285491082994987

Epoch: 5| Step: 10
Training loss: 2.349655341176777
Validation loss: 2.630291209361503

Epoch: 476| Step: 0
Training loss: 1.922272555783139
Validation loss: 2.608932005575929

Epoch: 5| Step: 1
Training loss: 1.855130905714647
Validation loss: 2.628818009913059

Epoch: 5| Step: 2
Training loss: 1.7384833400565491
Validation loss: 2.5931242439891498

Epoch: 5| Step: 3
Training loss: 1.7418583443525972
Validation loss: 2.571582694654883

Epoch: 5| Step: 4
Training loss: 1.6092127005210306
Validation loss: 2.6381420294770903

Epoch: 5| Step: 5
Training loss: 1.700593379188309
Validation loss: 2.5993877972349115

Epoch: 5| Step: 6
Training loss: 2.5447174482001564
Validation loss: 2.5891512693583283

Epoch: 5| Step: 7
Training loss: 2.2204352412702897
Validation loss: 2.583378860543508

Epoch: 5| Step: 8
Training loss: 1.7350428214821412
Validation loss: 2.58052231646223

Epoch: 5| Step: 9
Training loss: 2.6307090257533106
Validation loss: 2.583130653546876

Epoch: 5| Step: 10
Training loss: 2.216680071606175
Validation loss: 2.5235491403179933

Epoch: 477| Step: 0
Training loss: 2.912525579643069
Validation loss: 2.6060880684528094

Epoch: 5| Step: 1
Training loss: 1.565046904960929
Validation loss: 2.6293099936311135

Epoch: 5| Step: 2
Training loss: 2.555802688074941
Validation loss: 2.572826526569567

Epoch: 5| Step: 3
Training loss: 1.389713717419846
Validation loss: 2.581548122257015

Epoch: 5| Step: 4
Training loss: 1.9515878961283546
Validation loss: 2.5876786216164667

Epoch: 5| Step: 5
Training loss: 1.6450872863059363
Validation loss: 2.6099341323204794

Epoch: 5| Step: 6
Training loss: 2.247851087328345
Validation loss: 2.5645939644953497

Epoch: 5| Step: 7
Training loss: 1.49909421275306
Validation loss: 2.568077069079925

Epoch: 5| Step: 8
Training loss: 2.011829321331749
Validation loss: 2.5660894451892036

Epoch: 5| Step: 9
Training loss: 1.9291264880660386
Validation loss: 2.602622304113577

Epoch: 5| Step: 10
Training loss: 2.3819011008344773
Validation loss: 2.5722526635740337

Epoch: 478| Step: 0
Training loss: 1.828639422689479
Validation loss: 2.587970303566291

Epoch: 5| Step: 1
Training loss: 1.8261104471411582
Validation loss: 2.498324511625856

Epoch: 5| Step: 2
Training loss: 2.176520340203785
Validation loss: 2.5993577046662173

Epoch: 5| Step: 3
Training loss: 1.6909625945011904
Validation loss: 2.5649478864538064

Epoch: 5| Step: 4
Training loss: 2.2581697069225
Validation loss: 2.654219364768626

Epoch: 5| Step: 5
Training loss: 2.6840357964711052
Validation loss: 2.5476495272345168

Epoch: 5| Step: 6
Training loss: 1.7269457913777786
Validation loss: 2.584183130076886

Epoch: 5| Step: 7
Training loss: 1.7892667828665951
Validation loss: 2.611400168865754

Epoch: 5| Step: 8
Training loss: 1.867266154527978
Validation loss: 2.5797819876622157

Epoch: 5| Step: 9
Training loss: 2.3509080552814496
Validation loss: 2.640979934005834

Epoch: 5| Step: 10
Training loss: 1.9725804682612746
Validation loss: 2.5961120106139415

Epoch: 479| Step: 0
Training loss: 1.9127659980444933
Validation loss: 2.6131769843104538

Epoch: 5| Step: 1
Training loss: 1.6662033708691455
Validation loss: 2.639901595281307

Epoch: 5| Step: 2
Training loss: 1.7405884935807188
Validation loss: 2.633261328471216

Epoch: 5| Step: 3
Training loss: 2.183710685424124
Validation loss: 2.597420793339277

Epoch: 5| Step: 4
Training loss: 1.706222307588313
Validation loss: 2.5901627476603704

Epoch: 5| Step: 5
Training loss: 1.8958355690520243
Validation loss: 2.5556879868270928

Epoch: 5| Step: 6
Training loss: 2.08080904301633
Validation loss: 2.575223687453197

Epoch: 5| Step: 7
Training loss: 2.447444973133184
Validation loss: 2.6517860393735773

Epoch: 5| Step: 8
Training loss: 2.004084588456587
Validation loss: 2.633454723164156

Epoch: 5| Step: 9
Training loss: 1.9065918537725761
Validation loss: 2.6034495282204158

Epoch: 5| Step: 10
Training loss: 2.3415322555936733
Validation loss: 2.6835329443824913

Epoch: 480| Step: 0
Training loss: 1.7906443170434245
Validation loss: 2.597577712865407

Epoch: 5| Step: 1
Training loss: 1.9861885854494292
Validation loss: 2.597457122387252

Epoch: 5| Step: 2
Training loss: 1.6768606128850323
Validation loss: 2.6405931104236964

Epoch: 5| Step: 3
Training loss: 2.120018674300376
Validation loss: 2.5880916277945323

Epoch: 5| Step: 4
Training loss: 2.319783879441025
Validation loss: 2.626734102689091

Epoch: 5| Step: 5
Training loss: 1.9553280421988666
Validation loss: 2.6019500184639424

Epoch: 5| Step: 6
Training loss: 1.8100601085145065
Validation loss: 2.5864524357116974

Epoch: 5| Step: 7
Training loss: 1.7225396426086328
Validation loss: 2.5405547209312287

Epoch: 5| Step: 8
Training loss: 2.417612570318316
Validation loss: 2.6505064703394248

Epoch: 5| Step: 9
Training loss: 2.0178639596276575
Validation loss: 2.5686664114701574

Epoch: 5| Step: 10
Training loss: 2.2348453053440545
Validation loss: 2.556666822398037

Epoch: 481| Step: 0
Training loss: 2.3206534087078077
Validation loss: 2.5917659613356685

Epoch: 5| Step: 1
Training loss: 2.031765564265717
Validation loss: 2.6169346890079455

Epoch: 5| Step: 2
Training loss: 1.6541968521451649
Validation loss: 2.5961028664190855

Epoch: 5| Step: 3
Training loss: 2.32237999251864
Validation loss: 2.593469216362221

Epoch: 5| Step: 4
Training loss: 1.900331408057347
Validation loss: 2.601383245302978

Epoch: 5| Step: 5
Training loss: 2.1538185010434403
Validation loss: 2.6001724391860908

Epoch: 5| Step: 6
Training loss: 2.018590593687664
Validation loss: 2.5874816341024776

Epoch: 5| Step: 7
Training loss: 1.5113753685329645
Validation loss: 2.5395101031862484

Epoch: 5| Step: 8
Training loss: 2.1906478031729306
Validation loss: 2.5968548708302497

Epoch: 5| Step: 9
Training loss: 2.089968668689149
Validation loss: 2.6165134228562015

Epoch: 5| Step: 10
Training loss: 2.121036985421086
Validation loss: 2.6136181562364174

Epoch: 482| Step: 0
Training loss: 2.1209178310666528
Validation loss: 2.60863024300012

Epoch: 5| Step: 1
Training loss: 1.9385585969339019
Validation loss: 2.6046601721647322

Epoch: 5| Step: 2
Training loss: 2.195175763959249
Validation loss: 2.4954378257763135

Epoch: 5| Step: 3
Training loss: 1.9903490147690281
Validation loss: 2.599773961512674

Epoch: 5| Step: 4
Training loss: 1.9909284016118833
Validation loss: 2.6206261936529165

Epoch: 5| Step: 5
Training loss: 2.242440664639743
Validation loss: 2.5345021863201165

Epoch: 5| Step: 6
Training loss: 2.0315511626951337
Validation loss: 2.580057782351793

Epoch: 5| Step: 7
Training loss: 1.5412995012908566
Validation loss: 2.5513683773360727

Epoch: 5| Step: 8
Training loss: 1.6349447828995611
Validation loss: 2.642304640325137

Epoch: 5| Step: 9
Training loss: 2.4247009525547822
Validation loss: 2.6342226691320363

Epoch: 5| Step: 10
Training loss: 1.7814300847623412
Validation loss: 2.569711118556464

Epoch: 483| Step: 0
Training loss: 2.044757592307119
Validation loss: 2.6173956499142474

Epoch: 5| Step: 1
Training loss: 2.091231468287305
Validation loss: 2.585824765016199

Epoch: 5| Step: 2
Training loss: 2.221781419374119
Validation loss: 2.6010279159329937

Epoch: 5| Step: 3
Training loss: 1.966803966460186
Validation loss: 2.5631847397140444

Epoch: 5| Step: 4
Training loss: 1.6893445988896425
Validation loss: 2.6273385299461904

Epoch: 5| Step: 5
Training loss: 1.8746076809207155
Validation loss: 2.668486615024213

Epoch: 5| Step: 6
Training loss: 2.295348717784854
Validation loss: 2.621027282720081

Epoch: 5| Step: 7
Training loss: 2.4319486736980007
Validation loss: 2.6106051818718723

Epoch: 5| Step: 8
Training loss: 1.4794535112518967
Validation loss: 2.6008999124968097

Epoch: 5| Step: 9
Training loss: 1.7684533750013973
Validation loss: 2.5878242648550134

Epoch: 5| Step: 10
Training loss: 2.1432752700859066
Validation loss: 2.5553414895447135

Epoch: 484| Step: 0
Training loss: 1.744552307411818
Validation loss: 2.6467911652530307

Epoch: 5| Step: 1
Training loss: 2.9885700559990656
Validation loss: 2.6172464010546728

Epoch: 5| Step: 2
Training loss: 1.9524578938846744
Validation loss: 2.5510326547351743

Epoch: 5| Step: 3
Training loss: 1.8166641544476325
Validation loss: 2.647613283885188

Epoch: 5| Step: 4
Training loss: 2.276085114809993
Validation loss: 2.600690039150013

Epoch: 5| Step: 5
Training loss: 1.6472529634491604
Validation loss: 2.5779320707751494

Epoch: 5| Step: 6
Training loss: 1.6291771533104975
Validation loss: 2.6136337541123513

Epoch: 5| Step: 7
Training loss: 2.0943972597729363
Validation loss: 2.637305300913993

Epoch: 5| Step: 8
Training loss: 2.239673866985223
Validation loss: 2.5766019268085496

Epoch: 5| Step: 9
Training loss: 1.6461613565619162
Validation loss: 2.5401821962323354

Epoch: 5| Step: 10
Training loss: 2.0399000997952754
Validation loss: 2.6459651045719492

Epoch: 485| Step: 0
Training loss: 1.6066317093608995
Validation loss: 2.581566281844741

Epoch: 5| Step: 1
Training loss: 2.036247092866081
Validation loss: 2.6433903567665546

Epoch: 5| Step: 2
Training loss: 1.6710201466576902
Validation loss: 2.6111845948540906

Epoch: 5| Step: 3
Training loss: 2.2704996219610334
Validation loss: 2.53665241769801

Epoch: 5| Step: 4
Training loss: 1.8119171126104474
Validation loss: 2.5833610654911023

Epoch: 5| Step: 5
Training loss: 2.0819815509869204
Validation loss: 2.617491055649297

Epoch: 5| Step: 6
Training loss: 2.0164366278268573
Validation loss: 2.624383358814848

Epoch: 5| Step: 7
Training loss: 2.4037652996843923
Validation loss: 2.6472080958922826

Epoch: 5| Step: 8
Training loss: 2.352439742091886
Validation loss: 2.6478176671175224

Epoch: 5| Step: 9
Training loss: 2.015031830794186
Validation loss: 2.7517565527022843

Epoch: 5| Step: 10
Training loss: 2.1896074225361586
Validation loss: 2.6492756758586573

Epoch: 486| Step: 0
Training loss: 2.0589000611546227
Validation loss: 2.596641900207214

Epoch: 5| Step: 1
Training loss: 1.5685716535248944
Validation loss: 2.5777561613757634

Epoch: 5| Step: 2
Training loss: 1.8488392178129942
Validation loss: 2.606849380009188

Epoch: 5| Step: 3
Training loss: 2.548722796255191
Validation loss: 2.634468113811134

Epoch: 5| Step: 4
Training loss: 1.5801181104431528
Validation loss: 2.5852804374958875

Epoch: 5| Step: 5
Training loss: 1.9824255431192972
Validation loss: 2.6247931036056062

Epoch: 5| Step: 6
Training loss: 2.162735404724112
Validation loss: 2.6124387472196053

Epoch: 5| Step: 7
Training loss: 1.4019264726717418
Validation loss: 2.6039996625612956

Epoch: 5| Step: 8
Training loss: 1.985951075593782
Validation loss: 2.61556252688092

Epoch: 5| Step: 9
Training loss: 2.276242861959126
Validation loss: 2.6074643492825405

Epoch: 5| Step: 10
Training loss: 2.327596924563466
Validation loss: 2.5995198850126604

Epoch: 487| Step: 0
Training loss: 2.404250069355535
Validation loss: 2.642208779959331

Epoch: 5| Step: 1
Training loss: 2.1634809352950755
Validation loss: 2.5219783401262403

Epoch: 5| Step: 2
Training loss: 2.2207697956474486
Validation loss: 2.5138824905247303

Epoch: 5| Step: 3
Training loss: 1.7702211630845168
Validation loss: 2.655187634925463

Epoch: 5| Step: 4
Training loss: 1.468489116468613
Validation loss: 2.5678105374633247

Epoch: 5| Step: 5
Training loss: 1.6264035692356873
Validation loss: 2.575592404001136

Epoch: 5| Step: 6
Training loss: 1.9160441203044802
Validation loss: 2.5162862128986223

Epoch: 5| Step: 7
Training loss: 2.3626369133892067
Validation loss: 2.591450258427201

Epoch: 5| Step: 8
Training loss: 1.9215875426140343
Validation loss: 2.6021258371150853

Epoch: 5| Step: 9
Training loss: 1.782517634621553
Validation loss: 2.6099631560538263

Epoch: 5| Step: 10
Training loss: 2.4065824006598593
Validation loss: 2.620149256817987

Epoch: 488| Step: 0
Training loss: 2.144218713885049
Validation loss: 2.5692198747141366

Epoch: 5| Step: 1
Training loss: 1.7461341665484615
Validation loss: 2.6494363448865617

Epoch: 5| Step: 2
Training loss: 1.8008410925862033
Validation loss: 2.6288449995919714

Epoch: 5| Step: 3
Training loss: 1.7481070225772886
Validation loss: 2.5737711936437746

Epoch: 5| Step: 4
Training loss: 2.0993602232258266
Validation loss: 2.6040355670703295

Epoch: 5| Step: 5
Training loss: 2.1791568233153407
Validation loss: 2.6597615598611926

Epoch: 5| Step: 6
Training loss: 2.111426817839606
Validation loss: 2.602531572141171

Epoch: 5| Step: 7
Training loss: 1.889466301077721
Validation loss: 2.683155723884249

Epoch: 5| Step: 8
Training loss: 1.6629192024555082
Validation loss: 2.6104644766560305

Epoch: 5| Step: 9
Training loss: 2.485237979354468
Validation loss: 2.637147636458699

Epoch: 5| Step: 10
Training loss: 2.0135708773395757
Validation loss: 2.653963295439238

Epoch: 489| Step: 0
Training loss: 1.9188662291870495
Validation loss: 2.6461829614245507

Epoch: 5| Step: 1
Training loss: 1.8763905772814844
Validation loss: 2.5377783115886428

Epoch: 5| Step: 2
Training loss: 1.8900472215273543
Validation loss: 2.5798696671101036

Epoch: 5| Step: 3
Training loss: 1.6321899103201287
Validation loss: 2.6253693238292932

Epoch: 5| Step: 4
Training loss: 1.9679963016436492
Validation loss: 2.593469561348202

Epoch: 5| Step: 5
Training loss: 2.0677172246656936
Validation loss: 2.57843012789345

Epoch: 5| Step: 6
Training loss: 1.4626127215904265
Validation loss: 2.522622506690718

Epoch: 5| Step: 7
Training loss: 1.9077224672710487
Validation loss: 2.6534757097795643

Epoch: 5| Step: 8
Training loss: 2.138526500481516
Validation loss: 2.5850029586899144

Epoch: 5| Step: 9
Training loss: 1.8842394474802489
Validation loss: 2.5658329283825916

Epoch: 5| Step: 10
Training loss: 2.7030956288765142
Validation loss: 2.566192616563077

Epoch: 490| Step: 0
Training loss: 1.9331614617980004
Validation loss: 2.6552283680322746

Epoch: 5| Step: 1
Training loss: 1.9231906512450545
Validation loss: 2.6404322800050575

Epoch: 5| Step: 2
Training loss: 1.980890172780266
Validation loss: 2.6334423968107123

Epoch: 5| Step: 3
Training loss: 1.5500644208995311
Validation loss: 2.5669330535662014

Epoch: 5| Step: 4
Training loss: 1.9347443827266457
Validation loss: 2.6237563054858986

Epoch: 5| Step: 5
Training loss: 1.8124333731145457
Validation loss: 2.603507627382846

Epoch: 5| Step: 6
Training loss: 2.216793540918473
Validation loss: 2.6024649400965734

Epoch: 5| Step: 7
Training loss: 2.1750008024016907
Validation loss: 2.6128778612127905

Epoch: 5| Step: 8
Training loss: 1.3998325145537518
Validation loss: 2.557308817417219

Epoch: 5| Step: 9
Training loss: 2.420829596546679
Validation loss: 2.612899839013428

Epoch: 5| Step: 10
Training loss: 2.2199978610191695
Validation loss: 2.637970076303491

Epoch: 491| Step: 0
Training loss: 1.6604840841291555
Validation loss: 2.61488195332744

Epoch: 5| Step: 1
Training loss: 1.8937973646025752
Validation loss: 2.622760035766266

Epoch: 5| Step: 2
Training loss: 2.6061245894961664
Validation loss: 2.52809060341291

Epoch: 5| Step: 3
Training loss: 2.213504339165201
Validation loss: 2.548507572834653

Epoch: 5| Step: 4
Training loss: 2.097324565329941
Validation loss: 2.5797222958028465

Epoch: 5| Step: 5
Training loss: 2.3857243990459427
Validation loss: 2.5975316541695355

Epoch: 5| Step: 6
Training loss: 1.879592357837365
Validation loss: 2.595325810168264

Epoch: 5| Step: 7
Training loss: 1.6445969955821418
Validation loss: 2.612320079280854

Epoch: 5| Step: 8
Training loss: 1.7315191865277146
Validation loss: 2.502700776311544

Epoch: 5| Step: 9
Training loss: 1.723959432027261
Validation loss: 2.6274063177497977

Epoch: 5| Step: 10
Training loss: 2.030301503496187
Validation loss: 2.584258454395303

Epoch: 492| Step: 0
Training loss: 1.7776816246070544
Validation loss: 2.6361013490405276

Epoch: 5| Step: 1
Training loss: 1.7678693162683368
Validation loss: 2.5308343122400996

Epoch: 5| Step: 2
Training loss: 1.981754525143012
Validation loss: 2.626049453100252

Epoch: 5| Step: 3
Training loss: 1.5568069503166406
Validation loss: 2.576609972120322

Epoch: 5| Step: 4
Training loss: 1.6646768931170346
Validation loss: 2.515938250885651

Epoch: 5| Step: 5
Training loss: 2.729914312869386
Validation loss: 2.5956655575665097

Epoch: 5| Step: 6
Training loss: 1.7700776526017818
Validation loss: 2.5697449023367427

Epoch: 5| Step: 7
Training loss: 1.9907527768792246
Validation loss: 2.539930417986939

Epoch: 5| Step: 8
Training loss: 1.8864191105635733
Validation loss: 2.5773755607286453

Epoch: 5| Step: 9
Training loss: 1.9802607139256152
Validation loss: 2.607704880282947

Epoch: 5| Step: 10
Training loss: 1.9897677217957979
Validation loss: 2.61631835552354

Epoch: 493| Step: 0
Training loss: 1.8965866422727276
Validation loss: 2.5999181777946454

Epoch: 5| Step: 1
Training loss: 1.990804513834718
Validation loss: 2.634731976319551

Epoch: 5| Step: 2
Training loss: 2.074552634857969
Validation loss: 2.6730319256947808

Epoch: 5| Step: 3
Training loss: 1.9950324594634405
Validation loss: 2.67863842522453

Epoch: 5| Step: 4
Training loss: 1.5815049037610087
Validation loss: 2.680027703622769

Epoch: 5| Step: 5
Training loss: 2.109575502261925
Validation loss: 2.573027886161516

Epoch: 5| Step: 6
Training loss: 2.3834444802605783
Validation loss: 2.608879115185195

Epoch: 5| Step: 7
Training loss: 2.0189752458979244
Validation loss: 2.658608907197059

Epoch: 5| Step: 8
Training loss: 2.007179011885685
Validation loss: 2.627848005557077

Epoch: 5| Step: 9
Training loss: 1.5049609164615885
Validation loss: 2.596246165877357

Epoch: 5| Step: 10
Training loss: 1.5044772562759097
Validation loss: 2.653948162559003

Epoch: 494| Step: 0
Training loss: 1.928532057567156
Validation loss: 2.673359559528154

Epoch: 5| Step: 1
Training loss: 1.4961270560200184
Validation loss: 2.5313614689448305

Epoch: 5| Step: 2
Training loss: 1.6979849709967862
Validation loss: 2.626090971058183

Epoch: 5| Step: 3
Training loss: 2.4542288270946107
Validation loss: 2.6193015461834777

Epoch: 5| Step: 4
Training loss: 2.0558984473340924
Validation loss: 2.6516956776783505

Epoch: 5| Step: 5
Training loss: 1.6280253930841293
Validation loss: 2.6116321162911746

Epoch: 5| Step: 6
Training loss: 2.1712636842005453
Validation loss: 2.6338349845325757

Epoch: 5| Step: 7
Training loss: 1.899634843169611
Validation loss: 2.6429090539519713

Epoch: 5| Step: 8
Training loss: 1.9032557375245303
Validation loss: 2.587290382544034

Epoch: 5| Step: 9
Training loss: 1.8560011571683237
Validation loss: 2.6014061086013736

Epoch: 5| Step: 10
Training loss: 2.273456481644609
Validation loss: 2.6158676460874597

Epoch: 495| Step: 0
Training loss: 2.181786623639844
Validation loss: 2.582777238019782

Epoch: 5| Step: 1
Training loss: 1.9067755428097322
Validation loss: 2.6081856064169555

Epoch: 5| Step: 2
Training loss: 1.9634204965401911
Validation loss: 2.61395832614221

Epoch: 5| Step: 3
Training loss: 2.0613439383305945
Validation loss: 2.610422172966475

Epoch: 5| Step: 4
Training loss: 1.5190063982258113
Validation loss: 2.607593424577744

Epoch: 5| Step: 5
Training loss: 1.1935649888235962
Validation loss: 2.538228381442131

Epoch: 5| Step: 6
Training loss: 2.1749892925130427
Validation loss: 2.6089043726134955

Epoch: 5| Step: 7
Training loss: 2.6995953574552876
Validation loss: 2.5901969674119734

Epoch: 5| Step: 8
Training loss: 2.026528608028447
Validation loss: 2.5902791765033966

Epoch: 5| Step: 9
Training loss: 1.7101075410767972
Validation loss: 2.666483696561926

Epoch: 5| Step: 10
Training loss: 2.1674889935804704
Validation loss: 2.5400362728158914

Epoch: 496| Step: 0
Training loss: 2.4888815642241524
Validation loss: 2.6111241972455796

Epoch: 5| Step: 1
Training loss: 1.6895831636866976
Validation loss: 2.583852733261565

Epoch: 5| Step: 2
Training loss: 2.095276006029485
Validation loss: 2.604799872089512

Epoch: 5| Step: 3
Training loss: 1.787143661086749
Validation loss: 2.676107419700959

Epoch: 5| Step: 4
Training loss: 1.9631420980277894
Validation loss: 2.565878666861395

Epoch: 5| Step: 5
Training loss: 1.6655282026437979
Validation loss: 2.574473538030506

Epoch: 5| Step: 6
Training loss: 1.7641582642098212
Validation loss: 2.570259340795467

Epoch: 5| Step: 7
Training loss: 2.1512295423085774
Validation loss: 2.6363001959661534

Epoch: 5| Step: 8
Training loss: 2.1578299221299524
Validation loss: 2.601428633681223

Epoch: 5| Step: 9
Training loss: 1.7302569050854342
Validation loss: 2.6173972748418715

Epoch: 5| Step: 10
Training loss: 1.60714745293823
Validation loss: 2.5359966761444763

Epoch: 497| Step: 0
Training loss: 1.485124418909855
Validation loss: 2.5011928450559155

Epoch: 5| Step: 1
Training loss: 2.546385642003008
Validation loss: 2.6172235507530015

Epoch: 5| Step: 2
Training loss: 2.108319166635958
Validation loss: 2.537773314169186

Epoch: 5| Step: 3
Training loss: 2.1321141703168975
Validation loss: 2.604897559851814

Epoch: 5| Step: 4
Training loss: 2.1983627903111684
Validation loss: 2.6353147922254814

Epoch: 5| Step: 5
Training loss: 1.6295696709701541
Validation loss: 2.6658614049004097

Epoch: 5| Step: 6
Training loss: 2.395208415478006
Validation loss: 2.6460752123890527

Epoch: 5| Step: 7
Training loss: 1.635105184385554
Validation loss: 2.6377039198491192

Epoch: 5| Step: 8
Training loss: 1.7097146179804141
Validation loss: 2.623967940060244

Epoch: 5| Step: 9
Training loss: 2.0257098425517257
Validation loss: 2.660142384952057

Epoch: 5| Step: 10
Training loss: 1.8309490854964865
Validation loss: 2.6529672700999676

Epoch: 498| Step: 0
Training loss: 2.1364828533945976
Validation loss: 2.590706796481808

Epoch: 5| Step: 1
Training loss: 2.4569651681234363
Validation loss: 2.6780482566165538

Epoch: 5| Step: 2
Training loss: 1.8246104699999055
Validation loss: 2.5856657530738563

Epoch: 5| Step: 3
Training loss: 1.464987948631739
Validation loss: 2.6391711984460904

Epoch: 5| Step: 4
Training loss: 1.8873088537780323
Validation loss: 2.6003191508511794

Epoch: 5| Step: 5
Training loss: 1.7829228626965812
Validation loss: 2.560148071711392

Epoch: 5| Step: 6
Training loss: 1.6289628931529678
Validation loss: 2.614409348064426

Epoch: 5| Step: 7
Training loss: 2.3652490919365636
Validation loss: 2.654915107818399

Epoch: 5| Step: 8
Training loss: 1.5939281588438734
Validation loss: 2.5688147364022718

Epoch: 5| Step: 9
Training loss: 1.9970401080769065
Validation loss: 2.5817784013739256

Epoch: 5| Step: 10
Training loss: 1.8981722422710023
Validation loss: 2.6027762664029295

Epoch: 499| Step: 0
Training loss: 1.6976563735870582
Validation loss: 2.60076721860079

Epoch: 5| Step: 1
Training loss: 2.13742237953998
Validation loss: 2.6090094059885782

Epoch: 5| Step: 2
Training loss: 1.9329343345685985
Validation loss: 2.597576832519143

Epoch: 5| Step: 3
Training loss: 2.053140151898404
Validation loss: 2.569848347936078

Epoch: 5| Step: 4
Training loss: 1.9835113087575262
Validation loss: 2.585487537986471

Epoch: 5| Step: 5
Training loss: 2.156270234386208
Validation loss: 2.6827501981303956

Epoch: 5| Step: 6
Training loss: 1.3844295034593954
Validation loss: 2.613358104685513

Epoch: 5| Step: 7
Training loss: 1.5374966318977494
Validation loss: 2.7327631752520993

Epoch: 5| Step: 8
Training loss: 2.2319786185741055
Validation loss: 2.627117510024507

Epoch: 5| Step: 9
Training loss: 1.6853814425125688
Validation loss: 2.6482341525066126

Epoch: 5| Step: 10
Training loss: 2.9553658193461714
Validation loss: 2.6286496380296978

Epoch: 500| Step: 0
Training loss: 2.469503456738917
Validation loss: 2.533981105739021

Epoch: 5| Step: 1
Training loss: 2.4492668378328473
Validation loss: 2.529243866322276

Epoch: 5| Step: 2
Training loss: 1.7917038521862951
Validation loss: 2.6118891261705253

Epoch: 5| Step: 3
Training loss: 1.8417613409342262
Validation loss: 2.5690177117094826

Epoch: 5| Step: 4
Training loss: 1.549035615239454
Validation loss: 2.6297464834945066

Epoch: 5| Step: 5
Training loss: 1.8018378015145866
Validation loss: 2.558042478473587

Epoch: 5| Step: 6
Training loss: 1.7334161805870076
Validation loss: 2.5663888846746215

Epoch: 5| Step: 7
Training loss: 2.112876190457835
Validation loss: 2.5980004271883996

Epoch: 5| Step: 8
Training loss: 1.6602745103788838
Validation loss: 2.583127107503138

Epoch: 5| Step: 9
Training loss: 1.9365811168643141
Validation loss: 2.579601902202247

Epoch: 5| Step: 10
Training loss: 2.237010548511748
Validation loss: 2.582010746998997

Epoch: 501| Step: 0
Training loss: 1.7663844003047278
Validation loss: 2.617678180185309

Epoch: 5| Step: 1
Training loss: 2.5412943728917283
Validation loss: 2.5679650005673085

Epoch: 5| Step: 2
Training loss: 1.829286190232282
Validation loss: 2.6329412664054344

Epoch: 5| Step: 3
Training loss: 2.4141188926653103
Validation loss: 2.6232873893724986

Epoch: 5| Step: 4
Training loss: 1.6533349493362364
Validation loss: 2.6426127894080302

Epoch: 5| Step: 5
Training loss: 1.9062244851327785
Validation loss: 2.580006368085019

Epoch: 5| Step: 6
Training loss: 1.7454777597514635
Validation loss: 2.6716236129850652

Epoch: 5| Step: 7
Training loss: 2.057501428911865
Validation loss: 2.5548388059485974

Epoch: 5| Step: 8
Training loss: 1.4319943853566581
Validation loss: 2.6166360900212706

Epoch: 5| Step: 9
Training loss: 1.5721517391304283
Validation loss: 2.559816342318888

Epoch: 5| Step: 10
Training loss: 2.1679158522192385
Validation loss: 2.585657835087768

Epoch: 502| Step: 0
Training loss: 2.378410199943045
Validation loss: 2.610779166658357

Epoch: 5| Step: 1
Training loss: 1.7437597459090046
Validation loss: 2.640286732619838

Epoch: 5| Step: 2
Training loss: 1.95233382412943
Validation loss: 2.646185860093574

Epoch: 5| Step: 3
Training loss: 2.336234287558143
Validation loss: 2.6893687808611975

Epoch: 5| Step: 4
Training loss: 1.7369087201140008
Validation loss: 2.570951652931986

Epoch: 5| Step: 5
Training loss: 2.0602617545628648
Validation loss: 2.619825173877678

Epoch: 5| Step: 6
Training loss: 1.6564457615736037
Validation loss: 2.5803406503048203

Epoch: 5| Step: 7
Training loss: 1.8074962342620076
Validation loss: 2.6731880519865223

Epoch: 5| Step: 8
Training loss: 1.967498502621693
Validation loss: 2.6688694111185454

Epoch: 5| Step: 9
Training loss: 1.4167143682788856
Validation loss: 2.6673418992397635

Epoch: 5| Step: 10
Training loss: 2.146457717077411
Validation loss: 2.6265879748597745

Epoch: 503| Step: 0
Training loss: 1.675107024460227
Validation loss: 2.667193317193725

Epoch: 5| Step: 1
Training loss: 1.825135354026204
Validation loss: 2.651617908197983

Epoch: 5| Step: 2
Training loss: 2.3057965212706133
Validation loss: 2.625543265665293

Epoch: 5| Step: 3
Training loss: 2.128932903717897
Validation loss: 2.6359410780533303

Epoch: 5| Step: 4
Training loss: 1.8781983753158729
Validation loss: 2.646579377253309

Epoch: 5| Step: 5
Training loss: 1.9414558634568484
Validation loss: 2.515297221935647

Epoch: 5| Step: 6
Training loss: 1.8502934609741324
Validation loss: 2.661670230797314

Epoch: 5| Step: 7
Training loss: 2.1225515733615494
Validation loss: 2.5886424144419165

Epoch: 5| Step: 8
Training loss: 1.686527890551265
Validation loss: 2.6023586618927643

Epoch: 5| Step: 9
Training loss: 1.6451277206139858
Validation loss: 2.586354749086171

Epoch: 5| Step: 10
Training loss: 2.4204222228838566
Validation loss: 2.6201736333856642

Epoch: 504| Step: 0
Training loss: 2.578944775265579
Validation loss: 2.599924937135713

Epoch: 5| Step: 1
Training loss: 1.6624247053491477
Validation loss: 2.594912848879761

Epoch: 5| Step: 2
Training loss: 1.9650350974251194
Validation loss: 2.6676669596829887

Epoch: 5| Step: 3
Training loss: 2.060190005382117
Validation loss: 2.6118301278577043

Epoch: 5| Step: 4
Training loss: 1.4828625653480403
Validation loss: 2.6284294842537057

Epoch: 5| Step: 5
Training loss: 2.1346973851527475
Validation loss: 2.670162255249797

Epoch: 5| Step: 6
Training loss: 1.9640205129962292
Validation loss: 2.6181040804936853

Epoch: 5| Step: 7
Training loss: 1.9512511763242295
Validation loss: 2.594007345618864

Epoch: 5| Step: 8
Training loss: 1.7891086755648935
Validation loss: 2.584398089590663

Epoch: 5| Step: 9
Training loss: 1.8977672508319028
Validation loss: 2.630295927688181

Epoch: 5| Step: 10
Training loss: 1.8642741183111877
Validation loss: 2.5637288362330857

Epoch: 505| Step: 0
Training loss: 2.520718931854689
Validation loss: 2.58253554973827

Epoch: 5| Step: 1
Training loss: 2.2234724051442574
Validation loss: 2.6566679874781824

Epoch: 5| Step: 2
Training loss: 1.9970207674554097
Validation loss: 2.6848669677881034

Epoch: 5| Step: 3
Training loss: 1.9333056919270424
Validation loss: 2.6896486462018974

Epoch: 5| Step: 4
Training loss: 2.0931492413324184
Validation loss: 2.657068349208131

Epoch: 5| Step: 5
Training loss: 1.9727423016503456
Validation loss: 2.569953840321689

Epoch: 5| Step: 6
Training loss: 1.7619733605292454
Validation loss: 2.6208396851940496

Epoch: 5| Step: 7
Training loss: 1.9220222478763838
Validation loss: 2.5834159308601925

Epoch: 5| Step: 8
Training loss: 2.0182280772216483
Validation loss: 2.5611653457584906

Epoch: 5| Step: 9
Training loss: 1.6052326854894272
Validation loss: 2.6255419318712385

Epoch: 5| Step: 10
Training loss: 1.5137105432308895
Validation loss: 2.6458249145663264

Epoch: 506| Step: 0
Training loss: 2.022186481709608
Validation loss: 2.631867957536328

Epoch: 5| Step: 1
Training loss: 2.3025680883158626
Validation loss: 2.6145313795263796

Epoch: 5| Step: 2
Training loss: 1.6731629446498524
Validation loss: 2.608851811102714

Epoch: 5| Step: 3
Training loss: 1.7354258884705447
Validation loss: 2.671937412256716

Epoch: 5| Step: 4
Training loss: 2.408817556292035
Validation loss: 2.667188320038077

Epoch: 5| Step: 5
Training loss: 1.8370155578187053
Validation loss: 2.6048670880563605

Epoch: 5| Step: 6
Training loss: 1.965740143476758
Validation loss: 2.719636928266714

Epoch: 5| Step: 7
Training loss: 1.805077052492716
Validation loss: 2.713681482863622

Epoch: 5| Step: 8
Training loss: 1.8975769101766073
Validation loss: 2.63777250161249

Epoch: 5| Step: 9
Training loss: 2.074090698657444
Validation loss: 2.662315611227109

Epoch: 5| Step: 10
Training loss: 1.9437868194527272
Validation loss: 2.6715088248984125

Epoch: 507| Step: 0
Training loss: 2.042274254938659
Validation loss: 2.6963404424719317

Epoch: 5| Step: 1
Training loss: 2.0770093174497193
Validation loss: 2.66441626312953

Epoch: 5| Step: 2
Training loss: 1.5750272960416805
Validation loss: 2.633618833785306

Epoch: 5| Step: 3
Training loss: 1.911507282791014
Validation loss: 2.587730532349714

Epoch: 5| Step: 4
Training loss: 1.725216163691496
Validation loss: 2.6924967701837206

Epoch: 5| Step: 5
Training loss: 1.9622970063013732
Validation loss: 2.5995970558127377

Epoch: 5| Step: 6
Training loss: 1.9597127060629487
Validation loss: 2.6101552371375396

Epoch: 5| Step: 7
Training loss: 2.366274112955391
Validation loss: 2.6636423119947383

Epoch: 5| Step: 8
Training loss: 1.687456624921788
Validation loss: 2.5646186062135214

Epoch: 5| Step: 9
Training loss: 1.8615559841757268
Validation loss: 2.591804515078308

Epoch: 5| Step: 10
Training loss: 2.0381630269246154
Validation loss: 2.5607731200456727

Epoch: 508| Step: 0
Training loss: 1.4672865374109556
Validation loss: 2.572606798470392

Epoch: 5| Step: 1
Training loss: 2.190802996011733
Validation loss: 2.6245099912667795

Epoch: 5| Step: 2
Training loss: 2.3559378541156035
Validation loss: 2.6285510423312783

Epoch: 5| Step: 3
Training loss: 2.194554099496678
Validation loss: 2.57589432664994

Epoch: 5| Step: 4
Training loss: 1.8829598903344698
Validation loss: 2.6305834002134523

Epoch: 5| Step: 5
Training loss: 1.6498503212518372
Validation loss: 2.5864293847205135

Epoch: 5| Step: 6
Training loss: 1.391815832942011
Validation loss: 2.619803222860399

Epoch: 5| Step: 7
Training loss: 2.046400874313514
Validation loss: 2.5994143459053043

Epoch: 5| Step: 8
Training loss: 2.2639402241987567
Validation loss: 2.545936387862329

Epoch: 5| Step: 9
Training loss: 2.2624504210377316
Validation loss: 2.6409832053156532

Epoch: 5| Step: 10
Training loss: 1.513215263160851
Validation loss: 2.655865072291889

Epoch: 509| Step: 0
Training loss: 1.4710517054792742
Validation loss: 2.5940612139741157

Epoch: 5| Step: 1
Training loss: 2.09708719331126
Validation loss: 2.6310846026306742

Epoch: 5| Step: 2
Training loss: 1.6517881356593467
Validation loss: 2.625730466606178

Epoch: 5| Step: 3
Training loss: 1.9580773395931963
Validation loss: 2.6104677940628145

Epoch: 5| Step: 4
Training loss: 2.1275822153130206
Validation loss: 2.670791736446706

Epoch: 5| Step: 5
Training loss: 1.4538885592081794
Validation loss: 2.685575131205211

Epoch: 5| Step: 6
Training loss: 2.38185095225126
Validation loss: 2.759858590238631

Epoch: 5| Step: 7
Training loss: 2.012340027510764
Validation loss: 2.6517358253844567

Epoch: 5| Step: 8
Training loss: 1.7522328301273071
Validation loss: 2.7126657177794544

Epoch: 5| Step: 9
Training loss: 2.0983226435083253
Validation loss: 2.6656529713569306

Epoch: 5| Step: 10
Training loss: 1.91694735116552
Validation loss: 2.7116251406107623

Epoch: 510| Step: 0
Training loss: 1.517113731154473
Validation loss: 2.682564580413863

Epoch: 5| Step: 1
Training loss: 1.7399143048811565
Validation loss: 2.664331223587472

Epoch: 5| Step: 2
Training loss: 1.7655418173851185
Validation loss: 2.7077658924145

Epoch: 5| Step: 3
Training loss: 1.7450693697107114
Validation loss: 2.6597549728264513

Epoch: 5| Step: 4
Training loss: 1.7431748675698036
Validation loss: 2.599524254851173

Epoch: 5| Step: 5
Training loss: 1.9465775876479408
Validation loss: 2.6300950779630003

Epoch: 5| Step: 6
Training loss: 2.70218549509284
Validation loss: 2.606926862906904

Epoch: 5| Step: 7
Training loss: 2.0542482552049184
Validation loss: 2.6098717696887177

Epoch: 5| Step: 8
Training loss: 1.843190253684979
Validation loss: 2.5499797900470926

Epoch: 5| Step: 9
Training loss: 1.695103645644218
Validation loss: 2.599058376481802

Epoch: 5| Step: 10
Training loss: 2.0019374046638876
Validation loss: 2.6125261206051413

Epoch: 511| Step: 0
Training loss: 1.81379778209504
Validation loss: 2.644057091292029

Epoch: 5| Step: 1
Training loss: 1.905008756161889
Validation loss: 2.659411092306266

Epoch: 5| Step: 2
Training loss: 1.7974309310058203
Validation loss: 2.6108082335311127

Epoch: 5| Step: 3
Training loss: 1.964746795142992
Validation loss: 2.6077009950598082

Epoch: 5| Step: 4
Training loss: 1.9825953515730899
Validation loss: 2.6368425130719646

Epoch: 5| Step: 5
Training loss: 1.7304935496600498
Validation loss: 2.535013139922102

Epoch: 5| Step: 6
Training loss: 2.5369061982613497
Validation loss: 2.664360464926047

Epoch: 5| Step: 7
Training loss: 1.6667879378385606
Validation loss: 2.6185627423888937

Epoch: 5| Step: 8
Training loss: 1.5447963272953873
Validation loss: 2.6034535428766246

Epoch: 5| Step: 9
Training loss: 1.7067583158342698
Validation loss: 2.603644130006245

Epoch: 5| Step: 10
Training loss: 2.3171123181195803
Validation loss: 2.5755245593969627

Epoch: 512| Step: 0
Training loss: 2.3234256705603156
Validation loss: 2.6170775442912615

Epoch: 5| Step: 1
Training loss: 1.628161362957654
Validation loss: 2.6283403639706155

Epoch: 5| Step: 2
Training loss: 1.8598398220658856
Validation loss: 2.6386615433600005

Epoch: 5| Step: 3
Training loss: 2.2718749034519514
Validation loss: 2.6185541112827053

Epoch: 5| Step: 4
Training loss: 1.8831453780962228
Validation loss: 2.6063271152941354

Epoch: 5| Step: 5
Training loss: 1.8124703371975015
Validation loss: 2.553638321208325

Epoch: 5| Step: 6
Training loss: 2.0415311755421346
Validation loss: 2.6652659889455843

Epoch: 5| Step: 7
Training loss: 2.201535997847161
Validation loss: 2.6573150970111246

Epoch: 5| Step: 8
Training loss: 1.0523086281447083
Validation loss: 2.608212850389939

Epoch: 5| Step: 9
Training loss: 2.0095468592973678
Validation loss: 2.6014363075570026

Epoch: 5| Step: 10
Training loss: 1.7840798636637374
Validation loss: 2.6510491798456073

Epoch: 513| Step: 0
Training loss: 1.1842365596653597
Validation loss: 2.657525694218587

Epoch: 5| Step: 1
Training loss: 1.275545867304574
Validation loss: 2.610223052795765

Epoch: 5| Step: 2
Training loss: 2.024239870739328
Validation loss: 2.6224842174968592

Epoch: 5| Step: 3
Training loss: 2.0841679872033003
Validation loss: 2.6160274485779085

Epoch: 5| Step: 4
Training loss: 1.4730270283246423
Validation loss: 2.6938474330845392

Epoch: 5| Step: 5
Training loss: 1.8133072863956705
Validation loss: 2.582571448897752

Epoch: 5| Step: 6
Training loss: 2.0945007344761644
Validation loss: 2.6453596903466314

Epoch: 5| Step: 7
Training loss: 2.051014681655213
Validation loss: 2.564697337970181

Epoch: 5| Step: 8
Training loss: 1.699596284164062
Validation loss: 2.624700992155245

Epoch: 5| Step: 9
Training loss: 2.539161656717688
Validation loss: 2.635280617454502

Epoch: 5| Step: 10
Training loss: 2.1636097568700308
Validation loss: 2.5604056546879668

Epoch: 514| Step: 0
Training loss: 1.951547214274104
Validation loss: 2.6086225873387208

Epoch: 5| Step: 1
Training loss: 2.4342115668108737
Validation loss: 2.6021497953438097

Epoch: 5| Step: 2
Training loss: 1.672973058311478
Validation loss: 2.6121391376874836

Epoch: 5| Step: 3
Training loss: 2.1184517439495454
Validation loss: 2.5907193301246685

Epoch: 5| Step: 4
Training loss: 1.7795120594873304
Validation loss: 2.6440519214546314

Epoch: 5| Step: 5
Training loss: 2.214564068609678
Validation loss: 2.6505217234606473

Epoch: 5| Step: 6
Training loss: 1.6929834778008224
Validation loss: 2.581529835925085

Epoch: 5| Step: 7
Training loss: 1.4825921846647692
Validation loss: 2.6847410012465662

Epoch: 5| Step: 8
Training loss: 1.6856738205156279
Validation loss: 2.6388552427350738

Epoch: 5| Step: 9
Training loss: 1.8219929416490463
Validation loss: 2.6868662295552226

Epoch: 5| Step: 10
Training loss: 2.09746495232383
Validation loss: 2.594878185482047

Epoch: 515| Step: 0
Training loss: 1.6533614106768022
Validation loss: 2.626690813703884

Epoch: 5| Step: 1
Training loss: 2.0991477281363013
Validation loss: 2.623764897983146

Epoch: 5| Step: 2
Training loss: 1.996993666392881
Validation loss: 2.5800653459048455

Epoch: 5| Step: 3
Training loss: 1.4200530063783086
Validation loss: 2.7052860881230343

Epoch: 5| Step: 4
Training loss: 2.356119398145317
Validation loss: 2.6440699150048506

Epoch: 5| Step: 5
Training loss: 1.7205868702303388
Validation loss: 2.5731984190514705

Epoch: 5| Step: 6
Training loss: 1.6616101170708921
Validation loss: 2.5628594797390525

Epoch: 5| Step: 7
Training loss: 1.5757121913077323
Validation loss: 2.624306254558256

Epoch: 5| Step: 8
Training loss: 2.134478801923171
Validation loss: 2.6356254519901468

Epoch: 5| Step: 9
Training loss: 1.6473565919367046
Validation loss: 2.6370824818033958

Epoch: 5| Step: 10
Training loss: 2.5957913925513734
Validation loss: 2.582828854204968

Epoch: 516| Step: 0
Training loss: 1.6613257025354136
Validation loss: 2.6907613777569135

Epoch: 5| Step: 1
Training loss: 1.433798959789093
Validation loss: 2.6308209170794483

Epoch: 5| Step: 2
Training loss: 1.6439059194436316
Validation loss: 2.640169041570506

Epoch: 5| Step: 3
Training loss: 2.238492892446816
Validation loss: 2.6609832238139663

Epoch: 5| Step: 4
Training loss: 2.113801959012203
Validation loss: 2.6541382938887277

Epoch: 5| Step: 5
Training loss: 2.6080721040833317
Validation loss: 2.6210771519216856

Epoch: 5| Step: 6
Training loss: 1.5216899532167198
Validation loss: 2.5873615866924267

Epoch: 5| Step: 7
Training loss: 2.174015664290748
Validation loss: 2.6322851525903905

Epoch: 5| Step: 8
Training loss: 1.6234125306134028
Validation loss: 2.677439894803131

Epoch: 5| Step: 9
Training loss: 2.0316707468761166
Validation loss: 2.6015408087690868

Epoch: 5| Step: 10
Training loss: 1.7919245319951644
Validation loss: 2.655303958402617

Epoch: 517| Step: 0
Training loss: 1.9459959001723381
Validation loss: 2.654475542673477

Epoch: 5| Step: 1
Training loss: 1.5581064633683366
Validation loss: 2.6454259474669337

Epoch: 5| Step: 2
Training loss: 1.8216961362269342
Validation loss: 2.6506054506031833

Epoch: 5| Step: 3
Training loss: 2.1102784659150635
Validation loss: 2.6454773898353987

Epoch: 5| Step: 4
Training loss: 2.1618630149136333
Validation loss: 2.584018285677945

Epoch: 5| Step: 5
Training loss: 2.865636421605169
Validation loss: 2.717519584254858

Epoch: 5| Step: 6
Training loss: 2.039223032511271
Validation loss: 2.6068985891441594

Epoch: 5| Step: 7
Training loss: 1.7345396084038982
Validation loss: 2.654562355260298

Epoch: 5| Step: 8
Training loss: 1.7713579261004844
Validation loss: 2.6033371995292662

Epoch: 5| Step: 9
Training loss: 2.1105851834477933
Validation loss: 2.6408017094466807

Epoch: 5| Step: 10
Training loss: 1.1418565868277404
Validation loss: 2.6057006577265738

Epoch: 518| Step: 0
Training loss: 2.168587481211162
Validation loss: 2.673361940620828

Epoch: 5| Step: 1
Training loss: 1.76482758195892
Validation loss: 2.6631977940700127

Epoch: 5| Step: 2
Training loss: 1.5783580947808098
Validation loss: 2.606164297164004

Epoch: 5| Step: 3
Training loss: 2.1686542149039805
Validation loss: 2.647915011955729

Epoch: 5| Step: 4
Training loss: 1.5002250502561325
Validation loss: 2.6229642209768587

Epoch: 5| Step: 5
Training loss: 2.50772360765961
Validation loss: 2.615737639315531

Epoch: 5| Step: 6
Training loss: 1.7485716303835057
Validation loss: 2.5093983064717293

Epoch: 5| Step: 7
Training loss: 2.0876908951693958
Validation loss: 2.6572335667979194

Epoch: 5| Step: 8
Training loss: 2.19490519916305
Validation loss: 2.6141555377978123

Epoch: 5| Step: 9
Training loss: 1.5372274079622323
Validation loss: 2.6965301906568664

Epoch: 5| Step: 10
Training loss: 1.4406260624879572
Validation loss: 2.653974250446977

Epoch: 519| Step: 0
Training loss: 2.056315774068542
Validation loss: 2.651403714309881

Epoch: 5| Step: 1
Training loss: 1.661971663654653
Validation loss: 2.549903667785028

Epoch: 5| Step: 2
Training loss: 1.6948434207128524
Validation loss: 2.6093867621409395

Epoch: 5| Step: 3
Training loss: 1.864235943305791
Validation loss: 2.6187385460348587

Epoch: 5| Step: 4
Training loss: 1.8217366422852137
Validation loss: 2.6481691268602545

Epoch: 5| Step: 5
Training loss: 1.8462998167431162
Validation loss: 2.6853637303524205

Epoch: 5| Step: 6
Training loss: 2.0825537049328267
Validation loss: 2.5856999138592136

Epoch: 5| Step: 7
Training loss: 2.0024620637383936
Validation loss: 2.6026603380037017

Epoch: 5| Step: 8
Training loss: 1.6780704965389177
Validation loss: 2.5738015455247107

Epoch: 5| Step: 9
Training loss: 1.9589367876900172
Validation loss: 2.6682068820844984

Epoch: 5| Step: 10
Training loss: 1.5261595054498167
Validation loss: 2.597648063607909

Epoch: 520| Step: 0
Training loss: 1.9689639141792228
Validation loss: 2.6750449442775115

Epoch: 5| Step: 1
Training loss: 2.313499647019695
Validation loss: 2.659859286831759

Epoch: 5| Step: 2
Training loss: 1.8327730218484444
Validation loss: 2.6559748049206133

Epoch: 5| Step: 3
Training loss: 2.1428300401699354
Validation loss: 2.569871201495598

Epoch: 5| Step: 4
Training loss: 1.6361312358002058
Validation loss: 2.6684016196947073

Epoch: 5| Step: 5
Training loss: 1.7680262213656917
Validation loss: 2.622437000832379

Epoch: 5| Step: 6
Training loss: 1.8658197093680329
Validation loss: 2.6333923869704603

Epoch: 5| Step: 7
Training loss: 1.681506923628388
Validation loss: 2.6413578813218246

Epoch: 5| Step: 8
Training loss: 1.8727284977312113
Validation loss: 2.6259262269348436

Epoch: 5| Step: 9
Training loss: 2.4685352087138956
Validation loss: 2.587363580245627

Epoch: 5| Step: 10
Training loss: 1.5914114456204307
Validation loss: 2.590340121505379

Epoch: 521| Step: 0
Training loss: 2.084485523776605
Validation loss: 2.588695156534721

Epoch: 5| Step: 1
Training loss: 1.520723791836953
Validation loss: 2.5698449431782477

Epoch: 5| Step: 2
Training loss: 1.6983445297386262
Validation loss: 2.622764461697287

Epoch: 5| Step: 3
Training loss: 2.101116601089647
Validation loss: 2.544963929723173

Epoch: 5| Step: 4
Training loss: 2.4493720631777713
Validation loss: 2.5732054797181187

Epoch: 5| Step: 5
Training loss: 1.8793920574930134
Validation loss: 2.5889940321939426

Epoch: 5| Step: 6
Training loss: 1.8198339791083509
Validation loss: 2.504619071064132

Epoch: 5| Step: 7
Training loss: 1.8634083702501278
Validation loss: 2.60686893042323

Epoch: 5| Step: 8
Training loss: 1.7095379265335033
Validation loss: 2.5704837625692987

Epoch: 5| Step: 9
Training loss: 1.9458872853654197
Validation loss: 2.5665875559988205

Epoch: 5| Step: 10
Training loss: 2.1375276753379575
Validation loss: 2.5396204898354426

Epoch: 522| Step: 0
Training loss: 1.958518310359998
Validation loss: 2.591291388874987

Epoch: 5| Step: 1
Training loss: 1.8401295304316159
Validation loss: 2.705177794727812

Epoch: 5| Step: 2
Training loss: 1.930570824956847
Validation loss: 2.6389274813109997

Epoch: 5| Step: 3
Training loss: 1.8681329863177518
Validation loss: 2.603172388736015

Epoch: 5| Step: 4
Training loss: 1.6399954178211118
Validation loss: 2.5689185338105194

Epoch: 5| Step: 5
Training loss: 1.9794206422843938
Validation loss: 2.5799327827817544

Epoch: 5| Step: 6
Training loss: 1.8137875949110263
Validation loss: 2.560324765340006

Epoch: 5| Step: 7
Training loss: 1.5737456943250057
Validation loss: 2.5674792469197723

Epoch: 5| Step: 8
Training loss: 1.7445508724327121
Validation loss: 2.6447396828404286

Epoch: 5| Step: 9
Training loss: 1.531477930660318
Validation loss: 2.638933189666454

Epoch: 5| Step: 10
Training loss: 2.111579251947665
Validation loss: 2.590675424505914

Epoch: 523| Step: 0
Training loss: 1.0824394144807474
Validation loss: 2.588722093141111

Epoch: 5| Step: 1
Training loss: 1.502222163556516
Validation loss: 2.648164818898957

Epoch: 5| Step: 2
Training loss: 1.5767453649987122
Validation loss: 2.7120132460942683

Epoch: 5| Step: 3
Training loss: 2.2633276505696225
Validation loss: 2.6386318044499038

Epoch: 5| Step: 4
Training loss: 2.2552911216099996
Validation loss: 2.6328748742657537

Epoch: 5| Step: 5
Training loss: 1.7771397064796104
Validation loss: 2.6500407581286805

Epoch: 5| Step: 6
Training loss: 2.0855703423653926
Validation loss: 2.615549536935789

Epoch: 5| Step: 7
Training loss: 2.458269592579509
Validation loss: 2.6295369733467258

Epoch: 5| Step: 8
Training loss: 1.9222646178762475
Validation loss: 2.6976920774894673

Epoch: 5| Step: 9
Training loss: 2.2163372622037385
Validation loss: 2.591028401894316

Epoch: 5| Step: 10
Training loss: 1.8719693804910302
Validation loss: 2.601529386605829

Epoch: 524| Step: 0
Training loss: 1.6991979838889135
Validation loss: 2.643493511746546

Epoch: 5| Step: 1
Training loss: 1.8362205774119658
Validation loss: 2.6350101279142137

Epoch: 5| Step: 2
Training loss: 1.5019191544638513
Validation loss: 2.563580898054341

Epoch: 5| Step: 3
Training loss: 1.5332139324609142
Validation loss: 2.5624179461788192

Epoch: 5| Step: 4
Training loss: 1.6687465167634308
Validation loss: 2.6144691520467576

Epoch: 5| Step: 5
Training loss: 1.6237931538427777
Validation loss: 2.580503377108707

Epoch: 5| Step: 6
Training loss: 1.70994058070764
Validation loss: 2.6374356151024427

Epoch: 5| Step: 7
Training loss: 2.1898415158900373
Validation loss: 2.6991082081230453

Epoch: 5| Step: 8
Training loss: 1.8918132358294895
Validation loss: 2.585503679381477

Epoch: 5| Step: 9
Training loss: 2.1693796876215425
Validation loss: 2.6102054250388402

Epoch: 5| Step: 10
Training loss: 2.6276486975554576
Validation loss: 2.577302061453725

Epoch: 525| Step: 0
Training loss: 2.030946210005221
Validation loss: 2.6316945253000763

Epoch: 5| Step: 1
Training loss: 2.083652344756926
Validation loss: 2.641275994430466

Epoch: 5| Step: 2
Training loss: 1.9814848992241327
Validation loss: 2.5743636370715772

Epoch: 5| Step: 3
Training loss: 1.9034054278645147
Validation loss: 2.679829897230717

Epoch: 5| Step: 4
Training loss: 2.2534028917595568
Validation loss: 2.7013318156965633

Epoch: 5| Step: 5
Training loss: 2.2184781190017957
Validation loss: 2.6760416865674634

Epoch: 5| Step: 6
Training loss: 1.4751513161065093
Validation loss: 2.6301172559709123

Epoch: 5| Step: 7
Training loss: 1.8269192232253477
Validation loss: 2.6911141032379247

Epoch: 5| Step: 8
Training loss: 1.4270078634461116
Validation loss: 2.598385610739344

Epoch: 5| Step: 9
Training loss: 1.5503443335486888
Validation loss: 2.5834333196682175

Epoch: 5| Step: 10
Training loss: 1.4782824313501053
Validation loss: 2.6445405796057497

Epoch: 526| Step: 0
Training loss: 1.509500694964648
Validation loss: 2.4775421988339392

Epoch: 5| Step: 1
Training loss: 2.2476181562720585
Validation loss: 2.5961631977604807

Epoch: 5| Step: 2
Training loss: 2.4848457706109537
Validation loss: 2.5655607826625917

Epoch: 5| Step: 3
Training loss: 1.7024855506944798
Validation loss: 2.6297077226848593

Epoch: 5| Step: 4
Training loss: 2.276145554418676
Validation loss: 2.6724604174162367

Epoch: 5| Step: 5
Training loss: 1.4928016397401773
Validation loss: 2.5975540638187424

Epoch: 5| Step: 6
Training loss: 1.9716633630221312
Validation loss: 2.6767831810227163

Epoch: 5| Step: 7
Training loss: 1.6375147811571964
Validation loss: 2.6174666061063134

Epoch: 5| Step: 8
Training loss: 2.001860349412772
Validation loss: 2.5431693133951097

Epoch: 5| Step: 9
Training loss: 1.4142734096316603
Validation loss: 2.6552440468484053

Epoch: 5| Step: 10
Training loss: 1.730711013678847
Validation loss: 2.6624257072479933

Epoch: 527| Step: 0
Training loss: 1.7062148317618222
Validation loss: 2.606500866325191

Epoch: 5| Step: 1
Training loss: 1.6959255533973228
Validation loss: 2.6200182149376494

Epoch: 5| Step: 2
Training loss: 1.730571115191487
Validation loss: 2.6307884009591684

Epoch: 5| Step: 3
Training loss: 2.1016750376466833
Validation loss: 2.6738867563053788

Epoch: 5| Step: 4
Training loss: 2.1781016497680756
Validation loss: 2.6502448593599874

Epoch: 5| Step: 5
Training loss: 2.632645417749866
Validation loss: 2.607146539330915

Epoch: 5| Step: 6
Training loss: 1.6002612526510944
Validation loss: 2.6721776735553275

Epoch: 5| Step: 7
Training loss: 1.9270596545714982
Validation loss: 2.6337560369590776

Epoch: 5| Step: 8
Training loss: 1.7475002691571597
Validation loss: 2.67976755112153

Epoch: 5| Step: 9
Training loss: 1.5916612438622149
Validation loss: 2.6614507480767946

Epoch: 5| Step: 10
Training loss: 1.6624442098334355
Validation loss: 2.55255506289809

Epoch: 528| Step: 0
Training loss: 1.5615098486255974
Validation loss: 2.6765145697191857

Epoch: 5| Step: 1
Training loss: 1.3741839761763865
Validation loss: 2.662461428546068

Epoch: 5| Step: 2
Training loss: 1.8452043131769835
Validation loss: 2.6270894642957323

Epoch: 5| Step: 3
Training loss: 2.4289017661008185
Validation loss: 2.5958910261054533

Epoch: 5| Step: 4
Training loss: 1.9375909353266267
Validation loss: 2.614493620795608

Epoch: 5| Step: 5
Training loss: 2.1141795507310848
Validation loss: 2.556170187308222

Epoch: 5| Step: 6
Training loss: 1.7736785993661555
Validation loss: 2.5979815096651206

Epoch: 5| Step: 7
Training loss: 1.806221974297337
Validation loss: 2.671354043341604

Epoch: 5| Step: 8
Training loss: 2.020085330709366
Validation loss: 2.57112677952253

Epoch: 5| Step: 9
Training loss: 1.752938188197529
Validation loss: 2.690694473404618

Epoch: 5| Step: 10
Training loss: 1.674489552736084
Validation loss: 2.6354329617241468

Epoch: 529| Step: 0
Training loss: 1.6260344807158325
Validation loss: 2.62853929182276

Epoch: 5| Step: 1
Training loss: 1.4070558570180065
Validation loss: 2.6241618184055775

Epoch: 5| Step: 2
Training loss: 2.1298243791417
Validation loss: 2.6396189729082096

Epoch: 5| Step: 3
Training loss: 1.7557296959638482
Validation loss: 2.606055446384552

Epoch: 5| Step: 4
Training loss: 2.310635614182453
Validation loss: 2.6590861245961572

Epoch: 5| Step: 5
Training loss: 2.3879333502255937
Validation loss: 2.6393992280448955

Epoch: 5| Step: 6
Training loss: 2.1154591167108614
Validation loss: 2.625406459390739

Epoch: 5| Step: 7
Training loss: 1.630322762110247
Validation loss: 2.643728692979241

Epoch: 5| Step: 8
Training loss: 1.3894918732901358
Validation loss: 2.6374016418064

Epoch: 5| Step: 9
Training loss: 1.7635422972670312
Validation loss: 2.6611983493736475

Epoch: 5| Step: 10
Training loss: 2.078212191251229
Validation loss: 2.608618607172121

Epoch: 530| Step: 0
Training loss: 1.5947720859288137
Validation loss: 2.663335297052074

Epoch: 5| Step: 1
Training loss: 2.639174926603557
Validation loss: 2.692567860013668

Epoch: 5| Step: 2
Training loss: 1.398462178103112
Validation loss: 2.690998580826458

Epoch: 5| Step: 3
Training loss: 1.6719461586327902
Validation loss: 2.6093902125684845

Epoch: 5| Step: 4
Training loss: 1.7446474233947695
Validation loss: 2.596018748190422

Epoch: 5| Step: 5
Training loss: 2.2311081913354385
Validation loss: 2.70322973155267

Epoch: 5| Step: 6
Training loss: 1.7815996462661878
Validation loss: 2.7227018680323924

Epoch: 5| Step: 7
Training loss: 1.3603754856172197
Validation loss: 2.583993585890542

Epoch: 5| Step: 8
Training loss: 1.4703748116175699
Validation loss: 2.649331372771579

Epoch: 5| Step: 9
Training loss: 1.8996298856135856
Validation loss: 2.60066894984321

Epoch: 5| Step: 10
Training loss: 2.313063784770799
Validation loss: 2.5767255508078493

Epoch: 531| Step: 0
Training loss: 1.6267071339910026
Validation loss: 2.592837843788207

Epoch: 5| Step: 1
Training loss: 1.8083114238882556
Validation loss: 2.5175240549193543

Epoch: 5| Step: 2
Training loss: 1.5779482298700114
Validation loss: 2.6110884766116547

Epoch: 5| Step: 3
Training loss: 1.8412804309326956
Validation loss: 2.5827024283539792

Epoch: 5| Step: 4
Training loss: 2.0487216452684
Validation loss: 2.596658528105476

Epoch: 5| Step: 5
Training loss: 1.8402227509466909
Validation loss: 2.6326859241311706

Epoch: 5| Step: 6
Training loss: 2.3349053899969516
Validation loss: 2.633429482406318

Epoch: 5| Step: 7
Training loss: 1.7130588983853294
Validation loss: 2.594179497671699

Epoch: 5| Step: 8
Training loss: 1.6939448452182135
Validation loss: 2.6561137570421387

Epoch: 5| Step: 9
Training loss: 2.197929804131415
Validation loss: 2.6592397321174333

Epoch: 5| Step: 10
Training loss: 1.846818020065895
Validation loss: 2.5879138254374423

Epoch: 532| Step: 0
Training loss: 1.8262135220434883
Validation loss: 2.5669823677589414

Epoch: 5| Step: 1
Training loss: 1.6464257280758425
Validation loss: 2.641803301627057

Epoch: 5| Step: 2
Training loss: 1.6173061014075303
Validation loss: 2.6274734481304045

Epoch: 5| Step: 3
Training loss: 2.1922715598512355
Validation loss: 2.6439582265807737

Epoch: 5| Step: 4
Training loss: 2.1703879116021203
Validation loss: 2.6140303161521676

Epoch: 5| Step: 5
Training loss: 2.1482445092652127
Validation loss: 2.658387649968228

Epoch: 5| Step: 6
Training loss: 2.1084954582673827
Validation loss: 2.6158050877749006

Epoch: 5| Step: 7
Training loss: 1.7112062844041989
Validation loss: 2.561843345737992

Epoch: 5| Step: 8
Training loss: 1.839437127990571
Validation loss: 2.600415285136406

Epoch: 5| Step: 9
Training loss: 1.7899869171389053
Validation loss: 2.629716133907079

Epoch: 5| Step: 10
Training loss: 1.4480918759972883
Validation loss: 2.5583469362315805

Epoch: 533| Step: 0
Training loss: 1.4327305161910757
Validation loss: 2.616133430691657

Epoch: 5| Step: 1
Training loss: 1.9416748106735209
Validation loss: 2.638457669306696

Epoch: 5| Step: 2
Training loss: 1.8151966948894809
Validation loss: 2.6424357315074376

Epoch: 5| Step: 3
Training loss: 1.363339398299875
Validation loss: 2.565823522408839

Epoch: 5| Step: 4
Training loss: 2.375464544540323
Validation loss: 2.6419591919575978

Epoch: 5| Step: 5
Training loss: 1.4895966091320234
Validation loss: 2.657481296748116

Epoch: 5| Step: 6
Training loss: 2.1022987635919272
Validation loss: 2.6831219329697595

Epoch: 5| Step: 7
Training loss: 1.961404205347942
Validation loss: 2.5792497525055755

Epoch: 5| Step: 8
Training loss: 2.132146374986407
Validation loss: 2.655771870442083

Epoch: 5| Step: 9
Training loss: 1.9752324269339487
Validation loss: 2.6417669691092804

Epoch: 5| Step: 10
Training loss: 1.6681542751220315
Validation loss: 2.6410212094847676

Epoch: 534| Step: 0
Training loss: 1.633674576528024
Validation loss: 2.6648031803786085

Epoch: 5| Step: 1
Training loss: 1.7102506469493368
Validation loss: 2.527308500686035

Epoch: 5| Step: 2
Training loss: 1.990919480033425
Validation loss: 2.59990497262424

Epoch: 5| Step: 3
Training loss: 1.5880881323920617
Validation loss: 2.6369392723923104

Epoch: 5| Step: 4
Training loss: 1.6813586061702377
Validation loss: 2.613547445744268

Epoch: 5| Step: 5
Training loss: 1.5733535698758447
Validation loss: 2.688746568402229

Epoch: 5| Step: 6
Training loss: 1.489183848060808
Validation loss: 2.541545379026994

Epoch: 5| Step: 7
Training loss: 1.6214566111915942
Validation loss: 2.6638941687743465

Epoch: 5| Step: 8
Training loss: 2.323042576774494
Validation loss: 2.5979829957579503

Epoch: 5| Step: 9
Training loss: 2.250389171428373
Validation loss: 2.52419882915366

Epoch: 5| Step: 10
Training loss: 1.9403614325918679
Validation loss: 2.6466755219821767

Epoch: 535| Step: 0
Training loss: 2.3682104739330994
Validation loss: 2.6000085513445224

Epoch: 5| Step: 1
Training loss: 1.5544375884888264
Validation loss: 2.6071833287374786

Epoch: 5| Step: 2
Training loss: 1.3951338206131045
Validation loss: 2.6984920695012233

Epoch: 5| Step: 3
Training loss: 2.350926208590675
Validation loss: 2.584103981077311

Epoch: 5| Step: 4
Training loss: 2.288006535714158
Validation loss: 2.671712316187382

Epoch: 5| Step: 5
Training loss: 1.632432227137252
Validation loss: 2.611533044996468

Epoch: 5| Step: 6
Training loss: 1.590048437040523
Validation loss: 2.4865977324595248

Epoch: 5| Step: 7
Training loss: 2.1721149559019275
Validation loss: 2.6114781008417025

Epoch: 5| Step: 8
Training loss: 1.6052434535787923
Validation loss: 2.634999968717163

Epoch: 5| Step: 9
Training loss: 1.6360341099118827
Validation loss: 2.661849073880275

Epoch: 5| Step: 10
Training loss: 2.0541198874738247
Validation loss: 2.5451712225176637

Epoch: 536| Step: 0
Training loss: 1.8239681880502432
Validation loss: 2.612137205244374

Epoch: 5| Step: 1
Training loss: 2.1421754888174163
Validation loss: 2.6961020653266607

Epoch: 5| Step: 2
Training loss: 2.247614761834142
Validation loss: 2.6076013772199325

Epoch: 5| Step: 3
Training loss: 1.9097773950486785
Validation loss: 2.6085074494761975

Epoch: 5| Step: 4
Training loss: 1.927929652873632
Validation loss: 2.6912204758031075

Epoch: 5| Step: 5
Training loss: 1.7178523407164554
Validation loss: 2.7420920817097243

Epoch: 5| Step: 6
Training loss: 1.8968051753005302
Validation loss: 2.587551271551743

Epoch: 5| Step: 7
Training loss: 1.6992357275103727
Validation loss: 2.6204904866077765

Epoch: 5| Step: 8
Training loss: 1.475001241392486
Validation loss: 2.600885834070292

Epoch: 5| Step: 9
Training loss: 1.6894467745093795
Validation loss: 2.648578242823424

Epoch: 5| Step: 10
Training loss: 1.6725510986003385
Validation loss: 2.613671380098305

Epoch: 537| Step: 0
Training loss: 1.7570102471588536
Validation loss: 2.6382754409639944

Epoch: 5| Step: 1
Training loss: 1.6625138361075444
Validation loss: 2.7286543363289653

Epoch: 5| Step: 2
Training loss: 2.193870641102747
Validation loss: 2.532994087878395

Epoch: 5| Step: 3
Training loss: 1.5888027372693918
Validation loss: 2.548998200038474

Epoch: 5| Step: 4
Training loss: 1.9329338411868933
Validation loss: 2.625610172240903

Epoch: 5| Step: 5
Training loss: 1.6584378313402441
Validation loss: 2.6529098617736575

Epoch: 5| Step: 6
Training loss: 1.919758755806629
Validation loss: 2.666487225012116

Epoch: 5| Step: 7
Training loss: 1.5146018438594229
Validation loss: 2.6399150451509596

Epoch: 5| Step: 8
Training loss: 2.031562898451281
Validation loss: 2.5966762458521058

Epoch: 5| Step: 9
Training loss: 2.3805122654452044
Validation loss: 2.6488924058392125

Epoch: 5| Step: 10
Training loss: 1.6656832972875706
Validation loss: 2.6675175000365066

Epoch: 538| Step: 0
Training loss: 1.8744965831148515
Validation loss: 2.6554769328422956

Epoch: 5| Step: 1
Training loss: 1.6895861270127286
Validation loss: 2.6404191881275305

Epoch: 5| Step: 2
Training loss: 1.3304251107603904
Validation loss: 2.667526343683089

Epoch: 5| Step: 3
Training loss: 1.702731375747423
Validation loss: 2.5824950955801627

Epoch: 5| Step: 4
Training loss: 2.0617248928243086
Validation loss: 2.6357621071879223

Epoch: 5| Step: 5
Training loss: 1.9068240567694577
Validation loss: 2.6549435727117308

Epoch: 5| Step: 6
Training loss: 1.7839435490028974
Validation loss: 2.6693595809449517

Epoch: 5| Step: 7
Training loss: 1.991411005420776
Validation loss: 2.589933931662014

Epoch: 5| Step: 8
Training loss: 2.3029003390879166
Validation loss: 2.6468628603522504

Epoch: 5| Step: 9
Training loss: 1.9048554994941866
Validation loss: 2.6645449618085295

Epoch: 5| Step: 10
Training loss: 1.6560894870352276
Validation loss: 2.6553144763117555

Epoch: 539| Step: 0
Training loss: 2.089883679160023
Validation loss: 2.5763877686076313

Epoch: 5| Step: 1
Training loss: 1.82770331320281
Validation loss: 2.6703393938583138

Epoch: 5| Step: 2
Training loss: 1.7495635714606872
Validation loss: 2.691555257498262

Epoch: 5| Step: 3
Training loss: 1.0719034663832872
Validation loss: 2.61039440159054

Epoch: 5| Step: 4
Training loss: 2.4133858828153776
Validation loss: 2.5997584195227046

Epoch: 5| Step: 5
Training loss: 1.734639602959226
Validation loss: 2.5532392973210425

Epoch: 5| Step: 6
Training loss: 1.922294384858075
Validation loss: 2.5686291227998974

Epoch: 5| Step: 7
Training loss: 2.414840918409402
Validation loss: 2.61293456650506

Epoch: 5| Step: 8
Training loss: 1.8999790792819231
Validation loss: 2.6594143341962573

Epoch: 5| Step: 9
Training loss: 1.2251815311064842
Validation loss: 2.6307395870454133

Epoch: 5| Step: 10
Training loss: 1.5315675989987299
Validation loss: 2.6592609073960976

Epoch: 540| Step: 0
Training loss: 2.0698295749775886
Validation loss: 2.654882722155439

Epoch: 5| Step: 1
Training loss: 1.8240359621141835
Validation loss: 2.5987049311092814

Epoch: 5| Step: 2
Training loss: 1.6640406504168173
Validation loss: 2.6792042112053798

Epoch: 5| Step: 3
Training loss: 1.4845029273873154
Validation loss: 2.62378298180514

Epoch: 5| Step: 4
Training loss: 1.3318342135846601
Validation loss: 2.6058749640675485

Epoch: 5| Step: 5
Training loss: 2.010887789167401
Validation loss: 2.7041247011381118

Epoch: 5| Step: 6
Training loss: 1.5491641282663928
Validation loss: 2.575357010605206

Epoch: 5| Step: 7
Training loss: 1.571403921231231
Validation loss: 2.5876453721644626

Epoch: 5| Step: 8
Training loss: 2.1244664363817907
Validation loss: 2.6645457036112323

Epoch: 5| Step: 9
Training loss: 2.0802560076521943
Validation loss: 2.664620058903622

Epoch: 5| Step: 10
Training loss: 2.151048661806372
Validation loss: 2.629669908897778

Epoch: 541| Step: 0
Training loss: 1.1878600327661661
Validation loss: 2.6284697630044844

Epoch: 5| Step: 1
Training loss: 2.309765616742242
Validation loss: 2.616895898116053

Epoch: 5| Step: 2
Training loss: 1.9700419712920696
Validation loss: 2.6921906408677123

Epoch: 5| Step: 3
Training loss: 1.5783043183530188
Validation loss: 2.660010518344608

Epoch: 5| Step: 4
Training loss: 1.9519439788659048
Validation loss: 2.6485800605969687

Epoch: 5| Step: 5
Training loss: 1.4654386812707154
Validation loss: 2.6210203303384993

Epoch: 5| Step: 6
Training loss: 1.979892082452311
Validation loss: 2.6537680412358045

Epoch: 5| Step: 7
Training loss: 1.7203639688856727
Validation loss: 2.5819496709203094

Epoch: 5| Step: 8
Training loss: 1.616652174357055
Validation loss: 2.684334947132369

Epoch: 5| Step: 9
Training loss: 1.5873663718384623
Validation loss: 2.6878820092008033

Epoch: 5| Step: 10
Training loss: 2.121043729807017
Validation loss: 2.6661686909793803

Epoch: 542| Step: 0
Training loss: 1.9492404607813638
Validation loss: 2.6656649641133603

Epoch: 5| Step: 1
Training loss: 1.7245446751382962
Validation loss: 2.678699456791673

Epoch: 5| Step: 2
Training loss: 1.6324820298144898
Validation loss: 2.660057866058224

Epoch: 5| Step: 3
Training loss: 1.691344438440967
Validation loss: 2.7114448579710664

Epoch: 5| Step: 4
Training loss: 2.31387989011401
Validation loss: 2.6634109610208427

Epoch: 5| Step: 5
Training loss: 1.6955197115365137
Validation loss: 2.7087313552827226

Epoch: 5| Step: 6
Training loss: 1.6293934338239862
Validation loss: 2.670993569590881

Epoch: 5| Step: 7
Training loss: 1.5527035116331263
Validation loss: 2.6371137420844986

Epoch: 5| Step: 8
Training loss: 1.9425072723606025
Validation loss: 2.7040657067714298

Epoch: 5| Step: 9
Training loss: 2.115380335850155
Validation loss: 2.547242951917583

Epoch: 5| Step: 10
Training loss: 1.9781044234279825
Validation loss: 2.6635302661931197

Epoch: 543| Step: 0
Training loss: 1.4813263756742843
Validation loss: 2.652624084957519

Epoch: 5| Step: 1
Training loss: 2.0657810354236283
Validation loss: 2.6308186407302387

Epoch: 5| Step: 2
Training loss: 1.667068774671355
Validation loss: 2.6348875487299734

Epoch: 5| Step: 3
Training loss: 1.7683148445267827
Validation loss: 2.7032404186240933

Epoch: 5| Step: 4
Training loss: 2.4997743504731966
Validation loss: 2.591771034671821

Epoch: 5| Step: 5
Training loss: 1.4820266618994447
Validation loss: 2.6023004173834487

Epoch: 5| Step: 6
Training loss: 1.6528181112089237
Validation loss: 2.6592322597537184

Epoch: 5| Step: 7
Training loss: 1.9148359954564906
Validation loss: 2.5822597278030757

Epoch: 5| Step: 8
Training loss: 1.7370240197593547
Validation loss: 2.6860487125051353

Epoch: 5| Step: 9
Training loss: 1.810983352146482
Validation loss: 2.5476599180276516

Epoch: 5| Step: 10
Training loss: 2.0647917066547214
Validation loss: 2.632612527827526

Epoch: 544| Step: 0
Training loss: 1.5425677973656797
Validation loss: 2.7036696589543405

Epoch: 5| Step: 1
Training loss: 1.5192640996432192
Validation loss: 2.5877257210557385

Epoch: 5| Step: 2
Training loss: 2.3407058274047974
Validation loss: 2.6428089958220973

Epoch: 5| Step: 3
Training loss: 1.4359451675625416
Validation loss: 2.5652882982703913

Epoch: 5| Step: 4
Training loss: 1.8788440083367655
Validation loss: 2.6363968779499545

Epoch: 5| Step: 5
Training loss: 1.406653028590785
Validation loss: 2.707866360246977

Epoch: 5| Step: 6
Training loss: 1.9229710252654928
Validation loss: 2.6371277311249823

Epoch: 5| Step: 7
Training loss: 1.5157658619655514
Validation loss: 2.637338469616779

Epoch: 5| Step: 8
Training loss: 2.0541723497581663
Validation loss: 2.607064424533477

Epoch: 5| Step: 9
Training loss: 2.1295025191712016
Validation loss: 2.674027762629055

Epoch: 5| Step: 10
Training loss: 1.868020610017642
Validation loss: 2.6314158907353256

Epoch: 545| Step: 0
Training loss: 1.3509171990575186
Validation loss: 2.648575836546195

Epoch: 5| Step: 1
Training loss: 1.7527264065409391
Validation loss: 2.645285450746112

Epoch: 5| Step: 2
Training loss: 2.1177396722874318
Validation loss: 2.640051831774185

Epoch: 5| Step: 3
Training loss: 1.8016495669550654
Validation loss: 2.653037387010967

Epoch: 5| Step: 4
Training loss: 1.8698060257412574
Validation loss: 2.6101274521173576

Epoch: 5| Step: 5
Training loss: 1.3130878312861687
Validation loss: 2.6196972424209797

Epoch: 5| Step: 6
Training loss: 1.746482447429251
Validation loss: 2.6630732226845035

Epoch: 5| Step: 7
Training loss: 2.0212738369755217
Validation loss: 2.580347363564652

Epoch: 5| Step: 8
Training loss: 1.9991138402402786
Validation loss: 2.625148403740623

Epoch: 5| Step: 9
Training loss: 1.733792456318141
Validation loss: 2.607595011372176

Epoch: 5| Step: 10
Training loss: 1.5840690392611143
Validation loss: 2.5346298865862993

Epoch: 546| Step: 0
Training loss: 1.733863892723238
Validation loss: 2.625275828357582

Epoch: 5| Step: 1
Training loss: 1.8156191853678003
Validation loss: 2.5556051585481216

Epoch: 5| Step: 2
Training loss: 1.6473930629819897
Validation loss: 2.567381814955933

Epoch: 5| Step: 3
Training loss: 2.0864710893271203
Validation loss: 2.6164523026764677

Epoch: 5| Step: 4
Training loss: 1.9600807537259042
Validation loss: 2.741297790186478

Epoch: 5| Step: 5
Training loss: 1.9776464814575272
Validation loss: 2.6214352196665907

Epoch: 5| Step: 6
Training loss: 1.6745246497384825
Validation loss: 2.654250438674885

Epoch: 5| Step: 7
Training loss: 1.854950199949641
Validation loss: 2.5993211447641844

Epoch: 5| Step: 8
Training loss: 1.4749234907059685
Validation loss: 2.6240986147086467

Epoch: 5| Step: 9
Training loss: 2.276149534787184
Validation loss: 2.6212625573427992

Epoch: 5| Step: 10
Training loss: 1.6203092216377606
Validation loss: 2.5865432817355187

Epoch: 547| Step: 0
Training loss: 2.3270070508875498
Validation loss: 2.666304584565555

Epoch: 5| Step: 1
Training loss: 2.0449780708760104
Validation loss: 2.6613415249211765

Epoch: 5| Step: 2
Training loss: 1.7509953529213458
Validation loss: 2.560935047052407

Epoch: 5| Step: 3
Training loss: 1.852423101726179
Validation loss: 2.6867830684799547

Epoch: 5| Step: 4
Training loss: 1.5788045496513354
Validation loss: 2.643751733587775

Epoch: 5| Step: 5
Training loss: 2.114713454980032
Validation loss: 2.6603156490109763

Epoch: 5| Step: 6
Training loss: 1.754449772887419
Validation loss: 2.6606131629811864

Epoch: 5| Step: 7
Training loss: 1.7903923855559127
Validation loss: 2.6058647089927898

Epoch: 5| Step: 8
Training loss: 1.9222453311065202
Validation loss: 2.59903383738203

Epoch: 5| Step: 9
Training loss: 1.3390782340871352
Validation loss: 2.6085333751150483

Epoch: 5| Step: 10
Training loss: 1.2389978206729273
Validation loss: 2.673017847381826

Epoch: 548| Step: 0
Training loss: 1.9855692116041774
Validation loss: 2.617965600697401

Epoch: 5| Step: 1
Training loss: 1.5980210762114089
Validation loss: 2.5593634977957067

Epoch: 5| Step: 2
Training loss: 1.0999932982500704
Validation loss: 2.6140090677131522

Epoch: 5| Step: 3
Training loss: 1.5902837570870205
Validation loss: 2.6185236045587126

Epoch: 5| Step: 4
Training loss: 2.1421732628681025
Validation loss: 2.5509772421171357

Epoch: 5| Step: 5
Training loss: 1.9199515541243029
Validation loss: 2.578398494191252

Epoch: 5| Step: 6
Training loss: 2.566140171233436
Validation loss: 2.673066410966291

Epoch: 5| Step: 7
Training loss: 1.4537888517952833
Validation loss: 2.650195736349777

Epoch: 5| Step: 8
Training loss: 1.6364890144461943
Validation loss: 2.5546769802397105

Epoch: 5| Step: 9
Training loss: 1.707478410129138
Validation loss: 2.6674527296668322

Epoch: 5| Step: 10
Training loss: 1.6719810951295782
Validation loss: 2.6467899966556927

Epoch: 549| Step: 0
Training loss: 1.920343238330033
Validation loss: 2.6538402911965253

Epoch: 5| Step: 1
Training loss: 2.3706510781046317
Validation loss: 2.588363062587066

Epoch: 5| Step: 2
Training loss: 1.875942883246287
Validation loss: 2.5936884175321464

Epoch: 5| Step: 3
Training loss: 1.6414383098479886
Validation loss: 2.589922654300459

Epoch: 5| Step: 4
Training loss: 1.655599358353971
Validation loss: 2.644654734709994

Epoch: 5| Step: 5
Training loss: 1.7640019611685094
Validation loss: 2.5927684066646717

Epoch: 5| Step: 6
Training loss: 1.3244309156926626
Validation loss: 2.644696874690066

Epoch: 5| Step: 7
Training loss: 1.7643440123325609
Validation loss: 2.6460913785119096

Epoch: 5| Step: 8
Training loss: 1.7620617179540075
Validation loss: 2.6901523678010992

Epoch: 5| Step: 9
Training loss: 1.6327176591260342
Validation loss: 2.6576724254615796

Epoch: 5| Step: 10
Training loss: 2.0573842731992054
Validation loss: 2.5998104854643342

Epoch: 550| Step: 0
Training loss: 2.5777069677661038
Validation loss: 2.6210950391097567

Epoch: 5| Step: 1
Training loss: 1.5797018350465812
Validation loss: 2.6208660488420352

Epoch: 5| Step: 2
Training loss: 1.56196638532215
Validation loss: 2.6168544796788775

Epoch: 5| Step: 3
Training loss: 1.8806535047638278
Validation loss: 2.681168083715894

Epoch: 5| Step: 4
Training loss: 1.4292201544685006
Validation loss: 2.655643573908479

Epoch: 5| Step: 5
Training loss: 1.8880412835076912
Validation loss: 2.6039922866683107

Epoch: 5| Step: 6
Training loss: 1.6163958394751072
Validation loss: 2.618444410244385

Epoch: 5| Step: 7
Training loss: 1.7726862320228498
Validation loss: 2.6338119973357204

Epoch: 5| Step: 8
Training loss: 1.9212827312632352
Validation loss: 2.618252069264367

Epoch: 5| Step: 9
Training loss: 1.7678957490435017
Validation loss: 2.657335703958232

Epoch: 5| Step: 10
Training loss: 1.4174430440127108
Validation loss: 2.6578364673209123

Epoch: 551| Step: 0
Training loss: 1.5955015543108535
Validation loss: 2.570973660077318

Epoch: 5| Step: 1
Training loss: 2.155713221867436
Validation loss: 2.633949393382005

Epoch: 5| Step: 2
Training loss: 1.497386164979543
Validation loss: 2.678739637141483

Epoch: 5| Step: 3
Training loss: 1.6664790842670545
Validation loss: 2.6076463830744596

Epoch: 5| Step: 4
Training loss: 1.51857054478256
Validation loss: 2.618194702662893

Epoch: 5| Step: 5
Training loss: 2.049039089807424
Validation loss: 2.634420623421212

Epoch: 5| Step: 6
Training loss: 2.0889233425130747
Validation loss: 2.6787774109441513

Epoch: 5| Step: 7
Training loss: 2.159623092333461
Validation loss: 2.628127669998968

Epoch: 5| Step: 8
Training loss: 1.7303686522042427
Validation loss: 2.605644484706195

Epoch: 5| Step: 9
Training loss: 1.1565834286354375
Validation loss: 2.5707357061761504

Epoch: 5| Step: 10
Training loss: 1.292304153435354
Validation loss: 2.654784520357654

Epoch: 552| Step: 0
Training loss: 1.8581095644877208
Validation loss: 2.6013017241827825

Epoch: 5| Step: 1
Training loss: 2.1954898423212064
Validation loss: 2.6904042275377633

Epoch: 5| Step: 2
Training loss: 1.6788180207811132
Validation loss: 2.67758588900605

Epoch: 5| Step: 3
Training loss: 1.6383932283667608
Validation loss: 2.6436579660119772

Epoch: 5| Step: 4
Training loss: 1.6094766973566614
Validation loss: 2.6718279797184388

Epoch: 5| Step: 5
Training loss: 1.6055073605834684
Validation loss: 2.737788151489892

Epoch: 5| Step: 6
Training loss: 1.5984993274772024
Validation loss: 2.6042634787663452

Epoch: 5| Step: 7
Training loss: 2.1421602410182725
Validation loss: 2.6268627542325635

Epoch: 5| Step: 8
Training loss: 2.7990629705914407
Validation loss: 2.616485402595796

Epoch: 5| Step: 9
Training loss: 1.675166517492552
Validation loss: 2.6660055166415955

Epoch: 5| Step: 10
Training loss: 1.317437964685386
Validation loss: 2.6328522477232505

Epoch: 553| Step: 0
Training loss: 1.5158053418651354
Validation loss: 2.7008033696646843

Epoch: 5| Step: 1
Training loss: 2.1382191078597517
Validation loss: 2.6550112649873165

Epoch: 5| Step: 2
Training loss: 1.4884122054989988
Validation loss: 2.6197474011585373

Epoch: 5| Step: 3
Training loss: 1.73939290022746
Validation loss: 2.6834359506001406

Epoch: 5| Step: 4
Training loss: 1.6102764975018986
Validation loss: 2.6881669350442245

Epoch: 5| Step: 5
Training loss: 2.3785718861386758
Validation loss: 2.5826591686439135

Epoch: 5| Step: 6
Training loss: 1.57757279205441
Validation loss: 2.5269514141560423

Epoch: 5| Step: 7
Training loss: 1.6752471428354228
Validation loss: 2.6355022834963746

Epoch: 5| Step: 8
Training loss: 1.5510563450262427
Validation loss: 2.6488369890792365

Epoch: 5| Step: 9
Training loss: 2.2726125367420162
Validation loss: 2.609304951678171

Epoch: 5| Step: 10
Training loss: 1.5850726997237141
Validation loss: 2.6326335735299864

Epoch: 554| Step: 0
Training loss: 1.7467882793376595
Validation loss: 2.5550609118907586

Epoch: 5| Step: 1
Training loss: 1.9360645267909316
Validation loss: 2.6714556137670074

Epoch: 5| Step: 2
Training loss: 1.6558269464260509
Validation loss: 2.660757246321396

Epoch: 5| Step: 3
Training loss: 2.081011037310578
Validation loss: 2.5976289500830454

Epoch: 5| Step: 4
Training loss: 1.6859226625654011
Validation loss: 2.6581239473262452

Epoch: 5| Step: 5
Training loss: 2.3710802759733514
Validation loss: 2.616471274776056

Epoch: 5| Step: 6
Training loss: 1.8314409748785547
Validation loss: 2.682082993374666

Epoch: 5| Step: 7
Training loss: 2.272689853706963
Validation loss: 2.6763707575575264

Epoch: 5| Step: 8
Training loss: 1.3668061514749774
Validation loss: 2.6366321822053376

Epoch: 5| Step: 9
Training loss: 1.534194140059631
Validation loss: 2.6154668018310256

Epoch: 5| Step: 10
Training loss: 1.6169533675245626
Validation loss: 2.597920374858567

Epoch: 555| Step: 0
Training loss: 1.528453843008522
Validation loss: 2.604904769811082

Epoch: 5| Step: 1
Training loss: 1.9883370682051638
Validation loss: 2.7044164429768704

Epoch: 5| Step: 2
Training loss: 1.94164036772549
Validation loss: 2.6454221564066085

Epoch: 5| Step: 3
Training loss: 1.9890370309641987
Validation loss: 2.6143319771023363

Epoch: 5| Step: 4
Training loss: 1.6131891773911706
Validation loss: 2.69534552365035

Epoch: 5| Step: 5
Training loss: 1.6873602632664244
Validation loss: 2.6090410075408608

Epoch: 5| Step: 6
Training loss: 1.6130192061225026
Validation loss: 2.7566223355868624

Epoch: 5| Step: 7
Training loss: 1.7386319267501928
Validation loss: 2.6516283541979897

Epoch: 5| Step: 8
Training loss: 1.5869977441878653
Validation loss: 2.696967567371696

Epoch: 5| Step: 9
Training loss: 1.8826081730943083
Validation loss: 2.6558902098691615

Epoch: 5| Step: 10
Training loss: 2.103695605839012
Validation loss: 2.6416270920142297

Epoch: 556| Step: 0
Training loss: 1.5124586399192643
Validation loss: 2.6639696455733897

Epoch: 5| Step: 1
Training loss: 2.032567697221084
Validation loss: 2.624620381850433

Epoch: 5| Step: 2
Training loss: 1.3933277225989822
Validation loss: 2.64055577193641

Epoch: 5| Step: 3
Training loss: 1.7028373685362532
Validation loss: 2.5941685204126257

Epoch: 5| Step: 4
Training loss: 1.6344804777168045
Validation loss: 2.5614235090259077

Epoch: 5| Step: 5
Training loss: 2.2796430806989103
Validation loss: 2.5857774014332557

Epoch: 5| Step: 6
Training loss: 2.0072172596207256
Validation loss: 2.6140657131613034

Epoch: 5| Step: 7
Training loss: 1.7870045782328376
Validation loss: 2.626245095940114

Epoch: 5| Step: 8
Training loss: 1.3113194560519235
Validation loss: 2.646240375212269

Epoch: 5| Step: 9
Training loss: 2.0410826749602644
Validation loss: 2.6014374891367376

Epoch: 5| Step: 10
Training loss: 1.7881925375063048
Validation loss: 2.6402195250675438

Epoch: 557| Step: 0
Training loss: 1.3112406365393925
Validation loss: 2.608207779056625

Epoch: 5| Step: 1
Training loss: 2.4699608452971527
Validation loss: 2.6061822670309547

Epoch: 5| Step: 2
Training loss: 1.6798403648191202
Validation loss: 2.6146151649358877

Epoch: 5| Step: 3
Training loss: 1.4941222744481781
Validation loss: 2.5759472312307077

Epoch: 5| Step: 4
Training loss: 1.5096133057815018
Validation loss: 2.594714682525434

Epoch: 5| Step: 5
Training loss: 2.028083680941355
Validation loss: 2.6508516394678523

Epoch: 5| Step: 6
Training loss: 1.6218005742102033
Validation loss: 2.602432703590221

Epoch: 5| Step: 7
Training loss: 1.5245581002278854
Validation loss: 2.665991738748897

Epoch: 5| Step: 8
Training loss: 1.992769522823387
Validation loss: 2.5906778687292706

Epoch: 5| Step: 9
Training loss: 1.7288722817953481
Validation loss: 2.6343252293961608

Epoch: 5| Step: 10
Training loss: 2.3533665020183885
Validation loss: 2.6494443538434513

Epoch: 558| Step: 0
Training loss: 2.0629542457436467
Validation loss: 2.7083868808674727

Epoch: 5| Step: 1
Training loss: 1.8127181480933212
Validation loss: 2.674167561264711

Epoch: 5| Step: 2
Training loss: 1.7924027224737331
Validation loss: 2.592491623499688

Epoch: 5| Step: 3
Training loss: 2.23208896026937
Validation loss: 2.653438143887998

Epoch: 5| Step: 4
Training loss: 1.9570458691444987
Validation loss: 2.731449919914693

Epoch: 5| Step: 5
Training loss: 1.4640542305923494
Validation loss: 2.6590129556641107

Epoch: 5| Step: 6
Training loss: 2.1031436006763586
Validation loss: 2.6401893968548182

Epoch: 5| Step: 7
Training loss: 1.1695363423676814
Validation loss: 2.627655018723015

Epoch: 5| Step: 8
Training loss: 1.6053725165045174
Validation loss: 2.665572985889257

Epoch: 5| Step: 9
Training loss: 1.257713171786537
Validation loss: 2.6122952113623223

Epoch: 5| Step: 10
Training loss: 1.491302307567296
Validation loss: 2.7314569703985616

Epoch: 559| Step: 0
Training loss: 1.8375989822404806
Validation loss: 2.688852085009226

Epoch: 5| Step: 1
Training loss: 2.068828814062621
Validation loss: 2.567735580289455

Epoch: 5| Step: 2
Training loss: 1.746971575365463
Validation loss: 2.6512032327113944

Epoch: 5| Step: 3
Training loss: 1.7654874629912753
Validation loss: 2.5873660419646436

Epoch: 5| Step: 4
Training loss: 1.2466809076287995
Validation loss: 2.720061149509997

Epoch: 5| Step: 5
Training loss: 1.612032797501067
Validation loss: 2.667574247060093

Epoch: 5| Step: 6
Training loss: 2.461356959849845
Validation loss: 2.5818106827796306

Epoch: 5| Step: 7
Training loss: 2.0429042127637986
Validation loss: 2.640144746692864

Epoch: 5| Step: 8
Training loss: 1.6954676825172244
Validation loss: 2.5987191860965013

Epoch: 5| Step: 9
Training loss: 1.2205708424419177
Validation loss: 2.6509973756121257

Epoch: 5| Step: 10
Training loss: 1.7741608341898205
Validation loss: 2.6355122248111837

Epoch: 560| Step: 0
Training loss: 1.8364742062712678
Validation loss: 2.5892597218600106

Epoch: 5| Step: 1
Training loss: 1.9319188734322048
Validation loss: 2.664593731769788

Epoch: 5| Step: 2
Training loss: 1.8403056672420093
Validation loss: 2.667360178753983

Epoch: 5| Step: 3
Training loss: 1.7524186178295067
Validation loss: 2.696106502079081

Epoch: 5| Step: 4
Training loss: 1.8707278855589504
Validation loss: 2.64485117251527

Epoch: 5| Step: 5
Training loss: 2.3108082330851243
Validation loss: 2.646918208998459

Epoch: 5| Step: 6
Training loss: 1.3231942593949322
Validation loss: 2.5698960878919395

Epoch: 5| Step: 7
Training loss: 1.2526786237490797
Validation loss: 2.6513008748300924

Epoch: 5| Step: 8
Training loss: 2.0371003630778013
Validation loss: 2.613574414595393

Epoch: 5| Step: 9
Training loss: 1.2368083581613645
Validation loss: 2.695744140075606

Epoch: 5| Step: 10
Training loss: 2.1649040486347015
Validation loss: 2.6238006277745316

Epoch: 561| Step: 0
Training loss: 1.6336301371728381
Validation loss: 2.7515274440940267

Epoch: 5| Step: 1
Training loss: 1.670879531120206
Validation loss: 2.70127811628835

Epoch: 5| Step: 2
Training loss: 1.439731110396073
Validation loss: 2.6795946340291543

Epoch: 5| Step: 3
Training loss: 1.5413711969224904
Validation loss: 2.5806884212739107

Epoch: 5| Step: 4
Training loss: 1.6817327068784276
Validation loss: 2.6000756111541152

Epoch: 5| Step: 5
Training loss: 1.8049565894911461
Validation loss: 2.639534270815605

Epoch: 5| Step: 6
Training loss: 2.13680689767619
Validation loss: 2.5804218157934136

Epoch: 5| Step: 7
Training loss: 1.9633542552388072
Validation loss: 2.5957147653915724

Epoch: 5| Step: 8
Training loss: 1.929436424075896
Validation loss: 2.65724003852124

Epoch: 5| Step: 9
Training loss: 1.6632725806344053
Validation loss: 2.6425502142525783

Epoch: 5| Step: 10
Training loss: 2.4563239554805425
Validation loss: 2.660060905735686

Epoch: 562| Step: 0
Training loss: 1.4747998247254621
Validation loss: 2.633984318315369

Epoch: 5| Step: 1
Training loss: 2.496062993440695
Validation loss: 2.628180187413061

Epoch: 5| Step: 2
Training loss: 1.8239274047576366
Validation loss: 2.6438654990125583

Epoch: 5| Step: 3
Training loss: 1.6730262856615996
Validation loss: 2.538513669504785

Epoch: 5| Step: 4
Training loss: 2.206529300290289
Validation loss: 2.7530045750096566

Epoch: 5| Step: 5
Training loss: 1.6822296068143388
Validation loss: 2.7488820347604737

Epoch: 5| Step: 6
Training loss: 1.6389158519674896
Validation loss: 2.6078100760046126

Epoch: 5| Step: 7
Training loss: 1.4293154039456437
Validation loss: 2.6293773474339215

Epoch: 5| Step: 8
Training loss: 1.4742084286504828
Validation loss: 2.6160666472710288

Epoch: 5| Step: 9
Training loss: 1.8099545329795572
Validation loss: 2.668287185400348

Epoch: 5| Step: 10
Training loss: 1.8905102403348772
Validation loss: 2.681844120379585

Epoch: 563| Step: 0
Training loss: 2.31650608613112
Validation loss: 2.6704867736721236

Epoch: 5| Step: 1
Training loss: 2.006904129391913
Validation loss: 2.672156012528278

Epoch: 5| Step: 2
Training loss: 1.9349054376527244
Validation loss: 2.6977588738710465

Epoch: 5| Step: 3
Training loss: 1.327022903040636
Validation loss: 2.682381661268638

Epoch: 5| Step: 4
Training loss: 1.5913073951456824
Validation loss: 2.649309518177186

Epoch: 5| Step: 5
Training loss: 1.5404265115327187
Validation loss: 2.616480395796917

Epoch: 5| Step: 6
Training loss: 1.198906376318028
Validation loss: 2.597984576580864

Epoch: 5| Step: 7
Training loss: 1.8883828984506528
Validation loss: 2.645405342717244

Epoch: 5| Step: 8
Training loss: 1.7141716754539105
Validation loss: 2.700415740949347

Epoch: 5| Step: 9
Training loss: 1.7536013195829925
Validation loss: 2.653235828475359

Epoch: 5| Step: 10
Training loss: 1.7737704733271211
Validation loss: 2.5682294628298954

Epoch: 564| Step: 0
Training loss: 1.4187289635531293
Validation loss: 2.6185004002172216

Epoch: 5| Step: 1
Training loss: 1.2909945718546245
Validation loss: 2.6163292339700046

Epoch: 5| Step: 2
Training loss: 1.7605176667202134
Validation loss: 2.5742215275377966

Epoch: 5| Step: 3
Training loss: 2.061516960997643
Validation loss: 2.578501649293027

Epoch: 5| Step: 4
Training loss: 1.9080846743878503
Validation loss: 2.592649514743255

Epoch: 5| Step: 5
Training loss: 1.5676585682757047
Validation loss: 2.6243685281682616

Epoch: 5| Step: 6
Training loss: 1.6677684082927524
Validation loss: 2.701417560950526

Epoch: 5| Step: 7
Training loss: 2.0695152043044205
Validation loss: 2.6049098933381214

Epoch: 5| Step: 8
Training loss: 2.1858010370115757
Validation loss: 2.5085864023802507

Epoch: 5| Step: 9
Training loss: 1.723085726185597
Validation loss: 2.6731261158434805

Epoch: 5| Step: 10
Training loss: 1.4137816598114656
Validation loss: 2.6293513021530717

Epoch: 565| Step: 0
Training loss: 2.123130312405673
Validation loss: 2.6491204318789365

Epoch: 5| Step: 1
Training loss: 1.7012057207947313
Validation loss: 2.5704731189581995

Epoch: 5| Step: 2
Training loss: 2.3725715066888515
Validation loss: 2.6844878987215903

Epoch: 5| Step: 3
Training loss: 2.127048178546368
Validation loss: 2.6115819077067197

Epoch: 5| Step: 4
Training loss: 1.9034598521033577
Validation loss: 2.681709265190634

Epoch: 5| Step: 5
Training loss: 1.404649417008765
Validation loss: 2.653908190320704

Epoch: 5| Step: 6
Training loss: 1.2951132516422907
Validation loss: 2.5936971442338352

Epoch: 5| Step: 7
Training loss: 1.9056504354158799
Validation loss: 2.677085579281093

Epoch: 5| Step: 8
Training loss: 1.182142368698513
Validation loss: 2.6298287849540753

Epoch: 5| Step: 9
Training loss: 1.643156151779142
Validation loss: 2.6155428493383366

Epoch: 5| Step: 10
Training loss: 1.653768804188085
Validation loss: 2.693650458801999

Epoch: 566| Step: 0
Training loss: 1.4409680204317452
Validation loss: 2.6164132763323087

Epoch: 5| Step: 1
Training loss: 1.7421554767761775
Validation loss: 2.52340002097822

Epoch: 5| Step: 2
Training loss: 1.9963399656848775
Validation loss: 2.670482044757127

Epoch: 5| Step: 3
Training loss: 2.1638882012530067
Validation loss: 2.655845608411839

Epoch: 5| Step: 4
Training loss: 1.4516372447895531
Validation loss: 2.582616286409881

Epoch: 5| Step: 5
Training loss: 1.7535977846350912
Validation loss: 2.6537779556647543

Epoch: 5| Step: 6
Training loss: 2.2478599967801625
Validation loss: 2.578801269931421

Epoch: 5| Step: 7
Training loss: 1.5796665933585783
Validation loss: 2.5907032400273375

Epoch: 5| Step: 8
Training loss: 1.7114165867709508
Validation loss: 2.7138508620987696

Epoch: 5| Step: 9
Training loss: 1.8174518160093338
Validation loss: 2.6078524604055313

Epoch: 5| Step: 10
Training loss: 1.3089072236331498
Validation loss: 2.5467164300842255

Epoch: 567| Step: 0
Training loss: 1.5241583268132257
Validation loss: 2.680319601111382

Epoch: 5| Step: 1
Training loss: 2.530908349610313
Validation loss: 2.6463669416548083

Epoch: 5| Step: 2
Training loss: 1.703014475184694
Validation loss: 2.6169933312571807

Epoch: 5| Step: 3
Training loss: 1.5556159386192752
Validation loss: 2.6591093295599415

Epoch: 5| Step: 4
Training loss: 1.9361861912043734
Validation loss: 2.578763326039898

Epoch: 5| Step: 5
Training loss: 1.914101175968468
Validation loss: 2.595617770080958

Epoch: 5| Step: 6
Training loss: 1.621626212676311
Validation loss: 2.608157379719315

Epoch: 5| Step: 7
Training loss: 1.575665663270501
Validation loss: 2.574019572111994

Epoch: 5| Step: 8
Training loss: 1.9806738752869288
Validation loss: 2.712208429291262

Epoch: 5| Step: 9
Training loss: 1.6319805745483384
Validation loss: 2.6456084924154495

Epoch: 5| Step: 10
Training loss: 1.3474433177852658
Validation loss: 2.6658009506952625

Epoch: 568| Step: 0
Training loss: 2.029276196959133
Validation loss: 2.6261430069351093

Epoch: 5| Step: 1
Training loss: 2.0328834421620203
Validation loss: 2.6073172879786686

Epoch: 5| Step: 2
Training loss: 1.8299845179960803
Validation loss: 2.691154675516699

Epoch: 5| Step: 3
Training loss: 2.0236949388672505
Validation loss: 2.645946100758214

Epoch: 5| Step: 4
Training loss: 1.6058185873788138
Validation loss: 2.6297526826363966

Epoch: 5| Step: 5
Training loss: 2.0512462270493943
Validation loss: 2.659873197691149

Epoch: 5| Step: 6
Training loss: 1.179272509206612
Validation loss: 2.660050135778489

Epoch: 5| Step: 7
Training loss: 1.3874258897939054
Validation loss: 2.670738563342733

Epoch: 5| Step: 8
Training loss: 1.5753322099581306
Validation loss: 2.6729504231370282

Epoch: 5| Step: 9
Training loss: 1.7208246367868254
Validation loss: 2.6679884137043195

Epoch: 5| Step: 10
Training loss: 1.571930161223041
Validation loss: 2.728772303433377

Epoch: 569| Step: 0
Training loss: 1.7178126466753465
Validation loss: 2.6843418090682998

Epoch: 5| Step: 1
Training loss: 2.3915890015365324
Validation loss: 2.7186697416584424

Epoch: 5| Step: 2
Training loss: 2.1057665442666327
Validation loss: 2.661536028952668

Epoch: 5| Step: 3
Training loss: 1.5295720151300474
Validation loss: 2.604362353120028

Epoch: 5| Step: 4
Training loss: 1.59606623166076
Validation loss: 2.551577835966801

Epoch: 5| Step: 5
Training loss: 1.5517939952859536
Validation loss: 2.6287436288792856

Epoch: 5| Step: 6
Training loss: 1.450286389711569
Validation loss: 2.6859283707298376

Epoch: 5| Step: 7
Training loss: 1.5333986582869459
Validation loss: 2.6213307066718685

Epoch: 5| Step: 8
Training loss: 1.7100511458483445
Validation loss: 2.5976766433303906

Epoch: 5| Step: 9
Training loss: 1.4832012153394178
Validation loss: 2.612579345126247

Epoch: 5| Step: 10
Training loss: 1.76998929122875
Validation loss: 2.673214628214891

Epoch: 570| Step: 0
Training loss: 1.588810015249427
Validation loss: 2.6029081901079594

Epoch: 5| Step: 1
Training loss: 1.9908725363042574
Validation loss: 2.7944328630330353

Epoch: 5| Step: 2
Training loss: 2.1539806642293193
Validation loss: 2.535263953420818

Epoch: 5| Step: 3
Training loss: 1.5759132674164107
Validation loss: 2.605753562210457

Epoch: 5| Step: 4
Training loss: 1.780548626864252
Validation loss: 2.6551100734539377

Epoch: 5| Step: 5
Training loss: 1.8408473167158874
Validation loss: 2.67286070501322

Epoch: 5| Step: 6
Training loss: 1.9237963988500746
Validation loss: 2.646963257250483

Epoch: 5| Step: 7
Training loss: 1.299489797830255
Validation loss: 2.6575543795504655

Epoch: 5| Step: 8
Training loss: 2.1172051798515152
Validation loss: 2.7019894557507835

Epoch: 5| Step: 9
Training loss: 1.405173758761749
Validation loss: 2.612727243547849

Epoch: 5| Step: 10
Training loss: 2.147731151641528
Validation loss: 2.7021449233588237

Epoch: 571| Step: 0
Training loss: 1.5195132060806082
Validation loss: 2.533237023241848

Epoch: 5| Step: 1
Training loss: 1.7795294767694652
Validation loss: 2.666290469769983

Epoch: 5| Step: 2
Training loss: 1.5809558368621561
Validation loss: 2.6594434001710594

Epoch: 5| Step: 3
Training loss: 1.7655650440940311
Validation loss: 2.592679422151485

Epoch: 5| Step: 4
Training loss: 2.2660530475221825
Validation loss: 2.6020354247846442

Epoch: 5| Step: 5
Training loss: 1.5836452210412246
Validation loss: 2.6718311902306717

Epoch: 5| Step: 6
Training loss: 1.9519207102626432
Validation loss: 2.6594237388360287

Epoch: 5| Step: 7
Training loss: 1.8796072621711999
Validation loss: 2.6620724529018664

Epoch: 5| Step: 8
Training loss: 1.5496688427487595
Validation loss: 2.715670130990808

Epoch: 5| Step: 9
Training loss: 1.7274156076709988
Validation loss: 2.607409268263818

Epoch: 5| Step: 10
Training loss: 1.8458245454439803
Validation loss: 2.5719671816968552

Epoch: 572| Step: 0
Training loss: 1.7277052881844273
Validation loss: 2.5896819763928915

Epoch: 5| Step: 1
Training loss: 1.6979626452377574
Validation loss: 2.632342223805692

Epoch: 5| Step: 2
Training loss: 1.2538444052207423
Validation loss: 2.6798017842140647

Epoch: 5| Step: 3
Training loss: 2.4930997990395793
Validation loss: 2.6005299931188306

Epoch: 5| Step: 4
Training loss: 1.7610189397032765
Validation loss: 2.668398620262199

Epoch: 5| Step: 5
Training loss: 1.6389986969463761
Validation loss: 2.621676501858737

Epoch: 5| Step: 6
Training loss: 1.96864282225471
Validation loss: 2.665757081494491

Epoch: 5| Step: 7
Training loss: 1.6081146934941055
Validation loss: 2.630257453731885

Epoch: 5| Step: 8
Training loss: 1.9307928587461187
Validation loss: 2.6610029160165434

Epoch: 5| Step: 9
Training loss: 1.5509037766949472
Validation loss: 2.579242276016418

Epoch: 5| Step: 10
Training loss: 1.4479212955245349
Validation loss: 2.635402259331701

Epoch: 573| Step: 0
Training loss: 2.0449948593858496
Validation loss: 2.6972073270111445

Epoch: 5| Step: 1
Training loss: 1.7093487334804935
Validation loss: 2.700129447987752

Epoch: 5| Step: 2
Training loss: 2.5836827339234154
Validation loss: 2.6372757829256255

Epoch: 5| Step: 3
Training loss: 1.1455157735796728
Validation loss: 2.598274105542314

Epoch: 5| Step: 4
Training loss: 1.5439853071887366
Validation loss: 2.6966875850859364

Epoch: 5| Step: 5
Training loss: 2.098319802921092
Validation loss: 2.5990315687020495

Epoch: 5| Step: 6
Training loss: 1.7437503117386735
Validation loss: 2.716389260194727

Epoch: 5| Step: 7
Training loss: 1.4856796955572684
Validation loss: 2.684269325701132

Epoch: 5| Step: 8
Training loss: 1.715494644966095
Validation loss: 2.669337583478107

Epoch: 5| Step: 9
Training loss: 1.4832835953478032
Validation loss: 2.66977271635348

Epoch: 5| Step: 10
Training loss: 1.3047151391305414
Validation loss: 2.652620302251685

Epoch: 574| Step: 0
Training loss: 1.4906574813534756
Validation loss: 2.7140225620141294

Epoch: 5| Step: 1
Training loss: 1.4051690503571028
Validation loss: 2.6488240127820335

Epoch: 5| Step: 2
Training loss: 1.9730202518434954
Validation loss: 2.614344076823748

Epoch: 5| Step: 3
Training loss: 1.7348579215544848
Validation loss: 2.6836762170294213

Epoch: 5| Step: 4
Training loss: 1.8367220886278008
Validation loss: 2.652830881742168

Epoch: 5| Step: 5
Training loss: 1.463817755925117
Validation loss: 2.5774796370183743

Epoch: 5| Step: 6
Training loss: 2.025130458444162
Validation loss: 2.6370525841223094

Epoch: 5| Step: 7
Training loss: 2.204168194468016
Validation loss: 2.674961403234873

Epoch: 5| Step: 8
Training loss: 1.6952997725751728
Validation loss: 2.645230225908587

Epoch: 5| Step: 9
Training loss: 1.86725479068568
Validation loss: 2.6637554059665964

Epoch: 5| Step: 10
Training loss: 1.1363158675470626
Validation loss: 2.6526500747261514

Epoch: 575| Step: 0
Training loss: 1.2500226972426645
Validation loss: 2.7237341633719248

Epoch: 5| Step: 1
Training loss: 1.7805727959662951
Validation loss: 2.7210212699774337

Epoch: 5| Step: 2
Training loss: 1.8171572865592727
Validation loss: 2.7051053792243116

Epoch: 5| Step: 3
Training loss: 1.3876237092413748
Validation loss: 2.6383915257795536

Epoch: 5| Step: 4
Training loss: 2.047123668212979
Validation loss: 2.67375176584525

Epoch: 5| Step: 5
Training loss: 1.50026319102149
Validation loss: 2.6926160072065937

Epoch: 5| Step: 6
Training loss: 1.5426492480962668
Validation loss: 2.677170234751796

Epoch: 5| Step: 7
Training loss: 2.1437473219251446
Validation loss: 2.6733034963136713

Epoch: 5| Step: 8
Training loss: 1.906233803101816
Validation loss: 2.667052902109922

Epoch: 5| Step: 9
Training loss: 1.5786381255536102
Validation loss: 2.6664288348100844

Epoch: 5| Step: 10
Training loss: 2.0375850776743007
Validation loss: 2.681208725225842

Epoch: 576| Step: 0
Training loss: 1.6362854741435147
Validation loss: 2.6782005712450516

Epoch: 5| Step: 1
Training loss: 1.718689726726369
Validation loss: 2.6095588014636015

Epoch: 5| Step: 2
Training loss: 1.5321511711405689
Validation loss: 2.5997290373049338

Epoch: 5| Step: 3
Training loss: 1.799383982576009
Validation loss: 2.653916076626315

Epoch: 5| Step: 4
Training loss: 1.774736709946909
Validation loss: 2.6464031834107766

Epoch: 5| Step: 5
Training loss: 1.701696304090595
Validation loss: 2.70798216184579

Epoch: 5| Step: 6
Training loss: 2.2627540024285873
Validation loss: 2.688076177877068

Epoch: 5| Step: 7
Training loss: 1.4578428079249175
Validation loss: 2.63765068912598

Epoch: 5| Step: 8
Training loss: 1.8225490599048049
Validation loss: 2.611993816725078

Epoch: 5| Step: 9
Training loss: 1.7582707464761558
Validation loss: 2.630219221909893

Epoch: 5| Step: 10
Training loss: 1.4746454297641076
Validation loss: 2.5845872450460172

Epoch: 577| Step: 0
Training loss: 1.797148443231125
Validation loss: 2.674491871670035

Epoch: 5| Step: 1
Training loss: 1.894605245816549
Validation loss: 2.6205454090894316

Epoch: 5| Step: 2
Training loss: 1.4390705485331132
Validation loss: 2.637443950162296

Epoch: 5| Step: 3
Training loss: 1.0581681074992941
Validation loss: 2.63394257730625

Epoch: 5| Step: 4
Training loss: 1.4807685005079483
Validation loss: 2.6328418109672045

Epoch: 5| Step: 5
Training loss: 1.7152051957492989
Validation loss: 2.6247560941530605

Epoch: 5| Step: 6
Training loss: 2.7262884401237595
Validation loss: 2.664734544852119

Epoch: 5| Step: 7
Training loss: 1.4660335337406174
Validation loss: 2.6312829557069843

Epoch: 5| Step: 8
Training loss: 1.9617571086771763
Validation loss: 2.561880309885936

Epoch: 5| Step: 9
Training loss: 1.2865131484900545
Validation loss: 2.597636218706558

Epoch: 5| Step: 10
Training loss: 1.892452145252374
Validation loss: 2.669803897304608

Epoch: 578| Step: 0
Training loss: 0.9798447648512911
Validation loss: 2.581616110445869

Epoch: 5| Step: 1
Training loss: 2.138786918994803
Validation loss: 2.741035220497882

Epoch: 5| Step: 2
Training loss: 1.7520217116591335
Validation loss: 2.6780178934539647

Epoch: 5| Step: 3
Training loss: 1.3562840365168984
Validation loss: 2.571861867587421

Epoch: 5| Step: 4
Training loss: 1.8595521345633355
Validation loss: 2.5497434955170566

Epoch: 5| Step: 5
Training loss: 2.1645726453011203
Validation loss: 2.64327591428826

Epoch: 5| Step: 6
Training loss: 2.0540670756351886
Validation loss: 2.643699902724292

Epoch: 5| Step: 7
Training loss: 1.478449186296222
Validation loss: 2.5948200393242455

Epoch: 5| Step: 8
Training loss: 1.5476749548053723
Validation loss: 2.658810684555467

Epoch: 5| Step: 9
Training loss: 1.719723373834707
Validation loss: 2.5899931308181556

Epoch: 5| Step: 10
Training loss: 1.7326262997475903
Validation loss: 2.6746604325927055

Epoch: 579| Step: 0
Training loss: 2.6192945510499412
Validation loss: 2.6515312597752074

Epoch: 5| Step: 1
Training loss: 1.632440990181814
Validation loss: 2.5852475885646897

Epoch: 5| Step: 2
Training loss: 1.2856072095531137
Validation loss: 2.6933341359568086

Epoch: 5| Step: 3
Training loss: 2.093614943973789
Validation loss: 2.6523608232026867

Epoch: 5| Step: 4
Training loss: 2.066343483214976
Validation loss: 2.596223753825904

Epoch: 5| Step: 5
Training loss: 1.4237338480983541
Validation loss: 2.6211777872838824

Epoch: 5| Step: 6
Training loss: 1.1194437358802423
Validation loss: 2.664533717362759

Epoch: 5| Step: 7
Training loss: 1.6688395244001364
Validation loss: 2.6090905457730647

Epoch: 5| Step: 8
Training loss: 1.6110169266250167
Validation loss: 2.6133669167748175

Epoch: 5| Step: 9
Training loss: 1.5516231375194236
Validation loss: 2.695705697709071

Epoch: 5| Step: 10
Training loss: 1.7485843791068028
Validation loss: 2.676108142013062

Epoch: 580| Step: 0
Training loss: 1.1876876582391644
Validation loss: 2.722035966451332

Epoch: 5| Step: 1
Training loss: 1.8637711942453938
Validation loss: 2.705047698468238

Epoch: 5| Step: 2
Training loss: 1.7411097455961002
Validation loss: 2.639887339315777

Epoch: 5| Step: 3
Training loss: 1.622230664250139
Validation loss: 2.6921318768307896

Epoch: 5| Step: 4
Training loss: 1.734080109141632
Validation loss: 2.6471531397196046

Epoch: 5| Step: 5
Training loss: 1.4898095481559417
Validation loss: 2.6441037173001947

Epoch: 5| Step: 6
Training loss: 1.3671520119557137
Validation loss: 2.61361406597182

Epoch: 5| Step: 7
Training loss: 1.621309638297788
Validation loss: 2.6455229006319194

Epoch: 5| Step: 8
Training loss: 1.8392363434513095
Validation loss: 2.585450172139453

Epoch: 5| Step: 9
Training loss: 2.400919869092668
Validation loss: 2.638266218441046

Epoch: 5| Step: 10
Training loss: 1.8091176800426554
Validation loss: 2.6546810334879205

Epoch: 581| Step: 0
Training loss: 1.5016405353255364
Validation loss: 2.5859462439360685

Epoch: 5| Step: 1
Training loss: 1.5719147663887942
Validation loss: 2.6354452486120525

Epoch: 5| Step: 2
Training loss: 1.9689780209207255
Validation loss: 2.598265921096909

Epoch: 5| Step: 3
Training loss: 1.832362683864334
Validation loss: 2.6009089491446264

Epoch: 5| Step: 4
Training loss: 1.4917025751803483
Validation loss: 2.5714064186906076

Epoch: 5| Step: 5
Training loss: 1.2500001430511394
Validation loss: 2.6166256899891343

Epoch: 5| Step: 6
Training loss: 1.5834411366889407
Validation loss: 2.6104403060090076

Epoch: 5| Step: 7
Training loss: 2.454395718294012
Validation loss: 2.6779892167112727

Epoch: 5| Step: 8
Training loss: 1.9582481636302709
Validation loss: 2.7151090452044166

Epoch: 5| Step: 9
Training loss: 1.6814894126402244
Validation loss: 2.633262450986855

Epoch: 5| Step: 10
Training loss: 1.8057813755876062
Validation loss: 2.7138536242554925

Epoch: 582| Step: 0
Training loss: 1.318791297519076
Validation loss: 2.694323594710063

Epoch: 5| Step: 1
Training loss: 1.0979276708429053
Validation loss: 2.5991024294929868

Epoch: 5| Step: 2
Training loss: 1.2017190818801042
Validation loss: 2.6085057123769486

Epoch: 5| Step: 3
Training loss: 2.2173743483113797
Validation loss: 2.6684485475965807

Epoch: 5| Step: 4
Training loss: 1.8057025515393226
Validation loss: 2.6005456951276034

Epoch: 5| Step: 5
Training loss: 1.7878233103699517
Validation loss: 2.675832873335143

Epoch: 5| Step: 6
Training loss: 1.6197508615667233
Validation loss: 2.713100533931588

Epoch: 5| Step: 7
Training loss: 1.8220921931679095
Validation loss: 2.69212289594268

Epoch: 5| Step: 8
Training loss: 1.7955193754811647
Validation loss: 2.6200913260918286

Epoch: 5| Step: 9
Training loss: 2.2910740057099623
Validation loss: 2.6866110790841815

Epoch: 5| Step: 10
Training loss: 1.020014155233559
Validation loss: 2.7141752952087335

Epoch: 583| Step: 0
Training loss: 1.2741404272504195
Validation loss: 2.713797997995987

Epoch: 5| Step: 1
Training loss: 1.7092741802268903
Validation loss: 2.634360381930917

Epoch: 5| Step: 2
Training loss: 1.3706513041465338
Validation loss: 2.639893521442163

Epoch: 5| Step: 3
Training loss: 2.0659564561714236
Validation loss: 2.691367982855797

Epoch: 5| Step: 4
Training loss: 1.458758846148266
Validation loss: 2.6565814550381335

Epoch: 5| Step: 5
Training loss: 1.7158858276434625
Validation loss: 2.613873942978542

Epoch: 5| Step: 6
Training loss: 1.7511690866863816
Validation loss: 2.629131386548483

Epoch: 5| Step: 7
Training loss: 1.9001252635019332
Validation loss: 2.634354891385418

Epoch: 5| Step: 8
Training loss: 1.4143260056947695
Validation loss: 2.654791608351802

Epoch: 5| Step: 9
Training loss: 1.975892205854174
Validation loss: 2.744354465096433

Epoch: 5| Step: 10
Training loss: 1.8512832495403524
Validation loss: 2.6083326983759854

Epoch: 584| Step: 0
Training loss: 1.3311433041937084
Validation loss: 2.6243202942857433

Epoch: 5| Step: 1
Training loss: 1.6186642745601023
Validation loss: 2.6419851391464015

Epoch: 5| Step: 2
Training loss: 1.7069246097312776
Validation loss: 2.574549852421071

Epoch: 5| Step: 3
Training loss: 1.5223633720842795
Validation loss: 2.7133136201769124

Epoch: 5| Step: 4
Training loss: 2.166031805585134
Validation loss: 2.5976047389557566

Epoch: 5| Step: 5
Training loss: 2.101557621719768
Validation loss: 2.6945662440463214

Epoch: 5| Step: 6
Training loss: 2.041711599153973
Validation loss: 2.6570661532358297

Epoch: 5| Step: 7
Training loss: 1.6744695478274791
Validation loss: 2.6084333900363035

Epoch: 5| Step: 8
Training loss: 1.5889543674703426
Validation loss: 2.5905136652298015

Epoch: 5| Step: 9
Training loss: 1.309636352603457
Validation loss: 2.5716207275483374

Epoch: 5| Step: 10
Training loss: 1.6504241398224258
Validation loss: 2.689774958586472

Epoch: 585| Step: 0
Training loss: 1.9317999640029064
Validation loss: 2.5748205989997826

Epoch: 5| Step: 1
Training loss: 1.6181488128477646
Validation loss: 2.634170618654929

Epoch: 5| Step: 2
Training loss: 1.4498376064784986
Validation loss: 2.67047065635114

Epoch: 5| Step: 3
Training loss: 1.6406601674988288
Validation loss: 2.588333985328242

Epoch: 5| Step: 4
Training loss: 1.2420082202829772
Validation loss: 2.68549139269423

Epoch: 5| Step: 5
Training loss: 1.5244591832738243
Validation loss: 2.5727185033563225

Epoch: 5| Step: 6
Training loss: 1.227554843166888
Validation loss: 2.694628663512568

Epoch: 5| Step: 7
Training loss: 2.0212100225209553
Validation loss: 2.656015973334916

Epoch: 5| Step: 8
Training loss: 1.3907848652020285
Validation loss: 2.6883201506688637

Epoch: 5| Step: 9
Training loss: 1.7731753252139941
Validation loss: 2.6315022355730866

Epoch: 5| Step: 10
Training loss: 2.303370315965169
Validation loss: 2.6942652321106095

Epoch: 586| Step: 0
Training loss: 1.1009470525755396
Validation loss: 2.638218778929368

Epoch: 5| Step: 1
Training loss: 1.5518231867276635
Validation loss: 2.697539925902137

Epoch: 5| Step: 2
Training loss: 1.9312911686629537
Validation loss: 2.6683889763240685

Epoch: 5| Step: 3
Training loss: 1.6253460735659349
Validation loss: 2.7029781193766853

Epoch: 5| Step: 4
Training loss: 1.6054654086558524
Validation loss: 2.716231425549963

Epoch: 5| Step: 5
Training loss: 2.3189900029844135
Validation loss: 2.703461905282701

Epoch: 5| Step: 6
Training loss: 1.9532539019963744
Validation loss: 2.704697395773373

Epoch: 5| Step: 7
Training loss: 1.0912226222778052
Validation loss: 2.670983663395536

Epoch: 5| Step: 8
Training loss: 2.2096083457126223
Validation loss: 2.6913528526385337

Epoch: 5| Step: 9
Training loss: 1.4614585722390394
Validation loss: 2.596036336000635

Epoch: 5| Step: 10
Training loss: 1.3725539905928237
Validation loss: 2.720578039370524

Epoch: 587| Step: 0
Training loss: 1.2031752835949938
Validation loss: 2.6586470325852645

Epoch: 5| Step: 1
Training loss: 2.0669962107527224
Validation loss: 2.678549787723999

Epoch: 5| Step: 2
Training loss: 1.6645210601400207
Validation loss: 2.5959417781465404

Epoch: 5| Step: 3
Training loss: 1.7481859887033282
Validation loss: 2.539392141142402

Epoch: 5| Step: 4
Training loss: 1.4936528226135224
Validation loss: 2.604736706435575

Epoch: 5| Step: 5
Training loss: 1.6187561093955205
Validation loss: 2.496755896752958

Epoch: 5| Step: 6
Training loss: 1.7329082988816125
Validation loss: 2.6334301599614474

Epoch: 5| Step: 7
Training loss: 1.6148368226277847
Validation loss: 2.638248326207594

Epoch: 5| Step: 8
Training loss: 1.5175544020125364
Validation loss: 2.602690328854749

Epoch: 5| Step: 9
Training loss: 1.4862509668602137
Validation loss: 2.6632708066391797

Epoch: 5| Step: 10
Training loss: 2.4428159992319345
Validation loss: 2.5994753084926168

Epoch: 588| Step: 0
Training loss: 1.3916871375826407
Validation loss: 2.6691315008255283

Epoch: 5| Step: 1
Training loss: 1.8165821277418357
Validation loss: 2.6513084817117325

Epoch: 5| Step: 2
Training loss: 1.9935999631482177
Validation loss: 2.6865275474927204

Epoch: 5| Step: 3
Training loss: 1.6056387781106636
Validation loss: 2.579135581113207

Epoch: 5| Step: 4
Training loss: 2.348799695214504
Validation loss: 2.71046708316989

Epoch: 5| Step: 5
Training loss: 1.7532505092470525
Validation loss: 2.6485161048045645

Epoch: 5| Step: 6
Training loss: 1.5520959465316537
Validation loss: 2.610210447802746

Epoch: 5| Step: 7
Training loss: 1.350828555830348
Validation loss: 2.6169411085477794

Epoch: 5| Step: 8
Training loss: 1.5282501887117454
Validation loss: 2.6660097024989975

Epoch: 5| Step: 9
Training loss: 1.0737260833137194
Validation loss: 2.6041303124300086

Epoch: 5| Step: 10
Training loss: 1.7281887629025883
Validation loss: 2.732920184589156

Epoch: 589| Step: 0
Training loss: 1.4842460977902356
Validation loss: 2.6826832220383823

Epoch: 5| Step: 1
Training loss: 1.52238772487232
Validation loss: 2.7136184530042295

Epoch: 5| Step: 2
Training loss: 1.6032504235294889
Validation loss: 2.697025324931042

Epoch: 5| Step: 3
Training loss: 1.729647611659499
Validation loss: 2.711694357193677

Epoch: 5| Step: 4
Training loss: 1.3077522418907754
Validation loss: 2.672164977536167

Epoch: 5| Step: 5
Training loss: 1.55565226155874
Validation loss: 2.672444865506602

Epoch: 5| Step: 6
Training loss: 1.7392682991375676
Validation loss: 2.5864821808606986

Epoch: 5| Step: 7
Training loss: 2.254637072469147
Validation loss: 2.6403600777447513

Epoch: 5| Step: 8
Training loss: 2.099867580416833
Validation loss: 2.614368932117613

Epoch: 5| Step: 9
Training loss: 1.8337500344284876
Validation loss: 2.606323851634365

Epoch: 5| Step: 10
Training loss: 1.6680131321168261
Validation loss: 2.6875542017323295

Epoch: 590| Step: 0
Training loss: 1.692554885560334
Validation loss: 2.564783918820544

Epoch: 5| Step: 1
Training loss: 1.3083006573299933
Validation loss: 2.641251737882704

Epoch: 5| Step: 2
Training loss: 2.4557201483767557
Validation loss: 2.6327797241449327

Epoch: 5| Step: 3
Training loss: 1.6974239297488225
Validation loss: 2.680924117964587

Epoch: 5| Step: 4
Training loss: 1.734474591669223
Validation loss: 2.7152810918440538

Epoch: 5| Step: 5
Training loss: 1.4761223515452802
Validation loss: 2.665329138840952

Epoch: 5| Step: 6
Training loss: 1.678944339027246
Validation loss: 2.5934219380212395

Epoch: 5| Step: 7
Training loss: 1.4168596790698613
Validation loss: 2.651867034255068

Epoch: 5| Step: 8
Training loss: 1.6515674255355388
Validation loss: 2.6664190121279816

Epoch: 5| Step: 9
Training loss: 1.0650913949712126
Validation loss: 2.6701838642835525

Epoch: 5| Step: 10
Training loss: 2.172840919039943
Validation loss: 2.6725012076537533

Epoch: 591| Step: 0
Training loss: 1.7947748931378453
Validation loss: 2.6362617007222147

Epoch: 5| Step: 1
Training loss: 2.110534236403429
Validation loss: 2.742814391946298

Epoch: 5| Step: 2
Training loss: 1.7635817731820866
Validation loss: 2.6887855421814506

Epoch: 5| Step: 3
Training loss: 1.5179890551266748
Validation loss: 2.658489992548974

Epoch: 5| Step: 4
Training loss: 1.9246019695024146
Validation loss: 2.70847887605738

Epoch: 5| Step: 5
Training loss: 1.4803824286344949
Validation loss: 2.5812367811249133

Epoch: 5| Step: 6
Training loss: 1.3552686999884547
Validation loss: 2.561631418402591

Epoch: 5| Step: 7
Training loss: 1.199945186316773
Validation loss: 2.705508623036658

Epoch: 5| Step: 8
Training loss: 1.4891162042049824
Validation loss: 2.6419313571525636

Epoch: 5| Step: 9
Training loss: 1.9980367322796693
Validation loss: 2.663491844949599

Epoch: 5| Step: 10
Training loss: 1.6634630009876707
Validation loss: 2.5712271444799732

Epoch: 592| Step: 0
Training loss: 1.491429720694418
Validation loss: 2.685009853213348

Epoch: 5| Step: 1
Training loss: 1.543321091223678
Validation loss: 2.6541386773522655

Epoch: 5| Step: 2
Training loss: 1.2830500170263848
Validation loss: 2.6908205147086224

Epoch: 5| Step: 3
Training loss: 1.5788456999103384
Validation loss: 2.723543172220587

Epoch: 5| Step: 4
Training loss: 1.6722840851457879
Validation loss: 2.6887572167401053

Epoch: 5| Step: 5
Training loss: 1.8948350800386413
Validation loss: 2.6607232123795743

Epoch: 5| Step: 6
Training loss: 1.6577917157019897
Validation loss: 2.704489524830987

Epoch: 5| Step: 7
Training loss: 1.7524148764187173
Validation loss: 2.6358913266716475

Epoch: 5| Step: 8
Training loss: 1.6643467333545992
Validation loss: 2.6409998054517834

Epoch: 5| Step: 9
Training loss: 2.584270942927138
Validation loss: 2.7338939969119553

Epoch: 5| Step: 10
Training loss: 1.3331250485019166
Validation loss: 2.6646450946467106

Epoch: 593| Step: 0
Training loss: 1.3998840777905597
Validation loss: 2.7275301352223162

Epoch: 5| Step: 1
Training loss: 1.643486361519836
Validation loss: 2.6619502288216683

Epoch: 5| Step: 2
Training loss: 1.5510950803899914
Validation loss: 2.7076207046130945

Epoch: 5| Step: 3
Training loss: 1.5887502147755452
Validation loss: 2.729761453527383

Epoch: 5| Step: 4
Training loss: 1.3415149464721876
Validation loss: 2.7012607477183304

Epoch: 5| Step: 5
Training loss: 1.5375663339835248
Validation loss: 2.5986499317748737

Epoch: 5| Step: 6
Training loss: 2.374106992179363
Validation loss: 2.6518626027589405

Epoch: 5| Step: 7
Training loss: 1.7450811193460734
Validation loss: 2.71111656629054

Epoch: 5| Step: 8
Training loss: 1.7904536406590832
Validation loss: 2.7022913995900626

Epoch: 5| Step: 9
Training loss: 1.1121388245553308
Validation loss: 2.630351239958732

Epoch: 5| Step: 10
Training loss: 2.0793057865953006
Validation loss: 2.637971317807392

Epoch: 594| Step: 0
Training loss: 0.9508253088893062
Validation loss: 2.6458484998686087

Epoch: 5| Step: 1
Training loss: 1.651932974183044
Validation loss: 2.6772395856427336

Epoch: 5| Step: 2
Training loss: 1.2673506099085876
Validation loss: 2.6348306073234777

Epoch: 5| Step: 3
Training loss: 1.6280768682061182
Validation loss: 2.6826224645890053

Epoch: 5| Step: 4
Training loss: 1.657602801349843
Validation loss: 2.694513717070709

Epoch: 5| Step: 5
Training loss: 1.6514510681036165
Validation loss: 2.692340747591341

Epoch: 5| Step: 6
Training loss: 1.6364485852270687
Validation loss: 2.6413519297382853

Epoch: 5| Step: 7
Training loss: 1.8350003711793612
Validation loss: 2.6140436519946113

Epoch: 5| Step: 8
Training loss: 2.397209723027328
Validation loss: 2.7224785651476164

Epoch: 5| Step: 9
Training loss: 1.6684312380258612
Validation loss: 2.661706630665074

Epoch: 5| Step: 10
Training loss: 1.7859254344355735
Validation loss: 2.692483176410776

Epoch: 595| Step: 0
Training loss: 1.4444016344296238
Validation loss: 2.663395956898921

Epoch: 5| Step: 1
Training loss: 2.323230385800468
Validation loss: 2.6353819400305993

Epoch: 5| Step: 2
Training loss: 1.118744572034913
Validation loss: 2.7122044338324947

Epoch: 5| Step: 3
Training loss: 2.007375825530819
Validation loss: 2.712349235443238

Epoch: 5| Step: 4
Training loss: 1.4091559161575664
Validation loss: 2.6615674547326216

Epoch: 5| Step: 5
Training loss: 1.7295538763657612
Validation loss: 2.758466653514412

Epoch: 5| Step: 6
Training loss: 1.7960537567929415
Validation loss: 2.6759263479163202

Epoch: 5| Step: 7
Training loss: 1.400231260545133
Validation loss: 2.658163048933197

Epoch: 5| Step: 8
Training loss: 1.8939851268679802
Validation loss: 2.702935937665167

Epoch: 5| Step: 9
Training loss: 1.6965542653492278
Validation loss: 2.59810266784541

Epoch: 5| Step: 10
Training loss: 1.5755502829413406
Validation loss: 2.687055403613968

Epoch: 596| Step: 0
Training loss: 1.541938920940137
Validation loss: 2.6683484421962187

Epoch: 5| Step: 1
Training loss: 1.7350321718910426
Validation loss: 2.646893284526481

Epoch: 5| Step: 2
Training loss: 1.3779238045808153
Validation loss: 2.6842208272713086

Epoch: 5| Step: 3
Training loss: 1.7813063495490054
Validation loss: 2.6114781401089764

Epoch: 5| Step: 4
Training loss: 1.836403191125017
Validation loss: 2.6268992655640986

Epoch: 5| Step: 5
Training loss: 1.5159496470923866
Validation loss: 2.6481451958045623

Epoch: 5| Step: 6
Training loss: 1.6837960318635852
Validation loss: 2.7096644541996198

Epoch: 5| Step: 7
Training loss: 1.8914000128572683
Validation loss: 2.6290034525574275

Epoch: 5| Step: 8
Training loss: 1.2925094295725883
Validation loss: 2.666123885499944

Epoch: 5| Step: 9
Training loss: 1.111383902653421
Validation loss: 2.6052738544881953

Epoch: 5| Step: 10
Training loss: 2.0279672946361864
Validation loss: 2.6876261272057125

Epoch: 597| Step: 0
Training loss: 1.3418930441252175
Validation loss: 2.6237388038284006

Epoch: 5| Step: 1
Training loss: 1.071841185456227
Validation loss: 2.6521438691740147

Epoch: 5| Step: 2
Training loss: 1.469244934452367
Validation loss: 2.628301459524081

Epoch: 5| Step: 3
Training loss: 2.309197309830574
Validation loss: 2.7404856653104477

Epoch: 5| Step: 4
Training loss: 1.6179765628347929
Validation loss: 2.6730622246504963

Epoch: 5| Step: 5
Training loss: 1.71428801757794
Validation loss: 2.6451960503412475

Epoch: 5| Step: 6
Training loss: 1.8432308047904347
Validation loss: 2.7313882508691565

Epoch: 5| Step: 7
Training loss: 1.5224313396637887
Validation loss: 2.709509975578234

Epoch: 5| Step: 8
Training loss: 1.4017759996169543
Validation loss: 2.7348202691204477

Epoch: 5| Step: 9
Training loss: 1.549184597021741
Validation loss: 2.7346867012465434

Epoch: 5| Step: 10
Training loss: 2.239774462210659
Validation loss: 2.576667873545881

Epoch: 598| Step: 0
Training loss: 1.9443912392860532
Validation loss: 2.656243321255341

Epoch: 5| Step: 1
Training loss: 1.2884707855654847
Validation loss: 2.631435810048813

Epoch: 5| Step: 2
Training loss: 1.6791890668991978
Validation loss: 2.6016514694036874

Epoch: 5| Step: 3
Training loss: 1.5484646422377548
Validation loss: 2.6596794732937954

Epoch: 5| Step: 4
Training loss: 1.277875503774277
Validation loss: 2.604257595976886

Epoch: 5| Step: 5
Training loss: 1.7597894021310918
Validation loss: 2.6646263154561938

Epoch: 5| Step: 6
Training loss: 1.5279715338097548
Validation loss: 2.5754378598324235

Epoch: 5| Step: 7
Training loss: 1.5624893951056131
Validation loss: 2.654499397343884

Epoch: 5| Step: 8
Training loss: 2.121354735109244
Validation loss: 2.6289755507915755

Epoch: 5| Step: 9
Training loss: 1.495507187561088
Validation loss: 2.6720174768112237

Epoch: 5| Step: 10
Training loss: 2.173375660985332
Validation loss: 2.678159650998033

Epoch: 599| Step: 0
Training loss: 0.7824986207358785
Validation loss: 2.6612905423700934

Epoch: 5| Step: 1
Training loss: 1.4801191657007495
Validation loss: 2.604344788068947

Epoch: 5| Step: 2
Training loss: 1.831670859866886
Validation loss: 2.6230581712124104

Epoch: 5| Step: 3
Training loss: 1.0495798269356893
Validation loss: 2.619849576945887

Epoch: 5| Step: 4
Training loss: 1.396250671891996
Validation loss: 2.6902982600892646

Epoch: 5| Step: 5
Training loss: 2.2381418128129136
Validation loss: 2.6909558950390444

Epoch: 5| Step: 6
Training loss: 1.988305591966355
Validation loss: 2.6680110098736214

Epoch: 5| Step: 7
Training loss: 1.7408083944084976
Validation loss: 2.622841902552039

Epoch: 5| Step: 8
Training loss: 1.2207778297453546
Validation loss: 2.6903281778181096

Epoch: 5| Step: 9
Training loss: 1.616515383901174
Validation loss: 2.6370181679272204

Epoch: 5| Step: 10
Training loss: 1.5360264920195195
Validation loss: 2.6485244659743588

Epoch: 600| Step: 0
Training loss: 1.6254051143676083
Validation loss: 2.6620553630166155

Epoch: 5| Step: 1
Training loss: 2.118941927968769
Validation loss: 2.7136374968335266

Epoch: 5| Step: 2
Training loss: 1.5667453313246347
Validation loss: 2.689452337640126

Epoch: 5| Step: 3
Training loss: 1.8578570926021147
Validation loss: 2.690864422125617

Epoch: 5| Step: 4
Training loss: 1.536829146127375
Validation loss: 2.5812114538395363

Epoch: 5| Step: 5
Training loss: 1.9787273990306706
Validation loss: 2.5521793487213786

Epoch: 5| Step: 6
Training loss: 1.789908796150004
Validation loss: 2.6242255940283794

Epoch: 5| Step: 7
Training loss: 1.407186916621437
Validation loss: 2.6473017251331155

Epoch: 5| Step: 8
Training loss: 0.9801717361498988
Validation loss: 2.656734140129876

Epoch: 5| Step: 9
Training loss: 1.4217625667847726
Validation loss: 2.6284469673575277

Epoch: 5| Step: 10
Training loss: 1.8118284888875469
Validation loss: 2.636886848733596

Epoch: 601| Step: 0
Training loss: 1.4612232275632164
Validation loss: 2.6487771867659804

Epoch: 5| Step: 1
Training loss: 1.763614218478078
Validation loss: 2.713225025091337

Epoch: 5| Step: 2
Training loss: 1.4521146153383009
Validation loss: 2.725561493981694

Epoch: 5| Step: 3
Training loss: 1.8126569219600648
Validation loss: 2.659526204453452

Epoch: 5| Step: 4
Training loss: 1.4323650364434801
Validation loss: 2.5604301885290877

Epoch: 5| Step: 5
Training loss: 2.2769004429566593
Validation loss: 2.652710740689961

Epoch: 5| Step: 6
Training loss: 1.7964966748889246
Validation loss: 2.680133622795824

Epoch: 5| Step: 7
Training loss: 1.1333567397187623
Validation loss: 2.6836975949754303

Epoch: 5| Step: 8
Training loss: 1.6809415172635986
Validation loss: 2.7040862873730753

Epoch: 5| Step: 9
Training loss: 1.3347934040129523
Validation loss: 2.667384643831338

Epoch: 5| Step: 10
Training loss: 1.0436739591207482
Validation loss: 2.6846250900013233

Epoch: 602| Step: 0
Training loss: 1.6302609013703497
Validation loss: 2.7014580003118116

Epoch: 5| Step: 1
Training loss: 1.482336149890838
Validation loss: 2.6925868803952335

Epoch: 5| Step: 2
Training loss: 1.8975351960105713
Validation loss: 2.6068267070491253

Epoch: 5| Step: 3
Training loss: 1.762992449202788
Validation loss: 2.6613907610490757

Epoch: 5| Step: 4
Training loss: 1.9886650509437156
Validation loss: 2.662567732632733

Epoch: 5| Step: 5
Training loss: 1.4832979812409792
Validation loss: 2.642968883314766

Epoch: 5| Step: 6
Training loss: 1.9013663097471651
Validation loss: 2.651535057570601

Epoch: 5| Step: 7
Training loss: 1.693783751992501
Validation loss: 2.6143400386864637

Epoch: 5| Step: 8
Training loss: 1.4975272300677245
Validation loss: 2.6286164377110315

Epoch: 5| Step: 9
Training loss: 1.470633496261158
Validation loss: 2.5782336060838205

Epoch: 5| Step: 10
Training loss: 1.1922965303613215
Validation loss: 2.6461404711450265

Epoch: 603| Step: 0
Training loss: 1.7726764138135365
Validation loss: 2.656644758295061

Epoch: 5| Step: 1
Training loss: 1.9019553161972
Validation loss: 2.669946844705521

Epoch: 5| Step: 2
Training loss: 1.784425214338162
Validation loss: 2.6315625902270945

Epoch: 5| Step: 3
Training loss: 1.3647932614277514
Validation loss: 2.601892392934822

Epoch: 5| Step: 4
Training loss: 1.649230332471689
Validation loss: 2.6408132248280918

Epoch: 5| Step: 5
Training loss: 1.5171961555273346
Validation loss: 2.632171737894602

Epoch: 5| Step: 6
Training loss: 1.3656971683244634
Validation loss: 2.6080115921258122

Epoch: 5| Step: 7
Training loss: 1.6539020810369782
Validation loss: 2.6755692995285623

Epoch: 5| Step: 8
Training loss: 1.3576784179647847
Validation loss: 2.7990438439441063

Epoch: 5| Step: 9
Training loss: 1.76897928753464
Validation loss: 2.644124676387243

Epoch: 5| Step: 10
Training loss: 2.197982521938709
Validation loss: 2.600348796040173

Epoch: 604| Step: 0
Training loss: 1.2852835084932
Validation loss: 2.6674655413388226

Epoch: 5| Step: 1
Training loss: 1.5048563544579563
Validation loss: 2.7324793306732023

Epoch: 5| Step: 2
Training loss: 1.9492320822831248
Validation loss: 2.7080516930632084

Epoch: 5| Step: 3
Training loss: 2.300023211486455
Validation loss: 2.6456672132485766

Epoch: 5| Step: 4
Training loss: 1.2304925825444952
Validation loss: 2.709976094373602

Epoch: 5| Step: 5
Training loss: 1.5689804728540722
Validation loss: 2.619509393055905

Epoch: 5| Step: 6
Training loss: 1.9159870670535157
Validation loss: 2.6801092616610354

Epoch: 5| Step: 7
Training loss: 1.5560723659142708
Validation loss: 2.7287621804637725

Epoch: 5| Step: 8
Training loss: 1.4160955156611816
Validation loss: 2.586076455688703

Epoch: 5| Step: 9
Training loss: 1.750974520050747
Validation loss: 2.5442838026244297

Epoch: 5| Step: 10
Training loss: 1.6517365334159448
Validation loss: 2.6349187978361477

Epoch: 605| Step: 0
Training loss: 1.6776085341202374
Validation loss: 2.655848019685815

Epoch: 5| Step: 1
Training loss: 1.5730395574330824
Validation loss: 2.675132866083029

Epoch: 5| Step: 2
Training loss: 1.1977076251313805
Validation loss: 2.6688397331278817

Epoch: 5| Step: 3
Training loss: 1.6545401330151568
Validation loss: 2.665464743409525

Epoch: 5| Step: 4
Training loss: 1.2395456399182108
Validation loss: 2.563575371919616

Epoch: 5| Step: 5
Training loss: 1.4379161564042984
Validation loss: 2.5991792585961417

Epoch: 5| Step: 6
Training loss: 1.4254168319070173
Validation loss: 2.647360632103697

Epoch: 5| Step: 7
Training loss: 1.6147052677831457
Validation loss: 2.6009900567787323

Epoch: 5| Step: 8
Training loss: 1.7850934107298497
Validation loss: 2.7103994800851643

Epoch: 5| Step: 9
Training loss: 2.630518788563363
Validation loss: 2.5858965508220453

Epoch: 5| Step: 10
Training loss: 1.4497441986962536
Validation loss: 2.68030574280688

Epoch: 606| Step: 0
Training loss: 1.4451249284429957
Validation loss: 2.6104357761974417

Epoch: 5| Step: 1
Training loss: 1.9007236232088927
Validation loss: 2.638684314886002

Epoch: 5| Step: 2
Training loss: 1.2524070452462417
Validation loss: 2.67051313294784

Epoch: 5| Step: 3
Training loss: 0.9870470505102376
Validation loss: 2.5821227400515108

Epoch: 5| Step: 4
Training loss: 2.090098370879029
Validation loss: 2.708831217573802

Epoch: 5| Step: 5
Training loss: 2.041410183528668
Validation loss: 2.7175429789162373

Epoch: 5| Step: 6
Training loss: 1.5388056351917707
Validation loss: 2.69466622885368

Epoch: 5| Step: 7
Training loss: 1.914699277248556
Validation loss: 2.6653127431350536

Epoch: 5| Step: 8
Training loss: 1.4847072831724515
Validation loss: 2.7248681948635687

Epoch: 5| Step: 9
Training loss: 1.7595068331664623
Validation loss: 2.603954937274929

Epoch: 5| Step: 10
Training loss: 1.5795896173444584
Validation loss: 2.7071736587776436

Epoch: 607| Step: 0
Training loss: 1.5440452200735832
Validation loss: 2.687362972657231

Epoch: 5| Step: 1
Training loss: 1.5669624691907253
Validation loss: 2.6763962197888027

Epoch: 5| Step: 2
Training loss: 2.311561497132013
Validation loss: 2.674110354976482

Epoch: 5| Step: 3
Training loss: 1.271485781339228
Validation loss: 2.6072145458340765

Epoch: 5| Step: 4
Training loss: 1.064126172730409
Validation loss: 2.6762428095788318

Epoch: 5| Step: 5
Training loss: 1.5230938646141987
Validation loss: 2.5958363098476154

Epoch: 5| Step: 6
Training loss: 1.2530468048280246
Validation loss: 2.6295469586626967

Epoch: 5| Step: 7
Training loss: 1.7715843702397258
Validation loss: 2.6387437076351445

Epoch: 5| Step: 8
Training loss: 1.6413561690332958
Validation loss: 2.653015220870944

Epoch: 5| Step: 9
Training loss: 1.794847289684887
Validation loss: 2.6904727399109127

Epoch: 5| Step: 10
Training loss: 1.8769905967822362
Validation loss: 2.6576021076834104

Epoch: 608| Step: 0
Training loss: 1.6154265468171622
Validation loss: 2.6058684179030354

Epoch: 5| Step: 1
Training loss: 1.1432404513949856
Validation loss: 2.6917547689719985

Epoch: 5| Step: 2
Training loss: 1.5929020888752208
Validation loss: 2.6208402085177807

Epoch: 5| Step: 3
Training loss: 1.2844978663574174
Validation loss: 2.6178374755387797

Epoch: 5| Step: 4
Training loss: 1.6129217232135704
Validation loss: 2.590932073178993

Epoch: 5| Step: 5
Training loss: 1.5966111474681248
Validation loss: 2.625382962396418

Epoch: 5| Step: 6
Training loss: 1.654879092614468
Validation loss: 2.675076046524854

Epoch: 5| Step: 7
Training loss: 2.593549238041662
Validation loss: 2.631242645972822

Epoch: 5| Step: 8
Training loss: 1.628269574268351
Validation loss: 2.633489509609739

Epoch: 5| Step: 9
Training loss: 1.5765846969206352
Validation loss: 2.627622695630356

Epoch: 5| Step: 10
Training loss: 1.4335815262858038
Validation loss: 2.7228345258388202

Epoch: 609| Step: 0
Training loss: 1.5341721503584351
Validation loss: 2.6536435343781632

Epoch: 5| Step: 1
Training loss: 1.5685154895352054
Validation loss: 2.6002995645021416

Epoch: 5| Step: 2
Training loss: 1.4222544907760328
Validation loss: 2.6364620330180806

Epoch: 5| Step: 3
Training loss: 1.3325968685331484
Validation loss: 2.6074517683148577

Epoch: 5| Step: 4
Training loss: 1.5034053612403737
Validation loss: 2.6840103646869844

Epoch: 5| Step: 5
Training loss: 1.8129436344615404
Validation loss: 2.6883460580636176

Epoch: 5| Step: 6
Training loss: 1.6856344295318584
Validation loss: 2.7354644836315622

Epoch: 5| Step: 7
Training loss: 1.5604158616244281
Validation loss: 2.6522620920994453

Epoch: 5| Step: 8
Training loss: 1.4444841640260617
Validation loss: 2.6568144283652524

Epoch: 5| Step: 9
Training loss: 1.2954390515765253
Validation loss: 2.65410229636466

Epoch: 5| Step: 10
Training loss: 2.241331249323838
Validation loss: 2.6597641902367646

Epoch: 610| Step: 0
Training loss: 1.9778655811648
Validation loss: 2.679318227072389

Epoch: 5| Step: 1
Training loss: 1.7959976708199537
Validation loss: 2.750454769026228

Epoch: 5| Step: 2
Training loss: 1.8619023945237834
Validation loss: 2.7679448683516226

Epoch: 5| Step: 3
Training loss: 1.3623319889737422
Validation loss: 2.747775344208093

Epoch: 5| Step: 4
Training loss: 1.5627810416195258
Validation loss: 2.6514503958015125

Epoch: 5| Step: 5
Training loss: 1.7711749327049635
Validation loss: 2.6586251513908143

Epoch: 5| Step: 6
Training loss: 1.2405211109700593
Validation loss: 2.6413451628530384

Epoch: 5| Step: 7
Training loss: 1.77270573378418
Validation loss: 2.6645629016380523

Epoch: 5| Step: 8
Training loss: 1.2242309861828413
Validation loss: 2.6120603146363206

Epoch: 5| Step: 9
Training loss: 1.4859849731691837
Validation loss: 2.664830303926331

Epoch: 5| Step: 10
Training loss: 1.5114950167276937
Validation loss: 2.6015726271768527

Epoch: 611| Step: 0
Training loss: 0.9896606047059096
Validation loss: 2.632675347952442

Epoch: 5| Step: 1
Training loss: 1.6271291868787945
Validation loss: 2.7653524817124775

Epoch: 5| Step: 2
Training loss: 1.498237846367228
Validation loss: 2.610335590469333

Epoch: 5| Step: 3
Training loss: 1.7667035209962265
Validation loss: 2.641570542633904

Epoch: 5| Step: 4
Training loss: 1.454840601025659
Validation loss: 2.6057041189383363

Epoch: 5| Step: 5
Training loss: 1.7888006160247096
Validation loss: 2.7269181569813514

Epoch: 5| Step: 6
Training loss: 2.239733905314149
Validation loss: 2.603928540243192

Epoch: 5| Step: 7
Training loss: 1.330908383160449
Validation loss: 2.633467940198517

Epoch: 5| Step: 8
Training loss: 1.4076489166160207
Validation loss: 2.6864749740375746

Epoch: 5| Step: 9
Training loss: 1.6540555271251791
Validation loss: 2.6538094771780574

Epoch: 5| Step: 10
Training loss: 1.9640540779072795
Validation loss: 2.6298078269624536

Epoch: 612| Step: 0
Training loss: 1.4423524805597554
Validation loss: 2.7111217434633894

Epoch: 5| Step: 1
Training loss: 1.3532284738917038
Validation loss: 2.619789945693633

Epoch: 5| Step: 2
Training loss: 1.6978233483380611
Validation loss: 2.6266213882143354

Epoch: 5| Step: 3
Training loss: 1.3970849939676426
Validation loss: 2.5844604925626826

Epoch: 5| Step: 4
Training loss: 1.5664980283567098
Validation loss: 2.642661888456898

Epoch: 5| Step: 5
Training loss: 1.5826844927135515
Validation loss: 2.6259785101415916

Epoch: 5| Step: 6
Training loss: 1.402403168760986
Validation loss: 2.718009556530663

Epoch: 5| Step: 7
Training loss: 1.3794666048648578
Validation loss: 2.7373455266802864

Epoch: 5| Step: 8
Training loss: 1.5012838908998656
Validation loss: 2.6214453404834326

Epoch: 5| Step: 9
Training loss: 1.6453149518377832
Validation loss: 2.6714972139177604

Epoch: 5| Step: 10
Training loss: 2.4149050924160966
Validation loss: 2.6719891021799302

Epoch: 613| Step: 0
Training loss: 1.4032446642444103
Validation loss: 2.7289898559989973

Epoch: 5| Step: 1
Training loss: 1.861957903831738
Validation loss: 2.7106131498835278

Epoch: 5| Step: 2
Training loss: 1.5769532640942316
Validation loss: 2.6304194101399383

Epoch: 5| Step: 3
Training loss: 1.6747459646000684
Validation loss: 2.6111726267798967

Epoch: 5| Step: 4
Training loss: 2.01286529163814
Validation loss: 2.6891698759987417

Epoch: 5| Step: 5
Training loss: 1.3381493534043953
Validation loss: 2.6791609662338094

Epoch: 5| Step: 6
Training loss: 1.315775553228125
Validation loss: 2.6406775936105746

Epoch: 5| Step: 7
Training loss: 1.6614263007285894
Validation loss: 2.708061316928387

Epoch: 5| Step: 8
Training loss: 1.8223934476287509
Validation loss: 2.5456667722460504

Epoch: 5| Step: 9
Training loss: 1.495645959040137
Validation loss: 2.718306075569505

Epoch: 5| Step: 10
Training loss: 1.77803633054812
Validation loss: 2.588566749246387

Epoch: 614| Step: 0
Training loss: 1.3147642042426746
Validation loss: 2.6614567914961955

Epoch: 5| Step: 1
Training loss: 1.5143255581973505
Validation loss: 2.7358597856773277

Epoch: 5| Step: 2
Training loss: 1.5863171202976067
Validation loss: 2.57476652524361

Epoch: 5| Step: 3
Training loss: 1.6205722199719004
Validation loss: 2.640741009684168

Epoch: 5| Step: 4
Training loss: 2.262294768409091
Validation loss: 2.6911994815007625

Epoch: 5| Step: 5
Training loss: 1.4580220389773946
Validation loss: 2.5652988114919424

Epoch: 5| Step: 6
Training loss: 1.4113253241035295
Validation loss: 2.653590134553951

Epoch: 5| Step: 7
Training loss: 1.6601907165539842
Validation loss: 2.6773234386142772

Epoch: 5| Step: 8
Training loss: 1.2259129061481868
Validation loss: 2.7032687241277102

Epoch: 5| Step: 9
Training loss: 1.7179371385497977
Validation loss: 2.6656602170271304

Epoch: 5| Step: 10
Training loss: 2.0528312391661867
Validation loss: 2.711754814017305

Epoch: 615| Step: 0
Training loss: 1.5194513059635897
Validation loss: 2.567021335667706

Epoch: 5| Step: 1
Training loss: 1.5941871342771678
Validation loss: 2.697966216257859

Epoch: 5| Step: 2
Training loss: 1.1899275812184167
Validation loss: 2.6517073623119667

Epoch: 5| Step: 3
Training loss: 1.6769622695854791
Validation loss: 2.6601928421232777

Epoch: 5| Step: 4
Training loss: 2.07152098886444
Validation loss: 2.651444776275239

Epoch: 5| Step: 5
Training loss: 1.6172806717574517
Validation loss: 2.605903920859512

Epoch: 5| Step: 6
Training loss: 1.416165637258615
Validation loss: 2.671353493445854

Epoch: 5| Step: 7
Training loss: 1.4679789040840108
Validation loss: 2.6869686762402365

Epoch: 5| Step: 8
Training loss: 1.788231269267959
Validation loss: 2.6770023949624067

Epoch: 5| Step: 9
Training loss: 1.854492444625443
Validation loss: 2.613873792918884

Epoch: 5| Step: 10
Training loss: 1.8976838299508776
Validation loss: 2.6680125367128245

Epoch: 616| Step: 0
Training loss: 1.9428780884675545
Validation loss: 2.6057146028990656

Epoch: 5| Step: 1
Training loss: 1.4749670542254207
Validation loss: 2.75923876777225

Epoch: 5| Step: 2
Training loss: 1.666925108263367
Validation loss: 2.697996101218829

Epoch: 5| Step: 3
Training loss: 1.183707253833358
Validation loss: 2.652712626663748

Epoch: 5| Step: 4
Training loss: 1.965094851759824
Validation loss: 2.6555790593694137

Epoch: 5| Step: 5
Training loss: 1.7292472023957153
Validation loss: 2.595961214184318

Epoch: 5| Step: 6
Training loss: 1.6240618271685923
Validation loss: 2.7245194666872696

Epoch: 5| Step: 7
Training loss: 1.3322655703822492
Validation loss: 2.6532298924241067

Epoch: 5| Step: 8
Training loss: 1.2760615548381042
Validation loss: 2.6235121071443013

Epoch: 5| Step: 9
Training loss: 1.575653709504144
Validation loss: 2.6514126822865625

Epoch: 5| Step: 10
Training loss: 1.6442815813114664
Validation loss: 2.7093384533347398

Epoch: 617| Step: 0
Training loss: 1.7304487722376016
Validation loss: 2.6273502443555388

Epoch: 5| Step: 1
Training loss: 1.324034956608898
Validation loss: 2.7159748616832844

Epoch: 5| Step: 2
Training loss: 2.0379301120353777
Validation loss: 2.5610137118659546

Epoch: 5| Step: 3
Training loss: 1.3874474128861516
Validation loss: 2.6912446887299657

Epoch: 5| Step: 4
Training loss: 2.063926203672637
Validation loss: 2.657301046377473

Epoch: 5| Step: 5
Training loss: 1.4966241678152603
Validation loss: 2.719340926728761

Epoch: 5| Step: 6
Training loss: 1.5408913836659945
Validation loss: 2.5946210359114485

Epoch: 5| Step: 7
Training loss: 1.5194637018796981
Validation loss: 2.678584960926756

Epoch: 5| Step: 8
Training loss: 1.172453216318878
Validation loss: 2.6788771639528255

Epoch: 5| Step: 9
Training loss: 1.538172818106739
Validation loss: 2.673039860118345

Epoch: 5| Step: 10
Training loss: 1.5507262097639691
Validation loss: 2.6991049934883478

Epoch: 618| Step: 0
Training loss: 1.5576650964908754
Validation loss: 2.652372845130353

Epoch: 5| Step: 1
Training loss: 1.6882701105529658
Validation loss: 2.6009489325831376

Epoch: 5| Step: 2
Training loss: 1.4495102417009333
Validation loss: 2.623020323138381

Epoch: 5| Step: 3
Training loss: 1.4559194296038662
Validation loss: 2.6397819068743664

Epoch: 5| Step: 4
Training loss: 1.6830551100087057
Validation loss: 2.66723182256396

Epoch: 5| Step: 5
Training loss: 1.5147493330051673
Validation loss: 2.6075947193784774

Epoch: 5| Step: 6
Training loss: 1.6723753278535098
Validation loss: 2.7026857845207295

Epoch: 5| Step: 7
Training loss: 1.549846453906136
Validation loss: 2.7020273791548886

Epoch: 5| Step: 8
Training loss: 1.424381938547506
Validation loss: 2.7158145599682486

Epoch: 5| Step: 9
Training loss: 1.3690775858124773
Validation loss: 2.7483218900345956

Epoch: 5| Step: 10
Training loss: 2.6916345242056456
Validation loss: 2.63805579312232

Epoch: 619| Step: 0
Training loss: 1.3253016812189442
Validation loss: 2.6979383178810132

Epoch: 5| Step: 1
Training loss: 1.1775120767350684
Validation loss: 2.6953718519222614

Epoch: 5| Step: 2
Training loss: 1.2989688653628568
Validation loss: 2.6666631608857934

Epoch: 5| Step: 3
Training loss: 1.4479916871027192
Validation loss: 2.698600387518862

Epoch: 5| Step: 4
Training loss: 1.9299547265232528
Validation loss: 2.655206197976118

Epoch: 5| Step: 5
Training loss: 1.3477668606243547
Validation loss: 2.54094734650959

Epoch: 5| Step: 6
Training loss: 1.846352631461111
Validation loss: 2.646573032510191

Epoch: 5| Step: 7
Training loss: 1.7773178601737307
Validation loss: 2.6579833019712362

Epoch: 5| Step: 8
Training loss: 2.246581023062016
Validation loss: 2.6617201755036035

Epoch: 5| Step: 9
Training loss: 1.694697747640069
Validation loss: 2.6177807290639072

Epoch: 5| Step: 10
Training loss: 1.5023227827064065
Validation loss: 2.594910964861009

Epoch: 620| Step: 0
Training loss: 1.5464380591216944
Validation loss: 2.587491350722752

Epoch: 5| Step: 1
Training loss: 1.6931463369360693
Validation loss: 2.6141758063390226

Epoch: 5| Step: 2
Training loss: 1.486539206636075
Validation loss: 2.627740360313809

Epoch: 5| Step: 3
Training loss: 2.1842087099797083
Validation loss: 2.652143832442092

Epoch: 5| Step: 4
Training loss: 1.4424666145996652
Validation loss: 2.5911339758576273

Epoch: 5| Step: 5
Training loss: 1.1740814291123867
Validation loss: 2.6778963435421903

Epoch: 5| Step: 6
Training loss: 1.575961906127629
Validation loss: 2.692234419289089

Epoch: 5| Step: 7
Training loss: 1.6965463955912903
Validation loss: 2.6768589284033513

Epoch: 5| Step: 8
Training loss: 1.6676360966678023
Validation loss: 2.685871333802967

Epoch: 5| Step: 9
Training loss: 1.5379540184002976
Validation loss: 2.689234169067946

Epoch: 5| Step: 10
Training loss: 1.5285090613279084
Validation loss: 2.678696296621408

Epoch: 621| Step: 0
Training loss: 1.9978898360512949
Validation loss: 2.660701554452711

Epoch: 5| Step: 1
Training loss: 1.3552370340571127
Validation loss: 2.5736092235728854

Epoch: 5| Step: 2
Training loss: 1.651855180082372
Validation loss: 2.7145785591951657

Epoch: 5| Step: 3
Training loss: 1.1727539835032554
Validation loss: 2.752741793930119

Epoch: 5| Step: 4
Training loss: 1.9604094504839424
Validation loss: 2.651095406315409

Epoch: 5| Step: 5
Training loss: 1.589389745574125
Validation loss: 2.7234427621539834

Epoch: 5| Step: 6
Training loss: 1.2974414737268816
Validation loss: 2.7732846093285466

Epoch: 5| Step: 7
Training loss: 1.747104633776734
Validation loss: 2.6380741016137845

Epoch: 5| Step: 8
Training loss: 1.7300651544638963
Validation loss: 2.6233234598868074

Epoch: 5| Step: 9
Training loss: 1.5735739625094434
Validation loss: 2.6373689336753037

Epoch: 5| Step: 10
Training loss: 1.541463847179049
Validation loss: 2.7007608654213278

Epoch: 622| Step: 0
Training loss: 1.1691985019438025
Validation loss: 2.6444916821790545

Epoch: 5| Step: 1
Training loss: 1.565527081806322
Validation loss: 2.659720915456847

Epoch: 5| Step: 2
Training loss: 1.526073971906576
Validation loss: 2.6103556568946327

Epoch: 5| Step: 3
Training loss: 1.2416521274218923
Validation loss: 2.6684966433722432

Epoch: 5| Step: 4
Training loss: 2.1609113866810103
Validation loss: 2.6658400791398047

Epoch: 5| Step: 5
Training loss: 1.8576517534454238
Validation loss: 2.60121705264924

Epoch: 5| Step: 6
Training loss: 1.6949824701938738
Validation loss: 2.661889027035786

Epoch: 5| Step: 7
Training loss: 1.6421236731759155
Validation loss: 2.6675794808687563

Epoch: 5| Step: 8
Training loss: 1.338941487171273
Validation loss: 2.6861423937257927

Epoch: 5| Step: 9
Training loss: 1.3636287475864541
Validation loss: 2.6250654574747636

Epoch: 5| Step: 10
Training loss: 1.425743374256121
Validation loss: 2.539279047942651

Epoch: 623| Step: 0
Training loss: 1.373597123002298
Validation loss: 2.645607191024775

Epoch: 5| Step: 1
Training loss: 1.2471503199973752
Validation loss: 2.6108309686344606

Epoch: 5| Step: 2
Training loss: 1.3067676157460055
Validation loss: 2.6830078398658044

Epoch: 5| Step: 3
Training loss: 1.6314673472628671
Validation loss: 2.6889071390110395

Epoch: 5| Step: 4
Training loss: 2.0274300676319723
Validation loss: 2.6512086603225185

Epoch: 5| Step: 5
Training loss: 1.5324629047627472
Validation loss: 2.6783803717960204

Epoch: 5| Step: 6
Training loss: 1.7038429217002378
Validation loss: 2.671874138376735

Epoch: 5| Step: 7
Training loss: 1.5473523414925685
Validation loss: 2.5864518657829767

Epoch: 5| Step: 8
Training loss: 2.3612812753830514
Validation loss: 2.6658749295909177

Epoch: 5| Step: 9
Training loss: 1.4509347796409489
Validation loss: 2.628624391118556

Epoch: 5| Step: 10
Training loss: 1.3492136042352656
Validation loss: 2.6619868646615377

Epoch: 624| Step: 0
Training loss: 1.7034064244130251
Validation loss: 2.599407954090389

Epoch: 5| Step: 1
Training loss: 1.5129757566406987
Validation loss: 2.6614791368094823

Epoch: 5| Step: 2
Training loss: 1.5457625579397907
Validation loss: 2.651651200963365

Epoch: 5| Step: 3
Training loss: 1.7800484335664255
Validation loss: 2.661655190856919

Epoch: 5| Step: 4
Training loss: 1.5401497500548427
Validation loss: 2.604348142802045

Epoch: 5| Step: 5
Training loss: 1.417957736726557
Validation loss: 2.6812695883324547

Epoch: 5| Step: 6
Training loss: 1.4819808122883111
Validation loss: 2.6664604836658548

Epoch: 5| Step: 7
Training loss: 2.1485522430296715
Validation loss: 2.624143395263959

Epoch: 5| Step: 8
Training loss: 1.3220230398406707
Validation loss: 2.67300786141178

Epoch: 5| Step: 9
Training loss: 1.418261116929699
Validation loss: 2.626108319393695

Epoch: 5| Step: 10
Training loss: 1.3397617148150378
Validation loss: 2.6164908385380174

Epoch: 625| Step: 0
Training loss: 1.6572082914155586
Validation loss: 2.6717005952626165

Epoch: 5| Step: 1
Training loss: 2.4386003407086
Validation loss: 2.692684665143595

Epoch: 5| Step: 2
Training loss: 1.31146694581484
Validation loss: 2.743475918284375

Epoch: 5| Step: 3
Training loss: 1.6766962429999905
Validation loss: 2.679388550927466

Epoch: 5| Step: 4
Training loss: 1.3484334722394673
Validation loss: 2.6149467454619733

Epoch: 5| Step: 5
Training loss: 1.2293536264940201
Validation loss: 2.624948843883824

Epoch: 5| Step: 6
Training loss: 1.1363321807149016
Validation loss: 2.5535928524037708

Epoch: 5| Step: 7
Training loss: 1.864000417566048
Validation loss: 2.52406505453062

Epoch: 5| Step: 8
Training loss: 1.539402415890636
Validation loss: 2.7044086081921797

Epoch: 5| Step: 9
Training loss: 1.363401784732899
Validation loss: 2.6922490365372975

Epoch: 5| Step: 10
Training loss: 1.8016762319564392
Validation loss: 2.670612251018983

Epoch: 626| Step: 0
Training loss: 1.7114633248601352
Validation loss: 2.685479744319202

Epoch: 5| Step: 1
Training loss: 1.1526194097261109
Validation loss: 2.594460399099614

Epoch: 5| Step: 2
Training loss: 1.4429174425455522
Validation loss: 2.5119589158740805

Epoch: 5| Step: 3
Training loss: 1.5472037996663615
Validation loss: 2.729267995519327

Epoch: 5| Step: 4
Training loss: 1.188302822782481
Validation loss: 2.6088618520063376

Epoch: 5| Step: 5
Training loss: 1.2859453370236726
Validation loss: 2.584612599756182

Epoch: 5| Step: 6
Training loss: 1.7055941540426443
Validation loss: 2.8038381386803386

Epoch: 5| Step: 7
Training loss: 2.249942778813401
Validation loss: 2.688886396941463

Epoch: 5| Step: 8
Training loss: 1.661541457373888
Validation loss: 2.649376857037874

Epoch: 5| Step: 9
Training loss: 1.7197061133482172
Validation loss: 2.586094838742642

Epoch: 5| Step: 10
Training loss: 0.9584155600281333
Validation loss: 2.6587498386175756

Epoch: 627| Step: 0
Training loss: 1.4268619152109099
Validation loss: 2.736778914097727

Epoch: 5| Step: 1
Training loss: 1.1254927297905577
Validation loss: 2.6078275941218645

Epoch: 5| Step: 2
Training loss: 1.641094830768792
Validation loss: 2.6729012349745425

Epoch: 5| Step: 3
Training loss: 1.539324278280445
Validation loss: 2.685325147975005

Epoch: 5| Step: 4
Training loss: 1.9297928877867172
Validation loss: 2.6213556922941135

Epoch: 5| Step: 5
Training loss: 2.3082318482199136
Validation loss: 2.709472462756802

Epoch: 5| Step: 6
Training loss: 1.740413155668244
Validation loss: 2.6971786261753863

Epoch: 5| Step: 7
Training loss: 1.4534056197717506
Validation loss: 2.703234099704991

Epoch: 5| Step: 8
Training loss: 1.2227309816574305
Validation loss: 2.6124115389757834

Epoch: 5| Step: 9
Training loss: 1.600156511162028
Validation loss: 2.6455626952882065

Epoch: 5| Step: 10
Training loss: 1.4700421270185935
Validation loss: 2.651159447834739

Epoch: 628| Step: 0
Training loss: 1.8155842551618344
Validation loss: 2.663543524560149

Epoch: 5| Step: 1
Training loss: 1.3226549485409187
Validation loss: 2.7229763787988044

Epoch: 5| Step: 2
Training loss: 1.2731027923879368
Validation loss: 2.685481174355179

Epoch: 5| Step: 3
Training loss: 1.4295529161488147
Validation loss: 2.6744050838850297

Epoch: 5| Step: 4
Training loss: 1.6576708331326448
Validation loss: 2.685133208304276

Epoch: 5| Step: 5
Training loss: 1.4013978110765468
Validation loss: 2.7531352335548425

Epoch: 5| Step: 6
Training loss: 1.4368652932800328
Validation loss: 2.64284220506494

Epoch: 5| Step: 7
Training loss: 1.6617386759794976
Validation loss: 2.574982875182023

Epoch: 5| Step: 8
Training loss: 1.8903389706479088
Validation loss: 2.761080649062836

Epoch: 5| Step: 9
Training loss: 2.035631940605552
Validation loss: 2.6860915077702407

Epoch: 5| Step: 10
Training loss: 1.7024599929343756
Validation loss: 2.640531804891059

Epoch: 629| Step: 0
Training loss: 1.2209939594947306
Validation loss: 2.667516494769021

Epoch: 5| Step: 1
Training loss: 2.0774821957997007
Validation loss: 2.594065286643916

Epoch: 5| Step: 2
Training loss: 1.2408790174588107
Validation loss: 2.6151745924380134

Epoch: 5| Step: 3
Training loss: 1.6059284526616868
Validation loss: 2.6264867127384424

Epoch: 5| Step: 4
Training loss: 1.5202750221957153
Validation loss: 2.5765694577604177

Epoch: 5| Step: 5
Training loss: 1.4801886703756542
Validation loss: 2.6299128423789533

Epoch: 5| Step: 6
Training loss: 1.2912399397215328
Validation loss: 2.662917648035085

Epoch: 5| Step: 7
Training loss: 1.9118486953427216
Validation loss: 2.657382572590913

Epoch: 5| Step: 8
Training loss: 0.9757860072121514
Validation loss: 2.6303167394916547

Epoch: 5| Step: 9
Training loss: 1.795393822590239
Validation loss: 2.68759431933421

Epoch: 5| Step: 10
Training loss: 1.9607551763510722
Validation loss: 2.6341806156029066

Epoch: 630| Step: 0
Training loss: 1.466957296851177
Validation loss: 2.5956235519552147

Epoch: 5| Step: 1
Training loss: 1.2237538538902315
Validation loss: 2.6184225989193473

Epoch: 5| Step: 2
Training loss: 1.6523767923428636
Validation loss: 2.6346361308811908

Epoch: 5| Step: 3
Training loss: 0.9768363873739316
Validation loss: 2.805786080360535

Epoch: 5| Step: 4
Training loss: 0.9053918458603012
Validation loss: 2.6574507931347027

Epoch: 5| Step: 5
Training loss: 1.566537979941593
Validation loss: 2.6266794218498335

Epoch: 5| Step: 6
Training loss: 2.219255201822871
Validation loss: 2.632738036095292

Epoch: 5| Step: 7
Training loss: 1.7379795455563034
Validation loss: 2.6931756631322448

Epoch: 5| Step: 8
Training loss: 1.638220778382934
Validation loss: 2.6117901313711944

Epoch: 5| Step: 9
Training loss: 2.163664302616398
Validation loss: 2.6718645645529824

Epoch: 5| Step: 10
Training loss: 1.887054287156353
Validation loss: 2.6374392543434775

Epoch: 631| Step: 0
Training loss: 1.418093421016179
Validation loss: 2.627747230525961

Epoch: 5| Step: 1
Training loss: 2.008269617908744
Validation loss: 2.630664209808778

Epoch: 5| Step: 2
Training loss: 1.4748575368067698
Validation loss: 2.6787076998227315

Epoch: 5| Step: 3
Training loss: 1.4184471983577
Validation loss: 2.6361195680205065

Epoch: 5| Step: 4
Training loss: 1.7075581381242815
Validation loss: 2.6367263639485223

Epoch: 5| Step: 5
Training loss: 1.7952055763960397
Validation loss: 2.662120790508026

Epoch: 5| Step: 6
Training loss: 0.9267876542877213
Validation loss: 2.7517013665792063

Epoch: 5| Step: 7
Training loss: 1.6390020426608862
Validation loss: 2.631733985493997

Epoch: 5| Step: 8
Training loss: 1.383362741425847
Validation loss: 2.6949896515794007

Epoch: 5| Step: 9
Training loss: 1.672687083730285
Validation loss: 2.7071252932110808

Epoch: 5| Step: 10
Training loss: 1.5672163164830684
Validation loss: 2.6848018196085026

Epoch: 632| Step: 0
Training loss: 1.5522461705479298
Validation loss: 2.64065676007021

Epoch: 5| Step: 1
Training loss: 1.7423103186590319
Validation loss: 2.7086405101081574

Epoch: 5| Step: 2
Training loss: 1.3272013425632836
Validation loss: 2.673331454706789

Epoch: 5| Step: 3
Training loss: 2.1637364771975185
Validation loss: 2.6431284682177396

Epoch: 5| Step: 4
Training loss: 1.404065958065934
Validation loss: 2.762541803182804

Epoch: 5| Step: 5
Training loss: 1.4788998466147525
Validation loss: 2.6756845232656947

Epoch: 5| Step: 6
Training loss: 1.4676492502717127
Validation loss: 2.7023905379211572

Epoch: 5| Step: 7
Training loss: 1.4524775877912501
Validation loss: 2.7137912152646346

Epoch: 5| Step: 8
Training loss: 1.1872966993878655
Validation loss: 2.722004120844239

Epoch: 5| Step: 9
Training loss: 1.5371073585894492
Validation loss: 2.720959647227073

Epoch: 5| Step: 10
Training loss: 1.755574136379488
Validation loss: 2.556954153416119

Epoch: 633| Step: 0
Training loss: 1.4242290251628538
Validation loss: 2.6173631746573123

Epoch: 5| Step: 1
Training loss: 1.3861515228268624
Validation loss: 2.618716380325717

Epoch: 5| Step: 2
Training loss: 1.2540067353197002
Validation loss: 2.561751399628553

Epoch: 5| Step: 3
Training loss: 2.362419942478293
Validation loss: 2.685880191466984

Epoch: 5| Step: 4
Training loss: 1.6064073923383513
Validation loss: 2.6759958268451003

Epoch: 5| Step: 5
Training loss: 1.4688132252172568
Validation loss: 2.692419336080545

Epoch: 5| Step: 6
Training loss: 1.5853760575830327
Validation loss: 2.7117348106335206

Epoch: 5| Step: 7
Training loss: 1.5336707307186446
Validation loss: 2.6103013243737467

Epoch: 5| Step: 8
Training loss: 1.4263770961717657
Validation loss: 2.6963937933550604

Epoch: 5| Step: 9
Training loss: 1.7117150338435956
Validation loss: 2.708144391634081

Epoch: 5| Step: 10
Training loss: 1.4300706693886847
Validation loss: 2.650293168924011

Epoch: 634| Step: 0
Training loss: 2.131700050961506
Validation loss: 2.6350150216716552

Epoch: 5| Step: 1
Training loss: 1.6171504951702984
Validation loss: 2.6165202265275576

Epoch: 5| Step: 2
Training loss: 1.5645511134555465
Validation loss: 2.633776416499008

Epoch: 5| Step: 3
Training loss: 1.6716384720381736
Validation loss: 2.6695554747284476

Epoch: 5| Step: 4
Training loss: 1.6314642053033328
Validation loss: 2.6786496554435377

Epoch: 5| Step: 5
Training loss: 1.6541056156502916
Validation loss: 2.7813788422526375

Epoch: 5| Step: 6
Training loss: 1.8357229553832186
Validation loss: 2.6703250488573174

Epoch: 5| Step: 7
Training loss: 1.0783433002107612
Validation loss: 2.660508826018401

Epoch: 5| Step: 8
Training loss: 1.5041552845250385
Validation loss: 2.6427231678579552

Epoch: 5| Step: 9
Training loss: 1.3180540734459052
Validation loss: 2.785180447095684

Epoch: 5| Step: 10
Training loss: 1.6321890338829876
Validation loss: 2.672483951354617

Epoch: 635| Step: 0
Training loss: 1.3735203584537707
Validation loss: 2.612295971436978

Epoch: 5| Step: 1
Training loss: 1.3222837460965178
Validation loss: 2.6691518225301962

Epoch: 5| Step: 2
Training loss: 2.0866704788823185
Validation loss: 2.659316277566886

Epoch: 5| Step: 3
Training loss: 1.717752062917755
Validation loss: 2.616726054697319

Epoch: 5| Step: 4
Training loss: 1.0583294190061576
Validation loss: 2.6786477327001603

Epoch: 5| Step: 5
Training loss: 1.6318743625319663
Validation loss: 2.703015907272749

Epoch: 5| Step: 6
Training loss: 1.57368145806304
Validation loss: 2.6681482489529698

Epoch: 5| Step: 7
Training loss: 1.7731583161261268
Validation loss: 2.683400443548738

Epoch: 5| Step: 8
Training loss: 0.9289226431077869
Validation loss: 2.646806739560086

Epoch: 5| Step: 9
Training loss: 1.6017575028959583
Validation loss: 2.6907796896762677

Epoch: 5| Step: 10
Training loss: 1.8023824792610588
Validation loss: 2.665832954166705

Epoch: 636| Step: 0
Training loss: 1.8693744828029926
Validation loss: 2.64201458802364

Epoch: 5| Step: 1
Training loss: 1.5035993783150352
Validation loss: 2.7069197481434206

Epoch: 5| Step: 2
Training loss: 1.3431151465067386
Validation loss: 2.651020245222046

Epoch: 5| Step: 3
Training loss: 1.8337252660330123
Validation loss: 2.6831904019816673

Epoch: 5| Step: 4
Training loss: 1.865302694777097
Validation loss: 2.6636314785590534

Epoch: 5| Step: 5
Training loss: 1.1501203391096053
Validation loss: 2.655633915507234

Epoch: 5| Step: 6
Training loss: 1.5819093256933459
Validation loss: 2.6841984984065976

Epoch: 5| Step: 7
Training loss: 1.4978495123413078
Validation loss: 2.6281450790249474

Epoch: 5| Step: 8
Training loss: 0.9939504265349131
Validation loss: 2.7325962770402037

Epoch: 5| Step: 9
Training loss: 1.832575865524323
Validation loss: 2.628567188466426

Epoch: 5| Step: 10
Training loss: 1.5734253201965047
Validation loss: 2.6704772006345445

Epoch: 637| Step: 0
Training loss: 1.308642486120209
Validation loss: 2.659493919283632

Epoch: 5| Step: 1
Training loss: 1.3264425054945617
Validation loss: 2.6284582491402535

Epoch: 5| Step: 2
Training loss: 1.392759335405968
Validation loss: 2.619638688101952

Epoch: 5| Step: 3
Training loss: 1.677341757188172
Validation loss: 2.7222248012783594

Epoch: 5| Step: 4
Training loss: 1.6447818229949274
Validation loss: 2.617334254531774

Epoch: 5| Step: 5
Training loss: 2.124064071091215
Validation loss: 2.6044167455555343

Epoch: 5| Step: 6
Training loss: 1.5082698780572832
Validation loss: 2.6686901518383483

Epoch: 5| Step: 7
Training loss: 1.4917171196245886
Validation loss: 2.6480393989725544

Epoch: 5| Step: 8
Training loss: 1.5143966416321206
Validation loss: 2.717164515662426

Epoch: 5| Step: 9
Training loss: 1.249245845269422
Validation loss: 2.73897043745719

Epoch: 5| Step: 10
Training loss: 1.4175217609652624
Validation loss: 2.6761905973522744

Epoch: 638| Step: 0
Training loss: 1.4236651878114053
Validation loss: 2.684721809736612

Epoch: 5| Step: 1
Training loss: 1.3721080625506386
Validation loss: 2.846767832342733

Epoch: 5| Step: 2
Training loss: 2.1619853162452127
Validation loss: 2.7838678100169347

Epoch: 5| Step: 3
Training loss: 1.2795783512205228
Validation loss: 2.6834829461342893

Epoch: 5| Step: 4
Training loss: 1.4799022546915597
Validation loss: 2.668349656595723

Epoch: 5| Step: 5
Training loss: 1.480622215670942
Validation loss: 2.631568209346113

Epoch: 5| Step: 6
Training loss: 1.5285953164621464
Validation loss: 2.6490171485863954

Epoch: 5| Step: 7
Training loss: 1.3710867944089953
Validation loss: 2.68088187756422

Epoch: 5| Step: 8
Training loss: 1.6020940875356766
Validation loss: 2.6573313471844213

Epoch: 5| Step: 9
Training loss: 1.5907808958150051
Validation loss: 2.7133647826487257

Epoch: 5| Step: 10
Training loss: 1.7669047216257432
Validation loss: 2.7141257773730354

Epoch: 639| Step: 0
Training loss: 1.3590208885855573
Validation loss: 2.552380201808632

Epoch: 5| Step: 1
Training loss: 2.3288691822622454
Validation loss: 2.684370784676706

Epoch: 5| Step: 2
Training loss: 1.1517108278231076
Validation loss: 2.6645695951281887

Epoch: 5| Step: 3
Training loss: 1.5046903869664592
Validation loss: 2.5946369347323204

Epoch: 5| Step: 4
Training loss: 1.6956579322302525
Validation loss: 2.6708632667359833

Epoch: 5| Step: 5
Training loss: 1.498840917354233
Validation loss: 2.64006225507873

Epoch: 5| Step: 6
Training loss: 1.1788005905379002
Validation loss: 2.674390461612063

Epoch: 5| Step: 7
Training loss: 1.5346618322091359
Validation loss: 2.7163742216855624

Epoch: 5| Step: 8
Training loss: 1.5257283519476093
Validation loss: 2.7271334904145528

Epoch: 5| Step: 9
Training loss: 1.4960288090966345
Validation loss: 2.606291696793251

Epoch: 5| Step: 10
Training loss: 1.0924179139713721
Validation loss: 2.6096493244794683

Epoch: 640| Step: 0
Training loss: 1.269368228715861
Validation loss: 2.6611971904745535

Epoch: 5| Step: 1
Training loss: 1.839502647188547
Validation loss: 2.633037242180615

Epoch: 5| Step: 2
Training loss: 1.5790148954842487
Validation loss: 2.5323004579271036

Epoch: 5| Step: 3
Training loss: 1.2631384830802814
Validation loss: 2.663229666142645

Epoch: 5| Step: 4
Training loss: 1.7129308506625747
Validation loss: 2.5851936634904757

Epoch: 5| Step: 5
Training loss: 2.2821897896320715
Validation loss: 2.708070103905855

Epoch: 5| Step: 6
Training loss: 1.2813675989285762
Validation loss: 2.6062376198954476

Epoch: 5| Step: 7
Training loss: 1.1854993128780593
Validation loss: 2.6415251986069777

Epoch: 5| Step: 8
Training loss: 1.431045137761145
Validation loss: 2.6235325027427088

Epoch: 5| Step: 9
Training loss: 1.3019402183719326
Validation loss: 2.669328002477548

Epoch: 5| Step: 10
Training loss: 1.7506433394321623
Validation loss: 2.692008424371354

Epoch: 641| Step: 0
Training loss: 1.4623429988480499
Validation loss: 2.66783496204928

Epoch: 5| Step: 1
Training loss: 1.5423762089101387
Validation loss: 2.6902731752904105

Epoch: 5| Step: 2
Training loss: 1.9552870723564089
Validation loss: 2.694995245944084

Epoch: 5| Step: 3
Training loss: 1.3989017078398778
Validation loss: 2.643381310172015

Epoch: 5| Step: 4
Training loss: 1.1131789846464586
Validation loss: 2.7587187833017097

Epoch: 5| Step: 5
Training loss: 1.6986372029270902
Validation loss: 2.597930720500861

Epoch: 5| Step: 6
Training loss: 2.1695948645359353
Validation loss: 2.7073571754822616

Epoch: 5| Step: 7
Training loss: 1.1152118206248758
Validation loss: 2.6870877855300233

Epoch: 5| Step: 8
Training loss: 1.1809642022155764
Validation loss: 2.7826293164978755

Epoch: 5| Step: 9
Training loss: 1.5984783715535036
Validation loss: 2.710222868362698

Epoch: 5| Step: 10
Training loss: 1.0414438136452588
Validation loss: 2.6390037785426075

Epoch: 642| Step: 0
Training loss: 1.4439309605396415
Validation loss: 2.6125853112291693

Epoch: 5| Step: 1
Training loss: 1.6186927755838336
Validation loss: 2.6822854095841584

Epoch: 5| Step: 2
Training loss: 1.2677901785683583
Validation loss: 2.7316586166702987

Epoch: 5| Step: 3
Training loss: 1.6137010522299406
Validation loss: 2.6681059432107332

Epoch: 5| Step: 4
Training loss: 1.4132263915220582
Validation loss: 2.643371898887719

Epoch: 5| Step: 5
Training loss: 1.5475323754099282
Validation loss: 2.6731921728920125

Epoch: 5| Step: 6
Training loss: 1.4570598855157766
Validation loss: 2.7726854158774277

Epoch: 5| Step: 7
Training loss: 2.2631387683499105
Validation loss: 2.616098250789689

Epoch: 5| Step: 8
Training loss: 1.5150856552837795
Validation loss: 2.595327361988162

Epoch: 5| Step: 9
Training loss: 1.546454478430394
Validation loss: 2.630107138307557

Epoch: 5| Step: 10
Training loss: 1.3494561159419558
Validation loss: 2.646980613097584

Epoch: 643| Step: 0
Training loss: 1.8589137170312513
Validation loss: 2.6429978740726843

Epoch: 5| Step: 1
Training loss: 1.5865267706486976
Validation loss: 2.6364949945194955

Epoch: 5| Step: 2
Training loss: 0.9399604934141553
Validation loss: 2.6370218908651215

Epoch: 5| Step: 3
Training loss: 1.2245554934972762
Validation loss: 2.552099648164623

Epoch: 5| Step: 4
Training loss: 1.2540909580601627
Validation loss: 2.6426537328316275

Epoch: 5| Step: 5
Training loss: 1.25081555464222
Validation loss: 2.729146784641338

Epoch: 5| Step: 6
Training loss: 2.143807266404679
Validation loss: 2.698916348657295

Epoch: 5| Step: 7
Training loss: 1.354888659966817
Validation loss: 2.6454822855493276

Epoch: 5| Step: 8
Training loss: 1.6802292061171629
Validation loss: 2.680435516819652

Epoch: 5| Step: 9
Training loss: 1.5542015964922513
Validation loss: 2.5975389674780516

Epoch: 5| Step: 10
Training loss: 1.8041985580174704
Validation loss: 2.6645258259213813

Epoch: 644| Step: 0
Training loss: 1.565424128455312
Validation loss: 2.7266770271308824

Epoch: 5| Step: 1
Training loss: 1.146241352377317
Validation loss: 2.6424115020989416

Epoch: 5| Step: 2
Training loss: 1.631740455413672
Validation loss: 2.671406282921698

Epoch: 5| Step: 3
Training loss: 1.6268443131895873
Validation loss: 2.64666933729333

Epoch: 5| Step: 4
Training loss: 1.5369592227329096
Validation loss: 2.5927630218407267

Epoch: 5| Step: 5
Training loss: 1.5576653260831304
Validation loss: 2.7169032478959285

Epoch: 5| Step: 6
Training loss: 1.3959413553068964
Validation loss: 2.604707144158934

Epoch: 5| Step: 7
Training loss: 1.4688680073832412
Validation loss: 2.7094319329601486

Epoch: 5| Step: 8
Training loss: 2.0342479003955423
Validation loss: 2.6217228893167177

Epoch: 5| Step: 9
Training loss: 1.4345110627176942
Validation loss: 2.733040055593984

Epoch: 5| Step: 10
Training loss: 1.115797231506589
Validation loss: 2.7481823896601876

Epoch: 645| Step: 0
Training loss: 1.661361149384101
Validation loss: 2.6762923788790958

Epoch: 5| Step: 1
Training loss: 1.1561341614304022
Validation loss: 2.6013119913329503

Epoch: 5| Step: 2
Training loss: 2.0234631864471213
Validation loss: 2.637370308146227

Epoch: 5| Step: 3
Training loss: 1.4574896779030195
Validation loss: 2.692500699672996

Epoch: 5| Step: 4
Training loss: 1.5861490042829651
Validation loss: 2.6875633533715284

Epoch: 5| Step: 5
Training loss: 1.1549457720622294
Validation loss: 2.547198992364446

Epoch: 5| Step: 6
Training loss: 1.6393286533472484
Validation loss: 2.6185673986317344

Epoch: 5| Step: 7
Training loss: 1.2292346396752092
Validation loss: 2.6226989174696804

Epoch: 5| Step: 8
Training loss: 1.6462079197307158
Validation loss: 2.6611012120330764

Epoch: 5| Step: 9
Training loss: 1.2148883480214403
Validation loss: 2.602226001497315

Epoch: 5| Step: 10
Training loss: 1.7905453862305103
Validation loss: 2.6431026001484614

Epoch: 646| Step: 0
Training loss: 1.5198525527914089
Validation loss: 2.677880137746885

Epoch: 5| Step: 1
Training loss: 1.8114859276355775
Validation loss: 2.657123746736753

Epoch: 5| Step: 2
Training loss: 1.0144055601770865
Validation loss: 2.594542515590399

Epoch: 5| Step: 3
Training loss: 1.0966271840518051
Validation loss: 2.678486559021896

Epoch: 5| Step: 4
Training loss: 1.4044909601759212
Validation loss: 2.7047472255525555

Epoch: 5| Step: 5
Training loss: 1.8280416616370943
Validation loss: 2.7213341343001036

Epoch: 5| Step: 6
Training loss: 1.5847038394278945
Validation loss: 2.6684664650255594

Epoch: 5| Step: 7
Training loss: 1.363380144352457
Validation loss: 2.7040580217139

Epoch: 5| Step: 8
Training loss: 1.5425458497539513
Validation loss: 2.5916639118742455

Epoch: 5| Step: 9
Training loss: 1.9194030992195728
Validation loss: 2.658151791957494

Epoch: 5| Step: 10
Training loss: 1.6104497931635928
Validation loss: 2.6808890132239904

Epoch: 647| Step: 0
Training loss: 1.7003977226181053
Validation loss: 2.647472596280249

Epoch: 5| Step: 1
Training loss: 1.5974543287646799
Validation loss: 2.655118730558099

Epoch: 5| Step: 2
Training loss: 1.4346240756125022
Validation loss: 2.6685378501345722

Epoch: 5| Step: 3
Training loss: 1.2978930786014098
Validation loss: 2.636698273610008

Epoch: 5| Step: 4
Training loss: 1.3136607441585149
Validation loss: 2.6295895064860346

Epoch: 5| Step: 5
Training loss: 1.3868784208113716
Validation loss: 2.680175559815706

Epoch: 5| Step: 6
Training loss: 1.5513097213327405
Validation loss: 2.7235392489261177

Epoch: 5| Step: 7
Training loss: 1.6767297296943953
Validation loss: 2.6411352022097856

Epoch: 5| Step: 8
Training loss: 2.089628005255457
Validation loss: 2.652328907513709

Epoch: 5| Step: 9
Training loss: 0.8772648382663214
Validation loss: 2.6592834311905778

Epoch: 5| Step: 10
Training loss: 1.251269458844287
Validation loss: 2.619297803931278

Epoch: 648| Step: 0
Training loss: 1.626087924935479
Validation loss: 2.6658760104861456

Epoch: 5| Step: 1
Training loss: 1.1561646301096153
Validation loss: 2.731897948005575

Epoch: 5| Step: 2
Training loss: 1.565760148662511
Validation loss: 2.6727045432931855

Epoch: 5| Step: 3
Training loss: 1.2105464180732841
Validation loss: 2.594092559827466

Epoch: 5| Step: 4
Training loss: 1.4927921368362203
Validation loss: 2.6492146989856473

Epoch: 5| Step: 5
Training loss: 1.2424305612053794
Validation loss: 2.605100460521763

Epoch: 5| Step: 6
Training loss: 1.5343209437775411
Validation loss: 2.684488812640283

Epoch: 5| Step: 7
Training loss: 2.3467454206552647
Validation loss: 2.6325878126428717

Epoch: 5| Step: 8
Training loss: 1.7164978530741466
Validation loss: 2.6274413013603635

Epoch: 5| Step: 9
Training loss: 1.552737445948221
Validation loss: 2.7093086281951377

Epoch: 5| Step: 10
Training loss: 1.2780530167807564
Validation loss: 2.708014501794718

Epoch: 649| Step: 0
Training loss: 1.1657810198808316
Validation loss: 2.6314113132468164

Epoch: 5| Step: 1
Training loss: 1.2419321049547196
Validation loss: 2.6955156289877635

Epoch: 5| Step: 2
Training loss: 1.6866674842128857
Validation loss: 2.7189713792128543

Epoch: 5| Step: 3
Training loss: 1.5079710881929824
Validation loss: 2.6302224218055583

Epoch: 5| Step: 4
Training loss: 2.142551084641641
Validation loss: 2.706219851096107

Epoch: 5| Step: 5
Training loss: 1.1902373035621483
Validation loss: 2.7530458070624646

Epoch: 5| Step: 6
Training loss: 1.3432353608884822
Validation loss: 2.6877745659568872

Epoch: 5| Step: 7
Training loss: 1.6350292872801
Validation loss: 2.5984505941961236

Epoch: 5| Step: 8
Training loss: 1.872591760931007
Validation loss: 2.6746270586514345

Epoch: 5| Step: 9
Training loss: 1.4735065302450079
Validation loss: 2.6662950378567554

Epoch: 5| Step: 10
Training loss: 1.529504286925589
Validation loss: 2.746685640126883

Epoch: 650| Step: 0
Training loss: 1.5659839698292595
Validation loss: 2.663675515584667

Epoch: 5| Step: 1
Training loss: 1.2887559005942624
Validation loss: 2.625027867846562

Epoch: 5| Step: 2
Training loss: 1.6343975495921776
Validation loss: 2.64828511003345

Epoch: 5| Step: 3
Training loss: 1.6545301901125578
Validation loss: 2.6800681988544355

Epoch: 5| Step: 4
Training loss: 1.2337124168909634
Validation loss: 2.6468868436808797

Epoch: 5| Step: 5
Training loss: 1.6686997966858361
Validation loss: 2.6116810134672788

Epoch: 5| Step: 6
Training loss: 1.539409617670938
Validation loss: 2.686408872381698

Epoch: 5| Step: 7
Training loss: 1.5193487611840713
Validation loss: 2.7297382715844827

Epoch: 5| Step: 8
Training loss: 1.3572719573519485
Validation loss: 2.62892122960287

Epoch: 5| Step: 9
Training loss: 1.4399777495466564
Validation loss: 2.7059299716191707

Epoch: 5| Step: 10
Training loss: 1.894729194918476
Validation loss: 2.67533730013488

Epoch: 651| Step: 0
Training loss: 1.4083890117646731
Validation loss: 2.701018773823905

Epoch: 5| Step: 1
Training loss: 1.2063995486042332
Validation loss: 2.746951192802198

Epoch: 5| Step: 2
Training loss: 1.4377211525015774
Validation loss: 2.681314512651265

Epoch: 5| Step: 3
Training loss: 1.595385366899749
Validation loss: 2.640496924810611

Epoch: 5| Step: 4
Training loss: 1.7122036503452904
Validation loss: 2.6305652013641696

Epoch: 5| Step: 5
Training loss: 1.3047815620184993
Validation loss: 2.6443716382642326

Epoch: 5| Step: 6
Training loss: 2.0424296322377478
Validation loss: 2.5990304619800537

Epoch: 5| Step: 7
Training loss: 1.4072766265328986
Validation loss: 2.69118526960161

Epoch: 5| Step: 8
Training loss: 1.4837960971526427
Validation loss: 2.6321141983917493

Epoch: 5| Step: 9
Training loss: 1.338744443780391
Validation loss: 2.6829700291159044

Epoch: 5| Step: 10
Training loss: 1.0818377710875418
Validation loss: 2.6516983634277516

Epoch: 652| Step: 0
Training loss: 1.5604000476042137
Validation loss: 2.678173946376973

Epoch: 5| Step: 1
Training loss: 1.6390334629508727
Validation loss: 2.650891753536768

Epoch: 5| Step: 2
Training loss: 1.5727312429240676
Validation loss: 2.7481974672656917

Epoch: 5| Step: 3
Training loss: 0.9380447394533455
Validation loss: 2.6477139815325463

Epoch: 5| Step: 4
Training loss: 2.433689072703001
Validation loss: 2.5972744386243933

Epoch: 5| Step: 5
Training loss: 1.0719419452903576
Validation loss: 2.6689970085022066

Epoch: 5| Step: 6
Training loss: 1.5172703257777092
Validation loss: 2.753527823252429

Epoch: 5| Step: 7
Training loss: 1.6308878821890977
Validation loss: 2.7331244655879585

Epoch: 5| Step: 8
Training loss: 1.387702872076524
Validation loss: 2.6874494192519953

Epoch: 5| Step: 9
Training loss: 1.3171389660202986
Validation loss: 2.7058740024557393

Epoch: 5| Step: 10
Training loss: 1.2788875478263722
Validation loss: 2.6825148221518456

Epoch: 653| Step: 0
Training loss: 1.26276361527067
Validation loss: 2.6952365592874354

Epoch: 5| Step: 1
Training loss: 1.456442542711008
Validation loss: 2.6312382830181926

Epoch: 5| Step: 2
Training loss: 1.0351464037157012
Validation loss: 2.6165500158964257

Epoch: 5| Step: 3
Training loss: 1.3490942318285812
Validation loss: 2.6860977839827505

Epoch: 5| Step: 4
Training loss: 2.342324395533969
Validation loss: 2.6332600180577312

Epoch: 5| Step: 5
Training loss: 1.1084130643308023
Validation loss: 2.638006558781687

Epoch: 5| Step: 6
Training loss: 1.8062324021482032
Validation loss: 2.5242759759014732

Epoch: 5| Step: 7
Training loss: 1.842708681522363
Validation loss: 2.6645786438688486

Epoch: 5| Step: 8
Training loss: 1.4406551068318956
Validation loss: 2.626379619330766

Epoch: 5| Step: 9
Training loss: 1.33056775014267
Validation loss: 2.7037982015842728

Epoch: 5| Step: 10
Training loss: 1.5570375709386248
Validation loss: 2.685793513005515

Epoch: 654| Step: 0
Training loss: 1.1860060077727357
Validation loss: 2.6073617894229337

Epoch: 5| Step: 1
Training loss: 1.489120206885532
Validation loss: 2.639756434294802

Epoch: 5| Step: 2
Training loss: 1.4144412213245743
Validation loss: 2.695191232581682

Epoch: 5| Step: 3
Training loss: 2.1638809293187857
Validation loss: 2.61307621005614

Epoch: 5| Step: 4
Training loss: 1.8029106607756595
Validation loss: 2.7529370279963663

Epoch: 5| Step: 5
Training loss: 1.4011438278143429
Validation loss: 2.690615897420331

Epoch: 5| Step: 6
Training loss: 1.413639363581472
Validation loss: 2.717247917290798

Epoch: 5| Step: 7
Training loss: 1.2165489372792815
Validation loss: 2.627347879620997

Epoch: 5| Step: 8
Training loss: 1.283536777636659
Validation loss: 2.648379732121993

Epoch: 5| Step: 9
Training loss: 1.3978018568091286
Validation loss: 2.68841551544625

Epoch: 5| Step: 10
Training loss: 1.415438914752549
Validation loss: 2.619208355808064

Epoch: 655| Step: 0
Training loss: 1.4312053190361707
Validation loss: 2.6865090605872126

Epoch: 5| Step: 1
Training loss: 1.8164798844701844
Validation loss: 2.653972786046833

Epoch: 5| Step: 2
Training loss: 1.9722896424113858
Validation loss: 2.5862292955475485

Epoch: 5| Step: 3
Training loss: 1.5821378695505621
Validation loss: 2.618465123859066

Epoch: 5| Step: 4
Training loss: 1.3141428338895127
Validation loss: 2.679822541592242

Epoch: 5| Step: 5
Training loss: 1.2867278255659087
Validation loss: 2.7071289239967076

Epoch: 5| Step: 6
Training loss: 1.6006422422791904
Validation loss: 2.728064293667511

Epoch: 5| Step: 7
Training loss: 1.2367291756706793
Validation loss: 2.6967285545397917

Epoch: 5| Step: 8
Training loss: 0.9653885264789457
Validation loss: 2.664685194447583

Epoch: 5| Step: 9
Training loss: 1.809054025698378
Validation loss: 2.7666898234475985

Epoch: 5| Step: 10
Training loss: 1.4365346403741872
Validation loss: 2.6894771936985

Epoch: 656| Step: 0
Training loss: 1.3848822669657963
Validation loss: 2.528241496406976

Epoch: 5| Step: 1
Training loss: 1.4472932182286489
Validation loss: 2.6639311556034433

Epoch: 5| Step: 2
Training loss: 1.891579946415115
Validation loss: 2.645296309889632

Epoch: 5| Step: 3
Training loss: 1.241415491663897
Validation loss: 2.70129046336518

Epoch: 5| Step: 4
Training loss: 1.253349965133968
Validation loss: 2.697950611826635

Epoch: 5| Step: 5
Training loss: 1.929870164387919
Validation loss: 2.5770278002980405

Epoch: 5| Step: 6
Training loss: 1.5033725336437909
Validation loss: 2.5809225536410048

Epoch: 5| Step: 7
Training loss: 1.7085745183754553
Validation loss: 2.657750894108714

Epoch: 5| Step: 8
Training loss: 1.1885399531163472
Validation loss: 2.6700842444818345

Epoch: 5| Step: 9
Training loss: 1.6399662693555692
Validation loss: 2.6396658861173146

Epoch: 5| Step: 10
Training loss: 1.5585633850964031
Validation loss: 2.627089369638451

Epoch: 657| Step: 0
Training loss: 1.6051255947658845
Validation loss: 2.696915761128911

Epoch: 5| Step: 1
Training loss: 1.0626734423722515
Validation loss: 2.710338125662369

Epoch: 5| Step: 2
Training loss: 1.7307790645906875
Validation loss: 2.646599944771733

Epoch: 5| Step: 3
Training loss: 1.0324550870128
Validation loss: 2.6888716050513763

Epoch: 5| Step: 4
Training loss: 1.2566718384883375
Validation loss: 2.7071872801107304

Epoch: 5| Step: 5
Training loss: 1.929313468977597
Validation loss: 2.6478031894502343

Epoch: 5| Step: 6
Training loss: 1.3946098070430872
Validation loss: 2.6938648465965875

Epoch: 5| Step: 7
Training loss: 1.3869564658568299
Validation loss: 2.5826257265183528

Epoch: 5| Step: 8
Training loss: 1.3279857786922318
Validation loss: 2.7036257888167508

Epoch: 5| Step: 9
Training loss: 1.9169495277108293
Validation loss: 2.6662562670412733

Epoch: 5| Step: 10
Training loss: 1.1255870453039567
Validation loss: 2.6470587575516897

Epoch: 658| Step: 0
Training loss: 1.2844812539508308
Validation loss: 2.627928758789339

Epoch: 5| Step: 1
Training loss: 1.5083504147203448
Validation loss: 2.6062645109377667

Epoch: 5| Step: 2
Training loss: 1.5833715718654529
Validation loss: 2.7280806505382897

Epoch: 5| Step: 3
Training loss: 1.9872786536608655
Validation loss: 2.6789393336497382

Epoch: 5| Step: 4
Training loss: 1.2403307779646846
Validation loss: 2.5742368542342384

Epoch: 5| Step: 5
Training loss: 1.4634430966381229
Validation loss: 2.7371307840287127

Epoch: 5| Step: 6
Training loss: 1.6531192772230812
Validation loss: 2.722554708340378

Epoch: 5| Step: 7
Training loss: 1.4559723225048429
Validation loss: 2.714660673297607

Epoch: 5| Step: 8
Training loss: 1.2624804202534934
Validation loss: 2.6882266840970184

Epoch: 5| Step: 9
Training loss: 1.1006369523932542
Validation loss: 2.714873997810531

Epoch: 5| Step: 10
Training loss: 1.5977939089389799
Validation loss: 2.6767290145106

Epoch: 659| Step: 0
Training loss: 1.2007718048022058
Validation loss: 2.625731704621885

Epoch: 5| Step: 1
Training loss: 1.964914491263499
Validation loss: 2.651493908051655

Epoch: 5| Step: 2
Training loss: 1.4692627843586534
Validation loss: 2.598091547310355

Epoch: 5| Step: 3
Training loss: 1.5644466480973527
Validation loss: 2.6902190921867115

Epoch: 5| Step: 4
Training loss: 1.4084904519117358
Validation loss: 2.5785700916301573

Epoch: 5| Step: 5
Training loss: 1.4830406214474643
Validation loss: 2.6747804330995337

Epoch: 5| Step: 6
Training loss: 1.5422911109633035
Validation loss: 2.6464163251205233

Epoch: 5| Step: 7
Training loss: 1.4217923318494885
Validation loss: 2.649770625924474

Epoch: 5| Step: 8
Training loss: 1.300747295314507
Validation loss: 2.6658101202738886

Epoch: 5| Step: 9
Training loss: 1.5357290660108878
Validation loss: 2.749578564850145

Epoch: 5| Step: 10
Training loss: 1.5417107584378806
Validation loss: 2.6142303780264755

Epoch: 660| Step: 0
Training loss: 1.2606013874647302
Validation loss: 2.5294056884073495

Epoch: 5| Step: 1
Training loss: 1.2691840063719424
Validation loss: 2.6067878581872628

Epoch: 5| Step: 2
Training loss: 1.0968181084553552
Validation loss: 2.6769089493363722

Epoch: 5| Step: 3
Training loss: 1.3007245208925289
Validation loss: 2.6757666314149913

Epoch: 5| Step: 4
Training loss: 1.7619170692620323
Validation loss: 2.7213223699184157

Epoch: 5| Step: 5
Training loss: 1.185217520953731
Validation loss: 2.797780078216052

Epoch: 5| Step: 6
Training loss: 1.7281215757367112
Validation loss: 2.75848875481248

Epoch: 5| Step: 7
Training loss: 1.456058044225046
Validation loss: 2.734263327760268

Epoch: 5| Step: 8
Training loss: 1.6353642724587827
Validation loss: 2.74320964229015

Epoch: 5| Step: 9
Training loss: 1.3865160726804904
Validation loss: 2.6661213719784165

Epoch: 5| Step: 10
Training loss: 2.176456257677432
Validation loss: 2.7539708293067804

Epoch: 661| Step: 0
Training loss: 1.0543268222802769
Validation loss: 2.657878602791322

Epoch: 5| Step: 1
Training loss: 1.1007326395579204
Validation loss: 2.752978409591137

Epoch: 5| Step: 2
Training loss: 1.1563109304509098
Validation loss: 2.702173355134528

Epoch: 5| Step: 3
Training loss: 1.2490315977639754
Validation loss: 2.620692232858299

Epoch: 5| Step: 4
Training loss: 1.5245424616109053
Validation loss: 2.671300492753036

Epoch: 5| Step: 5
Training loss: 1.837463134603416
Validation loss: 2.6127734700223018

Epoch: 5| Step: 6
Training loss: 1.8814044926976288
Validation loss: 2.6569884902926066

Epoch: 5| Step: 7
Training loss: 1.5652446292382323
Validation loss: 2.6627582170445425

Epoch: 5| Step: 8
Training loss: 1.377760024409269
Validation loss: 2.7000338821533614

Epoch: 5| Step: 9
Training loss: 1.3734952756080432
Validation loss: 2.7389710692483207

Epoch: 5| Step: 10
Training loss: 1.7352784699013089
Validation loss: 2.595258080376194

Epoch: 662| Step: 0
Training loss: 1.0529217102167492
Validation loss: 2.6675347086962997

Epoch: 5| Step: 1
Training loss: 1.6645403968261077
Validation loss: 2.6729593667780045

Epoch: 5| Step: 2
Training loss: 1.5858781925631422
Validation loss: 2.569409996403397

Epoch: 5| Step: 3
Training loss: 1.532153349683912
Validation loss: 2.703855547753278

Epoch: 5| Step: 4
Training loss: 2.147653221552862
Validation loss: 2.7106516480118352

Epoch: 5| Step: 5
Training loss: 1.3087379034552682
Validation loss: 2.6712418353925447

Epoch: 5| Step: 6
Training loss: 1.2719809504438073
Validation loss: 2.658252910141083

Epoch: 5| Step: 7
Training loss: 1.1856985482190827
Validation loss: 2.7967502458240237

Epoch: 5| Step: 8
Training loss: 1.2675273397232112
Validation loss: 2.6142074895944245

Epoch: 5| Step: 9
Training loss: 1.444376627031018
Validation loss: 2.750795523391379

Epoch: 5| Step: 10
Training loss: 1.3153879545596696
Validation loss: 2.730835396382559

Epoch: 663| Step: 0
Training loss: 1.2428965913841705
Validation loss: 2.7245961286899307

Epoch: 5| Step: 1
Training loss: 1.4596879480614828
Validation loss: 2.6738781312025024

Epoch: 5| Step: 2
Training loss: 1.0671758424895754
Validation loss: 2.6597452358599383

Epoch: 5| Step: 3
Training loss: 1.0550625734620143
Validation loss: 2.729979397741342

Epoch: 5| Step: 4
Training loss: 1.4693546268116782
Validation loss: 2.7277028425010923

Epoch: 5| Step: 5
Training loss: 0.9945746712746247
Validation loss: 2.627852711685942

Epoch: 5| Step: 6
Training loss: 1.4425314876352662
Validation loss: 2.655721651694296

Epoch: 5| Step: 7
Training loss: 2.0762882002704433
Validation loss: 2.643057940033233

Epoch: 5| Step: 8
Training loss: 1.9496148878450283
Validation loss: 2.638904167854997

Epoch: 5| Step: 9
Training loss: 1.239462352373296
Validation loss: 2.6386849930349277

Epoch: 5| Step: 10
Training loss: 1.4420125869698968
Validation loss: 2.7110287098146713

Epoch: 664| Step: 0
Training loss: 1.4306898928448908
Validation loss: 2.7000946067086464

Epoch: 5| Step: 1
Training loss: 1.5052578487853687
Validation loss: 2.593830887716456

Epoch: 5| Step: 2
Training loss: 1.210985145862052
Validation loss: 2.654371383137849

Epoch: 5| Step: 3
Training loss: 1.4433172526943094
Validation loss: 2.6971888116043052

Epoch: 5| Step: 4
Training loss: 1.3695437807770914
Validation loss: 2.6742545571132963

Epoch: 5| Step: 5
Training loss: 1.1465215985625647
Validation loss: 2.6217662925976017

Epoch: 5| Step: 6
Training loss: 1.2539425663427648
Validation loss: 2.7139231269016197

Epoch: 5| Step: 7
Training loss: 1.9433590682906479
Validation loss: 2.6964171193571658

Epoch: 5| Step: 8
Training loss: 1.5627959161926215
Validation loss: 2.7125517861239334

Epoch: 5| Step: 9
Training loss: 1.127071909867155
Validation loss: 2.6954046798668116

Epoch: 5| Step: 10
Training loss: 1.6434258667207164
Validation loss: 2.7023046281106913

Epoch: 665| Step: 0
Training loss: 1.3038271048578018
Validation loss: 2.5916459145407718

Epoch: 5| Step: 1
Training loss: 1.4048552484034342
Validation loss: 2.59472833698255

Epoch: 5| Step: 2
Training loss: 1.9560736409115131
Validation loss: 2.6916832547895937

Epoch: 5| Step: 3
Training loss: 1.2629837450172974
Validation loss: 2.706704982185504

Epoch: 5| Step: 4
Training loss: 1.732796921930899
Validation loss: 2.700892212744617

Epoch: 5| Step: 5
Training loss: 1.574540628320312
Validation loss: 2.6615758692964344

Epoch: 5| Step: 6
Training loss: 1.2550962036616404
Validation loss: 2.6777869218846524

Epoch: 5| Step: 7
Training loss: 1.3308133013481056
Validation loss: 2.6215967578682227

Epoch: 5| Step: 8
Training loss: 1.1857353952961347
Validation loss: 2.6731803798160216

Epoch: 5| Step: 9
Training loss: 1.6331157493986266
Validation loss: 2.6930747129324684

Epoch: 5| Step: 10
Training loss: 1.1550473840910356
Validation loss: 2.6479519058789385

Epoch: 666| Step: 0
Training loss: 1.4123819386252465
Validation loss: 2.661327814395559

Epoch: 5| Step: 1
Training loss: 1.613277924836729
Validation loss: 2.7149821126587295

Epoch: 5| Step: 2
Training loss: 1.0205363730490578
Validation loss: 2.6915963126922358

Epoch: 5| Step: 3
Training loss: 1.1136927864629584
Validation loss: 2.7382674341290785

Epoch: 5| Step: 4
Training loss: 1.283751395279554
Validation loss: 2.6566150875238557

Epoch: 5| Step: 5
Training loss: 1.3997787351825206
Validation loss: 2.620310615028505

Epoch: 5| Step: 6
Training loss: 1.517979317244002
Validation loss: 2.7033290905726526

Epoch: 5| Step: 7
Training loss: 1.40939293488385
Validation loss: 2.6996149294410743

Epoch: 5| Step: 8
Training loss: 1.7377423426174439
Validation loss: 2.6707468607011995

Epoch: 5| Step: 9
Training loss: 2.2438747955725082
Validation loss: 2.640765408776013

Epoch: 5| Step: 10
Training loss: 1.4693499212424854
Validation loss: 2.6601790138870287

Epoch: 667| Step: 0
Training loss: 1.0776226697869347
Validation loss: 2.722185431358685

Epoch: 5| Step: 1
Training loss: 0.9111666657760822
Validation loss: 2.7046769563128863

Epoch: 5| Step: 2
Training loss: 1.3983368224660078
Validation loss: 2.673835869138538

Epoch: 5| Step: 3
Training loss: 1.6516232915136286
Validation loss: 2.5999131588123015

Epoch: 5| Step: 4
Training loss: 2.131601513823095
Validation loss: 2.61820883195378

Epoch: 5| Step: 5
Training loss: 1.2948905745415793
Validation loss: 2.7530972368459516

Epoch: 5| Step: 6
Training loss: 1.0346813912126362
Validation loss: 2.6686367812337095

Epoch: 5| Step: 7
Training loss: 1.4536068845383272
Validation loss: 2.718779819632865

Epoch: 5| Step: 8
Training loss: 1.116652887648409
Validation loss: 2.6941753093475715

Epoch: 5| Step: 9
Training loss: 1.6970010952965657
Validation loss: 2.662453904562428

Epoch: 5| Step: 10
Training loss: 1.4371014747495798
Validation loss: 2.763732797706401

Epoch: 668| Step: 0
Training loss: 1.4118934983404832
Validation loss: 2.7306325589502225

Epoch: 5| Step: 1
Training loss: 1.431493983233109
Validation loss: 2.645435371794534

Epoch: 5| Step: 2
Training loss: 1.0107372928814156
Validation loss: 2.7295959078428615

Epoch: 5| Step: 3
Training loss: 1.5545473275180954
Validation loss: 2.6438710042300357

Epoch: 5| Step: 4
Training loss: 1.7188031275080902
Validation loss: 2.6543827855650024

Epoch: 5| Step: 5
Training loss: 1.619227647455999
Validation loss: 2.6818303817967535

Epoch: 5| Step: 6
Training loss: 1.3981355735436967
Validation loss: 2.7044583371239868

Epoch: 5| Step: 7
Training loss: 1.2058071114027165
Validation loss: 2.6346682000808186

Epoch: 5| Step: 8
Training loss: 1.3176675521309777
Validation loss: 2.57586164465504

Epoch: 5| Step: 9
Training loss: 2.086792845501297
Validation loss: 2.6774466250410023

Epoch: 5| Step: 10
Training loss: 1.3910155015927705
Validation loss: 2.693588609611873

Epoch: 669| Step: 0
Training loss: 1.4187939977335542
Validation loss: 2.701665997278094

Epoch: 5| Step: 1
Training loss: 1.2050887096564633
Validation loss: 2.607696244698146

Epoch: 5| Step: 2
Training loss: 1.3646566890577914
Validation loss: 2.724912283732077

Epoch: 5| Step: 3
Training loss: 1.5344668483241848
Validation loss: 2.6981378552444237

Epoch: 5| Step: 4
Training loss: 1.3824870701852625
Validation loss: 2.6592078816356888

Epoch: 5| Step: 5
Training loss: 1.0529453158258062
Validation loss: 2.7111166655788796

Epoch: 5| Step: 6
Training loss: 1.8737479798126018
Validation loss: 2.6599932899208505

Epoch: 5| Step: 7
Training loss: 1.6124092313074005
Validation loss: 2.6508279531302126

Epoch: 5| Step: 8
Training loss: 1.3951015641898288
Validation loss: 2.6646163528778564

Epoch: 5| Step: 9
Training loss: 1.5844847691900248
Validation loss: 2.728959561733922

Epoch: 5| Step: 10
Training loss: 1.4052620702393794
Validation loss: 2.6904905049517924

Epoch: 670| Step: 0
Training loss: 1.2668985623020834
Validation loss: 2.744655683206713

Epoch: 5| Step: 1
Training loss: 1.4432815716619114
Validation loss: 2.6556853493473964

Epoch: 5| Step: 2
Training loss: 1.199660030526471
Validation loss: 2.693926151293813

Epoch: 5| Step: 3
Training loss: 1.3498738494848361
Validation loss: 2.649498037516756

Epoch: 5| Step: 4
Training loss: 1.7162390660926063
Validation loss: 2.6782628777336575

Epoch: 5| Step: 5
Training loss: 1.627033135506356
Validation loss: 2.6387816362186713

Epoch: 5| Step: 6
Training loss: 1.6033209102860455
Validation loss: 2.596798228061739

Epoch: 5| Step: 7
Training loss: 0.863630750514685
Validation loss: 2.560497987537261

Epoch: 5| Step: 8
Training loss: 2.1290834125682676
Validation loss: 2.6355937421781888

Epoch: 5| Step: 9
Training loss: 1.3258341161093008
Validation loss: 2.757572916983638

Epoch: 5| Step: 10
Training loss: 1.2342689082269944
Validation loss: 2.7092790440195857

Epoch: 671| Step: 0
Training loss: 1.5628348182529326
Validation loss: 2.675676632135322

Epoch: 5| Step: 1
Training loss: 1.4457320970313687
Validation loss: 2.7478719151363267

Epoch: 5| Step: 2
Training loss: 1.2655868524524359
Validation loss: 2.617946321168797

Epoch: 5| Step: 3
Training loss: 1.3144941167688882
Validation loss: 2.6927471044246003

Epoch: 5| Step: 4
Training loss: 1.4256740582030503
Validation loss: 2.706053400968421

Epoch: 5| Step: 5
Training loss: 2.0670469621215
Validation loss: 2.710832324802184

Epoch: 5| Step: 6
Training loss: 1.4706523830784242
Validation loss: 2.5939481965659676

Epoch: 5| Step: 7
Training loss: 1.2574322048591307
Validation loss: 2.648912463751302

Epoch: 5| Step: 8
Training loss: 1.2603986229143578
Validation loss: 2.702611759381529

Epoch: 5| Step: 9
Training loss: 1.5146542616042926
Validation loss: 2.703226373400374

Epoch: 5| Step: 10
Training loss: 1.2769587691991304
Validation loss: 2.679902066366971

Epoch: 672| Step: 0
Training loss: 1.3363770325159714
Validation loss: 2.625392465507342

Epoch: 5| Step: 1
Training loss: 1.312584647219265
Validation loss: 2.6718958419872525

Epoch: 5| Step: 2
Training loss: 1.301244658899843
Validation loss: 2.674014521731196

Epoch: 5| Step: 3
Training loss: 1.4776026377391558
Validation loss: 2.6866340181602673

Epoch: 5| Step: 4
Training loss: 1.4606832191182897
Validation loss: 2.7517143296180793

Epoch: 5| Step: 5
Training loss: 1.3845902561898993
Validation loss: 2.699998266750495

Epoch: 5| Step: 6
Training loss: 1.5808171641089783
Validation loss: 2.798966905563564

Epoch: 5| Step: 7
Training loss: 1.2022321286109656
Validation loss: 2.7233036366370817

Epoch: 5| Step: 8
Training loss: 1.4164330439445083
Validation loss: 2.6857694208407437

Epoch: 5| Step: 9
Training loss: 1.1268559088335435
Validation loss: 2.774700653949824

Epoch: 5| Step: 10
Training loss: 2.123310651772812
Validation loss: 2.660612925465469

Epoch: 673| Step: 0
Training loss: 1.9840946149607717
Validation loss: 2.6322020445593455

Epoch: 5| Step: 1
Training loss: 1.2231222611339627
Validation loss: 2.6910671423716215

Epoch: 5| Step: 2
Training loss: 1.6041207327603513
Validation loss: 2.6652265067561807

Epoch: 5| Step: 3
Training loss: 1.3082896776063437
Validation loss: 2.7021353334492293

Epoch: 5| Step: 4
Training loss: 0.9855967916879981
Validation loss: 2.7569885910245464

Epoch: 5| Step: 5
Training loss: 1.4060682391215606
Validation loss: 2.5933747962246625

Epoch: 5| Step: 6
Training loss: 1.8187619264611443
Validation loss: 2.6716431519124355

Epoch: 5| Step: 7
Training loss: 1.375214516638763
Validation loss: 2.7241407713812134

Epoch: 5| Step: 8
Training loss: 1.182021049863949
Validation loss: 2.7437222739895

Epoch: 5| Step: 9
Training loss: 1.4985561574469255
Validation loss: 2.7455505731042478

Epoch: 5| Step: 10
Training loss: 1.449504731538017
Validation loss: 2.679710322792046

Epoch: 674| Step: 0
Training loss: 1.2313877609562907
Validation loss: 2.680757746367037

Epoch: 5| Step: 1
Training loss: 1.2684491989524773
Validation loss: 2.7460750479481364

Epoch: 5| Step: 2
Training loss: 1.2016962163010574
Validation loss: 2.693771589065277

Epoch: 5| Step: 3
Training loss: 0.9581300616643872
Validation loss: 2.6158824112461128

Epoch: 5| Step: 4
Training loss: 1.6059942197683788
Validation loss: 2.641878184436493

Epoch: 5| Step: 5
Training loss: 1.4837254759538183
Validation loss: 2.7121138070800463

Epoch: 5| Step: 6
Training loss: 1.2644260520264088
Validation loss: 2.718573717647663

Epoch: 5| Step: 7
Training loss: 1.128563165505082
Validation loss: 2.6690646603624066

Epoch: 5| Step: 8
Training loss: 1.9647651186428232
Validation loss: 2.6648694461419336

Epoch: 5| Step: 9
Training loss: 1.5793139822630373
Validation loss: 2.7004555647162998

Epoch: 5| Step: 10
Training loss: 1.7976916240476002
Validation loss: 2.6441723405546975

Epoch: 675| Step: 0
Training loss: 1.2265453458910676
Validation loss: 2.5987002067229086

Epoch: 5| Step: 1
Training loss: 1.7765644754551462
Validation loss: 2.721513056288325

Epoch: 5| Step: 2
Training loss: 1.5226428967394854
Validation loss: 2.715267966670186

Epoch: 5| Step: 3
Training loss: 1.2699599730574305
Validation loss: 2.640562026283919

Epoch: 5| Step: 4
Training loss: 1.2253523767428416
Validation loss: 2.6795296456436044

Epoch: 5| Step: 5
Training loss: 1.344616632670807
Validation loss: 2.681213766049631

Epoch: 5| Step: 6
Training loss: 1.4703113292401606
Validation loss: 2.6917559556683366

Epoch: 5| Step: 7
Training loss: 1.2923894777395613
Validation loss: 2.633328443940394

Epoch: 5| Step: 8
Training loss: 1.4969980081813814
Validation loss: 2.7396340719710484

Epoch: 5| Step: 9
Training loss: 1.0712650265079333
Validation loss: 2.658641251809505

Epoch: 5| Step: 10
Training loss: 2.2888691791233122
Validation loss: 2.6122375922508536

Epoch: 676| Step: 0
Training loss: 1.5416857056687905
Validation loss: 2.685268655783315

Epoch: 5| Step: 1
Training loss: 1.0838446999679805
Validation loss: 2.701712692785816

Epoch: 5| Step: 2
Training loss: 1.54089308566975
Validation loss: 2.6611784139268835

Epoch: 5| Step: 3
Training loss: 1.3797180552571469
Validation loss: 2.675494624745336

Epoch: 5| Step: 4
Training loss: 1.3079417867801268
Validation loss: 2.722801283844886

Epoch: 5| Step: 5
Training loss: 1.3087301610191717
Validation loss: 2.7074201295335216

Epoch: 5| Step: 6
Training loss: 1.2965525950257826
Validation loss: 2.7790819811019087

Epoch: 5| Step: 7
Training loss: 1.289273423942796
Validation loss: 2.6884955813124867

Epoch: 5| Step: 8
Training loss: 1.5426026501496681
Validation loss: 2.887335722881677

Epoch: 5| Step: 9
Training loss: 1.7113174643638362
Validation loss: 2.627319580701504

Epoch: 5| Step: 10
Training loss: 1.9959117112136902
Validation loss: 2.6504510931304783

Epoch: 677| Step: 0
Training loss: 1.336502535716633
Validation loss: 2.6562129105566887

Epoch: 5| Step: 1
Training loss: 1.2707678772792474
Validation loss: 2.7351549761821037

Epoch: 5| Step: 2
Training loss: 1.1166507525282685
Validation loss: 2.6604284382424304

Epoch: 5| Step: 3
Training loss: 1.3408485404069552
Validation loss: 2.6779460028570408

Epoch: 5| Step: 4
Training loss: 1.4199542811918449
Validation loss: 2.68618359654696

Epoch: 5| Step: 5
Training loss: 1.3986729684708352
Validation loss: 2.624131581055921

Epoch: 5| Step: 6
Training loss: 2.2994048011882953
Validation loss: 2.607085211355175

Epoch: 5| Step: 7
Training loss: 1.5888235206910561
Validation loss: 2.7046053866526054

Epoch: 5| Step: 8
Training loss: 1.4992169879626662
Validation loss: 2.6133669942716304

Epoch: 5| Step: 9
Training loss: 1.3712831893423492
Validation loss: 2.6489585562093656

Epoch: 5| Step: 10
Training loss: 1.4693850503867423
Validation loss: 2.7447289797905525

Epoch: 678| Step: 0
Training loss: 1.6878168726926064
Validation loss: 2.752817307714311

Epoch: 5| Step: 1
Training loss: 1.0896954179130978
Validation loss: 2.778887247578522

Epoch: 5| Step: 2
Training loss: 1.3833047023169587
Validation loss: 2.7678908765519767

Epoch: 5| Step: 3
Training loss: 1.3620859059313104
Validation loss: 2.6925416195310254

Epoch: 5| Step: 4
Training loss: 1.619350295531721
Validation loss: 2.654613351864651

Epoch: 5| Step: 5
Training loss: 1.6219852799571972
Validation loss: 2.698525658450854

Epoch: 5| Step: 6
Training loss: 1.2215937180920295
Validation loss: 2.7537232101284475

Epoch: 5| Step: 7
Training loss: 1.3487501928914438
Validation loss: 2.6546587294551176

Epoch: 5| Step: 8
Training loss: 1.7245105961368734
Validation loss: 2.671112999652675

Epoch: 5| Step: 9
Training loss: 1.5152016274516984
Validation loss: 2.730766706273638

Epoch: 5| Step: 10
Training loss: 1.9311935786921925
Validation loss: 2.729910999750872

Epoch: 679| Step: 0
Training loss: 1.3777064650206754
Validation loss: 2.701117232799495

Epoch: 5| Step: 1
Training loss: 1.6507469740566474
Validation loss: 2.7078500441109705

Epoch: 5| Step: 2
Training loss: 1.0287963113291512
Validation loss: 2.7088144416173208

Epoch: 5| Step: 3
Training loss: 1.2244191972701244
Validation loss: 2.701117446347842

Epoch: 5| Step: 4
Training loss: 1.5263400865566337
Validation loss: 2.670422338365008

Epoch: 5| Step: 5
Training loss: 1.4758731100594182
Validation loss: 2.683176686534805

Epoch: 5| Step: 6
Training loss: 2.1715353281624314
Validation loss: 2.7069410968957657

Epoch: 5| Step: 7
Training loss: 0.8507046709721875
Validation loss: 2.6749222754778263

Epoch: 5| Step: 8
Training loss: 1.385973189968501
Validation loss: 2.662669151040439

Epoch: 5| Step: 9
Training loss: 1.46379511619511
Validation loss: 2.6962916391758096

Epoch: 5| Step: 10
Training loss: 1.8376071561332734
Validation loss: 2.7238847040301706

Epoch: 680| Step: 0
Training loss: 1.2223749781767639
Validation loss: 2.769916758157431

Epoch: 5| Step: 1
Training loss: 1.3874144192670408
Validation loss: 2.655128796361431

Epoch: 5| Step: 2
Training loss: 1.780834885797224
Validation loss: 2.7236562506596877

Epoch: 5| Step: 3
Training loss: 1.3697143745614444
Validation loss: 2.751236800606285

Epoch: 5| Step: 4
Training loss: 1.5862223552582548
Validation loss: 2.6513285271472116

Epoch: 5| Step: 5
Training loss: 1.0386730984569057
Validation loss: 2.7354600385519476

Epoch: 5| Step: 6
Training loss: 1.2811702145181258
Validation loss: 2.6142341643069074

Epoch: 5| Step: 7
Training loss: 1.2000547595245576
Validation loss: 2.7025175979999165

Epoch: 5| Step: 8
Training loss: 2.0358645328728815
Validation loss: 2.7070093242655404

Epoch: 5| Step: 9
Training loss: 0.9905623395097592
Validation loss: 2.6836615669386803

Epoch: 5| Step: 10
Training loss: 1.6262879769350014
Validation loss: 2.6983995058218273

Epoch: 681| Step: 0
Training loss: 1.2248146578651056
Validation loss: 2.650490440442797

Epoch: 5| Step: 1
Training loss: 1.202680530439289
Validation loss: 2.626894605547229

Epoch: 5| Step: 2
Training loss: 2.0110729773590195
Validation loss: 2.6521347267759707

Epoch: 5| Step: 3
Training loss: 1.1711298289985783
Validation loss: 2.7356170214913207

Epoch: 5| Step: 4
Training loss: 1.572355999925885
Validation loss: 2.688842600239809

Epoch: 5| Step: 5
Training loss: 1.423382808501407
Validation loss: 2.7424286804444113

Epoch: 5| Step: 6
Training loss: 1.5423032460165997
Validation loss: 2.689174283195569

Epoch: 5| Step: 7
Training loss: 1.4812051758241271
Validation loss: 2.695540002106151

Epoch: 5| Step: 8
Training loss: 1.3801746532241508
Validation loss: 2.7023292597015973

Epoch: 5| Step: 9
Training loss: 0.9962730994232911
Validation loss: 2.695923334012113

Epoch: 5| Step: 10
Training loss: 1.4024024037285598
Validation loss: 2.7289544691304823

Epoch: 682| Step: 0
Training loss: 1.7491791707476863
Validation loss: 2.6824415143348745

Epoch: 5| Step: 1
Training loss: 1.1616794848909293
Validation loss: 2.7650997561559048

Epoch: 5| Step: 2
Training loss: 1.8565610220466129
Validation loss: 2.6075587999715912

Epoch: 5| Step: 3
Training loss: 1.5789899816116724
Validation loss: 2.6845059268324394

Epoch: 5| Step: 4
Training loss: 1.255902326688837
Validation loss: 2.684685163292354

Epoch: 5| Step: 5
Training loss: 1.2853214888162152
Validation loss: 2.654707910873215

Epoch: 5| Step: 6
Training loss: 1.398376932377604
Validation loss: 2.6880361323198203

Epoch: 5| Step: 7
Training loss: 1.574243209308083
Validation loss: 2.704873843202163

Epoch: 5| Step: 8
Training loss: 1.2275780039629247
Validation loss: 2.625251848764171

Epoch: 5| Step: 9
Training loss: 1.2024882229170781
Validation loss: 2.5739092175090534

Epoch: 5| Step: 10
Training loss: 1.4305634863591439
Validation loss: 2.6769445511101666

Epoch: 683| Step: 0
Training loss: 1.3289660315323786
Validation loss: 2.6192218483181415

Epoch: 5| Step: 1
Training loss: 1.2847711513698508
Validation loss: 2.6371683183651253

Epoch: 5| Step: 2
Training loss: 1.3459372351411232
Validation loss: 2.73620393543299

Epoch: 5| Step: 3
Training loss: 1.3666948139191923
Validation loss: 2.6791627833519214

Epoch: 5| Step: 4
Training loss: 2.2312909162600514
Validation loss: 2.6813456760291157

Epoch: 5| Step: 5
Training loss: 1.104633946179541
Validation loss: 2.728928662138942

Epoch: 5| Step: 6
Training loss: 1.220235359596438
Validation loss: 2.688228787858975

Epoch: 5| Step: 7
Training loss: 1.6656909550245977
Validation loss: 2.69546398886229

Epoch: 5| Step: 8
Training loss: 1.348299972929371
Validation loss: 2.674357271228894

Epoch: 5| Step: 9
Training loss: 1.497700677331146
Validation loss: 2.753816434276627

Epoch: 5| Step: 10
Training loss: 1.0976272524875839
Validation loss: 2.705273993350982

Epoch: 684| Step: 0
Training loss: 1.3875984947367972
Validation loss: 2.736645551423221

Epoch: 5| Step: 1
Training loss: 1.4143517129947372
Validation loss: 2.7538259149634894

Epoch: 5| Step: 2
Training loss: 1.209453978411618
Validation loss: 2.7260310641822882

Epoch: 5| Step: 3
Training loss: 0.9158563861832323
Validation loss: 2.6283094616791156

Epoch: 5| Step: 4
Training loss: 1.103084946032191
Validation loss: 2.7814966801910512

Epoch: 5| Step: 5
Training loss: 1.6387305084396189
Validation loss: 2.7018756586237855

Epoch: 5| Step: 6
Training loss: 1.625708645579299
Validation loss: 2.685994451759526

Epoch: 5| Step: 7
Training loss: 1.4211069065552417
Validation loss: 2.686478659451896

Epoch: 5| Step: 8
Training loss: 1.2209071118625319
Validation loss: 2.726104272831823

Epoch: 5| Step: 9
Training loss: 1.605944486425806
Validation loss: 2.711348823922574

Epoch: 5| Step: 10
Training loss: 1.9224696286187268
Validation loss: 2.774839519622563

Epoch: 685| Step: 0
Training loss: 1.7716387394414246
Validation loss: 2.6246821186126

Epoch: 5| Step: 1
Training loss: 1.1741957001698495
Validation loss: 2.6063394675896787

Epoch: 5| Step: 2
Training loss: 1.614669830302366
Validation loss: 2.721376701568235

Epoch: 5| Step: 3
Training loss: 1.4271852034618593
Validation loss: 2.6512700071239066

Epoch: 5| Step: 4
Training loss: 1.390250637798578
Validation loss: 2.693861131317421

Epoch: 5| Step: 5
Training loss: 1.2665785035186574
Validation loss: 2.690628924181213

Epoch: 5| Step: 6
Training loss: 1.119249268695796
Validation loss: 2.657727195949464

Epoch: 5| Step: 7
Training loss: 1.1217808229663606
Validation loss: 2.659827062089402

Epoch: 5| Step: 8
Training loss: 2.1809302721451753
Validation loss: 2.6749065888496495

Epoch: 5| Step: 9
Training loss: 1.3905531189589355
Validation loss: 2.6786654804591783

Epoch: 5| Step: 10
Training loss: 1.537441736373421
Validation loss: 2.7621047136985926

Epoch: 686| Step: 0
Training loss: 1.5934884847865896
Validation loss: 2.7166373087901388

Epoch: 5| Step: 1
Training loss: 1.2648676737454325
Validation loss: 2.7388198667108528

Epoch: 5| Step: 2
Training loss: 1.5681007713614221
Validation loss: 2.67915507374859

Epoch: 5| Step: 3
Training loss: 0.8070332677618396
Validation loss: 2.6274769723767757

Epoch: 5| Step: 4
Training loss: 1.013597195323806
Validation loss: 2.7392247117858535

Epoch: 5| Step: 5
Training loss: 1.365282224326893
Validation loss: 2.6526941587525377

Epoch: 5| Step: 6
Training loss: 1.4180277662369984
Validation loss: 2.7749000299241953

Epoch: 5| Step: 7
Training loss: 1.7048137586569192
Validation loss: 2.696077047839777

Epoch: 5| Step: 8
Training loss: 1.9544344365445208
Validation loss: 2.654572300523689

Epoch: 5| Step: 9
Training loss: 1.270903236259334
Validation loss: 2.6698163784172184

Epoch: 5| Step: 10
Training loss: 1.4119901276991669
Validation loss: 2.70626299617981

Epoch: 687| Step: 0
Training loss: 0.9469602112150493
Validation loss: 2.6305752665888655

Epoch: 5| Step: 1
Training loss: 1.50324351583047
Validation loss: 2.6554033864123734

Epoch: 5| Step: 2
Training loss: 1.2196779875173007
Validation loss: 2.7279568786694153

Epoch: 5| Step: 3
Training loss: 1.1723960226842025
Validation loss: 2.7311883249009665

Epoch: 5| Step: 4
Training loss: 2.0144023883696343
Validation loss: 2.6093597799742354

Epoch: 5| Step: 5
Training loss: 1.6699518569128686
Validation loss: 2.6573506689780837

Epoch: 5| Step: 6
Training loss: 1.3087718330026843
Validation loss: 2.7284467571607665

Epoch: 5| Step: 7
Training loss: 1.342992968560031
Validation loss: 2.620992255557695

Epoch: 5| Step: 8
Training loss: 1.5709338121463856
Validation loss: 2.71159707833403

Epoch: 5| Step: 9
Training loss: 1.0232733092478306
Validation loss: 2.6119562264449687

Epoch: 5| Step: 10
Training loss: 1.6213012562504499
Validation loss: 2.6675449313910966

Epoch: 688| Step: 0
Training loss: 1.0367241267831675
Validation loss: 2.703966939888664

Epoch: 5| Step: 1
Training loss: 1.0574084187705874
Validation loss: 2.660707231509758

Epoch: 5| Step: 2
Training loss: 1.527051424505844
Validation loss: 2.670784225372029

Epoch: 5| Step: 3
Training loss: 1.5650745543494078
Validation loss: 2.7046831287353377

Epoch: 5| Step: 4
Training loss: 1.3529958015765837
Validation loss: 2.713248642919505

Epoch: 5| Step: 5
Training loss: 1.9951832704807837
Validation loss: 2.688705177927619

Epoch: 5| Step: 6
Training loss: 1.3955593219751474
Validation loss: 2.6979709616138225

Epoch: 5| Step: 7
Training loss: 1.1856885947876488
Validation loss: 2.691695705881844

Epoch: 5| Step: 8
Training loss: 1.6810219365401364
Validation loss: 2.665393541459496

Epoch: 5| Step: 9
Training loss: 1.31341203155258
Validation loss: 2.655336355823671

Epoch: 5| Step: 10
Training loss: 1.639677155398262
Validation loss: 2.6350493419306953

Epoch: 689| Step: 0
Training loss: 1.5324355226677673
Validation loss: 2.5926457186946377

Epoch: 5| Step: 1
Training loss: 0.8829273385493145
Validation loss: 2.6645062896446334

Epoch: 5| Step: 2
Training loss: 1.4316546138897048
Validation loss: 2.6034282958346173

Epoch: 5| Step: 3
Training loss: 1.4442779962706191
Validation loss: 2.638824756003479

Epoch: 5| Step: 4
Training loss: 1.0714672013539521
Validation loss: 2.621199792807749

Epoch: 5| Step: 5
Training loss: 1.4860374376964234
Validation loss: 2.5847730491723593

Epoch: 5| Step: 6
Training loss: 1.3592966868325187
Validation loss: 2.69087557654949

Epoch: 5| Step: 7
Training loss: 1.3335186660627334
Validation loss: 2.667608746184734

Epoch: 5| Step: 8
Training loss: 1.3113955437513964
Validation loss: 2.6080661296221175

Epoch: 5| Step: 9
Training loss: 1.9443047912340854
Validation loss: 2.6693156861929537

Epoch: 5| Step: 10
Training loss: 1.234989013545787
Validation loss: 2.6956907335394305

Epoch: 690| Step: 0
Training loss: 1.439794781949719
Validation loss: 2.7142019839321114

Epoch: 5| Step: 1
Training loss: 1.3217962832268886
Validation loss: 2.6844168164767366

Epoch: 5| Step: 2
Training loss: 1.9682033324802726
Validation loss: 2.8025222222957407

Epoch: 5| Step: 3
Training loss: 1.5104143690771408
Validation loss: 2.658006860888482

Epoch: 5| Step: 4
Training loss: 1.4488224608474394
Validation loss: 2.6473618919606396

Epoch: 5| Step: 5
Training loss: 1.3545866192805505
Validation loss: 2.7403822448719333

Epoch: 5| Step: 6
Training loss: 1.1150424879044536
Validation loss: 2.702259426603046

Epoch: 5| Step: 7
Training loss: 1.3749498444859687
Validation loss: 2.67572768645556

Epoch: 5| Step: 8
Training loss: 1.258324891918912
Validation loss: 2.673681861365007

Epoch: 5| Step: 9
Training loss: 1.3407974630188442
Validation loss: 2.649102408762646

Epoch: 5| Step: 10
Training loss: 1.2424946051467043
Validation loss: 2.6246285964418283

Epoch: 691| Step: 0
Training loss: 2.1342243370398033
Validation loss: 2.700235531863133

Epoch: 5| Step: 1
Training loss: 1.2530939911694399
Validation loss: 2.7693108530071724

Epoch: 5| Step: 2
Training loss: 1.6104298070031806
Validation loss: 2.7031267450533165

Epoch: 5| Step: 3
Training loss: 1.3725638048527011
Validation loss: 2.707011447523853

Epoch: 5| Step: 4
Training loss: 1.65236236345345
Validation loss: 2.741389181267548

Epoch: 5| Step: 5
Training loss: 1.238100778803986
Validation loss: 2.733311572039537

Epoch: 5| Step: 6
Training loss: 1.3389930359885074
Validation loss: 2.703482988324371

Epoch: 5| Step: 7
Training loss: 1.39319535924471
Validation loss: 2.6908345560900147

Epoch: 5| Step: 8
Training loss: 1.268402724821977
Validation loss: 2.6992577511289424

Epoch: 5| Step: 9
Training loss: 1.2848406001129749
Validation loss: 2.684053615578063

Epoch: 5| Step: 10
Training loss: 1.0087937893161283
Validation loss: 2.666659746109791

Epoch: 692| Step: 0
Training loss: 1.9733211794148147
Validation loss: 2.7099045889835778

Epoch: 5| Step: 1
Training loss: 1.215783935983179
Validation loss: 2.702967179927818

Epoch: 5| Step: 2
Training loss: 1.4947431957436448
Validation loss: 2.73826575734553

Epoch: 5| Step: 3
Training loss: 1.1246039965157455
Validation loss: 2.621492747125041

Epoch: 5| Step: 4
Training loss: 1.2935243087212578
Validation loss: 2.7153832817311674

Epoch: 5| Step: 5
Training loss: 1.3593436928136537
Validation loss: 2.6441259600859306

Epoch: 5| Step: 6
Training loss: 1.3241930933804626
Validation loss: 2.733895968009108

Epoch: 5| Step: 7
Training loss: 1.4580557241060401
Validation loss: 2.731993063597838

Epoch: 5| Step: 8
Training loss: 1.4427612882551621
Validation loss: 2.6305142801706483

Epoch: 5| Step: 9
Training loss: 1.20730049562339
Validation loss: 2.702001509483572

Epoch: 5| Step: 10
Training loss: 1.0523319643036093
Validation loss: 2.703501747949251

Epoch: 693| Step: 0
Training loss: 1.881505932302092
Validation loss: 2.7104359528937443

Epoch: 5| Step: 1
Training loss: 1.5614497660613305
Validation loss: 2.7546041965234482

Epoch: 5| Step: 2
Training loss: 1.1143237135419903
Validation loss: 2.6730508338102745

Epoch: 5| Step: 3
Training loss: 1.1743356937085512
Validation loss: 2.6924701957550976

Epoch: 5| Step: 4
Training loss: 1.4459712821092583
Validation loss: 2.7408095014931817

Epoch: 5| Step: 5
Training loss: 1.4996259540854673
Validation loss: 2.6807866555210422

Epoch: 5| Step: 6
Training loss: 1.2080501465715194
Validation loss: 2.601816234159041

Epoch: 5| Step: 7
Training loss: 1.1820692057544657
Validation loss: 2.7049577455740477

Epoch: 5| Step: 8
Training loss: 1.5656285055581933
Validation loss: 2.633507709666935

Epoch: 5| Step: 9
Training loss: 1.1116021594462742
Validation loss: 2.694799724522589

Epoch: 5| Step: 10
Training loss: 1.3734312645398485
Validation loss: 2.700864342693249

Epoch: 694| Step: 0
Training loss: 1.4229929794170506
Validation loss: 2.7369756563452023

Epoch: 5| Step: 1
Training loss: 1.2368439235705928
Validation loss: 2.6354064150024796

Epoch: 5| Step: 2
Training loss: 1.1290632620523027
Validation loss: 2.7299212874966066

Epoch: 5| Step: 3
Training loss: 1.3358683874980857
Validation loss: 2.671020073593767

Epoch: 5| Step: 4
Training loss: 1.1938598382558434
Validation loss: 2.583009622823166

Epoch: 5| Step: 5
Training loss: 1.8403390270412934
Validation loss: 2.7229401356328204

Epoch: 5| Step: 6
Training loss: 1.4497327689857007
Validation loss: 2.6844049132255243

Epoch: 5| Step: 7
Training loss: 1.2553137369603242
Validation loss: 2.6814438965265652

Epoch: 5| Step: 8
Training loss: 0.9997767258773268
Validation loss: 2.696729702922792

Epoch: 5| Step: 9
Training loss: 1.0711914129271982
Validation loss: 2.7802491589697857

Epoch: 5| Step: 10
Training loss: 2.1180396810746225
Validation loss: 2.7539653547442313

Epoch: 695| Step: 0
Training loss: 1.5182584712852
Validation loss: 2.6118350787888436

Epoch: 5| Step: 1
Training loss: 1.4483532236018923
Validation loss: 2.7311680912020537

Epoch: 5| Step: 2
Training loss: 1.4476562467061438
Validation loss: 2.658516290446719

Epoch: 5| Step: 3
Training loss: 1.2824136055741606
Validation loss: 2.6317499952069547

Epoch: 5| Step: 4
Training loss: 2.0617694138766622
Validation loss: 2.6690195192912314

Epoch: 5| Step: 5
Training loss: 1.1124573988740838
Validation loss: 2.710498662352477

Epoch: 5| Step: 6
Training loss: 1.2965752128737267
Validation loss: 2.74075689733765

Epoch: 5| Step: 7
Training loss: 0.8514873226474206
Validation loss: 2.724762811279389

Epoch: 5| Step: 8
Training loss: 1.6237951360218783
Validation loss: 2.774146865559025

Epoch: 5| Step: 9
Training loss: 1.3212988064358009
Validation loss: 2.593230623347153

Epoch: 5| Step: 10
Training loss: 0.8520319983043424
Validation loss: 2.7072583800084034

Epoch: 696| Step: 0
Training loss: 1.232159424901426
Validation loss: 2.7266582577153478

Epoch: 5| Step: 1
Training loss: 1.5326262536867852
Validation loss: 2.7347289819312235

Epoch: 5| Step: 2
Training loss: 1.357776754630876
Validation loss: 2.73817493986656

Epoch: 5| Step: 3
Training loss: 1.18453649864146
Validation loss: 2.6245757256706397

Epoch: 5| Step: 4
Training loss: 1.3358414821808524
Validation loss: 2.746024924364657

Epoch: 5| Step: 5
Training loss: 1.4044677460641442
Validation loss: 2.6581067500754965

Epoch: 5| Step: 6
Training loss: 1.3344779267470472
Validation loss: 2.718364206828869

Epoch: 5| Step: 7
Training loss: 1.1099477015022783
Validation loss: 2.7064630990962453

Epoch: 5| Step: 8
Training loss: 1.3362128882968638
Validation loss: 2.639365143069376

Epoch: 5| Step: 9
Training loss: 1.6284973216703864
Validation loss: 2.612426249087249

Epoch: 5| Step: 10
Training loss: 1.996084075127911
Validation loss: 2.6648943434184686

Epoch: 697| Step: 0
Training loss: 1.0946151581431007
Validation loss: 2.721953668909501

Epoch: 5| Step: 1
Training loss: 1.1330848103469418
Validation loss: 2.6476549478342375

Epoch: 5| Step: 2
Training loss: 1.2837337517383318
Validation loss: 2.6165681848542515

Epoch: 5| Step: 3
Training loss: 1.2933587814232914
Validation loss: 2.6201975557420303

Epoch: 5| Step: 4
Training loss: 1.4589728542623701
Validation loss: 2.623113913662822

Epoch: 5| Step: 5
Training loss: 1.0906145111716372
Validation loss: 2.7154773000359436

Epoch: 5| Step: 6
Training loss: 1.2450495443482459
Validation loss: 2.677388077437198

Epoch: 5| Step: 7
Training loss: 1.8153898943745974
Validation loss: 2.628517090747657

Epoch: 5| Step: 8
Training loss: 1.6318179665471406
Validation loss: 2.7913673753479777

Epoch: 5| Step: 9
Training loss: 1.0327666141168168
Validation loss: 2.767539718451408

Epoch: 5| Step: 10
Training loss: 1.563635451697634
Validation loss: 2.609844538612736

Epoch: 698| Step: 0
Training loss: 1.1623843596992613
Validation loss: 2.773594153401232

Epoch: 5| Step: 1
Training loss: 1.5089475480576873
Validation loss: 2.731719141715791

Epoch: 5| Step: 2
Training loss: 2.0491799924256098
Validation loss: 2.5730068979279523

Epoch: 5| Step: 3
Training loss: 0.9709582847332519
Validation loss: 2.6530096220528905

Epoch: 5| Step: 4
Training loss: 1.7381148012171357
Validation loss: 2.6817354897813384

Epoch: 5| Step: 5
Training loss: 1.1063271684186544
Validation loss: 2.6528257608937444

Epoch: 5| Step: 6
Training loss: 1.5462174993012023
Validation loss: 2.6249462704255255

Epoch: 5| Step: 7
Training loss: 1.5149865919722163
Validation loss: 2.6959201578962873

Epoch: 5| Step: 8
Training loss: 1.316077579026215
Validation loss: 2.7203292456102157

Epoch: 5| Step: 9
Training loss: 1.1708543019888944
Validation loss: 2.710227676444699

Epoch: 5| Step: 10
Training loss: 0.8063690984720218
Validation loss: 2.680887133206119

Epoch: 699| Step: 0
Training loss: 1.6983762559841884
Validation loss: 2.7004214339600727

Epoch: 5| Step: 1
Training loss: 0.9676892718411191
Validation loss: 2.707722096217826

Epoch: 5| Step: 2
Training loss: 1.4893488221423226
Validation loss: 2.698877191087092

Epoch: 5| Step: 3
Training loss: 1.1425498502444342
Validation loss: 2.6328561975842604

Epoch: 5| Step: 4
Training loss: 1.0181791028189369
Validation loss: 2.7100003450058425

Epoch: 5| Step: 5
Training loss: 1.2660776906393783
Validation loss: 2.6818352092361195

Epoch: 5| Step: 6
Training loss: 1.3463866071893993
Validation loss: 2.643871777529151

Epoch: 5| Step: 7
Training loss: 1.574495428491172
Validation loss: 2.710953333234744

Epoch: 5| Step: 8
Training loss: 1.2482817761597602
Validation loss: 2.6821393586326123

Epoch: 5| Step: 9
Training loss: 1.0862315486486585
Validation loss: 2.688271839278802

Epoch: 5| Step: 10
Training loss: 1.9693433079519669
Validation loss: 2.707010333807836

Epoch: 700| Step: 0
Training loss: 1.172182627672622
Validation loss: 2.71072195341101

Epoch: 5| Step: 1
Training loss: 1.1236609861361773
Validation loss: 2.749126441008093

Epoch: 5| Step: 2
Training loss: 1.0711092245930387
Validation loss: 2.650272309886655

Epoch: 5| Step: 3
Training loss: 1.849859299335397
Validation loss: 2.650455024019014

Epoch: 5| Step: 4
Training loss: 1.6993044776776247
Validation loss: 2.6651751233413417

Epoch: 5| Step: 5
Training loss: 1.2296320416790907
Validation loss: 2.740910272405428

Epoch: 5| Step: 6
Training loss: 1.3944732482986693
Validation loss: 2.739520187582852

Epoch: 5| Step: 7
Training loss: 1.3777918648683258
Validation loss: 2.7171426957568334

Epoch: 5| Step: 8
Training loss: 1.1486413476345023
Validation loss: 2.6818080454562634

Epoch: 5| Step: 9
Training loss: 0.9894972847452638
Validation loss: 2.667313230742546

Epoch: 5| Step: 10
Training loss: 1.1320431958102022
Validation loss: 2.7274684894011934

Epoch: 701| Step: 0
Training loss: 2.0138418901009074
Validation loss: 2.722086239803743

Epoch: 5| Step: 1
Training loss: 1.1174949809736152
Validation loss: 2.720911766031961

Epoch: 5| Step: 2
Training loss: 1.6361546238436635
Validation loss: 2.635985227557668

Epoch: 5| Step: 3
Training loss: 1.7113926948255036
Validation loss: 2.6757539366161995

Epoch: 5| Step: 4
Training loss: 0.8734308205009649
Validation loss: 2.6904891671465334

Epoch: 5| Step: 5
Training loss: 1.0454597586098466
Validation loss: 2.6776843776244625

Epoch: 5| Step: 6
Training loss: 1.181180804612666
Validation loss: 2.690999399172104

Epoch: 5| Step: 7
Training loss: 1.8983689911965087
Validation loss: 2.684588238832981

Epoch: 5| Step: 8
Training loss: 1.469764115877167
Validation loss: 2.707139214984177

Epoch: 5| Step: 9
Training loss: 1.3273047214134093
Validation loss: 2.652274086927039

Epoch: 5| Step: 10
Training loss: 0.6222864610879756
Validation loss: 2.711734809688133

Epoch: 702| Step: 0
Training loss: 1.1285445217870846
Validation loss: 2.792837879554886

Epoch: 5| Step: 1
Training loss: 1.252291153191767
Validation loss: 2.6715329530639766

Epoch: 5| Step: 2
Training loss: 1.9108361280476025
Validation loss: 2.6732214103278515

Epoch: 5| Step: 3
Training loss: 1.1463226776212
Validation loss: 2.7447767499931013

Epoch: 5| Step: 4
Training loss: 1.4077383430416988
Validation loss: 2.688185201694728

Epoch: 5| Step: 5
Training loss: 0.9700041620420848
Validation loss: 2.6982574330037634

Epoch: 5| Step: 6
Training loss: 1.249763371004787
Validation loss: 2.731241592991634

Epoch: 5| Step: 7
Training loss: 1.1127631337014894
Validation loss: 2.693837979226667

Epoch: 5| Step: 8
Training loss: 1.7875807177051897
Validation loss: 2.755931082456919

Epoch: 5| Step: 9
Training loss: 1.2654338268430765
Validation loss: 2.710183273014836

Epoch: 5| Step: 10
Training loss: 1.2138125345167146
Validation loss: 2.691317924410999

Epoch: 703| Step: 0
Training loss: 1.081792701839316
Validation loss: 2.6800412084784284

Epoch: 5| Step: 1
Training loss: 1.2824876901433646
Validation loss: 2.677908614618498

Epoch: 5| Step: 2
Training loss: 1.2119570470129382
Validation loss: 2.694485186394376

Epoch: 5| Step: 3
Training loss: 1.441303694056522
Validation loss: 2.6624206934407266

Epoch: 5| Step: 4
Training loss: 1.4822525108600517
Validation loss: 2.7138706080568107

Epoch: 5| Step: 5
Training loss: 1.0890521931536807
Validation loss: 2.6754038506933004

Epoch: 5| Step: 6
Training loss: 1.4128904596296472
Validation loss: 2.6098092425033856

Epoch: 5| Step: 7
Training loss: 1.1009220398752109
Validation loss: 2.788699410850337

Epoch: 5| Step: 8
Training loss: 1.897389503347676
Validation loss: 2.7277019759561725

Epoch: 5| Step: 9
Training loss: 1.3534943990432975
Validation loss: 2.7305568607089508

Epoch: 5| Step: 10
Training loss: 1.242326116924925
Validation loss: 2.776614415055878

Epoch: 704| Step: 0
Training loss: 0.994154924391037
Validation loss: 2.67684582265998

Epoch: 5| Step: 1
Training loss: 1.2323033295458659
Validation loss: 2.6823888894674743

Epoch: 5| Step: 2
Training loss: 1.5029542758608356
Validation loss: 2.715150271109445

Epoch: 5| Step: 3
Training loss: 2.017434778872818
Validation loss: 2.761584493713792

Epoch: 5| Step: 4
Training loss: 1.1683369952283675
Validation loss: 2.7052485413693126

Epoch: 5| Step: 5
Training loss: 1.4243525623731952
Validation loss: 2.6968576314385846

Epoch: 5| Step: 6
Training loss: 1.4470674325010988
Validation loss: 2.7137269315116384

Epoch: 5| Step: 7
Training loss: 1.4427826055511979
Validation loss: 2.678734642384708

Epoch: 5| Step: 8
Training loss: 1.397181325005947
Validation loss: 2.723501356086719

Epoch: 5| Step: 9
Training loss: 1.3742829967615797
Validation loss: 2.7390690793475034

Epoch: 5| Step: 10
Training loss: 1.2437367884255321
Validation loss: 2.7941058707229565

Epoch: 705| Step: 0
Training loss: 1.1780648092178152
Validation loss: 2.770632675890618

Epoch: 5| Step: 1
Training loss: 1.5014874712471815
Validation loss: 2.721201271456171

Epoch: 5| Step: 2
Training loss: 1.067110995542716
Validation loss: 2.6588091437541808

Epoch: 5| Step: 3
Training loss: 2.038054118253051
Validation loss: 2.7232646918165284

Epoch: 5| Step: 4
Training loss: 1.1737865878609122
Validation loss: 2.8089413368825

Epoch: 5| Step: 5
Training loss: 1.6748876790206575
Validation loss: 2.736148678295597

Epoch: 5| Step: 6
Training loss: 1.5184719443393906
Validation loss: 2.716198026293894

Epoch: 5| Step: 7
Training loss: 1.3704431625933282
Validation loss: 2.67365262608782

Epoch: 5| Step: 8
Training loss: 1.2475649480788515
Validation loss: 2.7766209242943223

Epoch: 5| Step: 9
Training loss: 0.8993550135212257
Validation loss: 2.7240866266146506

Epoch: 5| Step: 10
Training loss: 1.1323331147404159
Validation loss: 2.744291139224235

Epoch: 706| Step: 0
Training loss: 1.954061115995863
Validation loss: 2.7274079832922777

Epoch: 5| Step: 1
Training loss: 1.1809258435035683
Validation loss: 2.718139336575728

Epoch: 5| Step: 2
Training loss: 1.5646826948302006
Validation loss: 2.798700573368653

Epoch: 5| Step: 3
Training loss: 1.060571041499235
Validation loss: 2.6557787762540865

Epoch: 5| Step: 4
Training loss: 1.6177424708700965
Validation loss: 2.676922217097817

Epoch: 5| Step: 5
Training loss: 1.1752275956677318
Validation loss: 2.7378788179358975

Epoch: 5| Step: 6
Training loss: 1.3759629605597665
Validation loss: 2.7112970541942047

Epoch: 5| Step: 7
Training loss: 1.4214995171394829
Validation loss: 2.7060487512600875

Epoch: 5| Step: 8
Training loss: 1.2725161162069696
Validation loss: 2.7021900053447943

Epoch: 5| Step: 9
Training loss: 1.166669039496779
Validation loss: 2.6886635856273404

Epoch: 5| Step: 10
Training loss: 1.1145643904077458
Validation loss: 2.6621811202794117

Epoch: 707| Step: 0
Training loss: 1.2995360316777615
Validation loss: 2.6572737089800738

Epoch: 5| Step: 1
Training loss: 1.4734255453456078
Validation loss: 2.679326513170453

Epoch: 5| Step: 2
Training loss: 1.05008819300523
Validation loss: 2.7961480887261123

Epoch: 5| Step: 3
Training loss: 1.4543024030729441
Validation loss: 2.7067054245019313

Epoch: 5| Step: 4
Training loss: 1.1893874778233349
Validation loss: 2.6739545413971495

Epoch: 5| Step: 5
Training loss: 1.1948680674773524
Validation loss: 2.5584323732280363

Epoch: 5| Step: 6
Training loss: 1.285181340955318
Validation loss: 2.639950823412865

Epoch: 5| Step: 7
Training loss: 1.8959834559881739
Validation loss: 2.6061488316472268

Epoch: 5| Step: 8
Training loss: 0.930935991074081
Validation loss: 2.7226135228896937

Epoch: 5| Step: 9
Training loss: 1.5044281289355255
Validation loss: 2.733901389925534

Epoch: 5| Step: 10
Training loss: 1.6004634901111336
Validation loss: 2.642925858302129

Epoch: 708| Step: 0
Training loss: 1.0038835693647217
Validation loss: 2.7299607571463276

Epoch: 5| Step: 1
Training loss: 1.1846921249617346
Validation loss: 2.631916949230209

Epoch: 5| Step: 2
Training loss: 1.142906259222111
Validation loss: 2.735896612946342

Epoch: 5| Step: 3
Training loss: 1.4409312884582184
Validation loss: 2.6960355131641958

Epoch: 5| Step: 4
Training loss: 2.0524623411117995
Validation loss: 2.6472097887106165

Epoch: 5| Step: 5
Training loss: 1.0899552592448263
Validation loss: 2.727863733129623

Epoch: 5| Step: 6
Training loss: 1.4852386371490596
Validation loss: 2.6876145663003417

Epoch: 5| Step: 7
Training loss: 1.3608330985491695
Validation loss: 2.640521131981

Epoch: 5| Step: 8
Training loss: 1.6583233217994684
Validation loss: 2.8247713700498687

Epoch: 5| Step: 9
Training loss: 1.2324045122619305
Validation loss: 2.714053261984799

Epoch: 5| Step: 10
Training loss: 1.2218296559693487
Validation loss: 2.6715648485263497

Epoch: 709| Step: 0
Training loss: 1.158972241962054
Validation loss: 2.59003463583858

Epoch: 5| Step: 1
Training loss: 1.204844150674244
Validation loss: 2.640810717310013

Epoch: 5| Step: 2
Training loss: 1.1277634271064658
Validation loss: 2.583983599156579

Epoch: 5| Step: 3
Training loss: 1.2917147545425678
Validation loss: 2.7097990501419513

Epoch: 5| Step: 4
Training loss: 1.4646674698619235
Validation loss: 2.6685389578112124

Epoch: 5| Step: 5
Training loss: 2.0325801308989986
Validation loss: 2.7082080439765095

Epoch: 5| Step: 6
Training loss: 1.6872609287031808
Validation loss: 2.78020285305611

Epoch: 5| Step: 7
Training loss: 1.0048220720831176
Validation loss: 2.656210115484367

Epoch: 5| Step: 8
Training loss: 1.4417705127307898
Validation loss: 2.6248493864307862

Epoch: 5| Step: 9
Training loss: 0.9393001439769711
Validation loss: 2.7391349163164684

Epoch: 5| Step: 10
Training loss: 1.2708984525078761
Validation loss: 2.701515924730075

Epoch: 710| Step: 0
Training loss: 1.2904449448131725
Validation loss: 2.726884789903618

Epoch: 5| Step: 1
Training loss: 1.2403967082799532
Validation loss: 2.724699238946846

Epoch: 5| Step: 2
Training loss: 1.7387551336809142
Validation loss: 2.7025727753510966

Epoch: 5| Step: 3
Training loss: 1.0647311066390825
Validation loss: 2.7755278235856036

Epoch: 5| Step: 4
Training loss: 0.9998365208989952
Validation loss: 2.612764344891548

Epoch: 5| Step: 5
Training loss: 1.203220958103232
Validation loss: 2.6642590339216343

Epoch: 5| Step: 6
Training loss: 1.9126542496653225
Validation loss: 2.690303876597426

Epoch: 5| Step: 7
Training loss: 0.9874284706284787
Validation loss: 2.717478157503063

Epoch: 5| Step: 8
Training loss: 1.3326898999191892
Validation loss: 2.694538832797405

Epoch: 5| Step: 9
Training loss: 1.3791079279135867
Validation loss: 2.7946133502813635

Epoch: 5| Step: 10
Training loss: 1.0506978622305858
Validation loss: 2.74470871047753

Epoch: 711| Step: 0
Training loss: 1.1399158729498218
Validation loss: 2.7511963111316717

Epoch: 5| Step: 1
Training loss: 2.098730057513134
Validation loss: 2.690930914974745

Epoch: 5| Step: 2
Training loss: 0.8214488197283352
Validation loss: 2.7596103585723846

Epoch: 5| Step: 3
Training loss: 1.282880675796075
Validation loss: 2.647917523396098

Epoch: 5| Step: 4
Training loss: 1.2466181784565298
Validation loss: 2.673532782081402

Epoch: 5| Step: 5
Training loss: 0.7203050459933259
Validation loss: 2.7543749608577737

Epoch: 5| Step: 6
Training loss: 1.0075676790701453
Validation loss: 2.64407209268346

Epoch: 5| Step: 7
Training loss: 1.3100699226267756
Validation loss: 2.6662610476806927

Epoch: 5| Step: 8
Training loss: 1.4886907379628949
Validation loss: 2.655074867348729

Epoch: 5| Step: 9
Training loss: 1.205070507946703
Validation loss: 2.7893919207476077

Epoch: 5| Step: 10
Training loss: 1.6043352641232669
Validation loss: 2.75874100431545

Epoch: 712| Step: 0
Training loss: 1.174063609744358
Validation loss: 2.7485780591539464

Epoch: 5| Step: 1
Training loss: 1.441721315763015
Validation loss: 2.7028918265606126

Epoch: 5| Step: 2
Training loss: 1.340493714633365
Validation loss: 2.594524593558223

Epoch: 5| Step: 3
Training loss: 1.2003171283182794
Validation loss: 2.8095337674964513

Epoch: 5| Step: 4
Training loss: 1.0917025339383535
Validation loss: 2.697760956895648

Epoch: 5| Step: 5
Training loss: 2.1975216864686455
Validation loss: 2.665685533440377

Epoch: 5| Step: 6
Training loss: 1.5054624754334975
Validation loss: 2.7634191126362904

Epoch: 5| Step: 7
Training loss: 0.970254683192568
Validation loss: 2.7015144177752473

Epoch: 5| Step: 8
Training loss: 1.4028203042931353
Validation loss: 2.6735765562970557

Epoch: 5| Step: 9
Training loss: 1.4491921805442205
Validation loss: 2.7910715456622035

Epoch: 5| Step: 10
Training loss: 0.823740237211455
Validation loss: 2.7740894855194496

Epoch: 713| Step: 0
Training loss: 1.4924594970779244
Validation loss: 2.7483987509262153

Epoch: 5| Step: 1
Training loss: 1.0439361771700388
Validation loss: 2.777581304622822

Epoch: 5| Step: 2
Training loss: 1.1299363027191023
Validation loss: 2.5867728644459462

Epoch: 5| Step: 3
Training loss: 1.7337234922994078
Validation loss: 2.6825097101850033

Epoch: 5| Step: 4
Training loss: 1.1653928387446921
Validation loss: 2.707996517532508

Epoch: 5| Step: 5
Training loss: 1.0452352178769655
Validation loss: 2.729711937620195

Epoch: 5| Step: 6
Training loss: 1.2163993467748784
Validation loss: 2.6774842294191186

Epoch: 5| Step: 7
Training loss: 1.2724584548703477
Validation loss: 2.6438403314654866

Epoch: 5| Step: 8
Training loss: 1.0366957247260564
Validation loss: 2.6843529638550363

Epoch: 5| Step: 9
Training loss: 2.0351328198627288
Validation loss: 2.7488482254988624

Epoch: 5| Step: 10
Training loss: 1.2734597327040955
Validation loss: 2.675705292463966

Epoch: 714| Step: 0
Training loss: 1.2500456801650848
Validation loss: 2.7373213450441214

Epoch: 5| Step: 1
Training loss: 1.4007864463186395
Validation loss: 2.6968334584495746

Epoch: 5| Step: 2
Training loss: 1.2223193402189407
Validation loss: 2.686274934912524

Epoch: 5| Step: 3
Training loss: 1.9143089291500874
Validation loss: 2.5956538009034356

Epoch: 5| Step: 4
Training loss: 0.9874099690404433
Validation loss: 2.726986909247729

Epoch: 5| Step: 5
Training loss: 0.9190045296118418
Validation loss: 2.7464496640557563

Epoch: 5| Step: 6
Training loss: 1.4209978521117395
Validation loss: 2.6566724003438265

Epoch: 5| Step: 7
Training loss: 0.96618047002654
Validation loss: 2.7481908580551235

Epoch: 5| Step: 8
Training loss: 1.432981105522819
Validation loss: 2.63831339960008

Epoch: 5| Step: 9
Training loss: 1.5074751086101632
Validation loss: 2.6865340135377296

Epoch: 5| Step: 10
Training loss: 1.4312372198741978
Validation loss: 2.637858683085529

Epoch: 715| Step: 0
Training loss: 1.3400622487199376
Validation loss: 2.710074250626422

Epoch: 5| Step: 1
Training loss: 1.1351362926306647
Validation loss: 2.6386555827800606

Epoch: 5| Step: 2
Training loss: 1.0576100300751867
Validation loss: 2.804686313555432

Epoch: 5| Step: 3
Training loss: 0.9586885388306092
Validation loss: 2.690009166562998

Epoch: 5| Step: 4
Training loss: 1.9517846963680605
Validation loss: 2.7174113689438006

Epoch: 5| Step: 5
Training loss: 1.1703539322775334
Validation loss: 2.7013671961929866

Epoch: 5| Step: 6
Training loss: 1.4132663319033898
Validation loss: 2.732820702549532

Epoch: 5| Step: 7
Training loss: 1.4158580192463024
Validation loss: 2.7421054977993475

Epoch: 5| Step: 8
Training loss: 1.207648258466582
Validation loss: 2.6875587451234986

Epoch: 5| Step: 9
Training loss: 1.3064179964955254
Validation loss: 2.7724593304047818

Epoch: 5| Step: 10
Training loss: 1.264508968012252
Validation loss: 2.7089081995783455

Epoch: 716| Step: 0
Training loss: 1.3482175680822515
Validation loss: 2.6824771392061915

Epoch: 5| Step: 1
Training loss: 1.0847695745850239
Validation loss: 2.7808774915503034

Epoch: 5| Step: 2
Training loss: 1.0469831154635958
Validation loss: 2.7439949607440504

Epoch: 5| Step: 3
Training loss: 1.2781954384493321
Validation loss: 2.679872886511103

Epoch: 5| Step: 4
Training loss: 1.3186275859261005
Validation loss: 2.67480109909707

Epoch: 5| Step: 5
Training loss: 1.9598298002809673
Validation loss: 2.671284937929268

Epoch: 5| Step: 6
Training loss: 1.3592938366041543
Validation loss: 2.721241555305561

Epoch: 5| Step: 7
Training loss: 1.4679434976644044
Validation loss: 2.666066947021424

Epoch: 5| Step: 8
Training loss: 1.171157973591676
Validation loss: 2.729707042705538

Epoch: 5| Step: 9
Training loss: 1.4447990536472266
Validation loss: 2.6176339373729958

Epoch: 5| Step: 10
Training loss: 1.4202512755170862
Validation loss: 2.7902557126868017

Epoch: 717| Step: 0
Training loss: 1.4299444582629919
Validation loss: 2.667504293136524

Epoch: 5| Step: 1
Training loss: 1.2085180908667228
Validation loss: 2.653029543509816

Epoch: 5| Step: 2
Training loss: 1.270488952918968
Validation loss: 2.716589897812968

Epoch: 5| Step: 3
Training loss: 1.3512609509245768
Validation loss: 2.738783997483509

Epoch: 5| Step: 4
Training loss: 1.2543977623790616
Validation loss: 2.7234787854242377

Epoch: 5| Step: 5
Training loss: 1.3147133375511932
Validation loss: 2.7143656818102193

Epoch: 5| Step: 6
Training loss: 1.5014925524628213
Validation loss: 2.7895408039394884

Epoch: 5| Step: 7
Training loss: 2.185058320967162
Validation loss: 2.752239115580149

Epoch: 5| Step: 8
Training loss: 1.1847226138534783
Validation loss: 2.871781068866972

Epoch: 5| Step: 9
Training loss: 1.3329980647251192
Validation loss: 2.7848408985672055

Epoch: 5| Step: 10
Training loss: 1.1350437158408535
Validation loss: 2.7586063410383512

Epoch: 718| Step: 0
Training loss: 2.079870308537456
Validation loss: 2.751735089545147

Epoch: 5| Step: 1
Training loss: 1.337928403891789
Validation loss: 2.707491923052876

Epoch: 5| Step: 2
Training loss: 1.1888070693090809
Validation loss: 2.58383589893049

Epoch: 5| Step: 3
Training loss: 1.2918119758989888
Validation loss: 2.6769584565029145

Epoch: 5| Step: 4
Training loss: 1.063560237342538
Validation loss: 2.7653498497951086

Epoch: 5| Step: 5
Training loss: 1.362116449948691
Validation loss: 2.68212177436682

Epoch: 5| Step: 6
Training loss: 1.493063624554893
Validation loss: 2.7310954866954984

Epoch: 5| Step: 7
Training loss: 1.2902316253660528
Validation loss: 2.678164714791051

Epoch: 5| Step: 8
Training loss: 1.3714865966709344
Validation loss: 2.6761470220423744

Epoch: 5| Step: 9
Training loss: 1.035573738408755
Validation loss: 2.744970943722196

Epoch: 5| Step: 10
Training loss: 1.1907378776489066
Validation loss: 2.687886673167372

Epoch: 719| Step: 0
Training loss: 2.0436193768582993
Validation loss: 2.659801140521719

Epoch: 5| Step: 1
Training loss: 1.3855517997901534
Validation loss: 2.765390256264621

Epoch: 5| Step: 2
Training loss: 1.2685126810849643
Validation loss: 2.656508172727381

Epoch: 5| Step: 3
Training loss: 1.1181537211243948
Validation loss: 2.681464862998925

Epoch: 5| Step: 4
Training loss: 1.4087798780033214
Validation loss: 2.8153685257933705

Epoch: 5| Step: 5
Training loss: 1.2458502552495019
Validation loss: 2.789660316107238

Epoch: 5| Step: 6
Training loss: 1.2897594532953838
Validation loss: 2.6958295419256815

Epoch: 5| Step: 7
Training loss: 1.4130052861184323
Validation loss: 2.709368016044891

Epoch: 5| Step: 8
Training loss: 1.1400414633321259
Validation loss: 2.770565421245437

Epoch: 5| Step: 9
Training loss: 1.0388839683030864
Validation loss: 2.7651492131864357

Epoch: 5| Step: 10
Training loss: 1.0668179901391206
Validation loss: 2.8048046118573713

Epoch: 720| Step: 0
Training loss: 1.4137723846417292
Validation loss: 2.7125674246970033

Epoch: 5| Step: 1
Training loss: 1.4009607662776613
Validation loss: 2.673819229328225

Epoch: 5| Step: 2
Training loss: 1.278084822865003
Validation loss: 2.748435467546119

Epoch: 5| Step: 3
Training loss: 1.855235581052445
Validation loss: 2.7868820421838554

Epoch: 5| Step: 4
Training loss: 1.3492185520863347
Validation loss: 2.743103179234391

Epoch: 5| Step: 5
Training loss: 1.118190448566268
Validation loss: 2.7736670540477464

Epoch: 5| Step: 6
Training loss: 0.9161289364613986
Validation loss: 2.7937049813827937

Epoch: 5| Step: 7
Training loss: 1.281614670378768
Validation loss: 2.724901093645516

Epoch: 5| Step: 8
Training loss: 1.2648200312670754
Validation loss: 2.633805213511956

Epoch: 5| Step: 9
Training loss: 1.213424737014866
Validation loss: 2.7225209751592563

Epoch: 5| Step: 10
Training loss: 1.3704755644737046
Validation loss: 2.836511321391939

Epoch: 721| Step: 0
Training loss: 1.1383030917468422
Validation loss: 2.6484894704600377

Epoch: 5| Step: 1
Training loss: 1.0087475837385507
Validation loss: 2.6461884642427163

Epoch: 5| Step: 2
Training loss: 1.8311093090811343
Validation loss: 2.645140434992532

Epoch: 5| Step: 3
Training loss: 1.5184550654370195
Validation loss: 2.7114711320309084

Epoch: 5| Step: 4
Training loss: 1.4779147460311284
Validation loss: 2.701621855474684

Epoch: 5| Step: 5
Training loss: 1.4023229230858998
Validation loss: 2.7629043436864387

Epoch: 5| Step: 6
Training loss: 1.3847780213655296
Validation loss: 2.67442955832744

Epoch: 5| Step: 7
Training loss: 1.0060900377399689
Validation loss: 2.6928396481948753

Epoch: 5| Step: 8
Training loss: 1.2074883345520253
Validation loss: 2.636929242153459

Epoch: 5| Step: 9
Training loss: 1.1673334237306896
Validation loss: 2.6647803636371314

Epoch: 5| Step: 10
Training loss: 1.5759069889041681
Validation loss: 2.740433414633586

Epoch: 722| Step: 0
Training loss: 1.1988906660077587
Validation loss: 2.679435516031251

Epoch: 5| Step: 1
Training loss: 1.9189359320103103
Validation loss: 2.6720576204416475

Epoch: 5| Step: 2
Training loss: 1.3324600379777314
Validation loss: 2.7137875187633775

Epoch: 5| Step: 3
Training loss: 0.8056024701243492
Validation loss: 2.687957208713926

Epoch: 5| Step: 4
Training loss: 1.7845793278046742
Validation loss: 2.7168982600786964

Epoch: 5| Step: 5
Training loss: 1.2575596146454477
Validation loss: 2.6139859831567627

Epoch: 5| Step: 6
Training loss: 1.424316824728898
Validation loss: 2.704239357082342

Epoch: 5| Step: 7
Training loss: 1.2268151672977938
Validation loss: 2.7348124867535115

Epoch: 5| Step: 8
Training loss: 1.353296611730852
Validation loss: 2.763658827976952

Epoch: 5| Step: 9
Training loss: 0.695895818276606
Validation loss: 2.7268095799231347

Epoch: 5| Step: 10
Training loss: 1.1413660124593152
Validation loss: 2.743930316693614

Epoch: 723| Step: 0
Training loss: 1.1409909432107748
Validation loss: 2.7289696830319343

Epoch: 5| Step: 1
Training loss: 0.9858855812682167
Validation loss: 2.746111732155286

Epoch: 5| Step: 2
Training loss: 0.9901554896366955
Validation loss: 2.6891531156196855

Epoch: 5| Step: 3
Training loss: 1.6952660901445658
Validation loss: 2.7871892381997543

Epoch: 5| Step: 4
Training loss: 1.090346025786253
Validation loss: 2.6985392032598554

Epoch: 5| Step: 5
Training loss: 1.1806122647795612
Validation loss: 2.735824387403018

Epoch: 5| Step: 6
Training loss: 1.9814160130018634
Validation loss: 2.6499111992632614

Epoch: 5| Step: 7
Training loss: 1.0585122165038026
Validation loss: 2.6234306756096792

Epoch: 5| Step: 8
Training loss: 1.290642388621535
Validation loss: 2.697150822305939

Epoch: 5| Step: 9
Training loss: 1.333680147524465
Validation loss: 2.685762151149849

Epoch: 5| Step: 10
Training loss: 1.5321681325747711
Validation loss: 2.7272854447223667

Epoch: 724| Step: 0
Training loss: 1.8730239628095495
Validation loss: 2.6697362977859735

Epoch: 5| Step: 1
Training loss: 1.2448954784992998
Validation loss: 2.648779119578037

Epoch: 5| Step: 2
Training loss: 1.5343476706749404
Validation loss: 2.6666955856580477

Epoch: 5| Step: 3
Training loss: 1.3625602673841728
Validation loss: 2.6877960324394072

Epoch: 5| Step: 4
Training loss: 1.2909385207981792
Validation loss: 2.7600733098659553

Epoch: 5| Step: 5
Training loss: 0.9186115043729526
Validation loss: 2.6779411885103994

Epoch: 5| Step: 6
Training loss: 1.5854683167928891
Validation loss: 2.6934618707263662

Epoch: 5| Step: 7
Training loss: 0.9762025093318338
Validation loss: 2.822900662541227

Epoch: 5| Step: 8
Training loss: 1.030272164728183
Validation loss: 2.610382796214466

Epoch: 5| Step: 9
Training loss: 1.4831689854275225
Validation loss: 2.6815260921907065

Epoch: 5| Step: 10
Training loss: 1.4142490495742968
Validation loss: 2.6778300224658214

Epoch: 725| Step: 0
Training loss: 1.478416610889503
Validation loss: 2.8123388319427365

Epoch: 5| Step: 1
Training loss: 1.0664972399225658
Validation loss: 2.69844190000297

Epoch: 5| Step: 2
Training loss: 1.1120448692380764
Validation loss: 2.772058402242702

Epoch: 5| Step: 3
Training loss: 1.4149484967405508
Validation loss: 2.737091158326464

Epoch: 5| Step: 4
Training loss: 0.9528242168162763
Validation loss: 2.6610171031755026

Epoch: 5| Step: 5
Training loss: 1.3428191576023198
Validation loss: 2.642592434843274

Epoch: 5| Step: 6
Training loss: 1.2612699767573194
Validation loss: 2.633282008773605

Epoch: 5| Step: 7
Training loss: 1.1421737607450528
Validation loss: 2.639631891022909

Epoch: 5| Step: 8
Training loss: 1.1965821448223086
Validation loss: 2.7128434225943456

Epoch: 5| Step: 9
Training loss: 2.190626471460477
Validation loss: 2.711897177049158

Epoch: 5| Step: 10
Training loss: 1.045319611620696
Validation loss: 2.6987726245247483

Epoch: 726| Step: 0
Training loss: 1.0253052303541323
Validation loss: 2.6692707635422805

Epoch: 5| Step: 1
Training loss: 0.9755909168318718
Validation loss: 2.723500922145893

Epoch: 5| Step: 2
Training loss: 1.3200464375592729
Validation loss: 2.6920867321141895

Epoch: 5| Step: 3
Training loss: 1.783974287532037
Validation loss: 2.5604575786834567

Epoch: 5| Step: 4
Training loss: 0.9092086312084451
Validation loss: 2.8192358847249293

Epoch: 5| Step: 5
Training loss: 1.419984755770027
Validation loss: 2.7369794770159594

Epoch: 5| Step: 6
Training loss: 1.0854352159922533
Validation loss: 2.7272587087214384

Epoch: 5| Step: 7
Training loss: 1.0570400984817363
Validation loss: 2.652725512424176

Epoch: 5| Step: 8
Training loss: 1.3980126614686246
Validation loss: 2.6726350469073377

Epoch: 5| Step: 9
Training loss: 1.7894346691313185
Validation loss: 2.654968134825166

Epoch: 5| Step: 10
Training loss: 1.530809222249365
Validation loss: 2.762633167977615

Epoch: 727| Step: 0
Training loss: 0.9512193107917888
Validation loss: 2.746082601415355

Epoch: 5| Step: 1
Training loss: 1.6405900497346837
Validation loss: 2.7149066593450275

Epoch: 5| Step: 2
Training loss: 1.4909916424840057
Validation loss: 2.712791360081645

Epoch: 5| Step: 3
Training loss: 1.3467507679018105
Validation loss: 2.7426420155956017

Epoch: 5| Step: 4
Training loss: 2.026141741976988
Validation loss: 2.6982869679531216

Epoch: 5| Step: 5
Training loss: 1.1366165482238186
Validation loss: 2.7966817666601584

Epoch: 5| Step: 6
Training loss: 1.1721779495293596
Validation loss: 2.722990079720627

Epoch: 5| Step: 7
Training loss: 0.908714724594599
Validation loss: 2.775012903018137

Epoch: 5| Step: 8
Training loss: 1.369822116218444
Validation loss: 2.754455866237836

Epoch: 5| Step: 9
Training loss: 1.1243915501935557
Validation loss: 2.7624874663533805

Epoch: 5| Step: 10
Training loss: 1.1336680897288114
Validation loss: 2.7226536158855588

Epoch: 728| Step: 0
Training loss: 1.3930984958679171
Validation loss: 2.726318440596056

Epoch: 5| Step: 1
Training loss: 1.1531591084715884
Validation loss: 2.8048462066595485

Epoch: 5| Step: 2
Training loss: 1.1361305314176053
Validation loss: 2.6393279669048826

Epoch: 5| Step: 3
Training loss: 2.0377915905080224
Validation loss: 2.639203659855163

Epoch: 5| Step: 4
Training loss: 1.2316264201614553
Validation loss: 2.6335305938992435

Epoch: 5| Step: 5
Training loss: 1.0910426829281563
Validation loss: 2.6392596926814544

Epoch: 5| Step: 6
Training loss: 1.230381796050242
Validation loss: 2.741462895288613

Epoch: 5| Step: 7
Training loss: 1.4242250912138557
Validation loss: 2.7145439468138144

Epoch: 5| Step: 8
Training loss: 1.162084755516527
Validation loss: 2.7494937658242375

Epoch: 5| Step: 9
Training loss: 1.6294133337008865
Validation loss: 2.7839042015755053

Epoch: 5| Step: 10
Training loss: 0.9606164535509605
Validation loss: 2.6579244355939435

Epoch: 729| Step: 0
Training loss: 1.1107560279162325
Validation loss: 2.61980835247889

Epoch: 5| Step: 1
Training loss: 1.3956042951114869
Validation loss: 2.793958758539658

Epoch: 5| Step: 2
Training loss: 0.872230609032089
Validation loss: 2.688088321417771

Epoch: 5| Step: 3
Training loss: 1.570947471269811
Validation loss: 2.6579622481703336

Epoch: 5| Step: 4
Training loss: 1.199906142855852
Validation loss: 2.7100425633867133

Epoch: 5| Step: 5
Training loss: 1.203167208637144
Validation loss: 2.7254983433313824

Epoch: 5| Step: 6
Training loss: 0.9732724731069167
Validation loss: 2.7737134820133655

Epoch: 5| Step: 7
Training loss: 1.5956108598870764
Validation loss: 2.7265680023165104

Epoch: 5| Step: 8
Training loss: 1.2422161458869032
Validation loss: 2.6412933051473315

Epoch: 5| Step: 9
Training loss: 1.8642730952056596
Validation loss: 2.717333647128323

Epoch: 5| Step: 10
Training loss: 1.730895461263937
Validation loss: 2.7648203329051833

Epoch: 730| Step: 0
Training loss: 1.2725783181961703
Validation loss: 2.7532648448991597

Epoch: 5| Step: 1
Training loss: 1.108714108321615
Validation loss: 2.712852833846241

Epoch: 5| Step: 2
Training loss: 1.118997188516857
Validation loss: 2.7695270475064135

Epoch: 5| Step: 3
Training loss: 1.2669772235897592
Validation loss: 2.8029679942400905

Epoch: 5| Step: 4
Training loss: 1.2294483131537055
Validation loss: 2.8269501510171655

Epoch: 5| Step: 5
Training loss: 1.2803261845690446
Validation loss: 2.7595659461597006

Epoch: 5| Step: 6
Training loss: 1.1653081898035411
Validation loss: 2.7261764065425216

Epoch: 5| Step: 7
Training loss: 1.1982582047689139
Validation loss: 2.749724235393281

Epoch: 5| Step: 8
Training loss: 1.4568877366800843
Validation loss: 2.7016655389540327

Epoch: 5| Step: 9
Training loss: 1.4304942372008336
Validation loss: 2.8042168479571083

Epoch: 5| Step: 10
Training loss: 2.297757141533832
Validation loss: 2.6547323583189106

Epoch: 731| Step: 0
Training loss: 1.2381887792482758
Validation loss: 2.6803468909249606

Epoch: 5| Step: 1
Training loss: 1.5019414576361283
Validation loss: 2.7375615204656785

Epoch: 5| Step: 2
Training loss: 1.254241660823552
Validation loss: 2.6770858818901697

Epoch: 5| Step: 3
Training loss: 1.1257830120128474
Validation loss: 2.697825894761087

Epoch: 5| Step: 4
Training loss: 1.4441848892556133
Validation loss: 2.8303474265246145

Epoch: 5| Step: 5
Training loss: 1.0727717415911828
Validation loss: 2.660888962235571

Epoch: 5| Step: 6
Training loss: 1.5023606321722331
Validation loss: 2.6776861114926236

Epoch: 5| Step: 7
Training loss: 1.1512181878846135
Validation loss: 2.7068603572485923

Epoch: 5| Step: 8
Training loss: 0.9959083234943814
Validation loss: 2.71866138782019

Epoch: 5| Step: 9
Training loss: 2.0264238979263234
Validation loss: 2.7508310468093558

Epoch: 5| Step: 10
Training loss: 1.1695765015760793
Validation loss: 2.7294004450241647

Epoch: 732| Step: 0
Training loss: 1.06481524266282
Validation loss: 2.6443660715580215

Epoch: 5| Step: 1
Training loss: 1.2434845396675227
Validation loss: 2.6984535494268904

Epoch: 5| Step: 2
Training loss: 1.0525057797488448
Validation loss: 2.65620976899557

Epoch: 5| Step: 3
Training loss: 1.1049937922963589
Validation loss: 2.739781725343379

Epoch: 5| Step: 4
Training loss: 1.5131912354346815
Validation loss: 2.6889932933274916

Epoch: 5| Step: 5
Training loss: 1.838530442272933
Validation loss: 2.7435578094428847

Epoch: 5| Step: 6
Training loss: 0.877466709831396
Validation loss: 2.6076288902843627

Epoch: 5| Step: 7
Training loss: 1.4209382041793497
Validation loss: 2.7403931444162213

Epoch: 5| Step: 8
Training loss: 1.6009614886739665
Validation loss: 2.693529217444086

Epoch: 5| Step: 9
Training loss: 1.235652745137507
Validation loss: 2.708261571900525

Epoch: 5| Step: 10
Training loss: 1.0901170613485678
Validation loss: 2.7594766137968674

Epoch: 733| Step: 0
Training loss: 1.1949791536946963
Validation loss: 2.694225944616308

Epoch: 5| Step: 1
Training loss: 0.9720874026840546
Validation loss: 2.6547176808010016

Epoch: 5| Step: 2
Training loss: 1.169364019247558
Validation loss: 2.7231882559270586

Epoch: 5| Step: 3
Training loss: 1.163503679129534
Validation loss: 2.8010812664701925

Epoch: 5| Step: 4
Training loss: 1.0716399154666298
Validation loss: 2.6321584987680304

Epoch: 5| Step: 5
Training loss: 1.2049430882797088
Validation loss: 2.7403652186324003

Epoch: 5| Step: 6
Training loss: 1.1565646181703026
Validation loss: 2.746081483006861

Epoch: 5| Step: 7
Training loss: 1.866212342809191
Validation loss: 2.7624382011016944

Epoch: 5| Step: 8
Training loss: 1.56474265325735
Validation loss: 2.8192611487721932

Epoch: 5| Step: 9
Training loss: 1.5545079113159874
Validation loss: 2.729906809514159

Epoch: 5| Step: 10
Training loss: 1.062731100642561
Validation loss: 2.76087677817107

Epoch: 734| Step: 0
Training loss: 2.279483163211241
Validation loss: 2.7006369426259416

Epoch: 5| Step: 1
Training loss: 1.1891102664691986
Validation loss: 2.734257620593487

Epoch: 5| Step: 2
Training loss: 1.1782208856473693
Validation loss: 2.6599885481332612

Epoch: 5| Step: 3
Training loss: 1.209515234729436
Validation loss: 2.728895451166267

Epoch: 5| Step: 4
Training loss: 1.1518288189245673
Validation loss: 2.695048703360813

Epoch: 5| Step: 5
Training loss: 1.2286645650412733
Validation loss: 2.8068220608104215

Epoch: 5| Step: 6
Training loss: 1.2882230395044925
Validation loss: 2.651734692320055

Epoch: 5| Step: 7
Training loss: 1.2883415749365623
Validation loss: 2.699318424763257

Epoch: 5| Step: 8
Training loss: 1.0718787768772857
Validation loss: 2.783911194726535

Epoch: 5| Step: 9
Training loss: 1.2421144667934407
Validation loss: 2.669951394054137

Epoch: 5| Step: 10
Training loss: 1.2647411886836877
Validation loss: 2.677280422760537

Epoch: 735| Step: 0
Training loss: 1.062575842450539
Validation loss: 2.69050778011237

Epoch: 5| Step: 1
Training loss: 1.290681689035724
Validation loss: 2.68739233352186

Epoch: 5| Step: 2
Training loss: 2.136730242877855
Validation loss: 2.6837069145182357

Epoch: 5| Step: 3
Training loss: 1.1923055287902362
Validation loss: 2.6375408662632447

Epoch: 5| Step: 4
Training loss: 1.0354551063837198
Validation loss: 2.739669989956632

Epoch: 5| Step: 5
Training loss: 1.553577582812217
Validation loss: 2.6902084534470156

Epoch: 5| Step: 6
Training loss: 1.3534035904660973
Validation loss: 2.6842598677165337

Epoch: 5| Step: 7
Training loss: 0.8720233216819843
Validation loss: 2.698594132784155

Epoch: 5| Step: 8
Training loss: 1.086167235738728
Validation loss: 2.7104914835781573

Epoch: 5| Step: 9
Training loss: 1.1800759288637346
Validation loss: 2.7736640279585094

Epoch: 5| Step: 10
Training loss: 1.422352218192043
Validation loss: 2.675705328872439

Epoch: 736| Step: 0
Training loss: 0.9813265752373931
Validation loss: 2.745280966575672

Epoch: 5| Step: 1
Training loss: 1.189020187687798
Validation loss: 2.667416182353654

Epoch: 5| Step: 2
Training loss: 1.5511810786623361
Validation loss: 2.819992552226482

Epoch: 5| Step: 3
Training loss: 1.3227779686176566
Validation loss: 2.660215046753117

Epoch: 5| Step: 4
Training loss: 1.1748044338210188
Validation loss: 2.711851706243919

Epoch: 5| Step: 5
Training loss: 1.0328227101800953
Validation loss: 2.632704957445501

Epoch: 5| Step: 6
Training loss: 1.2965403665127708
Validation loss: 2.7443614609420837

Epoch: 5| Step: 7
Training loss: 1.198681142378723
Validation loss: 2.6393544411587815

Epoch: 5| Step: 8
Training loss: 1.4870747960256099
Validation loss: 2.7038331316729534

Epoch: 5| Step: 9
Training loss: 1.7021183223544354
Validation loss: 2.734235230607785

Epoch: 5| Step: 10
Training loss: 0.8211330487894392
Validation loss: 2.616123667581331

Epoch: 737| Step: 0
Training loss: 1.1289593641200513
Validation loss: 2.6770992220325738

Epoch: 5| Step: 1
Training loss: 1.172838044227621
Validation loss: 2.7298234758082125

Epoch: 5| Step: 2
Training loss: 0.9312208337504791
Validation loss: 2.713517080483815

Epoch: 5| Step: 3
Training loss: 1.0020902959908202
Validation loss: 2.7367080247100657

Epoch: 5| Step: 4
Training loss: 1.635879920740452
Validation loss: 2.5838577983229163

Epoch: 5| Step: 5
Training loss: 1.881850063902447
Validation loss: 2.780071414860332

Epoch: 5| Step: 6
Training loss: 0.8691126786786042
Validation loss: 2.759411929222118

Epoch: 5| Step: 7
Training loss: 1.293395602940992
Validation loss: 2.663377283444623

Epoch: 5| Step: 8
Training loss: 1.2682729735697145
Validation loss: 2.7518754550757882

Epoch: 5| Step: 9
Training loss: 1.4370261530875466
Validation loss: 2.7013235923528818

Epoch: 5| Step: 10
Training loss: 1.2739536666888616
Validation loss: 2.728572493025492

Epoch: 738| Step: 0
Training loss: 0.8201227967846508
Validation loss: 2.721392395878327

Epoch: 5| Step: 1
Training loss: 1.375321003983584
Validation loss: 2.7007566812164914

Epoch: 5| Step: 2
Training loss: 1.55724871351869
Validation loss: 2.6893225945516437

Epoch: 5| Step: 3
Training loss: 1.8141501577195942
Validation loss: 2.6775249153558103

Epoch: 5| Step: 4
Training loss: 0.9555008153767204
Validation loss: 2.7522711618432965

Epoch: 5| Step: 5
Training loss: 1.478763937412856
Validation loss: 2.789549840637393

Epoch: 5| Step: 6
Training loss: 1.3387250762243583
Validation loss: 2.6956434239632374

Epoch: 5| Step: 7
Training loss: 1.212028454984762
Validation loss: 2.741164810094931

Epoch: 5| Step: 8
Training loss: 0.9973768161059611
Validation loss: 2.6492574496174592

Epoch: 5| Step: 9
Training loss: 1.3371991451975025
Validation loss: 2.742653357634035

Epoch: 5| Step: 10
Training loss: 1.111311176619995
Validation loss: 2.6112533645640803

Epoch: 739| Step: 0
Training loss: 1.2774145357542754
Validation loss: 2.6739325563244143

Epoch: 5| Step: 1
Training loss: 1.0216919667988793
Validation loss: 2.738599790554807

Epoch: 5| Step: 2
Training loss: 1.2618975911189472
Validation loss: 2.6249228259577397

Epoch: 5| Step: 3
Training loss: 1.1154210457177332
Validation loss: 2.654834103087189

Epoch: 5| Step: 4
Training loss: 1.9567628474644139
Validation loss: 2.686448164452491

Epoch: 5| Step: 5
Training loss: 1.4172762606413971
Validation loss: 2.6277518802503774

Epoch: 5| Step: 6
Training loss: 1.4327247750852878
Validation loss: 2.776580947173085

Epoch: 5| Step: 7
Training loss: 1.1464064927430382
Validation loss: 2.7169303863301466

Epoch: 5| Step: 8
Training loss: 1.0846635769794384
Validation loss: 2.6857957103070946

Epoch: 5| Step: 9
Training loss: 1.4025605440586375
Validation loss: 2.6628819752171693

Epoch: 5| Step: 10
Training loss: 0.8834141731758386
Validation loss: 2.703245223003248

Epoch: 740| Step: 0
Training loss: 0.8186244853832557
Validation loss: 2.682683825993663

Epoch: 5| Step: 1
Training loss: 1.2217510150728015
Validation loss: 2.769539830842652

Epoch: 5| Step: 2
Training loss: 0.9300889182395744
Validation loss: 2.6568458829756487

Epoch: 5| Step: 3
Training loss: 2.0258201209949944
Validation loss: 2.7532487838339184

Epoch: 5| Step: 4
Training loss: 1.177740043259577
Validation loss: 2.739825829670246

Epoch: 5| Step: 5
Training loss: 0.9452052094916106
Validation loss: 2.728383301672942

Epoch: 5| Step: 6
Training loss: 1.5062348012830102
Validation loss: 2.728357633981525

Epoch: 5| Step: 7
Training loss: 1.2638753405859051
Validation loss: 2.6684520484699084

Epoch: 5| Step: 8
Training loss: 1.4580632459216802
Validation loss: 2.719720592003615

Epoch: 5| Step: 9
Training loss: 1.1465202988775298
Validation loss: 2.750415664313428

Epoch: 5| Step: 10
Training loss: 0.952034216656579
Validation loss: 2.6920426008435667

Epoch: 741| Step: 0
Training loss: 0.9904069919351702
Validation loss: 2.7732425808961616

Epoch: 5| Step: 1
Training loss: 1.1604575847942773
Validation loss: 2.6526404083247663

Epoch: 5| Step: 2
Training loss: 1.40681285190455
Validation loss: 2.717144033648116

Epoch: 5| Step: 3
Training loss: 0.9735619491455103
Validation loss: 2.700690581690448

Epoch: 5| Step: 4
Training loss: 1.2451285806770414
Validation loss: 2.797072500255249

Epoch: 5| Step: 5
Training loss: 1.3533018970048591
Validation loss: 2.8342818971189354

Epoch: 5| Step: 6
Training loss: 1.281312243182519
Validation loss: 2.7088087726341525

Epoch: 5| Step: 7
Training loss: 0.704690039179725
Validation loss: 2.7186520721145477

Epoch: 5| Step: 8
Training loss: 2.0476786659175215
Validation loss: 2.7210042036161326

Epoch: 5| Step: 9
Training loss: 1.1235330872597475
Validation loss: 2.682112188374817

Epoch: 5| Step: 10
Training loss: 1.60856163433784
Validation loss: 2.7502286840164474

Epoch: 742| Step: 0
Training loss: 1.2383298172436612
Validation loss: 2.828730884791365

Epoch: 5| Step: 1
Training loss: 1.39920372457014
Validation loss: 2.729539171497972

Epoch: 5| Step: 2
Training loss: 1.1253657276348248
Validation loss: 2.7158016275829353

Epoch: 5| Step: 3
Training loss: 1.3268910229254984
Validation loss: 2.6428755322328636

Epoch: 5| Step: 4
Training loss: 1.3568735455997638
Validation loss: 2.6665466830220206

Epoch: 5| Step: 5
Training loss: 1.8290427748911702
Validation loss: 2.5468317880392726

Epoch: 5| Step: 6
Training loss: 1.122716387343893
Validation loss: 2.730936554111759

Epoch: 5| Step: 7
Training loss: 1.1458446270935196
Validation loss: 2.6636993128883653

Epoch: 5| Step: 8
Training loss: 1.5032721433570864
Validation loss: 2.6804132597168255

Epoch: 5| Step: 9
Training loss: 1.211330768344902
Validation loss: 2.680234024529679

Epoch: 5| Step: 10
Training loss: 1.0607739059771648
Validation loss: 2.724056848134196

Epoch: 743| Step: 0
Training loss: 0.9739268020720924
Validation loss: 2.6703578727019885

Epoch: 5| Step: 1
Training loss: 1.115772338028165
Validation loss: 2.663785643941066

Epoch: 5| Step: 2
Training loss: 0.7574245600384735
Validation loss: 2.803609708974618

Epoch: 5| Step: 3
Training loss: 1.3016917847974816
Validation loss: 2.707885433641781

Epoch: 5| Step: 4
Training loss: 1.1848505982647919
Validation loss: 2.8407850326940594

Epoch: 5| Step: 5
Training loss: 1.2840658275183285
Validation loss: 2.684299256187313

Epoch: 5| Step: 6
Training loss: 1.2586297170376561
Validation loss: 2.647134542471371

Epoch: 5| Step: 7
Training loss: 1.3502096119381035
Validation loss: 2.690990765089034

Epoch: 5| Step: 8
Training loss: 1.2265219712091442
Validation loss: 2.6471097507794905

Epoch: 5| Step: 9
Training loss: 1.943889480443671
Validation loss: 2.755342488434793

Epoch: 5| Step: 10
Training loss: 1.4095960016646385
Validation loss: 2.709951407413859

Epoch: 744| Step: 0
Training loss: 1.2162302819718807
Validation loss: 2.6889397517555746

Epoch: 5| Step: 1
Training loss: 1.4283980094009157
Validation loss: 2.733527584461701

Epoch: 5| Step: 2
Training loss: 1.2177001147921516
Validation loss: 2.6145117903162878

Epoch: 5| Step: 3
Training loss: 0.8784893488230141
Validation loss: 2.6584197793301385

Epoch: 5| Step: 4
Training loss: 0.8633614067044756
Validation loss: 2.713905823198945

Epoch: 5| Step: 5
Training loss: 1.002932480731109
Validation loss: 2.71576078727218

Epoch: 5| Step: 6
Training loss: 1.849158807193144
Validation loss: 2.748501497090119

Epoch: 5| Step: 7
Training loss: 1.336284971502172
Validation loss: 2.7881445015787767

Epoch: 5| Step: 8
Training loss: 1.2965762702024934
Validation loss: 2.60346294090953

Epoch: 5| Step: 9
Training loss: 1.339619253496675
Validation loss: 2.6144596376677764

Epoch: 5| Step: 10
Training loss: 1.1288065090798782
Validation loss: 2.7746083282958294

Epoch: 745| Step: 0
Training loss: 1.2635504592040288
Validation loss: 2.733803810664231

Epoch: 5| Step: 1
Training loss: 0.9117017729681411
Validation loss: 2.618692610864621

Epoch: 5| Step: 2
Training loss: 0.9816781598105385
Validation loss: 2.7024318259872087

Epoch: 5| Step: 3
Training loss: 1.2478135059409
Validation loss: 2.7079047691450255

Epoch: 5| Step: 4
Training loss: 1.2579417665767143
Validation loss: 2.655380045759607

Epoch: 5| Step: 5
Training loss: 0.6610385709277917
Validation loss: 2.802435240807859

Epoch: 5| Step: 6
Training loss: 2.0715018832570844
Validation loss: 2.7744725243109705

Epoch: 5| Step: 7
Training loss: 1.391751722298775
Validation loss: 2.605427320622981

Epoch: 5| Step: 8
Training loss: 1.378885241988738
Validation loss: 2.77554172600087

Epoch: 5| Step: 9
Training loss: 1.1078106233180067
Validation loss: 2.7348090473939752

Epoch: 5| Step: 10
Training loss: 1.316650141640471
Validation loss: 2.671838957428261

Epoch: 746| Step: 0
Training loss: 1.4666280636620082
Validation loss: 2.667453998294687

Epoch: 5| Step: 1
Training loss: 1.4494602382610586
Validation loss: 2.7272697377942063

Epoch: 5| Step: 2
Training loss: 1.1175325834401224
Validation loss: 2.7359483580691455

Epoch: 5| Step: 3
Training loss: 1.2858778020784292
Validation loss: 2.6951502407099297

Epoch: 5| Step: 4
Training loss: 1.9478059285011866
Validation loss: 2.6370359115022213

Epoch: 5| Step: 5
Training loss: 1.260674106169129
Validation loss: 2.6721471419905742

Epoch: 5| Step: 6
Training loss: 1.2097511633063105
Validation loss: 2.690075564762757

Epoch: 5| Step: 7
Training loss: 1.25863790973313
Validation loss: 2.7436681017207354

Epoch: 5| Step: 8
Training loss: 1.0513783853449397
Validation loss: 2.637696783021323

Epoch: 5| Step: 9
Training loss: 0.9787123248277528
Validation loss: 2.6340938300851415

Epoch: 5| Step: 10
Training loss: 0.9725036807836389
Validation loss: 2.6464826371575803

Epoch: 747| Step: 0
Training loss: 1.0712482788891136
Validation loss: 2.708971710947933

Epoch: 5| Step: 1
Training loss: 1.9067220884995844
Validation loss: 2.7063042640053263

Epoch: 5| Step: 2
Training loss: 1.2097977719887265
Validation loss: 2.7297927381318954

Epoch: 5| Step: 3
Training loss: 1.2629060620993617
Validation loss: 2.715941482870209

Epoch: 5| Step: 4
Training loss: 1.136300550790452
Validation loss: 2.6355839217860466

Epoch: 5| Step: 5
Training loss: 0.9482308101266149
Validation loss: 2.744600311338225

Epoch: 5| Step: 6
Training loss: 1.0256043420323302
Validation loss: 2.6762150152325805

Epoch: 5| Step: 7
Training loss: 1.043754710112583
Validation loss: 2.703480593933321

Epoch: 5| Step: 8
Training loss: 1.1532160157051168
Validation loss: 2.6747574810228185

Epoch: 5| Step: 9
Training loss: 1.5960471110501495
Validation loss: 2.6158702823790336

Epoch: 5| Step: 10
Training loss: 1.335650318353835
Validation loss: 2.7316237692896537

Epoch: 748| Step: 0
Training loss: 1.2635793755238356
Validation loss: 2.6874926338753053

Epoch: 5| Step: 1
Training loss: 0.9103682111565289
Validation loss: 2.7485852223976313

Epoch: 5| Step: 2
Training loss: 1.1064355619157467
Validation loss: 2.72436325203014

Epoch: 5| Step: 3
Training loss: 0.835779870403504
Validation loss: 2.7374470506957316

Epoch: 5| Step: 4
Training loss: 1.9656518446115663
Validation loss: 2.7592887990470456

Epoch: 5| Step: 5
Training loss: 1.140020131719751
Validation loss: 2.6692973480388376

Epoch: 5| Step: 6
Training loss: 1.1036778693644949
Validation loss: 2.6686135544036427

Epoch: 5| Step: 7
Training loss: 1.5310266292904764
Validation loss: 2.8284575953939575

Epoch: 5| Step: 8
Training loss: 1.2316832830541071
Validation loss: 2.768538047496148

Epoch: 5| Step: 9
Training loss: 1.0364957384168183
Validation loss: 2.772384182405858

Epoch: 5| Step: 10
Training loss: 1.3474599059444206
Validation loss: 2.6788367579003594

Epoch: 749| Step: 0
Training loss: 1.1139428030291367
Validation loss: 2.7588391976425086

Epoch: 5| Step: 1
Training loss: 1.9852544682933682
Validation loss: 2.7963113955367214

Epoch: 5| Step: 2
Training loss: 1.0286146070674071
Validation loss: 2.726227781816254

Epoch: 5| Step: 3
Training loss: 1.351221559773978
Validation loss: 2.7492507853674653

Epoch: 5| Step: 4
Training loss: 1.0688922675848858
Validation loss: 2.7147100548333993

Epoch: 5| Step: 5
Training loss: 1.1555946142267233
Validation loss: 2.62757986423704

Epoch: 5| Step: 6
Training loss: 1.1972231087284293
Validation loss: 2.671489678916581

Epoch: 5| Step: 7
Training loss: 0.9316356666800871
Validation loss: 2.703004135245521

Epoch: 5| Step: 8
Training loss: 1.3321015459680416
Validation loss: 2.6063084126387195

Epoch: 5| Step: 9
Training loss: 1.0687804569120871
Validation loss: 2.666438085875435

Epoch: 5| Step: 10
Training loss: 0.8939092547575058
Validation loss: 2.7273913319395025

Epoch: 750| Step: 0
Training loss: 1.0683987625923261
Validation loss: 2.648548075150278

Epoch: 5| Step: 1
Training loss: 1.0836243727578025
Validation loss: 2.677542077410602

Epoch: 5| Step: 2
Training loss: 1.4414014531911208
Validation loss: 2.6593305498811945

Epoch: 5| Step: 3
Training loss: 1.0782769137622699
Validation loss: 2.7772544171604476

Epoch: 5| Step: 4
Training loss: 0.9899319218819734
Validation loss: 2.683174385810694

Epoch: 5| Step: 5
Training loss: 1.2197672193484184
Validation loss: 2.7273101547863767

Epoch: 5| Step: 6
Training loss: 1.3622846048166912
Validation loss: 2.7181147114964874

Epoch: 5| Step: 7
Training loss: 1.255784099215372
Validation loss: 2.7777106123840274

Epoch: 5| Step: 8
Training loss: 1.844029680149751
Validation loss: 2.7272808721022366

Epoch: 5| Step: 9
Training loss: 1.1844112984522595
Validation loss: 2.716719677733341

Epoch: 5| Step: 10
Training loss: 1.6747174921498174
Validation loss: 2.5616244129025576

Epoch: 751| Step: 0
Training loss: 1.3612420863542416
Validation loss: 2.618497462089023

Epoch: 5| Step: 1
Training loss: 1.1371080184294178
Validation loss: 2.691325144802828

Epoch: 5| Step: 2
Training loss: 1.6846332925274117
Validation loss: 2.731432674684827

Epoch: 5| Step: 3
Training loss: 0.8760202454356908
Validation loss: 2.5899190804366277

Epoch: 5| Step: 4
Training loss: 1.2250659341000614
Validation loss: 2.7171924558115026

Epoch: 5| Step: 5
Training loss: 1.321212055812717
Validation loss: 2.6702774156432834

Epoch: 5| Step: 6
Training loss: 1.1804980594371857
Validation loss: 2.6849414430121676

Epoch: 5| Step: 7
Training loss: 1.1889816878298636
Validation loss: 2.7442352844968405

Epoch: 5| Step: 8
Training loss: 1.1481471310944877
Validation loss: 2.5996290607270534

Epoch: 5| Step: 9
Training loss: 1.2655384363782893
Validation loss: 2.608746095278216

Epoch: 5| Step: 10
Training loss: 1.4609964124255614
Validation loss: 2.7739957375603286

Epoch: 752| Step: 0
Training loss: 1.096256381617624
Validation loss: 2.6735244022736904

Epoch: 5| Step: 1
Training loss: 1.6287038114707253
Validation loss: 2.7183436588783274

Epoch: 5| Step: 2
Training loss: 0.9243320115147946
Validation loss: 2.6485425007670544

Epoch: 5| Step: 3
Training loss: 1.1158335557576062
Validation loss: 2.662489879680778

Epoch: 5| Step: 4
Training loss: 1.065469966585086
Validation loss: 2.7088681316941847

Epoch: 5| Step: 5
Training loss: 1.2006666159777195
Validation loss: 2.660255182493225

Epoch: 5| Step: 6
Training loss: 1.6818432835338857
Validation loss: 2.711368700618417

Epoch: 5| Step: 7
Training loss: 1.100164405501046
Validation loss: 2.7269595700600036

Epoch: 5| Step: 8
Training loss: 1.5249746539401605
Validation loss: 2.7070945487656535

Epoch: 5| Step: 9
Training loss: 1.185191772169997
Validation loss: 2.7079613258947224

Epoch: 5| Step: 10
Training loss: 1.250532323023729
Validation loss: 2.725440769649943

Epoch: 753| Step: 0
Training loss: 1.1008554989943675
Validation loss: 2.713952080459363

Epoch: 5| Step: 1
Training loss: 1.0702746864934465
Validation loss: 2.652912428399208

Epoch: 5| Step: 2
Training loss: 0.8410045320068972
Validation loss: 2.7543239095556333

Epoch: 5| Step: 3
Training loss: 0.9564807787896691
Validation loss: 2.717575214522175

Epoch: 5| Step: 4
Training loss: 1.0060563274259833
Validation loss: 2.801826553726128

Epoch: 5| Step: 5
Training loss: 1.2017178914919306
Validation loss: 2.7356625189848898

Epoch: 5| Step: 6
Training loss: 1.0479144160181426
Validation loss: 2.8024249869043842

Epoch: 5| Step: 7
Training loss: 2.1277150032249925
Validation loss: 2.6743669204856935

Epoch: 5| Step: 8
Training loss: 1.0710989853879163
Validation loss: 2.842956470117082

Epoch: 5| Step: 9
Training loss: 1.5496465341484618
Validation loss: 2.7525112063330184

Epoch: 5| Step: 10
Training loss: 1.1985051520200654
Validation loss: 2.6202517808979944

Epoch: 754| Step: 0
Training loss: 1.1877709129899565
Validation loss: 2.6476053802581556

Epoch: 5| Step: 1
Training loss: 1.189954279413979
Validation loss: 2.722572518281987

Epoch: 5| Step: 2
Training loss: 1.0512593256007177
Validation loss: 2.695952350604827

Epoch: 5| Step: 3
Training loss: 1.019258835451793
Validation loss: 2.698133165290888

Epoch: 5| Step: 4
Training loss: 1.1872501612406317
Validation loss: 2.648678470168327

Epoch: 5| Step: 5
Training loss: 1.640893678009187
Validation loss: 2.804666154889742

Epoch: 5| Step: 6
Training loss: 1.3621811239885764
Validation loss: 2.7107876191897016

Epoch: 5| Step: 7
Training loss: 1.3778374179413317
Validation loss: 2.6641323354823516

Epoch: 5| Step: 8
Training loss: 1.3722412871676466
Validation loss: 2.673451249723206

Epoch: 5| Step: 9
Training loss: 1.1052639505316586
Validation loss: 2.6897439691196654

Epoch: 5| Step: 10
Training loss: 1.094861147363827
Validation loss: 2.671779690117018

Epoch: 755| Step: 0
Training loss: 1.4564187242726547
Validation loss: 2.83936774403617

Epoch: 5| Step: 1
Training loss: 1.4113170463914835
Validation loss: 2.6787209797297864

Epoch: 5| Step: 2
Training loss: 1.5162265802824877
Validation loss: 2.807857158690423

Epoch: 5| Step: 3
Training loss: 0.9406010520142389
Validation loss: 2.693936534112673

Epoch: 5| Step: 4
Training loss: 1.0510695958782361
Validation loss: 2.8016593921337543

Epoch: 5| Step: 5
Training loss: 1.880510624671707
Validation loss: 2.8623557573548655

Epoch: 5| Step: 6
Training loss: 1.1440290058633626
Validation loss: 2.758302384976708

Epoch: 5| Step: 7
Training loss: 1.1011404757642564
Validation loss: 2.6471731381769508

Epoch: 5| Step: 8
Training loss: 0.9517213147056341
Validation loss: 2.645676458422136

Epoch: 5| Step: 9
Training loss: 1.0299322783789597
Validation loss: 2.725295153827336

Epoch: 5| Step: 10
Training loss: 1.1759744783214174
Validation loss: 2.658704199393356

Epoch: 756| Step: 0
Training loss: 0.9328171760275747
Validation loss: 2.763452233399282

Epoch: 5| Step: 1
Training loss: 1.5487180576925228
Validation loss: 2.7534429964173186

Epoch: 5| Step: 2
Training loss: 1.2114024100457437
Validation loss: 2.7162736112616033

Epoch: 5| Step: 3
Training loss: 1.2410508239384344
Validation loss: 2.699038439384492

Epoch: 5| Step: 4
Training loss: 1.14004930573633
Validation loss: 2.7612621149574172

Epoch: 5| Step: 5
Training loss: 1.3535049680260023
Validation loss: 2.6490417346817106

Epoch: 5| Step: 6
Training loss: 1.8770876388698006
Validation loss: 2.672906021952373

Epoch: 5| Step: 7
Training loss: 1.0972233797756694
Validation loss: 2.8225592742790617

Epoch: 5| Step: 8
Training loss: 1.175502503263014
Validation loss: 2.7120738498882395

Epoch: 5| Step: 9
Training loss: 0.9399345258981134
Validation loss: 2.644438121785281

Epoch: 5| Step: 10
Training loss: 1.207835549829203
Validation loss: 2.604216262016975

Epoch: 757| Step: 0
Training loss: 1.1909257764196708
Validation loss: 2.693722771110426

Epoch: 5| Step: 1
Training loss: 1.3699300669481462
Validation loss: 2.761602740757824

Epoch: 5| Step: 2
Training loss: 1.072314707704466
Validation loss: 2.738261456311455

Epoch: 5| Step: 3
Training loss: 1.082837351944555
Validation loss: 2.734485884848463

Epoch: 5| Step: 4
Training loss: 1.440060284332853
Validation loss: 2.732767491975617

Epoch: 5| Step: 5
Training loss: 1.926291562572046
Validation loss: 2.697292981450073

Epoch: 5| Step: 6
Training loss: 1.0324113837353879
Validation loss: 2.7717269103018087

Epoch: 5| Step: 7
Training loss: 1.16308506630097
Validation loss: 2.7438594560357648

Epoch: 5| Step: 8
Training loss: 1.2344649076916459
Validation loss: 2.837277476338411

Epoch: 5| Step: 9
Training loss: 1.3969623307956838
Validation loss: 2.624588802807255

Epoch: 5| Step: 10
Training loss: 1.2745843883126367
Validation loss: 2.8007167015189616

Epoch: 758| Step: 0
Training loss: 1.2919243688797712
Validation loss: 2.7506866446172245

Epoch: 5| Step: 1
Training loss: 1.1861361652580023
Validation loss: 2.78595642286231

Epoch: 5| Step: 2
Training loss: 0.931007281937685
Validation loss: 2.7554149564553194

Epoch: 5| Step: 3
Training loss: 1.4407903911456557
Validation loss: 2.6543082835422753

Epoch: 5| Step: 4
Training loss: 1.3107475661495822
Validation loss: 2.6626788282116314

Epoch: 5| Step: 5
Training loss: 1.824125299776155
Validation loss: 2.6552048423931227

Epoch: 5| Step: 6
Training loss: 1.4910771098163276
Validation loss: 2.749591892198162

Epoch: 5| Step: 7
Training loss: 0.9521427408683754
Validation loss: 2.765856975589614

Epoch: 5| Step: 8
Training loss: 1.0419214255018758
Validation loss: 2.682522391170671

Epoch: 5| Step: 9
Training loss: 1.0902036667329118
Validation loss: 2.617539497645782

Epoch: 5| Step: 10
Training loss: 1.2644570224196336
Validation loss: 2.710695814897834

Epoch: 759| Step: 0
Training loss: 0.9956499794163048
Validation loss: 2.737694449904528

Epoch: 5| Step: 1
Training loss: 1.6172388778117732
Validation loss: 2.6205659461489264

Epoch: 5| Step: 2
Training loss: 1.217134970632072
Validation loss: 2.7469398946410077

Epoch: 5| Step: 3
Training loss: 1.4256416984091906
Validation loss: 2.6380833763127782

Epoch: 5| Step: 4
Training loss: 1.256812509645916
Validation loss: 2.681162421297351

Epoch: 5| Step: 5
Training loss: 1.258062160190383
Validation loss: 2.7155977380295786

Epoch: 5| Step: 6
Training loss: 1.2896316658950335
Validation loss: 2.7286520382483506

Epoch: 5| Step: 7
Training loss: 1.3326682080852632
Validation loss: 2.6995369217457297

Epoch: 5| Step: 8
Training loss: 1.132271841531306
Validation loss: 2.7297299863681874

Epoch: 5| Step: 9
Training loss: 0.9514991776768013
Validation loss: 2.7110391316257845

Epoch: 5| Step: 10
Training loss: 1.1555440139245066
Validation loss: 2.7185665677408086

Epoch: 760| Step: 0
Training loss: 1.2304023361448029
Validation loss: 2.70963163628333

Epoch: 5| Step: 1
Training loss: 1.5989711731965723
Validation loss: 2.725978649768274

Epoch: 5| Step: 2
Training loss: 1.9434802147182308
Validation loss: 2.7902640304205404

Epoch: 5| Step: 3
Training loss: 0.8919959642678215
Validation loss: 2.6610591873200238

Epoch: 5| Step: 4
Training loss: 1.0266179178686394
Validation loss: 2.8902858917689107

Epoch: 5| Step: 5
Training loss: 1.1661868584682884
Validation loss: 2.6476075981175318

Epoch: 5| Step: 6
Training loss: 1.0452999963853618
Validation loss: 2.703500442185713

Epoch: 5| Step: 7
Training loss: 1.2007592461678946
Validation loss: 2.723481600413434

Epoch: 5| Step: 8
Training loss: 1.2016998867270083
Validation loss: 2.8026954015030325

Epoch: 5| Step: 9
Training loss: 1.1502779790521973
Validation loss: 2.8129507890806162

Epoch: 5| Step: 10
Training loss: 1.3224845490878103
Validation loss: 2.790663536347801

Epoch: 761| Step: 0
Training loss: 0.9274655886330498
Validation loss: 2.663049082851098

Epoch: 5| Step: 1
Training loss: 1.208757764442225
Validation loss: 2.6694994363004874

Epoch: 5| Step: 2
Training loss: 1.3500406153185331
Validation loss: 2.762159304939847

Epoch: 5| Step: 3
Training loss: 1.2188821378625443
Validation loss: 2.7662227400174113

Epoch: 5| Step: 4
Training loss: 1.1378507974492347
Validation loss: 2.6507320238129015

Epoch: 5| Step: 5
Training loss: 1.8871055190801658
Validation loss: 2.6344129337160496

Epoch: 5| Step: 6
Training loss: 1.0189480337494512
Validation loss: 2.6552056360464986

Epoch: 5| Step: 7
Training loss: 1.0633646307996065
Validation loss: 2.7092896173359913

Epoch: 5| Step: 8
Training loss: 1.3164752070536871
Validation loss: 2.7098065599796883

Epoch: 5| Step: 9
Training loss: 1.1388521918662307
Validation loss: 2.693592190117681

Epoch: 5| Step: 10
Training loss: 1.1710401485867385
Validation loss: 2.724117682770465

Epoch: 762| Step: 0
Training loss: 0.9857451576232003
Validation loss: 2.714407358177785

Epoch: 5| Step: 1
Training loss: 1.1992462850882524
Validation loss: 2.670759028321856

Epoch: 5| Step: 2
Training loss: 1.1579626132780345
Validation loss: 2.7351455891801804

Epoch: 5| Step: 3
Training loss: 1.2065958268533348
Validation loss: 2.7390641637165687

Epoch: 5| Step: 4
Training loss: 1.369392404519666
Validation loss: 2.8576931031710684

Epoch: 5| Step: 5
Training loss: 1.0265462122166469
Validation loss: 2.741016262268159

Epoch: 5| Step: 6
Training loss: 0.8473353679509
Validation loss: 2.772462248696675

Epoch: 5| Step: 7
Training loss: 1.22945136744067
Validation loss: 2.7125190957617717

Epoch: 5| Step: 8
Training loss: 1.852170176520767
Validation loss: 2.751799061147051

Epoch: 5| Step: 9
Training loss: 1.1221473873217305
Validation loss: 2.7292438756984705

Epoch: 5| Step: 10
Training loss: 1.2608792373073214
Validation loss: 2.6854708967899663

Epoch: 763| Step: 0
Training loss: 1.213650181493265
Validation loss: 2.736923937669966

Epoch: 5| Step: 1
Training loss: 1.6277118209839911
Validation loss: 2.6282142126044157

Epoch: 5| Step: 2
Training loss: 1.1733520862767732
Validation loss: 2.7278198263577056

Epoch: 5| Step: 3
Training loss: 1.151264629374611
Validation loss: 2.70291899612693

Epoch: 5| Step: 4
Training loss: 1.0275978383357445
Validation loss: 2.6298766906751596

Epoch: 5| Step: 5
Training loss: 1.239739603188627
Validation loss: 2.6427322487178238

Epoch: 5| Step: 6
Training loss: 1.1032196458193138
Validation loss: 2.6232510750204656

Epoch: 5| Step: 7
Training loss: 1.2205441302705888
Validation loss: 2.7221342849284498

Epoch: 5| Step: 8
Training loss: 1.2349492922114236
Validation loss: 2.662463990778285

Epoch: 5| Step: 9
Training loss: 1.3535613345399957
Validation loss: 2.7334651252391304

Epoch: 5| Step: 10
Training loss: 1.3358079278584158
Validation loss: 2.713008811685184

Epoch: 764| Step: 0
Training loss: 1.1656334025307695
Validation loss: 2.7151391814761845

Epoch: 5| Step: 1
Training loss: 1.306474660873683
Validation loss: 2.723141906080724

Epoch: 5| Step: 2
Training loss: 0.8901102017100773
Validation loss: 2.6444968593968556

Epoch: 5| Step: 3
Training loss: 1.1772784968710446
Validation loss: 2.734720253426056

Epoch: 5| Step: 4
Training loss: 1.2399198358526329
Validation loss: 2.7464262337271674

Epoch: 5| Step: 5
Training loss: 1.7727633635975215
Validation loss: 2.701391123626907

Epoch: 5| Step: 6
Training loss: 1.0388030108204402
Validation loss: 2.64714077255924

Epoch: 5| Step: 7
Training loss: 1.1580606150962045
Validation loss: 2.77976107173934

Epoch: 5| Step: 8
Training loss: 1.247135790940799
Validation loss: 2.6548404280873616

Epoch: 5| Step: 9
Training loss: 0.9886674691730962
Validation loss: 2.6892979610840184

Epoch: 5| Step: 10
Training loss: 1.5956272961681803
Validation loss: 2.6234666395939694

Epoch: 765| Step: 0
Training loss: 2.0423914602475426
Validation loss: 2.763486183114523

Epoch: 5| Step: 1
Training loss: 1.2124801653783257
Validation loss: 2.7717698672044473

Epoch: 5| Step: 2
Training loss: 1.4890780180916052
Validation loss: 2.792487468424213

Epoch: 5| Step: 3
Training loss: 0.9797565867812669
Validation loss: 2.8128732759435082

Epoch: 5| Step: 4
Training loss: 1.3083550534399355
Validation loss: 2.7194688822762707

Epoch: 5| Step: 5
Training loss: 1.0310093570029324
Validation loss: 2.7754050208963195

Epoch: 5| Step: 6
Training loss: 0.8281693356719767
Validation loss: 2.7616267580507996

Epoch: 5| Step: 7
Training loss: 0.7293304304873542
Validation loss: 2.7959168897203006

Epoch: 5| Step: 8
Training loss: 1.1885500832654456
Validation loss: 2.733270680089404

Epoch: 5| Step: 9
Training loss: 1.505311621407729
Validation loss: 2.6464660132906768

Epoch: 5| Step: 10
Training loss: 1.2009998725617888
Validation loss: 2.7707748681400823

Epoch: 766| Step: 0
Training loss: 0.9600300730028167
Validation loss: 2.7268184287062285

Epoch: 5| Step: 1
Training loss: 1.699485880582943
Validation loss: 2.7175822660984426

Epoch: 5| Step: 2
Training loss: 1.2292915647165947
Validation loss: 2.7108778448593203

Epoch: 5| Step: 3
Training loss: 1.3034070978892451
Validation loss: 2.6837541278794164

Epoch: 5| Step: 4
Training loss: 1.082115858605405
Validation loss: 2.7376253119692144

Epoch: 5| Step: 5
Training loss: 0.9307989961329393
Validation loss: 2.660491263562683

Epoch: 5| Step: 6
Training loss: 1.2678162243877464
Validation loss: 2.655752862473452

Epoch: 5| Step: 7
Training loss: 0.8285529272593022
Validation loss: 2.7380090475545114

Epoch: 5| Step: 8
Training loss: 1.2098592079630408
Validation loss: 2.6790745679739714

Epoch: 5| Step: 9
Training loss: 1.6009929853925415
Validation loss: 2.758986914086011

Epoch: 5| Step: 10
Training loss: 1.4039578300430264
Validation loss: 2.8536126889812747

Epoch: 767| Step: 0
Training loss: 1.3138309270177073
Validation loss: 2.752537970409028

Epoch: 5| Step: 1
Training loss: 1.2998894277645552
Validation loss: 2.780489874961694

Epoch: 5| Step: 2
Training loss: 1.3019789030794722
Validation loss: 2.7759371880621697

Epoch: 5| Step: 3
Training loss: 1.1584860341988228
Validation loss: 2.80875795511819

Epoch: 5| Step: 4
Training loss: 0.9519257426872956
Validation loss: 2.6937058701302896

Epoch: 5| Step: 5
Training loss: 1.2141456683526455
Validation loss: 2.5711768378573474

Epoch: 5| Step: 6
Training loss: 1.072959355859947
Validation loss: 2.693441784787656

Epoch: 5| Step: 7
Training loss: 1.0659493386252294
Validation loss: 2.750413844869102

Epoch: 5| Step: 8
Training loss: 1.7348048734187025
Validation loss: 2.70170491468543

Epoch: 5| Step: 9
Training loss: 1.242321990787759
Validation loss: 2.7740486873130568

Epoch: 5| Step: 10
Training loss: 1.0102505432633428
Validation loss: 2.763040644806518

Epoch: 768| Step: 0
Training loss: 0.9633867018897083
Validation loss: 2.6877759260972303

Epoch: 5| Step: 1
Training loss: 1.302559859498324
Validation loss: 2.7083155711106652

Epoch: 5| Step: 2
Training loss: 0.9979084911821205
Validation loss: 2.709815452932708

Epoch: 5| Step: 3
Training loss: 1.1383258693016576
Validation loss: 2.78369713409271

Epoch: 5| Step: 4
Training loss: 1.3429901724943645
Validation loss: 2.662581707331698

Epoch: 5| Step: 5
Training loss: 1.050982884911032
Validation loss: 2.685218789144934

Epoch: 5| Step: 6
Training loss: 0.741920704321565
Validation loss: 2.7039251523761685

Epoch: 5| Step: 7
Training loss: 1.0028322761276054
Validation loss: 2.720161491198904

Epoch: 5| Step: 8
Training loss: 1.8272934024785004
Validation loss: 2.7822371368667396

Epoch: 5| Step: 9
Training loss: 1.1668074840756806
Validation loss: 2.754271602606439

Epoch: 5| Step: 10
Training loss: 1.0309344878301587
Validation loss: 2.7132052838836747

Epoch: 769| Step: 0
Training loss: 0.9740350594447758
Validation loss: 2.8157801779709732

Epoch: 5| Step: 1
Training loss: 1.5502648250398179
Validation loss: 2.7806235807759263

Epoch: 5| Step: 2
Training loss: 0.9875247155488743
Validation loss: 2.7321409929182847

Epoch: 5| Step: 3
Training loss: 1.1995174272105273
Validation loss: 2.744039416834376

Epoch: 5| Step: 4
Training loss: 1.364494767360362
Validation loss: 2.721064049412104

Epoch: 5| Step: 5
Training loss: 1.2512354467500253
Validation loss: 2.624233932946247

Epoch: 5| Step: 6
Training loss: 1.4816218492890727
Validation loss: 2.6962730252524376

Epoch: 5| Step: 7
Training loss: 0.9035841108161246
Validation loss: 2.6882341392841114

Epoch: 5| Step: 8
Training loss: 1.2775897334585051
Validation loss: 2.6824676261617886

Epoch: 5| Step: 9
Training loss: 1.0208261385813338
Validation loss: 2.682834158848249

Epoch: 5| Step: 10
Training loss: 1.1526804286700794
Validation loss: 2.64885323319417

Epoch: 770| Step: 0
Training loss: 1.1480202987517818
Validation loss: 2.7118635013116856

Epoch: 5| Step: 1
Training loss: 0.9875501559593978
Validation loss: 2.664306313832096

Epoch: 5| Step: 2
Training loss: 1.347058282405481
Validation loss: 2.7064554066377022

Epoch: 5| Step: 3
Training loss: 1.2655519064059038
Validation loss: 2.7773628405549227

Epoch: 5| Step: 4
Training loss: 1.0966083235038468
Validation loss: 2.6328743299651958

Epoch: 5| Step: 5
Training loss: 0.6833998486857795
Validation loss: 2.672792364641505

Epoch: 5| Step: 6
Training loss: 1.3604791475974056
Validation loss: 2.6975748524461927

Epoch: 5| Step: 7
Training loss: 1.1766151689997923
Validation loss: 2.820157819913739

Epoch: 5| Step: 8
Training loss: 1.1464339964941574
Validation loss: 2.6882917111330307

Epoch: 5| Step: 9
Training loss: 1.9053916249262222
Validation loss: 2.700376886370607

Epoch: 5| Step: 10
Training loss: 0.9544971157607898
Validation loss: 2.6909124559391655

Epoch: 771| Step: 0
Training loss: 1.0375584781206404
Validation loss: 2.617187173813059

Epoch: 5| Step: 1
Training loss: 0.9988816683683527
Validation loss: 2.68545343744008

Epoch: 5| Step: 2
Training loss: 1.2888222672839857
Validation loss: 2.7372713374546365

Epoch: 5| Step: 3
Training loss: 1.2513264294127162
Validation loss: 2.7345128159723946

Epoch: 5| Step: 4
Training loss: 1.8483945891558056
Validation loss: 2.6195518259750967

Epoch: 5| Step: 5
Training loss: 1.3157561646813025
Validation loss: 2.7549192956727677

Epoch: 5| Step: 6
Training loss: 1.10444232210876
Validation loss: 2.614360304816681

Epoch: 5| Step: 7
Training loss: 0.897246358994276
Validation loss: 2.7516198556709743

Epoch: 5| Step: 8
Training loss: 0.96380911886964
Validation loss: 2.7883858240597412

Epoch: 5| Step: 9
Training loss: 0.8992226528477423
Validation loss: 2.718845413376283

Epoch: 5| Step: 10
Training loss: 1.3697330863619948
Validation loss: 2.768958720915434

Epoch: 772| Step: 0
Training loss: 1.285204483564851
Validation loss: 2.6200779593882686

Epoch: 5| Step: 1
Training loss: 1.4072077139042822
Validation loss: 2.6766380926797986

Epoch: 5| Step: 2
Training loss: 1.163360537663607
Validation loss: 2.7772722649428148

Epoch: 5| Step: 3
Training loss: 1.2022246918405146
Validation loss: 2.6976901645170894

Epoch: 5| Step: 4
Training loss: 0.916367095344949
Validation loss: 2.770670633830804

Epoch: 5| Step: 5
Training loss: 1.2945096149374822
Validation loss: 2.8157056025395515

Epoch: 5| Step: 6
Training loss: 0.9998121085080616
Validation loss: 2.63797223034883

Epoch: 5| Step: 7
Training loss: 1.2985947478153643
Validation loss: 2.7853034690657448

Epoch: 5| Step: 8
Training loss: 1.7194870495520664
Validation loss: 2.708156187702446

Epoch: 5| Step: 9
Training loss: 1.1091290053449312
Validation loss: 2.7323838961170788

Epoch: 5| Step: 10
Training loss: 1.1749852423045508
Validation loss: 2.7318433836052107

Epoch: 773| Step: 0
Training loss: 1.8020837008378494
Validation loss: 2.7048887527772583

Epoch: 5| Step: 1
Training loss: 1.5178088941839536
Validation loss: 2.6275853689394895

Epoch: 5| Step: 2
Training loss: 1.2095790996383247
Validation loss: 2.656757547047419

Epoch: 5| Step: 3
Training loss: 1.2330510729338993
Validation loss: 2.77250841758904

Epoch: 5| Step: 4
Training loss: 0.8603523592127944
Validation loss: 2.7247286171191303

Epoch: 5| Step: 5
Training loss: 1.1798577596312345
Validation loss: 2.6789220527911057

Epoch: 5| Step: 6
Training loss: 0.8528548417250879
Validation loss: 2.7219615153543524

Epoch: 5| Step: 7
Training loss: 1.3307768880968136
Validation loss: 2.5916315622850234

Epoch: 5| Step: 8
Training loss: 1.3973638152915195
Validation loss: 2.7018015344304667

Epoch: 5| Step: 9
Training loss: 0.9057153571671762
Validation loss: 2.777581135718225

Epoch: 5| Step: 10
Training loss: 1.3827015891558945
Validation loss: 2.7089279900818206

Epoch: 774| Step: 0
Training loss: 0.9774917453895391
Validation loss: 2.6580612020440033

Epoch: 5| Step: 1
Training loss: 1.0707776249348682
Validation loss: 2.7092869583977683

Epoch: 5| Step: 2
Training loss: 1.1765719065093871
Validation loss: 2.587975242687885

Epoch: 5| Step: 3
Training loss: 1.2291056030536784
Validation loss: 2.715222080227597

Epoch: 5| Step: 4
Training loss: 1.0335622354490845
Validation loss: 2.7278854705686753

Epoch: 5| Step: 5
Training loss: 1.1526334236845799
Validation loss: 2.756329106085403

Epoch: 5| Step: 6
Training loss: 1.9037357070797087
Validation loss: 2.6726593217364076

Epoch: 5| Step: 7
Training loss: 0.8070614065941153
Validation loss: 2.7603057362298387

Epoch: 5| Step: 8
Training loss: 1.1543107653200047
Validation loss: 2.8137982233254317

Epoch: 5| Step: 9
Training loss: 1.4531371413513272
Validation loss: 2.6934499427254797

Epoch: 5| Step: 10
Training loss: 1.025300463390999
Validation loss: 2.8443478966897437

Epoch: 775| Step: 0
Training loss: 1.306198980621842
Validation loss: 2.6543533319311843

Epoch: 5| Step: 1
Training loss: 1.2435815534150552
Validation loss: 2.6647073799226555

Epoch: 5| Step: 2
Training loss: 1.382981198467843
Validation loss: 2.6667896391088943

Epoch: 5| Step: 3
Training loss: 1.1767210388769171
Validation loss: 2.689576371621755

Epoch: 5| Step: 4
Training loss: 1.7410021799589879
Validation loss: 2.7343709441124155

Epoch: 5| Step: 5
Training loss: 0.9794177010872965
Validation loss: 2.709402832693706

Epoch: 5| Step: 6
Training loss: 0.6032992965974885
Validation loss: 2.660703362980176

Epoch: 5| Step: 7
Training loss: 1.2831816649710956
Validation loss: 2.628109539010355

Epoch: 5| Step: 8
Training loss: 1.008341687275563
Validation loss: 2.7532091545307735

Epoch: 5| Step: 9
Training loss: 1.2415434889318446
Validation loss: 2.6889550452341515

Epoch: 5| Step: 10
Training loss: 1.3261755155308323
Validation loss: 2.76732896181146

Epoch: 776| Step: 0
Training loss: 1.0036633861981814
Validation loss: 2.7172624938560532

Epoch: 5| Step: 1
Training loss: 1.3439173483326552
Validation loss: 2.7341389778339087

Epoch: 5| Step: 2
Training loss: 1.771443460111851
Validation loss: 2.755184078026433

Epoch: 5| Step: 3
Training loss: 1.1095461646193496
Validation loss: 2.733951063444175

Epoch: 5| Step: 4
Training loss: 1.1531427749049512
Validation loss: 2.7025070674375393

Epoch: 5| Step: 5
Training loss: 1.3082200612805468
Validation loss: 2.7430082629053856

Epoch: 5| Step: 6
Training loss: 0.9383697925370794
Validation loss: 2.814154472154726

Epoch: 5| Step: 7
Training loss: 1.1487379654180274
Validation loss: 2.765848172916853

Epoch: 5| Step: 8
Training loss: 1.0951144291036967
Validation loss: 2.6817341901489544

Epoch: 5| Step: 9
Training loss: 1.0775291897389043
Validation loss: 2.6191085482260674

Epoch: 5| Step: 10
Training loss: 1.536797110068023
Validation loss: 2.7079082175879603

Epoch: 777| Step: 0
Training loss: 1.9102860545108404
Validation loss: 2.719665427918286

Epoch: 5| Step: 1
Training loss: 0.9721746516321345
Validation loss: 2.7023130960754873

Epoch: 5| Step: 2
Training loss: 0.9205287219513125
Validation loss: 2.7219520790857263

Epoch: 5| Step: 3
Training loss: 1.266768186457862
Validation loss: 2.7168240814935682

Epoch: 5| Step: 4
Training loss: 1.2722572989304095
Validation loss: 2.6816567755662137

Epoch: 5| Step: 5
Training loss: 1.041851516852584
Validation loss: 2.7085934200935182

Epoch: 5| Step: 6
Training loss: 1.053069788450523
Validation loss: 2.6752295571825764

Epoch: 5| Step: 7
Training loss: 1.1938010239806203
Validation loss: 2.660534231920311

Epoch: 5| Step: 8
Training loss: 0.9836948406455298
Validation loss: 2.7159679144837816

Epoch: 5| Step: 9
Training loss: 1.0844192319967805
Validation loss: 2.698861129798045

Epoch: 5| Step: 10
Training loss: 0.910178744975416
Validation loss: 2.777164482346126

Epoch: 778| Step: 0
Training loss: 1.268783208102392
Validation loss: 2.6860076412368676

Epoch: 5| Step: 1
Training loss: 1.106364934952845
Validation loss: 2.6815717378328414

Epoch: 5| Step: 2
Training loss: 1.0914218101402597
Validation loss: 2.6536443053125045

Epoch: 5| Step: 3
Training loss: 1.2159551216364288
Validation loss: 2.7226336798644057

Epoch: 5| Step: 4
Training loss: 0.9270525866492612
Validation loss: 2.6655791228707426

Epoch: 5| Step: 5
Training loss: 1.04438399972468
Validation loss: 2.7165288124940035

Epoch: 5| Step: 6
Training loss: 1.655134149052905
Validation loss: 2.6581224919634203

Epoch: 5| Step: 7
Training loss: 0.9932052018638903
Validation loss: 2.8230088021426516

Epoch: 5| Step: 8
Training loss: 0.9910368667870152
Validation loss: 2.6438324248015515

Epoch: 5| Step: 9
Training loss: 1.2520625264517158
Validation loss: 2.741217922663837

Epoch: 5| Step: 10
Training loss: 1.4198936658992944
Validation loss: 2.7085292709000064

Epoch: 779| Step: 0
Training loss: 1.1159049721973608
Validation loss: 2.7107987114933856

Epoch: 5| Step: 1
Training loss: 1.1421774658931314
Validation loss: 2.663555910847185

Epoch: 5| Step: 2
Training loss: 1.254705061736188
Validation loss: 2.7744174407500544

Epoch: 5| Step: 3
Training loss: 1.765747741213848
Validation loss: 2.72867704832659

Epoch: 5| Step: 4
Training loss: 1.0961633487500595
Validation loss: 2.7140378473387705

Epoch: 5| Step: 5
Training loss: 1.1144844914517211
Validation loss: 2.705961892235578

Epoch: 5| Step: 6
Training loss: 1.053062826523002
Validation loss: 2.721743845586243

Epoch: 5| Step: 7
Training loss: 1.199851052656577
Validation loss: 2.699433865588621

Epoch: 5| Step: 8
Training loss: 1.0307473200194877
Validation loss: 2.7867475639953927

Epoch: 5| Step: 9
Training loss: 1.004110590106337
Validation loss: 2.6437565655882422

Epoch: 5| Step: 10
Training loss: 1.0686239580931778
Validation loss: 2.7885386516566344

Epoch: 780| Step: 0
Training loss: 1.9063886998480786
Validation loss: 2.707959065162143

Epoch: 5| Step: 1
Training loss: 1.2993866830862961
Validation loss: 2.656783011980121

Epoch: 5| Step: 2
Training loss: 1.5845474390094976
Validation loss: 2.6822182527111456

Epoch: 5| Step: 3
Training loss: 1.2817759016056398
Validation loss: 2.6681293637448347

Epoch: 5| Step: 4
Training loss: 0.8514034577686367
Validation loss: 2.781281447454594

Epoch: 5| Step: 5
Training loss: 1.1527723646739019
Validation loss: 2.725002660766037

Epoch: 5| Step: 6
Training loss: 0.8531586972243418
Validation loss: 2.7787179144191025

Epoch: 5| Step: 7
Training loss: 1.1092968228155635
Validation loss: 2.649511881827588

Epoch: 5| Step: 8
Training loss: 0.8637634932682725
Validation loss: 2.7566734084924183

Epoch: 5| Step: 9
Training loss: 0.9734557515939177
Validation loss: 2.690668954969353

Epoch: 5| Step: 10
Training loss: 1.2918718646730747
Validation loss: 2.6934358978459936

Epoch: 781| Step: 0
Training loss: 0.9972118609736368
Validation loss: 2.677997236963538

Epoch: 5| Step: 1
Training loss: 1.1792771592060527
Validation loss: 2.7333738101430303

Epoch: 5| Step: 2
Training loss: 1.2301186684219814
Validation loss: 2.7697618941741378

Epoch: 5| Step: 3
Training loss: 1.176160073324063
Validation loss: 2.7009669418277342

Epoch: 5| Step: 4
Training loss: 1.0291799518690414
Validation loss: 2.8044440654301535

Epoch: 5| Step: 5
Training loss: 1.9477961361835878
Validation loss: 2.7118487605413426

Epoch: 5| Step: 6
Training loss: 1.0937272205705442
Validation loss: 2.7419854780268413

Epoch: 5| Step: 7
Training loss: 1.199839676637587
Validation loss: 2.713340257851642

Epoch: 5| Step: 8
Training loss: 1.0056562792724462
Validation loss: 2.6665542127627284

Epoch: 5| Step: 9
Training loss: 1.1242111937459152
Validation loss: 2.661784136684427

Epoch: 5| Step: 10
Training loss: 1.252125220886071
Validation loss: 2.7480396749028966

Epoch: 782| Step: 0
Training loss: 0.7801318750407067
Validation loss: 2.7089792297036666

Epoch: 5| Step: 1
Training loss: 1.559105351742868
Validation loss: 2.6512779099793797

Epoch: 5| Step: 2
Training loss: 1.3971841832656757
Validation loss: 2.670440019829183

Epoch: 5| Step: 3
Training loss: 1.1689603034948837
Validation loss: 2.758607278726677

Epoch: 5| Step: 4
Training loss: 1.8584115232887946
Validation loss: 2.7594251068820257

Epoch: 5| Step: 5
Training loss: 1.1610107357701773
Validation loss: 2.6936353309363197

Epoch: 5| Step: 6
Training loss: 1.0932059433523922
Validation loss: 2.7265178764798903

Epoch: 5| Step: 7
Training loss: 1.1041387638429132
Validation loss: 2.7845417999396935

Epoch: 5| Step: 8
Training loss: 1.200170183035081
Validation loss: 2.7323513266864468

Epoch: 5| Step: 9
Training loss: 0.9420200420503171
Validation loss: 2.6568931336659394

Epoch: 5| Step: 10
Training loss: 0.9297156449874138
Validation loss: 2.830599563236512

Epoch: 783| Step: 0
Training loss: 1.5796158801708533
Validation loss: 2.7436595595653777

Epoch: 5| Step: 1
Training loss: 1.123344209535358
Validation loss: 2.662109685089527

Epoch: 5| Step: 2
Training loss: 1.2113045413056618
Validation loss: 2.6381462663468533

Epoch: 5| Step: 3
Training loss: 0.8774513919115643
Validation loss: 2.7261001416318695

Epoch: 5| Step: 4
Training loss: 1.1821994437436953
Validation loss: 2.658027211705151

Epoch: 5| Step: 5
Training loss: 1.1807005618679738
Validation loss: 2.6865125780044194

Epoch: 5| Step: 6
Training loss: 1.1019182104335359
Validation loss: 2.6546698882549116

Epoch: 5| Step: 7
Training loss: 1.181062011292304
Validation loss: 2.6315921489187986

Epoch: 5| Step: 8
Training loss: 1.0673634351976538
Validation loss: 2.7281933933771025

Epoch: 5| Step: 9
Training loss: 1.14481134209749
Validation loss: 2.5989289877743986

Epoch: 5| Step: 10
Training loss: 1.2810625543947494
Validation loss: 2.7070895097305283

Epoch: 784| Step: 0
Training loss: 1.1870876399388672
Validation loss: 2.7116804309171956

Epoch: 5| Step: 1
Training loss: 1.1957714222068383
Validation loss: 2.7870061968127597

Epoch: 5| Step: 2
Training loss: 1.020444614333498
Validation loss: 2.745427920791204

Epoch: 5| Step: 3
Training loss: 0.9616712854418804
Validation loss: 2.693834631254952

Epoch: 5| Step: 4
Training loss: 1.8931071483920208
Validation loss: 2.6817056869827254

Epoch: 5| Step: 5
Training loss: 1.0524678928071938
Validation loss: 2.660646561912313

Epoch: 5| Step: 6
Training loss: 0.8551803520788797
Validation loss: 2.6998205947976195

Epoch: 5| Step: 7
Training loss: 1.0118945348313637
Validation loss: 2.7025013577136052

Epoch: 5| Step: 8
Training loss: 1.327118885196864
Validation loss: 2.7512168131259744

Epoch: 5| Step: 9
Training loss: 1.4318870759052653
Validation loss: 2.752354241561201

Epoch: 5| Step: 10
Training loss: 1.0346036767719862
Validation loss: 2.5764284107016993

Epoch: 785| Step: 0
Training loss: 0.8267605535262152
Validation loss: 2.669854372569816

Epoch: 5| Step: 1
Training loss: 0.9811775107851756
Validation loss: 2.6855483126370787

Epoch: 5| Step: 2
Training loss: 1.0934718186977352
Validation loss: 2.651239520040316

Epoch: 5| Step: 3
Training loss: 1.0476819813958531
Validation loss: 2.638035399995375

Epoch: 5| Step: 4
Training loss: 1.3310592102735201
Validation loss: 2.7661644620529904

Epoch: 5| Step: 5
Training loss: 1.950326730792059
Validation loss: 2.7014165901251053

Epoch: 5| Step: 6
Training loss: 0.9647181502534332
Validation loss: 2.6955864765725877

Epoch: 5| Step: 7
Training loss: 0.7938736135992943
Validation loss: 2.7512505000998275

Epoch: 5| Step: 8
Training loss: 1.0928787576138943
Validation loss: 2.593118401178779

Epoch: 5| Step: 9
Training loss: 1.380854411028582
Validation loss: 2.7961022212334345

Epoch: 5| Step: 10
Training loss: 0.9977508523966552
Validation loss: 2.6976158996570945

Epoch: 786| Step: 0
Training loss: 1.1204728590347726
Validation loss: 2.693533749804959

Epoch: 5| Step: 1
Training loss: 1.3486384696206477
Validation loss: 2.716621288804104

Epoch: 5| Step: 2
Training loss: 1.1090802620513152
Validation loss: 2.746813168851112

Epoch: 5| Step: 3
Training loss: 1.1450062049464382
Validation loss: 2.775307636305197

Epoch: 5| Step: 4
Training loss: 0.9203606144450354
Validation loss: 2.675446350538682

Epoch: 5| Step: 5
Training loss: 0.8386991641220453
Validation loss: 2.7654914960461605

Epoch: 5| Step: 6
Training loss: 1.063035381291729
Validation loss: 2.710249700056558

Epoch: 5| Step: 7
Training loss: 0.7617464891909304
Validation loss: 2.74016099093526

Epoch: 5| Step: 8
Training loss: 1.0839142097927648
Validation loss: 2.6669179714008724

Epoch: 5| Step: 9
Training loss: 1.8737334742208593
Validation loss: 2.676565295810134

Epoch: 5| Step: 10
Training loss: 1.2392169293332653
Validation loss: 2.6717930044591225

Epoch: 787| Step: 0
Training loss: 1.1549660022900774
Validation loss: 2.7443698906835348

Epoch: 5| Step: 1
Training loss: 1.0227024263195956
Validation loss: 2.6664162859222706

Epoch: 5| Step: 2
Training loss: 1.7215204971294251
Validation loss: 2.7842040201505465

Epoch: 5| Step: 3
Training loss: 1.0434917610183179
Validation loss: 2.736250894128001

Epoch: 5| Step: 4
Training loss: 1.4433322847170174
Validation loss: 2.7591976979483186

Epoch: 5| Step: 5
Training loss: 0.9612801413901246
Validation loss: 2.688025714788379

Epoch: 5| Step: 6
Training loss: 1.2564117972720332
Validation loss: 2.7436205645032623

Epoch: 5| Step: 7
Training loss: 1.2774794853489295
Validation loss: 2.7728925433867357

Epoch: 5| Step: 8
Training loss: 0.9707428523018364
Validation loss: 2.666702526630763

Epoch: 5| Step: 9
Training loss: 1.503548636585706
Validation loss: 2.742665263265424

Epoch: 5| Step: 10
Training loss: 1.112017801344703
Validation loss: 2.6988583579965866

Epoch: 788| Step: 0
Training loss: 1.2650005542618212
Validation loss: 2.7246123633616595

Epoch: 5| Step: 1
Training loss: 1.175749008395673
Validation loss: 2.769208865047967

Epoch: 5| Step: 2
Training loss: 1.072657668077347
Validation loss: 2.697341657804305

Epoch: 5| Step: 3
Training loss: 1.131733768779025
Validation loss: 2.7296681460417664

Epoch: 5| Step: 4
Training loss: 1.6420907149027573
Validation loss: 2.6568232825505587

Epoch: 5| Step: 5
Training loss: 1.3130979538265162
Validation loss: 2.7133937535020567

Epoch: 5| Step: 6
Training loss: 0.8665648278288695
Validation loss: 2.7555734959342626

Epoch: 5| Step: 7
Training loss: 1.1592733189497935
Validation loss: 2.733740386684161

Epoch: 5| Step: 8
Training loss: 0.9065724818545713
Validation loss: 2.6965489083340612

Epoch: 5| Step: 9
Training loss: 1.1590456800765139
Validation loss: 2.7148228099549843

Epoch: 5| Step: 10
Training loss: 0.8495162035837617
Validation loss: 2.6880386186733203

Epoch: 789| Step: 0
Training loss: 1.8929200547552076
Validation loss: 2.6711316286253997

Epoch: 5| Step: 1
Training loss: 1.3171696020247532
Validation loss: 2.6808408313732954

Epoch: 5| Step: 2
Training loss: 1.2630440097006415
Validation loss: 2.75598195143373

Epoch: 5| Step: 3
Training loss: 1.3957789633491018
Validation loss: 2.7646407659899026

Epoch: 5| Step: 4
Training loss: 0.9882513350833103
Validation loss: 2.830055018354388

Epoch: 5| Step: 5
Training loss: 0.8790511965440223
Validation loss: 2.7261150282164945

Epoch: 5| Step: 6
Training loss: 1.2645347986014797
Validation loss: 2.670026487912162

Epoch: 5| Step: 7
Training loss: 1.0077357299899676
Validation loss: 2.8100467597140124

Epoch: 5| Step: 8
Training loss: 1.0814671888131564
Validation loss: 2.6350665607526813

Epoch: 5| Step: 9
Training loss: 1.0587076498882133
Validation loss: 2.6344489394819233

Epoch: 5| Step: 10
Training loss: 1.3525239027805658
Validation loss: 2.6415879979648826

Epoch: 790| Step: 0
Training loss: 1.1488050015537226
Validation loss: 2.653510504275017

Epoch: 5| Step: 1
Training loss: 1.371706833666533
Validation loss: 2.7350799223812876

Epoch: 5| Step: 2
Training loss: 1.043650143809234
Validation loss: 2.777699308278317

Epoch: 5| Step: 3
Training loss: 1.7991707772647791
Validation loss: 2.6809219161920907

Epoch: 5| Step: 4
Training loss: 0.9241994873515996
Validation loss: 2.7419433709452803

Epoch: 5| Step: 5
Training loss: 1.1593923397772559
Validation loss: 2.680307380288514

Epoch: 5| Step: 6
Training loss: 1.0787698779700323
Validation loss: 2.6463596775504294

Epoch: 5| Step: 7
Training loss: 1.2969619078413754
Validation loss: 2.7693966429978607

Epoch: 5| Step: 8
Training loss: 0.8744415135747169
Validation loss: 2.682071733562739

Epoch: 5| Step: 9
Training loss: 1.3387793491968258
Validation loss: 2.7332420615507607

Epoch: 5| Step: 10
Training loss: 1.1425189663170432
Validation loss: 2.617387005164794

Epoch: 791| Step: 0
Training loss: 0.9050737179190759
Validation loss: 2.6843096261027344

Epoch: 5| Step: 1
Training loss: 1.2822302813160085
Validation loss: 2.6825482403557688

Epoch: 5| Step: 2
Training loss: 0.9463010615955095
Validation loss: 2.699259337223713

Epoch: 5| Step: 3
Training loss: 1.7269743691349821
Validation loss: 2.684972833550337

Epoch: 5| Step: 4
Training loss: 1.0446052998648812
Validation loss: 2.634645517420397

Epoch: 5| Step: 5
Training loss: 1.0234334232161766
Validation loss: 2.744382019601203

Epoch: 5| Step: 6
Training loss: 1.1288228779666285
Validation loss: 2.65348046707021

Epoch: 5| Step: 7
Training loss: 1.0992521583235761
Validation loss: 2.711210049852889

Epoch: 5| Step: 8
Training loss: 1.1946116368631154
Validation loss: 2.77153959547874

Epoch: 5| Step: 9
Training loss: 1.373982573269603
Validation loss: 2.714057356736338

Epoch: 5| Step: 10
Training loss: 0.7669855601755631
Validation loss: 2.7548454661842543

Epoch: 792| Step: 0
Training loss: 0.8992038941005474
Validation loss: 2.6947095570200954

Epoch: 5| Step: 1
Training loss: 1.2961146412201043
Validation loss: 2.6321706460806795

Epoch: 5| Step: 2
Training loss: 1.0323199876787523
Validation loss: 2.766258269209786

Epoch: 5| Step: 3
Training loss: 1.6643484523602692
Validation loss: 2.6917567175918737

Epoch: 5| Step: 4
Training loss: 0.6473472575968064
Validation loss: 2.7909174963685257

Epoch: 5| Step: 5
Training loss: 1.083278776898072
Validation loss: 2.5898740026079

Epoch: 5| Step: 6
Training loss: 0.9786172840663508
Validation loss: 2.7009105993035045

Epoch: 5| Step: 7
Training loss: 1.1131230827542071
Validation loss: 2.7559769375998813

Epoch: 5| Step: 8
Training loss: 1.2708023984718924
Validation loss: 2.707880548029092

Epoch: 5| Step: 9
Training loss: 1.0088910386426244
Validation loss: 2.713933415741637

Epoch: 5| Step: 10
Training loss: 1.488936712950389
Validation loss: 2.708919533331194

Epoch: 793| Step: 0
Training loss: 1.2895042356145665
Validation loss: 2.6300053736987676

Epoch: 5| Step: 1
Training loss: 1.7496709514257072
Validation loss: 2.776169241113424

Epoch: 5| Step: 2
Training loss: 1.298247840149374
Validation loss: 2.7182204112972435

Epoch: 5| Step: 3
Training loss: 1.1557188618380931
Validation loss: 2.6004493068790473

Epoch: 5| Step: 4
Training loss: 0.7053492017060964
Validation loss: 2.608157590066696

Epoch: 5| Step: 5
Training loss: 1.036815537028987
Validation loss: 2.6040892112452196

Epoch: 5| Step: 6
Training loss: 1.134227106210985
Validation loss: 2.741504888184039

Epoch: 5| Step: 7
Training loss: 1.227357837346051
Validation loss: 2.7447653746985536

Epoch: 5| Step: 8
Training loss: 1.0916616393597187
Validation loss: 2.6878681135845395

Epoch: 5| Step: 9
Training loss: 1.2336490282908879
Validation loss: 2.6636416392373556

Epoch: 5| Step: 10
Training loss: 1.046265097068234
Validation loss: 2.7032752914325724

Epoch: 794| Step: 0
Training loss: 1.3033724341824116
Validation loss: 2.7418371766242005

Epoch: 5| Step: 1
Training loss: 0.7344947879572578
Validation loss: 2.6528871176519995

Epoch: 5| Step: 2
Training loss: 1.0727723527658442
Validation loss: 2.7554053323713017

Epoch: 5| Step: 3
Training loss: 0.9273731693013745
Validation loss: 2.6919227698718

Epoch: 5| Step: 4
Training loss: 1.3669112444111564
Validation loss: 2.721045207361476

Epoch: 5| Step: 5
Training loss: 1.6350597631981947
Validation loss: 2.7561388314544737

Epoch: 5| Step: 6
Training loss: 1.404681878508287
Validation loss: 2.648883394004556

Epoch: 5| Step: 7
Training loss: 1.1662643397391068
Validation loss: 2.706514855200004

Epoch: 5| Step: 8
Training loss: 1.2981157916517951
Validation loss: 2.6889542729827833

Epoch: 5| Step: 9
Training loss: 0.9324425019442582
Validation loss: 2.7334524250147916

Epoch: 5| Step: 10
Training loss: 1.194724842299164
Validation loss: 2.7267991751390044

Epoch: 795| Step: 0
Training loss: 1.2004313845903467
Validation loss: 2.618246617395891

Epoch: 5| Step: 1
Training loss: 1.052434308772434
Validation loss: 2.6966632556131906

Epoch: 5| Step: 2
Training loss: 0.8989348320450968
Validation loss: 2.7298956145449487

Epoch: 5| Step: 3
Training loss: 0.8549612970125275
Validation loss: 2.6582975406444245

Epoch: 5| Step: 4
Training loss: 1.3522428883756785
Validation loss: 2.725243086489059

Epoch: 5| Step: 5
Training loss: 1.0268872773544602
Validation loss: 2.7646879352861746

Epoch: 5| Step: 6
Training loss: 1.21970613583151
Validation loss: 2.624197888623637

Epoch: 5| Step: 7
Training loss: 1.4077416456134175
Validation loss: 2.692103949417748

Epoch: 5| Step: 8
Training loss: 1.8870317977344766
Validation loss: 2.686735486596219

Epoch: 5| Step: 9
Training loss: 0.9711388084165453
Validation loss: 2.8098642100993043

Epoch: 5| Step: 10
Training loss: 1.0381927865878802
Validation loss: 2.7648057706272184

Epoch: 796| Step: 0
Training loss: 1.0801864486924948
Validation loss: 2.7448717527366804

Epoch: 5| Step: 1
Training loss: 1.3517055986977498
Validation loss: 2.7303596005432706

Epoch: 5| Step: 2
Training loss: 1.336906081984604
Validation loss: 2.709168508095532

Epoch: 5| Step: 3
Training loss: 1.743184988713679
Validation loss: 2.653332986127736

Epoch: 5| Step: 4
Training loss: 0.8041301760193394
Validation loss: 2.7749549662520288

Epoch: 5| Step: 5
Training loss: 1.2849437224833393
Validation loss: 2.737977876493813

Epoch: 5| Step: 6
Training loss: 1.273341497067217
Validation loss: 2.6614838990590854

Epoch: 5| Step: 7
Training loss: 0.8109701499172791
Validation loss: 2.7613314975719687

Epoch: 5| Step: 8
Training loss: 1.2937944892936952
Validation loss: 2.778771942177364

Epoch: 5| Step: 9
Training loss: 1.0386713195087716
Validation loss: 2.674329515761462

Epoch: 5| Step: 10
Training loss: 0.7995060886153602
Validation loss: 2.7036556396658007

Epoch: 797| Step: 0
Training loss: 0.9780913935241423
Validation loss: 2.75079600148854

Epoch: 5| Step: 1
Training loss: 0.8581421765791488
Validation loss: 2.730719353788035

Epoch: 5| Step: 2
Training loss: 1.3843280224547059
Validation loss: 2.820711844499703

Epoch: 5| Step: 3
Training loss: 0.82187674199489
Validation loss: 2.6511898807214016

Epoch: 5| Step: 4
Training loss: 1.8380618527437314
Validation loss: 2.6990292943595477

Epoch: 5| Step: 5
Training loss: 1.1431909205730848
Validation loss: 2.705245615010997

Epoch: 5| Step: 6
Training loss: 1.137606349626625
Validation loss: 2.684878886178017

Epoch: 5| Step: 7
Training loss: 0.9538782301528022
Validation loss: 2.7845842360013124

Epoch: 5| Step: 8
Training loss: 1.130441486317236
Validation loss: 2.708228126419788

Epoch: 5| Step: 9
Training loss: 0.9325265890324371
Validation loss: 2.719073539778313

Epoch: 5| Step: 10
Training loss: 1.4776731481934176
Validation loss: 2.6778772370063986

Epoch: 798| Step: 0
Training loss: 1.5214702718176594
Validation loss: 2.6743400920913554

Epoch: 5| Step: 1
Training loss: 0.7992907912077145
Validation loss: 2.777823726588493

Epoch: 5| Step: 2
Training loss: 0.9796606130119817
Validation loss: 2.7468173328307217

Epoch: 5| Step: 3
Training loss: 1.285138904025464
Validation loss: 2.7149582275749857

Epoch: 5| Step: 4
Training loss: 1.291233661839982
Validation loss: 2.6012908223132025

Epoch: 5| Step: 5
Training loss: 1.0274059436378888
Validation loss: 2.6920942980280156

Epoch: 5| Step: 6
Training loss: 1.03780012960163
Validation loss: 2.659485140020985

Epoch: 5| Step: 7
Training loss: 1.0615105228989583
Validation loss: 2.7151887403137405

Epoch: 5| Step: 8
Training loss: 1.7413471744146947
Validation loss: 2.8133766202780266

Epoch: 5| Step: 9
Training loss: 1.0145160195790621
Validation loss: 2.740017815341792

Epoch: 5| Step: 10
Training loss: 0.9584241734173045
Validation loss: 2.749841266909752

Epoch: 799| Step: 0
Training loss: 1.15683159506152
Validation loss: 2.7043235294056758

Epoch: 5| Step: 1
Training loss: 1.409417759485625
Validation loss: 2.7212101912336273

Epoch: 5| Step: 2
Training loss: 0.7094953392902658
Validation loss: 2.6949245768783348

Epoch: 5| Step: 3
Training loss: 1.1464932131061065
Validation loss: 2.6172282701089165

Epoch: 5| Step: 4
Training loss: 0.9997614635641157
Validation loss: 2.628487354101947

Epoch: 5| Step: 5
Training loss: 1.3932544836673433
Validation loss: 2.71592944970844

Epoch: 5| Step: 6
Training loss: 1.1202602677558962
Validation loss: 2.6690819109137727

Epoch: 5| Step: 7
Training loss: 1.8038483357209056
Validation loss: 2.7386928049715697

Epoch: 5| Step: 8
Training loss: 0.714320256896612
Validation loss: 2.6692103327696035

Epoch: 5| Step: 9
Training loss: 0.9565576432462147
Validation loss: 2.7042848914208593

Epoch: 5| Step: 10
Training loss: 1.1372408896647572
Validation loss: 2.6853363473657397

Epoch: 800| Step: 0
Training loss: 1.7272305814264624
Validation loss: 2.715305243168942

Epoch: 5| Step: 1
Training loss: 0.9473351836473926
Validation loss: 2.687902952159452

Epoch: 5| Step: 2
Training loss: 1.2250380062513382
Validation loss: 2.682562626072466

Epoch: 5| Step: 3
Training loss: 1.2258423069760098
Validation loss: 2.621727484209961

Epoch: 5| Step: 4
Training loss: 0.9322977367750498
Validation loss: 2.692520052347809

Epoch: 5| Step: 5
Training loss: 1.0902845796884504
Validation loss: 2.7201646465497524

Epoch: 5| Step: 6
Training loss: 1.2837871459222343
Validation loss: 2.7371616322412486

Epoch: 5| Step: 7
Training loss: 0.954400787754565
Validation loss: 2.6834469190370718

Epoch: 5| Step: 8
Training loss: 1.0133762994449462
Validation loss: 2.7417152768767346

Epoch: 5| Step: 9
Training loss: 1.1535484094866477
Validation loss: 2.7227749807095285

Epoch: 5| Step: 10
Training loss: 0.9508071607508641
Validation loss: 2.7159178289914925

Testing loss: 3.2314729063966157
