Epoch: 1| Step: 0
Training loss: 7.78404779960172
Validation loss: 7.0801091316061875

Epoch: 6| Step: 1
Training loss: 7.114651308717027
Validation loss: 7.077842472968766

Epoch: 6| Step: 2
Training loss: 6.925317463673146
Validation loss: 7.0763201088521885

Epoch: 6| Step: 3
Training loss: 6.715320652330985
Validation loss: 7.071878440906522

Epoch: 6| Step: 4
Training loss: 7.247359222381776
Validation loss: 7.0673905802652195

Epoch: 6| Step: 5
Training loss: 6.421707782285368
Validation loss: 7.065914442704575

Epoch: 6| Step: 6
Training loss: 7.4359955107463485
Validation loss: 7.06423730778074

Epoch: 6| Step: 7
Training loss: 7.947364264640373
Validation loss: 7.062122865960609

Epoch: 6| Step: 8
Training loss: 6.1630307725357545
Validation loss: 7.05810229039817

Epoch: 6| Step: 9
Training loss: 7.385979190238273
Validation loss: 7.053439524869455

Epoch: 6| Step: 10
Training loss: 6.606761081815166
Validation loss: 7.050538764660546

Epoch: 6| Step: 11
Training loss: 6.646352653980544
Validation loss: 7.048528042050921

Epoch: 6| Step: 12
Training loss: 6.253467055939974
Validation loss: 7.047646835706462

Epoch: 6| Step: 13
Training loss: 8.243618895997159
Validation loss: 7.042242110272455

Epoch: 2| Step: 0
Training loss: 7.056587107117845
Validation loss: 7.0437494314076865

Epoch: 6| Step: 1
Training loss: 7.261435599139417
Validation loss: 7.040421296832606

Epoch: 6| Step: 2
Training loss: 6.993101262744312
Validation loss: 7.0348410303713615

Epoch: 6| Step: 3
Training loss: 8.276168473370355
Validation loss: 7.032922470641834

Epoch: 6| Step: 4
Training loss: 6.41474433276466
Validation loss: 7.03117778125714

Epoch: 6| Step: 5
Training loss: 6.604129955618918
Validation loss: 7.029382240948155

Epoch: 6| Step: 6
Training loss: 6.389492242307049
Validation loss: 7.0257083295593885

Epoch: 6| Step: 7
Training loss: 7.075453500400389
Validation loss: 7.023714544664201

Epoch: 6| Step: 8
Training loss: 7.881326465402131
Validation loss: 7.01966857839736

Epoch: 6| Step: 9
Training loss: 5.6630669922568515
Validation loss: 7.016827820201243

Epoch: 6| Step: 10
Training loss: 6.000192003356929
Validation loss: 7.014258718417915

Epoch: 6| Step: 11
Training loss: 7.470982684720306
Validation loss: 7.0122506956225985

Epoch: 6| Step: 12
Training loss: 7.556676719108035
Validation loss: 7.009331324348008

Epoch: 6| Step: 13
Training loss: 7.065302739983418
Validation loss: 7.00817849212777

Epoch: 3| Step: 0
Training loss: 6.537680932307438
Validation loss: 7.008653542240713

Epoch: 6| Step: 1
Training loss: 6.714825002700706
Validation loss: 7.0021293026783376

Epoch: 6| Step: 2
Training loss: 6.796018489495913
Validation loss: 7.0018208738644505

Epoch: 6| Step: 3
Training loss: 8.004545827606336
Validation loss: 6.9989637173285395

Epoch: 6| Step: 4
Training loss: 8.141368165753933
Validation loss: 6.995542328657726

Epoch: 6| Step: 5
Training loss: 6.5083898537787
Validation loss: 6.992751636114021

Epoch: 6| Step: 6
Training loss: 5.86651680639349
Validation loss: 6.988640271022263

Epoch: 6| Step: 7
Training loss: 6.988704286909218
Validation loss: 6.9867536373184524

Epoch: 6| Step: 8
Training loss: 6.876147087809667
Validation loss: 6.985492028311922

Epoch: 6| Step: 9
Training loss: 6.91687354578913
Validation loss: 6.983029175151068

Epoch: 6| Step: 10
Training loss: 8.13701035393221
Validation loss: 6.979235473156501

Epoch: 6| Step: 11
Training loss: 6.160621910903278
Validation loss: 6.979048670244346

Epoch: 6| Step: 12
Training loss: 6.532220649688048
Validation loss: 6.978297464470894

Epoch: 6| Step: 13
Training loss: 7.120241148647465
Validation loss: 6.974373604315725

Epoch: 4| Step: 0
Training loss: 7.4227767235940805
Validation loss: 6.971461191699274

Epoch: 6| Step: 1
Training loss: 6.125709336915285
Validation loss: 6.967559684837084

Epoch: 6| Step: 2
Training loss: 5.907610701186846
Validation loss: 6.964438511210752

Epoch: 6| Step: 3
Training loss: 7.554588530246245
Validation loss: 6.965160144022272

Epoch: 6| Step: 4
Training loss: 7.507939269139822
Validation loss: 6.961768585650552

Epoch: 6| Step: 5
Training loss: 7.54333337172192
Validation loss: 6.959246878008647

Epoch: 6| Step: 6
Training loss: 7.382677640137323
Validation loss: 6.957241272062622

Epoch: 6| Step: 7
Training loss: 7.031667196824273
Validation loss: 6.9538714456294795

Epoch: 6| Step: 8
Training loss: 7.386429545501945
Validation loss: 6.950248067221696

Epoch: 6| Step: 9
Training loss: 6.886696593129416
Validation loss: 6.947870135703048

Epoch: 6| Step: 10
Training loss: 6.320092799797078
Validation loss: 6.9445367357691055

Epoch: 6| Step: 11
Training loss: 7.196836825761083
Validation loss: 6.941759000388977

Epoch: 6| Step: 12
Training loss: 6.251105859197285
Validation loss: 6.940450812184122

Epoch: 6| Step: 13
Training loss: 5.8515644557323165
Validation loss: 6.9382472516705525

Epoch: 5| Step: 0
Training loss: 6.968918597315915
Validation loss: 6.936260934211176

Epoch: 6| Step: 1
Training loss: 7.236716367368441
Validation loss: 6.9346313517314675

Epoch: 6| Step: 2
Training loss: 6.673810691464646
Validation loss: 6.931527122723801

Epoch: 6| Step: 3
Training loss: 5.674254703736086
Validation loss: 6.9271982723017045

Epoch: 6| Step: 4
Training loss: 6.256699900118011
Validation loss: 6.924358150201546

Epoch: 6| Step: 5
Training loss: 8.129159654868143
Validation loss: 6.921882362910877

Epoch: 6| Step: 6
Training loss: 8.159785998661075
Validation loss: 6.918157961103178

Epoch: 6| Step: 7
Training loss: 7.131343761365977
Validation loss: 6.915118232309286

Epoch: 6| Step: 8
Training loss: 7.149705317900347
Validation loss: 6.9134160703606495

Epoch: 6| Step: 9
Training loss: 6.156241944593397
Validation loss: 6.912220487180308

Epoch: 6| Step: 10
Training loss: 6.672972684877783
Validation loss: 6.907765856289592

Epoch: 6| Step: 11
Training loss: 6.610432280978775
Validation loss: 6.905535409522047

Epoch: 6| Step: 12
Training loss: 6.660652817815432
Validation loss: 6.899529209991429

Epoch: 6| Step: 13
Training loss: 6.6710055854601285
Validation loss: 6.897897734826514

Epoch: 6| Step: 0
Training loss: 6.971488106806167
Validation loss: 6.893939266303383

Epoch: 6| Step: 1
Training loss: 6.770993963439171
Validation loss: 6.890607379802161

Epoch: 6| Step: 2
Training loss: 7.219862286635963
Validation loss: 6.884286786639875

Epoch: 6| Step: 3
Training loss: 6.773687549450308
Validation loss: 6.881301083529338

Epoch: 6| Step: 4
Training loss: 7.328783473381311
Validation loss: 6.879234672889933

Epoch: 6| Step: 5
Training loss: 5.722070282500128
Validation loss: 6.875319216002427

Epoch: 6| Step: 6
Training loss: 6.14664604718659
Validation loss: 6.874129949351827

Epoch: 6| Step: 7
Training loss: 7.284254248365716
Validation loss: 6.870469104741258

Epoch: 6| Step: 8
Training loss: 6.557524620646927
Validation loss: 6.860036142713783

Epoch: 6| Step: 9
Training loss: 7.718900980225702
Validation loss: 6.862386366462253

Epoch: 6| Step: 10
Training loss: 6.65922028797291
Validation loss: 6.857094554870169

Epoch: 6| Step: 11
Training loss: 6.997243883598222
Validation loss: 6.8528141477994104

Epoch: 6| Step: 12
Training loss: 6.291935727595707
Validation loss: 6.845227836999154

Epoch: 6| Step: 13
Training loss: 7.613027710311368
Validation loss: 6.844263440827456

Epoch: 7| Step: 0
Training loss: 6.438924391111696
Validation loss: 6.840177418556427

Epoch: 6| Step: 1
Training loss: 6.681695433310725
Validation loss: 6.836864133504475

Epoch: 6| Step: 2
Training loss: 7.6223625249279365
Validation loss: 6.831793644898517

Epoch: 6| Step: 3
Training loss: 7.734126416459796
Validation loss: 6.828556030572651

Epoch: 6| Step: 4
Training loss: 6.147655083436476
Validation loss: 6.826124193670289

Epoch: 6| Step: 5
Training loss: 6.388089672722828
Validation loss: 6.818482762043953

Epoch: 6| Step: 6
Training loss: 6.59982583943242
Validation loss: 6.813789500775558

Epoch: 6| Step: 7
Training loss: 6.837422550746091
Validation loss: 6.80876227074811

Epoch: 6| Step: 8
Training loss: 6.7381255643246565
Validation loss: 6.80657915436078

Epoch: 6| Step: 9
Training loss: 7.647950699523615
Validation loss: 6.801090641856334

Epoch: 6| Step: 10
Training loss: 5.881292017463317
Validation loss: 6.796491093036842

Epoch: 6| Step: 11
Training loss: 6.8181341828502875
Validation loss: 6.793395701516203

Epoch: 6| Step: 12
Training loss: 6.464182249955869
Validation loss: 6.7847330210271934

Epoch: 6| Step: 13
Training loss: 7.025733513056439
Validation loss: 6.782437494210063

Epoch: 8| Step: 0
Training loss: 7.0436882713612
Validation loss: 6.777435534935756

Epoch: 6| Step: 1
Training loss: 7.050665468232192
Validation loss: 6.772287282018493

Epoch: 6| Step: 2
Training loss: 8.307407281882254
Validation loss: 6.766103882206124

Epoch: 6| Step: 3
Training loss: 6.076272638086879
Validation loss: 6.7646457839082546

Epoch: 6| Step: 4
Training loss: 6.267926561579009
Validation loss: 6.761445378191609

Epoch: 6| Step: 5
Training loss: 6.776006543603325
Validation loss: 6.7534090318605795

Epoch: 6| Step: 6
Training loss: 7.358658352762788
Validation loss: 6.749272400332333

Epoch: 6| Step: 7
Training loss: 5.63734268679485
Validation loss: 6.7428953942979755

Epoch: 6| Step: 8
Training loss: 6.411907396205869
Validation loss: 6.7396588460507125

Epoch: 6| Step: 9
Training loss: 6.145415245533784
Validation loss: 6.734615950785782

Epoch: 6| Step: 10
Training loss: 7.157293118742424
Validation loss: 6.725932814375345

Epoch: 6| Step: 11
Training loss: 6.793301750212013
Validation loss: 6.724144160532366

Epoch: 6| Step: 12
Training loss: 5.8648633150399645
Validation loss: 6.716200765181921

Epoch: 6| Step: 13
Training loss: 7.100167350408622
Validation loss: 6.716470225622964

Epoch: 9| Step: 0
Training loss: 4.977723852974342
Validation loss: 6.710385907834301

Epoch: 6| Step: 1
Training loss: 6.511681257390564
Validation loss: 6.703066790165197

Epoch: 6| Step: 2
Training loss: 5.984983726995617
Validation loss: 6.7014304831074005

Epoch: 6| Step: 3
Training loss: 6.0406556785345185
Validation loss: 6.6932492319410795

Epoch: 6| Step: 4
Training loss: 7.0523360041361025
Validation loss: 6.690540627230256

Epoch: 6| Step: 5
Training loss: 6.635799315082458
Validation loss: 6.680929779783966

Epoch: 6| Step: 6
Training loss: 6.209345314788126
Validation loss: 6.6745577112723655

Epoch: 6| Step: 7
Training loss: 5.438398615805441
Validation loss: 6.66725836660906

Epoch: 6| Step: 8
Training loss: 7.195872331641331
Validation loss: 6.666073703031835

Epoch: 6| Step: 9
Training loss: 6.858991260265495
Validation loss: 6.656046604914073

Epoch: 6| Step: 10
Training loss: 7.7519646892235485
Validation loss: 6.658120939561479

Epoch: 6| Step: 11
Training loss: 7.80177095311589
Validation loss: 6.650331833312282

Epoch: 6| Step: 12
Training loss: 7.204745890195237
Validation loss: 6.64181573431114

Epoch: 6| Step: 13
Training loss: 7.1836638454981445
Validation loss: 6.638369335063662

Epoch: 10| Step: 0
Training loss: 5.976263779299373
Validation loss: 6.629054309678652

Epoch: 6| Step: 1
Training loss: 5.775546833256962
Validation loss: 6.624523923535121

Epoch: 6| Step: 2
Training loss: 7.003317183207078
Validation loss: 6.620629331424194

Epoch: 6| Step: 3
Training loss: 6.100441725949768
Validation loss: 6.613572511636626

Epoch: 6| Step: 4
Training loss: 6.925939602232992
Validation loss: 6.604224324876407

Epoch: 6| Step: 5
Training loss: 6.8300524332873955
Validation loss: 6.598649464832292

Epoch: 6| Step: 6
Training loss: 6.708164694741576
Validation loss: 6.590584662408758

Epoch: 6| Step: 7
Training loss: 8.12072265716601
Validation loss: 6.584506578161214

Epoch: 6| Step: 8
Training loss: 6.7989925199171
Validation loss: 6.579523763409829

Epoch: 6| Step: 9
Training loss: 5.246533657328472
Validation loss: 6.5751734962376265

Epoch: 6| Step: 10
Training loss: 6.423597118832124
Validation loss: 6.5646262603968415

Epoch: 6| Step: 11
Training loss: 5.89949319246819
Validation loss: 6.563346896433502

Epoch: 6| Step: 12
Training loss: 6.8883271483953425
Validation loss: 6.554261376636987

Epoch: 6| Step: 13
Training loss: 7.184558034110923
Validation loss: 6.546012735291214

Epoch: 11| Step: 0
Training loss: 6.941847804874788
Validation loss: 6.54212443208791

Epoch: 6| Step: 1
Training loss: 5.828514106586157
Validation loss: 6.531620486738538

Epoch: 6| Step: 2
Training loss: 6.416807230941451
Validation loss: 6.530279755644687

Epoch: 6| Step: 3
Training loss: 6.3388304026865585
Validation loss: 6.516105964020377

Epoch: 6| Step: 4
Training loss: 5.654581234753789
Validation loss: 6.5106552890157365

Epoch: 6| Step: 5
Training loss: 6.391053873235283
Validation loss: 6.505918655767977

Epoch: 6| Step: 6
Training loss: 6.947562403609685
Validation loss: 6.501407019805285

Epoch: 6| Step: 7
Training loss: 7.870384195685451
Validation loss: 6.496679507022163

Epoch: 6| Step: 8
Training loss: 7.427861997243733
Validation loss: 6.481771696084354

Epoch: 6| Step: 9
Training loss: 6.0722329576557765
Validation loss: 6.482101224825075

Epoch: 6| Step: 10
Training loss: 6.519658804549083
Validation loss: 6.471110968011319

Epoch: 6| Step: 11
Training loss: 6.793271988631357
Validation loss: 6.459440050624532

Epoch: 6| Step: 12
Training loss: 5.82970090121751
Validation loss: 6.457061970586327

Epoch: 6| Step: 13
Training loss: 4.0914150888414165
Validation loss: 6.438494383993586

Epoch: 12| Step: 0
Training loss: 6.282857660692424
Validation loss: 6.4311839746446635

Epoch: 6| Step: 1
Training loss: 6.486006124855276
Validation loss: 6.4314661545893985

Epoch: 6| Step: 2
Training loss: 7.943986540123177
Validation loss: 6.4202559550759215

Epoch: 6| Step: 3
Training loss: 6.644007640303709
Validation loss: 6.412368475367088

Epoch: 6| Step: 4
Training loss: 7.104604340287448
Validation loss: 6.40165155876593

Epoch: 6| Step: 5
Training loss: 4.839602164950156
Validation loss: 6.392019829327563

Epoch: 6| Step: 6
Training loss: 6.38658644979561
Validation loss: 6.389818040441273

Epoch: 6| Step: 7
Training loss: 7.825734152189937
Validation loss: 6.370950463467428

Epoch: 6| Step: 8
Training loss: 6.329813564742985
Validation loss: 6.364050962656505

Epoch: 6| Step: 9
Training loss: 5.898927701070843
Validation loss: 6.358243209997302

Epoch: 6| Step: 10
Training loss: 5.461645601612421
Validation loss: 6.34879288637056

Epoch: 6| Step: 11
Training loss: 5.696144660677196
Validation loss: 6.337515489119566

Epoch: 6| Step: 12
Training loss: 5.370365540123493
Validation loss: 6.330209603971545

Epoch: 6| Step: 13
Training loss: 5.985486278489847
Validation loss: 6.316053798779312

Epoch: 13| Step: 0
Training loss: 6.27056492160277
Validation loss: 6.313468005217996

Epoch: 6| Step: 1
Training loss: 5.454570239906642
Validation loss: 6.303803787646322

Epoch: 6| Step: 2
Training loss: 6.31214163490039
Validation loss: 6.295904238357182

Epoch: 6| Step: 3
Training loss: 5.763571603562719
Validation loss: 6.289557525244105

Epoch: 6| Step: 4
Training loss: 6.93289636677707
Validation loss: 6.277949927077429

Epoch: 6| Step: 5
Training loss: 7.188371688394916
Validation loss: 6.265629432015248

Epoch: 6| Step: 6
Training loss: 6.386623183535769
Validation loss: 6.258009820379189

Epoch: 6| Step: 7
Training loss: 7.045345030350159
Validation loss: 6.2388919094774575

Epoch: 6| Step: 8
Training loss: 5.495146951142293
Validation loss: 6.232976911663126

Epoch: 6| Step: 9
Training loss: 5.328989266471912
Validation loss: 6.227538045694995

Epoch: 6| Step: 10
Training loss: 5.885996166045236
Validation loss: 6.219541685108283

Epoch: 6| Step: 11
Training loss: 6.078194978208188
Validation loss: 6.205491671445415

Epoch: 6| Step: 12
Training loss: 6.829366540534393
Validation loss: 6.1953758082680075

Epoch: 6| Step: 13
Training loss: 6.011323099086534
Validation loss: 6.184355107986231

Epoch: 14| Step: 0
Training loss: 6.114762762275902
Validation loss: 6.170790524245713

Epoch: 6| Step: 1
Training loss: 6.723572601514171
Validation loss: 6.16806891788369

Epoch: 6| Step: 2
Training loss: 7.094875968940432
Validation loss: 6.14959510679594

Epoch: 6| Step: 3
Training loss: 5.778215591438466
Validation loss: 6.143658417273549

Epoch: 6| Step: 4
Training loss: 5.544613315318414
Validation loss: 6.121810012073184

Epoch: 6| Step: 5
Training loss: 6.098555484522768
Validation loss: 6.1247073838815

Epoch: 6| Step: 6
Training loss: 5.997205083289645
Validation loss: 6.1069495951429085

Epoch: 6| Step: 7
Training loss: 5.455475308893559
Validation loss: 6.095576567204672

Epoch: 6| Step: 8
Training loss: 5.59900201351663
Validation loss: 6.088319304812415

Epoch: 6| Step: 9
Training loss: 5.760201733553302
Validation loss: 6.071315758335144

Epoch: 6| Step: 10
Training loss: 5.4476985656766646
Validation loss: 6.0625833011507675

Epoch: 6| Step: 11
Training loss: 7.06444934510543
Validation loss: 6.052401031321898

Epoch: 6| Step: 12
Training loss: 6.632677919350218
Validation loss: 6.04193209134756

Epoch: 6| Step: 13
Training loss: 5.282632500087569
Validation loss: 6.0182550394536305

Epoch: 15| Step: 0
Training loss: 5.252131801302396
Validation loss: 6.004752450936752

Epoch: 6| Step: 1
Training loss: 5.898409043805531
Validation loss: 5.998447983157203

Epoch: 6| Step: 2
Training loss: 5.321667110842527
Validation loss: 5.979767262594816

Epoch: 6| Step: 3
Training loss: 6.800455066937186
Validation loss: 5.963581520940071

Epoch: 6| Step: 4
Training loss: 5.9638971703080035
Validation loss: 5.960552158984827

Epoch: 6| Step: 5
Training loss: 4.419311211543339
Validation loss: 5.9416920809448275

Epoch: 6| Step: 6
Training loss: 6.788089801039218
Validation loss: 5.92733425648248

Epoch: 6| Step: 7
Training loss: 6.4844291225150945
Validation loss: 5.916503291609245

Epoch: 6| Step: 8
Training loss: 6.792222950002382
Validation loss: 5.900137343423627

Epoch: 6| Step: 9
Training loss: 5.420500391422198
Validation loss: 5.888856058783151

Epoch: 6| Step: 10
Training loss: 6.030143359553533
Validation loss: 5.86718541314836

Epoch: 6| Step: 11
Training loss: 4.965921808666548
Validation loss: 5.866666110076952

Epoch: 6| Step: 12
Training loss: 6.007328326454795
Validation loss: 5.8443021401034

Epoch: 6| Step: 13
Training loss: 6.3947543581267645
Validation loss: 5.825441520330297

Epoch: 16| Step: 0
Training loss: 6.2044119857065345
Validation loss: 5.815717852833702

Epoch: 6| Step: 1
Training loss: 5.205238623229088
Validation loss: 5.797787966494429

Epoch: 6| Step: 2
Training loss: 5.169527656331398
Validation loss: 5.784171499522935

Epoch: 6| Step: 3
Training loss: 5.164804840979972
Validation loss: 5.767626421488505

Epoch: 6| Step: 4
Training loss: 5.683046043197394
Validation loss: 5.754526055676243

Epoch: 6| Step: 5
Training loss: 5.714128137868153
Validation loss: 5.734141258717104

Epoch: 6| Step: 6
Training loss: 4.782315802369575
Validation loss: 5.723599322585922

Epoch: 6| Step: 7
Training loss: 4.740156112546662
Validation loss: 5.721468185287987

Epoch: 6| Step: 8
Training loss: 5.732757257011871
Validation loss: 5.695472254897456

Epoch: 6| Step: 9
Training loss: 5.745029125222796
Validation loss: 5.686105845081383

Epoch: 6| Step: 10
Training loss: 5.847839556453934
Validation loss: 5.660461982324851

Epoch: 6| Step: 11
Training loss: 5.994084621154146
Validation loss: 5.646819108051419

Epoch: 6| Step: 12
Training loss: 6.913273756652765
Validation loss: 5.62384544382502

Epoch: 6| Step: 13
Training loss: 7.242115600624084
Validation loss: 5.6084560939930945

Epoch: 17| Step: 0
Training loss: 5.092337383207643
Validation loss: 5.593326739807557

Epoch: 6| Step: 1
Training loss: 5.712953391749212
Validation loss: 5.565979899018287

Epoch: 6| Step: 2
Training loss: 6.031313248534943
Validation loss: 5.546501688546713

Epoch: 6| Step: 3
Training loss: 4.553925491373508
Validation loss: 5.533955360100235

Epoch: 6| Step: 4
Training loss: 5.262959062936414
Validation loss: 5.512103410204283

Epoch: 6| Step: 5
Training loss: 6.138723763402242
Validation loss: 5.488225596155994

Epoch: 6| Step: 6
Training loss: 5.972414818943109
Validation loss: 5.473096792048864

Epoch: 6| Step: 7
Training loss: 4.782978618021328
Validation loss: 5.44899813732928

Epoch: 6| Step: 8
Training loss: 4.961843236707914
Validation loss: 5.428543425679062

Epoch: 6| Step: 9
Training loss: 6.079693824688306
Validation loss: 5.4239360630451

Epoch: 6| Step: 10
Training loss: 5.065781648203502
Validation loss: 5.391249156531566

Epoch: 6| Step: 11
Training loss: 5.596391618856862
Validation loss: 5.382246748467553

Epoch: 6| Step: 12
Training loss: 4.952916859967764
Validation loss: 5.353839053934587

Epoch: 6| Step: 13
Training loss: 6.551117244103947
Validation loss: 5.334954583849605

Epoch: 18| Step: 0
Training loss: 4.701441060986169
Validation loss: 5.32247353809887

Epoch: 6| Step: 1
Training loss: 5.72553521865328
Validation loss: 5.292313517880191

Epoch: 6| Step: 2
Training loss: 5.4290507649921915
Validation loss: 5.260494018232903

Epoch: 6| Step: 3
Training loss: 4.394259106156692
Validation loss: 5.245874732528232

Epoch: 6| Step: 4
Training loss: 4.913641737252555
Validation loss: 5.21731195648085

Epoch: 6| Step: 5
Training loss: 5.197674803626889
Validation loss: 5.199536505931283

Epoch: 6| Step: 6
Training loss: 6.136948122901447
Validation loss: 5.170886636872939

Epoch: 6| Step: 7
Training loss: 5.254224258498466
Validation loss: 5.153262135622847

Epoch: 6| Step: 8
Training loss: 5.13697198163828
Validation loss: 5.133165834653611

Epoch: 6| Step: 9
Training loss: 5.356822660050495
Validation loss: 5.102361023262747

Epoch: 6| Step: 10
Training loss: 6.462383288393941
Validation loss: 5.075966257253068

Epoch: 6| Step: 11
Training loss: 4.476857759814503
Validation loss: 5.051651090401836

Epoch: 6| Step: 12
Training loss: 4.386111291283144
Validation loss: 5.037977893809391

Epoch: 6| Step: 13
Training loss: 3.774039084300355
Validation loss: 5.021632064310713

Epoch: 19| Step: 0
Training loss: 4.048984522727051
Validation loss: 4.993637331216325

Epoch: 6| Step: 1
Training loss: 4.950766787237732
Validation loss: 4.976374149903516

Epoch: 6| Step: 2
Training loss: 4.738966726359758
Validation loss: 4.952701309160354

Epoch: 6| Step: 3
Training loss: 4.282864231491657
Validation loss: 4.918120131663715

Epoch: 6| Step: 4
Training loss: 5.003545838955052
Validation loss: 4.89788973874474

Epoch: 6| Step: 5
Training loss: 4.468540853661276
Validation loss: 4.874797388772279

Epoch: 6| Step: 6
Training loss: 5.27279039721835
Validation loss: 4.832951136333922

Epoch: 6| Step: 7
Training loss: 5.187539341788882
Validation loss: 4.817461488137511

Epoch: 6| Step: 8
Training loss: 5.112130358327838
Validation loss: 4.786817579378673

Epoch: 6| Step: 9
Training loss: 5.089381491923838
Validation loss: 4.770078640294264

Epoch: 6| Step: 10
Training loss: 5.225600446304143
Validation loss: 4.728434552046963

Epoch: 6| Step: 11
Training loss: 4.830800916716424
Validation loss: 4.709531580220187

Epoch: 6| Step: 12
Training loss: 4.651663550322658
Validation loss: 4.672148994974006

Epoch: 6| Step: 13
Training loss: 4.906720181429014
Validation loss: 4.6380973664462015

Epoch: 20| Step: 0
Training loss: 5.391663912851533
Validation loss: 4.630564430029611

Epoch: 6| Step: 1
Training loss: 4.694550768208094
Validation loss: 4.591356627400836

Epoch: 6| Step: 2
Training loss: 4.3761392472479335
Validation loss: 4.574706926736425

Epoch: 6| Step: 3
Training loss: 4.89793868011932
Validation loss: 4.545039490481356

Epoch: 6| Step: 4
Training loss: 4.3365990486317445
Validation loss: 4.524113568526552

Epoch: 6| Step: 5
Training loss: 3.9576676996958473
Validation loss: 4.486284215792971

Epoch: 6| Step: 6
Training loss: 4.395885425036001
Validation loss: 4.475568614679878

Epoch: 6| Step: 7
Training loss: 4.7994749497305245
Validation loss: 4.436690628023911

Epoch: 6| Step: 8
Training loss: 4.74080410281418
Validation loss: 4.408372639900453

Epoch: 6| Step: 9
Training loss: 3.773549206582836
Validation loss: 4.371092628614415

Epoch: 6| Step: 10
Training loss: 4.108815434291408
Validation loss: 4.343356095982358

Epoch: 6| Step: 11
Training loss: 4.8760312285702385
Validation loss: 4.31908314357596

Epoch: 6| Step: 12
Training loss: 3.8805960578840635
Validation loss: 4.279214800270096

Epoch: 6| Step: 13
Training loss: 4.054178724176263
Validation loss: 4.254339915774897

Epoch: 21| Step: 0
Training loss: 4.714474793973111
Validation loss: 4.23338085882982

Epoch: 6| Step: 1
Training loss: 4.445169188430237
Validation loss: 4.19362194471632

Epoch: 6| Step: 2
Training loss: 3.168987293876389
Validation loss: 4.158427428397667

Epoch: 6| Step: 3
Training loss: 4.5928713418825415
Validation loss: 4.139920453934303

Epoch: 6| Step: 4
Training loss: 3.78197188619395
Validation loss: 4.115131830199459

Epoch: 6| Step: 5
Training loss: 3.877221239941955
Validation loss: 4.044973163688863

Epoch: 6| Step: 6
Training loss: 5.328390970611425
Validation loss: 4.04686190454611

Epoch: 6| Step: 7
Training loss: 3.459085283148386
Validation loss: 4.009157227805588

Epoch: 6| Step: 8
Training loss: 4.8969609470286395
Validation loss: 3.979063467706126

Epoch: 6| Step: 9
Training loss: 3.584234493997147
Validation loss: 3.9372713250791147

Epoch: 6| Step: 10
Training loss: 3.1477661931655496
Validation loss: 3.924719444057313

Epoch: 6| Step: 11
Training loss: 4.295715841517506
Validation loss: 3.890805851686184

Epoch: 6| Step: 12
Training loss: 3.5434934654428574
Validation loss: 3.8578687072127353

Epoch: 6| Step: 13
Training loss: 4.549067542137585
Validation loss: 3.852357089141807

Epoch: 22| Step: 0
Training loss: 3.762556543273869
Validation loss: 3.819720502903514

Epoch: 6| Step: 1
Training loss: 3.455117457776753
Validation loss: 3.778080398181084

Epoch: 6| Step: 2
Training loss: 4.054608941465612
Validation loss: 3.774326900481909

Epoch: 6| Step: 3
Training loss: 3.063077444015993
Validation loss: 3.735557393335873

Epoch: 6| Step: 4
Training loss: 3.408969038894617
Validation loss: 3.6676002742045433

Epoch: 6| Step: 5
Training loss: 4.107829568449467
Validation loss: 3.6440909295469073

Epoch: 6| Step: 6
Training loss: 3.305087018043304
Validation loss: 3.631505851563456

Epoch: 6| Step: 7
Training loss: 3.749469338063406
Validation loss: 3.6221217198469633

Epoch: 6| Step: 8
Training loss: 3.477517397608729
Validation loss: 3.590461426887642

Epoch: 6| Step: 9
Training loss: 4.172109761579973
Validation loss: 3.554879273446949

Epoch: 6| Step: 10
Training loss: 3.739939864792045
Validation loss: 3.5362868291523046

Epoch: 6| Step: 11
Training loss: 4.461215623513118
Validation loss: 3.5100898613680678

Epoch: 6| Step: 12
Training loss: 3.6442768952640616
Validation loss: 3.4829678848097125

Epoch: 6| Step: 13
Training loss: 3.288873590041425
Validation loss: 3.4704397088660683

Epoch: 23| Step: 0
Training loss: 4.120199010542405
Validation loss: 3.451560850386335

Epoch: 6| Step: 1
Training loss: 2.7214244097294147
Validation loss: 3.394021950345788

Epoch: 6| Step: 2
Training loss: 2.9547552221032434
Validation loss: 3.365230139380927

Epoch: 6| Step: 3
Training loss: 2.590202387262899
Validation loss: 3.3266888511045094

Epoch: 6| Step: 4
Training loss: 2.947102374693045
Validation loss: 3.3162037039088363

Epoch: 6| Step: 5
Training loss: 3.4804703940442243
Validation loss: 3.288440726929377

Epoch: 6| Step: 6
Training loss: 4.3502837516054536
Validation loss: 3.2719144558241786

Epoch: 6| Step: 7
Training loss: 3.2639816018502303
Validation loss: 3.2712540636462104

Epoch: 6| Step: 8
Training loss: 3.486712573997093
Validation loss: 3.214950841036241

Epoch: 6| Step: 9
Training loss: 3.7539564242468297
Validation loss: 3.198804786469192

Epoch: 6| Step: 10
Training loss: 3.822393369416162
Validation loss: 3.195924328613978

Epoch: 6| Step: 11
Training loss: 2.888519510064277
Validation loss: 3.149857506407692

Epoch: 6| Step: 12
Training loss: 3.453007622704597
Validation loss: 3.1578878236604826

Epoch: 6| Step: 13
Training loss: 3.2205432229863096
Validation loss: 3.1135195218158485

Epoch: 24| Step: 0
Training loss: 3.053803845374714
Validation loss: 3.1137649235148137

Epoch: 6| Step: 1
Training loss: 3.2164697069603276
Validation loss: 3.0836005129760857

Epoch: 6| Step: 2
Training loss: 3.323276193396025
Validation loss: 3.0589584304795663

Epoch: 6| Step: 3
Training loss: 3.604521687980403
Validation loss: 3.0322144613390614

Epoch: 6| Step: 4
Training loss: 2.944761675014098
Validation loss: 3.04249900749435

Epoch: 6| Step: 5
Training loss: 4.234128149515959
Validation loss: 2.9940129214668105

Epoch: 6| Step: 6
Training loss: 2.6065268133977026
Validation loss: 2.9813182114173915

Epoch: 6| Step: 7
Training loss: 2.50476764020068
Validation loss: 2.96591482568639

Epoch: 6| Step: 8
Training loss: 2.9900753843570875
Validation loss: 2.942866394403678

Epoch: 6| Step: 9
Training loss: 3.5238312968510557
Validation loss: 2.92489043238197

Epoch: 6| Step: 10
Training loss: 2.816699051153546
Validation loss: 2.9356377763664514

Epoch: 6| Step: 11
Training loss: 3.1195723128010546
Validation loss: 2.921584486852027

Epoch: 6| Step: 12
Training loss: 3.579851025726356
Validation loss: 2.8768837924615545

Epoch: 6| Step: 13
Training loss: 2.573046033646866
Validation loss: 2.9161515063679304

Epoch: 25| Step: 0
Training loss: 3.0995235323061086
Validation loss: 2.872607164079215

Epoch: 6| Step: 1
Training loss: 2.931903946733019
Validation loss: 2.871320344846603

Epoch: 6| Step: 2
Training loss: 3.3257595485403075
Validation loss: 2.857508149853186

Epoch: 6| Step: 3
Training loss: 3.7238835396180403
Validation loss: 2.8571470319919587

Epoch: 6| Step: 4
Training loss: 2.6091975534374106
Validation loss: 2.807633034339044

Epoch: 6| Step: 5
Training loss: 3.557966861718489
Validation loss: 2.8275109631074424

Epoch: 6| Step: 6
Training loss: 3.7544160907516786
Validation loss: 2.8121489329660956

Epoch: 6| Step: 7
Training loss: 2.5753241844176027
Validation loss: 2.7950003097369347

Epoch: 6| Step: 8
Training loss: 1.9063538069679795
Validation loss: 2.788217109140551

Epoch: 6| Step: 9
Training loss: 3.2401955241793834
Validation loss: 2.7688903525244086

Epoch: 6| Step: 10
Training loss: 3.297873250965105
Validation loss: 2.8074626517048573

Epoch: 6| Step: 11
Training loss: 3.207920708482618
Validation loss: 2.7744001248649597

Epoch: 6| Step: 12
Training loss: 2.8327289011382204
Validation loss: 2.7596152060194328

Epoch: 6| Step: 13
Training loss: 1.8441074477437187
Validation loss: 2.7423089459220895

Epoch: 26| Step: 0
Training loss: 3.7133467713620236
Validation loss: 2.7442295952661313

Epoch: 6| Step: 1
Training loss: 2.153849938410274
Validation loss: 2.743588555023209

Epoch: 6| Step: 2
Training loss: 3.12860357413602
Validation loss: 2.7460310551936638

Epoch: 6| Step: 3
Training loss: 2.2137272895324425
Validation loss: 2.7469514037206744

Epoch: 6| Step: 4
Training loss: 2.487803271031784
Validation loss: 2.745640262393373

Epoch: 6| Step: 5
Training loss: 3.1726327376256465
Validation loss: 2.7319542876904106

Epoch: 6| Step: 6
Training loss: 3.0578188249447553
Validation loss: 2.706954654052159

Epoch: 6| Step: 7
Training loss: 3.7997327810997015
Validation loss: 2.736942586104739

Epoch: 6| Step: 8
Training loss: 2.8585203800966217
Validation loss: 2.714467471246491

Epoch: 6| Step: 9
Training loss: 3.339334870771482
Validation loss: 2.7158162553333196

Epoch: 6| Step: 10
Training loss: 2.7382210848697452
Validation loss: 2.733296896291217

Epoch: 6| Step: 11
Training loss: 3.8235502350356674
Validation loss: 2.7140356228391465

Epoch: 6| Step: 12
Training loss: 2.9714377032391166
Validation loss: 2.727522988115606

Epoch: 6| Step: 13
Training loss: 1.354286227694662
Validation loss: 2.702735059501374

Epoch: 27| Step: 0
Training loss: 3.1798529054701956
Validation loss: 2.741270819107337

Epoch: 6| Step: 1
Training loss: 2.7578170819555154
Validation loss: 2.6814358014931194

Epoch: 6| Step: 2
Training loss: 2.864628203069517
Validation loss: 2.6943517512601667

Epoch: 6| Step: 3
Training loss: 3.353533114352691
Validation loss: 2.7171164029458756

Epoch: 6| Step: 4
Training loss: 2.771841014150532
Validation loss: 2.7039165799519176

Epoch: 6| Step: 5
Training loss: 3.17545601280859
Validation loss: 2.7016863390070367

Epoch: 6| Step: 6
Training loss: 3.025095876640311
Validation loss: 2.6980534842428976

Epoch: 6| Step: 7
Training loss: 2.562570989602378
Validation loss: 2.7045462942365353

Epoch: 6| Step: 8
Training loss: 3.0843517236884517
Validation loss: 2.70365461180303

Epoch: 6| Step: 9
Training loss: 3.2385446696708713
Validation loss: 2.6770728007197535

Epoch: 6| Step: 10
Training loss: 3.557962707109661
Validation loss: 2.6736069449676525

Epoch: 6| Step: 11
Training loss: 2.445671274598947
Validation loss: 2.7022076364299688

Epoch: 6| Step: 12
Training loss: 2.759859616676139
Validation loss: 2.652844211943623

Epoch: 6| Step: 13
Training loss: 3.4736212815207823
Validation loss: 2.684102554474295

Epoch: 28| Step: 0
Training loss: 3.424409389389314
Validation loss: 2.697446510308988

Epoch: 6| Step: 1
Training loss: 3.2267136803924723
Validation loss: 2.664888627180963

Epoch: 6| Step: 2
Training loss: 2.704028557383954
Validation loss: 2.663490672610743

Epoch: 6| Step: 3
Training loss: 2.9684921955804713
Validation loss: 2.698808190557874

Epoch: 6| Step: 4
Training loss: 2.9094261943439075
Validation loss: 2.684504857258312

Epoch: 6| Step: 5
Training loss: 3.246199219386919
Validation loss: 2.7016272852267957

Epoch: 6| Step: 6
Training loss: 3.2476727883269065
Validation loss: 2.717410318925165

Epoch: 6| Step: 7
Training loss: 3.23652820509689
Validation loss: 2.6699122317630053

Epoch: 6| Step: 8
Training loss: 3.0586586040378365
Validation loss: 2.668202621848259

Epoch: 6| Step: 9
Training loss: 2.9566037311184887
Validation loss: 2.6795505295064928

Epoch: 6| Step: 10
Training loss: 2.5622514743776494
Validation loss: 2.6835079874094356

Epoch: 6| Step: 11
Training loss: 2.522583052115783
Validation loss: 2.6552436278209623

Epoch: 6| Step: 12
Training loss: 3.2677564464006745
Validation loss: 2.6764661596957207

Epoch: 6| Step: 13
Training loss: 1.9081494607866327
Validation loss: 2.682613068649322

Epoch: 29| Step: 0
Training loss: 2.5905542564166133
Validation loss: 2.681508711364939

Epoch: 6| Step: 1
Training loss: 2.4173849507267144
Validation loss: 2.6929649331842636

Epoch: 6| Step: 2
Training loss: 2.9383178546373045
Validation loss: 2.660823827700814

Epoch: 6| Step: 3
Training loss: 2.867145922616627
Validation loss: 2.675488660944493

Epoch: 6| Step: 4
Training loss: 3.2266128942512062
Validation loss: 2.695704653500883

Epoch: 6| Step: 5
Training loss: 2.758565567551099
Validation loss: 2.694181320277808

Epoch: 6| Step: 6
Training loss: 3.388512018924026
Validation loss: 2.677820372284909

Epoch: 6| Step: 7
Training loss: 2.9292623389416312
Validation loss: 2.6793173946338693

Epoch: 6| Step: 8
Training loss: 2.6342490603932305
Validation loss: 2.700546714657191

Epoch: 6| Step: 9
Training loss: 3.874844947912281
Validation loss: 2.6811760150976482

Epoch: 6| Step: 10
Training loss: 2.3910400429263916
Validation loss: 2.6681126796980346

Epoch: 6| Step: 11
Training loss: 3.377406498583972
Validation loss: 2.7002857183549005

Epoch: 6| Step: 12
Training loss: 3.4951926322099736
Validation loss: 2.6791279622169153

Epoch: 6| Step: 13
Training loss: 3.1669543955403934
Validation loss: 2.6724284002601197

Epoch: 30| Step: 0
Training loss: 2.5328556195965217
Validation loss: 2.68676098895714

Epoch: 6| Step: 1
Training loss: 2.764015720935504
Validation loss: 2.670323448456564

Epoch: 6| Step: 2
Training loss: 2.9564134161463973
Validation loss: 2.682960745234519

Epoch: 6| Step: 3
Training loss: 3.46398543571952
Validation loss: 2.7003823186260214

Epoch: 6| Step: 4
Training loss: 3.633424768843066
Validation loss: 2.6751510377369465

Epoch: 6| Step: 5
Training loss: 2.9878570853989244
Validation loss: 2.6827964115859078

Epoch: 6| Step: 6
Training loss: 2.3779180569530767
Validation loss: 2.72543458874082

Epoch: 6| Step: 7
Training loss: 2.9604143873327198
Validation loss: 2.6674514091399244

Epoch: 6| Step: 8
Training loss: 2.372092625782764
Validation loss: 2.680320930601939

Epoch: 6| Step: 9
Training loss: 2.2373863148711393
Validation loss: 2.6673774643563557

Epoch: 6| Step: 10
Training loss: 3.579324179851925
Validation loss: 2.674118624616472

Epoch: 6| Step: 11
Training loss: 2.573126739286401
Validation loss: 2.677823140492644

Epoch: 6| Step: 12
Training loss: 3.620598850771514
Validation loss: 2.6967187153110945

Epoch: 6| Step: 13
Training loss: 3.586635945435546
Validation loss: 2.685782176160764

Epoch: 31| Step: 0
Training loss: 3.3075449608754965
Validation loss: 2.687352240569667

Epoch: 6| Step: 1
Training loss: 3.2541437875201455
Validation loss: 2.668359888658209

Epoch: 6| Step: 2
Training loss: 2.807075949869576
Validation loss: 2.6947129733540236

Epoch: 6| Step: 3
Training loss: 3.8201648394984136
Validation loss: 2.7010914350858566

Epoch: 6| Step: 4
Training loss: 3.02454444670721
Validation loss: 2.676663521240325

Epoch: 6| Step: 5
Training loss: 3.6935424436550144
Validation loss: 2.691306971858817

Epoch: 6| Step: 6
Training loss: 2.8282047492316855
Validation loss: 2.660745918423237

Epoch: 6| Step: 7
Training loss: 2.5196202935149636
Validation loss: 2.6945743158072673

Epoch: 6| Step: 8
Training loss: 3.5796814577542033
Validation loss: 2.672873911343292

Epoch: 6| Step: 9
Training loss: 2.734949716388196
Validation loss: 2.6510624087651826

Epoch: 6| Step: 10
Training loss: 2.1750860832981025
Validation loss: 2.683530215023407

Epoch: 6| Step: 11
Training loss: 2.501550765668235
Validation loss: 2.6660499923626273

Epoch: 6| Step: 12
Training loss: 2.7702453295314866
Validation loss: 2.657608352783053

Epoch: 6| Step: 13
Training loss: 2.3204995025390933
Validation loss: 2.6788299833050235

Epoch: 32| Step: 0
Training loss: 2.67487349879543
Validation loss: 2.6720903884645835

Epoch: 6| Step: 1
Training loss: 2.8782189634477593
Validation loss: 2.6905583233745767

Epoch: 6| Step: 2
Training loss: 3.0088104574154126
Validation loss: 2.69071666261308

Epoch: 6| Step: 3
Training loss: 3.0621364144125245
Validation loss: 2.6582561833401557

Epoch: 6| Step: 4
Training loss: 2.4925293882238715
Validation loss: 2.6652269434518048

Epoch: 6| Step: 5
Training loss: 3.0896070078592026
Validation loss: 2.677756772127501

Epoch: 6| Step: 6
Training loss: 3.444737254450224
Validation loss: 2.682081446826049

Epoch: 6| Step: 7
Training loss: 2.620792832134911
Validation loss: 2.6843410947019537

Epoch: 6| Step: 8
Training loss: 1.9309315242943421
Validation loss: 2.682851350485214

Epoch: 6| Step: 9
Training loss: 2.7597464461581467
Validation loss: 2.6847916425691847

Epoch: 6| Step: 10
Training loss: 2.949545330634995
Validation loss: 2.698436662401026

Epoch: 6| Step: 11
Training loss: 3.1547098462247187
Validation loss: 2.694147946456886

Epoch: 6| Step: 12
Training loss: 3.821963462523197
Validation loss: 2.6942417685373328

Epoch: 6| Step: 13
Training loss: 3.9375988175844157
Validation loss: 2.6901130250058025

Epoch: 33| Step: 0
Training loss: 2.921569155429331
Validation loss: 2.6465363373173396

Epoch: 6| Step: 1
Training loss: 3.412637164255227
Validation loss: 2.686710084183521

Epoch: 6| Step: 2
Training loss: 2.5707150407859
Validation loss: 2.6672832970733222

Epoch: 6| Step: 3
Training loss: 3.7732148351585737
Validation loss: 2.679385728364141

Epoch: 6| Step: 4
Training loss: 2.8080870870361028
Validation loss: 2.6994480093690814

Epoch: 6| Step: 5
Training loss: 3.089532462738961
Validation loss: 2.69564345772484

Epoch: 6| Step: 6
Training loss: 2.96052359151436
Validation loss: 2.700522072503484

Epoch: 6| Step: 7
Training loss: 2.990524108524215
Validation loss: 2.670628381884525

Epoch: 6| Step: 8
Training loss: 3.5176486146463017
Validation loss: 2.6886121981626374

Epoch: 6| Step: 9
Training loss: 2.814699626772391
Validation loss: 2.669047116744677

Epoch: 6| Step: 10
Training loss: 2.4313823516830264
Validation loss: 2.6960413307197917

Epoch: 6| Step: 11
Training loss: 2.680345637963999
Validation loss: 2.667998237815049

Epoch: 6| Step: 12
Training loss: 2.5109721686409534
Validation loss: 2.6712505822540935

Epoch: 6| Step: 13
Training loss: 3.0084779473907606
Validation loss: 2.7012465080839263

Epoch: 34| Step: 0
Training loss: 2.2362984867713958
Validation loss: 2.6883481140515664

Epoch: 6| Step: 1
Training loss: 2.5725075297342768
Validation loss: 2.6973388160102316

Epoch: 6| Step: 2
Training loss: 3.4346834608263714
Validation loss: 2.657849430000486

Epoch: 6| Step: 3
Training loss: 3.0551860431768882
Validation loss: 2.703177078924249

Epoch: 6| Step: 4
Training loss: 2.806463247917931
Validation loss: 2.685938149267042

Epoch: 6| Step: 5
Training loss: 3.6105619518341223
Validation loss: 2.6919760892656655

Epoch: 6| Step: 6
Training loss: 2.75308306139245
Validation loss: 2.6822603263103266

Epoch: 6| Step: 7
Training loss: 2.782036487946136
Validation loss: 2.693805669888766

Epoch: 6| Step: 8
Training loss: 3.6125942917499976
Validation loss: 2.7067503831745463

Epoch: 6| Step: 9
Training loss: 3.03088596950328
Validation loss: 2.684990497489114

Epoch: 6| Step: 10
Training loss: 2.674758604334451
Validation loss: 2.716748312732285

Epoch: 6| Step: 11
Training loss: 2.840330814114081
Validation loss: 2.717141142745393

Epoch: 6| Step: 12
Training loss: 3.376695277804248
Validation loss: 2.719622958294692

Epoch: 6| Step: 13
Training loss: 2.6894626991251154
Validation loss: 2.7027532305382977

Epoch: 35| Step: 0
Training loss: 3.1314118790803156
Validation loss: 2.6733580999930537

Epoch: 6| Step: 1
Training loss: 3.58411502444088
Validation loss: 2.6974215024400716

Epoch: 6| Step: 2
Training loss: 2.665010613568841
Validation loss: 2.6776079771660455

Epoch: 6| Step: 3
Training loss: 3.0298713616488158
Validation loss: 2.684573483899714

Epoch: 6| Step: 4
Training loss: 2.177379411583968
Validation loss: 2.653186551165934

Epoch: 6| Step: 5
Training loss: 2.689342665498977
Validation loss: 2.6901319893646782

Epoch: 6| Step: 6
Training loss: 2.783006948952424
Validation loss: 2.672694521621451

Epoch: 6| Step: 7
Training loss: 2.087038128404477
Validation loss: 2.67763966430963

Epoch: 6| Step: 8
Training loss: 3.6194564261587425
Validation loss: 2.675677478162191

Epoch: 6| Step: 9
Training loss: 3.5430172009504086
Validation loss: 2.6884107084051054

Epoch: 6| Step: 10
Training loss: 2.3824406568215646
Validation loss: 2.7019197810996127

Epoch: 6| Step: 11
Training loss: 2.746979354941906
Validation loss: 2.6668452999698764

Epoch: 6| Step: 12
Training loss: 2.619166295141262
Validation loss: 2.676423199029644

Epoch: 6| Step: 13
Training loss: 4.444113088547458
Validation loss: 2.6933359197165347

Epoch: 36| Step: 0
Training loss: 2.610654779784456
Validation loss: 2.680549298600286

Epoch: 6| Step: 1
Training loss: 2.4293161580678646
Validation loss: 2.68595261131947

Epoch: 6| Step: 2
Training loss: 3.180168996434974
Validation loss: 2.670812434267532

Epoch: 6| Step: 3
Training loss: 2.862977806759436
Validation loss: 2.6767178686568927

Epoch: 6| Step: 4
Training loss: 3.180880386075147
Validation loss: 2.6840328847131003

Epoch: 6| Step: 5
Training loss: 3.223868439160118
Validation loss: 2.6658873954404934

Epoch: 6| Step: 6
Training loss: 3.0216410817576156
Validation loss: 2.6570363742828778

Epoch: 6| Step: 7
Training loss: 2.713316387604731
Validation loss: 2.6690357270186102

Epoch: 6| Step: 8
Training loss: 3.560565624093532
Validation loss: 2.6896365564105604

Epoch: 6| Step: 9
Training loss: 3.4044978683763056
Validation loss: 2.642782795777654

Epoch: 6| Step: 10
Training loss: 2.4869539322829457
Validation loss: 2.6755248689831355

Epoch: 6| Step: 11
Training loss: 3.0894718066866256
Validation loss: 2.628409476807883

Epoch: 6| Step: 12
Training loss: 3.182714422753282
Validation loss: 2.681193152347873

Epoch: 6| Step: 13
Training loss: 2.363883655789843
Validation loss: 2.654404242006959

Epoch: 37| Step: 0
Training loss: 3.7357851821436445
Validation loss: 2.6912524351440066

Epoch: 6| Step: 1
Training loss: 3.1026443401145927
Validation loss: 2.677020237902415

Epoch: 6| Step: 2
Training loss: 2.4384618964191516
Validation loss: 2.6760077952833603

Epoch: 6| Step: 3
Training loss: 2.635481842401115
Validation loss: 2.6673963087550416

Epoch: 6| Step: 4
Training loss: 2.6820948161263147
Validation loss: 2.631847224237112

Epoch: 6| Step: 5
Training loss: 1.988353315744876
Validation loss: 2.6788784740626053

Epoch: 6| Step: 6
Training loss: 3.2810208195168507
Validation loss: 2.6580441751009434

Epoch: 6| Step: 7
Training loss: 3.017566747551367
Validation loss: 2.6671360324463538

Epoch: 6| Step: 8
Training loss: 3.2828100946155216
Validation loss: 2.673181162378421

Epoch: 6| Step: 9
Training loss: 2.9738890488944403
Validation loss: 2.6328702472205707

Epoch: 6| Step: 10
Training loss: 3.0083305408186556
Validation loss: 2.6762653465919373

Epoch: 6| Step: 11
Training loss: 3.3393748528667735
Validation loss: 2.6740445094762713

Epoch: 6| Step: 12
Training loss: 2.9918858149460337
Validation loss: 2.638937347548631

Epoch: 6| Step: 13
Training loss: 2.879460564797871
Validation loss: 2.7016371805945743

Epoch: 38| Step: 0
Training loss: 3.236546915931527
Validation loss: 2.6497669126748984

Epoch: 6| Step: 1
Training loss: 2.7546375358840884
Validation loss: 2.6427040194709996

Epoch: 6| Step: 2
Training loss: 3.2983458794934597
Validation loss: 2.643187898832706

Epoch: 6| Step: 3
Training loss: 3.4308061100680654
Validation loss: 2.695912742507107

Epoch: 6| Step: 4
Training loss: 3.179333716353766
Validation loss: 2.6753351824026423

Epoch: 6| Step: 5
Training loss: 2.1761327490424565
Validation loss: 2.660140784207525

Epoch: 6| Step: 6
Training loss: 3.987801787337577
Validation loss: 2.6728903110225826

Epoch: 6| Step: 7
Training loss: 2.4754485022563077
Validation loss: 2.683492793768768

Epoch: 6| Step: 8
Training loss: 2.3403994198159643
Validation loss: 2.6850087294164817

Epoch: 6| Step: 9
Training loss: 2.781832173312854
Validation loss: 2.6612879125398354

Epoch: 6| Step: 10
Training loss: 2.605909044389661
Validation loss: 2.6810044128141386

Epoch: 6| Step: 11
Training loss: 3.153954303669251
Validation loss: 2.6608581556573916

Epoch: 6| Step: 12
Training loss: 2.7643721161805095
Validation loss: 2.6850291706064273

Epoch: 6| Step: 13
Training loss: 2.9658291552490006
Validation loss: 2.6533016232089923

Epoch: 39| Step: 0
Training loss: 2.9610086799862816
Validation loss: 2.676383916873502

Epoch: 6| Step: 1
Training loss: 3.363215181098307
Validation loss: 2.671402122794173

Epoch: 6| Step: 2
Training loss: 2.4870075217556225
Validation loss: 2.660591596178509

Epoch: 6| Step: 3
Training loss: 2.443747510201437
Validation loss: 2.6661983938942813

Epoch: 6| Step: 4
Training loss: 3.254127082795613
Validation loss: 2.6580488171575802

Epoch: 6| Step: 5
Training loss: 2.6277090353528676
Validation loss: 2.662573476961166

Epoch: 6| Step: 6
Training loss: 2.7137996284940606
Validation loss: 2.645281794194491

Epoch: 6| Step: 7
Training loss: 3.3015612521442272
Validation loss: 2.667512029685343

Epoch: 6| Step: 8
Training loss: 3.308574726000502
Validation loss: 2.6859275365220876

Epoch: 6| Step: 9
Training loss: 3.6320839428212826
Validation loss: 2.6678874281278433

Epoch: 6| Step: 10
Training loss: 2.6908587381914657
Validation loss: 2.691523108398253

Epoch: 6| Step: 11
Training loss: 2.7540202665061155
Validation loss: 2.672094413202823

Epoch: 6| Step: 12
Training loss: 2.7381287884680567
Validation loss: 2.676357761017156

Epoch: 6| Step: 13
Training loss: 3.1751839051338266
Validation loss: 2.640895563875458

Epoch: 40| Step: 0
Training loss: 3.0440328791643485
Validation loss: 2.6613007543713016

Epoch: 6| Step: 1
Training loss: 4.178095491200955
Validation loss: 2.685631050886317

Epoch: 6| Step: 2
Training loss: 2.5644219796816334
Validation loss: 2.6505583857242945

Epoch: 6| Step: 3
Training loss: 2.5471645260868647
Validation loss: 2.6771796497938727

Epoch: 6| Step: 4
Training loss: 2.7926337621442188
Validation loss: 2.6584508909291644

Epoch: 6| Step: 5
Training loss: 2.033406448091992
Validation loss: 2.653643334398918

Epoch: 6| Step: 6
Training loss: 3.113318008722768
Validation loss: 2.6587018533856956

Epoch: 6| Step: 7
Training loss: 2.9927302333952404
Validation loss: 2.6865268804662352

Epoch: 6| Step: 8
Training loss: 2.8686403340839033
Validation loss: 2.67213873169395

Epoch: 6| Step: 9
Training loss: 3.1020556617529094
Validation loss: 2.6739735666659055

Epoch: 6| Step: 10
Training loss: 2.82712828212267
Validation loss: 2.666041132279683

Epoch: 6| Step: 11
Training loss: 3.314430681825901
Validation loss: 2.6649564679898528

Epoch: 6| Step: 12
Training loss: 2.6171468703119607
Validation loss: 2.664702256883777

Epoch: 6| Step: 13
Training loss: 3.0787952293701006
Validation loss: 2.6373148048077297

Epoch: 41| Step: 0
Training loss: 3.1896346181329895
Validation loss: 2.6359952516630814

Epoch: 6| Step: 1
Training loss: 2.435173978915402
Validation loss: 2.6661085408660306

Epoch: 6| Step: 2
Training loss: 2.5952171863965203
Validation loss: 2.6548939514702607

Epoch: 6| Step: 3
Training loss: 3.2639363134379185
Validation loss: 2.668559026565068

Epoch: 6| Step: 4
Training loss: 2.7560585214965183
Validation loss: 2.6464116985021557

Epoch: 6| Step: 5
Training loss: 3.6305562549977277
Validation loss: 2.6838971327272603

Epoch: 6| Step: 6
Training loss: 2.479679492728388
Validation loss: 2.6718749894455964

Epoch: 6| Step: 7
Training loss: 2.7576695910376463
Validation loss: 2.706801289909658

Epoch: 6| Step: 8
Training loss: 3.4050320188834617
Validation loss: 2.677674644581135

Epoch: 6| Step: 9
Training loss: 2.6813198267240694
Validation loss: 2.6785165579547634

Epoch: 6| Step: 10
Training loss: 3.5024359264408025
Validation loss: 2.6683955814358837

Epoch: 6| Step: 11
Training loss: 3.1445912989219855
Validation loss: 2.6383309474138765

Epoch: 6| Step: 12
Training loss: 2.60004616843094
Validation loss: 2.663313171859405

Epoch: 6| Step: 13
Training loss: 3.212953254993669
Validation loss: 2.690907791500751

Epoch: 42| Step: 0
Training loss: 2.5696492832315183
Validation loss: 2.66955935539861

Epoch: 6| Step: 1
Training loss: 2.904583196629523
Validation loss: 2.6519309962377946

Epoch: 6| Step: 2
Training loss: 3.5979881174973807
Validation loss: 2.6767617679673017

Epoch: 6| Step: 3
Training loss: 2.9847250528402522
Validation loss: 2.6688060683426733

Epoch: 6| Step: 4
Training loss: 3.6432172853695572
Validation loss: 2.6648902933759957

Epoch: 6| Step: 5
Training loss: 2.26405595840341
Validation loss: 2.6990579783654334

Epoch: 6| Step: 6
Training loss: 3.7180036549173154
Validation loss: 2.680097849118277

Epoch: 6| Step: 7
Training loss: 1.8385655849150935
Validation loss: 2.693968817138914

Epoch: 6| Step: 8
Training loss: 2.5058628953416915
Validation loss: 2.6478879329780254

Epoch: 6| Step: 9
Training loss: 3.667713940497051
Validation loss: 2.672302087225902

Epoch: 6| Step: 10
Training loss: 2.718565485162927
Validation loss: 2.6726529266779626

Epoch: 6| Step: 11
Training loss: 2.601957457292126
Validation loss: 2.642387824511263

Epoch: 6| Step: 12
Training loss: 3.274513086129434
Validation loss: 2.668975358161607

Epoch: 6| Step: 13
Training loss: 2.320136991599858
Validation loss: 2.6870735490219686

Epoch: 43| Step: 0
Training loss: 2.52094951603604
Validation loss: 2.6580778122262827

Epoch: 6| Step: 1
Training loss: 3.2057090198783476
Validation loss: 2.6745267311184366

Epoch: 6| Step: 2
Training loss: 2.116308726686149
Validation loss: 2.6244999008275123

Epoch: 6| Step: 3
Training loss: 2.4323997936407404
Validation loss: 2.678339568678491

Epoch: 6| Step: 4
Training loss: 2.9476018047789516
Validation loss: 2.6495475198549165

Epoch: 6| Step: 5
Training loss: 3.3945306881112884
Validation loss: 2.6549592097575117

Epoch: 6| Step: 6
Training loss: 2.7536948264919863
Validation loss: 2.6649428251236396

Epoch: 6| Step: 7
Training loss: 1.8062321381527215
Validation loss: 2.654535188605144

Epoch: 6| Step: 8
Training loss: 3.108586043515831
Validation loss: 2.6584998990113844

Epoch: 6| Step: 9
Training loss: 3.576478271025859
Validation loss: 2.627826757631527

Epoch: 6| Step: 10
Training loss: 3.2636598944087405
Validation loss: 2.670042466772292

Epoch: 6| Step: 11
Training loss: 3.111748177908567
Validation loss: 2.668829829504346

Epoch: 6| Step: 12
Training loss: 3.6762269547462294
Validation loss: 2.6731324013983864

Epoch: 6| Step: 13
Training loss: 3.0704839527510255
Validation loss: 2.6525783393695117

Epoch: 44| Step: 0
Training loss: 3.200299761560278
Validation loss: 2.6735939225268157

Epoch: 6| Step: 1
Training loss: 4.047488368620249
Validation loss: 2.670894959510062

Epoch: 6| Step: 2
Training loss: 2.8074586402244726
Validation loss: 2.683675325760536

Epoch: 6| Step: 3
Training loss: 2.4164011469582696
Validation loss: 2.64504171254245

Epoch: 6| Step: 4
Training loss: 3.2056193246417455
Validation loss: 2.6908419340262832

Epoch: 6| Step: 5
Training loss: 3.2648104149074393
Validation loss: 2.6791673964724603

Epoch: 6| Step: 6
Training loss: 2.2619053264607656
Validation loss: 2.6834933870331366

Epoch: 6| Step: 7
Training loss: 2.309224463732655
Validation loss: 2.641312904410763

Epoch: 6| Step: 8
Training loss: 3.14779876212155
Validation loss: 2.628451002353592

Epoch: 6| Step: 9
Training loss: 3.059598988953547
Validation loss: 2.6382051620188895

Epoch: 6| Step: 10
Training loss: 2.5854096118749803
Validation loss: 2.6736565190293717

Epoch: 6| Step: 11
Training loss: 2.5453311476893736
Validation loss: 2.6610177264993045

Epoch: 6| Step: 12
Training loss: 2.9572116892499634
Validation loss: 2.690647322753745

Epoch: 6| Step: 13
Training loss: 2.9468475308154387
Validation loss: 2.640513148386944

Epoch: 45| Step: 0
Training loss: 3.588854830973626
Validation loss: 2.653466537188999

Epoch: 6| Step: 1
Training loss: 3.0394967756873936
Validation loss: 2.6331036477514336

Epoch: 6| Step: 2
Training loss: 3.4764423478183955
Validation loss: 2.6641171294941226

Epoch: 6| Step: 3
Training loss: 2.3769480094760587
Validation loss: 2.679602189291917

Epoch: 6| Step: 4
Training loss: 3.394936066644915
Validation loss: 2.631785223051397

Epoch: 6| Step: 5
Training loss: 3.7069337468242844
Validation loss: 2.6518012213289444

Epoch: 6| Step: 6
Training loss: 2.7314554377270324
Validation loss: 2.654278676477106

Epoch: 6| Step: 7
Training loss: 2.0740154044554977
Validation loss: 2.6732652356737874

Epoch: 6| Step: 8
Training loss: 2.4716947352366914
Validation loss: 2.673595644664594

Epoch: 6| Step: 9
Training loss: 2.9333996664118707
Validation loss: 2.651522773693898

Epoch: 6| Step: 10
Training loss: 3.001329763068312
Validation loss: 2.6608396479342526

Epoch: 6| Step: 11
Training loss: 3.0723570405682024
Validation loss: 2.686559422386474

Epoch: 6| Step: 12
Training loss: 2.3487205187625766
Validation loss: 2.697384612250081

Epoch: 6| Step: 13
Training loss: 2.650917265146004
Validation loss: 2.645095314989649

Epoch: 46| Step: 0
Training loss: 3.1498008786193408
Validation loss: 2.665931287499276

Epoch: 6| Step: 1
Training loss: 2.8167412885302814
Validation loss: 2.662628464365703

Epoch: 6| Step: 2
Training loss: 3.351583556351397
Validation loss: 2.705448481474139

Epoch: 6| Step: 3
Training loss: 1.7990236124351913
Validation loss: 2.6614664595901525

Epoch: 6| Step: 4
Training loss: 3.454669037575045
Validation loss: 2.659541814555185

Epoch: 6| Step: 5
Training loss: 2.4644486825576144
Validation loss: 2.649084330362216

Epoch: 6| Step: 6
Training loss: 3.4643100125299178
Validation loss: 2.6772333470758567

Epoch: 6| Step: 7
Training loss: 3.183786959723786
Validation loss: 2.7104400739185355

Epoch: 6| Step: 8
Training loss: 2.7058550328390165
Validation loss: 2.637078620419412

Epoch: 6| Step: 9
Training loss: 2.7131436300703577
Validation loss: 2.678840873944336

Epoch: 6| Step: 10
Training loss: 3.074321430047454
Validation loss: 2.673350516535043

Epoch: 6| Step: 11
Training loss: 2.998272875490301
Validation loss: 2.6747930558430997

Epoch: 6| Step: 12
Training loss: 3.2334087605543456
Validation loss: 2.6597022248754616

Epoch: 6| Step: 13
Training loss: 1.7261600629510712
Validation loss: 2.678744238549331

Epoch: 47| Step: 0
Training loss: 2.780008789158382
Validation loss: 2.6393836250832603

Epoch: 6| Step: 1
Training loss: 3.2867150707691257
Validation loss: 2.662461515205597

Epoch: 6| Step: 2
Training loss: 3.1495201956438628
Validation loss: 2.6770117435592673

Epoch: 6| Step: 3
Training loss: 2.932852131937036
Validation loss: 2.656268486137172

Epoch: 6| Step: 4
Training loss: 3.1771073804268397
Validation loss: 2.667806976323442

Epoch: 6| Step: 5
Training loss: 2.680527891720173
Validation loss: 2.67618983291288

Epoch: 6| Step: 6
Training loss: 2.765602499660193
Validation loss: 2.642831723851971

Epoch: 6| Step: 7
Training loss: 2.7391695548950357
Validation loss: 2.684047671749949

Epoch: 6| Step: 8
Training loss: 2.8979073833990605
Validation loss: 2.6440056406820127

Epoch: 6| Step: 9
Training loss: 2.2068829241847765
Validation loss: 2.663325170338922

Epoch: 6| Step: 10
Training loss: 2.1321826046581784
Validation loss: 2.665688529193624

Epoch: 6| Step: 11
Training loss: 3.811888849020921
Validation loss: 2.6309577672635585

Epoch: 6| Step: 12
Training loss: 3.6982590780988067
Validation loss: 2.6620479139649036

Epoch: 6| Step: 13
Training loss: 2.9750088218750506
Validation loss: 2.649758170360665

Epoch: 48| Step: 0
Training loss: 3.489504609240073
Validation loss: 2.6865830666087507

Epoch: 6| Step: 1
Training loss: 3.0144103771508948
Validation loss: 2.6781630884434486

Epoch: 6| Step: 2
Training loss: 2.4153226754527846
Validation loss: 2.650301581558312

Epoch: 6| Step: 3
Training loss: 1.9722537999319016
Validation loss: 2.628043489142134

Epoch: 6| Step: 4
Training loss: 2.9467747142309104
Validation loss: 2.6493908955087324

Epoch: 6| Step: 5
Training loss: 3.642100415851813
Validation loss: 2.68056159004888

Epoch: 6| Step: 6
Training loss: 2.0739725257723864
Validation loss: 2.6935610656361293

Epoch: 6| Step: 7
Training loss: 2.677253351613931
Validation loss: 2.6742828837420154

Epoch: 6| Step: 8
Training loss: 2.784578453362977
Validation loss: 2.6785611369945603

Epoch: 6| Step: 9
Training loss: 3.631817687630606
Validation loss: 2.6702490215616566

Epoch: 6| Step: 10
Training loss: 3.7557801522455962
Validation loss: 2.6761219396695566

Epoch: 6| Step: 11
Training loss: 2.9915353248547
Validation loss: 2.675353984164936

Epoch: 6| Step: 12
Training loss: 2.647040885041733
Validation loss: 2.6505120405921563

Epoch: 6| Step: 13
Training loss: 2.57089171217094
Validation loss: 2.6782586641237653

Epoch: 49| Step: 0
Training loss: 3.8208936003601877
Validation loss: 2.646772978565542

Epoch: 6| Step: 1
Training loss: 2.574396847944541
Validation loss: 2.6749325403818176

Epoch: 6| Step: 2
Training loss: 3.52070704728368
Validation loss: 2.6767627352840817

Epoch: 6| Step: 3
Training loss: 2.851898926001912
Validation loss: 2.6492227187734043

Epoch: 6| Step: 4
Training loss: 2.150421447255833
Validation loss: 2.6709647089722655

Epoch: 6| Step: 5
Training loss: 2.176502375378179
Validation loss: 2.649359822664409

Epoch: 6| Step: 6
Training loss: 3.686275214118397
Validation loss: 2.68007175342155

Epoch: 6| Step: 7
Training loss: 2.8650183514977607
Validation loss: 2.6620507895806136

Epoch: 6| Step: 8
Training loss: 3.304467592971377
Validation loss: 2.669688826917161

Epoch: 6| Step: 9
Training loss: 2.173604372750083
Validation loss: 2.6622781681444625

Epoch: 6| Step: 10
Training loss: 2.616304436494145
Validation loss: 2.649383658564372

Epoch: 6| Step: 11
Training loss: 2.8516446036446417
Validation loss: 2.622905739590573

Epoch: 6| Step: 12
Training loss: 3.303275742424959
Validation loss: 2.665416956010683

Epoch: 6| Step: 13
Training loss: 2.2224281877859906
Validation loss: 2.6327911348821886

Epoch: 50| Step: 0
Training loss: 3.0657095147945057
Validation loss: 2.6624391049574414

Epoch: 6| Step: 1
Training loss: 3.0606898972445293
Validation loss: 2.6901787759628175

Epoch: 6| Step: 2
Training loss: 2.7249387261737406
Validation loss: 2.654990983749989

Epoch: 6| Step: 3
Training loss: 2.5238943719782174
Validation loss: 2.6145351526239695

Epoch: 6| Step: 4
Training loss: 2.4146840304644375
Validation loss: 2.6438289417505296

Epoch: 6| Step: 5
Training loss: 3.122163324339798
Validation loss: 2.640778781436918

Epoch: 6| Step: 6
Training loss: 3.7689624732809426
Validation loss: 2.6126549291481322

Epoch: 6| Step: 7
Training loss: 3.1337733899869082
Validation loss: 2.6548565929811656

Epoch: 6| Step: 8
Training loss: 2.114663734849306
Validation loss: 2.686568041129423

Epoch: 6| Step: 9
Training loss: 3.041418579296067
Validation loss: 2.6552772009783574

Epoch: 6| Step: 10
Training loss: 3.2530972321101164
Validation loss: 2.624292871224584

Epoch: 6| Step: 11
Training loss: 2.4170711003531937
Validation loss: 2.6556868316273277

Epoch: 6| Step: 12
Training loss: 3.253424234397107
Validation loss: 2.655403763900563

Epoch: 6| Step: 13
Training loss: 3.0057843392904506
Validation loss: 2.6384755678936305

Epoch: 51| Step: 0
Training loss: 2.962571470790782
Validation loss: 2.642057493001559

Epoch: 6| Step: 1
Training loss: 3.272126802594279
Validation loss: 2.6321902947661564

Epoch: 6| Step: 2
Training loss: 3.326625575752769
Validation loss: 2.6680083059535935

Epoch: 6| Step: 3
Training loss: 2.362865165463559
Validation loss: 2.6280675291061306

Epoch: 6| Step: 4
Training loss: 2.8179137789041975
Validation loss: 2.6361091300988924

Epoch: 6| Step: 5
Training loss: 2.547825922458664
Validation loss: 2.6739407028355315

Epoch: 6| Step: 6
Training loss: 2.07215333107621
Validation loss: 2.6674446354224806

Epoch: 6| Step: 7
Training loss: 3.0633970231445895
Validation loss: 2.621225910771158

Epoch: 6| Step: 8
Training loss: 2.9185960292026105
Validation loss: 2.6374854452461265

Epoch: 6| Step: 9
Training loss: 2.6845116967955147
Validation loss: 2.643649512841622

Epoch: 6| Step: 10
Training loss: 3.3259731732890567
Validation loss: 2.643523167840099

Epoch: 6| Step: 11
Training loss: 3.876623490394611
Validation loss: 2.649470209342952

Epoch: 6| Step: 12
Training loss: 2.8227663645315153
Validation loss: 2.6405168396978125

Epoch: 6| Step: 13
Training loss: 2.6358628529831227
Validation loss: 2.6691341065995964

Epoch: 52| Step: 0
Training loss: 3.1198721967099408
Validation loss: 2.6429816153095094

Epoch: 6| Step: 1
Training loss: 2.9141718048786363
Validation loss: 2.646009500529967

Epoch: 6| Step: 2
Training loss: 3.208214117700408
Validation loss: 2.6557182537399946

Epoch: 6| Step: 3
Training loss: 2.8180478796915227
Validation loss: 2.6747534928793275

Epoch: 6| Step: 4
Training loss: 2.868966114821359
Validation loss: 2.6291346696756306

Epoch: 6| Step: 5
Training loss: 3.3838675529767515
Validation loss: 2.6436368083070363

Epoch: 6| Step: 6
Training loss: 2.674197074675249
Validation loss: 2.6304445754987196

Epoch: 6| Step: 7
Training loss: 2.9959266347420517
Validation loss: 2.6621699727410624

Epoch: 6| Step: 8
Training loss: 2.7898351630188487
Validation loss: 2.6521131775415765

Epoch: 6| Step: 9
Training loss: 2.9321080495329195
Validation loss: 2.6710644043916645

Epoch: 6| Step: 10
Training loss: 2.484308973670577
Validation loss: 2.657053054551398

Epoch: 6| Step: 11
Training loss: 2.7696686402584434
Validation loss: 2.649809242250625

Epoch: 6| Step: 12
Training loss: 3.3685461432042882
Validation loss: 2.660305979625731

Epoch: 6| Step: 13
Training loss: 2.7770339213556805
Validation loss: 2.662779521274376

Epoch: 53| Step: 0
Training loss: 2.750982109175274
Validation loss: 2.6398494693484493

Epoch: 6| Step: 1
Training loss: 3.058720650604206
Validation loss: 2.655495969817485

Epoch: 6| Step: 2
Training loss: 2.596400182399764
Validation loss: 2.6688419732052377

Epoch: 6| Step: 3
Training loss: 3.10976878984106
Validation loss: 2.6339736169281776

Epoch: 6| Step: 4
Training loss: 2.7210539778486957
Validation loss: 2.6670412664436167

Epoch: 6| Step: 5
Training loss: 2.9679755555968796
Validation loss: 2.6508887309073588

Epoch: 6| Step: 6
Training loss: 2.7595905051315066
Validation loss: 2.640764951531746

Epoch: 6| Step: 7
Training loss: 2.678233917407387
Validation loss: 2.666674168509524

Epoch: 6| Step: 8
Training loss: 3.1754244783454983
Validation loss: 2.6454427726542775

Epoch: 6| Step: 9
Training loss: 3.5643664373020396
Validation loss: 2.64374022518746

Epoch: 6| Step: 10
Training loss: 3.2052811971487634
Validation loss: 2.6429803756741364

Epoch: 6| Step: 11
Training loss: 3.10388127664255
Validation loss: 2.6408555270661083

Epoch: 6| Step: 12
Training loss: 2.1844906406599365
Validation loss: 2.665221943571192

Epoch: 6| Step: 13
Training loss: 2.5109658069356207
Validation loss: 2.646630415557239

Epoch: 54| Step: 0
Training loss: 2.669872046272862
Validation loss: 2.6170027668723925

Epoch: 6| Step: 1
Training loss: 4.125693060711275
Validation loss: 2.6610878480497626

Epoch: 6| Step: 2
Training loss: 3.018035399717869
Validation loss: 2.678455641861806

Epoch: 6| Step: 3
Training loss: 2.7239433759834224
Validation loss: 2.6205577325183786

Epoch: 6| Step: 4
Training loss: 2.562076440556733
Validation loss: 2.653589746180631

Epoch: 6| Step: 5
Training loss: 2.3999158049755995
Validation loss: 2.6555968502820386

Epoch: 6| Step: 6
Training loss: 3.8792787125273396
Validation loss: 2.655115359833078

Epoch: 6| Step: 7
Training loss: 2.7314550012956067
Validation loss: 2.656602862841987

Epoch: 6| Step: 8
Training loss: 2.8113412801358706
Validation loss: 2.6664996082009065

Epoch: 6| Step: 9
Training loss: 2.299793802223443
Validation loss: 2.667328810650018

Epoch: 6| Step: 10
Training loss: 2.7212633814414797
Validation loss: 2.664500308946394

Epoch: 6| Step: 11
Training loss: 2.793240279223541
Validation loss: 2.6322123586996278

Epoch: 6| Step: 12
Training loss: 2.8531775512535233
Validation loss: 2.6293245682511097

Epoch: 6| Step: 13
Training loss: 2.7919605916474715
Validation loss: 2.6405115896269513

Epoch: 55| Step: 0
Training loss: 2.4185366356554976
Validation loss: 2.6447526176245995

Epoch: 6| Step: 1
Training loss: 2.4556205350622147
Validation loss: 2.6401274371844226

Epoch: 6| Step: 2
Training loss: 3.6944816574733763
Validation loss: 2.6663173205083845

Epoch: 6| Step: 3
Training loss: 2.936293171467412
Validation loss: 2.68158123397907

Epoch: 6| Step: 4
Training loss: 3.030412381251016
Validation loss: 2.6233701231189586

Epoch: 6| Step: 5
Training loss: 3.050862993813233
Validation loss: 2.6837525727413656

Epoch: 6| Step: 6
Training loss: 2.2224955576111
Validation loss: 2.632093309245328

Epoch: 6| Step: 7
Training loss: 3.217925327171978
Validation loss: 2.6602007136525136

Epoch: 6| Step: 8
Training loss: 2.770659610971836
Validation loss: 2.6453595692080625

Epoch: 6| Step: 9
Training loss: 2.8601386712874852
Validation loss: 2.661155065161412

Epoch: 6| Step: 10
Training loss: 2.7302441593300157
Validation loss: 2.636338860822295

Epoch: 6| Step: 11
Training loss: 2.7502734308422814
Validation loss: 2.641593521030408

Epoch: 6| Step: 12
Training loss: 3.434635841800946
Validation loss: 2.6375995567624844

Epoch: 6| Step: 13
Training loss: 3.296005929960083
Validation loss: 2.60623316983301

Epoch: 56| Step: 0
Training loss: 2.962173888208107
Validation loss: 2.645113757934712

Epoch: 6| Step: 1
Training loss: 3.218214564556022
Validation loss: 2.622835246254965

Epoch: 6| Step: 2
Training loss: 3.138495639109442
Validation loss: 2.6478968639689735

Epoch: 6| Step: 3
Training loss: 3.437027222459794
Validation loss: 2.6600106494174423

Epoch: 6| Step: 4
Training loss: 3.099685369952924
Validation loss: 2.635491614536769

Epoch: 6| Step: 5
Training loss: 2.8513499559594746
Validation loss: 2.6674351879416447

Epoch: 6| Step: 6
Training loss: 2.554132337064636
Validation loss: 2.643685102862607

Epoch: 6| Step: 7
Training loss: 2.432320005808598
Validation loss: 2.645779905069639

Epoch: 6| Step: 8
Training loss: 2.9543343141779332
Validation loss: 2.6315030363750975

Epoch: 6| Step: 9
Training loss: 3.7117965185858104
Validation loss: 2.6405250126028843

Epoch: 6| Step: 10
Training loss: 2.6217907861363634
Validation loss: 2.6453630163250086

Epoch: 6| Step: 11
Training loss: 2.9891061080726766
Validation loss: 2.641707717114872

Epoch: 6| Step: 12
Training loss: 1.9402273117683368
Validation loss: 2.6492724655913986

Epoch: 6| Step: 13
Training loss: 2.2151438460991946
Validation loss: 2.6312557182301517

Epoch: 57| Step: 0
Training loss: 2.7614880671867557
Validation loss: 2.6382201344946443

Epoch: 6| Step: 1
Training loss: 2.6241339208458268
Validation loss: 2.6458075307902926

Epoch: 6| Step: 2
Training loss: 2.713747003343668
Validation loss: 2.670593002134289

Epoch: 6| Step: 3
Training loss: 2.7363739554401607
Validation loss: 2.612216935737219

Epoch: 6| Step: 4
Training loss: 2.848066303049306
Validation loss: 2.621754816764523

Epoch: 6| Step: 5
Training loss: 2.4056669247136298
Validation loss: 2.646005854667639

Epoch: 6| Step: 6
Training loss: 2.902189966904976
Validation loss: 2.6639595130917266

Epoch: 6| Step: 7
Training loss: 3.1501124165169623
Validation loss: 2.6561193203615217

Epoch: 6| Step: 8
Training loss: 3.362625323941677
Validation loss: 2.6225915486636167

Epoch: 6| Step: 9
Training loss: 2.885775896059469
Validation loss: 2.615371593774598

Epoch: 6| Step: 10
Training loss: 2.7141188717238256
Validation loss: 2.6353105780419823

Epoch: 6| Step: 11
Training loss: 3.127013206500403
Validation loss: 2.635884543822668

Epoch: 6| Step: 12
Training loss: 2.8027660195295456
Validation loss: 2.64252521268591

Epoch: 6| Step: 13
Training loss: 4.203216665183066
Validation loss: 2.6602990923114596

Epoch: 58| Step: 0
Training loss: 2.2993420696466784
Validation loss: 2.62210750358297

Epoch: 6| Step: 1
Training loss: 2.3504773040759868
Validation loss: 2.641413372495927

Epoch: 6| Step: 2
Training loss: 3.4591900480566573
Validation loss: 2.606956270205689

Epoch: 6| Step: 3
Training loss: 3.1050747219560857
Validation loss: 2.6325144301590453

Epoch: 6| Step: 4
Training loss: 2.934624746011378
Validation loss: 2.639087043943921

Epoch: 6| Step: 5
Training loss: 2.8633005680197576
Validation loss: 2.6283287456606965

Epoch: 6| Step: 6
Training loss: 3.510147371159898
Validation loss: 2.65449825483561

Epoch: 6| Step: 7
Training loss: 2.8604019072046056
Validation loss: 2.633566940753813

Epoch: 6| Step: 8
Training loss: 2.7452723005691912
Validation loss: 2.6442546399604705

Epoch: 6| Step: 9
Training loss: 2.893975702633255
Validation loss: 2.6407733673376446

Epoch: 6| Step: 10
Training loss: 3.0478801927624377
Validation loss: 2.649464194703413

Epoch: 6| Step: 11
Training loss: 3.355730359644986
Validation loss: 2.637384490233661

Epoch: 6| Step: 12
Training loss: 2.248893041636202
Validation loss: 2.661797938282595

Epoch: 6| Step: 13
Training loss: 2.828143883742204
Validation loss: 2.641192756785216

Epoch: 59| Step: 0
Training loss: 2.7376810196898522
Validation loss: 2.660039276147966

Epoch: 6| Step: 1
Training loss: 2.135948697934939
Validation loss: 2.65882736911997

Epoch: 6| Step: 2
Training loss: 3.403602060835754
Validation loss: 2.6170089001999584

Epoch: 6| Step: 3
Training loss: 2.445924432499559
Validation loss: 2.653742955043776

Epoch: 6| Step: 4
Training loss: 2.672418728655203
Validation loss: 2.631198011572628

Epoch: 6| Step: 5
Training loss: 3.1151538611264793
Validation loss: 2.644291916523224

Epoch: 6| Step: 6
Training loss: 3.4441105482499967
Validation loss: 2.6532674221322514

Epoch: 6| Step: 7
Training loss: 2.5322052836673437
Validation loss: 2.6188054404632384

Epoch: 6| Step: 8
Training loss: 3.6120254891342163
Validation loss: 2.6927878634517137

Epoch: 6| Step: 9
Training loss: 3.4190931465289323
Validation loss: 2.631025240632127

Epoch: 6| Step: 10
Training loss: 1.8034271198688532
Validation loss: 2.62336482260847

Epoch: 6| Step: 11
Training loss: 3.218170558290616
Validation loss: 2.636602811281124

Epoch: 6| Step: 12
Training loss: 3.335388996137362
Validation loss: 2.635447269994663

Epoch: 6| Step: 13
Training loss: 2.4649717173781864
Validation loss: 2.622060613537307

Epoch: 60| Step: 0
Training loss: 2.5212107184115533
Validation loss: 2.662544319985233

Epoch: 6| Step: 1
Training loss: 2.711444730330081
Validation loss: 2.6438581882793524

Epoch: 6| Step: 2
Training loss: 2.975613981089134
Validation loss: 2.6659164014187455

Epoch: 6| Step: 3
Training loss: 2.911681647201225
Validation loss: 2.645181418764238

Epoch: 6| Step: 4
Training loss: 2.2566161896748063
Validation loss: 2.637283853113859

Epoch: 6| Step: 5
Training loss: 3.82259707799754
Validation loss: 2.633047576903454

Epoch: 6| Step: 6
Training loss: 3.40517205496844
Validation loss: 2.629420344544154

Epoch: 6| Step: 7
Training loss: 2.6513769890760357
Validation loss: 2.6462034729273327

Epoch: 6| Step: 8
Training loss: 2.893951151964818
Validation loss: 2.649130318218398

Epoch: 6| Step: 9
Training loss: 2.5421719804417857
Validation loss: 2.6442804221079346

Epoch: 6| Step: 10
Training loss: 3.192463619111514
Validation loss: 2.6641423874378045

Epoch: 6| Step: 11
Training loss: 2.9851169163284696
Validation loss: 2.654677396637721

Epoch: 6| Step: 12
Training loss: 3.3295633136247815
Validation loss: 2.6518995800029908

Epoch: 6| Step: 13
Training loss: 1.5779104559069097
Validation loss: 2.621818083807642

Epoch: 61| Step: 0
Training loss: 2.4708573244247782
Validation loss: 2.654385764134381

Epoch: 6| Step: 1
Training loss: 2.6216531034467567
Validation loss: 2.6334451488770947

Epoch: 6| Step: 2
Training loss: 3.4296154805401073
Validation loss: 2.660411796482174

Epoch: 6| Step: 3
Training loss: 2.653221288580498
Validation loss: 2.664046455440599

Epoch: 6| Step: 4
Training loss: 3.5577328558690953
Validation loss: 2.664699958488111

Epoch: 6| Step: 5
Training loss: 3.2600328668447065
Validation loss: 2.6551645086547975

Epoch: 6| Step: 6
Training loss: 2.86439748450154
Validation loss: 2.6107018815607557

Epoch: 6| Step: 7
Training loss: 2.6947156162292623
Validation loss: 2.6517062176339334

Epoch: 6| Step: 8
Training loss: 2.8902927517038406
Validation loss: 2.663875270248967

Epoch: 6| Step: 9
Training loss: 2.4508721764928074
Validation loss: 2.6204926496406644

Epoch: 6| Step: 10
Training loss: 2.2565297637538557
Validation loss: 2.641163277390326

Epoch: 6| Step: 11
Training loss: 3.640846343945282
Validation loss: 2.622801675192924

Epoch: 6| Step: 12
Training loss: 3.074483508641682
Validation loss: 2.6555391734652205

Epoch: 6| Step: 13
Training loss: 2.038304213500149
Validation loss: 2.6490492367583314

Epoch: 62| Step: 0
Training loss: 2.701936670076485
Validation loss: 2.5932770095300777

Epoch: 6| Step: 1
Training loss: 3.176363920880845
Validation loss: 2.652488998231455

Epoch: 6| Step: 2
Training loss: 2.8832544334362322
Validation loss: 2.6397049173418052

Epoch: 6| Step: 3
Training loss: 3.3526945180878336
Validation loss: 2.6499658476752663

Epoch: 6| Step: 4
Training loss: 2.6627909290956313
Validation loss: 2.6421994586145474

Epoch: 6| Step: 5
Training loss: 3.7898339813427366
Validation loss: 2.643524688457512

Epoch: 6| Step: 6
Training loss: 3.033032709113237
Validation loss: 2.639684046503292

Epoch: 6| Step: 7
Training loss: 3.000705953823779
Validation loss: 2.669020438506564

Epoch: 6| Step: 8
Training loss: 2.6488221375893195
Validation loss: 2.6221422411169217

Epoch: 6| Step: 9
Training loss: 2.3241640741665033
Validation loss: 2.62825199076106

Epoch: 6| Step: 10
Training loss: 3.1901324004915557
Validation loss: 2.6198549403453977

Epoch: 6| Step: 11
Training loss: 2.1606449174611235
Validation loss: 2.6581785802408797

Epoch: 6| Step: 12
Training loss: 2.825543147173316
Validation loss: 2.6382974841305127

Epoch: 6| Step: 13
Training loss: 2.7792847794613382
Validation loss: 2.6580748811953887

Epoch: 63| Step: 0
Training loss: 2.3356817099056526
Validation loss: 2.6564599433755007

Epoch: 6| Step: 1
Training loss: 3.86904092166307
Validation loss: 2.6133920884035997

Epoch: 6| Step: 2
Training loss: 3.6655460436968887
Validation loss: 2.681977783978583

Epoch: 6| Step: 3
Training loss: 2.550093974457501
Validation loss: 2.6449022024892477

Epoch: 6| Step: 4
Training loss: 2.7259225176227075
Validation loss: 2.6401754677321687

Epoch: 6| Step: 5
Training loss: 2.390995869510518
Validation loss: 2.6174281884325175

Epoch: 6| Step: 6
Training loss: 2.610237572917981
Validation loss: 2.6679119767745765

Epoch: 6| Step: 7
Training loss: 3.0710507347415223
Validation loss: 2.628931663882929

Epoch: 6| Step: 8
Training loss: 2.6073652739935747
Validation loss: 2.6443809325628194

Epoch: 6| Step: 9
Training loss: 2.978987539459322
Validation loss: 2.659424852236752

Epoch: 6| Step: 10
Training loss: 2.259707173982062
Validation loss: 2.64805134564302

Epoch: 6| Step: 11
Training loss: 3.164109820730248
Validation loss: 2.6582879545715814

Epoch: 6| Step: 12
Training loss: 3.139282243175872
Validation loss: 2.6429304134227394

Epoch: 6| Step: 13
Training loss: 3.9125730075057383
Validation loss: 2.6533805592769295

Epoch: 64| Step: 0
Training loss: 1.9195855623230504
Validation loss: 2.6457136500307135

Epoch: 6| Step: 1
Training loss: 2.813517577148113
Validation loss: 2.646569586000607

Epoch: 6| Step: 2
Training loss: 2.507180202549111
Validation loss: 2.674356979814279

Epoch: 6| Step: 3
Training loss: 3.500283910952852
Validation loss: 2.6425975275009126

Epoch: 6| Step: 4
Training loss: 3.357488625990746
Validation loss: 2.66351028371214

Epoch: 6| Step: 5
Training loss: 2.55930016935735
Validation loss: 2.647043233636278

Epoch: 6| Step: 6
Training loss: 2.446502006232123
Validation loss: 2.641277291160931

Epoch: 6| Step: 7
Training loss: 3.097570045301135
Validation loss: 2.642911542019098

Epoch: 6| Step: 8
Training loss: 2.301949429537378
Validation loss: 2.6352996456481077

Epoch: 6| Step: 9
Training loss: 3.57538043045396
Validation loss: 2.634752505938321

Epoch: 6| Step: 10
Training loss: 4.064252270085185
Validation loss: 2.6282743559932507

Epoch: 6| Step: 11
Training loss: 2.3172631568415833
Validation loss: 2.627057580212636

Epoch: 6| Step: 12
Training loss: 3.1916527717095313
Validation loss: 2.6379866822808946

Epoch: 6| Step: 13
Training loss: 2.160675483093981
Validation loss: 2.6326420231199026

Epoch: 65| Step: 0
Training loss: 2.7903021613950676
Validation loss: 2.619314354070902

Epoch: 6| Step: 1
Training loss: 2.5436384546815543
Validation loss: 2.59750165853274

Epoch: 6| Step: 2
Training loss: 3.0263678177435613
Validation loss: 2.6399704413827245

Epoch: 6| Step: 3
Training loss: 3.5150783537682178
Validation loss: 2.626158904302951

Epoch: 6| Step: 4
Training loss: 3.267292819704096
Validation loss: 2.618563997499743

Epoch: 6| Step: 5
Training loss: 2.8610961403398485
Validation loss: 2.6135495998098177

Epoch: 6| Step: 6
Training loss: 2.4223307519138424
Validation loss: 2.6110867132473805

Epoch: 6| Step: 7
Training loss: 2.3356447578637733
Validation loss: 2.633491561697789

Epoch: 6| Step: 8
Training loss: 3.3353521114839686
Validation loss: 2.5996968955631523

Epoch: 6| Step: 9
Training loss: 2.837933807149527
Validation loss: 2.642882686116528

Epoch: 6| Step: 10
Training loss: 3.2819753662523885
Validation loss: 2.6302493103272773

Epoch: 6| Step: 11
Training loss: 2.556087005567161
Validation loss: 2.6248533302658736

Epoch: 6| Step: 12
Training loss: 3.069164109889704
Validation loss: 2.6404107139081816

Epoch: 6| Step: 13
Training loss: 2.0239922782916513
Validation loss: 2.6101669103132905

Epoch: 66| Step: 0
Training loss: 2.9617715833374514
Validation loss: 2.612511149050621

Epoch: 6| Step: 1
Training loss: 2.728812002962052
Validation loss: 2.5947259143590777

Epoch: 6| Step: 2
Training loss: 3.1372624706312586
Validation loss: 2.638663824602028

Epoch: 6| Step: 3
Training loss: 2.208933970502799
Validation loss: 2.6216192453949687

Epoch: 6| Step: 4
Training loss: 3.000245084288265
Validation loss: 2.6322700752594628

Epoch: 6| Step: 5
Training loss: 3.4099730696971156
Validation loss: 2.644395577294117

Epoch: 6| Step: 6
Training loss: 3.1347458503075663
Validation loss: 2.583854851559734

Epoch: 6| Step: 7
Training loss: 2.3455416125898045
Validation loss: 2.635274733862535

Epoch: 6| Step: 8
Training loss: 2.570633053719453
Validation loss: 2.655495079709916

Epoch: 6| Step: 9
Training loss: 2.7993856914202824
Validation loss: 2.6348567881714264

Epoch: 6| Step: 10
Training loss: 2.9463204599337987
Validation loss: 2.6232801449148955

Epoch: 6| Step: 11
Training loss: 3.369135812949462
Validation loss: 2.6138591350892573

Epoch: 6| Step: 12
Training loss: 3.168424486524279
Validation loss: 2.6278018110989354

Epoch: 6| Step: 13
Training loss: 2.3697980831744063
Validation loss: 2.621616738098097

Epoch: 67| Step: 0
Training loss: 2.9448092812406137
Validation loss: 2.6679569328741968

Epoch: 6| Step: 1
Training loss: 2.017827922353875
Validation loss: 2.655463092598582

Epoch: 6| Step: 2
Training loss: 3.6311960869626216
Validation loss: 2.6179061233650733

Epoch: 6| Step: 3
Training loss: 2.8494214524760224
Validation loss: 2.628951886765002

Epoch: 6| Step: 4
Training loss: 2.850540437822044
Validation loss: 2.6245300899777435

Epoch: 6| Step: 5
Training loss: 2.2662468418576958
Validation loss: 2.6425343854196357

Epoch: 6| Step: 6
Training loss: 2.8312000396564674
Validation loss: 2.6542488034693785

Epoch: 6| Step: 7
Training loss: 2.8365217295405585
Validation loss: 2.65049345530495

Epoch: 6| Step: 8
Training loss: 3.6619934877497107
Validation loss: 2.5930905364274044

Epoch: 6| Step: 9
Training loss: 2.7081646989016295
Validation loss: 2.614406928969505

Epoch: 6| Step: 10
Training loss: 2.6902915296026393
Validation loss: 2.6307926959594328

Epoch: 6| Step: 11
Training loss: 2.675547256819457
Validation loss: 2.619868208375937

Epoch: 6| Step: 12
Training loss: 3.413279428304761
Validation loss: 2.6459997575499483

Epoch: 6| Step: 13
Training loss: 3.1145644851845735
Validation loss: 2.598019045583409

Epoch: 68| Step: 0
Training loss: 2.6754478079763704
Validation loss: 2.6265027080727363

Epoch: 6| Step: 1
Training loss: 3.3088995601919495
Validation loss: 2.6251409700808273

Epoch: 6| Step: 2
Training loss: 2.8799150994820333
Validation loss: 2.651343176531378

Epoch: 6| Step: 3
Training loss: 2.7827504429010195
Validation loss: 2.6602785362657766

Epoch: 6| Step: 4
Training loss: 2.5020201150709167
Validation loss: 2.6289111297654286

Epoch: 6| Step: 5
Training loss: 3.166428272576389
Validation loss: 2.633108783588443

Epoch: 6| Step: 6
Training loss: 3.5700345588528704
Validation loss: 2.662800379575407

Epoch: 6| Step: 7
Training loss: 2.85596901076999
Validation loss: 2.631831067053915

Epoch: 6| Step: 8
Training loss: 3.068760603441616
Validation loss: 2.6219208203193163

Epoch: 6| Step: 9
Training loss: 2.793577925398656
Validation loss: 2.612817682301322

Epoch: 6| Step: 10
Training loss: 2.2028866902776993
Validation loss: 2.6116940138191196

Epoch: 6| Step: 11
Training loss: 2.9079265065829962
Validation loss: 2.656936778704933

Epoch: 6| Step: 12
Training loss: 3.1062279498969794
Validation loss: 2.614436713981114

Epoch: 6| Step: 13
Training loss: 2.1050459909738293
Validation loss: 2.683185749916325

Epoch: 69| Step: 0
Training loss: 3.4111223283459697
Validation loss: 2.635202157780233

Epoch: 6| Step: 1
Training loss: 2.4045872083029103
Validation loss: 2.6124836461883576

Epoch: 6| Step: 2
Training loss: 2.695814887508941
Validation loss: 2.6286900382396388

Epoch: 6| Step: 3
Training loss: 3.2804756340723196
Validation loss: 2.637168486541655

Epoch: 6| Step: 4
Training loss: 3.648446910119021
Validation loss: 2.650413527895944

Epoch: 6| Step: 5
Training loss: 2.433307857467161
Validation loss: 2.683858244614738

Epoch: 6| Step: 6
Training loss: 3.166229184365024
Validation loss: 2.6687232349868504

Epoch: 6| Step: 7
Training loss: 2.2233620647573793
Validation loss: 2.6199494159871906

Epoch: 6| Step: 8
Training loss: 2.7011014387169485
Validation loss: 2.637437959614069

Epoch: 6| Step: 9
Training loss: 2.6251414124681594
Validation loss: 2.659525651148177

Epoch: 6| Step: 10
Training loss: 3.1714638128740535
Validation loss: 2.656263841934379

Epoch: 6| Step: 11
Training loss: 3.223728366881282
Validation loss: 2.596151481368844

Epoch: 6| Step: 12
Training loss: 2.426303874797814
Validation loss: 2.652301623258024

Epoch: 6| Step: 13
Training loss: 2.799927904699493
Validation loss: 2.6124053860226697

Epoch: 70| Step: 0
Training loss: 2.688827896302145
Validation loss: 2.670122972195752

Epoch: 6| Step: 1
Training loss: 2.5680243327987444
Validation loss: 2.62633119201627

Epoch: 6| Step: 2
Training loss: 2.9853878199977664
Validation loss: 2.695591126257681

Epoch: 6| Step: 3
Training loss: 3.401470786221967
Validation loss: 2.605120049646788

Epoch: 6| Step: 4
Training loss: 3.5239663414446465
Validation loss: 2.639162498743931

Epoch: 6| Step: 5
Training loss: 2.7690988910687295
Validation loss: 2.6322862979225095

Epoch: 6| Step: 6
Training loss: 2.3560576706969942
Validation loss: 2.671468298283006

Epoch: 6| Step: 7
Training loss: 3.7781399634280297
Validation loss: 2.6592638491702765

Epoch: 6| Step: 8
Training loss: 2.6343636400514074
Validation loss: 2.6477646145474707

Epoch: 6| Step: 9
Training loss: 2.9275501643703365
Validation loss: 2.6175623990563612

Epoch: 6| Step: 10
Training loss: 2.0954967443376726
Validation loss: 2.6580770956237663

Epoch: 6| Step: 11
Training loss: 2.8342915952748933
Validation loss: 2.6277122139148874

Epoch: 6| Step: 12
Training loss: 2.549274367515745
Validation loss: 2.628883522499953

Epoch: 6| Step: 13
Training loss: 3.016488223479843
Validation loss: 2.6279347358951717

Epoch: 71| Step: 0
Training loss: 1.5256974110810582
Validation loss: 2.6697829852127217

Epoch: 6| Step: 1
Training loss: 2.3542382108456574
Validation loss: 2.6176653829001717

Epoch: 6| Step: 2
Training loss: 3.3926853652721665
Validation loss: 2.6342316702965944

Epoch: 6| Step: 3
Training loss: 2.7379898155641587
Validation loss: 2.6153007424831305

Epoch: 6| Step: 4
Training loss: 3.3839263139552562
Validation loss: 2.669642690972884

Epoch: 6| Step: 5
Training loss: 2.892193343013918
Validation loss: 2.6364098760308528

Epoch: 6| Step: 6
Training loss: 2.3703914903267203
Validation loss: 2.6251568002742824

Epoch: 6| Step: 7
Training loss: 3.172550373804743
Validation loss: 2.6276430124917893

Epoch: 6| Step: 8
Training loss: 2.5372934605019206
Validation loss: 2.607441904856668

Epoch: 6| Step: 9
Training loss: 3.0734766218277754
Validation loss: 2.647587833395595

Epoch: 6| Step: 10
Training loss: 3.592684911377078
Validation loss: 2.681339622938935

Epoch: 6| Step: 11
Training loss: 3.1678898774475677
Validation loss: 2.662594428345694

Epoch: 6| Step: 12
Training loss: 2.8865073078855286
Validation loss: 2.6381910815173146

Epoch: 6| Step: 13
Training loss: 3.114413219556525
Validation loss: 2.6068617504818694

Epoch: 72| Step: 0
Training loss: 2.8694982546003223
Validation loss: 2.623988628147026

Epoch: 6| Step: 1
Training loss: 3.3402432029945617
Validation loss: 2.5979546216979594

Epoch: 6| Step: 2
Training loss: 2.3461023351491272
Validation loss: 2.598177558031657

Epoch: 6| Step: 3
Training loss: 3.2898064358709687
Validation loss: 2.608739846709782

Epoch: 6| Step: 4
Training loss: 2.8432935411263367
Validation loss: 2.6304046983173817

Epoch: 6| Step: 5
Training loss: 2.8023343641487126
Validation loss: 2.6304459058322363

Epoch: 6| Step: 6
Training loss: 2.7468213871398923
Validation loss: 2.600061138797307

Epoch: 6| Step: 7
Training loss: 2.646671032393512
Validation loss: 2.639982140040339

Epoch: 6| Step: 8
Training loss: 3.3349713751209284
Validation loss: 2.609047198888728

Epoch: 6| Step: 9
Training loss: 3.318352190159232
Validation loss: 2.588347365909667

Epoch: 6| Step: 10
Training loss: 2.401683784951543
Validation loss: 2.6054473097277686

Epoch: 6| Step: 11
Training loss: 2.9034679592145576
Validation loss: 2.6194957405451884

Epoch: 6| Step: 12
Training loss: 2.4754747956436938
Validation loss: 2.6443907396750475

Epoch: 6| Step: 13
Training loss: 2.83936852593999
Validation loss: 2.6151419827462234

Epoch: 73| Step: 0
Training loss: 2.3353460577421115
Validation loss: 2.584992381803253

Epoch: 6| Step: 1
Training loss: 3.1825274407701314
Validation loss: 2.605090169923193

Epoch: 6| Step: 2
Training loss: 2.5093823804544915
Validation loss: 2.5984520612752195

Epoch: 6| Step: 3
Training loss: 2.924897940395691
Validation loss: 2.615975263426258

Epoch: 6| Step: 4
Training loss: 3.3375956146602768
Validation loss: 2.647228805726401

Epoch: 6| Step: 5
Training loss: 2.995022299911193
Validation loss: 2.619667490797808

Epoch: 6| Step: 6
Training loss: 2.795949601675585
Validation loss: 2.6300995666049327

Epoch: 6| Step: 7
Training loss: 2.585805376717
Validation loss: 2.609111328243498

Epoch: 6| Step: 8
Training loss: 3.6550585769989987
Validation loss: 2.6623292482976137

Epoch: 6| Step: 9
Training loss: 2.9827958167974873
Validation loss: 2.591608859067946

Epoch: 6| Step: 10
Training loss: 2.3825358245814097
Validation loss: 2.6058363695961004

Epoch: 6| Step: 11
Training loss: 3.049701807422617
Validation loss: 2.5854671605584056

Epoch: 6| Step: 12
Training loss: 2.3042868055740215
Validation loss: 2.60233618870128

Epoch: 6| Step: 13
Training loss: 3.2432588944186347
Validation loss: 2.6584220195085835

Epoch: 74| Step: 0
Training loss: 2.1368990583200738
Validation loss: 2.6685898422318917

Epoch: 6| Step: 1
Training loss: 2.3773214137958267
Validation loss: 2.5828492941356376

Epoch: 6| Step: 2
Training loss: 3.0005807314505217
Validation loss: 2.642385362146388

Epoch: 6| Step: 3
Training loss: 2.5661936864977855
Validation loss: 2.6296761637888197

Epoch: 6| Step: 4
Training loss: 2.9200601908607142
Validation loss: 2.6071364249555513

Epoch: 6| Step: 5
Training loss: 3.1228459372897146
Validation loss: 2.579404940920127

Epoch: 6| Step: 6
Training loss: 2.7548867069772633
Validation loss: 2.6181126298519826

Epoch: 6| Step: 7
Training loss: 2.8223593937169387
Validation loss: 2.6388592851320727

Epoch: 6| Step: 8
Training loss: 3.35018743303816
Validation loss: 2.6001449842708144

Epoch: 6| Step: 9
Training loss: 3.879893627674959
Validation loss: 2.6273433326115234

Epoch: 6| Step: 10
Training loss: 1.8835009190876386
Validation loss: 2.611979060011035

Epoch: 6| Step: 11
Training loss: 3.3764066237411
Validation loss: 2.631585850846908

Epoch: 6| Step: 12
Training loss: 3.005842718186061
Validation loss: 2.6233959737036727

Epoch: 6| Step: 13
Training loss: 2.805140806665674
Validation loss: 2.6362949924409254

Epoch: 75| Step: 0
Training loss: 3.5475791198639017
Validation loss: 2.6212103649196656

Epoch: 6| Step: 1
Training loss: 2.914562847146347
Validation loss: 2.646973565203977

Epoch: 6| Step: 2
Training loss: 2.8090048371080174
Validation loss: 2.5782662261933615

Epoch: 6| Step: 3
Training loss: 2.4009738893245003
Validation loss: 2.5968642700379574

Epoch: 6| Step: 4
Training loss: 3.259162019553822
Validation loss: 2.6201803179695626

Epoch: 6| Step: 5
Training loss: 3.716200010372133
Validation loss: 2.6429658026400538

Epoch: 6| Step: 6
Training loss: 2.3440387802235993
Validation loss: 2.6232621719673506

Epoch: 6| Step: 7
Training loss: 3.075646966624366
Validation loss: 2.6454206078072953

Epoch: 6| Step: 8
Training loss: 2.528894058023737
Validation loss: 2.631866297709509

Epoch: 6| Step: 9
Training loss: 2.6149793732743185
Validation loss: 2.5843819026034227

Epoch: 6| Step: 10
Training loss: 2.607198024098905
Validation loss: 2.604515283363927

Epoch: 6| Step: 11
Training loss: 3.215469911207059
Validation loss: 2.5988309119065387

Epoch: 6| Step: 12
Training loss: 2.3184106912694165
Validation loss: 2.6050919560441543

Epoch: 6| Step: 13
Training loss: 2.698792530199984
Validation loss: 2.607277412033574

Testing loss: 2.612310731431222
