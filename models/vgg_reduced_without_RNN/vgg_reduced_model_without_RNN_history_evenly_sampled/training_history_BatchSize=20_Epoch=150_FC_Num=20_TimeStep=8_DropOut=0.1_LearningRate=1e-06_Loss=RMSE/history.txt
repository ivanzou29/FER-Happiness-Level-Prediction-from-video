Epoch: 1| Step: 0
Training loss: 4.741171009905255
Validation loss: 4.406236704248695

Epoch: 5| Step: 1
Training loss: 4.220215945390996
Validation loss: 4.4084507073312995

Epoch: 5| Step: 2
Training loss: 4.502381860008109
Validation loss: 4.402452121285204

Epoch: 5| Step: 3
Training loss: 4.717870971454804
Validation loss: 4.396160515768438

Epoch: 5| Step: 4
Training loss: 4.266418606779166
Validation loss: 4.392004913855262

Epoch: 5| Step: 5
Training loss: 4.171450475459809
Validation loss: 4.383816231062602

Epoch: 5| Step: 6
Training loss: 5.098801991991849
Validation loss: 4.381142696722375

Epoch: 5| Step: 7
Training loss: 4.435117699954667
Validation loss: 4.376074545022794

Epoch: 5| Step: 8
Training loss: 4.307240693030204
Validation loss: 4.378156694526154

Epoch: 5| Step: 9
Training loss: 4.905644081750277
Validation loss: 4.37286917366133

Epoch: 5| Step: 10
Training loss: 4.059668860249911
Validation loss: 4.368581470680736

Epoch: 2| Step: 0
Training loss: 4.837777079057115
Validation loss: 4.3609380402710185

Epoch: 5| Step: 1
Training loss: 4.860685411008917
Validation loss: 4.357861189017478

Epoch: 5| Step: 2
Training loss: 4.184745679850724
Validation loss: 4.35339036770528

Epoch: 5| Step: 3
Training loss: 4.928191282882464
Validation loss: 4.346587613961771

Epoch: 5| Step: 4
Training loss: 4.706317819053493
Validation loss: 4.348034066727214

Epoch: 5| Step: 5
Training loss: 4.256747555323884
Validation loss: 4.339844361987819

Epoch: 5| Step: 6
Training loss: 3.861954541255392
Validation loss: 4.336168108964679

Epoch: 5| Step: 7
Training loss: 3.967829680179159
Validation loss: 4.331457412759252

Epoch: 5| Step: 8
Training loss: 5.212014425882794
Validation loss: 4.325911296412544

Epoch: 5| Step: 9
Training loss: 3.683461450848603
Validation loss: 4.322182007904362

Epoch: 5| Step: 10
Training loss: 4.345321480783936
Validation loss: 4.318596329390404

Epoch: 3| Step: 0
Training loss: 4.346644911994399
Validation loss: 4.314117072581127

Epoch: 5| Step: 1
Training loss: 4.041268843640219
Validation loss: 4.305837824991171

Epoch: 5| Step: 2
Training loss: 4.5361341790565755
Validation loss: 4.30111370120772

Epoch: 5| Step: 3
Training loss: 4.758128990333013
Validation loss: 4.296824863771531

Epoch: 5| Step: 4
Training loss: 5.022829769505694
Validation loss: 4.293405895849231

Epoch: 5| Step: 5
Training loss: 4.644284228147679
Validation loss: 4.287721429595533

Epoch: 5| Step: 6
Training loss: 3.235899192918555
Validation loss: 4.283130114062118

Epoch: 5| Step: 7
Training loss: 4.645598857533567
Validation loss: 4.278236638271424

Epoch: 5| Step: 8
Training loss: 3.8407146595483157
Validation loss: 4.273989353150989

Epoch: 5| Step: 9
Training loss: 4.583036008496527
Validation loss: 4.268283626542787

Epoch: 5| Step: 10
Training loss: 4.687858059241315
Validation loss: 4.263801973359428

Epoch: 4| Step: 0
Training loss: 4.197537817634137
Validation loss: 4.257179373190472

Epoch: 5| Step: 1
Training loss: 4.844818391181477
Validation loss: 4.2498744147395255

Epoch: 5| Step: 2
Training loss: 4.7584909541028155
Validation loss: 4.246547276080765

Epoch: 5| Step: 3
Training loss: 4.903551659580414
Validation loss: 4.242275848311722

Epoch: 5| Step: 4
Training loss: 3.9233787055188727
Validation loss: 4.235633416387968

Epoch: 5| Step: 5
Training loss: 4.007453411590625
Validation loss: 4.228106981180908

Epoch: 5| Step: 6
Training loss: 4.626810492736152
Validation loss: 4.225425913886585

Epoch: 5| Step: 7
Training loss: 4.176312204974964
Validation loss: 4.221066478288671

Epoch: 5| Step: 8
Training loss: 3.8811269743705274
Validation loss: 4.2147522403697

Epoch: 5| Step: 9
Training loss: 4.495318626847797
Validation loss: 4.2064670789224055

Epoch: 5| Step: 10
Training loss: 3.93739439807547
Validation loss: 4.200162505401268

Epoch: 5| Step: 0
Training loss: 4.727834886524
Validation loss: 4.196897911907362

Epoch: 5| Step: 1
Training loss: 4.817867505992444
Validation loss: 4.190359660818211

Epoch: 5| Step: 2
Training loss: 4.553994179984534
Validation loss: 4.183663783307756

Epoch: 5| Step: 3
Training loss: 4.686806996298935
Validation loss: 4.180129626058445

Epoch: 5| Step: 4
Training loss: 3.679245195310358
Validation loss: 4.171650721542158

Epoch: 5| Step: 5
Training loss: 4.378510946488602
Validation loss: 4.170335128513101

Epoch: 5| Step: 6
Training loss: 3.5223412679803863
Validation loss: 4.163309651472185

Epoch: 5| Step: 7
Training loss: 3.939359316751526
Validation loss: 4.155421480765442

Epoch: 5| Step: 8
Training loss: 4.212620556292003
Validation loss: 4.154962655342342

Epoch: 5| Step: 9
Training loss: 4.707329071880019
Validation loss: 4.147142208716676

Epoch: 5| Step: 10
Training loss: 3.843039718379004
Validation loss: 4.143835273379632

Epoch: 6| Step: 0
Training loss: 3.7276160712178843
Validation loss: 4.137375108919369

Epoch: 5| Step: 1
Training loss: 3.826735388330346
Validation loss: 4.1340007859015016

Epoch: 5| Step: 2
Training loss: 4.019070464508135
Validation loss: 4.124133010544688

Epoch: 5| Step: 3
Training loss: 3.8934372385957103
Validation loss: 4.119484596024589

Epoch: 5| Step: 4
Training loss: 3.7350376451017397
Validation loss: 4.11738290599538

Epoch: 5| Step: 5
Training loss: 3.4174053665152035
Validation loss: 4.109887192758898

Epoch: 5| Step: 6
Training loss: 5.151953739562762
Validation loss: 4.10321302980628

Epoch: 5| Step: 7
Training loss: 5.25943398944052
Validation loss: 4.0956392053531685

Epoch: 5| Step: 8
Training loss: 4.961073409494124
Validation loss: 4.091833455518938

Epoch: 5| Step: 9
Training loss: 4.346042823801712
Validation loss: 4.0894865310229465

Epoch: 5| Step: 10
Training loss: 3.8173705710983055
Validation loss: 4.079026766208562

Epoch: 7| Step: 0
Training loss: 4.557439636734695
Validation loss: 4.070495990573215

Epoch: 5| Step: 1
Training loss: 3.4928234639217126
Validation loss: 4.0664985774473354

Epoch: 5| Step: 2
Training loss: 4.720764134509569
Validation loss: 4.058102845476341

Epoch: 5| Step: 3
Training loss: 4.241163154700035
Validation loss: 4.050956919801391

Epoch: 5| Step: 4
Training loss: 4.6213469641503355
Validation loss: 4.0437664991675755

Epoch: 5| Step: 5
Training loss: 3.516003261985611
Validation loss: 4.040592216127313

Epoch: 5| Step: 6
Training loss: 4.368099765658306
Validation loss: 4.034246038695417

Epoch: 5| Step: 7
Training loss: 3.4849959705389693
Validation loss: 4.028523420924345

Epoch: 5| Step: 8
Training loss: 4.614372828427656
Validation loss: 4.017880409955955

Epoch: 5| Step: 9
Training loss: 4.592418451722118
Validation loss: 4.010237883199944

Epoch: 5| Step: 10
Training loss: 3.2856878877846962
Validation loss: 4.005868498440406

Epoch: 8| Step: 0
Training loss: 3.847209830939348
Validation loss: 3.998946161294916

Epoch: 5| Step: 1
Training loss: 3.647680167231907
Validation loss: 3.997643779175577

Epoch: 5| Step: 2
Training loss: 4.123693548291945
Validation loss: 3.9851954143705464

Epoch: 5| Step: 3
Training loss: 4.265353127782915
Validation loss: 3.984000103223331

Epoch: 5| Step: 4
Training loss: 4.1714500182210745
Validation loss: 3.971344011987392

Epoch: 5| Step: 5
Training loss: 4.273787851983269
Validation loss: 3.9640751685625206

Epoch: 5| Step: 6
Training loss: 3.888282652937636
Validation loss: 3.9580470363185736

Epoch: 5| Step: 7
Training loss: 4.003095621065228
Validation loss: 3.9508276814065177

Epoch: 5| Step: 8
Training loss: 4.415088851570344
Validation loss: 3.948753369354752

Epoch: 5| Step: 9
Training loss: 3.5091854543612517
Validation loss: 3.9378974350668967

Epoch: 5| Step: 10
Training loss: 5.067266410333191
Validation loss: 3.9355641945566964

Epoch: 9| Step: 0
Training loss: 3.4028171424578315
Validation loss: 3.9213111471131707

Epoch: 5| Step: 1
Training loss: 4.110547496777844
Validation loss: 3.9141119875100614

Epoch: 5| Step: 2
Training loss: 4.310406605244923
Validation loss: 3.90483557247806

Epoch: 5| Step: 3
Training loss: 4.105703359881922
Validation loss: 3.8991819902160447

Epoch: 5| Step: 4
Training loss: 4.284584695816504
Validation loss: 3.8941953430287715

Epoch: 5| Step: 5
Training loss: 4.364768571344475
Validation loss: 3.878215716474362

Epoch: 5| Step: 6
Training loss: 3.788017710941405
Validation loss: 3.870239587417834

Epoch: 5| Step: 7
Training loss: 3.2285704195573195
Validation loss: 3.8700542107769595

Epoch: 5| Step: 8
Training loss: 3.5562075540325817
Validation loss: 3.8564286414172773

Epoch: 5| Step: 9
Training loss: 5.018096410014478
Validation loss: 3.8515533172259

Epoch: 5| Step: 10
Training loss: 3.918136334472073
Validation loss: 3.840714727632349

Epoch: 10| Step: 0
Training loss: 3.813445427409711
Validation loss: 3.835837442902476

Epoch: 5| Step: 1
Training loss: 4.074523972867107
Validation loss: 3.823978657575344

Epoch: 5| Step: 2
Training loss: 3.383634894576021
Validation loss: 3.8136898331182056

Epoch: 5| Step: 3
Training loss: 3.8949389459528367
Validation loss: 3.80675082389028

Epoch: 5| Step: 4
Training loss: 3.4496747900231677
Validation loss: 3.8003264157999674

Epoch: 5| Step: 5
Training loss: 4.417392359200952
Validation loss: 3.7916662835291457

Epoch: 5| Step: 6
Training loss: 2.9733183395395435
Validation loss: 3.7811987383656076

Epoch: 5| Step: 7
Training loss: 4.147716739778933
Validation loss: 3.77409058854543

Epoch: 5| Step: 8
Training loss: 4.281832690160072
Validation loss: 3.7646859959420804

Epoch: 5| Step: 9
Training loss: 4.350002700980214
Validation loss: 3.75326101785069

Epoch: 5| Step: 10
Training loss: 4.433487058187628
Validation loss: 3.7421219743558924

Epoch: 11| Step: 0
Training loss: 3.5144959395750552
Validation loss: 3.727976157264141

Epoch: 5| Step: 1
Training loss: 4.615423856470598
Validation loss: 3.724265241837285

Epoch: 5| Step: 2
Training loss: 3.0953930431749437
Validation loss: 3.711741360275007

Epoch: 5| Step: 3
Training loss: 3.874774311015251
Validation loss: 3.7061730305363683

Epoch: 5| Step: 4
Training loss: 3.819528323707076
Validation loss: 3.6898673863301017

Epoch: 5| Step: 5
Training loss: 4.038430140446604
Validation loss: 3.6836603390257183

Epoch: 5| Step: 6
Training loss: 4.131993463191635
Validation loss: 3.6728372933125786

Epoch: 5| Step: 7
Training loss: 4.148443477073142
Validation loss: 3.661917246864237

Epoch: 5| Step: 8
Training loss: 3.231861556893303
Validation loss: 3.6480328967336075

Epoch: 5| Step: 9
Training loss: 3.9116954232128522
Validation loss: 3.641523261393555

Epoch: 5| Step: 10
Training loss: 3.7200149820907953
Validation loss: 3.6287248743332237

Epoch: 12| Step: 0
Training loss: 3.9477228336845327
Validation loss: 3.617877221234306

Epoch: 5| Step: 1
Training loss: 3.8909567572769954
Validation loss: 3.6051713613765597

Epoch: 5| Step: 2
Training loss: 3.8332811158535165
Validation loss: 3.590781166797903

Epoch: 5| Step: 3
Training loss: 3.433686655499703
Validation loss: 3.581864824223278

Epoch: 5| Step: 4
Training loss: 3.287374829132193
Validation loss: 3.5745484530264227

Epoch: 5| Step: 5
Training loss: 4.282870466305553
Validation loss: 3.5590478837333803

Epoch: 5| Step: 6
Training loss: 4.200714441115451
Validation loss: 3.5499335256635836

Epoch: 5| Step: 7
Training loss: 4.154851692573427
Validation loss: 3.5393035871025695

Epoch: 5| Step: 8
Training loss: 2.443650238264264
Validation loss: 3.525575858096951

Epoch: 5| Step: 9
Training loss: 3.5351903755690604
Validation loss: 3.5207607618351133

Epoch: 5| Step: 10
Training loss: 3.784426781247336
Validation loss: 3.498565842918872

Epoch: 13| Step: 0
Training loss: 3.6658076378217404
Validation loss: 3.48713850033375

Epoch: 5| Step: 1
Training loss: 2.6206110639176576
Validation loss: 3.4774362113048367

Epoch: 5| Step: 2
Training loss: 3.4659034114967353
Validation loss: 3.4597633114606214

Epoch: 5| Step: 3
Training loss: 4.14163092144304
Validation loss: 3.450703038957679

Epoch: 5| Step: 4
Training loss: 4.090885237421949
Validation loss: 3.4374105701018944

Epoch: 5| Step: 5
Training loss: 3.14062332988334
Validation loss: 3.431940471230617

Epoch: 5| Step: 6
Training loss: 3.798756702212578
Validation loss: 3.407619830451984

Epoch: 5| Step: 7
Training loss: 3.3887917621083763
Validation loss: 3.4056337553070692

Epoch: 5| Step: 8
Training loss: 4.162277554820122
Validation loss: 3.3878345033283925

Epoch: 5| Step: 9
Training loss: 3.310908961116828
Validation loss: 3.3678933936818223

Epoch: 5| Step: 10
Training loss: 3.78986380058085
Validation loss: 3.366494049241046

Epoch: 14| Step: 0
Training loss: 3.899113353786821
Validation loss: 3.3535374885877585

Epoch: 5| Step: 1
Training loss: 3.9885127105950313
Validation loss: 3.331689397426793

Epoch: 5| Step: 2
Training loss: 2.5794122430078255
Validation loss: 3.317971088543592

Epoch: 5| Step: 3
Training loss: 3.8135422079417096
Validation loss: 3.300894596284506

Epoch: 5| Step: 4
Training loss: 2.796776284974506
Validation loss: 3.2911858226269883

Epoch: 5| Step: 5
Training loss: 3.596040344173211
Validation loss: 3.277569710039514

Epoch: 5| Step: 6
Training loss: 3.1883605094691356
Validation loss: 3.262017115779117

Epoch: 5| Step: 7
Training loss: 3.865247328371739
Validation loss: 3.2481843942696353

Epoch: 5| Step: 8
Training loss: 3.4947302519646035
Validation loss: 3.2340302048006877

Epoch: 5| Step: 9
Training loss: 3.2948567508939037
Validation loss: 3.21804607852835

Epoch: 5| Step: 10
Training loss: 3.645845002655246
Validation loss: 3.209467443052697

Epoch: 15| Step: 0
Training loss: 3.609431278731289
Validation loss: 3.1932452174884376

Epoch: 5| Step: 1
Training loss: 3.5506821420265227
Validation loss: 3.183785104502372

Epoch: 5| Step: 2
Training loss: 3.5646334500619807
Validation loss: 3.168111643638519

Epoch: 5| Step: 3
Training loss: 3.342861449642924
Validation loss: 3.154236123313269

Epoch: 5| Step: 4
Training loss: 2.637622638761898
Validation loss: 3.1355585544413187

Epoch: 5| Step: 5
Training loss: 3.489282137649606
Validation loss: 3.117839378168201

Epoch: 5| Step: 6
Training loss: 3.5064732771175726
Validation loss: 3.112214804469117

Epoch: 5| Step: 7
Training loss: 3.1083080819121
Validation loss: 3.0923762175231095

Epoch: 5| Step: 8
Training loss: 3.2341155164632145
Validation loss: 3.0936553599198153

Epoch: 5| Step: 9
Training loss: 3.366029473867588
Validation loss: 3.0725899221081985

Epoch: 5| Step: 10
Training loss: 3.4005796499371113
Validation loss: 3.0516818404522055

Epoch: 16| Step: 0
Training loss: 3.695769138631634
Validation loss: 3.0327044085729713

Epoch: 5| Step: 1
Training loss: 3.009624777437273
Validation loss: 3.0291627515031894

Epoch: 5| Step: 2
Training loss: 2.7665320164496148
Validation loss: 3.0045310808282655

Epoch: 5| Step: 3
Training loss: 3.5972959853718
Validation loss: 2.994226324463862

Epoch: 5| Step: 4
Training loss: 3.1123584638533415
Validation loss: 2.981813571679349

Epoch: 5| Step: 5
Training loss: 3.591344675262747
Validation loss: 2.964809336407108

Epoch: 5| Step: 6
Training loss: 3.491582011529631
Validation loss: 2.9486083561337675

Epoch: 5| Step: 7
Training loss: 2.8173237442356505
Validation loss: 2.9407208356924133

Epoch: 5| Step: 8
Training loss: 2.9180364026419467
Validation loss: 2.9336693370862164

Epoch: 5| Step: 9
Training loss: 3.4231434043290623
Validation loss: 2.905549307941251

Epoch: 5| Step: 10
Training loss: 2.8755494297629896
Validation loss: 2.8999114949147704

Epoch: 17| Step: 0
Training loss: 3.623909227097538
Validation loss: 2.887917545683077

Epoch: 5| Step: 1
Training loss: 2.7968138789312684
Validation loss: 2.867453659654023

Epoch: 5| Step: 2
Training loss: 3.0379341600125715
Validation loss: 2.8570889796393786

Epoch: 5| Step: 3
Training loss: 3.0364527148832203
Validation loss: 2.8382649098898596

Epoch: 5| Step: 4
Training loss: 3.0926291236657217
Validation loss: 2.8228873561746166

Epoch: 5| Step: 5
Training loss: 3.223232370377933
Validation loss: 2.8170009679934944

Epoch: 5| Step: 6
Training loss: 3.254071106690052
Validation loss: 2.795516686518536

Epoch: 5| Step: 7
Training loss: 3.0621661568676553
Validation loss: 2.78290868347665

Epoch: 5| Step: 8
Training loss: 2.624279377433732
Validation loss: 2.787841667559207

Epoch: 5| Step: 9
Training loss: 3.576325742952136
Validation loss: 2.768207599086384

Epoch: 5| Step: 10
Training loss: 2.692263528964672
Validation loss: 2.753835484987432

Epoch: 18| Step: 0
Training loss: 3.110178321313531
Validation loss: 2.7401109453525487

Epoch: 5| Step: 1
Training loss: 2.0233997945328612
Validation loss: 2.733294397645064

Epoch: 5| Step: 2
Training loss: 3.3019764559002875
Validation loss: 2.7191750968842725

Epoch: 5| Step: 3
Training loss: 2.903095625450573
Validation loss: 2.716419258631432

Epoch: 5| Step: 4
Training loss: 3.100471669892448
Validation loss: 2.7024378650361474

Epoch: 5| Step: 5
Training loss: 2.5437071588081297
Validation loss: 2.698316010433089

Epoch: 5| Step: 6
Training loss: 3.353882740079638
Validation loss: 2.6878019231494994

Epoch: 5| Step: 7
Training loss: 3.1999153245213297
Validation loss: 2.669608964290355

Epoch: 5| Step: 8
Training loss: 2.888019108864923
Validation loss: 2.666566668706935

Epoch: 5| Step: 9
Training loss: 3.3808294743406258
Validation loss: 2.6654041811401536

Epoch: 5| Step: 10
Training loss: 3.081174782227593
Validation loss: 2.650742196218193

Epoch: 19| Step: 0
Training loss: 2.870871357511408
Validation loss: 2.640390607917805

Epoch: 5| Step: 1
Training loss: 3.3171791281394594
Validation loss: 2.6470767296944078

Epoch: 5| Step: 2
Training loss: 2.405044650101518
Validation loss: 2.623456013545097

Epoch: 5| Step: 3
Training loss: 3.3039825625479025
Validation loss: 2.620253780736139

Epoch: 5| Step: 4
Training loss: 3.14007077617211
Validation loss: 2.6142915521143957

Epoch: 5| Step: 5
Training loss: 2.981405008632757
Validation loss: 2.599858956143809

Epoch: 5| Step: 6
Training loss: 2.2833192402574127
Validation loss: 2.5920254672005347

Epoch: 5| Step: 7
Training loss: 3.3185111152034
Validation loss: 2.5895010478717913

Epoch: 5| Step: 8
Training loss: 2.8404073667511565
Validation loss: 2.5855605408294355

Epoch: 5| Step: 9
Training loss: 2.8826262457828236
Validation loss: 2.5884410463656553

Epoch: 5| Step: 10
Training loss: 3.085820372084936
Validation loss: 2.578693109280782

Epoch: 20| Step: 0
Training loss: 2.8937122251875196
Validation loss: 2.563156382014316

Epoch: 5| Step: 1
Training loss: 3.164067623934894
Validation loss: 2.5480616759464345

Epoch: 5| Step: 2
Training loss: 3.080216834622364
Validation loss: 2.56293889570748

Epoch: 5| Step: 3
Training loss: 2.2136851784054112
Validation loss: 2.546020600040137

Epoch: 5| Step: 4
Training loss: 3.003061163280367
Validation loss: 2.5617293012482456

Epoch: 5| Step: 5
Training loss: 3.4008163369715367
Validation loss: 2.532168017438122

Epoch: 5| Step: 6
Training loss: 3.018284390953386
Validation loss: 2.5316412408268323

Epoch: 5| Step: 7
Training loss: 2.883148587285641
Validation loss: 2.545218756529544

Epoch: 5| Step: 8
Training loss: 2.091293716110546
Validation loss: 2.539519669461958

Epoch: 5| Step: 9
Training loss: 3.083772232847626
Validation loss: 2.5250404361982546

Epoch: 5| Step: 10
Training loss: 3.0233504408492897
Validation loss: 2.5191159060459816

Epoch: 21| Step: 0
Training loss: 3.0700082409776055
Validation loss: 2.527752033097884

Epoch: 5| Step: 1
Training loss: 3.210028526678516
Validation loss: 2.5187600529728953

Epoch: 5| Step: 2
Training loss: 2.3033071748689924
Validation loss: 2.5300094378051057

Epoch: 5| Step: 3
Training loss: 3.4276634274174693
Validation loss: 2.498716952140209

Epoch: 5| Step: 4
Training loss: 2.747608705683606
Validation loss: 2.522077448848435

Epoch: 5| Step: 5
Training loss: 2.872178725161869
Validation loss: 2.5006245438007415

Epoch: 5| Step: 6
Training loss: 3.0636138447483696
Validation loss: 2.5099507262273115

Epoch: 5| Step: 7
Training loss: 2.4530582297404426
Validation loss: 2.502895889898089

Epoch: 5| Step: 8
Training loss: 2.7826491704749317
Validation loss: 2.5177121017418145

Epoch: 5| Step: 9
Training loss: 2.8853652527195863
Validation loss: 2.5106070556120246

Epoch: 5| Step: 10
Training loss: 3.0463311125640113
Validation loss: 2.516070479898099

Epoch: 22| Step: 0
Training loss: 2.2460204004667332
Validation loss: 2.50611496902912

Epoch: 5| Step: 1
Training loss: 2.726703804092756
Validation loss: 2.4998874454387456

Epoch: 5| Step: 2
Training loss: 2.9478878024320294
Validation loss: 2.5103244447131554

Epoch: 5| Step: 3
Training loss: 3.0447596322635584
Validation loss: 2.500864169776903

Epoch: 5| Step: 4
Training loss: 2.957863049445478
Validation loss: 2.5032696149681306

Epoch: 5| Step: 5
Training loss: 2.969699105584598
Validation loss: 2.4860778223249027

Epoch: 5| Step: 6
Training loss: 3.4276969538110467
Validation loss: 2.50818924055794

Epoch: 5| Step: 7
Training loss: 2.6624081304756144
Validation loss: 2.496924658140388

Epoch: 5| Step: 8
Training loss: 2.942840105105323
Validation loss: 2.506791090393439

Epoch: 5| Step: 9
Training loss: 2.9282822150463965
Validation loss: 2.5000857861474612

Epoch: 5| Step: 10
Training loss: 2.7738737381114036
Validation loss: 2.4894987900233767

Epoch: 23| Step: 0
Training loss: 3.1669280462977443
Validation loss: 2.506728086487632

Epoch: 5| Step: 1
Training loss: 3.228885580975538
Validation loss: 2.4906885782379726

Epoch: 5| Step: 2
Training loss: 2.9622564674427245
Validation loss: 2.4775453268859065

Epoch: 5| Step: 3
Training loss: 2.4320523935998675
Validation loss: 2.490469891877825

Epoch: 5| Step: 4
Training loss: 3.1062383885617515
Validation loss: 2.4763247493978704

Epoch: 5| Step: 5
Training loss: 2.5318841022223313
Validation loss: 2.4849449737531493

Epoch: 5| Step: 6
Training loss: 2.3781975753878326
Validation loss: 2.489189314137225

Epoch: 5| Step: 7
Training loss: 3.60195940524138
Validation loss: 2.484210721378189

Epoch: 5| Step: 8
Training loss: 2.705709291494666
Validation loss: 2.486281055065174

Epoch: 5| Step: 9
Training loss: 3.143404968621277
Validation loss: 2.485997191577889

Epoch: 5| Step: 10
Training loss: 2.114173235534078
Validation loss: 2.4980190591478073

Epoch: 24| Step: 0
Training loss: 3.4618927130424204
Validation loss: 2.4938039722780965

Epoch: 5| Step: 1
Training loss: 2.7206042751694546
Validation loss: 2.490795135255655

Epoch: 5| Step: 2
Training loss: 2.775761020542666
Validation loss: 2.498371081709796

Epoch: 5| Step: 3
Training loss: 2.7945538484439743
Validation loss: 2.491314314080331

Epoch: 5| Step: 4
Training loss: 3.0037500467352003
Validation loss: 2.4878021967523303

Epoch: 5| Step: 5
Training loss: 2.9651296927535284
Validation loss: 2.4856949829542763

Epoch: 5| Step: 6
Training loss: 2.7624907756668673
Validation loss: 2.482669058097085

Epoch: 5| Step: 7
Training loss: 3.0396608680491024
Validation loss: 2.495501257522683

Epoch: 5| Step: 8
Training loss: 3.0199408604976554
Validation loss: 2.4869825357445343

Epoch: 5| Step: 9
Training loss: 2.522974591859421
Validation loss: 2.4926806536187742

Epoch: 5| Step: 10
Training loss: 2.4808935567584958
Validation loss: 2.4823384320850335

Epoch: 25| Step: 0
Training loss: 2.923099037040428
Validation loss: 2.4845475472094662

Epoch: 5| Step: 1
Training loss: 3.6492338761294034
Validation loss: 2.4824163644130395

Epoch: 5| Step: 2
Training loss: 2.563728782234943
Validation loss: 2.4767642653412927

Epoch: 5| Step: 3
Training loss: 2.566367138894094
Validation loss: 2.488736625527455

Epoch: 5| Step: 4
Training loss: 2.7661858975877647
Validation loss: 2.501964319851263

Epoch: 5| Step: 5
Training loss: 2.8326305939078904
Validation loss: 2.4916306305974874

Epoch: 5| Step: 6
Training loss: 2.589404498978921
Validation loss: 2.4916473903055096

Epoch: 5| Step: 7
Training loss: 2.9445644410191556
Validation loss: 2.4982286638357856

Epoch: 5| Step: 8
Training loss: 3.0342306053621093
Validation loss: 2.5035996333086756

Epoch: 5| Step: 9
Training loss: 2.933575219960619
Validation loss: 2.493632217723389

Epoch: 5| Step: 10
Training loss: 2.6645110079981214
Validation loss: 2.4806776756360716

Epoch: 26| Step: 0
Training loss: 3.2230253990751447
Validation loss: 2.4817833266086735

Epoch: 5| Step: 1
Training loss: 2.966521058813305
Validation loss: 2.4912905875905538

Epoch: 5| Step: 2
Training loss: 3.778676946692885
Validation loss: 2.492693225571806

Epoch: 5| Step: 3
Training loss: 2.6936586475149884
Validation loss: 2.4820431392888618

Epoch: 5| Step: 4
Training loss: 2.470598132650602
Validation loss: 2.4832611884165754

Epoch: 5| Step: 5
Training loss: 2.2588458484944787
Validation loss: 2.4851035001097133

Epoch: 5| Step: 6
Training loss: 3.443781713765469
Validation loss: 2.493784021209284

Epoch: 5| Step: 7
Training loss: 2.8961470363130433
Validation loss: 2.4751044628263905

Epoch: 5| Step: 8
Training loss: 2.18498259513435
Validation loss: 2.47705012870963

Epoch: 5| Step: 9
Training loss: 2.7658477521081664
Validation loss: 2.4823793184104437

Epoch: 5| Step: 10
Training loss: 2.493443761392915
Validation loss: 2.4852750508264063

Epoch: 27| Step: 0
Training loss: 2.797140439187072
Validation loss: 2.478469040759343

Epoch: 5| Step: 1
Training loss: 2.790710646114956
Validation loss: 2.4911942499786197

Epoch: 5| Step: 2
Training loss: 3.003561766556909
Validation loss: 2.49841668022948

Epoch: 5| Step: 3
Training loss: 2.943899934032106
Validation loss: 2.476519625335234

Epoch: 5| Step: 4
Training loss: 2.866098139816239
Validation loss: 2.4932100194830418

Epoch: 5| Step: 5
Training loss: 3.04405089346088
Validation loss: 2.495442165218682

Epoch: 5| Step: 6
Training loss: 2.8137972065419814
Validation loss: 2.4923877823962233

Epoch: 5| Step: 7
Training loss: 3.0246385657916743
Validation loss: 2.489512104037136

Epoch: 5| Step: 8
Training loss: 2.7432836531647964
Validation loss: 2.4805057418554415

Epoch: 5| Step: 9
Training loss: 3.0682749891423655
Validation loss: 2.4944028001325846

Epoch: 5| Step: 10
Training loss: 2.4694311433635816
Validation loss: 2.482341439457804

Epoch: 28| Step: 0
Training loss: 2.9020015057823434
Validation loss: 2.4892427803038526

Epoch: 5| Step: 1
Training loss: 2.9458004170421828
Validation loss: 2.4858885148475522

Epoch: 5| Step: 2
Training loss: 2.920940555739465
Validation loss: 2.482736923707311

Epoch: 5| Step: 3
Training loss: 3.013440225218811
Validation loss: 2.489506022170708

Epoch: 5| Step: 4
Training loss: 3.224666749754563
Validation loss: 2.493765582198581

Epoch: 5| Step: 5
Training loss: 2.769211421087931
Validation loss: 2.499473309154531

Epoch: 5| Step: 6
Training loss: 2.8549794248784863
Validation loss: 2.4909885405452674

Epoch: 5| Step: 7
Training loss: 2.967304560485036
Validation loss: 2.4958596409992615

Epoch: 5| Step: 8
Training loss: 2.880393897776423
Validation loss: 2.5062639005861285

Epoch: 5| Step: 9
Training loss: 2.0782039311842917
Validation loss: 2.4790811104272015

Epoch: 5| Step: 10
Training loss: 3.1876123445945588
Validation loss: 2.4870983089871994

Epoch: 29| Step: 0
Training loss: 3.3244098110854226
Validation loss: 2.5018333306539735

Epoch: 5| Step: 1
Training loss: 2.760937354924922
Validation loss: 2.49491549452243

Epoch: 5| Step: 2
Training loss: 2.7382231745635783
Validation loss: 2.478035193895148

Epoch: 5| Step: 3
Training loss: 2.5378958031658927
Validation loss: 2.4873581467662507

Epoch: 5| Step: 4
Training loss: 2.617075721289534
Validation loss: 2.4957950134748557

Epoch: 5| Step: 5
Training loss: 2.817949483333386
Validation loss: 2.495068150318137

Epoch: 5| Step: 6
Training loss: 3.0369949172061896
Validation loss: 2.4961914975932333

Epoch: 5| Step: 7
Training loss: 3.0887376659830945
Validation loss: 2.477850732188102

Epoch: 5| Step: 8
Training loss: 3.108618256001829
Validation loss: 2.4885123344169324

Epoch: 5| Step: 9
Training loss: 2.247332050807832
Validation loss: 2.495746297772351

Epoch: 5| Step: 10
Training loss: 3.3186993438820287
Validation loss: 2.4683322410245676

Epoch: 30| Step: 0
Training loss: 2.6147792383082535
Validation loss: 2.494012067599936

Epoch: 5| Step: 1
Training loss: 2.8202052214869915
Validation loss: 2.495747142133914

Epoch: 5| Step: 2
Training loss: 3.337057528650641
Validation loss: 2.47230406879132

Epoch: 5| Step: 3
Training loss: 2.762719044696362
Validation loss: 2.4834558054814493

Epoch: 5| Step: 4
Training loss: 3.077557351688135
Validation loss: 2.4734245573322973

Epoch: 5| Step: 5
Training loss: 2.840294215852467
Validation loss: 2.4936269714517727

Epoch: 5| Step: 6
Training loss: 3.1140089919512315
Validation loss: 2.4929847343507925

Epoch: 5| Step: 7
Training loss: 2.81963519895427
Validation loss: 2.473604600333194

Epoch: 5| Step: 8
Training loss: 2.4706426198433826
Validation loss: 2.4880629414247744

Epoch: 5| Step: 9
Training loss: 2.887363057377763
Validation loss: 2.4834229650988653

Epoch: 5| Step: 10
Training loss: 2.7178964261495264
Validation loss: 2.486328457012586

Epoch: 31| Step: 0
Training loss: 2.3976610150729574
Validation loss: 2.479332887725494

Epoch: 5| Step: 1
Training loss: 2.879381075952643
Validation loss: 2.4856235681435455

Epoch: 5| Step: 2
Training loss: 2.5639120723805413
Validation loss: 2.4888158747939486

Epoch: 5| Step: 3
Training loss: 3.036623723982319
Validation loss: 2.4997096077633367

Epoch: 5| Step: 4
Training loss: 2.7394126481139582
Validation loss: 2.4915188966725843

Epoch: 5| Step: 5
Training loss: 3.253053551144864
Validation loss: 2.471617143195818

Epoch: 5| Step: 6
Training loss: 2.729784529150981
Validation loss: 2.4923407168420706

Epoch: 5| Step: 7
Training loss: 2.7710043966698295
Validation loss: 2.4903083717246983

Epoch: 5| Step: 8
Training loss: 3.165592981988099
Validation loss: 2.4873155365216797

Epoch: 5| Step: 9
Training loss: 2.7973259929849172
Validation loss: 2.489403284164344

Epoch: 5| Step: 10
Training loss: 3.0396301210152212
Validation loss: 2.4959815143548023

Epoch: 32| Step: 0
Training loss: 2.8065599232156253
Validation loss: 2.4746683670226575

Epoch: 5| Step: 1
Training loss: 2.699127858200825
Validation loss: 2.487013453048752

Epoch: 5| Step: 2
Training loss: 2.7924969894953033
Validation loss: 2.48734982204627

Epoch: 5| Step: 3
Training loss: 1.9906740311313715
Validation loss: 2.4882905040091154

Epoch: 5| Step: 4
Training loss: 3.165617082892833
Validation loss: 2.4904491611017536

Epoch: 5| Step: 5
Training loss: 3.1162689308788076
Validation loss: 2.4800372056365023

Epoch: 5| Step: 6
Training loss: 3.4549192712298407
Validation loss: 2.470867897047458

Epoch: 5| Step: 7
Training loss: 3.1071404330239445
Validation loss: 2.4828422442640217

Epoch: 5| Step: 8
Training loss: 2.9544737627094566
Validation loss: 2.4873876092693816

Epoch: 5| Step: 9
Training loss: 2.5456141059580566
Validation loss: 2.4770285787390036

Epoch: 5| Step: 10
Training loss: 2.576826843803591
Validation loss: 2.4863567686556416

Epoch: 33| Step: 0
Training loss: 2.8265967692274194
Validation loss: 2.493971608407618

Epoch: 5| Step: 1
Training loss: 2.411917020101029
Validation loss: 2.470729063183978

Epoch: 5| Step: 2
Training loss: 2.6411507889998207
Validation loss: 2.474058728774335

Epoch: 5| Step: 3
Training loss: 3.0428248948064858
Validation loss: 2.480185223919083

Epoch: 5| Step: 4
Training loss: 3.2177929983282536
Validation loss: 2.496227247931925

Epoch: 5| Step: 5
Training loss: 3.0070810989287713
Validation loss: 2.478108777451379

Epoch: 5| Step: 6
Training loss: 3.013045556778337
Validation loss: 2.493225414379097

Epoch: 5| Step: 7
Training loss: 2.58999177673684
Validation loss: 2.485558681173102

Epoch: 5| Step: 8
Training loss: 2.0321646171782035
Validation loss: 2.4716491727154777

Epoch: 5| Step: 9
Training loss: 3.328849606142846
Validation loss: 2.4753715384594983

Epoch: 5| Step: 10
Training loss: 3.1860882493780216
Validation loss: 2.4794537598708746

Epoch: 34| Step: 0
Training loss: 2.8264240186686225
Validation loss: 2.487570294558605

Epoch: 5| Step: 1
Training loss: 3.008640086278551
Validation loss: 2.478071565668403

Epoch: 5| Step: 2
Training loss: 2.9115622586631695
Validation loss: 2.472990971516949

Epoch: 5| Step: 3
Training loss: 3.322951329607527
Validation loss: 2.466521641021829

Epoch: 5| Step: 4
Training loss: 2.889888525268157
Validation loss: 2.478124408923324

Epoch: 5| Step: 5
Training loss: 2.7259864526525375
Validation loss: 2.486591023842405

Epoch: 5| Step: 6
Training loss: 2.8072754547462564
Validation loss: 2.470276792060522

Epoch: 5| Step: 7
Training loss: 2.602145292971248
Validation loss: 2.476497535038524

Epoch: 5| Step: 8
Training loss: 2.352783393127554
Validation loss: 2.4819188637403573

Epoch: 5| Step: 9
Training loss: 2.9620578226631236
Validation loss: 2.4755090773937996

Epoch: 5| Step: 10
Training loss: 2.992001042146552
Validation loss: 2.4915027328933608

Epoch: 35| Step: 0
Training loss: 3.2065213689051886
Validation loss: 2.4696526103372833

Epoch: 5| Step: 1
Training loss: 2.7603423966307084
Validation loss: 2.491078142239705

Epoch: 5| Step: 2
Training loss: 2.4600933261939444
Validation loss: 2.4869044279724806

Epoch: 5| Step: 3
Training loss: 2.6599224956952163
Validation loss: 2.481081706806281

Epoch: 5| Step: 4
Training loss: 3.147696812591553
Validation loss: 2.472491217639439

Epoch: 5| Step: 5
Training loss: 2.2712856740464558
Validation loss: 2.4793225642060026

Epoch: 5| Step: 6
Training loss: 2.9485561005351295
Validation loss: 2.482131563703149

Epoch: 5| Step: 7
Training loss: 2.6268301442228617
Validation loss: 2.4861358595821397

Epoch: 5| Step: 8
Training loss: 2.7319169685737434
Validation loss: 2.4799752339144665

Epoch: 5| Step: 9
Training loss: 3.27852917444217
Validation loss: 2.4938835076847417

Epoch: 5| Step: 10
Training loss: 3.1735898348046168
Validation loss: 2.4873094709287487

Epoch: 36| Step: 0
Training loss: 2.7338450763008866
Validation loss: 2.487923679103859

Epoch: 5| Step: 1
Training loss: 3.296404619695229
Validation loss: 2.505229988146966

Epoch: 5| Step: 2
Training loss: 2.626693633355813
Validation loss: 2.4915014384694314

Epoch: 5| Step: 3
Training loss: 2.3929086386826963
Validation loss: 2.4939770780436064

Epoch: 5| Step: 4
Training loss: 3.2820639917619685
Validation loss: 2.482162030697838

Epoch: 5| Step: 5
Training loss: 2.8844763443522865
Validation loss: 2.4678996729599962

Epoch: 5| Step: 6
Training loss: 2.733036258494677
Validation loss: 2.4812984185859452

Epoch: 5| Step: 7
Training loss: 2.3213391842243416
Validation loss: 2.472945399704504

Epoch: 5| Step: 8
Training loss: 3.252068081676847
Validation loss: 2.4690103576619933

Epoch: 5| Step: 9
Training loss: 2.991807559918575
Validation loss: 2.4849589198152273

Epoch: 5| Step: 10
Training loss: 2.6319466364126436
Validation loss: 2.4748704286983316

Epoch: 37| Step: 0
Training loss: 2.7565567572507597
Validation loss: 2.4930932158899504

Epoch: 5| Step: 1
Training loss: 2.284272582214828
Validation loss: 2.481918688142786

Epoch: 5| Step: 2
Training loss: 2.843649055449973
Validation loss: 2.481912616074437

Epoch: 5| Step: 3
Training loss: 2.6935467672131304
Validation loss: 2.4767410795178253

Epoch: 5| Step: 4
Training loss: 2.7968531772891656
Validation loss: 2.4823502116294063

Epoch: 5| Step: 5
Training loss: 2.8180408575373344
Validation loss: 2.4854347392213545

Epoch: 5| Step: 6
Training loss: 2.900314669144317
Validation loss: 2.480581038503297

Epoch: 5| Step: 7
Training loss: 3.3395866071970968
Validation loss: 2.4839682823666016

Epoch: 5| Step: 8
Training loss: 3.3858526017653734
Validation loss: 2.475098313448217

Epoch: 5| Step: 9
Training loss: 2.5133192975523375
Validation loss: 2.4638318686963396

Epoch: 5| Step: 10
Training loss: 2.898516630753124
Validation loss: 2.4854801253598486

Epoch: 38| Step: 0
Training loss: 2.683396688941493
Validation loss: 2.47559131727633

Epoch: 5| Step: 1
Training loss: 3.0333411485620227
Validation loss: 2.4899236242536613

Epoch: 5| Step: 2
Training loss: 3.246473306254443
Validation loss: 2.4818417824430186

Epoch: 5| Step: 3
Training loss: 2.4741682639480356
Validation loss: 2.4949950951922935

Epoch: 5| Step: 4
Training loss: 2.9785854243870684
Validation loss: 2.4759642538130704

Epoch: 5| Step: 5
Training loss: 2.4952135041341412
Validation loss: 2.490887713173013

Epoch: 5| Step: 6
Training loss: 3.338453572381058
Validation loss: 2.47558213695799

Epoch: 5| Step: 7
Training loss: 3.079474138971655
Validation loss: 2.4781021617192946

Epoch: 5| Step: 8
Training loss: 2.497506996733036
Validation loss: 2.47901823785753

Epoch: 5| Step: 9
Training loss: 2.681499613633662
Validation loss: 2.4757585101335806

Epoch: 5| Step: 10
Training loss: 2.6703114535807906
Validation loss: 2.50094966899034

Epoch: 39| Step: 0
Training loss: 2.766543995385897
Validation loss: 2.4872370825785035

Epoch: 5| Step: 1
Training loss: 2.936603652878461
Validation loss: 2.4633589762268646

Epoch: 5| Step: 2
Training loss: 2.284637861874855
Validation loss: 2.4656987137988424

Epoch: 5| Step: 3
Training loss: 3.157199527944493
Validation loss: 2.484066165491747

Epoch: 5| Step: 4
Training loss: 2.8419626508778006
Validation loss: 2.473407005616631

Epoch: 5| Step: 5
Training loss: 3.08512539378443
Validation loss: 2.469597652902332

Epoch: 5| Step: 6
Training loss: 2.8046605525940387
Validation loss: 2.4734978619173384

Epoch: 5| Step: 7
Training loss: 2.0077705824220566
Validation loss: 2.4780164204406274

Epoch: 5| Step: 8
Training loss: 2.7186887010701346
Validation loss: 2.4784414654800977

Epoch: 5| Step: 9
Training loss: 3.13034302754391
Validation loss: 2.4763631582913805

Epoch: 5| Step: 10
Training loss: 3.3749498434225176
Validation loss: 2.493333199638511

Epoch: 40| Step: 0
Training loss: 3.6428079895635626
Validation loss: 2.481090549561198

Epoch: 5| Step: 1
Training loss: 2.6993544195282255
Validation loss: 2.477979091398989

Epoch: 5| Step: 2
Training loss: 2.4630336977054768
Validation loss: 2.4849931651228765

Epoch: 5| Step: 3
Training loss: 2.550745170770396
Validation loss: 2.489150693247512

Epoch: 5| Step: 4
Training loss: 2.4753708725307177
Validation loss: 2.476190842107892

Epoch: 5| Step: 5
Training loss: 3.1950004443913063
Validation loss: 2.4773618712921657

Epoch: 5| Step: 6
Training loss: 2.7108316978014204
Validation loss: 2.4854967346929095

Epoch: 5| Step: 7
Training loss: 3.3207770527498264
Validation loss: 2.4688913749567685

Epoch: 5| Step: 8
Training loss: 2.87455696341208
Validation loss: 2.4878608146351717

Epoch: 5| Step: 9
Training loss: 2.500281508808761
Validation loss: 2.483139823822929

Epoch: 5| Step: 10
Training loss: 2.3507638379786777
Validation loss: 2.4717517058763065

Epoch: 41| Step: 0
Training loss: 2.56760224180562
Validation loss: 2.487761659753346

Epoch: 5| Step: 1
Training loss: 3.3538679538817857
Validation loss: 2.4763716452089177

Epoch: 5| Step: 2
Training loss: 2.685920428565222
Validation loss: 2.492944651318338

Epoch: 5| Step: 3
Training loss: 2.680156700051065
Validation loss: 2.48723119201677

Epoch: 5| Step: 4
Training loss: 2.976200111736867
Validation loss: 2.490244260024788

Epoch: 5| Step: 5
Training loss: 2.7177258020270667
Validation loss: 2.490376049743235

Epoch: 5| Step: 6
Training loss: 2.585654989524611
Validation loss: 2.4699367849793004

Epoch: 5| Step: 7
Training loss: 2.96620936851789
Validation loss: 2.47184389040173

Epoch: 5| Step: 8
Training loss: 3.103244123832679
Validation loss: 2.4829108113803375

Epoch: 5| Step: 9
Training loss: 2.451366985200374
Validation loss: 2.466184492579507

Epoch: 5| Step: 10
Training loss: 3.021358751226554
Validation loss: 2.483580953780039

Epoch: 42| Step: 0
Training loss: 2.730375667617172
Validation loss: 2.4923841771920134

Epoch: 5| Step: 1
Training loss: 2.9742146841932744
Validation loss: 2.489459062782713

Epoch: 5| Step: 2
Training loss: 2.7607095431059903
Validation loss: 2.4786611861884174

Epoch: 5| Step: 3
Training loss: 2.8277439261131696
Validation loss: 2.478020595895157

Epoch: 5| Step: 4
Training loss: 2.612899683992089
Validation loss: 2.4748954075083724

Epoch: 5| Step: 5
Training loss: 3.287988627857302
Validation loss: 2.4762684989273374

Epoch: 5| Step: 6
Training loss: 2.493954405856533
Validation loss: 2.4720351497245736

Epoch: 5| Step: 7
Training loss: 3.286714635528608
Validation loss: 2.4907521278451874

Epoch: 5| Step: 8
Training loss: 2.6694805279993474
Validation loss: 2.4806106135365593

Epoch: 5| Step: 9
Training loss: 2.1947084729456625
Validation loss: 2.473915866731278

Epoch: 5| Step: 10
Training loss: 3.253438158014143
Validation loss: 2.476623244566237

Epoch: 43| Step: 0
Training loss: 3.0352747045940722
Validation loss: 2.4768946924219835

Epoch: 5| Step: 1
Training loss: 2.8900901505820213
Validation loss: 2.487219023298607

Epoch: 5| Step: 2
Training loss: 2.6331886452951725
Validation loss: 2.4629708755574686

Epoch: 5| Step: 3
Training loss: 2.2648029809277967
Validation loss: 2.4629206341723506

Epoch: 5| Step: 4
Training loss: 3.029299078718573
Validation loss: 2.4798869383335913

Epoch: 5| Step: 5
Training loss: 3.1676415063912606
Validation loss: 2.4605315905483853

Epoch: 5| Step: 6
Training loss: 2.8641114742172946
Validation loss: 2.4668660055341296

Epoch: 5| Step: 7
Training loss: 2.9087887411976086
Validation loss: 2.4728540327401882

Epoch: 5| Step: 8
Training loss: 2.529710089315835
Validation loss: 2.483402835659027

Epoch: 5| Step: 9
Training loss: 2.93448516671401
Validation loss: 2.462529288147378

Epoch: 5| Step: 10
Training loss: 2.8257065016162537
Validation loss: 2.4718984110528277

Epoch: 44| Step: 0
Training loss: 2.701742888341633
Validation loss: 2.465577024878994

Epoch: 5| Step: 1
Training loss: 3.1971967220164075
Validation loss: 2.477346525796957

Epoch: 5| Step: 2
Training loss: 2.892070017303411
Validation loss: 2.4671538886427373

Epoch: 5| Step: 3
Training loss: 2.4452756446279116
Validation loss: 2.481032087393239

Epoch: 5| Step: 4
Training loss: 2.667571679164904
Validation loss: 2.462794539061943

Epoch: 5| Step: 5
Training loss: 3.0601814991598606
Validation loss: 2.4779475668429614

Epoch: 5| Step: 6
Training loss: 3.0823654167700494
Validation loss: 2.479880331480322

Epoch: 5| Step: 7
Training loss: 2.5275203401405535
Validation loss: 2.4785757776470616

Epoch: 5| Step: 8
Training loss: 2.272237454430414
Validation loss: 2.483978016875398

Epoch: 5| Step: 9
Training loss: 3.1274529557383346
Validation loss: 2.4692895283375806

Epoch: 5| Step: 10
Training loss: 3.004223552558557
Validation loss: 2.4625638948193087

Epoch: 45| Step: 0
Training loss: 2.3508740808344477
Validation loss: 2.4694545784568254

Epoch: 5| Step: 1
Training loss: 3.1410809086359377
Validation loss: 2.482735113582513

Epoch: 5| Step: 2
Training loss: 3.083468992668413
Validation loss: 2.4855521842862696

Epoch: 5| Step: 3
Training loss: 2.962192400322491
Validation loss: 2.4830554851182085

Epoch: 5| Step: 4
Training loss: 3.162580430285899
Validation loss: 2.478212611612914

Epoch: 5| Step: 5
Training loss: 2.861216634719982
Validation loss: 2.475712682751962

Epoch: 5| Step: 6
Training loss: 2.7591266904850036
Validation loss: 2.4754833622421826

Epoch: 5| Step: 7
Training loss: 3.0075553486868767
Validation loss: 2.4698177700933295

Epoch: 5| Step: 8
Training loss: 2.1577897034034086
Validation loss: 2.460168108619782

Epoch: 5| Step: 9
Training loss: 3.086281749983822
Validation loss: 2.4632193975425345

Epoch: 5| Step: 10
Training loss: 2.3731976747674706
Validation loss: 2.4559701243201464

Epoch: 46| Step: 0
Training loss: 2.824558432848606
Validation loss: 2.476596347976975

Epoch: 5| Step: 1
Training loss: 2.7860082149891117
Validation loss: 2.4647840547871116

Epoch: 5| Step: 2
Training loss: 3.2515049897680193
Validation loss: 2.4773010806765567

Epoch: 5| Step: 3
Training loss: 2.896448321642188
Validation loss: 2.4599167813400573

Epoch: 5| Step: 4
Training loss: 3.1347642559868505
Validation loss: 2.4784869714048066

Epoch: 5| Step: 5
Training loss: 3.1054523203673097
Validation loss: 2.46291007947912

Epoch: 5| Step: 6
Training loss: 2.246046832050734
Validation loss: 2.4831235332307156

Epoch: 5| Step: 7
Training loss: 2.7580339812909425
Validation loss: 2.4818941869952194

Epoch: 5| Step: 8
Training loss: 2.658134420321249
Validation loss: 2.4781543639688906

Epoch: 5| Step: 9
Training loss: 2.659058824833204
Validation loss: 2.4781909496823458

Epoch: 5| Step: 10
Training loss: 2.8660853291791124
Validation loss: 2.4842714873863336

Epoch: 47| Step: 0
Training loss: 2.6154471461126656
Validation loss: 2.475563277070288

Epoch: 5| Step: 1
Training loss: 2.1676516739202962
Validation loss: 2.469654872262853

Epoch: 5| Step: 2
Training loss: 2.32305550837448
Validation loss: 2.4560616976801986

Epoch: 5| Step: 3
Training loss: 2.9805719400243715
Validation loss: 2.457867200849909

Epoch: 5| Step: 4
Training loss: 2.9194157496658426
Validation loss: 2.4873820797945037

Epoch: 5| Step: 5
Training loss: 2.932131467590992
Validation loss: 2.4752145338007265

Epoch: 5| Step: 6
Training loss: 2.948602028336274
Validation loss: 2.485307036363485

Epoch: 5| Step: 7
Training loss: 3.12966448755893
Validation loss: 2.466117839409842

Epoch: 5| Step: 8
Training loss: 2.895924427237189
Validation loss: 2.462960147252948

Epoch: 5| Step: 9
Training loss: 3.510221813616076
Validation loss: 2.4864890572322893

Epoch: 5| Step: 10
Training loss: 2.453030335367443
Validation loss: 2.4814035212503285

Epoch: 48| Step: 0
Training loss: 2.719190013838655
Validation loss: 2.4660617433606893

Epoch: 5| Step: 1
Training loss: 3.13530557801068
Validation loss: 2.4892346585958403

Epoch: 5| Step: 2
Training loss: 2.9982881430301616
Validation loss: 2.479175186728561

Epoch: 5| Step: 3
Training loss: 2.497464229109917
Validation loss: 2.472104517474537

Epoch: 5| Step: 4
Training loss: 2.6382497002203733
Validation loss: 2.4847810217009343

Epoch: 5| Step: 5
Training loss: 2.6230422394144166
Validation loss: 2.491436922211669

Epoch: 5| Step: 6
Training loss: 3.305943604317714
Validation loss: 2.4664213153998844

Epoch: 5| Step: 7
Training loss: 2.500304012887303
Validation loss: 2.469759769769766

Epoch: 5| Step: 8
Training loss: 2.9026110437461052
Validation loss: 2.4735109075965287

Epoch: 5| Step: 9
Training loss: 2.5255607435571554
Validation loss: 2.4748293613458436

Epoch: 5| Step: 10
Training loss: 2.983755956227527
Validation loss: 2.458675792055188

Epoch: 49| Step: 0
Training loss: 2.788698658865984
Validation loss: 2.4668820200131782

Epoch: 5| Step: 1
Training loss: 2.3509920258380714
Validation loss: 2.4815039891153288

Epoch: 5| Step: 2
Training loss: 2.7975468175002822
Validation loss: 2.4622890862022335

Epoch: 5| Step: 3
Training loss: 2.670346363761378
Validation loss: 2.471994778851379

Epoch: 5| Step: 4
Training loss: 3.408096792753882
Validation loss: 2.462339588264779

Epoch: 5| Step: 5
Training loss: 2.409019461794252
Validation loss: 2.451564466198184

Epoch: 5| Step: 6
Training loss: 3.049237083948773
Validation loss: 2.4733766354853657

Epoch: 5| Step: 7
Training loss: 2.79964050301212
Validation loss: 2.461401628648429

Epoch: 5| Step: 8
Training loss: 2.759019538906993
Validation loss: 2.4740524576326646

Epoch: 5| Step: 9
Training loss: 3.0807695985378234
Validation loss: 2.467933130226837

Epoch: 5| Step: 10
Training loss: 2.7355619633580033
Validation loss: 2.460425410825145

Epoch: 50| Step: 0
Training loss: 2.8730080379555547
Validation loss: 2.461198625775803

Epoch: 5| Step: 1
Training loss: 3.2370013939280273
Validation loss: 2.4556030158216187

Epoch: 5| Step: 2
Training loss: 2.9323910052116666
Validation loss: 2.4704714342398892

Epoch: 5| Step: 3
Training loss: 2.7932487294108754
Validation loss: 2.4619847650379545

Epoch: 5| Step: 4
Training loss: 3.457109181016031
Validation loss: 2.468038709611261

Epoch: 5| Step: 5
Training loss: 2.1747609456549126
Validation loss: 2.471862447304967

Epoch: 5| Step: 6
Training loss: 2.5099611198787968
Validation loss: 2.4574789589513046

Epoch: 5| Step: 7
Training loss: 2.58794267710034
Validation loss: 2.470362744889263

Epoch: 5| Step: 8
Training loss: 2.3208744896938356
Validation loss: 2.4793703835365073

Epoch: 5| Step: 9
Training loss: 3.0948032936606222
Validation loss: 2.4612528874764643

Epoch: 5| Step: 10
Training loss: 2.7615167309200515
Validation loss: 2.482865198614685

Epoch: 51| Step: 0
Training loss: 2.9136425871424847
Validation loss: 2.471784968912157

Epoch: 5| Step: 1
Training loss: 3.167739652917675
Validation loss: 2.4655353483418665

Epoch: 5| Step: 2
Training loss: 2.1403242582136595
Validation loss: 2.4755856817143855

Epoch: 5| Step: 3
Training loss: 3.2568037268834447
Validation loss: 2.4671351825401744

Epoch: 5| Step: 4
Training loss: 2.2353600951398964
Validation loss: 2.4733924606287925

Epoch: 5| Step: 5
Training loss: 3.083261300010206
Validation loss: 2.4551554012534473

Epoch: 5| Step: 6
Training loss: 3.0668675944252697
Validation loss: 2.468419071653909

Epoch: 5| Step: 7
Training loss: 3.0259119598026247
Validation loss: 2.4671230103006074

Epoch: 5| Step: 8
Training loss: 2.7994502481549
Validation loss: 2.4782982323160425

Epoch: 5| Step: 9
Training loss: 2.3412752437503563
Validation loss: 2.4710147719318827

Epoch: 5| Step: 10
Training loss: 2.6297286902480956
Validation loss: 2.4754389775789565

Epoch: 52| Step: 0
Training loss: 3.1382993371398125
Validation loss: 2.4714123124858935

Epoch: 5| Step: 1
Training loss: 2.5841155764948103
Validation loss: 2.500048243149455

Epoch: 5| Step: 2
Training loss: 3.0238861618514057
Validation loss: 2.473641546116965

Epoch: 5| Step: 3
Training loss: 2.824242134050192
Validation loss: 2.462584464748017

Epoch: 5| Step: 4
Training loss: 1.982737909692119
Validation loss: 2.459981263448929

Epoch: 5| Step: 5
Training loss: 2.9942713719516405
Validation loss: 2.4570829921844464

Epoch: 5| Step: 6
Training loss: 2.941576138437123
Validation loss: 2.4727932847421874

Epoch: 5| Step: 7
Training loss: 2.9496389329712716
Validation loss: 2.458006600562781

Epoch: 5| Step: 8
Training loss: 2.7315215126404064
Validation loss: 2.465113096086962

Epoch: 5| Step: 9
Training loss: 2.876782901076186
Validation loss: 2.4787696016469387

Epoch: 5| Step: 10
Training loss: 2.7493109273241103
Validation loss: 2.473853309530758

Epoch: 53| Step: 0
Training loss: 2.577548430734282
Validation loss: 2.4613241881197525

Epoch: 5| Step: 1
Training loss: 2.948413299315675
Validation loss: 2.485536579930357

Epoch: 5| Step: 2
Training loss: 2.4698969434173352
Validation loss: 2.4831580820851187

Epoch: 5| Step: 3
Training loss: 2.999139980385751
Validation loss: 2.4676881144286646

Epoch: 5| Step: 4
Training loss: 2.620464402892856
Validation loss: 2.461305205439219

Epoch: 5| Step: 5
Training loss: 3.158300055040828
Validation loss: 2.4771285565176284

Epoch: 5| Step: 6
Training loss: 3.144362924939701
Validation loss: 2.453962931327846

Epoch: 5| Step: 7
Training loss: 2.9936362163287864
Validation loss: 2.4681743336432236

Epoch: 5| Step: 8
Training loss: 2.187285930513267
Validation loss: 2.4659208850540826

Epoch: 5| Step: 9
Training loss: 2.965113128768284
Validation loss: 2.4717118354863077

Epoch: 5| Step: 10
Training loss: 2.583234221085093
Validation loss: 2.481078000444736

Epoch: 54| Step: 0
Training loss: 3.0895390993339893
Validation loss: 2.4733267039443536

Epoch: 5| Step: 1
Training loss: 2.921059887453331
Validation loss: 2.468251087705474

Epoch: 5| Step: 2
Training loss: 2.5292612434145596
Validation loss: 2.4533100334022864

Epoch: 5| Step: 3
Training loss: 3.1774473054779926
Validation loss: 2.4515817905169723

Epoch: 5| Step: 4
Training loss: 2.814134843183407
Validation loss: 2.4560684990806956

Epoch: 5| Step: 5
Training loss: 3.1531238748720427
Validation loss: 2.4634364048238204

Epoch: 5| Step: 6
Training loss: 2.6895344153303444
Validation loss: 2.472979893787388

Epoch: 5| Step: 7
Training loss: 2.690699868041159
Validation loss: 2.4706464176073486

Epoch: 5| Step: 8
Training loss: 2.3703457251013718
Validation loss: 2.4667994211830195

Epoch: 5| Step: 9
Training loss: 2.4015787534840056
Validation loss: 2.4707433084208783

Epoch: 5| Step: 10
Training loss: 2.978020738856116
Validation loss: 2.4671665553431277

Epoch: 55| Step: 0
Training loss: 2.6531236089156853
Validation loss: 2.4681086280179265

Epoch: 5| Step: 1
Training loss: 3.0568953630373223
Validation loss: 2.4608443047709754

Epoch: 5| Step: 2
Training loss: 2.6774788253901463
Validation loss: 2.4758014373271573

Epoch: 5| Step: 3
Training loss: 2.5050070213173785
Validation loss: 2.4707632354281452

Epoch: 5| Step: 4
Training loss: 2.7334619360032457
Validation loss: 2.4542642694697148

Epoch: 5| Step: 5
Training loss: 2.671765598488955
Validation loss: 2.456589492381209

Epoch: 5| Step: 6
Training loss: 2.5964953130058652
Validation loss: 2.4872460817632023

Epoch: 5| Step: 7
Training loss: 2.5644211429365193
Validation loss: 2.4599258961034622

Epoch: 5| Step: 8
Training loss: 2.416331881868917
Validation loss: 2.474336471976076

Epoch: 5| Step: 9
Training loss: 2.8592140694445507
Validation loss: 2.4607717390174195

Epoch: 5| Step: 10
Training loss: 3.863946222945961
Validation loss: 2.4417423628260706

Epoch: 56| Step: 0
Training loss: 3.349888238893013
Validation loss: 2.4716003939151436

Epoch: 5| Step: 1
Training loss: 2.735676047197691
Validation loss: 2.4685896715881825

Epoch: 5| Step: 2
Training loss: 2.772003920867481
Validation loss: 2.4719913056893024

Epoch: 5| Step: 3
Training loss: 2.2228366664611596
Validation loss: 2.469901338631735

Epoch: 5| Step: 4
Training loss: 2.850461815343258
Validation loss: 2.454107541984038

Epoch: 5| Step: 5
Training loss: 2.541371677561061
Validation loss: 2.4627460189646038

Epoch: 5| Step: 6
Training loss: 2.490217332968647
Validation loss: 2.461952601455823

Epoch: 5| Step: 7
Training loss: 2.1350343191350056
Validation loss: 2.4775477295748116

Epoch: 5| Step: 8
Training loss: 3.0086670293330893
Validation loss: 2.4519264549128534

Epoch: 5| Step: 9
Training loss: 3.4107135610073236
Validation loss: 2.460812371102467

Epoch: 5| Step: 10
Training loss: 3.0008098780689867
Validation loss: 2.4507815180399324

Epoch: 57| Step: 0
Training loss: 3.48260617370216
Validation loss: 2.4651133506193053

Epoch: 5| Step: 1
Training loss: 3.0795007719722425
Validation loss: 2.4545685044409256

Epoch: 5| Step: 2
Training loss: 2.713361815913089
Validation loss: 2.4503123028462253

Epoch: 5| Step: 3
Training loss: 3.036839787824116
Validation loss: 2.4532447964916795

Epoch: 5| Step: 4
Training loss: 2.7384662647297198
Validation loss: 2.4700388796162915

Epoch: 5| Step: 5
Training loss: 2.8636099716445584
Validation loss: 2.459645555297556

Epoch: 5| Step: 6
Training loss: 2.8690001866901347
Validation loss: 2.452638757004228

Epoch: 5| Step: 7
Training loss: 2.464023556398521
Validation loss: 2.4752102899154527

Epoch: 5| Step: 8
Training loss: 2.2001856682198193
Validation loss: 2.4637975857485492

Epoch: 5| Step: 9
Training loss: 2.4456206788693398
Validation loss: 2.4594649850353463

Epoch: 5| Step: 10
Training loss: 2.7086732406548952
Validation loss: 2.4643900294920966

Epoch: 58| Step: 0
Training loss: 2.6680592735203286
Validation loss: 2.464441290536102

Epoch: 5| Step: 1
Training loss: 2.831412580592607
Validation loss: 2.4746151723255645

Epoch: 5| Step: 2
Training loss: 2.7042525921901124
Validation loss: 2.4612855778706226

Epoch: 5| Step: 3
Training loss: 2.9954031057489034
Validation loss: 2.4755587163774293

Epoch: 5| Step: 4
Training loss: 2.7293331202252404
Validation loss: 2.4823423730645438

Epoch: 5| Step: 5
Training loss: 2.877262717770192
Validation loss: 2.44118118082186

Epoch: 5| Step: 6
Training loss: 2.6109975007774637
Validation loss: 2.4747182787449207

Epoch: 5| Step: 7
Training loss: 3.0522018426968445
Validation loss: 2.4711149089876683

Epoch: 5| Step: 8
Training loss: 2.6057101342340254
Validation loss: 2.4714027587680576

Epoch: 5| Step: 9
Training loss: 2.9381656298397445
Validation loss: 2.481220795205961

Epoch: 5| Step: 10
Training loss: 2.798719171079098
Validation loss: 2.469353866400131

Epoch: 59| Step: 0
Training loss: 2.6779271340916186
Validation loss: 2.447005492222475

Epoch: 5| Step: 1
Training loss: 3.0418957837352756
Validation loss: 2.4858425565768254

Epoch: 5| Step: 2
Training loss: 3.1243631858472596
Validation loss: 2.4744010321088967

Epoch: 5| Step: 3
Training loss: 2.5382040127702727
Validation loss: 2.471635651496081

Epoch: 5| Step: 4
Training loss: 2.525819014866627
Validation loss: 2.4727355988881743

Epoch: 5| Step: 5
Training loss: 2.6805417670475635
Validation loss: 2.4697508210508543

Epoch: 5| Step: 6
Training loss: 2.8883648258465375
Validation loss: 2.455454182320672

Epoch: 5| Step: 7
Training loss: 2.4140928198629434
Validation loss: 2.4660493339977263

Epoch: 5| Step: 8
Training loss: 2.501567921105443
Validation loss: 2.4600940744150286

Epoch: 5| Step: 9
Training loss: 2.985039282561055
Validation loss: 2.467347065901998

Epoch: 5| Step: 10
Training loss: 3.1983563910907664
Validation loss: 2.4625139178902007

Epoch: 60| Step: 0
Training loss: 3.660440505154053
Validation loss: 2.463931837787104

Epoch: 5| Step: 1
Training loss: 2.955914184336401
Validation loss: 2.448161238420258

Epoch: 5| Step: 2
Training loss: 2.830514141058895
Validation loss: 2.4675065586906277

Epoch: 5| Step: 3
Training loss: 2.771779427068788
Validation loss: 2.4550384359815975

Epoch: 5| Step: 4
Training loss: 2.648172640989786
Validation loss: 2.4646324487208027

Epoch: 5| Step: 5
Training loss: 2.518289706670464
Validation loss: 2.472807592732374

Epoch: 5| Step: 6
Training loss: 2.485676454544321
Validation loss: 2.439696536236421

Epoch: 5| Step: 7
Training loss: 2.9225126988352876
Validation loss: 2.441234953878117

Epoch: 5| Step: 8
Training loss: 2.4040343747910513
Validation loss: 2.4821228924937477

Epoch: 5| Step: 9
Training loss: 2.5141769885731207
Validation loss: 2.4534575743295477

Epoch: 5| Step: 10
Training loss: 2.8626655031026256
Validation loss: 2.4633163317528073

Epoch: 61| Step: 0
Training loss: 2.6198259860774455
Validation loss: 2.4617007929855155

Epoch: 5| Step: 1
Training loss: 3.0420149163978327
Validation loss: 2.453685990273898

Epoch: 5| Step: 2
Training loss: 2.4216783012991034
Validation loss: 2.4732129453437017

Epoch: 5| Step: 3
Training loss: 2.91769109628024
Validation loss: 2.4673357830801783

Epoch: 5| Step: 4
Training loss: 2.969017097102707
Validation loss: 2.464393731824138

Epoch: 5| Step: 5
Training loss: 2.564699299161051
Validation loss: 2.4764150255538957

Epoch: 5| Step: 6
Training loss: 2.8332335136632025
Validation loss: 2.472663114618196

Epoch: 5| Step: 7
Training loss: 3.318293273878131
Validation loss: 2.4728200874040063

Epoch: 5| Step: 8
Training loss: 2.4602268706743264
Validation loss: 2.4515986263707332

Epoch: 5| Step: 9
Training loss: 2.6949447602111625
Validation loss: 2.45817628473192

Epoch: 5| Step: 10
Training loss: 2.741227984672679
Validation loss: 2.4761316275218443

Epoch: 62| Step: 0
Training loss: 2.8739670266082973
Validation loss: 2.4696988117542933

Epoch: 5| Step: 1
Training loss: 3.2436899403798276
Validation loss: 2.4561712902067865

Epoch: 5| Step: 2
Training loss: 3.1553831515280004
Validation loss: 2.472646844166868

Epoch: 5| Step: 3
Training loss: 2.3105652422267644
Validation loss: 2.4560584629375337

Epoch: 5| Step: 4
Training loss: 2.506746534975723
Validation loss: 2.4403388112945374

Epoch: 5| Step: 5
Training loss: 2.8313566680418485
Validation loss: 2.4454177036514224

Epoch: 5| Step: 6
Training loss: 2.845934688909786
Validation loss: 2.4804418615192367

Epoch: 5| Step: 7
Training loss: 3.026051891701385
Validation loss: 2.449844963018528

Epoch: 5| Step: 8
Training loss: 2.4891252508592916
Validation loss: 2.4413287107562414

Epoch: 5| Step: 9
Training loss: 2.2647404489582157
Validation loss: 2.468465273310396

Epoch: 5| Step: 10
Training loss: 2.9385262178007934
Validation loss: 2.445782129331338

Epoch: 63| Step: 0
Training loss: 2.7343085580655395
Validation loss: 2.448115299695121

Epoch: 5| Step: 1
Training loss: 2.7512983378384694
Validation loss: 2.463645901807917

Epoch: 5| Step: 2
Training loss: 2.7110178822849633
Validation loss: 2.4546924289109158

Epoch: 5| Step: 3
Training loss: 3.194629101783402
Validation loss: 2.4404884258465347

Epoch: 5| Step: 4
Training loss: 2.518726971618034
Validation loss: 2.463511120108339

Epoch: 5| Step: 5
Training loss: 2.2812473871921575
Validation loss: 2.4537414111796254

Epoch: 5| Step: 6
Training loss: 2.4774512973467506
Validation loss: 2.4641599715425353

Epoch: 5| Step: 7
Training loss: 2.9945885807782413
Validation loss: 2.451941869582004

Epoch: 5| Step: 8
Training loss: 3.0095124432163467
Validation loss: 2.4496322240694655

Epoch: 5| Step: 9
Training loss: 3.2983108937131616
Validation loss: 2.4492484640420384

Epoch: 5| Step: 10
Training loss: 2.2954093772434065
Validation loss: 2.4575940941746803

Epoch: 64| Step: 0
Training loss: 3.3653776256782133
Validation loss: 2.451754979918449

Epoch: 5| Step: 1
Training loss: 2.559249118415373
Validation loss: 2.4536600516333893

Epoch: 5| Step: 2
Training loss: 2.5881509671524134
Validation loss: 2.463778805258443

Epoch: 5| Step: 3
Training loss: 3.2184034735057576
Validation loss: 2.4511783699289835

Epoch: 5| Step: 4
Training loss: 2.5112260539924494
Validation loss: 2.459370595709655

Epoch: 5| Step: 5
Training loss: 2.5165292761312616
Validation loss: 2.456347642953518

Epoch: 5| Step: 6
Training loss: 2.5828815393284326
Validation loss: 2.464401513048961

Epoch: 5| Step: 7
Training loss: 2.777739806445523
Validation loss: 2.4456254851260355

Epoch: 5| Step: 8
Training loss: 2.3275839157629123
Validation loss: 2.4615606859839074

Epoch: 5| Step: 9
Training loss: 2.7767228560545862
Validation loss: 2.465014549536418

Epoch: 5| Step: 10
Training loss: 3.3295813584293
Validation loss: 2.45446577727366

Epoch: 65| Step: 0
Training loss: 3.2261671512198284
Validation loss: 2.4640488418056052

Epoch: 5| Step: 1
Training loss: 2.3683762791511818
Validation loss: 2.456178421651276

Epoch: 5| Step: 2
Training loss: 2.4478981071472017
Validation loss: 2.4604937555543143

Epoch: 5| Step: 3
Training loss: 2.633858945355799
Validation loss: 2.4571193970949357

Epoch: 5| Step: 4
Training loss: 2.339285094449326
Validation loss: 2.460850466849309

Epoch: 5| Step: 5
Training loss: 2.4079394664126155
Validation loss: 2.4445536227220988

Epoch: 5| Step: 6
Training loss: 2.9360008472472585
Validation loss: 2.461167941459709

Epoch: 5| Step: 7
Training loss: 2.79706440715807
Validation loss: 2.4521287523200406

Epoch: 5| Step: 8
Training loss: 3.339299743249856
Validation loss: 2.462737138447683

Epoch: 5| Step: 9
Training loss: 2.6660275190039173
Validation loss: 2.451782154251112

Epoch: 5| Step: 10
Training loss: 3.1696887068627237
Validation loss: 2.4582562292850634

Epoch: 66| Step: 0
Training loss: 3.064256125658835
Validation loss: 2.4526996597817314

Epoch: 5| Step: 1
Training loss: 2.787321086667168
Validation loss: 2.465153710432756

Epoch: 5| Step: 2
Training loss: 3.0721257803022257
Validation loss: 2.4818721254261416

Epoch: 5| Step: 3
Training loss: 2.642935921072993
Validation loss: 2.455784071525349

Epoch: 5| Step: 4
Training loss: 3.1130475156339528
Validation loss: 2.4479887948878596

Epoch: 5| Step: 5
Training loss: 2.5963917343395955
Validation loss: 2.4630754623683364

Epoch: 5| Step: 6
Training loss: 2.103826388299884
Validation loss: 2.4563482952533624

Epoch: 5| Step: 7
Training loss: 2.937483442543928
Validation loss: 2.46086736534539

Epoch: 5| Step: 8
Training loss: 2.670420021852205
Validation loss: 2.46026229958336

Epoch: 5| Step: 9
Training loss: 1.9295074131752303
Validation loss: 2.461997133452013

Epoch: 5| Step: 10
Training loss: 3.3233279907377478
Validation loss: 2.4511301125093024

Epoch: 67| Step: 0
Training loss: 2.8502505275972427
Validation loss: 2.446806831265753

Epoch: 5| Step: 1
Training loss: 2.556185688431628
Validation loss: 2.456981773014601

Epoch: 5| Step: 2
Training loss: 2.4606043998896587
Validation loss: 2.4670557262640895

Epoch: 5| Step: 3
Training loss: 2.606166122879811
Validation loss: 2.4725105250349704

Epoch: 5| Step: 4
Training loss: 3.000920472395199
Validation loss: 2.45029588502733

Epoch: 5| Step: 5
Training loss: 2.7309188362668526
Validation loss: 2.4503093210302955

Epoch: 5| Step: 6
Training loss: 2.777602643743918
Validation loss: 2.4503604131599777

Epoch: 5| Step: 7
Training loss: 3.201294762217633
Validation loss: 2.48006247921393

Epoch: 5| Step: 8
Training loss: 2.8515932682415404
Validation loss: 2.4557790168624107

Epoch: 5| Step: 9
Training loss: 2.6307363049466876
Validation loss: 2.4525102992537358

Epoch: 5| Step: 10
Training loss: 2.940868799722316
Validation loss: 2.458071025357402

Epoch: 68| Step: 0
Training loss: 2.1184222572724782
Validation loss: 2.4619238009064577

Epoch: 5| Step: 1
Training loss: 2.8912382557882355
Validation loss: 2.458468251169909

Epoch: 5| Step: 2
Training loss: 2.6371479504554824
Validation loss: 2.4569457187428734

Epoch: 5| Step: 3
Training loss: 2.537449344824694
Validation loss: 2.4765047994599576

Epoch: 5| Step: 4
Training loss: 2.812220156840636
Validation loss: 2.4465670755740354

Epoch: 5| Step: 5
Training loss: 3.240084266979627
Validation loss: 2.4557856316623976

Epoch: 5| Step: 6
Training loss: 3.2646256519358894
Validation loss: 2.455026501374134

Epoch: 5| Step: 7
Training loss: 2.8467723170499726
Validation loss: 2.461979585654997

Epoch: 5| Step: 8
Training loss: 3.1430892765717755
Validation loss: 2.449588264242252

Epoch: 5| Step: 9
Training loss: 2.454896032458785
Validation loss: 2.4609392594869783

Epoch: 5| Step: 10
Training loss: 2.16531809383974
Validation loss: 2.452728599999856

Epoch: 69| Step: 0
Training loss: 2.594618134966374
Validation loss: 2.4534473498707468

Epoch: 5| Step: 1
Training loss: 2.9629128341496234
Validation loss: 2.45766103849272

Epoch: 5| Step: 2
Training loss: 2.8124984741206798
Validation loss: 2.4619214631509365

Epoch: 5| Step: 3
Training loss: 2.417165595105175
Validation loss: 2.458140554598553

Epoch: 5| Step: 4
Training loss: 3.156627368084865
Validation loss: 2.459807833020482

Epoch: 5| Step: 5
Training loss: 2.8668823079759735
Validation loss: 2.4729418045130425

Epoch: 5| Step: 6
Training loss: 2.9577969525992103
Validation loss: 2.4468544562558128

Epoch: 5| Step: 7
Training loss: 2.8293590909065274
Validation loss: 2.4689665969739316

Epoch: 5| Step: 8
Training loss: 3.038883939464319
Validation loss: 2.4582487456415834

Epoch: 5| Step: 9
Training loss: 2.3366433802635656
Validation loss: 2.4566853519415948

Epoch: 5| Step: 10
Training loss: 2.387070849929727
Validation loss: 2.4600804480020644

Epoch: 70| Step: 0
Training loss: 2.542136247958798
Validation loss: 2.4503675432072223

Epoch: 5| Step: 1
Training loss: 2.773383599415713
Validation loss: 2.4481874133378887

Epoch: 5| Step: 2
Training loss: 2.648624289798295
Validation loss: 2.44939054593907

Epoch: 5| Step: 3
Training loss: 2.904183586286591
Validation loss: 2.455799028756969

Epoch: 5| Step: 4
Training loss: 3.153527171230643
Validation loss: 2.448577023788166

Epoch: 5| Step: 5
Training loss: 2.2383117141115108
Validation loss: 2.4593152792461033

Epoch: 5| Step: 6
Training loss: 2.460970245627875
Validation loss: 2.45069141536781

Epoch: 5| Step: 7
Training loss: 2.9901385351129606
Validation loss: 2.4526034693580567

Epoch: 5| Step: 8
Training loss: 2.6311147405875723
Validation loss: 2.4528689690099528

Epoch: 5| Step: 9
Training loss: 3.020792274634537
Validation loss: 2.448763913109722

Epoch: 5| Step: 10
Training loss: 3.084897100132872
Validation loss: 2.460535620634362

Epoch: 71| Step: 0
Training loss: 2.995809330178682
Validation loss: 2.467223534947624

Epoch: 5| Step: 1
Training loss: 2.45391823159359
Validation loss: 2.454832087230224

Epoch: 5| Step: 2
Training loss: 3.039992633860849
Validation loss: 2.4645327977485096

Epoch: 5| Step: 3
Training loss: 2.0054272684905134
Validation loss: 2.456668069352396

Epoch: 5| Step: 4
Training loss: 3.0110223462236223
Validation loss: 2.4562006404171077

Epoch: 5| Step: 5
Training loss: 2.094549225812224
Validation loss: 2.4620186858741904

Epoch: 5| Step: 6
Training loss: 3.2901557319678023
Validation loss: 2.4571832953189188

Epoch: 5| Step: 7
Training loss: 3.2864147411101263
Validation loss: 2.4536492659010998

Epoch: 5| Step: 8
Training loss: 2.81333131160332
Validation loss: 2.4607748331718993

Epoch: 5| Step: 9
Training loss: 2.352360181393179
Validation loss: 2.470754244689492

Epoch: 5| Step: 10
Training loss: 2.6793592602298855
Validation loss: 2.440170575229318

Epoch: 72| Step: 0
Training loss: 2.5353204471214847
Validation loss: 2.44878954347827

Epoch: 5| Step: 1
Training loss: 2.548540191171814
Validation loss: 2.4505726024387613

Epoch: 5| Step: 2
Training loss: 2.863322883501032
Validation loss: 2.4557951093823243

Epoch: 5| Step: 3
Training loss: 3.0748305917610788
Validation loss: 2.434613594217454

Epoch: 5| Step: 4
Training loss: 2.554612651510082
Validation loss: 2.4564743507734526

Epoch: 5| Step: 5
Training loss: 2.528409140784601
Validation loss: 2.457583463404414

Epoch: 5| Step: 6
Training loss: 3.1901700673465276
Validation loss: 2.4586247684542046

Epoch: 5| Step: 7
Training loss: 2.999236486550919
Validation loss: 2.4481710933158762

Epoch: 5| Step: 8
Training loss: 2.178445332203489
Validation loss: 2.4623281815067535

Epoch: 5| Step: 9
Training loss: 2.9189338773195215
Validation loss: 2.4770383498347877

Epoch: 5| Step: 10
Training loss: 2.871890003053082
Validation loss: 2.4650089126738957

Epoch: 73| Step: 0
Training loss: 2.1778252415880273
Validation loss: 2.460006814462511

Epoch: 5| Step: 1
Training loss: 2.8853173267510464
Validation loss: 2.455037973384804

Epoch: 5| Step: 2
Training loss: 3.323326986364836
Validation loss: 2.43581222040164

Epoch: 5| Step: 3
Training loss: 2.6483001223242866
Validation loss: 2.4493886452322973

Epoch: 5| Step: 4
Training loss: 2.9130347027111125
Validation loss: 2.45822758774813

Epoch: 5| Step: 5
Training loss: 3.204413624652168
Validation loss: 2.4417372066504455

Epoch: 5| Step: 6
Training loss: 2.1857335178836306
Validation loss: 2.449816950434238

Epoch: 5| Step: 7
Training loss: 3.0991592128411356
Validation loss: 2.4570859376092447

Epoch: 5| Step: 8
Training loss: 2.546791590161441
Validation loss: 2.4615460970344474

Epoch: 5| Step: 9
Training loss: 2.437707549820057
Validation loss: 2.4676276683256546

Epoch: 5| Step: 10
Training loss: 2.7474643981959526
Validation loss: 2.460385295938177

Epoch: 74| Step: 0
Training loss: 2.7111741548080186
Validation loss: 2.44351612618235

Epoch: 5| Step: 1
Training loss: 2.0720928094911724
Validation loss: 2.4684472407881555

Epoch: 5| Step: 2
Training loss: 2.516461156407741
Validation loss: 2.4520828806061172

Epoch: 5| Step: 3
Training loss: 2.418752121246748
Validation loss: 2.4398990391272704

Epoch: 5| Step: 4
Training loss: 3.129082111650347
Validation loss: 2.4458647796923105

Epoch: 5| Step: 5
Training loss: 2.5059146533081105
Validation loss: 2.436022534994633

Epoch: 5| Step: 6
Training loss: 2.893038015749411
Validation loss: 2.4364142417421126

Epoch: 5| Step: 7
Training loss: 3.142440347158434
Validation loss: 2.430265867096929

Epoch: 5| Step: 8
Training loss: 2.9721066421742095
Validation loss: 2.445755689682384

Epoch: 5| Step: 9
Training loss: 2.9333107477821367
Validation loss: 2.4666877940513925

Epoch: 5| Step: 10
Training loss: 2.8221708394009632
Validation loss: 2.43392044771725

Epoch: 75| Step: 0
Training loss: 3.122805320649802
Validation loss: 2.4461322421977885

Epoch: 5| Step: 1
Training loss: 2.322098580810092
Validation loss: 2.4422433712668377

Epoch: 5| Step: 2
Training loss: 2.3603296432771548
Validation loss: 2.433211893989387

Epoch: 5| Step: 3
Training loss: 2.922576004227825
Validation loss: 2.4346499739365126

Epoch: 5| Step: 4
Training loss: 3.012220447279756
Validation loss: 2.4508467049328813

Epoch: 5| Step: 5
Training loss: 3.2213522752505983
Validation loss: 2.465577976271186

Epoch: 5| Step: 6
Training loss: 2.723542998082157
Validation loss: 2.428833111878501

Epoch: 5| Step: 7
Training loss: 2.470844780400624
Validation loss: 2.4499376589587096

Epoch: 5| Step: 8
Training loss: 2.9518948369406615
Validation loss: 2.4724642548441396

Epoch: 5| Step: 9
Training loss: 2.391719692143064
Validation loss: 2.4648496087772704

Epoch: 5| Step: 10
Training loss: 2.6126208190723905
Validation loss: 2.440600228170459

Epoch: 76| Step: 0
Training loss: 2.874981092307901
Validation loss: 2.4494313950785442

Epoch: 5| Step: 1
Training loss: 2.7471275065977743
Validation loss: 2.45815626298911

Epoch: 5| Step: 2
Training loss: 2.630814697067507
Validation loss: 2.4639742572759062

Epoch: 5| Step: 3
Training loss: 3.0541273613274518
Validation loss: 2.4701536971792977

Epoch: 5| Step: 4
Training loss: 2.8553769035545096
Validation loss: 2.4617945254206073

Epoch: 5| Step: 5
Training loss: 2.7884792711822315
Validation loss: 2.46312514480389

Epoch: 5| Step: 6
Training loss: 3.136782900865644
Validation loss: 2.4420791983540076

Epoch: 5| Step: 7
Training loss: 2.377630583890384
Validation loss: 2.4484820079411675

Epoch: 5| Step: 8
Training loss: 2.2912447685519117
Validation loss: 2.4453898489746835

Epoch: 5| Step: 9
Training loss: 3.026430368764089
Validation loss: 2.4570164526053904

Epoch: 5| Step: 10
Training loss: 2.4571621470312004
Validation loss: 2.448932378508057

Epoch: 77| Step: 0
Training loss: 2.7041745656451126
Validation loss: 2.452590973085317

Epoch: 5| Step: 1
Training loss: 2.644590210926454
Validation loss: 2.4587880196059624

Epoch: 5| Step: 2
Training loss: 2.6166099708230113
Validation loss: 2.432476151503155

Epoch: 5| Step: 3
Training loss: 2.489208581616448
Validation loss: 2.4558838180861953

Epoch: 5| Step: 4
Training loss: 2.5633379798850355
Validation loss: 2.4506162386183314

Epoch: 5| Step: 5
Training loss: 2.868767991352387
Validation loss: 2.449759805610857

Epoch: 5| Step: 6
Training loss: 2.540626584060757
Validation loss: 2.469797101594404

Epoch: 5| Step: 7
Training loss: 3.218718445262121
Validation loss: 2.4534480133908274

Epoch: 5| Step: 8
Training loss: 2.885390702737896
Validation loss: 2.4622909467571583

Epoch: 5| Step: 9
Training loss: 2.6199148059418014
Validation loss: 2.4554771316886046

Epoch: 5| Step: 10
Training loss: 3.0026932389126464
Validation loss: 2.448620056876549

Epoch: 78| Step: 0
Training loss: 2.684888857595938
Validation loss: 2.4428254842439405

Epoch: 5| Step: 1
Training loss: 2.654325438760491
Validation loss: 2.4680241340247915

Epoch: 5| Step: 2
Training loss: 3.0144513470153984
Validation loss: 2.442285467314912

Epoch: 5| Step: 3
Training loss: 2.960892085630448
Validation loss: 2.4531186523522583

Epoch: 5| Step: 4
Training loss: 2.853187745857316
Validation loss: 2.445069108393117

Epoch: 5| Step: 5
Training loss: 2.9518156832603717
Validation loss: 2.431209432970654

Epoch: 5| Step: 6
Training loss: 2.4130093644581336
Validation loss: 2.4451744168768763

Epoch: 5| Step: 7
Training loss: 2.1584694538371845
Validation loss: 2.4522950128408882

Epoch: 5| Step: 8
Training loss: 3.1305110402079355
Validation loss: 2.46047777868258

Epoch: 5| Step: 9
Training loss: 2.462149669687276
Validation loss: 2.4564842787680496

Epoch: 5| Step: 10
Training loss: 2.903042736058216
Validation loss: 2.467074101482797

Epoch: 79| Step: 0
Training loss: 3.1476271275062864
Validation loss: 2.473625356721425

Epoch: 5| Step: 1
Training loss: 3.1187337993438033
Validation loss: 2.462368694207099

Epoch: 5| Step: 2
Training loss: 2.364000447449101
Validation loss: 2.4414105878237673

Epoch: 5| Step: 3
Training loss: 2.033138395043101
Validation loss: 2.4542795514204787

Epoch: 5| Step: 4
Training loss: 2.9901106277464233
Validation loss: 2.434824770963672

Epoch: 5| Step: 5
Training loss: 1.8352596248971391
Validation loss: 2.46639741804422

Epoch: 5| Step: 6
Training loss: 3.2761659017435414
Validation loss: 2.442736447727403

Epoch: 5| Step: 7
Training loss: 2.654489180424452
Validation loss: 2.451193365723433

Epoch: 5| Step: 8
Training loss: 2.638108448156485
Validation loss: 2.4510195760098084

Epoch: 5| Step: 9
Training loss: 2.7883427222763233
Validation loss: 2.4500703684763505

Epoch: 5| Step: 10
Training loss: 2.9622522821957658
Validation loss: 2.4532113740313144

Epoch: 80| Step: 0
Training loss: 2.7097226809678263
Validation loss: 2.4461557736918467

Epoch: 5| Step: 1
Training loss: 2.60803498906963
Validation loss: 2.456426183827911

Epoch: 5| Step: 2
Training loss: 2.897797794129891
Validation loss: 2.468743830639779

Epoch: 5| Step: 3
Training loss: 2.0363852511379683
Validation loss: 2.425100039503479

Epoch: 5| Step: 4
Training loss: 2.9217041292053723
Validation loss: 2.4508104945067872

Epoch: 5| Step: 5
Training loss: 2.9937083709307197
Validation loss: 2.4367718940909677

Epoch: 5| Step: 6
Training loss: 2.4674588460688573
Validation loss: 2.4438963108026677

Epoch: 5| Step: 7
Training loss: 2.9634078296727604
Validation loss: 2.4663009469163395

Epoch: 5| Step: 8
Training loss: 2.925515747246994
Validation loss: 2.4456867779600144

Epoch: 5| Step: 9
Training loss: 3.078739937484349
Validation loss: 2.4242189241087844

Epoch: 5| Step: 10
Training loss: 2.3248427635266156
Validation loss: 2.4393265240910154

Epoch: 81| Step: 0
Training loss: 2.2368528058767505
Validation loss: 2.4335107782122596

Epoch: 5| Step: 1
Training loss: 2.6676532787842024
Validation loss: 2.45414701415238

Epoch: 5| Step: 2
Training loss: 2.7321331316065147
Validation loss: 2.4495175466516352

Epoch: 5| Step: 3
Training loss: 2.750284353640348
Validation loss: 2.4381099870580325

Epoch: 5| Step: 4
Training loss: 3.1805535713941078
Validation loss: 2.4436523983662513

Epoch: 5| Step: 5
Training loss: 2.5170975634126287
Validation loss: 2.4458674199884256

Epoch: 5| Step: 6
Training loss: 2.8084884857273122
Validation loss: 2.4522951560613224

Epoch: 5| Step: 7
Training loss: 3.091379509791635
Validation loss: 2.4473176888816646

Epoch: 5| Step: 8
Training loss: 3.0189374213946327
Validation loss: 2.442730311320163

Epoch: 5| Step: 9
Training loss: 2.426133773669135
Validation loss: 2.4387534257863437

Epoch: 5| Step: 10
Training loss: 2.67040555824195
Validation loss: 2.452944630113978

Epoch: 82| Step: 0
Training loss: 2.706592518757035
Validation loss: 2.4573561212354407

Epoch: 5| Step: 1
Training loss: 3.3381763244465836
Validation loss: 2.438885712702311

Epoch: 5| Step: 2
Training loss: 2.4890451740780186
Validation loss: 2.45213525621476

Epoch: 5| Step: 3
Training loss: 2.6088042405927783
Validation loss: 2.4508391306727333

Epoch: 5| Step: 4
Training loss: 2.960219484903731
Validation loss: 2.455566143680984

Epoch: 5| Step: 5
Training loss: 2.2156357736688763
Validation loss: 2.4689818813740505

Epoch: 5| Step: 6
Training loss: 2.973571395866169
Validation loss: 2.4614227394694357

Epoch: 5| Step: 7
Training loss: 2.5672508487326677
Validation loss: 2.435109613700591

Epoch: 5| Step: 8
Training loss: 2.112450512187888
Validation loss: 2.454171275233365

Epoch: 5| Step: 9
Training loss: 2.6843131043799997
Validation loss: 2.4429292544603665

Epoch: 5| Step: 10
Training loss: 3.3933641470788505
Validation loss: 2.453908539248238

Epoch: 83| Step: 0
Training loss: 2.289635492158235
Validation loss: 2.455561774486682

Epoch: 5| Step: 1
Training loss: 2.63901258368345
Validation loss: 2.43890103845654

Epoch: 5| Step: 2
Training loss: 2.1966138356193774
Validation loss: 2.4473679687956236

Epoch: 5| Step: 3
Training loss: 2.4255102623584994
Validation loss: 2.445095632005551

Epoch: 5| Step: 4
Training loss: 3.142253700139446
Validation loss: 2.448803454661489

Epoch: 5| Step: 5
Training loss: 3.1956843600475837
Validation loss: 2.4466653642295815

Epoch: 5| Step: 6
Training loss: 2.6162342669965795
Validation loss: 2.4448283371197537

Epoch: 5| Step: 7
Training loss: 2.703714824558807
Validation loss: 2.4385714483346455

Epoch: 5| Step: 8
Training loss: 3.5056167221039614
Validation loss: 2.4614134458977914

Epoch: 5| Step: 9
Training loss: 2.298654399001952
Validation loss: 2.467102761895395

Epoch: 5| Step: 10
Training loss: 2.9242976135985117
Validation loss: 2.457423893052743

Epoch: 84| Step: 0
Training loss: 2.073307735289183
Validation loss: 2.4558761278322865

Epoch: 5| Step: 1
Training loss: 2.5327490618019373
Validation loss: 2.456068885286113

Epoch: 5| Step: 2
Training loss: 2.913692829319091
Validation loss: 2.443355084703669

Epoch: 5| Step: 3
Training loss: 2.637701910887017
Validation loss: 2.4664087893518984

Epoch: 5| Step: 4
Training loss: 2.943900743905239
Validation loss: 2.4524917124747576

Epoch: 5| Step: 5
Training loss: 2.643112365447106
Validation loss: 2.439872358153365

Epoch: 5| Step: 6
Training loss: 2.5069059355488275
Validation loss: 2.4456521913884033

Epoch: 5| Step: 7
Training loss: 3.0059402782119204
Validation loss: 2.4309535330552943

Epoch: 5| Step: 8
Training loss: 3.0030622747660507
Validation loss: 2.452950951038795

Epoch: 5| Step: 9
Training loss: 2.8260074507013737
Validation loss: 2.45184776466914

Epoch: 5| Step: 10
Training loss: 2.859580611043712
Validation loss: 2.448797263315321

Epoch: 85| Step: 0
Training loss: 2.807511292160573
Validation loss: 2.454654189550152

Epoch: 5| Step: 1
Training loss: 2.5628167863746487
Validation loss: 2.445103300596488

Epoch: 5| Step: 2
Training loss: 2.52537183761984
Validation loss: 2.429426237420703

Epoch: 5| Step: 3
Training loss: 2.81443669078087
Validation loss: 2.453900652142516

Epoch: 5| Step: 4
Training loss: 2.627467312886241
Validation loss: 2.44405742203668

Epoch: 5| Step: 5
Training loss: 2.8888009579636056
Validation loss: 2.4441629912284215

Epoch: 5| Step: 6
Training loss: 2.893775171949019
Validation loss: 2.4325245323748796

Epoch: 5| Step: 7
Training loss: 2.2905366596918046
Validation loss: 2.4711046019708887

Epoch: 5| Step: 8
Training loss: 2.735653736293883
Validation loss: 2.440788930900801

Epoch: 5| Step: 9
Training loss: 2.8806357500600326
Validation loss: 2.4474642853777633

Epoch: 5| Step: 10
Training loss: 2.9546688827662413
Validation loss: 2.4540826775139677

Epoch: 86| Step: 0
Training loss: 2.456380736776188
Validation loss: 2.436872543000737

Epoch: 5| Step: 1
Training loss: 3.1802792010307503
Validation loss: 2.4609052675177163

Epoch: 5| Step: 2
Training loss: 2.769298721258192
Validation loss: 2.4473760346037152

Epoch: 5| Step: 3
Training loss: 2.9981706127763026
Validation loss: 2.45673921087465

Epoch: 5| Step: 4
Training loss: 2.2220715657133674
Validation loss: 2.4498644164496293

Epoch: 5| Step: 5
Training loss: 2.9870740259612356
Validation loss: 2.4692606597065874

Epoch: 5| Step: 6
Training loss: 2.7648262551544547
Validation loss: 2.467860892378589

Epoch: 5| Step: 7
Training loss: 2.949365877435265
Validation loss: 2.4350770540804603

Epoch: 5| Step: 8
Training loss: 2.6481695799218445
Validation loss: 2.455346091578117

Epoch: 5| Step: 9
Training loss: 2.5248212769964384
Validation loss: 2.44264805132945

Epoch: 5| Step: 10
Training loss: 2.6125346715351254
Validation loss: 2.4640691298720356

Epoch: 87| Step: 0
Training loss: 2.254483735730389
Validation loss: 2.455630563599323

Epoch: 5| Step: 1
Training loss: 2.7664067084961936
Validation loss: 2.459294032539922

Epoch: 5| Step: 2
Training loss: 2.7263291048644525
Validation loss: 2.4448647619762633

Epoch: 5| Step: 3
Training loss: 2.4053178443170338
Validation loss: 2.457779452951294

Epoch: 5| Step: 4
Training loss: 2.9713889188793123
Validation loss: 2.4586126135157436

Epoch: 5| Step: 5
Training loss: 2.9012181190142665
Validation loss: 2.4531788890284094

Epoch: 5| Step: 6
Training loss: 3.0855368052259253
Validation loss: 2.448334526331397

Epoch: 5| Step: 7
Training loss: 2.824277083136122
Validation loss: 2.454093047664514

Epoch: 5| Step: 8
Training loss: 2.860587774846725
Validation loss: 2.451472171642006

Epoch: 5| Step: 9
Training loss: 2.4337640154747993
Validation loss: 2.4403751434837218

Epoch: 5| Step: 10
Training loss: 2.885768129906656
Validation loss: 2.442828631563863

Epoch: 88| Step: 0
Training loss: 2.2140421821345773
Validation loss: 2.453301651143946

Epoch: 5| Step: 1
Training loss: 2.617468064485891
Validation loss: 2.457074208057431

Epoch: 5| Step: 2
Training loss: 3.512661239887225
Validation loss: 2.4484787134506787

Epoch: 5| Step: 3
Training loss: 2.826642485626124
Validation loss: 2.4448473795743615

Epoch: 5| Step: 4
Training loss: 2.392462828057413
Validation loss: 2.4475849978560014

Epoch: 5| Step: 5
Training loss: 2.2525357686207816
Validation loss: 2.440025506315793

Epoch: 5| Step: 6
Training loss: 2.736102708221631
Validation loss: 2.4533746583306213

Epoch: 5| Step: 7
Training loss: 2.626191186840994
Validation loss: 2.455896689577829

Epoch: 5| Step: 8
Training loss: 2.6934760430111315
Validation loss: 2.446230294709657

Epoch: 5| Step: 9
Training loss: 2.495020102685583
Validation loss: 2.440889570663118

Epoch: 5| Step: 10
Training loss: 3.3994179900688315
Validation loss: 2.432295418208744

Epoch: 89| Step: 0
Training loss: 2.8449600495816845
Validation loss: 2.4357377679684933

Epoch: 5| Step: 1
Training loss: 2.7061219112398525
Validation loss: 2.444538088053911

Epoch: 5| Step: 2
Training loss: 2.983502165494235
Validation loss: 2.4195432390498754

Epoch: 5| Step: 3
Training loss: 3.19580417571678
Validation loss: 2.4395362167731394

Epoch: 5| Step: 4
Training loss: 2.718157298057797
Validation loss: 2.4450759403713977

Epoch: 5| Step: 5
Training loss: 2.6699845614326265
Validation loss: 2.443256009183904

Epoch: 5| Step: 6
Training loss: 2.5946136323691116
Validation loss: 2.455483408508536

Epoch: 5| Step: 7
Training loss: 2.120225929061545
Validation loss: 2.4357031232721735

Epoch: 5| Step: 8
Training loss: 2.6272872769005997
Validation loss: 2.4402609114087843

Epoch: 5| Step: 9
Training loss: 2.5096394666735593
Validation loss: 2.43207074129694

Epoch: 5| Step: 10
Training loss: 2.869385918505283
Validation loss: 2.4578053053518834

Epoch: 90| Step: 0
Training loss: 2.698023309158747
Validation loss: 2.4594660294768764

Epoch: 5| Step: 1
Training loss: 2.720895731640317
Validation loss: 2.450696327272452

Epoch: 5| Step: 2
Training loss: 2.756486611795806
Validation loss: 2.4368377787249766

Epoch: 5| Step: 3
Training loss: 2.7763441730931455
Validation loss: 2.4246898487460538

Epoch: 5| Step: 4
Training loss: 2.674214727346887
Validation loss: 2.438770315510013

Epoch: 5| Step: 5
Training loss: 3.0227086176788753
Validation loss: 2.4610105785920493

Epoch: 5| Step: 6
Training loss: 2.871588963988507
Validation loss: 2.4534658029764826

Epoch: 5| Step: 7
Training loss: 2.6860731018526085
Validation loss: 2.4365403805595185

Epoch: 5| Step: 8
Training loss: 2.49337835769324
Validation loss: 2.4417484628691026

Epoch: 5| Step: 9
Training loss: 2.2733287457543825
Validation loss: 2.4551106720641847

Epoch: 5| Step: 10
Training loss: 2.868085756879225
Validation loss: 2.442266831062063

Epoch: 91| Step: 0
Training loss: 2.7152815870522273
Validation loss: 2.4589178566382586

Epoch: 5| Step: 1
Training loss: 2.935705245384959
Validation loss: 2.449630250292284

Epoch: 5| Step: 2
Training loss: 2.79419729249187
Validation loss: 2.4397429870697884

Epoch: 5| Step: 3
Training loss: 2.7330028469825987
Validation loss: 2.438953819070556

Epoch: 5| Step: 4
Training loss: 3.1947205981615014
Validation loss: 2.4552398745048922

Epoch: 5| Step: 5
Training loss: 2.6738357042270686
Validation loss: 2.460488620961225

Epoch: 5| Step: 6
Training loss: 2.1826510501427965
Validation loss: 2.449119511823811

Epoch: 5| Step: 7
Training loss: 2.622068130236522
Validation loss: 2.451766532065889

Epoch: 5| Step: 8
Training loss: 2.8586187978242945
Validation loss: 2.43662186510801

Epoch: 5| Step: 9
Training loss: 2.24484871233497
Validation loss: 2.435218630040124

Epoch: 5| Step: 10
Training loss: 2.9060532698136536
Validation loss: 2.441338470896345

Epoch: 92| Step: 0
Training loss: 2.579614012773039
Validation loss: 2.4439905718823676

Epoch: 5| Step: 1
Training loss: 2.0983878623335044
Validation loss: 2.448376615029713

Epoch: 5| Step: 2
Training loss: 3.0280872637874583
Validation loss: 2.4598037829822728

Epoch: 5| Step: 3
Training loss: 2.1308726896854293
Validation loss: 2.4439633166847323

Epoch: 5| Step: 4
Training loss: 2.7644085983866837
Validation loss: 2.4451051501135903

Epoch: 5| Step: 5
Training loss: 3.1576338651887608
Validation loss: 2.4454605082383507

Epoch: 5| Step: 6
Training loss: 2.746851245486647
Validation loss: 2.4475762335836913

Epoch: 5| Step: 7
Training loss: 2.881437640586191
Validation loss: 2.458395453645508

Epoch: 5| Step: 8
Training loss: 2.4980886782443408
Validation loss: 2.4361230617482055

Epoch: 5| Step: 9
Training loss: 2.939559863614358
Validation loss: 2.452980008480156

Epoch: 5| Step: 10
Training loss: 2.966983309645809
Validation loss: 2.4435636133486947

Epoch: 93| Step: 0
Training loss: 2.384694241291886
Validation loss: 2.4440619764784732

Epoch: 5| Step: 1
Training loss: 2.395098222378892
Validation loss: 2.450709035099754

Epoch: 5| Step: 2
Training loss: 2.439647901958101
Validation loss: 2.4371612961382425

Epoch: 5| Step: 3
Training loss: 2.8798761894845852
Validation loss: 2.4586982504873394

Epoch: 5| Step: 4
Training loss: 2.7731880183235225
Validation loss: 2.453299239338821

Epoch: 5| Step: 5
Training loss: 2.353362145702285
Validation loss: 2.4458676327632562

Epoch: 5| Step: 6
Training loss: 2.252568474341657
Validation loss: 2.4324023442112104

Epoch: 5| Step: 7
Training loss: 2.5772235565975166
Validation loss: 2.4549575355619373

Epoch: 5| Step: 8
Training loss: 3.222790450567496
Validation loss: 2.455034413579474

Epoch: 5| Step: 9
Training loss: 2.9090002029539517
Validation loss: 2.4537972680676723

Epoch: 5| Step: 10
Training loss: 3.445776668084204
Validation loss: 2.4339459405263586

Epoch: 94| Step: 0
Training loss: 3.5558353121954416
Validation loss: 2.451076228118184

Epoch: 5| Step: 1
Training loss: 2.584176746222865
Validation loss: 2.4440783045335857

Epoch: 5| Step: 2
Training loss: 2.3725997440767927
Validation loss: 2.4712054854304655

Epoch: 5| Step: 3
Training loss: 2.816790635204268
Validation loss: 2.450412062899488

Epoch: 5| Step: 4
Training loss: 2.641216776070647
Validation loss: 2.4576508795052274

Epoch: 5| Step: 5
Training loss: 2.413324434604713
Validation loss: 2.4293865155521277

Epoch: 5| Step: 6
Training loss: 2.456946730865724
Validation loss: 2.4537025254133384

Epoch: 5| Step: 7
Training loss: 2.5751978122321484
Validation loss: 2.446350268495859

Epoch: 5| Step: 8
Training loss: 2.1406228838165293
Validation loss: 2.4295797116714017

Epoch: 5| Step: 9
Training loss: 2.556171324622102
Validation loss: 2.4556328373968563

Epoch: 5| Step: 10
Training loss: 3.4237615532069072
Validation loss: 2.448792357546995

Epoch: 95| Step: 0
Training loss: 2.3036324882652637
Validation loss: 2.439437700250082

Epoch: 5| Step: 1
Training loss: 2.3466318342304113
Validation loss: 2.43392489999878

Epoch: 5| Step: 2
Training loss: 2.9336187816217345
Validation loss: 2.454895841352421

Epoch: 5| Step: 3
Training loss: 2.4018915510637213
Validation loss: 2.4609544676941084

Epoch: 5| Step: 4
Training loss: 3.072568884528205
Validation loss: 2.4429692934189524

Epoch: 5| Step: 5
Training loss: 2.7898365303743047
Validation loss: 2.435273093218642

Epoch: 5| Step: 6
Training loss: 2.7167877482323335
Validation loss: 2.4593569454825017

Epoch: 5| Step: 7
Training loss: 2.561915819522726
Validation loss: 2.441291502259707

Epoch: 5| Step: 8
Training loss: 2.880601484749397
Validation loss: 2.4487065542163604

Epoch: 5| Step: 9
Training loss: 2.9058425781814754
Validation loss: 2.4553974537283167

Epoch: 5| Step: 10
Training loss: 2.812754640707796
Validation loss: 2.4559541848267665

Epoch: 96| Step: 0
Training loss: 2.6117124766811624
Validation loss: 2.4447330869681396

Epoch: 5| Step: 1
Training loss: 2.8569410627492737
Validation loss: 2.4765889420085516

Epoch: 5| Step: 2
Training loss: 2.6615583447044
Validation loss: 2.454618484912664

Epoch: 5| Step: 3
Training loss: 2.709212048128092
Validation loss: 2.4497835638793153

Epoch: 5| Step: 4
Training loss: 2.9531689191509285
Validation loss: 2.4347261401397486

Epoch: 5| Step: 5
Training loss: 2.6086420183265955
Validation loss: 2.445844074913347

Epoch: 5| Step: 6
Training loss: 2.9735098176020838
Validation loss: 2.4575320817430217

Epoch: 5| Step: 7
Training loss: 2.7338950471637076
Validation loss: 2.4387559381756234

Epoch: 5| Step: 8
Training loss: 2.4156147432294577
Validation loss: 2.4494170342696044

Epoch: 5| Step: 9
Training loss: 2.5944349924097323
Validation loss: 2.451970999623116

Epoch: 5| Step: 10
Training loss: 2.653415109613835
Validation loss: 2.443826110895011

Epoch: 97| Step: 0
Training loss: 3.173329287721422
Validation loss: 2.4607303769868394

Epoch: 5| Step: 1
Training loss: 2.8982129279893076
Validation loss: 2.4499751473765805

Epoch: 5| Step: 2
Training loss: 2.536670015393861
Validation loss: 2.4424033036295176

Epoch: 5| Step: 3
Training loss: 2.4069685420479527
Validation loss: 2.4305876593122524

Epoch: 5| Step: 4
Training loss: 3.3761911056449305
Validation loss: 2.4358380807200786

Epoch: 5| Step: 5
Training loss: 2.7127054479468566
Validation loss: 2.440649432217227

Epoch: 5| Step: 6
Training loss: 2.755961372331788
Validation loss: 2.4484161345656434

Epoch: 5| Step: 7
Training loss: 1.8424691746072854
Validation loss: 2.4536782293978807

Epoch: 5| Step: 8
Training loss: 2.676928910330025
Validation loss: 2.444514176028851

Epoch: 5| Step: 9
Training loss: 2.5723649847932224
Validation loss: 2.4455316350970246

Epoch: 5| Step: 10
Training loss: 2.4768405120473824
Validation loss: 2.421842098376468

Epoch: 98| Step: 0
Training loss: 2.581875841135531
Validation loss: 2.4618307284060497

Epoch: 5| Step: 1
Training loss: 2.485334774777536
Validation loss: 2.4318218149364057

Epoch: 5| Step: 2
Training loss: 3.0495501389729376
Validation loss: 2.43940150175441

Epoch: 5| Step: 3
Training loss: 2.0857931365730975
Validation loss: 2.4417500681963107

Epoch: 5| Step: 4
Training loss: 2.8461657313695494
Validation loss: 2.408929517388378

Epoch: 5| Step: 5
Training loss: 2.9133853074361724
Validation loss: 2.4367588800212383

Epoch: 5| Step: 6
Training loss: 3.235415821030296
Validation loss: 2.4562071481420564

Epoch: 5| Step: 7
Training loss: 2.4546233054058724
Validation loss: 2.45663330031534

Epoch: 5| Step: 8
Training loss: 2.598413893270698
Validation loss: 2.432429998757921

Epoch: 5| Step: 9
Training loss: 2.4365608166596724
Validation loss: 2.434423617735601

Epoch: 5| Step: 10
Training loss: 2.8165207838242754
Validation loss: 2.4332245424668635

Epoch: 99| Step: 0
Training loss: 2.5536829288616993
Validation loss: 2.4321265266797596

Epoch: 5| Step: 1
Training loss: 2.5156057605836977
Validation loss: 2.438305416461145

Epoch: 5| Step: 2
Training loss: 2.9643349996333526
Validation loss: 2.455748712676786

Epoch: 5| Step: 3
Training loss: 2.681525131372422
Validation loss: 2.448177124982499

Epoch: 5| Step: 4
Training loss: 2.369901102634262
Validation loss: 2.452124050812023

Epoch: 5| Step: 5
Training loss: 2.184568348023815
Validation loss: 2.442177417268154

Epoch: 5| Step: 6
Training loss: 2.668085098522261
Validation loss: 2.4431529716279106

Epoch: 5| Step: 7
Training loss: 3.062368740460768
Validation loss: 2.4270961133893394

Epoch: 5| Step: 8
Training loss: 2.914062663633122
Validation loss: 2.4452927582165445

Epoch: 5| Step: 9
Training loss: 2.82994164558339
Validation loss: 2.4410138440524363

Epoch: 5| Step: 10
Training loss: 2.9897961335867294
Validation loss: 2.4331317418880736

Epoch: 100| Step: 0
Training loss: 2.8434028832835208
Validation loss: 2.4465006932380726

Epoch: 5| Step: 1
Training loss: 2.195541749978173
Validation loss: 2.4359858290067837

Epoch: 5| Step: 2
Training loss: 2.7189899207177732
Validation loss: 2.4586987645295566

Epoch: 5| Step: 3
Training loss: 2.7383583917784997
Validation loss: 2.4474036791736316

Epoch: 5| Step: 4
Training loss: 2.8103018753969073
Validation loss: 2.435826863494672

Epoch: 5| Step: 5
Training loss: 2.8158366438127533
Validation loss: 2.4547871187390586

Epoch: 5| Step: 6
Training loss: 2.926869575777308
Validation loss: 2.4475106605387196

Epoch: 5| Step: 7
Training loss: 2.9508231744067976
Validation loss: 2.4278620249265335

Epoch: 5| Step: 8
Training loss: 3.0269677500876684
Validation loss: 2.447490023627283

Epoch: 5| Step: 9
Training loss: 2.212608541638741
Validation loss: 2.444074620726614

Epoch: 5| Step: 10
Training loss: 2.1533938302359243
Validation loss: 2.437231139991312

Epoch: 101| Step: 0
Training loss: 2.8229258256789453
Validation loss: 2.448316964378777

Epoch: 5| Step: 1
Training loss: 1.8024961039253697
Validation loss: 2.4634095916451577

Epoch: 5| Step: 2
Training loss: 2.5114860842192233
Validation loss: 2.450324594167055

Epoch: 5| Step: 3
Training loss: 2.343339095653469
Validation loss: 2.4517517886385796

Epoch: 5| Step: 4
Training loss: 2.749037314019151
Validation loss: 2.4710642584309537

Epoch: 5| Step: 5
Training loss: 3.4037979119242268
Validation loss: 2.4764499537158398

Epoch: 5| Step: 6
Training loss: 2.8321358076065226
Validation loss: 2.462201541703441

Epoch: 5| Step: 7
Training loss: 2.116462386278513
Validation loss: 2.4499856876861834

Epoch: 5| Step: 8
Training loss: 3.056004233122685
Validation loss: 2.4308751889809064

Epoch: 5| Step: 9
Training loss: 3.175532895520408
Validation loss: 2.436940565717158

Epoch: 5| Step: 10
Training loss: 2.5024715604128347
Validation loss: 2.4362585915273662

Epoch: 102| Step: 0
Training loss: 2.701773421358891
Validation loss: 2.443647659567891

Epoch: 5| Step: 1
Training loss: 3.1992651035923805
Validation loss: 2.45596662640875

Epoch: 5| Step: 2
Training loss: 2.539678129242481
Validation loss: 2.437734546846152

Epoch: 5| Step: 3
Training loss: 2.494146934029315
Validation loss: 2.442642317721933

Epoch: 5| Step: 4
Training loss: 3.024634309212896
Validation loss: 2.4509813337366464

Epoch: 5| Step: 5
Training loss: 3.113904404826041
Validation loss: 2.432670470133896

Epoch: 5| Step: 6
Training loss: 2.8545628479216174
Validation loss: 2.456803371510473

Epoch: 5| Step: 7
Training loss: 1.8240538692090453
Validation loss: 2.448756887272362

Epoch: 5| Step: 8
Training loss: 2.249865209992538
Validation loss: 2.4290746063476885

Epoch: 5| Step: 9
Training loss: 2.437303681904142
Validation loss: 2.4490079236060738

Epoch: 5| Step: 10
Training loss: 2.9957053916326672
Validation loss: 2.4387787850311495

Epoch: 103| Step: 0
Training loss: 2.9352370940693837
Validation loss: 2.4509350043720324

Epoch: 5| Step: 1
Training loss: 2.9836368946233254
Validation loss: 2.4394247828993763

Epoch: 5| Step: 2
Training loss: 2.543795449790481
Validation loss: 2.4384096802499124

Epoch: 5| Step: 3
Training loss: 2.5275302446708388
Validation loss: 2.439691206031973

Epoch: 5| Step: 4
Training loss: 2.819519269563162
Validation loss: 2.4367296880632727

Epoch: 5| Step: 5
Training loss: 2.4033614817367264
Validation loss: 2.4393239145498

Epoch: 5| Step: 6
Training loss: 2.4866231666864618
Validation loss: 2.4567351954312593

Epoch: 5| Step: 7
Training loss: 2.901375897990543
Validation loss: 2.442405594464555

Epoch: 5| Step: 8
Training loss: 2.6972644758947135
Validation loss: 2.4324985235339365

Epoch: 5| Step: 9
Training loss: 3.055398453421007
Validation loss: 2.4438101236646155

Epoch: 5| Step: 10
Training loss: 2.317935946714246
Validation loss: 2.4421453371367785

Epoch: 104| Step: 0
Training loss: 2.874154173780635
Validation loss: 2.4383981468293765

Epoch: 5| Step: 1
Training loss: 2.4613176324714856
Validation loss: 2.4435454253877937

Epoch: 5| Step: 2
Training loss: 2.8180302819708984
Validation loss: 2.450947594858118

Epoch: 5| Step: 3
Training loss: 2.201262315653933
Validation loss: 2.4328615924858585

Epoch: 5| Step: 4
Training loss: 2.9315108258449087
Validation loss: 2.4268471489676293

Epoch: 5| Step: 5
Training loss: 2.7359205836933755
Validation loss: 2.4545002735974117

Epoch: 5| Step: 6
Training loss: 2.925268640163919
Validation loss: 2.4327300154687137

Epoch: 5| Step: 7
Training loss: 2.3743151631036468
Validation loss: 2.458348317115411

Epoch: 5| Step: 8
Training loss: 2.860960807267841
Validation loss: 2.4254908461277376

Epoch: 5| Step: 9
Training loss: 2.582465015628634
Validation loss: 2.444612595463488

Epoch: 5| Step: 10
Training loss: 2.8063199278820963
Validation loss: 2.446240652036528

Epoch: 105| Step: 0
Training loss: 3.0417730408623025
Validation loss: 2.4512568986383174

Epoch: 5| Step: 1
Training loss: 2.747116224093101
Validation loss: 2.4473045753323186

Epoch: 5| Step: 2
Training loss: 2.8054687771947227
Validation loss: 2.452333232014752

Epoch: 5| Step: 3
Training loss: 2.834781463650289
Validation loss: 2.4301450042963704

Epoch: 5| Step: 4
Training loss: 1.8577270257150655
Validation loss: 2.4401007272598894

Epoch: 5| Step: 5
Training loss: 2.7376528901904216
Validation loss: 2.454301346054397

Epoch: 5| Step: 6
Training loss: 2.4754526437241333
Validation loss: 2.462419858862813

Epoch: 5| Step: 7
Training loss: 2.9964796710484034
Validation loss: 2.4471115523287836

Epoch: 5| Step: 8
Training loss: 2.4959048108632143
Validation loss: 2.4426897940634116

Epoch: 5| Step: 9
Training loss: 2.675107996534222
Validation loss: 2.4419405602317723

Epoch: 5| Step: 10
Training loss: 2.7467851053398755
Validation loss: 2.463380986089863

Epoch: 106| Step: 0
Training loss: 3.1540410838623214
Validation loss: 2.4590952071373855

Epoch: 5| Step: 1
Training loss: 2.939796037410954
Validation loss: 2.4442768133446333

Epoch: 5| Step: 2
Training loss: 2.8426982905088285
Validation loss: 2.4499960019311517

Epoch: 5| Step: 3
Training loss: 2.2065272473127417
Validation loss: 2.450358278849798

Epoch: 5| Step: 4
Training loss: 2.7048962032689876
Validation loss: 2.4347993768539955

Epoch: 5| Step: 5
Training loss: 2.5382676039376184
Validation loss: 2.463952704271497

Epoch: 5| Step: 6
Training loss: 2.571127347862844
Validation loss: 2.4388466315931154

Epoch: 5| Step: 7
Training loss: 2.866100302645429
Validation loss: 2.436060198087774

Epoch: 5| Step: 8
Training loss: 2.2293623603652852
Validation loss: 2.4316979057021877

Epoch: 5| Step: 9
Training loss: 2.140070154163174
Validation loss: 2.4461243525516383

Epoch: 5| Step: 10
Training loss: 3.1921070688116533
Validation loss: 2.4406939148973223

Epoch: 107| Step: 0
Training loss: 2.9621318733279502
Validation loss: 2.4454917638880866

Epoch: 5| Step: 1
Training loss: 2.851113981742864
Validation loss: 2.4271535647157823

Epoch: 5| Step: 2
Training loss: 2.8715147371520056
Validation loss: 2.4399180769738003

Epoch: 5| Step: 3
Training loss: 2.774717481511112
Validation loss: 2.4569054338280143

Epoch: 5| Step: 4
Training loss: 3.429601159888094
Validation loss: 2.4345143293324143

Epoch: 5| Step: 5
Training loss: 2.513725843346691
Validation loss: 2.4359801312861866

Epoch: 5| Step: 6
Training loss: 2.6949796167002695
Validation loss: 2.452921628833418

Epoch: 5| Step: 7
Training loss: 2.435349420468071
Validation loss: 2.4472873469642007

Epoch: 5| Step: 8
Training loss: 2.0777321350923255
Validation loss: 2.439854498875107

Epoch: 5| Step: 9
Training loss: 2.4450904818527723
Validation loss: 2.4377036681382207

Epoch: 5| Step: 10
Training loss: 2.186421046515347
Validation loss: 2.4243063280160704

Epoch: 108| Step: 0
Training loss: 2.6051640139326633
Validation loss: 2.420180140460083

Epoch: 5| Step: 1
Training loss: 2.9492257023407293
Validation loss: 2.460981708682295

Epoch: 5| Step: 2
Training loss: 2.5847972188249253
Validation loss: 2.449042645975176

Epoch: 5| Step: 3
Training loss: 3.1096979481511307
Validation loss: 2.4360365217158404

Epoch: 5| Step: 4
Training loss: 2.801333065818521
Validation loss: 2.4506280953228674

Epoch: 5| Step: 5
Training loss: 2.566029142081967
Validation loss: 2.4364733494108224

Epoch: 5| Step: 6
Training loss: 2.8696056012565028
Validation loss: 2.4292201023334714

Epoch: 5| Step: 7
Training loss: 2.440761047557088
Validation loss: 2.440610594684158

Epoch: 5| Step: 8
Training loss: 2.097322746489413
Validation loss: 2.4483208501758313

Epoch: 5| Step: 9
Training loss: 2.2723616843521453
Validation loss: 2.423983224948201

Epoch: 5| Step: 10
Training loss: 3.015642077145624
Validation loss: 2.4504133361342593

Epoch: 109| Step: 0
Training loss: 2.446937191929196
Validation loss: 2.4341335930058707

Epoch: 5| Step: 1
Training loss: 3.2969231624610793
Validation loss: 2.4502028332966126

Epoch: 5| Step: 2
Training loss: 2.2546587502701327
Validation loss: 2.4610140109990764

Epoch: 5| Step: 3
Training loss: 2.828981385791067
Validation loss: 2.4465053379644615

Epoch: 5| Step: 4
Training loss: 2.225752940990395
Validation loss: 2.4309544526509104

Epoch: 5| Step: 5
Training loss: 2.7869692515253472
Validation loss: 2.4369559983828406

Epoch: 5| Step: 6
Training loss: 2.5183242627360674
Validation loss: 2.4517103549506234

Epoch: 5| Step: 7
Training loss: 2.858294006462661
Validation loss: 2.4487678903256604

Epoch: 5| Step: 8
Training loss: 2.5675997346786694
Validation loss: 2.4512428947017315

Epoch: 5| Step: 9
Training loss: 2.8490519301936112
Validation loss: 2.438159324425686

Epoch: 5| Step: 10
Training loss: 2.6448452423626954
Validation loss: 2.4416238614795014

Epoch: 110| Step: 0
Training loss: 2.59758750423014
Validation loss: 2.452928517325698

Epoch: 5| Step: 1
Training loss: 2.913499547667343
Validation loss: 2.4405101078135223

Epoch: 5| Step: 2
Training loss: 2.5945776113097136
Validation loss: 2.456996791819759

Epoch: 5| Step: 3
Training loss: 2.1948244903190877
Validation loss: 2.454220419248287

Epoch: 5| Step: 4
Training loss: 2.7524618053644696
Validation loss: 2.452525161467413

Epoch: 5| Step: 5
Training loss: 2.617260103499715
Validation loss: 2.4334546205458945

Epoch: 5| Step: 6
Training loss: 2.8997743716106603
Validation loss: 2.4585732578798023

Epoch: 5| Step: 7
Training loss: 2.612733244636619
Validation loss: 2.4403187051846715

Epoch: 5| Step: 8
Training loss: 3.2061775362924108
Validation loss: 2.4421338150600347

Epoch: 5| Step: 9
Training loss: 2.9677221827899647
Validation loss: 2.4471204822171186

Epoch: 5| Step: 10
Training loss: 1.6953100389032034
Validation loss: 2.4497862051842745

Epoch: 111| Step: 0
Training loss: 2.564730812953636
Validation loss: 2.447792480153288

Epoch: 5| Step: 1
Training loss: 2.8841685178835825
Validation loss: 2.429379346087711

Epoch: 5| Step: 2
Training loss: 2.9611594084267496
Validation loss: 2.4573001480646472

Epoch: 5| Step: 3
Training loss: 2.3361519297288083
Validation loss: 2.439313753812582

Epoch: 5| Step: 4
Training loss: 2.090251676016981
Validation loss: 2.4463656763832935

Epoch: 5| Step: 5
Training loss: 2.6503706546894095
Validation loss: 2.4480227798017573

Epoch: 5| Step: 6
Training loss: 3.1233990955520263
Validation loss: 2.453656449080788

Epoch: 5| Step: 7
Training loss: 2.4090314370301624
Validation loss: 2.437752215533779

Epoch: 5| Step: 8
Training loss: 2.4898056080017987
Validation loss: 2.4453624038927297

Epoch: 5| Step: 9
Training loss: 3.282744294465263
Validation loss: 2.4266053055182137

Epoch: 5| Step: 10
Training loss: 2.3529346809578042
Validation loss: 2.429562034199201

Epoch: 112| Step: 0
Training loss: 2.9515450908739163
Validation loss: 2.432644921804582

Epoch: 5| Step: 1
Training loss: 2.9415803531018634
Validation loss: 2.434261066390141

Epoch: 5| Step: 2
Training loss: 2.7653310156137776
Validation loss: 2.451265893955234

Epoch: 5| Step: 3
Training loss: 3.135184514944698
Validation loss: 2.43984968230089

Epoch: 5| Step: 4
Training loss: 1.9903463195524496
Validation loss: 2.4437513487132634

Epoch: 5| Step: 5
Training loss: 2.8494448807153407
Validation loss: 2.454766973795096

Epoch: 5| Step: 6
Training loss: 2.337385360436133
Validation loss: 2.4428087348506344

Epoch: 5| Step: 7
Training loss: 2.3048463928277845
Validation loss: 2.471701678240642

Epoch: 5| Step: 8
Training loss: 2.226332696131633
Validation loss: 2.4359011332373535

Epoch: 5| Step: 9
Training loss: 3.0866247256940103
Validation loss: 2.4561358899630292

Epoch: 5| Step: 10
Training loss: 2.759289397383976
Validation loss: 2.4617020916238546

Epoch: 113| Step: 0
Training loss: 2.4472416589633568
Validation loss: 2.437543566251091

Epoch: 5| Step: 1
Training loss: 2.8236113722209453
Validation loss: 2.44543975757897

Epoch: 5| Step: 2
Training loss: 2.56303483917455
Validation loss: 2.4526116350185707

Epoch: 5| Step: 3
Training loss: 2.6571124303631435
Validation loss: 2.4473508325314755

Epoch: 5| Step: 4
Training loss: 2.762774965574738
Validation loss: 2.426414497582942

Epoch: 5| Step: 5
Training loss: 2.050591160274983
Validation loss: 2.4513240745875566

Epoch: 5| Step: 6
Training loss: 2.306554006166302
Validation loss: 2.4472572099916654

Epoch: 5| Step: 7
Training loss: 3.265964618161832
Validation loss: 2.438120919342495

Epoch: 5| Step: 8
Training loss: 2.6543164564790036
Validation loss: 2.4454976595928968

Epoch: 5| Step: 9
Training loss: 3.312195673944267
Validation loss: 2.4304576769300352

Epoch: 5| Step: 10
Training loss: 2.2755973492801895
Validation loss: 2.455838582303615

Epoch: 114| Step: 0
Training loss: 2.8111153479013526
Validation loss: 2.443959886555195

Epoch: 5| Step: 1
Training loss: 2.4362476750886803
Validation loss: 2.423052155759024

Epoch: 5| Step: 2
Training loss: 2.6351939673937808
Validation loss: 2.4263773414249115

Epoch: 5| Step: 3
Training loss: 2.497223361162042
Validation loss: 2.458321319128024

Epoch: 5| Step: 4
Training loss: 3.035387813419637
Validation loss: 2.4512675714877217

Epoch: 5| Step: 5
Training loss: 3.072349435641639
Validation loss: 2.4463786487788726

Epoch: 5| Step: 6
Training loss: 2.3642288704148084
Validation loss: 2.4341001914468188

Epoch: 5| Step: 7
Training loss: 2.8157592538205525
Validation loss: 2.433599160452615

Epoch: 5| Step: 8
Training loss: 2.9792735651929187
Validation loss: 2.4367083738309074

Epoch: 5| Step: 9
Training loss: 2.3059324878163063
Validation loss: 2.4414841091415576

Epoch: 5| Step: 10
Training loss: 2.43869654312868
Validation loss: 2.419983882411383

Epoch: 115| Step: 0
Training loss: 3.004384810048977
Validation loss: 2.4522728470256943

Epoch: 5| Step: 1
Training loss: 2.62520952750899
Validation loss: 2.441258358255836

Epoch: 5| Step: 2
Training loss: 2.538705090529841
Validation loss: 2.4496234760173596

Epoch: 5| Step: 3
Training loss: 2.802959451709433
Validation loss: 2.458691492855414

Epoch: 5| Step: 4
Training loss: 2.414501755142443
Validation loss: 2.457828717785532

Epoch: 5| Step: 5
Training loss: 2.564812802776716
Validation loss: 2.4433412474236733

Epoch: 5| Step: 6
Training loss: 2.8096952228272416
Validation loss: 2.4380759607055293

Epoch: 5| Step: 7
Training loss: 2.4478085974247383
Validation loss: 2.4482814359079277

Epoch: 5| Step: 8
Training loss: 3.0500804765433833
Validation loss: 2.4356412844851736

Epoch: 5| Step: 9
Training loss: 2.934470054703766
Validation loss: 2.450088202466969

Epoch: 5| Step: 10
Training loss: 1.936803815726989
Validation loss: 2.4463155435424855

Epoch: 116| Step: 0
Training loss: 2.5618230344178876
Validation loss: 2.4617908254278063

Epoch: 5| Step: 1
Training loss: 3.047582456178909
Validation loss: 2.4566944218216404

Epoch: 5| Step: 2
Training loss: 2.4675142116581834
Validation loss: 2.447023583225128

Epoch: 5| Step: 3
Training loss: 2.4136795678473764
Validation loss: 2.4371655636772718

Epoch: 5| Step: 4
Training loss: 3.0027518367048702
Validation loss: 2.4392547380939984

Epoch: 5| Step: 5
Training loss: 2.9461840243229513
Validation loss: 2.45593905108499

Epoch: 5| Step: 6
Training loss: 2.2406505673704173
Validation loss: 2.4353043643471937

Epoch: 5| Step: 7
Training loss: 2.612725579410916
Validation loss: 2.4425333377873235

Epoch: 5| Step: 8
Training loss: 2.3737647207083907
Validation loss: 2.434166135756486

Epoch: 5| Step: 9
Training loss: 2.7838152081886265
Validation loss: 2.439275687455519

Epoch: 5| Step: 10
Training loss: 2.700304268540898
Validation loss: 2.456846139467305

Epoch: 117| Step: 0
Training loss: 2.563045722723264
Validation loss: 2.442246484696632

Epoch: 5| Step: 1
Training loss: 2.3485727155772724
Validation loss: 2.44418902436203

Epoch: 5| Step: 2
Training loss: 2.481612102693502
Validation loss: 2.4436221578137842

Epoch: 5| Step: 3
Training loss: 2.334247500858397
Validation loss: 2.44735880830991

Epoch: 5| Step: 4
Training loss: 2.9460982430645597
Validation loss: 2.4320087036826172

Epoch: 5| Step: 5
Training loss: 3.2035376306249437
Validation loss: 2.4344530684941446

Epoch: 5| Step: 6
Training loss: 2.6031053338561603
Validation loss: 2.427989773200987

Epoch: 5| Step: 7
Training loss: 3.036647906310011
Validation loss: 2.444690826481244

Epoch: 5| Step: 8
Training loss: 2.5523169481956254
Validation loss: 2.4290492355011466

Epoch: 5| Step: 9
Training loss: 2.5123967846977844
Validation loss: 2.436006516019572

Epoch: 5| Step: 10
Training loss: 2.6852889613368776
Validation loss: 2.435352347965974

Epoch: 118| Step: 0
Training loss: 3.055857402650201
Validation loss: 2.4405819950162284

Epoch: 5| Step: 1
Training loss: 2.3973157415299724
Validation loss: 2.4466401548369494

Epoch: 5| Step: 2
Training loss: 2.5962918247606233
Validation loss: 2.4594753408307115

Epoch: 5| Step: 3
Training loss: 2.8823188834679785
Validation loss: 2.4540728432237375

Epoch: 5| Step: 4
Training loss: 2.729818853439769
Validation loss: 2.458396053261483

Epoch: 5| Step: 5
Training loss: 1.9946553222699992
Validation loss: 2.4534014401149005

Epoch: 5| Step: 6
Training loss: 2.5848476729530128
Validation loss: 2.4254559905912485

Epoch: 5| Step: 7
Training loss: 2.3185027286265862
Validation loss: 2.445213706138488

Epoch: 5| Step: 8
Training loss: 2.4547415102741845
Validation loss: 2.4373137353196603

Epoch: 5| Step: 9
Training loss: 3.320546005116437
Validation loss: 2.4353833891224403

Epoch: 5| Step: 10
Training loss: 2.7037888962994048
Validation loss: 2.4468091426000598

Epoch: 119| Step: 0
Training loss: 2.535753552998195
Validation loss: 2.461366132814747

Epoch: 5| Step: 1
Training loss: 2.9868452623590755
Validation loss: 2.437919061111698

Epoch: 5| Step: 2
Training loss: 2.23019466286083
Validation loss: 2.444498886514854

Epoch: 5| Step: 3
Training loss: 2.301348838030471
Validation loss: 2.430048853672906

Epoch: 5| Step: 4
Training loss: 2.572023141332671
Validation loss: 2.4527805541930143

Epoch: 5| Step: 5
Training loss: 3.069125268680957
Validation loss: 2.4487659545875173

Epoch: 5| Step: 6
Training loss: 2.679608669178035
Validation loss: 2.426505025762177

Epoch: 5| Step: 7
Training loss: 3.2020576001144456
Validation loss: 2.4389253008837084

Epoch: 5| Step: 8
Training loss: 2.4071157309995583
Validation loss: 2.4474346387100665

Epoch: 5| Step: 9
Training loss: 2.4173755811768207
Validation loss: 2.436700639892607

Epoch: 5| Step: 10
Training loss: 2.8256720764653176
Validation loss: 2.4309790411588086

Epoch: 120| Step: 0
Training loss: 2.4672578575727333
Validation loss: 2.4498739181231395

Epoch: 5| Step: 1
Training loss: 3.026778393530402
Validation loss: 2.4540906105211553

Epoch: 5| Step: 2
Training loss: 1.9802860574520513
Validation loss: 2.454827259836713

Epoch: 5| Step: 3
Training loss: 2.6178991460469385
Validation loss: 2.4365444440143897

Epoch: 5| Step: 4
Training loss: 1.8477356069027726
Validation loss: 2.433406693269603

Epoch: 5| Step: 5
Training loss: 3.4572126265537437
Validation loss: 2.4275595542692807

Epoch: 5| Step: 6
Training loss: 2.877101959087199
Validation loss: 2.4441734663989623

Epoch: 5| Step: 7
Training loss: 2.556342379292816
Validation loss: 2.45265712786994

Epoch: 5| Step: 8
Training loss: 2.4506040606957673
Validation loss: 2.4305693689784897

Epoch: 5| Step: 9
Training loss: 2.9638679919171067
Validation loss: 2.4635292772161366

Epoch: 5| Step: 10
Training loss: 2.7341921499968227
Validation loss: 2.44066003170814

Epoch: 121| Step: 0
Training loss: 2.280219694562072
Validation loss: 2.4415950552834107

Epoch: 5| Step: 1
Training loss: 2.5844985323514513
Validation loss: 2.418934286133333

Epoch: 5| Step: 2
Training loss: 3.014284774945422
Validation loss: 2.445696213054098

Epoch: 5| Step: 3
Training loss: 2.8422394817478778
Validation loss: 2.4375915720492847

Epoch: 5| Step: 4
Training loss: 2.789779528175375
Validation loss: 2.4560537767805113

Epoch: 5| Step: 5
Training loss: 2.7183105288947846
Validation loss: 2.4842693656989803

Epoch: 5| Step: 6
Training loss: 2.399279418694994
Validation loss: 2.4550735983039704

Epoch: 5| Step: 7
Training loss: 3.000860726541246
Validation loss: 2.4540354691140562

Epoch: 5| Step: 8
Training loss: 2.1203020560809245
Validation loss: 2.419208706797274

Epoch: 5| Step: 9
Training loss: 2.452977753125846
Validation loss: 2.447417386641547

Epoch: 5| Step: 10
Training loss: 2.8129477250510058
Validation loss: 2.4498587133349456

Epoch: 122| Step: 0
Training loss: 2.9254352278383866
Validation loss: 2.4310043338643816

Epoch: 5| Step: 1
Training loss: 3.0408423539168403
Validation loss: 2.453142019640889

Epoch: 5| Step: 2
Training loss: 2.2224485705918555
Validation loss: 2.4700599062385864

Epoch: 5| Step: 3
Training loss: 2.435677458345277
Validation loss: 2.4337446450777716

Epoch: 5| Step: 4
Training loss: 2.576763834122569
Validation loss: 2.4341456110936037

Epoch: 5| Step: 5
Training loss: 2.813717218425852
Validation loss: 2.4403116539823966

Epoch: 5| Step: 6
Training loss: 2.670762840050878
Validation loss: 2.435007102116888

Epoch: 5| Step: 7
Training loss: 2.608708827704177
Validation loss: 2.4271003690506654

Epoch: 5| Step: 8
Training loss: 2.2000401319831475
Validation loss: 2.4328473356626534

Epoch: 5| Step: 9
Training loss: 2.702166348733328
Validation loss: 2.439391834228618

Epoch: 5| Step: 10
Training loss: 2.9204816300843524
Validation loss: 2.4337455994334247

Epoch: 123| Step: 0
Training loss: 2.894398962954224
Validation loss: 2.437489427786029

Epoch: 5| Step: 1
Training loss: 2.6700552828205395
Validation loss: 2.4369168921126096

Epoch: 5| Step: 2
Training loss: 2.4709265083984198
Validation loss: 2.4356999551671374

Epoch: 5| Step: 3
Training loss: 2.3814200913764307
Validation loss: 2.444576578990881

Epoch: 5| Step: 4
Training loss: 2.1871723474620013
Validation loss: 2.44742171171617

Epoch: 5| Step: 5
Training loss: 2.9205652249025627
Validation loss: 2.45432150265427

Epoch: 5| Step: 6
Training loss: 2.8783465272225173
Validation loss: 2.445373361414546

Epoch: 5| Step: 7
Training loss: 2.9492223070135832
Validation loss: 2.442780166165551

Epoch: 5| Step: 8
Training loss: 3.0515573371652116
Validation loss: 2.437847276785472

Epoch: 5| Step: 9
Training loss: 2.295492469790203
Validation loss: 2.450801972421291

Epoch: 5| Step: 10
Training loss: 2.2474370770668433
Validation loss: 2.4279331129923363

Epoch: 124| Step: 0
Training loss: 2.8017383254321873
Validation loss: 2.4514086850918537

Epoch: 5| Step: 1
Training loss: 2.5500657391021657
Validation loss: 2.433524542339502

Epoch: 5| Step: 2
Training loss: 2.8690698250071573
Validation loss: 2.4596546074871695

Epoch: 5| Step: 3
Training loss: 2.795083777685346
Validation loss: 2.4397628625506735

Epoch: 5| Step: 4
Training loss: 2.26425023955809
Validation loss: 2.45943787943358

Epoch: 5| Step: 5
Training loss: 2.4244821605124396
Validation loss: 2.4681440071486715

Epoch: 5| Step: 6
Training loss: 3.1106204505045563
Validation loss: 2.434050313642323

Epoch: 5| Step: 7
Training loss: 2.839827294807037
Validation loss: 2.4473077572220787

Epoch: 5| Step: 8
Training loss: 2.9919462181398266
Validation loss: 2.448706269973044

Epoch: 5| Step: 9
Training loss: 1.952094576819198
Validation loss: 2.448089814111615

Epoch: 5| Step: 10
Training loss: 2.1733377045702515
Validation loss: 2.4611145820458327

Epoch: 125| Step: 0
Training loss: 2.532015272712145
Validation loss: 2.4475121730534526

Epoch: 5| Step: 1
Training loss: 2.6342945851353057
Validation loss: 2.440016850951758

Epoch: 5| Step: 2
Training loss: 2.856064010340901
Validation loss: 2.4346194420288705

Epoch: 5| Step: 3
Training loss: 3.0555668416440973
Validation loss: 2.4323351674055576

Epoch: 5| Step: 4
Training loss: 2.67674409569862
Validation loss: 2.470593856450413

Epoch: 5| Step: 5
Training loss: 2.542365358551663
Validation loss: 2.434017603982177

Epoch: 5| Step: 6
Training loss: 2.788758333433961
Validation loss: 2.429703390233506

Epoch: 5| Step: 7
Training loss: 2.7416922184488772
Validation loss: 2.4268204079523925

Epoch: 5| Step: 8
Training loss: 2.0441375364997927
Validation loss: 2.446782369335884

Epoch: 5| Step: 9
Training loss: 2.5603147353473683
Validation loss: 2.438483883942764

Epoch: 5| Step: 10
Training loss: 2.389785220179857
Validation loss: 2.434413922017008

Epoch: 126| Step: 0
Training loss: 2.5508898584865234
Validation loss: 2.4352669616912497

Epoch: 5| Step: 1
Training loss: 3.185802082291324
Validation loss: 2.43270745008284

Epoch: 5| Step: 2
Training loss: 2.923107193392418
Validation loss: 2.450220055289824

Epoch: 5| Step: 3
Training loss: 2.800917958603507
Validation loss: 2.460980647174864

Epoch: 5| Step: 4
Training loss: 2.4953209959875617
Validation loss: 2.4469110675477856

Epoch: 5| Step: 5
Training loss: 2.1349099154976163
Validation loss: 2.4574195386369158

Epoch: 5| Step: 6
Training loss: 2.6430827784599376
Validation loss: 2.4588567320149854

Epoch: 5| Step: 7
Training loss: 2.4464973284911244
Validation loss: 2.4346387701908343

Epoch: 5| Step: 8
Training loss: 2.8010118461393794
Validation loss: 2.4479876408251235

Epoch: 5| Step: 9
Training loss: 2.961696557656403
Validation loss: 2.4541172805517233

Epoch: 5| Step: 10
Training loss: 1.801213144405792
Validation loss: 2.4753648750209827

Epoch: 127| Step: 0
Training loss: 2.720340395132007
Validation loss: 2.4507706192180763

Epoch: 5| Step: 1
Training loss: 2.471299605308263
Validation loss: 2.455128751375654

Epoch: 5| Step: 2
Training loss: 2.249279012664446
Validation loss: 2.467890170049508

Epoch: 5| Step: 3
Training loss: 2.8717322645113774
Validation loss: 2.43010440063339

Epoch: 5| Step: 4
Training loss: 2.395083688854615
Validation loss: 2.465453991698495

Epoch: 5| Step: 5
Training loss: 1.913641435669578
Validation loss: 2.447671694117168

Epoch: 5| Step: 6
Training loss: 2.664610328169725
Validation loss: 2.4399014515697095

Epoch: 5| Step: 7
Training loss: 2.4756702055122735
Validation loss: 2.433329627120898

Epoch: 5| Step: 8
Training loss: 3.223404269248245
Validation loss: 2.4413541010055426

Epoch: 5| Step: 9
Training loss: 3.03721660657764
Validation loss: 2.441781353492569

Epoch: 5| Step: 10
Training loss: 2.599259098566496
Validation loss: 2.4391227423632778

Epoch: 128| Step: 0
Training loss: 2.6844282116128984
Validation loss: 2.443790097517829

Epoch: 5| Step: 1
Training loss: 2.9553401651829114
Validation loss: 2.4711652088950986

Epoch: 5| Step: 2
Training loss: 2.3018352898500622
Validation loss: 2.4170726531286517

Epoch: 5| Step: 3
Training loss: 3.079450757484756
Validation loss: 2.44431681239974

Epoch: 5| Step: 4
Training loss: 2.6596698064151676
Validation loss: 2.459309701247742

Epoch: 5| Step: 5
Training loss: 2.710685608344346
Validation loss: 2.469360207612344

Epoch: 5| Step: 6
Training loss: 2.592790908898291
Validation loss: 2.435497841546738

Epoch: 5| Step: 7
Training loss: 2.513607661591186
Validation loss: 2.469730735361403

Epoch: 5| Step: 8
Training loss: 2.4288687844514203
Validation loss: 2.4517084780010507

Epoch: 5| Step: 9
Training loss: 2.4293869176071303
Validation loss: 2.4618426206555886

Epoch: 5| Step: 10
Training loss: 2.5611618083405423
Validation loss: 2.449845795992708

Epoch: 129| Step: 0
Training loss: 2.5017112597159863
Validation loss: 2.4312465817116675

Epoch: 5| Step: 1
Training loss: 3.048560043366818
Validation loss: 2.440307390894619

Epoch: 5| Step: 2
Training loss: 2.156723412774903
Validation loss: 2.459300448685092

Epoch: 5| Step: 3
Training loss: 2.9563474481824694
Validation loss: 2.444236137125859

Epoch: 5| Step: 4
Training loss: 2.2840809435823277
Validation loss: 2.4491585902076234

Epoch: 5| Step: 5
Training loss: 3.0906161995695927
Validation loss: 2.4518065270871214

Epoch: 5| Step: 6
Training loss: 2.4426194251391053
Validation loss: 2.442709285586256

Epoch: 5| Step: 7
Training loss: 2.1541862009762673
Validation loss: 2.450108747389711

Epoch: 5| Step: 8
Training loss: 3.2023271264758977
Validation loss: 2.431450782096453

Epoch: 5| Step: 9
Training loss: 2.5288045868047275
Validation loss: 2.423219084599532

Epoch: 5| Step: 10
Training loss: 2.350223197888877
Validation loss: 2.4370632237811924

Epoch: 130| Step: 0
Training loss: 2.5653371224259742
Validation loss: 2.4675254344438673

Epoch: 5| Step: 1
Training loss: 2.32684137173026
Validation loss: 2.453004449364719

Epoch: 5| Step: 2
Training loss: 3.0013559773778744
Validation loss: 2.4459629341117375

Epoch: 5| Step: 3
Training loss: 2.0552390631034503
Validation loss: 2.4360354251337

Epoch: 5| Step: 4
Training loss: 2.141219787384509
Validation loss: 2.422640223554484

Epoch: 5| Step: 5
Training loss: 2.820925659141314
Validation loss: 2.4432506001796677

Epoch: 5| Step: 6
Training loss: 2.714059400803768
Validation loss: 2.442648863668142

Epoch: 5| Step: 7
Training loss: 2.699331101813336
Validation loss: 2.461025169674365

Epoch: 5| Step: 8
Training loss: 3.112467852200476
Validation loss: 2.4193490851754307

Epoch: 5| Step: 9
Training loss: 2.542998189213716
Validation loss: 2.443545151560168

Epoch: 5| Step: 10
Training loss: 2.780245824689451
Validation loss: 2.454937589907341

Epoch: 131| Step: 0
Training loss: 2.225715984915374
Validation loss: 2.425875922237092

Epoch: 5| Step: 1
Training loss: 3.100333712674145
Validation loss: 2.448488505293733

Epoch: 5| Step: 2
Training loss: 2.4911490163132095
Validation loss: 2.440314528253245

Epoch: 5| Step: 3
Training loss: 1.949916309614839
Validation loss: 2.4315136457870588

Epoch: 5| Step: 4
Training loss: 3.2382715314804407
Validation loss: 2.4628855307947934

Epoch: 5| Step: 5
Training loss: 2.6042031756067128
Validation loss: 2.4289016542206605

Epoch: 5| Step: 6
Training loss: 2.4347978922411633
Validation loss: 2.445193515349001

Epoch: 5| Step: 7
Training loss: 3.3084416990684984
Validation loss: 2.44162502878739

Epoch: 5| Step: 8
Training loss: 2.4404023326548128
Validation loss: 2.426880130626182

Epoch: 5| Step: 9
Training loss: 2.1200746789410765
Validation loss: 2.432804924030679

Epoch: 5| Step: 10
Training loss: 2.7779394441819627
Validation loss: 2.442739364273345

Epoch: 132| Step: 0
Training loss: 2.8928629691790215
Validation loss: 2.446617782711095

Epoch: 5| Step: 1
Training loss: 2.9754800104730346
Validation loss: 2.435803277473164

Epoch: 5| Step: 2
Training loss: 2.5926618936399453
Validation loss: 2.464924079456207

Epoch: 5| Step: 3
Training loss: 2.4262211350105085
Validation loss: 2.441617986870051

Epoch: 5| Step: 4
Training loss: 2.5661399854146016
Validation loss: 2.4461858582090863

Epoch: 5| Step: 5
Training loss: 2.917165622721093
Validation loss: 2.4543727692596278

Epoch: 5| Step: 6
Training loss: 2.1423517766577764
Validation loss: 2.4647467416845243

Epoch: 5| Step: 7
Training loss: 3.058297991916556
Validation loss: 2.456328244520663

Epoch: 5| Step: 8
Training loss: 2.326264835168925
Validation loss: 2.4459013620565804

Epoch: 5| Step: 9
Training loss: 2.6738129664814108
Validation loss: 2.4497408442480593

Epoch: 5| Step: 10
Training loss: 2.063634849214743
Validation loss: 2.451928239686195

Epoch: 133| Step: 0
Training loss: 2.657653617258768
Validation loss: 2.448341353386058

Epoch: 5| Step: 1
Training loss: 2.697941302527003
Validation loss: 2.4400347142950043

Epoch: 5| Step: 2
Training loss: 2.5988231820008325
Validation loss: 2.4443267347113173

Epoch: 5| Step: 3
Training loss: 2.6085023620080006
Validation loss: 2.4291341290137893

Epoch: 5| Step: 4
Training loss: 2.778560666915557
Validation loss: 2.4634599000674977

Epoch: 5| Step: 5
Training loss: 2.5816838525635557
Validation loss: 2.4479675493644457

Epoch: 5| Step: 6
Training loss: 2.7049598420100818
Validation loss: 2.4653674153907974

Epoch: 5| Step: 7
Training loss: 2.4684971547117134
Validation loss: 2.4718599649350645

Epoch: 5| Step: 8
Training loss: 2.8160606733093085
Validation loss: 2.4442391541452158

Epoch: 5| Step: 9
Training loss: 2.495609433464494
Validation loss: 2.455505255099507

Epoch: 5| Step: 10
Training loss: 2.2429803915063835
Validation loss: 2.434201679622968

Epoch: 134| Step: 0
Training loss: 2.774686634137912
Validation loss: 2.458809833186154

Epoch: 5| Step: 1
Training loss: 2.800543143181349
Validation loss: 2.4417560233315814

Epoch: 5| Step: 2
Training loss: 2.4697610257641416
Validation loss: 2.453042021550402

Epoch: 5| Step: 3
Training loss: 2.662598148739754
Validation loss: 2.420382763152613

Epoch: 5| Step: 4
Training loss: 2.7142906009658767
Validation loss: 2.4386143993744764

Epoch: 5| Step: 5
Training loss: 2.5439022009302854
Validation loss: 2.455559373775535

Epoch: 5| Step: 6
Training loss: 2.7469512338659734
Validation loss: 2.4488673646870045

Epoch: 5| Step: 7
Training loss: 2.4152398556211065
Validation loss: 2.4580822568404006

Epoch: 5| Step: 8
Training loss: 2.383177282208577
Validation loss: 2.4368411452372816

Epoch: 5| Step: 9
Training loss: 2.867028172195232
Validation loss: 2.455275883868856

Epoch: 5| Step: 10
Training loss: 2.280122347610861
Validation loss: 2.4496539428392192

Epoch: 135| Step: 0
Training loss: 2.7912639403347432
Validation loss: 2.433695642730882

Epoch: 5| Step: 1
Training loss: 2.6346804730205466
Validation loss: 2.4335744003700968

Epoch: 5| Step: 2
Training loss: 2.066833105871012
Validation loss: 2.462688663023106

Epoch: 5| Step: 3
Training loss: 2.0051485787608097
Validation loss: 2.4482225096557584

Epoch: 5| Step: 4
Training loss: 2.621460299153245
Validation loss: 2.434743669559159

Epoch: 5| Step: 5
Training loss: 3.247815938826823
Validation loss: 2.4434471801510496

Epoch: 5| Step: 6
Training loss: 2.5810012956192567
Validation loss: 2.4433860462256676

Epoch: 5| Step: 7
Training loss: 2.3647134775877614
Validation loss: 2.4484132321112964

Epoch: 5| Step: 8
Training loss: 2.6606036242754785
Validation loss: 2.4408926837191487

Epoch: 5| Step: 9
Training loss: 2.6174180569797523
Validation loss: 2.4276420668045153

Epoch: 5| Step: 10
Training loss: 2.979705672866302
Validation loss: 2.4443347701757117

Epoch: 136| Step: 0
Training loss: 2.6417419960360635
Validation loss: 2.441804342123814

Epoch: 5| Step: 1
Training loss: 2.525923788459862
Validation loss: 2.44493176123943

Epoch: 5| Step: 2
Training loss: 3.4671453940132855
Validation loss: 2.442782337531682

Epoch: 5| Step: 3
Training loss: 2.025811529613657
Validation loss: 2.4344812362767625

Epoch: 5| Step: 4
Training loss: 2.788271580810541
Validation loss: 2.4457889986248493

Epoch: 5| Step: 5
Training loss: 2.194303341713844
Validation loss: 2.436197158300269

Epoch: 5| Step: 6
Training loss: 2.5959259465710045
Validation loss: 2.417571117797565

Epoch: 5| Step: 7
Training loss: 2.3857094086726898
Validation loss: 2.441727196646153

Epoch: 5| Step: 8
Training loss: 2.4438077056393643
Validation loss: 2.4387770473993866

Epoch: 5| Step: 9
Training loss: 2.6726529957412226
Validation loss: 2.4474097043516228

Epoch: 5| Step: 10
Training loss: 2.77028500478217
Validation loss: 2.4549050019095895

Epoch: 137| Step: 0
Training loss: 2.2418682655337543
Validation loss: 2.4687044308995896

Epoch: 5| Step: 1
Training loss: 2.8411324999269416
Validation loss: 2.426637914893051

Epoch: 5| Step: 2
Training loss: 2.511435105606524
Validation loss: 2.4371041180732984

Epoch: 5| Step: 3
Training loss: 2.032125313769561
Validation loss: 2.4450756100966435

Epoch: 5| Step: 4
Training loss: 2.792885860466902
Validation loss: 2.4330189051530158

Epoch: 5| Step: 5
Training loss: 2.693769107051626
Validation loss: 2.4431258760279446

Epoch: 5| Step: 6
Training loss: 3.1754321367438982
Validation loss: 2.432221793050113

Epoch: 5| Step: 7
Training loss: 2.8073335454550126
Validation loss: 2.4642531266840417

Epoch: 5| Step: 8
Training loss: 2.726756441492922
Validation loss: 2.4296857611421103

Epoch: 5| Step: 9
Training loss: 2.299784575615351
Validation loss: 2.451932239999463

Epoch: 5| Step: 10
Training loss: 2.558244567805681
Validation loss: 2.416711822387753

Epoch: 138| Step: 0
Training loss: 2.9936755591198394
Validation loss: 2.443993567701276

Epoch: 5| Step: 1
Training loss: 2.1452097557675414
Validation loss: 2.4566710935403524

Epoch: 5| Step: 2
Training loss: 2.646006320694967
Validation loss: 2.4331031291199094

Epoch: 5| Step: 3
Training loss: 1.8708497208838297
Validation loss: 2.4609512247984506

Epoch: 5| Step: 4
Training loss: 2.3033669001796615
Validation loss: 2.456404022937767

Epoch: 5| Step: 5
Training loss: 2.40540615990271
Validation loss: 2.4668427921491394

Epoch: 5| Step: 6
Training loss: 2.6992724533369636
Validation loss: 2.4355455024177823

Epoch: 5| Step: 7
Training loss: 2.817548332442916
Validation loss: 2.455627804868313

Epoch: 5| Step: 8
Training loss: 2.7344524263591574
Validation loss: 2.447078349389743

Epoch: 5| Step: 9
Training loss: 3.187123295084658
Validation loss: 2.4520067893376583

Epoch: 5| Step: 10
Training loss: 2.7018123372188705
Validation loss: 2.4421097167799037

Epoch: 139| Step: 0
Training loss: 1.9156904498769511
Validation loss: 2.4445148881178844

Epoch: 5| Step: 1
Training loss: 2.597221533174021
Validation loss: 2.430780520558561

Epoch: 5| Step: 2
Training loss: 2.8093492449469912
Validation loss: 2.454968063878248

Epoch: 5| Step: 3
Training loss: 2.405288999803746
Validation loss: 2.4537947590640905

Epoch: 5| Step: 4
Training loss: 2.986704930446383
Validation loss: 2.463153715341313

Epoch: 5| Step: 5
Training loss: 2.6114176903873907
Validation loss: 2.451135701800489

Epoch: 5| Step: 6
Training loss: 2.3616743188957052
Validation loss: 2.4528985019194787

Epoch: 5| Step: 7
Training loss: 2.8228216026224424
Validation loss: 2.4506168730905187

Epoch: 5| Step: 8
Training loss: 3.033610732281287
Validation loss: 2.419971045020256

Epoch: 5| Step: 9
Training loss: 2.504780395079713
Validation loss: 2.447663723547811

Epoch: 5| Step: 10
Training loss: 2.5418671596641613
Validation loss: 2.4370912819753223

Epoch: 140| Step: 0
Training loss: 2.8675289106699227
Validation loss: 2.4468799903286604

Epoch: 5| Step: 1
Training loss: 2.7066862428674443
Validation loss: 2.451404522873431

Epoch: 5| Step: 2
Training loss: 2.689058251297214
Validation loss: 2.4525684106449197

Epoch: 5| Step: 3
Training loss: 2.488067953169166
Validation loss: 2.463454304396404

Epoch: 5| Step: 4
Training loss: 2.9680701832660508
Validation loss: 2.4469075283981843

Epoch: 5| Step: 5
Training loss: 2.329592862883838
Validation loss: 2.435128660565966

Epoch: 5| Step: 6
Training loss: 3.39971380712214
Validation loss: 2.4356110802476727

Epoch: 5| Step: 7
Training loss: 2.6866033078367186
Validation loss: 2.4319429580856564

Epoch: 5| Step: 8
Training loss: 2.355017775450276
Validation loss: 2.484176618534492

Epoch: 5| Step: 9
Training loss: 1.9912196781701856
Validation loss: 2.449748752071959

Epoch: 5| Step: 10
Training loss: 1.6540626621300312
Validation loss: 2.4582388539736253

Epoch: 141| Step: 0
Training loss: 2.5601276488069957
Validation loss: 2.449095232102464

Epoch: 5| Step: 1
Training loss: 2.750364972951051
Validation loss: 2.4529318972888903

Epoch: 5| Step: 2
Training loss: 2.289941924745533
Validation loss: 2.4509808557306054

Epoch: 5| Step: 3
Training loss: 2.363244225077997
Validation loss: 2.449571882910006

Epoch: 5| Step: 4
Training loss: 2.554885903216539
Validation loss: 2.471795629874011

Epoch: 5| Step: 5
Training loss: 2.6649759018830146
Validation loss: 2.455159718439595

Epoch: 5| Step: 6
Training loss: 2.5412117180893814
Validation loss: 2.4733209201829727

Epoch: 5| Step: 7
Training loss: 2.5138292241143736
Validation loss: 2.450800831712741

Epoch: 5| Step: 8
Training loss: 2.613345659998932
Validation loss: 2.4686019736777713

Epoch: 5| Step: 9
Training loss: 2.7275811071600558
Validation loss: 2.454747859991594

Epoch: 5| Step: 10
Training loss: 2.8579009378722207
Validation loss: 2.4576359387596796

Epoch: 142| Step: 0
Training loss: 2.2644497684324247
Validation loss: 2.433132474166537

Epoch: 5| Step: 1
Training loss: 2.5416267475266063
Validation loss: 2.448727980728087

Epoch: 5| Step: 2
Training loss: 2.9223077626957963
Validation loss: 2.4464333355931758

Epoch: 5| Step: 3
Training loss: 2.403642207370612
Validation loss: 2.4490526972606887

Epoch: 5| Step: 4
Training loss: 2.530293884548077
Validation loss: 2.445084630775362

Epoch: 5| Step: 5
Training loss: 2.6791213079699476
Validation loss: 2.4510581827166598

Epoch: 5| Step: 6
Training loss: 2.7332735295460084
Validation loss: 2.4117057790456946

Epoch: 5| Step: 7
Training loss: 2.8384583253903917
Validation loss: 2.4720691234688874

Epoch: 5| Step: 8
Training loss: 2.6783481286840387
Validation loss: 2.4472967675072725

Epoch: 5| Step: 9
Training loss: 2.3158585156525135
Validation loss: 2.4571823594562616

Epoch: 5| Step: 10
Training loss: 2.71028661472095
Validation loss: 2.437559960582004

Epoch: 143| Step: 0
Training loss: 2.448505888022163
Validation loss: 2.432735726597375

Epoch: 5| Step: 1
Training loss: 2.124174069730545
Validation loss: 2.4377897136152105

Epoch: 5| Step: 2
Training loss: 2.687241830180088
Validation loss: 2.422568784400723

Epoch: 5| Step: 3
Training loss: 2.7051065932335487
Validation loss: 2.470566470330887

Epoch: 5| Step: 4
Training loss: 2.841390951732686
Validation loss: 2.4363039772490223

Epoch: 5| Step: 5
Training loss: 2.838040163493902
Validation loss: 2.432000231667018

Epoch: 5| Step: 6
Training loss: 2.1050686429536283
Validation loss: 2.44902677758907

Epoch: 5| Step: 7
Training loss: 2.5265604541701867
Validation loss: 2.4268683353666884

Epoch: 5| Step: 8
Training loss: 2.584091403442931
Validation loss: 2.432463904896274

Epoch: 5| Step: 9
Training loss: 2.8300924465325172
Validation loss: 2.4552915583804773

Epoch: 5| Step: 10
Training loss: 2.7984210807791454
Validation loss: 2.415003481816794

Epoch: 144| Step: 0
Training loss: 2.0810242126610734
Validation loss: 2.428957475446559

Epoch: 5| Step: 1
Training loss: 2.9804049143823255
Validation loss: 2.4531217206278964

Epoch: 5| Step: 2
Training loss: 2.535374236764028
Validation loss: 2.4414354133422824

Epoch: 5| Step: 3
Training loss: 2.3511041847292034
Validation loss: 2.441504398858774

Epoch: 5| Step: 4
Training loss: 2.617521532292596
Validation loss: 2.4496840325353872

Epoch: 5| Step: 5
Training loss: 2.7714949561273965
Validation loss: 2.4401529881395763

Epoch: 5| Step: 6
Training loss: 2.4981095796041863
Validation loss: 2.451642062339505

Epoch: 5| Step: 7
Training loss: 2.6326790161706115
Validation loss: 2.463845395283604

Epoch: 5| Step: 8
Training loss: 3.153688807973003
Validation loss: 2.459820956515877

Epoch: 5| Step: 9
Training loss: 2.0235764150176716
Validation loss: 2.435661358686176

Epoch: 5| Step: 10
Training loss: 2.6033635134378303
Validation loss: 2.429486399376464

Epoch: 145| Step: 0
Training loss: 2.890352968354773
Validation loss: 2.4596434665665177

Epoch: 5| Step: 1
Training loss: 2.916083486473844
Validation loss: 2.453709762766811

Epoch: 5| Step: 2
Training loss: 1.9734275594115112
Validation loss: 2.4634662585327063

Epoch: 5| Step: 3
Training loss: 2.847334897259344
Validation loss: 2.4375754324466183

Epoch: 5| Step: 4
Training loss: 2.0124034123906815
Validation loss: 2.4222821759059583

Epoch: 5| Step: 5
Training loss: 2.428807335302964
Validation loss: 2.4563681407410143

Epoch: 5| Step: 6
Training loss: 2.1960380685560446
Validation loss: 2.44794202244669

Epoch: 5| Step: 7
Training loss: 2.6658344360934385
Validation loss: 2.465048502000365

Epoch: 5| Step: 8
Training loss: 2.7870646354864377
Validation loss: 2.4534718728267375

Epoch: 5| Step: 9
Training loss: 2.7506052564914825
Validation loss: 2.4317261565300945

Epoch: 5| Step: 10
Training loss: 2.9845378092350274
Validation loss: 2.4430433460281926

Epoch: 146| Step: 0
Training loss: 2.611079772689012
Validation loss: 2.4601339205063404

Epoch: 5| Step: 1
Training loss: 2.5251753642306087
Validation loss: 2.4453204268622835

Epoch: 5| Step: 2
Training loss: 2.22594488847206
Validation loss: 2.4560093129045484

Epoch: 5| Step: 3
Training loss: 2.6032853936907143
Validation loss: 2.4613812758916125

Epoch: 5| Step: 4
Training loss: 2.9280973874869516
Validation loss: 2.4619673723061246

Epoch: 5| Step: 5
Training loss: 2.0652992441817184
Validation loss: 2.4467668818227892

Epoch: 5| Step: 6
Training loss: 2.9175250470574405
Validation loss: 2.449125450086776

Epoch: 5| Step: 7
Training loss: 2.778634974355075
Validation loss: 2.440127052729232

Epoch: 5| Step: 8
Training loss: 2.3632548180985715
Validation loss: 2.4484594311952983

Epoch: 5| Step: 9
Training loss: 2.6470875408135766
Validation loss: 2.4521463298373223

Epoch: 5| Step: 10
Training loss: 2.6918888185393084
Validation loss: 2.4476998045684524

Epoch: 147| Step: 0
Training loss: 3.0266752033981503
Validation loss: 2.459568479530423

Epoch: 5| Step: 1
Training loss: 2.389909026198156
Validation loss: 2.4416640068906834

Epoch: 5| Step: 2
Training loss: 2.870860229129972
Validation loss: 2.4268208188835514

Epoch: 5| Step: 3
Training loss: 2.630362528193428
Validation loss: 2.4351032759420677

Epoch: 5| Step: 4
Training loss: 2.8177369422423895
Validation loss: 2.455438803273858

Epoch: 5| Step: 5
Training loss: 2.619555412747614
Validation loss: 2.463569773286667

Epoch: 5| Step: 6
Training loss: 2.8322671305323315
Validation loss: 2.447672212046171

Epoch: 5| Step: 7
Training loss: 2.564782126619169
Validation loss: 2.444681961124122

Epoch: 5| Step: 8
Training loss: 1.9291375492389513
Validation loss: 2.460594951633881

Epoch: 5| Step: 9
Training loss: 2.3390762522362616
Validation loss: 2.4496460488374856

Epoch: 5| Step: 10
Training loss: 2.191525814718122
Validation loss: 2.437684190226067

Epoch: 148| Step: 0
Training loss: 2.7928870555960836
Validation loss: 2.4462354036869574

Epoch: 5| Step: 1
Training loss: 1.8638719945799833
Validation loss: 2.4707168930858816

Epoch: 5| Step: 2
Training loss: 2.611194912487805
Validation loss: 2.4434498545351975

Epoch: 5| Step: 3
Training loss: 2.749803275961398
Validation loss: 2.4396512404237543

Epoch: 5| Step: 4
Training loss: 2.9552030165073964
Validation loss: 2.435345796092365

Epoch: 5| Step: 5
Training loss: 2.335752958325049
Validation loss: 2.4482537488927285

Epoch: 5| Step: 6
Training loss: 2.0590994573863926
Validation loss: 2.445419308666598

Epoch: 5| Step: 7
Training loss: 2.9184308484086716
Validation loss: 2.4572356441122523

Epoch: 5| Step: 8
Training loss: 2.5306348641905916
Validation loss: 2.395271514320811

Epoch: 5| Step: 9
Training loss: 2.5027740346767913
Validation loss: 2.416871695118608

Epoch: 5| Step: 10
Training loss: 3.1003252535591237
Validation loss: 2.4599783433757434

Epoch: 149| Step: 0
Training loss: 2.4333486173315237
Validation loss: 2.458314806571325

Epoch: 5| Step: 1
Training loss: 2.9336740454848367
Validation loss: 2.41694385528716

Epoch: 5| Step: 2
Training loss: 2.8173181589202065
Validation loss: 2.4449137921199187

Epoch: 5| Step: 3
Training loss: 2.3905835116906475
Validation loss: 2.4578137895946717

Epoch: 5| Step: 4
Training loss: 2.225418492940032
Validation loss: 2.4419585774755137

Epoch: 5| Step: 5
Training loss: 2.868062148395768
Validation loss: 2.434083889668129

Epoch: 5| Step: 6
Training loss: 2.944475373719473
Validation loss: 2.4317564026958562

Epoch: 5| Step: 7
Training loss: 2.5252521237941385
Validation loss: 2.4329087365113495

Epoch: 5| Step: 8
Training loss: 2.52101817648727
Validation loss: 2.402681173509805

Epoch: 5| Step: 9
Training loss: 2.4112987314444525
Validation loss: 2.4485337993875684

Epoch: 5| Step: 10
Training loss: 2.306126135831259
Validation loss: 2.427789970691097

Epoch: 150| Step: 0
Training loss: 2.8172143208120373
Validation loss: 2.417617787489368

Epoch: 5| Step: 1
Training loss: 2.4052059336028444
Validation loss: 2.4452911683200895

Epoch: 5| Step: 2
Training loss: 2.78309167471482
Validation loss: 2.445840829277791

Epoch: 5| Step: 3
Training loss: 2.3136654571799706
Validation loss: 2.471894427494454

Epoch: 5| Step: 4
Training loss: 2.7768063997857086
Validation loss: 2.4432587719160748

Epoch: 5| Step: 5
Training loss: 2.7407127827382056
Validation loss: 2.4612951594017196

Epoch: 5| Step: 6
Training loss: 2.3479476976304445
Validation loss: 2.447290980890872

Epoch: 5| Step: 7
Training loss: 2.2298695415774517
Validation loss: 2.4276048153832748

Epoch: 5| Step: 8
Training loss: 2.5240340812002326
Validation loss: 2.442417971759237

Epoch: 5| Step: 9
Training loss: 2.8484590547366535
Validation loss: 2.4352309659612232

Epoch: 5| Step: 10
Training loss: 2.1806231715685853
Validation loss: 2.4328170134891565

Testing loss: 2.4415565491930438
