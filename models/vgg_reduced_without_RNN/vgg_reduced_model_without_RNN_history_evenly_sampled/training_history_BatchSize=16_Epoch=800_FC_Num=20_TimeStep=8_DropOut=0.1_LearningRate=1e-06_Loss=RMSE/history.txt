Epoch: 1| Step: 0
Training loss: 11.000391866466408
Validation loss: 10.910503732871096

Epoch: 6| Step: 1
Training loss: 9.34511553632201
Validation loss: 10.908342656135234

Epoch: 6| Step: 2
Training loss: 9.630573987165336
Validation loss: 10.904479312070926

Epoch: 6| Step: 3
Training loss: 10.987178612913794
Validation loss: 10.902726666026956

Epoch: 6| Step: 4
Training loss: 11.046949588680295
Validation loss: 10.900046708924275

Epoch: 6| Step: 5
Training loss: 10.5554840442399
Validation loss: 10.89783552764564

Epoch: 6| Step: 6
Training loss: 10.930368419974997
Validation loss: 10.895274050275049

Epoch: 6| Step: 7
Training loss: 11.776154972134766
Validation loss: 10.892167404849442

Epoch: 6| Step: 8
Training loss: 10.383747136262697
Validation loss: 10.890540500899851

Epoch: 6| Step: 9
Training loss: 10.769421443718407
Validation loss: 10.887371079526327

Epoch: 6| Step: 10
Training loss: 11.925980207356123
Validation loss: 10.885958270571738

Epoch: 6| Step: 11
Training loss: 11.066534136549263
Validation loss: 10.882082592126665

Epoch: 6| Step: 12
Training loss: 10.639795032907596
Validation loss: 10.880275387382278

Epoch: 6| Step: 13
Training loss: 11.117927274666156
Validation loss: 10.874722913003913

Epoch: 2| Step: 0
Training loss: 11.602784289621365
Validation loss: 10.87371945742042

Epoch: 6| Step: 1
Training loss: 10.131762848004444
Validation loss: 10.871609546017899

Epoch: 6| Step: 2
Training loss: 10.495470068928473
Validation loss: 10.868955534219843

Epoch: 6| Step: 3
Training loss: 10.43774340682687
Validation loss: 10.866288560753608

Epoch: 6| Step: 4
Training loss: 10.998719574359127
Validation loss: 10.8620988197935

Epoch: 6| Step: 5
Training loss: 10.651147957841175
Validation loss: 10.861533595206897

Epoch: 6| Step: 6
Training loss: 10.38399841562503
Validation loss: 10.859747351979609

Epoch: 6| Step: 7
Training loss: 11.712168724887563
Validation loss: 10.855305914679747

Epoch: 6| Step: 8
Training loss: 10.735129073086188
Validation loss: 10.854042779192127

Epoch: 6| Step: 9
Training loss: 11.145283585059927
Validation loss: 10.851387147187943

Epoch: 6| Step: 10
Training loss: 10.473955824346003
Validation loss: 10.849926471758774

Epoch: 6| Step: 11
Training loss: 10.092507300630565
Validation loss: 10.84509449819931

Epoch: 6| Step: 12
Training loss: 11.05218024515465
Validation loss: 10.844188416891093

Epoch: 6| Step: 13
Training loss: 10.717628887479103
Validation loss: 10.84037204012722

Epoch: 3| Step: 0
Training loss: 10.288186003384386
Validation loss: 10.839363887046437

Epoch: 6| Step: 1
Training loss: 9.953643545778892
Validation loss: 10.834107768078773

Epoch: 6| Step: 2
Training loss: 12.649994837341461
Validation loss: 10.832977208294011

Epoch: 6| Step: 3
Training loss: 10.133736314624333
Validation loss: 10.828543939162811

Epoch: 6| Step: 4
Training loss: 10.143673854314093
Validation loss: 10.82769267582252

Epoch: 6| Step: 5
Training loss: 11.22441888677107
Validation loss: 10.824492218757184

Epoch: 6| Step: 6
Training loss: 9.976212246690405
Validation loss: 10.820611370776572

Epoch: 6| Step: 7
Training loss: 11.595452936759036
Validation loss: 10.816824858073563

Epoch: 6| Step: 8
Training loss: 9.886285827394305
Validation loss: 10.815725994391444

Epoch: 6| Step: 9
Training loss: 9.98861274870313
Validation loss: 10.811426040506353

Epoch: 6| Step: 10
Training loss: 11.858208600208325
Validation loss: 10.81109174844494

Epoch: 6| Step: 11
Training loss: 9.984770813261534
Validation loss: 10.807806132950471

Epoch: 6| Step: 12
Training loss: 11.265606714834329
Validation loss: 10.80298352340072

Epoch: 6| Step: 13
Training loss: 10.943717889395531
Validation loss: 10.801340266248166

Epoch: 4| Step: 0
Training loss: 10.360216753838861
Validation loss: 10.798255605738786

Epoch: 6| Step: 1
Training loss: 10.857426618151958
Validation loss: 10.796362924332005

Epoch: 6| Step: 2
Training loss: 10.022604761296929
Validation loss: 10.793364309870094

Epoch: 6| Step: 3
Training loss: 10.454294182091067
Validation loss: 10.791588794425548

Epoch: 6| Step: 4
Training loss: 12.117655938720935
Validation loss: 10.788713550409794

Epoch: 6| Step: 5
Training loss: 10.260940667470388
Validation loss: 10.783216725843765

Epoch: 6| Step: 6
Training loss: 11.978508459611831
Validation loss: 10.78179939181617

Epoch: 6| Step: 7
Training loss: 10.55064891970883
Validation loss: 10.778346664045563

Epoch: 6| Step: 8
Training loss: 9.683199807940959
Validation loss: 10.77702612948665

Epoch: 6| Step: 9
Training loss: 9.635488368961816
Validation loss: 10.772574727496817

Epoch: 6| Step: 10
Training loss: 10.31605903015169
Validation loss: 10.77090140722834

Epoch: 6| Step: 11
Training loss: 10.777790432252916
Validation loss: 10.767481321434936

Epoch: 6| Step: 12
Training loss: 11.47175114002871
Validation loss: 10.765467271587452

Epoch: 6| Step: 13
Training loss: 11.014714542937659
Validation loss: 10.762163069809189

Epoch: 5| Step: 0
Training loss: 9.862393214973626
Validation loss: 10.757753827239638

Epoch: 6| Step: 1
Training loss: 10.099998972675536
Validation loss: 10.75649533616062

Epoch: 6| Step: 2
Training loss: 11.172832741399343
Validation loss: 10.752748394171956

Epoch: 6| Step: 3
Training loss: 10.6724601350613
Validation loss: 10.752265044798351

Epoch: 6| Step: 4
Training loss: 11.778194284172049
Validation loss: 10.75040788537281

Epoch: 6| Step: 5
Training loss: 10.10352902841997
Validation loss: 10.744665659135785

Epoch: 6| Step: 6
Training loss: 8.402259304840648
Validation loss: 10.739554651233872

Epoch: 6| Step: 7
Training loss: 9.633771194309963
Validation loss: 10.736484877475334

Epoch: 6| Step: 8
Training loss: 10.188078881415539
Validation loss: 10.731002761060893

Epoch: 6| Step: 9
Training loss: 11.16441785648579
Validation loss: 10.73156840109414

Epoch: 6| Step: 10
Training loss: 11.478316056894108
Validation loss: 10.727582462162939

Epoch: 6| Step: 11
Training loss: 10.897380731135184
Validation loss: 10.727106746808577

Epoch: 6| Step: 12
Training loss: 11.111905395939992
Validation loss: 10.722846423326306

Epoch: 6| Step: 13
Training loss: 12.91472593104567
Validation loss: 10.719704152529085

Epoch: 6| Step: 0
Training loss: 11.999846775348257
Validation loss: 10.716001062154536

Epoch: 6| Step: 1
Training loss: 9.906847625900607
Validation loss: 10.710854861460195

Epoch: 6| Step: 2
Training loss: 10.746738027646495
Validation loss: 10.708292964914914

Epoch: 6| Step: 3
Training loss: 11.07049788681223
Validation loss: 10.706694154349208

Epoch: 6| Step: 4
Training loss: 11.039761552861682
Validation loss: 10.700017035824104

Epoch: 6| Step: 5
Training loss: 10.439876811152097
Validation loss: 10.699777126588293

Epoch: 6| Step: 6
Training loss: 10.467757357323338
Validation loss: 10.695993691189026

Epoch: 6| Step: 7
Training loss: 10.566535494819542
Validation loss: 10.693761962228793

Epoch: 6| Step: 8
Training loss: 9.456128461400873
Validation loss: 10.689145089976211

Epoch: 6| Step: 9
Training loss: 9.765864450189376
Validation loss: 10.683079296828351

Epoch: 6| Step: 10
Training loss: 11.166436681703967
Validation loss: 10.680615063891915

Epoch: 6| Step: 11
Training loss: 11.501588131254554
Validation loss: 10.676227809306647

Epoch: 6| Step: 12
Training loss: 9.750269959453767
Validation loss: 10.676024142035732

Epoch: 6| Step: 13
Training loss: 10.004455336844384
Validation loss: 10.668103070090732

Epoch: 7| Step: 0
Training loss: 11.28034508792769
Validation loss: 10.664603720905037

Epoch: 6| Step: 1
Training loss: 10.373579916225657
Validation loss: 10.661278254520587

Epoch: 6| Step: 2
Training loss: 10.86182807275236
Validation loss: 10.659041273505592

Epoch: 6| Step: 3
Training loss: 8.877018228927929
Validation loss: 10.659465872908749

Epoch: 6| Step: 4
Training loss: 10.835238675532796
Validation loss: 10.65295183206843

Epoch: 6| Step: 5
Training loss: 10.556023954294194
Validation loss: 10.646496332005094

Epoch: 6| Step: 6
Training loss: 10.641844557726838
Validation loss: 10.646512351712477

Epoch: 6| Step: 7
Training loss: 10.368132742915044
Validation loss: 10.640152247238115

Epoch: 6| Step: 8
Training loss: 10.106102910619853
Validation loss: 10.638939219483659

Epoch: 6| Step: 9
Training loss: 11.045578595915865
Validation loss: 10.632183262749752

Epoch: 6| Step: 10
Training loss: 10.917126323156737
Validation loss: 10.629063747336394

Epoch: 6| Step: 11
Training loss: 10.011442885391743
Validation loss: 10.626435039975421

Epoch: 6| Step: 12
Training loss: 11.169132093352196
Validation loss: 10.62378531165414

Epoch: 6| Step: 13
Training loss: 10.361937607250995
Validation loss: 10.619077136012697

Epoch: 8| Step: 0
Training loss: 11.882559528454534
Validation loss: 10.611480802088277

Epoch: 6| Step: 1
Training loss: 10.334860494010748
Validation loss: 10.611106251771677

Epoch: 6| Step: 2
Training loss: 10.981540449857455
Validation loss: 10.606150215919948

Epoch: 6| Step: 3
Training loss: 11.351788995718707
Validation loss: 10.60071629158661

Epoch: 6| Step: 4
Training loss: 10.381131853491233
Validation loss: 10.594016698999472

Epoch: 6| Step: 5
Training loss: 9.990724457981639
Validation loss: 10.592276876312201

Epoch: 6| Step: 6
Training loss: 10.54590562674829
Validation loss: 10.587386493573469

Epoch: 6| Step: 7
Training loss: 11.081524885439778
Validation loss: 10.582726058480597

Epoch: 6| Step: 8
Training loss: 9.532569068560427
Validation loss: 10.578841883111787

Epoch: 6| Step: 9
Training loss: 9.326144265338712
Validation loss: 10.576639104832132

Epoch: 6| Step: 10
Training loss: 9.734483158006675
Validation loss: 10.570684553295116

Epoch: 6| Step: 11
Training loss: 10.236127816860508
Validation loss: 10.565927121227677

Epoch: 6| Step: 12
Training loss: 10.382231983865362
Validation loss: 10.561594709296658

Epoch: 6| Step: 13
Training loss: 11.198641721923941
Validation loss: 10.56030775721145

Epoch: 9| Step: 0
Training loss: 11.478109339893686
Validation loss: 10.55522984849722

Epoch: 6| Step: 1
Training loss: 10.150599765439702
Validation loss: 10.550579006128885

Epoch: 6| Step: 2
Training loss: 10.281111232203711
Validation loss: 10.54384543601834

Epoch: 6| Step: 3
Training loss: 10.888441876774943
Validation loss: 10.538938978212895

Epoch: 6| Step: 4
Training loss: 10.221688970764033
Validation loss: 10.537126843666073

Epoch: 6| Step: 5
Training loss: 11.473273359722327
Validation loss: 10.531339220280259

Epoch: 6| Step: 6
Training loss: 10.17451407657073
Validation loss: 10.527304724053383

Epoch: 6| Step: 7
Training loss: 8.456951861636618
Validation loss: 10.521228272051097

Epoch: 6| Step: 8
Training loss: 9.771437332799517
Validation loss: 10.5200530966714

Epoch: 6| Step: 9
Training loss: 10.427478479195344
Validation loss: 10.51645813603203

Epoch: 6| Step: 10
Training loss: 9.358206801834337
Validation loss: 10.508853318785635

Epoch: 6| Step: 11
Training loss: 10.706498598685396
Validation loss: 10.505657181921118

Epoch: 6| Step: 12
Training loss: 11.679584290931949
Validation loss: 10.496945348483614

Epoch: 6| Step: 13
Training loss: 10.567400455768587
Validation loss: 10.494777230186898

Epoch: 10| Step: 0
Training loss: 10.489063198271987
Validation loss: 10.487411023010292

Epoch: 6| Step: 1
Training loss: 9.998528563008307
Validation loss: 10.484369933541885

Epoch: 6| Step: 2
Training loss: 10.58576272630171
Validation loss: 10.480574578079946

Epoch: 6| Step: 3
Training loss: 9.856178212796395
Validation loss: 10.47427722308008

Epoch: 6| Step: 4
Training loss: 9.940337153958863
Validation loss: 10.472179592459211

Epoch: 6| Step: 5
Training loss: 10.269637857829117
Validation loss: 10.465613104666398

Epoch: 6| Step: 6
Training loss: 10.199646618275327
Validation loss: 10.460824156433734

Epoch: 6| Step: 7
Training loss: 10.242936096069528
Validation loss: 10.454498869285374

Epoch: 6| Step: 8
Training loss: 10.615851199592736
Validation loss: 10.456580648883742

Epoch: 6| Step: 9
Training loss: 10.568157779968308
Validation loss: 10.447375430945794

Epoch: 6| Step: 10
Training loss: 11.176774493830386
Validation loss: 10.442405639873533

Epoch: 6| Step: 11
Training loss: 10.89259335915422
Validation loss: 10.439577028265662

Epoch: 6| Step: 12
Training loss: 10.35031058172573
Validation loss: 10.436073646401484

Epoch: 6| Step: 13
Training loss: 9.484138498389857
Validation loss: 10.425047365288894

Epoch: 11| Step: 0
Training loss: 10.959040939247625
Validation loss: 10.420429719213436

Epoch: 6| Step: 1
Training loss: 10.699629832487014
Validation loss: 10.415612183060219

Epoch: 6| Step: 2
Training loss: 10.849498093769995
Validation loss: 10.41140293413015

Epoch: 6| Step: 3
Training loss: 9.742833168885644
Validation loss: 10.405550932906504

Epoch: 6| Step: 4
Training loss: 10.980822057749814
Validation loss: 10.403924448310299

Epoch: 6| Step: 5
Training loss: 10.626381458904826
Validation loss: 10.39756588402228

Epoch: 6| Step: 6
Training loss: 9.76801923775243
Validation loss: 10.39021625527497

Epoch: 6| Step: 7
Training loss: 10.507426950408176
Validation loss: 10.388467361590273

Epoch: 6| Step: 8
Training loss: 9.903399228758765
Validation loss: 10.37248954936476

Epoch: 6| Step: 9
Training loss: 9.35275763170322
Validation loss: 10.378985212224062

Epoch: 6| Step: 10
Training loss: 9.181913377077795
Validation loss: 10.368553051347726

Epoch: 6| Step: 11
Training loss: 11.109986193190819
Validation loss: 10.362650193038458

Epoch: 6| Step: 12
Training loss: 9.562192824672119
Validation loss: 10.357464548867057

Epoch: 6| Step: 13
Training loss: 10.899194922156951
Validation loss: 10.352408894851793

Epoch: 12| Step: 0
Training loss: 10.186598661838174
Validation loss: 10.34686092731388

Epoch: 6| Step: 1
Training loss: 9.473786578824397
Validation loss: 10.340592027710283

Epoch: 6| Step: 2
Training loss: 10.386668067053854
Validation loss: 10.33496740429662

Epoch: 6| Step: 3
Training loss: 10.203125747750738
Validation loss: 10.328110043283075

Epoch: 6| Step: 4
Training loss: 11.898427240639045
Validation loss: 10.326329252796759

Epoch: 6| Step: 5
Training loss: 9.584043482024278
Validation loss: 10.321513862758884

Epoch: 6| Step: 6
Training loss: 11.100830225783122
Validation loss: 10.31532443718532

Epoch: 6| Step: 7
Training loss: 9.44441343813525
Validation loss: 10.310180920383216

Epoch: 6| Step: 8
Training loss: 8.979875316816287
Validation loss: 10.307596249307805

Epoch: 6| Step: 9
Training loss: 11.66105851303951
Validation loss: 10.29724549656112

Epoch: 6| Step: 10
Training loss: 8.52710217820903
Validation loss: 10.29369392437774

Epoch: 6| Step: 11
Training loss: 10.918518336458213
Validation loss: 10.291001816078877

Epoch: 6| Step: 12
Training loss: 9.93979757367644
Validation loss: 10.287026834641663

Epoch: 6| Step: 13
Training loss: 10.203656636943858
Validation loss: 10.281536163268411

Epoch: 13| Step: 0
Training loss: 10.14095452806265
Validation loss: 10.271444155290725

Epoch: 6| Step: 1
Training loss: 11.226941022019936
Validation loss: 10.26682001320857

Epoch: 6| Step: 2
Training loss: 9.854798332330217
Validation loss: 10.25918478526345

Epoch: 6| Step: 3
Training loss: 10.037244485189586
Validation loss: 10.255105768612863

Epoch: 6| Step: 4
Training loss: 9.569921069801284
Validation loss: 10.247238659616583

Epoch: 6| Step: 5
Training loss: 11.108216731000125
Validation loss: 10.245447011492752

Epoch: 6| Step: 6
Training loss: 9.986227087609839
Validation loss: 10.237440240231736

Epoch: 6| Step: 7
Training loss: 9.745684328825215
Validation loss: 10.239118873695373

Epoch: 6| Step: 8
Training loss: 10.650539087253804
Validation loss: 10.222419117438259

Epoch: 6| Step: 9
Training loss: 9.684391039687023
Validation loss: 10.219741241857031

Epoch: 6| Step: 10
Training loss: 10.10971158394476
Validation loss: 10.21457011448214

Epoch: 6| Step: 11
Training loss: 10.161385795820564
Validation loss: 10.211397269648689

Epoch: 6| Step: 12
Training loss: 9.679454194121368
Validation loss: 10.206569141652812

Epoch: 6| Step: 13
Training loss: 9.661433239241894
Validation loss: 10.199148293504814

Epoch: 14| Step: 0
Training loss: 10.560110690952808
Validation loss: 10.194437173072192

Epoch: 6| Step: 1
Training loss: 10.014474692620707
Validation loss: 10.19267749259289

Epoch: 6| Step: 2
Training loss: 10.280517552034786
Validation loss: 10.182537183384156

Epoch: 6| Step: 3
Training loss: 9.313000147144992
Validation loss: 10.17901713533224

Epoch: 6| Step: 4
Training loss: 10.42203092672898
Validation loss: 10.165985668283591

Epoch: 6| Step: 5
Training loss: 8.928069147423303
Validation loss: 10.166525404211134

Epoch: 6| Step: 6
Training loss: 11.078053376002595
Validation loss: 10.166367434800529

Epoch: 6| Step: 7
Training loss: 11.277815953917216
Validation loss: 10.160247909432018

Epoch: 6| Step: 8
Training loss: 10.543127951280413
Validation loss: 10.151229550990578

Epoch: 6| Step: 9
Training loss: 9.239865911922776
Validation loss: 10.14985194057585

Epoch: 6| Step: 10
Training loss: 9.988483282200987
Validation loss: 10.138370235623608

Epoch: 6| Step: 11
Training loss: 10.117351138879327
Validation loss: 10.134724389187797

Epoch: 6| Step: 12
Training loss: 8.718063053975117
Validation loss: 10.13436480466152

Epoch: 6| Step: 13
Training loss: 10.061361497243931
Validation loss: 10.122373393423633

Epoch: 15| Step: 0
Training loss: 10.073988143807895
Validation loss: 10.122741978138198

Epoch: 6| Step: 1
Training loss: 9.957579856895213
Validation loss: 10.116398191669644

Epoch: 6| Step: 2
Training loss: 9.68803315695169
Validation loss: 10.110907377419961

Epoch: 6| Step: 3
Training loss: 9.562075536943784
Validation loss: 10.10774870541595

Epoch: 6| Step: 4
Training loss: 9.50130212794356
Validation loss: 10.097462633624774

Epoch: 6| Step: 5
Training loss: 9.765518749421993
Validation loss: 10.087742807389963

Epoch: 6| Step: 6
Training loss: 9.64509842272148
Validation loss: 10.081785219628925

Epoch: 6| Step: 7
Training loss: 10.40050267691986
Validation loss: 10.079064395994108

Epoch: 6| Step: 8
Training loss: 10.844683604217595
Validation loss: 10.073567381905146

Epoch: 6| Step: 9
Training loss: 10.927483904356961
Validation loss: 10.074845513540806

Epoch: 6| Step: 10
Training loss: 9.099067522837505
Validation loss: 10.071185728657241

Epoch: 6| Step: 11
Training loss: 10.022427395761982
Validation loss: 10.06234996889917

Epoch: 6| Step: 12
Training loss: 10.326648231458698
Validation loss: 10.05918633746129

Epoch: 6| Step: 13
Training loss: 9.949367514592558
Validation loss: 10.053970348691688

Epoch: 16| Step: 0
Training loss: 11.765516060252628
Validation loss: 10.049742723548327

Epoch: 6| Step: 1
Training loss: 10.586307938629236
Validation loss: 10.044813970470054

Epoch: 6| Step: 2
Training loss: 8.816452979495123
Validation loss: 10.042362065660955

Epoch: 6| Step: 3
Training loss: 9.911424121941307
Validation loss: 10.037201551229119

Epoch: 6| Step: 4
Training loss: 8.730643087604975
Validation loss: 10.032482322104348

Epoch: 6| Step: 5
Training loss: 9.712514170829028
Validation loss: 10.02784890673152

Epoch: 6| Step: 6
Training loss: 11.246847770723672
Validation loss: 10.02113968466584

Epoch: 6| Step: 7
Training loss: 8.026920799380747
Validation loss: 10.016896061736679

Epoch: 6| Step: 8
Training loss: 9.7814020992068
Validation loss: 10.015274363972697

Epoch: 6| Step: 9
Training loss: 9.865226448039282
Validation loss: 10.007571784978188

Epoch: 6| Step: 10
Training loss: 8.801150541519682
Validation loss: 10.002471679895425

Epoch: 6| Step: 11
Training loss: 11.226062994498353
Validation loss: 10.005511092208039

Epoch: 6| Step: 12
Training loss: 9.814215054637424
Validation loss: 10.00448317169432

Epoch: 6| Step: 13
Training loss: 9.95145075204176
Validation loss: 9.992410232452828

Epoch: 17| Step: 0
Training loss: 10.766701787019342
Validation loss: 9.988922349455972

Epoch: 6| Step: 1
Training loss: 8.87304021124282
Validation loss: 9.987311675111087

Epoch: 6| Step: 2
Training loss: 10.736640968643348
Validation loss: 9.977202897097191

Epoch: 6| Step: 3
Training loss: 9.325107309987024
Validation loss: 9.971368907087276

Epoch: 6| Step: 4
Training loss: 12.245496272306735
Validation loss: 9.97921852867154

Epoch: 6| Step: 5
Training loss: 9.896429446820628
Validation loss: 9.964255028134767

Epoch: 6| Step: 6
Training loss: 9.923210955211076
Validation loss: 9.976758051515118

Epoch: 6| Step: 7
Training loss: 9.659461218931368
Validation loss: 9.955193149648839

Epoch: 6| Step: 8
Training loss: 9.924324946663761
Validation loss: 9.959424798332448

Epoch: 6| Step: 9
Training loss: 9.063326672963928
Validation loss: 9.950064857103747

Epoch: 6| Step: 10
Training loss: 8.878096349308091
Validation loss: 9.943310130418222

Epoch: 6| Step: 11
Training loss: 8.752701696465195
Validation loss: 9.946055413358994

Epoch: 6| Step: 12
Training loss: 9.998547257758249
Validation loss: 9.94020756624923

Epoch: 6| Step: 13
Training loss: 9.111219059167693
Validation loss: 9.930520492213764

Epoch: 18| Step: 0
Training loss: 8.951289283337031
Validation loss: 9.926062259874804

Epoch: 6| Step: 1
Training loss: 9.923989762940176
Validation loss: 9.923612117976583

Epoch: 6| Step: 2
Training loss: 9.515586113811144
Validation loss: 9.923756872693424

Epoch: 6| Step: 3
Training loss: 9.25848329584566
Validation loss: 9.921506584936285

Epoch: 6| Step: 4
Training loss: 10.70151818458849
Validation loss: 9.915015599112019

Epoch: 6| Step: 5
Training loss: 10.673790063118322
Validation loss: 9.916874299564714

Epoch: 6| Step: 6
Training loss: 9.445990576751292
Validation loss: 9.903234506592344

Epoch: 6| Step: 7
Training loss: 11.608255776508871
Validation loss: 9.901545646050764

Epoch: 6| Step: 8
Training loss: 9.294067984850942
Validation loss: 9.901303896902327

Epoch: 6| Step: 9
Training loss: 9.196276566390708
Validation loss: 9.899346176670706

Epoch: 6| Step: 10
Training loss: 9.700532281173334
Validation loss: 9.896949848255302

Epoch: 6| Step: 11
Training loss: 9.271843764429606
Validation loss: 9.887822702721285

Epoch: 6| Step: 12
Training loss: 9.451287915502244
Validation loss: 9.882913953403138

Epoch: 6| Step: 13
Training loss: 10.236284337043818
Validation loss: 9.887668125315239

Epoch: 19| Step: 0
Training loss: 10.794206435774933
Validation loss: 9.879075525694258

Epoch: 6| Step: 1
Training loss: 10.813481457217465
Validation loss: 9.878794117632019

Epoch: 6| Step: 2
Training loss: 7.915550340615883
Validation loss: 9.87662216244219

Epoch: 6| Step: 3
Training loss: 9.824424156028616
Validation loss: 9.874137953981073

Epoch: 6| Step: 4
Training loss: 9.99376903959158
Validation loss: 9.863627666285668

Epoch: 6| Step: 5
Training loss: 8.654396271785894
Validation loss: 9.872272298012163

Epoch: 6| Step: 6
Training loss: 10.399848320661865
Validation loss: 9.861011017907579

Epoch: 6| Step: 7
Training loss: 10.598786453740455
Validation loss: 9.855737485295215

Epoch: 6| Step: 8
Training loss: 9.439749948454963
Validation loss: 9.85936782758907

Epoch: 6| Step: 9
Training loss: 10.131828736819731
Validation loss: 9.846743082382666

Epoch: 6| Step: 10
Training loss: 9.380433402714072
Validation loss: 9.839180309431018

Epoch: 6| Step: 11
Training loss: 9.99698211908263
Validation loss: 9.84217244763603

Epoch: 6| Step: 12
Training loss: 8.95538887308441
Validation loss: 9.82372290118065

Epoch: 6| Step: 13
Training loss: 9.00608281040601
Validation loss: 9.82753910680496

Epoch: 20| Step: 0
Training loss: 9.944057004782076
Validation loss: 9.822841925649815

Epoch: 6| Step: 1
Training loss: 9.587663639666486
Validation loss: 9.832963529473815

Epoch: 6| Step: 2
Training loss: 9.133124092471128
Validation loss: 9.810708890899706

Epoch: 6| Step: 3
Training loss: 10.089736376703168
Validation loss: 9.801839178508516

Epoch: 6| Step: 4
Training loss: 9.297018611023157
Validation loss: 9.808310608318198

Epoch: 6| Step: 5
Training loss: 9.806496502687724
Validation loss: 9.802287242044327

Epoch: 6| Step: 6
Training loss: 10.680748307090383
Validation loss: 9.769091379079498

Epoch: 6| Step: 7
Training loss: 10.811575260198376
Validation loss: 9.766894028768895

Epoch: 6| Step: 8
Training loss: 9.599473271224882
Validation loss: 9.781130822517248

Epoch: 6| Step: 9
Training loss: 10.182904476577475
Validation loss: 9.762323790981707

Epoch: 6| Step: 10
Training loss: 8.846558896490885
Validation loss: 9.77675015663715

Epoch: 6| Step: 11
Training loss: 9.929878046952226
Validation loss: 9.752398040081452

Epoch: 6| Step: 12
Training loss: 8.029862933479547
Validation loss: 9.734412557106488

Epoch: 6| Step: 13
Training loss: 9.194952401084148
Validation loss: 9.745715512241283

Epoch: 21| Step: 0
Training loss: 8.99905814434775
Validation loss: 9.729767021819208

Epoch: 6| Step: 1
Training loss: 8.753056455573283
Validation loss: 9.73074626982567

Epoch: 6| Step: 2
Training loss: 10.153354455028797
Validation loss: 9.721293982411604

Epoch: 6| Step: 3
Training loss: 9.856155377637114
Validation loss: 9.697605525691325

Epoch: 6| Step: 4
Training loss: 10.075259252199093
Validation loss: 9.69625328410933

Epoch: 6| Step: 5
Training loss: 8.886301930472074
Validation loss: 9.687183619747016

Epoch: 6| Step: 6
Training loss: 9.466485586807513
Validation loss: 9.680243909449926

Epoch: 6| Step: 7
Training loss: 8.891472801185344
Validation loss: 9.686578090279035

Epoch: 6| Step: 8
Training loss: 9.51810136214356
Validation loss: 9.671066312661026

Epoch: 6| Step: 9
Training loss: 10.207333221231577
Validation loss: 9.666191380760926

Epoch: 6| Step: 10
Training loss: 9.279853279006238
Validation loss: 9.648022047058165

Epoch: 6| Step: 11
Training loss: 10.515769379348733
Validation loss: 9.658909324056516

Epoch: 6| Step: 12
Training loss: 9.42193168256167
Validation loss: 9.646353001960016

Epoch: 6| Step: 13
Training loss: 10.409556004036478
Validation loss: 9.62688388507925

Epoch: 22| Step: 0
Training loss: 10.291477299439707
Validation loss: 9.621800394124051

Epoch: 6| Step: 1
Training loss: 8.143059481829258
Validation loss: 9.609959694633352

Epoch: 6| Step: 2
Training loss: 8.855516134908513
Validation loss: 9.615852022054366

Epoch: 6| Step: 3
Training loss: 10.717350548675878
Validation loss: 9.608114367122758

Epoch: 6| Step: 4
Training loss: 9.814606070014747
Validation loss: 9.595976016765281

Epoch: 6| Step: 5
Training loss: 9.336572856910738
Validation loss: 9.587310687579603

Epoch: 6| Step: 6
Training loss: 9.492551594097424
Validation loss: 9.578314087315201

Epoch: 6| Step: 7
Training loss: 9.405624216751288
Validation loss: 9.579197494527955

Epoch: 6| Step: 8
Training loss: 9.7954762508246
Validation loss: 9.554043769088032

Epoch: 6| Step: 9
Training loss: 8.902779528742826
Validation loss: 9.558950749017804

Epoch: 6| Step: 10
Training loss: 10.435418018400126
Validation loss: 9.561262483498012

Epoch: 6| Step: 11
Training loss: 8.966516302991726
Validation loss: 9.53237891892287

Epoch: 6| Step: 12
Training loss: 9.44425429607782
Validation loss: 9.537054996287948

Epoch: 6| Step: 13
Training loss: 8.248454093591237
Validation loss: 9.51653137260279

Epoch: 23| Step: 0
Training loss: 9.159644841800892
Validation loss: 9.517578523650583

Epoch: 6| Step: 1
Training loss: 7.634839822404235
Validation loss: 9.516237166040458

Epoch: 6| Step: 2
Training loss: 9.005898979594656
Validation loss: 9.486527566489345

Epoch: 6| Step: 3
Training loss: 10.021844274927567
Validation loss: 9.49499004406238

Epoch: 6| Step: 4
Training loss: 9.302032117428528
Validation loss: 9.474589168057504

Epoch: 6| Step: 5
Training loss: 8.184365174708926
Validation loss: 9.475647109696398

Epoch: 6| Step: 6
Training loss: 10.3579439351387
Validation loss: 9.465901623838777

Epoch: 6| Step: 7
Training loss: 9.800576905377696
Validation loss: 9.45935505251799

Epoch: 6| Step: 8
Training loss: 8.240456349596748
Validation loss: 9.452910002803705

Epoch: 6| Step: 9
Training loss: 10.021009500479051
Validation loss: 9.445229979469895

Epoch: 6| Step: 10
Training loss: 10.289390981611154
Validation loss: 9.439656085838704

Epoch: 6| Step: 11
Training loss: 9.6851551786722
Validation loss: 9.41001048611758

Epoch: 6| Step: 12
Training loss: 9.874637645398929
Validation loss: 9.403492929684697

Epoch: 6| Step: 13
Training loss: 8.974605336982226
Validation loss: 9.415505695856996

Epoch: 24| Step: 0
Training loss: 10.241259313872703
Validation loss: 9.385954276062838

Epoch: 6| Step: 1
Training loss: 10.323988185563952
Validation loss: 9.390085990800593

Epoch: 6| Step: 2
Training loss: 9.459040633543724
Validation loss: 9.372440059176983

Epoch: 6| Step: 3
Training loss: 9.390425135664286
Validation loss: 9.371172353700581

Epoch: 6| Step: 4
Training loss: 9.076519664966062
Validation loss: 9.351371595482778

Epoch: 6| Step: 5
Training loss: 9.181396948545347
Validation loss: 9.356395008106784

Epoch: 6| Step: 6
Training loss: 8.559063075476221
Validation loss: 9.347291900734735

Epoch: 6| Step: 7
Training loss: 9.082501667924513
Validation loss: 9.329245598006205

Epoch: 6| Step: 8
Training loss: 8.808957950480854
Validation loss: 9.308173691608067

Epoch: 6| Step: 9
Training loss: 8.810930694020026
Validation loss: 9.312827510378117

Epoch: 6| Step: 10
Training loss: 9.912449770940874
Validation loss: 9.310844124962097

Epoch: 6| Step: 11
Training loss: 8.240210533785728
Validation loss: 9.289941247226007

Epoch: 6| Step: 12
Training loss: 8.271092126546549
Validation loss: 9.288980017693895

Epoch: 6| Step: 13
Training loss: 10.051358896876986
Validation loss: 9.264649723104483

Epoch: 25| Step: 0
Training loss: 8.957970710926247
Validation loss: 9.26772258612283

Epoch: 6| Step: 1
Training loss: 9.872918790897662
Validation loss: 9.253457773115468

Epoch: 6| Step: 2
Training loss: 9.719686088987496
Validation loss: 9.243255812845366

Epoch: 6| Step: 3
Training loss: 8.290650987638312
Validation loss: 9.250704294235378

Epoch: 6| Step: 4
Training loss: 10.101684852797298
Validation loss: 9.227420407699196

Epoch: 6| Step: 5
Training loss: 9.72768763886446
Validation loss: 9.227531382859366

Epoch: 6| Step: 6
Training loss: 9.16735041987068
Validation loss: 9.21165346837924

Epoch: 6| Step: 7
Training loss: 8.66447372079796
Validation loss: 9.213439112401327

Epoch: 6| Step: 8
Training loss: 8.248654342492117
Validation loss: 9.186881774456172

Epoch: 6| Step: 9
Training loss: 9.200733852142923
Validation loss: 9.18070125039667

Epoch: 6| Step: 10
Training loss: 8.072097152624357
Validation loss: 9.16838190880338

Epoch: 6| Step: 11
Training loss: 8.461198994689486
Validation loss: 9.154572081670647

Epoch: 6| Step: 12
Training loss: 9.21425878746855
Validation loss: 9.142772265357445

Epoch: 6| Step: 13
Training loss: 9.952714130059574
Validation loss: 9.146924592132395

Epoch: 26| Step: 0
Training loss: 9.153167309830943
Validation loss: 9.12722818543133

Epoch: 6| Step: 1
Training loss: 8.7580964912697
Validation loss: 9.117213553686767

Epoch: 6| Step: 2
Training loss: 9.57602428405793
Validation loss: 9.09973810705466

Epoch: 6| Step: 3
Training loss: 10.006611736366251
Validation loss: 9.092789200899878

Epoch: 6| Step: 4
Training loss: 10.04281909286587
Validation loss: 9.096184972902124

Epoch: 6| Step: 5
Training loss: 7.876274369079058
Validation loss: 9.065978404251153

Epoch: 6| Step: 6
Training loss: 8.585061303676907
Validation loss: 9.068503223793458

Epoch: 6| Step: 7
Training loss: 9.139372911038878
Validation loss: 9.047679009255445

Epoch: 6| Step: 8
Training loss: 8.742502542636622
Validation loss: 9.033556533245871

Epoch: 6| Step: 9
Training loss: 7.588999325774219
Validation loss: 9.048982229492701

Epoch: 6| Step: 10
Training loss: 8.45726580217465
Validation loss: 9.021741909456257

Epoch: 6| Step: 11
Training loss: 9.225817437900066
Validation loss: 8.997832535200141

Epoch: 6| Step: 12
Training loss: 9.601262136778718
Validation loss: 8.998711994028898

Epoch: 6| Step: 13
Training loss: 7.884027060483094
Validation loss: 8.973819385756244

Epoch: 27| Step: 0
Training loss: 8.103517272610702
Validation loss: 8.976136920246953

Epoch: 6| Step: 1
Training loss: 9.002634298715362
Validation loss: 8.96418955485185

Epoch: 6| Step: 2
Training loss: 9.76801533245911
Validation loss: 8.950608805435525

Epoch: 6| Step: 3
Training loss: 8.899696910712132
Validation loss: 8.930698603271482

Epoch: 6| Step: 4
Training loss: 9.478164877023143
Validation loss: 8.945723745469781

Epoch: 6| Step: 5
Training loss: 8.624485608670245
Validation loss: 8.92452432526399

Epoch: 6| Step: 6
Training loss: 9.132774072310088
Validation loss: 8.923609295114353

Epoch: 6| Step: 7
Training loss: 8.246969880327638
Validation loss: 8.90017370294377

Epoch: 6| Step: 8
Training loss: 8.516822772701188
Validation loss: 8.872301129525914

Epoch: 6| Step: 9
Training loss: 8.495044834676511
Validation loss: 8.886724173422367

Epoch: 6| Step: 10
Training loss: 8.921425188420185
Validation loss: 8.866907812270828

Epoch: 6| Step: 11
Training loss: 8.18418106484384
Validation loss: 8.839159333040106

Epoch: 6| Step: 12
Training loss: 8.903084604018352
Validation loss: 8.836418080686117

Epoch: 6| Step: 13
Training loss: 8.879617269017752
Validation loss: 8.832975591224844

Epoch: 28| Step: 0
Training loss: 8.433126941110444
Validation loss: 8.819409861060945

Epoch: 6| Step: 1
Training loss: 9.961783052347167
Validation loss: 8.779286364977352

Epoch: 6| Step: 2
Training loss: 8.199778428224306
Validation loss: 8.789354119826026

Epoch: 6| Step: 3
Training loss: 10.036907751489702
Validation loss: 8.772845477756217

Epoch: 6| Step: 4
Training loss: 9.266226892075851
Validation loss: 8.745317031591332

Epoch: 6| Step: 5
Training loss: 7.479347021395323
Validation loss: 8.750568138229896

Epoch: 6| Step: 6
Training loss: 9.46754694682998
Validation loss: 8.726287609792141

Epoch: 6| Step: 7
Training loss: 9.11864260426605
Validation loss: 8.694608761390338

Epoch: 6| Step: 8
Training loss: 8.685335836555199
Validation loss: 8.691565672336525

Epoch: 6| Step: 9
Training loss: 8.295185154095275
Validation loss: 8.6946214330289

Epoch: 6| Step: 10
Training loss: 8.049920729726649
Validation loss: 8.65245515122069

Epoch: 6| Step: 11
Training loss: 8.079457510686728
Validation loss: 8.664630180494408

Epoch: 6| Step: 12
Training loss: 7.176897538377372
Validation loss: 8.627364177172861

Epoch: 6| Step: 13
Training loss: 7.607555257977022
Validation loss: 8.645142122687304

Epoch: 29| Step: 0
Training loss: 9.475782747572847
Validation loss: 8.602081776415918

Epoch: 6| Step: 1
Training loss: 6.952422442999831
Validation loss: 8.598644749627072

Epoch: 6| Step: 2
Training loss: 8.456585582945381
Validation loss: 8.580374454919296

Epoch: 6| Step: 3
Training loss: 8.328190042839347
Validation loss: 8.56294872430613

Epoch: 6| Step: 4
Training loss: 8.32309409196315
Validation loss: 8.559073273646696

Epoch: 6| Step: 5
Training loss: 8.23612039732414
Validation loss: 8.528634792390559

Epoch: 6| Step: 6
Training loss: 8.394903871441423
Validation loss: 8.51951899198521

Epoch: 6| Step: 7
Training loss: 7.7203352686367355
Validation loss: 8.526828696443953

Epoch: 6| Step: 8
Training loss: 7.927234409277846
Validation loss: 8.486770052824543

Epoch: 6| Step: 9
Training loss: 7.891736849264988
Validation loss: 8.482100197265883

Epoch: 6| Step: 10
Training loss: 9.89169831199908
Validation loss: 8.447012361989009

Epoch: 6| Step: 11
Training loss: 8.476844213348668
Validation loss: 8.43187489351442

Epoch: 6| Step: 12
Training loss: 8.504037234866283
Validation loss: 8.418101671378722

Epoch: 6| Step: 13
Training loss: 9.091630511702954
Validation loss: 8.434987194196642

Epoch: 30| Step: 0
Training loss: 8.969808589122083
Validation loss: 8.397404104358824

Epoch: 6| Step: 1
Training loss: 8.671668687720365
Validation loss: 8.393501207205324

Epoch: 6| Step: 2
Training loss: 7.921315190325557
Validation loss: 8.36130814647256

Epoch: 6| Step: 3
Training loss: 7.692193312161373
Validation loss: 8.365177124934174

Epoch: 6| Step: 4
Training loss: 8.28115648900624
Validation loss: 8.339186598446737

Epoch: 6| Step: 5
Training loss: 8.044022078458665
Validation loss: 8.313855556826438

Epoch: 6| Step: 6
Training loss: 8.503379150091735
Validation loss: 8.318270830120412

Epoch: 6| Step: 7
Training loss: 7.769760535046924
Validation loss: 8.292807231966632

Epoch: 6| Step: 8
Training loss: 8.325043585952438
Validation loss: 8.238764923941162

Epoch: 6| Step: 9
Training loss: 7.463570430795134
Validation loss: 8.206171014452492

Epoch: 6| Step: 10
Training loss: 8.916748711989895
Validation loss: 8.229111993207473

Epoch: 6| Step: 11
Training loss: 8.203369602007973
Validation loss: 8.207715739324954

Epoch: 6| Step: 12
Training loss: 7.315135774219346
Validation loss: 8.13449867160227

Epoch: 6| Step: 13
Training loss: 8.671843327644865
Validation loss: 8.152711345737387

Epoch: 31| Step: 0
Training loss: 8.510361582944695
Validation loss: 8.13064381198588

Epoch: 6| Step: 1
Training loss: 7.461576328589894
Validation loss: 8.122011125587898

Epoch: 6| Step: 2
Training loss: 8.300706801136727
Validation loss: 8.091615142646397

Epoch: 6| Step: 3
Training loss: 7.4374712775180685
Validation loss: 8.038240721733029

Epoch: 6| Step: 4
Training loss: 9.20430542090222
Validation loss: 8.072154568132571

Epoch: 6| Step: 5
Training loss: 7.944656389991281
Validation loss: 8.061302763270087

Epoch: 6| Step: 6
Training loss: 8.843360487916247
Validation loss: 8.007198719880098

Epoch: 6| Step: 7
Training loss: 7.171722609951656
Validation loss: 7.965411842362492

Epoch: 6| Step: 8
Training loss: 6.190449945862301
Validation loss: 7.967127432078474

Epoch: 6| Step: 9
Training loss: 8.821849003266026
Validation loss: 7.929737613393743

Epoch: 6| Step: 10
Training loss: 7.5330241159538955
Validation loss: 7.960381625096689

Epoch: 6| Step: 11
Training loss: 7.873071343533671
Validation loss: 7.919980396285022

Epoch: 6| Step: 12
Training loss: 7.3733244463480165
Validation loss: 7.864615648042044

Epoch: 6| Step: 13
Training loss: 6.644364181651843
Validation loss: 7.857198345583423

Epoch: 32| Step: 0
Training loss: 7.3500090203262305
Validation loss: 7.809584070245958

Epoch: 6| Step: 1
Training loss: 7.355307457239795
Validation loss: 7.779064562287339

Epoch: 6| Step: 2
Training loss: 8.080089219611068
Validation loss: 7.774187349012243

Epoch: 6| Step: 3
Training loss: 8.082715617170189
Validation loss: 7.727710741206443

Epoch: 6| Step: 4
Training loss: 6.552222933189235
Validation loss: 7.7056444377721425

Epoch: 6| Step: 5
Training loss: 7.469069470073183
Validation loss: 7.677273985128539

Epoch: 6| Step: 6
Training loss: 6.708420589029612
Validation loss: 7.656497908281342

Epoch: 6| Step: 7
Training loss: 7.730696973087049
Validation loss: 7.643736307257353

Epoch: 6| Step: 8
Training loss: 9.000745106688997
Validation loss: 7.642844106983255

Epoch: 6| Step: 9
Training loss: 8.155780413325914
Validation loss: 7.594408694145712

Epoch: 6| Step: 10
Training loss: 7.937793636147175
Validation loss: 7.540726754437469

Epoch: 6| Step: 11
Training loss: 6.295618428825494
Validation loss: 7.524377646680883

Epoch: 6| Step: 12
Training loss: 7.5493640151797825
Validation loss: 7.5149286460183955

Epoch: 6| Step: 13
Training loss: 6.157609663562544
Validation loss: 7.4796479910896725

Epoch: 33| Step: 0
Training loss: 8.938145754233693
Validation loss: 7.4577164465024355

Epoch: 6| Step: 1
Training loss: 7.342551015820175
Validation loss: 7.426340222654263

Epoch: 6| Step: 2
Training loss: 6.630321740446382
Validation loss: 7.33544257623141

Epoch: 6| Step: 3
Training loss: 6.790737845285919
Validation loss: 7.333416421853972

Epoch: 6| Step: 4
Training loss: 6.957501694860331
Validation loss: 7.3049273016520395

Epoch: 6| Step: 5
Training loss: 6.742936005489085
Validation loss: 7.310776618126936

Epoch: 6| Step: 6
Training loss: 7.899614648232923
Validation loss: 7.303515747209243

Epoch: 6| Step: 7
Training loss: 6.475306040479562
Validation loss: 7.241498475311938

Epoch: 6| Step: 8
Training loss: 7.968971877655563
Validation loss: 7.233317748309527

Epoch: 6| Step: 9
Training loss: 6.716510346189363
Validation loss: 7.14446756535059

Epoch: 6| Step: 10
Training loss: 6.740608463611931
Validation loss: 7.164544069025206

Epoch: 6| Step: 11
Training loss: 6.79462628929162
Validation loss: 7.109676166742234

Epoch: 6| Step: 12
Training loss: 7.106381366626033
Validation loss: 7.074913354778864

Epoch: 6| Step: 13
Training loss: 6.903986633323204
Validation loss: 7.071174628031554

Epoch: 34| Step: 0
Training loss: 7.3478405537424845
Validation loss: 6.942945101529381

Epoch: 6| Step: 1
Training loss: 6.661163092884005
Validation loss: 7.02968556417902

Epoch: 6| Step: 2
Training loss: 6.643213535012806
Validation loss: 6.970219418253176

Epoch: 6| Step: 3
Training loss: 6.889826098989467
Validation loss: 6.867264089372259

Epoch: 6| Step: 4
Training loss: 7.060053849055437
Validation loss: 6.927588853163099

Epoch: 6| Step: 5
Training loss: 6.819722677728402
Validation loss: 6.851809425977737

Epoch: 6| Step: 6
Training loss: 6.759672228750202
Validation loss: 6.795401257986606

Epoch: 6| Step: 7
Training loss: 6.217471197327705
Validation loss: 6.742964444126942

Epoch: 6| Step: 8
Training loss: 7.145718617162592
Validation loss: 6.738979204176352

Epoch: 6| Step: 9
Training loss: 6.530676711625494
Validation loss: 6.72938676471173

Epoch: 6| Step: 10
Training loss: 6.0330693954708
Validation loss: 6.706208259025921

Epoch: 6| Step: 11
Training loss: 6.378537262559754
Validation loss: 6.6983259772561325

Epoch: 6| Step: 12
Training loss: 7.3076839400641225
Validation loss: 6.547881968961549

Epoch: 6| Step: 13
Training loss: 5.264178068772569
Validation loss: 6.5480139199832825

Epoch: 35| Step: 0
Training loss: 6.938858036773212
Validation loss: 6.551768871142973

Epoch: 6| Step: 1
Training loss: 5.9607528717926215
Validation loss: 6.437603718787952

Epoch: 6| Step: 2
Training loss: 6.958769763653282
Validation loss: 6.462662919199046

Epoch: 6| Step: 3
Training loss: 6.411613489334887
Validation loss: 6.420789420433997

Epoch: 6| Step: 4
Training loss: 7.111490660048636
Validation loss: 6.366916694471293

Epoch: 6| Step: 5
Training loss: 6.159808219797715
Validation loss: 6.33876757269293

Epoch: 6| Step: 6
Training loss: 5.670271381429861
Validation loss: 6.293390869702671

Epoch: 6| Step: 7
Training loss: 6.146590812253671
Validation loss: 6.208306666458228

Epoch: 6| Step: 8
Training loss: 6.145533805487895
Validation loss: 6.21548659416375

Epoch: 6| Step: 9
Training loss: 5.581731575996342
Validation loss: 6.152016792054046

Epoch: 6| Step: 10
Training loss: 6.0820017711633065
Validation loss: 6.095389947280578

Epoch: 6| Step: 11
Training loss: 6.44834120364024
Validation loss: 6.140040190928829

Epoch: 6| Step: 12
Training loss: 5.360474231864053
Validation loss: 6.034897509933455

Epoch: 6| Step: 13
Training loss: 4.675508750935895
Validation loss: 5.979819614116404

Epoch: 36| Step: 0
Training loss: 6.014013773165003
Validation loss: 5.957381280479507

Epoch: 6| Step: 1
Training loss: 5.29438025315661
Validation loss: 5.939449050420171

Epoch: 6| Step: 2
Training loss: 6.373737584199425
Validation loss: 5.88653075570329

Epoch: 6| Step: 3
Training loss: 5.542478726578056
Validation loss: 5.848641171477824

Epoch: 6| Step: 4
Training loss: 6.1538016005883955
Validation loss: 5.792651419921106

Epoch: 6| Step: 5
Training loss: 4.948699996244674
Validation loss: 5.7482271783090875

Epoch: 6| Step: 6
Training loss: 6.791268397474304
Validation loss: 5.707474575323423

Epoch: 6| Step: 7
Training loss: 5.466232505088182
Validation loss: 5.644650983642255

Epoch: 6| Step: 8
Training loss: 6.102062639553223
Validation loss: 5.633710159471813

Epoch: 6| Step: 9
Training loss: 5.891208447771786
Validation loss: 5.519127509289041

Epoch: 6| Step: 10
Training loss: 4.633832796652151
Validation loss: 5.554212817219041

Epoch: 6| Step: 11
Training loss: 4.1432261232196685
Validation loss: 5.463470297417003

Epoch: 6| Step: 12
Training loss: 5.4176431020330105
Validation loss: 5.434562854470399

Epoch: 6| Step: 13
Training loss: 5.07140462013898
Validation loss: 5.491923703489164

Epoch: 37| Step: 0
Training loss: 5.872593163489804
Validation loss: 5.391803350981102

Epoch: 6| Step: 1
Training loss: 5.191965777667897
Validation loss: 5.360176362552489

Epoch: 6| Step: 2
Training loss: 5.8047959329121905
Validation loss: 5.29118276677819

Epoch: 6| Step: 3
Training loss: 5.672138638845251
Validation loss: 5.285619303143328

Epoch: 6| Step: 4
Training loss: 5.341704930938611
Validation loss: 5.1650450930866345

Epoch: 6| Step: 5
Training loss: 4.097656017263459
Validation loss: 5.109422525756408

Epoch: 6| Step: 6
Training loss: 5.532399720784122
Validation loss: 5.098314806795398

Epoch: 6| Step: 7
Training loss: 5.084860692099307
Validation loss: 5.063144611908146

Epoch: 6| Step: 8
Training loss: 5.744307644311888
Validation loss: 5.028190435109204

Epoch: 6| Step: 9
Training loss: 4.916912762361246
Validation loss: 5.013581929208031

Epoch: 6| Step: 10
Training loss: 4.071727191997249
Validation loss: 4.936069562217231

Epoch: 6| Step: 11
Training loss: 4.262395397703877
Validation loss: 4.9047132815241214

Epoch: 6| Step: 12
Training loss: 4.5855382066373895
Validation loss: 4.9164377551690075

Epoch: 6| Step: 13
Training loss: 4.102884366605086
Validation loss: 4.7277298461654755

Epoch: 38| Step: 0
Training loss: 5.3063187485769285
Validation loss: 4.804656179295835

Epoch: 6| Step: 1
Training loss: 4.858141383746234
Validation loss: 4.715251707818809

Epoch: 6| Step: 2
Training loss: 5.287167816910101
Validation loss: 4.673700098859921

Epoch: 6| Step: 3
Training loss: 4.564534400017205
Validation loss: 4.710484510487233

Epoch: 6| Step: 4
Training loss: 3.2704105630416636
Validation loss: 4.635566972058779

Epoch: 6| Step: 5
Training loss: 4.657316764138802
Validation loss: 4.586475900640216

Epoch: 6| Step: 6
Training loss: 4.5880606576357
Validation loss: 4.548492275951532

Epoch: 6| Step: 7
Training loss: 4.442624209443446
Validation loss: 4.518639371778334

Epoch: 6| Step: 8
Training loss: 4.657408295003476
Validation loss: 4.543462694894811

Epoch: 6| Step: 9
Training loss: 3.4202361341013714
Validation loss: 4.474112245294888

Epoch: 6| Step: 10
Training loss: 4.524905478823304
Validation loss: 4.489907058629803

Epoch: 6| Step: 11
Training loss: 5.024328553238599
Validation loss: 4.443301732860118

Epoch: 6| Step: 12
Training loss: 3.6679501599053
Validation loss: 4.384788596621595

Epoch: 6| Step: 13
Training loss: 4.43088866402975
Validation loss: 4.348952050217094

Epoch: 39| Step: 0
Training loss: 4.6838291290416
Validation loss: 4.317084383347202

Epoch: 6| Step: 1
Training loss: 4.524736866755779
Validation loss: 4.2526726664420496

Epoch: 6| Step: 2
Training loss: 4.073913738358117
Validation loss: 4.262672539332204

Epoch: 6| Step: 3
Training loss: 3.5681648055191766
Validation loss: 4.251086615500025

Epoch: 6| Step: 4
Training loss: 3.989305982917555
Validation loss: 4.191206429093562

Epoch: 6| Step: 5
Training loss: 3.9190646737289394
Validation loss: 4.1415366105925795

Epoch: 6| Step: 6
Training loss: 3.8539353309831745
Validation loss: 4.141317451514372

Epoch: 6| Step: 7
Training loss: 3.597893490667898
Validation loss: 4.110728457974353

Epoch: 6| Step: 8
Training loss: 4.289892231047758
Validation loss: 4.072867092819822

Epoch: 6| Step: 9
Training loss: 3.267785046963643
Validation loss: 4.062229427038864

Epoch: 6| Step: 10
Training loss: 5.935034310194306
Validation loss: 3.9693393038828937

Epoch: 6| Step: 11
Training loss: 2.30076549893802
Validation loss: 3.9247441716526366

Epoch: 6| Step: 12
Training loss: 4.521394100070718
Validation loss: 3.9357534644375183

Epoch: 6| Step: 13
Training loss: 3.8431204923887767
Validation loss: 3.9727150590069824

Epoch: 40| Step: 0
Training loss: 3.7010921258311256
Validation loss: 3.9053630440448326

Epoch: 6| Step: 1
Training loss: 4.383640367514665
Validation loss: 3.932029720068685

Epoch: 6| Step: 2
Training loss: 4.10580881381793
Validation loss: 3.9584675289564557

Epoch: 6| Step: 3
Training loss: 4.085652503728821
Validation loss: 3.8346397230094644

Epoch: 6| Step: 4
Training loss: 3.500299168471008
Validation loss: 3.911271674540206

Epoch: 6| Step: 5
Training loss: 3.604547881029706
Validation loss: 3.891057627883136

Epoch: 6| Step: 6
Training loss: 3.138844303125776
Validation loss: 3.8587930815282183

Epoch: 6| Step: 7
Training loss: 3.9851494728304457
Validation loss: 3.705933855860354

Epoch: 6| Step: 8
Training loss: 4.903521708576845
Validation loss: 3.7918057554242823

Epoch: 6| Step: 9
Training loss: 2.554221947856359
Validation loss: 3.7217013638438448

Epoch: 6| Step: 10
Training loss: 3.5605993722130966
Validation loss: 3.8050731537515836

Epoch: 6| Step: 11
Training loss: 2.535303237956425
Validation loss: 3.7737615543801857

Epoch: 6| Step: 12
Training loss: 3.8091756366386833
Validation loss: 3.7813814757827857

Epoch: 6| Step: 13
Training loss: 4.8403739731125075
Validation loss: 3.64559927521597

Epoch: 41| Step: 0
Training loss: 3.7573781228366134
Validation loss: 3.7188815718101083

Epoch: 6| Step: 1
Training loss: 4.640825569108435
Validation loss: 3.6417353851787384

Epoch: 6| Step: 2
Training loss: 3.83361472603544
Validation loss: 3.6836735202808546

Epoch: 6| Step: 3
Training loss: 3.8257625841897114
Validation loss: 3.674155685588544

Epoch: 6| Step: 4
Training loss: 3.2991578212335853
Validation loss: 3.696511362116886

Epoch: 6| Step: 5
Training loss: 3.343627642237772
Validation loss: 3.584312553186144

Epoch: 6| Step: 6
Training loss: 4.265882547170046
Validation loss: 3.660272074950616

Epoch: 6| Step: 7
Training loss: 3.2790931515691164
Validation loss: 3.6585497947367367

Epoch: 6| Step: 8
Training loss: 3.803713570080925
Validation loss: 3.5915055651799177

Epoch: 6| Step: 9
Training loss: 4.513323028830669
Validation loss: 3.64443616449898

Epoch: 6| Step: 10
Training loss: 2.5042168339820576
Validation loss: 3.589476419069501

Epoch: 6| Step: 11
Training loss: 3.792361744200697
Validation loss: 3.5017441243502887

Epoch: 6| Step: 12
Training loss: 3.6225500048864516
Validation loss: 3.5904067344072934

Epoch: 6| Step: 13
Training loss: 3.3590496526684146
Validation loss: 3.5692142353655214

Epoch: 42| Step: 0
Training loss: 3.691281852442639
Validation loss: 3.551267525466588

Epoch: 6| Step: 1
Training loss: 3.914636870554931
Validation loss: 3.4229706793918924

Epoch: 6| Step: 2
Training loss: 4.1359509844356594
Validation loss: 3.5762422176277453

Epoch: 6| Step: 3
Training loss: 3.3368626189515727
Validation loss: 3.505146284909854

Epoch: 6| Step: 4
Training loss: 4.354796928287368
Validation loss: 3.529316285499911

Epoch: 6| Step: 5
Training loss: 2.6833629259013865
Validation loss: 3.5401871855018645

Epoch: 6| Step: 6
Training loss: 3.6103666190178334
Validation loss: 3.557468789991456

Epoch: 6| Step: 7
Training loss: 3.0893808975487564
Validation loss: 3.4733710460053464

Epoch: 6| Step: 8
Training loss: 3.8636655857388655
Validation loss: 3.497016707639206

Epoch: 6| Step: 9
Training loss: 3.98039256014546
Validation loss: 3.493514533103238

Epoch: 6| Step: 10
Training loss: 5.075972538109481
Validation loss: 3.511780423386106

Epoch: 6| Step: 11
Training loss: 2.527122617595995
Validation loss: 3.528603242389237

Epoch: 6| Step: 12
Training loss: 3.3236928449854712
Validation loss: 3.5567231402381787

Epoch: 6| Step: 13
Training loss: 4.0182645560894334
Validation loss: 3.540076576495243

Epoch: 43| Step: 0
Training loss: 3.263720965743905
Validation loss: 3.5351774093709905

Epoch: 6| Step: 1
Training loss: 3.466054057743643
Validation loss: 3.5431328293315083

Epoch: 6| Step: 2
Training loss: 3.621380412946958
Validation loss: 3.5401280911473774

Epoch: 6| Step: 3
Training loss: 4.215133586318789
Validation loss: 3.4678533862882523

Epoch: 6| Step: 4
Training loss: 3.4194550339918477
Validation loss: 3.5625687358495193

Epoch: 6| Step: 5
Training loss: 3.6963028659336055
Validation loss: 3.53569547784953

Epoch: 6| Step: 6
Training loss: 2.558819057648977
Validation loss: 3.52723272515887

Epoch: 6| Step: 7
Training loss: 3.589508206995886
Validation loss: 3.577966116489729

Epoch: 6| Step: 8
Training loss: 4.439196195270876
Validation loss: 3.5300332282702462

Epoch: 6| Step: 9
Training loss: 3.4527015944287593
Validation loss: 3.465883551177474

Epoch: 6| Step: 10
Training loss: 4.273887819766362
Validation loss: 3.5422598402993906

Epoch: 6| Step: 11
Training loss: 3.3710456570656953
Validation loss: 3.505371059742391

Epoch: 6| Step: 12
Training loss: 4.5814349086441855
Validation loss: 3.678153697635918

Epoch: 6| Step: 13
Training loss: 2.9955578340879554
Validation loss: 3.598203527400723

Epoch: 44| Step: 0
Training loss: 3.7730178125741025
Validation loss: 3.5508245195229535

Epoch: 6| Step: 1
Training loss: 3.081063199522711
Validation loss: 3.5592189194782797

Epoch: 6| Step: 2
Training loss: 3.501762491325518
Validation loss: 3.414904627529945

Epoch: 6| Step: 3
Training loss: 3.6257405018011655
Validation loss: 3.5419877991891346

Epoch: 6| Step: 4
Training loss: 3.3462569206545276
Validation loss: 3.560198869148809

Epoch: 6| Step: 5
Training loss: 2.7562077421724718
Validation loss: 3.617736668407545

Epoch: 6| Step: 6
Training loss: 3.99412797025807
Validation loss: 3.519749711974363

Epoch: 6| Step: 7
Training loss: 3.594468020152689
Validation loss: 3.443011789977049

Epoch: 6| Step: 8
Training loss: 4.157824684076473
Validation loss: 3.515611500776801

Epoch: 6| Step: 9
Training loss: 3.231142059235095
Validation loss: 3.4769583365783716

Epoch: 6| Step: 10
Training loss: 4.4385282372885735
Validation loss: 3.5528143082297663

Epoch: 6| Step: 11
Training loss: 4.067189019430421
Validation loss: 3.4768224438571824

Epoch: 6| Step: 12
Training loss: 3.7814339837325783
Validation loss: 3.4741042435618588

Epoch: 6| Step: 13
Training loss: 2.977992717931284
Validation loss: 3.3643693753375308

Epoch: 45| Step: 0
Training loss: 4.190290972819149
Validation loss: 3.511804104884316

Epoch: 6| Step: 1
Training loss: 5.005341918729296
Validation loss: 3.532903983946853

Epoch: 6| Step: 2
Training loss: 3.526177873708825
Validation loss: 3.428108160594687

Epoch: 6| Step: 3
Training loss: 2.7979396732962765
Validation loss: 3.3596858345110547

Epoch: 6| Step: 4
Training loss: 2.152819239993044
Validation loss: 3.461543034176348

Epoch: 6| Step: 5
Training loss: 3.7494620891057964
Validation loss: 3.4760901824931376

Epoch: 6| Step: 6
Training loss: 3.935163622196601
Validation loss: 3.5609407047423844

Epoch: 6| Step: 7
Training loss: 3.4919265547169798
Validation loss: 3.437556031964636

Epoch: 6| Step: 8
Training loss: 4.317740973643337
Validation loss: 3.484865271551254

Epoch: 6| Step: 9
Training loss: 2.9694778353276106
Validation loss: 3.388112663532917

Epoch: 6| Step: 10
Training loss: 3.780658896406684
Validation loss: 3.439848532178729

Epoch: 6| Step: 11
Training loss: 3.0602121955251116
Validation loss: 3.418808933014139

Epoch: 6| Step: 12
Training loss: 2.8176085806421898
Validation loss: 3.3198051258971906

Epoch: 6| Step: 13
Training loss: 3.6657826629580015
Validation loss: 3.358128051867579

Epoch: 46| Step: 0
Training loss: 3.4532810365799276
Validation loss: 3.368669615629359

Epoch: 6| Step: 1
Training loss: 3.25341558706811
Validation loss: 3.3023644027476178

Epoch: 6| Step: 2
Training loss: 2.6724425488283803
Validation loss: 3.5408634952006204

Epoch: 6| Step: 3
Training loss: 4.663119580212409
Validation loss: 3.3735371894342223

Epoch: 6| Step: 4
Training loss: 3.3269533772528375
Validation loss: 3.484137998422967

Epoch: 6| Step: 5
Training loss: 3.543944101551529
Validation loss: 3.5021895988267002

Epoch: 6| Step: 6
Training loss: 4.330424775394622
Validation loss: 3.396602694197716

Epoch: 6| Step: 7
Training loss: 4.487858817968712
Validation loss: 3.377791318807147

Epoch: 6| Step: 8
Training loss: 3.1803747085914797
Validation loss: 3.4123428146255477

Epoch: 6| Step: 9
Training loss: 3.564334330212206
Validation loss: 3.4483006603726927

Epoch: 6| Step: 10
Training loss: 3.649002325540744
Validation loss: 3.453335027841176

Epoch: 6| Step: 11
Training loss: 2.965082734418762
Validation loss: 3.389442093467572

Epoch: 6| Step: 12
Training loss: 4.421490655916998
Validation loss: 3.5271034459123194

Epoch: 6| Step: 13
Training loss: 2.9230057267541736
Validation loss: 3.262756955042736

Epoch: 47| Step: 0
Training loss: 3.427121534202263
Validation loss: 3.5648979316061955

Epoch: 6| Step: 1
Training loss: 4.030517511577491
Validation loss: 3.4404309229606245

Epoch: 6| Step: 2
Training loss: 3.5717026823301454
Validation loss: 3.427833504697307

Epoch: 6| Step: 3
Training loss: 3.81149228645514
Validation loss: 3.441154722298875

Epoch: 6| Step: 4
Training loss: 3.8132913737445002
Validation loss: 3.4097148098014434

Epoch: 6| Step: 5
Training loss: 3.1795882225940497
Validation loss: 3.449737040524152

Epoch: 6| Step: 6
Training loss: 3.777063747943669
Validation loss: 3.38733416427124

Epoch: 6| Step: 7
Training loss: 3.8705051563594735
Validation loss: 3.3728905758373093

Epoch: 6| Step: 8
Training loss: 4.15332685658872
Validation loss: 3.436589480094726

Epoch: 6| Step: 9
Training loss: 3.8336652252704906
Validation loss: 3.4469953827358215

Epoch: 6| Step: 10
Training loss: 3.993389269755986
Validation loss: 3.487265292849215

Epoch: 6| Step: 11
Training loss: 3.7899652093986496
Validation loss: 3.413487210838972

Epoch: 6| Step: 12
Training loss: 2.9839227942943785
Validation loss: 3.4336978942710887

Epoch: 6| Step: 13
Training loss: 3.656338160829478
Validation loss: 3.2792289279433326

Epoch: 48| Step: 0
Training loss: 4.858566364089083
Validation loss: 3.3424440336247008

Epoch: 6| Step: 1
Training loss: 2.9198916634620162
Validation loss: 3.4180153501647608

Epoch: 6| Step: 2
Training loss: 3.713050000072656
Validation loss: 3.4023444221152794

Epoch: 6| Step: 3
Training loss: 2.414991773982284
Validation loss: 3.4040074435711167

Epoch: 6| Step: 4
Training loss: 3.5133834813813953
Validation loss: 3.418954428966759

Epoch: 6| Step: 5
Training loss: 3.565606887330064
Validation loss: 3.319297739116198

Epoch: 6| Step: 6
Training loss: 3.389565860552419
Validation loss: 3.555290158640157

Epoch: 6| Step: 7
Training loss: 4.908096451972022
Validation loss: 3.3407948434387906

Epoch: 6| Step: 8
Training loss: 3.0717490526460067
Validation loss: 3.3830288602771694

Epoch: 6| Step: 9
Training loss: 3.241141056182118
Validation loss: 3.4083421680612638

Epoch: 6| Step: 10
Training loss: 3.2917912777520053
Validation loss: 3.459584361366426

Epoch: 6| Step: 11
Training loss: 2.123792754175701
Validation loss: 3.4156865258003535

Epoch: 6| Step: 12
Training loss: 4.441051942084772
Validation loss: 3.4533720182867627

Epoch: 6| Step: 13
Training loss: 2.953600809831188
Validation loss: 3.4822757459246887

Epoch: 49| Step: 0
Training loss: 3.668449459730723
Validation loss: 3.4375807468331234

Epoch: 6| Step: 1
Training loss: 4.377186256202079
Validation loss: 3.4274508481204444

Epoch: 6| Step: 2
Training loss: 3.72130849323937
Validation loss: 3.316632649871849

Epoch: 6| Step: 3
Training loss: 3.8710677591600358
Validation loss: 3.2669634248103967

Epoch: 6| Step: 4
Training loss: 4.283060178445722
Validation loss: 3.3451903488617374

Epoch: 6| Step: 5
Training loss: 2.1197730461133824
Validation loss: 3.378499297137902

Epoch: 6| Step: 6
Training loss: 2.8603637319965602
Validation loss: 3.4224542919817775

Epoch: 6| Step: 7
Training loss: 2.831750390168031
Validation loss: 3.3231768114563502

Epoch: 6| Step: 8
Training loss: 3.714365963540534
Validation loss: 3.3258427292385586

Epoch: 6| Step: 9
Training loss: 2.3307942699240827
Validation loss: 3.527911493554911

Epoch: 6| Step: 10
Training loss: 3.499427884889959
Validation loss: 3.3988886293192953

Epoch: 6| Step: 11
Training loss: 4.00929087240631
Validation loss: 3.356127215969692

Epoch: 6| Step: 12
Training loss: 3.619425729966854
Validation loss: 3.2842311600608456

Epoch: 6| Step: 13
Training loss: 5.002637358328148
Validation loss: 3.3294307002523316

Epoch: 50| Step: 0
Training loss: 2.8957144806620048
Validation loss: 3.3878983305086035

Epoch: 6| Step: 1
Training loss: 3.4129140917039025
Validation loss: 3.3789649925552925

Epoch: 6| Step: 2
Training loss: 3.810057310939887
Validation loss: 3.415509021566839

Epoch: 6| Step: 3
Training loss: 3.399050041330913
Validation loss: 3.416328636053159

Epoch: 6| Step: 4
Training loss: 3.3871584280177536
Validation loss: 3.416548758172282

Epoch: 6| Step: 5
Training loss: 3.0476251705709894
Validation loss: 3.424156780859995

Epoch: 6| Step: 6
Training loss: 2.539999545390171
Validation loss: 3.4581569612325036

Epoch: 6| Step: 7
Training loss: 3.315733429109252
Validation loss: 3.384283698915589

Epoch: 6| Step: 8
Training loss: 3.961503750205296
Validation loss: 3.3992968736135376

Epoch: 6| Step: 9
Training loss: 3.3012690618182075
Validation loss: 3.371798491359576

Epoch: 6| Step: 10
Training loss: 4.23860255838516
Validation loss: 3.218699254050987

Epoch: 6| Step: 11
Training loss: 3.707657756059987
Validation loss: 3.5492167918425506

Epoch: 6| Step: 12
Training loss: 4.5842090579256505
Validation loss: 3.420795070416267

Epoch: 6| Step: 13
Training loss: 3.773166812641671
Validation loss: 3.396306695237795

Epoch: 51| Step: 0
Training loss: 3.50024985375277
Validation loss: 3.411198799551899

Epoch: 6| Step: 1
Training loss: 4.063491465553361
Validation loss: 3.4110265678234293

Epoch: 6| Step: 2
Training loss: 3.358705391795254
Validation loss: 3.369394080383873

Epoch: 6| Step: 3
Training loss: 3.145931486573236
Validation loss: 3.527128265964735

Epoch: 6| Step: 4
Training loss: 3.8632708820323467
Validation loss: 3.312481987521698

Epoch: 6| Step: 5
Training loss: 3.6582239805198355
Validation loss: 3.5020061623625605

Epoch: 6| Step: 6
Training loss: 3.8212637311884006
Validation loss: 3.387097450945777

Epoch: 6| Step: 7
Training loss: 3.047719672080252
Validation loss: 3.2620918986461023

Epoch: 6| Step: 8
Training loss: 2.8735920319482826
Validation loss: 3.3845436403001012

Epoch: 6| Step: 9
Training loss: 4.017690164638533
Validation loss: 3.3493742909914723

Epoch: 6| Step: 10
Training loss: 3.9862305154022173
Validation loss: 3.3686760812886316

Epoch: 6| Step: 11
Training loss: 3.60769838967983
Validation loss: 3.347265014309092

Epoch: 6| Step: 12
Training loss: 3.8986062909664128
Validation loss: 3.441431580841235

Epoch: 6| Step: 13
Training loss: 3.31085624937174
Validation loss: 3.3909038098087683

Epoch: 52| Step: 0
Training loss: 3.8984214767096184
Validation loss: 3.512091241293466

Epoch: 6| Step: 1
Training loss: 2.802952902113424
Validation loss: 3.3166139425225003

Epoch: 6| Step: 2
Training loss: 4.318680025408833
Validation loss: 3.404440409774961

Epoch: 6| Step: 3
Training loss: 3.6738896463648705
Validation loss: 3.2294272490654503

Epoch: 6| Step: 4
Training loss: 2.5080303917462508
Validation loss: 3.4278429714693397

Epoch: 6| Step: 5
Training loss: 2.222983177021874
Validation loss: 3.3427358259855766

Epoch: 6| Step: 6
Training loss: 4.252974423021033
Validation loss: 3.323992772730763

Epoch: 6| Step: 7
Training loss: 3.291925701781528
Validation loss: 3.275461337841068

Epoch: 6| Step: 8
Training loss: 3.255637927382126
Validation loss: 3.504975280976485

Epoch: 6| Step: 9
Training loss: 4.105812762480988
Validation loss: 3.4043594838529665

Epoch: 6| Step: 10
Training loss: 4.42640868787218
Validation loss: 3.2530817671547756

Epoch: 6| Step: 11
Training loss: 4.157140421316551
Validation loss: 3.494807453828051

Epoch: 6| Step: 12
Training loss: 3.143233549193472
Validation loss: 3.289308894122382

Epoch: 6| Step: 13
Training loss: 2.503585818731147
Validation loss: 3.4219201969434523

Epoch: 53| Step: 0
Training loss: 3.1659142620938425
Validation loss: 3.3306644550821303

Epoch: 6| Step: 1
Training loss: 3.115661094402885
Validation loss: 3.510596219282278

Epoch: 6| Step: 2
Training loss: 3.4895904237286097
Validation loss: 3.4529924398344782

Epoch: 6| Step: 3
Training loss: 3.731610923192862
Validation loss: 3.3330043927804094

Epoch: 6| Step: 4
Training loss: 4.029516276064334
Validation loss: 3.2635203893927227

Epoch: 6| Step: 5
Training loss: 3.2087103551979705
Validation loss: 3.3462332872433853

Epoch: 6| Step: 6
Training loss: 3.491281549766677
Validation loss: 3.240404036480099

Epoch: 6| Step: 7
Training loss: 2.595588124686329
Validation loss: 3.3181327653555743

Epoch: 6| Step: 8
Training loss: 3.178551173260414
Validation loss: 3.333507118514549

Epoch: 6| Step: 9
Training loss: 3.9126921975212854
Validation loss: 3.420973642528485

Epoch: 6| Step: 10
Training loss: 5.226312331982338
Validation loss: 3.371981289771742

Epoch: 6| Step: 11
Training loss: 3.748786602801921
Validation loss: 3.356783354791145

Epoch: 6| Step: 12
Training loss: 3.1473101923934275
Validation loss: 3.4408504203944106

Epoch: 6| Step: 13
Training loss: 2.6649359113133415
Validation loss: 3.262654496028743

Epoch: 54| Step: 0
Training loss: 4.134684897505511
Validation loss: 3.360807723332908

Epoch: 6| Step: 1
Training loss: 4.1786003624143735
Validation loss: 3.35072581601878

Epoch: 6| Step: 2
Training loss: 2.8296433898756903
Validation loss: 3.3741784882892203

Epoch: 6| Step: 3
Training loss: 3.3735591497215403
Validation loss: 3.347820718708993

Epoch: 6| Step: 4
Training loss: 2.815044100129703
Validation loss: 3.4458146770914784

Epoch: 6| Step: 5
Training loss: 2.5790982345680913
Validation loss: 3.4289315058295875

Epoch: 6| Step: 6
Training loss: 4.261677127288722
Validation loss: 3.552661741241773

Epoch: 6| Step: 7
Training loss: 4.485213889100658
Validation loss: 3.369702675288402

Epoch: 6| Step: 8
Training loss: 3.5147335024177266
Validation loss: 3.587561705095325

Epoch: 6| Step: 9
Training loss: 4.333951368030013
Validation loss: 3.366753915841857

Epoch: 6| Step: 10
Training loss: 3.105129852036828
Validation loss: 3.3232772672120365

Epoch: 6| Step: 11
Training loss: 2.636995428192029
Validation loss: 3.3615056631238875

Epoch: 6| Step: 12
Training loss: 4.4331863283341155
Validation loss: 3.370367750510175

Epoch: 6| Step: 13
Training loss: 2.17825839319695
Validation loss: 3.374275739004804

Epoch: 55| Step: 0
Training loss: 2.599723738885378
Validation loss: 3.3602815908591857

Epoch: 6| Step: 1
Training loss: 3.9564865354966656
Validation loss: 3.492757100323278

Epoch: 6| Step: 2
Training loss: 3.4493070874075196
Validation loss: 3.283948021327281

Epoch: 6| Step: 3
Training loss: 3.7523923236563053
Validation loss: 3.4101059083481604

Epoch: 6| Step: 4
Training loss: 2.9277788378982827
Validation loss: 3.389271054830314

Epoch: 6| Step: 5
Training loss: 3.8776983894837267
Validation loss: 3.3599284451395754

Epoch: 6| Step: 6
Training loss: 2.5279110208497246
Validation loss: 3.3857460832258854

Epoch: 6| Step: 7
Training loss: 3.2278107452313947
Validation loss: 3.272473453048774

Epoch: 6| Step: 8
Training loss: 3.5749114819218475
Validation loss: 3.4811074469235397

Epoch: 6| Step: 9
Training loss: 3.4765646945217794
Validation loss: 3.288184320183362

Epoch: 6| Step: 10
Training loss: 3.569347025675322
Validation loss: 3.226040819303941

Epoch: 6| Step: 11
Training loss: 3.1613388583605477
Validation loss: 3.3288497155010353

Epoch: 6| Step: 12
Training loss: 3.680910850666144
Validation loss: 3.324901160400198

Epoch: 6| Step: 13
Training loss: 4.347374371407517
Validation loss: 3.2700859312156676

Epoch: 56| Step: 0
Training loss: 2.7683327560684488
Validation loss: 3.3770577292649526

Epoch: 6| Step: 1
Training loss: 3.3768813929266943
Validation loss: 3.2201683391301192

Epoch: 6| Step: 2
Training loss: 3.8902044720098465
Validation loss: 3.317852898330306

Epoch: 6| Step: 3
Training loss: 3.6503570538768635
Validation loss: 3.319416809298804

Epoch: 6| Step: 4
Training loss: 3.4756705865201
Validation loss: 3.297121344463014

Epoch: 6| Step: 5
Training loss: 3.5161634244814524
Validation loss: 3.3742871277919826

Epoch: 6| Step: 6
Training loss: 4.231833733506892
Validation loss: 3.2785341272995816

Epoch: 6| Step: 7
Training loss: 3.4386245275338543
Validation loss: 3.297529978120594

Epoch: 6| Step: 8
Training loss: 3.520472596477818
Validation loss: 3.2800957348373534

Epoch: 6| Step: 9
Training loss: 2.94860801183516
Validation loss: 3.334447999415335

Epoch: 6| Step: 10
Training loss: 4.3263627744280795
Validation loss: 3.4258484687580286

Epoch: 6| Step: 11
Training loss: 4.415895334703446
Validation loss: 3.3802924094618003

Epoch: 6| Step: 12
Training loss: 2.8812529524583232
Validation loss: 3.423260613382908

Epoch: 6| Step: 13
Training loss: 3.069498279343002
Validation loss: 3.28429843380952

Epoch: 57| Step: 0
Training loss: 3.4572217296128867
Validation loss: 3.3394948454116182

Epoch: 6| Step: 1
Training loss: 2.4667263187034507
Validation loss: 3.266920351428836

Epoch: 6| Step: 2
Training loss: 4.428981718051892
Validation loss: 3.307290703415902

Epoch: 6| Step: 3
Training loss: 3.641096747617769
Validation loss: 3.348344368450296

Epoch: 6| Step: 4
Training loss: 3.3497259625755995
Validation loss: 3.3185314449711703

Epoch: 6| Step: 5
Training loss: 3.558924570628924
Validation loss: 3.485342204855767

Epoch: 6| Step: 6
Training loss: 2.931537827145067
Validation loss: 3.393483986267451

Epoch: 6| Step: 7
Training loss: 3.5584460833968503
Validation loss: 3.544899392498095

Epoch: 6| Step: 8
Training loss: 3.288203836383093
Validation loss: 3.3357972503711038

Epoch: 6| Step: 9
Training loss: 3.7460859853526802
Validation loss: 3.2730558744984335

Epoch: 6| Step: 10
Training loss: 5.09643858181983
Validation loss: 3.327961340475686

Epoch: 6| Step: 11
Training loss: 3.809552663739239
Validation loss: 3.3078691583782907

Epoch: 6| Step: 12
Training loss: 2.407691622799832
Validation loss: 3.447966579195818

Epoch: 6| Step: 13
Training loss: 3.5404214502528024
Validation loss: 3.4452354138470276

Epoch: 58| Step: 0
Training loss: 2.809780925749908
Validation loss: 3.40666858772577

Epoch: 6| Step: 1
Training loss: 4.491103809503224
Validation loss: 3.3366327174453985

Epoch: 6| Step: 2
Training loss: 4.096656291835758
Validation loss: 3.3156762492670304

Epoch: 6| Step: 3
Training loss: 4.6485392583399925
Validation loss: 3.464294374502147

Epoch: 6| Step: 4
Training loss: 3.849074854482905
Validation loss: 3.284919018017804

Epoch: 6| Step: 5
Training loss: 2.8946870872565627
Validation loss: 3.3565193098010506

Epoch: 6| Step: 6
Training loss: 2.9243727834798716
Validation loss: 3.381433203801788

Epoch: 6| Step: 7
Training loss: 3.237241939437132
Validation loss: 3.367079691272964

Epoch: 6| Step: 8
Training loss: 3.996887426528523
Validation loss: 3.3840810185908907

Epoch: 6| Step: 9
Training loss: 3.356935120738289
Validation loss: 3.3915299739494897

Epoch: 6| Step: 10
Training loss: 2.9335760326840985
Validation loss: 3.3329191309450006

Epoch: 6| Step: 11
Training loss: 3.89596362924538
Validation loss: 3.390245862805284

Epoch: 6| Step: 12
Training loss: 2.392676676063437
Validation loss: 3.3411167323086786

Epoch: 6| Step: 13
Training loss: 3.4781326005960587
Validation loss: 3.342451731185986

Epoch: 59| Step: 0
Training loss: 3.9310533337911293
Validation loss: 3.2549717708481505

Epoch: 6| Step: 1
Training loss: 2.8516200229643314
Validation loss: 3.3557394385222596

Epoch: 6| Step: 2
Training loss: 4.310285358939508
Validation loss: 3.3066446565609375

Epoch: 6| Step: 3
Training loss: 3.6204613521237428
Validation loss: 3.364104240095319

Epoch: 6| Step: 4
Training loss: 3.6879096369399256
Validation loss: 3.259664578845403

Epoch: 6| Step: 5
Training loss: 3.499247470064169
Validation loss: 3.2795082497178796

Epoch: 6| Step: 6
Training loss: 4.498380157539828
Validation loss: 3.414238476335588

Epoch: 6| Step: 7
Training loss: 3.236488278466021
Validation loss: 3.3666741278374923

Epoch: 6| Step: 8
Training loss: 2.9699071937729005
Validation loss: 3.3711852296280425

Epoch: 6| Step: 9
Training loss: 3.698177074164378
Validation loss: 3.220325037222666

Epoch: 6| Step: 10
Training loss: 3.0784485932482246
Validation loss: 3.33868489727609

Epoch: 6| Step: 11
Training loss: 3.3726532866054275
Validation loss: 3.3269354445682175

Epoch: 6| Step: 12
Training loss: 3.2270466069560872
Validation loss: 3.357036632781421

Epoch: 6| Step: 13
Training loss: 2.939094922111506
Validation loss: 3.3584435742087426

Epoch: 60| Step: 0
Training loss: 3.5263770585831797
Validation loss: 3.326117473613093

Epoch: 6| Step: 1
Training loss: 2.565620383329338
Validation loss: 3.3300694134339985

Epoch: 6| Step: 2
Training loss: 3.6049982923273496
Validation loss: 3.300683814441504

Epoch: 6| Step: 3
Training loss: 2.2893417240174943
Validation loss: 3.2542590803964404

Epoch: 6| Step: 4
Training loss: 4.357451421277574
Validation loss: 3.2950019937801427

Epoch: 6| Step: 5
Training loss: 3.7455240876575795
Validation loss: 3.438205369936963

Epoch: 6| Step: 6
Training loss: 3.8599704792692493
Validation loss: 3.3485783472852293

Epoch: 6| Step: 7
Training loss: 4.1918558268906985
Validation loss: 3.425775017839487

Epoch: 6| Step: 8
Training loss: 3.3674520224910847
Validation loss: 3.3874355781519228

Epoch: 6| Step: 9
Training loss: 3.063128348525575
Validation loss: 3.4559009110981007

Epoch: 6| Step: 10
Training loss: 3.431202060941298
Validation loss: 3.3892564653784216

Epoch: 6| Step: 11
Training loss: 4.430731110531097
Validation loss: 3.373228927844708

Epoch: 6| Step: 12
Training loss: 3.889741483203266
Validation loss: 3.3742309538789153

Epoch: 6| Step: 13
Training loss: 3.2197643274343464
Validation loss: 3.340484198884622

Epoch: 61| Step: 0
Training loss: 3.2687853255104504
Validation loss: 3.293768029113892

Epoch: 6| Step: 1
Training loss: 2.42308713051459
Validation loss: 3.269679247161872

Epoch: 6| Step: 2
Training loss: 3.413974787023997
Validation loss: 3.3654808849406552

Epoch: 6| Step: 3
Training loss: 3.5430150475889044
Validation loss: 3.3378875973765383

Epoch: 6| Step: 4
Training loss: 3.415073131710957
Validation loss: 3.422075083796843

Epoch: 6| Step: 5
Training loss: 3.6217958166832296
Validation loss: 3.2515929998057085

Epoch: 6| Step: 6
Training loss: 3.4301678227776895
Validation loss: 3.3834434939513156

Epoch: 6| Step: 7
Training loss: 4.928221664496643
Validation loss: 3.4219409776875773

Epoch: 6| Step: 8
Training loss: 3.852167851848291
Validation loss: 3.240971161176801

Epoch: 6| Step: 9
Training loss: 3.81584945880798
Validation loss: 3.379072994129851

Epoch: 6| Step: 10
Training loss: 4.160616080074138
Validation loss: 3.3410414623481497

Epoch: 6| Step: 11
Training loss: 3.63503192661962
Validation loss: 3.345527505386083

Epoch: 6| Step: 12
Training loss: 2.5753871367454195
Validation loss: 3.2943288044188166

Epoch: 6| Step: 13
Training loss: 3.159854454841433
Validation loss: 3.245090765072453

Epoch: 62| Step: 0
Training loss: 3.7833437836848605
Validation loss: 3.307261030607381

Epoch: 6| Step: 1
Training loss: 3.237855963855678
Validation loss: 3.336663352225678

Epoch: 6| Step: 2
Training loss: 3.0822331467556885
Validation loss: 3.3341708351467587

Epoch: 6| Step: 3
Training loss: 3.4966373638989587
Validation loss: 3.3317560360856704

Epoch: 6| Step: 4
Training loss: 3.227780756362647
Validation loss: 3.2909563875896577

Epoch: 6| Step: 5
Training loss: 3.2647183998729123
Validation loss: 3.350819609091634

Epoch: 6| Step: 6
Training loss: 3.4064694955082344
Validation loss: 3.3278472428609334

Epoch: 6| Step: 7
Training loss: 4.2326685996817
Validation loss: 3.242017071511091

Epoch: 6| Step: 8
Training loss: 3.6241785631461867
Validation loss: 3.4165450333845055

Epoch: 6| Step: 9
Training loss: 4.0155689517610895
Validation loss: 3.351462959371607

Epoch: 6| Step: 10
Training loss: 3.421072669877892
Validation loss: 3.3163534988545975

Epoch: 6| Step: 11
Training loss: 2.9431366105254666
Validation loss: 3.3499509034272914

Epoch: 6| Step: 12
Training loss: 3.276765501821982
Validation loss: 3.358154775817832

Epoch: 6| Step: 13
Training loss: 3.962680049620355
Validation loss: 3.4073262850713233

Epoch: 63| Step: 0
Training loss: 3.5069055552996438
Validation loss: 3.2614529464103437

Epoch: 6| Step: 1
Training loss: 3.99385934599429
Validation loss: 3.3881085352074396

Epoch: 6| Step: 2
Training loss: 2.5115716158426276
Validation loss: 3.2994589785034742

Epoch: 6| Step: 3
Training loss: 4.27865098460331
Validation loss: 3.490773474124072

Epoch: 6| Step: 4
Training loss: 3.3385037059480562
Validation loss: 3.3432741467714555

Epoch: 6| Step: 5
Training loss: 3.9474825792369126
Validation loss: 3.4416002268686046

Epoch: 6| Step: 6
Training loss: 2.817720188719981
Validation loss: 3.3932674253030424

Epoch: 6| Step: 7
Training loss: 3.413253863000608
Validation loss: 3.2214110768141277

Epoch: 6| Step: 8
Training loss: 2.757562296380702
Validation loss: 3.357747205976291

Epoch: 6| Step: 9
Training loss: 4.6572584045947
Validation loss: 3.263662813366184

Epoch: 6| Step: 10
Training loss: 3.8486390073852705
Validation loss: 3.284034003446541

Epoch: 6| Step: 11
Training loss: 3.640999050325701
Validation loss: 3.315722947165581

Epoch: 6| Step: 12
Training loss: 3.3977072446377234
Validation loss: 3.375624179281294

Epoch: 6| Step: 13
Training loss: 2.7412099807677794
Validation loss: 3.304806766119311

Epoch: 64| Step: 0
Training loss: 4.706331800988546
Validation loss: 3.433795920809906

Epoch: 6| Step: 1
Training loss: 2.2803453715902138
Validation loss: 3.273286381753953

Epoch: 6| Step: 2
Training loss: 2.782707346879158
Validation loss: 3.282147940861653

Epoch: 6| Step: 3
Training loss: 3.300225169273714
Validation loss: 3.44270089071583

Epoch: 6| Step: 4
Training loss: 4.235309793250053
Validation loss: 3.222411302969588

Epoch: 6| Step: 5
Training loss: 2.915583073190892
Validation loss: 3.2688265548127324

Epoch: 6| Step: 6
Training loss: 4.171180467263256
Validation loss: 3.3848234524280114

Epoch: 6| Step: 7
Training loss: 2.7924071701042994
Validation loss: 3.35976766708159

Epoch: 6| Step: 8
Training loss: 3.3596049385333355
Validation loss: 3.3270495487946876

Epoch: 6| Step: 9
Training loss: 2.2020336721757903
Validation loss: 3.331638062497695

Epoch: 6| Step: 10
Training loss: 3.772520976782458
Validation loss: 3.412979016750682

Epoch: 6| Step: 11
Training loss: 3.582996234266861
Validation loss: 3.505738825797396

Epoch: 6| Step: 12
Training loss: 4.182485738252265
Validation loss: 3.228192810071291

Epoch: 6| Step: 13
Training loss: 2.976142272922166
Validation loss: 3.389011079661015

Epoch: 65| Step: 0
Training loss: 3.594472132567479
Validation loss: 3.2882448830202486

Epoch: 6| Step: 1
Training loss: 3.4765310907552363
Validation loss: 3.4711558136046268

Epoch: 6| Step: 2
Training loss: 2.7731121893280135
Validation loss: 3.447988969558851

Epoch: 6| Step: 3
Training loss: 3.522389055052177
Validation loss: 3.336184138327826

Epoch: 6| Step: 4
Training loss: 3.924014780590284
Validation loss: 3.39308936099806

Epoch: 6| Step: 5
Training loss: 3.7585260740763418
Validation loss: 3.2143720049131317

Epoch: 6| Step: 6
Training loss: 2.988862184391846
Validation loss: 3.3191375047035065

Epoch: 6| Step: 7
Training loss: 4.1817236388303725
Validation loss: 3.279163415559589

Epoch: 6| Step: 8
Training loss: 4.228351433013161
Validation loss: 3.252077713244857

Epoch: 6| Step: 9
Training loss: 2.8251338758226665
Validation loss: 3.313165147078591

Epoch: 6| Step: 10
Training loss: 3.3348910188955436
Validation loss: 3.3968947172609165

Epoch: 6| Step: 11
Training loss: 4.042281323653828
Validation loss: 3.3279191605889005

Epoch: 6| Step: 12
Training loss: 2.7631819112111637
Validation loss: 3.435287961593182

Epoch: 6| Step: 13
Training loss: 4.338596058199655
Validation loss: 3.465880519972368

Epoch: 66| Step: 0
Training loss: 2.7845990879637372
Validation loss: 3.3182607682689205

Epoch: 6| Step: 1
Training loss: 3.5692438909557582
Validation loss: 3.1791135522875598

Epoch: 6| Step: 2
Training loss: 3.8290310779983043
Validation loss: 3.289672653108988

Epoch: 6| Step: 3
Training loss: 2.86446507065302
Validation loss: 3.2240646042354673

Epoch: 6| Step: 4
Training loss: 3.781218473444889
Validation loss: 3.3842536376158066

Epoch: 6| Step: 5
Training loss: 2.655710322588833
Validation loss: 3.3588176504381306

Epoch: 6| Step: 6
Training loss: 4.223465608142686
Validation loss: 3.3210121015161413

Epoch: 6| Step: 7
Training loss: 3.004183078109068
Validation loss: 3.4253537534801066

Epoch: 6| Step: 8
Training loss: 2.8114864642410855
Validation loss: 3.3652442174611434

Epoch: 6| Step: 9
Training loss: 3.831809127856159
Validation loss: 3.315069219577756

Epoch: 6| Step: 10
Training loss: 3.7073685037414585
Validation loss: 3.227317872799854

Epoch: 6| Step: 11
Training loss: 2.883077304328973
Validation loss: 3.3690256437227744

Epoch: 6| Step: 12
Training loss: 3.1571930335754455
Validation loss: 3.3543557065566496

Epoch: 6| Step: 13
Training loss: 4.041980744313652
Validation loss: 3.3574175226243863

Epoch: 67| Step: 0
Training loss: 3.5359146232050365
Validation loss: 3.3670023923968873

Epoch: 6| Step: 1
Training loss: 3.6222152536971364
Validation loss: 3.3366516452427537

Epoch: 6| Step: 2
Training loss: 2.6787605128079757
Validation loss: 3.156442274704342

Epoch: 6| Step: 3
Training loss: 3.139121839343164
Validation loss: 3.3863055833046656

Epoch: 6| Step: 4
Training loss: 3.3987130590509804
Validation loss: 3.3303434273063344

Epoch: 6| Step: 5
Training loss: 3.1992971482877284
Validation loss: 3.397148556819615

Epoch: 6| Step: 6
Training loss: 4.702068831264097
Validation loss: 3.187342699976378

Epoch: 6| Step: 7
Training loss: 3.572337171235413
Validation loss: 3.3624060359094257

Epoch: 6| Step: 8
Training loss: 3.4849579327752136
Validation loss: 3.357422030769128

Epoch: 6| Step: 9
Training loss: 2.6277874270533728
Validation loss: 3.355284925138532

Epoch: 6| Step: 10
Training loss: 3.2884619520206853
Validation loss: 3.42472113472631

Epoch: 6| Step: 11
Training loss: 3.9842536459000906
Validation loss: 3.3420326561736675

Epoch: 6| Step: 12
Training loss: 2.6203342935000458
Validation loss: 3.462290293428197

Epoch: 6| Step: 13
Training loss: 3.3801646805321615
Validation loss: 3.325878856039046

Epoch: 68| Step: 0
Training loss: 3.5548126534029127
Validation loss: 3.219410936066302

Epoch: 6| Step: 1
Training loss: 4.150897487432311
Validation loss: 3.3045843969349926

Epoch: 6| Step: 2
Training loss: 2.6766988475697175
Validation loss: 3.301381036299951

Epoch: 6| Step: 3
Training loss: 4.19585621185783
Validation loss: 3.4087584208922603

Epoch: 6| Step: 4
Training loss: 3.2091329659754746
Validation loss: 3.3961060134740744

Epoch: 6| Step: 5
Training loss: 3.2438323846545902
Validation loss: 3.237517945482224

Epoch: 6| Step: 6
Training loss: 4.128156898947061
Validation loss: 3.321194528862299

Epoch: 6| Step: 7
Training loss: 3.1527073684724853
Validation loss: 3.3746115895118787

Epoch: 6| Step: 8
Training loss: 2.5374074383470053
Validation loss: 3.212616919229351

Epoch: 6| Step: 9
Training loss: 4.086594712918844
Validation loss: 3.204335863580163

Epoch: 6| Step: 10
Training loss: 3.653144104110588
Validation loss: 3.1673745080419846

Epoch: 6| Step: 11
Training loss: 3.4729329225327144
Validation loss: 3.264139375927216

Epoch: 6| Step: 12
Training loss: 3.9734603683167626
Validation loss: 3.2465636510736813

Epoch: 6| Step: 13
Training loss: 3.0530779956959395
Validation loss: 3.192463336445319

Epoch: 69| Step: 0
Training loss: 3.2469556194499694
Validation loss: 3.191729249011073

Epoch: 6| Step: 1
Training loss: 3.9027469644352046
Validation loss: 3.1659553249157595

Epoch: 6| Step: 2
Training loss: 4.747433621634039
Validation loss: 3.2120619911819914

Epoch: 6| Step: 3
Training loss: 3.1538019034052933
Validation loss: 3.1885513399158474

Epoch: 6| Step: 4
Training loss: 3.080807828611037
Validation loss: 3.3438162143006136

Epoch: 6| Step: 5
Training loss: 3.283600755312388
Validation loss: 3.429654179938017

Epoch: 6| Step: 6
Training loss: 3.422237150633097
Validation loss: 3.279353247614111

Epoch: 6| Step: 7
Training loss: 3.362159178524396
Validation loss: 3.3952795110941985

Epoch: 6| Step: 8
Training loss: 3.2592303440548522
Validation loss: 3.2631337528871986

Epoch: 6| Step: 9
Training loss: 3.6442333234588733
Validation loss: 3.372393873072172

Epoch: 6| Step: 10
Training loss: 2.8247329855792276
Validation loss: 3.142568188829422

Epoch: 6| Step: 11
Training loss: 2.616284297129611
Validation loss: 3.307451006392437

Epoch: 6| Step: 12
Training loss: 3.5765483997578653
Validation loss: 3.4049535419503365

Epoch: 6| Step: 13
Training loss: 3.70089873662334
Validation loss: 3.277784441962077

Epoch: 70| Step: 0
Training loss: 2.3627483176868274
Validation loss: 3.4065635591772225

Epoch: 6| Step: 1
Training loss: 2.838325104924578
Validation loss: 3.27879527163056

Epoch: 6| Step: 2
Training loss: 2.5599714690347093
Validation loss: 3.2013697815640603

Epoch: 6| Step: 3
Training loss: 2.7772007300442825
Validation loss: 3.2829491469594547

Epoch: 6| Step: 4
Training loss: 2.188845956072579
Validation loss: 3.198299303431708

Epoch: 6| Step: 5
Training loss: 4.6906198927249845
Validation loss: 3.3280195972190616

Epoch: 6| Step: 6
Training loss: 4.387176136551278
Validation loss: 3.2284734664004753

Epoch: 6| Step: 7
Training loss: 2.410222230375984
Validation loss: 3.264529329813364

Epoch: 6| Step: 8
Training loss: 2.9835752044604784
Validation loss: 3.30697713487845

Epoch: 6| Step: 9
Training loss: 4.635203473049729
Validation loss: 3.338230125367696

Epoch: 6| Step: 10
Training loss: 3.7973969026273755
Validation loss: 3.3013953431649283

Epoch: 6| Step: 11
Training loss: 2.6828031083188666
Validation loss: 3.192168016099043

Epoch: 6| Step: 12
Training loss: 3.878098264443752
Validation loss: 3.3072993997928024

Epoch: 6| Step: 13
Training loss: 4.832202954583666
Validation loss: 3.2394276580794976

Epoch: 71| Step: 0
Training loss: 2.7286330616280683
Validation loss: 3.385000238419631

Epoch: 6| Step: 1
Training loss: 3.0946866553813033
Validation loss: 3.495804246511124

Epoch: 6| Step: 2
Training loss: 2.8225666030850927
Validation loss: 3.265685872871014

Epoch: 6| Step: 3
Training loss: 3.1527606069253147
Validation loss: 3.3849817983346044

Epoch: 6| Step: 4
Training loss: 2.2844823642449916
Validation loss: 3.2537229841608064

Epoch: 6| Step: 5
Training loss: 3.4175179669257414
Validation loss: 3.181528562677838

Epoch: 6| Step: 6
Training loss: 3.8359137571264315
Validation loss: 3.350243651973276

Epoch: 6| Step: 7
Training loss: 2.9421774776407563
Validation loss: 3.324515046850326

Epoch: 6| Step: 8
Training loss: 4.154750467420782
Validation loss: 3.278369994034201

Epoch: 6| Step: 9
Training loss: 2.9097724815120922
Validation loss: 3.1615777500032363

Epoch: 6| Step: 10
Training loss: 3.671766693465847
Validation loss: 3.2504717087748776

Epoch: 6| Step: 11
Training loss: 4.520061913462921
Validation loss: 3.2629973884874697

Epoch: 6| Step: 12
Training loss: 3.483747348791235
Validation loss: 3.2485552764254844

Epoch: 6| Step: 13
Training loss: 4.462316617216349
Validation loss: 3.2489833424863557

Epoch: 72| Step: 0
Training loss: 3.1858204923492877
Validation loss: 3.247883472729362

Epoch: 6| Step: 1
Training loss: 2.9119664239624514
Validation loss: 3.303655570279451

Epoch: 6| Step: 2
Training loss: 4.1844892923530566
Validation loss: 3.2955502316001057

Epoch: 6| Step: 3
Training loss: 4.3336276663564846
Validation loss: 3.191570545300853

Epoch: 6| Step: 4
Training loss: 4.128940434165492
Validation loss: 3.310903794975485

Epoch: 6| Step: 5
Training loss: 2.997908658000825
Validation loss: 3.2791086173753965

Epoch: 6| Step: 6
Training loss: 3.255148550883334
Validation loss: 3.2734241893060188

Epoch: 6| Step: 7
Training loss: 4.055483113401047
Validation loss: 3.1569161879131613

Epoch: 6| Step: 8
Training loss: 3.7510463526360245
Validation loss: 3.4614888865438393

Epoch: 6| Step: 9
Training loss: 2.851444440514117
Validation loss: 3.4440010533892833

Epoch: 6| Step: 10
Training loss: 4.211301883367713
Validation loss: 3.2977671844628413

Epoch: 6| Step: 11
Training loss: 3.062160862420338
Validation loss: 3.232976072630865

Epoch: 6| Step: 12
Training loss: 2.706757766978852
Validation loss: 3.3303155949280345

Epoch: 6| Step: 13
Training loss: 3.0820437819077444
Validation loss: 3.4757433791046215

Epoch: 73| Step: 0
Training loss: 3.619517159058882
Validation loss: 3.2987698065869764

Epoch: 6| Step: 1
Training loss: 2.9293858894225506
Validation loss: 3.304744837392072

Epoch: 6| Step: 2
Training loss: 3.9727109832144025
Validation loss: 3.28921851296544

Epoch: 6| Step: 3
Training loss: 2.9002969129431455
Validation loss: 3.3620871445389646

Epoch: 6| Step: 4
Training loss: 3.5487088071576185
Validation loss: 3.293544050625228

Epoch: 6| Step: 5
Training loss: 2.9470481716499632
Validation loss: 3.2735161898750094

Epoch: 6| Step: 6
Training loss: 2.791619077438189
Validation loss: 3.299050024278847

Epoch: 6| Step: 7
Training loss: 3.016299631822592
Validation loss: 3.2672209382673687

Epoch: 6| Step: 8
Training loss: 3.740965068149298
Validation loss: 3.3771258563338358

Epoch: 6| Step: 9
Training loss: 3.238915246762102
Validation loss: 3.384775312204504

Epoch: 6| Step: 10
Training loss: 3.992424228166562
Validation loss: 3.3917062735670664

Epoch: 6| Step: 11
Training loss: 3.6660564666245246
Validation loss: 3.2266959040852883

Epoch: 6| Step: 12
Training loss: 4.325065991554213
Validation loss: 3.216217709524021

Epoch: 6| Step: 13
Training loss: 2.3019278863636354
Validation loss: 3.18730138505334

Epoch: 74| Step: 0
Training loss: 2.853076104604816
Validation loss: 3.265694781307215

Epoch: 6| Step: 1
Training loss: 2.701605044240086
Validation loss: 3.3597697746002986

Epoch: 6| Step: 2
Training loss: 3.3614174954526774
Validation loss: 3.468312230044463

Epoch: 6| Step: 3
Training loss: 2.7259249665981176
Validation loss: 3.1270994898583857

Epoch: 6| Step: 4
Training loss: 3.0420390558688823
Validation loss: 3.305568688033552

Epoch: 6| Step: 5
Training loss: 3.647234242453277
Validation loss: 3.265660020369925

Epoch: 6| Step: 6
Training loss: 3.3646961740442376
Validation loss: 3.332953015032424

Epoch: 6| Step: 7
Training loss: 3.28072592773536
Validation loss: 3.2063850514315124

Epoch: 6| Step: 8
Training loss: 3.70992662012787
Validation loss: 3.32072205963037

Epoch: 6| Step: 9
Training loss: 3.323126679642995
Validation loss: 3.184120572798701

Epoch: 6| Step: 10
Training loss: 3.218088322747362
Validation loss: 3.2865529576289783

Epoch: 6| Step: 11
Training loss: 3.6228732743533723
Validation loss: 3.172009212108045

Epoch: 6| Step: 12
Training loss: 4.216401527321563
Validation loss: 3.283873778341051

Epoch: 6| Step: 13
Training loss: 4.173724389650294
Validation loss: 3.2726122113666225

Epoch: 75| Step: 0
Training loss: 3.043092541508806
Validation loss: 3.322135648089716

Epoch: 6| Step: 1
Training loss: 3.5524946554467243
Validation loss: 3.1776147234948637

Epoch: 6| Step: 2
Training loss: 3.7361343899883623
Validation loss: 3.2049072781597605

Epoch: 6| Step: 3
Training loss: 3.125297684796011
Validation loss: 3.2843556666172775

Epoch: 6| Step: 4
Training loss: 2.774749015936474
Validation loss: 3.1843392667931436

Epoch: 6| Step: 5
Training loss: 3.38432324088999
Validation loss: 3.4011136921924794

Epoch: 6| Step: 6
Training loss: 3.4997309172599396
Validation loss: 3.1742311297461363

Epoch: 6| Step: 7
Training loss: 3.188518884912454
Validation loss: 3.3250344632935054

Epoch: 6| Step: 8
Training loss: 3.810695283581662
Validation loss: 3.2099484992749283

Epoch: 6| Step: 9
Training loss: 3.2991062225511594
Validation loss: 3.2920714711359524

Epoch: 6| Step: 10
Training loss: 4.30517065864112
Validation loss: 3.3315884150500623

Epoch: 6| Step: 11
Training loss: 3.86407974677396
Validation loss: 3.193764458089726

Epoch: 6| Step: 12
Training loss: 3.9696382745025405
Validation loss: 3.213887170143389

Epoch: 6| Step: 13
Training loss: 2.301091171660034
Validation loss: 3.3784466140339138

Epoch: 76| Step: 0
Training loss: 3.7421165252517206
Validation loss: 3.32100604328165

Epoch: 6| Step: 1
Training loss: 2.5920633554192074
Validation loss: 3.2028101596525143

Epoch: 6| Step: 2
Training loss: 2.8407145638189806
Validation loss: 3.3300507692512484

Epoch: 6| Step: 3
Training loss: 2.518413538266768
Validation loss: 3.180144604355206

Epoch: 6| Step: 4
Training loss: 4.128401538674063
Validation loss: 3.306965757704326

Epoch: 6| Step: 5
Training loss: 3.775539531425533
Validation loss: 3.3190753274047733

Epoch: 6| Step: 6
Training loss: 2.7833847254350514
Validation loss: 3.1610905856971168

Epoch: 6| Step: 7
Training loss: 3.612310627656308
Validation loss: 3.2079825724291853

Epoch: 6| Step: 8
Training loss: 4.1409923462491856
Validation loss: 3.2007163607251377

Epoch: 6| Step: 9
Training loss: 2.962231999761355
Validation loss: 3.328269114598024

Epoch: 6| Step: 10
Training loss: 2.5634601003935704
Validation loss: 3.3595136090639577

Epoch: 6| Step: 11
Training loss: 3.5091219966246294
Validation loss: 3.3035992941942385

Epoch: 6| Step: 12
Training loss: 4.7159864404692105
Validation loss: 3.340912188280197

Epoch: 6| Step: 13
Training loss: 3.1914631757947034
Validation loss: 3.2638318884998188

Epoch: 77| Step: 0
Training loss: 3.76756091235052
Validation loss: 3.359991372586184

Epoch: 6| Step: 1
Training loss: 3.0853855073958014
Validation loss: 3.3706907116653073

Epoch: 6| Step: 2
Training loss: 2.575316963316914
Validation loss: 3.3214142175933277

Epoch: 6| Step: 3
Training loss: 3.6978855328749165
Validation loss: 3.287045169283431

Epoch: 6| Step: 4
Training loss: 3.5078078781811146
Validation loss: 3.211725463105061

Epoch: 6| Step: 5
Training loss: 3.4722058376349536
Validation loss: 3.245652186293892

Epoch: 6| Step: 6
Training loss: 4.317913693221459
Validation loss: 3.2756399861187364

Epoch: 6| Step: 7
Training loss: 3.409103738009272
Validation loss: 3.35525498835102

Epoch: 6| Step: 8
Training loss: 3.374567922555483
Validation loss: 3.3068548460360443

Epoch: 6| Step: 9
Training loss: 2.630493319843905
Validation loss: 3.247693591521478

Epoch: 6| Step: 10
Training loss: 3.7801824907120474
Validation loss: 3.266818085773868

Epoch: 6| Step: 11
Training loss: 2.5813687350325627
Validation loss: 3.4025928779131585

Epoch: 6| Step: 12
Training loss: 3.823341089677024
Validation loss: 3.2980686234020964

Epoch: 6| Step: 13
Training loss: 2.9635400934109035
Validation loss: 3.2797308917766106

Epoch: 78| Step: 0
Training loss: 3.889510519813545
Validation loss: 3.2024323417584997

Epoch: 6| Step: 1
Training loss: 3.8909402129776804
Validation loss: 3.2771800311719663

Epoch: 6| Step: 2
Training loss: 3.1911718126006035
Validation loss: 3.1677858407511845

Epoch: 6| Step: 3
Training loss: 4.152374985183554
Validation loss: 3.330083240609394

Epoch: 6| Step: 4
Training loss: 2.8646082281707077
Validation loss: 3.2995065795641287

Epoch: 6| Step: 5
Training loss: 3.095195085974268
Validation loss: 3.1265697851607244

Epoch: 6| Step: 6
Training loss: 3.717859498158433
Validation loss: 3.223968878518444

Epoch: 6| Step: 7
Training loss: 2.6221192310962826
Validation loss: 3.275369847441548

Epoch: 6| Step: 8
Training loss: 2.593737314951568
Validation loss: 3.338444142400744

Epoch: 6| Step: 9
Training loss: 3.2815394682585004
Validation loss: 3.2293242287410626

Epoch: 6| Step: 10
Training loss: 3.1279504199476817
Validation loss: 3.2172508647354077

Epoch: 6| Step: 11
Training loss: 3.157222786737999
Validation loss: 3.281972799466998

Epoch: 6| Step: 12
Training loss: 3.2652815496726793
Validation loss: 3.291397551541347

Epoch: 6| Step: 13
Training loss: 3.921076476733036
Validation loss: 3.3645130331597217

Epoch: 79| Step: 0
Training loss: 3.493642482570377
Validation loss: 3.3283919299052656

Epoch: 6| Step: 1
Training loss: 3.399937651567437
Validation loss: 3.2882134587812177

Epoch: 6| Step: 2
Training loss: 2.3516810187702304
Validation loss: 3.3430667639562497

Epoch: 6| Step: 3
Training loss: 3.424113338448512
Validation loss: 3.355060940971133

Epoch: 6| Step: 4
Training loss: 3.5713375297931425
Validation loss: 3.314010917893878

Epoch: 6| Step: 5
Training loss: 3.1427070965805037
Validation loss: 3.3325026451265094

Epoch: 6| Step: 6
Training loss: 3.688001695545659
Validation loss: 3.3576263417206493

Epoch: 6| Step: 7
Training loss: 3.4199207595657803
Validation loss: 3.3055396295209043

Epoch: 6| Step: 8
Training loss: 3.885220983791721
Validation loss: 3.2493481057190468

Epoch: 6| Step: 9
Training loss: 3.4130925037937554
Validation loss: 3.2513973207630418

Epoch: 6| Step: 10
Training loss: 3.3689028448700964
Validation loss: 3.2004007002719472

Epoch: 6| Step: 11
Training loss: 4.243250929598447
Validation loss: 3.3318953324625125

Epoch: 6| Step: 12
Training loss: 3.899617905116885
Validation loss: 3.257068937031437

Epoch: 6| Step: 13
Training loss: 3.727487765112382
Validation loss: 3.2392540199728757

Epoch: 80| Step: 0
Training loss: 2.729573071531889
Validation loss: 3.1790860522786297

Epoch: 6| Step: 1
Training loss: 3.146888219205182
Validation loss: 3.3769113027324313

Epoch: 6| Step: 2
Training loss: 4.234630844438731
Validation loss: 3.2082723122461614

Epoch: 6| Step: 3
Training loss: 4.36981286038824
Validation loss: 3.228231265331566

Epoch: 6| Step: 4
Training loss: 3.039461320533386
Validation loss: 3.2442493914262402

Epoch: 6| Step: 5
Training loss: 3.7604501710422387
Validation loss: 3.276423618345455

Epoch: 6| Step: 6
Training loss: 2.5900344893467846
Validation loss: 3.2336988471058707

Epoch: 6| Step: 7
Training loss: 3.698558970085538
Validation loss: 3.219445895362378

Epoch: 6| Step: 8
Training loss: 3.3625266261978726
Validation loss: 3.290931392251541

Epoch: 6| Step: 9
Training loss: 3.321869752005938
Validation loss: 3.2453953406883547

Epoch: 6| Step: 10
Training loss: 3.8853498492320786
Validation loss: 3.2998664339193837

Epoch: 6| Step: 11
Training loss: 3.8529874630131773
Validation loss: 3.291969905814649

Epoch: 6| Step: 12
Training loss: 3.5611449224328595
Validation loss: 3.423188150161037

Epoch: 6| Step: 13
Training loss: 2.1745900261006006
Validation loss: 3.3115751786850387

Epoch: 81| Step: 0
Training loss: 2.813812373523646
Validation loss: 3.2621978857820917

Epoch: 6| Step: 1
Training loss: 2.7514586481601717
Validation loss: 3.2124968687578264

Epoch: 6| Step: 2
Training loss: 4.421500577677045
Validation loss: 3.2625907425485297

Epoch: 6| Step: 3
Training loss: 2.6875665345938233
Validation loss: 3.4030843706420515

Epoch: 6| Step: 4
Training loss: 4.038536170297811
Validation loss: 3.4828284858114413

Epoch: 6| Step: 5
Training loss: 2.9947919143455515
Validation loss: 3.2048002642774747

Epoch: 6| Step: 6
Training loss: 2.7566152248479963
Validation loss: 3.273255871239933

Epoch: 6| Step: 7
Training loss: 3.516398298199046
Validation loss: 3.3316345151767073

Epoch: 6| Step: 8
Training loss: 4.163489440076311
Validation loss: 3.3362784700739545

Epoch: 6| Step: 9
Training loss: 3.3108441514757727
Validation loss: 3.201341599865442

Epoch: 6| Step: 10
Training loss: 3.1446386093862326
Validation loss: 3.2591244004295636

Epoch: 6| Step: 11
Training loss: 3.865227466517323
Validation loss: 3.257904922544783

Epoch: 6| Step: 12
Training loss: 3.1070486596271736
Validation loss: 3.400067631062729

Epoch: 6| Step: 13
Training loss: 2.708022779608386
Validation loss: 3.2508120157383558

Epoch: 82| Step: 0
Training loss: 3.5813860962257698
Validation loss: 3.1749049704026704

Epoch: 6| Step: 1
Training loss: 2.7563019416741623
Validation loss: 3.2758992771617415

Epoch: 6| Step: 2
Training loss: 3.739820141674949
Validation loss: 3.2113471661451563

Epoch: 6| Step: 3
Training loss: 4.265673067709368
Validation loss: 3.1400509826375402

Epoch: 6| Step: 4
Training loss: 2.7476789042406913
Validation loss: 3.3128092445969126

Epoch: 6| Step: 5
Training loss: 4.085610721277825
Validation loss: 3.2488327217710427

Epoch: 6| Step: 6
Training loss: 3.5287207263539018
Validation loss: 3.306268856741436

Epoch: 6| Step: 7
Training loss: 3.760476926424674
Validation loss: 3.1967526850391703

Epoch: 6| Step: 8
Training loss: 2.362653059265069
Validation loss: 3.253170853557095

Epoch: 6| Step: 9
Training loss: 3.5577693114006887
Validation loss: 3.3897470307512982

Epoch: 6| Step: 10
Training loss: 3.4464328181355683
Validation loss: 3.248831950035144

Epoch: 6| Step: 11
Training loss: 2.542987313620319
Validation loss: 3.2874554983597437

Epoch: 6| Step: 12
Training loss: 2.8098811354560613
Validation loss: 3.298848625804304

Epoch: 6| Step: 13
Training loss: 2.465036037096531
Validation loss: 3.307184144393349

Epoch: 83| Step: 0
Training loss: 3.791774887943941
Validation loss: 3.3734679274933312

Epoch: 6| Step: 1
Training loss: 2.611583848413859
Validation loss: 3.3540351203422367

Epoch: 6| Step: 2
Training loss: 4.123092210196043
Validation loss: 3.24075492030211

Epoch: 6| Step: 3
Training loss: 3.936028341749544
Validation loss: 3.2685493430394534

Epoch: 6| Step: 4
Training loss: 3.6962337192438723
Validation loss: 3.256151366572927

Epoch: 6| Step: 5
Training loss: 2.6606334644744836
Validation loss: 3.278798105962233

Epoch: 6| Step: 6
Training loss: 3.1899455543583355
Validation loss: 3.2666436041578106

Epoch: 6| Step: 7
Training loss: 3.3869671054050263
Validation loss: 3.3609629215622245

Epoch: 6| Step: 8
Training loss: 3.3286729818180176
Validation loss: 3.2302796966601677

Epoch: 6| Step: 9
Training loss: 2.6556355382755554
Validation loss: 3.1758068170315363

Epoch: 6| Step: 10
Training loss: 3.569310154019392
Validation loss: 3.2894777569705123

Epoch: 6| Step: 11
Training loss: 2.7010599528285955
Validation loss: 3.328431862447539

Epoch: 6| Step: 12
Training loss: 2.3991327427484874
Validation loss: 3.2775091345407037

Epoch: 6| Step: 13
Training loss: 3.3078086308820223
Validation loss: 3.2429432104487197

Epoch: 84| Step: 0
Training loss: 4.721411554401929
Validation loss: 3.246074884116825

Epoch: 6| Step: 1
Training loss: 3.049910847345839
Validation loss: 3.2374259988734786

Epoch: 6| Step: 2
Training loss: 3.257112789254285
Validation loss: 3.1776458400965137

Epoch: 6| Step: 3
Training loss: 3.7607164483587505
Validation loss: 3.2308482422498264

Epoch: 6| Step: 4
Training loss: 2.4286057986704415
Validation loss: 3.1961345596477977

Epoch: 6| Step: 5
Training loss: 3.847801988039426
Validation loss: 3.2979163763828554

Epoch: 6| Step: 6
Training loss: 3.4297467272256474
Validation loss: 3.2583090202465743

Epoch: 6| Step: 7
Training loss: 2.839047578762987
Validation loss: 3.3090036800778098

Epoch: 6| Step: 8
Training loss: 3.3605661099229396
Validation loss: 3.272054079322083

Epoch: 6| Step: 9
Training loss: 2.7348254023583074
Validation loss: 3.248280801722446

Epoch: 6| Step: 10
Training loss: 3.1767099296556576
Validation loss: 3.217907084856295

Epoch: 6| Step: 11
Training loss: 3.356822334803998
Validation loss: 3.2952088756826763

Epoch: 6| Step: 12
Training loss: 3.5836488156093314
Validation loss: 3.1772368699443523

Epoch: 6| Step: 13
Training loss: 2.420416608212729
Validation loss: 3.361259955361384

Epoch: 85| Step: 0
Training loss: 2.741538381232381
Validation loss: 3.281378888530137

Epoch: 6| Step: 1
Training loss: 3.4969801817919564
Validation loss: 3.168662943482218

Epoch: 6| Step: 2
Training loss: 3.301254184406811
Validation loss: 3.351436224898136

Epoch: 6| Step: 3
Training loss: 3.7834792698569144
Validation loss: 3.1769146811782742

Epoch: 6| Step: 4
Training loss: 3.5839873020253714
Validation loss: 3.2272214166315027

Epoch: 6| Step: 5
Training loss: 2.6929165570873264
Validation loss: 3.2073843428387194

Epoch: 6| Step: 6
Training loss: 2.49825960615043
Validation loss: 3.315720045431127

Epoch: 6| Step: 7
Training loss: 4.205157954711364
Validation loss: 3.1789357568418213

Epoch: 6| Step: 8
Training loss: 2.169349354532201
Validation loss: 3.276173288652825

Epoch: 6| Step: 9
Training loss: 3.7337886078571807
Validation loss: 3.181641392083992

Epoch: 6| Step: 10
Training loss: 2.797177346366359
Validation loss: 3.0797552556934304

Epoch: 6| Step: 11
Training loss: 3.6033433330254807
Validation loss: 3.1515694580541447

Epoch: 6| Step: 12
Training loss: 3.796850636094027
Validation loss: 3.18538054992752

Epoch: 6| Step: 13
Training loss: 3.3538958201233995
Validation loss: 3.015972857204439

Epoch: 86| Step: 0
Training loss: 2.9070067702228664
Validation loss: 3.0758246831880944

Epoch: 6| Step: 1
Training loss: 3.0952924486075992
Validation loss: 3.2855373985386804

Epoch: 6| Step: 2
Training loss: 3.29772808012084
Validation loss: 3.187946712133098

Epoch: 6| Step: 3
Training loss: 4.657643768827208
Validation loss: 3.358945442394052

Epoch: 6| Step: 4
Training loss: 3.9165456360858935
Validation loss: 3.4017567437427942

Epoch: 6| Step: 5
Training loss: 3.841287832275549
Validation loss: 3.2715572457178697

Epoch: 6| Step: 6
Training loss: 3.089352651889916
Validation loss: 3.2985636625275716

Epoch: 6| Step: 7
Training loss: 2.7202821996097972
Validation loss: 3.169955693065306

Epoch: 6| Step: 8
Training loss: 3.080071158392169
Validation loss: 3.316402956170068

Epoch: 6| Step: 9
Training loss: 2.6398978050276853
Validation loss: 3.374583424845509

Epoch: 6| Step: 10
Training loss: 2.5509408897929746
Validation loss: 3.27546215339434

Epoch: 6| Step: 11
Training loss: 3.2405030804233776
Validation loss: 3.337451600141727

Epoch: 6| Step: 12
Training loss: 2.5260366747829757
Validation loss: 3.3429995110422506

Epoch: 6| Step: 13
Training loss: 2.851918822718226
Validation loss: 3.1679678776413365

Epoch: 87| Step: 0
Training loss: 3.672623837994808
Validation loss: 3.2833876905183583

Epoch: 6| Step: 1
Training loss: 2.395721985814086
Validation loss: 3.329614383340536

Epoch: 6| Step: 2
Training loss: 2.7034675513398456
Validation loss: 3.1958940742281006

Epoch: 6| Step: 3
Training loss: 3.247686589778146
Validation loss: 3.409323816780068

Epoch: 6| Step: 4
Training loss: 3.059694990776772
Validation loss: 3.2764840683800616

Epoch: 6| Step: 5
Training loss: 2.8140733344818933
Validation loss: 3.286923450757535

Epoch: 6| Step: 6
Training loss: 3.80757874094946
Validation loss: 3.202006705713598

Epoch: 6| Step: 7
Training loss: 2.4610071565972738
Validation loss: 3.25676700859606

Epoch: 6| Step: 8
Training loss: 3.735765270186373
Validation loss: 3.1372014904041117

Epoch: 6| Step: 9
Training loss: 3.4147981946529544
Validation loss: 3.3939038523884064

Epoch: 6| Step: 10
Training loss: 3.004327831274982
Validation loss: 3.160383404860171

Epoch: 6| Step: 11
Training loss: 4.140953885818177
Validation loss: 3.1198387692317704

Epoch: 6| Step: 12
Training loss: 3.464965267695399
Validation loss: 3.3226599123326532

Epoch: 6| Step: 13
Training loss: 4.488382602274389
Validation loss: 3.205929036804384

Epoch: 88| Step: 0
Training loss: 3.57432601017338
Validation loss: 3.3140297513313977

Epoch: 6| Step: 1
Training loss: 3.470080283827522
Validation loss: 3.170671407721224

Epoch: 6| Step: 2
Training loss: 3.691941253806406
Validation loss: 3.134912896737217

Epoch: 6| Step: 3
Training loss: 3.5194973790510855
Validation loss: 3.153699230988053

Epoch: 6| Step: 4
Training loss: 3.964310934411223
Validation loss: 3.0706480005186814

Epoch: 6| Step: 5
Training loss: 4.056130683448922
Validation loss: 3.1908343732268993

Epoch: 6| Step: 6
Training loss: 2.9504792810102733
Validation loss: 3.1924048689746103

Epoch: 6| Step: 7
Training loss: 3.9305012582743677
Validation loss: 3.1492246035135665

Epoch: 6| Step: 8
Training loss: 3.559014874359972
Validation loss: 3.3094908763949733

Epoch: 6| Step: 9
Training loss: 2.74494756054427
Validation loss: 3.278125019832656

Epoch: 6| Step: 10
Training loss: 3.149821164337679
Validation loss: 3.291507625722705

Epoch: 6| Step: 11
Training loss: 2.613976447404266
Validation loss: 3.1194282353060045

Epoch: 6| Step: 12
Training loss: 3.5519364998786114
Validation loss: 3.360155867730105

Epoch: 6| Step: 13
Training loss: 2.65455869796675
Validation loss: 3.2833375789485166

Epoch: 89| Step: 0
Training loss: 2.673341315282129
Validation loss: 3.3392719333159726

Epoch: 6| Step: 1
Training loss: 3.5002242425200136
Validation loss: 3.2399575954656674

Epoch: 6| Step: 2
Training loss: 3.5406032686164237
Validation loss: 3.207771474742358

Epoch: 6| Step: 3
Training loss: 2.838868531238932
Validation loss: 3.251174864277408

Epoch: 6| Step: 4
Training loss: 2.977743240016976
Validation loss: 3.1600016411825984

Epoch: 6| Step: 5
Training loss: 3.1202568679610505
Validation loss: 3.1505234747420805

Epoch: 6| Step: 6
Training loss: 4.071127079673704
Validation loss: 3.2264806038888696

Epoch: 6| Step: 7
Training loss: 3.3345133758976777
Validation loss: 3.1547205519143295

Epoch: 6| Step: 8
Training loss: 3.236022234902776
Validation loss: 3.251364682527039

Epoch: 6| Step: 9
Training loss: 3.9921774668110226
Validation loss: 3.0252643838156135

Epoch: 6| Step: 10
Training loss: 3.465210904835409
Validation loss: 3.250703758324797

Epoch: 6| Step: 11
Training loss: 3.4910210831245094
Validation loss: 3.3120163107589717

Epoch: 6| Step: 12
Training loss: 3.0173369771160266
Validation loss: 3.157512448460332

Epoch: 6| Step: 13
Training loss: 4.101675733183991
Validation loss: 3.264909802051677

Epoch: 90| Step: 0
Training loss: 3.310228540649876
Validation loss: 3.2432776676004433

Epoch: 6| Step: 1
Training loss: 2.8046759389995013
Validation loss: 3.3899925144442147

Epoch: 6| Step: 2
Training loss: 2.69663920161812
Validation loss: 3.2599435558877037

Epoch: 6| Step: 3
Training loss: 2.8144349965260185
Validation loss: 3.0898383951172494

Epoch: 6| Step: 4
Training loss: 3.0582576094424896
Validation loss: 3.302422311456898

Epoch: 6| Step: 5
Training loss: 3.81072694166265
Validation loss: 3.2116706764984637

Epoch: 6| Step: 6
Training loss: 3.7730246371332576
Validation loss: 3.2521064753430737

Epoch: 6| Step: 7
Training loss: 3.338910031441261
Validation loss: 3.191508231488696

Epoch: 6| Step: 8
Training loss: 4.268106151186712
Validation loss: 3.2331364777769593

Epoch: 6| Step: 9
Training loss: 2.469330055563518
Validation loss: 3.2965719129098243

Epoch: 6| Step: 10
Training loss: 3.209546012742325
Validation loss: 3.23893342141214

Epoch: 6| Step: 11
Training loss: 4.023767194850429
Validation loss: 3.370950688996427

Epoch: 6| Step: 12
Training loss: 2.8623511662999617
Validation loss: 3.178380174929905

Epoch: 6| Step: 13
Training loss: 3.8037237243045667
Validation loss: 3.2968618749114174

Epoch: 91| Step: 0
Training loss: 3.7408373473659933
Validation loss: 3.243480383376311

Epoch: 6| Step: 1
Training loss: 3.8810086579161123
Validation loss: 3.4127156072284777

Epoch: 6| Step: 2
Training loss: 3.0143901292902515
Validation loss: 3.1557006690914267

Epoch: 6| Step: 3
Training loss: 3.9032358976908457
Validation loss: 3.167899128872991

Epoch: 6| Step: 4
Training loss: 2.7350309620556987
Validation loss: 3.2283755494757633

Epoch: 6| Step: 5
Training loss: 3.3173940241200004
Validation loss: 3.4343760132215437

Epoch: 6| Step: 6
Training loss: 3.208299876117065
Validation loss: 3.211504724115003

Epoch: 6| Step: 7
Training loss: 3.5123479192534144
Validation loss: 3.2349091038769924

Epoch: 6| Step: 8
Training loss: 3.128786920565112
Validation loss: 3.182021445759034

Epoch: 6| Step: 9
Training loss: 3.860064363881844
Validation loss: 3.1327360705088743

Epoch: 6| Step: 10
Training loss: 3.315282552653795
Validation loss: 3.1976652974847597

Epoch: 6| Step: 11
Training loss: 3.422789986963974
Validation loss: 3.2544558879180503

Epoch: 6| Step: 12
Training loss: 2.782080879829273
Validation loss: 3.1644844684305067

Epoch: 6| Step: 13
Training loss: 3.9049568171928133
Validation loss: 3.3238304461549126

Epoch: 92| Step: 0
Training loss: 3.184814518628425
Validation loss: 3.192851275456524

Epoch: 6| Step: 1
Training loss: 3.5355535968855283
Validation loss: 3.336794732382554

Epoch: 6| Step: 2
Training loss: 3.296509347317724
Validation loss: 3.2536754381768453

Epoch: 6| Step: 3
Training loss: 3.006085898506431
Validation loss: 3.1660156541505393

Epoch: 6| Step: 4
Training loss: 1.7017934651199025
Validation loss: 3.3184388413916097

Epoch: 6| Step: 5
Training loss: 3.10558068415606
Validation loss: 3.213478766791537

Epoch: 6| Step: 6
Training loss: 3.0726303398229007
Validation loss: 3.151258394494607

Epoch: 6| Step: 7
Training loss: 2.9234647454970384
Validation loss: 3.3572831803401475

Epoch: 6| Step: 8
Training loss: 3.3603894498463527
Validation loss: 3.165716163542126

Epoch: 6| Step: 9
Training loss: 3.205853003003674
Validation loss: 3.2331193172091153

Epoch: 6| Step: 10
Training loss: 2.574868845145738
Validation loss: 3.3330549682755306

Epoch: 6| Step: 11
Training loss: 4.063653400719805
Validation loss: 3.231205625533429

Epoch: 6| Step: 12
Training loss: 4.562849475592424
Validation loss: 3.211343021333001

Epoch: 6| Step: 13
Training loss: 3.6023742687725346
Validation loss: 3.238339911998699

Epoch: 93| Step: 0
Training loss: 4.472120601112904
Validation loss: 3.1921981090405724

Epoch: 6| Step: 1
Training loss: 3.6624646963038923
Validation loss: 3.2263097827221867

Epoch: 6| Step: 2
Training loss: 3.0294015498618165
Validation loss: 3.204879129967425

Epoch: 6| Step: 3
Training loss: 3.682270544585961
Validation loss: 3.26971022698627

Epoch: 6| Step: 4
Training loss: 2.9144450491402316
Validation loss: 3.2039513795273074

Epoch: 6| Step: 5
Training loss: 2.6888204480052824
Validation loss: 3.2040141594554075

Epoch: 6| Step: 6
Training loss: 4.163846294809269
Validation loss: 3.2429908331467385

Epoch: 6| Step: 7
Training loss: 2.8920136286624136
Validation loss: 3.1568695819923795

Epoch: 6| Step: 8
Training loss: 2.881865224298407
Validation loss: 3.2373705987396963

Epoch: 6| Step: 9
Training loss: 2.7059693118242163
Validation loss: 3.104591725933209

Epoch: 6| Step: 10
Training loss: 2.4691049827606673
Validation loss: 3.166348173082106

Epoch: 6| Step: 11
Training loss: 2.562648117622835
Validation loss: 3.1760345121071616

Epoch: 6| Step: 12
Training loss: 3.4680634240111394
Validation loss: 3.400622171711997

Epoch: 6| Step: 13
Training loss: 3.227009075008998
Validation loss: 3.23248879467781

Epoch: 94| Step: 0
Training loss: 2.7563257289179854
Validation loss: 3.1575406697858477

Epoch: 6| Step: 1
Training loss: 3.3665819088177993
Validation loss: 3.2088401472971952

Epoch: 6| Step: 2
Training loss: 3.382616702573728
Validation loss: 3.1158945948680095

Epoch: 6| Step: 3
Training loss: 3.813962061964883
Validation loss: 3.181262459079714

Epoch: 6| Step: 4
Training loss: 2.673583438174112
Validation loss: 3.2938176831222425

Epoch: 6| Step: 5
Training loss: 3.549135269368909
Validation loss: 3.1767975940776148

Epoch: 6| Step: 6
Training loss: 3.650958544138186
Validation loss: 3.1936800275892003

Epoch: 6| Step: 7
Training loss: 2.686511989223835
Validation loss: 3.2759434806771948

Epoch: 6| Step: 8
Training loss: 4.285079691089114
Validation loss: 3.2586919274758905

Epoch: 6| Step: 9
Training loss: 2.5750549532757816
Validation loss: 3.0518744702165344

Epoch: 6| Step: 10
Training loss: 4.4565874525708695
Validation loss: 3.205092295436828

Epoch: 6| Step: 11
Training loss: 2.7255044102819403
Validation loss: 3.231071798288044

Epoch: 6| Step: 12
Training loss: 3.005977239150769
Validation loss: 3.262477041454547

Epoch: 6| Step: 13
Training loss: 1.6951833227490296
Validation loss: 3.2580300496005434

Epoch: 95| Step: 0
Training loss: 3.8466603495801053
Validation loss: 3.2502261699170103

Epoch: 6| Step: 1
Training loss: 2.9160633734787953
Validation loss: 3.2628612721708308

Epoch: 6| Step: 2
Training loss: 3.9987200835033927
Validation loss: 3.103015601729246

Epoch: 6| Step: 3
Training loss: 2.495032811837796
Validation loss: 3.283866764742594

Epoch: 6| Step: 4
Training loss: 2.5597055596660057
Validation loss: 3.1481224689633365

Epoch: 6| Step: 5
Training loss: 3.415350838954823
Validation loss: 3.213291996895214

Epoch: 6| Step: 6
Training loss: 3.254202839499325
Validation loss: 3.356807688331095

Epoch: 6| Step: 7
Training loss: 3.431933386727525
Validation loss: 3.2930772006622164

Epoch: 6| Step: 8
Training loss: 2.823109262425522
Validation loss: 3.2123392046267183

Epoch: 6| Step: 9
Training loss: 2.703429805791848
Validation loss: 3.291648307573599

Epoch: 6| Step: 10
Training loss: 3.0875048556270333
Validation loss: 3.2580548468744497

Epoch: 6| Step: 11
Training loss: 2.8932605172881405
Validation loss: 3.230952915958309

Epoch: 6| Step: 12
Training loss: 3.2209890040932687
Validation loss: 3.2674775981915816

Epoch: 6| Step: 13
Training loss: 4.273129523580226
Validation loss: 3.2929531110616184

Epoch: 96| Step: 0
Training loss: 2.8904161532451393
Validation loss: 3.239243550928794

Epoch: 6| Step: 1
Training loss: 4.335490325688173
Validation loss: 3.2411642995005305

Epoch: 6| Step: 2
Training loss: 2.444097930257294
Validation loss: 3.358255481502088

Epoch: 6| Step: 3
Training loss: 3.200879607901901
Validation loss: 3.2885906249372483

Epoch: 6| Step: 4
Training loss: 3.043889387569753
Validation loss: 3.112837360745156

Epoch: 6| Step: 5
Training loss: 2.7704190013743895
Validation loss: 3.164379678939831

Epoch: 6| Step: 6
Training loss: 2.8628658810458525
Validation loss: 3.0768661685885927

Epoch: 6| Step: 7
Training loss: 2.5899554152314983
Validation loss: 3.220826830283835

Epoch: 6| Step: 8
Training loss: 3.1714696766117707
Validation loss: 3.175361792780277

Epoch: 6| Step: 9
Training loss: 3.9160168426587885
Validation loss: 3.335639377179735

Epoch: 6| Step: 10
Training loss: 3.8456507999392304
Validation loss: 3.1783091622031288

Epoch: 6| Step: 11
Training loss: 3.5033330033795473
Validation loss: 3.1834523517676923

Epoch: 6| Step: 12
Training loss: 3.2463606484834635
Validation loss: 3.1336361102127155

Epoch: 6| Step: 13
Training loss: 2.6048229967194088
Validation loss: 3.246269715202078

Epoch: 97| Step: 0
Training loss: 2.172739200044196
Validation loss: 3.309048532975966

Epoch: 6| Step: 1
Training loss: 3.5596876588167845
Validation loss: 3.2453378505304094

Epoch: 6| Step: 2
Training loss: 3.4882530903293674
Validation loss: 3.2199542362194387

Epoch: 6| Step: 3
Training loss: 3.644309083109898
Validation loss: 3.2299728662703675

Epoch: 6| Step: 4
Training loss: 3.991792244950038
Validation loss: 3.1798572114540793

Epoch: 6| Step: 5
Training loss: 2.735758927125823
Validation loss: 3.0659737029977285

Epoch: 6| Step: 6
Training loss: 3.1669241315344165
Validation loss: 3.1917242899658835

Epoch: 6| Step: 7
Training loss: 3.129377427264949
Validation loss: 3.181485824955198

Epoch: 6| Step: 8
Training loss: 3.7253106211755234
Validation loss: 3.178830149345901

Epoch: 6| Step: 9
Training loss: 3.591462443859985
Validation loss: 3.245921910672634

Epoch: 6| Step: 10
Training loss: 3.372704608385864
Validation loss: 3.2057951108059517

Epoch: 6| Step: 11
Training loss: 2.554874984907692
Validation loss: 3.146818275069528

Epoch: 6| Step: 12
Training loss: 2.9200691721835828
Validation loss: 3.3276680846411493

Epoch: 6| Step: 13
Training loss: 3.931851407430386
Validation loss: 3.2629212498469276

Epoch: 98| Step: 0
Training loss: 3.3842606825467274
Validation loss: 3.108144984226512

Epoch: 6| Step: 1
Training loss: 3.3979110134568113
Validation loss: 3.2833914804772775

Epoch: 6| Step: 2
Training loss: 3.239407370021213
Validation loss: 3.158078991239422

Epoch: 6| Step: 3
Training loss: 3.5891721012052784
Validation loss: 3.2718408118659825

Epoch: 6| Step: 4
Training loss: 2.547458418037884
Validation loss: 3.2588812103371594

Epoch: 6| Step: 5
Training loss: 3.498666645568561
Validation loss: 3.1351836841613046

Epoch: 6| Step: 6
Training loss: 3.0260968009053686
Validation loss: 3.1357517545100277

Epoch: 6| Step: 7
Training loss: 4.4128686421317775
Validation loss: 3.2104728771161333

Epoch: 6| Step: 8
Training loss: 4.320251795530236
Validation loss: 3.247647142921338

Epoch: 6| Step: 9
Training loss: 2.052635299367789
Validation loss: 3.1939612508404065

Epoch: 6| Step: 10
Training loss: 3.5542721683873135
Validation loss: 3.0719420881332034

Epoch: 6| Step: 11
Training loss: 2.985379354630203
Validation loss: 3.1095183157000017

Epoch: 6| Step: 12
Training loss: 2.8071461051802875
Validation loss: 3.2732152647789476

Epoch: 6| Step: 13
Training loss: 2.8697006478850158
Validation loss: 3.177315890500197

Epoch: 99| Step: 0
Training loss: 2.633016787790225
Validation loss: 3.1412646220290434

Epoch: 6| Step: 1
Training loss: 3.8382365063606705
Validation loss: 3.1296605720561814

Epoch: 6| Step: 2
Training loss: 2.674848719802323
Validation loss: 3.2587920959561396

Epoch: 6| Step: 3
Training loss: 2.46691565631604
Validation loss: 3.139550557626081

Epoch: 6| Step: 4
Training loss: 3.155750952821358
Validation loss: 3.2188907173986134

Epoch: 6| Step: 5
Training loss: 1.9236147069916547
Validation loss: 3.2362098809634174

Epoch: 6| Step: 6
Training loss: 3.663504942419863
Validation loss: 3.3133506588142327

Epoch: 6| Step: 7
Training loss: 3.981775011451713
Validation loss: 3.2150176698532142

Epoch: 6| Step: 8
Training loss: 2.524755741806746
Validation loss: 3.2913316644740713

Epoch: 6| Step: 9
Training loss: 3.8052930408778147
Validation loss: 3.174498822524375

Epoch: 6| Step: 10
Training loss: 3.692600666551582
Validation loss: 3.195535015356791

Epoch: 6| Step: 11
Training loss: 3.6696757771563746
Validation loss: 3.1805680332588984

Epoch: 6| Step: 12
Training loss: 3.0366386416747555
Validation loss: 3.31345542491709

Epoch: 6| Step: 13
Training loss: 2.3129360715720613
Validation loss: 3.161578086515855

Epoch: 100| Step: 0
Training loss: 3.0401521509141625
Validation loss: 3.164521282908476

Epoch: 6| Step: 1
Training loss: 2.5206809089753994
Validation loss: 3.0742584608301375

Epoch: 6| Step: 2
Training loss: 3.182052894704113
Validation loss: 3.170268801972421

Epoch: 6| Step: 3
Training loss: 2.8211863846677896
Validation loss: 3.259883807323801

Epoch: 6| Step: 4
Training loss: 4.033431534845864
Validation loss: 3.2518687243590247

Epoch: 6| Step: 5
Training loss: 2.657157832570806
Validation loss: 3.2103015156143564

Epoch: 6| Step: 6
Training loss: 3.9641507149076625
Validation loss: 3.3085136194178957

Epoch: 6| Step: 7
Training loss: 2.9955298180265264
Validation loss: 3.291138535096444

Epoch: 6| Step: 8
Training loss: 3.8991099295605722
Validation loss: 3.198180244157181

Epoch: 6| Step: 9
Training loss: 3.310820531646715
Validation loss: 3.2376504721598103

Epoch: 6| Step: 10
Training loss: 4.320434347852258
Validation loss: 3.1698740975526376

Epoch: 6| Step: 11
Training loss: 2.543230128296225
Validation loss: 3.1699652198991894

Epoch: 6| Step: 12
Training loss: 3.17320697046647
Validation loss: 3.2037500507442003

Epoch: 6| Step: 13
Training loss: 3.5082420307037103
Validation loss: 3.160354960696314

Epoch: 101| Step: 0
Training loss: 1.533379300437439
Validation loss: 3.1792724867440687

Epoch: 6| Step: 1
Training loss: 3.596556653899598
Validation loss: 3.2403413856197236

Epoch: 6| Step: 2
Training loss: 3.5175613157219137
Validation loss: 3.2304048390653275

Epoch: 6| Step: 3
Training loss: 2.4812183599112245
Validation loss: 3.248853141931006

Epoch: 6| Step: 4
Training loss: 4.570941171037636
Validation loss: 3.2397695270979234

Epoch: 6| Step: 5
Training loss: 3.0370650996571777
Validation loss: 3.2576392594865573

Epoch: 6| Step: 6
Training loss: 3.549916312077498
Validation loss: 3.0837725919833225

Epoch: 6| Step: 7
Training loss: 2.1600179507251402
Validation loss: 3.370164777937985

Epoch: 6| Step: 8
Training loss: 2.8615954173361984
Validation loss: 3.038211397857165

Epoch: 6| Step: 9
Training loss: 4.315743152898698
Validation loss: 3.2257699642373843

Epoch: 6| Step: 10
Training loss: 3.3140184772738372
Validation loss: 3.183413948292933

Epoch: 6| Step: 11
Training loss: 4.026639919402696
Validation loss: 3.186976848911465

Epoch: 6| Step: 12
Training loss: 3.325888728635718
Validation loss: 3.2814370019522454

Epoch: 6| Step: 13
Training loss: 2.0001587804708723
Validation loss: 3.2069398314577735

Epoch: 102| Step: 0
Training loss: 3.3428865547889113
Validation loss: 3.1568270179906093

Epoch: 6| Step: 1
Training loss: 3.279111910358397
Validation loss: 3.169063624874327

Epoch: 6| Step: 2
Training loss: 2.7081777283399195
Validation loss: 3.187335660567776

Epoch: 6| Step: 3
Training loss: 3.548369777474968
Validation loss: 3.287325347636779

Epoch: 6| Step: 4
Training loss: 3.0948724733372623
Validation loss: 3.2307472042036953

Epoch: 6| Step: 5
Training loss: 3.177581314499112
Validation loss: 3.221926830546377

Epoch: 6| Step: 6
Training loss: 3.214872228002664
Validation loss: 3.136174191231383

Epoch: 6| Step: 7
Training loss: 3.608713857366043
Validation loss: 3.106837825831444

Epoch: 6| Step: 8
Training loss: 3.0098099850721862
Validation loss: 3.1606480153850147

Epoch: 6| Step: 9
Training loss: 3.460141058014459
Validation loss: 3.1520248719218893

Epoch: 6| Step: 10
Training loss: 1.8805643803013636
Validation loss: 3.27246403348898

Epoch: 6| Step: 11
Training loss: 3.130113004649353
Validation loss: 3.214372812039374

Epoch: 6| Step: 12
Training loss: 2.62345950019159
Validation loss: 3.2087965573467168

Epoch: 6| Step: 13
Training loss: 3.3510602383528316
Validation loss: 3.2295180374029258

Epoch: 103| Step: 0
Training loss: 3.703664877122887
Validation loss: 3.245366395882189

Epoch: 6| Step: 1
Training loss: 3.8225980759308014
Validation loss: 3.2032915545765084

Epoch: 6| Step: 2
Training loss: 3.523485948859669
Validation loss: 3.3522833814207864

Epoch: 6| Step: 3
Training loss: 3.1041922002847366
Validation loss: 3.348895792102124

Epoch: 6| Step: 4
Training loss: 2.8357147045210684
Validation loss: 3.247509330920452

Epoch: 6| Step: 5
Training loss: 3.1367850290709303
Validation loss: 3.275299145148739

Epoch: 6| Step: 6
Training loss: 3.1579177529349556
Validation loss: 3.175893154290981

Epoch: 6| Step: 7
Training loss: 3.148752958713548
Validation loss: 3.197666001397152

Epoch: 6| Step: 8
Training loss: 3.5701906947220183
Validation loss: 3.3166123301082253

Epoch: 6| Step: 9
Training loss: 3.503553493948813
Validation loss: 3.105156403689825

Epoch: 6| Step: 10
Training loss: 2.3405925590599606
Validation loss: 3.0847249891128024

Epoch: 6| Step: 11
Training loss: 3.211307402231748
Validation loss: 3.1102045636296136

Epoch: 6| Step: 12
Training loss: 2.8404108921518527
Validation loss: 3.242361691032451

Epoch: 6| Step: 13
Training loss: 2.1048671450336687
Validation loss: 3.123056881487425

Epoch: 104| Step: 0
Training loss: 3.3490846094952
Validation loss: 3.2045391091666153

Epoch: 6| Step: 1
Training loss: 2.947284554331607
Validation loss: 3.0791630122991913

Epoch: 6| Step: 2
Training loss: 3.3353167990498913
Validation loss: 3.1639862679297246

Epoch: 6| Step: 3
Training loss: 2.9100982455419016
Validation loss: 3.1911878780334257

Epoch: 6| Step: 4
Training loss: 3.4625080755807507
Validation loss: 3.216348888451599

Epoch: 6| Step: 5
Training loss: 3.069739057652959
Validation loss: 3.187159233529319

Epoch: 6| Step: 6
Training loss: 3.899322470476091
Validation loss: 3.197113837935178

Epoch: 6| Step: 7
Training loss: 3.1027848071644146
Validation loss: 2.9039210765113315

Epoch: 6| Step: 8
Training loss: 2.742278268730111
Validation loss: 3.1944920577474436

Epoch: 6| Step: 9
Training loss: 3.1087859089322447
Validation loss: 3.1234125219321007

Epoch: 6| Step: 10
Training loss: 4.004167055149172
Validation loss: 3.2243365351997797

Epoch: 6| Step: 11
Training loss: 2.8102705702383886
Validation loss: 3.1588738418392572

Epoch: 6| Step: 12
Training loss: 2.553910630188246
Validation loss: 3.2745468010815735

Epoch: 6| Step: 13
Training loss: 3.669128169726278
Validation loss: 3.1820667253739985

Epoch: 105| Step: 0
Training loss: 3.5859884287556527
Validation loss: 3.115166659742226

Epoch: 6| Step: 1
Training loss: 3.3205078067558524
Validation loss: 3.2488809620026804

Epoch: 6| Step: 2
Training loss: 3.0799448278365458
Validation loss: 3.257782858129948

Epoch: 6| Step: 3
Training loss: 2.8528050054158594
Validation loss: 3.113369674416061

Epoch: 6| Step: 4
Training loss: 3.6721752287499205
Validation loss: 3.413287688655601

Epoch: 6| Step: 5
Training loss: 3.1060121072900415
Validation loss: 3.236898018284916

Epoch: 6| Step: 6
Training loss: 2.942700591400675
Validation loss: 3.3020559873749358

Epoch: 6| Step: 7
Training loss: 4.235964543598544
Validation loss: 3.1936122176407182

Epoch: 6| Step: 8
Training loss: 3.210330803721593
Validation loss: 3.2503859067610668

Epoch: 6| Step: 9
Training loss: 3.17352447465709
Validation loss: 3.257658363737404

Epoch: 6| Step: 10
Training loss: 2.825386449662294
Validation loss: 3.168355511395054

Epoch: 6| Step: 11
Training loss: 3.517352006370524
Validation loss: 3.242545638533348

Epoch: 6| Step: 12
Training loss: 3.887198659128106
Validation loss: 3.259953269565689

Epoch: 6| Step: 13
Training loss: 1.8959305776730948
Validation loss: 3.1325944365286946

Epoch: 106| Step: 0
Training loss: 2.628409487536823
Validation loss: 3.2080402797104206

Epoch: 6| Step: 1
Training loss: 2.6371823955784377
Validation loss: 3.164808314699292

Epoch: 6| Step: 2
Training loss: 4.085186103307563
Validation loss: 3.2280498075017476

Epoch: 6| Step: 3
Training loss: 3.7462832787772724
Validation loss: 3.181846894636876

Epoch: 6| Step: 4
Training loss: 3.5400602100661445
Validation loss: 3.1756435790723754

Epoch: 6| Step: 5
Training loss: 3.348717822767179
Validation loss: 3.1545588916458627

Epoch: 6| Step: 6
Training loss: 3.2448500397862277
Validation loss: 3.291623364609346

Epoch: 6| Step: 7
Training loss: 2.603256910995766
Validation loss: 3.1895631727809066

Epoch: 6| Step: 8
Training loss: 3.4945011539301767
Validation loss: 3.2621536689004147

Epoch: 6| Step: 9
Training loss: 4.062932387596629
Validation loss: 3.207074425089834

Epoch: 6| Step: 10
Training loss: 3.363948955116863
Validation loss: 3.2310575815151488

Epoch: 6| Step: 11
Training loss: 2.7990657814639515
Validation loss: 3.1798936028719273

Epoch: 6| Step: 12
Training loss: 2.8768579864827615
Validation loss: 3.2233315617864355

Epoch: 6| Step: 13
Training loss: 3.3271567498795487
Validation loss: 3.2591650054671755

Epoch: 107| Step: 0
Training loss: 3.5367054616494342
Validation loss: 3.170282725292584

Epoch: 6| Step: 1
Training loss: 3.7557443491064095
Validation loss: 3.229528320469172

Epoch: 6| Step: 2
Training loss: 4.019698989378429
Validation loss: 3.053940051419833

Epoch: 6| Step: 3
Training loss: 3.7033718364876016
Validation loss: 3.3365945165437094

Epoch: 6| Step: 4
Training loss: 2.7631461030904476
Validation loss: 3.280592745238802

Epoch: 6| Step: 5
Training loss: 3.107570105181565
Validation loss: 3.2641134860446717

Epoch: 6| Step: 6
Training loss: 3.119101183121791
Validation loss: 3.0859087991372816

Epoch: 6| Step: 7
Training loss: 3.5609567880212736
Validation loss: 3.0863842679319227

Epoch: 6| Step: 8
Training loss: 4.1725477040594
Validation loss: 3.247122351202982

Epoch: 6| Step: 9
Training loss: 3.704675148790896
Validation loss: 3.082947342404993

Epoch: 6| Step: 10
Training loss: 3.1512142081613197
Validation loss: 3.143762401643686

Epoch: 6| Step: 11
Training loss: 2.0715015379734023
Validation loss: 3.1308594830855183

Epoch: 6| Step: 12
Training loss: 3.0799987047366106
Validation loss: 3.135798424945608

Epoch: 6| Step: 13
Training loss: 1.9514280958599954
Validation loss: 3.387015429436537

Epoch: 108| Step: 0
Training loss: 2.918275135301643
Validation loss: 3.234364670518072

Epoch: 6| Step: 1
Training loss: 4.127607041928546
Validation loss: 3.3375580277528956

Epoch: 6| Step: 2
Training loss: 3.0442304040178336
Validation loss: 3.2032772193113503

Epoch: 6| Step: 3
Training loss: 3.5787694092549662
Validation loss: 3.2309578989002445

Epoch: 6| Step: 4
Training loss: 2.4714460499883324
Validation loss: 3.0614875457581037

Epoch: 6| Step: 5
Training loss: 3.5477785816451233
Validation loss: 3.115088851707843

Epoch: 6| Step: 6
Training loss: 3.761300163707862
Validation loss: 3.11656573043695

Epoch: 6| Step: 7
Training loss: 2.9212758475038734
Validation loss: 3.0669972755371373

Epoch: 6| Step: 8
Training loss: 3.4089795296709866
Validation loss: 3.0558464135284455

Epoch: 6| Step: 9
Training loss: 3.0443560237837395
Validation loss: 3.4744424345046556

Epoch: 6| Step: 10
Training loss: 4.111119353369163
Validation loss: 3.1667036341488526

Epoch: 6| Step: 11
Training loss: 3.22527001012064
Validation loss: 3.18113583557083

Epoch: 6| Step: 12
Training loss: 3.177236301095732
Validation loss: 3.340262376654277

Epoch: 6| Step: 13
Training loss: 2.903008242457111
Validation loss: 3.1195577588247363

Epoch: 109| Step: 0
Training loss: 3.1356743657022434
Validation loss: 3.226778655163933

Epoch: 6| Step: 1
Training loss: 3.4409586759356863
Validation loss: 3.2992730073568066

Epoch: 6| Step: 2
Training loss: 3.8165564297632733
Validation loss: 3.3378876649643066

Epoch: 6| Step: 3
Training loss: 3.4018173073273115
Validation loss: 3.24445848392628

Epoch: 6| Step: 4
Training loss: 3.811149608156887
Validation loss: 3.3261443445348697

Epoch: 6| Step: 5
Training loss: 3.2898680364237287
Validation loss: 3.2646160966519977

Epoch: 6| Step: 6
Training loss: 3.204578497868171
Validation loss: 3.2628247909802877

Epoch: 6| Step: 7
Training loss: 3.67332786873505
Validation loss: 3.100439645631251

Epoch: 6| Step: 8
Training loss: 3.6213758043973847
Validation loss: 3.232515659551145

Epoch: 6| Step: 9
Training loss: 3.1126046588261085
Validation loss: 3.187176809669374

Epoch: 6| Step: 10
Training loss: 2.7295880950838063
Validation loss: 3.1545080744807263

Epoch: 6| Step: 11
Training loss: 1.735237113514579
Validation loss: 3.351939582030377

Epoch: 6| Step: 12
Training loss: 2.299646483080292
Validation loss: 3.194753664223493

Epoch: 6| Step: 13
Training loss: 2.9601819526319644
Validation loss: 3.0812430406677507

Epoch: 110| Step: 0
Training loss: 2.773283102546532
Validation loss: 3.1173970261051687

Epoch: 6| Step: 1
Training loss: 3.214477963223547
Validation loss: 3.1394029702043476

Epoch: 6| Step: 2
Training loss: 3.1686396893744644
Validation loss: 3.13059317524981

Epoch: 6| Step: 3
Training loss: 3.78815013480018
Validation loss: 3.315436113162748

Epoch: 6| Step: 4
Training loss: 3.5327357314625236
Validation loss: 3.211461119241651

Epoch: 6| Step: 5
Training loss: 3.294861381983961
Validation loss: 3.1327028825880436

Epoch: 6| Step: 6
Training loss: 4.008249835270171
Validation loss: 3.1428662749646414

Epoch: 6| Step: 7
Training loss: 2.889540350240665
Validation loss: 3.225124825531478

Epoch: 6| Step: 8
Training loss: 3.79111574523253
Validation loss: 3.1249676528405033

Epoch: 6| Step: 9
Training loss: 2.7792337374240996
Validation loss: 3.281842317262933

Epoch: 6| Step: 10
Training loss: 2.1014533599535485
Validation loss: 3.178749134876435

Epoch: 6| Step: 11
Training loss: 3.1754827417749487
Validation loss: 3.188959149248635

Epoch: 6| Step: 12
Training loss: 2.919475855619534
Validation loss: 3.053548720139468

Epoch: 6| Step: 13
Training loss: 2.6894092431571206
Validation loss: 3.1548192491198956

Epoch: 111| Step: 0
Training loss: 3.0172175022176435
Validation loss: 3.104798934664705

Epoch: 6| Step: 1
Training loss: 3.345982171940892
Validation loss: 3.2576721417706778

Epoch: 6| Step: 2
Training loss: 2.9671453054118757
Validation loss: 3.0682044001162905

Epoch: 6| Step: 3
Training loss: 3.075434249361146
Validation loss: 3.1832128394920445

Epoch: 6| Step: 4
Training loss: 2.485709737513598
Validation loss: 3.1861988028082586

Epoch: 6| Step: 5
Training loss: 2.8010127824452846
Validation loss: 3.1968115108488173

Epoch: 6| Step: 6
Training loss: 4.991686967522932
Validation loss: 3.2939118910542193

Epoch: 6| Step: 7
Training loss: 3.033191963366859
Validation loss: 3.0990694515043335

Epoch: 6| Step: 8
Training loss: 3.2916866897424693
Validation loss: 3.2921512200903225

Epoch: 6| Step: 9
Training loss: 3.2501995318857446
Validation loss: 3.10665083795295

Epoch: 6| Step: 10
Training loss: 2.983511435308928
Validation loss: 3.341317633169869

Epoch: 6| Step: 11
Training loss: 3.6246898123786973
Validation loss: 3.1286380756288503

Epoch: 6| Step: 12
Training loss: 2.915471040804643
Validation loss: 3.1200389786976075

Epoch: 6| Step: 13
Training loss: 3.165696614576639
Validation loss: 3.223238007907855

Epoch: 112| Step: 0
Training loss: 3.591016708534863
Validation loss: 3.1827253483838214

Epoch: 6| Step: 1
Training loss: 3.3311749304924687
Validation loss: 3.045074819610147

Epoch: 6| Step: 2
Training loss: 3.89570170025449
Validation loss: 3.1874864156917333

Epoch: 6| Step: 3
Training loss: 3.6628905416844395
Validation loss: 3.10629052523861

Epoch: 6| Step: 4
Training loss: 3.265289581449127
Validation loss: 3.276358350335321

Epoch: 6| Step: 5
Training loss: 2.851366010193092
Validation loss: 3.041396102188094

Epoch: 6| Step: 6
Training loss: 2.1718333947018222
Validation loss: 3.086387213341362

Epoch: 6| Step: 7
Training loss: 3.050228523073107
Validation loss: 3.259809077611207

Epoch: 6| Step: 8
Training loss: 3.0768752296102075
Validation loss: 3.0925928568096066

Epoch: 6| Step: 9
Training loss: 3.02872385376631
Validation loss: 3.15192246696179

Epoch: 6| Step: 10
Training loss: 3.111573328771518
Validation loss: 3.2193865339309657

Epoch: 6| Step: 11
Training loss: 2.4881781492327546
Validation loss: 3.17286152826528

Epoch: 6| Step: 12
Training loss: 4.121407302571116
Validation loss: 3.1050358461320116

Epoch: 6| Step: 13
Training loss: 3.487161522850669
Validation loss: 3.171523937092477

Epoch: 113| Step: 0
Training loss: 2.9156803825000277
Validation loss: 3.0614097250007064

Epoch: 6| Step: 1
Training loss: 2.989096855608234
Validation loss: 3.192588529423554

Epoch: 6| Step: 2
Training loss: 3.02162151358341
Validation loss: 3.1025246153661112

Epoch: 6| Step: 3
Training loss: 3.6163023160122965
Validation loss: 3.1675898647787966

Epoch: 6| Step: 4
Training loss: 3.022193514774835
Validation loss: 3.113695615241448

Epoch: 6| Step: 5
Training loss: 3.7915038748088374
Validation loss: 3.2671454755731815

Epoch: 6| Step: 6
Training loss: 2.0712753647958793
Validation loss: 3.09275605845764

Epoch: 6| Step: 7
Training loss: 2.343556917502481
Validation loss: 3.0774587869407415

Epoch: 6| Step: 8
Training loss: 3.8015627709328665
Validation loss: 3.151924428780126

Epoch: 6| Step: 9
Training loss: 3.8336940816775726
Validation loss: 3.074285405862331

Epoch: 6| Step: 10
Training loss: 3.032605526842076
Validation loss: 3.168106417001839

Epoch: 6| Step: 11
Training loss: 3.9453122582766014
Validation loss: 2.990769228725184

Epoch: 6| Step: 12
Training loss: 3.0051524103648193
Validation loss: 3.209114432422917

Epoch: 6| Step: 13
Training loss: 3.4288811572137363
Validation loss: 3.1608868221721975

Epoch: 114| Step: 0
Training loss: 3.0305662662150943
Validation loss: 3.2061967936588367

Epoch: 6| Step: 1
Training loss: 2.6977779004164866
Validation loss: 3.2147818506217876

Epoch: 6| Step: 2
Training loss: 2.643068886894388
Validation loss: 3.246149591992515

Epoch: 6| Step: 3
Training loss: 4.050388534181879
Validation loss: 3.122542444101559

Epoch: 6| Step: 4
Training loss: 3.9378057694163795
Validation loss: 3.323447609226468

Epoch: 6| Step: 5
Training loss: 3.264139375927216
Validation loss: 3.1014215179998783

Epoch: 6| Step: 6
Training loss: 2.6150493029291986
Validation loss: 3.2033133406633736

Epoch: 6| Step: 7
Training loss: 3.3241289532341387
Validation loss: 3.3543615929755557

Epoch: 6| Step: 8
Training loss: 2.7418350036639505
Validation loss: 3.411914809490882

Epoch: 6| Step: 9
Training loss: 3.5673384351708717
Validation loss: 3.142347503114742

Epoch: 6| Step: 10
Training loss: 2.5107826398797806
Validation loss: 3.218410424251434

Epoch: 6| Step: 11
Training loss: 4.163484400830274
Validation loss: 3.2150226487868867

Epoch: 6| Step: 12
Training loss: 2.6464643752127137
Validation loss: 3.2038794660689076

Epoch: 6| Step: 13
Training loss: 3.5172774436834984
Validation loss: 3.0843792064166085

Epoch: 115| Step: 0
Training loss: 2.6749065668063623
Validation loss: 3.1443759454647355

Epoch: 6| Step: 1
Training loss: 3.1682676651711335
Validation loss: 3.2423199022312836

Epoch: 6| Step: 2
Training loss: 3.6629242582954507
Validation loss: 3.0576996725033103

Epoch: 6| Step: 3
Training loss: 3.2964193743406374
Validation loss: 3.2024514735489626

Epoch: 6| Step: 4
Training loss: 3.401765023030195
Validation loss: 3.2147982494239513

Epoch: 6| Step: 5
Training loss: 2.827487093814229
Validation loss: 3.2814228768227904

Epoch: 6| Step: 6
Training loss: 2.226997199205368
Validation loss: 3.2572417214759164

Epoch: 6| Step: 7
Training loss: 3.2099319702735416
Validation loss: 3.184399291212975

Epoch: 6| Step: 8
Training loss: 2.9314063967888804
Validation loss: 3.2186818771249968

Epoch: 6| Step: 9
Training loss: 2.3332526556327093
Validation loss: 3.163648175177074

Epoch: 6| Step: 10
Training loss: 2.57919233943095
Validation loss: 3.1705809986161166

Epoch: 6| Step: 11
Training loss: 3.6043716695765835
Validation loss: 3.0295247296600083

Epoch: 6| Step: 12
Training loss: 4.256225514166443
Validation loss: 3.132326347938545

Epoch: 6| Step: 13
Training loss: 2.7498531302333227
Validation loss: 3.284821495929724

Epoch: 116| Step: 0
Training loss: 3.3651550248189834
Validation loss: 3.2143591004363996

Epoch: 6| Step: 1
Training loss: 3.207747682565966
Validation loss: 3.157739830850288

Epoch: 6| Step: 2
Training loss: 4.234407882281228
Validation loss: 3.183584753552621

Epoch: 6| Step: 3
Training loss: 2.8494401950828876
Validation loss: 3.035535461730402

Epoch: 6| Step: 4
Training loss: 3.419316698489672
Validation loss: 3.1804726991633383

Epoch: 6| Step: 5
Training loss: 2.743567486299523
Validation loss: 3.017403841094716

Epoch: 6| Step: 6
Training loss: 3.056295532636283
Validation loss: 3.1892775538180946

Epoch: 6| Step: 7
Training loss: 3.1768354141978095
Validation loss: 3.209887229091916

Epoch: 6| Step: 8
Training loss: 3.3146369806660023
Validation loss: 3.095090976328027

Epoch: 6| Step: 9
Training loss: 2.349331833832804
Validation loss: 3.0337751582208976

Epoch: 6| Step: 10
Training loss: 3.3418105731016743
Validation loss: 3.1449330576545727

Epoch: 6| Step: 11
Training loss: 1.9701312835633817
Validation loss: 3.3068664437621127

Epoch: 6| Step: 12
Training loss: 2.549142775717204
Validation loss: 3.139642168118939

Epoch: 6| Step: 13
Training loss: 4.6398390801247755
Validation loss: 3.145113952328856

Epoch: 117| Step: 0
Training loss: 2.4178930218351393
Validation loss: 3.065274272610488

Epoch: 6| Step: 1
Training loss: 3.9589595633935137
Validation loss: 3.0677282287218812

Epoch: 6| Step: 2
Training loss: 2.681415234433926
Validation loss: 3.0385664630412625

Epoch: 6| Step: 3
Training loss: 2.202682558909083
Validation loss: 3.0897928857065846

Epoch: 6| Step: 4
Training loss: 2.9671277884390563
Validation loss: 3.147948747628608

Epoch: 6| Step: 5
Training loss: 4.263352455969171
Validation loss: 3.1976672376529383

Epoch: 6| Step: 6
Training loss: 2.078476496060933
Validation loss: 3.070257746723259

Epoch: 6| Step: 7
Training loss: 3.2732265650266394
Validation loss: 3.279212501108507

Epoch: 6| Step: 8
Training loss: 2.9973546126663533
Validation loss: 3.0312981761862887

Epoch: 6| Step: 9
Training loss: 3.48999541776952
Validation loss: 3.187769970689794

Epoch: 6| Step: 10
Training loss: 2.9942044862828374
Validation loss: 3.251236439803121

Epoch: 6| Step: 11
Training loss: 3.370719172772959
Validation loss: 3.1091403741772807

Epoch: 6| Step: 12
Training loss: 3.161145030820919
Validation loss: 3.129119644957633

Epoch: 6| Step: 13
Training loss: 4.373593785586215
Validation loss: 3.1355171769390084

Epoch: 118| Step: 0
Training loss: 3.7599255495614043
Validation loss: 3.079538554940562

Epoch: 6| Step: 1
Training loss: 3.693416697895984
Validation loss: 2.997736027021174

Epoch: 6| Step: 2
Training loss: 3.337018233256587
Validation loss: 3.165254369982726

Epoch: 6| Step: 3
Training loss: 1.8912294540751595
Validation loss: 3.2060210503093667

Epoch: 6| Step: 4
Training loss: 3.2706310104352796
Validation loss: 3.277739734549391

Epoch: 6| Step: 5
Training loss: 2.8515558112079087
Validation loss: 3.202157285721034

Epoch: 6| Step: 6
Training loss: 2.895505342273398
Validation loss: 3.24467577533325

Epoch: 6| Step: 7
Training loss: 3.7270013642755115
Validation loss: 3.1244644263944723

Epoch: 6| Step: 8
Training loss: 4.036268791752767
Validation loss: 3.1606195955027645

Epoch: 6| Step: 9
Training loss: 2.9052762276772315
Validation loss: 3.333511148345094

Epoch: 6| Step: 10
Training loss: 3.8563658067820503
Validation loss: 3.2260208467793663

Epoch: 6| Step: 11
Training loss: 3.3546960227371216
Validation loss: 3.238861369667812

Epoch: 6| Step: 12
Training loss: 3.2351975431664983
Validation loss: 3.374154804276465

Epoch: 6| Step: 13
Training loss: 2.4848430840362363
Validation loss: 3.155345192901372

Epoch: 119| Step: 0
Training loss: 2.948894235302198
Validation loss: 3.047382439742474

Epoch: 6| Step: 1
Training loss: 3.6914158089327294
Validation loss: 3.000971872560644

Epoch: 6| Step: 2
Training loss: 3.6275261594222146
Validation loss: 3.213767120057525

Epoch: 6| Step: 3
Training loss: 2.961083239992182
Validation loss: 3.2436010093155225

Epoch: 6| Step: 4
Training loss: 2.5412681037794624
Validation loss: 3.2478285951271286

Epoch: 6| Step: 5
Training loss: 2.543601805473079
Validation loss: 2.967784145471028

Epoch: 6| Step: 6
Training loss: 2.081331231992069
Validation loss: 3.124556694171605

Epoch: 6| Step: 7
Training loss: 2.814269378191456
Validation loss: 3.095871743975704

Epoch: 6| Step: 8
Training loss: 3.477205709898423
Validation loss: 3.282427507844066

Epoch: 6| Step: 9
Training loss: 3.007616864071919
Validation loss: 3.129905908978765

Epoch: 6| Step: 10
Training loss: 3.0610394790431474
Validation loss: 3.24853310559579

Epoch: 6| Step: 11
Training loss: 4.274591098437123
Validation loss: 3.0631942045925964

Epoch: 6| Step: 12
Training loss: 2.7217205086977283
Validation loss: 3.198898792851068

Epoch: 6| Step: 13
Training loss: 3.9962303757267734
Validation loss: 3.121144603591303

Epoch: 120| Step: 0
Training loss: 2.2644685095553485
Validation loss: 3.190801361356334

Epoch: 6| Step: 1
Training loss: 2.9396974176933197
Validation loss: 3.2636416987820076

Epoch: 6| Step: 2
Training loss: 3.1977241946937185
Validation loss: 3.3072318458847643

Epoch: 6| Step: 3
Training loss: 2.6106132264861532
Validation loss: 3.104115440230621

Epoch: 6| Step: 4
Training loss: 4.3795530333275465
Validation loss: 2.9826579983979635

Epoch: 6| Step: 5
Training loss: 2.712075821719656
Validation loss: 3.1485273716372952

Epoch: 6| Step: 6
Training loss: 2.363069181148749
Validation loss: 3.276383866468371

Epoch: 6| Step: 7
Training loss: 3.432477298669838
Validation loss: 3.25559167717188

Epoch: 6| Step: 8
Training loss: 4.217507864736156
Validation loss: 3.171646199626701

Epoch: 6| Step: 9
Training loss: 3.8888074926910385
Validation loss: 3.07437314903185

Epoch: 6| Step: 10
Training loss: 2.488408395342392
Validation loss: 3.055558077368965

Epoch: 6| Step: 11
Training loss: 4.1968761634398986
Validation loss: 3.140887402171086

Epoch: 6| Step: 12
Training loss: 2.240046206406452
Validation loss: 3.2344873135488386

Epoch: 6| Step: 13
Training loss: 2.7647160474998556
Validation loss: 3.199467854001569

Epoch: 121| Step: 0
Training loss: 3.0095495187260273
Validation loss: 3.3165998373493917

Epoch: 6| Step: 1
Training loss: 2.474010801595485
Validation loss: 3.2310405416171966

Epoch: 6| Step: 2
Training loss: 2.9417111668089073
Validation loss: 3.1218545108117755

Epoch: 6| Step: 3
Training loss: 3.0693101484360423
Validation loss: 3.193310267121728

Epoch: 6| Step: 4
Training loss: 2.902748541758257
Validation loss: 3.162333198729273

Epoch: 6| Step: 5
Training loss: 3.0612921376441604
Validation loss: 2.9429838596951585

Epoch: 6| Step: 6
Training loss: 3.1180519683598247
Validation loss: 3.333169122978592

Epoch: 6| Step: 7
Training loss: 2.711552267148699
Validation loss: 3.164369577900859

Epoch: 6| Step: 8
Training loss: 3.6570016463299226
Validation loss: 3.1487847537733535

Epoch: 6| Step: 9
Training loss: 2.761593050976052
Validation loss: 3.1078936813695406

Epoch: 6| Step: 10
Training loss: 2.780907942064744
Validation loss: 3.3160705485397273

Epoch: 6| Step: 11
Training loss: 3.097380694415476
Validation loss: 3.0856129523535993

Epoch: 6| Step: 12
Training loss: 3.989343873383203
Validation loss: 3.140106827777756

Epoch: 6| Step: 13
Training loss: 3.860283748495243
Validation loss: 3.222452301403262

Epoch: 122| Step: 0
Training loss: 3.8141527189455773
Validation loss: 3.303847089580409

Epoch: 6| Step: 1
Training loss: 2.981005619037378
Validation loss: 3.147529545432684

Epoch: 6| Step: 2
Training loss: 3.368388021693026
Validation loss: 3.2192089447742207

Epoch: 6| Step: 3
Training loss: 2.9032882858034266
Validation loss: 3.0947675559376093

Epoch: 6| Step: 4
Training loss: 3.8905512178464536
Validation loss: 3.2361404921332086

Epoch: 6| Step: 5
Training loss: 3.0892972402570247
Validation loss: 3.051094588550633

Epoch: 6| Step: 6
Training loss: 2.5746305885882137
Validation loss: 3.143965574876436

Epoch: 6| Step: 7
Training loss: 2.4768840208040928
Validation loss: 3.1902826168466647

Epoch: 6| Step: 8
Training loss: 3.677822539437132
Validation loss: 3.360394124893433

Epoch: 6| Step: 9
Training loss: 3.066211864360249
Validation loss: 3.238172672624146

Epoch: 6| Step: 10
Training loss: 2.8507117269479725
Validation loss: 3.3215057718873378

Epoch: 6| Step: 11
Training loss: 3.4745723214192075
Validation loss: 3.2160273138478224

Epoch: 6| Step: 12
Training loss: 3.653125699633033
Validation loss: 3.1743237503317387

Epoch: 6| Step: 13
Training loss: 1.5663710135970144
Validation loss: 3.0614594179008945

Epoch: 123| Step: 0
Training loss: 3.871026493723894
Validation loss: 3.0661286518348083

Epoch: 6| Step: 1
Training loss: 3.8130218899086277
Validation loss: 3.0915047644112255

Epoch: 6| Step: 2
Training loss: 3.4967545039439143
Validation loss: 3.1150929674037218

Epoch: 6| Step: 3
Training loss: 2.6448817506833184
Validation loss: 3.0849551536486284

Epoch: 6| Step: 4
Training loss: 3.0509497367647094
Validation loss: 3.162346857038324

Epoch: 6| Step: 5
Training loss: 2.341930446044743
Validation loss: 3.1662979936822655

Epoch: 6| Step: 6
Training loss: 3.201008018037907
Validation loss: 3.0047566533375654

Epoch: 6| Step: 7
Training loss: 2.3245194953795103
Validation loss: 3.1871899882922876

Epoch: 6| Step: 8
Training loss: 2.4362244814401866
Validation loss: 3.200696122845419

Epoch: 6| Step: 9
Training loss: 3.789273411494682
Validation loss: 3.1388916332385213

Epoch: 6| Step: 10
Training loss: 3.547520246925132
Validation loss: 3.2940882366832818

Epoch: 6| Step: 11
Training loss: 3.057251929437021
Validation loss: 3.12834642462598

Epoch: 6| Step: 12
Training loss: 3.381045260902967
Validation loss: 3.0612287597230243

Epoch: 6| Step: 13
Training loss: 2.394124181600409
Validation loss: 3.087702925594084

Epoch: 124| Step: 0
Training loss: 3.2368941517123555
Validation loss: 3.0873907249827983

Epoch: 6| Step: 1
Training loss: 2.376226209012712
Validation loss: 3.1080776622013624

Epoch: 6| Step: 2
Training loss: 3.4739008969768554
Validation loss: 3.061018985189089

Epoch: 6| Step: 3
Training loss: 3.6866472195692412
Validation loss: 3.1275965053634636

Epoch: 6| Step: 4
Training loss: 2.669699335207108
Validation loss: 2.9821535061142304

Epoch: 6| Step: 5
Training loss: 3.276744255733192
Validation loss: 3.0352349195559216

Epoch: 6| Step: 6
Training loss: 3.0982642328752186
Validation loss: 3.136894454798799

Epoch: 6| Step: 7
Training loss: 2.9400461403476386
Validation loss: 3.1112397307284287

Epoch: 6| Step: 8
Training loss: 3.1365417962618105
Validation loss: 3.2012183620793873

Epoch: 6| Step: 9
Training loss: 3.4513516252443273
Validation loss: 3.2142146752302883

Epoch: 6| Step: 10
Training loss: 3.8354897169746858
Validation loss: 3.2067586326211464

Epoch: 6| Step: 11
Training loss: 3.3717474629603403
Validation loss: 3.1188424955552057

Epoch: 6| Step: 12
Training loss: 3.2607660238440688
Validation loss: 3.2948409287318388

Epoch: 6| Step: 13
Training loss: 3.4957569833874116
Validation loss: 3.0414485395240214

Epoch: 125| Step: 0
Training loss: 2.898334676147407
Validation loss: 3.1793847870294134

Epoch: 6| Step: 1
Training loss: 2.2735663833004045
Validation loss: 3.168877953775206

Epoch: 6| Step: 2
Training loss: 3.235289218715284
Validation loss: 3.0951504239662673

Epoch: 6| Step: 3
Training loss: 2.5106722964066512
Validation loss: 3.2655649267481395

Epoch: 6| Step: 4
Training loss: 3.4924683596598407
Validation loss: 3.2629523896876784

Epoch: 6| Step: 5
Training loss: 2.713088795267239
Validation loss: 3.2876602678408284

Epoch: 6| Step: 6
Training loss: 2.5259855178937363
Validation loss: 2.982937067431058

Epoch: 6| Step: 7
Training loss: 2.668708843834029
Validation loss: 3.1984992897280295

Epoch: 6| Step: 8
Training loss: 3.149800575846436
Validation loss: 3.2600900388851164

Epoch: 6| Step: 9
Training loss: 3.560918088678444
Validation loss: 3.13325202769206

Epoch: 6| Step: 10
Training loss: 3.001713581244574
Validation loss: 3.149353528392936

Epoch: 6| Step: 11
Training loss: 2.6950288042783312
Validation loss: 3.1513708401177682

Epoch: 6| Step: 12
Training loss: 3.814767132172694
Validation loss: 3.198857863601043

Epoch: 6| Step: 13
Training loss: 3.5088307829154095
Validation loss: 3.162457269265354

Epoch: 126| Step: 0
Training loss: 2.9416370883855856
Validation loss: 3.1242851982103867

Epoch: 6| Step: 1
Training loss: 2.5464246854941623
Validation loss: 3.2122393513565815

Epoch: 6| Step: 2
Training loss: 4.279615103982182
Validation loss: 3.20729907949652

Epoch: 6| Step: 3
Training loss: 2.8286786459546933
Validation loss: 3.0640964277325295

Epoch: 6| Step: 4
Training loss: 3.1861775964926378
Validation loss: 3.176156236179286

Epoch: 6| Step: 5
Training loss: 4.010409400570055
Validation loss: 3.1630628498776256

Epoch: 6| Step: 6
Training loss: 3.923628699939355
Validation loss: 3.2087049342298934

Epoch: 6| Step: 7
Training loss: 2.8303672374323563
Validation loss: 3.2110378528243864

Epoch: 6| Step: 8
Training loss: 2.684606724641658
Validation loss: 3.0474362311080148

Epoch: 6| Step: 9
Training loss: 3.054607263472281
Validation loss: 3.2072100162412447

Epoch: 6| Step: 10
Training loss: 2.51900184451373
Validation loss: 3.0903231950935637

Epoch: 6| Step: 11
Training loss: 3.2848389389524715
Validation loss: 3.2352162458486613

Epoch: 6| Step: 12
Training loss: 3.0587741218866005
Validation loss: 3.269394320470611

Epoch: 6| Step: 13
Training loss: 2.860311886247527
Validation loss: 3.2015253145802585

Epoch: 127| Step: 0
Training loss: 2.803581848680537
Validation loss: 3.0235442278151634

Epoch: 6| Step: 1
Training loss: 3.3904264189759723
Validation loss: 3.0968669736244987

Epoch: 6| Step: 2
Training loss: 2.8916548260566373
Validation loss: 3.1454281305917315

Epoch: 6| Step: 3
Training loss: 2.356229997544927
Validation loss: 3.1640725096525637

Epoch: 6| Step: 4
Training loss: 2.7894109086262437
Validation loss: 3.0288791432077167

Epoch: 6| Step: 5
Training loss: 3.3288076354368505
Validation loss: 3.2600165965004253

Epoch: 6| Step: 6
Training loss: 3.4850022645174
Validation loss: 3.1473422024055377

Epoch: 6| Step: 7
Training loss: 2.5432799071287135
Validation loss: 3.269883282701367

Epoch: 6| Step: 8
Training loss: 3.732223082258373
Validation loss: 3.2455344952317953

Epoch: 6| Step: 9
Training loss: 3.860979742716793
Validation loss: 3.2062064191003277

Epoch: 6| Step: 10
Training loss: 2.9150030750500537
Validation loss: 3.1104973626449497

Epoch: 6| Step: 11
Training loss: 2.6544966352351267
Validation loss: 3.0649240964864797

Epoch: 6| Step: 12
Training loss: 3.2829777119972507
Validation loss: 3.226461526385797

Epoch: 6| Step: 13
Training loss: 2.813968953002704
Validation loss: 3.1066546289672954

Epoch: 128| Step: 0
Training loss: 2.9367486520408366
Validation loss: 3.013882413606124

Epoch: 6| Step: 1
Training loss: 2.1081774667815116
Validation loss: 3.085551471483307

Epoch: 6| Step: 2
Training loss: 2.937982722450388
Validation loss: 3.0872351600715384

Epoch: 6| Step: 3
Training loss: 3.13854532040091
Validation loss: 3.1802458103523983

Epoch: 6| Step: 4
Training loss: 3.6740866635504528
Validation loss: 3.1840746347973266

Epoch: 6| Step: 5
Training loss: 2.9393165328521276
Validation loss: 3.21812501871624

Epoch: 6| Step: 6
Training loss: 2.3008979288511906
Validation loss: 3.1710347411844206

Epoch: 6| Step: 7
Training loss: 2.4776235527695247
Validation loss: 3.2493024823757453

Epoch: 6| Step: 8
Training loss: 2.7285322272110326
Validation loss: 3.132351366102455

Epoch: 6| Step: 9
Training loss: 2.866742258036329
Validation loss: 3.0852834863913285

Epoch: 6| Step: 10
Training loss: 4.339438954315687
Validation loss: 3.095133773905492

Epoch: 6| Step: 11
Training loss: 3.482974331134988
Validation loss: 3.126932435131452

Epoch: 6| Step: 12
Training loss: 4.252111471414176
Validation loss: 3.220493496363036

Epoch: 6| Step: 13
Training loss: 4.70881688608453
Validation loss: 3.1677464849914174

Epoch: 129| Step: 0
Training loss: 3.8668967397796083
Validation loss: 3.094967889615385

Epoch: 6| Step: 1
Training loss: 3.7460451252220914
Validation loss: 3.1238047014016965

Epoch: 6| Step: 2
Training loss: 3.5467868071359234
Validation loss: 3.2301870829051036

Epoch: 6| Step: 3
Training loss: 3.7247749055787254
Validation loss: 3.141057125494685

Epoch: 6| Step: 4
Training loss: 3.3956225433144125
Validation loss: 3.117503642360594

Epoch: 6| Step: 5
Training loss: 2.6093983906137255
Validation loss: 3.0685041384885983

Epoch: 6| Step: 6
Training loss: 2.6678820661590543
Validation loss: 3.119807749887949

Epoch: 6| Step: 7
Training loss: 2.485126213844394
Validation loss: 3.0208847721856107

Epoch: 6| Step: 8
Training loss: 2.9543690155272118
Validation loss: 3.2513931923131585

Epoch: 6| Step: 9
Training loss: 3.0654842861595957
Validation loss: 3.140908929778219

Epoch: 6| Step: 10
Training loss: 2.4111427007188895
Validation loss: 3.1576907438281854

Epoch: 6| Step: 11
Training loss: 3.144936254731673
Validation loss: 3.2385567352564237

Epoch: 6| Step: 12
Training loss: 3.4435396715241064
Validation loss: 2.974808789729382

Epoch: 6| Step: 13
Training loss: 2.279814072272579
Validation loss: 3.1972191590281995

Epoch: 130| Step: 0
Training loss: 2.795298211800578
Validation loss: 3.2705959555022837

Epoch: 6| Step: 1
Training loss: 3.344048317409592
Validation loss: 3.0823095185559053

Epoch: 6| Step: 2
Training loss: 3.737503592703123
Validation loss: 3.1156337847555826

Epoch: 6| Step: 3
Training loss: 3.439335558396702
Validation loss: 3.0801283057514577

Epoch: 6| Step: 4
Training loss: 2.2062131192418035
Validation loss: 3.0554046070280645

Epoch: 6| Step: 5
Training loss: 2.7465378902702997
Validation loss: 3.0330972044674342

Epoch: 6| Step: 6
Training loss: 4.267828403702199
Validation loss: 3.024605992894789

Epoch: 6| Step: 7
Training loss: 3.201006677355441
Validation loss: 2.902784758853134

Epoch: 6| Step: 8
Training loss: 1.8960317431017892
Validation loss: 3.0387562104651673

Epoch: 6| Step: 9
Training loss: 3.128601592777605
Validation loss: 3.128388224762589

Epoch: 6| Step: 10
Training loss: 2.8020277242330427
Validation loss: 3.1545233351572795

Epoch: 6| Step: 11
Training loss: 4.26954777915945
Validation loss: 3.050654610745704

Epoch: 6| Step: 12
Training loss: 2.761752073095018
Validation loss: 3.0757664506714195

Epoch: 6| Step: 13
Training loss: 2.9748001287942714
Validation loss: 3.245270405846789

Epoch: 131| Step: 0
Training loss: 3.890866804460321
Validation loss: 3.1828746771478253

Epoch: 6| Step: 1
Training loss: 2.9255346543171967
Validation loss: 3.2633977761548048

Epoch: 6| Step: 2
Training loss: 3.0247522299944576
Validation loss: 3.1828851576223687

Epoch: 6| Step: 3
Training loss: 3.194392064720136
Validation loss: 3.248194918157663

Epoch: 6| Step: 4
Training loss: 3.1894543210346806
Validation loss: 3.181347332352746

Epoch: 6| Step: 5
Training loss: 2.731228134801012
Validation loss: 3.153127097792134

Epoch: 6| Step: 6
Training loss: 2.4641434389511154
Validation loss: 2.9645199097118695

Epoch: 6| Step: 7
Training loss: 2.6766094179155497
Validation loss: 3.2465780794794163

Epoch: 6| Step: 8
Training loss: 3.669334539217344
Validation loss: 3.2594952419290393

Epoch: 6| Step: 9
Training loss: 2.78123096931033
Validation loss: 3.08730353114375

Epoch: 6| Step: 10
Training loss: 3.6639917037403515
Validation loss: 3.079163769944266

Epoch: 6| Step: 11
Training loss: 2.8101892091304603
Validation loss: 3.206287855991348

Epoch: 6| Step: 12
Training loss: 3.132958006868706
Validation loss: 3.1300407019300818

Epoch: 6| Step: 13
Training loss: 1.8654737708365012
Validation loss: 3.1752953097224252

Epoch: 132| Step: 0
Training loss: 2.8825704995075747
Validation loss: 3.1776113269431154

Epoch: 6| Step: 1
Training loss: 3.8053051958235646
Validation loss: 3.1685672637337534

Epoch: 6| Step: 2
Training loss: 3.5383756867969134
Validation loss: 3.1516437022855013

Epoch: 6| Step: 3
Training loss: 2.538591170946836
Validation loss: 2.909714451782409

Epoch: 6| Step: 4
Training loss: 3.476349899134985
Validation loss: 3.159060816682303

Epoch: 6| Step: 5
Training loss: 2.975134960286909
Validation loss: 3.14114681654152

Epoch: 6| Step: 6
Training loss: 2.6683538781669154
Validation loss: 3.1765647175753613

Epoch: 6| Step: 7
Training loss: 3.668322333862877
Validation loss: 3.1165835261929073

Epoch: 6| Step: 8
Training loss: 3.352394125317004
Validation loss: 3.1078486046273843

Epoch: 6| Step: 9
Training loss: 3.5293809113369403
Validation loss: 3.211782296955769

Epoch: 6| Step: 10
Training loss: 2.573229586662696
Validation loss: 3.0529607524962636

Epoch: 6| Step: 11
Training loss: 3.697819510602918
Validation loss: 3.162392689929792

Epoch: 6| Step: 12
Training loss: 2.4675240671825764
Validation loss: 3.05996764228603

Epoch: 6| Step: 13
Training loss: 2.7723942903500887
Validation loss: 3.1417461286531374

Epoch: 133| Step: 0
Training loss: 3.2381363526840894
Validation loss: 3.020167775963613

Epoch: 6| Step: 1
Training loss: 2.6764912129811456
Validation loss: 3.224388366758908

Epoch: 6| Step: 2
Training loss: 2.141932401486242
Validation loss: 2.9178580181716955

Epoch: 6| Step: 3
Training loss: 3.1638836091886624
Validation loss: 3.1927056011018364

Epoch: 6| Step: 4
Training loss: 3.8721661203468547
Validation loss: 3.1690308052621456

Epoch: 6| Step: 5
Training loss: 3.3720017290031734
Validation loss: 3.2324962956736485

Epoch: 6| Step: 6
Training loss: 3.161513066747601
Validation loss: 3.11495970201325

Epoch: 6| Step: 7
Training loss: 3.5907227080408255
Validation loss: 3.0386022981732563

Epoch: 6| Step: 8
Training loss: 2.2868653255986757
Validation loss: 3.239507675804194

Epoch: 6| Step: 9
Training loss: 3.3022971740860276
Validation loss: 2.9775644634105634

Epoch: 6| Step: 10
Training loss: 2.750006415619736
Validation loss: 3.1709013658505216

Epoch: 6| Step: 11
Training loss: 2.2146486872602162
Validation loss: 3.198980237864096

Epoch: 6| Step: 12
Training loss: 2.856745109801623
Validation loss: 3.1422765033573294

Epoch: 6| Step: 13
Training loss: 3.1452814759166055
Validation loss: 3.210942373483387

Epoch: 134| Step: 0
Training loss: 2.356774419005531
Validation loss: 3.1208308270350957

Epoch: 6| Step: 1
Training loss: 4.012772909135039
Validation loss: 3.1423988693695204

Epoch: 6| Step: 2
Training loss: 2.846633957876692
Validation loss: 3.0471035880265696

Epoch: 6| Step: 3
Training loss: 2.8263986281701783
Validation loss: 3.214354696313262

Epoch: 6| Step: 4
Training loss: 3.9584376405056543
Validation loss: 3.0524169247908923

Epoch: 6| Step: 5
Training loss: 3.4065322059129097
Validation loss: 3.244899876668502

Epoch: 6| Step: 6
Training loss: 3.991449157161662
Validation loss: 3.2805663787893966

Epoch: 6| Step: 7
Training loss: 3.3801038791561893
Validation loss: 3.1079735881580457

Epoch: 6| Step: 8
Training loss: 3.009202195194351
Validation loss: 3.1575693991105616

Epoch: 6| Step: 9
Training loss: 2.7300711630185144
Validation loss: 3.116523766796467

Epoch: 6| Step: 10
Training loss: 3.1543331557511016
Validation loss: 3.035059184803407

Epoch: 6| Step: 11
Training loss: 3.2713730158285843
Validation loss: 3.203688338729572

Epoch: 6| Step: 12
Training loss: 2.937502272584726
Validation loss: 3.220596761751892

Epoch: 6| Step: 13
Training loss: 2.691983231706245
Validation loss: 3.048543145573445

Epoch: 135| Step: 0
Training loss: 2.708121032218923
Validation loss: 3.0096158802264914

Epoch: 6| Step: 1
Training loss: 2.653507387532297
Validation loss: 3.207717183247217

Epoch: 6| Step: 2
Training loss: 2.9639648421412184
Validation loss: 3.1702510471841285

Epoch: 6| Step: 3
Training loss: 2.8771642748592523
Validation loss: 3.0631891211518805

Epoch: 6| Step: 4
Training loss: 4.09468266003921
Validation loss: 3.1301281320035566

Epoch: 6| Step: 5
Training loss: 3.5623176929607294
Validation loss: 3.152525099327124

Epoch: 6| Step: 6
Training loss: 2.9914275715811045
Validation loss: 3.0677012177381044

Epoch: 6| Step: 7
Training loss: 3.7971462576714683
Validation loss: 3.1277005166082237

Epoch: 6| Step: 8
Training loss: 2.9101215130057687
Validation loss: 3.181993700981396

Epoch: 6| Step: 9
Training loss: 3.289756574814192
Validation loss: 3.0054321603807033

Epoch: 6| Step: 10
Training loss: 3.1941033572849586
Validation loss: 3.2462043874156907

Epoch: 6| Step: 11
Training loss: 3.165198152916971
Validation loss: 3.2224963462538585

Epoch: 6| Step: 12
Training loss: 3.1555850395502727
Validation loss: 3.1327576852268026

Epoch: 6| Step: 13
Training loss: 1.9773923315548296
Validation loss: 3.0948523642236263

Epoch: 136| Step: 0
Training loss: 3.677477130209363
Validation loss: 3.1102078087691893

Epoch: 6| Step: 1
Training loss: 2.094328159957115
Validation loss: 3.225973091179522

Epoch: 6| Step: 2
Training loss: 2.6513608928907786
Validation loss: 3.090415550615236

Epoch: 6| Step: 3
Training loss: 3.97663948269357
Validation loss: 3.096273619988911

Epoch: 6| Step: 4
Training loss: 3.430770390244887
Validation loss: 3.0498493259572004

Epoch: 6| Step: 5
Training loss: 3.082462565866892
Validation loss: 3.164704766432323

Epoch: 6| Step: 6
Training loss: 3.1823755098193622
Validation loss: 2.925505010752845

Epoch: 6| Step: 7
Training loss: 2.5956726302055584
Validation loss: 3.193841248842978

Epoch: 6| Step: 8
Training loss: 2.7090419331371756
Validation loss: 3.19798631035437

Epoch: 6| Step: 9
Training loss: 3.6432095632327903
Validation loss: 3.00248915028642

Epoch: 6| Step: 10
Training loss: 3.177754482400275
Validation loss: 3.200338085770524

Epoch: 6| Step: 11
Training loss: 2.936456048393285
Validation loss: 3.2814425894866712

Epoch: 6| Step: 12
Training loss: 2.7361981226925027
Validation loss: 2.972399124198339

Epoch: 6| Step: 13
Training loss: 3.4367648639086967
Validation loss: 3.0954139223206774

Epoch: 137| Step: 0
Training loss: 4.0443026935856015
Validation loss: 3.2096485983909386

Epoch: 6| Step: 1
Training loss: 3.0496933642226542
Validation loss: 3.1490580028419717

Epoch: 6| Step: 2
Training loss: 3.058495063212752
Validation loss: 3.2659367976098608

Epoch: 6| Step: 3
Training loss: 3.7819566302866483
Validation loss: 3.1434149290602877

Epoch: 6| Step: 4
Training loss: 3.8455625152843322
Validation loss: 2.9967329632738804

Epoch: 6| Step: 5
Training loss: 3.4039206283227137
Validation loss: 3.2166090408966355

Epoch: 6| Step: 6
Training loss: 2.6621059717169184
Validation loss: 3.0417645233995634

Epoch: 6| Step: 7
Training loss: 2.91479172160456
Validation loss: 3.133162634311922

Epoch: 6| Step: 8
Training loss: 2.15731519842522
Validation loss: 3.109750371420731

Epoch: 6| Step: 9
Training loss: 3.1164399974083072
Validation loss: 3.145880345872908

Epoch: 6| Step: 10
Training loss: 3.098461532307203
Validation loss: 3.0052699857612164

Epoch: 6| Step: 11
Training loss: 2.845414062564351
Validation loss: 3.1956544459408343

Epoch: 6| Step: 12
Training loss: 3.1269387906643655
Validation loss: 3.0946720630683195

Epoch: 6| Step: 13
Training loss: 3.0680745051462517
Validation loss: 3.0949956665560054

Epoch: 138| Step: 0
Training loss: 3.610111574261006
Validation loss: 3.1495431285808873

Epoch: 6| Step: 1
Training loss: 2.939376069639945
Validation loss: 3.1339557689145843

Epoch: 6| Step: 2
Training loss: 3.142678419827848
Validation loss: 3.1599211329588255

Epoch: 6| Step: 3
Training loss: 2.8794642079840194
Validation loss: 3.1194153695261613

Epoch: 6| Step: 4
Training loss: 3.4493840870268397
Validation loss: 3.088225115720827

Epoch: 6| Step: 5
Training loss: 2.4686057133097714
Validation loss: 3.008597244450387

Epoch: 6| Step: 6
Training loss: 2.711227005772673
Validation loss: 3.1458564246219214

Epoch: 6| Step: 7
Training loss: 3.517599543157309
Validation loss: 3.1238716139192553

Epoch: 6| Step: 8
Training loss: 2.747535034317311
Validation loss: 2.9608331061718767

Epoch: 6| Step: 9
Training loss: 2.4927656405968914
Validation loss: 3.089355597788602

Epoch: 6| Step: 10
Training loss: 3.7958513300636905
Validation loss: 3.015815647650533

Epoch: 6| Step: 11
Training loss: 2.9466871701328405
Validation loss: 3.236342126921961

Epoch: 6| Step: 12
Training loss: 3.0037883045867217
Validation loss: 3.2375729297540676

Epoch: 6| Step: 13
Training loss: 3.7903181060314277
Validation loss: 3.217443191546696

Epoch: 139| Step: 0
Training loss: 2.5687157213286045
Validation loss: 3.0898552969010558

Epoch: 6| Step: 1
Training loss: 3.1405442260679393
Validation loss: 3.0791371623366386

Epoch: 6| Step: 2
Training loss: 2.5495499681273217
Validation loss: 3.1934254113417433

Epoch: 6| Step: 3
Training loss: 3.48987477162589
Validation loss: 3.1984630542958237

Epoch: 6| Step: 4
Training loss: 3.349066100257874
Validation loss: 3.109531564574285

Epoch: 6| Step: 5
Training loss: 3.5273653792249378
Validation loss: 3.1744357972596786

Epoch: 6| Step: 6
Training loss: 2.2794016836041173
Validation loss: 3.050715610009711

Epoch: 6| Step: 7
Training loss: 3.9053893094759884
Validation loss: 3.29617245942478

Epoch: 6| Step: 8
Training loss: 2.741385579024465
Validation loss: 3.169748859898893

Epoch: 6| Step: 9
Training loss: 3.1392634083020337
Validation loss: 3.1707536998797887

Epoch: 6| Step: 10
Training loss: 3.263045464879639
Validation loss: 3.108352745385045

Epoch: 6| Step: 11
Training loss: 2.8929618668480765
Validation loss: 3.2427546068810176

Epoch: 6| Step: 12
Training loss: 3.150922149829651
Validation loss: 3.1548992553407342

Epoch: 6| Step: 13
Training loss: 4.238984136704273
Validation loss: 3.212806872271678

Epoch: 140| Step: 0
Training loss: 3.2251538025605693
Validation loss: 3.0678531721105955

Epoch: 6| Step: 1
Training loss: 1.9370309200349665
Validation loss: 3.149993276776081

Epoch: 6| Step: 2
Training loss: 3.7620427357559745
Validation loss: 3.148765246241178

Epoch: 6| Step: 3
Training loss: 3.1965708598185056
Validation loss: 3.076913153133055

Epoch: 6| Step: 4
Training loss: 2.437426834964624
Validation loss: 3.108755213893853

Epoch: 6| Step: 5
Training loss: 2.5272727142680775
Validation loss: 3.1155440504314282

Epoch: 6| Step: 6
Training loss: 3.2209358570779014
Validation loss: 3.1385058985704886

Epoch: 6| Step: 7
Training loss: 3.63847988602967
Validation loss: 3.067252425548476

Epoch: 6| Step: 8
Training loss: 2.6161466891782075
Validation loss: 3.145464293580168

Epoch: 6| Step: 9
Training loss: 2.8022259719639346
Validation loss: 3.075783285588075

Epoch: 6| Step: 10
Training loss: 3.278020813834564
Validation loss: 3.0731715932770407

Epoch: 6| Step: 11
Training loss: 3.0979311653897614
Validation loss: 3.0247382563405596

Epoch: 6| Step: 12
Training loss: 3.3612742178637824
Validation loss: 3.0600096149361886

Epoch: 6| Step: 13
Training loss: 2.851838900613299
Validation loss: 3.1681043786192884

Epoch: 141| Step: 0
Training loss: 2.5814499193410034
Validation loss: 3.2544139645249834

Epoch: 6| Step: 1
Training loss: 2.9366684406230417
Validation loss: 3.1305692747629004

Epoch: 6| Step: 2
Training loss: 3.331785812372087
Validation loss: 3.1550128046704233

Epoch: 6| Step: 3
Training loss: 2.895738357706287
Validation loss: 3.2278876310401468

Epoch: 6| Step: 4
Training loss: 2.400181238960591
Validation loss: 3.281033954061005

Epoch: 6| Step: 5
Training loss: 3.75982104768404
Validation loss: 3.074036507236186

Epoch: 6| Step: 6
Training loss: 3.524388491568708
Validation loss: 3.357883054344314

Epoch: 6| Step: 7
Training loss: 2.469353324468666
Validation loss: 3.110920594122593

Epoch: 6| Step: 8
Training loss: 3.4121268435174623
Validation loss: 3.0857543691594373

Epoch: 6| Step: 9
Training loss: 2.5023413185014918
Validation loss: 3.037878092353879

Epoch: 6| Step: 10
Training loss: 4.04846372312462
Validation loss: 3.120711592165786

Epoch: 6| Step: 11
Training loss: 3.196873365235866
Validation loss: 3.046544027429183

Epoch: 6| Step: 12
Training loss: 2.9722431712932433
Validation loss: 3.144964570160992

Epoch: 6| Step: 13
Training loss: 2.7462863990201596
Validation loss: 3.13375117117341

Epoch: 142| Step: 0
Training loss: 2.1156296294709667
Validation loss: 3.062119196374395

Epoch: 6| Step: 1
Training loss: 3.1235589328688027
Validation loss: 3.0700429325081977

Epoch: 6| Step: 2
Training loss: 3.49238029476903
Validation loss: 3.2004454443059025

Epoch: 6| Step: 3
Training loss: 2.3113915132202236
Validation loss: 3.1360775844428996

Epoch: 6| Step: 4
Training loss: 3.2198893188030233
Validation loss: 3.2133074746384738

Epoch: 6| Step: 5
Training loss: 2.695819309518491
Validation loss: 3.1750745927172708

Epoch: 6| Step: 6
Training loss: 2.687402058080879
Validation loss: 2.9450551848670763

Epoch: 6| Step: 7
Training loss: 3.32506653568554
Validation loss: 3.113464406899368

Epoch: 6| Step: 8
Training loss: 3.2823586180571707
Validation loss: 3.232653699953245

Epoch: 6| Step: 9
Training loss: 3.448235135002346
Validation loss: 3.084467316561387

Epoch: 6| Step: 10
Training loss: 3.621464945873011
Validation loss: 3.2381524273716864

Epoch: 6| Step: 11
Training loss: 2.350211024447812
Validation loss: 3.354947987344266

Epoch: 6| Step: 12
Training loss: 2.937782923283049
Validation loss: 2.9336695031211883

Epoch: 6| Step: 13
Training loss: 3.067155063824924
Validation loss: 3.0207273120259512

Epoch: 143| Step: 0
Training loss: 3.268463944998234
Validation loss: 3.1810842196084774

Epoch: 6| Step: 1
Training loss: 3.055025282035642
Validation loss: 2.97367805643075

Epoch: 6| Step: 2
Training loss: 2.697030313380164
Validation loss: 3.1966228416414224

Epoch: 6| Step: 3
Training loss: 2.2667130587075057
Validation loss: 3.173179042783123

Epoch: 6| Step: 4
Training loss: 2.0182563107213616
Validation loss: 3.0051184541075537

Epoch: 6| Step: 5
Training loss: 3.7053384724604586
Validation loss: 3.097228436419576

Epoch: 6| Step: 6
Training loss: 3.105517577741137
Validation loss: 3.1027407270209517

Epoch: 6| Step: 7
Training loss: 2.8214533392593393
Validation loss: 3.1604886407680666

Epoch: 6| Step: 8
Training loss: 3.9581235863511264
Validation loss: 3.251242919004035

Epoch: 6| Step: 9
Training loss: 3.56372076166389
Validation loss: 3.11479433202182

Epoch: 6| Step: 10
Training loss: 2.9051757796086632
Validation loss: 3.104438712556998

Epoch: 6| Step: 11
Training loss: 1.9872868117669629
Validation loss: 2.9833430901956377

Epoch: 6| Step: 12
Training loss: 3.619099385684836
Validation loss: 3.2586624430813727

Epoch: 6| Step: 13
Training loss: 2.7857768048268037
Validation loss: 3.2110938916934115

Epoch: 144| Step: 0
Training loss: 3.0161847005289775
Validation loss: 3.00955544067948

Epoch: 6| Step: 1
Training loss: 3.306621012936523
Validation loss: 3.3017954373644374

Epoch: 6| Step: 2
Training loss: 2.6140183120704883
Validation loss: 2.9347437676432597

Epoch: 6| Step: 3
Training loss: 3.547544441401785
Validation loss: 3.0828036746062737

Epoch: 6| Step: 4
Training loss: 3.1752086841155975
Validation loss: 3.071258293206535

Epoch: 6| Step: 5
Training loss: 3.7264223852147764
Validation loss: 3.2967631236432466

Epoch: 6| Step: 6
Training loss: 3.4164696768441263
Validation loss: 3.1157200031053973

Epoch: 6| Step: 7
Training loss: 2.3168535234944425
Validation loss: 3.169834059244829

Epoch: 6| Step: 8
Training loss: 3.265021163381129
Validation loss: 3.1586022202948407

Epoch: 6| Step: 9
Training loss: 3.5410684117687095
Validation loss: 3.150023714839945

Epoch: 6| Step: 10
Training loss: 2.896163665446202
Validation loss: 3.2458679303106175

Epoch: 6| Step: 11
Training loss: 1.829061545419501
Validation loss: 3.0956417368663174

Epoch: 6| Step: 12
Training loss: 3.003571609489289
Validation loss: 3.1278668418381477

Epoch: 6| Step: 13
Training loss: 2.1504198950664626
Validation loss: 3.1012426262900243

Epoch: 145| Step: 0
Training loss: 2.1418120719541673
Validation loss: 3.1243043892378477

Epoch: 6| Step: 1
Training loss: 3.5541406902572916
Validation loss: 3.041907553097134

Epoch: 6| Step: 2
Training loss: 3.14184273412773
Validation loss: 3.2158997505537528

Epoch: 6| Step: 3
Training loss: 2.958751022151743
Validation loss: 3.1481025973869143

Epoch: 6| Step: 4
Training loss: 3.220588529362897
Validation loss: 3.015714383605808

Epoch: 6| Step: 5
Training loss: 3.3187105510543833
Validation loss: 3.0223234366387164

Epoch: 6| Step: 6
Training loss: 2.327980805098326
Validation loss: 3.245515464167725

Epoch: 6| Step: 7
Training loss: 2.989810965951122
Validation loss: 3.1557072014641627

Epoch: 6| Step: 8
Training loss: 3.3013434478695207
Validation loss: 3.1808377170161526

Epoch: 6| Step: 9
Training loss: 2.4422541496373587
Validation loss: 3.0293579421226013

Epoch: 6| Step: 10
Training loss: 3.2333364984818007
Validation loss: 3.104537740726076

Epoch: 6| Step: 11
Training loss: 1.9962388674545637
Validation loss: 3.0920407696903793

Epoch: 6| Step: 12
Training loss: 3.9535812898641614
Validation loss: 3.0089628724013506

Epoch: 6| Step: 13
Training loss: 2.872781312080858
Validation loss: 3.104698719170958

Epoch: 146| Step: 0
Training loss: 3.045475251892173
Validation loss: 3.0535357203481643

Epoch: 6| Step: 1
Training loss: 2.734250485446256
Validation loss: 3.107252844893102

Epoch: 6| Step: 2
Training loss: 3.4911852599580198
Validation loss: 3.061073382795838

Epoch: 6| Step: 3
Training loss: 2.6640164100038453
Validation loss: 3.092220422568793

Epoch: 6| Step: 4
Training loss: 3.2427658852039682
Validation loss: 2.9505239928592046

Epoch: 6| Step: 5
Training loss: 2.6722343158602473
Validation loss: 3.029464187180679

Epoch: 6| Step: 6
Training loss: 4.333037415206237
Validation loss: 3.1444800685905028

Epoch: 6| Step: 7
Training loss: 2.720098314612177
Validation loss: 3.02884103638691

Epoch: 6| Step: 8
Training loss: 2.414799747417867
Validation loss: 3.2320023840008374

Epoch: 6| Step: 9
Training loss: 2.6865481088130165
Validation loss: 3.1002459823435626

Epoch: 6| Step: 10
Training loss: 3.1658485928621487
Validation loss: 3.1312604513999514

Epoch: 6| Step: 11
Training loss: 3.8030465913336498
Validation loss: 3.1569854844341845

Epoch: 6| Step: 12
Training loss: 2.3401910845668943
Validation loss: 3.2368818249024702

Epoch: 6| Step: 13
Training loss: 2.164259147660844
Validation loss: 3.0649728407714827

Epoch: 147| Step: 0
Training loss: 3.054364980076637
Validation loss: 2.9589772376534142

Epoch: 6| Step: 1
Training loss: 3.169055305535234
Validation loss: 3.1672855419027224

Epoch: 6| Step: 2
Training loss: 2.7118085621583634
Validation loss: 3.115924038100936

Epoch: 6| Step: 3
Training loss: 2.6380369607043948
Validation loss: 3.1365426675527783

Epoch: 6| Step: 4
Training loss: 2.765179959281919
Validation loss: 3.0871159372154877

Epoch: 6| Step: 5
Training loss: 2.809696325950774
Validation loss: 3.1929295603110748

Epoch: 6| Step: 6
Training loss: 3.434715252752792
Validation loss: 3.1886311598410324

Epoch: 6| Step: 7
Training loss: 3.201329616642449
Validation loss: 2.9945594341587696

Epoch: 6| Step: 8
Training loss: 3.3059737495723294
Validation loss: 3.0545645577524505

Epoch: 6| Step: 9
Training loss: 1.8143056228519445
Validation loss: 3.0090767743151567

Epoch: 6| Step: 10
Training loss: 2.7160109830586503
Validation loss: 3.011676913860724

Epoch: 6| Step: 11
Training loss: 4.085770379290197
Validation loss: 3.159106810047861

Epoch: 6| Step: 12
Training loss: 2.791388644897735
Validation loss: 3.193744511287842

Epoch: 6| Step: 13
Training loss: 3.3410138495351442
Validation loss: 3.018596559106474

Epoch: 148| Step: 0
Training loss: 2.610445362693436
Validation loss: 3.102005348940711

Epoch: 6| Step: 1
Training loss: 2.996314646151207
Validation loss: 3.0450819542614775

Epoch: 6| Step: 2
Training loss: 2.807300423706966
Validation loss: 3.0459729630796732

Epoch: 6| Step: 3
Training loss: 2.2576232619657226
Validation loss: 3.007195534173699

Epoch: 6| Step: 4
Training loss: 4.0368452645526816
Validation loss: 3.097237330267622

Epoch: 6| Step: 5
Training loss: 3.6391064010206158
Validation loss: 3.063231256377177

Epoch: 6| Step: 6
Training loss: 2.3689789996007384
Validation loss: 3.135030098293854

Epoch: 6| Step: 7
Training loss: 3.0337765575955022
Validation loss: 3.1041071243890768

Epoch: 6| Step: 8
Training loss: 2.711206692129449
Validation loss: 3.345128422838485

Epoch: 6| Step: 9
Training loss: 3.8766685093104236
Validation loss: 3.050731806694279

Epoch: 6| Step: 10
Training loss: 2.8898276389179007
Validation loss: 3.2562671985211007

Epoch: 6| Step: 11
Training loss: 3.811942012790136
Validation loss: 3.1026028938323003

Epoch: 6| Step: 12
Training loss: 1.872386000337279
Validation loss: 3.248113808991023

Epoch: 6| Step: 13
Training loss: 3.2309723430407358
Validation loss: 3.1642042591379194

Epoch: 149| Step: 0
Training loss: 3.327604154565994
Validation loss: 3.1206670217811703

Epoch: 6| Step: 1
Training loss: 2.7428051722944673
Validation loss: 3.0209060479147665

Epoch: 6| Step: 2
Training loss: 2.963673960186099
Validation loss: 3.170705622870473

Epoch: 6| Step: 3
Training loss: 3.3349646550125693
Validation loss: 3.1351731178202376

Epoch: 6| Step: 4
Training loss: 2.6608740556537565
Validation loss: 3.093768790444771

Epoch: 6| Step: 5
Training loss: 2.6101036653356946
Validation loss: 3.0473985430968624

Epoch: 6| Step: 6
Training loss: 3.6664664184913525
Validation loss: 3.1069083143890213

Epoch: 6| Step: 7
Training loss: 2.3985761670711945
Validation loss: 3.0822884890938878

Epoch: 6| Step: 8
Training loss: 2.9207183670150303
Validation loss: 3.1755106653442606

Epoch: 6| Step: 9
Training loss: 3.2644400020863733
Validation loss: 3.12861229439251

Epoch: 6| Step: 10
Training loss: 3.6853308035661962
Validation loss: 3.1786185415342247

Epoch: 6| Step: 11
Training loss: 4.031840199876338
Validation loss: 3.3054052790513397

Epoch: 6| Step: 12
Training loss: 2.7248606794946877
Validation loss: 3.0529700079065174

Epoch: 6| Step: 13
Training loss: 1.861636541538914
Validation loss: 3.0259409467598615

Epoch: 150| Step: 0
Training loss: 2.4777912737769157
Validation loss: 3.1464420966377227

Epoch: 6| Step: 1
Training loss: 3.6057882611677297
Validation loss: 3.0431811638352504

Epoch: 6| Step: 2
Training loss: 3.9322512323519585
Validation loss: 3.1231744549027303

Epoch: 6| Step: 3
Training loss: 3.0224678791317703
Validation loss: 3.1327980484495015

Epoch: 6| Step: 4
Training loss: 3.356998046256262
Validation loss: 3.1011908949601263

Epoch: 6| Step: 5
Training loss: 3.0750408697126015
Validation loss: 3.1796364845782463

Epoch: 6| Step: 6
Training loss: 3.062544219028659
Validation loss: 2.9595849698163468

Epoch: 6| Step: 7
Training loss: 3.473281512273512
Validation loss: 3.0346742729482084

Epoch: 6| Step: 8
Training loss: 3.2361454195560606
Validation loss: 3.1195345166987183

Epoch: 6| Step: 9
Training loss: 2.929265269052889
Validation loss: 3.162875122756456

Epoch: 6| Step: 10
Training loss: 3.3812771103313297
Validation loss: 3.0690161047110482

Epoch: 6| Step: 11
Training loss: 2.5774832186813996
Validation loss: 3.163272211149154

Epoch: 6| Step: 12
Training loss: 3.1128125382350538
Validation loss: 3.0864552069963076

Epoch: 6| Step: 13
Training loss: 2.948172154942072
Validation loss: 3.01894120197017

Epoch: 151| Step: 0
Training loss: 3.242873668448495
Validation loss: 3.1418608909775196

Epoch: 6| Step: 1
Training loss: 2.6078984085844046
Validation loss: 3.1423762856816966

Epoch: 6| Step: 2
Training loss: 3.6343046015893865
Validation loss: 3.089373009237214

Epoch: 6| Step: 3
Training loss: 3.126912866698996
Validation loss: 3.0002361242283064

Epoch: 6| Step: 4
Training loss: 3.226334903254618
Validation loss: 3.070869028598562

Epoch: 6| Step: 5
Training loss: 2.7761456229741435
Validation loss: 3.240394650281277

Epoch: 6| Step: 6
Training loss: 3.5527410858409683
Validation loss: 2.974613425650443

Epoch: 6| Step: 7
Training loss: 3.373412429977914
Validation loss: 3.180369506138401

Epoch: 6| Step: 8
Training loss: 3.401417515284069
Validation loss: 2.9495523569539324

Epoch: 6| Step: 9
Training loss: 3.253063372084136
Validation loss: 3.145434838339948

Epoch: 6| Step: 10
Training loss: 2.804778456209247
Validation loss: 3.0935459088289234

Epoch: 6| Step: 11
Training loss: 3.4738588943242616
Validation loss: 3.117652459721101

Epoch: 6| Step: 12
Training loss: 3.06833730746759
Validation loss: 3.14707026740309

Epoch: 6| Step: 13
Training loss: 1.8830567514109668
Validation loss: 2.9393796490304394

Epoch: 152| Step: 0
Training loss: 4.278288770819304
Validation loss: 3.127143052843083

Epoch: 6| Step: 1
Training loss: 2.0399119043963037
Validation loss: 3.1554971286600346

Epoch: 6| Step: 2
Training loss: 2.661906782517193
Validation loss: 3.037398310375821

Epoch: 6| Step: 3
Training loss: 2.569121574759271
Validation loss: 3.001191448684985

Epoch: 6| Step: 4
Training loss: 3.1739986432558753
Validation loss: 3.2534580528446946

Epoch: 6| Step: 5
Training loss: 3.534928018357758
Validation loss: 3.0127117757047754

Epoch: 6| Step: 6
Training loss: 3.179147435468017
Validation loss: 3.0362963360517154

Epoch: 6| Step: 7
Training loss: 3.855134804591438
Validation loss: 3.1764079462204324

Epoch: 6| Step: 8
Training loss: 3.143389647442228
Validation loss: 3.1250114900111137

Epoch: 6| Step: 9
Training loss: 2.9798821788256356
Validation loss: 3.0836738879487235

Epoch: 6| Step: 10
Training loss: 2.684694022960107
Validation loss: 2.9684108685072825

Epoch: 6| Step: 11
Training loss: 3.1967841678964315
Validation loss: 3.1306502995076904

Epoch: 6| Step: 12
Training loss: 3.142006337820517
Validation loss: 2.9969191275791425

Epoch: 6| Step: 13
Training loss: 1.6608841321379324
Validation loss: 3.2034473560118046

Epoch: 153| Step: 0
Training loss: 2.1543464551184983
Validation loss: 3.137835767692084

Epoch: 6| Step: 1
Training loss: 2.485248244260884
Validation loss: 3.0831767516105635

Epoch: 6| Step: 2
Training loss: 3.507766417474657
Validation loss: 3.13238272773538

Epoch: 6| Step: 3
Training loss: 2.9345472388859952
Validation loss: 3.2193401985097383

Epoch: 6| Step: 4
Training loss: 3.874675121839854
Validation loss: 3.130458447033914

Epoch: 6| Step: 5
Training loss: 3.1545003441535155
Validation loss: 3.0394783143627793

Epoch: 6| Step: 6
Training loss: 4.127080912671959
Validation loss: 3.170420402596125

Epoch: 6| Step: 7
Training loss: 2.2245115236861444
Validation loss: 3.1959016298297698

Epoch: 6| Step: 8
Training loss: 2.867023016345932
Validation loss: 3.0685719377344505

Epoch: 6| Step: 9
Training loss: 3.015753392465956
Validation loss: 3.2247474088176036

Epoch: 6| Step: 10
Training loss: 3.2913204606594992
Validation loss: 3.1143502550735582

Epoch: 6| Step: 11
Training loss: 3.3544420085857563
Validation loss: 3.095078604926556

Epoch: 6| Step: 12
Training loss: 2.6026314953390934
Validation loss: 3.2066225243051507

Epoch: 6| Step: 13
Training loss: 2.7868756608605056
Validation loss: 3.2011332292183656

Epoch: 154| Step: 0
Training loss: 3.4201597330369387
Validation loss: 3.1096404859892535

Epoch: 6| Step: 1
Training loss: 3.5669241755805268
Validation loss: 3.0218615925083143

Epoch: 6| Step: 2
Training loss: 3.2969666960922734
Validation loss: 3.0368907117357735

Epoch: 6| Step: 3
Training loss: 3.654080913121809
Validation loss: 2.9342212937851624

Epoch: 6| Step: 4
Training loss: 2.740945996893361
Validation loss: 2.974951859558033

Epoch: 6| Step: 5
Training loss: 2.3470358639785966
Validation loss: 2.95588497726773

Epoch: 6| Step: 6
Training loss: 2.451936859276242
Validation loss: 3.0555980441388804

Epoch: 6| Step: 7
Training loss: 2.747328587774251
Validation loss: 3.080159267757858

Epoch: 6| Step: 8
Training loss: 2.922384778599398
Validation loss: 3.1686785308071816

Epoch: 6| Step: 9
Training loss: 4.031696147035573
Validation loss: 2.967203675566583

Epoch: 6| Step: 10
Training loss: 2.705513929385844
Validation loss: 3.0379355169653572

Epoch: 6| Step: 11
Training loss: 3.432570928964622
Validation loss: 3.212158271263243

Epoch: 6| Step: 12
Training loss: 2.989696292316008
Validation loss: 3.1116772206260817

Epoch: 6| Step: 13
Training loss: 2.4654338148521164
Validation loss: 3.1027712650838897

Epoch: 155| Step: 0
Training loss: 2.730832142585663
Validation loss: 3.0868060840711267

Epoch: 6| Step: 1
Training loss: 2.767118147891569
Validation loss: 3.2378156402882503

Epoch: 6| Step: 2
Training loss: 3.887801160523713
Validation loss: 3.0860925587973878

Epoch: 6| Step: 3
Training loss: 4.331195499578195
Validation loss: 2.9880888104094607

Epoch: 6| Step: 4
Training loss: 2.8862201843439887
Validation loss: 3.1017304781007256

Epoch: 6| Step: 5
Training loss: 2.757060264462836
Validation loss: 3.193902851726486

Epoch: 6| Step: 6
Training loss: 2.6813044438025355
Validation loss: 3.150835535149273

Epoch: 6| Step: 7
Training loss: 2.5554799008804023
Validation loss: 2.961485292107119

Epoch: 6| Step: 8
Training loss: 3.1728763596964975
Validation loss: 3.0669306343073512

Epoch: 6| Step: 9
Training loss: 3.1267621984575555
Validation loss: 3.1321391808852064

Epoch: 6| Step: 10
Training loss: 2.733173476948808
Validation loss: 3.1295001436347287

Epoch: 6| Step: 11
Training loss: 2.7345069199483407
Validation loss: 3.2781205230719546

Epoch: 6| Step: 12
Training loss: 2.3847658249513635
Validation loss: 3.0749935289140264

Epoch: 6| Step: 13
Training loss: 3.6078404719151003
Validation loss: 3.1074545566023626

Epoch: 156| Step: 0
Training loss: 2.131253633468081
Validation loss: 3.0232933412617053

Epoch: 6| Step: 1
Training loss: 3.1790536909582254
Validation loss: 3.187434444119308

Epoch: 6| Step: 2
Training loss: 3.062870392491124
Validation loss: 3.111849108841937

Epoch: 6| Step: 3
Training loss: 2.9448808510581053
Validation loss: 3.2234458324481015

Epoch: 6| Step: 4
Training loss: 2.4733747791234855
Validation loss: 3.2697675787170284

Epoch: 6| Step: 5
Training loss: 2.41304503297737
Validation loss: 3.0577921162804826

Epoch: 6| Step: 6
Training loss: 3.5217744069935657
Validation loss: 3.072355094696751

Epoch: 6| Step: 7
Training loss: 3.2217415546120947
Validation loss: 3.0857457545959712

Epoch: 6| Step: 8
Training loss: 2.977132427290399
Validation loss: 3.0471846758377765

Epoch: 6| Step: 9
Training loss: 4.1796649112269275
Validation loss: 3.305075964797219

Epoch: 6| Step: 10
Training loss: 2.3852181719911547
Validation loss: 3.1860026430262556

Epoch: 6| Step: 11
Training loss: 3.1643503317190698
Validation loss: 3.11990229099454

Epoch: 6| Step: 12
Training loss: 3.7944926256205416
Validation loss: 3.013277786505021

Epoch: 6| Step: 13
Training loss: 3.0921122522050872
Validation loss: 3.1061033475949293

Epoch: 157| Step: 0
Training loss: 2.213085519502597
Validation loss: 3.2887166447701377

Epoch: 6| Step: 1
Training loss: 2.9090093823409804
Validation loss: 2.919147043850157

Epoch: 6| Step: 2
Training loss: 3.7621627656484953
Validation loss: 3.0608867760137297

Epoch: 6| Step: 3
Training loss: 3.6876805148149296
Validation loss: 3.158926098264622

Epoch: 6| Step: 4
Training loss: 3.1378662746666612
Validation loss: 3.106935411935139

Epoch: 6| Step: 5
Training loss: 2.552030809342053
Validation loss: 3.2068668962020186

Epoch: 6| Step: 6
Training loss: 2.445813989860645
Validation loss: 3.0792804184194886

Epoch: 6| Step: 7
Training loss: 3.1266302815362472
Validation loss: 3.086447630162363

Epoch: 6| Step: 8
Training loss: 2.392629344158395
Validation loss: 2.9958333849969314

Epoch: 6| Step: 9
Training loss: 3.3122195718930896
Validation loss: 3.0686406912166886

Epoch: 6| Step: 10
Training loss: 2.7543912852727503
Validation loss: 3.0530564743521795

Epoch: 6| Step: 11
Training loss: 3.282222639976457
Validation loss: 2.9733952196994062

Epoch: 6| Step: 12
Training loss: 3.25524098290918
Validation loss: 3.0813518821244736

Epoch: 6| Step: 13
Training loss: 2.4904969798730114
Validation loss: 3.151793190853081

Epoch: 158| Step: 0
Training loss: 2.8790422301353678
Validation loss: 3.189714200375123

Epoch: 6| Step: 1
Training loss: 2.703318859050617
Validation loss: 3.1879066281911825

Epoch: 6| Step: 2
Training loss: 3.2454347090652838
Validation loss: 3.0770004564451887

Epoch: 6| Step: 3
Training loss: 1.803371858144165
Validation loss: 3.0696651675292443

Epoch: 6| Step: 4
Training loss: 3.3888267987370466
Validation loss: 3.131502398159849

Epoch: 6| Step: 5
Training loss: 2.329343950306731
Validation loss: 3.0333505728604835

Epoch: 6| Step: 6
Training loss: 3.272433834937007
Validation loss: 2.973613057721804

Epoch: 6| Step: 7
Training loss: 2.346866011316633
Validation loss: 2.994276467941343

Epoch: 6| Step: 8
Training loss: 3.5590882946958367
Validation loss: 3.0800732800047532

Epoch: 6| Step: 9
Training loss: 3.0914817741062857
Validation loss: 3.101484857369873

Epoch: 6| Step: 10
Training loss: 3.1448969847481067
Validation loss: 2.9827744329644785

Epoch: 6| Step: 11
Training loss: 2.6967569654676598
Validation loss: 3.2120052181502836

Epoch: 6| Step: 12
Training loss: 3.210769240525666
Validation loss: 3.0651339667510227

Epoch: 6| Step: 13
Training loss: 4.625460421352352
Validation loss: 3.057812463244965

Epoch: 159| Step: 0
Training loss: 2.4088968359115035
Validation loss: 3.023211950989612

Epoch: 6| Step: 1
Training loss: 2.498851035261895
Validation loss: 3.0062564519165247

Epoch: 6| Step: 2
Training loss: 2.942949151281967
Validation loss: 2.9543446074788964

Epoch: 6| Step: 3
Training loss: 3.3378457679658506
Validation loss: 2.9895745422661646

Epoch: 6| Step: 4
Training loss: 3.063290863683588
Validation loss: 3.0212967434782962

Epoch: 6| Step: 5
Training loss: 2.9424853935300503
Validation loss: 3.187024176911514

Epoch: 6| Step: 6
Training loss: 3.7712297319038917
Validation loss: 3.1471120062066937

Epoch: 6| Step: 7
Training loss: 2.270687156895407
Validation loss: 3.11253189832948

Epoch: 6| Step: 8
Training loss: 3.2944992689860486
Validation loss: 3.149781975604606

Epoch: 6| Step: 9
Training loss: 3.9416422777987314
Validation loss: 3.0873244932305175

Epoch: 6| Step: 10
Training loss: 2.293185118258616
Validation loss: 3.0965379988661486

Epoch: 6| Step: 11
Training loss: 2.8861372469111397
Validation loss: 3.0625065269174643

Epoch: 6| Step: 12
Training loss: 3.3039490796892133
Validation loss: 3.179160059517477

Epoch: 6| Step: 13
Training loss: 2.7639544770484714
Validation loss: 3.2293504538948463

Epoch: 160| Step: 0
Training loss: 3.581788432337041
Validation loss: 3.230109051801035

Epoch: 6| Step: 1
Training loss: 3.2325189397246707
Validation loss: 3.114590404926508

Epoch: 6| Step: 2
Training loss: 2.1566416066918386
Validation loss: 3.0009886811326743

Epoch: 6| Step: 3
Training loss: 3.5855006531552682
Validation loss: 3.022266046207618

Epoch: 6| Step: 4
Training loss: 2.7177654544495136
Validation loss: 3.1503385817942626

Epoch: 6| Step: 5
Training loss: 2.4628813317627998
Validation loss: 3.1353825106791025

Epoch: 6| Step: 6
Training loss: 3.2351344594472615
Validation loss: 3.008020699301308

Epoch: 6| Step: 7
Training loss: 2.759870069596739
Validation loss: 3.0762241329006565

Epoch: 6| Step: 8
Training loss: 2.6500190806151775
Validation loss: 3.1280156374178723

Epoch: 6| Step: 9
Training loss: 2.914761784080231
Validation loss: 3.2920944708983635

Epoch: 6| Step: 10
Training loss: 2.778618757312044
Validation loss: 2.9183017126553925

Epoch: 6| Step: 11
Training loss: 3.699431432392501
Validation loss: 3.2083769402312554

Epoch: 6| Step: 12
Training loss: 2.768357817901178
Validation loss: 2.9421539809584694

Epoch: 6| Step: 13
Training loss: 2.487389517012662
Validation loss: 3.0275556495331664

Epoch: 161| Step: 0
Training loss: 2.513654991869778
Validation loss: 3.014506112956973

Epoch: 6| Step: 1
Training loss: 2.9345022285675255
Validation loss: 2.9374751288714496

Epoch: 6| Step: 2
Training loss: 2.261972996153391
Validation loss: 3.111554237187688

Epoch: 6| Step: 3
Training loss: 3.629354295285596
Validation loss: 3.0249824033228934

Epoch: 6| Step: 4
Training loss: 3.208648088216611
Validation loss: 3.0209102079109873

Epoch: 6| Step: 5
Training loss: 3.513766734362596
Validation loss: 3.0534868388241043

Epoch: 6| Step: 6
Training loss: 3.7495952387758975
Validation loss: 2.998331982907807

Epoch: 6| Step: 7
Training loss: 2.3586821896782784
Validation loss: 3.069125243621954

Epoch: 6| Step: 8
Training loss: 3.0101873361074913
Validation loss: 2.9590782488258767

Epoch: 6| Step: 9
Training loss: 2.724200868233361
Validation loss: 3.1732175394243898

Epoch: 6| Step: 10
Training loss: 2.524678211669608
Validation loss: 3.20601217756792

Epoch: 6| Step: 11
Training loss: 3.5991838589718634
Validation loss: 3.1248144525387325

Epoch: 6| Step: 12
Training loss: 2.4009549228006763
Validation loss: 3.0692094933399963

Epoch: 6| Step: 13
Training loss: 4.2739614552539065
Validation loss: 3.1640701048757216

Epoch: 162| Step: 0
Training loss: 3.38077855798662
Validation loss: 3.1235334913587294

Epoch: 6| Step: 1
Training loss: 3.448247027441024
Validation loss: 3.1030167666388317

Epoch: 6| Step: 2
Training loss: 3.867076032168778
Validation loss: 3.159334429046727

Epoch: 6| Step: 3
Training loss: 2.6684493027249703
Validation loss: 3.1730147518040503

Epoch: 6| Step: 4
Training loss: 3.639003277858129
Validation loss: 3.1392042390814416

Epoch: 6| Step: 5
Training loss: 2.5693339888283657
Validation loss: 3.0194349713621906

Epoch: 6| Step: 6
Training loss: 3.073812028864801
Validation loss: 3.0591824518108903

Epoch: 6| Step: 7
Training loss: 2.810325290409464
Validation loss: 3.0322161920117927

Epoch: 6| Step: 8
Training loss: 3.0960601504493086
Validation loss: 2.951052484773786

Epoch: 6| Step: 9
Training loss: 3.45954526018776
Validation loss: 3.0038548351836467

Epoch: 6| Step: 10
Training loss: 2.274351060976663
Validation loss: 3.030698957256499

Epoch: 6| Step: 11
Training loss: 2.7421295942403754
Validation loss: 3.1799565360891937

Epoch: 6| Step: 12
Training loss: 3.1170293246796836
Validation loss: 3.015345614093926

Epoch: 6| Step: 13
Training loss: 3.818429432101881
Validation loss: 3.2150421290698663

Epoch: 163| Step: 0
Training loss: 3.0700587199308162
Validation loss: 3.163904906591474

Epoch: 6| Step: 1
Training loss: 2.998552609013795
Validation loss: 3.1575645260639162

Epoch: 6| Step: 2
Training loss: 3.0712736920819683
Validation loss: 3.0642252380561796

Epoch: 6| Step: 3
Training loss: 1.8761138150922976
Validation loss: 3.0568198172385284

Epoch: 6| Step: 4
Training loss: 2.9353438235455074
Validation loss: 3.1850466349865654

Epoch: 6| Step: 5
Training loss: 3.5188177234372864
Validation loss: 3.0063956290325415

Epoch: 6| Step: 6
Training loss: 3.3521850292331483
Validation loss: 3.1034809061741173

Epoch: 6| Step: 7
Training loss: 2.983272488646673
Validation loss: 3.224505334939951

Epoch: 6| Step: 8
Training loss: 2.7902052645905076
Validation loss: 3.0716836904654783

Epoch: 6| Step: 9
Training loss: 2.5744465798032676
Validation loss: 2.992383327355699

Epoch: 6| Step: 10
Training loss: 2.6740163509750614
Validation loss: 3.009404037066814

Epoch: 6| Step: 11
Training loss: 3.0774642312568847
Validation loss: 3.0663137866772368

Epoch: 6| Step: 12
Training loss: 3.5247528260058227
Validation loss: 2.9945641272921866

Epoch: 6| Step: 13
Training loss: 3.5829658911335405
Validation loss: 3.1015374946779604

Epoch: 164| Step: 0
Training loss: 2.4258667566828973
Validation loss: 3.120333981050163

Epoch: 6| Step: 1
Training loss: 2.9084549609732253
Validation loss: 3.0141257635035585

Epoch: 6| Step: 2
Training loss: 2.7592232097553184
Validation loss: 3.0396802872013184

Epoch: 6| Step: 3
Training loss: 3.3017074098212214
Validation loss: 3.0644790862790936

Epoch: 6| Step: 4
Training loss: 4.001759380604835
Validation loss: 3.0994238170458632

Epoch: 6| Step: 5
Training loss: 2.9461144283988236
Validation loss: 3.188570274394635

Epoch: 6| Step: 6
Training loss: 3.1504163557729443
Validation loss: 3.271308322577975

Epoch: 6| Step: 7
Training loss: 2.977435767364142
Validation loss: 3.082057884194075

Epoch: 6| Step: 8
Training loss: 3.5342383779062265
Validation loss: 3.0313787353702724

Epoch: 6| Step: 9
Training loss: 2.878099180886498
Validation loss: 3.1018021216341456

Epoch: 6| Step: 10
Training loss: 1.8236282994097122
Validation loss: 3.060787416041589

Epoch: 6| Step: 11
Training loss: 2.8309772082145375
Validation loss: 3.2056669292148148

Epoch: 6| Step: 12
Training loss: 2.8634324599824
Validation loss: 3.2612170245133036

Epoch: 6| Step: 13
Training loss: 4.181600257789162
Validation loss: 3.128132107385173

Epoch: 165| Step: 0
Training loss: 3.1665234449691133
Validation loss: 3.051036583121824

Epoch: 6| Step: 1
Training loss: 3.2127766412151795
Validation loss: 2.9649995006895717

Epoch: 6| Step: 2
Training loss: 2.8772300695686432
Validation loss: 2.9348624717306384

Epoch: 6| Step: 3
Training loss: 2.247757429882622
Validation loss: 3.136694682053498

Epoch: 6| Step: 4
Training loss: 3.0800355510393875
Validation loss: 3.0627631751788456

Epoch: 6| Step: 5
Training loss: 3.280816621770939
Validation loss: 3.2071502948431596

Epoch: 6| Step: 6
Training loss: 2.843634634507449
Validation loss: 3.0846490328256952

Epoch: 6| Step: 7
Training loss: 2.662537527043752
Validation loss: 3.0339658829722107

Epoch: 6| Step: 8
Training loss: 3.493859899767955
Validation loss: 2.920915931546171

Epoch: 6| Step: 9
Training loss: 2.7043646467137195
Validation loss: 3.062100662135684

Epoch: 6| Step: 10
Training loss: 2.3647271895376685
Validation loss: 3.1676707130538686

Epoch: 6| Step: 11
Training loss: 3.435082435118489
Validation loss: 3.006030635468118

Epoch: 6| Step: 12
Training loss: 3.213755463959401
Validation loss: 3.3581934528740938

Epoch: 6| Step: 13
Training loss: 1.6378453276411669
Validation loss: 3.2473580844820997

Epoch: 166| Step: 0
Training loss: 2.841970033384289
Validation loss: 3.026489152855543

Epoch: 6| Step: 1
Training loss: 3.6608691910457214
Validation loss: 3.137314011661924

Epoch: 6| Step: 2
Training loss: 3.269136138340436
Validation loss: 3.1307480326520314

Epoch: 6| Step: 3
Training loss: 2.1483435038031633
Validation loss: 3.0808593671447997

Epoch: 6| Step: 4
Training loss: 3.2256242251455305
Validation loss: 3.1458198651929576

Epoch: 6| Step: 5
Training loss: 3.1972584663175816
Validation loss: 3.2470841117748863

Epoch: 6| Step: 6
Training loss: 2.5707968397554066
Validation loss: 3.0341581470201704

Epoch: 6| Step: 7
Training loss: 3.451587869974878
Validation loss: 3.059780506412203

Epoch: 6| Step: 8
Training loss: 3.279316650476406
Validation loss: 3.1035069399606403

Epoch: 6| Step: 9
Training loss: 3.053450468084813
Validation loss: 2.8409289539347538

Epoch: 6| Step: 10
Training loss: 2.2878782574536074
Validation loss: 3.009417530760624

Epoch: 6| Step: 11
Training loss: 2.8147753518481844
Validation loss: 3.063894470449944

Epoch: 6| Step: 12
Training loss: 3.2232681710705857
Validation loss: 3.032965701125013

Epoch: 6| Step: 13
Training loss: 2.646514644660841
Validation loss: 3.183823980183412

Epoch: 167| Step: 0
Training loss: 3.0370305581613852
Validation loss: 2.986132276580376

Epoch: 6| Step: 1
Training loss: 2.872666116531023
Validation loss: 3.160833976887011

Epoch: 6| Step: 2
Training loss: 3.097745838769897
Validation loss: 3.046534323334764

Epoch: 6| Step: 3
Training loss: 2.045668850856189
Validation loss: 3.1041622311866743

Epoch: 6| Step: 4
Training loss: 3.213849828320256
Validation loss: 2.913525982923275

Epoch: 6| Step: 5
Training loss: 3.262196178101333
Validation loss: 2.9832180112501363

Epoch: 6| Step: 6
Training loss: 2.76971951424536
Validation loss: 2.900137886323766

Epoch: 6| Step: 7
Training loss: 3.6876743081484995
Validation loss: 3.0812715778203907

Epoch: 6| Step: 8
Training loss: 3.4582094070720504
Validation loss: 3.14289796643831

Epoch: 6| Step: 9
Training loss: 3.4377036294445866
Validation loss: 3.2409389510890736

Epoch: 6| Step: 10
Training loss: 3.164586153378631
Validation loss: 3.0636334928150477

Epoch: 6| Step: 11
Training loss: 3.2854762879652224
Validation loss: 3.0338011428795584

Epoch: 6| Step: 12
Training loss: 2.767767986496555
Validation loss: 2.996824080615175

Epoch: 6| Step: 13
Training loss: 4.362040043496214
Validation loss: 3.0875098425708414

Epoch: 168| Step: 0
Training loss: 2.8099324692726264
Validation loss: 3.084346993459427

Epoch: 6| Step: 1
Training loss: 3.3030664242086285
Validation loss: 3.0166127821191737

Epoch: 6| Step: 2
Training loss: 1.6223096584826158
Validation loss: 3.0537148059894568

Epoch: 6| Step: 3
Training loss: 2.9285212522454938
Validation loss: 3.203588780788564

Epoch: 6| Step: 4
Training loss: 3.632302656595583
Validation loss: 3.0796617355530516

Epoch: 6| Step: 5
Training loss: 3.2882844634435773
Validation loss: 3.082517650426535

Epoch: 6| Step: 6
Training loss: 3.4410944785528845
Validation loss: 3.22417060182012

Epoch: 6| Step: 7
Training loss: 2.7572137544694812
Validation loss: 3.0116173362817493

Epoch: 6| Step: 8
Training loss: 2.6364962109502876
Validation loss: 2.903500241750184

Epoch: 6| Step: 9
Training loss: 2.944613831724112
Validation loss: 3.022148792722023

Epoch: 6| Step: 10
Training loss: 2.95674436278615
Validation loss: 3.067209229741206

Epoch: 6| Step: 11
Training loss: 2.647010801540424
Validation loss: 3.1225700635990497

Epoch: 6| Step: 12
Training loss: 3.5566012083380065
Validation loss: 3.040825484054664

Epoch: 6| Step: 13
Training loss: 3.6441152975138844
Validation loss: 2.9427028599690987

Epoch: 169| Step: 0
Training loss: 3.062001401834896
Validation loss: 3.1861233232590527

Epoch: 6| Step: 1
Training loss: 3.130206691510896
Validation loss: 3.0684105143840235

Epoch: 6| Step: 2
Training loss: 3.988362549673327
Validation loss: 3.2742921570740413

Epoch: 6| Step: 3
Training loss: 2.6523214572424716
Validation loss: 2.89874919452244

Epoch: 6| Step: 4
Training loss: 3.1606153760555693
Validation loss: 3.0806257609391263

Epoch: 6| Step: 5
Training loss: 2.6322544310129676
Validation loss: 3.0930474524507092

Epoch: 6| Step: 6
Training loss: 3.6051970903378727
Validation loss: 2.9778421269852684

Epoch: 6| Step: 7
Training loss: 1.8846739119120697
Validation loss: 3.2754170597246905

Epoch: 6| Step: 8
Training loss: 2.90612037943889
Validation loss: 3.1752557321603767

Epoch: 6| Step: 9
Training loss: 2.9767172465311345
Validation loss: 3.156627069215316

Epoch: 6| Step: 10
Training loss: 3.27805194318765
Validation loss: 3.083829679894741

Epoch: 6| Step: 11
Training loss: 3.165327859924692
Validation loss: 3.0853973094483664

Epoch: 6| Step: 12
Training loss: 3.0367113447479332
Validation loss: 3.0467100979649357

Epoch: 6| Step: 13
Training loss: 3.749505964161247
Validation loss: 2.9260132465966753

Epoch: 170| Step: 0
Training loss: 3.1364718633381234
Validation loss: 3.056320833452777

Epoch: 6| Step: 1
Training loss: 2.5610143495192688
Validation loss: 2.982939057881944

Epoch: 6| Step: 2
Training loss: 2.5641269636215926
Validation loss: 3.058966970465383

Epoch: 6| Step: 3
Training loss: 3.4713041507507008
Validation loss: 3.166805230840144

Epoch: 6| Step: 4
Training loss: 2.8462310699248863
Validation loss: 2.9809472310366534

Epoch: 6| Step: 5
Training loss: 2.337653406994482
Validation loss: 3.1329047739513136

Epoch: 6| Step: 6
Training loss: 2.60012365193871
Validation loss: 2.993284312478845

Epoch: 6| Step: 7
Training loss: 3.548200183291587
Validation loss: 3.1396951112521934

Epoch: 6| Step: 8
Training loss: 2.9530294090018283
Validation loss: 3.3067124387690505

Epoch: 6| Step: 9
Training loss: 2.4676443593814743
Validation loss: 3.114204223708058

Epoch: 6| Step: 10
Training loss: 4.529011561531645
Validation loss: 3.137091892332585

Epoch: 6| Step: 11
Training loss: 3.2340556553738624
Validation loss: 3.11234368010271

Epoch: 6| Step: 12
Training loss: 2.535052798471866
Validation loss: 2.990902760496849

Epoch: 6| Step: 13
Training loss: 2.1162415816020768
Validation loss: 3.160161872689523

Epoch: 171| Step: 0
Training loss: 2.484034101021776
Validation loss: 3.219301445127136

Epoch: 6| Step: 1
Training loss: 3.40827335842749
Validation loss: 3.0214462987938115

Epoch: 6| Step: 2
Training loss: 3.1905033697395364
Validation loss: 3.0712172447428943

Epoch: 6| Step: 3
Training loss: 2.785023390502229
Validation loss: 3.224258006295729

Epoch: 6| Step: 4
Training loss: 2.349159609903664
Validation loss: 3.0296526684640717

Epoch: 6| Step: 5
Training loss: 2.887956697091794
Validation loss: 3.2923536745478867

Epoch: 6| Step: 6
Training loss: 4.0800094050878695
Validation loss: 3.045624187259081

Epoch: 6| Step: 7
Training loss: 3.425822171844386
Validation loss: 3.115649321415258

Epoch: 6| Step: 8
Training loss: 2.296776801884184
Validation loss: 3.0620934620669016

Epoch: 6| Step: 9
Training loss: 3.7547314359115957
Validation loss: 3.1128753007540246

Epoch: 6| Step: 10
Training loss: 2.8978486401169805
Validation loss: 3.084527617228638

Epoch: 6| Step: 11
Training loss: 2.705389672802749
Validation loss: 3.151734722129311

Epoch: 6| Step: 12
Training loss: 3.1603198109325974
Validation loss: 3.1834496886327712

Epoch: 6| Step: 13
Training loss: 3.0287795864144775
Validation loss: 3.1834111087624604

Epoch: 172| Step: 0
Training loss: 2.820389426917888
Validation loss: 3.1485454785392823

Epoch: 6| Step: 1
Training loss: 2.2153659857472
Validation loss: 3.103485474245489

Epoch: 6| Step: 2
Training loss: 3.660531691406857
Validation loss: 2.9475183087699586

Epoch: 6| Step: 3
Training loss: 3.306344124332169
Validation loss: 2.937821226898874

Epoch: 6| Step: 4
Training loss: 1.4227759891670726
Validation loss: 3.1761017787860286

Epoch: 6| Step: 5
Training loss: 2.893903532960464
Validation loss: 3.0101860799163296

Epoch: 6| Step: 6
Training loss: 3.16405164928695
Validation loss: 3.115511076816062

Epoch: 6| Step: 7
Training loss: 2.56512818817406
Validation loss: 3.130171161432469

Epoch: 6| Step: 8
Training loss: 2.3602174177075503
Validation loss: 3.2378810462738072

Epoch: 6| Step: 9
Training loss: 2.9879494875579398
Validation loss: 2.9377255428444644

Epoch: 6| Step: 10
Training loss: 3.1218853496880183
Validation loss: 3.0244105481464656

Epoch: 6| Step: 11
Training loss: 3.672437778929999
Validation loss: 3.180156013629105

Epoch: 6| Step: 12
Training loss: 3.6230047588522454
Validation loss: 2.83742294702014

Epoch: 6| Step: 13
Training loss: 3.6144644124955465
Validation loss: 3.056973218208357

Epoch: 173| Step: 0
Training loss: 2.5293647432979434
Validation loss: 3.0775623031044494

Epoch: 6| Step: 1
Training loss: 2.976312101149627
Validation loss: 3.1513760302444194

Epoch: 6| Step: 2
Training loss: 2.188417296860394
Validation loss: 3.213577702426715

Epoch: 6| Step: 3
Training loss: 2.817429355388955
Validation loss: 3.1195871609097456

Epoch: 6| Step: 4
Training loss: 2.8108212017027863
Validation loss: 3.0732624280042447

Epoch: 6| Step: 5
Training loss: 3.6356078847239957
Validation loss: 2.8888039060413613

Epoch: 6| Step: 6
Training loss: 2.499739156466593
Validation loss: 2.8546592216133484

Epoch: 6| Step: 7
Training loss: 3.12328077708361
Validation loss: 3.0322300796312693

Epoch: 6| Step: 8
Training loss: 3.3186703200033434
Validation loss: 2.8536449587603214

Epoch: 6| Step: 9
Training loss: 2.549368170457629
Validation loss: 3.096457514649244

Epoch: 6| Step: 10
Training loss: 2.944120373276009
Validation loss: 3.0691877768918916

Epoch: 6| Step: 11
Training loss: 3.3489175955201516
Validation loss: 3.240750752980642

Epoch: 6| Step: 12
Training loss: 3.3529169506933916
Validation loss: 3.081301498323854

Epoch: 6| Step: 13
Training loss: 2.389557643797744
Validation loss: 3.1095032447277076

Epoch: 174| Step: 0
Training loss: 3.0710053960317385
Validation loss: 3.0134387024018463

Epoch: 6| Step: 1
Training loss: 2.561261971233014
Validation loss: 3.1243627837864496

Epoch: 6| Step: 2
Training loss: 2.7266969838901365
Validation loss: 3.168699731258357

Epoch: 6| Step: 3
Training loss: 2.8210794774394046
Validation loss: 3.063091427733594

Epoch: 6| Step: 4
Training loss: 4.1276828248945785
Validation loss: 3.058181155896284

Epoch: 6| Step: 5
Training loss: 2.379961753666133
Validation loss: 3.0729535172416607

Epoch: 6| Step: 6
Training loss: 3.4802896815344293
Validation loss: 3.020652508159173

Epoch: 6| Step: 7
Training loss: 4.399672339983826
Validation loss: 3.1045875921872295

Epoch: 6| Step: 8
Training loss: 2.710905311239466
Validation loss: 3.1133918163583174

Epoch: 6| Step: 9
Training loss: 2.636254118495164
Validation loss: 3.0918728397624453

Epoch: 6| Step: 10
Training loss: 1.744779839167196
Validation loss: 3.0314963362980696

Epoch: 6| Step: 11
Training loss: 3.2105002743682722
Validation loss: 3.186999666764681

Epoch: 6| Step: 12
Training loss: 1.8939653632955598
Validation loss: 3.2535854366056083

Epoch: 6| Step: 13
Training loss: 1.9930159099267295
Validation loss: 3.049635303560225

Epoch: 175| Step: 0
Training loss: 2.5227189591104424
Validation loss: 3.0422435704495223

Epoch: 6| Step: 1
Training loss: 3.6014792211341757
Validation loss: 3.0113495558841143

Epoch: 6| Step: 2
Training loss: 3.328064107561711
Validation loss: 3.1203017572340066

Epoch: 6| Step: 3
Training loss: 2.923475184317512
Validation loss: 2.9435085267522982

Epoch: 6| Step: 4
Training loss: 3.082256043024054
Validation loss: 2.9198714248052777

Epoch: 6| Step: 5
Training loss: 2.4388237317630392
Validation loss: 2.9412664242318955

Epoch: 6| Step: 6
Training loss: 4.014568976690215
Validation loss: 3.1595380841587923

Epoch: 6| Step: 7
Training loss: 3.4877828175710635
Validation loss: 3.185517883742259

Epoch: 6| Step: 8
Training loss: 4.398210699220346
Validation loss: 2.9543609003594637

Epoch: 6| Step: 9
Training loss: 2.6404585024016707
Validation loss: 3.15573875748397

Epoch: 6| Step: 10
Training loss: 3.1383509967433163
Validation loss: 3.047359330245496

Epoch: 6| Step: 11
Training loss: 2.296644341960564
Validation loss: 3.032865727350239

Epoch: 6| Step: 12
Training loss: 2.184709458402434
Validation loss: 3.1269553189247756

Epoch: 6| Step: 13
Training loss: 2.5667551578608494
Validation loss: 3.1171131440255

Epoch: 176| Step: 0
Training loss: 2.561146076080484
Validation loss: 3.0729734242771416

Epoch: 6| Step: 1
Training loss: 3.189525932793831
Validation loss: 3.042975840304313

Epoch: 6| Step: 2
Training loss: 2.4291693328092503
Validation loss: 3.092201799306173

Epoch: 6| Step: 3
Training loss: 3.136263727649918
Validation loss: 3.1220993329118354

Epoch: 6| Step: 4
Training loss: 2.3316128609452287
Validation loss: 2.9300293276865026

Epoch: 6| Step: 5
Training loss: 3.5262334518828635
Validation loss: 2.973358093435728

Epoch: 6| Step: 6
Training loss: 3.290740466288292
Validation loss: 2.906703259542648

Epoch: 6| Step: 7
Training loss: 3.2547111111140237
Validation loss: 3.0264880622559254

Epoch: 6| Step: 8
Training loss: 2.7319410554103865
Validation loss: 3.1561574517238493

Epoch: 6| Step: 9
Training loss: 2.887610105586834
Validation loss: 3.003996498609176

Epoch: 6| Step: 10
Training loss: 2.7925454839350765
Validation loss: 3.0304570947121214

Epoch: 6| Step: 11
Training loss: 3.331619934955248
Validation loss: 2.9753413793080394

Epoch: 6| Step: 12
Training loss: 3.5122610316320864
Validation loss: 3.2040389179058217

Epoch: 6| Step: 13
Training loss: 3.850917553245212
Validation loss: 3.154483394580872

Epoch: 177| Step: 0
Training loss: 3.315938496487502
Validation loss: 3.062356401784844

Epoch: 6| Step: 1
Training loss: 3.581368254994292
Validation loss: 3.048195927069728

Epoch: 6| Step: 2
Training loss: 1.9833568454064698
Validation loss: 3.143264845477123

Epoch: 6| Step: 3
Training loss: 2.507594399163336
Validation loss: 3.178423310918454

Epoch: 6| Step: 4
Training loss: 3.6921125109754134
Validation loss: 3.0922892198067817

Epoch: 6| Step: 5
Training loss: 2.821781695102308
Validation loss: 3.0932421051397325

Epoch: 6| Step: 6
Training loss: 2.254694174520721
Validation loss: 3.1862749515964297

Epoch: 6| Step: 7
Training loss: 4.09187588490246
Validation loss: 3.0460867510812824

Epoch: 6| Step: 8
Training loss: 2.6168650869797183
Validation loss: 2.9561077593002905

Epoch: 6| Step: 9
Training loss: 3.347216511603233
Validation loss: 3.0764053194165326

Epoch: 6| Step: 10
Training loss: 3.1608775745543833
Validation loss: 3.1117404270367874

Epoch: 6| Step: 11
Training loss: 2.7601894261136835
Validation loss: 3.183314677577177

Epoch: 6| Step: 12
Training loss: 2.769959754238335
Validation loss: 3.074171478266207

Epoch: 6| Step: 13
Training loss: 3.3277288210039195
Validation loss: 3.170632927870699

Epoch: 178| Step: 0
Training loss: 2.9034086715027434
Validation loss: 3.0670641435091217

Epoch: 6| Step: 1
Training loss: 3.045759887088101
Validation loss: 3.0756072037046462

Epoch: 6| Step: 2
Training loss: 3.0356196733364773
Validation loss: 3.0954328749306272

Epoch: 6| Step: 3
Training loss: 3.5549681164992424
Validation loss: 3.0171436003731493

Epoch: 6| Step: 4
Training loss: 3.212042328409548
Validation loss: 2.935877929667149

Epoch: 6| Step: 5
Training loss: 3.7730710185323404
Validation loss: 3.126825674676976

Epoch: 6| Step: 6
Training loss: 2.7620148452812847
Validation loss: 2.9389349138909373

Epoch: 6| Step: 7
Training loss: 3.6035555870921008
Validation loss: 3.0864010914481828

Epoch: 6| Step: 8
Training loss: 2.271463277625316
Validation loss: 3.0809814548430015

Epoch: 6| Step: 9
Training loss: 2.618831107037546
Validation loss: 3.0537145188751733

Epoch: 6| Step: 10
Training loss: 3.405817126845432
Validation loss: 3.0603433180305584

Epoch: 6| Step: 11
Training loss: 2.5205397842194452
Validation loss: 3.1786552657075844

Epoch: 6| Step: 12
Training loss: 2.9465491332122045
Validation loss: 3.057252177646071

Epoch: 6| Step: 13
Training loss: 2.0675667458845783
Validation loss: 3.086649700664694

Epoch: 179| Step: 0
Training loss: 2.2728455287338276
Validation loss: 2.943713463955677

Epoch: 6| Step: 1
Training loss: 2.6361251501958547
Validation loss: 3.009079060999534

Epoch: 6| Step: 2
Training loss: 2.262454109358761
Validation loss: 3.125681202793271

Epoch: 6| Step: 3
Training loss: 3.5367960630493758
Validation loss: 3.0882456481866645

Epoch: 6| Step: 4
Training loss: 3.283640254306514
Validation loss: 3.045439428605653

Epoch: 6| Step: 5
Training loss: 3.2816560039925022
Validation loss: 3.11427347538684

Epoch: 6| Step: 6
Training loss: 3.691180962040638
Validation loss: 2.9362956091264825

Epoch: 6| Step: 7
Training loss: 2.365299693307416
Validation loss: 2.899937780870502

Epoch: 6| Step: 8
Training loss: 3.874279570520403
Validation loss: 3.1915275452377005

Epoch: 6| Step: 9
Training loss: 3.1179874321156356
Validation loss: 2.9450274657284496

Epoch: 6| Step: 10
Training loss: 2.355166692645445
Validation loss: 3.084553971388408

Epoch: 6| Step: 11
Training loss: 3.1583038295149515
Validation loss: 2.940599367326572

Epoch: 6| Step: 12
Training loss: 2.6741470581394564
Validation loss: 2.995154393269268

Epoch: 6| Step: 13
Training loss: 2.6824445859903947
Validation loss: 3.0588158586413594

Epoch: 180| Step: 0
Training loss: 2.4230721744961254
Validation loss: 3.087028753054565

Epoch: 6| Step: 1
Training loss: 3.6869395201864505
Validation loss: 3.124074601187046

Epoch: 6| Step: 2
Training loss: 2.7961670389773357
Validation loss: 2.950268324462018

Epoch: 6| Step: 3
Training loss: 2.6743305366815617
Validation loss: 3.197904081654868

Epoch: 6| Step: 4
Training loss: 2.8829114116457797
Validation loss: 3.0819177193741383

Epoch: 6| Step: 5
Training loss: 3.0494993205372305
Validation loss: 3.1587448989214897

Epoch: 6| Step: 6
Training loss: 2.4433824033437186
Validation loss: 3.1634562306648246

Epoch: 6| Step: 7
Training loss: 3.6939062301721584
Validation loss: 3.218604575469155

Epoch: 6| Step: 8
Training loss: 3.2073797484978637
Validation loss: 3.3552501586781114

Epoch: 6| Step: 9
Training loss: 2.8169568670381118
Validation loss: 3.0338527988749573

Epoch: 6| Step: 10
Training loss: 2.8854449072235067
Validation loss: 3.138280321551719

Epoch: 6| Step: 11
Training loss: 2.8706077527658245
Validation loss: 3.138385746415669

Epoch: 6| Step: 12
Training loss: 3.230565283000715
Validation loss: 2.9860209233358845

Epoch: 6| Step: 13
Training loss: 2.538414975275012
Validation loss: 3.210385268221797

Epoch: 181| Step: 0
Training loss: 3.806174612316592
Validation loss: 3.098877247119812

Epoch: 6| Step: 1
Training loss: 2.780426332043549
Validation loss: 2.985818211686211

Epoch: 6| Step: 2
Training loss: 2.546713139357958
Validation loss: 3.0379189026907727

Epoch: 6| Step: 3
Training loss: 2.6549271823933394
Validation loss: 2.9216282553747694

Epoch: 6| Step: 4
Training loss: 3.0691860161146427
Validation loss: 3.050369507805144

Epoch: 6| Step: 5
Training loss: 3.3916033902150993
Validation loss: 3.0331334076474192

Epoch: 6| Step: 6
Training loss: 2.741597082149755
Validation loss: 3.048082691326348

Epoch: 6| Step: 7
Training loss: 2.5618774774394697
Validation loss: 3.0784994651015056

Epoch: 6| Step: 8
Training loss: 3.299803820471919
Validation loss: 3.1287889198323398

Epoch: 6| Step: 9
Training loss: 3.692292154566766
Validation loss: 2.8708330036156413

Epoch: 6| Step: 10
Training loss: 2.5976446854183366
Validation loss: 3.1609641444022083

Epoch: 6| Step: 11
Training loss: 3.242868816073842
Validation loss: 3.078048980791935

Epoch: 6| Step: 12
Training loss: 2.785709705977815
Validation loss: 3.0406970963628996

Epoch: 6| Step: 13
Training loss: 2.5779895168887386
Validation loss: 2.9392285537936726

Epoch: 182| Step: 0
Training loss: 4.296977315898319
Validation loss: 3.095853875536102

Epoch: 6| Step: 1
Training loss: 4.107212440422545
Validation loss: 3.058768350539856

Epoch: 6| Step: 2
Training loss: 3.275930688835122
Validation loss: 3.032410881738183

Epoch: 6| Step: 3
Training loss: 2.7658842148505993
Validation loss: 3.0567330781610647

Epoch: 6| Step: 4
Training loss: 2.1042714863972174
Validation loss: 3.0212551587629983

Epoch: 6| Step: 5
Training loss: 2.2584267806910803
Validation loss: 2.9922124544140494

Epoch: 6| Step: 6
Training loss: 2.284226448457874
Validation loss: 3.0274544047371394

Epoch: 6| Step: 7
Training loss: 3.1924406170680544
Validation loss: 3.063227589047142

Epoch: 6| Step: 8
Training loss: 2.430967135020104
Validation loss: 3.1526954736146453

Epoch: 6| Step: 9
Training loss: 2.632356689117
Validation loss: 3.1265732961979924

Epoch: 6| Step: 10
Training loss: 2.499422006548972
Validation loss: 3.1390824321030566

Epoch: 6| Step: 11
Training loss: 2.039744763582327
Validation loss: 3.141803632735933

Epoch: 6| Step: 12
Training loss: 3.7744345285667644
Validation loss: 3.124525243320481

Epoch: 6| Step: 13
Training loss: 3.72888955448808
Validation loss: 3.126388474330594

Epoch: 183| Step: 0
Training loss: 3.4473331261096667
Validation loss: 3.118131573718434

Epoch: 6| Step: 1
Training loss: 2.136052503747764
Validation loss: 3.2827231214335484

Epoch: 6| Step: 2
Training loss: 2.630865356166642
Validation loss: 3.1490357860394633

Epoch: 6| Step: 3
Training loss: 2.535782511846727
Validation loss: 3.189768017086606

Epoch: 6| Step: 4
Training loss: 3.353921127019765
Validation loss: 3.114263341070935

Epoch: 6| Step: 5
Training loss: 4.287446820788436
Validation loss: 3.19873655139194

Epoch: 6| Step: 6
Training loss: 3.1838444710514247
Validation loss: 3.0510125702958897

Epoch: 6| Step: 7
Training loss: 3.082646336357545
Validation loss: 3.1439576938684515

Epoch: 6| Step: 8
Training loss: 2.209553315602995
Validation loss: 3.0758815377178883

Epoch: 6| Step: 9
Training loss: 2.0080609000952165
Validation loss: 3.1242268941152602

Epoch: 6| Step: 10
Training loss: 2.859743521867697
Validation loss: 3.068410851923852

Epoch: 6| Step: 11
Training loss: 2.6937159135613453
Validation loss: 3.1803721323545453

Epoch: 6| Step: 12
Training loss: 3.8649484028400964
Validation loss: 3.079874951602573

Epoch: 6| Step: 13
Training loss: 2.581094776871315
Validation loss: 3.1751520466202097

Epoch: 184| Step: 0
Training loss: 2.509075286562788
Validation loss: 3.2466369784850073

Epoch: 6| Step: 1
Training loss: 3.2097137420980983
Validation loss: 3.19652243165734

Epoch: 6| Step: 2
Training loss: 3.0445835985122955
Validation loss: 3.082421784710986

Epoch: 6| Step: 3
Training loss: 3.053652692970684
Validation loss: 3.1319013392722788

Epoch: 6| Step: 4
Training loss: 4.111729400696352
Validation loss: 3.064714071317717

Epoch: 6| Step: 5
Training loss: 2.552650502818311
Validation loss: 3.1158349061817434

Epoch: 6| Step: 6
Training loss: 3.151000085141233
Validation loss: 3.102434039954867

Epoch: 6| Step: 7
Training loss: 2.6707365945881145
Validation loss: 3.0798550508860516

Epoch: 6| Step: 8
Training loss: 3.3632717509030345
Validation loss: 3.129052964283554

Epoch: 6| Step: 9
Training loss: 3.301378112641288
Validation loss: 2.9346353146091526

Epoch: 6| Step: 10
Training loss: 2.646354193494427
Validation loss: 3.011990755855517

Epoch: 6| Step: 11
Training loss: 3.98343853884724
Validation loss: 3.024384496368975

Epoch: 6| Step: 12
Training loss: 1.9601793381329762
Validation loss: 3.084957483810744

Epoch: 6| Step: 13
Training loss: 2.4814847052043434
Validation loss: 3.014472247606115

Epoch: 185| Step: 0
Training loss: 3.5281171827339493
Validation loss: 3.1940479746485932

Epoch: 6| Step: 1
Training loss: 2.1313171734110243
Validation loss: 3.0969517939539055

Epoch: 6| Step: 2
Training loss: 3.760941628175315
Validation loss: 3.0368150971353205

Epoch: 6| Step: 3
Training loss: 2.964692565521194
Validation loss: 3.091159249969539

Epoch: 6| Step: 4
Training loss: 3.936430528510078
Validation loss: 3.030756275972899

Epoch: 6| Step: 5
Training loss: 2.1151377760649686
Validation loss: 3.053318351003656

Epoch: 6| Step: 6
Training loss: 2.950381826485871
Validation loss: 3.0051170831894005

Epoch: 6| Step: 7
Training loss: 2.062251220495589
Validation loss: 2.9444653610979725

Epoch: 6| Step: 8
Training loss: 2.6988463303590624
Validation loss: 3.0112397549429386

Epoch: 6| Step: 9
Training loss: 2.938215614971276
Validation loss: 3.103224445679393

Epoch: 6| Step: 10
Training loss: 2.649587285994235
Validation loss: 3.059461038872827

Epoch: 6| Step: 11
Training loss: 3.0312852365864345
Validation loss: 3.0092848145863766

Epoch: 6| Step: 12
Training loss: 3.3815007650917965
Validation loss: 3.012023388575032

Epoch: 6| Step: 13
Training loss: 2.016349011879521
Validation loss: 3.0118587139984228

Epoch: 186| Step: 0
Training loss: 2.738634987265616
Validation loss: 2.9600627673233615

Epoch: 6| Step: 1
Training loss: 2.6121351982107837
Validation loss: 3.064313436609676

Epoch: 6| Step: 2
Training loss: 2.4573790966573963
Validation loss: 3.071567554740954

Epoch: 6| Step: 3
Training loss: 2.896716488613491
Validation loss: 2.967385846171838

Epoch: 6| Step: 4
Training loss: 2.264913407748382
Validation loss: 3.0827433951037397

Epoch: 6| Step: 5
Training loss: 3.391257793953274
Validation loss: 2.9574913763299286

Epoch: 6| Step: 6
Training loss: 2.6371062721592433
Validation loss: 2.9826132246127752

Epoch: 6| Step: 7
Training loss: 3.8138660422506216
Validation loss: 3.05085988554139

Epoch: 6| Step: 8
Training loss: 2.8811523288547987
Validation loss: 3.0022179427279516

Epoch: 6| Step: 9
Training loss: 3.449342062313014
Validation loss: 3.134310548125599

Epoch: 6| Step: 10
Training loss: 2.7152253904977415
Validation loss: 3.026572262166857

Epoch: 6| Step: 11
Training loss: 3.672604752118475
Validation loss: 2.977865187110436

Epoch: 6| Step: 12
Training loss: 2.5355500795552466
Validation loss: 3.0355903430253757

Epoch: 6| Step: 13
Training loss: 2.9503388355729485
Validation loss: 3.149442171615412

Epoch: 187| Step: 0
Training loss: 3.8818616105676194
Validation loss: 3.2204812723544

Epoch: 6| Step: 1
Training loss: 2.588025589788412
Validation loss: 3.1104282922885127

Epoch: 6| Step: 2
Training loss: 2.9818662314444966
Validation loss: 3.021683487517814

Epoch: 6| Step: 3
Training loss: 2.7193722067739476
Validation loss: 3.1897416409032044

Epoch: 6| Step: 4
Training loss: 3.308160350386545
Validation loss: 2.8880696157154353

Epoch: 6| Step: 5
Training loss: 3.0906371823216365
Validation loss: 3.087579722041779

Epoch: 6| Step: 6
Training loss: 2.7697384518698436
Validation loss: 2.977036678850212

Epoch: 6| Step: 7
Training loss: 2.568987565761483
Validation loss: 3.0762222611454235

Epoch: 6| Step: 8
Training loss: 3.0598902579182363
Validation loss: 3.0908329141102

Epoch: 6| Step: 9
Training loss: 3.2671318410677808
Validation loss: 3.103140449458617

Epoch: 6| Step: 10
Training loss: 2.8954939792038865
Validation loss: 2.9634177886737154

Epoch: 6| Step: 11
Training loss: 3.2584359649598977
Validation loss: 2.995324011414925

Epoch: 6| Step: 12
Training loss: 3.2575619095769404
Validation loss: 3.137443328739122

Epoch: 6| Step: 13
Training loss: 2.136663627959584
Validation loss: 3.033601869925175

Epoch: 188| Step: 0
Training loss: 2.684206430384815
Validation loss: 3.097873432831395

Epoch: 6| Step: 1
Training loss: 2.8896349061866355
Validation loss: 3.09858905552992

Epoch: 6| Step: 2
Training loss: 2.1326240204751326
Validation loss: 3.1245009452453925

Epoch: 6| Step: 3
Training loss: 3.509507617160103
Validation loss: 3.1020246571439625

Epoch: 6| Step: 4
Training loss: 3.0199181233605916
Validation loss: 3.03348629523098

Epoch: 6| Step: 5
Training loss: 3.569256448969553
Validation loss: 2.9782954608058145

Epoch: 6| Step: 6
Training loss: 2.7424562327979376
Validation loss: 3.0356428266004527

Epoch: 6| Step: 7
Training loss: 3.4606907328170147
Validation loss: 2.9886286613546846

Epoch: 6| Step: 8
Training loss: 3.051649685584476
Validation loss: 2.8858449048093777

Epoch: 6| Step: 9
Training loss: 3.0827770418659792
Validation loss: 2.9600872927745

Epoch: 6| Step: 10
Training loss: 2.976888003035584
Validation loss: 3.0243168822539808

Epoch: 6| Step: 11
Training loss: 2.8776654037012674
Validation loss: 2.907702316535884

Epoch: 6| Step: 12
Training loss: 2.38397588626776
Validation loss: 2.917915892975796

Epoch: 6| Step: 13
Training loss: 4.242507163802096
Validation loss: 2.851817766384905

Epoch: 189| Step: 0
Training loss: 2.54719232559917
Validation loss: 3.1633357019604778

Epoch: 6| Step: 1
Training loss: 3.7510590647250095
Validation loss: 2.89595366716552

Epoch: 6| Step: 2
Training loss: 3.236986957682867
Validation loss: 3.124195336551472

Epoch: 6| Step: 3
Training loss: 3.408657518061833
Validation loss: 2.949194933892858

Epoch: 6| Step: 4
Training loss: 2.5603595260646426
Validation loss: 3.004281082854314

Epoch: 6| Step: 5
Training loss: 2.9716252908983725
Validation loss: 3.1278268034820056

Epoch: 6| Step: 6
Training loss: 2.782709060451417
Validation loss: 3.056323766733505

Epoch: 6| Step: 7
Training loss: 3.345631007961079
Validation loss: 2.963193135510489

Epoch: 6| Step: 8
Training loss: 2.4589713825734005
Validation loss: 3.057242811094638

Epoch: 6| Step: 9
Training loss: 2.2055626768461107
Validation loss: 2.983507711232219

Epoch: 6| Step: 10
Training loss: 2.6358226920713173
Validation loss: 2.9950616313424563

Epoch: 6| Step: 11
Training loss: 2.949086814101846
Validation loss: 3.0461454962744177

Epoch: 6| Step: 12
Training loss: 3.4550955142828372
Validation loss: 3.1693657726116045

Epoch: 6| Step: 13
Training loss: 3.3460823552313714
Validation loss: 3.0353032516254963

Epoch: 190| Step: 0
Training loss: 4.00703812344044
Validation loss: 3.2174119518763895

Epoch: 6| Step: 1
Training loss: 2.4595556830182623
Validation loss: 3.058219429432774

Epoch: 6| Step: 2
Training loss: 2.643407134781247
Validation loss: 3.1854313719517253

Epoch: 6| Step: 3
Training loss: 2.2132133928609026
Validation loss: 2.98062056548297

Epoch: 6| Step: 4
Training loss: 3.6566793075616584
Validation loss: 3.0254178866283814

Epoch: 6| Step: 5
Training loss: 2.815110923248473
Validation loss: 3.0031907996889986

Epoch: 6| Step: 6
Training loss: 2.618782218061201
Validation loss: 3.036291392486767

Epoch: 6| Step: 7
Training loss: 2.970280945202426
Validation loss: 3.0073287039947436

Epoch: 6| Step: 8
Training loss: 3.011162336632436
Validation loss: 2.9665995487816574

Epoch: 6| Step: 9
Training loss: 2.796477390775606
Validation loss: 3.1871484139918587

Epoch: 6| Step: 10
Training loss: 2.9097444588583605
Validation loss: 2.94862166463524

Epoch: 6| Step: 11
Training loss: 3.6372992915726097
Validation loss: 3.0256575389194493

Epoch: 6| Step: 12
Training loss: 3.279809108622248
Validation loss: 2.987162456476023

Epoch: 6| Step: 13
Training loss: 2.753709198956381
Validation loss: 3.000458993288782

Epoch: 191| Step: 0
Training loss: 3.343524533094645
Validation loss: 2.834383188840882

Epoch: 6| Step: 1
Training loss: 3.09601517798279
Validation loss: 2.9889134183873773

Epoch: 6| Step: 2
Training loss: 2.4874441514383108
Validation loss: 3.104232340319824

Epoch: 6| Step: 3
Training loss: 2.879560419549982
Validation loss: 3.155576660303861

Epoch: 6| Step: 4
Training loss: 3.107210719177111
Validation loss: 3.0484293794605004

Epoch: 6| Step: 5
Training loss: 2.773792684672729
Validation loss: 3.06003283750542

Epoch: 6| Step: 6
Training loss: 3.7352721601037837
Validation loss: 3.098344198528908

Epoch: 6| Step: 7
Training loss: 3.3574977153846994
Validation loss: 3.111321368439717

Epoch: 6| Step: 8
Training loss: 2.775384439868196
Validation loss: 2.9995661912394507

Epoch: 6| Step: 9
Training loss: 2.799843603262202
Validation loss: 3.0885771023579682

Epoch: 6| Step: 10
Training loss: 2.778044149554683
Validation loss: 2.9665481130516462

Epoch: 6| Step: 11
Training loss: 2.311248440615601
Validation loss: 3.1693718861304045

Epoch: 6| Step: 12
Training loss: 3.337352015039774
Validation loss: 3.056234122993631

Epoch: 6| Step: 13
Training loss: 2.8610981402879867
Validation loss: 3.018116851440857

Epoch: 192| Step: 0
Training loss: 2.745212288657499
Validation loss: 3.1659907740677222

Epoch: 6| Step: 1
Training loss: 3.254075209683372
Validation loss: 3.1914315199535905

Epoch: 6| Step: 2
Training loss: 3.1711036984592345
Validation loss: 3.0874256247465506

Epoch: 6| Step: 3
Training loss: 3.3056744483773333
Validation loss: 3.0949839276109787

Epoch: 6| Step: 4
Training loss: 2.050116033294087
Validation loss: 3.150410275452393

Epoch: 6| Step: 5
Training loss: 2.52781047962913
Validation loss: 3.227313881156431

Epoch: 6| Step: 6
Training loss: 2.8875845099958832
Validation loss: 3.046385847340523

Epoch: 6| Step: 7
Training loss: 3.2694078647753453
Validation loss: 3.0179173999720863

Epoch: 6| Step: 8
Training loss: 3.254281378436576
Validation loss: 3.043181399713206

Epoch: 6| Step: 9
Training loss: 2.5525660674598725
Validation loss: 2.9756360573679728

Epoch: 6| Step: 10
Training loss: 3.3395049341573415
Validation loss: 3.0269917131315514

Epoch: 6| Step: 11
Training loss: 3.3727265224068033
Validation loss: 3.028291829166148

Epoch: 6| Step: 12
Training loss: 3.0069218889956213
Validation loss: 3.0582074143585594

Epoch: 6| Step: 13
Training loss: 2.3601444833784804
Validation loss: 3.082092274570476

Epoch: 193| Step: 0
Training loss: 2.7725022149313636
Validation loss: 2.9882865397946494

Epoch: 6| Step: 1
Training loss: 2.9271144299648415
Validation loss: 3.066960374571741

Epoch: 6| Step: 2
Training loss: 2.5803989439070847
Validation loss: 2.9215574707814067

Epoch: 6| Step: 3
Training loss: 2.4244620994898627
Validation loss: 2.972077646848435

Epoch: 6| Step: 4
Training loss: 2.131371538830254
Validation loss: 2.995599303984809

Epoch: 6| Step: 5
Training loss: 2.969876687928963
Validation loss: 3.039651245718331

Epoch: 6| Step: 6
Training loss: 4.465128037687647
Validation loss: 3.029194209049532

Epoch: 6| Step: 7
Training loss: 2.5084166942782433
Validation loss: 3.1068390478942773

Epoch: 6| Step: 8
Training loss: 2.8815385851867266
Validation loss: 3.093981226565325

Epoch: 6| Step: 9
Training loss: 3.0353463406729904
Validation loss: 2.916734658311629

Epoch: 6| Step: 10
Training loss: 2.7933159032230805
Validation loss: 2.9575468945017156

Epoch: 6| Step: 11
Training loss: 3.5206401403268504
Validation loss: 3.071243684737568

Epoch: 6| Step: 12
Training loss: 2.6898681497699797
Validation loss: 2.9507738424574463

Epoch: 6| Step: 13
Training loss: 4.2567300803037185
Validation loss: 3.047202755632629

Epoch: 194| Step: 0
Training loss: 3.2366790673293044
Validation loss: 2.962794596286228

Epoch: 6| Step: 1
Training loss: 3.6668120846667085
Validation loss: 3.0347602292257525

Epoch: 6| Step: 2
Training loss: 2.538468511500707
Validation loss: 3.0114897413502226

Epoch: 6| Step: 3
Training loss: 2.4142438209362185
Validation loss: 2.998561347540735

Epoch: 6| Step: 4
Training loss: 2.123554074397652
Validation loss: 3.2525391579033305

Epoch: 6| Step: 5
Training loss: 3.118925370233775
Validation loss: 2.990070396097013

Epoch: 6| Step: 6
Training loss: 2.747643154396172
Validation loss: 3.0494670888522637

Epoch: 6| Step: 7
Training loss: 2.9385802534982775
Validation loss: 2.9842103125504638

Epoch: 6| Step: 8
Training loss: 3.0482292100223525
Validation loss: 3.1255830282422794

Epoch: 6| Step: 9
Training loss: 1.7613282711919849
Validation loss: 2.9376707431040923

Epoch: 6| Step: 10
Training loss: 3.5336754495308687
Validation loss: 3.063573513935278

Epoch: 6| Step: 11
Training loss: 2.9816242742821037
Validation loss: 3.0053346776934795

Epoch: 6| Step: 12
Training loss: 3.559381558995822
Validation loss: 3.131167731079261

Epoch: 6| Step: 13
Training loss: 3.309673759079666
Validation loss: 2.9768930512767833

Epoch: 195| Step: 0
Training loss: 2.6176326543937347
Validation loss: 3.029924261576846

Epoch: 6| Step: 1
Training loss: 2.49682157647913
Validation loss: 3.0252989867758

Epoch: 6| Step: 2
Training loss: 1.9364575688889178
Validation loss: 2.925400079866105

Epoch: 6| Step: 3
Training loss: 2.5978997367382703
Validation loss: 2.9555233272455923

Epoch: 6| Step: 4
Training loss: 2.1445967311624683
Validation loss: 2.9552135349344595

Epoch: 6| Step: 5
Training loss: 2.1953158667053256
Validation loss: 2.9129544279589004

Epoch: 6| Step: 6
Training loss: 3.857117027115493
Validation loss: 3.016141802670977

Epoch: 6| Step: 7
Training loss: 3.4919770793970955
Validation loss: 2.9152387153003425

Epoch: 6| Step: 8
Training loss: 3.245288661819647
Validation loss: 3.088176373188845

Epoch: 6| Step: 9
Training loss: 2.648436509753917
Validation loss: 3.0261444695044326

Epoch: 6| Step: 10
Training loss: 2.5305748498290184
Validation loss: 3.173144079510688

Epoch: 6| Step: 11
Training loss: 3.94819182524923
Validation loss: 3.0933478446100895

Epoch: 6| Step: 12
Training loss: 3.3590879805621685
Validation loss: 3.138010977772683

Epoch: 6| Step: 13
Training loss: 3.0310991387334343
Validation loss: 3.0107904159545007

Epoch: 196| Step: 0
Training loss: 2.244088885289383
Validation loss: 3.0656593672974015

Epoch: 6| Step: 1
Training loss: 3.3455731421773165
Validation loss: 2.9156547831773474

Epoch: 6| Step: 2
Training loss: 2.8142204956232266
Validation loss: 3.0083970118679426

Epoch: 6| Step: 3
Training loss: 3.0180338197586574
Validation loss: 3.0001666422675957

Epoch: 6| Step: 4
Training loss: 2.938936734385949
Validation loss: 2.9849215673124565

Epoch: 6| Step: 5
Training loss: 2.512703757303386
Validation loss: 3.045497097862883

Epoch: 6| Step: 6
Training loss: 4.152963816297062
Validation loss: 3.154223399511522

Epoch: 6| Step: 7
Training loss: 3.0025204561094117
Validation loss: 3.0700117206700477

Epoch: 6| Step: 8
Training loss: 2.4523522198528673
Validation loss: 3.074249561379161

Epoch: 6| Step: 9
Training loss: 2.212242145922282
Validation loss: 2.912054887728455

Epoch: 6| Step: 10
Training loss: 2.139134242970329
Validation loss: 2.9562059026760674

Epoch: 6| Step: 11
Training loss: 2.2430069652080173
Validation loss: 2.9435659756137085

Epoch: 6| Step: 12
Training loss: 3.1497333595410986
Validation loss: 2.979307096650812

Epoch: 6| Step: 13
Training loss: 3.233431323686959
Validation loss: 3.0384038581615016

Epoch: 197| Step: 0
Training loss: 3.227111030855423
Validation loss: 3.097187825683979

Epoch: 6| Step: 1
Training loss: 1.908942400535441
Validation loss: 3.1051361935763295

Epoch: 6| Step: 2
Training loss: 3.650075018124895
Validation loss: 2.9897103037023594

Epoch: 6| Step: 3
Training loss: 2.559155584485443
Validation loss: 3.191872337519772

Epoch: 6| Step: 4
Training loss: 3.1389785930077383
Validation loss: 3.0491325805178686

Epoch: 6| Step: 5
Training loss: 3.192711253992003
Validation loss: 3.1976676786000873

Epoch: 6| Step: 6
Training loss: 2.588498049291149
Validation loss: 2.9768664484478062

Epoch: 6| Step: 7
Training loss: 1.823756484084862
Validation loss: 2.8871455373774726

Epoch: 6| Step: 8
Training loss: 3.350076412638974
Validation loss: 3.098091024940419

Epoch: 6| Step: 9
Training loss: 2.118145490171863
Validation loss: 3.0292805019301228

Epoch: 6| Step: 10
Training loss: 2.6966922490337186
Validation loss: 2.88463186274582

Epoch: 6| Step: 11
Training loss: 3.1784107541151756
Validation loss: 3.0186071105713568

Epoch: 6| Step: 12
Training loss: 3.6880261320648824
Validation loss: 2.9569087870176975

Epoch: 6| Step: 13
Training loss: 3.196055729242885
Validation loss: 2.881382599110775

Epoch: 198| Step: 0
Training loss: 3.248924224045003
Validation loss: 3.2461295070554237

Epoch: 6| Step: 1
Training loss: 2.136153960683522
Validation loss: 3.1553891068960884

Epoch: 6| Step: 2
Training loss: 3.44781818230032
Validation loss: 2.976147226813369

Epoch: 6| Step: 3
Training loss: 2.5228503226123378
Validation loss: 3.139959467350704

Epoch: 6| Step: 4
Training loss: 3.223253969190505
Validation loss: 3.0139434970428542

Epoch: 6| Step: 5
Training loss: 3.03802111515746
Validation loss: 2.9995553129740298

Epoch: 6| Step: 6
Training loss: 2.31901786470297
Validation loss: 2.8838919142684807

Epoch: 6| Step: 7
Training loss: 2.763323758579994
Validation loss: 2.9877033157079

Epoch: 6| Step: 8
Training loss: 2.7700744870909126
Validation loss: 2.935909789467503

Epoch: 6| Step: 9
Training loss: 3.7972600294263628
Validation loss: 3.0653181254470017

Epoch: 6| Step: 10
Training loss: 3.449219026489938
Validation loss: 3.0533341039963005

Epoch: 6| Step: 11
Training loss: 3.564298610734911
Validation loss: 2.990481121181877

Epoch: 6| Step: 12
Training loss: 2.4249360459536518
Validation loss: 2.9974589131076845

Epoch: 6| Step: 13
Training loss: 2.4338760824514063
Validation loss: 2.960226433925052

Epoch: 199| Step: 0
Training loss: 2.2595404642174555
Validation loss: 3.0071125862762655

Epoch: 6| Step: 1
Training loss: 3.2226784445258456
Validation loss: 3.2398577578079846

Epoch: 6| Step: 2
Training loss: 3.7322215491112516
Validation loss: 2.9142314735764656

Epoch: 6| Step: 3
Training loss: 2.6070399086739546
Validation loss: 2.867761771310444

Epoch: 6| Step: 4
Training loss: 2.974378530520664
Validation loss: 3.170540600522048

Epoch: 6| Step: 5
Training loss: 2.412126276984052
Validation loss: 2.9592790618601534

Epoch: 6| Step: 6
Training loss: 2.7175125287424287
Validation loss: 2.9519619430779835

Epoch: 6| Step: 7
Training loss: 2.706582564783989
Validation loss: 2.940255524982198

Epoch: 6| Step: 8
Training loss: 3.571207614603094
Validation loss: 2.9953972653661123

Epoch: 6| Step: 9
Training loss: 2.68316922446147
Validation loss: 3.0630481908230838

Epoch: 6| Step: 10
Training loss: 2.7260468003474054
Validation loss: 3.341875804784262

Epoch: 6| Step: 11
Training loss: 3.095317404992012
Validation loss: 3.0758143396747095

Epoch: 6| Step: 12
Training loss: 3.230544471083919
Validation loss: 3.2220859621360596

Epoch: 6| Step: 13
Training loss: 2.844781374182299
Validation loss: 3.0155937715605514

Epoch: 200| Step: 0
Training loss: 3.3138715675528756
Validation loss: 3.128689608785283

Epoch: 6| Step: 1
Training loss: 2.414428584417379
Validation loss: 3.0240265757635494

Epoch: 6| Step: 2
Training loss: 2.836022241760759
Validation loss: 3.079010054094428

Epoch: 6| Step: 3
Training loss: 3.6282117361762194
Validation loss: 3.004657643650696

Epoch: 6| Step: 4
Training loss: 3.0983116351334514
Validation loss: 2.906555211799375

Epoch: 6| Step: 5
Training loss: 2.732875041998485
Validation loss: 3.020452078302451

Epoch: 6| Step: 6
Training loss: 3.0192968911720186
Validation loss: 2.978040235410421

Epoch: 6| Step: 7
Training loss: 2.5734200750894782
Validation loss: 2.745064838666574

Epoch: 6| Step: 8
Training loss: 2.7945921548120505
Validation loss: 3.032306807878306

Epoch: 6| Step: 9
Training loss: 3.2988518306948715
Validation loss: 2.9975493601060577

Epoch: 6| Step: 10
Training loss: 3.2898736891225564
Validation loss: 3.0817399024698826

Epoch: 6| Step: 11
Training loss: 3.6258012609539905
Validation loss: 2.9814611872863694

Epoch: 6| Step: 12
Training loss: 2.3064593212378366
Validation loss: 2.9992728103997464

Epoch: 6| Step: 13
Training loss: 2.9308950961708438
Validation loss: 3.1138877793005055

Epoch: 201| Step: 0
Training loss: 2.4496344741316505
Validation loss: 3.0815702648024605

Epoch: 6| Step: 1
Training loss: 2.8988058262327066
Validation loss: 3.05939441615964

Epoch: 6| Step: 2
Training loss: 2.525653633648257
Validation loss: 3.0872403218347477

Epoch: 6| Step: 3
Training loss: 2.675891111025938
Validation loss: 3.093870965841094

Epoch: 6| Step: 4
Training loss: 3.011676476326613
Validation loss: 2.85987197248366

Epoch: 6| Step: 5
Training loss: 1.8500479124927216
Validation loss: 3.1241309436248135

Epoch: 6| Step: 6
Training loss: 3.19515520748629
Validation loss: 3.0883715030598133

Epoch: 6| Step: 7
Training loss: 4.179725375850583
Validation loss: 3.0884185466551326

Epoch: 6| Step: 8
Training loss: 3.128624454529183
Validation loss: 3.044799219594822

Epoch: 6| Step: 9
Training loss: 3.0368608281035896
Validation loss: 3.0433399544228856

Epoch: 6| Step: 10
Training loss: 3.4549823443655874
Validation loss: 3.002392283314976

Epoch: 6| Step: 11
Training loss: 2.752589480464064
Validation loss: 2.9605143830767062

Epoch: 6| Step: 12
Training loss: 3.045975146316854
Validation loss: 2.9537166956093857

Epoch: 6| Step: 13
Training loss: 2.8360092952667406
Validation loss: 2.9169552415637034

Epoch: 202| Step: 0
Training loss: 2.280189162990333
Validation loss: 2.991481875479215

Epoch: 6| Step: 1
Training loss: 2.885350379228333
Validation loss: 3.0280596960065154

Epoch: 6| Step: 2
Training loss: 3.1695707623823486
Validation loss: 3.0584947094909416

Epoch: 6| Step: 3
Training loss: 2.5502402884271596
Validation loss: 2.968740573559375

Epoch: 6| Step: 4
Training loss: 3.3717946973683275
Validation loss: 2.988969194748171

Epoch: 6| Step: 5
Training loss: 2.499565468217871
Validation loss: 2.973991659505085

Epoch: 6| Step: 6
Training loss: 3.7132351799211167
Validation loss: 3.0323397917872974

Epoch: 6| Step: 7
Training loss: 3.1697458722511684
Validation loss: 3.0412658672325903

Epoch: 6| Step: 8
Training loss: 2.644659087163579
Validation loss: 2.9496343291484473

Epoch: 6| Step: 9
Training loss: 2.928739755558034
Validation loss: 3.094041648385412

Epoch: 6| Step: 10
Training loss: 2.5511461262768127
Validation loss: 3.002343474230972

Epoch: 6| Step: 11
Training loss: 2.3095663897297554
Validation loss: 3.102947772668765

Epoch: 6| Step: 12
Training loss: 3.400988373428926
Validation loss: 3.119568470097699

Epoch: 6| Step: 13
Training loss: 2.2118852828218767
Validation loss: 2.982676663577101

Epoch: 203| Step: 0
Training loss: 2.987463027533788
Validation loss: 2.9021446985544834

Epoch: 6| Step: 1
Training loss: 3.198974301940023
Validation loss: 3.047824761443898

Epoch: 6| Step: 2
Training loss: 3.133345028334632
Validation loss: 3.0786406141031937

Epoch: 6| Step: 3
Training loss: 2.7503399205366077
Validation loss: 3.0458844169327124

Epoch: 6| Step: 4
Training loss: 2.614698997664678
Validation loss: 3.042201094820819

Epoch: 6| Step: 5
Training loss: 3.155459767739908
Validation loss: 3.1161055275295055

Epoch: 6| Step: 6
Training loss: 3.4181107671388684
Validation loss: 3.099550410717464

Epoch: 6| Step: 7
Training loss: 2.5629558622955635
Validation loss: 2.979629790105704

Epoch: 6| Step: 8
Training loss: 2.315786346291981
Validation loss: 3.067647164971754

Epoch: 6| Step: 9
Training loss: 3.9751860329142907
Validation loss: 2.950260148484273

Epoch: 6| Step: 10
Training loss: 3.714443758861364
Validation loss: 2.9945847471998364

Epoch: 6| Step: 11
Training loss: 2.9788055378886606
Validation loss: 3.1258092599447647

Epoch: 6| Step: 12
Training loss: 2.338360400633472
Validation loss: 2.861458405628185

Epoch: 6| Step: 13
Training loss: 3.5233958172077116
Validation loss: 2.912853765887109

Epoch: 204| Step: 0
Training loss: 3.490717431247401
Validation loss: 3.0807027617570926

Epoch: 6| Step: 1
Training loss: 2.542611889623039
Validation loss: 3.048916945534305

Epoch: 6| Step: 2
Training loss: 2.7353993268321695
Validation loss: 2.938031475133676

Epoch: 6| Step: 3
Training loss: 3.00199172343232
Validation loss: 3.073213166201519

Epoch: 6| Step: 4
Training loss: 1.982650788719273
Validation loss: 3.021219024109762

Epoch: 6| Step: 5
Training loss: 3.8507250016496997
Validation loss: 2.9979646659242722

Epoch: 6| Step: 6
Training loss: 3.567174956090379
Validation loss: 3.047366682903878

Epoch: 6| Step: 7
Training loss: 1.8064723580845852
Validation loss: 2.938948219092735

Epoch: 6| Step: 8
Training loss: 3.022595192141455
Validation loss: 3.045103135856327

Epoch: 6| Step: 9
Training loss: 2.351901616075902
Validation loss: 2.8106681126410074

Epoch: 6| Step: 10
Training loss: 2.943272701371912
Validation loss: 3.0099924217719876

Epoch: 6| Step: 11
Training loss: 2.620165778586422
Validation loss: 3.0583832884375126

Epoch: 6| Step: 12
Training loss: 2.7376879867038766
Validation loss: 3.2166602095481163

Epoch: 6| Step: 13
Training loss: 3.3413465186384346
Validation loss: 2.933083089402319

Epoch: 205| Step: 0
Training loss: 3.439350809008403
Validation loss: 2.89983309709985

Epoch: 6| Step: 1
Training loss: 3.635577849537653
Validation loss: 2.9845509858684127

Epoch: 6| Step: 2
Training loss: 2.874519307959342
Validation loss: 3.0764875573400925

Epoch: 6| Step: 3
Training loss: 2.757810684506086
Validation loss: 2.941240758657743

Epoch: 6| Step: 4
Training loss: 2.6072437468415446
Validation loss: 3.121419506821939

Epoch: 6| Step: 5
Training loss: 3.5031791961860614
Validation loss: 2.9248083899048942

Epoch: 6| Step: 6
Training loss: 2.240724943903414
Validation loss: 2.826374852885864

Epoch: 6| Step: 7
Training loss: 3.1342657433405243
Validation loss: 3.018748973405591

Epoch: 6| Step: 8
Training loss: 2.7731980771161395
Validation loss: 3.050199924938728

Epoch: 6| Step: 9
Training loss: 1.8808537341515557
Validation loss: 2.835825387561368

Epoch: 6| Step: 10
Training loss: 3.228997962400491
Validation loss: 3.129581068269679

Epoch: 6| Step: 11
Training loss: 2.9972949548223666
Validation loss: 2.9255345579243976

Epoch: 6| Step: 12
Training loss: 2.2504829312321144
Validation loss: 2.91356167449382

Epoch: 6| Step: 13
Training loss: 3.116279641938877
Validation loss: 3.034989325098526

Epoch: 206| Step: 0
Training loss: 3.111246283940096
Validation loss: 2.8790219857033286

Epoch: 6| Step: 1
Training loss: 2.6794880161604677
Validation loss: 2.979895195379906

Epoch: 6| Step: 2
Training loss: 2.4590359561954975
Validation loss: 3.1512145856441265

Epoch: 6| Step: 3
Training loss: 2.755654503812981
Validation loss: 2.9226716921714435

Epoch: 6| Step: 4
Training loss: 2.7146051315716666
Validation loss: 2.955915544249897

Epoch: 6| Step: 5
Training loss: 2.941911023358856
Validation loss: 3.090958666125584

Epoch: 6| Step: 6
Training loss: 3.1933392165361445
Validation loss: 3.0865566917525027

Epoch: 6| Step: 7
Training loss: 2.9917602233992557
Validation loss: 3.110763697287855

Epoch: 6| Step: 8
Training loss: 3.529688937392497
Validation loss: 3.175211853130763

Epoch: 6| Step: 9
Training loss: 2.051278306578617
Validation loss: 3.2522264100619758

Epoch: 6| Step: 10
Training loss: 3.455900017952202
Validation loss: 3.1439920994399113

Epoch: 6| Step: 11
Training loss: 3.055869729815561
Validation loss: 3.068973617872231

Epoch: 6| Step: 12
Training loss: 3.8255529365551513
Validation loss: 3.0753815695741484

Epoch: 6| Step: 13
Training loss: 1.9799816728957498
Validation loss: 3.1420860420475147

Epoch: 207| Step: 0
Training loss: 2.899249762469709
Validation loss: 2.8927521926857804

Epoch: 6| Step: 1
Training loss: 2.8708472736464956
Validation loss: 3.0554108084485456

Epoch: 6| Step: 2
Training loss: 3.150021592323534
Validation loss: 3.158114757718694

Epoch: 6| Step: 3
Training loss: 2.977218595670504
Validation loss: 2.9875640641219325

Epoch: 6| Step: 4
Training loss: 3.2245871937645645
Validation loss: 3.083368759040451

Epoch: 6| Step: 5
Training loss: 2.796631019222633
Validation loss: 2.9155742591828777

Epoch: 6| Step: 6
Training loss: 2.8225381369839813
Validation loss: 2.9348892447831534

Epoch: 6| Step: 7
Training loss: 2.9177736270730072
Validation loss: 2.834442687571519

Epoch: 6| Step: 8
Training loss: 4.210692446342471
Validation loss: 2.959038692086696

Epoch: 6| Step: 9
Training loss: 2.44577636219156
Validation loss: 3.118335991876921

Epoch: 6| Step: 10
Training loss: 2.1656620435312597
Validation loss: 2.9846912764712443

Epoch: 6| Step: 11
Training loss: 2.2574979041545005
Validation loss: 2.9519144261501356

Epoch: 6| Step: 12
Training loss: 2.41476617822422
Validation loss: 3.1186368841149408

Epoch: 6| Step: 13
Training loss: 2.4506100926508876
Validation loss: 2.952706475677236

Epoch: 208| Step: 0
Training loss: 2.9453524882791875
Validation loss: 3.0391955978275424

Epoch: 6| Step: 1
Training loss: 1.9810202167486506
Validation loss: 2.9105056371270384

Epoch: 6| Step: 2
Training loss: 2.4985644987559077
Validation loss: 2.9121290592918627

Epoch: 6| Step: 3
Training loss: 3.041591974325493
Validation loss: 3.0456861273179716

Epoch: 6| Step: 4
Training loss: 4.081042652792437
Validation loss: 3.011801186297584

Epoch: 6| Step: 5
Training loss: 3.151221168806837
Validation loss: 2.9436207862274304

Epoch: 6| Step: 6
Training loss: 3.2212140179520334
Validation loss: 3.031185159178963

Epoch: 6| Step: 7
Training loss: 2.753744177411712
Validation loss: 2.8618878196931883

Epoch: 6| Step: 8
Training loss: 2.560310172423668
Validation loss: 3.0384498343685773

Epoch: 6| Step: 9
Training loss: 1.7386306240147977
Validation loss: 3.0046536096133787

Epoch: 6| Step: 10
Training loss: 3.8139573110462837
Validation loss: 2.9346182500350557

Epoch: 6| Step: 11
Training loss: 3.1861056101525276
Validation loss: 3.042931221492255

Epoch: 6| Step: 12
Training loss: 3.190411005120155
Validation loss: 2.938394407290085

Epoch: 6| Step: 13
Training loss: 3.7245365289726795
Validation loss: 3.121713692988613

Epoch: 209| Step: 0
Training loss: 3.1712775207937263
Validation loss: 2.914623426118976

Epoch: 6| Step: 1
Training loss: 2.517815435927934
Validation loss: 3.1338185584839042

Epoch: 6| Step: 2
Training loss: 2.8103929044050275
Validation loss: 2.996395930275254

Epoch: 6| Step: 3
Training loss: 2.7276179066320996
Validation loss: 3.0603650997522984

Epoch: 6| Step: 4
Training loss: 3.8745786376250804
Validation loss: 2.9800974255828865

Epoch: 6| Step: 5
Training loss: 3.5183108772297267
Validation loss: 3.0208737589528987

Epoch: 6| Step: 6
Training loss: 3.093451745655289
Validation loss: 3.0289011427336994

Epoch: 6| Step: 7
Training loss: 2.9434494480660462
Validation loss: 3.0271358498787526

Epoch: 6| Step: 8
Training loss: 1.971123793195754
Validation loss: 2.978395471649142

Epoch: 6| Step: 9
Training loss: 2.927693983210365
Validation loss: 3.3194703195940156

Epoch: 6| Step: 10
Training loss: 2.787501649043532
Validation loss: 2.97416198894036

Epoch: 6| Step: 11
Training loss: 3.036011093119382
Validation loss: 3.0582539143532617

Epoch: 6| Step: 12
Training loss: 3.5453915623759253
Validation loss: 3.091852648123319

Epoch: 6| Step: 13
Training loss: 1.7467953767867739
Validation loss: 3.104264479061897

Epoch: 210| Step: 0
Training loss: 3.3212129695781982
Validation loss: 3.1172741984220504

Epoch: 6| Step: 1
Training loss: 3.1400540720177594
Validation loss: 3.065248447701535

Epoch: 6| Step: 2
Training loss: 2.5034586823324063
Validation loss: 3.1048482064265834

Epoch: 6| Step: 3
Training loss: 2.821238864915581
Validation loss: 3.1478590712175545

Epoch: 6| Step: 4
Training loss: 2.709686958278619
Validation loss: 3.057603593778004

Epoch: 6| Step: 5
Training loss: 2.413718979970539
Validation loss: 3.1002460948040325

Epoch: 6| Step: 6
Training loss: 2.241519522771456
Validation loss: 3.1277498382406725

Epoch: 6| Step: 7
Training loss: 2.907754324157349
Validation loss: 3.0653887767559165

Epoch: 6| Step: 8
Training loss: 2.399278126872817
Validation loss: 2.885339331568778

Epoch: 6| Step: 9
Training loss: 3.454532112205329
Validation loss: 2.9837424375571904

Epoch: 6| Step: 10
Training loss: 2.729425539352892
Validation loss: 3.1983667743447963

Epoch: 6| Step: 11
Training loss: 2.7878049264579827
Validation loss: 3.0618128755966847

Epoch: 6| Step: 12
Training loss: 4.650941626258521
Validation loss: 3.1988129835567216

Epoch: 6| Step: 13
Training loss: 2.9413628036715
Validation loss: 2.9834453782282377

Epoch: 211| Step: 0
Training loss: 3.1817344431571377
Validation loss: 3.01709090885682

Epoch: 6| Step: 1
Training loss: 3.508442913406992
Validation loss: 3.0281809866085685

Epoch: 6| Step: 2
Training loss: 3.397719033249549
Validation loss: 2.8735469679205

Epoch: 6| Step: 3
Training loss: 2.5264689185765183
Validation loss: 2.889496465641624

Epoch: 6| Step: 4
Training loss: 2.4199738947193308
Validation loss: 2.8926615823362334

Epoch: 6| Step: 5
Training loss: 2.822502744012788
Validation loss: 2.9313076137554455

Epoch: 6| Step: 6
Training loss: 2.4546469079831206
Validation loss: 2.9452090181674824

Epoch: 6| Step: 7
Training loss: 2.618897929599705
Validation loss: 2.928078568758747

Epoch: 6| Step: 8
Training loss: 3.0464226802678884
Validation loss: 2.96073010619552

Epoch: 6| Step: 9
Training loss: 4.0517197995851815
Validation loss: 3.0547579507073594

Epoch: 6| Step: 10
Training loss: 3.2590935473106737
Validation loss: 3.106657921551099

Epoch: 6| Step: 11
Training loss: 3.272034264653251
Validation loss: 3.0711513211445243

Epoch: 6| Step: 12
Training loss: 2.518362699884865
Validation loss: 3.08632791338507

Epoch: 6| Step: 13
Training loss: 1.804364790694315
Validation loss: 3.0043569505381362

Epoch: 212| Step: 0
Training loss: 3.6720723849872483
Validation loss: 2.932317625057028

Epoch: 6| Step: 1
Training loss: 2.536078474882376
Validation loss: 3.1072781721913363

Epoch: 6| Step: 2
Training loss: 2.7441328055382366
Validation loss: 3.111908425822719

Epoch: 6| Step: 3
Training loss: 3.1237112821245603
Validation loss: 2.9474804599458038

Epoch: 6| Step: 4
Training loss: 3.384753227761486
Validation loss: 3.0067621999832417

Epoch: 6| Step: 5
Training loss: 1.992118086260072
Validation loss: 2.9689472143775744

Epoch: 6| Step: 6
Training loss: 2.7579099297536067
Validation loss: 2.960116842910434

Epoch: 6| Step: 7
Training loss: 3.936393340072991
Validation loss: 3.0052315565399024

Epoch: 6| Step: 8
Training loss: 3.227446132597469
Validation loss: 2.840182414394827

Epoch: 6| Step: 9
Training loss: 2.7025500441301418
Validation loss: 3.0407446861498237

Epoch: 6| Step: 10
Training loss: 2.7221596920417896
Validation loss: 3.10723491649316

Epoch: 6| Step: 11
Training loss: 2.8992395653641743
Validation loss: 3.0693659208983326

Epoch: 6| Step: 12
Training loss: 2.2164850629066137
Validation loss: 3.0051967600508624

Epoch: 6| Step: 13
Training loss: 3.457153869868081
Validation loss: 2.9960236405939993

Epoch: 213| Step: 0
Training loss: 2.4856963092799114
Validation loss: 2.966011092199523

Epoch: 6| Step: 1
Training loss: 2.90806801650564
Validation loss: 3.094403707152752

Epoch: 6| Step: 2
Training loss: 3.4868571246068965
Validation loss: 2.960032208524372

Epoch: 6| Step: 3
Training loss: 2.5256654334660835
Validation loss: 2.9746220018072536

Epoch: 6| Step: 4
Training loss: 2.9493141411518446
Validation loss: 3.0120958202033448

Epoch: 6| Step: 5
Training loss: 1.9240153110275608
Validation loss: 3.0300801494279077

Epoch: 6| Step: 6
Training loss: 2.466615840886548
Validation loss: 2.926923138231533

Epoch: 6| Step: 7
Training loss: 4.038312063839442
Validation loss: 3.1073550999744146

Epoch: 6| Step: 8
Training loss: 3.1448111652394406
Validation loss: 3.005375024035524

Epoch: 6| Step: 9
Training loss: 2.2628596826087715
Validation loss: 3.012355442567404

Epoch: 6| Step: 10
Training loss: 2.3689848368245188
Validation loss: 2.955110709523089

Epoch: 6| Step: 11
Training loss: 3.2925067907913608
Validation loss: 2.8913190093360286

Epoch: 6| Step: 12
Training loss: 4.167781578945197
Validation loss: 2.974037052275956

Epoch: 6| Step: 13
Training loss: 2.7996590679235296
Validation loss: 2.9645927314614235

Epoch: 214| Step: 0
Training loss: 3.7767276675714916
Validation loss: 3.0807750074621096

Epoch: 6| Step: 1
Training loss: 2.2603036409824404
Validation loss: 3.033263136457029

Epoch: 6| Step: 2
Training loss: 2.6279443848878303
Validation loss: 2.9593260291230665

Epoch: 6| Step: 3
Training loss: 2.523462254075083
Validation loss: 3.1248281091156

Epoch: 6| Step: 4
Training loss: 2.9859153407385994
Validation loss: 2.96929313384693

Epoch: 6| Step: 5
Training loss: 2.8129534885590246
Validation loss: 3.0251553777514983

Epoch: 6| Step: 6
Training loss: 1.9062887719385653
Validation loss: 2.9719036094318696

Epoch: 6| Step: 7
Training loss: 3.2409158074055116
Validation loss: 3.0749368897398064

Epoch: 6| Step: 8
Training loss: 2.6125531058868643
Validation loss: 3.0336586039371087

Epoch: 6| Step: 9
Training loss: 2.75699341797484
Validation loss: 3.1872873325810858

Epoch: 6| Step: 10
Training loss: 1.7472647680787496
Validation loss: 2.952397553957122

Epoch: 6| Step: 11
Training loss: 3.585693750013277
Validation loss: 2.952359509788344

Epoch: 6| Step: 12
Training loss: 3.13748771391511
Validation loss: 3.0701686835154933

Epoch: 6| Step: 13
Training loss: 3.8429235795001726
Validation loss: 3.1455670620084346

Epoch: 215| Step: 0
Training loss: 3.1415199029642027
Validation loss: 2.925308341563775

Epoch: 6| Step: 1
Training loss: 3.001781888109824
Validation loss: 3.174110115290185

Epoch: 6| Step: 2
Training loss: 2.7126828602272877
Validation loss: 3.16510563463505

Epoch: 6| Step: 3
Training loss: 3.696652062756718
Validation loss: 3.117456462847636

Epoch: 6| Step: 4
Training loss: 2.6153698431003463
Validation loss: 2.9195021673911143

Epoch: 6| Step: 5
Training loss: 2.2543681446602584
Validation loss: 3.0465410300352986

Epoch: 6| Step: 6
Training loss: 3.402063299066749
Validation loss: 2.982943294031418

Epoch: 6| Step: 7
Training loss: 2.5354503114255196
Validation loss: 3.06714189017508

Epoch: 6| Step: 8
Training loss: 2.235658077158461
Validation loss: 3.0680010980227435

Epoch: 6| Step: 9
Training loss: 3.073008666304668
Validation loss: 2.921531407424938

Epoch: 6| Step: 10
Training loss: 2.9077295618461467
Validation loss: 2.8346892580256493

Epoch: 6| Step: 11
Training loss: 2.9404032543543708
Validation loss: 2.864009210025784

Epoch: 6| Step: 12
Training loss: 3.5026248898182653
Validation loss: 2.9972636158032286

Epoch: 6| Step: 13
Training loss: 2.337220314959456
Validation loss: 3.0233647524632032

Epoch: 216| Step: 0
Training loss: 3.1489929769370444
Validation loss: 3.1716248555933046

Epoch: 6| Step: 1
Training loss: 1.8174377793860501
Validation loss: 3.088248852480897

Epoch: 6| Step: 2
Training loss: 4.126046712606315
Validation loss: 3.063888946378898

Epoch: 6| Step: 3
Training loss: 1.5448697125952218
Validation loss: 3.017019395042091

Epoch: 6| Step: 4
Training loss: 3.683134177737192
Validation loss: 2.987477938415732

Epoch: 6| Step: 5
Training loss: 3.036862084235066
Validation loss: 2.9901486417165124

Epoch: 6| Step: 6
Training loss: 2.8611373056572678
Validation loss: 3.0216715231502804

Epoch: 6| Step: 7
Training loss: 2.3234911380776957
Validation loss: 2.93392355533275

Epoch: 6| Step: 8
Training loss: 2.7697063439119947
Validation loss: 2.9860236414958594

Epoch: 6| Step: 9
Training loss: 2.057583121084273
Validation loss: 3.0424310493817797

Epoch: 6| Step: 10
Training loss: 2.016226508706703
Validation loss: 3.0392274340206993

Epoch: 6| Step: 11
Training loss: 3.255095082665387
Validation loss: 3.078535919636991

Epoch: 6| Step: 12
Training loss: 2.822966871952989
Validation loss: 2.8516269876018323

Epoch: 6| Step: 13
Training loss: 3.869708478332107
Validation loss: 3.0730319449755448

Epoch: 217| Step: 0
Training loss: 2.6585771128010323
Validation loss: 2.931374697935734

Epoch: 6| Step: 1
Training loss: 3.3595598036922873
Validation loss: 3.030576144945311

Epoch: 6| Step: 2
Training loss: 2.9989857548613545
Validation loss: 3.0071757611740018

Epoch: 6| Step: 3
Training loss: 2.562158515320509
Validation loss: 2.836908262725296

Epoch: 6| Step: 4
Training loss: 2.9871276623443093
Validation loss: 2.9430080971516706

Epoch: 6| Step: 5
Training loss: 2.695309492468884
Validation loss: 3.101005360543683

Epoch: 6| Step: 6
Training loss: 2.828933515946687
Validation loss: 3.0482561950696265

Epoch: 6| Step: 7
Training loss: 2.903911839547267
Validation loss: 3.0583267322715044

Epoch: 6| Step: 8
Training loss: 2.812984170564715
Validation loss: 3.070759240367191

Epoch: 6| Step: 9
Training loss: 2.6823783687664795
Validation loss: 2.970960754824645

Epoch: 6| Step: 10
Training loss: 2.8920172560349813
Validation loss: 3.009960930481836

Epoch: 6| Step: 11
Training loss: 2.7250647160955976
Validation loss: 3.0506957879877667

Epoch: 6| Step: 12
Training loss: 3.200426705044243
Validation loss: 3.0954361405254898

Epoch: 6| Step: 13
Training loss: 2.860713957923801
Validation loss: 3.0581493342677177

Epoch: 218| Step: 0
Training loss: 3.751671990540934
Validation loss: 3.1839023952069887

Epoch: 6| Step: 1
Training loss: 2.4168398784081186
Validation loss: 3.0676288621950545

Epoch: 6| Step: 2
Training loss: 3.2803326005475184
Validation loss: 3.1150184223464685

Epoch: 6| Step: 3
Training loss: 2.8608434689797178
Validation loss: 3.001424603288967

Epoch: 6| Step: 4
Training loss: 3.0483269777504596
Validation loss: 2.9776630945849596

Epoch: 6| Step: 5
Training loss: 2.3179891237624175
Validation loss: 2.9808299243980705

Epoch: 6| Step: 6
Training loss: 3.044088018240105
Validation loss: 3.0562269510453217

Epoch: 6| Step: 7
Training loss: 2.6299367531543494
Validation loss: 3.0259559594782752

Epoch: 6| Step: 8
Training loss: 2.3110462464905304
Validation loss: 3.1122236184224206

Epoch: 6| Step: 9
Training loss: 3.7254212109307234
Validation loss: 2.914883228009738

Epoch: 6| Step: 10
Training loss: 2.2851591713389445
Validation loss: 2.940360815048831

Epoch: 6| Step: 11
Training loss: 2.937954968870164
Validation loss: 3.056656674966692

Epoch: 6| Step: 12
Training loss: 2.3870799389139914
Validation loss: 3.017623855250149

Epoch: 6| Step: 13
Training loss: 2.962180327217536
Validation loss: 2.938067600217542

Epoch: 219| Step: 0
Training loss: 2.0151695505753153
Validation loss: 3.0005700738768915

Epoch: 6| Step: 1
Training loss: 3.463502506044279
Validation loss: 3.1125756388428045

Epoch: 6| Step: 2
Training loss: 3.6984542814066628
Validation loss: 2.9182589633545044

Epoch: 6| Step: 3
Training loss: 2.3532254748531956
Validation loss: 2.861574041605145

Epoch: 6| Step: 4
Training loss: 2.3059634022848243
Validation loss: 2.992110771969612

Epoch: 6| Step: 5
Training loss: 3.084531980653281
Validation loss: 3.120437898351435

Epoch: 6| Step: 6
Training loss: 2.6272899993107948
Validation loss: 2.9748063888000456

Epoch: 6| Step: 7
Training loss: 2.2336673282807706
Validation loss: 3.0240378848249194

Epoch: 6| Step: 8
Training loss: 2.6318007882625007
Validation loss: 3.0590414475175316

Epoch: 6| Step: 9
Training loss: 4.034831740263924
Validation loss: 3.015218110613623

Epoch: 6| Step: 10
Training loss: 2.925285429762548
Validation loss: 2.945459093184367

Epoch: 6| Step: 11
Training loss: 3.1058020838693956
Validation loss: 2.923681408271952

Epoch: 6| Step: 12
Training loss: 3.736620878085955
Validation loss: 2.8306204573862694

Epoch: 6| Step: 13
Training loss: 2.7379763184464423
Validation loss: 3.072212018034112

Epoch: 220| Step: 0
Training loss: 2.687813496602227
Validation loss: 2.9280812163809316

Epoch: 6| Step: 1
Training loss: 2.8877980198170503
Validation loss: 2.896057526279004

Epoch: 6| Step: 2
Training loss: 2.6474458081225762
Validation loss: 3.0683522539519674

Epoch: 6| Step: 3
Training loss: 3.2108056257134723
Validation loss: 2.9872526642667547

Epoch: 6| Step: 4
Training loss: 3.0654027766917693
Validation loss: 2.8769435795667406

Epoch: 6| Step: 5
Training loss: 2.4399372533641115
Validation loss: 2.9995173883041404

Epoch: 6| Step: 6
Training loss: 3.288650305645875
Validation loss: 3.1809934786375544

Epoch: 6| Step: 7
Training loss: 2.7474045209461035
Validation loss: 2.9110913555093125

Epoch: 6| Step: 8
Training loss: 3.226360323947312
Validation loss: 3.0794902559937776

Epoch: 6| Step: 9
Training loss: 3.4277822290106887
Validation loss: 2.8699745888328425

Epoch: 6| Step: 10
Training loss: 3.085184280604335
Validation loss: 2.9350421950294865

Epoch: 6| Step: 11
Training loss: 2.7928985800298083
Validation loss: 2.9199274782796554

Epoch: 6| Step: 12
Training loss: 2.7694730550788207
Validation loss: 2.9667060711400524

Epoch: 6| Step: 13
Training loss: 3.745316314377034
Validation loss: 2.7846512155890046

Epoch: 221| Step: 0
Training loss: 2.042005964877601
Validation loss: 3.004946733850678

Epoch: 6| Step: 1
Training loss: 2.624339429301314
Validation loss: 2.9502891218783733

Epoch: 6| Step: 2
Training loss: 2.2772308897447178
Validation loss: 2.9948298937197824

Epoch: 6| Step: 3
Training loss: 2.6146584204926793
Validation loss: 2.9114803477963336

Epoch: 6| Step: 4
Training loss: 2.7543100047552604
Validation loss: 3.0736128068430406

Epoch: 6| Step: 5
Training loss: 3.6938660837383215
Validation loss: 3.004112043833232

Epoch: 6| Step: 6
Training loss: 2.4257382006672255
Validation loss: 2.9152557552494733

Epoch: 6| Step: 7
Training loss: 3.177326197279092
Validation loss: 2.9281541668861797

Epoch: 6| Step: 8
Training loss: 3.3807899824984275
Validation loss: 2.9741520383333944

Epoch: 6| Step: 9
Training loss: 3.3018555828377765
Validation loss: 2.8930229566239825

Epoch: 6| Step: 10
Training loss: 3.1478264833395544
Validation loss: 2.9189155493193035

Epoch: 6| Step: 11
Training loss: 2.8820710508018563
Validation loss: 2.978328844894958

Epoch: 6| Step: 12
Training loss: 2.603054592467232
Validation loss: 3.1472156266375646

Epoch: 6| Step: 13
Training loss: 2.0450445245871656
Validation loss: 2.943698509052845

Epoch: 222| Step: 0
Training loss: 3.26618565761348
Validation loss: 2.913366934850347

Epoch: 6| Step: 1
Training loss: 3.4079412059100216
Validation loss: 3.1280571633232945

Epoch: 6| Step: 2
Training loss: 2.8747261580372507
Validation loss: 2.7831397407480183

Epoch: 6| Step: 3
Training loss: 2.368287086044221
Validation loss: 3.0909948227709116

Epoch: 6| Step: 4
Training loss: 3.150798660029695
Validation loss: 3.0888337008645705

Epoch: 6| Step: 5
Training loss: 3.346011813966607
Validation loss: 2.9282625325300833

Epoch: 6| Step: 6
Training loss: 2.1843450410504786
Validation loss: 3.1381194743772305

Epoch: 6| Step: 7
Training loss: 1.8258863256446238
Validation loss: 3.03039336207396

Epoch: 6| Step: 8
Training loss: 1.9763272714678999
Validation loss: 3.117572050234917

Epoch: 6| Step: 9
Training loss: 3.4054253656153395
Validation loss: 3.01809207723451

Epoch: 6| Step: 10
Training loss: 2.9814246808265015
Validation loss: 2.9351168792381306

Epoch: 6| Step: 11
Training loss: 3.0075393354549966
Validation loss: 2.9511078539111213

Epoch: 6| Step: 12
Training loss: 3.229640720805619
Validation loss: 2.953983990817735

Epoch: 6| Step: 13
Training loss: 3.2855681570504705
Validation loss: 3.03124367726272

Epoch: 223| Step: 0
Training loss: 2.6367871084888828
Validation loss: 3.019695425513908

Epoch: 6| Step: 1
Training loss: 2.848258332912564
Validation loss: 3.0875756186593306

Epoch: 6| Step: 2
Training loss: 2.44477882289777
Validation loss: 3.001044652076224

Epoch: 6| Step: 3
Training loss: 2.885543398133989
Validation loss: 3.040602838631312

Epoch: 6| Step: 4
Training loss: 3.0215468693036085
Validation loss: 2.964618895314546

Epoch: 6| Step: 5
Training loss: 3.4119662695376825
Validation loss: 2.9537310911809134

Epoch: 6| Step: 6
Training loss: 3.7065339312583307
Validation loss: 2.9467450703188827

Epoch: 6| Step: 7
Training loss: 3.2104869071575846
Validation loss: 2.8971198189972176

Epoch: 6| Step: 8
Training loss: 3.236107403739876
Validation loss: 3.1668081743091414

Epoch: 6| Step: 9
Training loss: 2.383859073121851
Validation loss: 3.062135063160869

Epoch: 6| Step: 10
Training loss: 3.1770631049507587
Validation loss: 2.959559868495002

Epoch: 6| Step: 11
Training loss: 2.7834922238832824
Validation loss: 3.033656430427516

Epoch: 6| Step: 12
Training loss: 2.5685211710860276
Validation loss: 2.9681153478816538

Epoch: 6| Step: 13
Training loss: 2.5556164840216775
Validation loss: 2.83324953663476

Epoch: 224| Step: 0
Training loss: 4.230362571165799
Validation loss: 2.9482524325068775

Epoch: 6| Step: 1
Training loss: 2.5521582352422514
Validation loss: 3.019719876693451

Epoch: 6| Step: 2
Training loss: 2.802021257547234
Validation loss: 2.993308266828163

Epoch: 6| Step: 3
Training loss: 3.2274957743409476
Validation loss: 2.918151377961406

Epoch: 6| Step: 4
Training loss: 2.702941182672554
Validation loss: 3.0189271037621017

Epoch: 6| Step: 5
Training loss: 2.401281304857849
Validation loss: 2.9487182827114324

Epoch: 6| Step: 6
Training loss: 2.3022540160090363
Validation loss: 2.940481404860276

Epoch: 6| Step: 7
Training loss: 2.137462869957459
Validation loss: 3.105704604959658

Epoch: 6| Step: 8
Training loss: 2.5143124965225936
Validation loss: 3.148999525666743

Epoch: 6| Step: 9
Training loss: 2.9315762141075394
Validation loss: 2.852772697378732

Epoch: 6| Step: 10
Training loss: 3.698230454290537
Validation loss: 2.972337533723162

Epoch: 6| Step: 11
Training loss: 2.3474011274647237
Validation loss: 2.9315248827129285

Epoch: 6| Step: 12
Training loss: 2.786319184913984
Validation loss: 3.1436647517972847

Epoch: 6| Step: 13
Training loss: 1.7971855226975801
Validation loss: 3.027139869199649

Epoch: 225| Step: 0
Training loss: 2.730741080700072
Validation loss: 3.0371564689672415

Epoch: 6| Step: 1
Training loss: 3.642717145051553
Validation loss: 2.9127677890139463

Epoch: 6| Step: 2
Training loss: 2.6817412666611737
Validation loss: 3.127482335240997

Epoch: 6| Step: 3
Training loss: 2.348597586956472
Validation loss: 2.8496452922539945

Epoch: 6| Step: 4
Training loss: 2.7094993624365267
Validation loss: 3.013682955808698

Epoch: 6| Step: 5
Training loss: 2.7594601299421297
Validation loss: 3.0807296254607883

Epoch: 6| Step: 6
Training loss: 3.104154258208255
Validation loss: 2.970398954113875

Epoch: 6| Step: 7
Training loss: 3.940177975619023
Validation loss: 3.1261286332011293

Epoch: 6| Step: 8
Training loss: 2.6833532411614773
Validation loss: 3.1766367070674875

Epoch: 6| Step: 9
Training loss: 2.4617240496511505
Validation loss: 2.951811772419497

Epoch: 6| Step: 10
Training loss: 3.1781141432855216
Validation loss: 3.097296238433025

Epoch: 6| Step: 11
Training loss: 2.468984472028959
Validation loss: 2.9586079192878794

Epoch: 6| Step: 12
Training loss: 2.534065470390917
Validation loss: 3.141513514910039

Epoch: 6| Step: 13
Training loss: 3.3443919483625812
Validation loss: 2.838251189607711

Epoch: 226| Step: 0
Training loss: 2.4790967616208537
Validation loss: 2.952529240322994

Epoch: 6| Step: 1
Training loss: 2.746741879029081
Validation loss: 2.9635392940951557

Epoch: 6| Step: 2
Training loss: 3.057149767899692
Validation loss: 2.9012142963727965

Epoch: 6| Step: 3
Training loss: 2.3222313341796506
Validation loss: 2.867494922345243

Epoch: 6| Step: 4
Training loss: 3.3945688963318097
Validation loss: 3.0410899094346386

Epoch: 6| Step: 5
Training loss: 2.9392385005221437
Validation loss: 2.968426760318473

Epoch: 6| Step: 6
Training loss: 3.6614784612776163
Validation loss: 3.222529563265736

Epoch: 6| Step: 7
Training loss: 3.2597068200769903
Validation loss: 2.983510912872974

Epoch: 6| Step: 8
Training loss: 2.616876475513918
Validation loss: 3.0451779199904463

Epoch: 6| Step: 9
Training loss: 3.4847767688071456
Validation loss: 3.1773528750115183

Epoch: 6| Step: 10
Training loss: 2.386210236015743
Validation loss: 2.947510425232908

Epoch: 6| Step: 11
Training loss: 2.2488463941252452
Validation loss: 2.9169561837181384

Epoch: 6| Step: 12
Training loss: 2.2489417024403595
Validation loss: 2.9260820160572156

Epoch: 6| Step: 13
Training loss: 3.0845295072156125
Validation loss: 2.938636324364049

Epoch: 227| Step: 0
Training loss: 3.2811058376069075
Validation loss: 3.0301831313900216

Epoch: 6| Step: 1
Training loss: 3.7758999642278606
Validation loss: 2.9570943400556593

Epoch: 6| Step: 2
Training loss: 2.7397759856933974
Validation loss: 3.0000990232580134

Epoch: 6| Step: 3
Training loss: 2.2730264718175306
Validation loss: 2.802333498725783

Epoch: 6| Step: 4
Training loss: 2.4438820454467285
Validation loss: 2.9832022179986426

Epoch: 6| Step: 5
Training loss: 3.2621637280677227
Validation loss: 2.8441452947017027

Epoch: 6| Step: 6
Training loss: 3.5178644126280316
Validation loss: 2.995530381157419

Epoch: 6| Step: 7
Training loss: 2.873396716676319
Validation loss: 2.977650708828172

Epoch: 6| Step: 8
Training loss: 3.1637384696156503
Validation loss: 2.9798201881037443

Epoch: 6| Step: 9
Training loss: 2.8493225497141546
Validation loss: 2.7298571506812306

Epoch: 6| Step: 10
Training loss: 2.1557583455699825
Validation loss: 2.925012295422525

Epoch: 6| Step: 11
Training loss: 2.344088720641097
Validation loss: 2.96515931022194

Epoch: 6| Step: 12
Training loss: 3.593967331658744
Validation loss: 3.1039244551861236

Epoch: 6| Step: 13
Training loss: 2.0989425948872635
Validation loss: 2.982671343205007

Epoch: 228| Step: 0
Training loss: 2.2842677810075425
Validation loss: 2.976101857613688

Epoch: 6| Step: 1
Training loss: 4.012891024256526
Validation loss: 2.944213940846542

Epoch: 6| Step: 2
Training loss: 2.434057690528372
Validation loss: 2.8636963420629313

Epoch: 6| Step: 3
Training loss: 2.530140669006796
Validation loss: 2.9406212304683423

Epoch: 6| Step: 4
Training loss: 3.1517489225431574
Validation loss: 2.928745047853892

Epoch: 6| Step: 5
Training loss: 3.0971974902645734
Validation loss: 2.9798355278195636

Epoch: 6| Step: 6
Training loss: 3.224999739772579
Validation loss: 3.076689054627015

Epoch: 6| Step: 7
Training loss: 2.7080400357012704
Validation loss: 2.8948253344749713

Epoch: 6| Step: 8
Training loss: 2.9236901504895036
Validation loss: 3.095059478688946

Epoch: 6| Step: 9
Training loss: 1.9656109686564478
Validation loss: 3.058650552676915

Epoch: 6| Step: 10
Training loss: 3.113949578319848
Validation loss: 3.0151109154699673

Epoch: 6| Step: 11
Training loss: 3.3704017114482365
Validation loss: 3.023704515957886

Epoch: 6| Step: 12
Training loss: 2.146385294716217
Validation loss: 2.978381966520912

Epoch: 6| Step: 13
Training loss: 3.395664952009929
Validation loss: 3.012638885750895

Epoch: 229| Step: 0
Training loss: 3.2987422627036307
Validation loss: 3.084007065412418

Epoch: 6| Step: 1
Training loss: 2.723430244405496
Validation loss: 2.9025475413863653

Epoch: 6| Step: 2
Training loss: 2.5544491344621054
Validation loss: 2.835805713322985

Epoch: 6| Step: 3
Training loss: 2.7446045398563697
Validation loss: 2.961940057867638

Epoch: 6| Step: 4
Training loss: 3.1635705636096536
Validation loss: 2.904062640367247

Epoch: 6| Step: 5
Training loss: 2.436027962679171
Validation loss: 2.931721825691287

Epoch: 6| Step: 6
Training loss: 3.6137560393297155
Validation loss: 2.998147380480702

Epoch: 6| Step: 7
Training loss: 2.7017408586779657
Validation loss: 2.9859568681410353

Epoch: 6| Step: 8
Training loss: 2.595842918839572
Validation loss: 3.0849421366193246

Epoch: 6| Step: 9
Training loss: 2.997008739745081
Validation loss: 3.1134369264759636

Epoch: 6| Step: 10
Training loss: 2.2214553887461825
Validation loss: 3.2037845663829847

Epoch: 6| Step: 11
Training loss: 2.8750736392997807
Validation loss: 3.1232991534710686

Epoch: 6| Step: 12
Training loss: 2.8134986799774953
Validation loss: 3.0342394354652824

Epoch: 6| Step: 13
Training loss: 2.0848458966359424
Validation loss: 3.049939525521812

Epoch: 230| Step: 0
Training loss: 2.465956834091988
Validation loss: 3.003096926961299

Epoch: 6| Step: 1
Training loss: 2.271216707211296
Validation loss: 2.8020998961183357

Epoch: 6| Step: 2
Training loss: 2.1008156509391673
Validation loss: 3.02461967135047

Epoch: 6| Step: 3
Training loss: 2.146424172054395
Validation loss: 2.9258437854601658

Epoch: 6| Step: 4
Training loss: 3.4550808852094685
Validation loss: 3.0409196868313075

Epoch: 6| Step: 5
Training loss: 2.1461673464270277
Validation loss: 2.984078703813112

Epoch: 6| Step: 6
Training loss: 3.4844484877427746
Validation loss: 2.985169796069793

Epoch: 6| Step: 7
Training loss: 2.545059961538177
Validation loss: 3.0297994624299687

Epoch: 6| Step: 8
Training loss: 2.970120404817995
Validation loss: 2.8966759377784594

Epoch: 6| Step: 9
Training loss: 3.635857468836121
Validation loss: 3.0043823115864376

Epoch: 6| Step: 10
Training loss: 3.160529379866375
Validation loss: 2.8878185205385862

Epoch: 6| Step: 11
Training loss: 2.9193188915442834
Validation loss: 3.0105780057142555

Epoch: 6| Step: 12
Training loss: 3.0894236514153905
Validation loss: 2.8893416713549978

Epoch: 6| Step: 13
Training loss: 2.01018327797882
Validation loss: 2.9924555481489628

Epoch: 231| Step: 0
Training loss: 3.4255144108859055
Validation loss: 2.9733100605364764

Epoch: 6| Step: 1
Training loss: 3.701765366128261
Validation loss: 2.9289650049281657

Epoch: 6| Step: 2
Training loss: 3.0448629925352217
Validation loss: 3.1523635102640664

Epoch: 6| Step: 3
Training loss: 3.484095267113439
Validation loss: 2.9692469683374205

Epoch: 6| Step: 4
Training loss: 2.8772048788249136
Validation loss: 2.924986594153374

Epoch: 6| Step: 5
Training loss: 2.6295924205217025
Validation loss: 3.190908868824102

Epoch: 6| Step: 6
Training loss: 3.0326742385408583
Validation loss: 2.9944652959853664

Epoch: 6| Step: 7
Training loss: 3.1591739518881474
Validation loss: 3.009911107068541

Epoch: 6| Step: 8
Training loss: 1.7565267650238403
Validation loss: 3.020157645884451

Epoch: 6| Step: 9
Training loss: 3.3802377535926356
Validation loss: 3.192878130188144

Epoch: 6| Step: 10
Training loss: 2.7397793795178833
Validation loss: 2.9952272465240664

Epoch: 6| Step: 11
Training loss: 2.757200610871042
Validation loss: 3.022942979994258

Epoch: 6| Step: 12
Training loss: 2.363744163889264
Validation loss: 3.144669441677495

Epoch: 6| Step: 13
Training loss: 1.5197913724373038
Validation loss: 3.047657699326583

Epoch: 232| Step: 0
Training loss: 2.0871769226784007
Validation loss: 3.1090966339838424

Epoch: 6| Step: 1
Training loss: 2.7428423759795226
Validation loss: 3.0327489927204216

Epoch: 6| Step: 2
Training loss: 2.833120244558885
Validation loss: 3.010466994645411

Epoch: 6| Step: 3
Training loss: 2.6695996685152474
Validation loss: 2.9926862493514803

Epoch: 6| Step: 4
Training loss: 2.3537253132081113
Validation loss: 2.7502384940028266

Epoch: 6| Step: 5
Training loss: 2.468158892594194
Validation loss: 2.8689250609435115

Epoch: 6| Step: 6
Training loss: 2.6875333562155994
Validation loss: 2.9139720341096536

Epoch: 6| Step: 7
Training loss: 4.1437230450197955
Validation loss: 3.120611669989568

Epoch: 6| Step: 8
Training loss: 2.43000894364332
Validation loss: 2.8860827249896004

Epoch: 6| Step: 9
Training loss: 3.776480070073921
Validation loss: 2.9847155342714324

Epoch: 6| Step: 10
Training loss: 3.2244963969835903
Validation loss: 2.8569512896875917

Epoch: 6| Step: 11
Training loss: 2.598206242439806
Validation loss: 2.9294316880853706

Epoch: 6| Step: 12
Training loss: 3.09643869415655
Validation loss: 2.959584249124327

Epoch: 6| Step: 13
Training loss: 3.3843294403024724
Validation loss: 2.9732301818890368

Epoch: 233| Step: 0
Training loss: 3.179752283584515
Validation loss: 2.7969734503171524

Epoch: 6| Step: 1
Training loss: 2.998372590205771
Validation loss: 2.906150242785618

Epoch: 6| Step: 2
Training loss: 3.7875033287310687
Validation loss: 2.9560736784958515

Epoch: 6| Step: 3
Training loss: 2.0419023987537646
Validation loss: 2.9707892503188735

Epoch: 6| Step: 4
Training loss: 2.5536578141881328
Validation loss: 2.9523136656227718

Epoch: 6| Step: 5
Training loss: 3.3254676203203104
Validation loss: 3.1041420104710404

Epoch: 6| Step: 6
Training loss: 2.6143897746099767
Validation loss: 3.0245862421737777

Epoch: 6| Step: 7
Training loss: 2.600433746250832
Validation loss: 2.919170643165867

Epoch: 6| Step: 8
Training loss: 2.496689320942359
Validation loss: 2.9000050072632058

Epoch: 6| Step: 9
Training loss: 3.0399374205020813
Validation loss: 2.9751289603413658

Epoch: 6| Step: 10
Training loss: 2.3294051574277868
Validation loss: 3.004306017028729

Epoch: 6| Step: 11
Training loss: 2.0796255559602383
Validation loss: 3.010556042602742

Epoch: 6| Step: 12
Training loss: 2.2915598295334867
Validation loss: 3.0030522389403127

Epoch: 6| Step: 13
Training loss: 2.770789287092762
Validation loss: 2.9737496530273084

Epoch: 234| Step: 0
Training loss: 3.0096027545565502
Validation loss: 3.030573226502075

Epoch: 6| Step: 1
Training loss: 3.2261950858644095
Validation loss: 3.122109951710529

Epoch: 6| Step: 2
Training loss: 3.0926468548949777
Validation loss: 3.0403031683970916

Epoch: 6| Step: 3
Training loss: 2.1740451646129846
Validation loss: 3.0056080716090885

Epoch: 6| Step: 4
Training loss: 2.8026263385645476
Validation loss: 3.074602922836549

Epoch: 6| Step: 5
Training loss: 3.8547770798645695
Validation loss: 2.9486796111693323

Epoch: 6| Step: 6
Training loss: 2.844051303202279
Validation loss: 2.972854559995039

Epoch: 6| Step: 7
Training loss: 1.5694805617476164
Validation loss: 3.0795284486704735

Epoch: 6| Step: 8
Training loss: 2.7791482935292886
Validation loss: 3.030656720784208

Epoch: 6| Step: 9
Training loss: 3.66925032939105
Validation loss: 3.1822739204169848

Epoch: 6| Step: 10
Training loss: 2.5282145065853476
Validation loss: 2.9916410878735804

Epoch: 6| Step: 11
Training loss: 3.370525926703874
Validation loss: 3.063521065343734

Epoch: 6| Step: 12
Training loss: 2.1814398609154395
Validation loss: 2.9222430855595167

Epoch: 6| Step: 13
Training loss: 2.3826720149416563
Validation loss: 2.9832771136024077

Epoch: 235| Step: 0
Training loss: 2.58101552124559
Validation loss: 2.862272579840269

Epoch: 6| Step: 1
Training loss: 2.775353599908074
Validation loss: 2.9419381156875253

Epoch: 6| Step: 2
Training loss: 2.339991085654991
Validation loss: 2.864538591469897

Epoch: 6| Step: 3
Training loss: 2.5575540774418255
Validation loss: 2.9242089827876554

Epoch: 6| Step: 4
Training loss: 2.0643171917094185
Validation loss: 2.9897689527321583

Epoch: 6| Step: 5
Training loss: 2.8214445510328963
Validation loss: 2.8202695370893642

Epoch: 6| Step: 6
Training loss: 2.289263094813034
Validation loss: 2.956036490788822

Epoch: 6| Step: 7
Training loss: 3.1630049833824705
Validation loss: 2.8677403950566833

Epoch: 6| Step: 8
Training loss: 3.3662847384116925
Validation loss: 3.017229686467688

Epoch: 6| Step: 9
Training loss: 3.3610829824176114
Validation loss: 2.9514673575277515

Epoch: 6| Step: 10
Training loss: 2.285447426527814
Validation loss: 3.073586653302298

Epoch: 6| Step: 11
Training loss: 2.570876503143487
Validation loss: 3.15496159828027

Epoch: 6| Step: 12
Training loss: 3.713627211917184
Validation loss: 3.000073274790872

Epoch: 6| Step: 13
Training loss: 3.2523790601783222
Validation loss: 2.7749184527097595

Epoch: 236| Step: 0
Training loss: 2.6605402687493687
Validation loss: 3.0394152002118195

Epoch: 6| Step: 1
Training loss: 3.1539830290846376
Validation loss: 2.929769350720131

Epoch: 6| Step: 2
Training loss: 2.5488910769584656
Validation loss: 2.9208929045428573

Epoch: 6| Step: 3
Training loss: 2.8082709836594426
Validation loss: 2.809195190458731

Epoch: 6| Step: 4
Training loss: 3.477914063123002
Validation loss: 3.0153094558088562

Epoch: 6| Step: 5
Training loss: 2.542937810331656
Validation loss: 2.9194571420136044

Epoch: 6| Step: 6
Training loss: 2.827495441652329
Validation loss: 2.9221893329231166

Epoch: 6| Step: 7
Training loss: 2.556955619740163
Validation loss: 3.048532783498156

Epoch: 6| Step: 8
Training loss: 2.2851695003288386
Validation loss: 3.0569103663046815

Epoch: 6| Step: 9
Training loss: 2.377041090228566
Validation loss: 2.925583160523439

Epoch: 6| Step: 10
Training loss: 3.8822902888582265
Validation loss: 2.939859668255771

Epoch: 6| Step: 11
Training loss: 3.5054149972982787
Validation loss: 3.023539011575676

Epoch: 6| Step: 12
Training loss: 2.0658764800069127
Validation loss: 2.982378555115293

Epoch: 6| Step: 13
Training loss: 2.3150235402700323
Validation loss: 2.927638051290198

Epoch: 237| Step: 0
Training loss: 2.588528997030792
Validation loss: 2.896055054750851

Epoch: 6| Step: 1
Training loss: 3.0699211045854105
Validation loss: 3.0162469502111535

Epoch: 6| Step: 2
Training loss: 3.3564778454835182
Validation loss: 2.9363197463821065

Epoch: 6| Step: 3
Training loss: 3.2402957406881217
Validation loss: 2.9209950606916584

Epoch: 6| Step: 4
Training loss: 2.841463448276797
Validation loss: 3.0347624847311088

Epoch: 6| Step: 5
Training loss: 3.5078633396058327
Validation loss: 2.915475797937994

Epoch: 6| Step: 6
Training loss: 2.5812750789726375
Validation loss: 3.0521240623640704

Epoch: 6| Step: 7
Training loss: 2.034646700809022
Validation loss: 3.000233207033452

Epoch: 6| Step: 8
Training loss: 2.8590376191094284
Validation loss: 2.9826167258994705

Epoch: 6| Step: 9
Training loss: 2.4274437654465895
Validation loss: 3.1428723927197004

Epoch: 6| Step: 10
Training loss: 3.655644293277809
Validation loss: 2.938397638891557

Epoch: 6| Step: 11
Training loss: 3.0990502779274283
Validation loss: 2.9903429497034155

Epoch: 6| Step: 12
Training loss: 2.381532018586817
Validation loss: 3.1407114807900673

Epoch: 6| Step: 13
Training loss: 1.7799302951151625
Validation loss: 3.1237934039154007

Epoch: 238| Step: 0
Training loss: 2.4609371124751678
Validation loss: 2.9429379470079797

Epoch: 6| Step: 1
Training loss: 3.3020330639852555
Validation loss: 3.076938426056978

Epoch: 6| Step: 2
Training loss: 3.4746987136754566
Validation loss: 2.9012660456390855

Epoch: 6| Step: 3
Training loss: 3.0316825636715525
Validation loss: 3.03562802055778

Epoch: 6| Step: 4
Training loss: 1.5334037115006105
Validation loss: 2.876473384111609

Epoch: 6| Step: 5
Training loss: 2.557786747284883
Validation loss: 2.9418731860512892

Epoch: 6| Step: 6
Training loss: 3.0705982492664905
Validation loss: 2.8685991262972945

Epoch: 6| Step: 7
Training loss: 2.70017606373112
Validation loss: 2.9458822221216945

Epoch: 6| Step: 8
Training loss: 2.273185689817135
Validation loss: 2.8585037239017144

Epoch: 6| Step: 9
Training loss: 2.7139847308905103
Validation loss: 2.8532783366011136

Epoch: 6| Step: 10
Training loss: 3.161374907463838
Validation loss: 3.0054918494790237

Epoch: 6| Step: 11
Training loss: 3.070851674191186
Validation loss: 2.894199260575389

Epoch: 6| Step: 12
Training loss: 2.2641405175076965
Validation loss: 2.9634870889672977

Epoch: 6| Step: 13
Training loss: 2.4029249527190104
Validation loss: 2.9794187834220796

Epoch: 239| Step: 0
Training loss: 3.0394723022624675
Validation loss: 2.9057703635728833

Epoch: 6| Step: 1
Training loss: 2.9282040515109524
Validation loss: 2.9224589537895316

Epoch: 6| Step: 2
Training loss: 1.938817714391601
Validation loss: 2.892646451236449

Epoch: 6| Step: 3
Training loss: 3.073466071891531
Validation loss: 2.900754676715846

Epoch: 6| Step: 4
Training loss: 1.9391377817889772
Validation loss: 3.087344777592545

Epoch: 6| Step: 5
Training loss: 3.257728630468313
Validation loss: 2.9825958118067875

Epoch: 6| Step: 6
Training loss: 3.8976327069233463
Validation loss: 2.935582973021475

Epoch: 6| Step: 7
Training loss: 2.531755938417814
Validation loss: 2.9857995111947755

Epoch: 6| Step: 8
Training loss: 2.312921640258712
Validation loss: 3.0263155443544307

Epoch: 6| Step: 9
Training loss: 3.0211650973137916
Validation loss: 2.8921383431339724

Epoch: 6| Step: 10
Training loss: 3.597610390502366
Validation loss: 2.8491192577064517

Epoch: 6| Step: 11
Training loss: 3.128378605732635
Validation loss: 2.9444648143207917

Epoch: 6| Step: 12
Training loss: 2.425002705680675
Validation loss: 2.8748981534476856

Epoch: 6| Step: 13
Training loss: 2.7817968623839766
Validation loss: 2.974045888696166

Epoch: 240| Step: 0
Training loss: 1.6523745558732557
Validation loss: 3.0011856904658254

Epoch: 6| Step: 1
Training loss: 3.0292274570443256
Validation loss: 2.9696554084584603

Epoch: 6| Step: 2
Training loss: 2.1089861476076086
Validation loss: 2.680442420300136

Epoch: 6| Step: 3
Training loss: 3.06658833928905
Validation loss: 2.9709735654034306

Epoch: 6| Step: 4
Training loss: 1.8871297132043197
Validation loss: 3.0024708900421344

Epoch: 6| Step: 5
Training loss: 3.335193417043359
Validation loss: 2.913671625505204

Epoch: 6| Step: 6
Training loss: 2.9278265574005107
Validation loss: 3.003387597993158

Epoch: 6| Step: 7
Training loss: 3.651600546877366
Validation loss: 3.0875264930593143

Epoch: 6| Step: 8
Training loss: 2.66351625989588
Validation loss: 2.9284390646176455

Epoch: 6| Step: 9
Training loss: 2.029801072018579
Validation loss: 3.0394772347496826

Epoch: 6| Step: 10
Training loss: 3.2811325778840974
Validation loss: 2.9559724198166393

Epoch: 6| Step: 11
Training loss: 3.619539950101175
Validation loss: 3.1080335746402663

Epoch: 6| Step: 12
Training loss: 2.189203198721898
Validation loss: 3.104226767456507

Epoch: 6| Step: 13
Training loss: 4.528641153617958
Validation loss: 3.0743456994364076

Epoch: 241| Step: 0
Training loss: 3.02249043932492
Validation loss: 2.9124587390801953

Epoch: 6| Step: 1
Training loss: 2.455708983342766
Validation loss: 2.956005311033598

Epoch: 6| Step: 2
Training loss: 2.876342625790596
Validation loss: 2.9023305764318414

Epoch: 6| Step: 3
Training loss: 2.877445673425586
Validation loss: 2.955333570741404

Epoch: 6| Step: 4
Training loss: 2.966253093938102
Validation loss: 3.11093361452477

Epoch: 6| Step: 5
Training loss: 2.547033761347759
Validation loss: 2.965651138632899

Epoch: 6| Step: 6
Training loss: 2.2522906193601253
Validation loss: 2.974769648996443

Epoch: 6| Step: 7
Training loss: 3.4853347346101886
Validation loss: 2.918298585300358

Epoch: 6| Step: 8
Training loss: 3.1461700528717316
Validation loss: 2.8535106989874652

Epoch: 6| Step: 9
Training loss: 2.6590413405356244
Validation loss: 2.9553218599763342

Epoch: 6| Step: 10
Training loss: 2.6850747099131045
Validation loss: 2.906215874379732

Epoch: 6| Step: 11
Training loss: 2.641911029845237
Validation loss: 2.976968621442519

Epoch: 6| Step: 12
Training loss: 2.020039890952963
Validation loss: 2.9662143346766907

Epoch: 6| Step: 13
Training loss: 3.0118118449862714
Validation loss: 3.024009144127498

Epoch: 242| Step: 0
Training loss: 3.2012680998159797
Validation loss: 3.1668488984924457

Epoch: 6| Step: 1
Training loss: 3.5982584661552335
Validation loss: 3.0764909905389364

Epoch: 6| Step: 2
Training loss: 3.0306896202984825
Validation loss: 3.0577976941238885

Epoch: 6| Step: 3
Training loss: 2.976423125120314
Validation loss: 2.975391172435537

Epoch: 6| Step: 4
Training loss: 2.624520666772537
Validation loss: 3.0674214267149034

Epoch: 6| Step: 5
Training loss: 1.9022382201703485
Validation loss: 3.0431038993423507

Epoch: 6| Step: 6
Training loss: 2.405360763519569
Validation loss: 3.004833316115051

Epoch: 6| Step: 7
Training loss: 2.7457973271403255
Validation loss: 2.9874715299035373

Epoch: 6| Step: 8
Training loss: 2.8376626056343497
Validation loss: 2.9790945930003665

Epoch: 6| Step: 9
Training loss: 2.8276720896191505
Validation loss: 3.0455153004740336

Epoch: 6| Step: 10
Training loss: 3.064492647829104
Validation loss: 3.0665413729479942

Epoch: 6| Step: 11
Training loss: 2.3101640192235986
Validation loss: 3.065940817535214

Epoch: 6| Step: 12
Training loss: 3.898439334723704
Validation loss: 2.9777886987112545

Epoch: 6| Step: 13
Training loss: 2.4706242846548956
Validation loss: 3.0380380090304375

Epoch: 243| Step: 0
Training loss: 2.161458676502859
Validation loss: 2.8869828861219395

Epoch: 6| Step: 1
Training loss: 3.071817664914292
Validation loss: 3.136535318786191

Epoch: 6| Step: 2
Training loss: 3.4270866108021627
Validation loss: 3.030168095620751

Epoch: 6| Step: 3
Training loss: 2.573002112407388
Validation loss: 3.0403359238961816

Epoch: 6| Step: 4
Training loss: 2.6690875230819207
Validation loss: 2.9733066875388237

Epoch: 6| Step: 5
Training loss: 2.9953481848177543
Validation loss: 3.017220224560625

Epoch: 6| Step: 6
Training loss: 2.7000406120919367
Validation loss: 2.9342910494766783

Epoch: 6| Step: 7
Training loss: 1.4849575305093348
Validation loss: 2.935438455130953

Epoch: 6| Step: 8
Training loss: 2.613115564861659
Validation loss: 2.8927742384322506

Epoch: 6| Step: 9
Training loss: 3.477417024325926
Validation loss: 2.9516700806277822

Epoch: 6| Step: 10
Training loss: 3.0648190806823252
Validation loss: 3.039561578367623

Epoch: 6| Step: 11
Training loss: 3.3590837219289034
Validation loss: 2.9519402742240146

Epoch: 6| Step: 12
Training loss: 2.900588561217334
Validation loss: 2.8119688017801936

Epoch: 6| Step: 13
Training loss: 2.3103959073738456
Validation loss: 2.7954112388736636

Epoch: 244| Step: 0
Training loss: 3.136513671251686
Validation loss: 2.963595408305172

Epoch: 6| Step: 1
Training loss: 2.350136967989429
Validation loss: 2.9505668550890696

Epoch: 6| Step: 2
Training loss: 3.556164914472581
Validation loss: 2.9399731143240824

Epoch: 6| Step: 3
Training loss: 2.856776322968366
Validation loss: 3.1116568287689628

Epoch: 6| Step: 4
Training loss: 2.431145135731306
Validation loss: 2.8712432074611667

Epoch: 6| Step: 5
Training loss: 1.85487243707283
Validation loss: 3.033321366821218

Epoch: 6| Step: 6
Training loss: 2.640384189076293
Validation loss: 2.812246062779701

Epoch: 6| Step: 7
Training loss: 2.2315626251301866
Validation loss: 3.0712985506522053

Epoch: 6| Step: 8
Training loss: 3.0731751586470137
Validation loss: 2.8157143595123215

Epoch: 6| Step: 9
Training loss: 2.804654772044207
Validation loss: 2.8489464456647244

Epoch: 6| Step: 10
Training loss: 3.128057128901639
Validation loss: 3.0196745211732483

Epoch: 6| Step: 11
Training loss: 3.870724688354509
Validation loss: 2.985057922544439

Epoch: 6| Step: 12
Training loss: 3.361288971481727
Validation loss: 2.9284112328449536

Epoch: 6| Step: 13
Training loss: 2.339198869031223
Validation loss: 2.9577345414675023

Epoch: 245| Step: 0
Training loss: 2.857462425752507
Validation loss: 3.082505119613626

Epoch: 6| Step: 1
Training loss: 3.447222191210089
Validation loss: 3.050914421429646

Epoch: 6| Step: 2
Training loss: 2.8058707203954985
Validation loss: 2.8727492242429298

Epoch: 6| Step: 3
Training loss: 2.8851275982068056
Validation loss: 3.0316529990852055

Epoch: 6| Step: 4
Training loss: 2.21354882332636
Validation loss: 2.932558548545504

Epoch: 6| Step: 5
Training loss: 2.322293550084414
Validation loss: 3.057473431228297

Epoch: 6| Step: 6
Training loss: 2.7984468103165545
Validation loss: 2.9970324410686406

Epoch: 6| Step: 7
Training loss: 2.8987576289896984
Validation loss: 2.860756714014105

Epoch: 6| Step: 8
Training loss: 3.238122363270752
Validation loss: 2.96334627379155

Epoch: 6| Step: 9
Training loss: 2.43040293865315
Validation loss: 3.0087293587195525

Epoch: 6| Step: 10
Training loss: 2.9152175209716473
Validation loss: 3.0327180927687873

Epoch: 6| Step: 11
Training loss: 4.052479990133766
Validation loss: 3.0807732782716553

Epoch: 6| Step: 12
Training loss: 2.6546697067014695
Validation loss: 2.87350515958997

Epoch: 6| Step: 13
Training loss: 1.9825073825078177
Validation loss: 3.1112950045307577

Epoch: 246| Step: 0
Training loss: 1.594800490693992
Validation loss: 2.9463312145481915

Epoch: 6| Step: 1
Training loss: 3.810847064795086
Validation loss: 2.894258538526292

Epoch: 6| Step: 2
Training loss: 3.1550576252216436
Validation loss: 2.9400635256924343

Epoch: 6| Step: 3
Training loss: 2.9160756375166716
Validation loss: 2.921132197996973

Epoch: 6| Step: 4
Training loss: 2.1965217924992952
Validation loss: 2.965652029010538

Epoch: 6| Step: 5
Training loss: 3.3875645480041454
Validation loss: 2.875772111248603

Epoch: 6| Step: 6
Training loss: 2.784031452258891
Validation loss: 2.946057258964052

Epoch: 6| Step: 7
Training loss: 1.9652879944600545
Validation loss: 2.9533547818086463

Epoch: 6| Step: 8
Training loss: 2.3345773877266667
Validation loss: 2.930598772855824

Epoch: 6| Step: 9
Training loss: 3.434131983731763
Validation loss: 2.9546881134646346

Epoch: 6| Step: 10
Training loss: 2.43267540419851
Validation loss: 2.909680803806436

Epoch: 6| Step: 11
Training loss: 2.9052635897942345
Validation loss: 2.905796392729165

Epoch: 6| Step: 12
Training loss: 3.1790623905650968
Validation loss: 2.971163803677332

Epoch: 6| Step: 13
Training loss: 3.7801192933892205
Validation loss: 2.965856466470358

Epoch: 247| Step: 0
Training loss: 2.7789520028256676
Validation loss: 2.9566633368647475

Epoch: 6| Step: 1
Training loss: 3.7268525656485987
Validation loss: 2.816069838840492

Epoch: 6| Step: 2
Training loss: 2.649029600860079
Validation loss: 2.9295765863021423

Epoch: 6| Step: 3
Training loss: 2.2824810312241257
Validation loss: 2.8666084274572667

Epoch: 6| Step: 4
Training loss: 3.9777997982995026
Validation loss: 2.9425462706284202

Epoch: 6| Step: 5
Training loss: 2.418654139785263
Validation loss: 3.000211677466663

Epoch: 6| Step: 6
Training loss: 2.3984239807741945
Validation loss: 2.8101093847041025

Epoch: 6| Step: 7
Training loss: 2.9259861058226653
Validation loss: 2.7816849216755366

Epoch: 6| Step: 8
Training loss: 1.9376998921307451
Validation loss: 2.940241312801319

Epoch: 6| Step: 9
Training loss: 2.4210818068538114
Validation loss: 2.9365453449560475

Epoch: 6| Step: 10
Training loss: 3.395245054499386
Validation loss: 2.9246625848868244

Epoch: 6| Step: 11
Training loss: 2.5874726040629152
Validation loss: 2.8795561087679733

Epoch: 6| Step: 12
Training loss: 3.0867894022895235
Validation loss: 2.9738399844909438

Epoch: 6| Step: 13
Training loss: 2.6611098766213432
Validation loss: 2.929401020659535

Epoch: 248| Step: 0
Training loss: 2.5670133711582177
Validation loss: 2.9835748504489548

Epoch: 6| Step: 1
Training loss: 3.121790954863753
Validation loss: 2.841991823573861

Epoch: 6| Step: 2
Training loss: 2.3629394284047085
Validation loss: 3.0226797600217084

Epoch: 6| Step: 3
Training loss: 2.3300715763738653
Validation loss: 3.0237465104060472

Epoch: 6| Step: 4
Training loss: 2.0798359188138456
Validation loss: 2.8145262990130133

Epoch: 6| Step: 5
Training loss: 2.6898910177056967
Validation loss: 2.9523616302645808

Epoch: 6| Step: 6
Training loss: 2.814883260796373
Validation loss: 3.032223631272337

Epoch: 6| Step: 7
Training loss: 2.408744608819112
Validation loss: 3.0722206263201253

Epoch: 6| Step: 8
Training loss: 2.8160310408008478
Validation loss: 2.9414282553100954

Epoch: 6| Step: 9
Training loss: 3.643900825951513
Validation loss: 3.019362838907794

Epoch: 6| Step: 10
Training loss: 3.0757547150180176
Validation loss: 2.8907287986985146

Epoch: 6| Step: 11
Training loss: 2.498372692725281
Validation loss: 2.955924754872029

Epoch: 6| Step: 12
Training loss: 3.1969673329850945
Validation loss: 3.157917746440446

Epoch: 6| Step: 13
Training loss: 4.409946054833661
Validation loss: 2.9414656399046093

Epoch: 249| Step: 0
Training loss: 3.240476446324233
Validation loss: 2.9575396288646965

Epoch: 6| Step: 1
Training loss: 3.554051872686317
Validation loss: 2.949034500913316

Epoch: 6| Step: 2
Training loss: 3.812888954208347
Validation loss: 2.8501013239271207

Epoch: 6| Step: 3
Training loss: 2.644343269462516
Validation loss: 2.98682520443377

Epoch: 6| Step: 4
Training loss: 2.1155844387296434
Validation loss: 2.839400990107599

Epoch: 6| Step: 5
Training loss: 2.68869471054655
Validation loss: 2.857719964953632

Epoch: 6| Step: 6
Training loss: 2.7877854273798275
Validation loss: 3.065545764728813

Epoch: 6| Step: 7
Training loss: 3.2666720669241145
Validation loss: 2.9493683416660414

Epoch: 6| Step: 8
Training loss: 3.1616973702792093
Validation loss: 3.082890051051377

Epoch: 6| Step: 9
Training loss: 2.354355379716028
Validation loss: 2.9298033183732173

Epoch: 6| Step: 10
Training loss: 2.0596808615942015
Validation loss: 2.926309518247307

Epoch: 6| Step: 11
Training loss: 2.014227804261707
Validation loss: 2.9276939490599427

Epoch: 6| Step: 12
Training loss: 2.707369520401901
Validation loss: 2.8584010375541857

Epoch: 6| Step: 13
Training loss: 2.1136345700193906
Validation loss: 2.805574160248542

Epoch: 250| Step: 0
Training loss: 2.695374772831345
Validation loss: 2.9516318637950114

Epoch: 6| Step: 1
Training loss: 3.220488587978584
Validation loss: 2.8789862737685574

Epoch: 6| Step: 2
Training loss: 1.699415454221646
Validation loss: 2.896650608153276

Epoch: 6| Step: 3
Training loss: 3.0537546592049143
Validation loss: 2.9878248631483917

Epoch: 6| Step: 4
Training loss: 3.448082742216023
Validation loss: 2.916353109237698

Epoch: 6| Step: 5
Training loss: 2.5618734756841173
Validation loss: 2.8401159221042516

Epoch: 6| Step: 6
Training loss: 3.008644682463747
Validation loss: 2.9732294989941743

Epoch: 6| Step: 7
Training loss: 3.3464641073055565
Validation loss: 2.9730841405629684

Epoch: 6| Step: 8
Training loss: 2.4256409928566938
Validation loss: 2.8483556624516995

Epoch: 6| Step: 9
Training loss: 4.420377551908436
Validation loss: 2.869172845227004

Epoch: 6| Step: 10
Training loss: 3.081569235708939
Validation loss: 2.922735852837786

Epoch: 6| Step: 11
Training loss: 3.3714128433858224
Validation loss: 3.0307458936867

Epoch: 6| Step: 12
Training loss: 2.5846576577614115
Validation loss: 2.9260400822198704

Epoch: 6| Step: 13
Training loss: 3.0273602885132926
Validation loss: 3.0552799751900728

Epoch: 251| Step: 0
Training loss: 2.699084045317097
Validation loss: 3.021354342386837

Epoch: 6| Step: 1
Training loss: 2.324410259146592
Validation loss: 3.0869759181801015

Epoch: 6| Step: 2
Training loss: 2.893559136903852
Validation loss: 2.904441608716686

Epoch: 6| Step: 3
Training loss: 2.808892203696558
Validation loss: 2.8831764060648513

Epoch: 6| Step: 4
Training loss: 3.434662636260912
Validation loss: 3.003784187448746

Epoch: 6| Step: 5
Training loss: 3.9320643614025337
Validation loss: 3.138701066993899

Epoch: 6| Step: 6
Training loss: 2.029779459431656
Validation loss: 2.900718322916076

Epoch: 6| Step: 7
Training loss: 3.4072160663262663
Validation loss: 2.956790818877483

Epoch: 6| Step: 8
Training loss: 2.6490255507565026
Validation loss: 2.9951356149757884

Epoch: 6| Step: 9
Training loss: 2.63131943201079
Validation loss: 3.00303929885623

Epoch: 6| Step: 10
Training loss: 2.6403952955749888
Validation loss: 2.8826390665088093

Epoch: 6| Step: 11
Training loss: 1.9161781296562055
Validation loss: 2.832617306096845

Epoch: 6| Step: 12
Training loss: 3.5239698595713036
Validation loss: 2.9443406445139044

Epoch: 6| Step: 13
Training loss: 3.266429017303981
Validation loss: 3.0514442715276355

Epoch: 252| Step: 0
Training loss: 3.013192099690737
Validation loss: 2.9554264189841133

Epoch: 6| Step: 1
Training loss: 2.7831415323502715
Validation loss: 2.8434765889503897

Epoch: 6| Step: 2
Training loss: 4.221792522672352
Validation loss: 3.0572645092500608

Epoch: 6| Step: 3
Training loss: 2.7721754184391263
Validation loss: 2.986557578875825

Epoch: 6| Step: 4
Training loss: 2.8759692672870125
Validation loss: 3.0775097397151097

Epoch: 6| Step: 5
Training loss: 3.0247197549437974
Validation loss: 3.0276884166331186

Epoch: 6| Step: 6
Training loss: 3.797739189606167
Validation loss: 2.867682510665636

Epoch: 6| Step: 7
Training loss: 2.1621076106587203
Validation loss: 3.01174833491934

Epoch: 6| Step: 8
Training loss: 2.808503172027986
Validation loss: 2.98217169304384

Epoch: 6| Step: 9
Training loss: 3.1407443351278523
Validation loss: 2.764286105333909

Epoch: 6| Step: 10
Training loss: 2.760073418539137
Validation loss: 2.984591022205246

Epoch: 6| Step: 11
Training loss: 2.391194394188465
Validation loss: 2.811841833476096

Epoch: 6| Step: 12
Training loss: 2.931061201380031
Validation loss: 2.8774569277979887

Epoch: 6| Step: 13
Training loss: 1.723794435698764
Validation loss: 2.8493449422781096

Epoch: 253| Step: 0
Training loss: 2.0848478407191773
Validation loss: 2.9219221613944266

Epoch: 6| Step: 1
Training loss: 2.773951437169574
Validation loss: 3.0116170034428023

Epoch: 6| Step: 2
Training loss: 3.944301120560001
Validation loss: 2.9809952836370117

Epoch: 6| Step: 3
Training loss: 3.069823092604076
Validation loss: 3.0233650483952563

Epoch: 6| Step: 4
Training loss: 3.760384993626712
Validation loss: 2.9344908767237525

Epoch: 6| Step: 5
Training loss: 2.769511277916351
Validation loss: 3.081441914971311

Epoch: 6| Step: 6
Training loss: 2.224137119608152
Validation loss: 2.871048857490217

Epoch: 6| Step: 7
Training loss: 2.5898369376206594
Validation loss: 2.993354781517709

Epoch: 6| Step: 8
Training loss: 2.851259314736316
Validation loss: 2.9490522661860545

Epoch: 6| Step: 9
Training loss: 2.472212379474072
Validation loss: 2.923756546647094

Epoch: 6| Step: 10
Training loss: 2.530267501229287
Validation loss: 3.102866012138254

Epoch: 6| Step: 11
Training loss: 2.762649746111501
Validation loss: 2.9912898903357523

Epoch: 6| Step: 12
Training loss: 3.0688449759460252
Validation loss: 3.001088335510579

Epoch: 6| Step: 13
Training loss: 1.5950727022875433
Validation loss: 3.0672687647571046

Epoch: 254| Step: 0
Training loss: 2.5994688665305308
Validation loss: 2.968776648789872

Epoch: 6| Step: 1
Training loss: 2.8468765007542696
Validation loss: 2.973946624647182

Epoch: 6| Step: 2
Training loss: 2.564777292766941
Validation loss: 2.928326195125632

Epoch: 6| Step: 3
Training loss: 2.560814279753732
Validation loss: 2.9561585441560156

Epoch: 6| Step: 4
Training loss: 3.160597875266353
Validation loss: 2.8372356594333223

Epoch: 6| Step: 5
Training loss: 2.1891791302408823
Validation loss: 3.0707055753784647

Epoch: 6| Step: 6
Training loss: 2.917767416916357
Validation loss: 2.848040388080399

Epoch: 6| Step: 7
Training loss: 3.152751229763056
Validation loss: 3.061189119382153

Epoch: 6| Step: 8
Training loss: 2.3727281646833136
Validation loss: 2.976045212547992

Epoch: 6| Step: 9
Training loss: 2.784595320662145
Validation loss: 2.8731833840627634

Epoch: 6| Step: 10
Training loss: 2.631234168505669
Validation loss: 2.937779500768625

Epoch: 6| Step: 11
Training loss: 4.148812199856452
Validation loss: 2.9197133826833386

Epoch: 6| Step: 12
Training loss: 2.5021506595579375
Validation loss: 2.989175394295581

Epoch: 6| Step: 13
Training loss: 1.3599846010177812
Validation loss: 3.1225853711699014

Epoch: 255| Step: 0
Training loss: 3.0721731202300533
Validation loss: 2.841165247118337

Epoch: 6| Step: 1
Training loss: 2.1025494948649683
Validation loss: 3.015103591285924

Epoch: 6| Step: 2
Training loss: 2.970412742372074
Validation loss: 2.867820344218419

Epoch: 6| Step: 3
Training loss: 3.390049054851466
Validation loss: 3.117392594372833

Epoch: 6| Step: 4
Training loss: 2.6463164441646523
Validation loss: 2.9822462019036675

Epoch: 6| Step: 5
Training loss: 1.8697522795911048
Validation loss: 3.0247323437712605

Epoch: 6| Step: 6
Training loss: 3.541638512592983
Validation loss: 2.81166969357751

Epoch: 6| Step: 7
Training loss: 2.680812410512695
Validation loss: 2.876998182011496

Epoch: 6| Step: 8
Training loss: 2.6670470761126754
Validation loss: 2.9005178146949535

Epoch: 6| Step: 9
Training loss: 2.657880753723384
Validation loss: 2.9386701153727004

Epoch: 6| Step: 10
Training loss: 2.8751744756415842
Validation loss: 2.8675891064848136

Epoch: 6| Step: 11
Training loss: 3.2781789304299043
Validation loss: 2.9821643309440815

Epoch: 6| Step: 12
Training loss: 2.3875235591345194
Validation loss: 2.877755244386415

Epoch: 6| Step: 13
Training loss: 2.76292416867583
Validation loss: 3.0536098395737974

Epoch: 256| Step: 0
Training loss: 2.910394154495484
Validation loss: 2.762655770449868

Epoch: 6| Step: 1
Training loss: 2.4307023164552057
Validation loss: 3.0055824675747145

Epoch: 6| Step: 2
Training loss: 2.683574204463938
Validation loss: 2.7120171605398284

Epoch: 6| Step: 3
Training loss: 3.048124555971396
Validation loss: 2.8803282260706116

Epoch: 6| Step: 4
Training loss: 2.352722895538988
Validation loss: 2.8913914297146843

Epoch: 6| Step: 5
Training loss: 2.8991053549553625
Validation loss: 3.091707577368508

Epoch: 6| Step: 6
Training loss: 2.3793126152243165
Validation loss: 2.8038697469804057

Epoch: 6| Step: 7
Training loss: 3.24231942149722
Validation loss: 3.0199561441311236

Epoch: 6| Step: 8
Training loss: 3.248017807014398
Validation loss: 3.183182414357548

Epoch: 6| Step: 9
Training loss: 3.2551731606172702
Validation loss: 3.0125615467961215

Epoch: 6| Step: 10
Training loss: 2.8249841605223467
Validation loss: 2.9293499784573838

Epoch: 6| Step: 11
Training loss: 2.6152351954874087
Validation loss: 3.147582070830491

Epoch: 6| Step: 12
Training loss: 2.2706004265385555
Validation loss: 2.987859896270573

Epoch: 6| Step: 13
Training loss: 2.244062218155423
Validation loss: 2.9837304396215245

Epoch: 257| Step: 0
Training loss: 3.220890703632095
Validation loss: 2.893200148490499

Epoch: 6| Step: 1
Training loss: 3.2247714412635
Validation loss: 2.8295423271305293

Epoch: 6| Step: 2
Training loss: 3.3277434367631784
Validation loss: 2.886180085602586

Epoch: 6| Step: 3
Training loss: 2.518727066276398
Validation loss: 2.808554782049715

Epoch: 6| Step: 4
Training loss: 1.9124668243123746
Validation loss: 3.0246114056310223

Epoch: 6| Step: 5
Training loss: 2.489583439740507
Validation loss: 2.9710365181630434

Epoch: 6| Step: 6
Training loss: 2.8771261563291928
Validation loss: 2.7533085609886276

Epoch: 6| Step: 7
Training loss: 2.590575148007319
Validation loss: 3.0986194839315755

Epoch: 6| Step: 8
Training loss: 2.6323544248087223
Validation loss: 2.9468054992492667

Epoch: 6| Step: 9
Training loss: 2.763956029727162
Validation loss: 2.989685438162643

Epoch: 6| Step: 10
Training loss: 2.357009307991847
Validation loss: 2.9162922725839313

Epoch: 6| Step: 11
Training loss: 3.3809578196419787
Validation loss: 3.0366888851395144

Epoch: 6| Step: 12
Training loss: 3.485872913208543
Validation loss: 3.056634081363341

Epoch: 6| Step: 13
Training loss: 2.1719404251892565
Validation loss: 2.934340712701154

Epoch: 258| Step: 0
Training loss: 2.374995181430145
Validation loss: 3.0634718042223774

Epoch: 6| Step: 1
Training loss: 2.9545618830404163
Validation loss: 2.9210161981795304

Epoch: 6| Step: 2
Training loss: 1.9948531324778926
Validation loss: 3.0380718589385816

Epoch: 6| Step: 3
Training loss: 2.0598651354817603
Validation loss: 3.0048628690059918

Epoch: 6| Step: 4
Training loss: 3.266269455978428
Validation loss: 2.8983988660789275

Epoch: 6| Step: 5
Training loss: 3.475091858891557
Validation loss: 2.972781838006448

Epoch: 6| Step: 6
Training loss: 2.7156684336464765
Validation loss: 2.9270452643543363

Epoch: 6| Step: 7
Training loss: 2.795881212016881
Validation loss: 2.886518687680973

Epoch: 6| Step: 8
Training loss: 3.298022319156037
Validation loss: 2.8686236472805415

Epoch: 6| Step: 9
Training loss: 3.570315304677851
Validation loss: 2.8160608007602845

Epoch: 6| Step: 10
Training loss: 2.9202850422147497
Validation loss: 2.8584326263644018

Epoch: 6| Step: 11
Training loss: 1.9081414641273828
Validation loss: 2.928371352899335

Epoch: 6| Step: 12
Training loss: 2.121599843045915
Validation loss: 2.8730282417790054

Epoch: 6| Step: 13
Training loss: 1.1081828306785086
Validation loss: 3.1529244262966003

Epoch: 259| Step: 0
Training loss: 2.471921597703469
Validation loss: 2.895304579292009

Epoch: 6| Step: 1
Training loss: 3.2124866173610176
Validation loss: 3.12583222003287

Epoch: 6| Step: 2
Training loss: 2.396834741923258
Validation loss: 3.1290445516750967

Epoch: 6| Step: 3
Training loss: 2.990535269958657
Validation loss: 3.0001588611858483

Epoch: 6| Step: 4
Training loss: 3.0547132564151513
Validation loss: 2.9751975613235713

Epoch: 6| Step: 5
Training loss: 2.5824287327906315
Validation loss: 2.868609585141609

Epoch: 6| Step: 6
Training loss: 2.668360311390463
Validation loss: 2.9633664672790117

Epoch: 6| Step: 7
Training loss: 2.2376527020224035
Validation loss: 2.9803959256422683

Epoch: 6| Step: 8
Training loss: 2.1678953965982863
Validation loss: 2.962318648299938

Epoch: 6| Step: 9
Training loss: 2.817101338571658
Validation loss: 2.8852484404397734

Epoch: 6| Step: 10
Training loss: 2.8013251506728882
Validation loss: 2.9589485373408655

Epoch: 6| Step: 11
Training loss: 3.3918949684580126
Validation loss: 2.9364737448403777

Epoch: 6| Step: 12
Training loss: 3.037805135337552
Validation loss: 2.9444617147539636

Epoch: 6| Step: 13
Training loss: 1.8785005952388907
Validation loss: 3.0039596575272114

Epoch: 260| Step: 0
Training loss: 1.8003373333291421
Validation loss: 2.832816675541667

Epoch: 6| Step: 1
Training loss: 3.081868485285461
Validation loss: 2.8289850214882373

Epoch: 6| Step: 2
Training loss: 2.0856575653030416
Validation loss: 2.97615777286311

Epoch: 6| Step: 3
Training loss: 2.831754263124905
Validation loss: 2.8243176622747486

Epoch: 6| Step: 4
Training loss: 3.0197033752889446
Validation loss: 2.9315741433091955

Epoch: 6| Step: 5
Training loss: 2.221475136531256
Validation loss: 3.164395851229122

Epoch: 6| Step: 6
Training loss: 2.7125631509628354
Validation loss: 2.915633703980559

Epoch: 6| Step: 7
Training loss: 2.127418936452517
Validation loss: 2.9176371973953965

Epoch: 6| Step: 8
Training loss: 4.258397501383021
Validation loss: 2.858385061399105

Epoch: 6| Step: 9
Training loss: 3.5798139958570587
Validation loss: 2.9998310094496894

Epoch: 6| Step: 10
Training loss: 2.4320823911589127
Validation loss: 3.0294475027524

Epoch: 6| Step: 11
Training loss: 2.127105343138441
Validation loss: 2.742740531981548

Epoch: 6| Step: 12
Training loss: 2.907192938638697
Validation loss: 3.037975445536088

Epoch: 6| Step: 13
Training loss: 3.241971001807774
Validation loss: 3.0033996667791323

Epoch: 261| Step: 0
Training loss: 3.282214504357128
Validation loss: 2.828665676725528

Epoch: 6| Step: 1
Training loss: 2.040201271076328
Validation loss: 2.9570423731315163

Epoch: 6| Step: 2
Training loss: 3.125664449624743
Validation loss: 2.878733599954217

Epoch: 6| Step: 3
Training loss: 3.6108734851479674
Validation loss: 2.869950524240584

Epoch: 6| Step: 4
Training loss: 2.5252323912386245
Validation loss: 2.954016068002029

Epoch: 6| Step: 5
Training loss: 2.341187665917074
Validation loss: 2.9263087578218134

Epoch: 6| Step: 6
Training loss: 2.786548667703119
Validation loss: 2.9794299288089676

Epoch: 6| Step: 7
Training loss: 2.7638110230263933
Validation loss: 2.8783589430567624

Epoch: 6| Step: 8
Training loss: 2.7517498691240307
Validation loss: 3.016055524875813

Epoch: 6| Step: 9
Training loss: 3.6677113403088413
Validation loss: 2.8716480605414727

Epoch: 6| Step: 10
Training loss: 3.116675313301808
Validation loss: 3.0069750383459173

Epoch: 6| Step: 11
Training loss: 1.9937823923762126
Validation loss: 2.9270540709717556

Epoch: 6| Step: 12
Training loss: 2.759804241452889
Validation loss: 3.0784836077101816

Epoch: 6| Step: 13
Training loss: 3.885515772533103
Validation loss: 2.8521317396352175

Epoch: 262| Step: 0
Training loss: 3.5606944544806067
Validation loss: 3.0374694355444305

Epoch: 6| Step: 1
Training loss: 2.520397705605484
Validation loss: 3.0462862778042537

Epoch: 6| Step: 2
Training loss: 3.421050368628738
Validation loss: 3.0100392075419173

Epoch: 6| Step: 3
Training loss: 1.7096828929606864
Validation loss: 2.861737926490649

Epoch: 6| Step: 4
Training loss: 2.8859857395107946
Validation loss: 3.0443639748456657

Epoch: 6| Step: 5
Training loss: 3.3876450623705425
Validation loss: 3.1018140190843138

Epoch: 6| Step: 6
Training loss: 2.2768278764512693
Validation loss: 2.961101844636525

Epoch: 6| Step: 7
Training loss: 2.8436718605121363
Validation loss: 2.985159447605447

Epoch: 6| Step: 8
Training loss: 1.9258673534527482
Validation loss: 3.1952051872347242

Epoch: 6| Step: 9
Training loss: 3.2925212732553253
Validation loss: 3.089762008621021

Epoch: 6| Step: 10
Training loss: 2.9616836775200146
Validation loss: 2.9991096180229055

Epoch: 6| Step: 11
Training loss: 2.824006343045554
Validation loss: 3.133831694807618

Epoch: 6| Step: 12
Training loss: 2.7374921197647173
Validation loss: 2.979626419960164

Epoch: 6| Step: 13
Training loss: 2.9437057200217667
Validation loss: 3.017974824678874

Epoch: 263| Step: 0
Training loss: 3.107480492749292
Validation loss: 2.99992970415019

Epoch: 6| Step: 1
Training loss: 2.748435529108517
Validation loss: 2.9514598285048352

Epoch: 6| Step: 2
Training loss: 1.8147568956562836
Validation loss: 3.0175791563765118

Epoch: 6| Step: 3
Training loss: 4.04364945582958
Validation loss: 2.9702160948367107

Epoch: 6| Step: 4
Training loss: 2.9945823706869548
Validation loss: 2.761608078570968

Epoch: 6| Step: 5
Training loss: 2.492625039655558
Validation loss: 2.961076161383041

Epoch: 6| Step: 6
Training loss: 2.5396677088209842
Validation loss: 2.898836636920557

Epoch: 6| Step: 7
Training loss: 2.2371202157212347
Validation loss: 2.9178294352985312

Epoch: 6| Step: 8
Training loss: 3.256734472979066
Validation loss: 2.959846210844192

Epoch: 6| Step: 9
Training loss: 3.3577414155858443
Validation loss: 2.952790678430455

Epoch: 6| Step: 10
Training loss: 2.899314069196088
Validation loss: 2.951595165581105

Epoch: 6| Step: 11
Training loss: 2.7453999626457017
Validation loss: 2.9406270523589826

Epoch: 6| Step: 12
Training loss: 2.2971865903260724
Validation loss: 2.8203229552030793

Epoch: 6| Step: 13
Training loss: 2.4518668477557126
Validation loss: 2.979389774932917

Epoch: 264| Step: 0
Training loss: 2.106781785431173
Validation loss: 2.852854318680295

Epoch: 6| Step: 1
Training loss: 3.0365543164917033
Validation loss: 3.0126888299873835

Epoch: 6| Step: 2
Training loss: 2.920713142682934
Validation loss: 2.927132141724651

Epoch: 6| Step: 3
Training loss: 3.5561045745989244
Validation loss: 2.9000674673767763

Epoch: 6| Step: 4
Training loss: 3.2509926967157465
Validation loss: 3.0029025017346225

Epoch: 6| Step: 5
Training loss: 2.632165846379494
Validation loss: 2.9057423455542586

Epoch: 6| Step: 6
Training loss: 3.2925647202650077
Validation loss: 2.8289953884555104

Epoch: 6| Step: 7
Training loss: 1.9025455187692013
Validation loss: 2.891723951608214

Epoch: 6| Step: 8
Training loss: 2.816626001850753
Validation loss: 2.912714610527918

Epoch: 6| Step: 9
Training loss: 2.6552491939289524
Validation loss: 2.9341076628957996

Epoch: 6| Step: 10
Training loss: 2.24668268858331
Validation loss: 2.8498535510455394

Epoch: 6| Step: 11
Training loss: 3.0029519181087707
Validation loss: 2.8395690491717858

Epoch: 6| Step: 12
Training loss: 2.709935599543708
Validation loss: 2.963668879912574

Epoch: 6| Step: 13
Training loss: 3.857329533111497
Validation loss: 2.9618330654817795

Epoch: 265| Step: 0
Training loss: 3.372359479121539
Validation loss: 2.7992423597808482

Epoch: 6| Step: 1
Training loss: 2.5900053086097543
Validation loss: 3.0876762985798734

Epoch: 6| Step: 2
Training loss: 2.612771022920472
Validation loss: 2.7476577684469174

Epoch: 6| Step: 3
Training loss: 3.2248137309375196
Validation loss: 2.9670393552646313

Epoch: 6| Step: 4
Training loss: 3.258644930744675
Validation loss: 3.002080827228216

Epoch: 6| Step: 5
Training loss: 3.6496215467342923
Validation loss: 2.9616680343112978

Epoch: 6| Step: 6
Training loss: 3.314269690756751
Validation loss: 2.9995654160532377

Epoch: 6| Step: 7
Training loss: 2.8444016936023417
Validation loss: 3.0730367118089172

Epoch: 6| Step: 8
Training loss: 2.825391343954051
Validation loss: 2.9191365465195487

Epoch: 6| Step: 9
Training loss: 3.266803145639235
Validation loss: 2.8936341750425703

Epoch: 6| Step: 10
Training loss: 1.851978625444031
Validation loss: 2.8956602028130756

Epoch: 6| Step: 11
Training loss: 2.4111538743574323
Validation loss: 3.0026752804420034

Epoch: 6| Step: 12
Training loss: 2.7123381324673415
Validation loss: 2.95886135862939

Epoch: 6| Step: 13
Training loss: 2.376597018119741
Validation loss: 2.8632604509296105

Epoch: 266| Step: 0
Training loss: 2.684847654002256
Validation loss: 2.959842404157278

Epoch: 6| Step: 1
Training loss: 2.3628508372905532
Validation loss: 2.8720627989397705

Epoch: 6| Step: 2
Training loss: 3.4059271703203473
Validation loss: 3.0842468174574074

Epoch: 6| Step: 3
Training loss: 3.2174477025948853
Validation loss: 2.8934093223686226

Epoch: 6| Step: 4
Training loss: 2.597201154037494
Validation loss: 2.926109927808624

Epoch: 6| Step: 5
Training loss: 3.2234053047558304
Validation loss: 2.97391337153175

Epoch: 6| Step: 6
Training loss: 2.947895728442416
Validation loss: 3.159274005497897

Epoch: 6| Step: 7
Training loss: 3.6482087743648304
Validation loss: 2.988281218257772

Epoch: 6| Step: 8
Training loss: 3.1264199654776244
Validation loss: 3.050774448420754

Epoch: 6| Step: 9
Training loss: 2.0352637908696978
Validation loss: 2.8639408486632276

Epoch: 6| Step: 10
Training loss: 3.045775542817718
Validation loss: 2.909986673300695

Epoch: 6| Step: 11
Training loss: 1.925215446503885
Validation loss: 3.0560869193666744

Epoch: 6| Step: 12
Training loss: 2.7555044744569805
Validation loss: 3.0457032042567067

Epoch: 6| Step: 13
Training loss: 1.3929479677679326
Validation loss: 2.844518226656607

Epoch: 267| Step: 0
Training loss: 2.814161869308936
Validation loss: 3.0251778026515734

Epoch: 6| Step: 1
Training loss: 2.5777616302580073
Validation loss: 2.8572148650188254

Epoch: 6| Step: 2
Training loss: 1.9923238071858307
Validation loss: 3.026667127942152

Epoch: 6| Step: 3
Training loss: 3.2952076822452963
Validation loss: 2.9593315387354253

Epoch: 6| Step: 4
Training loss: 3.0928380373443645
Validation loss: 2.9385676576459847

Epoch: 6| Step: 5
Training loss: 2.0145472521018037
Validation loss: 2.9282539335349407

Epoch: 6| Step: 6
Training loss: 3.133958411938293
Validation loss: 3.1129870575329246

Epoch: 6| Step: 7
Training loss: 2.6806178132394662
Validation loss: 3.0712866268105588

Epoch: 6| Step: 8
Training loss: 2.4522281635287158
Validation loss: 3.0224565039739075

Epoch: 6| Step: 9
Training loss: 2.961801528679477
Validation loss: 2.9988505509704058

Epoch: 6| Step: 10
Training loss: 3.785091372033324
Validation loss: 3.1144325685463143

Epoch: 6| Step: 11
Training loss: 2.534434070204506
Validation loss: 2.916136822426698

Epoch: 6| Step: 12
Training loss: 3.6477708881442346
Validation loss: 2.9754026318883673

Epoch: 6| Step: 13
Training loss: 2.9527597352851602
Validation loss: 2.88457532959004

Epoch: 268| Step: 0
Training loss: 2.0125788655436483
Validation loss: 2.988257522161731

Epoch: 6| Step: 1
Training loss: 2.4482715971633056
Validation loss: 2.9244540316853285

Epoch: 6| Step: 2
Training loss: 2.0106523075923315
Validation loss: 2.868010514216768

Epoch: 6| Step: 3
Training loss: 2.806098774189065
Validation loss: 3.003376460421352

Epoch: 6| Step: 4
Training loss: 2.7663944704138417
Validation loss: 2.859862920440647

Epoch: 6| Step: 5
Training loss: 3.24160945289416
Validation loss: 2.8586808510875574

Epoch: 6| Step: 6
Training loss: 2.7663507748470857
Validation loss: 2.9825459472804465

Epoch: 6| Step: 7
Training loss: 2.9250242835446976
Validation loss: 2.9423850473335182

Epoch: 6| Step: 8
Training loss: 3.5114368499548307
Validation loss: 2.791040107477701

Epoch: 6| Step: 9
Training loss: 2.497556064041363
Validation loss: 2.9832925231950798

Epoch: 6| Step: 10
Training loss: 2.533105523340216
Validation loss: 2.8613384285419006

Epoch: 6| Step: 11
Training loss: 2.61010512684707
Validation loss: 2.8219297951624185

Epoch: 6| Step: 12
Training loss: 3.622856295526654
Validation loss: 2.881341529071987

Epoch: 6| Step: 13
Training loss: 3.0505330354770965
Validation loss: 3.0088044351583108

Epoch: 269| Step: 0
Training loss: 3.555094467174146
Validation loss: 3.0257831274046216

Epoch: 6| Step: 1
Training loss: 2.753965293305447
Validation loss: 2.8695370480204025

Epoch: 6| Step: 2
Training loss: 3.8306552543571937
Validation loss: 2.918687187963471

Epoch: 6| Step: 3
Training loss: 3.311789958356581
Validation loss: 2.8447415447530897

Epoch: 6| Step: 4
Training loss: 2.7537942200727974
Validation loss: 2.947896178921629

Epoch: 6| Step: 5
Training loss: 2.246379907043236
Validation loss: 2.8868131745767656

Epoch: 6| Step: 6
Training loss: 2.335679770448378
Validation loss: 2.9098841756163996

Epoch: 6| Step: 7
Training loss: 2.708158712381938
Validation loss: 2.9314586397667854

Epoch: 6| Step: 8
Training loss: 2.6701626114493537
Validation loss: 2.8574702042394113

Epoch: 6| Step: 9
Training loss: 2.5689901643403656
Validation loss: 3.0007951948997125

Epoch: 6| Step: 10
Training loss: 3.72883699689679
Validation loss: 2.9599865412219044

Epoch: 6| Step: 11
Training loss: 2.8008286646363576
Validation loss: 2.9157158815202733

Epoch: 6| Step: 12
Training loss: 2.9082536251072084
Validation loss: 3.1030801833262496

Epoch: 6| Step: 13
Training loss: 2.921563606192632
Validation loss: 2.940065653293023

Epoch: 270| Step: 0
Training loss: 2.7676224042086797
Validation loss: 2.9568154911177706

Epoch: 6| Step: 1
Training loss: 3.6344061524621445
Validation loss: 2.9863203868394024

Epoch: 6| Step: 2
Training loss: 1.9973124089199676
Validation loss: 3.0361226934694865

Epoch: 6| Step: 3
Training loss: 3.637244230631443
Validation loss: 2.9512384303373653

Epoch: 6| Step: 4
Training loss: 2.986383371484561
Validation loss: 3.01415054904685

Epoch: 6| Step: 5
Training loss: 3.218577259946865
Validation loss: 2.860435980706282

Epoch: 6| Step: 6
Training loss: 3.0370663557041677
Validation loss: 2.9718551432704867

Epoch: 6| Step: 7
Training loss: 2.6572411875688577
Validation loss: 2.9182129665051586

Epoch: 6| Step: 8
Training loss: 2.740214450407561
Validation loss: 2.9072838368056533

Epoch: 6| Step: 9
Training loss: 2.3539531127032713
Validation loss: 3.0539602536407116

Epoch: 6| Step: 10
Training loss: 2.5309518709162147
Validation loss: 2.9265227099332236

Epoch: 6| Step: 11
Training loss: 2.486575130110801
Validation loss: 2.8562070162842206

Epoch: 6| Step: 12
Training loss: 2.1905835897365447
Validation loss: 2.9285633711539503

Epoch: 6| Step: 13
Training loss: 2.0926025434774425
Validation loss: 2.7368648695604105

Epoch: 271| Step: 0
Training loss: 2.0349425571591695
Validation loss: 2.848005158106769

Epoch: 6| Step: 1
Training loss: 2.5471956952164088
Validation loss: 2.9887920400188133

Epoch: 6| Step: 2
Training loss: 2.7836111954135125
Validation loss: 2.9155197531312247

Epoch: 6| Step: 3
Training loss: 3.75986327998177
Validation loss: 2.910739065269381

Epoch: 6| Step: 4
Training loss: 4.2094019423814135
Validation loss: 2.846897831053714

Epoch: 6| Step: 5
Training loss: 3.009135166011434
Validation loss: 2.8367877714860223

Epoch: 6| Step: 6
Training loss: 2.019302916023893
Validation loss: 2.8918772363293823

Epoch: 6| Step: 7
Training loss: 2.581550403322352
Validation loss: 2.901997150595831

Epoch: 6| Step: 8
Training loss: 2.3122340900023497
Validation loss: 2.884565623632218

Epoch: 6| Step: 9
Training loss: 2.3381390355965306
Validation loss: 2.882698336723835

Epoch: 6| Step: 10
Training loss: 2.8019383805420297
Validation loss: 3.123580687419786

Epoch: 6| Step: 11
Training loss: 2.773314567312915
Validation loss: 2.9032194223527434

Epoch: 6| Step: 12
Training loss: 2.633113764610559
Validation loss: 2.969814972629897

Epoch: 6| Step: 13
Training loss: 3.5676334271143486
Validation loss: 2.8573248031434373

Epoch: 272| Step: 0
Training loss: 2.8861529424248937
Validation loss: 3.0316875824010068

Epoch: 6| Step: 1
Training loss: 2.460268831993262
Validation loss: 2.8976619775178163

Epoch: 6| Step: 2
Training loss: 2.394112828896707
Validation loss: 3.008721247025598

Epoch: 6| Step: 3
Training loss: 3.5488090451640373
Validation loss: 2.986360760003857

Epoch: 6| Step: 4
Training loss: 2.731672422795945
Validation loss: 2.9289669917946046

Epoch: 6| Step: 5
Training loss: 2.3812607011529563
Validation loss: 2.857289398737854

Epoch: 6| Step: 6
Training loss: 2.8597145087461446
Validation loss: 2.9734609241177354

Epoch: 6| Step: 7
Training loss: 1.5866913154968794
Validation loss: 2.922848082154905

Epoch: 6| Step: 8
Training loss: 3.0115274846043403
Validation loss: 2.9202438529809887

Epoch: 6| Step: 9
Training loss: 3.2016032255904743
Validation loss: 2.7894912720587572

Epoch: 6| Step: 10
Training loss: 2.9173450952510156
Validation loss: 2.9629146130894237

Epoch: 6| Step: 11
Training loss: 2.8867811885373587
Validation loss: 2.934177400319513

Epoch: 6| Step: 12
Training loss: 3.82740994995948
Validation loss: 2.989715002732772

Epoch: 6| Step: 13
Training loss: 2.8459318405535754
Validation loss: 2.822421306794618

Epoch: 273| Step: 0
Training loss: 2.438052090452141
Validation loss: 2.7726000817830907

Epoch: 6| Step: 1
Training loss: 3.3904483590940586
Validation loss: 2.9201192739380506

Epoch: 6| Step: 2
Training loss: 2.663349671518616
Validation loss: 2.879094221209456

Epoch: 6| Step: 3
Training loss: 2.539060434193871
Validation loss: 2.8731297432740805

Epoch: 6| Step: 4
Training loss: 3.366435451562399
Validation loss: 3.1337963399906537

Epoch: 6| Step: 5
Training loss: 2.388663191323392
Validation loss: 2.943766066343183

Epoch: 6| Step: 6
Training loss: 2.1496559710602057
Validation loss: 2.9743760646008686

Epoch: 6| Step: 7
Training loss: 3.504261419865088
Validation loss: 2.8667139810900983

Epoch: 6| Step: 8
Training loss: 2.3079459222180256
Validation loss: 2.813312126136696

Epoch: 6| Step: 9
Training loss: 3.0715127787658756
Validation loss: 3.019938782379333

Epoch: 6| Step: 10
Training loss: 2.46215596385697
Validation loss: 2.972621363692673

Epoch: 6| Step: 11
Training loss: 2.6134534930157547
Validation loss: 3.066570770049239

Epoch: 6| Step: 12
Training loss: 3.1565689076878924
Validation loss: 3.021526272187337

Epoch: 6| Step: 13
Training loss: 2.6996158467853983
Validation loss: 3.03085634132063

Epoch: 274| Step: 0
Training loss: 2.4668075065957553
Validation loss: 2.9709272516986336

Epoch: 6| Step: 1
Training loss: 2.5348250021338496
Validation loss: 2.9255248353798327

Epoch: 6| Step: 2
Training loss: 2.934056637914849
Validation loss: 2.978643580686782

Epoch: 6| Step: 3
Training loss: 2.5477704305367723
Validation loss: 2.952275689841845

Epoch: 6| Step: 4
Training loss: 2.6128138193985593
Validation loss: 2.9058480992127853

Epoch: 6| Step: 5
Training loss: 3.1899886046777084
Validation loss: 3.0564881190631454

Epoch: 6| Step: 6
Training loss: 2.4496295103870667
Validation loss: 2.902600304668881

Epoch: 6| Step: 7
Training loss: 3.5775263256327974
Validation loss: 3.042998219811412

Epoch: 6| Step: 8
Training loss: 2.687080616720156
Validation loss: 3.069126633561013

Epoch: 6| Step: 9
Training loss: 3.536203336815721
Validation loss: 2.999287199295211

Epoch: 6| Step: 10
Training loss: 3.357223602529747
Validation loss: 2.8043868555323503

Epoch: 6| Step: 11
Training loss: 2.4755774623868736
Validation loss: 2.843303105757539

Epoch: 6| Step: 12
Training loss: 1.8039640487590345
Validation loss: 2.884845683515287

Epoch: 6| Step: 13
Training loss: 2.396194850901898
Validation loss: 2.9170163596867456

Epoch: 275| Step: 0
Training loss: 3.498339804221886
Validation loss: 2.7844651062554604

Epoch: 6| Step: 1
Training loss: 3.553065606982164
Validation loss: 2.9752164370225653

Epoch: 6| Step: 2
Training loss: 2.290442457640863
Validation loss: 2.941382116135316

Epoch: 6| Step: 3
Training loss: 3.1768095972089587
Validation loss: 2.893262922975907

Epoch: 6| Step: 4
Training loss: 2.49026769279182
Validation loss: 2.880004470310707

Epoch: 6| Step: 5
Training loss: 3.4504457324030327
Validation loss: 2.8836459521775875

Epoch: 6| Step: 6
Training loss: 2.562328425920509
Validation loss: 3.1295629286460307

Epoch: 6| Step: 7
Training loss: 3.095668621653146
Validation loss: 2.9096756477637964

Epoch: 6| Step: 8
Training loss: 2.95532758004027
Validation loss: 3.0910857673796546

Epoch: 6| Step: 9
Training loss: 2.6308784059375707
Validation loss: 3.0396829793059186

Epoch: 6| Step: 10
Training loss: 1.5958656779199465
Validation loss: 2.939518476130481

Epoch: 6| Step: 11
Training loss: 2.434399124045564
Validation loss: 2.8699198875966996

Epoch: 6| Step: 12
Training loss: 2.652391211375802
Validation loss: 2.796344380662256

Epoch: 6| Step: 13
Training loss: 3.0973297370378514
Validation loss: 2.903137140988115

Epoch: 276| Step: 0
Training loss: 3.0850745431064444
Validation loss: 2.842256265725583

Epoch: 6| Step: 1
Training loss: 2.298208251972304
Validation loss: 2.8290071355246984

Epoch: 6| Step: 2
Training loss: 2.503837405967824
Validation loss: 3.0118177114198215

Epoch: 6| Step: 3
Training loss: 2.2089045043860702
Validation loss: 2.99034927747646

Epoch: 6| Step: 4
Training loss: 2.6949025602542918
Validation loss: 3.071398350181269

Epoch: 6| Step: 5
Training loss: 3.2249824405162557
Validation loss: 3.0668656851948075

Epoch: 6| Step: 6
Training loss: 2.088070354094876
Validation loss: 2.791168536388581

Epoch: 6| Step: 7
Training loss: 3.7933478907443807
Validation loss: 3.0593982121020042

Epoch: 6| Step: 8
Training loss: 2.7195210733636976
Validation loss: 2.924637972746944

Epoch: 6| Step: 9
Training loss: 3.025439799471245
Validation loss: 2.9442466752103544

Epoch: 6| Step: 10
Training loss: 3.7642213096703374
Validation loss: 3.0533298051384463

Epoch: 6| Step: 11
Training loss: 2.2462779094000247
Validation loss: 2.889340249940096

Epoch: 6| Step: 12
Training loss: 2.7777886443455393
Validation loss: 3.0216939382717958

Epoch: 6| Step: 13
Training loss: 2.4868717722980866
Validation loss: 2.865897225723879

Epoch: 277| Step: 0
Training loss: 2.5528307592266875
Validation loss: 2.995650494215034

Epoch: 6| Step: 1
Training loss: 2.437735130511172
Validation loss: 2.8697570515213595

Epoch: 6| Step: 2
Training loss: 2.7207005836929534
Validation loss: 2.943291492633248

Epoch: 6| Step: 3
Training loss: 2.3749718915380247
Validation loss: 2.8345044488687132

Epoch: 6| Step: 4
Training loss: 3.2835433937947442
Validation loss: 2.8764750052846146

Epoch: 6| Step: 5
Training loss: 2.6569577340126416
Validation loss: 3.000880460847285

Epoch: 6| Step: 6
Training loss: 2.4931164388445075
Validation loss: 2.965227068924676

Epoch: 6| Step: 7
Training loss: 2.3011878387824733
Validation loss: 2.9827612837219144

Epoch: 6| Step: 8
Training loss: 4.51960025032408
Validation loss: 2.7689532602463154

Epoch: 6| Step: 9
Training loss: 2.6003138206065066
Validation loss: 2.879674138355244

Epoch: 6| Step: 10
Training loss: 2.210822867397359
Validation loss: 2.9706663016557298

Epoch: 6| Step: 11
Training loss: 2.6643856445500758
Validation loss: 3.0059006345455663

Epoch: 6| Step: 12
Training loss: 2.1945301983437986
Validation loss: 3.0073222047991957

Epoch: 6| Step: 13
Training loss: 3.2644474516542332
Validation loss: 2.9719615635164405

Epoch: 278| Step: 0
Training loss: 2.9858599258957734
Validation loss: 3.0976537969731828

Epoch: 6| Step: 1
Training loss: 2.266402328261645
Validation loss: 2.9294470903754304

Epoch: 6| Step: 2
Training loss: 3.0291536298538633
Validation loss: 3.094191813728831

Epoch: 6| Step: 3
Training loss: 2.9301936411746365
Validation loss: 3.042092813624186

Epoch: 6| Step: 4
Training loss: 2.71780177275361
Validation loss: 2.9042224389695614

Epoch: 6| Step: 5
Training loss: 2.388046769251253
Validation loss: 2.8811574309461534

Epoch: 6| Step: 6
Training loss: 2.1672301537813716
Validation loss: 2.8393430787425618

Epoch: 6| Step: 7
Training loss: 3.445583479901158
Validation loss: 2.9983940526074506

Epoch: 6| Step: 8
Training loss: 2.2092140408902883
Validation loss: 2.816774186408994

Epoch: 6| Step: 9
Training loss: 2.603824582837891
Validation loss: 2.7664664941697636

Epoch: 6| Step: 10
Training loss: 3.6561993978536282
Validation loss: 2.861347275222968

Epoch: 6| Step: 11
Training loss: 2.553319535612404
Validation loss: 2.9712692866516788

Epoch: 6| Step: 12
Training loss: 2.768245253182745
Validation loss: 2.824937137706928

Epoch: 6| Step: 13
Training loss: 2.4266701757314832
Validation loss: 2.8520371861641554

Epoch: 279| Step: 0
Training loss: 3.178656783572883
Validation loss: 3.0056310637061965

Epoch: 6| Step: 1
Training loss: 3.9481500373784386
Validation loss: 2.7890599364156348

Epoch: 6| Step: 2
Training loss: 1.8129918319046836
Validation loss: 2.8168027680973844

Epoch: 6| Step: 3
Training loss: 2.017490322274179
Validation loss: 2.9519431844304336

Epoch: 6| Step: 4
Training loss: 3.193750722627502
Validation loss: 2.967770127315917

Epoch: 6| Step: 5
Training loss: 3.3656193385169564
Validation loss: 2.7411166168732928

Epoch: 6| Step: 6
Training loss: 2.74118075678634
Validation loss: 2.84097018046247

Epoch: 6| Step: 7
Training loss: 2.4479379423042076
Validation loss: 2.7972447099468876

Epoch: 6| Step: 8
Training loss: 2.6039291476969155
Validation loss: 2.9583001719142374

Epoch: 6| Step: 9
Training loss: 3.230043616221817
Validation loss: 2.941523747018319

Epoch: 6| Step: 10
Training loss: 1.9170792453487095
Validation loss: 3.0885080821519146

Epoch: 6| Step: 11
Training loss: 2.8822662745769128
Validation loss: 2.923247939501074

Epoch: 6| Step: 12
Training loss: 2.8067266760305767
Validation loss: 2.7971730580134078

Epoch: 6| Step: 13
Training loss: 1.7886834555136693
Validation loss: 3.0852092788687515

Epoch: 280| Step: 0
Training loss: 2.8964461814744173
Validation loss: 2.931201804331786

Epoch: 6| Step: 1
Training loss: 2.956468576492336
Validation loss: 2.892212877434625

Epoch: 6| Step: 2
Training loss: 3.8352025215557597
Validation loss: 3.1504555065066686

Epoch: 6| Step: 3
Training loss: 2.4977250238566704
Validation loss: 2.9550168814339237

Epoch: 6| Step: 4
Training loss: 2.7746626605943354
Validation loss: 2.8829439225903664

Epoch: 6| Step: 5
Training loss: 2.931523838550731
Validation loss: 3.0036259550055773

Epoch: 6| Step: 6
Training loss: 2.965812434392319
Validation loss: 2.8501574786002393

Epoch: 6| Step: 7
Training loss: 2.076487189793725
Validation loss: 2.948608432644564

Epoch: 6| Step: 8
Training loss: 3.1383317004615017
Validation loss: 2.842721818346441

Epoch: 6| Step: 9
Training loss: 2.4989263136289686
Validation loss: 3.0139302149966682

Epoch: 6| Step: 10
Training loss: 2.8254292322361416
Validation loss: 2.7569762144287346

Epoch: 6| Step: 11
Training loss: 2.4868514475889967
Validation loss: 2.8542974801502026

Epoch: 6| Step: 12
Training loss: 2.457668688738569
Validation loss: 2.9028794503609556

Epoch: 6| Step: 13
Training loss: 3.0877814469649874
Validation loss: 2.9211659167956108

Epoch: 281| Step: 0
Training loss: 3.5810263252643546
Validation loss: 2.9218664681915087

Epoch: 6| Step: 1
Training loss: 2.271984986551137
Validation loss: 2.9487657850685163

Epoch: 6| Step: 2
Training loss: 2.058598382644218
Validation loss: 3.007310120213577

Epoch: 6| Step: 3
Training loss: 2.6763840490602173
Validation loss: 3.0582327085790473

Epoch: 6| Step: 4
Training loss: 3.378920644387692
Validation loss: 2.9138952075981464

Epoch: 6| Step: 5
Training loss: 3.3190119810563368
Validation loss: 2.912512629051736

Epoch: 6| Step: 6
Training loss: 2.7150769908800467
Validation loss: 3.0094020504901158

Epoch: 6| Step: 7
Training loss: 2.8336946219681627
Validation loss: 2.836532132228223

Epoch: 6| Step: 8
Training loss: 2.912154567682529
Validation loss: 2.9901141849856008

Epoch: 6| Step: 9
Training loss: 1.647122115934646
Validation loss: 2.8927953676638363

Epoch: 6| Step: 10
Training loss: 2.927741215489841
Validation loss: 2.994726473333658

Epoch: 6| Step: 11
Training loss: 2.2016207923508917
Validation loss: 3.0060433665247865

Epoch: 6| Step: 12
Training loss: 2.6614350817436705
Validation loss: 2.829773878124528

Epoch: 6| Step: 13
Training loss: 3.473628145203499
Validation loss: 3.0173342174943283

Epoch: 282| Step: 0
Training loss: 3.2988229212880804
Validation loss: 2.8608037188981155

Epoch: 6| Step: 1
Training loss: 2.3512076176621535
Validation loss: 2.8475071462762864

Epoch: 6| Step: 2
Training loss: 2.517213118722926
Validation loss: 2.7801108539797847

Epoch: 6| Step: 3
Training loss: 2.7288125271870025
Validation loss: 2.949173210806774

Epoch: 6| Step: 4
Training loss: 1.8238140694735758
Validation loss: 2.888131546606854

Epoch: 6| Step: 5
Training loss: 3.287683773343455
Validation loss: 2.8888734512282106

Epoch: 6| Step: 6
Training loss: 3.0988830215321355
Validation loss: 2.9478860909536513

Epoch: 6| Step: 7
Training loss: 2.5434491103765366
Validation loss: 2.920665222692788

Epoch: 6| Step: 8
Training loss: 2.9917928968344096
Validation loss: 2.9047689325869577

Epoch: 6| Step: 9
Training loss: 2.770292922551603
Validation loss: 3.0487414326811213

Epoch: 6| Step: 10
Training loss: 2.4467269170585704
Validation loss: 2.905660599718343

Epoch: 6| Step: 11
Training loss: 2.500675491627954
Validation loss: 2.904312290538826

Epoch: 6| Step: 12
Training loss: 3.5655220999818504
Validation loss: 3.08946468036454

Epoch: 6| Step: 13
Training loss: 2.321513472042065
Validation loss: 2.8597760684952385

Epoch: 283| Step: 0
Training loss: 2.504305660391264
Validation loss: 2.7873807383026876

Epoch: 6| Step: 1
Training loss: 3.1423347336216425
Validation loss: 2.94397805005971

Epoch: 6| Step: 2
Training loss: 2.7313402174097146
Validation loss: 3.0262249422365746

Epoch: 6| Step: 3
Training loss: 2.6654440242605104
Validation loss: 2.8675933789342527

Epoch: 6| Step: 4
Training loss: 2.896245163282522
Validation loss: 2.8936834817730412

Epoch: 6| Step: 5
Training loss: 2.4970812925978283
Validation loss: 2.94325457022565

Epoch: 6| Step: 6
Training loss: 1.956178886900411
Validation loss: 2.870323116012611

Epoch: 6| Step: 7
Training loss: 2.739958202015407
Validation loss: 2.99120776381332

Epoch: 6| Step: 8
Training loss: 3.0208716729899088
Validation loss: 3.0090300051042256

Epoch: 6| Step: 9
Training loss: 2.3059403457138092
Validation loss: 2.967605819373905

Epoch: 6| Step: 10
Training loss: 2.2498223976400564
Validation loss: 2.9799807126415616

Epoch: 6| Step: 11
Training loss: 2.2230031257363745
Validation loss: 2.9422030827636547

Epoch: 6| Step: 12
Training loss: 2.809976420456319
Validation loss: 2.922034520226715

Epoch: 6| Step: 13
Training loss: 3.5912607611213807
Validation loss: 3.071909269901734

Epoch: 284| Step: 0
Training loss: 2.8978813851185827
Validation loss: 2.9913433859926233

Epoch: 6| Step: 1
Training loss: 3.1506712304317803
Validation loss: 2.9509415774505046

Epoch: 6| Step: 2
Training loss: 3.435215416251896
Validation loss: 2.896798843497979

Epoch: 6| Step: 3
Training loss: 2.6300074635969075
Validation loss: 2.961682475197973

Epoch: 6| Step: 4
Training loss: 2.624496593343043
Validation loss: 2.8835331732740364

Epoch: 6| Step: 5
Training loss: 2.9000519320343376
Validation loss: 2.937453149802871

Epoch: 6| Step: 6
Training loss: 3.4457498216637976
Validation loss: 2.9794134314188088

Epoch: 6| Step: 7
Training loss: 2.807482503563023
Validation loss: 2.9134663692910903

Epoch: 6| Step: 8
Training loss: 1.9271283806012
Validation loss: 2.932710249671788

Epoch: 6| Step: 9
Training loss: 1.879306806031817
Validation loss: 2.9845269380392017

Epoch: 6| Step: 10
Training loss: 3.067300265275377
Validation loss: 3.0599911642660818

Epoch: 6| Step: 11
Training loss: 3.1906931721337877
Validation loss: 2.9408640810494213

Epoch: 6| Step: 12
Training loss: 3.298259715498297
Validation loss: 2.7930171224322176

Epoch: 6| Step: 13
Training loss: 2.5591129154815677
Validation loss: 2.8880812734069026

Epoch: 285| Step: 0
Training loss: 2.1827338475534233
Validation loss: 2.8860736983055584

Epoch: 6| Step: 1
Training loss: 2.3649273144639675
Validation loss: 2.9899223443844756

Epoch: 6| Step: 2
Training loss: 2.475745418309754
Validation loss: 2.9930596552205793

Epoch: 6| Step: 3
Training loss: 2.847826038212464
Validation loss: 2.831024824358481

Epoch: 6| Step: 4
Training loss: 2.4720989641854563
Validation loss: 2.9373261455473845

Epoch: 6| Step: 5
Training loss: 3.293580348008693
Validation loss: 2.8771502054559295

Epoch: 6| Step: 6
Training loss: 2.635842953508711
Validation loss: 2.9744375275378143

Epoch: 6| Step: 7
Training loss: 3.746798611101659
Validation loss: 2.816331346151911

Epoch: 6| Step: 8
Training loss: 2.6787271363550493
Validation loss: 2.648513684435541

Epoch: 6| Step: 9
Training loss: 3.0321067307239473
Validation loss: 2.8058799466226327

Epoch: 6| Step: 10
Training loss: 2.7125277293673276
Validation loss: 2.7887277084808946

Epoch: 6| Step: 11
Training loss: 2.503947288902913
Validation loss: 2.904841112960983

Epoch: 6| Step: 12
Training loss: 2.7972965881739236
Validation loss: 2.8349241812923918

Epoch: 6| Step: 13
Training loss: 3.6370158499245697
Validation loss: 2.950064855884264

Epoch: 286| Step: 0
Training loss: 2.6368129685133925
Validation loss: 2.870924044837994

Epoch: 6| Step: 1
Training loss: 2.859640807424134
Validation loss: 2.8693011453339734

Epoch: 6| Step: 2
Training loss: 2.9865184496251103
Validation loss: 2.948750295896148

Epoch: 6| Step: 3
Training loss: 2.7804924436815357
Validation loss: 2.9446580885048586

Epoch: 6| Step: 4
Training loss: 2.592045603174363
Validation loss: 2.8833291049176797

Epoch: 6| Step: 5
Training loss: 1.7402682145892674
Validation loss: 2.889295144053858

Epoch: 6| Step: 6
Training loss: 2.981125265586989
Validation loss: 2.827362886097093

Epoch: 6| Step: 7
Training loss: 2.9562200242311194
Validation loss: 2.6909447619073212

Epoch: 6| Step: 8
Training loss: 3.311371521093338
Validation loss: 2.9402107624832694

Epoch: 6| Step: 9
Training loss: 2.4047169941957978
Validation loss: 2.9996137592564223

Epoch: 6| Step: 10
Training loss: 2.777960385572227
Validation loss: 2.748214041062287

Epoch: 6| Step: 11
Training loss: 2.349928988743326
Validation loss: 2.8516445425123518

Epoch: 6| Step: 12
Training loss: 2.9908641946737475
Validation loss: 2.919223975406089

Epoch: 6| Step: 13
Training loss: 3.1852525754037484
Validation loss: 2.9293743007149766

Epoch: 287| Step: 0
Training loss: 2.820857198849972
Validation loss: 2.8687459559372677

Epoch: 6| Step: 1
Training loss: 2.6164358397639096
Validation loss: 2.8902016642067516

Epoch: 6| Step: 2
Training loss: 2.8197467268167107
Validation loss: 2.8866067892087917

Epoch: 6| Step: 3
Training loss: 2.4263656821327233
Validation loss: 2.9141660796878237

Epoch: 6| Step: 4
Training loss: 2.8144460091643215
Validation loss: 2.8970128582532526

Epoch: 6| Step: 5
Training loss: 2.273920696073469
Validation loss: 2.8071658515136755

Epoch: 6| Step: 6
Training loss: 1.6138651163068747
Validation loss: 2.7815329617570725

Epoch: 6| Step: 7
Training loss: 3.2965116617027443
Validation loss: 3.014851312705676

Epoch: 6| Step: 8
Training loss: 3.3687290283003293
Validation loss: 2.8864527796315897

Epoch: 6| Step: 9
Training loss: 2.052095468036642
Validation loss: 3.030336885869099

Epoch: 6| Step: 10
Training loss: 2.0365914173657518
Validation loss: 2.8489547027284603

Epoch: 6| Step: 11
Training loss: 3.5833882763812577
Validation loss: 2.880991239065689

Epoch: 6| Step: 12
Training loss: 2.479704587477308
Validation loss: 2.6124566660770374

Epoch: 6| Step: 13
Training loss: 3.297879468298797
Validation loss: 2.981644123009388

Epoch: 288| Step: 0
Training loss: 1.6640933038430459
Validation loss: 3.0917512617474663

Epoch: 6| Step: 1
Training loss: 2.0282877523190037
Validation loss: 2.888720305305146

Epoch: 6| Step: 2
Training loss: 3.4113296290378714
Validation loss: 2.8394242157182905

Epoch: 6| Step: 3
Training loss: 3.220741914847519
Validation loss: 2.9260640570025065

Epoch: 6| Step: 4
Training loss: 3.3948270714922892
Validation loss: 2.9073744023480876

Epoch: 6| Step: 5
Training loss: 2.6423118665809793
Validation loss: 2.7915447932752424

Epoch: 6| Step: 6
Training loss: 2.8112664802580456
Validation loss: 2.811701746314507

Epoch: 6| Step: 7
Training loss: 1.4760148581917403
Validation loss: 2.913546482114333

Epoch: 6| Step: 8
Training loss: 3.580136728925689
Validation loss: 2.8747981296198644

Epoch: 6| Step: 9
Training loss: 2.877419158834006
Validation loss: 2.8816618491756767

Epoch: 6| Step: 10
Training loss: 2.713985257979451
Validation loss: 2.916959054123338

Epoch: 6| Step: 11
Training loss: 2.5965520591401967
Validation loss: 2.8863832089833417

Epoch: 6| Step: 12
Training loss: 1.5638469231175063
Validation loss: 2.718675457030678

Epoch: 6| Step: 13
Training loss: 3.1145199330148734
Validation loss: 3.040523890600267

Epoch: 289| Step: 0
Training loss: 3.5053435814863536
Validation loss: 2.997574995125402

Epoch: 6| Step: 1
Training loss: 2.4549299269734965
Validation loss: 2.978546633667415

Epoch: 6| Step: 2
Training loss: 2.23823075961541
Validation loss: 2.8920016517408644

Epoch: 6| Step: 3
Training loss: 2.4331870435696805
Validation loss: 2.9487853385544716

Epoch: 6| Step: 4
Training loss: 2.9446279200684224
Validation loss: 2.955655255987561

Epoch: 6| Step: 5
Training loss: 2.335052833041099
Validation loss: 2.9759277462760605

Epoch: 6| Step: 6
Training loss: 3.1999284378633046
Validation loss: 2.8084472588837355

Epoch: 6| Step: 7
Training loss: 3.0253261611010607
Validation loss: 3.0941069028246737

Epoch: 6| Step: 8
Training loss: 3.111536089693221
Validation loss: 2.8712442771166047

Epoch: 6| Step: 9
Training loss: 1.9356393185739684
Validation loss: 2.9103659123260384

Epoch: 6| Step: 10
Training loss: 1.5494768244194044
Validation loss: 2.8549814219278273

Epoch: 6| Step: 11
Training loss: 4.229577982527136
Validation loss: 2.7438919365169956

Epoch: 6| Step: 12
Training loss: 2.8381565964382167
Validation loss: 2.776854384431227

Epoch: 6| Step: 13
Training loss: 2.9046291630690435
Validation loss: 2.9723120527812856

Epoch: 290| Step: 0
Training loss: 2.963246112336576
Validation loss: 2.9408869682421366

Epoch: 6| Step: 1
Training loss: 3.555000978837234
Validation loss: 2.8017201247526127

Epoch: 6| Step: 2
Training loss: 2.6109654496418817
Validation loss: 2.8743319036096975

Epoch: 6| Step: 3
Training loss: 2.3160871572219888
Validation loss: 2.96614813784505

Epoch: 6| Step: 4
Training loss: 2.015141628768703
Validation loss: 2.9072890738065365

Epoch: 6| Step: 5
Training loss: 3.9782005189018954
Validation loss: 2.8536456783578603

Epoch: 6| Step: 6
Training loss: 2.755439493809768
Validation loss: 2.816428228869437

Epoch: 6| Step: 7
Training loss: 2.8344790068431225
Validation loss: 2.900062570932943

Epoch: 6| Step: 8
Training loss: 2.451128785259953
Validation loss: 2.8728053815167254

Epoch: 6| Step: 9
Training loss: 2.455040056636042
Validation loss: 2.9226664002811513

Epoch: 6| Step: 10
Training loss: 3.4364172877627603
Validation loss: 2.9127878886797745

Epoch: 6| Step: 11
Training loss: 2.489859136097591
Validation loss: 2.901601531052126

Epoch: 6| Step: 12
Training loss: 2.644066187931866
Validation loss: 2.8904456262827476

Epoch: 6| Step: 13
Training loss: 1.566544372100622
Validation loss: 2.9036400355910192

Epoch: 291| Step: 0
Training loss: 2.3600800326079923
Validation loss: 2.8583494189954903

Epoch: 6| Step: 1
Training loss: 2.9365443846421995
Validation loss: 2.82947665302973

Epoch: 6| Step: 2
Training loss: 3.4835472321126026
Validation loss: 3.0250698629685093

Epoch: 6| Step: 3
Training loss: 1.9382533177888999
Validation loss: 2.8233842135986285

Epoch: 6| Step: 4
Training loss: 2.8436477139700327
Validation loss: 3.0117309667104006

Epoch: 6| Step: 5
Training loss: 2.7728633662450393
Validation loss: 2.8461474842246623

Epoch: 6| Step: 6
Training loss: 3.701384445165496
Validation loss: 2.959403133742638

Epoch: 6| Step: 7
Training loss: 2.5318565112973577
Validation loss: 2.9805082442384556

Epoch: 6| Step: 8
Training loss: 2.8023127541105377
Validation loss: 2.9141048630769233

Epoch: 6| Step: 9
Training loss: 3.124561126408958
Validation loss: 3.023232365329488

Epoch: 6| Step: 10
Training loss: 2.654809269349178
Validation loss: 3.01462928910485

Epoch: 6| Step: 11
Training loss: 2.693806722446499
Validation loss: 3.019490240386051

Epoch: 6| Step: 12
Training loss: 3.460854281766157
Validation loss: 2.9679760557181827

Epoch: 6| Step: 13
Training loss: 1.7010353638002138
Validation loss: 2.994293706226628

Epoch: 292| Step: 0
Training loss: 2.1897124954393226
Validation loss: 2.9562410884985533

Epoch: 6| Step: 1
Training loss: 3.8564356680368133
Validation loss: 3.0309397356089263

Epoch: 6| Step: 2
Training loss: 2.4915759254016354
Validation loss: 2.906395115417678

Epoch: 6| Step: 3
Training loss: 2.639333375227233
Validation loss: 3.0278508002329105

Epoch: 6| Step: 4
Training loss: 2.9903632197910834
Validation loss: 2.9019413470921487

Epoch: 6| Step: 5
Training loss: 3.696787372495395
Validation loss: 2.858046985988568

Epoch: 6| Step: 6
Training loss: 2.4195469649743426
Validation loss: 2.9747321951641936

Epoch: 6| Step: 7
Training loss: 2.8394392268519923
Validation loss: 2.91716318489513

Epoch: 6| Step: 8
Training loss: 3.4736359697852532
Validation loss: 2.7869892778746577

Epoch: 6| Step: 9
Training loss: 2.4629905250853397
Validation loss: 2.9368426604839266

Epoch: 6| Step: 10
Training loss: 1.8276975735218255
Validation loss: 2.9816981433792717

Epoch: 6| Step: 11
Training loss: 3.172266442710152
Validation loss: 2.8481283449932215

Epoch: 6| Step: 12
Training loss: 2.4566195920922445
Validation loss: 2.919153549664485

Epoch: 6| Step: 13
Training loss: 2.6359755535352467
Validation loss: 2.7864758050597187

Epoch: 293| Step: 0
Training loss: 3.314073584725539
Validation loss: 2.8697015894733964

Epoch: 6| Step: 1
Training loss: 2.6665779834147134
Validation loss: 2.856063366752194

Epoch: 6| Step: 2
Training loss: 2.6072446612882185
Validation loss: 2.9456821145646934

Epoch: 6| Step: 3
Training loss: 2.9246419769014804
Validation loss: 2.870950430107762

Epoch: 6| Step: 4
Training loss: 2.8427937335564555
Validation loss: 2.9398320858733293

Epoch: 6| Step: 5
Training loss: 3.1637444983908916
Validation loss: 2.9244125443800058

Epoch: 6| Step: 6
Training loss: 2.4158103565791498
Validation loss: 2.7378389371300593

Epoch: 6| Step: 7
Training loss: 2.9016077846430037
Validation loss: 2.864670464914251

Epoch: 6| Step: 8
Training loss: 2.4025072988028113
Validation loss: 2.8494928252329035

Epoch: 6| Step: 9
Training loss: 2.8597832060055817
Validation loss: 3.059885358336494

Epoch: 6| Step: 10
Training loss: 2.049831206653134
Validation loss: 2.871481962887055

Epoch: 6| Step: 11
Training loss: 2.7793154042337362
Validation loss: 2.9447424195376892

Epoch: 6| Step: 12
Training loss: 3.9548447076183604
Validation loss: 2.8357667396124824

Epoch: 6| Step: 13
Training loss: 1.6626251890616743
Validation loss: 2.9900029843217713

Epoch: 294| Step: 0
Training loss: 1.5473473338313193
Validation loss: 2.9990667887889217

Epoch: 6| Step: 1
Training loss: 2.6021983426416635
Validation loss: 2.772944617883846

Epoch: 6| Step: 2
Training loss: 2.2584234024986576
Validation loss: 2.8275425388825397

Epoch: 6| Step: 3
Training loss: 2.4944647546275047
Validation loss: 2.8564905458060386

Epoch: 6| Step: 4
Training loss: 2.7029717903598627
Validation loss: 2.8219566680530455

Epoch: 6| Step: 5
Training loss: 2.5526661006375266
Validation loss: 2.977536307320754

Epoch: 6| Step: 6
Training loss: 2.76962301642971
Validation loss: 2.90158053044466

Epoch: 6| Step: 7
Training loss: 2.353217774850858
Validation loss: 2.77003032852231

Epoch: 6| Step: 8
Training loss: 3.0061709197304154
Validation loss: 2.958476924632229

Epoch: 6| Step: 9
Training loss: 3.4672985992579317
Validation loss: 2.8502137940690084

Epoch: 6| Step: 10
Training loss: 3.325861344595063
Validation loss: 2.8895206930605473

Epoch: 6| Step: 11
Training loss: 3.0450678234345463
Validation loss: 2.9500461242793556

Epoch: 6| Step: 12
Training loss: 2.4334552168259362
Validation loss: 2.8553691696436854

Epoch: 6| Step: 13
Training loss: 2.3200304264506926
Validation loss: 3.0158359879476295

Epoch: 295| Step: 0
Training loss: 2.339160545602945
Validation loss: 2.949319144451688

Epoch: 6| Step: 1
Training loss: 2.5022174537745756
Validation loss: 2.98202420344101

Epoch: 6| Step: 2
Training loss: 2.617238331770824
Validation loss: 2.999830120670739

Epoch: 6| Step: 3
Training loss: 2.638001894090506
Validation loss: 3.0025768629737617

Epoch: 6| Step: 4
Training loss: 3.0824255938804237
Validation loss: 2.8707233970552033

Epoch: 6| Step: 5
Training loss: 2.2283290346951086
Validation loss: 2.9007611990345974

Epoch: 6| Step: 6
Training loss: 2.996133856274916
Validation loss: 2.7604141287967083

Epoch: 6| Step: 7
Training loss: 2.865275980121416
Validation loss: 2.893399566301823

Epoch: 6| Step: 8
Training loss: 2.3769602465934296
Validation loss: 2.935083268303983

Epoch: 6| Step: 9
Training loss: 2.1233329966179038
Validation loss: 3.0139000228974333

Epoch: 6| Step: 10
Training loss: 3.32536466506151
Validation loss: 2.9151656605669882

Epoch: 6| Step: 11
Training loss: 2.590429731678353
Validation loss: 2.969010732499621

Epoch: 6| Step: 12
Training loss: 2.5272243182633742
Validation loss: 2.9587138091758654

Epoch: 6| Step: 13
Training loss: 2.573137302179326
Validation loss: 2.743507971128353

Epoch: 296| Step: 0
Training loss: 2.7302593538382376
Validation loss: 2.9358078536553895

Epoch: 6| Step: 1
Training loss: 2.6293204946198045
Validation loss: 2.786418503177706

Epoch: 6| Step: 2
Training loss: 3.0401526214535606
Validation loss: 2.9392861822497283

Epoch: 6| Step: 3
Training loss: 3.6055324957968513
Validation loss: 2.8137882686716478

Epoch: 6| Step: 4
Training loss: 2.7554909766057594
Validation loss: 3.03989750420828

Epoch: 6| Step: 5
Training loss: 2.542923746721601
Validation loss: 2.866614809256412

Epoch: 6| Step: 6
Training loss: 3.5875241959982036
Validation loss: 2.9611976832388693

Epoch: 6| Step: 7
Training loss: 2.7137087857750912
Validation loss: 2.8563315134629854

Epoch: 6| Step: 8
Training loss: 2.58476844016088
Validation loss: 2.869618928628799

Epoch: 6| Step: 9
Training loss: 2.635291135509791
Validation loss: 2.7358780599883725

Epoch: 6| Step: 10
Training loss: 3.0549686234231763
Validation loss: 2.882876751871755

Epoch: 6| Step: 11
Training loss: 1.8037281211112985
Validation loss: 2.958182541780883

Epoch: 6| Step: 12
Training loss: 2.266310279073979
Validation loss: 2.9675305606485374

Epoch: 6| Step: 13
Training loss: 2.231562411451585
Validation loss: 3.0166065612780657

Epoch: 297| Step: 0
Training loss: 2.2784564537188152
Validation loss: 2.861260124276832

Epoch: 6| Step: 1
Training loss: 2.8782486183880867
Validation loss: 2.961678118615889

Epoch: 6| Step: 2
Training loss: 2.357081732432178
Validation loss: 2.9200144199246223

Epoch: 6| Step: 3
Training loss: 2.6793579254780924
Validation loss: 2.8062733533009814

Epoch: 6| Step: 4
Training loss: 3.316683736274794
Validation loss: 2.868986831423621

Epoch: 6| Step: 5
Training loss: 2.751556736140196
Validation loss: 2.915972519528163

Epoch: 6| Step: 6
Training loss: 2.4595559738251347
Validation loss: 2.9953303329446426

Epoch: 6| Step: 7
Training loss: 2.470134781314596
Validation loss: 2.968005162805606

Epoch: 6| Step: 8
Training loss: 2.6903944175886894
Validation loss: 2.7559021894646203

Epoch: 6| Step: 9
Training loss: 2.1032778181355956
Validation loss: 2.9845701872285813

Epoch: 6| Step: 10
Training loss: 2.0217102219475223
Validation loss: 2.995096112470926

Epoch: 6| Step: 11
Training loss: 3.023322209173372
Validation loss: 2.872847396352312

Epoch: 6| Step: 12
Training loss: 2.9487364115610135
Validation loss: 2.968237445239215

Epoch: 6| Step: 13
Training loss: 3.6276114692623613
Validation loss: 2.972133654194632

Epoch: 298| Step: 0
Training loss: 2.785632677245265
Validation loss: 2.9164002702647966

Epoch: 6| Step: 1
Training loss: 2.601539497159238
Validation loss: 2.724031300607507

Epoch: 6| Step: 2
Training loss: 3.193143896829865
Validation loss: 2.9378182791421037

Epoch: 6| Step: 3
Training loss: 2.045096869937456
Validation loss: 2.889179747115445

Epoch: 6| Step: 4
Training loss: 2.7418219602562024
Validation loss: 2.811001301547504

Epoch: 6| Step: 5
Training loss: 2.9417800564475747
Validation loss: 2.9843595972851813

Epoch: 6| Step: 6
Training loss: 2.429412924409434
Validation loss: 2.807493543473086

Epoch: 6| Step: 7
Training loss: 2.633726238764545
Validation loss: 2.858669773897716

Epoch: 6| Step: 8
Training loss: 2.2319465725291256
Validation loss: 3.0175445770353893

Epoch: 6| Step: 9
Training loss: 2.080091191640297
Validation loss: 2.8955594052242755

Epoch: 6| Step: 10
Training loss: 3.2079416671738645
Validation loss: 2.897639369108389

Epoch: 6| Step: 11
Training loss: 3.0837502756107056
Validation loss: 3.0802802513107053

Epoch: 6| Step: 12
Training loss: 2.9815403123171365
Validation loss: 2.8864513932087728

Epoch: 6| Step: 13
Training loss: 2.923801704853077
Validation loss: 2.850016551031769

Epoch: 299| Step: 0
Training loss: 3.9630200932214996
Validation loss: 3.145297003059068

Epoch: 6| Step: 1
Training loss: 2.580204165756521
Validation loss: 2.9055574429722086

Epoch: 6| Step: 2
Training loss: 1.999538964538883
Validation loss: 2.9336168398522675

Epoch: 6| Step: 3
Training loss: 2.6546106103962535
Validation loss: 3.0077367646540534

Epoch: 6| Step: 4
Training loss: 2.2226830666907085
Validation loss: 2.8490845053765104

Epoch: 6| Step: 5
Training loss: 2.5222669786057037
Validation loss: 2.975919050693174

Epoch: 6| Step: 6
Training loss: 2.5414047940118407
Validation loss: 2.982307608376299

Epoch: 6| Step: 7
Training loss: 1.673136582731696
Validation loss: 2.7111101815698797

Epoch: 6| Step: 8
Training loss: 4.0973736981051445
Validation loss: 2.8128587500811815

Epoch: 6| Step: 9
Training loss: 2.6215957183679532
Validation loss: 2.942934246504448

Epoch: 6| Step: 10
Training loss: 2.901378527567455
Validation loss: 2.9525632509007598

Epoch: 6| Step: 11
Training loss: 2.8533192696922933
Validation loss: 2.9800349283370307

Epoch: 6| Step: 12
Training loss: 3.318671756834993
Validation loss: 3.0120870937062207

Epoch: 6| Step: 13
Training loss: 3.052230744604763
Validation loss: 2.908133169337323

Epoch: 300| Step: 0
Training loss: 2.7736446679337856
Validation loss: 2.984705898858362

Epoch: 6| Step: 1
Training loss: 2.87634163111652
Validation loss: 2.9279998945886425

Epoch: 6| Step: 2
Training loss: 3.0467501101207017
Validation loss: 3.0172024579146646

Epoch: 6| Step: 3
Training loss: 2.0087755320551857
Validation loss: 2.9135023317265003

Epoch: 6| Step: 4
Training loss: 3.4790474572383743
Validation loss: 2.838066961072391

Epoch: 6| Step: 5
Training loss: 2.4183369049669845
Validation loss: 2.9539412259040567

Epoch: 6| Step: 6
Training loss: 2.750128829712726
Validation loss: 2.839018948316478

Epoch: 6| Step: 7
Training loss: 2.6039254852509237
Validation loss: 3.0967077512550167

Epoch: 6| Step: 8
Training loss: 2.7901769810263324
Validation loss: 2.8843936020853196

Epoch: 6| Step: 9
Training loss: 2.2497085806421553
Validation loss: 2.9271071930121138

Epoch: 6| Step: 10
Training loss: 3.173165195188714
Validation loss: 2.7459115739146163

Epoch: 6| Step: 11
Training loss: 2.906745130139021
Validation loss: 2.7645503077015134

Epoch: 6| Step: 12
Training loss: 2.577904986617163
Validation loss: 2.861189229633962

Epoch: 6| Step: 13
Training loss: 2.292982787003191
Validation loss: 2.781216584212629

Epoch: 301| Step: 0
Training loss: 3.1991638998655767
Validation loss: 3.005949188860563

Epoch: 6| Step: 1
Training loss: 1.7867632754857348
Validation loss: 2.8559085924724568

Epoch: 6| Step: 2
Training loss: 2.9192584556750494
Validation loss: 2.9412020515569637

Epoch: 6| Step: 3
Training loss: 2.867125133698841
Validation loss: 2.97926972309431

Epoch: 6| Step: 4
Training loss: 2.9573624499750553
Validation loss: 2.872648980124523

Epoch: 6| Step: 5
Training loss: 2.384047491496641
Validation loss: 2.721354606916099

Epoch: 6| Step: 6
Training loss: 1.8886348243400795
Validation loss: 2.8590138480350906

Epoch: 6| Step: 7
Training loss: 3.6241130401463457
Validation loss: 2.8558568588448336

Epoch: 6| Step: 8
Training loss: 2.82145655033525
Validation loss: 2.838273632486362

Epoch: 6| Step: 9
Training loss: 1.8760964049028777
Validation loss: 2.9981801826853927

Epoch: 6| Step: 10
Training loss: 2.1069815160576963
Validation loss: 2.877080217394083

Epoch: 6| Step: 11
Training loss: 2.6832088544259327
Validation loss: 3.035524448867943

Epoch: 6| Step: 12
Training loss: 2.7123703042240246
Validation loss: 2.889369897209474

Epoch: 6| Step: 13
Training loss: 2.7671780293677926
Validation loss: 2.6901788355229996

Epoch: 302| Step: 0
Training loss: 2.7794122517831985
Validation loss: 2.895074952359775

Epoch: 6| Step: 1
Training loss: 2.1671426934833935
Validation loss: 3.01614413584736

Epoch: 6| Step: 2
Training loss: 2.333443116829716
Validation loss: 2.8735179371482165

Epoch: 6| Step: 3
Training loss: 2.5575907131600397
Validation loss: 3.0764069310636253

Epoch: 6| Step: 4
Training loss: 2.850033201057726
Validation loss: 2.8268791141715726

Epoch: 6| Step: 5
Training loss: 2.674487348257376
Validation loss: 2.899611234295955

Epoch: 6| Step: 6
Training loss: 2.9441098456933124
Validation loss: 2.943368412392655

Epoch: 6| Step: 7
Training loss: 2.3629197529886032
Validation loss: 2.822901581597266

Epoch: 6| Step: 8
Training loss: 2.0798834911140784
Validation loss: 2.9661591654230883

Epoch: 6| Step: 9
Training loss: 3.6611127550130758
Validation loss: 3.0090319936305137

Epoch: 6| Step: 10
Training loss: 2.2798629097129854
Validation loss: 2.8839650260636893

Epoch: 6| Step: 11
Training loss: 3.366491967254397
Validation loss: 2.878994594274876

Epoch: 6| Step: 12
Training loss: 1.7975135000515106
Validation loss: 2.981673464663271

Epoch: 6| Step: 13
Training loss: 3.822847426339215
Validation loss: 3.086623009747468

Epoch: 303| Step: 0
Training loss: 2.7656111205016747
Validation loss: 3.0658390575839007

Epoch: 6| Step: 1
Training loss: 2.380665296322184
Validation loss: 2.9526568183431934

Epoch: 6| Step: 2
Training loss: 3.4622453065700314
Validation loss: 2.9683575684389036

Epoch: 6| Step: 3
Training loss: 2.936987000168737
Validation loss: 2.882482994126261

Epoch: 6| Step: 4
Training loss: 2.2244691879940617
Validation loss: 2.7781311481721134

Epoch: 6| Step: 5
Training loss: 2.234099791324012
Validation loss: 3.055885026706621

Epoch: 6| Step: 6
Training loss: 2.070741429070891
Validation loss: 2.872136995991967

Epoch: 6| Step: 7
Training loss: 2.608563508266601
Validation loss: 2.953306785119406

Epoch: 6| Step: 8
Training loss: 3.2247476345946406
Validation loss: 2.9437256075735

Epoch: 6| Step: 9
Training loss: 3.0074427786161437
Validation loss: 2.8538977060103385

Epoch: 6| Step: 10
Training loss: 3.109329453331221
Validation loss: 2.865082840461586

Epoch: 6| Step: 11
Training loss: 2.873802599133103
Validation loss: 2.7239173097548104

Epoch: 6| Step: 12
Training loss: 2.532490179225486
Validation loss: 2.8540840978305755

Epoch: 6| Step: 13
Training loss: 3.4898736785500315
Validation loss: 2.8624493564858633

Epoch: 304| Step: 0
Training loss: 2.8277585124084217
Validation loss: 3.048140108722216

Epoch: 6| Step: 1
Training loss: 2.455873541095615
Validation loss: 2.859607701633666

Epoch: 6| Step: 2
Training loss: 2.8437937638824273
Validation loss: 2.82887911131647

Epoch: 6| Step: 3
Training loss: 3.1310925411753336
Validation loss: 2.841952688432729

Epoch: 6| Step: 4
Training loss: 1.970302030579404
Validation loss: 2.932504714858383

Epoch: 6| Step: 5
Training loss: 3.4179790736451237
Validation loss: 2.920505112840085

Epoch: 6| Step: 6
Training loss: 3.1121994302388627
Validation loss: 2.8856436518465673

Epoch: 6| Step: 7
Training loss: 3.6522451785244616
Validation loss: 2.9904653474283616

Epoch: 6| Step: 8
Training loss: 2.046453184970315
Validation loss: 2.842915312071186

Epoch: 6| Step: 9
Training loss: 2.167827979663991
Validation loss: 3.00551410463842

Epoch: 6| Step: 10
Training loss: 2.074832229266273
Validation loss: 2.828403806113042

Epoch: 6| Step: 11
Training loss: 2.4781998958550373
Validation loss: 2.863081895035686

Epoch: 6| Step: 12
Training loss: 2.64293438750686
Validation loss: 3.016881067480765

Epoch: 6| Step: 13
Training loss: 2.5083142310478657
Validation loss: 3.0773038175298817

Epoch: 305| Step: 0
Training loss: 2.3314231705970343
Validation loss: 2.983647550817597

Epoch: 6| Step: 1
Training loss: 3.0379498560711844
Validation loss: 2.8067559857013498

Epoch: 6| Step: 2
Training loss: 2.640530014586952
Validation loss: 2.77815353227749

Epoch: 6| Step: 3
Training loss: 2.1219197556462532
Validation loss: 2.768946238576607

Epoch: 6| Step: 4
Training loss: 3.0255411404920705
Validation loss: 2.991255903556029

Epoch: 6| Step: 5
Training loss: 2.4311735754087715
Validation loss: 2.908631813840945

Epoch: 6| Step: 6
Training loss: 2.757209776808144
Validation loss: 2.8717848253485703

Epoch: 6| Step: 7
Training loss: 2.478605468660735
Validation loss: 2.7864282763775545

Epoch: 6| Step: 8
Training loss: 3.4476830594463803
Validation loss: 2.895542852304575

Epoch: 6| Step: 9
Training loss: 2.9433920997061036
Validation loss: 2.9723016466133387

Epoch: 6| Step: 10
Training loss: 2.170436355209565
Validation loss: 2.973063054213759

Epoch: 6| Step: 11
Training loss: 3.3258571867890696
Validation loss: 3.03955730894992

Epoch: 6| Step: 12
Training loss: 2.5349689055873883
Validation loss: 3.013655075919518

Epoch: 6| Step: 13
Training loss: 2.7563552248152288
Validation loss: 2.9650615323727965

Epoch: 306| Step: 0
Training loss: 3.4041443362178696
Validation loss: 3.0611786510440377

Epoch: 6| Step: 1
Training loss: 2.0895277123038687
Validation loss: 2.932013694302498

Epoch: 6| Step: 2
Training loss: 2.128402230330806
Validation loss: 2.8706004278335695

Epoch: 6| Step: 3
Training loss: 2.9291869689614045
Validation loss: 2.8608219729267983

Epoch: 6| Step: 4
Training loss: 2.878226749970051
Validation loss: 2.9141568496853427

Epoch: 6| Step: 5
Training loss: 2.610046391714261
Validation loss: 2.774308192564044

Epoch: 6| Step: 6
Training loss: 2.265140771091304
Validation loss: 2.7919902482356544

Epoch: 6| Step: 7
Training loss: 2.798885879932277
Validation loss: 2.6744471672875596

Epoch: 6| Step: 8
Training loss: 3.974168097816466
Validation loss: 2.9549944481031374

Epoch: 6| Step: 9
Training loss: 3.0173916558486664
Validation loss: 2.853599075732581

Epoch: 6| Step: 10
Training loss: 1.785538179705638
Validation loss: 2.927973261672552

Epoch: 6| Step: 11
Training loss: 2.779006224371002
Validation loss: 2.9542154188325025

Epoch: 6| Step: 12
Training loss: 2.115318007854381
Validation loss: 2.937383614082237

Epoch: 6| Step: 13
Training loss: 2.1696351940954877
Validation loss: 2.9258568198652615

Epoch: 307| Step: 0
Training loss: 2.1459593751302637
Validation loss: 2.954374902307317

Epoch: 6| Step: 1
Training loss: 2.000292756588532
Validation loss: 2.8705874711775623

Epoch: 6| Step: 2
Training loss: 2.4017613146854804
Validation loss: 2.97053613563042

Epoch: 6| Step: 3
Training loss: 2.274301895513979
Validation loss: 2.8343334755147125

Epoch: 6| Step: 4
Training loss: 3.013546400245582
Validation loss: 2.9266016401803885

Epoch: 6| Step: 5
Training loss: 2.8269966361447842
Validation loss: 2.833617210794884

Epoch: 6| Step: 6
Training loss: 3.64999676534431
Validation loss: 3.0640508371903348

Epoch: 6| Step: 7
Training loss: 3.010166901431729
Validation loss: 2.973216765390532

Epoch: 6| Step: 8
Training loss: 3.0332067407315058
Validation loss: 3.0521944890872343

Epoch: 6| Step: 9
Training loss: 3.397209278774133
Validation loss: 2.7560702259728083

Epoch: 6| Step: 10
Training loss: 2.4276801645697303
Validation loss: 2.956294035547275

Epoch: 6| Step: 11
Training loss: 2.2996752012048085
Validation loss: 2.8788842298497856

Epoch: 6| Step: 12
Training loss: 2.935774113533076
Validation loss: 2.990658745905486

Epoch: 6| Step: 13
Training loss: 4.237357465209168
Validation loss: 2.8319954605867985

Epoch: 308| Step: 0
Training loss: 2.657389497370467
Validation loss: 2.953539355090245

Epoch: 6| Step: 1
Training loss: 3.0638566418270097
Validation loss: 2.719706755370277

Epoch: 6| Step: 2
Training loss: 3.5024604323532613
Validation loss: 2.7681131444041034

Epoch: 6| Step: 3
Training loss: 2.366923805380324
Validation loss: 2.904896393022074

Epoch: 6| Step: 4
Training loss: 2.5080435102786165
Validation loss: 2.8486285881092632

Epoch: 6| Step: 5
Training loss: 2.9895092005737234
Validation loss: 2.7883615196270592

Epoch: 6| Step: 6
Training loss: 2.684958742417903
Validation loss: 2.86964089391152

Epoch: 6| Step: 7
Training loss: 2.8424386155236525
Validation loss: 2.916597269407511

Epoch: 6| Step: 8
Training loss: 2.388935564260365
Validation loss: 2.807503049266572

Epoch: 6| Step: 9
Training loss: 2.2193473763923506
Validation loss: 3.124057921464147

Epoch: 6| Step: 10
Training loss: 2.2810450422630333
Validation loss: 2.8794452049604256

Epoch: 6| Step: 11
Training loss: 3.0175541058914623
Validation loss: 2.879370982991548

Epoch: 6| Step: 12
Training loss: 3.5055653058249137
Validation loss: 3.044546481460195

Epoch: 6| Step: 13
Training loss: 2.272670760752596
Validation loss: 2.9013828280162266

Epoch: 309| Step: 0
Training loss: 2.0360462783245494
Validation loss: 3.0131418472912426

Epoch: 6| Step: 1
Training loss: 2.482344943579517
Validation loss: 2.969778946268586

Epoch: 6| Step: 2
Training loss: 3.0991059767656557
Validation loss: 2.6769617844012794

Epoch: 6| Step: 3
Training loss: 2.7724958513674296
Validation loss: 2.8974260766163304

Epoch: 6| Step: 4
Training loss: 2.4153178386157887
Validation loss: 2.942297038916698

Epoch: 6| Step: 5
Training loss: 3.1063509090005645
Validation loss: 2.9490514029610946

Epoch: 6| Step: 6
Training loss: 2.746197585941382
Validation loss: 2.8004421141450426

Epoch: 6| Step: 7
Training loss: 2.6398382877181574
Validation loss: 2.781018334022804

Epoch: 6| Step: 8
Training loss: 3.209996292017046
Validation loss: 2.7910688626790647

Epoch: 6| Step: 9
Training loss: 2.708214087184155
Validation loss: 2.855252776873548

Epoch: 6| Step: 10
Training loss: 3.8271091904006376
Validation loss: 2.909358715101103

Epoch: 6| Step: 11
Training loss: 2.4662834110307337
Validation loss: 2.8681342246333443

Epoch: 6| Step: 12
Training loss: 2.5609566297392696
Validation loss: 2.976342003558447

Epoch: 6| Step: 13
Training loss: 2.9518013061396484
Validation loss: 2.8524736419518586

Epoch: 310| Step: 0
Training loss: 2.6254630815666933
Validation loss: 3.0768828366817726

Epoch: 6| Step: 1
Training loss: 2.5418060973231533
Validation loss: 2.7328527382460117

Epoch: 6| Step: 2
Training loss: 2.5677650141053747
Validation loss: 2.892457464018491

Epoch: 6| Step: 3
Training loss: 3.348290613666821
Validation loss: 2.8996672647699735

Epoch: 6| Step: 4
Training loss: 2.8927357158708777
Validation loss: 2.913694006571011

Epoch: 6| Step: 5
Training loss: 2.389888974248515
Validation loss: 2.8203024192641033

Epoch: 6| Step: 6
Training loss: 2.937268349461875
Validation loss: 2.984384509346721

Epoch: 6| Step: 7
Training loss: 2.3567026932843462
Validation loss: 2.914684461203901

Epoch: 6| Step: 8
Training loss: 2.3301589580881594
Validation loss: 2.8874422394756527

Epoch: 6| Step: 9
Training loss: 2.8572753534930286
Validation loss: 2.865249145334636

Epoch: 6| Step: 10
Training loss: 3.031169143070272
Validation loss: 2.942950444013058

Epoch: 6| Step: 11
Training loss: 2.0132028383107285
Validation loss: 2.8590007787917604

Epoch: 6| Step: 12
Training loss: 3.1066319620325116
Validation loss: 2.9087463430015936

Epoch: 6| Step: 13
Training loss: 2.6617046224825494
Validation loss: 2.705996314540212

Epoch: 311| Step: 0
Training loss: 2.193052166751012
Validation loss: 2.9238432429124326

Epoch: 6| Step: 1
Training loss: 2.3431128080777874
Validation loss: 3.100119434441624

Epoch: 6| Step: 2
Training loss: 2.515448712160664
Validation loss: 2.7918399768626476

Epoch: 6| Step: 3
Training loss: 3.7356797496759104
Validation loss: 2.7349870100577305

Epoch: 6| Step: 4
Training loss: 3.332915248082873
Validation loss: 2.7761026728322897

Epoch: 6| Step: 5
Training loss: 2.866838064910099
Validation loss: 2.741114521903242

Epoch: 6| Step: 6
Training loss: 2.5946337561616053
Validation loss: 2.937939790938279

Epoch: 6| Step: 7
Training loss: 3.2173955345238063
Validation loss: 2.8773803380376153

Epoch: 6| Step: 8
Training loss: 2.512150040731731
Validation loss: 2.8541106010543023

Epoch: 6| Step: 9
Training loss: 2.732711547592199
Validation loss: 2.954465569734874

Epoch: 6| Step: 10
Training loss: 2.0678260699238082
Validation loss: 2.8185123555611664

Epoch: 6| Step: 11
Training loss: 1.9802675765752478
Validation loss: 2.90163847811064

Epoch: 6| Step: 12
Training loss: 1.458706708067922
Validation loss: 2.8524254410603365

Epoch: 6| Step: 13
Training loss: 3.7104547126328753
Validation loss: 2.833048126776229

Epoch: 312| Step: 0
Training loss: 1.8989651421616511
Validation loss: 3.066847831659085

Epoch: 6| Step: 1
Training loss: 2.34316856801658
Validation loss: 2.913391044720713

Epoch: 6| Step: 2
Training loss: 2.5351253090308994
Validation loss: 2.951282456610484

Epoch: 6| Step: 3
Training loss: 2.5614409700673657
Validation loss: 2.8748162056133664

Epoch: 6| Step: 4
Training loss: 2.4874747270229953
Validation loss: 2.833988282897308

Epoch: 6| Step: 5
Training loss: 3.53513534286808
Validation loss: 2.7148416933028443

Epoch: 6| Step: 6
Training loss: 3.5679932120904376
Validation loss: 2.79160419211154

Epoch: 6| Step: 7
Training loss: 3.0811085449928295
Validation loss: 2.928601692058773

Epoch: 6| Step: 8
Training loss: 2.280634757909915
Validation loss: 2.756342361729804

Epoch: 6| Step: 9
Training loss: 2.542826611931047
Validation loss: 2.877649881050562

Epoch: 6| Step: 10
Training loss: 2.6933135207866985
Validation loss: 2.9612234355630673

Epoch: 6| Step: 11
Training loss: 3.476372394293182
Validation loss: 2.8884501134517437

Epoch: 6| Step: 12
Training loss: 2.9219533328403577
Validation loss: 2.7906773757626593

Epoch: 6| Step: 13
Training loss: 3.0701926016268075
Validation loss: 2.7932487762186193

Epoch: 313| Step: 0
Training loss: 2.4038500025791754
Validation loss: 2.9149780990413037

Epoch: 6| Step: 1
Training loss: 2.918969162875127
Validation loss: 2.865036349604387

Epoch: 6| Step: 2
Training loss: 2.48463601714523
Validation loss: 2.945120218445455

Epoch: 6| Step: 3
Training loss: 3.4947475803889994
Validation loss: 3.022294323375518

Epoch: 6| Step: 4
Training loss: 2.766614058197381
Validation loss: 2.895805667424273

Epoch: 6| Step: 5
Training loss: 2.784718868373036
Validation loss: 2.869141744583007

Epoch: 6| Step: 6
Training loss: 2.8221010575938736
Validation loss: 2.89803725984179

Epoch: 6| Step: 7
Training loss: 2.646099037185401
Validation loss: 2.958370933542187

Epoch: 6| Step: 8
Training loss: 3.1154226407649444
Validation loss: 2.982187056769384

Epoch: 6| Step: 9
Training loss: 2.4658431310825377
Validation loss: 2.8184434009546973

Epoch: 6| Step: 10
Training loss: 2.1299848991181114
Validation loss: 2.905597221357431

Epoch: 6| Step: 11
Training loss: 2.613890800606
Validation loss: 2.7456181743843775

Epoch: 6| Step: 12
Training loss: 1.8024699140093334
Validation loss: 2.791990749579691

Epoch: 6| Step: 13
Training loss: 2.298850112070936
Validation loss: 2.87418039917201

Epoch: 314| Step: 0
Training loss: 3.3558419034545484
Validation loss: 2.9109354840590904

Epoch: 6| Step: 1
Training loss: 3.0371797118061092
Validation loss: 2.8887432391067334

Epoch: 6| Step: 2
Training loss: 2.1488415147467874
Validation loss: 3.0672318495057853

Epoch: 6| Step: 3
Training loss: 2.357128766665929
Validation loss: 2.8930419254024398

Epoch: 6| Step: 4
Training loss: 2.940617631665848
Validation loss: 2.8563177596940346

Epoch: 6| Step: 5
Training loss: 3.405802006090122
Validation loss: 2.8658761915895843

Epoch: 6| Step: 6
Training loss: 2.6314544344607813
Validation loss: 2.736686619643438

Epoch: 6| Step: 7
Training loss: 3.2240843781629924
Validation loss: 2.8683482974345655

Epoch: 6| Step: 8
Training loss: 2.5163776859153333
Validation loss: 2.9132150466147886

Epoch: 6| Step: 9
Training loss: 2.7296927335762113
Validation loss: 3.0084557746587954

Epoch: 6| Step: 10
Training loss: 2.355878044741352
Validation loss: 2.8432650327803626

Epoch: 6| Step: 11
Training loss: 2.552913131234089
Validation loss: 2.803520488853814

Epoch: 6| Step: 12
Training loss: 2.0147641731631802
Validation loss: 2.907774568684496

Epoch: 6| Step: 13
Training loss: 2.498915246229234
Validation loss: 2.921080094179694

Epoch: 315| Step: 0
Training loss: 2.568672004499449
Validation loss: 2.850509875861955

Epoch: 6| Step: 1
Training loss: 2.9595863661566346
Validation loss: 2.973650585136065

Epoch: 6| Step: 2
Training loss: 2.533742548701542
Validation loss: 2.8871868604949085

Epoch: 6| Step: 3
Training loss: 2.46821173099419
Validation loss: 2.7878187506369105

Epoch: 6| Step: 4
Training loss: 2.7628145755121007
Validation loss: 2.9016561713247433

Epoch: 6| Step: 5
Training loss: 3.0842176835929718
Validation loss: 2.9144613047038206

Epoch: 6| Step: 6
Training loss: 2.8927953871605814
Validation loss: 2.9320320453495556

Epoch: 6| Step: 7
Training loss: 2.6190806359938854
Validation loss: 2.6987008840320432

Epoch: 6| Step: 8
Training loss: 3.47533197806887
Validation loss: 2.9080665416529725

Epoch: 6| Step: 9
Training loss: 2.165477634276559
Validation loss: 3.000283482533218

Epoch: 6| Step: 10
Training loss: 2.2425317799029094
Validation loss: 2.846173011099219

Epoch: 6| Step: 11
Training loss: 3.236649749926416
Validation loss: 2.9591472089115514

Epoch: 6| Step: 12
Training loss: 1.6696140295560618
Validation loss: 2.72508328011283

Epoch: 6| Step: 13
Training loss: 3.2907355395930145
Validation loss: 2.9340419972739333

Epoch: 316| Step: 0
Training loss: 2.148515512610618
Validation loss: 2.8890722483866558

Epoch: 6| Step: 1
Training loss: 2.363446089615345
Validation loss: 2.9730233696680206

Epoch: 6| Step: 2
Training loss: 2.156875961776603
Validation loss: 2.869259671844431

Epoch: 6| Step: 3
Training loss: 2.835616668964715
Validation loss: 2.84424571508515

Epoch: 6| Step: 4
Training loss: 2.989988151195103
Validation loss: 2.913220155033015

Epoch: 6| Step: 5
Training loss: 3.3786632296096353
Validation loss: 2.826935530624518

Epoch: 6| Step: 6
Training loss: 2.0910684294921693
Validation loss: 2.870793697261505

Epoch: 6| Step: 7
Training loss: 2.362026013656639
Validation loss: 2.9213016358289505

Epoch: 6| Step: 8
Training loss: 2.662278369400995
Validation loss: 2.756079108244657

Epoch: 6| Step: 9
Training loss: 2.0819139859097358
Validation loss: 2.763309720939684

Epoch: 6| Step: 10
Training loss: 3.463615672915095
Validation loss: 2.816997137547253

Epoch: 6| Step: 11
Training loss: 2.199002460258048
Validation loss: 2.8746919114660345

Epoch: 6| Step: 12
Training loss: 3.1968936505710546
Validation loss: 2.9919360284959864

Epoch: 6| Step: 13
Training loss: 1.9183521392567737
Validation loss: 2.7754965330826593

Epoch: 317| Step: 0
Training loss: 3.4423045480908048
Validation loss: 2.893854482458363

Epoch: 6| Step: 1
Training loss: 2.6115165648164185
Validation loss: 2.9134232419407504

Epoch: 6| Step: 2
Training loss: 2.29081435103986
Validation loss: 2.7306127868036274

Epoch: 6| Step: 3
Training loss: 3.4067312478092258
Validation loss: 2.922400477692111

Epoch: 6| Step: 4
Training loss: 1.7672984876781739
Validation loss: 2.944788037696989

Epoch: 6| Step: 5
Training loss: 2.510792705394145
Validation loss: 2.9375966862790155

Epoch: 6| Step: 6
Training loss: 3.1737804984407343
Validation loss: 2.931569007408173

Epoch: 6| Step: 7
Training loss: 1.8948554636606647
Validation loss: 2.9555920276572953

Epoch: 6| Step: 8
Training loss: 3.530723870166468
Validation loss: 2.7979405396201176

Epoch: 6| Step: 9
Training loss: 2.566422228712624
Validation loss: 2.980215790737226

Epoch: 6| Step: 10
Training loss: 2.155692429255236
Validation loss: 2.7646672271851425

Epoch: 6| Step: 11
Training loss: 2.904465486394651
Validation loss: 2.860507010526099

Epoch: 6| Step: 12
Training loss: 2.209835788960882
Validation loss: 2.9166961753395513

Epoch: 6| Step: 13
Training loss: 3.349951154438163
Validation loss: 2.8304560677943478

Epoch: 318| Step: 0
Training loss: 2.29560058946351
Validation loss: 2.876694958529084

Epoch: 6| Step: 1
Training loss: 2.935850288918921
Validation loss: 2.7839867461588823

Epoch: 6| Step: 2
Training loss: 2.8549333271318553
Validation loss: 2.8783157884503745

Epoch: 6| Step: 3
Training loss: 3.680514038299624
Validation loss: 2.8854452395124857

Epoch: 6| Step: 4
Training loss: 1.7596520864628515
Validation loss: 2.778150484314314

Epoch: 6| Step: 5
Training loss: 1.9980928745735902
Validation loss: 2.940531171029917

Epoch: 6| Step: 6
Training loss: 2.3889363626696407
Validation loss: 2.787816280626335

Epoch: 6| Step: 7
Training loss: 3.0355848012284583
Validation loss: 2.9046444320978706

Epoch: 6| Step: 8
Training loss: 2.23169093543549
Validation loss: 2.833952150020078

Epoch: 6| Step: 9
Training loss: 2.210043359046321
Validation loss: 2.984344099997586

Epoch: 6| Step: 10
Training loss: 2.5699730738850914
Validation loss: 2.8289906544534893

Epoch: 6| Step: 11
Training loss: 2.6713957775076027
Validation loss: 2.9681388515210294

Epoch: 6| Step: 12
Training loss: 2.923839377953045
Validation loss: 2.914890295665476

Epoch: 6| Step: 13
Training loss: 3.821826595770301
Validation loss: 2.952532676998097

Epoch: 319| Step: 0
Training loss: 2.4922904349089166
Validation loss: 2.830395026090857

Epoch: 6| Step: 1
Training loss: 2.4611517918852943
Validation loss: 2.930174552438387

Epoch: 6| Step: 2
Training loss: 2.7918444524681787
Validation loss: 2.788124989244226

Epoch: 6| Step: 3
Training loss: 3.33626710214873
Validation loss: 2.9430384799291613

Epoch: 6| Step: 4
Training loss: 2.3401292426127553
Validation loss: 2.9169711808070877

Epoch: 6| Step: 5
Training loss: 2.802909266102616
Validation loss: 2.873526464410399

Epoch: 6| Step: 6
Training loss: 2.801524384255799
Validation loss: 2.9491399434896435

Epoch: 6| Step: 7
Training loss: 1.847788509611211
Validation loss: 2.910879501386661

Epoch: 6| Step: 8
Training loss: 2.760860153176975
Validation loss: 2.8624349442801527

Epoch: 6| Step: 9
Training loss: 3.9454655079395664
Validation loss: 2.8965631112684234

Epoch: 6| Step: 10
Training loss: 3.424929157276226
Validation loss: 2.843431554338781

Epoch: 6| Step: 11
Training loss: 2.5649195157635982
Validation loss: 2.7944471415656995

Epoch: 6| Step: 12
Training loss: 2.185466366018821
Validation loss: 2.717488946085128

Epoch: 6| Step: 13
Training loss: 2.1310888458806367
Validation loss: 2.7590924409000506

Epoch: 320| Step: 0
Training loss: 3.1989592469062025
Validation loss: 2.8243315646143685

Epoch: 6| Step: 1
Training loss: 3.208366459927314
Validation loss: 2.9586645455393037

Epoch: 6| Step: 2
Training loss: 2.6428646544125125
Validation loss: 3.0649123912518865

Epoch: 6| Step: 3
Training loss: 3.0905655935226823
Validation loss: 2.934991747066151

Epoch: 6| Step: 4
Training loss: 2.1094995532526997
Validation loss: 2.96672902771613

Epoch: 6| Step: 5
Training loss: 2.178940730541874
Validation loss: 2.81278643636413

Epoch: 6| Step: 6
Training loss: 2.228448651149069
Validation loss: 2.8721004379524655

Epoch: 6| Step: 7
Training loss: 2.9930941251515297
Validation loss: 2.8233947545828975

Epoch: 6| Step: 8
Training loss: 2.5705067291616897
Validation loss: 2.8390420506332834

Epoch: 6| Step: 9
Training loss: 2.730421510650686
Validation loss: 2.945647169887923

Epoch: 6| Step: 10
Training loss: 1.903886925024385
Validation loss: 2.8045559935494877

Epoch: 6| Step: 11
Training loss: 2.701112295557004
Validation loss: 2.9882267180712465

Epoch: 6| Step: 12
Training loss: 3.2485932460070974
Validation loss: 2.854800279200016

Epoch: 6| Step: 13
Training loss: 2.1716065824115547
Validation loss: 2.8828127045354406

Epoch: 321| Step: 0
Training loss: 1.8503685171792905
Validation loss: 2.7791215929265074

Epoch: 6| Step: 1
Training loss: 2.733143120249172
Validation loss: 2.8006250151938703

Epoch: 6| Step: 2
Training loss: 1.906520699213342
Validation loss: 3.188772026143484

Epoch: 6| Step: 3
Training loss: 3.578824570412209
Validation loss: 2.816679406693984

Epoch: 6| Step: 4
Training loss: 2.50702538422742
Validation loss: 2.938958681424413

Epoch: 6| Step: 5
Training loss: 2.660474402493977
Validation loss: 2.981521966764453

Epoch: 6| Step: 6
Training loss: 3.15330972725848
Validation loss: 2.7249275851179156

Epoch: 6| Step: 7
Training loss: 3.078567705414531
Validation loss: 2.891548704024033

Epoch: 6| Step: 8
Training loss: 3.356573311632312
Validation loss: 2.8158113189954395

Epoch: 6| Step: 9
Training loss: 2.268465458284721
Validation loss: 2.741523382958088

Epoch: 6| Step: 10
Training loss: 2.6173173103593474
Validation loss: 2.8688974390727813

Epoch: 6| Step: 11
Training loss: 3.004340846020535
Validation loss: 3.101345968980827

Epoch: 6| Step: 12
Training loss: 2.1460331450335337
Validation loss: 2.9578167402049425

Epoch: 6| Step: 13
Training loss: 2.3300600139109107
Validation loss: 2.808156132529214

Epoch: 322| Step: 0
Training loss: 2.787388403330786
Validation loss: 2.851205062771402

Epoch: 6| Step: 1
Training loss: 3.258697755407241
Validation loss: 2.8425109572789276

Epoch: 6| Step: 2
Training loss: 3.070227701894355
Validation loss: 2.8878013879358844

Epoch: 6| Step: 3
Training loss: 2.7867566575877447
Validation loss: 2.9672322778883213

Epoch: 6| Step: 4
Training loss: 2.561226877431162
Validation loss: 2.8925397930389036

Epoch: 6| Step: 5
Training loss: 2.1283831872480703
Validation loss: 3.012681624153629

Epoch: 6| Step: 6
Training loss: 2.691878810195228
Validation loss: 2.9047240706972643

Epoch: 6| Step: 7
Training loss: 3.029783700455432
Validation loss: 2.9978500835529402

Epoch: 6| Step: 8
Training loss: 2.1438421869058315
Validation loss: 2.855969575387391

Epoch: 6| Step: 9
Training loss: 2.529438548004981
Validation loss: 2.826817489177985

Epoch: 6| Step: 10
Training loss: 2.4477759679305757
Validation loss: 2.813696558650789

Epoch: 6| Step: 11
Training loss: 2.212522982892856
Validation loss: 2.8475774047420783

Epoch: 6| Step: 12
Training loss: 2.22765700894723
Validation loss: 2.6462474027766016

Epoch: 6| Step: 13
Training loss: 3.4515298464514
Validation loss: 2.8877637977669783

Epoch: 323| Step: 0
Training loss: 2.82587710242506
Validation loss: 2.8571821160446587

Epoch: 6| Step: 1
Training loss: 2.056019398475301
Validation loss: 2.8519727455913944

Epoch: 6| Step: 2
Training loss: 3.3185892816913394
Validation loss: 2.882343791149974

Epoch: 6| Step: 3
Training loss: 2.2922878001604965
Validation loss: 2.8953270855129

Epoch: 6| Step: 4
Training loss: 2.7763709659664757
Validation loss: 2.812875042227839

Epoch: 6| Step: 5
Training loss: 2.139844543300898
Validation loss: 2.8807623578353745

Epoch: 6| Step: 6
Training loss: 3.0093758619709305
Validation loss: 2.867252609865131

Epoch: 6| Step: 7
Training loss: 2.2321531546218947
Validation loss: 2.904136420192904

Epoch: 6| Step: 8
Training loss: 3.067371775240808
Validation loss: 2.7255226712513148

Epoch: 6| Step: 9
Training loss: 1.8581387553393955
Validation loss: 2.8729094760245615

Epoch: 6| Step: 10
Training loss: 2.595223800916457
Validation loss: 2.9009183595040415

Epoch: 6| Step: 11
Training loss: 3.3485643185707916
Validation loss: 2.8394825064333196

Epoch: 6| Step: 12
Training loss: 2.4728355885052933
Validation loss: 2.922452283397938

Epoch: 6| Step: 13
Training loss: 3.2345802131456622
Validation loss: 2.803083119221459

Epoch: 324| Step: 0
Training loss: 3.166519529705578
Validation loss: 2.988393540738731

Epoch: 6| Step: 1
Training loss: 2.6735937825311566
Validation loss: 2.802039442547004

Epoch: 6| Step: 2
Training loss: 2.092198836372095
Validation loss: 2.8514870299161377

Epoch: 6| Step: 3
Training loss: 2.8514885879761818
Validation loss: 2.828580803389429

Epoch: 6| Step: 4
Training loss: 3.164253436320349
Validation loss: 2.7893834836913265

Epoch: 6| Step: 5
Training loss: 2.4055974496605272
Validation loss: 2.8452406812868087

Epoch: 6| Step: 6
Training loss: 2.786201954868489
Validation loss: 2.8556559765186185

Epoch: 6| Step: 7
Training loss: 1.815682740860915
Validation loss: 2.8747238072883077

Epoch: 6| Step: 8
Training loss: 3.1216716589398104
Validation loss: 2.836349970319626

Epoch: 6| Step: 9
Training loss: 2.3667692815894394
Validation loss: 2.9135907990123293

Epoch: 6| Step: 10
Training loss: 2.285867277202326
Validation loss: 2.9597176235332103

Epoch: 6| Step: 11
Training loss: 2.5921084253392257
Validation loss: 2.7078723871759136

Epoch: 6| Step: 12
Training loss: 2.164521426899564
Validation loss: 2.9915216699455387

Epoch: 6| Step: 13
Training loss: 2.1964592704444104
Validation loss: 3.0360787009638255

Epoch: 325| Step: 0
Training loss: 1.8950172666100227
Validation loss: 2.870055971037548

Epoch: 6| Step: 1
Training loss: 3.8446614495137217
Validation loss: 2.8060618774581507

Epoch: 6| Step: 2
Training loss: 3.082021967072522
Validation loss: 3.042557622264275

Epoch: 6| Step: 3
Training loss: 2.6379004874963714
Validation loss: 2.917710674380561

Epoch: 6| Step: 4
Training loss: 2.4853820678997223
Validation loss: 3.0192811490893408

Epoch: 6| Step: 5
Training loss: 1.4756139705880742
Validation loss: 3.0217584898385415

Epoch: 6| Step: 6
Training loss: 3.0864611217646254
Validation loss: 2.8126676065142635

Epoch: 6| Step: 7
Training loss: 3.119848965143604
Validation loss: 2.901155001486486

Epoch: 6| Step: 8
Training loss: 2.7137564039044966
Validation loss: 2.878121037803546

Epoch: 6| Step: 9
Training loss: 2.614123016404825
Validation loss: 2.805927699949152

Epoch: 6| Step: 10
Training loss: 2.5699961737222057
Validation loss: 2.912883947447845

Epoch: 6| Step: 11
Training loss: 2.237779917336613
Validation loss: 2.898454301734163

Epoch: 6| Step: 12
Training loss: 2.378776559285539
Validation loss: 2.886273321601647

Epoch: 6| Step: 13
Training loss: 2.398544855852629
Validation loss: 2.8112249923051404

Epoch: 326| Step: 0
Training loss: 2.8052348928307373
Validation loss: 2.6520779896520486

Epoch: 6| Step: 1
Training loss: 2.4982110298390277
Validation loss: 2.940385466469538

Epoch: 6| Step: 2
Training loss: 2.7696076935412797
Validation loss: 2.9134006256087277

Epoch: 6| Step: 3
Training loss: 2.9526370013668832
Validation loss: 2.9121829210318153

Epoch: 6| Step: 4
Training loss: 2.94447958423431
Validation loss: 2.918555135867348

Epoch: 6| Step: 5
Training loss: 2.578645595816859
Validation loss: 2.9387211038681995

Epoch: 6| Step: 6
Training loss: 2.7721121186650635
Validation loss: 2.8527679093741423

Epoch: 6| Step: 7
Training loss: 2.82714531722086
Validation loss: 2.8685832158759372

Epoch: 6| Step: 8
Training loss: 2.7490674084793785
Validation loss: 2.729629572844274

Epoch: 6| Step: 9
Training loss: 2.8281961505854794
Validation loss: 2.9609371848412906

Epoch: 6| Step: 10
Training loss: 3.173203814799224
Validation loss: 2.9016253463999626

Epoch: 6| Step: 11
Training loss: 1.56850302526482
Validation loss: 2.6349948433766834

Epoch: 6| Step: 12
Training loss: 2.2045574536484116
Validation loss: 2.78564153243683

Epoch: 6| Step: 13
Training loss: 2.928794134623977
Validation loss: 2.8779400999646647

Epoch: 327| Step: 0
Training loss: 2.327697714695999
Validation loss: 2.9274685572287775

Epoch: 6| Step: 1
Training loss: 2.879029808343273
Validation loss: 2.8349624042659016

Epoch: 6| Step: 2
Training loss: 2.3861289036888875
Validation loss: 2.8646255075402265

Epoch: 6| Step: 3
Training loss: 2.3535154223936634
Validation loss: 2.9077822478494117

Epoch: 6| Step: 4
Training loss: 2.780129281886928
Validation loss: 2.8415835554034916

Epoch: 6| Step: 5
Training loss: 1.6287787591088814
Validation loss: 2.924011514503016

Epoch: 6| Step: 6
Training loss: 2.661401935932903
Validation loss: 2.730431488509104

Epoch: 6| Step: 7
Training loss: 2.291950994250616
Validation loss: 2.977032331820339

Epoch: 6| Step: 8
Training loss: 2.4125057991234846
Validation loss: 2.8880089804032196

Epoch: 6| Step: 9
Training loss: 3.328251652703068
Validation loss: 2.943028764687109

Epoch: 6| Step: 10
Training loss: 3.211702353162581
Validation loss: 2.85041832562242

Epoch: 6| Step: 11
Training loss: 3.874416184284152
Validation loss: 2.911576186433548

Epoch: 6| Step: 12
Training loss: 2.259958270540082
Validation loss: 2.732323924829497

Epoch: 6| Step: 13
Training loss: 2.9723525825822055
Validation loss: 2.827016901734429

Epoch: 328| Step: 0
Training loss: 1.9802512626937696
Validation loss: 2.886359746607986

Epoch: 6| Step: 1
Training loss: 2.595165923295386
Validation loss: 2.9182012903813654

Epoch: 6| Step: 2
Training loss: 3.152121686145314
Validation loss: 2.94852684144703

Epoch: 6| Step: 3
Training loss: 2.593140128260037
Validation loss: 2.794749011238067

Epoch: 6| Step: 4
Training loss: 2.7027502957870437
Validation loss: 2.9382621205876207

Epoch: 6| Step: 5
Training loss: 3.1091403585108375
Validation loss: 2.901508432415201

Epoch: 6| Step: 6
Training loss: 3.616385649092733
Validation loss: 2.7531087294973045

Epoch: 6| Step: 7
Training loss: 1.896190679498657
Validation loss: 2.9697734612180366

Epoch: 6| Step: 8
Training loss: 3.220076500594005
Validation loss: 2.8209730250928846

Epoch: 6| Step: 9
Training loss: 1.8835787025334767
Validation loss: 2.8640024133484636

Epoch: 6| Step: 10
Training loss: 2.00470085823443
Validation loss: 2.8008475374538344

Epoch: 6| Step: 11
Training loss: 3.0326591441134627
Validation loss: 2.811588616410948

Epoch: 6| Step: 12
Training loss: 2.7421064663730337
Validation loss: 2.765137498929611

Epoch: 6| Step: 13
Training loss: 1.3896667951066972
Validation loss: 2.79753055704975

Epoch: 329| Step: 0
Training loss: 2.2974605722126293
Validation loss: 2.8440174029799015

Epoch: 6| Step: 1
Training loss: 2.3996634565267363
Validation loss: 2.7221844848914616

Epoch: 6| Step: 2
Training loss: 2.328336770071753
Validation loss: 2.9281725806435297

Epoch: 6| Step: 3
Training loss: 3.001561076587377
Validation loss: 2.796842141209617

Epoch: 6| Step: 4
Training loss: 2.6959882248527944
Validation loss: 2.792336962151335

Epoch: 6| Step: 5
Training loss: 2.968482557597936
Validation loss: 3.0379969623253475

Epoch: 6| Step: 6
Training loss: 2.644553878890213
Validation loss: 2.9220688918803615

Epoch: 6| Step: 7
Training loss: 2.5808178334380925
Validation loss: 2.8291295602268502

Epoch: 6| Step: 8
Training loss: 2.4008120235974633
Validation loss: 2.7748271284104833

Epoch: 6| Step: 9
Training loss: 2.6557956082509766
Validation loss: 2.902942115329266

Epoch: 6| Step: 10
Training loss: 3.079159790224098
Validation loss: 2.8549796188365772

Epoch: 6| Step: 11
Training loss: 2.4435313017174844
Validation loss: 2.862748493679414

Epoch: 6| Step: 12
Training loss: 2.602715039342434
Validation loss: 2.7216367434816995

Epoch: 6| Step: 13
Training loss: 3.403635964334312
Validation loss: 2.987550560967074

Epoch: 330| Step: 0
Training loss: 2.604061541660709
Validation loss: 2.842964652599612

Epoch: 6| Step: 1
Training loss: 2.6622904592092835
Validation loss: 2.801594792052446

Epoch: 6| Step: 2
Training loss: 1.7724315462223954
Validation loss: 2.8860840929357128

Epoch: 6| Step: 3
Training loss: 2.477796758437432
Validation loss: 2.6899254726862414

Epoch: 6| Step: 4
Training loss: 3.0514151370108435
Validation loss: 3.00501812547465

Epoch: 6| Step: 5
Training loss: 2.690181547654057
Validation loss: 2.8370393159441174

Epoch: 6| Step: 6
Training loss: 1.7582843740556355
Validation loss: 2.6840843985325344

Epoch: 6| Step: 7
Training loss: 2.921434828298186
Validation loss: 2.932209676813982

Epoch: 6| Step: 8
Training loss: 3.3313966529156533
Validation loss: 2.7758197449071504

Epoch: 6| Step: 9
Training loss: 2.3922878291682776
Validation loss: 2.765639959338553

Epoch: 6| Step: 10
Training loss: 2.5302854984515712
Validation loss: 2.867885760630849

Epoch: 6| Step: 11
Training loss: 2.5497509217629486
Validation loss: 2.9727678227210714

Epoch: 6| Step: 12
Training loss: 2.2347031999179743
Validation loss: 2.803138169927742

Epoch: 6| Step: 13
Training loss: 2.096362633224039
Validation loss: 2.890362886375415

Epoch: 331| Step: 0
Training loss: 1.7891389922068823
Validation loss: 2.7486804199470196

Epoch: 6| Step: 1
Training loss: 2.7718129732746175
Validation loss: 2.8358125784842083

Epoch: 6| Step: 2
Training loss: 2.2906863340984915
Validation loss: 2.8318094888495176

Epoch: 6| Step: 3
Training loss: 2.6897155146149836
Validation loss: 3.1350947874307016

Epoch: 6| Step: 4
Training loss: 2.554784557120381
Validation loss: 2.9382622209253904

Epoch: 6| Step: 5
Training loss: 3.062732298468163
Validation loss: 2.955477847029352

Epoch: 6| Step: 6
Training loss: 2.3102028236686962
Validation loss: 2.8053416216224782

Epoch: 6| Step: 7
Training loss: 2.2733418552690154
Validation loss: 2.903329158410887

Epoch: 6| Step: 8
Training loss: 2.3970447186757484
Validation loss: 2.7871460737609435

Epoch: 6| Step: 9
Training loss: 2.2885504140037036
Validation loss: 3.0372734857720673

Epoch: 6| Step: 10
Training loss: 3.655242781188236
Validation loss: 2.8754676734512494

Epoch: 6| Step: 11
Training loss: 2.3935140468550995
Validation loss: 2.9242474151091202

Epoch: 6| Step: 12
Training loss: 2.8526498889909635
Validation loss: 2.9389010291001907

Epoch: 6| Step: 13
Training loss: 3.0808609165493954
Validation loss: 2.8385388030645204

Epoch: 332| Step: 0
Training loss: 1.8128265875874114
Validation loss: 2.801956428837687

Epoch: 6| Step: 1
Training loss: 2.957655887316562
Validation loss: 2.8327329664285723

Epoch: 6| Step: 2
Training loss: 2.906550238082773
Validation loss: 2.8412583939045684

Epoch: 6| Step: 3
Training loss: 2.256586183984452
Validation loss: 2.8166946232323276

Epoch: 6| Step: 4
Training loss: 2.12003082001074
Validation loss: 2.815359594732657

Epoch: 6| Step: 5
Training loss: 2.1838229200725343
Validation loss: 2.836203260497119

Epoch: 6| Step: 6
Training loss: 2.106919731722215
Validation loss: 2.939928440830091

Epoch: 6| Step: 7
Training loss: 2.9833158041440835
Validation loss: 2.9171165230722496

Epoch: 6| Step: 8
Training loss: 2.98008123555923
Validation loss: 2.8381294962022205

Epoch: 6| Step: 9
Training loss: 2.9239905547316933
Validation loss: 2.9340160946242153

Epoch: 6| Step: 10
Training loss: 2.933729470843087
Validation loss: 3.0792759501452807

Epoch: 6| Step: 11
Training loss: 2.436492907499108
Validation loss: 2.863305863082689

Epoch: 6| Step: 12
Training loss: 2.0623282158722724
Validation loss: 2.986077638441514

Epoch: 6| Step: 13
Training loss: 3.9526978514516644
Validation loss: 2.8019053908190736

Epoch: 333| Step: 0
Training loss: 2.6603247411305793
Validation loss: 2.9676579900575444

Epoch: 6| Step: 1
Training loss: 3.124263218808619
Validation loss: 2.854978554760778

Epoch: 6| Step: 2
Training loss: 2.827658767627405
Validation loss: 2.72884918698386

Epoch: 6| Step: 3
Training loss: 1.794614614062471
Validation loss: 2.8788707922036747

Epoch: 6| Step: 4
Training loss: 2.367387316236641
Validation loss: 2.9170747802508115

Epoch: 6| Step: 5
Training loss: 1.2975150677462064
Validation loss: 2.9061022035170634

Epoch: 6| Step: 6
Training loss: 1.9785214091721965
Validation loss: 2.8983314308345607

Epoch: 6| Step: 7
Training loss: 2.4218228242237605
Validation loss: 2.865540907363296

Epoch: 6| Step: 8
Training loss: 3.018627510192022
Validation loss: 2.9661340817074247

Epoch: 6| Step: 9
Training loss: 3.1550629149147427
Validation loss: 2.9015066547031387

Epoch: 6| Step: 10
Training loss: 1.9192911161664823
Validation loss: 2.938387513078738

Epoch: 6| Step: 11
Training loss: 3.6671122077978575
Validation loss: 2.8791829345774462

Epoch: 6| Step: 12
Training loss: 3.607533567276385
Validation loss: 2.7103899837001255

Epoch: 6| Step: 13
Training loss: 3.236318105936513
Validation loss: 2.799945153814045

Epoch: 334| Step: 0
Training loss: 3.942276252778673
Validation loss: 2.8943752165777696

Epoch: 6| Step: 1
Training loss: 2.7946495707234087
Validation loss: 2.813399484379178

Epoch: 6| Step: 2
Training loss: 2.2854264580497463
Validation loss: 2.811299655589048

Epoch: 6| Step: 3
Training loss: 2.2915216457835355
Validation loss: 2.7875615984673883

Epoch: 6| Step: 4
Training loss: 2.5475765268438417
Validation loss: 2.955479697235663

Epoch: 6| Step: 5
Training loss: 2.814248791702091
Validation loss: 2.9490038478293226

Epoch: 6| Step: 6
Training loss: 2.4361558778371726
Validation loss: 2.8916666333083083

Epoch: 6| Step: 7
Training loss: 3.1685984558344416
Validation loss: 2.7385148724971677

Epoch: 6| Step: 8
Training loss: 2.264102819069263
Validation loss: 2.800632247614632

Epoch: 6| Step: 9
Training loss: 2.8679487584642716
Validation loss: 2.7257501903760795

Epoch: 6| Step: 10
Training loss: 2.7032652360999547
Validation loss: 2.929816329912716

Epoch: 6| Step: 11
Training loss: 2.2504618488596084
Validation loss: 2.9843611276385027

Epoch: 6| Step: 12
Training loss: 2.092950355075881
Validation loss: 2.7768053186790933

Epoch: 6| Step: 13
Training loss: 1.7080538063552515
Validation loss: 2.9079795204952767

Epoch: 335| Step: 0
Training loss: 3.0096696148906275
Validation loss: 2.977085254410548

Epoch: 6| Step: 1
Training loss: 2.6167306985330034
Validation loss: 2.8515228264229346

Epoch: 6| Step: 2
Training loss: 2.4786501007032657
Validation loss: 2.963898921156798

Epoch: 6| Step: 3
Training loss: 2.7146816287587057
Validation loss: 2.882021079288435

Epoch: 6| Step: 4
Training loss: 1.9772548744487883
Validation loss: 2.8113447781527885

Epoch: 6| Step: 5
Training loss: 3.434246118433788
Validation loss: 2.9522499028853435

Epoch: 6| Step: 6
Training loss: 2.904947132410855
Validation loss: 2.925729827010562

Epoch: 6| Step: 7
Training loss: 3.33105597584078
Validation loss: 2.889936494299487

Epoch: 6| Step: 8
Training loss: 3.1130124386478557
Validation loss: 2.9579466469263127

Epoch: 6| Step: 9
Training loss: 2.424968097909518
Validation loss: 2.87355992595281

Epoch: 6| Step: 10
Training loss: 1.9312704288920646
Validation loss: 2.873329693040792

Epoch: 6| Step: 11
Training loss: 2.3520655299938507
Validation loss: 2.7580143851350396

Epoch: 6| Step: 12
Training loss: 2.1261523992798304
Validation loss: 2.854219650077376

Epoch: 6| Step: 13
Training loss: 1.881059899341238
Validation loss: 2.727271322638124

Epoch: 336| Step: 0
Training loss: 2.057350318813028
Validation loss: 2.822402700859444

Epoch: 6| Step: 1
Training loss: 3.0001848481768554
Validation loss: 2.634913016569044

Epoch: 6| Step: 2
Training loss: 2.742617146885815
Validation loss: 2.716289507772432

Epoch: 6| Step: 3
Training loss: 3.200542916495129
Validation loss: 2.79911475467142

Epoch: 6| Step: 4
Training loss: 2.2542598453614295
Validation loss: 2.7994894609693666

Epoch: 6| Step: 5
Training loss: 2.487287721250292
Validation loss: 2.8120026926976984

Epoch: 6| Step: 6
Training loss: 3.125
Validation loss: 2.8481089456669095

Epoch: 6| Step: 7
Training loss: 2.3314225570183065
Validation loss: 2.8432662265697033

Epoch: 6| Step: 8
Training loss: 2.4002810671257633
Validation loss: 2.771174489799617

Epoch: 6| Step: 9
Training loss: 2.717355041427803
Validation loss: 2.8225254083903786

Epoch: 6| Step: 10
Training loss: 2.156635526386101
Validation loss: 2.875435687808069

Epoch: 6| Step: 11
Training loss: 2.8495231965742867
Validation loss: 2.754370944193599

Epoch: 6| Step: 12
Training loss: 2.65930986873781
Validation loss: 2.776481085875789

Epoch: 6| Step: 13
Training loss: 3.4550226443220775
Validation loss: 2.886507849654689

Epoch: 337| Step: 0
Training loss: 2.0338327274014736
Validation loss: 2.8790692836335854

Epoch: 6| Step: 1
Training loss: 2.8568547716678507
Validation loss: 2.933450968496055

Epoch: 6| Step: 2
Training loss: 2.92515469655526
Validation loss: 2.8903494524251365

Epoch: 6| Step: 3
Training loss: 3.254485482893082
Validation loss: 2.817765167526272

Epoch: 6| Step: 4
Training loss: 2.584410801631458
Validation loss: 2.95168754429017

Epoch: 6| Step: 5
Training loss: 1.7236456073577868
Validation loss: 2.866487835075384

Epoch: 6| Step: 6
Training loss: 3.8042705080219474
Validation loss: 2.9401826855211297

Epoch: 6| Step: 7
Training loss: 2.972982341109566
Validation loss: 2.835866485785028

Epoch: 6| Step: 8
Training loss: 3.212075433246733
Validation loss: 2.8013425147288427

Epoch: 6| Step: 9
Training loss: 1.974041382611895
Validation loss: 2.8824803846659295

Epoch: 6| Step: 10
Training loss: 3.107340698332762
Validation loss: 2.8315406188184946

Epoch: 6| Step: 11
Training loss: 2.228331816546034
Validation loss: 3.1299692559182892

Epoch: 6| Step: 12
Training loss: 1.7195829280590593
Validation loss: 2.9897246357220286

Epoch: 6| Step: 13
Training loss: 2.802877963438595
Validation loss: 2.900748339977486

Epoch: 338| Step: 0
Training loss: 3.2961134189146346
Validation loss: 2.940023518231001

Epoch: 6| Step: 1
Training loss: 2.371410970819523
Validation loss: 2.8690714181959827

Epoch: 6| Step: 2
Training loss: 3.0876453936856865
Validation loss: 2.814076709760974

Epoch: 6| Step: 3
Training loss: 2.1063452543458707
Validation loss: 3.0618177679075065

Epoch: 6| Step: 4
Training loss: 2.4537362473073787
Validation loss: 2.7262162548361704

Epoch: 6| Step: 5
Training loss: 2.2756634593669274
Validation loss: 2.773647447722212

Epoch: 6| Step: 6
Training loss: 3.3021617282422393
Validation loss: 2.903471566979229

Epoch: 6| Step: 7
Training loss: 2.68153740113945
Validation loss: 3.0298224621750425

Epoch: 6| Step: 8
Training loss: 2.602542726897045
Validation loss: 2.802480389920496

Epoch: 6| Step: 9
Training loss: 2.676870928896405
Validation loss: 2.952325965770408

Epoch: 6| Step: 10
Training loss: 3.0529457063067365
Validation loss: 2.98981247250639

Epoch: 6| Step: 11
Training loss: 2.0655455788999633
Validation loss: 2.813708064364742

Epoch: 6| Step: 12
Training loss: 2.6668747184973194
Validation loss: 2.893688512156968

Epoch: 6| Step: 13
Training loss: 2.1039457173688016
Validation loss: 2.816328223901304

Epoch: 339| Step: 0
Training loss: 2.6988069300192667
Validation loss: 2.8316929778045705

Epoch: 6| Step: 1
Training loss: 2.4685515311898785
Validation loss: 2.968338709580611

Epoch: 6| Step: 2
Training loss: 2.394816096976171
Validation loss: 3.0389229824460315

Epoch: 6| Step: 3
Training loss: 1.8660940376210609
Validation loss: 2.7217744528140995

Epoch: 6| Step: 4
Training loss: 3.3384271484031687
Validation loss: 2.8397326259444373

Epoch: 6| Step: 5
Training loss: 2.865052137449714
Validation loss: 2.9348557683839247

Epoch: 6| Step: 6
Training loss: 2.5479700273700194
Validation loss: 2.84081798874256

Epoch: 6| Step: 7
Training loss: 3.671237192154319
Validation loss: 2.78608034913213

Epoch: 6| Step: 8
Training loss: 2.3816004938214155
Validation loss: 2.758477016917932

Epoch: 6| Step: 9
Training loss: 2.7694647906121554
Validation loss: 2.971407818772491

Epoch: 6| Step: 10
Training loss: 2.4266828498545245
Validation loss: 2.9318936883189983

Epoch: 6| Step: 11
Training loss: 2.4798926457888153
Validation loss: 2.892838546428528

Epoch: 6| Step: 12
Training loss: 2.3900674406615905
Validation loss: 2.792041788869804

Epoch: 6| Step: 13
Training loss: 2.6903299025846645
Validation loss: 2.9600329949297968

Epoch: 340| Step: 0
Training loss: 2.3844286831353325
Validation loss: 2.999592879915372

Epoch: 6| Step: 1
Training loss: 2.504991126739563
Validation loss: 2.839742937425845

Epoch: 6| Step: 2
Training loss: 2.80209477267477
Validation loss: 2.8896072108009436

Epoch: 6| Step: 3
Training loss: 2.3794036996572023
Validation loss: 2.859074476885755

Epoch: 6| Step: 4
Training loss: 2.55621572159073
Validation loss: 2.816564662237021

Epoch: 6| Step: 5
Training loss: 2.13507463150551
Validation loss: 2.826033777266196

Epoch: 6| Step: 6
Training loss: 4.161474171378783
Validation loss: 2.979954517627457

Epoch: 6| Step: 7
Training loss: 1.9092402533951367
Validation loss: 2.8787093075763757

Epoch: 6| Step: 8
Training loss: 2.7374102503726427
Validation loss: 2.8370598210963522

Epoch: 6| Step: 9
Training loss: 2.3006913016956974
Validation loss: 2.895069203571988

Epoch: 6| Step: 10
Training loss: 2.934443730371034
Validation loss: 2.8930999368725483

Epoch: 6| Step: 11
Training loss: 3.218505998270141
Validation loss: 2.879451648231681

Epoch: 6| Step: 12
Training loss: 1.986748784926146
Validation loss: 2.868559714262464

Epoch: 6| Step: 13
Training loss: 3.097588056123973
Validation loss: 2.796545040731605

Epoch: 341| Step: 0
Training loss: 3.183985549127191
Validation loss: 2.780450482709497

Epoch: 6| Step: 1
Training loss: 3.410180859733652
Validation loss: 2.860396906114649

Epoch: 6| Step: 2
Training loss: 2.6197658307499716
Validation loss: 2.865003880630222

Epoch: 6| Step: 3
Training loss: 2.198606144903565
Validation loss: 2.911372816583738

Epoch: 6| Step: 4
Training loss: 2.5711011980957905
Validation loss: 2.876783947284281

Epoch: 6| Step: 5
Training loss: 2.00943889130721
Validation loss: 2.9573411336327107

Epoch: 6| Step: 6
Training loss: 2.4888005216366826
Validation loss: 2.968034539961427

Epoch: 6| Step: 7
Training loss: 2.836542910854625
Validation loss: 2.886105150341263

Epoch: 6| Step: 8
Training loss: 2.7649101583498763
Validation loss: 2.783598620371294

Epoch: 6| Step: 9
Training loss: 2.6777121155507158
Validation loss: 2.8235533567327527

Epoch: 6| Step: 10
Training loss: 2.2564987003281254
Validation loss: 2.83601843790941

Epoch: 6| Step: 11
Training loss: 3.6829202952609656
Validation loss: 2.7555394719894712

Epoch: 6| Step: 12
Training loss: 2.4745363436959202
Validation loss: 2.9539832071412464

Epoch: 6| Step: 13
Training loss: 2.6209056348991084
Validation loss: 2.725866024114878

Epoch: 342| Step: 0
Training loss: 3.656015241862439
Validation loss: 2.879275575338671

Epoch: 6| Step: 1
Training loss: 2.4705548992098447
Validation loss: 2.760134506122524

Epoch: 6| Step: 2
Training loss: 2.981499210074162
Validation loss: 2.799190830836301

Epoch: 6| Step: 3
Training loss: 3.1081715464141415
Validation loss: 2.897242983731137

Epoch: 6| Step: 4
Training loss: 1.732381826666823
Validation loss: 2.7863487800971884

Epoch: 6| Step: 5
Training loss: 2.440419136381753
Validation loss: 2.899927168919205

Epoch: 6| Step: 6
Training loss: 2.579938585895918
Validation loss: 2.81727837528427

Epoch: 6| Step: 7
Training loss: 2.7442247262468378
Validation loss: 2.680837568536103

Epoch: 6| Step: 8
Training loss: 3.565446538579735
Validation loss: 2.814164352634918

Epoch: 6| Step: 9
Training loss: 2.5129184734996013
Validation loss: 2.7429643994778004

Epoch: 6| Step: 10
Training loss: 2.5272564880305928
Validation loss: 2.846691449399133

Epoch: 6| Step: 11
Training loss: 2.2092805186658055
Validation loss: 2.9514287193999906

Epoch: 6| Step: 12
Training loss: 2.4996389128270193
Validation loss: 3.021946787481746

Epoch: 6| Step: 13
Training loss: 1.9579552089255492
Validation loss: 2.8955368875284933

Epoch: 343| Step: 0
Training loss: 1.771608056037658
Validation loss: 2.7950387273892283

Epoch: 6| Step: 1
Training loss: 3.178636831893481
Validation loss: 2.838439172476908

Epoch: 6| Step: 2
Training loss: 2.587110731541242
Validation loss: 2.792880764180657

Epoch: 6| Step: 3
Training loss: 2.063842336621111
Validation loss: 2.7509965815465094

Epoch: 6| Step: 4
Training loss: 2.86440664035436
Validation loss: 2.912432941553977

Epoch: 6| Step: 5
Training loss: 2.8624699420267015
Validation loss: 2.8177632500937837

Epoch: 6| Step: 6
Training loss: 2.151413067273497
Validation loss: 2.812711189571942

Epoch: 6| Step: 7
Training loss: 3.720412964407637
Validation loss: 2.842668718331712

Epoch: 6| Step: 8
Training loss: 2.662559376085886
Validation loss: 2.839700511335066

Epoch: 6| Step: 9
Training loss: 2.3515266086209285
Validation loss: 2.80389408430576

Epoch: 6| Step: 10
Training loss: 1.428199034927527
Validation loss: 3.074822076658447

Epoch: 6| Step: 11
Training loss: 2.0879352732524414
Validation loss: 2.7217325303851374

Epoch: 6| Step: 12
Training loss: 2.962498557818742
Validation loss: 2.8169836585941552

Epoch: 6| Step: 13
Training loss: 2.5366383409693976
Validation loss: 2.873130297380864

Epoch: 344| Step: 0
Training loss: 2.550668804500154
Validation loss: 2.909238238996485

Epoch: 6| Step: 1
Training loss: 3.044036795324837
Validation loss: 2.929725361678511

Epoch: 6| Step: 2
Training loss: 3.023778142147616
Validation loss: 2.8268046211453264

Epoch: 6| Step: 3
Training loss: 2.3938228187740016
Validation loss: 2.7402091822526207

Epoch: 6| Step: 4
Training loss: 2.5193972529774946
Validation loss: 2.944436584634236

Epoch: 6| Step: 5
Training loss: 2.275830559502439
Validation loss: 2.8690095726906346

Epoch: 6| Step: 6
Training loss: 2.4803604222469904
Validation loss: 2.7753388028498476

Epoch: 6| Step: 7
Training loss: 1.489249007402249
Validation loss: 2.844790477819049

Epoch: 6| Step: 8
Training loss: 2.6045975493956117
Validation loss: 2.8835188424432094

Epoch: 6| Step: 9
Training loss: 2.7912392550038265
Validation loss: 2.859350760128697

Epoch: 6| Step: 10
Training loss: 2.174281701051486
Validation loss: 2.76298804451816

Epoch: 6| Step: 11
Training loss: 3.435729802104829
Validation loss: 2.8277756552208744

Epoch: 6| Step: 12
Training loss: 2.3626416562516868
Validation loss: 2.830268536578275

Epoch: 6| Step: 13
Training loss: 3.760146465086674
Validation loss: 2.800078799491065

Epoch: 345| Step: 0
Training loss: 3.238296269472859
Validation loss: 2.8628756310211805

Epoch: 6| Step: 1
Training loss: 2.253949936785509
Validation loss: 2.874610471441753

Epoch: 6| Step: 2
Training loss: 2.057762484858687
Validation loss: 2.73647801967424

Epoch: 6| Step: 3
Training loss: 2.6281280045826687
Validation loss: 2.890371783472647

Epoch: 6| Step: 4
Training loss: 2.378133012354583
Validation loss: 2.935556772198574

Epoch: 6| Step: 5
Training loss: 1.7601186586608069
Validation loss: 2.9664475213018044

Epoch: 6| Step: 6
Training loss: 3.033054404656541
Validation loss: 2.8403663459645045

Epoch: 6| Step: 7
Training loss: 2.8300039888495383
Validation loss: 2.919762395639072

Epoch: 6| Step: 8
Training loss: 2.926862244497783
Validation loss: 2.6877803823165913

Epoch: 6| Step: 9
Training loss: 2.914294195296398
Validation loss: 2.8524960690957903

Epoch: 6| Step: 10
Training loss: 3.3151900686605007
Validation loss: 2.920385846680461

Epoch: 6| Step: 11
Training loss: 2.7740233756182664
Validation loss: 2.709496866445125

Epoch: 6| Step: 12
Training loss: 2.158877002578415
Validation loss: 2.842946969246016

Epoch: 6| Step: 13
Training loss: 2.494994110834361
Validation loss: 2.7768751655183745

Epoch: 346| Step: 0
Training loss: 2.239865685931999
Validation loss: 2.866318691689476

Epoch: 6| Step: 1
Training loss: 2.5405962727741946
Validation loss: 2.7750144984723777

Epoch: 6| Step: 2
Training loss: 2.778711853863761
Validation loss: 2.8108499369524544

Epoch: 6| Step: 3
Training loss: 3.191534891885954
Validation loss: 2.7927326658224754

Epoch: 6| Step: 4
Training loss: 2.1358335010629212
Validation loss: 2.9090652441382363

Epoch: 6| Step: 5
Training loss: 2.925689492104626
Validation loss: 2.9034512098920273

Epoch: 6| Step: 6
Training loss: 2.53328622933147
Validation loss: 2.8415645724168095

Epoch: 6| Step: 7
Training loss: 2.7361058451886393
Validation loss: 2.7240404247516867

Epoch: 6| Step: 8
Training loss: 2.8182499071884446
Validation loss: 2.7953991956362043

Epoch: 6| Step: 9
Training loss: 2.12575887705432
Validation loss: 2.991979434492651

Epoch: 6| Step: 10
Training loss: 3.82102238899067
Validation loss: 2.7920730036747576

Epoch: 6| Step: 11
Training loss: 2.393876600777186
Validation loss: 2.8231052159683014

Epoch: 6| Step: 12
Training loss: 2.329641680199721
Validation loss: 2.7773655349322204

Epoch: 6| Step: 13
Training loss: 2.965828029809683
Validation loss: 2.8310992633893233

Epoch: 347| Step: 0
Training loss: 2.190619288286063
Validation loss: 2.9695433069971724

Epoch: 6| Step: 1
Training loss: 3.234645666324199
Validation loss: 2.851141280461043

Epoch: 6| Step: 2
Training loss: 2.7794223738300765
Validation loss: 3.0162971653275243

Epoch: 6| Step: 3
Training loss: 2.4120915833098904
Validation loss: 2.820275726955801

Epoch: 6| Step: 4
Training loss: 2.7957390550919197
Validation loss: 2.9102128006788877

Epoch: 6| Step: 5
Training loss: 2.9690834259718706
Validation loss: 2.774574092876109

Epoch: 6| Step: 6
Training loss: 1.8934634630834852
Validation loss: 2.955818321867826

Epoch: 6| Step: 7
Training loss: 3.015169890062977
Validation loss: 2.861353287975903

Epoch: 6| Step: 8
Training loss: 1.9545756331648358
Validation loss: 2.6993766838070967

Epoch: 6| Step: 9
Training loss: 2.812485080255566
Validation loss: 2.7718545285712564

Epoch: 6| Step: 10
Training loss: 2.310361337185553
Validation loss: 2.7940394040574907

Epoch: 6| Step: 11
Training loss: 1.862892862143826
Validation loss: 2.841785656218618

Epoch: 6| Step: 12
Training loss: 2.0746233127120783
Validation loss: 2.802088878873281

Epoch: 6| Step: 13
Training loss: 3.826800058700483
Validation loss: 2.873984692149565

Epoch: 348| Step: 0
Training loss: 3.1939273434128084
Validation loss: 2.9113297506805385

Epoch: 6| Step: 1
Training loss: 3.1777063144600812
Validation loss: 2.783515521804348

Epoch: 6| Step: 2
Training loss: 3.322899382894085
Validation loss: 2.816024913979092

Epoch: 6| Step: 3
Training loss: 2.120566061849632
Validation loss: 2.7714153214909847

Epoch: 6| Step: 4
Training loss: 2.3247842052768544
Validation loss: 2.762402258054091

Epoch: 6| Step: 5
Training loss: 2.216545191522061
Validation loss: 2.7014367648115862

Epoch: 6| Step: 6
Training loss: 3.191103525173388
Validation loss: 2.8184668229159286

Epoch: 6| Step: 7
Training loss: 2.0904061104493556
Validation loss: 2.6605625263667534

Epoch: 6| Step: 8
Training loss: 3.1223817156339164
Validation loss: 2.8571829433200047

Epoch: 6| Step: 9
Training loss: 1.8013449756750566
Validation loss: 2.8507735368589016

Epoch: 6| Step: 10
Training loss: 2.2694873378792915
Validation loss: 2.8534423870834487

Epoch: 6| Step: 11
Training loss: 2.793913482730042
Validation loss: 2.7343628956047787

Epoch: 6| Step: 12
Training loss: 2.8424766959624916
Validation loss: 2.7854501824312194

Epoch: 6| Step: 13
Training loss: 1.6782024117059782
Validation loss: 2.8061323349376917

Epoch: 349| Step: 0
Training loss: 2.480756127238143
Validation loss: 2.7680733315169768

Epoch: 6| Step: 1
Training loss: 2.284592779087723
Validation loss: 2.7505994797769553

Epoch: 6| Step: 2
Training loss: 2.3855311159444472
Validation loss: 2.738629541957106

Epoch: 6| Step: 3
Training loss: 2.4426943867386264
Validation loss: 2.887857560547979

Epoch: 6| Step: 4
Training loss: 2.6483743935777566
Validation loss: 2.9340844510868473

Epoch: 6| Step: 5
Training loss: 2.2296929020538867
Validation loss: 2.812484845994529

Epoch: 6| Step: 6
Training loss: 2.8666674066882694
Validation loss: 2.956600091073697

Epoch: 6| Step: 7
Training loss: 3.651407409430111
Validation loss: 2.9126259159475185

Epoch: 6| Step: 8
Training loss: 2.5459662378294574
Validation loss: 2.9546150285093287

Epoch: 6| Step: 9
Training loss: 3.2488228059766184
Validation loss: 2.805085045842418

Epoch: 6| Step: 10
Training loss: 2.307466958120394
Validation loss: 2.8568701040000337

Epoch: 6| Step: 11
Training loss: 2.8734262554369776
Validation loss: 2.816852195604099

Epoch: 6| Step: 12
Training loss: 2.7162653651990056
Validation loss: 2.877137458285446

Epoch: 6| Step: 13
Training loss: 3.0987437625405216
Validation loss: 2.9099080658998417

Epoch: 350| Step: 0
Training loss: 2.7977964279307983
Validation loss: 2.6691488325849635

Epoch: 6| Step: 1
Training loss: 2.7802549146511537
Validation loss: 2.732166397055209

Epoch: 6| Step: 2
Training loss: 1.6276322100448668
Validation loss: 2.700301849495259

Epoch: 6| Step: 3
Training loss: 2.132909080917641
Validation loss: 2.9322362537656534

Epoch: 6| Step: 4
Training loss: 2.1777940408376226
Validation loss: 2.730374855439747

Epoch: 6| Step: 5
Training loss: 2.3224526755908044
Validation loss: 2.8889719672348457

Epoch: 6| Step: 6
Training loss: 2.7052441707837707
Validation loss: 2.7984530699805963

Epoch: 6| Step: 7
Training loss: 2.5447495842065835
Validation loss: 2.818555216099022

Epoch: 6| Step: 8
Training loss: 2.2325504562981306
Validation loss: 3.0703182129080213

Epoch: 6| Step: 9
Training loss: 2.44426551318096
Validation loss: 2.7886234097632796

Epoch: 6| Step: 10
Training loss: 2.531221366061038
Validation loss: 2.9900940478180433

Epoch: 6| Step: 11
Training loss: 2.2565287071817743
Validation loss: 2.9087227208059074

Epoch: 6| Step: 12
Training loss: 2.6196545261008377
Validation loss: 2.906294285258967

Epoch: 6| Step: 13
Training loss: 4.189893579337876
Validation loss: 2.8373913619340185

Epoch: 351| Step: 0
Training loss: 2.777584875614327
Validation loss: 2.8089693229012207

Epoch: 6| Step: 1
Training loss: 3.2895655303982285
Validation loss: 2.6387482039106707

Epoch: 6| Step: 2
Training loss: 2.4888273445346347
Validation loss: 2.912357106550694

Epoch: 6| Step: 3
Training loss: 2.2101816563580385
Validation loss: 2.8262980979515304

Epoch: 6| Step: 4
Training loss: 1.9345862105369602
Validation loss: 2.8143116702514828

Epoch: 6| Step: 5
Training loss: 2.8598802464095785
Validation loss: 2.8002621426536787

Epoch: 6| Step: 6
Training loss: 2.4872398892226957
Validation loss: 2.778394390155058

Epoch: 6| Step: 7
Training loss: 3.2268137245189936
Validation loss: 2.6900527531937968

Epoch: 6| Step: 8
Training loss: 3.1591985545707866
Validation loss: 2.914498262023585

Epoch: 6| Step: 9
Training loss: 2.8779835354544123
Validation loss: 2.844173851911845

Epoch: 6| Step: 10
Training loss: 2.640707161432135
Validation loss: 2.8536406726144152

Epoch: 6| Step: 11
Training loss: 3.1638997353968934
Validation loss: 2.9364928205654857

Epoch: 6| Step: 12
Training loss: 2.1967711032050445
Validation loss: 2.863529450131441

Epoch: 6| Step: 13
Training loss: 2.31042242803334
Validation loss: 2.697830936844984

Epoch: 352| Step: 0
Training loss: 3.1162964735303187
Validation loss: 2.995437995465516

Epoch: 6| Step: 1
Training loss: 2.6996524975699185
Validation loss: 2.837245050219366

Epoch: 6| Step: 2
Training loss: 2.2058775460433946
Validation loss: 3.029173447274863

Epoch: 6| Step: 3
Training loss: 2.6095791125843313
Validation loss: 2.8693557037980466

Epoch: 6| Step: 4
Training loss: 2.6776088292847358
Validation loss: 3.0277710125185795

Epoch: 6| Step: 5
Training loss: 1.8977025497146816
Validation loss: 2.8324603890048854

Epoch: 6| Step: 6
Training loss: 2.252042479119519
Validation loss: 2.7968456060299793

Epoch: 6| Step: 7
Training loss: 2.2241665983098824
Validation loss: 2.830597342035319

Epoch: 6| Step: 8
Training loss: 3.0011856597142916
Validation loss: 2.7823056771572414

Epoch: 6| Step: 9
Training loss: 2.5897699175820974
Validation loss: 2.919797756350025

Epoch: 6| Step: 10
Training loss: 2.571708694216776
Validation loss: 2.9353064797622364

Epoch: 6| Step: 11
Training loss: 3.0629795244001436
Validation loss: 2.828310090949995

Epoch: 6| Step: 12
Training loss: 3.3869216312592036
Validation loss: 2.9842263186690747

Epoch: 6| Step: 13
Training loss: 2.432712646473582
Validation loss: 2.6881199613160973

Epoch: 353| Step: 0
Training loss: 2.6915621553175213
Validation loss: 2.8308777733579484

Epoch: 6| Step: 1
Training loss: 2.666568952995422
Validation loss: 2.817856332997983

Epoch: 6| Step: 2
Training loss: 3.6214474337622145
Validation loss: 2.7665260820985424

Epoch: 6| Step: 3
Training loss: 2.66387840373239
Validation loss: 2.8740182281914453

Epoch: 6| Step: 4
Training loss: 2.7749968107737866
Validation loss: 2.9674096648770285

Epoch: 6| Step: 5
Training loss: 2.262195280008735
Validation loss: 2.7145584292922873

Epoch: 6| Step: 6
Training loss: 2.270927590563387
Validation loss: 2.824113873861534

Epoch: 6| Step: 7
Training loss: 3.5158809314395247
Validation loss: 2.8812314080310784

Epoch: 6| Step: 8
Training loss: 2.771344321800448
Validation loss: 2.78361781906898

Epoch: 6| Step: 9
Training loss: 2.7587200973127706
Validation loss: 2.9072160388816783

Epoch: 6| Step: 10
Training loss: 2.5299926272198148
Validation loss: 3.006484105182678

Epoch: 6| Step: 11
Training loss: 2.0493317049740187
Validation loss: 2.7573007743705453

Epoch: 6| Step: 12
Training loss: 2.133257920700563
Validation loss: 2.836472775842031

Epoch: 6| Step: 13
Training loss: 2.240378683642157
Validation loss: 2.7334864134457493

Epoch: 354| Step: 0
Training loss: 2.181197214444297
Validation loss: 2.783646471354789

Epoch: 6| Step: 1
Training loss: 2.7037371344751855
Validation loss: 2.73890928312993

Epoch: 6| Step: 2
Training loss: 3.021696313823756
Validation loss: 2.7759352671345674

Epoch: 6| Step: 3
Training loss: 2.448079746306256
Validation loss: 2.8632534044603934

Epoch: 6| Step: 4
Training loss: 2.8482837796648623
Validation loss: 2.819538368240639

Epoch: 6| Step: 5
Training loss: 3.3505228915574636
Validation loss: 2.7885440638598205

Epoch: 6| Step: 6
Training loss: 2.053797423917459
Validation loss: 2.778105944728896

Epoch: 6| Step: 7
Training loss: 2.394275744996514
Validation loss: 2.8464007170837697

Epoch: 6| Step: 8
Training loss: 2.6516923287055234
Validation loss: 2.834815897552599

Epoch: 6| Step: 9
Training loss: 2.884073782719069
Validation loss: 2.808801293080204

Epoch: 6| Step: 10
Training loss: 2.2134975533671155
Validation loss: 2.735235638397523

Epoch: 6| Step: 11
Training loss: 2.7444334043657417
Validation loss: 2.883273429136883

Epoch: 6| Step: 12
Training loss: 2.3323866990221913
Validation loss: 2.9160316063038625

Epoch: 6| Step: 13
Training loss: 1.82938537188093
Validation loss: 2.7142380788417917

Epoch: 355| Step: 0
Training loss: 2.6543063962876507
Validation loss: 2.9630573677960257

Epoch: 6| Step: 1
Training loss: 2.2305297843211815
Validation loss: 2.8786745482272855

Epoch: 6| Step: 2
Training loss: 2.4971544283654596
Validation loss: 2.708742328238482

Epoch: 6| Step: 3
Training loss: 3.219794094776302
Validation loss: 2.6647199397443733

Epoch: 6| Step: 4
Training loss: 2.798851721185643
Validation loss: 2.919262400466553

Epoch: 6| Step: 5
Training loss: 2.352080734787602
Validation loss: 2.76292063162459

Epoch: 6| Step: 6
Training loss: 2.464383863780958
Validation loss: 2.8173127337465758

Epoch: 6| Step: 7
Training loss: 2.575246973137965
Validation loss: 2.9255598136054934

Epoch: 6| Step: 8
Training loss: 2.508019174396038
Validation loss: 3.0255286321375205

Epoch: 6| Step: 9
Training loss: 2.865116712446448
Validation loss: 2.903159018686048

Epoch: 6| Step: 10
Training loss: 2.6555639839659317
Validation loss: 2.850275700224329

Epoch: 6| Step: 11
Training loss: 2.5621341351096247
Validation loss: 2.8668564513152197

Epoch: 6| Step: 12
Training loss: 2.2892874649479844
Validation loss: 2.775629288880441

Epoch: 6| Step: 13
Training loss: 3.303004636709878
Validation loss: 2.8313999389766504

Epoch: 356| Step: 0
Training loss: 3.7107209794975295
Validation loss: 2.569756032809888

Epoch: 6| Step: 1
Training loss: 2.452482102821679
Validation loss: 2.850593957786189

Epoch: 6| Step: 2
Training loss: 2.1451787474877464
Validation loss: 2.7949963299002962

Epoch: 6| Step: 3
Training loss: 2.2630608090175746
Validation loss: 2.9241799850660173

Epoch: 6| Step: 4
Training loss: 2.1469075251840484
Validation loss: 2.959773353731216

Epoch: 6| Step: 5
Training loss: 2.2973856455639656
Validation loss: 2.805213912869915

Epoch: 6| Step: 6
Training loss: 2.618825553587113
Validation loss: 2.912216256639703

Epoch: 6| Step: 7
Training loss: 2.4926022749476537
Validation loss: 2.7943049144364736

Epoch: 6| Step: 8
Training loss: 2.6259507773464428
Validation loss: 2.7325170427198144

Epoch: 6| Step: 9
Training loss: 2.862896860922394
Validation loss: 2.969232005188024

Epoch: 6| Step: 10
Training loss: 2.698878486263908
Validation loss: 2.8814768969433775

Epoch: 6| Step: 11
Training loss: 2.9691346571834347
Validation loss: 2.7321994697460505

Epoch: 6| Step: 12
Training loss: 2.2949006814180963
Validation loss: 2.721459813968735

Epoch: 6| Step: 13
Training loss: 2.8848846349012733
Validation loss: 2.795913185348734

Epoch: 357| Step: 0
Training loss: 3.099441379544768
Validation loss: 2.78679869195332

Epoch: 6| Step: 1
Training loss: 2.6718003111990956
Validation loss: 2.8581130431843067

Epoch: 6| Step: 2
Training loss: 3.4673648852459302
Validation loss: 2.7463529852412374

Epoch: 6| Step: 3
Training loss: 2.2407397337923802
Validation loss: 2.8333112967959444

Epoch: 6| Step: 4
Training loss: 2.3113373591664237
Validation loss: 2.749557918241934

Epoch: 6| Step: 5
Training loss: 2.3399892516582157
Validation loss: 2.749269989870293

Epoch: 6| Step: 6
Training loss: 1.4750206380143835
Validation loss: 2.744837398132127

Epoch: 6| Step: 7
Training loss: 2.817195702327693
Validation loss: 2.9049936181759506

Epoch: 6| Step: 8
Training loss: 3.0464364543168188
Validation loss: 3.0034721117653675

Epoch: 6| Step: 9
Training loss: 2.484015192811609
Validation loss: 2.8009686302015884

Epoch: 6| Step: 10
Training loss: 1.8605400090127944
Validation loss: 2.9235460119226055

Epoch: 6| Step: 11
Training loss: 2.451416197982795
Validation loss: 2.7233297558075664

Epoch: 6| Step: 12
Training loss: 2.4521137266995208
Validation loss: 2.8415181731366492

Epoch: 6| Step: 13
Training loss: 3.0926123174502362
Validation loss: 2.7966690670536365

Epoch: 358| Step: 0
Training loss: 2.31095968961863
Validation loss: 2.906661514467417

Epoch: 6| Step: 1
Training loss: 2.1760115715588704
Validation loss: 2.867922431393284

Epoch: 6| Step: 2
Training loss: 3.4727353407753827
Validation loss: 2.7932260229735837

Epoch: 6| Step: 3
Training loss: 2.638202888154158
Validation loss: 2.823924694088709

Epoch: 6| Step: 4
Training loss: 2.7023186335371085
Validation loss: 2.8344261295700455

Epoch: 6| Step: 5
Training loss: 2.2990996298488655
Validation loss: 2.7519583194368393

Epoch: 6| Step: 6
Training loss: 2.453922798030502
Validation loss: 2.817130757797933

Epoch: 6| Step: 7
Training loss: 1.5518961629296424
Validation loss: 3.066057287628295

Epoch: 6| Step: 8
Training loss: 3.22691095793552
Validation loss: 2.864733829665455

Epoch: 6| Step: 9
Training loss: 3.1062380815427
Validation loss: 2.894130561755788

Epoch: 6| Step: 10
Training loss: 2.7529089887313813
Validation loss: 2.765847836455287

Epoch: 6| Step: 11
Training loss: 1.597119080166438
Validation loss: 2.961527906532234

Epoch: 6| Step: 12
Training loss: 2.388111463606727
Validation loss: 2.775506514233983

Epoch: 6| Step: 13
Training loss: 2.220231649495857
Validation loss: 2.733959969755418

Epoch: 359| Step: 0
Training loss: 2.3244043099836897
Validation loss: 2.981767930171227

Epoch: 6| Step: 1
Training loss: 2.0341027987448954
Validation loss: 2.816490774772374

Epoch: 6| Step: 2
Training loss: 2.5226799267661635
Validation loss: 2.860932045297836

Epoch: 6| Step: 3
Training loss: 2.6987269791314286
Validation loss: 2.7326133910890005

Epoch: 6| Step: 4
Training loss: 1.7772438775811776
Validation loss: 2.8360161147372316

Epoch: 6| Step: 5
Training loss: 2.609307750817554
Validation loss: 2.96580376793106

Epoch: 6| Step: 6
Training loss: 2.537189344360117
Validation loss: 2.8076244886534334

Epoch: 6| Step: 7
Training loss: 2.8426370643710968
Validation loss: 2.843687566833399

Epoch: 6| Step: 8
Training loss: 2.5631722289587127
Validation loss: 2.8822022474747437

Epoch: 6| Step: 9
Training loss: 2.3195046196883538
Validation loss: 2.8897744596729376

Epoch: 6| Step: 10
Training loss: 3.24314009678551
Validation loss: 2.9570772386325763

Epoch: 6| Step: 11
Training loss: 2.918740942734709
Validation loss: 2.793583355369576

Epoch: 6| Step: 12
Training loss: 3.041633832223026
Validation loss: 2.842052112863469

Epoch: 6| Step: 13
Training loss: 2.785141954211426
Validation loss: 2.8255615854459935

Epoch: 360| Step: 0
Training loss: 2.319793540383998
Validation loss: 3.0021778955286123

Epoch: 6| Step: 1
Training loss: 3.289305906735264
Validation loss: 2.828326474468346

Epoch: 6| Step: 2
Training loss: 1.7644375209021248
Validation loss: 2.965258072173483

Epoch: 6| Step: 3
Training loss: 2.5319395656635177
Validation loss: 2.8825110790272896

Epoch: 6| Step: 4
Training loss: 2.2154986777296277
Validation loss: 2.917829837702906

Epoch: 6| Step: 5
Training loss: 3.0962686786234506
Validation loss: 2.9739575172783668

Epoch: 6| Step: 6
Training loss: 2.542420218237157
Validation loss: 2.9207327698674046

Epoch: 6| Step: 7
Training loss: 3.036366657074914
Validation loss: 2.7785846889424475

Epoch: 6| Step: 8
Training loss: 2.4948125425565664
Validation loss: 2.9494374427262664

Epoch: 6| Step: 9
Training loss: 2.6384286267182087
Validation loss: 2.931608300801028

Epoch: 6| Step: 10
Training loss: 2.92893528754736
Validation loss: 2.8073175197647284

Epoch: 6| Step: 11
Training loss: 2.505057369344274
Validation loss: 2.764093223161784

Epoch: 6| Step: 12
Training loss: 2.6772908428431212
Validation loss: 2.866185269771303

Epoch: 6| Step: 13
Training loss: 3.761277724544518
Validation loss: 2.8885382013339447

Epoch: 361| Step: 0
Training loss: 2.8286941545733053
Validation loss: 2.719644705984547

Epoch: 6| Step: 1
Training loss: 2.392135641481497
Validation loss: 2.808302941907498

Epoch: 6| Step: 2
Training loss: 1.9548667770613806
Validation loss: 2.7710314188032745

Epoch: 6| Step: 3
Training loss: 2.933190939076931
Validation loss: 2.8101802032240877

Epoch: 6| Step: 4
Training loss: 2.460019476278477
Validation loss: 2.908997072649448

Epoch: 6| Step: 5
Training loss: 2.1374263951528354
Validation loss: 2.6385578982751383

Epoch: 6| Step: 6
Training loss: 2.577184609654021
Validation loss: 2.7595300781114327

Epoch: 6| Step: 7
Training loss: 2.8493655586128095
Validation loss: 2.687368108780684

Epoch: 6| Step: 8
Training loss: 2.7402935388748446
Validation loss: 2.9548910207672505

Epoch: 6| Step: 9
Training loss: 2.8375952213123434
Validation loss: 2.785414522525017

Epoch: 6| Step: 10
Training loss: 2.653315639948039
Validation loss: 2.875762385385236

Epoch: 6| Step: 11
Training loss: 3.2179684477137056
Validation loss: 2.770965304405795

Epoch: 6| Step: 12
Training loss: 1.9309280053007318
Validation loss: 2.890346779996445

Epoch: 6| Step: 13
Training loss: 2.0634093158558584
Validation loss: 2.814828192976767

Epoch: 362| Step: 0
Training loss: 2.438563579432084
Validation loss: 3.05044312659733

Epoch: 6| Step: 1
Training loss: 2.182999914011165
Validation loss: 2.8671023900030477

Epoch: 6| Step: 2
Training loss: 2.446413322536451
Validation loss: 2.9531508973772196

Epoch: 6| Step: 3
Training loss: 2.99200136088784
Validation loss: 2.644524749114358

Epoch: 6| Step: 4
Training loss: 2.4090771601106304
Validation loss: 2.818226839103255

Epoch: 6| Step: 5
Training loss: 2.295781919961789
Validation loss: 2.826295273344694

Epoch: 6| Step: 6
Training loss: 3.8903681045959924
Validation loss: 2.961637753491795

Epoch: 6| Step: 7
Training loss: 2.7537630517401808
Validation loss: 2.7619448356614678

Epoch: 6| Step: 8
Training loss: 2.1926410752323653
Validation loss: 2.8045252010558683

Epoch: 6| Step: 9
Training loss: 2.389173677999877
Validation loss: 2.8293395103357857

Epoch: 6| Step: 10
Training loss: 2.2944207606146483
Validation loss: 2.821901815033532

Epoch: 6| Step: 11
Training loss: 1.924402699136437
Validation loss: 2.823790557357549

Epoch: 6| Step: 12
Training loss: 2.6195802596980133
Validation loss: 3.016347977098525

Epoch: 6| Step: 13
Training loss: 2.2058214500845983
Validation loss: 2.879030144044022

Epoch: 363| Step: 0
Training loss: 2.8069985731533706
Validation loss: 2.8294328896843712

Epoch: 6| Step: 1
Training loss: 2.5392037220341708
Validation loss: 2.745217992661083

Epoch: 6| Step: 2
Training loss: 3.1947352253982473
Validation loss: 2.7689715568711026

Epoch: 6| Step: 3
Training loss: 2.642677367292977
Validation loss: 2.9848047020242965

Epoch: 6| Step: 4
Training loss: 3.1932763511760878
Validation loss: 2.8228791009647867

Epoch: 6| Step: 5
Training loss: 2.1632931439977514
Validation loss: 2.8705856466313553

Epoch: 6| Step: 6
Training loss: 2.6912483866642902
Validation loss: 2.896914782951556

Epoch: 6| Step: 7
Training loss: 2.3436432877724895
Validation loss: 2.7853609742848273

Epoch: 6| Step: 8
Training loss: 2.0374094375423226
Validation loss: 2.87805788049791

Epoch: 6| Step: 9
Training loss: 2.11804947426623
Validation loss: 2.857994838080427

Epoch: 6| Step: 10
Training loss: 2.3607590007648773
Validation loss: 3.015757307945627

Epoch: 6| Step: 11
Training loss: 2.921677037025003
Validation loss: 2.8393717989184224

Epoch: 6| Step: 12
Training loss: 2.28092985650248
Validation loss: 2.846756439533593

Epoch: 6| Step: 13
Training loss: 1.3911991862762467
Validation loss: 2.8121478545070504

Epoch: 364| Step: 0
Training loss: 3.155093292694831
Validation loss: 2.749965338427934

Epoch: 6| Step: 1
Training loss: 2.9369425143161147
Validation loss: 2.8813547100735937

Epoch: 6| Step: 2
Training loss: 2.339036805566644
Validation loss: 2.8831288402887445

Epoch: 6| Step: 3
Training loss: 2.5411663084045117
Validation loss: 2.861279255243425

Epoch: 6| Step: 4
Training loss: 2.0948624573489214
Validation loss: 2.796607231044295

Epoch: 6| Step: 5
Training loss: 2.1413615275308735
Validation loss: 2.6817691413893288

Epoch: 6| Step: 6
Training loss: 2.638843544910649
Validation loss: 2.8109467696441217

Epoch: 6| Step: 7
Training loss: 2.614861300055946
Validation loss: 2.760142217092689

Epoch: 6| Step: 8
Training loss: 3.2138352880804475
Validation loss: 2.8255052413650104

Epoch: 6| Step: 9
Training loss: 2.7940784303965986
Validation loss: 2.9338454127691973

Epoch: 6| Step: 10
Training loss: 1.7433896557235735
Validation loss: 2.89111705295912

Epoch: 6| Step: 11
Training loss: 2.6981180378548135
Validation loss: 2.7925205088162226

Epoch: 6| Step: 12
Training loss: 2.933349924329597
Validation loss: 2.956355844927932

Epoch: 6| Step: 13
Training loss: 2.5029434995534334
Validation loss: 2.9517657564669237

Epoch: 365| Step: 0
Training loss: 3.127132908586763
Validation loss: 2.7709323317330368

Epoch: 6| Step: 1
Training loss: 3.3589729955688745
Validation loss: 2.769897566304021

Epoch: 6| Step: 2
Training loss: 1.9303137500493956
Validation loss: 2.945098238109695

Epoch: 6| Step: 3
Training loss: 1.9777977743578545
Validation loss: 2.9802070345470053

Epoch: 6| Step: 4
Training loss: 2.3187209299738147
Validation loss: 2.6981713934954694

Epoch: 6| Step: 5
Training loss: 2.355070722615461
Validation loss: 2.916767170195535

Epoch: 6| Step: 6
Training loss: 2.3252880041111013
Validation loss: 2.8954532456774023

Epoch: 6| Step: 7
Training loss: 2.613539154144778
Validation loss: 2.9605634921040775

Epoch: 6| Step: 8
Training loss: 1.6128135908507863
Validation loss: 2.672992995559374

Epoch: 6| Step: 9
Training loss: 2.2540558181932324
Validation loss: 2.918930987777579

Epoch: 6| Step: 10
Training loss: 3.5248555038812848
Validation loss: 2.964327307840962

Epoch: 6| Step: 11
Training loss: 2.9692096555133243
Validation loss: 2.8194184222184795

Epoch: 6| Step: 12
Training loss: 3.1975108001979935
Validation loss: 2.8125714328312883

Epoch: 6| Step: 13
Training loss: 1.620744782540183
Validation loss: 2.8662007203457804

Epoch: 366| Step: 0
Training loss: 2.1596341321288106
Validation loss: 2.7549764701279593

Epoch: 6| Step: 1
Training loss: 2.3675377715661647
Validation loss: 2.841202931366924

Epoch: 6| Step: 2
Training loss: 2.60894945523658
Validation loss: 2.686883350549373

Epoch: 6| Step: 3
Training loss: 2.6891551576440405
Validation loss: 3.0464907723382177

Epoch: 6| Step: 4
Training loss: 1.8924424444640664
Validation loss: 2.872188538136512

Epoch: 6| Step: 5
Training loss: 3.365358922671661
Validation loss: 2.8493163199290543

Epoch: 6| Step: 6
Training loss: 2.8916775823235037
Validation loss: 2.7834736478513222

Epoch: 6| Step: 7
Training loss: 2.81816962245081
Validation loss: 2.7862534995240096

Epoch: 6| Step: 8
Training loss: 3.0446210300284826
Validation loss: 2.870432995969297

Epoch: 6| Step: 9
Training loss: 2.2878925341063616
Validation loss: 2.5419851772933137

Epoch: 6| Step: 10
Training loss: 2.4277057968262143
Validation loss: 2.811545084338715

Epoch: 6| Step: 11
Training loss: 2.55821893873233
Validation loss: 2.823462959947138

Epoch: 6| Step: 12
Training loss: 2.4103124434991545
Validation loss: 2.6994550285238255

Epoch: 6| Step: 13
Training loss: 1.8850424449604226
Validation loss: 2.8196030322833456

Epoch: 367| Step: 0
Training loss: 2.639693598161592
Validation loss: 2.933073400620067

Epoch: 6| Step: 1
Training loss: 2.853128248967037
Validation loss: 2.9204272085998784

Epoch: 6| Step: 2
Training loss: 2.4159517765474505
Validation loss: 2.966548834644416

Epoch: 6| Step: 3
Training loss: 2.7801362282835966
Validation loss: 2.8718673131607044

Epoch: 6| Step: 4
Training loss: 2.2516989121950606
Validation loss: 2.743397436457479

Epoch: 6| Step: 5
Training loss: 3.867200693435512
Validation loss: 2.8714719778663973

Epoch: 6| Step: 6
Training loss: 2.49196717056644
Validation loss: 2.7831089581698794

Epoch: 6| Step: 7
Training loss: 2.175878115129479
Validation loss: 2.808710834981789

Epoch: 6| Step: 8
Training loss: 2.9277314433566044
Validation loss: 2.8319194889611756

Epoch: 6| Step: 9
Training loss: 2.310587323980265
Validation loss: 2.767883424278299

Epoch: 6| Step: 10
Training loss: 2.1259581705681256
Validation loss: 2.8623808333769234

Epoch: 6| Step: 11
Training loss: 2.2982537938500274
Validation loss: 2.8819223336777875

Epoch: 6| Step: 12
Training loss: 2.760378241121607
Validation loss: 2.806710186523159

Epoch: 6| Step: 13
Training loss: 2.2562598991705234
Validation loss: 2.8332776788629763

Epoch: 368| Step: 0
Training loss: 2.656851038531985
Validation loss: 2.9317704901120667

Epoch: 6| Step: 1
Training loss: 2.2432633321117845
Validation loss: 2.815128593858308

Epoch: 6| Step: 2
Training loss: 2.3126544385322654
Validation loss: 2.720369259656676

Epoch: 6| Step: 3
Training loss: 3.217814040904673
Validation loss: 2.7716929986293017

Epoch: 6| Step: 4
Training loss: 2.654411667116265
Validation loss: 2.860200705021175

Epoch: 6| Step: 5
Training loss: 3.2261981896988767
Validation loss: 2.9421511011511914

Epoch: 6| Step: 6
Training loss: 2.6840675080190812
Validation loss: 2.836801272015285

Epoch: 6| Step: 7
Training loss: 2.2397143185184714
Validation loss: 2.8699390322993366

Epoch: 6| Step: 8
Training loss: 3.1375617275776984
Validation loss: 2.8306616293686946

Epoch: 6| Step: 9
Training loss: 3.2454094377787284
Validation loss: 2.9471304422741245

Epoch: 6| Step: 10
Training loss: 2.319710290512412
Validation loss: 2.8405887689306772

Epoch: 6| Step: 11
Training loss: 1.879141366566979
Validation loss: 2.9071996687330173

Epoch: 6| Step: 12
Training loss: 2.504011464400448
Validation loss: 2.842324317930829

Epoch: 6| Step: 13
Training loss: 2.52825826286596
Validation loss: 2.7995244132084482

Epoch: 369| Step: 0
Training loss: 1.9397691544114226
Validation loss: 2.804402716968438

Epoch: 6| Step: 1
Training loss: 2.1072554500507996
Validation loss: 3.0322241495426785

Epoch: 6| Step: 2
Training loss: 2.8403494488275696
Validation loss: 2.8331784577600123

Epoch: 6| Step: 3
Training loss: 2.007299097823077
Validation loss: 2.8236880630935723

Epoch: 6| Step: 4
Training loss: 2.2985341832969697
Validation loss: 2.927352400395729

Epoch: 6| Step: 5
Training loss: 2.1979013837189583
Validation loss: 2.7110962688408033

Epoch: 6| Step: 6
Training loss: 2.56457677283069
Validation loss: 2.8218503800756523

Epoch: 6| Step: 7
Training loss: 2.960192906305517
Validation loss: 3.0314018922720942

Epoch: 6| Step: 8
Training loss: 2.3645466088847518
Validation loss: 2.7642155522583076

Epoch: 6| Step: 9
Training loss: 3.0164276794130824
Validation loss: 2.827104493931609

Epoch: 6| Step: 10
Training loss: 3.5488120012016764
Validation loss: 2.798233742534132

Epoch: 6| Step: 11
Training loss: 2.428219661561219
Validation loss: 2.6511897071489567

Epoch: 6| Step: 12
Training loss: 2.6197075852437877
Validation loss: 2.911341589090331

Epoch: 6| Step: 13
Training loss: 3.466903607511939
Validation loss: 2.869294033286922

Epoch: 370| Step: 0
Training loss: 3.2185627410637907
Validation loss: 2.783631010153463

Epoch: 6| Step: 1
Training loss: 2.4579180889402514
Validation loss: 2.747785868289347

Epoch: 6| Step: 2
Training loss: 2.9556512270606947
Validation loss: 2.9643766667653604

Epoch: 6| Step: 3
Training loss: 2.9973476128741465
Validation loss: 2.864623989737757

Epoch: 6| Step: 4
Training loss: 2.261976896058402
Validation loss: 2.9617897084592366

Epoch: 6| Step: 5
Training loss: 3.1270125965417317
Validation loss: 2.878883911941984

Epoch: 6| Step: 6
Training loss: 2.763909794032421
Validation loss: 2.8245095368363584

Epoch: 6| Step: 7
Training loss: 3.1564720755528817
Validation loss: 2.944516787301673

Epoch: 6| Step: 8
Training loss: 2.3724824713008186
Validation loss: 2.810308500000661

Epoch: 6| Step: 9
Training loss: 1.8530039910213272
Validation loss: 2.967959372006078

Epoch: 6| Step: 10
Training loss: 1.9633365864664705
Validation loss: 2.970403093359852

Epoch: 6| Step: 11
Training loss: 3.4523607331734625
Validation loss: 2.958548714057761

Epoch: 6| Step: 12
Training loss: 2.288208160848096
Validation loss: 2.931616674835054

Epoch: 6| Step: 13
Training loss: 2.501119839676439
Validation loss: 2.92185757311413

Epoch: 371| Step: 0
Training loss: 1.7712805314215594
Validation loss: 2.9191428969128848

Epoch: 6| Step: 1
Training loss: 3.356914240001028
Validation loss: 2.714132772737155

Epoch: 6| Step: 2
Training loss: 2.2065991003904064
Validation loss: 2.871779617335457

Epoch: 6| Step: 3
Training loss: 2.157120901950636
Validation loss: 2.8404772872836537

Epoch: 6| Step: 4
Training loss: 2.9061198871978924
Validation loss: 2.8287525050796756

Epoch: 6| Step: 5
Training loss: 2.859911425359338
Validation loss: 2.8202927366333546

Epoch: 6| Step: 6
Training loss: 2.361692793258989
Validation loss: 2.702858321747721

Epoch: 6| Step: 7
Training loss: 2.3435966950187033
Validation loss: 2.832306531653588

Epoch: 6| Step: 8
Training loss: 3.1025604256917156
Validation loss: 2.788999570630278

Epoch: 6| Step: 9
Training loss: 2.2732873191912417
Validation loss: 2.78389486844494

Epoch: 6| Step: 10
Training loss: 2.63755321720184
Validation loss: 2.8914857043599214

Epoch: 6| Step: 11
Training loss: 2.0261597455942972
Validation loss: 2.7551813917325547

Epoch: 6| Step: 12
Training loss: 3.081308026183309
Validation loss: 2.7514491891321446

Epoch: 6| Step: 13
Training loss: 3.456644189578199
Validation loss: 2.8217670915395026

Epoch: 372| Step: 0
Training loss: 3.317184159308183
Validation loss: 2.835277136409696

Epoch: 6| Step: 1
Training loss: 2.459838912620845
Validation loss: 2.7292910687398706

Epoch: 6| Step: 2
Training loss: 2.723192203262455
Validation loss: 2.89533561760756

Epoch: 6| Step: 3
Training loss: 1.7735789238420374
Validation loss: 2.8819918465565557

Epoch: 6| Step: 4
Training loss: 2.7283149050131197
Validation loss: 2.8213422704918725

Epoch: 6| Step: 5
Training loss: 2.855843786823994
Validation loss: 2.7671470099335713

Epoch: 6| Step: 6
Training loss: 3.016104704498996
Validation loss: 2.823092143038596

Epoch: 6| Step: 7
Training loss: 2.239691963814095
Validation loss: 2.848483113693

Epoch: 6| Step: 8
Training loss: 2.216428159727142
Validation loss: 2.9059157023230715

Epoch: 6| Step: 9
Training loss: 2.1125959882428527
Validation loss: 2.7137273462321247

Epoch: 6| Step: 10
Training loss: 3.017223823759373
Validation loss: 2.6706753157750835

Epoch: 6| Step: 11
Training loss: 2.561583936749809
Validation loss: 3.0327271056394216

Epoch: 6| Step: 12
Training loss: 2.3016862368551596
Validation loss: 2.9178700998251466

Epoch: 6| Step: 13
Training loss: 2.230055682252635
Validation loss: 2.9799696476011297

Epoch: 373| Step: 0
Training loss: 2.7519353645352638
Validation loss: 2.910703054600937

Epoch: 6| Step: 1
Training loss: 2.42430180202361
Validation loss: 2.7981485581538665

Epoch: 6| Step: 2
Training loss: 1.4032154402440122
Validation loss: 2.867195999594728

Epoch: 6| Step: 3
Training loss: 2.6176722746578127
Validation loss: 2.822594834568905

Epoch: 6| Step: 4
Training loss: 2.8050150135474867
Validation loss: 3.010249424512144

Epoch: 6| Step: 5
Training loss: 2.603939219396833
Validation loss: 2.8146555216374827

Epoch: 6| Step: 6
Training loss: 2.3551490781861255
Validation loss: 2.7403008678465754

Epoch: 6| Step: 7
Training loss: 2.5873518012171672
Validation loss: 2.9059257683717754

Epoch: 6| Step: 8
Training loss: 3.0627512926038705
Validation loss: 3.024299309033154

Epoch: 6| Step: 9
Training loss: 2.051087914199414
Validation loss: 2.8667240399168485

Epoch: 6| Step: 10
Training loss: 3.0093760204214424
Validation loss: 2.8487906115952795

Epoch: 6| Step: 11
Training loss: 2.66125617904985
Validation loss: 2.6992459988024855

Epoch: 6| Step: 12
Training loss: 3.944574812106271
Validation loss: 2.978310420167402

Epoch: 6| Step: 13
Training loss: 2.3489041431432525
Validation loss: 2.871498379528309

Epoch: 374| Step: 0
Training loss: 2.4969232700155635
Validation loss: 2.860401647291544

Epoch: 6| Step: 1
Training loss: 2.38086378114338
Validation loss: 2.690812930922151

Epoch: 6| Step: 2
Training loss: 2.911159839011999
Validation loss: 2.6872102543556435

Epoch: 6| Step: 3
Training loss: 2.031784222117137
Validation loss: 2.7605811625941907

Epoch: 6| Step: 4
Training loss: 3.8517749410542153
Validation loss: 2.84373379819578

Epoch: 6| Step: 5
Training loss: 2.470648120373395
Validation loss: 2.813421062565851

Epoch: 6| Step: 6
Training loss: 2.1510954350608777
Validation loss: 2.85610399513674

Epoch: 6| Step: 7
Training loss: 2.4127466263491044
Validation loss: 2.7713718406057453

Epoch: 6| Step: 8
Training loss: 2.230426099807039
Validation loss: 2.875375559969749

Epoch: 6| Step: 9
Training loss: 3.088392608974048
Validation loss: 2.863869005262217

Epoch: 6| Step: 10
Training loss: 2.493263897090452
Validation loss: 2.856301223490515

Epoch: 6| Step: 11
Training loss: 2.0998990307103975
Validation loss: 2.939924806299187

Epoch: 6| Step: 12
Training loss: 2.316640086215919
Validation loss: 2.9504220388798696

Epoch: 6| Step: 13
Training loss: 1.9572258584120514
Validation loss: 2.7681508257166634

Epoch: 375| Step: 0
Training loss: 3.25094004020676
Validation loss: 2.8675937374299303

Epoch: 6| Step: 1
Training loss: 2.9303012052523574
Validation loss: 2.673923637989917

Epoch: 6| Step: 2
Training loss: 2.930375732963323
Validation loss: 2.901582448593035

Epoch: 6| Step: 3
Training loss: 3.3650946607496297
Validation loss: 2.805031388723723

Epoch: 6| Step: 4
Training loss: 2.03123004610091
Validation loss: 2.856494792674101

Epoch: 6| Step: 5
Training loss: 2.283722987190097
Validation loss: 2.9180507282417074

Epoch: 6| Step: 6
Training loss: 3.216955184515272
Validation loss: 2.950828272452111

Epoch: 6| Step: 7
Training loss: 2.5136603982777532
Validation loss: 2.965489469285034

Epoch: 6| Step: 8
Training loss: 1.8521504172958483
Validation loss: 2.9557613409901466

Epoch: 6| Step: 9
Training loss: 3.042729927847419
Validation loss: 2.938645227975725

Epoch: 6| Step: 10
Training loss: 2.090119245677414
Validation loss: 2.8037079026907548

Epoch: 6| Step: 11
Training loss: 1.8662815849150727
Validation loss: 2.9212092914061945

Epoch: 6| Step: 12
Training loss: 3.3653984539040898
Validation loss: 2.8326225064694963

Epoch: 6| Step: 13
Training loss: 1.7388374038985517
Validation loss: 3.0391470457677623

Epoch: 376| Step: 0
Training loss: 2.376585381050993
Validation loss: 2.886891629365597

Epoch: 6| Step: 1
Training loss: 2.321980400311586
Validation loss: 2.885930677291138

Epoch: 6| Step: 2
Training loss: 2.6135560306069716
Validation loss: 2.8460261536791496

Epoch: 6| Step: 3
Training loss: 2.326755812320764
Validation loss: 2.7927600927508482

Epoch: 6| Step: 4
Training loss: 2.838331320898747
Validation loss: 2.802758738648508

Epoch: 6| Step: 5
Training loss: 2.2308233884414697
Validation loss: 2.7892666287564913

Epoch: 6| Step: 6
Training loss: 3.168884370802693
Validation loss: 2.860908006350614

Epoch: 6| Step: 7
Training loss: 3.411036776444779
Validation loss: 2.929117570467167

Epoch: 6| Step: 8
Training loss: 2.691474105356068
Validation loss: 2.802086465357079

Epoch: 6| Step: 9
Training loss: 2.1362681358286317
Validation loss: 2.686071151018375

Epoch: 6| Step: 10
Training loss: 2.932507106710605
Validation loss: 2.7689817207874396

Epoch: 6| Step: 11
Training loss: 1.5281422276686187
Validation loss: 2.7008413123333175

Epoch: 6| Step: 12
Training loss: 2.7447056524611786
Validation loss: 2.9561153224485928

Epoch: 6| Step: 13
Training loss: 3.663469669233665
Validation loss: 2.7490153372360795

Epoch: 377| Step: 0
Training loss: 2.1554016434668095
Validation loss: 2.7558841288650022

Epoch: 6| Step: 1
Training loss: 2.433074650884124
Validation loss: 2.8575491309089607

Epoch: 6| Step: 2
Training loss: 1.886369692655871
Validation loss: 2.8912394386364153

Epoch: 6| Step: 3
Training loss: 2.925056561306263
Validation loss: 2.646775630566526

Epoch: 6| Step: 4
Training loss: 2.795908329313623
Validation loss: 2.8682427360169465

Epoch: 6| Step: 5
Training loss: 2.4597193049188517
Validation loss: 2.873136945315514

Epoch: 6| Step: 6
Training loss: 2.562163074952519
Validation loss: 2.8183353345075313

Epoch: 6| Step: 7
Training loss: 2.4845732603797073
Validation loss: 2.883121419124632

Epoch: 6| Step: 8
Training loss: 3.3403327093192012
Validation loss: 2.8448357522537195

Epoch: 6| Step: 9
Training loss: 2.286469536987755
Validation loss: 2.8201084803429723

Epoch: 6| Step: 10
Training loss: 2.1689623506126714
Validation loss: 2.9804072600519453

Epoch: 6| Step: 11
Training loss: 2.3575266488471374
Validation loss: 2.893335486971184

Epoch: 6| Step: 12
Training loss: 3.5258531768920838
Validation loss: 2.7153361226569426

Epoch: 6| Step: 13
Training loss: 1.9791867171493276
Validation loss: 2.8692271488041077

Epoch: 378| Step: 0
Training loss: 2.8273639814206906
Validation loss: 2.871857966851073

Epoch: 6| Step: 1
Training loss: 2.193488724411104
Validation loss: 2.8746379920427056

Epoch: 6| Step: 2
Training loss: 2.7902460231802224
Validation loss: 2.8090605566273714

Epoch: 6| Step: 3
Training loss: 2.8362796461456576
Validation loss: 2.946822493248969

Epoch: 6| Step: 4
Training loss: 2.3464572783636592
Validation loss: 2.846340789206568

Epoch: 6| Step: 5
Training loss: 2.8968998616786448
Validation loss: 2.8778649599455033

Epoch: 6| Step: 6
Training loss: 1.6842667723583995
Validation loss: 2.759339830031375

Epoch: 6| Step: 7
Training loss: 2.197147349247246
Validation loss: 2.723119076368519

Epoch: 6| Step: 8
Training loss: 2.3274636577387158
Validation loss: 2.8216547722251377

Epoch: 6| Step: 9
Training loss: 2.7060008544413026
Validation loss: 2.893856329541225

Epoch: 6| Step: 10
Training loss: 2.385091523467681
Validation loss: 2.8400765164914477

Epoch: 6| Step: 11
Training loss: 3.50846941601711
Validation loss: 2.859540619276843

Epoch: 6| Step: 12
Training loss: 2.500024890775748
Validation loss: 2.9198002613398244

Epoch: 6| Step: 13
Training loss: 2.316351080972456
Validation loss: 2.84493787391764

Epoch: 379| Step: 0
Training loss: 2.372318661576005
Validation loss: 2.865220903758526

Epoch: 6| Step: 1
Training loss: 2.372517342217657
Validation loss: 2.821337177448436

Epoch: 6| Step: 2
Training loss: 1.4281463654837716
Validation loss: 2.875021677171791

Epoch: 6| Step: 3
Training loss: 2.6488060258788173
Validation loss: 2.810990772457193

Epoch: 6| Step: 4
Training loss: 3.533648461258407
Validation loss: 2.8206901743958994

Epoch: 6| Step: 5
Training loss: 2.7615883889516692
Validation loss: 2.7873137111762163

Epoch: 6| Step: 6
Training loss: 2.7726415217253755
Validation loss: 2.78353276026155

Epoch: 6| Step: 7
Training loss: 2.5089938509680643
Validation loss: 2.9150157498595006

Epoch: 6| Step: 8
Training loss: 2.225430170544501
Validation loss: 2.873972692723849

Epoch: 6| Step: 9
Training loss: 2.9399446095549107
Validation loss: 2.7737197337209873

Epoch: 6| Step: 10
Training loss: 2.3553452593820623
Validation loss: 2.898367677473429

Epoch: 6| Step: 11
Training loss: 2.6426694280466894
Validation loss: 2.799405155486563

Epoch: 6| Step: 12
Training loss: 2.6022320593139345
Validation loss: 2.94050445196219

Epoch: 6| Step: 13
Training loss: 2.018464801117629
Validation loss: 2.7707259621280755

Epoch: 380| Step: 0
Training loss: 2.291973255340961
Validation loss: 2.885884208703946

Epoch: 6| Step: 1
Training loss: 2.078539240573358
Validation loss: 2.8429970161883125

Epoch: 6| Step: 2
Training loss: 2.653326961886681
Validation loss: 2.8517507524955543

Epoch: 6| Step: 3
Training loss: 3.0530098993944943
Validation loss: 2.7685825928490204

Epoch: 6| Step: 4
Training loss: 2.6674659445107283
Validation loss: 2.7454561363741434

Epoch: 6| Step: 5
Training loss: 3.6158666320613224
Validation loss: 2.729899126770749

Epoch: 6| Step: 6
Training loss: 2.2240732298808323
Validation loss: 2.769266232348571

Epoch: 6| Step: 7
Training loss: 2.381884785143838
Validation loss: 2.844470940938312

Epoch: 6| Step: 8
Training loss: 2.3270267225828642
Validation loss: 2.7752117272432923

Epoch: 6| Step: 9
Training loss: 3.158221242990702
Validation loss: 2.7634020131054324

Epoch: 6| Step: 10
Training loss: 2.0391648073217814
Validation loss: 2.741889127065598

Epoch: 6| Step: 11
Training loss: 2.569885960583238
Validation loss: 2.880600130219107

Epoch: 6| Step: 12
Training loss: 2.2636113129908253
Validation loss: 2.9065004916282637

Epoch: 6| Step: 13
Training loss: 2.180004903455347
Validation loss: 2.819715178299654

Epoch: 381| Step: 0
Training loss: 2.2583017842058584
Validation loss: 2.884598574519708

Epoch: 6| Step: 1
Training loss: 2.6189811367828173
Validation loss: 2.9392347604724547

Epoch: 6| Step: 2
Training loss: 3.0926172513945285
Validation loss: 2.7703791327885052

Epoch: 6| Step: 3
Training loss: 3.55261277236571
Validation loss: 2.7882219252425715

Epoch: 6| Step: 4
Training loss: 2.542326346499543
Validation loss: 2.7631210246044544

Epoch: 6| Step: 5
Training loss: 2.0459846715119867
Validation loss: 2.932562392397315

Epoch: 6| Step: 6
Training loss: 2.917495627902562
Validation loss: 2.978739979762016

Epoch: 6| Step: 7
Training loss: 2.555943171733548
Validation loss: 2.8159636040605633

Epoch: 6| Step: 8
Training loss: 2.3544161391505805
Validation loss: 2.9107206433923207

Epoch: 6| Step: 9
Training loss: 2.056929492860325
Validation loss: 2.7376616851966324

Epoch: 6| Step: 10
Training loss: 2.3385060965389433
Validation loss: 2.7948431399474027

Epoch: 6| Step: 11
Training loss: 2.1057367667351086
Validation loss: 2.7624960068983007

Epoch: 6| Step: 12
Training loss: 3.047612340669972
Validation loss: 2.9284742654082816

Epoch: 6| Step: 13
Training loss: 3.5009621251445693
Validation loss: 2.692213368141128

Epoch: 382| Step: 0
Training loss: 2.93730779790089
Validation loss: 2.8262354008120036

Epoch: 6| Step: 1
Training loss: 1.6266651425328436
Validation loss: 2.8825583899670724

Epoch: 6| Step: 2
Training loss: 2.772239662791679
Validation loss: 2.854076478983986

Epoch: 6| Step: 3
Training loss: 2.8566539720797004
Validation loss: 2.859158985700527

Epoch: 6| Step: 4
Training loss: 3.135089912159493
Validation loss: 2.881468923470056

Epoch: 6| Step: 5
Training loss: 2.6913028691649403
Validation loss: 2.8709403646577987

Epoch: 6| Step: 6
Training loss: 1.9764784240934639
Validation loss: 2.792451421911301

Epoch: 6| Step: 7
Training loss: 3.250813602432288
Validation loss: 2.811250509816861

Epoch: 6| Step: 8
Training loss: 1.6754749080335256
Validation loss: 2.8379908041960396

Epoch: 6| Step: 9
Training loss: 2.7547680527652654
Validation loss: 2.713101830350231

Epoch: 6| Step: 10
Training loss: 3.36807274743026
Validation loss: 2.7084902191789064

Epoch: 6| Step: 11
Training loss: 2.8077421847175152
Validation loss: 2.7389742310097445

Epoch: 6| Step: 12
Training loss: 2.498657247435337
Validation loss: 2.752722050670991

Epoch: 6| Step: 13
Training loss: 1.921232907101921
Validation loss: 2.6710148993158986

Epoch: 383| Step: 0
Training loss: 2.5269677001796964
Validation loss: 2.7813555467116715

Epoch: 6| Step: 1
Training loss: 2.57981567434075
Validation loss: 2.9372093739389786

Epoch: 6| Step: 2
Training loss: 2.7300805947001545
Validation loss: 2.7815111716757968

Epoch: 6| Step: 3
Training loss: 2.005408008756745
Validation loss: 2.7861135427984234

Epoch: 6| Step: 4
Training loss: 3.0571154533349785
Validation loss: 2.8963821598105524

Epoch: 6| Step: 5
Training loss: 1.8677297148054208
Validation loss: 2.828928476443923

Epoch: 6| Step: 6
Training loss: 2.7937913656905957
Validation loss: 2.9033339425027904

Epoch: 6| Step: 7
Training loss: 3.6868083757846515
Validation loss: 2.9679850501133487

Epoch: 6| Step: 8
Training loss: 3.337778624144931
Validation loss: 2.775013916459646

Epoch: 6| Step: 9
Training loss: 2.141275348858457
Validation loss: 2.740832778736604

Epoch: 6| Step: 10
Training loss: 2.4466352206434587
Validation loss: 2.8288364851367422

Epoch: 6| Step: 11
Training loss: 2.21908083316271
Validation loss: 2.770177175206404

Epoch: 6| Step: 12
Training loss: 1.8160754487081177
Validation loss: 2.8485154595829467

Epoch: 6| Step: 13
Training loss: 4.173139630495288
Validation loss: 2.9034131914541805

Epoch: 384| Step: 0
Training loss: 2.3411505971031956
Validation loss: 2.8029655558715754

Epoch: 6| Step: 1
Training loss: 2.0370729759526753
Validation loss: 2.9559280297529815

Epoch: 6| Step: 2
Training loss: 2.8444524882454516
Validation loss: 2.7388807880942125

Epoch: 6| Step: 3
Training loss: 2.834967160850472
Validation loss: 2.9637414189571865

Epoch: 6| Step: 4
Training loss: 2.3556929397805613
Validation loss: 2.8834756485913036

Epoch: 6| Step: 5
Training loss: 2.1236171710960003
Validation loss: 2.9413503809784904

Epoch: 6| Step: 6
Training loss: 2.483235607741869
Validation loss: 2.8619873944903382

Epoch: 6| Step: 7
Training loss: 2.722925246754685
Validation loss: 2.8204442834458194

Epoch: 6| Step: 8
Training loss: 2.736090596009707
Validation loss: 2.899697536725046

Epoch: 6| Step: 9
Training loss: 2.062429484693597
Validation loss: 2.910498587010304

Epoch: 6| Step: 10
Training loss: 2.453646076040162
Validation loss: 2.760790188563004

Epoch: 6| Step: 11
Training loss: 3.5029658966277437
Validation loss: 2.8562239793755584

Epoch: 6| Step: 12
Training loss: 3.37767205602711
Validation loss: 2.674849512419294

Epoch: 6| Step: 13
Training loss: 1.8795197371582864
Validation loss: 2.8279287836399503

Epoch: 385| Step: 0
Training loss: 2.4737848053691223
Validation loss: 2.724110488596425

Epoch: 6| Step: 1
Training loss: 2.758455369061063
Validation loss: 2.760351894839229

Epoch: 6| Step: 2
Training loss: 2.2778253847538346
Validation loss: 2.952450138383117

Epoch: 6| Step: 3
Training loss: 2.3938071819278317
Validation loss: 2.875224894269596

Epoch: 6| Step: 4
Training loss: 2.137210768377616
Validation loss: 2.7814960479207747

Epoch: 6| Step: 5
Training loss: 2.6275161310021975
Validation loss: 3.0001848114336034

Epoch: 6| Step: 6
Training loss: 3.4339709112749373
Validation loss: 2.794590495311476

Epoch: 6| Step: 7
Training loss: 2.14912664284724
Validation loss: 2.8844116286115375

Epoch: 6| Step: 8
Training loss: 3.098114326155458
Validation loss: 2.878817055240294

Epoch: 6| Step: 9
Training loss: 2.546630941293529
Validation loss: 2.9985905527253176

Epoch: 6| Step: 10
Training loss: 2.725568180169896
Validation loss: 2.8369973021483914

Epoch: 6| Step: 11
Training loss: 2.9075088235814697
Validation loss: 2.709664693092384

Epoch: 6| Step: 12
Training loss: 2.581765304004401
Validation loss: 2.756872581737732

Epoch: 6| Step: 13
Training loss: 2.8310053368089956
Validation loss: 2.8584643574261794

Epoch: 386| Step: 0
Training loss: 3.3785363496499135
Validation loss: 2.749608744758214

Epoch: 6| Step: 1
Training loss: 2.2473480702817317
Validation loss: 2.9230258533732307

Epoch: 6| Step: 2
Training loss: 2.1564457016744054
Validation loss: 2.72029730839981

Epoch: 6| Step: 3
Training loss: 2.401836757350499
Validation loss: 2.7956981565065804

Epoch: 6| Step: 4
Training loss: 2.071859221017168
Validation loss: 2.859739681438031

Epoch: 6| Step: 5
Training loss: 2.5566672956854664
Validation loss: 2.7801243291222466

Epoch: 6| Step: 6
Training loss: 2.0609224239373476
Validation loss: 2.787430284694164

Epoch: 6| Step: 7
Training loss: 2.1010431832147463
Validation loss: 2.9284223246154584

Epoch: 6| Step: 8
Training loss: 3.404050064113226
Validation loss: 2.872844440823883

Epoch: 6| Step: 9
Training loss: 2.4012236177979966
Validation loss: 2.9508183291704966

Epoch: 6| Step: 10
Training loss: 2.4407653455641602
Validation loss: 2.772219860956462

Epoch: 6| Step: 11
Training loss: 3.04978107854895
Validation loss: 2.838857309915667

Epoch: 6| Step: 12
Training loss: 2.5512003298778687
Validation loss: 2.9241173035565695

Epoch: 6| Step: 13
Training loss: 2.435405320227314
Validation loss: 2.979597748187421

Epoch: 387| Step: 0
Training loss: 3.120355588016613
Validation loss: 2.9166290269054906

Epoch: 6| Step: 1
Training loss: 2.781954558209107
Validation loss: 2.8635078560649725

Epoch: 6| Step: 2
Training loss: 2.3514884861042296
Validation loss: 2.8815999625082465

Epoch: 6| Step: 3
Training loss: 2.7920706632192216
Validation loss: 2.8198652169849545

Epoch: 6| Step: 4
Training loss: 2.710827476181643
Validation loss: 2.7339491983475273

Epoch: 6| Step: 5
Training loss: 2.5308391096266702
Validation loss: 2.6052888666485425

Epoch: 6| Step: 6
Training loss: 1.892930445832601
Validation loss: 2.8380324184714443

Epoch: 6| Step: 7
Training loss: 1.934338358838652
Validation loss: 2.7818873487369635

Epoch: 6| Step: 8
Training loss: 1.8624781511292523
Validation loss: 2.798011355074927

Epoch: 6| Step: 9
Training loss: 2.7085231616667333
Validation loss: 2.964464463324211

Epoch: 6| Step: 10
Training loss: 2.42608905995453
Validation loss: 2.72477108243258

Epoch: 6| Step: 11
Training loss: 2.1048478890231697
Validation loss: 2.7408477368287167

Epoch: 6| Step: 12
Training loss: 3.4589998146888616
Validation loss: 2.749761593460366

Epoch: 6| Step: 13
Training loss: 2.553266124023395
Validation loss: 2.727740832988368

Epoch: 388| Step: 0
Training loss: 2.078959820790773
Validation loss: 2.856301065523715

Epoch: 6| Step: 1
Training loss: 1.7262245641515264
Validation loss: 2.7171813792304746

Epoch: 6| Step: 2
Training loss: 2.690402216000854
Validation loss: 2.7713719307975246

Epoch: 6| Step: 3
Training loss: 2.0378787525336426
Validation loss: 2.9306174546813315

Epoch: 6| Step: 4
Training loss: 2.3919730779925312
Validation loss: 2.9169323450080724

Epoch: 6| Step: 5
Training loss: 2.9111134842951114
Validation loss: 2.773012103268691

Epoch: 6| Step: 6
Training loss: 3.710172361498367
Validation loss: 2.955146168640855

Epoch: 6| Step: 7
Training loss: 2.4072128945479117
Validation loss: 2.8541997873641907

Epoch: 6| Step: 8
Training loss: 2.4817004892654575
Validation loss: 2.6935376497040786

Epoch: 6| Step: 9
Training loss: 2.4892521615336505
Validation loss: 2.794389395809465

Epoch: 6| Step: 10
Training loss: 1.7522833777617777
Validation loss: 2.9599233885249965

Epoch: 6| Step: 11
Training loss: 2.599553612756564
Validation loss: 2.6777256225108768

Epoch: 6| Step: 12
Training loss: 1.8635136681278832
Validation loss: 2.9563479988321077

Epoch: 6| Step: 13
Training loss: 3.294428057430597
Validation loss: 2.8742518135832875

Epoch: 389| Step: 0
Training loss: 1.9997527446496697
Validation loss: 2.6745540867492776

Epoch: 6| Step: 1
Training loss: 2.304361404366423
Validation loss: 2.7966363561803638

Epoch: 6| Step: 2
Training loss: 2.6263578626805164
Validation loss: 2.839313172757284

Epoch: 6| Step: 3
Training loss: 3.329107148581776
Validation loss: 2.8056343320634802

Epoch: 6| Step: 4
Training loss: 2.13794624176812
Validation loss: 2.74804221051841

Epoch: 6| Step: 5
Training loss: 2.6168807575899558
Validation loss: 2.7243378457058527

Epoch: 6| Step: 6
Training loss: 3.1649843733222482
Validation loss: 2.7388586745890247

Epoch: 6| Step: 7
Training loss: 2.299792039840488
Validation loss: 2.772928220562221

Epoch: 6| Step: 8
Training loss: 2.865182783810407
Validation loss: 2.903048507912115

Epoch: 6| Step: 9
Training loss: 3.028039707049474
Validation loss: 2.869406462323167

Epoch: 6| Step: 10
Training loss: 1.7713931227358537
Validation loss: 2.891614478191378

Epoch: 6| Step: 11
Training loss: 2.23565946352456
Validation loss: 2.7566412060187733

Epoch: 6| Step: 12
Training loss: 2.4570687053111944
Validation loss: 2.9144516498951676

Epoch: 6| Step: 13
Training loss: 2.96088757636425
Validation loss: 2.8312626811846884

Epoch: 390| Step: 0
Training loss: 2.0625063578189766
Validation loss: 2.741199264034777

Epoch: 6| Step: 1
Training loss: 2.36436268677456
Validation loss: 2.7754838039683576

Epoch: 6| Step: 2
Training loss: 3.1306650312030597
Validation loss: 2.8986895476255707

Epoch: 6| Step: 3
Training loss: 2.2217264761556663
Validation loss: 2.8701791002451764

Epoch: 6| Step: 4
Training loss: 2.6879944457382763
Validation loss: 2.8470450226028423

Epoch: 6| Step: 5
Training loss: 2.171274664809578
Validation loss: 2.93696018862848

Epoch: 6| Step: 6
Training loss: 2.5599676505667492
Validation loss: 2.8371464774933908

Epoch: 6| Step: 7
Training loss: 2.8358065151934766
Validation loss: 2.7476425124696684

Epoch: 6| Step: 8
Training loss: 2.3293970716294106
Validation loss: 2.832808340669456

Epoch: 6| Step: 9
Training loss: 2.3269012102141224
Validation loss: 2.8309031680566994

Epoch: 6| Step: 10
Training loss: 3.081306788170751
Validation loss: 2.6782405824740256

Epoch: 6| Step: 11
Training loss: 2.544505509037554
Validation loss: 2.7864251983638275

Epoch: 6| Step: 12
Training loss: 2.515706031394619
Validation loss: 2.820529795183326

Epoch: 6| Step: 13
Training loss: 2.195396448885609
Validation loss: 2.8336693934200876

Epoch: 391| Step: 0
Training loss: 2.735465132164607
Validation loss: 2.7525788611228514

Epoch: 6| Step: 1
Training loss: 2.230479652925957
Validation loss: 2.8833737448822276

Epoch: 6| Step: 2
Training loss: 2.1381186409872144
Validation loss: 2.8328508048228587

Epoch: 6| Step: 3
Training loss: 2.4097370790969617
Validation loss: 2.762894610219662

Epoch: 6| Step: 4
Training loss: 2.5883003802964173
Validation loss: 2.891623083300798

Epoch: 6| Step: 5
Training loss: 2.278829466186953
Validation loss: 2.6291717481533987

Epoch: 6| Step: 6
Training loss: 3.026185356751223
Validation loss: 2.741289579185626

Epoch: 6| Step: 7
Training loss: 2.475360951931292
Validation loss: 2.656977477277321

Epoch: 6| Step: 8
Training loss: 2.49941008283485
Validation loss: 2.826115683690723

Epoch: 6| Step: 9
Training loss: 2.521374027074428
Validation loss: 2.8068101834442625

Epoch: 6| Step: 10
Training loss: 2.7596355172687907
Validation loss: 2.8427917441777844

Epoch: 6| Step: 11
Training loss: 2.085587947288837
Validation loss: 2.6571342246388236

Epoch: 6| Step: 12
Training loss: 2.1427034186673275
Validation loss: 2.703703597942795

Epoch: 6| Step: 13
Training loss: 2.7380077535660208
Validation loss: 2.870721627070219

Epoch: 392| Step: 0
Training loss: 2.238404701649798
Validation loss: 2.850877104934373

Epoch: 6| Step: 1
Training loss: 2.3873328185341474
Validation loss: 2.915224134047884

Epoch: 6| Step: 2
Training loss: 1.8945403108675078
Validation loss: 2.821108616183315

Epoch: 6| Step: 3
Training loss: 3.7440480363568205
Validation loss: 2.8591713109081827

Epoch: 6| Step: 4
Training loss: 2.115320712904978
Validation loss: 2.8988886983590842

Epoch: 6| Step: 5
Training loss: 2.06916195550762
Validation loss: 2.8772448549498515

Epoch: 6| Step: 6
Training loss: 2.686943351406842
Validation loss: 2.8488277819247525

Epoch: 6| Step: 7
Training loss: 1.7008987014721593
Validation loss: 3.006660555133084

Epoch: 6| Step: 8
Training loss: 2.0741595530997823
Validation loss: 2.83717838156156

Epoch: 6| Step: 9
Training loss: 3.2717884070479197
Validation loss: 2.839641470350804

Epoch: 6| Step: 10
Training loss: 2.3369838450717766
Validation loss: 2.76683452546457

Epoch: 6| Step: 11
Training loss: 2.684331312257044
Validation loss: 2.8694646407167586

Epoch: 6| Step: 12
Training loss: 2.039456968773312
Validation loss: 2.767876255405491

Epoch: 6| Step: 13
Training loss: 2.297132205186072
Validation loss: 2.82523372880048

Epoch: 393| Step: 0
Training loss: 3.1140644232346357
Validation loss: 2.77855492525501

Epoch: 6| Step: 1
Training loss: 2.4728189086445354
Validation loss: 2.6852452510770735

Epoch: 6| Step: 2
Training loss: 1.982938351556346
Validation loss: 2.9079448769554546

Epoch: 6| Step: 3
Training loss: 2.344070921225322
Validation loss: 2.736904120114737

Epoch: 6| Step: 4
Training loss: 2.8129434871699286
Validation loss: 2.8408725103594272

Epoch: 6| Step: 5
Training loss: 2.1364627663876203
Validation loss: 2.68038263545464

Epoch: 6| Step: 6
Training loss: 3.138568869362196
Validation loss: 2.770003771404896

Epoch: 6| Step: 7
Training loss: 2.4527053960092795
Validation loss: 2.7086926741707393

Epoch: 6| Step: 8
Training loss: 2.5868383031446345
Validation loss: 2.9212127684381834

Epoch: 6| Step: 9
Training loss: 2.771233599058906
Validation loss: 2.8959140307470794

Epoch: 6| Step: 10
Training loss: 2.4254148148153507
Validation loss: 2.7354229865689095

Epoch: 6| Step: 11
Training loss: 2.547871213451911
Validation loss: 2.991818625735235

Epoch: 6| Step: 12
Training loss: 2.4709208155085975
Validation loss: 2.820768133459245

Epoch: 6| Step: 13
Training loss: 2.558572690454838
Validation loss: 2.822457126780218

Epoch: 394| Step: 0
Training loss: 1.7531855064463167
Validation loss: 2.8657862924966

Epoch: 6| Step: 1
Training loss: 3.1345470316600714
Validation loss: 2.867354533072981

Epoch: 6| Step: 2
Training loss: 2.741086385552101
Validation loss: 2.8371045520313034

Epoch: 6| Step: 3
Training loss: 1.8405430592560077
Validation loss: 2.7236163818542423

Epoch: 6| Step: 4
Training loss: 1.8327081076575003
Validation loss: 2.909264332295208

Epoch: 6| Step: 5
Training loss: 2.2162665854584875
Validation loss: 2.627578042667774

Epoch: 6| Step: 6
Training loss: 3.5028037693862
Validation loss: 2.98530510087249

Epoch: 6| Step: 7
Training loss: 2.9054157331224375
Validation loss: 2.801756692525693

Epoch: 6| Step: 8
Training loss: 2.9560135535108834
Validation loss: 2.691496888209787

Epoch: 6| Step: 9
Training loss: 2.209160080186064
Validation loss: 2.8626487277381836

Epoch: 6| Step: 10
Training loss: 3.0436395143356085
Validation loss: 2.8614857113777052

Epoch: 6| Step: 11
Training loss: 2.1410163465977847
Validation loss: 2.749881285028208

Epoch: 6| Step: 12
Training loss: 1.930418918387916
Validation loss: 2.844618432901736

Epoch: 6| Step: 13
Training loss: 3.2550540653549502
Validation loss: 2.766809907559004

Epoch: 395| Step: 0
Training loss: 3.0483166536264514
Validation loss: 2.661513029122899

Epoch: 6| Step: 1
Training loss: 3.2466300218408413
Validation loss: 2.8209409740981526

Epoch: 6| Step: 2
Training loss: 2.5371383183732057
Validation loss: 2.710234510660289

Epoch: 6| Step: 3
Training loss: 1.8302289804919807
Validation loss: 2.787923238540065

Epoch: 6| Step: 4
Training loss: 2.3487992891882254
Validation loss: 2.717431083369317

Epoch: 6| Step: 5
Training loss: 2.5197186067693758
Validation loss: 2.702824718349312

Epoch: 6| Step: 6
Training loss: 2.3131809778456787
Validation loss: 2.9345818684580944

Epoch: 6| Step: 7
Training loss: 2.9891699173924433
Validation loss: 2.6125970667670977

Epoch: 6| Step: 8
Training loss: 2.3072290921534426
Validation loss: 2.734421109749775

Epoch: 6| Step: 9
Training loss: 2.625440106509507
Validation loss: 2.803925975409402

Epoch: 6| Step: 10
Training loss: 2.586992768774849
Validation loss: 2.9745975173355004

Epoch: 6| Step: 11
Training loss: 2.0784186822558155
Validation loss: 2.842497160086863

Epoch: 6| Step: 12
Training loss: 2.769579199630096
Validation loss: 2.8617648354101033

Epoch: 6| Step: 13
Training loss: 3.217986970105769
Validation loss: 2.7997097229318393

Epoch: 396| Step: 0
Training loss: 2.616630107680939
Validation loss: 2.846478564607796

Epoch: 6| Step: 1
Training loss: 2.6945913925825073
Validation loss: 2.7541434618808056

Epoch: 6| Step: 2
Training loss: 1.8271889531726908
Validation loss: 2.855630521845105

Epoch: 6| Step: 3
Training loss: 2.391201872194233
Validation loss: 2.7905108903518916

Epoch: 6| Step: 4
Training loss: 1.7427828331813437
Validation loss: 2.7552823734591625

Epoch: 6| Step: 5
Training loss: 2.468574421107532
Validation loss: 2.892643113574427

Epoch: 6| Step: 6
Training loss: 2.3635465614892457
Validation loss: 2.8175487719165946

Epoch: 6| Step: 7
Training loss: 2.251547281397811
Validation loss: 2.8226961224456466

Epoch: 6| Step: 8
Training loss: 1.9654103973118313
Validation loss: 2.819268156065645

Epoch: 6| Step: 9
Training loss: 2.823077677021234
Validation loss: 2.7502217049597952

Epoch: 6| Step: 10
Training loss: 2.98044379187617
Validation loss: 2.7783371725788575

Epoch: 6| Step: 11
Training loss: 3.904852044774187
Validation loss: 2.865087610570379

Epoch: 6| Step: 12
Training loss: 2.299911464148114
Validation loss: 2.8941745408452304

Epoch: 6| Step: 13
Training loss: 3.15335932636906
Validation loss: 2.831743487998937

Epoch: 397| Step: 0
Training loss: 2.364917737082566
Validation loss: 2.823958013030863

Epoch: 6| Step: 1
Training loss: 2.177559309281994
Validation loss: 2.7851413411780945

Epoch: 6| Step: 2
Training loss: 3.152077513540425
Validation loss: 2.884889660188937

Epoch: 6| Step: 3
Training loss: 3.7698703751679377
Validation loss: 2.8766758062084183

Epoch: 6| Step: 4
Training loss: 3.4562223188454118
Validation loss: 2.784528592915066

Epoch: 6| Step: 5
Training loss: 2.2558409851117305
Validation loss: 2.865279260189813

Epoch: 6| Step: 6
Training loss: 2.2972837330974167
Validation loss: 2.77411944774967

Epoch: 6| Step: 7
Training loss: 2.6502819559059714
Validation loss: 2.840337899399284

Epoch: 6| Step: 8
Training loss: 2.5622405874552316
Validation loss: 2.9047124021325077

Epoch: 6| Step: 9
Training loss: 1.5685933129835998
Validation loss: 2.876412193297801

Epoch: 6| Step: 10
Training loss: 2.8914107620793623
Validation loss: 2.8281665500490982

Epoch: 6| Step: 11
Training loss: 2.1674537940638676
Validation loss: 2.758645313847299

Epoch: 6| Step: 12
Training loss: 1.8635014497850089
Validation loss: 2.73013941896129

Epoch: 6| Step: 13
Training loss: 2.760933296273814
Validation loss: 2.5696607962215796

Epoch: 398| Step: 0
Training loss: 2.7285877128149387
Validation loss: 2.8748250768092514

Epoch: 6| Step: 1
Training loss: 2.493887103525706
Validation loss: 2.798506133193952

Epoch: 6| Step: 2
Training loss: 2.5089876742981967
Validation loss: 2.9187787334150945

Epoch: 6| Step: 3
Training loss: 2.1494891557830336
Validation loss: 2.843657922904952

Epoch: 6| Step: 4
Training loss: 2.4054075475515817
Validation loss: 2.938362834426514

Epoch: 6| Step: 5
Training loss: 1.8120471783321386
Validation loss: 2.7430803754652926

Epoch: 6| Step: 6
Training loss: 1.805757147791623
Validation loss: 2.7944747479898107

Epoch: 6| Step: 7
Training loss: 2.647095646944913
Validation loss: 2.8502403188899588

Epoch: 6| Step: 8
Training loss: 2.67750055250773
Validation loss: 2.725239039587607

Epoch: 6| Step: 9
Training loss: 1.9779113268440298
Validation loss: 2.839461384064857

Epoch: 6| Step: 10
Training loss: 3.2854356499516384
Validation loss: 2.741571916886093

Epoch: 6| Step: 11
Training loss: 3.009171136940617
Validation loss: 2.726470998384058

Epoch: 6| Step: 12
Training loss: 2.5766181009838984
Validation loss: 2.7449165868896395

Epoch: 6| Step: 13
Training loss: 2.849167411055072
Validation loss: 2.866072507750982

Epoch: 399| Step: 0
Training loss: 1.896352808559916
Validation loss: 2.8437919221456665

Epoch: 6| Step: 1
Training loss: 2.2826097172484077
Validation loss: 2.8721013475130643

Epoch: 6| Step: 2
Training loss: 3.4034983868853605
Validation loss: 2.7258582942440506

Epoch: 6| Step: 3
Training loss: 2.7167982791153813
Validation loss: 2.7286434960609203

Epoch: 6| Step: 4
Training loss: 2.351021840748978
Validation loss: 2.886997537195807

Epoch: 6| Step: 5
Training loss: 1.9729015839861894
Validation loss: 2.8410384547741

Epoch: 6| Step: 6
Training loss: 2.7694425797357876
Validation loss: 2.793733545815427

Epoch: 6| Step: 7
Training loss: 2.851302294420906
Validation loss: 2.8301393981857585

Epoch: 6| Step: 8
Training loss: 2.6233577132233266
Validation loss: 2.760542874151157

Epoch: 6| Step: 9
Training loss: 2.0740782839237863
Validation loss: 2.732657172995047

Epoch: 6| Step: 10
Training loss: 2.5669547645913537
Validation loss: 2.9376067572197813

Epoch: 6| Step: 11
Training loss: 2.2388274107328656
Validation loss: 2.6134868271006075

Epoch: 6| Step: 12
Training loss: 2.402337001387879
Validation loss: 2.76698143520453

Epoch: 6| Step: 13
Training loss: 2.0590164358660434
Validation loss: 2.9873767066873733

Epoch: 400| Step: 0
Training loss: 1.8380422661355833
Validation loss: 2.5447452835118556

Epoch: 6| Step: 1
Training loss: 2.303693447070897
Validation loss: 2.74684228204355

Epoch: 6| Step: 2
Training loss: 2.531130469996804
Validation loss: 2.913755245891263

Epoch: 6| Step: 3
Training loss: 2.2505280616771888
Validation loss: 2.85540028293002

Epoch: 6| Step: 4
Training loss: 2.003127751817167
Validation loss: 2.898642923615631

Epoch: 6| Step: 5
Training loss: 2.7176439512811568
Validation loss: 2.6917264033451476

Epoch: 6| Step: 6
Training loss: 3.1789393939120663
Validation loss: 2.7456082040962055

Epoch: 6| Step: 7
Training loss: 2.3430365938983284
Validation loss: 2.7895704026231822

Epoch: 6| Step: 8
Training loss: 2.7424840522239835
Validation loss: 2.726898626779779

Epoch: 6| Step: 9
Training loss: 2.821504378033327
Validation loss: 2.8117685647567394

Epoch: 6| Step: 10
Training loss: 2.2752222350848847
Validation loss: 2.8345888301029745

Epoch: 6| Step: 11
Training loss: 2.574368601302761
Validation loss: 2.690161669747442

Epoch: 6| Step: 12
Training loss: 1.9963672547608438
Validation loss: 2.8384425359423515

Epoch: 6| Step: 13
Training loss: 2.755671980750017
Validation loss: 2.7346110430442803

Epoch: 401| Step: 0
Training loss: 2.0889191195259675
Validation loss: 2.7644576198685873

Epoch: 6| Step: 1
Training loss: 3.009732671380272
Validation loss: 2.825836131990101

Epoch: 6| Step: 2
Training loss: 1.9715333669858779
Validation loss: 2.9092344436361492

Epoch: 6| Step: 3
Training loss: 3.2678658859767284
Validation loss: 2.739066210649258

Epoch: 6| Step: 4
Training loss: 2.5943320666836196
Validation loss: 2.8461759510886995

Epoch: 6| Step: 5
Training loss: 2.0666237267781176
Validation loss: 2.6766561540270946

Epoch: 6| Step: 6
Training loss: 3.3662590995067814
Validation loss: 2.7497445959290836

Epoch: 6| Step: 7
Training loss: 3.240595047314791
Validation loss: 2.7160683007336903

Epoch: 6| Step: 8
Training loss: 2.053788253047157
Validation loss: 2.8354773450231274

Epoch: 6| Step: 9
Training loss: 2.210138506799581
Validation loss: 2.8161342425154223

Epoch: 6| Step: 10
Training loss: 3.0207807514393696
Validation loss: 2.7709356892478065

Epoch: 6| Step: 11
Training loss: 2.392029493060779
Validation loss: 2.8209291180095915

Epoch: 6| Step: 12
Training loss: 1.765464978013591
Validation loss: 2.859991077059517

Epoch: 6| Step: 13
Training loss: 2.92203949653935
Validation loss: 2.7605533323782687

Epoch: 402| Step: 0
Training loss: 2.6557112203469084
Validation loss: 2.886780462990625

Epoch: 6| Step: 1
Training loss: 3.152078875034068
Validation loss: 2.833883879579483

Epoch: 6| Step: 2
Training loss: 2.9462121859273536
Validation loss: 2.7933666145219114

Epoch: 6| Step: 3
Training loss: 1.9951915157624123
Validation loss: 2.624273640133793

Epoch: 6| Step: 4
Training loss: 2.2285293190858835
Validation loss: 2.7863867162349263

Epoch: 6| Step: 5
Training loss: 2.580266814223011
Validation loss: 2.698875444710914

Epoch: 6| Step: 6
Training loss: 2.3687310049457926
Validation loss: 2.7667911926525197

Epoch: 6| Step: 7
Training loss: 2.118043283173352
Validation loss: 2.8514201116474704

Epoch: 6| Step: 8
Training loss: 2.3414899992451264
Validation loss: 2.8320184613293757

Epoch: 6| Step: 9
Training loss: 3.3085052586491064
Validation loss: 2.8142596702489304

Epoch: 6| Step: 10
Training loss: 2.819915659028767
Validation loss: 2.7111091045250277

Epoch: 6| Step: 11
Training loss: 2.0877524491666786
Validation loss: 2.7861796961523786

Epoch: 6| Step: 12
Training loss: 2.2950956757658685
Validation loss: 2.9469000707350306

Epoch: 6| Step: 13
Training loss: 1.3548405315548795
Validation loss: 2.864332819898365

Epoch: 403| Step: 0
Training loss: 2.257895920212274
Validation loss: 2.7840783777437585

Epoch: 6| Step: 1
Training loss: 2.0391252880733455
Validation loss: 2.727432003735259

Epoch: 6| Step: 2
Training loss: 3.0719089385881118
Validation loss: 2.755288533468031

Epoch: 6| Step: 3
Training loss: 3.0113211640230384
Validation loss: 2.6714468042402024

Epoch: 6| Step: 4
Training loss: 2.1703874721993723
Validation loss: 2.8420417917193626

Epoch: 6| Step: 5
Training loss: 2.1177347186900244
Validation loss: 2.746974017633851

Epoch: 6| Step: 6
Training loss: 2.4690962922796906
Validation loss: 2.7477396534643095

Epoch: 6| Step: 7
Training loss: 1.7121157138436445
Validation loss: 2.746980665235916

Epoch: 6| Step: 8
Training loss: 2.5608649270909796
Validation loss: 2.8206249776718204

Epoch: 6| Step: 9
Training loss: 2.567495176019195
Validation loss: 2.9114560521600583

Epoch: 6| Step: 10
Training loss: 2.772867493416763
Validation loss: 2.7349517982705978

Epoch: 6| Step: 11
Training loss: 2.6193185812668296
Validation loss: 2.6928033492830474

Epoch: 6| Step: 12
Training loss: 3.029120100066592
Validation loss: 2.6152138029340715

Epoch: 6| Step: 13
Training loss: 2.3883033399524294
Validation loss: 2.81109056238965

Epoch: 404| Step: 0
Training loss: 2.8544424067674314
Validation loss: 2.826417574240129

Epoch: 6| Step: 1
Training loss: 2.520326190303506
Validation loss: 2.9531037103662836

Epoch: 6| Step: 2
Training loss: 2.613193664451544
Validation loss: 2.9011056043562093

Epoch: 6| Step: 3
Training loss: 1.9938646624368108
Validation loss: 2.761630478707371

Epoch: 6| Step: 4
Training loss: 2.5779696331026125
Validation loss: 2.875106065888211

Epoch: 6| Step: 5
Training loss: 2.699978446874424
Validation loss: 2.8967173426538704

Epoch: 6| Step: 6
Training loss: 3.2661552911247482
Validation loss: 2.8689828729056783

Epoch: 6| Step: 7
Training loss: 1.925608783914891
Validation loss: 2.840587238735981

Epoch: 6| Step: 8
Training loss: 2.3353713762540758
Validation loss: 2.7011006016023704

Epoch: 6| Step: 9
Training loss: 3.087541921230616
Validation loss: 2.759703642099295

Epoch: 6| Step: 10
Training loss: 1.2831120335313502
Validation loss: 2.9080022548047233

Epoch: 6| Step: 11
Training loss: 2.19755900819123
Validation loss: 2.6782212649345234

Epoch: 6| Step: 12
Training loss: 2.538632306554953
Validation loss: 2.9054063526722382

Epoch: 6| Step: 13
Training loss: 0.8285446183501619
Validation loss: 2.6381591139325784

Epoch: 405| Step: 0
Training loss: 2.681404831335029
Validation loss: 2.7994980072204045

Epoch: 6| Step: 1
Training loss: 2.4404793162220644
Validation loss: 2.8319662084525725

Epoch: 6| Step: 2
Training loss: 1.8025871043117394
Validation loss: 2.731622312730602

Epoch: 6| Step: 3
Training loss: 2.247845041608786
Validation loss: 2.8070386623088126

Epoch: 6| Step: 4
Training loss: 2.141253079903743
Validation loss: 2.846664719950415

Epoch: 6| Step: 5
Training loss: 2.8494283136231973
Validation loss: 2.6679635015806085

Epoch: 6| Step: 6
Training loss: 2.1767609888449795
Validation loss: 2.74896513670297

Epoch: 6| Step: 7
Training loss: 2.845912739738271
Validation loss: 2.805234445030799

Epoch: 6| Step: 8
Training loss: 2.689370147821268
Validation loss: 2.744329760435913

Epoch: 6| Step: 9
Training loss: 2.161180911970383
Validation loss: 2.7963281086356973

Epoch: 6| Step: 10
Training loss: 3.1162377155794774
Validation loss: 2.9144084984206717

Epoch: 6| Step: 11
Training loss: 2.8075936649829845
Validation loss: 2.668109442611908

Epoch: 6| Step: 12
Training loss: 2.4271694271769855
Validation loss: 2.697926603517435

Epoch: 6| Step: 13
Training loss: 3.2162937310481894
Validation loss: 2.662802362862544

Epoch: 406| Step: 0
Training loss: 2.2755320754719026
Validation loss: 2.802420412932307

Epoch: 6| Step: 1
Training loss: 2.4775509952412675
Validation loss: 2.677553811541404

Epoch: 6| Step: 2
Training loss: 2.4929596951283477
Validation loss: 2.9677930341978835

Epoch: 6| Step: 3
Training loss: 2.0102272800982894
Validation loss: 2.704983244836025

Epoch: 6| Step: 4
Training loss: 2.609768683607744
Validation loss: 2.873680660922819

Epoch: 6| Step: 5
Training loss: 2.117899982457472
Validation loss: 2.911059262834917

Epoch: 6| Step: 6
Training loss: 3.228874062027669
Validation loss: 2.96803147019138

Epoch: 6| Step: 7
Training loss: 3.0443485055395927
Validation loss: 2.88295746574494

Epoch: 6| Step: 8
Training loss: 2.0005387534249564
Validation loss: 2.957271890435035

Epoch: 6| Step: 9
Training loss: 2.5010615955868487
Validation loss: 2.980308754961645

Epoch: 6| Step: 10
Training loss: 2.0227933469584856
Validation loss: 2.843048981115298

Epoch: 6| Step: 11
Training loss: 3.0351196443959734
Validation loss: 2.9435006150569123

Epoch: 6| Step: 12
Training loss: 2.217931247137478
Validation loss: 2.78658658087977

Epoch: 6| Step: 13
Training loss: 3.284588087666344
Validation loss: 2.814815700927316

Epoch: 407| Step: 0
Training loss: 2.0456781746736064
Validation loss: 2.932094360933864

Epoch: 6| Step: 1
Training loss: 2.0898393007035
Validation loss: 2.882165680124606

Epoch: 6| Step: 2
Training loss: 2.029167163804429
Validation loss: 2.8165491869531007

Epoch: 6| Step: 3
Training loss: 3.085566013043573
Validation loss: 2.7656621673832187

Epoch: 6| Step: 4
Training loss: 2.5419565462829845
Validation loss: 2.7390245687925945

Epoch: 6| Step: 5
Training loss: 2.660335854000224
Validation loss: 2.8353017882483234

Epoch: 6| Step: 6
Training loss: 2.1784527744080036
Validation loss: 2.738344712982111

Epoch: 6| Step: 7
Training loss: 3.1018725799913898
Validation loss: 2.6777749499097543

Epoch: 6| Step: 8
Training loss: 2.3857935534150063
Validation loss: 2.7703364800582704

Epoch: 6| Step: 9
Training loss: 1.7302821900529275
Validation loss: 2.855673064077577

Epoch: 6| Step: 10
Training loss: 3.1853102099682578
Validation loss: 2.778802805089364

Epoch: 6| Step: 11
Training loss: 1.883335215080919
Validation loss: 2.7939630031952154

Epoch: 6| Step: 12
Training loss: 2.9447804585151234
Validation loss: 2.8943897691172995

Epoch: 6| Step: 13
Training loss: 2.4701855505620065
Validation loss: 2.897294918074261

Epoch: 408| Step: 0
Training loss: 2.0243754330311026
Validation loss: 2.7441136248740463

Epoch: 6| Step: 1
Training loss: 3.1374399916544875
Validation loss: 2.6822848256102856

Epoch: 6| Step: 2
Training loss: 2.8926763730360667
Validation loss: 2.900293143890838

Epoch: 6| Step: 3
Training loss: 2.3926795657704703
Validation loss: 2.8415473702443066

Epoch: 6| Step: 4
Training loss: 2.6210249822154426
Validation loss: 2.644606754493038

Epoch: 6| Step: 5
Training loss: 2.9134694331987756
Validation loss: 2.83029148568539

Epoch: 6| Step: 6
Training loss: 1.710295325872064
Validation loss: 2.7650729421466997

Epoch: 6| Step: 7
Training loss: 2.066625457270777
Validation loss: 2.7353007981588475

Epoch: 6| Step: 8
Training loss: 2.695958156928837
Validation loss: 2.956989387463728

Epoch: 6| Step: 9
Training loss: 2.5713055672063345
Validation loss: 2.9130755406544675

Epoch: 6| Step: 10
Training loss: 2.6628856576630087
Validation loss: 2.9425952944478015

Epoch: 6| Step: 11
Training loss: 1.6511008636098992
Validation loss: 2.7112221871705198

Epoch: 6| Step: 12
Training loss: 3.037802937789542
Validation loss: 2.949366136462089

Epoch: 6| Step: 13
Training loss: 2.466825096953564
Validation loss: 2.829273248896677

Epoch: 409| Step: 0
Training loss: 2.2542313947803536
Validation loss: 2.8260304861188232

Epoch: 6| Step: 1
Training loss: 2.3572141339313166
Validation loss: 2.8310829529657577

Epoch: 6| Step: 2
Training loss: 2.303641078483222
Validation loss: 2.7356532911610123

Epoch: 6| Step: 3
Training loss: 2.194974282707113
Validation loss: 2.8171937795026274

Epoch: 6| Step: 4
Training loss: 2.052982914158127
Validation loss: 2.7123755895880635

Epoch: 6| Step: 5
Training loss: 2.5216547570847645
Validation loss: 2.8019658106848837

Epoch: 6| Step: 6
Training loss: 2.413603408763528
Validation loss: 2.727585291570677

Epoch: 6| Step: 7
Training loss: 2.1983122507298605
Validation loss: 2.8300244290251095

Epoch: 6| Step: 8
Training loss: 3.1675304104881437
Validation loss: 2.9265292501591142

Epoch: 6| Step: 9
Training loss: 1.8071306873344708
Validation loss: 2.742727541484812

Epoch: 6| Step: 10
Training loss: 2.8638820460233965
Validation loss: 2.807334668683621

Epoch: 6| Step: 11
Training loss: 2.5038205517462067
Validation loss: 2.8256776851878627

Epoch: 6| Step: 12
Training loss: 1.9966127799547446
Validation loss: 2.9135920299787683

Epoch: 6| Step: 13
Training loss: 4.00650306414191
Validation loss: 2.8267569366336796

Epoch: 410| Step: 0
Training loss: 3.4245952784745377
Validation loss: 2.6611712793627755

Epoch: 6| Step: 1
Training loss: 2.733354825036139
Validation loss: 2.779169364178

Epoch: 6| Step: 2
Training loss: 3.3469666312645456
Validation loss: 2.7248825076889127

Epoch: 6| Step: 3
Training loss: 2.5674190293779686
Validation loss: 2.9870960450076853

Epoch: 6| Step: 4
Training loss: 2.6634102747294537
Validation loss: 2.7183325190854855

Epoch: 6| Step: 5
Training loss: 2.7842971739504843
Validation loss: 2.806670297279764

Epoch: 6| Step: 6
Training loss: 2.1814221551939785
Validation loss: 2.898142688722388

Epoch: 6| Step: 7
Training loss: 1.807496432120151
Validation loss: 2.780288805801478

Epoch: 6| Step: 8
Training loss: 1.960528205620041
Validation loss: 2.771639486823645

Epoch: 6| Step: 9
Training loss: 2.175346399543717
Validation loss: 2.9512824600850966

Epoch: 6| Step: 10
Training loss: 2.1230648429552446
Validation loss: 2.762394244351911

Epoch: 6| Step: 11
Training loss: 2.5329902224165632
Validation loss: 2.8279322466342407

Epoch: 6| Step: 12
Training loss: 2.011186073667128
Validation loss: 2.7537564419229907

Epoch: 6| Step: 13
Training loss: 2.944466142954338
Validation loss: 2.736083551844161

Epoch: 411| Step: 0
Training loss: 2.1788223354393033
Validation loss: 2.8947175118113035

Epoch: 6| Step: 1
Training loss: 1.7020533978908683
Validation loss: 2.80388906014383

Epoch: 6| Step: 2
Training loss: 2.262847355264769
Validation loss: 2.7838715469927635

Epoch: 6| Step: 3
Training loss: 3.7358307494926724
Validation loss: 2.7789149038709544

Epoch: 6| Step: 4
Training loss: 2.629704755158685
Validation loss: 2.669571099169098

Epoch: 6| Step: 5
Training loss: 2.6840308220766436
Validation loss: 2.888312985671322

Epoch: 6| Step: 6
Training loss: 2.102456735716938
Validation loss: 2.7564466728325985

Epoch: 6| Step: 7
Training loss: 2.2971904304495046
Validation loss: 2.7809373754321025

Epoch: 6| Step: 8
Training loss: 2.2849563380771514
Validation loss: 2.7393270889187016

Epoch: 6| Step: 9
Training loss: 2.5683898227757953
Validation loss: 2.7353755422409174

Epoch: 6| Step: 10
Training loss: 2.301377224117234
Validation loss: 2.7876538363025665

Epoch: 6| Step: 11
Training loss: 2.503969093522018
Validation loss: 2.827449697336809

Epoch: 6| Step: 12
Training loss: 2.420455024123297
Validation loss: 2.8190992841752402

Epoch: 6| Step: 13
Training loss: 2.229626712090738
Validation loss: 2.7069085419225383

Epoch: 412| Step: 0
Training loss: 1.8487337934236323
Validation loss: 2.9092399890727427

Epoch: 6| Step: 1
Training loss: 2.290467856144355
Validation loss: 2.7492283384486034

Epoch: 6| Step: 2
Training loss: 2.337340989033764
Validation loss: 2.564803081203255

Epoch: 6| Step: 3
Training loss: 2.3744814457219667
Validation loss: 2.8976397230020456

Epoch: 6| Step: 4
Training loss: 2.114717288229555
Validation loss: 2.7964028588799232

Epoch: 6| Step: 5
Training loss: 2.010321448513889
Validation loss: 2.71830597465756

Epoch: 6| Step: 6
Training loss: 3.1732736895536564
Validation loss: 2.8161473714133645

Epoch: 6| Step: 7
Training loss: 2.0522470812326614
Validation loss: 2.92021062218041

Epoch: 6| Step: 8
Training loss: 3.292571382089133
Validation loss: 2.795382985972955

Epoch: 6| Step: 9
Training loss: 2.9492915062424645
Validation loss: 2.896595769021392

Epoch: 6| Step: 10
Training loss: 2.6557825911428137
Validation loss: 2.717111473074466

Epoch: 6| Step: 11
Training loss: 2.948395671052489
Validation loss: 2.854588491731126

Epoch: 6| Step: 12
Training loss: 2.06366257702453
Validation loss: 2.678994710500245

Epoch: 6| Step: 13
Training loss: 1.9883100286473263
Validation loss: 2.899022971856741

Epoch: 413| Step: 0
Training loss: 2.841365443249475
Validation loss: 2.6057372117473863

Epoch: 6| Step: 1
Training loss: 3.1394683074299277
Validation loss: 2.9092215136425836

Epoch: 6| Step: 2
Training loss: 2.3619344609637634
Validation loss: 2.7932207749518327

Epoch: 6| Step: 3
Training loss: 2.5579764283908335
Validation loss: 2.912708091211755

Epoch: 6| Step: 4
Training loss: 2.5670073340934954
Validation loss: 2.8528101114756943

Epoch: 6| Step: 5
Training loss: 2.5144601340297683
Validation loss: 2.8692823573402957

Epoch: 6| Step: 6
Training loss: 2.4118656174278787
Validation loss: 2.967194439476297

Epoch: 6| Step: 7
Training loss: 2.654587079282373
Validation loss: 2.8959574073409287

Epoch: 6| Step: 8
Training loss: 2.82883709957599
Validation loss: 2.780888903502972

Epoch: 6| Step: 9
Training loss: 2.9461650879203565
Validation loss: 2.8991690848055174

Epoch: 6| Step: 10
Training loss: 2.5064098202554095
Validation loss: 2.728816450415693

Epoch: 6| Step: 11
Training loss: 2.1288445420027484
Validation loss: 2.805366772285324

Epoch: 6| Step: 12
Training loss: 2.5032473454477997
Validation loss: 2.95731773792493

Epoch: 6| Step: 13
Training loss: 2.2198266654177106
Validation loss: 2.7394455144727674

Epoch: 414| Step: 0
Training loss: 3.3114484161455646
Validation loss: 2.643540733439342

Epoch: 6| Step: 1
Training loss: 2.8221713462842906
Validation loss: 2.7998009717905976

Epoch: 6| Step: 2
Training loss: 2.320371273850532
Validation loss: 2.8532322329352446

Epoch: 6| Step: 3
Training loss: 2.1473428052716805
Validation loss: 2.849275046808852

Epoch: 6| Step: 4
Training loss: 3.561470016693889
Validation loss: 2.8119425500327315

Epoch: 6| Step: 5
Training loss: 3.1636976243608097
Validation loss: 2.704955097541762

Epoch: 6| Step: 6
Training loss: 2.220068741155125
Validation loss: 2.8480814495598414

Epoch: 6| Step: 7
Training loss: 1.9764530920575272
Validation loss: 2.7674060914856415

Epoch: 6| Step: 8
Training loss: 2.1311341553468512
Validation loss: 2.9083712631202983

Epoch: 6| Step: 9
Training loss: 3.1692922816599536
Validation loss: 2.9718306769787266

Epoch: 6| Step: 10
Training loss: 2.2759846579063097
Validation loss: 2.7957645846537447

Epoch: 6| Step: 11
Training loss: 2.6401966356971376
Validation loss: 2.8763852476081158

Epoch: 6| Step: 12
Training loss: 2.5433758997156986
Validation loss: 2.785579326467179

Epoch: 6| Step: 13
Training loss: 2.0631786732595336
Validation loss: 2.707915535278194

Epoch: 415| Step: 0
Training loss: 2.133330229915905
Validation loss: 2.8969278218563725

Epoch: 6| Step: 1
Training loss: 2.261592248729138
Validation loss: 2.7646131120269204

Epoch: 6| Step: 2
Training loss: 3.3231350020824357
Validation loss: 2.770649153418325

Epoch: 6| Step: 3
Training loss: 2.3708634743900325
Validation loss: 2.8410326805639445

Epoch: 6| Step: 4
Training loss: 2.5508438733579046
Validation loss: 2.8092505585130243

Epoch: 6| Step: 5
Training loss: 1.6565519093705852
Validation loss: 2.8681467454558804

Epoch: 6| Step: 6
Training loss: 2.5303838684412057
Validation loss: 2.647232087714232

Epoch: 6| Step: 7
Training loss: 2.4709937606973584
Validation loss: 2.777118237620119

Epoch: 6| Step: 8
Training loss: 3.307355088154005
Validation loss: 2.658162832898471

Epoch: 6| Step: 9
Training loss: 2.4824153440856263
Validation loss: 2.7873650715598175

Epoch: 6| Step: 10
Training loss: 1.823819298476714
Validation loss: 2.7790426057927826

Epoch: 6| Step: 11
Training loss: 2.0717366628363703
Validation loss: 2.7673111527302705

Epoch: 6| Step: 12
Training loss: 2.283779988376472
Validation loss: 2.7664733571840223

Epoch: 6| Step: 13
Training loss: 2.5119522484535293
Validation loss: 2.8325057917362475

Epoch: 416| Step: 0
Training loss: 2.114804210934416
Validation loss: 2.745355085960958

Epoch: 6| Step: 1
Training loss: 2.0902799632362723
Validation loss: 2.759695303786167

Epoch: 6| Step: 2
Training loss: 2.5371808870851686
Validation loss: 2.7866534985398337

Epoch: 6| Step: 3
Training loss: 3.010832937074986
Validation loss: 2.9404109075931495

Epoch: 6| Step: 4
Training loss: 2.287850745988293
Validation loss: 2.8082096897746927

Epoch: 6| Step: 5
Training loss: 3.128595496282303
Validation loss: 2.8075758903358903

Epoch: 6| Step: 6
Training loss: 2.568164983434887
Validation loss: 2.784026414352226

Epoch: 6| Step: 7
Training loss: 2.933025117055814
Validation loss: 2.7037319042864802

Epoch: 6| Step: 8
Training loss: 2.1765112482678948
Validation loss: 2.8125198345328086

Epoch: 6| Step: 9
Training loss: 2.207901126624272
Validation loss: 2.7306310436540246

Epoch: 6| Step: 10
Training loss: 1.7749969079433965
Validation loss: 2.777883164105532

Epoch: 6| Step: 11
Training loss: 2.5339573639532222
Validation loss: 2.950861029007593

Epoch: 6| Step: 12
Training loss: 2.1819998121882147
Validation loss: 2.815614239048645

Epoch: 6| Step: 13
Training loss: 3.0706426622537717
Validation loss: 2.6391879042028576

Epoch: 417| Step: 0
Training loss: 2.399215522349058
Validation loss: 2.904341593430641

Epoch: 6| Step: 1
Training loss: 3.4932133407465575
Validation loss: 2.8067183851625646

Epoch: 6| Step: 2
Training loss: 2.2414572985511074
Validation loss: 2.702549641923451

Epoch: 6| Step: 3
Training loss: 2.292316714482235
Validation loss: 2.6311663263497462

Epoch: 6| Step: 4
Training loss: 2.5146329831139185
Validation loss: 2.8371297852735315

Epoch: 6| Step: 5
Training loss: 2.5675982489726543
Validation loss: 2.7561220746329678

Epoch: 6| Step: 6
Training loss: 2.1571611331465044
Validation loss: 2.8371774056862393

Epoch: 6| Step: 7
Training loss: 2.3705922433816204
Validation loss: 2.8180110980195194

Epoch: 6| Step: 8
Training loss: 3.035846489343681
Validation loss: 2.828803000714683

Epoch: 6| Step: 9
Training loss: 2.0544364978949963
Validation loss: 2.6663855643573124

Epoch: 6| Step: 10
Training loss: 2.1947168376992656
Validation loss: 2.7099120559577807

Epoch: 6| Step: 11
Training loss: 2.4595037249718965
Validation loss: 2.8090732440190855

Epoch: 6| Step: 12
Training loss: 3.0338958519076042
Validation loss: 2.7358660826539984

Epoch: 6| Step: 13
Training loss: 2.8050760409134003
Validation loss: 2.5795422041879412

Epoch: 418| Step: 0
Training loss: 2.3231141101991413
Validation loss: 2.8740900489168375

Epoch: 6| Step: 1
Training loss: 2.401868025655197
Validation loss: 2.816917874625939

Epoch: 6| Step: 2
Training loss: 2.467763776197946
Validation loss: 2.7757955604166953

Epoch: 6| Step: 3
Training loss: 1.6599811775794968
Validation loss: 2.6200130867085236

Epoch: 6| Step: 4
Training loss: 1.972798922072222
Validation loss: 2.722788441137288

Epoch: 6| Step: 5
Training loss: 2.7269915486377205
Validation loss: 2.8332428444220596

Epoch: 6| Step: 6
Training loss: 2.6280154211036035
Validation loss: 2.800855936315567

Epoch: 6| Step: 7
Training loss: 2.7486885585050365
Validation loss: 2.72981816130469

Epoch: 6| Step: 8
Training loss: 2.207636657321193
Validation loss: 2.967156019105752

Epoch: 6| Step: 9
Training loss: 3.140698787904178
Validation loss: 2.74458871860795

Epoch: 6| Step: 10
Training loss: 2.4621873376320704
Validation loss: 2.852586065292133

Epoch: 6| Step: 11
Training loss: 2.3225738089898385
Validation loss: 2.805918035324741

Epoch: 6| Step: 12
Training loss: 2.6552315947535243
Validation loss: 2.733594677474177

Epoch: 6| Step: 13
Training loss: 1.871442535321254
Validation loss: 2.717536688537143

Epoch: 419| Step: 0
Training loss: 1.9911083215573804
Validation loss: 2.783219975764283

Epoch: 6| Step: 1
Training loss: 2.035112318271337
Validation loss: 2.7935205737262123

Epoch: 6| Step: 2
Training loss: 2.432036512389404
Validation loss: 2.7476314084236675

Epoch: 6| Step: 3
Training loss: 2.157987585567654
Validation loss: 2.8184215214835038

Epoch: 6| Step: 4
Training loss: 2.1501799574657245
Validation loss: 2.656884978304464

Epoch: 6| Step: 5
Training loss: 3.04102660111619
Validation loss: 2.7313700844918603

Epoch: 6| Step: 6
Training loss: 1.9639634574007774
Validation loss: 2.8096829305893114

Epoch: 6| Step: 7
Training loss: 2.8390458991951535
Validation loss: 2.9745411991398316

Epoch: 6| Step: 8
Training loss: 2.5579531268015008
Validation loss: 2.8178696008018638

Epoch: 6| Step: 9
Training loss: 3.3057402248427
Validation loss: 3.028435479080466

Epoch: 6| Step: 10
Training loss: 2.74005878997995
Validation loss: 2.656736311287684

Epoch: 6| Step: 11
Training loss: 2.402504917104018
Validation loss: 2.711892268885848

Epoch: 6| Step: 12
Training loss: 2.3448094325929776
Validation loss: 2.6981363502034967

Epoch: 6| Step: 13
Training loss: 3.4776041934805737
Validation loss: 2.734507631521961

Epoch: 420| Step: 0
Training loss: 3.0164825327054667
Validation loss: 2.6632242428153856

Epoch: 6| Step: 1
Training loss: 2.980051473902653
Validation loss: 2.8624126594926063

Epoch: 6| Step: 2
Training loss: 2.4025605886958887
Validation loss: 2.72610906700958

Epoch: 6| Step: 3
Training loss: 3.062258029642882
Validation loss: 2.6898602297219107

Epoch: 6| Step: 4
Training loss: 2.381145757360908
Validation loss: 2.7387328689818298

Epoch: 6| Step: 5
Training loss: 2.233443059171102
Validation loss: 2.8973187608580573

Epoch: 6| Step: 6
Training loss: 3.8939170544395867
Validation loss: 2.7743789916600066

Epoch: 6| Step: 7
Training loss: 1.847608634222271
Validation loss: 2.6709179481381184

Epoch: 6| Step: 8
Training loss: 1.9218040391180646
Validation loss: 2.7933019538980988

Epoch: 6| Step: 9
Training loss: 2.824726402064631
Validation loss: 2.819159163219339

Epoch: 6| Step: 10
Training loss: 2.525096525103563
Validation loss: 2.7607767564839722

Epoch: 6| Step: 11
Training loss: 2.184416641471493
Validation loss: 2.640905245114483

Epoch: 6| Step: 12
Training loss: 2.4236348311008293
Validation loss: 2.9128674815367144

Epoch: 6| Step: 13
Training loss: 2.4262481584104676
Validation loss: 2.749584198259224

Epoch: 421| Step: 0
Training loss: 2.542387396345353
Validation loss: 2.7818104132225017

Epoch: 6| Step: 1
Training loss: 2.933511176642477
Validation loss: 2.8292592611991885

Epoch: 6| Step: 2
Training loss: 3.824932651300844
Validation loss: 2.7891369761986438

Epoch: 6| Step: 3
Training loss: 2.0533599626168524
Validation loss: 2.793302770723444

Epoch: 6| Step: 4
Training loss: 1.8859327112372533
Validation loss: 2.780472138190686

Epoch: 6| Step: 5
Training loss: 2.812682082322106
Validation loss: 2.8839292366643265

Epoch: 6| Step: 6
Training loss: 2.2724237967662138
Validation loss: 2.836421575283949

Epoch: 6| Step: 7
Training loss: 2.9316990164800307
Validation loss: 2.745374488134234

Epoch: 6| Step: 8
Training loss: 1.7512816776566382
Validation loss: 2.8804762939127206

Epoch: 6| Step: 9
Training loss: 1.9405101650004235
Validation loss: 2.962751169401582

Epoch: 6| Step: 10
Training loss: 2.5039641422714602
Validation loss: 2.6661747458200984

Epoch: 6| Step: 11
Training loss: 2.764991385944876
Validation loss: 2.8740951189460544

Epoch: 6| Step: 12
Training loss: 1.7756324662102274
Validation loss: 2.7969353892116025

Epoch: 6| Step: 13
Training loss: 1.8048935809689852
Validation loss: 2.7902928358831955

Epoch: 422| Step: 0
Training loss: 2.8940867547329847
Validation loss: 2.70660567605547

Epoch: 6| Step: 1
Training loss: 2.908446271683731
Validation loss: 2.6801900864405304

Epoch: 6| Step: 2
Training loss: 1.7853278613919499
Validation loss: 2.7401864863153422

Epoch: 6| Step: 3
Training loss: 2.2117208973326075
Validation loss: 2.8060298808956556

Epoch: 6| Step: 4
Training loss: 2.3829101542489295
Validation loss: 2.7259678195498465

Epoch: 6| Step: 5
Training loss: 2.6060627456102465
Validation loss: 2.8849533566176184

Epoch: 6| Step: 6
Training loss: 2.1628890729405663
Validation loss: 2.791477265511983

Epoch: 6| Step: 7
Training loss: 2.813869905632667
Validation loss: 2.8658012406884477

Epoch: 6| Step: 8
Training loss: 2.7914025670477556
Validation loss: 2.9453432567813285

Epoch: 6| Step: 9
Training loss: 2.769739484827455
Validation loss: 2.8538115016725376

Epoch: 6| Step: 10
Training loss: 1.9797732845709333
Validation loss: 2.6953838332410123

Epoch: 6| Step: 11
Training loss: 2.1366576023871646
Validation loss: 2.750585584109825

Epoch: 6| Step: 12
Training loss: 2.261011938887756
Validation loss: 2.800290763791101

Epoch: 6| Step: 13
Training loss: 4.223975216431593
Validation loss: 2.718619639932731

Epoch: 423| Step: 0
Training loss: 2.289118951615664
Validation loss: 2.915591961911614

Epoch: 6| Step: 1
Training loss: 1.962798310951142
Validation loss: 2.6424802381807044

Epoch: 6| Step: 2
Training loss: 2.019945585443295
Validation loss: 2.6493766644776864

Epoch: 6| Step: 3
Training loss: 2.5286778697778023
Validation loss: 2.8167428339546423

Epoch: 6| Step: 4
Training loss: 2.2171742391156135
Validation loss: 2.8201556727567807

Epoch: 6| Step: 5
Training loss: 3.177262564851363
Validation loss: 2.8230089765023583

Epoch: 6| Step: 6
Training loss: 2.1159689236325776
Validation loss: 2.8659388543198783

Epoch: 6| Step: 7
Training loss: 2.2229745968745593
Validation loss: 2.801804388028551

Epoch: 6| Step: 8
Training loss: 2.5561172264331997
Validation loss: 2.62282313585617

Epoch: 6| Step: 9
Training loss: 2.3118417163772333
Validation loss: 2.702357985522323

Epoch: 6| Step: 10
Training loss: 2.975415106271134
Validation loss: 2.7258554389169554

Epoch: 6| Step: 11
Training loss: 2.9207346929926015
Validation loss: 2.7527773956057615

Epoch: 6| Step: 12
Training loss: 2.7747412827318136
Validation loss: 2.6793818418330964

Epoch: 6| Step: 13
Training loss: 2.3232744109655794
Validation loss: 2.8621923126979234

Epoch: 424| Step: 0
Training loss: 2.0610500209537106
Validation loss: 2.710056160840328

Epoch: 6| Step: 1
Training loss: 1.7916562131828115
Validation loss: 2.67225414772239

Epoch: 6| Step: 2
Training loss: 3.2334130372386336
Validation loss: 2.864056788105626

Epoch: 6| Step: 3
Training loss: 2.624988374230208
Validation loss: 2.820341185813979

Epoch: 6| Step: 4
Training loss: 2.8743736579959904
Validation loss: 2.8765543792573087

Epoch: 6| Step: 5
Training loss: 2.7947152605867287
Validation loss: 2.8697477179922712

Epoch: 6| Step: 6
Training loss: 2.3306927953400467
Validation loss: 2.8901585924062227

Epoch: 6| Step: 7
Training loss: 2.7552872894646305
Validation loss: 2.7948955250499874

Epoch: 6| Step: 8
Training loss: 2.251335171746311
Validation loss: 2.8771628937619083

Epoch: 6| Step: 9
Training loss: 2.538039532509118
Validation loss: 2.7381242784292437

Epoch: 6| Step: 10
Training loss: 2.078541305260042
Validation loss: 2.8017708733437945

Epoch: 6| Step: 11
Training loss: 2.496397952077741
Validation loss: 2.797650757888018

Epoch: 6| Step: 12
Training loss: 1.9727752951780628
Validation loss: 2.7704036551274744

Epoch: 6| Step: 13
Training loss: 2.3336147638172333
Validation loss: 2.7056285127199353

Epoch: 425| Step: 0
Training loss: 3.1911428242432582
Validation loss: 2.74178532057112

Epoch: 6| Step: 1
Training loss: 2.631831498575802
Validation loss: 2.842188741362161

Epoch: 6| Step: 2
Training loss: 1.9158272217991426
Validation loss: 2.669125974232521

Epoch: 6| Step: 3
Training loss: 2.372140266954287
Validation loss: 2.852287066695485

Epoch: 6| Step: 4
Training loss: 2.4297686498895494
Validation loss: 2.781707136178212

Epoch: 6| Step: 5
Training loss: 2.0346449431180034
Validation loss: 2.8149861658056143

Epoch: 6| Step: 6
Training loss: 3.2362258701596263
Validation loss: 2.800728234468248

Epoch: 6| Step: 7
Training loss: 2.4288719255801823
Validation loss: 2.7130168333005535

Epoch: 6| Step: 8
Training loss: 2.8228580051159353
Validation loss: 2.7433738464294404

Epoch: 6| Step: 9
Training loss: 2.453396533103652
Validation loss: 2.85970341538963

Epoch: 6| Step: 10
Training loss: 2.654808730511365
Validation loss: 2.836273235860989

Epoch: 6| Step: 11
Training loss: 2.7793003063489006
Validation loss: 2.7976509283300013

Epoch: 6| Step: 12
Training loss: 2.216453760960309
Validation loss: 2.883448419497535

Epoch: 6| Step: 13
Training loss: 2.109698461527566
Validation loss: 2.810924585573773

Epoch: 426| Step: 0
Training loss: 2.687343504141763
Validation loss: 2.888281349979348

Epoch: 6| Step: 1
Training loss: 2.6299134545536633
Validation loss: 2.8563536284942495

Epoch: 6| Step: 2
Training loss: 2.0028635029898783
Validation loss: 2.7371167946955737

Epoch: 6| Step: 3
Training loss: 2.3526716183078564
Validation loss: 2.8021785379718187

Epoch: 6| Step: 4
Training loss: 2.4069033639841773
Validation loss: 2.743006291813969

Epoch: 6| Step: 5
Training loss: 2.2243537521526506
Validation loss: 2.810957872101835

Epoch: 6| Step: 6
Training loss: 1.9555742089810002
Validation loss: 2.7176825351747036

Epoch: 6| Step: 7
Training loss: 3.241783172030549
Validation loss: 2.8088334054745263

Epoch: 6| Step: 8
Training loss: 2.525398366492871
Validation loss: 2.8587323881084465

Epoch: 6| Step: 9
Training loss: 2.087748109612233
Validation loss: 2.712380655664099

Epoch: 6| Step: 10
Training loss: 2.886846268538356
Validation loss: 2.6598125543702227

Epoch: 6| Step: 11
Training loss: 2.1615403002781517
Validation loss: 2.8028438496855514

Epoch: 6| Step: 12
Training loss: 2.3380643928216496
Validation loss: 2.7784232873052193

Epoch: 6| Step: 13
Training loss: 2.3522376425182645
Validation loss: 2.7883920382742873

Epoch: 427| Step: 0
Training loss: 1.8921021294964033
Validation loss: 2.884681067401259

Epoch: 6| Step: 1
Training loss: 2.047376498455578
Validation loss: 2.7370981193489046

Epoch: 6| Step: 2
Training loss: 2.807444458001908
Validation loss: 2.887262223181733

Epoch: 6| Step: 3
Training loss: 2.634514595215746
Validation loss: 2.9061168031914626

Epoch: 6| Step: 4
Training loss: 2.6226227304488705
Validation loss: 2.8241476362806375

Epoch: 6| Step: 5
Training loss: 2.321765585948804
Validation loss: 2.800041821602554

Epoch: 6| Step: 6
Training loss: 2.858756910548429
Validation loss: 2.9000538750616904

Epoch: 6| Step: 7
Training loss: 1.6466191826021668
Validation loss: 2.8664321174832064

Epoch: 6| Step: 8
Training loss: 3.1546118989362473
Validation loss: 2.729719186059813

Epoch: 6| Step: 9
Training loss: 2.361747306931221
Validation loss: 2.818333146848013

Epoch: 6| Step: 10
Training loss: 2.252347357486055
Validation loss: 2.714090954246406

Epoch: 6| Step: 11
Training loss: 2.2626211313099014
Validation loss: 2.7804259807495284

Epoch: 6| Step: 12
Training loss: 2.6518485909072336
Validation loss: 2.783618439805629

Epoch: 6| Step: 13
Training loss: 2.546158204107081
Validation loss: 2.7688992103366026

Epoch: 428| Step: 0
Training loss: 2.446646329637592
Validation loss: 2.7945412079703518

Epoch: 6| Step: 1
Training loss: 2.0716244553275414
Validation loss: 2.6753617909635534

Epoch: 6| Step: 2
Training loss: 2.9450383956815527
Validation loss: 2.862317212327412

Epoch: 6| Step: 3
Training loss: 3.0844673614432354
Validation loss: 2.9796898265834937

Epoch: 6| Step: 4
Training loss: 2.971243684382421
Validation loss: 2.735473414068015

Epoch: 6| Step: 5
Training loss: 2.145526592465885
Validation loss: 2.824741373321254

Epoch: 6| Step: 6
Training loss: 2.2230988985234026
Validation loss: 2.7791492086049967

Epoch: 6| Step: 7
Training loss: 2.0557772571269513
Validation loss: 2.9305430275961397

Epoch: 6| Step: 8
Training loss: 2.370044960207152
Validation loss: 2.954068395810992

Epoch: 6| Step: 9
Training loss: 2.696920694647014
Validation loss: 2.7813607701135683

Epoch: 6| Step: 10
Training loss: 2.352300585119837
Validation loss: 2.8270785844981074

Epoch: 6| Step: 11
Training loss: 3.097100187519481
Validation loss: 2.693731927964544

Epoch: 6| Step: 12
Training loss: 2.826051826800933
Validation loss: 2.783594706200522

Epoch: 6| Step: 13
Training loss: 2.16877976103049
Validation loss: 2.7642325224805884

Epoch: 429| Step: 0
Training loss: 2.2096042454771982
Validation loss: 2.7351175966960977

Epoch: 6| Step: 1
Training loss: 2.3553529524293335
Validation loss: 2.7579502658223802

Epoch: 6| Step: 2
Training loss: 1.932101450260602
Validation loss: 2.7292652771421992

Epoch: 6| Step: 3
Training loss: 2.857658663238753
Validation loss: 2.7370366225238745

Epoch: 6| Step: 4
Training loss: 2.771168298958023
Validation loss: 2.824924947184703

Epoch: 6| Step: 5
Training loss: 2.320404564671859
Validation loss: 2.8573022407362787

Epoch: 6| Step: 6
Training loss: 1.973656670729589
Validation loss: 2.8577452009659683

Epoch: 6| Step: 7
Training loss: 2.739982740250405
Validation loss: 2.7854312549884934

Epoch: 6| Step: 8
Training loss: 2.109291809702148
Validation loss: 2.7850000646924813

Epoch: 6| Step: 9
Training loss: 2.8122838255138087
Validation loss: 2.7904216933218513

Epoch: 6| Step: 10
Training loss: 2.0438755568454057
Validation loss: 2.903714614569286

Epoch: 6| Step: 11
Training loss: 2.6999271418313326
Validation loss: 2.732354391023576

Epoch: 6| Step: 12
Training loss: 3.3555469081955307
Validation loss: 2.8343667752093378

Epoch: 6| Step: 13
Training loss: 2.274781344459308
Validation loss: 2.7770618532019635

Epoch: 430| Step: 0
Training loss: 2.213401472850574
Validation loss: 2.847043845705752

Epoch: 6| Step: 1
Training loss: 2.821929806064067
Validation loss: 2.881241814347219

Epoch: 6| Step: 2
Training loss: 2.752823767057086
Validation loss: 2.703437093405415

Epoch: 6| Step: 3
Training loss: 2.6911858411654617
Validation loss: 2.7239215242637616

Epoch: 6| Step: 4
Training loss: 2.986420734134682
Validation loss: 2.8225334689011063

Epoch: 6| Step: 5
Training loss: 2.4567092660275542
Validation loss: 2.8803784085206057

Epoch: 6| Step: 6
Training loss: 3.080530146761661
Validation loss: 2.6224760597301757

Epoch: 6| Step: 7
Training loss: 2.481957368888806
Validation loss: 2.8338063609455806

Epoch: 6| Step: 8
Training loss: 2.2312023339402614
Validation loss: 2.772430863027484

Epoch: 6| Step: 9
Training loss: 2.3236689582470116
Validation loss: 2.6727105190615674

Epoch: 6| Step: 10
Training loss: 2.7066469566523303
Validation loss: 2.789211922840097

Epoch: 6| Step: 11
Training loss: 2.569695581300283
Validation loss: 2.948483761754245

Epoch: 6| Step: 12
Training loss: 2.2464000725221758
Validation loss: 2.7975175607177336

Epoch: 6| Step: 13
Training loss: 1.9582624693149324
Validation loss: 2.8055343599377416

Epoch: 431| Step: 0
Training loss: 2.381485966883161
Validation loss: 2.8459429637197218

Epoch: 6| Step: 1
Training loss: 2.4449091081945693
Validation loss: 2.768889838664882

Epoch: 6| Step: 2
Training loss: 2.110619975844558
Validation loss: 2.794231596215378

Epoch: 6| Step: 3
Training loss: 2.450794838407699
Validation loss: 2.7887646966602113

Epoch: 6| Step: 4
Training loss: 2.155243458990931
Validation loss: 2.83666900671494

Epoch: 6| Step: 5
Training loss: 1.9660795962732118
Validation loss: 2.675875696896113

Epoch: 6| Step: 6
Training loss: 2.420130144198026
Validation loss: 2.654465597047572

Epoch: 6| Step: 7
Training loss: 2.3387146838328716
Validation loss: 2.9236170465075912

Epoch: 6| Step: 8
Training loss: 2.6118759687631403
Validation loss: 2.9166195234247763

Epoch: 6| Step: 9
Training loss: 3.1779846580523965
Validation loss: 2.774159641468842

Epoch: 6| Step: 10
Training loss: 1.9437827717756757
Validation loss: 2.936152904876618

Epoch: 6| Step: 11
Training loss: 2.7854641480679874
Validation loss: 2.7862253221425126

Epoch: 6| Step: 12
Training loss: 2.462854613510517
Validation loss: 2.8749065187797873

Epoch: 6| Step: 13
Training loss: 1.5619308197927595
Validation loss: 2.9100905539885313

Epoch: 432| Step: 0
Training loss: 2.9602777959012987
Validation loss: 2.805620623080102

Epoch: 6| Step: 1
Training loss: 2.657892773832756
Validation loss: 2.882810853933816

Epoch: 6| Step: 2
Training loss: 1.9131642004793017
Validation loss: 2.801267760851143

Epoch: 6| Step: 3
Training loss: 2.367006905594403
Validation loss: 2.8196337142138814

Epoch: 6| Step: 4
Training loss: 2.761686980457297
Validation loss: 2.861786759748469

Epoch: 6| Step: 5
Training loss: 2.758281116817296
Validation loss: 2.788448191749243

Epoch: 6| Step: 6
Training loss: 1.949412303786559
Validation loss: 2.7270418528439135

Epoch: 6| Step: 7
Training loss: 2.197503459350502
Validation loss: 2.728921033007777

Epoch: 6| Step: 8
Training loss: 2.9834407922013955
Validation loss: 2.8867060708369423

Epoch: 6| Step: 9
Training loss: 2.144045248358359
Validation loss: 2.710898665959474

Epoch: 6| Step: 10
Training loss: 2.9628388030034656
Validation loss: 2.830756838869367

Epoch: 6| Step: 11
Training loss: 2.2449929367667982
Validation loss: 2.945340941503897

Epoch: 6| Step: 12
Training loss: 3.029424845429245
Validation loss: 2.933779321836462

Epoch: 6| Step: 13
Training loss: 2.7629651571279674
Validation loss: 2.7779761561104577

Epoch: 433| Step: 0
Training loss: 2.3714011180063337
Validation loss: 2.7242659305684374

Epoch: 6| Step: 1
Training loss: 2.8342549190298536
Validation loss: 2.7967192766380746

Epoch: 6| Step: 2
Training loss: 3.185780977947656
Validation loss: 2.8051750460200813

Epoch: 6| Step: 3
Training loss: 1.677392571728861
Validation loss: 2.840018395938132

Epoch: 6| Step: 4
Training loss: 1.9546281447268494
Validation loss: 2.6613463163156377

Epoch: 6| Step: 5
Training loss: 2.76750265919076
Validation loss: 2.7839985625106904

Epoch: 6| Step: 6
Training loss: 2.6753859624767737
Validation loss: 2.9172333291397834

Epoch: 6| Step: 7
Training loss: 2.460710303097515
Validation loss: 2.7644525713294947

Epoch: 6| Step: 8
Training loss: 2.072972154753248
Validation loss: 2.8356270134950488

Epoch: 6| Step: 9
Training loss: 2.958182066869291
Validation loss: 2.8533031994943245

Epoch: 6| Step: 10
Training loss: 2.309460782121336
Validation loss: 2.8334608462508166

Epoch: 6| Step: 11
Training loss: 2.3044919723069652
Validation loss: 2.698441481983235

Epoch: 6| Step: 12
Training loss: 2.516908306453714
Validation loss: 2.6851709704536963

Epoch: 6| Step: 13
Training loss: 1.859701304293952
Validation loss: 2.7856610032677813

Epoch: 434| Step: 0
Training loss: 2.40941184247022
Validation loss: 2.859091358404632

Epoch: 6| Step: 1
Training loss: 1.9770144824094273
Validation loss: 2.7186387647165318

Epoch: 6| Step: 2
Training loss: 3.164049991535846
Validation loss: 2.7854519642640856

Epoch: 6| Step: 3
Training loss: 2.9340509497776472
Validation loss: 2.7742058394069886

Epoch: 6| Step: 4
Training loss: 2.4064465727337216
Validation loss: 2.712053823335114

Epoch: 6| Step: 5
Training loss: 2.0230328365118004
Validation loss: 2.80761439523295

Epoch: 6| Step: 6
Training loss: 1.945747296257547
Validation loss: 2.752886465943857

Epoch: 6| Step: 7
Training loss: 2.2360959128211495
Validation loss: 2.8547032618847896

Epoch: 6| Step: 8
Training loss: 2.7129415970058495
Validation loss: 2.659244073232008

Epoch: 6| Step: 9
Training loss: 2.3842965929331252
Validation loss: 2.7090398398601363

Epoch: 6| Step: 10
Training loss: 2.642267923693321
Validation loss: 2.8168722570504845

Epoch: 6| Step: 11
Training loss: 2.7813725819523407
Validation loss: 2.84304639317115

Epoch: 6| Step: 12
Training loss: 2.3712803674501854
Validation loss: 2.769622403663901

Epoch: 6| Step: 13
Training loss: 2.5690856602910945
Validation loss: 2.7665944644369014

Epoch: 435| Step: 0
Training loss: 2.955401315305466
Validation loss: 2.7919640772173637

Epoch: 6| Step: 1
Training loss: 2.648678208836869
Validation loss: 2.8512161006276178

Epoch: 6| Step: 2
Training loss: 2.488601831597998
Validation loss: 2.8146535706633395

Epoch: 6| Step: 3
Training loss: 1.8102447685689766
Validation loss: 2.7074533141871044

Epoch: 6| Step: 4
Training loss: 1.8609233788403736
Validation loss: 2.867160660750342

Epoch: 6| Step: 5
Training loss: 2.4737406638240578
Validation loss: 2.7592166817729686

Epoch: 6| Step: 6
Training loss: 2.7604478558391805
Validation loss: 2.869550824195112

Epoch: 6| Step: 7
Training loss: 1.9822832632229146
Validation loss: 2.9367671341226123

Epoch: 6| Step: 8
Training loss: 2.495528131673803
Validation loss: 2.9173354455923506

Epoch: 6| Step: 9
Training loss: 2.1537533002530327
Validation loss: 2.9005789539189286

Epoch: 6| Step: 10
Training loss: 2.5203714078864263
Validation loss: 3.057388733172671

Epoch: 6| Step: 11
Training loss: 3.2848970036494234
Validation loss: 2.8989793917523414

Epoch: 6| Step: 12
Training loss: 2.8514431027015665
Validation loss: 2.8252251574083393

Epoch: 6| Step: 13
Training loss: 1.7736755076943609
Validation loss: 2.8103962676847143

Epoch: 436| Step: 0
Training loss: 2.4645873116219
Validation loss: 2.7658259051903897

Epoch: 6| Step: 1
Training loss: 2.749677639187147
Validation loss: 2.79536549135342

Epoch: 6| Step: 2
Training loss: 2.570078923241832
Validation loss: 2.853111992593518

Epoch: 6| Step: 3
Training loss: 2.6459616282038647
Validation loss: 2.7263771372804624

Epoch: 6| Step: 4
Training loss: 2.571438899095171
Validation loss: 2.741827976126668

Epoch: 6| Step: 5
Training loss: 2.6952923317859567
Validation loss: 2.7927952044806905

Epoch: 6| Step: 6
Training loss: 2.2924697046971736
Validation loss: 2.6350275021713565

Epoch: 6| Step: 7
Training loss: 2.3574730489086333
Validation loss: 2.7326244820461727

Epoch: 6| Step: 8
Training loss: 1.8556449083729514
Validation loss: 2.765852377292638

Epoch: 6| Step: 9
Training loss: 2.163257876208255
Validation loss: 2.7667437450995545

Epoch: 6| Step: 10
Training loss: 2.622293166594575
Validation loss: 2.8288436590238315

Epoch: 6| Step: 11
Training loss: 2.9334630619608406
Validation loss: 2.9310029826220565

Epoch: 6| Step: 12
Training loss: 2.046279005102587
Validation loss: 2.8553223186114014

Epoch: 6| Step: 13
Training loss: 2.8939939919220223
Validation loss: 2.807826778569512

Epoch: 437| Step: 0
Training loss: 2.1873195028769836
Validation loss: 2.936977127866164

Epoch: 6| Step: 1
Training loss: 2.4010301922064037
Validation loss: 2.677456641373083

Epoch: 6| Step: 2
Training loss: 2.5223724668718734
Validation loss: 2.7957269903419713

Epoch: 6| Step: 3
Training loss: 2.8298880629760976
Validation loss: 2.764816941074226

Epoch: 6| Step: 4
Training loss: 2.352852603703823
Validation loss: 2.6092127336343056

Epoch: 6| Step: 5
Training loss: 2.5726951060993906
Validation loss: 2.8743485670851636

Epoch: 6| Step: 6
Training loss: 2.5684548015779884
Validation loss: 2.7778523445033785

Epoch: 6| Step: 7
Training loss: 3.377544574118703
Validation loss: 2.8296370660287717

Epoch: 6| Step: 8
Training loss: 2.1482988902374953
Validation loss: 2.7805685204162174

Epoch: 6| Step: 9
Training loss: 2.0515930312965223
Validation loss: 2.7228277712672306

Epoch: 6| Step: 10
Training loss: 1.9616438972536703
Validation loss: 2.853440568644667

Epoch: 6| Step: 11
Training loss: 2.5475047450447255
Validation loss: 2.731531424537312

Epoch: 6| Step: 12
Training loss: 2.010079970026287
Validation loss: 2.850605631138412

Epoch: 6| Step: 13
Training loss: 3.0791968014231457
Validation loss: 2.9058309555734483

Epoch: 438| Step: 0
Training loss: 2.3154312320416084
Validation loss: 2.9317487682094954

Epoch: 6| Step: 1
Training loss: 1.8793682077714522
Validation loss: 2.8070169387063086

Epoch: 6| Step: 2
Training loss: 2.301540903480863
Validation loss: 2.9166380434052748

Epoch: 6| Step: 3
Training loss: 2.0972447622181267
Validation loss: 2.845183699725177

Epoch: 6| Step: 4
Training loss: 2.03606700470693
Validation loss: 2.7587671968546608

Epoch: 6| Step: 5
Training loss: 2.1714427710011504
Validation loss: 2.825852999786338

Epoch: 6| Step: 6
Training loss: 3.120171440500543
Validation loss: 2.798780887148651

Epoch: 6| Step: 7
Training loss: 1.7268601933333618
Validation loss: 2.664531829653598

Epoch: 6| Step: 8
Training loss: 3.054668924026399
Validation loss: 2.7582157675288395

Epoch: 6| Step: 9
Training loss: 1.9622840057859625
Validation loss: 2.698763047330096

Epoch: 6| Step: 10
Training loss: 2.5398679424108797
Validation loss: 2.76516796052973

Epoch: 6| Step: 11
Training loss: 2.7613877417771326
Validation loss: 2.7445217663866988

Epoch: 6| Step: 12
Training loss: 2.389357885508469
Validation loss: 2.718370338741793

Epoch: 6| Step: 13
Training loss: 2.0323778982425114
Validation loss: 2.8034671675716516

Epoch: 439| Step: 0
Training loss: 2.1942968224985084
Validation loss: 2.6700666038680265

Epoch: 6| Step: 1
Training loss: 2.960406333767502
Validation loss: 2.6677171399963693

Epoch: 6| Step: 2
Training loss: 2.799507734759152
Validation loss: 2.8824626306675882

Epoch: 6| Step: 3
Training loss: 1.8520800032297868
Validation loss: 2.802787551984255

Epoch: 6| Step: 4
Training loss: 2.8880626972398775
Validation loss: 2.7078412289637424

Epoch: 6| Step: 5
Training loss: 2.33119214679021
Validation loss: 2.700776411849751

Epoch: 6| Step: 6
Training loss: 2.271942381141639
Validation loss: 2.6400177659061237

Epoch: 6| Step: 7
Training loss: 2.3511322743189065
Validation loss: 2.903444120130179

Epoch: 6| Step: 8
Training loss: 2.0293589078584144
Validation loss: 2.768152554782698

Epoch: 6| Step: 9
Training loss: 1.758324849377936
Validation loss: 2.732787865336369

Epoch: 6| Step: 10
Training loss: 2.2830936872296697
Validation loss: 2.6968889773864335

Epoch: 6| Step: 11
Training loss: 2.3420291941294806
Validation loss: 2.7892999352370302

Epoch: 6| Step: 12
Training loss: 2.664425643378745
Validation loss: 2.844044385815754

Epoch: 6| Step: 13
Training loss: 2.501539614570959
Validation loss: 2.7427656958699194

Epoch: 440| Step: 0
Training loss: 2.5661878333201034
Validation loss: 2.729805361939286

Epoch: 6| Step: 1
Training loss: 2.596437004601877
Validation loss: 2.8996963573271053

Epoch: 6| Step: 2
Training loss: 2.5576603475441493
Validation loss: 2.8680055809207543

Epoch: 6| Step: 3
Training loss: 2.2843160013702595
Validation loss: 2.9284957787396264

Epoch: 6| Step: 4
Training loss: 2.225472273692238
Validation loss: 2.7233436653450402

Epoch: 6| Step: 5
Training loss: 2.0991756683233334
Validation loss: 2.8113414461002755

Epoch: 6| Step: 6
Training loss: 2.058075291241539
Validation loss: 2.928006693306928

Epoch: 6| Step: 7
Training loss: 2.4593753761378463
Validation loss: 2.7507512659593654

Epoch: 6| Step: 8
Training loss: 2.417733866633324
Validation loss: 2.753116118403135

Epoch: 6| Step: 9
Training loss: 3.155326632656664
Validation loss: 2.884556624195576

Epoch: 6| Step: 10
Training loss: 3.0335840107665417
Validation loss: 2.7993743228191037

Epoch: 6| Step: 11
Training loss: 3.5298611770867696
Validation loss: 2.791342519186196

Epoch: 6| Step: 12
Training loss: 2.2568484033218033
Validation loss: 2.8173717749435543

Epoch: 6| Step: 13
Training loss: 1.8472301806451341
Validation loss: 2.893898443596484

Epoch: 441| Step: 0
Training loss: 2.6934891435040753
Validation loss: 2.8265199142008224

Epoch: 6| Step: 1
Training loss: 2.9886112205484157
Validation loss: 2.7673352001506015

Epoch: 6| Step: 2
Training loss: 2.549237986383041
Validation loss: 2.579073482691278

Epoch: 6| Step: 3
Training loss: 2.5727903718621126
Validation loss: 2.833404371528007

Epoch: 6| Step: 4
Training loss: 2.1147956428368944
Validation loss: 2.793190579820142

Epoch: 6| Step: 5
Training loss: 2.423397545451336
Validation loss: 2.809932204691243

Epoch: 6| Step: 6
Training loss: 3.4383251240259844
Validation loss: 2.646943621374206

Epoch: 6| Step: 7
Training loss: 3.0395102673630294
Validation loss: 2.795480429624082

Epoch: 6| Step: 8
Training loss: 2.6483786247258503
Validation loss: 2.69228280859519

Epoch: 6| Step: 9
Training loss: 1.674149650397377
Validation loss: 2.7739152431281546

Epoch: 6| Step: 10
Training loss: 2.570272613494184
Validation loss: 2.8321271928342475

Epoch: 6| Step: 11
Training loss: 2.5047778250719985
Validation loss: 2.8752816371283867

Epoch: 6| Step: 12
Training loss: 1.853555435701777
Validation loss: 2.83076041070293

Epoch: 6| Step: 13
Training loss: 2.223040341408043
Validation loss: 2.8152391956596055

Epoch: 442| Step: 0
Training loss: 2.417730908259018
Validation loss: 2.827785032093145

Epoch: 6| Step: 1
Training loss: 2.9125380222965744
Validation loss: 2.7213458684853724

Epoch: 6| Step: 2
Training loss: 2.7110833999992896
Validation loss: 2.804558590502335

Epoch: 6| Step: 3
Training loss: 2.471117646797984
Validation loss: 2.9071285240049125

Epoch: 6| Step: 4
Training loss: 3.1983182242869694
Validation loss: 2.721778430456877

Epoch: 6| Step: 5
Training loss: 2.386392674124941
Validation loss: 2.735301720405484

Epoch: 6| Step: 6
Training loss: 3.015754024927628
Validation loss: 2.8813115812064813

Epoch: 6| Step: 7
Training loss: 2.4344980387512316
Validation loss: 2.8453368904957914

Epoch: 6| Step: 8
Training loss: 1.678418198870315
Validation loss: 2.7753968803194

Epoch: 6| Step: 9
Training loss: 2.035970631093447
Validation loss: 2.914925034756072

Epoch: 6| Step: 10
Training loss: 1.9242048330419381
Validation loss: 2.803667394667742

Epoch: 6| Step: 11
Training loss: 2.48276357152416
Validation loss: 2.9313357949653325

Epoch: 6| Step: 12
Training loss: 2.1248120617504056
Validation loss: 2.8081705211296453

Epoch: 6| Step: 13
Training loss: 1.692938764488792
Validation loss: 2.9417714045901384

Epoch: 443| Step: 0
Training loss: 2.531346072033883
Validation loss: 2.8804587767651157

Epoch: 6| Step: 1
Training loss: 3.4415105832031543
Validation loss: 2.7715017266772293

Epoch: 6| Step: 2
Training loss: 3.438862894549203
Validation loss: 2.761265622566534

Epoch: 6| Step: 3
Training loss: 1.762119019367173
Validation loss: 2.8699859904125646

Epoch: 6| Step: 4
Training loss: 1.856108609347253
Validation loss: 2.5726571678121446

Epoch: 6| Step: 5
Training loss: 2.5576599746743165
Validation loss: 2.6917835295438075

Epoch: 6| Step: 6
Training loss: 2.1057697144733245
Validation loss: 2.7499861115583157

Epoch: 6| Step: 7
Training loss: 1.5902018225834895
Validation loss: 2.751134882507321

Epoch: 6| Step: 8
Training loss: 2.866281641749307
Validation loss: 2.8288281403497906

Epoch: 6| Step: 9
Training loss: 2.5033463017127353
Validation loss: 2.754424971582547

Epoch: 6| Step: 10
Training loss: 2.2656252104660464
Validation loss: 2.827436285440479

Epoch: 6| Step: 11
Training loss: 2.6227805427777846
Validation loss: 2.76162302996274

Epoch: 6| Step: 12
Training loss: 1.9515406782214537
Validation loss: 2.814988091049339

Epoch: 6| Step: 13
Training loss: 2.049134499740943
Validation loss: 2.786261683829553

Epoch: 444| Step: 0
Training loss: 3.3621244312976164
Validation loss: 2.688964673569319

Epoch: 6| Step: 1
Training loss: 2.1801049711170126
Validation loss: 2.8945735535116723

Epoch: 6| Step: 2
Training loss: 2.5351291649169476
Validation loss: 2.6441809704490913

Epoch: 6| Step: 3
Training loss: 1.813570890094409
Validation loss: 2.8425667730827477

Epoch: 6| Step: 4
Training loss: 1.9156317058900136
Validation loss: 2.636536555100733

Epoch: 6| Step: 5
Training loss: 1.9957168730947112
Validation loss: 2.864924717284339

Epoch: 6| Step: 6
Training loss: 2.4325963114758093
Validation loss: 2.8135562558591323

Epoch: 6| Step: 7
Training loss: 2.2399594604706583
Validation loss: 2.7073009773105055

Epoch: 6| Step: 8
Training loss: 1.9275951083971197
Validation loss: 2.5722056650252707

Epoch: 6| Step: 9
Training loss: 2.325227098756381
Validation loss: 2.832410874543539

Epoch: 6| Step: 10
Training loss: 2.2702595630415354
Validation loss: 2.747157684503721

Epoch: 6| Step: 11
Training loss: 2.9938768841766725
Validation loss: 2.825047240251139

Epoch: 6| Step: 12
Training loss: 2.0439964029239426
Validation loss: 2.7087122144951743

Epoch: 6| Step: 13
Training loss: 3.9360534190530445
Validation loss: 2.7573423057124233

Epoch: 445| Step: 0
Training loss: 1.8586233206437424
Validation loss: 2.7945205064223866

Epoch: 6| Step: 1
Training loss: 2.7965367288453855
Validation loss: 2.671012531487755

Epoch: 6| Step: 2
Training loss: 2.6815287767438503
Validation loss: 2.786447031900793

Epoch: 6| Step: 3
Training loss: 2.548265323400855
Validation loss: 2.756948766269921

Epoch: 6| Step: 4
Training loss: 2.2612957863629544
Validation loss: 2.7478921704460415

Epoch: 6| Step: 5
Training loss: 1.668232738321534
Validation loss: 2.745375535394794

Epoch: 6| Step: 6
Training loss: 2.344753813356845
Validation loss: 2.7844822532098537

Epoch: 6| Step: 7
Training loss: 2.304553011833441
Validation loss: 2.8343249551584124

Epoch: 6| Step: 8
Training loss: 2.963729789854829
Validation loss: 2.7174165204444463

Epoch: 6| Step: 9
Training loss: 2.8567739861655537
Validation loss: 2.958288195582141

Epoch: 6| Step: 10
Training loss: 1.7586414332388356
Validation loss: 2.8392269635293057

Epoch: 6| Step: 11
Training loss: 3.522199121299852
Validation loss: 2.7103509100765275

Epoch: 6| Step: 12
Training loss: 2.583978562121438
Validation loss: 2.7228426192510136

Epoch: 6| Step: 13
Training loss: 2.853020282340333
Validation loss: 2.7676379191786413

Epoch: 446| Step: 0
Training loss: 1.4503677625264317
Validation loss: 2.6784162765703963

Epoch: 6| Step: 1
Training loss: 2.5504485726839343
Validation loss: 2.8090022798591887

Epoch: 6| Step: 2
Training loss: 2.7406202222723732
Validation loss: 2.7175665422374706

Epoch: 6| Step: 3
Training loss: 2.5076253945972287
Validation loss: 2.6467101395062085

Epoch: 6| Step: 4
Training loss: 2.658331022191812
Validation loss: 2.7365781397512197

Epoch: 6| Step: 5
Training loss: 2.4805231523930806
Validation loss: 2.9525978324059174

Epoch: 6| Step: 6
Training loss: 2.545121414196283
Validation loss: 2.757191933978994

Epoch: 6| Step: 7
Training loss: 2.016166673370426
Validation loss: 2.8023909893062533

Epoch: 6| Step: 8
Training loss: 1.9408948750591526
Validation loss: 2.830030482057101

Epoch: 6| Step: 9
Training loss: 2.7786419244874003
Validation loss: 2.794538622808025

Epoch: 6| Step: 10
Training loss: 3.6969942617002967
Validation loss: 2.7928517247179525

Epoch: 6| Step: 11
Training loss: 2.3910629768836764
Validation loss: 2.8384294939112538

Epoch: 6| Step: 12
Training loss: 2.812764473242222
Validation loss: 2.7449727770475714

Epoch: 6| Step: 13
Training loss: 1.725250919723763
Validation loss: 2.7841477341141454

Epoch: 447| Step: 0
Training loss: 2.3277808837546194
Validation loss: 2.7631826627174703

Epoch: 6| Step: 1
Training loss: 2.020670291052051
Validation loss: 2.904291728818742

Epoch: 6| Step: 2
Training loss: 2.5201439873870473
Validation loss: 2.8169433041650644

Epoch: 6| Step: 3
Training loss: 1.9435584804960602
Validation loss: 2.789865406412574

Epoch: 6| Step: 4
Training loss: 2.1201883705591005
Validation loss: 2.7537287773384875

Epoch: 6| Step: 5
Training loss: 2.044170194120768
Validation loss: 2.752084646687088

Epoch: 6| Step: 6
Training loss: 2.5560363568330544
Validation loss: 2.698275423271488

Epoch: 6| Step: 7
Training loss: 3.1650467460277762
Validation loss: 2.935783747120673

Epoch: 6| Step: 8
Training loss: 2.8211381290212603
Validation loss: 2.7957783007022172

Epoch: 6| Step: 9
Training loss: 2.5972878101610215
Validation loss: 2.7969898267447286

Epoch: 6| Step: 10
Training loss: 1.7246145591787527
Validation loss: 2.78850432754492

Epoch: 6| Step: 11
Training loss: 2.5729068544846796
Validation loss: 2.6136022022065215

Epoch: 6| Step: 12
Training loss: 2.6602265156835974
Validation loss: 2.854571722785731

Epoch: 6| Step: 13
Training loss: 2.3142577012366523
Validation loss: 2.795590290162875

Epoch: 448| Step: 0
Training loss: 2.398235300095982
Validation loss: 2.8249465666536446

Epoch: 6| Step: 1
Training loss: 2.352880368428707
Validation loss: 2.650684731964111

Epoch: 6| Step: 2
Training loss: 2.60673306971637
Validation loss: 2.751524384338782

Epoch: 6| Step: 3
Training loss: 1.8215678065640386
Validation loss: 2.7983699924810015

Epoch: 6| Step: 4
Training loss: 1.744726136148918
Validation loss: 2.7766044711259843

Epoch: 6| Step: 5
Training loss: 2.458633264467128
Validation loss: 2.7302501603351783

Epoch: 6| Step: 6
Training loss: 2.747209346763783
Validation loss: 2.6632818629370014

Epoch: 6| Step: 7
Training loss: 3.3679004454317463
Validation loss: 2.815591706605179

Epoch: 6| Step: 8
Training loss: 1.8066746064160608
Validation loss: 2.835611583477786

Epoch: 6| Step: 9
Training loss: 2.3733539900613
Validation loss: 2.6447579247063673

Epoch: 6| Step: 10
Training loss: 2.3629983527734337
Validation loss: 2.7826738140844935

Epoch: 6| Step: 11
Training loss: 2.8614934359243063
Validation loss: 2.8567582135939693

Epoch: 6| Step: 12
Training loss: 1.9902307212728667
Validation loss: 2.603837903999885

Epoch: 6| Step: 13
Training loss: 4.334847528048785
Validation loss: 2.845437321982731

Epoch: 449| Step: 0
Training loss: 1.8623369491175166
Validation loss: 2.9066632264056604

Epoch: 6| Step: 1
Training loss: 2.6597134617948113
Validation loss: 2.7679873291696895

Epoch: 6| Step: 2
Training loss: 2.0640705948814584
Validation loss: 2.816598281229215

Epoch: 6| Step: 3
Training loss: 1.888276840918195
Validation loss: 2.6469130108503807

Epoch: 6| Step: 4
Training loss: 2.4932048957131574
Validation loss: 2.7875138367641896

Epoch: 6| Step: 5
Training loss: 2.361097704780765
Validation loss: 2.67358029305206

Epoch: 6| Step: 6
Training loss: 2.9029909955028628
Validation loss: 2.7514364643028957

Epoch: 6| Step: 7
Training loss: 3.634338452195588
Validation loss: 2.6678836497667286

Epoch: 6| Step: 8
Training loss: 1.3027480094688024
Validation loss: 2.8129410064116342

Epoch: 6| Step: 9
Training loss: 2.1670648013408482
Validation loss: 2.6839953935766205

Epoch: 6| Step: 10
Training loss: 2.4154497129890746
Validation loss: 2.7698166769558914

Epoch: 6| Step: 11
Training loss: 2.41558582427124
Validation loss: 2.627676336331402

Epoch: 6| Step: 12
Training loss: 2.5629234894440645
Validation loss: 2.571240778098142

Epoch: 6| Step: 13
Training loss: 2.1765471776243586
Validation loss: 2.853524258753052

Epoch: 450| Step: 0
Training loss: 2.8814469077789084
Validation loss: 2.783376419380364

Epoch: 6| Step: 1
Training loss: 2.285243471225401
Validation loss: 2.769622768361393

Epoch: 6| Step: 2
Training loss: 1.6201809070972328
Validation loss: 2.864432707972113

Epoch: 6| Step: 3
Training loss: 1.7101008490332188
Validation loss: 2.6213536404855113

Epoch: 6| Step: 4
Training loss: 2.2775994970234676
Validation loss: 2.593672366610681

Epoch: 6| Step: 5
Training loss: 2.768406649067884
Validation loss: 2.6844927309318405

Epoch: 6| Step: 6
Training loss: 2.3257843130320253
Validation loss: 2.8342415257686038

Epoch: 6| Step: 7
Training loss: 2.7055012396134748
Validation loss: 2.747513893684483

Epoch: 6| Step: 8
Training loss: 2.9994838588488233
Validation loss: 2.865019850300356

Epoch: 6| Step: 9
Training loss: 2.303885110089994
Validation loss: 2.743810850450629

Epoch: 6| Step: 10
Training loss: 1.93746603659118
Validation loss: 2.7704572676074015

Epoch: 6| Step: 11
Training loss: 2.176758907791896
Validation loss: 2.864793830066025

Epoch: 6| Step: 12
Training loss: 3.065830832754534
Validation loss: 2.8164967358303348

Epoch: 6| Step: 13
Training loss: 1.7716004523927202
Validation loss: 2.652752791353643

Epoch: 451| Step: 0
Training loss: 2.8678139150415864
Validation loss: 2.8196680948908774

Epoch: 6| Step: 1
Training loss: 1.8542142140439168
Validation loss: 2.619801779480627

Epoch: 6| Step: 2
Training loss: 2.309465943895775
Validation loss: 2.815370131159457

Epoch: 6| Step: 3
Training loss: 3.09140449776454
Validation loss: 2.758098015002789

Epoch: 6| Step: 4
Training loss: 2.3310430276337
Validation loss: 2.851784355825817

Epoch: 6| Step: 5
Training loss: 1.8826666811118158
Validation loss: 2.6731317425378927

Epoch: 6| Step: 6
Training loss: 2.498777853737523
Validation loss: 2.659753949203258

Epoch: 6| Step: 7
Training loss: 2.3516474610248927
Validation loss: 2.8362643362793194

Epoch: 6| Step: 8
Training loss: 2.2483302384400705
Validation loss: 2.7552918337495718

Epoch: 6| Step: 9
Training loss: 2.0993361468295766
Validation loss: 2.7326081279815804

Epoch: 6| Step: 10
Training loss: 3.034907071797791
Validation loss: 2.6926702440087356

Epoch: 6| Step: 11
Training loss: 2.182410067773345
Validation loss: 2.7296926509294077

Epoch: 6| Step: 12
Training loss: 2.5863280217536984
Validation loss: 2.95105690047824

Epoch: 6| Step: 13
Training loss: 3.036822829880836
Validation loss: 2.7355935124384034

Epoch: 452| Step: 0
Training loss: 1.779745168982378
Validation loss: 2.736566153302416

Epoch: 6| Step: 1
Training loss: 2.290776571174445
Validation loss: 2.686740151598877

Epoch: 6| Step: 2
Training loss: 2.9996229570600175
Validation loss: 2.8113940727364954

Epoch: 6| Step: 3
Training loss: 3.002860612772629
Validation loss: 2.9341274652214033

Epoch: 6| Step: 4
Training loss: 1.6978272802621281
Validation loss: 2.724777589444335

Epoch: 6| Step: 5
Training loss: 3.3955439032720296
Validation loss: 2.6577847510113157

Epoch: 6| Step: 6
Training loss: 2.205560190573348
Validation loss: 2.869128199654389

Epoch: 6| Step: 7
Training loss: 1.9038439715831612
Validation loss: 2.8822127788139986

Epoch: 6| Step: 8
Training loss: 1.6938667285293003
Validation loss: 2.7419197001536766

Epoch: 6| Step: 9
Training loss: 1.5200531756987663
Validation loss: 2.786016008017883

Epoch: 6| Step: 10
Training loss: 2.3403362590099777
Validation loss: 2.8655461016650072

Epoch: 6| Step: 11
Training loss: 1.9669122747302115
Validation loss: 2.8024891223546162

Epoch: 6| Step: 12
Training loss: 1.9946131879544384
Validation loss: 2.7964385152600015

Epoch: 6| Step: 13
Training loss: 3.3848693092169033
Validation loss: 2.840316087495323

Epoch: 453| Step: 0
Training loss: 2.250489711450647
Validation loss: 2.79537842248871

Epoch: 6| Step: 1
Training loss: 2.562890092884271
Validation loss: 2.813904525279103

Epoch: 6| Step: 2
Training loss: 2.0989111302623695
Validation loss: 2.7125413436615817

Epoch: 6| Step: 3
Training loss: 2.873747013550111
Validation loss: 2.7368150250506393

Epoch: 6| Step: 4
Training loss: 2.7313559295573735
Validation loss: 2.7831527452671243

Epoch: 6| Step: 5
Training loss: 2.601513286503126
Validation loss: 2.6943674754882663

Epoch: 6| Step: 6
Training loss: 2.160911166016162
Validation loss: 2.7521326552971495

Epoch: 6| Step: 7
Training loss: 2.3859262602315887
Validation loss: 2.7318892198392617

Epoch: 6| Step: 8
Training loss: 1.4139124753833734
Validation loss: 2.8120560964570744

Epoch: 6| Step: 9
Training loss: 2.3167234464131976
Validation loss: 2.7062959913553564

Epoch: 6| Step: 10
Training loss: 3.051251676778555
Validation loss: 2.8864366585394836

Epoch: 6| Step: 11
Training loss: 2.5321548163404257
Validation loss: 2.684449102251899

Epoch: 6| Step: 12
Training loss: 1.665978130531338
Validation loss: 2.84834846840436

Epoch: 6| Step: 13
Training loss: 3.762405982379509
Validation loss: 2.742674918968401

Epoch: 454| Step: 0
Training loss: 2.1847026922968826
Validation loss: 2.764186580774597

Epoch: 6| Step: 1
Training loss: 2.5332444422167826
Validation loss: 2.804034558788667

Epoch: 6| Step: 2
Training loss: 2.0373729268332696
Validation loss: 2.6826636182641765

Epoch: 6| Step: 3
Training loss: 2.2223533061890266
Validation loss: 2.7470132534654175

Epoch: 6| Step: 4
Training loss: 2.336190608674428
Validation loss: 2.532773431336185

Epoch: 6| Step: 5
Training loss: 3.562612966787586
Validation loss: 2.8044750608362454

Epoch: 6| Step: 6
Training loss: 2.4471548531831333
Validation loss: 2.73408951964003

Epoch: 6| Step: 7
Training loss: 2.345655760020861
Validation loss: 2.7649157753566884

Epoch: 6| Step: 8
Training loss: 2.5790131859621614
Validation loss: 2.886781215179218

Epoch: 6| Step: 9
Training loss: 2.0562322923077536
Validation loss: 2.8690165692799425

Epoch: 6| Step: 10
Training loss: 3.0953049268249573
Validation loss: 2.748062306914465

Epoch: 6| Step: 11
Training loss: 2.289271218220176
Validation loss: 2.8429549831282523

Epoch: 6| Step: 12
Training loss: 2.139298299383496
Validation loss: 2.8131937727711085

Epoch: 6| Step: 13
Training loss: 2.5304078007913398
Validation loss: 2.7907684275717504

Epoch: 455| Step: 0
Training loss: 3.309345830945504
Validation loss: 2.729267432869964

Epoch: 6| Step: 1
Training loss: 2.2165927339237346
Validation loss: 2.7926932553204593

Epoch: 6| Step: 2
Training loss: 2.1552745437100693
Validation loss: 2.744519607695188

Epoch: 6| Step: 3
Training loss: 1.95143567078589
Validation loss: 2.6849612631300444

Epoch: 6| Step: 4
Training loss: 2.528637515105772
Validation loss: 2.661580227791156

Epoch: 6| Step: 5
Training loss: 1.491164730732627
Validation loss: 2.745838380789322

Epoch: 6| Step: 6
Training loss: 2.4519377344075983
Validation loss: 2.732056227867738

Epoch: 6| Step: 7
Training loss: 2.2480241789281115
Validation loss: 2.8360215294429763

Epoch: 6| Step: 8
Training loss: 2.0641567627421895
Validation loss: 2.8083062483531016

Epoch: 6| Step: 9
Training loss: 2.6525255008949395
Validation loss: 2.739924834678283

Epoch: 6| Step: 10
Training loss: 3.382521830486216
Validation loss: 2.707883033202814

Epoch: 6| Step: 11
Training loss: 2.5162601024654183
Validation loss: 2.757986819032759

Epoch: 6| Step: 12
Training loss: 2.6923110836133453
Validation loss: 2.9390809816968924

Epoch: 6| Step: 13
Training loss: 2.169107883617757
Validation loss: 2.8006004096281036

Epoch: 456| Step: 0
Training loss: 2.721311393048765
Validation loss: 2.832753083737902

Epoch: 6| Step: 1
Training loss: 2.8558544728150035
Validation loss: 2.759957337352162

Epoch: 6| Step: 2
Training loss: 2.3777606379207135
Validation loss: 2.7235007498873682

Epoch: 6| Step: 3
Training loss: 1.9897207508930552
Validation loss: 2.8158666844173377

Epoch: 6| Step: 4
Training loss: 2.4325028082114906
Validation loss: 2.8187361205541266

Epoch: 6| Step: 5
Training loss: 2.301578713830629
Validation loss: 2.7547755386576736

Epoch: 6| Step: 6
Training loss: 1.8257515653091358
Validation loss: 2.922388720925313

Epoch: 6| Step: 7
Training loss: 1.9294760275421887
Validation loss: 2.777853925406398

Epoch: 6| Step: 8
Training loss: 3.1389392484903067
Validation loss: 2.8296500878832394

Epoch: 6| Step: 9
Training loss: 2.849172097136135
Validation loss: 2.7397218799653613

Epoch: 6| Step: 10
Training loss: 1.968291456319171
Validation loss: 2.6567328335744995

Epoch: 6| Step: 11
Training loss: 2.7905355031185395
Validation loss: 2.7011399684853887

Epoch: 6| Step: 12
Training loss: 2.2616711020186058
Validation loss: 2.753071787464264

Epoch: 6| Step: 13
Training loss: 2.1661277858908394
Validation loss: 2.609313232170253

Epoch: 457| Step: 0
Training loss: 2.326284000695549
Validation loss: 2.615863589721369

Epoch: 6| Step: 1
Training loss: 3.4697735625158996
Validation loss: 2.8784038230898195

Epoch: 6| Step: 2
Training loss: 3.3732975091904143
Validation loss: 2.886513896146878

Epoch: 6| Step: 3
Training loss: 2.8026727862353287
Validation loss: 2.7683315586733555

Epoch: 6| Step: 4
Training loss: 2.274111723142356
Validation loss: 2.8810296125605483

Epoch: 6| Step: 5
Training loss: 1.927917038941071
Validation loss: 2.8290100888224705

Epoch: 6| Step: 6
Training loss: 2.3654583447710866
Validation loss: 2.9248940145991864

Epoch: 6| Step: 7
Training loss: 2.419371264412198
Validation loss: 2.815028707556462

Epoch: 6| Step: 8
Training loss: 1.9754617513411803
Validation loss: 2.686431497790845

Epoch: 6| Step: 9
Training loss: 1.98073935682063
Validation loss: 2.8981869306805934

Epoch: 6| Step: 10
Training loss: 2.560973852713023
Validation loss: 2.762338524581724

Epoch: 6| Step: 11
Training loss: 2.8456942440986164
Validation loss: 2.787788052829583

Epoch: 6| Step: 12
Training loss: 2.6403189938899145
Validation loss: 2.9404957388101143

Epoch: 6| Step: 13
Training loss: 2.2439398215073387
Validation loss: 2.7169501721829667

Epoch: 458| Step: 0
Training loss: 2.1152289646745213
Validation loss: 2.7720094495134977

Epoch: 6| Step: 1
Training loss: 2.6294015585009394
Validation loss: 2.754294654384712

Epoch: 6| Step: 2
Training loss: 2.1616369211958673
Validation loss: 2.9256090020135974

Epoch: 6| Step: 3
Training loss: 2.850350234613448
Validation loss: 2.8465664833215003

Epoch: 6| Step: 4
Training loss: 2.6260938635943147
Validation loss: 2.7201732191332195

Epoch: 6| Step: 5
Training loss: 2.1597844885231567
Validation loss: 2.6880723382445995

Epoch: 6| Step: 6
Training loss: 1.92998622790547
Validation loss: 2.69989409161143

Epoch: 6| Step: 7
Training loss: 2.8669317063818625
Validation loss: 2.8094970139696054

Epoch: 6| Step: 8
Training loss: 2.443941652241425
Validation loss: 2.747428979611987

Epoch: 6| Step: 9
Training loss: 2.348114832109049
Validation loss: 2.9165887221602347

Epoch: 6| Step: 10
Training loss: 2.7808571870272507
Validation loss: 2.8236979192935294

Epoch: 6| Step: 11
Training loss: 2.314349491680354
Validation loss: 2.8703676706551984

Epoch: 6| Step: 12
Training loss: 2.078082435573552
Validation loss: 2.8208202134246534

Epoch: 6| Step: 13
Training loss: 2.5656905431889916
Validation loss: 2.744331492366349

Epoch: 459| Step: 0
Training loss: 2.6033819211495195
Validation loss: 2.8553153288692465

Epoch: 6| Step: 1
Training loss: 2.5561651686790254
Validation loss: 2.864511887600011

Epoch: 6| Step: 2
Training loss: 2.967206533651186
Validation loss: 2.8045917062393113

Epoch: 6| Step: 3
Training loss: 2.082310069239638
Validation loss: 2.8296450578106094

Epoch: 6| Step: 4
Training loss: 2.4636599060029143
Validation loss: 2.779594445754347

Epoch: 6| Step: 5
Training loss: 3.342249738729893
Validation loss: 2.7612690169029306

Epoch: 6| Step: 6
Training loss: 2.2712236354811397
Validation loss: 2.8735516008620308

Epoch: 6| Step: 7
Training loss: 2.2339276486175224
Validation loss: 2.835895790799741

Epoch: 6| Step: 8
Training loss: 2.72131007887371
Validation loss: 2.8235147014747355

Epoch: 6| Step: 9
Training loss: 1.9141100819181438
Validation loss: 2.849710821813402

Epoch: 6| Step: 10
Training loss: 2.197086581246994
Validation loss: 2.718440707629609

Epoch: 6| Step: 11
Training loss: 2.202246957677012
Validation loss: 2.742835980054815

Epoch: 6| Step: 12
Training loss: 2.2376005991905266
Validation loss: 2.770654645905784

Epoch: 6| Step: 13
Training loss: 2.1721172609307158
Validation loss: 2.8604035670626375

Epoch: 460| Step: 0
Training loss: 3.5998615874067057
Validation loss: 2.7863397873019626

Epoch: 6| Step: 1
Training loss: 2.160782404234565
Validation loss: 2.854454126351578

Epoch: 6| Step: 2
Training loss: 2.34672032645315
Validation loss: 2.8094332492900045

Epoch: 6| Step: 3
Training loss: 2.965405316752999
Validation loss: 2.7588371979041217

Epoch: 6| Step: 4
Training loss: 2.531206295436742
Validation loss: 2.911359491027388

Epoch: 6| Step: 5
Training loss: 2.740047739406614
Validation loss: 2.8434702417730335

Epoch: 6| Step: 6
Training loss: 2.0914345079236494
Validation loss: 2.861433827722229

Epoch: 6| Step: 7
Training loss: 1.1882733286456264
Validation loss: 2.834589998605081

Epoch: 6| Step: 8
Training loss: 2.5909435301869146
Validation loss: 2.7953516815685586

Epoch: 6| Step: 9
Training loss: 2.164196464716322
Validation loss: 2.7117019913021956

Epoch: 6| Step: 10
Training loss: 2.33393605712931
Validation loss: 2.852808144358688

Epoch: 6| Step: 11
Training loss: 2.349590907099595
Validation loss: 2.794147627543401

Epoch: 6| Step: 12
Training loss: 1.7399282817749169
Validation loss: 2.776517022100363

Epoch: 6| Step: 13
Training loss: 2.6982316725557425
Validation loss: 2.690972782804916

Epoch: 461| Step: 0
Training loss: 2.7154456918954475
Validation loss: 2.8012249918113215

Epoch: 6| Step: 1
Training loss: 2.413624745402875
Validation loss: 2.789424355385061

Epoch: 6| Step: 2
Training loss: 2.4521084762835574
Validation loss: 2.6475198147835455

Epoch: 6| Step: 3
Training loss: 2.6418543555394134
Validation loss: 2.7801045364180497

Epoch: 6| Step: 4
Training loss: 1.8844053882786627
Validation loss: 2.7947115289374924

Epoch: 6| Step: 5
Training loss: 2.6155804155166362
Validation loss: 2.8514300293269295

Epoch: 6| Step: 6
Training loss: 2.8404357377088663
Validation loss: 2.7084227390219993

Epoch: 6| Step: 7
Training loss: 1.7649375454926857
Validation loss: 2.7485256200040227

Epoch: 6| Step: 8
Training loss: 1.9633047701318211
Validation loss: 2.7986258496861685

Epoch: 6| Step: 9
Training loss: 2.703130733064955
Validation loss: 2.728555377120361

Epoch: 6| Step: 10
Training loss: 2.5489770370772025
Validation loss: 2.660345177326694

Epoch: 6| Step: 11
Training loss: 2.6704415385595426
Validation loss: 2.8028978258170185

Epoch: 6| Step: 12
Training loss: 2.9742783320285464
Validation loss: 2.736286335603824

Epoch: 6| Step: 13
Training loss: 2.2713331203335563
Validation loss: 2.733005018522859

Epoch: 462| Step: 0
Training loss: 1.7476260568451734
Validation loss: 2.7621248210132427

Epoch: 6| Step: 1
Training loss: 2.7562771162225967
Validation loss: 2.802136899911329

Epoch: 6| Step: 2
Training loss: 2.060552081784002
Validation loss: 2.822660499855354

Epoch: 6| Step: 3
Training loss: 1.433735603985271
Validation loss: 2.830310925614684

Epoch: 6| Step: 4
Training loss: 2.4521015729417566
Validation loss: 2.7843641576814475

Epoch: 6| Step: 5
Training loss: 2.292482912754954
Validation loss: 2.7989798750156942

Epoch: 6| Step: 6
Training loss: 1.7209103272265114
Validation loss: 2.8301008319781005

Epoch: 6| Step: 7
Training loss: 2.474824698819388
Validation loss: 2.7234036781223874

Epoch: 6| Step: 8
Training loss: 3.1108594255215785
Validation loss: 2.8083212158588258

Epoch: 6| Step: 9
Training loss: 2.848286123433245
Validation loss: 2.7199293913474385

Epoch: 6| Step: 10
Training loss: 2.0467502468617327
Validation loss: 2.768203355687009

Epoch: 6| Step: 11
Training loss: 2.5898570064705972
Validation loss: 2.6826604130707374

Epoch: 6| Step: 12
Training loss: 2.3575276601550184
Validation loss: 2.889982291854777

Epoch: 6| Step: 13
Training loss: 2.231379708759378
Validation loss: 2.715782759405486

Epoch: 463| Step: 0
Training loss: 1.6561498071846914
Validation loss: 2.8320159108302034

Epoch: 6| Step: 1
Training loss: 2.012585381065027
Validation loss: 2.697689288331573

Epoch: 6| Step: 2
Training loss: 2.5637703514686296
Validation loss: 2.8861617467979563

Epoch: 6| Step: 3
Training loss: 2.098792537328569
Validation loss: 2.8276590232970906

Epoch: 6| Step: 4
Training loss: 2.705152335681065
Validation loss: 2.675756735225697

Epoch: 6| Step: 5
Training loss: 2.162205419156026
Validation loss: 2.802516329393195

Epoch: 6| Step: 6
Training loss: 2.213447682498495
Validation loss: 2.767515745525298

Epoch: 6| Step: 7
Training loss: 2.2982578396679547
Validation loss: 2.6795986723709357

Epoch: 6| Step: 8
Training loss: 1.9808831919278471
Validation loss: 2.745886927610752

Epoch: 6| Step: 9
Training loss: 2.7399632489043864
Validation loss: 2.8169627688651153

Epoch: 6| Step: 10
Training loss: 3.411288533340831
Validation loss: 2.8495141278505236

Epoch: 6| Step: 11
Training loss: 2.0513668713700604
Validation loss: 2.7704060758869766

Epoch: 6| Step: 12
Training loss: 2.662715448250077
Validation loss: 2.79175983439398

Epoch: 6| Step: 13
Training loss: 2.494634688395506
Validation loss: 2.73174879115509

Epoch: 464| Step: 0
Training loss: 2.9327412470117147
Validation loss: 2.8184556640811604

Epoch: 6| Step: 1
Training loss: 2.0736810881769276
Validation loss: 2.7513280273998344

Epoch: 6| Step: 2
Training loss: 2.445883687252148
Validation loss: 2.6676739750084826

Epoch: 6| Step: 3
Training loss: 1.984337633637179
Validation loss: 2.877046155671911

Epoch: 6| Step: 4
Training loss: 2.883846108001221
Validation loss: 2.799355464795956

Epoch: 6| Step: 5
Training loss: 2.122449578538897
Validation loss: 2.7165423501134516

Epoch: 6| Step: 6
Training loss: 3.136804638894544
Validation loss: 2.7549358178638403

Epoch: 6| Step: 7
Training loss: 2.3022254336128927
Validation loss: 2.6840039536921827

Epoch: 6| Step: 8
Training loss: 2.4073559089869074
Validation loss: 2.732385687222778

Epoch: 6| Step: 9
Training loss: 2.1599781038799266
Validation loss: 2.6513951843097368

Epoch: 6| Step: 10
Training loss: 2.709443925906989
Validation loss: 2.7024395526661666

Epoch: 6| Step: 11
Training loss: 1.9943880979370268
Validation loss: 2.814674465690042

Epoch: 6| Step: 12
Training loss: 2.0603022570292504
Validation loss: 2.5639092286800538

Epoch: 6| Step: 13
Training loss: 2.1915817326477343
Validation loss: 2.673519474485728

Epoch: 465| Step: 0
Training loss: 1.8190761837348774
Validation loss: 2.718894408693845

Epoch: 6| Step: 1
Training loss: 1.6446696968426964
Validation loss: 2.8727381058131627

Epoch: 6| Step: 2
Training loss: 2.154521525783838
Validation loss: 2.60345636406253

Epoch: 6| Step: 3
Training loss: 2.364151925099394
Validation loss: 2.674454435622841

Epoch: 6| Step: 4
Training loss: 2.4662687169644237
Validation loss: 2.6155910225935735

Epoch: 6| Step: 5
Training loss: 2.3203281183712567
Validation loss: 2.779282232685603

Epoch: 6| Step: 6
Training loss: 2.776155155765444
Validation loss: 2.7756304655784567

Epoch: 6| Step: 7
Training loss: 2.360457822390949
Validation loss: 2.7234303592474864

Epoch: 6| Step: 8
Training loss: 2.4312246679246434
Validation loss: 2.937382246461817

Epoch: 6| Step: 9
Training loss: 2.339980387320204
Validation loss: 2.7009533811931563

Epoch: 6| Step: 10
Training loss: 3.0679287186340605
Validation loss: 2.76309496426287

Epoch: 6| Step: 11
Training loss: 2.0583623361539076
Validation loss: 2.749726942867959

Epoch: 6| Step: 12
Training loss: 2.830914549502417
Validation loss: 2.915060808659893

Epoch: 6| Step: 13
Training loss: 2.614165881951988
Validation loss: 2.752041612606524

Epoch: 466| Step: 0
Training loss: 2.412396593793116
Validation loss: 2.678525296374077

Epoch: 6| Step: 1
Training loss: 1.540997523212361
Validation loss: 2.776043662630933

Epoch: 6| Step: 2
Training loss: 3.0086142524173205
Validation loss: 2.8237151466790564

Epoch: 6| Step: 3
Training loss: 2.920695510493117
Validation loss: 2.8033759406537437

Epoch: 6| Step: 4
Training loss: 2.916590026575157
Validation loss: 2.619915819688958

Epoch: 6| Step: 5
Training loss: 3.0834822919450615
Validation loss: 2.7008445301219886

Epoch: 6| Step: 6
Training loss: 1.7706485951120952
Validation loss: 2.7741204439591556

Epoch: 6| Step: 7
Training loss: 1.8890159632753973
Validation loss: 2.6955577794022423

Epoch: 6| Step: 8
Training loss: 2.867323536984808
Validation loss: 2.881725904297745

Epoch: 6| Step: 9
Training loss: 2.0306651520567915
Validation loss: 2.6938024665324116

Epoch: 6| Step: 10
Training loss: 2.391199379528242
Validation loss: 2.695037722213143

Epoch: 6| Step: 11
Training loss: 2.6865664790320274
Validation loss: 2.816125646613537

Epoch: 6| Step: 12
Training loss: 2.540261886191944
Validation loss: 2.7458364714828747

Epoch: 6| Step: 13
Training loss: 2.00343337995611
Validation loss: 2.78543400690768

Epoch: 467| Step: 0
Training loss: 2.1912242249421645
Validation loss: 2.774646583873759

Epoch: 6| Step: 1
Training loss: 1.9370389820562133
Validation loss: 2.8677538902210435

Epoch: 6| Step: 2
Training loss: 3.2166225476442944
Validation loss: 2.6960879220598613

Epoch: 6| Step: 3
Training loss: 2.429813295891902
Validation loss: 2.855734539482333

Epoch: 6| Step: 4
Training loss: 2.118078290751301
Validation loss: 2.7540749537682894

Epoch: 6| Step: 5
Training loss: 3.1489639031481573
Validation loss: 2.744059748080526

Epoch: 6| Step: 6
Training loss: 1.528613097204798
Validation loss: 2.8116400293802504

Epoch: 6| Step: 7
Training loss: 2.3008675680500055
Validation loss: 2.7047300432352515

Epoch: 6| Step: 8
Training loss: 2.647779985127143
Validation loss: 2.8063996984055213

Epoch: 6| Step: 9
Training loss: 1.867547930162398
Validation loss: 2.8234803912439865

Epoch: 6| Step: 10
Training loss: 2.5635819360783185
Validation loss: 2.616792576367125

Epoch: 6| Step: 11
Training loss: 2.020095834819291
Validation loss: 2.8316863398550054

Epoch: 6| Step: 12
Training loss: 2.1968891821630043
Validation loss: 2.666489156524153

Epoch: 6| Step: 13
Training loss: 3.053624741448181
Validation loss: 2.7442884777661964

Epoch: 468| Step: 0
Training loss: 2.082445743948509
Validation loss: 2.7628327374161517

Epoch: 6| Step: 1
Training loss: 2.3282479887357366
Validation loss: 2.727958771357122

Epoch: 6| Step: 2
Training loss: 2.6101109728843874
Validation loss: 2.639987882045318

Epoch: 6| Step: 3
Training loss: 2.0804559928568813
Validation loss: 2.94245090140846

Epoch: 6| Step: 4
Training loss: 1.4191507924495568
Validation loss: 2.8597204487325163

Epoch: 6| Step: 5
Training loss: 3.3960838147481627
Validation loss: 2.7556082279096614

Epoch: 6| Step: 6
Training loss: 2.0468836194504823
Validation loss: 2.986415869393707

Epoch: 6| Step: 7
Training loss: 2.0713776925138365
Validation loss: 2.7099037526963223

Epoch: 6| Step: 8
Training loss: 2.7003265183425618
Validation loss: 2.8637907370683062

Epoch: 6| Step: 9
Training loss: 1.50240855759102
Validation loss: 2.8025855048115456

Epoch: 6| Step: 10
Training loss: 2.167910683343996
Validation loss: 2.79647285474603

Epoch: 6| Step: 11
Training loss: 2.2563416861294368
Validation loss: 2.907558159538746

Epoch: 6| Step: 12
Training loss: 2.266167516538152
Validation loss: 2.730721009857416

Epoch: 6| Step: 13
Training loss: 3.356925177546268
Validation loss: 2.952895337482933

Epoch: 469| Step: 0
Training loss: 2.1400257023488916
Validation loss: 2.772685992831301

Epoch: 6| Step: 1
Training loss: 2.890695931878871
Validation loss: 2.6139982090331184

Epoch: 6| Step: 2
Training loss: 2.453221604698657
Validation loss: 2.657035625559438

Epoch: 6| Step: 3
Training loss: 2.2122690888507157
Validation loss: 2.8941080001677375

Epoch: 6| Step: 4
Training loss: 2.410069394517336
Validation loss: 2.792581598085204

Epoch: 6| Step: 5
Training loss: 2.3923594845890985
Validation loss: 2.8689665866297003

Epoch: 6| Step: 6
Training loss: 1.9856009713683107
Validation loss: 2.732364279257642

Epoch: 6| Step: 7
Training loss: 2.410232023411283
Validation loss: 2.676275951672363

Epoch: 6| Step: 8
Training loss: 2.808139896994327
Validation loss: 2.6942988709003335

Epoch: 6| Step: 9
Training loss: 2.432459779820488
Validation loss: 2.812401610992671

Epoch: 6| Step: 10
Training loss: 2.262082612543512
Validation loss: 2.7931855373234122

Epoch: 6| Step: 11
Training loss: 3.145260554499178
Validation loss: 2.74396962314102

Epoch: 6| Step: 12
Training loss: 2.337905208124682
Validation loss: 2.8034916345853262

Epoch: 6| Step: 13
Training loss: 1.9981570693548758
Validation loss: 2.8370166455239803

Epoch: 470| Step: 0
Training loss: 2.356097439549842
Validation loss: 2.6512662911395517

Epoch: 6| Step: 1
Training loss: 2.8031402825626808
Validation loss: 2.984576988503857

Epoch: 6| Step: 2
Training loss: 2.1748643240869154
Validation loss: 2.7262740791990945

Epoch: 6| Step: 3
Training loss: 2.5163497354721853
Validation loss: 2.8979463264193868

Epoch: 6| Step: 4
Training loss: 3.0167171101717067
Validation loss: 2.8526481886738138

Epoch: 6| Step: 5
Training loss: 2.5682718356338774
Validation loss: 2.6906062540322155

Epoch: 6| Step: 6
Training loss: 1.8282921869498365
Validation loss: 2.831820307178645

Epoch: 6| Step: 7
Training loss: 2.1037552182636605
Validation loss: 2.6872860870355937

Epoch: 6| Step: 8
Training loss: 2.2952334188467556
Validation loss: 2.8316455883702796

Epoch: 6| Step: 9
Training loss: 2.268009693434519
Validation loss: 2.7344700556814487

Epoch: 6| Step: 10
Training loss: 1.552820205715419
Validation loss: 2.828428796117495

Epoch: 6| Step: 11
Training loss: 2.539343152307722
Validation loss: 2.849762458307374

Epoch: 6| Step: 12
Training loss: 1.881875339129217
Validation loss: 2.696114041023238

Epoch: 6| Step: 13
Training loss: 2.611704443305584
Validation loss: 2.780482889801983

Epoch: 471| Step: 0
Training loss: 2.074118746485824
Validation loss: 2.715442677396164

Epoch: 6| Step: 1
Training loss: 2.129350136493334
Validation loss: 2.8400222296366904

Epoch: 6| Step: 2
Training loss: 3.357587613846549
Validation loss: 2.7414804762565352

Epoch: 6| Step: 3
Training loss: 2.398222575048074
Validation loss: 2.7397819405566266

Epoch: 6| Step: 4
Training loss: 2.4112763854580983
Validation loss: 2.772133515607875

Epoch: 6| Step: 5
Training loss: 2.3432207654429464
Validation loss: 2.7388558711922286

Epoch: 6| Step: 6
Training loss: 1.9286435658723746
Validation loss: 2.8870160811449312

Epoch: 6| Step: 7
Training loss: 1.7269036831926006
Validation loss: 2.787567799804638

Epoch: 6| Step: 8
Training loss: 2.2621342568864473
Validation loss: 2.763792837868439

Epoch: 6| Step: 9
Training loss: 2.3860046017547254
Validation loss: 2.6937585641782733

Epoch: 6| Step: 10
Training loss: 2.8094789173905474
Validation loss: 2.6146893208727815

Epoch: 6| Step: 11
Training loss: 2.2075598699760803
Validation loss: 2.6919030048199666

Epoch: 6| Step: 12
Training loss: 2.8624439550518694
Validation loss: 2.7820354503393663

Epoch: 6| Step: 13
Training loss: 2.361162733623178
Validation loss: 2.6265392722358274

Epoch: 472| Step: 0
Training loss: 2.6572423539819265
Validation loss: 2.8602818347140464

Epoch: 6| Step: 1
Training loss: 1.7149938287429325
Validation loss: 2.5718624796246314

Epoch: 6| Step: 2
Training loss: 2.492330995452561
Validation loss: 2.759090080830521

Epoch: 6| Step: 3
Training loss: 1.9324785195325174
Validation loss: 2.661872087660654

Epoch: 6| Step: 4
Training loss: 2.203522341994726
Validation loss: 2.633299857841027

Epoch: 6| Step: 5
Training loss: 3.2450021315275226
Validation loss: 2.703361684383658

Epoch: 6| Step: 6
Training loss: 3.2325983005101233
Validation loss: 2.6921816677936663

Epoch: 6| Step: 7
Training loss: 1.8589002500041072
Validation loss: 2.746681459613839

Epoch: 6| Step: 8
Training loss: 1.803500160578971
Validation loss: 2.725015720707054

Epoch: 6| Step: 9
Training loss: 1.9295796970417465
Validation loss: 2.738229231108963

Epoch: 6| Step: 10
Training loss: 2.1070782626136726
Validation loss: 2.7366864959900505

Epoch: 6| Step: 11
Training loss: 2.562647001190363
Validation loss: 2.7959891395721748

Epoch: 6| Step: 12
Training loss: 2.817656642888618
Validation loss: 2.7611451385619867

Epoch: 6| Step: 13
Training loss: 2.0168277198018387
Validation loss: 2.741520441083575

Epoch: 473| Step: 0
Training loss: 1.8951753445629784
Validation loss: 2.795481750199109

Epoch: 6| Step: 1
Training loss: 2.150622113732261
Validation loss: 2.777423822008402

Epoch: 6| Step: 2
Training loss: 2.417819263477882
Validation loss: 2.6868089682732155

Epoch: 6| Step: 3
Training loss: 1.9861563549208876
Validation loss: 2.774664893772808

Epoch: 6| Step: 4
Training loss: 2.5578651380861013
Validation loss: 2.8665421778908176

Epoch: 6| Step: 5
Training loss: 2.266295656058888
Validation loss: 2.7408121130140626

Epoch: 6| Step: 6
Training loss: 2.6158583269224542
Validation loss: 2.828869497010362

Epoch: 6| Step: 7
Training loss: 2.1544476038753504
Validation loss: 2.857544459462526

Epoch: 6| Step: 8
Training loss: 2.129739188940499
Validation loss: 2.881057361037773

Epoch: 6| Step: 9
Training loss: 2.1730565212322976
Validation loss: 2.789487176834954

Epoch: 6| Step: 10
Training loss: 2.2173255323653973
Validation loss: 2.7949571365993107

Epoch: 6| Step: 11
Training loss: 2.7451957873230253
Validation loss: 2.7828805680347384

Epoch: 6| Step: 12
Training loss: 3.274220957808773
Validation loss: 2.7943080695521245

Epoch: 6| Step: 13
Training loss: 3.022098057275052
Validation loss: 2.7357590545694785

Epoch: 474| Step: 0
Training loss: 2.1677679295362045
Validation loss: 2.9650202397383354

Epoch: 6| Step: 1
Training loss: 2.4369222494252156
Validation loss: 2.6993334343536737

Epoch: 6| Step: 2
Training loss: 2.4189837517762336
Validation loss: 2.7366722327216437

Epoch: 6| Step: 3
Training loss: 1.4972831440414955
Validation loss: 2.933281853148125

Epoch: 6| Step: 4
Training loss: 3.5515632733446143
Validation loss: 2.8867824939881825

Epoch: 6| Step: 5
Training loss: 2.4033915397942733
Validation loss: 2.765000501021933

Epoch: 6| Step: 6
Training loss: 3.070272430857336
Validation loss: 2.7969533836319425

Epoch: 6| Step: 7
Training loss: 2.61529426990436
Validation loss: 2.923726181828819

Epoch: 6| Step: 8
Training loss: 2.787283108060823
Validation loss: 2.9073014683277023

Epoch: 6| Step: 9
Training loss: 1.806714657478082
Validation loss: 2.6489155326710407

Epoch: 6| Step: 10
Training loss: 2.061321962487235
Validation loss: 2.829605459266273

Epoch: 6| Step: 11
Training loss: 2.301060606183609
Validation loss: 2.805345842658197

Epoch: 6| Step: 12
Training loss: 1.8419858606978345
Validation loss: 2.6909739674644

Epoch: 6| Step: 13
Training loss: 2.9408021587716733
Validation loss: 2.789265253309226

Epoch: 475| Step: 0
Training loss: 3.3708521467956203
Validation loss: 2.869177298487822

Epoch: 6| Step: 1
Training loss: 3.189428606190202
Validation loss: 2.751003573547653

Epoch: 6| Step: 2
Training loss: 2.2848371755738475
Validation loss: 2.7862183743646636

Epoch: 6| Step: 3
Training loss: 2.721365448899435
Validation loss: 2.8060868371182464

Epoch: 6| Step: 4
Training loss: 1.917295753513059
Validation loss: 2.797062424666482

Epoch: 6| Step: 5
Training loss: 2.3083729388239727
Validation loss: 2.806719581708871

Epoch: 6| Step: 6
Training loss: 2.906431459073815
Validation loss: 2.7046801733296624

Epoch: 6| Step: 7
Training loss: 2.7326633000417857
Validation loss: 2.8462134906322816

Epoch: 6| Step: 8
Training loss: 2.127755678370324
Validation loss: 2.754800564693317

Epoch: 6| Step: 9
Training loss: 2.042420060123737
Validation loss: 2.819484063737693

Epoch: 6| Step: 10
Training loss: 2.0408726400274224
Validation loss: 2.7206220149567857

Epoch: 6| Step: 11
Training loss: 2.177201251132598
Validation loss: 2.643973994530237

Epoch: 6| Step: 12
Training loss: 1.853016214249351
Validation loss: 2.6570587529115914

Epoch: 6| Step: 13
Training loss: 2.656981603062707
Validation loss: 2.642045307697709

Epoch: 476| Step: 0
Training loss: 2.7659420542905218
Validation loss: 2.732967446411886

Epoch: 6| Step: 1
Training loss: 1.9710639192347634
Validation loss: 2.7646223118083713

Epoch: 6| Step: 2
Training loss: 3.273102445002068
Validation loss: 2.8087905882586974

Epoch: 6| Step: 3
Training loss: 2.3072864426208555
Validation loss: 2.8432162132195256

Epoch: 6| Step: 4
Training loss: 1.926225653512462
Validation loss: 2.67964930659468

Epoch: 6| Step: 5
Training loss: 2.170132164160588
Validation loss: 2.838588947595916

Epoch: 6| Step: 6
Training loss: 2.007496374751674
Validation loss: 2.941522159517051

Epoch: 6| Step: 7
Training loss: 2.41249245756087
Validation loss: 2.847441464265188

Epoch: 6| Step: 8
Training loss: 2.132472419873466
Validation loss: 2.8467239556836654

Epoch: 6| Step: 9
Training loss: 2.5579301978303977
Validation loss: 2.7606191538034888

Epoch: 6| Step: 10
Training loss: 2.343532399566646
Validation loss: 2.711025048317761

Epoch: 6| Step: 11
Training loss: 2.1708530793661747
Validation loss: 2.910996610119831

Epoch: 6| Step: 12
Training loss: 2.7471289819988054
Validation loss: 2.817253642173425

Epoch: 6| Step: 13
Training loss: 1.705823807359767
Validation loss: 2.65758081018196

Epoch: 477| Step: 0
Training loss: 3.027136302116136
Validation loss: 2.7342810501858144

Epoch: 6| Step: 1
Training loss: 1.961646510366093
Validation loss: 2.7909318388140054

Epoch: 6| Step: 2
Training loss: 2.1507154560660564
Validation loss: 2.8296090108091043

Epoch: 6| Step: 3
Training loss: 2.8702392967495705
Validation loss: 2.715248093026082

Epoch: 6| Step: 4
Training loss: 2.366388570090411
Validation loss: 2.869664448312258

Epoch: 6| Step: 5
Training loss: 2.702173142618361
Validation loss: 2.831824855391036

Epoch: 6| Step: 6
Training loss: 1.1197890289039003
Validation loss: 2.743588076604491

Epoch: 6| Step: 7
Training loss: 2.668171060914711
Validation loss: 2.7088275919090563

Epoch: 6| Step: 8
Training loss: 2.1890035639037237
Validation loss: 2.758414281996832

Epoch: 6| Step: 9
Training loss: 1.9305507566848255
Validation loss: 2.786681458160707

Epoch: 6| Step: 10
Training loss: 2.6613693272189445
Validation loss: 2.771738457971437

Epoch: 6| Step: 11
Training loss: 2.970074167577821
Validation loss: 2.7713588478710918

Epoch: 6| Step: 12
Training loss: 2.6086717217494937
Validation loss: 2.7008670270087847

Epoch: 6| Step: 13
Training loss: 2.674399003582859
Validation loss: 2.674641789858275

Epoch: 478| Step: 0
Training loss: 2.404723835274643
Validation loss: 2.7988636405682605

Epoch: 6| Step: 1
Training loss: 2.9727505682721027
Validation loss: 2.805539142657155

Epoch: 6| Step: 2
Training loss: 2.492960077675344
Validation loss: 2.759081225905982

Epoch: 6| Step: 3
Training loss: 2.0309976274259562
Validation loss: 2.8984818710142886

Epoch: 6| Step: 4
Training loss: 2.078626529148674
Validation loss: 2.8125291273643755

Epoch: 6| Step: 5
Training loss: 2.0598745107853307
Validation loss: 2.8591535879135304

Epoch: 6| Step: 6
Training loss: 1.9944423107335334
Validation loss: 2.8285210879979954

Epoch: 6| Step: 7
Training loss: 2.8221438899729527
Validation loss: 2.8351039915307146

Epoch: 6| Step: 8
Training loss: 2.6600775574011295
Validation loss: 2.813516543861867

Epoch: 6| Step: 9
Training loss: 3.184353041643348
Validation loss: 2.747306362169379

Epoch: 6| Step: 10
Training loss: 2.444306480483212
Validation loss: 2.839207682165498

Epoch: 6| Step: 11
Training loss: 2.4768339664160743
Validation loss: 2.702458097554165

Epoch: 6| Step: 12
Training loss: 1.6359863827751913
Validation loss: 2.7089654583934464

Epoch: 6| Step: 13
Training loss: 2.425382080652881
Validation loss: 2.8213564273778733

Epoch: 479| Step: 0
Training loss: 3.1629968426303017
Validation loss: 2.7246729936514855

Epoch: 6| Step: 1
Training loss: 2.2310125486396304
Validation loss: 2.4422584975018355

Epoch: 6| Step: 2
Training loss: 2.5428879310434014
Validation loss: 2.792065151342274

Epoch: 6| Step: 3
Training loss: 2.123378808429366
Validation loss: 2.9070630567595166

Epoch: 6| Step: 4
Training loss: 1.8273929532241182
Validation loss: 2.5829652764879754

Epoch: 6| Step: 5
Training loss: 1.365661117809352
Validation loss: 2.921125930914152

Epoch: 6| Step: 6
Training loss: 2.4352020778266175
Validation loss: 2.8431478135706776

Epoch: 6| Step: 7
Training loss: 2.653176088593854
Validation loss: 2.9158212699326773

Epoch: 6| Step: 8
Training loss: 2.2658085189682087
Validation loss: 2.6709350110711214

Epoch: 6| Step: 9
Training loss: 1.74237853230264
Validation loss: 2.749218614377506

Epoch: 6| Step: 10
Training loss: 3.0467219387636204
Validation loss: 2.728599210046351

Epoch: 6| Step: 11
Training loss: 2.5705466120347933
Validation loss: 2.76831185019803

Epoch: 6| Step: 12
Training loss: 3.118770188015901
Validation loss: 2.823596743619671

Epoch: 6| Step: 13
Training loss: 1.9274357928752746
Validation loss: 2.5929496381290535

Epoch: 480| Step: 0
Training loss: 2.641825295949304
Validation loss: 2.762391592911109

Epoch: 6| Step: 1
Training loss: 2.3470716208674682
Validation loss: 2.680667126628779

Epoch: 6| Step: 2
Training loss: 3.372831424973543
Validation loss: 2.67703010164925

Epoch: 6| Step: 3
Training loss: 2.184559507859121
Validation loss: 2.627869901081702

Epoch: 6| Step: 4
Training loss: 2.3912520240818993
Validation loss: 2.6183348260196686

Epoch: 6| Step: 5
Training loss: 2.1547450466645675
Validation loss: 2.755703358207017

Epoch: 6| Step: 6
Training loss: 2.5204623135846407
Validation loss: 2.62370586332482

Epoch: 6| Step: 7
Training loss: 1.7452346770746807
Validation loss: 2.8508734396041735

Epoch: 6| Step: 8
Training loss: 1.9245204551166704
Validation loss: 2.626135522399534

Epoch: 6| Step: 9
Training loss: 1.8763976927590806
Validation loss: 2.7613377457467974

Epoch: 6| Step: 10
Training loss: 2.335620973505475
Validation loss: 2.6847493250367442

Epoch: 6| Step: 11
Training loss: 2.4239823555886453
Validation loss: 2.7064608911042867

Epoch: 6| Step: 12
Training loss: 2.4738440771656247
Validation loss: 2.8121785061028364

Epoch: 6| Step: 13
Training loss: 2.372008397066586
Validation loss: 2.6284776095692113

Epoch: 481| Step: 0
Training loss: 2.3790987685403
Validation loss: 2.7448445468542646

Epoch: 6| Step: 1
Training loss: 2.1581464526990763
Validation loss: 2.8581160247098447

Epoch: 6| Step: 2
Training loss: 2.3652503015437154
Validation loss: 2.739113889615215

Epoch: 6| Step: 3
Training loss: 2.902617122051505
Validation loss: 2.7950654850615066

Epoch: 6| Step: 4
Training loss: 2.233023494844564
Validation loss: 2.726082125276256

Epoch: 6| Step: 5
Training loss: 2.92570725717935
Validation loss: 2.8665579100433103

Epoch: 6| Step: 6
Training loss: 2.495598733497686
Validation loss: 2.6887431492547083

Epoch: 6| Step: 7
Training loss: 2.0553693329022424
Validation loss: 2.7950914472706923

Epoch: 6| Step: 8
Training loss: 2.4331102212319378
Validation loss: 2.8215317224498966

Epoch: 6| Step: 9
Training loss: 2.202355974318404
Validation loss: 2.8132106466565556

Epoch: 6| Step: 10
Training loss: 2.5042521554717316
Validation loss: 2.6269040465864273

Epoch: 6| Step: 11
Training loss: 3.1327252839617055
Validation loss: 2.7257989261492006

Epoch: 6| Step: 12
Training loss: 2.566625577011493
Validation loss: 2.6840671020876545

Epoch: 6| Step: 13
Training loss: 1.5542276747169177
Validation loss: 2.7235881663939967

Epoch: 482| Step: 0
Training loss: 2.179874644568796
Validation loss: 2.815309353345807

Epoch: 6| Step: 1
Training loss: 2.339478325688175
Validation loss: 2.730860857725732

Epoch: 6| Step: 2
Training loss: 2.284326125429676
Validation loss: 2.674699601081613

Epoch: 6| Step: 3
Training loss: 2.0558129770884164
Validation loss: 2.8012206616075437

Epoch: 6| Step: 4
Training loss: 2.0754639072501
Validation loss: 2.855085969640617

Epoch: 6| Step: 5
Training loss: 2.862135924794969
Validation loss: 2.8395569196602635

Epoch: 6| Step: 6
Training loss: 2.6821128612783554
Validation loss: 2.852888498501691

Epoch: 6| Step: 7
Training loss: 2.6307304141149217
Validation loss: 2.782459088857186

Epoch: 6| Step: 8
Training loss: 2.413863781894899
Validation loss: 2.81283543636192

Epoch: 6| Step: 9
Training loss: 2.9995790822063944
Validation loss: 2.7068961432848586

Epoch: 6| Step: 10
Training loss: 2.46517705099679
Validation loss: 2.7549550841675337

Epoch: 6| Step: 11
Training loss: 2.003499307638515
Validation loss: 2.6302088648648225

Epoch: 6| Step: 12
Training loss: 1.8856636714541757
Validation loss: 2.7431482647186423

Epoch: 6| Step: 13
Training loss: 2.4270337690496144
Validation loss: 2.687343570919546

Epoch: 483| Step: 0
Training loss: 1.976643918739042
Validation loss: 2.8176295074366555

Epoch: 6| Step: 1
Training loss: 2.2408494312885137
Validation loss: 2.74898342461247

Epoch: 6| Step: 2
Training loss: 1.8730488479810712
Validation loss: 2.598391530502072

Epoch: 6| Step: 3
Training loss: 2.4562296082715487
Validation loss: 2.735219448971236

Epoch: 6| Step: 4
Training loss: 2.1951899918553286
Validation loss: 2.7858159726831366

Epoch: 6| Step: 5
Training loss: 3.475143451611364
Validation loss: 2.6927605550098335

Epoch: 6| Step: 6
Training loss: 1.849673244900239
Validation loss: 2.7862031491842223

Epoch: 6| Step: 7
Training loss: 2.6878152706724943
Validation loss: 2.7741202572854204

Epoch: 6| Step: 8
Training loss: 1.6747499507044756
Validation loss: 2.7662657800765604

Epoch: 6| Step: 9
Training loss: 2.406030025583386
Validation loss: 2.910543728954113

Epoch: 6| Step: 10
Training loss: 2.190495646925421
Validation loss: 2.8102029688078924

Epoch: 6| Step: 11
Training loss: 2.7736376193206183
Validation loss: 2.823534530360775

Epoch: 6| Step: 12
Training loss: 2.3240730817009423
Validation loss: 2.7735353116655617

Epoch: 6| Step: 13
Training loss: 1.8830178809631244
Validation loss: 2.8144346431006846

Epoch: 484| Step: 0
Training loss: 2.9689849760524054
Validation loss: 2.7377588834912094

Epoch: 6| Step: 1
Training loss: 2.0450536180849355
Validation loss: 2.8287072668663713

Epoch: 6| Step: 2
Training loss: 2.589090044868469
Validation loss: 2.703123849117753

Epoch: 6| Step: 3
Training loss: 1.6330356719167416
Validation loss: 2.804891233790892

Epoch: 6| Step: 4
Training loss: 2.551194816115894
Validation loss: 2.824581479629477

Epoch: 6| Step: 5
Training loss: 1.8746940363156233
Validation loss: 2.703996856656407

Epoch: 6| Step: 6
Training loss: 2.498930702411842
Validation loss: 2.5990209029204543

Epoch: 6| Step: 7
Training loss: 2.0224597586458417
Validation loss: 2.68812365830367

Epoch: 6| Step: 8
Training loss: 2.160142784697521
Validation loss: 2.713574567040343

Epoch: 6| Step: 9
Training loss: 2.5202601598234575
Validation loss: 2.669443214226737

Epoch: 6| Step: 10
Training loss: 2.4092217462190635
Validation loss: 2.746310913384822

Epoch: 6| Step: 11
Training loss: 2.6072208855704546
Validation loss: 2.795911109431433

Epoch: 6| Step: 12
Training loss: 2.0772239624698123
Validation loss: 2.70654479921562

Epoch: 6| Step: 13
Training loss: 2.5273259205019762
Validation loss: 2.7349308659535647

Epoch: 485| Step: 0
Training loss: 1.8168770128782898
Validation loss: 2.6439241402616585

Epoch: 6| Step: 1
Training loss: 1.8519425786717216
Validation loss: 2.794355208702556

Epoch: 6| Step: 2
Training loss: 3.082109534909599
Validation loss: 2.770122258421146

Epoch: 6| Step: 3
Training loss: 2.2744605001096057
Validation loss: 2.7955632990836206

Epoch: 6| Step: 4
Training loss: 3.089497736137167
Validation loss: 2.8068213328619422

Epoch: 6| Step: 5
Training loss: 2.353130742809487
Validation loss: 2.650436517646683

Epoch: 6| Step: 6
Training loss: 1.7670914628083907
Validation loss: 2.7383699537767767

Epoch: 6| Step: 7
Training loss: 2.1216479397666714
Validation loss: 2.905803246926058

Epoch: 6| Step: 8
Training loss: 2.6247632964451713
Validation loss: 2.8542165827460044

Epoch: 6| Step: 9
Training loss: 2.6212284604971696
Validation loss: 2.7821807585158562

Epoch: 6| Step: 10
Training loss: 2.0103686496620328
Validation loss: 2.706103124305788

Epoch: 6| Step: 11
Training loss: 2.9195426567085505
Validation loss: 2.729225987178981

Epoch: 6| Step: 12
Training loss: 2.3179022089989427
Validation loss: 2.670686225269076

Epoch: 6| Step: 13
Training loss: 2.5748297699889573
Validation loss: 2.6335067040722775

Epoch: 486| Step: 0
Training loss: 2.1790834088828843
Validation loss: 2.632380858173512

Epoch: 6| Step: 1
Training loss: 2.153242584694079
Validation loss: 2.695099382147359

Epoch: 6| Step: 2
Training loss: 2.2190504273662497
Validation loss: 2.7455494824913536

Epoch: 6| Step: 3
Training loss: 1.9839498710298296
Validation loss: 2.7995768737149476

Epoch: 6| Step: 4
Training loss: 2.2777199802457377
Validation loss: 2.7120667773727747

Epoch: 6| Step: 5
Training loss: 2.5050944872794227
Validation loss: 2.7374098589070734

Epoch: 6| Step: 6
Training loss: 1.7332389478783659
Validation loss: 2.9486407808835584

Epoch: 6| Step: 7
Training loss: 2.1253977010728673
Validation loss: 2.8145984947064817

Epoch: 6| Step: 8
Training loss: 2.9641829848749666
Validation loss: 2.8396726187352104

Epoch: 6| Step: 9
Training loss: 2.1594548388680974
Validation loss: 2.725930522867503

Epoch: 6| Step: 10
Training loss: 3.0868151997969937
Validation loss: 2.811038699791385

Epoch: 6| Step: 11
Training loss: 2.5844004693211997
Validation loss: 2.623497251051651

Epoch: 6| Step: 12
Training loss: 1.7040697329808572
Validation loss: 2.74890441362923

Epoch: 6| Step: 13
Training loss: 2.501014598957879
Validation loss: 2.76713116378054

Epoch: 487| Step: 0
Training loss: 2.5271317689367883
Validation loss: 2.7340879903195683

Epoch: 6| Step: 1
Training loss: 2.249705295336044
Validation loss: 2.8025525748469575

Epoch: 6| Step: 2
Training loss: 2.055413179650459
Validation loss: 2.6527710245044305

Epoch: 6| Step: 3
Training loss: 2.1403685924360825
Validation loss: 2.6264647651755335

Epoch: 6| Step: 4
Training loss: 2.5224926954301643
Validation loss: 2.7419511312029825

Epoch: 6| Step: 5
Training loss: 3.295480731632864
Validation loss: 2.8368154954433438

Epoch: 6| Step: 6
Training loss: 2.485003697720699
Validation loss: 2.7965141591124403

Epoch: 6| Step: 7
Training loss: 2.5409891653479217
Validation loss: 2.924995826793239

Epoch: 6| Step: 8
Training loss: 2.1794760543372447
Validation loss: 2.6383395186802425

Epoch: 6| Step: 9
Training loss: 1.5708844865451945
Validation loss: 2.7541949232930367

Epoch: 6| Step: 10
Training loss: 2.190394094707757
Validation loss: 2.7902088212630938

Epoch: 6| Step: 11
Training loss: 2.8220532400082248
Validation loss: 2.757668121276027

Epoch: 6| Step: 12
Training loss: 2.6583758654724625
Validation loss: 2.702942288580588

Epoch: 6| Step: 13
Training loss: 1.1943417265931857
Validation loss: 2.684232147788632

Epoch: 488| Step: 0
Training loss: 2.1746040597709877
Validation loss: 2.6807453745309475

Epoch: 6| Step: 1
Training loss: 2.3783012334862352
Validation loss: 2.712054323386315

Epoch: 6| Step: 2
Training loss: 2.454312565541023
Validation loss: 2.695799834553672

Epoch: 6| Step: 3
Training loss: 1.9294150465160191
Validation loss: 2.7576332651058

Epoch: 6| Step: 4
Training loss: 2.98925111278243
Validation loss: 2.7147767072915863

Epoch: 6| Step: 5
Training loss: 3.0208852478477337
Validation loss: 2.986436307776603

Epoch: 6| Step: 6
Training loss: 1.9740711538908062
Validation loss: 2.8740249432024947

Epoch: 6| Step: 7
Training loss: 2.6345457263800163
Validation loss: 2.780992701354671

Epoch: 6| Step: 8
Training loss: 2.5192603150414263
Validation loss: 2.770095545317891

Epoch: 6| Step: 9
Training loss: 2.00743972345788
Validation loss: 2.805810328882297

Epoch: 6| Step: 10
Training loss: 2.172192776711588
Validation loss: 2.8505518128096194

Epoch: 6| Step: 11
Training loss: 2.4452400562414534
Validation loss: 2.896419973584511

Epoch: 6| Step: 12
Training loss: 1.9216423824305524
Validation loss: 2.796882224702352

Epoch: 6| Step: 13
Training loss: 2.437740607490711
Validation loss: 2.8240411806677996

Epoch: 489| Step: 0
Training loss: 1.9546827894073249
Validation loss: 2.5957260995628357

Epoch: 6| Step: 1
Training loss: 2.0523913647690266
Validation loss: 2.715277021125586

Epoch: 6| Step: 2
Training loss: 1.7928174189778856
Validation loss: 2.7718072019132833

Epoch: 6| Step: 3
Training loss: 3.068101237102655
Validation loss: 2.740559668832218

Epoch: 6| Step: 4
Training loss: 2.517434648046268
Validation loss: 2.7717109016466654

Epoch: 6| Step: 5
Training loss: 2.8213738217137774
Validation loss: 2.765838086467229

Epoch: 6| Step: 6
Training loss: 2.2719032380291924
Validation loss: 2.6178709594509177

Epoch: 6| Step: 7
Training loss: 2.6916219461542674
Validation loss: 2.744296590113916

Epoch: 6| Step: 8
Training loss: 1.9216070220946013
Validation loss: 2.8080360563683975

Epoch: 6| Step: 9
Training loss: 1.4434787148576844
Validation loss: 2.5392954416754687

Epoch: 6| Step: 10
Training loss: 2.282307941257447
Validation loss: 2.775747611958726

Epoch: 6| Step: 11
Training loss: 2.559478839635521
Validation loss: 2.79358497830205

Epoch: 6| Step: 12
Training loss: 2.0803470061690814
Validation loss: 2.802347482683437

Epoch: 6| Step: 13
Training loss: 2.9938845291651797
Validation loss: 2.850125070391943

Epoch: 490| Step: 0
Training loss: 1.1286299212216746
Validation loss: 2.769108991563303

Epoch: 6| Step: 1
Training loss: 2.4482203734817967
Validation loss: 2.719743386145868

Epoch: 6| Step: 2
Training loss: 1.854037276764632
Validation loss: 2.777539996528751

Epoch: 6| Step: 3
Training loss: 2.8685442549450277
Validation loss: 2.7917041433209824

Epoch: 6| Step: 4
Training loss: 2.4503325100463487
Validation loss: 2.7297676424830573

Epoch: 6| Step: 5
Training loss: 3.4799818047234177
Validation loss: 2.8264105629029252

Epoch: 6| Step: 6
Training loss: 2.4892544602333744
Validation loss: 2.8550781873517805

Epoch: 6| Step: 7
Training loss: 2.00063945561257
Validation loss: 2.9112337832880084

Epoch: 6| Step: 8
Training loss: 2.7632376501576514
Validation loss: 2.7345255876787897

Epoch: 6| Step: 9
Training loss: 1.7580542504117291
Validation loss: 2.743327598396327

Epoch: 6| Step: 10
Training loss: 2.1354826257955044
Validation loss: 2.9187740330471805

Epoch: 6| Step: 11
Training loss: 2.2149773343823167
Validation loss: 2.8022606814856896

Epoch: 6| Step: 12
Training loss: 2.176063724720719
Validation loss: 2.867598124304825

Epoch: 6| Step: 13
Training loss: 1.7855346412214552
Validation loss: 2.869914498436346

Epoch: 491| Step: 0
Training loss: 2.5617584458114466
Validation loss: 2.8284620366234363

Epoch: 6| Step: 1
Training loss: 1.896822018331207
Validation loss: 2.8255375127790097

Epoch: 6| Step: 2
Training loss: 2.1911895155188934
Validation loss: 2.878696815774886

Epoch: 6| Step: 3
Training loss: 2.3550514876453232
Validation loss: 2.7682843495931224

Epoch: 6| Step: 4
Training loss: 2.630719357441224
Validation loss: 2.6705597415162154

Epoch: 6| Step: 5
Training loss: 1.9145616153098204
Validation loss: 2.8199224301435226

Epoch: 6| Step: 6
Training loss: 3.35112398564468
Validation loss: 2.790194726853251

Epoch: 6| Step: 7
Training loss: 2.444778530333153
Validation loss: 2.5923993324736045

Epoch: 6| Step: 8
Training loss: 2.363186013060381
Validation loss: 2.746477776265815

Epoch: 6| Step: 9
Training loss: 2.0683335544894477
Validation loss: 2.744091947787473

Epoch: 6| Step: 10
Training loss: 2.807385944960832
Validation loss: 2.558031366183878

Epoch: 6| Step: 11
Training loss: 1.8748335446540079
Validation loss: 2.650070996357939

Epoch: 6| Step: 12
Training loss: 2.070915393495495
Validation loss: 2.847710146457886

Epoch: 6| Step: 13
Training loss: 2.3861791621984523
Validation loss: 2.7101989886317286

Epoch: 492| Step: 0
Training loss: 2.4054429323273485
Validation loss: 2.7312416894364415

Epoch: 6| Step: 1
Training loss: 2.3392914134448066
Validation loss: 2.76624544985678

Epoch: 6| Step: 2
Training loss: 2.0368469595932335
Validation loss: 2.735285363602938

Epoch: 6| Step: 3
Training loss: 2.352801531967396
Validation loss: 2.609652038765762

Epoch: 6| Step: 4
Training loss: 1.5895111710886927
Validation loss: 2.633417153987722

Epoch: 6| Step: 5
Training loss: 2.322299299324816
Validation loss: 2.7846682500015474

Epoch: 6| Step: 6
Training loss: 2.567196426794003
Validation loss: 2.801232954829476

Epoch: 6| Step: 7
Training loss: 2.192024021483455
Validation loss: 2.6927507926792473

Epoch: 6| Step: 8
Training loss: 2.8595911163204892
Validation loss: 2.9049856148231017

Epoch: 6| Step: 9
Training loss: 2.7332921963209036
Validation loss: 2.8073171106513737

Epoch: 6| Step: 10
Training loss: 2.161622031267444
Validation loss: 2.773916950117151

Epoch: 6| Step: 11
Training loss: 2.468903741998837
Validation loss: 2.7850236187885886

Epoch: 6| Step: 12
Training loss: 2.886338803861014
Validation loss: 2.747176386650809

Epoch: 6| Step: 13
Training loss: 3.3670872365800437
Validation loss: 2.7721293512765435

Epoch: 493| Step: 0
Training loss: 3.641183703860434
Validation loss: 2.7840235781660687

Epoch: 6| Step: 1
Training loss: 2.661667717885873
Validation loss: 2.7345069640115347

Epoch: 6| Step: 2
Training loss: 2.198493797378518
Validation loss: 2.776632595643796

Epoch: 6| Step: 3
Training loss: 1.6048264901086635
Validation loss: 2.7558532651053835

Epoch: 6| Step: 4
Training loss: 2.1464401670976474
Validation loss: 2.6764833481751324

Epoch: 6| Step: 5
Training loss: 2.0719180233546184
Validation loss: 2.7695735096988683

Epoch: 6| Step: 6
Training loss: 2.059614880126199
Validation loss: 2.736599088508952

Epoch: 6| Step: 7
Training loss: 2.2778781375123405
Validation loss: 2.7685387994005386

Epoch: 6| Step: 8
Training loss: 1.880160287963518
Validation loss: 2.6691450425628385

Epoch: 6| Step: 9
Training loss: 1.8896197334100584
Validation loss: 2.716447248442655

Epoch: 6| Step: 10
Training loss: 2.1026377143164763
Validation loss: 2.625190919338888

Epoch: 6| Step: 11
Training loss: 1.5041368976440437
Validation loss: 2.5824022765434425

Epoch: 6| Step: 12
Training loss: 2.354489757231222
Validation loss: 2.650322857268911

Epoch: 6| Step: 13
Training loss: 3.1577853254973287
Validation loss: 2.7597828789696424

Epoch: 494| Step: 0
Training loss: 2.1110796786639696
Validation loss: 2.6113582357194653

Epoch: 6| Step: 1
Training loss: 2.4564720694058373
Validation loss: 2.829174727351481

Epoch: 6| Step: 2
Training loss: 2.8824780277893667
Validation loss: 2.660379025304485

Epoch: 6| Step: 3
Training loss: 2.0164480968391163
Validation loss: 2.862488891161585

Epoch: 6| Step: 4
Training loss: 2.204375649287986
Validation loss: 2.813714317410804

Epoch: 6| Step: 5
Training loss: 2.882796124667668
Validation loss: 2.7481918981789417

Epoch: 6| Step: 6
Training loss: 2.3421061536673324
Validation loss: 2.8112234365519915

Epoch: 6| Step: 7
Training loss: 2.5605162408481648
Validation loss: 2.65136139085196

Epoch: 6| Step: 8
Training loss: 2.1685851724305065
Validation loss: 2.6431669425015274

Epoch: 6| Step: 9
Training loss: 2.7298663652291255
Validation loss: 2.8768372116060683

Epoch: 6| Step: 10
Training loss: 2.44063308069745
Validation loss: 2.7155864094917166

Epoch: 6| Step: 11
Training loss: 2.1405964870363823
Validation loss: 2.677698080992504

Epoch: 6| Step: 12
Training loss: 2.5217160237438985
Validation loss: 2.729424603849625

Epoch: 6| Step: 13
Training loss: 2.4810281918641035
Validation loss: 2.8151404962319138

Epoch: 495| Step: 0
Training loss: 1.7093027744690932
Validation loss: 2.7517341252922534

Epoch: 6| Step: 1
Training loss: 2.29722779347755
Validation loss: 2.8005691205196093

Epoch: 6| Step: 2
Training loss: 2.1282518973586844
Validation loss: 2.7452515449989154

Epoch: 6| Step: 3
Training loss: 2.3705014238399533
Validation loss: 2.781304149093649

Epoch: 6| Step: 4
Training loss: 1.9492855939698832
Validation loss: 2.6718424078030476

Epoch: 6| Step: 5
Training loss: 1.9456513504219304
Validation loss: 2.8539730243160677

Epoch: 6| Step: 6
Training loss: 1.7681391547490375
Validation loss: 2.783986214827047

Epoch: 6| Step: 7
Training loss: 2.4426860903206427
Validation loss: 2.7727950710160396

Epoch: 6| Step: 8
Training loss: 3.293527358925269
Validation loss: 2.713571668555899

Epoch: 6| Step: 9
Training loss: 2.7341227387822804
Validation loss: 2.7865287200683055

Epoch: 6| Step: 10
Training loss: 2.25755176556655
Validation loss: 2.7874431946996494

Epoch: 6| Step: 11
Training loss: 2.385176689592654
Validation loss: 2.6528844311733595

Epoch: 6| Step: 12
Training loss: 2.4516289881290296
Validation loss: 2.6386976694328057

Epoch: 6| Step: 13
Training loss: 1.9189668066941887
Validation loss: 2.8607342181046866

Epoch: 496| Step: 0
Training loss: 2.618537395286754
Validation loss: 2.6647908172057964

Epoch: 6| Step: 1
Training loss: 1.8776575963587765
Validation loss: 2.7223441177103305

Epoch: 6| Step: 2
Training loss: 1.9572574690314368
Validation loss: 2.5531211286574615

Epoch: 6| Step: 3
Training loss: 2.197679431520445
Validation loss: 2.708285299274329

Epoch: 6| Step: 4
Training loss: 2.176883329364044
Validation loss: 2.560723665752434

Epoch: 6| Step: 5
Training loss: 1.9729296202135336
Validation loss: 2.6489737756610716

Epoch: 6| Step: 6
Training loss: 1.5636571032941107
Validation loss: 2.7557571645788355

Epoch: 6| Step: 7
Training loss: 2.796885740802962
Validation loss: 2.688269938675776

Epoch: 6| Step: 8
Training loss: 2.161394037110028
Validation loss: 2.804236554579798

Epoch: 6| Step: 9
Training loss: 2.9174456146584373
Validation loss: 2.7523119452127984

Epoch: 6| Step: 10
Training loss: 2.572720312947909
Validation loss: 2.717221149041233

Epoch: 6| Step: 11
Training loss: 2.319927864433094
Validation loss: 2.694098268911478

Epoch: 6| Step: 12
Training loss: 2.296619219389054
Validation loss: 2.6568042444717768

Epoch: 6| Step: 13
Training loss: 1.8500115059159725
Validation loss: 2.5921959331209394

Epoch: 497| Step: 0
Training loss: 1.8473249787676653
Validation loss: 2.8505022258774066

Epoch: 6| Step: 1
Training loss: 2.716549563858158
Validation loss: 2.709451878597101

Epoch: 6| Step: 2
Training loss: 2.685194224005013
Validation loss: 2.8261106645627683

Epoch: 6| Step: 3
Training loss: 2.006595821819824
Validation loss: 2.8696267206192414

Epoch: 6| Step: 4
Training loss: 2.044926188846035
Validation loss: 2.8187804683370756

Epoch: 6| Step: 5
Training loss: 2.07138252676916
Validation loss: 2.822134150071871

Epoch: 6| Step: 6
Training loss: 2.2077084742914983
Validation loss: 2.7194186944030236

Epoch: 6| Step: 7
Training loss: 2.235830193269875
Validation loss: 2.6232397952752238

Epoch: 6| Step: 8
Training loss: 1.8131262256469582
Validation loss: 2.6470015828187377

Epoch: 6| Step: 9
Training loss: 3.1525314634418358
Validation loss: 2.778053807794367

Epoch: 6| Step: 10
Training loss: 3.095566033537835
Validation loss: 2.87459864050779

Epoch: 6| Step: 11
Training loss: 2.3182232116974695
Validation loss: 2.718817387906608

Epoch: 6| Step: 12
Training loss: 2.355520269991343
Validation loss: 2.808106824926713

Epoch: 6| Step: 13
Training loss: 2.5143754592428564
Validation loss: 2.778028162538001

Epoch: 498| Step: 0
Training loss: 3.275345639924758
Validation loss: 2.750111119923612

Epoch: 6| Step: 1
Training loss: 1.9694577110691402
Validation loss: 2.806575850013026

Epoch: 6| Step: 2
Training loss: 2.0856516209984792
Validation loss: 2.6439441214487687

Epoch: 6| Step: 3
Training loss: 2.4135470040539064
Validation loss: 2.8113938848901903

Epoch: 6| Step: 4
Training loss: 2.372671893598618
Validation loss: 2.794583827026429

Epoch: 6| Step: 5
Training loss: 1.7403046564879951
Validation loss: 2.6258601348404036

Epoch: 6| Step: 6
Training loss: 2.1125859440583037
Validation loss: 2.7748969201836204

Epoch: 6| Step: 7
Training loss: 2.165823099783185
Validation loss: 2.816585616811916

Epoch: 6| Step: 8
Training loss: 1.7120480351705805
Validation loss: 2.7867258680452873

Epoch: 6| Step: 9
Training loss: 2.728358772810161
Validation loss: 2.72526026929101

Epoch: 6| Step: 10
Training loss: 2.6700690339839968
Validation loss: 2.725169998635928

Epoch: 6| Step: 11
Training loss: 1.9440762678381496
Validation loss: 2.6764595515125706

Epoch: 6| Step: 12
Training loss: 1.7910889721809775
Validation loss: 2.762215623244012

Epoch: 6| Step: 13
Training loss: 2.7023382199515638
Validation loss: 2.757182818656914

Epoch: 499| Step: 0
Training loss: 2.2025240897031426
Validation loss: 2.7896252935787444

Epoch: 6| Step: 1
Training loss: 2.0928840554570103
Validation loss: 2.648399542237872

Epoch: 6| Step: 2
Training loss: 2.2826599571442854
Validation loss: 2.6694681595988716

Epoch: 6| Step: 3
Training loss: 1.8706977441104553
Validation loss: 2.582463916697663

Epoch: 6| Step: 4
Training loss: 2.192610520259968
Validation loss: 2.7898468066539768

Epoch: 6| Step: 5
Training loss: 1.8631815693740967
Validation loss: 2.8254268441016497

Epoch: 6| Step: 6
Training loss: 2.2461237897108064
Validation loss: 2.661474055718643

Epoch: 6| Step: 7
Training loss: 2.0128532099711984
Validation loss: 2.6858152358585037

Epoch: 6| Step: 8
Training loss: 1.9674483946608832
Validation loss: 2.712759626142453

Epoch: 6| Step: 9
Training loss: 3.174735747626996
Validation loss: 2.8401627856830864

Epoch: 6| Step: 10
Training loss: 3.0424766681312523
Validation loss: 2.7740951837465637

Epoch: 6| Step: 11
Training loss: 2.3687049358177834
Validation loss: 2.665645496774467

Epoch: 6| Step: 12
Training loss: 2.2166640456143516
Validation loss: 2.6669058650804716

Epoch: 6| Step: 13
Training loss: 1.974817463129201
Validation loss: 2.5902711568225776

Epoch: 500| Step: 0
Training loss: 1.9682529972595784
Validation loss: 2.5749315288379395

Epoch: 6| Step: 1
Training loss: 1.3589713714144145
Validation loss: 2.7062327193823186

Epoch: 6| Step: 2
Training loss: 2.142530720689699
Validation loss: 2.6579232815367986

Epoch: 6| Step: 3
Training loss: 1.707743341244468
Validation loss: 2.7482783166339977

Epoch: 6| Step: 4
Training loss: 1.9997080351390202
Validation loss: 2.7660281193034053

Epoch: 6| Step: 5
Training loss: 2.357026605092581
Validation loss: 2.8453652762716954

Epoch: 6| Step: 6
Training loss: 1.936634608784185
Validation loss: 2.903848810586345

Epoch: 6| Step: 7
Training loss: 2.452479964085979
Validation loss: 2.6487973733068695

Epoch: 6| Step: 8
Training loss: 2.4245036964254587
Validation loss: 2.714268459021116

Epoch: 6| Step: 9
Training loss: 2.899693466297141
Validation loss: 2.795048758909379

Epoch: 6| Step: 10
Training loss: 2.319700012543294
Validation loss: 2.837565634801702

Epoch: 6| Step: 11
Training loss: 1.7378963430065801
Validation loss: 2.797575313381994

Epoch: 6| Step: 12
Training loss: 3.603100892885394
Validation loss: 2.847121497359388

Epoch: 6| Step: 13
Training loss: 2.3769521219569576
Validation loss: 2.8681577502913207

Epoch: 501| Step: 0
Training loss: 1.8257628610098695
Validation loss: 2.8365557446511915

Epoch: 6| Step: 1
Training loss: 2.3911035594777608
Validation loss: 2.8157135063960843

Epoch: 6| Step: 2
Training loss: 1.7185075068638662
Validation loss: 2.838314221066054

Epoch: 6| Step: 3
Training loss: 2.864337055138919
Validation loss: 2.7417221588354685

Epoch: 6| Step: 4
Training loss: 2.579025481205787
Validation loss: 2.6640014699185213

Epoch: 6| Step: 5
Training loss: 2.7461293463753536
Validation loss: 2.736534177003598

Epoch: 6| Step: 6
Training loss: 2.6338298880723063
Validation loss: 2.691721103150386

Epoch: 6| Step: 7
Training loss: 3.6511376005983966
Validation loss: 2.852112212935578

Epoch: 6| Step: 8
Training loss: 1.9094650172415026
Validation loss: 2.6558728311624513

Epoch: 6| Step: 9
Training loss: 1.9644099642111534
Validation loss: 2.7211012733608455

Epoch: 6| Step: 10
Training loss: 1.7594576448641908
Validation loss: 2.850753129448625

Epoch: 6| Step: 11
Training loss: 3.3449683420824314
Validation loss: 2.8571534555615097

Epoch: 6| Step: 12
Training loss: 2.0740804680026868
Validation loss: 2.763617224583972

Epoch: 6| Step: 13
Training loss: 1.7427125832307675
Validation loss: 2.8721119953310734

Epoch: 502| Step: 0
Training loss: 3.218431623694069
Validation loss: 2.7937506202839666

Epoch: 6| Step: 1
Training loss: 1.9541661043579768
Validation loss: 2.768051613303063

Epoch: 6| Step: 2
Training loss: 1.8517148884704102
Validation loss: 2.710868120347392

Epoch: 6| Step: 3
Training loss: 3.00147274742991
Validation loss: 2.792210562821043

Epoch: 6| Step: 4
Training loss: 2.043282187580437
Validation loss: 2.9214916564537305

Epoch: 6| Step: 5
Training loss: 2.1842247557917376
Validation loss: 2.812814462963518

Epoch: 6| Step: 6
Training loss: 2.128750128664829
Validation loss: 2.5695386032534895

Epoch: 6| Step: 7
Training loss: 1.863073181434998
Validation loss: 2.580859555547344

Epoch: 6| Step: 8
Training loss: 2.049190231049168
Validation loss: 2.7641986654018407

Epoch: 6| Step: 9
Training loss: 1.052393247577343
Validation loss: 2.5741891599240407

Epoch: 6| Step: 10
Training loss: 2.124855709787032
Validation loss: 2.5930563410201413

Epoch: 6| Step: 11
Training loss: 2.0654631627754165
Validation loss: 2.68613620542205

Epoch: 6| Step: 12
Training loss: 2.0023490700295716
Validation loss: 2.78219877280627

Epoch: 6| Step: 13
Training loss: 3.2200225980925294
Validation loss: 2.824525243066221

Epoch: 503| Step: 0
Training loss: 1.9963062867486254
Validation loss: 2.7755565095080073

Epoch: 6| Step: 1
Training loss: 2.3398386552401753
Validation loss: 2.565575912285975

Epoch: 6| Step: 2
Training loss: 2.6498637902144053
Validation loss: 2.7615140220076047

Epoch: 6| Step: 3
Training loss: 2.483928520341324
Validation loss: 2.8158431333970952

Epoch: 6| Step: 4
Training loss: 2.2241504118711184
Validation loss: 2.7069958478815757

Epoch: 6| Step: 5
Training loss: 2.2792669586859544
Validation loss: 2.8307994705461286

Epoch: 6| Step: 6
Training loss: 2.255044157352873
Validation loss: 2.6951524636753157

Epoch: 6| Step: 7
Training loss: 2.260067246204622
Validation loss: 2.8546469882836045

Epoch: 6| Step: 8
Training loss: 1.8188015802678998
Validation loss: 2.595578666534159

Epoch: 6| Step: 9
Training loss: 2.0016819318982817
Validation loss: 2.973833096159921

Epoch: 6| Step: 10
Training loss: 2.814047663097252
Validation loss: 2.7143935464056046

Epoch: 6| Step: 11
Training loss: 2.2928628978309
Validation loss: 2.84956263619021

Epoch: 6| Step: 12
Training loss: 2.3966389725119193
Validation loss: 2.8722090628008923

Epoch: 6| Step: 13
Training loss: 2.4119430175743446
Validation loss: 2.9411555009042507

Epoch: 504| Step: 0
Training loss: 2.4073775981079133
Validation loss: 2.9039637685070585

Epoch: 6| Step: 1
Training loss: 2.2154839345684847
Validation loss: 2.7550032567816283

Epoch: 6| Step: 2
Training loss: 2.35840935556479
Validation loss: 2.890576211372916

Epoch: 6| Step: 3
Training loss: 1.491293914225072
Validation loss: 2.775305522805443

Epoch: 6| Step: 4
Training loss: 2.8700696714763594
Validation loss: 2.7552935736765067

Epoch: 6| Step: 5
Training loss: 2.08025371544672
Validation loss: 2.65092025341169

Epoch: 6| Step: 6
Training loss: 3.1834170052548414
Validation loss: 2.7226353691000558

Epoch: 6| Step: 7
Training loss: 2.308427162420959
Validation loss: 2.714125237087614

Epoch: 6| Step: 8
Training loss: 2.679892306939671
Validation loss: 2.7411314443521597

Epoch: 6| Step: 9
Training loss: 1.9795275375905907
Validation loss: 2.8453946465345674

Epoch: 6| Step: 10
Training loss: 1.745203256219051
Validation loss: 2.771897252279026

Epoch: 6| Step: 11
Training loss: 2.4035973728263973
Validation loss: 2.426004186693405

Epoch: 6| Step: 12
Training loss: 1.8139684582105644
Validation loss: 2.8049467032543296

Epoch: 6| Step: 13
Training loss: 1.8451669711514518
Validation loss: 2.914986161146887

Epoch: 505| Step: 0
Training loss: 3.034715068080296
Validation loss: 2.791679169399259

Epoch: 6| Step: 1
Training loss: 1.7029420946931249
Validation loss: 2.566290433325072

Epoch: 6| Step: 2
Training loss: 2.2810938533487928
Validation loss: 2.7360751584133305

Epoch: 6| Step: 3
Training loss: 1.9880678553255018
Validation loss: 2.720313420768854

Epoch: 6| Step: 4
Training loss: 2.6409839634435524
Validation loss: 2.6570091634535054

Epoch: 6| Step: 5
Training loss: 2.5887686452742127
Validation loss: 2.8725977327169843

Epoch: 6| Step: 6
Training loss: 3.427613206770427
Validation loss: 2.7116711361360637

Epoch: 6| Step: 7
Training loss: 2.4036667073102174
Validation loss: 2.6042726573088997

Epoch: 6| Step: 8
Training loss: 2.2048805763273163
Validation loss: 2.7607019832281168

Epoch: 6| Step: 9
Training loss: 1.5835590285346606
Validation loss: 2.7478550463265567

Epoch: 6| Step: 10
Training loss: 1.5795990508812037
Validation loss: 2.7629592652203727

Epoch: 6| Step: 11
Training loss: 2.1834274528930697
Validation loss: 2.646501778547382

Epoch: 6| Step: 12
Training loss: 2.322832684787812
Validation loss: 2.705538372569958

Epoch: 6| Step: 13
Training loss: 2.470079764031909
Validation loss: 2.7754269429734415

Epoch: 506| Step: 0
Training loss: 2.1135144343031036
Validation loss: 2.7955049968027623

Epoch: 6| Step: 1
Training loss: 1.811914086185088
Validation loss: 2.7778349231324677

Epoch: 6| Step: 2
Training loss: 2.38096592127265
Validation loss: 2.681961098139346

Epoch: 6| Step: 3
Training loss: 2.603985731832906
Validation loss: 3.050576896851021

Epoch: 6| Step: 4
Training loss: 2.8937471591614194
Validation loss: 2.6966876792015544

Epoch: 6| Step: 5
Training loss: 1.6751953381181137
Validation loss: 2.890291978254531

Epoch: 6| Step: 6
Training loss: 2.103923166619931
Validation loss: 2.735963757963351

Epoch: 6| Step: 7
Training loss: 2.242223227611695
Validation loss: 2.7694395194085266

Epoch: 6| Step: 8
Training loss: 2.205361820213781
Validation loss: 2.7782202156703963

Epoch: 6| Step: 9
Training loss: 2.4410740008297283
Validation loss: 2.717776643730976

Epoch: 6| Step: 10
Training loss: 1.6790558802908866
Validation loss: 2.8420487834371415

Epoch: 6| Step: 11
Training loss: 3.181213162851556
Validation loss: 2.652086638287366

Epoch: 6| Step: 12
Training loss: 2.285871449244402
Validation loss: 2.8055142969166433

Epoch: 6| Step: 13
Training loss: 1.8362026591265195
Validation loss: 2.6574036748790015

Epoch: 507| Step: 0
Training loss: 2.1251043406282735
Validation loss: 2.908769820464253

Epoch: 6| Step: 1
Training loss: 1.3018133519337594
Validation loss: 2.892022108480808

Epoch: 6| Step: 2
Training loss: 2.546418599617659
Validation loss: 2.663399554892752

Epoch: 6| Step: 3
Training loss: 2.944784992445696
Validation loss: 2.7887863087230262

Epoch: 6| Step: 4
Training loss: 1.7815405625386302
Validation loss: 2.715915465385762

Epoch: 6| Step: 5
Training loss: 2.445435152237996
Validation loss: 2.8588221783444077

Epoch: 6| Step: 6
Training loss: 2.3336128226421273
Validation loss: 2.801566361761502

Epoch: 6| Step: 7
Training loss: 2.0035977191137553
Validation loss: 2.679842256073729

Epoch: 6| Step: 8
Training loss: 2.2852653803402228
Validation loss: 2.7363437532307406

Epoch: 6| Step: 9
Training loss: 2.156277421417577
Validation loss: 2.7321891192669843

Epoch: 6| Step: 10
Training loss: 1.8779572372280413
Validation loss: 2.7331299983103694

Epoch: 6| Step: 11
Training loss: 2.510975966666304
Validation loss: 2.626244702546803

Epoch: 6| Step: 12
Training loss: 2.73756632267288
Validation loss: 2.592290983631848

Epoch: 6| Step: 13
Training loss: 2.705360414394215
Validation loss: 2.741235157771034

Epoch: 508| Step: 0
Training loss: 2.1122550235435265
Validation loss: 2.6525261097838695

Epoch: 6| Step: 1
Training loss: 2.047529625497824
Validation loss: 2.709810671554999

Epoch: 6| Step: 2
Training loss: 2.0837418219320623
Validation loss: 2.8833875554174373

Epoch: 6| Step: 3
Training loss: 3.175561125423932
Validation loss: 2.7469028808451057

Epoch: 6| Step: 4
Training loss: 2.032219992631139
Validation loss: 2.720249483401218

Epoch: 6| Step: 5
Training loss: 2.418545902128112
Validation loss: 2.6886721547178727

Epoch: 6| Step: 6
Training loss: 1.9042792842737217
Validation loss: 2.6861637568165686

Epoch: 6| Step: 7
Training loss: 2.305300873422902
Validation loss: 2.7272307791083255

Epoch: 6| Step: 8
Training loss: 1.7123033480259888
Validation loss: 2.659738560108785

Epoch: 6| Step: 9
Training loss: 1.64742439559633
Validation loss: 2.6530520409706355

Epoch: 6| Step: 10
Training loss: 2.0501632485867347
Validation loss: 2.7601793124838876

Epoch: 6| Step: 11
Training loss: 2.7324600053462174
Validation loss: 2.7688818363320618

Epoch: 6| Step: 12
Training loss: 2.045903098890871
Validation loss: 2.7153923320255933

Epoch: 6| Step: 13
Training loss: 3.6679188295325
Validation loss: 2.700759859238361

Epoch: 509| Step: 0
Training loss: 2.0157378409093596
Validation loss: 2.677934135941242

Epoch: 6| Step: 1
Training loss: 1.8140103854267977
Validation loss: 2.790097520345413

Epoch: 6| Step: 2
Training loss: 1.6181670829454686
Validation loss: 2.6639394096874947

Epoch: 6| Step: 3
Training loss: 2.982249836434577
Validation loss: 2.8503175155976677

Epoch: 6| Step: 4
Training loss: 1.700274119996503
Validation loss: 2.8561236085399213

Epoch: 6| Step: 5
Training loss: 2.6813859811726655
Validation loss: 2.5935061414637812

Epoch: 6| Step: 6
Training loss: 2.339479854352698
Validation loss: 2.5843672957393986

Epoch: 6| Step: 7
Training loss: 2.4641112192740304
Validation loss: 2.8942418590301626

Epoch: 6| Step: 8
Training loss: 2.117439733591165
Validation loss: 2.780932860148106

Epoch: 6| Step: 9
Training loss: 2.1538646606813487
Validation loss: 2.8295319558249457

Epoch: 6| Step: 10
Training loss: 3.434188079606777
Validation loss: 2.9449067356216942

Epoch: 6| Step: 11
Training loss: 2.05532780522533
Validation loss: 2.751724669074474

Epoch: 6| Step: 12
Training loss: 1.6263422191137618
Validation loss: 2.742697954179054

Epoch: 6| Step: 13
Training loss: 2.4082185693695757
Validation loss: 2.7096041371236006

Epoch: 510| Step: 0
Training loss: 2.072560597673871
Validation loss: 2.721569049537625

Epoch: 6| Step: 1
Training loss: 1.373835417267441
Validation loss: 2.657932292621582

Epoch: 6| Step: 2
Training loss: 1.9530530992624902
Validation loss: 2.6396747949098964

Epoch: 6| Step: 3
Training loss: 2.456279500148369
Validation loss: 2.6693273301927376

Epoch: 6| Step: 4
Training loss: 2.2161836422938532
Validation loss: 2.5397907464084812

Epoch: 6| Step: 5
Training loss: 2.6050431162657866
Validation loss: 2.67331587861567

Epoch: 6| Step: 6
Training loss: 3.0585047293578596
Validation loss: 2.9060614775361473

Epoch: 6| Step: 7
Training loss: 2.2006967568284224
Validation loss: 2.8792677765163113

Epoch: 6| Step: 8
Training loss: 2.6305598461577584
Validation loss: 2.6616715089234573

Epoch: 6| Step: 9
Training loss: 1.9912233300826663
Validation loss: 2.750523372900109

Epoch: 6| Step: 10
Training loss: 3.125101164134015
Validation loss: 2.760327963043292

Epoch: 6| Step: 11
Training loss: 1.980899320066887
Validation loss: 2.833758059655286

Epoch: 6| Step: 12
Training loss: 2.544728035325817
Validation loss: 2.819272578126245

Epoch: 6| Step: 13
Training loss: 1.5176009835543183
Validation loss: 2.718358918019285

Epoch: 511| Step: 0
Training loss: 2.133494397381546
Validation loss: 2.8312987161869465

Epoch: 6| Step: 1
Training loss: 2.0392632513500764
Validation loss: 2.7461616450422834

Epoch: 6| Step: 2
Training loss: 2.465844194655387
Validation loss: 2.6622780400721155

Epoch: 6| Step: 3
Training loss: 2.101730169818684
Validation loss: 2.6259218043803414

Epoch: 6| Step: 4
Training loss: 1.277961884701813
Validation loss: 2.671933044751079

Epoch: 6| Step: 5
Training loss: 1.9885655407865395
Validation loss: 2.824490968255926

Epoch: 6| Step: 6
Training loss: 1.495763916629279
Validation loss: 2.7665374003517385

Epoch: 6| Step: 7
Training loss: 2.1970611884061366
Validation loss: 2.8170659346262488

Epoch: 6| Step: 8
Training loss: 2.863023441880937
Validation loss: 2.682370682741358

Epoch: 6| Step: 9
Training loss: 2.41590825600146
Validation loss: 2.6845550561146556

Epoch: 6| Step: 10
Training loss: 2.8452290471935036
Validation loss: 2.8601425676504006

Epoch: 6| Step: 11
Training loss: 1.6869691084298584
Validation loss: 2.813460702103197

Epoch: 6| Step: 12
Training loss: 3.0718547645748346
Validation loss: 2.703271068443999

Epoch: 6| Step: 13
Training loss: 1.7641921179077804
Validation loss: 2.747104005526885

Epoch: 512| Step: 0
Training loss: 2.8734111541983993
Validation loss: 2.712021628918376

Epoch: 6| Step: 1
Training loss: 1.6866831745249569
Validation loss: 2.6783784182301638

Epoch: 6| Step: 2
Training loss: 3.2774770207185115
Validation loss: 2.7400440914258333

Epoch: 6| Step: 3
Training loss: 2.6820460136045012
Validation loss: 2.7176599812753794

Epoch: 6| Step: 4
Training loss: 2.7758148749623515
Validation loss: 2.778091467779535

Epoch: 6| Step: 5
Training loss: 2.2853079460199868
Validation loss: 2.753728105177605

Epoch: 6| Step: 6
Training loss: 2.1857661323916275
Validation loss: 2.7821413763828797

Epoch: 6| Step: 7
Training loss: 2.182107655150073
Validation loss: 2.8471866906249454

Epoch: 6| Step: 8
Training loss: 2.035575603837998
Validation loss: 2.711590420567778

Epoch: 6| Step: 9
Training loss: 2.3730291923209506
Validation loss: 2.756370948762771

Epoch: 6| Step: 10
Training loss: 1.792092368836261
Validation loss: 2.81320189328131

Epoch: 6| Step: 11
Training loss: 1.6648445261859919
Validation loss: 2.7588141524872505

Epoch: 6| Step: 12
Training loss: 1.9805380905020957
Validation loss: 2.716931495036188

Epoch: 6| Step: 13
Training loss: 1.9472864392850722
Validation loss: 2.702883797185622

Epoch: 513| Step: 0
Training loss: 2.3821416191838085
Validation loss: 2.8460708878150265

Epoch: 6| Step: 1
Training loss: 2.3389489400508596
Validation loss: 2.713369578549538

Epoch: 6| Step: 2
Training loss: 1.2062609538633453
Validation loss: 2.806099421014963

Epoch: 6| Step: 3
Training loss: 1.9634031319422172
Validation loss: 2.8013779453420784

Epoch: 6| Step: 4
Training loss: 2.7769117488829176
Validation loss: 2.7455088391110047

Epoch: 6| Step: 5
Training loss: 1.962990465044834
Validation loss: 2.733482246509353

Epoch: 6| Step: 6
Training loss: 1.9833165747738573
Validation loss: 2.5019657794664103

Epoch: 6| Step: 7
Training loss: 2.5278291545672498
Validation loss: 2.517724938688134

Epoch: 6| Step: 8
Training loss: 1.970707722290847
Validation loss: 2.7958741268531035

Epoch: 6| Step: 9
Training loss: 2.2267503090337133
Validation loss: 2.8309146110823615

Epoch: 6| Step: 10
Training loss: 1.9419313023965443
Validation loss: 2.878573261840896

Epoch: 6| Step: 11
Training loss: 2.6095398262640863
Validation loss: 2.8554866143740356

Epoch: 6| Step: 12
Training loss: 2.849448896965597
Validation loss: 2.82095800657355

Epoch: 6| Step: 13
Training loss: 3.3353535411292956
Validation loss: 2.699922962981099

Epoch: 514| Step: 0
Training loss: 2.1904034555593226
Validation loss: 2.7405866777793935

Epoch: 6| Step: 1
Training loss: 2.2247712006961025
Validation loss: 2.7661142057353145

Epoch: 6| Step: 2
Training loss: 1.6906109144713455
Validation loss: 2.69713725103926

Epoch: 6| Step: 3
Training loss: 1.6544167791552378
Validation loss: 2.719226533256017

Epoch: 6| Step: 4
Training loss: 3.344693344953666
Validation loss: 2.6686375612858724

Epoch: 6| Step: 5
Training loss: 1.6297491074764583
Validation loss: 2.6915685359274684

Epoch: 6| Step: 6
Training loss: 1.619060739863414
Validation loss: 2.656872076533238

Epoch: 6| Step: 7
Training loss: 2.815123457699908
Validation loss: 2.805583892762277

Epoch: 6| Step: 8
Training loss: 2.1957211368665575
Validation loss: 2.698094405401289

Epoch: 6| Step: 9
Training loss: 2.6818707083332374
Validation loss: 2.7854506113229123

Epoch: 6| Step: 10
Training loss: 2.3373792402927815
Validation loss: 2.8038922191038376

Epoch: 6| Step: 11
Training loss: 2.001018145805412
Validation loss: 2.753271675642089

Epoch: 6| Step: 12
Training loss: 2.134403180540938
Validation loss: 2.7236286257820774

Epoch: 6| Step: 13
Training loss: 1.7337682539041512
Validation loss: 2.734442884126986

Epoch: 515| Step: 0
Training loss: 2.249810740670301
Validation loss: 2.7160509455696276

Epoch: 6| Step: 1
Training loss: 2.28227942245962
Validation loss: 2.7805882415913397

Epoch: 6| Step: 2
Training loss: 2.2678212011726764
Validation loss: 2.84194769276395

Epoch: 6| Step: 3
Training loss: 2.0369113375994576
Validation loss: 2.7724131079872705

Epoch: 6| Step: 4
Training loss: 3.1100625662934442
Validation loss: 2.7549908935999063

Epoch: 6| Step: 5
Training loss: 3.426353276340896
Validation loss: 2.653595325418766

Epoch: 6| Step: 6
Training loss: 2.242983155186022
Validation loss: 2.775914129454968

Epoch: 6| Step: 7
Training loss: 1.7704338819972016
Validation loss: 2.7023917408174656

Epoch: 6| Step: 8
Training loss: 2.3753040520641138
Validation loss: 2.8026147745499905

Epoch: 6| Step: 9
Training loss: 1.856587476268585
Validation loss: 2.5978547495281936

Epoch: 6| Step: 10
Training loss: 2.8123903888959734
Validation loss: 2.727598970751439

Epoch: 6| Step: 11
Training loss: 2.0316471591896463
Validation loss: 2.67941589614974

Epoch: 6| Step: 12
Training loss: 1.655905201847649
Validation loss: 2.7509686618232676

Epoch: 6| Step: 13
Training loss: 1.9468459248093823
Validation loss: 2.6027018276774614

Epoch: 516| Step: 0
Training loss: 2.4390529673925867
Validation loss: 2.7612683874283888

Epoch: 6| Step: 1
Training loss: 2.92277374316928
Validation loss: 2.7713638523775725

Epoch: 6| Step: 2
Training loss: 2.58708723157541
Validation loss: 2.8205559538275207

Epoch: 6| Step: 3
Training loss: 2.169997247439278
Validation loss: 2.701143134667167

Epoch: 6| Step: 4
Training loss: 2.5213442408169264
Validation loss: 2.8260826831919346

Epoch: 6| Step: 5
Training loss: 2.4936820305378733
Validation loss: 2.680696250978843

Epoch: 6| Step: 6
Training loss: 2.4715645114043054
Validation loss: 2.817316804902674

Epoch: 6| Step: 7
Training loss: 2.167606137854838
Validation loss: 2.7305747273655245

Epoch: 6| Step: 8
Training loss: 2.878492307471459
Validation loss: 2.589098603888295

Epoch: 6| Step: 9
Training loss: 2.04767913165183
Validation loss: 2.786787647334076

Epoch: 6| Step: 10
Training loss: 1.8211561875540914
Validation loss: 2.7174249922620155

Epoch: 6| Step: 11
Training loss: 2.0877300661049207
Validation loss: 2.7162483482366575

Epoch: 6| Step: 12
Training loss: 2.283620151780858
Validation loss: 2.7065031362801735

Epoch: 6| Step: 13
Training loss: 1.6965138621867122
Validation loss: 2.599605985552842

Epoch: 517| Step: 0
Training loss: 2.2722712406051677
Validation loss: 2.7647383770193357

Epoch: 6| Step: 1
Training loss: 2.523808218826272
Validation loss: 2.810809423321254

Epoch: 6| Step: 2
Training loss: 2.176544110507327
Validation loss: 2.7350929117083176

Epoch: 6| Step: 3
Training loss: 1.9125083997953367
Validation loss: 2.8548695688495753

Epoch: 6| Step: 4
Training loss: 2.0317797630235734
Validation loss: 2.678959730240213

Epoch: 6| Step: 5
Training loss: 3.2253551672009464
Validation loss: 2.7605489713446336

Epoch: 6| Step: 6
Training loss: 2.4400070209089484
Validation loss: 2.9095364082496737

Epoch: 6| Step: 7
Training loss: 2.1028497433606272
Validation loss: 2.888652620153825

Epoch: 6| Step: 8
Training loss: 2.183868882208301
Validation loss: 2.6259417214373433

Epoch: 6| Step: 9
Training loss: 1.820220813979861
Validation loss: 2.7350597662129394

Epoch: 6| Step: 10
Training loss: 2.234334345094244
Validation loss: 2.6364586316337193

Epoch: 6| Step: 11
Training loss: 1.8251814660556915
Validation loss: 2.807345790448974

Epoch: 6| Step: 12
Training loss: 2.14273691067132
Validation loss: 2.626938648475996

Epoch: 6| Step: 13
Training loss: 1.8863480166178175
Validation loss: 2.871815174290241

Epoch: 518| Step: 0
Training loss: 2.7015702732342803
Validation loss: 2.833167885311605

Epoch: 6| Step: 1
Training loss: 2.2277128761373852
Validation loss: 2.8479918817179413

Epoch: 6| Step: 2
Training loss: 2.685689715661475
Validation loss: 2.675921671726004

Epoch: 6| Step: 3
Training loss: 1.6090593491414318
Validation loss: 2.804347893116611

Epoch: 6| Step: 4
Training loss: 2.4807754447144927
Validation loss: 2.7404398788431537

Epoch: 6| Step: 5
Training loss: 1.8760734028720378
Validation loss: 2.7312643322834114

Epoch: 6| Step: 6
Training loss: 2.7104725727606964
Validation loss: 2.8011146521226977

Epoch: 6| Step: 7
Training loss: 3.2094690533816115
Validation loss: 2.685512437347929

Epoch: 6| Step: 8
Training loss: 1.191365125603
Validation loss: 2.764347238932948

Epoch: 6| Step: 9
Training loss: 2.501637780643067
Validation loss: 2.6752404222309316

Epoch: 6| Step: 10
Training loss: 1.6171510848953397
Validation loss: 2.729823066350454

Epoch: 6| Step: 11
Training loss: 1.9156195710495754
Validation loss: 2.786082807799468

Epoch: 6| Step: 12
Training loss: 2.438430999586844
Validation loss: 2.8104154420420637

Epoch: 6| Step: 13
Training loss: 2.6114108429891587
Validation loss: 2.7689136385937263

Epoch: 519| Step: 0
Training loss: 1.6603288628094806
Validation loss: 2.61877073698306

Epoch: 6| Step: 1
Training loss: 3.2069619620826684
Validation loss: 2.732768508419248

Epoch: 6| Step: 2
Training loss: 1.859129240319592
Validation loss: 2.7585572889930985

Epoch: 6| Step: 3
Training loss: 1.9917440481861888
Validation loss: 2.853521886494996

Epoch: 6| Step: 4
Training loss: 1.8654112087928534
Validation loss: 2.7229430721611436

Epoch: 6| Step: 5
Training loss: 2.4270926108339874
Validation loss: 2.61359765874779

Epoch: 6| Step: 6
Training loss: 2.218973067984474
Validation loss: 2.8145421679786917

Epoch: 6| Step: 7
Training loss: 1.932001124608757
Validation loss: 2.7865821915888755

Epoch: 6| Step: 8
Training loss: 2.617454401327707
Validation loss: 2.574568783791352

Epoch: 6| Step: 9
Training loss: 2.2715263592422654
Validation loss: 2.684369130573266

Epoch: 6| Step: 10
Training loss: 2.3681252010342355
Validation loss: 2.6400802913573895

Epoch: 6| Step: 11
Training loss: 2.5511972459107755
Validation loss: 2.8800607593882646

Epoch: 6| Step: 12
Training loss: 1.9234837567541214
Validation loss: 2.7035251482249207

Epoch: 6| Step: 13
Training loss: 2.5094834699738064
Validation loss: 2.7629804556161397

Epoch: 520| Step: 0
Training loss: 2.0140814970436023
Validation loss: 2.7667021528840245

Epoch: 6| Step: 1
Training loss: 3.2257628847071964
Validation loss: 2.6848660807338947

Epoch: 6| Step: 2
Training loss: 1.381705190990421
Validation loss: 2.726489295191825

Epoch: 6| Step: 3
Training loss: 2.433249067998692
Validation loss: 2.6974739290756466

Epoch: 6| Step: 4
Training loss: 2.0059620683303256
Validation loss: 2.7402344947510686

Epoch: 6| Step: 5
Training loss: 2.1642246667578497
Validation loss: 2.712545288533521

Epoch: 6| Step: 6
Training loss: 2.1774239767930212
Validation loss: 2.905275066427324

Epoch: 6| Step: 7
Training loss: 1.9176899072140712
Validation loss: 2.6359905445105376

Epoch: 6| Step: 8
Training loss: 2.0446948605859245
Validation loss: 2.7872310268986515

Epoch: 6| Step: 9
Training loss: 1.9602217868934233
Validation loss: 2.7546338113662068

Epoch: 6| Step: 10
Training loss: 3.6857325310535365
Validation loss: 2.7343882664418717

Epoch: 6| Step: 11
Training loss: 2.5109824232962166
Validation loss: 2.7302364531223797

Epoch: 6| Step: 12
Training loss: 2.1880311593551593
Validation loss: 2.6434938880260757

Epoch: 6| Step: 13
Training loss: 3.573506001765398
Validation loss: 2.7431078324884117

Epoch: 521| Step: 0
Training loss: 2.7375300053036393
Validation loss: 2.77667346298453

Epoch: 6| Step: 1
Training loss: 2.487825025477346
Validation loss: 2.7687499417226027

Epoch: 6| Step: 2
Training loss: 2.034585766634273
Validation loss: 2.7186180028955307

Epoch: 6| Step: 3
Training loss: 3.1699996440417935
Validation loss: 2.744389446948768

Epoch: 6| Step: 4
Training loss: 1.9639025153383243
Validation loss: 2.7128368028519705

Epoch: 6| Step: 5
Training loss: 2.387780685302722
Validation loss: 2.804960908159478

Epoch: 6| Step: 6
Training loss: 2.246495060106794
Validation loss: 2.707643500255045

Epoch: 6| Step: 7
Training loss: 2.178396410020328
Validation loss: 2.779133344175209

Epoch: 6| Step: 8
Training loss: 1.8880917310009258
Validation loss: 2.9430908117182972

Epoch: 6| Step: 9
Training loss: 2.439591903953797
Validation loss: 2.6705123169642575

Epoch: 6| Step: 10
Training loss: 2.229923001144644
Validation loss: 2.706220158025907

Epoch: 6| Step: 11
Training loss: 2.5781162146216317
Validation loss: 2.8184674123282094

Epoch: 6| Step: 12
Training loss: 1.777155268809337
Validation loss: 2.8538281367442293

Epoch: 6| Step: 13
Training loss: 1.4699398659064606
Validation loss: 2.8173522111552303

Epoch: 522| Step: 0
Training loss: 2.568778371538214
Validation loss: 2.7562680401952404

Epoch: 6| Step: 1
Training loss: 2.088791056240341
Validation loss: 2.772760924619889

Epoch: 6| Step: 2
Training loss: 2.0145355355694936
Validation loss: 2.703967913590827

Epoch: 6| Step: 3
Training loss: 2.3073650776111254
Validation loss: 2.834044190567766

Epoch: 6| Step: 4
Training loss: 2.4858171607717066
Validation loss: 2.8087424760694315

Epoch: 6| Step: 5
Training loss: 2.2422840483078628
Validation loss: 2.7378191954901654

Epoch: 6| Step: 6
Training loss: 2.2328763617638634
Validation loss: 2.760814643786377

Epoch: 6| Step: 7
Training loss: 2.3361073307828772
Validation loss: 2.799838293477711

Epoch: 6| Step: 8
Training loss: 1.6635296465448013
Validation loss: 2.804084367697377

Epoch: 6| Step: 9
Training loss: 1.4515547933876927
Validation loss: 2.7562402101447545

Epoch: 6| Step: 10
Training loss: 3.309256639246121
Validation loss: 2.5807033857191524

Epoch: 6| Step: 11
Training loss: 1.8961757169091034
Validation loss: 2.661785178789452

Epoch: 6| Step: 12
Training loss: 1.8222185887259152
Validation loss: 2.656848349307048

Epoch: 6| Step: 13
Training loss: 3.108501982694561
Validation loss: 2.6142509019346574

Epoch: 523| Step: 0
Training loss: 1.9903500928546376
Validation loss: 2.7346527333585025

Epoch: 6| Step: 1
Training loss: 2.8685495742894616
Validation loss: 2.8103931607332386

Epoch: 6| Step: 2
Training loss: 2.0059993884465053
Validation loss: 2.642800730065453

Epoch: 6| Step: 3
Training loss: 1.9024460782644368
Validation loss: 2.7146986007693417

Epoch: 6| Step: 4
Training loss: 2.000219809850839
Validation loss: 2.825786433413797

Epoch: 6| Step: 5
Training loss: 1.4551966676492478
Validation loss: 2.6552133640166065

Epoch: 6| Step: 6
Training loss: 1.5366951797609336
Validation loss: 2.7216081617995758

Epoch: 6| Step: 7
Training loss: 3.0580087543210053
Validation loss: 2.8724361386318664

Epoch: 6| Step: 8
Training loss: 2.7245020910217583
Validation loss: 2.758529517353536

Epoch: 6| Step: 9
Training loss: 2.0679624643147414
Validation loss: 2.711410458035311

Epoch: 6| Step: 10
Training loss: 2.6316199615695552
Validation loss: 2.754493790223891

Epoch: 6| Step: 11
Training loss: 2.0263047100684672
Validation loss: 2.6784105422909184

Epoch: 6| Step: 12
Training loss: 2.0485267090158406
Validation loss: 2.8614372680862967

Epoch: 6| Step: 13
Training loss: 2.561623493179059
Validation loss: 2.6098781545402425

Epoch: 524| Step: 0
Training loss: 2.15371577292692
Validation loss: 2.6807826170562374

Epoch: 6| Step: 1
Training loss: 2.869575358487229
Validation loss: 2.768686466871897

Epoch: 6| Step: 2
Training loss: 2.279533262833053
Validation loss: 2.8027711380873543

Epoch: 6| Step: 3
Training loss: 2.5537262487590704
Validation loss: 2.7966266713637618

Epoch: 6| Step: 4
Training loss: 2.2147710879077946
Validation loss: 2.6994667391038405

Epoch: 6| Step: 5
Training loss: 2.6809929428832966
Validation loss: 2.7519887201103552

Epoch: 6| Step: 6
Training loss: 1.9087640412319427
Validation loss: 2.7918911245072766

Epoch: 6| Step: 7
Training loss: 1.6553732512770953
Validation loss: 2.638803113620254

Epoch: 6| Step: 8
Training loss: 1.9517708929015427
Validation loss: 2.6951605831430623

Epoch: 6| Step: 9
Training loss: 2.580645629475151
Validation loss: 2.7985446840995576

Epoch: 6| Step: 10
Training loss: 2.1133798516305182
Validation loss: 2.604531864933998

Epoch: 6| Step: 11
Training loss: 2.1107896370424277
Validation loss: 2.869362256390647

Epoch: 6| Step: 12
Training loss: 1.9833021492737108
Validation loss: 2.697748021590946

Epoch: 6| Step: 13
Training loss: 2.3141170724516527
Validation loss: 2.7469635861017623

Epoch: 525| Step: 0
Training loss: 2.3387371114664197
Validation loss: 2.697894789755555

Epoch: 6| Step: 1
Training loss: 2.332906945188961
Validation loss: 2.802292009341725

Epoch: 6| Step: 2
Training loss: 2.9012370200731734
Validation loss: 2.9139830330397607

Epoch: 6| Step: 3
Training loss: 1.7227874498295022
Validation loss: 2.8614957536425836

Epoch: 6| Step: 4
Training loss: 2.054311275486107
Validation loss: 2.8355735925676675

Epoch: 6| Step: 5
Training loss: 2.0600255514615737
Validation loss: 2.7374951642999004

Epoch: 6| Step: 6
Training loss: 2.8136116374096467
Validation loss: 2.627973730640904

Epoch: 6| Step: 7
Training loss: 2.2739957668026833
Validation loss: 2.7647989053280235

Epoch: 6| Step: 8
Training loss: 3.4839007820428316
Validation loss: 2.973633367707895

Epoch: 6| Step: 9
Training loss: 2.6586570156034477
Validation loss: 2.8829928039196

Epoch: 6| Step: 10
Training loss: 1.9140450613044881
Validation loss: 2.9981421764902145

Epoch: 6| Step: 11
Training loss: 2.6113664714134743
Validation loss: 2.7886146081681655

Epoch: 6| Step: 12
Training loss: 1.9166748903623325
Validation loss: 2.728063181028363

Epoch: 6| Step: 13
Training loss: 2.39658336232887
Validation loss: 2.6861813093736613

Epoch: 526| Step: 0
Training loss: 2.3872334476288204
Validation loss: 2.7295524032119958

Epoch: 6| Step: 1
Training loss: 1.5673128391701627
Validation loss: 2.8004130560535265

Epoch: 6| Step: 2
Training loss: 1.5479596891452794
Validation loss: 2.710873426608298

Epoch: 6| Step: 3
Training loss: 2.4991779883334853
Validation loss: 2.67698096259193

Epoch: 6| Step: 4
Training loss: 3.4450630910823805
Validation loss: 2.7230115284329703

Epoch: 6| Step: 5
Training loss: 1.840382879682743
Validation loss: 2.8334955468210956

Epoch: 6| Step: 6
Training loss: 2.5796667864110576
Validation loss: 2.723909063302846

Epoch: 6| Step: 7
Training loss: 1.2970033145529836
Validation loss: 2.84623372252686

Epoch: 6| Step: 8
Training loss: 1.7916461662479921
Validation loss: 2.6507618145944822

Epoch: 6| Step: 9
Training loss: 1.843419190810738
Validation loss: 2.669623189260404

Epoch: 6| Step: 10
Training loss: 2.4606505211516025
Validation loss: 2.6796259178639312

Epoch: 6| Step: 11
Training loss: 2.5638024346445185
Validation loss: 2.673918681216215

Epoch: 6| Step: 12
Training loss: 2.298707607224804
Validation loss: 2.620266578098697

Epoch: 6| Step: 13
Training loss: 3.8445345690410004
Validation loss: 2.8323583895004236

Epoch: 527| Step: 0
Training loss: 2.3495778171262365
Validation loss: 2.703078124980516

Epoch: 6| Step: 1
Training loss: 2.115258270438667
Validation loss: 2.622844870023528

Epoch: 6| Step: 2
Training loss: 2.7963364578134424
Validation loss: 2.7091417196320813

Epoch: 6| Step: 3
Training loss: 1.2846997038554588
Validation loss: 2.8140703299790517

Epoch: 6| Step: 4
Training loss: 1.5749064947558382
Validation loss: 2.7648098931366145

Epoch: 6| Step: 5
Training loss: 2.3673291053845227
Validation loss: 2.7380469652655695

Epoch: 6| Step: 6
Training loss: 2.4618650595703255
Validation loss: 2.7338877310266003

Epoch: 6| Step: 7
Training loss: 2.8097272132338516
Validation loss: 2.6903396575004397

Epoch: 6| Step: 8
Training loss: 2.577626683019983
Validation loss: 2.8140576204774836

Epoch: 6| Step: 9
Training loss: 3.05462131282195
Validation loss: 2.848699750347972

Epoch: 6| Step: 10
Training loss: 1.9744624263369404
Validation loss: 2.7133058554906886

Epoch: 6| Step: 11
Training loss: 1.8666050213898187
Validation loss: 2.772962718986859

Epoch: 6| Step: 12
Training loss: 2.661980226312878
Validation loss: 2.5574303938103813

Epoch: 6| Step: 13
Training loss: 1.5355485798222936
Validation loss: 2.7225034869241846

Epoch: 528| Step: 0
Training loss: 2.232956015564088
Validation loss: 2.7542550792232587

Epoch: 6| Step: 1
Training loss: 2.249987390270926
Validation loss: 2.6483593575076565

Epoch: 6| Step: 2
Training loss: 2.72718274950663
Validation loss: 2.851485469158079

Epoch: 6| Step: 3
Training loss: 2.923963646815389
Validation loss: 2.8564751468177056

Epoch: 6| Step: 4
Training loss: 2.139721310731296
Validation loss: 2.644297988493858

Epoch: 6| Step: 5
Training loss: 1.9078373787872238
Validation loss: 2.71116607289667

Epoch: 6| Step: 6
Training loss: 3.0284250211158454
Validation loss: 2.6893068389198613

Epoch: 6| Step: 7
Training loss: 2.8860823945505722
Validation loss: 2.60681618527319

Epoch: 6| Step: 8
Training loss: 2.078571013580266
Validation loss: 2.7033730034575134

Epoch: 6| Step: 9
Training loss: 2.09447330108695
Validation loss: 2.7585423042566775

Epoch: 6| Step: 10
Training loss: 1.5498677597239823
Validation loss: 2.681307280600035

Epoch: 6| Step: 11
Training loss: 1.662266653219892
Validation loss: 2.699670677959708

Epoch: 6| Step: 12
Training loss: 2.1108016099540174
Validation loss: 2.7141873824295626

Epoch: 6| Step: 13
Training loss: 2.336547975922305
Validation loss: 2.9788157122043213

Epoch: 529| Step: 0
Training loss: 2.3519598032766735
Validation loss: 2.697112215589522

Epoch: 6| Step: 1
Training loss: 2.3159679493506453
Validation loss: 2.739776781048286

Epoch: 6| Step: 2
Training loss: 1.7007654626522746
Validation loss: 2.6806199095838417

Epoch: 6| Step: 3
Training loss: 2.0122053132007043
Validation loss: 2.596762311349398

Epoch: 6| Step: 4
Training loss: 2.246150856950658
Validation loss: 2.665142860910782

Epoch: 6| Step: 5
Training loss: 2.5250305249474714
Validation loss: 2.7032560835620063

Epoch: 6| Step: 6
Training loss: 2.986024410753571
Validation loss: 2.714813116571679

Epoch: 6| Step: 7
Training loss: 2.947641762000987
Validation loss: 2.8499294655834224

Epoch: 6| Step: 8
Training loss: 2.691371347231506
Validation loss: 2.7554577564264524

Epoch: 6| Step: 9
Training loss: 1.8767019812387629
Validation loss: 2.839566702722501

Epoch: 6| Step: 10
Training loss: 2.427565650877201
Validation loss: 2.7730836158670162

Epoch: 6| Step: 11
Training loss: 2.889980429876784
Validation loss: 2.5980423124689898

Epoch: 6| Step: 12
Training loss: 1.843702024708523
Validation loss: 2.6670082710513405

Epoch: 6| Step: 13
Training loss: 2.150949348396013
Validation loss: 2.613880917310371

Epoch: 530| Step: 0
Training loss: 1.4437902733936612
Validation loss: 2.732258582418705

Epoch: 6| Step: 1
Training loss: 1.6658165512015661
Validation loss: 2.6054621831359133

Epoch: 6| Step: 2
Training loss: 2.944230181817548
Validation loss: 2.7520085249894217

Epoch: 6| Step: 3
Training loss: 2.053765964179005
Validation loss: 2.991229855276776

Epoch: 6| Step: 4
Training loss: 2.032001297732562
Validation loss: 2.7582103469351886

Epoch: 6| Step: 5
Training loss: 2.024159188610768
Validation loss: 2.7715273069870285

Epoch: 6| Step: 6
Training loss: 2.245899065951299
Validation loss: 2.818175692758076

Epoch: 6| Step: 7
Training loss: 2.423300538905889
Validation loss: 2.6915010687124883

Epoch: 6| Step: 8
Training loss: 2.2817097030864675
Validation loss: 2.838014377383126

Epoch: 6| Step: 9
Training loss: 1.4439908970257946
Validation loss: 2.80290392645482

Epoch: 6| Step: 10
Training loss: 2.6672096792325766
Validation loss: 2.6954575994027117

Epoch: 6| Step: 11
Training loss: 2.309626262866158
Validation loss: 2.6949667603188643

Epoch: 6| Step: 12
Training loss: 2.692019277886209
Validation loss: 2.5913633605966653

Epoch: 6| Step: 13
Training loss: 1.611113858860055
Validation loss: 2.65336611389504

Epoch: 531| Step: 0
Training loss: 1.3466669846918342
Validation loss: 2.7249692081406254

Epoch: 6| Step: 1
Training loss: 1.705407389412009
Validation loss: 2.7100366670994447

Epoch: 6| Step: 2
Training loss: 2.149269192712756
Validation loss: 2.6453258314161943

Epoch: 6| Step: 3
Training loss: 2.5147417306723296
Validation loss: 2.763627988892334

Epoch: 6| Step: 4
Training loss: 2.413195309230976
Validation loss: 2.6992464964776026

Epoch: 6| Step: 5
Training loss: 2.575655129804215
Validation loss: 2.619631483464

Epoch: 6| Step: 6
Training loss: 2.2656674085133846
Validation loss: 2.6525104854563955

Epoch: 6| Step: 7
Training loss: 2.2274643527174467
Validation loss: 2.6478926828805873

Epoch: 6| Step: 8
Training loss: 1.9020040784565453
Validation loss: 2.6630887272810453

Epoch: 6| Step: 9
Training loss: 2.51203017135894
Validation loss: 2.63537943804531

Epoch: 6| Step: 10
Training loss: 3.3335263832138793
Validation loss: 2.6916660071743976

Epoch: 6| Step: 11
Training loss: 1.8314894666105896
Validation loss: 2.844334648295795

Epoch: 6| Step: 12
Training loss: 1.736294139962858
Validation loss: 2.746139116860198

Epoch: 6| Step: 13
Training loss: 2.564891164749826
Validation loss: 2.794468308778161

Epoch: 532| Step: 0
Training loss: 2.551124724882725
Validation loss: 2.7592984504660474

Epoch: 6| Step: 1
Training loss: 1.8497456195282937
Validation loss: 2.6725570229461533

Epoch: 6| Step: 2
Training loss: 3.187686091955983
Validation loss: 2.6019033809603362

Epoch: 6| Step: 3
Training loss: 2.2552492579974928
Validation loss: 2.567713277816546

Epoch: 6| Step: 4
Training loss: 2.0875774894540076
Validation loss: 2.6938341896802025

Epoch: 6| Step: 5
Training loss: 1.7063210273463367
Validation loss: 2.765734472530417

Epoch: 6| Step: 6
Training loss: 1.8726862300658047
Validation loss: 2.7028417515343186

Epoch: 6| Step: 7
Training loss: 2.500488996365964
Validation loss: 2.665242809690332

Epoch: 6| Step: 8
Training loss: 1.9086551189510756
Validation loss: 2.7399744074175434

Epoch: 6| Step: 9
Training loss: 2.669864902293107
Validation loss: 2.6359602843213503

Epoch: 6| Step: 10
Training loss: 1.8177590203709997
Validation loss: 2.815075694620694

Epoch: 6| Step: 11
Training loss: 2.463105230941753
Validation loss: 2.5928488869937625

Epoch: 6| Step: 12
Training loss: 1.9812608447815996
Validation loss: 2.7834010151039528

Epoch: 6| Step: 13
Training loss: 2.5726285662466246
Validation loss: 2.6879902473832877

Epoch: 533| Step: 0
Training loss: 2.071917447997366
Validation loss: 2.8299836671973115

Epoch: 6| Step: 1
Training loss: 2.3513854711059237
Validation loss: 2.8645186114713876

Epoch: 6| Step: 2
Training loss: 3.0434198596042408
Validation loss: 2.7940779009838335

Epoch: 6| Step: 3
Training loss: 2.166776091917973
Validation loss: 2.676366730629154

Epoch: 6| Step: 4
Training loss: 2.662986381412855
Validation loss: 2.6702912146259035

Epoch: 6| Step: 5
Training loss: 2.040647862351591
Validation loss: 2.7292455523889156

Epoch: 6| Step: 6
Training loss: 2.0194330246905783
Validation loss: 2.7270315420143905

Epoch: 6| Step: 7
Training loss: 1.4215479883445736
Validation loss: 2.865511955623855

Epoch: 6| Step: 8
Training loss: 2.418404535270272
Validation loss: 2.7849342349634743

Epoch: 6| Step: 9
Training loss: 2.3426746190145464
Validation loss: 2.861680002207671

Epoch: 6| Step: 10
Training loss: 2.4354487860535574
Validation loss: 2.7390115840712292

Epoch: 6| Step: 11
Training loss: 2.003064668553227
Validation loss: 2.685030944606792

Epoch: 6| Step: 12
Training loss: 2.198010073540663
Validation loss: 2.6608280000315605

Epoch: 6| Step: 13
Training loss: 1.9689702107630254
Validation loss: 2.7082701177926136

Epoch: 534| Step: 0
Training loss: 1.8511807977799835
Validation loss: 2.65535846300372

Epoch: 6| Step: 1
Training loss: 1.9157906963133233
Validation loss: 2.8253442888984424

Epoch: 6| Step: 2
Training loss: 2.7157681654580945
Validation loss: 2.6133583499294115

Epoch: 6| Step: 3
Training loss: 1.7635366867484816
Validation loss: 2.658580948745847

Epoch: 6| Step: 4
Training loss: 2.189355444792224
Validation loss: 2.78399569682898

Epoch: 6| Step: 5
Training loss: 1.310148858064875
Validation loss: 2.7797658522292688

Epoch: 6| Step: 6
Training loss: 2.0867426886233362
Validation loss: 2.734517402280931

Epoch: 6| Step: 7
Training loss: 2.804435442380904
Validation loss: 2.62579392489917

Epoch: 6| Step: 8
Training loss: 2.6852464320577556
Validation loss: 2.748710911901562

Epoch: 6| Step: 9
Training loss: 3.4767723448782712
Validation loss: 2.707485196485922

Epoch: 6| Step: 10
Training loss: 2.409282606359646
Validation loss: 2.7252978517067534

Epoch: 6| Step: 11
Training loss: 1.9986004104604675
Validation loss: 2.6636737735590184

Epoch: 6| Step: 12
Training loss: 1.793029584662908
Validation loss: 2.87694630989181

Epoch: 6| Step: 13
Training loss: 2.471890154573883
Validation loss: 2.7414109629543177

Epoch: 535| Step: 0
Training loss: 1.6856763664003243
Validation loss: 2.695672800201728

Epoch: 6| Step: 1
Training loss: 1.4950632874224548
Validation loss: 2.6076353543622646

Epoch: 6| Step: 2
Training loss: 2.0952803299928346
Validation loss: 2.732901227287152

Epoch: 6| Step: 3
Training loss: 2.033370569023679
Validation loss: 2.714707209500702

Epoch: 6| Step: 4
Training loss: 2.3027602591447054
Validation loss: 2.7379999568510778

Epoch: 6| Step: 5
Training loss: 1.974225800308784
Validation loss: 2.829798101378004

Epoch: 6| Step: 6
Training loss: 2.6876044142200697
Validation loss: 2.7936477341798525

Epoch: 6| Step: 7
Training loss: 2.161790005771313
Validation loss: 2.701769790967244

Epoch: 6| Step: 8
Training loss: 2.317083198736231
Validation loss: 2.6894362462796546

Epoch: 6| Step: 9
Training loss: 1.7116554878833095
Validation loss: 2.6528939072797733

Epoch: 6| Step: 10
Training loss: 3.2075468478271456
Validation loss: 2.742622708597676

Epoch: 6| Step: 11
Training loss: 2.218883779011862
Validation loss: 2.6934142440695115

Epoch: 6| Step: 12
Training loss: 2.1105072373602973
Validation loss: 2.7476229439026993

Epoch: 6| Step: 13
Training loss: 1.6993251021854177
Validation loss: 2.874771795716999

Epoch: 536| Step: 0
Training loss: 1.9821168561528637
Validation loss: 2.8701105312309627

Epoch: 6| Step: 1
Training loss: 2.3043653359972254
Validation loss: 2.8249065982305464

Epoch: 6| Step: 2
Training loss: 2.8732194777350943
Validation loss: 2.64197050822363

Epoch: 6| Step: 3
Training loss: 2.5092558227970145
Validation loss: 2.8111762519555663

Epoch: 6| Step: 4
Training loss: 2.02957459826604
Validation loss: 2.861680850579019

Epoch: 6| Step: 5
Training loss: 2.5668963424504976
Validation loss: 2.6361997819667797

Epoch: 6| Step: 6
Training loss: 1.5703628304230186
Validation loss: 2.6412091061520324

Epoch: 6| Step: 7
Training loss: 2.24154643288213
Validation loss: 2.7125885494336037

Epoch: 6| Step: 8
Training loss: 2.1723444589085394
Validation loss: 2.6397803986683157

Epoch: 6| Step: 9
Training loss: 1.579788313458859
Validation loss: 2.7608835417961846

Epoch: 6| Step: 10
Training loss: 1.9032614372467966
Validation loss: 2.667706153974031

Epoch: 6| Step: 11
Training loss: 2.323918786446931
Validation loss: 2.8307628124505513

Epoch: 6| Step: 12
Training loss: 2.017155147798331
Validation loss: 2.802434231793953

Epoch: 6| Step: 13
Training loss: 2.2220200632118328
Validation loss: 2.7648075741099305

Epoch: 537| Step: 0
Training loss: 2.000503238308285
Validation loss: 2.725691591175151

Epoch: 6| Step: 1
Training loss: 2.046811401310981
Validation loss: 2.5866963318719067

Epoch: 6| Step: 2
Training loss: 2.1994982147174866
Validation loss: 2.7828143933704617

Epoch: 6| Step: 3
Training loss: 1.9458864276947652
Validation loss: 2.673871119690523

Epoch: 6| Step: 4
Training loss: 2.0248927476525393
Validation loss: 2.6255907438007497

Epoch: 6| Step: 5
Training loss: 2.0280308964649927
Validation loss: 2.849414146856621

Epoch: 6| Step: 6
Training loss: 1.707868497302163
Validation loss: 2.8562201063890833

Epoch: 6| Step: 7
Training loss: 2.5582729924776455
Validation loss: 2.6238330595061217

Epoch: 6| Step: 8
Training loss: 1.9165799770929859
Validation loss: 2.59988073536126

Epoch: 6| Step: 9
Training loss: 2.374180200533075
Validation loss: 2.6804313391436914

Epoch: 6| Step: 10
Training loss: 2.728172548279532
Validation loss: 2.851863477609196

Epoch: 6| Step: 11
Training loss: 2.363361754504335
Validation loss: 2.693765200349892

Epoch: 6| Step: 12
Training loss: 1.686434232631083
Validation loss: 2.7679530438115925

Epoch: 6| Step: 13
Training loss: 3.514074500755895
Validation loss: 2.5995057981259744

Epoch: 538| Step: 0
Training loss: 3.1788628935933443
Validation loss: 2.7415417036770786

Epoch: 6| Step: 1
Training loss: 1.5977563803337531
Validation loss: 2.722136111031428

Epoch: 6| Step: 2
Training loss: 2.118708328242369
Validation loss: 2.767560889523399

Epoch: 6| Step: 3
Training loss: 2.5382458121660547
Validation loss: 2.642260736127106

Epoch: 6| Step: 4
Training loss: 2.589261871378447
Validation loss: 2.7016686086799573

Epoch: 6| Step: 5
Training loss: 1.6284329758257143
Validation loss: 2.7010844363185096

Epoch: 6| Step: 6
Training loss: 2.038858220767415
Validation loss: 2.7428623375618213

Epoch: 6| Step: 7
Training loss: 2.136003391948964
Validation loss: 2.668500794099125

Epoch: 6| Step: 8
Training loss: 2.477474971148249
Validation loss: 2.72223516044977

Epoch: 6| Step: 9
Training loss: 2.731182567191734
Validation loss: 2.772317219927806

Epoch: 6| Step: 10
Training loss: 2.195713970359101
Validation loss: 2.650198028944846

Epoch: 6| Step: 11
Training loss: 1.8144751343146768
Validation loss: 2.7814417348145457

Epoch: 6| Step: 12
Training loss: 2.4297736542075588
Validation loss: 2.639072731607459

Epoch: 6| Step: 13
Training loss: 1.9721407075014517
Validation loss: 2.8111645854075578

Epoch: 539| Step: 0
Training loss: 2.2914529758583457
Validation loss: 2.683766506860796

Epoch: 6| Step: 1
Training loss: 2.867909686115029
Validation loss: 2.870403618428326

Epoch: 6| Step: 2
Training loss: 2.2302282307245163
Validation loss: 2.5450439514507774

Epoch: 6| Step: 3
Training loss: 2.372089811506415
Validation loss: 2.826154407691282

Epoch: 6| Step: 4
Training loss: 1.85341490460832
Validation loss: 2.802987751715004

Epoch: 6| Step: 5
Training loss: 2.4264072464343895
Validation loss: 2.693169373905111

Epoch: 6| Step: 6
Training loss: 1.6013050895940213
Validation loss: 2.9463549459103544

Epoch: 6| Step: 7
Training loss: 1.5961946176407356
Validation loss: 2.751361804325621

Epoch: 6| Step: 8
Training loss: 1.8715563622318452
Validation loss: 2.7249986586652577

Epoch: 6| Step: 9
Training loss: 2.2424907412810975
Validation loss: 2.66453822496052

Epoch: 6| Step: 10
Training loss: 2.404737814810025
Validation loss: 2.735606261293736

Epoch: 6| Step: 11
Training loss: 3.1020518188378756
Validation loss: 2.6878357429771365

Epoch: 6| Step: 12
Training loss: 1.2933073954504752
Validation loss: 2.781419495149619

Epoch: 6| Step: 13
Training loss: 2.629246773282819
Validation loss: 2.7766492600779205

Epoch: 540| Step: 0
Training loss: 2.754074113207344
Validation loss: 2.785750657339648

Epoch: 6| Step: 1
Training loss: 2.145654047417414
Validation loss: 2.6331093122626603

Epoch: 6| Step: 2
Training loss: 1.8461967010139626
Validation loss: 2.673204940274254

Epoch: 6| Step: 3
Training loss: 2.1956268845660567
Validation loss: 2.7446981475104564

Epoch: 6| Step: 4
Training loss: 2.38548354231419
Validation loss: 2.8141177393479886

Epoch: 6| Step: 5
Training loss: 1.5196281343380533
Validation loss: 2.8305210933228198

Epoch: 6| Step: 6
Training loss: 2.129670228279365
Validation loss: 2.685383974088551

Epoch: 6| Step: 7
Training loss: 2.127392263766395
Validation loss: 2.8052193751503816

Epoch: 6| Step: 8
Training loss: 1.7502087741023773
Validation loss: 2.749318895239732

Epoch: 6| Step: 9
Training loss: 3.270645298179536
Validation loss: 2.7244256973763603

Epoch: 6| Step: 10
Training loss: 1.8891862170881126
Validation loss: 2.7105137197462037

Epoch: 6| Step: 11
Training loss: 2.3174413520116164
Validation loss: 2.6256779382726125

Epoch: 6| Step: 12
Training loss: 1.8553823993064744
Validation loss: 2.575399022258909

Epoch: 6| Step: 13
Training loss: 2.6103794197739614
Validation loss: 2.6445687558041095

Epoch: 541| Step: 0
Training loss: 1.9870660512050944
Validation loss: 2.8131734773164907

Epoch: 6| Step: 1
Training loss: 2.1803106695569077
Validation loss: 2.691991278833261

Epoch: 6| Step: 2
Training loss: 2.44540873085286
Validation loss: 2.8202263208168366

Epoch: 6| Step: 3
Training loss: 2.309418042185736
Validation loss: 2.8385609763373845

Epoch: 6| Step: 4
Training loss: 2.371970201675029
Validation loss: 2.76636221799789

Epoch: 6| Step: 5
Training loss: 1.6293410491625393
Validation loss: 2.8253949107749796

Epoch: 6| Step: 6
Training loss: 3.3831444416653844
Validation loss: 2.927596111719148

Epoch: 6| Step: 7
Training loss: 2.747455286524721
Validation loss: 2.748962126320484

Epoch: 6| Step: 8
Training loss: 1.6755318267085326
Validation loss: 2.676170230428106

Epoch: 6| Step: 9
Training loss: 2.8474673612765358
Validation loss: 2.7422371945036943

Epoch: 6| Step: 10
Training loss: 2.161351899127107
Validation loss: 2.6960184674067915

Epoch: 6| Step: 11
Training loss: 1.4623598732616336
Validation loss: 2.789221132479762

Epoch: 6| Step: 12
Training loss: 2.5743701757139017
Validation loss: 2.804635140571851

Epoch: 6| Step: 13
Training loss: 2.40736858575716
Validation loss: 2.569359652705369

Epoch: 542| Step: 0
Training loss: 2.832682441297016
Validation loss: 2.7551935484243466

Epoch: 6| Step: 1
Training loss: 2.0895484787026675
Validation loss: 2.766897811628649

Epoch: 6| Step: 2
Training loss: 2.275113880535011
Validation loss: 2.565233656806379

Epoch: 6| Step: 3
Training loss: 1.9012938937425456
Validation loss: 2.807772819582006

Epoch: 6| Step: 4
Training loss: 2.1478943294198634
Validation loss: 2.702929986988043

Epoch: 6| Step: 5
Training loss: 2.149523318476351
Validation loss: 2.831671896014091

Epoch: 6| Step: 6
Training loss: 2.59977830528553
Validation loss: 2.7798090436545597

Epoch: 6| Step: 7
Training loss: 2.3821994680809366
Validation loss: 2.714038385752418

Epoch: 6| Step: 8
Training loss: 2.144371930094884
Validation loss: 2.6602590632387177

Epoch: 6| Step: 9
Training loss: 1.8894792978849015
Validation loss: 2.8338501205288953

Epoch: 6| Step: 10
Training loss: 2.329930469474192
Validation loss: 2.6933070643548205

Epoch: 6| Step: 11
Training loss: 2.100939122882689
Validation loss: 2.913328053645237

Epoch: 6| Step: 12
Training loss: 2.2673057898613433
Validation loss: 2.833653655092798

Epoch: 6| Step: 13
Training loss: 2.661388139987296
Validation loss: 2.850795310117712

Epoch: 543| Step: 0
Training loss: 1.9407391697322083
Validation loss: 2.7434432693471114

Epoch: 6| Step: 1
Training loss: 2.0452701013423797
Validation loss: 2.67574624880839

Epoch: 6| Step: 2
Training loss: 2.1229283949877726
Validation loss: 2.8223494292923235

Epoch: 6| Step: 3
Training loss: 1.7675239006703467
Validation loss: 2.7691494987128205

Epoch: 6| Step: 4
Training loss: 2.096805335989708
Validation loss: 2.7601462258227025

Epoch: 6| Step: 5
Training loss: 2.7897317548207
Validation loss: 2.5264091061232192

Epoch: 6| Step: 6
Training loss: 2.0704262756177902
Validation loss: 2.6117120330007513

Epoch: 6| Step: 7
Training loss: 2.838037307214462
Validation loss: 2.792558387735472

Epoch: 6| Step: 8
Training loss: 2.4264311234771863
Validation loss: 2.667762898185899

Epoch: 6| Step: 9
Training loss: 2.1666603332818215
Validation loss: 2.6192064520714493

Epoch: 6| Step: 10
Training loss: 1.8969674403684726
Validation loss: 2.7997894977440656

Epoch: 6| Step: 11
Training loss: 2.134109717397086
Validation loss: 2.733940387647519

Epoch: 6| Step: 12
Training loss: 2.792987359258371
Validation loss: 2.6685770373986153

Epoch: 6| Step: 13
Training loss: 2.0991029776310315
Validation loss: 2.6960132298512973

Epoch: 544| Step: 0
Training loss: 2.2825950942019277
Validation loss: 2.7981314381423776

Epoch: 6| Step: 1
Training loss: 2.5431110676261692
Validation loss: 2.88478674357287

Epoch: 6| Step: 2
Training loss: 2.357504197700461
Validation loss: 2.6762335857004413

Epoch: 6| Step: 3
Training loss: 2.591165288855325
Validation loss: 2.851769215497934

Epoch: 6| Step: 4
Training loss: 2.539751446494941
Validation loss: 2.6217342792394964

Epoch: 6| Step: 5
Training loss: 1.8947461822346479
Validation loss: 2.828588615982844

Epoch: 6| Step: 6
Training loss: 2.151945600013504
Validation loss: 2.5660275665493835

Epoch: 6| Step: 7
Training loss: 2.126210933552916
Validation loss: 2.768015979318542

Epoch: 6| Step: 8
Training loss: 2.182523789423645
Validation loss: 2.5557183067028366

Epoch: 6| Step: 9
Training loss: 2.781591158741638
Validation loss: 2.661482587129523

Epoch: 6| Step: 10
Training loss: 2.168494468388133
Validation loss: 2.831924155603938

Epoch: 6| Step: 11
Training loss: 1.7532516651327879
Validation loss: 2.5594611067868116

Epoch: 6| Step: 12
Training loss: 1.9902719900303367
Validation loss: 2.757470833297964

Epoch: 6| Step: 13
Training loss: 1.663580811322056
Validation loss: 2.5385478523122447

Epoch: 545| Step: 0
Training loss: 1.6911331202909616
Validation loss: 2.548470901603642

Epoch: 6| Step: 1
Training loss: 2.007600053168017
Validation loss: 2.7455861531785692

Epoch: 6| Step: 2
Training loss: 1.8630745251257357
Validation loss: 2.708588905360546

Epoch: 6| Step: 3
Training loss: 2.4258232174497207
Validation loss: 2.667816991370554

Epoch: 6| Step: 4
Training loss: 2.5734938207136744
Validation loss: 2.6374176190594745

Epoch: 6| Step: 5
Training loss: 2.0612696821708503
Validation loss: 2.718367215259116

Epoch: 6| Step: 6
Training loss: 2.8085702356619535
Validation loss: 2.8593721435145287

Epoch: 6| Step: 7
Training loss: 2.551440680936918
Validation loss: 2.8481613924926537

Epoch: 6| Step: 8
Training loss: 2.8444414241430356
Validation loss: 2.6104491505355027

Epoch: 6| Step: 9
Training loss: 1.815831772393788
Validation loss: 2.6536081368508917

Epoch: 6| Step: 10
Training loss: 2.3135079944902004
Validation loss: 2.711769820948844

Epoch: 6| Step: 11
Training loss: 1.8517955520690177
Validation loss: 2.7374947756559482

Epoch: 6| Step: 12
Training loss: 1.8360934576794428
Validation loss: 2.6596394975492843

Epoch: 6| Step: 13
Training loss: 1.6464512144032426
Validation loss: 2.634877715732915

Epoch: 546| Step: 0
Training loss: 1.8197550431663918
Validation loss: 2.774675595819127

Epoch: 6| Step: 1
Training loss: 2.367329206096575
Validation loss: 2.6548209991839213

Epoch: 6| Step: 2
Training loss: 2.4056118205565027
Validation loss: 2.7925048456627266

Epoch: 6| Step: 3
Training loss: 2.029786272119762
Validation loss: 2.7482690294926124

Epoch: 6| Step: 4
Training loss: 1.0837844801788885
Validation loss: 2.5759682472584458

Epoch: 6| Step: 5
Training loss: 2.289325061100341
Validation loss: 2.7437354653360986

Epoch: 6| Step: 6
Training loss: 2.450820131634909
Validation loss: 2.7321442160683387

Epoch: 6| Step: 7
Training loss: 2.8182742713350732
Validation loss: 2.7598000640911438

Epoch: 6| Step: 8
Training loss: 2.398783407212247
Validation loss: 2.789750757846368

Epoch: 6| Step: 9
Training loss: 1.5615409959828175
Validation loss: 2.6636097374454195

Epoch: 6| Step: 10
Training loss: 3.048351536510992
Validation loss: 2.7548449245789213

Epoch: 6| Step: 11
Training loss: 1.774702520023121
Validation loss: 2.8312555134269615

Epoch: 6| Step: 12
Training loss: 1.970171763198457
Validation loss: 2.696368449606643

Epoch: 6| Step: 13
Training loss: 1.943145525490472
Validation loss: 2.5653435101909183

Epoch: 547| Step: 0
Training loss: 2.4560583763019017
Validation loss: 2.7490181806310034

Epoch: 6| Step: 1
Training loss: 2.4138878817812865
Validation loss: 2.7492433515709975

Epoch: 6| Step: 2
Training loss: 1.7037819111690986
Validation loss: 2.766896885088806

Epoch: 6| Step: 3
Training loss: 1.8439656794202768
Validation loss: 2.7519466729293978

Epoch: 6| Step: 4
Training loss: 2.4410452858155547
Validation loss: 2.787981657991701

Epoch: 6| Step: 5
Training loss: 2.187973189264649
Validation loss: 2.699224725004948

Epoch: 6| Step: 6
Training loss: 2.6476584219789983
Validation loss: 2.713353013948398

Epoch: 6| Step: 7
Training loss: 2.2259038653731884
Validation loss: 2.6606023176931966

Epoch: 6| Step: 8
Training loss: 2.330428654283911
Validation loss: 2.496484609585101

Epoch: 6| Step: 9
Training loss: 1.7492621773784824
Validation loss: 2.692283916024705

Epoch: 6| Step: 10
Training loss: 2.130474332012478
Validation loss: 2.806871428429176

Epoch: 6| Step: 11
Training loss: 2.0169354104710955
Validation loss: 2.753819582717302

Epoch: 6| Step: 12
Training loss: 1.8665099251312336
Validation loss: 2.706793303859922

Epoch: 6| Step: 13
Training loss: 3.543258234581718
Validation loss: 2.8119528800008404

Epoch: 548| Step: 0
Training loss: 1.8584606583202588
Validation loss: 2.7715245791842267

Epoch: 6| Step: 1
Training loss: 2.6905854721798876
Validation loss: 2.7569673787513627

Epoch: 6| Step: 2
Training loss: 1.736054440739033
Validation loss: 2.651775697921837

Epoch: 6| Step: 3
Training loss: 1.6088149197987294
Validation loss: 2.86365843637139

Epoch: 6| Step: 4
Training loss: 2.648782083155927
Validation loss: 2.584864565161048

Epoch: 6| Step: 5
Training loss: 2.988786083786973
Validation loss: 2.6851525610902964

Epoch: 6| Step: 6
Training loss: 1.887441050638406
Validation loss: 2.70451312889242

Epoch: 6| Step: 7
Training loss: 1.9809511338339625
Validation loss: 2.726893198460729

Epoch: 6| Step: 8
Training loss: 2.169854081517212
Validation loss: 2.6757335951115206

Epoch: 6| Step: 9
Training loss: 2.028689017140227
Validation loss: 2.632612892029064

Epoch: 6| Step: 10
Training loss: 1.7245864261815436
Validation loss: 2.8003510349418455

Epoch: 6| Step: 11
Training loss: 1.6498797286155389
Validation loss: 2.6832824465332132

Epoch: 6| Step: 12
Training loss: 2.2304529299734503
Validation loss: 2.7672356129376663

Epoch: 6| Step: 13
Training loss: 2.357999994648423
Validation loss: 2.7143693123556827

Epoch: 549| Step: 0
Training loss: 2.3147751209953005
Validation loss: 2.704734983352223

Epoch: 6| Step: 1
Training loss: 2.5930306229848235
Validation loss: 2.7753179031061697

Epoch: 6| Step: 2
Training loss: 1.8238791694941172
Validation loss: 2.7310737241164937

Epoch: 6| Step: 3
Training loss: 2.149325988157483
Validation loss: 2.5207673073236214

Epoch: 6| Step: 4
Training loss: 1.7242764489666202
Validation loss: 2.824740342325524

Epoch: 6| Step: 5
Training loss: 2.2135084321762104
Validation loss: 2.6311600681808045

Epoch: 6| Step: 6
Training loss: 2.4994500509003577
Validation loss: 2.810282366386359

Epoch: 6| Step: 7
Training loss: 1.8182298263800662
Validation loss: 2.899750759431199

Epoch: 6| Step: 8
Training loss: 2.0957895849476396
Validation loss: 2.8384829170866035

Epoch: 6| Step: 9
Training loss: 2.86778115927032
Validation loss: 2.6797009405586336

Epoch: 6| Step: 10
Training loss: 1.613578713543602
Validation loss: 2.896741333563008

Epoch: 6| Step: 11
Training loss: 2.342807732951614
Validation loss: 2.6903408190925275

Epoch: 6| Step: 12
Training loss: 2.8548705261053775
Validation loss: 2.6145413790075143

Epoch: 6| Step: 13
Training loss: 1.9975384226554296
Validation loss: 2.785015183226964

Epoch: 550| Step: 0
Training loss: 2.3411221840710303
Validation loss: 2.917307807548985

Epoch: 6| Step: 1
Training loss: 1.9843145045873762
Validation loss: 2.8266422879096877

Epoch: 6| Step: 2
Training loss: 2.735067922805282
Validation loss: 2.746240700396776

Epoch: 6| Step: 3
Training loss: 2.2343363725217675
Validation loss: 2.9942695106118418

Epoch: 6| Step: 4
Training loss: 1.9383496913181404
Validation loss: 2.6827863645439494

Epoch: 6| Step: 5
Training loss: 1.6618441987671264
Validation loss: 2.6702275541874263

Epoch: 6| Step: 6
Training loss: 2.8303284886453897
Validation loss: 2.688615430587357

Epoch: 6| Step: 7
Training loss: 1.9800805909680836
Validation loss: 2.70025792179384

Epoch: 6| Step: 8
Training loss: 2.509478149574313
Validation loss: 2.6506673670032743

Epoch: 6| Step: 9
Training loss: 1.9886847126025071
Validation loss: 2.640338924683439

Epoch: 6| Step: 10
Training loss: 2.963383049678373
Validation loss: 2.910119970480509

Epoch: 6| Step: 11
Training loss: 1.5737244845284533
Validation loss: 2.74854769537441

Epoch: 6| Step: 12
Training loss: 1.8100129526423037
Validation loss: 2.73415592657897

Epoch: 6| Step: 13
Training loss: 1.757705142663448
Validation loss: 2.7147419614515598

Epoch: 551| Step: 0
Training loss: 1.9113759396402106
Validation loss: 2.764364031215532

Epoch: 6| Step: 1
Training loss: 1.9884420453537772
Validation loss: 2.919793855304849

Epoch: 6| Step: 2
Training loss: 1.732373225099918
Validation loss: 2.718921399963654

Epoch: 6| Step: 3
Training loss: 1.7310202518426607
Validation loss: 2.846224220886151

Epoch: 6| Step: 4
Training loss: 2.3982430543889426
Validation loss: 2.829075674980892

Epoch: 6| Step: 5
Training loss: 2.823886793790698
Validation loss: 2.8693681120763634

Epoch: 6| Step: 6
Training loss: 1.5644932811979257
Validation loss: 2.7096067787202336

Epoch: 6| Step: 7
Training loss: 2.0835818587522743
Validation loss: 2.620764620903196

Epoch: 6| Step: 8
Training loss: 2.188148075560663
Validation loss: 2.7367527228205324

Epoch: 6| Step: 9
Training loss: 1.8808730650786822
Validation loss: 2.8030548649935483

Epoch: 6| Step: 10
Training loss: 2.035502047457845
Validation loss: 2.6389609108620524

Epoch: 6| Step: 11
Training loss: 2.300818140223143
Validation loss: 2.887340501509383

Epoch: 6| Step: 12
Training loss: 2.6187178507358704
Validation loss: 2.731212280652001

Epoch: 6| Step: 13
Training loss: 3.655765077434763
Validation loss: 2.771258063882444

Epoch: 552| Step: 0
Training loss: 1.7515902106128924
Validation loss: 2.7526218039144457

Epoch: 6| Step: 1
Training loss: 2.60362514714779
Validation loss: 2.750976726514752

Epoch: 6| Step: 2
Training loss: 2.230105288632954
Validation loss: 2.830714367756522

Epoch: 6| Step: 3
Training loss: 1.7687891062804344
Validation loss: 2.8116810452884002

Epoch: 6| Step: 4
Training loss: 2.333804378192694
Validation loss: 2.6602010249282277

Epoch: 6| Step: 5
Training loss: 1.8705224297796692
Validation loss: 2.6545268328471257

Epoch: 6| Step: 6
Training loss: 2.5207359568386214
Validation loss: 2.666926627665034

Epoch: 6| Step: 7
Training loss: 1.7640026369572521
Validation loss: 2.557807938586104

Epoch: 6| Step: 8
Training loss: 2.507014447682233
Validation loss: 2.799713507438318

Epoch: 6| Step: 9
Training loss: 3.2941484069189477
Validation loss: 2.7992078088234575

Epoch: 6| Step: 10
Training loss: 2.0644049661409203
Validation loss: 2.7438101263403083

Epoch: 6| Step: 11
Training loss: 1.8299135767223285
Validation loss: 2.7182614447743054

Epoch: 6| Step: 12
Training loss: 1.7592938094436579
Validation loss: 2.684980153118743

Epoch: 6| Step: 13
Training loss: 2.3226619860247557
Validation loss: 2.875253657261239

Epoch: 553| Step: 0
Training loss: 1.887581385190523
Validation loss: 2.785820745083424

Epoch: 6| Step: 1
Training loss: 2.123763678440997
Validation loss: 2.739840461089931

Epoch: 6| Step: 2
Training loss: 2.185298574897763
Validation loss: 2.809078649513195

Epoch: 6| Step: 3
Training loss: 1.6663100417380745
Validation loss: 2.693545525151236

Epoch: 6| Step: 4
Training loss: 2.5495318263495625
Validation loss: 2.883188254261585

Epoch: 6| Step: 5
Training loss: 2.1208097994934487
Validation loss: 2.7546589364083514

Epoch: 6| Step: 6
Training loss: 2.0454041532609155
Validation loss: 2.7677927579725883

Epoch: 6| Step: 7
Training loss: 1.4779872580096445
Validation loss: 2.7614425310095627

Epoch: 6| Step: 8
Training loss: 2.485773808372677
Validation loss: 2.7057094288811485

Epoch: 6| Step: 9
Training loss: 2.213548500200083
Validation loss: 2.750948780496479

Epoch: 6| Step: 10
Training loss: 2.506644003474815
Validation loss: 2.5841806916151606

Epoch: 6| Step: 11
Training loss: 2.72849238173484
Validation loss: 2.6567019151146

Epoch: 6| Step: 12
Training loss: 2.1537870632177363
Validation loss: 2.8098838543060873

Epoch: 6| Step: 13
Training loss: 2.5024479325372218
Validation loss: 2.7133865767183716

Epoch: 554| Step: 0
Training loss: 1.337834667511354
Validation loss: 2.7375626236255663

Epoch: 6| Step: 1
Training loss: 2.2779381108907106
Validation loss: 2.618592626982678

Epoch: 6| Step: 2
Training loss: 2.255094059845398
Validation loss: 2.526649328091096

Epoch: 6| Step: 3
Training loss: 2.117478241611642
Validation loss: 2.754910409661498

Epoch: 6| Step: 4
Training loss: 2.6782309797187205
Validation loss: 2.7179534201527233

Epoch: 6| Step: 5
Training loss: 2.225045312998695
Validation loss: 2.693259777634642

Epoch: 6| Step: 6
Training loss: 1.8787395062283605
Validation loss: 2.611347709622388

Epoch: 6| Step: 7
Training loss: 1.7872785310995856
Validation loss: 2.727376310386365

Epoch: 6| Step: 8
Training loss: 2.1128976300956164
Validation loss: 2.6626905580397793

Epoch: 6| Step: 9
Training loss: 1.7653647712076794
Validation loss: 2.584087483212539

Epoch: 6| Step: 10
Training loss: 3.290881453589167
Validation loss: 2.744610841989613

Epoch: 6| Step: 11
Training loss: 1.8927068676380394
Validation loss: 2.660310187942325

Epoch: 6| Step: 12
Training loss: 2.3756780158522455
Validation loss: 2.785701596434271

Epoch: 6| Step: 13
Training loss: 1.8094651695540043
Validation loss: 2.6894701027486776

Epoch: 555| Step: 0
Training loss: 2.9316189922065776
Validation loss: 2.8933320278289343

Epoch: 6| Step: 1
Training loss: 2.5864321878017926
Validation loss: 2.6607213865223605

Epoch: 6| Step: 2
Training loss: 2.1775585428595408
Validation loss: 2.6576967892078165

Epoch: 6| Step: 3
Training loss: 2.1641706859662446
Validation loss: 2.692144473449581

Epoch: 6| Step: 4
Training loss: 2.0113757387334976
Validation loss: 2.6445503841871285

Epoch: 6| Step: 5
Training loss: 2.104039544020386
Validation loss: 2.676402084822648

Epoch: 6| Step: 6
Training loss: 1.6091391381322935
Validation loss: 2.915446426692346

Epoch: 6| Step: 7
Training loss: 2.2394590358100523
Validation loss: 2.8263090008711567

Epoch: 6| Step: 8
Training loss: 1.9340782714437388
Validation loss: 2.7564009185109075

Epoch: 6| Step: 9
Training loss: 2.398526764740039
Validation loss: 2.7159811094280957

Epoch: 6| Step: 10
Training loss: 1.6805431227140932
Validation loss: 2.7097712622368575

Epoch: 6| Step: 11
Training loss: 2.63694949800509
Validation loss: 2.6597399403694215

Epoch: 6| Step: 12
Training loss: 2.194612764859237
Validation loss: 2.6545834500293832

Epoch: 6| Step: 13
Training loss: 1.9201876668806748
Validation loss: 2.7342850302618844

Epoch: 556| Step: 0
Training loss: 2.4145461897232634
Validation loss: 2.6614652256747657

Epoch: 6| Step: 1
Training loss: 2.1517676605389826
Validation loss: 2.5585042828101767

Epoch: 6| Step: 2
Training loss: 2.2427001792333066
Validation loss: 2.812637506220448

Epoch: 6| Step: 3
Training loss: 2.5819151790228703
Validation loss: 2.7311105891700707

Epoch: 6| Step: 4
Training loss: 2.0791868780933678
Validation loss: 2.7203582695172392

Epoch: 6| Step: 5
Training loss: 2.2781953609783345
Validation loss: 2.7118749427714577

Epoch: 6| Step: 6
Training loss: 3.170357477387026
Validation loss: 2.9140358729857225

Epoch: 6| Step: 7
Training loss: 2.118180045827778
Validation loss: 2.6954036735866347

Epoch: 6| Step: 8
Training loss: 1.934909750339436
Validation loss: 2.7467504750655296

Epoch: 6| Step: 9
Training loss: 2.1499357790559563
Validation loss: 2.6914472769864854

Epoch: 6| Step: 10
Training loss: 1.8698629579970434
Validation loss: 2.7188224042624918

Epoch: 6| Step: 11
Training loss: 1.3066135283940685
Validation loss: 3.0042870732190043

Epoch: 6| Step: 12
Training loss: 1.8826323616943128
Validation loss: 2.740849966692385

Epoch: 6| Step: 13
Training loss: 1.926372445068487
Validation loss: 2.677887724652277

Epoch: 557| Step: 0
Training loss: 2.124788161545831
Validation loss: 2.6316580824457505

Epoch: 6| Step: 1
Training loss: 2.224895187652402
Validation loss: 2.742020506931009

Epoch: 6| Step: 2
Training loss: 2.206378347321588
Validation loss: 2.7401174898484424

Epoch: 6| Step: 3
Training loss: 1.2580606440889992
Validation loss: 2.8900644545420353

Epoch: 6| Step: 4
Training loss: 1.811209646845627
Validation loss: 2.8775826036815295

Epoch: 6| Step: 5
Training loss: 1.2272963545673083
Validation loss: 2.685033962696215

Epoch: 6| Step: 6
Training loss: 2.0763250601266794
Validation loss: 2.710074927938664

Epoch: 6| Step: 7
Training loss: 2.3048723566952596
Validation loss: 2.738244227765482

Epoch: 6| Step: 8
Training loss: 1.6333663220220667
Validation loss: 2.7459517557336777

Epoch: 6| Step: 9
Training loss: 2.5971139442145
Validation loss: 2.562252923162294

Epoch: 6| Step: 10
Training loss: 3.111297473169792
Validation loss: 2.6712201571794827

Epoch: 6| Step: 11
Training loss: 2.1562006847989457
Validation loss: 2.839878728252576

Epoch: 6| Step: 12
Training loss: 2.8439377942800323
Validation loss: 2.632669329025386

Epoch: 6| Step: 13
Training loss: 1.4765938245891934
Validation loss: 2.645146035929008

Epoch: 558| Step: 0
Training loss: 2.4540205371746584
Validation loss: 2.8600793189940554

Epoch: 6| Step: 1
Training loss: 2.5646041976695635
Validation loss: 2.6690485286908032

Epoch: 6| Step: 2
Training loss: 2.9403268725797727
Validation loss: 2.801596685320772

Epoch: 6| Step: 3
Training loss: 2.0353645320633227
Validation loss: 2.804806419783499

Epoch: 6| Step: 4
Training loss: 1.6713958481437055
Validation loss: 2.8290934676917883

Epoch: 6| Step: 5
Training loss: 1.6828342503635874
Validation loss: 2.7297475297345373

Epoch: 6| Step: 6
Training loss: 2.032677720899458
Validation loss: 2.676415225785187

Epoch: 6| Step: 7
Training loss: 1.6110776764407595
Validation loss: 2.8483759574336465

Epoch: 6| Step: 8
Training loss: 2.256011561424986
Validation loss: 2.7395456159348694

Epoch: 6| Step: 9
Training loss: 1.6818475363369856
Validation loss: 2.659447757340751

Epoch: 6| Step: 10
Training loss: 2.451035210800477
Validation loss: 2.718317971835531

Epoch: 6| Step: 11
Training loss: 2.1879157624914503
Validation loss: 2.8105750894855204

Epoch: 6| Step: 12
Training loss: 2.1572526452701135
Validation loss: 2.699717732741142

Epoch: 6| Step: 13
Training loss: 1.400465065481933
Validation loss: 2.7840026216075002

Epoch: 559| Step: 0
Training loss: 2.586325809331957
Validation loss: 2.7434723271912858

Epoch: 6| Step: 1
Training loss: 2.0355254733450816
Validation loss: 2.5905540852139284

Epoch: 6| Step: 2
Training loss: 1.6515381204038169
Validation loss: 2.6583952712882035

Epoch: 6| Step: 3
Training loss: 2.106526577955477
Validation loss: 2.773972471048196

Epoch: 6| Step: 4
Training loss: 2.0538738075500373
Validation loss: 2.8619054567803555

Epoch: 6| Step: 5
Training loss: 2.065851320919602
Validation loss: 2.6975832782373645

Epoch: 6| Step: 6
Training loss: 3.1133405232261393
Validation loss: 2.767692931572035

Epoch: 6| Step: 7
Training loss: 1.8519389739559011
Validation loss: 2.7515102408461467

Epoch: 6| Step: 8
Training loss: 2.3063729023426904
Validation loss: 2.663703118358368

Epoch: 6| Step: 9
Training loss: 2.478218463612006
Validation loss: 2.7110789541875784

Epoch: 6| Step: 10
Training loss: 1.660368495164217
Validation loss: 2.835041715201428

Epoch: 6| Step: 11
Training loss: 1.5900698039488876
Validation loss: 2.7843798799797597

Epoch: 6| Step: 12
Training loss: 1.9251788514517045
Validation loss: 2.6117766976440553

Epoch: 6| Step: 13
Training loss: 2.590400831511507
Validation loss: 2.8178342124227282

Epoch: 560| Step: 0
Training loss: 1.2413413566783509
Validation loss: 2.8658085707308123

Epoch: 6| Step: 1
Training loss: 1.9352324968578145
Validation loss: 2.7646229164094063

Epoch: 6| Step: 2
Training loss: 2.1430228509863944
Validation loss: 2.7363848512759334

Epoch: 6| Step: 3
Training loss: 2.6666512091506545
Validation loss: 2.677762250271321

Epoch: 6| Step: 4
Training loss: 1.8622829874071656
Validation loss: 2.916091919156082

Epoch: 6| Step: 5
Training loss: 2.6785487655407514
Validation loss: 2.7189320555295167

Epoch: 6| Step: 6
Training loss: 2.373097109164808
Validation loss: 2.793155285823183

Epoch: 6| Step: 7
Training loss: 1.8791748616222437
Validation loss: 2.739083082108441

Epoch: 6| Step: 8
Training loss: 2.4383062349779254
Validation loss: 2.772311288713114

Epoch: 6| Step: 9
Training loss: 2.7960796397413508
Validation loss: 2.7159135444826243

Epoch: 6| Step: 10
Training loss: 1.8416933129685853
Validation loss: 2.651985796366088

Epoch: 6| Step: 11
Training loss: 2.123551043014412
Validation loss: 2.614089618841285

Epoch: 6| Step: 12
Training loss: 1.8166276038050209
Validation loss: 2.627385157971687

Epoch: 6| Step: 13
Training loss: 1.4983204339433593
Validation loss: 2.701510915145886

Epoch: 561| Step: 0
Training loss: 1.985096417350701
Validation loss: 2.70945769857004

Epoch: 6| Step: 1
Training loss: 3.0324953018491727
Validation loss: 2.6462776732105238

Epoch: 6| Step: 2
Training loss: 1.823891326469388
Validation loss: 2.71661283901611

Epoch: 6| Step: 3
Training loss: 2.218110758073863
Validation loss: 2.710802699566923

Epoch: 6| Step: 4
Training loss: 1.513172485665303
Validation loss: 2.697824938797642

Epoch: 6| Step: 5
Training loss: 2.1550393506769914
Validation loss: 2.81033056487228

Epoch: 6| Step: 6
Training loss: 1.950440721347887
Validation loss: 2.910378422349572

Epoch: 6| Step: 7
Training loss: 1.6132250907673873
Validation loss: 2.7292149725869708

Epoch: 6| Step: 8
Training loss: 2.256489402348834
Validation loss: 2.6566227148939587

Epoch: 6| Step: 9
Training loss: 2.089784653443056
Validation loss: 2.6091705324684193

Epoch: 6| Step: 10
Training loss: 2.3707650222278245
Validation loss: 2.6711542231587195

Epoch: 6| Step: 11
Training loss: 1.842026179451726
Validation loss: 2.710994663943808

Epoch: 6| Step: 12
Training loss: 2.180479281873974
Validation loss: 2.7307031685672887

Epoch: 6| Step: 13
Training loss: 1.8002586020036495
Validation loss: 2.7359651377184275

Epoch: 562| Step: 0
Training loss: 2.5183568302104407
Validation loss: 2.7504984384364284

Epoch: 6| Step: 1
Training loss: 1.518023843987609
Validation loss: 2.6821038191229554

Epoch: 6| Step: 2
Training loss: 1.6220112238071134
Validation loss: 2.6138692195279374

Epoch: 6| Step: 3
Training loss: 1.828930147675658
Validation loss: 2.570090875198012

Epoch: 6| Step: 4
Training loss: 2.173146925149925
Validation loss: 2.870567864612953

Epoch: 6| Step: 5
Training loss: 2.4047349395930744
Validation loss: 2.700900037322313

Epoch: 6| Step: 6
Training loss: 2.2045281453333487
Validation loss: 2.810153734523038

Epoch: 6| Step: 7
Training loss: 2.18836086227793
Validation loss: 2.93132612139743

Epoch: 6| Step: 8
Training loss: 1.88937002097435
Validation loss: 2.7468336666949464

Epoch: 6| Step: 9
Training loss: 3.317557738203433
Validation loss: 2.8098423222165505

Epoch: 6| Step: 10
Training loss: 2.157340174973386
Validation loss: 2.7736808350049316

Epoch: 6| Step: 11
Training loss: 2.1016103746144315
Validation loss: 2.7712534939741604

Epoch: 6| Step: 12
Training loss: 2.064242118510866
Validation loss: 2.858059788703504

Epoch: 6| Step: 13
Training loss: 1.4238637911878063
Validation loss: 2.7608528267821817

Epoch: 563| Step: 0
Training loss: 2.166137031475534
Validation loss: 2.8045623922322087

Epoch: 6| Step: 1
Training loss: 2.3402435521592304
Validation loss: 2.762095899995696

Epoch: 6| Step: 2
Training loss: 3.028892622930076
Validation loss: 2.6441678583503716

Epoch: 6| Step: 3
Training loss: 1.732742228342927
Validation loss: 2.802255684585248

Epoch: 6| Step: 4
Training loss: 1.4979278238629956
Validation loss: 2.659820917619274

Epoch: 6| Step: 5
Training loss: 2.3961339568454743
Validation loss: 2.727003703144003

Epoch: 6| Step: 6
Training loss: 2.0465296097176138
Validation loss: 2.7822567536111853

Epoch: 6| Step: 7
Training loss: 1.7588286450987272
Validation loss: 2.6608649355438465

Epoch: 6| Step: 8
Training loss: 2.598533906599088
Validation loss: 2.6207802505891293

Epoch: 6| Step: 9
Training loss: 3.010524092256794
Validation loss: 2.7903604226288086

Epoch: 6| Step: 10
Training loss: 2.0729743399975624
Validation loss: 2.810633703051861

Epoch: 6| Step: 11
Training loss: 1.6544863109373928
Validation loss: 2.61836735580407

Epoch: 6| Step: 12
Training loss: 2.207086775089706
Validation loss: 2.80247888419948

Epoch: 6| Step: 13
Training loss: 1.8766235951460501
Validation loss: 2.6484325831293183

Epoch: 564| Step: 0
Training loss: 2.616056738876844
Validation loss: 2.6581745942277615

Epoch: 6| Step: 1
Training loss: 2.3300453816852773
Validation loss: 2.7048280003169745

Epoch: 6| Step: 2
Training loss: 1.8661365184787462
Validation loss: 2.8072039656904777

Epoch: 6| Step: 3
Training loss: 2.956539380223359
Validation loss: 2.770825799535008

Epoch: 6| Step: 4
Training loss: 2.6456639893973124
Validation loss: 2.7099059238261622

Epoch: 6| Step: 5
Training loss: 2.163830686196448
Validation loss: 2.847063914570996

Epoch: 6| Step: 6
Training loss: 1.9275463132328605
Validation loss: 2.8006699014867977

Epoch: 6| Step: 7
Training loss: 2.047951800904236
Validation loss: 2.788988200137561

Epoch: 6| Step: 8
Training loss: 2.3789022411193645
Validation loss: 2.6823419884989943

Epoch: 6| Step: 9
Training loss: 1.7691071867441208
Validation loss: 2.8605580407788493

Epoch: 6| Step: 10
Training loss: 2.585990974357414
Validation loss: 2.834630793678119

Epoch: 6| Step: 11
Training loss: 2.9456579678651527
Validation loss: 2.9265747825508868

Epoch: 6| Step: 12
Training loss: 2.0085341051134304
Validation loss: 2.6896392891046674

Epoch: 6| Step: 13
Training loss: 0.9756839004224415
Validation loss: 2.7079861464937127

Epoch: 565| Step: 0
Training loss: 2.3736261108273697
Validation loss: 2.7564422113662466

Epoch: 6| Step: 1
Training loss: 2.0011564725885886
Validation loss: 2.7444524006421505

Epoch: 6| Step: 2
Training loss: 2.637597148245096
Validation loss: 2.7382064241995745

Epoch: 6| Step: 3
Training loss: 1.9330664946579477
Validation loss: 2.8011818212610735

Epoch: 6| Step: 4
Training loss: 2.4917315122741965
Validation loss: 2.7479960401196957

Epoch: 6| Step: 5
Training loss: 3.4789012114777265
Validation loss: 2.949675992744508

Epoch: 6| Step: 6
Training loss: 1.8704623947054708
Validation loss: 2.9241190079054125

Epoch: 6| Step: 7
Training loss: 1.598920923182666
Validation loss: 2.846997108901094

Epoch: 6| Step: 8
Training loss: 2.663281278646597
Validation loss: 2.6927696794342753

Epoch: 6| Step: 9
Training loss: 2.103920900199643
Validation loss: 2.679827692167589

Epoch: 6| Step: 10
Training loss: 2.353780011407619
Validation loss: 2.7058557197343607

Epoch: 6| Step: 11
Training loss: 1.589430696784346
Validation loss: 2.70181841086249

Epoch: 6| Step: 12
Training loss: 1.9518039966265974
Validation loss: 2.6958371363247187

Epoch: 6| Step: 13
Training loss: 2.1840614541319128
Validation loss: 2.7543986493309007

Epoch: 566| Step: 0
Training loss: 2.6358502801508545
Validation loss: 2.6766695877784814

Epoch: 6| Step: 1
Training loss: 1.650980935248335
Validation loss: 2.7375857861346833

Epoch: 6| Step: 2
Training loss: 1.9041580853870557
Validation loss: 2.7056769798951725

Epoch: 6| Step: 3
Training loss: 2.4194408366598195
Validation loss: 2.7066105237143434

Epoch: 6| Step: 4
Training loss: 2.0851753356906246
Validation loss: 2.800224741473014

Epoch: 6| Step: 5
Training loss: 2.063207100543687
Validation loss: 2.663802429193871

Epoch: 6| Step: 6
Training loss: 2.065538307021251
Validation loss: 2.726607471615495

Epoch: 6| Step: 7
Training loss: 2.644682886912278
Validation loss: 2.552776934704563

Epoch: 6| Step: 8
Training loss: 2.532083444784176
Validation loss: 2.7653717449722537

Epoch: 6| Step: 9
Training loss: 2.912571911885909
Validation loss: 2.8385184070409015

Epoch: 6| Step: 10
Training loss: 2.1527270963985665
Validation loss: 2.715656386058502

Epoch: 6| Step: 11
Training loss: 2.2283127714971225
Validation loss: 2.803391974701795

Epoch: 6| Step: 12
Training loss: 2.201702768095759
Validation loss: 2.6267637235230046

Epoch: 6| Step: 13
Training loss: 1.4637326515270759
Validation loss: 2.5866785269359513

Epoch: 567| Step: 0
Training loss: 1.7053808968144344
Validation loss: 2.722377169414644

Epoch: 6| Step: 1
Training loss: 2.4359055219096497
Validation loss: 2.6398549542927365

Epoch: 6| Step: 2
Training loss: 2.716859094166448
Validation loss: 2.7847687686820275

Epoch: 6| Step: 3
Training loss: 2.0281791362384873
Validation loss: 2.7858675649703217

Epoch: 6| Step: 4
Training loss: 2.1636046879025557
Validation loss: 2.696668419655297

Epoch: 6| Step: 5
Training loss: 2.2710553565255878
Validation loss: 2.769431293720853

Epoch: 6| Step: 6
Training loss: 2.8447409779071764
Validation loss: 2.5916404067026266

Epoch: 6| Step: 7
Training loss: 2.012800262987274
Validation loss: 2.663911409982993

Epoch: 6| Step: 8
Training loss: 2.083499011763395
Validation loss: 2.56272212320605

Epoch: 6| Step: 9
Training loss: 1.9738440233077634
Validation loss: 2.919631111313026

Epoch: 6| Step: 10
Training loss: 1.7888066137966117
Validation loss: 2.6632953458597015

Epoch: 6| Step: 11
Training loss: 2.185637853124851
Validation loss: 2.704118693823832

Epoch: 6| Step: 12
Training loss: 2.246520955466659
Validation loss: 2.748332488512468

Epoch: 6| Step: 13
Training loss: 2.4431684070243267
Validation loss: 2.954223687130622

Epoch: 568| Step: 0
Training loss: 2.174363062760847
Validation loss: 2.7516944508838543

Epoch: 6| Step: 1
Training loss: 2.9670054881601517
Validation loss: 2.6791549455261303

Epoch: 6| Step: 2
Training loss: 2.4005131888079916
Validation loss: 2.7334553483740986

Epoch: 6| Step: 3
Training loss: 2.362675259664221
Validation loss: 2.8549488879882436

Epoch: 6| Step: 4
Training loss: 2.4103123445831054
Validation loss: 2.817205378312944

Epoch: 6| Step: 5
Training loss: 1.9066499384344084
Validation loss: 2.7124548130497237

Epoch: 6| Step: 6
Training loss: 1.5437206126516343
Validation loss: 2.793783143797517

Epoch: 6| Step: 7
Training loss: 2.079857355141649
Validation loss: 2.8013919889775134

Epoch: 6| Step: 8
Training loss: 2.0922474950118355
Validation loss: 2.625955892027314

Epoch: 6| Step: 9
Training loss: 1.7718889642935525
Validation loss: 2.741473678320578

Epoch: 6| Step: 10
Training loss: 2.0229831023328444
Validation loss: 2.7081054257150794

Epoch: 6| Step: 11
Training loss: 1.7019150662057507
Validation loss: 2.581428877430115

Epoch: 6| Step: 12
Training loss: 2.7540915136043713
Validation loss: 2.68445706213946

Epoch: 6| Step: 13
Training loss: 1.597096389384073
Validation loss: 2.694690531642656

Epoch: 569| Step: 0
Training loss: 1.7882815326442136
Validation loss: 2.77342085971257

Epoch: 6| Step: 1
Training loss: 2.271781396839682
Validation loss: 2.9483181790042443

Epoch: 6| Step: 2
Training loss: 2.861465107109311
Validation loss: 2.7361366805958487

Epoch: 6| Step: 3
Training loss: 2.528822311596916
Validation loss: 2.8102929113581676

Epoch: 6| Step: 4
Training loss: 2.780231503651756
Validation loss: 2.769510727608244

Epoch: 6| Step: 5
Training loss: 2.660805778356759
Validation loss: 2.715693043147432

Epoch: 6| Step: 6
Training loss: 2.110255078992368
Validation loss: 2.868265272248009

Epoch: 6| Step: 7
Training loss: 2.36072789491878
Validation loss: 2.5618897533529057

Epoch: 6| Step: 8
Training loss: 2.370725398855499
Validation loss: 2.7184144349176855

Epoch: 6| Step: 9
Training loss: 2.1461159109576027
Validation loss: 2.7208336349336633

Epoch: 6| Step: 10
Training loss: 1.7280809448586725
Validation loss: 2.808502229091105

Epoch: 6| Step: 11
Training loss: 2.6926844071309675
Validation loss: 2.7645548525247317

Epoch: 6| Step: 12
Training loss: 2.6587415790289994
Validation loss: 2.7264190127399224

Epoch: 6| Step: 13
Training loss: 1.0031594790418623
Validation loss: 2.6184938787625995

Epoch: 570| Step: 0
Training loss: 1.6909444059485779
Validation loss: 2.76824220542317

Epoch: 6| Step: 1
Training loss: 2.156601808015889
Validation loss: 2.813638840767702

Epoch: 6| Step: 2
Training loss: 3.0238487890474017
Validation loss: 2.7221104221045254

Epoch: 6| Step: 3
Training loss: 2.3218916839780586
Validation loss: 2.69642427285223

Epoch: 6| Step: 4
Training loss: 2.5638161977389435
Validation loss: 2.709018025962333

Epoch: 6| Step: 5
Training loss: 2.215511698980141
Validation loss: 2.5992016816570436

Epoch: 6| Step: 6
Training loss: 1.8274666668608621
Validation loss: 2.614473143898431

Epoch: 6| Step: 7
Training loss: 1.8728391275560958
Validation loss: 2.740945619027147

Epoch: 6| Step: 8
Training loss: 2.0137137881337606
Validation loss: 2.707049449020233

Epoch: 6| Step: 9
Training loss: 2.1145233621846917
Validation loss: 2.8693863464657623

Epoch: 6| Step: 10
Training loss: 3.0692535981637796
Validation loss: 2.6828500270264413

Epoch: 6| Step: 11
Training loss: 1.7829475345006258
Validation loss: 2.677411375603447

Epoch: 6| Step: 12
Training loss: 3.0175351433023034
Validation loss: 2.8254037774494702

Epoch: 6| Step: 13
Training loss: 1.6964700851523715
Validation loss: 2.8441073754176944

Epoch: 571| Step: 0
Training loss: 1.9011839791597038
Validation loss: 2.659106913530529

Epoch: 6| Step: 1
Training loss: 1.9092183375043992
Validation loss: 2.7034730873850994

Epoch: 6| Step: 2
Training loss: 2.45679369628654
Validation loss: 2.6959271177691666

Epoch: 6| Step: 3
Training loss: 2.262554324008994
Validation loss: 2.684993641658033

Epoch: 6| Step: 4
Training loss: 2.352950690755121
Validation loss: 2.746723581795258

Epoch: 6| Step: 5
Training loss: 3.3971317983802756
Validation loss: 2.6683515223888215

Epoch: 6| Step: 6
Training loss: 2.089916420501987
Validation loss: 2.6114960439607904

Epoch: 6| Step: 7
Training loss: 1.9442455629031041
Validation loss: 2.6770865139216746

Epoch: 6| Step: 8
Training loss: 2.272739998174934
Validation loss: 2.737311940184318

Epoch: 6| Step: 9
Training loss: 1.9696553888355808
Validation loss: 2.6905318184138056

Epoch: 6| Step: 10
Training loss: 2.502923210096964
Validation loss: 2.6417242486491133

Epoch: 6| Step: 11
Training loss: 1.5404441557125323
Validation loss: 2.7961976805531186

Epoch: 6| Step: 12
Training loss: 2.270397132719029
Validation loss: 2.6595782618677766

Epoch: 6| Step: 13
Training loss: 1.782119471846774
Validation loss: 2.7816507904017076

Epoch: 572| Step: 0
Training loss: 1.8747693237822671
Validation loss: 2.711792793002476

Epoch: 6| Step: 1
Training loss: 1.8791011463367433
Validation loss: 2.6798576263425855

Epoch: 6| Step: 2
Training loss: 2.250902101025742
Validation loss: 2.789737516668647

Epoch: 6| Step: 3
Training loss: 2.346232815792866
Validation loss: 2.645572128818977

Epoch: 6| Step: 4
Training loss: 1.8955973034604678
Validation loss: 2.7314319266444724

Epoch: 6| Step: 5
Training loss: 2.152591199548927
Validation loss: 2.875200308321812

Epoch: 6| Step: 6
Training loss: 2.272142493702416
Validation loss: 2.7220388596900484

Epoch: 6| Step: 7
Training loss: 1.4199915557932625
Validation loss: 2.789284383132511

Epoch: 6| Step: 8
Training loss: 1.814607907233579
Validation loss: 2.6536064490803604

Epoch: 6| Step: 9
Training loss: 2.0797812379824396
Validation loss: 2.740202797957513

Epoch: 6| Step: 10
Training loss: 3.147703326553287
Validation loss: 2.7605128792549762

Epoch: 6| Step: 11
Training loss: 2.751224765271898
Validation loss: 2.809957400025945

Epoch: 6| Step: 12
Training loss: 2.2298329744953382
Validation loss: 2.8047480628496215

Epoch: 6| Step: 13
Training loss: 1.9685509596224562
Validation loss: 2.63264140086798

Epoch: 573| Step: 0
Training loss: 1.8238334167103036
Validation loss: 2.630360315773418

Epoch: 6| Step: 1
Training loss: 1.9612166369428656
Validation loss: 2.6857159123624776

Epoch: 6| Step: 2
Training loss: 1.74246897797082
Validation loss: 2.6000063880324475

Epoch: 6| Step: 3
Training loss: 2.1441425464556887
Validation loss: 2.665717373845477

Epoch: 6| Step: 4
Training loss: 2.673915775219468
Validation loss: 2.7395240617885523

Epoch: 6| Step: 5
Training loss: 2.2184518963058775
Validation loss: 2.759232814948065

Epoch: 6| Step: 6
Training loss: 2.2529792135323587
Validation loss: 2.633183537848032

Epoch: 6| Step: 7
Training loss: 1.7553358475034109
Validation loss: 2.732107938286329

Epoch: 6| Step: 8
Training loss: 2.3428979978089544
Validation loss: 2.615130753311369

Epoch: 6| Step: 9
Training loss: 2.8608884714489196
Validation loss: 2.7612606220403797

Epoch: 6| Step: 10
Training loss: 1.672018027203857
Validation loss: 2.865771716368975

Epoch: 6| Step: 11
Training loss: 1.90505193364198
Validation loss: 2.840506949062662

Epoch: 6| Step: 12
Training loss: 2.346225600931225
Validation loss: 2.706999143588138

Epoch: 6| Step: 13
Training loss: 1.9513475799109987
Validation loss: 2.835886212033787

Epoch: 574| Step: 0
Training loss: 2.33330354217403
Validation loss: 2.657710350141506

Epoch: 6| Step: 1
Training loss: 2.4452874423074666
Validation loss: 2.771586074806814

Epoch: 6| Step: 2
Training loss: 1.8748130705159491
Validation loss: 2.675850393541016

Epoch: 6| Step: 3
Training loss: 2.2209380200912663
Validation loss: 2.701910220753327

Epoch: 6| Step: 4
Training loss: 1.9446927351086534
Validation loss: 2.6533668153447367

Epoch: 6| Step: 5
Training loss: 1.8397232955734166
Validation loss: 2.7498297121232356

Epoch: 6| Step: 6
Training loss: 2.568401333426281
Validation loss: 2.730746765174518

Epoch: 6| Step: 7
Training loss: 2.1340359822093578
Validation loss: 2.649709787186381

Epoch: 6| Step: 8
Training loss: 2.3372182747693926
Validation loss: 2.714487212246926

Epoch: 6| Step: 9
Training loss: 2.732562178090172
Validation loss: 2.6948942012339945

Epoch: 6| Step: 10
Training loss: 2.0113596178983526
Validation loss: 2.7141810861626183

Epoch: 6| Step: 11
Training loss: 2.445258971777099
Validation loss: 2.669167189047798

Epoch: 6| Step: 12
Training loss: 2.8881422773487087
Validation loss: 2.705384839539403

Epoch: 6| Step: 13
Training loss: 1.6690548079070038
Validation loss: 2.77504120995393

Epoch: 575| Step: 0
Training loss: 2.983660867140396
Validation loss: 2.836028679731383

Epoch: 6| Step: 1
Training loss: 1.9001770840489127
Validation loss: 2.6588706912251694

Epoch: 6| Step: 2
Training loss: 1.7092144097415098
Validation loss: 2.722649187083648

Epoch: 6| Step: 3
Training loss: 2.3449736389110005
Validation loss: 2.7462484961200557

Epoch: 6| Step: 4
Training loss: 2.4275422760634253
Validation loss: 2.7588803452833406

Epoch: 6| Step: 5
Training loss: 2.2289488736531986
Validation loss: 2.778424176784223

Epoch: 6| Step: 6
Training loss: 2.6918378907376623
Validation loss: 2.819805396118898

Epoch: 6| Step: 7
Training loss: 1.710161564427915
Validation loss: 2.702324527691003

Epoch: 6| Step: 8
Training loss: 1.8695655905681736
Validation loss: 2.7189355102584796

Epoch: 6| Step: 9
Training loss: 1.830805907578675
Validation loss: 2.767714611844804

Epoch: 6| Step: 10
Training loss: 2.251374884259909
Validation loss: 2.9261607601906516

Epoch: 6| Step: 11
Training loss: 2.355502354522934
Validation loss: 2.7953941204397252

Epoch: 6| Step: 12
Training loss: 2.170308927528951
Validation loss: 2.3946551596490018

Epoch: 6| Step: 13
Training loss: 2.7105420618472182
Validation loss: 2.6538032743379896

Epoch: 576| Step: 0
Training loss: 1.7746015585060289
Validation loss: 2.777640647648075

Epoch: 6| Step: 1
Training loss: 2.581391178731549
Validation loss: 2.6781904002311294

Epoch: 6| Step: 2
Training loss: 1.9800702358080409
Validation loss: 2.6982626956564144

Epoch: 6| Step: 3
Training loss: 1.8514838222092538
Validation loss: 2.619343378590894

Epoch: 6| Step: 4
Training loss: 2.3818763770142266
Validation loss: 2.712563352268908

Epoch: 6| Step: 5
Training loss: 2.0345746342321145
Validation loss: 2.7280565606281035

Epoch: 6| Step: 6
Training loss: 1.8728551677017131
Validation loss: 2.745512435944174

Epoch: 6| Step: 7
Training loss: 2.196571722028919
Validation loss: 2.601380050338123

Epoch: 6| Step: 8
Training loss: 2.6694685600674295
Validation loss: 2.793704473005191

Epoch: 6| Step: 9
Training loss: 1.958897353851402
Validation loss: 2.682038856170738

Epoch: 6| Step: 10
Training loss: 2.2647404489582157
Validation loss: 2.6702981712139136

Epoch: 6| Step: 11
Training loss: 2.487428144634381
Validation loss: 2.7060041219906084

Epoch: 6| Step: 12
Training loss: 2.444331450692546
Validation loss: 2.808008470060961

Epoch: 6| Step: 13
Training loss: 1.6261378486073497
Validation loss: 2.7401750545422043

Epoch: 577| Step: 0
Training loss: 2.803477161617199
Validation loss: 2.8029815735176262

Epoch: 6| Step: 1
Training loss: 1.6046757653985726
Validation loss: 2.8699949739036357

Epoch: 6| Step: 2
Training loss: 2.1990262043819744
Validation loss: 2.728876059123233

Epoch: 6| Step: 3
Training loss: 2.7534450280053377
Validation loss: 2.8250526260699855

Epoch: 6| Step: 4
Training loss: 1.954356057343941
Validation loss: 2.6938076303485894

Epoch: 6| Step: 5
Training loss: 2.14613590761486
Validation loss: 2.72684398678642

Epoch: 6| Step: 6
Training loss: 2.2848976967111754
Validation loss: 2.985195260868478

Epoch: 6| Step: 7
Training loss: 1.9023383608512603
Validation loss: 2.7645916846982743

Epoch: 6| Step: 8
Training loss: 2.9473745074424427
Validation loss: 2.610541895464381

Epoch: 6| Step: 9
Training loss: 1.5345144701810232
Validation loss: 2.6985447327904297

Epoch: 6| Step: 10
Training loss: 2.039035139229148
Validation loss: 2.612138107182194

Epoch: 6| Step: 11
Training loss: 1.8796883777289748
Validation loss: 2.6480706673805776

Epoch: 6| Step: 12
Training loss: 1.3788724468291598
Validation loss: 2.7963118025930886

Epoch: 6| Step: 13
Training loss: 1.6769558717930422
Validation loss: 2.6954497937413784

Epoch: 578| Step: 0
Training loss: 2.914027482300491
Validation loss: 2.694323225529228

Epoch: 6| Step: 1
Training loss: 2.075121322210364
Validation loss: 2.6090839447911236

Epoch: 6| Step: 2
Training loss: 2.4882285503274315
Validation loss: 2.7482630183932097

Epoch: 6| Step: 3
Training loss: 2.1858388860789297
Validation loss: 2.674329645173891

Epoch: 6| Step: 4
Training loss: 2.308594369646173
Validation loss: 2.5482202104411056

Epoch: 6| Step: 5
Training loss: 1.4520364601454734
Validation loss: 2.7065564071330743

Epoch: 6| Step: 6
Training loss: 1.6758650467557774
Validation loss: 2.6952373915651076

Epoch: 6| Step: 7
Training loss: 2.6556302413475725
Validation loss: 2.6497695684518967

Epoch: 6| Step: 8
Training loss: 1.2093983867266722
Validation loss: 2.8056431807778264

Epoch: 6| Step: 9
Training loss: 2.542459791497564
Validation loss: 2.6368340108298356

Epoch: 6| Step: 10
Training loss: 2.191060683259277
Validation loss: 2.6522623936744045

Epoch: 6| Step: 11
Training loss: 2.142289899497444
Validation loss: 2.65341963513359

Epoch: 6| Step: 12
Training loss: 2.7921518691766885
Validation loss: 2.7584218871787427

Epoch: 6| Step: 13
Training loss: 1.1959320656737937
Validation loss: 2.624197788977436

Epoch: 579| Step: 0
Training loss: 1.9867469848594572
Validation loss: 2.755240048554873

Epoch: 6| Step: 1
Training loss: 2.6081509031741295
Validation loss: 2.754510789627514

Epoch: 6| Step: 2
Training loss: 2.9336364986794594
Validation loss: 2.7692144816672686

Epoch: 6| Step: 3
Training loss: 2.12772598447033
Validation loss: 2.8054218183874773

Epoch: 6| Step: 4
Training loss: 1.9149314931861638
Validation loss: 2.6703944997577684

Epoch: 6| Step: 5
Training loss: 2.3772493050951637
Validation loss: 2.735189730772484

Epoch: 6| Step: 6
Training loss: 1.7269419257511216
Validation loss: 2.7054380997201024

Epoch: 6| Step: 7
Training loss: 2.0716761290788592
Validation loss: 2.795245652650305

Epoch: 6| Step: 8
Training loss: 1.6256249033199341
Validation loss: 2.7350769562357193

Epoch: 6| Step: 9
Training loss: 1.6899592528989391
Validation loss: 2.673117269623989

Epoch: 6| Step: 10
Training loss: 2.2238816568942803
Validation loss: 2.6227928537498606

Epoch: 6| Step: 11
Training loss: 2.03829579170862
Validation loss: 2.699171416779998

Epoch: 6| Step: 12
Training loss: 1.8983482057269598
Validation loss: 2.896021695996171

Epoch: 6| Step: 13
Training loss: 3.520588943456629
Validation loss: 2.766889820212298

Epoch: 580| Step: 0
Training loss: 1.6712462767143688
Validation loss: 2.6753581822265304

Epoch: 6| Step: 1
Training loss: 2.158195944381437
Validation loss: 2.84058643099501

Epoch: 6| Step: 2
Training loss: 2.0186448060963897
Validation loss: 2.7158036741134133

Epoch: 6| Step: 3
Training loss: 2.2606399941467874
Validation loss: 2.754498288351684

Epoch: 6| Step: 4
Training loss: 1.4401171535943387
Validation loss: 2.6019668173768435

Epoch: 6| Step: 5
Training loss: 1.9194728446524145
Validation loss: 2.660684156105185

Epoch: 6| Step: 6
Training loss: 1.8482025822702643
Validation loss: 2.834567442449915

Epoch: 6| Step: 7
Training loss: 1.7904847334802398
Validation loss: 2.8752907743715523

Epoch: 6| Step: 8
Training loss: 2.6244638894624335
Validation loss: 2.6553895004092674

Epoch: 6| Step: 9
Training loss: 3.5122809888227624
Validation loss: 2.697141218441415

Epoch: 6| Step: 10
Training loss: 1.8269772309219205
Validation loss: 2.744635562801198

Epoch: 6| Step: 11
Training loss: 2.7081197996813713
Validation loss: 2.7938775895015935

Epoch: 6| Step: 12
Training loss: 1.9347524542757846
Validation loss: 2.6130646627017864

Epoch: 6| Step: 13
Training loss: 2.341550685232167
Validation loss: 2.6510243135530582

Epoch: 581| Step: 0
Training loss: 2.2826971402221257
Validation loss: 2.795954336606796

Epoch: 6| Step: 1
Training loss: 1.842207958829355
Validation loss: 2.6825312312224385

Epoch: 6| Step: 2
Training loss: 2.906626195042548
Validation loss: 2.7773244663940564

Epoch: 6| Step: 3
Training loss: 2.482836072748631
Validation loss: 2.8007621387482917

Epoch: 6| Step: 4
Training loss: 1.563862778509849
Validation loss: 2.6793788412971487

Epoch: 6| Step: 5
Training loss: 2.307139085212334
Validation loss: 2.8725339434817183

Epoch: 6| Step: 6
Training loss: 2.641156566319479
Validation loss: 2.712939382001992

Epoch: 6| Step: 7
Training loss: 2.179849379349498
Validation loss: 2.7483142942159913

Epoch: 6| Step: 8
Training loss: 2.4784923459185535
Validation loss: 2.614180131084827

Epoch: 6| Step: 9
Training loss: 2.3266366387026287
Validation loss: 2.7040209689254735

Epoch: 6| Step: 10
Training loss: 2.5824655695611414
Validation loss: 2.7394473056405593

Epoch: 6| Step: 11
Training loss: 1.5018440673284228
Validation loss: 2.729844769405244

Epoch: 6| Step: 12
Training loss: 1.7035863408992329
Validation loss: 2.6494002370306293

Epoch: 6| Step: 13
Training loss: 1.5555068114378952
Validation loss: 2.651041294681881

Epoch: 582| Step: 0
Training loss: 2.0872439747123823
Validation loss: 2.819483409071297

Epoch: 6| Step: 1
Training loss: 1.4183960157918294
Validation loss: 2.7800903538961235

Epoch: 6| Step: 2
Training loss: 1.747388253193165
Validation loss: 2.6869243425978095

Epoch: 6| Step: 3
Training loss: 1.830660243973066
Validation loss: 2.6438248439234915

Epoch: 6| Step: 4
Training loss: 1.9915003769644597
Validation loss: 2.7133699791523744

Epoch: 6| Step: 5
Training loss: 2.1915204839460607
Validation loss: 2.6509924243238174

Epoch: 6| Step: 6
Training loss: 2.5708866115924924
Validation loss: 2.6873299806524753

Epoch: 6| Step: 7
Training loss: 2.121338101357489
Validation loss: 2.713392991040552

Epoch: 6| Step: 8
Training loss: 2.4827049928295746
Validation loss: 2.750468360565999

Epoch: 6| Step: 9
Training loss: 2.1208750013094124
Validation loss: 2.7750973721439327

Epoch: 6| Step: 10
Training loss: 1.9395750685480577
Validation loss: 2.710481147623055

Epoch: 6| Step: 11
Training loss: 2.0809975181685774
Validation loss: 2.7240412934024993

Epoch: 6| Step: 12
Training loss: 2.6865115454912187
Validation loss: 2.676424567812254

Epoch: 6| Step: 13
Training loss: 3.2620231075251933
Validation loss: 2.729394926814484

Epoch: 583| Step: 0
Training loss: 2.0371348890570253
Validation loss: 2.691915872976587

Epoch: 6| Step: 1
Training loss: 2.172579644151317
Validation loss: 2.6512023667873734

Epoch: 6| Step: 2
Training loss: 1.8165175537134837
Validation loss: 2.55039645898594

Epoch: 6| Step: 3
Training loss: 1.6566840988459872
Validation loss: 2.764763514087866

Epoch: 6| Step: 4
Training loss: 2.3986806342435867
Validation loss: 2.576805613415202

Epoch: 6| Step: 5
Training loss: 1.5273503061919709
Validation loss: 2.6391113344731187

Epoch: 6| Step: 6
Training loss: 2.1325477743219787
Validation loss: 2.9148218417613245

Epoch: 6| Step: 7
Training loss: 3.2899783347671616
Validation loss: 2.6910888393263335

Epoch: 6| Step: 8
Training loss: 1.6608180264183734
Validation loss: 2.818514979675897

Epoch: 6| Step: 9
Training loss: 2.879321292271145
Validation loss: 2.7554928187481598

Epoch: 6| Step: 10
Training loss: 2.385236863824096
Validation loss: 2.7197793207957304

Epoch: 6| Step: 11
Training loss: 1.9850731770361707
Validation loss: 2.815077970415754

Epoch: 6| Step: 12
Training loss: 1.4592162411450986
Validation loss: 2.7885826375697405

Epoch: 6| Step: 13
Training loss: 1.8199438941607695
Validation loss: 2.744184703178764

Epoch: 584| Step: 0
Training loss: 1.675129299012842
Validation loss: 2.731430535683068

Epoch: 6| Step: 1
Training loss: 1.852494918466206
Validation loss: 2.7294818793521207

Epoch: 6| Step: 2
Training loss: 2.2556651110212735
Validation loss: 2.7122478816493794

Epoch: 6| Step: 3
Training loss: 2.2676444688763144
Validation loss: 2.7270105648836607

Epoch: 6| Step: 4
Training loss: 3.278749512277175
Validation loss: 2.6800368398305556

Epoch: 6| Step: 5
Training loss: 2.2428855739731826
Validation loss: 2.7186033996502545

Epoch: 6| Step: 6
Training loss: 2.0775236249147344
Validation loss: 2.7381817090099827

Epoch: 6| Step: 7
Training loss: 2.126097451848306
Validation loss: 2.68997978851524

Epoch: 6| Step: 8
Training loss: 1.6508468448805527
Validation loss: 2.8404807485174013

Epoch: 6| Step: 9
Training loss: 2.3942920758279596
Validation loss: 2.6878356514129456

Epoch: 6| Step: 10
Training loss: 1.5844268369001004
Validation loss: 2.72269018865353

Epoch: 6| Step: 11
Training loss: 1.897700853636307
Validation loss: 2.702723374465082

Epoch: 6| Step: 12
Training loss: 2.313973344093772
Validation loss: 2.813654838654019

Epoch: 6| Step: 13
Training loss: 3.4563762841771535
Validation loss: 2.8271928083853504

Epoch: 585| Step: 0
Training loss: 2.7411945860306757
Validation loss: 2.6665472137194572

Epoch: 6| Step: 1
Training loss: 2.216143514330884
Validation loss: 2.724700773537027

Epoch: 6| Step: 2
Training loss: 2.3092254961941134
Validation loss: 2.6443247212864067

Epoch: 6| Step: 3
Training loss: 1.5398583847426541
Validation loss: 2.6524170661789963

Epoch: 6| Step: 4
Training loss: 1.9260146055767011
Validation loss: 2.476003158040512

Epoch: 6| Step: 5
Training loss: 2.02546078184303
Validation loss: 2.6754863766059445

Epoch: 6| Step: 6
Training loss: 2.426962155003421
Validation loss: 2.745889035278207

Epoch: 6| Step: 7
Training loss: 1.605486273379885
Validation loss: 2.7141408845410795

Epoch: 6| Step: 8
Training loss: 1.6363815652221523
Validation loss: 2.6844063505191698

Epoch: 6| Step: 9
Training loss: 1.985174183349795
Validation loss: 2.7435984032353016

Epoch: 6| Step: 10
Training loss: 1.1721763223447181
Validation loss: 2.6882680428396073

Epoch: 6| Step: 11
Training loss: 2.3874548543286678
Validation loss: 2.745647422097079

Epoch: 6| Step: 12
Training loss: 2.7684645219279194
Validation loss: 2.6641364617347847

Epoch: 6| Step: 13
Training loss: 1.81394164531347
Validation loss: 2.84391451448449

Epoch: 586| Step: 0
Training loss: 3.127476130820592
Validation loss: 2.8012761676046387

Epoch: 6| Step: 1
Training loss: 2.0689146685106694
Validation loss: 2.718513701036415

Epoch: 6| Step: 2
Training loss: 1.8981313576339045
Validation loss: 2.6665506440220814

Epoch: 6| Step: 3
Training loss: 2.0949415545630172
Validation loss: 2.851375270826617

Epoch: 6| Step: 4
Training loss: 2.1677100774735694
Validation loss: 2.7900944192738946

Epoch: 6| Step: 5
Training loss: 1.720758131968747
Validation loss: 2.7189255618717936

Epoch: 6| Step: 6
Training loss: 2.0206832698935733
Validation loss: 2.739223403397225

Epoch: 6| Step: 7
Training loss: 2.4011346519046257
Validation loss: 2.69357332816516

Epoch: 6| Step: 8
Training loss: 1.5549038683746577
Validation loss: 2.6341755344096933

Epoch: 6| Step: 9
Training loss: 1.7364990699473404
Validation loss: 2.715171337983187

Epoch: 6| Step: 10
Training loss: 1.8448444932567967
Validation loss: 2.795774091813633

Epoch: 6| Step: 11
Training loss: 2.265904271244236
Validation loss: 2.7761869915236033

Epoch: 6| Step: 12
Training loss: 2.4377467690779833
Validation loss: 2.650899277456148

Epoch: 6| Step: 13
Training loss: 2.3235734316191654
Validation loss: 2.5913631617469806

Epoch: 587| Step: 0
Training loss: 2.196285371620398
Validation loss: 2.8184451073534755

Epoch: 6| Step: 1
Training loss: 2.2469132761022856
Validation loss: 2.8461088719147996

Epoch: 6| Step: 2
Training loss: 1.6184144456587348
Validation loss: 2.8032870912436807

Epoch: 6| Step: 3
Training loss: 2.3742198666679464
Validation loss: 2.8630883545374957

Epoch: 6| Step: 4
Training loss: 2.4541503318497746
Validation loss: 2.8680512111269763

Epoch: 6| Step: 5
Training loss: 1.7738378803830857
Validation loss: 2.7329964505436157

Epoch: 6| Step: 6
Training loss: 1.94525581491756
Validation loss: 2.663800589086461

Epoch: 6| Step: 7
Training loss: 1.889233352848261
Validation loss: 2.705121678745503

Epoch: 6| Step: 8
Training loss: 2.346362273060763
Validation loss: 2.651281457699203

Epoch: 6| Step: 9
Training loss: 1.8005417273510695
Validation loss: 2.7645960718105886

Epoch: 6| Step: 10
Training loss: 2.342681641269011
Validation loss: 2.6979283443313338

Epoch: 6| Step: 11
Training loss: 2.1048870804824737
Validation loss: 2.729165345315082

Epoch: 6| Step: 12
Training loss: 3.031692315304727
Validation loss: 2.7651134180258525

Epoch: 6| Step: 13
Training loss: 1.7590205809585742
Validation loss: 2.8648007492534537

Epoch: 588| Step: 0
Training loss: 2.1677492322703724
Validation loss: 2.698149596245109

Epoch: 6| Step: 1
Training loss: 1.8061912183865552
Validation loss: 2.6413865956798754

Epoch: 6| Step: 2
Training loss: 2.2441557110975734
Validation loss: 2.613151231297736

Epoch: 6| Step: 3
Training loss: 1.7582437622011733
Validation loss: 2.566527923353354

Epoch: 6| Step: 4
Training loss: 1.9821364624823639
Validation loss: 2.716082442840364

Epoch: 6| Step: 5
Training loss: 3.0129540825354106
Validation loss: 2.6907520083322924

Epoch: 6| Step: 6
Training loss: 2.640452542965473
Validation loss: 2.527267106712915

Epoch: 6| Step: 7
Training loss: 1.828956610480418
Validation loss: 2.7168470848846455

Epoch: 6| Step: 8
Training loss: 2.3517455983405102
Validation loss: 2.6423185407597094

Epoch: 6| Step: 9
Training loss: 1.536121482346566
Validation loss: 2.6705196876869124

Epoch: 6| Step: 10
Training loss: 1.4944570168994848
Validation loss: 2.6352776892795866

Epoch: 6| Step: 11
Training loss: 1.9864026621108974
Validation loss: 2.604697809669486

Epoch: 6| Step: 12
Training loss: 2.970516121199505
Validation loss: 2.6455948011333237

Epoch: 6| Step: 13
Training loss: 1.851102618958308
Validation loss: 2.6478486951263984

Epoch: 589| Step: 0
Training loss: 2.1030076740975607
Validation loss: 2.7621362102050497

Epoch: 6| Step: 1
Training loss: 1.796438811060924
Validation loss: 2.5996600337403315

Epoch: 6| Step: 2
Training loss: 1.567466091902637
Validation loss: 2.617656381573361

Epoch: 6| Step: 3
Training loss: 1.9855519206305468
Validation loss: 2.7570991949678083

Epoch: 6| Step: 4
Training loss: 1.5805737221554117
Validation loss: 2.6713017633923384

Epoch: 6| Step: 5
Training loss: 2.0493156500363447
Validation loss: 2.8499640789765475

Epoch: 6| Step: 6
Training loss: 1.8549485933116139
Validation loss: 2.653508133386747

Epoch: 6| Step: 7
Training loss: 2.010281362246466
Validation loss: 2.747003100657462

Epoch: 6| Step: 8
Training loss: 2.8713810575847374
Validation loss: 2.7120502360085785

Epoch: 6| Step: 9
Training loss: 2.8881010016323674
Validation loss: 2.582848117948219

Epoch: 6| Step: 10
Training loss: 2.074714558283151
Validation loss: 2.5739148997427477

Epoch: 6| Step: 11
Training loss: 2.2090059611566875
Validation loss: 2.816577895621696

Epoch: 6| Step: 12
Training loss: 2.4876322955505725
Validation loss: 2.7000512652617656

Epoch: 6| Step: 13
Training loss: 2.3491613352501832
Validation loss: 2.630041874544751

Epoch: 590| Step: 0
Training loss: 2.2692200649262655
Validation loss: 2.7029001357127016

Epoch: 6| Step: 1
Training loss: 1.8869352038831553
Validation loss: 2.812942408104136

Epoch: 6| Step: 2
Training loss: 1.8042814780596435
Validation loss: 2.7942379653270266

Epoch: 6| Step: 3
Training loss: 2.1035276393139952
Validation loss: 2.816274111016298

Epoch: 6| Step: 4
Training loss: 1.768784658139627
Validation loss: 2.7894953443007027

Epoch: 6| Step: 5
Training loss: 1.1963769997175582
Validation loss: 2.885976074717086

Epoch: 6| Step: 6
Training loss: 1.8332614956855202
Validation loss: 2.7193517748551073

Epoch: 6| Step: 7
Training loss: 2.267372141706252
Validation loss: 2.819903034965549

Epoch: 6| Step: 8
Training loss: 2.2963131587230876
Validation loss: 2.750908104125281

Epoch: 6| Step: 9
Training loss: 2.07455654231441
Validation loss: 2.7152828559932556

Epoch: 6| Step: 10
Training loss: 2.40686542517997
Validation loss: 2.5993360847868217

Epoch: 6| Step: 11
Training loss: 1.9678972607598828
Validation loss: 2.826949623226115

Epoch: 6| Step: 12
Training loss: 1.9106359835013564
Validation loss: 2.592982867022038

Epoch: 6| Step: 13
Training loss: 3.849567260202153
Validation loss: 2.7273325151451124

Epoch: 591| Step: 0
Training loss: 1.677178642771266
Validation loss: 2.845891585823062

Epoch: 6| Step: 1
Training loss: 1.8867058605440927
Validation loss: 2.633335424185884

Epoch: 6| Step: 2
Training loss: 1.8263367603954717
Validation loss: 2.7143874036200155

Epoch: 6| Step: 3
Training loss: 2.3819222209797015
Validation loss: 2.7029236246620836

Epoch: 6| Step: 4
Training loss: 2.061059853578187
Validation loss: 2.498727940391924

Epoch: 6| Step: 5
Training loss: 1.9585819762902754
Validation loss: 2.863480893692685

Epoch: 6| Step: 6
Training loss: 2.389089053538462
Validation loss: 2.686233972082955

Epoch: 6| Step: 7
Training loss: 2.624963305988883
Validation loss: 2.7581057298074843

Epoch: 6| Step: 8
Training loss: 2.2103346147567553
Validation loss: 2.722595373292794

Epoch: 6| Step: 9
Training loss: 2.5745958622198875
Validation loss: 2.6319713400854923

Epoch: 6| Step: 10
Training loss: 2.7669951067771974
Validation loss: 2.737147521306433

Epoch: 6| Step: 11
Training loss: 2.352127564934792
Validation loss: 2.711689908129314

Epoch: 6| Step: 12
Training loss: 2.4017367953091053
Validation loss: 2.7639260704801933

Epoch: 6| Step: 13
Training loss: 2.315446471463578
Validation loss: 2.7586246691165193

Epoch: 592| Step: 0
Training loss: 2.1218869463172774
Validation loss: 2.6293319081816757

Epoch: 6| Step: 1
Training loss: 2.022976502444692
Validation loss: 2.738704528435604

Epoch: 6| Step: 2
Training loss: 2.190731821979249
Validation loss: 2.8117598868987472

Epoch: 6| Step: 3
Training loss: 1.6364920739140163
Validation loss: 2.733154123700669

Epoch: 6| Step: 4
Training loss: 2.38440738520996
Validation loss: 2.7087166854863347

Epoch: 6| Step: 5
Training loss: 3.2821646732487046
Validation loss: 2.949039429926608

Epoch: 6| Step: 6
Training loss: 1.5821799879443896
Validation loss: 2.757663655278291

Epoch: 6| Step: 7
Training loss: 2.087494572615278
Validation loss: 2.8195736356702987

Epoch: 6| Step: 8
Training loss: 1.8691721308652842
Validation loss: 2.8264588056303723

Epoch: 6| Step: 9
Training loss: 2.850736315460131
Validation loss: 2.7912912099459013

Epoch: 6| Step: 10
Training loss: 1.2867992994322572
Validation loss: 2.86528511616729

Epoch: 6| Step: 11
Training loss: 2.1411807042014073
Validation loss: 2.701835884965517

Epoch: 6| Step: 12
Training loss: 2.0280995512836624
Validation loss: 2.793771053166152

Epoch: 6| Step: 13
Training loss: 1.7793432369954663
Validation loss: 2.737529247691647

Epoch: 593| Step: 0
Training loss: 1.6364196649746579
Validation loss: 2.853185939386243

Epoch: 6| Step: 1
Training loss: 2.2581829044404764
Validation loss: 2.7864692433998233

Epoch: 6| Step: 2
Training loss: 2.14021297304189
Validation loss: 2.9088303067998433

Epoch: 6| Step: 3
Training loss: 2.3831948895914707
Validation loss: 2.714325265691072

Epoch: 6| Step: 4
Training loss: 2.3954146530754246
Validation loss: 2.692585147553299

Epoch: 6| Step: 5
Training loss: 2.035940418255955
Validation loss: 2.7738546263160093

Epoch: 6| Step: 6
Training loss: 2.7806333222525126
Validation loss: 2.7111595729308324

Epoch: 6| Step: 7
Training loss: 2.2105245575264463
Validation loss: 2.692259147773888

Epoch: 6| Step: 8
Training loss: 2.735467136805516
Validation loss: 2.5068308282858407

Epoch: 6| Step: 9
Training loss: 1.8650492151838738
Validation loss: 2.839317680074059

Epoch: 6| Step: 10
Training loss: 2.2907672041692733
Validation loss: 2.8194576182767297

Epoch: 6| Step: 11
Training loss: 1.9457623065126517
Validation loss: 2.607366482383378

Epoch: 6| Step: 12
Training loss: 1.8517931058184096
Validation loss: 2.822055683686546

Epoch: 6| Step: 13
Training loss: 1.2629395711129245
Validation loss: 2.646320148208865

Epoch: 594| Step: 0
Training loss: 1.9492685315458593
Validation loss: 2.660683524995021

Epoch: 6| Step: 1
Training loss: 1.8582631481356768
Validation loss: 2.7928078813131227

Epoch: 6| Step: 2
Training loss: 2.5642093446700986
Validation loss: 2.8838258892916127

Epoch: 6| Step: 3
Training loss: 2.348219208968605
Validation loss: 2.901085709181387

Epoch: 6| Step: 4
Training loss: 2.4561471000258375
Validation loss: 2.752208108481343

Epoch: 6| Step: 5
Training loss: 1.8456928555641885
Validation loss: 2.9611745037046533

Epoch: 6| Step: 6
Training loss: 2.68926766392587
Validation loss: 2.766658060023648

Epoch: 6| Step: 7
Training loss: 1.3149277168975042
Validation loss: 2.688281625503518

Epoch: 6| Step: 8
Training loss: 2.8793448084380073
Validation loss: 2.7329936200278198

Epoch: 6| Step: 9
Training loss: 2.6201798825719793
Validation loss: 2.681787634203023

Epoch: 6| Step: 10
Training loss: 2.2670427819090895
Validation loss: 2.717017914685191

Epoch: 6| Step: 11
Training loss: 1.9251449183621363
Validation loss: 2.787871974878945

Epoch: 6| Step: 12
Training loss: 2.063860357927921
Validation loss: 2.76833859301484

Epoch: 6| Step: 13
Training loss: 2.2943470855985013
Validation loss: 2.6549503068688334

Epoch: 595| Step: 0
Training loss: 1.6446798443203834
Validation loss: 2.6181654813241018

Epoch: 6| Step: 1
Training loss: 2.567533712787914
Validation loss: 2.878560040049119

Epoch: 6| Step: 2
Training loss: 1.6911825336045172
Validation loss: 2.7043257272929973

Epoch: 6| Step: 3
Training loss: 2.3471710668503323
Validation loss: 2.644690027182865

Epoch: 6| Step: 4
Training loss: 2.605234024020831
Validation loss: 2.775479964255268

Epoch: 6| Step: 5
Training loss: 2.466535226653475
Validation loss: 2.7293719333713256

Epoch: 6| Step: 6
Training loss: 2.217966505521826
Validation loss: 2.7244559696002493

Epoch: 6| Step: 7
Training loss: 2.2291508136316285
Validation loss: 2.752763506276041

Epoch: 6| Step: 8
Training loss: 2.419374812053968
Validation loss: 2.7447649964241343

Epoch: 6| Step: 9
Training loss: 1.9660287851688614
Validation loss: 2.702990207349801

Epoch: 6| Step: 10
Training loss: 1.5729885548043674
Validation loss: 2.5878000967266583

Epoch: 6| Step: 11
Training loss: 2.158932330500014
Validation loss: 2.666804354968741

Epoch: 6| Step: 12
Training loss: 1.9143208232092037
Validation loss: 2.8162884390253504

Epoch: 6| Step: 13
Training loss: 1.7019825874809587
Validation loss: 2.7547047457214706

Epoch: 596| Step: 0
Training loss: 2.558237578083867
Validation loss: 2.7534497694577955

Epoch: 6| Step: 1
Training loss: 2.030385699157012
Validation loss: 2.7721646096389456

Epoch: 6| Step: 2
Training loss: 1.8555015159524673
Validation loss: 2.680052208026898

Epoch: 6| Step: 3
Training loss: 1.8276053448123637
Validation loss: 2.701352162789025

Epoch: 6| Step: 4
Training loss: 1.9795020639091305
Validation loss: 2.5619679040360666

Epoch: 6| Step: 5
Training loss: 2.0499507712059026
Validation loss: 2.8766364210578237

Epoch: 6| Step: 6
Training loss: 2.250219758216098
Validation loss: 2.880112607014514

Epoch: 6| Step: 7
Training loss: 3.14507468130354
Validation loss: 2.728093103721503

Epoch: 6| Step: 8
Training loss: 2.196242708944204
Validation loss: 2.7268783518495203

Epoch: 6| Step: 9
Training loss: 1.4576657629218892
Validation loss: 2.620117877303654

Epoch: 6| Step: 10
Training loss: 2.362842966848692
Validation loss: 2.791251218833617

Epoch: 6| Step: 11
Training loss: 1.6882076898778176
Validation loss: 2.5956431750702746

Epoch: 6| Step: 12
Training loss: 2.105982107450549
Validation loss: 2.778716352459613

Epoch: 6| Step: 13
Training loss: 2.084907305918822
Validation loss: 2.6154673644570035

Epoch: 597| Step: 0
Training loss: 2.0052891174161123
Validation loss: 2.8089889628707074

Epoch: 6| Step: 1
Training loss: 1.9574004717745104
Validation loss: 2.714884872284431

Epoch: 6| Step: 2
Training loss: 2.7276433425565587
Validation loss: 2.6952071431003195

Epoch: 6| Step: 3
Training loss: 2.037174446917311
Validation loss: 2.6913639926550323

Epoch: 6| Step: 4
Training loss: 1.702452220498371
Validation loss: 2.9386673132828696

Epoch: 6| Step: 5
Training loss: 2.0255106906010782
Validation loss: 2.7568418852706285

Epoch: 6| Step: 6
Training loss: 2.7754104688714847
Validation loss: 2.693011600595622

Epoch: 6| Step: 7
Training loss: 2.040503566335951
Validation loss: 2.815158501777503

Epoch: 6| Step: 8
Training loss: 1.6929698174811687
Validation loss: 2.722378396438964

Epoch: 6| Step: 9
Training loss: 1.7938090829721998
Validation loss: 2.852454444288026

Epoch: 6| Step: 10
Training loss: 1.878300241936481
Validation loss: 2.781758883927246

Epoch: 6| Step: 11
Training loss: 1.951886448113554
Validation loss: 2.7052152557520133

Epoch: 6| Step: 12
Training loss: 2.135498367855562
Validation loss: 2.7528228511462984

Epoch: 6| Step: 13
Training loss: 2.128752032652516
Validation loss: 2.794690637847501

Epoch: 598| Step: 0
Training loss: 2.263032890495486
Validation loss: 2.6959368372172663

Epoch: 6| Step: 1
Training loss: 2.399679253920823
Validation loss: 2.713884780508478

Epoch: 6| Step: 2
Training loss: 2.274107110164017
Validation loss: 2.7583307267772064

Epoch: 6| Step: 3
Training loss: 1.9129031037010658
Validation loss: 2.848325572978007

Epoch: 6| Step: 4
Training loss: 2.389447489443861
Validation loss: 2.7308587192148526

Epoch: 6| Step: 5
Training loss: 1.8806993965096437
Validation loss: 2.8276896359482615

Epoch: 6| Step: 6
Training loss: 1.598443394684573
Validation loss: 2.862653268165232

Epoch: 6| Step: 7
Training loss: 1.9863173222881023
Validation loss: 2.776103305407465

Epoch: 6| Step: 8
Training loss: 2.790616412005394
Validation loss: 2.7084526202970345

Epoch: 6| Step: 9
Training loss: 2.279494773033728
Validation loss: 2.745089669325572

Epoch: 6| Step: 10
Training loss: 1.8035832449217044
Validation loss: 2.8236556407104003

Epoch: 6| Step: 11
Training loss: 2.170713923923224
Validation loss: 2.614030113142421

Epoch: 6| Step: 12
Training loss: 2.114537005238025
Validation loss: 2.6607792593236694

Epoch: 6| Step: 13
Training loss: 1.2225156465554943
Validation loss: 2.702699873341313

Epoch: 599| Step: 0
Training loss: 1.9985945651061892
Validation loss: 2.7676415303253266

Epoch: 6| Step: 1
Training loss: 2.410693734702054
Validation loss: 2.7787092548972514

Epoch: 6| Step: 2
Training loss: 2.21875053728124
Validation loss: 2.780753177606405

Epoch: 6| Step: 3
Training loss: 1.8104003056824713
Validation loss: 2.632057290735257

Epoch: 6| Step: 4
Training loss: 1.8812137638290143
Validation loss: 2.7338074585322234

Epoch: 6| Step: 5
Training loss: 2.7229924917912576
Validation loss: 2.783262465138904

Epoch: 6| Step: 6
Training loss: 2.2213092067472235
Validation loss: 2.5297986656193534

Epoch: 6| Step: 7
Training loss: 1.4389129826080327
Validation loss: 2.7184786012241844

Epoch: 6| Step: 8
Training loss: 1.917057294706748
Validation loss: 2.6585621190058717

Epoch: 6| Step: 9
Training loss: 1.4898884422988203
Validation loss: 2.688681731623945

Epoch: 6| Step: 10
Training loss: 2.6276359946847174
Validation loss: 2.695587071930546

Epoch: 6| Step: 11
Training loss: 3.1702422651742976
Validation loss: 2.7551308383011293

Epoch: 6| Step: 12
Training loss: 1.942279826368919
Validation loss: 2.6546603653738328

Epoch: 6| Step: 13
Training loss: 1.9933296071318605
Validation loss: 2.761662519962541

Epoch: 600| Step: 0
Training loss: 1.940432144877659
Validation loss: 2.542186815632968

Epoch: 6| Step: 1
Training loss: 1.8071323364851934
Validation loss: 2.8476708882449056

Epoch: 6| Step: 2
Training loss: 1.629200348501826
Validation loss: 2.7240491121884647

Epoch: 6| Step: 3
Training loss: 1.7749534547102748
Validation loss: 2.6482719737251372

Epoch: 6| Step: 4
Training loss: 2.0747815534208134
Validation loss: 2.6233216939969894

Epoch: 6| Step: 5
Training loss: 2.5873977825227534
Validation loss: 2.6276849530840267

Epoch: 6| Step: 6
Training loss: 2.269846909019849
Validation loss: 2.644349257940055

Epoch: 6| Step: 7
Training loss: 2.1946285173283986
Validation loss: 2.815795196793632

Epoch: 6| Step: 8
Training loss: 2.2277157657815265
Validation loss: 2.709339726005506

Epoch: 6| Step: 9
Training loss: 1.7840874141223737
Validation loss: 2.66107002737417

Epoch: 6| Step: 10
Training loss: 2.180647225150515
Validation loss: 2.6377818356854954

Epoch: 6| Step: 11
Training loss: 1.8031854364854636
Validation loss: 2.555397465140621

Epoch: 6| Step: 12
Training loss: 1.912321209497682
Validation loss: 2.805276742618026

Epoch: 6| Step: 13
Training loss: 2.4673339065878173
Validation loss: 2.8487382483475185

Epoch: 601| Step: 0
Training loss: 2.3759997421996624
Validation loss: 2.722436671452939

Epoch: 6| Step: 1
Training loss: 1.2791566262280853
Validation loss: 2.605820840152853

Epoch: 6| Step: 2
Training loss: 2.6077045873184486
Validation loss: 2.6454670082172744

Epoch: 6| Step: 3
Training loss: 2.151052208629081
Validation loss: 2.812801267469585

Epoch: 6| Step: 4
Training loss: 2.04343060438781
Validation loss: 2.8258245132650286

Epoch: 6| Step: 5
Training loss: 1.8839523220954162
Validation loss: 2.734117102583318

Epoch: 6| Step: 6
Training loss: 2.517045940678591
Validation loss: 2.7207780081590514

Epoch: 6| Step: 7
Training loss: 2.1920154289203806
Validation loss: 2.7472248263089085

Epoch: 6| Step: 8
Training loss: 2.1694470563355353
Validation loss: 2.686455088744843

Epoch: 6| Step: 9
Training loss: 2.687330906006267
Validation loss: 2.9111559396011235

Epoch: 6| Step: 10
Training loss: 2.108117187738858
Validation loss: 2.6412045121493644

Epoch: 6| Step: 11
Training loss: 2.497511197085096
Validation loss: 2.7037343923252988

Epoch: 6| Step: 12
Training loss: 2.061015085837926
Validation loss: 2.736797922288287

Epoch: 6| Step: 13
Training loss: 1.758077372622212
Validation loss: 2.5083213598867493

Epoch: 602| Step: 0
Training loss: 2.395879418855896
Validation loss: 2.5978334714156386

Epoch: 6| Step: 1
Training loss: 1.969472843258945
Validation loss: 2.6725538382462917

Epoch: 6| Step: 2
Training loss: 2.7724181115153956
Validation loss: 2.5816699533502443

Epoch: 6| Step: 3
Training loss: 1.9139189374373777
Validation loss: 2.657715078630905

Epoch: 6| Step: 4
Training loss: 2.249873263710378
Validation loss: 2.649250970006091

Epoch: 6| Step: 5
Training loss: 2.1071485283800704
Validation loss: 2.832186693699937

Epoch: 6| Step: 6
Training loss: 2.022916748905933
Validation loss: 2.669711473992615

Epoch: 6| Step: 7
Training loss: 2.4063339218763877
Validation loss: 2.8186534385111526

Epoch: 6| Step: 8
Training loss: 1.933274059647628
Validation loss: 2.7145282960172468

Epoch: 6| Step: 9
Training loss: 1.902937214924684
Validation loss: 2.650519610565231

Epoch: 6| Step: 10
Training loss: 2.8723713011168126
Validation loss: 2.6467712704546624

Epoch: 6| Step: 11
Training loss: 2.2486410275530146
Validation loss: 2.6632548434627035

Epoch: 6| Step: 12
Training loss: 1.5648191407240228
Validation loss: 2.8446546754255855

Epoch: 6| Step: 13
Training loss: 1.9824632461816127
Validation loss: 2.8130013500997926

Epoch: 603| Step: 0
Training loss: 1.91274000918255
Validation loss: 2.6333445223288514

Epoch: 6| Step: 1
Training loss: 2.425301767037217
Validation loss: 2.6878756351000717

Epoch: 6| Step: 2
Training loss: 2.435978243268701
Validation loss: 2.7391030682792747

Epoch: 6| Step: 3
Training loss: 3.4345998841401806
Validation loss: 2.654116772995531

Epoch: 6| Step: 4
Training loss: 2.671049023834237
Validation loss: 2.717187387856715

Epoch: 6| Step: 5
Training loss: 2.2210489102834585
Validation loss: 2.6132487525527566

Epoch: 6| Step: 6
Training loss: 2.6186198855466727
Validation loss: 2.686953371455735

Epoch: 6| Step: 7
Training loss: 1.6409032676495465
Validation loss: 2.6217873520287087

Epoch: 6| Step: 8
Training loss: 1.3751114886774543
Validation loss: 2.6019448575796553

Epoch: 6| Step: 9
Training loss: 1.7923380754401117
Validation loss: 2.6045322596382556

Epoch: 6| Step: 10
Training loss: 2.146824900835229
Validation loss: 2.7769537448630652

Epoch: 6| Step: 11
Training loss: 1.5127203725631604
Validation loss: 2.4731555413822646

Epoch: 6| Step: 12
Training loss: 1.8547397827903607
Validation loss: 2.693111369918348

Epoch: 6| Step: 13
Training loss: 1.772308460749583
Validation loss: 2.72974168821929

Epoch: 604| Step: 0
Training loss: 2.0699252936109485
Validation loss: 2.9209447045129324

Epoch: 6| Step: 1
Training loss: 3.110185527112735
Validation loss: 2.6999639849385746

Epoch: 6| Step: 2
Training loss: 1.6499531363565607
Validation loss: 2.7262453608842425

Epoch: 6| Step: 3
Training loss: 2.16230840550867
Validation loss: 2.7938692577508517

Epoch: 6| Step: 4
Training loss: 2.188145678459813
Validation loss: 2.6846618375323335

Epoch: 6| Step: 5
Training loss: 2.353941768830253
Validation loss: 2.7423528394650165

Epoch: 6| Step: 6
Training loss: 1.992534293115359
Validation loss: 2.5587749142460336

Epoch: 6| Step: 7
Training loss: 1.9519246799914856
Validation loss: 2.6490933371584737

Epoch: 6| Step: 8
Training loss: 1.84254519651717
Validation loss: 2.832739489705084

Epoch: 6| Step: 9
Training loss: 1.5872932239342417
Validation loss: 2.808413352445832

Epoch: 6| Step: 10
Training loss: 2.8019403376248273
Validation loss: 2.6823994703379848

Epoch: 6| Step: 11
Training loss: 2.22053327221199
Validation loss: 2.6199807084760507

Epoch: 6| Step: 12
Training loss: 2.662964983530486
Validation loss: 2.628291364132839

Epoch: 6| Step: 13
Training loss: 1.7936243923749033
Validation loss: 2.7160039547759998

Epoch: 605| Step: 0
Training loss: 1.7079609100549926
Validation loss: 2.6129171414956143

Epoch: 6| Step: 1
Training loss: 1.5887333321766253
Validation loss: 2.7128739195057667

Epoch: 6| Step: 2
Training loss: 1.9160973145533347
Validation loss: 2.7597889987430166

Epoch: 6| Step: 3
Training loss: 1.2260751910340628
Validation loss: 2.708225168256374

Epoch: 6| Step: 4
Training loss: 2.4978514021449048
Validation loss: 2.9315793290472256

Epoch: 6| Step: 5
Training loss: 2.249671594176965
Validation loss: 2.7231668472048622

Epoch: 6| Step: 6
Training loss: 2.2977141838980386
Validation loss: 2.6983812826651135

Epoch: 6| Step: 7
Training loss: 3.2011472969903787
Validation loss: 2.8655714136863737

Epoch: 6| Step: 8
Training loss: 2.0261805731088605
Validation loss: 2.7041774580853772

Epoch: 6| Step: 9
Training loss: 1.9954635909431024
Validation loss: 2.670091570299833

Epoch: 6| Step: 10
Training loss: 2.0306882815188545
Validation loss: 2.724123654922749

Epoch: 6| Step: 11
Training loss: 2.062169828863804
Validation loss: 2.7883077374442897

Epoch: 6| Step: 12
Training loss: 2.0568747826399063
Validation loss: 2.733757046253351

Epoch: 6| Step: 13
Training loss: 1.728892553579461
Validation loss: 2.769811830239484

Epoch: 606| Step: 0
Training loss: 2.1102016383363122
Validation loss: 2.4327208767919157

Epoch: 6| Step: 1
Training loss: 1.9584640770413435
Validation loss: 2.690665899372279

Epoch: 6| Step: 2
Training loss: 1.3817391405474304
Validation loss: 2.7758235619847835

Epoch: 6| Step: 3
Training loss: 2.055468856712927
Validation loss: 2.6486990300979816

Epoch: 6| Step: 4
Training loss: 1.740666978970201
Validation loss: 2.811766329363505

Epoch: 6| Step: 5
Training loss: 1.8565783585938733
Validation loss: 2.656645462739044

Epoch: 6| Step: 6
Training loss: 2.370474267819529
Validation loss: 2.630928207291072

Epoch: 6| Step: 7
Training loss: 2.3757660282930653
Validation loss: 2.68578498150215

Epoch: 6| Step: 8
Training loss: 3.304376393637698
Validation loss: 2.5769067535386347

Epoch: 6| Step: 9
Training loss: 1.8715121571917726
Validation loss: 2.681851240096187

Epoch: 6| Step: 10
Training loss: 1.7085720763818102
Validation loss: 2.6222729339104003

Epoch: 6| Step: 11
Training loss: 1.7870464042867547
Validation loss: 2.758682392195066

Epoch: 6| Step: 12
Training loss: 1.9344576668523275
Validation loss: 2.693465236293825

Epoch: 6| Step: 13
Training loss: 2.120184884556568
Validation loss: 2.6536085426112486

Epoch: 607| Step: 0
Training loss: 1.3109756882462502
Validation loss: 2.559308022641613

Epoch: 6| Step: 1
Training loss: 2.601038424655746
Validation loss: 2.68633107860823

Epoch: 6| Step: 2
Training loss: 1.4707499746127777
Validation loss: 2.678070523801905

Epoch: 6| Step: 3
Training loss: 2.0121319689007025
Validation loss: 2.7747475986458587

Epoch: 6| Step: 4
Training loss: 2.199150558688298
Validation loss: 2.5245527782535127

Epoch: 6| Step: 5
Training loss: 1.8560062954894534
Validation loss: 2.7540369002094813

Epoch: 6| Step: 6
Training loss: 2.8576181152709346
Validation loss: 2.5781576821402012

Epoch: 6| Step: 7
Training loss: 2.692077464435956
Validation loss: 2.7009405333141747

Epoch: 6| Step: 8
Training loss: 2.512019920980831
Validation loss: 2.728258564406794

Epoch: 6| Step: 9
Training loss: 1.978203495631679
Validation loss: 2.807524172832487

Epoch: 6| Step: 10
Training loss: 1.8254824719137355
Validation loss: 2.6585267860038457

Epoch: 6| Step: 11
Training loss: 2.420595778750096
Validation loss: 2.5970371448293212

Epoch: 6| Step: 12
Training loss: 1.976842928206253
Validation loss: 2.6708079530968614

Epoch: 6| Step: 13
Training loss: 1.94478517302083
Validation loss: 2.6677911954849454

Epoch: 608| Step: 0
Training loss: 2.125951666066328
Validation loss: 2.658520753281476

Epoch: 6| Step: 1
Training loss: 1.9473092123068079
Validation loss: 2.6622372424569183

Epoch: 6| Step: 2
Training loss: 1.930472272300826
Validation loss: 2.733439887453758

Epoch: 6| Step: 3
Training loss: 3.413072385747417
Validation loss: 2.6247629282243157

Epoch: 6| Step: 4
Training loss: 2.163125065779003
Validation loss: 2.6562864104447077

Epoch: 6| Step: 5
Training loss: 1.6902287637623161
Validation loss: 2.6970283229444445

Epoch: 6| Step: 6
Training loss: 2.0268089456349143
Validation loss: 2.803727269088046

Epoch: 6| Step: 7
Training loss: 1.7830137254589968
Validation loss: 2.601327505316154

Epoch: 6| Step: 8
Training loss: 1.9010393813306754
Validation loss: 2.644197860760825

Epoch: 6| Step: 9
Training loss: 1.8908944686661073
Validation loss: 2.726009545184458

Epoch: 6| Step: 10
Training loss: 1.3498773377818019
Validation loss: 2.733044027159107

Epoch: 6| Step: 11
Training loss: 2.092914699356316
Validation loss: 2.707760719239872

Epoch: 6| Step: 12
Training loss: 2.037605554385753
Validation loss: 2.647572709584802

Epoch: 6| Step: 13
Training loss: 1.414003149652278
Validation loss: 2.7393351682302445

Epoch: 609| Step: 0
Training loss: 2.0943609456564354
Validation loss: 2.8861273143693156

Epoch: 6| Step: 1
Training loss: 1.6439345629679294
Validation loss: 2.709703409998824

Epoch: 6| Step: 2
Training loss: 2.18025927410465
Validation loss: 2.7523017295172636

Epoch: 6| Step: 3
Training loss: 2.778542218455788
Validation loss: 2.8301598953564175

Epoch: 6| Step: 4
Training loss: 2.501827525694518
Validation loss: 2.699622589161653

Epoch: 6| Step: 5
Training loss: 1.7161422366701293
Validation loss: 2.6127510672787797

Epoch: 6| Step: 6
Training loss: 1.944794244939903
Validation loss: 2.8228553795894262

Epoch: 6| Step: 7
Training loss: 1.3973567345327413
Validation loss: 2.764770459218668

Epoch: 6| Step: 8
Training loss: 1.5772578812645794
Validation loss: 2.7656804802188613

Epoch: 6| Step: 9
Training loss: 1.810817661220508
Validation loss: 2.7724529168095233

Epoch: 6| Step: 10
Training loss: 3.0971737807001474
Validation loss: 2.752250340756814

Epoch: 6| Step: 11
Training loss: 2.272475206095084
Validation loss: 2.6972024748082437

Epoch: 6| Step: 12
Training loss: 1.627879818780084
Validation loss: 2.686015421843248

Epoch: 6| Step: 13
Training loss: 2.252516187298495
Validation loss: 2.8648841692484734

Epoch: 610| Step: 0
Training loss: 2.410535488865205
Validation loss: 2.8402559870078665

Epoch: 6| Step: 1
Training loss: 1.818381074802549
Validation loss: 2.658469487124894

Epoch: 6| Step: 2
Training loss: 2.865035993473116
Validation loss: 2.7256472816529747

Epoch: 6| Step: 3
Training loss: 1.782079202490957
Validation loss: 2.586962249591605

Epoch: 6| Step: 4
Training loss: 1.5784967570037443
Validation loss: 2.7500556854397407

Epoch: 6| Step: 5
Training loss: 1.573660398906456
Validation loss: 2.6888538955781134

Epoch: 6| Step: 6
Training loss: 1.371193471906606
Validation loss: 2.702976804824133

Epoch: 6| Step: 7
Training loss: 2.2047677915620665
Validation loss: 2.6265425166328558

Epoch: 6| Step: 8
Training loss: 1.9149974797085345
Validation loss: 2.66833424405721

Epoch: 6| Step: 9
Training loss: 2.156246793440494
Validation loss: 2.7350010721493603

Epoch: 6| Step: 10
Training loss: 2.3174663517390863
Validation loss: 2.62535165715588

Epoch: 6| Step: 11
Training loss: 2.6420446789275194
Validation loss: 2.646338754570911

Epoch: 6| Step: 12
Training loss: 1.9339016139460392
Validation loss: 2.510404797556892

Epoch: 6| Step: 13
Training loss: 2.538159018943521
Validation loss: 2.669342266400511

Epoch: 611| Step: 0
Training loss: 1.7616412701876882
Validation loss: 2.682403235898307

Epoch: 6| Step: 1
Training loss: 1.5744333428585462
Validation loss: 2.7945511366961227

Epoch: 6| Step: 2
Training loss: 2.174340474774855
Validation loss: 2.7717675706493075

Epoch: 6| Step: 3
Training loss: 2.4330697513464328
Validation loss: 2.8059276634030836

Epoch: 6| Step: 4
Training loss: 2.044502339142291
Validation loss: 2.9089307361928074

Epoch: 6| Step: 5
Training loss: 1.772054191557231
Validation loss: 2.816946818887545

Epoch: 6| Step: 6
Training loss: 1.7261421762170284
Validation loss: 2.8273060139191517

Epoch: 6| Step: 7
Training loss: 2.2394319941523353
Validation loss: 2.8483908079873825

Epoch: 6| Step: 8
Training loss: 1.756296139582767
Validation loss: 2.743751444739008

Epoch: 6| Step: 9
Training loss: 2.1008667201781623
Validation loss: 2.7308520905715

Epoch: 6| Step: 10
Training loss: 1.8118745448153695
Validation loss: 2.7020303621304764

Epoch: 6| Step: 11
Training loss: 1.770053946324911
Validation loss: 2.799792938772613

Epoch: 6| Step: 12
Training loss: 3.0396956933955193
Validation loss: 2.687729245038484

Epoch: 6| Step: 13
Training loss: 1.6226969317578763
Validation loss: 2.6557404079376763

Epoch: 612| Step: 0
Training loss: 2.1006252084747277
Validation loss: 2.681804918583174

Epoch: 6| Step: 1
Training loss: 1.445275383550019
Validation loss: 2.794224402276219

Epoch: 6| Step: 2
Training loss: 2.355815703743585
Validation loss: 2.697594754605383

Epoch: 6| Step: 3
Training loss: 2.1260678469291836
Validation loss: 2.813328021998549

Epoch: 6| Step: 4
Training loss: 3.265261835228547
Validation loss: 2.759667189662377

Epoch: 6| Step: 5
Training loss: 2.2973380108699164
Validation loss: 2.6920941713741264

Epoch: 6| Step: 6
Training loss: 2.616312820256305
Validation loss: 2.8105754579904403

Epoch: 6| Step: 7
Training loss: 1.806596613167458
Validation loss: 2.7950687787332105

Epoch: 6| Step: 8
Training loss: 1.58543215061936
Validation loss: 2.5781951666040737

Epoch: 6| Step: 9
Training loss: 1.8775109326568764
Validation loss: 2.7268302389476378

Epoch: 6| Step: 10
Training loss: 1.912489637957657
Validation loss: 2.6359528393317975

Epoch: 6| Step: 11
Training loss: 1.7888963780466856
Validation loss: 2.8690653286893357

Epoch: 6| Step: 12
Training loss: 2.2054692775443265
Validation loss: 2.656436901526355

Epoch: 6| Step: 13
Training loss: 1.8333401752113063
Validation loss: 2.627253253365654

Epoch: 613| Step: 0
Training loss: 2.000196804854011
Validation loss: 2.807471389644452

Epoch: 6| Step: 1
Training loss: 1.8500704004450164
Validation loss: 2.5811138866938896

Epoch: 6| Step: 2
Training loss: 2.6477548625340592
Validation loss: 2.6946725507394325

Epoch: 6| Step: 3
Training loss: 2.4917918880811616
Validation loss: 2.794723518264794

Epoch: 6| Step: 4
Training loss: 1.7138566149958803
Validation loss: 2.94044053079271

Epoch: 6| Step: 5
Training loss: 1.435375301981277
Validation loss: 2.642938163705736

Epoch: 6| Step: 6
Training loss: 1.7171897048172406
Validation loss: 2.76979748718573

Epoch: 6| Step: 7
Training loss: 2.393405668428265
Validation loss: 2.6729600717178705

Epoch: 6| Step: 8
Training loss: 1.780906309466142
Validation loss: 2.9424800257534094

Epoch: 6| Step: 9
Training loss: 2.201803907014948
Validation loss: 2.639910175043617

Epoch: 6| Step: 10
Training loss: 3.274987775474039
Validation loss: 2.716253592077351

Epoch: 6| Step: 11
Training loss: 2.047967750116583
Validation loss: 2.663172040078571

Epoch: 6| Step: 12
Training loss: 2.5137445280754367
Validation loss: 2.6733505146171193

Epoch: 6| Step: 13
Training loss: 1.4181900061968982
Validation loss: 2.767528394570903

Epoch: 614| Step: 0
Training loss: 1.7496302077732417
Validation loss: 2.7159369558099566

Epoch: 6| Step: 1
Training loss: 1.4016273815230393
Validation loss: 2.7559610848948863

Epoch: 6| Step: 2
Training loss: 2.549491053635678
Validation loss: 2.680169933561116

Epoch: 6| Step: 3
Training loss: 1.9212455649191322
Validation loss: 2.8765128356632155

Epoch: 6| Step: 4
Training loss: 2.030284476055249
Validation loss: 2.7785524290175623

Epoch: 6| Step: 5
Training loss: 2.128704096444244
Validation loss: 2.7921596441401193

Epoch: 6| Step: 6
Training loss: 1.6976560927073674
Validation loss: 2.6764158800059232

Epoch: 6| Step: 7
Training loss: 3.1935519939040535
Validation loss: 2.8015397622631726

Epoch: 6| Step: 8
Training loss: 1.6298147910742329
Validation loss: 2.7487209474141228

Epoch: 6| Step: 9
Training loss: 2.1521368186880077
Validation loss: 2.731360212369043

Epoch: 6| Step: 10
Training loss: 1.8153167410400568
Validation loss: 2.8417099959468493

Epoch: 6| Step: 11
Training loss: 1.57522694602652
Validation loss: 2.6960500655876367

Epoch: 6| Step: 12
Training loss: 2.685218197216494
Validation loss: 2.7798304154749895

Epoch: 6| Step: 13
Training loss: 2.5824345491577505
Validation loss: 2.859561576294727

Epoch: 615| Step: 0
Training loss: 2.233049012585403
Validation loss: 2.7879562612990774

Epoch: 6| Step: 1
Training loss: 2.1422060953859323
Validation loss: 2.6595923640897716

Epoch: 6| Step: 2
Training loss: 2.612520708795997
Validation loss: 2.8373773609492288

Epoch: 6| Step: 3
Training loss: 2.218797710066928
Validation loss: 2.594967183510539

Epoch: 6| Step: 4
Training loss: 1.2908383246256154
Validation loss: 2.8378021285380384

Epoch: 6| Step: 5
Training loss: 1.956662689651182
Validation loss: 2.750282621730048

Epoch: 6| Step: 6
Training loss: 2.210352951794982
Validation loss: 2.622033003561898

Epoch: 6| Step: 7
Training loss: 2.300473566644237
Validation loss: 2.556957017384315

Epoch: 6| Step: 8
Training loss: 1.4666040855118796
Validation loss: 2.7019640261997586

Epoch: 6| Step: 9
Training loss: 2.830607468072121
Validation loss: 2.6921724575776778

Epoch: 6| Step: 10
Training loss: 2.1679544534297754
Validation loss: 2.79614324501799

Epoch: 6| Step: 11
Training loss: 2.6205133514675567
Validation loss: 2.7336799659402446

Epoch: 6| Step: 12
Training loss: 1.442713199244624
Validation loss: 2.7384986322459044

Epoch: 6| Step: 13
Training loss: 1.7002402556568812
Validation loss: 2.7569601591766557

Epoch: 616| Step: 0
Training loss: 1.8424167661875472
Validation loss: 2.693152035856754

Epoch: 6| Step: 1
Training loss: 1.8917245741171858
Validation loss: 2.6981982129646664

Epoch: 6| Step: 2
Training loss: 1.6813216665656256
Validation loss: 2.769903286112205

Epoch: 6| Step: 3
Training loss: 2.0986950680040097
Validation loss: 2.7297512356153817

Epoch: 6| Step: 4
Training loss: 1.968681939780291
Validation loss: 2.6466411713498137

Epoch: 6| Step: 5
Training loss: 2.1095642004992006
Validation loss: 2.8271543117040436

Epoch: 6| Step: 6
Training loss: 2.761197614263537
Validation loss: 2.836567126914857

Epoch: 6| Step: 7
Training loss: 1.3588389951308104
Validation loss: 2.8320914589461514

Epoch: 6| Step: 8
Training loss: 1.9307675447260808
Validation loss: 2.720150017207803

Epoch: 6| Step: 9
Training loss: 1.7052161301807645
Validation loss: 2.689117976732649

Epoch: 6| Step: 10
Training loss: 1.8934514380050775
Validation loss: 2.8879619895573905

Epoch: 6| Step: 11
Training loss: 2.8706255264996012
Validation loss: 2.921203277236853

Epoch: 6| Step: 12
Training loss: 2.3478843336973365
Validation loss: 2.741005386245756

Epoch: 6| Step: 13
Training loss: 1.5182048431419741
Validation loss: 2.7915613236905603

Epoch: 617| Step: 0
Training loss: 2.4096188432967365
Validation loss: 2.6050530842644557

Epoch: 6| Step: 1
Training loss: 2.096678777800222
Validation loss: 2.7891485869016606

Epoch: 6| Step: 2
Training loss: 2.151813199377081
Validation loss: 2.6353812834056076

Epoch: 6| Step: 3
Training loss: 2.2724106819553107
Validation loss: 2.7229435061908704

Epoch: 6| Step: 4
Training loss: 1.5963035023683887
Validation loss: 2.674076934863195

Epoch: 6| Step: 5
Training loss: 1.943810430734207
Validation loss: 2.624333833779237

Epoch: 6| Step: 6
Training loss: 2.6605812215037266
Validation loss: 2.6844757780484385

Epoch: 6| Step: 7
Training loss: 1.8466208139412263
Validation loss: 2.6563986421191066

Epoch: 6| Step: 8
Training loss: 2.099515350365626
Validation loss: 2.7622801173364855

Epoch: 6| Step: 9
Training loss: 2.8775136159513393
Validation loss: 2.547355600974027

Epoch: 6| Step: 10
Training loss: 2.0109888030223706
Validation loss: 2.6918173355373343

Epoch: 6| Step: 11
Training loss: 2.0405504198451396
Validation loss: 2.6814377040719735

Epoch: 6| Step: 12
Training loss: 1.7316530192366404
Validation loss: 2.6399020691840165

Epoch: 6| Step: 13
Training loss: 1.6714161751302579
Validation loss: 2.870955761067232

Epoch: 618| Step: 0
Training loss: 2.4253515087087685
Validation loss: 2.776255984522637

Epoch: 6| Step: 1
Training loss: 2.337324566301151
Validation loss: 2.6850458144647282

Epoch: 6| Step: 2
Training loss: 1.9755294572994133
Validation loss: 2.7247403216319417

Epoch: 6| Step: 3
Training loss: 2.7821933132446395
Validation loss: 2.7466037600880333

Epoch: 6| Step: 4
Training loss: 1.7183627992922377
Validation loss: 2.692278305551652

Epoch: 6| Step: 5
Training loss: 2.3683025893762375
Validation loss: 2.650246890735787

Epoch: 6| Step: 6
Training loss: 2.113004260851874
Validation loss: 2.7423778031192017

Epoch: 6| Step: 7
Training loss: 3.2944554132711734
Validation loss: 2.734856099407071

Epoch: 6| Step: 8
Training loss: 1.6587231003880625
Validation loss: 2.773939292445306

Epoch: 6| Step: 9
Training loss: 2.2539682363253855
Validation loss: 2.6501917044731305

Epoch: 6| Step: 10
Training loss: 2.2234833423770293
Validation loss: 2.7937893973936183

Epoch: 6| Step: 11
Training loss: 1.1906054197288332
Validation loss: 2.6042013061844806

Epoch: 6| Step: 12
Training loss: 1.958919870183641
Validation loss: 2.5960319494282413

Epoch: 6| Step: 13
Training loss: 1.580825534587493
Validation loss: 2.6092016358873935

Epoch: 619| Step: 0
Training loss: 1.9428975385585607
Validation loss: 2.6515752241448958

Epoch: 6| Step: 1
Training loss: 2.0978717373605127
Validation loss: 2.8012649595095436

Epoch: 6| Step: 2
Training loss: 1.6351112355881425
Validation loss: 2.8585242580380443

Epoch: 6| Step: 3
Training loss: 1.7713911711242905
Validation loss: 2.704320931943265

Epoch: 6| Step: 4
Training loss: 1.8678611912666552
Validation loss: 2.625599963979512

Epoch: 6| Step: 5
Training loss: 2.1833255719151268
Validation loss: 2.816925455641328

Epoch: 6| Step: 6
Training loss: 1.9790082433103846
Validation loss: 2.6990938160848983

Epoch: 6| Step: 7
Training loss: 2.059690006227376
Validation loss: 2.651118779855453

Epoch: 6| Step: 8
Training loss: 2.2255100908532737
Validation loss: 2.703928074000809

Epoch: 6| Step: 9
Training loss: 1.9403668390087805
Validation loss: 2.6528704285841744

Epoch: 6| Step: 10
Training loss: 2.5619781707143403
Validation loss: 2.6952957388208243

Epoch: 6| Step: 11
Training loss: 2.7031390239373843
Validation loss: 2.6439139067170503

Epoch: 6| Step: 12
Training loss: 1.7692992877291043
Validation loss: 2.6983448616346095

Epoch: 6| Step: 13
Training loss: 2.293494922892621
Validation loss: 2.7331670021193037

Epoch: 620| Step: 0
Training loss: 1.7429757152710585
Validation loss: 2.8343441666261935

Epoch: 6| Step: 1
Training loss: 1.1015671533797435
Validation loss: 2.697902958934449

Epoch: 6| Step: 2
Training loss: 2.980827419953048
Validation loss: 2.7591409751893776

Epoch: 6| Step: 3
Training loss: 2.1170316406537943
Validation loss: 2.774042655371117

Epoch: 6| Step: 4
Training loss: 2.360659218222757
Validation loss: 2.5694273408118935

Epoch: 6| Step: 5
Training loss: 1.61498563943153
Validation loss: 2.7997600945412153

Epoch: 6| Step: 6
Training loss: 1.6787766936928739
Validation loss: 2.7649240311677126

Epoch: 6| Step: 7
Training loss: 1.656941827198373
Validation loss: 2.59343467601486

Epoch: 6| Step: 8
Training loss: 2.314362265819405
Validation loss: 2.6084242620079037

Epoch: 6| Step: 9
Training loss: 2.0412330037125983
Validation loss: 2.742474034084826

Epoch: 6| Step: 10
Training loss: 2.972884341097378
Validation loss: 2.686832065479923

Epoch: 6| Step: 11
Training loss: 2.340953735572287
Validation loss: 2.65073440008563

Epoch: 6| Step: 12
Training loss: 2.1119153585018102
Validation loss: 2.696403318116091

Epoch: 6| Step: 13
Training loss: 1.7887684942818212
Validation loss: 2.686457433419176

Epoch: 621| Step: 0
Training loss: 1.8023386941548682
Validation loss: 2.7236692944668306

Epoch: 6| Step: 1
Training loss: 2.0399206701449493
Validation loss: 2.6597197713360217

Epoch: 6| Step: 2
Training loss: 1.7439386436667277
Validation loss: 2.5974105675602446

Epoch: 6| Step: 3
Training loss: 1.4503377619694509
Validation loss: 2.7948143951428808

Epoch: 6| Step: 4
Training loss: 1.86682150857034
Validation loss: 2.702806352399814

Epoch: 6| Step: 5
Training loss: 1.7941269800758213
Validation loss: 2.604112528740702

Epoch: 6| Step: 6
Training loss: 2.7733206710923732
Validation loss: 2.7202687823835463

Epoch: 6| Step: 7
Training loss: 1.978592444657943
Validation loss: 2.7066385486576294

Epoch: 6| Step: 8
Training loss: 2.5331579482286193
Validation loss: 2.694562727628051

Epoch: 6| Step: 9
Training loss: 1.840804835084967
Validation loss: 2.6676308948527234

Epoch: 6| Step: 10
Training loss: 2.528283346943946
Validation loss: 2.8355403829907737

Epoch: 6| Step: 11
Training loss: 1.3694535141430255
Validation loss: 2.681796516826326

Epoch: 6| Step: 12
Training loss: 1.8482866885138847
Validation loss: 2.740874494137668

Epoch: 6| Step: 13
Training loss: 2.616296690603055
Validation loss: 2.509507036204477

Epoch: 622| Step: 0
Training loss: 1.8544929588762218
Validation loss: 2.6821213222612763

Epoch: 6| Step: 1
Training loss: 2.2127556216748525
Validation loss: 2.7482486696853408

Epoch: 6| Step: 2
Training loss: 2.127616841820478
Validation loss: 2.6994902360855333

Epoch: 6| Step: 3
Training loss: 1.6127642895478393
Validation loss: 2.6503706817731447

Epoch: 6| Step: 4
Training loss: 1.742253597357073
Validation loss: 2.7819298529360577

Epoch: 6| Step: 5
Training loss: 3.4455295070546668
Validation loss: 2.6940020099939073

Epoch: 6| Step: 6
Training loss: 2.0263982490089223
Validation loss: 2.697784407916565

Epoch: 6| Step: 7
Training loss: 2.223971174025857
Validation loss: 2.5552224584479446

Epoch: 6| Step: 8
Training loss: 2.4698512844150082
Validation loss: 2.7416769994062316

Epoch: 6| Step: 9
Training loss: 1.7312883283317864
Validation loss: 2.6309839691107633

Epoch: 6| Step: 10
Training loss: 2.1688960661057153
Validation loss: 2.6943654174331333

Epoch: 6| Step: 11
Training loss: 2.06004892994815
Validation loss: 2.654050797072263

Epoch: 6| Step: 12
Training loss: 1.8744606513907036
Validation loss: 2.670819033865911

Epoch: 6| Step: 13
Training loss: 3.328649918258199
Validation loss: 2.58098626784148

Epoch: 623| Step: 0
Training loss: 2.1566244712408404
Validation loss: 2.712721238731196

Epoch: 6| Step: 1
Training loss: 1.5202667888108905
Validation loss: 2.726312693289415

Epoch: 6| Step: 2
Training loss: 1.4519855584931807
Validation loss: 2.6869121527692625

Epoch: 6| Step: 3
Training loss: 3.0594395506987686
Validation loss: 2.8369306845994586

Epoch: 6| Step: 4
Training loss: 2.7602519627983826
Validation loss: 2.6811249010182276

Epoch: 6| Step: 5
Training loss: 1.8517127640025255
Validation loss: 2.9311678240227006

Epoch: 6| Step: 6
Training loss: 1.9525521620890722
Validation loss: 2.701119481225466

Epoch: 6| Step: 7
Training loss: 1.7723585703479943
Validation loss: 2.8473876140414354

Epoch: 6| Step: 8
Training loss: 1.36832672611613
Validation loss: 2.853202556990096

Epoch: 6| Step: 9
Training loss: 2.3284078336614393
Validation loss: 2.915892791628088

Epoch: 6| Step: 10
Training loss: 1.674882554448971
Validation loss: 2.826171684507498

Epoch: 6| Step: 11
Training loss: 2.406909109233983
Validation loss: 2.808917482286845

Epoch: 6| Step: 12
Training loss: 1.7880711369967062
Validation loss: 2.7147606914353593

Epoch: 6| Step: 13
Training loss: 2.444279461649057
Validation loss: 2.8236054833827486

Epoch: 624| Step: 0
Training loss: 1.728155721491379
Validation loss: 2.7024126756810367

Epoch: 6| Step: 1
Training loss: 2.116722816062959
Validation loss: 2.632117204108784

Epoch: 6| Step: 2
Training loss: 3.035980466184235
Validation loss: 2.57243011033667

Epoch: 6| Step: 3
Training loss: 2.1455720415255173
Validation loss: 2.6753760543387974

Epoch: 6| Step: 4
Training loss: 2.2508753027658095
Validation loss: 2.9044271877469

Epoch: 6| Step: 5
Training loss: 1.6062545152890162
Validation loss: 2.7138793346608145

Epoch: 6| Step: 6
Training loss: 1.9107728052791009
Validation loss: 2.7754323613474785

Epoch: 6| Step: 7
Training loss: 1.6718333586738856
Validation loss: 2.603545565134873

Epoch: 6| Step: 8
Training loss: 1.6010535943557642
Validation loss: 2.6728212304633803

Epoch: 6| Step: 9
Training loss: 1.9104366291740655
Validation loss: 2.673387062313914

Epoch: 6| Step: 10
Training loss: 2.3564275052424972
Validation loss: 2.698375214585982

Epoch: 6| Step: 11
Training loss: 1.3850535105617565
Validation loss: 2.766376960205652

Epoch: 6| Step: 12
Training loss: 1.674336911373782
Validation loss: 2.7605221168466305

Epoch: 6| Step: 13
Training loss: 1.749527867525072
Validation loss: 2.770622993631863

Epoch: 625| Step: 0
Training loss: 1.817667402300303
Validation loss: 2.590616497244193

Epoch: 6| Step: 1
Training loss: 1.707458442640261
Validation loss: 2.664889568023321

Epoch: 6| Step: 2
Training loss: 1.499489458938085
Validation loss: 2.6878942356432036

Epoch: 6| Step: 3
Training loss: 2.715052930059542
Validation loss: 2.829661210726434

Epoch: 6| Step: 4
Training loss: 1.3404504053203665
Validation loss: 2.5900721632003996

Epoch: 6| Step: 5
Training loss: 2.1256131802157086
Validation loss: 2.610876079850767

Epoch: 6| Step: 6
Training loss: 2.1549176508842014
Validation loss: 2.6435415548389343

Epoch: 6| Step: 7
Training loss: 2.9182179458205453
Validation loss: 2.5932652138640075

Epoch: 6| Step: 8
Training loss: 2.200436080715025
Validation loss: 2.740868941037771

Epoch: 6| Step: 9
Training loss: 1.8409985200543442
Validation loss: 2.630416774785392

Epoch: 6| Step: 10
Training loss: 1.5136781753901136
Validation loss: 2.6491314901381413

Epoch: 6| Step: 11
Training loss: 2.224502627898722
Validation loss: 2.7242515815671453

Epoch: 6| Step: 12
Training loss: 2.6907175010526823
Validation loss: 2.7599285375980713

Epoch: 6| Step: 13
Training loss: 1.2429831973326584
Validation loss: 2.75655211088918

Epoch: 626| Step: 0
Training loss: 2.471827074206008
Validation loss: 2.7572237004573004

Epoch: 6| Step: 1
Training loss: 1.4517081952350304
Validation loss: 2.744755916888411

Epoch: 6| Step: 2
Training loss: 2.581184929496294
Validation loss: 2.7251782572645813

Epoch: 6| Step: 3
Training loss: 1.3459870989721132
Validation loss: 2.750735908777189

Epoch: 6| Step: 4
Training loss: 1.8020760273279992
Validation loss: 2.7031804940405464

Epoch: 6| Step: 5
Training loss: 1.5501677791480866
Validation loss: 2.592443994074632

Epoch: 6| Step: 6
Training loss: 2.7031132692291973
Validation loss: 2.8189416982672038

Epoch: 6| Step: 7
Training loss: 2.3921621529340724
Validation loss: 2.7002628140776923

Epoch: 6| Step: 8
Training loss: 1.6734431390462514
Validation loss: 2.783538894131452

Epoch: 6| Step: 9
Training loss: 1.8542051489904905
Validation loss: 2.733158417764259

Epoch: 6| Step: 10
Training loss: 2.8105024237494205
Validation loss: 2.68256296342343

Epoch: 6| Step: 11
Training loss: 1.8755376680680238
Validation loss: 2.6752117722547077

Epoch: 6| Step: 12
Training loss: 1.974539705551045
Validation loss: 2.7178968883392525

Epoch: 6| Step: 13
Training loss: 0.8730797814775172
Validation loss: 2.5943421321618176

Epoch: 627| Step: 0
Training loss: 1.6561306604540142
Validation loss: 2.5967370673717753

Epoch: 6| Step: 1
Training loss: 1.6616933371425973
Validation loss: 2.6366512589835267

Epoch: 6| Step: 2
Training loss: 1.921723770766535
Validation loss: 2.619549127818564

Epoch: 6| Step: 3
Training loss: 2.0319439216219664
Validation loss: 2.727340490871895

Epoch: 6| Step: 4
Training loss: 2.9466690460759333
Validation loss: 2.7467305520066403

Epoch: 6| Step: 5
Training loss: 2.4444412775693474
Validation loss: 2.645170160816945

Epoch: 6| Step: 6
Training loss: 2.1340319602167543
Validation loss: 2.598012831407944

Epoch: 6| Step: 7
Training loss: 1.7764342947054816
Validation loss: 2.8334677225220077

Epoch: 6| Step: 8
Training loss: 2.10608150362866
Validation loss: 2.751050551730264

Epoch: 6| Step: 9
Training loss: 2.2462926627275297
Validation loss: 2.81777303194272

Epoch: 6| Step: 10
Training loss: 1.7868866995408101
Validation loss: 2.668437829746168

Epoch: 6| Step: 11
Training loss: 1.6914925145799147
Validation loss: 2.605424889252543

Epoch: 6| Step: 12
Training loss: 2.0588649737570393
Validation loss: 2.6697475654515337

Epoch: 6| Step: 13
Training loss: 1.524716354006397
Validation loss: 2.590237802581937

Epoch: 628| Step: 0
Training loss: 2.0575113943718444
Validation loss: 2.7419318202752496

Epoch: 6| Step: 1
Training loss: 2.716703499698382
Validation loss: 2.7486246963855554

Epoch: 6| Step: 2
Training loss: 2.5826014640795094
Validation loss: 2.7707980518622244

Epoch: 6| Step: 3
Training loss: 1.6491219062507252
Validation loss: 2.6622101387129384

Epoch: 6| Step: 4
Training loss: 2.155939162696455
Validation loss: 3.002164989248838

Epoch: 6| Step: 5
Training loss: 2.4912482617377436
Validation loss: 2.8933676592769415

Epoch: 6| Step: 6
Training loss: 1.8777407007049356
Validation loss: 2.9962379245573847

Epoch: 6| Step: 7
Training loss: 1.2956833477655727
Validation loss: 2.676536162906836

Epoch: 6| Step: 8
Training loss: 2.250948811854429
Validation loss: 2.8566580203735525

Epoch: 6| Step: 9
Training loss: 1.8376599611994613
Validation loss: 2.678215834633353

Epoch: 6| Step: 10
Training loss: 2.334672055628011
Validation loss: 2.751552114876871

Epoch: 6| Step: 11
Training loss: 1.9055494052885333
Validation loss: 2.698156576971237

Epoch: 6| Step: 12
Training loss: 2.051305968958237
Validation loss: 2.722791668767741

Epoch: 6| Step: 13
Training loss: 2.5898094117432757
Validation loss: 2.619980476572489

Epoch: 629| Step: 0
Training loss: 2.001668710741984
Validation loss: 2.7025967395406365

Epoch: 6| Step: 1
Training loss: 2.243885952116813
Validation loss: 2.502649575719828

Epoch: 6| Step: 2
Training loss: 1.8114053775124188
Validation loss: 2.7579188897604867

Epoch: 6| Step: 3
Training loss: 1.9836722503790358
Validation loss: 2.6787828104393947

Epoch: 6| Step: 4
Training loss: 1.7309170867658377
Validation loss: 2.6510588182031145

Epoch: 6| Step: 5
Training loss: 2.1756322183026264
Validation loss: 2.8024675702261397

Epoch: 6| Step: 6
Training loss: 1.6305978896613182
Validation loss: 2.7495864247672768

Epoch: 6| Step: 7
Training loss: 2.1808885116311645
Validation loss: 2.7860361645226615

Epoch: 6| Step: 8
Training loss: 2.6327050976679143
Validation loss: 2.7426700284946266

Epoch: 6| Step: 9
Training loss: 2.4912453906623857
Validation loss: 2.813968031029224

Epoch: 6| Step: 10
Training loss: 1.6931199341195136
Validation loss: 2.7661924007823653

Epoch: 6| Step: 11
Training loss: 2.3485537319391736
Validation loss: 2.6480637889046377

Epoch: 6| Step: 12
Training loss: 2.764339859644458
Validation loss: 2.5518118915935637

Epoch: 6| Step: 13
Training loss: 2.024712827123421
Validation loss: 2.753346626941444

Epoch: 630| Step: 0
Training loss: 2.7977353269921554
Validation loss: 2.7518129311225636

Epoch: 6| Step: 1
Training loss: 1.7295131412832867
Validation loss: 2.854013271953799

Epoch: 6| Step: 2
Training loss: 2.1833644466755513
Validation loss: 2.829724083820794

Epoch: 6| Step: 3
Training loss: 2.190742052028351
Validation loss: 2.903382209469658

Epoch: 6| Step: 4
Training loss: 2.715709871956608
Validation loss: 2.7914109318763187

Epoch: 6| Step: 5
Training loss: 2.268908627011465
Validation loss: 2.7429382261396076

Epoch: 6| Step: 6
Training loss: 1.7158701959435605
Validation loss: 2.7315567442447475

Epoch: 6| Step: 7
Training loss: 1.7278916434205553
Validation loss: 2.5918431725994875

Epoch: 6| Step: 8
Training loss: 1.9713711924722654
Validation loss: 2.7762402947082374

Epoch: 6| Step: 9
Training loss: 1.9561678567526137
Validation loss: 2.8635389668677433

Epoch: 6| Step: 10
Training loss: 1.6291022971754952
Validation loss: 2.8297836379336605

Epoch: 6| Step: 11
Training loss: 2.0084929148269137
Validation loss: 2.784571524952833

Epoch: 6| Step: 12
Training loss: 1.8090824925142799
Validation loss: 2.8004749416810597

Epoch: 6| Step: 13
Training loss: 1.9884891064110226
Validation loss: 2.6459098755107737

Epoch: 631| Step: 0
Training loss: 2.610811671769762
Validation loss: 2.715152229376292

Epoch: 6| Step: 1
Training loss: 2.111706723578696
Validation loss: 2.6675684913963673

Epoch: 6| Step: 2
Training loss: 2.681393983616271
Validation loss: 2.8514852488897358

Epoch: 6| Step: 3
Training loss: 1.6670672014875443
Validation loss: 2.605288703302219

Epoch: 6| Step: 4
Training loss: 1.7969760368800056
Validation loss: 2.593305017596317

Epoch: 6| Step: 5
Training loss: 2.3175072972122086
Validation loss: 2.681251280304536

Epoch: 6| Step: 6
Training loss: 1.5128202934671149
Validation loss: 2.7018703090733114

Epoch: 6| Step: 7
Training loss: 2.1124362913377857
Validation loss: 2.564559996901688

Epoch: 6| Step: 8
Training loss: 1.9789807148630338
Validation loss: 2.6549451080315296

Epoch: 6| Step: 9
Training loss: 1.7453744247229035
Validation loss: 2.6537186984567596

Epoch: 6| Step: 10
Training loss: 1.7497081513232797
Validation loss: 2.641394161232819

Epoch: 6| Step: 11
Training loss: 2.076256966484458
Validation loss: 2.6157948735907506

Epoch: 6| Step: 12
Training loss: 2.441569037541594
Validation loss: 2.715688506232917

Epoch: 6| Step: 13
Training loss: 2.107256807751418
Validation loss: 2.5753195664593505

Epoch: 632| Step: 0
Training loss: 1.8653656439001751
Validation loss: 2.6434511038275375

Epoch: 6| Step: 1
Training loss: 1.8292063587838132
Validation loss: 2.606700805839357

Epoch: 6| Step: 2
Training loss: 2.5206515874578947
Validation loss: 2.89240562806091

Epoch: 6| Step: 3
Training loss: 1.9471529791264717
Validation loss: 2.7772385603688323

Epoch: 6| Step: 4
Training loss: 1.3201862703734901
Validation loss: 2.768309574851909

Epoch: 6| Step: 5
Training loss: 2.062615824828395
Validation loss: 2.7460960689596674

Epoch: 6| Step: 6
Training loss: 1.630104849783922
Validation loss: 2.7296038098034425

Epoch: 6| Step: 7
Training loss: 3.0229878251376032
Validation loss: 2.893614613892305

Epoch: 6| Step: 8
Training loss: 1.8612228956228085
Validation loss: 2.7282590774621447

Epoch: 6| Step: 9
Training loss: 2.675892091112115
Validation loss: 2.6503263637062986

Epoch: 6| Step: 10
Training loss: 1.9495708017693152
Validation loss: 2.9045655870009717

Epoch: 6| Step: 11
Training loss: 1.5065941508461294
Validation loss: 2.662043670837053

Epoch: 6| Step: 12
Training loss: 2.310538207269245
Validation loss: 2.740316044013441

Epoch: 6| Step: 13
Training loss: 2.248633393534679
Validation loss: 2.753574436700961

Epoch: 633| Step: 0
Training loss: 1.5484938194587596
Validation loss: 2.740865003259256

Epoch: 6| Step: 1
Training loss: 2.9318506011890975
Validation loss: 2.6317826991387263

Epoch: 6| Step: 2
Training loss: 2.4651383648586442
Validation loss: 2.68670336474623

Epoch: 6| Step: 3
Training loss: 2.0882964208232377
Validation loss: 2.8105592309582024

Epoch: 6| Step: 4
Training loss: 2.2748309187884552
Validation loss: 2.626787279411334

Epoch: 6| Step: 5
Training loss: 2.140274576059178
Validation loss: 2.8572859569683904

Epoch: 6| Step: 6
Training loss: 1.6595565610362801
Validation loss: 2.609178923432349

Epoch: 6| Step: 7
Training loss: 2.4453873790452403
Validation loss: 2.7733100155837325

Epoch: 6| Step: 8
Training loss: 2.243966702593292
Validation loss: 2.701367249337881

Epoch: 6| Step: 9
Training loss: 1.9668023299716433
Validation loss: 2.6398609315871413

Epoch: 6| Step: 10
Training loss: 1.8489325149954294
Validation loss: 2.7156971996190586

Epoch: 6| Step: 11
Training loss: 1.4598992069934411
Validation loss: 2.8597961112101578

Epoch: 6| Step: 12
Training loss: 1.580374219615876
Validation loss: 2.7729111463874667

Epoch: 6| Step: 13
Training loss: 2.1066978137011425
Validation loss: 2.8616325118239483

Epoch: 634| Step: 0
Training loss: 1.67812242561015
Validation loss: 2.6487614212773636

Epoch: 6| Step: 1
Training loss: 1.7503479203010042
Validation loss: 2.7463978736237795

Epoch: 6| Step: 2
Training loss: 0.9500972622723448
Validation loss: 2.6639897910920265

Epoch: 6| Step: 3
Training loss: 1.8921827094145784
Validation loss: 2.7598133216425675

Epoch: 6| Step: 4
Training loss: 1.8834405381852426
Validation loss: 2.671115146646006

Epoch: 6| Step: 5
Training loss: 1.6829723795790665
Validation loss: 2.74349873278238

Epoch: 6| Step: 6
Training loss: 2.3859994057129392
Validation loss: 2.63305512211639

Epoch: 6| Step: 7
Training loss: 2.171427728717325
Validation loss: 2.5954262332775078

Epoch: 6| Step: 8
Training loss: 1.877943779807694
Validation loss: 2.671904199077624

Epoch: 6| Step: 9
Training loss: 1.799507799670632
Validation loss: 2.757732098409692

Epoch: 6| Step: 10
Training loss: 1.8703544286937506
Validation loss: 2.7123894267584445

Epoch: 6| Step: 11
Training loss: 2.1987278120993556
Validation loss: 2.7696790968860587

Epoch: 6| Step: 12
Training loss: 2.9326563733125406
Validation loss: 2.8971665887467997

Epoch: 6| Step: 13
Training loss: 1.8031119863480165
Validation loss: 2.7217012200092707

Epoch: 635| Step: 0
Training loss: 1.4164268159714613
Validation loss: 2.785473298310812

Epoch: 6| Step: 1
Training loss: 2.0592671112835297
Validation loss: 2.7366431270300073

Epoch: 6| Step: 2
Training loss: 1.8803232286453704
Validation loss: 2.814283260026505

Epoch: 6| Step: 3
Training loss: 2.146301761596224
Validation loss: 2.6312177181857717

Epoch: 6| Step: 4
Training loss: 1.354584771191434
Validation loss: 2.6818502516726435

Epoch: 6| Step: 5
Training loss: 2.6011194533476343
Validation loss: 2.8142488226743994

Epoch: 6| Step: 6
Training loss: 2.2723265355277884
Validation loss: 2.744719752559523

Epoch: 6| Step: 7
Training loss: 1.7929004664497763
Validation loss: 2.719316189030155

Epoch: 6| Step: 8
Training loss: 2.540995545714767
Validation loss: 2.679482595123894

Epoch: 6| Step: 9
Training loss: 1.9847323478877636
Validation loss: 2.7900009922504077

Epoch: 6| Step: 10
Training loss: 2.3627117889579052
Validation loss: 2.5878281992377232

Epoch: 6| Step: 11
Training loss: 1.8806419682648454
Validation loss: 2.693256702131977

Epoch: 6| Step: 12
Training loss: 2.0402188000494443
Validation loss: 2.757225008672342

Epoch: 6| Step: 13
Training loss: 3.2839698781201374
Validation loss: 2.6980525283600914

Epoch: 636| Step: 0
Training loss: 2.071852201448553
Validation loss: 2.7254994212742822

Epoch: 6| Step: 1
Training loss: 1.6274746611888893
Validation loss: 2.6792197257931587

Epoch: 6| Step: 2
Training loss: 1.45474759642538
Validation loss: 2.723261671851652

Epoch: 6| Step: 3
Training loss: 2.506691179899654
Validation loss: 2.7585211940783907

Epoch: 6| Step: 4
Training loss: 1.938555091785459
Validation loss: 2.7163807483398705

Epoch: 6| Step: 5
Training loss: 1.5688304075022457
Validation loss: 2.7896455958548096

Epoch: 6| Step: 6
Training loss: 2.2681023043613613
Validation loss: 2.685444783616677

Epoch: 6| Step: 7
Training loss: 1.4504730472420908
Validation loss: 2.7977053940917194

Epoch: 6| Step: 8
Training loss: 1.5507170618259196
Validation loss: 2.6212190899729277

Epoch: 6| Step: 9
Training loss: 2.1229550114526345
Validation loss: 2.7052429009245484

Epoch: 6| Step: 10
Training loss: 1.838376182766907
Validation loss: 2.8908785402010317

Epoch: 6| Step: 11
Training loss: 2.6907314124425405
Validation loss: 2.8037053305524773

Epoch: 6| Step: 12
Training loss: 1.4721455384122488
Validation loss: 2.7285990315328723

Epoch: 6| Step: 13
Training loss: 3.5473897283189113
Validation loss: 2.760864870287796

Epoch: 637| Step: 0
Training loss: 1.7977636378978752
Validation loss: 2.578093390396856

Epoch: 6| Step: 1
Training loss: 1.8833264800878193
Validation loss: 2.8348067076230565

Epoch: 6| Step: 2
Training loss: 2.3571264402635266
Validation loss: 2.5879648042504417

Epoch: 6| Step: 3
Training loss: 1.7161012527008668
Validation loss: 2.8052967232632113

Epoch: 6| Step: 4
Training loss: 1.8592742123255117
Validation loss: 2.6954525005688628

Epoch: 6| Step: 5
Training loss: 1.7157473605631866
Validation loss: 2.85178260554977

Epoch: 6| Step: 6
Training loss: 2.2932494737388933
Validation loss: 2.8043676637237884

Epoch: 6| Step: 7
Training loss: 2.192406845810643
Validation loss: 2.869997347284221

Epoch: 6| Step: 8
Training loss: 2.700693437044189
Validation loss: 2.77590372679088

Epoch: 6| Step: 9
Training loss: 1.493880824022397
Validation loss: 2.750634821187242

Epoch: 6| Step: 10
Training loss: 1.7082735686974302
Validation loss: 2.7033712263205354

Epoch: 6| Step: 11
Training loss: 1.7151819820998502
Validation loss: 2.856196387261632

Epoch: 6| Step: 12
Training loss: 1.799747459921705
Validation loss: 2.714730646340751

Epoch: 6| Step: 13
Training loss: 2.989157474681999
Validation loss: 2.7499150461627604

Epoch: 638| Step: 0
Training loss: 1.8484758490794861
Validation loss: 2.6444350360360485

Epoch: 6| Step: 1
Training loss: 1.605191914620701
Validation loss: 2.70979365946958

Epoch: 6| Step: 2
Training loss: 1.6128466300110083
Validation loss: 2.6055156454297523

Epoch: 6| Step: 3
Training loss: 1.669619455894798
Validation loss: 2.669490979488365

Epoch: 6| Step: 4
Training loss: 1.776266924611693
Validation loss: 2.788148326149528

Epoch: 6| Step: 5
Training loss: 1.5193594318127392
Validation loss: 2.7411541390121568

Epoch: 6| Step: 6
Training loss: 2.060058998818549
Validation loss: 2.6439999374602614

Epoch: 6| Step: 7
Training loss: 2.106382720116346
Validation loss: 2.827538832423789

Epoch: 6| Step: 8
Training loss: 1.5488913909190138
Validation loss: 2.66692337183638

Epoch: 6| Step: 9
Training loss: 2.2747027360144108
Validation loss: 2.6668913920243926

Epoch: 6| Step: 10
Training loss: 2.7239377742499626
Validation loss: 2.739380151956255

Epoch: 6| Step: 11
Training loss: 1.6463014041692825
Validation loss: 2.6641520428990306

Epoch: 6| Step: 12
Training loss: 3.029987662261923
Validation loss: 2.6693563842669827

Epoch: 6| Step: 13
Training loss: 1.6367035275573063
Validation loss: 2.682051125499295

Epoch: 639| Step: 0
Training loss: 2.2764710836704247
Validation loss: 2.673734153264106

Epoch: 6| Step: 1
Training loss: 1.7896825390615925
Validation loss: 2.7432842325642413

Epoch: 6| Step: 2
Training loss: 1.9803620258896644
Validation loss: 2.7047496567354816

Epoch: 6| Step: 3
Training loss: 1.485835110158209
Validation loss: 2.6780585157610624

Epoch: 6| Step: 4
Training loss: 1.6425067101374897
Validation loss: 2.535819188131844

Epoch: 6| Step: 5
Training loss: 2.152911490386219
Validation loss: 2.63496700797269

Epoch: 6| Step: 6
Training loss: 1.9383822247589546
Validation loss: 2.687267225658264

Epoch: 6| Step: 7
Training loss: 2.381699499122396
Validation loss: 2.653137761872641

Epoch: 6| Step: 8
Training loss: 1.692001766533076
Validation loss: 2.5181804903011016

Epoch: 6| Step: 9
Training loss: 2.608454924685533
Validation loss: 2.60148185662392

Epoch: 6| Step: 10
Training loss: 2.548457303604653
Validation loss: 2.7077803505520133

Epoch: 6| Step: 11
Training loss: 1.474524731764636
Validation loss: 2.5597879733427

Epoch: 6| Step: 12
Training loss: 1.9324434808556912
Validation loss: 2.7406097183814553

Epoch: 6| Step: 13
Training loss: 1.3003445828859066
Validation loss: 2.7544791510147366

Epoch: 640| Step: 0
Training loss: 1.980934825581883
Validation loss: 2.740670718775447

Epoch: 6| Step: 1
Training loss: 1.8020793348793551
Validation loss: 2.6646607805907716

Epoch: 6| Step: 2
Training loss: 2.3665236747777723
Validation loss: 2.854236434564055

Epoch: 6| Step: 3
Training loss: 3.2869083118654756
Validation loss: 2.570540430678778

Epoch: 6| Step: 4
Training loss: 1.7439891582816969
Validation loss: 2.7007639181401855

Epoch: 6| Step: 5
Training loss: 2.391606746370454
Validation loss: 2.561902160296418

Epoch: 6| Step: 6
Training loss: 1.850553599857633
Validation loss: 2.5514240216036947

Epoch: 6| Step: 7
Training loss: 1.5445342415533196
Validation loss: 2.784333175949608

Epoch: 6| Step: 8
Training loss: 1.9002345492499304
Validation loss: 2.7545422082327105

Epoch: 6| Step: 9
Training loss: 1.508877076973717
Validation loss: 2.658386635462137

Epoch: 6| Step: 10
Training loss: 2.416545590842608
Validation loss: 2.778873021019502

Epoch: 6| Step: 11
Training loss: 0.9866119882751908
Validation loss: 2.725636664566879

Epoch: 6| Step: 12
Training loss: 1.6812256623389108
Validation loss: 2.7700107940958696

Epoch: 6| Step: 13
Training loss: 2.3673896325558164
Validation loss: 2.638330588860125

Epoch: 641| Step: 0
Training loss: 2.8289498659494083
Validation loss: 2.755141998658045

Epoch: 6| Step: 1
Training loss: 2.2137045647015037
Validation loss: 2.8080654153662614

Epoch: 6| Step: 2
Training loss: 1.7011067041818544
Validation loss: 2.5676364986394886

Epoch: 6| Step: 3
Training loss: 2.092744500426983
Validation loss: 2.8427836847450507

Epoch: 6| Step: 4
Training loss: 1.2627129195800901
Validation loss: 2.807080942755818

Epoch: 6| Step: 5
Training loss: 2.34481217793244
Validation loss: 2.668359629254293

Epoch: 6| Step: 6
Training loss: 1.9606373469821556
Validation loss: 2.8200813348476874

Epoch: 6| Step: 7
Training loss: 1.4125036425248163
Validation loss: 2.815635045456254

Epoch: 6| Step: 8
Training loss: 2.001291573239793
Validation loss: 2.77851525645045

Epoch: 6| Step: 9
Training loss: 2.881752046548781
Validation loss: 2.7867762208999

Epoch: 6| Step: 10
Training loss: 2.0821154149777197
Validation loss: 2.898205353499788

Epoch: 6| Step: 11
Training loss: 1.8583388446788858
Validation loss: 2.7210345581863993

Epoch: 6| Step: 12
Training loss: 1.4622743579220363
Validation loss: 2.6678453402268674

Epoch: 6| Step: 13
Training loss: 1.6964548367066037
Validation loss: 2.6963004131663335

Epoch: 642| Step: 0
Training loss: 2.501052348855395
Validation loss: 2.6017167299615194

Epoch: 6| Step: 1
Training loss: 1.6143786228802386
Validation loss: 2.723089796629433

Epoch: 6| Step: 2
Training loss: 2.4075332786660546
Validation loss: 2.6809161212903643

Epoch: 6| Step: 3
Training loss: 1.6028229010518382
Validation loss: 2.7321559507420603

Epoch: 6| Step: 4
Training loss: 2.5903405450938077
Validation loss: 2.6418831033166894

Epoch: 6| Step: 5
Training loss: 1.2350304710243065
Validation loss: 2.6382540787881474

Epoch: 6| Step: 6
Training loss: 2.573546256643352
Validation loss: 2.5909519777065113

Epoch: 6| Step: 7
Training loss: 1.861737201325503
Validation loss: 2.7472411381538078

Epoch: 6| Step: 8
Training loss: 2.0935232694474686
Validation loss: 2.622186879101233

Epoch: 6| Step: 9
Training loss: 2.4241757201279994
Validation loss: 2.5365338527877235

Epoch: 6| Step: 10
Training loss: 1.7538853157680234
Validation loss: 2.8684837091713

Epoch: 6| Step: 11
Training loss: 1.8088946823326228
Validation loss: 2.693978268634404

Epoch: 6| Step: 12
Training loss: 1.6823462446904103
Validation loss: 2.830381102811451

Epoch: 6| Step: 13
Training loss: 1.9757105382149478
Validation loss: 2.611513190823439

Epoch: 643| Step: 0
Training loss: 1.794286439012966
Validation loss: 2.762096586826966

Epoch: 6| Step: 1
Training loss: 2.714273033255877
Validation loss: 2.5554284586101597

Epoch: 6| Step: 2
Training loss: 1.8647836829724769
Validation loss: 2.652610404757986

Epoch: 6| Step: 3
Training loss: 1.5669481667111467
Validation loss: 2.693705360962646

Epoch: 6| Step: 4
Training loss: 2.3154046657823995
Validation loss: 2.6794835059659627

Epoch: 6| Step: 5
Training loss: 2.2319636638103733
Validation loss: 2.7239549991671415

Epoch: 6| Step: 6
Training loss: 1.516677255209267
Validation loss: 2.573939552822431

Epoch: 6| Step: 7
Training loss: 1.6019236831917525
Validation loss: 2.5473071930147357

Epoch: 6| Step: 8
Training loss: 2.037816862029409
Validation loss: 2.7109356313639132

Epoch: 6| Step: 9
Training loss: 1.664813378216775
Validation loss: 2.6565927630584367

Epoch: 6| Step: 10
Training loss: 1.7239036282467828
Validation loss: 2.7279783127640527

Epoch: 6| Step: 11
Training loss: 2.7134238502469286
Validation loss: 2.762447667975307

Epoch: 6| Step: 12
Training loss: 2.1569723494963258
Validation loss: 2.6756216925131513

Epoch: 6| Step: 13
Training loss: 1.2894790438797765
Validation loss: 2.5930835773604555

Epoch: 644| Step: 0
Training loss: 1.5299716206330845
Validation loss: 2.7788510384854974

Epoch: 6| Step: 1
Training loss: 1.1670221173267077
Validation loss: 2.779876229597072

Epoch: 6| Step: 2
Training loss: 1.5787258703905285
Validation loss: 2.7769327571074864

Epoch: 6| Step: 3
Training loss: 1.9117618357951858
Validation loss: 2.8159043949553784

Epoch: 6| Step: 4
Training loss: 2.0916088030386395
Validation loss: 2.7620459678329934

Epoch: 6| Step: 5
Training loss: 2.1345114177041946
Validation loss: 2.872840511715409

Epoch: 6| Step: 6
Training loss: 1.7855722289120273
Validation loss: 2.8468907774033316

Epoch: 6| Step: 7
Training loss: 2.641513742619468
Validation loss: 2.72977893470836

Epoch: 6| Step: 8
Training loss: 2.2258931542568434
Validation loss: 2.6857633996748422

Epoch: 6| Step: 9
Training loss: 2.4089552299675048
Validation loss: 2.791596507435315

Epoch: 6| Step: 10
Training loss: 2.4195204579670317
Validation loss: 2.647839769298084

Epoch: 6| Step: 11
Training loss: 1.8743336447147276
Validation loss: 2.748770686081939

Epoch: 6| Step: 12
Training loss: 2.778734677058438
Validation loss: 2.7522859841849856

Epoch: 6| Step: 13
Training loss: 1.983284598107045
Validation loss: 2.7206415864460203

Epoch: 645| Step: 0
Training loss: 1.8004362557824323
Validation loss: 2.548481619501852

Epoch: 6| Step: 1
Training loss: 1.4855748998710334
Validation loss: 2.614847693866852

Epoch: 6| Step: 2
Training loss: 2.195754688840366
Validation loss: 2.791388113138006

Epoch: 6| Step: 3
Training loss: 1.8351870037699571
Validation loss: 2.5865323434310734

Epoch: 6| Step: 4
Training loss: 3.030995466419581
Validation loss: 2.7152623678103947

Epoch: 6| Step: 5
Training loss: 1.4454271425710814
Validation loss: 2.7494739157910497

Epoch: 6| Step: 6
Training loss: 1.8515323684751586
Validation loss: 2.671340793989473

Epoch: 6| Step: 7
Training loss: 2.1719627088222313
Validation loss: 2.741156191866102

Epoch: 6| Step: 8
Training loss: 1.8476779928399916
Validation loss: 2.6379733042124185

Epoch: 6| Step: 9
Training loss: 1.9568210877284264
Validation loss: 2.7699939064745753

Epoch: 6| Step: 10
Training loss: 1.75806726940636
Validation loss: 2.603352032308928

Epoch: 6| Step: 11
Training loss: 1.8228860761709706
Validation loss: 2.714943200496644

Epoch: 6| Step: 12
Training loss: 2.028289045332547
Validation loss: 2.83797797327571

Epoch: 6| Step: 13
Training loss: 3.397336022782671
Validation loss: 2.750530114449799

Epoch: 646| Step: 0
Training loss: 1.7145034348082713
Validation loss: 2.662885915674709

Epoch: 6| Step: 1
Training loss: 2.2021012328643557
Validation loss: 2.920428172457819

Epoch: 6| Step: 2
Training loss: 1.9433602337859284
Validation loss: 2.8756788860238927

Epoch: 6| Step: 3
Training loss: 2.0743208175805514
Validation loss: 2.745792567338443

Epoch: 6| Step: 4
Training loss: 1.4303457277025147
Validation loss: 2.828644473584433

Epoch: 6| Step: 5
Training loss: 2.11834212346608
Validation loss: 2.82379322468449

Epoch: 6| Step: 6
Training loss: 2.985034330544426
Validation loss: 2.788096954908391

Epoch: 6| Step: 7
Training loss: 2.043412869613159
Validation loss: 2.788903735320587

Epoch: 6| Step: 8
Training loss: 1.7306174048645944
Validation loss: 2.694290793556646

Epoch: 6| Step: 9
Training loss: 1.9546402813447712
Validation loss: 2.708173117304227

Epoch: 6| Step: 10
Training loss: 1.9083410582184783
Validation loss: 2.7386517256474487

Epoch: 6| Step: 11
Training loss: 2.358057728042148
Validation loss: 2.7444262031957094

Epoch: 6| Step: 12
Training loss: 1.5357775801862106
Validation loss: 2.551814156040817

Epoch: 6| Step: 13
Training loss: 1.2861754483489205
Validation loss: 2.8296622897585824

Epoch: 647| Step: 0
Training loss: 1.9033244462259498
Validation loss: 2.7489175176238736

Epoch: 6| Step: 1
Training loss: 1.4073771727718227
Validation loss: 2.6355064759732394

Epoch: 6| Step: 2
Training loss: 1.4285997932887873
Validation loss: 2.5117748822421055

Epoch: 6| Step: 3
Training loss: 2.3398000365999643
Validation loss: 2.7770148165384723

Epoch: 6| Step: 4
Training loss: 1.8584151154499922
Validation loss: 2.5792120189742413

Epoch: 6| Step: 5
Training loss: 2.683103202839694
Validation loss: 2.6808764421333393

Epoch: 6| Step: 6
Training loss: 1.7696257643900424
Validation loss: 2.7503529412585195

Epoch: 6| Step: 7
Training loss: 3.044681639917735
Validation loss: 2.680236770636335

Epoch: 6| Step: 8
Training loss: 2.1264598544179414
Validation loss: 2.774542480233726

Epoch: 6| Step: 9
Training loss: 1.759258235220955
Validation loss: 2.531452396716914

Epoch: 6| Step: 10
Training loss: 2.053836312596013
Validation loss: 2.7648348598716708

Epoch: 6| Step: 11
Training loss: 1.6072751762778683
Validation loss: 2.5875877143965633

Epoch: 6| Step: 12
Training loss: 1.6203815412388596
Validation loss: 2.7650940885299065

Epoch: 6| Step: 13
Training loss: 2.1642388778035877
Validation loss: 2.8178891878364167

Epoch: 648| Step: 0
Training loss: 3.1244500248465603
Validation loss: 2.7119923324043396

Epoch: 6| Step: 1
Training loss: 1.4061097393023336
Validation loss: 2.76166877110162

Epoch: 6| Step: 2
Training loss: 1.7255992014558135
Validation loss: 2.633955179684079

Epoch: 6| Step: 3
Training loss: 2.278302627148194
Validation loss: 2.6301372650464256

Epoch: 6| Step: 4
Training loss: 2.8466773424089826
Validation loss: 2.9033461402237717

Epoch: 6| Step: 5
Training loss: 2.5461821754647285
Validation loss: 2.6965501917945707

Epoch: 6| Step: 6
Training loss: 1.8531733077187256
Validation loss: 2.729420956698784

Epoch: 6| Step: 7
Training loss: 1.9569911686186818
Validation loss: 2.730649736942557

Epoch: 6| Step: 8
Training loss: 1.9116594449577293
Validation loss: 2.506888889248671

Epoch: 6| Step: 9
Training loss: 1.857002090526877
Validation loss: 2.7006822519760334

Epoch: 6| Step: 10
Training loss: 1.214941284581971
Validation loss: 2.73273349788649

Epoch: 6| Step: 11
Training loss: 1.7087538907077253
Validation loss: 2.8101834381285435

Epoch: 6| Step: 12
Training loss: 1.642839952935743
Validation loss: 2.7725161792135804

Epoch: 6| Step: 13
Training loss: 2.0498820340710284
Validation loss: 2.7176757866646626

Epoch: 649| Step: 0
Training loss: 1.745481447735913
Validation loss: 2.8152100435176792

Epoch: 6| Step: 1
Training loss: 2.003175241491922
Validation loss: 2.6093509646684145

Epoch: 6| Step: 2
Training loss: 1.4698601443395378
Validation loss: 2.571894773850512

Epoch: 6| Step: 3
Training loss: 2.3931394829340458
Validation loss: 2.741094106149217

Epoch: 6| Step: 4
Training loss: 2.025492092669893
Validation loss: 2.9311538782680975

Epoch: 6| Step: 5
Training loss: 1.9775313464355637
Validation loss: 2.62869465508831

Epoch: 6| Step: 6
Training loss: 1.4965211740787172
Validation loss: 2.65186171239855

Epoch: 6| Step: 7
Training loss: 2.9560796902332935
Validation loss: 2.6886244813558964

Epoch: 6| Step: 8
Training loss: 1.559859065756645
Validation loss: 2.708717748812634

Epoch: 6| Step: 9
Training loss: 1.808368710056113
Validation loss: 2.6455125414805987

Epoch: 6| Step: 10
Training loss: 2.346469471279091
Validation loss: 2.641499272133869

Epoch: 6| Step: 11
Training loss: 1.8070475681885878
Validation loss: 2.7546225782195597

Epoch: 6| Step: 12
Training loss: 1.6086482657133574
Validation loss: 2.6616781538210743

Epoch: 6| Step: 13
Training loss: 2.1320515487336418
Validation loss: 2.704250122640144

Epoch: 650| Step: 0
Training loss: 1.8195927060445432
Validation loss: 2.6798824039831888

Epoch: 6| Step: 1
Training loss: 1.7285989342564965
Validation loss: 2.717703010772309

Epoch: 6| Step: 2
Training loss: 2.9895205253002373
Validation loss: 2.6506553861826943

Epoch: 6| Step: 3
Training loss: 2.2526289098773535
Validation loss: 2.7385074844492188

Epoch: 6| Step: 4
Training loss: 1.6358420270370406
Validation loss: 2.7243915375657672

Epoch: 6| Step: 5
Training loss: 2.4218266636116472
Validation loss: 2.7128991166208873

Epoch: 6| Step: 6
Training loss: 1.642012454502577
Validation loss: 2.6759351762271235

Epoch: 6| Step: 7
Training loss: 2.101431576646188
Validation loss: 2.5681641299410027

Epoch: 6| Step: 8
Training loss: 2.168704126406049
Validation loss: 2.7952619942606662

Epoch: 6| Step: 9
Training loss: 1.4708873537137586
Validation loss: 2.715285924486595

Epoch: 6| Step: 10
Training loss: 2.099857134727763
Validation loss: 2.710478156922983

Epoch: 6| Step: 11
Training loss: 2.1195165907131055
Validation loss: 2.747524075396337

Epoch: 6| Step: 12
Training loss: 1.9820467288593577
Validation loss: 2.6947002755296103

Epoch: 6| Step: 13
Training loss: 1.312993229423667
Validation loss: 2.7188912622407413

Epoch: 651| Step: 0
Training loss: 1.595737116065255
Validation loss: 2.5194081510332857

Epoch: 6| Step: 1
Training loss: 2.3187509541882303
Validation loss: 2.6473156322545113

Epoch: 6| Step: 2
Training loss: 2.407093445229109
Validation loss: 2.7439995807205633

Epoch: 6| Step: 3
Training loss: 3.04163978947997
Validation loss: 2.7245180289130224

Epoch: 6| Step: 4
Training loss: 2.051170675451349
Validation loss: 2.80354315763568

Epoch: 6| Step: 5
Training loss: 1.7420552977622226
Validation loss: 2.5978105362137955

Epoch: 6| Step: 6
Training loss: 2.4786305742835486
Validation loss: 2.6789436036066037

Epoch: 6| Step: 7
Training loss: 2.1057777531903263
Validation loss: 2.74012503073498

Epoch: 6| Step: 8
Training loss: 2.105453915800305
Validation loss: 2.7708307069304463

Epoch: 6| Step: 9
Training loss: 2.0318938188669953
Validation loss: 2.6277138139262357

Epoch: 6| Step: 10
Training loss: 2.238808454967657
Validation loss: 2.73447434392847

Epoch: 6| Step: 11
Training loss: 1.9873503958579493
Validation loss: 2.5307211354443093

Epoch: 6| Step: 12
Training loss: 1.6736827595817163
Validation loss: 2.716354354247584

Epoch: 6| Step: 13
Training loss: 1.985635552310731
Validation loss: 2.845650158093879

Epoch: 652| Step: 0
Training loss: 1.9156069382878633
Validation loss: 2.6422313452978896

Epoch: 6| Step: 1
Training loss: 1.6305075260188697
Validation loss: 2.761868025940392

Epoch: 6| Step: 2
Training loss: 2.486261383383474
Validation loss: 2.673156132735414

Epoch: 6| Step: 3
Training loss: 1.7066855353315706
Validation loss: 2.6260018573217057

Epoch: 6| Step: 4
Training loss: 1.9306617161799728
Validation loss: 2.7954002612979014

Epoch: 6| Step: 5
Training loss: 1.4920500846822118
Validation loss: 2.650636931502577

Epoch: 6| Step: 6
Training loss: 1.9781643253412944
Validation loss: 2.8899969117555844

Epoch: 6| Step: 7
Training loss: 1.803601883842887
Validation loss: 2.7193593657838635

Epoch: 6| Step: 8
Training loss: 1.8082557181066592
Validation loss: 2.6087280752643944

Epoch: 6| Step: 9
Training loss: 1.9438489441051687
Validation loss: 2.6797053614152393

Epoch: 6| Step: 10
Training loss: 1.7967245951191788
Validation loss: 2.8467298489305044

Epoch: 6| Step: 11
Training loss: 3.300340611768204
Validation loss: 2.903703162228235

Epoch: 6| Step: 12
Training loss: 2.3838896771192624
Validation loss: 2.771913240435809

Epoch: 6| Step: 13
Training loss: 2.3473887362534045
Validation loss: 2.7524416982457875

Epoch: 653| Step: 0
Training loss: 1.970141751471016
Validation loss: 2.716624984280519

Epoch: 6| Step: 1
Training loss: 2.361880355388771
Validation loss: 2.8653035572734833

Epoch: 6| Step: 2
Training loss: 1.2143772615656112
Validation loss: 2.8369993498089863

Epoch: 6| Step: 3
Training loss: 2.8897670813025202
Validation loss: 2.6718258745567995

Epoch: 6| Step: 4
Training loss: 2.6805574211768564
Validation loss: 2.6692837628947568

Epoch: 6| Step: 5
Training loss: 2.3745774344925294
Validation loss: 2.7206478046282703

Epoch: 6| Step: 6
Training loss: 2.0606091241337787
Validation loss: 2.5724092388100055

Epoch: 6| Step: 7
Training loss: 1.8583872760190965
Validation loss: 2.6986260404244145

Epoch: 6| Step: 8
Training loss: 2.179569583013974
Validation loss: 2.6910766807461823

Epoch: 6| Step: 9
Training loss: 1.4377535720751635
Validation loss: 2.728855011620506

Epoch: 6| Step: 10
Training loss: 2.1608637225506153
Validation loss: 2.567554521104504

Epoch: 6| Step: 11
Training loss: 1.631794004968795
Validation loss: 2.670154888341028

Epoch: 6| Step: 12
Training loss: 1.1335156067428782
Validation loss: 2.6060980363895014

Epoch: 6| Step: 13
Training loss: 1.3374366602650563
Validation loss: 2.714059506596495

Epoch: 654| Step: 0
Training loss: 1.5768225554621498
Validation loss: 2.667829549044894

Epoch: 6| Step: 1
Training loss: 1.6415192119904476
Validation loss: 2.4822654216227984

Epoch: 6| Step: 2
Training loss: 2.441946229347388
Validation loss: 2.510677135381965

Epoch: 6| Step: 3
Training loss: 2.3465803222954835
Validation loss: 2.793446519086547

Epoch: 6| Step: 4
Training loss: 2.1993584867975677
Validation loss: 2.856310069617376

Epoch: 6| Step: 5
Training loss: 1.5082140768266572
Validation loss: 2.791775610543895

Epoch: 6| Step: 6
Training loss: 2.8277155964461427
Validation loss: 2.5861156553315134

Epoch: 6| Step: 7
Training loss: 1.9870217161676544
Validation loss: 2.794616891252991

Epoch: 6| Step: 8
Training loss: 1.9326746750387487
Validation loss: 2.747670373621382

Epoch: 6| Step: 9
Training loss: 2.0148455864970787
Validation loss: 2.716078003795521

Epoch: 6| Step: 10
Training loss: 1.7219846631695186
Validation loss: 2.699147586968651

Epoch: 6| Step: 11
Training loss: 1.7495402685929302
Validation loss: 2.615735594861081

Epoch: 6| Step: 12
Training loss: 2.1195853193046434
Validation loss: 2.8186091123775925

Epoch: 6| Step: 13
Training loss: 1.1656511973691883
Validation loss: 2.717712836287637

Epoch: 655| Step: 0
Training loss: 1.9355039466693504
Validation loss: 2.7204911414918223

Epoch: 6| Step: 1
Training loss: 2.0718960445940553
Validation loss: 2.672757826916221

Epoch: 6| Step: 2
Training loss: 2.320542860316297
Validation loss: 2.6832272532391217

Epoch: 6| Step: 3
Training loss: 2.105021413300031
Validation loss: 2.6965966298370057

Epoch: 6| Step: 4
Training loss: 1.8563553468756733
Validation loss: 2.6653609411827497

Epoch: 6| Step: 5
Training loss: 1.8166453870641095
Validation loss: 2.652870945589299

Epoch: 6| Step: 6
Training loss: 1.9049737128499096
Validation loss: 2.588019201544444

Epoch: 6| Step: 7
Training loss: 2.0153358902699945
Validation loss: 2.568297940842075

Epoch: 6| Step: 8
Training loss: 1.803680138771636
Validation loss: 2.808292142985219

Epoch: 6| Step: 9
Training loss: 1.8189394770237517
Validation loss: 2.68326071416287

Epoch: 6| Step: 10
Training loss: 2.2300182629166727
Validation loss: 2.818635970996243

Epoch: 6| Step: 11
Training loss: 1.6482789022074753
Validation loss: 2.5519595094584795

Epoch: 6| Step: 12
Training loss: 1.4388774409057603
Validation loss: 2.667509060967586

Epoch: 6| Step: 13
Training loss: 3.7968236346753836
Validation loss: 2.637454693845486

Epoch: 656| Step: 0
Training loss: 2.7228718348000807
Validation loss: 2.6222197638953713

Epoch: 6| Step: 1
Training loss: 1.7097222179526812
Validation loss: 2.7435734534905527

Epoch: 6| Step: 2
Training loss: 2.1961181899820685
Validation loss: 2.7731633560544893

Epoch: 6| Step: 3
Training loss: 1.7259050731524035
Validation loss: 2.6217455771960876

Epoch: 6| Step: 4
Training loss: 1.7764705986469507
Validation loss: 2.705167345123309

Epoch: 6| Step: 5
Training loss: 1.433964985275007
Validation loss: 2.594400186757671

Epoch: 6| Step: 6
Training loss: 1.9737608583524893
Validation loss: 2.7409931137832233

Epoch: 6| Step: 7
Training loss: 1.467239252219758
Validation loss: 2.770403179026016

Epoch: 6| Step: 8
Training loss: 1.8560565860565568
Validation loss: 2.778500548198105

Epoch: 6| Step: 9
Training loss: 1.5120374555540252
Validation loss: 2.784336040363243

Epoch: 6| Step: 10
Training loss: 1.9459949200319828
Validation loss: 2.565990196071569

Epoch: 6| Step: 11
Training loss: 2.2083867864317446
Validation loss: 2.5723633319176056

Epoch: 6| Step: 12
Training loss: 2.0199851258362904
Validation loss: 2.661808919796184

Epoch: 6| Step: 13
Training loss: 2.3376962426370445
Validation loss: 2.8158036821745114

Epoch: 657| Step: 0
Training loss: 1.9613320611011278
Validation loss: 2.7274292731888097

Epoch: 6| Step: 1
Training loss: 3.2661368959029136
Validation loss: 2.61964762585741

Epoch: 6| Step: 2
Training loss: 1.805166205787594
Validation loss: 2.554751894078055

Epoch: 6| Step: 3
Training loss: 2.4556057771904656
Validation loss: 2.6629861253362765

Epoch: 6| Step: 4
Training loss: 2.441689631990964
Validation loss: 2.5791655120324855

Epoch: 6| Step: 5
Training loss: 1.994961053281672
Validation loss: 2.5364226076176895

Epoch: 6| Step: 6
Training loss: 1.839895454214773
Validation loss: 2.716466968921417

Epoch: 6| Step: 7
Training loss: 2.002538262429129
Validation loss: 2.591272075610033

Epoch: 6| Step: 8
Training loss: 1.6341774815667256
Validation loss: 2.645319260768114

Epoch: 6| Step: 9
Training loss: 1.042352501476926
Validation loss: 2.7447059681636965

Epoch: 6| Step: 10
Training loss: 2.0430595421537876
Validation loss: 2.7543939946751

Epoch: 6| Step: 11
Training loss: 2.1460041484312717
Validation loss: 2.6159027185932993

Epoch: 6| Step: 12
Training loss: 1.5467746586477973
Validation loss: 2.679872502903368

Epoch: 6| Step: 13
Training loss: 1.2971628168450777
Validation loss: 2.6472856177268422

Epoch: 658| Step: 0
Training loss: 2.3528781391563243
Validation loss: 2.661078155459033

Epoch: 6| Step: 1
Training loss: 1.9109107401635899
Validation loss: 2.5941103267237704

Epoch: 6| Step: 2
Training loss: 2.16758710921559
Validation loss: 2.6513936933456606

Epoch: 6| Step: 3
Training loss: 2.1324373131825753
Validation loss: 2.720069918457721

Epoch: 6| Step: 4
Training loss: 1.6658576273263823
Validation loss: 2.731480555411286

Epoch: 6| Step: 5
Training loss: 1.9745538932031448
Validation loss: 2.662682359778231

Epoch: 6| Step: 6
Training loss: 1.9418068056192204
Validation loss: 2.617642646924747

Epoch: 6| Step: 7
Training loss: 1.9702285179977763
Validation loss: 2.735792986231544

Epoch: 6| Step: 8
Training loss: 1.463127656891051
Validation loss: 2.823368981811379

Epoch: 6| Step: 9
Training loss: 2.40685769866613
Validation loss: 2.814030608838097

Epoch: 6| Step: 10
Training loss: 2.898145470726863
Validation loss: 2.650339516916158

Epoch: 6| Step: 11
Training loss: 1.6005525707702688
Validation loss: 2.8204861193413557

Epoch: 6| Step: 12
Training loss: 1.6449766303492404
Validation loss: 2.6526962848955455

Epoch: 6| Step: 13
Training loss: 1.8072405834472456
Validation loss: 2.6582892044277067

Epoch: 659| Step: 0
Training loss: 1.8989886829868636
Validation loss: 2.6954624614042926

Epoch: 6| Step: 1
Training loss: 1.534906187390407
Validation loss: 2.648127971506364

Epoch: 6| Step: 2
Training loss: 2.2714575046776995
Validation loss: 2.7276166333258374

Epoch: 6| Step: 3
Training loss: 1.5114998276963105
Validation loss: 2.73035504386935

Epoch: 6| Step: 4
Training loss: 2.2107634459011916
Validation loss: 2.836141413261222

Epoch: 6| Step: 5
Training loss: 1.6483363983825225
Validation loss: 2.7545016565911298

Epoch: 6| Step: 6
Training loss: 1.8006859214192952
Validation loss: 2.618052968829543

Epoch: 6| Step: 7
Training loss: 2.0356842937506894
Validation loss: 2.7425757730039972

Epoch: 6| Step: 8
Training loss: 3.153147768632177
Validation loss: 2.821157235822488

Epoch: 6| Step: 9
Training loss: 1.5860018411748333
Validation loss: 2.6671075549387697

Epoch: 6| Step: 10
Training loss: 2.6900855645677972
Validation loss: 2.8309346063817977

Epoch: 6| Step: 11
Training loss: 1.542179417613145
Validation loss: 2.755855252124973

Epoch: 6| Step: 12
Training loss: 2.3791954729125635
Validation loss: 2.586643917714528

Epoch: 6| Step: 13
Training loss: 2.1792844994551377
Validation loss: 2.731577943617629

Epoch: 660| Step: 0
Training loss: 1.9645113654386792
Validation loss: 2.661639842613671

Epoch: 6| Step: 1
Training loss: 1.9134304326481553
Validation loss: 2.833663996837484

Epoch: 6| Step: 2
Training loss: 2.1055994223277916
Validation loss: 2.6301170863687835

Epoch: 6| Step: 3
Training loss: 2.130543714266877
Validation loss: 2.532318997504014

Epoch: 6| Step: 4
Training loss: 1.7532428939808054
Validation loss: 2.7034043193781265

Epoch: 6| Step: 5
Training loss: 1.9658687640537706
Validation loss: 2.9035545973053414

Epoch: 6| Step: 6
Training loss: 2.081883638169924
Validation loss: 2.645920879849296

Epoch: 6| Step: 7
Training loss: 2.370895251743267
Validation loss: 2.8763221524588487

Epoch: 6| Step: 8
Training loss: 2.3878169303766072
Validation loss: 2.761815695715944

Epoch: 6| Step: 9
Training loss: 2.0343372066051937
Validation loss: 2.74655888813801

Epoch: 6| Step: 10
Training loss: 2.2064530146834898
Validation loss: 2.7087596545151547

Epoch: 6| Step: 11
Training loss: 2.5170717995382574
Validation loss: 2.5952953514402872

Epoch: 6| Step: 12
Training loss: 1.1495398077491334
Validation loss: 2.769199144483275

Epoch: 6| Step: 13
Training loss: 2.599738779150343
Validation loss: 2.633979952115714

Epoch: 661| Step: 0
Training loss: 2.310221709638875
Validation loss: 2.727543568423755

Epoch: 6| Step: 1
Training loss: 1.7451189635640794
Validation loss: 2.6901633526901434

Epoch: 6| Step: 2
Training loss: 2.2271769428712163
Validation loss: 2.8111228323934787

Epoch: 6| Step: 3
Training loss: 1.582748740174487
Validation loss: 2.689290556033272

Epoch: 6| Step: 4
Training loss: 1.7526229547529895
Validation loss: 2.764060743555769

Epoch: 6| Step: 5
Training loss: 1.8231217477878652
Validation loss: 2.741474561085344

Epoch: 6| Step: 6
Training loss: 1.8533282652563787
Validation loss: 2.667830220746195

Epoch: 6| Step: 7
Training loss: 1.8618071220960821
Validation loss: 2.625861199989049

Epoch: 6| Step: 8
Training loss: 2.965970957186208
Validation loss: 2.7464684867696563

Epoch: 6| Step: 9
Training loss: 1.8895090135499162
Validation loss: 2.6507964029324484

Epoch: 6| Step: 10
Training loss: 2.3682590992528345
Validation loss: 2.59996389643211

Epoch: 6| Step: 11
Training loss: 2.340231326805935
Validation loss: 2.729467670011293

Epoch: 6| Step: 12
Training loss: 2.4719181254756752
Validation loss: 2.7546717263879006

Epoch: 6| Step: 13
Training loss: 1.9110783572618377
Validation loss: 2.639002365093277

Epoch: 662| Step: 0
Training loss: 2.2545519454294887
Validation loss: 2.7505636998529126

Epoch: 6| Step: 1
Training loss: 2.3917281653531113
Validation loss: 2.845418064682652

Epoch: 6| Step: 2
Training loss: 2.0200029482678343
Validation loss: 2.693332644412951

Epoch: 6| Step: 3
Training loss: 1.9665460511845236
Validation loss: 2.726177320591324

Epoch: 6| Step: 4
Training loss: 1.938221458733677
Validation loss: 2.659503243151756

Epoch: 6| Step: 5
Training loss: 2.7040960078321876
Validation loss: 2.612566349179889

Epoch: 6| Step: 6
Training loss: 1.6677388160043505
Validation loss: 2.772924847894059

Epoch: 6| Step: 7
Training loss: 2.8913959196865244
Validation loss: 2.6525235553488966

Epoch: 6| Step: 8
Training loss: 1.5058810656775203
Validation loss: 2.7805447672321777

Epoch: 6| Step: 9
Training loss: 1.7183505894669846
Validation loss: 2.853831147000919

Epoch: 6| Step: 10
Training loss: 1.5663874522767425
Validation loss: 2.658092617789014

Epoch: 6| Step: 11
Training loss: 1.9690696820066211
Validation loss: 2.7781175636996562

Epoch: 6| Step: 12
Training loss: 1.6261097713123625
Validation loss: 2.818754531503461

Epoch: 6| Step: 13
Training loss: 1.9527202339370013
Validation loss: 2.7984629353585926

Epoch: 663| Step: 0
Training loss: 1.3097123560438895
Validation loss: 2.6625849944660245

Epoch: 6| Step: 1
Training loss: 1.6262267690607575
Validation loss: 2.7573439290564754

Epoch: 6| Step: 2
Training loss: 1.8612565850422556
Validation loss: 2.907131545208888

Epoch: 6| Step: 3
Training loss: 1.4558834023792022
Validation loss: 2.6020035814932165

Epoch: 6| Step: 4
Training loss: 1.5853407164472064
Validation loss: 2.7743905458477554

Epoch: 6| Step: 5
Training loss: 2.3589074890574135
Validation loss: 2.7685482648592794

Epoch: 6| Step: 6
Training loss: 2.9003819115504634
Validation loss: 2.7186624335837157

Epoch: 6| Step: 7
Training loss: 2.627511956998004
Validation loss: 2.7358776027104135

Epoch: 6| Step: 8
Training loss: 1.6656991136963406
Validation loss: 2.6282061370018535

Epoch: 6| Step: 9
Training loss: 2.0031292991175467
Validation loss: 2.682025702137925

Epoch: 6| Step: 10
Training loss: 2.272425055784079
Validation loss: 2.6169292245985907

Epoch: 6| Step: 11
Training loss: 2.6062632754785917
Validation loss: 2.7325100099823665

Epoch: 6| Step: 12
Training loss: 1.8903563127250502
Validation loss: 2.6769535082216387

Epoch: 6| Step: 13
Training loss: 2.0701688896609305
Validation loss: 2.741208306719395

Epoch: 664| Step: 0
Training loss: 2.55517965353292
Validation loss: 2.697952122672479

Epoch: 6| Step: 1
Training loss: 2.530389804438922
Validation loss: 2.623988745387195

Epoch: 6| Step: 2
Training loss: 2.079249257171854
Validation loss: 2.6531127953370333

Epoch: 6| Step: 3
Training loss: 2.457435950592289
Validation loss: 2.7006659959066712

Epoch: 6| Step: 4
Training loss: 1.7485811748909759
Validation loss: 2.7313219943964624

Epoch: 6| Step: 5
Training loss: 1.991113111217285
Validation loss: 2.6339622857712195

Epoch: 6| Step: 6
Training loss: 0.9637777640651758
Validation loss: 2.6935311990442132

Epoch: 6| Step: 7
Training loss: 1.6492781823100804
Validation loss: 2.7331587723196673

Epoch: 6| Step: 8
Training loss: 1.6587800908180126
Validation loss: 2.749702545665199

Epoch: 6| Step: 9
Training loss: 2.9114687424111407
Validation loss: 2.7653937836678057

Epoch: 6| Step: 10
Training loss: 1.5833396493216911
Validation loss: 2.6348194686112016

Epoch: 6| Step: 11
Training loss: 1.613848127104595
Validation loss: 2.583151818553043

Epoch: 6| Step: 12
Training loss: 1.6285749139605061
Validation loss: 2.7498394778508564

Epoch: 6| Step: 13
Training loss: 1.0035548801250436
Validation loss: 2.6676722442429073

Epoch: 665| Step: 0
Training loss: 2.6212964043536813
Validation loss: 2.5701779117325607

Epoch: 6| Step: 1
Training loss: 2.1846563111704804
Validation loss: 2.751426482487105

Epoch: 6| Step: 2
Training loss: 1.864937803647781
Validation loss: 2.695573596456006

Epoch: 6| Step: 3
Training loss: 1.8650290810616241
Validation loss: 2.806485173115855

Epoch: 6| Step: 4
Training loss: 2.1960598905349014
Validation loss: 2.756969200379861

Epoch: 6| Step: 5
Training loss: 1.6217060449464387
Validation loss: 2.7770979111504097

Epoch: 6| Step: 6
Training loss: 2.7151741979365487
Validation loss: 2.7497159159986984

Epoch: 6| Step: 7
Training loss: 1.6079001474170342
Validation loss: 2.7816779505761446

Epoch: 6| Step: 8
Training loss: 1.7391711753758745
Validation loss: 2.6001586999332242

Epoch: 6| Step: 9
Training loss: 1.8100548397629335
Validation loss: 2.5102686844573063

Epoch: 6| Step: 10
Training loss: 1.667691710288195
Validation loss: 2.7150970074091116

Epoch: 6| Step: 11
Training loss: 1.5800233508448815
Validation loss: 2.7024934120800284

Epoch: 6| Step: 12
Training loss: 2.013148242492947
Validation loss: 2.694841038989443

Epoch: 6| Step: 13
Training loss: 1.7034344873172513
Validation loss: 2.6740981479594246

Epoch: 666| Step: 0
Training loss: 2.2302610497715674
Validation loss: 2.7232078447462915

Epoch: 6| Step: 1
Training loss: 2.3324966860765013
Validation loss: 2.6321486100427585

Epoch: 6| Step: 2
Training loss: 1.8592683136409804
Validation loss: 2.6669122421978138

Epoch: 6| Step: 3
Training loss: 2.294649875835819
Validation loss: 2.778998734561809

Epoch: 6| Step: 4
Training loss: 1.9350890879859726
Validation loss: 2.72647476043365

Epoch: 6| Step: 5
Training loss: 1.649694460698607
Validation loss: 2.8669647553198336

Epoch: 6| Step: 6
Training loss: 1.9998798334261314
Validation loss: 2.738572558873447

Epoch: 6| Step: 7
Training loss: 1.6113205048352013
Validation loss: 2.8620594678530393

Epoch: 6| Step: 8
Training loss: 1.914069226311523
Validation loss: 2.6800642913122186

Epoch: 6| Step: 9
Training loss: 1.8717461645148952
Validation loss: 2.81099100957876

Epoch: 6| Step: 10
Training loss: 2.316927100255148
Validation loss: 2.932011372871123

Epoch: 6| Step: 11
Training loss: 1.2083721921964512
Validation loss: 2.6834834753930177

Epoch: 6| Step: 12
Training loss: 2.8678245564299085
Validation loss: 2.8089679648592667

Epoch: 6| Step: 13
Training loss: 2.3256585285791065
Validation loss: 2.5066205898193115

Epoch: 667| Step: 0
Training loss: 1.952702346847389
Validation loss: 2.8054504983704827

Epoch: 6| Step: 1
Training loss: 2.450638695590785
Validation loss: 2.7827423726392437

Epoch: 6| Step: 2
Training loss: 2.644624739421383
Validation loss: 2.764637890443162

Epoch: 6| Step: 3
Training loss: 1.832828307673066
Validation loss: 2.6032976215667234

Epoch: 6| Step: 4
Training loss: 2.191591088426591
Validation loss: 2.6544215569278298

Epoch: 6| Step: 5
Training loss: 1.6427357492555898
Validation loss: 2.7092665365297375

Epoch: 6| Step: 6
Training loss: 1.5185786303628959
Validation loss: 2.694038577758725

Epoch: 6| Step: 7
Training loss: 2.5540737149706363
Validation loss: 2.620871516781234

Epoch: 6| Step: 8
Training loss: 2.4073007444515655
Validation loss: 2.506861599996641

Epoch: 6| Step: 9
Training loss: 1.3221323236300666
Validation loss: 2.655445609726678

Epoch: 6| Step: 10
Training loss: 1.9127568988668155
Validation loss: 2.70627410702873

Epoch: 6| Step: 11
Training loss: 2.0140599525263903
Validation loss: 2.6721596865110167

Epoch: 6| Step: 12
Training loss: 1.596421191087818
Validation loss: 2.578381269290284

Epoch: 6| Step: 13
Training loss: 2.576737186392993
Validation loss: 2.667127656570769

Epoch: 668| Step: 0
Training loss: 2.2409388025822894
Validation loss: 2.7938682245386204

Epoch: 6| Step: 1
Training loss: 2.3247652324977826
Validation loss: 2.7124083657983937

Epoch: 6| Step: 2
Training loss: 1.711910580741967
Validation loss: 2.6307004383960884

Epoch: 6| Step: 3
Training loss: 1.3274588316660019
Validation loss: 2.8074569444979427

Epoch: 6| Step: 4
Training loss: 2.16204607835589
Validation loss: 2.56045751360265

Epoch: 6| Step: 5
Training loss: 1.5323350915346203
Validation loss: 2.671961813356321

Epoch: 6| Step: 6
Training loss: 2.258081756692983
Validation loss: 2.6709510747194236

Epoch: 6| Step: 7
Training loss: 1.7221608390260341
Validation loss: 2.715045595253234

Epoch: 6| Step: 8
Training loss: 1.8075997111147004
Validation loss: 2.4918123484222714

Epoch: 6| Step: 9
Training loss: 2.9010955056765435
Validation loss: 2.7036877535430706

Epoch: 6| Step: 10
Training loss: 2.208741300314246
Validation loss: 2.638287116042951

Epoch: 6| Step: 11
Training loss: 1.469663863254595
Validation loss: 2.6635247241280178

Epoch: 6| Step: 12
Training loss: 1.4797645846855092
Validation loss: 2.7353429381393726

Epoch: 6| Step: 13
Training loss: 1.5863144149507198
Validation loss: 2.7821521768309876

Epoch: 669| Step: 0
Training loss: 2.0404142963233887
Validation loss: 2.778965015871628

Epoch: 6| Step: 1
Training loss: 1.9447040142404524
Validation loss: 2.8401652769646026

Epoch: 6| Step: 2
Training loss: 1.3409154403959396
Validation loss: 2.8258318109222427

Epoch: 6| Step: 3
Training loss: 1.6332583754070886
Validation loss: 2.7382382779843146

Epoch: 6| Step: 4
Training loss: 2.2963010109690094
Validation loss: 2.9066793914276303

Epoch: 6| Step: 5
Training loss: 2.6443335319771264
Validation loss: 2.9017653224462507

Epoch: 6| Step: 6
Training loss: 2.214866786076742
Validation loss: 2.712900088062135

Epoch: 6| Step: 7
Training loss: 2.0647055652925665
Validation loss: 2.710533107909065

Epoch: 6| Step: 8
Training loss: 1.9912181216152893
Validation loss: 2.774954648447798

Epoch: 6| Step: 9
Training loss: 2.0391914648437868
Validation loss: 2.709171046025876

Epoch: 6| Step: 10
Training loss: 1.894932026109496
Validation loss: 2.7918722141014998

Epoch: 6| Step: 11
Training loss: 2.070363976180509
Validation loss: 2.736927740615896

Epoch: 6| Step: 12
Training loss: 2.0443843218813336
Validation loss: 2.6930437614366856

Epoch: 6| Step: 13
Training loss: 1.9232063954124812
Validation loss: 2.728342538819429

Epoch: 670| Step: 0
Training loss: 2.8019262976527464
Validation loss: 2.683532107519448

Epoch: 6| Step: 1
Training loss: 1.7863672602120606
Validation loss: 2.6744246590474234

Epoch: 6| Step: 2
Training loss: 1.2409283476131536
Validation loss: 2.6718617302033096

Epoch: 6| Step: 3
Training loss: 1.7373120981608388
Validation loss: 2.7437378311382585

Epoch: 6| Step: 4
Training loss: 1.8349331320238957
Validation loss: 2.7111048682075

Epoch: 6| Step: 5
Training loss: 1.7568637576399986
Validation loss: 2.649682150388124

Epoch: 6| Step: 6
Training loss: 1.927142484289794
Validation loss: 2.6798080368913126

Epoch: 6| Step: 7
Training loss: 2.3374902164030087
Validation loss: 2.573120743465408

Epoch: 6| Step: 8
Training loss: 1.574209057042119
Validation loss: 2.7253249582856265

Epoch: 6| Step: 9
Training loss: 2.2782964529397898
Validation loss: 2.7302276050884213

Epoch: 6| Step: 10
Training loss: 2.5491333292784497
Validation loss: 2.758750508966742

Epoch: 6| Step: 11
Training loss: 2.2576396308375415
Validation loss: 2.6479452381538766

Epoch: 6| Step: 12
Training loss: 2.109344595230813
Validation loss: 2.6398643878264227

Epoch: 6| Step: 13
Training loss: 1.5548202994671938
Validation loss: 2.555222080205891

Epoch: 671| Step: 0
Training loss: 1.6951105375452866
Validation loss: 2.8754876763334836

Epoch: 6| Step: 1
Training loss: 2.0446743382667694
Validation loss: 2.646465313886727

Epoch: 6| Step: 2
Training loss: 1.7311794638466318
Validation loss: 2.7043303254551954

Epoch: 6| Step: 3
Training loss: 1.7875388374644412
Validation loss: 2.847006522417818

Epoch: 6| Step: 4
Training loss: 1.774511474219722
Validation loss: 2.809091314007623

Epoch: 6| Step: 5
Training loss: 2.0051168313555334
Validation loss: 2.719069808501969

Epoch: 6| Step: 6
Training loss: 2.051033280644307
Validation loss: 2.7399760681851535

Epoch: 6| Step: 7
Training loss: 1.7912089036591605
Validation loss: 2.6945051004329863

Epoch: 6| Step: 8
Training loss: 2.7207572805651985
Validation loss: 2.8521784556699377

Epoch: 6| Step: 9
Training loss: 2.0611806175163063
Validation loss: 2.747231181221098

Epoch: 6| Step: 10
Training loss: 1.7849364030552068
Validation loss: 2.5756472825682533

Epoch: 6| Step: 11
Training loss: 2.3135534413012455
Validation loss: 2.828205142633174

Epoch: 6| Step: 12
Training loss: 3.1152548858063027
Validation loss: 2.7069339825578207

Epoch: 6| Step: 13
Training loss: 1.428596705826154
Validation loss: 2.745021943893121

Epoch: 672| Step: 0
Training loss: 2.4633324005304136
Validation loss: 2.65067604490388

Epoch: 6| Step: 1
Training loss: 1.7277278505875284
Validation loss: 2.6164331962036034

Epoch: 6| Step: 2
Training loss: 2.078855113791474
Validation loss: 2.5739712014848584

Epoch: 6| Step: 3
Training loss: 1.7813403458019434
Validation loss: 2.6752587215634835

Epoch: 6| Step: 4
Training loss: 1.5893739948277026
Validation loss: 2.676322683070302

Epoch: 6| Step: 5
Training loss: 2.7949457600743903
Validation loss: 2.6287605900974134

Epoch: 6| Step: 6
Training loss: 2.1266387903345656
Validation loss: 2.62021063320451

Epoch: 6| Step: 7
Training loss: 1.7076768156354807
Validation loss: 2.6483699059010575

Epoch: 6| Step: 8
Training loss: 1.3598993978036047
Validation loss: 2.552300983629891

Epoch: 6| Step: 9
Training loss: 1.5360342528875133
Validation loss: 2.644306869077246

Epoch: 6| Step: 10
Training loss: 2.339324740767586
Validation loss: 2.8448972680976845

Epoch: 6| Step: 11
Training loss: 1.9092274535464888
Validation loss: 2.595438111723687

Epoch: 6| Step: 12
Training loss: 1.5362082412544358
Validation loss: 2.7821190971586844

Epoch: 6| Step: 13
Training loss: 2.261141424993855
Validation loss: 2.7051599437103095

Epoch: 673| Step: 0
Training loss: 1.6961868773643767
Validation loss: 2.7804838634472615

Epoch: 6| Step: 1
Training loss: 1.7858905242055072
Validation loss: 2.7793807831794886

Epoch: 6| Step: 2
Training loss: 1.5525482642001498
Validation loss: 2.7397632450123206

Epoch: 6| Step: 3
Training loss: 1.9536791206140383
Validation loss: 2.5775749179040925

Epoch: 6| Step: 4
Training loss: 2.7489774710299955
Validation loss: 2.8400266572948207

Epoch: 6| Step: 5
Training loss: 1.8883958395870302
Validation loss: 2.7787476994254443

Epoch: 6| Step: 6
Training loss: 2.524866036364487
Validation loss: 2.659402269872577

Epoch: 6| Step: 7
Training loss: 1.8426665662736952
Validation loss: 2.8285075869206278

Epoch: 6| Step: 8
Training loss: 1.6986959420445664
Validation loss: 2.755100629554467

Epoch: 6| Step: 9
Training loss: 1.470199356833701
Validation loss: 2.450022092371789

Epoch: 6| Step: 10
Training loss: 2.4133803505646805
Validation loss: 2.7383766213296226

Epoch: 6| Step: 11
Training loss: 2.147886226326119
Validation loss: 2.8022813057274627

Epoch: 6| Step: 12
Training loss: 1.9573714213814517
Validation loss: 2.7161435542435624

Epoch: 6| Step: 13
Training loss: 1.7255787528146975
Validation loss: 2.6679765505427366

Epoch: 674| Step: 0
Training loss: 2.035676095360499
Validation loss: 2.6596718739676932

Epoch: 6| Step: 1
Training loss: 1.4934392342454603
Validation loss: 2.5486195730205026

Epoch: 6| Step: 2
Training loss: 2.816613304791417
Validation loss: 2.6614454656122564

Epoch: 6| Step: 3
Training loss: 1.7245448133884518
Validation loss: 2.577355586663605

Epoch: 6| Step: 4
Training loss: 1.6715292885120248
Validation loss: 2.7063016011867114

Epoch: 6| Step: 5
Training loss: 1.8602519171353349
Validation loss: 2.612376632796085

Epoch: 6| Step: 6
Training loss: 1.8110129734798437
Validation loss: 2.544722547837408

Epoch: 6| Step: 7
Training loss: 2.5271065790837435
Validation loss: 2.710555769345178

Epoch: 6| Step: 8
Training loss: 1.945934027844381
Validation loss: 2.692550012514375

Epoch: 6| Step: 9
Training loss: 1.6015194026451725
Validation loss: 2.6603235885965235

Epoch: 6| Step: 10
Training loss: 1.6756445911234006
Validation loss: 2.7762437492268064

Epoch: 6| Step: 11
Training loss: 2.2510824778498275
Validation loss: 2.6924267915604974

Epoch: 6| Step: 12
Training loss: 2.1180075996125702
Validation loss: 2.7291068232016142

Epoch: 6| Step: 13
Training loss: 1.0206829012105614
Validation loss: 2.8185167078610402

Epoch: 675| Step: 0
Training loss: 1.6983379317281586
Validation loss: 2.7973988387849595

Epoch: 6| Step: 1
Training loss: 1.500267163962119
Validation loss: 2.6638428121097126

Epoch: 6| Step: 2
Training loss: 1.4661482635351426
Validation loss: 2.7584672836283017

Epoch: 6| Step: 3
Training loss: 2.606238027128899
Validation loss: 2.7002278985661112

Epoch: 6| Step: 4
Training loss: 1.76119263229995
Validation loss: 2.7320885174361957

Epoch: 6| Step: 5
Training loss: 2.4403589550573925
Validation loss: 2.626881777039238

Epoch: 6| Step: 6
Training loss: 1.6512005686381936
Validation loss: 2.6118086043509168

Epoch: 6| Step: 7
Training loss: 1.8399169000228972
Validation loss: 2.694497865252254

Epoch: 6| Step: 8
Training loss: 2.079025417669754
Validation loss: 2.610885887131462

Epoch: 6| Step: 9
Training loss: 2.0403751518269555
Validation loss: 2.8104349537775954

Epoch: 6| Step: 10
Training loss: 1.6914938536196003
Validation loss: 2.5788752573235847

Epoch: 6| Step: 11
Training loss: 1.700059914935567
Validation loss: 2.6340995362633324

Epoch: 6| Step: 12
Training loss: 1.5348149276896257
Validation loss: 2.7096520071478776

Epoch: 6| Step: 13
Training loss: 1.1495720066915016
Validation loss: 2.50734278912485

Epoch: 676| Step: 0
Training loss: 1.9664319636497913
Validation loss: 2.637491606758424

Epoch: 6| Step: 1
Training loss: 1.601786528014687
Validation loss: 2.615460342405642

Epoch: 6| Step: 2
Training loss: 2.1512131395567846
Validation loss: 2.5076837182997016

Epoch: 6| Step: 3
Training loss: 2.179891597257409
Validation loss: 2.547451807301055

Epoch: 6| Step: 4
Training loss: 1.7565571689439985
Validation loss: 2.741800856919568

Epoch: 6| Step: 5
Training loss: 2.2701893047767414
Validation loss: 2.7420035320019975

Epoch: 6| Step: 6
Training loss: 2.060080756669268
Validation loss: 2.733848165220429

Epoch: 6| Step: 7
Training loss: 1.77929071117552
Validation loss: 2.738069158357393

Epoch: 6| Step: 8
Training loss: 2.423981175289771
Validation loss: 2.710501054327207

Epoch: 6| Step: 9
Training loss: 1.5065534009106787
Validation loss: 2.710243920093625

Epoch: 6| Step: 10
Training loss: 2.1620397926994923
Validation loss: 2.7054686526269602

Epoch: 6| Step: 11
Training loss: 1.6509299576410323
Validation loss: 2.7698036232432743

Epoch: 6| Step: 12
Training loss: 1.9899582301601164
Validation loss: 2.6520890829451256

Epoch: 6| Step: 13
Training loss: 3.6314107836321656
Validation loss: 2.9479306760326303

Epoch: 677| Step: 0
Training loss: 1.9819470668503003
Validation loss: 2.7327972594988372

Epoch: 6| Step: 1
Training loss: 2.1111172862827043
Validation loss: 2.714857179873059

Epoch: 6| Step: 2
Training loss: 1.6473788798936564
Validation loss: 2.637059309039966

Epoch: 6| Step: 3
Training loss: 1.924413477731947
Validation loss: 2.5903520096664714

Epoch: 6| Step: 4
Training loss: 2.6176667187488856
Validation loss: 2.6171452305355247

Epoch: 6| Step: 5
Training loss: 2.0466396982775032
Validation loss: 2.690494290632158

Epoch: 6| Step: 6
Training loss: 1.342875440017783
Validation loss: 2.756017002435588

Epoch: 6| Step: 7
Training loss: 1.8678241745582502
Validation loss: 2.7066949945287195

Epoch: 6| Step: 8
Training loss: 2.0718298767607646
Validation loss: 2.498561409331268

Epoch: 6| Step: 9
Training loss: 1.884712558453881
Validation loss: 2.565000351164172

Epoch: 6| Step: 10
Training loss: 2.030769408666163
Validation loss: 2.6274859342056813

Epoch: 6| Step: 11
Training loss: 2.0356587615125363
Validation loss: 2.583426618396877

Epoch: 6| Step: 12
Training loss: 2.1157793943789867
Validation loss: 2.57728251255364

Epoch: 6| Step: 13
Training loss: 1.6291003214537894
Validation loss: 2.5963264218892084

Epoch: 678| Step: 0
Training loss: 2.409558585330798
Validation loss: 2.69169058754033

Epoch: 6| Step: 1
Training loss: 1.574950396044269
Validation loss: 2.685235259978811

Epoch: 6| Step: 2
Training loss: 1.5858151994725147
Validation loss: 2.854884899271636

Epoch: 6| Step: 3
Training loss: 2.1591682036951507
Validation loss: 2.591295168110363

Epoch: 6| Step: 4
Training loss: 2.2922439079390933
Validation loss: 2.706044345966704

Epoch: 6| Step: 5
Training loss: 1.1876444477769124
Validation loss: 2.541696372952106

Epoch: 6| Step: 6
Training loss: 1.463229416450064
Validation loss: 2.6858143128460465

Epoch: 6| Step: 7
Training loss: 2.9882212514401596
Validation loss: 2.7980188801166634

Epoch: 6| Step: 8
Training loss: 2.251368000807739
Validation loss: 2.667709998894798

Epoch: 6| Step: 9
Training loss: 1.7406315034645534
Validation loss: 2.7027257116660897

Epoch: 6| Step: 10
Training loss: 1.9542360121319229
Validation loss: 2.722779585847975

Epoch: 6| Step: 11
Training loss: 2.6818269691264542
Validation loss: 2.7151198866338095

Epoch: 6| Step: 12
Training loss: 1.4511126458671233
Validation loss: 2.6780566500298586

Epoch: 6| Step: 13
Training loss: 1.0570196857369598
Validation loss: 2.624471545801723

Epoch: 679| Step: 0
Training loss: 1.7106527849309576
Validation loss: 2.7311699178355093

Epoch: 6| Step: 1
Training loss: 1.9570402651520151
Validation loss: 2.815609479816808

Epoch: 6| Step: 2
Training loss: 2.0097631337675885
Validation loss: 2.4856285182820685

Epoch: 6| Step: 3
Training loss: 2.2361744923688414
Validation loss: 2.7432072900505884

Epoch: 6| Step: 4
Training loss: 1.524219253672913
Validation loss: 2.60321250974955

Epoch: 6| Step: 5
Training loss: 1.4191452484097546
Validation loss: 2.651490336444397

Epoch: 6| Step: 6
Training loss: 2.3137704607008907
Validation loss: 2.7141336795073117

Epoch: 6| Step: 7
Training loss: 2.3454502296542463
Validation loss: 2.842861960466419

Epoch: 6| Step: 8
Training loss: 1.7963198923889465
Validation loss: 2.6892533450586193

Epoch: 6| Step: 9
Training loss: 1.7171057725918308
Validation loss: 2.782352885591793

Epoch: 6| Step: 10
Training loss: 1.9659058144362183
Validation loss: 2.6192273519894544

Epoch: 6| Step: 11
Training loss: 2.6726278393307807
Validation loss: 2.657897377572334

Epoch: 6| Step: 12
Training loss: 1.5768413799873406
Validation loss: 2.635038180793335

Epoch: 6| Step: 13
Training loss: 1.4996055243269542
Validation loss: 2.726909586799405

Epoch: 680| Step: 0
Training loss: 1.8826114024803482
Validation loss: 2.7152767114429386

Epoch: 6| Step: 1
Training loss: 1.965953051145233
Validation loss: 2.63416751114575

Epoch: 6| Step: 2
Training loss: 2.0669969028252226
Validation loss: 2.7179556405026184

Epoch: 6| Step: 3
Training loss: 2.0087858579292015
Validation loss: 2.639146435886651

Epoch: 6| Step: 4
Training loss: 1.569724053350847
Validation loss: 2.563609276558542

Epoch: 6| Step: 5
Training loss: 1.3536530131841538
Validation loss: 2.581296513442341

Epoch: 6| Step: 6
Training loss: 1.5401040827269838
Validation loss: 2.801274281441043

Epoch: 6| Step: 7
Training loss: 3.304347388258759
Validation loss: 2.688688551001024

Epoch: 6| Step: 8
Training loss: 1.4730552719633547
Validation loss: 2.6907987246033147

Epoch: 6| Step: 9
Training loss: 1.7127909615033636
Validation loss: 2.5552131237788784

Epoch: 6| Step: 10
Training loss: 1.6461465111067888
Validation loss: 2.6503259337447775

Epoch: 6| Step: 11
Training loss: 1.7840205279738732
Validation loss: 2.670871972603842

Epoch: 6| Step: 12
Training loss: 1.9536389704595354
Validation loss: 2.7949949082011147

Epoch: 6| Step: 13
Training loss: 1.1198182509467791
Validation loss: 2.7505996782992916

Epoch: 681| Step: 0
Training loss: 2.319596819209434
Validation loss: 2.6762879878273536

Epoch: 6| Step: 1
Training loss: 2.1884202383913895
Validation loss: 2.674240987565414

Epoch: 6| Step: 2
Training loss: 1.702955395014161
Validation loss: 2.6992375345123927

Epoch: 6| Step: 3
Training loss: 1.7829718048040115
Validation loss: 2.8544848517491057

Epoch: 6| Step: 4
Training loss: 2.541508362222919
Validation loss: 2.7971260790841534

Epoch: 6| Step: 5
Training loss: 2.3619467758655115
Validation loss: 2.6944150434312966

Epoch: 6| Step: 6
Training loss: 1.5727279836229089
Validation loss: 2.629852615096013

Epoch: 6| Step: 7
Training loss: 1.5754999669061995
Validation loss: 2.7108954515937747

Epoch: 6| Step: 8
Training loss: 2.674398914434388
Validation loss: 2.5604879782477985

Epoch: 6| Step: 9
Training loss: 1.7553954736876156
Validation loss: 2.534831389925448

Epoch: 6| Step: 10
Training loss: 1.5099656144073297
Validation loss: 2.686776986610489

Epoch: 6| Step: 11
Training loss: 1.7681729996477578
Validation loss: 2.7919891463803124

Epoch: 6| Step: 12
Training loss: 1.825500038307877
Validation loss: 2.658746821546927

Epoch: 6| Step: 13
Training loss: 2.5335104938934943
Validation loss: 2.6212977892082043

Epoch: 682| Step: 0
Training loss: 1.7429228458147574
Validation loss: 2.8293931975632183

Epoch: 6| Step: 1
Training loss: 1.7694065479523482
Validation loss: 2.776088124486944

Epoch: 6| Step: 2
Training loss: 2.1610484151999314
Validation loss: 2.7403859195321685

Epoch: 6| Step: 3
Training loss: 1.1978898529147772
Validation loss: 2.730436579296632

Epoch: 6| Step: 4
Training loss: 2.439471108070226
Validation loss: 2.705277537542705

Epoch: 6| Step: 5
Training loss: 1.7962253889018482
Validation loss: 2.7928747086569756

Epoch: 6| Step: 6
Training loss: 2.48065713482469
Validation loss: 2.8291781752285523

Epoch: 6| Step: 7
Training loss: 1.900236807672121
Validation loss: 2.6233618625657797

Epoch: 6| Step: 8
Training loss: 2.014401559870618
Validation loss: 2.6493045463164604

Epoch: 6| Step: 9
Training loss: 2.131384626594448
Validation loss: 2.6861641753153767

Epoch: 6| Step: 10
Training loss: 1.7261559193226144
Validation loss: 2.702243456095714

Epoch: 6| Step: 11
Training loss: 1.5238488840088986
Validation loss: 2.6729936688404123

Epoch: 6| Step: 12
Training loss: 3.044909973317022
Validation loss: 2.6207978854739586

Epoch: 6| Step: 13
Training loss: 2.1456407133394317
Validation loss: 2.491140605467392

Epoch: 683| Step: 0
Training loss: 1.730687594730016
Validation loss: 2.6173381822651987

Epoch: 6| Step: 1
Training loss: 3.0061447474083156
Validation loss: 2.686145464966866

Epoch: 6| Step: 2
Training loss: 1.797376280812471
Validation loss: 2.5212465308810375

Epoch: 6| Step: 3
Training loss: 1.9306789430422053
Validation loss: 2.6281622255395933

Epoch: 6| Step: 4
Training loss: 1.763528845511929
Validation loss: 2.6630584977587155

Epoch: 6| Step: 5
Training loss: 1.8829626759513527
Validation loss: 2.7969381793075883

Epoch: 6| Step: 6
Training loss: 2.0481488871993028
Validation loss: 2.7408472972161184

Epoch: 6| Step: 7
Training loss: 2.0106859833846
Validation loss: 2.6585780520198066

Epoch: 6| Step: 8
Training loss: 2.0087535745604352
Validation loss: 2.6842195283647237

Epoch: 6| Step: 9
Training loss: 1.8714216418850398
Validation loss: 2.644797914073203

Epoch: 6| Step: 10
Training loss: 2.06543522827271
Validation loss: 2.817834648667552

Epoch: 6| Step: 11
Training loss: 1.5280274716948483
Validation loss: 2.7179081761198556

Epoch: 6| Step: 12
Training loss: 1.7037977937080686
Validation loss: 2.646218207358102

Epoch: 6| Step: 13
Training loss: 2.044586999502627
Validation loss: 2.7208106068287936

Epoch: 684| Step: 0
Training loss: 1.675711819293031
Validation loss: 2.763261427795147

Epoch: 6| Step: 1
Training loss: 1.2747554862485448
Validation loss: 2.624119683753721

Epoch: 6| Step: 2
Training loss: 2.2129190683851627
Validation loss: 2.541054040744332

Epoch: 6| Step: 3
Training loss: 2.6550244365077638
Validation loss: 2.5496909983999663

Epoch: 6| Step: 4
Training loss: 1.9817484496394377
Validation loss: 2.724629058984375

Epoch: 6| Step: 5
Training loss: 1.356061822168371
Validation loss: 2.649092039415247

Epoch: 6| Step: 6
Training loss: 1.8876537588788427
Validation loss: 2.5859405930964106

Epoch: 6| Step: 7
Training loss: 1.920474030271184
Validation loss: 2.696100181653955

Epoch: 6| Step: 8
Training loss: 1.6659573794130365
Validation loss: 2.798506539931084

Epoch: 6| Step: 9
Training loss: 1.8973423817222905
Validation loss: 2.6932099142700516

Epoch: 6| Step: 10
Training loss: 1.9214448524996781
Validation loss: 2.6383221924695914

Epoch: 6| Step: 11
Training loss: 1.838919243301124
Validation loss: 2.6558615693059506

Epoch: 6| Step: 12
Training loss: 2.4568433826229708
Validation loss: 2.6597381446810373

Epoch: 6| Step: 13
Training loss: 1.6311313425221856
Validation loss: 2.884532839454112

Epoch: 685| Step: 0
Training loss: 2.371624806995974
Validation loss: 2.632623755728777

Epoch: 6| Step: 1
Training loss: 2.4558270388719836
Validation loss: 2.738612362532219

Epoch: 6| Step: 2
Training loss: 1.8506859100634876
Validation loss: 2.8046089924840585

Epoch: 6| Step: 3
Training loss: 1.9367505746852642
Validation loss: 2.8153885841531316

Epoch: 6| Step: 4
Training loss: 1.6888771795332596
Validation loss: 2.6504829240679695

Epoch: 6| Step: 5
Training loss: 2.0025250469265337
Validation loss: 2.827051524973448

Epoch: 6| Step: 6
Training loss: 1.4260633215735727
Validation loss: 2.7038973453486967

Epoch: 6| Step: 7
Training loss: 1.7863755350601263
Validation loss: 2.6628405995795745

Epoch: 6| Step: 8
Training loss: 1.665741266197084
Validation loss: 2.7181812418002025

Epoch: 6| Step: 9
Training loss: 1.7425276762024593
Validation loss: 2.7749497206298606

Epoch: 6| Step: 10
Training loss: 2.6518897677911006
Validation loss: 2.7369731605891396

Epoch: 6| Step: 11
Training loss: 1.823216687899147
Validation loss: 2.655711032107337

Epoch: 6| Step: 12
Training loss: 1.6869245890352647
Validation loss: 2.7091284374372413

Epoch: 6| Step: 13
Training loss: 1.08933281629154
Validation loss: 2.7625067579433322

Epoch: 686| Step: 0
Training loss: 1.980260954720742
Validation loss: 2.668365342859899

Epoch: 6| Step: 1
Training loss: 2.5855497778337213
Validation loss: 2.661385957212084

Epoch: 6| Step: 2
Training loss: 1.9834015628822004
Validation loss: 2.64253895285677

Epoch: 6| Step: 3
Training loss: 2.432706864157736
Validation loss: 2.579254716278084

Epoch: 6| Step: 4
Training loss: 2.0485975864919435
Validation loss: 2.576783367059644

Epoch: 6| Step: 5
Training loss: 2.056743101227823
Validation loss: 2.8232710814531834

Epoch: 6| Step: 6
Training loss: 1.4806210079759248
Validation loss: 2.6579195377198856

Epoch: 6| Step: 7
Training loss: 1.749232668904328
Validation loss: 2.656092643540639

Epoch: 6| Step: 8
Training loss: 1.3468928289450406
Validation loss: 2.708673169670678

Epoch: 6| Step: 9
Training loss: 1.3232993926460914
Validation loss: 2.8732156695938897

Epoch: 6| Step: 10
Training loss: 1.395511613844652
Validation loss: 2.632428989160637

Epoch: 6| Step: 11
Training loss: 2.5456369585467677
Validation loss: 2.6546218456907713

Epoch: 6| Step: 12
Training loss: 1.7320832929075136
Validation loss: 2.7865345511000226

Epoch: 6| Step: 13
Training loss: 1.7025155893247852
Validation loss: 2.7129856642451027

Epoch: 687| Step: 0
Training loss: 1.5968289273477987
Validation loss: 2.7765399944483224

Epoch: 6| Step: 1
Training loss: 2.6406829647045034
Validation loss: 2.7496198286982496

Epoch: 6| Step: 2
Training loss: 2.353266203393837
Validation loss: 2.748384068058592

Epoch: 6| Step: 3
Training loss: 2.154928050953246
Validation loss: 2.5565950491502054

Epoch: 6| Step: 4
Training loss: 1.7791504113960825
Validation loss: 2.6321056088010435

Epoch: 6| Step: 5
Training loss: 1.298270887571569
Validation loss: 2.621767756408076

Epoch: 6| Step: 6
Training loss: 1.3733871277131056
Validation loss: 2.8526762258036023

Epoch: 6| Step: 7
Training loss: 2.1234600995049218
Validation loss: 2.694097862588276

Epoch: 6| Step: 8
Training loss: 1.57375781408041
Validation loss: 2.736958307304397

Epoch: 6| Step: 9
Training loss: 2.2071757851594507
Validation loss: 2.7841691683923155

Epoch: 6| Step: 10
Training loss: 2.3321829639458684
Validation loss: 2.5002568584691414

Epoch: 6| Step: 11
Training loss: 1.4337540622643656
Validation loss: 2.728798327043665

Epoch: 6| Step: 12
Training loss: 1.9417945273981232
Validation loss: 2.7504000163072098

Epoch: 6| Step: 13
Training loss: 1.7935310761838454
Validation loss: 2.784280706294378

Epoch: 688| Step: 0
Training loss: 1.5895335951690037
Validation loss: 2.6477733944271518

Epoch: 6| Step: 1
Training loss: 2.8008319844820844
Validation loss: 2.6743908651779007

Epoch: 6| Step: 2
Training loss: 1.7116101479910824
Validation loss: 2.584264565242156

Epoch: 6| Step: 3
Training loss: 1.7082336520754435
Validation loss: 2.7903660839539346

Epoch: 6| Step: 4
Training loss: 1.5276218951298062
Validation loss: 2.64539551029353

Epoch: 6| Step: 5
Training loss: 1.4130206406065091
Validation loss: 2.745048771649888

Epoch: 6| Step: 6
Training loss: 2.2619051156485908
Validation loss: 2.7971581628325675

Epoch: 6| Step: 7
Training loss: 1.5012915931549116
Validation loss: 2.610767981302886

Epoch: 6| Step: 8
Training loss: 1.7575734972067303
Validation loss: 2.7870605477350474

Epoch: 6| Step: 9
Training loss: 1.9438160115406504
Validation loss: 2.7346668862277315

Epoch: 6| Step: 10
Training loss: 2.2922863440339283
Validation loss: 2.750961094746667

Epoch: 6| Step: 11
Training loss: 2.4254703537500033
Validation loss: 2.6622666377567623

Epoch: 6| Step: 12
Training loss: 1.8358569837730183
Validation loss: 2.7135379862012936

Epoch: 6| Step: 13
Training loss: 1.8401923041817203
Validation loss: 2.752329658072475

Epoch: 689| Step: 0
Training loss: 1.9246954342566611
Validation loss: 2.5813960370878846

Epoch: 6| Step: 1
Training loss: 2.7293198423619027
Validation loss: 2.671413738506583

Epoch: 6| Step: 2
Training loss: 1.376770613458364
Validation loss: 2.685578271825878

Epoch: 6| Step: 3
Training loss: 1.3634700261882704
Validation loss: 2.7960562145398526

Epoch: 6| Step: 4
Training loss: 2.223851638366767
Validation loss: 2.799080588643119

Epoch: 6| Step: 5
Training loss: 2.3077031465422575
Validation loss: 2.6008973329854497

Epoch: 6| Step: 6
Training loss: 1.5609271716443442
Validation loss: 2.600142765858408

Epoch: 6| Step: 7
Training loss: 2.174380825963649
Validation loss: 2.6796092432111895

Epoch: 6| Step: 8
Training loss: 1.9175477974118107
Validation loss: 2.8531648299614263

Epoch: 6| Step: 9
Training loss: 1.9492683480781228
Validation loss: 2.674617624080286

Epoch: 6| Step: 10
Training loss: 1.871735910588079
Validation loss: 2.658915001861019

Epoch: 6| Step: 11
Training loss: 1.8915298440440806
Validation loss: 2.6562815520157708

Epoch: 6| Step: 12
Training loss: 1.6733288014617789
Validation loss: 2.5867617566496923

Epoch: 6| Step: 13
Training loss: 0.9758051567722457
Validation loss: 2.733810031729751

Epoch: 690| Step: 0
Training loss: 1.849001952897026
Validation loss: 2.6702523040577364

Epoch: 6| Step: 1
Training loss: 1.7092869430819049
Validation loss: 2.726218026484835

Epoch: 6| Step: 2
Training loss: 2.0685189017210703
Validation loss: 2.8308440024568964

Epoch: 6| Step: 3
Training loss: 1.8594746282477004
Validation loss: 2.7500768550078423

Epoch: 6| Step: 4
Training loss: 1.6961414753908401
Validation loss: 2.6063354406572703

Epoch: 6| Step: 5
Training loss: 2.2534074413181773
Validation loss: 2.8584473071812284

Epoch: 6| Step: 6
Training loss: 1.9339079014053808
Validation loss: 2.7183030868767624

Epoch: 6| Step: 7
Training loss: 2.0379181789636185
Validation loss: 2.8125199730823622

Epoch: 6| Step: 8
Training loss: 2.1575289264388577
Validation loss: 2.818804976142726

Epoch: 6| Step: 9
Training loss: 2.684286724943929
Validation loss: 2.6984555179104537

Epoch: 6| Step: 10
Training loss: 1.7140707650415692
Validation loss: 2.7871131885736253

Epoch: 6| Step: 11
Training loss: 1.5939461082528494
Validation loss: 2.6587565988104243

Epoch: 6| Step: 12
Training loss: 1.5113031964527424
Validation loss: 2.7337862867636815

Epoch: 6| Step: 13
Training loss: 1.9909619320190795
Validation loss: 2.749189684409867

Epoch: 691| Step: 0
Training loss: 1.801885634439547
Validation loss: 2.867293638513741

Epoch: 6| Step: 1
Training loss: 2.050722887934434
Validation loss: 2.7112013023647403

Epoch: 6| Step: 2
Training loss: 2.1146087143851493
Validation loss: 2.689090497553279

Epoch: 6| Step: 3
Training loss: 1.9420480569143983
Validation loss: 2.5402539366852444

Epoch: 6| Step: 4
Training loss: 1.4521734752433393
Validation loss: 2.8933566688109575

Epoch: 6| Step: 5
Training loss: 1.658371196806585
Validation loss: 2.631069196877201

Epoch: 6| Step: 6
Training loss: 2.5062064378714926
Validation loss: 2.7771066366235457

Epoch: 6| Step: 7
Training loss: 1.967752052361309
Validation loss: 2.6134616818886593

Epoch: 6| Step: 8
Training loss: 1.8432266009692764
Validation loss: 2.6014396591424935

Epoch: 6| Step: 9
Training loss: 1.944963906548993
Validation loss: 2.604950244451939

Epoch: 6| Step: 10
Training loss: 1.4716017613223362
Validation loss: 2.7849064354668163

Epoch: 6| Step: 11
Training loss: 1.822831011985037
Validation loss: 2.6544563322646484

Epoch: 6| Step: 12
Training loss: 2.4698459751739104
Validation loss: 2.7128433488842414

Epoch: 6| Step: 13
Training loss: 2.576386669074579
Validation loss: 2.617405705055973

Epoch: 692| Step: 0
Training loss: 1.5787698919956474
Validation loss: 2.7821105145693434

Epoch: 6| Step: 1
Training loss: 1.6387306539294155
Validation loss: 2.673322083650254

Epoch: 6| Step: 2
Training loss: 1.3440371361835772
Validation loss: 2.6935789264232026

Epoch: 6| Step: 3
Training loss: 1.378931234419767
Validation loss: 2.587766491201095

Epoch: 6| Step: 4
Training loss: 1.917367502978887
Validation loss: 2.8922214656949956

Epoch: 6| Step: 5
Training loss: 1.7254463834521108
Validation loss: 2.694677373248479

Epoch: 6| Step: 6
Training loss: 1.5820242422443171
Validation loss: 2.783806900655636

Epoch: 6| Step: 7
Training loss: 1.6970885505973827
Validation loss: 2.7714049949061055

Epoch: 6| Step: 8
Training loss: 2.3347432327409345
Validation loss: 2.8460514708615405

Epoch: 6| Step: 9
Training loss: 1.7609465740142694
Validation loss: 2.652060991961343

Epoch: 6| Step: 10
Training loss: 1.9567553540828275
Validation loss: 2.733118907997589

Epoch: 6| Step: 11
Training loss: 1.8981114488205255
Validation loss: 2.8718495935316066

Epoch: 6| Step: 12
Training loss: 1.7670120597388959
Validation loss: 2.7135302457761403

Epoch: 6| Step: 13
Training loss: 3.6857978642345666
Validation loss: 2.596592614183188

Epoch: 693| Step: 0
Training loss: 1.6381624905496175
Validation loss: 2.7752765285300596

Epoch: 6| Step: 1
Training loss: 1.4936196210456116
Validation loss: 2.705634709502116

Epoch: 6| Step: 2
Training loss: 1.6556290236150941
Validation loss: 2.6420267977274485

Epoch: 6| Step: 3
Training loss: 2.1518989560325266
Validation loss: 2.7863183145167825

Epoch: 6| Step: 4
Training loss: 2.201412103198288
Validation loss: 2.7814539214376923

Epoch: 6| Step: 5
Training loss: 2.861990311068403
Validation loss: 2.6881619043979392

Epoch: 6| Step: 6
Training loss: 1.803875364730594
Validation loss: 2.6959848015766608

Epoch: 6| Step: 7
Training loss: 2.477975051403302
Validation loss: 2.743213643989847

Epoch: 6| Step: 8
Training loss: 2.3981161989592867
Validation loss: 2.8168315169569293

Epoch: 6| Step: 9
Training loss: 1.3557228927476905
Validation loss: 2.667539504343468

Epoch: 6| Step: 10
Training loss: 1.8147418528477866
Validation loss: 2.719991644420313

Epoch: 6| Step: 11
Training loss: 1.8851374916506112
Validation loss: 2.7134379012639904

Epoch: 6| Step: 12
Training loss: 1.6749019138597416
Validation loss: 2.6501161844908405

Epoch: 6| Step: 13
Training loss: 1.2346402136867658
Validation loss: 2.864049905610623

Epoch: 694| Step: 0
Training loss: 2.2391266349769903
Validation loss: 2.7243386747392484

Epoch: 6| Step: 1
Training loss: 1.4905589538913362
Validation loss: 2.47740019166968

Epoch: 6| Step: 2
Training loss: 1.9043472048637462
Validation loss: 2.792681327043877

Epoch: 6| Step: 3
Training loss: 2.8920281381253856
Validation loss: 2.683340999760724

Epoch: 6| Step: 4
Training loss: 2.192360192672843
Validation loss: 2.685271642577672

Epoch: 6| Step: 5
Training loss: 1.66092884711006
Validation loss: 2.8522319615260767

Epoch: 6| Step: 6
Training loss: 1.6436167006599667
Validation loss: 2.6623758749572985

Epoch: 6| Step: 7
Training loss: 2.0392977407108934
Validation loss: 2.7015335991217775

Epoch: 6| Step: 8
Training loss: 1.6411604234665722
Validation loss: 2.7360633421656058

Epoch: 6| Step: 9
Training loss: 1.7626911194981294
Validation loss: 2.7373416138026005

Epoch: 6| Step: 10
Training loss: 1.8731058089578159
Validation loss: 2.6384452545865953

Epoch: 6| Step: 11
Training loss: 1.4091385315233789
Validation loss: 2.757791926191525

Epoch: 6| Step: 12
Training loss: 1.8796029494399435
Validation loss: 2.684715650625077

Epoch: 6| Step: 13
Training loss: 2.5305774878528395
Validation loss: 2.6883082890182393

Epoch: 695| Step: 0
Training loss: 2.573555150263968
Validation loss: 2.7744211719744087

Epoch: 6| Step: 1
Training loss: 2.450851261402368
Validation loss: 2.8518393168238805

Epoch: 6| Step: 2
Training loss: 2.4124888997983787
Validation loss: 2.694037711804773

Epoch: 6| Step: 3
Training loss: 2.1845967236194035
Validation loss: 2.7780810437386836

Epoch: 6| Step: 4
Training loss: 2.936013190413944
Validation loss: 2.717870943338839

Epoch: 6| Step: 5
Training loss: 2.002919331435014
Validation loss: 2.593309861541513

Epoch: 6| Step: 6
Training loss: 1.661625470052825
Validation loss: 2.957582912103753

Epoch: 6| Step: 7
Training loss: 1.496335560352903
Validation loss: 2.5721881968263713

Epoch: 6| Step: 8
Training loss: 2.0496916283136835
Validation loss: 2.546214064431094

Epoch: 6| Step: 9
Training loss: 1.6522828580129072
Validation loss: 2.8111099910100203

Epoch: 6| Step: 10
Training loss: 2.179680608923079
Validation loss: 2.770797688244661

Epoch: 6| Step: 11
Training loss: 1.1220512421716304
Validation loss: 2.5653363099634916

Epoch: 6| Step: 12
Training loss: 1.6205416922851217
Validation loss: 2.711152501812679

Epoch: 6| Step: 13
Training loss: 1.785264761066297
Validation loss: 2.7957118747149368

Epoch: 696| Step: 0
Training loss: 1.8363949469584695
Validation loss: 2.8184740050053194

Epoch: 6| Step: 1
Training loss: 1.8777516836626846
Validation loss: 2.7766264382074892

Epoch: 6| Step: 2
Training loss: 2.0045525473455617
Validation loss: 2.746476412526435

Epoch: 6| Step: 3
Training loss: 1.857386896584259
Validation loss: 2.75814403395799

Epoch: 6| Step: 4
Training loss: 2.185980350709714
Validation loss: 2.717777655876656

Epoch: 6| Step: 5
Training loss: 1.7624916022350912
Validation loss: 2.702386137099579

Epoch: 6| Step: 6
Training loss: 1.5220870855232784
Validation loss: 2.845669405715301

Epoch: 6| Step: 7
Training loss: 1.6714040502908365
Validation loss: 2.6850939972417907

Epoch: 6| Step: 8
Training loss: 3.009715877569889
Validation loss: 2.7662483408774534

Epoch: 6| Step: 9
Training loss: 2.1436981639767536
Validation loss: 2.640257339236027

Epoch: 6| Step: 10
Training loss: 1.6551264424729368
Validation loss: 2.7740016855050995

Epoch: 6| Step: 11
Training loss: 2.377733765350259
Validation loss: 2.5841373118099726

Epoch: 6| Step: 12
Training loss: 1.5849385239384859
Validation loss: 2.597284336746411

Epoch: 6| Step: 13
Training loss: 2.09623946039943
Validation loss: 2.653121499541771

Epoch: 697| Step: 0
Training loss: 1.366880545899243
Validation loss: 2.717065125241259

Epoch: 6| Step: 1
Training loss: 1.6155018152612224
Validation loss: 2.6706760712337805

Epoch: 6| Step: 2
Training loss: 2.07899147269008
Validation loss: 2.8018506736488327

Epoch: 6| Step: 3
Training loss: 2.521475865049059
Validation loss: 2.772460214399735

Epoch: 6| Step: 4
Training loss: 1.3478517694587808
Validation loss: 2.6716704516674157

Epoch: 6| Step: 5
Training loss: 2.5920708977869515
Validation loss: 2.6989515167026257

Epoch: 6| Step: 6
Training loss: 2.2002635797914394
Validation loss: 2.8286170085057676

Epoch: 6| Step: 7
Training loss: 1.7661146987095155
Validation loss: 2.7606866261467706

Epoch: 6| Step: 8
Training loss: 1.9978792151904454
Validation loss: 2.6934116018209564

Epoch: 6| Step: 9
Training loss: 1.7912795143863725
Validation loss: 2.682976791346461

Epoch: 6| Step: 10
Training loss: 1.6364512076931967
Validation loss: 2.6757420139895687

Epoch: 6| Step: 11
Training loss: 2.1820168576310506
Validation loss: 2.6779111419669097

Epoch: 6| Step: 12
Training loss: 1.2813026603483548
Validation loss: 2.7361304329637783

Epoch: 6| Step: 13
Training loss: 2.144892872267097
Validation loss: 2.781028289825312

Epoch: 698| Step: 0
Training loss: 1.8536924834534099
Validation loss: 2.6975020327846413

Epoch: 6| Step: 1
Training loss: 2.1043362942549955
Validation loss: 2.693138244537091

Epoch: 6| Step: 2
Training loss: 1.7220750031391685
Validation loss: 2.625731782730112

Epoch: 6| Step: 3
Training loss: 1.8459672688385595
Validation loss: 2.6504036560156594

Epoch: 6| Step: 4
Training loss: 1.3727030208220652
Validation loss: 2.6878119705193395

Epoch: 6| Step: 5
Training loss: 2.032484178469781
Validation loss: 2.6635751307009676

Epoch: 6| Step: 6
Training loss: 2.141074585863992
Validation loss: 2.620105926551971

Epoch: 6| Step: 7
Training loss: 1.555748045834125
Validation loss: 2.749950253734932

Epoch: 6| Step: 8
Training loss: 1.717144163936864
Validation loss: 2.6781018139532176

Epoch: 6| Step: 9
Training loss: 1.7336297023323521
Validation loss: 2.827560985877238

Epoch: 6| Step: 10
Training loss: 1.7477939870322123
Validation loss: 2.6751727492611646

Epoch: 6| Step: 11
Training loss: 2.0385096008658548
Validation loss: 2.6445926731771863

Epoch: 6| Step: 12
Training loss: 3.02768930739504
Validation loss: 2.651085098916215

Epoch: 6| Step: 13
Training loss: 2.515771328479054
Validation loss: 2.63860714175998

Epoch: 699| Step: 0
Training loss: 2.052077575778791
Validation loss: 2.7208148958752068

Epoch: 6| Step: 1
Training loss: 1.8440691138366927
Validation loss: 2.658421860391365

Epoch: 6| Step: 2
Training loss: 1.19844303453105
Validation loss: 2.6046653286531445

Epoch: 6| Step: 3
Training loss: 2.8089522980455386
Validation loss: 2.7047659678785703

Epoch: 6| Step: 4
Training loss: 2.563595886359781
Validation loss: 2.8206613167173997

Epoch: 6| Step: 5
Training loss: 1.7809854277497084
Validation loss: 2.5469620316904638

Epoch: 6| Step: 6
Training loss: 1.593702053770025
Validation loss: 2.5893668099658056

Epoch: 6| Step: 7
Training loss: 1.4546767942237466
Validation loss: 2.661245749166485

Epoch: 6| Step: 8
Training loss: 1.900205064047275
Validation loss: 2.6092095177980257

Epoch: 6| Step: 9
Training loss: 1.7191559745590452
Validation loss: 2.6379461348433355

Epoch: 6| Step: 10
Training loss: 2.0199003786128324
Validation loss: 2.6119080332636053

Epoch: 6| Step: 11
Training loss: 1.872736709260355
Validation loss: 2.6663788369670973

Epoch: 6| Step: 12
Training loss: 2.1273335378501903
Validation loss: 2.635575311404193

Epoch: 6| Step: 13
Training loss: 1.6066494426489966
Validation loss: 2.768213568728879

Epoch: 700| Step: 0
Training loss: 1.8357055517543381
Validation loss: 2.71044010607707

Epoch: 6| Step: 1
Training loss: 1.7784441884367013
Validation loss: 2.6143596164356797

Epoch: 6| Step: 2
Training loss: 1.5715491137159185
Validation loss: 2.704445618700185

Epoch: 6| Step: 3
Training loss: 2.316939860182898
Validation loss: 2.6259002567681766

Epoch: 6| Step: 4
Training loss: 1.608396732813494
Validation loss: 2.8236223027654868

Epoch: 6| Step: 5
Training loss: 1.6404735676950581
Validation loss: 2.812414339827942

Epoch: 6| Step: 6
Training loss: 1.9276281944027285
Validation loss: 2.591562817943502

Epoch: 6| Step: 7
Training loss: 2.3021756206903454
Validation loss: 2.6847213179631093

Epoch: 6| Step: 8
Training loss: 2.528730197891188
Validation loss: 2.7412259636698706

Epoch: 6| Step: 9
Training loss: 2.181504671373771
Validation loss: 2.7295445382017527

Epoch: 6| Step: 10
Training loss: 1.8847303318020066
Validation loss: 2.653765259045053

Epoch: 6| Step: 11
Training loss: 2.9251946343767994
Validation loss: 2.6072829989306254

Epoch: 6| Step: 12
Training loss: 1.6649160569025643
Validation loss: 2.689571506605176

Epoch: 6| Step: 13
Training loss: 0.682003351014538
Validation loss: 2.7032765584226928

Epoch: 701| Step: 0
Training loss: 2.0928906627297463
Validation loss: 2.700127168354911

Epoch: 6| Step: 1
Training loss: 1.7870246575292215
Validation loss: 2.5806222176621447

Epoch: 6| Step: 2
Training loss: 1.3484470866581928
Validation loss: 2.648551558770857

Epoch: 6| Step: 3
Training loss: 1.137586334641115
Validation loss: 2.669544738274303

Epoch: 6| Step: 4
Training loss: 1.8379213693380314
Validation loss: 2.611480335148622

Epoch: 6| Step: 5
Training loss: 2.1938524923264913
Validation loss: 2.5878363329841463

Epoch: 6| Step: 6
Training loss: 1.9852390360618932
Validation loss: 2.6398392394307613

Epoch: 6| Step: 7
Training loss: 1.8370931681024167
Validation loss: 2.518899264307667

Epoch: 6| Step: 8
Training loss: 2.982811163556782
Validation loss: 2.651560171419262

Epoch: 6| Step: 9
Training loss: 1.2509611249413397
Validation loss: 2.6458689582512136

Epoch: 6| Step: 10
Training loss: 1.5015760724806897
Validation loss: 2.7467911383399954

Epoch: 6| Step: 11
Training loss: 1.8351460150851047
Validation loss: 2.6758971251854593

Epoch: 6| Step: 12
Training loss: 2.0073854459807543
Validation loss: 2.623392248530219

Epoch: 6| Step: 13
Training loss: 2.5029061592058883
Validation loss: 2.7804532603038488

Epoch: 702| Step: 0
Training loss: 1.4326166050239528
Validation loss: 2.8515423724421765

Epoch: 6| Step: 1
Training loss: 1.9484254985032847
Validation loss: 2.6789088446967377

Epoch: 6| Step: 2
Training loss: 2.2814987256048433
Validation loss: 2.690325014155035

Epoch: 6| Step: 3
Training loss: 2.6190770857668477
Validation loss: 2.704997998852276

Epoch: 6| Step: 4
Training loss: 2.2873992605904756
Validation loss: 2.620880793666652

Epoch: 6| Step: 5
Training loss: 1.128191236416559
Validation loss: 2.5740473793830407

Epoch: 6| Step: 6
Training loss: 1.8309803370321562
Validation loss: 2.733580756325293

Epoch: 6| Step: 7
Training loss: 2.0945825771828477
Validation loss: 2.654431438010379

Epoch: 6| Step: 8
Training loss: 1.5306952892533774
Validation loss: 2.7749465730670297

Epoch: 6| Step: 9
Training loss: 2.0637392886904515
Validation loss: 2.7789428458705108

Epoch: 6| Step: 10
Training loss: 2.0936077695904274
Validation loss: 2.6706902002878823

Epoch: 6| Step: 11
Training loss: 1.8741457582661303
Validation loss: 2.6862987228810287

Epoch: 6| Step: 12
Training loss: 2.166160145264625
Validation loss: 2.7470164488997386

Epoch: 6| Step: 13
Training loss: 1.8882219790593369
Validation loss: 2.826212243699935

Epoch: 703| Step: 0
Training loss: 1.974292401418191
Validation loss: 2.7090796364514653

Epoch: 6| Step: 1
Training loss: 1.7853637841789864
Validation loss: 2.7662352916415713

Epoch: 6| Step: 2
Training loss: 1.4872805617862297
Validation loss: 2.765844884304531

Epoch: 6| Step: 3
Training loss: 1.5749536507462374
Validation loss: 2.8195106589769

Epoch: 6| Step: 4
Training loss: 2.051408479230118
Validation loss: 2.608355848690973

Epoch: 6| Step: 5
Training loss: 2.3017928226415725
Validation loss: 2.7788700448816734

Epoch: 6| Step: 6
Training loss: 1.884127082774458
Validation loss: 2.6634113932014447

Epoch: 6| Step: 7
Training loss: 2.047503658752526
Validation loss: 2.678682487341825

Epoch: 6| Step: 8
Training loss: 2.0698437429966456
Validation loss: 2.62110324518811

Epoch: 6| Step: 9
Training loss: 1.7696519014771614
Validation loss: 2.573351029545562

Epoch: 6| Step: 10
Training loss: 2.31018414395069
Validation loss: 2.7007033415290795

Epoch: 6| Step: 11
Training loss: 1.4079057906017578
Validation loss: 2.7213328097734437

Epoch: 6| Step: 12
Training loss: 2.1366801424042916
Validation loss: 2.816366897691981

Epoch: 6| Step: 13
Training loss: 2.0699234506946964
Validation loss: 2.8068312199754097

Epoch: 704| Step: 0
Training loss: 1.9630134202495493
Validation loss: 2.768946411711346

Epoch: 6| Step: 1
Training loss: 2.4821702302872026
Validation loss: 2.8224173233872105

Epoch: 6| Step: 2
Training loss: 1.5646082578554021
Validation loss: 2.8243370961216923

Epoch: 6| Step: 3
Training loss: 1.3029720884482316
Validation loss: 2.6400116802067815

Epoch: 6| Step: 4
Training loss: 1.487982131655887
Validation loss: 2.6446077510200534

Epoch: 6| Step: 5
Training loss: 1.643143238011391
Validation loss: 2.6555995427050645

Epoch: 6| Step: 6
Training loss: 1.8467709636270404
Validation loss: 2.683856867205647

Epoch: 6| Step: 7
Training loss: 1.9560933863924934
Validation loss: 2.746675604644822

Epoch: 6| Step: 8
Training loss: 2.0152631331312683
Validation loss: 2.7573002285986745

Epoch: 6| Step: 9
Training loss: 1.4104843814584176
Validation loss: 2.619795981489461

Epoch: 6| Step: 10
Training loss: 1.8644589075382056
Validation loss: 2.7203844697403943

Epoch: 6| Step: 11
Training loss: 2.9782847630817444
Validation loss: 2.6668706527171544

Epoch: 6| Step: 12
Training loss: 1.7478018306554532
Validation loss: 2.7863751124245755

Epoch: 6| Step: 13
Training loss: 2.265553861356215
Validation loss: 2.889593922386662

Epoch: 705| Step: 0
Training loss: 2.187775185850791
Validation loss: 2.7198697317188407

Epoch: 6| Step: 1
Training loss: 2.031328639929048
Validation loss: 2.607421416824569

Epoch: 6| Step: 2
Training loss: 1.5512345657994808
Validation loss: 2.639774478247148

Epoch: 6| Step: 3
Training loss: 1.8900048365859055
Validation loss: 2.5927429141804113

Epoch: 6| Step: 4
Training loss: 1.6565283055672142
Validation loss: 2.766530784915281

Epoch: 6| Step: 5
Training loss: 1.7377432344184482
Validation loss: 2.75340283267585

Epoch: 6| Step: 6
Training loss: 2.2035084924986497
Validation loss: 2.625552936140134

Epoch: 6| Step: 7
Training loss: 1.6311368968821223
Validation loss: 2.7696692955922004

Epoch: 6| Step: 8
Training loss: 1.9322982609748567
Validation loss: 2.6549353051441926

Epoch: 6| Step: 9
Training loss: 1.7443529023342954
Validation loss: 2.5305283587666727

Epoch: 6| Step: 10
Training loss: 1.8540195949675289
Validation loss: 2.7134104165864987

Epoch: 6| Step: 11
Training loss: 2.9409242516250544
Validation loss: 2.6789629178513517

Epoch: 6| Step: 12
Training loss: 1.5658857665216726
Validation loss: 2.697043854767751

Epoch: 6| Step: 13
Training loss: 1.5181849774777885
Validation loss: 2.739180024064166

Epoch: 706| Step: 0
Training loss: 1.9256142936589677
Validation loss: 2.7700835262114674

Epoch: 6| Step: 1
Training loss: 2.694207183206002
Validation loss: 2.725337959301378

Epoch: 6| Step: 2
Training loss: 1.2233282320572794
Validation loss: 2.7824405870078803

Epoch: 6| Step: 3
Training loss: 1.7828267798156956
Validation loss: 2.6396460114279674

Epoch: 6| Step: 4
Training loss: 1.8944191181780772
Validation loss: 2.83838831176928

Epoch: 6| Step: 5
Training loss: 1.9431760768612902
Validation loss: 2.717021032642409

Epoch: 6| Step: 6
Training loss: 1.3112858196999024
Validation loss: 2.5971388449658868

Epoch: 6| Step: 7
Training loss: 2.0147157732703165
Validation loss: 2.651423035790003

Epoch: 6| Step: 8
Training loss: 2.197159068596829
Validation loss: 2.833373945030807

Epoch: 6| Step: 9
Training loss: 1.7359009636743177
Validation loss: 2.680155175586684

Epoch: 6| Step: 10
Training loss: 2.3137265638321693
Validation loss: 2.8234190243935298

Epoch: 6| Step: 11
Training loss: 1.9780641061290032
Validation loss: 2.7672428131157085

Epoch: 6| Step: 12
Training loss: 1.7936138247594335
Validation loss: 2.530867187729429

Epoch: 6| Step: 13
Training loss: 2.0311656054057363
Validation loss: 2.752639128740166

Epoch: 707| Step: 0
Training loss: 1.6556440000498667
Validation loss: 2.6084976357101968

Epoch: 6| Step: 1
Training loss: 1.9748554321687217
Validation loss: 2.7265638407910684

Epoch: 6| Step: 2
Training loss: 1.8126241707197175
Validation loss: 2.6638562392623357

Epoch: 6| Step: 3
Training loss: 3.227554427440734
Validation loss: 2.7545687310715623

Epoch: 6| Step: 4
Training loss: 1.8217537213064092
Validation loss: 2.716638423277877

Epoch: 6| Step: 5
Training loss: 1.418905573982218
Validation loss: 2.7140867093591785

Epoch: 6| Step: 6
Training loss: 1.6892273151115988
Validation loss: 2.689235793486665

Epoch: 6| Step: 7
Training loss: 1.799893439635516
Validation loss: 2.6181683640119724

Epoch: 6| Step: 8
Training loss: 1.3174489586514284
Validation loss: 2.832095495279587

Epoch: 6| Step: 9
Training loss: 2.2361941101698113
Validation loss: 2.641727658780728

Epoch: 6| Step: 10
Training loss: 2.1202525794516527
Validation loss: 2.695876483071383

Epoch: 6| Step: 11
Training loss: 1.9909880973195728
Validation loss: 2.6194278233849664

Epoch: 6| Step: 12
Training loss: 1.5840046948353714
Validation loss: 2.659389335969933

Epoch: 6| Step: 13
Training loss: 0.8259863318196832
Validation loss: 2.7435547221110284

Epoch: 708| Step: 0
Training loss: 1.3089982503612647
Validation loss: 2.7256646199202863

Epoch: 6| Step: 1
Training loss: 2.356223218042163
Validation loss: 2.801391355706794

Epoch: 6| Step: 2
Training loss: 1.7215840642537206
Validation loss: 2.7250585540895913

Epoch: 6| Step: 3
Training loss: 1.0272776071121061
Validation loss: 2.6897626053513166

Epoch: 6| Step: 4
Training loss: 1.874324231759246
Validation loss: 2.607619385357136

Epoch: 6| Step: 5
Training loss: 2.676516244002031
Validation loss: 2.67549508755259

Epoch: 6| Step: 6
Training loss: 1.6632251334052373
Validation loss: 2.6788707856517195

Epoch: 6| Step: 7
Training loss: 1.3513975538912781
Validation loss: 2.747501791655682

Epoch: 6| Step: 8
Training loss: 2.361162733623178
Validation loss: 2.5378865825532095

Epoch: 6| Step: 9
Training loss: 1.9086803515005077
Validation loss: 2.8498930139759544

Epoch: 6| Step: 10
Training loss: 2.499762142310232
Validation loss: 2.7506904462436097

Epoch: 6| Step: 11
Training loss: 2.0819513187488647
Validation loss: 2.632557324419308

Epoch: 6| Step: 12
Training loss: 1.839031193935896
Validation loss: 2.6803696621928106

Epoch: 6| Step: 13
Training loss: 1.532898385444471
Validation loss: 2.7575068220309027

Epoch: 709| Step: 0
Training loss: 1.918631072195128
Validation loss: 2.6336746213770597

Epoch: 6| Step: 1
Training loss: 1.6687938070083579
Validation loss: 2.816538309057362

Epoch: 6| Step: 2
Training loss: 1.9980253962371923
Validation loss: 2.6440529773355967

Epoch: 6| Step: 3
Training loss: 1.5839997277885742
Validation loss: 2.7138147355883726

Epoch: 6| Step: 4
Training loss: 3.083478271239566
Validation loss: 2.7284351634476307

Epoch: 6| Step: 5
Training loss: 1.7645264305238768
Validation loss: 2.6386624469186204

Epoch: 6| Step: 6
Training loss: 2.573394133915215
Validation loss: 2.6993739818643476

Epoch: 6| Step: 7
Training loss: 1.8671712834759318
Validation loss: 2.758690521690255

Epoch: 6| Step: 8
Training loss: 1.6240714427943275
Validation loss: 2.6444227531091307

Epoch: 6| Step: 9
Training loss: 1.9820499165174355
Validation loss: 2.691794872541973

Epoch: 6| Step: 10
Training loss: 1.7277203298192327
Validation loss: 2.6826923721374403

Epoch: 6| Step: 11
Training loss: 1.8930347942775856
Validation loss: 2.661686855057778

Epoch: 6| Step: 12
Training loss: 1.7631894758322337
Validation loss: 2.7438456981507118

Epoch: 6| Step: 13
Training loss: 1.8169271399040663
Validation loss: 2.6474825768912895

Epoch: 710| Step: 0
Training loss: 1.8916993674702138
Validation loss: 2.711161857471082

Epoch: 6| Step: 1
Training loss: 2.328210406688996
Validation loss: 2.7729307740982714

Epoch: 6| Step: 2
Training loss: 1.7443914457370782
Validation loss: 2.6631044820766343

Epoch: 6| Step: 3
Training loss: 1.918220394741789
Validation loss: 2.6793579589664964

Epoch: 6| Step: 4
Training loss: 1.6239311664585374
Validation loss: 2.622483521472699

Epoch: 6| Step: 5
Training loss: 0.9976764745611482
Validation loss: 2.6946090819486983

Epoch: 6| Step: 6
Training loss: 1.274196936574429
Validation loss: 2.6951346214014396

Epoch: 6| Step: 7
Training loss: 1.570194069111475
Validation loss: 2.6993855702830323

Epoch: 6| Step: 8
Training loss: 1.6358845845202068
Validation loss: 2.6195458140831622

Epoch: 6| Step: 9
Training loss: 1.4387491852255072
Validation loss: 2.65504982729923

Epoch: 6| Step: 10
Training loss: 1.2528261660760383
Validation loss: 2.6678109239208627

Epoch: 6| Step: 11
Training loss: 1.7903015643501787
Validation loss: 2.8485977878456543

Epoch: 6| Step: 12
Training loss: 2.3121638698120552
Validation loss: 2.6734213761495096

Epoch: 6| Step: 13
Training loss: 2.9695822101446554
Validation loss: 2.5859795469583275

Epoch: 711| Step: 0
Training loss: 2.1035394268761314
Validation loss: 2.639594135880183

Epoch: 6| Step: 1
Training loss: 2.205454575442074
Validation loss: 2.6977994070362814

Epoch: 6| Step: 2
Training loss: 1.1066982589563215
Validation loss: 2.8217632430329513

Epoch: 6| Step: 3
Training loss: 2.4035665237937054
Validation loss: 2.717081512473156

Epoch: 6| Step: 4
Training loss: 1.6047793948002143
Validation loss: 2.5976238941093057

Epoch: 6| Step: 5
Training loss: 1.9199018816911049
Validation loss: 2.6073999631123166

Epoch: 6| Step: 6
Training loss: 1.8957103717318797
Validation loss: 2.7274226869679317

Epoch: 6| Step: 7
Training loss: 1.3909722226877648
Validation loss: 2.750297154642131

Epoch: 6| Step: 8
Training loss: 2.3884500820093537
Validation loss: 2.7464072380349798

Epoch: 6| Step: 9
Training loss: 1.41316510804532
Validation loss: 2.6703017599076255

Epoch: 6| Step: 10
Training loss: 2.522764039298907
Validation loss: 2.6757005286984565

Epoch: 6| Step: 11
Training loss: 1.774833499460066
Validation loss: 2.649379291616729

Epoch: 6| Step: 12
Training loss: 1.347491710403791
Validation loss: 2.669425557852289

Epoch: 6| Step: 13
Training loss: 2.2386532885409403
Validation loss: 2.64856470724359

Epoch: 712| Step: 0
Training loss: 2.023235296213165
Validation loss: 2.5673565427117313

Epoch: 6| Step: 1
Training loss: 2.9101066021876574
Validation loss: 2.7718502010411594

Epoch: 6| Step: 2
Training loss: 1.3682883490038174
Validation loss: 2.6573667867658886

Epoch: 6| Step: 3
Training loss: 2.2334889609168873
Validation loss: 2.8288756077942465

Epoch: 6| Step: 4
Training loss: 1.6251483262665423
Validation loss: 2.71851075500834

Epoch: 6| Step: 5
Training loss: 1.6727247128825145
Validation loss: 2.7286912190366506

Epoch: 6| Step: 6
Training loss: 1.6596961247703625
Validation loss: 2.795628911538682

Epoch: 6| Step: 7
Training loss: 2.1496836984087557
Validation loss: 2.7945777852840727

Epoch: 6| Step: 8
Training loss: 1.4604457088671883
Validation loss: 2.75940602601142

Epoch: 6| Step: 9
Training loss: 1.9591345534565419
Validation loss: 2.757008953239867

Epoch: 6| Step: 10
Training loss: 2.0554766281829497
Validation loss: 2.6604406463094565

Epoch: 6| Step: 11
Training loss: 2.0139515161824755
Validation loss: 2.7456655416289655

Epoch: 6| Step: 12
Training loss: 1.5423034778956692
Validation loss: 2.624647807350205

Epoch: 6| Step: 13
Training loss: 2.377062454154225
Validation loss: 2.73469923121651

Epoch: 713| Step: 0
Training loss: 2.4118468354086464
Validation loss: 2.630897623829145

Epoch: 6| Step: 1
Training loss: 2.0969202892341556
Validation loss: 2.720701711592592

Epoch: 6| Step: 2
Training loss: 1.4171914736724627
Validation loss: 2.64330929223982

Epoch: 6| Step: 3
Training loss: 2.501062930163823
Validation loss: 2.621909011740874

Epoch: 6| Step: 4
Training loss: 2.7191517850901383
Validation loss: 2.6594422135158644

Epoch: 6| Step: 5
Training loss: 1.5277920038350843
Validation loss: 2.6116370160625277

Epoch: 6| Step: 6
Training loss: 1.827073928072249
Validation loss: 2.7377354958355653

Epoch: 6| Step: 7
Training loss: 1.7652996742510572
Validation loss: 2.5958424694839577

Epoch: 6| Step: 8
Training loss: 1.745590717813549
Validation loss: 2.504875045214536

Epoch: 6| Step: 9
Training loss: 2.0160652093937417
Validation loss: 2.596867705513432

Epoch: 6| Step: 10
Training loss: 1.7864069657869421
Validation loss: 2.7395531424871513

Epoch: 6| Step: 11
Training loss: 1.7944722572365328
Validation loss: 2.5375655761607447

Epoch: 6| Step: 12
Training loss: 1.77359035018099
Validation loss: 2.6086123745138514

Epoch: 6| Step: 13
Training loss: 1.3146383033217885
Validation loss: 2.5913818357433507

Epoch: 714| Step: 0
Training loss: 2.129701238463345
Validation loss: 2.7641540503278352

Epoch: 6| Step: 1
Training loss: 1.9448495336939866
Validation loss: 2.6718921844327035

Epoch: 6| Step: 2
Training loss: 1.7459658718859328
Validation loss: 2.727087470840149

Epoch: 6| Step: 3
Training loss: 1.6402671787064154
Validation loss: 2.652805118913473

Epoch: 6| Step: 4
Training loss: 1.9327164942983137
Validation loss: 2.691518099264724

Epoch: 6| Step: 5
Training loss: 1.8911004217465568
Validation loss: 2.838043852624762

Epoch: 6| Step: 6
Training loss: 2.2901642006720913
Validation loss: 2.8215378200505645

Epoch: 6| Step: 7
Training loss: 1.8802704171227493
Validation loss: 2.789324783866114

Epoch: 6| Step: 8
Training loss: 1.035274455680961
Validation loss: 2.6593622870691047

Epoch: 6| Step: 9
Training loss: 1.5941220017653766
Validation loss: 2.803604576402843

Epoch: 6| Step: 10
Training loss: 2.754195567415607
Validation loss: 2.709162259780381

Epoch: 6| Step: 11
Training loss: 1.9108641391250112
Validation loss: 2.802747224573407

Epoch: 6| Step: 12
Training loss: 1.547168896431703
Validation loss: 2.725962256773308

Epoch: 6| Step: 13
Training loss: 1.4718713262232714
Validation loss: 2.6522995257958306

Epoch: 715| Step: 0
Training loss: 1.7211260238024932
Validation loss: 2.7540804774481207

Epoch: 6| Step: 1
Training loss: 2.2854239543380155
Validation loss: 2.605741839748547

Epoch: 6| Step: 2
Training loss: 1.6865469749235142
Validation loss: 2.686535111885919

Epoch: 6| Step: 3
Training loss: 1.9364925349352906
Validation loss: 2.692224466507392

Epoch: 6| Step: 4
Training loss: 2.414436582944668
Validation loss: 2.5975218389073236

Epoch: 6| Step: 5
Training loss: 1.7117842577713491
Validation loss: 2.6854567567204874

Epoch: 6| Step: 6
Training loss: 1.835416679367891
Validation loss: 2.573918584970865

Epoch: 6| Step: 7
Training loss: 1.593385392912041
Validation loss: 2.550138630035338

Epoch: 6| Step: 8
Training loss: 2.586022874050952
Validation loss: 2.533636868037911

Epoch: 6| Step: 9
Training loss: 1.7889342282883067
Validation loss: 2.674347125380302

Epoch: 6| Step: 10
Training loss: 1.5011887608217949
Validation loss: 2.7015776019238094

Epoch: 6| Step: 11
Training loss: 1.911300721976817
Validation loss: 2.6109371597178765

Epoch: 6| Step: 12
Training loss: 1.4870210052679256
Validation loss: 2.674442620793608

Epoch: 6| Step: 13
Training loss: 1.4022037361825428
Validation loss: 2.5953474022116687

Epoch: 716| Step: 0
Training loss: 1.8855338789051619
Validation loss: 2.625561825446655

Epoch: 6| Step: 1
Training loss: 1.9584399119925784
Validation loss: 2.669796441065087

Epoch: 6| Step: 2
Training loss: 1.9248141632543583
Validation loss: 2.5968847396788575

Epoch: 6| Step: 3
Training loss: 2.1035926967658733
Validation loss: 2.8265330256962997

Epoch: 6| Step: 4
Training loss: 1.3702111514464987
Validation loss: 2.775100837323251

Epoch: 6| Step: 5
Training loss: 2.9659320507536076
Validation loss: 2.6033087474363774

Epoch: 6| Step: 6
Training loss: 1.8369326877004655
Validation loss: 2.7868818287680592

Epoch: 6| Step: 7
Training loss: 1.7598007147843802
Validation loss: 2.7489076702822266

Epoch: 6| Step: 8
Training loss: 1.958239154039062
Validation loss: 2.8222435644188635

Epoch: 6| Step: 9
Training loss: 1.737658648486249
Validation loss: 2.610762187307225

Epoch: 6| Step: 10
Training loss: 2.0999259390714142
Validation loss: 2.8685883993066184

Epoch: 6| Step: 11
Training loss: 1.2842711209429312
Validation loss: 2.6749647029494983

Epoch: 6| Step: 12
Training loss: 1.454857726334686
Validation loss: 2.8449258538046553

Epoch: 6| Step: 13
Training loss: 1.599819146306251
Validation loss: 2.720114886202896

Epoch: 717| Step: 0
Training loss: 1.396562864858802
Validation loss: 2.643181371365329

Epoch: 6| Step: 1
Training loss: 1.853798719037303
Validation loss: 2.6573066786027675

Epoch: 6| Step: 2
Training loss: 1.471876023731564
Validation loss: 2.726221586705263

Epoch: 6| Step: 3
Training loss: 1.854434204802151
Validation loss: 2.7189291014687638

Epoch: 6| Step: 4
Training loss: 2.296177557070923
Validation loss: 2.750547464567024

Epoch: 6| Step: 5
Training loss: 1.9979915070529852
Validation loss: 2.820060336249251

Epoch: 6| Step: 6
Training loss: 1.7237229277744233
Validation loss: 2.792641555961983

Epoch: 6| Step: 7
Training loss: 2.2932254576077264
Validation loss: 2.839824378938344

Epoch: 6| Step: 8
Training loss: 1.8978342110246091
Validation loss: 2.7550927453567167

Epoch: 6| Step: 9
Training loss: 1.6013544459230946
Validation loss: 2.7093289395104354

Epoch: 6| Step: 10
Training loss: 3.144011991288708
Validation loss: 2.7540108991242183

Epoch: 6| Step: 11
Training loss: 1.940818897333941
Validation loss: 2.6169918197139164

Epoch: 6| Step: 12
Training loss: 1.4178587815699764
Validation loss: 2.79730956720325

Epoch: 6| Step: 13
Training loss: 1.5701432777436053
Validation loss: 2.6105371807153754

Epoch: 718| Step: 0
Training loss: 1.6672967991131655
Validation loss: 2.6762804078818583

Epoch: 6| Step: 1
Training loss: 1.1998417134000054
Validation loss: 2.702790312088456

Epoch: 6| Step: 2
Training loss: 1.308035569211895
Validation loss: 2.7293792381311857

Epoch: 6| Step: 3
Training loss: 1.7539963051290537
Validation loss: 2.718369819104676

Epoch: 6| Step: 4
Training loss: 2.1232545079082685
Validation loss: 2.680464062184951

Epoch: 6| Step: 5
Training loss: 1.5906135513703057
Validation loss: 2.795677995386498

Epoch: 6| Step: 6
Training loss: 2.043502475319808
Validation loss: 2.624607786907667

Epoch: 6| Step: 7
Training loss: 1.9065082562715772
Validation loss: 2.669523459224439

Epoch: 6| Step: 8
Training loss: 1.4362249109585128
Validation loss: 2.636391510279088

Epoch: 6| Step: 9
Training loss: 2.0833082451899236
Validation loss: 2.5457513835656407

Epoch: 6| Step: 10
Training loss: 1.8760187560325297
Validation loss: 2.581672663290612

Epoch: 6| Step: 11
Training loss: 1.5593312748529407
Validation loss: 2.756479349110034

Epoch: 6| Step: 12
Training loss: 1.5946980816644976
Validation loss: 2.6252536563230096

Epoch: 6| Step: 13
Training loss: 3.2038171532090107
Validation loss: 2.786848276289996

Epoch: 719| Step: 0
Training loss: 1.9444722885075851
Validation loss: 2.739977588605323

Epoch: 6| Step: 1
Training loss: 1.1349799631677633
Validation loss: 2.7552362597191777

Epoch: 6| Step: 2
Training loss: 1.9033096649827244
Validation loss: 2.695605412885648

Epoch: 6| Step: 3
Training loss: 2.3246357006850897
Validation loss: 2.745188093203395

Epoch: 6| Step: 4
Training loss: 1.960604453205677
Validation loss: 2.7327050726063393

Epoch: 6| Step: 5
Training loss: 1.4303228081966612
Validation loss: 2.683207627642813

Epoch: 6| Step: 6
Training loss: 1.9606623361551159
Validation loss: 2.817888892160045

Epoch: 6| Step: 7
Training loss: 2.3864064613231792
Validation loss: 2.616726599417712

Epoch: 6| Step: 8
Training loss: 2.3972876958155833
Validation loss: 2.5571697972884326

Epoch: 6| Step: 9
Training loss: 1.7461715100615574
Validation loss: 2.8555742692103436

Epoch: 6| Step: 10
Training loss: 1.890146494440782
Validation loss: 2.5687829603377947

Epoch: 6| Step: 11
Training loss: 1.88364059788699
Validation loss: 2.736256225181903

Epoch: 6| Step: 12
Training loss: 1.7075776855758602
Validation loss: 2.658178830993985

Epoch: 6| Step: 13
Training loss: 1.9509527715366042
Validation loss: 2.715395343748428

Epoch: 720| Step: 0
Training loss: 2.2140164453297158
Validation loss: 2.764076703769666

Epoch: 6| Step: 1
Training loss: 2.2904615065448857
Validation loss: 2.754588219583285

Epoch: 6| Step: 2
Training loss: 1.7269103791529956
Validation loss: 2.7842607111050213

Epoch: 6| Step: 3
Training loss: 1.5329509552029834
Validation loss: 2.7287492756194847

Epoch: 6| Step: 4
Training loss: 1.9920915169126572
Validation loss: 2.6857130573124772

Epoch: 6| Step: 5
Training loss: 1.7455401812528655
Validation loss: 2.7039342557176957

Epoch: 6| Step: 6
Training loss: 1.7801032139288975
Validation loss: 2.644069350708498

Epoch: 6| Step: 7
Training loss: 2.2537545561360934
Validation loss: 2.6250493591402653

Epoch: 6| Step: 8
Training loss: 1.5815489233881803
Validation loss: 2.787954293480223

Epoch: 6| Step: 9
Training loss: 1.7892006899840238
Validation loss: 2.8126603585562915

Epoch: 6| Step: 10
Training loss: 1.7595969404013174
Validation loss: 2.6952858601199265

Epoch: 6| Step: 11
Training loss: 2.0076533748045895
Validation loss: 2.7027383243592102

Epoch: 6| Step: 12
Training loss: 2.739712894600916
Validation loss: 2.7002655151310573

Epoch: 6| Step: 13
Training loss: 1.2480700375791007
Validation loss: 2.6169284634205487

Epoch: 721| Step: 0
Training loss: 3.0793550618669974
Validation loss: 2.699841920873042

Epoch: 6| Step: 1
Training loss: 1.7062565422631344
Validation loss: 2.5833345056611208

Epoch: 6| Step: 2
Training loss: 1.3739555033012822
Validation loss: 2.62826672438759

Epoch: 6| Step: 3
Training loss: 1.5318902681757887
Validation loss: 2.5391977309191827

Epoch: 6| Step: 4
Training loss: 1.8085025245283972
Validation loss: 2.65383974153584

Epoch: 6| Step: 5
Training loss: 1.9188187652094955
Validation loss: 2.796164402141324

Epoch: 6| Step: 6
Training loss: 2.097126302427329
Validation loss: 2.741554181744709

Epoch: 6| Step: 7
Training loss: 1.9204290269302315
Validation loss: 2.6750864780690136

Epoch: 6| Step: 8
Training loss: 1.6388247831202967
Validation loss: 2.680952215865368

Epoch: 6| Step: 9
Training loss: 1.5976097641130271
Validation loss: 2.675507882272981

Epoch: 6| Step: 10
Training loss: 2.4291217304695145
Validation loss: 2.708870148446531

Epoch: 6| Step: 11
Training loss: 1.8074744697340082
Validation loss: 2.788825204498507

Epoch: 6| Step: 12
Training loss: 1.7788729282989244
Validation loss: 2.653692514348162

Epoch: 6| Step: 13
Training loss: 1.401235711180549
Validation loss: 2.7038865347722485

Epoch: 722| Step: 0
Training loss: 1.3627351470456952
Validation loss: 2.6486796829395325

Epoch: 6| Step: 1
Training loss: 1.6407181486298639
Validation loss: 2.685027686861412

Epoch: 6| Step: 2
Training loss: 2.2166499555526715
Validation loss: 2.8646694259160994

Epoch: 6| Step: 3
Training loss: 2.886062898580942
Validation loss: 2.8669207308203166

Epoch: 6| Step: 4
Training loss: 1.7811952549067425
Validation loss: 2.7285990935428193

Epoch: 6| Step: 5
Training loss: 1.3626476662786131
Validation loss: 2.708204091840156

Epoch: 6| Step: 6
Training loss: 1.8596604713112928
Validation loss: 2.7291416059663356

Epoch: 6| Step: 7
Training loss: 1.3305007778396254
Validation loss: 2.7182625548236783

Epoch: 6| Step: 8
Training loss: 1.7691902017248315
Validation loss: 2.7247993910194004

Epoch: 6| Step: 9
Training loss: 1.997886972004491
Validation loss: 2.7706121251080558

Epoch: 6| Step: 10
Training loss: 1.8014269020947529
Validation loss: 2.7161690589234975

Epoch: 6| Step: 11
Training loss: 1.6605590331701015
Validation loss: 2.6297124430333256

Epoch: 6| Step: 12
Training loss: 1.54533540807085
Validation loss: 2.7363145325545704

Epoch: 6| Step: 13
Training loss: 2.1244869734862335
Validation loss: 2.799237031455003

Epoch: 723| Step: 0
Training loss: 2.43080402981272
Validation loss: 2.723628098676847

Epoch: 6| Step: 1
Training loss: 1.8596914967676828
Validation loss: 2.5284923012905716

Epoch: 6| Step: 2
Training loss: 1.7805065812179683
Validation loss: 2.555292834574698

Epoch: 6| Step: 3
Training loss: 2.2427260121028043
Validation loss: 2.6924681267282056

Epoch: 6| Step: 4
Training loss: 1.3947731470764053
Validation loss: 2.6604175300476935

Epoch: 6| Step: 5
Training loss: 1.4707275226489356
Validation loss: 2.6819796804377014

Epoch: 6| Step: 6
Training loss: 2.4583092596739595
Validation loss: 2.6497688950748115

Epoch: 6| Step: 7
Training loss: 2.1718866361676823
Validation loss: 2.628502252214228

Epoch: 6| Step: 8
Training loss: 2.017066381055293
Validation loss: 2.68912038105215

Epoch: 6| Step: 9
Training loss: 1.8561107287837393
Validation loss: 2.7252881730049117

Epoch: 6| Step: 10
Training loss: 2.176615638933167
Validation loss: 2.7276640065446367

Epoch: 6| Step: 11
Training loss: 1.3614223015280158
Validation loss: 2.691661810736424

Epoch: 6| Step: 12
Training loss: 2.1237554832778387
Validation loss: 2.6905215944439216

Epoch: 6| Step: 13
Training loss: 1.4664819127816568
Validation loss: 2.7656613349787174

Epoch: 724| Step: 0
Training loss: 2.2008837398759153
Validation loss: 2.59454739872491

Epoch: 6| Step: 1
Training loss: 1.7100225641200775
Validation loss: 2.82644670058178

Epoch: 6| Step: 2
Training loss: 2.3560410748448763
Validation loss: 2.820623410743314

Epoch: 6| Step: 3
Training loss: 2.628780639731081
Validation loss: 2.6181068858926535

Epoch: 6| Step: 4
Training loss: 1.5878707302672435
Validation loss: 2.808107075529474

Epoch: 6| Step: 5
Training loss: 1.4171281324777458
Validation loss: 2.7726933295659983

Epoch: 6| Step: 6
Training loss: 1.9670210012644205
Validation loss: 2.7339848421965987

Epoch: 6| Step: 7
Training loss: 1.6320848805849781
Validation loss: 2.670143123135311

Epoch: 6| Step: 8
Training loss: 1.6766492467446783
Validation loss: 2.6117662056254156

Epoch: 6| Step: 9
Training loss: 2.023449047158775
Validation loss: 2.7851103791374596

Epoch: 6| Step: 10
Training loss: 1.5879497822044697
Validation loss: 2.744817869342272

Epoch: 6| Step: 11
Training loss: 1.9500272675588468
Validation loss: 2.751580288623564

Epoch: 6| Step: 12
Training loss: 2.054216338118735
Validation loss: 2.758465120980177

Epoch: 6| Step: 13
Training loss: 2.117544671930694
Validation loss: 2.635568406153322

Epoch: 725| Step: 0
Training loss: 1.735163466478479
Validation loss: 2.722834254677083

Epoch: 6| Step: 1
Training loss: 2.276420078784132
Validation loss: 2.6748123425518067

Epoch: 6| Step: 2
Training loss: 2.3847881194232405
Validation loss: 2.602966554470482

Epoch: 6| Step: 3
Training loss: 1.6528909557212559
Validation loss: 2.646778549895435

Epoch: 6| Step: 4
Training loss: 1.601477197375785
Validation loss: 2.736185599586495

Epoch: 6| Step: 5
Training loss: 1.7354713617554005
Validation loss: 2.6187627193858534

Epoch: 6| Step: 6
Training loss: 1.1456032377466343
Validation loss: 2.66876795359889

Epoch: 6| Step: 7
Training loss: 1.902688623769911
Validation loss: 2.6672546865765816

Epoch: 6| Step: 8
Training loss: 1.7574891195598037
Validation loss: 2.816761542805609

Epoch: 6| Step: 9
Training loss: 2.0257565674489975
Validation loss: 2.7153223363800696

Epoch: 6| Step: 10
Training loss: 1.468815254222803
Validation loss: 2.7715510042562186

Epoch: 6| Step: 11
Training loss: 1.7455209906350477
Validation loss: 2.6893522285782603

Epoch: 6| Step: 12
Training loss: 2.352029240822192
Validation loss: 2.722097044026833

Epoch: 6| Step: 13
Training loss: 2.624746037868362
Validation loss: 2.6152037707338143

Epoch: 726| Step: 0
Training loss: 2.7221225560253477
Validation loss: 2.719597768802116

Epoch: 6| Step: 1
Training loss: 1.2598947858024154
Validation loss: 2.657017318433811

Epoch: 6| Step: 2
Training loss: 1.7975243763338522
Validation loss: 2.762387925250614

Epoch: 6| Step: 3
Training loss: 1.9448434041978306
Validation loss: 2.758268691184301

Epoch: 6| Step: 4
Training loss: 1.849133536047887
Validation loss: 2.643258581639875

Epoch: 6| Step: 5
Training loss: 1.6554902691452889
Validation loss: 2.687061663264065

Epoch: 6| Step: 6
Training loss: 1.7476371753864137
Validation loss: 2.77136712056519

Epoch: 6| Step: 7
Training loss: 2.019351796306452
Validation loss: 2.697042586750768

Epoch: 6| Step: 8
Training loss: 2.3397741546215545
Validation loss: 2.7092031749586325

Epoch: 6| Step: 9
Training loss: 1.3257075130208609
Validation loss: 2.7237484981571107

Epoch: 6| Step: 10
Training loss: 2.029121809926413
Validation loss: 2.683847708658985

Epoch: 6| Step: 11
Training loss: 1.8253915680210022
Validation loss: 2.8690539895735525

Epoch: 6| Step: 12
Training loss: 1.705563680371963
Validation loss: 2.6658375922772852

Epoch: 6| Step: 13
Training loss: 2.061145915959722
Validation loss: 2.676226992269911

Epoch: 727| Step: 0
Training loss: 2.8944319117252992
Validation loss: 2.65774049435844

Epoch: 6| Step: 1
Training loss: 2.170080967108968
Validation loss: 2.7044330504650866

Epoch: 6| Step: 2
Training loss: 1.7638949129630854
Validation loss: 2.6307200853939356

Epoch: 6| Step: 3
Training loss: 1.568001636260989
Validation loss: 2.7161980017542042

Epoch: 6| Step: 4
Training loss: 1.6424698402736337
Validation loss: 2.783439671140127

Epoch: 6| Step: 5
Training loss: 1.5983668754540004
Validation loss: 2.7591869186790583

Epoch: 6| Step: 6
Training loss: 1.9627052637137021
Validation loss: 2.752627058558087

Epoch: 6| Step: 7
Training loss: 1.5677996975286879
Validation loss: 2.6928049182348013

Epoch: 6| Step: 8
Training loss: 2.2373460343735063
Validation loss: 2.6981249749553986

Epoch: 6| Step: 9
Training loss: 2.166268886829418
Validation loss: 2.650906604069717

Epoch: 6| Step: 10
Training loss: 2.850727282970105
Validation loss: 2.7851096468948855

Epoch: 6| Step: 11
Training loss: 1.617276912557865
Validation loss: 2.720924569545499

Epoch: 6| Step: 12
Training loss: 1.3879438978944332
Validation loss: 2.73606098190828

Epoch: 6| Step: 13
Training loss: 0.7412446709195254
Validation loss: 2.6072052748944277

Epoch: 728| Step: 0
Training loss: 1.9823153763150119
Validation loss: 2.5730602594163736

Epoch: 6| Step: 1
Training loss: 1.5981270765545437
Validation loss: 2.7556243277866197

Epoch: 6| Step: 2
Training loss: 1.6785294199965473
Validation loss: 2.852335178249129

Epoch: 6| Step: 3
Training loss: 1.4585319747061545
Validation loss: 2.7570723226755236

Epoch: 6| Step: 4
Training loss: 2.2594009672284576
Validation loss: 2.7349293797539014

Epoch: 6| Step: 5
Training loss: 1.9076101734746782
Validation loss: 2.6493450050701752

Epoch: 6| Step: 6
Training loss: 1.9117941357863177
Validation loss: 2.6776907884312364

Epoch: 6| Step: 7
Training loss: 2.116924199134294
Validation loss: 2.6506048567480978

Epoch: 6| Step: 8
Training loss: 1.5842915529927037
Validation loss: 2.6694997311264093

Epoch: 6| Step: 9
Training loss: 2.080896809253577
Validation loss: 2.6167399038841905

Epoch: 6| Step: 10
Training loss: 1.583776721442893
Validation loss: 2.8101389336903675

Epoch: 6| Step: 11
Training loss: 2.6913656777035344
Validation loss: 2.6190792959721696

Epoch: 6| Step: 12
Training loss: 1.5024391052803716
Validation loss: 2.8861408816692875

Epoch: 6| Step: 13
Training loss: 2.1880191731842022
Validation loss: 2.7902841874766953

Epoch: 729| Step: 0
Training loss: 1.7054003993206914
Validation loss: 2.7000758452493896

Epoch: 6| Step: 1
Training loss: 1.755830316865367
Validation loss: 2.666996466972211

Epoch: 6| Step: 2
Training loss: 1.9825592143775135
Validation loss: 2.561904574932712

Epoch: 6| Step: 3
Training loss: 1.0824700853121545
Validation loss: 2.73957786589146

Epoch: 6| Step: 4
Training loss: 1.7373451712803483
Validation loss: 2.7073650235131694

Epoch: 6| Step: 5
Training loss: 1.5002484115899846
Validation loss: 2.734137005974305

Epoch: 6| Step: 6
Training loss: 1.517019672324081
Validation loss: 2.745817018888958

Epoch: 6| Step: 7
Training loss: 1.3582863230069127
Validation loss: 2.816849806568731

Epoch: 6| Step: 8
Training loss: 1.6211555928762935
Validation loss: 2.778069023191177

Epoch: 6| Step: 9
Training loss: 1.8630974956889355
Validation loss: 2.6185296746027213

Epoch: 6| Step: 10
Training loss: 2.3281356504055886
Validation loss: 2.6571287087907383

Epoch: 6| Step: 11
Training loss: 1.4099559694544261
Validation loss: 2.7828959569446683

Epoch: 6| Step: 12
Training loss: 2.758700392656896
Validation loss: 2.7556195998442963

Epoch: 6| Step: 13
Training loss: 2.0055614870546687
Validation loss: 2.7338369779512353

Epoch: 730| Step: 0
Training loss: 1.4980908005701556
Validation loss: 2.6477017428644913

Epoch: 6| Step: 1
Training loss: 1.5176924143287758
Validation loss: 2.635393558374784

Epoch: 6| Step: 2
Training loss: 1.806850837643608
Validation loss: 2.721303087828573

Epoch: 6| Step: 3
Training loss: 2.0530577022955487
Validation loss: 2.839365924709475

Epoch: 6| Step: 4
Training loss: 2.6289418913875284
Validation loss: 2.7703878821988823

Epoch: 6| Step: 5
Training loss: 1.2687397998719252
Validation loss: 2.5734137153419194

Epoch: 6| Step: 6
Training loss: 1.2888979720109843
Validation loss: 2.7836278318841985

Epoch: 6| Step: 7
Training loss: 2.571239547745338
Validation loss: 2.7182431652044854

Epoch: 6| Step: 8
Training loss: 1.8179129965330758
Validation loss: 2.7781969037944223

Epoch: 6| Step: 9
Training loss: 1.0322828033918752
Validation loss: 2.7020864279861776

Epoch: 6| Step: 10
Training loss: 1.787596589259788
Validation loss: 2.659173021897953

Epoch: 6| Step: 11
Training loss: 2.812080606344414
Validation loss: 2.6606263274855264

Epoch: 6| Step: 12
Training loss: 1.6053082091170359
Validation loss: 2.542890477657007

Epoch: 6| Step: 13
Training loss: 1.9542962796539918
Validation loss: 2.6602885401443315

Epoch: 731| Step: 0
Training loss: 1.481627481383667
Validation loss: 2.7344582399979425

Epoch: 6| Step: 1
Training loss: 1.8140056538772376
Validation loss: 2.726783986734157

Epoch: 6| Step: 2
Training loss: 1.844961770341325
Validation loss: 2.5307412633257766

Epoch: 6| Step: 3
Training loss: 1.7955785967483657
Validation loss: 2.7749677098021612

Epoch: 6| Step: 4
Training loss: 2.5608232175919157
Validation loss: 2.8041840806821483

Epoch: 6| Step: 5
Training loss: 2.9186233133599284
Validation loss: 2.8001465986478786

Epoch: 6| Step: 6
Training loss: 1.678400584631528
Validation loss: 2.6477625193005974

Epoch: 6| Step: 7
Training loss: 1.6507079773007893
Validation loss: 2.6134139873272324

Epoch: 6| Step: 8
Training loss: 1.4323749402431771
Validation loss: 2.7452138472673826

Epoch: 6| Step: 9
Training loss: 1.8858392849484245
Validation loss: 2.7853376899592135

Epoch: 6| Step: 10
Training loss: 1.3448028875228046
Validation loss: 2.700103374038182

Epoch: 6| Step: 11
Training loss: 2.278995601875778
Validation loss: 2.571500844915583

Epoch: 6| Step: 12
Training loss: 1.333856043081318
Validation loss: 2.5945038315917737

Epoch: 6| Step: 13
Training loss: 1.8225694670866643
Validation loss: 2.7651286615167896

Epoch: 732| Step: 0
Training loss: 1.4534130836327313
Validation loss: 2.6318304261025394

Epoch: 6| Step: 1
Training loss: 1.9932647784297777
Validation loss: 2.7552310719274704

Epoch: 6| Step: 2
Training loss: 3.0912857259682736
Validation loss: 2.696184077505761

Epoch: 6| Step: 3
Training loss: 1.8849241832390629
Validation loss: 2.6804352145887345

Epoch: 6| Step: 4
Training loss: 2.1177902208349417
Validation loss: 2.6835884012626128

Epoch: 6| Step: 5
Training loss: 1.708326673107035
Validation loss: 2.73341111405897

Epoch: 6| Step: 6
Training loss: 1.4546874475530334
Validation loss: 2.7500885383321743

Epoch: 6| Step: 7
Training loss: 1.5487263707412757
Validation loss: 2.6736783793250662

Epoch: 6| Step: 8
Training loss: 1.7667748412116848
Validation loss: 2.7826131927531557

Epoch: 6| Step: 9
Training loss: 1.8249564466113153
Validation loss: 2.8282631741920663

Epoch: 6| Step: 10
Training loss: 1.1826318035907795
Validation loss: 2.754837430499696

Epoch: 6| Step: 11
Training loss: 1.6475688941918023
Validation loss: 2.723363891282314

Epoch: 6| Step: 12
Training loss: 2.0406320895996317
Validation loss: 2.832455539511372

Epoch: 6| Step: 13
Training loss: 1.3266052526767123
Validation loss: 2.8112226878568807

Epoch: 733| Step: 0
Training loss: 1.543529862372334
Validation loss: 2.830323660860807

Epoch: 6| Step: 1
Training loss: 1.756709044932764
Validation loss: 2.5938369147332927

Epoch: 6| Step: 2
Training loss: 1.8473716984489679
Validation loss: 2.644514169872767

Epoch: 6| Step: 3
Training loss: 2.0581140990885185
Validation loss: 2.7269731010226654

Epoch: 6| Step: 4
Training loss: 1.4287597481035443
Validation loss: 2.7104487132005737

Epoch: 6| Step: 5
Training loss: 2.479870052624789
Validation loss: 2.7365654947253955

Epoch: 6| Step: 6
Training loss: 1.8797403177528722
Validation loss: 2.8219870745694116

Epoch: 6| Step: 7
Training loss: 1.1142097750312858
Validation loss: 2.7622207501202807

Epoch: 6| Step: 8
Training loss: 1.3808567851040954
Validation loss: 2.545307180906898

Epoch: 6| Step: 9
Training loss: 1.8874810931540904
Validation loss: 2.6451502596417322

Epoch: 6| Step: 10
Training loss: 3.151532868911274
Validation loss: 2.558522911064922

Epoch: 6| Step: 11
Training loss: 1.951442695892496
Validation loss: 2.6630120881028896

Epoch: 6| Step: 12
Training loss: 1.7967811228236932
Validation loss: 2.6398414322529846

Epoch: 6| Step: 13
Training loss: 1.5218599416626202
Validation loss: 2.6846036974774474

Epoch: 734| Step: 0
Training loss: 2.7805576962989833
Validation loss: 2.736454952715428

Epoch: 6| Step: 1
Training loss: 2.1233927314311245
Validation loss: 2.6472851703243916

Epoch: 6| Step: 2
Training loss: 1.607196481506423
Validation loss: 2.766592829841201

Epoch: 6| Step: 3
Training loss: 2.114252061373529
Validation loss: 2.6990788659504803

Epoch: 6| Step: 4
Training loss: 1.8292338602965772
Validation loss: 2.6989728477453987

Epoch: 6| Step: 5
Training loss: 1.9381322751958923
Validation loss: 2.676238337021975

Epoch: 6| Step: 6
Training loss: 1.6736297667937845
Validation loss: 2.7113276952000915

Epoch: 6| Step: 7
Training loss: 1.370888197399068
Validation loss: 2.6101558215342013

Epoch: 6| Step: 8
Training loss: 1.5333987360288208
Validation loss: 2.6823071087588746

Epoch: 6| Step: 9
Training loss: 1.811630566660486
Validation loss: 2.66603223754991

Epoch: 6| Step: 10
Training loss: 1.3813766093504902
Validation loss: 2.728322056622807

Epoch: 6| Step: 11
Training loss: 1.6085148707239887
Validation loss: 2.6601719980702963

Epoch: 6| Step: 12
Training loss: 1.817207143452715
Validation loss: 2.784226691514525

Epoch: 6| Step: 13
Training loss: 2.355146851061198
Validation loss: 2.588562602065804

Epoch: 735| Step: 0
Training loss: 1.733161708086748
Validation loss: 2.5181947842305172

Epoch: 6| Step: 1
Training loss: 1.9627593191078914
Validation loss: 2.8301225215149057

Epoch: 6| Step: 2
Training loss: 1.847272191849715
Validation loss: 2.7633397416051473

Epoch: 6| Step: 3
Training loss: 1.5028839996710608
Validation loss: 2.648624323191329

Epoch: 6| Step: 4
Training loss: 1.9528772425865448
Validation loss: 2.568083605759731

Epoch: 6| Step: 5
Training loss: 2.8945958262870817
Validation loss: 2.8580075881058034

Epoch: 6| Step: 6
Training loss: 1.2632445566560992
Validation loss: 2.7717428504204054

Epoch: 6| Step: 7
Training loss: 1.9242002485518754
Validation loss: 2.7225671133527314

Epoch: 6| Step: 8
Training loss: 1.7767398688651612
Validation loss: 2.7556629501757692

Epoch: 6| Step: 9
Training loss: 1.842861996187006
Validation loss: 2.7669083676751796

Epoch: 6| Step: 10
Training loss: 1.958248955011302
Validation loss: 2.694421118526165

Epoch: 6| Step: 11
Training loss: 2.041241763788019
Validation loss: 2.776103449006627

Epoch: 6| Step: 12
Training loss: 2.0771617521317505
Validation loss: 2.8913193045965255

Epoch: 6| Step: 13
Training loss: 1.6186696507606044
Validation loss: 2.8620100520853704

Epoch: 736| Step: 0
Training loss: 1.2518249541328832
Validation loss: 2.710766911669364

Epoch: 6| Step: 1
Training loss: 2.590148539610204
Validation loss: 2.6853855683777224

Epoch: 6| Step: 2
Training loss: 2.0295008243879593
Validation loss: 2.663763381495466

Epoch: 6| Step: 3
Training loss: 1.515654101534802
Validation loss: 2.8103345877609933

Epoch: 6| Step: 4
Training loss: 2.0424554300289604
Validation loss: 2.6015886273855577

Epoch: 6| Step: 5
Training loss: 2.9446988465710837
Validation loss: 2.706660750177693

Epoch: 6| Step: 6
Training loss: 1.9957270276050727
Validation loss: 2.6546580727696356

Epoch: 6| Step: 7
Training loss: 2.148680184269227
Validation loss: 2.753029458838794

Epoch: 6| Step: 8
Training loss: 1.5418194703678256
Validation loss: 2.6563140118273476

Epoch: 6| Step: 9
Training loss: 1.8839787713492886
Validation loss: 2.7017935203181627

Epoch: 6| Step: 10
Training loss: 1.7071618350992628
Validation loss: 2.6843591534046327

Epoch: 6| Step: 11
Training loss: 2.0002287495450592
Validation loss: 2.590655028510091

Epoch: 6| Step: 12
Training loss: 1.4101468241791324
Validation loss: 2.6061589006711188

Epoch: 6| Step: 13
Training loss: 1.331108243316833
Validation loss: 2.6745955227266287

Epoch: 737| Step: 0
Training loss: 1.3048907367229876
Validation loss: 2.7361114248208915

Epoch: 6| Step: 1
Training loss: 2.0853013343689324
Validation loss: 2.6687095191565327

Epoch: 6| Step: 2
Training loss: 1.5755326535961123
Validation loss: 2.8375019976422893

Epoch: 6| Step: 3
Training loss: 1.7821932520431598
Validation loss: 2.7388936189934867

Epoch: 6| Step: 4
Training loss: 1.294291945757943
Validation loss: 2.6623857900706067

Epoch: 6| Step: 5
Training loss: 1.741029910755839
Validation loss: 2.673493899513456

Epoch: 6| Step: 6
Training loss: 1.7698335705115242
Validation loss: 2.65690295393459

Epoch: 6| Step: 7
Training loss: 2.8264777512969497
Validation loss: 2.640444087300514

Epoch: 6| Step: 8
Training loss: 2.058517541506257
Validation loss: 2.7378200616420343

Epoch: 6| Step: 9
Training loss: 1.7081813822212384
Validation loss: 2.6147622388510916

Epoch: 6| Step: 10
Training loss: 2.7861148420490385
Validation loss: 2.7103578291094994

Epoch: 6| Step: 11
Training loss: 1.1915687325167288
Validation loss: 2.708227465684688

Epoch: 6| Step: 12
Training loss: 1.5349895202328683
Validation loss: 2.698177386021953

Epoch: 6| Step: 13
Training loss: 1.826250533587556
Validation loss: 2.661553750186902

Epoch: 738| Step: 0
Training loss: 2.66377923527843
Validation loss: 2.803466556716582

Epoch: 6| Step: 1
Training loss: 2.1287198886320886
Validation loss: 2.9162879580789465

Epoch: 6| Step: 2
Training loss: 1.7457978341340776
Validation loss: 2.716578851804636

Epoch: 6| Step: 3
Training loss: 1.6661469920914453
Validation loss: 2.657298936460607

Epoch: 6| Step: 4
Training loss: 1.7076409340108
Validation loss: 2.6254808915161467

Epoch: 6| Step: 5
Training loss: 1.7253070944943396
Validation loss: 2.9013283495979345

Epoch: 6| Step: 6
Training loss: 2.2506240403189994
Validation loss: 2.8877424816875488

Epoch: 6| Step: 7
Training loss: 1.2725048745592205
Validation loss: 2.7145786007486463

Epoch: 6| Step: 8
Training loss: 1.594588713519321
Validation loss: 2.658050540686622

Epoch: 6| Step: 9
Training loss: 1.758461116227463
Validation loss: 2.7149061735112987

Epoch: 6| Step: 10
Training loss: 1.7284944522229038
Validation loss: 2.6293832734719773

Epoch: 6| Step: 11
Training loss: 2.0068280964719083
Validation loss: 2.6819769141304546

Epoch: 6| Step: 12
Training loss: 2.746897073945632
Validation loss: 2.770514175078257

Epoch: 6| Step: 13
Training loss: 2.227878221967647
Validation loss: 2.6271820599277396

Epoch: 739| Step: 0
Training loss: 1.5767053696288909
Validation loss: 2.6817428363490268

Epoch: 6| Step: 1
Training loss: 2.598846117144007
Validation loss: 2.656385561375059

Epoch: 6| Step: 2
Training loss: 1.8689606997509993
Validation loss: 2.6529596892339136

Epoch: 6| Step: 3
Training loss: 2.14848166680454
Validation loss: 2.6527308953647726

Epoch: 6| Step: 4
Training loss: 1.367884038876308
Validation loss: 2.668866106269297

Epoch: 6| Step: 5
Training loss: 1.8648050343362481
Validation loss: 2.7738313600065907

Epoch: 6| Step: 6
Training loss: 2.094433573259809
Validation loss: 2.616064154741616

Epoch: 6| Step: 7
Training loss: 1.4689519215838225
Validation loss: 2.60493832843478

Epoch: 6| Step: 8
Training loss: 1.5259728096105698
Validation loss: 2.7535184351088997

Epoch: 6| Step: 9
Training loss: 1.2340323056980103
Validation loss: 2.642523648321745

Epoch: 6| Step: 10
Training loss: 2.8194552569085447
Validation loss: 2.7396061562293568

Epoch: 6| Step: 11
Training loss: 1.5014493615817641
Validation loss: 2.710041673221272

Epoch: 6| Step: 12
Training loss: 1.4955973386777066
Validation loss: 2.6204528998353376

Epoch: 6| Step: 13
Training loss: 2.2513140973545895
Validation loss: 2.690810183223386

Epoch: 740| Step: 0
Training loss: 2.0778298993069915
Validation loss: 2.5128529329280043

Epoch: 6| Step: 1
Training loss: 1.627943014858089
Validation loss: 2.712469318024128

Epoch: 6| Step: 2
Training loss: 1.7361184370098255
Validation loss: 2.5539984630431984

Epoch: 6| Step: 3
Training loss: 1.43940658183531
Validation loss: 2.7239357470068897

Epoch: 6| Step: 4
Training loss: 1.5532656354573104
Validation loss: 2.5531393538770772

Epoch: 6| Step: 5
Training loss: 2.3767272290204007
Validation loss: 2.580114588942049

Epoch: 6| Step: 6
Training loss: 1.1531863477975197
Validation loss: 2.750700304910943

Epoch: 6| Step: 7
Training loss: 1.9376439071863847
Validation loss: 2.6010184775616803

Epoch: 6| Step: 8
Training loss: 1.4305434869464975
Validation loss: 2.6285504737280334

Epoch: 6| Step: 9
Training loss: 1.5537996296770604
Validation loss: 2.683354185083606

Epoch: 6| Step: 10
Training loss: 1.576172328792918
Validation loss: 2.6770049365735122

Epoch: 6| Step: 11
Training loss: 2.278247686570164
Validation loss: 2.6964842144779877

Epoch: 6| Step: 12
Training loss: 1.5507063763509576
Validation loss: 2.647645567233304

Epoch: 6| Step: 13
Training loss: 1.63401261172336
Validation loss: 2.5852947084940507

Epoch: 741| Step: 0
Training loss: 1.3120384312967304
Validation loss: 2.753630161576934

Epoch: 6| Step: 1
Training loss: 1.8309381473329815
Validation loss: 2.5946309085857777

Epoch: 6| Step: 2
Training loss: 1.880574903039595
Validation loss: 2.831580940855781

Epoch: 6| Step: 3
Training loss: 1.7680519101302663
Validation loss: 2.658191861443

Epoch: 6| Step: 4
Training loss: 1.763574946075041
Validation loss: 2.6210040174045326

Epoch: 6| Step: 5
Training loss: 1.9965841209827961
Validation loss: 2.553795298867162

Epoch: 6| Step: 6
Training loss: 2.1586943330639228
Validation loss: 2.8078974556231984

Epoch: 6| Step: 7
Training loss: 1.884255137514103
Validation loss: 2.6695887113668686

Epoch: 6| Step: 8
Training loss: 1.868562519275979
Validation loss: 2.7300077133598624

Epoch: 6| Step: 9
Training loss: 1.9547208446216968
Validation loss: 2.741082900754566

Epoch: 6| Step: 10
Training loss: 1.4587925142632212
Validation loss: 2.5895167860663637

Epoch: 6| Step: 11
Training loss: 1.1888949583221506
Validation loss: 2.719720275286043

Epoch: 6| Step: 12
Training loss: 2.0588928816037764
Validation loss: 2.621682588071427

Epoch: 6| Step: 13
Training loss: 3.225742041806176
Validation loss: 2.7133899298546598

Epoch: 742| Step: 0
Training loss: 1.628538973085732
Validation loss: 2.7315089399373065

Epoch: 6| Step: 1
Training loss: 2.928879771465234
Validation loss: 2.755277406270318

Epoch: 6| Step: 2
Training loss: 1.8301216372728768
Validation loss: 2.6287310697835236

Epoch: 6| Step: 3
Training loss: 1.8670928803415274
Validation loss: 2.709247929426343

Epoch: 6| Step: 4
Training loss: 2.399881034127798
Validation loss: 2.585067747002729

Epoch: 6| Step: 5
Training loss: 1.7163814523786896
Validation loss: 2.6627591451607815

Epoch: 6| Step: 6
Training loss: 1.7479610144983717
Validation loss: 2.7561175224152894

Epoch: 6| Step: 7
Training loss: 1.5644989197466088
Validation loss: 2.630397489055712

Epoch: 6| Step: 8
Training loss: 1.6833966133133462
Validation loss: 2.69928645930006

Epoch: 6| Step: 9
Training loss: 1.4613556289022003
Validation loss: 2.6669734671314753

Epoch: 6| Step: 10
Training loss: 1.4267912331386907
Validation loss: 2.6257227729308137

Epoch: 6| Step: 11
Training loss: 1.884609140807967
Validation loss: 2.6640837784029454

Epoch: 6| Step: 12
Training loss: 2.137098763268184
Validation loss: 2.6679997098911223

Epoch: 6| Step: 13
Training loss: 2.296702683401224
Validation loss: 2.6178254056742563

Epoch: 743| Step: 0
Training loss: 1.3494504180794482
Validation loss: 2.5967389550019

Epoch: 6| Step: 1
Training loss: 2.1497541242662623
Validation loss: 2.6884208507655267

Epoch: 6| Step: 2
Training loss: 1.4367389322826687
Validation loss: 2.7057845308683204

Epoch: 6| Step: 3
Training loss: 1.9165185857319977
Validation loss: 2.6663012549035514

Epoch: 6| Step: 4
Training loss: 2.075973888872467
Validation loss: 2.630839923933788

Epoch: 6| Step: 5
Training loss: 1.6007621440054447
Validation loss: 2.561253351220476

Epoch: 6| Step: 6
Training loss: 1.995399667961259
Validation loss: 2.7964191066358017

Epoch: 6| Step: 7
Training loss: 2.1035843096812195
Validation loss: 2.69491331554601

Epoch: 6| Step: 8
Training loss: 2.0659465314477
Validation loss: 2.7022991219270978

Epoch: 6| Step: 9
Training loss: 1.8138941960292028
Validation loss: 2.792042266331503

Epoch: 6| Step: 10
Training loss: 1.3915801464909112
Validation loss: 2.7318803424368983

Epoch: 6| Step: 11
Training loss: 1.4768311594212453
Validation loss: 2.63777813860347

Epoch: 6| Step: 12
Training loss: 1.3697835199188757
Validation loss: 2.6284407056399854

Epoch: 6| Step: 13
Training loss: 3.032567789777694
Validation loss: 2.687116516867127

Epoch: 744| Step: 0
Training loss: 1.676804805712511
Validation loss: 2.602871063511134

Epoch: 6| Step: 1
Training loss: 1.520071370055451
Validation loss: 2.6110463077262462

Epoch: 6| Step: 2
Training loss: 1.9946257984599411
Validation loss: 2.558781941574083

Epoch: 6| Step: 3
Training loss: 1.8476266999734643
Validation loss: 2.6311130218242327

Epoch: 6| Step: 4
Training loss: 1.6490337143337979
Validation loss: 2.6578733836390684

Epoch: 6| Step: 5
Training loss: 1.4246253776017603
Validation loss: 2.5963067580232404

Epoch: 6| Step: 6
Training loss: 1.449417799777893
Validation loss: 2.5217916859730134

Epoch: 6| Step: 7
Training loss: 2.1117029977677375
Validation loss: 2.6618618812221677

Epoch: 6| Step: 8
Training loss: 1.4287856128756422
Validation loss: 2.7599448709642913

Epoch: 6| Step: 9
Training loss: 1.402234511517213
Validation loss: 2.6549988668393123

Epoch: 6| Step: 10
Training loss: 2.851893241200326
Validation loss: 2.6157656421041358

Epoch: 6| Step: 11
Training loss: 1.4650855920154127
Validation loss: 2.744283269745895

Epoch: 6| Step: 12
Training loss: 1.6524319816822428
Validation loss: 2.7739840708273915

Epoch: 6| Step: 13
Training loss: 2.4160731562407984
Validation loss: 2.7469565628189048

Epoch: 745| Step: 0
Training loss: 1.09743342734265
Validation loss: 2.8885196520686813

Epoch: 6| Step: 1
Training loss: 1.464103084233763
Validation loss: 2.632306845641451

Epoch: 6| Step: 2
Training loss: 1.6626330042819102
Validation loss: 2.7908898602688783

Epoch: 6| Step: 3
Training loss: 1.818764810403515
Validation loss: 2.6575921602531185

Epoch: 6| Step: 4
Training loss: 2.0338340168897897
Validation loss: 2.9508590864212456

Epoch: 6| Step: 5
Training loss: 1.590681225695389
Validation loss: 2.860007663638805

Epoch: 6| Step: 6
Training loss: 1.8169372438752946
Validation loss: 2.8049422896837064

Epoch: 6| Step: 7
Training loss: 2.892435032964764
Validation loss: 2.780481732675759

Epoch: 6| Step: 8
Training loss: 1.405421245932034
Validation loss: 2.7608278751085025

Epoch: 6| Step: 9
Training loss: 1.7772821772044098
Validation loss: 2.799221907306762

Epoch: 6| Step: 10
Training loss: 1.8047266043517722
Validation loss: 2.7206289983290666

Epoch: 6| Step: 11
Training loss: 2.5040671643521115
Validation loss: 2.8826848688337057

Epoch: 6| Step: 12
Training loss: 1.3420979302287672
Validation loss: 2.727858515366636

Epoch: 6| Step: 13
Training loss: 2.6597243082975126
Validation loss: 2.838280434774298

Epoch: 746| Step: 0
Training loss: 2.2224513598033804
Validation loss: 2.642844530229828

Epoch: 6| Step: 1
Training loss: 2.1524982708471
Validation loss: 2.6484747273698215

Epoch: 6| Step: 2
Training loss: 1.8916091249203504
Validation loss: 2.718353197266093

Epoch: 6| Step: 3
Training loss: 2.1018132056693046
Validation loss: 2.7092303214475946

Epoch: 6| Step: 4
Training loss: 1.3601728268511004
Validation loss: 2.6112644261019047

Epoch: 6| Step: 5
Training loss: 1.3097480351796842
Validation loss: 2.7040522877707382

Epoch: 6| Step: 6
Training loss: 2.303700174174729
Validation loss: 2.8207238105646093

Epoch: 6| Step: 7
Training loss: 2.546027013109475
Validation loss: 2.8521424116697154

Epoch: 6| Step: 8
Training loss: 1.3168253245713473
Validation loss: 2.5272763194082226

Epoch: 6| Step: 9
Training loss: 1.831715831160406
Validation loss: 2.666220928311889

Epoch: 6| Step: 10
Training loss: 1.7051372714451571
Validation loss: 2.638578066810747

Epoch: 6| Step: 11
Training loss: 1.546617814079011
Validation loss: 2.735335880801655

Epoch: 6| Step: 12
Training loss: 2.478940958813403
Validation loss: 2.6090671013048445

Epoch: 6| Step: 13
Training loss: 1.8156289026740409
Validation loss: 2.7219627463333853

Epoch: 747| Step: 0
Training loss: 1.6883617602582088
Validation loss: 2.663673013227025

Epoch: 6| Step: 1
Training loss: 1.5032853070783134
Validation loss: 2.770177901678939

Epoch: 6| Step: 2
Training loss: 1.852797084569861
Validation loss: 2.809328164305407

Epoch: 6| Step: 3
Training loss: 1.5027098814096342
Validation loss: 2.670637380338595

Epoch: 6| Step: 4
Training loss: 1.979878414736595
Validation loss: 2.6581248789895047

Epoch: 6| Step: 5
Training loss: 2.390764718554221
Validation loss: 2.6679017679781625

Epoch: 6| Step: 6
Training loss: 1.791117657965524
Validation loss: 2.730937276941817

Epoch: 6| Step: 7
Training loss: 1.6805399306370485
Validation loss: 2.7042767443647264

Epoch: 6| Step: 8
Training loss: 1.8611216315482964
Validation loss: 2.7352010381038734

Epoch: 6| Step: 9
Training loss: 2.0701360663323274
Validation loss: 2.603424234857696

Epoch: 6| Step: 10
Training loss: 1.5788394330593916
Validation loss: 2.615060534674486

Epoch: 6| Step: 11
Training loss: 1.1415573907795795
Validation loss: 2.6392608485857774

Epoch: 6| Step: 12
Training loss: 2.5677553576225134
Validation loss: 2.8020174020486213

Epoch: 6| Step: 13
Training loss: 1.0677979718549337
Validation loss: 2.7213219855591553

Epoch: 748| Step: 0
Training loss: 1.9797732845709333
Validation loss: 2.7236580042073193

Epoch: 6| Step: 1
Training loss: 1.479737355279558
Validation loss: 2.733266744495345

Epoch: 6| Step: 2
Training loss: 2.566787482386559
Validation loss: 2.5815466852940547

Epoch: 6| Step: 3
Training loss: 1.21690914315795
Validation loss: 2.7453373808621047

Epoch: 6| Step: 4
Training loss: 1.8927998289906287
Validation loss: 2.9186076940850625

Epoch: 6| Step: 5
Training loss: 1.737548262111094
Validation loss: 2.675404828083301

Epoch: 6| Step: 6
Training loss: 1.9226877618382827
Validation loss: 2.8246543853633033

Epoch: 6| Step: 7
Training loss: 2.153547057931425
Validation loss: 2.601185530489709

Epoch: 6| Step: 8
Training loss: 1.9820179795605462
Validation loss: 2.660037683051474

Epoch: 6| Step: 9
Training loss: 1.916896916809261
Validation loss: 2.8951634230994183

Epoch: 6| Step: 10
Training loss: 2.042118865817484
Validation loss: 2.6316552398624133

Epoch: 6| Step: 11
Training loss: 1.4230579862702706
Validation loss: 2.697606715597467

Epoch: 6| Step: 12
Training loss: 1.755899974111764
Validation loss: 2.732648071992746

Epoch: 6| Step: 13
Training loss: 2.3594865583104423
Validation loss: 2.643243718204465

Epoch: 749| Step: 0
Training loss: 2.1419642359208213
Validation loss: 2.700193175337059

Epoch: 6| Step: 1
Training loss: 2.746366528003889
Validation loss: 2.5174613797071848

Epoch: 6| Step: 2
Training loss: 2.1603528117862654
Validation loss: 2.7374142015495018

Epoch: 6| Step: 3
Training loss: 1.635255510039524
Validation loss: 2.776112580697573

Epoch: 6| Step: 4
Training loss: 1.683876668785797
Validation loss: 2.5822594081248007

Epoch: 6| Step: 5
Training loss: 1.864435634055455
Validation loss: 2.618107436200929

Epoch: 6| Step: 6
Training loss: 1.6282750651783222
Validation loss: 2.6537620633862433

Epoch: 6| Step: 7
Training loss: 1.7672082334831747
Validation loss: 2.630163391730012

Epoch: 6| Step: 8
Training loss: 2.3255266885089245
Validation loss: 2.5542306678784543

Epoch: 6| Step: 9
Training loss: 1.1874994478726357
Validation loss: 2.8622629979878567

Epoch: 6| Step: 10
Training loss: 1.838597938893969
Validation loss: 2.5916135103205487

Epoch: 6| Step: 11
Training loss: 1.8296458121485146
Validation loss: 2.5426548516673275

Epoch: 6| Step: 12
Training loss: 1.3385732872143519
Validation loss: 2.6314174962886296

Epoch: 6| Step: 13
Training loss: 1.7119416377734897
Validation loss: 2.5939539248394685

Epoch: 750| Step: 0
Training loss: 2.7656371552798293
Validation loss: 2.7171982459960673

Epoch: 6| Step: 1
Training loss: 1.9936314753875055
Validation loss: 2.7676365515082875

Epoch: 6| Step: 2
Training loss: 2.087292863082911
Validation loss: 2.655039313169564

Epoch: 6| Step: 3
Training loss: 2.1209879755725143
Validation loss: 2.7227339314549632

Epoch: 6| Step: 4
Training loss: 1.4053710309801901
Validation loss: 2.707954973496453

Epoch: 6| Step: 5
Training loss: 1.4436134042567308
Validation loss: 2.669957136899563

Epoch: 6| Step: 6
Training loss: 1.4471550820743042
Validation loss: 2.797307657744551

Epoch: 6| Step: 7
Training loss: 2.0819042517772317
Validation loss: 2.6374842370475955

Epoch: 6| Step: 8
Training loss: 1.649946778334953
Validation loss: 2.6822626287742524

Epoch: 6| Step: 9
Training loss: 1.6682242347468912
Validation loss: 2.7007316650798354

Epoch: 6| Step: 10
Training loss: 2.10614195413539
Validation loss: 2.805554201682226

Epoch: 6| Step: 11
Training loss: 1.1644180062215161
Validation loss: 2.5312273000947334

Epoch: 6| Step: 12
Training loss: 1.62112610566355
Validation loss: 2.652099304277439

Epoch: 6| Step: 13
Training loss: 1.5446788726942324
Validation loss: 2.608531659163064

Epoch: 751| Step: 0
Training loss: 1.9517182433851716
Validation loss: 2.8280923202766735

Epoch: 6| Step: 1
Training loss: 2.8142826788473045
Validation loss: 2.710258929242744

Epoch: 6| Step: 2
Training loss: 1.746259506516463
Validation loss: 2.7742759831732657

Epoch: 6| Step: 3
Training loss: 2.076524390566289
Validation loss: 2.840642277393973

Epoch: 6| Step: 4
Training loss: 1.1391862129668358
Validation loss: 2.637947144576656

Epoch: 6| Step: 5
Training loss: 1.5532371618654235
Validation loss: 2.7262888999504407

Epoch: 6| Step: 6
Training loss: 2.0567304658603174
Validation loss: 2.7226293866211466

Epoch: 6| Step: 7
Training loss: 1.4123398208943334
Validation loss: 2.7336587003415325

Epoch: 6| Step: 8
Training loss: 1.4227649293182274
Validation loss: 2.7380705056856574

Epoch: 6| Step: 9
Training loss: 1.7354227286511896
Validation loss: 2.6168052515415012

Epoch: 6| Step: 10
Training loss: 2.058535493609106
Validation loss: 2.739771037645092

Epoch: 6| Step: 11
Training loss: 1.3859097122107507
Validation loss: 2.6864178351546144

Epoch: 6| Step: 12
Training loss: 1.8676128461618602
Validation loss: 2.7266062888047484

Epoch: 6| Step: 13
Training loss: 1.9317349834171966
Validation loss: 2.8768486546045793

Epoch: 752| Step: 0
Training loss: 2.1718765368559088
Validation loss: 2.6962177437001547

Epoch: 6| Step: 1
Training loss: 2.9198516531062775
Validation loss: 2.6404632846016196

Epoch: 6| Step: 2
Training loss: 1.559991730643632
Validation loss: 2.7752173529602397

Epoch: 6| Step: 3
Training loss: 1.7926853595911447
Validation loss: 2.6343431511944346

Epoch: 6| Step: 4
Training loss: 1.490634769431675
Validation loss: 2.6879180789057644

Epoch: 6| Step: 5
Training loss: 1.8335879611430643
Validation loss: 2.637423974163103

Epoch: 6| Step: 6
Training loss: 1.5852263411155292
Validation loss: 2.606027079549991

Epoch: 6| Step: 7
Training loss: 1.5000889274939717
Validation loss: 2.6849195526782252

Epoch: 6| Step: 8
Training loss: 1.6636314729333461
Validation loss: 2.6543616679531126

Epoch: 6| Step: 9
Training loss: 2.040121804509203
Validation loss: 2.7299507446996256

Epoch: 6| Step: 10
Training loss: 1.8271165984665811
Validation loss: 2.7213760270688456

Epoch: 6| Step: 11
Training loss: 1.6045535558200832
Validation loss: 2.6327478495753334

Epoch: 6| Step: 12
Training loss: 1.321450820573531
Validation loss: 2.7119985997221234

Epoch: 6| Step: 13
Training loss: 1.6946038377901846
Validation loss: 2.7505223485708448

Epoch: 753| Step: 0
Training loss: 1.5231347981522467
Validation loss: 2.7686274041619314

Epoch: 6| Step: 1
Training loss: 1.6991180740874225
Validation loss: 2.835015040945872

Epoch: 6| Step: 2
Training loss: 1.6293689976132788
Validation loss: 2.6994498517683856

Epoch: 6| Step: 3
Training loss: 2.3536947221793323
Validation loss: 2.7488507939429647

Epoch: 6| Step: 4
Training loss: 2.695978762336416
Validation loss: 2.6140514575204827

Epoch: 6| Step: 5
Training loss: 1.2502977016710681
Validation loss: 2.7897237543786004

Epoch: 6| Step: 6
Training loss: 1.4949991788829986
Validation loss: 2.7307050800055466

Epoch: 6| Step: 7
Training loss: 1.537268352890948
Validation loss: 2.725839462761187

Epoch: 6| Step: 8
Training loss: 1.3753192270951284
Validation loss: 2.743507116583824

Epoch: 6| Step: 9
Training loss: 1.5122797119884503
Validation loss: 2.938926491797041

Epoch: 6| Step: 10
Training loss: 1.5462245151451848
Validation loss: 2.6969730777863417

Epoch: 6| Step: 11
Training loss: 1.9580507345085065
Validation loss: 2.7085069242619544

Epoch: 6| Step: 12
Training loss: 1.8542538168781604
Validation loss: 2.661326327069486

Epoch: 6| Step: 13
Training loss: 1.5809988915610242
Validation loss: 2.8256022087405905

Epoch: 754| Step: 0
Training loss: 1.8790141052886045
Validation loss: 2.7640718530170547

Epoch: 6| Step: 1
Training loss: 1.6919250397456762
Validation loss: 2.6850275846987586

Epoch: 6| Step: 2
Training loss: 1.4259314052995777
Validation loss: 2.6024750548960025

Epoch: 6| Step: 3
Training loss: 2.116825199448058
Validation loss: 2.635782779540804

Epoch: 6| Step: 4
Training loss: 1.8182550681054186
Validation loss: 2.6348573116300567

Epoch: 6| Step: 5
Training loss: 1.4199437870397058
Validation loss: 2.847611522763587

Epoch: 6| Step: 6
Training loss: 1.4457506495129153
Validation loss: 2.6620966555202052

Epoch: 6| Step: 7
Training loss: 1.933090113544881
Validation loss: 2.7336620783154775

Epoch: 6| Step: 8
Training loss: 1.9133035205995093
Validation loss: 2.814482227596912

Epoch: 6| Step: 9
Training loss: 1.376714764248208
Validation loss: 2.8082686211008454

Epoch: 6| Step: 10
Training loss: 1.3108837530419155
Validation loss: 2.8070032346487714

Epoch: 6| Step: 11
Training loss: 2.2540780304448167
Validation loss: 2.729500322221381

Epoch: 6| Step: 12
Training loss: 1.4888651345779416
Validation loss: 2.8016484399549033

Epoch: 6| Step: 13
Training loss: 3.2706349468608447
Validation loss: 2.964900439598057

Epoch: 755| Step: 0
Training loss: 2.5092974393076672
Validation loss: 2.622495136840469

Epoch: 6| Step: 1
Training loss: 1.8979858363500375
Validation loss: 2.5958627797862412

Epoch: 6| Step: 2
Training loss: 1.4171314972870468
Validation loss: 2.7548992074210887

Epoch: 6| Step: 3
Training loss: 1.7854310873807604
Validation loss: 2.68553105139522

Epoch: 6| Step: 4
Training loss: 1.7467684199758429
Validation loss: 2.54213854623623

Epoch: 6| Step: 5
Training loss: 0.931218497492328
Validation loss: 2.656251761371335

Epoch: 6| Step: 6
Training loss: 1.6513927419389556
Validation loss: 2.620939243941067

Epoch: 6| Step: 7
Training loss: 1.8555778391040019
Validation loss: 2.6598788572398107

Epoch: 6| Step: 8
Training loss: 2.105280540419644
Validation loss: 2.601232511022407

Epoch: 6| Step: 9
Training loss: 1.8565340537624246
Validation loss: 2.6596077434270824

Epoch: 6| Step: 10
Training loss: 2.1752451265256596
Validation loss: 2.7506111506291346

Epoch: 6| Step: 11
Training loss: 1.580381159257401
Validation loss: 2.7757666599236153

Epoch: 6| Step: 12
Training loss: 1.7501738325703156
Validation loss: 2.7372550664110884

Epoch: 6| Step: 13
Training loss: 1.6369219451266623
Validation loss: 2.6170776030661482

Epoch: 756| Step: 0
Training loss: 1.7360735300023173
Validation loss: 2.6450912666156383

Epoch: 6| Step: 1
Training loss: 1.6387405472052883
Validation loss: 2.5362852678099084

Epoch: 6| Step: 2
Training loss: 1.6256570221395386
Validation loss: 2.770528423277149

Epoch: 6| Step: 3
Training loss: 2.371535132865118
Validation loss: 2.8447475745807713

Epoch: 6| Step: 4
Training loss: 2.836491134029891
Validation loss: 2.826136503043534

Epoch: 6| Step: 5
Training loss: 1.0758040504006288
Validation loss: 2.783595279972252

Epoch: 6| Step: 6
Training loss: 1.573405545619542
Validation loss: 2.7859176480716084

Epoch: 6| Step: 7
Training loss: 1.5813270791306955
Validation loss: 2.5864946536997575

Epoch: 6| Step: 8
Training loss: 2.185879134079959
Validation loss: 2.843842503213879

Epoch: 6| Step: 9
Training loss: 1.7210266294131447
Validation loss: 2.7048997090968836

Epoch: 6| Step: 10
Training loss: 1.4888457581850612
Validation loss: 2.843899929922266

Epoch: 6| Step: 11
Training loss: 2.040276177168148
Validation loss: 2.6864848946804596

Epoch: 6| Step: 12
Training loss: 2.2735130061559263
Validation loss: 2.655523274349727

Epoch: 6| Step: 13
Training loss: 2.270599901526308
Validation loss: 2.848053353695569

Epoch: 757| Step: 0
Training loss: 1.3821157650635165
Validation loss: 2.728255012717403

Epoch: 6| Step: 1
Training loss: 1.6365236152369294
Validation loss: 2.736479095165748

Epoch: 6| Step: 2
Training loss: 2.049719544741955
Validation loss: 2.5872919500829097

Epoch: 6| Step: 3
Training loss: 1.680360100504518
Validation loss: 2.666823387027129

Epoch: 6| Step: 4
Training loss: 1.3883755953990031
Validation loss: 2.85276364976871

Epoch: 6| Step: 5
Training loss: 2.665664325526888
Validation loss: 2.723734658455061

Epoch: 6| Step: 6
Training loss: 1.6331631954615724
Validation loss: 2.7242949605275566

Epoch: 6| Step: 7
Training loss: 1.3398580300151237
Validation loss: 2.6133880743004028

Epoch: 6| Step: 8
Training loss: 2.6685365042059637
Validation loss: 2.657836336140857

Epoch: 6| Step: 9
Training loss: 1.4347213759065396
Validation loss: 2.7136950715308283

Epoch: 6| Step: 10
Training loss: 1.830738579484844
Validation loss: 2.635996449846023

Epoch: 6| Step: 11
Training loss: 1.3826274424718354
Validation loss: 2.7979052693485014

Epoch: 6| Step: 12
Training loss: 1.9399955428947295
Validation loss: 2.7059415082759943

Epoch: 6| Step: 13
Training loss: 2.303260387235336
Validation loss: 2.677105220071421

Epoch: 758| Step: 0
Training loss: 2.601417697851748
Validation loss: 2.8091457149228907

Epoch: 6| Step: 1
Training loss: 1.4872941075009445
Validation loss: 2.7127499650782614

Epoch: 6| Step: 2
Training loss: 2.691947273610939
Validation loss: 2.6210720052245504

Epoch: 6| Step: 3
Training loss: 2.079402674223389
Validation loss: 2.724964024348715

Epoch: 6| Step: 4
Training loss: 1.5834126787214584
Validation loss: 2.622380434540065

Epoch: 6| Step: 5
Training loss: 1.7678891408867616
Validation loss: 2.7342698393726765

Epoch: 6| Step: 6
Training loss: 1.7420272411314337
Validation loss: 2.7182997945011174

Epoch: 6| Step: 7
Training loss: 2.0735636968089795
Validation loss: 2.556512714550042

Epoch: 6| Step: 8
Training loss: 1.6247653791806476
Validation loss: 2.7410785517659204

Epoch: 6| Step: 9
Training loss: 1.6061422972435384
Validation loss: 2.7608867453195955

Epoch: 6| Step: 10
Training loss: 1.4264861572160894
Validation loss: 2.6185927219471004

Epoch: 6| Step: 11
Training loss: 1.6535615514067723
Validation loss: 2.732853987771278

Epoch: 6| Step: 12
Training loss: 1.174288489630492
Validation loss: 2.641416286104612

Epoch: 6| Step: 13
Training loss: 1.3140790160385185
Validation loss: 2.7507681384437297

Epoch: 759| Step: 0
Training loss: 1.4188379403306182
Validation loss: 2.629234585160143

Epoch: 6| Step: 1
Training loss: 1.590083673542744
Validation loss: 2.9195540069638253

Epoch: 6| Step: 2
Training loss: 1.3250024327669663
Validation loss: 2.858118874378006

Epoch: 6| Step: 3
Training loss: 1.7247919178281472
Validation loss: 2.7132840262857134

Epoch: 6| Step: 4
Training loss: 2.995771288770894
Validation loss: 2.8505606875707437

Epoch: 6| Step: 5
Training loss: 1.4194887699705516
Validation loss: 2.824925283869973

Epoch: 6| Step: 6
Training loss: 2.2172843497954657
Validation loss: 2.8757919693804075

Epoch: 6| Step: 7
Training loss: 1.5520023947825095
Validation loss: 2.7919235760224352

Epoch: 6| Step: 8
Training loss: 1.4441183569844587
Validation loss: 2.8255247051510577

Epoch: 6| Step: 9
Training loss: 1.5342486078915831
Validation loss: 2.8230949871960016

Epoch: 6| Step: 10
Training loss: 1.80339479593163
Validation loss: 2.699073390229322

Epoch: 6| Step: 11
Training loss: 2.1605085254687255
Validation loss: 2.7365968640811253

Epoch: 6| Step: 12
Training loss: 2.4782487682015066
Validation loss: 2.72268447323462

Epoch: 6| Step: 13
Training loss: 1.5561622257834569
Validation loss: 2.672265274299634

Epoch: 760| Step: 0
Training loss: 1.7999363570088323
Validation loss: 2.644811145181318

Epoch: 6| Step: 1
Training loss: 2.1063939257611333
Validation loss: 2.775737313959734

Epoch: 6| Step: 2
Training loss: 1.7486794802862444
Validation loss: 2.6857166005903923

Epoch: 6| Step: 3
Training loss: 1.602514960684845
Validation loss: 2.7088651855863453

Epoch: 6| Step: 4
Training loss: 2.1543289694033834
Validation loss: 2.712793320051304

Epoch: 6| Step: 5
Training loss: 2.0565678220435717
Validation loss: 2.64307617022745

Epoch: 6| Step: 6
Training loss: 1.9167493995833735
Validation loss: 2.6351513534305884

Epoch: 6| Step: 7
Training loss: 2.1401378884857345
Validation loss: 2.540380724163227

Epoch: 6| Step: 8
Training loss: 1.9131052542972578
Validation loss: 2.7479579182401883

Epoch: 6| Step: 9
Training loss: 1.3170941194170886
Validation loss: 2.7952592556856404

Epoch: 6| Step: 10
Training loss: 1.936128192219974
Validation loss: 2.518776618932689

Epoch: 6| Step: 11
Training loss: 2.35698624499341
Validation loss: 2.9596188421433

Epoch: 6| Step: 12
Training loss: 1.6161736152695982
Validation loss: 2.7428941512962184

Epoch: 6| Step: 13
Training loss: 2.120219856773903
Validation loss: 2.6526906013249025

Epoch: 761| Step: 0
Training loss: 1.503445720757175
Validation loss: 2.784802499952172

Epoch: 6| Step: 1
Training loss: 1.5779129490163462
Validation loss: 2.722977031718375

Epoch: 6| Step: 2
Training loss: 1.7569765943250302
Validation loss: 2.843892033187606

Epoch: 6| Step: 3
Training loss: 2.697613162688953
Validation loss: 2.6420380186118773

Epoch: 6| Step: 4
Training loss: 1.661365885140622
Validation loss: 2.6354490190049304

Epoch: 6| Step: 5
Training loss: 1.731578187098662
Validation loss: 2.5318998786001914

Epoch: 6| Step: 6
Training loss: 1.7532063810393834
Validation loss: 2.493986468191304

Epoch: 6| Step: 7
Training loss: 2.3969183966377288
Validation loss: 2.7011059811504867

Epoch: 6| Step: 8
Training loss: 1.8489548230921418
Validation loss: 2.676192497912429

Epoch: 6| Step: 9
Training loss: 1.6725926507852458
Validation loss: 2.6699631111356164

Epoch: 6| Step: 10
Training loss: 1.474496354578168
Validation loss: 2.581151899325733

Epoch: 6| Step: 11
Training loss: 1.958336309336031
Validation loss: 2.7458293440161756

Epoch: 6| Step: 12
Training loss: 1.2773332507900643
Validation loss: 2.703095705697655

Epoch: 6| Step: 13
Training loss: 1.8683792843755824
Validation loss: 2.6446078159687856

Epoch: 762| Step: 0
Training loss: 1.8636049513273505
Validation loss: 2.6395625524153425

Epoch: 6| Step: 1
Training loss: 1.5149525202496743
Validation loss: 2.790408874270151

Epoch: 6| Step: 2
Training loss: 1.3778304098742808
Validation loss: 2.701248675732397

Epoch: 6| Step: 3
Training loss: 1.9167503324851438
Validation loss: 2.5368666343715853

Epoch: 6| Step: 4
Training loss: 1.669587897204121
Validation loss: 2.741653630212911

Epoch: 6| Step: 5
Training loss: 2.305083470353699
Validation loss: 2.6294387541123023

Epoch: 6| Step: 6
Training loss: 1.648901417614093
Validation loss: 2.8033432728317558

Epoch: 6| Step: 7
Training loss: 1.6288801232307806
Validation loss: 2.795005570927352

Epoch: 6| Step: 8
Training loss: 3.0113045374205916
Validation loss: 2.763108351671409

Epoch: 6| Step: 9
Training loss: 1.3145551939470037
Validation loss: 2.7197072455308455

Epoch: 6| Step: 10
Training loss: 1.4071149920802102
Validation loss: 2.7350016673636155

Epoch: 6| Step: 11
Training loss: 1.9744537926119077
Validation loss: 2.688364945248142

Epoch: 6| Step: 12
Training loss: 1.8833876241887615
Validation loss: 2.7919049009060846

Epoch: 6| Step: 13
Training loss: 1.8931211277193885
Validation loss: 2.646485604275805

Epoch: 763| Step: 0
Training loss: 1.8402379093609924
Validation loss: 2.5936614563950284

Epoch: 6| Step: 1
Training loss: 1.73761659409378
Validation loss: 2.6561142348085736

Epoch: 6| Step: 2
Training loss: 1.880118060564649
Validation loss: 2.6614901485355227

Epoch: 6| Step: 3
Training loss: 2.736120571457913
Validation loss: 2.649160171526787

Epoch: 6| Step: 4
Training loss: 2.068366060615375
Validation loss: 2.4682779230721676

Epoch: 6| Step: 5
Training loss: 2.142535171843265
Validation loss: 2.682396736958399

Epoch: 6| Step: 6
Training loss: 1.1404972788750256
Validation loss: 2.6873459062329825

Epoch: 6| Step: 7
Training loss: 1.5529708970063967
Validation loss: 2.688712893518911

Epoch: 6| Step: 8
Training loss: 1.6951347293027423
Validation loss: 2.6831808943324362

Epoch: 6| Step: 9
Training loss: 1.7068750934188746
Validation loss: 2.658985340839514

Epoch: 6| Step: 10
Training loss: 1.989611467358927
Validation loss: 2.6765339867382596

Epoch: 6| Step: 11
Training loss: 1.3232481333468813
Validation loss: 2.6675441942666285

Epoch: 6| Step: 12
Training loss: 2.218472745523784
Validation loss: 2.7302292783577866

Epoch: 6| Step: 13
Training loss: 1.7491826464738032
Validation loss: 2.6956898685917183

Epoch: 764| Step: 0
Training loss: 1.5971316196710208
Validation loss: 2.6889021550368266

Epoch: 6| Step: 1
Training loss: 2.0353491869243525
Validation loss: 2.7045385375560715

Epoch: 6| Step: 2
Training loss: 2.0690342825938934
Validation loss: 2.637225393509661

Epoch: 6| Step: 3
Training loss: 2.5359720525074074
Validation loss: 2.7844047835650474

Epoch: 6| Step: 4
Training loss: 1.2408788733561689
Validation loss: 2.7241637431030568

Epoch: 6| Step: 5
Training loss: 1.239639403840839
Validation loss: 2.9034389503632876

Epoch: 6| Step: 6
Training loss: 1.0455122091199822
Validation loss: 2.6248009074428684

Epoch: 6| Step: 7
Training loss: 1.9473434937728007
Validation loss: 2.666600762662929

Epoch: 6| Step: 8
Training loss: 1.9264077179323251
Validation loss: 2.783455330504305

Epoch: 6| Step: 9
Training loss: 1.4778627191159315
Validation loss: 2.7247059380711476

Epoch: 6| Step: 10
Training loss: 3.058760871072835
Validation loss: 2.7300478865142197

Epoch: 6| Step: 11
Training loss: 1.543932341027104
Validation loss: 2.633303602099337

Epoch: 6| Step: 12
Training loss: 2.2327319953558997
Validation loss: 2.6089961014053786

Epoch: 6| Step: 13
Training loss: 1.0145191334198138
Validation loss: 2.6902447178066446

Epoch: 765| Step: 0
Training loss: 1.4172051846074796
Validation loss: 2.8101829902048827

Epoch: 6| Step: 1
Training loss: 1.9001921406014743
Validation loss: 2.712775687833593

Epoch: 6| Step: 2
Training loss: 2.0335510132175574
Validation loss: 2.6110128330069253

Epoch: 6| Step: 3
Training loss: 1.410500016935579
Validation loss: 2.6153348803413983

Epoch: 6| Step: 4
Training loss: 1.803271510156821
Validation loss: 2.7414120486675615

Epoch: 6| Step: 5
Training loss: 1.313149927076082
Validation loss: 2.5951265452281067

Epoch: 6| Step: 6
Training loss: 2.001294075017694
Validation loss: 2.785229733484664

Epoch: 6| Step: 7
Training loss: 1.8640021443088624
Validation loss: 2.602854121709175

Epoch: 6| Step: 8
Training loss: 1.49999173479982
Validation loss: 2.7709761095575445

Epoch: 6| Step: 9
Training loss: 1.4103058711850676
Validation loss: 2.6212340088567085

Epoch: 6| Step: 10
Training loss: 1.6048435005348984
Validation loss: 2.6161526941823796

Epoch: 6| Step: 11
Training loss: 2.8374017975740524
Validation loss: 2.66271160526378

Epoch: 6| Step: 12
Training loss: 1.669558194362081
Validation loss: 2.773140989910236

Epoch: 6| Step: 13
Training loss: 2.0566888497432476
Validation loss: 2.7014166480140207

Epoch: 766| Step: 0
Training loss: 1.6372588001852912
Validation loss: 2.6020720756154097

Epoch: 6| Step: 1
Training loss: 1.3028594132887028
Validation loss: 2.6964915988229228

Epoch: 6| Step: 2
Training loss: 1.2184876868808068
Validation loss: 2.6522547750298244

Epoch: 6| Step: 3
Training loss: 1.5023497614589005
Validation loss: 2.6345218136461224

Epoch: 6| Step: 4
Training loss: 1.6699981136654005
Validation loss: 2.677732971463416

Epoch: 6| Step: 5
Training loss: 1.364283676830702
Validation loss: 2.7653159952714943

Epoch: 6| Step: 6
Training loss: 1.1323265875116717
Validation loss: 2.598612168199361

Epoch: 6| Step: 7
Training loss: 1.7283054030003029
Validation loss: 2.691447475109346

Epoch: 6| Step: 8
Training loss: 2.2219142647451386
Validation loss: 2.762796834762102

Epoch: 6| Step: 9
Training loss: 1.5955889694861576
Validation loss: 2.754414042866619

Epoch: 6| Step: 10
Training loss: 2.429180521677418
Validation loss: 2.676091678709143

Epoch: 6| Step: 11
Training loss: 2.1778806355032407
Validation loss: 2.855708059409561

Epoch: 6| Step: 12
Training loss: 1.853539550112316
Validation loss: 2.7524992650527036

Epoch: 6| Step: 13
Training loss: 2.256685708368035
Validation loss: 2.5805475938847264

Epoch: 767| Step: 0
Training loss: 1.139978303870156
Validation loss: 2.794800771596507

Epoch: 6| Step: 1
Training loss: 1.4716322194464024
Validation loss: 2.7123369566664324

Epoch: 6| Step: 2
Training loss: 1.4665925433473008
Validation loss: 2.6010381398109788

Epoch: 6| Step: 3
Training loss: 1.6526135524223147
Validation loss: 2.787387249990972

Epoch: 6| Step: 4
Training loss: 1.9410619910205391
Validation loss: 2.6410345002827107

Epoch: 6| Step: 5
Training loss: 1.7419356091332932
Validation loss: 2.7612145844649088

Epoch: 6| Step: 6
Training loss: 1.838061074471893
Validation loss: 2.720580208578062

Epoch: 6| Step: 7
Training loss: 1.814683651112869
Validation loss: 2.6494417161251533

Epoch: 6| Step: 8
Training loss: 2.0130733928916893
Validation loss: 2.7599790365910044

Epoch: 6| Step: 9
Training loss: 1.802368655981403
Validation loss: 2.604045443430856

Epoch: 6| Step: 10
Training loss: 1.3831392753405654
Validation loss: 2.6703344011500385

Epoch: 6| Step: 11
Training loss: 1.8316393597794334
Validation loss: 2.7031812100668815

Epoch: 6| Step: 12
Training loss: 2.5251964190540637
Validation loss: 2.6699366638535924

Epoch: 6| Step: 13
Training loss: 1.4886208294515273
Validation loss: 2.677113235311105

Epoch: 768| Step: 0
Training loss: 2.58158263494741
Validation loss: 2.787515925372908

Epoch: 6| Step: 1
Training loss: 2.2130718375852574
Validation loss: 2.6173064624660625

Epoch: 6| Step: 2
Training loss: 1.6116184042509598
Validation loss: 2.6319518641195567

Epoch: 6| Step: 3
Training loss: 1.9240977761530897
Validation loss: 2.702280688842828

Epoch: 6| Step: 4
Training loss: 1.7937424928727381
Validation loss: 2.747612143016649

Epoch: 6| Step: 5
Training loss: 1.023008241976354
Validation loss: 2.805714624626036

Epoch: 6| Step: 6
Training loss: 1.9129777598307132
Validation loss: 2.78987269153693

Epoch: 6| Step: 7
Training loss: 2.1347891901361176
Validation loss: 2.7353895639094783

Epoch: 6| Step: 8
Training loss: 2.2363690634899163
Validation loss: 2.754892762250331

Epoch: 6| Step: 9
Training loss: 1.915640044658882
Validation loss: 2.8010534377722847

Epoch: 6| Step: 10
Training loss: 2.7641943555642485
Validation loss: 2.839584958751

Epoch: 6| Step: 11
Training loss: 1.076078878216583
Validation loss: 2.7216932993435803

Epoch: 6| Step: 12
Training loss: 2.0527210180717317
Validation loss: 2.6649629142246516

Epoch: 6| Step: 13
Training loss: 1.1651893128733586
Validation loss: 2.695853972116272

Epoch: 769| Step: 0
Training loss: 1.438582468892871
Validation loss: 2.625162358885885

Epoch: 6| Step: 1
Training loss: 1.7987113525395448
Validation loss: 2.8973120768286846

Epoch: 6| Step: 2
Training loss: 1.5272890359195643
Validation loss: 2.7503288944937405

Epoch: 6| Step: 3
Training loss: 1.5630501350860375
Validation loss: 2.736279764611983

Epoch: 6| Step: 4
Training loss: 3.0203720442126705
Validation loss: 2.654968271940544

Epoch: 6| Step: 5
Training loss: 1.1579597307460567
Validation loss: 2.745510504000879

Epoch: 6| Step: 6
Training loss: 1.564010729013897
Validation loss: 2.701288247349013

Epoch: 6| Step: 7
Training loss: 1.6892075553101793
Validation loss: 2.575551616827686

Epoch: 6| Step: 8
Training loss: 1.4777683400368224
Validation loss: 2.551324648129522

Epoch: 6| Step: 9
Training loss: 1.9360563991386595
Validation loss: 2.667477840697479

Epoch: 6| Step: 10
Training loss: 2.0709827417808557
Validation loss: 2.644445325730594

Epoch: 6| Step: 11
Training loss: 1.2272294290527763
Validation loss: 2.5981737330581836

Epoch: 6| Step: 12
Training loss: 2.1425588740802777
Validation loss: 2.7286232697982253

Epoch: 6| Step: 13
Training loss: 1.4167088147045677
Validation loss: 2.8354137902882925

Epoch: 770| Step: 0
Training loss: 1.7642089431567156
Validation loss: 2.6937189590366883

Epoch: 6| Step: 1
Training loss: 2.0066377639378814
Validation loss: 2.71947826211529

Epoch: 6| Step: 2
Training loss: 0.8164262906037778
Validation loss: 2.7827999851356062

Epoch: 6| Step: 3
Training loss: 1.236141100292296
Validation loss: 2.6017831909973035

Epoch: 6| Step: 4
Training loss: 2.0662576373190484
Validation loss: 2.8723016339536143

Epoch: 6| Step: 5
Training loss: 1.4888034014729092
Validation loss: 2.6199055109580334

Epoch: 6| Step: 6
Training loss: 1.365373290584297
Validation loss: 2.6778504006998665

Epoch: 6| Step: 7
Training loss: 1.7831771865412238
Validation loss: 2.728905549216082

Epoch: 6| Step: 8
Training loss: 2.238708348826608
Validation loss: 2.6013917471227934

Epoch: 6| Step: 9
Training loss: 2.0263860127137603
Validation loss: 2.6422295076325164

Epoch: 6| Step: 10
Training loss: 1.9517743743160207
Validation loss: 2.674910235573617

Epoch: 6| Step: 11
Training loss: 2.132602779152147
Validation loss: 2.75097077910994

Epoch: 6| Step: 12
Training loss: 2.785467914194504
Validation loss: 2.719558639881694

Epoch: 6| Step: 13
Training loss: 2.0824452859896763
Validation loss: 2.6959024576385557

Epoch: 771| Step: 0
Training loss: 1.6716107311126145
Validation loss: 2.7908162171687594

Epoch: 6| Step: 1
Training loss: 1.6983867844745302
Validation loss: 2.6353000834116815

Epoch: 6| Step: 2
Training loss: 1.5983345065677754
Validation loss: 2.8189383297226915

Epoch: 6| Step: 3
Training loss: 2.00297456316287
Validation loss: 2.7388137085071285

Epoch: 6| Step: 4
Training loss: 1.5936261297220902
Validation loss: 2.605085634252946

Epoch: 6| Step: 5
Training loss: 1.5384813169895273
Validation loss: 2.8165666137077934

Epoch: 6| Step: 6
Training loss: 1.6282555174544473
Validation loss: 2.646632244355026

Epoch: 6| Step: 7
Training loss: 1.9197038000831563
Validation loss: 2.6818338250524136

Epoch: 6| Step: 8
Training loss: 1.697686427445486
Validation loss: 2.6669229411861743

Epoch: 6| Step: 9
Training loss: 1.681249982982763
Validation loss: 2.719586375857918

Epoch: 6| Step: 10
Training loss: 2.3359213735987034
Validation loss: 2.7524881712858376

Epoch: 6| Step: 11
Training loss: 2.646533292761692
Validation loss: 2.7268472763670544

Epoch: 6| Step: 12
Training loss: 1.3522999686432615
Validation loss: 2.6942004244227915

Epoch: 6| Step: 13
Training loss: 2.091705234774864
Validation loss: 2.6576948488942933

Epoch: 772| Step: 0
Training loss: 1.6573620068168615
Validation loss: 2.5509732147201887

Epoch: 6| Step: 1
Training loss: 2.64697981697807
Validation loss: 2.6375617550325643

Epoch: 6| Step: 2
Training loss: 1.421390157346193
Validation loss: 2.6254942819758966

Epoch: 6| Step: 3
Training loss: 1.3399801379482552
Validation loss: 2.7552871740895672

Epoch: 6| Step: 4
Training loss: 2.2308184721998794
Validation loss: 2.797845053175308

Epoch: 6| Step: 5
Training loss: 1.3821797620507987
Validation loss: 2.6662123466788925

Epoch: 6| Step: 6
Training loss: 1.3488704353278615
Validation loss: 2.7454809102694266

Epoch: 6| Step: 7
Training loss: 1.739082203331006
Validation loss: 2.602887655555628

Epoch: 6| Step: 8
Training loss: 1.5799447322788427
Validation loss: 2.6842215593386034

Epoch: 6| Step: 9
Training loss: 1.7389698507712776
Validation loss: 2.681273201542956

Epoch: 6| Step: 10
Training loss: 1.6729614435508267
Validation loss: 2.6674900520616593

Epoch: 6| Step: 11
Training loss: 1.9371236004838812
Validation loss: 2.670718740384408

Epoch: 6| Step: 12
Training loss: 1.8397270538188812
Validation loss: 2.7085705046697695

Epoch: 6| Step: 13
Training loss: 2.22792455940663
Validation loss: 2.7184934314688105

Epoch: 773| Step: 0
Training loss: 2.8805111018296166
Validation loss: 2.6838853102733946

Epoch: 6| Step: 1
Training loss: 2.2955110613357634
Validation loss: 2.578903701136355

Epoch: 6| Step: 2
Training loss: 1.3169087885508115
Validation loss: 2.6358651988936677

Epoch: 6| Step: 3
Training loss: 1.6548246332245253
Validation loss: 2.7147442108695707

Epoch: 6| Step: 4
Training loss: 1.7854557245256273
Validation loss: 2.8959536689360186

Epoch: 6| Step: 5
Training loss: 1.739525236275099
Validation loss: 2.540359576200536

Epoch: 6| Step: 6
Training loss: 1.44729956047849
Validation loss: 2.7733119253881537

Epoch: 6| Step: 7
Training loss: 1.7761854484581425
Validation loss: 2.6665693971624007

Epoch: 6| Step: 8
Training loss: 1.5415164341627445
Validation loss: 2.6419279191432232

Epoch: 6| Step: 9
Training loss: 1.8738763621286314
Validation loss: 2.758009330843516

Epoch: 6| Step: 10
Training loss: 1.7176020863718013
Validation loss: 2.611514699647722

Epoch: 6| Step: 11
Training loss: 2.275791378502875
Validation loss: 2.6137478329423685

Epoch: 6| Step: 12
Training loss: 1.9624433472832754
Validation loss: 2.641826731177998

Epoch: 6| Step: 13
Training loss: 1.8241546423550454
Validation loss: 2.749733403876307

Epoch: 774| Step: 0
Training loss: 1.9399601483921916
Validation loss: 2.7103978494333663

Epoch: 6| Step: 1
Training loss: 1.6907162569416598
Validation loss: 2.897263040675435

Epoch: 6| Step: 2
Training loss: 1.658062860422348
Validation loss: 2.7151530616864843

Epoch: 6| Step: 3
Training loss: 1.7870452702599267
Validation loss: 2.55416014203985

Epoch: 6| Step: 4
Training loss: 1.1653830699058176
Validation loss: 2.57478231267944

Epoch: 6| Step: 5
Training loss: 1.3574331598704705
Validation loss: 2.6666782062291094

Epoch: 6| Step: 6
Training loss: 0.9599007697279465
Validation loss: 2.6922473896547934

Epoch: 6| Step: 7
Training loss: 1.4991921792749487
Validation loss: 2.6022744882642606

Epoch: 6| Step: 8
Training loss: 2.425585064656317
Validation loss: 2.676861157460337

Epoch: 6| Step: 9
Training loss: 1.9485449228293865
Validation loss: 2.6059615698305025

Epoch: 6| Step: 10
Training loss: 2.215914136262854
Validation loss: 2.593570285407085

Epoch: 6| Step: 11
Training loss: 1.8183814681500545
Validation loss: 2.5724254550431764

Epoch: 6| Step: 12
Training loss: 1.7645308218404618
Validation loss: 2.633610426266637

Epoch: 6| Step: 13
Training loss: 1.4291070478958892
Validation loss: 2.566932246602437

Epoch: 775| Step: 0
Training loss: 1.3712668459056587
Validation loss: 2.5907017547064264

Epoch: 6| Step: 1
Training loss: 1.5674505011182365
Validation loss: 2.63751574917257

Epoch: 6| Step: 2
Training loss: 1.9108250233197368
Validation loss: 2.625502498715251

Epoch: 6| Step: 3
Training loss: 1.5332433998989659
Validation loss: 2.591934889484038

Epoch: 6| Step: 4
Training loss: 1.6998263270357181
Validation loss: 2.633619439744715

Epoch: 6| Step: 5
Training loss: 2.8334708086956657
Validation loss: 2.582034923643998

Epoch: 6| Step: 6
Training loss: 1.3291715649760683
Validation loss: 2.665774354411291

Epoch: 6| Step: 7
Training loss: 1.9204095975757196
Validation loss: 2.6903827542321235

Epoch: 6| Step: 8
Training loss: 2.3796525858711726
Validation loss: 2.56494257115867

Epoch: 6| Step: 9
Training loss: 1.3276692225471303
Validation loss: 2.6168427839226327

Epoch: 6| Step: 10
Training loss: 1.714199909833034
Validation loss: 2.6951975950882687

Epoch: 6| Step: 11
Training loss: 1.2134963042112954
Validation loss: 2.794630508357003

Epoch: 6| Step: 12
Training loss: 2.124301346761572
Validation loss: 2.6804592705329218

Epoch: 6| Step: 13
Training loss: 1.7200542703095325
Validation loss: 2.6727408120690366

Epoch: 776| Step: 0
Training loss: 1.542459060892317
Validation loss: 2.712394715865852

Epoch: 6| Step: 1
Training loss: 0.9739665814762746
Validation loss: 2.6088800302869757

Epoch: 6| Step: 2
Training loss: 2.336320316242332
Validation loss: 2.714448052629688

Epoch: 6| Step: 3
Training loss: 1.6654685084704872
Validation loss: 2.812391698796174

Epoch: 6| Step: 4
Training loss: 1.853409244551593
Validation loss: 2.848943249375563

Epoch: 6| Step: 5
Training loss: 1.5869082031141826
Validation loss: 2.711450881673263

Epoch: 6| Step: 6
Training loss: 1.4809029377793999
Validation loss: 2.67562726221964

Epoch: 6| Step: 7
Training loss: 1.8675546963404424
Validation loss: 2.732037550771306

Epoch: 6| Step: 8
Training loss: 1.7581701296354775
Validation loss: 2.8029410527111622

Epoch: 6| Step: 9
Training loss: 1.8029269924563123
Validation loss: 2.6731146552651395

Epoch: 6| Step: 10
Training loss: 1.239512893000336
Validation loss: 2.720167997927948

Epoch: 6| Step: 11
Training loss: 1.304958429587922
Validation loss: 2.7200671333962396

Epoch: 6| Step: 12
Training loss: 1.7362211557056249
Validation loss: 2.783687254143772

Epoch: 6| Step: 13
Training loss: 1.5777436352708558
Validation loss: 2.6332804997654127

Epoch: 777| Step: 0
Training loss: 1.4002513097952063
Validation loss: 2.700583087956178

Epoch: 6| Step: 1
Training loss: 2.0932926418617765
Validation loss: 2.75622871380847

Epoch: 6| Step: 2
Training loss: 2.077057298849764
Validation loss: 2.7112091194112145

Epoch: 6| Step: 3
Training loss: 1.957424101545643
Validation loss: 2.6595756876981316

Epoch: 6| Step: 4
Training loss: 1.2438735076309588
Validation loss: 2.798572709962187

Epoch: 6| Step: 5
Training loss: 1.5579814425184704
Validation loss: 2.7698582362869417

Epoch: 6| Step: 6
Training loss: 1.6919549135824947
Validation loss: 2.7193679361922416

Epoch: 6| Step: 7
Training loss: 1.2551481567562572
Validation loss: 2.6638683050679903

Epoch: 6| Step: 8
Training loss: 1.5986201356304797
Validation loss: 2.7280250286957175

Epoch: 6| Step: 9
Training loss: 1.2632199736710186
Validation loss: 2.599388426460966

Epoch: 6| Step: 10
Training loss: 2.792512101409291
Validation loss: 2.8430936070011548

Epoch: 6| Step: 11
Training loss: 1.6516332519158812
Validation loss: 2.657563666331374

Epoch: 6| Step: 12
Training loss: 1.995403073255855
Validation loss: 2.6718796516094434

Epoch: 6| Step: 13
Training loss: 1.9169280108972278
Validation loss: 2.6811234724834625

Epoch: 778| Step: 0
Training loss: 1.1066170379893445
Validation loss: 2.717112375076487

Epoch: 6| Step: 1
Training loss: 2.3070852447092154
Validation loss: 2.7412242213603766

Epoch: 6| Step: 2
Training loss: 1.6822459762872066
Validation loss: 2.7226580164324212

Epoch: 6| Step: 3
Training loss: 2.063827087700131
Validation loss: 2.6333029829243833

Epoch: 6| Step: 4
Training loss: 1.7375370104024577
Validation loss: 2.7588304255451375

Epoch: 6| Step: 5
Training loss: 1.5793627426825139
Validation loss: 2.609341802024191

Epoch: 6| Step: 6
Training loss: 1.7888549950878991
Validation loss: 2.5260577853498027

Epoch: 6| Step: 7
Training loss: 2.388651513225766
Validation loss: 2.634371785335005

Epoch: 6| Step: 8
Training loss: 1.3826959851849554
Validation loss: 2.645361826260965

Epoch: 6| Step: 9
Training loss: 1.842748855079147
Validation loss: 2.746636816676573

Epoch: 6| Step: 10
Training loss: 1.9963431902340765
Validation loss: 2.7010380706877704

Epoch: 6| Step: 11
Training loss: 1.674811378220965
Validation loss: 2.5557464725881602

Epoch: 6| Step: 12
Training loss: 1.864163683617629
Validation loss: 2.75523748420594

Epoch: 6| Step: 13
Training loss: 1.9490873793249117
Validation loss: 2.827653720412968

Epoch: 779| Step: 0
Training loss: 2.1043058166823783
Validation loss: 2.715135275308497

Epoch: 6| Step: 1
Training loss: 1.4219238775886058
Validation loss: 2.654258676502307

Epoch: 6| Step: 2
Training loss: 1.3153641195176216
Validation loss: 2.5543206947457207

Epoch: 6| Step: 3
Training loss: 1.6571293062210388
Validation loss: 2.4612803522280404

Epoch: 6| Step: 4
Training loss: 1.5443915265818864
Validation loss: 2.9248434012406803

Epoch: 6| Step: 5
Training loss: 3.2089935878405487
Validation loss: 2.9004748616174663

Epoch: 6| Step: 6
Training loss: 2.1310898527681297
Validation loss: 2.858915759551642

Epoch: 6| Step: 7
Training loss: 1.719345752463146
Validation loss: 2.710988440641855

Epoch: 6| Step: 8
Training loss: 1.6787706578646033
Validation loss: 2.8098450470345893

Epoch: 6| Step: 9
Training loss: 1.1592957359013765
Validation loss: 2.8811130280338277

Epoch: 6| Step: 10
Training loss: 1.248522075514436
Validation loss: 2.7804323750313715

Epoch: 6| Step: 11
Training loss: 2.1602049230572615
Validation loss: 2.718557807146104

Epoch: 6| Step: 12
Training loss: 1.7646037160994041
Validation loss: 2.7135330999010567

Epoch: 6| Step: 13
Training loss: 1.488345007144018
Validation loss: 2.739423946437191

Epoch: 780| Step: 0
Training loss: 1.679251041927131
Validation loss: 2.5632263720295327

Epoch: 6| Step: 1
Training loss: 1.8104382331128417
Validation loss: 2.522532377036172

Epoch: 6| Step: 2
Training loss: 1.7086458928193224
Validation loss: 2.6959127843482933

Epoch: 6| Step: 3
Training loss: 1.7566833938777027
Validation loss: 2.6145962578088366

Epoch: 6| Step: 4
Training loss: 1.4370252405762478
Validation loss: 2.638671101634329

Epoch: 6| Step: 5
Training loss: 1.8451583138957544
Validation loss: 2.67792533815349

Epoch: 6| Step: 6
Training loss: 1.68019004223732
Validation loss: 2.5971813176382716

Epoch: 6| Step: 7
Training loss: 1.3368457584473468
Validation loss: 2.767000731596136

Epoch: 6| Step: 8
Training loss: 1.204943385080303
Validation loss: 2.7948136778261112

Epoch: 6| Step: 9
Training loss: 2.3866747962912656
Validation loss: 2.6645369992025665

Epoch: 6| Step: 10
Training loss: 1.5737658433669652
Validation loss: 2.806583045176271

Epoch: 6| Step: 11
Training loss: 1.9241121498778644
Validation loss: 2.763523669160464

Epoch: 6| Step: 12
Training loss: 2.53583177873821
Validation loss: 2.625442791776684

Epoch: 6| Step: 13
Training loss: 2.274658609283565
Validation loss: 2.7374735584219136

Epoch: 781| Step: 0
Training loss: 2.085929727718432
Validation loss: 2.813272896398261

Epoch: 6| Step: 1
Training loss: 1.2868669712877792
Validation loss: 2.5672902294727895

Epoch: 6| Step: 2
Training loss: 1.7757781458775939
Validation loss: 2.7762452193119933

Epoch: 6| Step: 3
Training loss: 1.6949393569315503
Validation loss: 2.7460260596006636

Epoch: 6| Step: 4
Training loss: 1.4132876301669401
Validation loss: 2.689324573531782

Epoch: 6| Step: 5
Training loss: 1.514825196961634
Validation loss: 2.8164005390704583

Epoch: 6| Step: 6
Training loss: 1.9220216276478255
Validation loss: 2.6878955566183227

Epoch: 6| Step: 7
Training loss: 1.5734031211332322
Validation loss: 2.6113936674756397

Epoch: 6| Step: 8
Training loss: 2.657113507104322
Validation loss: 2.6477293320730877

Epoch: 6| Step: 9
Training loss: 1.4858284510120245
Validation loss: 2.7136973671624105

Epoch: 6| Step: 10
Training loss: 1.6359787317306569
Validation loss: 2.703074301915761

Epoch: 6| Step: 11
Training loss: 1.466628876473787
Validation loss: 2.666150549451955

Epoch: 6| Step: 12
Training loss: 1.4758935452453787
Validation loss: 2.602368574663491

Epoch: 6| Step: 13
Training loss: 1.2774756593867542
Validation loss: 2.581698516316328

Epoch: 782| Step: 0
Training loss: 1.8368778498972422
Validation loss: 2.739637573583627

Epoch: 6| Step: 1
Training loss: 1.5280792728751587
Validation loss: 2.668995838581458

Epoch: 6| Step: 2
Training loss: 1.4795835561205175
Validation loss: 2.8125200815520732

Epoch: 6| Step: 3
Training loss: 1.8959007111478074
Validation loss: 2.790805739610331

Epoch: 6| Step: 4
Training loss: 1.7538841602998911
Validation loss: 2.76225212001041

Epoch: 6| Step: 5
Training loss: 1.6704748833054612
Validation loss: 2.687364163200837

Epoch: 6| Step: 6
Training loss: 2.0311275738722063
Validation loss: 2.877978113291618

Epoch: 6| Step: 7
Training loss: 1.8045886124109658
Validation loss: 2.7357317158952346

Epoch: 6| Step: 8
Training loss: 1.697073588684762
Validation loss: 2.777880815386097

Epoch: 6| Step: 9
Training loss: 2.677545698044836
Validation loss: 2.7287351362143477

Epoch: 6| Step: 10
Training loss: 1.2540271736376687
Validation loss: 2.667810393474811

Epoch: 6| Step: 11
Training loss: 1.4038560623767917
Validation loss: 2.623823809668908

Epoch: 6| Step: 12
Training loss: 2.418195328704055
Validation loss: 2.7591665349067775

Epoch: 6| Step: 13
Training loss: 1.3196568412932101
Validation loss: 2.783415689171656

Epoch: 783| Step: 0
Training loss: 1.3768359844621076
Validation loss: 2.6579516274080266

Epoch: 6| Step: 1
Training loss: 1.4954953104836501
Validation loss: 2.6584719259131613

Epoch: 6| Step: 2
Training loss: 1.407319700506352
Validation loss: 2.6883343467219443

Epoch: 6| Step: 3
Training loss: 1.9789374637062207
Validation loss: 2.7499649310369665

Epoch: 6| Step: 4
Training loss: 1.803020880220162
Validation loss: 2.6631110088435435

Epoch: 6| Step: 5
Training loss: 1.2194868941124826
Validation loss: 2.592435463405357

Epoch: 6| Step: 6
Training loss: 2.7264486469446423
Validation loss: 2.49650598852958

Epoch: 6| Step: 7
Training loss: 2.076408193350382
Validation loss: 2.582491739262222

Epoch: 6| Step: 8
Training loss: 1.487028781399407
Validation loss: 2.6522585485911034

Epoch: 6| Step: 9
Training loss: 2.0719713007438005
Validation loss: 2.596587782285849

Epoch: 6| Step: 10
Training loss: 2.0886381004945895
Validation loss: 2.7882775194491387

Epoch: 6| Step: 11
Training loss: 1.608375461138636
Validation loss: 2.614620994025688

Epoch: 6| Step: 12
Training loss: 1.3737269490384638
Validation loss: 2.7114572239903545

Epoch: 6| Step: 13
Training loss: 1.1795089788705582
Validation loss: 2.719486678490039

Epoch: 784| Step: 0
Training loss: 1.657935023117099
Validation loss: 2.838758963856679

Epoch: 6| Step: 1
Training loss: 1.2875967304224962
Validation loss: 2.719392489117287

Epoch: 6| Step: 2
Training loss: 1.5108872130111743
Validation loss: 2.6246699630142665

Epoch: 6| Step: 3
Training loss: 1.40739911071849
Validation loss: 2.7339806769575667

Epoch: 6| Step: 4
Training loss: 2.1098885370255642
Validation loss: 2.787778947887994

Epoch: 6| Step: 5
Training loss: 1.2895980184989453
Validation loss: 2.7801121754005305

Epoch: 6| Step: 6
Training loss: 1.6936361577249754
Validation loss: 2.7573638089002217

Epoch: 6| Step: 7
Training loss: 2.1600628741261727
Validation loss: 2.7974763224854833

Epoch: 6| Step: 8
Training loss: 1.468349483341998
Validation loss: 2.787940334800068

Epoch: 6| Step: 9
Training loss: 2.5375962939101835
Validation loss: 2.765246622703687

Epoch: 6| Step: 10
Training loss: 2.234237773389294
Validation loss: 2.6923819917182916

Epoch: 6| Step: 11
Training loss: 1.7818142181380707
Validation loss: 2.735565215746235

Epoch: 6| Step: 12
Training loss: 1.8392345934574272
Validation loss: 2.6661984241826047

Epoch: 6| Step: 13
Training loss: 1.8100744657847065
Validation loss: 2.6306929648777535

Epoch: 785| Step: 0
Training loss: 2.012599359748812
Validation loss: 2.6818871194330085

Epoch: 6| Step: 1
Training loss: 1.6218631251493945
Validation loss: 2.6354878977054494

Epoch: 6| Step: 2
Training loss: 1.8061136002831288
Validation loss: 2.676145656949647

Epoch: 6| Step: 3
Training loss: 2.3407720338810463
Validation loss: 2.7851376086674358

Epoch: 6| Step: 4
Training loss: 1.784312910880355
Validation loss: 2.6998230000310817

Epoch: 6| Step: 5
Training loss: 1.6548497020552084
Validation loss: 2.587778717116553

Epoch: 6| Step: 6
Training loss: 1.195094069924212
Validation loss: 2.639494619345184

Epoch: 6| Step: 7
Training loss: 1.1994098921049363
Validation loss: 2.6643521890536035

Epoch: 6| Step: 8
Training loss: 2.551147247742295
Validation loss: 2.683119880620918

Epoch: 6| Step: 9
Training loss: 1.995262495473286
Validation loss: 2.665019602132556

Epoch: 6| Step: 10
Training loss: 1.798735145046245
Validation loss: 2.6685112955390005

Epoch: 6| Step: 11
Training loss: 2.197270616313775
Validation loss: 2.8432312868352843

Epoch: 6| Step: 12
Training loss: 1.9420924365224435
Validation loss: 2.5766602502725022

Epoch: 6| Step: 13
Training loss: 2.012591304247976
Validation loss: 2.6660512087706745

Epoch: 786| Step: 0
Training loss: 1.863614162558121
Validation loss: 2.742597046110791

Epoch: 6| Step: 1
Training loss: 2.045770245088856
Validation loss: 2.87517875108567

Epoch: 6| Step: 2
Training loss: 2.772895437647042
Validation loss: 2.777864667770863

Epoch: 6| Step: 3
Training loss: 1.76164499200331
Validation loss: 2.6942225895144367

Epoch: 6| Step: 4
Training loss: 1.6632338058850717
Validation loss: 2.8231854175574944

Epoch: 6| Step: 5
Training loss: 1.4262423671080195
Validation loss: 2.729406879007748

Epoch: 6| Step: 6
Training loss: 1.0170681017576828
Validation loss: 2.6073700318408317

Epoch: 6| Step: 7
Training loss: 1.0511019192612496
Validation loss: 2.605399470422828

Epoch: 6| Step: 8
Training loss: 2.013061549345334
Validation loss: 2.8074845197880514

Epoch: 6| Step: 9
Training loss: 2.260713080266185
Validation loss: 2.715334625260309

Epoch: 6| Step: 10
Training loss: 1.747069493693911
Validation loss: 2.818852557802293

Epoch: 6| Step: 11
Training loss: 1.8907634589828277
Validation loss: 2.830754873634475

Epoch: 6| Step: 12
Training loss: 1.1429536642459663
Validation loss: 2.895155471380929

Epoch: 6| Step: 13
Training loss: 1.4184503919541263
Validation loss: 2.591481553753647

Epoch: 787| Step: 0
Training loss: 1.8857103263103319
Validation loss: 2.6583250758195556

Epoch: 6| Step: 1
Training loss: 0.8464769518869585
Validation loss: 2.7838484528070433

Epoch: 6| Step: 2
Training loss: 1.081641612495035
Validation loss: 2.7144229482823126

Epoch: 6| Step: 3
Training loss: 1.672125111347978
Validation loss: 2.6512175593373435

Epoch: 6| Step: 4
Training loss: 1.7238971280607165
Validation loss: 2.7203174646314863

Epoch: 6| Step: 5
Training loss: 1.3514143140404276
Validation loss: 2.6374884769180396

Epoch: 6| Step: 6
Training loss: 1.670951088856678
Validation loss: 2.567019385239015

Epoch: 6| Step: 7
Training loss: 1.3439937636594044
Validation loss: 2.653092158488842

Epoch: 6| Step: 8
Training loss: 2.3158816793784736
Validation loss: 2.6915421875967196

Epoch: 6| Step: 9
Training loss: 1.7717537974729625
Validation loss: 2.5392631758149555

Epoch: 6| Step: 10
Training loss: 2.100543941714674
Validation loss: 2.7908893049904564

Epoch: 6| Step: 11
Training loss: 1.3625098289345206
Validation loss: 2.8305022664240087

Epoch: 6| Step: 12
Training loss: 1.856264991571275
Validation loss: 2.7007190192842736

Epoch: 6| Step: 13
Training loss: 2.1621727800591835
Validation loss: 2.6736220768472503

Epoch: 788| Step: 0
Training loss: 1.5111827442232089
Validation loss: 2.686680095630598

Epoch: 6| Step: 1
Training loss: 1.5274726832767709
Validation loss: 2.65673983145444

Epoch: 6| Step: 2
Training loss: 1.773809116768234
Validation loss: 2.7652876870536933

Epoch: 6| Step: 3
Training loss: 1.6577454059912835
Validation loss: 2.586070807116225

Epoch: 6| Step: 4
Training loss: 1.2019997325808058
Validation loss: 2.687045756034462

Epoch: 6| Step: 5
Training loss: 1.4954653383789431
Validation loss: 2.759174694566039

Epoch: 6| Step: 6
Training loss: 1.6237105608959947
Validation loss: 2.821047165023944

Epoch: 6| Step: 7
Training loss: 1.5054300094394701
Validation loss: 2.7394620710324156

Epoch: 6| Step: 8
Training loss: 1.7313179360842088
Validation loss: 2.752074631824117

Epoch: 6| Step: 9
Training loss: 2.0246901004219344
Validation loss: 2.6990361217865857

Epoch: 6| Step: 10
Training loss: 1.7198402414869216
Validation loss: 2.5968756085705786

Epoch: 6| Step: 11
Training loss: 3.347440590249366
Validation loss: 2.653268045344221

Epoch: 6| Step: 12
Training loss: 2.085743984432752
Validation loss: 2.633848261952752

Epoch: 6| Step: 13
Training loss: 1.6818605781994365
Validation loss: 2.6482508315858366

Epoch: 789| Step: 0
Training loss: 1.7687202262394401
Validation loss: 2.7430019103596015

Epoch: 6| Step: 1
Training loss: 1.3069587628135049
Validation loss: 2.5277947943594463

Epoch: 6| Step: 2
Training loss: 1.378384758998191
Validation loss: 2.6008089104809544

Epoch: 6| Step: 3
Training loss: 1.4993978722351535
Validation loss: 2.720634824545389

Epoch: 6| Step: 4
Training loss: 1.5883353010701136
Validation loss: 2.647601629113468

Epoch: 6| Step: 5
Training loss: 1.6258126207704395
Validation loss: 2.571354969025721

Epoch: 6| Step: 6
Training loss: 1.6282861933657404
Validation loss: 2.58046874070104

Epoch: 6| Step: 7
Training loss: 2.584722965528939
Validation loss: 2.675050886067133

Epoch: 6| Step: 8
Training loss: 0.85023324795478
Validation loss: 2.7615410980157744

Epoch: 6| Step: 9
Training loss: 2.564078426369737
Validation loss: 2.775747738489956

Epoch: 6| Step: 10
Training loss: 2.083173427802869
Validation loss: 2.552904450896691

Epoch: 6| Step: 11
Training loss: 2.1987864745358534
Validation loss: 2.6794869637186447

Epoch: 6| Step: 12
Training loss: 1.9621419057516927
Validation loss: 2.655944181206346

Epoch: 6| Step: 13
Training loss: 1.3683692402528962
Validation loss: 2.7310763900041946

Epoch: 790| Step: 0
Training loss: 1.1903667480253228
Validation loss: 2.899756161216039

Epoch: 6| Step: 1
Training loss: 2.178711265793061
Validation loss: 2.622199064785972

Epoch: 6| Step: 2
Training loss: 1.9466011038391124
Validation loss: 2.5912118831697573

Epoch: 6| Step: 3
Training loss: 1.1431243894814205
Validation loss: 2.7708740071017592

Epoch: 6| Step: 4
Training loss: 1.520687104950897
Validation loss: 2.5361622279586427

Epoch: 6| Step: 5
Training loss: 0.9300888541546836
Validation loss: 2.8549212952245138

Epoch: 6| Step: 6
Training loss: 1.3329587151844233
Validation loss: 2.6545034371642093

Epoch: 6| Step: 7
Training loss: 1.5566516526428709
Validation loss: 2.733642917026503

Epoch: 6| Step: 8
Training loss: 1.722648291883014
Validation loss: 2.6462327779815293

Epoch: 6| Step: 9
Training loss: 1.5437537405609651
Validation loss: 2.600296793130041

Epoch: 6| Step: 10
Training loss: 1.8213057530024441
Validation loss: 2.745208415942351

Epoch: 6| Step: 11
Training loss: 2.7343068141610014
Validation loss: 2.644253903130089

Epoch: 6| Step: 12
Training loss: 1.8254607259202926
Validation loss: 2.5468714724280423

Epoch: 6| Step: 13
Training loss: 0.7336755627724385
Validation loss: 2.839702404475769

Epoch: 791| Step: 0
Training loss: 1.6214273500167826
Validation loss: 2.560835923524134

Epoch: 6| Step: 1
Training loss: 2.390852375063275
Validation loss: 2.641333818672613

Epoch: 6| Step: 2
Training loss: 1.4891777642421282
Validation loss: 2.633497477991081

Epoch: 6| Step: 3
Training loss: 1.5274455239029676
Validation loss: 2.6231335471159185

Epoch: 6| Step: 4
Training loss: 1.565102203249427
Validation loss: 2.5421906386227975

Epoch: 6| Step: 5
Training loss: 2.086231568142498
Validation loss: 2.678475716712533

Epoch: 6| Step: 6
Training loss: 1.2555616153347626
Validation loss: 2.700184065554242

Epoch: 6| Step: 7
Training loss: 2.5150305004052633
Validation loss: 2.706288629973402

Epoch: 6| Step: 8
Training loss: 1.7018422186724182
Validation loss: 2.6392819165532213

Epoch: 6| Step: 9
Training loss: 1.8052673069000564
Validation loss: 2.678932026285086

Epoch: 6| Step: 10
Training loss: 1.5899065834769506
Validation loss: 2.6843433008327042

Epoch: 6| Step: 11
Training loss: 1.4346706908381108
Validation loss: 2.6223436852991413

Epoch: 6| Step: 12
Training loss: 1.6152601320733906
Validation loss: 2.671286928352911

Epoch: 6| Step: 13
Training loss: 1.749892844597941
Validation loss: 2.846024914206955

Epoch: 792| Step: 0
Training loss: 1.858909292161666
Validation loss: 2.55630263483892

Epoch: 6| Step: 1
Training loss: 1.1193830350739757
Validation loss: 2.5881989024071936

Epoch: 6| Step: 2
Training loss: 1.6104350626471773
Validation loss: 2.618996406122919

Epoch: 6| Step: 3
Training loss: 2.797961146686841
Validation loss: 2.703607516494379

Epoch: 6| Step: 4
Training loss: 1.5901746850652028
Validation loss: 2.7974420567176903

Epoch: 6| Step: 5
Training loss: 2.1148001523662328
Validation loss: 2.657671098145857

Epoch: 6| Step: 6
Training loss: 1.4860718514950029
Validation loss: 2.706219011775549

Epoch: 6| Step: 7
Training loss: 1.6017015350282997
Validation loss: 2.6322464174763547

Epoch: 6| Step: 8
Training loss: 1.7656424192396398
Validation loss: 2.7647254166287807

Epoch: 6| Step: 9
Training loss: 1.633249178813948
Validation loss: 2.7715069732754114

Epoch: 6| Step: 10
Training loss: 1.7792235777043954
Validation loss: 2.8725933061774778

Epoch: 6| Step: 11
Training loss: 1.3289841958161832
Validation loss: 2.955053783536877

Epoch: 6| Step: 12
Training loss: 2.2255148045620157
Validation loss: 2.747011243251618

Epoch: 6| Step: 13
Training loss: 1.5066331589750925
Validation loss: 2.8562372964850393

Epoch: 793| Step: 0
Training loss: 2.723954316835864
Validation loss: 2.7665680411346227

Epoch: 6| Step: 1
Training loss: 1.5422528501383181
Validation loss: 2.7319906435213683

Epoch: 6| Step: 2
Training loss: 1.8693564359150638
Validation loss: 2.7437635983478104

Epoch: 6| Step: 3
Training loss: 1.9157090559124335
Validation loss: 2.7123221731004166

Epoch: 6| Step: 4
Training loss: 1.6351592798838315
Validation loss: 2.6480163249974034

Epoch: 6| Step: 5
Training loss: 2.21793629944037
Validation loss: 2.764751411529857

Epoch: 6| Step: 6
Training loss: 1.3496977891682165
Validation loss: 2.5532113417457833

Epoch: 6| Step: 7
Training loss: 1.4352038745734266
Validation loss: 2.7130020213111234

Epoch: 6| Step: 8
Training loss: 1.260749562756797
Validation loss: 2.668341096220344

Epoch: 6| Step: 9
Training loss: 1.8073450643106415
Validation loss: 2.6458972980989377

Epoch: 6| Step: 10
Training loss: 1.5655857895987386
Validation loss: 2.655012220916885

Epoch: 6| Step: 11
Training loss: 1.832042051499008
Validation loss: 2.764074611361935

Epoch: 6| Step: 12
Training loss: 1.3731848266236626
Validation loss: 2.6985774546873897

Epoch: 6| Step: 13
Training loss: 1.4598244899919306
Validation loss: 2.6384706611219304

Epoch: 794| Step: 0
Training loss: 1.8864138023081836
Validation loss: 2.4994500129501276

Epoch: 6| Step: 1
Training loss: 1.8422401194220128
Validation loss: 2.766536078933702

Epoch: 6| Step: 2
Training loss: 1.2923293362213681
Validation loss: 2.7394444944237106

Epoch: 6| Step: 3
Training loss: 1.5678296554444973
Validation loss: 2.8091454968102694

Epoch: 6| Step: 4
Training loss: 2.6511008225431683
Validation loss: 2.6182262844112905

Epoch: 6| Step: 5
Training loss: 1.4305299038526424
Validation loss: 2.726268024305161

Epoch: 6| Step: 6
Training loss: 1.4054421541624897
Validation loss: 2.5744552870866055

Epoch: 6| Step: 7
Training loss: 1.7235701509059602
Validation loss: 2.7430369412373983

Epoch: 6| Step: 8
Training loss: 1.4480628984921553
Validation loss: 2.4953119642815613

Epoch: 6| Step: 9
Training loss: 1.4341080494054081
Validation loss: 2.676377818077877

Epoch: 6| Step: 10
Training loss: 1.635391753507081
Validation loss: 2.8216003544507235

Epoch: 6| Step: 11
Training loss: 2.0353202534086736
Validation loss: 2.699203884137897

Epoch: 6| Step: 12
Training loss: 1.6744192141354977
Validation loss: 2.716274460688628

Epoch: 6| Step: 13
Training loss: 1.5887759510144823
Validation loss: 2.5119811081635395

Epoch: 795| Step: 0
Training loss: 1.4187705555237575
Validation loss: 2.6495855627653073

Epoch: 6| Step: 1
Training loss: 0.9872683132576059
Validation loss: 2.6594117940895075

Epoch: 6| Step: 2
Training loss: 1.6640048308073128
Validation loss: 2.5278601351475998

Epoch: 6| Step: 3
Training loss: 1.4593925262640384
Validation loss: 2.881379063338004

Epoch: 6| Step: 4
Training loss: 1.1683627583548157
Validation loss: 2.701264087909627

Epoch: 6| Step: 5
Training loss: 1.4152201766318722
Validation loss: 2.662719778884133

Epoch: 6| Step: 6
Training loss: 1.389395180717381
Validation loss: 2.783918279026621

Epoch: 6| Step: 7
Training loss: 2.155386599848368
Validation loss: 2.7475677335369126

Epoch: 6| Step: 8
Training loss: 2.575208644376753
Validation loss: 2.6375017233102622

Epoch: 6| Step: 9
Training loss: 1.7360873318209273
Validation loss: 2.7332869495274954

Epoch: 6| Step: 10
Training loss: 1.5150629948275742
Validation loss: 2.631714247190862

Epoch: 6| Step: 11
Training loss: 1.6612036419120124
Validation loss: 2.7062003306682163

Epoch: 6| Step: 12
Training loss: 1.7318637297148993
Validation loss: 2.4852262532123772

Epoch: 6| Step: 13
Training loss: 1.3412173156453302
Validation loss: 2.6816051840416613

Epoch: 796| Step: 0
Training loss: 2.3449750623210717
Validation loss: 2.5879704387830427

Epoch: 6| Step: 1
Training loss: 1.8493228033756586
Validation loss: 2.7882904797782886

Epoch: 6| Step: 2
Training loss: 1.9186159739452566
Validation loss: 2.585981847907411

Epoch: 6| Step: 3
Training loss: 1.790375606618527
Validation loss: 2.7684256040073767

Epoch: 6| Step: 4
Training loss: 1.1144972200491639
Validation loss: 2.8033728766755885

Epoch: 6| Step: 5
Training loss: 2.782947322400367
Validation loss: 2.59193341179252

Epoch: 6| Step: 6
Training loss: 1.8542117709842352
Validation loss: 2.707669570712643

Epoch: 6| Step: 7
Training loss: 1.4681704574959251
Validation loss: 2.7410019121011144

Epoch: 6| Step: 8
Training loss: 1.703245666149006
Validation loss: 2.7802773637232163

Epoch: 6| Step: 9
Training loss: 1.7827127707936112
Validation loss: 2.5250159737556768

Epoch: 6| Step: 10
Training loss: 2.1284469248969473
Validation loss: 2.727937437664604

Epoch: 6| Step: 11
Training loss: 0.9704169421416029
Validation loss: 2.734651292474749

Epoch: 6| Step: 12
Training loss: 1.6572636795158406
Validation loss: 2.706645262174031

Epoch: 6| Step: 13
Training loss: 1.3989193475119288
Validation loss: 2.7054141152143174

Epoch: 797| Step: 0
Training loss: 1.7031222002198891
Validation loss: 2.6230618040123796

Epoch: 6| Step: 1
Training loss: 1.5534923310963813
Validation loss: 2.7601609157807974

Epoch: 6| Step: 2
Training loss: 1.3799118395301522
Validation loss: 2.7349237063163514

Epoch: 6| Step: 3
Training loss: 1.7338019446723463
Validation loss: 2.7951662874510568

Epoch: 6| Step: 4
Training loss: 2.2004348888580547
Validation loss: 2.6705721422995885

Epoch: 6| Step: 5
Training loss: 2.3707258011265657
Validation loss: 2.525893722953191

Epoch: 6| Step: 6
Training loss: 1.5895256455312428
Validation loss: 2.6236311433983786

Epoch: 6| Step: 7
Training loss: 1.8687349554878843
Validation loss: 2.5997050745174066

Epoch: 6| Step: 8
Training loss: 2.073583243335318
Validation loss: 2.6844513799185963

Epoch: 6| Step: 9
Training loss: 0.8830912327233269
Validation loss: 2.6406913856258005

Epoch: 6| Step: 10
Training loss: 1.818002438366286
Validation loss: 2.781519866714738

Epoch: 6| Step: 11
Training loss: 2.486119167899699
Validation loss: 2.619806653697534

Epoch: 6| Step: 12
Training loss: 1.4821669368133819
Validation loss: 2.79343617804155

Epoch: 6| Step: 13
Training loss: 1.0775671911863784
Validation loss: 2.793144924425462

Epoch: 798| Step: 0
Training loss: 1.450955073102116
Validation loss: 2.6444794659212745

Epoch: 6| Step: 1
Training loss: 1.6073599487093628
Validation loss: 2.69862744116949

Epoch: 6| Step: 2
Training loss: 1.682358715819503
Validation loss: 2.5836235886288184

Epoch: 6| Step: 3
Training loss: 1.6778801709242996
Validation loss: 2.732643903777985

Epoch: 6| Step: 4
Training loss: 2.525502968728438
Validation loss: 2.701007019668392

Epoch: 6| Step: 5
Training loss: 2.1794706940926485
Validation loss: 2.6951236439330892

Epoch: 6| Step: 6
Training loss: 1.51463442807633
Validation loss: 2.699029421637839

Epoch: 6| Step: 7
Training loss: 2.566464125911099
Validation loss: 2.621707674970248

Epoch: 6| Step: 8
Training loss: 1.537805809063804
Validation loss: 2.709208574376079

Epoch: 6| Step: 9
Training loss: 1.8989716080707124
Validation loss: 2.7148070181740698

Epoch: 6| Step: 10
Training loss: 1.265427515140205
Validation loss: 2.688673215006246

Epoch: 6| Step: 11
Training loss: 1.0944929596808257
Validation loss: 2.670187227027891

Epoch: 6| Step: 12
Training loss: 2.050513491634771
Validation loss: 2.6577410687741274

Epoch: 6| Step: 13
Training loss: 1.475948387685756
Validation loss: 2.6071795499168666

Epoch: 799| Step: 0
Training loss: 1.0291258581207268
Validation loss: 2.6717048134580823

Epoch: 6| Step: 1
Training loss: 1.7097443901557885
Validation loss: 2.7279694715023495

Epoch: 6| Step: 2
Training loss: 1.6132487369983457
Validation loss: 2.624500628551681

Epoch: 6| Step: 3
Training loss: 2.122846971240665
Validation loss: 2.6982468905656276

Epoch: 6| Step: 4
Training loss: 1.8495288094171483
Validation loss: 2.7141008343987996

Epoch: 6| Step: 5
Training loss: 1.6202711844993634
Validation loss: 2.6092140128934656

Epoch: 6| Step: 6
Training loss: 2.3390208024644785
Validation loss: 2.6223684579280024

Epoch: 6| Step: 7
Training loss: 1.7652341697036007
Validation loss: 2.5889821675036044

Epoch: 6| Step: 8
Training loss: 1.3290782424708392
Validation loss: 2.6139191223130718

Epoch: 6| Step: 9
Training loss: 1.575999424232339
Validation loss: 2.6770161142708777

Epoch: 6| Step: 10
Training loss: 1.7290429986446576
Validation loss: 2.7175377573743296

Epoch: 6| Step: 11
Training loss: 1.707512410176029
Validation loss: 2.801461111629236

Epoch: 6| Step: 12
Training loss: 1.516837117115417
Validation loss: 2.5819831565535742

Epoch: 6| Step: 13
Training loss: 1.939664124289131
Validation loss: 2.6265048046621935

Epoch: 800| Step: 0
Training loss: 2.6495072896424823
Validation loss: 2.6938709667084484

Epoch: 6| Step: 1
Training loss: 1.4801827106589218
Validation loss: 2.6670102050697477

Epoch: 6| Step: 2
Training loss: 1.599881662522553
Validation loss: 2.716940194824482

Epoch: 6| Step: 3
Training loss: 1.3951068619847053
Validation loss: 2.7177935115187273

Epoch: 6| Step: 4
Training loss: 1.877994688975144
Validation loss: 2.663868048595003

Epoch: 6| Step: 5
Training loss: 1.7250745066156545
Validation loss: 2.557322077132489

Epoch: 6| Step: 6
Training loss: 1.200343148521274
Validation loss: 2.566872173030629

Epoch: 6| Step: 7
Training loss: 1.5728905614577111
Validation loss: 2.62543081448742

Epoch: 6| Step: 8
Training loss: 2.2882324380249677
Validation loss: 2.6784080469997207

Epoch: 6| Step: 9
Training loss: 1.905457441320641
Validation loss: 2.659156129332661

Epoch: 6| Step: 10
Training loss: 1.5487967219783048
Validation loss: 2.8321721682285537

Epoch: 6| Step: 11
Training loss: 1.9117255444205221
Validation loss: 2.6787530738427403

Epoch: 6| Step: 12
Training loss: 1.6894226424273158
Validation loss: 2.7042602586826923

Epoch: 6| Step: 13
Training loss: 1.3482059850229704
Validation loss: 2.867554996393401

Testing loss: 2.9046888992007975
