Epoch: 1| Step: 0
Training loss: 5.470979421407813
Validation loss: 6.480491324190243

Epoch: 5| Step: 1
Training loss: 5.771328056787493
Validation loss: 6.475635882405553

Epoch: 5| Step: 2
Training loss: 6.800675796138181
Validation loss: 6.47439379879095

Epoch: 5| Step: 3
Training loss: 6.465901065351531
Validation loss: 6.471429592533266

Epoch: 5| Step: 4
Training loss: 5.873199836405992
Validation loss: 6.470026365194322

Epoch: 5| Step: 5
Training loss: 6.162409610356208
Validation loss: 6.4640427687578494

Epoch: 5| Step: 6
Training loss: 6.8416435448847865
Validation loss: 6.462408972419796

Epoch: 5| Step: 7
Training loss: 7.235453514959423
Validation loss: 6.457448134820934

Epoch: 5| Step: 8
Training loss: 6.580091169009778
Validation loss: 6.454907389122189

Epoch: 5| Step: 9
Training loss: 7.490556493644024
Validation loss: 6.452593689887882

Epoch: 5| Step: 10
Training loss: 6.134101489242109
Validation loss: 6.447390652086411

Epoch: 2| Step: 0
Training loss: 6.775689020346156
Validation loss: 6.444405878215879

Epoch: 5| Step: 1
Training loss: 6.714796597602042
Validation loss: 6.439318812455587

Epoch: 5| Step: 2
Training loss: 6.801245395832014
Validation loss: 6.43652774148362

Epoch: 5| Step: 3
Training loss: 5.352479998049184
Validation loss: 6.43402097672842

Epoch: 5| Step: 4
Training loss: 6.65037083559831
Validation loss: 6.428050411614242

Epoch: 5| Step: 5
Training loss: 6.261124742762565
Validation loss: 6.426312833311283

Epoch: 5| Step: 6
Training loss: 6.03837330822405
Validation loss: 6.423467666308853

Epoch: 5| Step: 7
Training loss: 7.591917217096746
Validation loss: 6.41984094232511

Epoch: 5| Step: 8
Training loss: 6.594623525891541
Validation loss: 6.412476321887525

Epoch: 5| Step: 9
Training loss: 5.31622776065411
Validation loss: 6.4120111867275495

Epoch: 5| Step: 10
Training loss: 6.323113913394853
Validation loss: 6.407341242224335

Epoch: 3| Step: 0
Training loss: 6.692834740618834
Validation loss: 6.403071967671105

Epoch: 5| Step: 1
Training loss: 6.567288640704932
Validation loss: 6.402577118217734

Epoch: 5| Step: 2
Training loss: 5.260756236783959
Validation loss: 6.398133022948973

Epoch: 5| Step: 3
Training loss: 6.740383503584245
Validation loss: 6.393061942881369

Epoch: 5| Step: 4
Training loss: 7.24882550427352
Validation loss: 6.3882030450053975

Epoch: 5| Step: 5
Training loss: 6.1997510060179915
Validation loss: 6.3856749910352235

Epoch: 5| Step: 6
Training loss: 6.764529379568898
Validation loss: 6.380869293900747

Epoch: 5| Step: 7
Training loss: 6.268292627355411
Validation loss: 6.377997298381939

Epoch: 5| Step: 8
Training loss: 5.821533075141866
Validation loss: 6.375138466457453

Epoch: 5| Step: 9
Training loss: 6.9356637535033485
Validation loss: 6.372095007940702

Epoch: 5| Step: 10
Training loss: 5.381235453622543
Validation loss: 6.369308958755999

Epoch: 4| Step: 0
Training loss: 5.703612591528135
Validation loss: 6.362950115680151

Epoch: 5| Step: 1
Training loss: 6.4752995602158245
Validation loss: 6.356766344412749

Epoch: 5| Step: 2
Training loss: 7.2881764223957175
Validation loss: 6.358008043558005

Epoch: 5| Step: 3
Training loss: 6.305678203508419
Validation loss: 6.351792603270983

Epoch: 5| Step: 4
Training loss: 5.5178603702699744
Validation loss: 6.348853969664277

Epoch: 5| Step: 5
Training loss: 6.730734564723357
Validation loss: 6.346270533454945

Epoch: 5| Step: 6
Training loss: 6.199386738626539
Validation loss: 6.339133475293739

Epoch: 5| Step: 7
Training loss: 6.4939893661895995
Validation loss: 6.33681727482215

Epoch: 5| Step: 8
Training loss: 5.9892612359612345
Validation loss: 6.33152986030707

Epoch: 5| Step: 9
Training loss: 6.346062900985281
Validation loss: 6.328857784566006

Epoch: 5| Step: 10
Training loss: 6.694373190655828
Validation loss: 6.323024158165848

Epoch: 5| Step: 0
Training loss: 7.830437902918638
Validation loss: 6.319984141036926

Epoch: 5| Step: 1
Training loss: 5.868966108574299
Validation loss: 6.31423653721068

Epoch: 5| Step: 2
Training loss: 6.4293688930402
Validation loss: 6.312515465079733

Epoch: 5| Step: 3
Training loss: 6.2497647050435585
Validation loss: 6.3075266711875795

Epoch: 5| Step: 4
Training loss: 7.0594962154821115
Validation loss: 6.304662500673903

Epoch: 5| Step: 5
Training loss: 5.794454475378707
Validation loss: 6.298678181758587

Epoch: 5| Step: 6
Training loss: 5.998922887124326
Validation loss: 6.296673480931726

Epoch: 5| Step: 7
Training loss: 6.286632452204545
Validation loss: 6.289166442749953

Epoch: 5| Step: 8
Training loss: 5.416004531689414
Validation loss: 6.287470990260851

Epoch: 5| Step: 9
Training loss: 6.79546501179739
Validation loss: 6.2814976718825974

Epoch: 5| Step: 10
Training loss: 4.9926597121150325
Validation loss: 6.274601474224793

Epoch: 6| Step: 0
Training loss: 5.017693684198674
Validation loss: 6.272818699727526

Epoch: 5| Step: 1
Training loss: 6.1232200683240965
Validation loss: 6.268901184560234

Epoch: 5| Step: 2
Training loss: 6.292117913171364
Validation loss: 6.264955644602015

Epoch: 5| Step: 3
Training loss: 6.480472870515568
Validation loss: 6.257973970329677

Epoch: 5| Step: 4
Training loss: 5.586965527670011
Validation loss: 6.2541466228821445

Epoch: 5| Step: 5
Training loss: 5.5410102895308295
Validation loss: 6.252802276790503

Epoch: 5| Step: 6
Training loss: 6.458832883485752
Validation loss: 6.244050736366821

Epoch: 5| Step: 7
Training loss: 7.035868979808066
Validation loss: 6.241514993639074

Epoch: 5| Step: 8
Training loss: 6.615088191752848
Validation loss: 6.236539091870791

Epoch: 5| Step: 9
Training loss: 6.2369364206738025
Validation loss: 6.230199647185761

Epoch: 5| Step: 10
Training loss: 7.252513581308919
Validation loss: 6.225282139468516

Epoch: 7| Step: 0
Training loss: 6.249536420795827
Validation loss: 6.220602594676873

Epoch: 5| Step: 1
Training loss: 5.8232398128296765
Validation loss: 6.213426776545808

Epoch: 5| Step: 2
Training loss: 6.258867001118918
Validation loss: 6.209438599158602

Epoch: 5| Step: 3
Training loss: 5.592055250481568
Validation loss: 6.2046034083772135

Epoch: 5| Step: 4
Training loss: 5.995841492556105
Validation loss: 6.199002248431643

Epoch: 5| Step: 5
Training loss: 5.5732342305719005
Validation loss: 6.197128337037783

Epoch: 5| Step: 6
Training loss: 6.458387838154161
Validation loss: 6.192722231915405

Epoch: 5| Step: 7
Training loss: 5.342950950801523
Validation loss: 6.181796457653777

Epoch: 5| Step: 8
Training loss: 7.08226959618572
Validation loss: 6.178230891093442

Epoch: 5| Step: 9
Training loss: 6.4288402198425825
Validation loss: 6.172900175884961

Epoch: 5| Step: 10
Training loss: 7.318981460833429
Validation loss: 6.162214550564306

Epoch: 8| Step: 0
Training loss: 7.1298624144731155
Validation loss: 6.163319532677256

Epoch: 5| Step: 1
Training loss: 5.58334098170122
Validation loss: 6.154513166381393

Epoch: 5| Step: 2
Training loss: 5.383083209357551
Validation loss: 6.153143782521816

Epoch: 5| Step: 3
Training loss: 5.283169910939958
Validation loss: 6.143983892275903

Epoch: 5| Step: 4
Training loss: 6.659256377074355
Validation loss: 6.139460235080628

Epoch: 5| Step: 5
Training loss: 5.815364008996247
Validation loss: 6.135253851720047

Epoch: 5| Step: 6
Training loss: 6.593276454318913
Validation loss: 6.126904166299674

Epoch: 5| Step: 7
Training loss: 5.74986167409619
Validation loss: 6.121316910342211

Epoch: 5| Step: 8
Training loss: 5.450850485140144
Validation loss: 6.1131287702887

Epoch: 5| Step: 9
Training loss: 7.379474381748262
Validation loss: 6.107756292268422

Epoch: 5| Step: 10
Training loss: 6.099620006795089
Validation loss: 6.0989835408349595

Epoch: 9| Step: 0
Training loss: 6.168305497160369
Validation loss: 6.096431597978066

Epoch: 5| Step: 1
Training loss: 6.865146858883863
Validation loss: 6.0894758213361815

Epoch: 5| Step: 2
Training loss: 6.337713667598964
Validation loss: 6.079981105167366

Epoch: 5| Step: 3
Training loss: 6.3745290544873905
Validation loss: 6.0725266906156845

Epoch: 5| Step: 4
Training loss: 5.664345022587528
Validation loss: 6.068161981461052

Epoch: 5| Step: 5
Training loss: 5.718508856019806
Validation loss: 6.061049407598487

Epoch: 5| Step: 6
Training loss: 6.868690230827166
Validation loss: 6.054484406821871

Epoch: 5| Step: 7
Training loss: 5.836329026985239
Validation loss: 6.049711029086019

Epoch: 5| Step: 8
Training loss: 5.499765564517131
Validation loss: 6.0383010887516475

Epoch: 5| Step: 9
Training loss: 5.483834699224882
Validation loss: 6.032504529811105

Epoch: 5| Step: 10
Training loss: 5.684198783840075
Validation loss: 6.029637149080931

Epoch: 10| Step: 0
Training loss: 6.535139613976883
Validation loss: 6.015683684151382

Epoch: 5| Step: 1
Training loss: 6.34736327448887
Validation loss: 6.010773202361885

Epoch: 5| Step: 2
Training loss: 5.609155167121228
Validation loss: 6.009389662221198

Epoch: 5| Step: 3
Training loss: 6.298665816707269
Validation loss: 5.995920612966958

Epoch: 5| Step: 4
Training loss: 5.9200610601008385
Validation loss: 5.988176334832181

Epoch: 5| Step: 5
Training loss: 5.801142270962609
Validation loss: 5.986560087717185

Epoch: 5| Step: 6
Training loss: 5.902096211098104
Validation loss: 5.979311208088028

Epoch: 5| Step: 7
Training loss: 5.72627938313618
Validation loss: 5.962907512725752

Epoch: 5| Step: 8
Training loss: 5.379119890966514
Validation loss: 5.958337975564817

Epoch: 5| Step: 9
Training loss: 6.116067094373709
Validation loss: 5.954074466846595

Epoch: 5| Step: 10
Training loss: 6.2162372362384355
Validation loss: 5.943246627148553

Epoch: 11| Step: 0
Training loss: 4.903619923846458
Validation loss: 5.934887557540124

Epoch: 5| Step: 1
Training loss: 6.092509764615367
Validation loss: 5.927761102350464

Epoch: 5| Step: 2
Training loss: 6.087846762554532
Validation loss: 5.919155411435685

Epoch: 5| Step: 3
Training loss: 5.7569889219759585
Validation loss: 5.912278049395094

Epoch: 5| Step: 4
Training loss: 6.267332229712088
Validation loss: 5.9053007518606595

Epoch: 5| Step: 5
Training loss: 6.707337805130207
Validation loss: 5.8947839670192765

Epoch: 5| Step: 6
Training loss: 6.454322242052069
Validation loss: 5.884959826723884

Epoch: 5| Step: 7
Training loss: 4.986183723244486
Validation loss: 5.878578654790781

Epoch: 5| Step: 8
Training loss: 5.913127790030456
Validation loss: 5.86706071804621

Epoch: 5| Step: 9
Training loss: 5.319893751876066
Validation loss: 5.857964719534214

Epoch: 5| Step: 10
Training loss: 6.210603371515625
Validation loss: 5.852975896406717

Epoch: 12| Step: 0
Training loss: 5.2509692069469125
Validation loss: 5.841995913936695

Epoch: 5| Step: 1
Training loss: 6.61523235671286
Validation loss: 5.830741423691025

Epoch: 5| Step: 2
Training loss: 6.220682581893081
Validation loss: 5.827234528472446

Epoch: 5| Step: 3
Training loss: 5.755152839864905
Validation loss: 5.805554270709427

Epoch: 5| Step: 4
Training loss: 6.079245495911524
Validation loss: 5.802540446860877

Epoch: 5| Step: 5
Training loss: 5.025089828675193
Validation loss: 5.792523516432771

Epoch: 5| Step: 6
Training loss: 5.499745276361297
Validation loss: 5.785660015710454

Epoch: 5| Step: 7
Training loss: 6.357674186141415
Validation loss: 5.775212583130379

Epoch: 5| Step: 8
Training loss: 5.825161832599723
Validation loss: 5.759433713727004

Epoch: 5| Step: 9
Training loss: 5.679522946163357
Validation loss: 5.755486081285363

Epoch: 5| Step: 10
Training loss: 5.283451321284212
Validation loss: 5.7426184042681285

Epoch: 13| Step: 0
Training loss: 4.783099446354916
Validation loss: 5.733239613306221

Epoch: 5| Step: 1
Training loss: 6.18806716939698
Validation loss: 5.718314250337569

Epoch: 5| Step: 2
Training loss: 6.071623553823615
Validation loss: 5.711987154716769

Epoch: 5| Step: 3
Training loss: 5.656959447048111
Validation loss: 5.700388799884614

Epoch: 5| Step: 4
Training loss: 5.797860691551049
Validation loss: 5.694745168974753

Epoch: 5| Step: 5
Training loss: 6.462051535417117
Validation loss: 5.677864340550739

Epoch: 5| Step: 6
Training loss: 5.413729042253993
Validation loss: 5.667587536008718

Epoch: 5| Step: 7
Training loss: 5.7745632782650755
Validation loss: 5.652410218790643

Epoch: 5| Step: 8
Training loss: 5.80353798657518
Validation loss: 5.649152822065831

Epoch: 5| Step: 9
Training loss: 5.115695229096623
Validation loss: 5.63858752709352

Epoch: 5| Step: 10
Training loss: 5.273146874225421
Validation loss: 5.625171143766462

Epoch: 14| Step: 0
Training loss: 6.342845532812935
Validation loss: 5.614770690006789

Epoch: 5| Step: 1
Training loss: 5.614738938741473
Validation loss: 5.602652519675794

Epoch: 5| Step: 2
Training loss: 5.838374802186868
Validation loss: 5.594783876007176

Epoch: 5| Step: 3
Training loss: 5.199617870668629
Validation loss: 5.5791597864284

Epoch: 5| Step: 4
Training loss: 6.197954381833341
Validation loss: 5.563123422188567

Epoch: 5| Step: 5
Training loss: 4.631449146596534
Validation loss: 5.5523576917042305

Epoch: 5| Step: 6
Training loss: 5.17678148501355
Validation loss: 5.540255993474594

Epoch: 5| Step: 7
Training loss: 5.344147962954541
Validation loss: 5.532437783239485

Epoch: 5| Step: 8
Training loss: 6.015666218405866
Validation loss: 5.51608124722888

Epoch: 5| Step: 9
Training loss: 5.4853060983461726
Validation loss: 5.502131913090445

Epoch: 5| Step: 10
Training loss: 5.143330056532885
Validation loss: 5.488423900336368

Epoch: 15| Step: 0
Training loss: 6.398390400658457
Validation loss: 5.477236958127748

Epoch: 5| Step: 1
Training loss: 4.662238858761685
Validation loss: 5.462786514556237

Epoch: 5| Step: 2
Training loss: 6.048297724565998
Validation loss: 5.450840258505893

Epoch: 5| Step: 3
Training loss: 6.494471032478259
Validation loss: 5.435998085204844

Epoch: 5| Step: 4
Training loss: 5.434426326849332
Validation loss: 5.428696571073143

Epoch: 5| Step: 5
Training loss: 4.203961710979634
Validation loss: 5.411301386310085

Epoch: 5| Step: 6
Training loss: 4.789160274733448
Validation loss: 5.4035858488602075

Epoch: 5| Step: 7
Training loss: 5.094694085188557
Validation loss: 5.378444173892572

Epoch: 5| Step: 8
Training loss: 5.2976014305870915
Validation loss: 5.368943635425254

Epoch: 5| Step: 9
Training loss: 5.949323586875858
Validation loss: 5.352064559951434

Epoch: 5| Step: 10
Training loss: 4.730330650273095
Validation loss: 5.341148984557973

Epoch: 16| Step: 0
Training loss: 4.503854795957713
Validation loss: 5.327158284638073

Epoch: 5| Step: 1
Training loss: 6.09972663642089
Validation loss: 5.313259511047697

Epoch: 5| Step: 2
Training loss: 6.012417024606926
Validation loss: 5.28791695930432

Epoch: 5| Step: 3
Training loss: 6.095306667157873
Validation loss: 5.286694617097772

Epoch: 5| Step: 4
Training loss: 4.748818300724497
Validation loss: 5.266985033354998

Epoch: 5| Step: 5
Training loss: 5.68577264398446
Validation loss: 5.256852720406875

Epoch: 5| Step: 6
Training loss: 4.536546650087801
Validation loss: 5.23394480740283

Epoch: 5| Step: 7
Training loss: 4.894418823217465
Validation loss: 5.223614837258086

Epoch: 5| Step: 8
Training loss: 5.112307765489761
Validation loss: 5.198476770534516

Epoch: 5| Step: 9
Training loss: 5.5854102679506115
Validation loss: 5.1863102196505215

Epoch: 5| Step: 10
Training loss: 4.156428053634402
Validation loss: 5.179999442132763

Epoch: 17| Step: 0
Training loss: 4.870315648684618
Validation loss: 5.155173906916798

Epoch: 5| Step: 1
Training loss: 4.1228488746275405
Validation loss: 5.146821421588119

Epoch: 5| Step: 2
Training loss: 5.9928810484188695
Validation loss: 5.126117891515341

Epoch: 5| Step: 3
Training loss: 5.318139885986812
Validation loss: 5.111708514442426

Epoch: 5| Step: 4
Training loss: 4.667809596201585
Validation loss: 5.0901018440116035

Epoch: 5| Step: 5
Training loss: 5.684214554798268
Validation loss: 5.064814352649179

Epoch: 5| Step: 6
Training loss: 5.557377889358159
Validation loss: 5.060107629158167

Epoch: 5| Step: 7
Training loss: 4.595222496648141
Validation loss: 5.043222787067877

Epoch: 5| Step: 8
Training loss: 4.875930892880205
Validation loss: 5.010867331395408

Epoch: 5| Step: 9
Training loss: 4.53145877751787
Validation loss: 5.012040309465686

Epoch: 5| Step: 10
Training loss: 5.558709213762575
Validation loss: 4.987022476267403

Epoch: 18| Step: 0
Training loss: 5.989957989018377
Validation loss: 4.959953650702244

Epoch: 5| Step: 1
Training loss: 5.42135327382196
Validation loss: 4.955495214255087

Epoch: 5| Step: 2
Training loss: 4.303148164042705
Validation loss: 4.934230751725838

Epoch: 5| Step: 3
Training loss: 3.7658265879002872
Validation loss: 4.906849490299068

Epoch: 5| Step: 4
Training loss: 4.930596269370795
Validation loss: 4.901792870945825

Epoch: 5| Step: 5
Training loss: 4.449321849455706
Validation loss: 4.87397222462655

Epoch: 5| Step: 6
Training loss: 4.177378934958541
Validation loss: 4.855746695171582

Epoch: 5| Step: 7
Training loss: 5.4603685074416495
Validation loss: 4.83744833233064

Epoch: 5| Step: 8
Training loss: 4.770472928000651
Validation loss: 4.825791779049941

Epoch: 5| Step: 9
Training loss: 5.34707894842031
Validation loss: 4.807535863661123

Epoch: 5| Step: 10
Training loss: 4.85051623870928
Validation loss: 4.7719715740026745

Epoch: 19| Step: 0
Training loss: 4.204900317014113
Validation loss: 4.763864693401387

Epoch: 5| Step: 1
Training loss: 3.628620050188216
Validation loss: 4.737811748011637

Epoch: 5| Step: 2
Training loss: 5.7694132282063775
Validation loss: 4.722375915426203

Epoch: 5| Step: 3
Training loss: 4.927984218485445
Validation loss: 4.6897928822507255

Epoch: 5| Step: 4
Training loss: 4.412085166212911
Validation loss: 4.683243630582601

Epoch: 5| Step: 5
Training loss: 5.440453615069218
Validation loss: 4.64774451539461

Epoch: 5| Step: 6
Training loss: 5.102757265818862
Validation loss: 4.634360800439166

Epoch: 5| Step: 7
Training loss: 4.090008605724132
Validation loss: 4.62047080646016

Epoch: 5| Step: 8
Training loss: 4.8687296914691975
Validation loss: 4.596351470105193

Epoch: 5| Step: 9
Training loss: 4.6397979718654305
Validation loss: 4.573852695914692

Epoch: 5| Step: 10
Training loss: 4.112045290775464
Validation loss: 4.556334492895766

Epoch: 20| Step: 0
Training loss: 3.880743139222444
Validation loss: 4.526240521795962

Epoch: 5| Step: 1
Training loss: 4.44946266959233
Validation loss: 4.510353994892059

Epoch: 5| Step: 2
Training loss: 4.61597262696029
Validation loss: 4.486070892303719

Epoch: 5| Step: 3
Training loss: 4.744625263108679
Validation loss: 4.472292487801095

Epoch: 5| Step: 4
Training loss: 4.82111963967688
Validation loss: 4.4541284644912915

Epoch: 5| Step: 5
Training loss: 3.773273977839513
Validation loss: 4.420550305754529

Epoch: 5| Step: 6
Training loss: 4.629589793281121
Validation loss: 4.410407375397384

Epoch: 5| Step: 7
Training loss: 5.4264187201452465
Validation loss: 4.370894044989584

Epoch: 5| Step: 8
Training loss: 4.53138174983571
Validation loss: 4.361580296074881

Epoch: 5| Step: 9
Training loss: 4.185111660031736
Validation loss: 4.326006202985687

Epoch: 5| Step: 10
Training loss: 3.553408482766645
Validation loss: 4.307095387238735

Epoch: 21| Step: 0
Training loss: 4.801409339634407
Validation loss: 4.300429098263948

Epoch: 5| Step: 1
Training loss: 5.058612979572524
Validation loss: 4.257087521012543

Epoch: 5| Step: 2
Training loss: 4.1899711946576135
Validation loss: 4.236181915505563

Epoch: 5| Step: 3
Training loss: 4.457328017549334
Validation loss: 4.217207446366487

Epoch: 5| Step: 4
Training loss: 3.4468791280325743
Validation loss: 4.188446379997932

Epoch: 5| Step: 5
Training loss: 4.208450970406154
Validation loss: 4.167722215567398

Epoch: 5| Step: 6
Training loss: 4.407191399185283
Validation loss: 4.1439430456766395

Epoch: 5| Step: 7
Training loss: 3.3459613653621427
Validation loss: 4.114199240864785

Epoch: 5| Step: 8
Training loss: 3.935955047265433
Validation loss: 4.090641778378981

Epoch: 5| Step: 9
Training loss: 3.914076388214507
Validation loss: 4.091284131898285

Epoch: 5| Step: 10
Training loss: 4.303625733960589
Validation loss: 4.053640517120087

Epoch: 22| Step: 0
Training loss: 3.5783096998761215
Validation loss: 4.031724611086464

Epoch: 5| Step: 1
Training loss: 4.26599007745475
Validation loss: 3.998537489696376

Epoch: 5| Step: 2
Training loss: 4.421330826235966
Validation loss: 3.984623183889959

Epoch: 5| Step: 3
Training loss: 4.424379535860791
Validation loss: 3.9606186405761354

Epoch: 5| Step: 4
Training loss: 5.176853699327726
Validation loss: 3.9362570432907105

Epoch: 5| Step: 5
Training loss: 2.9299277245261983
Validation loss: 3.9046825717928297

Epoch: 5| Step: 6
Training loss: 3.671786303159117
Validation loss: 3.8621779007561132

Epoch: 5| Step: 7
Training loss: 3.215470504385819
Validation loss: 3.845332857158667

Epoch: 5| Step: 8
Training loss: 4.809643975482846
Validation loss: 3.819380779214295

Epoch: 5| Step: 9
Training loss: 2.828574297712228
Validation loss: 3.80999135379953

Epoch: 5| Step: 10
Training loss: 3.8119338819087543
Validation loss: 3.784580262194766

Epoch: 23| Step: 0
Training loss: 4.5751401785965635
Validation loss: 3.7558450505379795

Epoch: 5| Step: 1
Training loss: 3.1581217437431417
Validation loss: 3.7392001954801555

Epoch: 5| Step: 2
Training loss: 3.768205067474698
Validation loss: 3.682046541335183

Epoch: 5| Step: 3
Training loss: 4.812337699234098
Validation loss: 3.6760861920434817

Epoch: 5| Step: 4
Training loss: 3.2169127915324647
Validation loss: 3.645019948674548

Epoch: 5| Step: 5
Training loss: 3.5990379902497875
Validation loss: 3.648193054660143

Epoch: 5| Step: 6
Training loss: 3.926807963922155
Validation loss: 3.597456802961338

Epoch: 5| Step: 7
Training loss: 3.815362324838862
Validation loss: 3.5914095997288094

Epoch: 5| Step: 8
Training loss: 3.2805438053768743
Validation loss: 3.560094827797229

Epoch: 5| Step: 9
Training loss: 3.233963797409696
Validation loss: 3.555370490120661

Epoch: 5| Step: 10
Training loss: 3.452621216078988
Validation loss: 3.5127358188205067

Epoch: 24| Step: 0
Training loss: 4.012515277774044
Validation loss: 3.491487254320164

Epoch: 5| Step: 1
Training loss: 3.5056222989566197
Validation loss: 3.460295619490776

Epoch: 5| Step: 2
Training loss: 2.8440816497241865
Validation loss: 3.4367768945030024

Epoch: 5| Step: 3
Training loss: 3.1062225770411427
Validation loss: 3.4414286234505513

Epoch: 5| Step: 4
Training loss: 3.8454996484308177
Validation loss: 3.4008469423706944

Epoch: 5| Step: 5
Training loss: 4.033465109529884
Validation loss: 3.3812180076151477

Epoch: 5| Step: 6
Training loss: 3.443964757298152
Validation loss: 3.3709643188233875

Epoch: 5| Step: 7
Training loss: 3.4708041045998725
Validation loss: 3.3168785780892076

Epoch: 5| Step: 8
Training loss: 3.2850296776300447
Validation loss: 3.2952690651327243

Epoch: 5| Step: 9
Training loss: 3.1350990379544954
Validation loss: 3.2971227580287246

Epoch: 5| Step: 10
Training loss: 3.739848192163319
Validation loss: 3.2645145142766996

Epoch: 25| Step: 0
Training loss: 2.8456934062763004
Validation loss: 3.2697674015231497

Epoch: 5| Step: 1
Training loss: 4.044879436040042
Validation loss: 3.2267341968337266

Epoch: 5| Step: 2
Training loss: 3.3795897746143293
Validation loss: 3.201464179478244

Epoch: 5| Step: 3
Training loss: 3.343304898593381
Validation loss: 3.1975234102759345

Epoch: 5| Step: 4
Training loss: 3.6883934361082424
Validation loss: 3.1916613373740965

Epoch: 5| Step: 5
Training loss: 2.649573158580162
Validation loss: 3.151871172949875

Epoch: 5| Step: 6
Training loss: 3.578778869320596
Validation loss: 3.1347781848908225

Epoch: 5| Step: 7
Training loss: 3.1490350728848338
Validation loss: 3.1257020616994953

Epoch: 5| Step: 8
Training loss: 3.645060837058742
Validation loss: 3.1001779669924723

Epoch: 5| Step: 9
Training loss: 2.765959638619686
Validation loss: 3.074252262405283

Epoch: 5| Step: 10
Training loss: 3.1114537943468594
Validation loss: 3.0532686070499566

Epoch: 26| Step: 0
Training loss: 2.764139757214188
Validation loss: 3.048102743970967

Epoch: 5| Step: 1
Training loss: 3.25895250166078
Validation loss: 3.0212271586765285

Epoch: 5| Step: 2
Training loss: 3.145597857489492
Validation loss: 3.01764923732983

Epoch: 5| Step: 3
Training loss: 3.3199979745330146
Validation loss: 2.9859903408607225

Epoch: 5| Step: 4
Training loss: 2.193181642989638
Validation loss: 2.991467580158903

Epoch: 5| Step: 5
Training loss: 3.4118126760402836
Validation loss: 2.9526835967501683

Epoch: 5| Step: 6
Training loss: 3.3434526543006844
Validation loss: 2.950824268211059

Epoch: 5| Step: 7
Training loss: 3.4345632319286556
Validation loss: 2.928835058310569

Epoch: 5| Step: 8
Training loss: 3.081751666907445
Validation loss: 2.924422140004403

Epoch: 5| Step: 9
Training loss: 3.762612051578477
Validation loss: 2.8947911884165607

Epoch: 5| Step: 10
Training loss: 2.3320290007971773
Validation loss: 2.875393983615381

Epoch: 27| Step: 0
Training loss: 3.092952432803795
Validation loss: 2.9123511726907667

Epoch: 5| Step: 1
Training loss: 3.0249506985768875
Validation loss: 2.8505720660748834

Epoch: 5| Step: 2
Training loss: 2.014229106300889
Validation loss: 2.8426917612265696

Epoch: 5| Step: 3
Training loss: 2.99339298038767
Validation loss: 2.8152957779826964

Epoch: 5| Step: 4
Training loss: 3.5210033729318218
Validation loss: 2.8184885037470324

Epoch: 5| Step: 5
Training loss: 3.166563802018816
Validation loss: 2.822971472571227

Epoch: 5| Step: 6
Training loss: 3.4310391832080533
Validation loss: 2.796360144699325

Epoch: 5| Step: 7
Training loss: 2.941291310368412
Validation loss: 2.809211205437478

Epoch: 5| Step: 8
Training loss: 2.9721627947450653
Validation loss: 2.759114372725226

Epoch: 5| Step: 9
Training loss: 3.090807507625529
Validation loss: 2.7777448243746727

Epoch: 5| Step: 10
Training loss: 2.8335095145108022
Validation loss: 2.7639338682634444

Epoch: 28| Step: 0
Training loss: 3.007252192637337
Validation loss: 2.772527160478946

Epoch: 5| Step: 1
Training loss: 3.164473594050266
Validation loss: 2.744967964449106

Epoch: 5| Step: 2
Training loss: 2.652034511151739
Validation loss: 2.7547608320797563

Epoch: 5| Step: 3
Training loss: 2.905393576822713
Validation loss: 2.7520118133680564

Epoch: 5| Step: 4
Training loss: 2.956984646831823
Validation loss: 2.736928362575023

Epoch: 5| Step: 5
Training loss: 3.4945033371866163
Validation loss: 2.724231608775839

Epoch: 5| Step: 6
Training loss: 2.9069057258092625
Validation loss: 2.713599548862513

Epoch: 5| Step: 7
Training loss: 2.9666284308666246
Validation loss: 2.699039999962617

Epoch: 5| Step: 8
Training loss: 3.1193561706402693
Validation loss: 2.673447156546482

Epoch: 5| Step: 9
Training loss: 2.67541323170612
Validation loss: 2.6810565848415644

Epoch: 5| Step: 10
Training loss: 2.8827617196260107
Validation loss: 2.7105602004093514

Epoch: 29| Step: 0
Training loss: 2.550751807143676
Validation loss: 2.6859740799552605

Epoch: 5| Step: 1
Training loss: 3.4940010158054773
Validation loss: 2.6914541446021203

Epoch: 5| Step: 2
Training loss: 2.6106642775883455
Validation loss: 2.687136958241733

Epoch: 5| Step: 3
Training loss: 2.594296501220066
Validation loss: 2.668043942899956

Epoch: 5| Step: 4
Training loss: 2.5080544423365048
Validation loss: 2.671687324599689

Epoch: 5| Step: 5
Training loss: 2.654951428904821
Validation loss: 2.6591668547068648

Epoch: 5| Step: 6
Training loss: 2.944456426328196
Validation loss: 2.671095609614931

Epoch: 5| Step: 7
Training loss: 2.953390119651066
Validation loss: 2.655822759117311

Epoch: 5| Step: 8
Training loss: 3.491301217145661
Validation loss: 2.6455286112299854

Epoch: 5| Step: 9
Training loss: 2.868093238400334
Validation loss: 2.6561270833152943

Epoch: 5| Step: 10
Training loss: 3.532841416670411
Validation loss: 2.65734444546182

Epoch: 30| Step: 0
Training loss: 2.379695266640826
Validation loss: 2.654473434856766

Epoch: 5| Step: 1
Training loss: 3.25124012688557
Validation loss: 2.6489386467195684

Epoch: 5| Step: 2
Training loss: 3.3212481448247666
Validation loss: 2.6585858666157187

Epoch: 5| Step: 3
Training loss: 2.76653339532262
Validation loss: 2.6356769572495273

Epoch: 5| Step: 4
Training loss: 3.3403675404782867
Validation loss: 2.6336185135271846

Epoch: 5| Step: 5
Training loss: 2.3043409183921266
Validation loss: 2.627628615869163

Epoch: 5| Step: 6
Training loss: 2.6103048894829026
Validation loss: 2.625101826807677

Epoch: 5| Step: 7
Training loss: 2.7806180600375314
Validation loss: 2.641471172378968

Epoch: 5| Step: 8
Training loss: 2.5882043957778396
Validation loss: 2.652425853855091

Epoch: 5| Step: 9
Training loss: 3.798999960967383
Validation loss: 2.6609915814568814

Epoch: 5| Step: 10
Training loss: 2.6072850795108393
Validation loss: 2.6327352988698354

Epoch: 31| Step: 0
Training loss: 2.5510752860414114
Validation loss: 2.6106033425663213

Epoch: 5| Step: 1
Training loss: 3.0160356153110506
Validation loss: 2.6510638776740376

Epoch: 5| Step: 2
Training loss: 3.14768423909241
Validation loss: 2.652247169895646

Epoch: 5| Step: 3
Training loss: 2.6751992588163107
Validation loss: 2.635095565970452

Epoch: 5| Step: 4
Training loss: 3.0972370571205055
Validation loss: 2.621437745718168

Epoch: 5| Step: 5
Training loss: 2.472592417780442
Validation loss: 2.6328544750892102

Epoch: 5| Step: 6
Training loss: 3.3511416297701175
Validation loss: 2.5977782858649565

Epoch: 5| Step: 7
Training loss: 2.406258521126856
Validation loss: 2.6286129813115906

Epoch: 5| Step: 8
Training loss: 3.062998517002764
Validation loss: 2.614145833006168

Epoch: 5| Step: 9
Training loss: 2.779612369819331
Validation loss: 2.620986802542189

Epoch: 5| Step: 10
Training loss: 3.6541722580719425
Validation loss: 2.6401329565082006

Epoch: 32| Step: 0
Training loss: 3.144348973269068
Validation loss: 2.603479573493375

Epoch: 5| Step: 1
Training loss: 3.088234657266161
Validation loss: 2.64752796607047

Epoch: 5| Step: 2
Training loss: 2.927132675098933
Validation loss: 2.609245740678027

Epoch: 5| Step: 3
Training loss: 2.6173769754174336
Validation loss: 2.626497400219133

Epoch: 5| Step: 4
Training loss: 2.3325871455195135
Validation loss: 2.6306558756818443

Epoch: 5| Step: 5
Training loss: 3.073962655361183
Validation loss: 2.62726945821712

Epoch: 5| Step: 6
Training loss: 3.4938594903320874
Validation loss: 2.59130764647326

Epoch: 5| Step: 7
Training loss: 2.812186923085796
Validation loss: 2.6322662594081243

Epoch: 5| Step: 8
Training loss: 2.480209120732011
Validation loss: 2.6122998159687265

Epoch: 5| Step: 9
Training loss: 3.1305891790185574
Validation loss: 2.6207718439465073

Epoch: 5| Step: 10
Training loss: 3.1157180267189593
Validation loss: 2.6394715818829555

Epoch: 33| Step: 0
Training loss: 2.803736873601084
Validation loss: 2.622822979466474

Epoch: 5| Step: 1
Training loss: 3.271306548338618
Validation loss: 2.610692239543005

Epoch: 5| Step: 2
Training loss: 3.4495361458581693
Validation loss: 2.615177742121566

Epoch: 5| Step: 3
Training loss: 2.721164113881056
Validation loss: 2.590986328030607

Epoch: 5| Step: 4
Training loss: 3.2510943404337547
Validation loss: 2.6040871517388453

Epoch: 5| Step: 5
Training loss: 2.9326680801757035
Validation loss: 2.6298502321402775

Epoch: 5| Step: 6
Training loss: 2.5106088609582673
Validation loss: 2.634416092511851

Epoch: 5| Step: 7
Training loss: 3.5382604637554596
Validation loss: 2.6192152346967505

Epoch: 5| Step: 8
Training loss: 2.8512275394556794
Validation loss: 2.6310070584806162

Epoch: 5| Step: 9
Training loss: 2.266194554790553
Validation loss: 2.6369074928246348

Epoch: 5| Step: 10
Training loss: 2.38014727513458
Validation loss: 2.6051058395255517

Epoch: 34| Step: 0
Training loss: 3.827986734189891
Validation loss: 2.6106890962316296

Epoch: 5| Step: 1
Training loss: 2.9496814491136356
Validation loss: 2.613716427578155

Epoch: 5| Step: 2
Training loss: 2.4567399329859145
Validation loss: 2.6126827481256396

Epoch: 5| Step: 3
Training loss: 2.9166225611667067
Validation loss: 2.628319069305034

Epoch: 5| Step: 4
Training loss: 2.553872821410544
Validation loss: 2.6393642601488247

Epoch: 5| Step: 5
Training loss: 3.2626371449843368
Validation loss: 2.6350938974749565

Epoch: 5| Step: 6
Training loss: 2.5025439670294074
Validation loss: 2.632904411409055

Epoch: 5| Step: 7
Training loss: 3.222186725976337
Validation loss: 2.5974550689726237

Epoch: 5| Step: 8
Training loss: 2.8423258810135397
Validation loss: 2.651999809426233

Epoch: 5| Step: 9
Training loss: 2.6686855263705516
Validation loss: 2.6239095044934726

Epoch: 5| Step: 10
Training loss: 2.731450811550373
Validation loss: 2.611090487395298

Epoch: 35| Step: 0
Training loss: 2.7009475846583957
Validation loss: 2.64185249141114

Epoch: 5| Step: 1
Training loss: 2.640985678694987
Validation loss: 2.591224087882389

Epoch: 5| Step: 2
Training loss: 3.1045010960473
Validation loss: 2.6306699585088698

Epoch: 5| Step: 3
Training loss: 2.921145587796846
Validation loss: 2.60689281162543

Epoch: 5| Step: 4
Training loss: 3.416112637764458
Validation loss: 2.645551624049714

Epoch: 5| Step: 5
Training loss: 2.7718270797629896
Validation loss: 2.6206378250788656

Epoch: 5| Step: 6
Training loss: 2.7550460296496464
Validation loss: 2.6256555226091822

Epoch: 5| Step: 7
Training loss: 3.386984985165108
Validation loss: 2.6031590799254802

Epoch: 5| Step: 8
Training loss: 2.533552464828983
Validation loss: 2.616859166881674

Epoch: 5| Step: 9
Training loss: 3.1594005006389265
Validation loss: 2.606764691980256

Epoch: 5| Step: 10
Training loss: 2.736376656449754
Validation loss: 2.600846920126254

Epoch: 36| Step: 0
Training loss: 2.9367158533048032
Validation loss: 2.628814379216434

Epoch: 5| Step: 1
Training loss: 2.701461191743388
Validation loss: 2.636979109087186

Epoch: 5| Step: 2
Training loss: 3.609265346430265
Validation loss: 2.632874156645853

Epoch: 5| Step: 3
Training loss: 2.932860098581097
Validation loss: 2.629476111041292

Epoch: 5| Step: 4
Training loss: 2.6088908768595207
Validation loss: 2.6126689088321733

Epoch: 5| Step: 5
Training loss: 2.670181630132439
Validation loss: 2.6081881246595686

Epoch: 5| Step: 6
Training loss: 3.2641834928695523
Validation loss: 2.6105553974135383

Epoch: 5| Step: 7
Training loss: 3.4458430913181974
Validation loss: 2.602752683305677

Epoch: 5| Step: 8
Training loss: 2.774468888328843
Validation loss: 2.596852435382476

Epoch: 5| Step: 9
Training loss: 2.7592020397478474
Validation loss: 2.629532222460076

Epoch: 5| Step: 10
Training loss: 2.3766985390957234
Validation loss: 2.6129777184128162

Epoch: 37| Step: 0
Training loss: 2.920741223358078
Validation loss: 2.6093864335051626

Epoch: 5| Step: 1
Training loss: 2.900855523557609
Validation loss: 2.615743134636517

Epoch: 5| Step: 2
Training loss: 2.953725925239284
Validation loss: 2.6457217080467648

Epoch: 5| Step: 3
Training loss: 3.415315097106622
Validation loss: 2.6187882693953557

Epoch: 5| Step: 4
Training loss: 2.2909762874260267
Validation loss: 2.607799758741887

Epoch: 5| Step: 5
Training loss: 2.7252554397549713
Validation loss: 2.6222542447761703

Epoch: 5| Step: 6
Training loss: 3.459781772368678
Validation loss: 2.601488414319129

Epoch: 5| Step: 7
Training loss: 2.7823914318033953
Validation loss: 2.6303613332919267

Epoch: 5| Step: 8
Training loss: 2.7186276638525375
Validation loss: 2.623647662783067

Epoch: 5| Step: 9
Training loss: 2.9720504885424326
Validation loss: 2.6441069740800005

Epoch: 5| Step: 10
Training loss: 2.706053718338197
Validation loss: 2.6227148748126208

Epoch: 38| Step: 0
Training loss: 2.514516455881125
Validation loss: 2.6048933358260027

Epoch: 5| Step: 1
Training loss: 3.043650167657021
Validation loss: 2.610930041040249

Epoch: 5| Step: 2
Training loss: 3.133962063577411
Validation loss: 2.6238460416616487

Epoch: 5| Step: 3
Training loss: 3.1564542496566905
Validation loss: 2.626176444498647

Epoch: 5| Step: 4
Training loss: 2.267182124188686
Validation loss: 2.6234699337190124

Epoch: 5| Step: 5
Training loss: 2.961584015571164
Validation loss: 2.634043482235094

Epoch: 5| Step: 6
Training loss: 3.1362196357750203
Validation loss: 2.622485200923939

Epoch: 5| Step: 7
Training loss: 2.845265917158405
Validation loss: 2.6192568443451565

Epoch: 5| Step: 8
Training loss: 2.9295680314182855
Validation loss: 2.6152152375728135

Epoch: 5| Step: 9
Training loss: 3.724243594183377
Validation loss: 2.620087084487332

Epoch: 5| Step: 10
Training loss: 2.0985897551495625
Validation loss: 2.618897953093318

Epoch: 39| Step: 0
Training loss: 2.9406742233713152
Validation loss: 2.6112461839152608

Epoch: 5| Step: 1
Training loss: 1.88216873496536
Validation loss: 2.6377515250969608

Epoch: 5| Step: 2
Training loss: 3.37724215592737
Validation loss: 2.6189249392845246

Epoch: 5| Step: 3
Training loss: 2.231186305400501
Validation loss: 2.635333055555031

Epoch: 5| Step: 4
Training loss: 3.2219240408716163
Validation loss: 2.6204348130878836

Epoch: 5| Step: 5
Training loss: 3.5895625389295325
Validation loss: 2.627668340053349

Epoch: 5| Step: 6
Training loss: 2.811528440724751
Validation loss: 2.603113410511362

Epoch: 5| Step: 7
Training loss: 2.8599499400632817
Validation loss: 2.6144682509131

Epoch: 5| Step: 8
Training loss: 3.3671908987076815
Validation loss: 2.5851335174444934

Epoch: 5| Step: 9
Training loss: 2.6087353316343878
Validation loss: 2.6097040487790775

Epoch: 5| Step: 10
Training loss: 2.6888204480052824
Validation loss: 2.6401410140787402

Epoch: 40| Step: 0
Training loss: 2.824334064414064
Validation loss: 2.604353487922437

Epoch: 5| Step: 1
Training loss: 3.2434329662590855
Validation loss: 2.6280749769240805

Epoch: 5| Step: 2
Training loss: 3.204710628401883
Validation loss: 2.6365535624483623

Epoch: 5| Step: 3
Training loss: 2.476903079709009
Validation loss: 2.6339998617716702

Epoch: 5| Step: 4
Training loss: 3.302356808927412
Validation loss: 2.606393283688367

Epoch: 5| Step: 5
Training loss: 2.7082609215861884
Validation loss: 2.6238610159564972

Epoch: 5| Step: 6
Training loss: 2.8201129874462283
Validation loss: 2.63415720271448

Epoch: 5| Step: 7
Training loss: 2.792523456635481
Validation loss: 2.5905959216677514

Epoch: 5| Step: 8
Training loss: 3.03259216168548
Validation loss: 2.6323927395641067

Epoch: 5| Step: 9
Training loss: 2.4186397478076995
Validation loss: 2.6034031913331477

Epoch: 5| Step: 10
Training loss: 3.2570299265221285
Validation loss: 2.611659280629487

Epoch: 41| Step: 0
Training loss: 3.042974391241562
Validation loss: 2.6316259351625377

Epoch: 5| Step: 1
Training loss: 2.794068276113827
Validation loss: 2.6149666706225374

Epoch: 5| Step: 2
Training loss: 2.4034034438715595
Validation loss: 2.62749674982893

Epoch: 5| Step: 3
Training loss: 2.8808802303270538
Validation loss: 2.6086186572927748

Epoch: 5| Step: 4
Training loss: 2.704844991505071
Validation loss: 2.6173237720582514

Epoch: 5| Step: 5
Training loss: 2.706097065963048
Validation loss: 2.60872858824246

Epoch: 5| Step: 6
Training loss: 2.8925421878042745
Validation loss: 2.612190251221106

Epoch: 5| Step: 7
Training loss: 3.261263330153816
Validation loss: 2.6333222989725646

Epoch: 5| Step: 8
Training loss: 3.504970971394049
Validation loss: 2.608784602481766

Epoch: 5| Step: 9
Training loss: 3.220632946760433
Validation loss: 2.634051201243617

Epoch: 5| Step: 10
Training loss: 2.769733631395896
Validation loss: 2.6143916671451617

Epoch: 42| Step: 0
Training loss: 2.903022204202169
Validation loss: 2.619482336548597

Epoch: 5| Step: 1
Training loss: 3.400948695050719
Validation loss: 2.6430514141848103

Epoch: 5| Step: 2
Training loss: 2.9330171508599756
Validation loss: 2.6221181605167927

Epoch: 5| Step: 3
Training loss: 2.1320644086731324
Validation loss: 2.624044149573757

Epoch: 5| Step: 4
Training loss: 2.7666480117383405
Validation loss: 2.6100754014305743

Epoch: 5| Step: 5
Training loss: 2.951674170575188
Validation loss: 2.6383499098822747

Epoch: 5| Step: 6
Training loss: 2.7517680639958275
Validation loss: 2.597279771651942

Epoch: 5| Step: 7
Training loss: 3.308732679528535
Validation loss: 2.6253072458245565

Epoch: 5| Step: 8
Training loss: 3.1407702967497957
Validation loss: 2.6204726921459844

Epoch: 5| Step: 9
Training loss: 2.5833554010576685
Validation loss: 2.5975980120673525

Epoch: 5| Step: 10
Training loss: 3.2815802998282995
Validation loss: 2.6229346403136073

Epoch: 43| Step: 0
Training loss: 2.835167309972572
Validation loss: 2.6182896073422643

Epoch: 5| Step: 1
Training loss: 3.2409109520994983
Validation loss: 2.634071319612302

Epoch: 5| Step: 2
Training loss: 2.6064041494618655
Validation loss: 2.6518470615285694

Epoch: 5| Step: 3
Training loss: 2.496040355606781
Validation loss: 2.6017801551634823

Epoch: 5| Step: 4
Training loss: 3.2274801136352695
Validation loss: 2.6023338485228305

Epoch: 5| Step: 5
Training loss: 2.803821143014326
Validation loss: 2.6186325577501783

Epoch: 5| Step: 6
Training loss: 3.032768577009993
Validation loss: 2.6027681798368327

Epoch: 5| Step: 7
Training loss: 3.1726951102643492
Validation loss: 2.597212231005413

Epoch: 5| Step: 8
Training loss: 2.514148349849075
Validation loss: 2.619195464205213

Epoch: 5| Step: 9
Training loss: 3.1889186021112415
Validation loss: 2.6138415799130006

Epoch: 5| Step: 10
Training loss: 2.866504889366442
Validation loss: 2.6187741045623563

Epoch: 44| Step: 0
Training loss: 3.025609067021123
Validation loss: 2.5965806262431927

Epoch: 5| Step: 1
Training loss: 2.6842818398347266
Validation loss: 2.611943380513323

Epoch: 5| Step: 2
Training loss: 3.378377566569463
Validation loss: 2.6055522089335557

Epoch: 5| Step: 3
Training loss: 2.580474337953759
Validation loss: 2.599252286206357

Epoch: 5| Step: 4
Training loss: 2.974166586688778
Validation loss: 2.623698044993735

Epoch: 5| Step: 5
Training loss: 2.9507436687812345
Validation loss: 2.6071590814558627

Epoch: 5| Step: 6
Training loss: 2.1735885776032915
Validation loss: 2.608243920507403

Epoch: 5| Step: 7
Training loss: 3.211549278321889
Validation loss: 2.6042513794605324

Epoch: 5| Step: 8
Training loss: 2.9260851876614358
Validation loss: 2.6466256701697985

Epoch: 5| Step: 9
Training loss: 3.3970057486012992
Validation loss: 2.6159064742775997

Epoch: 5| Step: 10
Training loss: 2.498379754501921
Validation loss: 2.6108392285759017

Epoch: 45| Step: 0
Training loss: 3.3270650259209757
Validation loss: 2.6398374583683233

Epoch: 5| Step: 1
Training loss: 2.3523769045659444
Validation loss: 2.6283141250397977

Epoch: 5| Step: 2
Training loss: 3.0131816551834025
Validation loss: 2.6233527469032643

Epoch: 5| Step: 3
Training loss: 2.1311239747852637
Validation loss: 2.6337057765843164

Epoch: 5| Step: 4
Training loss: 3.0855908935590524
Validation loss: 2.6081226652885166

Epoch: 5| Step: 5
Training loss: 2.508666656584701
Validation loss: 2.614851569451631

Epoch: 5| Step: 6
Training loss: 2.813759246363587
Validation loss: 2.605083267513654

Epoch: 5| Step: 7
Training loss: 3.1046652852124215
Validation loss: 2.62361570071851

Epoch: 5| Step: 8
Training loss: 3.2057408514153334
Validation loss: 2.6100642317211964

Epoch: 5| Step: 9
Training loss: 3.525910518278953
Validation loss: 2.6136501150090887

Epoch: 5| Step: 10
Training loss: 2.766481514752279
Validation loss: 2.593738560330738

Epoch: 46| Step: 0
Training loss: 2.8241797480125927
Validation loss: 2.623205775926577

Epoch: 5| Step: 1
Training loss: 2.767523938000538
Validation loss: 2.5977276871423887

Epoch: 5| Step: 2
Training loss: 3.695874806500776
Validation loss: 2.6020765387055094

Epoch: 5| Step: 3
Training loss: 2.456918880640418
Validation loss: 2.612664947585857

Epoch: 5| Step: 4
Training loss: 3.267635037142599
Validation loss: 2.5935327350203283

Epoch: 5| Step: 5
Training loss: 2.623348897558991
Validation loss: 2.608607272017472

Epoch: 5| Step: 6
Training loss: 2.674839984706865
Validation loss: 2.602915491264969

Epoch: 5| Step: 7
Training loss: 3.3343104519803712
Validation loss: 2.612057959123982

Epoch: 5| Step: 8
Training loss: 2.9094355362802777
Validation loss: 2.6230427896646202

Epoch: 5| Step: 9
Training loss: 2.5760753460225128
Validation loss: 2.6665378486247184

Epoch: 5| Step: 10
Training loss: 2.6596595871878903
Validation loss: 2.6236302063261783

Epoch: 47| Step: 0
Training loss: 2.331360482469142
Validation loss: 2.620262020757637

Epoch: 5| Step: 1
Training loss: 2.7046735440339864
Validation loss: 2.6057944807155895

Epoch: 5| Step: 2
Training loss: 2.4945359600057317
Validation loss: 2.6393316268483753

Epoch: 5| Step: 3
Training loss: 3.4308826910036885
Validation loss: 2.5843738943818457

Epoch: 5| Step: 4
Training loss: 2.464429043615751
Validation loss: 2.6003205444128374

Epoch: 5| Step: 5
Training loss: 2.80897428139157
Validation loss: 2.617056097246949

Epoch: 5| Step: 6
Training loss: 3.0771182200099156
Validation loss: 2.6159804426905784

Epoch: 5| Step: 7
Training loss: 3.6659096167494734
Validation loss: 2.6447146157000043

Epoch: 5| Step: 8
Training loss: 2.6467902087757618
Validation loss: 2.6051579334118635

Epoch: 5| Step: 9
Training loss: 3.4947007798013607
Validation loss: 2.6023297607171174

Epoch: 5| Step: 10
Training loss: 2.4041711323485613
Validation loss: 2.6088035723648493

Epoch: 48| Step: 0
Training loss: 3.28157986390675
Validation loss: 2.6216073630943595

Epoch: 5| Step: 1
Training loss: 2.910128394896052
Validation loss: 2.6127810997845846

Epoch: 5| Step: 2
Training loss: 2.710679715347344
Validation loss: 2.623410284105705

Epoch: 5| Step: 3
Training loss: 2.736193068858775
Validation loss: 2.5865633097343257

Epoch: 5| Step: 4
Training loss: 3.0714842135436498
Validation loss: 2.6085941412985987

Epoch: 5| Step: 5
Training loss: 2.0433904675725363
Validation loss: 2.612064236559651

Epoch: 5| Step: 6
Training loss: 2.733727601931564
Validation loss: 2.5944796248974122

Epoch: 5| Step: 7
Training loss: 3.1071023734826886
Validation loss: 2.614019214339981

Epoch: 5| Step: 8
Training loss: 3.2467702810162637
Validation loss: 2.631233449463985

Epoch: 5| Step: 9
Training loss: 2.9162569757370758
Validation loss: 2.6200659585528383

Epoch: 5| Step: 10
Training loss: 3.1275142473586977
Validation loss: 2.5895103638807595

Epoch: 49| Step: 0
Training loss: 3.581773122557744
Validation loss: 2.6215344330845496

Epoch: 5| Step: 1
Training loss: 2.428680309291194
Validation loss: 2.6163617191210484

Epoch: 5| Step: 2
Training loss: 2.634084332088608
Validation loss: 2.6104014245022933

Epoch: 5| Step: 3
Training loss: 2.6935611950763425
Validation loss: 2.6074116555057016

Epoch: 5| Step: 4
Training loss: 2.825678067146725
Validation loss: 2.6042526641100214

Epoch: 5| Step: 5
Training loss: 2.7035509777141473
Validation loss: 2.619445927361787

Epoch: 5| Step: 6
Training loss: 2.638296240350838
Validation loss: 2.587246640692214

Epoch: 5| Step: 7
Training loss: 3.2261415812008507
Validation loss: 2.5932386328871324

Epoch: 5| Step: 8
Training loss: 2.864889195614625
Validation loss: 2.5898322059662244

Epoch: 5| Step: 9
Training loss: 3.5383093834700006
Validation loss: 2.5979511146371

Epoch: 5| Step: 10
Training loss: 2.6119236177956995
Validation loss: 2.582786022432432

Epoch: 50| Step: 0
Training loss: 2.29872461700116
Validation loss: 2.6289406695109734

Epoch: 5| Step: 1
Training loss: 2.8933386359920634
Validation loss: 2.5795069585647155

Epoch: 5| Step: 2
Training loss: 3.2786894480516353
Validation loss: 2.5885309540310755

Epoch: 5| Step: 3
Training loss: 2.641567175001455
Validation loss: 2.5973020818093016

Epoch: 5| Step: 4
Training loss: 3.307386806451249
Validation loss: 2.6153122985891604

Epoch: 5| Step: 5
Training loss: 3.138043001764063
Validation loss: 2.5638097791704624

Epoch: 5| Step: 6
Training loss: 2.246315270156492
Validation loss: 2.5978295092582817

Epoch: 5| Step: 7
Training loss: 3.089834799192946
Validation loss: 2.5886252086824992

Epoch: 5| Step: 8
Training loss: 3.1804916527189846
Validation loss: 2.6178938687338955

Epoch: 5| Step: 9
Training loss: 2.651939844493509
Validation loss: 2.6197358939741324

Epoch: 5| Step: 10
Training loss: 2.945879894214164
Validation loss: 2.607699583322437

Epoch: 51| Step: 0
Training loss: 3.052248085618151
Validation loss: 2.6069602342259772

Epoch: 5| Step: 1
Training loss: 3.001801267914114
Validation loss: 2.605289874278651

Epoch: 5| Step: 2
Training loss: 3.2002003785815867
Validation loss: 2.6188764044669526

Epoch: 5| Step: 3
Training loss: 2.4615733460558706
Validation loss: 2.5924591537062867

Epoch: 5| Step: 4
Training loss: 3.268012675173212
Validation loss: 2.5935115158484683

Epoch: 5| Step: 5
Training loss: 2.9956856540434607
Validation loss: 2.6257984003907713

Epoch: 5| Step: 6
Training loss: 2.8528163713739616
Validation loss: 2.6122890169173734

Epoch: 5| Step: 7
Training loss: 2.7675388416848596
Validation loss: 2.613443138194354

Epoch: 5| Step: 8
Training loss: 2.8267998725915917
Validation loss: 2.6146368820288584

Epoch: 5| Step: 9
Training loss: 2.7727987064193464
Validation loss: 2.628819395681252

Epoch: 5| Step: 10
Training loss: 2.424881969607659
Validation loss: 2.6138703268326346

Epoch: 52| Step: 0
Training loss: 2.2724659734849655
Validation loss: 2.6231589680608534

Epoch: 5| Step: 1
Training loss: 2.9301593044576113
Validation loss: 2.608521975708398

Epoch: 5| Step: 2
Training loss: 3.351065360947877
Validation loss: 2.6130224560497988

Epoch: 5| Step: 3
Training loss: 2.7303413503283327
Validation loss: 2.621482649961672

Epoch: 5| Step: 4
Training loss: 3.023458318121157
Validation loss: 2.6004257509856012

Epoch: 5| Step: 5
Training loss: 2.4850295062395342
Validation loss: 2.629902925226278

Epoch: 5| Step: 6
Training loss: 3.0672088544571516
Validation loss: 2.6080819140442544

Epoch: 5| Step: 7
Training loss: 3.1571801958298846
Validation loss: 2.6168993601949304

Epoch: 5| Step: 8
Training loss: 2.9579642876048395
Validation loss: 2.577576088541005

Epoch: 5| Step: 9
Training loss: 2.70858909181822
Validation loss: 2.590647422645693

Epoch: 5| Step: 10
Training loss: 2.9168638616839244
Validation loss: 2.6035940775449475

Epoch: 53| Step: 0
Training loss: 3.1079929673398845
Validation loss: 2.5901619427375624

Epoch: 5| Step: 1
Training loss: 2.8864959093940756
Validation loss: 2.593871448736043

Epoch: 5| Step: 2
Training loss: 2.797217832896697
Validation loss: 2.6329352227705494

Epoch: 5| Step: 3
Training loss: 2.6720739814772707
Validation loss: 2.6233776995859506

Epoch: 5| Step: 4
Training loss: 2.875406485307688
Validation loss: 2.580810652542294

Epoch: 5| Step: 5
Training loss: 3.055944940051037
Validation loss: 2.6004777306143816

Epoch: 5| Step: 6
Training loss: 2.3097820289786704
Validation loss: 2.598201442157592

Epoch: 5| Step: 7
Training loss: 3.925905990516649
Validation loss: 2.60180371850123

Epoch: 5| Step: 8
Training loss: 2.3544533028985275
Validation loss: 2.6034397362539714

Epoch: 5| Step: 9
Training loss: 3.106251897369972
Validation loss: 2.586175994636565

Epoch: 5| Step: 10
Training loss: 2.3209535888344335
Validation loss: 2.614217480507919

Epoch: 54| Step: 0
Training loss: 2.409163358622967
Validation loss: 2.609683725860085

Epoch: 5| Step: 1
Training loss: 2.706221113865711
Validation loss: 2.594413696131389

Epoch: 5| Step: 2
Training loss: 2.8380099203892044
Validation loss: 2.620494668861071

Epoch: 5| Step: 3
Training loss: 2.8422935025673066
Validation loss: 2.6182352455920275

Epoch: 5| Step: 4
Training loss: 2.8377259555201615
Validation loss: 2.6182965855781366

Epoch: 5| Step: 5
Training loss: 2.9978014519355765
Validation loss: 2.601526149446652

Epoch: 5| Step: 6
Training loss: 3.2626279374684466
Validation loss: 2.612696267466752

Epoch: 5| Step: 7
Training loss: 3.083751203384443
Validation loss: 2.5947088432964405

Epoch: 5| Step: 8
Training loss: 3.0798037835574594
Validation loss: 2.601396391724108

Epoch: 5| Step: 9
Training loss: 2.716371570154038
Validation loss: 2.5875447741437183

Epoch: 5| Step: 10
Training loss: 2.927538111281452
Validation loss: 2.5942035816627893

Epoch: 55| Step: 0
Training loss: 2.983350008557422
Validation loss: 2.6074062340644306

Epoch: 5| Step: 1
Training loss: 2.942661377298671
Validation loss: 2.590903672364774

Epoch: 5| Step: 2
Training loss: 2.7078352445691665
Validation loss: 2.6023444795459882

Epoch: 5| Step: 3
Training loss: 2.6468778535901825
Validation loss: 2.5947357530418103

Epoch: 5| Step: 4
Training loss: 2.928124908805528
Validation loss: 2.5912156783508227

Epoch: 5| Step: 5
Training loss: 3.0018536880692896
Validation loss: 2.610185129595602

Epoch: 5| Step: 6
Training loss: 2.6949779358139327
Validation loss: 2.640090048414245

Epoch: 5| Step: 7
Training loss: 3.1902851577590026
Validation loss: 2.5814973504046943

Epoch: 5| Step: 8
Training loss: 2.5272267711046212
Validation loss: 2.610494029711298

Epoch: 5| Step: 9
Training loss: 3.129614817650944
Validation loss: 2.582037649087316

Epoch: 5| Step: 10
Training loss: 2.984014838890018
Validation loss: 2.597650866426189

Epoch: 56| Step: 0
Training loss: 2.325894509794225
Validation loss: 2.5987215477802588

Epoch: 5| Step: 1
Training loss: 2.743962248845563
Validation loss: 2.61880304696576

Epoch: 5| Step: 2
Training loss: 2.5168981706695597
Validation loss: 2.591165856263259

Epoch: 5| Step: 3
Training loss: 3.1539225542215434
Validation loss: 2.5757476216728685

Epoch: 5| Step: 4
Training loss: 2.9457280601960636
Validation loss: 2.6105216085292735

Epoch: 5| Step: 5
Training loss: 3.32373932766788
Validation loss: 2.5865156127708153

Epoch: 5| Step: 6
Training loss: 3.28584940851665
Validation loss: 2.5865520890390976

Epoch: 5| Step: 7
Training loss: 2.66032133556446
Validation loss: 2.6015135663686584

Epoch: 5| Step: 8
Training loss: 3.06973408693684
Validation loss: 2.5993811015896107

Epoch: 5| Step: 9
Training loss: 3.154720577918693
Validation loss: 2.605859362053211

Epoch: 5| Step: 10
Training loss: 2.5111166794564204
Validation loss: 2.60850004062928

Epoch: 57| Step: 0
Training loss: 3.2217619793786785
Validation loss: 2.5842519239077664

Epoch: 5| Step: 1
Training loss: 2.4926149964276996
Validation loss: 2.6098482683891246

Epoch: 5| Step: 2
Training loss: 3.4337756702198172
Validation loss: 2.5781581743529163

Epoch: 5| Step: 3
Training loss: 3.4111922220975224
Validation loss: 2.6029305111175245

Epoch: 5| Step: 4
Training loss: 2.921775775387397
Validation loss: 2.600742064754792

Epoch: 5| Step: 5
Training loss: 2.8638622324217176
Validation loss: 2.6279323955871954

Epoch: 5| Step: 6
Training loss: 2.8912499654318826
Validation loss: 2.6006889351052873

Epoch: 5| Step: 7
Training loss: 2.452184508987728
Validation loss: 2.5742860504210823

Epoch: 5| Step: 8
Training loss: 2.1679465352887752
Validation loss: 2.6111893918863123

Epoch: 5| Step: 9
Training loss: 2.695985660248833
Validation loss: 2.5995515723391125

Epoch: 5| Step: 10
Training loss: 2.8854731658655526
Validation loss: 2.6183452153467113

Epoch: 58| Step: 0
Training loss: 3.326306629867192
Validation loss: 2.6290786833620885

Epoch: 5| Step: 1
Training loss: 2.091143223692397
Validation loss: 2.6133467998978035

Epoch: 5| Step: 2
Training loss: 2.8777020237827102
Validation loss: 2.6113378628432864

Epoch: 5| Step: 3
Training loss: 3.2762976194179028
Validation loss: 2.5946777805509633

Epoch: 5| Step: 4
Training loss: 2.2664749129846915
Validation loss: 2.5965569167744134

Epoch: 5| Step: 5
Training loss: 2.8790215271187676
Validation loss: 2.590778608307964

Epoch: 5| Step: 6
Training loss: 2.3557215819038873
Validation loss: 2.606878001450854

Epoch: 5| Step: 7
Training loss: 3.095724227303865
Validation loss: 2.5959209396213363

Epoch: 5| Step: 8
Training loss: 2.3646950268238087
Validation loss: 2.602190336050023

Epoch: 5| Step: 9
Training loss: 3.1107932072144813
Validation loss: 2.6006089773629215

Epoch: 5| Step: 10
Training loss: 3.681781148884829
Validation loss: 2.6001611253824946

Epoch: 59| Step: 0
Training loss: 3.2136541230460383
Validation loss: 2.590882562767876

Epoch: 5| Step: 1
Training loss: 2.666410513337128
Validation loss: 2.6221647014789733

Epoch: 5| Step: 2
Training loss: 2.868714967733998
Validation loss: 2.594266349594146

Epoch: 5| Step: 3
Training loss: 3.0828423152048305
Validation loss: 2.610384082756964

Epoch: 5| Step: 4
Training loss: 2.9155874889777857
Validation loss: 2.5940663717657295

Epoch: 5| Step: 5
Training loss: 3.0240187763862387
Validation loss: 2.639484275385372

Epoch: 5| Step: 6
Training loss: 2.998805444037096
Validation loss: 2.6002143259586243

Epoch: 5| Step: 7
Training loss: 2.4403801554659754
Validation loss: 2.5589089441275457

Epoch: 5| Step: 8
Training loss: 3.115283814997574
Validation loss: 2.577421311208286

Epoch: 5| Step: 9
Training loss: 2.1807206962669365
Validation loss: 2.588900050909208

Epoch: 5| Step: 10
Training loss: 3.2832545379117004
Validation loss: 2.5973851833122987

Epoch: 60| Step: 0
Training loss: 3.1706018758570096
Validation loss: 2.586356428208429

Epoch: 5| Step: 1
Training loss: 3.10447037681077
Validation loss: 2.603071443342901

Epoch: 5| Step: 2
Training loss: 3.1405421004100935
Validation loss: 2.5704617671872243

Epoch: 5| Step: 3
Training loss: 2.7179285321134308
Validation loss: 2.580487875029156

Epoch: 5| Step: 4
Training loss: 2.9233391505161404
Validation loss: 2.5982189056699987

Epoch: 5| Step: 5
Training loss: 2.429840573705001
Validation loss: 2.6081628251553934

Epoch: 5| Step: 6
Training loss: 3.0091312044290706
Validation loss: 2.6050058547636694

Epoch: 5| Step: 7
Training loss: 3.499102204841865
Validation loss: 2.59150518204355

Epoch: 5| Step: 8
Training loss: 2.5389490659757517
Validation loss: 2.6134661333758866

Epoch: 5| Step: 9
Training loss: 2.2900215717615633
Validation loss: 2.6123994725009636

Epoch: 5| Step: 10
Training loss: 2.5819866505520803
Validation loss: 2.574319211506533

Epoch: 61| Step: 0
Training loss: 3.174970647721267
Validation loss: 2.585614518733718

Epoch: 5| Step: 1
Training loss: 2.1915247268065094
Validation loss: 2.6124224415413257

Epoch: 5| Step: 2
Training loss: 2.83928825056129
Validation loss: 2.5882381818310085

Epoch: 5| Step: 3
Training loss: 2.95974457798624
Validation loss: 2.5620829475186717

Epoch: 5| Step: 4
Training loss: 3.2500044015707874
Validation loss: 2.5982138982055645

Epoch: 5| Step: 5
Training loss: 2.4620600970670528
Validation loss: 2.5740750678360786

Epoch: 5| Step: 6
Training loss: 3.0905807137088686
Validation loss: 2.5811974507762425

Epoch: 5| Step: 7
Training loss: 2.8661736714996446
Validation loss: 2.593744890010548

Epoch: 5| Step: 8
Training loss: 3.2716280868621235
Validation loss: 2.5880924123119944

Epoch: 5| Step: 9
Training loss: 2.336796733303588
Validation loss: 2.6059443510231315

Epoch: 5| Step: 10
Training loss: 3.3268779872011587
Validation loss: 2.581730058941001

Epoch: 62| Step: 0
Training loss: 3.5650415556680595
Validation loss: 2.5677425531421214

Epoch: 5| Step: 1
Training loss: 2.6205996006345003
Validation loss: 2.599550356371837

Epoch: 5| Step: 2
Training loss: 2.6232119328652352
Validation loss: 2.591326680980698

Epoch: 5| Step: 3
Training loss: 2.8358981547503097
Validation loss: 2.5931402330541817

Epoch: 5| Step: 4
Training loss: 3.147701205730016
Validation loss: 2.6075885452279732

Epoch: 5| Step: 5
Training loss: 2.8532352087790116
Validation loss: 2.6043234310752252

Epoch: 5| Step: 6
Training loss: 2.5006834049740965
Validation loss: 2.602820150114126

Epoch: 5| Step: 7
Training loss: 3.1942084533946424
Validation loss: 2.625020870393369

Epoch: 5| Step: 8
Training loss: 2.343196854485523
Validation loss: 2.6090088355829875

Epoch: 5| Step: 9
Training loss: 2.986971858757589
Validation loss: 2.616784591896654

Epoch: 5| Step: 10
Training loss: 2.807567085150784
Validation loss: 2.59821017343512

Epoch: 63| Step: 0
Training loss: 2.5611861978071113
Validation loss: 2.6002651838990474

Epoch: 5| Step: 1
Training loss: 3.2618320468253383
Validation loss: 2.610186491862436

Epoch: 5| Step: 2
Training loss: 2.6306104195322817
Validation loss: 2.6044334094529504

Epoch: 5| Step: 3
Training loss: 2.9531411468225897
Validation loss: 2.602448356685547

Epoch: 5| Step: 4
Training loss: 2.6993560976893303
Validation loss: 2.594263551024833

Epoch: 5| Step: 5
Training loss: 2.91165691829011
Validation loss: 2.609005731513168

Epoch: 5| Step: 6
Training loss: 3.0578886853972094
Validation loss: 2.5944053394287536

Epoch: 5| Step: 7
Training loss: 2.9000456839284565
Validation loss: 2.6040329439018906

Epoch: 5| Step: 8
Training loss: 3.110831681448737
Validation loss: 2.5865981727710428

Epoch: 5| Step: 9
Training loss: 2.722403078061678
Validation loss: 2.6170137041890227

Epoch: 5| Step: 10
Training loss: 2.7334704837660344
Validation loss: 2.5983744993082882

Epoch: 64| Step: 0
Training loss: 2.493595120393582
Validation loss: 2.6003690775537773

Epoch: 5| Step: 1
Training loss: 3.3151556921483483
Validation loss: 2.604513082454253

Epoch: 5| Step: 2
Training loss: 2.930352463597696
Validation loss: 2.5741983077674013

Epoch: 5| Step: 3
Training loss: 3.522906278162159
Validation loss: 2.604754425334098

Epoch: 5| Step: 4
Training loss: 2.44451072150267
Validation loss: 2.591133338690739

Epoch: 5| Step: 5
Training loss: 2.946204902779608
Validation loss: 2.6181609164090314

Epoch: 5| Step: 6
Training loss: 2.4217274282472117
Validation loss: 2.575450462805757

Epoch: 5| Step: 7
Training loss: 2.640542384553833
Validation loss: 2.5897245198850967

Epoch: 5| Step: 8
Training loss: 2.4887586581789902
Validation loss: 2.6181223238563636

Epoch: 5| Step: 9
Training loss: 3.3618034634032807
Validation loss: 2.5866725773939914

Epoch: 5| Step: 10
Training loss: 2.6523880652881577
Validation loss: 2.6017251713235376

Epoch: 65| Step: 0
Training loss: 2.305144701075294
Validation loss: 2.603013655513823

Epoch: 5| Step: 1
Training loss: 2.2025975887921687
Validation loss: 2.6028680811473897

Epoch: 5| Step: 2
Training loss: 3.521969373059696
Validation loss: 2.6286362065900253

Epoch: 5| Step: 3
Training loss: 3.050491924951104
Validation loss: 2.581419110183157

Epoch: 5| Step: 4
Training loss: 2.57030953172321
Validation loss: 2.587346791546818

Epoch: 5| Step: 5
Training loss: 2.8592237422104656
Validation loss: 2.58601959269719

Epoch: 5| Step: 6
Training loss: 2.57237341907656
Validation loss: 2.591599263731014

Epoch: 5| Step: 7
Training loss: 3.2953442821172882
Validation loss: 2.5929764455116002

Epoch: 5| Step: 8
Training loss: 2.7818068043413238
Validation loss: 2.571913168559186

Epoch: 5| Step: 9
Training loss: 3.0037697313337706
Validation loss: 2.585653766030639

Epoch: 5| Step: 10
Training loss: 3.3212507291139053
Validation loss: 2.5942789159434683

Epoch: 66| Step: 0
Training loss: 2.8814085149293263
Validation loss: 2.6160275103163118

Epoch: 5| Step: 1
Training loss: 3.590506375231579
Validation loss: 2.5842957571205414

Epoch: 5| Step: 2
Training loss: 2.934116443947074
Validation loss: 2.582687314189867

Epoch: 5| Step: 3
Training loss: 2.787365822064478
Validation loss: 2.585424875221893

Epoch: 5| Step: 4
Training loss: 2.892957581352496
Validation loss: 2.6060119329347144

Epoch: 5| Step: 5
Training loss: 2.6948782308383863
Validation loss: 2.583987174780844

Epoch: 5| Step: 6
Training loss: 2.7479332179876605
Validation loss: 2.5855697401558975

Epoch: 5| Step: 7
Training loss: 2.8983713641165885
Validation loss: 2.582386561999941

Epoch: 5| Step: 8
Training loss: 2.603586411998348
Validation loss: 2.5810422499543955

Epoch: 5| Step: 9
Training loss: 2.735560568873693
Validation loss: 2.586607614700677

Epoch: 5| Step: 10
Training loss: 2.6365957725951104
Validation loss: 2.561875984412197

Epoch: 67| Step: 0
Training loss: 2.110547453382301
Validation loss: 2.564488103675651

Epoch: 5| Step: 1
Training loss: 3.01982401505604
Validation loss: 2.5862715588106058

Epoch: 5| Step: 2
Training loss: 3.105658221912548
Validation loss: 2.5953660890275083

Epoch: 5| Step: 3
Training loss: 3.615456877733908
Validation loss: 2.566321507018752

Epoch: 5| Step: 4
Training loss: 2.8950250901895735
Validation loss: 2.6065926187206894

Epoch: 5| Step: 5
Training loss: 2.8864143014883408
Validation loss: 2.6220131907639503

Epoch: 5| Step: 6
Training loss: 2.5708751120694115
Validation loss: 2.592187377405126

Epoch: 5| Step: 7
Training loss: 2.9632496525120513
Validation loss: 2.5742203882397585

Epoch: 5| Step: 8
Training loss: 2.847402386017893
Validation loss: 2.585094447697164

Epoch: 5| Step: 9
Training loss: 2.386901848445501
Validation loss: 2.585395278545384

Epoch: 5| Step: 10
Training loss: 3.079400277642757
Validation loss: 2.5829638939094353

Epoch: 68| Step: 0
Training loss: 2.7936272545119722
Validation loss: 2.5921569470734283

Epoch: 5| Step: 1
Training loss: 2.6502639639041883
Validation loss: 2.6067734801360003

Epoch: 5| Step: 2
Training loss: 3.145766116470468
Validation loss: 2.5788290594416217

Epoch: 5| Step: 3
Training loss: 3.066018399536106
Validation loss: 2.5604630404590654

Epoch: 5| Step: 4
Training loss: 2.917061660904772
Validation loss: 2.5960729816621657

Epoch: 5| Step: 5
Training loss: 2.855253991688947
Validation loss: 2.6055326978356894

Epoch: 5| Step: 6
Training loss: 2.9898808206134517
Validation loss: 2.587731223851747

Epoch: 5| Step: 7
Training loss: 2.9703284634919207
Validation loss: 2.603026245128528

Epoch: 5| Step: 8
Training loss: 2.749876019544112
Validation loss: 2.596194418501409

Epoch: 5| Step: 9
Training loss: 2.7899784753167385
Validation loss: 2.5773989652301807

Epoch: 5| Step: 10
Training loss: 3.0021006858760098
Validation loss: 2.5746710159632

Epoch: 69| Step: 0
Training loss: 3.3469218958713376
Validation loss: 2.5959125941899783

Epoch: 5| Step: 1
Training loss: 2.309448806760207
Validation loss: 2.5870297427136126

Epoch: 5| Step: 2
Training loss: 2.849214271518879
Validation loss: 2.5777600738306177

Epoch: 5| Step: 3
Training loss: 2.7839930005807694
Validation loss: 2.59600641492666

Epoch: 5| Step: 4
Training loss: 3.190437160421306
Validation loss: 2.568786556122603

Epoch: 5| Step: 5
Training loss: 2.57224245285453
Validation loss: 2.5654191788120126

Epoch: 5| Step: 6
Training loss: 2.8083985835191476
Validation loss: 2.606517510013627

Epoch: 5| Step: 7
Training loss: 2.8265324951063864
Validation loss: 2.583746667306102

Epoch: 5| Step: 8
Training loss: 2.882027702711967
Validation loss: 2.575677806429982

Epoch: 5| Step: 9
Training loss: 3.350051503710749
Validation loss: 2.570943360566829

Epoch: 5| Step: 10
Training loss: 2.683242352840751
Validation loss: 2.5696696703671913

Epoch: 70| Step: 0
Training loss: 3.028150409162777
Validation loss: 2.6051287272297947

Epoch: 5| Step: 1
Training loss: 2.4526591253424788
Validation loss: 2.6208050673416867

Epoch: 5| Step: 2
Training loss: 3.137103787515647
Validation loss: 2.571004554520855

Epoch: 5| Step: 3
Training loss: 2.469743456317022
Validation loss: 2.613262844328973

Epoch: 5| Step: 4
Training loss: 2.4436676050525272
Validation loss: 2.6082440993950353

Epoch: 5| Step: 5
Training loss: 3.153737191542033
Validation loss: 2.5981275926694485

Epoch: 5| Step: 6
Training loss: 3.258189520300394
Validation loss: 2.588210962846452

Epoch: 5| Step: 7
Training loss: 2.729954574262924
Validation loss: 2.5999345692896267

Epoch: 5| Step: 8
Training loss: 3.1390592553220227
Validation loss: 2.595446260637716

Epoch: 5| Step: 9
Training loss: 2.9190567214854717
Validation loss: 2.6141720876403105

Epoch: 5| Step: 10
Training loss: 2.960405206266623
Validation loss: 2.606671384840124

Epoch: 71| Step: 0
Training loss: 2.7039923186052004
Validation loss: 2.598849852840417

Epoch: 5| Step: 1
Training loss: 3.263774877049439
Validation loss: 2.5554740582752133

Epoch: 5| Step: 2
Training loss: 3.094014628488571
Validation loss: 2.6036415089050244

Epoch: 5| Step: 3
Training loss: 2.139314904936085
Validation loss: 2.582326234915573

Epoch: 5| Step: 4
Training loss: 3.084367492728484
Validation loss: 2.5759894064244233

Epoch: 5| Step: 5
Training loss: 2.6320111331414364
Validation loss: 2.5907359079660637

Epoch: 5| Step: 6
Training loss: 3.2502497063589626
Validation loss: 2.5758739106530415

Epoch: 5| Step: 7
Training loss: 2.983611004088546
Validation loss: 2.5870193069024046

Epoch: 5| Step: 8
Training loss: 3.145133506961402
Validation loss: 2.5761353731634515

Epoch: 5| Step: 9
Training loss: 2.645527639276018
Validation loss: 2.6061166313638156

Epoch: 5| Step: 10
Training loss: 2.4217684814655227
Validation loss: 2.595013898251568

Epoch: 72| Step: 0
Training loss: 3.04551846554885
Validation loss: 2.598087097109522

Epoch: 5| Step: 1
Training loss: 3.3920778598576455
Validation loss: 2.6016053946354614

Epoch: 5| Step: 2
Training loss: 3.1537459609844576
Validation loss: 2.614616416058696

Epoch: 5| Step: 3
Training loss: 2.892777255130912
Validation loss: 2.581221148376268

Epoch: 5| Step: 4
Training loss: 2.907951431194146
Validation loss: 2.594981076704247

Epoch: 5| Step: 5
Training loss: 2.1503487148930263
Validation loss: 2.598800143075809

Epoch: 5| Step: 6
Training loss: 2.8893499088043684
Validation loss: 2.5897558994204655

Epoch: 5| Step: 7
Training loss: 3.008436262178627
Validation loss: 2.589339417701273

Epoch: 5| Step: 8
Training loss: 2.3580449883955485
Validation loss: 2.5797151436581136

Epoch: 5| Step: 9
Training loss: 3.108823947862946
Validation loss: 2.6143847863513474

Epoch: 5| Step: 10
Training loss: 2.4462987111523793
Validation loss: 2.59576239405904

Epoch: 73| Step: 0
Training loss: 2.6927134491055935
Validation loss: 2.584096111878304

Epoch: 5| Step: 1
Training loss: 2.2111414084070726
Validation loss: 2.5919969913294802

Epoch: 5| Step: 2
Training loss: 2.7108316978014204
Validation loss: 2.5982438214855166

Epoch: 5| Step: 3
Training loss: 2.956117435894556
Validation loss: 2.5872025740788955

Epoch: 5| Step: 4
Training loss: 2.828913963242039
Validation loss: 2.5542515644953374

Epoch: 5| Step: 5
Training loss: 2.675220469721139
Validation loss: 2.587996771739278

Epoch: 5| Step: 6
Training loss: 3.0386010140756716
Validation loss: 2.5623295384897404

Epoch: 5| Step: 7
Training loss: 3.1528738868916193
Validation loss: 2.5651743259874196

Epoch: 5| Step: 8
Training loss: 2.408362910035177
Validation loss: 2.60828110823023

Epoch: 5| Step: 9
Training loss: 3.66954960338282
Validation loss: 2.5801275019306695

Epoch: 5| Step: 10
Training loss: 3.0662871319419347
Validation loss: 2.576675969393737

Epoch: 74| Step: 0
Training loss: 2.954044098098114
Validation loss: 2.590372767302132

Epoch: 5| Step: 1
Training loss: 2.8390852008220633
Validation loss: 2.5689870588187524

Epoch: 5| Step: 2
Training loss: 2.940322169603115
Validation loss: 2.610828341001391

Epoch: 5| Step: 3
Training loss: 2.8301081158909525
Validation loss: 2.6077470107911864

Epoch: 5| Step: 4
Training loss: 2.892488116319885
Validation loss: 2.5748189541723008

Epoch: 5| Step: 5
Training loss: 2.800625125039661
Validation loss: 2.6108989179537363

Epoch: 5| Step: 6
Training loss: 2.626382191384599
Validation loss: 2.5688463484060335

Epoch: 5| Step: 7
Training loss: 2.5436945053908047
Validation loss: 2.5762249828553188

Epoch: 5| Step: 8
Training loss: 2.754927209214441
Validation loss: 2.593585308967998

Epoch: 5| Step: 9
Training loss: 3.407650860744526
Validation loss: 2.572649596430129

Epoch: 5| Step: 10
Training loss: 2.786139658355592
Validation loss: 2.609354822381559

Epoch: 75| Step: 0
Training loss: 3.2220042545946423
Validation loss: 2.6154447779674754

Epoch: 5| Step: 1
Training loss: 2.301039987209174
Validation loss: 2.6006229370231084

Epoch: 5| Step: 2
Training loss: 3.296004772590219
Validation loss: 2.579142042054377

Epoch: 5| Step: 3
Training loss: 3.2140459667590986
Validation loss: 2.593031462361932

Epoch: 5| Step: 4
Training loss: 2.52704742439673
Validation loss: 2.5818119557569665

Epoch: 5| Step: 5
Training loss: 2.8314760703130393
Validation loss: 2.559437279830763

Epoch: 5| Step: 6
Training loss: 2.820271415094186
Validation loss: 2.5691477985599342

Epoch: 5| Step: 7
Training loss: 2.8597808716597735
Validation loss: 2.615845163998586

Epoch: 5| Step: 8
Training loss: 2.7831933593578673
Validation loss: 2.5705372302903218

Epoch: 5| Step: 9
Training loss: 3.030840501948988
Validation loss: 2.5913633922543253

Epoch: 5| Step: 10
Training loss: 2.4924531514041703
Validation loss: 2.58806818032006

Epoch: 76| Step: 0
Training loss: 2.7039562556887313
Validation loss: 2.594917249199299

Epoch: 5| Step: 1
Training loss: 2.4663699302379567
Validation loss: 2.5928356675721274

Epoch: 5| Step: 2
Training loss: 3.2489914429593902
Validation loss: 2.5756775814861608

Epoch: 5| Step: 3
Training loss: 2.7943777518364437
Validation loss: 2.5989248872150608

Epoch: 5| Step: 4
Training loss: 2.0023912201671017
Validation loss: 2.589425261735015

Epoch: 5| Step: 5
Training loss: 2.893138225967723
Validation loss: 2.5937730294213512

Epoch: 5| Step: 6
Training loss: 3.362003735078987
Validation loss: 2.5724623695326376

Epoch: 5| Step: 7
Training loss: 2.7028667348624094
Validation loss: 2.58624643844137

Epoch: 5| Step: 8
Training loss: 2.849824391358961
Validation loss: 2.598570483496309

Epoch: 5| Step: 9
Training loss: 2.894070278429544
Validation loss: 2.5754630239102143

Epoch: 5| Step: 10
Training loss: 3.3851896395732433
Validation loss: 2.5598795528334595

Epoch: 77| Step: 0
Training loss: 2.5557629482684225
Validation loss: 2.5786697274610364

Epoch: 5| Step: 1
Training loss: 2.3546246333548506
Validation loss: 2.5866270073933184

Epoch: 5| Step: 2
Training loss: 3.0198789645565745
Validation loss: 2.5564694117857503

Epoch: 5| Step: 3
Training loss: 3.2122402100961254
Validation loss: 2.6033972947829853

Epoch: 5| Step: 4
Training loss: 3.1228321948766955
Validation loss: 2.579821043459202

Epoch: 5| Step: 5
Training loss: 2.5618324340649314
Validation loss: 2.571385032384826

Epoch: 5| Step: 6
Training loss: 2.690932277806834
Validation loss: 2.555527971450842

Epoch: 5| Step: 7
Training loss: 2.8837477244751364
Validation loss: 2.591450056616378

Epoch: 5| Step: 8
Training loss: 2.978393792334109
Validation loss: 2.565579351687285

Epoch: 5| Step: 9
Training loss: 3.421470583354296
Validation loss: 2.5770904901691156

Epoch: 5| Step: 10
Training loss: 2.444180162429184
Validation loss: 2.571776068297825

Epoch: 78| Step: 0
Training loss: 2.7588582852211436
Validation loss: 2.566513689844262

Epoch: 5| Step: 1
Training loss: 3.216676803599248
Validation loss: 2.5939648773106256

Epoch: 5| Step: 2
Training loss: 2.9637727474142532
Validation loss: 2.611569342648363

Epoch: 5| Step: 3
Training loss: 3.034684585194351
Validation loss: 2.565197179213683

Epoch: 5| Step: 4
Training loss: 2.6659390728478245
Validation loss: 2.559544148826112

Epoch: 5| Step: 5
Training loss: 1.9237869800485947
Validation loss: 2.5817708259588197

Epoch: 5| Step: 6
Training loss: 2.963523037834592
Validation loss: 2.589353022783327

Epoch: 5| Step: 7
Training loss: 2.916252070433155
Validation loss: 2.6210873963814953

Epoch: 5| Step: 8
Training loss: 2.8898787901384195
Validation loss: 2.576171924756785

Epoch: 5| Step: 9
Training loss: 2.556458025910973
Validation loss: 2.573880836033061

Epoch: 5| Step: 10
Training loss: 3.303425288558069
Validation loss: 2.576205821840913

Epoch: 79| Step: 0
Training loss: 2.2248571457169235
Validation loss: 2.588684369929776

Epoch: 5| Step: 1
Training loss: 3.7879861148309852
Validation loss: 2.615012851627745

Epoch: 5| Step: 2
Training loss: 3.071398361032134
Validation loss: 2.6147203816838984

Epoch: 5| Step: 3
Training loss: 3.055708536499216
Validation loss: 2.5471372959384295

Epoch: 5| Step: 4
Training loss: 2.433361452628229
Validation loss: 2.614839812284236

Epoch: 5| Step: 5
Training loss: 2.9508239823798017
Validation loss: 2.6093745372551487

Epoch: 5| Step: 6
Training loss: 3.138520555818756
Validation loss: 2.571056697213518

Epoch: 5| Step: 7
Training loss: 3.0892086413193347
Validation loss: 2.5699713511398583

Epoch: 5| Step: 8
Training loss: 2.5941465143666207
Validation loss: 2.568140091244117

Epoch: 5| Step: 9
Training loss: 1.7955659161256714
Validation loss: 2.6112731726064498

Epoch: 5| Step: 10
Training loss: 2.8474921452629127
Validation loss: 2.599233652973738

Epoch: 80| Step: 0
Training loss: 3.1434752023773664
Validation loss: 2.590239435143971

Epoch: 5| Step: 1
Training loss: 2.7613697829715065
Validation loss: 2.5574427176343693

Epoch: 5| Step: 2
Training loss: 3.4259104166071226
Validation loss: 2.5991838963014766

Epoch: 5| Step: 3
Training loss: 2.7520437449039115
Validation loss: 2.588637514226344

Epoch: 5| Step: 4
Training loss: 3.10376759125068
Validation loss: 2.5586058006951578

Epoch: 5| Step: 5
Training loss: 2.4787336874313035
Validation loss: 2.5903066785844246

Epoch: 5| Step: 6
Training loss: 2.8935298036708463
Validation loss: 2.5766131301420945

Epoch: 5| Step: 7
Training loss: 3.0254142666724753
Validation loss: 2.5951679039384987

Epoch: 5| Step: 8
Training loss: 2.5425611600018305
Validation loss: 2.5898876291334036

Epoch: 5| Step: 9
Training loss: 2.162935259459929
Validation loss: 2.5879037200974095

Epoch: 5| Step: 10
Training loss: 3.064911807410946
Validation loss: 2.5871543062450817

Epoch: 81| Step: 0
Training loss: 2.8005910726380847
Validation loss: 2.573823934688191

Epoch: 5| Step: 1
Training loss: 3.3879692118663356
Validation loss: 2.5645223631215184

Epoch: 5| Step: 2
Training loss: 3.2658594950758597
Validation loss: 2.6100350539203343

Epoch: 5| Step: 3
Training loss: 2.7451927475926983
Validation loss: 2.5679162014175714

Epoch: 5| Step: 4
Training loss: 2.725661864089358
Validation loss: 2.5946125415477956

Epoch: 5| Step: 5
Training loss: 2.9381722837537207
Validation loss: 2.6100770048869535

Epoch: 5| Step: 6
Training loss: 3.133561727302642
Validation loss: 2.5971919090466358

Epoch: 5| Step: 7
Training loss: 3.113212479390621
Validation loss: 2.6201963992552253

Epoch: 5| Step: 8
Training loss: 1.8699686574094239
Validation loss: 2.570903175721466

Epoch: 5| Step: 9
Training loss: 2.189482199537942
Validation loss: 2.5766405144263067

Epoch: 5| Step: 10
Training loss: 3.032801752007536
Validation loss: 2.574248279983073

Epoch: 82| Step: 0
Training loss: 3.2916665539962815
Validation loss: 2.5697222082729723

Epoch: 5| Step: 1
Training loss: 3.3070538933454365
Validation loss: 2.580343821644185

Epoch: 5| Step: 2
Training loss: 3.217453630731259
Validation loss: 2.5864932284053945

Epoch: 5| Step: 3
Training loss: 2.464048713834195
Validation loss: 2.598153633230792

Epoch: 5| Step: 4
Training loss: 2.3745333564489406
Validation loss: 2.5856522956558377

Epoch: 5| Step: 5
Training loss: 2.8516919250380375
Validation loss: 2.5808822669039

Epoch: 5| Step: 6
Training loss: 2.7405522788131074
Validation loss: 2.571011044869464

Epoch: 5| Step: 7
Training loss: 2.5326231069665535
Validation loss: 2.592967187435304

Epoch: 5| Step: 8
Training loss: 3.0888920414250642
Validation loss: 2.5914363829072284

Epoch: 5| Step: 9
Training loss: 2.562815018806015
Validation loss: 2.575869101098938

Epoch: 5| Step: 10
Training loss: 2.901789369685627
Validation loss: 2.587385091102185

Epoch: 83| Step: 0
Training loss: 2.536304278594294
Validation loss: 2.5903382994805293

Epoch: 5| Step: 1
Training loss: 2.3466549989923218
Validation loss: 2.5817485474169417

Epoch: 5| Step: 2
Training loss: 3.1012410110165
Validation loss: 2.5996522993969355

Epoch: 5| Step: 3
Training loss: 3.191373976657502
Validation loss: 2.5832028089715133

Epoch: 5| Step: 4
Training loss: 2.7599510136002676
Validation loss: 2.582184432548291

Epoch: 5| Step: 5
Training loss: 3.261166536104603
Validation loss: 2.587637754976942

Epoch: 5| Step: 6
Training loss: 2.965243386737475
Validation loss: 2.5828657428372432

Epoch: 5| Step: 7
Training loss: 2.642739256508872
Validation loss: 2.5713799477397794

Epoch: 5| Step: 8
Training loss: 3.034727166872824
Validation loss: 2.563040515509601

Epoch: 5| Step: 9
Training loss: 2.6631893393876407
Validation loss: 2.5655514356463955

Epoch: 5| Step: 10
Training loss: 2.49655868188096
Validation loss: 2.568395004171936

Epoch: 84| Step: 0
Training loss: 2.51608774419107
Validation loss: 2.5409734908049906

Epoch: 5| Step: 1
Training loss: 2.813811017819115
Validation loss: 2.570361566834203

Epoch: 5| Step: 2
Training loss: 3.1508370997754374
Validation loss: 2.607639043057789

Epoch: 5| Step: 3
Training loss: 2.390965456187752
Validation loss: 2.5895212143654267

Epoch: 5| Step: 4
Training loss: 3.090150376645247
Validation loss: 2.566900603036207

Epoch: 5| Step: 5
Training loss: 2.2157336941463077
Validation loss: 2.584504679331969

Epoch: 5| Step: 6
Training loss: 2.8350753104081794
Validation loss: 2.5659931598535684

Epoch: 5| Step: 7
Training loss: 3.279481538409174
Validation loss: 2.570959980170754

Epoch: 5| Step: 8
Training loss: 2.730151069289943
Validation loss: 2.566217568603091

Epoch: 5| Step: 9
Training loss: 2.608526765843617
Validation loss: 2.582458719849744

Epoch: 5| Step: 10
Training loss: 3.4553777328671944
Validation loss: 2.5786813304136067

Epoch: 85| Step: 0
Training loss: 3.3997408768139934
Validation loss: 2.57970357715616

Epoch: 5| Step: 1
Training loss: 3.1630179482408183
Validation loss: 2.5594633244012512

Epoch: 5| Step: 2
Training loss: 2.5617580735381016
Validation loss: 2.5484253722904646

Epoch: 5| Step: 3
Training loss: 2.8037946124530593
Validation loss: 2.5522565748134642

Epoch: 5| Step: 4
Training loss: 2.3013058438381337
Validation loss: 2.606957406998033

Epoch: 5| Step: 5
Training loss: 2.759830158232354
Validation loss: 2.5853970931463297

Epoch: 5| Step: 6
Training loss: 2.955528129204994
Validation loss: 2.5822694839281715

Epoch: 5| Step: 7
Training loss: 2.701186968250267
Validation loss: 2.581218397241074

Epoch: 5| Step: 8
Training loss: 2.6881911697527614
Validation loss: 2.598643244093698

Epoch: 5| Step: 9
Training loss: 2.7142554654321724
Validation loss: 2.5906847046259136

Epoch: 5| Step: 10
Training loss: 2.987992735255141
Validation loss: 2.5591504900677733

Epoch: 86| Step: 0
Training loss: 2.9791936984314122
Validation loss: 2.5815453476367307

Epoch: 5| Step: 1
Training loss: 3.0817945266147224
Validation loss: 2.567832822119255

Epoch: 5| Step: 2
Training loss: 2.160406115465385
Validation loss: 2.546004521480943

Epoch: 5| Step: 3
Training loss: 3.3725585584031594
Validation loss: 2.5747606865760706

Epoch: 5| Step: 4
Training loss: 2.9372457840671946
Validation loss: 2.543424442974599

Epoch: 5| Step: 5
Training loss: 3.157884533346992
Validation loss: 2.5906893743602253

Epoch: 5| Step: 6
Training loss: 2.671592474383421
Validation loss: 2.583655027378664

Epoch: 5| Step: 7
Training loss: 2.5070863427052235
Validation loss: 2.570212606027446

Epoch: 5| Step: 8
Training loss: 2.788246355936656
Validation loss: 2.5944574752481198

Epoch: 5| Step: 9
Training loss: 2.420156940068761
Validation loss: 2.563851402086377

Epoch: 5| Step: 10
Training loss: 2.992380001559038
Validation loss: 2.588135012639901

Epoch: 87| Step: 0
Training loss: 3.529187840950298
Validation loss: 2.582627220454544

Epoch: 5| Step: 1
Training loss: 2.8785832507280507
Validation loss: 2.592956128914474

Epoch: 5| Step: 2
Training loss: 2.918223011219823
Validation loss: 2.5793073750145554

Epoch: 5| Step: 3
Training loss: 2.3173881623937405
Validation loss: 2.5933359435594756

Epoch: 5| Step: 4
Training loss: 2.8994063328774535
Validation loss: 2.593933218592987

Epoch: 5| Step: 5
Training loss: 2.005279011327113
Validation loss: 2.554982663824182

Epoch: 5| Step: 6
Training loss: 3.1724878480165986
Validation loss: 2.5767648280345705

Epoch: 5| Step: 7
Training loss: 2.630314578689673
Validation loss: 2.6363895348373214

Epoch: 5| Step: 8
Training loss: 2.608146423939284
Validation loss: 2.5868957209440215

Epoch: 5| Step: 9
Training loss: 2.9007614977529097
Validation loss: 2.5834909371825527

Epoch: 5| Step: 10
Training loss: 3.292168317466436
Validation loss: 2.57512286998474

Epoch: 88| Step: 0
Training loss: 3.205992071473901
Validation loss: 2.6074794835281114

Epoch: 5| Step: 1
Training loss: 2.518263102910607
Validation loss: 2.584713874275562

Epoch: 5| Step: 2
Training loss: 2.093009931807777
Validation loss: 2.5865336438190916

Epoch: 5| Step: 3
Training loss: 3.357553813443421
Validation loss: 2.617611904320444

Epoch: 5| Step: 4
Training loss: 2.4490547186087923
Validation loss: 2.5863720289268106

Epoch: 5| Step: 5
Training loss: 3.0185188283922297
Validation loss: 2.5603105168711218

Epoch: 5| Step: 6
Training loss: 3.0729250288165266
Validation loss: 2.581779718058043

Epoch: 5| Step: 7
Training loss: 2.9685516291146494
Validation loss: 2.5919105490081704

Epoch: 5| Step: 8
Training loss: 2.4222626406634777
Validation loss: 2.5660433448101503

Epoch: 5| Step: 9
Training loss: 3.0741816788683685
Validation loss: 2.567803970137029

Epoch: 5| Step: 10
Training loss: 2.8620769471301686
Validation loss: 2.595921712884608

Epoch: 89| Step: 0
Training loss: 2.9411510746925327
Validation loss: 2.5438959225832396

Epoch: 5| Step: 1
Training loss: 2.7409468667337067
Validation loss: 2.5711107243553073

Epoch: 5| Step: 2
Training loss: 3.1851657473376007
Validation loss: 2.5752465938550593

Epoch: 5| Step: 3
Training loss: 3.282661642959597
Validation loss: 2.5634465104005235

Epoch: 5| Step: 4
Training loss: 2.679895331772831
Validation loss: 2.57159260393716

Epoch: 5| Step: 5
Training loss: 2.9440793964729988
Validation loss: 2.586046691994281

Epoch: 5| Step: 6
Training loss: 2.5767639266489275
Validation loss: 2.5716038699671357

Epoch: 5| Step: 7
Training loss: 2.3154878645224493
Validation loss: 2.5571706053278627

Epoch: 5| Step: 8
Training loss: 2.8646646569008007
Validation loss: 2.5740586914383625

Epoch: 5| Step: 9
Training loss: 3.3498453930151
Validation loss: 2.5604851487666602

Epoch: 5| Step: 10
Training loss: 2.224963125716271
Validation loss: 2.6021070687951466

Epoch: 90| Step: 0
Training loss: 3.0841470280492467
Validation loss: 2.6023733012563026

Epoch: 5| Step: 1
Training loss: 3.2464149949627576
Validation loss: 2.6120985815996205

Epoch: 5| Step: 2
Training loss: 1.964125940091895
Validation loss: 2.60176950360557

Epoch: 5| Step: 3
Training loss: 2.9029558442503034
Validation loss: 2.553318905073807

Epoch: 5| Step: 4
Training loss: 3.1615260377240344
Validation loss: 2.587155564702224

Epoch: 5| Step: 5
Training loss: 2.6231344042253375
Validation loss: 2.545993780568226

Epoch: 5| Step: 6
Training loss: 2.5955351236252637
Validation loss: 2.5963345611033137

Epoch: 5| Step: 7
Training loss: 2.418127791146023
Validation loss: 2.573598540092801

Epoch: 5| Step: 8
Training loss: 2.994726951010459
Validation loss: 2.595077034822826

Epoch: 5| Step: 9
Training loss: 2.746345432517675
Validation loss: 2.568793761649035

Epoch: 5| Step: 10
Training loss: 3.4812509533317533
Validation loss: 2.5469436520498068

Epoch: 91| Step: 0
Training loss: 2.9025900159968088
Validation loss: 2.596919769193024

Epoch: 5| Step: 1
Training loss: 3.3025059635128726
Validation loss: 2.5177187600185644

Epoch: 5| Step: 2
Training loss: 2.5227473115242307
Validation loss: 2.558006345315888

Epoch: 5| Step: 3
Training loss: 2.930305761586029
Validation loss: 2.57652603637323

Epoch: 5| Step: 4
Training loss: 2.857232296769914
Validation loss: 2.556077548685523

Epoch: 5| Step: 5
Training loss: 2.5644707893408194
Validation loss: 2.546600438728277

Epoch: 5| Step: 6
Training loss: 3.1200669071163865
Validation loss: 2.548695150233771

Epoch: 5| Step: 7
Training loss: 2.9947624581059777
Validation loss: 2.5777514567751987

Epoch: 5| Step: 8
Training loss: 2.4595122554727302
Validation loss: 2.6046372104606896

Epoch: 5| Step: 9
Training loss: 2.8378113159943434
Validation loss: 2.6155793736253137

Epoch: 5| Step: 10
Training loss: 2.7459411144569255
Validation loss: 2.5780380010608615

Epoch: 92| Step: 0
Training loss: 2.6683824701528533
Validation loss: 2.56457094495217

Epoch: 5| Step: 1
Training loss: 2.8764374498064313
Validation loss: 2.5465573268062554

Epoch: 5| Step: 2
Training loss: 3.2771368495664217
Validation loss: 2.579281582506163

Epoch: 5| Step: 3
Training loss: 2.93769592281092
Validation loss: 2.56454036036845

Epoch: 5| Step: 4
Training loss: 2.5465227129163175
Validation loss: 2.5608289398742663

Epoch: 5| Step: 5
Training loss: 2.8320100349420896
Validation loss: 2.561305372135001

Epoch: 5| Step: 6
Training loss: 2.8446171035948673
Validation loss: 2.5714236005856135

Epoch: 5| Step: 7
Training loss: 2.6193180351279852
Validation loss: 2.576800706110821

Epoch: 5| Step: 8
Training loss: 3.384059614454528
Validation loss: 2.5934110484995165

Epoch: 5| Step: 9
Training loss: 2.6766245605970056
Validation loss: 2.557578782477121

Epoch: 5| Step: 10
Training loss: 2.317672203439571
Validation loss: 2.5652817284844027

Epoch: 93| Step: 0
Training loss: 2.63084487514564
Validation loss: 2.5359461053362806

Epoch: 5| Step: 1
Training loss: 2.617888672690284
Validation loss: 2.5644221236377547

Epoch: 5| Step: 2
Training loss: 2.876859146727532
Validation loss: 2.5874553236458935

Epoch: 5| Step: 3
Training loss: 2.8347382334804667
Validation loss: 2.591031427568786

Epoch: 5| Step: 4
Training loss: 3.1651431651828195
Validation loss: 2.561082622551528

Epoch: 5| Step: 5
Training loss: 2.7727440195388002
Validation loss: 2.57149588611464

Epoch: 5| Step: 6
Training loss: 2.924880170405357
Validation loss: 2.6113626289436644

Epoch: 5| Step: 7
Training loss: 2.9758934410460562
Validation loss: 2.5781937725183237

Epoch: 5| Step: 8
Training loss: 3.1849542062961618
Validation loss: 2.5648214433114638

Epoch: 5| Step: 9
Training loss: 2.4498216291619013
Validation loss: 2.5768270935191553

Epoch: 5| Step: 10
Training loss: 2.589672422423857
Validation loss: 2.57823449303489

Epoch: 94| Step: 0
Training loss: 3.0723900984996027
Validation loss: 2.5797405641408813

Epoch: 5| Step: 1
Training loss: 2.9799492259468434
Validation loss: 2.566123551383827

Epoch: 5| Step: 2
Training loss: 3.0294929996755244
Validation loss: 2.5976740270637495

Epoch: 5| Step: 3
Training loss: 2.595672813910212
Validation loss: 2.5496483328874286

Epoch: 5| Step: 4
Training loss: 3.0200130181947755
Validation loss: 2.5829179964474247

Epoch: 5| Step: 5
Training loss: 2.99008160380892
Validation loss: 2.5792956695216134

Epoch: 5| Step: 6
Training loss: 2.7231108670396535
Validation loss: 2.561319898325998

Epoch: 5| Step: 7
Training loss: 3.0529333673347248
Validation loss: 2.581329848148393

Epoch: 5| Step: 8
Training loss: 2.6836797486675272
Validation loss: 2.582065626167547

Epoch: 5| Step: 9
Training loss: 2.3895337974072297
Validation loss: 2.5702613545955275

Epoch: 5| Step: 10
Training loss: 2.40110446629901
Validation loss: 2.5698412570963436

Epoch: 95| Step: 0
Training loss: 2.759119604783337
Validation loss: 2.571248100380123

Epoch: 5| Step: 1
Training loss: 2.75824152821547
Validation loss: 2.56740351220083

Epoch: 5| Step: 2
Training loss: 2.1012179294296884
Validation loss: 2.588462781014636

Epoch: 5| Step: 3
Training loss: 2.0897205352111565
Validation loss: 2.582665243569489

Epoch: 5| Step: 4
Training loss: 3.0693465016323134
Validation loss: 2.5674843233137183

Epoch: 5| Step: 5
Training loss: 2.130972379350604
Validation loss: 2.5722577753968108

Epoch: 5| Step: 6
Training loss: 2.7175062996125394
Validation loss: 2.596667991209866

Epoch: 5| Step: 7
Training loss: 2.83624081001121
Validation loss: 2.6089279246693113

Epoch: 5| Step: 8
Training loss: 3.0951898480242694
Validation loss: 2.57456413261392

Epoch: 5| Step: 9
Training loss: 3.323346212879299
Validation loss: 2.5483668070354475

Epoch: 5| Step: 10
Training loss: 3.9607636603555836
Validation loss: 2.5804166461280014

Epoch: 96| Step: 0
Training loss: 3.4248365711286763
Validation loss: 2.592548635260378

Epoch: 5| Step: 1
Training loss: 2.2809595419553923
Validation loss: 2.5627411129394426

Epoch: 5| Step: 2
Training loss: 3.0389234810146033
Validation loss: 2.5516091581569946

Epoch: 5| Step: 3
Training loss: 2.9430666184968772
Validation loss: 2.5789495070141406

Epoch: 5| Step: 4
Training loss: 2.389801980757541
Validation loss: 2.5640009614279933

Epoch: 5| Step: 5
Training loss: 2.85995477520592
Validation loss: 2.5793909489213593

Epoch: 5| Step: 6
Training loss: 2.341736602643882
Validation loss: 2.585114267756493

Epoch: 5| Step: 7
Training loss: 2.872820318172609
Validation loss: 2.5690724772572024

Epoch: 5| Step: 8
Training loss: 3.0233375079355014
Validation loss: 2.556641381064319

Epoch: 5| Step: 9
Training loss: 3.058543549536148
Validation loss: 2.58197797859597

Epoch: 5| Step: 10
Training loss: 2.620930014213332
Validation loss: 2.5592352085500334

Epoch: 97| Step: 0
Training loss: 2.8504884134032697
Validation loss: 2.582480630920626

Epoch: 5| Step: 1
Training loss: 2.4306152142665893
Validation loss: 2.5621570434691634

Epoch: 5| Step: 2
Training loss: 2.8693829272473743
Validation loss: 2.572294598359696

Epoch: 5| Step: 3
Training loss: 2.798884261447456
Validation loss: 2.5700060751563747

Epoch: 5| Step: 4
Training loss: 2.3802562572459904
Validation loss: 2.582800239221374

Epoch: 5| Step: 5
Training loss: 2.7804834402435317
Validation loss: 2.5891307257046776

Epoch: 5| Step: 6
Training loss: 2.665674879495132
Validation loss: 2.5674283526200563

Epoch: 5| Step: 7
Training loss: 3.150874782378074
Validation loss: 2.6176460747174444

Epoch: 5| Step: 8
Training loss: 2.7989506185576967
Validation loss: 2.58580254023907

Epoch: 5| Step: 9
Training loss: 2.6417264729016505
Validation loss: 2.581152552861593

Epoch: 5| Step: 10
Training loss: 3.6740155413054403
Validation loss: 2.5902648612122294

Epoch: 98| Step: 0
Training loss: 3.3569892395956145
Validation loss: 2.5962120515319094

Epoch: 5| Step: 1
Training loss: 2.415689358464602
Validation loss: 2.6049314088923663

Epoch: 5| Step: 2
Training loss: 2.887243158716659
Validation loss: 2.567765773882934

Epoch: 5| Step: 3
Training loss: 2.860162845323675
Validation loss: 2.596907274360504

Epoch: 5| Step: 4
Training loss: 3.0355750620997006
Validation loss: 2.590651364121015

Epoch: 5| Step: 5
Training loss: 2.693973285953238
Validation loss: 2.589160916343607

Epoch: 5| Step: 6
Training loss: 2.7570318138271155
Validation loss: 2.569152859682733

Epoch: 5| Step: 7
Training loss: 2.803327480390186
Validation loss: 2.569249504060706

Epoch: 5| Step: 8
Training loss: 1.8955543508422728
Validation loss: 2.5739128504548288

Epoch: 5| Step: 9
Training loss: 3.1008593629439765
Validation loss: 2.605891686521351

Epoch: 5| Step: 10
Training loss: 2.9794657808257052
Validation loss: 2.593379277247991

Epoch: 99| Step: 0
Training loss: 2.7036068878180908
Validation loss: 2.5576217652516515

Epoch: 5| Step: 1
Training loss: 3.1845801949018697
Validation loss: 2.589683710774538

Epoch: 5| Step: 2
Training loss: 3.308260525944039
Validation loss: 2.560662072430212

Epoch: 5| Step: 3
Training loss: 2.021869655879179
Validation loss: 2.561062511405646

Epoch: 5| Step: 4
Training loss: 2.718995971076228
Validation loss: 2.5687506469505386

Epoch: 5| Step: 5
Training loss: 2.8105812309238347
Validation loss: 2.5715089590246083

Epoch: 5| Step: 6
Training loss: 2.8284970876494304
Validation loss: 2.5832213742397405

Epoch: 5| Step: 7
Training loss: 2.7881317722808676
Validation loss: 2.6057610728226233

Epoch: 5| Step: 8
Training loss: 3.2237370938430643
Validation loss: 2.5944878252393258

Epoch: 5| Step: 9
Training loss: 2.1118642177571845
Validation loss: 2.5742255539165964

Epoch: 5| Step: 10
Training loss: 3.4019748562214978
Validation loss: 2.595859344462186

Epoch: 100| Step: 0
Training loss: 2.7302342042615373
Validation loss: 2.5913225871883534

Epoch: 5| Step: 1
Training loss: 2.737745115550114
Validation loss: 2.5939388154530576

Epoch: 5| Step: 2
Training loss: 2.526786164885957
Validation loss: 2.5642527026850566

Epoch: 5| Step: 3
Training loss: 2.549489089795843
Validation loss: 2.569499179649169

Epoch: 5| Step: 4
Training loss: 3.0367311297322104
Validation loss: 2.5888339206343733

Epoch: 5| Step: 5
Training loss: 2.4593458084254687
Validation loss: 2.577403537687028

Epoch: 5| Step: 6
Training loss: 2.600665146770618
Validation loss: 2.568022123575454

Epoch: 5| Step: 7
Training loss: 3.022273665189803
Validation loss: 2.5790715861078093

Epoch: 5| Step: 8
Training loss: 3.2603716049899147
Validation loss: 2.6133909367529222

Epoch: 5| Step: 9
Training loss: 2.85916920739549
Validation loss: 2.5494793409628005

Epoch: 5| Step: 10
Training loss: 3.263199338827887
Validation loss: 2.5403192415946325

Epoch: 101| Step: 0
Training loss: 2.5738635360775937
Validation loss: 2.586954323681895

Epoch: 5| Step: 1
Training loss: 2.9687801961868927
Validation loss: 2.603079251239426

Epoch: 5| Step: 2
Training loss: 2.876059129757051
Validation loss: 2.5868685215288245

Epoch: 5| Step: 3
Training loss: 2.4875845659919635
Validation loss: 2.5444203560376106

Epoch: 5| Step: 4
Training loss: 3.2171918931053813
Validation loss: 2.5734947342025767

Epoch: 5| Step: 5
Training loss: 2.58533426953214
Validation loss: 2.57506527629294

Epoch: 5| Step: 6
Training loss: 3.1185954267767864
Validation loss: 2.562074740518898

Epoch: 5| Step: 7
Training loss: 2.107154298894451
Validation loss: 2.5710165051654204

Epoch: 5| Step: 8
Training loss: 3.3254907059505925
Validation loss: 2.5589156519994365

Epoch: 5| Step: 9
Training loss: 3.0485193754822077
Validation loss: 2.5593163026216024

Epoch: 5| Step: 10
Training loss: 2.356575422809266
Validation loss: 2.560977654665119

Epoch: 102| Step: 0
Training loss: 2.4281805829887357
Validation loss: 2.581705736448686

Epoch: 5| Step: 1
Training loss: 2.509060843102871
Validation loss: 2.5756132586911296

Epoch: 5| Step: 2
Training loss: 3.148149576581577
Validation loss: 2.5663977501554056

Epoch: 5| Step: 3
Training loss: 3.6711708205259868
Validation loss: 2.5621326087121967

Epoch: 5| Step: 4
Training loss: 2.831037844357451
Validation loss: 2.5645925310280058

Epoch: 5| Step: 5
Training loss: 2.389185153963722
Validation loss: 2.569038987995512

Epoch: 5| Step: 6
Training loss: 3.2158309885375473
Validation loss: 2.6024826990892014

Epoch: 5| Step: 7
Training loss: 2.02993708508342
Validation loss: 2.579426860041648

Epoch: 5| Step: 8
Training loss: 2.8376360553942668
Validation loss: 2.584130366330672

Epoch: 5| Step: 9
Training loss: 3.0710471635660643
Validation loss: 2.540003129438637

Epoch: 5| Step: 10
Training loss: 2.4857545297399746
Validation loss: 2.6014763617267542

Epoch: 103| Step: 0
Training loss: 2.8276135735675303
Validation loss: 2.593070916734161

Epoch: 5| Step: 1
Training loss: 3.2522554640799197
Validation loss: 2.5689288615275165

Epoch: 5| Step: 2
Training loss: 2.4914590853294882
Validation loss: 2.5794034903396073

Epoch: 5| Step: 3
Training loss: 2.830272554678197
Validation loss: 2.537657548471031

Epoch: 5| Step: 4
Training loss: 3.1380054689825285
Validation loss: 2.582960995752449

Epoch: 5| Step: 5
Training loss: 2.9870783360633193
Validation loss: 2.5737864911480637

Epoch: 5| Step: 6
Training loss: 2.8003240874605946
Validation loss: 2.554845262106602

Epoch: 5| Step: 7
Training loss: 2.6223654469027338
Validation loss: 2.5788452614010624

Epoch: 5| Step: 8
Training loss: 2.3248987565505836
Validation loss: 2.57496140209484

Epoch: 5| Step: 9
Training loss: 2.9250741672079004
Validation loss: 2.5686584410829605

Epoch: 5| Step: 10
Training loss: 2.983558583058573
Validation loss: 2.5536184977885195

Epoch: 104| Step: 0
Training loss: 3.0864303774709687
Validation loss: 2.571394094991949

Epoch: 5| Step: 1
Training loss: 3.320660884755902
Validation loss: 2.595437807497068

Epoch: 5| Step: 2
Training loss: 2.8340504991531974
Validation loss: 2.579770540709668

Epoch: 5| Step: 3
Training loss: 2.8556514321479627
Validation loss: 2.5603738503577604

Epoch: 5| Step: 4
Training loss: 2.5971397402671372
Validation loss: 2.5741732433659483

Epoch: 5| Step: 5
Training loss: 3.0365535313300196
Validation loss: 2.5500778522144594

Epoch: 5| Step: 6
Training loss: 2.777802205508165
Validation loss: 2.581578253607092

Epoch: 5| Step: 7
Training loss: 3.036203643080592
Validation loss: 2.55086426003975

Epoch: 5| Step: 8
Training loss: 2.9452951769736755
Validation loss: 2.5852460753182323

Epoch: 5| Step: 9
Training loss: 2.284838845143965
Validation loss: 2.5721316293068526

Epoch: 5| Step: 10
Training loss: 2.0543998255794964
Validation loss: 2.5527671241123597

Epoch: 105| Step: 0
Training loss: 2.99869318155745
Validation loss: 2.540819853776619

Epoch: 5| Step: 1
Training loss: 3.359994520682454
Validation loss: 2.534052480501542

Epoch: 5| Step: 2
Training loss: 3.0915846519868078
Validation loss: 2.558679231857854

Epoch: 5| Step: 3
Training loss: 2.265293912702123
Validation loss: 2.578906468160916

Epoch: 5| Step: 4
Training loss: 2.633835681450364
Validation loss: 2.541013928023033

Epoch: 5| Step: 5
Training loss: 2.47680913136349
Validation loss: 2.5466992989334787

Epoch: 5| Step: 6
Training loss: 2.5828963084392154
Validation loss: 2.5757040072741555

Epoch: 5| Step: 7
Training loss: 2.808345863321879
Validation loss: 2.5794066345053954

Epoch: 5| Step: 8
Training loss: 3.165543423926168
Validation loss: 2.5900119067455387

Epoch: 5| Step: 9
Training loss: 3.170270542188623
Validation loss: 2.5243668004013053

Epoch: 5| Step: 10
Training loss: 2.1660977374680397
Validation loss: 2.5693163569248028

Epoch: 106| Step: 0
Training loss: 2.732103374206597
Validation loss: 2.5617240593347534

Epoch: 5| Step: 1
Training loss: 2.968915914617463
Validation loss: 2.5956463484541996

Epoch: 5| Step: 2
Training loss: 3.114596329643837
Validation loss: 2.5637363199646885

Epoch: 5| Step: 3
Training loss: 2.388789850099211
Validation loss: 2.586849479984173

Epoch: 5| Step: 4
Training loss: 3.1273216778531143
Validation loss: 2.595666259794206

Epoch: 5| Step: 5
Training loss: 2.6259284421144207
Validation loss: 2.5474163370689396

Epoch: 5| Step: 6
Training loss: 2.467308396124841
Validation loss: 2.567739683731676

Epoch: 5| Step: 7
Training loss: 3.1322877972478196
Validation loss: 2.5731294273385346

Epoch: 5| Step: 8
Training loss: 2.807218042279911
Validation loss: 2.549927623034502

Epoch: 5| Step: 9
Training loss: 2.9474693111669534
Validation loss: 2.5786745909447264

Epoch: 5| Step: 10
Training loss: 2.862280864740081
Validation loss: 2.5977006406196295

Epoch: 107| Step: 0
Training loss: 2.4864008099523964
Validation loss: 2.5789787392859242

Epoch: 5| Step: 1
Training loss: 2.5285979141005885
Validation loss: 2.566060833359785

Epoch: 5| Step: 2
Training loss: 2.980691923932755
Validation loss: 2.575098296926708

Epoch: 5| Step: 3
Training loss: 3.083037972264976
Validation loss: 2.5763816042511123

Epoch: 5| Step: 4
Training loss: 2.828094650864438
Validation loss: 2.5277905510239322

Epoch: 5| Step: 5
Training loss: 3.079194943130872
Validation loss: 2.5651064806779327

Epoch: 5| Step: 6
Training loss: 2.908467912884851
Validation loss: 2.578208461092935

Epoch: 5| Step: 7
Training loss: 2.311373255709573
Validation loss: 2.5616400191288613

Epoch: 5| Step: 8
Training loss: 3.299530695287296
Validation loss: 2.593471541309837

Epoch: 5| Step: 9
Training loss: 2.8829312597277497
Validation loss: 2.5642110572896053

Epoch: 5| Step: 10
Training loss: 2.4389416270635484
Validation loss: 2.577734217108014

Epoch: 108| Step: 0
Training loss: 3.012778406218351
Validation loss: 2.5773920214858763

Epoch: 5| Step: 1
Training loss: 2.236682367378686
Validation loss: 2.5714201480648082

Epoch: 5| Step: 2
Training loss: 2.167044117646133
Validation loss: 2.5428717328677846

Epoch: 5| Step: 3
Training loss: 3.6395448056332422
Validation loss: 2.5675728141114798

Epoch: 5| Step: 4
Training loss: 2.767890993254089
Validation loss: 2.5661344687869483

Epoch: 5| Step: 5
Training loss: 2.726996706953253
Validation loss: 2.578280930264348

Epoch: 5| Step: 6
Training loss: 3.3301362600314084
Validation loss: 2.552097906322614

Epoch: 5| Step: 7
Training loss: 2.6116497609220817
Validation loss: 2.593493821952131

Epoch: 5| Step: 8
Training loss: 2.061385113490588
Validation loss: 2.552932919963266

Epoch: 5| Step: 9
Training loss: 2.692681042491709
Validation loss: 2.563334408960976

Epoch: 5| Step: 10
Training loss: 3.3442410972963215
Validation loss: 2.5716318688435416

Epoch: 109| Step: 0
Training loss: 2.780899111440664
Validation loss: 2.5462366991929413

Epoch: 5| Step: 1
Training loss: 3.101123846056707
Validation loss: 2.570137118430806

Epoch: 5| Step: 2
Training loss: 3.077619017244925
Validation loss: 2.5475334918195243

Epoch: 5| Step: 3
Training loss: 2.9603502803466744
Validation loss: 2.5633699624613024

Epoch: 5| Step: 4
Training loss: 2.9251680635603217
Validation loss: 2.588883578161397

Epoch: 5| Step: 5
Training loss: 2.7191703734478327
Validation loss: 2.568318944099916

Epoch: 5| Step: 6
Training loss: 2.768340937791363
Validation loss: 2.548984149750646

Epoch: 5| Step: 7
Training loss: 3.0492735200772234
Validation loss: 2.5861061565878543

Epoch: 5| Step: 8
Training loss: 2.520143608966452
Validation loss: 2.5724149173808946

Epoch: 5| Step: 9
Training loss: 2.48115551670166
Validation loss: 2.5921625032638707

Epoch: 5| Step: 10
Training loss: 2.5040599281891005
Validation loss: 2.6056455295861953

Epoch: 110| Step: 0
Training loss: 3.312713184334345
Validation loss: 2.5666678224754635

Epoch: 5| Step: 1
Training loss: 3.0709192195840074
Validation loss: 2.5763816311175893

Epoch: 5| Step: 2
Training loss: 2.921487547945028
Validation loss: 2.551268270666619

Epoch: 5| Step: 3
Training loss: 2.463128558652137
Validation loss: 2.5691422005792957

Epoch: 5| Step: 4
Training loss: 2.4049197396509094
Validation loss: 2.549828692944802

Epoch: 5| Step: 5
Training loss: 2.6285352969499973
Validation loss: 2.5775626376223015

Epoch: 5| Step: 6
Training loss: 3.2277064477681154
Validation loss: 2.5925173023831674

Epoch: 5| Step: 7
Training loss: 2.9598879602208843
Validation loss: 2.573435579398792

Epoch: 5| Step: 8
Training loss: 2.1315156116705807
Validation loss: 2.600355581866558

Epoch: 5| Step: 9
Training loss: 2.3067956625236
Validation loss: 2.5723355099299634

Epoch: 5| Step: 10
Training loss: 3.4422555107223856
Validation loss: 2.561450498225048

Epoch: 111| Step: 0
Training loss: 2.5721097187827238
Validation loss: 2.553156587411809

Epoch: 5| Step: 1
Training loss: 2.8185157018755014
Validation loss: 2.553506778606209

Epoch: 5| Step: 2
Training loss: 2.5377272630968903
Validation loss: 2.5562183090834196

Epoch: 5| Step: 3
Training loss: 2.636517371505495
Validation loss: 2.5672418034546047

Epoch: 5| Step: 4
Training loss: 2.36151026424816
Validation loss: 2.5686057606529302

Epoch: 5| Step: 5
Training loss: 2.568262088223979
Validation loss: 2.5465661656906113

Epoch: 5| Step: 6
Training loss: 2.8393312435149918
Validation loss: 2.5819192470214998

Epoch: 5| Step: 7
Training loss: 3.547206510268222
Validation loss: 2.5643614854052843

Epoch: 5| Step: 8
Training loss: 3.2083134010653582
Validation loss: 2.558953157851203

Epoch: 5| Step: 9
Training loss: 3.0023894331089753
Validation loss: 2.5982376566885255

Epoch: 5| Step: 10
Training loss: 2.7628482305681956
Validation loss: 2.5771717087781996

Epoch: 112| Step: 0
Training loss: 3.0764466953132805
Validation loss: 2.5647406997302613

Epoch: 5| Step: 1
Training loss: 2.76882301389294
Validation loss: 2.5775472342250865

Epoch: 5| Step: 2
Training loss: 2.9533631566811587
Validation loss: 2.5889252415830692

Epoch: 5| Step: 3
Training loss: 2.6931353192984897
Validation loss: 2.607939433024922

Epoch: 5| Step: 4
Training loss: 2.790016160870306
Validation loss: 2.5810979333787905

Epoch: 5| Step: 5
Training loss: 3.3331668971153965
Validation loss: 2.568435982847916

Epoch: 5| Step: 6
Training loss: 3.1520578474555405
Validation loss: 2.5602154436099225

Epoch: 5| Step: 7
Training loss: 2.5781356348916544
Validation loss: 2.5753868261684523

Epoch: 5| Step: 8
Training loss: 2.371530307255208
Validation loss: 2.566099736338361

Epoch: 5| Step: 9
Training loss: 3.072065090999838
Validation loss: 2.5942083132498768

Epoch: 5| Step: 10
Training loss: 2.1776055131087073
Validation loss: 2.5821854313235715

Epoch: 113| Step: 0
Training loss: 3.354970484232796
Validation loss: 2.572631643456313

Epoch: 5| Step: 1
Training loss: 2.341648838432385
Validation loss: 2.584218169069412

Epoch: 5| Step: 2
Training loss: 2.231649056446581
Validation loss: 2.6022067895839176

Epoch: 5| Step: 3
Training loss: 2.776178601139928
Validation loss: 2.585351877472545

Epoch: 5| Step: 4
Training loss: 2.755583470170679
Validation loss: 2.5819538530489283

Epoch: 5| Step: 5
Training loss: 2.3451309204970285
Validation loss: 2.5671357791953717

Epoch: 5| Step: 6
Training loss: 3.1943384751881543
Validation loss: 2.577058053141157

Epoch: 5| Step: 7
Training loss: 2.9474309694135346
Validation loss: 2.559903728186807

Epoch: 5| Step: 8
Training loss: 2.8693756152704704
Validation loss: 2.557714570458278

Epoch: 5| Step: 9
Training loss: 2.9982972080951695
Validation loss: 2.620423669436989

Epoch: 5| Step: 10
Training loss: 2.7643378759414525
Validation loss: 2.552301707833129

Epoch: 114| Step: 0
Training loss: 2.7393330120025516
Validation loss: 2.5753251510122572

Epoch: 5| Step: 1
Training loss: 2.572166817519034
Validation loss: 2.5876520526032416

Epoch: 5| Step: 2
Training loss: 3.411508822856141
Validation loss: 2.5642135717288976

Epoch: 5| Step: 3
Training loss: 2.6837685873723176
Validation loss: 2.56057775107482

Epoch: 5| Step: 4
Training loss: 2.712607097708868
Validation loss: 2.6138167853182748

Epoch: 5| Step: 5
Training loss: 2.6206532774804536
Validation loss: 2.5677810592417885

Epoch: 5| Step: 6
Training loss: 3.1921264881609024
Validation loss: 2.564665646837014

Epoch: 5| Step: 7
Training loss: 2.8781982545093627
Validation loss: 2.5566317587754774

Epoch: 5| Step: 8
Training loss: 2.747287452813897
Validation loss: 2.555688666936765

Epoch: 5| Step: 9
Training loss: 3.146992013189595
Validation loss: 2.5405577734174436

Epoch: 5| Step: 10
Training loss: 2.241574619015286
Validation loss: 2.5614209548156643

Epoch: 115| Step: 0
Training loss: 3.1079107316009877
Validation loss: 2.5596013155364274

Epoch: 5| Step: 1
Training loss: 2.633398064489748
Validation loss: 2.5660889341772752

Epoch: 5| Step: 2
Training loss: 3.000504133463515
Validation loss: 2.577348754206742

Epoch: 5| Step: 3
Training loss: 2.452003951774263
Validation loss: 2.555183796201945

Epoch: 5| Step: 4
Training loss: 2.4814750972853354
Validation loss: 2.5511133483161212

Epoch: 5| Step: 5
Training loss: 2.457749787807989
Validation loss: 2.5638921024171704

Epoch: 5| Step: 6
Training loss: 3.586508312794853
Validation loss: 2.5914786334660573

Epoch: 5| Step: 7
Training loss: 3.105712266886999
Validation loss: 2.56512629727056

Epoch: 5| Step: 8
Training loss: 2.6342554863985477
Validation loss: 2.544812024055293

Epoch: 5| Step: 9
Training loss: 2.9753110963385185
Validation loss: 2.5551150876280038

Epoch: 5| Step: 10
Training loss: 2.3748119681361484
Validation loss: 2.541774918584104

Epoch: 116| Step: 0
Training loss: 3.1029246531616335
Validation loss: 2.5456483867783275

Epoch: 5| Step: 1
Training loss: 3.1793859090406054
Validation loss: 2.553708178311405

Epoch: 5| Step: 2
Training loss: 2.1372135572745634
Validation loss: 2.5854756691035656

Epoch: 5| Step: 3
Training loss: 2.449797006878008
Validation loss: 2.581191236327688

Epoch: 5| Step: 4
Training loss: 2.8131654587899826
Validation loss: 2.5658881340791324

Epoch: 5| Step: 5
Training loss: 2.9916300042614665
Validation loss: 2.5815099704701607

Epoch: 5| Step: 6
Training loss: 2.3215978896046674
Validation loss: 2.5827349811033313

Epoch: 5| Step: 7
Training loss: 2.688643988271133
Validation loss: 2.6078005481441835

Epoch: 5| Step: 8
Training loss: 2.443564280601723
Validation loss: 2.5611244059026546

Epoch: 5| Step: 9
Training loss: 3.4442354278998253
Validation loss: 2.5571671064952386

Epoch: 5| Step: 10
Training loss: 3.0921117895726002
Validation loss: 2.578301020455694

Epoch: 117| Step: 0
Training loss: 3.381501893199372
Validation loss: 2.53608794214918

Epoch: 5| Step: 1
Training loss: 3.3330171117197405
Validation loss: 2.524346252026993

Epoch: 5| Step: 2
Training loss: 2.879313343100884
Validation loss: 2.5832903296404

Epoch: 5| Step: 3
Training loss: 2.892973404689241
Validation loss: 2.5725064335255126

Epoch: 5| Step: 4
Training loss: 2.6050584919049973
Validation loss: 2.5685513584390676

Epoch: 5| Step: 5
Training loss: 2.5726155917015694
Validation loss: 2.581551366592699

Epoch: 5| Step: 6
Training loss: 2.622249524689187
Validation loss: 2.5568493494243274

Epoch: 5| Step: 7
Training loss: 2.2522757994649476
Validation loss: 2.5726155897085468

Epoch: 5| Step: 8
Training loss: 2.4838779360070546
Validation loss: 2.556552149892368

Epoch: 5| Step: 9
Training loss: 3.0668697711471657
Validation loss: 2.540678646905328

Epoch: 5| Step: 10
Training loss: 2.607631077749781
Validation loss: 2.5679074559880295

Epoch: 118| Step: 0
Training loss: 2.5953280692463183
Validation loss: 2.5934581540510284

Epoch: 5| Step: 1
Training loss: 1.9976701278711704
Validation loss: 2.548977522855729

Epoch: 5| Step: 2
Training loss: 2.5132598183536023
Validation loss: 2.575537851744954

Epoch: 5| Step: 3
Training loss: 2.9003342337215834
Validation loss: 2.566177224339089

Epoch: 5| Step: 4
Training loss: 3.234151933874517
Validation loss: 2.574406353046566

Epoch: 5| Step: 5
Training loss: 3.439325021570934
Validation loss: 2.577131146547579

Epoch: 5| Step: 6
Training loss: 2.8996418304250917
Validation loss: 2.548851051364184

Epoch: 5| Step: 7
Training loss: 2.972871509432703
Validation loss: 2.5345924102211823

Epoch: 5| Step: 8
Training loss: 3.0770151683890967
Validation loss: 2.5550890198052905

Epoch: 5| Step: 9
Training loss: 2.687427164909426
Validation loss: 2.5788860193468857

Epoch: 5| Step: 10
Training loss: 2.4761277066823117
Validation loss: 2.5917856433318196

Epoch: 119| Step: 0
Training loss: 2.7630803529954346
Validation loss: 2.5698190307583526

Epoch: 5| Step: 1
Training loss: 2.8864402378542504
Validation loss: 2.5574828343075016

Epoch: 5| Step: 2
Training loss: 2.8450637968449275
Validation loss: 2.573736697726775

Epoch: 5| Step: 3
Training loss: 3.0385186265227313
Validation loss: 2.5725977471109425

Epoch: 5| Step: 4
Training loss: 3.0539389080839654
Validation loss: 2.551625176281961

Epoch: 5| Step: 5
Training loss: 2.4475171568038334
Validation loss: 2.5944597963457734

Epoch: 5| Step: 6
Training loss: 2.3422913144690516
Validation loss: 2.599374574576309

Epoch: 5| Step: 7
Training loss: 2.991081969805852
Validation loss: 2.56007390459733

Epoch: 5| Step: 8
Training loss: 3.1121386030952234
Validation loss: 2.5726331302415404

Epoch: 5| Step: 9
Training loss: 2.935658466098813
Validation loss: 2.603030656354384

Epoch: 5| Step: 10
Training loss: 2.3181586238904313
Validation loss: 2.5561152365929267

Epoch: 120| Step: 0
Training loss: 2.869643653518874
Validation loss: 2.5868231571517497

Epoch: 5| Step: 1
Training loss: 3.099997329710764
Validation loss: 2.5755366294171806

Epoch: 5| Step: 2
Training loss: 2.0201474103867723
Validation loss: 2.581605107571097

Epoch: 5| Step: 3
Training loss: 3.2722945300498307
Validation loss: 2.565957083205455

Epoch: 5| Step: 4
Training loss: 2.489867754109218
Validation loss: 2.572095155850555

Epoch: 5| Step: 5
Training loss: 2.6263259082193287
Validation loss: 2.5819396430180737

Epoch: 5| Step: 6
Training loss: 2.528019102917697
Validation loss: 2.5993707025446553

Epoch: 5| Step: 7
Training loss: 3.038039792923429
Validation loss: 2.586187340873792

Epoch: 5| Step: 8
Training loss: 2.398717907347494
Validation loss: 2.578657104431234

Epoch: 5| Step: 9
Training loss: 3.33303399331389
Validation loss: 2.5569905205107517

Epoch: 5| Step: 10
Training loss: 3.2675311352531335
Validation loss: 2.540319329393334

Epoch: 121| Step: 0
Training loss: 2.828336507570295
Validation loss: 2.5636927282210786

Epoch: 5| Step: 1
Training loss: 2.7583812094813993
Validation loss: 2.5865827428999193

Epoch: 5| Step: 2
Training loss: 2.3905194826463183
Validation loss: 2.5873542842503388

Epoch: 5| Step: 3
Training loss: 2.7680643821516457
Validation loss: 2.5905483989032883

Epoch: 5| Step: 4
Training loss: 2.910006484715948
Validation loss: 2.5811924142633087

Epoch: 5| Step: 5
Training loss: 2.482026627692078
Validation loss: 2.5758567455048644

Epoch: 5| Step: 6
Training loss: 2.900637385599382
Validation loss: 2.5605888272840844

Epoch: 5| Step: 7
Training loss: 3.0924183455274745
Validation loss: 2.549216995368635

Epoch: 5| Step: 8
Training loss: 2.639455863767171
Validation loss: 2.578201365404194

Epoch: 5| Step: 9
Training loss: 2.9340709394682385
Validation loss: 2.5774661279074356

Epoch: 5| Step: 10
Training loss: 3.0103329093571514
Validation loss: 2.5712838640040467

Epoch: 122| Step: 0
Training loss: 2.7819746123635722
Validation loss: 2.558105287859432

Epoch: 5| Step: 1
Training loss: 2.5140764671113147
Validation loss: 2.543017266755185

Epoch: 5| Step: 2
Training loss: 2.077571250161956
Validation loss: 2.5515814811158735

Epoch: 5| Step: 3
Training loss: 3.288922014656725
Validation loss: 2.576289616766912

Epoch: 5| Step: 4
Training loss: 3.462149448758963
Validation loss: 2.561315173044079

Epoch: 5| Step: 5
Training loss: 2.6936103200433235
Validation loss: 2.56469255193846

Epoch: 5| Step: 6
Training loss: 3.0025982731245464
Validation loss: 2.5720164422284237

Epoch: 5| Step: 7
Training loss: 2.8873612407685294
Validation loss: 2.5414955737866376

Epoch: 5| Step: 8
Training loss: 2.7899382255579064
Validation loss: 2.5885399308595707

Epoch: 5| Step: 9
Training loss: 2.6372438713202855
Validation loss: 2.560584966685445

Epoch: 5| Step: 10
Training loss: 2.4197799973542438
Validation loss: 2.6006181904907493

Epoch: 123| Step: 0
Training loss: 2.8155972698510046
Validation loss: 2.5884923946134486

Epoch: 5| Step: 1
Training loss: 2.7057243594340163
Validation loss: 2.550521957258269

Epoch: 5| Step: 2
Training loss: 2.551637467861573
Validation loss: 2.5399370089358526

Epoch: 5| Step: 3
Training loss: 2.754774457280639
Validation loss: 2.566680829084062

Epoch: 5| Step: 4
Training loss: 3.3138719992266297
Validation loss: 2.5639931075198485

Epoch: 5| Step: 5
Training loss: 3.001529621537946
Validation loss: 2.5755051911067754

Epoch: 5| Step: 6
Training loss: 2.4013277712236314
Validation loss: 2.5869868060819234

Epoch: 5| Step: 7
Training loss: 2.525057057406418
Validation loss: 2.546705126436814

Epoch: 5| Step: 8
Training loss: 2.969145256634083
Validation loss: 2.570318844480664

Epoch: 5| Step: 9
Training loss: 2.7759632054179812
Validation loss: 2.5489701999609164

Epoch: 5| Step: 10
Training loss: 2.9368075914231304
Validation loss: 2.6012331171346252

Epoch: 124| Step: 0
Training loss: 2.7411077824485486
Validation loss: 2.567634218192932

Epoch: 5| Step: 1
Training loss: 3.2805047051643546
Validation loss: 2.5349604783231023

Epoch: 5| Step: 2
Training loss: 2.092451575481173
Validation loss: 2.5451262712782596

Epoch: 5| Step: 3
Training loss: 2.7106898301850677
Validation loss: 2.5979417479786426

Epoch: 5| Step: 4
Training loss: 2.8192812230846442
Validation loss: 2.5642355037336007

Epoch: 5| Step: 5
Training loss: 2.8358396402924657
Validation loss: 2.5880138543868814

Epoch: 5| Step: 6
Training loss: 3.1068683277488987
Validation loss: 2.5843672798677186

Epoch: 5| Step: 7
Training loss: 2.820391202129686
Validation loss: 2.574274210558297

Epoch: 5| Step: 8
Training loss: 2.2320230549951283
Validation loss: 2.5727955095204553

Epoch: 5| Step: 9
Training loss: 3.1302510204144434
Validation loss: 2.5565491280351287

Epoch: 5| Step: 10
Training loss: 2.968345212946543
Validation loss: 2.549237997445189

Epoch: 125| Step: 0
Training loss: 2.4702305277688246
Validation loss: 2.564080831957808

Epoch: 5| Step: 1
Training loss: 3.3930835160765365
Validation loss: 2.5433978178778633

Epoch: 5| Step: 2
Training loss: 2.660917780876454
Validation loss: 2.5861768610205798

Epoch: 5| Step: 3
Training loss: 3.1179678568770646
Validation loss: 2.5670256140222247

Epoch: 5| Step: 4
Training loss: 2.7242850599431754
Validation loss: 2.5567964116414004

Epoch: 5| Step: 5
Training loss: 2.922276107265487
Validation loss: 2.5892596149286

Epoch: 5| Step: 6
Training loss: 2.7360759567179738
Validation loss: 2.569856787486288

Epoch: 5| Step: 7
Training loss: 3.0781434344209258
Validation loss: 2.551834492776731

Epoch: 5| Step: 8
Training loss: 2.4719705941756747
Validation loss: 2.5331249916502103

Epoch: 5| Step: 9
Training loss: 2.644745450381653
Validation loss: 2.5736474098032454

Epoch: 5| Step: 10
Training loss: 2.542937716574513
Validation loss: 2.544878728597769

Epoch: 126| Step: 0
Training loss: 3.1514004757887037
Validation loss: 2.541026269923007

Epoch: 5| Step: 1
Training loss: 2.57947084382378
Validation loss: 2.5698541997595363

Epoch: 5| Step: 2
Training loss: 2.7306280130591065
Validation loss: 2.557738760260862

Epoch: 5| Step: 3
Training loss: 2.8556365708742684
Validation loss: 2.562587236329634

Epoch: 5| Step: 4
Training loss: 2.392647778801155
Validation loss: 2.54685358586693

Epoch: 5| Step: 5
Training loss: 3.0856259731996643
Validation loss: 2.5802709533756993

Epoch: 5| Step: 6
Training loss: 2.3223533004238925
Validation loss: 2.583911836105275

Epoch: 5| Step: 7
Training loss: 3.079145852837185
Validation loss: 2.5808196353639894

Epoch: 5| Step: 8
Training loss: 2.475093947660099
Validation loss: 2.54137129271811

Epoch: 5| Step: 9
Training loss: 2.9360461594073923
Validation loss: 2.589188161481579

Epoch: 5| Step: 10
Training loss: 3.268712386722677
Validation loss: 2.586649310321551

Epoch: 127| Step: 0
Training loss: 3.0812176499593305
Validation loss: 2.5261737284483106

Epoch: 5| Step: 1
Training loss: 2.5880824295076597
Validation loss: 2.5536212555681286

Epoch: 5| Step: 2
Training loss: 2.539554301829539
Validation loss: 2.5782407881911653

Epoch: 5| Step: 3
Training loss: 2.3501607068891195
Validation loss: 2.5638373911999786

Epoch: 5| Step: 4
Training loss: 2.9551862355265373
Validation loss: 2.5679535478602245

Epoch: 5| Step: 5
Training loss: 3.160157758903379
Validation loss: 2.5960267550533276

Epoch: 5| Step: 6
Training loss: 2.888195274503535
Validation loss: 2.584851278623524

Epoch: 5| Step: 7
Training loss: 2.832952773024035
Validation loss: 2.5413950878062974

Epoch: 5| Step: 8
Training loss: 3.1597835287963223
Validation loss: 2.5490617582684383

Epoch: 5| Step: 9
Training loss: 2.6109532134920443
Validation loss: 2.563129970889396

Epoch: 5| Step: 10
Training loss: 2.227694574970781
Validation loss: 2.563304522716865

Epoch: 128| Step: 0
Training loss: 2.895178100958055
Validation loss: 2.5211812627317065

Epoch: 5| Step: 1
Training loss: 3.2748478511964993
Validation loss: 2.5655172429038067

Epoch: 5| Step: 2
Training loss: 2.621342426902596
Validation loss: 2.5736279820628085

Epoch: 5| Step: 3
Training loss: 2.4474456550401684
Validation loss: 2.5342339282522413

Epoch: 5| Step: 4
Training loss: 2.59026111214475
Validation loss: 2.592050585960581

Epoch: 5| Step: 5
Training loss: 2.906445896560572
Validation loss: 2.5963788839737685

Epoch: 5| Step: 6
Training loss: 2.473918285380351
Validation loss: 2.5691509777285346

Epoch: 5| Step: 7
Training loss: 2.7731574118583358
Validation loss: 2.5284542482893198

Epoch: 5| Step: 8
Training loss: 2.294448608946799
Validation loss: 2.5768986783129346

Epoch: 5| Step: 9
Training loss: 2.9304513978050313
Validation loss: 2.5446507439635173

Epoch: 5| Step: 10
Training loss: 3.411456966642538
Validation loss: 2.5698596585231734

Epoch: 129| Step: 0
Training loss: 2.952126308892007
Validation loss: 2.5553787107689203

Epoch: 5| Step: 1
Training loss: 3.0018508288117016
Validation loss: 2.5515217283474203

Epoch: 5| Step: 2
Training loss: 2.454431562478644
Validation loss: 2.5524338107177686

Epoch: 5| Step: 3
Training loss: 2.4549027337036797
Validation loss: 2.605906586906603

Epoch: 5| Step: 4
Training loss: 3.3255916499297564
Validation loss: 2.532235828020123

Epoch: 5| Step: 5
Training loss: 3.0413854982896433
Validation loss: 2.56875258109455

Epoch: 5| Step: 6
Training loss: 2.3512731228329766
Validation loss: 2.5477885768069473

Epoch: 5| Step: 7
Training loss: 2.6500027062744143
Validation loss: 2.5821990557314867

Epoch: 5| Step: 8
Training loss: 2.591712519085729
Validation loss: 2.584308615489076

Epoch: 5| Step: 9
Training loss: 3.2152170587953246
Validation loss: 2.5929245290672136

Epoch: 5| Step: 10
Training loss: 2.615493089273344
Validation loss: 2.5361340336021154

Epoch: 130| Step: 0
Training loss: 3.112515497743561
Validation loss: 2.5700787416977526

Epoch: 5| Step: 1
Training loss: 2.6236932317472648
Validation loss: 2.559432233051075

Epoch: 5| Step: 2
Training loss: 2.9181494803677395
Validation loss: 2.575353782356945

Epoch: 5| Step: 3
Training loss: 2.070816151517616
Validation loss: 2.584236103056236

Epoch: 5| Step: 4
Training loss: 3.0409050776209825
Validation loss: 2.583667795664613

Epoch: 5| Step: 5
Training loss: 3.3193956971856533
Validation loss: 2.57234679164195

Epoch: 5| Step: 6
Training loss: 2.6606973554268234
Validation loss: 2.579142189164849

Epoch: 5| Step: 7
Training loss: 1.8885722720876195
Validation loss: 2.56990906419606

Epoch: 5| Step: 8
Training loss: 2.736118567295748
Validation loss: 2.5629475205538323

Epoch: 5| Step: 9
Training loss: 2.954214228223436
Validation loss: 2.5597919678425582

Epoch: 5| Step: 10
Training loss: 3.1033478410042314
Validation loss: 2.5371014590653274

Epoch: 131| Step: 0
Training loss: 2.711255057696439
Validation loss: 2.5596823859906936

Epoch: 5| Step: 1
Training loss: 2.3178270173849325
Validation loss: 2.588506859847636

Epoch: 5| Step: 2
Training loss: 2.619362272005462
Validation loss: 2.593772533253141

Epoch: 5| Step: 3
Training loss: 2.9485612755344013
Validation loss: 2.55827134903615

Epoch: 5| Step: 4
Training loss: 3.4784369398210346
Validation loss: 2.557173869563954

Epoch: 5| Step: 5
Training loss: 2.5332924408707536
Validation loss: 2.5522958760325665

Epoch: 5| Step: 6
Training loss: 2.8185749989252815
Validation loss: 2.5710539965246086

Epoch: 5| Step: 7
Training loss: 2.335220379936308
Validation loss: 2.564036633166067

Epoch: 5| Step: 8
Training loss: 2.6574599259262692
Validation loss: 2.573662293663196

Epoch: 5| Step: 9
Training loss: 2.8325868258926685
Validation loss: 2.5469901796617824

Epoch: 5| Step: 10
Training loss: 3.5603864322909122
Validation loss: 2.5485974150954815

Epoch: 132| Step: 0
Training loss: 2.497798140775789
Validation loss: 2.5806036108463615

Epoch: 5| Step: 1
Training loss: 3.411178103675133
Validation loss: 2.5792944638836346

Epoch: 5| Step: 2
Training loss: 2.945880056079943
Validation loss: 2.583276033179501

Epoch: 5| Step: 3
Training loss: 2.583578641586031
Validation loss: 2.570464661484673

Epoch: 5| Step: 4
Training loss: 2.9866069017402443
Validation loss: 2.5888528604400696

Epoch: 5| Step: 5
Training loss: 2.8068726084700466
Validation loss: 2.563906256989676

Epoch: 5| Step: 6
Training loss: 2.7346021285412103
Validation loss: 2.5436109418719344

Epoch: 5| Step: 7
Training loss: 2.9889483336816745
Validation loss: 2.5600154656265435

Epoch: 5| Step: 8
Training loss: 2.267684211187956
Validation loss: 2.5801475211084433

Epoch: 5| Step: 9
Training loss: 2.424775386514971
Validation loss: 2.5869706917785527

Epoch: 5| Step: 10
Training loss: 2.864136280664087
Validation loss: 2.58653688883939

Epoch: 133| Step: 0
Training loss: 3.3261723050774092
Validation loss: 2.556193551284378

Epoch: 5| Step: 1
Training loss: 2.60147873568931
Validation loss: 2.5766057176400063

Epoch: 5| Step: 2
Training loss: 2.9693728145012415
Validation loss: 2.567608641907522

Epoch: 5| Step: 3
Training loss: 3.178676885138265
Validation loss: 2.561265775760207

Epoch: 5| Step: 4
Training loss: 2.328188696892372
Validation loss: 2.58650814142561

Epoch: 5| Step: 5
Training loss: 2.9744792065659107
Validation loss: 2.565283226525007

Epoch: 5| Step: 6
Training loss: 2.8576568277464696
Validation loss: 2.5576779014325783

Epoch: 5| Step: 7
Training loss: 2.431350090104392
Validation loss: 2.5867392098966

Epoch: 5| Step: 8
Training loss: 2.9086231673866587
Validation loss: 2.5540428947714404

Epoch: 5| Step: 9
Training loss: 2.3949102752061178
Validation loss: 2.583319012631654

Epoch: 5| Step: 10
Training loss: 2.404884049759082
Validation loss: 2.553908912669023

Epoch: 134| Step: 0
Training loss: 2.58384910685013
Validation loss: 2.5638356163355827

Epoch: 5| Step: 1
Training loss: 2.9203147598347665
Validation loss: 2.5288810638731967

Epoch: 5| Step: 2
Training loss: 2.7143931941213824
Validation loss: 2.574062669270267

Epoch: 5| Step: 3
Training loss: 2.655213187327886
Validation loss: 2.557506699520068

Epoch: 5| Step: 4
Training loss: 2.544725224588786
Validation loss: 2.538823307656625

Epoch: 5| Step: 5
Training loss: 2.8631543473540613
Validation loss: 2.5639494631489543

Epoch: 5| Step: 6
Training loss: 3.4776883820353923
Validation loss: 2.5743681003988255

Epoch: 5| Step: 7
Training loss: 2.6081740305296064
Validation loss: 2.6167951353112793

Epoch: 5| Step: 8
Training loss: 2.0528414595790156
Validation loss: 2.5751938476020757

Epoch: 5| Step: 9
Training loss: 3.4660614867042185
Validation loss: 2.5425222447265234

Epoch: 5| Step: 10
Training loss: 2.7871039857658566
Validation loss: 2.571567871533484

Epoch: 135| Step: 0
Training loss: 2.8473359020664875
Validation loss: 2.5495082776428184

Epoch: 5| Step: 1
Training loss: 2.8951841948685746
Validation loss: 2.6098808646594214

Epoch: 5| Step: 2
Training loss: 2.2455023210811236
Validation loss: 2.552016977665947

Epoch: 5| Step: 3
Training loss: 3.0325808405655783
Validation loss: 2.5590932626968868

Epoch: 5| Step: 4
Training loss: 2.542748038797032
Validation loss: 2.58837407635234

Epoch: 5| Step: 5
Training loss: 3.2729515133724054
Validation loss: 2.510580353082459

Epoch: 5| Step: 6
Training loss: 2.1472081221621604
Validation loss: 2.579854362946859

Epoch: 5| Step: 7
Training loss: 2.837546488511314
Validation loss: 2.601538138247961

Epoch: 5| Step: 8
Training loss: 3.3516976567117203
Validation loss: 2.5572077871464542

Epoch: 5| Step: 9
Training loss: 2.766659817821191
Validation loss: 2.5380192034175475

Epoch: 5| Step: 10
Training loss: 2.794848256504454
Validation loss: 2.5710138198898407

Epoch: 136| Step: 0
Training loss: 2.627057495312807
Validation loss: 2.556887073079714

Epoch: 5| Step: 1
Training loss: 2.4795268034950717
Validation loss: 2.5816218223890828

Epoch: 5| Step: 2
Training loss: 2.907642482110201
Validation loss: 2.5351962612492374

Epoch: 5| Step: 3
Training loss: 2.5791809693793954
Validation loss: 2.5843253227413596

Epoch: 5| Step: 4
Training loss: 2.8935007997323514
Validation loss: 2.547516540258212

Epoch: 5| Step: 5
Training loss: 2.988706152134424
Validation loss: 2.5407615036971767

Epoch: 5| Step: 6
Training loss: 3.2298945109145194
Validation loss: 2.5659448512288106

Epoch: 5| Step: 7
Training loss: 2.5683806327839376
Validation loss: 2.568045904820905

Epoch: 5| Step: 8
Training loss: 2.7717116452908868
Validation loss: 2.575506893228772

Epoch: 5| Step: 9
Training loss: 2.7573017803756525
Validation loss: 2.5761546053569533

Epoch: 5| Step: 10
Training loss: 2.907358921921906
Validation loss: 2.5693867700680326

Epoch: 137| Step: 0
Training loss: 2.2869446627548577
Validation loss: 2.5746430909618776

Epoch: 5| Step: 1
Training loss: 2.6465679760780665
Validation loss: 2.5846443329650044

Epoch: 5| Step: 2
Training loss: 3.1089446570328594
Validation loss: 2.560292721693776

Epoch: 5| Step: 3
Training loss: 2.7392989810019124
Validation loss: 2.556790189021143

Epoch: 5| Step: 4
Training loss: 2.8725306645575155
Validation loss: 2.5800839938634446

Epoch: 5| Step: 5
Training loss: 2.3946831858786624
Validation loss: 2.574254947386509

Epoch: 5| Step: 6
Training loss: 3.1299180051161084
Validation loss: 2.5737716817150513

Epoch: 5| Step: 7
Training loss: 2.9557920653698924
Validation loss: 2.5329318721272536

Epoch: 5| Step: 8
Training loss: 3.20353748177788
Validation loss: 2.54852154728717

Epoch: 5| Step: 9
Training loss: 2.7516938974784098
Validation loss: 2.5930615601297613

Epoch: 5| Step: 10
Training loss: 2.332894783587349
Validation loss: 2.5835613763038507

Epoch: 138| Step: 0
Training loss: 3.2408506279939453
Validation loss: 2.5576888588949616

Epoch: 5| Step: 1
Training loss: 2.7742032565492893
Validation loss: 2.5595185377738305

Epoch: 5| Step: 2
Training loss: 3.0450961666863128
Validation loss: 2.5581895614356474

Epoch: 5| Step: 3
Training loss: 2.795117982479492
Validation loss: 2.583899641997435

Epoch: 5| Step: 4
Training loss: 2.3719541192208937
Validation loss: 2.527770861610538

Epoch: 5| Step: 5
Training loss: 2.704474668982584
Validation loss: 2.5749408985543205

Epoch: 5| Step: 6
Training loss: 2.688566040811429
Validation loss: 2.5365295204761495

Epoch: 5| Step: 7
Training loss: 2.5903015192447785
Validation loss: 2.5584511763593016

Epoch: 5| Step: 8
Training loss: 2.6092574955415095
Validation loss: 2.527875060414756

Epoch: 5| Step: 9
Training loss: 2.9439062510366356
Validation loss: 2.5712530417122252

Epoch: 5| Step: 10
Training loss: 2.9233474693116053
Validation loss: 2.5814445774449077

Epoch: 139| Step: 0
Training loss: 2.7152947579514444
Validation loss: 2.544161111304649

Epoch: 5| Step: 1
Training loss: 2.8711786166772604
Validation loss: 2.5392519826051574

Epoch: 5| Step: 2
Training loss: 3.232187314469171
Validation loss: 2.578407319373003

Epoch: 5| Step: 3
Training loss: 2.6934365641132785
Validation loss: 2.57688251385756

Epoch: 5| Step: 4
Training loss: 2.5169266833788373
Validation loss: 2.560727571693729

Epoch: 5| Step: 5
Training loss: 2.4149128919099123
Validation loss: 2.5735341055649648

Epoch: 5| Step: 6
Training loss: 2.8474120989085407
Validation loss: 2.5148775537652495

Epoch: 5| Step: 7
Training loss: 2.5032941096755157
Validation loss: 2.5186234213798873

Epoch: 5| Step: 8
Training loss: 3.3721779221444756
Validation loss: 2.5363982266504013

Epoch: 5| Step: 9
Training loss: 2.7008853520420835
Validation loss: 2.5311525975057623

Epoch: 5| Step: 10
Training loss: 2.5225931650580726
Validation loss: 2.5597168649942605

Epoch: 140| Step: 0
Training loss: 2.9758394419417704
Validation loss: 2.601079165021123

Epoch: 5| Step: 1
Training loss: 2.73625258151543
Validation loss: 2.57200852707622

Epoch: 5| Step: 2
Training loss: 2.868737739752873
Validation loss: 2.5777472553970315

Epoch: 5| Step: 3
Training loss: 2.5209237915286753
Validation loss: 2.5885038723236082

Epoch: 5| Step: 4
Training loss: 2.8595867808141153
Validation loss: 2.556159308584542

Epoch: 5| Step: 5
Training loss: 2.4224866525382702
Validation loss: 2.583213125231275

Epoch: 5| Step: 6
Training loss: 3.5951020724219798
Validation loss: 2.5886606079461063

Epoch: 5| Step: 7
Training loss: 2.6621105392800555
Validation loss: 2.571054066821328

Epoch: 5| Step: 8
Training loss: 3.0605172726113063
Validation loss: 2.591806287604909

Epoch: 5| Step: 9
Training loss: 2.416231335421336
Validation loss: 2.573045784560693

Epoch: 5| Step: 10
Training loss: 2.2038846701478607
Validation loss: 2.575872246095498

Epoch: 141| Step: 0
Training loss: 2.8716442592438134
Validation loss: 2.5847126582708855

Epoch: 5| Step: 1
Training loss: 2.8480860591165915
Validation loss: 2.5806857450688345

Epoch: 5| Step: 2
Training loss: 2.027028435972944
Validation loss: 2.562719402229723

Epoch: 5| Step: 3
Training loss: 2.6833511975880397
Validation loss: 2.5783301795412914

Epoch: 5| Step: 4
Training loss: 2.4111250996611147
Validation loss: 2.5913072012778056

Epoch: 5| Step: 5
Training loss: 2.8717066934474555
Validation loss: 2.5981903052713604

Epoch: 5| Step: 6
Training loss: 3.109024258101467
Validation loss: 2.583375035987043

Epoch: 5| Step: 7
Training loss: 3.181380587372631
Validation loss: 2.595682273694639

Epoch: 5| Step: 8
Training loss: 2.513569625991982
Validation loss: 2.5598609855263756

Epoch: 5| Step: 9
Training loss: 3.405286320146982
Validation loss: 2.5486407344235373

Epoch: 5| Step: 10
Training loss: 2.587029264080329
Validation loss: 2.607433154349169

Epoch: 142| Step: 0
Training loss: 2.891300431804119
Validation loss: 2.5852027391733707

Epoch: 5| Step: 1
Training loss: 3.0642832021483835
Validation loss: 2.560224676929615

Epoch: 5| Step: 2
Training loss: 2.6960700255958225
Validation loss: 2.589901314978835

Epoch: 5| Step: 3
Training loss: 3.713044991612842
Validation loss: 2.569537264333489

Epoch: 5| Step: 4
Training loss: 2.274387017134713
Validation loss: 2.561540942897171

Epoch: 5| Step: 5
Training loss: 2.664979212037505
Validation loss: 2.5372294387348253

Epoch: 5| Step: 6
Training loss: 2.6440917964241484
Validation loss: 2.553261142860844

Epoch: 5| Step: 7
Training loss: 2.334560639176186
Validation loss: 2.575552892400903

Epoch: 5| Step: 8
Training loss: 2.318648952534189
Validation loss: 2.580872269123953

Epoch: 5| Step: 9
Training loss: 3.063521234383014
Validation loss: 2.578116276273514

Epoch: 5| Step: 10
Training loss: 2.6545412738441714
Validation loss: 2.526397429010942

Epoch: 143| Step: 0
Training loss: 2.7641882316323936
Validation loss: 2.5425930056541723

Epoch: 5| Step: 1
Training loss: 2.5823565348891915
Validation loss: 2.574210306824395

Epoch: 5| Step: 2
Training loss: 2.6544154395428747
Validation loss: 2.5657707388095914

Epoch: 5| Step: 3
Training loss: 2.393489144158194
Validation loss: 2.5733611750968164

Epoch: 5| Step: 4
Training loss: 3.1856850337433404
Validation loss: 2.5200252195314823

Epoch: 5| Step: 5
Training loss: 2.6781597620378315
Validation loss: 2.5878195483430173

Epoch: 5| Step: 6
Training loss: 2.6921828523973232
Validation loss: 2.56412632474271

Epoch: 5| Step: 7
Training loss: 3.4398924391586663
Validation loss: 2.560145967844335

Epoch: 5| Step: 8
Training loss: 2.6869595893629263
Validation loss: 2.578740611927822

Epoch: 5| Step: 9
Training loss: 2.532685520347287
Validation loss: 2.5734319398020755

Epoch: 5| Step: 10
Training loss: 2.963497454286077
Validation loss: 2.580264123670847

Epoch: 144| Step: 0
Training loss: 2.5744829751357683
Validation loss: 2.561016434654509

Epoch: 5| Step: 1
Training loss: 2.6468863206641577
Validation loss: 2.5506659229179425

Epoch: 5| Step: 2
Training loss: 2.2672004220858484
Validation loss: 2.5586480102446707

Epoch: 5| Step: 3
Training loss: 3.2754568640346733
Validation loss: 2.570724153622692

Epoch: 5| Step: 4
Training loss: 2.1845267661967944
Validation loss: 2.561461853901137

Epoch: 5| Step: 5
Training loss: 3.3100196621129334
Validation loss: 2.567100336271537

Epoch: 5| Step: 6
Training loss: 2.8944289463512614
Validation loss: 2.5778522266360353

Epoch: 5| Step: 7
Training loss: 2.4091778072107073
Validation loss: 2.5968750414230026

Epoch: 5| Step: 8
Training loss: 2.849304475742001
Validation loss: 2.5929830410304135

Epoch: 5| Step: 9
Training loss: 2.9170964787181624
Validation loss: 2.5621276102670563

Epoch: 5| Step: 10
Training loss: 2.9915525395151743
Validation loss: 2.5412698258067747

Epoch: 145| Step: 0
Training loss: 3.550886532405059
Validation loss: 2.5819185926867854

Epoch: 5| Step: 1
Training loss: 2.4038465312077153
Validation loss: 2.5320484431923727

Epoch: 5| Step: 2
Training loss: 2.503777415848704
Validation loss: 2.5525138091787998

Epoch: 5| Step: 3
Training loss: 2.6793607729477804
Validation loss: 2.5688720640590113

Epoch: 5| Step: 4
Training loss: 2.8500818876582166
Validation loss: 2.559991851125202

Epoch: 5| Step: 5
Training loss: 2.5373249388191903
Validation loss: 2.5316677693185414

Epoch: 5| Step: 6
Training loss: 2.803809918576735
Validation loss: 2.5513718384020083

Epoch: 5| Step: 7
Training loss: 2.5244402236615895
Validation loss: 2.55187174104279

Epoch: 5| Step: 8
Training loss: 2.784802000996376
Validation loss: 2.5622132143601783

Epoch: 5| Step: 9
Training loss: 2.5184532047458474
Validation loss: 2.588793016281325

Epoch: 5| Step: 10
Training loss: 3.3178724949983245
Validation loss: 2.5764505775347986

Epoch: 146| Step: 0
Training loss: 3.313233060515583
Validation loss: 2.545564003164997

Epoch: 5| Step: 1
Training loss: 2.8158831275886658
Validation loss: 2.5580552433160704

Epoch: 5| Step: 2
Training loss: 2.3006178274874505
Validation loss: 2.5324210832179435

Epoch: 5| Step: 3
Training loss: 3.488565431234646
Validation loss: 2.591886641530496

Epoch: 5| Step: 4
Training loss: 2.1331492846291646
Validation loss: 2.5716579259872856

Epoch: 5| Step: 5
Training loss: 2.9510274229413977
Validation loss: 2.5744758851116214

Epoch: 5| Step: 6
Training loss: 2.703961546122229
Validation loss: 2.5591936107297695

Epoch: 5| Step: 7
Training loss: 2.628354789857562
Validation loss: 2.556479371626879

Epoch: 5| Step: 8
Training loss: 2.497085207229727
Validation loss: 2.543105628564535

Epoch: 5| Step: 9
Training loss: 2.6233498063917358
Validation loss: 2.562636094940041

Epoch: 5| Step: 10
Training loss: 2.991762295383789
Validation loss: 2.5591849757365175

Epoch: 147| Step: 0
Training loss: 3.078157221436685
Validation loss: 2.5783398391738386

Epoch: 5| Step: 1
Training loss: 3.1044118558240714
Validation loss: 2.561098126975032

Epoch: 5| Step: 2
Training loss: 2.512316595566945
Validation loss: 2.5968519486875317

Epoch: 5| Step: 3
Training loss: 2.260948880265178
Validation loss: 2.5627359931379097

Epoch: 5| Step: 4
Training loss: 3.0842922025657855
Validation loss: 2.5677960979093855

Epoch: 5| Step: 5
Training loss: 2.3178790654651467
Validation loss: 2.5741824654607792

Epoch: 5| Step: 6
Training loss: 2.698958167651893
Validation loss: 2.57253545997946

Epoch: 5| Step: 7
Training loss: 2.5615364682283883
Validation loss: 2.54916845983697

Epoch: 5| Step: 8
Training loss: 2.910155266883223
Validation loss: 2.577899920798874

Epoch: 5| Step: 9
Training loss: 3.1918431033245094
Validation loss: 2.5849186369400696

Epoch: 5| Step: 10
Training loss: 2.45230302585452
Validation loss: 2.6081863554027174

Epoch: 148| Step: 0
Training loss: 2.7430887941903195
Validation loss: 2.5594044497922868

Epoch: 5| Step: 1
Training loss: 2.86953298484029
Validation loss: 2.5629017772784177

Epoch: 5| Step: 2
Training loss: 2.959204173973421
Validation loss: 2.5760968954085657

Epoch: 5| Step: 3
Training loss: 2.8439273988494778
Validation loss: 2.527835931221334

Epoch: 5| Step: 4
Training loss: 3.0316825636715525
Validation loss: 2.5808452267479542

Epoch: 5| Step: 5
Training loss: 2.9378238255996956
Validation loss: 2.5490347867452607

Epoch: 5| Step: 6
Training loss: 2.70170538344068
Validation loss: 2.545356780631362

Epoch: 5| Step: 7
Training loss: 2.5673392587060273
Validation loss: 2.5723278349490326

Epoch: 5| Step: 8
Training loss: 2.4493827704062783
Validation loss: 2.5462690898808664

Epoch: 5| Step: 9
Training loss: 2.928794460244086
Validation loss: 2.572728803861475

Epoch: 5| Step: 10
Training loss: 2.319801967982245
Validation loss: 2.56888884975076

Epoch: 149| Step: 0
Training loss: 2.7168242551190396
Validation loss: 2.586935156912401

Epoch: 5| Step: 1
Training loss: 2.46025516799339
Validation loss: 2.5761736294236646

Epoch: 5| Step: 2
Training loss: 2.9064050448499095
Validation loss: 2.5939685775394827

Epoch: 5| Step: 3
Training loss: 2.478902968372345
Validation loss: 2.5636256557065713

Epoch: 5| Step: 4
Training loss: 2.2964616260806614
Validation loss: 2.5596840135030487

Epoch: 5| Step: 5
Training loss: 2.7066617551142036
Validation loss: 2.5843667521343088

Epoch: 5| Step: 6
Training loss: 3.440767573175315
Validation loss: 2.5663146012310287

Epoch: 5| Step: 7
Training loss: 3.012273161012729
Validation loss: 2.5533237405377927

Epoch: 5| Step: 8
Training loss: 2.8639546392247746
Validation loss: 2.5854415256824597

Epoch: 5| Step: 9
Training loss: 3.124266576532059
Validation loss: 2.5558079842617687

Epoch: 5| Step: 10
Training loss: 2.4291680568824137
Validation loss: 2.5623045015630987

Epoch: 150| Step: 0
Training loss: 2.86127513016197
Validation loss: 2.5806726501010875

Epoch: 5| Step: 1
Training loss: 3.0402617846256557
Validation loss: 2.552297919072723

Epoch: 5| Step: 2
Training loss: 2.4734303978572822
Validation loss: 2.5597268722913595

Epoch: 5| Step: 3
Training loss: 2.2761829486588683
Validation loss: 2.5721048588331437

Epoch: 5| Step: 4
Training loss: 3.0303366946749106
Validation loss: 2.546659503644935

Epoch: 5| Step: 5
Training loss: 2.4376212847930607
Validation loss: 2.563882274362363

Epoch: 5| Step: 6
Training loss: 2.4509901731707315
Validation loss: 2.563981749056348

Epoch: 5| Step: 7
Training loss: 3.2056782292591217
Validation loss: 2.5713426171643485

Epoch: 5| Step: 8
Training loss: 3.015610927094349
Validation loss: 2.531695299518138

Epoch: 5| Step: 9
Training loss: 2.966569923223621
Validation loss: 2.5684110793095853

Epoch: 5| Step: 10
Training loss: 2.739835333505304
Validation loss: 2.5397378850876065

Epoch: 151| Step: 0
Training loss: 3.27160316365494
Validation loss: 2.5465119520412967

Epoch: 5| Step: 1
Training loss: 3.415310489731786
Validation loss: 2.5558687000467804

Epoch: 5| Step: 2
Training loss: 2.7082518540866123
Validation loss: 2.562088610953563

Epoch: 5| Step: 3
Training loss: 3.2317445535177893
Validation loss: 2.5493049285934055

Epoch: 5| Step: 4
Training loss: 2.577707430228596
Validation loss: 2.561438718134164

Epoch: 5| Step: 5
Training loss: 3.1741258874745553
Validation loss: 2.5840724823114494

Epoch: 5| Step: 6
Training loss: 2.0819371186067364
Validation loss: 2.5596447486024556

Epoch: 5| Step: 7
Training loss: 2.424525527155743
Validation loss: 2.590050857774078

Epoch: 5| Step: 8
Training loss: 2.8046458461717996
Validation loss: 2.5149471954763105

Epoch: 5| Step: 9
Training loss: 2.5640626190204117
Validation loss: 2.6099810909252152

Epoch: 5| Step: 10
Training loss: 2.0989416861682497
Validation loss: 2.575937612387316

Epoch: 152| Step: 0
Training loss: 3.2250896352686973
Validation loss: 2.5695609736899714

Epoch: 5| Step: 1
Training loss: 1.9120611198344748
Validation loss: 2.5711549421295867

Epoch: 5| Step: 2
Training loss: 2.535361165609702
Validation loss: 2.569590209008751

Epoch: 5| Step: 3
Training loss: 2.330927448611586
Validation loss: 2.600449494189641

Epoch: 5| Step: 4
Training loss: 3.240427886353547
Validation loss: 2.545413308161837

Epoch: 5| Step: 5
Training loss: 3.364153918252457
Validation loss: 2.589578669695987

Epoch: 5| Step: 6
Training loss: 3.078108269505611
Validation loss: 2.593045506316716

Epoch: 5| Step: 7
Training loss: 2.9352859919214205
Validation loss: 2.542259839190401

Epoch: 5| Step: 8
Training loss: 2.610415496785317
Validation loss: 2.5944809381000713

Epoch: 5| Step: 9
Training loss: 2.420668467577817
Validation loss: 2.539097130778294

Epoch: 5| Step: 10
Training loss: 3.099405071638056
Validation loss: 2.549943074639165

Epoch: 153| Step: 0
Training loss: 3.065462197930106
Validation loss: 2.557084235896692

Epoch: 5| Step: 1
Training loss: 2.4743743760815646
Validation loss: 2.560985169960614

Epoch: 5| Step: 2
Training loss: 2.5588765461260943
Validation loss: 2.5519549506825463

Epoch: 5| Step: 3
Training loss: 2.736455855836147
Validation loss: 2.5921867217064016

Epoch: 5| Step: 4
Training loss: 3.089664265933126
Validation loss: 2.5637099248139705

Epoch: 5| Step: 5
Training loss: 2.2343649697245365
Validation loss: 2.559085279523945

Epoch: 5| Step: 6
Training loss: 2.933551163243649
Validation loss: 2.553469079306842

Epoch: 5| Step: 7
Training loss: 2.897108570217373
Validation loss: 2.5745519972929687

Epoch: 5| Step: 8
Training loss: 2.9500409527538434
Validation loss: 2.5593796496923953

Epoch: 5| Step: 9
Training loss: 2.315141458000037
Validation loss: 2.5723618614204984

Epoch: 5| Step: 10
Training loss: 3.139363809026798
Validation loss: 2.5546054120055963

Epoch: 154| Step: 0
Training loss: 2.000765058101152
Validation loss: 2.5782662808813654

Epoch: 5| Step: 1
Training loss: 2.773294708444538
Validation loss: 2.596467552622449

Epoch: 5| Step: 2
Training loss: 2.812004639129285
Validation loss: 2.5701258763944312

Epoch: 5| Step: 3
Training loss: 3.0362438477304257
Validation loss: 2.593592846909784

Epoch: 5| Step: 4
Training loss: 2.935899501390193
Validation loss: 2.567047040641415

Epoch: 5| Step: 5
Training loss: 3.0135000381381114
Validation loss: 2.5566302386189883

Epoch: 5| Step: 6
Training loss: 3.637817872306187
Validation loss: 2.5490089474003503

Epoch: 5| Step: 7
Training loss: 2.2526439391283524
Validation loss: 2.59036200450761

Epoch: 5| Step: 8
Training loss: 3.0952808946577846
Validation loss: 2.5569525437172005

Epoch: 5| Step: 9
Training loss: 2.545151952617773
Validation loss: 2.587900844313105

Epoch: 5| Step: 10
Training loss: 1.922510429721117
Validation loss: 2.525377914322745

Epoch: 155| Step: 0
Training loss: 2.4043452663184564
Validation loss: 2.5888708256970934

Epoch: 5| Step: 1
Training loss: 3.2726407412928515
Validation loss: 2.54296416603314

Epoch: 5| Step: 2
Training loss: 2.913606255126473
Validation loss: 2.5290963842904852

Epoch: 5| Step: 3
Training loss: 2.6482859880437752
Validation loss: 2.551090638242249

Epoch: 5| Step: 4
Training loss: 3.0150359373971627
Validation loss: 2.538212207061511

Epoch: 5| Step: 5
Training loss: 2.725267075215951
Validation loss: 2.5582223078552815

Epoch: 5| Step: 6
Training loss: 2.8745481716544794
Validation loss: 2.565317493340357

Epoch: 5| Step: 7
Training loss: 2.107596318588184
Validation loss: 2.574066516626624

Epoch: 5| Step: 8
Training loss: 2.403072091699555
Validation loss: 2.604299454451718

Epoch: 5| Step: 9
Training loss: 2.7207590331544798
Validation loss: 2.586242625064327

Epoch: 5| Step: 10
Training loss: 3.18024186684032
Validation loss: 2.5805624349662923

Epoch: 156| Step: 0
Training loss: 3.255127017213516
Validation loss: 2.5319109759741543

Epoch: 5| Step: 1
Training loss: 2.8114730655547535
Validation loss: 2.581729191064716

Epoch: 5| Step: 2
Training loss: 2.258574993909388
Validation loss: 2.5662806014684976

Epoch: 5| Step: 3
Training loss: 2.354313859867231
Validation loss: 2.5445537506612586

Epoch: 5| Step: 4
Training loss: 3.179109188041862
Validation loss: 2.5666225814975308

Epoch: 5| Step: 5
Training loss: 2.950967313290075
Validation loss: 2.556408377328666

Epoch: 5| Step: 6
Training loss: 2.5344197712623164
Validation loss: 2.578004476117214

Epoch: 5| Step: 7
Training loss: 2.829294711002469
Validation loss: 2.5667724388082838

Epoch: 5| Step: 8
Training loss: 3.1487382693070303
Validation loss: 2.53052371275403

Epoch: 5| Step: 9
Training loss: 2.656189951498417
Validation loss: 2.555681838747814

Epoch: 5| Step: 10
Training loss: 2.2505937428675504
Validation loss: 2.541337924141178

Epoch: 157| Step: 0
Training loss: 3.179643110485608
Validation loss: 2.551438076541696

Epoch: 5| Step: 1
Training loss: 2.4572553911451718
Validation loss: 2.607972831690318

Epoch: 5| Step: 2
Training loss: 2.726523587624147
Validation loss: 2.5886962627236714

Epoch: 5| Step: 3
Training loss: 2.956787260564385
Validation loss: 2.562425719874579

Epoch: 5| Step: 4
Training loss: 2.1204086518044045
Validation loss: 2.554775188740261

Epoch: 5| Step: 5
Training loss: 2.720408229907308
Validation loss: 2.567399946931405

Epoch: 5| Step: 6
Training loss: 1.9182304623306239
Validation loss: 2.552234390204866

Epoch: 5| Step: 7
Training loss: 3.16804160000239
Validation loss: 2.568083487963877

Epoch: 5| Step: 8
Training loss: 3.196343216057059
Validation loss: 2.5522681973981776

Epoch: 5| Step: 9
Training loss: 2.7927590885029834
Validation loss: 2.577818245784333

Epoch: 5| Step: 10
Training loss: 2.9492024200189455
Validation loss: 2.5698073409043456

Epoch: 158| Step: 0
Training loss: 3.1081255218609742
Validation loss: 2.562087836484584

Epoch: 5| Step: 1
Training loss: 2.662654291974562
Validation loss: 2.576083983114518

Epoch: 5| Step: 2
Training loss: 2.9018385025085585
Validation loss: 2.5824392516795

Epoch: 5| Step: 3
Training loss: 2.4149367838734372
Validation loss: 2.5567603922263116

Epoch: 5| Step: 4
Training loss: 2.1313265700023654
Validation loss: 2.585517628384706

Epoch: 5| Step: 5
Training loss: 2.2481817740259573
Validation loss: 2.5658296601753103

Epoch: 5| Step: 6
Training loss: 2.4380738976586285
Validation loss: 2.5705724842093614

Epoch: 5| Step: 7
Training loss: 2.904715840661567
Validation loss: 2.607145079110957

Epoch: 5| Step: 8
Training loss: 3.2262972152311544
Validation loss: 2.5809150879575196

Epoch: 5| Step: 9
Training loss: 3.5459203569706013
Validation loss: 2.5773736589170593

Epoch: 5| Step: 10
Training loss: 2.563142649383539
Validation loss: 2.5504529331182866

Epoch: 159| Step: 0
Training loss: 3.068791213992194
Validation loss: 2.560449494633426

Epoch: 5| Step: 1
Training loss: 2.576573870502503
Validation loss: 2.591520483682364

Epoch: 5| Step: 2
Training loss: 2.6613168299334653
Validation loss: 2.532966493609521

Epoch: 5| Step: 3
Training loss: 2.0541520381919884
Validation loss: 2.59261924508096

Epoch: 5| Step: 4
Training loss: 2.4043466545796144
Validation loss: 2.5357697870394267

Epoch: 5| Step: 5
Training loss: 3.2966905876760078
Validation loss: 2.56957266765786

Epoch: 5| Step: 6
Training loss: 2.6651328165764414
Validation loss: 2.5744623134365017

Epoch: 5| Step: 7
Training loss: 2.409760428744752
Validation loss: 2.5744433275098735

Epoch: 5| Step: 8
Training loss: 2.879092248009151
Validation loss: 2.5456223242326126

Epoch: 5| Step: 9
Training loss: 3.6566558351822853
Validation loss: 2.549206070881647

Epoch: 5| Step: 10
Training loss: 2.562933443209181
Validation loss: 2.5540456239876095

Epoch: 160| Step: 0
Training loss: 2.9769504724802838
Validation loss: 2.5896758902088384

Epoch: 5| Step: 1
Training loss: 2.2657905255064628
Validation loss: 2.541553738561709

Epoch: 5| Step: 2
Training loss: 3.3284360355226776
Validation loss: 2.544475295343169

Epoch: 5| Step: 3
Training loss: 2.9330410493825827
Validation loss: 2.5507302959046227

Epoch: 5| Step: 4
Training loss: 2.160955519197683
Validation loss: 2.5402960268049886

Epoch: 5| Step: 5
Training loss: 3.342341616636427
Validation loss: 2.5628070512276873

Epoch: 5| Step: 6
Training loss: 2.299790692134964
Validation loss: 2.5573169645264437

Epoch: 5| Step: 7
Training loss: 2.823716663773426
Validation loss: 2.5471355547288677

Epoch: 5| Step: 8
Training loss: 2.455966542901404
Validation loss: 2.588851962272972

Epoch: 5| Step: 9
Training loss: 2.7608636074400197
Validation loss: 2.5529220585748287

Epoch: 5| Step: 10
Training loss: 2.9469815086299795
Validation loss: 2.5663487473880044

Epoch: 161| Step: 0
Training loss: 2.5652465987317257
Validation loss: 2.6011143982450786

Epoch: 5| Step: 1
Training loss: 2.3228913948725727
Validation loss: 2.571204729214837

Epoch: 5| Step: 2
Training loss: 2.6481767824290157
Validation loss: 2.5441106725555174

Epoch: 5| Step: 3
Training loss: 2.461799785378286
Validation loss: 2.5197349395414688

Epoch: 5| Step: 4
Training loss: 2.8757916894633593
Validation loss: 2.5728405692143026

Epoch: 5| Step: 5
Training loss: 2.953520248847392
Validation loss: 2.547115443168915

Epoch: 5| Step: 6
Training loss: 2.3469382408347954
Validation loss: 2.562964472580995

Epoch: 5| Step: 7
Training loss: 2.962447855687667
Validation loss: 2.55306106549386

Epoch: 5| Step: 8
Training loss: 3.8702832710231205
Validation loss: 2.5678399883906127

Epoch: 5| Step: 9
Training loss: 2.4394794154220327
Validation loss: 2.565617715388243

Epoch: 5| Step: 10
Training loss: 2.3076906454862818
Validation loss: 2.578380889474154

Epoch: 162| Step: 0
Training loss: 2.7606851027382158
Validation loss: 2.5625805185605026

Epoch: 5| Step: 1
Training loss: 2.4429274557665814
Validation loss: 2.5412488022651987

Epoch: 5| Step: 2
Training loss: 3.071933774492569
Validation loss: 2.5778191577408105

Epoch: 5| Step: 3
Training loss: 2.780809431864038
Validation loss: 2.579956103470785

Epoch: 5| Step: 4
Training loss: 2.3807001475288416
Validation loss: 2.5554153766710654

Epoch: 5| Step: 5
Training loss: 2.3893598811783603
Validation loss: 2.5367032882226446

Epoch: 5| Step: 6
Training loss: 2.6756392169762697
Validation loss: 2.555575597722219

Epoch: 5| Step: 7
Training loss: 3.1258256965800877
Validation loss: 2.52843744967049

Epoch: 5| Step: 8
Training loss: 2.2841679971109565
Validation loss: 2.5501144073465185

Epoch: 5| Step: 9
Training loss: 3.3010883617298465
Validation loss: 2.522936213795721

Epoch: 5| Step: 10
Training loss: 3.2424757496111525
Validation loss: 2.539385092461945

Epoch: 163| Step: 0
Training loss: 2.5948860713814983
Validation loss: 2.5535820410074197

Epoch: 5| Step: 1
Training loss: 2.599134899147889
Validation loss: 2.5515926335517554

Epoch: 5| Step: 2
Training loss: 3.1586084901898364
Validation loss: 2.520068641912055

Epoch: 5| Step: 3
Training loss: 2.207807502281974
Validation loss: 2.584231406780311

Epoch: 5| Step: 4
Training loss: 2.97889742045841
Validation loss: 2.572392466123955

Epoch: 5| Step: 5
Training loss: 2.722747757412424
Validation loss: 2.5638898246395847

Epoch: 5| Step: 6
Training loss: 2.9939491922454313
Validation loss: 2.560706963193465

Epoch: 5| Step: 7
Training loss: 2.5657010437711367
Validation loss: 2.5682697064792968

Epoch: 5| Step: 8
Training loss: 2.7260347309153077
Validation loss: 2.5774409311674535

Epoch: 5| Step: 9
Training loss: 2.889368722468609
Validation loss: 2.5826558438072724

Epoch: 5| Step: 10
Training loss: 3.0036870234027555
Validation loss: 2.578218114221095

Epoch: 164| Step: 0
Training loss: 2.668755924834703
Validation loss: 2.5428069209859845

Epoch: 5| Step: 1
Training loss: 3.1887221143961972
Validation loss: 2.564660261984365

Epoch: 5| Step: 2
Training loss: 2.583969612108244
Validation loss: 2.5808546196946853

Epoch: 5| Step: 3
Training loss: 2.4039022709091724
Validation loss: 2.5550114137577493

Epoch: 5| Step: 4
Training loss: 2.1968487017646035
Validation loss: 2.605273652764162

Epoch: 5| Step: 5
Training loss: 2.9007208947586722
Validation loss: 2.5392667197616197

Epoch: 5| Step: 6
Training loss: 3.191474381540191
Validation loss: 2.547569009729597

Epoch: 5| Step: 7
Training loss: 2.5454215366526958
Validation loss: 2.6082423370564514

Epoch: 5| Step: 8
Training loss: 3.248405505559958
Validation loss: 2.598868462190773

Epoch: 5| Step: 9
Training loss: 2.212526646685296
Validation loss: 2.5158470146029126

Epoch: 5| Step: 10
Training loss: 2.858051431469405
Validation loss: 2.5831586793283376

Epoch: 165| Step: 0
Training loss: 2.580972936506835
Validation loss: 2.575834049056182

Epoch: 5| Step: 1
Training loss: 2.9807140004458015
Validation loss: 2.579903625910269

Epoch: 5| Step: 2
Training loss: 2.9853370274323128
Validation loss: 2.555818508394385

Epoch: 5| Step: 3
Training loss: 2.543249814956615
Validation loss: 2.5720435535083634

Epoch: 5| Step: 4
Training loss: 2.5901265399906745
Validation loss: 2.5352459601924267

Epoch: 5| Step: 5
Training loss: 2.3229360422828833
Validation loss: 2.551010908695956

Epoch: 5| Step: 6
Training loss: 3.0620554387252135
Validation loss: 2.556926280065377

Epoch: 5| Step: 7
Training loss: 2.7230395973512165
Validation loss: 2.571716076971805

Epoch: 5| Step: 8
Training loss: 2.628393794952578
Validation loss: 2.5464969396939914

Epoch: 5| Step: 9
Training loss: 2.7372680182557696
Validation loss: 2.587840055844999

Epoch: 5| Step: 10
Training loss: 3.0937000617418433
Validation loss: 2.5683990376884536

Epoch: 166| Step: 0
Training loss: 2.8357567427436567
Validation loss: 2.5680937286959815

Epoch: 5| Step: 1
Training loss: 2.4241013661079656
Validation loss: 2.504481887067194

Epoch: 5| Step: 2
Training loss: 2.695979911989711
Validation loss: 2.5406847586395576

Epoch: 5| Step: 3
Training loss: 2.924673117606245
Validation loss: 2.5426783206755714

Epoch: 5| Step: 4
Training loss: 2.8738180301639846
Validation loss: 2.5545082487247726

Epoch: 5| Step: 5
Training loss: 2.16708163420201
Validation loss: 2.593146766861879

Epoch: 5| Step: 6
Training loss: 2.750700427934362
Validation loss: 2.585322915584576

Epoch: 5| Step: 7
Training loss: 3.2103573908564087
Validation loss: 2.5864595563409885

Epoch: 5| Step: 8
Training loss: 2.452583787830321
Validation loss: 2.579942222772456

Epoch: 5| Step: 9
Training loss: 3.0796040500925894
Validation loss: 2.5582724663760623

Epoch: 5| Step: 10
Training loss: 2.9549580692730837
Validation loss: 2.561960404131537

Epoch: 167| Step: 0
Training loss: 3.0309975115829717
Validation loss: 2.5599661363969175

Epoch: 5| Step: 1
Training loss: 2.7643127776630965
Validation loss: 2.5575378769276136

Epoch: 5| Step: 2
Training loss: 3.0869376963960033
Validation loss: 2.5782764617788296

Epoch: 5| Step: 3
Training loss: 2.4809588090889862
Validation loss: 2.565781934982355

Epoch: 5| Step: 4
Training loss: 2.925207512170344
Validation loss: 2.5500801071430286

Epoch: 5| Step: 5
Training loss: 2.504736228654482
Validation loss: 2.565217888556123

Epoch: 5| Step: 6
Training loss: 2.9365497431894583
Validation loss: 2.534805932720394

Epoch: 5| Step: 7
Training loss: 2.27109629890396
Validation loss: 2.5733505732737587

Epoch: 5| Step: 8
Training loss: 2.942316854087716
Validation loss: 2.538774204846536

Epoch: 5| Step: 9
Training loss: 2.4755774623868736
Validation loss: 2.578975591119278

Epoch: 5| Step: 10
Training loss: 2.8979123197550822
Validation loss: 2.5452637061355903

Epoch: 168| Step: 0
Training loss: 2.5875608759551305
Validation loss: 2.5810232329683576

Epoch: 5| Step: 1
Training loss: 2.485874515217475
Validation loss: 2.541476443465051

Epoch: 5| Step: 2
Training loss: 3.16589212147298
Validation loss: 2.5450360340052938

Epoch: 5| Step: 3
Training loss: 2.719065154652713
Validation loss: 2.55523382173617

Epoch: 5| Step: 4
Training loss: 2.6603204393621254
Validation loss: 2.535583329670807

Epoch: 5| Step: 5
Training loss: 2.7737788460440522
Validation loss: 2.5844270127406435

Epoch: 5| Step: 6
Training loss: 2.123096398808597
Validation loss: 2.5461939556611095

Epoch: 5| Step: 7
Training loss: 2.804578433665615
Validation loss: 2.5774493105468474

Epoch: 5| Step: 8
Training loss: 3.2997464516076778
Validation loss: 2.5415054258712972

Epoch: 5| Step: 9
Training loss: 2.876331352797592
Validation loss: 2.564417760963939

Epoch: 5| Step: 10
Training loss: 2.892733572956363
Validation loss: 2.566960056744496

Epoch: 169| Step: 0
Training loss: 2.703046852702119
Validation loss: 2.5386919809848276

Epoch: 5| Step: 1
Training loss: 2.701518998421856
Validation loss: 2.5409602053030906

Epoch: 5| Step: 2
Training loss: 2.5666938516077176
Validation loss: 2.554915693777046

Epoch: 5| Step: 3
Training loss: 2.475923473814822
Validation loss: 2.5961849082474746

Epoch: 5| Step: 4
Training loss: 3.108493085613295
Validation loss: 2.5641362348460572

Epoch: 5| Step: 5
Training loss: 2.3565825048127946
Validation loss: 2.5496895645977617

Epoch: 5| Step: 6
Training loss: 3.2906472925371135
Validation loss: 2.552737646917329

Epoch: 5| Step: 7
Training loss: 2.617622726463488
Validation loss: 2.5736445908052175

Epoch: 5| Step: 8
Training loss: 3.23152455209397
Validation loss: 2.5578334956050646

Epoch: 5| Step: 9
Training loss: 2.2125809563087664
Validation loss: 2.5640601214303063

Epoch: 5| Step: 10
Training loss: 3.1801219146678763
Validation loss: 2.567098155214004

Epoch: 170| Step: 0
Training loss: 3.580254067084554
Validation loss: 2.520197858844546

Epoch: 5| Step: 1
Training loss: 2.5351254030769703
Validation loss: 2.557774748859267

Epoch: 5| Step: 2
Training loss: 3.0013205482869263
Validation loss: 2.523593361489408

Epoch: 5| Step: 3
Training loss: 2.2202336898013915
Validation loss: 2.579715587872766

Epoch: 5| Step: 4
Training loss: 2.2446545575982904
Validation loss: 2.5861588552409636

Epoch: 5| Step: 5
Training loss: 2.680598957542735
Validation loss: 2.537195857554082

Epoch: 5| Step: 6
Training loss: 2.71545113554587
Validation loss: 2.5773740508176783

Epoch: 5| Step: 7
Training loss: 2.1324652644164854
Validation loss: 2.5709164151812005

Epoch: 5| Step: 8
Training loss: 3.477829742923618
Validation loss: 2.5484108299400514

Epoch: 5| Step: 9
Training loss: 2.846945675287737
Validation loss: 2.526478142300059

Epoch: 5| Step: 10
Training loss: 2.40524171784302
Validation loss: 2.571493074727469

Epoch: 171| Step: 0
Training loss: 3.1760764272223705
Validation loss: 2.598799464383763

Epoch: 5| Step: 1
Training loss: 2.240798466776358
Validation loss: 2.546711387791922

Epoch: 5| Step: 2
Training loss: 3.173038062722436
Validation loss: 2.533974757283974

Epoch: 5| Step: 3
Training loss: 3.0713413834474275
Validation loss: 2.542135193110277

Epoch: 5| Step: 4
Training loss: 2.7538749097839927
Validation loss: 2.519997256644221

Epoch: 5| Step: 5
Training loss: 2.291454640608144
Validation loss: 2.582436504820147

Epoch: 5| Step: 6
Training loss: 2.518900758382238
Validation loss: 2.543518994842012

Epoch: 5| Step: 7
Training loss: 2.832657696070584
Validation loss: 2.5600911184888067

Epoch: 5| Step: 8
Training loss: 2.8586296402481
Validation loss: 2.5701449775032033

Epoch: 5| Step: 9
Training loss: 1.9117947593329008
Validation loss: 2.5318745944290066

Epoch: 5| Step: 10
Training loss: 3.2187868875408303
Validation loss: 2.606547310428658

Epoch: 172| Step: 0
Training loss: 2.5828589239638804
Validation loss: 2.566696730177814

Epoch: 5| Step: 1
Training loss: 2.3140495882054006
Validation loss: 2.584438609188701

Epoch: 5| Step: 2
Training loss: 3.2260072244183693
Validation loss: 2.5666009910199783

Epoch: 5| Step: 3
Training loss: 2.7509184084031215
Validation loss: 2.555649104916982

Epoch: 5| Step: 4
Training loss: 3.2945739526222315
Validation loss: 2.557795189548281

Epoch: 5| Step: 5
Training loss: 2.945769985296614
Validation loss: 2.537107960359415

Epoch: 5| Step: 6
Training loss: 2.511549497511145
Validation loss: 2.5788334414762817

Epoch: 5| Step: 7
Training loss: 2.6987831658590995
Validation loss: 2.563264138104049

Epoch: 5| Step: 8
Training loss: 2.484201965064185
Validation loss: 2.5588815223687638

Epoch: 5| Step: 9
Training loss: 2.26772416307435
Validation loss: 2.5695335019845054

Epoch: 5| Step: 10
Training loss: 3.1112327968172377
Validation loss: 2.5924027184873615

Epoch: 173| Step: 0
Training loss: 3.2437988689173913
Validation loss: 2.552777171708883

Epoch: 5| Step: 1
Training loss: 2.5673135346895966
Validation loss: 2.5678267021196635

Epoch: 5| Step: 2
Training loss: 2.414863231411278
Validation loss: 2.579309986056809

Epoch: 5| Step: 3
Training loss: 2.368346984720136
Validation loss: 2.5545161257728637

Epoch: 5| Step: 4
Training loss: 3.1069149848300364
Validation loss: 2.553387699129419

Epoch: 5| Step: 5
Training loss: 3.0089743215746303
Validation loss: 2.585760410095355

Epoch: 5| Step: 6
Training loss: 2.9028204915272102
Validation loss: 2.5838587230304007

Epoch: 5| Step: 7
Training loss: 2.6318717203910214
Validation loss: 2.571690607075193

Epoch: 5| Step: 8
Training loss: 2.64842525693151
Validation loss: 2.5471165714414967

Epoch: 5| Step: 9
Training loss: 1.9099105957836662
Validation loss: 2.5854755342521183

Epoch: 5| Step: 10
Training loss: 3.4117982806629366
Validation loss: 2.5570562762386135

Epoch: 174| Step: 0
Training loss: 2.9238180136139458
Validation loss: 2.5824181672006685

Epoch: 5| Step: 1
Training loss: 2.7776772343135336
Validation loss: 2.5433876727506335

Epoch: 5| Step: 2
Training loss: 2.3245968294774686
Validation loss: 2.5888121742471837

Epoch: 5| Step: 3
Training loss: 2.380687529047421
Validation loss: 2.5873328345699225

Epoch: 5| Step: 4
Training loss: 2.639657469694129
Validation loss: 2.554538349776207

Epoch: 5| Step: 5
Training loss: 2.605006232666057
Validation loss: 2.549536695139972

Epoch: 5| Step: 6
Training loss: 2.6767806143
Validation loss: 2.5642865273862943

Epoch: 5| Step: 7
Training loss: 2.863453941810078
Validation loss: 2.5483312942087992

Epoch: 5| Step: 8
Training loss: 2.643877452907459
Validation loss: 2.530225018847274

Epoch: 5| Step: 9
Training loss: 3.1475986470708097
Validation loss: 2.5442731632696374

Epoch: 5| Step: 10
Training loss: 3.3359840979437236
Validation loss: 2.588741204097247

Epoch: 175| Step: 0
Training loss: 2.500065039742345
Validation loss: 2.582655934633588

Epoch: 5| Step: 1
Training loss: 2.9118056161265224
Validation loss: 2.536779306858218

Epoch: 5| Step: 2
Training loss: 2.861962320395616
Validation loss: 2.561817120217944

Epoch: 5| Step: 3
Training loss: 2.5658218438375577
Validation loss: 2.5322900344806185

Epoch: 5| Step: 4
Training loss: 2.841733448067951
Validation loss: 2.516294133186399

Epoch: 5| Step: 5
Training loss: 3.038982164747969
Validation loss: 2.5673244305560563

Epoch: 5| Step: 6
Training loss: 3.0042991034053466
Validation loss: 2.5451540487338655

Epoch: 5| Step: 7
Training loss: 2.5456722672661303
Validation loss: 2.5259195155929395

Epoch: 5| Step: 8
Training loss: 2.1797813477360495
Validation loss: 2.5287108777255707

Epoch: 5| Step: 9
Training loss: 2.8556661263650125
Validation loss: 2.602472497632544

Epoch: 5| Step: 10
Training loss: 3.1028765529967846
Validation loss: 2.5585057342177167

Epoch: 176| Step: 0
Training loss: 2.4754222085896394
Validation loss: 2.550554228192186

Epoch: 5| Step: 1
Training loss: 2.96603542498618
Validation loss: 2.514308522044835

Epoch: 5| Step: 2
Training loss: 2.730023567461285
Validation loss: 2.5276518440864773

Epoch: 5| Step: 3
Training loss: 2.3289747287596163
Validation loss: 2.572352786277084

Epoch: 5| Step: 4
Training loss: 2.6441994575834054
Validation loss: 2.567466383148785

Epoch: 5| Step: 5
Training loss: 2.8510099528877206
Validation loss: 2.6150022206377126

Epoch: 5| Step: 6
Training loss: 3.280644678866056
Validation loss: 2.5590854317945113

Epoch: 5| Step: 7
Training loss: 2.5643174774018225
Validation loss: 2.611671066839075

Epoch: 5| Step: 8
Training loss: 2.8947620377060095
Validation loss: 2.538201416003657

Epoch: 5| Step: 9
Training loss: 2.686127068008563
Validation loss: 2.570541120821232

Epoch: 5| Step: 10
Training loss: 2.8420577830722897
Validation loss: 2.5436061867155444

Epoch: 177| Step: 0
Training loss: 2.4087794496787835
Validation loss: 2.539914184800468

Epoch: 5| Step: 1
Training loss: 2.794757147732344
Validation loss: 2.58506479765194

Epoch: 5| Step: 2
Training loss: 2.8566983728715383
Validation loss: 2.5098369968896166

Epoch: 5| Step: 3
Training loss: 2.9731969354189554
Validation loss: 2.5591558078762517

Epoch: 5| Step: 4
Training loss: 2.4261336753981384
Validation loss: 2.548571699570039

Epoch: 5| Step: 5
Training loss: 2.7171541989585295
Validation loss: 2.581574172161439

Epoch: 5| Step: 6
Training loss: 3.5430675354027343
Validation loss: 2.5546958350955378

Epoch: 5| Step: 7
Training loss: 2.094914923604272
Validation loss: 2.5430591846234214

Epoch: 5| Step: 8
Training loss: 2.976510275234927
Validation loss: 2.575158867503503

Epoch: 5| Step: 9
Training loss: 2.884059729244626
Validation loss: 2.5869635884119155

Epoch: 5| Step: 10
Training loss: 2.723638589934263
Validation loss: 2.5813155979357676

Epoch: 178| Step: 0
Training loss: 2.6808033391072814
Validation loss: 2.5713302203782145

Epoch: 5| Step: 1
Training loss: 2.712390257553518
Validation loss: 2.561986916370789

Epoch: 5| Step: 2
Training loss: 3.3814136176440863
Validation loss: 2.594275066446237

Epoch: 5| Step: 3
Training loss: 2.0764161160943906
Validation loss: 2.551962940087709

Epoch: 5| Step: 4
Training loss: 2.9228551516015386
Validation loss: 2.5497669183821543

Epoch: 5| Step: 5
Training loss: 3.3651230008231416
Validation loss: 2.5482858886575124

Epoch: 5| Step: 6
Training loss: 2.6628840460520444
Validation loss: 2.5512755025581906

Epoch: 5| Step: 7
Training loss: 2.734081056326732
Validation loss: 2.5554065202405396

Epoch: 5| Step: 8
Training loss: 2.552051829448542
Validation loss: 2.5448398386884645

Epoch: 5| Step: 9
Training loss: 2.425633424441052
Validation loss: 2.579269617477699

Epoch: 5| Step: 10
Training loss: 2.6410423716418054
Validation loss: 2.5367646856180084

Epoch: 179| Step: 0
Training loss: 2.79042306406481
Validation loss: 2.5473958865639683

Epoch: 5| Step: 1
Training loss: 2.5229915071239404
Validation loss: 2.571073680029628

Epoch: 5| Step: 2
Training loss: 2.200410509823829
Validation loss: 2.5606944428353655

Epoch: 5| Step: 3
Training loss: 2.271886237325254
Validation loss: 2.5627589221264184

Epoch: 5| Step: 4
Training loss: 2.5980987860242957
Validation loss: 2.555793136855726

Epoch: 5| Step: 5
Training loss: 2.938521511942266
Validation loss: 2.5610351847789943

Epoch: 5| Step: 6
Training loss: 3.3882881233087567
Validation loss: 2.5335400743785073

Epoch: 5| Step: 7
Training loss: 3.0677149998711695
Validation loss: 2.5721065352975105

Epoch: 5| Step: 8
Training loss: 2.639161737178643
Validation loss: 2.5504289596837153

Epoch: 5| Step: 9
Training loss: 2.3293884740408553
Validation loss: 2.5599927463992733

Epoch: 5| Step: 10
Training loss: 3.337773481158276
Validation loss: 2.555005623260379

Epoch: 180| Step: 0
Training loss: 2.9731048766780916
Validation loss: 2.5634185301290975

Epoch: 5| Step: 1
Training loss: 2.513304404168969
Validation loss: 2.559635223738578

Epoch: 5| Step: 2
Training loss: 2.6692472329685852
Validation loss: 2.527274780580039

Epoch: 5| Step: 3
Training loss: 2.4864741639836034
Validation loss: 2.5587172501526085

Epoch: 5| Step: 4
Training loss: 2.8014199607318284
Validation loss: 2.562874409244686

Epoch: 5| Step: 5
Training loss: 2.2375932471595203
Validation loss: 2.5309188081221254

Epoch: 5| Step: 6
Training loss: 3.38676746513767
Validation loss: 2.608703855116266

Epoch: 5| Step: 7
Training loss: 2.586163652102342
Validation loss: 2.5630653191958803

Epoch: 5| Step: 8
Training loss: 2.397757666845934
Validation loss: 2.554660144318379

Epoch: 5| Step: 9
Training loss: 2.5653578476273164
Validation loss: 2.5597003161120178

Epoch: 5| Step: 10
Training loss: 3.4197216487289075
Validation loss: 2.5562536491574392

Epoch: 181| Step: 0
Training loss: 2.7137358456264025
Validation loss: 2.563131513196152

Epoch: 5| Step: 1
Training loss: 3.1963169599015515
Validation loss: 2.5518538377918962

Epoch: 5| Step: 2
Training loss: 2.243344742668957
Validation loss: 2.557301743435758

Epoch: 5| Step: 3
Training loss: 2.6314317835265575
Validation loss: 2.5521779705596503

Epoch: 5| Step: 4
Training loss: 2.913569922657403
Validation loss: 2.5428295961580454

Epoch: 5| Step: 5
Training loss: 2.74041482082508
Validation loss: 2.5906118659724817

Epoch: 5| Step: 6
Training loss: 2.4857089701879134
Validation loss: 2.5532315097129192

Epoch: 5| Step: 7
Training loss: 3.560407860783907
Validation loss: 2.5488594286790343

Epoch: 5| Step: 8
Training loss: 2.571437044735224
Validation loss: 2.5728958771385377

Epoch: 5| Step: 9
Training loss: 2.211407938266364
Validation loss: 2.5507549660231503

Epoch: 5| Step: 10
Training loss: 2.8771344430091226
Validation loss: 2.6013763596659394

Epoch: 182| Step: 0
Training loss: 3.113312035459851
Validation loss: 2.5702113317936663

Epoch: 5| Step: 1
Training loss: 2.331518273347618
Validation loss: 2.5535178262528273

Epoch: 5| Step: 2
Training loss: 2.5860864878719556
Validation loss: 2.5534488389207466

Epoch: 5| Step: 3
Training loss: 3.077091721351329
Validation loss: 2.572636325033163

Epoch: 5| Step: 4
Training loss: 2.556177014192672
Validation loss: 2.572705718595364

Epoch: 5| Step: 5
Training loss: 3.0051081402151247
Validation loss: 2.5579586991578735

Epoch: 5| Step: 6
Training loss: 2.6439048667621394
Validation loss: 2.565260284122142

Epoch: 5| Step: 7
Training loss: 2.338642812012761
Validation loss: 2.578855412178002

Epoch: 5| Step: 8
Training loss: 2.6989530440857408
Validation loss: 2.5264513984826182

Epoch: 5| Step: 9
Training loss: 3.2948043612343048
Validation loss: 2.598408185682156

Epoch: 5| Step: 10
Training loss: 2.5707500050630157
Validation loss: 2.5352231175878286

Epoch: 183| Step: 0
Training loss: 3.105758173669191
Validation loss: 2.551399341375268

Epoch: 5| Step: 1
Training loss: 2.6147982039187645
Validation loss: 2.560849870744939

Epoch: 5| Step: 2
Training loss: 3.095348677214364
Validation loss: 2.56580731216028

Epoch: 5| Step: 3
Training loss: 2.562581596005822
Validation loss: 2.539034362081732

Epoch: 5| Step: 4
Training loss: 2.5477621019652616
Validation loss: 2.5568958662289893

Epoch: 5| Step: 5
Training loss: 2.8385609664027567
Validation loss: 2.5549758688671305

Epoch: 5| Step: 6
Training loss: 2.5425501887676365
Validation loss: 2.579839077573528

Epoch: 5| Step: 7
Training loss: 3.014024853508331
Validation loss: 2.572859204272419

Epoch: 5| Step: 8
Training loss: 2.055700248345406
Validation loss: 2.5530607125372633

Epoch: 5| Step: 9
Training loss: 2.5140086602704446
Validation loss: 2.530386717397642

Epoch: 5| Step: 10
Training loss: 3.2119761177115733
Validation loss: 2.5745317334597666

Epoch: 184| Step: 0
Training loss: 3.2290463989175358
Validation loss: 2.5440341232556487

Epoch: 5| Step: 1
Training loss: 2.755901074110906
Validation loss: 2.572295707614994

Epoch: 5| Step: 2
Training loss: 3.147591375428965
Validation loss: 2.5479092149242595

Epoch: 5| Step: 3
Training loss: 2.1698218871118318
Validation loss: 2.5779356020868414

Epoch: 5| Step: 4
Training loss: 2.6962942795528577
Validation loss: 2.562141344335925

Epoch: 5| Step: 5
Training loss: 2.0833450952833665
Validation loss: 2.586361237589171

Epoch: 5| Step: 6
Training loss: 2.936351145646091
Validation loss: 2.587767508626131

Epoch: 5| Step: 7
Training loss: 2.525264397554714
Validation loss: 2.586174783284516

Epoch: 5| Step: 8
Training loss: 3.3888968709076925
Validation loss: 2.5815331488055144

Epoch: 5| Step: 9
Training loss: 2.3734925153834077
Validation loss: 2.5227671915589513

Epoch: 5| Step: 10
Training loss: 2.5863478412807144
Validation loss: 2.5732720793723

Epoch: 185| Step: 0
Training loss: 3.4615137726971095
Validation loss: 2.592704863842944

Epoch: 5| Step: 1
Training loss: 1.9638282775818146
Validation loss: 2.5331792554917443

Epoch: 5| Step: 2
Training loss: 2.5792623149862166
Validation loss: 2.55519751040515

Epoch: 5| Step: 3
Training loss: 2.4891884675511706
Validation loss: 2.524932710938281

Epoch: 5| Step: 4
Training loss: 3.139578270016852
Validation loss: 2.597092503080495

Epoch: 5| Step: 5
Training loss: 2.4878712171054214
Validation loss: 2.551674079016467

Epoch: 5| Step: 6
Training loss: 2.713215862686823
Validation loss: 2.5401414793314436

Epoch: 5| Step: 7
Training loss: 2.7460217744557145
Validation loss: 2.5668683278746673

Epoch: 5| Step: 8
Training loss: 3.271053930404204
Validation loss: 2.5631500038015824

Epoch: 5| Step: 9
Training loss: 2.675189544522237
Validation loss: 2.545031825459997

Epoch: 5| Step: 10
Training loss: 2.4705349227885884
Validation loss: 2.527586997438875

Epoch: 186| Step: 0
Training loss: 2.525232674482139
Validation loss: 2.539542196062888

Epoch: 5| Step: 1
Training loss: 2.094012571353576
Validation loss: 2.5645900419510066

Epoch: 5| Step: 2
Training loss: 2.828508888450495
Validation loss: 2.573540552676497

Epoch: 5| Step: 3
Training loss: 2.5409123182004842
Validation loss: 2.5597677844231157

Epoch: 5| Step: 4
Training loss: 2.948499013221683
Validation loss: 2.499928707726506

Epoch: 5| Step: 5
Training loss: 2.859279943668449
Validation loss: 2.5616634853340425

Epoch: 5| Step: 6
Training loss: 3.4012759226827924
Validation loss: 2.5634081582095276

Epoch: 5| Step: 7
Training loss: 2.7577407438544586
Validation loss: 2.5723085731475632

Epoch: 5| Step: 8
Training loss: 2.2711745072931153
Validation loss: 2.5601889500759283

Epoch: 5| Step: 9
Training loss: 2.847889999194099
Validation loss: 2.553913821297752

Epoch: 5| Step: 10
Training loss: 3.019730377540278
Validation loss: 2.5284173637780283

Epoch: 187| Step: 0
Training loss: 2.827979321178927
Validation loss: 2.561863677911628

Epoch: 5| Step: 1
Training loss: 2.821446241078569
Validation loss: 2.595452534790212

Epoch: 5| Step: 2
Training loss: 2.8275951078762485
Validation loss: 2.549733656160388

Epoch: 5| Step: 3
Training loss: 2.65088119970487
Validation loss: 2.54548811594915

Epoch: 5| Step: 4
Training loss: 2.554616757967882
Validation loss: 2.578319721941532

Epoch: 5| Step: 5
Training loss: 2.438862151006852
Validation loss: 2.557713109079766

Epoch: 5| Step: 6
Training loss: 3.3574384918600573
Validation loss: 2.551579348081367

Epoch: 5| Step: 7
Training loss: 2.4883086533886445
Validation loss: 2.6003493294030218

Epoch: 5| Step: 8
Training loss: 2.911011599602451
Validation loss: 2.5676106637772724

Epoch: 5| Step: 9
Training loss: 2.9175837210416273
Validation loss: 2.5461956043808276

Epoch: 5| Step: 10
Training loss: 2.5498790226082773
Validation loss: 2.576179795272964

Epoch: 188| Step: 0
Training loss: 2.18625049327149
Validation loss: 2.5588338774785986

Epoch: 5| Step: 1
Training loss: 2.772948917819472
Validation loss: 2.5797380896795605

Epoch: 5| Step: 2
Training loss: 2.6045034470545425
Validation loss: 2.541340965598915

Epoch: 5| Step: 3
Training loss: 3.0624019062135956
Validation loss: 2.5691966202173204

Epoch: 5| Step: 4
Training loss: 2.1061376524712783
Validation loss: 2.5386103543167575

Epoch: 5| Step: 5
Training loss: 2.874410817685622
Validation loss: 2.5524858135179356

Epoch: 5| Step: 6
Training loss: 2.9162373544718867
Validation loss: 2.5370463600806095

Epoch: 5| Step: 7
Training loss: 2.8011428408061607
Validation loss: 2.5838232545066657

Epoch: 5| Step: 8
Training loss: 2.6276019688355423
Validation loss: 2.5608620679937797

Epoch: 5| Step: 9
Training loss: 3.1084657806186873
Validation loss: 2.551366230558457

Epoch: 5| Step: 10
Training loss: 3.153131133755029
Validation loss: 2.5645277282706376

Epoch: 189| Step: 0
Training loss: 3.094925165951014
Validation loss: 2.573765419454728

Epoch: 5| Step: 1
Training loss: 2.41299325910908
Validation loss: 2.580138551844457

Epoch: 5| Step: 2
Training loss: 2.822605289492276
Validation loss: 2.5785802096873103

Epoch: 5| Step: 3
Training loss: 2.444353104339438
Validation loss: 2.534758099264463

Epoch: 5| Step: 4
Training loss: 2.618023730241136
Validation loss: 2.560748545440393

Epoch: 5| Step: 5
Training loss: 3.227639671985219
Validation loss: 2.5816952140746716

Epoch: 5| Step: 6
Training loss: 2.369598470225539
Validation loss: 2.574958832440873

Epoch: 5| Step: 7
Training loss: 2.8341122472874303
Validation loss: 2.5224917304413443

Epoch: 5| Step: 8
Training loss: 2.8692051079802847
Validation loss: 2.5693667249187886

Epoch: 5| Step: 9
Training loss: 2.9763007261654932
Validation loss: 2.5753717342726783

Epoch: 5| Step: 10
Training loss: 2.6701943984680874
Validation loss: 2.55178563933012

Epoch: 190| Step: 0
Training loss: 2.7001876306683226
Validation loss: 2.6116844510477297

Epoch: 5| Step: 1
Training loss: 2.3373339507339166
Validation loss: 2.5229398464712616

Epoch: 5| Step: 2
Training loss: 2.9302382294862936
Validation loss: 2.5229641715448077

Epoch: 5| Step: 3
Training loss: 2.798101827403237
Validation loss: 2.57159648788688

Epoch: 5| Step: 4
Training loss: 2.5037152340970623
Validation loss: 2.5790132456045227

Epoch: 5| Step: 5
Training loss: 2.620885439922313
Validation loss: 2.547835048741082

Epoch: 5| Step: 6
Training loss: 2.5370599449693096
Validation loss: 2.5582055158098194

Epoch: 5| Step: 7
Training loss: 2.640179478006453
Validation loss: 2.585064133204593

Epoch: 5| Step: 8
Training loss: 3.0347301522817425
Validation loss: 2.5410386420298803

Epoch: 5| Step: 9
Training loss: 2.8378005620602194
Validation loss: 2.5636828894021217

Epoch: 5| Step: 10
Training loss: 3.241178865840121
Validation loss: 2.5506346685475045

Epoch: 191| Step: 0
Training loss: 2.744021071683981
Validation loss: 2.5597559945852852

Epoch: 5| Step: 1
Training loss: 2.7784610437775714
Validation loss: 2.5411468563025608

Epoch: 5| Step: 2
Training loss: 3.1321736205150397
Validation loss: 2.5156524662818227

Epoch: 5| Step: 3
Training loss: 2.5429150272443066
Validation loss: 2.588113297030336

Epoch: 5| Step: 4
Training loss: 2.816486331049864
Validation loss: 2.565292648470808

Epoch: 5| Step: 5
Training loss: 2.4688338253421027
Validation loss: 2.572578818176919

Epoch: 5| Step: 6
Training loss: 2.1103608264922764
Validation loss: 2.5784711837160708

Epoch: 5| Step: 7
Training loss: 2.525474364034847
Validation loss: 2.5851510900601267

Epoch: 5| Step: 8
Training loss: 2.518045717886338
Validation loss: 2.5628905240104527

Epoch: 5| Step: 9
Training loss: 3.2335784963361833
Validation loss: 2.5556022022802893

Epoch: 5| Step: 10
Training loss: 3.435691774054913
Validation loss: 2.563116800232034

Epoch: 192| Step: 0
Training loss: 2.609767495976728
Validation loss: 2.5540021810242934

Epoch: 5| Step: 1
Training loss: 2.9064038963999463
Validation loss: 2.5597562644942595

Epoch: 5| Step: 2
Training loss: 2.666431257665472
Validation loss: 2.56206498554191

Epoch: 5| Step: 3
Training loss: 3.193357881784819
Validation loss: 2.5811724553329762

Epoch: 5| Step: 4
Training loss: 2.7567056914968724
Validation loss: 2.5262161967593086

Epoch: 5| Step: 5
Training loss: 2.861956322358688
Validation loss: 2.5824144057488767

Epoch: 5| Step: 6
Training loss: 2.5681875425230447
Validation loss: 2.550433751373122

Epoch: 5| Step: 7
Training loss: 3.260005222152553
Validation loss: 2.5912644255524944

Epoch: 5| Step: 8
Training loss: 2.2101842453047573
Validation loss: 2.592955525810954

Epoch: 5| Step: 9
Training loss: 2.25582671699169
Validation loss: 2.551409815869211

Epoch: 5| Step: 10
Training loss: 3.039517483816112
Validation loss: 2.5573900918649275

Epoch: 193| Step: 0
Training loss: 2.5099793576915324
Validation loss: 2.5614566674880725

Epoch: 5| Step: 1
Training loss: 3.348311120949022
Validation loss: 2.5730964362360784

Epoch: 5| Step: 2
Training loss: 2.313490578128714
Validation loss: 2.5752655250808636

Epoch: 5| Step: 3
Training loss: 2.683790441243005
Validation loss: 2.5617203345473984

Epoch: 5| Step: 4
Training loss: 2.342926999871591
Validation loss: 2.52766816971626

Epoch: 5| Step: 5
Training loss: 2.9975428054972917
Validation loss: 2.5638730452156544

Epoch: 5| Step: 6
Training loss: 2.3028646210647423
Validation loss: 2.571630381479436

Epoch: 5| Step: 7
Training loss: 2.9802346793837664
Validation loss: 2.569018674689511

Epoch: 5| Step: 8
Training loss: 2.730737675642578
Validation loss: 2.5729642464005322

Epoch: 5| Step: 9
Training loss: 3.386281549553894
Validation loss: 2.5490353982289986

Epoch: 5| Step: 10
Training loss: 2.5611712104143245
Validation loss: 2.5617336604945957

Epoch: 194| Step: 0
Training loss: 2.705841904103723
Validation loss: 2.5600764401236926

Epoch: 5| Step: 1
Training loss: 3.258080633824753
Validation loss: 2.591418141619747

Epoch: 5| Step: 2
Training loss: 3.136333209105046
Validation loss: 2.560340682878691

Epoch: 5| Step: 3
Training loss: 2.880183481358697
Validation loss: 2.5389610493651267

Epoch: 5| Step: 4
Training loss: 2.0298372490947396
Validation loss: 2.5782259804795844

Epoch: 5| Step: 5
Training loss: 2.715692576806589
Validation loss: 2.579333953452508

Epoch: 5| Step: 6
Training loss: 2.397864257699349
Validation loss: 2.5475883660022247

Epoch: 5| Step: 7
Training loss: 2.3294965557032805
Validation loss: 2.5710159427833923

Epoch: 5| Step: 8
Training loss: 2.785023133680052
Validation loss: 2.559417489305749

Epoch: 5| Step: 9
Training loss: 3.224679318829944
Validation loss: 2.560324785365908

Epoch: 5| Step: 10
Training loss: 2.524658663500375
Validation loss: 2.5875458312863913

Epoch: 195| Step: 0
Training loss: 2.582762921844613
Validation loss: 2.54499165858428

Epoch: 5| Step: 1
Training loss: 2.4803459076988394
Validation loss: 2.544992119940332

Epoch: 5| Step: 2
Training loss: 2.2469101989281013
Validation loss: 2.492235446915795

Epoch: 5| Step: 3
Training loss: 2.4852249323094204
Validation loss: 2.54174319380187

Epoch: 5| Step: 4
Training loss: 2.63117889525688
Validation loss: 2.5684667950278772

Epoch: 5| Step: 5
Training loss: 2.4787837996417137
Validation loss: 2.532754644061442

Epoch: 5| Step: 6
Training loss: 3.2547568209001114
Validation loss: 2.536463713709189

Epoch: 5| Step: 7
Training loss: 3.57044605364269
Validation loss: 2.5381408906914693

Epoch: 5| Step: 8
Training loss: 2.9359245133531466
Validation loss: 2.5398136281785093

Epoch: 5| Step: 9
Training loss: 2.6112119867124504
Validation loss: 2.5488051632258752

Epoch: 5| Step: 10
Training loss: 2.3479316537193133
Validation loss: 2.5414494106074557

Epoch: 196| Step: 0
Training loss: 3.217190855597904
Validation loss: 2.523113698683303

Epoch: 5| Step: 1
Training loss: 2.843332280929866
Validation loss: 2.5301047058112056

Epoch: 5| Step: 2
Training loss: 2.2485485693648526
Validation loss: 2.5487450747973504

Epoch: 5| Step: 3
Training loss: 3.0347200961557754
Validation loss: 2.5758800598029263

Epoch: 5| Step: 4
Training loss: 2.623647704799588
Validation loss: 2.5722383551005037

Epoch: 5| Step: 5
Training loss: 3.4864063585409832
Validation loss: 2.564951334693162

Epoch: 5| Step: 6
Training loss: 2.4760343066598143
Validation loss: 2.521902687563332

Epoch: 5| Step: 7
Training loss: 2.198238066063995
Validation loss: 2.575974211571305

Epoch: 5| Step: 8
Training loss: 2.6089609697082823
Validation loss: 2.594937790511411

Epoch: 5| Step: 9
Training loss: 2.7657127581967096
Validation loss: 2.5332707125604896

Epoch: 5| Step: 10
Training loss: 2.419070681425195
Validation loss: 2.578914973002624

Epoch: 197| Step: 0
Training loss: 2.486830355734119
Validation loss: 2.5689961109247776

Epoch: 5| Step: 1
Training loss: 2.6141995354741367
Validation loss: 2.582679781642189

Epoch: 5| Step: 2
Training loss: 2.8555171769363112
Validation loss: 2.5588010717588463

Epoch: 5| Step: 3
Training loss: 2.430314158002149
Validation loss: 2.582690398770983

Epoch: 5| Step: 4
Training loss: 2.7230728684452776
Validation loss: 2.571842210549394

Epoch: 5| Step: 5
Training loss: 3.4189440572780474
Validation loss: 2.5777629151801027

Epoch: 5| Step: 6
Training loss: 2.9689777487681956
Validation loss: 2.5610027235828787

Epoch: 5| Step: 7
Training loss: 3.104999166049323
Validation loss: 2.5906443371481482

Epoch: 5| Step: 8
Training loss: 2.569570602435765
Validation loss: 2.544660869950677

Epoch: 5| Step: 9
Training loss: 2.7065386963958025
Validation loss: 2.5474598349815274

Epoch: 5| Step: 10
Training loss: 2.461171263234031
Validation loss: 2.518050128323141

Epoch: 198| Step: 0
Training loss: 2.5148692447049106
Validation loss: 2.5613054482042927

Epoch: 5| Step: 1
Training loss: 3.4329997341957066
Validation loss: 2.5716917664344794

Epoch: 5| Step: 2
Training loss: 2.6494436687723337
Validation loss: 2.524243566043779

Epoch: 5| Step: 3
Training loss: 2.8249272767555484
Validation loss: 2.5497865897627774

Epoch: 5| Step: 4
Training loss: 2.9819933590319323
Validation loss: 2.564352828824745

Epoch: 5| Step: 5
Training loss: 2.485492958588373
Validation loss: 2.5605440055355704

Epoch: 5| Step: 6
Training loss: 2.584311535942818
Validation loss: 2.554085076343506

Epoch: 5| Step: 7
Training loss: 3.153816418033432
Validation loss: 2.493646723303676

Epoch: 5| Step: 8
Training loss: 2.3532931527371863
Validation loss: 2.531867647338274

Epoch: 5| Step: 9
Training loss: 2.457437890976411
Validation loss: 2.5568498016221954

Epoch: 5| Step: 10
Training loss: 2.816254716201267
Validation loss: 2.5345966108140248

Epoch: 199| Step: 0
Training loss: 2.9595878162016214
Validation loss: 2.548674001353014

Epoch: 5| Step: 1
Training loss: 2.724937676233251
Validation loss: 2.541028745761659

Epoch: 5| Step: 2
Training loss: 2.764577721190248
Validation loss: 2.5656710007408052

Epoch: 5| Step: 3
Training loss: 2.7574196338441808
Validation loss: 2.531428306636507

Epoch: 5| Step: 4
Training loss: 2.8129030574634553
Validation loss: 2.545637956555287

Epoch: 5| Step: 5
Training loss: 1.964811897398841
Validation loss: 2.5184109394172065

Epoch: 5| Step: 6
Training loss: 3.0744500079294386
Validation loss: 2.5903151692535595

Epoch: 5| Step: 7
Training loss: 2.862831236485768
Validation loss: 2.5430818928291417

Epoch: 5| Step: 8
Training loss: 2.6565547095160866
Validation loss: 2.5955760945745388

Epoch: 5| Step: 9
Training loss: 2.4780779031941904
Validation loss: 2.5590661354351627

Epoch: 5| Step: 10
Training loss: 3.121150277667856
Validation loss: 2.5777495338586176

Epoch: 200| Step: 0
Training loss: 2.476610153172994
Validation loss: 2.5501723212565515

Epoch: 5| Step: 1
Training loss: 3.0148871116950047
Validation loss: 2.5684384671996767

Epoch: 5| Step: 2
Training loss: 3.176037692406056
Validation loss: 2.598424657245396

Epoch: 5| Step: 3
Training loss: 2.2567799460952447
Validation loss: 2.547469137680019

Epoch: 5| Step: 4
Training loss: 1.9984558820438307
Validation loss: 2.535738377879526

Epoch: 5| Step: 5
Training loss: 2.954503297838484
Validation loss: 2.5442050911027714

Epoch: 5| Step: 6
Training loss: 2.472517591207506
Validation loss: 2.5291980025505922

Epoch: 5| Step: 7
Training loss: 2.4679525511893203
Validation loss: 2.566597117989422

Epoch: 5| Step: 8
Training loss: 3.0181693772501417
Validation loss: 2.5517658165875394

Epoch: 5| Step: 9
Training loss: 3.127149224312483
Validation loss: 2.5321522255194777

Epoch: 5| Step: 10
Training loss: 2.945847520879513
Validation loss: 2.560063469057378

Epoch: 201| Step: 0
Training loss: 2.888244308388147
Validation loss: 2.5800733535887796

Epoch: 5| Step: 1
Training loss: 2.700084674355185
Validation loss: 2.550983468364831

Epoch: 5| Step: 2
Training loss: 2.614980376190018
Validation loss: 2.5575610890791634

Epoch: 5| Step: 3
Training loss: 2.391962213453804
Validation loss: 2.586389582224421

Epoch: 5| Step: 4
Training loss: 2.624686631162699
Validation loss: 2.552966278075116

Epoch: 5| Step: 5
Training loss: 2.295901968242181
Validation loss: 2.571118056978586

Epoch: 5| Step: 6
Training loss: 2.8446838187120873
Validation loss: 2.544851931343022

Epoch: 5| Step: 7
Training loss: 2.8467168736850774
Validation loss: 2.53905943713386

Epoch: 5| Step: 8
Training loss: 2.536072458188763
Validation loss: 2.5757829811910264

Epoch: 5| Step: 9
Training loss: 3.4819180845718436
Validation loss: 2.59323058775793

Epoch: 5| Step: 10
Training loss: 2.6192921844257464
Validation loss: 2.555855031572984

Epoch: 202| Step: 0
Training loss: 2.872122112015881
Validation loss: 2.6023010774298436

Epoch: 5| Step: 1
Training loss: 2.9469494710110626
Validation loss: 2.5681654386315094

Epoch: 5| Step: 2
Training loss: 2.4134609621066576
Validation loss: 2.5578429409832655

Epoch: 5| Step: 3
Training loss: 2.3609868284938162
Validation loss: 2.558801816164004

Epoch: 5| Step: 4
Training loss: 3.240771469293465
Validation loss: 2.554477094555833

Epoch: 5| Step: 5
Training loss: 2.3662790500411344
Validation loss: 2.559905669015133

Epoch: 5| Step: 6
Training loss: 3.3133330827043874
Validation loss: 2.5578021183374906

Epoch: 5| Step: 7
Training loss: 2.3926358212112255
Validation loss: 2.535395121956621

Epoch: 5| Step: 8
Training loss: 2.5813973668776096
Validation loss: 2.592109368861764

Epoch: 5| Step: 9
Training loss: 2.503258774667621
Validation loss: 2.556350090232977

Epoch: 5| Step: 10
Training loss: 2.846075260124283
Validation loss: 2.583559729599023

Epoch: 203| Step: 0
Training loss: 3.1433649210254604
Validation loss: 2.557046699624507

Epoch: 5| Step: 1
Training loss: 2.588933770450596
Validation loss: 2.5518856860220214

Epoch: 5| Step: 2
Training loss: 2.635664122854002
Validation loss: 2.541909507986553

Epoch: 5| Step: 3
Training loss: 2.5041987446165415
Validation loss: 2.5754859132524044

Epoch: 5| Step: 4
Training loss: 2.9255744239625905
Validation loss: 2.560506313730434

Epoch: 5| Step: 5
Training loss: 2.7733811063808864
Validation loss: 2.578125867100803

Epoch: 5| Step: 6
Training loss: 2.427132492768199
Validation loss: 2.5405398994187527

Epoch: 5| Step: 7
Training loss: 2.94317549426657
Validation loss: 2.544788693095323

Epoch: 5| Step: 8
Training loss: 2.5870195873449426
Validation loss: 2.5691741637870913

Epoch: 5| Step: 9
Training loss: 2.446907863664204
Validation loss: 2.563911779411544

Epoch: 5| Step: 10
Training loss: 3.1159820137826992
Validation loss: 2.5394910447256778

Epoch: 204| Step: 0
Training loss: 3.231684500960005
Validation loss: 2.546866109844963

Epoch: 5| Step: 1
Training loss: 2.77529097397631
Validation loss: 2.567878572897181

Epoch: 5| Step: 2
Training loss: 1.6263011711449937
Validation loss: 2.5425012164162855

Epoch: 5| Step: 3
Training loss: 2.7754802219604984
Validation loss: 2.560935178190803

Epoch: 5| Step: 4
Training loss: 3.236798396731558
Validation loss: 2.5850728721611262

Epoch: 5| Step: 5
Training loss: 2.4401473316675246
Validation loss: 2.549797193041513

Epoch: 5| Step: 6
Training loss: 2.9078213945239435
Validation loss: 2.5310136610523584

Epoch: 5| Step: 7
Training loss: 3.14110170608634
Validation loss: 2.509350258405097

Epoch: 5| Step: 8
Training loss: 2.205019305570691
Validation loss: 2.5410399374504546

Epoch: 5| Step: 9
Training loss: 2.8151054182352726
Validation loss: 2.5445746219679015

Epoch: 5| Step: 10
Training loss: 2.506382424525673
Validation loss: 2.5387066194001173

Epoch: 205| Step: 0
Training loss: 3.093575212569624
Validation loss: 2.57574005738463

Epoch: 5| Step: 1
Training loss: 2.7256121796479436
Validation loss: 2.5990446047074904

Epoch: 5| Step: 2
Training loss: 2.164413919388091
Validation loss: 2.5697300067612194

Epoch: 5| Step: 3
Training loss: 3.341136160301583
Validation loss: 2.528589766720089

Epoch: 5| Step: 4
Training loss: 2.9582523460227366
Validation loss: 2.5445744214768244

Epoch: 5| Step: 5
Training loss: 2.7663471550650374
Validation loss: 2.5590050226585497

Epoch: 5| Step: 6
Training loss: 2.941212195572146
Validation loss: 2.588288409416759

Epoch: 5| Step: 7
Training loss: 2.6812698541364095
Validation loss: 2.554447368128606

Epoch: 5| Step: 8
Training loss: 2.255049760865758
Validation loss: 2.584960463442416

Epoch: 5| Step: 9
Training loss: 2.294125318874
Validation loss: 2.5474661196403865

Epoch: 5| Step: 10
Training loss: 2.564445873288014
Validation loss: 2.573472229606762

Epoch: 206| Step: 0
Training loss: 3.0575704019695915
Validation loss: 2.546310289725042

Epoch: 5| Step: 1
Training loss: 2.480559195724309
Validation loss: 2.5796956806211284

Epoch: 5| Step: 2
Training loss: 2.480502487313627
Validation loss: 2.537356942132515

Epoch: 5| Step: 3
Training loss: 3.0406195174948967
Validation loss: 2.547173480620586

Epoch: 5| Step: 4
Training loss: 2.816524085173653
Validation loss: 2.588770391160978

Epoch: 5| Step: 5
Training loss: 2.0722741388403096
Validation loss: 2.563859850377891

Epoch: 5| Step: 6
Training loss: 2.474167011227128
Validation loss: 2.5632655783151543

Epoch: 5| Step: 7
Training loss: 3.2299413100541075
Validation loss: 2.5744452454274183

Epoch: 5| Step: 8
Training loss: 3.133783736897547
Validation loss: 2.5706256080170506

Epoch: 5| Step: 9
Training loss: 2.242050326201927
Validation loss: 2.557001594212151

Epoch: 5| Step: 10
Training loss: 2.9105904274481045
Validation loss: 2.5889184208453844

Epoch: 207| Step: 0
Training loss: 2.4745595636450335
Validation loss: 2.5745148566020606

Epoch: 5| Step: 1
Training loss: 2.3267190259308625
Validation loss: 2.505220907228911

Epoch: 5| Step: 2
Training loss: 2.8507366499962488
Validation loss: 2.5917781011230963

Epoch: 5| Step: 3
Training loss: 2.8778723590319935
Validation loss: 2.563881038478555

Epoch: 5| Step: 4
Training loss: 3.507528790595725
Validation loss: 2.556044886118458

Epoch: 5| Step: 5
Training loss: 2.3389910384418697
Validation loss: 2.558850226079662

Epoch: 5| Step: 6
Training loss: 2.8409285749287467
Validation loss: 2.544063649902977

Epoch: 5| Step: 7
Training loss: 2.441002114988518
Validation loss: 2.5427947026632918

Epoch: 5| Step: 8
Training loss: 2.2928690328149677
Validation loss: 2.538902367779218

Epoch: 5| Step: 9
Training loss: 3.1153063152939473
Validation loss: 2.5494560703124387

Epoch: 5| Step: 10
Training loss: 2.820987102950999
Validation loss: 2.562846278682628

Epoch: 208| Step: 0
Training loss: 2.5215096210188017
Validation loss: 2.5571847419664597

Epoch: 5| Step: 1
Training loss: 2.8758684588129233
Validation loss: 2.574450881666969

Epoch: 5| Step: 2
Training loss: 2.3121527333745
Validation loss: 2.5346485092570994

Epoch: 5| Step: 3
Training loss: 2.8335248284047267
Validation loss: 2.5593868045744252

Epoch: 5| Step: 4
Training loss: 2.0619458696825026
Validation loss: 2.549900119770956

Epoch: 5| Step: 5
Training loss: 3.2253544279998536
Validation loss: 2.5516921452824888

Epoch: 5| Step: 6
Training loss: 2.921252505652708
Validation loss: 2.555087201740069

Epoch: 5| Step: 7
Training loss: 2.7872190393741407
Validation loss: 2.5084565464324213

Epoch: 5| Step: 8
Training loss: 2.852350497126795
Validation loss: 2.56366371364646

Epoch: 5| Step: 9
Training loss: 2.709309377612565
Validation loss: 2.542254069060953

Epoch: 5| Step: 10
Training loss: 2.278227698335943
Validation loss: 2.56275078531501

Epoch: 209| Step: 0
Training loss: 3.270409250810309
Validation loss: 2.5408858917771

Epoch: 5| Step: 1
Training loss: 2.095120564999725
Validation loss: 2.572607517953945

Epoch: 5| Step: 2
Training loss: 1.8385428914038133
Validation loss: 2.551940844343683

Epoch: 5| Step: 3
Training loss: 3.0321185254002185
Validation loss: 2.5816709453734497

Epoch: 5| Step: 4
Training loss: 2.532676200799886
Validation loss: 2.5478710071831054

Epoch: 5| Step: 5
Training loss: 2.996680171230327
Validation loss: 2.562058405489272

Epoch: 5| Step: 6
Training loss: 2.6469998128708623
Validation loss: 2.576104097405268

Epoch: 5| Step: 7
Training loss: 3.0194334974171406
Validation loss: 2.5187692581067918

Epoch: 5| Step: 8
Training loss: 2.398266018878713
Validation loss: 2.5413012094744567

Epoch: 5| Step: 9
Training loss: 3.3728380696354123
Validation loss: 2.57387759896117

Epoch: 5| Step: 10
Training loss: 2.3275976415818547
Validation loss: 2.5541526633723906

Epoch: 210| Step: 0
Training loss: 3.0370117171799134
Validation loss: 2.5362295294469015

Epoch: 5| Step: 1
Training loss: 2.543571717109255
Validation loss: 2.5326576446053433

Epoch: 5| Step: 2
Training loss: 2.820931490867116
Validation loss: 2.572478345507991

Epoch: 5| Step: 3
Training loss: 2.9909416772480233
Validation loss: 2.5569660128203613

Epoch: 5| Step: 4
Training loss: 2.263479440193345
Validation loss: 2.548519619919783

Epoch: 5| Step: 5
Training loss: 2.591816468728923
Validation loss: 2.5597459493442227

Epoch: 5| Step: 6
Training loss: 2.8306622162417217
Validation loss: 2.56948972723282

Epoch: 5| Step: 7
Training loss: 2.606594225794797
Validation loss: 2.550064916747532

Epoch: 5| Step: 8
Training loss: 2.8626963185784033
Validation loss: 2.574348469468607

Epoch: 5| Step: 9
Training loss: 2.3628484156189264
Validation loss: 2.564666272586746

Epoch: 5| Step: 10
Training loss: 3.108874716839661
Validation loss: 2.5267920028042505

Epoch: 211| Step: 0
Training loss: 2.413743278853602
Validation loss: 2.546399093505206

Epoch: 5| Step: 1
Training loss: 2.8859424502212043
Validation loss: 2.568147225712456

Epoch: 5| Step: 2
Training loss: 2.4968803969075455
Validation loss: 2.5788140900846614

Epoch: 5| Step: 3
Training loss: 2.400513387447658
Validation loss: 2.549049255135299

Epoch: 5| Step: 4
Training loss: 2.119431211175543
Validation loss: 2.55960994211411

Epoch: 5| Step: 5
Training loss: 3.395835283586999
Validation loss: 2.5491447126702984

Epoch: 5| Step: 6
Training loss: 3.117364022747004
Validation loss: 2.5414206595733413

Epoch: 5| Step: 7
Training loss: 1.946815124864611
Validation loss: 2.5797681567082114

Epoch: 5| Step: 8
Training loss: 2.377879455161171
Validation loss: 2.5646672322026527

Epoch: 5| Step: 9
Training loss: 2.6927841047968153
Validation loss: 2.545349821992991

Epoch: 5| Step: 10
Training loss: 3.968025081239926
Validation loss: 2.5738674913024915

Epoch: 212| Step: 0
Training loss: 2.61995630271522
Validation loss: 2.600734407559546

Epoch: 5| Step: 1
Training loss: 2.486461123425107
Validation loss: 2.5453201078189935

Epoch: 5| Step: 2
Training loss: 2.964845358304076
Validation loss: 2.565105981963041

Epoch: 5| Step: 3
Training loss: 2.7715618829729713
Validation loss: 2.5664801771826267

Epoch: 5| Step: 4
Training loss: 2.259897081512953
Validation loss: 2.5500181546933263

Epoch: 5| Step: 5
Training loss: 3.3113192487181227
Validation loss: 2.5638824663442605

Epoch: 5| Step: 6
Training loss: 2.7552876355897915
Validation loss: 2.5342777935417615

Epoch: 5| Step: 7
Training loss: 2.7025428100921656
Validation loss: 2.5115123187997215

Epoch: 5| Step: 8
Training loss: 2.079100186413354
Validation loss: 2.5822238689860697

Epoch: 5| Step: 9
Training loss: 3.2099255825935553
Validation loss: 2.563825809062728

Epoch: 5| Step: 10
Training loss: 2.786868303508631
Validation loss: 2.5781236973594837

Epoch: 213| Step: 0
Training loss: 2.8562950681640817
Validation loss: 2.5723122397477813

Epoch: 5| Step: 1
Training loss: 3.0040811753156307
Validation loss: 2.548575018073871

Epoch: 5| Step: 2
Training loss: 2.9840830715060407
Validation loss: 2.5426200666838823

Epoch: 5| Step: 3
Training loss: 2.9133574832057896
Validation loss: 2.565654110062329

Epoch: 5| Step: 4
Training loss: 2.722162494739451
Validation loss: 2.556948113154806

Epoch: 5| Step: 5
Training loss: 2.369905830959012
Validation loss: 2.5407202310282866

Epoch: 5| Step: 6
Training loss: 2.995136132816264
Validation loss: 2.5712084816404537

Epoch: 5| Step: 7
Training loss: 2.629927324951697
Validation loss: 2.548376621489869

Epoch: 5| Step: 8
Training loss: 2.7124952957886017
Validation loss: 2.521738310108081

Epoch: 5| Step: 9
Training loss: 2.3394927970056267
Validation loss: 2.543195752380797

Epoch: 5| Step: 10
Training loss: 2.462148991852657
Validation loss: 2.55409585047973

Epoch: 214| Step: 0
Training loss: 2.7485414451734544
Validation loss: 2.581645406860848

Epoch: 5| Step: 1
Training loss: 2.4937968543677513
Validation loss: 2.5553052700372514

Epoch: 5| Step: 2
Training loss: 2.933025279631014
Validation loss: 2.5507462451745715

Epoch: 5| Step: 3
Training loss: 2.5805078765092575
Validation loss: 2.56074919116877

Epoch: 5| Step: 4
Training loss: 2.6575125891171085
Validation loss: 2.5461221469662845

Epoch: 5| Step: 5
Training loss: 2.6549631928732036
Validation loss: 2.556163126723958

Epoch: 5| Step: 6
Training loss: 3.2473149578890528
Validation loss: 2.542675327196819

Epoch: 5| Step: 7
Training loss: 2.5278872534924552
Validation loss: 2.525687503798864

Epoch: 5| Step: 8
Training loss: 2.505154921715065
Validation loss: 2.5678105264811877

Epoch: 5| Step: 9
Training loss: 2.5409944197688406
Validation loss: 2.5531624423489796

Epoch: 5| Step: 10
Training loss: 3.0302444835266753
Validation loss: 2.5729044790694617

Epoch: 215| Step: 0
Training loss: 2.4366505438727404
Validation loss: 2.5322136796045456

Epoch: 5| Step: 1
Training loss: 2.7608894279193836
Validation loss: 2.540738924086703

Epoch: 5| Step: 2
Training loss: 3.1556519801073857
Validation loss: 2.5254009794697665

Epoch: 5| Step: 3
Training loss: 3.114414750621953
Validation loss: 2.5594773802659754

Epoch: 5| Step: 4
Training loss: 2.2940714847298853
Validation loss: 2.5460508427212747

Epoch: 5| Step: 5
Training loss: 2.931495535841758
Validation loss: 2.5652322027095282

Epoch: 5| Step: 6
Training loss: 2.5172805551085164
Validation loss: 2.556415471331664

Epoch: 5| Step: 7
Training loss: 2.968674668811927
Validation loss: 2.579379786476097

Epoch: 5| Step: 8
Training loss: 2.044710368792738
Validation loss: 2.566347997679852

Epoch: 5| Step: 9
Training loss: 2.517259812929487
Validation loss: 2.5146768788681557

Epoch: 5| Step: 10
Training loss: 3.125413943531386
Validation loss: 2.503130761352265

Epoch: 216| Step: 0
Training loss: 2.2107237587855004
Validation loss: 2.576445256119206

Epoch: 5| Step: 1
Training loss: 2.86628563440783
Validation loss: 2.578650407648744

Epoch: 5| Step: 2
Training loss: 2.7723468194030927
Validation loss: 2.571015557890657

Epoch: 5| Step: 3
Training loss: 2.392471398289242
Validation loss: 2.555095215464858

Epoch: 5| Step: 4
Training loss: 3.2930524460189585
Validation loss: 2.5581774817220695

Epoch: 5| Step: 5
Training loss: 3.0154676643400067
Validation loss: 2.5521005281258784

Epoch: 5| Step: 6
Training loss: 2.3077021133997024
Validation loss: 2.584922148789609

Epoch: 5| Step: 7
Training loss: 2.1344765679473294
Validation loss: 2.541294783470552

Epoch: 5| Step: 8
Training loss: 2.5203557993982324
Validation loss: 2.5153837634160685

Epoch: 5| Step: 9
Training loss: 2.764665512630509
Validation loss: 2.530959735180723

Epoch: 5| Step: 10
Training loss: 3.4514488881910754
Validation loss: 2.54783867710845

Epoch: 217| Step: 0
Training loss: 2.8224431071194376
Validation loss: 2.5598360806874765

Epoch: 5| Step: 1
Training loss: 2.6901648860158436
Validation loss: 2.554407848104385

Epoch: 5| Step: 2
Training loss: 2.647951604781218
Validation loss: 2.541155205042098

Epoch: 5| Step: 3
Training loss: 2.7441841529299107
Validation loss: 2.5497214368451573

Epoch: 5| Step: 4
Training loss: 2.960785793957441
Validation loss: 2.542348271693394

Epoch: 5| Step: 5
Training loss: 3.1210288183072885
Validation loss: 2.559713714169842

Epoch: 5| Step: 6
Training loss: 2.7572727269491475
Validation loss: 2.5194044410188385

Epoch: 5| Step: 7
Training loss: 2.630343674806624
Validation loss: 2.572530564958584

Epoch: 5| Step: 8
Training loss: 2.1137768063912397
Validation loss: 2.5580849458567925

Epoch: 5| Step: 9
Training loss: 2.6321308827076995
Validation loss: 2.556589875927554

Epoch: 5| Step: 10
Training loss: 2.8172738991350847
Validation loss: 2.5577862130649747

Epoch: 218| Step: 0
Training loss: 2.3399580734931056
Validation loss: 2.5406422435900486

Epoch: 5| Step: 1
Training loss: 2.7624149982614177
Validation loss: 2.542572654489217

Epoch: 5| Step: 2
Training loss: 2.9083508517403547
Validation loss: 2.5479420280675082

Epoch: 5| Step: 3
Training loss: 2.0711371165095036
Validation loss: 2.578718283347084

Epoch: 5| Step: 4
Training loss: 2.936005394735759
Validation loss: 2.5837900298570657

Epoch: 5| Step: 5
Training loss: 3.3868934735872966
Validation loss: 2.5281137269631433

Epoch: 5| Step: 6
Training loss: 2.7965675909644165
Validation loss: 2.576081512107054

Epoch: 5| Step: 7
Training loss: 2.462333743296978
Validation loss: 2.5549492969197507

Epoch: 5| Step: 8
Training loss: 3.3346829702056815
Validation loss: 2.5759896801061144

Epoch: 5| Step: 9
Training loss: 2.80810364331959
Validation loss: 2.534162272308251

Epoch: 5| Step: 10
Training loss: 1.708408245522106
Validation loss: 2.5348576185387337

Epoch: 219| Step: 0
Training loss: 2.946593312203429
Validation loss: 2.582058223361133

Epoch: 5| Step: 1
Training loss: 2.737170463480249
Validation loss: 2.472480724539161

Epoch: 5| Step: 2
Training loss: 2.9215809067193117
Validation loss: 2.56980489678239

Epoch: 5| Step: 3
Training loss: 2.336462669918431
Validation loss: 2.5566679775400836

Epoch: 5| Step: 4
Training loss: 2.792412378341808
Validation loss: 2.5524484657395643

Epoch: 5| Step: 5
Training loss: 2.5833103630111163
Validation loss: 2.5275176492256204

Epoch: 5| Step: 6
Training loss: 2.4129809083084526
Validation loss: 2.564567368247611

Epoch: 5| Step: 7
Training loss: 3.02267880247709
Validation loss: 2.5627651412578216

Epoch: 5| Step: 8
Training loss: 2.5677100459487083
Validation loss: 2.5437050252176014

Epoch: 5| Step: 9
Training loss: 2.7282867663337385
Validation loss: 2.5393710394628566

Epoch: 5| Step: 10
Training loss: 2.5338365502576585
Validation loss: 2.548083363648456

Epoch: 220| Step: 0
Training loss: 3.3966858306683565
Validation loss: 2.5460356182168575

Epoch: 5| Step: 1
Training loss: 2.0302295175474367
Validation loss: 2.551859182358931

Epoch: 5| Step: 2
Training loss: 3.2449689217653006
Validation loss: 2.530306596873095

Epoch: 5| Step: 3
Training loss: 2.363561894170678
Validation loss: 2.522160649392442

Epoch: 5| Step: 4
Training loss: 2.4771014568755616
Validation loss: 2.552029696301241

Epoch: 5| Step: 5
Training loss: 2.643086476851446
Validation loss: 2.5229987336984396

Epoch: 5| Step: 6
Training loss: 2.7388920558509633
Validation loss: 2.522377272729595

Epoch: 5| Step: 7
Training loss: 2.5616756136590517
Validation loss: 2.572522872621738

Epoch: 5| Step: 8
Training loss: 2.7588029763200015
Validation loss: 2.5606582359699543

Epoch: 5| Step: 9
Training loss: 2.2749644391980017
Validation loss: 2.582092920854211

Epoch: 5| Step: 10
Training loss: 3.220399304385638
Validation loss: 2.548062877246319

Epoch: 221| Step: 0
Training loss: 2.8344335850693247
Validation loss: 2.564016484199235

Epoch: 5| Step: 1
Training loss: 3.100330329030906
Validation loss: 2.5625721901029896

Epoch: 5| Step: 2
Training loss: 2.924435233343525
Validation loss: 2.529598337815823

Epoch: 5| Step: 3
Training loss: 2.087447173769336
Validation loss: 2.5799974967026733

Epoch: 5| Step: 4
Training loss: 2.495887616500723
Validation loss: 2.564148768392452

Epoch: 5| Step: 5
Training loss: 2.9410687135142397
Validation loss: 2.5721008032201174

Epoch: 5| Step: 6
Training loss: 2.5623483380352736
Validation loss: 2.567660124206225

Epoch: 5| Step: 7
Training loss: 3.0034430137982957
Validation loss: 2.5362638269350564

Epoch: 5| Step: 8
Training loss: 2.4174115797755076
Validation loss: 2.5391777826457473

Epoch: 5| Step: 9
Training loss: 2.463283909760844
Validation loss: 2.5615710443743924

Epoch: 5| Step: 10
Training loss: 2.744754817553635
Validation loss: 2.5554094847605184

Epoch: 222| Step: 0
Training loss: 2.3514841263089483
Validation loss: 2.5676723584950985

Epoch: 5| Step: 1
Training loss: 2.821657319824216
Validation loss: 2.5235156767800384

Epoch: 5| Step: 2
Training loss: 2.216979919136172
Validation loss: 2.5473870274118138

Epoch: 5| Step: 3
Training loss: 3.1746026699126313
Validation loss: 2.526804160017817

Epoch: 5| Step: 4
Training loss: 2.4561870926040044
Validation loss: 2.5717286184356465

Epoch: 5| Step: 5
Training loss: 2.9015906937009524
Validation loss: 2.5563510168679975

Epoch: 5| Step: 6
Training loss: 3.077410464932771
Validation loss: 2.5712500685389625

Epoch: 5| Step: 7
Training loss: 2.2556245227452782
Validation loss: 2.530523523306757

Epoch: 5| Step: 8
Training loss: 2.551295650658761
Validation loss: 2.5826717294301407

Epoch: 5| Step: 9
Training loss: 2.620673565222369
Validation loss: 2.5886528397484305

Epoch: 5| Step: 10
Training loss: 3.2564996136782693
Validation loss: 2.5586437439325858

Epoch: 223| Step: 0
Training loss: 2.5998539626849846
Validation loss: 2.568107314561073

Epoch: 5| Step: 1
Training loss: 2.1376542688213767
Validation loss: 2.570564065957719

Epoch: 5| Step: 2
Training loss: 2.6213886305460234
Validation loss: 2.543951340805733

Epoch: 5| Step: 3
Training loss: 2.16520214714058
Validation loss: 2.5540549227735787

Epoch: 5| Step: 4
Training loss: 3.135441996492153
Validation loss: 2.5754065965076927

Epoch: 5| Step: 5
Training loss: 3.3104633332010716
Validation loss: 2.547927678154794

Epoch: 5| Step: 6
Training loss: 2.2535987260757326
Validation loss: 2.534780694730349

Epoch: 5| Step: 7
Training loss: 2.861770710224771
Validation loss: 2.575954693398182

Epoch: 5| Step: 8
Training loss: 3.3589761186700775
Validation loss: 2.5264319584030335

Epoch: 5| Step: 9
Training loss: 2.371472399170367
Validation loss: 2.5569347552484696

Epoch: 5| Step: 10
Training loss: 2.536180098441303
Validation loss: 2.536558917184857

Epoch: 224| Step: 0
Training loss: 3.093142208930978
Validation loss: 2.563052686329766

Epoch: 5| Step: 1
Training loss: 2.98617898632257
Validation loss: 2.5580565361323973

Epoch: 5| Step: 2
Training loss: 2.4142813475336355
Validation loss: 2.5266208479875236

Epoch: 5| Step: 3
Training loss: 2.7244247319267387
Validation loss: 2.5731000897577276

Epoch: 5| Step: 4
Training loss: 2.006217590260392
Validation loss: 2.5284802307714727

Epoch: 5| Step: 5
Training loss: 2.7665648506763847
Validation loss: 2.5416705502850743

Epoch: 5| Step: 6
Training loss: 2.64852950124818
Validation loss: 2.5656289087314996

Epoch: 5| Step: 7
Training loss: 3.2478683523548972
Validation loss: 2.6008403898916597

Epoch: 5| Step: 8
Training loss: 2.381124730457149
Validation loss: 2.54778011748548

Epoch: 5| Step: 9
Training loss: 2.377266254346613
Validation loss: 2.531878224405432

Epoch: 5| Step: 10
Training loss: 3.1330134072892037
Validation loss: 2.5747795088633953

Epoch: 225| Step: 0
Training loss: 2.736220951963022
Validation loss: 2.554718425817307

Epoch: 5| Step: 1
Training loss: 2.4085756432975245
Validation loss: 2.5672954125888756

Epoch: 5| Step: 2
Training loss: 2.8921907050858455
Validation loss: 2.5654996257391938

Epoch: 5| Step: 3
Training loss: 3.0071161430112063
Validation loss: 2.5905326620279503

Epoch: 5| Step: 4
Training loss: 2.6856558038988134
Validation loss: 2.561441501523313

Epoch: 5| Step: 5
Training loss: 2.598408938472858
Validation loss: 2.5511987693045657

Epoch: 5| Step: 6
Training loss: 2.6597523655745094
Validation loss: 2.556727999085648

Epoch: 5| Step: 7
Training loss: 2.958581314080924
Validation loss: 2.5372321385474748

Epoch: 5| Step: 8
Training loss: 2.810501914761564
Validation loss: 2.5566586150586614

Epoch: 5| Step: 9
Training loss: 2.4601506019641324
Validation loss: 2.5700583308744833

Epoch: 5| Step: 10
Training loss: 2.6023390702062676
Validation loss: 2.5476098504372726

Epoch: 226| Step: 0
Training loss: 2.872282319349179
Validation loss: 2.5252910128320765

Epoch: 5| Step: 1
Training loss: 2.4276308634534813
Validation loss: 2.5294167055064047

Epoch: 5| Step: 2
Training loss: 2.7737231470143087
Validation loss: 2.6023212856050724

Epoch: 5| Step: 3
Training loss: 2.6719301452299926
Validation loss: 2.583120141443345

Epoch: 5| Step: 4
Training loss: 2.872142532722129
Validation loss: 2.5586327665125674

Epoch: 5| Step: 5
Training loss: 2.6765769053982877
Validation loss: 2.5615554657506543

Epoch: 5| Step: 6
Training loss: 2.9451847605236257
Validation loss: 2.5107157498461703

Epoch: 5| Step: 7
Training loss: 2.491776866028185
Validation loss: 2.573331119880806

Epoch: 5| Step: 8
Training loss: 2.852936379756562
Validation loss: 2.559224373908608

Epoch: 5| Step: 9
Training loss: 2.6684324160432618
Validation loss: 2.587408579445402

Epoch: 5| Step: 10
Training loss: 2.510059431519892
Validation loss: 2.5867054894978905

Epoch: 227| Step: 0
Training loss: 2.375601240649962
Validation loss: 2.5729248244696095

Epoch: 5| Step: 1
Training loss: 3.062464811161835
Validation loss: 2.5659067741699277

Epoch: 5| Step: 2
Training loss: 2.668150062041218
Validation loss: 2.576212303066254

Epoch: 5| Step: 3
Training loss: 2.0528655005767553
Validation loss: 2.58617295435993

Epoch: 5| Step: 4
Training loss: 2.671550619500767
Validation loss: 2.5892064932340664

Epoch: 5| Step: 5
Training loss: 2.9905445179727805
Validation loss: 2.5284113318955743

Epoch: 5| Step: 6
Training loss: 2.7895143287182647
Validation loss: 2.523485033989629

Epoch: 5| Step: 7
Training loss: 2.7916344503185444
Validation loss: 2.5493568011364025

Epoch: 5| Step: 8
Training loss: 2.3055333541148424
Validation loss: 2.552067929175981

Epoch: 5| Step: 9
Training loss: 3.245011536000206
Validation loss: 2.508988825847231

Epoch: 5| Step: 10
Training loss: 2.295837687114965
Validation loss: 2.553550929751806

Epoch: 228| Step: 0
Training loss: 2.8120792498049973
Validation loss: 2.5198183435880455

Epoch: 5| Step: 1
Training loss: 2.6679911801022267
Validation loss: 2.536775655598427

Epoch: 5| Step: 2
Training loss: 3.0916717947397263
Validation loss: 2.5523107337386266

Epoch: 5| Step: 3
Training loss: 2.647489304849637
Validation loss: 2.534831800539747

Epoch: 5| Step: 4
Training loss: 2.6976014963311044
Validation loss: 2.562353730747997

Epoch: 5| Step: 5
Training loss: 2.737313832959437
Validation loss: 2.5636917712403458

Epoch: 5| Step: 6
Training loss: 2.855448711027497
Validation loss: 2.5515453519124938

Epoch: 5| Step: 7
Training loss: 2.120084800103842
Validation loss: 2.5468449734572944

Epoch: 5| Step: 8
Training loss: 2.313605173319392
Validation loss: 2.5510846740382616

Epoch: 5| Step: 9
Training loss: 3.065196504501148
Validation loss: 2.54374751729613

Epoch: 5| Step: 10
Training loss: 2.69243009938752
Validation loss: 2.5579709552925154

Epoch: 229| Step: 0
Training loss: 2.5716790274098225
Validation loss: 2.544311908685883

Epoch: 5| Step: 1
Training loss: 3.2001477803439076
Validation loss: 2.540573393512227

Epoch: 5| Step: 2
Training loss: 2.1509389290894254
Validation loss: 2.5125378240110474

Epoch: 5| Step: 3
Training loss: 2.7035337811562985
Validation loss: 2.5547219300105164

Epoch: 5| Step: 4
Training loss: 2.9548496276496854
Validation loss: 2.5586708671560334

Epoch: 5| Step: 5
Training loss: 2.209354980032727
Validation loss: 2.5757301297202586

Epoch: 5| Step: 6
Training loss: 2.541662111955741
Validation loss: 2.5353078337522863

Epoch: 5| Step: 7
Training loss: 2.610714779753691
Validation loss: 2.545169618964574

Epoch: 5| Step: 8
Training loss: 3.0699063486234963
Validation loss: 2.55577273532391

Epoch: 5| Step: 9
Training loss: 3.0112296373970193
Validation loss: 2.5303406337151846

Epoch: 5| Step: 10
Training loss: 2.6564976296280562
Validation loss: 2.5513187437575264

Epoch: 230| Step: 0
Training loss: 2.60717113875187
Validation loss: 2.554119487374157

Epoch: 5| Step: 1
Training loss: 2.5501476394697744
Validation loss: 2.5263780727402727

Epoch: 5| Step: 2
Training loss: 2.1653407759436747
Validation loss: 2.5708703335497223

Epoch: 5| Step: 3
Training loss: 2.7427188543245165
Validation loss: 2.521016121317702

Epoch: 5| Step: 4
Training loss: 2.6234186041164524
Validation loss: 2.5584778371889545

Epoch: 5| Step: 5
Training loss: 2.635554394245517
Validation loss: 2.582981663907754

Epoch: 5| Step: 6
Training loss: 3.1579870599502127
Validation loss: 2.5754149451774477

Epoch: 5| Step: 7
Training loss: 2.6717082189072068
Validation loss: 2.5604742923809654

Epoch: 5| Step: 8
Training loss: 3.183395585521607
Validation loss: 2.568918013880872

Epoch: 5| Step: 9
Training loss: 2.689961038470403
Validation loss: 2.5708891274802523

Epoch: 5| Step: 10
Training loss: 2.686512166716861
Validation loss: 2.547952979103445

Epoch: 231| Step: 0
Training loss: 2.3991594750085783
Validation loss: 2.5864658503107467

Epoch: 5| Step: 1
Training loss: 2.724396378043185
Validation loss: 2.5603856413556283

Epoch: 5| Step: 2
Training loss: 2.582572107037733
Validation loss: 2.556164509757554

Epoch: 5| Step: 3
Training loss: 2.4558839287371548
Validation loss: 2.58419990063924

Epoch: 5| Step: 4
Training loss: 2.523409533271883
Validation loss: 2.5766748898824967

Epoch: 5| Step: 5
Training loss: 2.5529903642507694
Validation loss: 2.5724316012247077

Epoch: 5| Step: 6
Training loss: 2.9392764624549526
Validation loss: 2.585965208856796

Epoch: 5| Step: 7
Training loss: 2.4944723053612674
Validation loss: 2.540922882336555

Epoch: 5| Step: 8
Training loss: 2.815524869402181
Validation loss: 2.540821023186095

Epoch: 5| Step: 9
Training loss: 2.9951880328167566
Validation loss: 2.5396905281054303

Epoch: 5| Step: 10
Training loss: 3.2919383037528713
Validation loss: 2.574465338664579

Epoch: 232| Step: 0
Training loss: 2.419511096686884
Validation loss: 2.570628370488848

Epoch: 5| Step: 1
Training loss: 2.468618848190048
Validation loss: 2.5966517553251878

Epoch: 5| Step: 2
Training loss: 2.7697309629156392
Validation loss: 2.5396385075902868

Epoch: 5| Step: 3
Training loss: 3.012935249258295
Validation loss: 2.5747450264556

Epoch: 5| Step: 4
Training loss: 2.4674208720930206
Validation loss: 2.549458777288647

Epoch: 5| Step: 5
Training loss: 2.536221085144336
Validation loss: 2.542945811936582

Epoch: 5| Step: 6
Training loss: 2.8738327974170255
Validation loss: 2.5242332012404094

Epoch: 5| Step: 7
Training loss: 3.388868026113305
Validation loss: 2.5411066406285907

Epoch: 5| Step: 8
Training loss: 2.951118877750477
Validation loss: 2.5786638250565095

Epoch: 5| Step: 9
Training loss: 2.4427595858426336
Validation loss: 2.518549783245719

Epoch: 5| Step: 10
Training loss: 2.1795643323875793
Validation loss: 2.568870042184102

Epoch: 233| Step: 0
Training loss: 2.3635859017220713
Validation loss: 2.5655916668445458

Epoch: 5| Step: 1
Training loss: 3.0607638985055705
Validation loss: 2.592839085644451

Epoch: 5| Step: 2
Training loss: 3.0451877715245694
Validation loss: 2.54959770958658

Epoch: 5| Step: 3
Training loss: 2.539671370055031
Validation loss: 2.5156253515849767

Epoch: 5| Step: 4
Training loss: 2.908181973720515
Validation loss: 2.5425839462600437

Epoch: 5| Step: 5
Training loss: 1.7754013682293215
Validation loss: 2.5664744655026395

Epoch: 5| Step: 6
Training loss: 2.9210393189967507
Validation loss: 2.537361065402978

Epoch: 5| Step: 7
Training loss: 2.8384922594909328
Validation loss: 2.5486684957049133

Epoch: 5| Step: 8
Training loss: 2.3894561702702006
Validation loss: 2.5504699335141763

Epoch: 5| Step: 9
Training loss: 2.3710857058141963
Validation loss: 2.5752164113179363

Epoch: 5| Step: 10
Training loss: 3.3054668688875823
Validation loss: 2.563834396428074

Epoch: 234| Step: 0
Training loss: 1.832577751976984
Validation loss: 2.5081107352916687

Epoch: 5| Step: 1
Training loss: 2.599123157684579
Validation loss: 2.5400943408112013

Epoch: 5| Step: 2
Training loss: 2.9986858668591125
Validation loss: 2.571382471120764

Epoch: 5| Step: 3
Training loss: 2.2531070449261827
Validation loss: 2.56572108558511

Epoch: 5| Step: 4
Training loss: 3.173617931741684
Validation loss: 2.523026117675793

Epoch: 5| Step: 5
Training loss: 2.400856512933878
Validation loss: 2.531790877729463

Epoch: 5| Step: 6
Training loss: 3.00241071480949
Validation loss: 2.556267564716573

Epoch: 5| Step: 7
Training loss: 2.652321726914045
Validation loss: 2.568927308730125

Epoch: 5| Step: 8
Training loss: 2.9941906312074957
Validation loss: 2.5357560683588574

Epoch: 5| Step: 9
Training loss: 3.0389694552654887
Validation loss: 2.524593141352382

Epoch: 5| Step: 10
Training loss: 2.601110104012008
Validation loss: 2.532086742373807

Epoch: 235| Step: 0
Training loss: 2.681372910463414
Validation loss: 2.558681297855338

Epoch: 5| Step: 1
Training loss: 2.9192172932316187
Validation loss: 2.54367991785253

Epoch: 5| Step: 2
Training loss: 2.8504840640519395
Validation loss: 2.5682022394143162

Epoch: 5| Step: 3
Training loss: 2.5386453608666004
Validation loss: 2.5151806490317266

Epoch: 5| Step: 4
Training loss: 2.7736383069909842
Validation loss: 2.5704963010696122

Epoch: 5| Step: 5
Training loss: 2.744811538730518
Validation loss: 2.524668730557342

Epoch: 5| Step: 6
Training loss: 2.6676558706260622
Validation loss: 2.563437931736573

Epoch: 5| Step: 7
Training loss: 2.2090722293399367
Validation loss: 2.509263261592067

Epoch: 5| Step: 8
Training loss: 2.534332470707527
Validation loss: 2.56316325730379

Epoch: 5| Step: 9
Training loss: 3.060958318556771
Validation loss: 2.544520706426488

Epoch: 5| Step: 10
Training loss: 2.706207458302679
Validation loss: 2.5397320597671427

Epoch: 236| Step: 0
Training loss: 2.6493286613988873
Validation loss: 2.5764103213698353

Epoch: 5| Step: 1
Training loss: 2.258374312569785
Validation loss: 2.536352347709428

Epoch: 5| Step: 2
Training loss: 3.060508547642112
Validation loss: 2.5619067714191996

Epoch: 5| Step: 3
Training loss: 2.996883999330694
Validation loss: 2.551980916911302

Epoch: 5| Step: 4
Training loss: 2.9260123432809073
Validation loss: 2.5165221460945095

Epoch: 5| Step: 5
Training loss: 2.6062444307190007
Validation loss: 2.563089371480715

Epoch: 5| Step: 6
Training loss: 2.2026614519885745
Validation loss: 2.530628239390579

Epoch: 5| Step: 7
Training loss: 2.9426019069815053
Validation loss: 2.577084596084995

Epoch: 5| Step: 8
Training loss: 2.120529183972851
Validation loss: 2.5307066615452953

Epoch: 5| Step: 9
Training loss: 2.5641444442458834
Validation loss: 2.5295677758041126

Epoch: 5| Step: 10
Training loss: 3.5266980565578487
Validation loss: 2.5320193419069663

Epoch: 237| Step: 0
Training loss: 2.9352309208607177
Validation loss: 2.5578145746756915

Epoch: 5| Step: 1
Training loss: 2.6026715271753256
Validation loss: 2.5604203291632457

Epoch: 5| Step: 2
Training loss: 1.7639118086292824
Validation loss: 2.529769420900431

Epoch: 5| Step: 3
Training loss: 2.4272613678388106
Validation loss: 2.5544235184923894

Epoch: 5| Step: 4
Training loss: 2.494779572162234
Validation loss: 2.560911597196893

Epoch: 5| Step: 5
Training loss: 3.20887411604933
Validation loss: 2.5491597778107944

Epoch: 5| Step: 6
Training loss: 3.4135290641346376
Validation loss: 2.5503757227755055

Epoch: 5| Step: 7
Training loss: 2.9493726677550907
Validation loss: 2.5166056189263073

Epoch: 5| Step: 8
Training loss: 2.621237647118883
Validation loss: 2.536913094669955

Epoch: 5| Step: 9
Training loss: 2.6268211586857677
Validation loss: 2.579599189092674

Epoch: 5| Step: 10
Training loss: 2.402675500308757
Validation loss: 2.5435866983429003

Epoch: 238| Step: 0
Training loss: 2.947132307289566
Validation loss: 2.5739783725778573

Epoch: 5| Step: 1
Training loss: 3.0058347863374575
Validation loss: 2.5707613964476463

Epoch: 5| Step: 2
Training loss: 2.310767272085657
Validation loss: 2.5391528839355755

Epoch: 5| Step: 3
Training loss: 2.2180057405650335
Validation loss: 2.5407955684809687

Epoch: 5| Step: 4
Training loss: 2.859554431059051
Validation loss: 2.543513238656088

Epoch: 5| Step: 5
Training loss: 3.397013609303323
Validation loss: 2.567620656283503

Epoch: 5| Step: 6
Training loss: 2.6661858919987855
Validation loss: 2.555201878788314

Epoch: 5| Step: 7
Training loss: 2.638686783619291
Validation loss: 2.528030296425948

Epoch: 5| Step: 8
Training loss: 2.915648000939218
Validation loss: 2.5554986760779856

Epoch: 5| Step: 9
Training loss: 2.308919144626888
Validation loss: 2.5484025004435265

Epoch: 5| Step: 10
Training loss: 2.6183231451984463
Validation loss: 2.5827572124250184

Epoch: 239| Step: 0
Training loss: 2.1510882307159003
Validation loss: 2.567848260826662

Epoch: 5| Step: 1
Training loss: 2.7079388746916284
Validation loss: 2.5724822350963534

Epoch: 5| Step: 2
Training loss: 2.5979533319605967
Validation loss: 2.543236180473686

Epoch: 5| Step: 3
Training loss: 2.116948525993616
Validation loss: 2.5624900895714173

Epoch: 5| Step: 4
Training loss: 2.739849691653764
Validation loss: 2.5799224524112954

Epoch: 5| Step: 5
Training loss: 3.2869335542327907
Validation loss: 2.566468188433582

Epoch: 5| Step: 6
Training loss: 3.023673745716
Validation loss: 2.563051866641646

Epoch: 5| Step: 7
Training loss: 2.9702925037752426
Validation loss: 2.541265908621689

Epoch: 5| Step: 8
Training loss: 3.1687895702773075
Validation loss: 2.5199939513732073

Epoch: 5| Step: 9
Training loss: 2.1058625541242697
Validation loss: 2.547661118510705

Epoch: 5| Step: 10
Training loss: 2.282846284233826
Validation loss: 2.5742155083735754

Epoch: 240| Step: 0
Training loss: 2.9060819843906676
Validation loss: 2.563441537019103

Epoch: 5| Step: 1
Training loss: 2.9702470719035907
Validation loss: 2.542929071243761

Epoch: 5| Step: 2
Training loss: 2.9744689467427152
Validation loss: 2.570405638914446

Epoch: 5| Step: 3
Training loss: 3.1169288164613587
Validation loss: 2.5374890339996976

Epoch: 5| Step: 4
Training loss: 2.5249802919128577
Validation loss: 2.5265520922101934

Epoch: 5| Step: 5
Training loss: 3.174703154616835
Validation loss: 2.558510698155541

Epoch: 5| Step: 6
Training loss: 2.303715801678576
Validation loss: 2.5857530674392337

Epoch: 5| Step: 7
Training loss: 2.542738662365901
Validation loss: 2.529791753869783

Epoch: 5| Step: 8
Training loss: 2.694643684003552
Validation loss: 2.579202395409076

Epoch: 5| Step: 9
Training loss: 2.1805105535421943
Validation loss: 2.5606468191628426

Epoch: 5| Step: 10
Training loss: 2.4034802237534887
Validation loss: 2.5486854164694956

Epoch: 241| Step: 0
Training loss: 2.8779903285094015
Validation loss: 2.545810473216102

Epoch: 5| Step: 1
Training loss: 2.522016095417885
Validation loss: 2.559283318772468

Epoch: 5| Step: 2
Training loss: 2.343700154092345
Validation loss: 2.5664031223721273

Epoch: 5| Step: 3
Training loss: 2.7525528416078604
Validation loss: 2.5330956922245242

Epoch: 5| Step: 4
Training loss: 3.0665727898147033
Validation loss: 2.5162242964581454

Epoch: 5| Step: 5
Training loss: 2.9805450629667534
Validation loss: 2.5418681288958425

Epoch: 5| Step: 6
Training loss: 2.8891706777551573
Validation loss: 2.530857957716815

Epoch: 5| Step: 7
Training loss: 2.397168050305917
Validation loss: 2.5267910977959023

Epoch: 5| Step: 8
Training loss: 2.554424680670532
Validation loss: 2.5316823668322774

Epoch: 5| Step: 9
Training loss: 2.328925795090798
Validation loss: 2.534916602092098

Epoch: 5| Step: 10
Training loss: 2.9588994482965107
Validation loss: 2.5343897711396717

Epoch: 242| Step: 0
Training loss: 2.7431569355661245
Validation loss: 2.547478425752546

Epoch: 5| Step: 1
Training loss: 2.9724159494488798
Validation loss: 2.5486754095738755

Epoch: 5| Step: 2
Training loss: 2.9847263309132344
Validation loss: 2.5542900591891957

Epoch: 5| Step: 3
Training loss: 2.646569417452806
Validation loss: 2.5561457198934225

Epoch: 5| Step: 4
Training loss: 2.5809848529145074
Validation loss: 2.580187774606371

Epoch: 5| Step: 5
Training loss: 2.5550647888628704
Validation loss: 2.49008116445231

Epoch: 5| Step: 6
Training loss: 1.7489470992902336
Validation loss: 2.538097831028627

Epoch: 5| Step: 7
Training loss: 2.704172625973507
Validation loss: 2.5104845851621804

Epoch: 5| Step: 8
Training loss: 3.14146541149837
Validation loss: 2.5479634753112808

Epoch: 5| Step: 9
Training loss: 2.783248526219607
Validation loss: 2.522464830022541

Epoch: 5| Step: 10
Training loss: 2.8984748447202495
Validation loss: 2.5600538466126768

Epoch: 243| Step: 0
Training loss: 2.462074816251097
Validation loss: 2.526362185266324

Epoch: 5| Step: 1
Training loss: 2.3038442329760263
Validation loss: 2.5636822564124766

Epoch: 5| Step: 2
Training loss: 2.857728744789538
Validation loss: 2.571136178558965

Epoch: 5| Step: 3
Training loss: 2.0286517618571773
Validation loss: 2.5550227599238693

Epoch: 5| Step: 4
Training loss: 2.742002301605394
Validation loss: 2.5331225349058015

Epoch: 5| Step: 5
Training loss: 3.457518117640669
Validation loss: 2.5366430515809633

Epoch: 5| Step: 6
Training loss: 3.0777135273837013
Validation loss: 2.5546144458282316

Epoch: 5| Step: 7
Training loss: 2.4720156353514673
Validation loss: 2.547716959969861

Epoch: 5| Step: 8
Training loss: 2.2664893244574613
Validation loss: 2.5558402666905127

Epoch: 5| Step: 9
Training loss: 2.8309140441845853
Validation loss: 2.581377770534297

Epoch: 5| Step: 10
Training loss: 2.679821667217955
Validation loss: 2.5434998091848025

Epoch: 244| Step: 0
Training loss: 2.731981199666204
Validation loss: 2.5175460260575755

Epoch: 5| Step: 1
Training loss: 2.7250510674687365
Validation loss: 2.5682697434126074

Epoch: 5| Step: 2
Training loss: 2.6572878436922522
Validation loss: 2.5525181239021215

Epoch: 5| Step: 3
Training loss: 3.2032874089447856
Validation loss: 2.537054377235118

Epoch: 5| Step: 4
Training loss: 2.801148798832487
Validation loss: 2.5768582152511024

Epoch: 5| Step: 5
Training loss: 2.6025896307235428
Validation loss: 2.588855183591889

Epoch: 5| Step: 6
Training loss: 2.808016445796442
Validation loss: 2.5626387559813666

Epoch: 5| Step: 7
Training loss: 2.4137099912973436
Validation loss: 2.552547328441454

Epoch: 5| Step: 8
Training loss: 2.2364392115559197
Validation loss: 2.5550024104367353

Epoch: 5| Step: 9
Training loss: 2.8683098615372766
Validation loss: 2.5576515580254853

Epoch: 5| Step: 10
Training loss: 2.424033698033437
Validation loss: 2.55077703887326

Epoch: 245| Step: 0
Training loss: 3.066753003383978
Validation loss: 2.5767250931437427

Epoch: 5| Step: 1
Training loss: 2.1844648831147464
Validation loss: 2.50198492498886

Epoch: 5| Step: 2
Training loss: 2.6204346511748544
Validation loss: 2.5121157069086917

Epoch: 5| Step: 3
Training loss: 3.1276292040243856
Validation loss: 2.5603961106268383

Epoch: 5| Step: 4
Training loss: 3.1057910296117317
Validation loss: 2.5503264382916253

Epoch: 5| Step: 5
Training loss: 2.609956779268277
Validation loss: 2.537219498307053

Epoch: 5| Step: 6
Training loss: 2.662093075025758
Validation loss: 2.562817854717748

Epoch: 5| Step: 7
Training loss: 2.724490539803185
Validation loss: 2.5632407480622748

Epoch: 5| Step: 8
Training loss: 2.2983138579534006
Validation loss: 2.5274765771706966

Epoch: 5| Step: 9
Training loss: 2.7788722986652012
Validation loss: 2.5475372303053985

Epoch: 5| Step: 10
Training loss: 2.2240959559672997
Validation loss: 2.5608538260476084

Epoch: 246| Step: 0
Training loss: 2.893383297847722
Validation loss: 2.5541816755817144

Epoch: 5| Step: 1
Training loss: 2.4974823672538013
Validation loss: 2.5305016395185578

Epoch: 5| Step: 2
Training loss: 2.3626907998195104
Validation loss: 2.5595482994551153

Epoch: 5| Step: 3
Training loss: 2.3210342260924604
Validation loss: 2.5707583110158763

Epoch: 5| Step: 4
Training loss: 2.461744581817618
Validation loss: 2.5441816895837106

Epoch: 5| Step: 5
Training loss: 2.943300728824333
Validation loss: 2.546432582513885

Epoch: 5| Step: 6
Training loss: 2.3831924885923725
Validation loss: 2.550210692556429

Epoch: 5| Step: 7
Training loss: 3.2818149625233577
Validation loss: 2.5437201124962443

Epoch: 5| Step: 8
Training loss: 2.8242317505427783
Validation loss: 2.507218929153387

Epoch: 5| Step: 9
Training loss: 2.3206575182119176
Validation loss: 2.550386752823985

Epoch: 5| Step: 10
Training loss: 3.351409552936811
Validation loss: 2.5511320827941124

Epoch: 247| Step: 0
Training loss: 1.9671092992726749
Validation loss: 2.5309369724032464

Epoch: 5| Step: 1
Training loss: 2.39383925229206
Validation loss: 2.5047655072166566

Epoch: 5| Step: 2
Training loss: 2.900973544642189
Validation loss: 2.527196743416505

Epoch: 5| Step: 3
Training loss: 2.3391829689616572
Validation loss: 2.5447772156694346

Epoch: 5| Step: 4
Training loss: 2.880824615786068
Validation loss: 2.5039934145041336

Epoch: 5| Step: 5
Training loss: 2.5493499338648333
Validation loss: 2.550342218195558

Epoch: 5| Step: 6
Training loss: 2.9315379898027483
Validation loss: 2.547792756146137

Epoch: 5| Step: 7
Training loss: 2.774190021560585
Validation loss: 2.5512310668476235

Epoch: 5| Step: 8
Training loss: 2.9486038072155893
Validation loss: 2.537668201418973

Epoch: 5| Step: 9
Training loss: 2.5774055170600025
Validation loss: 2.5371918744641335

Epoch: 5| Step: 10
Training loss: 2.9879975227846143
Validation loss: 2.5081369571375167

Epoch: 248| Step: 0
Training loss: 2.6200794241419967
Validation loss: 2.5584014011183696

Epoch: 5| Step: 1
Training loss: 2.607898317162675
Validation loss: 2.5727850070038936

Epoch: 5| Step: 2
Training loss: 2.8976890235049235
Validation loss: 2.542367646538307

Epoch: 5| Step: 3
Training loss: 2.939907467222824
Validation loss: 2.574683002860072

Epoch: 5| Step: 4
Training loss: 2.790618804207104
Validation loss: 2.563924238063579

Epoch: 5| Step: 5
Training loss: 1.9902757634734438
Validation loss: 2.5245464924054106

Epoch: 5| Step: 6
Training loss: 2.9505775403563406
Validation loss: 2.551535643087772

Epoch: 5| Step: 7
Training loss: 2.117685069494128
Validation loss: 2.5174570598900092

Epoch: 5| Step: 8
Training loss: 2.743347444308743
Validation loss: 2.5551205477802683

Epoch: 5| Step: 9
Training loss: 2.829189205688526
Validation loss: 2.5230793687537925

Epoch: 5| Step: 10
Training loss: 2.8591975589581673
Validation loss: 2.5403340371468164

Epoch: 249| Step: 0
Training loss: 2.520208412665076
Validation loss: 2.5359286658817997

Epoch: 5| Step: 1
Training loss: 2.3877916687165444
Validation loss: 2.53576752444038

Epoch: 5| Step: 2
Training loss: 3.189409469427197
Validation loss: 2.5421468937358385

Epoch: 5| Step: 3
Training loss: 2.906856022479408
Validation loss: 2.5517597796171008

Epoch: 5| Step: 4
Training loss: 3.017729978228102
Validation loss: 2.5520366327074115

Epoch: 5| Step: 5
Training loss: 2.5491953384301724
Validation loss: 2.574971599045901

Epoch: 5| Step: 6
Training loss: 2.857796154945313
Validation loss: 2.5521387097141677

Epoch: 5| Step: 7
Training loss: 2.506250768647112
Validation loss: 2.5494771166750922

Epoch: 5| Step: 8
Training loss: 2.6974926078914296
Validation loss: 2.5433317936926874

Epoch: 5| Step: 9
Training loss: 2.3599596120320285
Validation loss: 2.5481564400660073

Epoch: 5| Step: 10
Training loss: 2.4647638516542285
Validation loss: 2.520977192774543

Epoch: 250| Step: 0
Training loss: 2.876362684977718
Validation loss: 2.5359473027716715

Epoch: 5| Step: 1
Training loss: 2.732833514997011
Validation loss: 2.5649999833592236

Epoch: 5| Step: 2
Training loss: 2.538316446883935
Validation loss: 2.536479503041849

Epoch: 5| Step: 3
Training loss: 2.2095679904329044
Validation loss: 2.5340892829918396

Epoch: 5| Step: 4
Training loss: 2.900196128000929
Validation loss: 2.5209079047651257

Epoch: 5| Step: 5
Training loss: 2.8277751221443435
Validation loss: 2.531012520536979

Epoch: 5| Step: 6
Training loss: 2.673219398328375
Validation loss: 2.543333228055127

Epoch: 5| Step: 7
Training loss: 2.369058304101016
Validation loss: 2.560035878410402

Epoch: 5| Step: 8
Training loss: 2.835343564053694
Validation loss: 2.533781610961887

Epoch: 5| Step: 9
Training loss: 3.0341602001908803
Validation loss: 2.5295161937174857

Epoch: 5| Step: 10
Training loss: 2.5370840022908534
Validation loss: 2.5798171788477693

Epoch: 251| Step: 0
Training loss: 2.4150142830373014
Validation loss: 2.5633842269276816

Epoch: 5| Step: 1
Training loss: 3.018242841178893
Validation loss: 2.538539393503907

Epoch: 5| Step: 2
Training loss: 2.6567300699279235
Validation loss: 2.563524961140657

Epoch: 5| Step: 3
Training loss: 2.5388010682717566
Validation loss: 2.5271364293009073

Epoch: 5| Step: 4
Training loss: 2.4873552021458143
Validation loss: 2.539728550032872

Epoch: 5| Step: 5
Training loss: 2.931430471106827
Validation loss: 2.533295690335627

Epoch: 5| Step: 6
Training loss: 2.390003298034946
Validation loss: 2.5825029349132964

Epoch: 5| Step: 7
Training loss: 3.06863132099705
Validation loss: 2.5557231376271208

Epoch: 5| Step: 8
Training loss: 2.3977736756626817
Validation loss: 2.495271335069908

Epoch: 5| Step: 9
Training loss: 2.8127513349341906
Validation loss: 2.567842803777343

Epoch: 5| Step: 10
Training loss: 3.059118934646222
Validation loss: 2.577898446995924

Epoch: 252| Step: 0
Training loss: 3.0196335788773436
Validation loss: 2.5471428537103518

Epoch: 5| Step: 1
Training loss: 3.013743708132074
Validation loss: 2.5498369655009117

Epoch: 5| Step: 2
Training loss: 2.6839753924860608
Validation loss: 2.57457517653275

Epoch: 5| Step: 3
Training loss: 2.73237074285387
Validation loss: 2.5606500264062513

Epoch: 5| Step: 4
Training loss: 2.541352070167268
Validation loss: 2.5342757830132405

Epoch: 5| Step: 5
Training loss: 2.2932879406110884
Validation loss: 2.5685739021568463

Epoch: 5| Step: 6
Training loss: 2.5855404644102995
Validation loss: 2.550615698236355

Epoch: 5| Step: 7
Training loss: 2.948215339187126
Validation loss: 2.5519493953540158

Epoch: 5| Step: 8
Training loss: 2.4645285911209545
Validation loss: 2.6128007961641044

Epoch: 5| Step: 9
Training loss: 2.5528410325246083
Validation loss: 2.5734142393442703

Epoch: 5| Step: 10
Training loss: 2.7430973119548647
Validation loss: 2.550662669449915

Epoch: 253| Step: 0
Training loss: 2.6015155776549275
Validation loss: 2.545731097930897

Epoch: 5| Step: 1
Training loss: 2.7422506211017814
Validation loss: 2.560699046121431

Epoch: 5| Step: 2
Training loss: 2.5953481874992166
Validation loss: 2.612718728571882

Epoch: 5| Step: 3
Training loss: 3.162097462000799
Validation loss: 2.5240276670985753

Epoch: 5| Step: 4
Training loss: 2.533695311367799
Validation loss: 2.5916502531421033

Epoch: 5| Step: 5
Training loss: 3.0020314332357105
Validation loss: 2.5712630549596

Epoch: 5| Step: 6
Training loss: 3.2878317081792057
Validation loss: 2.5261808718370315

Epoch: 5| Step: 7
Training loss: 2.3634423571441747
Validation loss: 2.554917695589112

Epoch: 5| Step: 8
Training loss: 2.001076646929649
Validation loss: 2.551331398550335

Epoch: 5| Step: 9
Training loss: 2.4496425523611354
Validation loss: 2.557073055278366

Epoch: 5| Step: 10
Training loss: 2.586717101994954
Validation loss: 2.578228994331079

Epoch: 254| Step: 0
Training loss: 2.3151615394603433
Validation loss: 2.5051539812597796

Epoch: 5| Step: 1
Training loss: 2.8852143658575327
Validation loss: 2.565534272381519

Epoch: 5| Step: 2
Training loss: 2.253021648433349
Validation loss: 2.5362185752989266

Epoch: 5| Step: 3
Training loss: 2.6752168157537257
Validation loss: 2.533665406885685

Epoch: 5| Step: 4
Training loss: 2.6974230477968044
Validation loss: 2.520415099950483

Epoch: 5| Step: 5
Training loss: 3.6138035412216167
Validation loss: 2.5610462630139668

Epoch: 5| Step: 6
Training loss: 2.362672030528218
Validation loss: 2.5424519577631437

Epoch: 5| Step: 7
Training loss: 2.8850788419055777
Validation loss: 2.5668247683472156

Epoch: 5| Step: 8
Training loss: 2.8474990110588196
Validation loss: 2.591080466155147

Epoch: 5| Step: 9
Training loss: 2.0811558470178095
Validation loss: 2.5733927471907023

Epoch: 5| Step: 10
Training loss: 2.577212177860157
Validation loss: 2.5528920238236488

Epoch: 255| Step: 0
Training loss: 3.2255940681191047
Validation loss: 2.5732321391143254

Epoch: 5| Step: 1
Training loss: 3.010262895680515
Validation loss: 2.5565964028702415

Epoch: 5| Step: 2
Training loss: 2.3882009146434084
Validation loss: 2.5529772808643627

Epoch: 5| Step: 3
Training loss: 2.673136095617535
Validation loss: 2.5416575922031557

Epoch: 5| Step: 4
Training loss: 2.6862775994503236
Validation loss: 2.5530955952579117

Epoch: 5| Step: 5
Training loss: 3.0888360040316556
Validation loss: 2.5677147834242704

Epoch: 5| Step: 6
Training loss: 1.9665579930145785
Validation loss: 2.5763573675896785

Epoch: 5| Step: 7
Training loss: 2.7101155994717274
Validation loss: 2.540594054836368

Epoch: 5| Step: 8
Training loss: 2.331623904436194
Validation loss: 2.535064539370861

Epoch: 5| Step: 9
Training loss: 2.937333122545472
Validation loss: 2.547826176022851

Epoch: 5| Step: 10
Training loss: 2.041728297750094
Validation loss: 2.5248808341353772

Epoch: 256| Step: 0
Training loss: 3.051823124301119
Validation loss: 2.5322338376369946

Epoch: 5| Step: 1
Training loss: 2.5339918004470072
Validation loss: 2.5411001737778416

Epoch: 5| Step: 2
Training loss: 2.9321778152795375
Validation loss: 2.549246144201052

Epoch: 5| Step: 3
Training loss: 2.4693623036970833
Validation loss: 2.544348252444277

Epoch: 5| Step: 4
Training loss: 2.9156097313582316
Validation loss: 2.559757063204323

Epoch: 5| Step: 5
Training loss: 2.3829926969838104
Validation loss: 2.598254930515382

Epoch: 5| Step: 6
Training loss: 2.494628476172526
Validation loss: 2.598258557540693

Epoch: 5| Step: 7
Training loss: 3.0284961894167086
Validation loss: 2.5769147700429498

Epoch: 5| Step: 8
Training loss: 2.874324387488176
Validation loss: 2.5328888762371795

Epoch: 5| Step: 9
Training loss: 2.270412464395817
Validation loss: 2.5519073974826973

Epoch: 5| Step: 10
Training loss: 2.627557144777686
Validation loss: 2.576533535669211

Epoch: 257| Step: 0
Training loss: 2.617536834632506
Validation loss: 2.584299874940172

Epoch: 5| Step: 1
Training loss: 2.93388403867095
Validation loss: 2.537872069717776

Epoch: 5| Step: 2
Training loss: 2.8002672987462267
Validation loss: 2.5775826110774647

Epoch: 5| Step: 3
Training loss: 2.766052126902871
Validation loss: 2.5599168693083674

Epoch: 5| Step: 4
Training loss: 3.014860540552331
Validation loss: 2.5592754173305288

Epoch: 5| Step: 5
Training loss: 2.149564135527899
Validation loss: 2.5442651346030978

Epoch: 5| Step: 6
Training loss: 2.8989365962853046
Validation loss: 2.5548525089589598

Epoch: 5| Step: 7
Training loss: 2.7518750647363563
Validation loss: 2.5750252692685875

Epoch: 5| Step: 8
Training loss: 2.3503690713861336
Validation loss: 2.5745422328338434

Epoch: 5| Step: 9
Training loss: 2.0813756773064798
Validation loss: 2.544454479644045

Epoch: 5| Step: 10
Training loss: 3.1089664363331577
Validation loss: 2.5855713761611634

Epoch: 258| Step: 0
Training loss: 2.540809382543368
Validation loss: 2.5618623289762743

Epoch: 5| Step: 1
Training loss: 2.383671039939855
Validation loss: 2.539629513365935

Epoch: 5| Step: 2
Training loss: 2.846165898906225
Validation loss: 2.5609553053523593

Epoch: 5| Step: 3
Training loss: 3.0189162561983194
Validation loss: 2.5611379912007153

Epoch: 5| Step: 4
Training loss: 3.093294977191469
Validation loss: 2.5156339526630194

Epoch: 5| Step: 5
Training loss: 2.507303441749967
Validation loss: 2.566850381406936

Epoch: 5| Step: 6
Training loss: 2.649953312732484
Validation loss: 2.5412475008982236

Epoch: 5| Step: 7
Training loss: 2.1502008033839646
Validation loss: 2.563319610650609

Epoch: 5| Step: 8
Training loss: 2.906516278281532
Validation loss: 2.521544406956861

Epoch: 5| Step: 9
Training loss: 3.0156768636246127
Validation loss: 2.553380962177031

Epoch: 5| Step: 10
Training loss: 2.5268697633200747
Validation loss: 2.5514791230887295

Epoch: 259| Step: 0
Training loss: 3.194633430382366
Validation loss: 2.5431779483327395

Epoch: 5| Step: 1
Training loss: 2.4028794102376514
Validation loss: 2.5523762504497944

Epoch: 5| Step: 2
Training loss: 2.5199767199455203
Validation loss: 2.5401516318728063

Epoch: 5| Step: 3
Training loss: 2.2204976250975736
Validation loss: 2.5550808144212045

Epoch: 5| Step: 4
Training loss: 2.3088149531159776
Validation loss: 2.5400510942392303

Epoch: 5| Step: 5
Training loss: 3.0346605443518393
Validation loss: 2.5425910420319746

Epoch: 5| Step: 6
Training loss: 3.279358818373426
Validation loss: 2.511246691858182

Epoch: 5| Step: 7
Training loss: 2.939660434446236
Validation loss: 2.5486444582087575

Epoch: 5| Step: 8
Training loss: 2.7088710153372704
Validation loss: 2.5991572693293747

Epoch: 5| Step: 9
Training loss: 2.1083261778738955
Validation loss: 2.571921445836133

Epoch: 5| Step: 10
Training loss: 2.645168931898999
Validation loss: 2.565941616134492

Epoch: 260| Step: 0
Training loss: 2.5310739526634376
Validation loss: 2.5356701928578196

Epoch: 5| Step: 1
Training loss: 2.22659312444674
Validation loss: 2.5337706138536853

Epoch: 5| Step: 2
Training loss: 2.2079814654553678
Validation loss: 2.53599414029898

Epoch: 5| Step: 3
Training loss: 2.620219646303158
Validation loss: 2.5441270744536593

Epoch: 5| Step: 4
Training loss: 2.7148395346190295
Validation loss: 2.5335836567229184

Epoch: 5| Step: 5
Training loss: 2.891048750876375
Validation loss: 2.541769535666656

Epoch: 5| Step: 6
Training loss: 2.2177091494287433
Validation loss: 2.5366445392470762

Epoch: 5| Step: 7
Training loss: 3.132075425195921
Validation loss: 2.5445594571409407

Epoch: 5| Step: 8
Training loss: 2.85049677752179
Validation loss: 2.540856461385514

Epoch: 5| Step: 9
Training loss: 3.299402940085882
Validation loss: 2.5307170935393515

Epoch: 5| Step: 10
Training loss: 2.3659672881289153
Validation loss: 2.531053957582048

Epoch: 261| Step: 0
Training loss: 3.2803039640214
Validation loss: 2.562238542337542

Epoch: 5| Step: 1
Training loss: 2.3362034674960412
Validation loss: 2.5458713639892903

Epoch: 5| Step: 2
Training loss: 2.856223448915844
Validation loss: 2.536608043675261

Epoch: 5| Step: 3
Training loss: 3.0091169426893787
Validation loss: 2.5919943347128642

Epoch: 5| Step: 4
Training loss: 2.244350546371934
Validation loss: 2.572766124288008

Epoch: 5| Step: 5
Training loss: 2.718339384794565
Validation loss: 2.5389664846839444

Epoch: 5| Step: 6
Training loss: 2.8065305301997623
Validation loss: 2.561211819209091

Epoch: 5| Step: 7
Training loss: 2.469139647819327
Validation loss: 2.548136625309804

Epoch: 5| Step: 8
Training loss: 2.7410173228849666
Validation loss: 2.56018988533499

Epoch: 5| Step: 9
Training loss: 2.4332175170649175
Validation loss: 2.5233785305602003

Epoch: 5| Step: 10
Training loss: 2.3804876273558198
Validation loss: 2.54325816939296

Epoch: 262| Step: 0
Training loss: 2.4598289293803353
Validation loss: 2.556841776351475

Epoch: 5| Step: 1
Training loss: 2.739338234113572
Validation loss: 2.5655813391834994

Epoch: 5| Step: 2
Training loss: 2.33340112269793
Validation loss: 2.5219546439244698

Epoch: 5| Step: 3
Training loss: 2.703415254213205
Validation loss: 2.5608268565885575

Epoch: 5| Step: 4
Training loss: 2.9863742702553973
Validation loss: 2.5492113013263014

Epoch: 5| Step: 5
Training loss: 2.852685994429198
Validation loss: 2.5359495333663564

Epoch: 5| Step: 6
Training loss: 2.0902730055283163
Validation loss: 2.534724297220397

Epoch: 5| Step: 7
Training loss: 2.714337594031247
Validation loss: 2.5617659022750363

Epoch: 5| Step: 8
Training loss: 2.755922529009275
Validation loss: 2.5652662123699583

Epoch: 5| Step: 9
Training loss: 2.7030659928248446
Validation loss: 2.561073938872204

Epoch: 5| Step: 10
Training loss: 3.0352715626220834
Validation loss: 2.5394492183787203

Epoch: 263| Step: 0
Training loss: 2.638355973179309
Validation loss: 2.5472459430478516

Epoch: 5| Step: 1
Training loss: 2.657314491149026
Validation loss: 2.53246291681865

Epoch: 5| Step: 2
Training loss: 2.812738959439531
Validation loss: 2.5274852018200122

Epoch: 5| Step: 3
Training loss: 2.438291274529567
Validation loss: 2.545608882221439

Epoch: 5| Step: 4
Training loss: 2.814666083470291
Validation loss: 2.5276062430260344

Epoch: 5| Step: 5
Training loss: 2.5360231019601414
Validation loss: 2.548502958592825

Epoch: 5| Step: 6
Training loss: 3.061078422850327
Validation loss: 2.519033693885604

Epoch: 5| Step: 7
Training loss: 2.4268526177721323
Validation loss: 2.5656236398124808

Epoch: 5| Step: 8
Training loss: 3.0970492255265287
Validation loss: 2.5323367898224105

Epoch: 5| Step: 9
Training loss: 2.522539386422874
Validation loss: 2.5924446437749498

Epoch: 5| Step: 10
Training loss: 2.41266302635141
Validation loss: 2.512600702642936

Epoch: 264| Step: 0
Training loss: 2.6282108288333945
Validation loss: 2.518859151941659

Epoch: 5| Step: 1
Training loss: 2.4109054711637805
Validation loss: 2.536405849644462

Epoch: 5| Step: 2
Training loss: 2.1243536471051025
Validation loss: 2.5412915109436374

Epoch: 5| Step: 3
Training loss: 2.5173703412000026
Validation loss: 2.5132064479599365

Epoch: 5| Step: 4
Training loss: 3.6102102394912734
Validation loss: 2.5414845813086138

Epoch: 5| Step: 5
Training loss: 3.0969870230452443
Validation loss: 2.5746388919793413

Epoch: 5| Step: 6
Training loss: 2.311319101228001
Validation loss: 2.5378141923066724

Epoch: 5| Step: 7
Training loss: 2.4717662107349483
Validation loss: 2.5177446048403396

Epoch: 5| Step: 8
Training loss: 2.9246571396944336
Validation loss: 2.5837622282182937

Epoch: 5| Step: 9
Training loss: 2.7843165261992766
Validation loss: 2.572668783930994

Epoch: 5| Step: 10
Training loss: 2.563205342795129
Validation loss: 2.5697794608168585

Epoch: 265| Step: 0
Training loss: 2.744148444439482
Validation loss: 2.531031970001548

Epoch: 5| Step: 1
Training loss: 2.7966930820398215
Validation loss: 2.58101549343408

Epoch: 5| Step: 2
Training loss: 2.2915448474295155
Validation loss: 2.53588628238211

Epoch: 5| Step: 3
Training loss: 2.476311222650202
Validation loss: 2.539447275039954

Epoch: 5| Step: 4
Training loss: 2.8025651727834937
Validation loss: 2.568082448764624

Epoch: 5| Step: 5
Training loss: 2.9245428461675553
Validation loss: 2.5371638552401734

Epoch: 5| Step: 6
Training loss: 3.1163928708936615
Validation loss: 2.545438217142145

Epoch: 5| Step: 7
Training loss: 3.0911342467444674
Validation loss: 2.531910861558047

Epoch: 5| Step: 8
Training loss: 1.9752688792245865
Validation loss: 2.52049429503529

Epoch: 5| Step: 9
Training loss: 2.5266131092256563
Validation loss: 2.572769997498074

Epoch: 5| Step: 10
Training loss: 2.601233567530117
Validation loss: 2.57337471073808

Epoch: 266| Step: 0
Training loss: 2.6700042957457084
Validation loss: 2.532863852445989

Epoch: 5| Step: 1
Training loss: 3.080609088964192
Validation loss: 2.5408411068774317

Epoch: 5| Step: 2
Training loss: 2.3806517763201813
Validation loss: 2.5460583119587388

Epoch: 5| Step: 3
Training loss: 2.2113726831261973
Validation loss: 2.5865998884068593

Epoch: 5| Step: 4
Training loss: 1.9956686683318945
Validation loss: 2.550088232107633

Epoch: 5| Step: 5
Training loss: 3.3915453246309237
Validation loss: 2.549035602392122

Epoch: 5| Step: 6
Training loss: 2.5738039738987757
Validation loss: 2.565733502478461

Epoch: 5| Step: 7
Training loss: 2.7132848421617273
Validation loss: 2.6023224323032372

Epoch: 5| Step: 8
Training loss: 2.7430153491028477
Validation loss: 2.518879258075258

Epoch: 5| Step: 9
Training loss: 2.2338437602597603
Validation loss: 2.552490183528847

Epoch: 5| Step: 10
Training loss: 2.943964075294319
Validation loss: 2.532933091736141

Epoch: 267| Step: 0
Training loss: 3.113788175773822
Validation loss: 2.583802993930819

Epoch: 5| Step: 1
Training loss: 2.606012885195773
Validation loss: 2.5360263357954946

Epoch: 5| Step: 2
Training loss: 1.7050900103841917
Validation loss: 2.577275922612164

Epoch: 5| Step: 3
Training loss: 2.95252960500321
Validation loss: 2.5924853377314694

Epoch: 5| Step: 4
Training loss: 2.9293186616780487
Validation loss: 2.528354967724939

Epoch: 5| Step: 5
Training loss: 2.5470039943488514
Validation loss: 2.530268928812985

Epoch: 5| Step: 6
Training loss: 2.968998948751991
Validation loss: 2.536652937671879

Epoch: 5| Step: 7
Training loss: 2.8852854307514773
Validation loss: 2.5189192418840616

Epoch: 5| Step: 8
Training loss: 2.8301047461437725
Validation loss: 2.5580856493813107

Epoch: 5| Step: 9
Training loss: 2.2930821873225917
Validation loss: 2.511439639938865

Epoch: 5| Step: 10
Training loss: 2.319475221969049
Validation loss: 2.563601077445137

Epoch: 268| Step: 0
Training loss: 2.9322309922512835
Validation loss: 2.534691617403247

Epoch: 5| Step: 1
Training loss: 2.834173321094083
Validation loss: 2.5381577412433467

Epoch: 5| Step: 2
Training loss: 2.580517762446569
Validation loss: 2.6117327916663364

Epoch: 5| Step: 3
Training loss: 2.354049432136647
Validation loss: 2.5954779621392854

Epoch: 5| Step: 4
Training loss: 2.3897797330604313
Validation loss: 2.525818683477593

Epoch: 5| Step: 5
Training loss: 2.5530743186524165
Validation loss: 2.548255352581956

Epoch: 5| Step: 6
Training loss: 2.842699129213888
Validation loss: 2.554486899584421

Epoch: 5| Step: 7
Training loss: 2.523065403765278
Validation loss: 2.5158238618648623

Epoch: 5| Step: 8
Training loss: 2.674839984706865
Validation loss: 2.5386881173823865

Epoch: 5| Step: 9
Training loss: 2.9560112951576505
Validation loss: 2.544083084237669

Epoch: 5| Step: 10
Training loss: 2.7715126772746665
Validation loss: 2.558399033278193

Epoch: 269| Step: 0
Training loss: 2.4103882120003095
Validation loss: 2.498146690965686

Epoch: 5| Step: 1
Training loss: 2.344742424977581
Validation loss: 2.5626094118456373

Epoch: 5| Step: 2
Training loss: 2.5740840801387073
Validation loss: 2.5374642268225953

Epoch: 5| Step: 3
Training loss: 3.072469094650986
Validation loss: 2.5533188016574297

Epoch: 5| Step: 4
Training loss: 3.0079558103034496
Validation loss: 2.543552691097547

Epoch: 5| Step: 5
Training loss: 2.807626698353456
Validation loss: 2.502447246153525

Epoch: 5| Step: 6
Training loss: 2.9562647038874386
Validation loss: 2.5248720823010506

Epoch: 5| Step: 7
Training loss: 2.6397498672648614
Validation loss: 2.5474057379693926

Epoch: 5| Step: 8
Training loss: 2.569987453326165
Validation loss: 2.4949526677800207

Epoch: 5| Step: 9
Training loss: 2.590444181640867
Validation loss: 2.5637746262487684

Epoch: 5| Step: 10
Training loss: 2.138030324365797
Validation loss: 2.549647717528739

Epoch: 270| Step: 0
Training loss: 2.82809507238244
Validation loss: 2.5664635695238216

Epoch: 5| Step: 1
Training loss: 1.9216887841298698
Validation loss: 2.5494330166534134

Epoch: 5| Step: 2
Training loss: 3.2053761085104004
Validation loss: 2.5462789275230695

Epoch: 5| Step: 3
Training loss: 2.5359997866838047
Validation loss: 2.5476824403237677

Epoch: 5| Step: 4
Training loss: 2.7756031446277194
Validation loss: 2.5256047772481165

Epoch: 5| Step: 5
Training loss: 2.7104757393907226
Validation loss: 2.5568087655933285

Epoch: 5| Step: 6
Training loss: 2.7705103941761853
Validation loss: 2.5268066218908305

Epoch: 5| Step: 7
Training loss: 2.8024168040630695
Validation loss: 2.597746833494381

Epoch: 5| Step: 8
Training loss: 2.3765615048177566
Validation loss: 2.562523699935216

Epoch: 5| Step: 9
Training loss: 2.8777224048931513
Validation loss: 2.537743574420449

Epoch: 5| Step: 10
Training loss: 2.5581385083730788
Validation loss: 2.5446020014451984

Epoch: 271| Step: 0
Training loss: 2.706851749606569
Validation loss: 2.5879934671329066

Epoch: 5| Step: 1
Training loss: 3.2498936268931335
Validation loss: 2.535130977070127

Epoch: 5| Step: 2
Training loss: 1.7449033635004898
Validation loss: 2.5223584258075897

Epoch: 5| Step: 3
Training loss: 2.999546175645019
Validation loss: 2.5428564802559466

Epoch: 5| Step: 4
Training loss: 2.7960772522116932
Validation loss: 2.555664535973132

Epoch: 5| Step: 5
Training loss: 2.049717683658566
Validation loss: 2.5508101709059843

Epoch: 5| Step: 6
Training loss: 2.5176295474226187
Validation loss: 2.555042150031883

Epoch: 5| Step: 7
Training loss: 2.3415288954782034
Validation loss: 2.5660860434363277

Epoch: 5| Step: 8
Training loss: 3.5205271811620458
Validation loss: 2.5512802926576623

Epoch: 5| Step: 9
Training loss: 2.451020036227175
Validation loss: 2.5280301889328087

Epoch: 5| Step: 10
Training loss: 2.420354451948141
Validation loss: 2.5740263187890955

Epoch: 272| Step: 0
Training loss: 2.5917860201943945
Validation loss: 2.556283679512331

Epoch: 5| Step: 1
Training loss: 3.098091393173633
Validation loss: 2.5664600778662567

Epoch: 5| Step: 2
Training loss: 3.22888572865409
Validation loss: 2.548079284893576

Epoch: 5| Step: 3
Training loss: 2.6922850482114176
Validation loss: 2.519478966896333

Epoch: 5| Step: 4
Training loss: 2.324529444340028
Validation loss: 2.538890878889563

Epoch: 5| Step: 5
Training loss: 2.473496714574183
Validation loss: 2.5306935753998894

Epoch: 5| Step: 6
Training loss: 2.5136269163010305
Validation loss: 2.521256207888346

Epoch: 5| Step: 7
Training loss: 1.5087369150575662
Validation loss: 2.576292092550222

Epoch: 5| Step: 8
Training loss: 2.6245242096359735
Validation loss: 2.542309999537631

Epoch: 5| Step: 9
Training loss: 3.3168230457596506
Validation loss: 2.5490830683658454

Epoch: 5| Step: 10
Training loss: 2.6363451883812608
Validation loss: 2.5689562249367954

Epoch: 273| Step: 0
Training loss: 2.867190493548335
Validation loss: 2.5609970307187653

Epoch: 5| Step: 1
Training loss: 2.3272656384408883
Validation loss: 2.5729704926760713

Epoch: 5| Step: 2
Training loss: 2.386057960452178
Validation loss: 2.520616172346132

Epoch: 5| Step: 3
Training loss: 2.7090201069538726
Validation loss: 2.563774147273758

Epoch: 5| Step: 4
Training loss: 1.833007682430403
Validation loss: 2.576765876666037

Epoch: 5| Step: 5
Training loss: 3.3057110871839894
Validation loss: 2.520474390461964

Epoch: 5| Step: 6
Training loss: 2.870837640043958
Validation loss: 2.550273280667849

Epoch: 5| Step: 7
Training loss: 2.710501072297749
Validation loss: 2.5291456101204552

Epoch: 5| Step: 8
Training loss: 2.76201311887019
Validation loss: 2.524318859012269

Epoch: 5| Step: 9
Training loss: 2.813212410450853
Validation loss: 2.55672988517062

Epoch: 5| Step: 10
Training loss: 2.3940652266231535
Validation loss: 2.547753163587658

Epoch: 274| Step: 0
Training loss: 2.160731647696431
Validation loss: 2.5441663047612626

Epoch: 5| Step: 1
Training loss: 2.5369262159336743
Validation loss: 2.5507036646529224

Epoch: 5| Step: 2
Training loss: 3.5823308888017023
Validation loss: 2.557502197744871

Epoch: 5| Step: 3
Training loss: 3.2829634779247385
Validation loss: 2.5403961662225227

Epoch: 5| Step: 4
Training loss: 2.698886878538668
Validation loss: 2.5625648430304313

Epoch: 5| Step: 5
Training loss: 2.4393090601850913
Validation loss: 2.536967149151521

Epoch: 5| Step: 6
Training loss: 2.2376693235294716
Validation loss: 2.5473062932822104

Epoch: 5| Step: 7
Training loss: 2.6410303651161096
Validation loss: 2.600957194337688

Epoch: 5| Step: 8
Training loss: 2.151904163367949
Validation loss: 2.529078740485041

Epoch: 5| Step: 9
Training loss: 2.87639252483196
Validation loss: 2.5520580555859165

Epoch: 5| Step: 10
Training loss: 2.688931638292003
Validation loss: 2.5232418533950747

Epoch: 275| Step: 0
Training loss: 2.3303292100022577
Validation loss: 2.551594103459263

Epoch: 5| Step: 1
Training loss: 1.9405617671376545
Validation loss: 2.529933342416076

Epoch: 5| Step: 2
Training loss: 2.9764586903649812
Validation loss: 2.546596779402588

Epoch: 5| Step: 3
Training loss: 2.3035796007959806
Validation loss: 2.569280711593269

Epoch: 5| Step: 4
Training loss: 3.2256803992469463
Validation loss: 2.5520695062948766

Epoch: 5| Step: 5
Training loss: 2.6153007424831305
Validation loss: 2.5512986129215647

Epoch: 5| Step: 6
Training loss: 2.929092061886556
Validation loss: 2.54828745604479

Epoch: 5| Step: 7
Training loss: 2.9979403100971296
Validation loss: 2.5326594868694445

Epoch: 5| Step: 8
Training loss: 2.5215715530654697
Validation loss: 2.543098904192855

Epoch: 5| Step: 9
Training loss: 2.856469517792742
Validation loss: 2.541238944141563

Epoch: 5| Step: 10
Training loss: 2.6177480524351138
Validation loss: 2.547251778358502

Epoch: 276| Step: 0
Training loss: 2.1508408299517083
Validation loss: 2.5720529367355205

Epoch: 5| Step: 1
Training loss: 2.033378776709532
Validation loss: 2.550928812938287

Epoch: 5| Step: 2
Training loss: 3.2701771233793937
Validation loss: 2.5145451893066135

Epoch: 5| Step: 3
Training loss: 2.5851334073673486
Validation loss: 2.5602189222552605

Epoch: 5| Step: 4
Training loss: 2.4980622411140474
Validation loss: 2.547124051644578

Epoch: 5| Step: 5
Training loss: 2.1468385607252003
Validation loss: 2.542798196067101

Epoch: 5| Step: 6
Training loss: 3.1315853160167455
Validation loss: 2.5655646877347484

Epoch: 5| Step: 7
Training loss: 3.0338409991108204
Validation loss: 2.541251702596176

Epoch: 5| Step: 8
Training loss: 2.8307964711170372
Validation loss: 2.5560898308902678

Epoch: 5| Step: 9
Training loss: 2.1230065588470213
Validation loss: 2.5661722117938406

Epoch: 5| Step: 10
Training loss: 2.948589090999876
Validation loss: 2.5336683057792007

Epoch: 277| Step: 0
Training loss: 2.598875565571054
Validation loss: 2.5456034308727595

Epoch: 5| Step: 1
Training loss: 2.7904549336487867
Validation loss: 2.569854247643478

Epoch: 5| Step: 2
Training loss: 3.041626464020666
Validation loss: 2.574005833695363

Epoch: 5| Step: 3
Training loss: 2.4585562674953514
Validation loss: 2.5304835556935403

Epoch: 5| Step: 4
Training loss: 2.322585100764441
Validation loss: 2.519135774540499

Epoch: 5| Step: 5
Training loss: 2.7325998702300436
Validation loss: 2.568517609364188

Epoch: 5| Step: 6
Training loss: 2.4621212004726027
Validation loss: 2.5613078934304516

Epoch: 5| Step: 7
Training loss: 2.6607995956803667
Validation loss: 2.519006507706234

Epoch: 5| Step: 8
Training loss: 2.2425187029106475
Validation loss: 2.559529455304967

Epoch: 5| Step: 9
Training loss: 2.9546375740468958
Validation loss: 2.5322154108265287

Epoch: 5| Step: 10
Training loss: 3.000077246625122
Validation loss: 2.5469002932876617

Epoch: 278| Step: 0
Training loss: 2.8209770455276737
Validation loss: 2.525707728635422

Epoch: 5| Step: 1
Training loss: 2.7300647005511713
Validation loss: 2.5143239886213715

Epoch: 5| Step: 2
Training loss: 2.2233435133091395
Validation loss: 2.5363615309425263

Epoch: 5| Step: 3
Training loss: 2.3248211248355624
Validation loss: 2.5368028666044062

Epoch: 5| Step: 4
Training loss: 2.5398862470851573
Validation loss: 2.529156190462241

Epoch: 5| Step: 5
Training loss: 2.387321034060046
Validation loss: 2.5169980294341876

Epoch: 5| Step: 6
Training loss: 3.3355461087545963
Validation loss: 2.5261690581895007

Epoch: 5| Step: 7
Training loss: 2.720594460096652
Validation loss: 2.5451470915557413

Epoch: 5| Step: 8
Training loss: 2.3604700439918243
Validation loss: 2.5630775394091394

Epoch: 5| Step: 9
Training loss: 3.140872319290682
Validation loss: 2.518782410275334

Epoch: 5| Step: 10
Training loss: 2.6590888616914135
Validation loss: 2.5246176170311343

Epoch: 279| Step: 0
Training loss: 3.018288814469833
Validation loss: 2.5214897351359573

Epoch: 5| Step: 1
Training loss: 2.3594948441339363
Validation loss: 2.571386374330646

Epoch: 5| Step: 2
Training loss: 3.016656728766776
Validation loss: 2.5587476092765225

Epoch: 5| Step: 3
Training loss: 2.46703742780618
Validation loss: 2.5568068284302328

Epoch: 5| Step: 4
Training loss: 2.705081474219497
Validation loss: 2.5265061602953613

Epoch: 5| Step: 5
Training loss: 2.287820837315454
Validation loss: 2.5228649188122128

Epoch: 5| Step: 6
Training loss: 3.2167460304971605
Validation loss: 2.5390748130177947

Epoch: 5| Step: 7
Training loss: 2.670638484264625
Validation loss: 2.5425720908572313

Epoch: 5| Step: 8
Training loss: 2.4659596379264945
Validation loss: 2.5533217826579215

Epoch: 5| Step: 9
Training loss: 2.5306327915048152
Validation loss: 2.5405865332074997

Epoch: 5| Step: 10
Training loss: 2.2933543724196523
Validation loss: 2.582276731254794

Epoch: 280| Step: 0
Training loss: 2.108481436893994
Validation loss: 2.541425247332964

Epoch: 5| Step: 1
Training loss: 2.6081657120182484
Validation loss: 2.5813522708330034

Epoch: 5| Step: 2
Training loss: 2.821711143222735
Validation loss: 2.5202677253315393

Epoch: 5| Step: 3
Training loss: 2.5462830212436485
Validation loss: 2.5475987208181285

Epoch: 5| Step: 4
Training loss: 2.6893685520812016
Validation loss: 2.539598712701114

Epoch: 5| Step: 5
Training loss: 3.3377750526272614
Validation loss: 2.5806530303732558

Epoch: 5| Step: 6
Training loss: 2.5400659075018357
Validation loss: 2.534876751278244

Epoch: 5| Step: 7
Training loss: 2.6228899876876666
Validation loss: 2.543818810519849

Epoch: 5| Step: 8
Training loss: 2.69219507359144
Validation loss: 2.5415849260661383

Epoch: 5| Step: 9
Training loss: 2.8166603682709046
Validation loss: 2.534866170541216

Epoch: 5| Step: 10
Training loss: 2.2765612558375867
Validation loss: 2.538805678941202

Epoch: 281| Step: 0
Training loss: 2.324572419257582
Validation loss: 2.5261426459983745

Epoch: 5| Step: 1
Training loss: 2.294618289427949
Validation loss: 2.5181178741866956

Epoch: 5| Step: 2
Training loss: 2.9589635867153423
Validation loss: 2.5192785618551787

Epoch: 5| Step: 3
Training loss: 2.290666246237992
Validation loss: 2.5714813974683555

Epoch: 5| Step: 4
Training loss: 3.158961123138815
Validation loss: 2.5571046319776487

Epoch: 5| Step: 5
Training loss: 2.2485531287453555
Validation loss: 2.5697502555845726

Epoch: 5| Step: 6
Training loss: 2.2198988398280277
Validation loss: 2.576982293527547

Epoch: 5| Step: 7
Training loss: 2.981260581967429
Validation loss: 2.5528167541344016

Epoch: 5| Step: 8
Training loss: 2.9716235258002244
Validation loss: 2.5382845304075032

Epoch: 5| Step: 9
Training loss: 2.5768212923517386
Validation loss: 2.5636798404505616

Epoch: 5| Step: 10
Training loss: 3.1970477254226863
Validation loss: 2.5598312224730706

Epoch: 282| Step: 0
Training loss: 2.626050738801055
Validation loss: 2.563474196347474

Epoch: 5| Step: 1
Training loss: 2.372417451248469
Validation loss: 2.55751570906106

Epoch: 5| Step: 2
Training loss: 2.490730744800996
Validation loss: 2.529603309833874

Epoch: 5| Step: 3
Training loss: 3.7175356380804137
Validation loss: 2.531683816402163

Epoch: 5| Step: 4
Training loss: 3.1656274763513728
Validation loss: 2.5455976783931398

Epoch: 5| Step: 5
Training loss: 2.0223840747707222
Validation loss: 2.5445721626767646

Epoch: 5| Step: 6
Training loss: 1.645918526034032
Validation loss: 2.553031779971808

Epoch: 5| Step: 7
Training loss: 2.402523275971172
Validation loss: 2.4893623288624247

Epoch: 5| Step: 8
Training loss: 2.8538095478222965
Validation loss: 2.5446007964964776

Epoch: 5| Step: 9
Training loss: 2.920115548029354
Validation loss: 2.5502638866683736

Epoch: 5| Step: 10
Training loss: 2.414592302079175
Validation loss: 2.5642462232238348

Epoch: 283| Step: 0
Training loss: 2.3415474269640937
Validation loss: 2.5469768591122337

Epoch: 5| Step: 1
Training loss: 2.9434267680572614
Validation loss: 2.562883780028319

Epoch: 5| Step: 2
Training loss: 3.2637428810161793
Validation loss: 2.597357977274082

Epoch: 5| Step: 3
Training loss: 2.591258311426255
Validation loss: 2.530035346558962

Epoch: 5| Step: 4
Training loss: 2.718789286713274
Validation loss: 2.5725660825483008

Epoch: 5| Step: 5
Training loss: 2.2356883637297926
Validation loss: 2.573906526287245

Epoch: 5| Step: 6
Training loss: 1.9669356690181579
Validation loss: 2.561375831349232

Epoch: 5| Step: 7
Training loss: 2.7678281123313315
Validation loss: 2.5560236180154847

Epoch: 5| Step: 8
Training loss: 3.0117820802355744
Validation loss: 2.543276849845597

Epoch: 5| Step: 9
Training loss: 2.63190478516164
Validation loss: 2.543218659965087

Epoch: 5| Step: 10
Training loss: 2.6213172328405365
Validation loss: 2.566808089009288

Epoch: 284| Step: 0
Training loss: 2.899177066191855
Validation loss: 2.5369239124289664

Epoch: 5| Step: 1
Training loss: 2.7130954739243256
Validation loss: 2.5442181279045917

Epoch: 5| Step: 2
Training loss: 2.884781989152554
Validation loss: 2.565468723960968

Epoch: 5| Step: 3
Training loss: 2.5449810826286114
Validation loss: 2.5416886009131914

Epoch: 5| Step: 4
Training loss: 2.707529173576721
Validation loss: 2.5244433271143443

Epoch: 5| Step: 5
Training loss: 3.0191820739751667
Validation loss: 2.5399319360263055

Epoch: 5| Step: 6
Training loss: 2.5630870239748518
Validation loss: 2.5746418403289524

Epoch: 5| Step: 7
Training loss: 1.9823142337232822
Validation loss: 2.504812430398625

Epoch: 5| Step: 8
Training loss: 2.562980792833531
Validation loss: 2.560946738364404

Epoch: 5| Step: 9
Training loss: 2.582098193895085
Validation loss: 2.5116807256028966

Epoch: 5| Step: 10
Training loss: 2.4394151060075293
Validation loss: 2.5404125628378122

Epoch: 285| Step: 0
Training loss: 2.6943176202542
Validation loss: 2.593674251529138

Epoch: 5| Step: 1
Training loss: 2.532658691254453
Validation loss: 2.5635669716920058

Epoch: 5| Step: 2
Training loss: 2.4068927649528598
Validation loss: 2.5483640586595175

Epoch: 5| Step: 3
Training loss: 2.3057099741299307
Validation loss: 2.5405180686103432

Epoch: 5| Step: 4
Training loss: 3.127722965284937
Validation loss: 2.5867411405009975

Epoch: 5| Step: 5
Training loss: 2.4739530757379713
Validation loss: 2.5508123679005235

Epoch: 5| Step: 6
Training loss: 2.8978150719925666
Validation loss: 2.5525260894487576

Epoch: 5| Step: 7
Training loss: 2.6474137479656408
Validation loss: 2.531874242062817

Epoch: 5| Step: 8
Training loss: 2.876913014719544
Validation loss: 2.535438579390788

Epoch: 5| Step: 9
Training loss: 2.8671667113836787
Validation loss: 2.5179255865084644

Epoch: 5| Step: 10
Training loss: 2.4068607694630617
Validation loss: 2.5613195249880065

Epoch: 286| Step: 0
Training loss: 2.512447743797614
Validation loss: 2.540113242346635

Epoch: 5| Step: 1
Training loss: 2.779498888449559
Validation loss: 2.547690641360608

Epoch: 5| Step: 2
Training loss: 2.7425283019171207
Validation loss: 2.560504718779942

Epoch: 5| Step: 3
Training loss: 2.2091284586008895
Validation loss: 2.520829395917236

Epoch: 5| Step: 4
Training loss: 2.2208900339452193
Validation loss: 2.572127721247695

Epoch: 5| Step: 5
Training loss: 2.915637207005696
Validation loss: 2.508851879766616

Epoch: 5| Step: 6
Training loss: 2.4287457864344906
Validation loss: 2.570528434936114

Epoch: 5| Step: 7
Training loss: 3.1514154554039036
Validation loss: 2.531233455918367

Epoch: 5| Step: 8
Training loss: 2.769682757668286
Validation loss: 2.5499937589449577

Epoch: 5| Step: 9
Training loss: 2.582211948368136
Validation loss: 2.5158589042321626

Epoch: 5| Step: 10
Training loss: 3.1124594260639036
Validation loss: 2.5404889911837456

Epoch: 287| Step: 0
Training loss: 3.076893361571682
Validation loss: 2.51517561894405

Epoch: 5| Step: 1
Training loss: 2.7961506678161867
Validation loss: 2.5589124355692947

Epoch: 5| Step: 2
Training loss: 2.6751900792549383
Validation loss: 2.5416210072284504

Epoch: 5| Step: 3
Training loss: 2.345700279062595
Validation loss: 2.5518663764097784

Epoch: 5| Step: 4
Training loss: 2.382023915360551
Validation loss: 2.492032773842985

Epoch: 5| Step: 5
Training loss: 2.6559103355899194
Validation loss: 2.5357356623223954

Epoch: 5| Step: 6
Training loss: 2.3195586858497093
Validation loss: 2.5460843141588465

Epoch: 5| Step: 7
Training loss: 2.611966610717007
Validation loss: 2.53619320782951

Epoch: 5| Step: 8
Training loss: 2.930423084738176
Validation loss: 2.522463146990033

Epoch: 5| Step: 9
Training loss: 2.467618658890211
Validation loss: 2.5878639630619618

Epoch: 5| Step: 10
Training loss: 2.6643439449081643
Validation loss: 2.5330653981009172

Epoch: 288| Step: 0
Training loss: 2.8868730268948593
Validation loss: 2.5087480445531813

Epoch: 5| Step: 1
Training loss: 2.7246147128363933
Validation loss: 2.496102704929119

Epoch: 5| Step: 2
Training loss: 2.8371522261797306
Validation loss: 2.558574664356194

Epoch: 5| Step: 3
Training loss: 2.0235524973354795
Validation loss: 2.5372127335801746

Epoch: 5| Step: 4
Training loss: 2.8458710190906062
Validation loss: 2.5612712268040525

Epoch: 5| Step: 5
Training loss: 2.5500720032642756
Validation loss: 2.511359962300094

Epoch: 5| Step: 6
Training loss: 2.794899183990262
Validation loss: 2.54791789316236

Epoch: 5| Step: 7
Training loss: 2.481182710518283
Validation loss: 2.573866353839797

Epoch: 5| Step: 8
Training loss: 2.49630101258289
Validation loss: 2.59298178490719

Epoch: 5| Step: 9
Training loss: 2.7802507984457625
Validation loss: 2.564088268670082

Epoch: 5| Step: 10
Training loss: 2.614466377063988
Validation loss: 2.535810680793373

Epoch: 289| Step: 0
Training loss: 3.0584576455888417
Validation loss: 2.5276495311155838

Epoch: 5| Step: 1
Training loss: 3.0036347939967682
Validation loss: 2.541695473754997

Epoch: 5| Step: 2
Training loss: 2.3827620704192256
Validation loss: 2.539388256395123

Epoch: 5| Step: 3
Training loss: 2.9282113794310334
Validation loss: 2.5867838294828327

Epoch: 5| Step: 4
Training loss: 2.7928078344979896
Validation loss: 2.569479051567728

Epoch: 5| Step: 5
Training loss: 2.6311525267897675
Validation loss: 2.537132445655699

Epoch: 5| Step: 6
Training loss: 2.6074850581939746
Validation loss: 2.581124331483062

Epoch: 5| Step: 7
Training loss: 2.1540446406124505
Validation loss: 2.532122511377603

Epoch: 5| Step: 8
Training loss: 2.6216874793265905
Validation loss: 2.5331428091746613

Epoch: 5| Step: 9
Training loss: 2.71382220691853
Validation loss: 2.5825684927254513

Epoch: 5| Step: 10
Training loss: 2.2372467153390594
Validation loss: 2.5936582410454943

Epoch: 290| Step: 0
Training loss: 2.538154885858894
Validation loss: 2.541402492044601

Epoch: 5| Step: 1
Training loss: 2.01990085075206
Validation loss: 2.5342645594297513

Epoch: 5| Step: 2
Training loss: 2.210487994002876
Validation loss: 2.5373599580514115

Epoch: 5| Step: 3
Training loss: 2.839659043382852
Validation loss: 2.5562584580093652

Epoch: 5| Step: 4
Training loss: 2.328471932387632
Validation loss: 2.545246080730922

Epoch: 5| Step: 5
Training loss: 2.373126144027133
Validation loss: 2.5598441115931125

Epoch: 5| Step: 6
Training loss: 2.7395603386865197
Validation loss: 2.5791752560064802

Epoch: 5| Step: 7
Training loss: 3.541340008799263
Validation loss: 2.5763621966310613

Epoch: 5| Step: 8
Training loss: 2.5550176657944994
Validation loss: 2.5732952004037113

Epoch: 5| Step: 9
Training loss: 2.6921641662613753
Validation loss: 2.6014914598551777

Epoch: 5| Step: 10
Training loss: 2.892285504115542
Validation loss: 2.5649380289613846

Epoch: 291| Step: 0
Training loss: 3.07915746733066
Validation loss: 2.530138872531005

Epoch: 5| Step: 1
Training loss: 2.597184538497035
Validation loss: 2.5402073775285996

Epoch: 5| Step: 2
Training loss: 2.4673461785726363
Validation loss: 2.5227014830929275

Epoch: 5| Step: 3
Training loss: 2.4942966254071663
Validation loss: 2.559415711376307

Epoch: 5| Step: 4
Training loss: 2.395495471075017
Validation loss: 2.5432102277803894

Epoch: 5| Step: 5
Training loss: 2.304070548547046
Validation loss: 2.577454673653648

Epoch: 5| Step: 6
Training loss: 2.822932582308301
Validation loss: 2.5281495024904515

Epoch: 5| Step: 7
Training loss: 2.606384116548132
Validation loss: 2.5521878497127277

Epoch: 5| Step: 8
Training loss: 2.7730704051178945
Validation loss: 2.5249899982687634

Epoch: 5| Step: 9
Training loss: 2.2704191850982083
Validation loss: 2.5296223270033256

Epoch: 5| Step: 10
Training loss: 3.027010597848125
Validation loss: 2.549795914135208

Epoch: 292| Step: 0
Training loss: 3.105644864060841
Validation loss: 2.5395209805474583

Epoch: 5| Step: 1
Training loss: 2.8077913498970832
Validation loss: 2.5140881489353455

Epoch: 5| Step: 2
Training loss: 2.408854573567674
Validation loss: 2.5494765173639675

Epoch: 5| Step: 3
Training loss: 2.9317094259810657
Validation loss: 2.5342658542666157

Epoch: 5| Step: 4
Training loss: 2.7579978469939816
Validation loss: 2.5360162845081744

Epoch: 5| Step: 5
Training loss: 2.7287500563379927
Validation loss: 2.535261839015808

Epoch: 5| Step: 6
Training loss: 1.8744931489621353
Validation loss: 2.5713966911388635

Epoch: 5| Step: 7
Training loss: 2.4811265929159
Validation loss: 2.539302599639914

Epoch: 5| Step: 8
Training loss: 2.572234018141758
Validation loss: 2.529691039109914

Epoch: 5| Step: 9
Training loss: 2.821937578928942
Validation loss: 2.548979202461929

Epoch: 5| Step: 10
Training loss: 2.2073395370277935
Validation loss: 2.5273934086022236

Epoch: 293| Step: 0
Training loss: 2.6291577245819164
Validation loss: 2.5520530117929967

Epoch: 5| Step: 1
Training loss: 2.393596721950877
Validation loss: 2.584544800494217

Epoch: 5| Step: 2
Training loss: 2.626253827694587
Validation loss: 2.5671661206497496

Epoch: 5| Step: 3
Training loss: 2.7987313530025166
Validation loss: 2.5815293870572655

Epoch: 5| Step: 4
Training loss: 2.536552714655237
Validation loss: 2.523232824092132

Epoch: 5| Step: 5
Training loss: 1.952219211350731
Validation loss: 2.520518904090147

Epoch: 5| Step: 6
Training loss: 2.6342361178278977
Validation loss: 2.531121255124147

Epoch: 5| Step: 7
Training loss: 2.369661957820575
Validation loss: 2.5140282484213916

Epoch: 5| Step: 8
Training loss: 3.1008475221840497
Validation loss: 2.594514161214543

Epoch: 5| Step: 9
Training loss: 3.17980956796941
Validation loss: 2.5203578876557895

Epoch: 5| Step: 10
Training loss: 2.8673385039851063
Validation loss: 2.515178104940007

Epoch: 294| Step: 0
Training loss: 2.9699657962255244
Validation loss: 2.5514918127551267

Epoch: 5| Step: 1
Training loss: 3.158277408101359
Validation loss: 2.546701404849161

Epoch: 5| Step: 2
Training loss: 2.875398359481345
Validation loss: 2.54575050443083

Epoch: 5| Step: 3
Training loss: 2.7043515989041818
Validation loss: 2.5679838676727305

Epoch: 5| Step: 4
Training loss: 2.471858903950636
Validation loss: 2.517411481395563

Epoch: 5| Step: 5
Training loss: 2.0042644574687274
Validation loss: 2.530818461350891

Epoch: 5| Step: 6
Training loss: 2.416758590353081
Validation loss: 2.531151168394787

Epoch: 5| Step: 7
Training loss: 2.449748832128538
Validation loss: 2.5412115506242476

Epoch: 5| Step: 8
Training loss: 2.4909125148949633
Validation loss: 2.5086887952237755

Epoch: 5| Step: 9
Training loss: 2.7939517125440068
Validation loss: 2.558502084905648

Epoch: 5| Step: 10
Training loss: 2.6726189185609868
Validation loss: 2.518639817236685

Epoch: 295| Step: 0
Training loss: 2.6156840546753837
Validation loss: 2.5283949902785574

Epoch: 5| Step: 1
Training loss: 2.828331112595696
Validation loss: 2.574832429380534

Epoch: 5| Step: 2
Training loss: 2.2751189106476764
Validation loss: 2.5861948676661135

Epoch: 5| Step: 3
Training loss: 2.5441360255708942
Validation loss: 2.5330551032993873

Epoch: 5| Step: 4
Training loss: 2.6859242455031724
Validation loss: 2.536339978012201

Epoch: 5| Step: 5
Training loss: 2.1458791585924053
Validation loss: 2.5143505861387188

Epoch: 5| Step: 6
Training loss: 3.1345030677623407
Validation loss: 2.558980496192108

Epoch: 5| Step: 7
Training loss: 2.5303744461940134
Validation loss: 2.539942106059196

Epoch: 5| Step: 8
Training loss: 2.6178733724069847
Validation loss: 2.5369460576171714

Epoch: 5| Step: 9
Training loss: 3.04994383588265
Validation loss: 2.562950889962583

Epoch: 5| Step: 10
Training loss: 2.708960172054147
Validation loss: 2.536931190769125

Epoch: 296| Step: 0
Training loss: 2.8665218568052104
Validation loss: 2.5586175417269463

Epoch: 5| Step: 1
Training loss: 2.8376851227318944
Validation loss: 2.572708113127135

Epoch: 5| Step: 2
Training loss: 2.4514785392392957
Validation loss: 2.5255974921512783

Epoch: 5| Step: 3
Training loss: 2.353733112843893
Validation loss: 2.5165346906263157

Epoch: 5| Step: 4
Training loss: 3.248138334692103
Validation loss: 2.575308371435002

Epoch: 5| Step: 5
Training loss: 2.771153500829337
Validation loss: 2.545882674359509

Epoch: 5| Step: 6
Training loss: 1.9609233962079953
Validation loss: 2.525329831224368

Epoch: 5| Step: 7
Training loss: 2.9738496046795038
Validation loss: 2.5414952469634757

Epoch: 5| Step: 8
Training loss: 2.4650625382667104
Validation loss: 2.5268229514596796

Epoch: 5| Step: 9
Training loss: 2.708793121825542
Validation loss: 2.524478690567191

Epoch: 5| Step: 10
Training loss: 2.1941430720552826
Validation loss: 2.5393498598713973

Epoch: 297| Step: 0
Training loss: 2.4364086544543886
Validation loss: 2.548785646209013

Epoch: 5| Step: 1
Training loss: 3.4034022755105213
Validation loss: 2.5093902265003765

Epoch: 5| Step: 2
Training loss: 3.1836243048763793
Validation loss: 2.5045590218749307

Epoch: 5| Step: 3
Training loss: 2.716570627430091
Validation loss: 2.517845769970948

Epoch: 5| Step: 4
Training loss: 2.4890555190702677
Validation loss: 2.53923622060828

Epoch: 5| Step: 5
Training loss: 2.715500566904272
Validation loss: 2.5523252679306765

Epoch: 5| Step: 6
Training loss: 2.420550174753363
Validation loss: 2.5621453026478047

Epoch: 5| Step: 7
Training loss: 2.3183003444596175
Validation loss: 2.5173283163633005

Epoch: 5| Step: 8
Training loss: 2.361290766544324
Validation loss: 2.534107210582358

Epoch: 5| Step: 9
Training loss: 2.3470014271416892
Validation loss: 2.581127069806589

Epoch: 5| Step: 10
Training loss: 2.7995469953023204
Validation loss: 2.5288818515529705

Epoch: 298| Step: 0
Training loss: 2.2365753436975666
Validation loss: 2.517791206715094

Epoch: 5| Step: 1
Training loss: 2.027754843014594
Validation loss: 2.5290341874531825

Epoch: 5| Step: 2
Training loss: 2.449858124186745
Validation loss: 2.5400772618893748

Epoch: 5| Step: 3
Training loss: 1.9552423825463725
Validation loss: 2.546403943116256

Epoch: 5| Step: 4
Training loss: 2.5442497905900914
Validation loss: 2.5738257295579765

Epoch: 5| Step: 5
Training loss: 3.173209825591274
Validation loss: 2.5691723187688345

Epoch: 5| Step: 6
Training loss: 3.3026759020086267
Validation loss: 2.555576095287477

Epoch: 5| Step: 7
Training loss: 2.5367877806307564
Validation loss: 2.500052242348474

Epoch: 5| Step: 8
Training loss: 2.3495880658712642
Validation loss: 2.5657123986200525

Epoch: 5| Step: 9
Training loss: 2.8110323149385286
Validation loss: 2.5470993574299974

Epoch: 5| Step: 10
Training loss: 3.1785148689050655
Validation loss: 2.521206421287763

Epoch: 299| Step: 0
Training loss: 2.2134386345315
Validation loss: 2.565637170310785

Epoch: 5| Step: 1
Training loss: 2.975497798784891
Validation loss: 2.556412665422173

Epoch: 5| Step: 2
Training loss: 2.3976212395491916
Validation loss: 2.5404277554466526

Epoch: 5| Step: 3
Training loss: 2.7896858608633743
Validation loss: 2.540217079189411

Epoch: 5| Step: 4
Training loss: 2.2253693177681466
Validation loss: 2.5467277306615426

Epoch: 5| Step: 5
Training loss: 3.0701854572754117
Validation loss: 2.5226037200363014

Epoch: 5| Step: 6
Training loss: 3.141534626122861
Validation loss: 2.55973028850442

Epoch: 5| Step: 7
Training loss: 2.421805989912714
Validation loss: 2.543723887829327

Epoch: 5| Step: 8
Training loss: 2.892844672739645
Validation loss: 2.550604533487967

Epoch: 5| Step: 9
Training loss: 2.5686965082915076
Validation loss: 2.535994372300896

Epoch: 5| Step: 10
Training loss: 2.172419418052068
Validation loss: 2.5671711197701503

Epoch: 300| Step: 0
Training loss: 2.1294661319401347
Validation loss: 2.546968617025057

Epoch: 5| Step: 1
Training loss: 2.6149369769406645
Validation loss: 2.576553642470502

Epoch: 5| Step: 2
Training loss: 2.41796875
Validation loss: 2.5179921363671873

Epoch: 5| Step: 3
Training loss: 2.789113105720868
Validation loss: 2.560029418318672

Epoch: 5| Step: 4
Training loss: 2.1851186597016463
Validation loss: 2.5515551471076146

Epoch: 5| Step: 5
Training loss: 2.744584473252126
Validation loss: 2.581905753196192

Epoch: 5| Step: 6
Training loss: 2.8437164640021195
Validation loss: 2.563108364494459

Epoch: 5| Step: 7
Training loss: 3.006644837271312
Validation loss: 2.536682605819728

Epoch: 5| Step: 8
Training loss: 2.5864537579458458
Validation loss: 2.5632438890502947

Epoch: 5| Step: 9
Training loss: 2.9131615603660626
Validation loss: 2.5605067672849118

Epoch: 5| Step: 10
Training loss: 2.6755366526834004
Validation loss: 2.5387971513166945

Epoch: 301| Step: 0
Training loss: 2.6220528543413217
Validation loss: 2.5466273484525974

Epoch: 5| Step: 1
Training loss: 2.336668786752186
Validation loss: 2.5614440827362213

Epoch: 5| Step: 2
Training loss: 2.5431136926459157
Validation loss: 2.542534977583807

Epoch: 5| Step: 3
Training loss: 3.0217876812253492
Validation loss: 2.5734347311396095

Epoch: 5| Step: 4
Training loss: 2.3130585279502
Validation loss: 2.5356584274652336

Epoch: 5| Step: 5
Training loss: 2.337254691894209
Validation loss: 2.562754971764726

Epoch: 5| Step: 6
Training loss: 3.1055092862920395
Validation loss: 2.5165404046123196

Epoch: 5| Step: 7
Training loss: 2.292666465680882
Validation loss: 2.539386200949512

Epoch: 5| Step: 8
Training loss: 2.9359643046732415
Validation loss: 2.5552002223352184

Epoch: 5| Step: 9
Training loss: 2.710482688371424
Validation loss: 2.5626403906196673

Epoch: 5| Step: 10
Training loss: 3.1199362354609566
Validation loss: 2.573850416360856

Epoch: 302| Step: 0
Training loss: 2.654318252937733
Validation loss: 2.52428388736973

Epoch: 5| Step: 1
Training loss: 2.0325064661127255
Validation loss: 2.575037201253177

Epoch: 5| Step: 2
Training loss: 2.9897722102632995
Validation loss: 2.551348348880758

Epoch: 5| Step: 3
Training loss: 2.821931580306848
Validation loss: 2.5257572610634473

Epoch: 5| Step: 4
Training loss: 2.388060946250705
Validation loss: 2.5414011504062906

Epoch: 5| Step: 5
Training loss: 2.486547707617592
Validation loss: 2.543115704755991

Epoch: 5| Step: 6
Training loss: 3.089176226438952
Validation loss: 2.5788496359524236

Epoch: 5| Step: 7
Training loss: 2.5612988331702087
Validation loss: 2.5577806182824223

Epoch: 5| Step: 8
Training loss: 2.591326029021451
Validation loss: 2.5511947307012264

Epoch: 5| Step: 9
Training loss: 2.900993269146248
Validation loss: 2.5488102426146395

Epoch: 5| Step: 10
Training loss: 2.5713382981364266
Validation loss: 2.5474834650171205

Epoch: 303| Step: 0
Training loss: 2.720785409486812
Validation loss: 2.5171246602137147

Epoch: 5| Step: 1
Training loss: 2.7839361356557135
Validation loss: 2.5502671853784986

Epoch: 5| Step: 2
Training loss: 2.766269070042011
Validation loss: 2.5262953378521575

Epoch: 5| Step: 3
Training loss: 2.695304538880906
Validation loss: 2.5254279384523266

Epoch: 5| Step: 4
Training loss: 2.505756236307893
Validation loss: 2.5416019716574065

Epoch: 5| Step: 5
Training loss: 2.661246324270567
Validation loss: 2.5754731964785993

Epoch: 5| Step: 6
Training loss: 3.013229762916525
Validation loss: 2.4915262196768824

Epoch: 5| Step: 7
Training loss: 2.235041272253821
Validation loss: 2.513184332795636

Epoch: 5| Step: 8
Training loss: 2.525897831443092
Validation loss: 2.513608937491825

Epoch: 5| Step: 9
Training loss: 1.9762116976554398
Validation loss: 2.541337075760444

Epoch: 5| Step: 10
Training loss: 3.100486126592313
Validation loss: 2.5567699804410244

Epoch: 304| Step: 0
Training loss: 3.159025426102365
Validation loss: 2.531034968135067

Epoch: 5| Step: 1
Training loss: 2.3981806216774944
Validation loss: 2.5479340019062637

Epoch: 5| Step: 2
Training loss: 2.4719877620011386
Validation loss: 2.5489187263865962

Epoch: 5| Step: 3
Training loss: 2.7443336717573024
Validation loss: 2.5554098890585775

Epoch: 5| Step: 4
Training loss: 2.691504046209427
Validation loss: 2.5418367239876436

Epoch: 5| Step: 5
Training loss: 2.545655502709776
Validation loss: 2.5150852142711853

Epoch: 5| Step: 6
Training loss: 2.8986023395890803
Validation loss: 2.5157615417181214

Epoch: 5| Step: 7
Training loss: 2.7806130011949795
Validation loss: 2.5350519055141016

Epoch: 5| Step: 8
Training loss: 2.198206395824236
Validation loss: 2.5727734492039054

Epoch: 5| Step: 9
Training loss: 2.212767904839931
Validation loss: 2.5107948424473374

Epoch: 5| Step: 10
Training loss: 2.668982027138389
Validation loss: 2.581571302235936

Epoch: 305| Step: 0
Training loss: 2.4127333849349757
Validation loss: 2.52309393619473

Epoch: 5| Step: 1
Training loss: 3.124984588585045
Validation loss: 2.564753934017238

Epoch: 5| Step: 2
Training loss: 2.4496191935524205
Validation loss: 2.539790685845051

Epoch: 5| Step: 3
Training loss: 3.086954224568696
Validation loss: 2.5540901592843133

Epoch: 5| Step: 4
Training loss: 2.9571199391216085
Validation loss: 2.5316142107951394

Epoch: 5| Step: 5
Training loss: 2.715779841566261
Validation loss: 2.535586711682396

Epoch: 5| Step: 6
Training loss: 1.8883573946832553
Validation loss: 2.5795720965991342

Epoch: 5| Step: 7
Training loss: 3.1056170734036432
Validation loss: 2.539708644286862

Epoch: 5| Step: 8
Training loss: 2.3554308937282356
Validation loss: 2.518761078933757

Epoch: 5| Step: 9
Training loss: 2.28654826225633
Validation loss: 2.51330674819201

Epoch: 5| Step: 10
Training loss: 2.3940457074256463
Validation loss: 2.5626263821157553

Epoch: 306| Step: 0
Training loss: 3.1864927607797813
Validation loss: 2.547301833864971

Epoch: 5| Step: 1
Training loss: 2.3035327151943608
Validation loss: 2.569412992159828

Epoch: 5| Step: 2
Training loss: 3.1478067906961402
Validation loss: 2.5524447901904646

Epoch: 5| Step: 3
Training loss: 2.536143153437235
Validation loss: 2.537765979147791

Epoch: 5| Step: 4
Training loss: 2.951169128214721
Validation loss: 2.5254702518106975

Epoch: 5| Step: 5
Training loss: 2.275509339211363
Validation loss: 2.5514288787450132

Epoch: 5| Step: 6
Training loss: 2.5853306729639276
Validation loss: 2.5341427669490786

Epoch: 5| Step: 7
Training loss: 2.238998750789374
Validation loss: 2.5862462877699635

Epoch: 5| Step: 8
Training loss: 1.8532623343052754
Validation loss: 2.548578182669135

Epoch: 5| Step: 9
Training loss: 3.018933946521837
Validation loss: 2.53976011727865

Epoch: 5| Step: 10
Training loss: 2.5306873402603594
Validation loss: 2.5347902826474855

Epoch: 307| Step: 0
Training loss: 2.2598093040155263
Validation loss: 2.533891009808947

Epoch: 5| Step: 1
Training loss: 2.405778516676311
Validation loss: 2.568237369664743

Epoch: 5| Step: 2
Training loss: 2.202390507759565
Validation loss: 2.5404270419864172

Epoch: 5| Step: 3
Training loss: 2.6728472808926247
Validation loss: 2.5263078754604815

Epoch: 5| Step: 4
Training loss: 2.7564348881098053
Validation loss: 2.5301423763162223

Epoch: 5| Step: 5
Training loss: 2.516523307439207
Validation loss: 2.5549207208810634

Epoch: 5| Step: 6
Training loss: 3.0476466057729197
Validation loss: 2.5486422844925465

Epoch: 5| Step: 7
Training loss: 3.1931774962540067
Validation loss: 2.5167704518098284

Epoch: 5| Step: 8
Training loss: 2.535837796002875
Validation loss: 2.5588641019705487

Epoch: 5| Step: 9
Training loss: 2.4598782636402827
Validation loss: 2.533669925717902

Epoch: 5| Step: 10
Training loss: 3.025853495347251
Validation loss: 2.4979267824787774

Epoch: 308| Step: 0
Training loss: 2.627091800475385
Validation loss: 2.5389001342252016

Epoch: 5| Step: 1
Training loss: 2.9951181427288986
Validation loss: 2.5422351325173733

Epoch: 5| Step: 2
Training loss: 2.569843469743707
Validation loss: 2.4685483086595874

Epoch: 5| Step: 3
Training loss: 2.3258352604631045
Validation loss: 2.53536824873372

Epoch: 5| Step: 4
Training loss: 2.6645906433848268
Validation loss: 2.591738139414917

Epoch: 5| Step: 5
Training loss: 2.743720253889599
Validation loss: 2.5362535471377328

Epoch: 5| Step: 6
Training loss: 2.69375804360023
Validation loss: 2.5159273561409123

Epoch: 5| Step: 7
Training loss: 2.8578937633675805
Validation loss: 2.5347643678803977

Epoch: 5| Step: 8
Training loss: 2.3404237668327745
Validation loss: 2.5520241099943117

Epoch: 5| Step: 9
Training loss: 2.8242310751913804
Validation loss: 2.563039097177193

Epoch: 5| Step: 10
Training loss: 2.424338091151129
Validation loss: 2.511911401569019

Epoch: 309| Step: 0
Training loss: 2.4981183600319583
Validation loss: 2.5632773150053505

Epoch: 5| Step: 1
Training loss: 2.6554838983115476
Validation loss: 2.543698088264464

Epoch: 5| Step: 2
Training loss: 2.407988774644154
Validation loss: 2.502098542478583

Epoch: 5| Step: 3
Training loss: 3.05102991319144
Validation loss: 2.567191221009185

Epoch: 5| Step: 4
Training loss: 2.446766576398804
Validation loss: 2.5433310185520024

Epoch: 5| Step: 5
Training loss: 2.5780344629285152
Validation loss: 2.5497844069659017

Epoch: 5| Step: 6
Training loss: 2.8174718356819186
Validation loss: 2.511044288281502

Epoch: 5| Step: 7
Training loss: 3.0514943636286342
Validation loss: 2.5577662554112712

Epoch: 5| Step: 8
Training loss: 2.3608097993660904
Validation loss: 2.544961722643143

Epoch: 5| Step: 9
Training loss: 2.8056017732328016
Validation loss: 2.544500195370603

Epoch: 5| Step: 10
Training loss: 2.23759047682273
Validation loss: 2.5872348509748324

Epoch: 310| Step: 0
Training loss: 2.9322846561074796
Validation loss: 2.549628544808092

Epoch: 5| Step: 1
Training loss: 2.377302860305754
Validation loss: 2.5378430963265193

Epoch: 5| Step: 2
Training loss: 2.5231163363795805
Validation loss: 2.5579740521395506

Epoch: 5| Step: 3
Training loss: 2.4789136442259916
Validation loss: 2.562621989374091

Epoch: 5| Step: 4
Training loss: 2.2048584091156616
Validation loss: 2.564326909894142

Epoch: 5| Step: 5
Training loss: 2.0530579345526014
Validation loss: 2.5574639528852625

Epoch: 5| Step: 6
Training loss: 2.4723496088743144
Validation loss: 2.5123947439041547

Epoch: 5| Step: 7
Training loss: 2.960416803398013
Validation loss: 2.548923328309371

Epoch: 5| Step: 8
Training loss: 2.59793644591396
Validation loss: 2.5457664949694676

Epoch: 5| Step: 9
Training loss: 2.964547485506556
Validation loss: 2.5549068305973073

Epoch: 5| Step: 10
Training loss: 3.3493437280777076
Validation loss: 2.5398064201757045

Epoch: 311| Step: 0
Training loss: 2.4381365800673973
Validation loss: 2.5021818136114384

Epoch: 5| Step: 1
Training loss: 2.6146958974085863
Validation loss: 2.5192344664344093

Epoch: 5| Step: 2
Training loss: 2.1222548986030816
Validation loss: 2.5346712250485868

Epoch: 5| Step: 3
Training loss: 2.939777384264115
Validation loss: 2.580905715097066

Epoch: 5| Step: 4
Training loss: 2.3580454939383917
Validation loss: 2.560170407042529

Epoch: 5| Step: 5
Training loss: 3.029091135068937
Validation loss: 2.554260437978202

Epoch: 5| Step: 6
Training loss: 2.3260075713712576
Validation loss: 2.5571642673243873

Epoch: 5| Step: 7
Training loss: 2.624022801480431
Validation loss: 2.552099015315588

Epoch: 5| Step: 8
Training loss: 2.4004686931085435
Validation loss: 2.514005057518792

Epoch: 5| Step: 9
Training loss: 3.163038299946156
Validation loss: 2.5232811777814628

Epoch: 5| Step: 10
Training loss: 2.7530428784319034
Validation loss: 2.563944502741708

Epoch: 312| Step: 0
Training loss: 3.3738609087120723
Validation loss: 2.567077398124553

Epoch: 5| Step: 1
Training loss: 2.3804759091506535
Validation loss: 2.566794513745983

Epoch: 5| Step: 2
Training loss: 2.5814858465078236
Validation loss: 2.5217485535145743

Epoch: 5| Step: 3
Training loss: 2.105105791672837
Validation loss: 2.5587168133136364

Epoch: 5| Step: 4
Training loss: 2.7129199779617035
Validation loss: 2.5124885166595345

Epoch: 5| Step: 5
Training loss: 2.309405137460342
Validation loss: 2.5500703072873834

Epoch: 5| Step: 6
Training loss: 2.7462620907405793
Validation loss: 2.5577986594577937

Epoch: 5| Step: 7
Training loss: 2.8058227111808702
Validation loss: 2.557114747747854

Epoch: 5| Step: 8
Training loss: 2.649035450998758
Validation loss: 2.542190722323117

Epoch: 5| Step: 9
Training loss: 3.1254967866843533
Validation loss: 2.5208690152295126

Epoch: 5| Step: 10
Training loss: 1.9561512809439352
Validation loss: 2.5418209840704202

Epoch: 313| Step: 0
Training loss: 2.2376597342135387
Validation loss: 2.522838683393272

Epoch: 5| Step: 1
Training loss: 2.6416572494419204
Validation loss: 2.5096625242606616

Epoch: 5| Step: 2
Training loss: 2.283986684042199
Validation loss: 2.5588795697431883

Epoch: 5| Step: 3
Training loss: 2.8250113360422273
Validation loss: 2.5201007575527994

Epoch: 5| Step: 4
Training loss: 2.4325336823282884
Validation loss: 2.5493436075919926

Epoch: 5| Step: 5
Training loss: 3.571168358723808
Validation loss: 2.538749250678253

Epoch: 5| Step: 6
Training loss: 1.9961129801620783
Validation loss: 2.545890041379184

Epoch: 5| Step: 7
Training loss: 2.4030947124026016
Validation loss: 2.5776547775949257

Epoch: 5| Step: 8
Training loss: 2.9059543254121936
Validation loss: 2.537212515330284

Epoch: 5| Step: 9
Training loss: 2.9114820084721007
Validation loss: 2.5630612182722965

Epoch: 5| Step: 10
Training loss: 2.250153218456637
Validation loss: 2.520516973617901

Epoch: 314| Step: 0
Training loss: 2.7292788727580044
Validation loss: 2.525058547837429

Epoch: 5| Step: 1
Training loss: 2.645091145464776
Validation loss: 2.521435224299434

Epoch: 5| Step: 2
Training loss: 2.3230670030695912
Validation loss: 2.5287147433926016

Epoch: 5| Step: 3
Training loss: 2.631216952372354
Validation loss: 2.552810219536515

Epoch: 5| Step: 4
Training loss: 2.7895693705757516
Validation loss: 2.558321265094342

Epoch: 5| Step: 5
Training loss: 2.352858075609832
Validation loss: 2.5327442123621613

Epoch: 5| Step: 6
Training loss: 2.8235493944433356
Validation loss: 2.5452291320653573

Epoch: 5| Step: 7
Training loss: 2.6331350428935028
Validation loss: 2.531336442713817

Epoch: 5| Step: 8
Training loss: 2.5902128805213014
Validation loss: 2.528971674836545

Epoch: 5| Step: 9
Training loss: 2.4161449943574462
Validation loss: 2.532640832365153

Epoch: 5| Step: 10
Training loss: 2.9444674385020675
Validation loss: 2.518359609298372

Epoch: 315| Step: 0
Training loss: 2.5857289394393983
Validation loss: 2.5392598605381016

Epoch: 5| Step: 1
Training loss: 2.8866371483941755
Validation loss: 2.5405788712946134

Epoch: 5| Step: 2
Training loss: 2.323556603750492
Validation loss: 2.562014613087405

Epoch: 5| Step: 3
Training loss: 2.8062015792645396
Validation loss: 2.56852337988008

Epoch: 5| Step: 4
Training loss: 2.17604707090572
Validation loss: 2.56508477699585

Epoch: 5| Step: 5
Training loss: 2.19167757309592
Validation loss: 2.5619544512230403

Epoch: 5| Step: 6
Training loss: 2.3156125540662704
Validation loss: 2.5413389541012372

Epoch: 5| Step: 7
Training loss: 2.6990515385244285
Validation loss: 2.5197740999149447

Epoch: 5| Step: 8
Training loss: 2.6690617971058708
Validation loss: 2.5247176568573964

Epoch: 5| Step: 9
Training loss: 3.1584623533550364
Validation loss: 2.5041336233543476

Epoch: 5| Step: 10
Training loss: 2.9703372928200724
Validation loss: 2.5120987316784933

Epoch: 316| Step: 0
Training loss: 2.4201526054627274
Validation loss: 2.5531085926873778

Epoch: 5| Step: 1
Training loss: 2.4974379762999295
Validation loss: 2.5508099819603456

Epoch: 5| Step: 2
Training loss: 3.3246734344044335
Validation loss: 2.5147617912290845

Epoch: 5| Step: 3
Training loss: 2.6015463705393387
Validation loss: 2.529748860166399

Epoch: 5| Step: 4
Training loss: 3.091683362177131
Validation loss: 2.5143835252333444

Epoch: 5| Step: 5
Training loss: 2.4578837506248528
Validation loss: 2.555269546638071

Epoch: 5| Step: 6
Training loss: 2.6001057713341673
Validation loss: 2.5379273002756326

Epoch: 5| Step: 7
Training loss: 2.485089948933594
Validation loss: 2.550754425305274

Epoch: 5| Step: 8
Training loss: 2.6716181759906656
Validation loss: 2.554877137266175

Epoch: 5| Step: 9
Training loss: 2.565236375115807
Validation loss: 2.558646195710269

Epoch: 5| Step: 10
Training loss: 2.341559136343851
Validation loss: 2.5566876309185314

Epoch: 317| Step: 0
Training loss: 2.0243220807537514
Validation loss: 2.57713209157444

Epoch: 5| Step: 1
Training loss: 2.273174572189878
Validation loss: 2.5387134170047334

Epoch: 5| Step: 2
Training loss: 2.5362406382004883
Validation loss: 2.5693316929260956

Epoch: 5| Step: 3
Training loss: 3.3133637363822213
Validation loss: 2.5757816188930094

Epoch: 5| Step: 4
Training loss: 2.4539585519662035
Validation loss: 2.51956354241211

Epoch: 5| Step: 5
Training loss: 2.824221451416412
Validation loss: 2.57215971612708

Epoch: 5| Step: 6
Training loss: 2.2849221134058495
Validation loss: 2.5474798301057624

Epoch: 5| Step: 7
Training loss: 3.021918178750864
Validation loss: 2.5204520873276963

Epoch: 5| Step: 8
Training loss: 2.61101676779498
Validation loss: 2.546317997820586

Epoch: 5| Step: 9
Training loss: 2.8475065466694183
Validation loss: 2.5508916684882883

Epoch: 5| Step: 10
Training loss: 2.279192375396101
Validation loss: 2.555844744310621

Epoch: 318| Step: 0
Training loss: 2.317214181634515
Validation loss: 2.5321165834916406

Epoch: 5| Step: 1
Training loss: 2.2752911852936
Validation loss: 2.5695276185017164

Epoch: 5| Step: 2
Training loss: 2.0818299273121332
Validation loss: 2.512874539887519

Epoch: 5| Step: 3
Training loss: 2.232888107140891
Validation loss: 2.5732809619854673

Epoch: 5| Step: 4
Training loss: 2.6295117252057243
Validation loss: 2.550962053043992

Epoch: 5| Step: 5
Training loss: 2.894839951170964
Validation loss: 2.5765773270622767

Epoch: 5| Step: 6
Training loss: 2.7231265391165302
Validation loss: 2.5522906167535293

Epoch: 5| Step: 7
Training loss: 2.344505696854979
Validation loss: 2.5288752338187512

Epoch: 5| Step: 8
Training loss: 3.693620419367448
Validation loss: 2.5390152192742312

Epoch: 5| Step: 9
Training loss: 2.8992683474246426
Validation loss: 2.5015181884604174

Epoch: 5| Step: 10
Training loss: 2.385985816011693
Validation loss: 2.5486217482649236

Epoch: 319| Step: 0
Training loss: 2.925514932284324
Validation loss: 2.526005347070817

Epoch: 5| Step: 1
Training loss: 2.6700884997956007
Validation loss: 2.5934173043455395

Epoch: 5| Step: 2
Training loss: 3.041957701951397
Validation loss: 2.5673033292904446

Epoch: 5| Step: 3
Training loss: 2.6290619621244566
Validation loss: 2.5679795689518725

Epoch: 5| Step: 4
Training loss: 2.8614671067995694
Validation loss: 2.5353039933056243

Epoch: 5| Step: 5
Training loss: 2.0748000542697493
Validation loss: 2.536223041063221

Epoch: 5| Step: 6
Training loss: 1.5884708409597406
Validation loss: 2.5751125561583668

Epoch: 5| Step: 7
Training loss: 2.7940507833552815
Validation loss: 2.572098605471876

Epoch: 5| Step: 8
Training loss: 2.772163979864125
Validation loss: 2.5620466592127844

Epoch: 5| Step: 9
Training loss: 2.452875987249597
Validation loss: 2.561307673230074

Epoch: 5| Step: 10
Training loss: 2.6843815831202473
Validation loss: 2.524060593663179

Epoch: 320| Step: 0
Training loss: 3.0870856744550808
Validation loss: 2.5280966766229858

Epoch: 5| Step: 1
Training loss: 2.588586838837861
Validation loss: 2.55721500499778

Epoch: 5| Step: 2
Training loss: 2.2697908184113538
Validation loss: 2.5522217288401854

Epoch: 5| Step: 3
Training loss: 2.8490524322944446
Validation loss: 2.5085239095845524

Epoch: 5| Step: 4
Training loss: 2.5074224911516807
Validation loss: 2.512435514565038

Epoch: 5| Step: 5
Training loss: 2.5047094809364263
Validation loss: 2.539489977673787

Epoch: 5| Step: 6
Training loss: 2.4646173001354
Validation loss: 2.516153002841169

Epoch: 5| Step: 7
Training loss: 2.3436387099228684
Validation loss: 2.5535714890846157

Epoch: 5| Step: 8
Training loss: 3.03238648808333
Validation loss: 2.5493678325765337

Epoch: 5| Step: 9
Training loss: 2.133566922075359
Validation loss: 2.5506681180265565

Epoch: 5| Step: 10
Training loss: 2.7129085531940005
Validation loss: 2.5442214127892426

Epoch: 321| Step: 0
Training loss: 2.771067979863258
Validation loss: 2.540933236569893

Epoch: 5| Step: 1
Training loss: 2.9018237134520484
Validation loss: 2.5367842809711822

Epoch: 5| Step: 2
Training loss: 2.2666897080690194
Validation loss: 2.535489670423084

Epoch: 5| Step: 3
Training loss: 2.2580272744003858
Validation loss: 2.521723467464306

Epoch: 5| Step: 4
Training loss: 2.8709115522014894
Validation loss: 2.525016117927818

Epoch: 5| Step: 5
Training loss: 2.5129271073067287
Validation loss: 2.5252885205486786

Epoch: 5| Step: 6
Training loss: 2.382115396556642
Validation loss: 2.550513696975389

Epoch: 5| Step: 7
Training loss: 2.8026756785556692
Validation loss: 2.5112330612488227

Epoch: 5| Step: 8
Training loss: 1.6889583502603565
Validation loss: 2.521086355101565

Epoch: 5| Step: 9
Training loss: 3.3238764764853426
Validation loss: 2.502481708529219

Epoch: 5| Step: 10
Training loss: 2.6848237662844574
Validation loss: 2.5721314673432842

Epoch: 322| Step: 0
Training loss: 2.4493464629780584
Validation loss: 2.5257882985216145

Epoch: 5| Step: 1
Training loss: 2.372288209809852
Validation loss: 2.5214769453162273

Epoch: 5| Step: 2
Training loss: 2.7881329694478825
Validation loss: 2.5693713505828377

Epoch: 5| Step: 3
Training loss: 3.0973977826534997
Validation loss: 2.507183032881476

Epoch: 5| Step: 4
Training loss: 2.456689856362419
Validation loss: 2.5685440444387995

Epoch: 5| Step: 5
Training loss: 2.5462311474978145
Validation loss: 2.562683591111031

Epoch: 5| Step: 6
Training loss: 2.90720966860854
Validation loss: 2.5338989772543448

Epoch: 5| Step: 7
Training loss: 1.933406443145298
Validation loss: 2.573991501602185

Epoch: 5| Step: 8
Training loss: 2.5367883445373343
Validation loss: 2.56899276591037

Epoch: 5| Step: 9
Training loss: 3.049774980843153
Validation loss: 2.5294573335583075

Epoch: 5| Step: 10
Training loss: 2.842536919051261
Validation loss: 2.521578982978826

Epoch: 323| Step: 0
Training loss: 2.748864806563241
Validation loss: 2.5572890655569176

Epoch: 5| Step: 1
Training loss: 2.1522418377074906
Validation loss: 2.564832767070754

Epoch: 5| Step: 2
Training loss: 2.503939481089205
Validation loss: 2.5213537120613845

Epoch: 5| Step: 3
Training loss: 2.6078041510794026
Validation loss: 2.537307855401484

Epoch: 5| Step: 4
Training loss: 2.5541232824660036
Validation loss: 2.535900668083481

Epoch: 5| Step: 5
Training loss: 2.080116866203192
Validation loss: 2.5337981945593633

Epoch: 5| Step: 6
Training loss: 2.7485585336238243
Validation loss: 2.54599072251626

Epoch: 5| Step: 7
Training loss: 3.4117939480617467
Validation loss: 2.5367547969307944

Epoch: 5| Step: 8
Training loss: 2.6521821232625813
Validation loss: 2.54505422596163

Epoch: 5| Step: 9
Training loss: 2.3397775172569784
Validation loss: 2.519653763001941

Epoch: 5| Step: 10
Training loss: 2.8208462957613096
Validation loss: 2.5578636306897207

Epoch: 324| Step: 0
Training loss: 2.2908013415146677
Validation loss: 2.551166439196157

Epoch: 5| Step: 1
Training loss: 3.1090741035903617
Validation loss: 2.532979105480428

Epoch: 5| Step: 2
Training loss: 2.765831718693379
Validation loss: 2.517228223220797

Epoch: 5| Step: 3
Training loss: 2.918483949090039
Validation loss: 2.5453921194236475

Epoch: 5| Step: 4
Training loss: 2.516472999329371
Validation loss: 2.5452215576564283

Epoch: 5| Step: 5
Training loss: 2.5343992634280896
Validation loss: 2.5241401801636205

Epoch: 5| Step: 6
Training loss: 2.110888806846681
Validation loss: 2.522027760796209

Epoch: 5| Step: 7
Training loss: 2.4977319920104226
Validation loss: 2.524984255684463

Epoch: 5| Step: 8
Training loss: 2.8584850156110067
Validation loss: 2.505251143058628

Epoch: 5| Step: 9
Training loss: 2.0744252937198904
Validation loss: 2.5733920817220644

Epoch: 5| Step: 10
Training loss: 2.9556538083501005
Validation loss: 2.5362709732396187

Epoch: 325| Step: 0
Training loss: 2.5624702265800816
Validation loss: 2.53529555805454

Epoch: 5| Step: 1
Training loss: 2.8532980457987875
Validation loss: 2.550025753057683

Epoch: 5| Step: 2
Training loss: 2.7862996754383142
Validation loss: 2.501128298963375

Epoch: 5| Step: 3
Training loss: 2.0578132322363683
Validation loss: 2.582934626344553

Epoch: 5| Step: 4
Training loss: 2.3921111231097054
Validation loss: 2.5514373862559427

Epoch: 5| Step: 5
Training loss: 3.0238907348632162
Validation loss: 2.4931252934130175

Epoch: 5| Step: 6
Training loss: 2.7280837572613676
Validation loss: 2.540217163963981

Epoch: 5| Step: 7
Training loss: 2.8657003178573257
Validation loss: 2.540561781502864

Epoch: 5| Step: 8
Training loss: 2.52129138116348
Validation loss: 2.526783362599218

Epoch: 5| Step: 9
Training loss: 2.3947051888994486
Validation loss: 2.543529261402185

Epoch: 5| Step: 10
Training loss: 2.645443374451704
Validation loss: 2.5254868986130874

Epoch: 326| Step: 0
Training loss: 2.702805516761794
Validation loss: 2.5331502355097815

Epoch: 5| Step: 1
Training loss: 2.767510757218624
Validation loss: 2.5486544727700036

Epoch: 5| Step: 2
Training loss: 2.3100236572771666
Validation loss: 2.570540845562125

Epoch: 5| Step: 3
Training loss: 2.7888311722935386
Validation loss: 2.5842388073295446

Epoch: 5| Step: 4
Training loss: 2.1986387853379497
Validation loss: 2.503302922099415

Epoch: 5| Step: 5
Training loss: 2.5704925381296717
Validation loss: 2.5555254123512707

Epoch: 5| Step: 6
Training loss: 2.9507178128316363
Validation loss: 2.5655940345415416

Epoch: 5| Step: 7
Training loss: 2.2154146296350876
Validation loss: 2.545673966173081

Epoch: 5| Step: 8
Training loss: 2.756331783819999
Validation loss: 2.5379689456407073

Epoch: 5| Step: 9
Training loss: 2.992558150080999
Validation loss: 2.5380314012960654

Epoch: 5| Step: 10
Training loss: 2.334229319978976
Validation loss: 2.560109571972366

Epoch: 327| Step: 0
Training loss: 2.609322187608797
Validation loss: 2.5304834189246233

Epoch: 5| Step: 1
Training loss: 2.378621301983208
Validation loss: 2.5460855798260753

Epoch: 5| Step: 2
Training loss: 2.48494114213162
Validation loss: 2.5361736806892674

Epoch: 5| Step: 3
Training loss: 2.4023287640856266
Validation loss: 2.5295528878884297

Epoch: 5| Step: 4
Training loss: 2.882578274275344
Validation loss: 2.5478908803511655

Epoch: 5| Step: 5
Training loss: 2.2197319329427994
Validation loss: 2.5242807187230327

Epoch: 5| Step: 6
Training loss: 2.611363641102203
Validation loss: 2.521497545541285

Epoch: 5| Step: 7
Training loss: 2.7409371245060705
Validation loss: 2.530046260601631

Epoch: 5| Step: 8
Training loss: 2.7231863373298246
Validation loss: 2.5327000770736285

Epoch: 5| Step: 9
Training loss: 2.721174014515233
Validation loss: 2.5732923232373865

Epoch: 5| Step: 10
Training loss: 2.6364462026384565
Validation loss: 2.531187315235199

Epoch: 328| Step: 0
Training loss: 2.3608468624669454
Validation loss: 2.543677662289538

Epoch: 5| Step: 1
Training loss: 3.2701752277986285
Validation loss: 2.533264851116758

Epoch: 5| Step: 2
Training loss: 2.345106317350869
Validation loss: 2.535758800070063

Epoch: 5| Step: 3
Training loss: 2.5306985513442486
Validation loss: 2.5242508946566833

Epoch: 5| Step: 4
Training loss: 2.3187869416042086
Validation loss: 2.572477649905865

Epoch: 5| Step: 5
Training loss: 2.389771053409431
Validation loss: 2.529804983512473

Epoch: 5| Step: 6
Training loss: 3.048566769156992
Validation loss: 2.5383568032147314

Epoch: 5| Step: 7
Training loss: 2.310826701409111
Validation loss: 2.534139720898677

Epoch: 5| Step: 8
Training loss: 2.351702815840727
Validation loss: 2.5599845076628642

Epoch: 5| Step: 9
Training loss: 2.705277484474628
Validation loss: 2.5526715715517962

Epoch: 5| Step: 10
Training loss: 2.6290142609625535
Validation loss: 2.5294312587470418

Epoch: 329| Step: 0
Training loss: 2.5471588163851644
Validation loss: 2.51194220799715

Epoch: 5| Step: 1
Training loss: 2.4569367358734477
Validation loss: 2.5648033190953754

Epoch: 5| Step: 2
Training loss: 2.8516298887050127
Validation loss: 2.5157212386935224

Epoch: 5| Step: 3
Training loss: 2.952335635656354
Validation loss: 2.539273531515593

Epoch: 5| Step: 4
Training loss: 2.0152608853079172
Validation loss: 2.531307299314958

Epoch: 5| Step: 5
Training loss: 2.394767015310088
Validation loss: 2.5694422910223618

Epoch: 5| Step: 6
Training loss: 2.712507249673042
Validation loss: 2.5723490400054927

Epoch: 5| Step: 7
Training loss: 2.624997093562379
Validation loss: 2.5242826331142214

Epoch: 5| Step: 8
Training loss: 2.5215160506760887
Validation loss: 2.5194279556614307

Epoch: 5| Step: 9
Training loss: 2.6416750293041757
Validation loss: 2.5560623217186893

Epoch: 5| Step: 10
Training loss: 2.1413827933105685
Validation loss: 2.50705662393243

Epoch: 330| Step: 0
Training loss: 2.3976583302458696
Validation loss: 2.534841158684539

Epoch: 5| Step: 1
Training loss: 2.2167338492554896
Validation loss: 2.569188064245754

Epoch: 5| Step: 2
Training loss: 2.1797101419564937
Validation loss: 2.537864237984746

Epoch: 5| Step: 3
Training loss: 2.712532299921772
Validation loss: 2.547903505885187

Epoch: 5| Step: 4
Training loss: 2.3914230111801844
Validation loss: 2.540318677967262

Epoch: 5| Step: 5
Training loss: 2.6373832712964482
Validation loss: 2.542717659034698

Epoch: 5| Step: 6
Training loss: 2.9632985708674346
Validation loss: 2.542297015471517

Epoch: 5| Step: 7
Training loss: 2.300685705717254
Validation loss: 2.5084356362412144

Epoch: 5| Step: 8
Training loss: 2.4302603975341817
Validation loss: 2.547682600319708

Epoch: 5| Step: 9
Training loss: 2.5537677007314734
Validation loss: 2.5320890259799524

Epoch: 5| Step: 10
Training loss: 3.4944338816725877
Validation loss: 2.551702652231228

Epoch: 331| Step: 0
Training loss: 2.6153665613181327
Validation loss: 2.513674695983156

Epoch: 5| Step: 1
Training loss: 2.3851872851654523
Validation loss: 2.544630997618549

Epoch: 5| Step: 2
Training loss: 2.282275975108268
Validation loss: 2.552878892233015

Epoch: 5| Step: 3
Training loss: 2.8926791753639867
Validation loss: 2.5647892624319333

Epoch: 5| Step: 4
Training loss: 2.213243447952802
Validation loss: 2.5903801770271833

Epoch: 5| Step: 5
Training loss: 3.366844354479072
Validation loss: 2.5590296991602015

Epoch: 5| Step: 6
Training loss: 2.7774275325794675
Validation loss: 2.518548527152489

Epoch: 5| Step: 7
Training loss: 1.7985619628684868
Validation loss: 2.529610088829287

Epoch: 5| Step: 8
Training loss: 2.4890260165714286
Validation loss: 2.516189105331948

Epoch: 5| Step: 9
Training loss: 2.7408874560036702
Validation loss: 2.5632277364996567

Epoch: 5| Step: 10
Training loss: 2.428589993093363
Validation loss: 2.53780332682338

Epoch: 332| Step: 0
Training loss: 2.303443391859929
Validation loss: 2.5243547177723262

Epoch: 5| Step: 1
Training loss: 2.5795896126875015
Validation loss: 2.530543072772232

Epoch: 5| Step: 2
Training loss: 2.173779866658859
Validation loss: 2.5434322696819978

Epoch: 5| Step: 3
Training loss: 2.631017418229932
Validation loss: 2.550557520998592

Epoch: 5| Step: 4
Training loss: 2.87990847654087
Validation loss: 2.5493011489551347

Epoch: 5| Step: 5
Training loss: 2.687415986633104
Validation loss: 2.551270040205967

Epoch: 5| Step: 6
Training loss: 2.9542047050692215
Validation loss: 2.525344685157108

Epoch: 5| Step: 7
Training loss: 2.541594290614837
Validation loss: 2.554419837254506

Epoch: 5| Step: 8
Training loss: 3.0990207355958947
Validation loss: 2.548005204151627

Epoch: 5| Step: 9
Training loss: 1.9692107978338789
Validation loss: 2.513421663841953

Epoch: 5| Step: 10
Training loss: 2.786299076461023
Validation loss: 2.572694739394522

Epoch: 333| Step: 0
Training loss: 2.7670237996270717
Validation loss: 2.527387470638684

Epoch: 5| Step: 1
Training loss: 1.9425856387040805
Validation loss: 2.477563529110612

Epoch: 5| Step: 2
Training loss: 2.4373948490252726
Validation loss: 2.5629176638077977

Epoch: 5| Step: 3
Training loss: 2.255014236472922
Validation loss: 2.532339614309822

Epoch: 5| Step: 4
Training loss: 2.4593945707247746
Validation loss: 2.5532612452754915

Epoch: 5| Step: 5
Training loss: 2.6104767808946487
Validation loss: 2.574651390329791

Epoch: 5| Step: 6
Training loss: 2.37370154373023
Validation loss: 2.537962532412134

Epoch: 5| Step: 7
Training loss: 3.1102002452890227
Validation loss: 2.4971206408884843

Epoch: 5| Step: 8
Training loss: 2.5390817494763107
Validation loss: 2.5651281112187125

Epoch: 5| Step: 9
Training loss: 2.8713073235827546
Validation loss: 2.5301878653024485

Epoch: 5| Step: 10
Training loss: 3.080905800681569
Validation loss: 2.5275413744157023

Epoch: 334| Step: 0
Training loss: 2.736783258678054
Validation loss: 2.5208881829509235

Epoch: 5| Step: 1
Training loss: 2.64558937169522
Validation loss: 2.5720639595417123

Epoch: 5| Step: 2
Training loss: 2.1707567588299383
Validation loss: 2.49903391455537

Epoch: 5| Step: 3
Training loss: 1.971656833193139
Validation loss: 2.5296060289337823

Epoch: 5| Step: 4
Training loss: 2.72883139921815
Validation loss: 2.5260365195053294

Epoch: 5| Step: 5
Training loss: 2.103601423831972
Validation loss: 2.5520818560062137

Epoch: 5| Step: 6
Training loss: 3.141585170049711
Validation loss: 2.558295373239852

Epoch: 5| Step: 7
Training loss: 2.797407302070612
Validation loss: 2.5103827414511453

Epoch: 5| Step: 8
Training loss: 2.8163523252195004
Validation loss: 2.5535023601365605

Epoch: 5| Step: 9
Training loss: 3.318516144352712
Validation loss: 2.5503058673746013

Epoch: 5| Step: 10
Training loss: 1.6429948674990729
Validation loss: 2.530144103889276

Epoch: 335| Step: 0
Training loss: 2.6176908549888926
Validation loss: 2.527551883373409

Epoch: 5| Step: 1
Training loss: 3.191830853122748
Validation loss: 2.5238260122284704

Epoch: 5| Step: 2
Training loss: 2.442481989564743
Validation loss: 2.5391986123227293

Epoch: 5| Step: 3
Training loss: 2.5754561048087443
Validation loss: 2.5232208503351776

Epoch: 5| Step: 4
Training loss: 2.6326748503519726
Validation loss: 2.5233116645542037

Epoch: 5| Step: 5
Training loss: 2.7325602585691366
Validation loss: 2.5346710065798574

Epoch: 5| Step: 6
Training loss: 2.976598383970052
Validation loss: 2.535566070725273

Epoch: 5| Step: 7
Training loss: 2.538686871253215
Validation loss: 2.5516484090658063

Epoch: 5| Step: 8
Training loss: 2.3387606602501756
Validation loss: 2.551046812323078

Epoch: 5| Step: 9
Training loss: 1.8367812145649882
Validation loss: 2.5787415126225253

Epoch: 5| Step: 10
Training loss: 2.5077468055367813
Validation loss: 2.467201807706065

Epoch: 336| Step: 0
Training loss: 2.724106871504033
Validation loss: 2.5282892437651023

Epoch: 5| Step: 1
Training loss: 2.6914117422726074
Validation loss: 2.5562173683596363

Epoch: 5| Step: 2
Training loss: 2.599266253152811
Validation loss: 2.5192740446846065

Epoch: 5| Step: 3
Training loss: 1.982748611659419
Validation loss: 2.5399586206685694

Epoch: 5| Step: 4
Training loss: 2.3758712977285534
Validation loss: 2.5377321292798256

Epoch: 5| Step: 5
Training loss: 2.5453689896770606
Validation loss: 2.5142150083562296

Epoch: 5| Step: 6
Training loss: 2.754902198287872
Validation loss: 2.517661222721182

Epoch: 5| Step: 7
Training loss: 3.184701176972321
Validation loss: 2.4983354585057573

Epoch: 5| Step: 8
Training loss: 2.793454428106308
Validation loss: 2.545080536578744

Epoch: 5| Step: 9
Training loss: 2.699324565751049
Validation loss: 2.521240096469153

Epoch: 5| Step: 10
Training loss: 2.441900047718599
Validation loss: 2.5425083935881863

Epoch: 337| Step: 0
Training loss: 3.2352868605343623
Validation loss: 2.5663701347062142

Epoch: 5| Step: 1
Training loss: 2.345619981548451
Validation loss: 2.5240320691140408

Epoch: 5| Step: 2
Training loss: 2.747650096149945
Validation loss: 2.5124895645681584

Epoch: 5| Step: 3
Training loss: 2.5702200180158745
Validation loss: 2.5222724544728696

Epoch: 5| Step: 4
Training loss: 2.500178044654893
Validation loss: 2.527187174368127

Epoch: 5| Step: 5
Training loss: 2.433583169243652
Validation loss: 2.5103927942719637

Epoch: 5| Step: 6
Training loss: 2.7890625
Validation loss: 2.5515792174668555

Epoch: 5| Step: 7
Training loss: 2.4864104947262655
Validation loss: 2.561220394318886

Epoch: 5| Step: 8
Training loss: 2.115903570635262
Validation loss: 2.5304658237950926

Epoch: 5| Step: 9
Training loss: 2.853325118769054
Validation loss: 2.531233955230157

Epoch: 5| Step: 10
Training loss: 2.185305993763105
Validation loss: 2.5270531359161605

Epoch: 338| Step: 0
Training loss: 3.1853920941666036
Validation loss: 2.518183699201403

Epoch: 5| Step: 1
Training loss: 2.8062112648378474
Validation loss: 2.5420601000825735

Epoch: 5| Step: 2
Training loss: 2.0881282432094803
Validation loss: 2.5449517227636314

Epoch: 5| Step: 3
Training loss: 2.8064363175627043
Validation loss: 2.5400125533121476

Epoch: 5| Step: 4
Training loss: 2.448519909706674
Validation loss: 2.524417151259621

Epoch: 5| Step: 5
Training loss: 2.4612633867805465
Validation loss: 2.5227598037608336

Epoch: 5| Step: 6
Training loss: 2.193805543897365
Validation loss: 2.5113949495613417

Epoch: 5| Step: 7
Training loss: 3.1421784312128267
Validation loss: 2.5555822997977287

Epoch: 5| Step: 8
Training loss: 2.297110616834575
Validation loss: 2.582074634409118

Epoch: 5| Step: 9
Training loss: 2.143737201263213
Validation loss: 2.5510157545644554

Epoch: 5| Step: 10
Training loss: 2.369278994149469
Validation loss: 2.5503859255468737

Epoch: 339| Step: 0
Training loss: 2.571689688957967
Validation loss: 2.566435060757525

Epoch: 5| Step: 1
Training loss: 2.6770765747301652
Validation loss: 2.5717770751026423

Epoch: 5| Step: 2
Training loss: 2.6775237041603073
Validation loss: 2.5213050814443485

Epoch: 5| Step: 3
Training loss: 2.5380822739789353
Validation loss: 2.4955788609817695

Epoch: 5| Step: 4
Training loss: 2.6282413996662166
Validation loss: 2.53637172438835

Epoch: 5| Step: 5
Training loss: 2.0960176628256733
Validation loss: 2.541960235484774

Epoch: 5| Step: 6
Training loss: 2.0869757536506466
Validation loss: 2.572335934489985

Epoch: 5| Step: 7
Training loss: 3.380124475568454
Validation loss: 2.5722662269746746

Epoch: 5| Step: 8
Training loss: 2.221307704092291
Validation loss: 2.5190991672761753

Epoch: 5| Step: 9
Training loss: 2.570935020311114
Validation loss: 2.563914476124907

Epoch: 5| Step: 10
Training loss: 2.7285282077376296
Validation loss: 2.5360803166832464

Epoch: 340| Step: 0
Training loss: 2.87466992681079
Validation loss: 2.5316494356010093

Epoch: 5| Step: 1
Training loss: 2.004232815016342
Validation loss: 2.55235666833311

Epoch: 5| Step: 2
Training loss: 2.6030723612249886
Validation loss: 2.553051824843113

Epoch: 5| Step: 3
Training loss: 2.753507284930269
Validation loss: 2.5345757190416087

Epoch: 5| Step: 4
Training loss: 2.643892332173066
Validation loss: 2.518985127375987

Epoch: 5| Step: 5
Training loss: 2.7238805308758267
Validation loss: 2.5119484866039703

Epoch: 5| Step: 6
Training loss: 2.372556734682977
Validation loss: 2.535136965660874

Epoch: 5| Step: 7
Training loss: 3.048712699508681
Validation loss: 2.5237701998263686

Epoch: 5| Step: 8
Training loss: 2.9436088511973963
Validation loss: 2.501414593030426

Epoch: 5| Step: 9
Training loss: 2.280765638795202
Validation loss: 2.5203268453712355

Epoch: 5| Step: 10
Training loss: 2.2333324641135883
Validation loss: 2.506256740322567

Epoch: 341| Step: 0
Training loss: 2.5526167850510704
Validation loss: 2.5655114911077197

Epoch: 5| Step: 1
Training loss: 2.777953004608427
Validation loss: 2.536305881687739

Epoch: 5| Step: 2
Training loss: 3.1324318062315286
Validation loss: 2.588072315910916

Epoch: 5| Step: 3
Training loss: 2.541457422950878
Validation loss: 2.565519007611418

Epoch: 5| Step: 4
Training loss: 2.8794171774085076
Validation loss: 2.5286170962317516

Epoch: 5| Step: 5
Training loss: 3.138719122767824
Validation loss: 2.5521275717186955

Epoch: 5| Step: 6
Training loss: 2.1546114901938904
Validation loss: 2.552268298345985

Epoch: 5| Step: 7
Training loss: 2.239952329060242
Validation loss: 2.5436334990113565

Epoch: 5| Step: 8
Training loss: 2.2234777665395935
Validation loss: 2.5450282852601496

Epoch: 5| Step: 9
Training loss: 2.0368037666630583
Validation loss: 2.543393917073672

Epoch: 5| Step: 10
Training loss: 2.4338735355319696
Validation loss: 2.616682966563106

Epoch: 342| Step: 0
Training loss: 2.7684244761045984
Validation loss: 2.558042712985674

Epoch: 5| Step: 1
Training loss: 2.1354974746921394
Validation loss: 2.498906098249756

Epoch: 5| Step: 2
Training loss: 3.2431612689595766
Validation loss: 2.5506926681373163

Epoch: 5| Step: 3
Training loss: 2.1221390707337413
Validation loss: 2.53869468403879

Epoch: 5| Step: 4
Training loss: 2.4621293345675284
Validation loss: 2.5570715774921204

Epoch: 5| Step: 5
Training loss: 2.354142000412352
Validation loss: 2.563498923833602

Epoch: 5| Step: 6
Training loss: 2.781054972122106
Validation loss: 2.5600270169348898

Epoch: 5| Step: 7
Training loss: 2.55705538795703
Validation loss: 2.5292441470893565

Epoch: 5| Step: 8
Training loss: 2.633512047445488
Validation loss: 2.5543119419104428

Epoch: 5| Step: 9
Training loss: 2.129454935743947
Validation loss: 2.5593827448349136

Epoch: 5| Step: 10
Training loss: 3.16337129554708
Validation loss: 2.4892409017878956

Epoch: 343| Step: 0
Training loss: 2.5825994330999427
Validation loss: 2.499650137016233

Epoch: 5| Step: 1
Training loss: 2.3921449105565924
Validation loss: 2.5473451173574317

Epoch: 5| Step: 2
Training loss: 1.9825538027607383
Validation loss: 2.517079065515295

Epoch: 5| Step: 3
Training loss: 2.638810386382383
Validation loss: 2.5114814866831017

Epoch: 5| Step: 4
Training loss: 2.5327035945232876
Validation loss: 2.549119481880442

Epoch: 5| Step: 5
Training loss: 3.3196360179432287
Validation loss: 2.552342159430536

Epoch: 5| Step: 6
Training loss: 2.8654259199671914
Validation loss: 2.537865937067794

Epoch: 5| Step: 7
Training loss: 2.4864674519399776
Validation loss: 2.5530611864931947

Epoch: 5| Step: 8
Training loss: 2.442607712181371
Validation loss: 2.5294580683559125

Epoch: 5| Step: 9
Training loss: 2.4700144173514107
Validation loss: 2.5405209314297323

Epoch: 5| Step: 10
Training loss: 2.5559274073517058
Validation loss: 2.5361114865845678

Epoch: 344| Step: 0
Training loss: 2.784709193663483
Validation loss: 2.5214210021191463

Epoch: 5| Step: 1
Training loss: 2.9733521778495984
Validation loss: 2.5394419507888784

Epoch: 5| Step: 2
Training loss: 2.5378540919502854
Validation loss: 2.5141299730097013

Epoch: 5| Step: 3
Training loss: 2.433431702633011
Validation loss: 2.5213854859710447

Epoch: 5| Step: 4
Training loss: 2.751979722164543
Validation loss: 2.5655814011365994

Epoch: 5| Step: 5
Training loss: 2.7893822751130917
Validation loss: 2.549014440747118

Epoch: 5| Step: 6
Training loss: 2.3500044721195605
Validation loss: 2.5179420011633797

Epoch: 5| Step: 7
Training loss: 2.096300990849902
Validation loss: 2.563070940451205

Epoch: 5| Step: 8
Training loss: 2.856520765563282
Validation loss: 2.5067863911826405

Epoch: 5| Step: 9
Training loss: 2.5630971631443287
Validation loss: 2.539152037853709

Epoch: 5| Step: 10
Training loss: 2.3265317034812716
Validation loss: 2.5551172227275223

Epoch: 345| Step: 0
Training loss: 2.3425023127557663
Validation loss: 2.5207883735402756

Epoch: 5| Step: 1
Training loss: 3.5742686450581607
Validation loss: 2.5291003872256526

Epoch: 5| Step: 2
Training loss: 2.378678133946876
Validation loss: 2.5571583062583816

Epoch: 5| Step: 3
Training loss: 2.2775958332287614
Validation loss: 2.5294461352163915

Epoch: 5| Step: 4
Training loss: 2.7909732545769175
Validation loss: 2.569330956560657

Epoch: 5| Step: 5
Training loss: 2.4205644568749816
Validation loss: 2.5862441902644746

Epoch: 5| Step: 6
Training loss: 2.504648845371951
Validation loss: 2.5297566491259675

Epoch: 5| Step: 7
Training loss: 2.4023349172538335
Validation loss: 2.5686953435882076

Epoch: 5| Step: 8
Training loss: 2.3390705442322117
Validation loss: 2.4934878821142146

Epoch: 5| Step: 9
Training loss: 2.5490135154680083
Validation loss: 2.5145603373572403

Epoch: 5| Step: 10
Training loss: 2.6290613273238015
Validation loss: 2.528862987720784

Epoch: 346| Step: 0
Training loss: 2.4083399428262617
Validation loss: 2.519507881826309

Epoch: 5| Step: 1
Training loss: 2.657506578209416
Validation loss: 2.5243041539196183

Epoch: 5| Step: 2
Training loss: 3.0252894365542544
Validation loss: 2.54526444090251

Epoch: 5| Step: 3
Training loss: 2.4451461589165495
Validation loss: 2.5527819775692806

Epoch: 5| Step: 4
Training loss: 1.730952554758845
Validation loss: 2.5433246450520803

Epoch: 5| Step: 5
Training loss: 2.7200991911192482
Validation loss: 2.5123966326587164

Epoch: 5| Step: 6
Training loss: 2.2678655660706704
Validation loss: 2.5293206716813206

Epoch: 5| Step: 7
Training loss: 2.4750691914760674
Validation loss: 2.495018070283825

Epoch: 5| Step: 8
Training loss: 2.799836705759544
Validation loss: 2.508399735918432

Epoch: 5| Step: 9
Training loss: 2.7474781090347644
Validation loss: 2.56150319370161

Epoch: 5| Step: 10
Training loss: 2.877846676833449
Validation loss: 2.5205125517324083

Epoch: 347| Step: 0
Training loss: 3.0708835061131308
Validation loss: 2.5226730254913785

Epoch: 5| Step: 1
Training loss: 2.8166958346540145
Validation loss: 2.5414706564261396

Epoch: 5| Step: 2
Training loss: 2.8008134273452354
Validation loss: 2.535596778827415

Epoch: 5| Step: 3
Training loss: 2.458687277276516
Validation loss: 2.543979291319137

Epoch: 5| Step: 4
Training loss: 2.6920129897667198
Validation loss: 2.5549696538536724

Epoch: 5| Step: 5
Training loss: 2.2159464141619063
Validation loss: 2.5642028970922994

Epoch: 5| Step: 6
Training loss: 2.3263166944647833
Validation loss: 2.5287744805286065

Epoch: 5| Step: 7
Training loss: 2.7717862223586573
Validation loss: 2.52026763276546

Epoch: 5| Step: 8
Training loss: 2.707638362825659
Validation loss: 2.5550514471978456

Epoch: 5| Step: 9
Training loss: 2.1815223764255123
Validation loss: 2.573702637635075

Epoch: 5| Step: 10
Training loss: 2.299752541374049
Validation loss: 2.505948524774583

Epoch: 348| Step: 0
Training loss: 2.6905576478190896
Validation loss: 2.5267195077677576

Epoch: 5| Step: 1
Training loss: 2.313508921985064
Validation loss: 2.5541359374154653

Epoch: 5| Step: 2
Training loss: 1.7979909997148322
Validation loss: 2.5572534440550805

Epoch: 5| Step: 3
Training loss: 3.389819071394813
Validation loss: 2.5580332633341585

Epoch: 5| Step: 4
Training loss: 2.7501101038305573
Validation loss: 2.5669497340895653

Epoch: 5| Step: 5
Training loss: 2.6430209874948276
Validation loss: 2.552874177938846

Epoch: 5| Step: 6
Training loss: 2.6923061245085793
Validation loss: 2.510171928282882

Epoch: 5| Step: 7
Training loss: 2.3862897671582632
Validation loss: 2.5583575511284615

Epoch: 5| Step: 8
Training loss: 2.8638384226181928
Validation loss: 2.5087248176134747

Epoch: 5| Step: 9
Training loss: 2.718178875446901
Validation loss: 2.517291899226929

Epoch: 5| Step: 10
Training loss: 1.7818322819433208
Validation loss: 2.5337136950374997

Epoch: 349| Step: 0
Training loss: 2.505708090778702
Validation loss: 2.5340000528741102

Epoch: 5| Step: 1
Training loss: 1.674861201898169
Validation loss: 2.529150974292372

Epoch: 5| Step: 2
Training loss: 2.1244876468305587
Validation loss: 2.5158045169728473

Epoch: 5| Step: 3
Training loss: 2.7438393858511287
Validation loss: 2.5680710674588307

Epoch: 5| Step: 4
Training loss: 2.383253213118181
Validation loss: 2.553065794505067

Epoch: 5| Step: 5
Training loss: 3.0543985449670092
Validation loss: 2.519944905382623

Epoch: 5| Step: 6
Training loss: 2.6080459590794045
Validation loss: 2.550070269085164

Epoch: 5| Step: 7
Training loss: 2.6429079559036683
Validation loss: 2.5646349529255055

Epoch: 5| Step: 8
Training loss: 3.0229323011888307
Validation loss: 2.5632392323253956

Epoch: 5| Step: 9
Training loss: 2.9101369153090935
Validation loss: 2.5685645441475775

Epoch: 5| Step: 10
Training loss: 2.426550603421065
Validation loss: 2.548769020819456

Epoch: 350| Step: 0
Training loss: 2.9829964374721736
Validation loss: 2.526029059062856

Epoch: 5| Step: 1
Training loss: 2.5160985465407633
Validation loss: 2.5447499942279315

Epoch: 5| Step: 2
Training loss: 2.3929538727589588
Validation loss: 2.479179379878784

Epoch: 5| Step: 3
Training loss: 2.724712542149614
Validation loss: 2.5824450154088536

Epoch: 5| Step: 4
Training loss: 2.809104565258675
Validation loss: 2.513588911590562

Epoch: 5| Step: 5
Training loss: 2.063038842298308
Validation loss: 2.565023572742632

Epoch: 5| Step: 6
Training loss: 2.0495245870737975
Validation loss: 2.5880607768530024

Epoch: 5| Step: 7
Training loss: 2.300659176449045
Validation loss: 2.530591282727548

Epoch: 5| Step: 8
Training loss: 2.702974436541335
Validation loss: 2.5407102447256142

Epoch: 5| Step: 9
Training loss: 3.033304835454637
Validation loss: 2.544802843109567

Epoch: 5| Step: 10
Training loss: 2.41750497637989
Validation loss: 2.535372224577103

Epoch: 351| Step: 0
Training loss: 2.522295619673412
Validation loss: 2.554582137873246

Epoch: 5| Step: 1
Training loss: 2.7142832225415257
Validation loss: 2.5080018320735213

Epoch: 5| Step: 2
Training loss: 2.4029841864196912
Validation loss: 2.5411921235850428

Epoch: 5| Step: 3
Training loss: 2.2802675822997633
Validation loss: 2.5230495660497985

Epoch: 5| Step: 4
Training loss: 2.9679776441858046
Validation loss: 2.5306247114584246

Epoch: 5| Step: 5
Training loss: 2.5157121915693272
Validation loss: 2.5423487012611408

Epoch: 5| Step: 6
Training loss: 2.1251199351853343
Validation loss: 2.507677097273145

Epoch: 5| Step: 7
Training loss: 2.8927657165074026
Validation loss: 2.551886092887572

Epoch: 5| Step: 8
Training loss: 2.469455666427755
Validation loss: 2.5787813456802957

Epoch: 5| Step: 9
Training loss: 2.6214852189966606
Validation loss: 2.533197961692043

Epoch: 5| Step: 10
Training loss: 2.60205394238584
Validation loss: 2.501464827864736

Epoch: 352| Step: 0
Training loss: 2.5609724562600067
Validation loss: 2.518431874687675

Epoch: 5| Step: 1
Training loss: 2.2589019997841664
Validation loss: 2.5269130975057648

Epoch: 5| Step: 2
Training loss: 2.5175726323034535
Validation loss: 2.56204547247464

Epoch: 5| Step: 3
Training loss: 2.895525104027205
Validation loss: 2.507253897513621

Epoch: 5| Step: 4
Training loss: 2.822982580862919
Validation loss: 2.54414379164473

Epoch: 5| Step: 5
Training loss: 2.681916758190636
Validation loss: 2.4966160863216613

Epoch: 5| Step: 6
Training loss: 1.684641784036369
Validation loss: 2.537950166522285

Epoch: 5| Step: 7
Training loss: 2.20088763970083
Validation loss: 2.5557230704195577

Epoch: 5| Step: 8
Training loss: 2.9172674559396956
Validation loss: 2.526431716897816

Epoch: 5| Step: 9
Training loss: 2.7862195824750744
Validation loss: 2.5227757804821938

Epoch: 5| Step: 10
Training loss: 2.918825077504448
Validation loss: 2.5375973233683697

Epoch: 353| Step: 0
Training loss: 2.7194273532394866
Validation loss: 2.504055613918973

Epoch: 5| Step: 1
Training loss: 2.0707614627803186
Validation loss: 2.5281275586045915

Epoch: 5| Step: 2
Training loss: 2.422499348548825
Validation loss: 2.5639348778644733

Epoch: 5| Step: 3
Training loss: 2.6683002673675045
Validation loss: 2.5457507239628043

Epoch: 5| Step: 4
Training loss: 2.7531815244866986
Validation loss: 2.507115562123408

Epoch: 5| Step: 5
Training loss: 2.1228342800856566
Validation loss: 2.5409033052793184

Epoch: 5| Step: 6
Training loss: 2.672689391830835
Validation loss: 2.491491451420861

Epoch: 5| Step: 7
Training loss: 2.3265226853898384
Validation loss: 2.4918676955449004

Epoch: 5| Step: 8
Training loss: 2.852143863307809
Validation loss: 2.5518578190935535

Epoch: 5| Step: 9
Training loss: 2.6580471466739732
Validation loss: 2.5263059433231976

Epoch: 5| Step: 10
Training loss: 2.673065901703483
Validation loss: 2.5060632847621567

Epoch: 354| Step: 0
Training loss: 2.654708594585848
Validation loss: 2.572736980362541

Epoch: 5| Step: 1
Training loss: 2.635626491793164
Validation loss: 2.5509623675996194

Epoch: 5| Step: 2
Training loss: 2.203769887054429
Validation loss: 2.540688832111843

Epoch: 5| Step: 3
Training loss: 3.0237056012026273
Validation loss: 2.518095369469955

Epoch: 5| Step: 4
Training loss: 2.7410543768748665
Validation loss: 2.4951197294422114

Epoch: 5| Step: 5
Training loss: 2.5841919692333417
Validation loss: 2.5476272169737073

Epoch: 5| Step: 6
Training loss: 2.3392207824115205
Validation loss: 2.5287368301982083

Epoch: 5| Step: 7
Training loss: 2.149932008599705
Validation loss: 2.5542439445768426

Epoch: 5| Step: 8
Training loss: 2.750032598128881
Validation loss: 2.5347622490130806

Epoch: 5| Step: 9
Training loss: 2.775530130422441
Validation loss: 2.5439146890506095

Epoch: 5| Step: 10
Training loss: 1.8945608864265406
Validation loss: 2.5473770028359084

Epoch: 355| Step: 0
Training loss: 2.873107785033723
Validation loss: 2.545604926394481

Epoch: 5| Step: 1
Training loss: 2.170952800116403
Validation loss: 2.550182772139895

Epoch: 5| Step: 2
Training loss: 2.9114916713673433
Validation loss: 2.554433879723427

Epoch: 5| Step: 3
Training loss: 2.260953203738602
Validation loss: 2.573536440054759

Epoch: 5| Step: 4
Training loss: 2.415974375342589
Validation loss: 2.5302799502588793

Epoch: 5| Step: 5
Training loss: 2.2985610482666416
Validation loss: 2.5298437701358543

Epoch: 5| Step: 6
Training loss: 2.8483778637090573
Validation loss: 2.5638073523294316

Epoch: 5| Step: 7
Training loss: 3.279350675649348
Validation loss: 2.5110183959363663

Epoch: 5| Step: 8
Training loss: 2.1103416206093906
Validation loss: 2.55941341759509

Epoch: 5| Step: 9
Training loss: 2.341532357415279
Validation loss: 2.543044406942472

Epoch: 5| Step: 10
Training loss: 2.207374748573438
Validation loss: 2.516594204480496

Epoch: 356| Step: 0
Training loss: 2.3498423422015198
Validation loss: 2.51733110269707

Epoch: 5| Step: 1
Training loss: 2.5577629778990154
Validation loss: 2.5257249727296545

Epoch: 5| Step: 2
Training loss: 3.1699564726816503
Validation loss: 2.553996395265193

Epoch: 5| Step: 3
Training loss: 2.58942447910643
Validation loss: 2.587741169374159

Epoch: 5| Step: 4
Training loss: 2.5789088126987134
Validation loss: 2.5098033627832677

Epoch: 5| Step: 5
Training loss: 2.5995690208644744
Validation loss: 2.5276790949941805

Epoch: 5| Step: 6
Training loss: 2.3607569809171842
Validation loss: 2.578450872137197

Epoch: 5| Step: 7
Training loss: 2.409555517972029
Validation loss: 2.5153143865570895

Epoch: 5| Step: 8
Training loss: 2.018167238003163
Validation loss: 2.571480277892276

Epoch: 5| Step: 9
Training loss: 2.8782671732791534
Validation loss: 2.5858614562508255

Epoch: 5| Step: 10
Training loss: 2.401135247669339
Validation loss: 2.5485332955456856

Epoch: 357| Step: 0
Training loss: 1.806283880529793
Validation loss: 2.537037914454848

Epoch: 5| Step: 1
Training loss: 2.624786549927103
Validation loss: 2.5251030045127187

Epoch: 5| Step: 2
Training loss: 2.8315661660138987
Validation loss: 2.530428061351779

Epoch: 5| Step: 3
Training loss: 2.4369752759278045
Validation loss: 2.5338136296878107

Epoch: 5| Step: 4
Training loss: 2.7086142663258452
Validation loss: 2.5363422997355882

Epoch: 5| Step: 5
Training loss: 2.6801173807885146
Validation loss: 2.5280336875279246

Epoch: 5| Step: 6
Training loss: 2.520531649441721
Validation loss: 2.5388279697841196

Epoch: 5| Step: 7
Training loss: 3.0484882485424585
Validation loss: 2.5343807805421545

Epoch: 5| Step: 8
Training loss: 2.627969243245595
Validation loss: 2.5238012769580003

Epoch: 5| Step: 9
Training loss: 1.8979016085326383
Validation loss: 2.488654842706621

Epoch: 5| Step: 10
Training loss: 2.7737863240693645
Validation loss: 2.5544014701265727

Epoch: 358| Step: 0
Training loss: 2.2349775875597793
Validation loss: 2.507566739315336

Epoch: 5| Step: 1
Training loss: 2.6446418682724655
Validation loss: 2.5611326349663255

Epoch: 5| Step: 2
Training loss: 2.872785461690261
Validation loss: 2.5122393081083856

Epoch: 5| Step: 3
Training loss: 2.2650248817946625
Validation loss: 2.5260640988983507

Epoch: 5| Step: 4
Training loss: 2.1589264775134973
Validation loss: 2.5249516944971564

Epoch: 5| Step: 5
Training loss: 2.7695964165299105
Validation loss: 2.5442717163381317

Epoch: 5| Step: 6
Training loss: 2.7219126929772965
Validation loss: 2.5538877643014097

Epoch: 5| Step: 7
Training loss: 2.481917695499814
Validation loss: 2.565747157294779

Epoch: 5| Step: 8
Training loss: 2.634841092147984
Validation loss: 2.491962201641985

Epoch: 5| Step: 9
Training loss: 2.8097819439867404
Validation loss: 2.5122844549100907

Epoch: 5| Step: 10
Training loss: 2.135103441542167
Validation loss: 2.5373600934393115

Epoch: 359| Step: 0
Training loss: 2.3183688362012083
Validation loss: 2.562347057389397

Epoch: 5| Step: 1
Training loss: 2.8647119296715404
Validation loss: 2.5339758327285535

Epoch: 5| Step: 2
Training loss: 2.2035510145029193
Validation loss: 2.536415803368328

Epoch: 5| Step: 3
Training loss: 2.6730353083535183
Validation loss: 2.5359945370778427

Epoch: 5| Step: 4
Training loss: 2.6552421003977873
Validation loss: 2.5442744056551554

Epoch: 5| Step: 5
Training loss: 2.806171842646388
Validation loss: 2.5047867197848

Epoch: 5| Step: 6
Training loss: 2.7155787947996246
Validation loss: 2.5202622603668026

Epoch: 5| Step: 7
Training loss: 2.007292208814193
Validation loss: 2.577193760293929

Epoch: 5| Step: 8
Training loss: 1.9246126850425667
Validation loss: 2.5341086046416974

Epoch: 5| Step: 9
Training loss: 2.7137676493924303
Validation loss: 2.5015810602051225

Epoch: 5| Step: 10
Training loss: 2.846165898906225
Validation loss: 2.526668809112819

Epoch: 360| Step: 0
Training loss: 2.485852551882047
Validation loss: 2.541914295564788

Epoch: 5| Step: 1
Training loss: 2.553552124453508
Validation loss: 2.535650838621564

Epoch: 5| Step: 2
Training loss: 3.0401138801325853
Validation loss: 2.5348325428816847

Epoch: 5| Step: 3
Training loss: 2.2806378941211958
Validation loss: 2.5406534289090206

Epoch: 5| Step: 4
Training loss: 2.701577156869943
Validation loss: 2.571698145393379

Epoch: 5| Step: 5
Training loss: 2.6722709853106412
Validation loss: 2.5109495937539785

Epoch: 5| Step: 6
Training loss: 2.637167207233218
Validation loss: 2.5509855908430192

Epoch: 5| Step: 7
Training loss: 2.3912433497749697
Validation loss: 2.5265664174148856

Epoch: 5| Step: 8
Training loss: 1.8666514501064981
Validation loss: 2.5391050364525913

Epoch: 5| Step: 9
Training loss: 2.4759602581587794
Validation loss: 2.5259614868091225

Epoch: 5| Step: 10
Training loss: 2.9295776346587363
Validation loss: 2.541753255726466

Epoch: 361| Step: 0
Training loss: 2.9151476764731785
Validation loss: 2.563311356603731

Epoch: 5| Step: 1
Training loss: 2.299986723156631
Validation loss: 2.523361610778342

Epoch: 5| Step: 2
Training loss: 2.2001222749889027
Validation loss: 2.5272804854993347

Epoch: 5| Step: 3
Training loss: 2.740630922561214
Validation loss: 2.510801706939864

Epoch: 5| Step: 4
Training loss: 2.4508672152549438
Validation loss: 2.479598372703658

Epoch: 5| Step: 5
Training loss: 2.4172833631428174
Validation loss: 2.523529492479979

Epoch: 5| Step: 6
Training loss: 3.150666236055172
Validation loss: 2.568873249639412

Epoch: 5| Step: 7
Training loss: 2.30494683309873
Validation loss: 2.519148843891421

Epoch: 5| Step: 8
Training loss: 2.386487484480135
Validation loss: 2.5258581012130437

Epoch: 5| Step: 9
Training loss: 2.561666213436579
Validation loss: 2.559649857560579

Epoch: 5| Step: 10
Training loss: 2.523103296216325
Validation loss: 2.57837561777958

Epoch: 362| Step: 0
Training loss: 2.3598280717972617
Validation loss: 2.548910581098696

Epoch: 5| Step: 1
Training loss: 2.0425680726752904
Validation loss: 2.506134688438131

Epoch: 5| Step: 2
Training loss: 2.963739121512435
Validation loss: 2.555046021012281

Epoch: 5| Step: 3
Training loss: 3.10262989347092
Validation loss: 2.547562009837271

Epoch: 5| Step: 4
Training loss: 2.573838433056741
Validation loss: 2.5102786519492652

Epoch: 5| Step: 5
Training loss: 2.998719577929164
Validation loss: 2.506654104017162

Epoch: 5| Step: 6
Training loss: 2.403258904544862
Validation loss: 2.5540800827257333

Epoch: 5| Step: 7
Training loss: 2.2966229566484966
Validation loss: 2.509550602271351

Epoch: 5| Step: 8
Training loss: 2.051608254938593
Validation loss: 2.5473750353535247

Epoch: 5| Step: 9
Training loss: 2.2799792996520916
Validation loss: 2.531793010221902

Epoch: 5| Step: 10
Training loss: 2.6920036904081583
Validation loss: 2.5188615701821635

Epoch: 363| Step: 0
Training loss: 2.21622925603962
Validation loss: 2.529413881809233

Epoch: 5| Step: 1
Training loss: 2.420500334413628
Validation loss: 2.540035547134176

Epoch: 5| Step: 2
Training loss: 2.5441988124955293
Validation loss: 2.565545765866076

Epoch: 5| Step: 3
Training loss: 2.59830947349544
Validation loss: 2.537435159865612

Epoch: 5| Step: 4
Training loss: 2.3094768868194318
Validation loss: 2.5693150767586816

Epoch: 5| Step: 5
Training loss: 2.2112103081607826
Validation loss: 2.4953560375878125

Epoch: 5| Step: 6
Training loss: 2.372766046429797
Validation loss: 2.527962352751637

Epoch: 5| Step: 7
Training loss: 2.493883948684384
Validation loss: 2.503613852280552

Epoch: 5| Step: 8
Training loss: 2.664777911381375
Validation loss: 2.506582533085639

Epoch: 5| Step: 9
Training loss: 2.824354492977458
Validation loss: 2.548910011827741

Epoch: 5| Step: 10
Training loss: 3.1156385966686297
Validation loss: 2.542277809500035

Epoch: 364| Step: 0
Training loss: 2.3845246714241335
Validation loss: 2.4979352915785857

Epoch: 5| Step: 1
Training loss: 2.0743349549237475
Validation loss: 2.5398041147409978

Epoch: 5| Step: 2
Training loss: 2.739590885359843
Validation loss: 2.5650397939409055

Epoch: 5| Step: 3
Training loss: 2.5253831667100326
Validation loss: 2.5386881779721198

Epoch: 5| Step: 4
Training loss: 2.7390222784767904
Validation loss: 2.5571308857772985

Epoch: 5| Step: 5
Training loss: 2.893836634350425
Validation loss: 2.536391938825408

Epoch: 5| Step: 6
Training loss: 3.2838224953503863
Validation loss: 2.4975028189565065

Epoch: 5| Step: 7
Training loss: 2.1600196063953234
Validation loss: 2.527533655715141

Epoch: 5| Step: 8
Training loss: 2.1015455961433904
Validation loss: 2.5229892716776927

Epoch: 5| Step: 9
Training loss: 2.359224327278379
Validation loss: 2.535069096159906

Epoch: 5| Step: 10
Training loss: 2.8715366566859144
Validation loss: 2.50379483657858

Epoch: 365| Step: 0
Training loss: 2.884276475804529
Validation loss: 2.5466499664544213

Epoch: 5| Step: 1
Training loss: 1.4876242962364288
Validation loss: 2.507512388946642

Epoch: 5| Step: 2
Training loss: 2.605302842561444
Validation loss: 2.496511850019052

Epoch: 5| Step: 3
Training loss: 3.1001209973748214
Validation loss: 2.5267840748389374

Epoch: 5| Step: 4
Training loss: 2.714287263109726
Validation loss: 2.538865550237983

Epoch: 5| Step: 5
Training loss: 2.466715880066286
Validation loss: 2.51174314189755

Epoch: 5| Step: 6
Training loss: 2.478276090116921
Validation loss: 2.513780005323213

Epoch: 5| Step: 7
Training loss: 2.371753883536364
Validation loss: 2.5571442967962823

Epoch: 5| Step: 8
Training loss: 2.180145762408817
Validation loss: 2.5533994470868793

Epoch: 5| Step: 9
Training loss: 2.3771872236688703
Validation loss: 2.5714828256000906

Epoch: 5| Step: 10
Training loss: 3.099033044934925
Validation loss: 2.5168413113314605

Epoch: 366| Step: 0
Training loss: 2.918283958721788
Validation loss: 2.5074871962550676

Epoch: 5| Step: 1
Training loss: 2.1144726227841453
Validation loss: 2.5525470482289117

Epoch: 5| Step: 2
Training loss: 2.6085373681879487
Validation loss: 2.4970491673340733

Epoch: 5| Step: 3
Training loss: 2.78073955523707
Validation loss: 2.5422536107374567

Epoch: 5| Step: 4
Training loss: 2.5854054621090707
Validation loss: 2.510371042384278

Epoch: 5| Step: 5
Training loss: 2.9354469754396306
Validation loss: 2.5169372865652466

Epoch: 5| Step: 6
Training loss: 2.28504200185157
Validation loss: 2.5504315465135914

Epoch: 5| Step: 7
Training loss: 2.1846336113426674
Validation loss: 2.539913224916579

Epoch: 5| Step: 8
Training loss: 2.7243191034612906
Validation loss: 2.507057786594134

Epoch: 5| Step: 9
Training loss: 2.2359346934900057
Validation loss: 2.5872067685250983

Epoch: 5| Step: 10
Training loss: 2.4535337459901387
Validation loss: 2.559838210847843

Epoch: 367| Step: 0
Training loss: 2.615529551524873
Validation loss: 2.509755730037879

Epoch: 5| Step: 1
Training loss: 2.1327991974244607
Validation loss: 2.528664130363742

Epoch: 5| Step: 2
Training loss: 2.5091745830990835
Validation loss: 2.5491544718342185

Epoch: 5| Step: 3
Training loss: 1.8822049628848474
Validation loss: 2.548368781297074

Epoch: 5| Step: 4
Training loss: 2.959105234227307
Validation loss: 2.5491381505568986

Epoch: 5| Step: 5
Training loss: 2.3771995598487248
Validation loss: 2.545864370506069

Epoch: 5| Step: 6
Training loss: 2.4585323145451228
Validation loss: 2.5414284642069687

Epoch: 5| Step: 7
Training loss: 2.180064397788152
Validation loss: 2.561819124642906

Epoch: 5| Step: 8
Training loss: 2.6474048322912043
Validation loss: 2.516615335680816

Epoch: 5| Step: 9
Training loss: 3.12096816324694
Validation loss: 2.5550198812453533

Epoch: 5| Step: 10
Training loss: 2.500042152049426
Validation loss: 2.539507706627269

Epoch: 368| Step: 0
Training loss: 2.9576732991668453
Validation loss: 2.51620897299409

Epoch: 5| Step: 1
Training loss: 2.30741963487332
Validation loss: 2.515067200017453

Epoch: 5| Step: 2
Training loss: 2.9254531574531555
Validation loss: 2.50720780633345

Epoch: 5| Step: 3
Training loss: 2.5177548319119007
Validation loss: 2.525504659886168

Epoch: 5| Step: 4
Training loss: 2.4969226971058327
Validation loss: 2.5041114782278764

Epoch: 5| Step: 5
Training loss: 2.087630938232411
Validation loss: 2.5261593634678015

Epoch: 5| Step: 6
Training loss: 2.597256599602212
Validation loss: 2.5455339631722955

Epoch: 5| Step: 7
Training loss: 2.6472584848587677
Validation loss: 2.467028008863923

Epoch: 5| Step: 8
Training loss: 2.3838123662638573
Validation loss: 2.515034506360528

Epoch: 5| Step: 9
Training loss: 2.3371495193229266
Validation loss: 2.5147374133194664

Epoch: 5| Step: 10
Training loss: 2.595814630023651
Validation loss: 2.4836133389280954

Epoch: 369| Step: 0
Training loss: 2.5221218777701653
Validation loss: 2.531335062319224

Epoch: 5| Step: 1
Training loss: 3.1534464253582906
Validation loss: 2.52356074273616

Epoch: 5| Step: 2
Training loss: 2.549771306123648
Validation loss: 2.503328441597998

Epoch: 5| Step: 3
Training loss: 2.1783062239664774
Validation loss: 2.4918107547707207

Epoch: 5| Step: 4
Training loss: 2.334990548680392
Validation loss: 2.5220349474393347

Epoch: 5| Step: 5
Training loss: 2.4267141910063375
Validation loss: 2.5280732446398493

Epoch: 5| Step: 6
Training loss: 2.594631550822098
Validation loss: 2.528985587950434

Epoch: 5| Step: 7
Training loss: 1.6604441673589208
Validation loss: 2.517617629497264

Epoch: 5| Step: 8
Training loss: 2.347685904164835
Validation loss: 2.5141845871714823

Epoch: 5| Step: 9
Training loss: 2.739802788090222
Validation loss: 2.506088065191325

Epoch: 5| Step: 10
Training loss: 3.1325089837970674
Validation loss: 2.555241035381354

Epoch: 370| Step: 0
Training loss: 2.6424848338461535
Validation loss: 2.5425512757094113

Epoch: 5| Step: 1
Training loss: 2.17985189494723
Validation loss: 2.486898409827203

Epoch: 5| Step: 2
Training loss: 2.6272142245069046
Validation loss: 2.5340157998913457

Epoch: 5| Step: 3
Training loss: 2.4484673279757176
Validation loss: 2.5718527759768066

Epoch: 5| Step: 4
Training loss: 2.359374090535576
Validation loss: 2.5027723486460713

Epoch: 5| Step: 5
Training loss: 2.4743281252035056
Validation loss: 2.5262638824390438

Epoch: 5| Step: 6
Training loss: 2.8259534560283237
Validation loss: 2.5569941419021274

Epoch: 5| Step: 7
Training loss: 2.740611609814424
Validation loss: 2.5433937185054436

Epoch: 5| Step: 8
Training loss: 2.433867462097943
Validation loss: 2.495667621948998

Epoch: 5| Step: 9
Training loss: 2.357898780856931
Validation loss: 2.5108949163753076

Epoch: 5| Step: 10
Training loss: 2.656584415702137
Validation loss: 2.5053109853280273

Epoch: 371| Step: 0
Training loss: 2.2622878127945394
Validation loss: 2.5446192837322115

Epoch: 5| Step: 1
Training loss: 2.87471438108678
Validation loss: 2.4928630723663994

Epoch: 5| Step: 2
Training loss: 2.60962223549216
Validation loss: 2.5096278989827225

Epoch: 5| Step: 3
Training loss: 2.2551644712298398
Validation loss: 2.515100099147931

Epoch: 5| Step: 4
Training loss: 2.029817046391445
Validation loss: 2.546969380489953

Epoch: 5| Step: 5
Training loss: 2.09449515676223
Validation loss: 2.498861671032308

Epoch: 5| Step: 6
Training loss: 2.7592142233230077
Validation loss: 2.567256811328986

Epoch: 5| Step: 7
Training loss: 2.233740443042191
Validation loss: 2.526209893739056

Epoch: 5| Step: 8
Training loss: 2.8652937869287674
Validation loss: 2.539830940019898

Epoch: 5| Step: 9
Training loss: 3.0401715998152543
Validation loss: 2.5635604844973945

Epoch: 5| Step: 10
Training loss: 2.5023578015759766
Validation loss: 2.527473158949194

Epoch: 372| Step: 0
Training loss: 2.2087819945215306
Validation loss: 2.4908750688106034

Epoch: 5| Step: 1
Training loss: 2.224614197790262
Validation loss: 2.5066301468676926

Epoch: 5| Step: 2
Training loss: 2.893223105263162
Validation loss: 2.485180993962795

Epoch: 5| Step: 3
Training loss: 2.5179700642534093
Validation loss: 2.545648547909178

Epoch: 5| Step: 4
Training loss: 1.9443848631071285
Validation loss: 2.5115492321185657

Epoch: 5| Step: 5
Training loss: 2.2713352197038934
Validation loss: 2.559299209732442

Epoch: 5| Step: 6
Training loss: 2.9885293695501094
Validation loss: 2.5266750739542667

Epoch: 5| Step: 7
Training loss: 2.599128569771913
Validation loss: 2.5428129635847228

Epoch: 5| Step: 8
Training loss: 2.5055150236228587
Validation loss: 2.5546661051925263

Epoch: 5| Step: 9
Training loss: 2.343220663694708
Validation loss: 2.5357689362902898

Epoch: 5| Step: 10
Training loss: 3.2357628834616854
Validation loss: 2.5729592919145334

Epoch: 373| Step: 0
Training loss: 2.013089855305383
Validation loss: 2.5147039742275252

Epoch: 5| Step: 1
Training loss: 3.477984671148178
Validation loss: 2.5287416224397954

Epoch: 5| Step: 2
Training loss: 2.6127155415813452
Validation loss: 2.5747663380559747

Epoch: 5| Step: 3
Training loss: 2.6896576315390477
Validation loss: 2.5352245044607016

Epoch: 5| Step: 4
Training loss: 2.6529267110065757
Validation loss: 2.5510649473468043

Epoch: 5| Step: 5
Training loss: 2.2425665451944217
Validation loss: 2.530881182600935

Epoch: 5| Step: 6
Training loss: 2.302540855915039
Validation loss: 2.5267997947909677

Epoch: 5| Step: 7
Training loss: 2.6230493291302275
Validation loss: 2.5198480583532974

Epoch: 5| Step: 8
Training loss: 2.285411435738219
Validation loss: 2.4964194878572536

Epoch: 5| Step: 9
Training loss: 2.6017521969479973
Validation loss: 2.5365862265291192

Epoch: 5| Step: 10
Training loss: 2.0457866774740285
Validation loss: 2.519637406301972

Epoch: 374| Step: 0
Training loss: 1.9509090823209316
Validation loss: 2.5552343745489208

Epoch: 5| Step: 1
Training loss: 2.9466211462460516
Validation loss: 2.545499498521121

Epoch: 5| Step: 2
Training loss: 2.264569898446761
Validation loss: 2.5190598213664996

Epoch: 5| Step: 3
Training loss: 3.008881614224862
Validation loss: 2.529872621323109

Epoch: 5| Step: 4
Training loss: 2.2426032235874502
Validation loss: 2.5730559711691594

Epoch: 5| Step: 5
Training loss: 2.652364874012669
Validation loss: 2.5302959656168933

Epoch: 5| Step: 6
Training loss: 2.61723997148893
Validation loss: 2.5194519289946933

Epoch: 5| Step: 7
Training loss: 2.7100611432768584
Validation loss: 2.541900584328143

Epoch: 5| Step: 8
Training loss: 2.397367058370711
Validation loss: 2.5068357299000277

Epoch: 5| Step: 9
Training loss: 2.236351472824355
Validation loss: 2.5239640472656077

Epoch: 5| Step: 10
Training loss: 2.982860720261181
Validation loss: 2.5363230082419856

Epoch: 375| Step: 0
Training loss: 1.770566927748281
Validation loss: 2.528612525787912

Epoch: 5| Step: 1
Training loss: 2.7976478063077255
Validation loss: 2.4957045713689525

Epoch: 5| Step: 2
Training loss: 2.854423529953902
Validation loss: 2.5709577595099096

Epoch: 5| Step: 3
Training loss: 2.5545783063318206
Validation loss: 2.5329191355293124

Epoch: 5| Step: 4
Training loss: 2.0076213107385423
Validation loss: 2.511319759115839

Epoch: 5| Step: 5
Training loss: 2.2527726362143325
Validation loss: 2.532758283910696

Epoch: 5| Step: 6
Training loss: 2.9152382940710457
Validation loss: 2.4924527939791234

Epoch: 5| Step: 7
Training loss: 2.5179628680447803
Validation loss: 2.538832070974966

Epoch: 5| Step: 8
Training loss: 2.554445121069622
Validation loss: 2.504829919667566

Epoch: 5| Step: 9
Training loss: 2.5417203636959282
Validation loss: 2.498013355135715

Epoch: 5| Step: 10
Training loss: 2.8319216371567526
Validation loss: 2.50941327820473

Epoch: 376| Step: 0
Training loss: 2.122405431682827
Validation loss: 2.547276430838491

Epoch: 5| Step: 1
Training loss: 3.6367774901271197
Validation loss: 2.5247028957007327

Epoch: 5| Step: 2
Training loss: 2.2033431574169144
Validation loss: 2.5259314410348126

Epoch: 5| Step: 3
Training loss: 2.1651078876986145
Validation loss: 2.5545794042125336

Epoch: 5| Step: 4
Training loss: 2.3023014454341535
Validation loss: 2.514433236898087

Epoch: 5| Step: 5
Training loss: 2.3133737099208442
Validation loss: 2.531303288729218

Epoch: 5| Step: 6
Training loss: 2.084530931213551
Validation loss: 2.503560234272216

Epoch: 5| Step: 7
Training loss: 2.699394695106794
Validation loss: 2.4999473074005323

Epoch: 5| Step: 8
Training loss: 2.43147825135583
Validation loss: 2.5312988568220294

Epoch: 5| Step: 9
Training loss: 2.771613238338302
Validation loss: 2.549420954778492

Epoch: 5| Step: 10
Training loss: 2.4926945759422443
Validation loss: 2.5409550295078036

Epoch: 377| Step: 0
Training loss: 2.3617434708250733
Validation loss: 2.54173295532909

Epoch: 5| Step: 1
Training loss: 2.4549454658495797
Validation loss: 2.5678842015862533

Epoch: 5| Step: 2
Training loss: 2.5196886116980117
Validation loss: 2.489178678235306

Epoch: 5| Step: 3
Training loss: 2.4788265048333766
Validation loss: 2.5458356079050586

Epoch: 5| Step: 4
Training loss: 2.261033871909458
Validation loss: 2.5542168300486807

Epoch: 5| Step: 5
Training loss: 2.7947167108649915
Validation loss: 2.547845984137645

Epoch: 5| Step: 6
Training loss: 2.3797110964030384
Validation loss: 2.5320659149402434

Epoch: 5| Step: 7
Training loss: 3.2507423140016827
Validation loss: 2.5119529730630794

Epoch: 5| Step: 8
Training loss: 2.166425385856649
Validation loss: 2.5419757909886025

Epoch: 5| Step: 9
Training loss: 2.150267996829911
Validation loss: 2.5170283998096887

Epoch: 5| Step: 10
Training loss: 2.4930601117001845
Validation loss: 2.5186388400840682

Epoch: 378| Step: 0
Training loss: 2.5945993894079513
Validation loss: 2.528938358066346

Epoch: 5| Step: 1
Training loss: 2.535436112249109
Validation loss: 2.5299677222185153

Epoch: 5| Step: 2
Training loss: 3.1887880602531253
Validation loss: 2.5468196886796757

Epoch: 5| Step: 3
Training loss: 2.4125733952401642
Validation loss: 2.5387510602474257

Epoch: 5| Step: 4
Training loss: 2.4347518687943657
Validation loss: 2.480751454149263

Epoch: 5| Step: 5
Training loss: 2.755326228272533
Validation loss: 2.513007438139825

Epoch: 5| Step: 6
Training loss: 2.058746853370323
Validation loss: 2.511077861866444

Epoch: 5| Step: 7
Training loss: 2.005865674626488
Validation loss: 2.5237901906511646

Epoch: 5| Step: 8
Training loss: 2.3901504344760958
Validation loss: 2.509976788921603

Epoch: 5| Step: 9
Training loss: 2.6338479923364253
Validation loss: 2.521498873877144

Epoch: 5| Step: 10
Training loss: 2.7659008513558923
Validation loss: 2.5198620381201087

Epoch: 379| Step: 0
Training loss: 2.7853059661559194
Validation loss: 2.535011581519358

Epoch: 5| Step: 1
Training loss: 2.3761888841117145
Validation loss: 2.5566765327946173

Epoch: 5| Step: 2
Training loss: 2.227813797414067
Validation loss: 2.497396186800273

Epoch: 5| Step: 3
Training loss: 2.3097160696606696
Validation loss: 2.5272167791599065

Epoch: 5| Step: 4
Training loss: 2.5015485735761147
Validation loss: 2.6019227300983454

Epoch: 5| Step: 5
Training loss: 2.705304188009974
Validation loss: 2.4920695292347066

Epoch: 5| Step: 6
Training loss: 2.251548446198441
Validation loss: 2.5668385272212833

Epoch: 5| Step: 7
Training loss: 2.495550678616781
Validation loss: 2.5510897730064444

Epoch: 5| Step: 8
Training loss: 2.97995130614366
Validation loss: 2.5362712279590136

Epoch: 5| Step: 9
Training loss: 2.5047113846980427
Validation loss: 2.5459059509876134

Epoch: 5| Step: 10
Training loss: 2.467741071989233
Validation loss: 2.4878619151660284

Epoch: 380| Step: 0
Training loss: 2.3223500152217977
Validation loss: 2.531517301316368

Epoch: 5| Step: 1
Training loss: 2.230398093472327
Validation loss: 2.4956095392723086

Epoch: 5| Step: 2
Training loss: 2.4378691173717795
Validation loss: 2.529082481922757

Epoch: 5| Step: 3
Training loss: 2.4143136396913225
Validation loss: 2.5209035278028207

Epoch: 5| Step: 4
Training loss: 2.069255631073584
Validation loss: 2.520950358057698

Epoch: 5| Step: 5
Training loss: 3.0609650171044915
Validation loss: 2.5252990165475446

Epoch: 5| Step: 6
Training loss: 2.6606980722871505
Validation loss: 2.5451705587354456

Epoch: 5| Step: 7
Training loss: 2.5253972335929578
Validation loss: 2.524633023497753

Epoch: 5| Step: 8
Training loss: 2.976052708661499
Validation loss: 2.5293520642476035

Epoch: 5| Step: 9
Training loss: 2.9050835350225275
Validation loss: 2.548552940235085

Epoch: 5| Step: 10
Training loss: 1.7471247622436614
Validation loss: 2.56392157935632

Epoch: 381| Step: 0
Training loss: 2.812070262714833
Validation loss: 2.53838251163438

Epoch: 5| Step: 1
Training loss: 2.373136291075181
Validation loss: 2.528730084344967

Epoch: 5| Step: 2
Training loss: 2.6310861060777193
Validation loss: 2.556434922076333

Epoch: 5| Step: 3
Training loss: 2.6699637554151767
Validation loss: 2.5244457024311364

Epoch: 5| Step: 4
Training loss: 2.472675727176942
Validation loss: 2.5305082033578676

Epoch: 5| Step: 5
Training loss: 2.678725979297223
Validation loss: 2.5291928675565623

Epoch: 5| Step: 6
Training loss: 2.8599517740838656
Validation loss: 2.5526295715018983

Epoch: 5| Step: 7
Training loss: 2.085195002047463
Validation loss: 2.54483764862642

Epoch: 5| Step: 8
Training loss: 2.2052771695552846
Validation loss: 2.5524626446014755

Epoch: 5| Step: 9
Training loss: 2.6634662218166576
Validation loss: 2.534233539796358

Epoch: 5| Step: 10
Training loss: 2.060598016619494
Validation loss: 2.5179871780744243

Epoch: 382| Step: 0
Training loss: 1.562191665744588
Validation loss: 2.5461866942336813

Epoch: 5| Step: 1
Training loss: 2.4535506541292214
Validation loss: 2.5721349373482063

Epoch: 5| Step: 2
Training loss: 2.063827087700131
Validation loss: 2.56609316862984

Epoch: 5| Step: 3
Training loss: 2.2861756748905324
Validation loss: 2.4834155800047295

Epoch: 5| Step: 4
Training loss: 3.064603744705104
Validation loss: 2.559861539342824

Epoch: 5| Step: 5
Training loss: 2.4068557175047394
Validation loss: 2.506200136696167

Epoch: 5| Step: 6
Training loss: 2.7960944764870965
Validation loss: 2.5646706608273844

Epoch: 5| Step: 7
Training loss: 2.409847888973896
Validation loss: 2.5942109646346077

Epoch: 5| Step: 8
Training loss: 2.3765209748642504
Validation loss: 2.5502140823118333

Epoch: 5| Step: 9
Training loss: 2.036433955548291
Validation loss: 2.488693474381556

Epoch: 5| Step: 10
Training loss: 3.563892962191692
Validation loss: 2.5534630232716324

Epoch: 383| Step: 0
Training loss: 2.7944934444627023
Validation loss: 2.5492901589600585

Epoch: 5| Step: 1
Training loss: 1.9787475811479043
Validation loss: 2.5420633050598296

Epoch: 5| Step: 2
Training loss: 2.5272824310929773
Validation loss: 2.541328507200029

Epoch: 5| Step: 3
Training loss: 2.517920731936749
Validation loss: 2.519382319206558

Epoch: 5| Step: 4
Training loss: 2.3229329631786877
Validation loss: 2.553098104578288

Epoch: 5| Step: 5
Training loss: 2.885834224156253
Validation loss: 2.5299812002138924

Epoch: 5| Step: 6
Training loss: 2.091264872569334
Validation loss: 2.477106509426309

Epoch: 5| Step: 7
Training loss: 2.4286664675701073
Validation loss: 2.527386636847675

Epoch: 5| Step: 8
Training loss: 2.6700768917598903
Validation loss: 2.508474464058766

Epoch: 5| Step: 9
Training loss: 2.932186108999157
Validation loss: 2.5303481366625453

Epoch: 5| Step: 10
Training loss: 2.2780172356547133
Validation loss: 2.5617281183660694

Epoch: 384| Step: 0
Training loss: 2.552471541377779
Validation loss: 2.5083650022478117

Epoch: 5| Step: 1
Training loss: 2.1806815557124146
Validation loss: 2.534502442228772

Epoch: 5| Step: 2
Training loss: 2.252170575405028
Validation loss: 2.5352281539096473

Epoch: 5| Step: 3
Training loss: 2.0664739759916957
Validation loss: 2.4829127917417564

Epoch: 5| Step: 4
Training loss: 2.388741942132108
Validation loss: 2.507062263399073

Epoch: 5| Step: 5
Training loss: 2.7229005548009737
Validation loss: 2.489861324066331

Epoch: 5| Step: 6
Training loss: 3.12158703397114
Validation loss: 2.553884666514612

Epoch: 5| Step: 7
Training loss: 2.9021424830849476
Validation loss: 2.5019254243033275

Epoch: 5| Step: 8
Training loss: 2.761418737710166
Validation loss: 2.5341691812422384

Epoch: 5| Step: 9
Training loss: 2.2259185395189047
Validation loss: 2.5404034896130723

Epoch: 5| Step: 10
Training loss: 1.957385489864635
Validation loss: 2.5289301175061865

Epoch: 385| Step: 0
Training loss: 2.517951410880709
Validation loss: 2.4869109811161656

Epoch: 5| Step: 1
Training loss: 2.7811073523811967
Validation loss: 2.479997595082287

Epoch: 5| Step: 2
Training loss: 2.691184423686887
Validation loss: 2.5516390623264877

Epoch: 5| Step: 3
Training loss: 2.332332828005742
Validation loss: 2.4829903560315665

Epoch: 5| Step: 4
Training loss: 2.4050889620119356
Validation loss: 2.5076594187961185

Epoch: 5| Step: 5
Training loss: 2.4321445417868475
Validation loss: 2.535445863511476

Epoch: 5| Step: 6
Training loss: 2.1988283288480877
Validation loss: 2.544606351748623

Epoch: 5| Step: 7
Training loss: 2.6667969393698727
Validation loss: 2.515919997678086

Epoch: 5| Step: 8
Training loss: 2.2387970601326823
Validation loss: 2.5318959945078134

Epoch: 5| Step: 9
Training loss: 2.765155989539175
Validation loss: 2.5349729968406574

Epoch: 5| Step: 10
Training loss: 2.4535703801442184
Validation loss: 2.544032176365252

Epoch: 386| Step: 0
Training loss: 2.22997806315901
Validation loss: 2.508511439453944

Epoch: 5| Step: 1
Training loss: 2.8846403287151423
Validation loss: 2.5317001479292447

Epoch: 5| Step: 2
Training loss: 2.2806156269277085
Validation loss: 2.523574106632139

Epoch: 5| Step: 3
Training loss: 2.1669140698938
Validation loss: 2.4978210500570768

Epoch: 5| Step: 4
Training loss: 2.719371330032555
Validation loss: 2.530427181958884

Epoch: 5| Step: 5
Training loss: 2.3047856714062123
Validation loss: 2.5260674276878885

Epoch: 5| Step: 6
Training loss: 2.5962299303170777
Validation loss: 2.5121953003697954

Epoch: 5| Step: 7
Training loss: 2.9555321626366853
Validation loss: 2.5407803821074575

Epoch: 5| Step: 8
Training loss: 2.486751163809521
Validation loss: 2.5662236464864887

Epoch: 5| Step: 9
Training loss: 2.8172269305338182
Validation loss: 2.518677581859131

Epoch: 5| Step: 10
Training loss: 1.8512516968054147
Validation loss: 2.5568935972584734

Epoch: 387| Step: 0
Training loss: 2.4540195656317447
Validation loss: 2.532061401345209

Epoch: 5| Step: 1
Training loss: 2.436511108122613
Validation loss: 2.498137766966601

Epoch: 5| Step: 2
Training loss: 2.615361273993683
Validation loss: 2.5568733007614215

Epoch: 5| Step: 3
Training loss: 1.8237699491626875
Validation loss: 2.5348060611650802

Epoch: 5| Step: 4
Training loss: 2.6603476837781908
Validation loss: 2.5652006521027264

Epoch: 5| Step: 5
Training loss: 2.59616555485707
Validation loss: 2.5277616040647186

Epoch: 5| Step: 6
Training loss: 2.515011540835769
Validation loss: 2.544710591075996

Epoch: 5| Step: 7
Training loss: 2.2718435251188653
Validation loss: 2.541419578200474

Epoch: 5| Step: 8
Training loss: 2.8007135742183262
Validation loss: 2.560416298096469

Epoch: 5| Step: 9
Training loss: 2.856152161773531
Validation loss: 2.5445220927655905

Epoch: 5| Step: 10
Training loss: 1.971783435466947
Validation loss: 2.4985190163140283

Epoch: 388| Step: 0
Training loss: 2.40501134128236
Validation loss: 2.537064333466977

Epoch: 5| Step: 1
Training loss: 2.886669855387676
Validation loss: 2.515209421755305

Epoch: 5| Step: 2
Training loss: 2.2922564932354383
Validation loss: 2.511874063896201

Epoch: 5| Step: 3
Training loss: 1.92172848522916
Validation loss: 2.530112858952492

Epoch: 5| Step: 4
Training loss: 3.4471595293960444
Validation loss: 2.557212374402983

Epoch: 5| Step: 5
Training loss: 2.1350610080194636
Validation loss: 2.5481258028363913

Epoch: 5| Step: 6
Training loss: 2.4561047770737217
Validation loss: 2.563570532791857

Epoch: 5| Step: 7
Training loss: 2.1964793515067376
Validation loss: 2.5447577574206415

Epoch: 5| Step: 8
Training loss: 2.5504123952657722
Validation loss: 2.5258834669234225

Epoch: 5| Step: 9
Training loss: 2.2415974867496926
Validation loss: 2.5356301638108683

Epoch: 5| Step: 10
Training loss: 2.628278047911093
Validation loss: 2.5579025881820057

Epoch: 389| Step: 0
Training loss: 2.6568643196158703
Validation loss: 2.5225951579665487

Epoch: 5| Step: 1
Training loss: 1.7638856540693657
Validation loss: 2.5069850736956814

Epoch: 5| Step: 2
Training loss: 2.962130907461629
Validation loss: 2.5663099700573198

Epoch: 5| Step: 3
Training loss: 2.296856108088229
Validation loss: 2.556822911251198

Epoch: 5| Step: 4
Training loss: 2.3994112802690424
Validation loss: 2.501244675060442

Epoch: 5| Step: 5
Training loss: 2.0332021868993992
Validation loss: 2.526713200929967

Epoch: 5| Step: 6
Training loss: 2.172010019619981
Validation loss: 2.54069122352057

Epoch: 5| Step: 7
Training loss: 2.61934716237412
Validation loss: 2.5827994759258197

Epoch: 5| Step: 8
Training loss: 2.6156688326463726
Validation loss: 2.482441959209656

Epoch: 5| Step: 9
Training loss: 3.0818621416196947
Validation loss: 2.5250092809103077

Epoch: 5| Step: 10
Training loss: 2.755901160622928
Validation loss: 2.484129236414335

Epoch: 390| Step: 0
Training loss: 3.2533796784221503
Validation loss: 2.529219612794152

Epoch: 5| Step: 1
Training loss: 2.551139864752144
Validation loss: 2.497812802288423

Epoch: 5| Step: 2
Training loss: 2.3983222859198663
Validation loss: 2.534157694667553

Epoch: 5| Step: 3
Training loss: 1.8625795334597486
Validation loss: 2.525396176828333

Epoch: 5| Step: 4
Training loss: 2.10059183954308
Validation loss: 2.5541844618606198

Epoch: 5| Step: 5
Training loss: 2.3793852626057164
Validation loss: 2.5313172905577734

Epoch: 5| Step: 6
Training loss: 2.124940646969536
Validation loss: 2.5287570509223443

Epoch: 5| Step: 7
Training loss: 2.132410926881586
Validation loss: 2.5350950219695805

Epoch: 5| Step: 8
Training loss: 2.984459521310078
Validation loss: 2.4822030407675033

Epoch: 5| Step: 9
Training loss: 3.111153865323646
Validation loss: 2.4931405788065453

Epoch: 5| Step: 10
Training loss: 2.4147005194817432
Validation loss: 2.515453312127808

Epoch: 391| Step: 0
Training loss: 2.9786568229851875
Validation loss: 2.505861861030827

Epoch: 5| Step: 1
Training loss: 2.8138732100921615
Validation loss: 2.5294056742178626

Epoch: 5| Step: 2
Training loss: 2.0594328992284647
Validation loss: 2.5172368371538507

Epoch: 5| Step: 3
Training loss: 2.410652987392121
Validation loss: 2.5475116213156546

Epoch: 5| Step: 4
Training loss: 2.4614099442650357
Validation loss: 2.520681808549689

Epoch: 5| Step: 5
Training loss: 2.3531361127492203
Validation loss: 2.511955811285234

Epoch: 5| Step: 6
Training loss: 2.669522504649854
Validation loss: 2.520013450781823

Epoch: 5| Step: 7
Training loss: 2.6946384637549987
Validation loss: 2.535406107974113

Epoch: 5| Step: 8
Training loss: 2.5394030533334115
Validation loss: 2.549501372568519

Epoch: 5| Step: 9
Training loss: 2.052742737554327
Validation loss: 2.4928074563024136

Epoch: 5| Step: 10
Training loss: 2.626291320708121
Validation loss: 2.507705824724188

Epoch: 392| Step: 0
Training loss: 2.7716323350656107
Validation loss: 2.5724726122659454

Epoch: 5| Step: 1
Training loss: 2.4345236971570112
Validation loss: 2.519627644732375

Epoch: 5| Step: 2
Training loss: 2.761481678241798
Validation loss: 2.534647401731895

Epoch: 5| Step: 3
Training loss: 3.201333489332893
Validation loss: 2.526464181892201

Epoch: 5| Step: 4
Training loss: 2.6754164398324756
Validation loss: 2.5378633823818526

Epoch: 5| Step: 5
Training loss: 2.705821461919274
Validation loss: 2.5303381631226256

Epoch: 5| Step: 6
Training loss: 1.5668877601180045
Validation loss: 2.560696170820622

Epoch: 5| Step: 7
Training loss: 2.570951527290289
Validation loss: 2.528701863895751

Epoch: 5| Step: 8
Training loss: 2.1536073938803977
Validation loss: 2.5528117419677616

Epoch: 5| Step: 9
Training loss: 2.1401298674278593
Validation loss: 2.5304868482763454

Epoch: 5| Step: 10
Training loss: 1.952911182143829
Validation loss: 2.535278737016334

Epoch: 393| Step: 0
Training loss: 1.8695958140312086
Validation loss: 2.5127539164223145

Epoch: 5| Step: 1
Training loss: 2.4724917485144755
Validation loss: 2.5291691943491843

Epoch: 5| Step: 2
Training loss: 3.0071998665864657
Validation loss: 2.537390342350251

Epoch: 5| Step: 3
Training loss: 2.1951929243109976
Validation loss: 2.5389595489202454

Epoch: 5| Step: 4
Training loss: 2.632908669365168
Validation loss: 2.499980208103222

Epoch: 5| Step: 5
Training loss: 2.1322448869452244
Validation loss: 2.5202679211443884

Epoch: 5| Step: 6
Training loss: 1.5915819268695357
Validation loss: 2.513250894975315

Epoch: 5| Step: 7
Training loss: 2.6507185843402348
Validation loss: 2.512364115474227

Epoch: 5| Step: 8
Training loss: 1.933725063604583
Validation loss: 2.591794317092002

Epoch: 5| Step: 9
Training loss: 3.2185105910661047
Validation loss: 2.5274354557607386

Epoch: 5| Step: 10
Training loss: 2.8968514681192623
Validation loss: 2.510298833956766

Epoch: 394| Step: 0
Training loss: 2.774418273299559
Validation loss: 2.5359605321458116

Epoch: 5| Step: 1
Training loss: 2.3560421879849565
Validation loss: 2.502036007005494

Epoch: 5| Step: 2
Training loss: 2.5927967939743657
Validation loss: 2.526844697675377

Epoch: 5| Step: 3
Training loss: 2.357181059540152
Validation loss: 2.564789106501792

Epoch: 5| Step: 4
Training loss: 2.493661761336118
Validation loss: 2.5318178233506505

Epoch: 5| Step: 5
Training loss: 2.0590079829990837
Validation loss: 2.494286278512758

Epoch: 5| Step: 6
Training loss: 2.0458850359420855
Validation loss: 2.529755169570049

Epoch: 5| Step: 7
Training loss: 2.79691540566353
Validation loss: 2.5427673148160395

Epoch: 5| Step: 8
Training loss: 2.4497702432452604
Validation loss: 2.4964044053344896

Epoch: 5| Step: 9
Training loss: 3.1551393877726563
Validation loss: 2.5479582745020473

Epoch: 5| Step: 10
Training loss: 2.043084165037267
Validation loss: 2.51563271345738

Epoch: 395| Step: 0
Training loss: 2.0333504014262935
Validation loss: 2.5178206979820033

Epoch: 5| Step: 1
Training loss: 2.5796293551328806
Validation loss: 2.5306270110730504

Epoch: 5| Step: 2
Training loss: 2.4884071497902913
Validation loss: 2.5285625342448257

Epoch: 5| Step: 3
Training loss: 2.2156025227642693
Validation loss: 2.5469087122488956

Epoch: 5| Step: 4
Training loss: 2.575967706856982
Validation loss: 2.520030990201848

Epoch: 5| Step: 5
Training loss: 2.5165498348510926
Validation loss: 2.527821801846594

Epoch: 5| Step: 6
Training loss: 1.999782729268151
Validation loss: 2.5498392930322176

Epoch: 5| Step: 7
Training loss: 2.7117009475813827
Validation loss: 2.514152375564235

Epoch: 5| Step: 8
Training loss: 2.9060508085509933
Validation loss: 2.5234863942964427

Epoch: 5| Step: 9
Training loss: 2.2176650712461288
Validation loss: 2.519700986832119

Epoch: 5| Step: 10
Training loss: 3.0952633325714674
Validation loss: 2.582555394399477

Epoch: 396| Step: 0
Training loss: 2.297858514219988
Validation loss: 2.485813044822067

Epoch: 5| Step: 1
Training loss: 1.9994609225461708
Validation loss: 2.5145356353235964

Epoch: 5| Step: 2
Training loss: 3.111165360325933
Validation loss: 2.561758634950303

Epoch: 5| Step: 3
Training loss: 2.8999850108318346
Validation loss: 2.564207136159076

Epoch: 5| Step: 4
Training loss: 2.199612678765167
Validation loss: 2.539083327593702

Epoch: 5| Step: 5
Training loss: 2.58768885563671
Validation loss: 2.5015108567879687

Epoch: 5| Step: 6
Training loss: 2.142973231395412
Validation loss: 2.548599929850613

Epoch: 5| Step: 7
Training loss: 2.533349661607155
Validation loss: 2.5261808606739167

Epoch: 5| Step: 8
Training loss: 2.22460851761397
Validation loss: 2.540384128548958

Epoch: 5| Step: 9
Training loss: 2.666205207316108
Validation loss: 2.481936210653265

Epoch: 5| Step: 10
Training loss: 2.488009307708993
Validation loss: 2.516468481197673

Epoch: 397| Step: 0
Training loss: 3.065585392220721
Validation loss: 2.5104152046464527

Epoch: 5| Step: 1
Training loss: 2.445933497737419
Validation loss: 2.5207217510535207

Epoch: 5| Step: 2
Training loss: 1.8768724628625693
Validation loss: 2.5013877021804487

Epoch: 5| Step: 3
Training loss: 2.36105206234964
Validation loss: 2.501436371557866

Epoch: 5| Step: 4
Training loss: 2.421983876395954
Validation loss: 2.545473973772811

Epoch: 5| Step: 5
Training loss: 2.1863105810026178
Validation loss: 2.51576279614577

Epoch: 5| Step: 6
Training loss: 2.1245141315380747
Validation loss: 2.5224431852851352

Epoch: 5| Step: 7
Training loss: 2.161755706063137
Validation loss: 2.543664733581575

Epoch: 5| Step: 8
Training loss: 2.5650763237437713
Validation loss: 2.546104517435297

Epoch: 5| Step: 9
Training loss: 3.217183593036193
Validation loss: 2.5081233024730945

Epoch: 5| Step: 10
Training loss: 2.7522617922341515
Validation loss: 2.5258544534502922

Epoch: 398| Step: 0
Training loss: 2.3578673339292013
Validation loss: 2.522833285476348

Epoch: 5| Step: 1
Training loss: 2.3814214930019304
Validation loss: 2.512236543679742

Epoch: 5| Step: 2
Training loss: 2.3316762580519796
Validation loss: 2.508650406061612

Epoch: 5| Step: 3
Training loss: 2.994080425336599
Validation loss: 2.5245930794089038

Epoch: 5| Step: 4
Training loss: 2.1594670939922658
Validation loss: 2.536159509822836

Epoch: 5| Step: 5
Training loss: 2.193714143726289
Validation loss: 2.5478407619583545

Epoch: 5| Step: 6
Training loss: 2.2350955681562037
Validation loss: 2.5543780927697743

Epoch: 5| Step: 7
Training loss: 2.7056755425307326
Validation loss: 2.5474296573331787

Epoch: 5| Step: 8
Training loss: 3.237945355157471
Validation loss: 2.4997101056801347

Epoch: 5| Step: 9
Training loss: 2.376729937491903
Validation loss: 2.50653029490551

Epoch: 5| Step: 10
Training loss: 2.39707326454485
Validation loss: 2.497228088634216

Epoch: 399| Step: 0
Training loss: 2.085099755697779
Validation loss: 2.5220949586676955

Epoch: 5| Step: 1
Training loss: 3.1424720608752192
Validation loss: 2.526744474208735

Epoch: 5| Step: 2
Training loss: 2.9864374992744707
Validation loss: 2.5085240782098897

Epoch: 5| Step: 3
Training loss: 2.396327877142293
Validation loss: 2.5257932506351413

Epoch: 5| Step: 4
Training loss: 2.3727877502878885
Validation loss: 2.5655564159295223

Epoch: 5| Step: 5
Training loss: 2.0296433183355904
Validation loss: 2.539471621686342

Epoch: 5| Step: 6
Training loss: 2.895926073816838
Validation loss: 2.5269780826805746

Epoch: 5| Step: 7
Training loss: 2.3208533276484817
Validation loss: 2.5240336353115076

Epoch: 5| Step: 8
Training loss: 1.9808793404125333
Validation loss: 2.5092733168544887

Epoch: 5| Step: 9
Training loss: 2.142734462768495
Validation loss: 2.548400931115046

Epoch: 5| Step: 10
Training loss: 2.373467703973024
Validation loss: 2.5600125785423757

Epoch: 400| Step: 0
Training loss: 1.9169411946382633
Validation loss: 2.521641599564461

Epoch: 5| Step: 1
Training loss: 2.4266357882424994
Validation loss: 2.5256186327804637

Epoch: 5| Step: 2
Training loss: 3.0075924483222587
Validation loss: 2.548302680677149

Epoch: 5| Step: 3
Training loss: 2.0796904439926807
Validation loss: 2.5504388355598424

Epoch: 5| Step: 4
Training loss: 2.4938540252940022
Validation loss: 2.553047985984292

Epoch: 5| Step: 5
Training loss: 2.9359610564224283
Validation loss: 2.4915270592949406

Epoch: 5| Step: 6
Training loss: 2.2717994477986094
Validation loss: 2.5297716057662836

Epoch: 5| Step: 7
Training loss: 2.260431691015797
Validation loss: 2.5344590446065527

Epoch: 5| Step: 8
Training loss: 2.7749730117447746
Validation loss: 2.496027201720043

Epoch: 5| Step: 9
Training loss: 2.1143864757689865
Validation loss: 2.538476973574979

Epoch: 5| Step: 10
Training loss: 2.4498907259491793
Validation loss: 2.531145505623236

Epoch: 401| Step: 0
Training loss: 2.606735630667859
Validation loss: 2.5491360969387826

Epoch: 5| Step: 1
Training loss: 2.289381402100722
Validation loss: 2.4999412755324344

Epoch: 5| Step: 2
Training loss: 1.9401165306840893
Validation loss: 2.5541890287016753

Epoch: 5| Step: 3
Training loss: 3.274132848189391
Validation loss: 2.519648366401546

Epoch: 5| Step: 4
Training loss: 2.2063653802284326
Validation loss: 2.518590760653502

Epoch: 5| Step: 5
Training loss: 2.505334408152649
Validation loss: 2.5269422996994377

Epoch: 5| Step: 6
Training loss: 2.2072078667923924
Validation loss: 2.5212799065871496

Epoch: 5| Step: 7
Training loss: 2.832712236282822
Validation loss: 2.5245130999712453

Epoch: 5| Step: 8
Training loss: 2.1029408979396096
Validation loss: 2.5207280393200744

Epoch: 5| Step: 9
Training loss: 2.4627790070303672
Validation loss: 2.5187892112691515

Epoch: 5| Step: 10
Training loss: 2.458613579072802
Validation loss: 2.569614942489171

Epoch: 402| Step: 0
Training loss: 2.0459752325607945
Validation loss: 2.5218607921326934

Epoch: 5| Step: 1
Training loss: 2.1267380058297434
Validation loss: 2.5420369148058026

Epoch: 5| Step: 2
Training loss: 2.2705793209505525
Validation loss: 2.5178444178167703

Epoch: 5| Step: 3
Training loss: 2.980155478396226
Validation loss: 2.5581872254676097

Epoch: 5| Step: 4
Training loss: 2.116725068775978
Validation loss: 2.5350505716388936

Epoch: 5| Step: 5
Training loss: 2.546255305438725
Validation loss: 2.4954324343374044

Epoch: 5| Step: 6
Training loss: 2.473965700372803
Validation loss: 2.5207932815753145

Epoch: 5| Step: 7
Training loss: 2.576762168647544
Validation loss: 2.5263027964935025

Epoch: 5| Step: 8
Training loss: 2.26840113540134
Validation loss: 2.515612692456669

Epoch: 5| Step: 9
Training loss: 2.7360600102574915
Validation loss: 2.542965423172004

Epoch: 5| Step: 10
Training loss: 2.7776145749362335
Validation loss: 2.53007827593601

Epoch: 403| Step: 0
Training loss: 3.447381537976873
Validation loss: 2.478825102436848

Epoch: 5| Step: 1
Training loss: 2.027155931772988
Validation loss: 2.520339530663211

Epoch: 5| Step: 2
Training loss: 2.5364391683889727
Validation loss: 2.5161674040619313

Epoch: 5| Step: 3
Training loss: 2.187296176678906
Validation loss: 2.490619190779685

Epoch: 5| Step: 4
Training loss: 2.4193513581035555
Validation loss: 2.5210808893691734

Epoch: 5| Step: 5
Training loss: 2.2895554151791186
Validation loss: 2.526731435521544

Epoch: 5| Step: 6
Training loss: 2.6823731246480205
Validation loss: 2.5324478262502703

Epoch: 5| Step: 7
Training loss: 2.1496365617034217
Validation loss: 2.4821527528076017

Epoch: 5| Step: 8
Training loss: 2.1387947221424395
Validation loss: 2.5086816398375182

Epoch: 5| Step: 9
Training loss: 2.1917673177294934
Validation loss: 2.541538189552974

Epoch: 5| Step: 10
Training loss: 2.884616194504844
Validation loss: 2.5303543280591083

Epoch: 404| Step: 0
Training loss: 2.6880082825237914
Validation loss: 2.5072277129560483

Epoch: 5| Step: 1
Training loss: 2.474243715122362
Validation loss: 2.497519256978406

Epoch: 5| Step: 2
Training loss: 1.9343878454419703
Validation loss: 2.536230882918208

Epoch: 5| Step: 3
Training loss: 2.1134247510774538
Validation loss: 2.5267452382041156

Epoch: 5| Step: 4
Training loss: 2.3733841267876032
Validation loss: 2.4817561972209905

Epoch: 5| Step: 5
Training loss: 2.7748410394177294
Validation loss: 2.570257659136556

Epoch: 5| Step: 6
Training loss: 2.290678215709759
Validation loss: 2.5505487522336585

Epoch: 5| Step: 7
Training loss: 2.483685667743562
Validation loss: 2.560991192691994

Epoch: 5| Step: 8
Training loss: 2.6550256038947015
Validation loss: 2.496840638236354

Epoch: 5| Step: 9
Training loss: 2.5915792182650828
Validation loss: 2.5547897540679316

Epoch: 5| Step: 10
Training loss: 2.5736965176480333
Validation loss: 2.5414990029055198

Epoch: 405| Step: 0
Training loss: 1.9880155074744725
Validation loss: 2.5270401312850357

Epoch: 5| Step: 1
Training loss: 2.0542084458173147
Validation loss: 2.524963278286653

Epoch: 5| Step: 2
Training loss: 2.6547577200365207
Validation loss: 2.516492094586014

Epoch: 5| Step: 3
Training loss: 2.7964071383296067
Validation loss: 2.5593979179907507

Epoch: 5| Step: 4
Training loss: 3.1799353800511843
Validation loss: 2.5641778734583935

Epoch: 5| Step: 5
Training loss: 2.6279975488265173
Validation loss: 2.489064655875037

Epoch: 5| Step: 6
Training loss: 2.262219414778997
Validation loss: 2.590505530488266

Epoch: 5| Step: 7
Training loss: 2.537050547516122
Validation loss: 2.481357818787775

Epoch: 5| Step: 8
Training loss: 2.180221874950169
Validation loss: 2.5390031144712397

Epoch: 5| Step: 9
Training loss: 2.1744257815692913
Validation loss: 2.5101364613189268

Epoch: 5| Step: 10
Training loss: 2.322425573694262
Validation loss: 2.5474770415254544

Epoch: 406| Step: 0
Training loss: 2.4804948940551346
Validation loss: 2.5453933350766245

Epoch: 5| Step: 1
Training loss: 1.8414013661452124
Validation loss: 2.549216180785471

Epoch: 5| Step: 2
Training loss: 2.1881911139700123
Validation loss: 2.4888392643564163

Epoch: 5| Step: 3
Training loss: 2.023001723329769
Validation loss: 2.5022985290029287

Epoch: 5| Step: 4
Training loss: 2.9080847414412325
Validation loss: 2.52925351171792

Epoch: 5| Step: 5
Training loss: 2.7364489728121084
Validation loss: 2.5014338232237328

Epoch: 5| Step: 6
Training loss: 2.735764853249524
Validation loss: 2.547602775185018

Epoch: 5| Step: 7
Training loss: 2.2720294800175562
Validation loss: 2.511467316337873

Epoch: 5| Step: 8
Training loss: 2.681829280565804
Validation loss: 2.512299832924336

Epoch: 5| Step: 9
Training loss: 2.63439812157961
Validation loss: 2.4855171994087697

Epoch: 5| Step: 10
Training loss: 2.2086233152577086
Validation loss: 2.500702090787419

Epoch: 407| Step: 0
Training loss: 2.397746530214722
Validation loss: 2.5394579386514584

Epoch: 5| Step: 1
Training loss: 2.079093305966462
Validation loss: 2.55397604864185

Epoch: 5| Step: 2
Training loss: 2.860078318663949
Validation loss: 2.5243078673964887

Epoch: 5| Step: 3
Training loss: 2.177258960508768
Validation loss: 2.5068676786175996

Epoch: 5| Step: 4
Training loss: 2.3167156250901018
Validation loss: 2.560485432115408

Epoch: 5| Step: 5
Training loss: 2.5253924187626557
Validation loss: 2.4868540319989902

Epoch: 5| Step: 6
Training loss: 2.260969232153303
Validation loss: 2.515667848165437

Epoch: 5| Step: 7
Training loss: 2.282638649714334
Validation loss: 2.514802153465174

Epoch: 5| Step: 8
Training loss: 2.41249502705274
Validation loss: 2.5289268604044546

Epoch: 5| Step: 9
Training loss: 3.1394529670391584
Validation loss: 2.499247218180624

Epoch: 5| Step: 10
Training loss: 2.5982272560271555
Validation loss: 2.513928036122543

Epoch: 408| Step: 0
Training loss: 2.2994301006976454
Validation loss: 2.529213245292231

Epoch: 5| Step: 1
Training loss: 2.7756345830939613
Validation loss: 2.5473786865165575

Epoch: 5| Step: 2
Training loss: 3.029954299078518
Validation loss: 2.5369410161162693

Epoch: 5| Step: 3
Training loss: 1.818379501411676
Validation loss: 2.5269398313642037

Epoch: 5| Step: 4
Training loss: 2.6633788543299457
Validation loss: 2.5292363271570255

Epoch: 5| Step: 5
Training loss: 2.6466449083575716
Validation loss: 2.5207872151775246

Epoch: 5| Step: 6
Training loss: 2.856894829747379
Validation loss: 2.572027153211625

Epoch: 5| Step: 7
Training loss: 2.6776793493047055
Validation loss: 2.559184284535102

Epoch: 5| Step: 8
Training loss: 2.1254233892180303
Validation loss: 2.5847891622991814

Epoch: 5| Step: 9
Training loss: 1.8340482040526684
Validation loss: 2.519719406470269

Epoch: 5| Step: 10
Training loss: 2.123065741349015
Validation loss: 2.544009041308285

Epoch: 409| Step: 0
Training loss: 2.714250195062888
Validation loss: 2.5508731191755785

Epoch: 5| Step: 1
Training loss: 2.3070012262123663
Validation loss: 2.5599948133395576

Epoch: 5| Step: 2
Training loss: 2.474493757164897
Validation loss: 2.571047488834842

Epoch: 5| Step: 3
Training loss: 2.233801494702879
Validation loss: 2.520882831705504

Epoch: 5| Step: 4
Training loss: 2.2567231081163994
Validation loss: 2.525625827476728

Epoch: 5| Step: 5
Training loss: 2.8272408636662143
Validation loss: 2.512415091562907

Epoch: 5| Step: 6
Training loss: 2.7057559049066593
Validation loss: 2.514603316828859

Epoch: 5| Step: 7
Training loss: 2.8933641806802437
Validation loss: 2.546969800219403

Epoch: 5| Step: 8
Training loss: 2.2418513561115443
Validation loss: 2.530735401088591

Epoch: 5| Step: 9
Training loss: 2.344696565854822
Validation loss: 2.541659868218824

Epoch: 5| Step: 10
Training loss: 2.0386535702183473
Validation loss: 2.519856635861508

Epoch: 410| Step: 0
Training loss: 1.9666414019475869
Validation loss: 2.5499967438324953

Epoch: 5| Step: 1
Training loss: 2.263858606438907
Validation loss: 2.5244219232664795

Epoch: 5| Step: 2
Training loss: 2.872537968503317
Validation loss: 2.516927689715835

Epoch: 5| Step: 3
Training loss: 2.1518458848103172
Validation loss: 2.4624501496620264

Epoch: 5| Step: 4
Training loss: 2.470416701530173
Validation loss: 2.496732829839211

Epoch: 5| Step: 5
Training loss: 2.337801900532903
Validation loss: 2.540816534224787

Epoch: 5| Step: 6
Training loss: 2.5484569293883044
Validation loss: 2.533194532974476

Epoch: 5| Step: 7
Training loss: 2.533639980462525
Validation loss: 2.552444141859011

Epoch: 5| Step: 8
Training loss: 2.563179670307533
Validation loss: 2.547903095365141

Epoch: 5| Step: 9
Training loss: 2.778586923581955
Validation loss: 2.550250219317453

Epoch: 5| Step: 10
Training loss: 2.3805432129278694
Validation loss: 2.5334099563167936

Epoch: 411| Step: 0
Training loss: 2.571115478497995
Validation loss: 2.5005612430420237

Epoch: 5| Step: 1
Training loss: 2.374696913001612
Validation loss: 2.4942628120658585

Epoch: 5| Step: 2
Training loss: 2.418771539636559
Validation loss: 2.5494913784282955

Epoch: 5| Step: 3
Training loss: 1.9188866060318603
Validation loss: 2.539722806453815

Epoch: 5| Step: 4
Training loss: 1.919364592195724
Validation loss: 2.523216279261003

Epoch: 5| Step: 5
Training loss: 1.9279689781336606
Validation loss: 2.5392382549734833

Epoch: 5| Step: 6
Training loss: 3.472044608765675
Validation loss: 2.522227516436493

Epoch: 5| Step: 7
Training loss: 2.393263812777703
Validation loss: 2.512829159854823

Epoch: 5| Step: 8
Training loss: 2.936900950282876
Validation loss: 2.5415626543597454

Epoch: 5| Step: 9
Training loss: 2.2294455618208215
Validation loss: 2.5189920957470826

Epoch: 5| Step: 10
Training loss: 2.455591504690659
Validation loss: 2.53666717652616

Epoch: 412| Step: 0
Training loss: 1.7407019058852633
Validation loss: 2.531135818820996

Epoch: 5| Step: 1
Training loss: 2.6241197472556417
Validation loss: 2.56284511232096

Epoch: 5| Step: 2
Training loss: 2.2791473941115994
Validation loss: 2.5424823185172225

Epoch: 5| Step: 3
Training loss: 2.6382005384918767
Validation loss: 2.524202497590211

Epoch: 5| Step: 4
Training loss: 2.877928030623887
Validation loss: 2.5256858234213517

Epoch: 5| Step: 5
Training loss: 2.1930791280085047
Validation loss: 2.4732414288899727

Epoch: 5| Step: 6
Training loss: 2.463818997559353
Validation loss: 2.529698392478024

Epoch: 5| Step: 7
Training loss: 2.1552613797734193
Validation loss: 2.5603299490394784

Epoch: 5| Step: 8
Training loss: 2.6254177669330523
Validation loss: 2.5480936319402945

Epoch: 5| Step: 9
Training loss: 2.561187407965435
Validation loss: 2.4721738791300876

Epoch: 5| Step: 10
Training loss: 2.5669940525011294
Validation loss: 2.526442972234106

Epoch: 413| Step: 0
Training loss: 2.5488598350218568
Validation loss: 2.5436680302672485

Epoch: 5| Step: 1
Training loss: 2.2206406395809952
Validation loss: 2.48579038996048

Epoch: 5| Step: 2
Training loss: 1.9374078297995252
Validation loss: 2.5134075054552394

Epoch: 5| Step: 3
Training loss: 2.573539771692276
Validation loss: 2.5147333181989326

Epoch: 5| Step: 4
Training loss: 2.572025366057376
Validation loss: 2.5506115642296185

Epoch: 5| Step: 5
Training loss: 2.2377860967908068
Validation loss: 2.501646600951196

Epoch: 5| Step: 6
Training loss: 2.530544323924776
Validation loss: 2.5390659874323394

Epoch: 5| Step: 7
Training loss: 2.1673693128916343
Validation loss: 2.5349954685294382

Epoch: 5| Step: 8
Training loss: 2.3950750284249276
Validation loss: 2.532801598322633

Epoch: 5| Step: 9
Training loss: 2.5572977991801045
Validation loss: 2.5171967207024277

Epoch: 5| Step: 10
Training loss: 3.113405155793819
Validation loss: 2.5764897544769862

Epoch: 414| Step: 0
Training loss: 2.604486603475219
Validation loss: 2.4727464299269135

Epoch: 5| Step: 1
Training loss: 2.8637573345994536
Validation loss: 2.502568921625745

Epoch: 5| Step: 2
Training loss: 2.1402935133392775
Validation loss: 2.555814959563811

Epoch: 5| Step: 3
Training loss: 2.119104397371788
Validation loss: 2.5125199302601597

Epoch: 5| Step: 4
Training loss: 1.7945705065753388
Validation loss: 2.538086925346793

Epoch: 5| Step: 5
Training loss: 2.2619061697092673
Validation loss: 2.504160085965693

Epoch: 5| Step: 6
Training loss: 2.311032422368576
Validation loss: 2.563886066002174

Epoch: 5| Step: 7
Training loss: 2.462621978217298
Validation loss: 2.5403364531097066

Epoch: 5| Step: 8
Training loss: 3.2760191867625155
Validation loss: 2.5465612771269277

Epoch: 5| Step: 9
Training loss: 2.532606726729476
Validation loss: 2.57526059742072

Epoch: 5| Step: 10
Training loss: 2.3036964483965723
Validation loss: 2.541671670888261

Epoch: 415| Step: 0
Training loss: 2.517636081688403
Validation loss: 2.575235567748071

Epoch: 5| Step: 1
Training loss: 2.0222133630458368
Validation loss: 2.4814590772890526

Epoch: 5| Step: 2
Training loss: 2.821639322132239
Validation loss: 2.502353139117477

Epoch: 5| Step: 3
Training loss: 2.464035651351577
Validation loss: 2.4952241420529058

Epoch: 5| Step: 4
Training loss: 1.7614212630792874
Validation loss: 2.5245938003902793

Epoch: 5| Step: 5
Training loss: 2.645685887671313
Validation loss: 2.5199661376866955

Epoch: 5| Step: 6
Training loss: 2.218566886975108
Validation loss: 2.5328679698728376

Epoch: 5| Step: 7
Training loss: 2.3835718164525717
Validation loss: 2.54865001168817

Epoch: 5| Step: 8
Training loss: 2.37281558318574
Validation loss: 2.519110564265585

Epoch: 5| Step: 9
Training loss: 2.7968631509711037
Validation loss: 2.53733110106708

Epoch: 5| Step: 10
Training loss: 2.489116151354794
Validation loss: 2.5654527303158745

Epoch: 416| Step: 0
Training loss: 2.918712516070201
Validation loss: 2.510039465136036

Epoch: 5| Step: 1
Training loss: 2.8596026220555357
Validation loss: 2.519208947276631

Epoch: 5| Step: 2
Training loss: 2.451400539477372
Validation loss: 2.544960011172646

Epoch: 5| Step: 3
Training loss: 1.8183539991780766
Validation loss: 2.5143276531124124

Epoch: 5| Step: 4
Training loss: 2.410367044538693
Validation loss: 2.5002580283942515

Epoch: 5| Step: 5
Training loss: 2.108494440590194
Validation loss: 2.5258767357786285

Epoch: 5| Step: 6
Training loss: 2.3835380075063917
Validation loss: 2.54280495047162

Epoch: 5| Step: 7
Training loss: 2.3111810789256086
Validation loss: 2.4888479889046167

Epoch: 5| Step: 8
Training loss: 2.7974114782596304
Validation loss: 2.4951954953925477

Epoch: 5| Step: 9
Training loss: 2.1981627942682
Validation loss: 2.4748797618570717

Epoch: 5| Step: 10
Training loss: 2.327493466737881
Validation loss: 2.4889288548435005

Epoch: 417| Step: 0
Training loss: 2.0963898144330977
Validation loss: 2.5167973973036664

Epoch: 5| Step: 1
Training loss: 2.7809623826715506
Validation loss: 2.5582598559392564

Epoch: 5| Step: 2
Training loss: 2.059038667898415
Validation loss: 2.5159414911766116

Epoch: 5| Step: 3
Training loss: 2.8230182211838857
Validation loss: 2.4895413083225297

Epoch: 5| Step: 4
Training loss: 2.817102523427651
Validation loss: 2.5187517048115398

Epoch: 5| Step: 5
Training loss: 2.737109925509703
Validation loss: 2.542432126781929

Epoch: 5| Step: 6
Training loss: 2.3433307527045866
Validation loss: 2.449608776205425

Epoch: 5| Step: 7
Training loss: 2.053881701137348
Validation loss: 2.505666760473073

Epoch: 5| Step: 8
Training loss: 2.03701269957264
Validation loss: 2.545926710009773

Epoch: 5| Step: 9
Training loss: 2.312736086779528
Validation loss: 2.5351177246588534

Epoch: 5| Step: 10
Training loss: 2.00097549013972
Validation loss: 2.5323637286224687

Epoch: 418| Step: 0
Training loss: 2.849163561768433
Validation loss: 2.5218026636494417

Epoch: 5| Step: 1
Training loss: 2.160950223343271
Validation loss: 2.4818555744723483

Epoch: 5| Step: 2
Training loss: 1.8301971299145714
Validation loss: 2.547974155601079

Epoch: 5| Step: 3
Training loss: 2.6503354813890847
Validation loss: 2.481120405767163

Epoch: 5| Step: 4
Training loss: 2.4492559354109966
Validation loss: 2.487539866492768

Epoch: 5| Step: 5
Training loss: 2.4433276618832718
Validation loss: 2.503265654193014

Epoch: 5| Step: 6
Training loss: 2.485226659128139
Validation loss: 2.4682777527359687

Epoch: 5| Step: 7
Training loss: 1.744005563254626
Validation loss: 2.550884145063309

Epoch: 5| Step: 8
Training loss: 2.4212052926744776
Validation loss: 2.4372576794785363

Epoch: 5| Step: 9
Training loss: 2.7467463058512114
Validation loss: 2.506911252203649

Epoch: 5| Step: 10
Training loss: 2.6219660164604326
Validation loss: 2.509382458097774

Epoch: 419| Step: 0
Training loss: 1.6738598886189056
Validation loss: 2.508071478670578

Epoch: 5| Step: 1
Training loss: 2.6918207964943455
Validation loss: 2.5603424531568058

Epoch: 5| Step: 2
Training loss: 2.4955676842271455
Validation loss: 2.535109679132185

Epoch: 5| Step: 3
Training loss: 1.8350490287030863
Validation loss: 2.52989063452793

Epoch: 5| Step: 4
Training loss: 2.5067834376806815
Validation loss: 2.49427871488215

Epoch: 5| Step: 5
Training loss: 2.4933467070412956
Validation loss: 2.497661425853731

Epoch: 5| Step: 6
Training loss: 2.059937011718692
Validation loss: 2.6078964700498375

Epoch: 5| Step: 7
Training loss: 2.7153865134431445
Validation loss: 2.519553873148646

Epoch: 5| Step: 8
Training loss: 2.647151488508505
Validation loss: 2.522788121165013

Epoch: 5| Step: 9
Training loss: 2.572031762130183
Validation loss: 2.546423347508665

Epoch: 5| Step: 10
Training loss: 2.5721870242356957
Validation loss: 2.534356528630687

Epoch: 420| Step: 0
Training loss: 2.2856039016329825
Validation loss: 2.4965481492555273

Epoch: 5| Step: 1
Training loss: 2.2147957394625593
Validation loss: 2.5598557628210696

Epoch: 5| Step: 2
Training loss: 2.7708295568760732
Validation loss: 2.513877835163797

Epoch: 5| Step: 3
Training loss: 2.1667317478480275
Validation loss: 2.525965664203032

Epoch: 5| Step: 4
Training loss: 1.9258079913838073
Validation loss: 2.545632981614887

Epoch: 5| Step: 5
Training loss: 2.5816036914937355
Validation loss: 2.529677907173616

Epoch: 5| Step: 6
Training loss: 2.125161557507526
Validation loss: 2.517480784169329

Epoch: 5| Step: 7
Training loss: 1.9302045615897578
Validation loss: 2.5783521346455323

Epoch: 5| Step: 8
Training loss: 2.7516413905343935
Validation loss: 2.514441071261579

Epoch: 5| Step: 9
Training loss: 2.8911284137233806
Validation loss: 2.5153951201654956

Epoch: 5| Step: 10
Training loss: 2.931393871558785
Validation loss: 2.523132875769734

Epoch: 421| Step: 0
Training loss: 1.691202904721475
Validation loss: 2.50284689552192

Epoch: 5| Step: 1
Training loss: 2.1655905936894717
Validation loss: 2.5242677023478435

Epoch: 5| Step: 2
Training loss: 2.2859245378148922
Validation loss: 2.51977531978794

Epoch: 5| Step: 3
Training loss: 3.0940012203675265
Validation loss: 2.528460990822829

Epoch: 5| Step: 4
Training loss: 2.3719577377825813
Validation loss: 2.55587832219925

Epoch: 5| Step: 5
Training loss: 2.244181739689461
Validation loss: 2.549352824979368

Epoch: 5| Step: 6
Training loss: 2.374164936426116
Validation loss: 2.558511430621126

Epoch: 5| Step: 7
Training loss: 2.7842751670262396
Validation loss: 2.526368365628856

Epoch: 5| Step: 8
Training loss: 2.5862133420666584
Validation loss: 2.5018734803154845

Epoch: 5| Step: 9
Training loss: 2.422892793476009
Validation loss: 2.5436850709699486

Epoch: 5| Step: 10
Training loss: 2.0248955735019143
Validation loss: 2.5367480723993503

Epoch: 422| Step: 0
Training loss: 2.7025666294124138
Validation loss: 2.533990856530315

Epoch: 5| Step: 1
Training loss: 3.05484172304898
Validation loss: 2.5482672972380898

Epoch: 5| Step: 2
Training loss: 1.8353097045191242
Validation loss: 2.548349101487014

Epoch: 5| Step: 3
Training loss: 2.318712087151621
Validation loss: 2.539077571448691

Epoch: 5| Step: 4
Training loss: 2.629642015178249
Validation loss: 2.549696180592795

Epoch: 5| Step: 5
Training loss: 2.424854242722582
Validation loss: 2.5295407139878314

Epoch: 5| Step: 6
Training loss: 1.811982837427304
Validation loss: 2.5160536709409684

Epoch: 5| Step: 7
Training loss: 2.162272901131702
Validation loss: 2.5036463274705105

Epoch: 5| Step: 8
Training loss: 2.352877936495094
Validation loss: 2.531773225361965

Epoch: 5| Step: 9
Training loss: 2.37928395647479
Validation loss: 2.5057328430041452

Epoch: 5| Step: 10
Training loss: 2.614556017323899
Validation loss: 2.531194392821124

Epoch: 423| Step: 0
Training loss: 2.4734532426247577
Validation loss: 2.5559969014969

Epoch: 5| Step: 1
Training loss: 2.48166676823821
Validation loss: 2.519621156330243

Epoch: 5| Step: 2
Training loss: 2.1083705064514553
Validation loss: 2.506272105200126

Epoch: 5| Step: 3
Training loss: 2.685743867064825
Validation loss: 2.5004150569063217

Epoch: 5| Step: 4
Training loss: 2.1017606847406847
Validation loss: 2.4935974253706816

Epoch: 5| Step: 5
Training loss: 2.9872006126648367
Validation loss: 2.5257701992202475

Epoch: 5| Step: 6
Training loss: 2.495952572359747
Validation loss: 2.5147913914209066

Epoch: 5| Step: 7
Training loss: 1.8750190098116744
Validation loss: 2.511935212924841

Epoch: 5| Step: 8
Training loss: 2.450897371643816
Validation loss: 2.516370238606894

Epoch: 5| Step: 9
Training loss: 2.019553562535409
Validation loss: 2.522937244155133

Epoch: 5| Step: 10
Training loss: 2.729027276204395
Validation loss: 2.498849901611467

Epoch: 424| Step: 0
Training loss: 2.2943066620527857
Validation loss: 2.5352137249548927

Epoch: 5| Step: 1
Training loss: 2.5713699160047123
Validation loss: 2.508539476210348

Epoch: 5| Step: 2
Training loss: 2.7982200073717864
Validation loss: 2.508211093134744

Epoch: 5| Step: 3
Training loss: 2.478277148354065
Validation loss: 2.5215927477809856

Epoch: 5| Step: 4
Training loss: 2.139295401757084
Validation loss: 2.5134302949006098

Epoch: 5| Step: 5
Training loss: 2.1365944444389355
Validation loss: 2.524404096997278

Epoch: 5| Step: 6
Training loss: 2.6102911888302076
Validation loss: 2.508822850197848

Epoch: 5| Step: 7
Training loss: 2.7921923431883884
Validation loss: 2.535453555091491

Epoch: 5| Step: 8
Training loss: 1.9119184669524174
Validation loss: 2.547890077418212

Epoch: 5| Step: 9
Training loss: 2.249143755432026
Validation loss: 2.5374967542419737

Epoch: 5| Step: 10
Training loss: 2.416767173080223
Validation loss: 2.507728646049862

Epoch: 425| Step: 0
Training loss: 2.455986734894955
Validation loss: 2.50525008495913

Epoch: 5| Step: 1
Training loss: 2.211927859366463
Validation loss: 2.5225489476949474

Epoch: 5| Step: 2
Training loss: 2.4360159244110813
Validation loss: 2.516689564701845

Epoch: 5| Step: 3
Training loss: 2.161476545755036
Validation loss: 2.529965224409065

Epoch: 5| Step: 4
Training loss: 2.648395729298181
Validation loss: 2.5302370648316175

Epoch: 5| Step: 5
Training loss: 2.481035495201245
Validation loss: 2.5287538954842

Epoch: 5| Step: 6
Training loss: 2.09528021620444
Validation loss: 2.516439644425764

Epoch: 5| Step: 7
Training loss: 2.1128951476223783
Validation loss: 2.5096409734114205

Epoch: 5| Step: 8
Training loss: 3.102992268746002
Validation loss: 2.4958580848553544

Epoch: 5| Step: 9
Training loss: 2.306559381176657
Validation loss: 2.5305055662749125

Epoch: 5| Step: 10
Training loss: 2.024441149797677
Validation loss: 2.553815624845927

Epoch: 426| Step: 0
Training loss: 2.4563393884754063
Validation loss: 2.5746984816415988

Epoch: 5| Step: 1
Training loss: 2.100677871288432
Validation loss: 2.586434429868154

Epoch: 5| Step: 2
Training loss: 2.9531030401795952
Validation loss: 2.5241817950257133

Epoch: 5| Step: 3
Training loss: 2.369610242221856
Validation loss: 2.5486309521687494

Epoch: 5| Step: 4
Training loss: 2.090785988851556
Validation loss: 2.494769856165807

Epoch: 5| Step: 5
Training loss: 2.125768634684407
Validation loss: 2.5131178953458484

Epoch: 5| Step: 6
Training loss: 2.6253731780230893
Validation loss: 2.5636442857477375

Epoch: 5| Step: 7
Training loss: 2.2264424609569198
Validation loss: 2.5379327842743162

Epoch: 5| Step: 8
Training loss: 2.4268230467841763
Validation loss: 2.541934981792961

Epoch: 5| Step: 9
Training loss: 2.750905668071682
Validation loss: 2.520308564442045

Epoch: 5| Step: 10
Training loss: 1.8487199943124446
Validation loss: 2.5236104524140632

Epoch: 427| Step: 0
Training loss: 2.38107867087626
Validation loss: 2.5260781041418094

Epoch: 5| Step: 1
Training loss: 2.5874887291114543
Validation loss: 2.5156240838406556

Epoch: 5| Step: 2
Training loss: 1.6815905768448944
Validation loss: 2.4998713326927304

Epoch: 5| Step: 3
Training loss: 2.4548937987064217
Validation loss: 2.52781582330831

Epoch: 5| Step: 4
Training loss: 2.0935339745059998
Validation loss: 2.5149732848821693

Epoch: 5| Step: 5
Training loss: 2.2792868332041007
Validation loss: 2.5180432270856854

Epoch: 5| Step: 6
Training loss: 2.2758636637784737
Validation loss: 2.514416790161012

Epoch: 5| Step: 7
Training loss: 2.75535737892265
Validation loss: 2.4906035039149614

Epoch: 5| Step: 8
Training loss: 2.777380405189504
Validation loss: 2.5056016287647314

Epoch: 5| Step: 9
Training loss: 2.481885802630448
Validation loss: 2.537249414956481

Epoch: 5| Step: 10
Training loss: 2.683785910577119
Validation loss: 2.5321815869892474

Epoch: 428| Step: 0
Training loss: 2.2637323300679397
Validation loss: 2.481241113344025

Epoch: 5| Step: 1
Training loss: 2.564638129691417
Validation loss: 2.470426890002361

Epoch: 5| Step: 2
Training loss: 2.2326361018575938
Validation loss: 2.51651230214859

Epoch: 5| Step: 3
Training loss: 2.3584166342465696
Validation loss: 2.521387945509147

Epoch: 5| Step: 4
Training loss: 2.313983853566539
Validation loss: 2.470508877758871

Epoch: 5| Step: 5
Training loss: 2.543253752270406
Validation loss: 2.5049700382012707

Epoch: 5| Step: 6
Training loss: 2.376484457185475
Validation loss: 2.5302262053119

Epoch: 5| Step: 7
Training loss: 2.1422950188986687
Validation loss: 2.580739413675746

Epoch: 5| Step: 8
Training loss: 3.4746852649894584
Validation loss: 2.5513167089767412

Epoch: 5| Step: 9
Training loss: 1.9937683415540846
Validation loss: 2.5293964976572756

Epoch: 5| Step: 10
Training loss: 2.0150063918322334
Validation loss: 2.5339594501070346

Epoch: 429| Step: 0
Training loss: 2.2255240176911846
Validation loss: 2.4934403160512404

Epoch: 5| Step: 1
Training loss: 1.7310015889231565
Validation loss: 2.5161031662071855

Epoch: 5| Step: 2
Training loss: 2.1941115600334262
Validation loss: 2.5398061991205405

Epoch: 5| Step: 3
Training loss: 2.1780183478669364
Validation loss: 2.535150640669081

Epoch: 5| Step: 4
Training loss: 2.4704784668117368
Validation loss: 2.5167456145991034

Epoch: 5| Step: 5
Training loss: 2.1854528384735037
Validation loss: 2.571180983666773

Epoch: 5| Step: 6
Training loss: 2.9519718885866544
Validation loss: 2.493467198534896

Epoch: 5| Step: 7
Training loss: 2.520304054203533
Validation loss: 2.502806158671487

Epoch: 5| Step: 8
Training loss: 2.895453302343142
Validation loss: 2.500352088171701

Epoch: 5| Step: 9
Training loss: 2.4573420341690912
Validation loss: 2.50985437862464

Epoch: 5| Step: 10
Training loss: 2.3869157325882995
Validation loss: 2.5631159370555134

Epoch: 430| Step: 0
Training loss: 2.6768053754097
Validation loss: 2.5263640579974256

Epoch: 5| Step: 1
Training loss: 1.9040979212977416
Validation loss: 2.546152336084106

Epoch: 5| Step: 2
Training loss: 2.7644694009937534
Validation loss: 2.550486392016891

Epoch: 5| Step: 3
Training loss: 2.2791004243344917
Validation loss: 2.520328713940826

Epoch: 5| Step: 4
Training loss: 2.548838601511036
Validation loss: 2.4945658988528856

Epoch: 5| Step: 5
Training loss: 2.691464095469856
Validation loss: 2.518104199324661

Epoch: 5| Step: 6
Training loss: 2.4569059743313995
Validation loss: 2.4449338352764673

Epoch: 5| Step: 7
Training loss: 2.261076050199364
Validation loss: 2.524808623360338

Epoch: 5| Step: 8
Training loss: 2.0391285618863355
Validation loss: 2.5152569981061226

Epoch: 5| Step: 9
Training loss: 2.334659698978457
Validation loss: 2.5404043327552754

Epoch: 5| Step: 10
Training loss: 2.3038196028711195
Validation loss: 2.4762787471803636

Epoch: 431| Step: 0
Training loss: 2.4983369063881367
Validation loss: 2.5119704411928656

Epoch: 5| Step: 1
Training loss: 2.7359299080665473
Validation loss: 2.5315266727263586

Epoch: 5| Step: 2
Training loss: 1.478905650288359
Validation loss: 2.4728228596118393

Epoch: 5| Step: 3
Training loss: 2.057652875521072
Validation loss: 2.521247715469931

Epoch: 5| Step: 4
Training loss: 2.327754868136947
Validation loss: 2.5068603973605996

Epoch: 5| Step: 5
Training loss: 2.475726350492803
Validation loss: 2.5594819166288434

Epoch: 5| Step: 6
Training loss: 2.3460669699863925
Validation loss: 2.4607232623807973

Epoch: 5| Step: 7
Training loss: 2.611161585471005
Validation loss: 2.542096021212302

Epoch: 5| Step: 8
Training loss: 2.676976915512901
Validation loss: 2.500093030736806

Epoch: 5| Step: 9
Training loss: 2.474507149840759
Validation loss: 2.506368663131777

Epoch: 5| Step: 10
Training loss: 2.33671970093203
Validation loss: 2.495387594948879

Epoch: 432| Step: 0
Training loss: 2.3250332983770385
Validation loss: 2.5362683431592914

Epoch: 5| Step: 1
Training loss: 2.552443145507332
Validation loss: 2.5527602429169916

Epoch: 5| Step: 2
Training loss: 2.5511425749662004
Validation loss: 2.5132521608565823

Epoch: 5| Step: 3
Training loss: 2.236428337683711
Validation loss: 2.5066668666835374

Epoch: 5| Step: 4
Training loss: 2.58528862041049
Validation loss: 2.526845815722465

Epoch: 5| Step: 5
Training loss: 2.006206894646207
Validation loss: 2.467552432504425

Epoch: 5| Step: 6
Training loss: 2.5205732689582763
Validation loss: 2.5293061715238396

Epoch: 5| Step: 7
Training loss: 1.9608058809281697
Validation loss: 2.5816863728244117

Epoch: 5| Step: 8
Training loss: 2.4061045416921845
Validation loss: 2.5263056064167553

Epoch: 5| Step: 9
Training loss: 2.6026651147944615
Validation loss: 2.4940003174382115

Epoch: 5| Step: 10
Training loss: 2.360852618809153
Validation loss: 2.4900501699278084

Epoch: 433| Step: 0
Training loss: 2.315363683125815
Validation loss: 2.5284150175407065

Epoch: 5| Step: 1
Training loss: 2.4631560482845343
Validation loss: 2.5338207677262976

Epoch: 5| Step: 2
Training loss: 2.437881831070904
Validation loss: 2.5141399343704993

Epoch: 5| Step: 3
Training loss: 2.807469595305433
Validation loss: 2.5359194280072836

Epoch: 5| Step: 4
Training loss: 2.958473327619638
Validation loss: 2.531180789618621

Epoch: 5| Step: 5
Training loss: 2.54234041341427
Validation loss: 2.559612549211803

Epoch: 5| Step: 6
Training loss: 2.562787016635026
Validation loss: 2.526040504961896

Epoch: 5| Step: 7
Training loss: 2.161244013321871
Validation loss: 2.5028427312681285

Epoch: 5| Step: 8
Training loss: 2.0154615232428434
Validation loss: 2.5347994851933366

Epoch: 5| Step: 9
Training loss: 2.1261183096119756
Validation loss: 2.557944475593957

Epoch: 5| Step: 10
Training loss: 1.7714185607864616
Validation loss: 2.5344750209130082

Epoch: 434| Step: 0
Training loss: 2.30451783671049
Validation loss: 2.5021716724752934

Epoch: 5| Step: 1
Training loss: 2.6331542384735664
Validation loss: 2.549066714951244

Epoch: 5| Step: 2
Training loss: 2.6104210681274362
Validation loss: 2.5280684805393316

Epoch: 5| Step: 3
Training loss: 2.318537588749761
Validation loss: 2.5711496237129214

Epoch: 5| Step: 4
Training loss: 2.1035945101851854
Validation loss: 2.512829445516638

Epoch: 5| Step: 5
Training loss: 2.9324371861903793
Validation loss: 2.504611524307381

Epoch: 5| Step: 6
Training loss: 2.2824179389967987
Validation loss: 2.5499887834543946

Epoch: 5| Step: 7
Training loss: 2.4381793127046416
Validation loss: 2.506410700915141

Epoch: 5| Step: 8
Training loss: 1.8801546450176694
Validation loss: 2.5082461968872676

Epoch: 5| Step: 9
Training loss: 2.0947320257795887
Validation loss: 2.5407814990672626

Epoch: 5| Step: 10
Training loss: 2.793978507235742
Validation loss: 2.5422719839490804

Epoch: 435| Step: 0
Training loss: 2.5162191696286977
Validation loss: 2.494381535229954

Epoch: 5| Step: 1
Training loss: 2.283457589307125
Validation loss: 2.495912801990171

Epoch: 5| Step: 2
Training loss: 2.011134742483232
Validation loss: 2.51618129373177

Epoch: 5| Step: 3
Training loss: 2.048079158303697
Validation loss: 2.536285293079548

Epoch: 5| Step: 4
Training loss: 1.9881055713077198
Validation loss: 2.548090698146849

Epoch: 5| Step: 5
Training loss: 1.7287862274941732
Validation loss: 2.4965792027620743

Epoch: 5| Step: 6
Training loss: 2.557892914511742
Validation loss: 2.5361944390107647

Epoch: 5| Step: 7
Training loss: 2.11400542481736
Validation loss: 2.545272861749371

Epoch: 5| Step: 8
Training loss: 3.549032084724414
Validation loss: 2.553704305805011

Epoch: 5| Step: 9
Training loss: 2.5178054931815845
Validation loss: 2.5268537800181683

Epoch: 5| Step: 10
Training loss: 2.4762508545228505
Validation loss: 2.4884453072895045

Epoch: 436| Step: 0
Training loss: 2.6238325338481365
Validation loss: 2.523654488643271

Epoch: 5| Step: 1
Training loss: 2.208833805689882
Validation loss: 2.498113367937696

Epoch: 5| Step: 2
Training loss: 1.79814182903435
Validation loss: 2.527543876649051

Epoch: 5| Step: 3
Training loss: 2.5161938705285993
Validation loss: 2.539655979108127

Epoch: 5| Step: 4
Training loss: 2.844716169951837
Validation loss: 2.5599978526600555

Epoch: 5| Step: 5
Training loss: 2.4808733752778673
Validation loss: 2.555486735126475

Epoch: 5| Step: 6
Training loss: 2.2178782510114963
Validation loss: 2.5103485805540973

Epoch: 5| Step: 7
Training loss: 2.5224207669263157
Validation loss: 2.518891533882476

Epoch: 5| Step: 8
Training loss: 2.130327614675642
Validation loss: 2.555006373788243

Epoch: 5| Step: 9
Training loss: 2.1582453244601734
Validation loss: 2.485347803710426

Epoch: 5| Step: 10
Training loss: 2.830536546561174
Validation loss: 2.506889308530346

Epoch: 437| Step: 0
Training loss: 2.8154166463125816
Validation loss: 2.5082226694039473

Epoch: 5| Step: 1
Training loss: 2.7498718578654127
Validation loss: 2.555746252911706

Epoch: 5| Step: 2
Training loss: 1.7682147992261552
Validation loss: 2.500769341952038

Epoch: 5| Step: 3
Training loss: 2.3639001965828204
Validation loss: 2.5348470215400973

Epoch: 5| Step: 4
Training loss: 1.4355063504058991
Validation loss: 2.5041366879885487

Epoch: 5| Step: 5
Training loss: 2.5153000900184215
Validation loss: 2.5143069691622597

Epoch: 5| Step: 6
Training loss: 2.4536674531488756
Validation loss: 2.5079357060855285

Epoch: 5| Step: 7
Training loss: 2.3986194057010715
Validation loss: 2.528920082618775

Epoch: 5| Step: 8
Training loss: 2.247957468119204
Validation loss: 2.5262031888345273

Epoch: 5| Step: 9
Training loss: 2.412224325923665
Validation loss: 2.5317709703297284

Epoch: 5| Step: 10
Training loss: 2.6856718720910444
Validation loss: 2.5299244717675533

Epoch: 438| Step: 0
Training loss: 1.929296229922922
Validation loss: 2.5247552259827577

Epoch: 5| Step: 1
Training loss: 2.7085024756409175
Validation loss: 2.5249227352985772

Epoch: 5| Step: 2
Training loss: 2.8465692986208126
Validation loss: 2.5316009460502515

Epoch: 5| Step: 3
Training loss: 2.363748198477766
Validation loss: 2.5595200502052347

Epoch: 5| Step: 4
Training loss: 2.604329238903356
Validation loss: 2.5434052092302233

Epoch: 5| Step: 5
Training loss: 1.7485927645800072
Validation loss: 2.569656279823395

Epoch: 5| Step: 6
Training loss: 2.3357049832673353
Validation loss: 2.5819827276224854

Epoch: 5| Step: 7
Training loss: 1.9137092108587412
Validation loss: 2.5358942273835607

Epoch: 5| Step: 8
Training loss: 2.2273553875392005
Validation loss: 2.482755648560327

Epoch: 5| Step: 9
Training loss: 2.920675919046254
Validation loss: 2.539960185119946

Epoch: 5| Step: 10
Training loss: 2.4523865384017527
Validation loss: 2.5129772400341275

Epoch: 439| Step: 0
Training loss: 2.3473699461770163
Validation loss: 2.526918865128084

Epoch: 5| Step: 1
Training loss: 2.7774345715745388
Validation loss: 2.5439084419748403

Epoch: 5| Step: 2
Training loss: 2.3560300446102036
Validation loss: 2.5265106584473944

Epoch: 5| Step: 3
Training loss: 1.9099309433441582
Validation loss: 2.5367526928638098

Epoch: 5| Step: 4
Training loss: 2.131146013961668
Validation loss: 2.4838510782390784

Epoch: 5| Step: 5
Training loss: 2.7602086018775656
Validation loss: 2.4736917785842873

Epoch: 5| Step: 6
Training loss: 2.253219843758403
Validation loss: 2.5378652097553323

Epoch: 5| Step: 7
Training loss: 2.2759092337505455
Validation loss: 2.53681970886423

Epoch: 5| Step: 8
Training loss: 2.306549044607164
Validation loss: 2.511489904944992

Epoch: 5| Step: 9
Training loss: 2.0046567348102684
Validation loss: 2.5156786757566687

Epoch: 5| Step: 10
Training loss: 2.778974223491964
Validation loss: 2.542631423781234

Epoch: 440| Step: 0
Training loss: 2.498316197793569
Validation loss: 2.5343925731083012

Epoch: 5| Step: 1
Training loss: 2.577550280697532
Validation loss: 2.4994538910503787

Epoch: 5| Step: 2
Training loss: 2.257687469505232
Validation loss: 2.484682464096571

Epoch: 5| Step: 3
Training loss: 2.4411525258783096
Validation loss: 2.534680631323229

Epoch: 5| Step: 4
Training loss: 1.6556095828486594
Validation loss: 2.5143155105143657

Epoch: 5| Step: 5
Training loss: 2.2795593058340677
Validation loss: 2.5706120987891063

Epoch: 5| Step: 6
Training loss: 2.577090061418472
Validation loss: 2.5185285934594512

Epoch: 5| Step: 7
Training loss: 2.676555438012885
Validation loss: 2.5586932048616737

Epoch: 5| Step: 8
Training loss: 2.1383493397986526
Validation loss: 2.4958475759795817

Epoch: 5| Step: 9
Training loss: 2.360481659504254
Validation loss: 2.5464813463701743

Epoch: 5| Step: 10
Training loss: 2.3060527313965937
Validation loss: 2.514860545188198

Epoch: 441| Step: 0
Training loss: 2.4373306802481993
Validation loss: 2.569961553316116

Epoch: 5| Step: 1
Training loss: 3.0609795046110526
Validation loss: 2.5447873169755435

Epoch: 5| Step: 2
Training loss: 1.6788910152832228
Validation loss: 2.506577150276586

Epoch: 5| Step: 3
Training loss: 2.2226676203163693
Validation loss: 2.4853257428843603

Epoch: 5| Step: 4
Training loss: 2.0708369904248536
Validation loss: 2.4926648995063116

Epoch: 5| Step: 5
Training loss: 2.8841701711747083
Validation loss: 2.5322728138325523

Epoch: 5| Step: 6
Training loss: 2.464831272099706
Validation loss: 2.525458375962114

Epoch: 5| Step: 7
Training loss: 2.1102497688820274
Validation loss: 2.5366685044981323

Epoch: 5| Step: 8
Training loss: 2.776776262511681
Validation loss: 2.5169013200905326

Epoch: 5| Step: 9
Training loss: 1.9135705432433123
Validation loss: 2.5069955225913287

Epoch: 5| Step: 10
Training loss: 2.266310279073979
Validation loss: 2.555977860654138

Epoch: 442| Step: 0
Training loss: 2.6371682017108786
Validation loss: 2.554497904856225

Epoch: 5| Step: 1
Training loss: 2.4870616852549974
Validation loss: 2.526945637477321

Epoch: 5| Step: 2
Training loss: 2.2563076614239663
Validation loss: 2.503198262704986

Epoch: 5| Step: 3
Training loss: 2.628540557774825
Validation loss: 2.527746593949051

Epoch: 5| Step: 4
Training loss: 2.0921137095195306
Validation loss: 2.587004809071835

Epoch: 5| Step: 5
Training loss: 2.3518778947482413
Validation loss: 2.487819490791816

Epoch: 5| Step: 6
Training loss: 2.3427877866966256
Validation loss: 2.560541763826823

Epoch: 5| Step: 7
Training loss: 2.470739697573932
Validation loss: 2.560628586305698

Epoch: 5| Step: 8
Training loss: 2.2249157621746476
Validation loss: 2.5566128901199954

Epoch: 5| Step: 9
Training loss: 2.460444712876034
Validation loss: 2.516158109428015

Epoch: 5| Step: 10
Training loss: 2.102927973277025
Validation loss: 2.5505890547318275

Epoch: 443| Step: 0
Training loss: 2.2064752739290894
Validation loss: 2.554850620484599

Epoch: 5| Step: 1
Training loss: 2.608003358616451
Validation loss: 2.5217419739910865

Epoch: 5| Step: 2
Training loss: 2.381667565607427
Validation loss: 2.5142403503103647

Epoch: 5| Step: 3
Training loss: 2.476094006049535
Validation loss: 2.570072534279014

Epoch: 5| Step: 4
Training loss: 2.212468887368969
Validation loss: 2.522082901748118

Epoch: 5| Step: 5
Training loss: 2.7362361132817017
Validation loss: 2.5558666207423157

Epoch: 5| Step: 6
Training loss: 2.4355673341725392
Validation loss: 2.478989434949712

Epoch: 5| Step: 7
Training loss: 1.978963848229082
Validation loss: 2.5185169586977

Epoch: 5| Step: 8
Training loss: 2.4953804250512106
Validation loss: 2.5268423164972176

Epoch: 5| Step: 9
Training loss: 1.8501551305321136
Validation loss: 2.5649394267536163

Epoch: 5| Step: 10
Training loss: 1.8490082711653208
Validation loss: 2.4887583470923698

Epoch: 444| Step: 0
Training loss: 2.7976391137436383
Validation loss: 2.5159756423668074

Epoch: 5| Step: 1
Training loss: 1.8959085079282096
Validation loss: 2.510293834937033

Epoch: 5| Step: 2
Training loss: 2.850634614660186
Validation loss: 2.526291502985676

Epoch: 5| Step: 3
Training loss: 2.3473674069659682
Validation loss: 2.5331741700612143

Epoch: 5| Step: 4
Training loss: 2.0607308400550055
Validation loss: 2.493575832319274

Epoch: 5| Step: 5
Training loss: 2.4653600282037003
Validation loss: 2.5624587493145397

Epoch: 5| Step: 6
Training loss: 2.2171825191127326
Validation loss: 2.4625515500728774

Epoch: 5| Step: 7
Training loss: 1.9767580199507722
Validation loss: 2.5518802731971175

Epoch: 5| Step: 8
Training loss: 2.3805311945357825
Validation loss: 2.520478229602027

Epoch: 5| Step: 9
Training loss: 2.4273401432851585
Validation loss: 2.554588852590575

Epoch: 5| Step: 10
Training loss: 2.3050789193567516
Validation loss: 2.526173416895025

Epoch: 445| Step: 0
Training loss: 2.5644693018220734
Validation loss: 2.5364217889255505

Epoch: 5| Step: 1
Training loss: 2.2525952524585784
Validation loss: 2.4875414381462666

Epoch: 5| Step: 2
Training loss: 2.031386972357464
Validation loss: 2.5107501957302114

Epoch: 5| Step: 3
Training loss: 2.4635895501954614
Validation loss: 2.4962024497192177

Epoch: 5| Step: 4
Training loss: 2.7182334321463606
Validation loss: 2.4985487304402905

Epoch: 5| Step: 5
Training loss: 1.940195177917654
Validation loss: 2.5559288652376337

Epoch: 5| Step: 6
Training loss: 2.6886158777868125
Validation loss: 2.503246600908103

Epoch: 5| Step: 7
Training loss: 2.1833067894795053
Validation loss: 2.5606319893016565

Epoch: 5| Step: 8
Training loss: 2.7500126578299775
Validation loss: 2.524154122447772

Epoch: 5| Step: 9
Training loss: 1.9219962601282927
Validation loss: 2.5393034103361667

Epoch: 5| Step: 10
Training loss: 2.182907624516913
Validation loss: 2.543687202561526

Epoch: 446| Step: 0
Training loss: 2.1536156968603253
Validation loss: 2.5457126932904157

Epoch: 5| Step: 1
Training loss: 2.2125119914791345
Validation loss: 2.554131174753471

Epoch: 5| Step: 2
Training loss: 2.6278743447465946
Validation loss: 2.5091930825643516

Epoch: 5| Step: 3
Training loss: 2.2581229342977247
Validation loss: 2.5492880018845017

Epoch: 5| Step: 4
Training loss: 1.9006625977660725
Validation loss: 2.548178188331637

Epoch: 5| Step: 5
Training loss: 3.241689326608363
Validation loss: 2.5435435736395777

Epoch: 5| Step: 6
Training loss: 2.1526852317797887
Validation loss: 2.4715953933802526

Epoch: 5| Step: 7
Training loss: 2.10021963787439
Validation loss: 2.546698715075094

Epoch: 5| Step: 8
Training loss: 2.089707300598065
Validation loss: 2.50054183441152

Epoch: 5| Step: 9
Training loss: 2.5357621090560456
Validation loss: 2.5386271896342563

Epoch: 5| Step: 10
Training loss: 2.4155976682550326
Validation loss: 2.542721964167125

Epoch: 447| Step: 0
Training loss: 1.9922382423072116
Validation loss: 2.504032058323464

Epoch: 5| Step: 1
Training loss: 1.9698036038826974
Validation loss: 2.515849253847889

Epoch: 5| Step: 2
Training loss: 2.240235545682726
Validation loss: 2.551910316842323

Epoch: 5| Step: 3
Training loss: 2.702619736918757
Validation loss: 2.542556249621641

Epoch: 5| Step: 4
Training loss: 1.9282944937080335
Validation loss: 2.4922767458850394

Epoch: 5| Step: 5
Training loss: 2.6879057467034855
Validation loss: 2.502061928778117

Epoch: 5| Step: 6
Training loss: 2.6366353791796278
Validation loss: 2.4891197777713825

Epoch: 5| Step: 7
Training loss: 2.0896800324671814
Validation loss: 2.541080196048532

Epoch: 5| Step: 8
Training loss: 1.9875862390773829
Validation loss: 2.534887871016886

Epoch: 5| Step: 9
Training loss: 2.655381273813625
Validation loss: 2.4797480397790066

Epoch: 5| Step: 10
Training loss: 2.6781185439398096
Validation loss: 2.558712919832718

Epoch: 448| Step: 0
Training loss: 2.688865137476973
Validation loss: 2.5236502190450536

Epoch: 5| Step: 1
Training loss: 2.9279255769578745
Validation loss: 2.540810123138851

Epoch: 5| Step: 2
Training loss: 1.8835744621843054
Validation loss: 2.5027539999284714

Epoch: 5| Step: 3
Training loss: 1.2862512161797797
Validation loss: 2.502353413681303

Epoch: 5| Step: 4
Training loss: 2.8733721561272607
Validation loss: 2.5632365869098233

Epoch: 5| Step: 5
Training loss: 2.318176930808289
Validation loss: 2.512239542814258

Epoch: 5| Step: 6
Training loss: 1.9313523990680692
Validation loss: 2.5124048070414764

Epoch: 5| Step: 7
Training loss: 2.55177500412789
Validation loss: 2.5126455052334116

Epoch: 5| Step: 8
Training loss: 1.6187196559344879
Validation loss: 2.4774097367467114

Epoch: 5| Step: 9
Training loss: 2.4003435445316788
Validation loss: 2.5677370115029547

Epoch: 5| Step: 10
Training loss: 2.4678701450493556
Validation loss: 2.4653116625865694

Epoch: 449| Step: 0
Training loss: 2.5373582020494885
Validation loss: 2.4819541420732887

Epoch: 5| Step: 1
Training loss: 2.0398366342841947
Validation loss: 2.528786202929394

Epoch: 5| Step: 2
Training loss: 2.4714953452901285
Validation loss: 2.5192482562581175

Epoch: 5| Step: 3
Training loss: 2.027788587509444
Validation loss: 2.516556027596427

Epoch: 5| Step: 4
Training loss: 2.216762673538477
Validation loss: 2.5174087842576856

Epoch: 5| Step: 5
Training loss: 2.1358991372515037
Validation loss: 2.4997980287449857

Epoch: 5| Step: 6
Training loss: 2.026714013993845
Validation loss: 2.551146525221131

Epoch: 5| Step: 7
Training loss: 2.3769902372950127
Validation loss: 2.501173798017852

Epoch: 5| Step: 8
Training loss: 2.719482849269004
Validation loss: 2.533134738146623

Epoch: 5| Step: 9
Training loss: 2.3568411856981943
Validation loss: 2.537326435178842

Epoch: 5| Step: 10
Training loss: 2.7258775610403347
Validation loss: 2.4835527467502994

Epoch: 450| Step: 0
Training loss: 1.6656925295082214
Validation loss: 2.4810692744057987

Epoch: 5| Step: 1
Training loss: 2.709699804423053
Validation loss: 2.537819568461101

Epoch: 5| Step: 2
Training loss: 2.2299718620680475
Validation loss: 2.550824626210892

Epoch: 5| Step: 3
Training loss: 2.6412675967264447
Validation loss: 2.526775085587873

Epoch: 5| Step: 4
Training loss: 2.375204278292068
Validation loss: 2.5325834417496127

Epoch: 5| Step: 5
Training loss: 2.5634441962242445
Validation loss: 2.497972131510337

Epoch: 5| Step: 6
Training loss: 2.5996575240011803
Validation loss: 2.5182745617106455

Epoch: 5| Step: 7
Training loss: 1.7969680762026574
Validation loss: 2.5163890870803964

Epoch: 5| Step: 8
Training loss: 2.35570852599687
Validation loss: 2.5089212003109838

Epoch: 5| Step: 9
Training loss: 2.268462200143305
Validation loss: 2.4964715381377727

Epoch: 5| Step: 10
Training loss: 2.250575415889501
Validation loss: 2.5256689059008997

Epoch: 451| Step: 0
Training loss: 2.668822390715807
Validation loss: 2.4818857509834173

Epoch: 5| Step: 1
Training loss: 1.7754818060932955
Validation loss: 2.494534432839473

Epoch: 5| Step: 2
Training loss: 2.431236239592928
Validation loss: 2.5210857795477915

Epoch: 5| Step: 3
Training loss: 2.108207209839185
Validation loss: 2.5321877971885693

Epoch: 5| Step: 4
Training loss: 2.0176383911467384
Validation loss: 2.537313717609238

Epoch: 5| Step: 5
Training loss: 2.434267394756793
Validation loss: 2.556366881930634

Epoch: 5| Step: 6
Training loss: 2.516181457768491
Validation loss: 2.497090636166194

Epoch: 5| Step: 7
Training loss: 2.3869271195228343
Validation loss: 2.541623519808276

Epoch: 5| Step: 8
Training loss: 2.3896554214880577
Validation loss: 2.5325110173419776

Epoch: 5| Step: 9
Training loss: 2.14500680455549
Validation loss: 2.4733631506585465

Epoch: 5| Step: 10
Training loss: 2.72867255554881
Validation loss: 2.524319804514449

Epoch: 452| Step: 0
Training loss: 2.6481462616705036
Validation loss: 2.5189892959847016

Epoch: 5| Step: 1
Training loss: 2.1598118650661378
Validation loss: 2.517395729295556

Epoch: 5| Step: 2
Training loss: 3.0095495187260273
Validation loss: 2.520248614432896

Epoch: 5| Step: 3
Training loss: 2.282697871343989
Validation loss: 2.5497830868303573

Epoch: 5| Step: 4
Training loss: 2.0917899223375933
Validation loss: 2.5618224580091535

Epoch: 5| Step: 5
Training loss: 2.009978198792002
Validation loss: 2.4996047363783838

Epoch: 5| Step: 6
Training loss: 2.257685779856534
Validation loss: 2.5702000885857283

Epoch: 5| Step: 7
Training loss: 2.13939369596915
Validation loss: 2.493561633215655

Epoch: 5| Step: 8
Training loss: 2.148979645729859
Validation loss: 2.4995577113319416

Epoch: 5| Step: 9
Training loss: 2.2230000154647107
Validation loss: 2.5618704055659958

Epoch: 5| Step: 10
Training loss: 2.7561257366792065
Validation loss: 2.548400939162887

Epoch: 453| Step: 0
Training loss: 2.676152603108977
Validation loss: 2.5046619775214687

Epoch: 5| Step: 1
Training loss: 2.4405215193806544
Validation loss: 2.503813308727104

Epoch: 5| Step: 2
Training loss: 2.1779375605885183
Validation loss: 2.5148323291476076

Epoch: 5| Step: 3
Training loss: 2.308835089602067
Validation loss: 2.488816528884758

Epoch: 5| Step: 4
Training loss: 2.4453910839384694
Validation loss: 2.505062389047564

Epoch: 5| Step: 5
Training loss: 2.068435912476729
Validation loss: 2.5347098350549992

Epoch: 5| Step: 6
Training loss: 1.8124192976249847
Validation loss: 2.5290084326612527

Epoch: 5| Step: 7
Training loss: 1.8374426333237224
Validation loss: 2.533466219155828

Epoch: 5| Step: 8
Training loss: 2.97446205340413
Validation loss: 2.46480684239925

Epoch: 5| Step: 9
Training loss: 2.148110881600309
Validation loss: 2.5353532664621903

Epoch: 5| Step: 10
Training loss: 2.3534843221141832
Validation loss: 2.530999320502759

Epoch: 454| Step: 0
Training loss: 2.066093320173611
Validation loss: 2.550411322731331

Epoch: 5| Step: 1
Training loss: 2.423386723412538
Validation loss: 2.566608725576857

Epoch: 5| Step: 2
Training loss: 2.1517469406026404
Validation loss: 2.500864379922786

Epoch: 5| Step: 3
Training loss: 2.355633326612145
Validation loss: 2.5538544623944976

Epoch: 5| Step: 4
Training loss: 1.8200019931782299
Validation loss: 2.4884465270670737

Epoch: 5| Step: 5
Training loss: 3.0174629263508534
Validation loss: 2.525999122179318

Epoch: 5| Step: 6
Training loss: 2.4278374893251717
Validation loss: 2.5838570720502823

Epoch: 5| Step: 7
Training loss: 1.922425044053227
Validation loss: 2.521647206412948

Epoch: 5| Step: 8
Training loss: 2.5711001780640266
Validation loss: 2.5491382792851094

Epoch: 5| Step: 9
Training loss: 2.519579036762184
Validation loss: 2.556603269729428

Epoch: 5| Step: 10
Training loss: 1.4510549752345547
Validation loss: 2.512822970167462

Epoch: 455| Step: 0
Training loss: 1.6204325970806432
Validation loss: 2.554209114675774

Epoch: 5| Step: 1
Training loss: 2.246466405057399
Validation loss: 2.493420369783854

Epoch: 5| Step: 2
Training loss: 2.400673386360022
Validation loss: 2.52695172155533

Epoch: 5| Step: 3
Training loss: 2.382876235859938
Validation loss: 2.5490025408275576

Epoch: 5| Step: 4
Training loss: 1.9962115766234876
Validation loss: 2.551548716785793

Epoch: 5| Step: 5
Training loss: 2.081555167155056
Validation loss: 2.544374433331854

Epoch: 5| Step: 6
Training loss: 2.7437687414828313
Validation loss: 2.5560117166267857

Epoch: 5| Step: 7
Training loss: 2.430565580317093
Validation loss: 2.551771158324976

Epoch: 5| Step: 8
Training loss: 3.0143214753753753
Validation loss: 2.526540405104582

Epoch: 5| Step: 9
Training loss: 1.980758976785159
Validation loss: 2.5463376273832927

Epoch: 5| Step: 10
Training loss: 2.5702868057404467
Validation loss: 2.53246905040493

Epoch: 456| Step: 0
Training loss: 1.903355511515532
Validation loss: 2.522691823824459

Epoch: 5| Step: 1
Training loss: 2.1642799681317904
Validation loss: 2.53201739995315

Epoch: 5| Step: 2
Training loss: 2.9615722620023175
Validation loss: 2.519134516195288

Epoch: 5| Step: 3
Training loss: 2.5807791255012122
Validation loss: 2.5497496146808913

Epoch: 5| Step: 4
Training loss: 3.0179197445178336
Validation loss: 2.506829220660657

Epoch: 5| Step: 5
Training loss: 2.2035317552744016
Validation loss: 2.520243866057799

Epoch: 5| Step: 6
Training loss: 2.6933728301422435
Validation loss: 2.5452338036111155

Epoch: 5| Step: 7
Training loss: 1.8794785101966816
Validation loss: 2.5272862898154584

Epoch: 5| Step: 8
Training loss: 2.419622345768566
Validation loss: 2.5597457610581715

Epoch: 5| Step: 9
Training loss: 1.776236790950876
Validation loss: 2.5316773872521416

Epoch: 5| Step: 10
Training loss: 1.8272352743386593
Validation loss: 2.4842285672388047

Epoch: 457| Step: 0
Training loss: 2.142784866748983
Validation loss: 2.5573188471696233

Epoch: 5| Step: 1
Training loss: 1.7043989823727546
Validation loss: 2.5043498415756735

Epoch: 5| Step: 2
Training loss: 2.791536831090268
Validation loss: 2.513042992101994

Epoch: 5| Step: 3
Training loss: 1.9133678187719447
Validation loss: 2.5263386534775183

Epoch: 5| Step: 4
Training loss: 3.3076530839781544
Validation loss: 2.509862210937896

Epoch: 5| Step: 5
Training loss: 2.2304326203154154
Validation loss: 2.5269701258782193

Epoch: 5| Step: 6
Training loss: 2.072958813211679
Validation loss: 2.512206400087077

Epoch: 5| Step: 7
Training loss: 2.320944343619467
Validation loss: 2.524426604374041

Epoch: 5| Step: 8
Training loss: 2.161124207435986
Validation loss: 2.503814796445347

Epoch: 5| Step: 9
Training loss: 2.143365039126207
Validation loss: 2.526138773350811

Epoch: 5| Step: 10
Training loss: 2.401205447576477
Validation loss: 2.5050879939830635

Epoch: 458| Step: 0
Training loss: 2.2807763012840656
Validation loss: 2.488144852917085

Epoch: 5| Step: 1
Training loss: 2.1729441693748632
Validation loss: 2.5469534115951182

Epoch: 5| Step: 2
Training loss: 2.9834956126768173
Validation loss: 2.4819129667539612

Epoch: 5| Step: 3
Training loss: 1.9272838247668365
Validation loss: 2.5487109432551156

Epoch: 5| Step: 4
Training loss: 1.8833954094752958
Validation loss: 2.4964315922167413

Epoch: 5| Step: 5
Training loss: 2.074290703568957
Validation loss: 2.5474939188805688

Epoch: 5| Step: 6
Training loss: 2.6482536679723867
Validation loss: 2.510850643090682

Epoch: 5| Step: 7
Training loss: 2.2233137019871596
Validation loss: 2.493067218345988

Epoch: 5| Step: 8
Training loss: 2.298302343195099
Validation loss: 2.5285481980435813

Epoch: 5| Step: 9
Training loss: 2.293132821602841
Validation loss: 2.5581228537270264

Epoch: 5| Step: 10
Training loss: 2.417603004415073
Validation loss: 2.5222305057237766

Epoch: 459| Step: 0
Training loss: 2.135062459706541
Validation loss: 2.5104380212555597

Epoch: 5| Step: 1
Training loss: 2.4116014694895265
Validation loss: 2.5390696697275867

Epoch: 5| Step: 2
Training loss: 1.885507767585691
Validation loss: 2.595639478216322

Epoch: 5| Step: 3
Training loss: 2.5586215185158214
Validation loss: 2.5135820965263047

Epoch: 5| Step: 4
Training loss: 2.2702015922534753
Validation loss: 2.5292744646826812

Epoch: 5| Step: 5
Training loss: 2.6188478583576806
Validation loss: 2.535618892636652

Epoch: 5| Step: 6
Training loss: 2.362953655141987
Validation loss: 2.527715054160192

Epoch: 5| Step: 7
Training loss: 2.1266884547146883
Validation loss: 2.5098988395479376

Epoch: 5| Step: 8
Training loss: 2.280079057728255
Validation loss: 2.509432326042985

Epoch: 5| Step: 9
Training loss: 2.2712445251365265
Validation loss: 2.5585958341019994

Epoch: 5| Step: 10
Training loss: 2.498384144244907
Validation loss: 2.5021704696342324

Epoch: 460| Step: 0
Training loss: 2.319272408669416
Validation loss: 2.502858859198608

Epoch: 5| Step: 1
Training loss: 1.7528040083776246
Validation loss: 2.5103473775461107

Epoch: 5| Step: 2
Training loss: 2.214965494029194
Validation loss: 2.510565346442527

Epoch: 5| Step: 3
Training loss: 2.260191617623706
Validation loss: 2.4955739105485577

Epoch: 5| Step: 4
Training loss: 1.997933452590049
Validation loss: 2.513646704265388

Epoch: 5| Step: 5
Training loss: 2.1750765469114683
Validation loss: 2.5184343920796226

Epoch: 5| Step: 6
Training loss: 2.405508447302808
Validation loss: 2.474967510473773

Epoch: 5| Step: 7
Training loss: 2.690633853981966
Validation loss: 2.4933640710974756

Epoch: 5| Step: 8
Training loss: 3.024089417664477
Validation loss: 2.515644107807945

Epoch: 5| Step: 9
Training loss: 1.9204724784493965
Validation loss: 2.5241888262385346

Epoch: 5| Step: 10
Training loss: 2.3192453724094455
Validation loss: 2.5298700595787933

Epoch: 461| Step: 0
Training loss: 2.727407417439339
Validation loss: 2.4867786098318616

Epoch: 5| Step: 1
Training loss: 2.2091840389014257
Validation loss: 2.5044482844301994

Epoch: 5| Step: 2
Training loss: 2.0339084541477073
Validation loss: 2.4873307823783093

Epoch: 5| Step: 3
Training loss: 2.621206721729431
Validation loss: 2.498581457176893

Epoch: 5| Step: 4
Training loss: 2.345986176881774
Validation loss: 2.532989542284945

Epoch: 5| Step: 5
Training loss: 2.3908433004202316
Validation loss: 2.480744129307582

Epoch: 5| Step: 6
Training loss: 2.1482338548726365
Validation loss: 2.5139789529661556

Epoch: 5| Step: 7
Training loss: 1.9713932639863851
Validation loss: 2.572229605927804

Epoch: 5| Step: 8
Training loss: 2.2322795084949894
Validation loss: 2.5366284457257535

Epoch: 5| Step: 9
Training loss: 2.2634555295262744
Validation loss: 2.518655731538694

Epoch: 5| Step: 10
Training loss: 2.4616388199595085
Validation loss: 2.5293964378585057

Epoch: 462| Step: 0
Training loss: 1.8680174192233134
Validation loss: 2.4872656116651326

Epoch: 5| Step: 1
Training loss: 2.660483632829373
Validation loss: 2.4820697325824255

Epoch: 5| Step: 2
Training loss: 2.186802998262635
Validation loss: 2.575754225477398

Epoch: 5| Step: 3
Training loss: 2.5300895008645945
Validation loss: 2.5322535186710056

Epoch: 5| Step: 4
Training loss: 2.272193174894169
Validation loss: 2.5470689279102046

Epoch: 5| Step: 5
Training loss: 2.4118513826477743
Validation loss: 2.5415270605803006

Epoch: 5| Step: 6
Training loss: 2.03203884359464
Validation loss: 2.5503337985061316

Epoch: 5| Step: 7
Training loss: 2.973593685600549
Validation loss: 2.5384266006396854

Epoch: 5| Step: 8
Training loss: 2.515632771545158
Validation loss: 2.5963771367851516

Epoch: 5| Step: 9
Training loss: 1.7391241537374602
Validation loss: 2.5388080519281253

Epoch: 5| Step: 10
Training loss: 2.1108402390736676
Validation loss: 2.491654544194065

Epoch: 463| Step: 0
Training loss: 2.4200657146768747
Validation loss: 2.563326490502888

Epoch: 5| Step: 1
Training loss: 2.344424138074118
Validation loss: 2.543897323371483

Epoch: 5| Step: 2
Training loss: 1.794875118406244
Validation loss: 2.522717232549933

Epoch: 5| Step: 3
Training loss: 2.2642301277568166
Validation loss: 2.527566145098169

Epoch: 5| Step: 4
Training loss: 2.455586164618386
Validation loss: 2.5643958505121023

Epoch: 5| Step: 5
Training loss: 1.6995028554247633
Validation loss: 2.5030342085892454

Epoch: 5| Step: 6
Training loss: 2.424915398763864
Validation loss: 2.4959969383762752

Epoch: 5| Step: 7
Training loss: 2.8524277301964465
Validation loss: 2.529531370692214

Epoch: 5| Step: 8
Training loss: 2.1802190317133547
Validation loss: 2.5133713222090606

Epoch: 5| Step: 9
Training loss: 1.949872597176004
Validation loss: 2.5231065608357506

Epoch: 5| Step: 10
Training loss: 2.340795154778504
Validation loss: 2.514773460694705

Epoch: 464| Step: 0
Training loss: 2.8822709068448678
Validation loss: 2.4964745459425015

Epoch: 5| Step: 1
Training loss: 2.7286010816185393
Validation loss: 2.4848215201452337

Epoch: 5| Step: 2
Training loss: 2.0658326245186553
Validation loss: 2.4896400926768236

Epoch: 5| Step: 3
Training loss: 2.1820108480349916
Validation loss: 2.5251270508740866

Epoch: 5| Step: 4
Training loss: 1.9791144983209004
Validation loss: 2.52827453134558

Epoch: 5| Step: 5
Training loss: 2.540234855547394
Validation loss: 2.5436611174017316

Epoch: 5| Step: 6
Training loss: 2.3058173045088504
Validation loss: 2.512732074785975

Epoch: 5| Step: 7
Training loss: 2.393021622639394
Validation loss: 2.526472000257755

Epoch: 5| Step: 8
Training loss: 2.2673016888119673
Validation loss: 2.5250229671103432

Epoch: 5| Step: 9
Training loss: 1.8147407361277732
Validation loss: 2.5363584142769167

Epoch: 5| Step: 10
Training loss: 2.302981504941642
Validation loss: 2.4775411464913875

Epoch: 465| Step: 0
Training loss: 1.9635062851150749
Validation loss: 2.5151213178191134

Epoch: 5| Step: 1
Training loss: 2.3152361997723006
Validation loss: 2.5437515405119777

Epoch: 5| Step: 2
Training loss: 2.271645905121574
Validation loss: 2.5561996259233157

Epoch: 5| Step: 3
Training loss: 2.5559979265529957
Validation loss: 2.51759745015411

Epoch: 5| Step: 4
Training loss: 2.191801691670378
Validation loss: 2.524468112962832

Epoch: 5| Step: 5
Training loss: 2.050321632833538
Validation loss: 2.5158319425726967

Epoch: 5| Step: 6
Training loss: 2.376467803332475
Validation loss: 2.526997114787557

Epoch: 5| Step: 7
Training loss: 2.342522566777233
Validation loss: 2.494267191067657

Epoch: 5| Step: 8
Training loss: 2.6547119175426213
Validation loss: 2.5375230669425677

Epoch: 5| Step: 9
Training loss: 2.4394161811028607
Validation loss: 2.5045921716292163

Epoch: 5| Step: 10
Training loss: 1.8894825786182134
Validation loss: 2.5311462703158956

Epoch: 466| Step: 0
Training loss: 2.691956396030341
Validation loss: 2.496074800651938

Epoch: 5| Step: 1
Training loss: 2.7095826030950976
Validation loss: 2.547264070912946

Epoch: 5| Step: 2
Training loss: 2.522126415251721
Validation loss: 2.4686082098562787

Epoch: 5| Step: 3
Training loss: 2.519749074583568
Validation loss: 2.567745771989828

Epoch: 5| Step: 4
Training loss: 1.9772341947677474
Validation loss: 2.546196696310948

Epoch: 5| Step: 5
Training loss: 2.8042716990540484
Validation loss: 2.5339760087655345

Epoch: 5| Step: 6
Training loss: 2.135761834757595
Validation loss: 2.5092136967941485

Epoch: 5| Step: 7
Training loss: 1.9433251459375633
Validation loss: 2.5248619140113293

Epoch: 5| Step: 8
Training loss: 1.8957611182016463
Validation loss: 2.5168570169905524

Epoch: 5| Step: 9
Training loss: 2.241085087186891
Validation loss: 2.5540633311997487

Epoch: 5| Step: 10
Training loss: 1.6445000797316942
Validation loss: 2.4992880627883842

Epoch: 467| Step: 0
Training loss: 2.217136709909808
Validation loss: 2.5207518823153827

Epoch: 5| Step: 1
Training loss: 2.665572021244118
Validation loss: 2.520756458875443

Epoch: 5| Step: 2
Training loss: 2.265195082290649
Validation loss: 2.523434922579472

Epoch: 5| Step: 3
Training loss: 2.149285832158643
Validation loss: 2.497840146267084

Epoch: 5| Step: 4
Training loss: 2.0914980036402038
Validation loss: 2.5274751469954966

Epoch: 5| Step: 5
Training loss: 2.452778494107449
Validation loss: 2.538888333312935

Epoch: 5| Step: 6
Training loss: 2.5994459368819296
Validation loss: 2.520478400478969

Epoch: 5| Step: 7
Training loss: 2.0196170751755336
Validation loss: 2.532315144425594

Epoch: 5| Step: 8
Training loss: 1.5114716714822138
Validation loss: 2.5146339241020783

Epoch: 5| Step: 9
Training loss: 2.477905005831746
Validation loss: 2.5830439715790634

Epoch: 5| Step: 10
Training loss: 2.1115336357832297
Validation loss: 2.554875894015972

Epoch: 468| Step: 0
Training loss: 2.072162535725152
Validation loss: 2.518383814719176

Epoch: 5| Step: 1
Training loss: 2.141695186657637
Validation loss: 2.528922759876701

Epoch: 5| Step: 2
Training loss: 2.291295131274248
Validation loss: 2.5341699050631368

Epoch: 5| Step: 3
Training loss: 1.8825973451124547
Validation loss: 2.5133859112374566

Epoch: 5| Step: 4
Training loss: 2.3547168752639007
Validation loss: 2.537187537718804

Epoch: 5| Step: 5
Training loss: 2.818303711064564
Validation loss: 2.52232757686257

Epoch: 5| Step: 6
Training loss: 2.980110036879373
Validation loss: 2.545122254264629

Epoch: 5| Step: 7
Training loss: 2.5175612680656565
Validation loss: 2.501084992606554

Epoch: 5| Step: 8
Training loss: 1.8976837043142551
Validation loss: 2.549678803011721

Epoch: 5| Step: 9
Training loss: 2.035861136701649
Validation loss: 2.5540423617759602

Epoch: 5| Step: 10
Training loss: 2.0862251683443587
Validation loss: 2.5602029709152436

Epoch: 469| Step: 0
Training loss: 1.8906233606252578
Validation loss: 2.5345099621891842

Epoch: 5| Step: 1
Training loss: 2.304039712159654
Validation loss: 2.5254828635576403

Epoch: 5| Step: 2
Training loss: 2.0410468140185762
Validation loss: 2.5072804647160054

Epoch: 5| Step: 3
Training loss: 1.9653949305734406
Validation loss: 2.547825813788291

Epoch: 5| Step: 4
Training loss: 2.605298358429988
Validation loss: 2.5212312064195204

Epoch: 5| Step: 5
Training loss: 1.4659638458467221
Validation loss: 2.5364061882415188

Epoch: 5| Step: 6
Training loss: 2.3637220743951497
Validation loss: 2.5332044942564993

Epoch: 5| Step: 7
Training loss: 2.2041734946517133
Validation loss: 2.5231135086796512

Epoch: 5| Step: 8
Training loss: 3.1911157781672492
Validation loss: 2.5067517793573324

Epoch: 5| Step: 9
Training loss: 2.3158749876592166
Validation loss: 2.4887562323203722

Epoch: 5| Step: 10
Training loss: 2.285235750820605
Validation loss: 2.4823289844493446

Epoch: 470| Step: 0
Training loss: 1.9275922635925538
Validation loss: 2.5566228601816836

Epoch: 5| Step: 1
Training loss: 2.279283172121674
Validation loss: 2.5326141627345464

Epoch: 5| Step: 2
Training loss: 3.084866031105825
Validation loss: 2.520128206589643

Epoch: 5| Step: 3
Training loss: 2.1803460989079118
Validation loss: 2.536474089682948

Epoch: 5| Step: 4
Training loss: 1.9758165482293846
Validation loss: 2.517100046491901

Epoch: 5| Step: 5
Training loss: 2.0469961348936474
Validation loss: 2.547055343059967

Epoch: 5| Step: 6
Training loss: 1.8753043245665912
Validation loss: 2.525512350274625

Epoch: 5| Step: 7
Training loss: 1.967076756130288
Validation loss: 2.4851186476086187

Epoch: 5| Step: 8
Training loss: 2.944771066779587
Validation loss: 2.519611318387092

Epoch: 5| Step: 9
Training loss: 2.48104251022852
Validation loss: 2.50120354261574

Epoch: 5| Step: 10
Training loss: 2.2480364815001916
Validation loss: 2.5538550375901243

Epoch: 471| Step: 0
Training loss: 2.4702007039184406
Validation loss: 2.5604631636117086

Epoch: 5| Step: 1
Training loss: 2.2389867180127485
Validation loss: 2.552555029754773

Epoch: 5| Step: 2
Training loss: 1.9250089323158606
Validation loss: 2.549833886922763

Epoch: 5| Step: 3
Training loss: 2.6793031110967664
Validation loss: 2.4863577997386046

Epoch: 5| Step: 4
Training loss: 2.441749780518393
Validation loss: 2.4979197327635903

Epoch: 5| Step: 5
Training loss: 1.7883446598434953
Validation loss: 2.520229254677793

Epoch: 5| Step: 6
Training loss: 1.9037489195612085
Validation loss: 2.5363960090845814

Epoch: 5| Step: 7
Training loss: 3.2243173098445177
Validation loss: 2.5441101767786125

Epoch: 5| Step: 8
Training loss: 1.8613967802789422
Validation loss: 2.548146463790648

Epoch: 5| Step: 9
Training loss: 1.8300013897583067
Validation loss: 2.4844485263182015

Epoch: 5| Step: 10
Training loss: 2.1110455714754695
Validation loss: 2.524765379978892

Epoch: 472| Step: 0
Training loss: 2.8001230655600646
Validation loss: 2.5280670415723394

Epoch: 5| Step: 1
Training loss: 2.128655935147923
Validation loss: 2.5181649069190604

Epoch: 5| Step: 2
Training loss: 2.7621198090485817
Validation loss: 2.5217994486799302

Epoch: 5| Step: 3
Training loss: 2.256229466056903
Validation loss: 2.5742832331182712

Epoch: 5| Step: 4
Training loss: 1.8252696373727884
Validation loss: 2.547316019233059

Epoch: 5| Step: 5
Training loss: 2.228100376073339
Validation loss: 2.545072319072945

Epoch: 5| Step: 6
Training loss: 2.4245717447199184
Validation loss: 2.5158068556094477

Epoch: 5| Step: 7
Training loss: 2.244871546717314
Validation loss: 2.477634517647409

Epoch: 5| Step: 8
Training loss: 1.7839802347080473
Validation loss: 2.518563493350624

Epoch: 5| Step: 9
Training loss: 1.959229048018814
Validation loss: 2.565721830980097

Epoch: 5| Step: 10
Training loss: 2.6407218779901362
Validation loss: 2.49492722598844

Epoch: 473| Step: 0
Training loss: 2.2845050112025835
Validation loss: 2.54961477149027

Epoch: 5| Step: 1
Training loss: 1.7439100704761359
Validation loss: 2.5482948694315013

Epoch: 5| Step: 2
Training loss: 2.021208842937211
Validation loss: 2.570789544110254

Epoch: 5| Step: 3
Training loss: 2.4525590960647494
Validation loss: 2.4956647919110986

Epoch: 5| Step: 4
Training loss: 2.0880109789767958
Validation loss: 2.556465631709026

Epoch: 5| Step: 5
Training loss: 2.539483326003405
Validation loss: 2.5282907241788806

Epoch: 5| Step: 6
Training loss: 1.754779012302986
Validation loss: 2.5034759117380965

Epoch: 5| Step: 7
Training loss: 2.4631810209944986
Validation loss: 2.473056352539122

Epoch: 5| Step: 8
Training loss: 2.4465267591293554
Validation loss: 2.532356187609576

Epoch: 5| Step: 9
Training loss: 2.7364057574807825
Validation loss: 2.5020964579367644

Epoch: 5| Step: 10
Training loss: 2.0853735915189953
Validation loss: 2.5275558684690984

Epoch: 474| Step: 0
Training loss: 2.189461183150314
Validation loss: 2.5448354283408046

Epoch: 5| Step: 1
Training loss: 2.494327499331168
Validation loss: 2.5188376115858353

Epoch: 5| Step: 2
Training loss: 2.464351163512313
Validation loss: 2.498795705339518

Epoch: 5| Step: 3
Training loss: 2.2740749238956415
Validation loss: 2.5185855785857734

Epoch: 5| Step: 4
Training loss: 2.33104077747735
Validation loss: 2.50900465218498

Epoch: 5| Step: 5
Training loss: 1.8125973379372127
Validation loss: 2.516779960638934

Epoch: 5| Step: 6
Training loss: 2.1881517801659034
Validation loss: 2.578256262019689

Epoch: 5| Step: 7
Training loss: 2.030756729094165
Validation loss: 2.541957536659715

Epoch: 5| Step: 8
Training loss: 1.6040081424744288
Validation loss: 2.5137107137241106

Epoch: 5| Step: 9
Training loss: 2.635208895689235
Validation loss: 2.4924615382781865

Epoch: 5| Step: 10
Training loss: 2.8507724451340457
Validation loss: 2.5437641865908973

Epoch: 475| Step: 0
Training loss: 2.1057640533865984
Validation loss: 2.5003304365675323

Epoch: 5| Step: 1
Training loss: 2.1480022197548534
Validation loss: 2.5210748989128615

Epoch: 5| Step: 2
Training loss: 2.030092936864199
Validation loss: 2.51288944295998

Epoch: 5| Step: 3
Training loss: 1.5394748967878515
Validation loss: 2.5574063564688982

Epoch: 5| Step: 4
Training loss: 3.0277923054788927
Validation loss: 2.5175341973484784

Epoch: 5| Step: 5
Training loss: 2.651933820954561
Validation loss: 2.4996730570150802

Epoch: 5| Step: 6
Training loss: 2.218426962963271
Validation loss: 2.5049217731700395

Epoch: 5| Step: 7
Training loss: 2.105849081306865
Validation loss: 2.59049837545726

Epoch: 5| Step: 8
Training loss: 2.120322970854304
Validation loss: 2.5446356924266964

Epoch: 5| Step: 9
Training loss: 2.4647153890470044
Validation loss: 2.5251077731929166

Epoch: 5| Step: 10
Training loss: 2.274624858569628
Validation loss: 2.456216856466643

Epoch: 476| Step: 0
Training loss: 2.4517968342359913
Validation loss: 2.537598120465736

Epoch: 5| Step: 1
Training loss: 1.8570240449103625
Validation loss: 2.543081087369751

Epoch: 5| Step: 2
Training loss: 2.030581202811086
Validation loss: 2.5518152259763753

Epoch: 5| Step: 3
Training loss: 1.946824187324402
Validation loss: 2.508377252347617

Epoch: 5| Step: 4
Training loss: 2.1802651791756613
Validation loss: 2.4988312768411247

Epoch: 5| Step: 5
Training loss: 2.229309529037483
Validation loss: 2.5343785794189104

Epoch: 5| Step: 6
Training loss: 1.9758071360734428
Validation loss: 2.5821539141181633

Epoch: 5| Step: 7
Training loss: 2.217714309744056
Validation loss: 2.5499965186339613

Epoch: 5| Step: 8
Training loss: 2.421972358961692
Validation loss: 2.490623910200952

Epoch: 5| Step: 9
Training loss: 3.024399242173892
Validation loss: 2.5296216664885187

Epoch: 5| Step: 10
Training loss: 2.6034280772273886
Validation loss: 2.5751944563586027

Epoch: 477| Step: 0
Training loss: 1.9889156026603079
Validation loss: 2.5027212570744144

Epoch: 5| Step: 1
Training loss: 2.3979404195299003
Validation loss: 2.54182479903752

Epoch: 5| Step: 2
Training loss: 2.0233413496701824
Validation loss: 2.541950314565559

Epoch: 5| Step: 3
Training loss: 2.2906543807868567
Validation loss: 2.498589539268661

Epoch: 5| Step: 4
Training loss: 1.9706710646472287
Validation loss: 2.5757193798912517

Epoch: 5| Step: 5
Training loss: 2.6478117707187456
Validation loss: 2.4921905263478052

Epoch: 5| Step: 6
Training loss: 2.099915380135411
Validation loss: 2.5512296761152617

Epoch: 5| Step: 7
Training loss: 2.067329416860352
Validation loss: 2.6004222738755307

Epoch: 5| Step: 8
Training loss: 2.412444822639024
Validation loss: 2.58985531773939

Epoch: 5| Step: 9
Training loss: 2.323150953671789
Validation loss: 2.5822305406162958

Epoch: 5| Step: 10
Training loss: 2.158460285866771
Validation loss: 2.5710780553400765

Epoch: 478| Step: 0
Training loss: 1.884008383948913
Validation loss: 2.570506246454459

Epoch: 5| Step: 1
Training loss: 2.1069098867981153
Validation loss: 2.5572459052614422

Epoch: 5| Step: 2
Training loss: 2.568993690978931
Validation loss: 2.517139067587818

Epoch: 5| Step: 3
Training loss: 2.4810463540706698
Validation loss: 2.483888374767562

Epoch: 5| Step: 4
Training loss: 2.370384952491482
Validation loss: 2.46314566320958

Epoch: 5| Step: 5
Training loss: 2.540145032902155
Validation loss: 2.5337220596693015

Epoch: 5| Step: 6
Training loss: 2.552833000677033
Validation loss: 2.5744765254053346

Epoch: 5| Step: 7
Training loss: 1.7828604796202843
Validation loss: 2.548350920838386

Epoch: 5| Step: 8
Training loss: 1.9896833650963321
Validation loss: 2.515106860153382

Epoch: 5| Step: 9
Training loss: 1.7784512936129744
Validation loss: 2.5146738632705614

Epoch: 5| Step: 10
Training loss: 2.6281921414429594
Validation loss: 2.5762263143191104

Epoch: 479| Step: 0
Training loss: 2.3480199954141674
Validation loss: 2.531579625503146

Epoch: 5| Step: 1
Training loss: 1.8191466302098849
Validation loss: 2.4974421942186833

Epoch: 5| Step: 2
Training loss: 2.1432147545096254
Validation loss: 2.5404118221264302

Epoch: 5| Step: 3
Training loss: 2.032636902575067
Validation loss: 2.5827969676695295

Epoch: 5| Step: 4
Training loss: 2.51451095649667
Validation loss: 2.584755334138416

Epoch: 5| Step: 5
Training loss: 2.328022897004725
Validation loss: 2.516774746321348

Epoch: 5| Step: 6
Training loss: 2.162569598362381
Validation loss: 2.5533073374742377

Epoch: 5| Step: 7
Training loss: 2.087530092490751
Validation loss: 2.5698470919770053

Epoch: 5| Step: 8
Training loss: 2.823292011677702
Validation loss: 2.5372542194111034

Epoch: 5| Step: 9
Training loss: 2.27801514244238
Validation loss: 2.5249485799930187

Epoch: 5| Step: 10
Training loss: 2.1020500440075653
Validation loss: 2.5298055651895455

Epoch: 480| Step: 0
Training loss: 2.2025914188598525
Validation loss: 2.5012141806822226

Epoch: 5| Step: 1
Training loss: 2.3035082887633305
Validation loss: 2.50714526383703

Epoch: 5| Step: 2
Training loss: 1.9779916052413553
Validation loss: 2.533317621837571

Epoch: 5| Step: 3
Training loss: 3.0492028367186603
Validation loss: 2.5578499037200975

Epoch: 5| Step: 4
Training loss: 1.6824897987997387
Validation loss: 2.5804292630341537

Epoch: 5| Step: 5
Training loss: 2.6199702258274638
Validation loss: 2.505777000047948

Epoch: 5| Step: 6
Training loss: 2.216799241119332
Validation loss: 2.528129824999035

Epoch: 5| Step: 7
Training loss: 2.327171693750507
Validation loss: 2.5183188978985283

Epoch: 5| Step: 8
Training loss: 2.0273739733491993
Validation loss: 2.5855649074894487

Epoch: 5| Step: 9
Training loss: 1.9426138056307405
Validation loss: 2.5526854925779743

Epoch: 5| Step: 10
Training loss: 2.201066157621031
Validation loss: 2.5633791949194547

Epoch: 481| Step: 0
Training loss: 2.288991048172911
Validation loss: 2.5137376277654995

Epoch: 5| Step: 1
Training loss: 1.8090552118246506
Validation loss: 2.5039039862523027

Epoch: 5| Step: 2
Training loss: 2.516840860094071
Validation loss: 2.5695365409971322

Epoch: 5| Step: 3
Training loss: 2.6039731882065684
Validation loss: 2.5379546120676326

Epoch: 5| Step: 4
Training loss: 2.313583738679313
Validation loss: 2.5497641423575708

Epoch: 5| Step: 5
Training loss: 1.8200632997131634
Validation loss: 2.5631911473455147

Epoch: 5| Step: 6
Training loss: 2.777002412876706
Validation loss: 2.4919511084566697

Epoch: 5| Step: 7
Training loss: 1.5609668839660709
Validation loss: 2.466192956312168

Epoch: 5| Step: 8
Training loss: 2.0291659888462865
Validation loss: 2.501390921349571

Epoch: 5| Step: 9
Training loss: 2.192642053854337
Validation loss: 2.5501569363845937

Epoch: 5| Step: 10
Training loss: 2.210649019973107
Validation loss: 2.4935023242761263

Epoch: 482| Step: 0
Training loss: 2.628681326280673
Validation loss: 2.5092012750462374

Epoch: 5| Step: 1
Training loss: 2.3533376286100935
Validation loss: 2.4892052241340057

Epoch: 5| Step: 2
Training loss: 2.785671020702821
Validation loss: 2.5234088698609174

Epoch: 5| Step: 3
Training loss: 2.113402527098572
Validation loss: 2.563090068630529

Epoch: 5| Step: 4
Training loss: 2.523399518084414
Validation loss: 2.541816635051372

Epoch: 5| Step: 5
Training loss: 2.285208624867209
Validation loss: 2.5067017772912776

Epoch: 5| Step: 6
Training loss: 1.8613587383943015
Validation loss: 2.541643503353519

Epoch: 5| Step: 7
Training loss: 1.8286917696356404
Validation loss: 2.5099608134628

Epoch: 5| Step: 8
Training loss: 1.6486063504634612
Validation loss: 2.4933720827055557

Epoch: 5| Step: 9
Training loss: 1.9898944897691984
Validation loss: 2.4781018865375617

Epoch: 5| Step: 10
Training loss: 2.5160290885177736
Validation loss: 2.545395809689052

Epoch: 483| Step: 0
Training loss: 2.0685246647394018
Validation loss: 2.5276141116144064

Epoch: 5| Step: 1
Training loss: 1.5970688465210114
Validation loss: 2.5240494800561364

Epoch: 5| Step: 2
Training loss: 2.8782272469813974
Validation loss: 2.5347410066382157

Epoch: 5| Step: 3
Training loss: 2.5568423268112532
Validation loss: 2.5002547934115635

Epoch: 5| Step: 4
Training loss: 2.304210548833794
Validation loss: 2.5553602461960696

Epoch: 5| Step: 5
Training loss: 2.44723727490687
Validation loss: 2.5517398833331786

Epoch: 5| Step: 6
Training loss: 2.350214575041303
Validation loss: 2.5656024231360197

Epoch: 5| Step: 7
Training loss: 1.9669320326186064
Validation loss: 2.4852044399136006

Epoch: 5| Step: 8
Training loss: 2.4593315576305823
Validation loss: 2.5335772354294885

Epoch: 5| Step: 9
Training loss: 2.2177581719394253
Validation loss: 2.5433984428123457

Epoch: 5| Step: 10
Training loss: 1.9295142709916528
Validation loss: 2.515082197124573

Epoch: 484| Step: 0
Training loss: 2.3364824660868
Validation loss: 2.503486012774058

Epoch: 5| Step: 1
Training loss: 2.1640898224245415
Validation loss: 2.4996482991407483

Epoch: 5| Step: 2
Training loss: 2.173011427581133
Validation loss: 2.523340550804905

Epoch: 5| Step: 3
Training loss: 2.0798798229272344
Validation loss: 2.5962213128488423

Epoch: 5| Step: 4
Training loss: 2.5992916609476273
Validation loss: 2.5581015036859482

Epoch: 5| Step: 5
Training loss: 2.638992075547914
Validation loss: 2.5501597381190377

Epoch: 5| Step: 6
Training loss: 2.3807678455411803
Validation loss: 2.5332289869221545

Epoch: 5| Step: 7
Training loss: 1.8096225523060259
Validation loss: 2.4989457686611147

Epoch: 5| Step: 8
Training loss: 1.9497050135578402
Validation loss: 2.530798551366961

Epoch: 5| Step: 9
Training loss: 2.4781344746700773
Validation loss: 2.5361394274699878

Epoch: 5| Step: 10
Training loss: 1.8297466030722582
Validation loss: 2.5453525031206374

Epoch: 485| Step: 0
Training loss: 1.945200844130273
Validation loss: 2.4853577308635453

Epoch: 5| Step: 1
Training loss: 1.9442207306126205
Validation loss: 2.5186396299491296

Epoch: 5| Step: 2
Training loss: 2.296303398994117
Validation loss: 2.554092000141502

Epoch: 5| Step: 3
Training loss: 2.0832842121691164
Validation loss: 2.52213403462443

Epoch: 5| Step: 4
Training loss: 2.3379354958622147
Validation loss: 2.550902247073694

Epoch: 5| Step: 5
Training loss: 2.6774135539314123
Validation loss: 2.5361326133632582

Epoch: 5| Step: 6
Training loss: 1.982004085921494
Validation loss: 2.535935331930557

Epoch: 5| Step: 7
Training loss: 2.6188793578325344
Validation loss: 2.570459479273702

Epoch: 5| Step: 8
Training loss: 1.7156933741329128
Validation loss: 2.541295824544815

Epoch: 5| Step: 9
Training loss: 2.6002679760090315
Validation loss: 2.5192430241528725

Epoch: 5| Step: 10
Training loss: 1.767652377260333
Validation loss: 2.5135206591424013

Epoch: 486| Step: 0
Training loss: 2.557665288064301
Validation loss: 2.52136523053119

Epoch: 5| Step: 1
Training loss: 1.9102025562750553
Validation loss: 2.5067281366001235

Epoch: 5| Step: 2
Training loss: 2.529194503538816
Validation loss: 2.543328369564887

Epoch: 5| Step: 3
Training loss: 1.9366503667665271
Validation loss: 2.539793837160292

Epoch: 5| Step: 4
Training loss: 2.129793706584039
Validation loss: 2.469400519816709

Epoch: 5| Step: 5
Training loss: 2.021616701964209
Validation loss: 2.470576603188986

Epoch: 5| Step: 6
Training loss: 2.5777548784393507
Validation loss: 2.5316397932578494

Epoch: 5| Step: 7
Training loss: 1.9090514313137619
Validation loss: 2.4742624938894955

Epoch: 5| Step: 8
Training loss: 1.7468504492820736
Validation loss: 2.5318373942116486

Epoch: 5| Step: 9
Training loss: 2.5784657571030447
Validation loss: 2.5685740498725895

Epoch: 5| Step: 10
Training loss: 1.9785873836899017
Validation loss: 2.5393209699736725

Epoch: 487| Step: 0
Training loss: 1.6428273269364466
Validation loss: 2.5488969256011664

Epoch: 5| Step: 1
Training loss: 1.8615764760454434
Validation loss: 2.5322438685041004

Epoch: 5| Step: 2
Training loss: 2.116481987213042
Validation loss: 2.5472355606304156

Epoch: 5| Step: 3
Training loss: 2.462920246959552
Validation loss: 2.5465158712238893

Epoch: 5| Step: 4
Training loss: 2.343878272043259
Validation loss: 2.5139355610300447

Epoch: 5| Step: 5
Training loss: 2.4189965647325726
Validation loss: 2.496527468952361

Epoch: 5| Step: 6
Training loss: 2.398367318484089
Validation loss: 2.521231080333723

Epoch: 5| Step: 7
Training loss: 2.9618013676838237
Validation loss: 2.520853463213476

Epoch: 5| Step: 8
Training loss: 2.235526368458553
Validation loss: 2.508128867992046

Epoch: 5| Step: 9
Training loss: 2.3573172987756514
Validation loss: 2.534738351202415

Epoch: 5| Step: 10
Training loss: 1.659849035223585
Validation loss: 2.506382391794634

Epoch: 488| Step: 0
Training loss: 2.150838612970343
Validation loss: 2.486520735375631

Epoch: 5| Step: 1
Training loss: 2.2086145713750365
Validation loss: 2.5313957463068526

Epoch: 5| Step: 2
Training loss: 2.2048023953633797
Validation loss: 2.5177789922361575

Epoch: 5| Step: 3
Training loss: 2.2655820645177376
Validation loss: 2.5440458085975486

Epoch: 5| Step: 4
Training loss: 2.565596965306732
Validation loss: 2.5469122936206676

Epoch: 5| Step: 5
Training loss: 2.1750322624532266
Validation loss: 2.5171120289954687

Epoch: 5| Step: 6
Training loss: 1.4717786688574337
Validation loss: 2.57427834839188

Epoch: 5| Step: 7
Training loss: 2.227025890650343
Validation loss: 2.524904828799524

Epoch: 5| Step: 8
Training loss: 2.281437069264279
Validation loss: 2.4830295280558357

Epoch: 5| Step: 9
Training loss: 1.867579079910797
Validation loss: 2.5130998088437737

Epoch: 5| Step: 10
Training loss: 2.925518518118372
Validation loss: 2.53872034384761

Epoch: 489| Step: 0
Training loss: 2.4632558408153202
Validation loss: 2.5288903837210497

Epoch: 5| Step: 1
Training loss: 2.0732134378158547
Validation loss: 2.5083345269777566

Epoch: 5| Step: 2
Training loss: 2.693234557647611
Validation loss: 2.4890785798848976

Epoch: 5| Step: 3
Training loss: 2.3145474829130595
Validation loss: 2.4992751634565753

Epoch: 5| Step: 4
Training loss: 2.29260022192878
Validation loss: 2.478744130273591

Epoch: 5| Step: 5
Training loss: 2.1767271441031575
Validation loss: 2.5603766479211014

Epoch: 5| Step: 6
Training loss: 2.147548311198583
Validation loss: 2.509675498912451

Epoch: 5| Step: 7
Training loss: 1.8887878193025878
Validation loss: 2.560371717639202

Epoch: 5| Step: 8
Training loss: 2.6740201849050775
Validation loss: 2.5439523838160576

Epoch: 5| Step: 9
Training loss: 2.102676493418358
Validation loss: 2.5489476729511114

Epoch: 5| Step: 10
Training loss: 1.36846441311711
Validation loss: 2.5173122480376953

Epoch: 490| Step: 0
Training loss: 1.975241600421427
Validation loss: 2.547095462294609

Epoch: 5| Step: 1
Training loss: 2.6106908529906248
Validation loss: 2.5247414834993553

Epoch: 5| Step: 2
Training loss: 1.664568685276988
Validation loss: 2.5223541225081063

Epoch: 5| Step: 3
Training loss: 2.580778109294571
Validation loss: 2.550536950940188

Epoch: 5| Step: 4
Training loss: 2.1964578593358297
Validation loss: 2.4633979650521356

Epoch: 5| Step: 5
Training loss: 1.891654939937234
Validation loss: 2.5460458655669167

Epoch: 5| Step: 6
Training loss: 2.024797608422141
Validation loss: 2.5509004431094016

Epoch: 5| Step: 7
Training loss: 2.712434558694269
Validation loss: 2.5528798979546723

Epoch: 5| Step: 8
Training loss: 2.119622663529594
Validation loss: 2.5298139336229317

Epoch: 5| Step: 9
Training loss: 1.9092360076011943
Validation loss: 2.5213062710896867

Epoch: 5| Step: 10
Training loss: 2.4195904200718186
Validation loss: 2.4867652574720966

Epoch: 491| Step: 0
Training loss: 2.0711335479469684
Validation loss: 2.516098869530509

Epoch: 5| Step: 1
Training loss: 2.728063831320893
Validation loss: 2.5350741393609577

Epoch: 5| Step: 2
Training loss: 2.0004155204190694
Validation loss: 2.536087335125125

Epoch: 5| Step: 3
Training loss: 2.021724609253298
Validation loss: 2.546875126829433

Epoch: 5| Step: 4
Training loss: 2.3068036208353058
Validation loss: 2.5503680460426916

Epoch: 5| Step: 5
Training loss: 2.4945757194399873
Validation loss: 2.5359119390162452

Epoch: 5| Step: 6
Training loss: 1.8335645558747864
Validation loss: 2.534890228455892

Epoch: 5| Step: 7
Training loss: 1.8798717151661086
Validation loss: 2.533429405590589

Epoch: 5| Step: 8
Training loss: 2.4244472502927144
Validation loss: 2.553912193119698

Epoch: 5| Step: 9
Training loss: 2.3915939860537403
Validation loss: 2.519408146963059

Epoch: 5| Step: 10
Training loss: 2.4268574316197897
Validation loss: 2.508381488664722

Epoch: 492| Step: 0
Training loss: 1.983128914863769
Validation loss: 2.538107876092831

Epoch: 5| Step: 1
Training loss: 1.9721766124818316
Validation loss: 2.5102477546379056

Epoch: 5| Step: 2
Training loss: 2.1756399988864517
Validation loss: 2.544854701644831

Epoch: 5| Step: 3
Training loss: 2.2668939654133022
Validation loss: 2.535121566398943

Epoch: 5| Step: 4
Training loss: 1.9123527520035897
Validation loss: 2.560065581003404

Epoch: 5| Step: 5
Training loss: 2.426132299603767
Validation loss: 2.53415340584066

Epoch: 5| Step: 6
Training loss: 1.9781482954295762
Validation loss: 2.5542669106531353

Epoch: 5| Step: 7
Training loss: 2.49429404459745
Validation loss: 2.531666401256161

Epoch: 5| Step: 8
Training loss: 2.381367429706326
Validation loss: 2.596576566404485

Epoch: 5| Step: 9
Training loss: 2.249493223975007
Validation loss: 2.555997390956222

Epoch: 5| Step: 10
Training loss: 2.49056829868997
Validation loss: 2.5370299462570287

Epoch: 493| Step: 0
Training loss: 1.946207782677035
Validation loss: 2.5450836974607687

Epoch: 5| Step: 1
Training loss: 1.8822606967840452
Validation loss: 2.5136965335084875

Epoch: 5| Step: 2
Training loss: 2.6017145335819816
Validation loss: 2.4979939277352003

Epoch: 5| Step: 3
Training loss: 2.078705441289243
Validation loss: 2.5553682219448026

Epoch: 5| Step: 4
Training loss: 2.19840345973141
Validation loss: 2.568625455433458

Epoch: 5| Step: 5
Training loss: 2.026768597289895
Validation loss: 2.5499837717613203

Epoch: 5| Step: 6
Training loss: 2.1106484419244125
Validation loss: 2.49241744258876

Epoch: 5| Step: 7
Training loss: 2.464448295584902
Validation loss: 2.5993995089017883

Epoch: 5| Step: 8
Training loss: 1.8448864295554248
Validation loss: 2.564086544970475

Epoch: 5| Step: 9
Training loss: 2.787887624979777
Validation loss: 2.4850725858653906

Epoch: 5| Step: 10
Training loss: 2.2634305652563262
Validation loss: 2.5520046969552577

Epoch: 494| Step: 0
Training loss: 1.9394558909416644
Validation loss: 2.5363278821729582

Epoch: 5| Step: 1
Training loss: 2.678248783843043
Validation loss: 2.537289953456743

Epoch: 5| Step: 2
Training loss: 1.7993586086256688
Validation loss: 2.5097858305406184

Epoch: 5| Step: 3
Training loss: 2.1146586613008487
Validation loss: 2.491322181527413

Epoch: 5| Step: 4
Training loss: 2.2332186607793307
Validation loss: 2.506264586947461

Epoch: 5| Step: 5
Training loss: 1.73298052840787
Validation loss: 2.50478987982849

Epoch: 5| Step: 6
Training loss: 2.1411615520677607
Validation loss: 2.548397905125095

Epoch: 5| Step: 7
Training loss: 2.3153629623188308
Validation loss: 2.499679732573937

Epoch: 5| Step: 8
Training loss: 2.1413788964557474
Validation loss: 2.4604562929919473

Epoch: 5| Step: 9
Training loss: 2.808992614861324
Validation loss: 2.5250240666734918

Epoch: 5| Step: 10
Training loss: 2.4165172749964867
Validation loss: 2.5414743291849753

Epoch: 495| Step: 0
Training loss: 2.312143040505561
Validation loss: 2.5851420875804263

Epoch: 5| Step: 1
Training loss: 2.225351318740771
Validation loss: 2.5632017431814065

Epoch: 5| Step: 2
Training loss: 2.16333237873795
Validation loss: 2.5291786879857434

Epoch: 5| Step: 3
Training loss: 2.394924511127953
Validation loss: 2.568146602807377

Epoch: 5| Step: 4
Training loss: 1.8092548653311975
Validation loss: 2.527200783850838

Epoch: 5| Step: 5
Training loss: 2.3360325210280224
Validation loss: 2.510736074353359

Epoch: 5| Step: 6
Training loss: 1.987269295792043
Validation loss: 2.5044633113452526

Epoch: 5| Step: 7
Training loss: 2.464407759856725
Validation loss: 2.516130197300995

Epoch: 5| Step: 8
Training loss: 2.119665293632759
Validation loss: 2.5876796460110225

Epoch: 5| Step: 9
Training loss: 1.9818217755126821
Validation loss: 2.486047930783622

Epoch: 5| Step: 10
Training loss: 2.3900469910219786
Validation loss: 2.5300993233961973

Epoch: 496| Step: 0
Training loss: 2.0674212149908135
Validation loss: 2.5284569939728048

Epoch: 5| Step: 1
Training loss: 2.1101931645350365
Validation loss: 2.548953806094586

Epoch: 5| Step: 2
Training loss: 2.2343910056654654
Validation loss: 2.487920969061505

Epoch: 5| Step: 3
Training loss: 2.699046591804266
Validation loss: 2.532080631148117

Epoch: 5| Step: 4
Training loss: 2.2887708458610008
Validation loss: 2.5301058264707215

Epoch: 5| Step: 5
Training loss: 2.5906353369346697
Validation loss: 2.5496475124091424

Epoch: 5| Step: 6
Training loss: 2.2466184849010786
Validation loss: 2.5246709787326256

Epoch: 5| Step: 7
Training loss: 2.234070763849472
Validation loss: 2.4970175221438025

Epoch: 5| Step: 8
Training loss: 1.8750162759710247
Validation loss: 2.523949776359967

Epoch: 5| Step: 9
Training loss: 1.625508888964255
Validation loss: 2.5317090265326985

Epoch: 5| Step: 10
Training loss: 2.4491534308038783
Validation loss: 2.4769896285181368

Epoch: 497| Step: 0
Training loss: 2.446240136424409
Validation loss: 2.557689419195701

Epoch: 5| Step: 1
Training loss: 2.1470310115626687
Validation loss: 2.5349697186808884

Epoch: 5| Step: 2
Training loss: 2.400605057899456
Validation loss: 2.5574308328739446

Epoch: 5| Step: 3
Training loss: 1.848131372765244
Validation loss: 2.5864227457273454

Epoch: 5| Step: 4
Training loss: 1.9068297458256283
Validation loss: 2.475449722224294

Epoch: 5| Step: 5
Training loss: 1.707156667750394
Validation loss: 2.5194094250139476

Epoch: 5| Step: 6
Training loss: 2.246098526659323
Validation loss: 2.5756798727271764

Epoch: 5| Step: 7
Training loss: 2.179446736919956
Validation loss: 2.5568208607974188

Epoch: 5| Step: 8
Training loss: 2.2301610944918875
Validation loss: 2.5302915187739985

Epoch: 5| Step: 9
Training loss: 1.8777670469986925
Validation loss: 2.5125042842199314

Epoch: 5| Step: 10
Training loss: 2.823582578899456
Validation loss: 2.553689248400296

Epoch: 498| Step: 0
Training loss: 2.3102961167949516
Validation loss: 2.548917646686103

Epoch: 5| Step: 1
Training loss: 1.6992552303914488
Validation loss: 2.528442639936496

Epoch: 5| Step: 2
Training loss: 1.7471152097797948
Validation loss: 2.538301167909438

Epoch: 5| Step: 3
Training loss: 1.8840397044612542
Validation loss: 2.5327554598901783

Epoch: 5| Step: 4
Training loss: 1.934340947210427
Validation loss: 2.521726093398672

Epoch: 5| Step: 5
Training loss: 2.1408778131818083
Validation loss: 2.4935010504246735

Epoch: 5| Step: 6
Training loss: 2.9182749719047223
Validation loss: 2.4874546834489197

Epoch: 5| Step: 7
Training loss: 1.9110683143737612
Validation loss: 2.5496823814980023

Epoch: 5| Step: 8
Training loss: 1.9841876805119423
Validation loss: 2.4938467481886253

Epoch: 5| Step: 9
Training loss: 2.583998584203657
Validation loss: 2.4532029099244843

Epoch: 5| Step: 10
Training loss: 2.672344233484899
Validation loss: 2.489479461973061

Epoch: 499| Step: 0
Training loss: 1.6076088260103671
Validation loss: 2.5429345661308758

Epoch: 5| Step: 1
Training loss: 2.3304920836050065
Validation loss: 2.5079457196490615

Epoch: 5| Step: 2
Training loss: 2.031237558180045
Validation loss: 2.5177626600126817

Epoch: 5| Step: 3
Training loss: 3.0802245749306714
Validation loss: 2.558518029815974

Epoch: 5| Step: 4
Training loss: 2.194992965304631
Validation loss: 2.498994833366135

Epoch: 5| Step: 5
Training loss: 2.0217871102948126
Validation loss: 2.506138648259247

Epoch: 5| Step: 6
Training loss: 2.149785066551292
Validation loss: 2.542862511142949

Epoch: 5| Step: 7
Training loss: 1.7030223150532873
Validation loss: 2.5058438725471888

Epoch: 5| Step: 8
Training loss: 2.1686926930356387
Validation loss: 2.527742219700598

Epoch: 5| Step: 9
Training loss: 2.331949766131654
Validation loss: 2.4781226688795037

Epoch: 5| Step: 10
Training loss: 2.250926992404302
Validation loss: 2.531232571741263

Epoch: 500| Step: 0
Training loss: 2.6434010016048726
Validation loss: 2.526900392457689

Epoch: 5| Step: 1
Training loss: 1.957022661201681
Validation loss: 2.55365948870817

Epoch: 5| Step: 2
Training loss: 1.3895005384006947
Validation loss: 2.5399337467715446

Epoch: 5| Step: 3
Training loss: 1.898015858486478
Validation loss: 2.5160214374111587

Epoch: 5| Step: 4
Training loss: 2.6768123227302665
Validation loss: 2.4661513296861033

Epoch: 5| Step: 5
Training loss: 2.1304961540941263
Validation loss: 2.5722595095671745

Epoch: 5| Step: 6
Training loss: 2.3081782397925017
Validation loss: 2.50292408481366

Epoch: 5| Step: 7
Training loss: 1.8465189427577327
Validation loss: 2.5083837504156534

Epoch: 5| Step: 8
Training loss: 2.3706604311824933
Validation loss: 2.5559437294079332

Epoch: 5| Step: 9
Training loss: 2.0559629245710376
Validation loss: 2.53188455280377

Epoch: 5| Step: 10
Training loss: 2.0333230810480187
Validation loss: 2.556487227559575

Epoch: 501| Step: 0
Training loss: 2.1237449305554126
Validation loss: 2.509894986268447

Epoch: 5| Step: 1
Training loss: 1.6499159993839667
Validation loss: 2.5201395124581447

Epoch: 5| Step: 2
Training loss: 2.122810806864503
Validation loss: 2.5404261468811433

Epoch: 5| Step: 3
Training loss: 2.4561767062446025
Validation loss: 2.52379083974084

Epoch: 5| Step: 4
Training loss: 2.1599733575308098
Validation loss: 2.554834467048039

Epoch: 5| Step: 5
Training loss: 2.329089278662576
Validation loss: 2.561751884986184

Epoch: 5| Step: 6
Training loss: 1.8636623288775438
Validation loss: 2.578464600789559

Epoch: 5| Step: 7
Training loss: 1.8055977775658083
Validation loss: 2.534755227913588

Epoch: 5| Step: 8
Training loss: 2.170307499417723
Validation loss: 2.488644858656421

Epoch: 5| Step: 9
Training loss: 2.067788712663188
Validation loss: 2.5108239645934085

Epoch: 5| Step: 10
Training loss: 3.0591561883095566
Validation loss: 2.5126094701822916

Epoch: 502| Step: 0
Training loss: 2.4292264543856366
Validation loss: 2.511497244233595

Epoch: 5| Step: 1
Training loss: 2.4101347837311367
Validation loss: 2.5422266668177635

Epoch: 5| Step: 2
Training loss: 2.1396268201926008
Validation loss: 2.4916218159891326

Epoch: 5| Step: 3
Training loss: 2.3471310451738723
Validation loss: 2.534855607964425

Epoch: 5| Step: 4
Training loss: 1.3062043195704172
Validation loss: 2.4717220777396562

Epoch: 5| Step: 5
Training loss: 1.8686101114740343
Validation loss: 2.515175756545366

Epoch: 5| Step: 6
Training loss: 2.0163040791476377
Validation loss: 2.60720409494535

Epoch: 5| Step: 7
Training loss: 2.753233828867148
Validation loss: 2.5674227618741523

Epoch: 5| Step: 8
Training loss: 2.2588685413829985
Validation loss: 2.520639155967198

Epoch: 5| Step: 9
Training loss: 2.118194565788605
Validation loss: 2.5605344119294715

Epoch: 5| Step: 10
Training loss: 2.1349563722820784
Validation loss: 2.517756211606248

Epoch: 503| Step: 0
Training loss: 2.1078554684930153
Validation loss: 2.5771101708411224

Epoch: 5| Step: 1
Training loss: 2.202098959221041
Validation loss: 2.4996491319282446

Epoch: 5| Step: 2
Training loss: 1.3283561056682753
Validation loss: 2.5390066852855804

Epoch: 5| Step: 3
Training loss: 1.9492492673392323
Validation loss: 2.518834279348396

Epoch: 5| Step: 4
Training loss: 2.0134202594602137
Validation loss: 2.5509953650734745

Epoch: 5| Step: 5
Training loss: 2.0277149838112134
Validation loss: 2.5729005363137745

Epoch: 5| Step: 6
Training loss: 2.1424860973641535
Validation loss: 2.538103985339648

Epoch: 5| Step: 7
Training loss: 1.5250869819974469
Validation loss: 2.5121293245648473

Epoch: 5| Step: 8
Training loss: 2.9965835827380087
Validation loss: 2.5115797622887017

Epoch: 5| Step: 9
Training loss: 2.5157374007424997
Validation loss: 2.4949311892118855

Epoch: 5| Step: 10
Training loss: 3.0042035534869624
Validation loss: 2.542397885279856

Epoch: 504| Step: 0
Training loss: 2.2673614161830176
Validation loss: 2.4883434413899153

Epoch: 5| Step: 1
Training loss: 2.375889561350265
Validation loss: 2.4800839159923083

Epoch: 5| Step: 2
Training loss: 1.8614010711497972
Validation loss: 2.51128836316942

Epoch: 5| Step: 3
Training loss: 1.9168804989273507
Validation loss: 2.539185510373872

Epoch: 5| Step: 4
Training loss: 2.285151241981692
Validation loss: 2.5377106167812853

Epoch: 5| Step: 5
Training loss: 2.033854179691668
Validation loss: 2.5777054391529317

Epoch: 5| Step: 6
Training loss: 2.347400010227042
Validation loss: 2.52736931330643

Epoch: 5| Step: 7
Training loss: 2.1304334849511894
Validation loss: 2.5068516920378685

Epoch: 5| Step: 8
Training loss: 1.779825678443873
Validation loss: 2.504216613368342

Epoch: 5| Step: 9
Training loss: 2.853384444441506
Validation loss: 2.557888383348802

Epoch: 5| Step: 10
Training loss: 2.151963326677012
Validation loss: 2.5209659008320964

Epoch: 505| Step: 0
Training loss: 1.989076826189325
Validation loss: 2.5033448372700495

Epoch: 5| Step: 1
Training loss: 1.9816095501256472
Validation loss: 2.5415079022518823

Epoch: 5| Step: 2
Training loss: 1.87629210138324
Validation loss: 2.5253489772695707

Epoch: 5| Step: 3
Training loss: 2.0981206113549526
Validation loss: 2.564387765880981

Epoch: 5| Step: 4
Training loss: 1.8325294841980913
Validation loss: 2.5130631723120382

Epoch: 5| Step: 5
Training loss: 2.4278139207226705
Validation loss: 2.5338459768307215

Epoch: 5| Step: 6
Training loss: 2.6950572017338845
Validation loss: 2.5568880636891484

Epoch: 5| Step: 7
Training loss: 1.9210410440916448
Validation loss: 2.555718475223605

Epoch: 5| Step: 8
Training loss: 2.5704336398718532
Validation loss: 2.5044541682766157

Epoch: 5| Step: 9
Training loss: 2.3230190739203698
Validation loss: 2.54098976161628

Epoch: 5| Step: 10
Training loss: 2.0404430407589884
Validation loss: 2.5408118495124974

Epoch: 506| Step: 0
Training loss: 2.3130566725989006
Validation loss: 2.545191207418365

Epoch: 5| Step: 1
Training loss: 2.7325623525920175
Validation loss: 2.54426721532797

Epoch: 5| Step: 2
Training loss: 2.285597225580611
Validation loss: 2.5573088745583488

Epoch: 5| Step: 3
Training loss: 2.055209713558527
Validation loss: 2.55049007491147

Epoch: 5| Step: 4
Training loss: 1.9234328120381348
Validation loss: 2.5190564100424986

Epoch: 5| Step: 5
Training loss: 1.9922739645949932
Validation loss: 2.532725331747696

Epoch: 5| Step: 6
Training loss: 2.0781235085388796
Validation loss: 2.547178548166184

Epoch: 5| Step: 7
Training loss: 2.005097806452329
Validation loss: 2.5231812618555045

Epoch: 5| Step: 8
Training loss: 1.583617444230462
Validation loss: 2.567017639539166

Epoch: 5| Step: 9
Training loss: 2.165738775173788
Validation loss: 2.533201513870932

Epoch: 5| Step: 10
Training loss: 2.634988400688917
Validation loss: 2.52317122442514

Epoch: 507| Step: 0
Training loss: 2.6416940725772164
Validation loss: 2.4564951585016073

Epoch: 5| Step: 1
Training loss: 2.147504680304262
Validation loss: 2.537213494423396

Epoch: 5| Step: 2
Training loss: 2.5052926306443988
Validation loss: 2.5177046818001836

Epoch: 5| Step: 3
Training loss: 1.7667334124114498
Validation loss: 2.579530704491652

Epoch: 5| Step: 4
Training loss: 1.8878693478200435
Validation loss: 2.570468770543683

Epoch: 5| Step: 5
Training loss: 2.3702081223542217
Validation loss: 2.507641018939627

Epoch: 5| Step: 6
Training loss: 1.6754184143365933
Validation loss: 2.510122396747282

Epoch: 5| Step: 7
Training loss: 2.041917577882845
Validation loss: 2.5592388948820726

Epoch: 5| Step: 8
Training loss: 2.612408365349145
Validation loss: 2.5738112938689173

Epoch: 5| Step: 9
Training loss: 2.3022754525732765
Validation loss: 2.534029265460976

Epoch: 5| Step: 10
Training loss: 1.961799644828902
Validation loss: 2.4923062006460035

Epoch: 508| Step: 0
Training loss: 2.479570649728422
Validation loss: 2.5594725824700473

Epoch: 5| Step: 1
Training loss: 1.7857366574112188
Validation loss: 2.520972447805609

Epoch: 5| Step: 2
Training loss: 2.188014160765968
Validation loss: 2.526818857663421

Epoch: 5| Step: 3
Training loss: 1.856445376713735
Validation loss: 2.485149213120313

Epoch: 5| Step: 4
Training loss: 1.6999192471117708
Validation loss: 2.5496719949251894

Epoch: 5| Step: 5
Training loss: 2.6718485869948116
Validation loss: 2.550627886129692

Epoch: 5| Step: 6
Training loss: 2.293806868427679
Validation loss: 2.5359114916777306

Epoch: 5| Step: 7
Training loss: 2.250530816088195
Validation loss: 2.5664011335144767

Epoch: 5| Step: 8
Training loss: 2.3017191764298213
Validation loss: 2.547926366112746

Epoch: 5| Step: 9
Training loss: 2.056240176841207
Validation loss: 2.5500919819279018

Epoch: 5| Step: 10
Training loss: 2.144661765652172
Validation loss: 2.518323058448104

Epoch: 509| Step: 0
Training loss: 1.950808562857893
Validation loss: 2.483278196113235

Epoch: 5| Step: 1
Training loss: 2.29885052691931
Validation loss: 2.532037005720896

Epoch: 5| Step: 2
Training loss: 2.628747807754422
Validation loss: 2.5233878234892755

Epoch: 5| Step: 3
Training loss: 2.3344153098184135
Validation loss: 2.5405792486895202

Epoch: 5| Step: 4
Training loss: 1.8268748516405053
Validation loss: 2.497806640050265

Epoch: 5| Step: 5
Training loss: 1.9972306986902875
Validation loss: 2.4844193086022126

Epoch: 5| Step: 6
Training loss: 2.1737599049408867
Validation loss: 2.547870965929343

Epoch: 5| Step: 7
Training loss: 2.22623181480764
Validation loss: 2.5115594456296972

Epoch: 5| Step: 8
Training loss: 1.812126055322258
Validation loss: 2.4634273394732302

Epoch: 5| Step: 9
Training loss: 2.4187083553701556
Validation loss: 2.5449611766650397

Epoch: 5| Step: 10
Training loss: 2.1426869506461363
Validation loss: 2.593275711534922

Epoch: 510| Step: 0
Training loss: 1.739579305434751
Validation loss: 2.542370010150377

Epoch: 5| Step: 1
Training loss: 2.255161828199566
Validation loss: 2.5349162976813426

Epoch: 5| Step: 2
Training loss: 2.318075726711288
Validation loss: 2.5384506091569254

Epoch: 5| Step: 3
Training loss: 2.2704338865653324
Validation loss: 2.5396220555045717

Epoch: 5| Step: 4
Training loss: 2.712221396768769
Validation loss: 2.6080391136414423

Epoch: 5| Step: 5
Training loss: 2.3610100543766595
Validation loss: 2.5402340602866205

Epoch: 5| Step: 6
Training loss: 1.933328691290621
Validation loss: 2.5025750844302697

Epoch: 5| Step: 7
Training loss: 2.511313778042216
Validation loss: 2.568562720649268

Epoch: 5| Step: 8
Training loss: 1.8782292214925813
Validation loss: 2.5226497590828507

Epoch: 5| Step: 9
Training loss: 1.7433852795337288
Validation loss: 2.5281445854135467

Epoch: 5| Step: 10
Training loss: 1.808280439819165
Validation loss: 2.48353769757121

Epoch: 511| Step: 0
Training loss: 1.8492415162052138
Validation loss: 2.5308392210523487

Epoch: 5| Step: 1
Training loss: 1.8669158865682063
Validation loss: 2.4781219261018057

Epoch: 5| Step: 2
Training loss: 1.9992840200594286
Validation loss: 2.5367120957522657

Epoch: 5| Step: 3
Training loss: 2.2359002516101083
Validation loss: 2.598818879049486

Epoch: 5| Step: 4
Training loss: 1.7660428118284843
Validation loss: 2.5389411396212327

Epoch: 5| Step: 5
Training loss: 2.1129989576504147
Validation loss: 2.5247530073291666

Epoch: 5| Step: 6
Training loss: 2.6473852897482617
Validation loss: 2.511132315765974

Epoch: 5| Step: 7
Training loss: 1.738983766704864
Validation loss: 2.5389815859842377

Epoch: 5| Step: 8
Training loss: 2.6711370330186766
Validation loss: 2.555775316243541

Epoch: 5| Step: 9
Training loss: 1.845541067930974
Validation loss: 2.5205945137681707

Epoch: 5| Step: 10
Training loss: 2.3823896189174607
Validation loss: 2.5400685962253915

Epoch: 512| Step: 0
Training loss: 1.781637584614266
Validation loss: 2.5618053808408576

Epoch: 5| Step: 1
Training loss: 1.4462153733443066
Validation loss: 2.4957406193820564

Epoch: 5| Step: 2
Training loss: 2.0444391331166
Validation loss: 2.5742054607995613

Epoch: 5| Step: 3
Training loss: 2.3643363678025016
Validation loss: 2.574692044399512

Epoch: 5| Step: 4
Training loss: 2.716247371386166
Validation loss: 2.542829633460861

Epoch: 5| Step: 5
Training loss: 1.921544612615774
Validation loss: 2.5227311933685077

Epoch: 5| Step: 6
Training loss: 2.405784462816809
Validation loss: 2.5427058304693886

Epoch: 5| Step: 7
Training loss: 2.2232323086085204
Validation loss: 2.4832496581240893

Epoch: 5| Step: 8
Training loss: 1.5906113030044402
Validation loss: 2.5312343563000024

Epoch: 5| Step: 9
Training loss: 2.4826006040903823
Validation loss: 2.5394708443578717

Epoch: 5| Step: 10
Training loss: 1.9642525422404005
Validation loss: 2.501432941324266

Epoch: 513| Step: 0
Training loss: 2.3499159006532175
Validation loss: 2.499460908745191

Epoch: 5| Step: 1
Training loss: 2.4778098445959413
Validation loss: 2.503287942496492

Epoch: 5| Step: 2
Training loss: 2.0887214285210787
Validation loss: 2.5568323433174043

Epoch: 5| Step: 3
Training loss: 1.8992695182188026
Validation loss: 2.546921980813516

Epoch: 5| Step: 4
Training loss: 2.6785001654454876
Validation loss: 2.571375630768544

Epoch: 5| Step: 5
Training loss: 1.4956629359419318
Validation loss: 2.522295034231656

Epoch: 5| Step: 6
Training loss: 1.8309714824845391
Validation loss: 2.473078756052248

Epoch: 5| Step: 7
Training loss: 2.1877920773199597
Validation loss: 2.5218571883998564

Epoch: 5| Step: 8
Training loss: 2.194973848226209
Validation loss: 2.525075867434099

Epoch: 5| Step: 9
Training loss: 2.5663381535569507
Validation loss: 2.4724467460817925

Epoch: 5| Step: 10
Training loss: 1.8470740661227985
Validation loss: 2.503803626762145

Epoch: 514| Step: 0
Training loss: 2.3774873858737955
Validation loss: 2.5926843503245074

Epoch: 5| Step: 1
Training loss: 2.139500454860923
Validation loss: 2.511658741943475

Epoch: 5| Step: 2
Training loss: 1.5009464615811041
Validation loss: 2.543400209763366

Epoch: 5| Step: 3
Training loss: 2.256635418463788
Validation loss: 2.5153138606432264

Epoch: 5| Step: 4
Training loss: 2.3619665603273243
Validation loss: 2.52638269694906

Epoch: 5| Step: 5
Training loss: 1.6590958383802865
Validation loss: 2.6321706324451775

Epoch: 5| Step: 6
Training loss: 2.5190287244127454
Validation loss: 2.484457178576065

Epoch: 5| Step: 7
Training loss: 1.9555674425520038
Validation loss: 2.490793308343545

Epoch: 5| Step: 8
Training loss: 2.493728591712325
Validation loss: 2.5616825199433926

Epoch: 5| Step: 9
Training loss: 1.927003051185271
Validation loss: 2.5715280553430815

Epoch: 5| Step: 10
Training loss: 1.6908036847975292
Validation loss: 2.50579845317421

Epoch: 515| Step: 0
Training loss: 2.2046219089410903
Validation loss: 2.5248798309682505

Epoch: 5| Step: 1
Training loss: 2.6116735876105683
Validation loss: 2.5012154629049275

Epoch: 5| Step: 2
Training loss: 2.041844600267872
Validation loss: 2.5623123536434695

Epoch: 5| Step: 3
Training loss: 2.1975457720714537
Validation loss: 2.549064998693999

Epoch: 5| Step: 4
Training loss: 2.073505631041119
Validation loss: 2.5375366553409058

Epoch: 5| Step: 5
Training loss: 1.9491607106957587
Validation loss: 2.494329761492204

Epoch: 5| Step: 6
Training loss: 2.1529543472673165
Validation loss: 2.5386085537360317

Epoch: 5| Step: 7
Training loss: 1.985419231411804
Validation loss: 2.530061362960985

Epoch: 5| Step: 8
Training loss: 2.1319249580588977
Validation loss: 2.6125255367386924

Epoch: 5| Step: 9
Training loss: 1.8477873483485043
Validation loss: 2.513174353366032

Epoch: 5| Step: 10
Training loss: 2.352698169108557
Validation loss: 2.520815539485811

Epoch: 516| Step: 0
Training loss: 2.0024020552285924
Validation loss: 2.5292006805279454

Epoch: 5| Step: 1
Training loss: 2.145206421565414
Validation loss: 2.5759297575524522

Epoch: 5| Step: 2
Training loss: 2.498829663043483
Validation loss: 2.506025581703899

Epoch: 5| Step: 3
Training loss: 2.152478222531908
Validation loss: 2.537342903159683

Epoch: 5| Step: 4
Training loss: 1.217639612891653
Validation loss: 2.540206894109808

Epoch: 5| Step: 5
Training loss: 2.0659069474822718
Validation loss: 2.5523988757633598

Epoch: 5| Step: 6
Training loss: 2.4866322753137093
Validation loss: 2.5679597234633293

Epoch: 5| Step: 7
Training loss: 2.3121207673761615
Validation loss: 2.5755640360961958

Epoch: 5| Step: 8
Training loss: 2.28828693049264
Validation loss: 2.5426464851660784

Epoch: 5| Step: 9
Training loss: 1.992787708297549
Validation loss: 2.518579222878641

Epoch: 5| Step: 10
Training loss: 2.5807463295395077
Validation loss: 2.5507275802271967

Epoch: 517| Step: 0
Training loss: 2.2119486622914732
Validation loss: 2.5053788065441625

Epoch: 5| Step: 1
Training loss: 1.9659385588738132
Validation loss: 2.4939280143323823

Epoch: 5| Step: 2
Training loss: 1.8542368443384851
Validation loss: 2.528511684973797

Epoch: 5| Step: 3
Training loss: 1.7199529426258766
Validation loss: 2.4706638467787423

Epoch: 5| Step: 4
Training loss: 1.8542519524779886
Validation loss: 2.566658737187415

Epoch: 5| Step: 5
Training loss: 3.1007798598313525
Validation loss: 2.4427269928051563

Epoch: 5| Step: 6
Training loss: 2.473482930868061
Validation loss: 2.565108163715049

Epoch: 5| Step: 7
Training loss: 2.1411014221628535
Validation loss: 2.561054569406476

Epoch: 5| Step: 8
Training loss: 1.631677114175944
Validation loss: 2.5331215005929213

Epoch: 5| Step: 9
Training loss: 2.1423957350653544
Validation loss: 2.5023363179276883

Epoch: 5| Step: 10
Training loss: 1.855537429341597
Validation loss: 2.565192687936679

Epoch: 518| Step: 0
Training loss: 2.423181292273822
Validation loss: 2.506795824366422

Epoch: 5| Step: 1
Training loss: 1.5246868781393246
Validation loss: 2.5445966154408906

Epoch: 5| Step: 2
Training loss: 1.8392909164990043
Validation loss: 2.5369671754248833

Epoch: 5| Step: 3
Training loss: 2.3482528157054356
Validation loss: 2.570574592507849

Epoch: 5| Step: 4
Training loss: 2.087280869546608
Validation loss: 2.5567917792700423

Epoch: 5| Step: 5
Training loss: 2.092410783768571
Validation loss: 2.514176153460064

Epoch: 5| Step: 6
Training loss: 2.514549641566526
Validation loss: 2.5069054641157242

Epoch: 5| Step: 7
Training loss: 1.7613840398417735
Validation loss: 2.5415226626405683

Epoch: 5| Step: 8
Training loss: 1.5641847301666993
Validation loss: 2.53477755033064

Epoch: 5| Step: 9
Training loss: 2.9050141034465122
Validation loss: 2.5166414785914113

Epoch: 5| Step: 10
Training loss: 1.8507549601241966
Validation loss: 2.5668272812249007

Epoch: 519| Step: 0
Training loss: 1.962608628394903
Validation loss: 2.589449250844721

Epoch: 5| Step: 1
Training loss: 2.332207601195585
Validation loss: 2.5389873383080186

Epoch: 5| Step: 2
Training loss: 1.563332755380834
Validation loss: 2.5582490562492324

Epoch: 5| Step: 3
Training loss: 2.0954343938112427
Validation loss: 2.6298636983219774

Epoch: 5| Step: 4
Training loss: 1.7843313502436027
Validation loss: 2.5101876062227286

Epoch: 5| Step: 5
Training loss: 2.3047045690906574
Validation loss: 2.5407960719675797

Epoch: 5| Step: 6
Training loss: 2.530595294441703
Validation loss: 2.5600988952444044

Epoch: 5| Step: 7
Training loss: 2.1849081761250617
Validation loss: 2.4813562762788193

Epoch: 5| Step: 8
Training loss: 2.1105467755905263
Validation loss: 2.5412771295300316

Epoch: 5| Step: 9
Training loss: 2.156146171392016
Validation loss: 2.5330167190687045

Epoch: 5| Step: 10
Training loss: 2.4622408851581095
Validation loss: 2.5178258897695414

Epoch: 520| Step: 0
Training loss: 1.97189406976683
Validation loss: 2.548475994233007

Epoch: 5| Step: 1
Training loss: 2.0120452319648314
Validation loss: 2.584506433058763

Epoch: 5| Step: 2
Training loss: 2.1422976898857553
Validation loss: 2.5004055945236154

Epoch: 5| Step: 3
Training loss: 2.325343678822529
Validation loss: 2.5650432870321014

Epoch: 5| Step: 4
Training loss: 1.3627329600949611
Validation loss: 2.5997709154437927

Epoch: 5| Step: 5
Training loss: 2.703472401780932
Validation loss: 2.5470757177918943

Epoch: 5| Step: 6
Training loss: 2.27771066422045
Validation loss: 2.4772378628147425

Epoch: 5| Step: 7
Training loss: 2.26868069545516
Validation loss: 2.4389905450342484

Epoch: 5| Step: 8
Training loss: 1.6715933303999357
Validation loss: 2.557586954286738

Epoch: 5| Step: 9
Training loss: 1.8657856550964127
Validation loss: 2.5344837051962568

Epoch: 5| Step: 10
Training loss: 2.352436194856898
Validation loss: 2.616391202625382

Epoch: 521| Step: 0
Training loss: 2.0026517216691584
Validation loss: 2.5076503476980534

Epoch: 5| Step: 1
Training loss: 2.0475557083544023
Validation loss: 2.540086251500469

Epoch: 5| Step: 2
Training loss: 2.1060980314676367
Validation loss: 2.521998387847846

Epoch: 5| Step: 3
Training loss: 2.27127465209011
Validation loss: 2.5075083474592925

Epoch: 5| Step: 4
Training loss: 1.7112411159956316
Validation loss: 2.5166944226670713

Epoch: 5| Step: 5
Training loss: 1.6991970718579468
Validation loss: 2.558619870288378

Epoch: 5| Step: 6
Training loss: 2.834741093084047
Validation loss: 2.5209015691504058

Epoch: 5| Step: 7
Training loss: 2.264274563016246
Validation loss: 2.5458714677081913

Epoch: 5| Step: 8
Training loss: 2.154331625470517
Validation loss: 2.578250036504548

Epoch: 5| Step: 9
Training loss: 1.9232575940580103
Validation loss: 2.5343349085766826

Epoch: 5| Step: 10
Training loss: 1.9731842240926851
Validation loss: 2.5307431409203867

Epoch: 522| Step: 0
Training loss: 1.9730379547358554
Validation loss: 2.5967720198986832

Epoch: 5| Step: 1
Training loss: 1.9536487334909645
Validation loss: 2.530325497561848

Epoch: 5| Step: 2
Training loss: 1.8057700869274695
Validation loss: 2.5308334319754024

Epoch: 5| Step: 3
Training loss: 2.741351051677164
Validation loss: 2.555361750052987

Epoch: 5| Step: 4
Training loss: 1.5131661831696424
Validation loss: 2.538304597808863

Epoch: 5| Step: 5
Training loss: 2.012305194595867
Validation loss: 2.60423145746828

Epoch: 5| Step: 6
Training loss: 2.38867776391215
Validation loss: 2.6017996293699395

Epoch: 5| Step: 7
Training loss: 2.2378365972079424
Validation loss: 2.5412680644361183

Epoch: 5| Step: 8
Training loss: 1.8573327268753286
Validation loss: 2.5156834500726792

Epoch: 5| Step: 9
Training loss: 2.2422993595518594
Validation loss: 2.5834235748846655

Epoch: 5| Step: 10
Training loss: 2.260134127021059
Validation loss: 2.5429837801513857

Epoch: 523| Step: 0
Training loss: 1.8635408552525905
Validation loss: 2.497181178984277

Epoch: 5| Step: 1
Training loss: 2.542370422572224
Validation loss: 2.507437598394297

Epoch: 5| Step: 2
Training loss: 1.9705962954583245
Validation loss: 2.589019284335832

Epoch: 5| Step: 3
Training loss: 2.013919078849084
Validation loss: 2.562819208651925

Epoch: 5| Step: 4
Training loss: 2.0363745968929314
Validation loss: 2.554434685115691

Epoch: 5| Step: 5
Training loss: 1.672846574213593
Validation loss: 2.4938646176128554

Epoch: 5| Step: 6
Training loss: 2.00995103520208
Validation loss: 2.578735328541796

Epoch: 5| Step: 7
Training loss: 2.1411127801631396
Validation loss: 2.5109960818112365

Epoch: 5| Step: 8
Training loss: 2.254793570938676
Validation loss: 2.5980625527828707

Epoch: 5| Step: 9
Training loss: 2.351345318368482
Validation loss: 2.474805221980917

Epoch: 5| Step: 10
Training loss: 1.9972690772495467
Validation loss: 2.4726160116115756

Epoch: 524| Step: 0
Training loss: 2.119755500153763
Validation loss: 2.5670090778029775

Epoch: 5| Step: 1
Training loss: 1.9502231250168438
Validation loss: 2.5434328462266516

Epoch: 5| Step: 2
Training loss: 2.0685067993303123
Validation loss: 2.4951288702408942

Epoch: 5| Step: 3
Training loss: 2.417920631336637
Validation loss: 2.518296605705449

Epoch: 5| Step: 4
Training loss: 2.3627095689617
Validation loss: 2.572045463248044

Epoch: 5| Step: 5
Training loss: 2.278172128030295
Validation loss: 2.5428762000540495

Epoch: 5| Step: 6
Training loss: 1.7743137564306815
Validation loss: 2.603513966791321

Epoch: 5| Step: 7
Training loss: 2.121795257283456
Validation loss: 2.4943916602465586

Epoch: 5| Step: 8
Training loss: 1.6193577306806428
Validation loss: 2.5601778671298945

Epoch: 5| Step: 9
Training loss: 2.4946350706856455
Validation loss: 2.5332627087314017

Epoch: 5| Step: 10
Training loss: 1.8615174332344675
Validation loss: 2.53894105884297

Epoch: 525| Step: 0
Training loss: 1.73392006345982
Validation loss: 2.565851323585968

Epoch: 5| Step: 1
Training loss: 2.273927930651094
Validation loss: 2.4664382328955377

Epoch: 5| Step: 2
Training loss: 1.8326896346618733
Validation loss: 2.570747993640211

Epoch: 5| Step: 3
Training loss: 2.4015197829528323
Validation loss: 2.488818405660897

Epoch: 5| Step: 4
Training loss: 2.44675176512336
Validation loss: 2.5388390802951606

Epoch: 5| Step: 5
Training loss: 1.7185958793204517
Validation loss: 2.5415240707890723

Epoch: 5| Step: 6
Training loss: 1.9215989573654535
Validation loss: 2.5287863722311603

Epoch: 5| Step: 7
Training loss: 1.7198957612366086
Validation loss: 2.507092063909454

Epoch: 5| Step: 8
Training loss: 1.9647364805149343
Validation loss: 2.5490038010228186

Epoch: 5| Step: 9
Training loss: 2.8063879782011423
Validation loss: 2.567571639912228

Epoch: 5| Step: 10
Training loss: 2.1231830907672955
Validation loss: 2.513112314352805

Epoch: 526| Step: 0
Training loss: 2.3731806964582347
Validation loss: 2.582877477808162

Epoch: 5| Step: 1
Training loss: 1.7709121536963992
Validation loss: 2.5073753039479514

Epoch: 5| Step: 2
Training loss: 1.7379857187112366
Validation loss: 2.594181732054087

Epoch: 5| Step: 3
Training loss: 1.7940667806420474
Validation loss: 2.4373030276628582

Epoch: 5| Step: 4
Training loss: 2.6410525726320273
Validation loss: 2.610014689378267

Epoch: 5| Step: 5
Training loss: 1.9241910795389818
Validation loss: 2.5988108442897637

Epoch: 5| Step: 6
Training loss: 2.269615605111271
Validation loss: 2.5813832903383256

Epoch: 5| Step: 7
Training loss: 2.5985186758568535
Validation loss: 2.5591327604535388

Epoch: 5| Step: 8
Training loss: 1.5355275411269333
Validation loss: 2.5660892423829176

Epoch: 5| Step: 9
Training loss: 1.908498095044971
Validation loss: 2.5232248422711545

Epoch: 5| Step: 10
Training loss: 1.9537859599391252
Validation loss: 2.5532159996908055

Epoch: 527| Step: 0
Training loss: 2.634121261087886
Validation loss: 2.5109518011215144

Epoch: 5| Step: 1
Training loss: 1.8917075596673207
Validation loss: 2.52553936795845

Epoch: 5| Step: 2
Training loss: 2.1909557838313627
Validation loss: 2.5611761381562324

Epoch: 5| Step: 3
Training loss: 2.3174918655861783
Validation loss: 2.559788034935261

Epoch: 5| Step: 4
Training loss: 1.938646531040265
Validation loss: 2.5010837477298957

Epoch: 5| Step: 5
Training loss: 2.0232072500362195
Validation loss: 2.5707379006019706

Epoch: 5| Step: 6
Training loss: 1.7046458602001502
Validation loss: 2.5429851219628485

Epoch: 5| Step: 7
Training loss: 2.044920709094104
Validation loss: 2.5152274594523867

Epoch: 5| Step: 8
Training loss: 1.9031027781625138
Validation loss: 2.5117641419292394

Epoch: 5| Step: 9
Training loss: 2.4682660171667568
Validation loss: 2.5408092720594184

Epoch: 5| Step: 10
Training loss: 1.890162766123644
Validation loss: 2.5427301590220095

Epoch: 528| Step: 0
Training loss: 1.913263146224068
Validation loss: 2.5151209947038313

Epoch: 5| Step: 1
Training loss: 2.0083567553324415
Validation loss: 2.5627895584801275

Epoch: 5| Step: 2
Training loss: 2.4292570757086147
Validation loss: 2.55529017992919

Epoch: 5| Step: 3
Training loss: 2.350445047806906
Validation loss: 2.5294320026739396

Epoch: 5| Step: 4
Training loss: 1.8653179050136537
Validation loss: 2.5392460087673547

Epoch: 5| Step: 5
Training loss: 1.9007783750989742
Validation loss: 2.573471299174811

Epoch: 5| Step: 6
Training loss: 1.722301697520886
Validation loss: 2.5036421983372246

Epoch: 5| Step: 7
Training loss: 2.166433529659712
Validation loss: 2.4724140508372394

Epoch: 5| Step: 8
Training loss: 1.7091109746634974
Validation loss: 2.539497650948028

Epoch: 5| Step: 9
Training loss: 2.1758360384989177
Validation loss: 2.501539927142601

Epoch: 5| Step: 10
Training loss: 2.3812468841612446
Validation loss: 2.5717197513947774

Epoch: 529| Step: 0
Training loss: 1.9414163815638865
Validation loss: 2.587513496593983

Epoch: 5| Step: 1
Training loss: 2.6729865188173045
Validation loss: 2.5071168801846735

Epoch: 5| Step: 2
Training loss: 1.8768213962213371
Validation loss: 2.5768518057888987

Epoch: 5| Step: 3
Training loss: 2.023880486619972
Validation loss: 2.565543367647154

Epoch: 5| Step: 4
Training loss: 1.9229977437371613
Validation loss: 2.534524148853131

Epoch: 5| Step: 5
Training loss: 2.1494760673345934
Validation loss: 2.5439950078055027

Epoch: 5| Step: 6
Training loss: 1.7270756990135931
Validation loss: 2.5622209496554786

Epoch: 5| Step: 7
Training loss: 1.8386855316789539
Validation loss: 2.5383799054558294

Epoch: 5| Step: 8
Training loss: 2.046818390274553
Validation loss: 2.5911167554769183

Epoch: 5| Step: 9
Training loss: 1.8567169167357802
Validation loss: 2.527028368320932

Epoch: 5| Step: 10
Training loss: 2.9378898848847292
Validation loss: 2.5115901553231317

Epoch: 530| Step: 0
Training loss: 1.8170781687338227
Validation loss: 2.4872487647116346

Epoch: 5| Step: 1
Training loss: 2.1534187415499892
Validation loss: 2.4774066716468424

Epoch: 5| Step: 2
Training loss: 1.9121000233188705
Validation loss: 2.552148372046587

Epoch: 5| Step: 3
Training loss: 2.6615795747398048
Validation loss: 2.5520281402533

Epoch: 5| Step: 4
Training loss: 1.8967511886084127
Validation loss: 2.5171672007372528

Epoch: 5| Step: 5
Training loss: 2.4955111257939087
Validation loss: 2.5311540225645923

Epoch: 5| Step: 6
Training loss: 1.6422576773155249
Validation loss: 2.5666326767351917

Epoch: 5| Step: 7
Training loss: 2.0736697057593294
Validation loss: 2.5425176932288087

Epoch: 5| Step: 8
Training loss: 1.9657616717882171
Validation loss: 2.5642035039591287

Epoch: 5| Step: 9
Training loss: 2.183096786478346
Validation loss: 2.5517358948148567

Epoch: 5| Step: 10
Training loss: 2.0745304541569425
Validation loss: 2.499281049736997

Epoch: 531| Step: 0
Training loss: 2.045905429582324
Validation loss: 2.511713044437851

Epoch: 5| Step: 1
Training loss: 2.2129513899699913
Validation loss: 2.4989642581877067

Epoch: 5| Step: 2
Training loss: 2.2877589344996148
Validation loss: 2.563159631125991

Epoch: 5| Step: 3
Training loss: 2.4920135724354786
Validation loss: 2.511341777388209

Epoch: 5| Step: 4
Training loss: 1.7137148536734248
Validation loss: 2.564131968667239

Epoch: 5| Step: 5
Training loss: 2.1173344522412383
Validation loss: 2.5121092480889824

Epoch: 5| Step: 6
Training loss: 1.3770138558055636
Validation loss: 2.5342187521268085

Epoch: 5| Step: 7
Training loss: 1.9015076854268633
Validation loss: 2.5211394702176246

Epoch: 5| Step: 8
Training loss: 1.8237992320955476
Validation loss: 2.463795696156155

Epoch: 5| Step: 9
Training loss: 1.4985923520008988
Validation loss: 2.5143607077222025

Epoch: 5| Step: 10
Training loss: 2.5619638393807267
Validation loss: 2.542803173529115

Epoch: 532| Step: 0
Training loss: 1.8664830367275245
Validation loss: 2.557374815573504

Epoch: 5| Step: 1
Training loss: 2.1884801576066524
Validation loss: 2.536456143951701

Epoch: 5| Step: 2
Training loss: 2.071314846167904
Validation loss: 2.5915797089178962

Epoch: 5| Step: 3
Training loss: 1.6595679822871499
Validation loss: 2.4933647065159965

Epoch: 5| Step: 4
Training loss: 1.663250720674309
Validation loss: 2.5781761385611737

Epoch: 5| Step: 5
Training loss: 2.494599230730349
Validation loss: 2.5304953866834268

Epoch: 5| Step: 6
Training loss: 2.0727888160524577
Validation loss: 2.557153837956099

Epoch: 5| Step: 7
Training loss: 1.8443040177050258
Validation loss: 2.516939554887605

Epoch: 5| Step: 8
Training loss: 1.9477177346658536
Validation loss: 2.5140578276779073

Epoch: 5| Step: 9
Training loss: 2.812430402106533
Validation loss: 2.5245330991301693

Epoch: 5| Step: 10
Training loss: 2.1732520259477806
Validation loss: 2.4928942499340674

Epoch: 533| Step: 0
Training loss: 1.8083256631972728
Validation loss: 2.501356798561017

Epoch: 5| Step: 1
Training loss: 1.6883859781089243
Validation loss: 2.487808981965707

Epoch: 5| Step: 2
Training loss: 2.102537361566021
Validation loss: 2.4985354676584195

Epoch: 5| Step: 3
Training loss: 1.5604517672588551
Validation loss: 2.501569956384273

Epoch: 5| Step: 4
Training loss: 2.5245342882698476
Validation loss: 2.5173509348681438

Epoch: 5| Step: 5
Training loss: 2.3173239628536875
Validation loss: 2.5758353896794413

Epoch: 5| Step: 6
Training loss: 2.480583801004298
Validation loss: 2.5491633731165453

Epoch: 5| Step: 7
Training loss: 1.9276772966988354
Validation loss: 2.5511892179320315

Epoch: 5| Step: 8
Training loss: 1.69816075854232
Validation loss: 2.552218936400647

Epoch: 5| Step: 9
Training loss: 2.7118799511718565
Validation loss: 2.536995378711515

Epoch: 5| Step: 10
Training loss: 1.6995081161884331
Validation loss: 2.505432546281325

Epoch: 534| Step: 0
Training loss: 1.5337614367120047
Validation loss: 2.530910856618293

Epoch: 5| Step: 1
Training loss: 2.043726122422097
Validation loss: 2.5509698108990215

Epoch: 5| Step: 2
Training loss: 2.3132250912029293
Validation loss: 2.523189530335309

Epoch: 5| Step: 3
Training loss: 2.454641177337079
Validation loss: 2.561257531109417

Epoch: 5| Step: 4
Training loss: 2.03689097095934
Validation loss: 2.529401558249753

Epoch: 5| Step: 5
Training loss: 1.9448963624070437
Validation loss: 2.557031022252829

Epoch: 5| Step: 6
Training loss: 1.8404428595948297
Validation loss: 2.4821218679143273

Epoch: 5| Step: 7
Training loss: 2.3042905303976373
Validation loss: 2.531953002787001

Epoch: 5| Step: 8
Training loss: 2.0189190347959176
Validation loss: 2.552426042748718

Epoch: 5| Step: 9
Training loss: 2.192347795168565
Validation loss: 2.547811040611596

Epoch: 5| Step: 10
Training loss: 2.0663752129861375
Validation loss: 2.522082668466511

Epoch: 535| Step: 0
Training loss: 1.8602321796709478
Validation loss: 2.499035915993145

Epoch: 5| Step: 1
Training loss: 2.778720777240389
Validation loss: 2.5312626690372175

Epoch: 5| Step: 2
Training loss: 1.99573138805543
Validation loss: 2.6011328474985604

Epoch: 5| Step: 3
Training loss: 1.991796716995667
Validation loss: 2.5321686826039658

Epoch: 5| Step: 4
Training loss: 1.7262687605847336
Validation loss: 2.476387449660139

Epoch: 5| Step: 5
Training loss: 2.3045295273256263
Validation loss: 2.58776093646943

Epoch: 5| Step: 6
Training loss: 1.7464825839428302
Validation loss: 2.4994372421521787

Epoch: 5| Step: 7
Training loss: 2.4776613703735735
Validation loss: 2.555622476771879

Epoch: 5| Step: 8
Training loss: 1.959775420771375
Validation loss: 2.5881960259603582

Epoch: 5| Step: 9
Training loss: 2.0140720269545334
Validation loss: 2.5670329653052013

Epoch: 5| Step: 10
Training loss: 1.912627760665075
Validation loss: 2.5107378377429352

Epoch: 536| Step: 0
Training loss: 1.7836639377119479
Validation loss: 2.5458626676982465

Epoch: 5| Step: 1
Training loss: 2.3147657481044193
Validation loss: 2.4968617687403287

Epoch: 5| Step: 2
Training loss: 1.8312193285355718
Validation loss: 2.5847966644002844

Epoch: 5| Step: 3
Training loss: 2.541965738013088
Validation loss: 2.5752701998786196

Epoch: 5| Step: 4
Training loss: 2.0828792712990767
Validation loss: 2.4951457734123337

Epoch: 5| Step: 5
Training loss: 1.8920672881720093
Validation loss: 2.5135773024102437

Epoch: 5| Step: 6
Training loss: 1.9697930131407004
Validation loss: 2.564593592633605

Epoch: 5| Step: 7
Training loss: 1.728565348971416
Validation loss: 2.543432478326669

Epoch: 5| Step: 8
Training loss: 1.9230078483060349
Validation loss: 2.6016915242024274

Epoch: 5| Step: 9
Training loss: 1.9034731917541379
Validation loss: 2.5479013204688883

Epoch: 5| Step: 10
Training loss: 2.480744306021709
Validation loss: 2.57670978025283

Epoch: 537| Step: 0
Training loss: 1.6455885145733287
Validation loss: 2.5168223246589685

Epoch: 5| Step: 1
Training loss: 1.8940011138107102
Validation loss: 2.5485788244397227

Epoch: 5| Step: 2
Training loss: 2.1327130081390346
Validation loss: 2.5388882777767248

Epoch: 5| Step: 3
Training loss: 1.8244034144772103
Validation loss: 2.4781992999962505

Epoch: 5| Step: 4
Training loss: 2.061082873303793
Validation loss: 2.545701550341807

Epoch: 5| Step: 5
Training loss: 2.2601010033309503
Validation loss: 2.550151080578767

Epoch: 5| Step: 6
Training loss: 1.930582618828619
Validation loss: 2.55289878717151

Epoch: 5| Step: 7
Training loss: 2.3916581857067913
Validation loss: 2.5745121794563395

Epoch: 5| Step: 8
Training loss: 2.009118275238291
Validation loss: 2.509128815327329

Epoch: 5| Step: 9
Training loss: 2.0879881419433386
Validation loss: 2.547614004409245

Epoch: 5| Step: 10
Training loss: 2.2177510766431068
Validation loss: 2.6147767813182496

Epoch: 538| Step: 0
Training loss: 1.8304819416738165
Validation loss: 2.60483740029962

Epoch: 5| Step: 1
Training loss: 2.3522135191423907
Validation loss: 2.5847573683831295

Epoch: 5| Step: 2
Training loss: 1.863474901800532
Validation loss: 2.514908829470556

Epoch: 5| Step: 3
Training loss: 1.985432320606795
Validation loss: 2.5543271261184706

Epoch: 5| Step: 4
Training loss: 1.345016370694959
Validation loss: 2.5725482226661898

Epoch: 5| Step: 5
Training loss: 2.01123835188656
Validation loss: 2.576929404227637

Epoch: 5| Step: 6
Training loss: 2.1497690963952762
Validation loss: 2.523936703936446

Epoch: 5| Step: 7
Training loss: 2.00093319102581
Validation loss: 2.4816900505992217

Epoch: 5| Step: 8
Training loss: 2.8286729144871665
Validation loss: 2.5514276061829197

Epoch: 5| Step: 9
Training loss: 1.9244938816717607
Validation loss: 2.498211957515143

Epoch: 5| Step: 10
Training loss: 1.7898631740466844
Validation loss: 2.558074854968875

Epoch: 539| Step: 0
Training loss: 2.6859756404882726
Validation loss: 2.514290104571405

Epoch: 5| Step: 1
Training loss: 1.8661448867742927
Validation loss: 2.5853657499502454

Epoch: 5| Step: 2
Training loss: 2.072819296947776
Validation loss: 2.5514394751987197

Epoch: 5| Step: 3
Training loss: 1.7577035827801606
Validation loss: 2.553054930669475

Epoch: 5| Step: 4
Training loss: 2.076670890832384
Validation loss: 2.5372735407037914

Epoch: 5| Step: 5
Training loss: 2.2463109185094448
Validation loss: 2.533671904854598

Epoch: 5| Step: 6
Training loss: 1.7018666649711327
Validation loss: 2.5370640101148867

Epoch: 5| Step: 7
Training loss: 2.1219717776177194
Validation loss: 2.556990019210323

Epoch: 5| Step: 8
Training loss: 2.516240204641849
Validation loss: 2.549814120391888

Epoch: 5| Step: 9
Training loss: 1.8088670033941183
Validation loss: 2.564879204556041

Epoch: 5| Step: 10
Training loss: 1.780035441399395
Validation loss: 2.5359464702786587

Epoch: 540| Step: 0
Training loss: 1.9133913693060836
Validation loss: 2.5410629239935574

Epoch: 5| Step: 1
Training loss: 2.3706233203659726
Validation loss: 2.5025425943145065

Epoch: 5| Step: 2
Training loss: 1.840676671907413
Validation loss: 2.6180627962277794

Epoch: 5| Step: 3
Training loss: 1.4299243668248602
Validation loss: 2.521284587935895

Epoch: 5| Step: 4
Training loss: 2.366866187519181
Validation loss: 2.5433366269768065

Epoch: 5| Step: 5
Training loss: 2.516010325994362
Validation loss: 2.531164279520859

Epoch: 5| Step: 6
Training loss: 1.8754050135283995
Validation loss: 2.584857358811023

Epoch: 5| Step: 7
Training loss: 1.5529834091764296
Validation loss: 2.525634412768898

Epoch: 5| Step: 8
Training loss: 2.3835618138557244
Validation loss: 2.5342801075443115

Epoch: 5| Step: 9
Training loss: 1.9484987324237493
Validation loss: 2.574793527913087

Epoch: 5| Step: 10
Training loss: 2.2002982544299003
Validation loss: 2.516571993277289

Epoch: 541| Step: 0
Training loss: 1.545554242641264
Validation loss: 2.544153606267515

Epoch: 5| Step: 1
Training loss: 1.707367678384089
Validation loss: 2.572236616430916

Epoch: 5| Step: 2
Training loss: 1.980025864538166
Validation loss: 2.5643691322437254

Epoch: 5| Step: 3
Training loss: 2.7245517957065513
Validation loss: 2.598525505925446

Epoch: 5| Step: 4
Training loss: 2.4932925844517584
Validation loss: 2.5225149749324696

Epoch: 5| Step: 5
Training loss: 2.2959766317833177
Validation loss: 2.5737624312545164

Epoch: 5| Step: 6
Training loss: 1.7648110327995712
Validation loss: 2.571636606072546

Epoch: 5| Step: 7
Training loss: 1.6366096405588195
Validation loss: 2.539368452975671

Epoch: 5| Step: 8
Training loss: 2.055294164871903
Validation loss: 2.4698734928000947

Epoch: 5| Step: 9
Training loss: 1.9371966462920147
Validation loss: 2.5287995483344883

Epoch: 5| Step: 10
Training loss: 2.114720783245123
Validation loss: 2.543576482408967

Epoch: 542| Step: 0
Training loss: 1.4760223692514418
Validation loss: 2.5387857477830553

Epoch: 5| Step: 1
Training loss: 2.327864459519611
Validation loss: 2.526756105582188

Epoch: 5| Step: 2
Training loss: 2.430472293214781
Validation loss: 2.454009206662097

Epoch: 5| Step: 3
Training loss: 2.4284581450479554
Validation loss: 2.576427396261658

Epoch: 5| Step: 4
Training loss: 2.1897185927794385
Validation loss: 2.4840925059547905

Epoch: 5| Step: 5
Training loss: 1.6647141304557116
Validation loss: 2.4800292569064535

Epoch: 5| Step: 6
Training loss: 2.3480172538253363
Validation loss: 2.623994299634184

Epoch: 5| Step: 7
Training loss: 1.9459088495319212
Validation loss: 2.552382369328243

Epoch: 5| Step: 8
Training loss: 1.737906769265736
Validation loss: 2.5177170850140658

Epoch: 5| Step: 9
Training loss: 1.6756198334036216
Validation loss: 2.574044456247438

Epoch: 5| Step: 10
Training loss: 1.5982819989618748
Validation loss: 2.519885045914748

Epoch: 543| Step: 0
Training loss: 1.9536728967839456
Validation loss: 2.5259436526289454

Epoch: 5| Step: 1
Training loss: 2.2276204055457054
Validation loss: 2.516766473064675

Epoch: 5| Step: 2
Training loss: 1.9465093033472967
Validation loss: 2.522706654673437

Epoch: 5| Step: 3
Training loss: 1.74673689021597
Validation loss: 2.5759605572254727

Epoch: 5| Step: 4
Training loss: 2.4157388045927854
Validation loss: 2.5717920365745166

Epoch: 5| Step: 5
Training loss: 1.9034369302315706
Validation loss: 2.5326321604892814

Epoch: 5| Step: 6
Training loss: 2.220868778005552
Validation loss: 2.5320061278841957

Epoch: 5| Step: 7
Training loss: 1.5587540546477687
Validation loss: 2.530685648513922

Epoch: 5| Step: 8
Training loss: 2.338326753682754
Validation loss: 2.592048742390139

Epoch: 5| Step: 9
Training loss: 1.9267365908336183
Validation loss: 2.47606561640478

Epoch: 5| Step: 10
Training loss: 2.2381794159044355
Validation loss: 2.5350063561606606

Epoch: 544| Step: 0
Training loss: 1.8098978239272627
Validation loss: 2.5011022557890135

Epoch: 5| Step: 1
Training loss: 1.7426414411543727
Validation loss: 2.5040474255899228

Epoch: 5| Step: 2
Training loss: 2.158056635653473
Validation loss: 2.5078142429555697

Epoch: 5| Step: 3
Training loss: 2.02146114022728
Validation loss: 2.521528023378163

Epoch: 5| Step: 4
Training loss: 2.4753621077313293
Validation loss: 2.5127462073911078

Epoch: 5| Step: 5
Training loss: 1.5171633906074318
Validation loss: 2.493334966082343

Epoch: 5| Step: 6
Training loss: 2.7307539151093887
Validation loss: 2.5148746546188643

Epoch: 5| Step: 7
Training loss: 2.334678999832114
Validation loss: 2.5196223661025834

Epoch: 5| Step: 8
Training loss: 1.6667850055008229
Validation loss: 2.5974949550645796

Epoch: 5| Step: 9
Training loss: 2.2766574983798504
Validation loss: 2.5472953746907026

Epoch: 5| Step: 10
Training loss: 1.7521632312000874
Validation loss: 2.5581227094164194

Epoch: 545| Step: 0
Training loss: 2.0537202248066277
Validation loss: 2.547325712941822

Epoch: 5| Step: 1
Training loss: 2.3047010518338324
Validation loss: 2.498717087569936

Epoch: 5| Step: 2
Training loss: 1.6694793650267872
Validation loss: 2.5515446395514676

Epoch: 5| Step: 3
Training loss: 2.21847682936826
Validation loss: 2.5086596932556002

Epoch: 5| Step: 4
Training loss: 2.763954994608132
Validation loss: 2.4717682861103363

Epoch: 5| Step: 5
Training loss: 1.9874482274060028
Validation loss: 2.536974052973274

Epoch: 5| Step: 6
Training loss: 2.025420877493749
Validation loss: 2.587876542173591

Epoch: 5| Step: 7
Training loss: 2.3499218866879716
Validation loss: 2.5899611117525834

Epoch: 5| Step: 8
Training loss: 1.9760550348864954
Validation loss: 2.4867166040499993

Epoch: 5| Step: 9
Training loss: 1.3959235926051259
Validation loss: 2.5162781285555074

Epoch: 5| Step: 10
Training loss: 1.6954594561612413
Validation loss: 2.5221552124157998

Epoch: 546| Step: 0
Training loss: 2.049592987221864
Validation loss: 2.5277653068842763

Epoch: 5| Step: 1
Training loss: 1.883724197686872
Validation loss: 2.557402530161201

Epoch: 5| Step: 2
Training loss: 1.8174110832659744
Validation loss: 2.5433144331054964

Epoch: 5| Step: 3
Training loss: 2.218399020091135
Validation loss: 2.569870626892026

Epoch: 5| Step: 4
Training loss: 1.8677703713792084
Validation loss: 2.55699453191324

Epoch: 5| Step: 5
Training loss: 2.59085086440712
Validation loss: 2.4730215195037903

Epoch: 5| Step: 6
Training loss: 2.2108511217046094
Validation loss: 2.5757312708387725

Epoch: 5| Step: 7
Training loss: 2.0488116006393926
Validation loss: 2.519179313508274

Epoch: 5| Step: 8
Training loss: 1.488746550305371
Validation loss: 2.554467539383781

Epoch: 5| Step: 9
Training loss: 2.7045071105919978
Validation loss: 2.5028474957556917

Epoch: 5| Step: 10
Training loss: 1.369417127259849
Validation loss: 2.5617214663949617

Epoch: 547| Step: 0
Training loss: 2.224419991835927
Validation loss: 2.5538034943276893

Epoch: 5| Step: 1
Training loss: 2.1284505093829016
Validation loss: 2.569890471589935

Epoch: 5| Step: 2
Training loss: 2.5502475805331883
Validation loss: 2.539369996589925

Epoch: 5| Step: 3
Training loss: 1.740472608158415
Validation loss: 2.6029290367135394

Epoch: 5| Step: 4
Training loss: 1.2478188558636827
Validation loss: 2.5906181844896286

Epoch: 5| Step: 5
Training loss: 2.4163442155415185
Validation loss: 2.466195924121151

Epoch: 5| Step: 6
Training loss: 1.844855672055164
Validation loss: 2.544611738739801

Epoch: 5| Step: 7
Training loss: 1.3977117946413404
Validation loss: 2.5320620736263617

Epoch: 5| Step: 8
Training loss: 2.4656357256096424
Validation loss: 2.4903755844457645

Epoch: 5| Step: 9
Training loss: 2.2653155937705196
Validation loss: 2.482139737055869

Epoch: 5| Step: 10
Training loss: 2.193296871500624
Validation loss: 2.5254210974740596

Epoch: 548| Step: 0
Training loss: 1.6809230784393088
Validation loss: 2.543552958190395

Epoch: 5| Step: 1
Training loss: 2.280661101950635
Validation loss: 2.532712964580453

Epoch: 5| Step: 2
Training loss: 2.6692143628109433
Validation loss: 2.5315682259140044

Epoch: 5| Step: 3
Training loss: 2.1214765621259883
Validation loss: 2.5009265177480495

Epoch: 5| Step: 4
Training loss: 1.5077000709480541
Validation loss: 2.5573295054301166

Epoch: 5| Step: 5
Training loss: 1.9195361909348612
Validation loss: 2.493920846406228

Epoch: 5| Step: 6
Training loss: 2.680906680163743
Validation loss: 2.5724595970714446

Epoch: 5| Step: 7
Training loss: 1.4395906752727157
Validation loss: 2.5750299813388615

Epoch: 5| Step: 8
Training loss: 1.7644414395056653
Validation loss: 2.5070639588155763

Epoch: 5| Step: 9
Training loss: 1.8174616546993474
Validation loss: 2.593159247189609

Epoch: 5| Step: 10
Training loss: 2.1591192864191315
Validation loss: 2.5875707775484527

Epoch: 549| Step: 0
Training loss: 2.2118739648683428
Validation loss: 2.563360937492547

Epoch: 5| Step: 1
Training loss: 1.8396078877810165
Validation loss: 2.553311469124402

Epoch: 5| Step: 2
Training loss: 1.9370959691273995
Validation loss: 2.538636583270773

Epoch: 5| Step: 3
Training loss: 1.6193248243667182
Validation loss: 2.5008770655256747

Epoch: 5| Step: 4
Training loss: 2.035631940605552
Validation loss: 2.6334745593991262

Epoch: 5| Step: 5
Training loss: 2.1264311515162375
Validation loss: 2.5911339550804486

Epoch: 5| Step: 6
Training loss: 2.025175313071818
Validation loss: 2.5616180889211453

Epoch: 5| Step: 7
Training loss: 1.9950114860299626
Validation loss: 2.5067372427390877

Epoch: 5| Step: 8
Training loss: 2.3242911704184683
Validation loss: 2.489386713768861

Epoch: 5| Step: 9
Training loss: 2.056691863752156
Validation loss: 2.6106719351184724

Epoch: 5| Step: 10
Training loss: 2.6776894997607372
Validation loss: 2.5578186499337745

Epoch: 550| Step: 0
Training loss: 2.020240998385796
Validation loss: 2.5318383014664363

Epoch: 5| Step: 1
Training loss: 1.7999497353635199
Validation loss: 2.550238277917281

Epoch: 5| Step: 2
Training loss: 1.930267617443543
Validation loss: 2.5213297435925197

Epoch: 5| Step: 3
Training loss: 2.0892110562056256
Validation loss: 2.500721908238263

Epoch: 5| Step: 4
Training loss: 1.788640334781602
Validation loss: 2.472853912481444

Epoch: 5| Step: 5
Training loss: 1.7323092969164327
Validation loss: 2.5903550668113

Epoch: 5| Step: 6
Training loss: 2.4700990684811757
Validation loss: 2.561694911878436

Epoch: 5| Step: 7
Training loss: 1.6251932176013268
Validation loss: 2.5651403051145696

Epoch: 5| Step: 8
Training loss: 2.1007491455802736
Validation loss: 2.473246931414318

Epoch: 5| Step: 9
Training loss: 1.9295700593493303
Validation loss: 2.5412687423521167

Epoch: 5| Step: 10
Training loss: 2.237450250679907
Validation loss: 2.506511991085117

Epoch: 551| Step: 0
Training loss: 2.1289526138156667
Validation loss: 2.5746366237094267

Epoch: 5| Step: 1
Training loss: 2.151411959077939
Validation loss: 2.550111113967947

Epoch: 5| Step: 2
Training loss: 1.8338892122874642
Validation loss: 2.5423136882265176

Epoch: 5| Step: 3
Training loss: 2.0770928824258488
Validation loss: 2.5267901806122235

Epoch: 5| Step: 4
Training loss: 1.5559964444529257
Validation loss: 2.515745783363328

Epoch: 5| Step: 5
Training loss: 1.757890623263966
Validation loss: 2.494710291296761

Epoch: 5| Step: 6
Training loss: 2.8530565502232816
Validation loss: 2.5067668088270016

Epoch: 5| Step: 7
Training loss: 2.018016963180459
Validation loss: 2.5395714892540115

Epoch: 5| Step: 8
Training loss: 2.169046439982618
Validation loss: 2.551298562177268

Epoch: 5| Step: 9
Training loss: 1.5627926361707216
Validation loss: 2.4658188403261336

Epoch: 5| Step: 10
Training loss: 1.7713744140951366
Validation loss: 2.549973829779749

Epoch: 552| Step: 0
Training loss: 2.0592035479801796
Validation loss: 2.564151280893224

Epoch: 5| Step: 1
Training loss: 1.9529117315203006
Validation loss: 2.4993657138103207

Epoch: 5| Step: 2
Training loss: 1.8223625721548578
Validation loss: 2.580171381364906

Epoch: 5| Step: 3
Training loss: 2.2755094439872785
Validation loss: 2.551053933294791

Epoch: 5| Step: 4
Training loss: 2.405818157335369
Validation loss: 2.554006216192035

Epoch: 5| Step: 5
Training loss: 1.8467197101195787
Validation loss: 2.5426315125083576

Epoch: 5| Step: 6
Training loss: 1.6981614605327782
Validation loss: 2.522230742040964

Epoch: 5| Step: 7
Training loss: 2.3373325226704913
Validation loss: 2.549184382674575

Epoch: 5| Step: 8
Training loss: 2.1221480585735115
Validation loss: 2.575817198148574

Epoch: 5| Step: 9
Training loss: 1.6329347117560047
Validation loss: 2.527197503217479

Epoch: 5| Step: 10
Training loss: 1.6070560674090952
Validation loss: 2.5129490074380754

Epoch: 553| Step: 0
Training loss: 1.5052146075512842
Validation loss: 2.5357745846930575

Epoch: 5| Step: 1
Training loss: 2.2827312938077062
Validation loss: 2.475658443889323

Epoch: 5| Step: 2
Training loss: 1.8739566443200493
Validation loss: 2.5931273225813993

Epoch: 5| Step: 3
Training loss: 2.6178125346815495
Validation loss: 2.5515074191647544

Epoch: 5| Step: 4
Training loss: 1.5162341280088378
Validation loss: 2.52445566878514

Epoch: 5| Step: 5
Training loss: 2.004913612274076
Validation loss: 2.551947773959286

Epoch: 5| Step: 6
Training loss: 2.2130206643099477
Validation loss: 2.569884636807766

Epoch: 5| Step: 7
Training loss: 1.759716850392326
Validation loss: 2.568339590340093

Epoch: 5| Step: 8
Training loss: 2.290658440027056
Validation loss: 2.53083515705081

Epoch: 5| Step: 9
Training loss: 1.5835838705243057
Validation loss: 2.5212859728162864

Epoch: 5| Step: 10
Training loss: 1.7628559240150168
Validation loss: 2.6034211566250907

Epoch: 554| Step: 0
Training loss: 1.743648104954943
Validation loss: 2.5359196157877886

Epoch: 5| Step: 1
Training loss: 1.9521534448800837
Validation loss: 2.552590386398933

Epoch: 5| Step: 2
Training loss: 1.986341928379706
Validation loss: 2.504790286156086

Epoch: 5| Step: 3
Training loss: 2.5759601173393674
Validation loss: 2.5297250746068203

Epoch: 5| Step: 4
Training loss: 1.7867030948274987
Validation loss: 2.5568120523501308

Epoch: 5| Step: 5
Training loss: 1.7080682533349003
Validation loss: 2.6019999596882344

Epoch: 5| Step: 6
Training loss: 2.311791079344618
Validation loss: 2.5516936844557296

Epoch: 5| Step: 7
Training loss: 1.8766073966392693
Validation loss: 2.478767603496041

Epoch: 5| Step: 8
Training loss: 1.954654857384283
Validation loss: 2.4902779565255297

Epoch: 5| Step: 9
Training loss: 2.102427364913601
Validation loss: 2.5179117334420247

Epoch: 5| Step: 10
Training loss: 1.9763962747390125
Validation loss: 2.5122838804011653

Epoch: 555| Step: 0
Training loss: 2.731829695647763
Validation loss: 2.4561120522310893

Epoch: 5| Step: 1
Training loss: 1.7905874624528564
Validation loss: 2.565272442411986

Epoch: 5| Step: 2
Training loss: 1.6075074554317932
Validation loss: 2.5517932776404386

Epoch: 5| Step: 3
Training loss: 2.3119629932332564
Validation loss: 2.509061954769972

Epoch: 5| Step: 4
Training loss: 2.1292033416913885
Validation loss: 2.576956613044885

Epoch: 5| Step: 5
Training loss: 2.254905756738237
Validation loss: 2.5545485529827046

Epoch: 5| Step: 6
Training loss: 1.8898251315363161
Validation loss: 2.521183766193161

Epoch: 5| Step: 7
Training loss: 1.8988275951329041
Validation loss: 2.5567729428787596

Epoch: 5| Step: 8
Training loss: 2.1188820676799924
Validation loss: 2.581872727778982

Epoch: 5| Step: 9
Training loss: 1.5360590874015927
Validation loss: 2.5323810772199815

Epoch: 5| Step: 10
Training loss: 1.460572140952857
Validation loss: 2.5801131472062373

Epoch: 556| Step: 0
Training loss: 1.9415146856899528
Validation loss: 2.508476097201324

Epoch: 5| Step: 1
Training loss: 1.809129211387142
Validation loss: 2.608223269715291

Epoch: 5| Step: 2
Training loss: 1.7148130235982288
Validation loss: 2.493676555114444

Epoch: 5| Step: 3
Training loss: 2.2193553260010703
Validation loss: 2.552852769942835

Epoch: 5| Step: 4
Training loss: 2.003435284035123
Validation loss: 2.5404952951052486

Epoch: 5| Step: 5
Training loss: 2.6422924668336103
Validation loss: 2.537752300049052

Epoch: 5| Step: 6
Training loss: 1.6156703448250118
Validation loss: 2.579533898691235

Epoch: 5| Step: 7
Training loss: 1.638805506716958
Validation loss: 2.5417763901347823

Epoch: 5| Step: 8
Training loss: 1.8219098462392387
Validation loss: 2.517752832117423

Epoch: 5| Step: 9
Training loss: 1.8774854081929093
Validation loss: 2.560482448441512

Epoch: 5| Step: 10
Training loss: 2.660851655158874
Validation loss: 2.5490188539215555

Epoch: 557| Step: 0
Training loss: 2.5269197700906725
Validation loss: 2.4925670691550734

Epoch: 5| Step: 1
Training loss: 1.9967082471875046
Validation loss: 2.581990132631139

Epoch: 5| Step: 2
Training loss: 2.206768729201619
Validation loss: 2.5346615092405167

Epoch: 5| Step: 3
Training loss: 1.3237787826766159
Validation loss: 2.5446960421044142

Epoch: 5| Step: 4
Training loss: 1.87485840580678
Validation loss: 2.5326954107515784

Epoch: 5| Step: 5
Training loss: 1.8609974298187826
Validation loss: 2.5144012752153357

Epoch: 5| Step: 6
Training loss: 1.9538717444544476
Validation loss: 2.5542109142958656

Epoch: 5| Step: 7
Training loss: 1.743621236224019
Validation loss: 2.5552758271381757

Epoch: 5| Step: 8
Training loss: 2.220993734248708
Validation loss: 2.5634413040009956

Epoch: 5| Step: 9
Training loss: 2.2184008471358365
Validation loss: 2.48328010494879

Epoch: 5| Step: 10
Training loss: 2.264740027861659
Validation loss: 2.552611220115382

Epoch: 558| Step: 0
Training loss: 2.0045445784466804
Validation loss: 2.5334920404460637

Epoch: 5| Step: 1
Training loss: 1.7243208336004994
Validation loss: 2.515264186767789

Epoch: 5| Step: 2
Training loss: 1.8650402667119306
Validation loss: 2.540153565084866

Epoch: 5| Step: 3
Training loss: 1.9542060606780807
Validation loss: 2.630618478008667

Epoch: 5| Step: 4
Training loss: 1.8529311646441224
Validation loss: 2.5836255066773806

Epoch: 5| Step: 5
Training loss: 1.5750109475375977
Validation loss: 2.5846995757700317

Epoch: 5| Step: 6
Training loss: 2.3568802332206737
Validation loss: 2.5327040889902794

Epoch: 5| Step: 7
Training loss: 2.127660320261561
Validation loss: 2.4950510067018596

Epoch: 5| Step: 8
Training loss: 2.4178669897306793
Validation loss: 2.5672216227232205

Epoch: 5| Step: 9
Training loss: 2.3922871315388883
Validation loss: 2.5232528476225378

Epoch: 5| Step: 10
Training loss: 1.8749031041857736
Validation loss: 2.5656807569954325

Epoch: 559| Step: 0
Training loss: 2.5458967518334465
Validation loss: 2.518413771379269

Epoch: 5| Step: 1
Training loss: 1.701017843602515
Validation loss: 2.536674018505217

Epoch: 5| Step: 2
Training loss: 2.0416941997721647
Validation loss: 2.5153855867368287

Epoch: 5| Step: 3
Training loss: 1.897542923252095
Validation loss: 2.4838449701257264

Epoch: 5| Step: 4
Training loss: 2.099140913400123
Validation loss: 2.495683574879377

Epoch: 5| Step: 5
Training loss: 2.437492957471797
Validation loss: 2.5549155191828365

Epoch: 5| Step: 6
Training loss: 1.8451209063314316
Validation loss: 2.516509210308307

Epoch: 5| Step: 7
Training loss: 1.8308582576929797
Validation loss: 2.5649175957206984

Epoch: 5| Step: 8
Training loss: 1.5954680812491713
Validation loss: 2.5730337178012412

Epoch: 5| Step: 9
Training loss: 1.8404061982393511
Validation loss: 2.566275957246782

Epoch: 5| Step: 10
Training loss: 2.0689515444952398
Validation loss: 2.506604142446979

Epoch: 560| Step: 0
Training loss: 2.189090259710899
Validation loss: 2.4999839679655165

Epoch: 5| Step: 1
Training loss: 1.9260531034348396
Validation loss: 2.5807561201934304

Epoch: 5| Step: 2
Training loss: 2.2712069446133722
Validation loss: 2.5624228144960663

Epoch: 5| Step: 3
Training loss: 1.91035245110078
Validation loss: 2.503181306885408

Epoch: 5| Step: 4
Training loss: 2.204436432664081
Validation loss: 2.490412923261893

Epoch: 5| Step: 5
Training loss: 1.3848353961536377
Validation loss: 2.5419894160956105

Epoch: 5| Step: 6
Training loss: 2.3185083844344034
Validation loss: 2.547829387833699

Epoch: 5| Step: 7
Training loss: 1.2230423387792404
Validation loss: 2.5760185677915164

Epoch: 5| Step: 8
Training loss: 1.8964063037081207
Validation loss: 2.486536907827227

Epoch: 5| Step: 9
Training loss: 2.101543780956073
Validation loss: 2.525569940652788

Epoch: 5| Step: 10
Training loss: 1.6924259204514154
Validation loss: 2.5641864486470305

Epoch: 561| Step: 0
Training loss: 2.4382607666641527
Validation loss: 2.549750556785488

Epoch: 5| Step: 1
Training loss: 1.7018794833771107
Validation loss: 2.5347897557175383

Epoch: 5| Step: 2
Training loss: 2.533934406030701
Validation loss: 2.521497539441004

Epoch: 5| Step: 3
Training loss: 1.4099731749154016
Validation loss: 2.550898473319636

Epoch: 5| Step: 4
Training loss: 1.9574945019563168
Validation loss: 2.544546279022328

Epoch: 5| Step: 5
Training loss: 1.780560945782741
Validation loss: 2.5142392501097213

Epoch: 5| Step: 6
Training loss: 2.1135595564996152
Validation loss: 2.5693946464019475

Epoch: 5| Step: 7
Training loss: 1.9791531077138003
Validation loss: 2.5476982295602615

Epoch: 5| Step: 8
Training loss: 1.9995461187326289
Validation loss: 2.4770621755810627

Epoch: 5| Step: 9
Training loss: 2.3377697753265654
Validation loss: 2.527885925978157

Epoch: 5| Step: 10
Training loss: 1.6397382973999115
Validation loss: 2.5331242796752993

Epoch: 562| Step: 0
Training loss: 2.1672743776450702
Validation loss: 2.586754548647536

Epoch: 5| Step: 1
Training loss: 1.8053859663653167
Validation loss: 2.589903512467891

Epoch: 5| Step: 2
Training loss: 1.8050872888355154
Validation loss: 2.5134270177129556

Epoch: 5| Step: 3
Training loss: 1.7330640357458953
Validation loss: 2.550018297451902

Epoch: 5| Step: 4
Training loss: 2.445460793383095
Validation loss: 2.5287089555348863

Epoch: 5| Step: 5
Training loss: 1.5328938749374266
Validation loss: 2.478849085790364

Epoch: 5| Step: 6
Training loss: 1.9884511579002226
Validation loss: 2.5547484912774916

Epoch: 5| Step: 7
Training loss: 1.575802368567234
Validation loss: 2.5775660520776262

Epoch: 5| Step: 8
Training loss: 2.639303113539705
Validation loss: 2.530604678383588

Epoch: 5| Step: 9
Training loss: 2.3774243078206516
Validation loss: 2.527485525383256

Epoch: 5| Step: 10
Training loss: 1.7072704156371905
Validation loss: 2.597584217746546

Epoch: 563| Step: 0
Training loss: 1.8550184486479424
Validation loss: 2.5864903104150416

Epoch: 5| Step: 1
Training loss: 2.082017737482535
Validation loss: 2.5264562021622927

Epoch: 5| Step: 2
Training loss: 2.013321499168698
Validation loss: 2.4587318141947927

Epoch: 5| Step: 3
Training loss: 1.8349383293411665
Validation loss: 2.585414148349806

Epoch: 5| Step: 4
Training loss: 2.2843342663933615
Validation loss: 2.4673069721153778

Epoch: 5| Step: 5
Training loss: 2.216950559960424
Validation loss: 2.529889660707524

Epoch: 5| Step: 6
Training loss: 1.4371310050728072
Validation loss: 2.460495701862368

Epoch: 5| Step: 7
Training loss: 2.0902441479021907
Validation loss: 2.5162102781411737

Epoch: 5| Step: 8
Training loss: 2.045866856297122
Validation loss: 2.5269042324873396

Epoch: 5| Step: 9
Training loss: 1.9307826714364975
Validation loss: 2.570764204646064

Epoch: 5| Step: 10
Training loss: 1.3634053258533603
Validation loss: 2.511714629544342

Epoch: 564| Step: 0
Training loss: 1.6607143047584731
Validation loss: 2.544274711969091

Epoch: 5| Step: 1
Training loss: 1.707369982459509
Validation loss: 2.4993678780711845

Epoch: 5| Step: 2
Training loss: 2.422333507820075
Validation loss: 2.524613465839499

Epoch: 5| Step: 3
Training loss: 1.733503380406035
Validation loss: 2.56780340205952

Epoch: 5| Step: 4
Training loss: 2.266377817243176
Validation loss: 2.4830546188891285

Epoch: 5| Step: 5
Training loss: 2.4061420961436832
Validation loss: 2.45980288928406

Epoch: 5| Step: 6
Training loss: 1.9114040051742316
Validation loss: 2.5720587127755814

Epoch: 5| Step: 7
Training loss: 2.02606195931622
Validation loss: 2.555714781807553

Epoch: 5| Step: 8
Training loss: 1.6877770373089085
Validation loss: 2.5020101402944612

Epoch: 5| Step: 9
Training loss: 2.13335615781654
Validation loss: 2.529749363824801

Epoch: 5| Step: 10
Training loss: 1.7935917588458925
Validation loss: 2.5217110931057456

Epoch: 565| Step: 0
Training loss: 1.8572936389832035
Validation loss: 2.5249387044258085

Epoch: 5| Step: 1
Training loss: 1.95282810243407
Validation loss: 2.596187187314721

Epoch: 5| Step: 2
Training loss: 1.9553208481517603
Validation loss: 2.557199396829213

Epoch: 5| Step: 3
Training loss: 2.0861525978312296
Validation loss: 2.5558829933384923

Epoch: 5| Step: 4
Training loss: 1.982298538054442
Validation loss: 2.56447539584501

Epoch: 5| Step: 5
Training loss: 1.4161006507339204
Validation loss: 2.5398330475930213

Epoch: 5| Step: 6
Training loss: 2.59919846724315
Validation loss: 2.5486671850501095

Epoch: 5| Step: 7
Training loss: 1.708242165838807
Validation loss: 2.5521392782649417

Epoch: 5| Step: 8
Training loss: 1.5531345451568248
Validation loss: 2.534722375544316

Epoch: 5| Step: 9
Training loss: 2.624274744025272
Validation loss: 2.556564636387211

Epoch: 5| Step: 10
Training loss: 1.549289091189838
Validation loss: 2.573535074824266

Epoch: 566| Step: 0
Training loss: 1.2741846806259276
Validation loss: 2.556408703248093

Epoch: 5| Step: 1
Training loss: 1.857865626519583
Validation loss: 2.5214113735314756

Epoch: 5| Step: 2
Training loss: 1.7191174201118666
Validation loss: 2.6073801020481144

Epoch: 5| Step: 3
Training loss: 2.0914834123355384
Validation loss: 2.5113556993618693

Epoch: 5| Step: 4
Training loss: 2.120289911924289
Validation loss: 2.542160148329007

Epoch: 5| Step: 5
Training loss: 2.1724577197492017
Validation loss: 2.6023694051179973

Epoch: 5| Step: 6
Training loss: 1.3876942816454652
Validation loss: 2.4975956281037037

Epoch: 5| Step: 7
Training loss: 2.657825227288705
Validation loss: 2.5539698352105042

Epoch: 5| Step: 8
Training loss: 2.014293733733503
Validation loss: 2.48805950820918

Epoch: 5| Step: 9
Training loss: 2.0107364960155003
Validation loss: 2.568076506054191

Epoch: 5| Step: 10
Training loss: 2.008593811723611
Validation loss: 2.5819888478269233

Epoch: 567| Step: 0
Training loss: 2.2831928915376953
Validation loss: 2.535877034243713

Epoch: 5| Step: 1
Training loss: 2.1540217288735675
Validation loss: 2.5745083387406553

Epoch: 5| Step: 2
Training loss: 1.8281410412206873
Validation loss: 2.4975406917336644

Epoch: 5| Step: 3
Training loss: 1.2807855927441538
Validation loss: 2.5473939165802246

Epoch: 5| Step: 4
Training loss: 1.9128038900449884
Validation loss: 2.539557419115678

Epoch: 5| Step: 5
Training loss: 1.8340593836581256
Validation loss: 2.574701661922005

Epoch: 5| Step: 6
Training loss: 1.7585303981085392
Validation loss: 2.6259297268981934

Epoch: 5| Step: 7
Training loss: 2.1707593947965895
Validation loss: 2.5228954527852765

Epoch: 5| Step: 8
Training loss: 2.125551600951359
Validation loss: 2.553349251073272

Epoch: 5| Step: 9
Training loss: 2.6048286715525246
Validation loss: 2.5159394858649624

Epoch: 5| Step: 10
Training loss: 1.871453427843362
Validation loss: 2.521986443808174

Epoch: 568| Step: 0
Training loss: 2.4529257529429387
Validation loss: 2.509956062988683

Epoch: 5| Step: 1
Training loss: 1.625618743473789
Validation loss: 2.595132960430379

Epoch: 5| Step: 2
Training loss: 1.850095916529764
Validation loss: 2.5286546875147784

Epoch: 5| Step: 3
Training loss: 1.6755943638733877
Validation loss: 2.529738495117698

Epoch: 5| Step: 4
Training loss: 2.4770433217873835
Validation loss: 2.578685815098362

Epoch: 5| Step: 5
Training loss: 1.936276080040237
Validation loss: 2.520207554119785

Epoch: 5| Step: 6
Training loss: 1.3579565079400242
Validation loss: 2.6037245528133175

Epoch: 5| Step: 7
Training loss: 1.7775940435884874
Validation loss: 2.55606722019427

Epoch: 5| Step: 8
Training loss: 1.7181042238313553
Validation loss: 2.5420079475358563

Epoch: 5| Step: 9
Training loss: 2.727637923238586
Validation loss: 2.482407249610981

Epoch: 5| Step: 10
Training loss: 1.631707871877604
Validation loss: 2.538141013917154

Epoch: 569| Step: 0
Training loss: 1.700611604738036
Validation loss: 2.519165550783852

Epoch: 5| Step: 1
Training loss: 1.1263114384903956
Validation loss: 2.585599406223915

Epoch: 5| Step: 2
Training loss: 1.7361854520351916
Validation loss: 2.5405022852044965

Epoch: 5| Step: 3
Training loss: 1.8169051602920752
Validation loss: 2.5711719252938505

Epoch: 5| Step: 4
Training loss: 1.7758322524245416
Validation loss: 2.589759349275205

Epoch: 5| Step: 5
Training loss: 2.1169251001340688
Validation loss: 2.5012302458295363

Epoch: 5| Step: 6
Training loss: 2.3530844392358357
Validation loss: 2.537026479772441

Epoch: 5| Step: 7
Training loss: 1.6673856694318898
Validation loss: 2.5997723847361236

Epoch: 5| Step: 8
Training loss: 2.2609551018462746
Validation loss: 2.5473230811921046

Epoch: 5| Step: 9
Training loss: 1.9975267257143863
Validation loss: 2.557332751418986

Epoch: 5| Step: 10
Training loss: 2.7091585418225756
Validation loss: 2.5437289612392795

Epoch: 570| Step: 0
Training loss: 1.2410781032935565
Validation loss: 2.548095024384287

Epoch: 5| Step: 1
Training loss: 1.7636711990845189
Validation loss: 2.5025266687177865

Epoch: 5| Step: 2
Training loss: 1.9998629642269605
Validation loss: 2.576653603022374

Epoch: 5| Step: 3
Training loss: 2.8876867258707306
Validation loss: 2.5484175433133602

Epoch: 5| Step: 4
Training loss: 2.1861550692520435
Validation loss: 2.507232533528226

Epoch: 5| Step: 5
Training loss: 1.3130657702328137
Validation loss: 2.5481468360404302

Epoch: 5| Step: 6
Training loss: 2.1591055938002297
Validation loss: 2.554730513858683

Epoch: 5| Step: 7
Training loss: 1.7355794075461
Validation loss: 2.4443484812190763

Epoch: 5| Step: 8
Training loss: 1.6322329281980317
Validation loss: 2.5154735693107453

Epoch: 5| Step: 9
Training loss: 2.338554829742383
Validation loss: 2.5483995157006456

Epoch: 5| Step: 10
Training loss: 1.64382796302085
Validation loss: 2.5200392908899727

Epoch: 571| Step: 0
Training loss: 1.9406356663802393
Validation loss: 2.5010724525856216

Epoch: 5| Step: 1
Training loss: 2.1187758452602994
Validation loss: 2.5026909937533772

Epoch: 5| Step: 2
Training loss: 1.8381308582034857
Validation loss: 2.505714198799024

Epoch: 5| Step: 3
Training loss: 1.603184469506807
Validation loss: 2.5900216227816744

Epoch: 5| Step: 4
Training loss: 2.3956801876933707
Validation loss: 2.6079312150160185

Epoch: 5| Step: 5
Training loss: 1.9117763646232029
Validation loss: 2.5423337409670026

Epoch: 5| Step: 6
Training loss: 2.195182823613868
Validation loss: 2.527696240445138

Epoch: 5| Step: 7
Training loss: 1.8158179201986566
Validation loss: 2.4937500405453576

Epoch: 5| Step: 8
Training loss: 1.7699597242051095
Validation loss: 2.6178577811852968

Epoch: 5| Step: 9
Training loss: 1.8545287632361067
Validation loss: 2.5309554637253013

Epoch: 5| Step: 10
Training loss: 2.0746429641754
Validation loss: 2.538713992096497

Epoch: 572| Step: 0
Training loss: 1.7784378875962583
Validation loss: 2.5103510743939452

Epoch: 5| Step: 1
Training loss: 2.0631479343733177
Validation loss: 2.56811400389739

Epoch: 5| Step: 2
Training loss: 2.125149889876796
Validation loss: 2.482110542771891

Epoch: 5| Step: 3
Training loss: 1.6324180601157117
Validation loss: 2.5026262568389597

Epoch: 5| Step: 4
Training loss: 1.8405767385894554
Validation loss: 2.5087344126306506

Epoch: 5| Step: 5
Training loss: 2.0142807137215644
Validation loss: 2.5768360603811162

Epoch: 5| Step: 6
Training loss: 2.043133993376983
Validation loss: 2.5047241572634236

Epoch: 5| Step: 7
Training loss: 1.2749428773687406
Validation loss: 2.495932474638809

Epoch: 5| Step: 8
Training loss: 1.899491947411049
Validation loss: 2.5409617227272348

Epoch: 5| Step: 9
Training loss: 2.727046278742366
Validation loss: 2.5603547404352245

Epoch: 5| Step: 10
Training loss: 1.8694441816919578
Validation loss: 2.5568130239378943

Epoch: 573| Step: 0
Training loss: 1.4541928049414499
Validation loss: 2.5898636386399496

Epoch: 5| Step: 1
Training loss: 1.806626768316793
Validation loss: 2.530250059110763

Epoch: 5| Step: 2
Training loss: 1.9078304430518518
Validation loss: 2.5440752509670954

Epoch: 5| Step: 3
Training loss: 1.9339748430874348
Validation loss: 2.512689950438126

Epoch: 5| Step: 4
Training loss: 1.9044789701599154
Validation loss: 2.5822043702536837

Epoch: 5| Step: 5
Training loss: 1.864632170763962
Validation loss: 2.5245698332342634

Epoch: 5| Step: 6
Training loss: 2.159553981932127
Validation loss: 2.614034811784255

Epoch: 5| Step: 7
Training loss: 1.6405537181082799
Validation loss: 2.6137829150117704

Epoch: 5| Step: 8
Training loss: 1.8275564238765358
Validation loss: 2.5081025591794344

Epoch: 5| Step: 9
Training loss: 1.8383151627187568
Validation loss: 2.5508712197151273

Epoch: 5| Step: 10
Training loss: 2.6073677428837803
Validation loss: 2.531996168975091

Epoch: 574| Step: 0
Training loss: 2.4601966348230437
Validation loss: 2.5597528558272575

Epoch: 5| Step: 1
Training loss: 1.9185545855986879
Validation loss: 2.5555929091242544

Epoch: 5| Step: 2
Training loss: 2.2460645590834107
Validation loss: 2.5526458609146196

Epoch: 5| Step: 3
Training loss: 1.8567485050037715
Validation loss: 2.5437861427274537

Epoch: 5| Step: 4
Training loss: 1.8000458314147119
Validation loss: 2.5147769186058024

Epoch: 5| Step: 5
Training loss: 1.6112332032884094
Validation loss: 2.520682701004362

Epoch: 5| Step: 6
Training loss: 2.1018789967735145
Validation loss: 2.557819164101389

Epoch: 5| Step: 7
Training loss: 1.6118418481500831
Validation loss: 2.4689347434400704

Epoch: 5| Step: 8
Training loss: 1.8541329484366853
Validation loss: 2.5111789811383582

Epoch: 5| Step: 9
Training loss: 1.576177925561497
Validation loss: 2.548894943199443

Epoch: 5| Step: 10
Training loss: 2.3996622642663583
Validation loss: 2.507077423940435

Epoch: 575| Step: 0
Training loss: 2.141316323130033
Validation loss: 2.584873407938003

Epoch: 5| Step: 1
Training loss: 1.7136060553823953
Validation loss: 2.513941428790233

Epoch: 5| Step: 2
Training loss: 1.9490060327083256
Validation loss: 2.520775029453892

Epoch: 5| Step: 3
Training loss: 2.2370312247623017
Validation loss: 2.5586219273161412

Epoch: 5| Step: 4
Training loss: 1.5893886955292196
Validation loss: 2.554450526452474

Epoch: 5| Step: 5
Training loss: 1.7266443845914146
Validation loss: 2.618234962618148

Epoch: 5| Step: 6
Training loss: 2.0772745787318434
Validation loss: 2.596444185724517

Epoch: 5| Step: 7
Training loss: 1.9147423607245129
Validation loss: 2.607151240545305

Epoch: 5| Step: 8
Training loss: 1.8781187187508708
Validation loss: 2.5710772097929677

Epoch: 5| Step: 9
Training loss: 1.7685820536863246
Validation loss: 2.5765023164846808

Epoch: 5| Step: 10
Training loss: 2.364322653586014
Validation loss: 2.5289208256823152

Epoch: 576| Step: 0
Training loss: 2.465686490799397
Validation loss: 2.5373100368071584

Epoch: 5| Step: 1
Training loss: 1.409829437342172
Validation loss: 2.5599451121764227

Epoch: 5| Step: 2
Training loss: 1.7161927359099738
Validation loss: 2.6050814046275352

Epoch: 5| Step: 3
Training loss: 1.290756545856139
Validation loss: 2.5772236391600747

Epoch: 5| Step: 4
Training loss: 2.25074829797745
Validation loss: 2.537511980978263

Epoch: 5| Step: 5
Training loss: 2.1557539217193367
Validation loss: 2.517474115079791

Epoch: 5| Step: 6
Training loss: 2.0077435077139048
Validation loss: 2.532493037959995

Epoch: 5| Step: 7
Training loss: 2.0692827074766544
Validation loss: 2.5714403018278555

Epoch: 5| Step: 8
Training loss: 2.0151062527038817
Validation loss: 2.4781093071229887

Epoch: 5| Step: 9
Training loss: 1.9181153033605889
Validation loss: 2.543599599226892

Epoch: 5| Step: 10
Training loss: 1.8748655270992638
Validation loss: 2.505454432111035

Epoch: 577| Step: 0
Training loss: 1.9374348414139588
Validation loss: 2.5305826392854374

Epoch: 5| Step: 1
Training loss: 1.6026303336811445
Validation loss: 2.555171543754763

Epoch: 5| Step: 2
Training loss: 2.0500022934691464
Validation loss: 2.5415367340035306

Epoch: 5| Step: 3
Training loss: 1.9339888968479377
Validation loss: 2.5086201222943076

Epoch: 5| Step: 4
Training loss: 2.4794121842400285
Validation loss: 2.5565105324821134

Epoch: 5| Step: 5
Training loss: 1.8765764602789818
Validation loss: 2.630635641535783

Epoch: 5| Step: 6
Training loss: 2.32556287863479
Validation loss: 2.600513645302656

Epoch: 5| Step: 7
Training loss: 1.6417624027718358
Validation loss: 2.540034017045206

Epoch: 5| Step: 8
Training loss: 1.606403904529021
Validation loss: 2.555243362003322

Epoch: 5| Step: 9
Training loss: 1.4513044540611337
Validation loss: 2.5225791745116917

Epoch: 5| Step: 10
Training loss: 2.0065212030799535
Validation loss: 2.501012854338761

Epoch: 578| Step: 0
Training loss: 1.7623444860581807
Validation loss: 2.5340930473815884

Epoch: 5| Step: 1
Training loss: 1.4951884665712303
Validation loss: 2.5653160742681687

Epoch: 5| Step: 2
Training loss: 2.2180831336839812
Validation loss: 2.5871517655470644

Epoch: 5| Step: 3
Training loss: 1.6067188157657801
Validation loss: 2.538350276840243

Epoch: 5| Step: 4
Training loss: 1.6889358345974697
Validation loss: 2.507941030779404

Epoch: 5| Step: 5
Training loss: 1.3694169966831682
Validation loss: 2.5559211445010104

Epoch: 5| Step: 6
Training loss: 2.024466234667508
Validation loss: 2.575643245472554

Epoch: 5| Step: 7
Training loss: 2.30508036740221
Validation loss: 2.543190178926771

Epoch: 5| Step: 8
Training loss: 1.5802998428486585
Validation loss: 2.5476730991597076

Epoch: 5| Step: 9
Training loss: 2.229374765920667
Validation loss: 2.5147807649146534

Epoch: 5| Step: 10
Training loss: 2.5117309000483736
Validation loss: 2.524500517399004

Epoch: 579| Step: 0
Training loss: 2.076716469136404
Validation loss: 2.564624415490832

Epoch: 5| Step: 1
Training loss: 2.4203732664534208
Validation loss: 2.5231955950214453

Epoch: 5| Step: 2
Training loss: 1.9498002708069404
Validation loss: 2.534816080841918

Epoch: 5| Step: 3
Training loss: 2.0546554736988356
Validation loss: 2.520039836163706

Epoch: 5| Step: 4
Training loss: 1.6682492451368098
Validation loss: 2.5350711551058427

Epoch: 5| Step: 5
Training loss: 1.7885650876140449
Validation loss: 2.5937798008230386

Epoch: 5| Step: 6
Training loss: 1.1976504928540075
Validation loss: 2.624833802461808

Epoch: 5| Step: 7
Training loss: 2.0437206394524727
Validation loss: 2.5725564660107354

Epoch: 5| Step: 8
Training loss: 2.4124791159244734
Validation loss: 2.5057830874385068

Epoch: 5| Step: 9
Training loss: 1.1488552242067465
Validation loss: 2.5552133505242534

Epoch: 5| Step: 10
Training loss: 1.9640969284791063
Validation loss: 2.5147802093257448

Epoch: 580| Step: 0
Training loss: 1.7513688047573246
Validation loss: 2.5274220686656745

Epoch: 5| Step: 1
Training loss: 1.684165910471816
Validation loss: 2.5525295916299107

Epoch: 5| Step: 2
Training loss: 1.9857652254814016
Validation loss: 2.4826720733302614

Epoch: 5| Step: 3
Training loss: 1.9581340796646414
Validation loss: 2.539239925372875

Epoch: 5| Step: 4
Training loss: 1.4233291232979635
Validation loss: 2.455400682033218

Epoch: 5| Step: 5
Training loss: 1.695871779484818
Validation loss: 2.5404847402913977

Epoch: 5| Step: 6
Training loss: 2.415623231322121
Validation loss: 2.524800337844471

Epoch: 5| Step: 7
Training loss: 2.124713092957841
Validation loss: 2.5649939685414718

Epoch: 5| Step: 8
Training loss: 1.6876764558441277
Validation loss: 2.5056821565929286

Epoch: 5| Step: 9
Training loss: 1.4317745130521027
Validation loss: 2.499832980411682

Epoch: 5| Step: 10
Training loss: 2.5911561796406715
Validation loss: 2.5621452516180394

Epoch: 581| Step: 0
Training loss: 1.6531898009898693
Validation loss: 2.514408195115203

Epoch: 5| Step: 1
Training loss: 1.859958460969487
Validation loss: 2.525888064634149

Epoch: 5| Step: 2
Training loss: 2.0258710800832507
Validation loss: 2.5445372447176355

Epoch: 5| Step: 3
Training loss: 2.241789991916925
Validation loss: 2.6049299149537593

Epoch: 5| Step: 4
Training loss: 1.6383384392633877
Validation loss: 2.5204307019685777

Epoch: 5| Step: 5
Training loss: 1.9439937917037229
Validation loss: 2.5683102798963127

Epoch: 5| Step: 6
Training loss: 2.3473941193286527
Validation loss: 2.5234222650393474

Epoch: 5| Step: 7
Training loss: 1.645913600976267
Validation loss: 2.531086619796469

Epoch: 5| Step: 8
Training loss: 2.0965268524000527
Validation loss: 2.5663610563558277

Epoch: 5| Step: 9
Training loss: 1.8507571501026292
Validation loss: 2.5247937053506555

Epoch: 5| Step: 10
Training loss: 1.6312523648182766
Validation loss: 2.5186524224714497

Epoch: 582| Step: 0
Training loss: 2.0135752583514037
Validation loss: 2.5013003884526834

Epoch: 5| Step: 1
Training loss: 1.6210382291179444
Validation loss: 2.594189136829022

Epoch: 5| Step: 2
Training loss: 1.2071746444708893
Validation loss: 2.5156455717148187

Epoch: 5| Step: 3
Training loss: 1.9987283478614402
Validation loss: 2.5794381882604287

Epoch: 5| Step: 4
Training loss: 1.5045968191802592
Validation loss: 2.5127369097946115

Epoch: 5| Step: 5
Training loss: 2.171858972723575
Validation loss: 2.5900554098750095

Epoch: 5| Step: 6
Training loss: 1.9128598541595443
Validation loss: 2.522362248359145

Epoch: 5| Step: 7
Training loss: 2.1025846470180403
Validation loss: 2.557090738017338

Epoch: 5| Step: 8
Training loss: 2.4770361991827587
Validation loss: 2.5615476734008045

Epoch: 5| Step: 9
Training loss: 1.81317987516113
Validation loss: 2.5214131691082695

Epoch: 5| Step: 10
Training loss: 1.6631491576816018
Validation loss: 2.5645700872632697

Epoch: 583| Step: 0
Training loss: 1.5339778036428988
Validation loss: 2.630693392688282

Epoch: 5| Step: 1
Training loss: 1.684347528293771
Validation loss: 2.575747203646993

Epoch: 5| Step: 2
Training loss: 2.100209080414976
Validation loss: 2.5161238720714474

Epoch: 5| Step: 3
Training loss: 1.7766146663096043
Validation loss: 2.5263101049258787

Epoch: 5| Step: 4
Training loss: 1.7979941158771238
Validation loss: 2.5482830959291394

Epoch: 5| Step: 5
Training loss: 1.541096461584836
Validation loss: 2.5175766097745633

Epoch: 5| Step: 6
Training loss: 2.4300875319111954
Validation loss: 2.5026827251571158

Epoch: 5| Step: 7
Training loss: 2.105991956711758
Validation loss: 2.5343010229967486

Epoch: 5| Step: 8
Training loss: 1.8671451068997629
Validation loss: 2.5715062214253837

Epoch: 5| Step: 9
Training loss: 2.362202446985273
Validation loss: 2.6005485500281034

Epoch: 5| Step: 10
Training loss: 1.7373664420411326
Validation loss: 2.4839167936940316

Epoch: 584| Step: 0
Training loss: 1.61521791682686
Validation loss: 2.516556409612625

Epoch: 5| Step: 1
Training loss: 2.3350081109961844
Validation loss: 2.525048537159936

Epoch: 5| Step: 2
Training loss: 1.691735004429054
Validation loss: 2.5253161050651918

Epoch: 5| Step: 3
Training loss: 1.472600880196653
Validation loss: 2.5155196975785796

Epoch: 5| Step: 4
Training loss: 1.9243650355240582
Validation loss: 2.5565096349858023

Epoch: 5| Step: 5
Training loss: 2.094780170314914
Validation loss: 2.5641086260346886

Epoch: 5| Step: 6
Training loss: 1.5771956020424514
Validation loss: 2.5834595361289954

Epoch: 5| Step: 7
Training loss: 2.450971107315728
Validation loss: 2.5646384115817202

Epoch: 5| Step: 8
Training loss: 1.886074485323319
Validation loss: 2.479471543812447

Epoch: 5| Step: 9
Training loss: 1.8528610376005543
Validation loss: 2.543133872142721

Epoch: 5| Step: 10
Training loss: 1.683798368193967
Validation loss: 2.5666634496352523

Epoch: 585| Step: 0
Training loss: 1.73667617587795
Validation loss: 2.5325220745833237

Epoch: 5| Step: 1
Training loss: 2.259932212656929
Validation loss: 2.482992891803874

Epoch: 5| Step: 2
Training loss: 1.8960948037174852
Validation loss: 2.5180745841161256

Epoch: 5| Step: 3
Training loss: 1.5562489398508406
Validation loss: 2.553295866211211

Epoch: 5| Step: 4
Training loss: 2.1161706037774914
Validation loss: 2.541046515432588

Epoch: 5| Step: 5
Training loss: 1.6351875663051323
Validation loss: 2.5474213382143933

Epoch: 5| Step: 6
Training loss: 2.2736664227460035
Validation loss: 2.536316967869907

Epoch: 5| Step: 7
Training loss: 1.9446853791178877
Validation loss: 2.5824623601261645

Epoch: 5| Step: 8
Training loss: 1.5343261493434843
Validation loss: 2.480938398738787

Epoch: 5| Step: 9
Training loss: 2.0397515429867186
Validation loss: 2.471667710855013

Epoch: 5| Step: 10
Training loss: 1.9878346479333773
Validation loss: 2.6085853268451187

Epoch: 586| Step: 0
Training loss: 1.8323985303027261
Validation loss: 2.616428581234622

Epoch: 5| Step: 1
Training loss: 2.698935818231667
Validation loss: 2.561922308380214

Epoch: 5| Step: 2
Training loss: 1.6057103478781467
Validation loss: 2.5050051965828053

Epoch: 5| Step: 3
Training loss: 1.8306370617490966
Validation loss: 2.603358418379242

Epoch: 5| Step: 4
Training loss: 2.3830156083390226
Validation loss: 2.5311896913130467

Epoch: 5| Step: 5
Training loss: 1.6135004739775434
Validation loss: 2.5611607022708265

Epoch: 5| Step: 6
Training loss: 1.6805858959615345
Validation loss: 2.4941928698188347

Epoch: 5| Step: 7
Training loss: 1.6921980416347333
Validation loss: 2.5461581044273256

Epoch: 5| Step: 8
Training loss: 1.8243346739046782
Validation loss: 2.569972945202945

Epoch: 5| Step: 9
Training loss: 1.8165936773260487
Validation loss: 2.499496422573824

Epoch: 5| Step: 10
Training loss: 1.6183368081874976
Validation loss: 2.4604438480640387

Epoch: 587| Step: 0
Training loss: 1.923593140788629
Validation loss: 2.55987879672407

Epoch: 5| Step: 1
Training loss: 1.903961433797423
Validation loss: 2.4979506347741935

Epoch: 5| Step: 2
Training loss: 2.3029438211510254
Validation loss: 2.526113660873415

Epoch: 5| Step: 3
Training loss: 1.486648905923124
Validation loss: 2.5270776638540955

Epoch: 5| Step: 4
Training loss: 2.0323066897271236
Validation loss: 2.5574540590285033

Epoch: 5| Step: 5
Training loss: 1.805240893047391
Validation loss: 2.5650489549247464

Epoch: 5| Step: 6
Training loss: 1.7392425964820792
Validation loss: 2.6655237404532057

Epoch: 5| Step: 7
Training loss: 2.1728268739819323
Validation loss: 2.5612478440862696

Epoch: 5| Step: 8
Training loss: 1.7771011354628785
Validation loss: 2.5428613517458563

Epoch: 5| Step: 9
Training loss: 2.01258703955801
Validation loss: 2.5310381009782232

Epoch: 5| Step: 10
Training loss: 1.7740493592767905
Validation loss: 2.5238742418042723

Epoch: 588| Step: 0
Training loss: 1.704577255530359
Validation loss: 2.548037507966384

Epoch: 5| Step: 1
Training loss: 2.0864266382845478
Validation loss: 2.502687445389844

Epoch: 5| Step: 2
Training loss: 1.5071048953906456
Validation loss: 2.4947055066440953

Epoch: 5| Step: 3
Training loss: 2.0807910539178835
Validation loss: 2.574920481469419

Epoch: 5| Step: 4
Training loss: 1.36060575696789
Validation loss: 2.529347015212021

Epoch: 5| Step: 5
Training loss: 1.76962098153077
Validation loss: 2.4958895013126665

Epoch: 5| Step: 6
Training loss: 2.063907027760282
Validation loss: 2.5439481190600297

Epoch: 5| Step: 7
Training loss: 1.6142012441407958
Validation loss: 2.5680135422273724

Epoch: 5| Step: 8
Training loss: 1.7203426957836858
Validation loss: 2.522912648527874

Epoch: 5| Step: 9
Training loss: 2.5488900480385075
Validation loss: 2.542286980909011

Epoch: 5| Step: 10
Training loss: 1.8064852261080373
Validation loss: 2.507365412844539

Epoch: 589| Step: 0
Training loss: 2.076090684596934
Validation loss: 2.571073895405157

Epoch: 5| Step: 1
Training loss: 1.8539776080609514
Validation loss: 2.5670307222723068

Epoch: 5| Step: 2
Training loss: 1.7896387762941097
Validation loss: 2.49912094330369

Epoch: 5| Step: 3
Training loss: 1.6860439942164467
Validation loss: 2.521640228095907

Epoch: 5| Step: 4
Training loss: 1.5476395230109061
Validation loss: 2.5930843475152536

Epoch: 5| Step: 5
Training loss: 1.879172577887441
Validation loss: 2.5680531603430055

Epoch: 5| Step: 6
Training loss: 1.6027872752292616
Validation loss: 2.527097945026556

Epoch: 5| Step: 7
Training loss: 1.7020984320591488
Validation loss: 2.5198799275506554

Epoch: 5| Step: 8
Training loss: 2.3534632506815036
Validation loss: 2.5330554899118405

Epoch: 5| Step: 9
Training loss: 1.6203311459269483
Validation loss: 2.51606296035669

Epoch: 5| Step: 10
Training loss: 2.6530636693832417
Validation loss: 2.5117280605514036

Epoch: 590| Step: 0
Training loss: 1.744259957292634
Validation loss: 2.4941649297847817

Epoch: 5| Step: 1
Training loss: 1.9165184613300803
Validation loss: 2.5296349598542047

Epoch: 5| Step: 2
Training loss: 1.6110047911863397
Validation loss: 2.530727840535064

Epoch: 5| Step: 3
Training loss: 1.7222726961485169
Validation loss: 2.4793710566629743

Epoch: 5| Step: 4
Training loss: 1.614826930548596
Validation loss: 2.526727748435241

Epoch: 5| Step: 5
Training loss: 2.02311297432263
Validation loss: 2.503170617777764

Epoch: 5| Step: 6
Training loss: 1.9619995523893603
Validation loss: 2.5557215567442655

Epoch: 5| Step: 7
Training loss: 1.6334741155455224
Validation loss: 2.548214298875933

Epoch: 5| Step: 8
Training loss: 2.5382665707112952
Validation loss: 2.445294949892093

Epoch: 5| Step: 9
Training loss: 1.6238350727445634
Validation loss: 2.560113195961353

Epoch: 5| Step: 10
Training loss: 2.0860661956290807
Validation loss: 2.584200114920788

Epoch: 591| Step: 0
Training loss: 1.7957484155154284
Validation loss: 2.600912411804694

Epoch: 5| Step: 1
Training loss: 1.9302969522268445
Validation loss: 2.578847899751982

Epoch: 5| Step: 2
Training loss: 1.4443304901329832
Validation loss: 2.534674959242655

Epoch: 5| Step: 3
Training loss: 1.9351885143388623
Validation loss: 2.525801077167383

Epoch: 5| Step: 4
Training loss: 1.8663323012113684
Validation loss: 2.59041531330448

Epoch: 5| Step: 5
Training loss: 2.0334857081034614
Validation loss: 2.578290714371151

Epoch: 5| Step: 6
Training loss: 1.84849719533999
Validation loss: 2.556122437721253

Epoch: 5| Step: 7
Training loss: 2.7297214691546494
Validation loss: 2.606824201259438

Epoch: 5| Step: 8
Training loss: 1.8079763722310578
Validation loss: 2.507502403301884

Epoch: 5| Step: 9
Training loss: 1.4128105564859241
Validation loss: 2.561742217845736

Epoch: 5| Step: 10
Training loss: 1.6382558519598558
Validation loss: 2.555425025610845

Epoch: 592| Step: 0
Training loss: 1.4333485073942387
Validation loss: 2.581175823795058

Epoch: 5| Step: 1
Training loss: 2.447339762350956
Validation loss: 2.555757763330635

Epoch: 5| Step: 2
Training loss: 1.3861055979664714
Validation loss: 2.607925942107672

Epoch: 5| Step: 3
Training loss: 2.0605148240620457
Validation loss: 2.5467128897095392

Epoch: 5| Step: 4
Training loss: 1.6673185345281372
Validation loss: 2.5942152495353987

Epoch: 5| Step: 5
Training loss: 1.708505652816035
Validation loss: 2.5701186990409326

Epoch: 5| Step: 6
Training loss: 2.2230142797782797
Validation loss: 2.549701591016095

Epoch: 5| Step: 7
Training loss: 2.05976617134155
Validation loss: 2.551992286596665

Epoch: 5| Step: 8
Training loss: 1.98546023993163
Validation loss: 2.5506373350740494

Epoch: 5| Step: 9
Training loss: 1.928107043017292
Validation loss: 2.5420507231309464

Epoch: 5| Step: 10
Training loss: 1.81922349566986
Validation loss: 2.5305274165973324

Epoch: 593| Step: 0
Training loss: 2.0475547768295312
Validation loss: 2.5182681451555338

Epoch: 5| Step: 1
Training loss: 2.1936955589212266
Validation loss: 2.507604260737821

Epoch: 5| Step: 2
Training loss: 1.386847906411032
Validation loss: 2.5987571483738017

Epoch: 5| Step: 3
Training loss: 1.8510885799075263
Validation loss: 2.5147967148514203

Epoch: 5| Step: 4
Training loss: 2.288029773004928
Validation loss: 2.5141876971655304

Epoch: 5| Step: 5
Training loss: 1.9314574491320322
Validation loss: 2.6481090529175364

Epoch: 5| Step: 6
Training loss: 1.5231130401179338
Validation loss: 2.586957089527864

Epoch: 5| Step: 7
Training loss: 1.9187376885531708
Validation loss: 2.4879756423069934

Epoch: 5| Step: 8
Training loss: 1.6177376074106282
Validation loss: 2.520197202726052

Epoch: 5| Step: 9
Training loss: 1.4851613421405503
Validation loss: 2.5454567728244606

Epoch: 5| Step: 10
Training loss: 2.0040933919453243
Validation loss: 2.5649402463382676

Epoch: 594| Step: 0
Training loss: 1.7351309014005591
Validation loss: 2.5379408713577702

Epoch: 5| Step: 1
Training loss: 1.1138326249904988
Validation loss: 2.5373709375824878

Epoch: 5| Step: 2
Training loss: 1.823366607360082
Validation loss: 2.504294047588858

Epoch: 5| Step: 3
Training loss: 1.6440720449379744
Validation loss: 2.5363198020757327

Epoch: 5| Step: 4
Training loss: 2.060786489141198
Validation loss: 2.5532394810665378

Epoch: 5| Step: 5
Training loss: 2.511378809586088
Validation loss: 2.5536229943632063

Epoch: 5| Step: 6
Training loss: 1.4272342332940313
Validation loss: 2.564680158993595

Epoch: 5| Step: 7
Training loss: 1.9360694526241877
Validation loss: 2.5105094894209348

Epoch: 5| Step: 8
Training loss: 1.757102721284254
Validation loss: 2.5379738951996393

Epoch: 5| Step: 9
Training loss: 2.0359042325233148
Validation loss: 2.608227557151643

Epoch: 5| Step: 10
Training loss: 2.389974966995468
Validation loss: 2.5526760461935667

Epoch: 595| Step: 0
Training loss: 1.5625968903064729
Validation loss: 2.5021249948509094

Epoch: 5| Step: 1
Training loss: 1.3994676429303425
Validation loss: 2.5747411064321564

Epoch: 5| Step: 2
Training loss: 2.0930586855006497
Validation loss: 2.552090112218001

Epoch: 5| Step: 3
Training loss: 1.4783783903140324
Validation loss: 2.5514153763917617

Epoch: 5| Step: 4
Training loss: 1.51036409308478
Validation loss: 2.565143044510623

Epoch: 5| Step: 5
Training loss: 1.8281740361345482
Validation loss: 2.517729794655604

Epoch: 5| Step: 6
Training loss: 1.5698513283769222
Validation loss: 2.522131731331959

Epoch: 5| Step: 7
Training loss: 2.204905554723155
Validation loss: 2.5416822949081483

Epoch: 5| Step: 8
Training loss: 2.7360456322216415
Validation loss: 2.534620981802243

Epoch: 5| Step: 9
Training loss: 1.807846804914023
Validation loss: 2.602260503968305

Epoch: 5| Step: 10
Training loss: 2.1851213874531714
Validation loss: 2.5235012062529694

Epoch: 596| Step: 0
Training loss: 0.9838328912365533
Validation loss: 2.5355872611956616

Epoch: 5| Step: 1
Training loss: 1.6381650375020198
Validation loss: 2.554786344293535

Epoch: 5| Step: 2
Training loss: 2.3305996025913327
Validation loss: 2.531728195217963

Epoch: 5| Step: 3
Training loss: 1.8446923773260195
Validation loss: 2.5585878804382265

Epoch: 5| Step: 4
Training loss: 1.8788726232616566
Validation loss: 2.60072558125374

Epoch: 5| Step: 5
Training loss: 1.5094237736310867
Validation loss: 2.5035893617254623

Epoch: 5| Step: 6
Training loss: 2.285818880957756
Validation loss: 2.5309209514786293

Epoch: 5| Step: 7
Training loss: 1.6956166640574877
Validation loss: 2.6089311831062187

Epoch: 5| Step: 8
Training loss: 1.787417592636628
Validation loss: 2.529496775164943

Epoch: 5| Step: 9
Training loss: 2.461226092174495
Validation loss: 2.5205371580662654

Epoch: 5| Step: 10
Training loss: 1.6010300658415242
Validation loss: 2.5209864132019235

Epoch: 597| Step: 0
Training loss: 1.9165111216026596
Validation loss: 2.593948999078476

Epoch: 5| Step: 1
Training loss: 1.947924105652121
Validation loss: 2.5536737968749232

Epoch: 5| Step: 2
Training loss: 2.354476795755373
Validation loss: 2.5162884879208045

Epoch: 5| Step: 3
Training loss: 1.9564678424285515
Validation loss: 2.5621636172650244

Epoch: 5| Step: 4
Training loss: 1.3461519995875846
Validation loss: 2.5043260184948686

Epoch: 5| Step: 5
Training loss: 1.8574836151098646
Validation loss: 2.5325880308399857

Epoch: 5| Step: 6
Training loss: 1.96598112582735
Validation loss: 2.5354899580818064

Epoch: 5| Step: 7
Training loss: 1.2166930226297503
Validation loss: 2.54370593227095

Epoch: 5| Step: 8
Training loss: 2.2495133615450102
Validation loss: 2.5242565007874465

Epoch: 5| Step: 9
Training loss: 2.206270718139542
Validation loss: 2.5154999763239823

Epoch: 5| Step: 10
Training loss: 1.0187229737985546
Validation loss: 2.5718546287909954

Epoch: 598| Step: 0
Training loss: 1.7252104976317864
Validation loss: 2.5344735496748405

Epoch: 5| Step: 1
Training loss: 1.4301121815781423
Validation loss: 2.53273912909472

Epoch: 5| Step: 2
Training loss: 1.7712129597368083
Validation loss: 2.4972772302030988

Epoch: 5| Step: 3
Training loss: 1.8642503949073228
Validation loss: 2.5161118002941194

Epoch: 5| Step: 4
Training loss: 1.6218962004641222
Validation loss: 2.626362350876789

Epoch: 5| Step: 5
Training loss: 1.8536929979261136
Validation loss: 2.581525176434983

Epoch: 5| Step: 6
Training loss: 1.8178821761136472
Validation loss: 2.578899716854352

Epoch: 5| Step: 7
Training loss: 2.415343108514429
Validation loss: 2.5991302505053255

Epoch: 5| Step: 8
Training loss: 1.7285356251049846
Validation loss: 2.570991919782323

Epoch: 5| Step: 9
Training loss: 2.1296457108828775
Validation loss: 2.535280127397934

Epoch: 5| Step: 10
Training loss: 1.6927055319738438
Validation loss: 2.4608249683502637

Epoch: 599| Step: 0
Training loss: 2.250692472921615
Validation loss: 2.520828330118829

Epoch: 5| Step: 1
Training loss: 2.105767336818753
Validation loss: 2.520293378210994

Epoch: 5| Step: 2
Training loss: 1.8860532483323593
Validation loss: 2.5388855777056882

Epoch: 5| Step: 3
Training loss: 2.0060994599807263
Validation loss: 2.5302376605941794

Epoch: 5| Step: 4
Training loss: 1.714897693663224
Validation loss: 2.5941616136492014

Epoch: 5| Step: 5
Training loss: 1.8729492416632447
Validation loss: 2.525132516985678

Epoch: 5| Step: 6
Training loss: 1.9599253561442345
Validation loss: 2.479846928920776

Epoch: 5| Step: 7
Training loss: 2.330059809265032
Validation loss: 2.5251140393691713

Epoch: 5| Step: 8
Training loss: 1.7944411006433114
Validation loss: 2.530610821539047

Epoch: 5| Step: 9
Training loss: 1.18841933752882
Validation loss: 2.5412291485264733

Epoch: 5| Step: 10
Training loss: 1.4708041172890176
Validation loss: 2.6057129421543443

Epoch: 600| Step: 0
Training loss: 1.7958436742899373
Validation loss: 2.530517777070431

Epoch: 5| Step: 1
Training loss: 1.4036765817684425
Validation loss: 2.5693330000241197

Epoch: 5| Step: 2
Training loss: 1.8149502733212572
Validation loss: 2.5120786467939253

Epoch: 5| Step: 3
Training loss: 1.6572342593138516
Validation loss: 2.543759017004789

Epoch: 5| Step: 4
Training loss: 1.9009216131336306
Validation loss: 2.544072022828312

Epoch: 5| Step: 5
Training loss: 1.635387525683554
Validation loss: 2.4819183255854096

Epoch: 5| Step: 6
Training loss: 2.041693615897721
Validation loss: 2.567481188012584

Epoch: 5| Step: 7
Training loss: 1.7041638207198102
Validation loss: 2.4687655744246966

Epoch: 5| Step: 8
Training loss: 2.5455451723165705
Validation loss: 2.556762110838109

Epoch: 5| Step: 9
Training loss: 1.9206187786941242
Validation loss: 2.5499610033698836

Epoch: 5| Step: 10
Training loss: 1.6474338025004878
Validation loss: 2.4902460070408146

Testing loss: 2.809127066080486
