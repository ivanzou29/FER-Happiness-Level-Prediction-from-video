Epoch: 1| Step: 0
Training loss: 2.7235212326049805
Validation loss: 2.517005887082828

Epoch: 5| Step: 1
Training loss: 2.7665209770202637
Validation loss: 2.517612152202155

Epoch: 5| Step: 2
Training loss: 3.1548633575439453
Validation loss: 2.515552382315359

Epoch: 5| Step: 3
Training loss: 3.035144090652466
Validation loss: 2.5170277011009956

Epoch: 5| Step: 4
Training loss: 2.8077614307403564
Validation loss: 2.5156910701464583

Epoch: 5| Step: 5
Training loss: 2.4896140098571777
Validation loss: 2.5142618328012447

Epoch: 5| Step: 6
Training loss: 3.0781006813049316
Validation loss: 2.514165832150367

Epoch: 5| Step: 7
Training loss: 2.4503226280212402
Validation loss: 2.51310061382991

Epoch: 5| Step: 8
Training loss: 2.841073989868164
Validation loss: 2.5120572813095583

Epoch: 5| Step: 9
Training loss: 2.5758509635925293
Validation loss: 2.510291963495234

Epoch: 5| Step: 10
Training loss: 2.4194083213806152
Validation loss: 2.5095396913507932

Epoch: 2| Step: 0
Training loss: 2.8159492015838623
Validation loss: 2.5073468198058424

Epoch: 5| Step: 1
Training loss: 2.8190505504608154
Validation loss: 2.5076122642845236

Epoch: 5| Step: 2
Training loss: 2.9835307598114014
Validation loss: 2.5048144196951263

Epoch: 5| Step: 3
Training loss: 2.3321290016174316
Validation loss: 2.505371283459407

Epoch: 5| Step: 4
Training loss: 2.4777286052703857
Validation loss: 2.5048816691162767

Epoch: 5| Step: 5
Training loss: 2.928281307220459
Validation loss: 2.5043960745616625

Epoch: 5| Step: 6
Training loss: 2.8101396560668945
Validation loss: 2.5028835009503108

Epoch: 5| Step: 7
Training loss: 2.6549899578094482
Validation loss: 2.501978866515621

Epoch: 5| Step: 8
Training loss: 2.5229363441467285
Validation loss: 2.5033082962036133

Epoch: 5| Step: 9
Training loss: 2.746075391769409
Validation loss: 2.5018359948230047

Epoch: 5| Step: 10
Training loss: 3.354949474334717
Validation loss: 2.5009632802778676

Epoch: 3| Step: 0
Training loss: 2.417253017425537
Validation loss: 2.4981863293596493

Epoch: 5| Step: 1
Training loss: 2.569441318511963
Validation loss: 2.496726933346

Epoch: 5| Step: 2
Training loss: 2.085599422454834
Validation loss: 2.4971692177557174

Epoch: 5| Step: 3
Training loss: 2.1608848571777344
Validation loss: 2.4960306716221634

Epoch: 5| Step: 4
Training loss: 3.1760003566741943
Validation loss: 2.496454679837791

Epoch: 5| Step: 5
Training loss: 2.8633229732513428
Validation loss: 2.4930337731556227

Epoch: 5| Step: 6
Training loss: 2.798255443572998
Validation loss: 2.492517835350447

Epoch: 5| Step: 7
Training loss: 3.459934711456299
Validation loss: 2.493036941815448

Epoch: 5| Step: 8
Training loss: 2.6215767860412598
Validation loss: 2.495046123381584

Epoch: 5| Step: 9
Training loss: 2.9382760524749756
Validation loss: 2.491347720546107

Epoch: 5| Step: 10
Training loss: 3.2629380226135254
Validation loss: 2.488737895924558

Epoch: 4| Step: 0
Training loss: 2.2681338787078857
Validation loss: 2.4896161940789994

Epoch: 5| Step: 1
Training loss: 3.006248950958252
Validation loss: 2.4866856169956986

Epoch: 5| Step: 2
Training loss: 3.125152111053467
Validation loss: 2.4862350084448375

Epoch: 5| Step: 3
Training loss: 2.645876407623291
Validation loss: 2.4852955648975987

Epoch: 5| Step: 4
Training loss: 2.3666179180145264
Validation loss: 2.4820557589172036

Epoch: 5| Step: 5
Training loss: 3.1846489906311035
Validation loss: 2.4833136937951528

Epoch: 5| Step: 6
Training loss: 2.939964771270752
Validation loss: 2.4827229335743892

Epoch: 5| Step: 7
Training loss: 1.6657955646514893
Validation loss: 2.482054325842088

Epoch: 5| Step: 8
Training loss: 2.9386963844299316
Validation loss: 2.4784756629697737

Epoch: 5| Step: 9
Training loss: 3.272977828979492
Validation loss: 2.479391059567851

Epoch: 5| Step: 10
Training loss: 2.824125051498413
Validation loss: 2.474195675183368

Epoch: 5| Step: 0
Training loss: 3.253570556640625
Validation loss: 2.4732569981646795

Epoch: 5| Step: 1
Training loss: 2.0505900382995605
Validation loss: 2.474018824997769

Epoch: 5| Step: 2
Training loss: 2.692375659942627
Validation loss: 2.4720132863649757

Epoch: 5| Step: 3
Training loss: 3.073948383331299
Validation loss: 2.4701897892900693

Epoch: 5| Step: 4
Training loss: 3.35164213180542
Validation loss: 2.4704645654206634

Epoch: 5| Step: 5
Training loss: 3.0457558631896973
Validation loss: 2.471544970748245

Epoch: 5| Step: 6
Training loss: 2.869229793548584
Validation loss: 2.468140097074611

Epoch: 5| Step: 7
Training loss: 1.974731683731079
Validation loss: 2.468235513215424

Epoch: 5| Step: 8
Training loss: 2.5994322299957275
Validation loss: 2.466024737204275

Epoch: 5| Step: 9
Training loss: 2.175562620162964
Validation loss: 2.462819973627726

Epoch: 5| Step: 10
Training loss: 3.107151508331299
Validation loss: 2.462050755818685

Epoch: 6| Step: 0
Training loss: 3.0583865642547607
Validation loss: 2.462932489251578

Epoch: 5| Step: 1
Training loss: 2.810685634613037
Validation loss: 2.4624962909247285

Epoch: 5| Step: 2
Training loss: 2.2363007068634033
Validation loss: 2.4596148921597387

Epoch: 5| Step: 3
Training loss: 2.257127285003662
Validation loss: 2.4595310431654736

Epoch: 5| Step: 4
Training loss: 2.71630597114563
Validation loss: 2.458959020594115

Epoch: 5| Step: 5
Training loss: 2.8471148014068604
Validation loss: 2.4558709026664816

Epoch: 5| Step: 6
Training loss: 2.7538676261901855
Validation loss: 2.4551504696569135

Epoch: 5| Step: 7
Training loss: 2.94730544090271
Validation loss: 2.4546386887950282

Epoch: 5| Step: 8
Training loss: 2.9682085514068604
Validation loss: 2.4536630722784225

Epoch: 5| Step: 9
Training loss: 2.642726421356201
Validation loss: 2.452744448056785

Epoch: 5| Step: 10
Training loss: 2.8561863899230957
Validation loss: 2.448982141351187

Epoch: 7| Step: 0
Training loss: 2.7107720375061035
Validation loss: 2.4463442499919603

Epoch: 5| Step: 1
Training loss: 2.8130970001220703
Validation loss: 2.448236685927196

Epoch: 5| Step: 2
Training loss: 2.372652053833008
Validation loss: 2.445297464247673

Epoch: 5| Step: 3
Training loss: 3.1371254920959473
Validation loss: 2.4425159987582954

Epoch: 5| Step: 4
Training loss: 3.2360846996307373
Validation loss: 2.444292001826789

Epoch: 5| Step: 5
Training loss: 2.7364799976348877
Validation loss: 2.4412902247521187

Epoch: 5| Step: 6
Training loss: 2.6219382286071777
Validation loss: 2.438043227759741

Epoch: 5| Step: 7
Training loss: 2.0368831157684326
Validation loss: 2.4373828903321297

Epoch: 5| Step: 8
Training loss: 2.711486339569092
Validation loss: 2.436088377429593

Epoch: 5| Step: 9
Training loss: 2.4477477073669434
Validation loss: 2.4349199007916194

Epoch: 5| Step: 10
Training loss: 3.223325729370117
Validation loss: 2.433819901558661

Epoch: 8| Step: 0
Training loss: 2.4501519203186035
Validation loss: 2.429489012687437

Epoch: 5| Step: 1
Training loss: 2.897475481033325
Validation loss: 2.4312985712482083

Epoch: 5| Step: 2
Training loss: 2.5046825408935547
Validation loss: 2.4292984982972503

Epoch: 5| Step: 3
Training loss: 2.5307910442352295
Validation loss: 2.4302073704299105

Epoch: 5| Step: 4
Training loss: 3.040321111679077
Validation loss: 2.424721271761002

Epoch: 5| Step: 5
Training loss: 3.0300958156585693
Validation loss: 2.4248145370073217

Epoch: 5| Step: 6
Training loss: 2.3027732372283936
Validation loss: 2.4234173477336927

Epoch: 5| Step: 7
Training loss: 2.782341241836548
Validation loss: 2.422768187779252

Epoch: 5| Step: 8
Training loss: 2.695253372192383
Validation loss: 2.4199578736418035

Epoch: 5| Step: 9
Training loss: 2.631117343902588
Validation loss: 2.419210477541852

Epoch: 5| Step: 10
Training loss: 3.053086996078491
Validation loss: 2.4121879480218373

Epoch: 9| Step: 0
Training loss: 2.2087650299072266
Validation loss: 2.411284554389215

Epoch: 5| Step: 1
Training loss: 3.4812302589416504
Validation loss: 2.4134722883983324

Epoch: 5| Step: 2
Training loss: 3.530892848968506
Validation loss: 2.413619887444281

Epoch: 5| Step: 3
Training loss: 2.361147165298462
Validation loss: 2.4084495985379784

Epoch: 5| Step: 4
Training loss: 3.019707679748535
Validation loss: 2.405913588821247

Epoch: 5| Step: 5
Training loss: 2.4088032245635986
Validation loss: 2.404086885913726

Epoch: 5| Step: 6
Training loss: 2.7534232139587402
Validation loss: 2.4048791598248225

Epoch: 5| Step: 7
Training loss: 2.3650269508361816
Validation loss: 2.4020562607754945

Epoch: 5| Step: 8
Training loss: 3.0177626609802246
Validation loss: 2.4016906548571844

Epoch: 5| Step: 9
Training loss: 2.1959586143493652
Validation loss: 2.400610153393079

Epoch: 5| Step: 10
Training loss: 2.3719077110290527
Validation loss: 2.3964001260777956

Epoch: 10| Step: 0
Training loss: 2.981996536254883
Validation loss: 2.3964539856039067

Epoch: 5| Step: 1
Training loss: 2.860485315322876
Validation loss: 2.392478671125186

Epoch: 5| Step: 2
Training loss: 2.585641384124756
Validation loss: 2.391071652853361

Epoch: 5| Step: 3
Training loss: 2.767244338989258
Validation loss: 2.3909521154178086

Epoch: 5| Step: 4
Training loss: 3.622612476348877
Validation loss: 2.391003588194488

Epoch: 5| Step: 5
Training loss: 2.887251377105713
Validation loss: 2.38543027447116

Epoch: 5| Step: 6
Training loss: 2.932650327682495
Validation loss: 2.3848819822393437

Epoch: 5| Step: 7
Training loss: 1.4522496461868286
Validation loss: 2.381547707383351

Epoch: 5| Step: 8
Training loss: 2.517890453338623
Validation loss: 2.3792812003884265

Epoch: 5| Step: 9
Training loss: 2.3639354705810547
Validation loss: 2.379122772524434

Epoch: 5| Step: 10
Training loss: 2.7029480934143066
Validation loss: 2.3751307610542542

Epoch: 11| Step: 0
Training loss: 2.7401301860809326
Validation loss: 2.3766649102651947

Epoch: 5| Step: 1
Training loss: 2.4055161476135254
Validation loss: 2.3743975726507043

Epoch: 5| Step: 2
Training loss: 2.650782585144043
Validation loss: 2.3697214062495897

Epoch: 5| Step: 3
Training loss: 2.705655097961426
Validation loss: 2.3659609492107103

Epoch: 5| Step: 4
Training loss: 3.098466157913208
Validation loss: 2.3650253690699095

Epoch: 5| Step: 5
Training loss: 2.3133769035339355
Validation loss: 2.3636052659762803

Epoch: 5| Step: 6
Training loss: 2.3688511848449707
Validation loss: 2.3659615414116972

Epoch: 5| Step: 7
Training loss: 3.061555862426758
Validation loss: 2.362100831923946

Epoch: 5| Step: 8
Training loss: 3.0320026874542236
Validation loss: 2.361182315375215

Epoch: 5| Step: 9
Training loss: 2.180638551712036
Validation loss: 2.360035624555362

Epoch: 5| Step: 10
Training loss: 3.0406737327575684
Validation loss: 2.3596799758172806

Epoch: 12| Step: 0
Training loss: 2.7213568687438965
Validation loss: 2.3539823255231305

Epoch: 5| Step: 1
Training loss: 2.6547603607177734
Validation loss: 2.348326593317011

Epoch: 5| Step: 2
Training loss: 2.8005313873291016
Validation loss: 2.351266702016195

Epoch: 5| Step: 3
Training loss: 2.367893934249878
Validation loss: 2.3472211386567805

Epoch: 5| Step: 4
Training loss: 2.497826099395752
Validation loss: 2.342294377665366

Epoch: 5| Step: 5
Training loss: 3.0336132049560547
Validation loss: 2.3442907820465746

Epoch: 5| Step: 6
Training loss: 2.892285108566284
Validation loss: 2.344359697834138

Epoch: 5| Step: 7
Training loss: 2.5695624351501465
Validation loss: 2.339793351388747

Epoch: 5| Step: 8
Training loss: 2.9191770553588867
Validation loss: 2.338555120652722

Epoch: 5| Step: 9
Training loss: 2.7451653480529785
Validation loss: 2.334651885494109

Epoch: 5| Step: 10
Training loss: 2.1177167892456055
Validation loss: 2.3329448110313824

Epoch: 13| Step: 0
Training loss: 2.7663094997406006
Validation loss: 2.330157467114028

Epoch: 5| Step: 1
Training loss: 2.7787957191467285
Validation loss: 2.326693150304979

Epoch: 5| Step: 2
Training loss: 2.6670594215393066
Validation loss: 2.3225376298350673

Epoch: 5| Step: 3
Training loss: 2.7516884803771973
Validation loss: 2.3202442584499234

Epoch: 5| Step: 4
Training loss: 2.174426555633545
Validation loss: 2.322321887939207

Epoch: 5| Step: 5
Training loss: 3.155346393585205
Validation loss: 2.3128325503359557

Epoch: 5| Step: 6
Training loss: 2.775609254837036
Validation loss: 2.315689371478173

Epoch: 5| Step: 7
Training loss: 3.0558555126190186
Validation loss: 2.3148761667231077

Epoch: 5| Step: 8
Training loss: 2.4522738456726074
Validation loss: 2.308830399667063

Epoch: 5| Step: 9
Training loss: 2.304861545562744
Validation loss: 2.3051926897418116

Epoch: 5| Step: 10
Training loss: 2.3036434650421143
Validation loss: 2.301887294297577

Epoch: 14| Step: 0
Training loss: 2.314267635345459
Validation loss: 2.30120341239437

Epoch: 5| Step: 1
Training loss: 2.3936614990234375
Validation loss: 2.2987624111995903

Epoch: 5| Step: 2
Training loss: 2.8959860801696777
Validation loss: 2.297274563902168

Epoch: 5| Step: 3
Training loss: 2.884511947631836
Validation loss: 2.2947532746099655

Epoch: 5| Step: 4
Training loss: 3.0006752014160156
Validation loss: 2.292864417517057

Epoch: 5| Step: 5
Training loss: 2.3360772132873535
Validation loss: 2.290444512521067

Epoch: 5| Step: 6
Training loss: 2.5677835941314697
Validation loss: 2.284107573570744

Epoch: 5| Step: 7
Training loss: 2.961623191833496
Validation loss: 2.288754840050974

Epoch: 5| Step: 8
Training loss: 2.727174758911133
Validation loss: 2.2805679100815968

Epoch: 5| Step: 9
Training loss: 2.1531646251678467
Validation loss: 2.2775915104855775

Epoch: 5| Step: 10
Training loss: 2.8945705890655518
Validation loss: 2.2772290604088896

Epoch: 15| Step: 0
Training loss: 2.7167468070983887
Validation loss: 2.269074788657568

Epoch: 5| Step: 1
Training loss: 2.6645569801330566
Validation loss: 2.2705281383247784

Epoch: 5| Step: 2
Training loss: 2.1915111541748047
Validation loss: 2.269241084334671

Epoch: 5| Step: 3
Training loss: 2.7267088890075684
Validation loss: 2.2679231269385225

Epoch: 5| Step: 4
Training loss: 2.944650173187256
Validation loss: 2.262139397282754

Epoch: 5| Step: 5
Training loss: 3.31217885017395
Validation loss: 2.2614552692700456

Epoch: 5| Step: 6
Training loss: 2.3853256702423096
Validation loss: 2.256215382647771

Epoch: 5| Step: 7
Training loss: 2.410881519317627
Validation loss: 2.254301363422025

Epoch: 5| Step: 8
Training loss: 2.397376537322998
Validation loss: 2.2540130589597966

Epoch: 5| Step: 9
Training loss: 2.7571444511413574
Validation loss: 2.246254495395127

Epoch: 5| Step: 10
Training loss: 2.3424813747406006
Validation loss: 2.247517401172269

Epoch: 16| Step: 0
Training loss: 2.530449390411377
Validation loss: 2.245610449903755

Epoch: 5| Step: 1
Training loss: 2.9757068157196045
Validation loss: 2.245001454507151

Epoch: 5| Step: 2
Training loss: 2.2061080932617188
Validation loss: 2.2416831626687

Epoch: 5| Step: 3
Training loss: 2.9060111045837402
Validation loss: 2.2364832637130574

Epoch: 5| Step: 4
Training loss: 2.832406997680664
Validation loss: 2.237474413328273

Epoch: 5| Step: 5
Training loss: 1.9227794408798218
Validation loss: 2.2360805811420565

Epoch: 5| Step: 6
Training loss: 2.8089287281036377
Validation loss: 2.232762684104263

Epoch: 5| Step: 7
Training loss: 2.9049153327941895
Validation loss: 2.2274777837978896

Epoch: 5| Step: 8
Training loss: 2.6747868061065674
Validation loss: 2.2320892772366925

Epoch: 5| Step: 9
Training loss: 2.558152437210083
Validation loss: 2.222721751018237

Epoch: 5| Step: 10
Training loss: 2.329435348510742
Validation loss: 2.2181176370190037

Epoch: 17| Step: 0
Training loss: 2.542726993560791
Validation loss: 2.2173645188731532

Epoch: 5| Step: 1
Training loss: 2.0512914657592773
Validation loss: 2.21718644326733

Epoch: 5| Step: 2
Training loss: 3.0503973960876465
Validation loss: 2.205928123125466

Epoch: 5| Step: 3
Training loss: 2.351219892501831
Validation loss: 2.20713791026864

Epoch: 5| Step: 4
Training loss: 2.7593836784362793
Validation loss: 2.2006890619954755

Epoch: 5| Step: 5
Training loss: 2.693990468978882
Validation loss: 2.201893442420549

Epoch: 5| Step: 6
Training loss: 2.531904458999634
Validation loss: 2.1946133259804017

Epoch: 5| Step: 7
Training loss: 2.5727906227111816
Validation loss: 2.193826747196977

Epoch: 5| Step: 8
Training loss: 2.8672165870666504
Validation loss: 2.1935023184745543

Epoch: 5| Step: 9
Training loss: 2.719830274581909
Validation loss: 2.187912192395938

Epoch: 5| Step: 10
Training loss: 2.3936026096343994
Validation loss: 2.1857064359931537

Epoch: 18| Step: 0
Training loss: 2.506169557571411
Validation loss: 2.1826313029053392

Epoch: 5| Step: 1
Training loss: 2.830249071121216
Validation loss: 2.1814076567208893

Epoch: 5| Step: 2
Training loss: 2.7520196437835693
Validation loss: 2.1788874364668325

Epoch: 5| Step: 3
Training loss: 3.1447505950927734
Validation loss: 2.1711906463869157

Epoch: 5| Step: 4
Training loss: 2.336843967437744
Validation loss: 2.170879331968164

Epoch: 5| Step: 5
Training loss: 2.7902112007141113
Validation loss: 2.1714846626404793

Epoch: 5| Step: 6
Training loss: 2.6851272583007812
Validation loss: 2.165412364467498

Epoch: 5| Step: 7
Training loss: 1.890655517578125
Validation loss: 2.1637570114545923

Epoch: 5| Step: 8
Training loss: 2.373802900314331
Validation loss: 2.1611540125262354

Epoch: 5| Step: 9
Training loss: 2.170149564743042
Validation loss: 2.1599738238960184

Epoch: 5| Step: 10
Training loss: 2.8271641731262207
Validation loss: 2.1523970685979372

Epoch: 19| Step: 0
Training loss: 2.9911582469940186
Validation loss: 2.1476403897808445

Epoch: 5| Step: 1
Training loss: 2.6581172943115234
Validation loss: 2.1490632462245163

Epoch: 5| Step: 2
Training loss: 2.5036022663116455
Validation loss: 2.14917209968772

Epoch: 5| Step: 3
Training loss: 1.9389864206314087
Validation loss: 2.1379257350839596

Epoch: 5| Step: 4
Training loss: 2.6848955154418945
Validation loss: 2.142310616790607

Epoch: 5| Step: 5
Training loss: 2.869408130645752
Validation loss: 2.129539064181748

Epoch: 5| Step: 6
Training loss: 2.6557376384735107
Validation loss: 2.135584613328339

Epoch: 5| Step: 7
Training loss: 2.227527618408203
Validation loss: 2.1313971550233903

Epoch: 5| Step: 8
Training loss: 2.6447691917419434
Validation loss: 2.1280286722285773

Epoch: 5| Step: 9
Training loss: 2.593106508255005
Validation loss: 2.1250879687647664

Epoch: 5| Step: 10
Training loss: 2.2146384716033936
Validation loss: 2.1152729257460563

Epoch: 20| Step: 0
Training loss: 3.0380187034606934
Validation loss: 2.1183793108950377

Epoch: 5| Step: 1
Training loss: 2.288483142852783
Validation loss: 2.1176274668785835

Epoch: 5| Step: 2
Training loss: 2.930894136428833
Validation loss: 2.1018324821226058

Epoch: 5| Step: 3
Training loss: 2.059035539627075
Validation loss: 2.1072351214706257

Epoch: 5| Step: 4
Training loss: 2.631782293319702
Validation loss: 2.1129010633755754

Epoch: 5| Step: 5
Training loss: 2.630828857421875
Validation loss: 2.100488813974524

Epoch: 5| Step: 6
Training loss: 2.057535171508789
Validation loss: 2.098776037975024

Epoch: 5| Step: 7
Training loss: 2.4347870349884033
Validation loss: 2.0935500744850404

Epoch: 5| Step: 8
Training loss: 2.9026055335998535
Validation loss: 2.0970047212416127

Epoch: 5| Step: 9
Training loss: 2.2357280254364014
Validation loss: 2.0898145091149116

Epoch: 5| Step: 10
Training loss: 2.6253111362457275
Validation loss: 2.0881446753778765

Epoch: 21| Step: 0
Training loss: 2.682368516921997
Validation loss: 2.086435055219999

Epoch: 5| Step: 1
Training loss: 2.746267795562744
Validation loss: 2.0745119945977324

Epoch: 5| Step: 2
Training loss: 2.111536979675293
Validation loss: 2.0786509142127088

Epoch: 5| Step: 3
Training loss: 2.259542226791382
Validation loss: 2.0747697994273198

Epoch: 5| Step: 4
Training loss: 2.4793715476989746
Validation loss: 2.07404322778025

Epoch: 5| Step: 5
Training loss: 2.5620059967041016
Validation loss: 2.0690637134736583

Epoch: 5| Step: 6
Training loss: 2.411236524581909
Validation loss: 2.0722334679736885

Epoch: 5| Step: 7
Training loss: 2.984891891479492
Validation loss: 2.066693180350847

Epoch: 5| Step: 8
Training loss: 2.435567855834961
Validation loss: 2.0639255623663626

Epoch: 5| Step: 9
Training loss: 2.5015602111816406
Validation loss: 2.057236265110713

Epoch: 5| Step: 10
Training loss: 2.5576655864715576
Validation loss: 2.0565249663527294

Epoch: 22| Step: 0
Training loss: 2.7706797122955322
Validation loss: 2.0588727510103615

Epoch: 5| Step: 1
Training loss: 2.797248363494873
Validation loss: 2.0527367643130723

Epoch: 5| Step: 2
Training loss: 2.935755968093872
Validation loss: 2.054304701025768

Epoch: 5| Step: 3
Training loss: 2.113598346710205
Validation loss: 2.0480399593230216

Epoch: 5| Step: 4
Training loss: 2.157953977584839
Validation loss: 2.054162689434585

Epoch: 5| Step: 5
Training loss: 2.358158826828003
Validation loss: 2.0379644824612524

Epoch: 5| Step: 6
Training loss: 1.738472580909729
Validation loss: 2.0467154056795183

Epoch: 5| Step: 7
Training loss: 2.5735557079315186
Validation loss: 2.038704364530502

Epoch: 5| Step: 8
Training loss: 2.6854121685028076
Validation loss: 2.030458350335398

Epoch: 5| Step: 9
Training loss: 2.7434170246124268
Validation loss: 2.037711471639654

Epoch: 5| Step: 10
Training loss: 2.609808921813965
Validation loss: 2.037197953911238

Epoch: 23| Step: 0
Training loss: 2.216712236404419
Validation loss: 2.0321089644585886

Epoch: 5| Step: 1
Training loss: 2.40730357170105
Validation loss: 2.029810324791939

Epoch: 5| Step: 2
Training loss: 2.3799407482147217
Validation loss: 2.0389519532521567

Epoch: 5| Step: 3
Training loss: 3.166743516921997
Validation loss: 2.03289189902685

Epoch: 5| Step: 4
Training loss: 2.589189052581787
Validation loss: 2.027995673559045

Epoch: 5| Step: 5
Training loss: 2.1924891471862793
Validation loss: 2.0322677884050595

Epoch: 5| Step: 6
Training loss: 1.920639991760254
Validation loss: 2.0319424918902818

Epoch: 5| Step: 7
Training loss: 2.8574531078338623
Validation loss: 2.0225451120766262

Epoch: 5| Step: 8
Training loss: 2.4448440074920654
Validation loss: 2.0265655427850704

Epoch: 5| Step: 9
Training loss: 2.783425807952881
Validation loss: 2.024795478390109

Epoch: 5| Step: 10
Training loss: 2.4187824726104736
Validation loss: 2.0192714147670294

Epoch: 24| Step: 0
Training loss: 2.213989734649658
Validation loss: 2.023280147583254

Epoch: 5| Step: 1
Training loss: 2.4286952018737793
Validation loss: 2.021531319105497

Epoch: 5| Step: 2
Training loss: 2.850224256515503
Validation loss: 2.0199918157310894

Epoch: 5| Step: 3
Training loss: 2.169316291809082
Validation loss: 2.0139028820940243

Epoch: 5| Step: 4
Training loss: 2.788135528564453
Validation loss: 2.022463413976854

Epoch: 5| Step: 5
Training loss: 2.7254035472869873
Validation loss: 2.007965167363485

Epoch: 5| Step: 6
Training loss: 2.623359441757202
Validation loss: 2.0077168505678893

Epoch: 5| Step: 7
Training loss: 2.627593517303467
Validation loss: 2.0174633302996234

Epoch: 5| Step: 8
Training loss: 2.098921537399292
Validation loss: 2.008951258915727

Epoch: 5| Step: 9
Training loss: 2.2558772563934326
Validation loss: 2.0121537152157036

Epoch: 5| Step: 10
Training loss: 2.5832948684692383
Validation loss: 2.001980927682692

Epoch: 25| Step: 0
Training loss: 2.3125786781311035
Validation loss: 2.0050097204023793

Epoch: 5| Step: 1
Training loss: 2.598020315170288
Validation loss: 2.008916703603601

Epoch: 5| Step: 2
Training loss: 2.556912899017334
Validation loss: 2.0091284910837808

Epoch: 5| Step: 3
Training loss: 2.5464038848876953
Validation loss: 2.002933713697618

Epoch: 5| Step: 4
Training loss: 2.3669488430023193
Validation loss: 2.0025578109166955

Epoch: 5| Step: 5
Training loss: 2.1195859909057617
Validation loss: 2.006143662237352

Epoch: 5| Step: 6
Training loss: 2.6734490394592285
Validation loss: 2.0130464389760006

Epoch: 5| Step: 7
Training loss: 2.3942906856536865
Validation loss: 2.0008489598510084

Epoch: 5| Step: 8
Training loss: 3.050565481185913
Validation loss: 1.9999003435975762

Epoch: 5| Step: 9
Training loss: 2.5216128826141357
Validation loss: 2.0044571661180064

Epoch: 5| Step: 10
Training loss: 2.0390191078186035
Validation loss: 2.005237329390741

Epoch: 26| Step: 0
Training loss: 2.8229684829711914
Validation loss: 1.9931691000538487

Epoch: 5| Step: 1
Training loss: 2.218964099884033
Validation loss: 2.002255762777021

Epoch: 5| Step: 2
Training loss: 2.1722049713134766
Validation loss: 1.99215857572453

Epoch: 5| Step: 3
Training loss: 2.460221767425537
Validation loss: 1.996710446573073

Epoch: 5| Step: 4
Training loss: 2.8901331424713135
Validation loss: 1.9908581267121017

Epoch: 5| Step: 5
Training loss: 2.3108112812042236
Validation loss: 1.9883036818555606

Epoch: 5| Step: 6
Training loss: 2.44083833694458
Validation loss: 1.9889300971902826

Epoch: 5| Step: 7
Training loss: 2.523159980773926
Validation loss: 1.99709883300207

Epoch: 5| Step: 8
Training loss: 2.6299052238464355
Validation loss: 1.9881706545429845

Epoch: 5| Step: 9
Training loss: 2.486372470855713
Validation loss: 1.9836418064691688

Epoch: 5| Step: 10
Training loss: 2.195046901702881
Validation loss: 1.9925206425369426

Epoch: 27| Step: 0
Training loss: 2.29685378074646
Validation loss: 1.99357093662344

Epoch: 5| Step: 1
Training loss: 2.199129104614258
Validation loss: 1.9938084720283427

Epoch: 5| Step: 2
Training loss: 2.718021869659424
Validation loss: 1.9869907594496203

Epoch: 5| Step: 3
Training loss: 2.719184398651123
Validation loss: 1.9895566355797552

Epoch: 5| Step: 4
Training loss: 2.433455467224121
Validation loss: 1.9868938384517547

Epoch: 5| Step: 5
Training loss: 1.9858261346817017
Validation loss: 1.9921302667228125

Epoch: 5| Step: 6
Training loss: 2.7324726581573486
Validation loss: 1.9908714422615625

Epoch: 5| Step: 7
Training loss: 2.8380484580993652
Validation loss: 1.9958129493139123

Epoch: 5| Step: 8
Training loss: 2.365360975265503
Validation loss: 1.9926725126081897

Epoch: 5| Step: 9
Training loss: 2.0422523021698
Validation loss: 1.9879902126968547

Epoch: 5| Step: 10
Training loss: 2.942382335662842
Validation loss: 1.9917961243660218

Epoch: 28| Step: 0
Training loss: 2.4748432636260986
Validation loss: 1.9886014551244757

Epoch: 5| Step: 1
Training loss: 2.7381770610809326
Validation loss: 1.9847527063021095

Epoch: 5| Step: 2
Training loss: 2.6509289741516113
Validation loss: 1.9970001328376032

Epoch: 5| Step: 3
Training loss: 2.3475213050842285
Validation loss: 1.995360086041112

Epoch: 5| Step: 4
Training loss: 2.901583433151245
Validation loss: 1.9917467537746634

Epoch: 5| Step: 5
Training loss: 2.070866584777832
Validation loss: 1.989583061587426

Epoch: 5| Step: 6
Training loss: 2.6385738849639893
Validation loss: 1.9911347691730787

Epoch: 5| Step: 7
Training loss: 2.390979051589966
Validation loss: 1.994497242794242

Epoch: 5| Step: 8
Training loss: 2.700063705444336
Validation loss: 1.9956474816927345

Epoch: 5| Step: 9
Training loss: 2.456146240234375
Validation loss: 1.988419000820447

Epoch: 5| Step: 10
Training loss: 1.5989673137664795
Validation loss: 1.9881888128096057

Epoch: 29| Step: 0
Training loss: 2.4999709129333496
Validation loss: 1.9855971951638498

Epoch: 5| Step: 1
Training loss: 2.7021989822387695
Validation loss: 1.9870080665875507

Epoch: 5| Step: 2
Training loss: 2.1123650074005127
Validation loss: 1.9869527432226366

Epoch: 5| Step: 3
Training loss: 2.3932642936706543
Validation loss: 1.9829192879379436

Epoch: 5| Step: 4
Training loss: 2.852193832397461
Validation loss: 1.9845821498542704

Epoch: 5| Step: 5
Training loss: 2.5981497764587402
Validation loss: 1.9903674279489825

Epoch: 5| Step: 6
Training loss: 2.3675663471221924
Validation loss: 1.984932808465855

Epoch: 5| Step: 7
Training loss: 2.433560371398926
Validation loss: 1.9803016403669953

Epoch: 5| Step: 8
Training loss: 2.7486438751220703
Validation loss: 1.9926521880652315

Epoch: 5| Step: 9
Training loss: 2.103248357772827
Validation loss: 1.999174456442556

Epoch: 5| Step: 10
Training loss: 2.1261188983917236
Validation loss: 1.9753531461120934

Epoch: 30| Step: 0
Training loss: 1.6315428018569946
Validation loss: 1.990608033313546

Epoch: 5| Step: 1
Training loss: 3.115234851837158
Validation loss: 1.9945484848432644

Epoch: 5| Step: 2
Training loss: 2.132058620452881
Validation loss: 1.9965094648381716

Epoch: 5| Step: 3
Training loss: 1.9181705713272095
Validation loss: 1.98686049830529

Epoch: 5| Step: 4
Training loss: 2.70712947845459
Validation loss: 1.9918771302828224

Epoch: 5| Step: 5
Training loss: 2.433974266052246
Validation loss: 1.9880915662293792

Epoch: 5| Step: 6
Training loss: 2.5755324363708496
Validation loss: 1.976211206887358

Epoch: 5| Step: 7
Training loss: 2.7464051246643066
Validation loss: 1.9829529728940738

Epoch: 5| Step: 8
Training loss: 2.683579444885254
Validation loss: 1.9837676632788874

Epoch: 5| Step: 9
Training loss: 2.243974208831787
Validation loss: 1.9821650007719636

Epoch: 5| Step: 10
Training loss: 2.8479106426239014
Validation loss: 1.9856806314119728

Epoch: 31| Step: 0
Training loss: 2.4531636238098145
Validation loss: 1.9777738061002506

Epoch: 5| Step: 1
Training loss: 2.559669017791748
Validation loss: 1.978851511914243

Epoch: 5| Step: 2
Training loss: 2.4718620777130127
Validation loss: 1.9720915543135775

Epoch: 5| Step: 3
Training loss: 2.0350897312164307
Validation loss: 1.9947969477663758

Epoch: 5| Step: 4
Training loss: 2.599304437637329
Validation loss: 1.9798775795967347

Epoch: 5| Step: 5
Training loss: 2.8307509422302246
Validation loss: 1.9788550407655778

Epoch: 5| Step: 6
Training loss: 2.898958206176758
Validation loss: 1.9776910069168254

Epoch: 5| Step: 7
Training loss: 2.270193576812744
Validation loss: 1.9777484119579356

Epoch: 5| Step: 8
Training loss: 2.4546871185302734
Validation loss: 1.9678919110246884

Epoch: 5| Step: 9
Training loss: 1.999388337135315
Validation loss: 1.9784733018567484

Epoch: 5| Step: 10
Training loss: 2.411760091781616
Validation loss: 1.9730334640831075

Epoch: 32| Step: 0
Training loss: 1.8552688360214233
Validation loss: 1.9683815868951942

Epoch: 5| Step: 1
Training loss: 2.5961995124816895
Validation loss: 1.9831656896939842

Epoch: 5| Step: 2
Training loss: 2.513678550720215
Validation loss: 1.980757878672692

Epoch: 5| Step: 3
Training loss: 2.492666006088257
Validation loss: 1.978159414824619

Epoch: 5| Step: 4
Training loss: 2.4330403804779053
Validation loss: 1.9846050841833955

Epoch: 5| Step: 5
Training loss: 2.7611942291259766
Validation loss: 1.9806653632912585

Epoch: 5| Step: 6
Training loss: 2.155151605606079
Validation loss: 1.9788471344978578

Epoch: 5| Step: 7
Training loss: 2.3451218605041504
Validation loss: 1.9815906042693763

Epoch: 5| Step: 8
Training loss: 2.4613089561462402
Validation loss: 1.9671865829857447

Epoch: 5| Step: 9
Training loss: 2.8444180488586426
Validation loss: 1.9825391615590742

Epoch: 5| Step: 10
Training loss: 2.4578990936279297
Validation loss: 1.9804140470361198

Epoch: 33| Step: 0
Training loss: 3.0012974739074707
Validation loss: 1.975025374402282

Epoch: 5| Step: 1
Training loss: 2.2853710651397705
Validation loss: 1.9808859902043496

Epoch: 5| Step: 2
Training loss: 2.851729154586792
Validation loss: 1.9806087119604951

Epoch: 5| Step: 3
Training loss: 2.07517409324646
Validation loss: 1.979854219703264

Epoch: 5| Step: 4
Training loss: 2.532384157180786
Validation loss: 1.9778753403694398

Epoch: 5| Step: 5
Training loss: 2.3138110637664795
Validation loss: 1.987177869325043

Epoch: 5| Step: 6
Training loss: 2.457535982131958
Validation loss: 1.9885862181263585

Epoch: 5| Step: 7
Training loss: 2.6152358055114746
Validation loss: 1.9901971150470037

Epoch: 5| Step: 8
Training loss: 1.7348066568374634
Validation loss: 1.9789536024934502

Epoch: 5| Step: 9
Training loss: 2.5935254096984863
Validation loss: 1.9875738646394463

Epoch: 5| Step: 10
Training loss: 2.432757616043091
Validation loss: 1.9812052954909622

Epoch: 34| Step: 0
Training loss: 2.437429904937744
Validation loss: 1.9933001097812448

Epoch: 5| Step: 1
Training loss: 2.2329959869384766
Validation loss: 1.9855227214033886

Epoch: 5| Step: 2
Training loss: 2.2822959423065186
Validation loss: 1.9908944047907347

Epoch: 5| Step: 3
Training loss: 2.1195740699768066
Validation loss: 1.9817284384081442

Epoch: 5| Step: 4
Training loss: 2.6745245456695557
Validation loss: 1.9804483485478226

Epoch: 5| Step: 5
Training loss: 2.4066002368927
Validation loss: 1.979725096815376

Epoch: 5| Step: 6
Training loss: 2.2368762493133545
Validation loss: 1.9878474140679965

Epoch: 5| Step: 7
Training loss: 2.7094764709472656
Validation loss: 1.986596372819716

Epoch: 5| Step: 8
Training loss: 2.7922732830047607
Validation loss: 1.9795083179268786

Epoch: 5| Step: 9
Training loss: 2.4838707447052
Validation loss: 1.9882173089570896

Epoch: 5| Step: 10
Training loss: 2.4075136184692383
Validation loss: 1.9844717338520994

Epoch: 35| Step: 0
Training loss: 2.0776915550231934
Validation loss: 1.988744620353945

Epoch: 5| Step: 1
Training loss: 2.636284828186035
Validation loss: 1.9890405131924538

Epoch: 5| Step: 2
Training loss: 1.9494869709014893
Validation loss: 1.9822494035126061

Epoch: 5| Step: 3
Training loss: 3.0100491046905518
Validation loss: 1.9782007663480696

Epoch: 5| Step: 4
Training loss: 2.5473341941833496
Validation loss: 1.9856802994205105

Epoch: 5| Step: 5
Training loss: 2.1345362663269043
Validation loss: 1.9770331190478416

Epoch: 5| Step: 6
Training loss: 3.110258102416992
Validation loss: 1.985549888303203

Epoch: 5| Step: 7
Training loss: 2.040677547454834
Validation loss: 1.9751538012617378

Epoch: 5| Step: 8
Training loss: 2.1282172203063965
Validation loss: 1.9866497465359267

Epoch: 5| Step: 9
Training loss: 2.828052520751953
Validation loss: 1.9865468214916926

Epoch: 5| Step: 10
Training loss: 2.2631473541259766
Validation loss: 1.9929961594202186

Epoch: 36| Step: 0
Training loss: 2.555842876434326
Validation loss: 1.9856420358022053

Epoch: 5| Step: 1
Training loss: 2.4514687061309814
Validation loss: 1.9824848521140315

Epoch: 5| Step: 2
Training loss: 2.420412302017212
Validation loss: 1.987230698267619

Epoch: 5| Step: 3
Training loss: 2.5038392543792725
Validation loss: 1.9854807392243417

Epoch: 5| Step: 4
Training loss: 2.35068941116333
Validation loss: 1.9901344955608409

Epoch: 5| Step: 5
Training loss: 2.337399959564209
Validation loss: 1.9791796835519935

Epoch: 5| Step: 6
Training loss: 1.56966233253479
Validation loss: 1.978496959132533

Epoch: 5| Step: 7
Training loss: 2.7979896068573
Validation loss: 1.9797016382217407

Epoch: 5| Step: 8
Training loss: 2.777848482131958
Validation loss: 1.9819901861170286

Epoch: 5| Step: 9
Training loss: 2.198403835296631
Validation loss: 1.9721837684672365

Epoch: 5| Step: 10
Training loss: 2.8626039028167725
Validation loss: 1.9824828717016405

Epoch: 37| Step: 0
Training loss: 1.999315619468689
Validation loss: 1.9859102925946635

Epoch: 5| Step: 1
Training loss: 2.29011869430542
Validation loss: 1.9680605293602071

Epoch: 5| Step: 2
Training loss: 2.367798328399658
Validation loss: 1.9745556833923503

Epoch: 5| Step: 3
Training loss: 2.5343875885009766
Validation loss: 1.9797807867809007

Epoch: 5| Step: 4
Training loss: 2.7308590412139893
Validation loss: 1.9789233566612325

Epoch: 5| Step: 5
Training loss: 2.5090649127960205
Validation loss: 1.9855251004618983

Epoch: 5| Step: 6
Training loss: 2.964808225631714
Validation loss: 1.9842547460268902

Epoch: 5| Step: 7
Training loss: 2.5446853637695312
Validation loss: 1.9867274735563545

Epoch: 5| Step: 8
Training loss: 2.167354106903076
Validation loss: 1.9792148759288173

Epoch: 5| Step: 9
Training loss: 2.6833364963531494
Validation loss: 1.9788430172909972

Epoch: 5| Step: 10
Training loss: 1.7738910913467407
Validation loss: 1.9792609676238029

Epoch: 38| Step: 0
Training loss: 2.789278030395508
Validation loss: 1.9854110825446345

Epoch: 5| Step: 1
Training loss: 3.183208465576172
Validation loss: 1.9828533587917205

Epoch: 5| Step: 2
Training loss: 2.843449115753174
Validation loss: 1.9875552090265418

Epoch: 5| Step: 3
Training loss: 2.089094877243042
Validation loss: 1.9761898517608643

Epoch: 5| Step: 4
Training loss: 2.060701847076416
Validation loss: 1.9823595875052995

Epoch: 5| Step: 5
Training loss: 2.057068347930908
Validation loss: 1.9810138133264357

Epoch: 5| Step: 6
Training loss: 2.236088275909424
Validation loss: 1.9841373351312452

Epoch: 5| Step: 7
Training loss: 2.0298526287078857
Validation loss: 1.9896803748223089

Epoch: 5| Step: 8
Training loss: 2.4069650173187256
Validation loss: 1.98254487335041

Epoch: 5| Step: 9
Training loss: 2.2613511085510254
Validation loss: 1.9793321906879384

Epoch: 5| Step: 10
Training loss: 2.7105908393859863
Validation loss: 1.991847599706342

Epoch: 39| Step: 0
Training loss: 2.5120391845703125
Validation loss: 1.982459911736109

Epoch: 5| Step: 1
Training loss: 2.3389434814453125
Validation loss: 1.9776447537124797

Epoch: 5| Step: 2
Training loss: 2.213183641433716
Validation loss: 1.9758199632808726

Epoch: 5| Step: 3
Training loss: 2.5845112800598145
Validation loss: 1.984317780822836

Epoch: 5| Step: 4
Training loss: 1.9627498388290405
Validation loss: 1.967505762653966

Epoch: 5| Step: 5
Training loss: 2.5082881450653076
Validation loss: 1.9790729566286969

Epoch: 5| Step: 6
Training loss: 1.9846950769424438
Validation loss: 1.982211184758012

Epoch: 5| Step: 7
Training loss: 2.4025044441223145
Validation loss: 1.980002248159019

Epoch: 5| Step: 8
Training loss: 2.98762845993042
Validation loss: 1.973777783814297

Epoch: 5| Step: 9
Training loss: 2.521700620651245
Validation loss: 1.9857238338839622

Epoch: 5| Step: 10
Training loss: 2.6747705936431885
Validation loss: 1.9780182761530722

Epoch: 40| Step: 0
Training loss: 2.7771568298339844
Validation loss: 1.984575886880198

Epoch: 5| Step: 1
Training loss: 2.5559802055358887
Validation loss: 1.987216188061622

Epoch: 5| Step: 2
Training loss: 2.1176486015319824
Validation loss: 1.9880436594768236

Epoch: 5| Step: 3
Training loss: 2.5514848232269287
Validation loss: 1.9878184385197137

Epoch: 5| Step: 4
Training loss: 2.8888542652130127
Validation loss: 1.980334158866636

Epoch: 5| Step: 5
Training loss: 2.0299203395843506
Validation loss: 1.9803051948547363

Epoch: 5| Step: 6
Training loss: 2.148622989654541
Validation loss: 1.9836721292106054

Epoch: 5| Step: 7
Training loss: 2.374876022338867
Validation loss: 1.9740395392141035

Epoch: 5| Step: 8
Training loss: 2.8023924827575684
Validation loss: 1.9732131522188905

Epoch: 5| Step: 9
Training loss: 2.2459511756896973
Validation loss: 1.9905976172416442

Epoch: 5| Step: 10
Training loss: 2.016200542449951
Validation loss: 1.9758113763665641

Epoch: 41| Step: 0
Training loss: 2.483717441558838
Validation loss: 1.9811032882300756

Epoch: 5| Step: 1
Training loss: 2.1441073417663574
Validation loss: 1.9744425255765197

Epoch: 5| Step: 2
Training loss: 2.4622128009796143
Validation loss: 1.977253189650915

Epoch: 5| Step: 3
Training loss: 2.1840949058532715
Validation loss: 1.9841524759928386

Epoch: 5| Step: 4
Training loss: 2.6898467540740967
Validation loss: 1.9809756714810607

Epoch: 5| Step: 5
Training loss: 2.3369784355163574
Validation loss: 1.9761041492544196

Epoch: 5| Step: 6
Training loss: 2.166465997695923
Validation loss: 1.9785101900818527

Epoch: 5| Step: 7
Training loss: 2.158424139022827
Validation loss: 1.9760560348469725

Epoch: 5| Step: 8
Training loss: 2.7633936405181885
Validation loss: 1.9790929286710677

Epoch: 5| Step: 9
Training loss: 2.586859941482544
Validation loss: 1.9774659192690285

Epoch: 5| Step: 10
Training loss: 2.5834176540374756
Validation loss: 1.9749015672232515

Epoch: 42| Step: 0
Training loss: 2.6204257011413574
Validation loss: 1.9813497668953353

Epoch: 5| Step: 1
Training loss: 2.2560505867004395
Validation loss: 1.9817307315846926

Epoch: 5| Step: 2
Training loss: 2.1953654289245605
Validation loss: 1.9888149871621081

Epoch: 5| Step: 3
Training loss: 2.431817054748535
Validation loss: 1.9825331959673154

Epoch: 5| Step: 4
Training loss: 2.5148766040802
Validation loss: 1.9815626759682932

Epoch: 5| Step: 5
Training loss: 2.318448305130005
Validation loss: 1.9758211412737448

Epoch: 5| Step: 6
Training loss: 2.317046642303467
Validation loss: 1.9844454693537887

Epoch: 5| Step: 7
Training loss: 2.97440767288208
Validation loss: 1.9847938335070046

Epoch: 5| Step: 8
Training loss: 2.2469215393066406
Validation loss: 1.987905752274298

Epoch: 5| Step: 9
Training loss: 2.330650568008423
Validation loss: 1.9860738426126459

Epoch: 5| Step: 10
Training loss: 2.304896116256714
Validation loss: 1.9844228888070712

Epoch: 43| Step: 0
Training loss: 2.787245512008667
Validation loss: 1.9814192095110494

Epoch: 5| Step: 1
Training loss: 2.227468729019165
Validation loss: 1.976574062019266

Epoch: 5| Step: 2
Training loss: 2.4187064170837402
Validation loss: 1.987293037035132

Epoch: 5| Step: 3
Training loss: 2.5237369537353516
Validation loss: 1.9795185545439362

Epoch: 5| Step: 4
Training loss: 1.6661548614501953
Validation loss: 1.9757370538609003

Epoch: 5| Step: 5
Training loss: 1.8463643789291382
Validation loss: 1.9735803706671602

Epoch: 5| Step: 6
Training loss: 2.8112027645111084
Validation loss: 1.9800814095363821

Epoch: 5| Step: 7
Training loss: 2.4334990978240967
Validation loss: 1.985017212488318

Epoch: 5| Step: 8
Training loss: 2.712745189666748
Validation loss: 1.9786187282172583

Epoch: 5| Step: 9
Training loss: 2.243032693862915
Validation loss: 1.9659123625806583

Epoch: 5| Step: 10
Training loss: 2.939091920852661
Validation loss: 1.9791615906582083

Epoch: 44| Step: 0
Training loss: 2.2694220542907715
Validation loss: 1.9736271942815473

Epoch: 5| Step: 1
Training loss: 2.4167091846466064
Validation loss: 1.9814208310137513

Epoch: 5| Step: 2
Training loss: 2.878093957901001
Validation loss: 1.9880668552972938

Epoch: 5| Step: 3
Training loss: 2.124403238296509
Validation loss: 1.9764244376972158

Epoch: 5| Step: 4
Training loss: 2.527021884918213
Validation loss: 1.9812870820363362

Epoch: 5| Step: 5
Training loss: 2.635566234588623
Validation loss: 1.9759498783337173

Epoch: 5| Step: 6
Training loss: 1.6942355632781982
Validation loss: 1.986520944103118

Epoch: 5| Step: 7
Training loss: 2.6300854682922363
Validation loss: 1.9806605615923483

Epoch: 5| Step: 8
Training loss: 1.91924250125885
Validation loss: 1.9849035855262511

Epoch: 5| Step: 9
Training loss: 2.437778949737549
Validation loss: 1.9724905439602431

Epoch: 5| Step: 10
Training loss: 2.932446002960205
Validation loss: 1.9778962135314941

Epoch: 45| Step: 0
Training loss: 2.350877285003662
Validation loss: 1.9827696238794634

Epoch: 5| Step: 1
Training loss: 1.9444042444229126
Validation loss: 1.9780194656823271

Epoch: 5| Step: 2
Training loss: 2.0527501106262207
Validation loss: 1.978997899639991

Epoch: 5| Step: 3
Training loss: 2.411669969558716
Validation loss: 1.9774516500452513

Epoch: 5| Step: 4
Training loss: 2.6934397220611572
Validation loss: 1.9772750164872857

Epoch: 5| Step: 5
Training loss: 2.7576045989990234
Validation loss: 1.9908832093720794

Epoch: 5| Step: 6
Training loss: 2.6490371227264404
Validation loss: 1.9762671814169934

Epoch: 5| Step: 7
Training loss: 2.3293938636779785
Validation loss: 1.9816959673358547

Epoch: 5| Step: 8
Training loss: 1.4814653396606445
Validation loss: 1.970469763202052

Epoch: 5| Step: 9
Training loss: 2.4655520915985107
Validation loss: 1.9754100102250294

Epoch: 5| Step: 10
Training loss: 3.408029556274414
Validation loss: 1.9807255396278955

Epoch: 46| Step: 0
Training loss: 2.0242531299591064
Validation loss: 1.9821692153971682

Epoch: 5| Step: 1
Training loss: 2.614077568054199
Validation loss: 1.9769612960917975

Epoch: 5| Step: 2
Training loss: 2.2411811351776123
Validation loss: 1.9687598200254544

Epoch: 5| Step: 3
Training loss: 2.217742443084717
Validation loss: 1.9802910922676005

Epoch: 5| Step: 4
Training loss: 2.068909168243408
Validation loss: 1.9745713203184065

Epoch: 5| Step: 5
Training loss: 2.0715019702911377
Validation loss: 1.977912042730598

Epoch: 5| Step: 6
Training loss: 2.4568941593170166
Validation loss: 1.9732102091594408

Epoch: 5| Step: 7
Training loss: 2.3607659339904785
Validation loss: 1.9688981002376926

Epoch: 5| Step: 8
Training loss: 2.5022125244140625
Validation loss: 1.9630542301362561

Epoch: 5| Step: 9
Training loss: 2.816068172454834
Validation loss: 1.979782449301853

Epoch: 5| Step: 10
Training loss: 3.058112621307373
Validation loss: 1.9672675376297326

Epoch: 47| Step: 0
Training loss: 1.921537160873413
Validation loss: 1.9605188677387853

Epoch: 5| Step: 1
Training loss: 2.1675028800964355
Validation loss: 1.9830101074710969

Epoch: 5| Step: 2
Training loss: 2.4468650817871094
Validation loss: 1.9786988176325315

Epoch: 5| Step: 3
Training loss: 2.3552372455596924
Validation loss: 1.9681027884124427

Epoch: 5| Step: 4
Training loss: 2.1610450744628906
Validation loss: 1.9638537976049608

Epoch: 5| Step: 5
Training loss: 2.800675630569458
Validation loss: 1.9735671422814811

Epoch: 5| Step: 6
Training loss: 2.3246195316314697
Validation loss: 1.9607771596600931

Epoch: 5| Step: 7
Training loss: 2.714341640472412
Validation loss: 1.976460123574862

Epoch: 5| Step: 8
Training loss: 1.9418611526489258
Validation loss: 1.9670472862899944

Epoch: 5| Step: 9
Training loss: 2.6110565662384033
Validation loss: 1.9694159800006497

Epoch: 5| Step: 10
Training loss: 2.85554838180542
Validation loss: 1.9718428939901373

Epoch: 48| Step: 0
Training loss: 1.9994335174560547
Validation loss: 1.9772903688492314

Epoch: 5| Step: 1
Training loss: 2.5581676959991455
Validation loss: 1.9730594363263858

Epoch: 5| Step: 2
Training loss: 2.6195297241210938
Validation loss: 1.9682948794416202

Epoch: 5| Step: 3
Training loss: 2.822279691696167
Validation loss: 1.9683391612063172

Epoch: 5| Step: 4
Training loss: 2.4026637077331543
Validation loss: 1.9739969391976633

Epoch: 5| Step: 5
Training loss: 2.1283786296844482
Validation loss: 1.9784656263166858

Epoch: 5| Step: 6
Training loss: 2.2705838680267334
Validation loss: 1.9703276888016732

Epoch: 5| Step: 7
Training loss: 2.2655904293060303
Validation loss: 1.9735876731975104

Epoch: 5| Step: 8
Training loss: 2.3328094482421875
Validation loss: 1.984673789752427

Epoch: 5| Step: 9
Training loss: 2.213070869445801
Validation loss: 1.973642505625243

Epoch: 5| Step: 10
Training loss: 2.735349416732788
Validation loss: 1.9772436388077275

Epoch: 49| Step: 0
Training loss: 2.6800873279571533
Validation loss: 1.9795380292400238

Epoch: 5| Step: 1
Training loss: 2.198092460632324
Validation loss: 1.9726913962312924

Epoch: 5| Step: 2
Training loss: 3.0059726238250732
Validation loss: 1.9808085426207511

Epoch: 5| Step: 3
Training loss: 2.411592483520508
Validation loss: 1.9785054640103412

Epoch: 5| Step: 4
Training loss: 2.2234952449798584
Validation loss: 1.971987332067182

Epoch: 5| Step: 5
Training loss: 2.474703311920166
Validation loss: 1.972719184813961

Epoch: 5| Step: 6
Training loss: 1.9578930139541626
Validation loss: 1.977874994277954

Epoch: 5| Step: 7
Training loss: 2.4197661876678467
Validation loss: 1.9801922100846485

Epoch: 5| Step: 8
Training loss: 2.5220367908477783
Validation loss: 1.9740126158601494

Epoch: 5| Step: 9
Training loss: 2.1255218982696533
Validation loss: 1.9836133936400056

Epoch: 5| Step: 10
Training loss: 2.135572910308838
Validation loss: 1.968022866915631

Epoch: 50| Step: 0
Training loss: 2.3805744647979736
Validation loss: 1.9620458233741023

Epoch: 5| Step: 1
Training loss: 2.307006359100342
Validation loss: 1.965880060708651

Epoch: 5| Step: 2
Training loss: 2.522557258605957
Validation loss: 1.975005344677997

Epoch: 5| Step: 3
Training loss: 2.456538200378418
Validation loss: 1.972383701673118

Epoch: 5| Step: 4
Training loss: 2.9523558616638184
Validation loss: 1.9698885717699606

Epoch: 5| Step: 5
Training loss: 2.1326255798339844
Validation loss: 1.9732110423426474

Epoch: 5| Step: 6
Training loss: 2.5999484062194824
Validation loss: 1.9602802799594017

Epoch: 5| Step: 7
Training loss: 1.9403488636016846
Validation loss: 1.969292313821854

Epoch: 5| Step: 8
Training loss: 2.0241971015930176
Validation loss: 1.9687316648421749

Epoch: 5| Step: 9
Training loss: 2.190763473510742
Validation loss: 1.9715193189600462

Epoch: 5| Step: 10
Training loss: 2.671980619430542
Validation loss: 1.9552659168038318

Epoch: 51| Step: 0
Training loss: 2.576899528503418
Validation loss: 1.9680166962326213

Epoch: 5| Step: 1
Training loss: 2.1203460693359375
Validation loss: 1.9581043950973018

Epoch: 5| Step: 2
Training loss: 2.5993056297302246
Validation loss: 1.9777146424016645

Epoch: 5| Step: 3
Training loss: 2.547008991241455
Validation loss: 1.9713326372126097

Epoch: 5| Step: 4
Training loss: 2.539527416229248
Validation loss: 1.9750286891896238

Epoch: 5| Step: 5
Training loss: 2.0821070671081543
Validation loss: 1.9741282450255526

Epoch: 5| Step: 6
Training loss: 2.5494377613067627
Validation loss: 1.97123630585209

Epoch: 5| Step: 7
Training loss: 2.5401649475097656
Validation loss: 1.9701106189399638

Epoch: 5| Step: 8
Training loss: 1.9668155908584595
Validation loss: 1.969165475137772

Epoch: 5| Step: 9
Training loss: 2.2101833820343018
Validation loss: 1.9714713276073497

Epoch: 5| Step: 10
Training loss: 2.374401330947876
Validation loss: 1.9786178219702937

Epoch: 52| Step: 0
Training loss: 1.65860116481781
Validation loss: 1.9788939465758622

Epoch: 5| Step: 1
Training loss: 2.145845890045166
Validation loss: 1.9738475263759654

Epoch: 5| Step: 2
Training loss: 2.9184730052948
Validation loss: 1.9693152725055654

Epoch: 5| Step: 3
Training loss: 2.818498134613037
Validation loss: 1.973482144776211

Epoch: 5| Step: 4
Training loss: 2.272711992263794
Validation loss: 1.9662776557348107

Epoch: 5| Step: 5
Training loss: 2.247619390487671
Validation loss: 1.9752659400304158

Epoch: 5| Step: 6
Training loss: 2.621861696243286
Validation loss: 1.971207147003502

Epoch: 5| Step: 7
Training loss: 2.4712331295013428
Validation loss: 1.9703323584730907

Epoch: 5| Step: 8
Training loss: 1.8772563934326172
Validation loss: 1.961229573013962

Epoch: 5| Step: 9
Training loss: 2.5318102836608887
Validation loss: 1.9771741974738337

Epoch: 5| Step: 10
Training loss: 2.4511125087738037
Validation loss: 1.9619925099034463

Epoch: 53| Step: 0
Training loss: 2.3903021812438965
Validation loss: 1.967511752600311

Epoch: 5| Step: 1
Training loss: 1.826185941696167
Validation loss: 1.9694079840055077

Epoch: 5| Step: 2
Training loss: 2.6484267711639404
Validation loss: 1.9639518273774015

Epoch: 5| Step: 3
Training loss: 2.8667025566101074
Validation loss: 1.9694651788280857

Epoch: 5| Step: 4
Training loss: 2.4978742599487305
Validation loss: 1.9752792953163065

Epoch: 5| Step: 5
Training loss: 2.4199445247650146
Validation loss: 1.9708754452325965

Epoch: 5| Step: 6
Training loss: 2.1500842571258545
Validation loss: 1.9685627952698739

Epoch: 5| Step: 7
Training loss: 2.1964008808135986
Validation loss: 1.9626882024990615

Epoch: 5| Step: 8
Training loss: 2.3280045986175537
Validation loss: 1.9795629311633367

Epoch: 5| Step: 9
Training loss: 2.430097818374634
Validation loss: 1.9747731801002257

Epoch: 5| Step: 10
Training loss: 2.168536424636841
Validation loss: 1.9850368448483047

Epoch: 54| Step: 0
Training loss: 3.0333988666534424
Validation loss: 1.9713495034043507

Epoch: 5| Step: 1
Training loss: 1.653601884841919
Validation loss: 1.9656877863791682

Epoch: 5| Step: 2
Training loss: 2.1103107929229736
Validation loss: 1.971520088052237

Epoch: 5| Step: 3
Training loss: 2.3774521350860596
Validation loss: 1.9563633293233893

Epoch: 5| Step: 4
Training loss: 2.51405668258667
Validation loss: 1.974523437920437

Epoch: 5| Step: 5
Training loss: 2.2082958221435547
Validation loss: 1.9668079345457015

Epoch: 5| Step: 6
Training loss: 2.9331064224243164
Validation loss: 1.9746053423932803

Epoch: 5| Step: 7
Training loss: 2.337092876434326
Validation loss: 1.9688168776932584

Epoch: 5| Step: 8
Training loss: 2.0451760292053223
Validation loss: 1.9661019181692472

Epoch: 5| Step: 9
Training loss: 2.500889301300049
Validation loss: 1.9629138387659544

Epoch: 5| Step: 10
Training loss: 2.287675142288208
Validation loss: 1.966366485882831

Epoch: 55| Step: 0
Training loss: 2.778550386428833
Validation loss: 1.97471438172043

Epoch: 5| Step: 1
Training loss: 1.9360342025756836
Validation loss: 1.9656449658896333

Epoch: 5| Step: 2
Training loss: 2.148022413253784
Validation loss: 1.9642174231108798

Epoch: 5| Step: 3
Training loss: 2.6930789947509766
Validation loss: 1.9542574267233572

Epoch: 5| Step: 4
Training loss: 2.1949193477630615
Validation loss: 1.9609852734432425

Epoch: 5| Step: 5
Training loss: 2.2690956592559814
Validation loss: 1.9487566768482167

Epoch: 5| Step: 6
Training loss: 2.409848690032959
Validation loss: 1.9693131408383768

Epoch: 5| Step: 7
Training loss: 2.759550094604492
Validation loss: 1.961986098238217

Epoch: 5| Step: 8
Training loss: 2.11074161529541
Validation loss: 1.9636951261951077

Epoch: 5| Step: 9
Training loss: 2.3890042304992676
Validation loss: 1.9724963659881263

Epoch: 5| Step: 10
Training loss: 2.2239110469818115
Validation loss: 1.9629505398452922

Epoch: 56| Step: 0
Training loss: 2.7584328651428223
Validation loss: 1.9601120833427674

Epoch: 5| Step: 1
Training loss: 2.4511988162994385
Validation loss: 1.9587753408698625

Epoch: 5| Step: 2
Training loss: 2.480386257171631
Validation loss: 1.9622038231101087

Epoch: 5| Step: 3
Training loss: 2.297086238861084
Validation loss: 1.964884740050121

Epoch: 5| Step: 4
Training loss: 1.8917757272720337
Validation loss: 1.9719054032397527

Epoch: 5| Step: 5
Training loss: 2.130812406539917
Validation loss: 1.9652728085876794

Epoch: 5| Step: 6
Training loss: 2.817903518676758
Validation loss: 1.9616538247754496

Epoch: 5| Step: 7
Training loss: 2.438601016998291
Validation loss: 1.9636772153198079

Epoch: 5| Step: 8
Training loss: 2.6503725051879883
Validation loss: 1.9801517609627015

Epoch: 5| Step: 9
Training loss: 1.8371994495391846
Validation loss: 1.9661588963641916

Epoch: 5| Step: 10
Training loss: 2.0598649978637695
Validation loss: 1.9791166718288133

Epoch: 57| Step: 0
Training loss: 2.042095184326172
Validation loss: 1.9661147543179092

Epoch: 5| Step: 1
Training loss: 2.3016867637634277
Validation loss: 1.9634308045910251

Epoch: 5| Step: 2
Training loss: 2.8062987327575684
Validation loss: 1.9598233212706864

Epoch: 5| Step: 3
Training loss: 2.4147727489471436
Validation loss: 1.9629437718340146

Epoch: 5| Step: 4
Training loss: 2.5053110122680664
Validation loss: 1.9632946278459282

Epoch: 5| Step: 5
Training loss: 2.404808521270752
Validation loss: 1.9554884792656027

Epoch: 5| Step: 6
Training loss: 2.2721993923187256
Validation loss: 1.9556327545514671

Epoch: 5| Step: 7
Training loss: 2.1080007553100586
Validation loss: 1.977422459151155

Epoch: 5| Step: 8
Training loss: 2.4771335124969482
Validation loss: 1.9649653627026467

Epoch: 5| Step: 9
Training loss: 2.3520400524139404
Validation loss: 1.9674180835805914

Epoch: 5| Step: 10
Training loss: 2.0893237590789795
Validation loss: 1.957786347276421

Epoch: 58| Step: 0
Training loss: 1.8355038166046143
Validation loss: 1.9658104476108347

Epoch: 5| Step: 1
Training loss: 2.4371886253356934
Validation loss: 1.966464445155154

Epoch: 5| Step: 2
Training loss: 2.2969813346862793
Validation loss: 1.9640733093343756

Epoch: 5| Step: 3
Training loss: 2.1865808963775635
Validation loss: 1.9670847590251634

Epoch: 5| Step: 4
Training loss: 2.458709478378296
Validation loss: 1.9695792992909749

Epoch: 5| Step: 5
Training loss: 2.9000582695007324
Validation loss: 1.9692833641523957

Epoch: 5| Step: 6
Training loss: 2.537454128265381
Validation loss: 1.9750228261434903

Epoch: 5| Step: 7
Training loss: 2.691895008087158
Validation loss: 1.958346264336699

Epoch: 5| Step: 8
Training loss: 1.9810583591461182
Validation loss: 1.9675218110443444

Epoch: 5| Step: 9
Training loss: 1.873307466506958
Validation loss: 1.9710881799779914

Epoch: 5| Step: 10
Training loss: 2.515989065170288
Validation loss: 1.990222841180781

Epoch: 59| Step: 0
Training loss: 2.5299124717712402
Validation loss: 1.9643792080622848

Epoch: 5| Step: 1
Training loss: 2.055492401123047
Validation loss: 1.9738103728140555

Epoch: 5| Step: 2
Training loss: 3.0411219596862793
Validation loss: 1.9698022988534742

Epoch: 5| Step: 3
Training loss: 2.4843106269836426
Validation loss: 1.9707004126682077

Epoch: 5| Step: 4
Training loss: 1.9091908931732178
Validation loss: 1.9675854534231207

Epoch: 5| Step: 5
Training loss: 1.8632183074951172
Validation loss: 1.9591626531334334

Epoch: 5| Step: 6
Training loss: 2.568488597869873
Validation loss: 1.969876738004787

Epoch: 5| Step: 7
Training loss: 2.1863749027252197
Validation loss: 1.9643307578179143

Epoch: 5| Step: 8
Training loss: 2.214956045150757
Validation loss: 1.9578649818256337

Epoch: 5| Step: 9
Training loss: 2.192535638809204
Validation loss: 1.9635555231443016

Epoch: 5| Step: 10
Training loss: 2.6677794456481934
Validation loss: 1.9607352184992966

Epoch: 60| Step: 0
Training loss: 2.435116767883301
Validation loss: 1.9499066863008725

Epoch: 5| Step: 1
Training loss: 2.1541404724121094
Validation loss: 1.9697297965326617

Epoch: 5| Step: 2
Training loss: 2.0683789253234863
Validation loss: 1.9648581704785746

Epoch: 5| Step: 3
Training loss: 2.157276153564453
Validation loss: 1.9633218678095008

Epoch: 5| Step: 4
Training loss: 2.154564619064331
Validation loss: 1.972981938751795

Epoch: 5| Step: 5
Training loss: 2.588130474090576
Validation loss: 1.9681841814389793

Epoch: 5| Step: 6
Training loss: 1.957930564880371
Validation loss: 1.9732966820398967

Epoch: 5| Step: 7
Training loss: 2.3585193157196045
Validation loss: 1.958568448661476

Epoch: 5| Step: 8
Training loss: 2.617760419845581
Validation loss: 1.9649829274864608

Epoch: 5| Step: 9
Training loss: 2.5092711448669434
Validation loss: 1.9656205433671192

Epoch: 5| Step: 10
Training loss: 2.6846835613250732
Validation loss: 1.9630173239656674

Epoch: 61| Step: 0
Training loss: 2.6388707160949707
Validation loss: 1.9655416575811242

Epoch: 5| Step: 1
Training loss: 2.311791181564331
Validation loss: 1.9690221817262712

Epoch: 5| Step: 2
Training loss: 2.0281898975372314
Validation loss: 1.9690447161274571

Epoch: 5| Step: 3
Training loss: 2.2245371341705322
Validation loss: 1.9697921660638624

Epoch: 5| Step: 4
Training loss: 2.388075113296509
Validation loss: 1.9573193224527503

Epoch: 5| Step: 5
Training loss: 2.3644564151763916
Validation loss: 1.9607458614533948

Epoch: 5| Step: 6
Training loss: 2.4017908573150635
Validation loss: 1.9506785177415418

Epoch: 5| Step: 7
Training loss: 2.043855667114258
Validation loss: 1.9407563106988066

Epoch: 5| Step: 8
Training loss: 2.4747376441955566
Validation loss: 1.9446123517969602

Epoch: 5| Step: 9
Training loss: 2.1707847118377686
Validation loss: 1.9509560831131474

Epoch: 5| Step: 10
Training loss: 2.5721802711486816
Validation loss: 1.948958077738362

Epoch: 62| Step: 0
Training loss: 1.8967304229736328
Validation loss: 1.9566657863637453

Epoch: 5| Step: 1
Training loss: 2.517129421234131
Validation loss: 1.9660141083502

Epoch: 5| Step: 2
Training loss: 2.1497576236724854
Validation loss: 1.9541628591475948

Epoch: 5| Step: 3
Training loss: 2.853789806365967
Validation loss: 1.94500913927632

Epoch: 5| Step: 4
Training loss: 2.3939404487609863
Validation loss: 1.9650331594610726

Epoch: 5| Step: 5
Training loss: 2.4888291358947754
Validation loss: 1.9586000698868946

Epoch: 5| Step: 6
Training loss: 2.4569664001464844
Validation loss: 1.9432831502729846

Epoch: 5| Step: 7
Training loss: 2.0975677967071533
Validation loss: 1.9472059844642557

Epoch: 5| Step: 8
Training loss: 2.318709373474121
Validation loss: 1.9572276197453982

Epoch: 5| Step: 9
Training loss: 2.0000736713409424
Validation loss: 1.968083853362709

Epoch: 5| Step: 10
Training loss: 2.190380334854126
Validation loss: 1.9567705790201824

Epoch: 63| Step: 0
Training loss: 2.0075860023498535
Validation loss: 1.9633838527946061

Epoch: 5| Step: 1
Training loss: 2.3286633491516113
Validation loss: 1.9512597886464929

Epoch: 5| Step: 2
Training loss: 2.109251022338867
Validation loss: 1.9566473435330134

Epoch: 5| Step: 3
Training loss: 2.2078864574432373
Validation loss: 1.9585278752029582

Epoch: 5| Step: 4
Training loss: 2.5620930194854736
Validation loss: 1.9554831084384714

Epoch: 5| Step: 5
Training loss: 2.2120883464813232
Validation loss: 1.9524359574881933

Epoch: 5| Step: 6
Training loss: 2.1979033946990967
Validation loss: 1.9514486302611649

Epoch: 5| Step: 7
Training loss: 2.7511725425720215
Validation loss: 1.9529223262622792

Epoch: 5| Step: 8
Training loss: 2.661400318145752
Validation loss: 1.9423201904501965

Epoch: 5| Step: 9
Training loss: 2.375343084335327
Validation loss: 1.9341219778983825

Epoch: 5| Step: 10
Training loss: 1.9846374988555908
Validation loss: 1.9609189930782522

Epoch: 64| Step: 0
Training loss: 2.1809370517730713
Validation loss: 1.948990128373587

Epoch: 5| Step: 1
Training loss: 1.8234859704971313
Validation loss: 1.9635077548283402

Epoch: 5| Step: 2
Training loss: 2.5524821281433105
Validation loss: 1.9542401593218568

Epoch: 5| Step: 3
Training loss: 2.2266178131103516
Validation loss: 1.9647753546314854

Epoch: 5| Step: 4
Training loss: 2.1405205726623535
Validation loss: 1.975027754742612

Epoch: 5| Step: 5
Training loss: 2.276787519454956
Validation loss: 1.9628182970067507

Epoch: 5| Step: 6
Training loss: 1.9649598598480225
Validation loss: 1.9575563476931663

Epoch: 5| Step: 7
Training loss: 1.986936330795288
Validation loss: 1.9733170027373939

Epoch: 5| Step: 8
Training loss: 3.147500991821289
Validation loss: 1.9618059204470726

Epoch: 5| Step: 9
Training loss: 2.5687084197998047
Validation loss: 1.9666579000411495

Epoch: 5| Step: 10
Training loss: 2.4848270416259766
Validation loss: 1.965202926307596

Epoch: 65| Step: 0
Training loss: 2.6391758918762207
Validation loss: 1.947224655459004

Epoch: 5| Step: 1
Training loss: 2.0015206336975098
Validation loss: 1.9642861940527474

Epoch: 5| Step: 2
Training loss: 2.025212526321411
Validation loss: 1.9595919129669026

Epoch: 5| Step: 3
Training loss: 1.4014981985092163
Validation loss: 1.9710041412743189

Epoch: 5| Step: 4
Training loss: 2.5562620162963867
Validation loss: 1.96059763175185

Epoch: 5| Step: 5
Training loss: 2.7694811820983887
Validation loss: 1.9583212585859402

Epoch: 5| Step: 6
Training loss: 2.0729024410247803
Validation loss: 1.9439976112816924

Epoch: 5| Step: 7
Training loss: 2.5214762687683105
Validation loss: 1.9464659344765447

Epoch: 5| Step: 8
Training loss: 2.4152097702026367
Validation loss: 1.9521598674917733

Epoch: 5| Step: 9
Training loss: 2.624194622039795
Validation loss: 1.9571911852846864

Epoch: 5| Step: 10
Training loss: 2.1952333450317383
Validation loss: 1.951755864645845

Epoch: 66| Step: 0
Training loss: 2.6738643646240234
Validation loss: 1.9677264908308625

Epoch: 5| Step: 1
Training loss: 2.2232842445373535
Validation loss: 1.9704021100075013

Epoch: 5| Step: 2
Training loss: 2.681731939315796
Validation loss: 1.9446064592689596

Epoch: 5| Step: 3
Training loss: 2.18910551071167
Validation loss: 1.9544666018537296

Epoch: 5| Step: 4
Training loss: 2.423121690750122
Validation loss: 1.95146083447241

Epoch: 5| Step: 5
Training loss: 1.8397318124771118
Validation loss: 1.955335154328295

Epoch: 5| Step: 6
Training loss: 2.067115306854248
Validation loss: 1.9592167459508425

Epoch: 5| Step: 7
Training loss: 2.4393959045410156
Validation loss: 1.9538855462945917

Epoch: 5| Step: 8
Training loss: 2.2815303802490234
Validation loss: 1.9528638726921492

Epoch: 5| Step: 9
Training loss: 2.2590408325195312
Validation loss: 1.9386642056126748

Epoch: 5| Step: 10
Training loss: 2.036310911178589
Validation loss: 1.9465696837312432

Epoch: 67| Step: 0
Training loss: 1.7500308752059937
Validation loss: 1.954753073312903

Epoch: 5| Step: 1
Training loss: 2.943761110305786
Validation loss: 1.95359052893936

Epoch: 5| Step: 2
Training loss: 2.104361057281494
Validation loss: 1.951807188731368

Epoch: 5| Step: 3
Training loss: 2.273371696472168
Validation loss: 1.9580196424197125

Epoch: 5| Step: 4
Training loss: 2.145813465118408
Validation loss: 1.9447513241921701

Epoch: 5| Step: 5
Training loss: 2.4385318756103516
Validation loss: 1.9615188580687328

Epoch: 5| Step: 6
Training loss: 2.228145122528076
Validation loss: 1.9418454195863457

Epoch: 5| Step: 7
Training loss: 1.9386285543441772
Validation loss: 1.9624452770397227

Epoch: 5| Step: 8
Training loss: 2.2536025047302246
Validation loss: 1.9540489617214407

Epoch: 5| Step: 9
Training loss: 2.334664821624756
Validation loss: 1.9515414417430919

Epoch: 5| Step: 10
Training loss: 2.77384352684021
Validation loss: 1.9420669091645109

Epoch: 68| Step: 0
Training loss: 2.2270541191101074
Validation loss: 1.959020850478962

Epoch: 5| Step: 1
Training loss: 2.4493610858917236
Validation loss: 1.9549487752299155

Epoch: 5| Step: 2
Training loss: 2.497708559036255
Validation loss: 1.9492507698715373

Epoch: 5| Step: 3
Training loss: 2.277855634689331
Validation loss: 1.9653846115194342

Epoch: 5| Step: 4
Training loss: 2.6995346546173096
Validation loss: 1.958603020637266

Epoch: 5| Step: 5
Training loss: 1.8505370616912842
Validation loss: 1.9505979643073132

Epoch: 5| Step: 6
Training loss: 2.3647923469543457
Validation loss: 1.9629190455200851

Epoch: 5| Step: 7
Training loss: 2.319653034210205
Validation loss: 1.957752372628899

Epoch: 5| Step: 8
Training loss: 2.3117973804473877
Validation loss: 1.973722416867492

Epoch: 5| Step: 9
Training loss: 1.970668077468872
Validation loss: 1.9708802828224756

Epoch: 5| Step: 10
Training loss: 2.1189534664154053
Validation loss: 1.983804169521537

Epoch: 69| Step: 0
Training loss: 1.9305099248886108
Validation loss: 1.9599215010161042

Epoch: 5| Step: 1
Training loss: 2.3922016620635986
Validation loss: 1.9652537761196014

Epoch: 5| Step: 2
Training loss: 2.809603214263916
Validation loss: 1.958776779072259

Epoch: 5| Step: 3
Training loss: 2.236104726791382
Validation loss: 1.9657688038323515

Epoch: 5| Step: 4
Training loss: 2.567230701446533
Validation loss: 1.9652851384173158

Epoch: 5| Step: 5
Training loss: 2.0480802059173584
Validation loss: 1.9695895717990013

Epoch: 5| Step: 6
Training loss: 2.14437198638916
Validation loss: 1.9601018069892802

Epoch: 5| Step: 7
Training loss: 2.152498483657837
Validation loss: 1.9488482462462557

Epoch: 5| Step: 8
Training loss: 2.116797924041748
Validation loss: 1.9540161509667673

Epoch: 5| Step: 9
Training loss: 2.1275486946105957
Validation loss: 1.955383203362906

Epoch: 5| Step: 10
Training loss: 2.3618383407592773
Validation loss: 1.9625380359670168

Epoch: 70| Step: 0
Training loss: 1.9340381622314453
Validation loss: 1.9619586403651903

Epoch: 5| Step: 1
Training loss: 1.8517096042633057
Validation loss: 1.947305619075734

Epoch: 5| Step: 2
Training loss: 2.1504359245300293
Validation loss: 1.9561451019779328

Epoch: 5| Step: 3
Training loss: 3.0055482387542725
Validation loss: 1.961777412763206

Epoch: 5| Step: 4
Training loss: 2.007145404815674
Validation loss: 1.9614685094484718

Epoch: 5| Step: 5
Training loss: 1.8885746002197266
Validation loss: 1.967297892416677

Epoch: 5| Step: 6
Training loss: 2.1175615787506104
Validation loss: 1.9412870919832619

Epoch: 5| Step: 7
Training loss: 2.0637800693511963
Validation loss: 1.973823760145454

Epoch: 5| Step: 8
Training loss: 2.1389858722686768
Validation loss: 1.9721918977716917

Epoch: 5| Step: 9
Training loss: 2.910045623779297
Validation loss: 1.9726863291955763

Epoch: 5| Step: 10
Training loss: 2.9149065017700195
Validation loss: 1.9677643519575878

Epoch: 71| Step: 0
Training loss: 2.0110092163085938
Validation loss: 1.9624786492316955

Epoch: 5| Step: 1
Training loss: 2.2962307929992676
Validation loss: 1.9695506736796389

Epoch: 5| Step: 2
Training loss: 2.996809720993042
Validation loss: 1.9661264906647384

Epoch: 5| Step: 3
Training loss: 2.1413159370422363
Validation loss: 1.9770037230624948

Epoch: 5| Step: 4
Training loss: 2.214038372039795
Validation loss: 1.9661668705683883

Epoch: 5| Step: 5
Training loss: 2.182889938354492
Validation loss: 1.960878997720698

Epoch: 5| Step: 6
Training loss: 2.3713841438293457
Validation loss: 1.9484926782628542

Epoch: 5| Step: 7
Training loss: 2.354876756668091
Validation loss: 1.967626505000617

Epoch: 5| Step: 8
Training loss: 2.2835049629211426
Validation loss: 1.9614465992937806

Epoch: 5| Step: 9
Training loss: 1.8332226276397705
Validation loss: 1.9667144783081547

Epoch: 5| Step: 10
Training loss: 2.071493625640869
Validation loss: 1.960497179339009

Epoch: 72| Step: 0
Training loss: 1.177051305770874
Validation loss: 1.9619263192658782

Epoch: 5| Step: 1
Training loss: 2.617917537689209
Validation loss: 1.9587311424234861

Epoch: 5| Step: 2
Training loss: 3.0770130157470703
Validation loss: 1.9562880441706667

Epoch: 5| Step: 3
Training loss: 2.193251371383667
Validation loss: 1.9605411778214157

Epoch: 5| Step: 4
Training loss: 2.148430347442627
Validation loss: 1.9479995671138968

Epoch: 5| Step: 5
Training loss: 2.5596020221710205
Validation loss: 1.9379080008434992

Epoch: 5| Step: 6
Training loss: 2.4285788536071777
Validation loss: 1.9469822901551441

Epoch: 5| Step: 7
Training loss: 2.0832695960998535
Validation loss: 1.948898030865577

Epoch: 5| Step: 8
Training loss: 2.4185009002685547
Validation loss: 1.9519216706675868

Epoch: 5| Step: 9
Training loss: 1.853843331336975
Validation loss: 1.932795496397121

Epoch: 5| Step: 10
Training loss: 2.3320374488830566
Validation loss: 1.939861705226283

Epoch: 73| Step: 0
Training loss: 2.665396213531494
Validation loss: 1.9564220572030673

Epoch: 5| Step: 1
Training loss: 2.9075233936309814
Validation loss: 1.9375106852541688

Epoch: 5| Step: 2
Training loss: 2.2650787830352783
Validation loss: 1.942380300132177

Epoch: 5| Step: 3
Training loss: 2.284168004989624
Validation loss: 1.9479790195342033

Epoch: 5| Step: 4
Training loss: 2.1709885597229004
Validation loss: 1.9420527130044916

Epoch: 5| Step: 5
Training loss: 2.454685688018799
Validation loss: 1.9498659974785262

Epoch: 5| Step: 6
Training loss: 2.0934340953826904
Validation loss: 1.947148589677708

Epoch: 5| Step: 7
Training loss: 1.4832985401153564
Validation loss: 1.970419709400464

Epoch: 5| Step: 8
Training loss: 1.6371597051620483
Validation loss: 1.967256829302798

Epoch: 5| Step: 9
Training loss: 2.3375372886657715
Validation loss: 1.9472216316448745

Epoch: 5| Step: 10
Training loss: 2.542736291885376
Validation loss: 1.9574390854886783

Epoch: 74| Step: 0
Training loss: 1.952497124671936
Validation loss: 1.9378877685916038

Epoch: 5| Step: 1
Training loss: 2.4749279022216797
Validation loss: 1.9616209076296898

Epoch: 5| Step: 2
Training loss: 2.72406268119812
Validation loss: 1.9448627374505485

Epoch: 5| Step: 3
Training loss: 2.2071642875671387
Validation loss: 1.9521605532656434

Epoch: 5| Step: 4
Training loss: 2.427642583847046
Validation loss: 1.9592731998812767

Epoch: 5| Step: 5
Training loss: 1.9681094884872437
Validation loss: 1.9498195481556717

Epoch: 5| Step: 6
Training loss: 2.555129289627075
Validation loss: 1.9495915700030584

Epoch: 5| Step: 7
Training loss: 1.872955083847046
Validation loss: 1.9688461903602845

Epoch: 5| Step: 8
Training loss: 1.981894850730896
Validation loss: 1.9539034276880243

Epoch: 5| Step: 9
Training loss: 2.5740129947662354
Validation loss: 1.9686447830610379

Epoch: 5| Step: 10
Training loss: 2.0434625148773193
Validation loss: 1.9664791284068939

Epoch: 75| Step: 0
Training loss: 1.9371337890625
Validation loss: 1.9632633091301046

Epoch: 5| Step: 1
Training loss: 2.471259593963623
Validation loss: 1.9663569260669012

Epoch: 5| Step: 2
Training loss: 2.1253905296325684
Validation loss: 1.9773520013337493

Epoch: 5| Step: 3
Training loss: 2.6083195209503174
Validation loss: 1.9707488654762186

Epoch: 5| Step: 4
Training loss: 2.18979549407959
Validation loss: 1.957333049466533

Epoch: 5| Step: 5
Training loss: 2.025183916091919
Validation loss: 1.9751385411908549

Epoch: 5| Step: 6
Training loss: 2.339707851409912
Validation loss: 1.9715613165209371

Epoch: 5| Step: 7
Training loss: 2.0778698921203613
Validation loss: 1.9748386695820799

Epoch: 5| Step: 8
Training loss: 2.322061538696289
Validation loss: 1.9752991994222004

Epoch: 5| Step: 9
Training loss: 2.3038840293884277
Validation loss: 1.9745309481056788

Epoch: 5| Step: 10
Training loss: 2.2505364418029785
Validation loss: 1.964065336411999

Epoch: 76| Step: 0
Training loss: 2.04960298538208
Validation loss: 1.9661979162564842

Epoch: 5| Step: 1
Training loss: 1.9878530502319336
Validation loss: 1.9702214335882535

Epoch: 5| Step: 2
Training loss: 2.233541488647461
Validation loss: 1.9805583274492653

Epoch: 5| Step: 3
Training loss: 2.7613437175750732
Validation loss: 1.962347927913871

Epoch: 5| Step: 4
Training loss: 1.9396026134490967
Validation loss: 1.9679547817476335

Epoch: 5| Step: 5
Training loss: 2.1642022132873535
Validation loss: 1.9627618840945664

Epoch: 5| Step: 6
Training loss: 2.457610607147217
Validation loss: 1.9711335756445443

Epoch: 5| Step: 7
Training loss: 1.46512770652771
Validation loss: 1.977553277887324

Epoch: 5| Step: 8
Training loss: 2.0179076194763184
Validation loss: 1.9745934945280834

Epoch: 5| Step: 9
Training loss: 2.8577120304107666
Validation loss: 1.9734882680318688

Epoch: 5| Step: 10
Training loss: 2.7998385429382324
Validation loss: 1.9706250647062897

Epoch: 77| Step: 0
Training loss: 2.5615410804748535
Validation loss: 1.9551621393490863

Epoch: 5| Step: 1
Training loss: 2.2198123931884766
Validation loss: 1.9736049969991047

Epoch: 5| Step: 2
Training loss: 2.2723045349121094
Validation loss: 1.9630318021261564

Epoch: 5| Step: 3
Training loss: 2.04557466506958
Validation loss: 1.974702767146531

Epoch: 5| Step: 4
Training loss: 2.437528610229492
Validation loss: 1.9778927577439176

Epoch: 5| Step: 5
Training loss: 2.4998574256896973
Validation loss: 1.9851467122313797

Epoch: 5| Step: 6
Training loss: 2.4297523498535156
Validation loss: 1.9773513527326687

Epoch: 5| Step: 7
Training loss: 2.1551032066345215
Validation loss: 1.987718907735681

Epoch: 5| Step: 8
Training loss: 1.9463390111923218
Validation loss: 1.9592578898194015

Epoch: 5| Step: 9
Training loss: 2.034475803375244
Validation loss: 1.9730965193881784

Epoch: 5| Step: 10
Training loss: 1.8633111715316772
Validation loss: 1.9497742575983847

Epoch: 78| Step: 0
Training loss: 2.634880542755127
Validation loss: 1.9556044468315699

Epoch: 5| Step: 1
Training loss: 2.2745730876922607
Validation loss: 1.9719726500972625

Epoch: 5| Step: 2
Training loss: 2.1839675903320312
Validation loss: 1.9471123218536377

Epoch: 5| Step: 3
Training loss: 2.3483099937438965
Validation loss: 1.9637445890775291

Epoch: 5| Step: 4
Training loss: 2.3036587238311768
Validation loss: 1.9481606278368222

Epoch: 5| Step: 5
Training loss: 1.855050802230835
Validation loss: 1.967650403258621

Epoch: 5| Step: 6
Training loss: 2.163520574569702
Validation loss: 1.9383450464535785

Epoch: 5| Step: 7
Training loss: 2.3195114135742188
Validation loss: 1.9541753363865677

Epoch: 5| Step: 8
Training loss: 2.5297493934631348
Validation loss: 1.9600159006734048

Epoch: 5| Step: 9
Training loss: 1.9551883935928345
Validation loss: 1.9590801167231735

Epoch: 5| Step: 10
Training loss: 2.000087261199951
Validation loss: 1.950887890272243

Epoch: 79| Step: 0
Training loss: 2.1302497386932373
Validation loss: 1.9535348133374286

Epoch: 5| Step: 1
Training loss: 1.7846418619155884
Validation loss: 1.953887407497693

Epoch: 5| Step: 2
Training loss: 2.984454870223999
Validation loss: 1.952428012765864

Epoch: 5| Step: 3
Training loss: 1.7100372314453125
Validation loss: 1.9654880390372327

Epoch: 5| Step: 4
Training loss: 2.5499980449676514
Validation loss: 1.9427885099123883

Epoch: 5| Step: 5
Training loss: 1.8557262420654297
Validation loss: 1.9517089141312467

Epoch: 5| Step: 6
Training loss: 2.585491418838501
Validation loss: 1.9503762619469756

Epoch: 5| Step: 7
Training loss: 2.1452372074127197
Validation loss: 1.947530190149943

Epoch: 5| Step: 8
Training loss: 1.8556019067764282
Validation loss: 1.9498901905552033

Epoch: 5| Step: 9
Training loss: 2.4882655143737793
Validation loss: 1.9697945451223722

Epoch: 5| Step: 10
Training loss: 2.565622329711914
Validation loss: 1.9681760457254225

Epoch: 80| Step: 0
Training loss: 2.11993145942688
Validation loss: 1.9443619430706065

Epoch: 5| Step: 1
Training loss: 2.615593433380127
Validation loss: 1.9649619620333436

Epoch: 5| Step: 2
Training loss: 1.9480183124542236
Validation loss: 1.9635064499352568

Epoch: 5| Step: 3
Training loss: 1.7880897521972656
Validation loss: 1.9461330316400016

Epoch: 5| Step: 4
Training loss: 2.4208474159240723
Validation loss: 1.9488645933007682

Epoch: 5| Step: 5
Training loss: 2.531472682952881
Validation loss: 1.9403775943222867

Epoch: 5| Step: 6
Training loss: 1.9663801193237305
Validation loss: 1.9600435046739475

Epoch: 5| Step: 7
Training loss: 2.4055001735687256
Validation loss: 1.9590111112081876

Epoch: 5| Step: 8
Training loss: 2.7390809059143066
Validation loss: 1.968295007623652

Epoch: 5| Step: 9
Training loss: 2.0175442695617676
Validation loss: 1.9546679732620076

Epoch: 5| Step: 10
Training loss: 1.968651294708252
Validation loss: 1.9590135966577837

Epoch: 81| Step: 0
Training loss: 1.8158038854599
Validation loss: 1.969693591517787

Epoch: 5| Step: 1
Training loss: 2.4219515323638916
Validation loss: 1.947032343956732

Epoch: 5| Step: 2
Training loss: 2.7771565914154053
Validation loss: 1.941376925796591

Epoch: 5| Step: 3
Training loss: 1.9005546569824219
Validation loss: 1.9390077437123945

Epoch: 5| Step: 4
Training loss: 2.3484668731689453
Validation loss: 1.9486418334386681

Epoch: 5| Step: 5
Training loss: 2.269071340560913
Validation loss: 1.9623188164926344

Epoch: 5| Step: 6
Training loss: 2.126509428024292
Validation loss: 1.9726811916597429

Epoch: 5| Step: 7
Training loss: 2.173595428466797
Validation loss: 1.9411772361365698

Epoch: 5| Step: 8
Training loss: 1.9578005075454712
Validation loss: 1.9682227232122933

Epoch: 5| Step: 9
Training loss: 2.3568034172058105
Validation loss: 1.9495679140090942

Epoch: 5| Step: 10
Training loss: 2.2717926502227783
Validation loss: 1.9674552691880094

Epoch: 82| Step: 0
Training loss: 2.2308859825134277
Validation loss: 1.9581319657705163

Epoch: 5| Step: 1
Training loss: 1.5758681297302246
Validation loss: 1.9710256002282585

Epoch: 5| Step: 2
Training loss: 2.429882049560547
Validation loss: 1.9592813445675759

Epoch: 5| Step: 3
Training loss: 1.9306795597076416
Validation loss: 1.9790632288943055

Epoch: 5| Step: 4
Training loss: 2.1654651165008545
Validation loss: 1.9667793525162565

Epoch: 5| Step: 5
Training loss: 2.385099411010742
Validation loss: 1.9846925722655429

Epoch: 5| Step: 6
Training loss: 1.797454595565796
Validation loss: 1.9889677237438899

Epoch: 5| Step: 7
Training loss: 2.6589252948760986
Validation loss: 1.982307263599929

Epoch: 5| Step: 8
Training loss: 2.2169528007507324
Validation loss: 1.9874208511844758

Epoch: 5| Step: 9
Training loss: 2.6536285877227783
Validation loss: 1.983194520396571

Epoch: 5| Step: 10
Training loss: 2.462589740753174
Validation loss: 1.989171648538241

Epoch: 83| Step: 0
Training loss: 2.529938220977783
Validation loss: 1.9953272573409542

Epoch: 5| Step: 1
Training loss: 2.310650587081909
Validation loss: 1.990786203774073

Epoch: 5| Step: 2
Training loss: 2.44254469871521
Validation loss: 1.9873651919826385

Epoch: 5| Step: 3
Training loss: 2.381382465362549
Validation loss: 1.9749825705764115

Epoch: 5| Step: 4
Training loss: 1.874431848526001
Validation loss: 1.97385327277645

Epoch: 5| Step: 5
Training loss: 2.314746379852295
Validation loss: 1.9599775665549821

Epoch: 5| Step: 6
Training loss: 1.9191462993621826
Validation loss: 1.956147720736842

Epoch: 5| Step: 7
Training loss: 2.670464515686035
Validation loss: 1.984649291602514

Epoch: 5| Step: 8
Training loss: 1.5252336263656616
Validation loss: 1.966823144625592

Epoch: 5| Step: 9
Training loss: 2.4485626220703125
Validation loss: 1.9580352434547998

Epoch: 5| Step: 10
Training loss: 2.057098150253296
Validation loss: 1.9756145003021404

Epoch: 84| Step: 0
Training loss: 2.5021960735321045
Validation loss: 1.9464779361601798

Epoch: 5| Step: 1
Training loss: 2.242495059967041
Validation loss: 1.9438602847437705

Epoch: 5| Step: 2
Training loss: 1.7756540775299072
Validation loss: 1.971221213699669

Epoch: 5| Step: 3
Training loss: 2.0027999877929688
Validation loss: 1.9588735295880226

Epoch: 5| Step: 4
Training loss: 1.7378126382827759
Validation loss: 1.9846445514309792

Epoch: 5| Step: 5
Training loss: 2.655217409133911
Validation loss: 1.9647971968497

Epoch: 5| Step: 6
Training loss: 2.537865161895752
Validation loss: 1.968434755520154

Epoch: 5| Step: 7
Training loss: 2.1151533126831055
Validation loss: 1.959374366268035

Epoch: 5| Step: 8
Training loss: 2.4302456378936768
Validation loss: 1.9799527275946833

Epoch: 5| Step: 9
Training loss: 2.059279203414917
Validation loss: 1.991411555197931

Epoch: 5| Step: 10
Training loss: 2.0854928493499756
Validation loss: 1.9749067098863664

Epoch: 85| Step: 0
Training loss: 2.680163860321045
Validation loss: 1.9533238539131739

Epoch: 5| Step: 1
Training loss: 2.295480251312256
Validation loss: 1.9525415346186648

Epoch: 5| Step: 2
Training loss: 1.9665066003799438
Validation loss: 1.967335142115111

Epoch: 5| Step: 3
Training loss: 2.230553150177002
Validation loss: 1.9529360725033669

Epoch: 5| Step: 4
Training loss: 2.249950647354126
Validation loss: 1.9548067200568415

Epoch: 5| Step: 5
Training loss: 2.1772968769073486
Validation loss: 1.9514017951103948

Epoch: 5| Step: 6
Training loss: 1.9272228479385376
Validation loss: 1.9606688278977589

Epoch: 5| Step: 7
Training loss: 2.0669491291046143
Validation loss: 1.9640468230811499

Epoch: 5| Step: 8
Training loss: 2.55370831489563
Validation loss: 1.9672119386734501

Epoch: 5| Step: 9
Training loss: 2.109963893890381
Validation loss: 1.9664119315403763

Epoch: 5| Step: 10
Training loss: 2.0200579166412354
Validation loss: 1.9640715276041338

Epoch: 86| Step: 0
Training loss: 1.9534971714019775
Validation loss: 1.9629246214384675

Epoch: 5| Step: 1
Training loss: 1.7035995721817017
Validation loss: 1.968340084116946

Epoch: 5| Step: 2
Training loss: 2.428143262863159
Validation loss: 1.9578766258814002

Epoch: 5| Step: 3
Training loss: 2.0844340324401855
Validation loss: 1.9454640444888864

Epoch: 5| Step: 4
Training loss: 2.2293829917907715
Validation loss: 1.9644576375202467

Epoch: 5| Step: 5
Training loss: 2.042006492614746
Validation loss: 1.9594660459026214

Epoch: 5| Step: 6
Training loss: 1.8042466640472412
Validation loss: 1.9500125787591422

Epoch: 5| Step: 7
Training loss: 2.2444167137145996
Validation loss: 1.9614907080127346

Epoch: 5| Step: 8
Training loss: 2.117295265197754
Validation loss: 1.9418835614317207

Epoch: 5| Step: 9
Training loss: 2.8689112663269043
Validation loss: 1.9579070075865714

Epoch: 5| Step: 10
Training loss: 2.639768600463867
Validation loss: 1.9527407743597542

Epoch: 87| Step: 0
Training loss: 1.994956374168396
Validation loss: 1.9605072185557375

Epoch: 5| Step: 1
Training loss: 2.3111071586608887
Validation loss: 1.9595351616541545

Epoch: 5| Step: 2
Training loss: 1.9458858966827393
Validation loss: 1.9524006484657206

Epoch: 5| Step: 3
Training loss: 2.5341718196868896
Validation loss: 1.9807321307479695

Epoch: 5| Step: 4
Training loss: 2.364865779876709
Validation loss: 1.9547552216437556

Epoch: 5| Step: 5
Training loss: 2.222597599029541
Validation loss: 1.9735281646892588

Epoch: 5| Step: 6
Training loss: 1.979819893836975
Validation loss: 1.9789527693102438

Epoch: 5| Step: 7
Training loss: 2.0158705711364746
Validation loss: 1.9695312028290124

Epoch: 5| Step: 8
Training loss: 2.2241361141204834
Validation loss: 1.9852944830412507

Epoch: 5| Step: 9
Training loss: 2.3292431831359863
Validation loss: 1.9710737928267448

Epoch: 5| Step: 10
Training loss: 2.3244807720184326
Validation loss: 1.9690186246748893

Epoch: 88| Step: 0
Training loss: 1.9954578876495361
Validation loss: 1.9671771013608543

Epoch: 5| Step: 1
Training loss: 2.2887825965881348
Validation loss: 1.970502967475563

Epoch: 5| Step: 2
Training loss: 2.211920976638794
Validation loss: 1.9751768535183323

Epoch: 5| Step: 3
Training loss: 2.2122015953063965
Validation loss: 1.9649363730543403

Epoch: 5| Step: 4
Training loss: 2.606201648712158
Validation loss: 1.9825207802557177

Epoch: 5| Step: 5
Training loss: 1.6873000860214233
Validation loss: 1.9961997078311058

Epoch: 5| Step: 6
Training loss: 1.8854553699493408
Validation loss: 1.9916023105703375

Epoch: 5| Step: 7
Training loss: 2.986119270324707
Validation loss: 1.9776499348302041

Epoch: 5| Step: 8
Training loss: 2.3349921703338623
Validation loss: 1.9796021523014191

Epoch: 5| Step: 9
Training loss: 2.0815606117248535
Validation loss: 1.969200099668195

Epoch: 5| Step: 10
Training loss: 1.8084897994995117
Validation loss: 1.9846881922855173

Epoch: 89| Step: 0
Training loss: 2.2651028633117676
Validation loss: 1.9652377085019184

Epoch: 5| Step: 1
Training loss: 2.2619171142578125
Validation loss: 1.9808860619862874

Epoch: 5| Step: 2
Training loss: 1.9144264459609985
Validation loss: 1.969035365248239

Epoch: 5| Step: 3
Training loss: 2.1368517875671387
Validation loss: 1.9633952904773015

Epoch: 5| Step: 4
Training loss: 2.5329489707946777
Validation loss: 1.9556224858889015

Epoch: 5| Step: 5
Training loss: 2.7093539237976074
Validation loss: 1.9533569607683408

Epoch: 5| Step: 6
Training loss: 2.038125514984131
Validation loss: 1.9565003879608647

Epoch: 5| Step: 7
Training loss: 2.2972381114959717
Validation loss: 1.9363660222740584

Epoch: 5| Step: 8
Training loss: 1.6508090496063232
Validation loss: 1.9599874916897024

Epoch: 5| Step: 9
Training loss: 1.9897916316986084
Validation loss: 1.9708976732787264

Epoch: 5| Step: 10
Training loss: 2.2740535736083984
Validation loss: 1.9640365518549436

Epoch: 90| Step: 0
Training loss: 2.541351556777954
Validation loss: 1.954457934184741

Epoch: 5| Step: 1
Training loss: 1.6224782466888428
Validation loss: 1.9707543849945068

Epoch: 5| Step: 2
Training loss: 2.7364132404327393
Validation loss: 1.9687738200669647

Epoch: 5| Step: 3
Training loss: 2.3126132488250732
Validation loss: 1.9524452532491376

Epoch: 5| Step: 4
Training loss: 1.9544464349746704
Validation loss: 1.9630393597387499

Epoch: 5| Step: 5
Training loss: 2.369483470916748
Validation loss: 1.9785653416828444

Epoch: 5| Step: 6
Training loss: 2.1850695610046387
Validation loss: 1.9777816854497439

Epoch: 5| Step: 7
Training loss: 2.613900899887085
Validation loss: 1.9704718359055058

Epoch: 5| Step: 8
Training loss: 1.611952543258667
Validation loss: 1.9505182543108541

Epoch: 5| Step: 9
Training loss: 2.167573928833008
Validation loss: 1.9701293642802904

Epoch: 5| Step: 10
Training loss: 1.951048493385315
Validation loss: 1.962230666991203

Epoch: 91| Step: 0
Training loss: 2.1578714847564697
Validation loss: 1.9504317083666403

Epoch: 5| Step: 1
Training loss: 1.8628740310668945
Validation loss: 1.9696018426649031

Epoch: 5| Step: 2
Training loss: 1.9003794193267822
Validation loss: 1.9673508469776442

Epoch: 5| Step: 3
Training loss: 2.114351987838745
Validation loss: 1.9703088960339945

Epoch: 5| Step: 4
Training loss: 2.570655345916748
Validation loss: 1.9575599675537438

Epoch: 5| Step: 5
Training loss: 2.4536447525024414
Validation loss: 1.965014039829213

Epoch: 5| Step: 6
Training loss: 2.458519458770752
Validation loss: 1.9304223855336506

Epoch: 5| Step: 7
Training loss: 2.317023992538452
Validation loss: 1.965405971773209

Epoch: 5| Step: 8
Training loss: 2.4974241256713867
Validation loss: 1.9457016747484925

Epoch: 5| Step: 9
Training loss: 2.143437623977661
Validation loss: 1.9436963527433333

Epoch: 5| Step: 10
Training loss: 1.5940576791763306
Validation loss: 1.964467845937257

Epoch: 92| Step: 0
Training loss: 1.964482307434082
Validation loss: 1.9581734403487174

Epoch: 5| Step: 1
Training loss: 2.0115983486175537
Validation loss: 1.9675752065515006

Epoch: 5| Step: 2
Training loss: 2.4727401733398438
Validation loss: 1.9589684676098567

Epoch: 5| Step: 3
Training loss: 2.0006661415100098
Validation loss: 1.9539388277197396

Epoch: 5| Step: 4
Training loss: 2.261631488800049
Validation loss: 1.9709490858098513

Epoch: 5| Step: 5
Training loss: 2.55521821975708
Validation loss: 1.9731696933828375

Epoch: 5| Step: 6
Training loss: 2.806516170501709
Validation loss: 1.9701094768380607

Epoch: 5| Step: 7
Training loss: 2.1647162437438965
Validation loss: 1.9772169602814542

Epoch: 5| Step: 8
Training loss: 2.2469613552093506
Validation loss: 1.9674227442792667

Epoch: 5| Step: 9
Training loss: 1.458412766456604
Validation loss: 1.9910881788499895

Epoch: 5| Step: 10
Training loss: 2.1010477542877197
Validation loss: 1.9769961449407762

Epoch: 93| Step: 0
Training loss: 2.0178720951080322
Validation loss: 1.9817595071690057

Epoch: 5| Step: 1
Training loss: 1.8579479455947876
Validation loss: 1.980363968879946

Epoch: 5| Step: 2
Training loss: 2.226853132247925
Validation loss: 1.9735744666027766

Epoch: 5| Step: 3
Training loss: 2.1215076446533203
Validation loss: 1.959578698681247

Epoch: 5| Step: 4
Training loss: 2.301318645477295
Validation loss: 1.9613963429645827

Epoch: 5| Step: 5
Training loss: 2.2869277000427246
Validation loss: 1.964123741272957

Epoch: 5| Step: 6
Training loss: 2.332965850830078
Validation loss: 1.96214384161016

Epoch: 5| Step: 7
Training loss: 2.504136562347412
Validation loss: 1.9681052930893437

Epoch: 5| Step: 8
Training loss: 2.008538246154785
Validation loss: 1.957682155793713

Epoch: 5| Step: 9
Training loss: 2.14332914352417
Validation loss: 1.9621594951998802

Epoch: 5| Step: 10
Training loss: 2.253791570663452
Validation loss: 1.9564168427580146

Epoch: 94| Step: 0
Training loss: 1.9803917407989502
Validation loss: 1.9702663998450003

Epoch: 5| Step: 1
Training loss: 2.0020718574523926
Validation loss: 1.9693993394092848

Epoch: 5| Step: 2
Training loss: 1.9587913751602173
Validation loss: 1.9754783363752468

Epoch: 5| Step: 3
Training loss: 1.8380272388458252
Validation loss: 1.9553188662375174

Epoch: 5| Step: 4
Training loss: 2.672842502593994
Validation loss: 1.956528332925612

Epoch: 5| Step: 5
Training loss: 2.0345633029937744
Validation loss: 1.9876639381531747

Epoch: 5| Step: 6
Training loss: 1.9826908111572266
Validation loss: 1.9642460705131612

Epoch: 5| Step: 7
Training loss: 2.303724765777588
Validation loss: 1.9571232718806113

Epoch: 5| Step: 8
Training loss: 2.1065051555633545
Validation loss: 1.9523971631962767

Epoch: 5| Step: 9
Training loss: 2.8203787803649902
Validation loss: 1.9737818010391728

Epoch: 5| Step: 10
Training loss: 2.5144331455230713
Validation loss: 1.9657190358766945

Epoch: 95| Step: 0
Training loss: 2.4612090587615967
Validation loss: 1.9566983048633864

Epoch: 5| Step: 1
Training loss: 1.9653247594833374
Validation loss: 1.945743312117874

Epoch: 5| Step: 2
Training loss: 2.305933713912964
Validation loss: 1.9492598938685592

Epoch: 5| Step: 3
Training loss: 2.589115619659424
Validation loss: 1.9665070477352347

Epoch: 5| Step: 4
Training loss: 2.187167167663574
Validation loss: 1.9293682805953487

Epoch: 5| Step: 5
Training loss: 2.255113363265991
Validation loss: 1.9495820947872695

Epoch: 5| Step: 6
Training loss: 2.098292112350464
Validation loss: 1.9462410455108972

Epoch: 5| Step: 7
Training loss: 1.9881114959716797
Validation loss: 1.9359379993971957

Epoch: 5| Step: 8
Training loss: 2.168795347213745
Validation loss: 1.9580035030200917

Epoch: 5| Step: 9
Training loss: 1.9603002071380615
Validation loss: 1.947764414612965

Epoch: 5| Step: 10
Training loss: 2.0345985889434814
Validation loss: 1.9325767922145065

Epoch: 96| Step: 0
Training loss: 1.974514365196228
Validation loss: 1.9338854410315072

Epoch: 5| Step: 1
Training loss: 2.0558388233184814
Validation loss: 1.9440044164657593

Epoch: 5| Step: 2
Training loss: 2.1968510150909424
Validation loss: 1.9535709657976705

Epoch: 5| Step: 3
Training loss: 1.9779131412506104
Validation loss: 1.9547119140625

Epoch: 5| Step: 4
Training loss: 1.925183892250061
Validation loss: 1.9593009141183668

Epoch: 5| Step: 5
Training loss: 1.7835391759872437
Validation loss: 1.9569835509023359

Epoch: 5| Step: 6
Training loss: 2.322345733642578
Validation loss: 1.950404208193543

Epoch: 5| Step: 7
Training loss: 2.5226998329162598
Validation loss: 1.963974480987877

Epoch: 5| Step: 8
Training loss: 2.2349495887756348
Validation loss: 1.9668767067693895

Epoch: 5| Step: 9
Training loss: 2.531052589416504
Validation loss: 1.967419429491925

Epoch: 5| Step: 10
Training loss: 2.5374186038970947
Validation loss: 1.9485737431433894

Epoch: 97| Step: 0
Training loss: 2.1349165439605713
Validation loss: 1.9520543903432868

Epoch: 5| Step: 1
Training loss: 2.1139655113220215
Validation loss: 1.9637714175767795

Epoch: 5| Step: 2
Training loss: 1.545074462890625
Validation loss: 1.962459280926694

Epoch: 5| Step: 3
Training loss: 2.34635329246521
Validation loss: 1.9592155769307127

Epoch: 5| Step: 4
Training loss: 2.4718496799468994
Validation loss: 1.9697864132542764

Epoch: 5| Step: 5
Training loss: 2.3110220432281494
Validation loss: 1.97847278400134

Epoch: 5| Step: 6
Training loss: 2.3227882385253906
Validation loss: 1.9785162428373932

Epoch: 5| Step: 7
Training loss: 2.349323272705078
Validation loss: 1.9559111492608183

Epoch: 5| Step: 8
Training loss: 2.1961662769317627
Validation loss: 1.9735352954556864

Epoch: 5| Step: 9
Training loss: 2.0018115043640137
Validation loss: 1.9731439390490133

Epoch: 5| Step: 10
Training loss: 2.0675344467163086
Validation loss: 1.977805515771271

Epoch: 98| Step: 0
Training loss: 2.189544200897217
Validation loss: 1.9807028770446777

Epoch: 5| Step: 1
Training loss: 2.4014065265655518
Validation loss: 1.9811429515961678

Epoch: 5| Step: 2
Training loss: 1.8531204462051392
Validation loss: 1.9706220267921366

Epoch: 5| Step: 3
Training loss: 2.250684976577759
Validation loss: 1.9495679819455711

Epoch: 5| Step: 4
Training loss: 2.2630796432495117
Validation loss: 1.958120289669242

Epoch: 5| Step: 5
Training loss: 2.2040207386016846
Validation loss: 1.9825703738838114

Epoch: 5| Step: 6
Training loss: 2.1299006938934326
Validation loss: 1.971484189392418

Epoch: 5| Step: 7
Training loss: 2.469160795211792
Validation loss: 1.9614184056558917

Epoch: 5| Step: 8
Training loss: 2.011669874191284
Validation loss: 1.9781181530285907

Epoch: 5| Step: 9
Training loss: 2.0817389488220215
Validation loss: 1.9634902169627528

Epoch: 5| Step: 10
Training loss: 2.013458728790283
Validation loss: 1.9549496968587239

Epoch: 99| Step: 0
Training loss: 1.9731523990631104
Validation loss: 1.951373637363475

Epoch: 5| Step: 1
Training loss: 2.469783306121826
Validation loss: 1.9797686838334607

Epoch: 5| Step: 2
Training loss: 2.5275933742523193
Validation loss: 1.9615206782535841

Epoch: 5| Step: 3
Training loss: 2.0328755378723145
Validation loss: 1.9625781505338606

Epoch: 5| Step: 4
Training loss: 2.3018100261688232
Validation loss: 1.9720897905288204

Epoch: 5| Step: 5
Training loss: 2.002148389816284
Validation loss: 1.9496976995980868

Epoch: 5| Step: 6
Training loss: 2.277102470397949
Validation loss: 1.9412357691795594

Epoch: 5| Step: 7
Training loss: 1.7762715816497803
Validation loss: 1.947695352697885

Epoch: 5| Step: 8
Training loss: 2.1199452877044678
Validation loss: 1.9595413746372345

Epoch: 5| Step: 9
Training loss: 1.966880440711975
Validation loss: 1.9566831229835429

Epoch: 5| Step: 10
Training loss: 2.556265354156494
Validation loss: 1.9573830827589958

Epoch: 100| Step: 0
Training loss: 1.7658029794692993
Validation loss: 1.953519393039006

Epoch: 5| Step: 1
Training loss: 2.12101674079895
Validation loss: 1.9431663738783969

Epoch: 5| Step: 2
Training loss: 2.2147936820983887
Validation loss: 1.9478441951095418

Epoch: 5| Step: 3
Training loss: 1.7482643127441406
Validation loss: 1.9645111150639032

Epoch: 5| Step: 4
Training loss: 2.2734405994415283
Validation loss: 1.9531490495128017

Epoch: 5| Step: 5
Training loss: 2.6987714767456055
Validation loss: 1.985426910461918

Epoch: 5| Step: 6
Training loss: 1.953046441078186
Validation loss: 1.9798484335663498

Epoch: 5| Step: 7
Training loss: 1.4098777770996094
Validation loss: 1.9733595284082557

Epoch: 5| Step: 8
Training loss: 2.40126371383667
Validation loss: 1.97335801329664

Epoch: 5| Step: 9
Training loss: 3.0059309005737305
Validation loss: 1.9938139338647165

Epoch: 5| Step: 10
Training loss: 2.2758636474609375
Validation loss: 1.9940094370995798

Epoch: 101| Step: 0
Training loss: 2.2044663429260254
Validation loss: 2.0002860202584216

Epoch: 5| Step: 1
Training loss: 2.612496852874756
Validation loss: 1.9789966665288454

Epoch: 5| Step: 2
Training loss: 1.6753708124160767
Validation loss: 1.981666629032422

Epoch: 5| Step: 3
Training loss: 1.945098876953125
Validation loss: 1.9946518380154845

Epoch: 5| Step: 4
Training loss: 2.5123322010040283
Validation loss: 1.9952274445564515

Epoch: 5| Step: 5
Training loss: 1.7480719089508057
Validation loss: 1.9899996993362263

Epoch: 5| Step: 6
Training loss: 2.0038299560546875
Validation loss: 2.0236954355752594

Epoch: 5| Step: 7
Training loss: 2.845141887664795
Validation loss: 1.9929311301118584

Epoch: 5| Step: 8
Training loss: 1.9035488367080688
Validation loss: 2.01025100164516

Epoch: 5| Step: 9
Training loss: 2.2548744678497314
Validation loss: 1.9997565310488465

Epoch: 5| Step: 10
Training loss: 2.1689486503601074
Validation loss: 1.976965529944307

Epoch: 102| Step: 0
Training loss: 2.483786106109619
Validation loss: 1.982658568248954

Epoch: 5| Step: 1
Training loss: 1.699058175086975
Validation loss: 1.9773497376390683

Epoch: 5| Step: 2
Training loss: 2.3071818351745605
Validation loss: 1.9761180903321953

Epoch: 5| Step: 3
Training loss: 2.3088722229003906
Validation loss: 1.9770634020528486

Epoch: 5| Step: 4
Training loss: 2.3589565753936768
Validation loss: 1.9760326775171424

Epoch: 5| Step: 5
Training loss: 2.0142159461975098
Validation loss: 1.9460515873406523

Epoch: 5| Step: 6
Training loss: 2.266575574874878
Validation loss: 1.9482602714210429

Epoch: 5| Step: 7
Training loss: 1.8079532384872437
Validation loss: 1.940449240387127

Epoch: 5| Step: 8
Training loss: 2.2990965843200684
Validation loss: 1.9564133805613364

Epoch: 5| Step: 9
Training loss: 2.0598723888397217
Validation loss: 1.9492490471050303

Epoch: 5| Step: 10
Training loss: 2.29470157623291
Validation loss: 1.9432621771289456

Epoch: 103| Step: 0
Training loss: 2.0007224082946777
Validation loss: 1.9637278254314134

Epoch: 5| Step: 1
Training loss: 1.7605006694793701
Validation loss: 1.9379068497688539

Epoch: 5| Step: 2
Training loss: 2.17750883102417
Validation loss: 1.9640269100025136

Epoch: 5| Step: 3
Training loss: 2.630153179168701
Validation loss: 1.9617267244605607

Epoch: 5| Step: 4
Training loss: 2.3711204528808594
Validation loss: 1.9479412160893923

Epoch: 5| Step: 5
Training loss: 2.187809467315674
Validation loss: 1.9636902975779709

Epoch: 5| Step: 6
Training loss: 2.14469575881958
Validation loss: 1.9562456056635866

Epoch: 5| Step: 7
Training loss: 1.8178056478500366
Validation loss: 1.9537142143454602

Epoch: 5| Step: 8
Training loss: 2.5436179637908936
Validation loss: 1.9421392999669558

Epoch: 5| Step: 9
Training loss: 1.9317219257354736
Validation loss: 1.9554725000935216

Epoch: 5| Step: 10
Training loss: 2.304097890853882
Validation loss: 1.978384784472886

Epoch: 104| Step: 0
Training loss: 2.763324022293091
Validation loss: 1.9632920949689803

Epoch: 5| Step: 1
Training loss: 2.348863124847412
Validation loss: 1.965161508129489

Epoch: 5| Step: 2
Training loss: 1.5780792236328125
Validation loss: 1.9585847239340506

Epoch: 5| Step: 3
Training loss: 2.0917611122131348
Validation loss: 1.966640337820976

Epoch: 5| Step: 4
Training loss: 2.079132080078125
Validation loss: 1.9868045981212328

Epoch: 5| Step: 5
Training loss: 2.7180256843566895
Validation loss: 1.9951979473072996

Epoch: 5| Step: 6
Training loss: 1.3788553476333618
Validation loss: 2.006033376980853

Epoch: 5| Step: 7
Training loss: 2.3749778270721436
Validation loss: 2.0003401361485964

Epoch: 5| Step: 8
Training loss: 2.207850456237793
Validation loss: 1.987453217147499

Epoch: 5| Step: 9
Training loss: 1.988827109336853
Validation loss: 1.9973058982561993

Epoch: 5| Step: 10
Training loss: 2.167523145675659
Validation loss: 1.9785838357863887

Epoch: 105| Step: 0
Training loss: 2.190250873565674
Validation loss: 1.9893184708010765

Epoch: 5| Step: 1
Training loss: 2.4869167804718018
Validation loss: 1.9921955857225644

Epoch: 5| Step: 2
Training loss: 2.236170530319214
Validation loss: 1.978363352437173

Epoch: 5| Step: 3
Training loss: 1.9316236972808838
Validation loss: 1.9903928015821724

Epoch: 5| Step: 4
Training loss: 1.938694953918457
Validation loss: 1.98342647347399

Epoch: 5| Step: 5
Training loss: 2.3064944744110107
Validation loss: 1.99255548625864

Epoch: 5| Step: 6
Training loss: 2.567908763885498
Validation loss: 1.989649970044372

Epoch: 5| Step: 7
Training loss: 1.9887298345565796
Validation loss: 2.0039570331573486

Epoch: 5| Step: 8
Training loss: 2.0179972648620605
Validation loss: 1.9953623984449653

Epoch: 5| Step: 9
Training loss: 2.023284435272217
Validation loss: 2.0057816813069005

Epoch: 5| Step: 10
Training loss: 2.0656614303588867
Validation loss: 1.9768468205646803

Epoch: 106| Step: 0
Training loss: 2.3680336475372314
Validation loss: 1.9691846011787333

Epoch: 5| Step: 1
Training loss: 2.337102174758911
Validation loss: 1.9743629655530375

Epoch: 5| Step: 2
Training loss: 2.325425624847412
Validation loss: 1.9571443373157131

Epoch: 5| Step: 3
Training loss: 1.6679937839508057
Validation loss: 1.96154034778636

Epoch: 5| Step: 4
Training loss: 2.287036180496216
Validation loss: 1.9898444657684655

Epoch: 5| Step: 5
Training loss: 2.2407472133636475
Validation loss: 1.9798502242693337

Epoch: 5| Step: 6
Training loss: 2.2154746055603027
Validation loss: 1.969515481302815

Epoch: 5| Step: 7
Training loss: 1.9647306203842163
Validation loss: 1.9652966530092302

Epoch: 5| Step: 8
Training loss: 1.9372278451919556
Validation loss: 1.9759295999362905

Epoch: 5| Step: 9
Training loss: 2.241722822189331
Validation loss: 1.9633282474292222

Epoch: 5| Step: 10
Training loss: 2.0235347747802734
Validation loss: 1.9572388100367721

Epoch: 107| Step: 0
Training loss: 2.1458749771118164
Validation loss: 1.9549022938615532

Epoch: 5| Step: 1
Training loss: 2.5037684440612793
Validation loss: 1.9783401873803907

Epoch: 5| Step: 2
Training loss: 2.004624843597412
Validation loss: 1.9604860787750573

Epoch: 5| Step: 3
Training loss: 1.8314396142959595
Validation loss: 1.9627449076662782

Epoch: 5| Step: 4
Training loss: 2.223944664001465
Validation loss: 1.9520946779558737

Epoch: 5| Step: 5
Training loss: 1.8533008098602295
Validation loss: 1.9438338382269746

Epoch: 5| Step: 6
Training loss: 2.0473029613494873
Validation loss: 1.9646266198927356

Epoch: 5| Step: 7
Training loss: 2.250136375427246
Validation loss: 1.9367645837927376

Epoch: 5| Step: 8
Training loss: 2.3539421558380127
Validation loss: 1.9650209693498508

Epoch: 5| Step: 9
Training loss: 2.500298023223877
Validation loss: 1.9955493455292077

Epoch: 5| Step: 10
Training loss: 1.8185381889343262
Validation loss: 1.952061660828129

Epoch: 108| Step: 0
Training loss: 2.3011488914489746
Validation loss: 1.9820544488968388

Epoch: 5| Step: 1
Training loss: 1.9960390329360962
Validation loss: 1.9775908788045247

Epoch: 5| Step: 2
Training loss: 2.070883274078369
Validation loss: 1.9926980157052316

Epoch: 5| Step: 3
Training loss: 2.065645217895508
Validation loss: 1.985684266654394

Epoch: 5| Step: 4
Training loss: 2.242396593093872
Validation loss: 1.988149909562962

Epoch: 5| Step: 5
Training loss: 2.0910048484802246
Validation loss: 1.9879876605926021

Epoch: 5| Step: 6
Training loss: 2.16929030418396
Validation loss: 1.9826103564231627

Epoch: 5| Step: 7
Training loss: 2.1408896446228027
Validation loss: 1.9947750773481143

Epoch: 5| Step: 8
Training loss: 2.1689789295196533
Validation loss: 1.9838436688146284

Epoch: 5| Step: 9
Training loss: 2.388136625289917
Validation loss: 1.9910889325603363

Epoch: 5| Step: 10
Training loss: 1.8482834100723267
Validation loss: 1.9718478533529467

Epoch: 109| Step: 0
Training loss: 2.5420825481414795
Validation loss: 1.9864072184408865

Epoch: 5| Step: 1
Training loss: 2.372004747390747
Validation loss: 1.987950490367028

Epoch: 5| Step: 2
Training loss: 1.9841388463974
Validation loss: 1.9763587392786497

Epoch: 5| Step: 3
Training loss: 1.6126747131347656
Validation loss: 1.97133836694943

Epoch: 5| Step: 4
Training loss: 2.33992338180542
Validation loss: 1.9623686690484323

Epoch: 5| Step: 5
Training loss: 2.3339993953704834
Validation loss: 1.9770543703468897

Epoch: 5| Step: 6
Training loss: 2.512740135192871
Validation loss: 1.974741699875042

Epoch: 5| Step: 7
Training loss: 2.6260910034179688
Validation loss: 1.98712630169366

Epoch: 5| Step: 8
Training loss: 1.964272141456604
Validation loss: 1.9868962867285616

Epoch: 5| Step: 9
Training loss: 1.7711448669433594
Validation loss: 2.002339134934128

Epoch: 5| Step: 10
Training loss: 1.3798613548278809
Validation loss: 1.973567715255163

Epoch: 110| Step: 0
Training loss: 2.3514060974121094
Validation loss: 1.9818532697616085

Epoch: 5| Step: 1
Training loss: 1.9839134216308594
Validation loss: 1.9751772188371228

Epoch: 5| Step: 2
Training loss: 2.6716909408569336
Validation loss: 1.974812622993223

Epoch: 5| Step: 3
Training loss: 2.0078964233398438
Validation loss: 1.9550231041446808

Epoch: 5| Step: 4
Training loss: 2.0820155143737793
Validation loss: 1.948863030761801

Epoch: 5| Step: 5
Training loss: 2.0303921699523926
Validation loss: 1.9715878143105456

Epoch: 5| Step: 6
Training loss: 2.4260709285736084
Validation loss: 1.9390508308205554

Epoch: 5| Step: 7
Training loss: 2.1323611736297607
Validation loss: 1.944235174886642

Epoch: 5| Step: 8
Training loss: 1.8196792602539062
Validation loss: 1.985755862728242

Epoch: 5| Step: 9
Training loss: 1.9501899480819702
Validation loss: 1.9469593865897066

Epoch: 5| Step: 10
Training loss: 2.0464611053466797
Validation loss: 1.968639918552932

Epoch: 111| Step: 0
Training loss: 1.8847757577896118
Validation loss: 1.9620566803921935

Epoch: 5| Step: 1
Training loss: 2.717862129211426
Validation loss: 1.9533624008137693

Epoch: 5| Step: 2
Training loss: 2.254772186279297
Validation loss: 1.9607946565074306

Epoch: 5| Step: 3
Training loss: 2.1137523651123047
Validation loss: 1.9641822858523297

Epoch: 5| Step: 4
Training loss: 1.908905267715454
Validation loss: 1.9688193913429015

Epoch: 5| Step: 5
Training loss: 1.7869768142700195
Validation loss: 1.9752953616521691

Epoch: 5| Step: 6
Training loss: 2.0623950958251953
Validation loss: 1.9634064166776595

Epoch: 5| Step: 7
Training loss: 1.6721597909927368
Validation loss: 1.9802257668587468

Epoch: 5| Step: 8
Training loss: 1.9756793975830078
Validation loss: 1.970376121100559

Epoch: 5| Step: 9
Training loss: 2.2388272285461426
Validation loss: 1.9709121014482232

Epoch: 5| Step: 10
Training loss: 2.817042350769043
Validation loss: 1.9678190844033354

Epoch: 112| Step: 0
Training loss: 2.2258248329162598
Validation loss: 1.9881539447333223

Epoch: 5| Step: 1
Training loss: 1.7476832866668701
Validation loss: 1.9954584657504995

Epoch: 5| Step: 2
Training loss: 1.9573328495025635
Validation loss: 1.983014488732943

Epoch: 5| Step: 3
Training loss: 2.210477113723755
Validation loss: 1.9975252228398477

Epoch: 5| Step: 4
Training loss: 2.6463632583618164
Validation loss: 1.9813378113572315

Epoch: 5| Step: 5
Training loss: 1.6255590915679932
Validation loss: 1.9870930025654454

Epoch: 5| Step: 6
Training loss: 2.3220925331115723
Validation loss: 2.0126311958477063

Epoch: 5| Step: 7
Training loss: 1.9124982357025146
Validation loss: 2.020621103625144

Epoch: 5| Step: 8
Training loss: 2.426663637161255
Validation loss: 1.984854011125462

Epoch: 5| Step: 9
Training loss: 2.2053799629211426
Validation loss: 1.9752760010380899

Epoch: 5| Step: 10
Training loss: 2.2965245246887207
Validation loss: 1.998216768746735

Epoch: 113| Step: 0
Training loss: 2.1708943843841553
Validation loss: 1.9824743168328398

Epoch: 5| Step: 1
Training loss: 2.451711893081665
Validation loss: 1.9826693022122948

Epoch: 5| Step: 2
Training loss: 2.137411594390869
Validation loss: 1.963382265901053

Epoch: 5| Step: 3
Training loss: 2.0306220054626465
Validation loss: 1.9681158809251682

Epoch: 5| Step: 4
Training loss: 2.0921108722686768
Validation loss: 1.9588363811533938

Epoch: 5| Step: 5
Training loss: 2.594203233718872
Validation loss: 1.984829827021527

Epoch: 5| Step: 6
Training loss: 2.022416591644287
Validation loss: 1.9599499599907988

Epoch: 5| Step: 7
Training loss: 2.275843620300293
Validation loss: 1.9767843856606433

Epoch: 5| Step: 8
Training loss: 2.4483275413513184
Validation loss: 1.9618821041558379

Epoch: 5| Step: 9
Training loss: 1.1815451383590698
Validation loss: 1.948626523376793

Epoch: 5| Step: 10
Training loss: 2.1292333602905273
Validation loss: 1.9736517090951242

Epoch: 114| Step: 0
Training loss: 2.425354242324829
Validation loss: 1.9611851425581082

Epoch: 5| Step: 1
Training loss: 1.6431024074554443
Validation loss: 1.9448089240699686

Epoch: 5| Step: 2
Training loss: 2.123020648956299
Validation loss: 1.9671725803805935

Epoch: 5| Step: 3
Training loss: 1.9460111856460571
Validation loss: 1.9700822458472302

Epoch: 5| Step: 4
Training loss: 2.46797776222229
Validation loss: 1.9785853483343636

Epoch: 5| Step: 5
Training loss: 2.6626007556915283
Validation loss: 1.9752044113733436

Epoch: 5| Step: 6
Training loss: 1.9164402484893799
Validation loss: 1.9757490901536838

Epoch: 5| Step: 7
Training loss: 2.2021706104278564
Validation loss: 2.0019209461827434

Epoch: 5| Step: 8
Training loss: 1.8992068767547607
Validation loss: 1.9985906462515555

Epoch: 5| Step: 9
Training loss: 1.8891611099243164
Validation loss: 1.988172508055164

Epoch: 5| Step: 10
Training loss: 2.329415798187256
Validation loss: 1.9883360824277323

Epoch: 115| Step: 0
Training loss: 1.5683165788650513
Validation loss: 1.9764766000932263

Epoch: 5| Step: 1
Training loss: 2.436335802078247
Validation loss: 1.9993549213614514

Epoch: 5| Step: 2
Training loss: 2.428375720977783
Validation loss: 1.9886457022800241

Epoch: 5| Step: 3
Training loss: 1.7224677801132202
Validation loss: 1.9855829746492448

Epoch: 5| Step: 4
Training loss: 2.1824746131896973
Validation loss: 1.9898734387531076

Epoch: 5| Step: 5
Training loss: 2.0631160736083984
Validation loss: 1.9890050567606443

Epoch: 5| Step: 6
Training loss: 2.3594939708709717
Validation loss: 1.9771537601306874

Epoch: 5| Step: 7
Training loss: 2.0426948070526123
Validation loss: 1.9888797549791233

Epoch: 5| Step: 8
Training loss: 1.8803510665893555
Validation loss: 1.9592382548957743

Epoch: 5| Step: 9
Training loss: 2.180786609649658
Validation loss: 1.982532755021126

Epoch: 5| Step: 10
Training loss: 2.664571762084961
Validation loss: 1.9657816361355525

Epoch: 116| Step: 0
Training loss: 2.092592716217041
Validation loss: 1.98065863245277

Epoch: 5| Step: 1
Training loss: 2.0333926677703857
Validation loss: 1.9696996609369914

Epoch: 5| Step: 2
Training loss: 1.573377251625061
Validation loss: 1.9926330030605357

Epoch: 5| Step: 3
Training loss: 1.8635202646255493
Validation loss: 1.9879927071191932

Epoch: 5| Step: 4
Training loss: 2.309645414352417
Validation loss: 1.996436466452896

Epoch: 5| Step: 5
Training loss: 2.216343879699707
Validation loss: 1.9881389141082764

Epoch: 5| Step: 6
Training loss: 2.305025100708008
Validation loss: 1.9914894257822344

Epoch: 5| Step: 7
Training loss: 1.9254271984100342
Validation loss: 2.005936127836986

Epoch: 5| Step: 8
Training loss: 2.7314188480377197
Validation loss: 2.0058457543773036

Epoch: 5| Step: 9
Training loss: 2.1445870399475098
Validation loss: 1.9886770889323244

Epoch: 5| Step: 10
Training loss: 2.390118360519409
Validation loss: 1.9851443357365106

Epoch: 117| Step: 0
Training loss: 2.3326191902160645
Validation loss: 1.9622203791013328

Epoch: 5| Step: 1
Training loss: 1.8493282794952393
Validation loss: 1.9788364069436186

Epoch: 5| Step: 2
Training loss: 1.6137481927871704
Validation loss: 1.9795720602876397

Epoch: 5| Step: 3
Training loss: 2.126495838165283
Validation loss: 1.9647076322186379

Epoch: 5| Step: 4
Training loss: 1.6619980335235596
Validation loss: 1.9556828724440707

Epoch: 5| Step: 5
Training loss: 2.2804622650146484
Validation loss: 1.986921174551851

Epoch: 5| Step: 6
Training loss: 2.3440937995910645
Validation loss: 1.9802965066766227

Epoch: 5| Step: 7
Training loss: 1.7989692687988281
Validation loss: 1.9855603133478472

Epoch: 5| Step: 8
Training loss: 2.572230815887451
Validation loss: 1.9726278076889694

Epoch: 5| Step: 9
Training loss: 2.4513955116271973
Validation loss: 1.9814030380659207

Epoch: 5| Step: 10
Training loss: 2.3926279544830322
Validation loss: 1.968908085617968

Epoch: 118| Step: 0
Training loss: 2.0758907794952393
Validation loss: 1.9858106028649114

Epoch: 5| Step: 1
Training loss: 1.840481162071228
Validation loss: 1.9620983151979343

Epoch: 5| Step: 2
Training loss: 2.2011911869049072
Validation loss: 1.9653314031580442

Epoch: 5| Step: 3
Training loss: 1.7994028329849243
Validation loss: 1.953015467172028

Epoch: 5| Step: 4
Training loss: 2.046943187713623
Validation loss: 1.9707718587690783

Epoch: 5| Step: 5
Training loss: 1.4714823961257935
Validation loss: 1.9714678846379763

Epoch: 5| Step: 6
Training loss: 2.338759183883667
Validation loss: 1.9507446468517344

Epoch: 5| Step: 7
Training loss: 3.034794569015503
Validation loss: 1.9572904109954834

Epoch: 5| Step: 8
Training loss: 1.9754180908203125
Validation loss: 1.956496605309107

Epoch: 5| Step: 9
Training loss: 2.8140788078308105
Validation loss: 1.954913511071154

Epoch: 5| Step: 10
Training loss: 1.7361503839492798
Validation loss: 1.9717615291636477

Epoch: 119| Step: 0
Training loss: 2.2723212242126465
Validation loss: 1.969078738202331

Epoch: 5| Step: 1
Training loss: 2.350153923034668
Validation loss: 1.9680376450220745

Epoch: 5| Step: 2
Training loss: 1.6922763586044312
Validation loss: 1.978917621797131

Epoch: 5| Step: 3
Training loss: 2.714108943939209
Validation loss: 1.9504424410481607

Epoch: 5| Step: 4
Training loss: 2.0375120639801025
Validation loss: 1.9658541602473105

Epoch: 5| Step: 5
Training loss: 2.176267147064209
Validation loss: 1.9866297809026574

Epoch: 5| Step: 6
Training loss: 2.2543234825134277
Validation loss: 1.9797957404967277

Epoch: 5| Step: 7
Training loss: 2.002403736114502
Validation loss: 1.9681505900557323

Epoch: 5| Step: 8
Training loss: 1.8800640106201172
Validation loss: 1.9953522143825408

Epoch: 5| Step: 9
Training loss: 1.869126558303833
Validation loss: 1.997913702841728

Epoch: 5| Step: 10
Training loss: 2.0550994873046875
Validation loss: 1.9597791638425601

Epoch: 120| Step: 0
Training loss: 2.247464418411255
Validation loss: 1.995113988076487

Epoch: 5| Step: 1
Training loss: 1.9161840677261353
Validation loss: 2.0087169319070797

Epoch: 5| Step: 2
Training loss: 2.435606002807617
Validation loss: 2.004370548391855

Epoch: 5| Step: 3
Training loss: 1.9820473194122314
Validation loss: 2.0201277399575837

Epoch: 5| Step: 4
Training loss: 2.0867793560028076
Validation loss: 2.022791349759666

Epoch: 5| Step: 5
Training loss: 1.8416801691055298
Validation loss: 1.997409810302078

Epoch: 5| Step: 6
Training loss: 1.9347851276397705
Validation loss: 2.0233548277167865

Epoch: 5| Step: 7
Training loss: 2.169046401977539
Validation loss: 2.007158180718781

Epoch: 5| Step: 8
Training loss: 2.3503031730651855
Validation loss: 2.0274547325667513

Epoch: 5| Step: 9
Training loss: 2.1875109672546387
Validation loss: 1.9959254739105061

Epoch: 5| Step: 10
Training loss: 2.2395272254943848
Validation loss: 2.030888695870676

Epoch: 121| Step: 0
Training loss: 2.0379862785339355
Validation loss: 2.012664835940125

Epoch: 5| Step: 1
Training loss: 1.3718059062957764
Validation loss: 1.9910399272877684

Epoch: 5| Step: 2
Training loss: 1.911014199256897
Validation loss: 2.0130829349640877

Epoch: 5| Step: 3
Training loss: 2.367978096008301
Validation loss: 2.0034271978562876

Epoch: 5| Step: 4
Training loss: 2.1931004524230957
Validation loss: 1.9895962951003865

Epoch: 5| Step: 5
Training loss: 1.8052423000335693
Validation loss: 1.9818009676471833

Epoch: 5| Step: 6
Training loss: 2.2572436332702637
Validation loss: 2.00459683710529

Epoch: 5| Step: 7
Training loss: 2.050602912902832
Validation loss: 1.9632730253281132

Epoch: 5| Step: 8
Training loss: 2.373751163482666
Validation loss: 1.9708104043878534

Epoch: 5| Step: 9
Training loss: 2.372725486755371
Validation loss: 1.9780314045567666

Epoch: 5| Step: 10
Training loss: 2.422060012817383
Validation loss: 1.9870113403566423

Epoch: 122| Step: 0
Training loss: 1.9297202825546265
Validation loss: 1.9699984365893948

Epoch: 5| Step: 1
Training loss: 2.6919219493865967
Validation loss: 1.965948058712867

Epoch: 5| Step: 2
Training loss: 1.9414259195327759
Validation loss: 1.9369275057187645

Epoch: 5| Step: 3
Training loss: 1.4218692779541016
Validation loss: 1.9524794060696837

Epoch: 5| Step: 4
Training loss: 2.112762451171875
Validation loss: 1.9663924581261092

Epoch: 5| Step: 5
Training loss: 1.8362869024276733
Validation loss: 1.9533988416835826

Epoch: 5| Step: 6
Training loss: 2.339740037918091
Validation loss: 1.968790997741043

Epoch: 5| Step: 7
Training loss: 2.038700580596924
Validation loss: 1.98960970294091

Epoch: 5| Step: 8
Training loss: 2.200298309326172
Validation loss: 1.9770719620489305

Epoch: 5| Step: 9
Training loss: 2.6564724445343018
Validation loss: 1.995676512359291

Epoch: 5| Step: 10
Training loss: 1.9394299983978271
Validation loss: 1.9696311643046718

Epoch: 123| Step: 0
Training loss: 1.9574205875396729
Validation loss: 1.9686028893275926

Epoch: 5| Step: 1
Training loss: 1.634581208229065
Validation loss: 1.9791910968801028

Epoch: 5| Step: 2
Training loss: 2.3916096687316895
Validation loss: 1.9725323325844222

Epoch: 5| Step: 3
Training loss: 1.9345653057098389
Validation loss: 1.9705022714471305

Epoch: 5| Step: 4
Training loss: 2.162524938583374
Validation loss: 1.9733917315800984

Epoch: 5| Step: 5
Training loss: 1.9678903818130493
Validation loss: 1.9792806345929381

Epoch: 5| Step: 6
Training loss: 2.467308282852173
Validation loss: 1.97965020133603

Epoch: 5| Step: 7
Training loss: 2.2604403495788574
Validation loss: 1.972574160945031

Epoch: 5| Step: 8
Training loss: 1.8584072589874268
Validation loss: 2.0020366304664203

Epoch: 5| Step: 9
Training loss: 2.0768702030181885
Validation loss: 1.9936931517816359

Epoch: 5| Step: 10
Training loss: 2.4912142753601074
Validation loss: 1.9896415254121185

Epoch: 124| Step: 0
Training loss: 1.8101301193237305
Validation loss: 1.9789628777452695

Epoch: 5| Step: 1
Training loss: 1.8747409582138062
Validation loss: 2.009367853082636

Epoch: 5| Step: 2
Training loss: 1.964058518409729
Validation loss: 2.007787458358272

Epoch: 5| Step: 3
Training loss: 2.665151596069336
Validation loss: 1.976809517029793

Epoch: 5| Step: 4
Training loss: 1.5176408290863037
Validation loss: 1.974650449650262

Epoch: 5| Step: 5
Training loss: 2.0023627281188965
Validation loss: 1.9799079946292344

Epoch: 5| Step: 6
Training loss: 2.150514602661133
Validation loss: 1.9671536273853754

Epoch: 5| Step: 7
Training loss: 2.2875618934631348
Validation loss: 1.965273186724673

Epoch: 5| Step: 8
Training loss: 2.642285108566284
Validation loss: 1.9868978992585213

Epoch: 5| Step: 9
Training loss: 2.386643171310425
Validation loss: 1.9814860513133388

Epoch: 5| Step: 10
Training loss: 1.8338385820388794
Validation loss: 1.9678672898200251

Epoch: 125| Step: 0
Training loss: 1.7920448780059814
Validation loss: 1.9856832834982103

Epoch: 5| Step: 1
Training loss: 1.9114177227020264
Validation loss: 1.9669100264067292

Epoch: 5| Step: 2
Training loss: 2.023237705230713
Validation loss: 1.9695183333530222

Epoch: 5| Step: 3
Training loss: 2.3772823810577393
Validation loss: 1.9877054486223447

Epoch: 5| Step: 4
Training loss: 2.191506862640381
Validation loss: 1.9828244357980707

Epoch: 5| Step: 5
Training loss: 2.4869678020477295
Validation loss: 1.9544430381508284

Epoch: 5| Step: 6
Training loss: 2.052856922149658
Validation loss: 1.9635159251510457

Epoch: 5| Step: 7
Training loss: 2.470930576324463
Validation loss: 1.9418164735199304

Epoch: 5| Step: 8
Training loss: 2.2061574459075928
Validation loss: 1.982871896477156

Epoch: 5| Step: 9
Training loss: 1.98526132106781
Validation loss: 1.9823259794583885

Epoch: 5| Step: 10
Training loss: 1.6829440593719482
Validation loss: 1.9543364919641966

Epoch: 126| Step: 0
Training loss: 1.4196078777313232
Validation loss: 1.9622849700271443

Epoch: 5| Step: 1
Training loss: 1.8428682088851929
Validation loss: 1.9998061785133936

Epoch: 5| Step: 2
Training loss: 2.3763325214385986
Validation loss: 2.008188606590353

Epoch: 5| Step: 3
Training loss: 1.7938514947891235
Validation loss: 1.992020619812832

Epoch: 5| Step: 4
Training loss: 1.6473572254180908
Validation loss: 1.9685156371003838

Epoch: 5| Step: 5
Training loss: 2.4829647541046143
Validation loss: 1.9906254365880003

Epoch: 5| Step: 6
Training loss: 2.187328815460205
Validation loss: 1.96873358116355

Epoch: 5| Step: 7
Training loss: 2.0523922443389893
Validation loss: 1.9579102864829443

Epoch: 5| Step: 8
Training loss: 2.531543016433716
Validation loss: 1.9643193726898522

Epoch: 5| Step: 9
Training loss: 2.176222085952759
Validation loss: 1.9760566770389516

Epoch: 5| Step: 10
Training loss: 2.72930908203125
Validation loss: 1.9840943864596787

Epoch: 127| Step: 0
Training loss: 2.275660991668701
Validation loss: 1.9592351503269647

Epoch: 5| Step: 1
Training loss: 2.498363971710205
Validation loss: 2.0072441972712034

Epoch: 5| Step: 2
Training loss: 2.34883189201355
Validation loss: 1.9728328617670203

Epoch: 5| Step: 3
Training loss: 2.228226661682129
Validation loss: 1.9857556525097098

Epoch: 5| Step: 4
Training loss: 2.197171688079834
Validation loss: 1.9974276596500027

Epoch: 5| Step: 5
Training loss: 1.8066904544830322
Validation loss: 1.999196970334617

Epoch: 5| Step: 6
Training loss: 2.011043071746826
Validation loss: 1.9982310110522854

Epoch: 5| Step: 7
Training loss: 1.8983886241912842
Validation loss: 2.01904692188386

Epoch: 5| Step: 8
Training loss: 1.898982286453247
Validation loss: 1.9982755632810696

Epoch: 5| Step: 9
Training loss: 1.9057010412216187
Validation loss: 1.9828460857432375

Epoch: 5| Step: 10
Training loss: 1.8873921632766724
Validation loss: 1.9849540495103406

Epoch: 128| Step: 0
Training loss: 1.9822895526885986
Validation loss: 1.9803368929893739

Epoch: 5| Step: 1
Training loss: 2.2335586547851562
Validation loss: 1.9720030189842306

Epoch: 5| Step: 2
Training loss: 1.8116390705108643
Validation loss: 1.9866090269498928

Epoch: 5| Step: 3
Training loss: 2.4392364025115967
Validation loss: 1.9968179630976852

Epoch: 5| Step: 4
Training loss: 2.4282264709472656
Validation loss: 2.023385556795264

Epoch: 5| Step: 5
Training loss: 1.806957483291626
Validation loss: 2.0034872985655263

Epoch: 5| Step: 6
Training loss: 1.9023199081420898
Validation loss: 1.9847817241504628

Epoch: 5| Step: 7
Training loss: 1.6965656280517578
Validation loss: 1.9909360242146317

Epoch: 5| Step: 8
Training loss: 2.5287058353424072
Validation loss: 2.0003335322103193

Epoch: 5| Step: 9
Training loss: 2.112321376800537
Validation loss: 1.98886836472378

Epoch: 5| Step: 10
Training loss: 2.206402540206909
Validation loss: 1.9549193305353965

Epoch: 129| Step: 0
Training loss: 1.8566372394561768
Validation loss: 1.9727033363875521

Epoch: 5| Step: 1
Training loss: 1.9439243078231812
Validation loss: 1.9777290769802627

Epoch: 5| Step: 2
Training loss: 2.375615358352661
Validation loss: 1.9687103199702438

Epoch: 5| Step: 3
Training loss: 2.153320789337158
Validation loss: 1.987714821292508

Epoch: 5| Step: 4
Training loss: 1.4087674617767334
Validation loss: 1.9517427682876587

Epoch: 5| Step: 5
Training loss: 2.587555408477783
Validation loss: 1.9697793145333566

Epoch: 5| Step: 6
Training loss: 1.6686222553253174
Validation loss: 1.9807270560213315

Epoch: 5| Step: 7
Training loss: 2.2121548652648926
Validation loss: 1.9789428851937736

Epoch: 5| Step: 8
Training loss: 2.3982837200164795
Validation loss: 1.9815397929119807

Epoch: 5| Step: 9
Training loss: 2.0860931873321533
Validation loss: 1.96871736485471

Epoch: 5| Step: 10
Training loss: 2.4848392009735107
Validation loss: 1.957168185582725

Epoch: 130| Step: 0
Training loss: 2.0100507736206055
Validation loss: 1.9708391402357368

Epoch: 5| Step: 1
Training loss: 2.3943886756896973
Validation loss: 1.952972637709751

Epoch: 5| Step: 2
Training loss: 1.8200763463974
Validation loss: 1.9744336130798503

Epoch: 5| Step: 3
Training loss: 2.1445364952087402
Validation loss: 1.9792908840281989

Epoch: 5| Step: 4
Training loss: 2.1710140705108643
Validation loss: 1.9676019030232583

Epoch: 5| Step: 5
Training loss: 2.4335811138153076
Validation loss: 1.9746354600434661

Epoch: 5| Step: 6
Training loss: 1.531558632850647
Validation loss: 1.9723862960774412

Epoch: 5| Step: 7
Training loss: 2.1948680877685547
Validation loss: 1.9766329462810228

Epoch: 5| Step: 8
Training loss: 2.304220676422119
Validation loss: 1.980876709825249

Epoch: 5| Step: 9
Training loss: 2.3423168659210205
Validation loss: 1.9593776913099392

Epoch: 5| Step: 10
Training loss: 1.723681926727295
Validation loss: 1.9570752061823362

Epoch: 131| Step: 0
Training loss: 1.6807136535644531
Validation loss: 1.9801179375699771

Epoch: 5| Step: 1
Training loss: 1.3863948583602905
Validation loss: 1.976252330246792

Epoch: 5| Step: 2
Training loss: 2.503551721572876
Validation loss: 1.9949014494496007

Epoch: 5| Step: 3
Training loss: 1.8178374767303467
Validation loss: 1.9819290971243253

Epoch: 5| Step: 4
Training loss: 2.0241286754608154
Validation loss: 2.001154743215089

Epoch: 5| Step: 5
Training loss: 2.3429105281829834
Validation loss: 1.991290347550505

Epoch: 5| Step: 6
Training loss: 2.2601072788238525
Validation loss: 1.9793519537935975

Epoch: 5| Step: 7
Training loss: 2.3946564197540283
Validation loss: 2.0022097736276607

Epoch: 5| Step: 8
Training loss: 2.5920538902282715
Validation loss: 1.9982037005885955

Epoch: 5| Step: 9
Training loss: 1.4026038646697998
Validation loss: 2.0004298328071513

Epoch: 5| Step: 10
Training loss: 2.5245721340179443
Validation loss: 1.9961884713942004

Epoch: 132| Step: 0
Training loss: 1.9531389474868774
Validation loss: 2.0020726393627863

Epoch: 5| Step: 1
Training loss: 2.5118815898895264
Validation loss: 2.0034405416057957

Epoch: 5| Step: 2
Training loss: 2.271855115890503
Validation loss: 2.0001253081906225

Epoch: 5| Step: 3
Training loss: 2.0633435249328613
Validation loss: 2.0015435308538456

Epoch: 5| Step: 4
Training loss: 1.9515798091888428
Validation loss: 2.0177565518245903

Epoch: 5| Step: 5
Training loss: 1.7557264566421509
Validation loss: 2.0047488904768422

Epoch: 5| Step: 6
Training loss: 2.0077762603759766
Validation loss: 1.987065335755707

Epoch: 5| Step: 7
Training loss: 1.785030722618103
Validation loss: 1.9937080452519078

Epoch: 5| Step: 8
Training loss: 2.019862651824951
Validation loss: 1.9835547298513434

Epoch: 5| Step: 9
Training loss: 2.5117039680480957
Validation loss: 2.006830579491072

Epoch: 5| Step: 10
Training loss: 2.0998289585113525
Validation loss: 1.9827816332540205

Epoch: 133| Step: 0
Training loss: 2.33882999420166
Validation loss: 1.9812165191096645

Epoch: 5| Step: 1
Training loss: 1.9385734796524048
Validation loss: 1.9887670137548958

Epoch: 5| Step: 2
Training loss: 1.8317838907241821
Validation loss: 1.9577933870336062

Epoch: 5| Step: 3
Training loss: 1.9129890203475952
Validation loss: 1.985240004395926

Epoch: 5| Step: 4
Training loss: 1.9781084060668945
Validation loss: 1.9591587743451517

Epoch: 5| Step: 5
Training loss: 2.392486095428467
Validation loss: 1.964750720608619

Epoch: 5| Step: 6
Training loss: 1.6863971948623657
Validation loss: 1.9680425633666336

Epoch: 5| Step: 7
Training loss: 2.331324577331543
Validation loss: 1.9651068897657498

Epoch: 5| Step: 8
Training loss: 2.050934314727783
Validation loss: 1.9536577091422132

Epoch: 5| Step: 9
Training loss: 2.5526270866394043
Validation loss: 1.9712368211438578

Epoch: 5| Step: 10
Training loss: 1.7977914810180664
Validation loss: 1.985608240609528

Epoch: 134| Step: 0
Training loss: 2.004249095916748
Validation loss: 1.9811387446618849

Epoch: 5| Step: 1
Training loss: 2.1078314781188965
Validation loss: 1.9500080539334206

Epoch: 5| Step: 2
Training loss: 2.3726179599761963
Validation loss: 1.9744079843644173

Epoch: 5| Step: 3
Training loss: 2.7547385692596436
Validation loss: 1.9731444005043275

Epoch: 5| Step: 4
Training loss: 1.8960965871810913
Validation loss: 1.9800715651563419

Epoch: 5| Step: 5
Training loss: 1.5153512954711914
Validation loss: 1.9684537379972395

Epoch: 5| Step: 6
Training loss: 2.292585611343384
Validation loss: 1.9737536291922293

Epoch: 5| Step: 7
Training loss: 1.6273267269134521
Validation loss: 2.0036851744497977

Epoch: 5| Step: 8
Training loss: 2.1355323791503906
Validation loss: 1.9931028222524991

Epoch: 5| Step: 9
Training loss: 2.264029026031494
Validation loss: 1.9853376316767868

Epoch: 5| Step: 10
Training loss: 1.941920280456543
Validation loss: 1.9681282415184924

Epoch: 135| Step: 0
Training loss: 1.9565811157226562
Validation loss: 1.96932646536058

Epoch: 5| Step: 1
Training loss: 2.014667510986328
Validation loss: 2.001531857316212

Epoch: 5| Step: 2
Training loss: 2.273287296295166
Validation loss: 1.9907820814399309

Epoch: 5| Step: 3
Training loss: 2.3522071838378906
Validation loss: 2.007510565942334

Epoch: 5| Step: 4
Training loss: 1.766497015953064
Validation loss: 1.9932682386008642

Epoch: 5| Step: 5
Training loss: 1.9154140949249268
Validation loss: 2.009615631513698

Epoch: 5| Step: 6
Training loss: 2.248730421066284
Validation loss: 1.986635333748274

Epoch: 5| Step: 7
Training loss: 2.0367586612701416
Validation loss: 2.0025621921785417

Epoch: 5| Step: 8
Training loss: 2.6470117568969727
Validation loss: 1.9872180954102547

Epoch: 5| Step: 9
Training loss: 1.5352890491485596
Validation loss: 2.0019694246271604

Epoch: 5| Step: 10
Training loss: 1.9999676942825317
Validation loss: 2.014105490458909

Epoch: 136| Step: 0
Training loss: 1.7760111093521118
Validation loss: 1.9933482113704886

Epoch: 5| Step: 1
Training loss: 1.3558260202407837
Validation loss: 2.013475057899311

Epoch: 5| Step: 2
Training loss: 2.082183361053467
Validation loss: 2.004812973801808

Epoch: 5| Step: 3
Training loss: 2.371983528137207
Validation loss: 1.997411653559695

Epoch: 5| Step: 4
Training loss: 2.4122700691223145
Validation loss: 2.0004580777178527

Epoch: 5| Step: 5
Training loss: 2.2298972606658936
Validation loss: 1.998620633156069

Epoch: 5| Step: 6
Training loss: 1.8410508632659912
Validation loss: 1.9867220078745196

Epoch: 5| Step: 7
Training loss: 1.6916635036468506
Validation loss: 1.9880372683207195

Epoch: 5| Step: 8
Training loss: 2.030358076095581
Validation loss: 1.956793749204246

Epoch: 5| Step: 9
Training loss: 2.6087231636047363
Validation loss: 1.9918798387691539

Epoch: 5| Step: 10
Training loss: 2.6054868698120117
Validation loss: 1.9809457127765944

Epoch: 137| Step: 0
Training loss: 1.31031334400177
Validation loss: 1.972264782074959

Epoch: 5| Step: 1
Training loss: 2.4423460960388184
Validation loss: 1.969223363425142

Epoch: 5| Step: 2
Training loss: 1.8860557079315186
Validation loss: 1.98571991151379

Epoch: 5| Step: 3
Training loss: 2.2052865028381348
Validation loss: 1.9764450314224407

Epoch: 5| Step: 4
Training loss: 2.425304889678955
Validation loss: 1.9884217631432317

Epoch: 5| Step: 5
Training loss: 2.0206847190856934
Validation loss: 1.9962199785376107

Epoch: 5| Step: 6
Training loss: 2.3388679027557373
Validation loss: 2.0009256191151117

Epoch: 5| Step: 7
Training loss: 2.5961720943450928
Validation loss: 1.9845621944755636

Epoch: 5| Step: 8
Training loss: 1.9357366561889648
Validation loss: 1.974704768068047

Epoch: 5| Step: 9
Training loss: 1.6088831424713135
Validation loss: 1.9561190271890292

Epoch: 5| Step: 10
Training loss: 2.1684441566467285
Validation loss: 1.9678183114656838

Epoch: 138| Step: 0
Training loss: 1.9837909936904907
Validation loss: 1.9945466877311788

Epoch: 5| Step: 1
Training loss: 1.7847387790679932
Validation loss: 1.9628947678432669

Epoch: 5| Step: 2
Training loss: 2.8296608924865723
Validation loss: 1.9871583472016037

Epoch: 5| Step: 3
Training loss: 1.6118526458740234
Validation loss: 1.9964881391935452

Epoch: 5| Step: 4
Training loss: 2.2168631553649902
Validation loss: 2.010324734513478

Epoch: 5| Step: 5
Training loss: 1.8810596466064453
Validation loss: 1.9833916617978005

Epoch: 5| Step: 6
Training loss: 2.2875990867614746
Validation loss: 1.9901518437170214

Epoch: 5| Step: 7
Training loss: 1.765968918800354
Validation loss: 2.0018013626016598

Epoch: 5| Step: 8
Training loss: 2.1881518363952637
Validation loss: 1.9947146420837731

Epoch: 5| Step: 9
Training loss: 2.227936267852783
Validation loss: 1.9839443417005642

Epoch: 5| Step: 10
Training loss: 1.9256004095077515
Validation loss: 2.0001775987686647

Epoch: 139| Step: 0
Training loss: 3.0428223609924316
Validation loss: 1.965918521727285

Epoch: 5| Step: 1
Training loss: 1.5818053483963013
Validation loss: 1.9844802400117278

Epoch: 5| Step: 2
Training loss: 2.000645160675049
Validation loss: 2.0064482470994354

Epoch: 5| Step: 3
Training loss: 1.9473053216934204
Validation loss: 1.9745262104977843

Epoch: 5| Step: 4
Training loss: 2.3737399578094482
Validation loss: 1.9974894241620136

Epoch: 5| Step: 5
Training loss: 2.2357540130615234
Validation loss: 1.9958333405115272

Epoch: 5| Step: 6
Training loss: 1.7432191371917725
Validation loss: 2.0023226225247948

Epoch: 5| Step: 7
Training loss: 1.5660206079483032
Validation loss: 1.9749181398781397

Epoch: 5| Step: 8
Training loss: 2.5820679664611816
Validation loss: 2.0076003677101544

Epoch: 5| Step: 9
Training loss: 2.0203778743743896
Validation loss: 2.0073435857731807

Epoch: 5| Step: 10
Training loss: 1.705133318901062
Validation loss: 2.0009864196982434

Epoch: 140| Step: 0
Training loss: 2.6130576133728027
Validation loss: 1.9850082077005857

Epoch: 5| Step: 1
Training loss: 1.9687588214874268
Validation loss: 2.0018069128836355

Epoch: 5| Step: 2
Training loss: 2.2731990814208984
Validation loss: 2.004206044058646

Epoch: 5| Step: 3
Training loss: 2.072252035140991
Validation loss: 1.98441098325996

Epoch: 5| Step: 4
Training loss: 2.044956922531128
Validation loss: 1.993313072830118

Epoch: 5| Step: 5
Training loss: 2.3247406482696533
Validation loss: 1.9723198336939658

Epoch: 5| Step: 6
Training loss: 1.8415580987930298
Validation loss: 1.9913009905046033

Epoch: 5| Step: 7
Training loss: 2.2004520893096924
Validation loss: 1.9946403400872343

Epoch: 5| Step: 8
Training loss: 1.6743402481079102
Validation loss: 1.9893718560536702

Epoch: 5| Step: 9
Training loss: 1.8131386041641235
Validation loss: 1.9951191691942112

Epoch: 5| Step: 10
Training loss: 1.9865280389785767
Validation loss: 1.976873520881899

Epoch: 141| Step: 0
Training loss: 2.0589332580566406
Validation loss: 1.9763444213457004

Epoch: 5| Step: 1
Training loss: 1.9954391717910767
Validation loss: 1.9762240327814573

Epoch: 5| Step: 2
Training loss: 2.069751501083374
Validation loss: 1.9759356949919014

Epoch: 5| Step: 3
Training loss: 2.3357505798339844
Validation loss: 1.9810436233397453

Epoch: 5| Step: 4
Training loss: 2.041048049926758
Validation loss: 2.0132455172077304

Epoch: 5| Step: 5
Training loss: 2.2111332416534424
Validation loss: 2.009607522718368

Epoch: 5| Step: 6
Training loss: 1.8039096593856812
Validation loss: 1.9952701599367204

Epoch: 5| Step: 7
Training loss: 1.756032943725586
Validation loss: 1.9957973623788485

Epoch: 5| Step: 8
Training loss: 2.524501323699951
Validation loss: 1.9849251598440192

Epoch: 5| Step: 9
Training loss: 1.6897704601287842
Validation loss: 2.013847889438752

Epoch: 5| Step: 10
Training loss: 2.1220173835754395
Validation loss: 1.9946418962171

Epoch: 142| Step: 0
Training loss: 1.996490478515625
Validation loss: 1.9962503704973447

Epoch: 5| Step: 1
Training loss: 2.072953701019287
Validation loss: 1.9726723009540188

Epoch: 5| Step: 2
Training loss: 2.407081365585327
Validation loss: 1.9884232833821287

Epoch: 5| Step: 3
Training loss: 1.7380812168121338
Validation loss: 2.016560528867988

Epoch: 5| Step: 4
Training loss: 1.4936108589172363
Validation loss: 2.02034919364478

Epoch: 5| Step: 5
Training loss: 2.5805163383483887
Validation loss: 2.0264273215365667

Epoch: 5| Step: 6
Training loss: 1.9274240732192993
Validation loss: 2.020410817156556

Epoch: 5| Step: 7
Training loss: 2.122629165649414
Validation loss: 2.0201437127205635

Epoch: 5| Step: 8
Training loss: 2.1824278831481934
Validation loss: 2.0015487337625153

Epoch: 5| Step: 9
Training loss: 1.9567676782608032
Validation loss: 2.002073436655024

Epoch: 5| Step: 10
Training loss: 2.4651241302490234
Validation loss: 2.0230364338044198

Epoch: 143| Step: 0
Training loss: 1.8247029781341553
Validation loss: 2.0082458475584626

Epoch: 5| Step: 1
Training loss: 1.7320892810821533
Validation loss: 2.0141962305192025

Epoch: 5| Step: 2
Training loss: 2.490734815597534
Validation loss: 1.9929953057278869

Epoch: 5| Step: 3
Training loss: 2.298250913619995
Validation loss: 1.9880156068391697

Epoch: 5| Step: 4
Training loss: 1.897565245628357
Validation loss: 1.9856766321325814

Epoch: 5| Step: 5
Training loss: 2.66015887260437
Validation loss: 1.9840742516261276

Epoch: 5| Step: 6
Training loss: 1.9996941089630127
Validation loss: 2.0045487470524286

Epoch: 5| Step: 7
Training loss: 1.7793744802474976
Validation loss: 1.9950409294456564

Epoch: 5| Step: 8
Training loss: 1.8453495502471924
Validation loss: 2.006826117474546

Epoch: 5| Step: 9
Training loss: 2.2275519371032715
Validation loss: 2.007683959058536

Epoch: 5| Step: 10
Training loss: 1.9212394952774048
Validation loss: 2.005571444829305

Epoch: 144| Step: 0
Training loss: 2.056016683578491
Validation loss: 2.00760938531609

Epoch: 5| Step: 1
Training loss: 1.7279274463653564
Validation loss: 1.9911491511970438

Epoch: 5| Step: 2
Training loss: 2.1201465129852295
Validation loss: 1.9849634683260353

Epoch: 5| Step: 3
Training loss: 2.2579073905944824
Validation loss: 1.9988375786812074

Epoch: 5| Step: 4
Training loss: 2.891422748565674
Validation loss: 1.9694289212585778

Epoch: 5| Step: 5
Training loss: 2.1991233825683594
Validation loss: 1.9791651925733011

Epoch: 5| Step: 6
Training loss: 1.8417752981185913
Validation loss: 1.9497294759237638

Epoch: 5| Step: 7
Training loss: 1.6413812637329102
Validation loss: 1.967222652127666

Epoch: 5| Step: 8
Training loss: 1.5487300157546997
Validation loss: 1.9751985444817493

Epoch: 5| Step: 9
Training loss: 1.8446199893951416
Validation loss: 1.98788236289896

Epoch: 5| Step: 10
Training loss: 2.421504020690918
Validation loss: 1.9634848743356683

Epoch: 145| Step: 0
Training loss: 2.214662551879883
Validation loss: 1.9560057655457528

Epoch: 5| Step: 1
Training loss: 1.7388540506362915
Validation loss: 1.9619551807321527

Epoch: 5| Step: 2
Training loss: 2.1151504516601562
Validation loss: 1.9750044884220246

Epoch: 5| Step: 3
Training loss: 1.9032083749771118
Validation loss: 1.9864304655341691

Epoch: 5| Step: 4
Training loss: 2.8329291343688965
Validation loss: 1.979594240906418

Epoch: 5| Step: 5
Training loss: 1.925541639328003
Validation loss: 1.9642450706933134

Epoch: 5| Step: 6
Training loss: 1.768088698387146
Validation loss: 1.9504963915835145

Epoch: 5| Step: 7
Training loss: 2.3476920127868652
Validation loss: 1.9682409455699306

Epoch: 5| Step: 8
Training loss: 1.6548579931259155
Validation loss: 1.9764461312242734

Epoch: 5| Step: 9
Training loss: 1.6599966287612915
Validation loss: 1.9853226266881472

Epoch: 5| Step: 10
Training loss: 2.4802091121673584
Validation loss: 1.9991042665255967

Epoch: 146| Step: 0
Training loss: 1.6881086826324463
Validation loss: 1.9881790402115032

Epoch: 5| Step: 1
Training loss: 1.9828364849090576
Validation loss: 2.0058152085991314

Epoch: 5| Step: 2
Training loss: 1.9134142398834229
Validation loss: 1.9847599524323658

Epoch: 5| Step: 3
Training loss: 1.7846639156341553
Validation loss: 2.0004783471425376

Epoch: 5| Step: 4
Training loss: 2.1863274574279785
Validation loss: 2.007258956150342

Epoch: 5| Step: 5
Training loss: 1.940270185470581
Validation loss: 1.9924067053743588

Epoch: 5| Step: 6
Training loss: 2.592421770095825
Validation loss: 2.006522214540871

Epoch: 5| Step: 7
Training loss: 1.9175136089324951
Validation loss: 1.9925696465276903

Epoch: 5| Step: 8
Training loss: 2.038297176361084
Validation loss: 1.9931516839611916

Epoch: 5| Step: 9
Training loss: 2.1540603637695312
Validation loss: 1.9683712041506203

Epoch: 5| Step: 10
Training loss: 2.533658504486084
Validation loss: 2.005546295514671

Epoch: 147| Step: 0
Training loss: 1.753724455833435
Validation loss: 1.9842181167294901

Epoch: 5| Step: 1
Training loss: 1.9098011255264282
Validation loss: 1.985847544926469

Epoch: 5| Step: 2
Training loss: 2.0313663482666016
Validation loss: 1.9914114398341025

Epoch: 5| Step: 3
Training loss: 2.240194797515869
Validation loss: 2.008664987420523

Epoch: 5| Step: 4
Training loss: 2.011742353439331
Validation loss: 1.9935364505296111

Epoch: 5| Step: 5
Training loss: 2.206345558166504
Validation loss: 1.9666031304226126

Epoch: 5| Step: 6
Training loss: 2.7911994457244873
Validation loss: 1.9953868991585189

Epoch: 5| Step: 7
Training loss: 1.873899221420288
Validation loss: 1.9734789812436668

Epoch: 5| Step: 8
Training loss: 1.7941734790802002
Validation loss: 1.960989482941166

Epoch: 5| Step: 9
Training loss: 1.5870665311813354
Validation loss: 1.9774918376758535

Epoch: 5| Step: 10
Training loss: 2.341672658920288
Validation loss: 1.969066298136147

Epoch: 148| Step: 0
Training loss: 2.7025139331817627
Validation loss: 2.0002138896655013

Epoch: 5| Step: 1
Training loss: 2.3600430488586426
Validation loss: 1.9736124905206824

Epoch: 5| Step: 2
Training loss: 1.661924958229065
Validation loss: 1.9807973625839397

Epoch: 5| Step: 3
Training loss: 1.8557884693145752
Validation loss: 1.9871328235954366

Epoch: 5| Step: 4
Training loss: 1.7234214544296265
Validation loss: 1.9962743892464587

Epoch: 5| Step: 5
Training loss: 2.2977662086486816
Validation loss: 1.9870613441672376

Epoch: 5| Step: 6
Training loss: 2.1226675510406494
Validation loss: 1.995031169665757

Epoch: 5| Step: 7
Training loss: 1.8623453378677368
Validation loss: 1.9933336652735227

Epoch: 5| Step: 8
Training loss: 1.6778644323349
Validation loss: 2.0192665259043374

Epoch: 5| Step: 9
Training loss: 1.9909454584121704
Validation loss: 1.9740360013900264

Epoch: 5| Step: 10
Training loss: 2.366995096206665
Validation loss: 2.0159034293184996

Epoch: 149| Step: 0
Training loss: 1.9014484882354736
Validation loss: 1.993429873579292

Epoch: 5| Step: 1
Training loss: 1.9205577373504639
Validation loss: 1.9907166060581003

Epoch: 5| Step: 2
Training loss: 2.32142972946167
Validation loss: 1.97588845094045

Epoch: 5| Step: 3
Training loss: 2.0267388820648193
Validation loss: 1.9695898717449558

Epoch: 5| Step: 4
Training loss: 1.9188125133514404
Validation loss: 2.0157831368907804

Epoch: 5| Step: 5
Training loss: 1.756555199623108
Validation loss: 1.9979926745096843

Epoch: 5| Step: 6
Training loss: 2.031424045562744
Validation loss: 1.9686133861541748

Epoch: 5| Step: 7
Training loss: 2.2937400341033936
Validation loss: 2.0017174225981518

Epoch: 5| Step: 8
Training loss: 2.077918529510498
Validation loss: 1.9685568283962946

Epoch: 5| Step: 9
Training loss: 1.8645013570785522
Validation loss: 1.9871826159056796

Epoch: 5| Step: 10
Training loss: 2.3754618167877197
Validation loss: 2.0025940966862503

Epoch: 150| Step: 0
Training loss: 1.9994447231292725
Validation loss: 1.977495188354164

Epoch: 5| Step: 1
Training loss: 2.2308402061462402
Validation loss: 1.9807014311513593

Epoch: 5| Step: 2
Training loss: 2.379450798034668
Validation loss: 1.9851193735676427

Epoch: 5| Step: 3
Training loss: 1.6905622482299805
Validation loss: 1.9866358413491199

Epoch: 5| Step: 4
Training loss: 2.1608541011810303
Validation loss: 1.966143485038511

Epoch: 5| Step: 5
Training loss: 1.5622702836990356
Validation loss: 1.9711069701820292

Epoch: 5| Step: 6
Training loss: 2.219245433807373
Validation loss: 2.0163945536459646

Epoch: 5| Step: 7
Training loss: 1.8905599117279053
Validation loss: 1.9945606877726894

Epoch: 5| Step: 8
Training loss: 2.221764087677002
Validation loss: 2.0151672260735625

Epoch: 5| Step: 9
Training loss: 1.9698089361190796
Validation loss: 1.986555963434199

Epoch: 5| Step: 10
Training loss: 2.2699477672576904
Validation loss: 1.9876817990374822

Epoch: 151| Step: 0
Training loss: 1.9347003698349
Validation loss: 2.0066834649732037

Epoch: 5| Step: 1
Training loss: 1.4635549783706665
Validation loss: 2.008072751824574

Epoch: 5| Step: 2
Training loss: 1.8433059453964233
Validation loss: 2.0144660959961596

Epoch: 5| Step: 3
Training loss: 1.9306278228759766
Validation loss: 1.9965143729281682

Epoch: 5| Step: 4
Training loss: 2.0958456993103027
Validation loss: 2.0084582810760825

Epoch: 5| Step: 5
Training loss: 2.5540273189544678
Validation loss: 1.98259400808683

Epoch: 5| Step: 6
Training loss: 1.9512860774993896
Validation loss: 1.981476326142588

Epoch: 5| Step: 7
Training loss: 2.020095109939575
Validation loss: 1.982115989090294

Epoch: 5| Step: 8
Training loss: 2.1917223930358887
Validation loss: 2.0024277151271863

Epoch: 5| Step: 9
Training loss: 2.1141796112060547
Validation loss: 2.0186376494746052

Epoch: 5| Step: 10
Training loss: 2.2821526527404785
Validation loss: 1.964630934499925

Epoch: 152| Step: 0
Training loss: 1.804938554763794
Validation loss: 1.9862142057829006

Epoch: 5| Step: 1
Training loss: 2.4127540588378906
Validation loss: 1.9597765053472211

Epoch: 5| Step: 2
Training loss: 1.966144323348999
Validation loss: 1.969939770237092

Epoch: 5| Step: 3
Training loss: 2.113304615020752
Validation loss: 1.9905897955740652

Epoch: 5| Step: 4
Training loss: 2.3868839740753174
Validation loss: 1.989804107655761

Epoch: 5| Step: 5
Training loss: 1.8364757299423218
Validation loss: 1.969633069089664

Epoch: 5| Step: 6
Training loss: 2.394860029220581
Validation loss: 1.9796353950295398

Epoch: 5| Step: 7
Training loss: 1.82623291015625
Validation loss: 1.9665733575820923

Epoch: 5| Step: 8
Training loss: 1.822863221168518
Validation loss: 1.9527740068333124

Epoch: 5| Step: 9
Training loss: 1.7890952825546265
Validation loss: 1.9735887345447336

Epoch: 5| Step: 10
Training loss: 2.2152926921844482
Validation loss: 1.9721206747075564

Epoch: 153| Step: 0
Training loss: 2.201488971710205
Validation loss: 1.9678051240982548

Epoch: 5| Step: 1
Training loss: 2.3436996936798096
Validation loss: 1.9777421592384257

Epoch: 5| Step: 2
Training loss: 1.6083415746688843
Validation loss: 1.9759085844921809

Epoch: 5| Step: 3
Training loss: 2.2759337425231934
Validation loss: 2.0061531374531407

Epoch: 5| Step: 4
Training loss: 1.7831255197525024
Validation loss: 1.9892070165244482

Epoch: 5| Step: 5
Training loss: 2.065671443939209
Validation loss: 1.9768997110346311

Epoch: 5| Step: 6
Training loss: 1.3944694995880127
Validation loss: 2.0090928334061817

Epoch: 5| Step: 7
Training loss: 2.1547160148620605
Validation loss: 1.9959049301762735

Epoch: 5| Step: 8
Training loss: 2.8341495990753174
Validation loss: 1.9935603090511855

Epoch: 5| Step: 9
Training loss: 1.7177766561508179
Validation loss: 1.995823681995433

Epoch: 5| Step: 10
Training loss: 1.9990147352218628
Validation loss: 2.0206672530020438

Epoch: 154| Step: 0
Training loss: 2.329533338546753
Validation loss: 1.9814223051071167

Epoch: 5| Step: 1
Training loss: 2.2566020488739014
Validation loss: 1.9888851258062548

Epoch: 5| Step: 2
Training loss: 2.4186184406280518
Validation loss: 1.9842101194525277

Epoch: 5| Step: 3
Training loss: 1.879949927330017
Validation loss: 2.001533794146712

Epoch: 5| Step: 4
Training loss: 1.531954050064087
Validation loss: 1.980439273259973

Epoch: 5| Step: 5
Training loss: 1.686280608177185
Validation loss: 1.9980240688529065

Epoch: 5| Step: 6
Training loss: 1.7914998531341553
Validation loss: 1.9929854536569247

Epoch: 5| Step: 7
Training loss: 1.9887959957122803
Validation loss: 2.017422153103736

Epoch: 5| Step: 8
Training loss: 2.271925210952759
Validation loss: 2.013559804167799

Epoch: 5| Step: 9
Training loss: 2.24220609664917
Validation loss: 1.9872606967085151

Epoch: 5| Step: 10
Training loss: 1.7759078741073608
Validation loss: 2.0174527642547444

Epoch: 155| Step: 0
Training loss: 1.8670355081558228
Validation loss: 1.996448419427359

Epoch: 5| Step: 1
Training loss: 2.5689616203308105
Validation loss: 1.9926771579250213

Epoch: 5| Step: 2
Training loss: 1.8255220651626587
Validation loss: 1.997081374609342

Epoch: 5| Step: 3
Training loss: 1.6627086400985718
Validation loss: 1.9979436782098585

Epoch: 5| Step: 4
Training loss: 1.9549710750579834
Validation loss: 2.0149031249425744

Epoch: 5| Step: 5
Training loss: 1.9664920568466187
Validation loss: 1.9716092078916487

Epoch: 5| Step: 6
Training loss: 2.1057071685791016
Validation loss: 1.9863114344176425

Epoch: 5| Step: 7
Training loss: 1.9117778539657593
Validation loss: 1.9688278757115847

Epoch: 5| Step: 8
Training loss: 1.4854341745376587
Validation loss: 1.9891931703013759

Epoch: 5| Step: 9
Training loss: 2.5714993476867676
Validation loss: 2.009065730597383

Epoch: 5| Step: 10
Training loss: 2.5791239738464355
Validation loss: 1.9868633452282156

Epoch: 156| Step: 0
Training loss: 1.8571611642837524
Validation loss: 1.969706348193589

Epoch: 5| Step: 1
Training loss: 2.471090793609619
Validation loss: 2.0056090124191774

Epoch: 5| Step: 2
Training loss: 1.6768054962158203
Validation loss: 1.9621148135072441

Epoch: 5| Step: 3
Training loss: 2.2284374237060547
Validation loss: 1.9943310419718425

Epoch: 5| Step: 4
Training loss: 2.132753372192383
Validation loss: 1.9871681787634408

Epoch: 5| Step: 5
Training loss: 2.2871012687683105
Validation loss: 1.9950913536933161

Epoch: 5| Step: 6
Training loss: 1.592261552810669
Validation loss: 1.9837266822015085

Epoch: 5| Step: 7
Training loss: 2.215366840362549
Validation loss: 1.992293386049168

Epoch: 5| Step: 8
Training loss: 1.7209850549697876
Validation loss: 1.971384330462384

Epoch: 5| Step: 9
Training loss: 2.2202768325805664
Validation loss: 2.009183851621484

Epoch: 5| Step: 10
Training loss: 1.8494707345962524
Validation loss: 1.9816933024314143

Epoch: 157| Step: 0
Training loss: 2.3057448863983154
Validation loss: 1.9590922606888639

Epoch: 5| Step: 1
Training loss: 1.2522751092910767
Validation loss: 1.9741426206404162

Epoch: 5| Step: 2
Training loss: 1.9882516860961914
Validation loss: 1.9920993017893966

Epoch: 5| Step: 3
Training loss: 2.6454503536224365
Validation loss: 1.9777464225728025

Epoch: 5| Step: 4
Training loss: 1.558355450630188
Validation loss: 1.9965551924961868

Epoch: 5| Step: 5
Training loss: 1.8600059747695923
Validation loss: 1.9859572392638012

Epoch: 5| Step: 6
Training loss: 2.2803540229797363
Validation loss: 2.016351943374962

Epoch: 5| Step: 7
Training loss: 2.095115900039673
Validation loss: 2.0132989575785976

Epoch: 5| Step: 8
Training loss: 2.1078853607177734
Validation loss: 2.035625994846385

Epoch: 5| Step: 9
Training loss: 2.231208562850952
Validation loss: 2.01782396019146

Epoch: 5| Step: 10
Training loss: 2.2153115272521973
Validation loss: 2.0083495596403718

Epoch: 158| Step: 0
Training loss: 2.1779539585113525
Validation loss: 1.9941258302298925

Epoch: 5| Step: 1
Training loss: 1.604455590248108
Validation loss: 1.990093792638471

Epoch: 5| Step: 2
Training loss: 2.5821425914764404
Validation loss: 2.0214875026415755

Epoch: 5| Step: 3
Training loss: 2.3589682579040527
Validation loss: 1.9764258348813621

Epoch: 5| Step: 4
Training loss: 1.6814548969268799
Validation loss: 1.9980218128491474

Epoch: 5| Step: 5
Training loss: 1.4256806373596191
Validation loss: 2.004828699173466

Epoch: 5| Step: 6
Training loss: 2.053816556930542
Validation loss: 1.959809894202858

Epoch: 5| Step: 7
Training loss: 1.7038313150405884
Validation loss: 2.0029169615878852

Epoch: 5| Step: 8
Training loss: 2.215301036834717
Validation loss: 1.9858317323910293

Epoch: 5| Step: 9
Training loss: 2.1720430850982666
Validation loss: 1.9935203303572953

Epoch: 5| Step: 10
Training loss: 2.534201145172119
Validation loss: 1.9697293440500896

Epoch: 159| Step: 0
Training loss: 2.7938239574432373
Validation loss: 1.9855087418710031

Epoch: 5| Step: 1
Training loss: 1.708387017250061
Validation loss: 1.9663793784315868

Epoch: 5| Step: 2
Training loss: 1.7111715078353882
Validation loss: 1.9602313003232401

Epoch: 5| Step: 3
Training loss: 2.040609836578369
Validation loss: 1.9926479939491517

Epoch: 5| Step: 4
Training loss: 1.8417974710464478
Validation loss: 1.9693393489365936

Epoch: 5| Step: 5
Training loss: 1.9905550479888916
Validation loss: 1.9781182709560599

Epoch: 5| Step: 6
Training loss: 1.3096683025360107
Validation loss: 2.0107708182386173

Epoch: 5| Step: 7
Training loss: 1.9153683185577393
Validation loss: 1.9685938512125323

Epoch: 5| Step: 8
Training loss: 2.4552035331726074
Validation loss: 1.966122760567614

Epoch: 5| Step: 9
Training loss: 2.078765630722046
Validation loss: 1.981243182254094

Epoch: 5| Step: 10
Training loss: 2.2383997440338135
Validation loss: 1.9617179209186184

Epoch: 160| Step: 0
Training loss: 1.8948535919189453
Validation loss: 1.971992902858283

Epoch: 5| Step: 1
Training loss: 1.5488669872283936
Validation loss: 1.9908307188300676

Epoch: 5| Step: 2
Training loss: 2.387151002883911
Validation loss: 2.0119298863154587

Epoch: 5| Step: 3
Training loss: 2.0276358127593994
Validation loss: 1.9956220516594507

Epoch: 5| Step: 4
Training loss: 1.7406418323516846
Validation loss: 2.0181730434458744

Epoch: 5| Step: 5
Training loss: 2.1076512336730957
Validation loss: 2.017213821411133

Epoch: 5| Step: 6
Training loss: 2.406956434249878
Validation loss: 2.008046926990632

Epoch: 5| Step: 7
Training loss: 2.194661855697632
Validation loss: 1.997193004495354

Epoch: 5| Step: 8
Training loss: 2.2864956855773926
Validation loss: 2.014888045608356

Epoch: 5| Step: 9
Training loss: 1.960322380065918
Validation loss: 2.029337008794149

Epoch: 5| Step: 10
Training loss: 1.7064323425292969
Validation loss: 2.0277116734494447

Epoch: 161| Step: 0
Training loss: 1.7735602855682373
Validation loss: 2.0173338690111713

Epoch: 5| Step: 1
Training loss: 1.3810207843780518
Validation loss: 1.9917006889979045

Epoch: 5| Step: 2
Training loss: 2.0835773944854736
Validation loss: 2.0229393564244753

Epoch: 5| Step: 3
Training loss: 2.425079822540283
Validation loss: 1.9758721654133131

Epoch: 5| Step: 4
Training loss: 1.6355441808700562
Validation loss: 2.0017448881621003

Epoch: 5| Step: 5
Training loss: 2.4799015522003174
Validation loss: 1.985818729605726

Epoch: 5| Step: 6
Training loss: 1.7534373998641968
Validation loss: 1.9828441681400422

Epoch: 5| Step: 7
Training loss: 2.05236554145813
Validation loss: 2.0056548631319435

Epoch: 5| Step: 8
Training loss: 1.8161609172821045
Validation loss: 2.0024353073489283

Epoch: 5| Step: 9
Training loss: 2.602630376815796
Validation loss: 1.971230908106732

Epoch: 5| Step: 10
Training loss: 2.3456664085388184
Validation loss: 1.9944785833358765

Epoch: 162| Step: 0
Training loss: 2.1685447692871094
Validation loss: 1.9859263115031744

Epoch: 5| Step: 1
Training loss: 2.0538463592529297
Validation loss: 1.9693030106124056

Epoch: 5| Step: 2
Training loss: 2.187711238861084
Validation loss: 1.9986238453977851

Epoch: 5| Step: 3
Training loss: 2.3379764556884766
Validation loss: 1.9743555912407496

Epoch: 5| Step: 4
Training loss: 1.6555103063583374
Validation loss: 1.977168152409215

Epoch: 5| Step: 5
Training loss: 1.9945579767227173
Validation loss: 1.9724986014827606

Epoch: 5| Step: 6
Training loss: 1.984964370727539
Validation loss: 1.9924740073501424

Epoch: 5| Step: 7
Training loss: 2.1990559101104736
Validation loss: 2.0030430542525424

Epoch: 5| Step: 8
Training loss: 1.8496959209442139
Validation loss: 1.9965763707314768

Epoch: 5| Step: 9
Training loss: 1.5401415824890137
Validation loss: 2.002758974670082

Epoch: 5| Step: 10
Training loss: 2.349329948425293
Validation loss: 1.9959492401410175

Epoch: 163| Step: 0
Training loss: 1.3030201196670532
Validation loss: 1.9943796755165182

Epoch: 5| Step: 1
Training loss: 2.004525661468506
Validation loss: 1.9884484275694816

Epoch: 5| Step: 2
Training loss: 1.8232618570327759
Validation loss: 2.0160864732598744

Epoch: 5| Step: 3
Training loss: 1.8765316009521484
Validation loss: 2.0025280585853

Epoch: 5| Step: 4
Training loss: 2.1581757068634033
Validation loss: 1.9754331829727336

Epoch: 5| Step: 5
Training loss: 2.262645721435547
Validation loss: 1.9974324626307334

Epoch: 5| Step: 6
Training loss: 2.452671527862549
Validation loss: 1.9897785699495705

Epoch: 5| Step: 7
Training loss: 2.025751829147339
Validation loss: 1.9924892405027985

Epoch: 5| Step: 8
Training loss: 1.7799828052520752
Validation loss: 1.9688077088325255

Epoch: 5| Step: 9
Training loss: 2.013692855834961
Validation loss: 1.97886364177991

Epoch: 5| Step: 10
Training loss: 2.5488014221191406
Validation loss: 1.9767328910930182

Epoch: 164| Step: 0
Training loss: 2.2998318672180176
Validation loss: 2.015551633732293

Epoch: 5| Step: 1
Training loss: 2.0873470306396484
Validation loss: 1.9647679149463613

Epoch: 5| Step: 2
Training loss: 1.7832403182983398
Validation loss: 1.9874998728434246

Epoch: 5| Step: 3
Training loss: 2.368055820465088
Validation loss: 1.9959718809332898

Epoch: 5| Step: 4
Training loss: 2.128469944000244
Validation loss: 1.9860315399785196

Epoch: 5| Step: 5
Training loss: 1.7770206928253174
Validation loss: 1.961574754407329

Epoch: 5| Step: 6
Training loss: 1.978600263595581
Validation loss: 1.9948883466823126

Epoch: 5| Step: 7
Training loss: 1.9893684387207031
Validation loss: 1.9851433179711784

Epoch: 5| Step: 8
Training loss: 1.9438291788101196
Validation loss: 1.9837813761926466

Epoch: 5| Step: 9
Training loss: 1.9580310583114624
Validation loss: 1.9874676094260266

Epoch: 5| Step: 10
Training loss: 1.8184003829956055
Validation loss: 2.0064498968021844

Epoch: 165| Step: 0
Training loss: 2.2114498615264893
Validation loss: 2.0120414328831497

Epoch: 5| Step: 1
Training loss: 1.5644553899765015
Validation loss: 1.9679899728426369

Epoch: 5| Step: 2
Training loss: 1.828478455543518
Validation loss: 2.007756813879936

Epoch: 5| Step: 3
Training loss: 1.8368314504623413
Validation loss: 2.0077820977857037

Epoch: 5| Step: 4
Training loss: 2.405869960784912
Validation loss: 1.9825687113628592

Epoch: 5| Step: 5
Training loss: 2.1960668563842773
Validation loss: 1.9929820696512859

Epoch: 5| Step: 6
Training loss: 1.518615484237671
Validation loss: 2.0098669875052666

Epoch: 5| Step: 7
Training loss: 1.6531257629394531
Validation loss: 1.9878337152542607

Epoch: 5| Step: 8
Training loss: 2.0614309310913086
Validation loss: 2.0266338240715767

Epoch: 5| Step: 9
Training loss: 2.1196303367614746
Validation loss: 2.009062259427963

Epoch: 5| Step: 10
Training loss: 2.8534939289093018
Validation loss: 1.9934333960215251

Epoch: 166| Step: 0
Training loss: 1.7529780864715576
Validation loss: 1.9954470485769293

Epoch: 5| Step: 1
Training loss: 2.0238595008850098
Validation loss: 2.010204038312358

Epoch: 5| Step: 2
Training loss: 2.408625364303589
Validation loss: 2.0096816093690935

Epoch: 5| Step: 3
Training loss: 2.1199843883514404
Validation loss: 1.9964755171088762

Epoch: 5| Step: 4
Training loss: 1.3896026611328125
Validation loss: 1.9716809167656848

Epoch: 5| Step: 5
Training loss: 2.198523759841919
Validation loss: 1.9573551288215063

Epoch: 5| Step: 6
Training loss: 2.1048507690429688
Validation loss: 1.9640088183905489

Epoch: 5| Step: 7
Training loss: 2.109492063522339
Validation loss: 1.9757896854031471

Epoch: 5| Step: 8
Training loss: 2.056832790374756
Validation loss: 1.9815692799065703

Epoch: 5| Step: 9
Training loss: 2.4750921726226807
Validation loss: 1.98649561789728

Epoch: 5| Step: 10
Training loss: 1.244310975074768
Validation loss: 1.9627128942038423

Epoch: 167| Step: 0
Training loss: 1.7437374591827393
Validation loss: 1.9730721109656877

Epoch: 5| Step: 1
Training loss: 2.2111778259277344
Validation loss: 1.9589253266652424

Epoch: 5| Step: 2
Training loss: 1.9404895305633545
Validation loss: 1.965923765654205

Epoch: 5| Step: 3
Training loss: 1.7443568706512451
Validation loss: 1.9834393326954176

Epoch: 5| Step: 4
Training loss: 2.490028142929077
Validation loss: 1.9968275985410135

Epoch: 5| Step: 5
Training loss: 1.8657588958740234
Validation loss: 2.0074975823843353

Epoch: 5| Step: 6
Training loss: 2.3715994358062744
Validation loss: 1.998982229540425

Epoch: 5| Step: 7
Training loss: 2.028926134109497
Validation loss: 1.9970768574745423

Epoch: 5| Step: 8
Training loss: 1.9012759923934937
Validation loss: 1.9931197589443577

Epoch: 5| Step: 9
Training loss: 1.7931745052337646
Validation loss: 2.0075026635200746

Epoch: 5| Step: 10
Training loss: 1.6935272216796875
Validation loss: 1.995382490978446

Epoch: 168| Step: 0
Training loss: 1.7752958536148071
Validation loss: 1.9995219579306982

Epoch: 5| Step: 1
Training loss: 2.2886910438537598
Validation loss: 2.0148400350283553

Epoch: 5| Step: 2
Training loss: 2.2410624027252197
Validation loss: 1.9835420846939087

Epoch: 5| Step: 3
Training loss: 1.5756795406341553
Validation loss: 1.979659386860427

Epoch: 5| Step: 4
Training loss: 2.2489547729492188
Validation loss: 1.991356977852442

Epoch: 5| Step: 5
Training loss: 1.9189453125
Validation loss: 2.006725788116455

Epoch: 5| Step: 6
Training loss: 2.9175217151641846
Validation loss: 2.002152148113456

Epoch: 5| Step: 7
Training loss: 1.6636641025543213
Validation loss: 1.996904807706033

Epoch: 5| Step: 8
Training loss: 1.748313307762146
Validation loss: 2.0087007873801777

Epoch: 5| Step: 9
Training loss: 1.9737144708633423
Validation loss: 2.007022209064935

Epoch: 5| Step: 10
Training loss: 1.5741477012634277
Validation loss: 2.0004993113138343

Epoch: 169| Step: 0
Training loss: 1.6005098819732666
Validation loss: 2.025733555516889

Epoch: 5| Step: 1
Training loss: 2.0253195762634277
Validation loss: 1.99004566284918

Epoch: 5| Step: 2
Training loss: 1.8733558654785156
Validation loss: 1.99443607817414

Epoch: 5| Step: 3
Training loss: 2.294849157333374
Validation loss: 2.0013955639254664

Epoch: 5| Step: 4
Training loss: 1.6774877309799194
Validation loss: 1.9943288346772552

Epoch: 5| Step: 5
Training loss: 1.9325278997421265
Validation loss: 2.0039610055185135

Epoch: 5| Step: 6
Training loss: 1.965512990951538
Validation loss: 2.004548877798101

Epoch: 5| Step: 7
Training loss: 2.476862907409668
Validation loss: 1.9775724731465822

Epoch: 5| Step: 8
Training loss: 1.8346360921859741
Validation loss: 1.9969553883357714

Epoch: 5| Step: 9
Training loss: 2.3394649028778076
Validation loss: 1.9782372828452819

Epoch: 5| Step: 10
Training loss: 1.9341425895690918
Validation loss: 1.9796526893492667

Epoch: 170| Step: 0
Training loss: 2.0523478984832764
Validation loss: 1.9873830297941804

Epoch: 5| Step: 1
Training loss: 1.562382698059082
Validation loss: 1.9731293698792816

Epoch: 5| Step: 2
Training loss: 2.5096945762634277
Validation loss: 1.9872299996755456

Epoch: 5| Step: 3
Training loss: 1.7668609619140625
Validation loss: 1.9986836756429365

Epoch: 5| Step: 4
Training loss: 1.7817761898040771
Validation loss: 1.9814718654078822

Epoch: 5| Step: 5
Training loss: 1.4898617267608643
Validation loss: 1.9944473671656784

Epoch: 5| Step: 6
Training loss: 1.3450615406036377
Validation loss: 1.9854717536639142

Epoch: 5| Step: 7
Training loss: 2.558915376663208
Validation loss: 1.9998901864533782

Epoch: 5| Step: 8
Training loss: 1.9577267169952393
Validation loss: 2.005647652892656

Epoch: 5| Step: 9
Training loss: 2.786870241165161
Validation loss: 1.9746966772182013

Epoch: 5| Step: 10
Training loss: 2.161750555038452
Validation loss: 1.9896461604743876

Epoch: 171| Step: 0
Training loss: 2.303429126739502
Validation loss: 2.0060391631177676

Epoch: 5| Step: 1
Training loss: 1.9250580072402954
Validation loss: 1.984590248395038

Epoch: 5| Step: 2
Training loss: 1.7961208820343018
Validation loss: 1.9735706390873078

Epoch: 5| Step: 3
Training loss: 2.0516586303710938
Validation loss: 1.978967123134162

Epoch: 5| Step: 4
Training loss: 1.7705070972442627
Validation loss: 1.9891241519681868

Epoch: 5| Step: 5
Training loss: 2.0969221591949463
Validation loss: 1.9934887937320176

Epoch: 5| Step: 6
Training loss: 1.7702877521514893
Validation loss: 2.0030456268659202

Epoch: 5| Step: 7
Training loss: 2.066586494445801
Validation loss: 1.962325152530465

Epoch: 5| Step: 8
Training loss: 1.5324366092681885
Validation loss: 1.9873035389889953

Epoch: 5| Step: 9
Training loss: 2.310394048690796
Validation loss: 1.981805650136804

Epoch: 5| Step: 10
Training loss: 2.2875146865844727
Validation loss: 1.9971312553651872

Epoch: 172| Step: 0
Training loss: 1.5985124111175537
Validation loss: 1.9939063185004777

Epoch: 5| Step: 1
Training loss: 2.292268753051758
Validation loss: 1.9945761926712529

Epoch: 5| Step: 2
Training loss: 2.272775650024414
Validation loss: 1.9947486359585997

Epoch: 5| Step: 3
Training loss: 2.4751665592193604
Validation loss: 2.0049430836913404

Epoch: 5| Step: 4
Training loss: 1.826677918434143
Validation loss: 2.0041104760221256

Epoch: 5| Step: 5
Training loss: 2.0182642936706543
Validation loss: 1.9837408924615512

Epoch: 5| Step: 6
Training loss: 1.7692848443984985
Validation loss: 1.9810977417935607

Epoch: 5| Step: 7
Training loss: 1.872145414352417
Validation loss: 1.9895332731226438

Epoch: 5| Step: 8
Training loss: 1.8241863250732422
Validation loss: 1.9877993124787525

Epoch: 5| Step: 9
Training loss: 1.842158555984497
Validation loss: 1.9790589283871394

Epoch: 5| Step: 10
Training loss: 2.0198822021484375
Validation loss: 1.9968699710343474

Epoch: 173| Step: 0
Training loss: 2.2254981994628906
Validation loss: 1.977067914060367

Epoch: 5| Step: 1
Training loss: 1.9425586462020874
Validation loss: 1.974937718401673

Epoch: 5| Step: 2
Training loss: 1.5817382335662842
Validation loss: 1.9806035039245442

Epoch: 5| Step: 3
Training loss: 2.1780529022216797
Validation loss: 1.9961504167126072

Epoch: 5| Step: 4
Training loss: 2.051154136657715
Validation loss: 1.9770351879058345

Epoch: 5| Step: 5
Training loss: 1.9487972259521484
Validation loss: 2.003683049191711

Epoch: 5| Step: 6
Training loss: 1.9677913188934326
Validation loss: 2.002802728324808

Epoch: 5| Step: 7
Training loss: 1.9289770126342773
Validation loss: 2.0175037076396327

Epoch: 5| Step: 8
Training loss: 1.9768422842025757
Validation loss: 1.9861460988239577

Epoch: 5| Step: 9
Training loss: 2.068671464920044
Validation loss: 1.9997412825143466

Epoch: 5| Step: 10
Training loss: 1.9296282529830933
Validation loss: 1.9956430876126854

Epoch: 174| Step: 0
Training loss: 1.9406883716583252
Validation loss: 2.019996682802836

Epoch: 5| Step: 1
Training loss: 1.9248584508895874
Validation loss: 1.9842366505694646

Epoch: 5| Step: 2
Training loss: 2.690506935119629
Validation loss: 2.0045780058830016

Epoch: 5| Step: 3
Training loss: 2.0319695472717285
Validation loss: 1.9928759041652884

Epoch: 5| Step: 4
Training loss: 1.2147502899169922
Validation loss: 2.001213978695613

Epoch: 5| Step: 5
Training loss: 1.5218168497085571
Validation loss: 1.9940345876960344

Epoch: 5| Step: 6
Training loss: 2.169456958770752
Validation loss: 1.978877088075043

Epoch: 5| Step: 7
Training loss: 2.16947865486145
Validation loss: 1.9924353630312028

Epoch: 5| Step: 8
Training loss: 1.8042482137680054
Validation loss: 1.9788578761521207

Epoch: 5| Step: 9
Training loss: 2.582047700881958
Validation loss: 1.982326215313327

Epoch: 5| Step: 10
Training loss: 1.471625566482544
Validation loss: 2.004468043645223

Epoch: 175| Step: 0
Training loss: 1.699373483657837
Validation loss: 1.9696560623825237

Epoch: 5| Step: 1
Training loss: 2.20754075050354
Validation loss: 1.9775060863905056

Epoch: 5| Step: 2
Training loss: 1.7890071868896484
Validation loss: 1.9913221584853305

Epoch: 5| Step: 3
Training loss: 2.0827624797821045
Validation loss: 1.974881072198191

Epoch: 5| Step: 4
Training loss: 2.357987403869629
Validation loss: 1.9956111395230858

Epoch: 5| Step: 5
Training loss: 2.0249392986297607
Validation loss: 1.9829980916874383

Epoch: 5| Step: 6
Training loss: 2.0916972160339355
Validation loss: 1.978234524367958

Epoch: 5| Step: 7
Training loss: 1.7569948434829712
Validation loss: 2.0043471667074386

Epoch: 5| Step: 8
Training loss: 1.8740192651748657
Validation loss: 1.9927243724946053

Epoch: 5| Step: 9
Training loss: 2.1309661865234375
Validation loss: 2.0076533966167

Epoch: 5| Step: 10
Training loss: 1.7858405113220215
Validation loss: 1.9933853892869846

Epoch: 176| Step: 0
Training loss: 2.1779847145080566
Validation loss: 1.9716816102304766

Epoch: 5| Step: 1
Training loss: 2.1674396991729736
Validation loss: 2.000298797443349

Epoch: 5| Step: 2
Training loss: 1.7155758142471313
Validation loss: 1.9847501631705993

Epoch: 5| Step: 3
Training loss: 1.8656883239746094
Validation loss: 2.0077251964999783

Epoch: 5| Step: 4
Training loss: 1.8869845867156982
Validation loss: 1.9944013498162712

Epoch: 5| Step: 5
Training loss: 1.7409480810165405
Validation loss: 1.9730815772087342

Epoch: 5| Step: 6
Training loss: 1.5314700603485107
Validation loss: 2.000225438866564

Epoch: 5| Step: 7
Training loss: 2.289271831512451
Validation loss: 1.998538455655498

Epoch: 5| Step: 8
Training loss: 2.453458786010742
Validation loss: 2.007892838088415

Epoch: 5| Step: 9
Training loss: 2.153156280517578
Validation loss: 1.9898240091980144

Epoch: 5| Step: 10
Training loss: 1.841475486755371
Validation loss: 1.980247345021976

Epoch: 177| Step: 0
Training loss: 1.8322079181671143
Validation loss: 1.99758437115659

Epoch: 5| Step: 1
Training loss: 2.381298780441284
Validation loss: 2.0182002539275796

Epoch: 5| Step: 2
Training loss: 1.8542144298553467
Validation loss: 1.9944723036981398

Epoch: 5| Step: 3
Training loss: 1.8912115097045898
Validation loss: 1.979128595321409

Epoch: 5| Step: 4
Training loss: 2.0163586139678955
Validation loss: 1.9910087559812812

Epoch: 5| Step: 5
Training loss: 2.029625654220581
Validation loss: 1.9893341064453125

Epoch: 5| Step: 6
Training loss: 1.6672815084457397
Validation loss: 1.9947600133957402

Epoch: 5| Step: 7
Training loss: 2.3028006553649902
Validation loss: 1.9772800258410874

Epoch: 5| Step: 8
Training loss: 1.8655166625976562
Validation loss: 1.9849813715104134

Epoch: 5| Step: 9
Training loss: 2.187657594680786
Validation loss: 2.0087091615123134

Epoch: 5| Step: 10
Training loss: 1.5965890884399414
Validation loss: 2.019823658850885

Epoch: 178| Step: 0
Training loss: 1.9280424118041992
Validation loss: 1.9779024636873634

Epoch: 5| Step: 1
Training loss: 2.1562869548797607
Validation loss: 2.0092421808550434

Epoch: 5| Step: 2
Training loss: 1.9123340845108032
Validation loss: 1.9923738177104662

Epoch: 5| Step: 3
Training loss: 1.901365041732788
Validation loss: 1.9878943248461651

Epoch: 5| Step: 4
Training loss: 2.0125343799591064
Validation loss: 1.9989044640653877

Epoch: 5| Step: 5
Training loss: 2.3664326667785645
Validation loss: 1.9796422296954739

Epoch: 5| Step: 6
Training loss: 1.8872743844985962
Validation loss: 1.9747982230237735

Epoch: 5| Step: 7
Training loss: 1.7876331806182861
Validation loss: 2.002353532339937

Epoch: 5| Step: 8
Training loss: 2.250056743621826
Validation loss: 2.006156003603371

Epoch: 5| Step: 9
Training loss: 1.6940542459487915
Validation loss: 2.015302852917743

Epoch: 5| Step: 10
Training loss: 1.8133525848388672
Validation loss: 2.003245961281561

Epoch: 179| Step: 0
Training loss: 1.914433240890503
Validation loss: 1.9959232089340047

Epoch: 5| Step: 1
Training loss: 1.8031154870986938
Validation loss: 1.9824315591525006

Epoch: 5| Step: 2
Training loss: 1.9283653497695923
Validation loss: 2.0038542414224274

Epoch: 5| Step: 3
Training loss: 2.034938335418701
Validation loss: 2.0042064113001667

Epoch: 5| Step: 4
Training loss: 2.3012356758117676
Validation loss: 2.0016900377888835

Epoch: 5| Step: 5
Training loss: 1.5708945989608765
Validation loss: 2.012464589970086

Epoch: 5| Step: 6
Training loss: 2.8398780822753906
Validation loss: 2.0129207257301576

Epoch: 5| Step: 7
Training loss: 1.8600200414657593
Validation loss: 2.0200846195220947

Epoch: 5| Step: 8
Training loss: 1.6443488597869873
Validation loss: 1.9992870899938768

Epoch: 5| Step: 9
Training loss: 1.7714647054672241
Validation loss: 2.0058031543608634

Epoch: 5| Step: 10
Training loss: 1.9789718389511108
Validation loss: 2.0095143061812206

Epoch: 180| Step: 0
Training loss: 2.2413649559020996
Validation loss: 2.010898877215642

Epoch: 5| Step: 1
Training loss: 2.192101240158081
Validation loss: 2.0295856870630735

Epoch: 5| Step: 2
Training loss: 1.817571997642517
Validation loss: 1.983998049971878

Epoch: 5| Step: 3
Training loss: 2.1719324588775635
Validation loss: 1.9922117084585211

Epoch: 5| Step: 4
Training loss: 1.5805789232254028
Validation loss: 1.9991800297972977

Epoch: 5| Step: 5
Training loss: 1.6554864645004272
Validation loss: 1.995292273900842

Epoch: 5| Step: 6
Training loss: 1.825482964515686
Validation loss: 1.9740837889332925

Epoch: 5| Step: 7
Training loss: 2.1074764728546143
Validation loss: 1.9621664298477994

Epoch: 5| Step: 8
Training loss: 2.1691184043884277
Validation loss: 1.9625993838874243

Epoch: 5| Step: 9
Training loss: 2.363471508026123
Validation loss: 1.9798629155722998

Epoch: 5| Step: 10
Training loss: 1.2731819152832031
Validation loss: 1.9752339983499179

Epoch: 181| Step: 0
Training loss: 2.1090099811553955
Validation loss: 1.980304479598999

Epoch: 5| Step: 1
Training loss: 1.910557508468628
Validation loss: 1.9887388265261086

Epoch: 5| Step: 2
Training loss: 2.1980862617492676
Validation loss: 1.9956143697102864

Epoch: 5| Step: 3
Training loss: 1.6097780466079712
Validation loss: 1.9918262420162078

Epoch: 5| Step: 4
Training loss: 1.6368598937988281
Validation loss: 2.0064081530417166

Epoch: 5| Step: 5
Training loss: 1.9414918422698975
Validation loss: 1.98842752492556

Epoch: 5| Step: 6
Training loss: 1.9155852794647217
Validation loss: 2.0248036974219867

Epoch: 5| Step: 7
Training loss: 1.9987932443618774
Validation loss: 1.9856114284966582

Epoch: 5| Step: 8
Training loss: 1.3578964471817017
Validation loss: 1.9977709683038856

Epoch: 5| Step: 9
Training loss: 2.6279444694519043
Validation loss: 1.9900729438310027

Epoch: 5| Step: 10
Training loss: 2.5358617305755615
Validation loss: 1.9806623830590198

Epoch: 182| Step: 0
Training loss: 1.5110477209091187
Validation loss: 1.9990933146528018

Epoch: 5| Step: 1
Training loss: 2.2360570430755615
Validation loss: 1.959395916231217

Epoch: 5| Step: 2
Training loss: 1.445370078086853
Validation loss: 1.9753411457102785

Epoch: 5| Step: 3
Training loss: 2.229828119277954
Validation loss: 1.9886950997896091

Epoch: 5| Step: 4
Training loss: 1.7611579895019531
Validation loss: 1.9814108264061712

Epoch: 5| Step: 5
Training loss: 1.8973331451416016
Validation loss: 1.9909030493869577

Epoch: 5| Step: 6
Training loss: 1.6723320484161377
Validation loss: 1.9806046280809628

Epoch: 5| Step: 7
Training loss: 2.0941522121429443
Validation loss: 1.9876023402778051

Epoch: 5| Step: 8
Training loss: 2.3376576900482178
Validation loss: 1.9693280240540862

Epoch: 5| Step: 9
Training loss: 1.9971692562103271
Validation loss: 1.9723372715775684

Epoch: 5| Step: 10
Training loss: 2.4662857055664062
Validation loss: 1.9864420813898886

Epoch: 183| Step: 0
Training loss: 1.883803129196167
Validation loss: 1.9752511619239725

Epoch: 5| Step: 1
Training loss: 1.8956245183944702
Validation loss: 1.9584034591592767

Epoch: 5| Step: 2
Training loss: 2.236161470413208
Validation loss: 1.9758580166806456

Epoch: 5| Step: 3
Training loss: 1.4972293376922607
Validation loss: 1.9895576494996265

Epoch: 5| Step: 4
Training loss: 1.9457523822784424
Validation loss: 2.0123795053010345

Epoch: 5| Step: 5
Training loss: 2.1009998321533203
Validation loss: 2.004596858896235

Epoch: 5| Step: 6
Training loss: 1.549748182296753
Validation loss: 1.9976617367036882

Epoch: 5| Step: 7
Training loss: 2.179882049560547
Validation loss: 1.9869486670340262

Epoch: 5| Step: 8
Training loss: 2.1176629066467285
Validation loss: 2.001344603876914

Epoch: 5| Step: 9
Training loss: 1.9661487340927124
Validation loss: 2.00253995772331

Epoch: 5| Step: 10
Training loss: 2.2726426124572754
Validation loss: 2.022670404885405

Epoch: 184| Step: 0
Training loss: 1.7227407693862915
Validation loss: 2.008481369223646

Epoch: 5| Step: 1
Training loss: 1.7896878719329834
Validation loss: 2.011159395658842

Epoch: 5| Step: 2
Training loss: 1.6711084842681885
Validation loss: 2.003766152166551

Epoch: 5| Step: 3
Training loss: 1.741650938987732
Validation loss: 2.0278995831807456

Epoch: 5| Step: 4
Training loss: 1.7377172708511353
Validation loss: 2.024029198513236

Epoch: 5| Step: 5
Training loss: 1.4806101322174072
Validation loss: 2.016732395336192

Epoch: 5| Step: 6
Training loss: 2.327335834503174
Validation loss: 2.044376122054233

Epoch: 5| Step: 7
Training loss: 2.48875093460083
Validation loss: 2.015005955132105

Epoch: 5| Step: 8
Training loss: 1.7842967510223389
Validation loss: 2.009125032732564

Epoch: 5| Step: 9
Training loss: 2.2315471172332764
Validation loss: 1.994550189664287

Epoch: 5| Step: 10
Training loss: 2.742013931274414
Validation loss: 1.9994237166579052

Epoch: 185| Step: 0
Training loss: 2.0882012844085693
Validation loss: 2.0062111090588313

Epoch: 5| Step: 1
Training loss: 1.8030617237091064
Validation loss: 2.0159248075177594

Epoch: 5| Step: 2
Training loss: 1.9693794250488281
Validation loss: 1.9849966213267336

Epoch: 5| Step: 3
Training loss: 2.1656947135925293
Validation loss: 1.953276413743214

Epoch: 5| Step: 4
Training loss: 2.242058277130127
Validation loss: 1.9935703969770862

Epoch: 5| Step: 5
Training loss: 2.3524677753448486
Validation loss: 1.978324943973172

Epoch: 5| Step: 6
Training loss: 1.6219065189361572
Validation loss: 2.00275376150685

Epoch: 5| Step: 7
Training loss: 2.2602627277374268
Validation loss: 1.9899587169770272

Epoch: 5| Step: 8
Training loss: 1.4153187274932861
Validation loss: 1.9652268335383425

Epoch: 5| Step: 9
Training loss: 1.6500627994537354
Validation loss: 1.9859808132212649

Epoch: 5| Step: 10
Training loss: 2.0474908351898193
Validation loss: 1.997867254800694

Epoch: 186| Step: 0
Training loss: 1.4946880340576172
Validation loss: 1.9879619639406922

Epoch: 5| Step: 1
Training loss: 1.7693712711334229
Validation loss: 1.972722339373763

Epoch: 5| Step: 2
Training loss: 1.6583741903305054
Validation loss: 1.9607866310304212

Epoch: 5| Step: 3
Training loss: 1.6483516693115234
Validation loss: 2.008276824028261

Epoch: 5| Step: 4
Training loss: 2.0212337970733643
Validation loss: 1.9995645130834272

Epoch: 5| Step: 5
Training loss: 1.8405539989471436
Validation loss: 1.9931107439020628

Epoch: 5| Step: 6
Training loss: 1.868783712387085
Validation loss: 1.9675385900723037

Epoch: 5| Step: 7
Training loss: 2.069575786590576
Validation loss: 1.982378816091886

Epoch: 5| Step: 8
Training loss: 2.3283700942993164
Validation loss: 2.0110322134469145

Epoch: 5| Step: 9
Training loss: 2.32904052734375
Validation loss: 1.9787372696784236

Epoch: 5| Step: 10
Training loss: 2.5872840881347656
Validation loss: 2.003129287432599

Epoch: 187| Step: 0
Training loss: 1.7485634088516235
Validation loss: 2.0076052476001043

Epoch: 5| Step: 1
Training loss: 2.082914352416992
Validation loss: 2.0061692794164023

Epoch: 5| Step: 2
Training loss: 2.551081418991089
Validation loss: 2.017852901130594

Epoch: 5| Step: 3
Training loss: 1.8987083435058594
Validation loss: 2.02291355850876

Epoch: 5| Step: 4
Training loss: 1.9650949239730835
Validation loss: 2.0256365358188586

Epoch: 5| Step: 5
Training loss: 1.8222767114639282
Validation loss: 2.0518674799191055

Epoch: 5| Step: 6
Training loss: 1.8464435338974
Validation loss: 2.059255207738569

Epoch: 5| Step: 7
Training loss: 1.9542033672332764
Validation loss: 2.042315465147777

Epoch: 5| Step: 8
Training loss: 1.720754623413086
Validation loss: 2.0774821722379295

Epoch: 5| Step: 9
Training loss: 2.0003113746643066
Validation loss: 2.0424491692614812

Epoch: 5| Step: 10
Training loss: 2.1577351093292236
Validation loss: 2.0245948581285376

Epoch: 188| Step: 0
Training loss: 2.0062384605407715
Validation loss: 2.027886616286411

Epoch: 5| Step: 1
Training loss: 1.830137848854065
Validation loss: 2.0224445686545423

Epoch: 5| Step: 2
Training loss: 1.8342266082763672
Validation loss: 2.0044490778318016

Epoch: 5| Step: 3
Training loss: 1.3356043100357056
Validation loss: 2.00465307440809

Epoch: 5| Step: 4
Training loss: 2.2168021202087402
Validation loss: 1.9938610881887457

Epoch: 5| Step: 5
Training loss: 2.4914917945861816
Validation loss: 1.9864167756931757

Epoch: 5| Step: 6
Training loss: 2.0620851516723633
Validation loss: 1.9577913425301994

Epoch: 5| Step: 7
Training loss: 1.6094297170639038
Validation loss: 1.9830506245295207

Epoch: 5| Step: 8
Training loss: 1.7977670431137085
Validation loss: 1.9653906976023028

Epoch: 5| Step: 9
Training loss: 2.29380464553833
Validation loss: 1.9767939429129324

Epoch: 5| Step: 10
Training loss: 1.9900034666061401
Validation loss: 1.9841798556748258

Epoch: 189| Step: 0
Training loss: 1.4099041223526
Validation loss: 1.9807546920673822

Epoch: 5| Step: 1
Training loss: 2.5746686458587646
Validation loss: 1.9739608790284844

Epoch: 5| Step: 2
Training loss: 2.3509721755981445
Validation loss: 1.9585204970452093

Epoch: 5| Step: 3
Training loss: 2.3053088188171387
Validation loss: 1.95988630735746

Epoch: 5| Step: 4
Training loss: 1.6057049036026
Validation loss: 1.9971370081747732

Epoch: 5| Step: 5
Training loss: 1.7348636388778687
Validation loss: 1.9862603192688317

Epoch: 5| Step: 6
Training loss: 1.4806838035583496
Validation loss: 1.987697660282094

Epoch: 5| Step: 7
Training loss: 2.020448684692383
Validation loss: 2.0142439334623274

Epoch: 5| Step: 8
Training loss: 2.075373649597168
Validation loss: 1.9647965764486661

Epoch: 5| Step: 9
Training loss: 1.8497123718261719
Validation loss: 1.9809867361540436

Epoch: 5| Step: 10
Training loss: 2.4091784954071045
Validation loss: 1.9970154992995723

Epoch: 190| Step: 0
Training loss: 2.1483113765716553
Validation loss: 2.0078762654335267

Epoch: 5| Step: 1
Training loss: 2.2578094005584717
Validation loss: 1.9963777116549912

Epoch: 5| Step: 2
Training loss: 1.5234670639038086
Validation loss: 2.003624047002485

Epoch: 5| Step: 3
Training loss: 2.2763028144836426
Validation loss: 2.0190954131464802

Epoch: 5| Step: 4
Training loss: 2.1494250297546387
Validation loss: 2.0186427408649075

Epoch: 5| Step: 5
Training loss: 1.8823387622833252
Validation loss: 2.001663733554143

Epoch: 5| Step: 6
Training loss: 1.5435473918914795
Validation loss: 1.9839112156180925

Epoch: 5| Step: 7
Training loss: 1.598896861076355
Validation loss: 2.0261481808077906

Epoch: 5| Step: 8
Training loss: 1.8443431854248047
Validation loss: 1.9989143712546236

Epoch: 5| Step: 9
Training loss: 2.044646739959717
Validation loss: 1.9885311101072578

Epoch: 5| Step: 10
Training loss: 2.088940382003784
Validation loss: 1.9935134931277203

Epoch: 191| Step: 0
Training loss: 1.9836313724517822
Validation loss: 1.9782863304179201

Epoch: 5| Step: 1
Training loss: 2.0616302490234375
Validation loss: 1.9894173478567472

Epoch: 5| Step: 2
Training loss: 1.9631353616714478
Validation loss: 1.9699342814824914

Epoch: 5| Step: 3
Training loss: 1.916482925415039
Validation loss: 1.9951129472383888

Epoch: 5| Step: 4
Training loss: 1.611188292503357
Validation loss: 2.0030506657015894

Epoch: 5| Step: 5
Training loss: 2.016724109649658
Validation loss: 2.001870737280897

Epoch: 5| Step: 6
Training loss: 2.0951340198516846
Validation loss: 1.9753244794825071

Epoch: 5| Step: 7
Training loss: 2.1853389739990234
Validation loss: 1.9777563182256555

Epoch: 5| Step: 8
Training loss: 1.9982417821884155
Validation loss: 1.9743586842731764

Epoch: 5| Step: 9
Training loss: 1.828985571861267
Validation loss: 1.9813962687728226

Epoch: 5| Step: 10
Training loss: 1.8575024604797363
Validation loss: 1.9863967382779686

Epoch: 192| Step: 0
Training loss: 1.5047365427017212
Validation loss: 1.9740074898606987

Epoch: 5| Step: 1
Training loss: 1.8279831409454346
Validation loss: 1.9937575632526028

Epoch: 5| Step: 2
Training loss: 1.4323618412017822
Validation loss: 2.014316903647556

Epoch: 5| Step: 3
Training loss: 2.25022292137146
Validation loss: 2.0057949532744703

Epoch: 5| Step: 4
Training loss: 1.5715999603271484
Validation loss: 1.988005466358636

Epoch: 5| Step: 5
Training loss: 2.2583632469177246
Validation loss: 1.9807310232552149

Epoch: 5| Step: 6
Training loss: 2.338392496109009
Validation loss: 2.0068132569712978

Epoch: 5| Step: 7
Training loss: 1.432973861694336
Validation loss: 2.006973989548222

Epoch: 5| Step: 8
Training loss: 2.44575834274292
Validation loss: 2.0223115272419427

Epoch: 5| Step: 9
Training loss: 2.0416922569274902
Validation loss: 2.007601013747595

Epoch: 5| Step: 10
Training loss: 2.431910514831543
Validation loss: 2.014017112793461

Epoch: 193| Step: 0
Training loss: 2.03472900390625
Validation loss: 2.031640378377771

Epoch: 5| Step: 1
Training loss: 2.3075013160705566
Validation loss: 2.0282259653973322

Epoch: 5| Step: 2
Training loss: 1.7181475162506104
Validation loss: 2.0079949132857786

Epoch: 5| Step: 3
Training loss: 1.896537184715271
Validation loss: 2.0149904502335416

Epoch: 5| Step: 4
Training loss: 1.4177640676498413
Validation loss: 2.0383717167762017

Epoch: 5| Step: 5
Training loss: 2.125406265258789
Validation loss: 2.016635711475085

Epoch: 5| Step: 6
Training loss: 2.2562057971954346
Validation loss: 2.0248951527380172

Epoch: 5| Step: 7
Training loss: 1.3933852910995483
Validation loss: 2.0399331174870974

Epoch: 5| Step: 8
Training loss: 1.7950832843780518
Validation loss: 1.993704447182276

Epoch: 5| Step: 9
Training loss: 2.4560248851776123
Validation loss: 2.049706476990895

Epoch: 5| Step: 10
Training loss: 1.7776169776916504
Validation loss: 1.9995622839978946

Epoch: 194| Step: 0
Training loss: 2.0512213706970215
Validation loss: 1.9929049527773293

Epoch: 5| Step: 1
Training loss: 2.154843330383301
Validation loss: 1.977298705808578

Epoch: 5| Step: 2
Training loss: 2.0908398628234863
Validation loss: 2.003521632122737

Epoch: 5| Step: 3
Training loss: 1.9787695407867432
Validation loss: 2.032332918977225

Epoch: 5| Step: 4
Training loss: 2.3728458881378174
Validation loss: 2.003385402823007

Epoch: 5| Step: 5
Training loss: 1.7873817682266235
Validation loss: 1.9877812413759128

Epoch: 5| Step: 6
Training loss: 1.615250825881958
Validation loss: 2.012581443273893

Epoch: 5| Step: 7
Training loss: 2.2207484245300293
Validation loss: 2.0310967763264975

Epoch: 5| Step: 8
Training loss: 1.393477439880371
Validation loss: 2.0359859748553206

Epoch: 5| Step: 9
Training loss: 1.9903112649917603
Validation loss: 1.9975862477415351

Epoch: 5| Step: 10
Training loss: 1.720665454864502
Validation loss: 2.0262131896070255

Epoch: 195| Step: 0
Training loss: 1.5564053058624268
Validation loss: 2.0048636544135308

Epoch: 5| Step: 1
Training loss: 2.154465675354004
Validation loss: 1.987223566219371

Epoch: 5| Step: 2
Training loss: 1.2599372863769531
Validation loss: 1.9911837231728338

Epoch: 5| Step: 3
Training loss: 2.001422643661499
Validation loss: 2.0016605443851923

Epoch: 5| Step: 4
Training loss: 1.6273256540298462
Validation loss: 2.001647690291046

Epoch: 5| Step: 5
Training loss: 2.2416751384735107
Validation loss: 1.9902083899385186

Epoch: 5| Step: 6
Training loss: 2.582268476486206
Validation loss: 1.9679312911084903

Epoch: 5| Step: 7
Training loss: 1.8157135248184204
Validation loss: 2.00720480949648

Epoch: 5| Step: 8
Training loss: 2.3298680782318115
Validation loss: 1.9915495457187775

Epoch: 5| Step: 9
Training loss: 1.6915737390518188
Validation loss: 1.997601051484385

Epoch: 5| Step: 10
Training loss: 1.959430456161499
Validation loss: 1.9834029007983465

Epoch: 196| Step: 0
Training loss: 2.117363452911377
Validation loss: 2.0118343907017864

Epoch: 5| Step: 1
Training loss: 1.8642250299453735
Validation loss: 1.9878702445696759

Epoch: 5| Step: 2
Training loss: 1.8358322381973267
Validation loss: 2.0203996871107366

Epoch: 5| Step: 3
Training loss: 1.825646162033081
Validation loss: 1.9869299140027774

Epoch: 5| Step: 4
Training loss: 2.4788119792938232
Validation loss: 1.981007509334113

Epoch: 5| Step: 5
Training loss: 1.55112624168396
Validation loss: 1.9691071843588224

Epoch: 5| Step: 6
Training loss: 2.2706286907196045
Validation loss: 2.0013130377697688

Epoch: 5| Step: 7
Training loss: 1.4212744235992432
Validation loss: 1.9968408756358649

Epoch: 5| Step: 8
Training loss: 2.1745195388793945
Validation loss: 1.988820343889216

Epoch: 5| Step: 9
Training loss: 1.6339807510375977
Validation loss: 1.988927932195766

Epoch: 5| Step: 10
Training loss: 2.0562217235565186
Validation loss: 2.013844359305597

Epoch: 197| Step: 0
Training loss: 2.1069514751434326
Validation loss: 1.960444773397138

Epoch: 5| Step: 1
Training loss: 1.5749151706695557
Validation loss: 1.9791347390861922

Epoch: 5| Step: 2
Training loss: 1.2964681386947632
Validation loss: 1.982713532704179

Epoch: 5| Step: 3
Training loss: 1.4492934942245483
Validation loss: 2.0194178345382854

Epoch: 5| Step: 4
Training loss: 1.8726856708526611
Validation loss: 2.0019704731561805

Epoch: 5| Step: 5
Training loss: 2.11110258102417
Validation loss: 1.9898904664542085

Epoch: 5| Step: 6
Training loss: 1.528150200843811
Validation loss: 2.0207301749978015

Epoch: 5| Step: 7
Training loss: 2.668015956878662
Validation loss: 2.0102514682277555

Epoch: 5| Step: 8
Training loss: 2.394387722015381
Validation loss: 2.004908525815574

Epoch: 5| Step: 9
Training loss: 2.2916483879089355
Validation loss: 2.0277832451687066

Epoch: 5| Step: 10
Training loss: 1.8536862134933472
Validation loss: 2.0166150062314925

Epoch: 198| Step: 0
Training loss: 1.6383841037750244
Validation loss: 1.9901301014807917

Epoch: 5| Step: 1
Training loss: 2.235077142715454
Validation loss: 1.9951674425473778

Epoch: 5| Step: 2
Training loss: 1.2548327445983887
Validation loss: 1.9932561459079865

Epoch: 5| Step: 3
Training loss: 1.4822442531585693
Validation loss: 2.007624944051107

Epoch: 5| Step: 4
Training loss: 2.1792917251586914
Validation loss: 2.0098546269119426

Epoch: 5| Step: 5
Training loss: 2.253261089324951
Validation loss: 2.000764105909614

Epoch: 5| Step: 6
Training loss: 1.9200414419174194
Validation loss: 1.967778782690725

Epoch: 5| Step: 7
Training loss: 1.4404428005218506
Validation loss: 1.960530460521739

Epoch: 5| Step: 8
Training loss: 2.326021671295166
Validation loss: 2.0063508813099196

Epoch: 5| Step: 9
Training loss: 2.190824031829834
Validation loss: 1.9724786743041007

Epoch: 5| Step: 10
Training loss: 2.2072012424468994
Validation loss: 2.0175354019288094

Epoch: 199| Step: 0
Training loss: 2.1097917556762695
Validation loss: 1.9932295968455653

Epoch: 5| Step: 1
Training loss: 1.1908824443817139
Validation loss: 1.9746520544892998

Epoch: 5| Step: 2
Training loss: 1.8779996633529663
Validation loss: 2.0069783503009426

Epoch: 5| Step: 3
Training loss: 1.7982189655303955
Validation loss: 1.9844587477304603

Epoch: 5| Step: 4
Training loss: 1.6828014850616455
Validation loss: 1.9948974399156467

Epoch: 5| Step: 5
Training loss: 2.0086989402770996
Validation loss: 2.020160516103109

Epoch: 5| Step: 6
Training loss: 2.16920804977417
Validation loss: 2.0223843974451863

Epoch: 5| Step: 7
Training loss: 1.9473310708999634
Validation loss: 1.9782917627724268

Epoch: 5| Step: 8
Training loss: 1.9993743896484375
Validation loss: 2.0013850158260715

Epoch: 5| Step: 9
Training loss: 2.3867154121398926
Validation loss: 1.9668312354754376

Epoch: 5| Step: 10
Training loss: 1.7908991575241089
Validation loss: 1.9923287668535787

Epoch: 200| Step: 0
Training loss: 2.0600037574768066
Validation loss: 1.9987216893062796

Epoch: 5| Step: 1
Training loss: 1.702519416809082
Validation loss: 1.9712088748972902

Epoch: 5| Step: 2
Training loss: 1.5918080806732178
Validation loss: 2.010552795984412

Epoch: 5| Step: 3
Training loss: 1.4069372415542603
Validation loss: 2.018377152822351

Epoch: 5| Step: 4
Training loss: 1.7068376541137695
Validation loss: 2.0151014712549027

Epoch: 5| Step: 5
Training loss: 1.875239610671997
Validation loss: 1.987359582736928

Epoch: 5| Step: 6
Training loss: 2.0010030269622803
Validation loss: 2.0042026145483858

Epoch: 5| Step: 7
Training loss: 2.7779037952423096
Validation loss: 2.035740917728793

Epoch: 5| Step: 8
Training loss: 2.204285144805908
Validation loss: 1.98775069175228

Epoch: 5| Step: 9
Training loss: 1.7727937698364258
Validation loss: 2.0098649212109145

Epoch: 5| Step: 10
Training loss: 1.8067301511764526
Validation loss: 1.9934450272590882

Epoch: 201| Step: 0
Training loss: 1.7251096963882446
Validation loss: 2.0056474798469135

Epoch: 5| Step: 1
Training loss: 1.6767314672470093
Validation loss: 1.987312529676704

Epoch: 5| Step: 2
Training loss: 2.1055994033813477
Validation loss: 2.0057814633974465

Epoch: 5| Step: 3
Training loss: 1.7435925006866455
Validation loss: 2.0037585535357074

Epoch: 5| Step: 4
Training loss: 1.7414970397949219
Validation loss: 1.9912425112980667

Epoch: 5| Step: 5
Training loss: 2.1344048976898193
Validation loss: 1.9709041041712607

Epoch: 5| Step: 6
Training loss: 2.2267699241638184
Validation loss: 1.969985846550234

Epoch: 5| Step: 7
Training loss: 2.3267626762390137
Validation loss: 1.9789203546380485

Epoch: 5| Step: 8
Training loss: 1.9143898487091064
Validation loss: 1.9959556261698406

Epoch: 5| Step: 9
Training loss: 1.2816379070281982
Validation loss: 1.9972856172951319

Epoch: 5| Step: 10
Training loss: 2.1704607009887695
Validation loss: 1.9898371235016854

Epoch: 202| Step: 0
Training loss: 1.984838843345642
Validation loss: 1.991525778206446

Epoch: 5| Step: 1
Training loss: 1.400935173034668
Validation loss: 1.999607188727266

Epoch: 5| Step: 2
Training loss: 1.7526479959487915
Validation loss: 2.0181247521472234

Epoch: 5| Step: 3
Training loss: 1.9152460098266602
Validation loss: 2.018577147555608

Epoch: 5| Step: 4
Training loss: 1.898552656173706
Validation loss: 2.0035895378358903

Epoch: 5| Step: 5
Training loss: 2.051095485687256
Validation loss: 1.9834562578508932

Epoch: 5| Step: 6
Training loss: 1.926926851272583
Validation loss: 2.000553843795612

Epoch: 5| Step: 7
Training loss: 2.604039430618286
Validation loss: 2.003853451821112

Epoch: 5| Step: 8
Training loss: 1.9147577285766602
Validation loss: 2.0042360277586084

Epoch: 5| Step: 9
Training loss: 1.5687153339385986
Validation loss: 2.0221573460486626

Epoch: 5| Step: 10
Training loss: 2.138733386993408
Validation loss: 2.021307106940977

Epoch: 203| Step: 0
Training loss: 2.2583911418914795
Validation loss: 1.985380837994237

Epoch: 5| Step: 1
Training loss: 1.7401840686798096
Validation loss: 2.0026111218237106

Epoch: 5| Step: 2
Training loss: 1.6493381261825562
Validation loss: 1.9911192501744917

Epoch: 5| Step: 3
Training loss: 2.257232666015625
Validation loss: 1.9984727341641662

Epoch: 5| Step: 4
Training loss: 2.252016067504883
Validation loss: 2.000076723355119

Epoch: 5| Step: 5
Training loss: 1.4189833402633667
Validation loss: 2.012126479097592

Epoch: 5| Step: 6
Training loss: 2.03999924659729
Validation loss: 2.0025521939800632

Epoch: 5| Step: 7
Training loss: 2.3438808917999268
Validation loss: 1.9919011746683428

Epoch: 5| Step: 8
Training loss: 1.6749553680419922
Validation loss: 1.9849263621914772

Epoch: 5| Step: 9
Training loss: 1.5278855562210083
Validation loss: 1.981736736912881

Epoch: 5| Step: 10
Training loss: 1.706181526184082
Validation loss: 1.9784605041626961

Epoch: 204| Step: 0
Training loss: 1.7951240539550781
Validation loss: 1.9947573369549167

Epoch: 5| Step: 1
Training loss: 1.3454087972640991
Validation loss: 1.9839244401583107

Epoch: 5| Step: 2
Training loss: 1.7320013046264648
Validation loss: 2.0101742411172516

Epoch: 5| Step: 3
Training loss: 2.0948009490966797
Validation loss: 1.9906136758865849

Epoch: 5| Step: 4
Training loss: 1.6193153858184814
Validation loss: 2.013083505374129

Epoch: 5| Step: 5
Training loss: 2.038144588470459
Validation loss: 2.029020917031073

Epoch: 5| Step: 6
Training loss: 1.9259748458862305
Validation loss: 2.0070568182135142

Epoch: 5| Step: 7
Training loss: 1.8697483539581299
Validation loss: 2.0018145166417605

Epoch: 5| Step: 8
Training loss: 2.290933609008789
Validation loss: 1.9985653815730926

Epoch: 5| Step: 9
Training loss: 2.0696418285369873
Validation loss: 1.9917225299342987

Epoch: 5| Step: 10
Training loss: 2.205711841583252
Validation loss: 2.0109969774881997

Epoch: 205| Step: 0
Training loss: 1.7359144687652588
Validation loss: 2.018110562396306

Epoch: 5| Step: 1
Training loss: 1.985750436782837
Validation loss: 2.0049407635965655

Epoch: 5| Step: 2
Training loss: 2.095008611679077
Validation loss: 2.002091943576772

Epoch: 5| Step: 3
Training loss: 1.8835499286651611
Validation loss: 2.0057286985458864

Epoch: 5| Step: 4
Training loss: 1.9247255325317383
Validation loss: 1.9747110669330885

Epoch: 5| Step: 5
Training loss: 1.9478477239608765
Validation loss: 1.9542567396676669

Epoch: 5| Step: 6
Training loss: 1.9896621704101562
Validation loss: 1.9966791932300856

Epoch: 5| Step: 7
Training loss: 1.553648591041565
Validation loss: 1.9800801815525177

Epoch: 5| Step: 8
Training loss: 1.480293869972229
Validation loss: 2.0168854485275927

Epoch: 5| Step: 9
Training loss: 1.7426538467407227
Validation loss: 2.0143826443661927

Epoch: 5| Step: 10
Training loss: 2.8251452445983887
Validation loss: 1.9896478704226914

Epoch: 206| Step: 0
Training loss: 2.6696066856384277
Validation loss: 1.9991535012440016

Epoch: 5| Step: 1
Training loss: 1.9592599868774414
Validation loss: 2.00153176758879

Epoch: 5| Step: 2
Training loss: 1.373051643371582
Validation loss: 1.9783753297662223

Epoch: 5| Step: 3
Training loss: 1.6537507772445679
Validation loss: 1.9933634727231917

Epoch: 5| Step: 4
Training loss: 2.2178473472595215
Validation loss: 1.9858868429737706

Epoch: 5| Step: 5
Training loss: 1.8794405460357666
Validation loss: 1.9950637009836012

Epoch: 5| Step: 6
Training loss: 2.1651229858398438
Validation loss: 1.9956720964882964

Epoch: 5| Step: 7
Training loss: 1.6059839725494385
Validation loss: 1.9895038220190233

Epoch: 5| Step: 8
Training loss: 1.9560645818710327
Validation loss: 2.0009248000319286

Epoch: 5| Step: 9
Training loss: 1.471217155456543
Validation loss: 2.002027101414178

Epoch: 5| Step: 10
Training loss: 2.075227975845337
Validation loss: 2.0077412564267396

Epoch: 207| Step: 0
Training loss: 1.4333091974258423
Validation loss: 2.004012107849121

Epoch: 5| Step: 1
Training loss: 2.0471267700195312
Validation loss: 2.014276490416578

Epoch: 5| Step: 2
Training loss: 1.9650135040283203
Validation loss: 2.0255854065700243

Epoch: 5| Step: 3
Training loss: 1.4730666875839233
Validation loss: 2.009510924739222

Epoch: 5| Step: 4
Training loss: 1.7034202814102173
Validation loss: 2.0214961856924076

Epoch: 5| Step: 5
Training loss: 2.2037901878356934
Validation loss: 1.9929765988421697

Epoch: 5| Step: 6
Training loss: 1.3818005323410034
Validation loss: 2.0360866849140455

Epoch: 5| Step: 7
Training loss: 2.252713918685913
Validation loss: 1.9947094609660487

Epoch: 5| Step: 8
Training loss: 1.858917474746704
Validation loss: 2.033828285432631

Epoch: 5| Step: 9
Training loss: 2.241598129272461
Validation loss: 2.0141854440012286

Epoch: 5| Step: 10
Training loss: 2.369138717651367
Validation loss: 2.0199435026414934

Epoch: 208| Step: 0
Training loss: 1.9127511978149414
Validation loss: 2.014956480713301

Epoch: 5| Step: 1
Training loss: 2.2337920665740967
Validation loss: 2.0276765528545586

Epoch: 5| Step: 2
Training loss: 1.6420528888702393
Validation loss: 2.0132892862443

Epoch: 5| Step: 3
Training loss: 2.015021800994873
Validation loss: 1.986902649684619

Epoch: 5| Step: 4
Training loss: 2.1108081340789795
Validation loss: 1.9586229631977696

Epoch: 5| Step: 5
Training loss: 2.122527837753296
Validation loss: 1.9916139418079006

Epoch: 5| Step: 6
Training loss: 1.558945894241333
Validation loss: 1.9976127198947373

Epoch: 5| Step: 7
Training loss: 1.6020584106445312
Validation loss: 1.9834133476339362

Epoch: 5| Step: 8
Training loss: 1.877431869506836
Validation loss: 2.0207796122438166

Epoch: 5| Step: 9
Training loss: 1.786816954612732
Validation loss: 1.9837401707967122

Epoch: 5| Step: 10
Training loss: 2.3014605045318604
Validation loss: 1.9793922811426141

Epoch: 209| Step: 0
Training loss: 1.7701656818389893
Validation loss: 1.9926694567485521

Epoch: 5| Step: 1
Training loss: 1.5927318334579468
Validation loss: 1.9974194136998986

Epoch: 5| Step: 2
Training loss: 1.7412948608398438
Validation loss: 1.99867828430668

Epoch: 5| Step: 3
Training loss: 1.8041751384735107
Validation loss: 1.984754745678235

Epoch: 5| Step: 4
Training loss: 1.5636038780212402
Validation loss: 1.9910609927228702

Epoch: 5| Step: 5
Training loss: 1.9889323711395264
Validation loss: 2.010236273529709

Epoch: 5| Step: 6
Training loss: 2.5213351249694824
Validation loss: 2.01302005398658

Epoch: 5| Step: 7
Training loss: 2.122049331665039
Validation loss: 1.9975646362509778

Epoch: 5| Step: 8
Training loss: 1.7282193899154663
Validation loss: 2.0204151727819957

Epoch: 5| Step: 9
Training loss: 2.019503116607666
Validation loss: 2.031748697321902

Epoch: 5| Step: 10
Training loss: 1.842768669128418
Validation loss: 2.011737249230826

Epoch: 210| Step: 0
Training loss: 1.5794366598129272
Validation loss: 1.9918656297909316

Epoch: 5| Step: 1
Training loss: 1.417741060256958
Validation loss: 2.0196230078256256

Epoch: 5| Step: 2
Training loss: 1.4996446371078491
Validation loss: 2.0188567510215183

Epoch: 5| Step: 3
Training loss: 2.0657317638397217
Validation loss: 1.9814455406640166

Epoch: 5| Step: 4
Training loss: 1.4861605167388916
Validation loss: 2.004598996972525

Epoch: 5| Step: 5
Training loss: 2.44148850440979
Validation loss: 1.9743200989179714

Epoch: 5| Step: 6
Training loss: 2.280219316482544
Validation loss: 2.0216411570067048

Epoch: 5| Step: 7
Training loss: 1.74506413936615
Validation loss: 2.0001911181275562

Epoch: 5| Step: 8
Training loss: 1.8080345392227173
Validation loss: 1.9959319714576966

Epoch: 5| Step: 9
Training loss: 2.435516357421875
Validation loss: 1.9978660268168296

Epoch: 5| Step: 10
Training loss: 2.0483438968658447
Validation loss: 2.049065759105067

Epoch: 211| Step: 0
Training loss: 2.489226818084717
Validation loss: 1.996914130385204

Epoch: 5| Step: 1
Training loss: 1.6564280986785889
Validation loss: 1.9948669364375453

Epoch: 5| Step: 2
Training loss: 1.4538427591323853
Validation loss: 2.012417862492223

Epoch: 5| Step: 3
Training loss: 2.0439999103546143
Validation loss: 1.995894657668247

Epoch: 5| Step: 4
Training loss: 1.9364326000213623
Validation loss: 1.9777307638558008

Epoch: 5| Step: 5
Training loss: 1.5983749628067017
Validation loss: 2.015699414796727

Epoch: 5| Step: 6
Training loss: 2.092616558074951
Validation loss: 2.006782788102345

Epoch: 5| Step: 7
Training loss: 1.9934272766113281
Validation loss: 2.007970822754727

Epoch: 5| Step: 8
Training loss: 1.5677191019058228
Validation loss: 2.0203270719897364

Epoch: 5| Step: 9
Training loss: 1.9394121170043945
Validation loss: 2.0074289280881166

Epoch: 5| Step: 10
Training loss: 2.1234283447265625
Validation loss: 2.002323163452969

Epoch: 212| Step: 0
Training loss: 1.5753545761108398
Validation loss: 2.0239226177174556

Epoch: 5| Step: 1
Training loss: 2.544889450073242
Validation loss: 2.0174668194145284

Epoch: 5| Step: 2
Training loss: 2.1151843070983887
Validation loss: 1.994375991564925

Epoch: 5| Step: 3
Training loss: 1.9887034893035889
Validation loss: 1.9825117626497823

Epoch: 5| Step: 4
Training loss: 1.914947509765625
Validation loss: 2.00660143744561

Epoch: 5| Step: 5
Training loss: 2.334160327911377
Validation loss: 1.9850525215107908

Epoch: 5| Step: 6
Training loss: 1.821347951889038
Validation loss: 2.0109328428904214

Epoch: 5| Step: 7
Training loss: 1.8837484121322632
Validation loss: 1.9901460588619273

Epoch: 5| Step: 8
Training loss: 1.4215710163116455
Validation loss: 2.0209561432561567

Epoch: 5| Step: 9
Training loss: 1.720942735671997
Validation loss: 2.0455684918229298

Epoch: 5| Step: 10
Training loss: 1.4003673791885376
Validation loss: 2.0228342856130292

Epoch: 213| Step: 0
Training loss: 2.258706569671631
Validation loss: 2.0036358410312283

Epoch: 5| Step: 1
Training loss: 2.0569591522216797
Validation loss: 2.0130147216140584

Epoch: 5| Step: 2
Training loss: 1.564690351486206
Validation loss: 2.0220110877867667

Epoch: 5| Step: 3
Training loss: 1.6643693447113037
Validation loss: 2.036689119954263

Epoch: 5| Step: 4
Training loss: 1.9021947383880615
Validation loss: 1.9997737894776046

Epoch: 5| Step: 5
Training loss: 1.8364906311035156
Validation loss: 1.9758957816708473

Epoch: 5| Step: 6
Training loss: 2.236450672149658
Validation loss: 1.9865499363150647

Epoch: 5| Step: 7
Training loss: 1.7306842803955078
Validation loss: 1.9966134461023475

Epoch: 5| Step: 8
Training loss: 2.1375818252563477
Validation loss: 2.0055359717338317

Epoch: 5| Step: 9
Training loss: 2.0888354778289795
Validation loss: 1.9651445342648415

Epoch: 5| Step: 10
Training loss: 1.4043149948120117
Validation loss: 1.9970399705312585

Epoch: 214| Step: 0
Training loss: 1.8556983470916748
Validation loss: 2.010862555555118

Epoch: 5| Step: 1
Training loss: 1.1542260646820068
Validation loss: 2.02297955430964

Epoch: 5| Step: 2
Training loss: 1.4471619129180908
Validation loss: 2.053754416845178

Epoch: 5| Step: 3
Training loss: 2.3588411808013916
Validation loss: 2.027544749680386

Epoch: 5| Step: 4
Training loss: 1.6207828521728516
Validation loss: 2.0416648951909875

Epoch: 5| Step: 5
Training loss: 1.9424337148666382
Validation loss: 2.013824357781359

Epoch: 5| Step: 6
Training loss: 2.034801483154297
Validation loss: 2.006765816801338

Epoch: 5| Step: 7
Training loss: 2.156857490539551
Validation loss: 2.0220176776250205

Epoch: 5| Step: 8
Training loss: 1.4789323806762695
Validation loss: 2.019806718313566

Epoch: 5| Step: 9
Training loss: 2.2974724769592285
Validation loss: 1.996794613458777

Epoch: 5| Step: 10
Training loss: 2.5485527515411377
Validation loss: 2.0306356773581555

Epoch: 215| Step: 0
Training loss: 1.5772508382797241
Validation loss: 1.9593831672463367

Epoch: 5| Step: 1
Training loss: 2.2450263500213623
Validation loss: 2.003266872898225

Epoch: 5| Step: 2
Training loss: 1.7904813289642334
Validation loss: 1.963988688684279

Epoch: 5| Step: 3
Training loss: 1.9224507808685303
Validation loss: 1.9992754382471885

Epoch: 5| Step: 4
Training loss: 1.861631155014038
Validation loss: 1.9902975828416887

Epoch: 5| Step: 5
Training loss: 1.8301435708999634
Validation loss: 1.988734096609136

Epoch: 5| Step: 6
Training loss: 2.0040841102600098
Validation loss: 2.0274257813730547

Epoch: 5| Step: 7
Training loss: 1.9832395315170288
Validation loss: 2.0357675578004573

Epoch: 5| Step: 8
Training loss: 2.253152370452881
Validation loss: 2.0247407831171507

Epoch: 5| Step: 9
Training loss: 2.020110845565796
Validation loss: 2.050095715830403

Epoch: 5| Step: 10
Training loss: 1.2806243896484375
Validation loss: 2.020731105599352

Epoch: 216| Step: 0
Training loss: 1.3548076152801514
Validation loss: 2.041495746181857

Epoch: 5| Step: 1
Training loss: 1.7435346841812134
Validation loss: 2.005784680766444

Epoch: 5| Step: 2
Training loss: 1.9902946949005127
Validation loss: 2.000751764543595

Epoch: 5| Step: 3
Training loss: 1.6205856800079346
Validation loss: 2.0065159669486423

Epoch: 5| Step: 4
Training loss: 2.1090152263641357
Validation loss: 2.007576673261581

Epoch: 5| Step: 5
Training loss: 2.072673797607422
Validation loss: 2.002423809420678

Epoch: 5| Step: 6
Training loss: 1.6787713766098022
Validation loss: 2.002706535400883

Epoch: 5| Step: 7
Training loss: 2.1093811988830566
Validation loss: 1.974736645657529

Epoch: 5| Step: 8
Training loss: 1.8573417663574219
Validation loss: 2.019155445919242

Epoch: 5| Step: 9
Training loss: 1.8787933588027954
Validation loss: 1.9863668667372836

Epoch: 5| Step: 10
Training loss: 2.115262031555176
Validation loss: 1.9968542616854432

Epoch: 217| Step: 0
Training loss: 1.5128034353256226
Validation loss: 1.9707506369518977

Epoch: 5| Step: 1
Training loss: 2.1520283222198486
Validation loss: 1.9952045563728578

Epoch: 5| Step: 2
Training loss: 1.8273162841796875
Validation loss: 1.996278162925474

Epoch: 5| Step: 3
Training loss: 1.4862900972366333
Validation loss: 1.9864924787193217

Epoch: 5| Step: 4
Training loss: 2.242102861404419
Validation loss: 1.985540610487743

Epoch: 5| Step: 5
Training loss: 2.0551717281341553
Validation loss: 2.034625332842591

Epoch: 5| Step: 6
Training loss: 1.7032066583633423
Validation loss: 2.0030651451438986

Epoch: 5| Step: 7
Training loss: 1.8976821899414062
Validation loss: 2.011338610802927

Epoch: 5| Step: 8
Training loss: 1.4019057750701904
Validation loss: 2.038402108735936

Epoch: 5| Step: 9
Training loss: 2.5583770275115967
Validation loss: 2.0613876978556314

Epoch: 5| Step: 10
Training loss: 1.8130155801773071
Validation loss: 2.004757786309847

Epoch: 218| Step: 0
Training loss: 1.4739023447036743
Validation loss: 2.031151984327583

Epoch: 5| Step: 1
Training loss: 2.0641589164733887
Validation loss: 2.0175613459720405

Epoch: 5| Step: 2
Training loss: 1.5379530191421509
Validation loss: 2.01752047897667

Epoch: 5| Step: 3
Training loss: 1.5406728982925415
Validation loss: 1.996985202194542

Epoch: 5| Step: 4
Training loss: 2.2090156078338623
Validation loss: 2.008864487371137

Epoch: 5| Step: 5
Training loss: 1.4296238422393799
Validation loss: 2.013932466506958

Epoch: 5| Step: 6
Training loss: 2.427978992462158
Validation loss: 1.9871457712624663

Epoch: 5| Step: 7
Training loss: 1.539090871810913
Validation loss: 1.9905655768609816

Epoch: 5| Step: 8
Training loss: 2.1051387786865234
Validation loss: 2.0205543964139876

Epoch: 5| Step: 9
Training loss: 2.1381678581237793
Validation loss: 2.0065971318111626

Epoch: 5| Step: 10
Training loss: 2.2070958614349365
Validation loss: 1.9859485523675078

Epoch: 219| Step: 0
Training loss: 2.3066673278808594
Validation loss: 2.000358372606257

Epoch: 5| Step: 1
Training loss: 1.9127649068832397
Validation loss: 2.0038897324633855

Epoch: 5| Step: 2
Training loss: 1.5252104997634888
Validation loss: 1.9711831256907473

Epoch: 5| Step: 3
Training loss: 1.7967536449432373
Validation loss: 1.9738568349551129

Epoch: 5| Step: 4
Training loss: 1.8951467275619507
Validation loss: 2.0000117337831886

Epoch: 5| Step: 5
Training loss: 1.863011121749878
Validation loss: 1.9927324787262948

Epoch: 5| Step: 6
Training loss: 2.8006844520568848
Validation loss: 1.9929968887759792

Epoch: 5| Step: 7
Training loss: 1.3320112228393555
Validation loss: 2.008519544396349

Epoch: 5| Step: 8
Training loss: 1.6923882961273193
Validation loss: 1.9873269014461066

Epoch: 5| Step: 9
Training loss: 1.6689002513885498
Validation loss: 1.9998619838427472

Epoch: 5| Step: 10
Training loss: 1.8941164016723633
Validation loss: 1.9822095465916458

Epoch: 220| Step: 0
Training loss: 2.0358424186706543
Validation loss: 1.997942014407086

Epoch: 5| Step: 1
Training loss: 1.7746527194976807
Validation loss: 2.0039090674410582

Epoch: 5| Step: 2
Training loss: 2.0974483489990234
Validation loss: 2.0018130694666216

Epoch: 5| Step: 3
Training loss: 1.4481843709945679
Validation loss: 2.0162345517066216

Epoch: 5| Step: 4
Training loss: 1.9696975946426392
Validation loss: 2.0070583615251767

Epoch: 5| Step: 5
Training loss: 2.1377851963043213
Validation loss: 2.007374737852363

Epoch: 5| Step: 6
Training loss: 1.2473076581954956
Validation loss: 1.9782292176318426

Epoch: 5| Step: 7
Training loss: 2.331437826156616
Validation loss: 2.0103771327644266

Epoch: 5| Step: 8
Training loss: 2.13808012008667
Validation loss: 2.002839590913506

Epoch: 5| Step: 9
Training loss: 1.2977287769317627
Validation loss: 1.9904676534796273

Epoch: 5| Step: 10
Training loss: 1.8781267404556274
Validation loss: 2.0452616727480324

Epoch: 221| Step: 0
Training loss: 2.434427261352539
Validation loss: 2.003525495529175

Epoch: 5| Step: 1
Training loss: 1.654882788658142
Validation loss: 2.0227533796782136

Epoch: 5| Step: 2
Training loss: 1.4556962251663208
Validation loss: 2.003530676646899

Epoch: 5| Step: 3
Training loss: 2.322056293487549
Validation loss: 2.0001449892597813

Epoch: 5| Step: 4
Training loss: 1.870035171508789
Validation loss: 2.013518148852933

Epoch: 5| Step: 5
Training loss: 1.41532564163208
Validation loss: 1.9855529556992233

Epoch: 5| Step: 6
Training loss: 1.6500580310821533
Validation loss: 2.018941487035444

Epoch: 5| Step: 7
Training loss: 2.042480945587158
Validation loss: 2.008957983345114

Epoch: 5| Step: 8
Training loss: 2.1120643615722656
Validation loss: 2.0339281892263763

Epoch: 5| Step: 9
Training loss: 1.9472334384918213
Validation loss: 2.0199689096020115

Epoch: 5| Step: 10
Training loss: 1.4967708587646484
Validation loss: 2.0349652126271236

Epoch: 222| Step: 0
Training loss: 1.921608567237854
Validation loss: 2.028093248285273

Epoch: 5| Step: 1
Training loss: 1.6463840007781982
Validation loss: 2.004484648345619

Epoch: 5| Step: 2
Training loss: 1.484057068824768
Validation loss: 2.024520668932187

Epoch: 5| Step: 3
Training loss: 1.818434715270996
Validation loss: 2.023176770056448

Epoch: 5| Step: 4
Training loss: 2.0817017555236816
Validation loss: 2.030506549342986

Epoch: 5| Step: 5
Training loss: 1.9268379211425781
Validation loss: 1.9986527427550285

Epoch: 5| Step: 6
Training loss: 1.9792201519012451
Validation loss: 1.9868227307514479

Epoch: 5| Step: 7
Training loss: 1.815917730331421
Validation loss: 1.9986573701263757

Epoch: 5| Step: 8
Training loss: 1.9685472249984741
Validation loss: 1.977699669458533

Epoch: 5| Step: 9
Training loss: 1.9802430868148804
Validation loss: 2.0119981022291284

Epoch: 5| Step: 10
Training loss: 1.94468355178833
Validation loss: 2.017147987119613

Epoch: 223| Step: 0
Training loss: 1.7713483572006226
Validation loss: 2.010101410650438

Epoch: 5| Step: 1
Training loss: 1.7004884481430054
Validation loss: 1.9980713141861783

Epoch: 5| Step: 2
Training loss: 1.5911293029785156
Validation loss: 1.9913213022293583

Epoch: 5| Step: 3
Training loss: 1.9616674184799194
Validation loss: 1.9793550788715322

Epoch: 5| Step: 4
Training loss: 1.1882572174072266
Validation loss: 1.9847485147496706

Epoch: 5| Step: 5
Training loss: 1.7218033075332642
Validation loss: 1.9946725932500695

Epoch: 5| Step: 6
Training loss: 2.010418653488159
Validation loss: 2.005151548693257

Epoch: 5| Step: 7
Training loss: 1.8914291858673096
Validation loss: 1.9966244159206268

Epoch: 5| Step: 8
Training loss: 2.547701358795166
Validation loss: 1.9842965423419912

Epoch: 5| Step: 9
Training loss: 1.779362440109253
Validation loss: 1.9745534466158958

Epoch: 5| Step: 10
Training loss: 2.279608964920044
Validation loss: 1.99687546812078

Epoch: 224| Step: 0
Training loss: 1.4025088548660278
Validation loss: 2.0319861878630934

Epoch: 5| Step: 1
Training loss: 1.8544273376464844
Validation loss: 1.9930637049418625

Epoch: 5| Step: 2
Training loss: 2.3438737392425537
Validation loss: 1.9886703952666251

Epoch: 5| Step: 3
Training loss: 2.2454845905303955
Validation loss: 1.9943520228068035

Epoch: 5| Step: 4
Training loss: 1.5347572565078735
Validation loss: 1.9948356177217217

Epoch: 5| Step: 5
Training loss: 1.717797040939331
Validation loss: 1.9815497270194433

Epoch: 5| Step: 6
Training loss: 1.7650301456451416
Validation loss: 1.9920323766687864

Epoch: 5| Step: 7
Training loss: 2.2084150314331055
Validation loss: 1.9934917496096702

Epoch: 5| Step: 8
Training loss: 1.5472005605697632
Validation loss: 1.9807825011591758

Epoch: 5| Step: 9
Training loss: 1.5095970630645752
Validation loss: 2.0214521731099775

Epoch: 5| Step: 10
Training loss: 2.1974401473999023
Validation loss: 1.9911196693297355

Epoch: 225| Step: 0
Training loss: 2.2822623252868652
Validation loss: 2.026000622780092

Epoch: 5| Step: 1
Training loss: 2.3621163368225098
Validation loss: 2.0153970295383083

Epoch: 5| Step: 2
Training loss: 2.2213990688323975
Validation loss: 2.0006713264731952

Epoch: 5| Step: 3
Training loss: 1.6298015117645264
Validation loss: 2.0018769323184924

Epoch: 5| Step: 4
Training loss: 1.5111027956008911
Validation loss: 1.9813969263466455

Epoch: 5| Step: 5
Training loss: 1.450986623764038
Validation loss: 2.0030338123280513

Epoch: 5| Step: 6
Training loss: 1.9739443063735962
Validation loss: 1.9742831107108825

Epoch: 5| Step: 7
Training loss: 1.8576555252075195
Validation loss: 2.0087809562683105

Epoch: 5| Step: 8
Training loss: 1.631598711013794
Validation loss: 2.01780209490048

Epoch: 5| Step: 9
Training loss: 1.56083083152771
Validation loss: 2.0021428984980427

Epoch: 5| Step: 10
Training loss: 1.911896824836731
Validation loss: 2.036597642847287

Epoch: 226| Step: 0
Training loss: 2.295863628387451
Validation loss: 1.9889403466255433

Epoch: 5| Step: 1
Training loss: 2.1326115131378174
Validation loss: 1.9674501598522227

Epoch: 5| Step: 2
Training loss: 1.6585931777954102
Validation loss: 1.9899352596652122

Epoch: 5| Step: 3
Training loss: 1.9918235540390015
Validation loss: 1.9956864772304412

Epoch: 5| Step: 4
Training loss: 1.7599337100982666
Validation loss: 1.9970579813885432

Epoch: 5| Step: 5
Training loss: 2.195955991744995
Validation loss: 1.9835101468588716

Epoch: 5| Step: 6
Training loss: 2.3989691734313965
Validation loss: 2.0024817964082122

Epoch: 5| Step: 7
Training loss: 1.782658338546753
Validation loss: 1.9947985026144213

Epoch: 5| Step: 8
Training loss: 1.1353132724761963
Validation loss: 1.9954045857152631

Epoch: 5| Step: 9
Training loss: 1.6403993368148804
Validation loss: 2.006974531758216

Epoch: 5| Step: 10
Training loss: 1.2062304019927979
Validation loss: 1.985904159084443

Epoch: 227| Step: 0
Training loss: 2.3430769443511963
Validation loss: 2.0290169818426973

Epoch: 5| Step: 1
Training loss: 1.858136773109436
Validation loss: 1.9734520117441814

Epoch: 5| Step: 2
Training loss: 1.644168496131897
Validation loss: 1.96156439089006

Epoch: 5| Step: 3
Training loss: 1.6220556497573853
Validation loss: 2.000794700396958

Epoch: 5| Step: 4
Training loss: 1.8874499797821045
Validation loss: 2.014695052177675

Epoch: 5| Step: 5
Training loss: 1.888811469078064
Validation loss: 1.9872378533886326

Epoch: 5| Step: 6
Training loss: 1.820119857788086
Validation loss: 1.9951613128826182

Epoch: 5| Step: 7
Training loss: 1.9032981395721436
Validation loss: 2.0015791257222495

Epoch: 5| Step: 8
Training loss: 1.2566277980804443
Validation loss: 1.9988248271326865

Epoch: 5| Step: 9
Training loss: 1.7599912881851196
Validation loss: 2.0168805788922053

Epoch: 5| Step: 10
Training loss: 2.380439519882202
Validation loss: 2.0019655484025196

Epoch: 228| Step: 0
Training loss: 1.3210856914520264
Validation loss: 1.9972391718177385

Epoch: 5| Step: 1
Training loss: 2.0226457118988037
Validation loss: 1.9737170024584698

Epoch: 5| Step: 2
Training loss: 1.7688572406768799
Validation loss: 2.003496286689594

Epoch: 5| Step: 3
Training loss: 2.142099380493164
Validation loss: 2.0158814948092223

Epoch: 5| Step: 4
Training loss: 1.9833078384399414
Validation loss: 2.0427661659897014

Epoch: 5| Step: 5
Training loss: 1.6029762029647827
Validation loss: 2.0172170926165838

Epoch: 5| Step: 6
Training loss: 1.6763795614242554
Validation loss: 2.0307847428065475

Epoch: 5| Step: 7
Training loss: 1.368385672569275
Validation loss: 2.031739442579208

Epoch: 5| Step: 8
Training loss: 2.472991943359375
Validation loss: 2.0135165017138243

Epoch: 5| Step: 9
Training loss: 1.7486079931259155
Validation loss: 2.0333420717588035

Epoch: 5| Step: 10
Training loss: 2.3357787132263184
Validation loss: 2.0024976345800583

Epoch: 229| Step: 0
Training loss: 2.135859251022339
Validation loss: 2.0221370009965796

Epoch: 5| Step: 1
Training loss: 1.7097365856170654
Validation loss: 2.013840453599089

Epoch: 5| Step: 2
Training loss: 1.4668266773223877
Validation loss: 2.0133198333042923

Epoch: 5| Step: 3
Training loss: 1.6675361394882202
Validation loss: 1.9866789540936869

Epoch: 5| Step: 4
Training loss: 1.781745195388794
Validation loss: 2.0286289517597487

Epoch: 5| Step: 5
Training loss: 1.4149210453033447
Validation loss: 1.9839009110645582

Epoch: 5| Step: 6
Training loss: 1.9651620388031006
Validation loss: 1.9834117492039998

Epoch: 5| Step: 7
Training loss: 2.2556471824645996
Validation loss: 1.971406562353975

Epoch: 5| Step: 8
Training loss: 2.0945637226104736
Validation loss: 2.0106059787093953

Epoch: 5| Step: 9
Training loss: 1.7247213125228882
Validation loss: 2.0219950381145684

Epoch: 5| Step: 10
Training loss: 2.0557940006256104
Validation loss: 2.0003768961916686

Epoch: 230| Step: 0
Training loss: 1.8826515674591064
Validation loss: 1.9871451290704871

Epoch: 5| Step: 1
Training loss: 1.5815913677215576
Validation loss: 1.9820568920463644

Epoch: 5| Step: 2
Training loss: 2.3444714546203613
Validation loss: 2.0177284632959673

Epoch: 5| Step: 3
Training loss: 2.34686279296875
Validation loss: 1.9791366233620593

Epoch: 5| Step: 4
Training loss: 1.6434720754623413
Validation loss: 1.969659036205661

Epoch: 5| Step: 5
Training loss: 1.5644813776016235
Validation loss: 2.0008496725431053

Epoch: 5| Step: 6
Training loss: 1.723081350326538
Validation loss: 1.973805860806537

Epoch: 5| Step: 7
Training loss: 1.761580467224121
Validation loss: 2.0086618008152133

Epoch: 5| Step: 8
Training loss: 1.746842384338379
Validation loss: 1.9897355623142694

Epoch: 5| Step: 9
Training loss: 1.8582652807235718
Validation loss: 2.0271978006568006

Epoch: 5| Step: 10
Training loss: 1.5867547988891602
Validation loss: 1.9799471952581917

Epoch: 231| Step: 0
Training loss: 2.4644787311553955
Validation loss: 2.0314594020125685

Epoch: 5| Step: 1
Training loss: 1.6459426879882812
Validation loss: 2.0220064514426777

Epoch: 5| Step: 2
Training loss: 1.2073450088500977
Validation loss: 2.0112688272230086

Epoch: 5| Step: 3
Training loss: 2.1549103260040283
Validation loss: 2.0231740628519366

Epoch: 5| Step: 4
Training loss: 1.7604042291641235
Validation loss: 2.0154619986011135

Epoch: 5| Step: 5
Training loss: 1.6938966512680054
Validation loss: 2.0081846714019775

Epoch: 5| Step: 6
Training loss: 1.3762584924697876
Validation loss: 1.9874223355324037

Epoch: 5| Step: 7
Training loss: 2.146085262298584
Validation loss: 1.9947112914054625

Epoch: 5| Step: 8
Training loss: 1.8601032495498657
Validation loss: 1.9971661080596268

Epoch: 5| Step: 9
Training loss: 2.0872554779052734
Validation loss: 2.0194539869985273

Epoch: 5| Step: 10
Training loss: 1.694417953491211
Validation loss: 2.0162625466623614

Epoch: 232| Step: 0
Training loss: 1.6199582815170288
Validation loss: 1.9807675192433019

Epoch: 5| Step: 1
Training loss: 1.879774808883667
Validation loss: 2.008080028718518

Epoch: 5| Step: 2
Training loss: 1.896523118019104
Validation loss: 2.001172960445445

Epoch: 5| Step: 3
Training loss: 1.5606372356414795
Validation loss: 2.011789532117946

Epoch: 5| Step: 4
Training loss: 2.1142098903656006
Validation loss: 1.9774150361296952

Epoch: 5| Step: 5
Training loss: 2.014845609664917
Validation loss: 1.9937878385666878

Epoch: 5| Step: 6
Training loss: 1.8277080059051514
Validation loss: 2.0157138070752545

Epoch: 5| Step: 7
Training loss: 1.8950351476669312
Validation loss: 1.9647780003086213

Epoch: 5| Step: 8
Training loss: 1.8645395040512085
Validation loss: 2.004380072316816

Epoch: 5| Step: 9
Training loss: 1.745269775390625
Validation loss: 1.9851053863443353

Epoch: 5| Step: 10
Training loss: 1.6999479532241821
Validation loss: 2.02474578221639

Epoch: 233| Step: 0
Training loss: 1.9109115600585938
Validation loss: 1.9945246686217606

Epoch: 5| Step: 1
Training loss: 2.207137107849121
Validation loss: 2.0114245594188733

Epoch: 5| Step: 2
Training loss: 2.257185459136963
Validation loss: 2.01792481125042

Epoch: 5| Step: 3
Training loss: 1.72331964969635
Validation loss: 1.9917632302930277

Epoch: 5| Step: 4
Training loss: 1.7560828924179077
Validation loss: 2.0069944807278213

Epoch: 5| Step: 5
Training loss: 1.4982588291168213
Validation loss: 2.028021567611284

Epoch: 5| Step: 6
Training loss: 2.0403990745544434
Validation loss: 2.03058656056722

Epoch: 5| Step: 7
Training loss: 1.1512010097503662
Validation loss: 2.0146280770660727

Epoch: 5| Step: 8
Training loss: 1.9494445323944092
Validation loss: 2.010891754140136

Epoch: 5| Step: 9
Training loss: 1.5229203701019287
Validation loss: 2.0070645398991083

Epoch: 5| Step: 10
Training loss: 2.319977283477783
Validation loss: 2.012054447204836

Epoch: 234| Step: 0
Training loss: 1.8907417058944702
Validation loss: 2.0107809574373308

Epoch: 5| Step: 1
Training loss: 1.66483473777771
Validation loss: 2.0059523544003888

Epoch: 5| Step: 2
Training loss: 1.7104008197784424
Validation loss: 1.9954520438307075

Epoch: 5| Step: 3
Training loss: 1.885263442993164
Validation loss: 1.9932943390261741

Epoch: 5| Step: 4
Training loss: 1.9332401752471924
Validation loss: 2.0199827840251308

Epoch: 5| Step: 5
Training loss: 2.1240901947021484
Validation loss: 1.9853207193395144

Epoch: 5| Step: 6
Training loss: 1.7991749048233032
Validation loss: 1.9917489610692507

Epoch: 5| Step: 7
Training loss: 1.7824780941009521
Validation loss: 2.023827938623326

Epoch: 5| Step: 8
Training loss: 1.8887287378311157
Validation loss: 1.9837207563461796

Epoch: 5| Step: 9
Training loss: 1.2202528715133667
Validation loss: 1.9716557405328239

Epoch: 5| Step: 10
Training loss: 2.1641290187835693
Validation loss: 2.002390476965135

Epoch: 235| Step: 0
Training loss: 1.6544663906097412
Validation loss: 1.9828164641575148

Epoch: 5| Step: 1
Training loss: 2.1614015102386475
Validation loss: 2.0016925847658547

Epoch: 5| Step: 2
Training loss: 1.7610712051391602
Validation loss: 2.026248892148336

Epoch: 5| Step: 3
Training loss: 2.0160605907440186
Validation loss: 1.9930507803475985

Epoch: 5| Step: 4
Training loss: 1.9503142833709717
Validation loss: 2.0237162754099858

Epoch: 5| Step: 5
Training loss: 1.950865387916565
Validation loss: 2.0378375668679514

Epoch: 5| Step: 6
Training loss: 1.746482491493225
Validation loss: 2.009999946881366

Epoch: 5| Step: 7
Training loss: 1.2718826532363892
Validation loss: 2.010829838373328

Epoch: 5| Step: 8
Training loss: 2.0976593494415283
Validation loss: 2.007069988917279

Epoch: 5| Step: 9
Training loss: 2.064127206802368
Validation loss: 2.0138555880515807

Epoch: 5| Step: 10
Training loss: 1.3691823482513428
Validation loss: 1.9926372112766388

Epoch: 236| Step: 0
Training loss: 1.4803996086120605
Validation loss: 2.0063505147093084

Epoch: 5| Step: 1
Training loss: 1.7783820629119873
Validation loss: 1.991858397760699

Epoch: 5| Step: 2
Training loss: 1.623673439025879
Validation loss: 1.99574113404879

Epoch: 5| Step: 3
Training loss: 1.6790615320205688
Validation loss: 2.022247004252608

Epoch: 5| Step: 4
Training loss: 2.3089046478271484
Validation loss: 1.9941948152357531

Epoch: 5| Step: 5
Training loss: 2.3873353004455566
Validation loss: 2.0177028256077922

Epoch: 5| Step: 6
Training loss: 1.9258426427841187
Validation loss: 1.9752573095342165

Epoch: 5| Step: 7
Training loss: 1.963209867477417
Validation loss: 2.010492524793071

Epoch: 5| Step: 8
Training loss: 1.5364617109298706
Validation loss: 2.030480736045427

Epoch: 5| Step: 9
Training loss: 1.847373604774475
Validation loss: 1.9925071129234888

Epoch: 5| Step: 10
Training loss: 1.5053212642669678
Validation loss: 2.0091314469614336

Epoch: 237| Step: 0
Training loss: 1.2871768474578857
Validation loss: 2.0111183940723376

Epoch: 5| Step: 1
Training loss: 2.0892627239227295
Validation loss: 1.9918627354406542

Epoch: 5| Step: 2
Training loss: 1.9142996072769165
Validation loss: 2.0121431389162616

Epoch: 5| Step: 3
Training loss: 1.3704715967178345
Validation loss: 1.9896679411652267

Epoch: 5| Step: 4
Training loss: 2.206512451171875
Validation loss: 2.015947990520026

Epoch: 5| Step: 5
Training loss: 1.778969168663025
Validation loss: 2.0102255728936966

Epoch: 5| Step: 6
Training loss: 1.714259386062622
Validation loss: 1.9888134310322423

Epoch: 5| Step: 7
Training loss: 1.9676334857940674
Validation loss: 2.005214173306701

Epoch: 5| Step: 8
Training loss: 1.8931665420532227
Validation loss: 2.012809461162936

Epoch: 5| Step: 9
Training loss: 1.9139502048492432
Validation loss: 2.0000579549420263

Epoch: 5| Step: 10
Training loss: 1.5755175352096558
Validation loss: 2.0303115370453044

Epoch: 238| Step: 0
Training loss: 2.034893751144409
Validation loss: 2.031684975470266

Epoch: 5| Step: 1
Training loss: 1.7844864130020142
Validation loss: 2.0380187598607873

Epoch: 5| Step: 2
Training loss: 1.330367922782898
Validation loss: 2.0474782579688617

Epoch: 5| Step: 3
Training loss: 1.9362421035766602
Validation loss: 2.0519799160700973

Epoch: 5| Step: 4
Training loss: 1.6429216861724854
Validation loss: 2.0152737530328895

Epoch: 5| Step: 5
Training loss: 1.950815200805664
Validation loss: 2.027594409963136

Epoch: 5| Step: 6
Training loss: 1.994140386581421
Validation loss: 2.0071495425316597

Epoch: 5| Step: 7
Training loss: 1.6759681701660156
Validation loss: 2.0047088669192408

Epoch: 5| Step: 8
Training loss: 2.1043295860290527
Validation loss: 1.9885310793435702

Epoch: 5| Step: 9
Training loss: 1.5355304479599
Validation loss: 1.985274334107676

Epoch: 5| Step: 10
Training loss: 2.0510857105255127
Validation loss: 1.9954219992442797

Epoch: 239| Step: 0
Training loss: 1.7719471454620361
Validation loss: 1.9866511744837607

Epoch: 5| Step: 1
Training loss: 1.4294198751449585
Validation loss: 2.0001383289214103

Epoch: 5| Step: 2
Training loss: 1.9667682647705078
Validation loss: 1.9979160242183234

Epoch: 5| Step: 3
Training loss: 2.238450527191162
Validation loss: 2.005133669863465

Epoch: 5| Step: 4
Training loss: 1.4664068222045898
Validation loss: 1.9946454955685524

Epoch: 5| Step: 5
Training loss: 2.325166702270508
Validation loss: 1.9926356359194684

Epoch: 5| Step: 6
Training loss: 1.3527507781982422
Validation loss: 1.995854296991902

Epoch: 5| Step: 7
Training loss: 2.032116174697876
Validation loss: 2.0277720882046606

Epoch: 5| Step: 8
Training loss: 1.8452308177947998
Validation loss: 2.01731732327451

Epoch: 5| Step: 9
Training loss: 1.4189703464508057
Validation loss: 2.007109506155855

Epoch: 5| Step: 10
Training loss: 2.026395797729492
Validation loss: 2.0281703651592298

Epoch: 240| Step: 0
Training loss: 1.8343452215194702
Validation loss: 2.00822187495488

Epoch: 5| Step: 1
Training loss: 2.456937313079834
Validation loss: 2.004891316095988

Epoch: 5| Step: 2
Training loss: 1.8913301229476929
Validation loss: 2.021673474260556

Epoch: 5| Step: 3
Training loss: 1.5465140342712402
Validation loss: 2.0019761054746565

Epoch: 5| Step: 4
Training loss: 1.4722096920013428
Validation loss: 1.9758677931242092

Epoch: 5| Step: 5
Training loss: 1.6701866388320923
Validation loss: 1.9987055434975574

Epoch: 5| Step: 6
Training loss: 1.822782278060913
Validation loss: 1.9930066806013866

Epoch: 5| Step: 7
Training loss: 2.223679304122925
Validation loss: 2.0096754463770057

Epoch: 5| Step: 8
Training loss: 1.7440614700317383
Validation loss: 1.9793439013983614

Epoch: 5| Step: 9
Training loss: 1.6004527807235718
Validation loss: 2.015106870282081

Epoch: 5| Step: 10
Training loss: 1.5321846008300781
Validation loss: 2.0169409500655306

Epoch: 241| Step: 0
Training loss: 1.7560956478118896
Validation loss: 2.0134037143440655

Epoch: 5| Step: 1
Training loss: 1.371781587600708
Validation loss: 2.0231239077865437

Epoch: 5| Step: 2
Training loss: 1.9276626110076904
Validation loss: 2.014051184859327

Epoch: 5| Step: 3
Training loss: 1.3968398571014404
Validation loss: 1.9947726200985652

Epoch: 5| Step: 4
Training loss: 2.069653272628784
Validation loss: 1.999467771540406

Epoch: 5| Step: 5
Training loss: 1.554989218711853
Validation loss: 2.0275398800449986

Epoch: 5| Step: 6
Training loss: 1.6491807699203491
Validation loss: 2.026617370625978

Epoch: 5| Step: 7
Training loss: 2.116279125213623
Validation loss: 1.9993078477921025

Epoch: 5| Step: 8
Training loss: 1.8157589435577393
Validation loss: 2.036945294308406

Epoch: 5| Step: 9
Training loss: 1.71999192237854
Validation loss: 2.0144443793963362

Epoch: 5| Step: 10
Training loss: 2.5863654613494873
Validation loss: 2.0041443494058426

Epoch: 242| Step: 0
Training loss: 1.9461872577667236
Validation loss: 1.9762274988235966

Epoch: 5| Step: 1
Training loss: 1.7894560098648071
Validation loss: 2.0199457189088226

Epoch: 5| Step: 2
Training loss: 2.0290637016296387
Validation loss: 1.9712144623520553

Epoch: 5| Step: 3
Training loss: 1.5890947580337524
Validation loss: 2.008271678801506

Epoch: 5| Step: 4
Training loss: 1.6134016513824463
Validation loss: 1.9863583554503739

Epoch: 5| Step: 5
Training loss: 1.6991723775863647
Validation loss: 1.9827942463659471

Epoch: 5| Step: 6
Training loss: 1.7994184494018555
Validation loss: 2.024682371847091

Epoch: 5| Step: 7
Training loss: 1.6413240432739258
Validation loss: 1.9687407465391262

Epoch: 5| Step: 8
Training loss: 2.1257293224334717
Validation loss: 1.9787799466040827

Epoch: 5| Step: 9
Training loss: 1.8045552968978882
Validation loss: 2.016145098593927

Epoch: 5| Step: 10
Training loss: 1.8401713371276855
Validation loss: 1.9887160767791092

Epoch: 243| Step: 0
Training loss: 1.6441543102264404
Validation loss: 1.9622918636568132

Epoch: 5| Step: 1
Training loss: 2.033904552459717
Validation loss: 2.0160841736742245

Epoch: 5| Step: 2
Training loss: 2.0659308433532715
Validation loss: 2.0107418670449206

Epoch: 5| Step: 3
Training loss: 1.5655142068862915
Validation loss: 2.0259774269596225

Epoch: 5| Step: 4
Training loss: 1.8843132257461548
Validation loss: 2.026534304823927

Epoch: 5| Step: 5
Training loss: 1.7818622589111328
Validation loss: 2.026321631605907

Epoch: 5| Step: 6
Training loss: 1.7789970636367798
Validation loss: 2.0397396882375083

Epoch: 5| Step: 7
Training loss: 1.549964427947998
Validation loss: 2.0215693596870667

Epoch: 5| Step: 8
Training loss: 2.1687541007995605
Validation loss: 2.0145561361825592

Epoch: 5| Step: 9
Training loss: 2.1112842559814453
Validation loss: 2.0314100493666944

Epoch: 5| Step: 10
Training loss: 1.4941017627716064
Validation loss: 1.9989339972055087

Epoch: 244| Step: 0
Training loss: 1.1762486696243286
Validation loss: 2.01457380735746

Epoch: 5| Step: 1
Training loss: 1.2547820806503296
Validation loss: 1.994249011880608

Epoch: 5| Step: 2
Training loss: 1.9865366220474243
Validation loss: 1.9843573852251934

Epoch: 5| Step: 3
Training loss: 2.1194252967834473
Validation loss: 2.019469681606498

Epoch: 5| Step: 4
Training loss: 1.5621246099472046
Validation loss: 1.9915549908914874

Epoch: 5| Step: 5
Training loss: 1.9354883432388306
Validation loss: 2.0151695128410094

Epoch: 5| Step: 6
Training loss: 2.352354049682617
Validation loss: 2.0029835803534395

Epoch: 5| Step: 7
Training loss: 1.7297592163085938
Validation loss: 1.9999432435599707

Epoch: 5| Step: 8
Training loss: 2.059323787689209
Validation loss: 1.9986518864990563

Epoch: 5| Step: 9
Training loss: 1.754098892211914
Validation loss: 2.006237144111305

Epoch: 5| Step: 10
Training loss: 2.076303482055664
Validation loss: 2.002071037087389

Epoch: 245| Step: 0
Training loss: 1.7395528554916382
Validation loss: 2.010388123091831

Epoch: 5| Step: 1
Training loss: 2.0341134071350098
Validation loss: 2.018821435589944

Epoch: 5| Step: 2
Training loss: 1.5756900310516357
Validation loss: 2.0489871066103698

Epoch: 5| Step: 3
Training loss: 1.4741274118423462
Validation loss: 2.0258654458548433

Epoch: 5| Step: 4
Training loss: 2.325496196746826
Validation loss: 2.023158186225481

Epoch: 5| Step: 5
Training loss: 1.673114538192749
Validation loss: 2.036231692119311

Epoch: 5| Step: 6
Training loss: 1.586883544921875
Validation loss: 2.016813967817573

Epoch: 5| Step: 7
Training loss: 1.342694878578186
Validation loss: 2.0005088160114903

Epoch: 5| Step: 8
Training loss: 2.0459952354431152
Validation loss: 2.0076543823365243

Epoch: 5| Step: 9
Training loss: 1.6895195245742798
Validation loss: 2.020554429741316

Epoch: 5| Step: 10
Training loss: 2.275324583053589
Validation loss: 2.012408983322882

Epoch: 246| Step: 0
Training loss: 2.269791603088379
Validation loss: 2.0163766261070006

Epoch: 5| Step: 1
Training loss: 1.4888466596603394
Validation loss: 2.0075209589414698

Epoch: 5| Step: 2
Training loss: 1.436179518699646
Validation loss: 2.0324609202723347

Epoch: 5| Step: 3
Training loss: 1.3159550428390503
Validation loss: 1.9935395333074755

Epoch: 5| Step: 4
Training loss: 1.9234918355941772
Validation loss: 2.0091003474368843

Epoch: 5| Step: 5
Training loss: 1.9499629735946655
Validation loss: 1.988309633347296

Epoch: 5| Step: 6
Training loss: 1.886577844619751
Validation loss: 2.0045479728329565

Epoch: 5| Step: 7
Training loss: 2.3780648708343506
Validation loss: 2.009175249325332

Epoch: 5| Step: 8
Training loss: 2.1148173809051514
Validation loss: 1.9974973842661867

Epoch: 5| Step: 9
Training loss: 1.4292678833007812
Validation loss: 2.0296930407965057

Epoch: 5| Step: 10
Training loss: 1.53568696975708
Validation loss: 1.9750239285089637

Epoch: 247| Step: 0
Training loss: 2.0285539627075195
Validation loss: 1.991491279294414

Epoch: 5| Step: 1
Training loss: 1.610884428024292
Validation loss: 1.984402451463925

Epoch: 5| Step: 2
Training loss: 1.642921805381775
Validation loss: 1.9830327828725178

Epoch: 5| Step: 3
Training loss: 2.132509708404541
Validation loss: 2.015172553318803

Epoch: 5| Step: 4
Training loss: 1.6123472452163696
Validation loss: 1.9778556887821486

Epoch: 5| Step: 5
Training loss: 1.0964301824569702
Validation loss: 2.026346109246695

Epoch: 5| Step: 6
Training loss: 2.078545331954956
Validation loss: 2.0131077266508535

Epoch: 5| Step: 7
Training loss: 2.0520806312561035
Validation loss: 2.016706601265938

Epoch: 5| Step: 8
Training loss: 2.16504168510437
Validation loss: 2.003721229491695

Epoch: 5| Step: 9
Training loss: 1.245809555053711
Validation loss: 2.01678123781758

Epoch: 5| Step: 10
Training loss: 1.9450151920318604
Validation loss: 1.9757995849014611

Epoch: 248| Step: 0
Training loss: 1.6534948348999023
Validation loss: 2.033359948024955

Epoch: 5| Step: 1
Training loss: 1.8064311742782593
Validation loss: 2.0164180199305215

Epoch: 5| Step: 2
Training loss: 1.8725874423980713
Validation loss: 2.0171828833959435

Epoch: 5| Step: 3
Training loss: 2.114521026611328
Validation loss: 2.0136348932020125

Epoch: 5| Step: 4
Training loss: 1.6703672409057617
Validation loss: 2.005725940068563

Epoch: 5| Step: 5
Training loss: 1.621622085571289
Validation loss: 1.9930070266928723

Epoch: 5| Step: 6
Training loss: 1.7805416584014893
Validation loss: 2.0019247685709307

Epoch: 5| Step: 7
Training loss: 1.7068684101104736
Validation loss: 2.039731735824257

Epoch: 5| Step: 8
Training loss: 1.988808274269104
Validation loss: 2.016630020192874

Epoch: 5| Step: 9
Training loss: 1.6184279918670654
Validation loss: 1.9958061595116892

Epoch: 5| Step: 10
Training loss: 1.8307836055755615
Validation loss: 2.005385834683654

Epoch: 249| Step: 0
Training loss: 2.0380520820617676
Validation loss: 2.0254789552380963

Epoch: 5| Step: 1
Training loss: 2.166591167449951
Validation loss: 2.0194139172953944

Epoch: 5| Step: 2
Training loss: 1.4316012859344482
Validation loss: 1.960185891838484

Epoch: 5| Step: 3
Training loss: 1.9239833354949951
Validation loss: 2.0257209424049623

Epoch: 5| Step: 4
Training loss: 2.0395328998565674
Validation loss: 2.0439331428979033

Epoch: 5| Step: 5
Training loss: 1.9636399745941162
Validation loss: 2.0336959951667377

Epoch: 5| Step: 6
Training loss: 1.5685365200042725
Validation loss: 2.0260116528439265

Epoch: 5| Step: 7
Training loss: 1.5901753902435303
Validation loss: 2.0577761793649323

Epoch: 5| Step: 8
Training loss: 1.5303078889846802
Validation loss: 2.0383419323992986

Epoch: 5| Step: 9
Training loss: 1.452866792678833
Validation loss: 2.0018324941717167

Epoch: 5| Step: 10
Training loss: 1.965019702911377
Validation loss: 2.024220512759301

Epoch: 250| Step: 0
Training loss: 1.6372448205947876
Validation loss: 2.019333052378829

Epoch: 5| Step: 1
Training loss: 2.409534454345703
Validation loss: 2.0089962649089035

Epoch: 5| Step: 2
Training loss: 1.7649726867675781
Validation loss: 1.981282764865506

Epoch: 5| Step: 3
Training loss: 1.660996437072754
Validation loss: 2.001072911806004

Epoch: 5| Step: 4
Training loss: 2.278740406036377
Validation loss: 1.9974024423988916

Epoch: 5| Step: 5
Training loss: 1.530963659286499
Validation loss: 1.9717161091425086

Epoch: 5| Step: 6
Training loss: 1.8683865070343018
Validation loss: 2.001455955607917

Epoch: 5| Step: 7
Training loss: 1.551688313484192
Validation loss: 2.0076349268677416

Epoch: 5| Step: 8
Training loss: 1.6587193012237549
Validation loss: 1.994375144281695

Epoch: 5| Step: 9
Training loss: 1.6554710865020752
Validation loss: 1.9825391346408474

Epoch: 5| Step: 10
Training loss: 1.6012122631072998
Validation loss: 2.009955169052206

Epoch: 251| Step: 0
Training loss: 2.01023268699646
Validation loss: 2.016224640671925

Epoch: 5| Step: 1
Training loss: 1.4231138229370117
Validation loss: 2.0131620899323495

Epoch: 5| Step: 2
Training loss: 2.339813232421875
Validation loss: 2.035712203671855

Epoch: 5| Step: 3
Training loss: 2.016083240509033
Validation loss: 1.993198666521298

Epoch: 5| Step: 4
Training loss: 1.103668451309204
Validation loss: 2.021011044902186

Epoch: 5| Step: 5
Training loss: 2.4774162769317627
Validation loss: 2.014572828046737

Epoch: 5| Step: 6
Training loss: 1.5897611379623413
Validation loss: 2.0643397710656606

Epoch: 5| Step: 7
Training loss: 1.7657253742218018
Validation loss: 2.03548200027917

Epoch: 5| Step: 8
Training loss: 1.3393996953964233
Validation loss: 2.0448303120110625

Epoch: 5| Step: 9
Training loss: 1.712057113647461
Validation loss: 2.0144764402861237

Epoch: 5| Step: 10
Training loss: 1.7065764665603638
Validation loss: 2.015161636055157

Epoch: 252| Step: 0
Training loss: 2.2374091148376465
Validation loss: 2.0462478668459

Epoch: 5| Step: 1
Training loss: 1.4974009990692139
Validation loss: 2.0535280243042977

Epoch: 5| Step: 2
Training loss: 1.9768197536468506
Validation loss: 2.01510166352795

Epoch: 5| Step: 3
Training loss: 1.5765955448150635
Validation loss: 2.026062839774675

Epoch: 5| Step: 4
Training loss: 1.5612419843673706
Validation loss: 2.0131578624889417

Epoch: 5| Step: 5
Training loss: 2.19189190864563
Validation loss: 2.0280961785265195

Epoch: 5| Step: 6
Training loss: 0.9179538488388062
Validation loss: 2.0088017961030364

Epoch: 5| Step: 7
Training loss: 2.3444623947143555
Validation loss: 2.014980875035768

Epoch: 5| Step: 8
Training loss: 1.776282548904419
Validation loss: 1.979186491299701

Epoch: 5| Step: 9
Training loss: 1.6344420909881592
Validation loss: 2.0059735082810923

Epoch: 5| Step: 10
Training loss: 1.9159101247787476
Validation loss: 2.007745768434258

Epoch: 253| Step: 0
Training loss: 1.4998674392700195
Validation loss: 1.9986800339914137

Epoch: 5| Step: 1
Training loss: 1.595848798751831
Validation loss: 1.9542695553072038

Epoch: 5| Step: 2
Training loss: 1.8413970470428467
Validation loss: 2.016154553300591

Epoch: 5| Step: 3
Training loss: 1.9922637939453125
Validation loss: 1.9978077873106925

Epoch: 5| Step: 4
Training loss: 1.8397773504257202
Validation loss: 2.0268548124579975

Epoch: 5| Step: 5
Training loss: 1.6241849660873413
Validation loss: 1.996156919387079

Epoch: 5| Step: 6
Training loss: 1.6370773315429688
Validation loss: 1.9904418068547403

Epoch: 5| Step: 7
Training loss: 2.1749041080474854
Validation loss: 2.000890936902774

Epoch: 5| Step: 8
Training loss: 1.8358043432235718
Validation loss: 2.019393672225296

Epoch: 5| Step: 9
Training loss: 1.8216354846954346
Validation loss: 2.0390559678436606

Epoch: 5| Step: 10
Training loss: 1.750322699546814
Validation loss: 2.0002943674723306

Epoch: 254| Step: 0
Training loss: 1.9926679134368896
Validation loss: 2.0201536045279553

Epoch: 5| Step: 1
Training loss: 1.5508185625076294
Validation loss: 2.0229866222668718

Epoch: 5| Step: 2
Training loss: 2.0334768295288086
Validation loss: 2.0098486767020276

Epoch: 5| Step: 3
Training loss: 1.998579740524292
Validation loss: 2.0101044870192006

Epoch: 5| Step: 4
Training loss: 1.7788203954696655
Validation loss: 1.9981071500368015

Epoch: 5| Step: 5
Training loss: 1.8269485235214233
Validation loss: 2.025023370660761

Epoch: 5| Step: 6
Training loss: 1.5999159812927246
Validation loss: 1.99382568687521

Epoch: 5| Step: 7
Training loss: 1.1380757093429565
Validation loss: 1.9794712938288206

Epoch: 5| Step: 8
Training loss: 1.8295657634735107
Validation loss: 2.023838076540219

Epoch: 5| Step: 9
Training loss: 1.794121503829956
Validation loss: 2.0126334044241134

Epoch: 5| Step: 10
Training loss: 1.9107409715652466
Validation loss: 2.012072220925362

Epoch: 255| Step: 0
Training loss: 2.137385845184326
Validation loss: 2.0029199354110228

Epoch: 5| Step: 1
Training loss: 1.4124534130096436
Validation loss: 2.0285080671310425

Epoch: 5| Step: 2
Training loss: 1.969689130783081
Validation loss: 2.0052011166849444

Epoch: 5| Step: 3
Training loss: 1.7880722284317017
Validation loss: 2.0127659664359143

Epoch: 5| Step: 4
Training loss: 2.049212694168091
Validation loss: 2.014013926188151

Epoch: 5| Step: 5
Training loss: 1.403302788734436
Validation loss: 2.0103443156006517

Epoch: 5| Step: 6
Training loss: 1.670985221862793
Validation loss: 2.009486303534559

Epoch: 5| Step: 7
Training loss: 1.7299617528915405
Validation loss: 2.0185693335789505

Epoch: 5| Step: 8
Training loss: 1.8391125202178955
Validation loss: 1.988846573778378

Epoch: 5| Step: 9
Training loss: 1.6602857112884521
Validation loss: 2.0216048532916653

Epoch: 5| Step: 10
Training loss: 1.8820792436599731
Validation loss: 1.9921924362900436

Epoch: 256| Step: 0
Training loss: 1.917872428894043
Validation loss: 2.0021287702745005

Epoch: 5| Step: 1
Training loss: 2.0670573711395264
Validation loss: 2.0152076341772593

Epoch: 5| Step: 2
Training loss: 1.4659578800201416
Validation loss: 2.017759323120117

Epoch: 5| Step: 3
Training loss: 1.515865683555603
Validation loss: 1.993516343896107

Epoch: 5| Step: 4
Training loss: 1.9810245037078857
Validation loss: 2.0173839548582673

Epoch: 5| Step: 5
Training loss: 1.328446626663208
Validation loss: 2.0642988361338133

Epoch: 5| Step: 6
Training loss: 1.7704722881317139
Validation loss: 2.0290962790930145

Epoch: 5| Step: 7
Training loss: 1.8891063928604126
Validation loss: 2.0399510014441704

Epoch: 5| Step: 8
Training loss: 1.9776484966278076
Validation loss: 2.0313175673125894

Epoch: 5| Step: 9
Training loss: 2.046175241470337
Validation loss: 2.0127107097256567

Epoch: 5| Step: 10
Training loss: 1.5855648517608643
Validation loss: 2.0080354521351476

Epoch: 257| Step: 0
Training loss: 1.4230873584747314
Validation loss: 2.012817200794015

Epoch: 5| Step: 1
Training loss: 1.5428876876831055
Validation loss: 2.007980495370844

Epoch: 5| Step: 2
Training loss: 1.9902331829071045
Validation loss: 2.0037664956943964

Epoch: 5| Step: 3
Training loss: 2.3149633407592773
Validation loss: 2.035669747219291

Epoch: 5| Step: 4
Training loss: 1.0572116374969482
Validation loss: 2.0014724295626403

Epoch: 5| Step: 5
Training loss: 1.8787596225738525
Validation loss: 1.971084710090391

Epoch: 5| Step: 6
Training loss: 1.6985927820205688
Validation loss: 1.9792971675113966

Epoch: 5| Step: 7
Training loss: 2.53547739982605
Validation loss: 2.001534587593489

Epoch: 5| Step: 8
Training loss: 1.8664638996124268
Validation loss: 1.9777359859917754

Epoch: 5| Step: 9
Training loss: 1.853996992111206
Validation loss: 1.971886770699614

Epoch: 5| Step: 10
Training loss: 1.3163892030715942
Validation loss: 1.9855636729989001

Epoch: 258| Step: 0
Training loss: 1.929427146911621
Validation loss: 1.972630093174596

Epoch: 5| Step: 1
Training loss: 1.3913100957870483
Validation loss: 1.9931703741832445

Epoch: 5| Step: 2
Training loss: 1.8660821914672852
Validation loss: 2.039012465425717

Epoch: 5| Step: 3
Training loss: 2.072657585144043
Validation loss: 2.0310120531307754

Epoch: 5| Step: 4
Training loss: 1.6503833532333374
Validation loss: 2.0492054441923737

Epoch: 5| Step: 5
Training loss: 1.5040850639343262
Validation loss: 2.0717710884668494

Epoch: 5| Step: 6
Training loss: 2.1158299446105957
Validation loss: 2.0524050497239634

Epoch: 5| Step: 7
Training loss: 2.1926074028015137
Validation loss: 2.042583348930523

Epoch: 5| Step: 8
Training loss: 1.1601884365081787
Validation loss: 2.052235164949971

Epoch: 5| Step: 9
Training loss: 2.0399675369262695
Validation loss: 2.0552796958595194

Epoch: 5| Step: 10
Training loss: 1.704842448234558
Validation loss: 2.0424283153267315

Epoch: 259| Step: 0
Training loss: 2.2259325981140137
Validation loss: 2.0490597858223865

Epoch: 5| Step: 1
Training loss: 1.0928866863250732
Validation loss: 2.0383505975046465

Epoch: 5| Step: 2
Training loss: 1.6766220331192017
Validation loss: 2.023650914110163

Epoch: 5| Step: 3
Training loss: 1.6411466598510742
Validation loss: 2.0292617326141684

Epoch: 5| Step: 4
Training loss: 1.604071021080017
Validation loss: 1.9950777356342604

Epoch: 5| Step: 5
Training loss: 1.644134521484375
Validation loss: 2.0220241892722344

Epoch: 5| Step: 6
Training loss: 1.661187767982483
Validation loss: 2.0225878248932543

Epoch: 5| Step: 7
Training loss: 1.5954558849334717
Validation loss: 2.001224970304838

Epoch: 5| Step: 8
Training loss: 1.9678751230239868
Validation loss: 2.0214002978417183

Epoch: 5| Step: 9
Training loss: 2.13016939163208
Validation loss: 1.9948350178298129

Epoch: 5| Step: 10
Training loss: 2.234174966812134
Validation loss: 2.013241215418744

Epoch: 260| Step: 0
Training loss: 1.5907292366027832
Validation loss: 2.010985912815217

Epoch: 5| Step: 1
Training loss: 1.9864921569824219
Validation loss: 2.020265866351384

Epoch: 5| Step: 2
Training loss: 1.9143993854522705
Validation loss: 1.992389222627045

Epoch: 5| Step: 3
Training loss: 1.0721840858459473
Validation loss: 1.9898822807496594

Epoch: 5| Step: 4
Training loss: 1.2702043056488037
Validation loss: 1.9862196419828682

Epoch: 5| Step: 5
Training loss: 1.5574443340301514
Validation loss: 1.9910636845455374

Epoch: 5| Step: 6
Training loss: 1.9565317630767822
Validation loss: 2.0140511579411005

Epoch: 5| Step: 7
Training loss: 1.9188944101333618
Validation loss: 1.9906709847911712

Epoch: 5| Step: 8
Training loss: 2.230456590652466
Validation loss: 1.992654659414804

Epoch: 5| Step: 9
Training loss: 2.017393112182617
Validation loss: 2.052452528348533

Epoch: 5| Step: 10
Training loss: 1.9302749633789062
Validation loss: 2.0334241928592807

Epoch: 261| Step: 0
Training loss: 2.262406826019287
Validation loss: 2.0022505457683275

Epoch: 5| Step: 1
Training loss: 1.5753484964370728
Validation loss: 2.023884157980642

Epoch: 5| Step: 2
Training loss: 1.7521051168441772
Validation loss: 2.0336562997551373

Epoch: 5| Step: 3
Training loss: 1.7233753204345703
Validation loss: 1.970910867055257

Epoch: 5| Step: 4
Training loss: 1.3923171758651733
Validation loss: 2.0140993287486415

Epoch: 5| Step: 5
Training loss: 1.5038576126098633
Validation loss: 2.0129637923291934

Epoch: 5| Step: 6
Training loss: 1.971029281616211
Validation loss: 1.995484294429902

Epoch: 5| Step: 7
Training loss: 1.261534333229065
Validation loss: 1.9687116363997101

Epoch: 5| Step: 8
Training loss: 2.310588836669922
Validation loss: 1.975194905393867

Epoch: 5| Step: 9
Training loss: 2.1575100421905518
Validation loss: 1.997749992596206

Epoch: 5| Step: 10
Training loss: 1.321081519126892
Validation loss: 2.0051251008946407

Epoch: 262| Step: 0
Training loss: 1.6870476007461548
Validation loss: 2.0305899753365466

Epoch: 5| Step: 1
Training loss: 1.9073238372802734
Validation loss: 2.0210734644243793

Epoch: 5| Step: 2
Training loss: 1.3124277591705322
Validation loss: 2.037500162278452

Epoch: 5| Step: 3
Training loss: 1.6502851247787476
Validation loss: 2.0375116807158276

Epoch: 5| Step: 4
Training loss: 1.4420562982559204
Validation loss: 2.017946579123056

Epoch: 5| Step: 5
Training loss: 1.1675100326538086
Validation loss: 2.021462881436912

Epoch: 5| Step: 6
Training loss: 2.2522175312042236
Validation loss: 2.0202783564085602

Epoch: 5| Step: 7
Training loss: 2.1114120483398438
Validation loss: 2.0218691095229118

Epoch: 5| Step: 8
Training loss: 1.286975383758545
Validation loss: 2.0516591533537833

Epoch: 5| Step: 9
Training loss: 2.150599241256714
Validation loss: 2.03013002744285

Epoch: 5| Step: 10
Training loss: 2.4595932960510254
Validation loss: 1.9974802412012571

Epoch: 263| Step: 0
Training loss: 2.0179855823516846
Validation loss: 2.0047512118534376

Epoch: 5| Step: 1
Training loss: 1.0893256664276123
Validation loss: 1.9997348426490702

Epoch: 5| Step: 2
Training loss: 1.891175627708435
Validation loss: 2.0019388788489887

Epoch: 5| Step: 3
Training loss: 2.250067949295044
Validation loss: 1.9842310849056448

Epoch: 5| Step: 4
Training loss: 1.4692637920379639
Validation loss: 2.0252769429196595

Epoch: 5| Step: 5
Training loss: 1.557523250579834
Validation loss: 2.00223131333628

Epoch: 5| Step: 6
Training loss: 1.62067449092865
Validation loss: 2.022757073884369

Epoch: 5| Step: 7
Training loss: 1.8657341003417969
Validation loss: 1.9859893885991906

Epoch: 5| Step: 8
Training loss: 2.3303885459899902
Validation loss: 2.0018649421712404

Epoch: 5| Step: 9
Training loss: 1.6135141849517822
Validation loss: 1.9931685950166436

Epoch: 5| Step: 10
Training loss: 1.7845379114151
Validation loss: 2.008423953927973

Epoch: 264| Step: 0
Training loss: 2.389242649078369
Validation loss: 2.0072223909439577

Epoch: 5| Step: 1
Training loss: 1.929274559020996
Validation loss: 1.9650852782751924

Epoch: 5| Step: 2
Training loss: 2.352924108505249
Validation loss: 2.003283808308263

Epoch: 5| Step: 3
Training loss: 1.394038200378418
Validation loss: 1.9891566973860546

Epoch: 5| Step: 4
Training loss: 1.3168931007385254
Validation loss: 2.0020139114831084

Epoch: 5| Step: 5
Training loss: 1.6712573766708374
Validation loss: 1.9989981702578965

Epoch: 5| Step: 6
Training loss: 1.342276930809021
Validation loss: 1.9898624086892733

Epoch: 5| Step: 7
Training loss: 2.3329501152038574
Validation loss: 2.003355082645211

Epoch: 5| Step: 8
Training loss: 1.2716909646987915
Validation loss: 2.034418454734228

Epoch: 5| Step: 9
Training loss: 1.3634511232376099
Validation loss: 2.008276193372665

Epoch: 5| Step: 10
Training loss: 2.023588180541992
Validation loss: 2.011239533783287

Epoch: 265| Step: 0
Training loss: 1.6273069381713867
Validation loss: 2.0115598632443334

Epoch: 5| Step: 1
Training loss: 1.8590338230133057
Validation loss: 1.9932647610223422

Epoch: 5| Step: 2
Training loss: 1.5664122104644775
Validation loss: 2.0215561184831845

Epoch: 5| Step: 3
Training loss: 1.8532966375350952
Validation loss: 2.0209271292532645

Epoch: 5| Step: 4
Training loss: 1.8713585138320923
Validation loss: 2.0237144065159622

Epoch: 5| Step: 5
Training loss: 1.4062912464141846
Validation loss: 2.0484902794643114

Epoch: 5| Step: 6
Training loss: 1.9313881397247314
Validation loss: 2.0303882591186033

Epoch: 5| Step: 7
Training loss: 1.3467113971710205
Validation loss: 2.049593679366573

Epoch: 5| Step: 8
Training loss: 1.5488542318344116
Validation loss: 1.9982576729148946

Epoch: 5| Step: 9
Training loss: 1.9112145900726318
Validation loss: 1.9908214230691232

Epoch: 5| Step: 10
Training loss: 2.371793746948242
Validation loss: 2.005811486192929

Epoch: 266| Step: 0
Training loss: 1.572121024131775
Validation loss: 2.0170090634335756

Epoch: 5| Step: 1
Training loss: 1.8728034496307373
Validation loss: 2.026075091413272

Epoch: 5| Step: 2
Training loss: 1.8685821294784546
Validation loss: 2.02745747053495

Epoch: 5| Step: 3
Training loss: 1.917907953262329
Validation loss: 1.9810356452900877

Epoch: 5| Step: 4
Training loss: 1.5248470306396484
Validation loss: 2.042897875590991

Epoch: 5| Step: 5
Training loss: 1.1791807413101196
Validation loss: 2.0445644188952703

Epoch: 5| Step: 6
Training loss: 2.6601157188415527
Validation loss: 1.9844863504491828

Epoch: 5| Step: 7
Training loss: 1.381563425064087
Validation loss: 2.0042383145260554

Epoch: 5| Step: 8
Training loss: 1.959924340248108
Validation loss: 2.0301065547491914

Epoch: 5| Step: 9
Training loss: 1.5843232870101929
Validation loss: 2.0104011438226186

Epoch: 5| Step: 10
Training loss: 1.5562201738357544
Validation loss: 1.9971728529981387

Epoch: 267| Step: 0
Training loss: 1.5250999927520752
Validation loss: 2.0161108073367866

Epoch: 5| Step: 1
Training loss: 1.942997932434082
Validation loss: 1.9765511558901878

Epoch: 5| Step: 2
Training loss: 1.2864015102386475
Validation loss: 2.026870304538358

Epoch: 5| Step: 3
Training loss: 1.1578480005264282
Validation loss: 2.0250482174658004

Epoch: 5| Step: 4
Training loss: 1.548246145248413
Validation loss: 2.0036183954567037

Epoch: 5| Step: 5
Training loss: 2.4073891639709473
Validation loss: 1.9884665883997434

Epoch: 5| Step: 6
Training loss: 1.3272300958633423
Validation loss: 2.016214983437651

Epoch: 5| Step: 7
Training loss: 2.3904385566711426
Validation loss: 1.992911628497544

Epoch: 5| Step: 8
Training loss: 2.1710033416748047
Validation loss: 2.0351537940322713

Epoch: 5| Step: 9
Training loss: 1.446187973022461
Validation loss: 2.0051364309044293

Epoch: 5| Step: 10
Training loss: 2.0674169063568115
Validation loss: 1.9768265511399956

Epoch: 268| Step: 0
Training loss: 2.1181092262268066
Validation loss: 2.022847392225778

Epoch: 5| Step: 1
Training loss: 2.2785744667053223
Validation loss: 2.015887096364011

Epoch: 5| Step: 2
Training loss: 1.7096296548843384
Validation loss: 1.9957624507206742

Epoch: 5| Step: 3
Training loss: 1.6480181217193604
Validation loss: 1.9815342785209737

Epoch: 5| Step: 4
Training loss: 1.54415762424469
Validation loss: 2.0136264088333293

Epoch: 5| Step: 5
Training loss: 1.3596532344818115
Validation loss: 2.0144384381591633

Epoch: 5| Step: 6
Training loss: 1.9439270496368408
Validation loss: 2.0175098321771108

Epoch: 5| Step: 7
Training loss: 1.951743721961975
Validation loss: 2.0206777165012975

Epoch: 5| Step: 8
Training loss: 1.4682763814926147
Validation loss: 2.024331804244749

Epoch: 5| Step: 9
Training loss: 1.5829263925552368
Validation loss: 2.055369402772637

Epoch: 5| Step: 10
Training loss: 1.4403783082962036
Validation loss: 2.0265992277412006

Epoch: 269| Step: 0
Training loss: 1.5292412042617798
Validation loss: 2.0268023629342355

Epoch: 5| Step: 1
Training loss: 1.7194114923477173
Validation loss: 2.0555040297969693

Epoch: 5| Step: 2
Training loss: 1.660647988319397
Validation loss: 2.0073001538553545

Epoch: 5| Step: 3
Training loss: 1.7321617603302002
Validation loss: 2.007646838823954

Epoch: 5| Step: 4
Training loss: 2.0970053672790527
Validation loss: 2.004616109273767

Epoch: 5| Step: 5
Training loss: 1.6721069812774658
Validation loss: 2.009702523549398

Epoch: 5| Step: 6
Training loss: 2.130770683288574
Validation loss: 2.0304091335624777

Epoch: 5| Step: 7
Training loss: 1.8278160095214844
Validation loss: 2.0303647774522022

Epoch: 5| Step: 8
Training loss: 1.589134693145752
Validation loss: 2.005469624714185

Epoch: 5| Step: 9
Training loss: 1.568971872329712
Validation loss: 2.022075714603547

Epoch: 5| Step: 10
Training loss: 1.38338041305542
Validation loss: 1.985262147841915

Epoch: 270| Step: 0
Training loss: 1.8573646545410156
Validation loss: 2.0249039626890615

Epoch: 5| Step: 1
Training loss: 1.746092438697815
Validation loss: 2.011291462888

Epoch: 5| Step: 2
Training loss: 1.6513830423355103
Validation loss: 2.0378324036957114

Epoch: 5| Step: 3
Training loss: 1.8907861709594727
Validation loss: 2.0156322217756704

Epoch: 5| Step: 4
Training loss: 1.871808409690857
Validation loss: 2.0250417237640708

Epoch: 5| Step: 5
Training loss: 1.7579561471939087
Validation loss: 2.026092435723992

Epoch: 5| Step: 6
Training loss: 1.0164072513580322
Validation loss: 1.9945074319839478

Epoch: 5| Step: 7
Training loss: 1.8364721536636353
Validation loss: 2.0278703089683288

Epoch: 5| Step: 8
Training loss: 1.7533445358276367
Validation loss: 2.021716676732545

Epoch: 5| Step: 9
Training loss: 1.8230407238006592
Validation loss: 2.026747421551776

Epoch: 5| Step: 10
Training loss: 2.2414772510528564
Validation loss: 2.0524823742528118

Epoch: 271| Step: 0
Training loss: 1.652463674545288
Validation loss: 1.9961870665191321

Epoch: 5| Step: 1
Training loss: 2.062117099761963
Validation loss: 1.9965746351467666

Epoch: 5| Step: 2
Training loss: 1.6174523830413818
Validation loss: 1.9987490382245792

Epoch: 5| Step: 3
Training loss: 1.5854368209838867
Validation loss: 2.0012937822649555

Epoch: 5| Step: 4
Training loss: 1.301804780960083
Validation loss: 1.9968731428987236

Epoch: 5| Step: 5
Training loss: 1.6134830713272095
Validation loss: 1.9932351420002599

Epoch: 5| Step: 6
Training loss: 2.1670022010803223
Validation loss: 1.988741651658089

Epoch: 5| Step: 7
Training loss: 1.8560388088226318
Validation loss: 1.9977708196127286

Epoch: 5| Step: 8
Training loss: 1.6747300624847412
Validation loss: 2.023887800913985

Epoch: 5| Step: 9
Training loss: 1.714210867881775
Validation loss: 2.00737238443026

Epoch: 5| Step: 10
Training loss: 1.753026008605957
Validation loss: 2.0074202514463857

Epoch: 272| Step: 0
Training loss: 1.4515674114227295
Validation loss: 1.9791528896618915

Epoch: 5| Step: 1
Training loss: 1.8899269104003906
Validation loss: 2.00272302217381

Epoch: 5| Step: 2
Training loss: 1.5313159227371216
Validation loss: 1.9966829976727885

Epoch: 5| Step: 3
Training loss: 2.0434796810150146
Validation loss: 2.019754509772024

Epoch: 5| Step: 4
Training loss: 1.6125586032867432
Validation loss: 2.0114419793569915

Epoch: 5| Step: 5
Training loss: 1.8816373348236084
Validation loss: 2.012981278921968

Epoch: 5| Step: 6
Training loss: 1.515856385231018
Validation loss: 1.9938800565658077

Epoch: 5| Step: 7
Training loss: 1.374342918395996
Validation loss: 1.977296192158935

Epoch: 5| Step: 8
Training loss: 1.8922122716903687
Validation loss: 1.999048573996431

Epoch: 5| Step: 9
Training loss: 2.085601329803467
Validation loss: 2.0106829904740855

Epoch: 5| Step: 10
Training loss: 1.7698125839233398
Validation loss: 2.0313918321363387

Epoch: 273| Step: 0
Training loss: 1.9599294662475586
Validation loss: 2.0128812315643474

Epoch: 5| Step: 1
Training loss: 1.278512716293335
Validation loss: 1.9887217860068045

Epoch: 5| Step: 2
Training loss: 1.5832760334014893
Validation loss: 2.0263558574902114

Epoch: 5| Step: 3
Training loss: 2.1888229846954346
Validation loss: 2.0230174756819204

Epoch: 5| Step: 4
Training loss: 2.0184998512268066
Validation loss: 2.0020674441450383

Epoch: 5| Step: 5
Training loss: 1.7066986560821533
Validation loss: 2.014751777854017

Epoch: 5| Step: 6
Training loss: 2.028878927230835
Validation loss: 1.9914873492333196

Epoch: 5| Step: 7
Training loss: 0.8921168446540833
Validation loss: 2.0072738111660047

Epoch: 5| Step: 8
Training loss: 1.9442189931869507
Validation loss: 2.0211827383246472

Epoch: 5| Step: 9
Training loss: 1.6801252365112305
Validation loss: 2.0160415557123

Epoch: 5| Step: 10
Training loss: 1.8512439727783203
Validation loss: 2.0094358690323366

Epoch: 274| Step: 0
Training loss: 2.0820298194885254
Validation loss: 2.0482905295587357

Epoch: 5| Step: 1
Training loss: 1.7637341022491455
Validation loss: 2.0283082531344507

Epoch: 5| Step: 2
Training loss: 2.011291027069092
Validation loss: 2.0287888114170363

Epoch: 5| Step: 3
Training loss: 1.617316484451294
Validation loss: 2.0091084408503708

Epoch: 5| Step: 4
Training loss: 2.111307382583618
Validation loss: 1.9923170471704135

Epoch: 5| Step: 5
Training loss: 1.5532926321029663
Validation loss: 2.0395885821311706

Epoch: 5| Step: 6
Training loss: 0.7984493970870972
Validation loss: 2.0356518222439672

Epoch: 5| Step: 7
Training loss: 1.6942565441131592
Validation loss: 2.0232923928127495

Epoch: 5| Step: 8
Training loss: 1.5661646127700806
Validation loss: 1.991436928831121

Epoch: 5| Step: 9
Training loss: 1.8634666204452515
Validation loss: 2.0160444859535462

Epoch: 5| Step: 10
Training loss: 2.117934465408325
Validation loss: 2.0607871201730545

Epoch: 275| Step: 0
Training loss: 1.822180986404419
Validation loss: 2.053480545679728

Epoch: 5| Step: 1
Training loss: 1.84977126121521
Validation loss: 2.0176632545327626

Epoch: 5| Step: 2
Training loss: 1.1395303010940552
Validation loss: 2.0239059668715282

Epoch: 5| Step: 3
Training loss: 1.8763525485992432
Validation loss: 2.0250860926925496

Epoch: 5| Step: 4
Training loss: 1.4822826385498047
Validation loss: 2.0410109963468326

Epoch: 5| Step: 5
Training loss: 1.9224128723144531
Validation loss: 2.041146796236756

Epoch: 5| Step: 6
Training loss: 1.9229042530059814
Validation loss: 2.0061464771147697

Epoch: 5| Step: 7
Training loss: 1.4561903476715088
Validation loss: 2.056303772875058

Epoch: 5| Step: 8
Training loss: 2.115201473236084
Validation loss: 1.9998213783387215

Epoch: 5| Step: 9
Training loss: 1.6007416248321533
Validation loss: 2.0040781587682743

Epoch: 5| Step: 10
Training loss: 1.7392100095748901
Validation loss: 2.027519855447995

Epoch: 276| Step: 0
Training loss: 1.3911936283111572
Validation loss: 1.9872929332076863

Epoch: 5| Step: 1
Training loss: 2.2424073219299316
Validation loss: 2.0058029800333004

Epoch: 5| Step: 2
Training loss: 2.0544564723968506
Validation loss: 1.9672306455591673

Epoch: 5| Step: 3
Training loss: 1.0601956844329834
Validation loss: 1.9794866513180476

Epoch: 5| Step: 4
Training loss: 1.7526767253875732
Validation loss: 2.0113114310849096

Epoch: 5| Step: 5
Training loss: 1.7645959854125977
Validation loss: 1.992448160725255

Epoch: 5| Step: 6
Training loss: 1.9325872659683228
Validation loss: 1.992245126796025

Epoch: 5| Step: 7
Training loss: 2.006804943084717
Validation loss: 2.010149126411766

Epoch: 5| Step: 8
Training loss: 1.2919921875
Validation loss: 2.0165666610963884

Epoch: 5| Step: 9
Training loss: 2.333467721939087
Validation loss: 2.0386993410766765

Epoch: 5| Step: 10
Training loss: 1.4764680862426758
Validation loss: 2.0348829851355603

Epoch: 277| Step: 0
Training loss: 1.5885570049285889
Validation loss: 2.0126439512416883

Epoch: 5| Step: 1
Training loss: 1.9783741235733032
Validation loss: 2.013534320298062

Epoch: 5| Step: 2
Training loss: 2.4972758293151855
Validation loss: 2.0434085912601923

Epoch: 5| Step: 3
Training loss: 1.5583982467651367
Validation loss: 2.037801686153617

Epoch: 5| Step: 4
Training loss: 1.7324529886245728
Validation loss: 2.020182914631341

Epoch: 5| Step: 5
Training loss: 1.9280080795288086
Validation loss: 2.038069112326509

Epoch: 5| Step: 6
Training loss: 1.6942589282989502
Validation loss: 2.019284588034435

Epoch: 5| Step: 7
Training loss: 1.3060197830200195
Validation loss: 1.9995112521674043

Epoch: 5| Step: 8
Training loss: 1.092763900756836
Validation loss: 1.9998675469429261

Epoch: 5| Step: 9
Training loss: 2.082601547241211
Validation loss: 2.0285704366622435

Epoch: 5| Step: 10
Training loss: 1.6084121465682983
Validation loss: 2.02795749069542

Epoch: 278| Step: 0
Training loss: 1.7567822933197021
Validation loss: 1.980035912606024

Epoch: 5| Step: 1
Training loss: 2.4207024574279785
Validation loss: 2.0064548061740015

Epoch: 5| Step: 2
Training loss: 1.7603042125701904
Validation loss: 2.0165372484473774

Epoch: 5| Step: 3
Training loss: 1.1697593927383423
Validation loss: 2.0184387519795406

Epoch: 5| Step: 4
Training loss: 1.7518104314804077
Validation loss: 1.980796649891843

Epoch: 5| Step: 5
Training loss: 1.5366548299789429
Validation loss: 2.0105109445510374

Epoch: 5| Step: 6
Training loss: 2.042611837387085
Validation loss: 1.9836538055891633

Epoch: 5| Step: 7
Training loss: 2.027219295501709
Validation loss: 2.004297948652698

Epoch: 5| Step: 8
Training loss: 1.7300926446914673
Validation loss: 1.999944479234757

Epoch: 5| Step: 9
Training loss: 1.4958839416503906
Validation loss: 2.002061419589545

Epoch: 5| Step: 10
Training loss: 1.5353718996047974
Validation loss: 1.9894360393606207

Epoch: 279| Step: 0
Training loss: 2.16392183303833
Validation loss: 1.9840518428433327

Epoch: 5| Step: 1
Training loss: 1.9911682605743408
Validation loss: 2.0140559545127292

Epoch: 5| Step: 2
Training loss: 1.0265649557113647
Validation loss: 2.0353763129121516

Epoch: 5| Step: 3
Training loss: 1.4700757265090942
Validation loss: 2.042730657003259

Epoch: 5| Step: 4
Training loss: 1.7576446533203125
Validation loss: 2.003127649266233

Epoch: 5| Step: 5
Training loss: 1.8938636779785156
Validation loss: 2.01078708710209

Epoch: 5| Step: 6
Training loss: 1.5516220331192017
Validation loss: 1.973709975519488

Epoch: 5| Step: 7
Training loss: 1.2050632238388062
Validation loss: 2.0475516729457404

Epoch: 5| Step: 8
Training loss: 2.427154541015625
Validation loss: 2.012932486431573

Epoch: 5| Step: 9
Training loss: 1.5028965473175049
Validation loss: 2.036494537066388

Epoch: 5| Step: 10
Training loss: 1.7036302089691162
Validation loss: 2.040994128873271

Epoch: 280| Step: 0
Training loss: 1.7658249139785767
Validation loss: 2.0204325670837076

Epoch: 5| Step: 1
Training loss: 1.7776895761489868
Validation loss: 2.0617177640238116

Epoch: 5| Step: 2
Training loss: 1.0643441677093506
Validation loss: 2.0348788871560046

Epoch: 5| Step: 3
Training loss: 1.3350027799606323
Validation loss: 2.0220701104851178

Epoch: 5| Step: 4
Training loss: 2.075148582458496
Validation loss: 2.0103890690752255

Epoch: 5| Step: 5
Training loss: 1.3839216232299805
Validation loss: 2.011396219653468

Epoch: 5| Step: 6
Training loss: 1.3492428064346313
Validation loss: 2.0467277188454904

Epoch: 5| Step: 7
Training loss: 2.2469019889831543
Validation loss: 2.016305931152836

Epoch: 5| Step: 8
Training loss: 1.845446228981018
Validation loss: 2.047813046363092

Epoch: 5| Step: 9
Training loss: 2.3785946369171143
Validation loss: 2.0079591274261475

Epoch: 5| Step: 10
Training loss: 1.5243972539901733
Validation loss: 2.001340405915373

Epoch: 281| Step: 0
Training loss: 1.8111737966537476
Validation loss: 1.982654776624454

Epoch: 5| Step: 1
Training loss: 1.1389039754867554
Validation loss: 2.0351818569244875

Epoch: 5| Step: 2
Training loss: 1.1853008270263672
Validation loss: 2.043029959483813

Epoch: 5| Step: 3
Training loss: 1.8844093084335327
Validation loss: 2.0022675850058116

Epoch: 5| Step: 4
Training loss: 1.770806074142456
Validation loss: 1.9933989637641496

Epoch: 5| Step: 5
Training loss: 2.074820041656494
Validation loss: 1.990006724993388

Epoch: 5| Step: 6
Training loss: 1.3135054111480713
Validation loss: 1.9997347862489763

Epoch: 5| Step: 7
Training loss: 2.2937910556793213
Validation loss: 2.0299368545573246

Epoch: 5| Step: 8
Training loss: 1.5683494806289673
Validation loss: 1.9561390466587518

Epoch: 5| Step: 9
Training loss: 1.6385034322738647
Validation loss: 2.005052620364774

Epoch: 5| Step: 10
Training loss: 2.519087076187134
Validation loss: 1.984505820017989

Epoch: 282| Step: 0
Training loss: 1.9382950067520142
Validation loss: 2.0094991345559396

Epoch: 5| Step: 1
Training loss: 1.759642243385315
Validation loss: 1.9994043355347009

Epoch: 5| Step: 2
Training loss: 1.00478196144104
Validation loss: 2.00409927932165

Epoch: 5| Step: 3
Training loss: 1.8604522943496704
Validation loss: 2.053301752254527

Epoch: 5| Step: 4
Training loss: 1.7114038467407227
Validation loss: 2.0238440934047905

Epoch: 5| Step: 5
Training loss: 1.7870063781738281
Validation loss: 2.0198872397022862

Epoch: 5| Step: 6
Training loss: 1.8485291004180908
Validation loss: 2.03577063673286

Epoch: 5| Step: 7
Training loss: 1.6505382061004639
Validation loss: 2.0263689538483978

Epoch: 5| Step: 8
Training loss: 1.3016927242279053
Validation loss: 2.052178354673488

Epoch: 5| Step: 9
Training loss: 2.0150978565216064
Validation loss: 1.9828352287251463

Epoch: 5| Step: 10
Training loss: 1.9075599908828735
Validation loss: 2.0188665108014177

Epoch: 283| Step: 0
Training loss: 1.116886019706726
Validation loss: 2.041299561018585

Epoch: 5| Step: 1
Training loss: 1.7605149745941162
Validation loss: 2.0099035283570648

Epoch: 5| Step: 2
Training loss: 1.285370111465454
Validation loss: 1.9979900724144393

Epoch: 5| Step: 3
Training loss: 2.8106191158294678
Validation loss: 2.016416270245788

Epoch: 5| Step: 4
Training loss: 1.4574369192123413
Validation loss: 2.0136212777065974

Epoch: 5| Step: 5
Training loss: 1.9292528629302979
Validation loss: 2.0436126647457

Epoch: 5| Step: 6
Training loss: 1.743548035621643
Validation loss: 2.00400891611653

Epoch: 5| Step: 7
Training loss: 1.1364696025848389
Validation loss: 2.005134041591357

Epoch: 5| Step: 8
Training loss: 1.940863013267517
Validation loss: 2.010676928745803

Epoch: 5| Step: 9
Training loss: 1.8280874490737915
Validation loss: 2.019590946935838

Epoch: 5| Step: 10
Training loss: 1.7255690097808838
Validation loss: 2.0190895936822377

Epoch: 284| Step: 0
Training loss: 1.5356988906860352
Validation loss: 2.0394704854616554

Epoch: 5| Step: 1
Training loss: 2.0791354179382324
Validation loss: 2.0192410535709833

Epoch: 5| Step: 2
Training loss: 1.2605799436569214
Validation loss: 2.0196971124218357

Epoch: 5| Step: 3
Training loss: 1.236133337020874
Validation loss: 2.002634927790652

Epoch: 5| Step: 4
Training loss: 2.0970120429992676
Validation loss: 2.015692053302642

Epoch: 5| Step: 5
Training loss: 1.1866364479064941
Validation loss: 1.9923250213746102

Epoch: 5| Step: 6
Training loss: 1.4686702489852905
Validation loss: 2.029577660304244

Epoch: 5| Step: 7
Training loss: 1.8179022073745728
Validation loss: 2.0132452928891746

Epoch: 5| Step: 8
Training loss: 2.0129008293151855
Validation loss: 2.0342239385010092

Epoch: 5| Step: 9
Training loss: 1.7977440357208252
Validation loss: 2.0017766337240896

Epoch: 5| Step: 10
Training loss: 2.810004234313965
Validation loss: 2.007615386798818

Epoch: 285| Step: 0
Training loss: 1.9752687215805054
Validation loss: 2.006155542148057

Epoch: 5| Step: 1
Training loss: 1.4268593788146973
Validation loss: 2.064232067395282

Epoch: 5| Step: 2
Training loss: 1.472556710243225
Validation loss: 2.012631311852445

Epoch: 5| Step: 3
Training loss: 1.59822678565979
Validation loss: 2.047096424205329

Epoch: 5| Step: 4
Training loss: 2.2403922080993652
Validation loss: 1.9990101911688363

Epoch: 5| Step: 5
Training loss: 0.9465773701667786
Validation loss: 2.0123997516529535

Epoch: 5| Step: 6
Training loss: 2.4614787101745605
Validation loss: 2.0499760412400767

Epoch: 5| Step: 7
Training loss: 2.0496368408203125
Validation loss: 2.0326672677070863

Epoch: 5| Step: 8
Training loss: 1.2801851034164429
Validation loss: 2.0450731374884166

Epoch: 5| Step: 9
Training loss: 1.5568252801895142
Validation loss: 2.0273313445429646

Epoch: 5| Step: 10
Training loss: 1.606956124305725
Validation loss: 2.041788221687399

Epoch: 286| Step: 0
Training loss: 1.7780792713165283
Validation loss: 2.046353758022349

Epoch: 5| Step: 1
Training loss: 1.6725788116455078
Validation loss: 2.0550568590882006

Epoch: 5| Step: 2
Training loss: 0.9653528332710266
Validation loss: 2.0096597094689646

Epoch: 5| Step: 3
Training loss: 1.7731525897979736
Validation loss: 2.0649792930131317

Epoch: 5| Step: 4
Training loss: 2.2966160774230957
Validation loss: 2.0525712697736678

Epoch: 5| Step: 5
Training loss: 1.7584025859832764
Validation loss: 2.0306695712509977

Epoch: 5| Step: 6
Training loss: 2.0059847831726074
Validation loss: 2.0571560372588453

Epoch: 5| Step: 7
Training loss: 1.6863844394683838
Validation loss: 1.9860938543914466

Epoch: 5| Step: 8
Training loss: 1.5983434915542603
Validation loss: 2.0133652763981975

Epoch: 5| Step: 9
Training loss: 1.7710622549057007
Validation loss: 2.012273644888273

Epoch: 5| Step: 10
Training loss: 1.5938173532485962
Validation loss: 2.027445859806512

Epoch: 287| Step: 0
Training loss: 1.8293756246566772
Validation loss: 2.0225807159177718

Epoch: 5| Step: 1
Training loss: 1.671156644821167
Validation loss: 2.0243455607403993

Epoch: 5| Step: 2
Training loss: 1.969122290611267
Validation loss: 2.0169980231151787

Epoch: 5| Step: 3
Training loss: 2.2940735816955566
Validation loss: 1.9695725799888693

Epoch: 5| Step: 4
Training loss: 1.3886128664016724
Validation loss: 1.9839410474223476

Epoch: 5| Step: 5
Training loss: 1.444707989692688
Validation loss: 2.033798654874166

Epoch: 5| Step: 6
Training loss: 1.8252489566802979
Validation loss: 1.9900061917561356

Epoch: 5| Step: 7
Training loss: 1.2807235717773438
Validation loss: 2.0224520442306355

Epoch: 5| Step: 8
Training loss: 1.7240930795669556
Validation loss: 1.9985667685026764

Epoch: 5| Step: 9
Training loss: 1.8468666076660156
Validation loss: 1.9920090526662848

Epoch: 5| Step: 10
Training loss: 1.2578051090240479
Validation loss: 2.0239537723602785

Epoch: 288| Step: 0
Training loss: 1.7145709991455078
Validation loss: 2.018117896972164

Epoch: 5| Step: 1
Training loss: 1.670962929725647
Validation loss: 1.984385859581732

Epoch: 5| Step: 2
Training loss: 1.4868074655532837
Validation loss: 2.0126996553072365

Epoch: 5| Step: 3
Training loss: 1.4445109367370605
Validation loss: 2.0383261480639057

Epoch: 5| Step: 4
Training loss: 1.4433166980743408
Validation loss: 2.0131158495462067

Epoch: 5| Step: 5
Training loss: 1.7140785455703735
Validation loss: 2.0332748864286687

Epoch: 5| Step: 6
Training loss: 1.5953707695007324
Validation loss: 2.0499590443026636

Epoch: 5| Step: 7
Training loss: 2.0652647018432617
Validation loss: 2.070449818847

Epoch: 5| Step: 8
Training loss: 2.1565194129943848
Validation loss: 2.0533963480303363

Epoch: 5| Step: 9
Training loss: 2.192582368850708
Validation loss: 2.0602825457049954

Epoch: 5| Step: 10
Training loss: 1.5886619091033936
Validation loss: 2.0457386214246034

Epoch: 289| Step: 0
Training loss: 1.3811067342758179
Validation loss: 2.041790331563642

Epoch: 5| Step: 1
Training loss: 1.4713218212127686
Validation loss: 2.038436124401708

Epoch: 5| Step: 2
Training loss: 1.9385249614715576
Validation loss: 2.0571570011877243

Epoch: 5| Step: 3
Training loss: 1.8355098962783813
Validation loss: 2.030328401955225

Epoch: 5| Step: 4
Training loss: 1.551943063735962
Validation loss: 2.025290193096284

Epoch: 5| Step: 5
Training loss: 1.6727526187896729
Validation loss: 2.0258722241206835

Epoch: 5| Step: 6
Training loss: 1.807050347328186
Validation loss: 2.024834913592185

Epoch: 5| Step: 7
Training loss: 1.6976091861724854
Validation loss: 2.0341096770378853

Epoch: 5| Step: 8
Training loss: 1.6627566814422607
Validation loss: 2.0468666553497314

Epoch: 5| Step: 9
Training loss: 1.4791091680526733
Validation loss: 2.0170485358084402

Epoch: 5| Step: 10
Training loss: 1.9756723642349243
Validation loss: 1.9855727059866792

Epoch: 290| Step: 0
Training loss: 1.4548386335372925
Validation loss: 2.036684282364384

Epoch: 5| Step: 1
Training loss: 1.9906963109970093
Validation loss: 1.9868923976857176

Epoch: 5| Step: 2
Training loss: 1.8370888233184814
Validation loss: 2.0215157462704565

Epoch: 5| Step: 3
Training loss: 1.2318823337554932
Validation loss: 2.009745285075198

Epoch: 5| Step: 4
Training loss: 2.245941162109375
Validation loss: 1.9958728436500794

Epoch: 5| Step: 5
Training loss: 1.8911235332489014
Validation loss: 2.0061603284651235

Epoch: 5| Step: 6
Training loss: 1.8099817037582397
Validation loss: 2.0092402196699575

Epoch: 5| Step: 7
Training loss: 1.329073190689087
Validation loss: 2.001140515009562

Epoch: 5| Step: 8
Training loss: 1.7425906658172607
Validation loss: 1.992974563311505

Epoch: 5| Step: 9
Training loss: 1.6127134561538696
Validation loss: 2.0478599430412374

Epoch: 5| Step: 10
Training loss: 1.6497732400894165
Validation loss: 2.0084907957302627

Epoch: 291| Step: 0
Training loss: 1.7364492416381836
Validation loss: 2.0064049664364068

Epoch: 5| Step: 1
Training loss: 2.2410888671875
Validation loss: 2.015271061210222

Epoch: 5| Step: 2
Training loss: 1.9690946340560913
Validation loss: 1.9838039105938328

Epoch: 5| Step: 3
Training loss: 1.6582874059677124
Validation loss: 2.013434293449566

Epoch: 5| Step: 4
Training loss: 1.7347427606582642
Validation loss: 1.988278745323099

Epoch: 5| Step: 5
Training loss: 1.8554483652114868
Validation loss: 2.0277968042640278

Epoch: 5| Step: 6
Training loss: 1.4044134616851807
Validation loss: 1.964097604956678

Epoch: 5| Step: 7
Training loss: 1.5196293592453003
Validation loss: 2.0115813029709684

Epoch: 5| Step: 8
Training loss: 1.6088054180145264
Validation loss: 2.005722112553094

Epoch: 5| Step: 9
Training loss: 2.1122078895568848
Validation loss: 2.0360681446649695

Epoch: 5| Step: 10
Training loss: 0.8076366186141968
Validation loss: 1.9957898944936774

Epoch: 292| Step: 0
Training loss: 1.7797787189483643
Validation loss: 1.990993607428766

Epoch: 5| Step: 1
Training loss: 1.8564239740371704
Validation loss: 2.0330561668642106

Epoch: 5| Step: 2
Training loss: 1.666386365890503
Validation loss: 2.005850471476073

Epoch: 5| Step: 3
Training loss: 2.0578999519348145
Validation loss: 2.0414540242123347

Epoch: 5| Step: 4
Training loss: 1.4891035556793213
Validation loss: 2.0255398955396426

Epoch: 5| Step: 5
Training loss: 1.6142804622650146
Validation loss: 2.047385342659489

Epoch: 5| Step: 6
Training loss: 1.910913109779358
Validation loss: 2.0334840218226113

Epoch: 5| Step: 7
Training loss: 1.117969274520874
Validation loss: 2.0506343123733357

Epoch: 5| Step: 8
Training loss: 1.730711579322815
Validation loss: 2.042853852753998

Epoch: 5| Step: 9
Training loss: 1.851932168006897
Validation loss: 2.0290076758271907

Epoch: 5| Step: 10
Training loss: 1.413519263267517
Validation loss: 2.025812920703683

Epoch: 293| Step: 0
Training loss: 1.5098692178726196
Validation loss: 2.019452405232255

Epoch: 5| Step: 1
Training loss: 2.113135814666748
Validation loss: 2.0072125260547926

Epoch: 5| Step: 2
Training loss: 1.543846845626831
Validation loss: 2.0243425215444257

Epoch: 5| Step: 3
Training loss: 1.5047740936279297
Validation loss: 2.024837432369109

Epoch: 5| Step: 4
Training loss: 1.6066316366195679
Validation loss: 2.021422883515717

Epoch: 5| Step: 5
Training loss: 1.4687931537628174
Validation loss: 2.0026733888092862

Epoch: 5| Step: 6
Training loss: 1.9857933521270752
Validation loss: 1.9992871476757912

Epoch: 5| Step: 7
Training loss: 1.3028287887573242
Validation loss: 2.048675949855517

Epoch: 5| Step: 8
Training loss: 1.618790626525879
Validation loss: 1.9697063135844406

Epoch: 5| Step: 9
Training loss: 2.114037036895752
Validation loss: 2.028496209011283

Epoch: 5| Step: 10
Training loss: 1.794007658958435
Validation loss: 1.9994032421419698

Epoch: 294| Step: 0
Training loss: 1.5791833400726318
Validation loss: 2.025570748954691

Epoch: 5| Step: 1
Training loss: 1.49135422706604
Validation loss: 2.0690847468632523

Epoch: 5| Step: 2
Training loss: 2.1987128257751465
Validation loss: 2.03149704522984

Epoch: 5| Step: 3
Training loss: 1.6118271350860596
Validation loss: 2.0355308440423783

Epoch: 5| Step: 4
Training loss: 1.1802899837493896
Validation loss: 2.0528123263389833

Epoch: 5| Step: 5
Training loss: 2.3778772354125977
Validation loss: 2.0726463230707313

Epoch: 5| Step: 6
Training loss: 1.6691936254501343
Validation loss: 2.0486010877034997

Epoch: 5| Step: 7
Training loss: 1.7634931802749634
Validation loss: 2.037509560585022

Epoch: 5| Step: 8
Training loss: 1.425377607345581
Validation loss: 2.0304069647225003

Epoch: 5| Step: 9
Training loss: 1.867279052734375
Validation loss: 2.046885253280722

Epoch: 5| Step: 10
Training loss: 1.661495566368103
Validation loss: 2.0137939965853127

Epoch: 295| Step: 0
Training loss: 1.9143520593643188
Validation loss: 2.0260978283420688

Epoch: 5| Step: 1
Training loss: 1.6762523651123047
Validation loss: 2.041880758859778

Epoch: 5| Step: 2
Training loss: 1.3382362127304077
Validation loss: 2.044302068730836

Epoch: 5| Step: 3
Training loss: 1.7109458446502686
Validation loss: 1.9927974259981545

Epoch: 5| Step: 4
Training loss: 1.6893079280853271
Validation loss: 1.9951867698341288

Epoch: 5| Step: 5
Training loss: 1.3373260498046875
Validation loss: 2.0199265505677912

Epoch: 5| Step: 6
Training loss: 1.6561415195465088
Validation loss: 1.9862139378824542

Epoch: 5| Step: 7
Training loss: 1.6370973587036133
Validation loss: 2.035739311607935

Epoch: 5| Step: 8
Training loss: 1.5108911991119385
Validation loss: 2.009240331188325

Epoch: 5| Step: 9
Training loss: 1.8698184490203857
Validation loss: 2.0216735537334154

Epoch: 5| Step: 10
Training loss: 1.907481074333191
Validation loss: 2.030152661826021

Epoch: 296| Step: 0
Training loss: 1.6323543787002563
Validation loss: 2.035285593360983

Epoch: 5| Step: 1
Training loss: 1.3737224340438843
Validation loss: 2.0353198256543887

Epoch: 5| Step: 2
Training loss: 1.1875163316726685
Validation loss: 2.030085991787654

Epoch: 5| Step: 3
Training loss: 1.8551229238510132
Validation loss: 2.0190254078116467

Epoch: 5| Step: 4
Training loss: 2.1539673805236816
Validation loss: 2.05714266274565

Epoch: 5| Step: 5
Training loss: 1.5839147567749023
Validation loss: 2.048943333728339

Epoch: 5| Step: 6
Training loss: 1.8122303485870361
Validation loss: 2.0602534214655557

Epoch: 5| Step: 7
Training loss: 2.6783688068389893
Validation loss: 2.026604034567392

Epoch: 5| Step: 8
Training loss: 1.8612855672836304
Validation loss: 2.0214095448934906

Epoch: 5| Step: 9
Training loss: 1.5601781606674194
Validation loss: 2.0451701456500637

Epoch: 5| Step: 10
Training loss: 1.066279649734497
Validation loss: 2.0242093686134583

Epoch: 297| Step: 0
Training loss: 1.6828088760375977
Validation loss: 2.0329798549734135

Epoch: 5| Step: 1
Training loss: 1.8367913961410522
Validation loss: 2.038942575454712

Epoch: 5| Step: 2
Training loss: 1.6634851694107056
Validation loss: 2.0333169326987317

Epoch: 5| Step: 3
Training loss: 1.3454868793487549
Validation loss: 2.0100939812198764

Epoch: 5| Step: 4
Training loss: 2.0242722034454346
Validation loss: 2.014348109563192

Epoch: 5| Step: 5
Training loss: 1.596468210220337
Validation loss: 1.99192016355453

Epoch: 5| Step: 6
Training loss: 1.7310035228729248
Validation loss: 2.0051973122422413

Epoch: 5| Step: 7
Training loss: 2.0435657501220703
Validation loss: 2.0207440878755305

Epoch: 5| Step: 8
Training loss: 1.423683762550354
Validation loss: 2.0092569307614396

Epoch: 5| Step: 9
Training loss: 1.3276712894439697
Validation loss: 2.045645531787667

Epoch: 5| Step: 10
Training loss: 1.665833592414856
Validation loss: 2.0229204649566324

Epoch: 298| Step: 0
Training loss: 2.003373622894287
Validation loss: 2.028536847842637

Epoch: 5| Step: 1
Training loss: 1.3315589427947998
Validation loss: 2.016970924151841

Epoch: 5| Step: 2
Training loss: 1.0821220874786377
Validation loss: 2.0625795856598885

Epoch: 5| Step: 3
Training loss: 0.9748291969299316
Validation loss: 2.0230253242677256

Epoch: 5| Step: 4
Training loss: 2.1111936569213867
Validation loss: 2.0377019682238178

Epoch: 5| Step: 5
Training loss: 1.9283249378204346
Validation loss: 2.0029975829585904

Epoch: 5| Step: 6
Training loss: 1.8456264734268188
Validation loss: 2.000447997482874

Epoch: 5| Step: 7
Training loss: 1.3385543823242188
Validation loss: 2.0171302800537436

Epoch: 5| Step: 8
Training loss: 1.742648720741272
Validation loss: 2.0098628613256637

Epoch: 5| Step: 9
Training loss: 1.64048171043396
Validation loss: 2.0202310367297103

Epoch: 5| Step: 10
Training loss: 2.216531991958618
Validation loss: 2.0199099074127855

Epoch: 299| Step: 0
Training loss: 1.4095077514648438
Validation loss: 2.0254413235572075

Epoch: 5| Step: 1
Training loss: 1.3930476903915405
Validation loss: 2.0108117826523317

Epoch: 5| Step: 2
Training loss: 1.9782015085220337
Validation loss: 2.039200080338345

Epoch: 5| Step: 3
Training loss: 1.731536865234375
Validation loss: 1.9958317971998645

Epoch: 5| Step: 4
Training loss: 1.896908164024353
Validation loss: 2.04014834537301

Epoch: 5| Step: 5
Training loss: 2.030017137527466
Validation loss: 1.990937650844615

Epoch: 5| Step: 6
Training loss: 1.510243535041809
Validation loss: 2.0226562766618628

Epoch: 5| Step: 7
Training loss: 2.239767551422119
Validation loss: 2.0155616396216938

Epoch: 5| Step: 8
Training loss: 1.8943071365356445
Validation loss: 2.0257213833511516

Epoch: 5| Step: 9
Training loss: 1.1157945394515991
Validation loss: 2.001271797764686

Epoch: 5| Step: 10
Training loss: 1.3381540775299072
Validation loss: 2.010610954735869

Epoch: 300| Step: 0
Training loss: 1.7429378032684326
Validation loss: 2.0619201762701875

Epoch: 5| Step: 1
Training loss: 1.628713607788086
Validation loss: 2.059969073982649

Epoch: 5| Step: 2
Training loss: 1.9155861139297485
Validation loss: 2.0603168831076673

Epoch: 5| Step: 3
Training loss: 1.9832441806793213
Validation loss: 2.0412585132865497

Epoch: 5| Step: 4
Training loss: 1.8698011636734009
Validation loss: 2.060204557193223

Epoch: 5| Step: 5
Training loss: 1.0181365013122559
Validation loss: 2.031452512228361

Epoch: 5| Step: 6
Training loss: 1.3847583532333374
Validation loss: 2.0550604738214964

Epoch: 5| Step: 7
Training loss: 1.526709794998169
Validation loss: 2.031349697420674

Epoch: 5| Step: 8
Training loss: 1.6280609369277954
Validation loss: 2.046470247289186

Epoch: 5| Step: 9
Training loss: 2.0129945278167725
Validation loss: 2.026480822152989

Epoch: 5| Step: 10
Training loss: 1.637942910194397
Validation loss: 2.0112969567698817

Epoch: 301| Step: 0
Training loss: 1.5488580465316772
Validation loss: 2.0189640778367237

Epoch: 5| Step: 1
Training loss: 1.333198070526123
Validation loss: 1.9897203086524882

Epoch: 5| Step: 2
Training loss: 1.7555164098739624
Validation loss: 2.0296939521707515

Epoch: 5| Step: 3
Training loss: 1.7310670614242554
Validation loss: 1.9994139850780528

Epoch: 5| Step: 4
Training loss: 1.8833833932876587
Validation loss: 1.990834128472113

Epoch: 5| Step: 5
Training loss: 2.5617172718048096
Validation loss: 2.0140573991242277

Epoch: 5| Step: 6
Training loss: 1.406585931777954
Validation loss: 2.0265593246747087

Epoch: 5| Step: 7
Training loss: 1.518768072128296
Validation loss: 1.9937204519907634

Epoch: 5| Step: 8
Training loss: 1.362034559249878
Validation loss: 1.9918482572801652

Epoch: 5| Step: 9
Training loss: 1.9977394342422485
Validation loss: 2.002655529206799

Epoch: 5| Step: 10
Training loss: 1.4364023208618164
Validation loss: 2.0202758645498626

Epoch: 302| Step: 0
Training loss: 1.7440242767333984
Validation loss: 2.01684001440643

Epoch: 5| Step: 1
Training loss: 1.9390411376953125
Validation loss: 2.0323818063223236

Epoch: 5| Step: 2
Training loss: 1.078224778175354
Validation loss: 2.043871420685963

Epoch: 5| Step: 3
Training loss: 1.7734134197235107
Validation loss: 2.0363708798603346

Epoch: 5| Step: 4
Training loss: 1.4963405132293701
Validation loss: 1.9909821582096878

Epoch: 5| Step: 5
Training loss: 1.6541141271591187
Validation loss: 2.046071596043084

Epoch: 5| Step: 6
Training loss: 1.4379054307937622
Validation loss: 2.0324370156052294

Epoch: 5| Step: 7
Training loss: 2.0356922149658203
Validation loss: 2.01526371125252

Epoch: 5| Step: 8
Training loss: 1.657173752784729
Validation loss: 1.9784845280390915

Epoch: 5| Step: 9
Training loss: 1.8346824645996094
Validation loss: 2.0297567741845244

Epoch: 5| Step: 10
Training loss: 1.686281681060791
Validation loss: 2.0284619972270024

Epoch: 303| Step: 0
Training loss: 2.123918056488037
Validation loss: 1.9884218938889042

Epoch: 5| Step: 1
Training loss: 1.6529098749160767
Validation loss: 2.001239433083483

Epoch: 5| Step: 2
Training loss: 1.932202935218811
Validation loss: 2.0081731657828055

Epoch: 5| Step: 3
Training loss: 1.2558144330978394
Validation loss: 2.02074622467

Epoch: 5| Step: 4
Training loss: 1.7348906993865967
Validation loss: 2.005483842665149

Epoch: 5| Step: 5
Training loss: 1.6177148818969727
Validation loss: 2.031316820011344

Epoch: 5| Step: 6
Training loss: 1.4759067296981812
Validation loss: 2.045517352319533

Epoch: 5| Step: 7
Training loss: 1.6146867275238037
Validation loss: 2.0310718564577

Epoch: 5| Step: 8
Training loss: 1.6263660192489624
Validation loss: 2.020637294297577

Epoch: 5| Step: 9
Training loss: 1.7383921146392822
Validation loss: 2.0278785151820027

Epoch: 5| Step: 10
Training loss: 1.6981898546218872
Validation loss: 2.0487942413617204

Epoch: 304| Step: 0
Training loss: 1.4423563480377197
Validation loss: 2.0458041673065512

Epoch: 5| Step: 1
Training loss: 1.9739208221435547
Validation loss: 2.0488437080896027

Epoch: 5| Step: 2
Training loss: 1.5930367708206177
Validation loss: 2.0745673179626465

Epoch: 5| Step: 3
Training loss: 1.7019447088241577
Validation loss: 1.9705539364968576

Epoch: 5| Step: 4
Training loss: 1.6062666177749634
Validation loss: 2.034109902638261

Epoch: 5| Step: 5
Training loss: 1.7244656085968018
Validation loss: 2.0292032380257883

Epoch: 5| Step: 6
Training loss: 1.8611587285995483
Validation loss: 2.037565795324182

Epoch: 5| Step: 7
Training loss: 1.327680230140686
Validation loss: 1.9835459237457604

Epoch: 5| Step: 8
Training loss: 1.7854650020599365
Validation loss: 2.0211270650227866

Epoch: 5| Step: 9
Training loss: 1.6618045568466187
Validation loss: 1.9993859926859539

Epoch: 5| Step: 10
Training loss: 1.599852442741394
Validation loss: 2.0372278536519697

Epoch: 305| Step: 0
Training loss: 1.6172497272491455
Validation loss: 2.005537989319012

Epoch: 5| Step: 1
Training loss: 1.7156105041503906
Validation loss: 2.0073365652433006

Epoch: 5| Step: 2
Training loss: 1.7398334741592407
Validation loss: 1.9945958724585913

Epoch: 5| Step: 3
Training loss: 1.8632539510726929
Validation loss: 2.0150533491565334

Epoch: 5| Step: 4
Training loss: 1.8803497552871704
Validation loss: 2.0134947056411416

Epoch: 5| Step: 5
Training loss: 1.8616548776626587
Validation loss: 1.977183113815964

Epoch: 5| Step: 6
Training loss: 1.0460344552993774
Validation loss: 2.0086244921530447

Epoch: 5| Step: 7
Training loss: 1.437363624572754
Validation loss: 1.9726393363809074

Epoch: 5| Step: 8
Training loss: 1.9937366247177124
Validation loss: 1.9834325057204052

Epoch: 5| Step: 9
Training loss: 1.5450961589813232
Validation loss: 2.0117342946349934

Epoch: 5| Step: 10
Training loss: 1.8529465198516846
Validation loss: 1.965706092055126

Epoch: 306| Step: 0
Training loss: 1.3991872072219849
Validation loss: 2.0019305764987902

Epoch: 5| Step: 1
Training loss: 1.530460238456726
Validation loss: 1.998724651593034

Epoch: 5| Step: 2
Training loss: 2.1730642318725586
Validation loss: 1.9898870298939366

Epoch: 5| Step: 3
Training loss: 1.7159309387207031
Validation loss: 2.056283090704231

Epoch: 5| Step: 4
Training loss: 0.9461658596992493
Validation loss: 1.989488999048869

Epoch: 5| Step: 5
Training loss: 1.4158709049224854
Validation loss: 2.0249179588851107

Epoch: 5| Step: 6
Training loss: 1.0198484659194946
Validation loss: 2.0034759365102297

Epoch: 5| Step: 7
Training loss: 1.439213752746582
Validation loss: 2.0023596056046022

Epoch: 5| Step: 8
Training loss: 2.353574514389038
Validation loss: 2.0233863476783998

Epoch: 5| Step: 9
Training loss: 1.9245895147323608
Validation loss: 2.0344322855754564

Epoch: 5| Step: 10
Training loss: 2.2088623046875
Validation loss: 2.0237749263804448

Epoch: 307| Step: 0
Training loss: 1.6588608026504517
Validation loss: 2.0043967462355092

Epoch: 5| Step: 1
Training loss: 1.5279067754745483
Validation loss: 1.9910137550805205

Epoch: 5| Step: 2
Training loss: 2.1470139026641846
Validation loss: 2.0285917892250964

Epoch: 5| Step: 3
Training loss: 1.0977287292480469
Validation loss: 2.0036582639140468

Epoch: 5| Step: 4
Training loss: 1.8270289897918701
Validation loss: 2.0326494786047165

Epoch: 5| Step: 5
Training loss: 1.6771833896636963
Validation loss: 2.035728439208

Epoch: 5| Step: 6
Training loss: 1.2942957878112793
Validation loss: 2.0336917959233767

Epoch: 5| Step: 7
Training loss: 2.020383358001709
Validation loss: 1.9830849350139659

Epoch: 5| Step: 8
Training loss: 2.0641002655029297
Validation loss: 2.015471840417513

Epoch: 5| Step: 9
Training loss: 1.2247450351715088
Validation loss: 2.0142907404130503

Epoch: 5| Step: 10
Training loss: 1.815532922744751
Validation loss: 2.018247437733476

Epoch: 308| Step: 0
Training loss: 1.930646300315857
Validation loss: 2.013267324816796

Epoch: 5| Step: 1
Training loss: 1.5859125852584839
Validation loss: 2.006704140734929

Epoch: 5| Step: 2
Training loss: 1.7036619186401367
Validation loss: 1.9736015668479345

Epoch: 5| Step: 3
Training loss: 1.8582388162612915
Validation loss: 2.0280639484364498

Epoch: 5| Step: 4
Training loss: 1.1217448711395264
Validation loss: 2.0217594997857207

Epoch: 5| Step: 5
Training loss: 1.571812391281128
Validation loss: 2.0254043917502127

Epoch: 5| Step: 6
Training loss: 1.7569115161895752
Validation loss: 2.0385153037245556

Epoch: 5| Step: 7
Training loss: 1.4546929597854614
Validation loss: 2.0293008729975712

Epoch: 5| Step: 8
Training loss: 1.8040294647216797
Validation loss: 2.0653772559217227

Epoch: 5| Step: 9
Training loss: 1.6657041311264038
Validation loss: 2.0204480143003565

Epoch: 5| Step: 10
Training loss: 1.3805584907531738
Validation loss: 2.0589560872764996

Epoch: 309| Step: 0
Training loss: 1.5767227411270142
Validation loss: 2.0423820300768782

Epoch: 5| Step: 1
Training loss: 1.9429527521133423
Validation loss: 2.0649152071245256

Epoch: 5| Step: 2
Training loss: 1.7879912853240967
Validation loss: 2.0545479559129283

Epoch: 5| Step: 3
Training loss: 1.8822520971298218
Validation loss: 2.077057848694504

Epoch: 5| Step: 4
Training loss: 1.3632322549819946
Validation loss: 2.067217452551729

Epoch: 5| Step: 5
Training loss: 1.9022910594940186
Validation loss: 2.0209773868642826

Epoch: 5| Step: 6
Training loss: 1.7882438898086548
Validation loss: 2.0245652044973066

Epoch: 5| Step: 7
Training loss: 1.7732651233673096
Validation loss: 2.040900235534996

Epoch: 5| Step: 8
Training loss: 1.3563052415847778
Validation loss: 2.0156022092347503

Epoch: 5| Step: 9
Training loss: 1.7394269704818726
Validation loss: 2.0201453701142342

Epoch: 5| Step: 10
Training loss: 1.3506064414978027
Validation loss: 2.038572585710915

Epoch: 310| Step: 0
Training loss: 2.043506383895874
Validation loss: 1.9873270219372166

Epoch: 5| Step: 1
Training loss: 2.430224895477295
Validation loss: 2.010896635311906

Epoch: 5| Step: 2
Training loss: 1.6950912475585938
Validation loss: 2.0243152751717517

Epoch: 5| Step: 3
Training loss: 1.208690881729126
Validation loss: 2.008337038819508

Epoch: 5| Step: 4
Training loss: 1.31121027469635
Validation loss: 2.0068138312268

Epoch: 5| Step: 5
Training loss: 2.0053932666778564
Validation loss: 2.017525670348957

Epoch: 5| Step: 6
Training loss: 1.1825354099273682
Validation loss: 2.009360573625052

Epoch: 5| Step: 7
Training loss: 1.667175531387329
Validation loss: 2.0362885126503567

Epoch: 5| Step: 8
Training loss: 1.6801038980484009
Validation loss: 2.0211284852796987

Epoch: 5| Step: 9
Training loss: 1.516585111618042
Validation loss: 2.0407873738196587

Epoch: 5| Step: 10
Training loss: 1.3858386278152466
Validation loss: 2.011897522916076

Epoch: 311| Step: 0
Training loss: 2.053126096725464
Validation loss: 2.0276669686840427

Epoch: 5| Step: 1
Training loss: 1.3037941455841064
Validation loss: 2.030625686850599

Epoch: 5| Step: 2
Training loss: 1.4687426090240479
Validation loss: 2.0121990442276

Epoch: 5| Step: 3
Training loss: 1.742358922958374
Validation loss: 2.0104401598694506

Epoch: 5| Step: 4
Training loss: 1.3474886417388916
Validation loss: 2.032383185560985

Epoch: 5| Step: 5
Training loss: 1.870814561843872
Validation loss: 2.0376863018158944

Epoch: 5| Step: 6
Training loss: 1.25559401512146
Validation loss: 2.0162516178623324

Epoch: 5| Step: 7
Training loss: 1.8233238458633423
Validation loss: 2.0339426327777166

Epoch: 5| Step: 8
Training loss: 1.3466871976852417
Validation loss: 2.0042807286785496

Epoch: 5| Step: 9
Training loss: 1.973615288734436
Validation loss: 2.0074070397243706

Epoch: 5| Step: 10
Training loss: 1.870265245437622
Validation loss: 2.0348233022997455

Epoch: 312| Step: 0
Training loss: 1.3897531032562256
Validation loss: 2.0271352234707085

Epoch: 5| Step: 1
Training loss: 1.5487617254257202
Validation loss: 2.010458984682637

Epoch: 5| Step: 2
Training loss: 1.7785704135894775
Validation loss: 2.001243145235123

Epoch: 5| Step: 3
Training loss: 1.7886568307876587
Validation loss: 1.9913770806404851

Epoch: 5| Step: 4
Training loss: 1.8689771890640259
Validation loss: 2.0119409920066915

Epoch: 5| Step: 5
Training loss: 1.8762401342391968
Validation loss: 1.9998374010926934

Epoch: 5| Step: 6
Training loss: 1.348376989364624
Validation loss: 2.012182427990821

Epoch: 5| Step: 7
Training loss: 2.413839817047119
Validation loss: 1.9866521896854523

Epoch: 5| Step: 8
Training loss: 1.5928196907043457
Validation loss: 2.023586949994487

Epoch: 5| Step: 9
Training loss: 1.074073314666748
Validation loss: 2.0114396515712945

Epoch: 5| Step: 10
Training loss: 1.5352928638458252
Validation loss: 2.0199880035974647

Epoch: 313| Step: 0
Training loss: 1.6159263849258423
Validation loss: 2.0052589626722437

Epoch: 5| Step: 1
Training loss: 1.133043646812439
Validation loss: 2.003476086483207

Epoch: 5| Step: 2
Training loss: 1.8142904043197632
Validation loss: 2.037577247106901

Epoch: 5| Step: 3
Training loss: 1.9640487432479858
Validation loss: 2.0632862865283923

Epoch: 5| Step: 4
Training loss: 1.5393141508102417
Validation loss: 2.0118715609273603

Epoch: 5| Step: 5
Training loss: 1.464302659034729
Validation loss: 2.014996023588283

Epoch: 5| Step: 6
Training loss: 1.325160264968872
Validation loss: 2.061114804719084

Epoch: 5| Step: 7
Training loss: 1.943859338760376
Validation loss: 2.0303621471569104

Epoch: 5| Step: 8
Training loss: 1.8123359680175781
Validation loss: 2.0296659597786526

Epoch: 5| Step: 9
Training loss: 1.8407119512557983
Validation loss: 2.052106438144561

Epoch: 5| Step: 10
Training loss: 1.6345207691192627
Validation loss: 2.029158330732776

Epoch: 314| Step: 0
Training loss: 1.43526029586792
Validation loss: 2.0299317888034287

Epoch: 5| Step: 1
Training loss: 1.451050043106079
Validation loss: 1.9949393400581934

Epoch: 5| Step: 2
Training loss: 1.9008592367172241
Validation loss: 2.0344006553772958

Epoch: 5| Step: 3
Training loss: 2.095015287399292
Validation loss: 2.05386265888009

Epoch: 5| Step: 4
Training loss: 1.2759777307510376
Validation loss: 2.0225110284743772

Epoch: 5| Step: 5
Training loss: 1.7482455968856812
Validation loss: 2.0005897937282437

Epoch: 5| Step: 6
Training loss: 1.581279993057251
Validation loss: 2.030761282931092

Epoch: 5| Step: 7
Training loss: 1.5418336391448975
Validation loss: 2.023671438617091

Epoch: 5| Step: 8
Training loss: 1.0323866605758667
Validation loss: 2.0166029443023024

Epoch: 5| Step: 9
Training loss: 2.322319984436035
Validation loss: 2.0024270319169566

Epoch: 5| Step: 10
Training loss: 1.64693021774292
Validation loss: 2.0174634712998585

Epoch: 315| Step: 0
Training loss: 1.5580447912216187
Validation loss: 2.0061223647927724

Epoch: 5| Step: 1
Training loss: 1.7274442911148071
Validation loss: 2.0594133318111463

Epoch: 5| Step: 2
Training loss: 1.5632727146148682
Validation loss: 2.0078039541039416

Epoch: 5| Step: 3
Training loss: 2.158289670944214
Validation loss: 2.054145851442891

Epoch: 5| Step: 4
Training loss: 1.110264778137207
Validation loss: 2.023766468929988

Epoch: 5| Step: 5
Training loss: 1.9929660558700562
Validation loss: 2.0082136200320337

Epoch: 5| Step: 6
Training loss: 1.9859586954116821
Validation loss: 2.0455724270113054

Epoch: 5| Step: 7
Training loss: 1.29695725440979
Validation loss: 2.005029314307756

Epoch: 5| Step: 8
Training loss: 1.1782143115997314
Validation loss: 2.0251520654206634

Epoch: 5| Step: 9
Training loss: 1.72077214717865
Validation loss: 2.0114142689653622

Epoch: 5| Step: 10
Training loss: 1.5902645587921143
Validation loss: 1.9961669214310185

Epoch: 316| Step: 0
Training loss: 1.5887296199798584
Validation loss: 2.017659318062567

Epoch: 5| Step: 1
Training loss: 1.7219250202178955
Validation loss: 1.984269457478677

Epoch: 5| Step: 2
Training loss: 1.2413837909698486
Validation loss: 2.0148550310442523

Epoch: 5| Step: 3
Training loss: 1.8510799407958984
Validation loss: 2.0343537792082755

Epoch: 5| Step: 4
Training loss: 2.049412488937378
Validation loss: 2.017630079741119

Epoch: 5| Step: 5
Training loss: 1.9374984502792358
Validation loss: 2.015750692736718

Epoch: 5| Step: 6
Training loss: 1.0192562341690063
Validation loss: 2.033071658944571

Epoch: 5| Step: 7
Training loss: 1.7974491119384766
Validation loss: 1.9983400503794353

Epoch: 5| Step: 8
Training loss: 1.9559166431427002
Validation loss: 2.0331706898186797

Epoch: 5| Step: 9
Training loss: 1.1598700284957886
Validation loss: 2.003279785956106

Epoch: 5| Step: 10
Training loss: 1.566658616065979
Validation loss: 2.033084278465599

Epoch: 317| Step: 0
Training loss: 1.6488491296768188
Validation loss: 2.014791537356633

Epoch: 5| Step: 1
Training loss: 1.2828534841537476
Validation loss: 2.078501242463307

Epoch: 5| Step: 2
Training loss: 1.9649219512939453
Validation loss: 2.030946713621898

Epoch: 5| Step: 3
Training loss: 1.8109413385391235
Validation loss: 2.056540484069496

Epoch: 5| Step: 4
Training loss: 1.9867582321166992
Validation loss: 2.006184954797068

Epoch: 5| Step: 5
Training loss: 1.4668415784835815
Validation loss: 2.0102834496446835

Epoch: 5| Step: 6
Training loss: 1.3890721797943115
Validation loss: 1.9940105304923108

Epoch: 5| Step: 7
Training loss: 1.824987769126892
Validation loss: 2.0076622270768687

Epoch: 5| Step: 8
Training loss: 1.4571031332015991
Validation loss: 1.9940261238364763

Epoch: 5| Step: 9
Training loss: 1.6179420948028564
Validation loss: 2.043021768651983

Epoch: 5| Step: 10
Training loss: 1.5256624221801758
Validation loss: 2.021419591801141

Epoch: 318| Step: 0
Training loss: 1.588451623916626
Validation loss: 2.022590346233819

Epoch: 5| Step: 1
Training loss: 1.6860644817352295
Validation loss: 2.006185523925289

Epoch: 5| Step: 2
Training loss: 1.9532296657562256
Validation loss: 2.015644775923862

Epoch: 5| Step: 3
Training loss: 1.3122540712356567
Validation loss: 2.025418953229022

Epoch: 5| Step: 4
Training loss: 1.7147819995880127
Validation loss: 1.9987576443661925

Epoch: 5| Step: 5
Training loss: 1.6770551204681396
Validation loss: 2.0030695981876825

Epoch: 5| Step: 6
Training loss: 1.1040065288543701
Validation loss: 2.019778201656957

Epoch: 5| Step: 7
Training loss: 1.7414233684539795
Validation loss: 2.0016343721779446

Epoch: 5| Step: 8
Training loss: 1.4724713563919067
Validation loss: 2.026811181858022

Epoch: 5| Step: 9
Training loss: 2.1745924949645996
Validation loss: 2.0436033202755834

Epoch: 5| Step: 10
Training loss: 1.6870399713516235
Validation loss: 2.043178235330889

Epoch: 319| Step: 0
Training loss: 1.8408254384994507
Validation loss: 2.0293038032388173

Epoch: 5| Step: 1
Training loss: 2.1110427379608154
Validation loss: 2.0629931111489572

Epoch: 5| Step: 2
Training loss: 1.6502405405044556
Validation loss: 2.0547068900959466

Epoch: 5| Step: 3
Training loss: 1.691702127456665
Validation loss: 2.076259970664978

Epoch: 5| Step: 4
Training loss: 1.2633073329925537
Validation loss: 2.0200373152250886

Epoch: 5| Step: 5
Training loss: 1.4295059442520142
Validation loss: 2.041066790139803

Epoch: 5| Step: 6
Training loss: 2.1021347045898438
Validation loss: 2.0553359113713747

Epoch: 5| Step: 7
Training loss: 1.8809388875961304
Validation loss: 2.0181958983021397

Epoch: 5| Step: 8
Training loss: 1.423818588256836
Validation loss: 2.0429007609685264

Epoch: 5| Step: 9
Training loss: 1.7109296321868896
Validation loss: 2.0424866214875252

Epoch: 5| Step: 10
Training loss: 1.1134365797042847
Validation loss: 2.053108924178667

Epoch: 320| Step: 0
Training loss: 1.578263521194458
Validation loss: 2.0038047554672405

Epoch: 5| Step: 1
Training loss: 1.8487484455108643
Validation loss: 2.0374825385309037

Epoch: 5| Step: 2
Training loss: 1.7981517314910889
Validation loss: 1.9609908673071093

Epoch: 5| Step: 3
Training loss: 1.5872292518615723
Validation loss: 2.024537609469506

Epoch: 5| Step: 4
Training loss: 1.569570779800415
Validation loss: 2.003835362772788

Epoch: 5| Step: 5
Training loss: 1.5998538732528687
Validation loss: 2.020699829183599

Epoch: 5| Step: 6
Training loss: 1.4489796161651611
Validation loss: 2.0052141271611696

Epoch: 5| Step: 7
Training loss: 1.5146129131317139
Validation loss: 2.01516612755355

Epoch: 5| Step: 8
Training loss: 1.8212963342666626
Validation loss: 1.9818509035213019

Epoch: 5| Step: 9
Training loss: 1.687234878540039
Validation loss: 2.0043022735144502

Epoch: 5| Step: 10
Training loss: 1.4526751041412354
Validation loss: 2.0271461343252533

Epoch: 321| Step: 0
Training loss: 1.6313482522964478
Validation loss: 2.0397110318624847

Epoch: 5| Step: 1
Training loss: 1.7401260137557983
Validation loss: 2.042663844682837

Epoch: 5| Step: 2
Training loss: 0.9826051592826843
Validation loss: 2.022904972876272

Epoch: 5| Step: 3
Training loss: 1.5790477991104126
Validation loss: 2.004587073479929

Epoch: 5| Step: 4
Training loss: 1.6252247095108032
Validation loss: 2.0576751552602297

Epoch: 5| Step: 5
Training loss: 2.029294490814209
Validation loss: 2.0367859460974254

Epoch: 5| Step: 6
Training loss: 1.5855947732925415
Validation loss: 2.039525907526734

Epoch: 5| Step: 7
Training loss: 1.9725621938705444
Validation loss: 2.049455391463413

Epoch: 5| Step: 8
Training loss: 1.9700654745101929
Validation loss: 2.043701389784454

Epoch: 5| Step: 9
Training loss: 1.137510895729065
Validation loss: 2.0334923164818877

Epoch: 5| Step: 10
Training loss: 1.9360837936401367
Validation loss: 2.0407488423009075

Epoch: 322| Step: 0
Training loss: 1.4601653814315796
Validation loss: 2.0422902773785334

Epoch: 5| Step: 1
Training loss: 1.708371877670288
Validation loss: 2.0235456625620523

Epoch: 5| Step: 2
Training loss: 1.9687893390655518
Validation loss: 2.0435137287262948

Epoch: 5| Step: 3
Training loss: 1.4378076791763306
Validation loss: 2.029397858086453

Epoch: 5| Step: 4
Training loss: 1.3973232507705688
Validation loss: 2.0540009672923754

Epoch: 5| Step: 5
Training loss: 1.563245415687561
Validation loss: 2.043927668243326

Epoch: 5| Step: 6
Training loss: 1.7440245151519775
Validation loss: 1.99332114829812

Epoch: 5| Step: 7
Training loss: 2.1349058151245117
Validation loss: 2.0202436331779725

Epoch: 5| Step: 8
Training loss: 1.6538867950439453
Validation loss: 2.085070005027197

Epoch: 5| Step: 9
Training loss: 1.356315016746521
Validation loss: 2.017178225260909

Epoch: 5| Step: 10
Training loss: 1.265635371208191
Validation loss: 2.000719178107477

Epoch: 323| Step: 0
Training loss: 1.803966760635376
Validation loss: 2.0081970486589658

Epoch: 5| Step: 1
Training loss: 1.9986006021499634
Validation loss: 2.0410387644203762

Epoch: 5| Step: 2
Training loss: 1.5850493907928467
Validation loss: 2.0221309687501643

Epoch: 5| Step: 3
Training loss: 1.5742712020874023
Validation loss: 2.0267715018282653

Epoch: 5| Step: 4
Training loss: 2.1279208660125732
Validation loss: 2.00993138359439

Epoch: 5| Step: 5
Training loss: 1.801746129989624
Validation loss: 2.0444067319234214

Epoch: 5| Step: 6
Training loss: 1.357928991317749
Validation loss: 1.9953478074842883

Epoch: 5| Step: 7
Training loss: 1.125043511390686
Validation loss: 2.051570966679563

Epoch: 5| Step: 8
Training loss: 1.548940896987915
Validation loss: 2.021563429986277

Epoch: 5| Step: 9
Training loss: 1.593493103981018
Validation loss: 2.055783002607284

Epoch: 5| Step: 10
Training loss: 1.372288465499878
Validation loss: 2.02614325733595

Epoch: 324| Step: 0
Training loss: 1.4116312265396118
Validation loss: 2.013491489553964

Epoch: 5| Step: 1
Training loss: 1.826434850692749
Validation loss: 2.015049539586549

Epoch: 5| Step: 2
Training loss: 1.6077995300292969
Validation loss: 1.9966720406727125

Epoch: 5| Step: 3
Training loss: 1.0824058055877686
Validation loss: 2.024436358482607

Epoch: 5| Step: 4
Training loss: 1.8525810241699219
Validation loss: 2.0310019793048983

Epoch: 5| Step: 5
Training loss: 1.7728646993637085
Validation loss: 2.043076635688864

Epoch: 5| Step: 6
Training loss: 1.8648900985717773
Validation loss: 1.9899581734852125

Epoch: 5| Step: 7
Training loss: 1.5003821849822998
Validation loss: 2.0248072993370796

Epoch: 5| Step: 8
Training loss: 1.8654342889785767
Validation loss: 2.0298703614101616

Epoch: 5| Step: 9
Training loss: 1.4073572158813477
Validation loss: 2.0424753389050885

Epoch: 5| Step: 10
Training loss: 1.8443317413330078
Validation loss: 1.9970546576284594

Epoch: 325| Step: 0
Training loss: 2.408417224884033
Validation loss: 2.037742712164438

Epoch: 5| Step: 1
Training loss: 1.4597400426864624
Validation loss: 2.029361069843333

Epoch: 5| Step: 2
Training loss: 1.5756345987319946
Validation loss: 2.0051700069058325

Epoch: 5| Step: 3
Training loss: 1.4327366352081299
Validation loss: 2.015903498536797

Epoch: 5| Step: 4
Training loss: 1.4998598098754883
Validation loss: 1.9986545296125515

Epoch: 5| Step: 5
Training loss: 1.968304991722107
Validation loss: 2.063744327073456

Epoch: 5| Step: 6
Training loss: 1.6220191717147827
Validation loss: 2.064358542042394

Epoch: 5| Step: 7
Training loss: 1.8171584606170654
Validation loss: 2.051916395464251

Epoch: 5| Step: 8
Training loss: 1.2417106628417969
Validation loss: 2.043658246276199

Epoch: 5| Step: 9
Training loss: 1.4967106580734253
Validation loss: 2.0300310734779603

Epoch: 5| Step: 10
Training loss: 1.4291455745697021
Validation loss: 2.021324192323992

Epoch: 326| Step: 0
Training loss: 1.9467626810073853
Validation loss: 2.0212539601069626

Epoch: 5| Step: 1
Training loss: 1.2948294878005981
Validation loss: 2.0477113800664104

Epoch: 5| Step: 2
Training loss: 0.6633108854293823
Validation loss: 2.0270352427677443

Epoch: 5| Step: 3
Training loss: 1.5702152252197266
Validation loss: 2.0336411794026694

Epoch: 5| Step: 4
Training loss: 1.402177095413208
Validation loss: 2.0199174086252847

Epoch: 5| Step: 5
Training loss: 1.4910835027694702
Validation loss: 2.0096484896957234

Epoch: 5| Step: 6
Training loss: 1.4366555213928223
Validation loss: 1.9948844525121874

Epoch: 5| Step: 7
Training loss: 1.7662384510040283
Validation loss: 1.9943202234083606

Epoch: 5| Step: 8
Training loss: 1.906672716140747
Validation loss: 2.031627247410436

Epoch: 5| Step: 9
Training loss: 1.9116472005844116
Validation loss: 2.031421337076413

Epoch: 5| Step: 10
Training loss: 2.4784481525421143
Validation loss: 1.980343908391973

Epoch: 327| Step: 0
Training loss: 1.3162076473236084
Validation loss: 2.0257685081933134

Epoch: 5| Step: 1
Training loss: 1.4864641427993774
Validation loss: 2.0221188363208564

Epoch: 5| Step: 2
Training loss: 1.2388594150543213
Validation loss: 1.9958161705283708

Epoch: 5| Step: 3
Training loss: 1.4619777202606201
Validation loss: 2.0299266845949235

Epoch: 5| Step: 4
Training loss: 1.6571455001831055
Validation loss: 2.0258487219451577

Epoch: 5| Step: 5
Training loss: 1.4822918176651
Validation loss: 2.0039224073451054

Epoch: 5| Step: 6
Training loss: 1.6460046768188477
Validation loss: 1.9986200153186757

Epoch: 5| Step: 7
Training loss: 1.8689075708389282
Validation loss: 2.0239315955869612

Epoch: 5| Step: 8
Training loss: 1.730308175086975
Validation loss: 1.9805222711255472

Epoch: 5| Step: 9
Training loss: 1.6525919437408447
Validation loss: 2.021405714814381

Epoch: 5| Step: 10
Training loss: 2.291195869445801
Validation loss: 2.0139061109994048

Epoch: 328| Step: 0
Training loss: 1.5885459184646606
Validation loss: 2.0052014935401177

Epoch: 5| Step: 1
Training loss: 1.4480644464492798
Validation loss: 2.019189214193693

Epoch: 5| Step: 2
Training loss: 1.4460890293121338
Validation loss: 2.0162962226457495

Epoch: 5| Step: 3
Training loss: 0.9451875686645508
Validation loss: 2.013803433346492

Epoch: 5| Step: 4
Training loss: 1.7336753606796265
Validation loss: 2.0440576461053666

Epoch: 5| Step: 5
Training loss: 1.9720611572265625
Validation loss: 2.042172393491191

Epoch: 5| Step: 6
Training loss: 1.8596744537353516
Validation loss: 2.031028562976468

Epoch: 5| Step: 7
Training loss: 1.8528363704681396
Validation loss: 2.0573740172129806

Epoch: 5| Step: 8
Training loss: 2.2541418075561523
Validation loss: 2.0876933951531687

Epoch: 5| Step: 9
Training loss: 1.3831273317337036
Validation loss: 2.04254670809674

Epoch: 5| Step: 10
Training loss: 1.8282667398452759
Validation loss: 2.0606286833363194

Epoch: 329| Step: 0
Training loss: 1.5014747381210327
Validation loss: 2.0220768656781924

Epoch: 5| Step: 1
Training loss: 1.8324626684188843
Validation loss: 2.031188570043092

Epoch: 5| Step: 2
Training loss: 1.8294458389282227
Validation loss: 2.041003509234357

Epoch: 5| Step: 3
Training loss: 1.5847676992416382
Validation loss: 2.025484800338745

Epoch: 5| Step: 4
Training loss: 1.8451597690582275
Validation loss: 1.9973536896449264

Epoch: 5| Step: 5
Training loss: 1.6844819784164429
Validation loss: 1.9922464432254914

Epoch: 5| Step: 6
Training loss: 1.4589983224868774
Validation loss: 1.995500313338413

Epoch: 5| Step: 7
Training loss: 1.442481279373169
Validation loss: 2.0319312849352436

Epoch: 5| Step: 8
Training loss: 1.5445764064788818
Validation loss: 2.043216302830686

Epoch: 5| Step: 9
Training loss: 1.4666727781295776
Validation loss: 2.010874153465353

Epoch: 5| Step: 10
Training loss: 1.5924776792526245
Validation loss: 2.0018254813327583

Epoch: 330| Step: 0
Training loss: 1.8133608102798462
Validation loss: 2.039418730684506

Epoch: 5| Step: 1
Training loss: 1.7820335626602173
Validation loss: 2.0115219393084125

Epoch: 5| Step: 2
Training loss: 1.3523383140563965
Validation loss: 2.018629612461213

Epoch: 5| Step: 3
Training loss: 1.5329302549362183
Validation loss: 2.0191916701614216

Epoch: 5| Step: 4
Training loss: 1.544632911682129
Validation loss: 2.038447312129441

Epoch: 5| Step: 5
Training loss: 1.328627586364746
Validation loss: 2.0167142652696177

Epoch: 5| Step: 6
Training loss: 1.609999418258667
Validation loss: 2.0417805384564143

Epoch: 5| Step: 7
Training loss: 1.8414719104766846
Validation loss: 2.0307161961832354

Epoch: 5| Step: 8
Training loss: 1.2108705043792725
Validation loss: 2.0585229704456944

Epoch: 5| Step: 9
Training loss: 1.7179210186004639
Validation loss: 2.0524875015340824

Epoch: 5| Step: 10
Training loss: 2.18172287940979
Validation loss: 2.033089465992425

Epoch: 331| Step: 0
Training loss: 1.2134578227996826
Validation loss: 2.010524196009482

Epoch: 5| Step: 1
Training loss: 1.511634111404419
Validation loss: 2.053958794122101

Epoch: 5| Step: 2
Training loss: 1.5831763744354248
Validation loss: 2.0428075880132694

Epoch: 5| Step: 3
Training loss: 1.1136329174041748
Validation loss: 2.031764195811364

Epoch: 5| Step: 4
Training loss: 1.4472742080688477
Validation loss: 2.017156395860898

Epoch: 5| Step: 5
Training loss: 1.664913535118103
Validation loss: 2.0123879755696943

Epoch: 5| Step: 6
Training loss: 1.9526748657226562
Validation loss: 2.029647322111232

Epoch: 5| Step: 7
Training loss: 1.6229747533798218
Validation loss: 1.9970821719015799

Epoch: 5| Step: 8
Training loss: 2.2198519706726074
Validation loss: 2.020588182633923

Epoch: 5| Step: 9
Training loss: 1.3479738235473633
Validation loss: 2.0374638700997956

Epoch: 5| Step: 10
Training loss: 2.129624366760254
Validation loss: 2.0168242082800916

Epoch: 332| Step: 0
Training loss: 2.082972764968872
Validation loss: 2.010680575524607

Epoch: 5| Step: 1
Training loss: 1.7046597003936768
Validation loss: 2.0620471328817387

Epoch: 5| Step: 2
Training loss: 1.5812081098556519
Validation loss: 1.99476206943553

Epoch: 5| Step: 3
Training loss: 1.4149746894836426
Validation loss: 2.027137828129594

Epoch: 5| Step: 4
Training loss: 1.8285986185073853
Validation loss: 2.029175332797471

Epoch: 5| Step: 5
Training loss: 1.335152268409729
Validation loss: 2.0450280199768724

Epoch: 5| Step: 6
Training loss: 1.4674489498138428
Validation loss: 2.024932889528172

Epoch: 5| Step: 7
Training loss: 1.7740342617034912
Validation loss: 2.0042784572929464

Epoch: 5| Step: 8
Training loss: 1.3059974908828735
Validation loss: 2.0300795749951432

Epoch: 5| Step: 9
Training loss: 1.3974097967147827
Validation loss: 2.045565644900004

Epoch: 5| Step: 10
Training loss: 1.5177202224731445
Validation loss: 2.0325497004293624

Epoch: 333| Step: 0
Training loss: 1.660865068435669
Validation loss: 2.044629416158122

Epoch: 5| Step: 1
Training loss: 2.089136838912964
Validation loss: 2.017922365537254

Epoch: 5| Step: 2
Training loss: 1.6499465703964233
Validation loss: 2.0092545940030004

Epoch: 5| Step: 3
Training loss: 1.2930018901824951
Validation loss: 2.0060438315073648

Epoch: 5| Step: 4
Training loss: 1.3379838466644287
Validation loss: 2.0336084404299335

Epoch: 5| Step: 5
Training loss: 1.8373386859893799
Validation loss: 2.0009043037250476

Epoch: 5| Step: 6
Training loss: 1.8879477977752686
Validation loss: 1.9983995832422727

Epoch: 5| Step: 7
Training loss: 1.6563972234725952
Validation loss: 2.0232855799377605

Epoch: 5| Step: 8
Training loss: 1.6566593647003174
Validation loss: 1.9988941454118299

Epoch: 5| Step: 9
Training loss: 1.3261061906814575
Validation loss: 1.973908346186402

Epoch: 5| Step: 10
Training loss: 1.5156861543655396
Validation loss: 1.9913749887097267

Epoch: 334| Step: 0
Training loss: 2.1626458168029785
Validation loss: 2.0162695902650074

Epoch: 5| Step: 1
Training loss: 0.9484649896621704
Validation loss: 2.065139324434342

Epoch: 5| Step: 2
Training loss: 1.2393271923065186
Validation loss: 2.051725727255626

Epoch: 5| Step: 3
Training loss: 1.464950680732727
Validation loss: 2.001495535655688

Epoch: 5| Step: 4
Training loss: 1.5062010288238525
Validation loss: 2.0277917256919284

Epoch: 5| Step: 5
Training loss: 2.164715528488159
Validation loss: 2.0483348036325104

Epoch: 5| Step: 6
Training loss: 1.6023918390274048
Validation loss: 2.000564093230873

Epoch: 5| Step: 7
Training loss: 1.4818896055221558
Validation loss: 2.0347322533207555

Epoch: 5| Step: 8
Training loss: 1.617616057395935
Validation loss: 2.0284698009490967

Epoch: 5| Step: 9
Training loss: 1.7742226123809814
Validation loss: 2.0135190294634913

Epoch: 5| Step: 10
Training loss: 1.6200456619262695
Validation loss: 2.001955211803477

Epoch: 335| Step: 0
Training loss: 1.503340244293213
Validation loss: 2.035215039407053

Epoch: 5| Step: 1
Training loss: 0.9383938908576965
Validation loss: 2.02345779121563

Epoch: 5| Step: 2
Training loss: 1.810555100440979
Validation loss: 2.0250077875711585

Epoch: 5| Step: 3
Training loss: 1.3970617055892944
Validation loss: 2.0444825772316224

Epoch: 5| Step: 4
Training loss: 1.9959237575531006
Validation loss: 2.019521479965538

Epoch: 5| Step: 5
Training loss: 1.880677580833435
Validation loss: 2.026720235424657

Epoch: 5| Step: 6
Training loss: 1.9161109924316406
Validation loss: 2.024394163521387

Epoch: 5| Step: 7
Training loss: 1.3174118995666504
Validation loss: 2.036248342965239

Epoch: 5| Step: 8
Training loss: 1.3903014659881592
Validation loss: 2.0210901242430492

Epoch: 5| Step: 9
Training loss: 1.5576088428497314
Validation loss: 2.0093613875809537

Epoch: 5| Step: 10
Training loss: 1.8293687105178833
Validation loss: 2.0031560595317552

Epoch: 336| Step: 0
Training loss: 1.1181955337524414
Validation loss: 2.0031993696766515

Epoch: 5| Step: 1
Training loss: 2.0014004707336426
Validation loss: 2.025911914405002

Epoch: 5| Step: 2
Training loss: 1.4322130680084229
Validation loss: 1.9886771094414495

Epoch: 5| Step: 3
Training loss: 1.5363892316818237
Validation loss: 2.0376668207107054

Epoch: 5| Step: 4
Training loss: 2.1991448402404785
Validation loss: 2.024135338362827

Epoch: 5| Step: 5
Training loss: 1.5545873641967773
Validation loss: 1.998937645266133

Epoch: 5| Step: 6
Training loss: 1.8114993572235107
Validation loss: 2.0159670819518385

Epoch: 5| Step: 7
Training loss: 1.4582440853118896
Validation loss: 2.0543338419288717

Epoch: 5| Step: 8
Training loss: 1.33272385597229
Validation loss: 2.050838488404469

Epoch: 5| Step: 9
Training loss: 1.5806748867034912
Validation loss: 1.9973905547972648

Epoch: 5| Step: 10
Training loss: 1.6233271360397339
Validation loss: 2.0491696403872584

Epoch: 337| Step: 0
Training loss: 1.7864458560943604
Validation loss: 2.0246287930396294

Epoch: 5| Step: 1
Training loss: 1.5729691982269287
Validation loss: 2.008922464104109

Epoch: 5| Step: 2
Training loss: 1.9252103567123413
Validation loss: 2.0629144214814708

Epoch: 5| Step: 3
Training loss: 1.5377804040908813
Validation loss: 2.0193943490264235

Epoch: 5| Step: 4
Training loss: 0.9952880144119263
Validation loss: 2.0370122976200555

Epoch: 5| Step: 5
Training loss: 1.7272682189941406
Validation loss: 1.988482113807432

Epoch: 5| Step: 6
Training loss: 1.4288972616195679
Validation loss: 2.024019218260242

Epoch: 5| Step: 7
Training loss: 1.6594657897949219
Validation loss: 2.032418094655519

Epoch: 5| Step: 8
Training loss: 2.038966655731201
Validation loss: 1.99198454682545

Epoch: 5| Step: 9
Training loss: 1.418370008468628
Validation loss: 2.0105987723155687

Epoch: 5| Step: 10
Training loss: 1.3315322399139404
Validation loss: 2.020531731267129

Epoch: 338| Step: 0
Training loss: 1.4504082202911377
Validation loss: 2.027013712031867

Epoch: 5| Step: 1
Training loss: 1.472522497177124
Validation loss: 2.0224564562561693

Epoch: 5| Step: 2
Training loss: 1.498063564300537
Validation loss: 2.0576921047702914

Epoch: 5| Step: 3
Training loss: 1.3424782752990723
Validation loss: 2.036937185513076

Epoch: 5| Step: 4
Training loss: 1.680428147315979
Validation loss: 2.0111297138275637

Epoch: 5| Step: 5
Training loss: 2.203666925430298
Validation loss: 2.0259062756774244

Epoch: 5| Step: 6
Training loss: 1.3188644647598267
Validation loss: 2.0407417140981203

Epoch: 5| Step: 7
Training loss: 1.6009342670440674
Validation loss: 2.042902138925368

Epoch: 5| Step: 8
Training loss: 1.4487650394439697
Validation loss: 2.0277199347813926

Epoch: 5| Step: 9
Training loss: 1.8732585906982422
Validation loss: 2.0119664028126705

Epoch: 5| Step: 10
Training loss: 1.976633906364441
Validation loss: 2.0434893049219602

Epoch: 339| Step: 0
Training loss: 1.6285864114761353
Validation loss: 2.0385775976283576

Epoch: 5| Step: 1
Training loss: 1.5466578006744385
Validation loss: 2.0790915527651386

Epoch: 5| Step: 2
Training loss: 1.133134126663208
Validation loss: 2.080079609347928

Epoch: 5| Step: 3
Training loss: 1.548593282699585
Validation loss: 2.0360151619039555

Epoch: 5| Step: 4
Training loss: 2.0326590538024902
Validation loss: 2.037508697919948

Epoch: 5| Step: 5
Training loss: 1.5521076917648315
Validation loss: 1.9956848159913094

Epoch: 5| Step: 6
Training loss: 1.7240060567855835
Validation loss: 2.0359258574824177

Epoch: 5| Step: 7
Training loss: 1.413238286972046
Validation loss: 2.0411709931588944

Epoch: 5| Step: 8
Training loss: 1.4690076112747192
Validation loss: 2.078511397043864

Epoch: 5| Step: 9
Training loss: 1.6790587902069092
Validation loss: 2.032432190833553

Epoch: 5| Step: 10
Training loss: 1.9223042726516724
Validation loss: 2.0281976422955914

Epoch: 340| Step: 0
Training loss: 1.4313849210739136
Validation loss: 2.0283339587591027

Epoch: 5| Step: 1
Training loss: 0.9962002635002136
Validation loss: 2.0155550869562293

Epoch: 5| Step: 2
Training loss: 1.889298677444458
Validation loss: 2.038495627782678

Epoch: 5| Step: 3
Training loss: 2.1756134033203125
Validation loss: 2.0262309799912157

Epoch: 5| Step: 4
Training loss: 1.4889241456985474
Validation loss: 2.026656325145434

Epoch: 5| Step: 5
Training loss: 1.9299224615097046
Validation loss: 2.0018608070188955

Epoch: 5| Step: 6
Training loss: 1.2250380516052246
Validation loss: 2.0168764463035007

Epoch: 5| Step: 7
Training loss: 1.8728077411651611
Validation loss: 2.004115767376397

Epoch: 5| Step: 8
Training loss: 1.356695532798767
Validation loss: 2.0652962487231017

Epoch: 5| Step: 9
Training loss: 1.7086464166641235
Validation loss: 2.0478583664022465

Epoch: 5| Step: 10
Training loss: 1.523681640625
Validation loss: 2.039133261608821

Epoch: 341| Step: 0
Training loss: 1.436462640762329
Validation loss: 2.006920204367689

Epoch: 5| Step: 1
Training loss: 1.6349456310272217
Validation loss: 2.0196791925737934

Epoch: 5| Step: 2
Training loss: 0.5840896368026733
Validation loss: 2.00645020187542

Epoch: 5| Step: 3
Training loss: 1.476170301437378
Validation loss: 2.0142618315194243

Epoch: 5| Step: 4
Training loss: 1.8360573053359985
Validation loss: 2.0114838897541003

Epoch: 5| Step: 5
Training loss: 1.6325187683105469
Validation loss: 1.9797309778069938

Epoch: 5| Step: 6
Training loss: 1.20390784740448
Validation loss: 2.0052960816250054

Epoch: 5| Step: 7
Training loss: 2.0892558097839355
Validation loss: 2.002354516777941

Epoch: 5| Step: 8
Training loss: 1.6708351373672485
Validation loss: 2.0332916705839095

Epoch: 5| Step: 9
Training loss: 2.0842514038085938
Validation loss: 2.019697673859135

Epoch: 5| Step: 10
Training loss: 1.916906476020813
Validation loss: 1.994332339174004

Epoch: 342| Step: 0
Training loss: 2.4783387184143066
Validation loss: 1.9745013662563857

Epoch: 5| Step: 1
Training loss: 1.4596465826034546
Validation loss: 2.0063162093521445

Epoch: 5| Step: 2
Training loss: 1.4036494493484497
Validation loss: 2.0200352540580173

Epoch: 5| Step: 3
Training loss: 1.3327115774154663
Validation loss: 2.0289373115826677

Epoch: 5| Step: 4
Training loss: 1.855352759361267
Validation loss: 2.0378247114919845

Epoch: 5| Step: 5
Training loss: 1.47320556640625
Validation loss: 2.027379471768615

Epoch: 5| Step: 6
Training loss: 1.6039537191390991
Validation loss: 2.020392838344779

Epoch: 5| Step: 7
Training loss: 1.252638578414917
Validation loss: 2.037384328021798

Epoch: 5| Step: 8
Training loss: 1.5307613611221313
Validation loss: 2.00168469900726

Epoch: 5| Step: 9
Training loss: 1.2667744159698486
Validation loss: 2.043446528014316

Epoch: 5| Step: 10
Training loss: 1.772538185119629
Validation loss: 2.0574761923923286

Epoch: 343| Step: 0
Training loss: 1.5488572120666504
Validation loss: 2.049336148846534

Epoch: 5| Step: 1
Training loss: 1.2938898801803589
Validation loss: 2.0719390428194435

Epoch: 5| Step: 2
Training loss: 1.867408037185669
Validation loss: 2.062745733927655

Epoch: 5| Step: 3
Training loss: 1.948744535446167
Validation loss: 2.039775288233193

Epoch: 5| Step: 4
Training loss: 1.7535938024520874
Validation loss: 2.0461918000252015

Epoch: 5| Step: 5
Training loss: 2.0740535259246826
Validation loss: 2.0121483623340564

Epoch: 5| Step: 6
Training loss: 1.5464709997177124
Validation loss: 2.01624854277539

Epoch: 5| Step: 7
Training loss: 1.3839439153671265
Validation loss: 2.0117900833006828

Epoch: 5| Step: 8
Training loss: 1.512569785118103
Validation loss: 2.006067083727929

Epoch: 5| Step: 9
Training loss: 1.2294929027557373
Validation loss: 2.0091660996919036

Epoch: 5| Step: 10
Training loss: 1.2498455047607422
Validation loss: 1.9730575059049873

Epoch: 344| Step: 0
Training loss: 1.764396071434021
Validation loss: 1.9985996459120063

Epoch: 5| Step: 1
Training loss: 1.8107478618621826
Validation loss: 1.9941883933159612

Epoch: 5| Step: 2
Training loss: 1.523595929145813
Validation loss: 1.991099916478639

Epoch: 5| Step: 3
Training loss: 1.6767174005508423
Validation loss: 2.0629688667994674

Epoch: 5| Step: 4
Training loss: 1.5473626852035522
Validation loss: 2.052328368668915

Epoch: 5| Step: 5
Training loss: 1.8973808288574219
Validation loss: 2.0229655388862855

Epoch: 5| Step: 6
Training loss: 1.382124900817871
Validation loss: 2.0316287548311296

Epoch: 5| Step: 7
Training loss: 1.6367909908294678
Validation loss: 2.0867899489659134

Epoch: 5| Step: 8
Training loss: 1.5521191358566284
Validation loss: 2.041540995720894

Epoch: 5| Step: 9
Training loss: 1.3352324962615967
Validation loss: 2.045015219719179

Epoch: 5| Step: 10
Training loss: 1.4276127815246582
Validation loss: 2.0262109438578286

Epoch: 345| Step: 0
Training loss: 2.013716220855713
Validation loss: 2.0206640766512964

Epoch: 5| Step: 1
Training loss: 1.2408249378204346
Validation loss: 2.0270462125860234

Epoch: 5| Step: 2
Training loss: 1.6734310388565063
Validation loss: 1.9892139896269767

Epoch: 5| Step: 3
Training loss: 1.4517377614974976
Validation loss: 2.0186587431097545

Epoch: 5| Step: 4
Training loss: 1.5300171375274658
Validation loss: 1.9858707176741732

Epoch: 5| Step: 5
Training loss: 1.8147433996200562
Validation loss: 2.003852846801922

Epoch: 5| Step: 6
Training loss: 1.4563720226287842
Validation loss: 1.994395238096996

Epoch: 5| Step: 7
Training loss: 1.5854196548461914
Validation loss: 1.9995568952252787

Epoch: 5| Step: 8
Training loss: 1.7548134326934814
Validation loss: 1.9941586679027927

Epoch: 5| Step: 9
Training loss: 1.5915400981903076
Validation loss: 1.9971928314496112

Epoch: 5| Step: 10
Training loss: 1.4354873895645142
Validation loss: 2.0203475977784846

Epoch: 346| Step: 0
Training loss: 1.635385513305664
Validation loss: 2.016164982190696

Epoch: 5| Step: 1
Training loss: 1.562016248703003
Validation loss: 2.030235634055189

Epoch: 5| Step: 2
Training loss: 1.526397466659546
Validation loss: 1.998059925212655

Epoch: 5| Step: 3
Training loss: 1.7190406322479248
Validation loss: 1.9978623723471036

Epoch: 5| Step: 4
Training loss: 1.6553821563720703
Validation loss: 2.0639565913907942

Epoch: 5| Step: 5
Training loss: 0.9748173952102661
Validation loss: 2.047560194487213

Epoch: 5| Step: 6
Training loss: 1.9062869548797607
Validation loss: 2.0399365271291425

Epoch: 5| Step: 7
Training loss: 2.071772575378418
Validation loss: 2.046548105055286

Epoch: 5| Step: 8
Training loss: 1.2475074529647827
Validation loss: 2.0451719145621023

Epoch: 5| Step: 9
Training loss: 1.387408971786499
Validation loss: 2.0629350293067192

Epoch: 5| Step: 10
Training loss: 1.9421566724777222
Validation loss: 2.066985373855919

Epoch: 347| Step: 0
Training loss: 1.4584699869155884
Validation loss: 2.011091193845195

Epoch: 5| Step: 1
Training loss: 1.7759220600128174
Validation loss: 2.0552679723308933

Epoch: 5| Step: 2
Training loss: 1.0887640714645386
Validation loss: 2.030597795722305

Epoch: 5| Step: 3
Training loss: 1.5165207386016846
Validation loss: 2.0179901007683045

Epoch: 5| Step: 4
Training loss: 1.6370413303375244
Validation loss: 1.9889809059840378

Epoch: 5| Step: 5
Training loss: 1.7724637985229492
Validation loss: 2.0098165350575603

Epoch: 5| Step: 6
Training loss: 1.6494731903076172
Validation loss: 2.0009162759268158

Epoch: 5| Step: 7
Training loss: 1.0233643054962158
Validation loss: 2.0372928983421734

Epoch: 5| Step: 8
Training loss: 1.979016900062561
Validation loss: 1.996499156439176

Epoch: 5| Step: 9
Training loss: 1.4353874921798706
Validation loss: 2.0073914297165407

Epoch: 5| Step: 10
Training loss: 2.252592086791992
Validation loss: 1.9953972626757879

Epoch: 348| Step: 0
Training loss: 1.5635569095611572
Validation loss: 1.9770736309789843

Epoch: 5| Step: 1
Training loss: 1.5806362628936768
Validation loss: 2.0028111857752644

Epoch: 5| Step: 2
Training loss: 1.257633090019226
Validation loss: 1.985193657618697

Epoch: 5| Step: 3
Training loss: 1.6873775720596313
Validation loss: 2.0143604252928045

Epoch: 5| Step: 4
Training loss: 1.6743055582046509
Validation loss: 2.0252901174688853

Epoch: 5| Step: 5
Training loss: 1.3487972021102905
Validation loss: 1.9905500155623241

Epoch: 5| Step: 6
Training loss: 1.4138453006744385
Validation loss: 2.0341851352363505

Epoch: 5| Step: 7
Training loss: 1.7928218841552734
Validation loss: 2.0651148442299134

Epoch: 5| Step: 8
Training loss: 1.9011147022247314
Validation loss: 1.9916744103995703

Epoch: 5| Step: 9
Training loss: 1.648669958114624
Validation loss: 2.052335032852747

Epoch: 5| Step: 10
Training loss: 1.6556463241577148
Validation loss: 2.0638934553310437

Epoch: 349| Step: 0
Training loss: 1.0243805646896362
Validation loss: 2.0370427741799304

Epoch: 5| Step: 1
Training loss: 2.124718427658081
Validation loss: 1.9858656224384104

Epoch: 5| Step: 2
Training loss: 1.1339635848999023
Validation loss: 2.0311125298982025

Epoch: 5| Step: 3
Training loss: 1.8178352117538452
Validation loss: 2.03189956244602

Epoch: 5| Step: 4
Training loss: 1.665418028831482
Validation loss: 1.9850047288402435

Epoch: 5| Step: 5
Training loss: 1.1963489055633545
Validation loss: 2.0313890262316634

Epoch: 5| Step: 6
Training loss: 1.716975450515747
Validation loss: 2.0244048513391966

Epoch: 5| Step: 7
Training loss: 1.4767942428588867
Validation loss: 2.031695373596684

Epoch: 5| Step: 8
Training loss: 2.0999703407287598
Validation loss: 2.0246817360642138

Epoch: 5| Step: 9
Training loss: 1.8657665252685547
Validation loss: 1.9834418655723653

Epoch: 5| Step: 10
Training loss: 1.0191587209701538
Validation loss: 2.0358567481399863

Epoch: 350| Step: 0
Training loss: 1.5258899927139282
Validation loss: 2.002423829929803

Epoch: 5| Step: 1
Training loss: 1.6375572681427002
Validation loss: 1.998228524320869

Epoch: 5| Step: 2
Training loss: 2.2862331867218018
Validation loss: 2.000457076616185

Epoch: 5| Step: 3
Training loss: 1.8502334356307983
Validation loss: 2.023409458898729

Epoch: 5| Step: 4
Training loss: 1.390500783920288
Validation loss: 2.0014486928139963

Epoch: 5| Step: 5
Training loss: 1.0540422201156616
Validation loss: 2.033439423448296

Epoch: 5| Step: 6
Training loss: 1.3668473958969116
Validation loss: 2.033530699309482

Epoch: 5| Step: 7
Training loss: 1.571361780166626
Validation loss: 2.017436646646069

Epoch: 5| Step: 8
Training loss: 2.0787160396575928
Validation loss: 2.045116727070142

Epoch: 5| Step: 9
Training loss: 1.290648341178894
Validation loss: 2.0072168432256228

Epoch: 5| Step: 10
Training loss: 1.472151756286621
Validation loss: 2.021027727793622

Testing loss: 1.9971077177259657
