Epoch: 1| Step: 0
Training loss: 3.7182986736297607
Validation loss: 2.880271404981613

Epoch: 5| Step: 1
Training loss: 3.1203575134277344
Validation loss: 2.8715852200984955

Epoch: 5| Step: 2
Training loss: 3.5043399333953857
Validation loss: 2.8685530622800193

Epoch: 5| Step: 3
Training loss: 3.099245548248291
Validation loss: 2.8632549246152244

Epoch: 5| Step: 4
Training loss: 3.516134738922119
Validation loss: 2.8584739168485007

Epoch: 5| Step: 5
Training loss: 3.2143492698669434
Validation loss: 2.8534093548854194

Epoch: 5| Step: 6
Training loss: 3.1631953716278076
Validation loss: 2.847443958123525

Epoch: 5| Step: 7
Training loss: 2.508751630783081
Validation loss: 2.843327154715856

Epoch: 5| Step: 8
Training loss: 3.0815632343292236
Validation loss: 2.833558370669683

Epoch: 5| Step: 9
Training loss: 2.536658763885498
Validation loss: 2.830699155728022

Epoch: 5| Step: 10
Training loss: 2.1440911293029785
Validation loss: 2.823646366596222

Epoch: 5| Step: 11
Training loss: 3.6507701873779297
Validation loss: 2.8184968531131744

Epoch: 2| Step: 0
Training loss: 3.8004722595214844
Validation loss: 2.812592407067617

Epoch: 5| Step: 1
Training loss: 2.6337757110595703
Validation loss: 2.805738647778829

Epoch: 5| Step: 2
Training loss: 2.3287253379821777
Validation loss: 2.7965738574663797

Epoch: 5| Step: 3
Training loss: 3.529198169708252
Validation loss: 2.790274759133657

Epoch: 5| Step: 4
Training loss: 3.0205740928649902
Validation loss: 2.7825183868408203

Epoch: 5| Step: 5
Training loss: 3.24116849899292
Validation loss: 2.776330361763636

Epoch: 5| Step: 6
Training loss: 2.934668779373169
Validation loss: 2.7684512635072074

Epoch: 5| Step: 7
Training loss: 2.8482041358947754
Validation loss: 2.7587996820608773

Epoch: 5| Step: 8
Training loss: 2.8464436531066895
Validation loss: 2.7524508436520896

Epoch: 5| Step: 9
Training loss: 3.0317203998565674
Validation loss: 2.7459182143211365

Epoch: 5| Step: 10
Training loss: 2.377091646194458
Validation loss: 2.736667941013972

Epoch: 5| Step: 11
Training loss: 3.702549457550049
Validation loss: 2.7239817480246225

Epoch: 3| Step: 0
Training loss: 2.5974903106689453
Validation loss: 2.7144750157992044

Epoch: 5| Step: 1
Training loss: 3.123239040374756
Validation loss: 2.7065718472003937

Epoch: 5| Step: 2
Training loss: 2.7826762199401855
Validation loss: 2.6958889762560525

Epoch: 5| Step: 3
Training loss: 3.26104998588562
Validation loss: 2.6858184039592743

Epoch: 5| Step: 4
Training loss: 2.6546201705932617
Validation loss: 2.672408332427343

Epoch: 5| Step: 5
Training loss: 2.0576469898223877
Validation loss: 2.6582966645558677

Epoch: 5| Step: 6
Training loss: 2.7005419731140137
Validation loss: 2.6473005513350167

Epoch: 5| Step: 7
Training loss: 2.465538501739502
Validation loss: 2.6330220997333527

Epoch: 5| Step: 8
Training loss: 3.5118980407714844
Validation loss: 2.61993141969045

Epoch: 5| Step: 9
Training loss: 2.899510622024536
Validation loss: 2.6041167875130973

Epoch: 5| Step: 10
Training loss: 3.2720470428466797
Validation loss: 2.5864823907613754

Epoch: 5| Step: 11
Training loss: 2.132362127304077
Validation loss: 2.5718519190947213

Epoch: 4| Step: 0
Training loss: 3.210902690887451
Validation loss: 2.559100071589152

Epoch: 5| Step: 1
Training loss: 3.218698501586914
Validation loss: 2.532186379035314

Epoch: 5| Step: 2
Training loss: 2.1440491676330566
Validation loss: 2.5164014597733817

Epoch: 5| Step: 3
Training loss: 2.53379487991333
Validation loss: 2.4951454202334085

Epoch: 5| Step: 4
Training loss: 2.4629712104797363
Validation loss: 2.476715629299482

Epoch: 5| Step: 5
Training loss: 2.071702241897583
Validation loss: 2.4554870227972665

Epoch: 5| Step: 6
Training loss: 3.045750856399536
Validation loss: 2.4337304631868997

Epoch: 5| Step: 7
Training loss: 2.286846876144409
Validation loss: 2.405000259478887

Epoch: 5| Step: 8
Training loss: 2.1838183403015137
Validation loss: 2.3805812696615853

Epoch: 5| Step: 9
Training loss: 2.4948508739471436
Validation loss: 2.3528975347677865

Epoch: 5| Step: 10
Training loss: 2.6987223625183105
Validation loss: 2.324436475833257

Epoch: 5| Step: 11
Training loss: 2.8319027423858643
Validation loss: 2.2959086497624717

Epoch: 5| Step: 0
Training loss: 2.5195932388305664
Validation loss: 2.280136307080587

Epoch: 5| Step: 1
Training loss: 2.4848010540008545
Validation loss: 2.2551898856957755

Epoch: 5| Step: 2
Training loss: 2.3777801990509033
Validation loss: 2.226159522930781

Epoch: 5| Step: 3
Training loss: 2.4353737831115723
Validation loss: 2.192353064815203

Epoch: 5| Step: 4
Training loss: 2.2979342937469482
Validation loss: 2.1714308857917786

Epoch: 5| Step: 5
Training loss: 2.2525229454040527
Validation loss: 2.1622862269481025

Epoch: 5| Step: 6
Training loss: 2.280076265335083
Validation loss: 2.1228384325901666

Epoch: 5| Step: 7
Training loss: 1.8214771747589111
Validation loss: 2.106341818968455

Epoch: 5| Step: 8
Training loss: 1.939424753189087
Validation loss: 2.090832844376564

Epoch: 5| Step: 9
Training loss: 1.7066665887832642
Validation loss: 2.0756202985843024

Epoch: 5| Step: 10
Training loss: 2.435030460357666
Validation loss: 2.0537683268388114

Epoch: 5| Step: 11
Training loss: 2.018733263015747
Validation loss: 2.041945993900299

Epoch: 6| Step: 0
Training loss: 2.1052982807159424
Validation loss: 2.049439176917076

Epoch: 5| Step: 1
Training loss: 2.0253121852874756
Validation loss: 2.0420935302972794

Epoch: 5| Step: 2
Training loss: 2.3871119022369385
Validation loss: 2.0485986173152924

Epoch: 5| Step: 3
Training loss: 2.270369052886963
Validation loss: 2.0536241779724755

Epoch: 5| Step: 4
Training loss: 2.551159620285034
Validation loss: 2.0620751728614173

Epoch: 5| Step: 5
Training loss: 2.02357816696167
Validation loss: 2.043131003777186

Epoch: 5| Step: 6
Training loss: 2.6939005851745605
Validation loss: 2.0535529057184854

Epoch: 5| Step: 7
Training loss: 1.7366997003555298
Validation loss: 2.0607299506664276

Epoch: 5| Step: 8
Training loss: 1.6569242477416992
Validation loss: 2.0528793732325235

Epoch: 5| Step: 9
Training loss: 2.1218392848968506
Validation loss: 2.065090457598368

Epoch: 5| Step: 10
Training loss: 1.30410897731781
Validation loss: 2.069362829128901

Epoch: 5| Step: 11
Training loss: 2.161167860031128
Validation loss: 2.1058051884174347

Epoch: 7| Step: 0
Training loss: 1.6460654735565186
Validation loss: 2.090933139125506

Epoch: 5| Step: 1
Training loss: 2.098018169403076
Validation loss: 2.085080166657766

Epoch: 5| Step: 2
Training loss: 2.023662805557251
Validation loss: 2.083584909637769

Epoch: 5| Step: 3
Training loss: 1.7980372905731201
Validation loss: 2.085424875219663

Epoch: 5| Step: 4
Training loss: 2.276456356048584
Validation loss: 2.0689340978860855

Epoch: 5| Step: 5
Training loss: 2.2193214893341064
Validation loss: 2.0760228832562766

Epoch: 5| Step: 6
Training loss: 2.4675698280334473
Validation loss: 2.063279926776886

Epoch: 5| Step: 7
Training loss: 1.7701456546783447
Validation loss: 2.069953386982282

Epoch: 5| Step: 8
Training loss: 2.3739752769470215
Validation loss: 2.0643239667018256

Epoch: 5| Step: 9
Training loss: 2.3795340061187744
Validation loss: 2.0642864952484765

Epoch: 5| Step: 10
Training loss: 2.2497501373291016
Validation loss: 2.056935131549835

Epoch: 5| Step: 11
Training loss: 0.8772329092025757
Validation loss: 2.05292642613252

Epoch: 8| Step: 0
Training loss: 1.897247314453125
Validation loss: 2.0549326290686927

Epoch: 5| Step: 1
Training loss: 2.0389435291290283
Validation loss: 2.061431422829628

Epoch: 5| Step: 2
Training loss: 1.7499736547470093
Validation loss: 2.0390006552139917

Epoch: 5| Step: 3
Training loss: 2.5491485595703125
Validation loss: 2.0301869213581085

Epoch: 5| Step: 4
Training loss: 2.4355578422546387
Validation loss: 2.047717660665512

Epoch: 5| Step: 5
Training loss: 2.2100675106048584
Validation loss: 2.039955347776413

Epoch: 5| Step: 6
Training loss: 1.7878773212432861
Validation loss: 2.046129489938418

Epoch: 5| Step: 7
Training loss: 1.6901521682739258
Validation loss: 2.0469833314418793

Epoch: 5| Step: 8
Training loss: 2.2522969245910645
Validation loss: 2.04130357503891

Epoch: 5| Step: 9
Training loss: 1.735879898071289
Validation loss: 2.0309248765309653

Epoch: 5| Step: 10
Training loss: 2.789971113204956
Validation loss: 2.0480715334415436

Epoch: 5| Step: 11
Training loss: 1.522526741027832
Validation loss: 2.0410442550977073

Epoch: 9| Step: 0
Training loss: 1.8263946771621704
Validation loss: 2.041385586063067

Epoch: 5| Step: 1
Training loss: 2.7531933784484863
Validation loss: 2.0314703484376273

Epoch: 5| Step: 2
Training loss: 2.278763771057129
Validation loss: 2.0365539292494454

Epoch: 5| Step: 3
Training loss: 1.7861827611923218
Validation loss: 2.0438215881586075

Epoch: 5| Step: 4
Training loss: 2.015921115875244
Validation loss: 2.0351475377877555

Epoch: 5| Step: 5
Training loss: 1.688126564025879
Validation loss: 2.0307818154493966

Epoch: 5| Step: 6
Training loss: 1.8371835947036743
Validation loss: 2.0384321808815002

Epoch: 5| Step: 7
Training loss: 2.784813165664673
Validation loss: 2.0468928466240564

Epoch: 5| Step: 8
Training loss: 2.08552885055542
Validation loss: 2.0407583117485046

Epoch: 5| Step: 9
Training loss: 1.9355922937393188
Validation loss: 2.0418849090735116

Epoch: 5| Step: 10
Training loss: 1.7025737762451172
Validation loss: 2.042710209886233

Epoch: 5| Step: 11
Training loss: 2.902512550354004
Validation loss: 2.0372189730405807

Epoch: 10| Step: 0
Training loss: 1.916599988937378
Validation loss: 2.0480175216992698

Epoch: 5| Step: 1
Training loss: 1.8935130834579468
Validation loss: 2.0444867809613547

Epoch: 5| Step: 2
Training loss: 2.4926135540008545
Validation loss: 2.0433261394500732

Epoch: 5| Step: 3
Training loss: 2.357255458831787
Validation loss: 2.0402021954456964

Epoch: 5| Step: 4
Training loss: 1.6977170705795288
Validation loss: 2.063868890206019

Epoch: 5| Step: 5
Training loss: 1.6869882345199585
Validation loss: 2.070922667781512

Epoch: 5| Step: 6
Training loss: 2.3073060512542725
Validation loss: 2.0657650331656137

Epoch: 5| Step: 7
Training loss: 2.8119075298309326
Validation loss: 2.055838664372762

Epoch: 5| Step: 8
Training loss: 1.4477365016937256
Validation loss: 2.0843010991811752

Epoch: 5| Step: 9
Training loss: 2.37184476852417
Validation loss: 2.07636222243309

Epoch: 5| Step: 10
Training loss: 1.6595840454101562
Validation loss: 2.0581716696421304

Epoch: 5| Step: 11
Training loss: 3.229682445526123
Validation loss: 2.067564124862353

Epoch: 11| Step: 0
Training loss: 2.4632461071014404
Validation loss: 2.0619762341181436

Epoch: 5| Step: 1
Training loss: 2.1093826293945312
Validation loss: 2.070673177639643

Epoch: 5| Step: 2
Training loss: 1.6792672872543335
Validation loss: 2.078612824281057

Epoch: 5| Step: 3
Training loss: 2.2280094623565674
Validation loss: 2.0575157503286996

Epoch: 5| Step: 4
Training loss: 2.3789713382720947
Validation loss: 2.061431179443995

Epoch: 5| Step: 5
Training loss: 2.2074034214019775
Validation loss: 2.062633141875267

Epoch: 5| Step: 6
Training loss: 1.9753652811050415
Validation loss: 2.0477578540643058

Epoch: 5| Step: 7
Training loss: 1.8802101612091064
Validation loss: 2.032986323038737

Epoch: 5| Step: 8
Training loss: 1.8475086688995361
Validation loss: 2.0322123865286508

Epoch: 5| Step: 9
Training loss: 1.9838931560516357
Validation loss: 2.0372608254353204

Epoch: 5| Step: 10
Training loss: 2.3104500770568848
Validation loss: 2.0357628017663956

Epoch: 5| Step: 11
Training loss: 1.0062360763549805
Validation loss: 2.020660549402237

Epoch: 12| Step: 0
Training loss: 2.658271074295044
Validation loss: 2.034407635529836

Epoch: 5| Step: 1
Training loss: 1.73653244972229
Validation loss: 2.0410188982884088

Epoch: 5| Step: 2
Training loss: 1.7768983840942383
Validation loss: 2.0533828089634576

Epoch: 5| Step: 3
Training loss: 1.799271821975708
Validation loss: 2.0546493430932364

Epoch: 5| Step: 4
Training loss: 2.3292181491851807
Validation loss: 2.077701429526011

Epoch: 5| Step: 5
Training loss: 1.9813387393951416
Validation loss: 2.0675994555155435

Epoch: 5| Step: 6
Training loss: 2.0570297241210938
Validation loss: 2.0724936723709106

Epoch: 5| Step: 7
Training loss: 2.0181498527526855
Validation loss: 2.093316838145256

Epoch: 5| Step: 8
Training loss: 1.8995345830917358
Validation loss: 2.08322574198246

Epoch: 5| Step: 9
Training loss: 1.9840911626815796
Validation loss: 2.073492338260015

Epoch: 5| Step: 10
Training loss: 2.4823203086853027
Validation loss: 2.0797272423903146

Epoch: 5| Step: 11
Training loss: 2.35109806060791
Validation loss: 2.0816950102647147

Epoch: 13| Step: 0
Training loss: 2.0374538898468018
Validation loss: 2.073424423734347

Epoch: 5| Step: 1
Training loss: 1.9846941232681274
Validation loss: 2.073107436299324

Epoch: 5| Step: 2
Training loss: 1.6519899368286133
Validation loss: 2.068245326479276

Epoch: 5| Step: 3
Training loss: 2.354909658432007
Validation loss: 2.0689185907443366

Epoch: 5| Step: 4
Training loss: 1.9611186981201172
Validation loss: 2.067615643143654

Epoch: 5| Step: 5
Training loss: 2.3651185035705566
Validation loss: 2.0489541739225388

Epoch: 5| Step: 6
Training loss: 1.6190900802612305
Validation loss: 2.0593269368012748

Epoch: 5| Step: 7
Training loss: 2.012014865875244
Validation loss: 2.047655483086904

Epoch: 5| Step: 8
Training loss: 1.8069560527801514
Validation loss: 2.039936731259028

Epoch: 5| Step: 9
Training loss: 2.2665863037109375
Validation loss: 2.0431936035553613

Epoch: 5| Step: 10
Training loss: 2.625154972076416
Validation loss: 2.0368295510609946

Epoch: 5| Step: 11
Training loss: 1.8565298318862915
Validation loss: 2.029685854911804

Epoch: 14| Step: 0
Training loss: 1.9952720403671265
Validation loss: 2.0303329676389694

Epoch: 5| Step: 1
Training loss: 2.1058602333068848
Validation loss: 2.038496474424998

Epoch: 5| Step: 2
Training loss: 2.5118536949157715
Validation loss: 2.0522923668225608

Epoch: 5| Step: 3
Training loss: 1.5672118663787842
Validation loss: 2.0342155595620475

Epoch: 5| Step: 4
Training loss: 2.4601991176605225
Validation loss: 2.017258495092392

Epoch: 5| Step: 5
Training loss: 2.09511137008667
Validation loss: 2.0237052937348685

Epoch: 5| Step: 6
Training loss: 1.7888237237930298
Validation loss: 2.0330863296985626

Epoch: 5| Step: 7
Training loss: 2.2493722438812256
Validation loss: 2.032197574774424

Epoch: 5| Step: 8
Training loss: 1.7676442861557007
Validation loss: 2.0271954387426376

Epoch: 5| Step: 9
Training loss: 2.1244733333587646
Validation loss: 2.040330414970716

Epoch: 5| Step: 10
Training loss: 2.091060161590576
Validation loss: 2.023248001933098

Epoch: 5| Step: 11
Training loss: 1.6939730644226074
Validation loss: 2.030649041136106

Epoch: 15| Step: 0
Training loss: 1.8088977336883545
Validation loss: 2.0263620217641196

Epoch: 5| Step: 1
Training loss: 2.246466875076294
Validation loss: 2.038102721174558

Epoch: 5| Step: 2
Training loss: 1.8726708889007568
Validation loss: 2.0560677299896875

Epoch: 5| Step: 3
Training loss: 2.6158688068389893
Validation loss: 2.063751811782519

Epoch: 5| Step: 4
Training loss: 1.6882562637329102
Validation loss: 2.0733805845181146

Epoch: 5| Step: 5
Training loss: 1.9687530994415283
Validation loss: 2.0945550898710885

Epoch: 5| Step: 6
Training loss: 2.1378543376922607
Validation loss: 2.0951607078313828

Epoch: 5| Step: 7
Training loss: 2.1335484981536865
Validation loss: 2.0972319493691125

Epoch: 5| Step: 8
Training loss: 2.384167194366455
Validation loss: 2.0990353723367057

Epoch: 5| Step: 9
Training loss: 1.8817150592803955
Validation loss: 2.0762050598859787

Epoch: 5| Step: 10
Training loss: 2.1430511474609375
Validation loss: 2.070720632870992

Epoch: 5| Step: 11
Training loss: 1.1701568365097046
Validation loss: 2.061061521371206

Epoch: 16| Step: 0
Training loss: 2.0657124519348145
Validation loss: 2.0483330488204956

Epoch: 5| Step: 1
Training loss: 1.453079104423523
Validation loss: 2.0487482845783234

Epoch: 5| Step: 2
Training loss: 1.9194618463516235
Validation loss: 2.043169910709063

Epoch: 5| Step: 3
Training loss: 2.2851433753967285
Validation loss: 2.0366472552220025

Epoch: 5| Step: 4
Training loss: 1.902685523033142
Validation loss: 2.0289389342069626

Epoch: 5| Step: 5
Training loss: 1.6157585382461548
Validation loss: 2.0353319893280664

Epoch: 5| Step: 6
Training loss: 2.5673375129699707
Validation loss: 2.0332631915807724

Epoch: 5| Step: 7
Training loss: 2.0160393714904785
Validation loss: 2.026898051301638

Epoch: 5| Step: 8
Training loss: 1.814557671546936
Validation loss: 2.028041183948517

Epoch: 5| Step: 9
Training loss: 2.523651599884033
Validation loss: 2.029988939563433

Epoch: 5| Step: 10
Training loss: 2.4190444946289062
Validation loss: 2.021773338317871

Epoch: 5| Step: 11
Training loss: 1.604801893234253
Validation loss: 2.01639986038208

Epoch: 17| Step: 0
Training loss: 1.5336041450500488
Validation loss: 2.0208310733238855

Epoch: 5| Step: 1
Training loss: 2.8494772911071777
Validation loss: 2.0248639583587646

Epoch: 5| Step: 2
Training loss: 2.602235794067383
Validation loss: 2.012435639897982

Epoch: 5| Step: 3
Training loss: 1.8276984691619873
Validation loss: 2.0077774624029794

Epoch: 5| Step: 4
Training loss: 2.3542098999023438
Validation loss: 2.012963652610779

Epoch: 5| Step: 5
Training loss: 1.8112823963165283
Validation loss: 2.0077964862187705

Epoch: 5| Step: 6
Training loss: 1.6413052082061768
Validation loss: 2.02129473288854

Epoch: 5| Step: 7
Training loss: 2.179168224334717
Validation loss: 2.015450820326805

Epoch: 5| Step: 8
Training loss: 2.3639063835144043
Validation loss: 2.0010105073451996

Epoch: 5| Step: 9
Training loss: 1.6082665920257568
Validation loss: 2.0121019780635834

Epoch: 5| Step: 10
Training loss: 1.875484824180603
Validation loss: 2.0215454002221427

Epoch: 5| Step: 11
Training loss: 1.6942229270935059
Validation loss: 2.008181298772494

Epoch: 18| Step: 0
Training loss: 1.8530365228652954
Validation loss: 2.005002439022064

Epoch: 5| Step: 1
Training loss: 1.684849739074707
Validation loss: 2.017088368535042

Epoch: 5| Step: 2
Training loss: 2.4411938190460205
Validation loss: 2.017875775694847

Epoch: 5| Step: 3
Training loss: 1.9654796123504639
Validation loss: 2.008007367451986

Epoch: 5| Step: 4
Training loss: 1.8740053176879883
Validation loss: 2.0128510892391205

Epoch: 5| Step: 5
Training loss: 2.192645311355591
Validation loss: 2.0188535153865814

Epoch: 5| Step: 6
Training loss: 2.0492494106292725
Validation loss: 2.01766300201416

Epoch: 5| Step: 7
Training loss: 2.04931640625
Validation loss: 2.0192425598700843

Epoch: 5| Step: 8
Training loss: 2.3352456092834473
Validation loss: 2.023093357682228

Epoch: 5| Step: 9
Training loss: 2.140134334564209
Validation loss: 2.0178756564855576

Epoch: 5| Step: 10
Training loss: 1.7944749593734741
Validation loss: 2.027958631515503

Epoch: 5| Step: 11
Training loss: 2.058225631713867
Validation loss: 2.0343942095836005

Epoch: 19| Step: 0
Training loss: 2.0864384174346924
Validation loss: 2.035707861185074

Epoch: 5| Step: 1
Training loss: 1.8647401332855225
Validation loss: 2.0393309891223907

Epoch: 5| Step: 2
Training loss: 1.974941611289978
Validation loss: 2.0527492463588715

Epoch: 5| Step: 3
Training loss: 2.55694842338562
Validation loss: 2.0570531487464905

Epoch: 5| Step: 4
Training loss: 1.9779083728790283
Validation loss: 2.0618059585491815

Epoch: 5| Step: 5
Training loss: 2.5031204223632812
Validation loss: 2.0570500095685325

Epoch: 5| Step: 6
Training loss: 1.9298242330551147
Validation loss: 2.063590427239736

Epoch: 5| Step: 7
Training loss: 1.916565179824829
Validation loss: 2.036399155855179

Epoch: 5| Step: 8
Training loss: 1.913923978805542
Validation loss: 2.063676660259565

Epoch: 5| Step: 9
Training loss: 1.8373916149139404
Validation loss: 2.028524706761042

Epoch: 5| Step: 10
Training loss: 1.8613086938858032
Validation loss: 2.0361363738775253

Epoch: 5| Step: 11
Training loss: 1.5379163026809692
Validation loss: 2.0179163068532944

Epoch: 20| Step: 0
Training loss: 1.5194271802902222
Validation loss: 2.0405228783686957

Epoch: 5| Step: 1
Training loss: 1.6573683023452759
Validation loss: 2.0458332002162933

Epoch: 5| Step: 2
Training loss: 2.753236770629883
Validation loss: 2.0327178885539374

Epoch: 5| Step: 3
Training loss: 2.485151767730713
Validation loss: 2.037713199853897

Epoch: 5| Step: 4
Training loss: 1.6214462518692017
Validation loss: 2.0386052230993905

Epoch: 5| Step: 5
Training loss: 2.2096333503723145
Validation loss: 2.0432185182968774

Epoch: 5| Step: 6
Training loss: 1.7041981220245361
Validation loss: 2.0432201276222863

Epoch: 5| Step: 7
Training loss: 1.8477237224578857
Validation loss: 2.0593485484520593

Epoch: 5| Step: 8
Training loss: 1.515131950378418
Validation loss: 2.069908360640208

Epoch: 5| Step: 9
Training loss: 2.142260789871216
Validation loss: 2.0616173396507897

Epoch: 5| Step: 10
Training loss: 2.380500555038452
Validation loss: 2.0535635948181152

Epoch: 5| Step: 11
Training loss: 3.9777650833129883
Validation loss: 2.0499698718388877

Epoch: 21| Step: 0
Training loss: 1.8625510931015015
Validation loss: 2.039253522952398

Epoch: 5| Step: 1
Training loss: 2.0270986557006836
Validation loss: 2.0260316282510757

Epoch: 5| Step: 2
Training loss: 2.038403034210205
Validation loss: 2.0256282091140747

Epoch: 5| Step: 3
Training loss: 1.8455207347869873
Validation loss: 2.011597231030464

Epoch: 5| Step: 4
Training loss: 1.9375905990600586
Validation loss: 2.0060013780991235

Epoch: 5| Step: 5
Training loss: 1.8234819173812866
Validation loss: 1.998717685540517

Epoch: 5| Step: 6
Training loss: 2.407611131668091
Validation loss: 1.994828740755717

Epoch: 5| Step: 7
Training loss: 2.425269603729248
Validation loss: 2.009092981616656

Epoch: 5| Step: 8
Training loss: 1.865301489830017
Validation loss: 2.0024129102627435

Epoch: 5| Step: 9
Training loss: 1.6010509729385376
Validation loss: 2.007009968161583

Epoch: 5| Step: 10
Training loss: 2.3343966007232666
Validation loss: 2.006403381625811

Epoch: 5| Step: 11
Training loss: 2.4424445629119873
Validation loss: 2.0044298321008682

Epoch: 22| Step: 0
Training loss: 1.7037980556488037
Validation loss: 2.0114300598700843

Epoch: 5| Step: 1
Training loss: 1.76999032497406
Validation loss: 2.0157489528258643

Epoch: 5| Step: 2
Training loss: 2.1695876121520996
Validation loss: 2.0011422832806907

Epoch: 5| Step: 3
Training loss: 2.306579113006592
Validation loss: 2.0097019523382187

Epoch: 5| Step: 4
Training loss: 2.474973678588867
Validation loss: 2.013839696844419

Epoch: 5| Step: 5
Training loss: 2.5509719848632812
Validation loss: 2.0182845344146094

Epoch: 5| Step: 6
Training loss: 1.5843392610549927
Validation loss: 2.0134318470954895

Epoch: 5| Step: 7
Training loss: 2.106920003890991
Validation loss: 2.027532234787941

Epoch: 5| Step: 8
Training loss: 1.882262945175171
Validation loss: 2.017592007915179

Epoch: 5| Step: 9
Training loss: 1.716978669166565
Validation loss: 2.0247297982374826

Epoch: 5| Step: 10
Training loss: 1.9613136053085327
Validation loss: 2.0143690953652063

Epoch: 5| Step: 11
Training loss: 1.1856189966201782
Validation loss: 2.0363448907931647

Epoch: 23| Step: 0
Training loss: 2.1129982471466064
Validation loss: 2.029534548521042

Epoch: 5| Step: 1
Training loss: 2.0472800731658936
Validation loss: 2.0409854352474213

Epoch: 5| Step: 2
Training loss: 1.909746527671814
Validation loss: 2.035848394036293

Epoch: 5| Step: 3
Training loss: 2.5800375938415527
Validation loss: 2.038733333349228

Epoch: 5| Step: 4
Training loss: 2.6867458820343018
Validation loss: 2.039614682396253

Epoch: 5| Step: 5
Training loss: 1.7793095111846924
Validation loss: 2.046840156118075

Epoch: 5| Step: 6
Training loss: 1.982617974281311
Validation loss: 2.047673945625623

Epoch: 5| Step: 7
Training loss: 1.5443730354309082
Validation loss: 2.051942686239878

Epoch: 5| Step: 8
Training loss: 1.646949052810669
Validation loss: 2.0424693822860718

Epoch: 5| Step: 9
Training loss: 1.7381360530853271
Validation loss: 2.0528384248415628

Epoch: 5| Step: 10
Training loss: 1.963452935218811
Validation loss: 2.057499051094055

Epoch: 5| Step: 11
Training loss: 2.50765323638916
Validation loss: 2.0582401156425476

Epoch: 24| Step: 0
Training loss: 1.5770339965820312
Validation loss: 2.048039654890696

Epoch: 5| Step: 1
Training loss: 1.9235798120498657
Validation loss: 2.04211089015007

Epoch: 5| Step: 2
Training loss: 2.1345245838165283
Validation loss: 2.0412586579720178

Epoch: 5| Step: 3
Training loss: 1.7778507471084595
Validation loss: 2.0419161170721054

Epoch: 5| Step: 4
Training loss: 2.02123761177063
Validation loss: 2.026831035812696

Epoch: 5| Step: 5
Training loss: 1.8009827136993408
Validation loss: 2.0082684755325317

Epoch: 5| Step: 6
Training loss: 1.493310570716858
Validation loss: 2.0177194426457086

Epoch: 5| Step: 7
Training loss: 2.1192450523376465
Validation loss: 2.0146649281183877

Epoch: 5| Step: 8
Training loss: 2.4285178184509277
Validation loss: 2.0226143896579742

Epoch: 5| Step: 9
Training loss: 2.4148309230804443
Validation loss: 2.0177265107631683

Epoch: 5| Step: 10
Training loss: 2.4625585079193115
Validation loss: 2.0336630940437317

Epoch: 5| Step: 11
Training loss: 1.5210257768630981
Validation loss: 2.0213175614674888

Epoch: 25| Step: 0
Training loss: 2.2756943702697754
Validation loss: 2.027060558398565

Epoch: 5| Step: 1
Training loss: 1.5964820384979248
Validation loss: 2.030990093946457

Epoch: 5| Step: 2
Training loss: 1.9570764303207397
Validation loss: 2.032792702317238

Epoch: 5| Step: 3
Training loss: 1.5810729265213013
Validation loss: 2.0294756392637887

Epoch: 5| Step: 4
Training loss: 1.7937920093536377
Validation loss: 2.0295103639364243

Epoch: 5| Step: 5
Training loss: 2.0286765098571777
Validation loss: 2.0590935995181403

Epoch: 5| Step: 6
Training loss: 1.9175546169281006
Validation loss: 2.0449442267417908

Epoch: 5| Step: 7
Training loss: 2.084852695465088
Validation loss: 2.065750097235044

Epoch: 5| Step: 8
Training loss: 2.025545835494995
Validation loss: 2.0470399806896844

Epoch: 5| Step: 9
Training loss: 2.617882251739502
Validation loss: 2.050098732113838

Epoch: 5| Step: 10
Training loss: 2.222938060760498
Validation loss: 2.060498038927714

Epoch: 5| Step: 11
Training loss: 1.4080243110656738
Validation loss: 2.0500356405973434

Epoch: 26| Step: 0
Training loss: 1.9166568517684937
Validation loss: 2.047195225954056

Epoch: 5| Step: 1
Training loss: 2.0278708934783936
Validation loss: 2.027102400859197

Epoch: 5| Step: 2
Training loss: 2.1636176109313965
Validation loss: 2.02721298734347

Epoch: 5| Step: 3
Training loss: 1.7467374801635742
Validation loss: 2.0035672187805176

Epoch: 5| Step: 4
Training loss: 1.9234145879745483
Validation loss: 2.007233460744222

Epoch: 5| Step: 5
Training loss: 1.8027973175048828
Validation loss: 2.0151033798853555

Epoch: 5| Step: 6
Training loss: 1.817453145980835
Validation loss: 1.998038073380788

Epoch: 5| Step: 7
Training loss: 2.2560205459594727
Validation loss: 1.9984463254610698

Epoch: 5| Step: 8
Training loss: 2.331641912460327
Validation loss: 2.017259339491526

Epoch: 5| Step: 9
Training loss: 1.545078158378601
Validation loss: 2.0216187884410224

Epoch: 5| Step: 10
Training loss: 2.004453420639038
Validation loss: 2.033862148722013

Epoch: 5| Step: 11
Training loss: 3.943573236465454
Validation loss: 2.012312481800715

Epoch: 27| Step: 0
Training loss: 2.089064359664917
Validation loss: 2.018360768755277

Epoch: 5| Step: 1
Training loss: 1.4019790887832642
Validation loss: 2.0348557382822037

Epoch: 5| Step: 2
Training loss: 2.1792075634002686
Validation loss: 2.0393759409586587

Epoch: 5| Step: 3
Training loss: 2.299107789993286
Validation loss: 2.05023263891538

Epoch: 5| Step: 4
Training loss: 2.0483388900756836
Validation loss: 2.029377445578575

Epoch: 5| Step: 5
Training loss: 2.047624111175537
Validation loss: 2.0300483107566833

Epoch: 5| Step: 6
Training loss: 1.6989418268203735
Validation loss: 2.038828283548355

Epoch: 5| Step: 7
Training loss: 2.250730276107788
Validation loss: 2.02761177221934

Epoch: 5| Step: 8
Training loss: 2.0578062534332275
Validation loss: 2.041712020834287

Epoch: 5| Step: 9
Training loss: 1.566535234451294
Validation loss: 2.025006795922915

Epoch: 5| Step: 10
Training loss: 2.4588229656219482
Validation loss: 2.016805718342463

Epoch: 5| Step: 11
Training loss: 1.4283955097198486
Validation loss: 2.0423059662183127

Epoch: 28| Step: 0
Training loss: 1.9448864459991455
Validation loss: 2.0104679663976035

Epoch: 5| Step: 1
Training loss: 2.112231731414795
Validation loss: 2.0356478790442147

Epoch: 5| Step: 2
Training loss: 1.9531151056289673
Validation loss: 2.0301829477151236

Epoch: 5| Step: 3
Training loss: 2.1561779975891113
Validation loss: 2.0322797695795694

Epoch: 5| Step: 4
Training loss: 1.8407337665557861
Validation loss: 2.054349333047867

Epoch: 5| Step: 5
Training loss: 1.6873152256011963
Validation loss: 2.040430426597595

Epoch: 5| Step: 6
Training loss: 1.7643053531646729
Validation loss: 2.0570675879716873

Epoch: 5| Step: 7
Training loss: 2.523458957672119
Validation loss: 2.0561145146687827

Epoch: 5| Step: 8
Training loss: 1.8946338891983032
Validation loss: 2.030927057067553

Epoch: 5| Step: 9
Training loss: 2.4507298469543457
Validation loss: 2.048232396443685

Epoch: 5| Step: 10
Training loss: 1.5112510919570923
Validation loss: 2.033959671854973

Epoch: 5| Step: 11
Training loss: 1.932326078414917
Validation loss: 2.033608148495356

Epoch: 29| Step: 0
Training loss: 2.345355272293091
Validation loss: 2.0278091182311377

Epoch: 5| Step: 1
Training loss: 2.101318836212158
Validation loss: 2.0025747368733087

Epoch: 5| Step: 2
Training loss: 2.058941125869751
Validation loss: 2.0001076012849808

Epoch: 5| Step: 3
Training loss: 1.8381109237670898
Validation loss: 1.9881309568881989

Epoch: 5| Step: 4
Training loss: 2.0437510013580322
Validation loss: 1.9920251766840618

Epoch: 5| Step: 5
Training loss: 2.0061264038085938
Validation loss: 1.9868608017762501

Epoch: 5| Step: 6
Training loss: 2.0862672328948975
Validation loss: 1.9907986223697662

Epoch: 5| Step: 7
Training loss: 1.8753280639648438
Validation loss: 1.9917754977941513

Epoch: 5| Step: 8
Training loss: 2.0432827472686768
Validation loss: 1.9879807382822037

Epoch: 5| Step: 9
Training loss: 1.801936388015747
Validation loss: 2.0028769274552665

Epoch: 5| Step: 10
Training loss: 2.155338764190674
Validation loss: 1.974463015794754

Epoch: 5| Step: 11
Training loss: 1.3609870672225952
Validation loss: 1.9885038435459137

Epoch: 30| Step: 0
Training loss: 2.1139330863952637
Validation loss: 1.9810311098893483

Epoch: 5| Step: 1
Training loss: 1.9831187725067139
Validation loss: 1.988043452302615

Epoch: 5| Step: 2
Training loss: 2.161043882369995
Validation loss: 1.9883335083723068

Epoch: 5| Step: 3
Training loss: 1.6783851385116577
Validation loss: 1.995802233616511

Epoch: 5| Step: 4
Training loss: 2.217113494873047
Validation loss: 2.010865166783333

Epoch: 5| Step: 5
Training loss: 2.3577003479003906
Validation loss: 2.014933153986931

Epoch: 5| Step: 6
Training loss: 1.7289187908172607
Validation loss: 2.0226740638415017

Epoch: 5| Step: 7
Training loss: 1.7084009647369385
Validation loss: 2.039178346594175

Epoch: 5| Step: 8
Training loss: 1.5379472970962524
Validation loss: 2.038199260830879

Epoch: 5| Step: 9
Training loss: 2.1134371757507324
Validation loss: 2.0546976923942566

Epoch: 5| Step: 10
Training loss: 2.2613117694854736
Validation loss: 2.0464782118797302

Epoch: 5| Step: 11
Training loss: 1.7660452127456665
Validation loss: 2.0514316856861115

Epoch: 31| Step: 0
Training loss: 1.6310360431671143
Validation loss: 2.0462035536766052

Epoch: 5| Step: 1
Training loss: 1.7849674224853516
Validation loss: 2.0371925284465155

Epoch: 5| Step: 2
Training loss: 2.375671625137329
Validation loss: 2.0660742670297623

Epoch: 5| Step: 3
Training loss: 2.220498561859131
Validation loss: 2.0508148868878684

Epoch: 5| Step: 4
Training loss: 1.7027724981307983
Validation loss: 2.064401557048162

Epoch: 5| Step: 5
Training loss: 1.7592175006866455
Validation loss: 2.051594376564026

Epoch: 5| Step: 6
Training loss: 1.917975664138794
Validation loss: 2.0521569748719535

Epoch: 5| Step: 7
Training loss: 1.3897831439971924
Validation loss: 2.0471350649992623

Epoch: 5| Step: 8
Training loss: 2.131702423095703
Validation loss: 2.047863413890203

Epoch: 5| Step: 9
Training loss: 2.637490749359131
Validation loss: 2.0255683213472366

Epoch: 5| Step: 10
Training loss: 2.0007777214050293
Validation loss: 2.0182074507077536

Epoch: 5| Step: 11
Training loss: 1.7516863346099854
Validation loss: 2.0087622702121735

Epoch: 32| Step: 0
Training loss: 1.944498062133789
Validation loss: 2.015837167700132

Epoch: 5| Step: 1
Training loss: 2.0025951862335205
Validation loss: 2.0036009748776755

Epoch: 5| Step: 2
Training loss: 1.668125867843628
Validation loss: 1.9942507992188137

Epoch: 5| Step: 3
Training loss: 2.1824147701263428
Validation loss: 2.000386451681455

Epoch: 5| Step: 4
Training loss: 1.8265060186386108
Validation loss: 1.9814223498106003

Epoch: 5| Step: 5
Training loss: 2.1288537979125977
Validation loss: 1.990823229153951

Epoch: 5| Step: 6
Training loss: 1.9845081567764282
Validation loss: 1.9786740442117055

Epoch: 5| Step: 7
Training loss: 1.6082956790924072
Validation loss: 1.9749594380458195

Epoch: 5| Step: 8
Training loss: 1.9625431299209595
Validation loss: 1.985942656795184

Epoch: 5| Step: 9
Training loss: 2.5645084381103516
Validation loss: 1.9907281796137493

Epoch: 5| Step: 10
Training loss: 1.980576753616333
Validation loss: 1.9993764907121658

Epoch: 5| Step: 11
Training loss: 1.5419189929962158
Validation loss: 1.9911406487226486

Epoch: 33| Step: 0
Training loss: 2.1380398273468018
Validation loss: 2.014301980535189

Epoch: 5| Step: 1
Training loss: 1.8871911764144897
Validation loss: 2.0390409181515374

Epoch: 5| Step: 2
Training loss: 1.9010568857192993
Validation loss: 2.052528977394104

Epoch: 5| Step: 3
Training loss: 1.4633162021636963
Validation loss: 2.0668063114086785

Epoch: 5| Step: 4
Training loss: 2.011075496673584
Validation loss: 2.084399089217186

Epoch: 5| Step: 5
Training loss: 1.1469676494598389
Validation loss: 2.0726085007190704

Epoch: 5| Step: 6
Training loss: 2.599240303039551
Validation loss: 2.084924583633741

Epoch: 5| Step: 7
Training loss: 2.587181568145752
Validation loss: 2.085403487086296

Epoch: 5| Step: 8
Training loss: 2.1870341300964355
Validation loss: 2.086687753597895

Epoch: 5| Step: 9
Training loss: 1.9042415618896484
Validation loss: 2.056611051162084

Epoch: 5| Step: 10
Training loss: 1.981603980064392
Validation loss: 2.0695945421854653

Epoch: 5| Step: 11
Training loss: 1.7715020179748535
Validation loss: 2.0427866925795874

Epoch: 34| Step: 0
Training loss: 2.0318493843078613
Validation loss: 2.032587915658951

Epoch: 5| Step: 1
Training loss: 2.1505932807922363
Validation loss: 2.0193079064289727

Epoch: 5| Step: 2
Training loss: 2.045748233795166
Validation loss: 2.0142475813627243

Epoch: 5| Step: 3
Training loss: 1.8887569904327393
Validation loss: 2.010992298523585

Epoch: 5| Step: 4
Training loss: 1.8784106969833374
Validation loss: 2.021254246433576

Epoch: 5| Step: 5
Training loss: 1.5384700298309326
Validation loss: 2.0032548109690347

Epoch: 5| Step: 6
Training loss: 1.9866224527359009
Validation loss: 2.003213102618853

Epoch: 5| Step: 7
Training loss: 1.8252906799316406
Validation loss: 1.9956862777471542

Epoch: 5| Step: 8
Training loss: 1.9952895641326904
Validation loss: 1.9934584349393845

Epoch: 5| Step: 9
Training loss: 2.0971171855926514
Validation loss: 1.989554613828659

Epoch: 5| Step: 10
Training loss: 2.1357364654541016
Validation loss: 2.002734293540319

Epoch: 5| Step: 11
Training loss: 2.4871301651000977
Validation loss: 2.011272355914116

Epoch: 35| Step: 0
Training loss: 1.8804264068603516
Validation loss: 2.035503809650739

Epoch: 5| Step: 1
Training loss: 1.9930747747421265
Validation loss: 2.013739824295044

Epoch: 5| Step: 2
Training loss: 1.996769666671753
Validation loss: 2.0232698172330856

Epoch: 5| Step: 3
Training loss: 2.244380474090576
Validation loss: 2.038811201850573

Epoch: 5| Step: 4
Training loss: 2.5141613483428955
Validation loss: 2.0206041634082794

Epoch: 5| Step: 5
Training loss: 1.9457861185073853
Validation loss: 2.0406047304471335

Epoch: 5| Step: 6
Training loss: 1.651649832725525
Validation loss: 2.0361758967240653

Epoch: 5| Step: 7
Training loss: 2.165762424468994
Validation loss: 2.036213909586271

Epoch: 5| Step: 8
Training loss: 1.6111161708831787
Validation loss: 2.0419926593701043

Epoch: 5| Step: 9
Training loss: 1.3852790594100952
Validation loss: 2.0520996749401093

Epoch: 5| Step: 10
Training loss: 2.059685468673706
Validation loss: 2.062733083963394

Epoch: 5| Step: 11
Training loss: 1.8671802282333374
Validation loss: 2.0550807416439056

Epoch: 36| Step: 0
Training loss: 2.0628743171691895
Validation loss: 2.064286688963572

Epoch: 5| Step: 1
Training loss: 2.119929552078247
Validation loss: 2.08282836774985

Epoch: 5| Step: 2
Training loss: 1.781923532485962
Validation loss: 2.059331407149633

Epoch: 5| Step: 3
Training loss: 1.421568751335144
Validation loss: 2.078830266992251

Epoch: 5| Step: 4
Training loss: 2.014723777770996
Validation loss: 2.0351068675518036

Epoch: 5| Step: 5
Training loss: 1.6467987298965454
Validation loss: 2.041567698121071

Epoch: 5| Step: 6
Training loss: 2.2065110206604004
Validation loss: 2.0398329347372055

Epoch: 5| Step: 7
Training loss: 2.5918498039245605
Validation loss: 2.04911707341671

Epoch: 5| Step: 8
Training loss: 2.09741473197937
Validation loss: 2.0447147538264594

Epoch: 5| Step: 9
Training loss: 1.4588121175765991
Validation loss: 2.031964341799418

Epoch: 5| Step: 10
Training loss: 2.145550489425659
Validation loss: 2.029822145899137

Epoch: 5| Step: 11
Training loss: 1.4714722633361816
Validation loss: 2.0121118277311325

Epoch: 37| Step: 0
Training loss: 2.0830769538879395
Validation loss: 2.0325461328029633

Epoch: 5| Step: 1
Training loss: 1.5544536113739014
Validation loss: 2.0119250814119973

Epoch: 5| Step: 2
Training loss: 1.9282886981964111
Validation loss: 2.013251706957817

Epoch: 5| Step: 3
Training loss: 1.8065639734268188
Validation loss: 2.036193569501241

Epoch: 5| Step: 4
Training loss: 2.5432076454162598
Validation loss: 2.0436541189750037

Epoch: 5| Step: 5
Training loss: 1.713645577430725
Validation loss: 2.051115175088247

Epoch: 5| Step: 6
Training loss: 1.8256003856658936
Validation loss: 2.065490717689196

Epoch: 5| Step: 7
Training loss: 1.9021539688110352
Validation loss: 2.0503840943177543

Epoch: 5| Step: 8
Training loss: 1.8672338724136353
Validation loss: 2.0381869624058404

Epoch: 5| Step: 9
Training loss: 2.428356647491455
Validation loss: 2.052132894595464

Epoch: 5| Step: 10
Training loss: 1.8803609609603882
Validation loss: 2.0472726772228875

Epoch: 5| Step: 11
Training loss: 1.2333102226257324
Validation loss: 2.0228743652502694

Epoch: 38| Step: 0
Training loss: 1.8595346212387085
Validation loss: 2.0066925833622613

Epoch: 5| Step: 1
Training loss: 1.9678981304168701
Validation loss: 2.007338876525561

Epoch: 5| Step: 2
Training loss: 2.3301944732666016
Validation loss: 1.9936316112677257

Epoch: 5| Step: 3
Training loss: 1.7091964483261108
Validation loss: 1.976963609457016

Epoch: 5| Step: 4
Training loss: 2.0437846183776855
Validation loss: 1.9699264119068782

Epoch: 5| Step: 5
Training loss: 1.5474176406860352
Validation loss: 1.9847135245800018

Epoch: 5| Step: 6
Training loss: 2.1344170570373535
Validation loss: 1.9740118930737178

Epoch: 5| Step: 7
Training loss: 1.8958957195281982
Validation loss: 1.9850629568099976

Epoch: 5| Step: 8
Training loss: 2.0667243003845215
Validation loss: 1.9888236224651337

Epoch: 5| Step: 9
Training loss: 2.2064554691314697
Validation loss: 2.004167010386785

Epoch: 5| Step: 10
Training loss: 1.9107879400253296
Validation loss: 2.002698689699173

Epoch: 5| Step: 11
Training loss: 1.2123699188232422
Validation loss: 2.016421467065811

Epoch: 39| Step: 0
Training loss: 1.3404260873794556
Validation loss: 2.019675781329473

Epoch: 5| Step: 1
Training loss: 1.757520318031311
Validation loss: 2.0531285305817923

Epoch: 5| Step: 2
Training loss: 1.9334304332733154
Validation loss: 2.0936629275480905

Epoch: 5| Step: 3
Training loss: 2.8435187339782715
Validation loss: 2.0964930057525635

Epoch: 5| Step: 4
Training loss: 1.6909652948379517
Validation loss: 2.127866804599762

Epoch: 5| Step: 5
Training loss: 2.247488498687744
Validation loss: 2.12897981206576

Epoch: 5| Step: 6
Training loss: 1.8092546463012695
Validation loss: 2.117223173379898

Epoch: 5| Step: 7
Training loss: 2.3370261192321777
Validation loss: 2.088605264822642

Epoch: 5| Step: 8
Training loss: 1.9654018878936768
Validation loss: 2.08649372557799

Epoch: 5| Step: 9
Training loss: 1.3460967540740967
Validation loss: 2.0890182058016458

Epoch: 5| Step: 10
Training loss: 2.283135175704956
Validation loss: 2.085463066895803

Epoch: 5| Step: 11
Training loss: 2.117103338241577
Validation loss: 2.079095577200254

Epoch: 40| Step: 0
Training loss: 1.712121605873108
Validation loss: 2.046011582016945

Epoch: 5| Step: 1
Training loss: 2.0710761547088623
Validation loss: 2.0355457862218223

Epoch: 5| Step: 2
Training loss: 1.4387247562408447
Validation loss: 2.0248109996318817

Epoch: 5| Step: 3
Training loss: 2.193211555480957
Validation loss: 2.037247821688652

Epoch: 5| Step: 4
Training loss: 1.9564831256866455
Validation loss: 2.015963062644005

Epoch: 5| Step: 5
Training loss: 2.170618772506714
Validation loss: 2.008273775378863

Epoch: 5| Step: 6
Training loss: 2.1411755084991455
Validation loss: 1.997726211945216

Epoch: 5| Step: 7
Training loss: 1.767496109008789
Validation loss: 2.0129261513551078

Epoch: 5| Step: 8
Training loss: 1.981780767440796
Validation loss: 2.0154775232076645

Epoch: 5| Step: 9
Training loss: 1.7193434238433838
Validation loss: 2.009938751657804

Epoch: 5| Step: 10
Training loss: 2.136984348297119
Validation loss: 2.007412552833557

Epoch: 5| Step: 11
Training loss: 1.7257832288742065
Validation loss: 1.981241837143898

Epoch: 41| Step: 0
Training loss: 1.6987653970718384
Validation loss: 2.008495738108953

Epoch: 5| Step: 1
Training loss: 1.7686046361923218
Validation loss: 2.0017735014359155

Epoch: 5| Step: 2
Training loss: 2.526982069015503
Validation loss: 1.9936571667591731

Epoch: 5| Step: 3
Training loss: 1.8242524862289429
Validation loss: 2.0091285407543182

Epoch: 5| Step: 4
Training loss: 1.9445953369140625
Validation loss: 1.9873425712188084

Epoch: 5| Step: 5
Training loss: 1.9736881256103516
Validation loss: 1.9989675084749858

Epoch: 5| Step: 6
Training loss: 1.9695135354995728
Validation loss: 1.9966040253639221

Epoch: 5| Step: 7
Training loss: 2.2328286170959473
Validation loss: 1.9930103967587154

Epoch: 5| Step: 8
Training loss: 1.7176052331924438
Validation loss: 2.0002221862475076

Epoch: 5| Step: 9
Training loss: 1.6084930896759033
Validation loss: 1.9942239373922348

Epoch: 5| Step: 10
Training loss: 1.6923385858535767
Validation loss: 2.0037930806477866

Epoch: 5| Step: 11
Training loss: 3.1851837635040283
Validation loss: 2.0193186700344086

Epoch: 42| Step: 0
Training loss: 2.1863198280334473
Validation loss: 2.0374833246072135

Epoch: 5| Step: 1
Training loss: 1.7930047512054443
Validation loss: 2.0539624094963074

Epoch: 5| Step: 2
Training loss: 2.0495753288269043
Validation loss: 2.072476496299108

Epoch: 5| Step: 3
Training loss: 2.212630271911621
Validation loss: 2.086959093809128

Epoch: 5| Step: 4
Training loss: 1.9968467950820923
Validation loss: 2.1007608473300934

Epoch: 5| Step: 5
Training loss: 1.774839997291565
Validation loss: 2.103151246905327

Epoch: 5| Step: 6
Training loss: 1.9948186874389648
Validation loss: 2.089126447836558

Epoch: 5| Step: 7
Training loss: 2.1185779571533203
Validation loss: 2.1141888350248337

Epoch: 5| Step: 8
Training loss: 1.8505423069000244
Validation loss: 2.0692297418912253

Epoch: 5| Step: 9
Training loss: 1.585194706916809
Validation loss: 2.0665492117404938

Epoch: 5| Step: 10
Training loss: 1.9639755487442017
Validation loss: 2.05403600136439

Epoch: 5| Step: 11
Training loss: 1.1734061241149902
Validation loss: 2.066474457581838

Epoch: 43| Step: 0
Training loss: 2.1157383918762207
Validation loss: 2.0363583912452063

Epoch: 5| Step: 1
Training loss: 1.680748701095581
Validation loss: 2.0094145139058432

Epoch: 5| Step: 2
Training loss: 2.4659557342529297
Validation loss: 2.018372649947802

Epoch: 5| Step: 3
Training loss: 1.778183937072754
Validation loss: 2.005322883526484

Epoch: 5| Step: 4
Training loss: 2.534325361251831
Validation loss: 2.002895767490069

Epoch: 5| Step: 5
Training loss: 1.9103050231933594
Validation loss: 1.9984727203845978

Epoch: 5| Step: 6
Training loss: 1.2955306768417358
Validation loss: 1.9782219032446544

Epoch: 5| Step: 7
Training loss: 1.9397655725479126
Validation loss: 1.9734562039375305

Epoch: 5| Step: 8
Training loss: 1.7345635890960693
Validation loss: 1.9795601665973663

Epoch: 5| Step: 9
Training loss: 1.5417611598968506
Validation loss: 1.9830511113007863

Epoch: 5| Step: 10
Training loss: 1.9960941076278687
Validation loss: 1.9778996209303539

Epoch: 5| Step: 11
Training loss: 2.6390509605407715
Validation loss: 1.9771197189887364

Epoch: 44| Step: 0
Training loss: 2.1135189533233643
Validation loss: 1.9971157014369965

Epoch: 5| Step: 1
Training loss: 1.7305376529693604
Validation loss: 1.9936173458894093

Epoch: 5| Step: 2
Training loss: 2.0462212562561035
Validation loss: 2.004018967350324

Epoch: 5| Step: 3
Training loss: 1.5345518589019775
Validation loss: 2.0133002003033957

Epoch: 5| Step: 4
Training loss: 2.284698963165283
Validation loss: 2.0092467814683914

Epoch: 5| Step: 5
Training loss: 2.0006442070007324
Validation loss: 2.0158697962760925

Epoch: 5| Step: 6
Training loss: 2.1845154762268066
Validation loss: 2.0257885456085205

Epoch: 5| Step: 7
Training loss: 2.063438653945923
Validation loss: 2.03287535905838

Epoch: 5| Step: 8
Training loss: 1.721662163734436
Validation loss: 2.0310996025800705

Epoch: 5| Step: 9
Training loss: 1.846075415611267
Validation loss: 2.048260043064753

Epoch: 5| Step: 10
Training loss: 1.575060248374939
Validation loss: 2.0417540023724237

Epoch: 5| Step: 11
Training loss: 1.6510756015777588
Validation loss: 2.0464256008466086

Epoch: 45| Step: 0
Training loss: 1.6068729162216187
Validation loss: 2.036769544084867

Epoch: 5| Step: 1
Training loss: 1.476716160774231
Validation loss: 2.0899277379115424

Epoch: 5| Step: 2
Training loss: 1.525519609451294
Validation loss: 2.114806746443113

Epoch: 5| Step: 3
Training loss: 2.04145884513855
Validation loss: 2.108486980199814

Epoch: 5| Step: 4
Training loss: 2.23374605178833
Validation loss: 2.134076183040937

Epoch: 5| Step: 5
Training loss: 2.089864730834961
Validation loss: 2.111423119902611

Epoch: 5| Step: 6
Training loss: 2.6056010723114014
Validation loss: 2.104704827070236

Epoch: 5| Step: 7
Training loss: 1.7115609645843506
Validation loss: 2.1020575811465583

Epoch: 5| Step: 8
Training loss: 1.9237878322601318
Validation loss: 2.0812936375538507

Epoch: 5| Step: 9
Training loss: 1.9115791320800781
Validation loss: 2.050609121719996

Epoch: 5| Step: 10
Training loss: 2.258310317993164
Validation loss: 2.037385712067286

Epoch: 5| Step: 11
Training loss: 2.0439553260803223
Validation loss: 2.0233026246229806

Epoch: 46| Step: 0
Training loss: 2.038708209991455
Validation loss: 2.0184664825598397

Epoch: 5| Step: 1
Training loss: 1.599063515663147
Validation loss: 1.9869956970214844

Epoch: 5| Step: 2
Training loss: 1.9579147100448608
Validation loss: 1.9735409220059712

Epoch: 5| Step: 3
Training loss: 1.5032203197479248
Validation loss: 1.9784933974345524

Epoch: 5| Step: 4
Training loss: 2.1956801414489746
Validation loss: 1.9757049431403477

Epoch: 5| Step: 5
Training loss: 1.7724195718765259
Validation loss: 1.9820014139016469

Epoch: 5| Step: 6
Training loss: 2.561082363128662
Validation loss: 1.980476771791776

Epoch: 5| Step: 7
Training loss: 1.8346188068389893
Validation loss: 1.996831163764

Epoch: 5| Step: 8
Training loss: 1.9685890674591064
Validation loss: 2.0170056273539863

Epoch: 5| Step: 9
Training loss: 1.7626979351043701
Validation loss: 2.036282459894816

Epoch: 5| Step: 10
Training loss: 2.1845998764038086
Validation loss: 2.027672524253527

Epoch: 5| Step: 11
Training loss: 2.281313896179199
Validation loss: 2.039833794037501

Epoch: 47| Step: 0
Training loss: 2.334423065185547
Validation loss: 2.019025887052218

Epoch: 5| Step: 1
Training loss: 2.25144100189209
Validation loss: 2.019895518819491

Epoch: 5| Step: 2
Training loss: 1.2374322414398193
Validation loss: 2.0152474492788315

Epoch: 5| Step: 3
Training loss: 1.9495350122451782
Validation loss: 2.0088310092687607

Epoch: 5| Step: 4
Training loss: 2.091827869415283
Validation loss: 1.9930259833733242

Epoch: 5| Step: 5
Training loss: 1.717301607131958
Validation loss: 2.000336547692617

Epoch: 5| Step: 6
Training loss: 2.0846147537231445
Validation loss: 1.9775099108616512

Epoch: 5| Step: 7
Training loss: 1.5978190898895264
Validation loss: 1.9787225325902302

Epoch: 5| Step: 8
Training loss: 1.9833917617797852
Validation loss: 1.9880971411863964

Epoch: 5| Step: 9
Training loss: 1.8127944469451904
Validation loss: 1.9831200192372005

Epoch: 5| Step: 10
Training loss: 1.7780593633651733
Validation loss: 2.004610146085421

Epoch: 5| Step: 11
Training loss: 2.8485074043273926
Validation loss: 2.000087042649587

Epoch: 48| Step: 0
Training loss: 1.817853569984436
Validation loss: 2.0237546463807425

Epoch: 5| Step: 1
Training loss: 1.8723701238632202
Validation loss: 2.0458097209533057

Epoch: 5| Step: 2
Training loss: 2.903885841369629
Validation loss: 2.045105258623759

Epoch: 5| Step: 3
Training loss: 1.7631118297576904
Validation loss: 2.0795692652463913

Epoch: 5| Step: 4
Training loss: 1.6840317249298096
Validation loss: 2.058344746629397

Epoch: 5| Step: 5
Training loss: 2.370922803878784
Validation loss: 2.0548791140317917

Epoch: 5| Step: 6
Training loss: 1.8418378829956055
Validation loss: 2.059877042969068

Epoch: 5| Step: 7
Training loss: 2.5199732780456543
Validation loss: 2.055599237481753

Epoch: 5| Step: 8
Training loss: 1.2197811603546143
Validation loss: 2.0593182494242988

Epoch: 5| Step: 9
Training loss: 1.1592872142791748
Validation loss: 2.0378563006718955

Epoch: 5| Step: 10
Training loss: 2.01595139503479
Validation loss: 2.0489108314116797

Epoch: 5| Step: 11
Training loss: 0.9856839179992676
Validation loss: 2.031543960173925

Epoch: 49| Step: 0
Training loss: 1.9275915622711182
Validation loss: 2.0394951601823172

Epoch: 5| Step: 1
Training loss: 2.338573932647705
Validation loss: 2.055446376403173

Epoch: 5| Step: 2
Training loss: 1.5473600625991821
Validation loss: 2.0275107522805533

Epoch: 5| Step: 3
Training loss: 1.5948809385299683
Validation loss: 2.0262227257092795

Epoch: 5| Step: 4
Training loss: 1.5905534029006958
Validation loss: 2.0309018989404044

Epoch: 5| Step: 5
Training loss: 2.3741836547851562
Validation loss: 2.0248900254567466

Epoch: 5| Step: 6
Training loss: 2.3199973106384277
Validation loss: 2.0149857799212136

Epoch: 5| Step: 7
Training loss: 1.6099493503570557
Validation loss: 2.0053104758262634

Epoch: 5| Step: 8
Training loss: 1.9913971424102783
Validation loss: 1.9905489087104797

Epoch: 5| Step: 9
Training loss: 1.702836275100708
Validation loss: 2.0066753178834915

Epoch: 5| Step: 10
Training loss: 1.734151840209961
Validation loss: 1.987162912885348

Epoch: 5| Step: 11
Training loss: 2.007438898086548
Validation loss: 1.9850589384635289

Epoch: 50| Step: 0
Training loss: 2.095658540725708
Validation loss: 1.9823967864116032

Epoch: 5| Step: 1
Training loss: 1.9158817529678345
Validation loss: 1.9749126782019932

Epoch: 5| Step: 2
Training loss: 1.7793867588043213
Validation loss: 1.9786398708820343

Epoch: 5| Step: 3
Training loss: 1.981671929359436
Validation loss: 1.967240571975708

Epoch: 5| Step: 4
Training loss: 1.733557939529419
Validation loss: 1.973906139532725

Epoch: 5| Step: 5
Training loss: 1.7536433935165405
Validation loss: 1.987806757291158

Epoch: 5| Step: 6
Training loss: 2.041922092437744
Validation loss: 1.9937871595223744

Epoch: 5| Step: 7
Training loss: 1.7356901168823242
Validation loss: 2.023595998684565

Epoch: 5| Step: 8
Training loss: 1.6275384426116943
Validation loss: 2.0270290970802307

Epoch: 5| Step: 9
Training loss: 2.087031841278076
Validation loss: 2.0420734584331512

Epoch: 5| Step: 10
Training loss: 2.3189170360565186
Validation loss: 2.0531223664681115

Epoch: 5| Step: 11
Training loss: 1.3097681999206543
Validation loss: 2.037760689854622

Epoch: 51| Step: 0
Training loss: 1.6165111064910889
Validation loss: 2.0333396196365356

Epoch: 5| Step: 1
Training loss: 2.338087558746338
Validation loss: 2.0550233076016107

Epoch: 5| Step: 2
Training loss: 2.513429641723633
Validation loss: 2.033459613720576

Epoch: 5| Step: 3
Training loss: 1.7732717990875244
Validation loss: 2.0239572525024414

Epoch: 5| Step: 4
Training loss: 1.800848364830017
Validation loss: 2.0243689914544425

Epoch: 5| Step: 5
Training loss: 1.3276106119155884
Validation loss: 2.0035048921902976

Epoch: 5| Step: 6
Training loss: 2.301809787750244
Validation loss: 2.00826163093249

Epoch: 5| Step: 7
Training loss: 1.6764341592788696
Validation loss: 2.011322408914566

Epoch: 5| Step: 8
Training loss: 1.7541913986206055
Validation loss: 2.0113938053448996

Epoch: 5| Step: 9
Training loss: 1.3845689296722412
Validation loss: 1.9986756543318431

Epoch: 5| Step: 10
Training loss: 2.1964287757873535
Validation loss: 2.014487236738205

Epoch: 5| Step: 11
Training loss: 1.6907020807266235
Validation loss: 2.013470803697904

Epoch: 52| Step: 0
Training loss: 2.005793571472168
Validation loss: 2.006678511699041

Epoch: 5| Step: 1
Training loss: 1.479411005973816
Validation loss: 2.022262612978617

Epoch: 5| Step: 2
Training loss: 1.5532585382461548
Validation loss: 2.0319011211395264

Epoch: 5| Step: 3
Training loss: 1.9501714706420898
Validation loss: 2.0135328421990075

Epoch: 5| Step: 4
Training loss: 1.4957256317138672
Validation loss: 2.006177008152008

Epoch: 5| Step: 5
Training loss: 2.085374355316162
Validation loss: 2.0250704884529114

Epoch: 5| Step: 6
Training loss: 2.3130836486816406
Validation loss: 2.0287907818953195

Epoch: 5| Step: 7
Training loss: 1.7567098140716553
Validation loss: 2.0111617793639502

Epoch: 5| Step: 8
Training loss: 1.734553337097168
Validation loss: 2.031564027070999

Epoch: 5| Step: 9
Training loss: 1.9459291696548462
Validation loss: 2.0338234305381775

Epoch: 5| Step: 10
Training loss: 2.123016834259033
Validation loss: 2.036458889643351

Epoch: 5| Step: 11
Training loss: 2.6352384090423584
Validation loss: 2.012985755999883

Epoch: 53| Step: 0
Training loss: 2.089900255203247
Validation loss: 2.0335338513056436

Epoch: 5| Step: 1
Training loss: 1.6794029474258423
Validation loss: 2.0040345788002014

Epoch: 5| Step: 2
Training loss: 1.9570057392120361
Validation loss: 2.0274783770243325

Epoch: 5| Step: 3
Training loss: 1.6654489040374756
Validation loss: 2.039588585495949

Epoch: 5| Step: 4
Training loss: 1.8980510234832764
Validation loss: 2.0187807778517404

Epoch: 5| Step: 5
Training loss: 1.7751693725585938
Validation loss: 2.0132654954989753

Epoch: 5| Step: 6
Training loss: 1.5499693155288696
Validation loss: 2.005870044231415

Epoch: 5| Step: 7
Training loss: 1.9031633138656616
Validation loss: 2.0110818594694138

Epoch: 5| Step: 8
Training loss: 1.9117753505706787
Validation loss: 1.9665612230698268

Epoch: 5| Step: 9
Training loss: 1.6846435070037842
Validation loss: 1.9950383404890697

Epoch: 5| Step: 10
Training loss: 2.3437886238098145
Validation loss: 1.9905283798774083

Epoch: 5| Step: 11
Training loss: 2.441338062286377
Validation loss: 1.998635729153951

Epoch: 54| Step: 0
Training loss: 2.067478656768799
Validation loss: 2.0084145416816077

Epoch: 5| Step: 1
Training loss: 1.8062736988067627
Validation loss: 2.0052194794019065

Epoch: 5| Step: 2
Training loss: 1.9397504329681396
Validation loss: 1.9928028633197148

Epoch: 5| Step: 3
Training loss: 1.9891583919525146
Validation loss: 2.018637011448542

Epoch: 5| Step: 4
Training loss: 1.8804479837417603
Validation loss: 2.011454035838445

Epoch: 5| Step: 5
Training loss: 2.0748538970947266
Validation loss: 2.023060590028763

Epoch: 5| Step: 6
Training loss: 1.4868552684783936
Validation loss: 2.0369218438863754

Epoch: 5| Step: 7
Training loss: 2.111447334289551
Validation loss: 2.048675720890363

Epoch: 5| Step: 8
Training loss: 2.022143602371216
Validation loss: 2.038952594002088

Epoch: 5| Step: 9
Training loss: 1.7065061330795288
Validation loss: 2.03032386302948

Epoch: 5| Step: 10
Training loss: 1.4626195430755615
Validation loss: 2.0271989554166794

Epoch: 5| Step: 11
Training loss: 1.4776983261108398
Validation loss: 2.0432823300361633

Epoch: 55| Step: 0
Training loss: 2.1852059364318848
Validation loss: 2.0205673376719155

Epoch: 5| Step: 1
Training loss: 1.9387760162353516
Validation loss: 2.0220877528190613

Epoch: 5| Step: 2
Training loss: 2.132107734680176
Validation loss: 2.003534570336342

Epoch: 5| Step: 3
Training loss: 1.715070366859436
Validation loss: 1.98650261759758

Epoch: 5| Step: 4
Training loss: 1.367566704750061
Validation loss: 1.9882817268371582

Epoch: 5| Step: 5
Training loss: 1.755425214767456
Validation loss: 1.9732721249262493

Epoch: 5| Step: 6
Training loss: 2.0850260257720947
Validation loss: 1.9746671617031097

Epoch: 5| Step: 7
Training loss: 1.3345310688018799
Validation loss: 1.9819694807132084

Epoch: 5| Step: 8
Training loss: 1.728261947631836
Validation loss: 1.9764335801204045

Epoch: 5| Step: 9
Training loss: 1.9253466129302979
Validation loss: 1.9848501632610958

Epoch: 5| Step: 10
Training loss: 2.4688358306884766
Validation loss: 2.003228113055229

Epoch: 5| Step: 11
Training loss: 1.8288317918777466
Validation loss: 2.00931050380071

Epoch: 56| Step: 0
Training loss: 1.8114713430404663
Validation loss: 2.035611853003502

Epoch: 5| Step: 1
Training loss: 1.4887365102767944
Validation loss: 2.0548052738110223

Epoch: 5| Step: 2
Training loss: 2.0851964950561523
Validation loss: 2.094075302282969

Epoch: 5| Step: 3
Training loss: 1.641424536705017
Validation loss: 2.0732917487621307

Epoch: 5| Step: 4
Training loss: 2.4648995399475098
Validation loss: 2.0921025027831397

Epoch: 5| Step: 5
Training loss: 1.8094139099121094
Validation loss: 2.0702547828356423

Epoch: 5| Step: 6
Training loss: 1.4198968410491943
Validation loss: 2.0584766566753387

Epoch: 5| Step: 7
Training loss: 1.8276512622833252
Validation loss: 2.0533312459786734

Epoch: 5| Step: 8
Training loss: 2.3990206718444824
Validation loss: 2.039954046408335

Epoch: 5| Step: 9
Training loss: 1.8591982126235962
Validation loss: 2.0298586984475455

Epoch: 5| Step: 10
Training loss: 1.741957426071167
Validation loss: 2.0177200386921563

Epoch: 5| Step: 11
Training loss: 2.365077495574951
Validation loss: 1.9994950493176777

Epoch: 57| Step: 0
Training loss: 1.8101240396499634
Validation loss: 1.9949275155862172

Epoch: 5| Step: 1
Training loss: 2.1212799549102783
Validation loss: 1.9795054246981938

Epoch: 5| Step: 2
Training loss: 1.2674586772918701
Validation loss: 1.9872598002354305

Epoch: 5| Step: 3
Training loss: 1.7394052743911743
Validation loss: 2.0106120506922402

Epoch: 5| Step: 4
Training loss: 2.2139906883239746
Validation loss: 2.014978547890981

Epoch: 5| Step: 5
Training loss: 2.0613961219787598
Validation loss: 2.008236179749171

Epoch: 5| Step: 6
Training loss: 2.141951084136963
Validation loss: 2.014622022708257

Epoch: 5| Step: 7
Training loss: 1.7926759719848633
Validation loss: 2.0148175607124963

Epoch: 5| Step: 8
Training loss: 1.7121155261993408
Validation loss: 2.008004069328308

Epoch: 5| Step: 9
Training loss: 1.87851881980896
Validation loss: 1.9975284188985825

Epoch: 5| Step: 10
Training loss: 1.8392261266708374
Validation loss: 2.0361110270023346

Epoch: 5| Step: 11
Training loss: 0.6136221885681152
Validation loss: 2.0075531552235284

Epoch: 58| Step: 0
Training loss: 2.145608901977539
Validation loss: 2.001684824625651

Epoch: 5| Step: 1
Training loss: 2.616811752319336
Validation loss: 2.0121937642494836

Epoch: 5| Step: 2
Training loss: 1.6669533252716064
Validation loss: 1.991647630929947

Epoch: 5| Step: 3
Training loss: 1.5424034595489502
Validation loss: 2.0206525127092996

Epoch: 5| Step: 4
Training loss: 2.1747374534606934
Validation loss: 1.9965048432350159

Epoch: 5| Step: 5
Training loss: 1.7102811336517334
Validation loss: 1.977830484509468

Epoch: 5| Step: 6
Training loss: 1.7320878505706787
Validation loss: 1.9955534487962723

Epoch: 5| Step: 7
Training loss: 1.835481882095337
Validation loss: 1.9734013477961223

Epoch: 5| Step: 8
Training loss: 1.6653257608413696
Validation loss: 1.9929314305384953

Epoch: 5| Step: 9
Training loss: 1.61624014377594
Validation loss: 1.9907682836055756

Epoch: 5| Step: 10
Training loss: 1.8265348672866821
Validation loss: 2.0176481952269874

Epoch: 5| Step: 11
Training loss: 1.356590747833252
Validation loss: 2.040168970823288

Epoch: 59| Step: 0
Training loss: 1.9285370111465454
Validation loss: 2.0539175868034363

Epoch: 5| Step: 1
Training loss: 2.2439749240875244
Validation loss: 2.0698892176151276

Epoch: 5| Step: 2
Training loss: 2.147395610809326
Validation loss: 2.0573345919450126

Epoch: 5| Step: 3
Training loss: 2.02549409866333
Validation loss: 2.067410781979561

Epoch: 5| Step: 4
Training loss: 1.939269781112671
Validation loss: 2.0476196904977164

Epoch: 5| Step: 5
Training loss: 1.8447847366333008
Validation loss: 2.0454138616720834

Epoch: 5| Step: 6
Training loss: 1.489189624786377
Validation loss: 2.0418748607238135

Epoch: 5| Step: 7
Training loss: 1.739484429359436
Validation loss: 2.0348972777525582

Epoch: 5| Step: 8
Training loss: 1.5962896347045898
Validation loss: 2.0311586062113443

Epoch: 5| Step: 9
Training loss: 1.538165807723999
Validation loss: 2.015065222978592

Epoch: 5| Step: 10
Training loss: 1.751358985900879
Validation loss: 2.0233664512634277

Epoch: 5| Step: 11
Training loss: 1.9664407968521118
Validation loss: 2.012775724132856

Epoch: 60| Step: 0
Training loss: 1.384059190750122
Validation loss: 2.0178471753994622

Epoch: 5| Step: 1
Training loss: 1.8909740447998047
Validation loss: 1.9998787691195805

Epoch: 5| Step: 2
Training loss: 2.168139934539795
Validation loss: 2.0370706220467887

Epoch: 5| Step: 3
Training loss: 2.0423636436462402
Validation loss: 2.0309853901465735

Epoch: 5| Step: 4
Training loss: 2.0008959770202637
Validation loss: 2.043552706638972

Epoch: 5| Step: 5
Training loss: 1.3037660121917725
Validation loss: 2.0178515166044235

Epoch: 5| Step: 6
Training loss: 1.8889923095703125
Validation loss: 2.0254609286785126

Epoch: 5| Step: 7
Training loss: 1.2293789386749268
Validation loss: 2.0279082308212915

Epoch: 5| Step: 8
Training loss: 2.074073314666748
Validation loss: 2.008504201968511

Epoch: 5| Step: 9
Training loss: 2.2346179485321045
Validation loss: 2.0084115316470466

Epoch: 5| Step: 10
Training loss: 1.6058508157730103
Validation loss: 2.00430528819561

Epoch: 5| Step: 11
Training loss: 3.060363531112671
Validation loss: 1.9997438093026478

Epoch: 61| Step: 0
Training loss: 1.3060966730117798
Validation loss: 1.9914438774188359

Epoch: 5| Step: 1
Training loss: 1.4591352939605713
Validation loss: 1.9879685839017232

Epoch: 5| Step: 2
Training loss: 1.9617900848388672
Validation loss: 1.9801082462072372

Epoch: 5| Step: 3
Training loss: 2.116145372390747
Validation loss: 2.002332478761673

Epoch: 5| Step: 4
Training loss: 1.9943208694458008
Validation loss: 1.9794020702441533

Epoch: 5| Step: 5
Training loss: 1.7338275909423828
Validation loss: 1.9831806967655818

Epoch: 5| Step: 6
Training loss: 2.1737148761749268
Validation loss: 1.9879834453264873

Epoch: 5| Step: 7
Training loss: 1.6800687313079834
Validation loss: 1.9805619269609451

Epoch: 5| Step: 8
Training loss: 1.6637766361236572
Validation loss: 1.9740852514902751

Epoch: 5| Step: 9
Training loss: 2.0944669246673584
Validation loss: 1.9963116546471913

Epoch: 5| Step: 10
Training loss: 1.7235076427459717
Validation loss: 2.020957405368487

Epoch: 5| Step: 11
Training loss: 2.1538500785827637
Validation loss: 2.000989630818367

Epoch: 62| Step: 0
Training loss: 1.521051049232483
Validation loss: 2.011073092619578

Epoch: 5| Step: 1
Training loss: 1.5187578201293945
Validation loss: 2.0364224016666412

Epoch: 5| Step: 2
Training loss: 1.858137845993042
Validation loss: 2.038847024242083

Epoch: 5| Step: 3
Training loss: 2.158602714538574
Validation loss: 2.036366884907087

Epoch: 5| Step: 4
Training loss: 1.900231122970581
Validation loss: 2.0429923236370087

Epoch: 5| Step: 5
Training loss: 2.0282490253448486
Validation loss: 2.055778662363688

Epoch: 5| Step: 6
Training loss: 1.7859729528427124
Validation loss: 2.038623278339704

Epoch: 5| Step: 7
Training loss: 1.855425477027893
Validation loss: 2.028321440021197

Epoch: 5| Step: 8
Training loss: 1.633541464805603
Validation loss: 2.0114684452613196

Epoch: 5| Step: 9
Training loss: 1.7903251647949219
Validation loss: 2.0132462978363037

Epoch: 5| Step: 10
Training loss: 1.8861888647079468
Validation loss: 2.0103339602549872

Epoch: 5| Step: 11
Training loss: 1.885695457458496
Validation loss: 2.013491918643316

Epoch: 63| Step: 0
Training loss: 1.8165010213851929
Validation loss: 1.9924656798442204

Epoch: 5| Step: 1
Training loss: 1.6877052783966064
Validation loss: 2.0101885745922723

Epoch: 5| Step: 2
Training loss: 1.676529884338379
Validation loss: 2.0056987007459006

Epoch: 5| Step: 3
Training loss: 1.5358690023422241
Validation loss: 1.986383448044459

Epoch: 5| Step: 4
Training loss: 2.111757755279541
Validation loss: 1.9811595578988392

Epoch: 5| Step: 5
Training loss: 1.350999116897583
Validation loss: 1.9722471634546916

Epoch: 5| Step: 6
Training loss: 2.1223742961883545
Validation loss: 1.9692669411500294

Epoch: 5| Step: 7
Training loss: 1.958439588546753
Validation loss: 1.9463369498650234

Epoch: 5| Step: 8
Training loss: 1.9635337591171265
Validation loss: 1.9672108838955562

Epoch: 5| Step: 9
Training loss: 1.7824089527130127
Validation loss: 1.9536729355653126

Epoch: 5| Step: 10
Training loss: 1.910009741783142
Validation loss: 1.991391157110532

Epoch: 5| Step: 11
Training loss: 2.6174535751342773
Validation loss: 1.994573046763738

Epoch: 64| Step: 0
Training loss: 1.7870700359344482
Validation loss: 2.0459397236506143

Epoch: 5| Step: 1
Training loss: 1.6987197399139404
Validation loss: 2.0496637374162674

Epoch: 5| Step: 2
Training loss: 1.6428455114364624
Validation loss: 2.090346415837606

Epoch: 5| Step: 3
Training loss: 2.6123852729797363
Validation loss: 2.1141919940710068

Epoch: 5| Step: 4
Training loss: 2.2088119983673096
Validation loss: 2.1429130136966705

Epoch: 5| Step: 5
Training loss: 1.7492218017578125
Validation loss: 2.125579526027044

Epoch: 5| Step: 6
Training loss: 1.6215242147445679
Validation loss: 2.101069465279579

Epoch: 5| Step: 7
Training loss: 1.6393144130706787
Validation loss: 2.0732119580109916

Epoch: 5| Step: 8
Training loss: 2.030895709991455
Validation loss: 2.0387930274009705

Epoch: 5| Step: 9
Training loss: 2.1622214317321777
Validation loss: 2.0310664425293603

Epoch: 5| Step: 10
Training loss: 1.4714752435684204
Validation loss: 1.988686054944992

Epoch: 5| Step: 11
Training loss: 1.522783875465393
Validation loss: 1.9761026352643967

Epoch: 65| Step: 0
Training loss: 2.7135519981384277
Validation loss: 1.9825360278288524

Epoch: 5| Step: 1
Training loss: 1.7880245447158813
Validation loss: 1.9622560093800228

Epoch: 5| Step: 2
Training loss: 1.6581710577011108
Validation loss: 1.9727354496717453

Epoch: 5| Step: 3
Training loss: 1.9366645812988281
Validation loss: 1.9725203464428585

Epoch: 5| Step: 4
Training loss: 1.635999083518982
Validation loss: 1.9891825467348099

Epoch: 5| Step: 5
Training loss: 1.9573551416397095
Validation loss: 1.9857452263434727

Epoch: 5| Step: 6
Training loss: 1.5400724411010742
Validation loss: 2.0107684830824533

Epoch: 5| Step: 7
Training loss: 1.3252341747283936
Validation loss: 1.9976447721322377

Epoch: 5| Step: 8
Training loss: 1.6351817846298218
Validation loss: 1.9955436438322067

Epoch: 5| Step: 9
Training loss: 1.6656625270843506
Validation loss: 2.0110796988010406

Epoch: 5| Step: 10
Training loss: 2.0520637035369873
Validation loss: 2.0211074352264404

Epoch: 5| Step: 11
Training loss: 0.9208856821060181
Validation loss: 2.029467359185219

Epoch: 66| Step: 0
Training loss: 1.6428287029266357
Validation loss: 2.0287776589393616

Epoch: 5| Step: 1
Training loss: 1.7877197265625
Validation loss: 2.018702174226443

Epoch: 5| Step: 2
Training loss: 1.7368896007537842
Validation loss: 2.0301828583081565

Epoch: 5| Step: 3
Training loss: 2.1505138874053955
Validation loss: 2.0109683175881705

Epoch: 5| Step: 4
Training loss: 1.4348042011260986
Validation loss: 2.0073686689138412

Epoch: 5| Step: 5
Training loss: 2.4288461208343506
Validation loss: 1.9834078550338745

Epoch: 5| Step: 6
Training loss: 1.6265647411346436
Validation loss: 1.9802263975143433

Epoch: 5| Step: 7
Training loss: 1.6090965270996094
Validation loss: 1.9928069214026134

Epoch: 5| Step: 8
Training loss: 1.428008794784546
Validation loss: 1.9991226543982823

Epoch: 5| Step: 9
Training loss: 2.2898154258728027
Validation loss: 2.011033390959104

Epoch: 5| Step: 10
Training loss: 1.7008154392242432
Validation loss: 1.9946578294038773

Epoch: 5| Step: 11
Training loss: 1.7134082317352295
Validation loss: 1.998955970009168

Epoch: 67| Step: 0
Training loss: 1.5178545713424683
Validation loss: 2.0027691473563514

Epoch: 5| Step: 1
Training loss: 1.8608577251434326
Validation loss: 2.0107691884040833

Epoch: 5| Step: 2
Training loss: 1.695884108543396
Validation loss: 1.9848016798496246

Epoch: 5| Step: 3
Training loss: 1.5604878664016724
Validation loss: 1.9811651408672333

Epoch: 5| Step: 4
Training loss: 1.6926876306533813
Validation loss: 1.963231032093366

Epoch: 5| Step: 5
Training loss: 1.1862825155258179
Validation loss: 1.9727953225374222

Epoch: 5| Step: 6
Training loss: 2.1202003955841064
Validation loss: 1.9659288475910823

Epoch: 5| Step: 7
Training loss: 2.0469048023223877
Validation loss: 1.9856446137030919

Epoch: 5| Step: 8
Training loss: 1.482895016670227
Validation loss: 2.0073268810908

Epoch: 5| Step: 9
Training loss: 1.9742310047149658
Validation loss: 2.0258775452772775

Epoch: 5| Step: 10
Training loss: 2.306488037109375
Validation loss: 2.029265453418096

Epoch: 5| Step: 11
Training loss: 4.151484966278076
Validation loss: 2.0644758542378745

Epoch: 68| Step: 0
Training loss: 1.7511736154556274
Validation loss: 2.0520419776439667

Epoch: 5| Step: 1
Training loss: 1.708091378211975
Validation loss: 2.0521366397539773

Epoch: 5| Step: 2
Training loss: 1.539252519607544
Validation loss: 2.015084664026896

Epoch: 5| Step: 3
Training loss: 1.698984146118164
Validation loss: 2.013291666905085

Epoch: 5| Step: 4
Training loss: 1.9015557765960693
Validation loss: 1.997547835111618

Epoch: 5| Step: 5
Training loss: 2.188427448272705
Validation loss: 1.9871708750724792

Epoch: 5| Step: 6
Training loss: 1.7269032001495361
Validation loss: 1.9828530699014664

Epoch: 5| Step: 7
Training loss: 1.8762626647949219
Validation loss: 1.961503192782402

Epoch: 5| Step: 8
Training loss: 1.9410673379898071
Validation loss: 1.9542334079742432

Epoch: 5| Step: 9
Training loss: 1.5089216232299805
Validation loss: 1.9820313503344853

Epoch: 5| Step: 10
Training loss: 1.8075857162475586
Validation loss: 1.9806828200817108

Epoch: 5| Step: 11
Training loss: 1.839827537536621
Validation loss: 1.9902241577704747

Epoch: 69| Step: 0
Training loss: 1.672082543373108
Validation loss: 1.980178525050481

Epoch: 5| Step: 1
Training loss: 1.9914337396621704
Validation loss: 1.9866533825794856

Epoch: 5| Step: 2
Training loss: 1.794590950012207
Validation loss: 2.0001718401908875

Epoch: 5| Step: 3
Training loss: 1.8672239780426025
Validation loss: 2.0166226973136268

Epoch: 5| Step: 4
Training loss: 2.0418999195098877
Validation loss: 2.048502658804258

Epoch: 5| Step: 5
Training loss: 1.7513036727905273
Validation loss: 2.068270588914553

Epoch: 5| Step: 6
Training loss: 1.6015913486480713
Validation loss: 2.053548350930214

Epoch: 5| Step: 7
Training loss: 1.668797254562378
Validation loss: 2.043621073166529

Epoch: 5| Step: 8
Training loss: 2.0780560970306396
Validation loss: 2.0439878900845847

Epoch: 5| Step: 9
Training loss: 1.5246156454086304
Validation loss: 2.051295667886734

Epoch: 5| Step: 10
Training loss: 1.3889402151107788
Validation loss: 2.046276112397512

Epoch: 5| Step: 11
Training loss: 2.228595733642578
Validation loss: 2.044279416402181

Epoch: 70| Step: 0
Training loss: 1.5433228015899658
Validation loss: 2.0350444316864014

Epoch: 5| Step: 1
Training loss: 1.6762737035751343
Validation loss: 2.0474929958581924

Epoch: 5| Step: 2
Training loss: 1.6891119480133057
Validation loss: 2.0175266414880753

Epoch: 5| Step: 3
Training loss: 1.4805433750152588
Validation loss: 2.0172973722219467

Epoch: 5| Step: 4
Training loss: 2.1494572162628174
Validation loss: 2.0078753332297006

Epoch: 5| Step: 5
Training loss: 1.4659204483032227
Validation loss: 2.0207179387410483

Epoch: 5| Step: 6
Training loss: 1.887555718421936
Validation loss: 2.012566631038984

Epoch: 5| Step: 7
Training loss: 2.3923439979553223
Validation loss: 2.0092344184716544

Epoch: 5| Step: 8
Training loss: 1.647743582725525
Validation loss: 2.0003588994344077

Epoch: 5| Step: 9
Training loss: 1.541234016418457
Validation loss: 2.0042582054932914

Epoch: 5| Step: 10
Training loss: 1.8822014331817627
Validation loss: 1.997979650894801

Epoch: 5| Step: 11
Training loss: 1.5881083011627197
Validation loss: 2.005527858932813

Epoch: 71| Step: 0
Training loss: 1.874799370765686
Validation loss: 2.01310866077741

Epoch: 5| Step: 1
Training loss: 2.2635507583618164
Validation loss: 2.018403540054957

Epoch: 5| Step: 2
Training loss: 1.7773357629776
Validation loss: 2.0141018678744635

Epoch: 5| Step: 3
Training loss: 1.4246835708618164
Validation loss: 2.0246643275022507

Epoch: 5| Step: 4
Training loss: 2.0219175815582275
Validation loss: 1.9908470859130223

Epoch: 5| Step: 5
Training loss: 2.077235698699951
Validation loss: 2.0055971990029016

Epoch: 5| Step: 6
Training loss: 1.617859125137329
Validation loss: 2.030807837843895

Epoch: 5| Step: 7
Training loss: 1.5085325241088867
Validation loss: 2.017809967199961

Epoch: 5| Step: 8
Training loss: 1.41474449634552
Validation loss: 2.0387293249368668

Epoch: 5| Step: 9
Training loss: 1.7917683124542236
Validation loss: 2.0356331914663315

Epoch: 5| Step: 10
Training loss: 1.4729704856872559
Validation loss: 2.044703950484594

Epoch: 5| Step: 11
Training loss: 1.359209656715393
Validation loss: 2.04889444510142

Epoch: 72| Step: 0
Training loss: 1.5488903522491455
Validation loss: 2.0654056618611016

Epoch: 5| Step: 1
Training loss: 1.6596031188964844
Validation loss: 2.0757969419161477

Epoch: 5| Step: 2
Training loss: 1.9068161249160767
Validation loss: 2.0869115789731345

Epoch: 5| Step: 3
Training loss: 1.9338020086288452
Validation loss: 2.104234923919042

Epoch: 5| Step: 4
Training loss: 1.82096266746521
Validation loss: 2.0880588988463082

Epoch: 5| Step: 5
Training loss: 1.6566482782363892
Validation loss: 2.0775022407372794

Epoch: 5| Step: 6
Training loss: 1.7515712976455688
Validation loss: 2.0491371800502143

Epoch: 5| Step: 7
Training loss: 1.0594743490219116
Validation loss: 2.0325689911842346

Epoch: 5| Step: 8
Training loss: 1.7563514709472656
Validation loss: 2.0091797411441803

Epoch: 5| Step: 9
Training loss: 1.7542531490325928
Validation loss: 2.0183675487836203

Epoch: 5| Step: 10
Training loss: 2.295569896697998
Validation loss: 1.9798842469851177

Epoch: 5| Step: 11
Training loss: 2.9009838104248047
Validation loss: 1.9806114087502162

Epoch: 73| Step: 0
Training loss: 2.155822277069092
Validation loss: 1.9875101099411647

Epoch: 5| Step: 1
Training loss: 2.500253438949585
Validation loss: 1.976145659883817

Epoch: 5| Step: 2
Training loss: 1.7724584341049194
Validation loss: 1.975447456041972

Epoch: 5| Step: 3
Training loss: 1.6919962167739868
Validation loss: 1.9834984093904495

Epoch: 5| Step: 4
Training loss: 1.9413026571273804
Validation loss: 1.9876495550076168

Epoch: 5| Step: 5
Training loss: 1.4131114482879639
Validation loss: 1.9934219320615132

Epoch: 5| Step: 6
Training loss: 1.693433403968811
Validation loss: 2.0017292698224387

Epoch: 5| Step: 7
Training loss: 1.7630523443222046
Validation loss: 2.0182104309399924

Epoch: 5| Step: 8
Training loss: 1.3092542886734009
Validation loss: 2.0174376914898553

Epoch: 5| Step: 9
Training loss: 1.3692976236343384
Validation loss: 2.046437601248423

Epoch: 5| Step: 10
Training loss: 1.959529161453247
Validation loss: 2.0592453380425773

Epoch: 5| Step: 11
Training loss: 0.9112933874130249
Validation loss: 2.0671174873908362

Epoch: 74| Step: 0
Training loss: 2.1560914516448975
Validation loss: 2.0218484302361808

Epoch: 5| Step: 1
Training loss: 1.1128826141357422
Validation loss: 2.005219509204229

Epoch: 5| Step: 2
Training loss: 1.1624829769134521
Validation loss: 2.0038053542375565

Epoch: 5| Step: 3
Training loss: 1.6706409454345703
Validation loss: 2.0014493564764657

Epoch: 5| Step: 4
Training loss: 2.080976963043213
Validation loss: 2.001790394385656

Epoch: 5| Step: 5
Training loss: 1.9039160013198853
Validation loss: 1.9725922097762425

Epoch: 5| Step: 6
Training loss: 1.4527051448822021
Validation loss: 1.975505252679189

Epoch: 5| Step: 7
Training loss: 1.7127548456192017
Validation loss: 1.9651791999737422

Epoch: 5| Step: 8
Training loss: 2.3717164993286133
Validation loss: 1.9811280369758606

Epoch: 5| Step: 9
Training loss: 2.1941380500793457
Validation loss: 1.9734177788098652

Epoch: 5| Step: 10
Training loss: 1.6130542755126953
Validation loss: 1.9938843895991643

Epoch: 5| Step: 11
Training loss: 1.218284249305725
Validation loss: 2.0059020817279816

Epoch: 75| Step: 0
Training loss: 1.8510749340057373
Validation loss: 2.039673631389936

Epoch: 5| Step: 1
Training loss: 2.0647988319396973
Validation loss: 2.0668380111455917

Epoch: 5| Step: 2
Training loss: 1.8254287242889404
Validation loss: 2.1095794339974723

Epoch: 5| Step: 3
Training loss: 1.7942907810211182
Validation loss: 2.1311603486537933

Epoch: 5| Step: 4
Training loss: 1.5889370441436768
Validation loss: 2.137975513935089

Epoch: 5| Step: 5
Training loss: 1.8708146810531616
Validation loss: 2.107879176735878

Epoch: 5| Step: 6
Training loss: 1.9867446422576904
Validation loss: 2.1075028081734977

Epoch: 5| Step: 7
Training loss: 1.560784101486206
Validation loss: 2.063277244567871

Epoch: 5| Step: 8
Training loss: 1.306904673576355
Validation loss: 2.0748999814192453

Epoch: 5| Step: 9
Training loss: 1.8515905141830444
Validation loss: 2.0692137529452643

Epoch: 5| Step: 10
Training loss: 1.7670705318450928
Validation loss: 2.0443459500869117

Epoch: 5| Step: 11
Training loss: 1.6398924589157104
Validation loss: 2.0169916848341622

Testing loss: 1.7596569421480028
