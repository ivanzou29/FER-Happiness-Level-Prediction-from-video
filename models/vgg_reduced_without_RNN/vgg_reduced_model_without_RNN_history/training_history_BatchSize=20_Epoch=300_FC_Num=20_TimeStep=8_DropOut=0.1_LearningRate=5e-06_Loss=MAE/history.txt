Epoch: 1| Step: 0
Training loss: 7.781744480133057
Validation loss: 7.404200772444407

Epoch: 5| Step: 1
Training loss: 7.247926235198975
Validation loss: 7.395995060602824

Epoch: 5| Step: 2
Training loss: 7.419624328613281
Validation loss: 7.389276007811229

Epoch: 5| Step: 3
Training loss: 7.5984930992126465
Validation loss: 7.380845010280609

Epoch: 5| Step: 4
Training loss: 7.832304954528809
Validation loss: 7.374447623888652

Epoch: 5| Step: 5
Training loss: 6.058411598205566
Validation loss: 7.366113881270091

Epoch: 5| Step: 6
Training loss: 7.84674596786499
Validation loss: 7.359597047170003

Epoch: 5| Step: 7
Training loss: 7.605735778808594
Validation loss: 7.35306974252065

Epoch: 5| Step: 8
Training loss: 6.402841091156006
Validation loss: 7.343125561873118

Epoch: 5| Step: 9
Training loss: 8.571220397949219
Validation loss: 7.3363368312517805

Epoch: 5| Step: 10
Training loss: 7.215419769287109
Validation loss: 7.329530815283458

Epoch: 5| Step: 11
Training loss: 8.400540351867676
Validation loss: 7.320305705070496

Epoch: 2| Step: 0
Training loss: 7.481165409088135
Validation loss: 7.312055865923564

Epoch: 5| Step: 1
Training loss: 7.627943992614746
Validation loss: 7.30448317527771

Epoch: 5| Step: 2
Training loss: 7.127122402191162
Validation loss: 7.295547664165497

Epoch: 5| Step: 3
Training loss: 6.7085700035095215
Validation loss: 7.285974562168121

Epoch: 5| Step: 4
Training loss: 6.815615653991699
Validation loss: 7.276394943396251

Epoch: 5| Step: 5
Training loss: 7.280635833740234
Validation loss: 7.267596423625946

Epoch: 5| Step: 6
Training loss: 7.427265167236328
Validation loss: 7.257972379525502

Epoch: 5| Step: 7
Training loss: 7.482510566711426
Validation loss: 7.243889192740123

Epoch: 5| Step: 8
Training loss: 8.51533317565918
Validation loss: 7.235710779825847

Epoch: 5| Step: 9
Training loss: 6.609255313873291
Validation loss: 7.221907794475555

Epoch: 5| Step: 10
Training loss: 7.409198760986328
Validation loss: 7.211146195729573

Epoch: 5| Step: 11
Training loss: 8.107812881469727
Validation loss: 7.200192292531331

Epoch: 3| Step: 0
Training loss: 7.379600524902344
Validation loss: 7.1848170558611555

Epoch: 5| Step: 1
Training loss: 6.455129146575928
Validation loss: 7.171320180098216

Epoch: 5| Step: 2
Training loss: 8.125277519226074
Validation loss: 7.158454378445943

Epoch: 5| Step: 3
Training loss: 7.1866278648376465
Validation loss: 7.14276389280955

Epoch: 5| Step: 4
Training loss: 7.173327445983887
Validation loss: 7.127841353416443

Epoch: 5| Step: 5
Training loss: 7.34945821762085
Validation loss: 7.113724231719971

Epoch: 5| Step: 6
Training loss: 8.01697826385498
Validation loss: 7.097324351469676

Epoch: 5| Step: 7
Training loss: 7.878998756408691
Validation loss: 7.080225010712941

Epoch: 5| Step: 8
Training loss: 5.800637245178223
Validation loss: 7.064693709214528

Epoch: 5| Step: 9
Training loss: 6.612765312194824
Validation loss: 7.047598242759705

Epoch: 5| Step: 10
Training loss: 7.198673248291016
Validation loss: 7.02822611729304

Epoch: 5| Step: 11
Training loss: 5.934807300567627
Validation loss: 7.011001725991567

Epoch: 4| Step: 0
Training loss: 7.545781135559082
Validation loss: 6.991914828618367

Epoch: 5| Step: 1
Training loss: 7.035712242126465
Validation loss: 6.968183596928914

Epoch: 5| Step: 2
Training loss: 7.545215606689453
Validation loss: 6.951359987258911

Epoch: 5| Step: 3
Training loss: 7.194449424743652
Validation loss: 6.92466155687968

Epoch: 5| Step: 4
Training loss: 6.261327266693115
Validation loss: 6.9004858533541364

Epoch: 5| Step: 5
Training loss: 6.112009525299072
Validation loss: 6.880776623884837

Epoch: 5| Step: 6
Training loss: 5.749028205871582
Validation loss: 6.858123362064362

Epoch: 5| Step: 7
Training loss: 7.403784275054932
Validation loss: 6.829878568649292

Epoch: 5| Step: 8
Training loss: 7.344695091247559
Validation loss: 6.806575953960419

Epoch: 5| Step: 9
Training loss: 7.445021152496338
Validation loss: 6.775066415468852

Epoch: 5| Step: 10
Training loss: 6.4528608322143555
Validation loss: 6.749762614568074

Epoch: 5| Step: 11
Training loss: 8.25114917755127
Validation loss: 6.721553603808085

Epoch: 5| Step: 0
Training loss: 6.202422142028809
Validation loss: 6.692874054114024

Epoch: 5| Step: 1
Training loss: 6.437948703765869
Validation loss: 6.655741949876149

Epoch: 5| Step: 2
Training loss: 7.740089416503906
Validation loss: 6.6257626215616865

Epoch: 5| Step: 3
Training loss: 6.332462310791016
Validation loss: 6.591344674428304

Epoch: 5| Step: 4
Training loss: 6.296830177307129
Validation loss: 6.569187641143799

Epoch: 5| Step: 5
Training loss: 6.955926418304443
Validation loss: 6.528009374936421

Epoch: 5| Step: 6
Training loss: 5.948277473449707
Validation loss: 6.487920423348744

Epoch: 5| Step: 7
Training loss: 6.984527587890625
Validation loss: 6.458964745203654

Epoch: 5| Step: 8
Training loss: 5.818832874298096
Validation loss: 6.419920285542806

Epoch: 5| Step: 9
Training loss: 7.193646430969238
Validation loss: 6.384017626444499

Epoch: 5| Step: 10
Training loss: 6.244714260101318
Validation loss: 6.352004706859589

Epoch: 5| Step: 11
Training loss: 8.218034744262695
Validation loss: 6.309986372788747

Epoch: 6| Step: 0
Training loss: 6.182027816772461
Validation loss: 6.273156364758809

Epoch: 5| Step: 1
Training loss: 6.802584171295166
Validation loss: 6.244106451670329

Epoch: 5| Step: 2
Training loss: 6.012059211730957
Validation loss: 6.202160596847534

Epoch: 5| Step: 3
Training loss: 6.459694862365723
Validation loss: 6.138188819090526

Epoch: 5| Step: 4
Training loss: 6.274033546447754
Validation loss: 6.103772819042206

Epoch: 5| Step: 5
Training loss: 6.131793975830078
Validation loss: 6.060937126477559

Epoch: 5| Step: 6
Training loss: 6.522313117980957
Validation loss: 6.028916200002034

Epoch: 5| Step: 7
Training loss: 6.358656406402588
Validation loss: 5.982490996519725

Epoch: 5| Step: 8
Training loss: 5.959948539733887
Validation loss: 5.9388405084609985

Epoch: 5| Step: 9
Training loss: 5.50681209564209
Validation loss: 5.8910767038663225

Epoch: 5| Step: 10
Training loss: 5.252100467681885
Validation loss: 5.833480139573415

Epoch: 5| Step: 11
Training loss: 5.706578254699707
Validation loss: 5.78396608432134

Epoch: 7| Step: 0
Training loss: 5.877383232116699
Validation loss: 5.736475328604381

Epoch: 5| Step: 1
Training loss: 5.965205192565918
Validation loss: 5.671289344628652

Epoch: 5| Step: 2
Training loss: 5.461771488189697
Validation loss: 5.599326411883037

Epoch: 5| Step: 3
Training loss: 5.580175876617432
Validation loss: 5.551586151123047

Epoch: 5| Step: 4
Training loss: 6.753385066986084
Validation loss: 5.5024320880572

Epoch: 5| Step: 5
Training loss: 4.876154899597168
Validation loss: 5.439473112424214

Epoch: 5| Step: 6
Training loss: 4.686972618103027
Validation loss: 5.369168043136597

Epoch: 5| Step: 7
Training loss: 5.327449798583984
Validation loss: 5.290567219257355

Epoch: 5| Step: 8
Training loss: 4.157057285308838
Validation loss: 5.197612086931865

Epoch: 5| Step: 9
Training loss: 5.439042091369629
Validation loss: 5.0991891622543335

Epoch: 5| Step: 10
Training loss: 5.748501777648926
Validation loss: 5.026372611522675

Epoch: 5| Step: 11
Training loss: 5.700291156768799
Validation loss: 4.942830165227254

Epoch: 8| Step: 0
Training loss: 5.343985557556152
Validation loss: 4.830004314581553

Epoch: 5| Step: 1
Training loss: 6.0900492668151855
Validation loss: 4.724039733409882

Epoch: 5| Step: 2
Training loss: 4.492262363433838
Validation loss: 4.644875168800354

Epoch: 5| Step: 3
Training loss: 4.91917085647583
Validation loss: 4.5163791080315905

Epoch: 5| Step: 4
Training loss: 3.966869354248047
Validation loss: 4.404083112875621

Epoch: 5| Step: 5
Training loss: 4.59424352645874
Validation loss: 4.274417956670125

Epoch: 5| Step: 6
Training loss: 4.011873722076416
Validation loss: 4.174448937177658

Epoch: 5| Step: 7
Training loss: 4.407407760620117
Validation loss: 4.028529177109401

Epoch: 5| Step: 8
Training loss: 3.148982286453247
Validation loss: 3.8897284865379333

Epoch: 5| Step: 9
Training loss: 3.696176528930664
Validation loss: 3.8017253379027047

Epoch: 5| Step: 10
Training loss: 3.028043270111084
Validation loss: 3.685547818740209

Epoch: 5| Step: 11
Training loss: 5.322729110717773
Validation loss: 3.528399775425593

Epoch: 9| Step: 0
Training loss: 3.5125179290771484
Validation loss: 3.392454872528712

Epoch: 5| Step: 1
Training loss: 2.066471815109253
Validation loss: 3.2297113140424094

Epoch: 5| Step: 2
Training loss: 3.264864444732666
Validation loss: 3.182347595691681

Epoch: 5| Step: 3
Training loss: 2.9003167152404785
Validation loss: 3.054706613222758

Epoch: 5| Step: 4
Training loss: 2.5881402492523193
Validation loss: 2.887912154197693

Epoch: 5| Step: 5
Training loss: 2.6589596271514893
Validation loss: 2.8605639338493347

Epoch: 5| Step: 6
Training loss: 2.4219272136688232
Validation loss: 2.6481484373410544

Epoch: 5| Step: 7
Training loss: 2.638471841812134
Validation loss: 2.5030700316031775

Epoch: 5| Step: 8
Training loss: 2.618147373199463
Validation loss: 2.4883655508359275

Epoch: 5| Step: 9
Training loss: 2.83420991897583
Validation loss: 2.4294172128041587

Epoch: 5| Step: 10
Training loss: 2.494955062866211
Validation loss: 2.442109316587448

Epoch: 5| Step: 11
Training loss: 2.144674777984619
Validation loss: 2.465418333808581

Epoch: 10| Step: 0
Training loss: 2.7963192462921143
Validation loss: 2.3928228865067163

Epoch: 5| Step: 1
Training loss: 2.296316146850586
Validation loss: 2.3669334848721824

Epoch: 5| Step: 2
Training loss: 1.93912672996521
Validation loss: 2.4258598486582437

Epoch: 5| Step: 3
Training loss: 2.070782423019409
Validation loss: 2.39251779516538

Epoch: 5| Step: 4
Training loss: 2.5160434246063232
Validation loss: 2.4447820683320365

Epoch: 5| Step: 5
Training loss: 1.8861585855484009
Validation loss: 2.3778975208600364

Epoch: 5| Step: 6
Training loss: 2.2535219192504883
Validation loss: 2.3916987230380378

Epoch: 5| Step: 7
Training loss: 3.174506187438965
Validation loss: 2.5308572749296823

Epoch: 5| Step: 8
Training loss: 2.0874104499816895
Validation loss: 2.4365669041872025

Epoch: 5| Step: 9
Training loss: 3.3452887535095215
Validation loss: 2.4729228715101876

Epoch: 5| Step: 10
Training loss: 2.371058464050293
Validation loss: 2.3668894122044244

Epoch: 5| Step: 11
Training loss: 4.195898056030273
Validation loss: 2.373542288939158

Epoch: 11| Step: 0
Training loss: 2.3653407096862793
Validation loss: 2.368651866912842

Epoch: 5| Step: 1
Training loss: 2.4230945110321045
Validation loss: 2.3202341298262277

Epoch: 5| Step: 2
Training loss: 2.400503635406494
Validation loss: 2.321556329727173

Epoch: 5| Step: 3
Training loss: 2.249828815460205
Validation loss: 2.3375666439533234

Epoch: 5| Step: 4
Training loss: 2.2758238315582275
Validation loss: 2.3795921405156455

Epoch: 5| Step: 5
Training loss: 2.3868813514709473
Validation loss: 2.460647930701574

Epoch: 5| Step: 6
Training loss: 3.2070019245147705
Validation loss: 2.50076894958814

Epoch: 5| Step: 7
Training loss: 2.4627718925476074
Validation loss: 2.492120752731959

Epoch: 5| Step: 8
Training loss: 3.094935178756714
Validation loss: 2.518731027841568

Epoch: 5| Step: 9
Training loss: 2.914454698562622
Validation loss: 2.541482925415039

Epoch: 5| Step: 10
Training loss: 1.71161687374115
Validation loss: 2.426498124996821

Epoch: 5| Step: 11
Training loss: 2.3396449089050293
Validation loss: 2.415466378132502

Epoch: 12| Step: 0
Training loss: 1.8448768854141235
Validation loss: 2.3543331921100616

Epoch: 5| Step: 1
Training loss: 2.233088970184326
Validation loss: 2.3626332779725394

Epoch: 5| Step: 2
Training loss: 3.05460262298584
Validation loss: 2.2560608883698783

Epoch: 5| Step: 3
Training loss: 2.013556957244873
Validation loss: 2.3728921711444855

Epoch: 5| Step: 4
Training loss: 1.869002342224121
Validation loss: 2.2600614726543427

Epoch: 5| Step: 5
Training loss: 2.260666847229004
Validation loss: 2.385204861561457

Epoch: 5| Step: 6
Training loss: 1.711281180381775
Validation loss: 2.31284399330616

Epoch: 5| Step: 7
Training loss: 2.675828456878662
Validation loss: 2.345677192012469

Epoch: 5| Step: 8
Training loss: 2.3549296855926514
Validation loss: 2.27884508172671

Epoch: 5| Step: 9
Training loss: 1.8290475606918335
Validation loss: 2.3138695855935416

Epoch: 5| Step: 10
Training loss: 2.6747710704803467
Validation loss: 2.2667690018812814

Epoch: 5| Step: 11
Training loss: 3.247699499130249
Validation loss: 2.2374683221181235

Epoch: 13| Step: 0
Training loss: 1.818672776222229
Validation loss: 2.2572054266929626

Epoch: 5| Step: 1
Training loss: 1.9695637226104736
Validation loss: 2.3043794333934784

Epoch: 5| Step: 2
Training loss: 2.1447043418884277
Validation loss: 2.2538261910279593

Epoch: 5| Step: 3
Training loss: 2.8019042015075684
Validation loss: 2.3921861747900643

Epoch: 5| Step: 4
Training loss: 3.006275177001953
Validation loss: 2.3291968504587808

Epoch: 5| Step: 5
Training loss: 2.7889866828918457
Validation loss: 2.406310796737671

Epoch: 5| Step: 6
Training loss: 2.0047378540039062
Validation loss: 2.299945111076037

Epoch: 5| Step: 7
Training loss: 2.4068729877471924
Validation loss: 2.3974331518014274

Epoch: 5| Step: 8
Training loss: 2.11201548576355
Validation loss: 2.3046514987945557

Epoch: 5| Step: 9
Training loss: 2.266895055770874
Validation loss: 2.3632489889860153

Epoch: 5| Step: 10
Training loss: 1.9861160516738892
Validation loss: 2.3581910133361816

Epoch: 5| Step: 11
Training loss: 3.865832805633545
Validation loss: 2.330916961034139

Epoch: 14| Step: 0
Training loss: 2.4935975074768066
Validation loss: 2.2879542062679925

Epoch: 5| Step: 1
Training loss: 2.7335143089294434
Validation loss: 2.317615588506063

Epoch: 5| Step: 2
Training loss: 1.6816095113754272
Validation loss: 2.364100913206736

Epoch: 5| Step: 3
Training loss: 1.507807731628418
Validation loss: 2.2842940390110016

Epoch: 5| Step: 4
Training loss: 2.3349196910858154
Validation loss: 2.3031004865964255

Epoch: 5| Step: 5
Training loss: 2.7498764991760254
Validation loss: 2.304812103509903

Epoch: 5| Step: 6
Training loss: 3.1338024139404297
Validation loss: 2.3725500404834747

Epoch: 5| Step: 7
Training loss: 2.2419939041137695
Validation loss: 2.2932768861452737

Epoch: 5| Step: 8
Training loss: 1.7789764404296875
Validation loss: 2.287946472565333

Epoch: 5| Step: 9
Training loss: 2.0432910919189453
Validation loss: 2.2217289060354233

Epoch: 5| Step: 10
Training loss: 1.9211755990982056
Validation loss: 2.2481906910737357

Epoch: 5| Step: 11
Training loss: 4.267665863037109
Validation loss: 2.380915492773056

Epoch: 15| Step: 0
Training loss: 2.872851848602295
Validation loss: 2.1653699576854706

Epoch: 5| Step: 1
Training loss: 2.0625462532043457
Validation loss: 2.301784574985504

Epoch: 5| Step: 2
Training loss: 1.8592922687530518
Validation loss: 2.395740975936254

Epoch: 5| Step: 3
Training loss: 2.7633216381073
Validation loss: 2.211620251337687

Epoch: 5| Step: 4
Training loss: 1.7868156433105469
Validation loss: 2.2002292374769845

Epoch: 5| Step: 5
Training loss: 2.356473684310913
Validation loss: 2.32795050740242

Epoch: 5| Step: 6
Training loss: 2.1498939990997314
Validation loss: 2.2654004842042923

Epoch: 5| Step: 7
Training loss: 2.4640936851501465
Validation loss: 2.2539418985446296

Epoch: 5| Step: 8
Training loss: 2.169926166534424
Validation loss: 2.3098152925570807

Epoch: 5| Step: 9
Training loss: 2.600747585296631
Validation loss: 2.2893405656019845

Epoch: 5| Step: 10
Training loss: 2.2999191284179688
Validation loss: 2.2699350913365683

Epoch: 5| Step: 11
Training loss: 2.4520010948181152
Validation loss: 2.3148927092552185

Epoch: 16| Step: 0
Training loss: 2.1051840782165527
Validation loss: 2.260431468486786

Epoch: 5| Step: 1
Training loss: 2.369140148162842
Validation loss: 2.370416074991226

Epoch: 5| Step: 2
Training loss: 2.249051570892334
Validation loss: 2.3049243489901223

Epoch: 5| Step: 3
Training loss: 3.024400472640991
Validation loss: 2.2743052691221237

Epoch: 5| Step: 4
Training loss: 2.1417627334594727
Validation loss: 2.34328830242157

Epoch: 5| Step: 5
Training loss: 2.3728199005126953
Validation loss: 2.289253681898117

Epoch: 5| Step: 6
Training loss: 1.8654788732528687
Validation loss: 2.3149395187695823

Epoch: 5| Step: 7
Training loss: 2.1859283447265625
Validation loss: 2.344939738512039

Epoch: 5| Step: 8
Training loss: 1.7080409526824951
Validation loss: 2.2802698016166687

Epoch: 5| Step: 9
Training loss: 2.773953914642334
Validation loss: 2.223257899284363

Epoch: 5| Step: 10
Training loss: 2.5942025184631348
Validation loss: 2.301320811112722

Epoch: 5| Step: 11
Training loss: 2.913379669189453
Validation loss: 2.3031027764081955

Epoch: 17| Step: 0
Training loss: 2.195213794708252
Validation loss: 2.3013391395409903

Epoch: 5| Step: 1
Training loss: 2.552534580230713
Validation loss: 2.2838317503531775

Epoch: 5| Step: 2
Training loss: 1.6123965978622437
Validation loss: 2.2784937421480813

Epoch: 5| Step: 3
Training loss: 2.199791669845581
Validation loss: 2.257856637239456

Epoch: 5| Step: 4
Training loss: 2.656445026397705
Validation loss: 2.2930874675512314

Epoch: 5| Step: 5
Training loss: 2.458199977874756
Validation loss: 2.208335186044375

Epoch: 5| Step: 6
Training loss: 2.6107177734375
Validation loss: 2.28391266365846

Epoch: 5| Step: 7
Training loss: 1.7247062921524048
Validation loss: 2.317103698849678

Epoch: 5| Step: 8
Training loss: 2.4893386363983154
Validation loss: 2.2276279429594674

Epoch: 5| Step: 9
Training loss: 2.3162646293640137
Validation loss: 2.266531447569529

Epoch: 5| Step: 10
Training loss: 2.059534788131714
Validation loss: 2.2621698677539825

Epoch: 5| Step: 11
Training loss: 2.4540278911590576
Validation loss: 2.265844697753588

Epoch: 18| Step: 0
Training loss: 2.533888816833496
Validation loss: 2.2657766739527383

Epoch: 5| Step: 1
Training loss: 1.7656173706054688
Validation loss: 2.2230028063058853

Epoch: 5| Step: 2
Training loss: 1.9364573955535889
Validation loss: 2.2646143635114035

Epoch: 5| Step: 3
Training loss: 2.4093017578125
Validation loss: 2.261009067296982

Epoch: 5| Step: 4
Training loss: 2.868398904800415
Validation loss: 2.335564081867536

Epoch: 5| Step: 5
Training loss: 1.9922573566436768
Validation loss: 2.3170862048864365

Epoch: 5| Step: 6
Training loss: 1.8505306243896484
Validation loss: 2.312151074409485

Epoch: 5| Step: 7
Training loss: 2.245469570159912
Validation loss: 2.3504478534062705

Epoch: 5| Step: 8
Training loss: 2.315342664718628
Validation loss: 2.3680300613244376

Epoch: 5| Step: 9
Training loss: 2.30055570602417
Validation loss: 2.3353768388430276

Epoch: 5| Step: 10
Training loss: 2.9089298248291016
Validation loss: 2.318846359848976

Epoch: 5| Step: 11
Training loss: 3.097805976867676
Validation loss: 2.2631847063700357

Epoch: 19| Step: 0
Training loss: 1.983934998512268
Validation loss: 2.2686424950758615

Epoch: 5| Step: 1
Training loss: 2.438742160797119
Validation loss: 2.292876034975052

Epoch: 5| Step: 2
Training loss: 1.8682037591934204
Validation loss: 2.31734029452006

Epoch: 5| Step: 3
Training loss: 2.382652759552002
Validation loss: 2.307658831278483

Epoch: 5| Step: 4
Training loss: 1.8612638711929321
Validation loss: 2.2747546384731927

Epoch: 5| Step: 5
Training loss: 1.8842799663543701
Validation loss: 2.2007780174414315

Epoch: 5| Step: 6
Training loss: 2.6253275871276855
Validation loss: 2.285924737652143

Epoch: 5| Step: 7
Training loss: 2.7044453620910645
Validation loss: 2.174713412920634

Epoch: 5| Step: 8
Training loss: 2.2754111289978027
Validation loss: 2.2810835043589273

Epoch: 5| Step: 9
Training loss: 2.508100986480713
Validation loss: 2.3257353802522025

Epoch: 5| Step: 10
Training loss: 2.818782091140747
Validation loss: 2.321244557698568

Epoch: 5| Step: 11
Training loss: 2.5844509601593018
Validation loss: 2.166534721851349

Epoch: 20| Step: 0
Training loss: 2.2778632640838623
Validation loss: 2.208969220519066

Epoch: 5| Step: 1
Training loss: 2.0286412239074707
Validation loss: 2.287221312522888

Epoch: 5| Step: 2
Training loss: 1.8032954931259155
Validation loss: 2.2190454502900443

Epoch: 5| Step: 3
Training loss: 1.8101571798324585
Validation loss: 2.1720104813575745

Epoch: 5| Step: 4
Training loss: 2.612236499786377
Validation loss: 2.2367411802212396

Epoch: 5| Step: 5
Training loss: 2.243657350540161
Validation loss: 2.2060699959596

Epoch: 5| Step: 6
Training loss: 2.1250202655792236
Validation loss: 2.1899152795473733

Epoch: 5| Step: 7
Training loss: 2.733768939971924
Validation loss: 2.2580295453468957

Epoch: 5| Step: 8
Training loss: 2.2652058601379395
Validation loss: 2.2726313223441443

Epoch: 5| Step: 9
Training loss: 2.259575366973877
Validation loss: 2.2480881611506143

Epoch: 5| Step: 10
Training loss: 2.3493523597717285
Validation loss: 2.166633332769076

Epoch: 5| Step: 11
Training loss: 1.1538509130477905
Validation loss: 2.270473832885424

Epoch: 21| Step: 0
Training loss: 2.6823182106018066
Validation loss: 2.239436293641726

Epoch: 5| Step: 1
Training loss: 2.6551456451416016
Validation loss: 2.322738433877627

Epoch: 5| Step: 2
Training loss: 2.2531285285949707
Validation loss: 2.2571604549884796

Epoch: 5| Step: 3
Training loss: 2.049867868423462
Validation loss: 2.29793914159139

Epoch: 5| Step: 4
Training loss: 1.6848758459091187
Validation loss: 2.2180508573849997

Epoch: 5| Step: 5
Training loss: 1.736669898033142
Validation loss: 2.3291498919328055

Epoch: 5| Step: 6
Training loss: 2.068246841430664
Validation loss: 2.308145374059677

Epoch: 5| Step: 7
Training loss: 2.493628978729248
Validation loss: 2.244847595691681

Epoch: 5| Step: 8
Training loss: 3.0739822387695312
Validation loss: 2.317488729953766

Epoch: 5| Step: 9
Training loss: 2.189805507659912
Validation loss: 2.2707868218421936

Epoch: 5| Step: 10
Training loss: 1.6757997274398804
Validation loss: 2.2723342974980674

Epoch: 5| Step: 11
Training loss: 1.808286190032959
Validation loss: 2.255744864543279

Epoch: 22| Step: 0
Training loss: 1.8469263315200806
Validation loss: 2.209376484155655

Epoch: 5| Step: 1
Training loss: 2.5193824768066406
Validation loss: 2.2527699073155723

Epoch: 5| Step: 2
Training loss: 2.1697912216186523
Validation loss: 2.215390702088674

Epoch: 5| Step: 3
Training loss: 2.7884316444396973
Validation loss: 2.221283569931984

Epoch: 5| Step: 4
Training loss: 2.7280831336975098
Validation loss: 2.2414452830950418

Epoch: 5| Step: 5
Training loss: 2.2207438945770264
Validation loss: 2.149127329389254

Epoch: 5| Step: 6
Training loss: 2.078019380569458
Validation loss: 2.2315765569607415

Epoch: 5| Step: 7
Training loss: 2.073103427886963
Validation loss: 2.225923458735148

Epoch: 5| Step: 8
Training loss: 1.6274080276489258
Validation loss: 2.2633367677529654

Epoch: 5| Step: 9
Training loss: 1.7434520721435547
Validation loss: 2.1715727945168815

Epoch: 5| Step: 10
Training loss: 2.480936050415039
Validation loss: 2.217679580052694

Epoch: 5| Step: 11
Training loss: 3.4536213874816895
Validation loss: 2.1917077600955963

Epoch: 23| Step: 0
Training loss: 2.3471648693084717
Validation loss: 2.160492315888405

Epoch: 5| Step: 1
Training loss: 1.7517343759536743
Validation loss: 2.1919317841529846

Epoch: 5| Step: 2
Training loss: 2.1999711990356445
Validation loss: 2.242398257056872

Epoch: 5| Step: 3
Training loss: 1.9565365314483643
Validation loss: 2.257394547263781

Epoch: 5| Step: 4
Training loss: 2.6674888134002686
Validation loss: 2.2960472851991653

Epoch: 5| Step: 5
Training loss: 2.0816664695739746
Validation loss: 2.203054666519165

Epoch: 5| Step: 6
Training loss: 1.9691263437271118
Validation loss: 2.221418743332227

Epoch: 5| Step: 7
Training loss: 2.2916793823242188
Validation loss: 2.26180370648702

Epoch: 5| Step: 8
Training loss: 2.1969387531280518
Validation loss: 2.227984751264254

Epoch: 5| Step: 9
Training loss: 2.5832271575927734
Validation loss: 2.237399180730184

Epoch: 5| Step: 10
Training loss: 2.194251537322998
Validation loss: 2.1968356668949127

Epoch: 5| Step: 11
Training loss: 2.125842332839966
Validation loss: 2.186848446726799

Epoch: 24| Step: 0
Training loss: 2.8612210750579834
Validation loss: 2.22346060971419

Epoch: 5| Step: 1
Training loss: 2.2846570014953613
Validation loss: 2.261478846271833

Epoch: 5| Step: 2
Training loss: 1.565740704536438
Validation loss: 2.2791209469238916

Epoch: 5| Step: 3
Training loss: 2.2847721576690674
Validation loss: 2.2742684533198676

Epoch: 5| Step: 4
Training loss: 2.044637680053711
Validation loss: 2.235912655790647

Epoch: 5| Step: 5
Training loss: 2.3655953407287598
Validation loss: 2.234456797440847

Epoch: 5| Step: 6
Training loss: 2.2458858489990234
Validation loss: 2.1943611900011697

Epoch: 5| Step: 7
Training loss: 2.8447139263153076
Validation loss: 2.200732931494713

Epoch: 5| Step: 8
Training loss: 2.235656261444092
Validation loss: 2.205014556646347

Epoch: 5| Step: 9
Training loss: 1.8799949884414673
Validation loss: 2.2445518473784127

Epoch: 5| Step: 10
Training loss: 1.8591063022613525
Validation loss: 2.1854398399591446

Epoch: 5| Step: 11
Training loss: 1.0830354690551758
Validation loss: 2.222230166196823

Epoch: 25| Step: 0
Training loss: 2.8848824501037598
Validation loss: 2.2183827261130014

Epoch: 5| Step: 1
Training loss: 1.276989221572876
Validation loss: 2.210522308945656

Epoch: 5| Step: 2
Training loss: 2.0339431762695312
Validation loss: 2.2229401717583337

Epoch: 5| Step: 3
Training loss: 1.853295922279358
Validation loss: 2.17554580171903

Epoch: 5| Step: 4
Training loss: 3.05983829498291
Validation loss: 2.241286799311638

Epoch: 5| Step: 5
Training loss: 2.455756664276123
Validation loss: 2.22108988960584

Epoch: 5| Step: 6
Training loss: 3.043600559234619
Validation loss: 2.267420490582784

Epoch: 5| Step: 7
Training loss: 1.6116325855255127
Validation loss: 2.2112721304098764

Epoch: 5| Step: 8
Training loss: 2.33378529548645
Validation loss: 2.1349476973215737

Epoch: 5| Step: 9
Training loss: 1.9041496515274048
Validation loss: 2.2035176108280816

Epoch: 5| Step: 10
Training loss: 2.04193115234375
Validation loss: 2.2037943998972573

Epoch: 5| Step: 11
Training loss: 1.4281364679336548
Validation loss: 2.196242089072863

Epoch: 26| Step: 0
Training loss: 2.4005942344665527
Validation loss: 2.2039088358481727

Epoch: 5| Step: 1
Training loss: 2.494046688079834
Validation loss: 2.1941807667414346

Epoch: 5| Step: 2
Training loss: 2.2434849739074707
Validation loss: 2.212720359365145

Epoch: 5| Step: 3
Training loss: 2.0151782035827637
Validation loss: 2.2252408464749656

Epoch: 5| Step: 4
Training loss: 2.1178269386291504
Validation loss: 2.2314352790514627

Epoch: 5| Step: 5
Training loss: 1.9239110946655273
Validation loss: 2.2166657199462256

Epoch: 5| Step: 6
Training loss: 2.0588173866271973
Validation loss: 2.1055101652940116

Epoch: 5| Step: 7
Training loss: 1.7405153512954712
Validation loss: 2.237314502398173

Epoch: 5| Step: 8
Training loss: 2.601848840713501
Validation loss: 2.222344249486923

Epoch: 5| Step: 9
Training loss: 1.9728533029556274
Validation loss: 2.2053817212581635

Epoch: 5| Step: 10
Training loss: 2.180800676345825
Validation loss: 2.1480157673358917

Epoch: 5| Step: 11
Training loss: 2.294870615005493
Validation loss: 2.117680033047994

Epoch: 27| Step: 0
Training loss: 1.7219693660736084
Validation loss: 2.265554373462995

Epoch: 5| Step: 1
Training loss: 2.5421242713928223
Validation loss: 2.163508653640747

Epoch: 5| Step: 2
Training loss: 1.997265100479126
Validation loss: 2.2167310317357383

Epoch: 5| Step: 3
Training loss: 2.5617477893829346
Validation loss: 2.1472959568103156

Epoch: 5| Step: 4
Training loss: 1.9338347911834717
Validation loss: 2.186133394638697

Epoch: 5| Step: 5
Training loss: 2.1585164070129395
Validation loss: 2.1918585846821466

Epoch: 5| Step: 6
Training loss: 2.8046677112579346
Validation loss: 2.1659203867117562

Epoch: 5| Step: 7
Training loss: 2.4137215614318848
Validation loss: 2.1839118202527366

Epoch: 5| Step: 8
Training loss: 2.2990987300872803
Validation loss: 2.209787741303444

Epoch: 5| Step: 9
Training loss: 1.5587356090545654
Validation loss: 2.214458261926969

Epoch: 5| Step: 10
Training loss: 1.9921443462371826
Validation loss: 2.284221798181534

Epoch: 5| Step: 11
Training loss: 4.360108375549316
Validation loss: 2.1655791451533637

Epoch: 28| Step: 0
Training loss: 2.1089277267456055
Validation loss: 2.241158902645111

Epoch: 5| Step: 1
Training loss: 1.745995283126831
Validation loss: 2.1743875046571097

Epoch: 5| Step: 2
Training loss: 2.440995693206787
Validation loss: 2.2088529467582703

Epoch: 5| Step: 3
Training loss: 2.2204132080078125
Validation loss: 2.1442959855000177

Epoch: 5| Step: 4
Training loss: 2.260584592819214
Validation loss: 2.1348294069369635

Epoch: 5| Step: 5
Training loss: 1.6849727630615234
Validation loss: 2.1449300944805145

Epoch: 5| Step: 6
Training loss: 2.0536341667175293
Validation loss: 2.184706454475721

Epoch: 5| Step: 7
Training loss: 2.4988701343536377
Validation loss: 2.118083248535792

Epoch: 5| Step: 8
Training loss: 1.9876266717910767
Validation loss: 2.1729311645030975

Epoch: 5| Step: 9
Training loss: 2.7235372066497803
Validation loss: 2.207393065094948

Epoch: 5| Step: 10
Training loss: 2.499696731567383
Validation loss: 2.201877772808075

Epoch: 5| Step: 11
Training loss: 0.6796255111694336
Validation loss: 2.17452572286129

Epoch: 29| Step: 0
Training loss: 2.3583195209503174
Validation loss: 2.2393088042736053

Epoch: 5| Step: 1
Training loss: 2.2236647605895996
Validation loss: 2.2523454427719116

Epoch: 5| Step: 2
Training loss: 1.9161583185195923
Validation loss: 2.2762841482957206

Epoch: 5| Step: 3
Training loss: 2.051593542098999
Validation loss: 2.1804789503415427

Epoch: 5| Step: 4
Training loss: 2.3983356952667236
Validation loss: 2.192717730998993

Epoch: 5| Step: 5
Training loss: 2.070970296859741
Validation loss: 2.162028988202413

Epoch: 5| Step: 6
Training loss: 2.533695936203003
Validation loss: 2.260783006747564

Epoch: 5| Step: 7
Training loss: 1.6463979482650757
Validation loss: 2.170402412613233

Epoch: 5| Step: 8
Training loss: 2.112208604812622
Validation loss: 2.2121747881174088

Epoch: 5| Step: 9
Training loss: 2.408186435699463
Validation loss: 2.2117957274119058

Epoch: 5| Step: 10
Training loss: 1.7017269134521484
Validation loss: 2.2201239615678787

Epoch: 5| Step: 11
Training loss: 2.851914405822754
Validation loss: 2.1406984676917395

Epoch: 30| Step: 0
Training loss: 2.020803689956665
Validation loss: 2.067819500962893

Epoch: 5| Step: 1
Training loss: 2.7231478691101074
Validation loss: 2.177365928888321

Epoch: 5| Step: 2
Training loss: 2.260068655014038
Validation loss: 2.1767815401156745

Epoch: 5| Step: 3
Training loss: 1.9219610691070557
Validation loss: 2.1434640089670816

Epoch: 5| Step: 4
Training loss: 1.9192901849746704
Validation loss: 2.1694135665893555

Epoch: 5| Step: 5
Training loss: 2.2734994888305664
Validation loss: 2.1797884851694107

Epoch: 5| Step: 6
Training loss: 2.0667550563812256
Validation loss: 2.187447249889374

Epoch: 5| Step: 7
Training loss: 2.0290474891662598
Validation loss: 2.1291069984436035

Epoch: 5| Step: 8
Training loss: 2.687741994857788
Validation loss: 2.169270450870196

Epoch: 5| Step: 9
Training loss: 2.0849030017852783
Validation loss: 2.187300687034925

Epoch: 5| Step: 10
Training loss: 2.008293867111206
Validation loss: 2.2115157643953958

Epoch: 5| Step: 11
Training loss: 0.7935165166854858
Validation loss: 2.1833938509225845

Epoch: 31| Step: 0
Training loss: 2.5559988021850586
Validation loss: 2.133767381310463

Epoch: 5| Step: 1
Training loss: 1.8971471786499023
Validation loss: 2.2870994806289673

Epoch: 5| Step: 2
Training loss: 2.170687198638916
Validation loss: 2.0838319112857184

Epoch: 5| Step: 3
Training loss: 1.9298652410507202
Validation loss: 2.152357300122579

Epoch: 5| Step: 4
Training loss: 2.8316097259521484
Validation loss: 2.22494283815225

Epoch: 5| Step: 5
Training loss: 2.4005000591278076
Validation loss: 2.1898417373498282

Epoch: 5| Step: 6
Training loss: 1.77682363986969
Validation loss: 2.223812853296598

Epoch: 5| Step: 7
Training loss: 1.890242576599121
Validation loss: 2.2189557204643884

Epoch: 5| Step: 8
Training loss: 2.2799813747406006
Validation loss: 2.131026178598404

Epoch: 5| Step: 9
Training loss: 2.0895514488220215
Validation loss: 2.1962451338768005

Epoch: 5| Step: 10
Training loss: 1.639618158340454
Validation loss: 2.170334219932556

Epoch: 5| Step: 11
Training loss: 1.9600849151611328
Validation loss: 2.2019563615322113

Epoch: 32| Step: 0
Training loss: 2.0264222621917725
Validation loss: 2.166805018981298

Epoch: 5| Step: 1
Training loss: 1.5147895812988281
Validation loss: 2.104474425315857

Epoch: 5| Step: 2
Training loss: 2.4224464893341064
Validation loss: 2.158838152885437

Epoch: 5| Step: 3
Training loss: 1.6978733539581299
Validation loss: 2.2176752388477325

Epoch: 5| Step: 4
Training loss: 2.324779987335205
Validation loss: 2.1683238993088403

Epoch: 5| Step: 5
Training loss: 2.1069092750549316
Validation loss: 2.177648365497589

Epoch: 5| Step: 6
Training loss: 2.259661912918091
Validation loss: 2.2203344802061715

Epoch: 5| Step: 7
Training loss: 1.9281775951385498
Validation loss: 2.2129505574703217

Epoch: 5| Step: 8
Training loss: 1.9840896129608154
Validation loss: 2.1796693404515586

Epoch: 5| Step: 9
Training loss: 2.8613154888153076
Validation loss: 2.1783473988374076

Epoch: 5| Step: 10
Training loss: 2.0579092502593994
Validation loss: 2.172247509161631

Epoch: 5| Step: 11
Training loss: 3.2754173278808594
Validation loss: 2.237899581591288

Epoch: 33| Step: 0
Training loss: 2.124727725982666
Validation loss: 2.1348737676938376

Epoch: 5| Step: 1
Training loss: 1.6044318675994873
Validation loss: 2.1680393864711127

Epoch: 5| Step: 2
Training loss: 2.088334798812866
Validation loss: 2.096221203605334

Epoch: 5| Step: 3
Training loss: 2.0635488033294678
Validation loss: 2.2041788399219513

Epoch: 5| Step: 4
Training loss: 2.6625308990478516
Validation loss: 2.115671237309774

Epoch: 5| Step: 5
Training loss: 2.7039387226104736
Validation loss: 2.265796090165774

Epoch: 5| Step: 6
Training loss: 1.9432376623153687
Validation loss: 2.1954132318496704

Epoch: 5| Step: 7
Training loss: 1.5718390941619873
Validation loss: 2.1268443763256073

Epoch: 5| Step: 8
Training loss: 2.413630962371826
Validation loss: 2.2314567069212594

Epoch: 5| Step: 9
Training loss: 2.384958267211914
Validation loss: 2.1777618676424026

Epoch: 5| Step: 10
Training loss: 1.8968493938446045
Validation loss: 2.1558397064606347

Epoch: 5| Step: 11
Training loss: 1.0160815715789795
Validation loss: 2.0912730346123376

Epoch: 34| Step: 0
Training loss: 2.272505283355713
Validation loss: 2.1257991890112558

Epoch: 5| Step: 1
Training loss: 2.403087615966797
Validation loss: 2.164783621827761

Epoch: 5| Step: 2
Training loss: 1.994227409362793
Validation loss: 2.1987597346305847

Epoch: 5| Step: 3
Training loss: 2.1780054569244385
Validation loss: 2.135842114686966

Epoch: 5| Step: 4
Training loss: 1.9712820053100586
Validation loss: 2.1291685154040656

Epoch: 5| Step: 5
Training loss: 2.1628875732421875
Validation loss: 2.17295278608799

Epoch: 5| Step: 6
Training loss: 2.50254487991333
Validation loss: 2.124108135700226

Epoch: 5| Step: 7
Training loss: 2.0857386589050293
Validation loss: 2.1743202904860177

Epoch: 5| Step: 8
Training loss: 1.7337554693222046
Validation loss: 2.1250954965750375

Epoch: 5| Step: 9
Training loss: 2.0893168449401855
Validation loss: 2.1523165553808212

Epoch: 5| Step: 10
Training loss: 2.0220425128936768
Validation loss: 2.126373444994291

Epoch: 5| Step: 11
Training loss: 2.6092419624328613
Validation loss: 2.157782793045044

Epoch: 35| Step: 0
Training loss: 1.9851264953613281
Validation loss: 2.2306038985649743

Epoch: 5| Step: 1
Training loss: 2.3226704597473145
Validation loss: 2.1491841077804565

Epoch: 5| Step: 2
Training loss: 1.6970674991607666
Validation loss: 2.1169704298178353

Epoch: 5| Step: 3
Training loss: 2.410430669784546
Validation loss: 2.101087917884191

Epoch: 5| Step: 4
Training loss: 2.130146026611328
Validation loss: 2.2178659786780677

Epoch: 5| Step: 5
Training loss: 1.712829828262329
Validation loss: 2.09253391623497

Epoch: 5| Step: 6
Training loss: 1.9100854396820068
Validation loss: 2.1395386308431625

Epoch: 5| Step: 7
Training loss: 2.068946123123169
Validation loss: 2.147763818502426

Epoch: 5| Step: 8
Training loss: 2.292233943939209
Validation loss: 2.091724460323652

Epoch: 5| Step: 9
Training loss: 2.4153494834899902
Validation loss: 2.262204279502233

Epoch: 5| Step: 10
Training loss: 2.179614782333374
Validation loss: 2.0770285427570343

Epoch: 5| Step: 11
Training loss: 2.2733559608459473
Validation loss: 2.1271372189124427

Epoch: 36| Step: 0
Training loss: 2.3270039558410645
Validation loss: 2.307950804630915

Epoch: 5| Step: 1
Training loss: 2.329319477081299
Validation loss: 2.115502913792928

Epoch: 5| Step: 2
Training loss: 2.4303722381591797
Validation loss: 2.1689896484216056

Epoch: 5| Step: 3
Training loss: 2.323479413986206
Validation loss: 2.130127007762591

Epoch: 5| Step: 4
Training loss: 2.5411460399627686
Validation loss: 2.1449826757113137

Epoch: 5| Step: 5
Training loss: 1.9737011194229126
Validation loss: 2.1621298789978027

Epoch: 5| Step: 6
Training loss: 2.0727040767669678
Validation loss: 2.1290769229332605

Epoch: 5| Step: 7
Training loss: 2.228429079055786
Validation loss: 2.2124656041463218

Epoch: 5| Step: 8
Training loss: 1.929060935974121
Validation loss: 2.1182834059000015

Epoch: 5| Step: 9
Training loss: 1.5782920122146606
Validation loss: 2.173047954837481

Epoch: 5| Step: 10
Training loss: 1.6163638830184937
Validation loss: 2.1332684655984244

Epoch: 5| Step: 11
Training loss: 1.7597439289093018
Validation loss: 2.230211148659388

Epoch: 37| Step: 0
Training loss: 2.240002393722534
Validation loss: 2.1163184195756912

Epoch: 5| Step: 1
Training loss: 2.4880013465881348
Validation loss: 2.2007214526335397

Epoch: 5| Step: 2
Training loss: 1.928375244140625
Validation loss: 2.210097759962082

Epoch: 5| Step: 3
Training loss: 2.063066005706787
Validation loss: 2.1648860623439155

Epoch: 5| Step: 4
Training loss: 2.004092216491699
Validation loss: 2.114468807975451

Epoch: 5| Step: 5
Training loss: 2.605259418487549
Validation loss: 2.2248081117868423

Epoch: 5| Step: 6
Training loss: 1.6427885293960571
Validation loss: 2.1775315552949905

Epoch: 5| Step: 7
Training loss: 2.081726551055908
Validation loss: 2.2106307496627173

Epoch: 5| Step: 8
Training loss: 1.7924970388412476
Validation loss: 2.239249830444654

Epoch: 5| Step: 9
Training loss: 2.373778820037842
Validation loss: 2.222940961519877

Epoch: 5| Step: 10
Training loss: 1.9413566589355469
Validation loss: 2.1274666438500085

Epoch: 5| Step: 11
Training loss: 2.333282470703125
Validation loss: 2.169964780410131

Epoch: 38| Step: 0
Training loss: 2.170896530151367
Validation loss: 2.2233957846959433

Epoch: 5| Step: 1
Training loss: 2.090967893600464
Validation loss: 2.1084900548060737

Epoch: 5| Step: 2
Training loss: 2.3330001831054688
Validation loss: 2.235281929373741

Epoch: 5| Step: 3
Training loss: 2.1584811210632324
Validation loss: 2.1617300609747567

Epoch: 5| Step: 4
Training loss: 1.976212501525879
Validation loss: 2.170892834663391

Epoch: 5| Step: 5
Training loss: 2.173078775405884
Validation loss: 2.199015498161316

Epoch: 5| Step: 6
Training loss: 2.860983371734619
Validation loss: 2.204750974973043

Epoch: 5| Step: 7
Training loss: 1.9029629230499268
Validation loss: 2.195844292640686

Epoch: 5| Step: 8
Training loss: 2.4537322521209717
Validation loss: 2.1401300032933555

Epoch: 5| Step: 9
Training loss: 1.6900908946990967
Validation loss: 2.160519684354464

Epoch: 5| Step: 10
Training loss: 1.9920583963394165
Validation loss: 2.2190208385388055

Epoch: 5| Step: 11
Training loss: 2.4462482929229736
Validation loss: 2.185621907313665

Epoch: 39| Step: 0
Training loss: 1.9480937719345093
Validation loss: 2.1188058654467263

Epoch: 5| Step: 1
Training loss: 2.491842269897461
Validation loss: 2.1483943462371826

Epoch: 5| Step: 2
Training loss: 1.7622572183609009
Validation loss: 2.163958966732025

Epoch: 5| Step: 3
Training loss: 2.244018077850342
Validation loss: 2.234405055642128

Epoch: 5| Step: 4
Training loss: 1.506133794784546
Validation loss: 2.1680708080530167

Epoch: 5| Step: 5
Training loss: 1.9012298583984375
Validation loss: 2.132940798997879

Epoch: 5| Step: 6
Training loss: 1.9629262685775757
Validation loss: 2.117013692855835

Epoch: 5| Step: 7
Training loss: 1.5792443752288818
Validation loss: 2.2261822720368705

Epoch: 5| Step: 8
Training loss: 2.976868152618408
Validation loss: 2.207675645748774

Epoch: 5| Step: 9
Training loss: 1.9074863195419312
Validation loss: 2.1916148960590363

Epoch: 5| Step: 10
Training loss: 2.5665125846862793
Validation loss: 2.1067425906658173

Epoch: 5| Step: 11
Training loss: 2.6676177978515625
Validation loss: 2.1251490960518518

Epoch: 40| Step: 0
Training loss: 1.975589394569397
Validation loss: 2.214236944913864

Epoch: 5| Step: 1
Training loss: 1.9644155502319336
Validation loss: 2.1420090049505234

Epoch: 5| Step: 2
Training loss: 2.532759428024292
Validation loss: 2.1255900512139

Epoch: 5| Step: 3
Training loss: 1.7682554721832275
Validation loss: 2.125892529884974

Epoch: 5| Step: 4
Training loss: 1.4503569602966309
Validation loss: 2.119806190331777

Epoch: 5| Step: 5
Training loss: 2.1624820232391357
Validation loss: 2.224687710404396

Epoch: 5| Step: 6
Training loss: 2.098879814147949
Validation loss: 2.230802138646444

Epoch: 5| Step: 7
Training loss: 2.3722128868103027
Validation loss: 2.1449789653221765

Epoch: 5| Step: 8
Training loss: 2.5808756351470947
Validation loss: 2.246289844314257

Epoch: 5| Step: 9
Training loss: 2.4310173988342285
Validation loss: 2.1969221234321594

Epoch: 5| Step: 10
Training loss: 2.2272822856903076
Validation loss: 2.1487683852513633

Epoch: 5| Step: 11
Training loss: 1.806014060974121
Validation loss: 2.2811257541179657

Epoch: 41| Step: 0
Training loss: 2.1524252891540527
Validation loss: 2.137164076169332

Epoch: 5| Step: 1
Training loss: 1.9187076091766357
Validation loss: 2.0775160988171897

Epoch: 5| Step: 2
Training loss: 2.374356746673584
Validation loss: 2.1181385020414987

Epoch: 5| Step: 3
Training loss: 1.777395486831665
Validation loss: 2.1065414249897003

Epoch: 5| Step: 4
Training loss: 1.997167944908142
Validation loss: 2.1319483816623688

Epoch: 5| Step: 5
Training loss: 1.9780099391937256
Validation loss: 2.0988822182019553

Epoch: 5| Step: 6
Training loss: 2.1062324047088623
Validation loss: 2.1412248412768045

Epoch: 5| Step: 7
Training loss: 2.0617432594299316
Validation loss: 2.206705426176389

Epoch: 5| Step: 8
Training loss: 1.6478267908096313
Validation loss: 2.2200917452573776

Epoch: 5| Step: 9
Training loss: 2.2392210960388184
Validation loss: 2.193824584285418

Epoch: 5| Step: 10
Training loss: 2.2223105430603027
Validation loss: 2.188759138186773

Epoch: 5| Step: 11
Training loss: 1.7652628421783447
Validation loss: 2.2523987690607705

Epoch: 42| Step: 0
Training loss: 1.6942756175994873
Validation loss: 2.1401262283325195

Epoch: 5| Step: 1
Training loss: 1.8388967514038086
Validation loss: 2.103563869992892

Epoch: 5| Step: 2
Training loss: 1.7372156381607056
Validation loss: 2.1903300682703652

Epoch: 5| Step: 3
Training loss: 2.539987325668335
Validation loss: 2.112122341990471

Epoch: 5| Step: 4
Training loss: 2.186671257019043
Validation loss: 2.187147935231527

Epoch: 5| Step: 5
Training loss: 2.1395604610443115
Validation loss: 2.135645459095637

Epoch: 5| Step: 6
Training loss: 1.8998775482177734
Validation loss: 2.1741178085406623

Epoch: 5| Step: 7
Training loss: 2.7949917316436768
Validation loss: 2.195192148288091

Epoch: 5| Step: 8
Training loss: 2.1530590057373047
Validation loss: 2.2041078954935074

Epoch: 5| Step: 9
Training loss: 2.3106632232666016
Validation loss: 2.1501199156045914

Epoch: 5| Step: 10
Training loss: 1.3071174621582031
Validation loss: 2.1503665695587793

Epoch: 5| Step: 11
Training loss: 2.772858142852783
Validation loss: 2.170459051926931

Epoch: 43| Step: 0
Training loss: 2.359013080596924
Validation loss: 2.143548051516215

Epoch: 5| Step: 1
Training loss: 2.7466065883636475
Validation loss: 2.188964198033015

Epoch: 5| Step: 2
Training loss: 1.5978795289993286
Validation loss: 2.144431392351786

Epoch: 5| Step: 3
Training loss: 2.1277074813842773
Validation loss: 2.1333209574222565

Epoch: 5| Step: 4
Training loss: 1.8964154720306396
Validation loss: 2.145303641756376

Epoch: 5| Step: 5
Training loss: 1.931928277015686
Validation loss: 2.2174234837293625

Epoch: 5| Step: 6
Training loss: 2.3489089012145996
Validation loss: 2.181278809905052

Epoch: 5| Step: 7
Training loss: 2.0384840965270996
Validation loss: 2.125148425499598

Epoch: 5| Step: 8
Training loss: 2.1462693214416504
Validation loss: 2.109936699271202

Epoch: 5| Step: 9
Training loss: 1.7410647869110107
Validation loss: 2.107589304447174

Epoch: 5| Step: 10
Training loss: 2.4021754264831543
Validation loss: 2.171794891357422

Epoch: 5| Step: 11
Training loss: 1.6145273447036743
Validation loss: 2.1383345077435174

Epoch: 44| Step: 0
Training loss: 2.7525954246520996
Validation loss: 2.1910131176312766

Epoch: 5| Step: 1
Training loss: 2.146280288696289
Validation loss: 2.1650062104066214

Epoch: 5| Step: 2
Training loss: 2.4497222900390625
Validation loss: 2.20698111752669

Epoch: 5| Step: 3
Training loss: 2.3732943534851074
Validation loss: 2.1646323104699454

Epoch: 5| Step: 4
Training loss: 2.234771490097046
Validation loss: 2.1715630342562995

Epoch: 5| Step: 5
Training loss: 2.424638271331787
Validation loss: 2.0523270865281424

Epoch: 5| Step: 6
Training loss: 1.8660640716552734
Validation loss: 2.108022799094518

Epoch: 5| Step: 7
Training loss: 2.002878189086914
Validation loss: 2.181214580933253

Epoch: 5| Step: 8
Training loss: 1.669769287109375
Validation loss: 2.1546807487805686

Epoch: 5| Step: 9
Training loss: 1.7389352321624756
Validation loss: 2.136932224035263

Epoch: 5| Step: 10
Training loss: 1.7148630619049072
Validation loss: 2.157414128383001

Epoch: 5| Step: 11
Training loss: 1.7937504053115845
Validation loss: 2.059976741671562

Epoch: 45| Step: 0
Training loss: 1.5410888195037842
Validation loss: 2.14579946299394

Epoch: 5| Step: 1
Training loss: 2.5643131732940674
Validation loss: 2.196202357610067

Epoch: 5| Step: 2
Training loss: 2.2217822074890137
Validation loss: 2.177677631378174

Epoch: 5| Step: 3
Training loss: 1.421535611152649
Validation loss: 2.1195449034372964

Epoch: 5| Step: 4
Training loss: 2.3994638919830322
Validation loss: 2.1191000441710153

Epoch: 5| Step: 5
Training loss: 2.1549184322357178
Validation loss: 2.1462638477484384

Epoch: 5| Step: 6
Training loss: 2.126530170440674
Validation loss: 2.1302021741867065

Epoch: 5| Step: 7
Training loss: 2.3982937335968018
Validation loss: 2.1309464275836945

Epoch: 5| Step: 8
Training loss: 2.412914752960205
Validation loss: 2.1916408985853195

Epoch: 5| Step: 9
Training loss: 2.1479439735412598
Validation loss: 2.118450954556465

Epoch: 5| Step: 10
Training loss: 1.6110814809799194
Validation loss: 2.0965184966723123

Epoch: 5| Step: 11
Training loss: 2.2184805870056152
Validation loss: 2.121069014072418

Epoch: 46| Step: 0
Training loss: 1.6517969369888306
Validation loss: 2.169263611237208

Epoch: 5| Step: 1
Training loss: 2.5863308906555176
Validation loss: 2.1880917698144913

Epoch: 5| Step: 2
Training loss: 1.972858190536499
Validation loss: 2.0600738326708474

Epoch: 5| Step: 3
Training loss: 2.3760883808135986
Validation loss: 2.1577821175257363

Epoch: 5| Step: 4
Training loss: 2.021684169769287
Validation loss: 2.228673741221428

Epoch: 5| Step: 5
Training loss: 2.164135456085205
Validation loss: 2.1378789991140366

Epoch: 5| Step: 6
Training loss: 2.8529067039489746
Validation loss: 2.168944835662842

Epoch: 5| Step: 7
Training loss: 1.641065239906311
Validation loss: 2.1265788276990256

Epoch: 5| Step: 8
Training loss: 2.133474349975586
Validation loss: 2.2233952482541404

Epoch: 5| Step: 9
Training loss: 2.0703468322753906
Validation loss: 2.140912006298701

Epoch: 5| Step: 10
Training loss: 2.0666327476501465
Validation loss: 2.180066133538882

Epoch: 5| Step: 11
Training loss: 2.4222137928009033
Validation loss: 2.187827005982399

Epoch: 47| Step: 0
Training loss: 2.5837388038635254
Validation loss: 2.036422943075498

Epoch: 5| Step: 1
Training loss: 1.9052505493164062
Validation loss: 2.247612635294596

Epoch: 5| Step: 2
Training loss: 1.8753103017807007
Validation loss: 2.1955798864364624

Epoch: 5| Step: 3
Training loss: 1.8930885791778564
Validation loss: 2.1210852563381195

Epoch: 5| Step: 4
Training loss: 2.3979334831237793
Validation loss: 2.1271380434433618

Epoch: 5| Step: 5
Training loss: 2.04059100151062
Validation loss: 2.1477256417274475

Epoch: 5| Step: 6
Training loss: 1.6536328792572021
Validation loss: 2.20224699874719

Epoch: 5| Step: 7
Training loss: 1.9396884441375732
Validation loss: 2.0410772959391275

Epoch: 5| Step: 8
Training loss: 2.5020246505737305
Validation loss: 2.1250206530094147

Epoch: 5| Step: 9
Training loss: 1.9142014980316162
Validation loss: 2.1337354481220245

Epoch: 5| Step: 10
Training loss: 2.054481029510498
Validation loss: 2.1145129054784775

Epoch: 5| Step: 11
Training loss: 3.3489644527435303
Validation loss: 2.215391760071119

Epoch: 48| Step: 0
Training loss: 1.782478928565979
Validation loss: 2.109151845177015

Epoch: 5| Step: 1
Training loss: 2.2031569480895996
Validation loss: 2.2130349576473236

Epoch: 5| Step: 2
Training loss: 1.7539966106414795
Validation loss: 2.212075650691986

Epoch: 5| Step: 3
Training loss: 1.9015426635742188
Validation loss: 2.23150501648585

Epoch: 5| Step: 4
Training loss: 3.146233081817627
Validation loss: 2.189767455061277

Epoch: 5| Step: 5
Training loss: 1.7897088527679443
Validation loss: 2.248074784874916

Epoch: 5| Step: 6
Training loss: 1.8653329610824585
Validation loss: 2.1021984666585922

Epoch: 5| Step: 7
Training loss: 2.3409550189971924
Validation loss: 2.1768069366614022

Epoch: 5| Step: 8
Training loss: 2.2637779712677
Validation loss: 2.1715083569288254

Epoch: 5| Step: 9
Training loss: 2.341010570526123
Validation loss: 2.2208801954984665

Epoch: 5| Step: 10
Training loss: 2.1666476726531982
Validation loss: 2.103498379389445

Epoch: 5| Step: 11
Training loss: 2.1827335357666016
Validation loss: 2.1885122805833817

Epoch: 49| Step: 0
Training loss: 1.425013780593872
Validation loss: 2.0941514720519385

Epoch: 5| Step: 1
Training loss: 2.0311269760131836
Validation loss: 2.1373864014943442

Epoch: 5| Step: 2
Training loss: 2.390164852142334
Validation loss: 2.1205760886271796

Epoch: 5| Step: 3
Training loss: 2.251204013824463
Validation loss: 2.1098968038956323

Epoch: 5| Step: 4
Training loss: 1.8367717266082764
Validation loss: 2.146252085765203

Epoch: 5| Step: 5
Training loss: 2.3863818645477295
Validation loss: 2.178567806879679

Epoch: 5| Step: 6
Training loss: 1.9226270914077759
Validation loss: 2.1269881576299667

Epoch: 5| Step: 7
Training loss: 1.6458961963653564
Validation loss: 2.209373945991198

Epoch: 5| Step: 8
Training loss: 2.0238943099975586
Validation loss: 2.091187780102094

Epoch: 5| Step: 9
Training loss: 1.8993885517120361
Validation loss: 2.1331582218408585

Epoch: 5| Step: 10
Training loss: 2.47733473777771
Validation loss: 2.1243814478317895

Epoch: 5| Step: 11
Training loss: 3.0047740936279297
Validation loss: 2.1802983631690345

Epoch: 50| Step: 0
Training loss: 2.4103620052337646
Validation loss: 2.1120474139849343

Epoch: 5| Step: 1
Training loss: 1.9508812427520752
Validation loss: 2.1238368401924768

Epoch: 5| Step: 2
Training loss: 1.91363525390625
Validation loss: 2.1299278686443963

Epoch: 5| Step: 3
Training loss: 1.810203194618225
Validation loss: 2.2008712589740753

Epoch: 5| Step: 4
Training loss: 3.0737407207489014
Validation loss: 2.1090237498283386

Epoch: 5| Step: 5
Training loss: 1.8868900537490845
Validation loss: 2.2020874470472336

Epoch: 5| Step: 6
Training loss: 2.535311222076416
Validation loss: 2.066574349999428

Epoch: 5| Step: 7
Training loss: 2.080292224884033
Validation loss: 2.196725606918335

Epoch: 5| Step: 8
Training loss: 2.0694243907928467
Validation loss: 2.181718776623408

Epoch: 5| Step: 9
Training loss: 2.232572078704834
Validation loss: 2.173627033829689

Epoch: 5| Step: 10
Training loss: 1.5796672105789185
Validation loss: 2.067281186580658

Epoch: 5| Step: 11
Training loss: 1.7432844638824463
Validation loss: 2.161892140905062

Epoch: 51| Step: 0
Training loss: 2.138216018676758
Validation loss: 2.1508679687976837

Epoch: 5| Step: 1
Training loss: 2.1321372985839844
Validation loss: 2.1374628196159997

Epoch: 5| Step: 2
Training loss: 2.376216173171997
Validation loss: 2.222901393969854

Epoch: 5| Step: 3
Training loss: 1.4648135900497437
Validation loss: 2.2228923539320626

Epoch: 5| Step: 4
Training loss: 2.2081611156463623
Validation loss: 2.0792630364497504

Epoch: 5| Step: 5
Training loss: 1.9075603485107422
Validation loss: 2.065770407517751

Epoch: 5| Step: 6
Training loss: 2.4995639324188232
Validation loss: 2.2029138753811517

Epoch: 5| Step: 7
Training loss: 2.1259427070617676
Validation loss: 2.1780883173147836

Epoch: 5| Step: 8
Training loss: 2.1888785362243652
Validation loss: 2.159012660384178

Epoch: 5| Step: 9
Training loss: 2.1598079204559326
Validation loss: 2.1400449921687446

Epoch: 5| Step: 10
Training loss: 2.0756752490997314
Validation loss: 2.1332523624102273

Epoch: 5| Step: 11
Training loss: 2.429629325866699
Validation loss: 2.1342024753491082

Epoch: 52| Step: 0
Training loss: 2.2135097980499268
Validation loss: 2.0926718463500342

Epoch: 5| Step: 1
Training loss: 1.9416812658309937
Validation loss: 2.172211026151975

Epoch: 5| Step: 2
Training loss: 2.380204439163208
Validation loss: 2.1372622748215995

Epoch: 5| Step: 3
Training loss: 1.8930069208145142
Validation loss: 2.1031093994776406

Epoch: 5| Step: 4
Training loss: 1.8328840732574463
Validation loss: 2.2760309676329293

Epoch: 5| Step: 5
Training loss: 2.757174015045166
Validation loss: 2.163581813375155

Epoch: 5| Step: 6
Training loss: 1.5901377201080322
Validation loss: 2.227931578954061

Epoch: 5| Step: 7
Training loss: 2.228358745574951
Validation loss: 2.1993893583615622

Epoch: 5| Step: 8
Training loss: 2.0968518257141113
Validation loss: 2.212265486518542

Epoch: 5| Step: 9
Training loss: 2.263909101486206
Validation loss: 2.1472173929214478

Epoch: 5| Step: 10
Training loss: 2.185236692428589
Validation loss: 2.192068780461947

Epoch: 5| Step: 11
Training loss: 2.734064817428589
Validation loss: 2.1598641822735467

Epoch: 53| Step: 0
Training loss: 2.187089204788208
Validation loss: 2.1141484628121057

Epoch: 5| Step: 1
Training loss: 1.6434320211410522
Validation loss: 2.140040228764216

Epoch: 5| Step: 2
Training loss: 1.9924871921539307
Validation loss: 2.2041004051764808

Epoch: 5| Step: 3
Training loss: 2.1108622550964355
Validation loss: 2.0577522863944373

Epoch: 5| Step: 4
Training loss: 1.8164886236190796
Validation loss: 2.1531605223814645

Epoch: 5| Step: 5
Training loss: 1.7216123342514038
Validation loss: 2.2332587440808616

Epoch: 5| Step: 6
Training loss: 2.215311050415039
Validation loss: 2.138414869705836

Epoch: 5| Step: 7
Training loss: 1.8952646255493164
Validation loss: 2.2206698457400003

Epoch: 5| Step: 8
Training loss: 2.5549769401550293
Validation loss: 2.0932457943757377

Epoch: 5| Step: 9
Training loss: 1.7882766723632812
Validation loss: 2.1365758925676346

Epoch: 5| Step: 10
Training loss: 2.5817012786865234
Validation loss: 2.1012409329414368

Epoch: 5| Step: 11
Training loss: 2.9091861248016357
Validation loss: 2.152007112900416

Epoch: 54| Step: 0
Training loss: 2.1036887168884277
Validation loss: 2.170941715439161

Epoch: 5| Step: 1
Training loss: 2.1918492317199707
Validation loss: 2.0201235115528107

Epoch: 5| Step: 2
Training loss: 1.9059350490570068
Validation loss: 2.1602225651343665

Epoch: 5| Step: 3
Training loss: 1.9679269790649414
Validation loss: 2.1676222334305444

Epoch: 5| Step: 4
Training loss: 1.8362953662872314
Validation loss: 2.105906074245771

Epoch: 5| Step: 5
Training loss: 2.004981756210327
Validation loss: 2.1414556801319122

Epoch: 5| Step: 6
Training loss: 2.2557058334350586
Validation loss: 2.099642420808474

Epoch: 5| Step: 7
Training loss: 2.2139718532562256
Validation loss: 2.1296511441469193

Epoch: 5| Step: 8
Training loss: 2.374748706817627
Validation loss: 2.181533843278885

Epoch: 5| Step: 9
Training loss: 1.4904347658157349
Validation loss: 2.127300908168157

Epoch: 5| Step: 10
Training loss: 2.5504913330078125
Validation loss: 2.180695171157519

Epoch: 5| Step: 11
Training loss: 2.6669065952301025
Validation loss: 2.121066133181254

Epoch: 55| Step: 0
Training loss: 1.621922254562378
Validation loss: 2.17211551964283

Epoch: 5| Step: 1
Training loss: 2.0518317222595215
Validation loss: 2.073500861724218

Epoch: 5| Step: 2
Training loss: 2.4393436908721924
Validation loss: 2.1216698239247003

Epoch: 5| Step: 3
Training loss: 1.6894617080688477
Validation loss: 2.069691926240921

Epoch: 5| Step: 4
Training loss: 2.1698858737945557
Validation loss: 2.1057648261388144

Epoch: 5| Step: 5
Training loss: 2.206044912338257
Validation loss: 2.131987680991491

Epoch: 5| Step: 6
Training loss: 2.001690626144409
Validation loss: 2.193591127792994

Epoch: 5| Step: 7
Training loss: 2.061267852783203
Validation loss: 2.158999820550283

Epoch: 5| Step: 8
Training loss: 2.599334955215454
Validation loss: 2.0979258120059967

Epoch: 5| Step: 9
Training loss: 1.8356775045394897
Validation loss: 2.175991396109263

Epoch: 5| Step: 10
Training loss: 1.838667631149292
Validation loss: 2.1398595919211707

Epoch: 5| Step: 11
Training loss: 1.149811029434204
Validation loss: 2.1704137325286865

Epoch: 56| Step: 0
Training loss: 2.4377167224884033
Validation loss: 2.122567812601725

Epoch: 5| Step: 1
Training loss: 2.7952523231506348
Validation loss: 2.043242866794268

Epoch: 5| Step: 2
Training loss: 1.9516500234603882
Validation loss: 2.1500519712766013

Epoch: 5| Step: 3
Training loss: 1.5403066873550415
Validation loss: 2.139667605360349

Epoch: 5| Step: 4
Training loss: 1.5255506038665771
Validation loss: 2.1278508404890695

Epoch: 5| Step: 5
Training loss: 1.9256458282470703
Validation loss: 2.1453731805086136

Epoch: 5| Step: 6
Training loss: 2.6084799766540527
Validation loss: 2.2158903181552887

Epoch: 5| Step: 7
Training loss: 2.4196391105651855
Validation loss: 2.1653671065966287

Epoch: 5| Step: 8
Training loss: 2.063884735107422
Validation loss: 2.0880988289912543

Epoch: 5| Step: 9
Training loss: 2.359499931335449
Validation loss: 2.200138434767723

Epoch: 5| Step: 10
Training loss: 1.9996801614761353
Validation loss: 2.1237882574399314

Epoch: 5| Step: 11
Training loss: 1.5758280754089355
Validation loss: 2.1762467473745346

Epoch: 57| Step: 0
Training loss: 2.172293186187744
Validation loss: 2.122438887755076

Epoch: 5| Step: 1
Training loss: 2.1614527702331543
Validation loss: 2.1435774167378745

Epoch: 5| Step: 2
Training loss: 1.5630321502685547
Validation loss: 2.1236274441083274

Epoch: 5| Step: 3
Training loss: 2.6160449981689453
Validation loss: 2.1654711812734604

Epoch: 5| Step: 4
Training loss: 1.7482731342315674
Validation loss: 2.093267798423767

Epoch: 5| Step: 5
Training loss: 1.8738806247711182
Validation loss: 2.193883493542671

Epoch: 5| Step: 6
Training loss: 2.2055134773254395
Validation loss: 2.1321930636962256

Epoch: 5| Step: 7
Training loss: 1.8839161396026611
Validation loss: 2.1582906742890677

Epoch: 5| Step: 8
Training loss: 2.290113925933838
Validation loss: 2.1645587931076684

Epoch: 5| Step: 9
Training loss: 2.4111766815185547
Validation loss: 2.10636638601621

Epoch: 5| Step: 10
Training loss: 2.013888120651245
Validation loss: 2.1432662655909858

Epoch: 5| Step: 11
Training loss: 1.6802830696105957
Validation loss: 2.1627973169088364

Epoch: 58| Step: 0
Training loss: 2.276899576187134
Validation loss: 2.1404776324828467

Epoch: 5| Step: 1
Training loss: 1.6101630926132202
Validation loss: 2.1268619000911713

Epoch: 5| Step: 2
Training loss: 1.8817718029022217
Validation loss: 2.1953541934490204

Epoch: 5| Step: 3
Training loss: 2.120407819747925
Validation loss: 2.2043725351492562

Epoch: 5| Step: 4
Training loss: 1.8640031814575195
Validation loss: 2.269311785697937

Epoch: 5| Step: 5
Training loss: 2.2237117290496826
Validation loss: 2.0743480374415717

Epoch: 5| Step: 6
Training loss: 2.257807493209839
Validation loss: 2.1891144712766013

Epoch: 5| Step: 7
Training loss: 1.268085241317749
Validation loss: 2.1901683509349823

Epoch: 5| Step: 8
Training loss: 2.6262097358703613
Validation loss: 2.2948808073997498

Epoch: 5| Step: 9
Training loss: 2.5691165924072266
Validation loss: 2.2086061388254166

Epoch: 5| Step: 10
Training loss: 1.7248684167861938
Validation loss: 2.1873181213935218

Epoch: 5| Step: 11
Training loss: 2.977133274078369
Validation loss: 2.1333182553450265

Epoch: 59| Step: 0
Training loss: 2.1136410236358643
Validation loss: 2.0825486928224564

Epoch: 5| Step: 1
Training loss: 1.7122074365615845
Validation loss: 2.1056297620137534

Epoch: 5| Step: 2
Training loss: 2.220024824142456
Validation loss: 2.1072969883680344

Epoch: 5| Step: 3
Training loss: 1.7414958477020264
Validation loss: 2.137474795182546

Epoch: 5| Step: 4
Training loss: 1.5573680400848389
Validation loss: 2.13105408847332

Epoch: 5| Step: 5
Training loss: 2.1579577922821045
Validation loss: 2.1095901081959405

Epoch: 5| Step: 6
Training loss: 2.429935932159424
Validation loss: 2.1183315416177115

Epoch: 5| Step: 7
Training loss: 2.403534412384033
Validation loss: 2.160130192836126

Epoch: 5| Step: 8
Training loss: 2.6353707313537598
Validation loss: 2.219589759906133

Epoch: 5| Step: 9
Training loss: 2.2969775199890137
Validation loss: 2.1601452827453613

Epoch: 5| Step: 10
Training loss: 2.0724120140075684
Validation loss: 2.078415036201477

Epoch: 5| Step: 11
Training loss: 1.8604743480682373
Validation loss: 2.2143748998641968

Epoch: 60| Step: 0
Training loss: 1.9338887929916382
Validation loss: 2.2220723778009415

Epoch: 5| Step: 1
Training loss: 2.135861873626709
Validation loss: 2.1913398653268814

Epoch: 5| Step: 2
Training loss: 1.75872802734375
Validation loss: 2.1492817600568137

Epoch: 5| Step: 3
Training loss: 2.0719120502471924
Validation loss: 2.0935474236806235

Epoch: 5| Step: 4
Training loss: 1.8687846660614014
Validation loss: 2.1218038350343704

Epoch: 5| Step: 5
Training loss: 2.2896177768707275
Validation loss: 2.190154621998469

Epoch: 5| Step: 6
Training loss: 1.9650123119354248
Validation loss: 2.104885766903559

Epoch: 5| Step: 7
Training loss: 1.9356439113616943
Validation loss: 2.191583583752314

Epoch: 5| Step: 8
Training loss: 2.105391025543213
Validation loss: 2.1643919746081033

Epoch: 5| Step: 9
Training loss: 2.0774030685424805
Validation loss: 2.184469997882843

Epoch: 5| Step: 10
Training loss: 2.3026130199432373
Validation loss: 2.1207316468159356

Epoch: 5| Step: 11
Training loss: 2.0052120685577393
Validation loss: 2.0840467313925424

Epoch: 61| Step: 0
Training loss: 1.4123313426971436
Validation loss: 2.178408667445183

Epoch: 5| Step: 1
Training loss: 2.2795252799987793
Validation loss: 2.158172850807508

Epoch: 5| Step: 2
Training loss: 1.8709800243377686
Validation loss: 2.1349763522545495

Epoch: 5| Step: 3
Training loss: 2.3410158157348633
Validation loss: 2.1128653436899185

Epoch: 5| Step: 4
Training loss: 2.0517578125
Validation loss: 2.1574943363666534

Epoch: 5| Step: 5
Training loss: 2.4153029918670654
Validation loss: 2.130173474550247

Epoch: 5| Step: 6
Training loss: 2.1117749214172363
Validation loss: 2.140409459670385

Epoch: 5| Step: 7
Training loss: 1.8701679706573486
Validation loss: 2.08473830918471

Epoch: 5| Step: 8
Training loss: 2.066072940826416
Validation loss: 2.1542755514383316

Epoch: 5| Step: 9
Training loss: 2.194777488708496
Validation loss: 2.0614109138647714

Epoch: 5| Step: 10
Training loss: 2.0178003311157227
Validation loss: 2.0189560105403266

Epoch: 5| Step: 11
Training loss: 1.2594939470291138
Validation loss: 2.2193414668242135

Epoch: 62| Step: 0
Training loss: 1.8917953968048096
Validation loss: 2.1295124689737954

Epoch: 5| Step: 1
Training loss: 2.117319345474243
Validation loss: 2.099124938249588

Epoch: 5| Step: 2
Training loss: 1.714120864868164
Validation loss: 2.171191011865934

Epoch: 5| Step: 3
Training loss: 2.6290183067321777
Validation loss: 2.216267933448156

Epoch: 5| Step: 4
Training loss: 1.8424603939056396
Validation loss: 2.108080873886744

Epoch: 5| Step: 5
Training loss: 2.402629852294922
Validation loss: 2.141690899928411

Epoch: 5| Step: 6
Training loss: 2.1491756439208984
Validation loss: 2.179572641849518

Epoch: 5| Step: 7
Training loss: 1.7916256189346313
Validation loss: 2.1337400873502097

Epoch: 5| Step: 8
Training loss: 2.099871873855591
Validation loss: 2.1384011606375375

Epoch: 5| Step: 9
Training loss: 1.9375841617584229
Validation loss: 2.1882701267798743

Epoch: 5| Step: 10
Training loss: 1.9306132793426514
Validation loss: 2.1102261642615

Epoch: 5| Step: 11
Training loss: 1.4267656803131104
Validation loss: 2.0865622460842133

Epoch: 63| Step: 0
Training loss: 1.5769248008728027
Validation loss: 2.161406715710958

Epoch: 5| Step: 1
Training loss: 2.2253382205963135
Validation loss: 2.164202243089676

Epoch: 5| Step: 2
Training loss: 2.243011236190796
Validation loss: 2.2385630160570145

Epoch: 5| Step: 3
Training loss: 1.676009178161621
Validation loss: 2.0941639890273414

Epoch: 5| Step: 4
Training loss: 2.9365596771240234
Validation loss: 2.0687025686105094

Epoch: 5| Step: 5
Training loss: 1.4486807584762573
Validation loss: 2.0848189244667688

Epoch: 5| Step: 6
Training loss: 1.9234205484390259
Validation loss: 2.1127183934052787

Epoch: 5| Step: 7
Training loss: 2.0685882568359375
Validation loss: 2.190129056572914

Epoch: 5| Step: 8
Training loss: 1.9659879207611084
Validation loss: 2.196266492207845

Epoch: 5| Step: 9
Training loss: 1.8203437328338623
Validation loss: 2.211527854204178

Epoch: 5| Step: 10
Training loss: 2.5251574516296387
Validation loss: 2.2259210546811423

Epoch: 5| Step: 11
Training loss: 2.001995801925659
Validation loss: 2.1471249212821326

Epoch: 64| Step: 0
Training loss: 1.9468152523040771
Validation loss: 2.124406119187673

Epoch: 5| Step: 1
Training loss: 1.8446836471557617
Validation loss: 2.2297265827655792

Epoch: 5| Step: 2
Training loss: 1.6415170431137085
Validation loss: 2.2037840535243354

Epoch: 5| Step: 3
Training loss: 2.0804429054260254
Validation loss: 2.2102444171905518

Epoch: 5| Step: 4
Training loss: 1.6403688192367554
Validation loss: 2.168256998062134

Epoch: 5| Step: 5
Training loss: 2.0107455253601074
Validation loss: 2.1720477640628815

Epoch: 5| Step: 6
Training loss: 2.8508458137512207
Validation loss: 2.180256739258766

Epoch: 5| Step: 7
Training loss: 2.417524576187134
Validation loss: 2.1902196606000266

Epoch: 5| Step: 8
Training loss: 2.1467111110687256
Validation loss: 2.1499822586774826

Epoch: 5| Step: 9
Training loss: 1.7935264110565186
Validation loss: 2.1100301345189414

Epoch: 5| Step: 10
Training loss: 2.1742873191833496
Validation loss: 2.1171189546585083

Epoch: 5| Step: 11
Training loss: 2.3431200981140137
Validation loss: 2.138915553689003

Epoch: 65| Step: 0
Training loss: 2.3808891773223877
Validation loss: 2.248057007789612

Epoch: 5| Step: 1
Training loss: 2.5306625366210938
Validation loss: 2.126889005303383

Epoch: 5| Step: 2
Training loss: 1.782751441001892
Validation loss: 2.150021255016327

Epoch: 5| Step: 3
Training loss: 2.051396369934082
Validation loss: 2.1596873054901757

Epoch: 5| Step: 4
Training loss: 1.6834713220596313
Validation loss: 2.087490434447924

Epoch: 5| Step: 5
Training loss: 1.7345558404922485
Validation loss: 2.1242433240016303

Epoch: 5| Step: 6
Training loss: 2.1446471214294434
Validation loss: 2.1499108026425042

Epoch: 5| Step: 7
Training loss: 1.5597740411758423
Validation loss: 2.0964483420054116

Epoch: 5| Step: 8
Training loss: 1.6711002588272095
Validation loss: 2.053777058919271

Epoch: 5| Step: 9
Training loss: 2.4489493370056152
Validation loss: 2.1176860133806863

Epoch: 5| Step: 10
Training loss: 2.2404112815856934
Validation loss: 2.0665330986181893

Epoch: 5| Step: 11
Training loss: 2.5324454307556152
Validation loss: 2.1130201369524

Epoch: 66| Step: 0
Training loss: 2.371861696243286
Validation loss: 2.1814894576867423

Epoch: 5| Step: 1
Training loss: 1.9605194330215454
Validation loss: 2.1238072365522385

Epoch: 5| Step: 2
Training loss: 1.4823577404022217
Validation loss: 2.1872090498606362

Epoch: 5| Step: 3
Training loss: 2.4335110187530518
Validation loss: 2.119826083381971

Epoch: 5| Step: 4
Training loss: 1.9314091205596924
Validation loss: 2.091247260570526

Epoch: 5| Step: 5
Training loss: 2.1450040340423584
Validation loss: 2.108650803565979

Epoch: 5| Step: 6
Training loss: 2.109815835952759
Validation loss: 2.1981696635484695

Epoch: 5| Step: 7
Training loss: 2.1892898082733154
Validation loss: 2.1907292852799096

Epoch: 5| Step: 8
Training loss: 1.8208730220794678
Validation loss: 2.0957679748535156

Epoch: 5| Step: 9
Training loss: 2.0879578590393066
Validation loss: 2.155772457520167

Epoch: 5| Step: 10
Training loss: 1.7934961318969727
Validation loss: 2.109837089975675

Epoch: 5| Step: 11
Training loss: 0.45572078227996826
Validation loss: 2.1377830505371094

Epoch: 67| Step: 0
Training loss: 1.9965219497680664
Validation loss: 2.114732081691424

Epoch: 5| Step: 1
Training loss: 2.169729709625244
Validation loss: 2.187332039078077

Epoch: 5| Step: 2
Training loss: 1.8290799856185913
Validation loss: 2.1575124810139337

Epoch: 5| Step: 3
Training loss: 2.050185441970825
Validation loss: 2.0952368726332984

Epoch: 5| Step: 4
Training loss: 2.4176082611083984
Validation loss: 2.1664205491542816

Epoch: 5| Step: 5
Training loss: 1.8964484930038452
Validation loss: 2.1290355722109475

Epoch: 5| Step: 6
Training loss: 2.629366397857666
Validation loss: 2.1064877013365426

Epoch: 5| Step: 7
Training loss: 2.296170711517334
Validation loss: 2.133257642388344

Epoch: 5| Step: 8
Training loss: 1.4550755023956299
Validation loss: 2.0713398406902948

Epoch: 5| Step: 9
Training loss: 1.894432783126831
Validation loss: 2.1163315773010254

Epoch: 5| Step: 10
Training loss: 1.8493576049804688
Validation loss: 2.2257887721061707

Epoch: 5| Step: 11
Training loss: 0.9688018560409546
Validation loss: 2.1680389046669006

Epoch: 68| Step: 0
Training loss: 2.316946029663086
Validation loss: 2.187095125516256

Epoch: 5| Step: 1
Training loss: 2.1630289554595947
Validation loss: 2.2190541476011276

Epoch: 5| Step: 2
Training loss: 1.716377854347229
Validation loss: 2.1608228037754693

Epoch: 5| Step: 3
Training loss: 1.459861159324646
Validation loss: 2.136065661907196

Epoch: 5| Step: 4
Training loss: 2.0500009059906006
Validation loss: 2.1136258840560913

Epoch: 5| Step: 5
Training loss: 1.4335665702819824
Validation loss: 2.1808467557032905

Epoch: 5| Step: 6
Training loss: 1.7067819833755493
Validation loss: 2.215938995281855

Epoch: 5| Step: 7
Training loss: 2.3458428382873535
Validation loss: 2.144570142030716

Epoch: 5| Step: 8
Training loss: 1.9609794616699219
Validation loss: 2.2066821455955505

Epoch: 5| Step: 9
Training loss: 2.5412163734436035
Validation loss: 2.155232757329941

Epoch: 5| Step: 10
Training loss: 2.4795737266540527
Validation loss: 2.2198223769664764

Epoch: 5| Step: 11
Training loss: 2.370133638381958
Validation loss: 2.2023150424162545

Epoch: 69| Step: 0
Training loss: 2.3834757804870605
Validation loss: 2.1380364894866943

Epoch: 5| Step: 1
Training loss: 1.515804648399353
Validation loss: 2.1734468241532645

Epoch: 5| Step: 2
Training loss: 1.9287068843841553
Validation loss: 2.1023428787787757

Epoch: 5| Step: 3
Training loss: 2.0945980548858643
Validation loss: 2.106013829509417

Epoch: 5| Step: 4
Training loss: 1.694380521774292
Validation loss: 2.205865522225698

Epoch: 5| Step: 5
Training loss: 1.9036948680877686
Validation loss: 2.1667787432670593

Epoch: 5| Step: 6
Training loss: 2.703120708465576
Validation loss: 2.171581268310547

Epoch: 5| Step: 7
Training loss: 2.0226221084594727
Validation loss: 2.0878369361162186

Epoch: 5| Step: 8
Training loss: 2.248906135559082
Validation loss: 2.2883974611759186

Epoch: 5| Step: 9
Training loss: 1.8626537322998047
Validation loss: 2.1765708923339844

Epoch: 5| Step: 10
Training loss: 1.9399620294570923
Validation loss: 2.1126033812761307

Epoch: 5| Step: 11
Training loss: 2.029007911682129
Validation loss: 2.209630454579989

Epoch: 70| Step: 0
Training loss: 1.481262445449829
Validation loss: 2.129937614003817

Epoch: 5| Step: 1
Training loss: 1.8802560567855835
Validation loss: 2.1757728656133017

Epoch: 5| Step: 2
Training loss: 2.0811684131622314
Validation loss: 2.1515229990084968

Epoch: 5| Step: 3
Training loss: 2.076659917831421
Validation loss: 2.193928877512614

Epoch: 5| Step: 4
Training loss: 2.335223436355591
Validation loss: 2.1124797413746514

Epoch: 5| Step: 5
Training loss: 2.3942742347717285
Validation loss: 2.18386510014534

Epoch: 5| Step: 6
Training loss: 2.1301321983337402
Validation loss: 2.1840266486008963

Epoch: 5| Step: 7
Training loss: 2.0375566482543945
Validation loss: 2.1854691207408905

Epoch: 5| Step: 8
Training loss: 2.3035080432891846
Validation loss: 2.1728405406077704

Epoch: 5| Step: 9
Training loss: 1.6376707553863525
Validation loss: 2.2682270854711533

Epoch: 5| Step: 10
Training loss: 2.119753837585449
Validation loss: 2.0696177581946054

Epoch: 5| Step: 11
Training loss: 3.176386833190918
Validation loss: 2.2462626894315085

Epoch: 71| Step: 0
Training loss: 1.9697906970977783
Validation loss: 2.234918395678202

Epoch: 5| Step: 1
Training loss: 1.805619478225708
Validation loss: 2.223257968823115

Epoch: 5| Step: 2
Training loss: 2.0934977531433105
Validation loss: 2.052981893221537

Epoch: 5| Step: 3
Training loss: 2.2341339588165283
Validation loss: 2.14258573949337

Epoch: 5| Step: 4
Training loss: 2.082078456878662
Validation loss: 2.187363862991333

Epoch: 5| Step: 5
Training loss: 2.117828369140625
Validation loss: 2.1545950224002204

Epoch: 5| Step: 6
Training loss: 1.8719621896743774
Validation loss: 2.074649120370547

Epoch: 5| Step: 7
Training loss: 1.965210199356079
Validation loss: 2.1403124630451202

Epoch: 5| Step: 8
Training loss: 2.1363511085510254
Validation loss: 2.113027443488439

Epoch: 5| Step: 9
Training loss: 2.3478055000305176
Validation loss: 2.1301790475845337

Epoch: 5| Step: 10
Training loss: 1.7685163021087646
Validation loss: 2.0996572176615396

Epoch: 5| Step: 11
Training loss: 3.3994626998901367
Validation loss: 2.0488136957089105

Epoch: 72| Step: 0
Training loss: 2.157508373260498
Validation loss: 2.07767017185688

Epoch: 5| Step: 1
Training loss: 2.5977847576141357
Validation loss: 2.1505573640267053

Epoch: 5| Step: 2
Training loss: 1.3379020690917969
Validation loss: 2.0949236005544662

Epoch: 5| Step: 3
Training loss: 2.1977462768554688
Validation loss: 2.1767570773760476

Epoch: 5| Step: 4
Training loss: 1.9249489307403564
Validation loss: 2.168880879878998

Epoch: 5| Step: 5
Training loss: 1.8924413919448853
Validation loss: 2.1161892265081406

Epoch: 5| Step: 6
Training loss: 1.9169737100601196
Validation loss: 2.119841088851293

Epoch: 5| Step: 7
Training loss: 2.1635518074035645
Validation loss: 2.15329480667909

Epoch: 5| Step: 8
Training loss: 1.9707021713256836
Validation loss: 2.189848174651464

Epoch: 5| Step: 9
Training loss: 1.9179630279541016
Validation loss: 2.107295294602712

Epoch: 5| Step: 10
Training loss: 2.0303070545196533
Validation loss: 2.146604508161545

Epoch: 5| Step: 11
Training loss: 1.785923957824707
Validation loss: 2.1947053323189416

Epoch: 73| Step: 0
Training loss: 2.5901660919189453
Validation loss: 2.111816962560018

Epoch: 5| Step: 1
Training loss: 1.9519519805908203
Validation loss: 2.1225208789110184

Epoch: 5| Step: 2
Training loss: 1.722182273864746
Validation loss: 2.1589604963858924

Epoch: 5| Step: 3
Training loss: 1.8169376850128174
Validation loss: 2.095311686396599

Epoch: 5| Step: 4
Training loss: 1.9418408870697021
Validation loss: 2.1278335799773536

Epoch: 5| Step: 5
Training loss: 1.5704702138900757
Validation loss: 2.235877980788549

Epoch: 5| Step: 6
Training loss: 1.5418527126312256
Validation loss: 2.083666910727819

Epoch: 5| Step: 7
Training loss: 1.7871052026748657
Validation loss: 2.0944489339987435

Epoch: 5| Step: 8
Training loss: 2.586930990219116
Validation loss: 2.137273132801056

Epoch: 5| Step: 9
Training loss: 2.644324779510498
Validation loss: 2.1989323745171228

Epoch: 5| Step: 10
Training loss: 2.1512951850891113
Validation loss: 2.1236001451810202

Epoch: 5| Step: 11
Training loss: 2.2245349884033203
Validation loss: 2.0995743572711945

Epoch: 74| Step: 0
Training loss: 2.278548240661621
Validation loss: 2.1569606363773346

Epoch: 5| Step: 1
Training loss: 1.999516487121582
Validation loss: 2.0492204477389655

Epoch: 5| Step: 2
Training loss: 2.6137757301330566
Validation loss: 2.128292183081309

Epoch: 5| Step: 3
Training loss: 1.7691256999969482
Validation loss: 2.088389535744985

Epoch: 5| Step: 4
Training loss: 1.7029247283935547
Validation loss: 2.2582501967748008

Epoch: 5| Step: 5
Training loss: 1.8022778034210205
Validation loss: 2.091575856010119

Epoch: 5| Step: 6
Training loss: 1.5986390113830566
Validation loss: 2.1461697022120156

Epoch: 5| Step: 7
Training loss: 1.488150715827942
Validation loss: 2.2238201647996902

Epoch: 5| Step: 8
Training loss: 2.3760972023010254
Validation loss: 2.1842115968465805

Epoch: 5| Step: 9
Training loss: 2.5860233306884766
Validation loss: 2.176863501469294

Epoch: 5| Step: 10
Training loss: 2.3705382347106934
Validation loss: 2.1326136787732444

Epoch: 5| Step: 11
Training loss: 2.4892842769622803
Validation loss: 2.1169438610474267

Epoch: 75| Step: 0
Training loss: 2.0354137420654297
Validation loss: 2.1742293337980905

Epoch: 5| Step: 1
Training loss: 1.5874831676483154
Validation loss: 2.133715401093165

Epoch: 5| Step: 2
Training loss: 1.90240478515625
Validation loss: 2.23917326827844

Epoch: 5| Step: 3
Training loss: 3.076759099960327
Validation loss: 2.087305853764216

Epoch: 5| Step: 4
Training loss: 1.7143042087554932
Validation loss: 2.169655422369639

Epoch: 5| Step: 5
Training loss: 1.8112318515777588
Validation loss: 2.163101146618525

Epoch: 5| Step: 6
Training loss: 2.1516125202178955
Validation loss: 2.086628938714663

Epoch: 5| Step: 7
Training loss: 2.0461816787719727
Validation loss: 2.1495859076579413

Epoch: 5| Step: 8
Training loss: 1.9050159454345703
Validation loss: 2.1228684782981873

Epoch: 5| Step: 9
Training loss: 2.455238103866577
Validation loss: 2.1355545918146768

Epoch: 5| Step: 10
Training loss: 2.0055007934570312
Validation loss: 2.1236472676197686

Epoch: 5| Step: 11
Training loss: 2.983114719390869
Validation loss: 2.1517512251933417

Epoch: 76| Step: 0
Training loss: 1.6329456567764282
Validation loss: 2.204661806424459

Epoch: 5| Step: 1
Training loss: 2.3914523124694824
Validation loss: 2.1440156747897468

Epoch: 5| Step: 2
Training loss: 2.097341775894165
Validation loss: 2.1536339620749154

Epoch: 5| Step: 3
Training loss: 1.740352988243103
Validation loss: 2.2358515361944833

Epoch: 5| Step: 4
Training loss: 1.707578420639038
Validation loss: 2.1403366327285767

Epoch: 5| Step: 5
Training loss: 2.3105826377868652
Validation loss: 2.161503071586291

Epoch: 5| Step: 6
Training loss: 2.174368381500244
Validation loss: 2.141903892159462

Epoch: 5| Step: 7
Training loss: 2.359400510787964
Validation loss: 2.098464315136274

Epoch: 5| Step: 8
Training loss: 2.081831932067871
Validation loss: 2.1533463398615518

Epoch: 5| Step: 9
Training loss: 2.007270336151123
Validation loss: 2.1056013156970343

Epoch: 5| Step: 10
Training loss: 1.9142944812774658
Validation loss: 2.0929793318112693

Epoch: 5| Step: 11
Training loss: 0.9855852127075195
Validation loss: 2.219345808029175

Epoch: 77| Step: 0
Training loss: 1.7533382177352905
Validation loss: 2.1391007055838904

Epoch: 5| Step: 1
Training loss: 2.033400058746338
Validation loss: 2.1494523336489997

Epoch: 5| Step: 2
Training loss: 1.894304633140564
Validation loss: 2.0698827306429544

Epoch: 5| Step: 3
Training loss: 2.0622496604919434
Validation loss: 2.136844058831533

Epoch: 5| Step: 4
Training loss: 1.835221529006958
Validation loss: 2.1093906660874686

Epoch: 5| Step: 5
Training loss: 2.077021360397339
Validation loss: 2.0808009604612985

Epoch: 5| Step: 6
Training loss: 1.765369176864624
Validation loss: 2.1079969008763633

Epoch: 5| Step: 7
Training loss: 1.904199242591858
Validation loss: 2.1314327170451484

Epoch: 5| Step: 8
Training loss: 1.8975569009780884
Validation loss: 2.1167761385440826

Epoch: 5| Step: 9
Training loss: 1.8925914764404297
Validation loss: 2.137000491221746

Epoch: 5| Step: 10
Training loss: 2.192288875579834
Validation loss: 2.1130002240339913

Epoch: 5| Step: 11
Training loss: 2.962082624435425
Validation loss: 2.1325139105319977

Epoch: 78| Step: 0
Training loss: 2.393475294113159
Validation loss: 2.2122324804464975

Epoch: 5| Step: 1
Training loss: 1.7963100671768188
Validation loss: 2.2099625567595163

Epoch: 5| Step: 2
Training loss: 2.403151750564575
Validation loss: 2.1095493336518607

Epoch: 5| Step: 3
Training loss: 1.7677665948867798
Validation loss: 2.129724328716596

Epoch: 5| Step: 4
Training loss: 2.164278507232666
Validation loss: 2.202872802813848

Epoch: 5| Step: 5
Training loss: 1.601058006286621
Validation loss: 2.1991798182328544

Epoch: 5| Step: 6
Training loss: 1.8850215673446655
Validation loss: 2.1763290415207543

Epoch: 5| Step: 7
Training loss: 2.0439822673797607
Validation loss: 2.1917936205863953

Epoch: 5| Step: 8
Training loss: 2.68401837348938
Validation loss: 2.151618411143621

Epoch: 5| Step: 9
Training loss: 2.154461622238159
Validation loss: 2.1549752255280814

Epoch: 5| Step: 10
Training loss: 1.831419587135315
Validation loss: 2.1614411969979606

Epoch: 5| Step: 11
Training loss: 1.4424463510513306
Validation loss: 2.0831777850786843

Epoch: 79| Step: 0
Training loss: 2.0456759929656982
Validation loss: 2.101804713408152

Epoch: 5| Step: 1
Training loss: 2.25785756111145
Validation loss: 2.1777121076981225

Epoch: 5| Step: 2
Training loss: 2.527263641357422
Validation loss: 2.0961004942655563

Epoch: 5| Step: 3
Training loss: 1.7671730518341064
Validation loss: 2.1094577511151633

Epoch: 5| Step: 4
Training loss: 2.097444534301758
Validation loss: 2.146055390437444

Epoch: 5| Step: 5
Training loss: 1.6005046367645264
Validation loss: 2.24259323378404

Epoch: 5| Step: 6
Training loss: 1.584533452987671
Validation loss: 2.152890016635259

Epoch: 5| Step: 7
Training loss: 2.0892345905303955
Validation loss: 2.1347225258747735

Epoch: 5| Step: 8
Training loss: 1.659002661705017
Validation loss: 2.138606980443001

Epoch: 5| Step: 9
Training loss: 2.3696320056915283
Validation loss: 2.215754598379135

Epoch: 5| Step: 10
Training loss: 2.2601540088653564
Validation loss: 2.1590296775102615

Epoch: 5| Step: 11
Training loss: 1.8441977500915527
Validation loss: 2.131846328576406

Epoch: 80| Step: 0
Training loss: 2.4664292335510254
Validation loss: 2.1601723482211432

Epoch: 5| Step: 1
Training loss: 2.18205189704895
Validation loss: 2.2161561052004495

Epoch: 5| Step: 2
Training loss: 1.7516815662384033
Validation loss: 2.1897805084784827

Epoch: 5| Step: 3
Training loss: 2.126922130584717
Validation loss: 2.248382200797399

Epoch: 5| Step: 4
Training loss: 2.109489917755127
Validation loss: 2.1289191941420236

Epoch: 5| Step: 5
Training loss: 2.3179526329040527
Validation loss: 2.21077994008859

Epoch: 5| Step: 6
Training loss: 1.8998523950576782
Validation loss: 2.1105705946683884

Epoch: 5| Step: 7
Training loss: 1.8321527242660522
Validation loss: 2.1374861001968384

Epoch: 5| Step: 8
Training loss: 1.7750694751739502
Validation loss: 2.173420170942942

Epoch: 5| Step: 9
Training loss: 1.9493992328643799
Validation loss: 2.101899594068527

Epoch: 5| Step: 10
Training loss: 2.0023670196533203
Validation loss: 2.2132811148961387

Epoch: 5| Step: 11
Training loss: 1.6979743242263794
Validation loss: 2.1196706046660743

Epoch: 81| Step: 0
Training loss: 1.3061875104904175
Validation loss: 2.120374937852224

Epoch: 5| Step: 1
Training loss: 1.583554983139038
Validation loss: 2.0730542292197547

Epoch: 5| Step: 2
Training loss: 2.297212600708008
Validation loss: 2.1115746100743613

Epoch: 5| Step: 3
Training loss: 1.3307191133499146
Validation loss: 2.150108809272448

Epoch: 5| Step: 4
Training loss: 1.9780937433242798
Validation loss: 2.165858839948972

Epoch: 5| Step: 5
Training loss: 2.2640509605407715
Validation loss: 2.195158541202545

Epoch: 5| Step: 6
Training loss: 2.2969460487365723
Validation loss: 2.1064338634411492

Epoch: 5| Step: 7
Training loss: 2.614927053451538
Validation loss: 2.054808775583903

Epoch: 5| Step: 8
Training loss: 1.649863600730896
Validation loss: 2.0270203997691474

Epoch: 5| Step: 9
Training loss: 2.2740914821624756
Validation loss: 2.1934061348438263

Epoch: 5| Step: 10
Training loss: 1.8721497058868408
Validation loss: 2.130007197459539

Epoch: 5| Step: 11
Training loss: 2.6823019981384277
Validation loss: 2.089792932073275

Epoch: 82| Step: 0
Training loss: 1.7917182445526123
Validation loss: 2.1479952136675515

Epoch: 5| Step: 1
Training loss: 2.919694423675537
Validation loss: 2.1394953529040017

Epoch: 5| Step: 2
Training loss: 2.446345567703247
Validation loss: 2.1423021654287973

Epoch: 5| Step: 3
Training loss: 2.000859498977661
Validation loss: 2.140492687622706

Epoch: 5| Step: 4
Training loss: 2.2437663078308105
Validation loss: 2.172953888773918

Epoch: 5| Step: 5
Training loss: 2.1014397144317627
Validation loss: 2.15709957977136

Epoch: 5| Step: 6
Training loss: 1.7774633169174194
Validation loss: 2.133969803651174

Epoch: 5| Step: 7
Training loss: 2.296552896499634
Validation loss: 2.1924977699915567

Epoch: 5| Step: 8
Training loss: 1.3762061595916748
Validation loss: 2.1460352540016174

Epoch: 5| Step: 9
Training loss: 1.390337586402893
Validation loss: 2.1636469066143036

Epoch: 5| Step: 10
Training loss: 1.6912126541137695
Validation loss: 2.209842011332512

Epoch: 5| Step: 11
Training loss: 1.9673609733581543
Validation loss: 2.151422401269277

Epoch: 83| Step: 0
Training loss: 1.9706169366836548
Validation loss: 2.206373870372772

Epoch: 5| Step: 1
Training loss: 2.634944438934326
Validation loss: 2.201766754190127

Epoch: 5| Step: 2
Training loss: 1.7225253582000732
Validation loss: 2.18768472969532

Epoch: 5| Step: 3
Training loss: 2.163186550140381
Validation loss: 2.147856682538986

Epoch: 5| Step: 4
Training loss: 2.4068219661712646
Validation loss: 2.1324529548486075

Epoch: 5| Step: 5
Training loss: 1.6902183294296265
Validation loss: 2.125819186369578

Epoch: 5| Step: 6
Training loss: 2.4549427032470703
Validation loss: 2.1522788206736245

Epoch: 5| Step: 7
Training loss: 2.033527374267578
Validation loss: 2.118863875667254

Epoch: 5| Step: 8
Training loss: 1.6013456583023071
Validation loss: 2.1282491187254586

Epoch: 5| Step: 9
Training loss: 1.4487121105194092
Validation loss: 2.161220704515775

Epoch: 5| Step: 10
Training loss: 1.5549198389053345
Validation loss: 2.1476715952157974

Epoch: 5| Step: 11
Training loss: 1.943674921989441
Validation loss: 2.201647932330767

Epoch: 84| Step: 0
Training loss: 1.8388620615005493
Validation loss: 2.176494305332502

Epoch: 5| Step: 1
Training loss: 2.1751766204833984
Validation loss: 2.154842029015223

Epoch: 5| Step: 2
Training loss: 1.785740852355957
Validation loss: 2.1199749608834586

Epoch: 5| Step: 3
Training loss: 2.1142804622650146
Validation loss: 2.1211432417233786

Epoch: 5| Step: 4
Training loss: 1.7119414806365967
Validation loss: 2.1035261352856955

Epoch: 5| Step: 5
Training loss: 1.9073060750961304
Validation loss: 2.2515832285086312

Epoch: 5| Step: 6
Training loss: 2.2000298500061035
Validation loss: 2.095507502555847

Epoch: 5| Step: 7
Training loss: 1.9454371929168701
Validation loss: 2.1430675635735192

Epoch: 5| Step: 8
Training loss: 1.9736419916152954
Validation loss: 2.166596601406733

Epoch: 5| Step: 9
Training loss: 2.1925766468048096
Validation loss: 2.220760573943456

Epoch: 5| Step: 10
Training loss: 2.0595364570617676
Validation loss: 2.1319744835297265

Epoch: 5| Step: 11
Training loss: 2.151728630065918
Validation loss: 2.1142138491074243

Epoch: 85| Step: 0
Training loss: 2.2216145992279053
Validation loss: 2.19590171178182

Epoch: 5| Step: 1
Training loss: 1.7093970775604248
Validation loss: 2.2536486238241196

Epoch: 5| Step: 2
Training loss: 2.357534885406494
Validation loss: 2.116681843996048

Epoch: 5| Step: 3
Training loss: 2.0594820976257324
Validation loss: 2.1194918105999627

Epoch: 5| Step: 4
Training loss: 1.7725900411605835
Validation loss: 2.1225463251272836

Epoch: 5| Step: 5
Training loss: 2.6672582626342773
Validation loss: 2.1524223387241364

Epoch: 5| Step: 6
Training loss: 2.1131272315979004
Validation loss: 2.117049361268679

Epoch: 5| Step: 7
Training loss: 1.9636319875717163
Validation loss: 2.1514598578214645

Epoch: 5| Step: 8
Training loss: 1.5609104633331299
Validation loss: 2.1095502773920694

Epoch: 5| Step: 9
Training loss: 1.5466700792312622
Validation loss: 2.167432596286138

Epoch: 5| Step: 10
Training loss: 2.1564323902130127
Validation loss: 2.233983024954796

Epoch: 5| Step: 11
Training loss: 2.4746015071868896
Validation loss: 2.0607125212748847

Epoch: 86| Step: 0
Training loss: 1.86883544921875
Validation loss: 2.159993569056193

Epoch: 5| Step: 1
Training loss: 1.7690839767456055
Validation loss: 2.1496939609448114

Epoch: 5| Step: 2
Training loss: 1.9861812591552734
Validation loss: 2.1294120649496713

Epoch: 5| Step: 3
Training loss: 1.5236774682998657
Validation loss: 2.0995495319366455

Epoch: 5| Step: 4
Training loss: 1.8727085590362549
Validation loss: 2.2057909667491913

Epoch: 5| Step: 5
Training loss: 2.360271453857422
Validation loss: 2.1872636576493583

Epoch: 5| Step: 6
Training loss: 1.9749984741210938
Validation loss: 2.212202618519465

Epoch: 5| Step: 7
Training loss: 2.162155866622925
Validation loss: 2.0960072626670203

Epoch: 5| Step: 8
Training loss: 2.258871078491211
Validation loss: 2.1380793700615564

Epoch: 5| Step: 9
Training loss: 1.8503456115722656
Validation loss: 2.1900181273619332

Epoch: 5| Step: 10
Training loss: 2.0596871376037598
Validation loss: 2.126869633793831

Epoch: 5| Step: 11
Training loss: 1.2683088779449463
Validation loss: 2.1418451418479285

Epoch: 87| Step: 0
Training loss: 1.8090661764144897
Validation loss: 2.209717179338137

Epoch: 5| Step: 1
Training loss: 2.0680103302001953
Validation loss: 2.0572523176670074

Epoch: 5| Step: 2
Training loss: 2.2038302421569824
Validation loss: 2.1422174721956253

Epoch: 5| Step: 3
Training loss: 1.803269386291504
Validation loss: 2.1331549485524497

Epoch: 5| Step: 4
Training loss: 1.7060997486114502
Validation loss: 2.148028239607811

Epoch: 5| Step: 5
Training loss: 1.7730939388275146
Validation loss: 2.192907303571701

Epoch: 5| Step: 6
Training loss: 2.358490467071533
Validation loss: 2.1545572032531104

Epoch: 5| Step: 7
Training loss: 2.2176480293273926
Validation loss: 2.084219659368197

Epoch: 5| Step: 8
Training loss: 1.8289306163787842
Validation loss: 2.110863298177719

Epoch: 5| Step: 9
Training loss: 2.150043249130249
Validation loss: 2.105284477273623

Epoch: 5| Step: 10
Training loss: 2.347628116607666
Validation loss: 2.157073676586151

Epoch: 5| Step: 11
Training loss: 2.173644542694092
Validation loss: 2.1524818738301597

Epoch: 88| Step: 0
Training loss: 2.188192129135132
Validation loss: 2.024821256597837

Epoch: 5| Step: 1
Training loss: 2.358363628387451
Validation loss: 2.242823322614034

Epoch: 5| Step: 2
Training loss: 1.7880895137786865
Validation loss: 2.1506330519914627

Epoch: 5| Step: 3
Training loss: 1.8805568218231201
Validation loss: 2.2085736443599067

Epoch: 5| Step: 4
Training loss: 2.187528133392334
Validation loss: 2.1237705747286477

Epoch: 5| Step: 5
Training loss: 2.070119857788086
Validation loss: 2.172254448135694

Epoch: 5| Step: 6
Training loss: 1.6849467754364014
Validation loss: 2.2760322093963623

Epoch: 5| Step: 7
Training loss: 1.6041691303253174
Validation loss: 2.1270223259925842

Epoch: 5| Step: 8
Training loss: 2.503490447998047
Validation loss: 2.089356059829394

Epoch: 5| Step: 9
Training loss: 2.106114387512207
Validation loss: 2.1722029596567154

Epoch: 5| Step: 10
Training loss: 1.8291183710098267
Validation loss: 2.1955776115258536

Epoch: 5| Step: 11
Training loss: 1.368532419204712
Validation loss: 2.18149770796299

Epoch: 89| Step: 0
Training loss: 2.1335740089416504
Validation loss: 2.1507602284351983

Epoch: 5| Step: 1
Training loss: 1.7177797555923462
Validation loss: 2.1668616384267807

Epoch: 5| Step: 2
Training loss: 1.9069788455963135
Validation loss: 2.0795650581518808

Epoch: 5| Step: 3
Training loss: 2.13690447807312
Validation loss: 2.2015399734179177

Epoch: 5| Step: 4
Training loss: 1.7892811298370361
Validation loss: 2.1132342716058097

Epoch: 5| Step: 5
Training loss: 1.8683658838272095
Validation loss: 2.1086382071177163

Epoch: 5| Step: 6
Training loss: 2.1670827865600586
Validation loss: 2.1430879086256027

Epoch: 5| Step: 7
Training loss: 2.148404359817505
Validation loss: 2.1732702553272247

Epoch: 5| Step: 8
Training loss: 1.527951955795288
Validation loss: 2.1219644943873086

Epoch: 5| Step: 9
Training loss: 2.234431743621826
Validation loss: 2.125056912501653

Epoch: 5| Step: 10
Training loss: 2.240009069442749
Validation loss: 2.0910345862309136

Epoch: 5| Step: 11
Training loss: 2.126608371734619
Validation loss: 2.0584645768006644

Epoch: 90| Step: 0
Training loss: 2.1427242755889893
Validation loss: 2.1353520452976227

Epoch: 5| Step: 1
Training loss: 2.0306296348571777
Validation loss: 2.167499581972758

Epoch: 5| Step: 2
Training loss: 2.015071392059326
Validation loss: 2.1776231626669564

Epoch: 5| Step: 3
Training loss: 1.8508037328720093
Validation loss: 2.1627329190572104

Epoch: 5| Step: 4
Training loss: 2.240689754486084
Validation loss: 2.150138035416603

Epoch: 5| Step: 5
Training loss: 2.098095417022705
Validation loss: 2.176323488354683

Epoch: 5| Step: 6
Training loss: 1.4711287021636963
Validation loss: 2.1178392618894577

Epoch: 5| Step: 7
Training loss: 2.103949546813965
Validation loss: 2.133386721213659

Epoch: 5| Step: 8
Training loss: 2.074382781982422
Validation loss: 2.176443745692571

Epoch: 5| Step: 9
Training loss: 2.015209197998047
Validation loss: 2.2165132065614066

Epoch: 5| Step: 10
Training loss: 1.8898547887802124
Validation loss: 2.127425620953242

Epoch: 5| Step: 11
Training loss: 3.314887046813965
Validation loss: 2.1250234146912894

Epoch: 91| Step: 0
Training loss: 2.5348782539367676
Validation loss: 2.177303155263265

Epoch: 5| Step: 1
Training loss: 1.8852742910385132
Validation loss: 2.1471768418947854

Epoch: 5| Step: 2
Training loss: 1.9037355184555054
Validation loss: 2.13709565003713

Epoch: 5| Step: 3
Training loss: 1.7762473821640015
Validation loss: 2.1082016776005426

Epoch: 5| Step: 4
Training loss: 2.216557025909424
Validation loss: 2.124192327260971

Epoch: 5| Step: 5
Training loss: 2.2855591773986816
Validation loss: 2.1358243773380914

Epoch: 5| Step: 6
Training loss: 1.5186318159103394
Validation loss: 2.1991511384646096

Epoch: 5| Step: 7
Training loss: 1.8736270666122437
Validation loss: 2.1011769473552704

Epoch: 5| Step: 8
Training loss: 1.962784767150879
Validation loss: 2.093982994556427

Epoch: 5| Step: 9
Training loss: 2.0255210399627686
Validation loss: 2.0440595199664435

Epoch: 5| Step: 10
Training loss: 1.8318464756011963
Validation loss: 2.0945810874303183

Epoch: 5| Step: 11
Training loss: 0.981028139591217
Validation loss: 2.1263305097818375

Epoch: 92| Step: 0
Training loss: 2.4511120319366455
Validation loss: 2.2157533516486487

Epoch: 5| Step: 1
Training loss: 1.7961328029632568
Validation loss: 2.165800521771113

Epoch: 5| Step: 2
Training loss: 1.7243754863739014
Validation loss: 2.0712794760862985

Epoch: 5| Step: 3
Training loss: 1.7923316955566406
Validation loss: 2.1614767014980316

Epoch: 5| Step: 4
Training loss: 2.821843385696411
Validation loss: 2.1382306615511575

Epoch: 5| Step: 5
Training loss: 2.129617691040039
Validation loss: 2.208629091580709

Epoch: 5| Step: 6
Training loss: 1.0679409503936768
Validation loss: 2.1173106332619986

Epoch: 5| Step: 7
Training loss: 1.8104352951049805
Validation loss: 2.121371954679489

Epoch: 5| Step: 8
Training loss: 1.9135291576385498
Validation loss: 2.1918050249417624

Epoch: 5| Step: 9
Training loss: 2.221285343170166
Validation loss: 2.1089418033758798

Epoch: 5| Step: 10
Training loss: 1.348836898803711
Validation loss: 2.195963352918625

Epoch: 5| Step: 11
Training loss: 3.3659279346466064
Validation loss: 2.2268666177988052

Epoch: 93| Step: 0
Training loss: 2.1332173347473145
Validation loss: 2.1733443588018417

Epoch: 5| Step: 1
Training loss: 2.003533124923706
Validation loss: 2.1920549422502518

Epoch: 5| Step: 2
Training loss: 2.040431261062622
Validation loss: 2.1280806014935174

Epoch: 5| Step: 3
Training loss: 1.6436710357666016
Validation loss: 2.214671199520429

Epoch: 5| Step: 4
Training loss: 2.3028130531311035
Validation loss: 2.124737431605657

Epoch: 5| Step: 5
Training loss: 2.4249892234802246
Validation loss: 2.150870735446612

Epoch: 5| Step: 6
Training loss: 1.5227329730987549
Validation loss: 2.062962477405866

Epoch: 5| Step: 7
Training loss: 1.5992460250854492
Validation loss: 2.1227665642897287

Epoch: 5| Step: 8
Training loss: 1.7807056903839111
Validation loss: 2.1350342681010566

Epoch: 5| Step: 9
Training loss: 1.828741431236267
Validation loss: 2.1804674665133157

Epoch: 5| Step: 10
Training loss: 2.2606475353240967
Validation loss: 2.1102496534585953

Epoch: 5| Step: 11
Training loss: 1.9165881872177124
Validation loss: 2.1472003857294717

Epoch: 94| Step: 0
Training loss: 2.060121536254883
Validation loss: 2.0998801489671073

Epoch: 5| Step: 1
Training loss: 1.8547565937042236
Validation loss: 2.185388445854187

Epoch: 5| Step: 2
Training loss: 1.6637318134307861
Validation loss: 2.2094543278217316

Epoch: 5| Step: 3
Training loss: 1.6654201745986938
Validation loss: 2.118106484413147

Epoch: 5| Step: 4
Training loss: 2.3923068046569824
Validation loss: 2.135781188805898

Epoch: 5| Step: 5
Training loss: 1.511254072189331
Validation loss: 2.175410211086273

Epoch: 5| Step: 6
Training loss: 1.695796012878418
Validation loss: 2.1430169443289437

Epoch: 5| Step: 7
Training loss: 1.9430944919586182
Validation loss: 2.0941444635391235

Epoch: 5| Step: 8
Training loss: 2.356646776199341
Validation loss: 2.1987405717372894

Epoch: 5| Step: 9
Training loss: 1.9022762775421143
Validation loss: 2.140218863884608

Epoch: 5| Step: 10
Training loss: 1.8971363306045532
Validation loss: 2.13986403743426

Epoch: 5| Step: 11
Training loss: 1.5346732139587402
Validation loss: 2.137533262372017

Epoch: 95| Step: 0
Training loss: 2.7295074462890625
Validation loss: 2.114864652355512

Epoch: 5| Step: 1
Training loss: 1.658853530883789
Validation loss: 2.171716496348381

Epoch: 5| Step: 2
Training loss: 1.5578391551971436
Validation loss: 2.142484391729037

Epoch: 5| Step: 3
Training loss: 2.296764373779297
Validation loss: 2.161399096250534

Epoch: 5| Step: 4
Training loss: 1.6927289962768555
Validation loss: 2.0645639151334763

Epoch: 5| Step: 5
Training loss: 1.6367063522338867
Validation loss: 2.1947721193234124

Epoch: 5| Step: 6
Training loss: 2.127312183380127
Validation loss: 2.09721302986145

Epoch: 5| Step: 7
Training loss: 2.251523017883301
Validation loss: 2.1025498310724893

Epoch: 5| Step: 8
Training loss: 1.9965492486953735
Validation loss: 2.149366726477941

Epoch: 5| Step: 9
Training loss: 2.404825448989868
Validation loss: 2.144241894284884

Epoch: 5| Step: 10
Training loss: 1.611652135848999
Validation loss: 2.144697591662407

Epoch: 5| Step: 11
Training loss: 2.030301570892334
Validation loss: 2.245870292186737

Epoch: 96| Step: 0
Training loss: 2.4285717010498047
Validation loss: 2.125865196188291

Epoch: 5| Step: 1
Training loss: 2.010633707046509
Validation loss: 2.075660770138105

Epoch: 5| Step: 2
Training loss: 2.3333935737609863
Validation loss: 2.1017671823501587

Epoch: 5| Step: 3
Training loss: 1.7055755853652954
Validation loss: 2.130707855025927

Epoch: 5| Step: 4
Training loss: 1.6493980884552002
Validation loss: 2.0653673509756723

Epoch: 5| Step: 5
Training loss: 2.007218599319458
Validation loss: 2.183364743987719

Epoch: 5| Step: 6
Training loss: 1.9438936710357666
Validation loss: 2.0789870669444404

Epoch: 5| Step: 7
Training loss: 2.312251329421997
Validation loss: 2.0716160784165063

Epoch: 5| Step: 8
Training loss: 1.9322803020477295
Validation loss: 2.1383022169272103

Epoch: 5| Step: 9
Training loss: 1.8805739879608154
Validation loss: 2.0953080356121063

Epoch: 5| Step: 10
Training loss: 2.19303560256958
Validation loss: 2.1092332949241004

Epoch: 5| Step: 11
Training loss: 1.4129823446273804
Validation loss: 2.160372093319893

Epoch: 97| Step: 0
Training loss: 2.077338218688965
Validation loss: 2.1501493006944656

Epoch: 5| Step: 1
Training loss: 2.283367872238159
Validation loss: 2.215586597720782

Epoch: 5| Step: 2
Training loss: 1.7625356912612915
Validation loss: 2.1314333329598107

Epoch: 5| Step: 3
Training loss: 2.0596141815185547
Validation loss: 2.072725291053454

Epoch: 5| Step: 4
Training loss: 1.8827778100967407
Validation loss: 2.183308412631353

Epoch: 5| Step: 5
Training loss: 1.9499130249023438
Validation loss: 2.1734701146682105

Epoch: 5| Step: 6
Training loss: 2.1435818672180176
Validation loss: 2.1146555493275323

Epoch: 5| Step: 7
Training loss: 2.0676209926605225
Validation loss: 2.1412162532409034

Epoch: 5| Step: 8
Training loss: 2.0693936347961426
Validation loss: 2.2037721425294876

Epoch: 5| Step: 9
Training loss: 1.6353704929351807
Validation loss: 2.0997459640105567

Epoch: 5| Step: 10
Training loss: 2.2528598308563232
Validation loss: 2.170778493086497

Epoch: 5| Step: 11
Training loss: 0.8298710584640503
Validation loss: 2.1816831529140472

Epoch: 98| Step: 0
Training loss: 1.6915009021759033
Validation loss: 2.127987210949262

Epoch: 5| Step: 1
Training loss: 1.5490317344665527
Validation loss: 2.1991357505321503

Epoch: 5| Step: 2
Training loss: 1.214290976524353
Validation loss: 2.0919742981592813

Epoch: 5| Step: 3
Training loss: 2.076561450958252
Validation loss: 2.1073638101418815

Epoch: 5| Step: 4
Training loss: 1.4788519144058228
Validation loss: 2.127060815691948

Epoch: 5| Step: 5
Training loss: 2.1564040184020996
Validation loss: 2.175389364361763

Epoch: 5| Step: 6
Training loss: 2.0541329383850098
Validation loss: 2.1036730160315833

Epoch: 5| Step: 7
Training loss: 2.014036178588867
Validation loss: 2.1551262189944587

Epoch: 5| Step: 8
Training loss: 2.291369915008545
Validation loss: 2.1916868140300116

Epoch: 5| Step: 9
Training loss: 1.7502979040145874
Validation loss: 2.130296935637792

Epoch: 5| Step: 10
Training loss: 2.2968502044677734
Validation loss: 2.114894558986028

Epoch: 5| Step: 11
Training loss: 2.0994482040405273
Validation loss: 2.1969342033068338

Epoch: 99| Step: 0
Training loss: 1.816529631614685
Validation loss: 2.1278235465288162

Epoch: 5| Step: 1
Training loss: 1.7891037464141846
Validation loss: 2.19784377515316

Epoch: 5| Step: 2
Training loss: 2.3659069538116455
Validation loss: 2.199903979897499

Epoch: 5| Step: 3
Training loss: 2.2305164337158203
Validation loss: 2.1372324228286743

Epoch: 5| Step: 4
Training loss: 2.244123935699463
Validation loss: 2.1972057074308395

Epoch: 5| Step: 5
Training loss: 2.036698579788208
Validation loss: 2.253617246945699

Epoch: 5| Step: 6
Training loss: 1.9621608257293701
Validation loss: 2.115844984849294

Epoch: 5| Step: 7
Training loss: 2.210289478302002
Validation loss: 2.2032430768013

Epoch: 5| Step: 8
Training loss: 1.6041148900985718
Validation loss: 2.1987817933162055

Epoch: 5| Step: 9
Training loss: 1.682541847229004
Validation loss: 2.1987961729367576

Epoch: 5| Step: 10
Training loss: 2.515498638153076
Validation loss: 2.050230840841929

Epoch: 5| Step: 11
Training loss: 1.13709557056427
Validation loss: 2.2089201559623084

Epoch: 100| Step: 0
Training loss: 2.440178871154785
Validation loss: 2.0802823305130005

Epoch: 5| Step: 1
Training loss: 1.7205791473388672
Validation loss: 2.1572843492031097

Epoch: 5| Step: 2
Training loss: 1.4234368801116943
Validation loss: 2.145349199573199

Epoch: 5| Step: 3
Training loss: 1.6852651834487915
Validation loss: 2.0469741274913154

Epoch: 5| Step: 4
Training loss: 1.8956477642059326
Validation loss: 2.1151664008696875

Epoch: 5| Step: 5
Training loss: 1.988674521446228
Validation loss: 2.1449824372927346

Epoch: 5| Step: 6
Training loss: 2.045219898223877
Validation loss: 2.0689554065465927

Epoch: 5| Step: 7
Training loss: 1.985633134841919
Validation loss: 2.1310960153738656

Epoch: 5| Step: 8
Training loss: 2.025658130645752
Validation loss: 2.150915026664734

Epoch: 5| Step: 9
Training loss: 2.190859317779541
Validation loss: 2.248277952273687

Epoch: 5| Step: 10
Training loss: 1.869720458984375
Validation loss: 2.1932310362656913

Epoch: 5| Step: 11
Training loss: 3.1623752117156982
Validation loss: 2.113443369666735

Epoch: 101| Step: 0
Training loss: 2.242990493774414
Validation loss: 2.119897812604904

Epoch: 5| Step: 1
Training loss: 1.6509382724761963
Validation loss: 2.150625611344973

Epoch: 5| Step: 2
Training loss: 1.8800384998321533
Validation loss: 2.091038405895233

Epoch: 5| Step: 3
Training loss: 2.1884164810180664
Validation loss: 2.1684718430042267

Epoch: 5| Step: 4
Training loss: 2.2832424640655518
Validation loss: 2.233743200699488

Epoch: 5| Step: 5
Training loss: 1.865931510925293
Validation loss: 2.0632518778244653

Epoch: 5| Step: 6
Training loss: 1.7462871074676514
Validation loss: 2.063477039337158

Epoch: 5| Step: 7
Training loss: 1.7533676624298096
Validation loss: 2.129364530245463

Epoch: 5| Step: 8
Training loss: 1.9833511114120483
Validation loss: 2.1375248730182648

Epoch: 5| Step: 9
Training loss: 2.210766077041626
Validation loss: 2.1268040289481482

Epoch: 5| Step: 10
Training loss: 1.4170385599136353
Validation loss: 2.1912842392921448

Epoch: 5| Step: 11
Training loss: 2.1422462463378906
Validation loss: 2.1502114882071814

Epoch: 102| Step: 0
Training loss: 2.2379150390625
Validation loss: 2.2132408718268075

Epoch: 5| Step: 1
Training loss: 2.2776565551757812
Validation loss: 2.1214640537897744

Epoch: 5| Step: 2
Training loss: 2.070382595062256
Validation loss: 2.11186213294665

Epoch: 5| Step: 3
Training loss: 2.2052865028381348
Validation loss: 2.2081676622231803

Epoch: 5| Step: 4
Training loss: 2.321889877319336
Validation loss: 2.1550647169351578

Epoch: 5| Step: 5
Training loss: 1.5117131471633911
Validation loss: 2.1246419548988342

Epoch: 5| Step: 6
Training loss: 2.125162124633789
Validation loss: 2.147368167837461

Epoch: 5| Step: 7
Training loss: 2.349925994873047
Validation loss: 2.078402876853943

Epoch: 5| Step: 8
Training loss: 1.2942136526107788
Validation loss: 2.2214898268381753

Epoch: 5| Step: 9
Training loss: 1.083147406578064
Validation loss: 2.199007193247477

Epoch: 5| Step: 10
Training loss: 2.1499361991882324
Validation loss: 2.1361583173274994

Epoch: 5| Step: 11
Training loss: 1.8194622993469238
Validation loss: 2.0859738985697427

Epoch: 103| Step: 0
Training loss: 1.6184087991714478
Validation loss: 2.1500816891590753

Epoch: 5| Step: 1
Training loss: 1.7283084392547607
Validation loss: 2.1050901114940643

Epoch: 5| Step: 2
Training loss: 2.1031010150909424
Validation loss: 2.0701034367084503

Epoch: 5| Step: 3
Training loss: 1.8386738300323486
Validation loss: 2.117355758945147

Epoch: 5| Step: 4
Training loss: 2.392153739929199
Validation loss: 2.1280660778284073

Epoch: 5| Step: 5
Training loss: 2.2979092597961426
Validation loss: 2.1223904490470886

Epoch: 5| Step: 6
Training loss: 1.9225828647613525
Validation loss: 2.186527118086815

Epoch: 5| Step: 7
Training loss: 1.732804536819458
Validation loss: 2.104075243075689

Epoch: 5| Step: 8
Training loss: 1.4852041006088257
Validation loss: 2.135010321935018

Epoch: 5| Step: 9
Training loss: 2.4260292053222656
Validation loss: 2.0905072689056396

Epoch: 5| Step: 10
Training loss: 1.9510914087295532
Validation loss: 2.140756676594416

Epoch: 5| Step: 11
Training loss: 3.7240052223205566
Validation loss: 2.0981577336788177

Epoch: 104| Step: 0
Training loss: 1.8237626552581787
Validation loss: 2.1506262719631195

Epoch: 5| Step: 1
Training loss: 1.6913779973983765
Validation loss: 2.148005207379659

Epoch: 5| Step: 2
Training loss: 1.3568623065948486
Validation loss: 2.166260063648224

Epoch: 5| Step: 3
Training loss: 1.874668836593628
Validation loss: 2.2022368808587394

Epoch: 5| Step: 4
Training loss: 1.8465344905853271
Validation loss: 2.0533752044041953

Epoch: 5| Step: 5
Training loss: 2.0069522857666016
Validation loss: 2.148335779706637

Epoch: 5| Step: 6
Training loss: 2.079371452331543
Validation loss: 2.100017492969831

Epoch: 5| Step: 7
Training loss: 1.9259116649627686
Validation loss: 2.099857062101364

Epoch: 5| Step: 8
Training loss: 2.6279025077819824
Validation loss: 2.1268709202607474

Epoch: 5| Step: 9
Training loss: 1.6253283023834229
Validation loss: 2.1447509626547494

Epoch: 5| Step: 10
Training loss: 1.7439416646957397
Validation loss: 2.1410453021526337

Epoch: 5| Step: 11
Training loss: 2.631472587585449
Validation loss: 2.1515185683965683

Epoch: 105| Step: 0
Training loss: 1.3779687881469727
Validation loss: 2.1728189984957376

Epoch: 5| Step: 1
Training loss: 1.737187147140503
Validation loss: 2.079944650332133

Epoch: 5| Step: 2
Training loss: 1.8064152002334595
Validation loss: 2.1169757544994354

Epoch: 5| Step: 3
Training loss: 1.954563856124878
Validation loss: 2.1033317297697067

Epoch: 5| Step: 4
Training loss: 2.287155866622925
Validation loss: 2.216714471578598

Epoch: 5| Step: 5
Training loss: 1.7386058568954468
Validation loss: 2.152364502350489

Epoch: 5| Step: 6
Training loss: 1.9568830728530884
Validation loss: 2.152458742260933

Epoch: 5| Step: 7
Training loss: 2.2818472385406494
Validation loss: 2.233998656272888

Epoch: 5| Step: 8
Training loss: 2.2323014736175537
Validation loss: 2.1855061699946723

Epoch: 5| Step: 9
Training loss: 2.0972352027893066
Validation loss: 2.1332982381184897

Epoch: 5| Step: 10
Training loss: 1.64474356174469
Validation loss: 2.0978917678197226

Epoch: 5| Step: 11
Training loss: 2.244307041168213
Validation loss: 2.1598362773656845

Epoch: 106| Step: 0
Training loss: 2.2509844303131104
Validation loss: 2.1505294144153595

Epoch: 5| Step: 1
Training loss: 1.7894370555877686
Validation loss: 2.1700960199038186

Epoch: 5| Step: 2
Training loss: 1.943020224571228
Validation loss: 2.113806222875913

Epoch: 5| Step: 3
Training loss: 1.8412399291992188
Validation loss: 2.1968637158473334

Epoch: 5| Step: 4
Training loss: 1.6425319910049438
Validation loss: 2.260429322719574

Epoch: 5| Step: 5
Training loss: 1.4878792762756348
Validation loss: 2.1572583466768265

Epoch: 5| Step: 6
Training loss: 1.9919277429580688
Validation loss: 2.2395189255476

Epoch: 5| Step: 7
Training loss: 1.9925647974014282
Validation loss: 2.1173753341039023

Epoch: 5| Step: 8
Training loss: 1.6359411478042603
Validation loss: 2.1049372404813766

Epoch: 5| Step: 9
Training loss: 2.3312630653381348
Validation loss: 2.0692919890085855

Epoch: 5| Step: 10
Training loss: 1.9711382389068604
Validation loss: 2.20927424232165

Epoch: 5| Step: 11
Training loss: 2.7363944053649902
Validation loss: 2.1235090593496957

Epoch: 107| Step: 0
Training loss: 1.9947036504745483
Validation loss: 2.226354176799456

Epoch: 5| Step: 1
Training loss: 1.9975837469100952
Validation loss: 2.1711594462394714

Epoch: 5| Step: 2
Training loss: 1.9700502157211304
Validation loss: 2.1818141837914786

Epoch: 5| Step: 3
Training loss: 2.024810314178467
Validation loss: 2.0955088486274085

Epoch: 5| Step: 4
Training loss: 1.900872826576233
Validation loss: 2.1055562446514764

Epoch: 5| Step: 5
Training loss: 2.309492588043213
Validation loss: 2.159862885872523

Epoch: 5| Step: 6
Training loss: 1.9035638570785522
Validation loss: 2.179758886496226

Epoch: 5| Step: 7
Training loss: 1.2546143531799316
Validation loss: 2.1064558178186417

Epoch: 5| Step: 8
Training loss: 1.7519944906234741
Validation loss: 2.187122404575348

Epoch: 5| Step: 9
Training loss: 1.674424409866333
Validation loss: 2.137492368618647

Epoch: 5| Step: 10
Training loss: 2.0080008506774902
Validation loss: 2.067958196004232

Epoch: 5| Step: 11
Training loss: 2.543423891067505
Validation loss: 2.03724534312884

Epoch: 108| Step: 0
Training loss: 1.8702685832977295
Validation loss: 2.1605274428923926

Epoch: 5| Step: 1
Training loss: 1.7839748859405518
Validation loss: 2.119290212790171

Epoch: 5| Step: 2
Training loss: 1.978935956954956
Validation loss: 2.1640899628400803

Epoch: 5| Step: 3
Training loss: 1.5825648307800293
Validation loss: 2.1746641993522644

Epoch: 5| Step: 4
Training loss: 1.5579490661621094
Validation loss: 2.0420584628979364

Epoch: 5| Step: 5
Training loss: 1.8826652765274048
Validation loss: 2.203445707758268

Epoch: 5| Step: 6
Training loss: 2.3408617973327637
Validation loss: 2.1545931299527488

Epoch: 5| Step: 7
Training loss: 1.6321169137954712
Validation loss: 2.157229632139206

Epoch: 5| Step: 8
Training loss: 1.606590986251831
Validation loss: 2.2030628571907678

Epoch: 5| Step: 9
Training loss: 1.9757232666015625
Validation loss: 2.183179865280787

Epoch: 5| Step: 10
Training loss: 2.3522143363952637
Validation loss: 2.1653206745783486

Epoch: 5| Step: 11
Training loss: 2.2414186000823975
Validation loss: 2.184324860572815

Epoch: 109| Step: 0
Training loss: 1.802109956741333
Validation loss: 2.1285434613625207

Epoch: 5| Step: 1
Training loss: 2.1756978034973145
Validation loss: 2.1632290482521057

Epoch: 5| Step: 2
Training loss: 2.1473824977874756
Validation loss: 2.101740762591362

Epoch: 5| Step: 3
Training loss: 1.6245511770248413
Validation loss: 2.1938283989826837

Epoch: 5| Step: 4
Training loss: 1.6949840784072876
Validation loss: 2.168970833222071

Epoch: 5| Step: 5
Training loss: 2.0484719276428223
Validation loss: 2.151448925336202

Epoch: 5| Step: 6
Training loss: 2.038130044937134
Validation loss: 2.2251614133516946

Epoch: 5| Step: 7
Training loss: 2.464026927947998
Validation loss: 2.0508853743473687

Epoch: 5| Step: 8
Training loss: 1.7447131872177124
Validation loss: 2.1671890318393707

Epoch: 5| Step: 9
Training loss: 1.9839904308319092
Validation loss: 2.119624783595403

Epoch: 5| Step: 10
Training loss: 1.681749701499939
Validation loss: 2.0902767181396484

Epoch: 5| Step: 11
Training loss: 1.1308081150054932
Validation loss: 2.15067853530248

Epoch: 110| Step: 0
Training loss: 2.447537899017334
Validation loss: 2.0844391882419586

Epoch: 5| Step: 1
Training loss: 1.8123916387557983
Validation loss: 2.170243332783381

Epoch: 5| Step: 2
Training loss: 2.402784824371338
Validation loss: 2.107703005274137

Epoch: 5| Step: 3
Training loss: 1.204026460647583
Validation loss: 2.193021366993586

Epoch: 5| Step: 4
Training loss: 1.3411445617675781
Validation loss: 2.1169749597708383

Epoch: 5| Step: 5
Training loss: 2.156203031539917
Validation loss: 2.098281666636467

Epoch: 5| Step: 6
Training loss: 1.9583568572998047
Validation loss: 2.1298128018776574

Epoch: 5| Step: 7
Training loss: 1.690469741821289
Validation loss: 2.134444539745649

Epoch: 5| Step: 8
Training loss: 1.9445949792861938
Validation loss: 2.0617300222317376

Epoch: 5| Step: 9
Training loss: 2.34251070022583
Validation loss: 2.1164376189311347

Epoch: 5| Step: 10
Training loss: 1.5794864892959595
Validation loss: 2.0788122763236365

Epoch: 5| Step: 11
Training loss: 1.808395266532898
Validation loss: 2.106550306081772

Epoch: 111| Step: 0
Training loss: 2.1614980697631836
Validation loss: 2.066943407058716

Epoch: 5| Step: 1
Training loss: 1.7450628280639648
Validation loss: 2.0647275149822235

Epoch: 5| Step: 2
Training loss: 2.606154680252075
Validation loss: 2.182234078645706

Epoch: 5| Step: 3
Training loss: 1.8261909484863281
Validation loss: 2.205366571744283

Epoch: 5| Step: 4
Training loss: 2.2118194103240967
Validation loss: 2.1596313069264093

Epoch: 5| Step: 5
Training loss: 1.5303906202316284
Validation loss: 2.2245624164740243

Epoch: 5| Step: 6
Training loss: 1.4514877796173096
Validation loss: 2.1847535322109857

Epoch: 5| Step: 7
Training loss: 1.485984206199646
Validation loss: 2.0527553260326385

Epoch: 5| Step: 8
Training loss: 1.9154682159423828
Validation loss: 2.108847146232923

Epoch: 5| Step: 9
Training loss: 1.8996593952178955
Validation loss: 2.1562410245339074

Epoch: 5| Step: 10
Training loss: 1.9901412725448608
Validation loss: 2.085187166929245

Epoch: 5| Step: 11
Training loss: 0.8399024605751038
Validation loss: 2.1611593862374625

Epoch: 112| Step: 0
Training loss: 2.3522448539733887
Validation loss: 2.0990618069966636

Epoch: 5| Step: 1
Training loss: 1.8202165365219116
Validation loss: 2.1386147340138755

Epoch: 5| Step: 2
Training loss: 1.3247603178024292
Validation loss: 2.148873825867971

Epoch: 5| Step: 3
Training loss: 1.7271966934204102
Validation loss: 2.1450143853823342

Epoch: 5| Step: 4
Training loss: 1.591270089149475
Validation loss: 2.15769362449646

Epoch: 5| Step: 5
Training loss: 2.0143980979919434
Validation loss: 2.100684955716133

Epoch: 5| Step: 6
Training loss: 2.0110785961151123
Validation loss: 2.1322507560253143

Epoch: 5| Step: 7
Training loss: 2.4530835151672363
Validation loss: 2.2477196753025055

Epoch: 5| Step: 8
Training loss: 1.3697831630706787
Validation loss: 2.133912056684494

Epoch: 5| Step: 9
Training loss: 1.7114527225494385
Validation loss: 2.0954298277695975

Epoch: 5| Step: 10
Training loss: 1.9772424697875977
Validation loss: 2.1072441140810647

Epoch: 5| Step: 11
Training loss: 2.3657584190368652
Validation loss: 2.0483033706744513

Epoch: 113| Step: 0
Training loss: 1.9687614440917969
Validation loss: 2.0978861997524896

Epoch: 5| Step: 1
Training loss: 1.9129345417022705
Validation loss: 2.1985926628112793

Epoch: 5| Step: 2
Training loss: 1.2324451208114624
Validation loss: 2.130037873983383

Epoch: 5| Step: 3
Training loss: 2.1570863723754883
Validation loss: 2.220366984605789

Epoch: 5| Step: 4
Training loss: 2.035543918609619
Validation loss: 2.113264406720797

Epoch: 5| Step: 5
Training loss: 1.580919861793518
Validation loss: 2.092099830508232

Epoch: 5| Step: 6
Training loss: 2.327536106109619
Validation loss: 2.2872409522533417

Epoch: 5| Step: 7
Training loss: 2.2825734615325928
Validation loss: 2.181171695391337

Epoch: 5| Step: 8
Training loss: 2.1155600547790527
Validation loss: 2.1660351951917014

Epoch: 5| Step: 9
Training loss: 1.8891537189483643
Validation loss: 2.1658952037493386

Epoch: 5| Step: 10
Training loss: 1.672037124633789
Validation loss: 2.147700289885203

Epoch: 5| Step: 11
Training loss: 0.32818758487701416
Validation loss: 2.1462106108665466

Epoch: 114| Step: 0
Training loss: 1.679152250289917
Validation loss: 2.0709987729787827

Epoch: 5| Step: 1
Training loss: 2.2504563331604004
Validation loss: 2.091715837518374

Epoch: 5| Step: 2
Training loss: 1.660072684288025
Validation loss: 2.1408180445432663

Epoch: 5| Step: 3
Training loss: 2.0883848667144775
Validation loss: 2.0954432487487793

Epoch: 5| Step: 4
Training loss: 1.8998275995254517
Validation loss: 2.1290934483210244

Epoch: 5| Step: 5
Training loss: 2.127149820327759
Validation loss: 2.163427839676539

Epoch: 5| Step: 6
Training loss: 1.749874472618103
Validation loss: 2.2035683492819467

Epoch: 5| Step: 7
Training loss: 2.036409616470337
Validation loss: 2.171997378269831

Epoch: 5| Step: 8
Training loss: 1.6042826175689697
Validation loss: 2.1841705441474915

Epoch: 5| Step: 9
Training loss: 1.7669203281402588
Validation loss: 2.1139384110768638

Epoch: 5| Step: 10
Training loss: 1.7662208080291748
Validation loss: 2.148149753610293

Epoch: 5| Step: 11
Training loss: 3.442281484603882
Validation loss: 2.068990687529246

Epoch: 115| Step: 0
Training loss: 1.8285160064697266
Validation loss: 2.0648824820915856

Epoch: 5| Step: 1
Training loss: 1.9471676349639893
Validation loss: 2.0985012153784433

Epoch: 5| Step: 2
Training loss: 2.2311463356018066
Validation loss: 2.1306195606788

Epoch: 5| Step: 3
Training loss: 2.012969493865967
Validation loss: 2.1263398925463357

Epoch: 5| Step: 4
Training loss: 2.170546770095825
Validation loss: 2.178379570444425

Epoch: 5| Step: 5
Training loss: 1.550102710723877
Validation loss: 2.255644758542379

Epoch: 5| Step: 6
Training loss: 2.419349431991577
Validation loss: 2.12916329006354

Epoch: 5| Step: 7
Training loss: 1.1702765226364136
Validation loss: 2.113393803437551

Epoch: 5| Step: 8
Training loss: 1.4486161470413208
Validation loss: 2.1362761159737906

Epoch: 5| Step: 9
Training loss: 2.06355619430542
Validation loss: 2.191725437839826

Epoch: 5| Step: 10
Training loss: 1.8496830463409424
Validation loss: 2.156207079688708

Epoch: 5| Step: 11
Training loss: 2.4714274406433105
Validation loss: 2.1355200111865997

Epoch: 116| Step: 0
Training loss: 2.014650821685791
Validation loss: 2.188692698876063

Epoch: 5| Step: 1
Training loss: 2.1332573890686035
Validation loss: 2.202884078025818

Epoch: 5| Step: 2
Training loss: 1.9266579151153564
Validation loss: 2.113776629169782

Epoch: 5| Step: 3
Training loss: 1.3814365863800049
Validation loss: 2.2413265854120255

Epoch: 5| Step: 4
Training loss: 1.5589404106140137
Validation loss: 2.1427012383937836

Epoch: 5| Step: 5
Training loss: 2.053168535232544
Validation loss: 2.123737096786499

Epoch: 5| Step: 6
Training loss: 1.7630805969238281
Validation loss: 2.173440823952357

Epoch: 5| Step: 7
Training loss: 1.8292728662490845
Validation loss: 2.1060591439406076

Epoch: 5| Step: 8
Training loss: 1.8716983795166016
Validation loss: 2.1343817114830017

Epoch: 5| Step: 9
Training loss: 2.049246311187744
Validation loss: 2.1098259886105857

Epoch: 5| Step: 10
Training loss: 2.0169544219970703
Validation loss: 2.2012822379668555

Epoch: 5| Step: 11
Training loss: 1.2252485752105713
Validation loss: 2.1964217176040015

Epoch: 117| Step: 0
Training loss: 1.8333790302276611
Validation loss: 2.1185608506202698

Epoch: 5| Step: 1
Training loss: 1.3884236812591553
Validation loss: 2.120743821064631

Epoch: 5| Step: 2
Training loss: 1.3219168186187744
Validation loss: 2.090410446127256

Epoch: 5| Step: 3
Training loss: 2.043950319290161
Validation loss: 2.2293778359889984

Epoch: 5| Step: 4
Training loss: 2.3746533393859863
Validation loss: 2.2600928942362466

Epoch: 5| Step: 5
Training loss: 1.845580816268921
Validation loss: 2.2987287044525146

Epoch: 5| Step: 6
Training loss: 1.7970054149627686
Validation loss: 2.201243052879969

Epoch: 5| Step: 7
Training loss: 1.9833892583847046
Validation loss: 2.257658133904139

Epoch: 5| Step: 8
Training loss: 2.6642022132873535
Validation loss: 2.2586165765921273

Epoch: 5| Step: 9
Training loss: 2.1522889137268066
Validation loss: 2.1973113417625427

Epoch: 5| Step: 10
Training loss: 1.3366397619247437
Validation loss: 2.1312441726525626

Epoch: 5| Step: 11
Training loss: 2.9895050525665283
Validation loss: 2.0920825948317847

Epoch: 118| Step: 0
Training loss: 2.2731211185455322
Validation loss: 2.14710063735644

Epoch: 5| Step: 1
Training loss: 1.5875310897827148
Validation loss: 2.1601531505584717

Epoch: 5| Step: 2
Training loss: 2.0850985050201416
Validation loss: 2.092239335179329

Epoch: 5| Step: 3
Training loss: 2.3621678352355957
Validation loss: 2.2471816738446555

Epoch: 5| Step: 4
Training loss: 2.3980209827423096
Validation loss: 2.2257888267437616

Epoch: 5| Step: 5
Training loss: 1.9700725078582764
Validation loss: 2.1684206078449884

Epoch: 5| Step: 6
Training loss: 1.9300510883331299
Validation loss: 2.1405336360136666

Epoch: 5| Step: 7
Training loss: 2.1785762310028076
Validation loss: 2.276110182205836

Epoch: 5| Step: 8
Training loss: 1.9211008548736572
Validation loss: 2.2139159391323724

Epoch: 5| Step: 9
Training loss: 2.3679394721984863
Validation loss: 2.1885234266519547

Epoch: 5| Step: 10
Training loss: 1.590733289718628
Validation loss: 2.1860276410977044

Epoch: 5| Step: 11
Training loss: 2.337909460067749
Validation loss: 2.180548126498858

Epoch: 119| Step: 0
Training loss: 1.4940173625946045
Validation loss: 2.0438089023033776

Epoch: 5| Step: 1
Training loss: 2.1787543296813965
Validation loss: 2.11628865202268

Epoch: 5| Step: 2
Training loss: 1.581148386001587
Validation loss: 2.154307941595713

Epoch: 5| Step: 3
Training loss: 2.200389862060547
Validation loss: 2.1900856097539267

Epoch: 5| Step: 4
Training loss: 1.4871281385421753
Validation loss: 2.210415934522947

Epoch: 5| Step: 5
Training loss: 2.2046382427215576
Validation loss: 2.251542384425799

Epoch: 5| Step: 6
Training loss: 2.4056284427642822
Validation loss: 2.2133662750323615

Epoch: 5| Step: 7
Training loss: 1.3697868585586548
Validation loss: 2.250473275780678

Epoch: 5| Step: 8
Training loss: 2.1050562858581543
Validation loss: 2.192842428882917

Epoch: 5| Step: 9
Training loss: 2.17095947265625
Validation loss: 2.2329984307289124

Epoch: 5| Step: 10
Training loss: 1.4167457818984985
Validation loss: 2.236979236205419

Epoch: 5| Step: 11
Training loss: 2.0912528038024902
Validation loss: 2.260879561305046

Epoch: 120| Step: 0
Training loss: 2.1847310066223145
Validation loss: 2.214597165584564

Epoch: 5| Step: 1
Training loss: 1.910727858543396
Validation loss: 2.159119332830111

Epoch: 5| Step: 2
Training loss: 1.808805227279663
Validation loss: 2.1009639898935952

Epoch: 5| Step: 3
Training loss: 1.8370847702026367
Validation loss: 2.13861254354318

Epoch: 5| Step: 4
Training loss: 2.291498899459839
Validation loss: 2.1692239741484323

Epoch: 5| Step: 5
Training loss: 1.4251724481582642
Validation loss: 2.1847592989603677

Epoch: 5| Step: 6
Training loss: 2.1108570098876953
Validation loss: 2.145160580674807

Epoch: 5| Step: 7
Training loss: 1.7699754238128662
Validation loss: 2.166788915793101

Epoch: 5| Step: 8
Training loss: 1.6105272769927979
Validation loss: 2.0623312145471573

Epoch: 5| Step: 9
Training loss: 2.2078425884246826
Validation loss: 2.197526435057322

Epoch: 5| Step: 10
Training loss: 2.0687732696533203
Validation loss: 2.1741071542104087

Epoch: 5| Step: 11
Training loss: 2.207899570465088
Validation loss: 2.0969355404376984

Epoch: 121| Step: 0
Training loss: 1.1681482791900635
Validation loss: 2.038393040498098

Epoch: 5| Step: 1
Training loss: 1.2866445779800415
Validation loss: 2.052450949947039

Epoch: 5| Step: 2
Training loss: 2.2709414958953857
Validation loss: 2.163666600982348

Epoch: 5| Step: 3
Training loss: 1.7370294332504272
Validation loss: 2.192146266500155

Epoch: 5| Step: 4
Training loss: 2.3927977085113525
Validation loss: 2.15315118432045

Epoch: 5| Step: 5
Training loss: 1.8383365869522095
Validation loss: 2.222941368818283

Epoch: 5| Step: 6
Training loss: 1.6156673431396484
Validation loss: 2.1857548356056213

Epoch: 5| Step: 7
Training loss: 1.9159046411514282
Validation loss: 2.1250574737787247

Epoch: 5| Step: 8
Training loss: 2.2545981407165527
Validation loss: 2.254185954729716

Epoch: 5| Step: 9
Training loss: 1.8906112909317017
Validation loss: 2.216465840737025

Epoch: 5| Step: 10
Training loss: 1.8001716136932373
Validation loss: 2.1870822509129844

Epoch: 5| Step: 11
Training loss: 2.572037935256958
Validation loss: 2.132452428340912

Epoch: 122| Step: 0
Training loss: 1.922938346862793
Validation loss: 2.176231801509857

Epoch: 5| Step: 1
Training loss: 1.4909260272979736
Validation loss: 2.1937386294205985

Epoch: 5| Step: 2
Training loss: 1.9891042709350586
Validation loss: 2.0944630901018777

Epoch: 5| Step: 3
Training loss: 1.623077154159546
Validation loss: 2.1513674408197403

Epoch: 5| Step: 4
Training loss: 1.62973153591156
Validation loss: 2.1474883208672204

Epoch: 5| Step: 5
Training loss: 2.1275618076324463
Validation loss: 2.1087104876836142

Epoch: 5| Step: 6
Training loss: 1.9994885921478271
Validation loss: 2.1549865504105887

Epoch: 5| Step: 7
Training loss: 2.541015863418579
Validation loss: 2.1545975704987845

Epoch: 5| Step: 8
Training loss: 1.8805853128433228
Validation loss: 2.1427155882120132

Epoch: 5| Step: 9
Training loss: 1.6180099248886108
Validation loss: 2.115911771853765

Epoch: 5| Step: 10
Training loss: 2.2866034507751465
Validation loss: 2.12329193452994

Epoch: 5| Step: 11
Training loss: 1.51861572265625
Validation loss: 2.1478551775217056

Epoch: 123| Step: 0
Training loss: 2.0324018001556396
Validation loss: 2.1761739552021027

Epoch: 5| Step: 1
Training loss: 1.8013654947280884
Validation loss: 2.2179955393075943

Epoch: 5| Step: 2
Training loss: 1.9163230657577515
Validation loss: 2.176543116569519

Epoch: 5| Step: 3
Training loss: 2.2225558757781982
Validation loss: 2.1383771697680154

Epoch: 5| Step: 4
Training loss: 1.4553091526031494
Validation loss: 2.1988613357146582

Epoch: 5| Step: 5
Training loss: 1.7951860427856445
Validation loss: 2.197633291284243

Epoch: 5| Step: 6
Training loss: 1.9819285869598389
Validation loss: 2.199106807510058

Epoch: 5| Step: 7
Training loss: 2.216430187225342
Validation loss: 2.2471054941415787

Epoch: 5| Step: 8
Training loss: 2.0120177268981934
Validation loss: 2.266050174832344

Epoch: 5| Step: 9
Training loss: 1.7893832921981812
Validation loss: 2.2047087252140045

Epoch: 5| Step: 10
Training loss: 1.4633358716964722
Validation loss: 2.1939622263113656

Epoch: 5| Step: 11
Training loss: 1.4176037311553955
Validation loss: 2.2248715460300446

Epoch: 124| Step: 0
Training loss: 1.9017518758773804
Validation loss: 2.091618518034617

Epoch: 5| Step: 1
Training loss: 2.032896041870117
Validation loss: 2.0636286437511444

Epoch: 5| Step: 2
Training loss: 1.7329683303833008
Validation loss: 2.1827137966950736

Epoch: 5| Step: 3
Training loss: 1.462087869644165
Validation loss: 2.210883508125941

Epoch: 5| Step: 4
Training loss: 1.6992318630218506
Validation loss: 2.1770210564136505

Epoch: 5| Step: 5
Training loss: 2.1802101135253906
Validation loss: 2.1178286423285804

Epoch: 5| Step: 6
Training loss: 1.8396943807601929
Validation loss: 2.156155859430631

Epoch: 5| Step: 7
Training loss: 1.570881962776184
Validation loss: 2.1024217853943505

Epoch: 5| Step: 8
Training loss: 2.3411409854888916
Validation loss: 2.1544716556866965

Epoch: 5| Step: 9
Training loss: 1.6367775201797485
Validation loss: 2.0621734907229743

Epoch: 5| Step: 10
Training loss: 2.0089735984802246
Validation loss: 2.1352778474489846

Epoch: 5| Step: 11
Training loss: 2.8360297679901123
Validation loss: 2.1610890924930573

Epoch: 125| Step: 0
Training loss: 2.4460315704345703
Validation loss: 2.0416178852319717

Epoch: 5| Step: 1
Training loss: 1.6231944561004639
Validation loss: 2.091372494896253

Epoch: 5| Step: 2
Training loss: 1.5868462324142456
Validation loss: 2.1269149283568063

Epoch: 5| Step: 3
Training loss: 1.363966941833496
Validation loss: 2.1572923064231873

Epoch: 5| Step: 4
Training loss: 1.9297577142715454
Validation loss: 2.0685363858938217

Epoch: 5| Step: 5
Training loss: 2.4876742362976074
Validation loss: 2.1634728958209357

Epoch: 5| Step: 6
Training loss: 1.251847743988037
Validation loss: 2.2282567024230957

Epoch: 5| Step: 7
Training loss: 2.0205681324005127
Validation loss: 2.1971345792214074

Epoch: 5| Step: 8
Training loss: 1.7590484619140625
Validation loss: 2.1121950646241507

Epoch: 5| Step: 9
Training loss: 1.948423981666565
Validation loss: 2.1785649955272675

Epoch: 5| Step: 10
Training loss: 1.5578112602233887
Validation loss: 2.1569114675124488

Epoch: 5| Step: 11
Training loss: 2.2179434299468994
Validation loss: 2.218655010064443

Epoch: 126| Step: 0
Training loss: 2.2436070442199707
Validation loss: 2.287180701891581

Epoch: 5| Step: 1
Training loss: 1.8081676959991455
Validation loss: 2.1684808234373727

Epoch: 5| Step: 2
Training loss: 2.172849178314209
Validation loss: 2.1614686201016107

Epoch: 5| Step: 3
Training loss: 2.1424648761749268
Validation loss: 2.253740072250366

Epoch: 5| Step: 4
Training loss: 2.2344212532043457
Validation loss: 2.1148402045170465

Epoch: 5| Step: 5
Training loss: 1.1196224689483643
Validation loss: 2.181199073791504

Epoch: 5| Step: 6
Training loss: 2.0457522869110107
Validation loss: 2.1956932892402015

Epoch: 5| Step: 7
Training loss: 1.7869107723236084
Validation loss: 2.1638146738211312

Epoch: 5| Step: 8
Training loss: 1.5880752801895142
Validation loss: 2.1831811169783273

Epoch: 5| Step: 9
Training loss: 1.3942445516586304
Validation loss: 2.0959484378496804

Epoch: 5| Step: 10
Training loss: 1.8854471445083618
Validation loss: 2.192367896437645

Epoch: 5| Step: 11
Training loss: 2.10520076751709
Validation loss: 2.1187897423903146

Epoch: 127| Step: 0
Training loss: 2.0103187561035156
Validation loss: 2.125649909178416

Epoch: 5| Step: 1
Training loss: 1.5084339380264282
Validation loss: 2.112973799308141

Epoch: 5| Step: 2
Training loss: 1.162428855895996
Validation loss: 2.1357213457425437

Epoch: 5| Step: 3
Training loss: 1.9451097249984741
Validation loss: 2.128692706425985

Epoch: 5| Step: 4
Training loss: 2.2512917518615723
Validation loss: 2.199008067448934

Epoch: 5| Step: 5
Training loss: 2.6409072875976562
Validation loss: 2.107399677236875

Epoch: 5| Step: 6
Training loss: 1.501893401145935
Validation loss: 2.009655018647512

Epoch: 5| Step: 7
Training loss: 2.156337261199951
Validation loss: 2.221818228562673

Epoch: 5| Step: 8
Training loss: 1.6744768619537354
Validation loss: 2.0973879794279733

Epoch: 5| Step: 9
Training loss: 2.1704297065734863
Validation loss: 2.1715740114450455

Epoch: 5| Step: 10
Training loss: 1.3056830167770386
Validation loss: 2.1452717582384744

Epoch: 5| Step: 11
Training loss: 0.9979737997055054
Validation loss: 2.1449134747187295

Epoch: 128| Step: 0
Training loss: 1.5792236328125
Validation loss: 2.1772505839665732

Epoch: 5| Step: 1
Training loss: 2.4194529056549072
Validation loss: 2.1067800323168435

Epoch: 5| Step: 2
Training loss: 1.8329709768295288
Validation loss: 2.1068919946750007

Epoch: 5| Step: 3
Training loss: 1.664168357849121
Validation loss: 2.167019322514534

Epoch: 5| Step: 4
Training loss: 1.4929378032684326
Validation loss: 2.187785098950068

Epoch: 5| Step: 5
Training loss: 2.174287796020508
Validation loss: 2.180933023492495

Epoch: 5| Step: 6
Training loss: 2.0233566761016846
Validation loss: 2.230437089999517

Epoch: 5| Step: 7
Training loss: 1.6171802282333374
Validation loss: 2.1546925753355026

Epoch: 5| Step: 8
Training loss: 1.7704966068267822
Validation loss: 2.140675445397695

Epoch: 5| Step: 9
Training loss: 1.7786757946014404
Validation loss: 2.211095377802849

Epoch: 5| Step: 10
Training loss: 1.9554351568222046
Validation loss: 2.085721770922343

Epoch: 5| Step: 11
Training loss: 0.26892995834350586
Validation loss: 2.1744242856899896

Epoch: 129| Step: 0
Training loss: 2.059321880340576
Validation loss: 2.1471059819062552

Epoch: 5| Step: 1
Training loss: 1.7825405597686768
Validation loss: 2.19632280866305

Epoch: 5| Step: 2
Training loss: 1.6732330322265625
Validation loss: 2.1230992625157037

Epoch: 5| Step: 3
Training loss: 1.5012720823287964
Validation loss: 2.2124935189882913

Epoch: 5| Step: 4
Training loss: 2.0259718894958496
Validation loss: 2.10445906718572

Epoch: 5| Step: 5
Training loss: 1.7476537227630615
Validation loss: 2.1770261079072952

Epoch: 5| Step: 6
Training loss: 1.683086633682251
Validation loss: 2.159652198354403

Epoch: 5| Step: 7
Training loss: 1.8589986562728882
Validation loss: 2.14460959037145

Epoch: 5| Step: 8
Training loss: 2.059638261795044
Validation loss: 2.0271949072678885

Epoch: 5| Step: 9
Training loss: 1.6423476934432983
Validation loss: 2.065525675813357

Epoch: 5| Step: 10
Training loss: 1.9348011016845703
Validation loss: 2.1710793177286782

Epoch: 5| Step: 11
Training loss: 1.8691537380218506
Validation loss: 2.0894802610079446

Epoch: 130| Step: 0
Training loss: 1.3500291109085083
Validation loss: 2.139910856882731

Epoch: 5| Step: 1
Training loss: 2.082327127456665
Validation loss: 2.123628795146942

Epoch: 5| Step: 2
Training loss: 1.4056308269500732
Validation loss: 2.208051159977913

Epoch: 5| Step: 3
Training loss: 1.51764976978302
Validation loss: 2.1145079831282296

Epoch: 5| Step: 4
Training loss: 1.4677711725234985
Validation loss: 2.1633335053920746

Epoch: 5| Step: 5
Training loss: 1.8170421123504639
Validation loss: 2.158851698040962

Epoch: 5| Step: 6
Training loss: 1.8748571872711182
Validation loss: 2.1790448178847632

Epoch: 5| Step: 7
Training loss: 2.6303677558898926
Validation loss: 2.2316489815711975

Epoch: 5| Step: 8
Training loss: 1.7216211557388306
Validation loss: 2.142334366838137

Epoch: 5| Step: 9
Training loss: 1.3640564680099487
Validation loss: 2.2125488917032876

Epoch: 5| Step: 10
Training loss: 1.872252106666565
Validation loss: 2.2544945180416107

Epoch: 5| Step: 11
Training loss: 2.1094069480895996
Validation loss: 2.1123301138480506

Epoch: 131| Step: 0
Training loss: 1.762796401977539
Validation loss: 2.2199471245209375

Epoch: 5| Step: 1
Training loss: 1.8748819828033447
Validation loss: 2.1745755871136985

Epoch: 5| Step: 2
Training loss: 1.8654083013534546
Validation loss: 2.150072688857714

Epoch: 5| Step: 3
Training loss: 1.9842634201049805
Validation loss: 2.1667499442895255

Epoch: 5| Step: 4
Training loss: 1.0106563568115234
Validation loss: 2.132977142930031

Epoch: 5| Step: 5
Training loss: 1.791133165359497
Validation loss: 2.109870821237564

Epoch: 5| Step: 6
Training loss: 2.1692402362823486
Validation loss: 2.1760848512252173

Epoch: 5| Step: 7
Training loss: 1.6720165014266968
Validation loss: 2.1411644717057547

Epoch: 5| Step: 8
Training loss: 2.088233470916748
Validation loss: 2.1317372818787894

Epoch: 5| Step: 9
Training loss: 1.8788869380950928
Validation loss: 2.2011639376481376

Epoch: 5| Step: 10
Training loss: 2.1022942066192627
Validation loss: 2.176877131064733

Epoch: 5| Step: 11
Training loss: 0.6256402730941772
Validation loss: 2.07426410416762

Epoch: 132| Step: 0
Training loss: 2.115114688873291
Validation loss: 2.1378876070181527

Epoch: 5| Step: 1
Training loss: 1.6246459484100342
Validation loss: 2.101392229398092

Epoch: 5| Step: 2
Training loss: 1.8092186450958252
Validation loss: 2.1661356588204703

Epoch: 5| Step: 3
Training loss: 2.4014697074890137
Validation loss: 2.083517293135325

Epoch: 5| Step: 4
Training loss: 1.7202355861663818
Validation loss: 2.182554046312968

Epoch: 5| Step: 5
Training loss: 1.447454810142517
Validation loss: 2.1369133492310843

Epoch: 5| Step: 6
Training loss: 1.6978622674942017
Validation loss: 2.157746950785319

Epoch: 5| Step: 7
Training loss: 2.126915216445923
Validation loss: 2.1516969005266824

Epoch: 5| Step: 8
Training loss: 1.4230730533599854
Validation loss: 2.169083540638288

Epoch: 5| Step: 9
Training loss: 2.0559303760528564
Validation loss: 2.183882554372152

Epoch: 5| Step: 10
Training loss: 1.7988160848617554
Validation loss: 2.1303850263357162

Epoch: 5| Step: 11
Training loss: 1.6539000272750854
Validation loss: 2.1717299818992615

Epoch: 133| Step: 0
Training loss: 1.597904920578003
Validation loss: 2.1649016539255777

Epoch: 5| Step: 1
Training loss: 1.449577808380127
Validation loss: 2.1803922057151794

Epoch: 5| Step: 2
Training loss: 1.6771156787872314
Validation loss: 2.2035299191872277

Epoch: 5| Step: 3
Training loss: 1.7819792032241821
Validation loss: 2.113271420200666

Epoch: 5| Step: 4
Training loss: 2.0230722427368164
Validation loss: 2.159713163971901

Epoch: 5| Step: 5
Training loss: 2.461179733276367
Validation loss: 2.148520608743032

Epoch: 5| Step: 6
Training loss: 1.229028582572937
Validation loss: 2.0684382120768228

Epoch: 5| Step: 7
Training loss: 1.9881150722503662
Validation loss: 2.1229086965322495

Epoch: 5| Step: 8
Training loss: 1.7076919078826904
Validation loss: 2.083648771047592

Epoch: 5| Step: 9
Training loss: 1.8277736902236938
Validation loss: 2.1902855237325034

Epoch: 5| Step: 10
Training loss: 2.1479270458221436
Validation loss: 2.0976784229278564

Epoch: 5| Step: 11
Training loss: 2.2000656127929688
Validation loss: 2.2119204501310983

Epoch: 134| Step: 0
Training loss: 1.4362518787384033
Validation loss: 2.1962341417868934

Epoch: 5| Step: 1
Training loss: 1.8154550790786743
Validation loss: 2.1514446487029395

Epoch: 5| Step: 2
Training loss: 1.708359956741333
Validation loss: 2.2014284332593284

Epoch: 5| Step: 3
Training loss: 2.432868480682373
Validation loss: 2.1509916583697

Epoch: 5| Step: 4
Training loss: 1.3440828323364258
Validation loss: 2.1388050417105355

Epoch: 5| Step: 5
Training loss: 1.787632703781128
Validation loss: 2.084042876958847

Epoch: 5| Step: 6
Training loss: 2.0884947776794434
Validation loss: 2.1979377418756485

Epoch: 5| Step: 7
Training loss: 1.6542730331420898
Validation loss: 2.13739184041818

Epoch: 5| Step: 8
Training loss: 1.9621120691299438
Validation loss: 2.121785660584768

Epoch: 5| Step: 9
Training loss: 2.384528636932373
Validation loss: 2.1384018063545227

Epoch: 5| Step: 10
Training loss: 1.445320725440979
Validation loss: 2.04991152882576

Epoch: 5| Step: 11
Training loss: 2.181051731109619
Validation loss: 2.1706724564234414

Epoch: 135| Step: 0
Training loss: 1.8082005977630615
Validation loss: 2.2066246569156647

Epoch: 5| Step: 1
Training loss: 1.4823520183563232
Validation loss: 2.163228064775467

Epoch: 5| Step: 2
Training loss: 1.4213204383850098
Validation loss: 2.1426994800567627

Epoch: 5| Step: 3
Training loss: 1.7586488723754883
Validation loss: 2.1181520223617554

Epoch: 5| Step: 4
Training loss: 1.8530126810073853
Validation loss: 2.1238415092229843

Epoch: 5| Step: 5
Training loss: 1.62604558467865
Validation loss: 2.1589225778977075

Epoch: 5| Step: 6
Training loss: 1.5639970302581787
Validation loss: 2.1696528693040213

Epoch: 5| Step: 7
Training loss: 1.5818511247634888
Validation loss: 2.130452518661817

Epoch: 5| Step: 8
Training loss: 1.8309190273284912
Validation loss: 2.1092600325743356

Epoch: 5| Step: 9
Training loss: 2.099604845046997
Validation loss: 2.211483269929886

Epoch: 5| Step: 10
Training loss: 1.9334595203399658
Validation loss: 2.180653750896454

Epoch: 5| Step: 11
Training loss: 1.2559071779251099
Validation loss: 2.125852420926094

Epoch: 136| Step: 0
Training loss: 2.0385570526123047
Validation loss: 2.168600767850876

Epoch: 5| Step: 1
Training loss: 2.801246166229248
Validation loss: 2.1467758268117905

Epoch: 5| Step: 2
Training loss: 1.5077797174453735
Validation loss: 2.032428835829099

Epoch: 5| Step: 3
Training loss: 1.5528939962387085
Validation loss: 2.1536210775375366

Epoch: 5| Step: 4
Training loss: 1.4508776664733887
Validation loss: 2.172405883669853

Epoch: 5| Step: 5
Training loss: 1.5613902807235718
Validation loss: 2.1509009102980294

Epoch: 5| Step: 6
Training loss: 1.8192665576934814
Validation loss: 2.1346532702445984

Epoch: 5| Step: 7
Training loss: 1.868817925453186
Validation loss: 2.1172711849212646

Epoch: 5| Step: 8
Training loss: 1.995497465133667
Validation loss: 2.0835385819276175

Epoch: 5| Step: 9
Training loss: 1.1666547060012817
Validation loss: 2.152793367703756

Epoch: 5| Step: 10
Training loss: 1.5540902614593506
Validation loss: 2.0898954967657724

Epoch: 5| Step: 11
Training loss: 3.030216693878174
Validation loss: 2.1079590022563934

Epoch: 137| Step: 0
Training loss: 1.931626558303833
Validation loss: 2.205612728993098

Epoch: 5| Step: 1
Training loss: 2.053413152694702
Validation loss: 2.2385553320248923

Epoch: 5| Step: 2
Training loss: 1.7515308856964111
Validation loss: 2.117416058977445

Epoch: 5| Step: 3
Training loss: 1.8139889240264893
Validation loss: 2.1246167918046317

Epoch: 5| Step: 4
Training loss: 2.50915789604187
Validation loss: 2.1991511632998786

Epoch: 5| Step: 5
Training loss: 2.0057530403137207
Validation loss: 2.1539749453465142

Epoch: 5| Step: 6
Training loss: 1.4150803089141846
Validation loss: 2.245840907096863

Epoch: 5| Step: 7
Training loss: 1.5870487689971924
Validation loss: 2.1754657675822577

Epoch: 5| Step: 8
Training loss: 1.5644886493682861
Validation loss: 2.26807893315951

Epoch: 5| Step: 9
Training loss: 1.5963242053985596
Validation loss: 2.2066106100877128

Epoch: 5| Step: 10
Training loss: 1.313819169998169
Validation loss: 2.12370964884758

Epoch: 5| Step: 11
Training loss: 1.1675196886062622
Validation loss: 2.2247601052125296

Epoch: 138| Step: 0
Training loss: 1.513800024986267
Validation loss: 2.1515375872453055

Epoch: 5| Step: 1
Training loss: 1.316952109336853
Validation loss: 2.255886271595955

Epoch: 5| Step: 2
Training loss: 1.6506941318511963
Validation loss: 2.135764772693316

Epoch: 5| Step: 3
Training loss: 2.036694288253784
Validation loss: 2.146497756242752

Epoch: 5| Step: 4
Training loss: 1.0629403591156006
Validation loss: 2.0790525376796722

Epoch: 5| Step: 5
Training loss: 1.8973686695098877
Validation loss: 2.0956860979398093

Epoch: 5| Step: 6
Training loss: 1.46353018283844
Validation loss: 2.1560512433449426

Epoch: 5| Step: 7
Training loss: 1.5766828060150146
Validation loss: 2.1267877717812858

Epoch: 5| Step: 8
Training loss: 2.1908957958221436
Validation loss: 2.186627517143885

Epoch: 5| Step: 9
Training loss: 1.5531500577926636
Validation loss: 2.180898994207382

Epoch: 5| Step: 10
Training loss: 2.8356966972351074
Validation loss: 2.138187696536382

Epoch: 5| Step: 11
Training loss: 2.4720542430877686
Validation loss: 2.134337618947029

Epoch: 139| Step: 0
Training loss: 1.0078392028808594
Validation loss: 2.1230997095505395

Epoch: 5| Step: 1
Training loss: 1.7930729389190674
Validation loss: 2.2622099816799164

Epoch: 5| Step: 2
Training loss: 1.4157910346984863
Validation loss: 2.20867790778478

Epoch: 5| Step: 3
Training loss: 2.0696632862091064
Validation loss: 2.201891139149666

Epoch: 5| Step: 4
Training loss: 1.7263206243515015
Validation loss: 2.0677787164847055

Epoch: 5| Step: 5
Training loss: 1.8066991567611694
Validation loss: 2.2167317966620126

Epoch: 5| Step: 6
Training loss: 1.4888885021209717
Validation loss: 2.162301237384478

Epoch: 5| Step: 7
Training loss: 2.594146251678467
Validation loss: 2.2176773945490518

Epoch: 5| Step: 8
Training loss: 2.146857261657715
Validation loss: 2.1728814244270325

Epoch: 5| Step: 9
Training loss: 1.576238751411438
Validation loss: 2.1528884371121726

Epoch: 5| Step: 10
Training loss: 1.8545067310333252
Validation loss: 2.1184535523255668

Epoch: 5| Step: 11
Training loss: 1.1068685054779053
Validation loss: 2.126139501730601

Epoch: 140| Step: 0
Training loss: 1.365019679069519
Validation loss: 2.1759857833385468

Epoch: 5| Step: 1
Training loss: 1.5953994989395142
Validation loss: 2.237629756331444

Epoch: 5| Step: 2
Training loss: 1.7728052139282227
Validation loss: 2.1214507867892585

Epoch: 5| Step: 3
Training loss: 1.4282792806625366
Validation loss: 2.1653042982021966

Epoch: 5| Step: 4
Training loss: 1.6269458532333374
Validation loss: 2.1634365618228912

Epoch: 5| Step: 5
Training loss: 1.8288695812225342
Validation loss: 2.1408712615569434

Epoch: 5| Step: 6
Training loss: 1.8079683780670166
Validation loss: 2.0887173116207123

Epoch: 5| Step: 7
Training loss: 2.1103971004486084
Validation loss: 2.2023601134618125

Epoch: 5| Step: 8
Training loss: 1.844117522239685
Validation loss: 2.1060973753531775

Epoch: 5| Step: 9
Training loss: 2.0818710327148438
Validation loss: 2.154819220304489

Epoch: 5| Step: 10
Training loss: 1.5562465190887451
Validation loss: 2.161546220382055

Epoch: 5| Step: 11
Training loss: 0.9538528919219971
Validation loss: 2.0584632754325867

Epoch: 141| Step: 0
Training loss: 2.1828110218048096
Validation loss: 2.1998275915781655

Epoch: 5| Step: 1
Training loss: 1.551858901977539
Validation loss: 2.135988935828209

Epoch: 5| Step: 2
Training loss: 1.437448263168335
Validation loss: 2.1484688967466354

Epoch: 5| Step: 3
Training loss: 1.5832964181900024
Validation loss: 2.152960633238157

Epoch: 5| Step: 4
Training loss: 1.6214277744293213
Validation loss: 2.1175765047470727

Epoch: 5| Step: 5
Training loss: 1.4368895292282104
Validation loss: 2.0965787221988044

Epoch: 5| Step: 6
Training loss: 1.8639024496078491
Validation loss: 2.1175360679626465

Epoch: 5| Step: 7
Training loss: 1.6815185546875
Validation loss: 2.1922219743331275

Epoch: 5| Step: 8
Training loss: 1.782555341720581
Validation loss: 2.078234260280927

Epoch: 5| Step: 9
Training loss: 2.4692115783691406
Validation loss: 2.1055022378762565

Epoch: 5| Step: 10
Training loss: 1.5995157957077026
Validation loss: 2.1358731389045715

Epoch: 5| Step: 11
Training loss: 1.3517204523086548
Validation loss: 2.0638997654120126

Epoch: 142| Step: 0
Training loss: 1.2957093715667725
Validation loss: 2.1146313746770224

Epoch: 5| Step: 1
Training loss: 1.758374571800232
Validation loss: 2.1228692680597305

Epoch: 5| Step: 2
Training loss: 1.91879141330719
Validation loss: 2.1679519563913345

Epoch: 5| Step: 3
Training loss: 1.8796972036361694
Validation loss: 2.1466745187838874

Epoch: 5| Step: 4
Training loss: 1.6432090997695923
Validation loss: 2.1060293912887573

Epoch: 5| Step: 5
Training loss: 2.064014196395874
Validation loss: 2.1840059409538903

Epoch: 5| Step: 6
Training loss: 1.9255688190460205
Validation loss: 2.1114258766174316

Epoch: 5| Step: 7
Training loss: 1.8045341968536377
Validation loss: 2.2541790356238685

Epoch: 5| Step: 8
Training loss: 1.9830583333969116
Validation loss: 2.142332454522451

Epoch: 5| Step: 9
Training loss: 1.664923071861267
Validation loss: 2.1055605014165244

Epoch: 5| Step: 10
Training loss: 1.699439287185669
Validation loss: 2.1717241605122886

Epoch: 5| Step: 11
Training loss: 1.71987783908844
Validation loss: 2.1471906900405884

Epoch: 143| Step: 0
Training loss: 1.867274284362793
Validation loss: 2.094619477788607

Epoch: 5| Step: 1
Training loss: 1.9675941467285156
Validation loss: 2.1578930219014487

Epoch: 5| Step: 2
Training loss: 1.8246654272079468
Validation loss: 2.180826554695765

Epoch: 5| Step: 3
Training loss: 1.6404346227645874
Validation loss: 2.167341818412145

Epoch: 5| Step: 4
Training loss: 1.9377695322036743
Validation loss: 2.1562462896108627

Epoch: 5| Step: 5
Training loss: 1.7830917835235596
Validation loss: 2.188535908857981

Epoch: 5| Step: 6
Training loss: 1.6505260467529297
Validation loss: 2.20534910261631

Epoch: 5| Step: 7
Training loss: 1.4062691926956177
Validation loss: 2.1937010089556375

Epoch: 5| Step: 8
Training loss: 1.9925661087036133
Validation loss: 2.194824367761612

Epoch: 5| Step: 9
Training loss: 2.3263840675354004
Validation loss: 2.1986805150906243

Epoch: 5| Step: 10
Training loss: 1.546144723892212
Validation loss: 2.194161464770635

Epoch: 5| Step: 11
Training loss: 0.9647018313407898
Validation loss: 2.157522434989611

Epoch: 144| Step: 0
Training loss: 1.5075594186782837
Validation loss: 2.0948133120934167

Epoch: 5| Step: 1
Training loss: 1.863752007484436
Validation loss: 2.139573593934377

Epoch: 5| Step: 2
Training loss: 1.3832906484603882
Validation loss: 2.124960352977117

Epoch: 5| Step: 3
Training loss: 1.8204851150512695
Validation loss: 2.180268074075381

Epoch: 5| Step: 4
Training loss: 1.968682050704956
Validation loss: 2.113460252682368

Epoch: 5| Step: 5
Training loss: 1.34830904006958
Validation loss: 2.141765385866165

Epoch: 5| Step: 6
Training loss: 1.5488190650939941
Validation loss: 2.12639511624972

Epoch: 5| Step: 7
Training loss: 1.6756147146224976
Validation loss: 2.1080770095189414

Epoch: 5| Step: 8
Training loss: 2.018922805786133
Validation loss: 2.090324113766352

Epoch: 5| Step: 9
Training loss: 1.4490594863891602
Validation loss: 2.1303898096084595

Epoch: 5| Step: 10
Training loss: 1.9732024669647217
Validation loss: 2.119995648662249

Epoch: 5| Step: 11
Training loss: 2.5965380668640137
Validation loss: 2.1905872225761414

Epoch: 145| Step: 0
Training loss: 2.28021502494812
Validation loss: 2.0968072613080344

Epoch: 5| Step: 1
Training loss: 2.4141433238983154
Validation loss: 2.1843850215276084

Epoch: 5| Step: 2
Training loss: 1.944687843322754
Validation loss: 2.1029201497634253

Epoch: 5| Step: 3
Training loss: 1.4734846353530884
Validation loss: 2.132485181093216

Epoch: 5| Step: 4
Training loss: 1.537005066871643
Validation loss: 2.0988858739535012

Epoch: 5| Step: 5
Training loss: 1.4105066061019897
Validation loss: 2.161524956425031

Epoch: 5| Step: 6
Training loss: 1.921510100364685
Validation loss: 2.1710055619478226

Epoch: 5| Step: 7
Training loss: 1.7340114116668701
Validation loss: 2.0863485982020697

Epoch: 5| Step: 8
Training loss: 1.5841938257217407
Validation loss: 2.144597793618838

Epoch: 5| Step: 9
Training loss: 1.7740437984466553
Validation loss: 2.1186587860186896

Epoch: 5| Step: 10
Training loss: 1.3519413471221924
Validation loss: 2.078698461254438

Epoch: 5| Step: 11
Training loss: 1.3695770502090454
Validation loss: 2.169349585970243

Epoch: 146| Step: 0
Training loss: 2.0588958263397217
Validation loss: 2.187776709596316

Epoch: 5| Step: 1
Training loss: 1.4800091981887817
Validation loss: 2.1699088315169015

Epoch: 5| Step: 2
Training loss: 1.8807417154312134
Validation loss: 2.2541198631127677

Epoch: 5| Step: 3
Training loss: 2.0153801441192627
Validation loss: 2.146775414546331

Epoch: 5| Step: 4
Training loss: 1.7480655908584595
Validation loss: 2.2511139412721

Epoch: 5| Step: 5
Training loss: 1.7772939205169678
Validation loss: 2.22492016851902

Epoch: 5| Step: 6
Training loss: 1.9228706359863281
Validation loss: 2.1133302599191666

Epoch: 5| Step: 7
Training loss: 1.6478351354599
Validation loss: 2.127401997645696

Epoch: 5| Step: 8
Training loss: 1.804292917251587
Validation loss: 2.1331678380568824

Epoch: 5| Step: 9
Training loss: 1.7302751541137695
Validation loss: 2.103949944178263

Epoch: 5| Step: 10
Training loss: 1.9284502267837524
Validation loss: 2.0642872005701065

Epoch: 5| Step: 11
Training loss: 1.3046138286590576
Validation loss: 2.0444585929314294

Epoch: 147| Step: 0
Training loss: 2.317786931991577
Validation loss: 2.1304140836000443

Epoch: 5| Step: 1
Training loss: 1.4258472919464111
Validation loss: 2.100255717833837

Epoch: 5| Step: 2
Training loss: 1.0849077701568604
Validation loss: 2.163888802131017

Epoch: 5| Step: 3
Training loss: 1.8655751943588257
Validation loss: 2.185275783141454

Epoch: 5| Step: 4
Training loss: 1.916102409362793
Validation loss: 2.0739033818244934

Epoch: 5| Step: 5
Training loss: 1.5876966714859009
Validation loss: 2.1086943248907724

Epoch: 5| Step: 6
Training loss: 2.382640838623047
Validation loss: 2.1723670164744058

Epoch: 5| Step: 7
Training loss: 1.727216362953186
Validation loss: 2.1035621911287308

Epoch: 5| Step: 8
Training loss: 1.4564331769943237
Validation loss: 2.07742370168368

Epoch: 5| Step: 9
Training loss: 1.3520019054412842
Validation loss: 2.1414941350618997

Epoch: 5| Step: 10
Training loss: 2.031177043914795
Validation loss: 2.127203474442164

Epoch: 5| Step: 11
Training loss: 1.6170655488967896
Validation loss: 2.167217507958412

Epoch: 148| Step: 0
Training loss: 1.776244878768921
Validation loss: 2.130132590730985

Epoch: 5| Step: 1
Training loss: 1.2882072925567627
Validation loss: 2.0996701469024024

Epoch: 5| Step: 2
Training loss: 1.129623293876648
Validation loss: 2.200164978702863

Epoch: 5| Step: 3
Training loss: 1.5410257577896118
Validation loss: 2.1204697291056314

Epoch: 5| Step: 4
Training loss: 1.9372150897979736
Validation loss: 2.090682382384936

Epoch: 5| Step: 5
Training loss: 1.5733635425567627
Validation loss: 2.1138271441062293

Epoch: 5| Step: 6
Training loss: 1.4895013570785522
Validation loss: 2.1219405134518943

Epoch: 5| Step: 7
Training loss: 1.9850581884384155
Validation loss: 2.161298001805941

Epoch: 5| Step: 8
Training loss: 1.9727888107299805
Validation loss: 2.18543008963267

Epoch: 5| Step: 9
Training loss: 2.0614161491394043
Validation loss: 2.2812674790620804

Epoch: 5| Step: 10
Training loss: 2.2750682830810547
Validation loss: 2.1530599196751914

Epoch: 5| Step: 11
Training loss: 2.4656529426574707
Validation loss: 2.1663106977939606

Epoch: 149| Step: 0
Training loss: 1.917694091796875
Validation loss: 2.21373043457667

Epoch: 5| Step: 1
Training loss: 1.2402288913726807
Validation loss: 2.10877255598704

Epoch: 5| Step: 2
Training loss: 1.7431329488754272
Validation loss: 2.08366988102595

Epoch: 5| Step: 3
Training loss: 2.2972583770751953
Validation loss: 2.126860037446022

Epoch: 5| Step: 4
Training loss: 1.3224356174468994
Validation loss: 2.1650335093339286

Epoch: 5| Step: 5
Training loss: 1.8802716732025146
Validation loss: 2.143417070309321

Epoch: 5| Step: 6
Training loss: 1.90909743309021
Validation loss: 2.173527866601944

Epoch: 5| Step: 7
Training loss: 1.6280052661895752
Validation loss: 2.083989381790161

Epoch: 5| Step: 8
Training loss: 1.5673763751983643
Validation loss: 2.21336796383063

Epoch: 5| Step: 9
Training loss: 1.8192812204360962
Validation loss: 2.124897023042043

Epoch: 5| Step: 10
Training loss: 1.511832594871521
Validation loss: 2.2053681711355844

Epoch: 5| Step: 11
Training loss: 2.594715118408203
Validation loss: 2.082764054338137

Epoch: 150| Step: 0
Training loss: 2.0668227672576904
Validation loss: 2.113960122068723

Epoch: 5| Step: 1
Training loss: 1.97689688205719
Validation loss: 2.1147089848915734

Epoch: 5| Step: 2
Training loss: 1.5353400707244873
Validation loss: 2.0848192423582077

Epoch: 5| Step: 3
Training loss: 1.7157304286956787
Validation loss: 2.0826689352591834

Epoch: 5| Step: 4
Training loss: 1.418192982673645
Validation loss: 2.1787055184443793

Epoch: 5| Step: 5
Training loss: 1.751875638961792
Validation loss: 2.1275453170140586

Epoch: 5| Step: 6
Training loss: 1.6818729639053345
Validation loss: 2.23102867603302

Epoch: 5| Step: 7
Training loss: 2.190370559692383
Validation loss: 2.1157700220743814

Epoch: 5| Step: 8
Training loss: 1.616389274597168
Validation loss: 2.141203155120214

Epoch: 5| Step: 9
Training loss: 1.7412452697753906
Validation loss: 2.2773757725954056

Epoch: 5| Step: 10
Training loss: 1.4467861652374268
Validation loss: 2.2092621276775994

Epoch: 5| Step: 11
Training loss: 2.481807231903076
Validation loss: 2.1379067997137704

Epoch: 151| Step: 0
Training loss: 1.1304737329483032
Validation loss: 2.22879030307134

Epoch: 5| Step: 1
Training loss: 1.1928094625473022
Validation loss: 2.0730013797680535

Epoch: 5| Step: 2
Training loss: 1.7571709156036377
Validation loss: 2.2272829016049704

Epoch: 5| Step: 3
Training loss: 1.9491024017333984
Validation loss: 2.1179390301307044

Epoch: 5| Step: 4
Training loss: 1.780811071395874
Validation loss: 2.1538014511267343

Epoch: 5| Step: 5
Training loss: 1.3628263473510742
Validation loss: 2.1414697021245956

Epoch: 5| Step: 6
Training loss: 1.4571717977523804
Validation loss: 2.110548511147499

Epoch: 5| Step: 7
Training loss: 2.099456787109375
Validation loss: 2.130750278631846

Epoch: 5| Step: 8
Training loss: 1.4968318939208984
Validation loss: 2.110021710395813

Epoch: 5| Step: 9
Training loss: 2.102623462677002
Validation loss: 2.1009702185789743

Epoch: 5| Step: 10
Training loss: 1.898003339767456
Validation loss: 2.1494454642136893

Epoch: 5| Step: 11
Training loss: 3.0755715370178223
Validation loss: 2.1269941478967667

Epoch: 152| Step: 0
Training loss: 1.3903852701187134
Validation loss: 2.132346694668134

Epoch: 5| Step: 1
Training loss: 1.5655771493911743
Validation loss: 2.1506044814984002

Epoch: 5| Step: 2
Training loss: 1.8989779949188232
Validation loss: 2.1329207569360733

Epoch: 5| Step: 3
Training loss: 1.263400673866272
Validation loss: 2.0639413446187973

Epoch: 5| Step: 4
Training loss: 1.0150877237319946
Validation loss: 2.1859559218088784

Epoch: 5| Step: 5
Training loss: 2.1692357063293457
Validation loss: 2.1166089673837027

Epoch: 5| Step: 6
Training loss: 1.4733245372772217
Validation loss: 2.1604087203741074

Epoch: 5| Step: 7
Training loss: 2.229300022125244
Validation loss: 2.246768688162168

Epoch: 5| Step: 8
Training loss: 2.455972194671631
Validation loss: 2.18609186510245

Epoch: 5| Step: 9
Training loss: 1.9421653747558594
Validation loss: 2.212433268626531

Epoch: 5| Step: 10
Training loss: 1.1472735404968262
Validation loss: 2.2528503984212875

Epoch: 5| Step: 11
Training loss: 1.022011399269104
Validation loss: 2.2705041070779166

Epoch: 153| Step: 0
Training loss: 2.3268308639526367
Validation loss: 2.1100418468316398

Epoch: 5| Step: 1
Training loss: 1.6194499731063843
Validation loss: 2.170162707567215

Epoch: 5| Step: 2
Training loss: 1.8516594171524048
Validation loss: 2.1717251936594644

Epoch: 5| Step: 3
Training loss: 1.7623573541641235
Validation loss: 2.089089259505272

Epoch: 5| Step: 4
Training loss: 1.7972005605697632
Validation loss: 2.1281419595082602

Epoch: 5| Step: 5
Training loss: 1.6637061834335327
Validation loss: 2.1056706408659616

Epoch: 5| Step: 6
Training loss: 1.2239662408828735
Validation loss: 2.155775879820188

Epoch: 5| Step: 7
Training loss: 1.325962781906128
Validation loss: 2.1651312708854675

Epoch: 5| Step: 8
Training loss: 1.3719722032546997
Validation loss: 2.077840988834699

Epoch: 5| Step: 9
Training loss: 1.5606149435043335
Validation loss: 2.113584414124489

Epoch: 5| Step: 10
Training loss: 1.7822242975234985
Validation loss: 2.1399912933508554

Epoch: 5| Step: 11
Training loss: 2.492852210998535
Validation loss: 2.1359710345665612

Epoch: 154| Step: 0
Training loss: 1.282716989517212
Validation loss: 2.044383386770884

Epoch: 5| Step: 1
Training loss: 1.5987257957458496
Validation loss: 2.1796065072218576

Epoch: 5| Step: 2
Training loss: 1.5781714916229248
Validation loss: 2.126038064559301

Epoch: 5| Step: 3
Training loss: 2.020484447479248
Validation loss: 2.2363692770401635

Epoch: 5| Step: 4
Training loss: 1.31651771068573
Validation loss: 2.146417344609896

Epoch: 5| Step: 5
Training loss: 1.3275699615478516
Validation loss: 2.170322597026825

Epoch: 5| Step: 6
Training loss: 1.6657154560089111
Validation loss: 2.184023439884186

Epoch: 5| Step: 7
Training loss: 1.5753471851348877
Validation loss: 2.233154142896334

Epoch: 5| Step: 8
Training loss: 2.0210204124450684
Validation loss: 2.177778790394465

Epoch: 5| Step: 9
Training loss: 2.42638897895813
Validation loss: 2.1089062988758087

Epoch: 5| Step: 10
Training loss: 1.6994237899780273
Validation loss: 2.1583466629187265

Epoch: 5| Step: 11
Training loss: 2.2136635780334473
Validation loss: 2.2089673429727554

Epoch: 155| Step: 0
Training loss: 2.097665786743164
Validation loss: 2.1798236121733985

Epoch: 5| Step: 1
Training loss: 1.9012928009033203
Validation loss: 2.087871899207433

Epoch: 5| Step: 2
Training loss: 1.697977066040039
Validation loss: 2.1381223499774933

Epoch: 5| Step: 3
Training loss: 1.8289377689361572
Validation loss: 2.155634010831515

Epoch: 5| Step: 4
Training loss: 1.4561370611190796
Validation loss: 2.1873839596907296

Epoch: 5| Step: 5
Training loss: 1.6448818445205688
Validation loss: 2.1813651273647943

Epoch: 5| Step: 6
Training loss: 2.0810742378234863
Validation loss: 2.183233564098676

Epoch: 5| Step: 7
Training loss: 1.3211971521377563
Validation loss: 2.1472389101982117

Epoch: 5| Step: 8
Training loss: 1.8946115970611572
Validation loss: 2.200910414258639

Epoch: 5| Step: 9
Training loss: 1.4367939233779907
Validation loss: 2.1598731180032096

Epoch: 5| Step: 10
Training loss: 1.6383308172225952
Validation loss: 2.1518253087997437

Epoch: 5| Step: 11
Training loss: 0.42832422256469727
Validation loss: 2.190743754307429

Epoch: 156| Step: 0
Training loss: 1.5122047662734985
Validation loss: 2.261516491572062

Epoch: 5| Step: 1
Training loss: 1.043354868888855
Validation loss: 2.1341350972652435

Epoch: 5| Step: 2
Training loss: 1.9549462795257568
Validation loss: 2.2095569719870887

Epoch: 5| Step: 3
Training loss: 1.7260433435440063
Validation loss: 2.266414155562719

Epoch: 5| Step: 4
Training loss: 2.3226561546325684
Validation loss: 2.2838115990161896

Epoch: 5| Step: 5
Training loss: 1.5900577306747437
Validation loss: 2.094314843416214

Epoch: 5| Step: 6
Training loss: 1.2650668621063232
Validation loss: 2.1796375264724097

Epoch: 5| Step: 7
Training loss: 1.6174490451812744
Validation loss: 2.0917852769295373

Epoch: 5| Step: 8
Training loss: 1.5758671760559082
Validation loss: 2.1422928820053735

Epoch: 5| Step: 9
Training loss: 2.7976980209350586
Validation loss: 2.1849474956591926

Epoch: 5| Step: 10
Training loss: 1.269327163696289
Validation loss: 2.1777247140804925

Epoch: 5| Step: 11
Training loss: 1.2337456941604614
Validation loss: 2.1384564886490502

Epoch: 157| Step: 0
Training loss: 1.4494738578796387
Validation loss: 2.1360585192839303

Epoch: 5| Step: 1
Training loss: 1.409759283065796
Validation loss: 2.012394294142723

Epoch: 5| Step: 2
Training loss: 1.4715064764022827
Validation loss: 2.0937000115712485

Epoch: 5| Step: 3
Training loss: 1.611270546913147
Validation loss: 2.134225790699323

Epoch: 5| Step: 4
Training loss: 2.6153697967529297
Validation loss: 2.221789136528969

Epoch: 5| Step: 5
Training loss: 1.848629355430603
Validation loss: 2.1927108267943063

Epoch: 5| Step: 6
Training loss: 1.2789325714111328
Validation loss: 2.162427395582199

Epoch: 5| Step: 7
Training loss: 1.5726362466812134
Validation loss: 2.1900341560443244

Epoch: 5| Step: 8
Training loss: 1.146117925643921
Validation loss: 2.1866839875777564

Epoch: 5| Step: 9
Training loss: 2.058262825012207
Validation loss: 2.1444681038459144

Epoch: 5| Step: 10
Training loss: 1.537024736404419
Validation loss: 2.1917685170968375

Epoch: 5| Step: 11
Training loss: 0.9175021648406982
Validation loss: 2.1823203762372336

Epoch: 158| Step: 0
Training loss: 1.5193980932235718
Validation loss: 2.1784037947654724

Epoch: 5| Step: 1
Training loss: 1.195255994796753
Validation loss: 2.1677137911319733

Epoch: 5| Step: 2
Training loss: 1.6328372955322266
Validation loss: 2.1848336309194565

Epoch: 5| Step: 3
Training loss: 1.5140854120254517
Validation loss: 2.1818333814541497

Epoch: 5| Step: 4
Training loss: 1.8983631134033203
Validation loss: 2.2393726259469986

Epoch: 5| Step: 5
Training loss: 1.3088659048080444
Validation loss: 2.1858209123214087

Epoch: 5| Step: 6
Training loss: 2.051344633102417
Validation loss: 2.233672300974528

Epoch: 5| Step: 7
Training loss: 1.2163320779800415
Validation loss: 2.1430214196443558

Epoch: 5| Step: 8
Training loss: 1.430162787437439
Validation loss: 2.0714373787244162

Epoch: 5| Step: 9
Training loss: 1.951974868774414
Validation loss: 2.1904205630222955

Epoch: 5| Step: 10
Training loss: 2.0945041179656982
Validation loss: 2.053651973605156

Epoch: 5| Step: 11
Training loss: 3.141458511352539
Validation loss: 2.1583717266718545

Epoch: 159| Step: 0
Training loss: 1.7238199710845947
Validation loss: 2.088068276643753

Epoch: 5| Step: 1
Training loss: 1.5456198453903198
Validation loss: 2.288927068312963

Epoch: 5| Step: 2
Training loss: 1.7941639423370361
Validation loss: 2.0987917880217233

Epoch: 5| Step: 3
Training loss: 1.8186571598052979
Validation loss: 2.228745291630427

Epoch: 5| Step: 4
Training loss: 1.7096469402313232
Validation loss: 2.2422183553377786

Epoch: 5| Step: 5
Training loss: 1.9580034017562866
Validation loss: 2.1452577809492746

Epoch: 5| Step: 6
Training loss: 1.7246021032333374
Validation loss: 2.245370109875997

Epoch: 5| Step: 7
Training loss: 1.4481627941131592
Validation loss: 2.1940567394097648

Epoch: 5| Step: 8
Training loss: 1.6198184490203857
Validation loss: 2.08847085138162

Epoch: 5| Step: 9
Training loss: 1.7366743087768555
Validation loss: 2.1175170640150704

Epoch: 5| Step: 10
Training loss: 1.065877914428711
Validation loss: 2.148416375120481

Epoch: 5| Step: 11
Training loss: 2.443941831588745
Validation loss: 2.184336950381597

Epoch: 160| Step: 0
Training loss: 2.094499111175537
Validation loss: 2.1688026984532676

Epoch: 5| Step: 1
Training loss: 1.7071590423583984
Validation loss: 2.1377223382393518

Epoch: 5| Step: 2
Training loss: 1.9893989562988281
Validation loss: 2.149849012494087

Epoch: 5| Step: 3
Training loss: 1.34212327003479
Validation loss: 2.248607705036799

Epoch: 5| Step: 4
Training loss: 1.9325774908065796
Validation loss: 2.19620248178641

Epoch: 5| Step: 5
Training loss: 1.3154103755950928
Validation loss: 2.1333804627259574

Epoch: 5| Step: 6
Training loss: 1.642416000366211
Validation loss: 2.1684351563453674

Epoch: 5| Step: 7
Training loss: 1.7552235126495361
Validation loss: 2.0937444468339286

Epoch: 5| Step: 8
Training loss: 2.0756773948669434
Validation loss: 2.2344242533047995

Epoch: 5| Step: 9
Training loss: 1.2898038625717163
Validation loss: 2.173269659280777

Epoch: 5| Step: 10
Training loss: 1.2239872217178345
Validation loss: 2.198060527443886

Epoch: 5| Step: 11
Training loss: 1.2680890560150146
Validation loss: 2.06062317887942

Epoch: 161| Step: 0
Training loss: 1.3105388879776
Validation loss: 2.1560288866360984

Epoch: 5| Step: 1
Training loss: 1.8333423137664795
Validation loss: 2.153741419315338

Epoch: 5| Step: 2
Training loss: 1.7332737445831299
Validation loss: 2.2243063002824783

Epoch: 5| Step: 3
Training loss: 1.5591490268707275
Validation loss: 2.193904588619868

Epoch: 5| Step: 4
Training loss: 1.8286834955215454
Validation loss: 2.2918251703182855

Epoch: 5| Step: 5
Training loss: 2.152974843978882
Validation loss: 2.2107529789209366

Epoch: 5| Step: 6
Training loss: 1.5029017925262451
Validation loss: 2.2717162718375525

Epoch: 5| Step: 7
Training loss: 1.5960705280303955
Validation loss: 2.2053864896297455

Epoch: 5| Step: 8
Training loss: 1.70733642578125
Validation loss: 2.186805471777916

Epoch: 5| Step: 9
Training loss: 1.8675025701522827
Validation loss: 2.1705755392710366

Epoch: 5| Step: 10
Training loss: 1.205335259437561
Validation loss: 2.1616403410832086

Epoch: 5| Step: 11
Training loss: 1.3303735256195068
Validation loss: 2.173711806535721

Epoch: 162| Step: 0
Training loss: 1.1678078174591064
Validation loss: 2.1898388663927713

Epoch: 5| Step: 1
Training loss: 1.350557565689087
Validation loss: 2.1053171306848526

Epoch: 5| Step: 2
Training loss: 1.494882583618164
Validation loss: 2.143497253457705

Epoch: 5| Step: 3
Training loss: 1.7534220218658447
Validation loss: 2.132371708750725

Epoch: 5| Step: 4
Training loss: 1.591528296470642
Validation loss: 2.133949930469195

Epoch: 5| Step: 5
Training loss: 1.8869349956512451
Validation loss: 2.137605885664622

Epoch: 5| Step: 6
Training loss: 2.136695623397827
Validation loss: 2.0932046870390573

Epoch: 5| Step: 7
Training loss: 1.4563162326812744
Validation loss: 2.152515878280004

Epoch: 5| Step: 8
Training loss: 2.042667865753174
Validation loss: 2.0649138490358987

Epoch: 5| Step: 9
Training loss: 1.3258056640625
Validation loss: 2.142112428943316

Epoch: 5| Step: 10
Training loss: 1.4412087202072144
Validation loss: 2.135153442621231

Epoch: 5| Step: 11
Training loss: 1.3786582946777344
Validation loss: 2.1304319898287454

Epoch: 163| Step: 0
Training loss: 1.5503603219985962
Validation loss: 2.2325932482878366

Epoch: 5| Step: 1
Training loss: 1.441704511642456
Validation loss: 2.1064193745454154

Epoch: 5| Step: 2
Training loss: 2.0777504444122314
Validation loss: 2.2127384146054587

Epoch: 5| Step: 3
Training loss: 1.8114795684814453
Validation loss: 2.087953398625056

Epoch: 5| Step: 4
Training loss: 2.0023703575134277
Validation loss: 2.135911454757055

Epoch: 5| Step: 5
Training loss: 1.4701961278915405
Validation loss: 2.282775272925695

Epoch: 5| Step: 6
Training loss: 1.761193871498108
Validation loss: 2.145732099811236

Epoch: 5| Step: 7
Training loss: 1.2903099060058594
Validation loss: 2.2439045707384744

Epoch: 5| Step: 8
Training loss: 2.124910831451416
Validation loss: 2.20016040901343

Epoch: 5| Step: 9
Training loss: 1.3258817195892334
Validation loss: 2.147230808933576

Epoch: 5| Step: 10
Training loss: 1.151177167892456
Validation loss: 2.1562195122241974

Epoch: 5| Step: 11
Training loss: 0.8929882645606995
Validation loss: 2.253188153107961

Epoch: 164| Step: 0
Training loss: 1.9690792560577393
Validation loss: 2.145352060596148

Epoch: 5| Step: 1
Training loss: 1.3092540502548218
Validation loss: 2.1633253941933313

Epoch: 5| Step: 2
Training loss: 1.0962198972702026
Validation loss: 2.223583002885183

Epoch: 5| Step: 3
Training loss: 2.160212993621826
Validation loss: 2.179228271047274

Epoch: 5| Step: 4
Training loss: 1.422684907913208
Validation loss: 2.281857962409655

Epoch: 5| Step: 5
Training loss: 1.3003766536712646
Validation loss: 2.171918734908104

Epoch: 5| Step: 6
Training loss: 1.4004260301589966
Validation loss: 2.157255912820498

Epoch: 5| Step: 7
Training loss: 1.2784395217895508
Validation loss: 2.1864898254474006

Epoch: 5| Step: 8
Training loss: 1.791731595993042
Validation loss: 2.0709035396575928

Epoch: 5| Step: 9
Training loss: 1.654871940612793
Validation loss: 2.255362311999003

Epoch: 5| Step: 10
Training loss: 2.4368081092834473
Validation loss: 2.194365292787552

Epoch: 5| Step: 11
Training loss: 1.3260960578918457
Validation loss: 2.2093938837448754

Epoch: 165| Step: 0
Training loss: 1.7881635427474976
Validation loss: 2.1479833523432412

Epoch: 5| Step: 1
Training loss: 1.3586617708206177
Validation loss: 2.190893441438675

Epoch: 5| Step: 2
Training loss: 1.7798717021942139
Validation loss: 2.113820935289065

Epoch: 5| Step: 3
Training loss: 1.6009916067123413
Validation loss: 2.214770366748174

Epoch: 5| Step: 4
Training loss: 1.660604476928711
Validation loss: 2.109113872051239

Epoch: 5| Step: 5
Training loss: 1.448296308517456
Validation loss: 2.1771653493245444

Epoch: 5| Step: 6
Training loss: 1.5123618841171265
Validation loss: 2.1648828834295273

Epoch: 5| Step: 7
Training loss: 1.3801168203353882
Validation loss: 2.1700805922349296

Epoch: 5| Step: 8
Training loss: 2.07332181930542
Validation loss: 2.158561716477076

Epoch: 5| Step: 9
Training loss: 1.6027727127075195
Validation loss: 2.1405723989009857

Epoch: 5| Step: 10
Training loss: 1.8438317775726318
Validation loss: 2.17601685722669

Epoch: 5| Step: 11
Training loss: 1.6671452522277832
Validation loss: 2.1417398750782013

Epoch: 166| Step: 0
Training loss: 1.4124492406845093
Validation loss: 2.1641368518273034

Epoch: 5| Step: 1
Training loss: 1.0721447467803955
Validation loss: 2.180733879407247

Epoch: 5| Step: 2
Training loss: 1.2542463541030884
Validation loss: 2.184116800626119

Epoch: 5| Step: 3
Training loss: 1.9147717952728271
Validation loss: 2.2452047715584436

Epoch: 5| Step: 4
Training loss: 1.2159738540649414
Validation loss: 2.0870089878638587

Epoch: 5| Step: 5
Training loss: 1.1717745065689087
Validation loss: 2.0738487243652344

Epoch: 5| Step: 6
Training loss: 1.8024132251739502
Validation loss: 2.2357570827007294

Epoch: 5| Step: 7
Training loss: 2.1931986808776855
Validation loss: 2.1724411696195602

Epoch: 5| Step: 8
Training loss: 1.8989884853363037
Validation loss: 2.1128905415534973

Epoch: 5| Step: 9
Training loss: 1.5823038816452026
Validation loss: 2.221154655019442

Epoch: 5| Step: 10
Training loss: 1.9438730478286743
Validation loss: 2.188198462128639

Epoch: 5| Step: 11
Training loss: 1.7400058507919312
Validation loss: 2.20370422800382

Epoch: 167| Step: 0
Training loss: 1.7715692520141602
Validation loss: 2.1607105980316796

Epoch: 5| Step: 1
Training loss: 1.859500527381897
Validation loss: 2.228856315215429

Epoch: 5| Step: 2
Training loss: 1.2418346405029297
Validation loss: 2.272512967387835

Epoch: 5| Step: 3
Training loss: 1.773036003112793
Validation loss: 2.24500040213267

Epoch: 5| Step: 4
Training loss: 2.1974732875823975
Validation loss: 2.2030249337355294

Epoch: 5| Step: 5
Training loss: 1.1774104833602905
Validation loss: 2.2094222207864127

Epoch: 5| Step: 6
Training loss: 1.6429555416107178
Validation loss: 2.292265991369883

Epoch: 5| Step: 7
Training loss: 1.8099002838134766
Validation loss: 2.1754367699225745

Epoch: 5| Step: 8
Training loss: 1.430687665939331
Validation loss: 2.1017709920803704

Epoch: 5| Step: 9
Training loss: 1.7037382125854492
Validation loss: 2.255968297521273

Epoch: 5| Step: 10
Training loss: 1.7083756923675537
Validation loss: 2.144844780365626

Epoch: 5| Step: 11
Training loss: 0.5861450433731079
Validation loss: 2.2306142250696817

Epoch: 168| Step: 0
Training loss: 1.7717676162719727
Validation loss: 2.233213151494662

Epoch: 5| Step: 1
Training loss: 1.810049057006836
Validation loss: 2.1618839850028357

Epoch: 5| Step: 2
Training loss: 1.7379153966903687
Validation loss: 2.141090919574102

Epoch: 5| Step: 3
Training loss: 1.775254249572754
Validation loss: 2.225126897295316

Epoch: 5| Step: 4
Training loss: 1.5186357498168945
Validation loss: 2.1178662925958633

Epoch: 5| Step: 5
Training loss: 1.703442931175232
Validation loss: 2.170868754386902

Epoch: 5| Step: 6
Training loss: 1.2305645942687988
Validation loss: 2.19553970793883

Epoch: 5| Step: 7
Training loss: 1.9606940746307373
Validation loss: 2.189481864372889

Epoch: 5| Step: 8
Training loss: 1.5025306940078735
Validation loss: 2.099422737956047

Epoch: 5| Step: 9
Training loss: 1.6664050817489624
Validation loss: 2.200496400396029

Epoch: 5| Step: 10
Training loss: 1.0736610889434814
Validation loss: 2.280582537253698

Epoch: 5| Step: 11
Training loss: 0.8895490169525146
Validation loss: 2.167041098078092

Epoch: 169| Step: 0
Training loss: 1.6393892765045166
Validation loss: 2.1586852371692657

Epoch: 5| Step: 1
Training loss: 1.236502766609192
Validation loss: 2.1723263561725616

Epoch: 5| Step: 2
Training loss: 1.320928931236267
Validation loss: 2.2198185125986734

Epoch: 5| Step: 3
Training loss: 1.7777740955352783
Validation loss: 2.2403123676776886

Epoch: 5| Step: 4
Training loss: 1.9439427852630615
Validation loss: 2.153027445077896

Epoch: 5| Step: 5
Training loss: 2.2541298866271973
Validation loss: 2.156978855530421

Epoch: 5| Step: 6
Training loss: 1.0393562316894531
Validation loss: 2.0253238677978516

Epoch: 5| Step: 7
Training loss: 1.97963547706604
Validation loss: 2.174171601732572

Epoch: 5| Step: 8
Training loss: 1.5501779317855835
Validation loss: 2.2023384670416513

Epoch: 5| Step: 9
Training loss: 1.8255808353424072
Validation loss: 2.222071091334025

Epoch: 5| Step: 10
Training loss: 1.2038605213165283
Validation loss: 2.2058156381050744

Epoch: 5| Step: 11
Training loss: 1.520471453666687
Validation loss: 2.2287312746047974

Epoch: 170| Step: 0
Training loss: 1.6289888620376587
Validation loss: 2.1645654986302056

Epoch: 5| Step: 1
Training loss: 1.8640838861465454
Validation loss: 2.2981844445069632

Epoch: 5| Step: 2
Training loss: 1.451207160949707
Validation loss: 2.1404521763324738

Epoch: 5| Step: 3
Training loss: 1.1995093822479248
Validation loss: 2.1336493343114853

Epoch: 5| Step: 4
Training loss: 1.6341298818588257
Validation loss: 2.161132584015528

Epoch: 5| Step: 5
Training loss: 0.9822441339492798
Validation loss: 2.1169403195381165

Epoch: 5| Step: 6
Training loss: 1.3769315481185913
Validation loss: 2.239686926205953

Epoch: 5| Step: 7
Training loss: 1.8699334859848022
Validation loss: 2.174626807371775

Epoch: 5| Step: 8
Training loss: 1.2539242506027222
Validation loss: 2.184576133886973

Epoch: 5| Step: 9
Training loss: 1.925885796546936
Validation loss: 2.266880825161934

Epoch: 5| Step: 10
Training loss: 1.902137041091919
Validation loss: 2.1037415812412896

Epoch: 5| Step: 11
Training loss: 2.4200797080993652
Validation loss: 2.2346141586701074

Epoch: 171| Step: 0
Training loss: 1.593658447265625
Validation loss: 2.1104025493065515

Epoch: 5| Step: 1
Training loss: 1.6083440780639648
Validation loss: 2.1188070128361383

Epoch: 5| Step: 2
Training loss: 1.6237112283706665
Validation loss: 2.160847822825114

Epoch: 5| Step: 3
Training loss: 1.7517106533050537
Validation loss: 2.173046256105105

Epoch: 5| Step: 4
Training loss: 1.6578601598739624
Validation loss: 2.194090257088343

Epoch: 5| Step: 5
Training loss: 1.466735601425171
Validation loss: 2.2465265889962516

Epoch: 5| Step: 6
Training loss: 1.2434276342391968
Validation loss: 2.159155229727427

Epoch: 5| Step: 7
Training loss: 1.6831779479980469
Validation loss: 2.178860222299894

Epoch: 5| Step: 8
Training loss: 1.6808559894561768
Validation loss: 2.1431062867244086

Epoch: 5| Step: 9
Training loss: 1.686191201210022
Validation loss: 2.1772843648989997

Epoch: 5| Step: 10
Training loss: 1.5462372303009033
Validation loss: 2.2656939973433814

Epoch: 5| Step: 11
Training loss: 1.8699772357940674
Validation loss: 2.248986005783081

Epoch: 172| Step: 0
Training loss: 1.162442922592163
Validation loss: 2.2442935705184937

Epoch: 5| Step: 1
Training loss: 1.5623795986175537
Validation loss: 2.2199940184752145

Epoch: 5| Step: 2
Training loss: 1.225396752357483
Validation loss: 2.1775496304035187

Epoch: 5| Step: 3
Training loss: 1.7380316257476807
Validation loss: 2.1794778257608414

Epoch: 5| Step: 4
Training loss: 2.083524703979492
Validation loss: 2.1614320973555246

Epoch: 5| Step: 5
Training loss: 1.1848533153533936
Validation loss: 2.1964924136797586

Epoch: 5| Step: 6
Training loss: 1.6226040124893188
Validation loss: 2.145978346467018

Epoch: 5| Step: 7
Training loss: 2.0731799602508545
Validation loss: 2.1321532130241394

Epoch: 5| Step: 8
Training loss: 1.7938759326934814
Validation loss: 2.1594079534212747

Epoch: 5| Step: 9
Training loss: 1.9359500408172607
Validation loss: 2.1950251857439675

Epoch: 5| Step: 10
Training loss: 1.327168345451355
Validation loss: 2.227502539753914

Epoch: 5| Step: 11
Training loss: 1.6393457651138306
Validation loss: 2.1332602202892303

Epoch: 173| Step: 0
Training loss: 1.5793834924697876
Validation loss: 2.2289981842041016

Epoch: 5| Step: 1
Training loss: 1.3625494241714478
Validation loss: 2.234848072131475

Epoch: 5| Step: 2
Training loss: 1.7723734378814697
Validation loss: 2.243761976559957

Epoch: 5| Step: 3
Training loss: 1.885289192199707
Validation loss: 2.1219441095987954

Epoch: 5| Step: 4
Training loss: 1.671351671218872
Validation loss: 2.1638130346934

Epoch: 5| Step: 5
Training loss: 1.4822511672973633
Validation loss: 2.23926908771197

Epoch: 5| Step: 6
Training loss: 1.621106743812561
Validation loss: 2.214296122392019

Epoch: 5| Step: 7
Training loss: 1.1357558965682983
Validation loss: 2.074621766805649

Epoch: 5| Step: 8
Training loss: 1.803731918334961
Validation loss: 2.1065755685170493

Epoch: 5| Step: 9
Training loss: 1.5961862802505493
Validation loss: 2.214182515939077

Epoch: 5| Step: 10
Training loss: 2.054914951324463
Validation loss: 2.167362113793691

Epoch: 5| Step: 11
Training loss: 0.809008002281189
Validation loss: 2.1706289649009705

Epoch: 174| Step: 0
Training loss: 1.474541187286377
Validation loss: 2.194835598270098

Epoch: 5| Step: 1
Training loss: 2.2211830615997314
Validation loss: 2.1914480924606323

Epoch: 5| Step: 2
Training loss: 1.014676809310913
Validation loss: 2.2512320429086685

Epoch: 5| Step: 3
Training loss: 1.5498838424682617
Validation loss: 2.1672176122665405

Epoch: 5| Step: 4
Training loss: 1.8983036279678345
Validation loss: 2.192248006661733

Epoch: 5| Step: 5
Training loss: 1.811827301979065
Validation loss: 2.1717394391695657

Epoch: 5| Step: 6
Training loss: 1.869017243385315
Validation loss: 2.139130582412084

Epoch: 5| Step: 7
Training loss: 1.3259437084197998
Validation loss: 2.1698246399561563

Epoch: 5| Step: 8
Training loss: 1.1133501529693604
Validation loss: 2.197794293363889

Epoch: 5| Step: 9
Training loss: 1.3730207681655884
Validation loss: 2.133819490671158

Epoch: 5| Step: 10
Training loss: 1.2322461605072021
Validation loss: 2.194529205560684

Epoch: 5| Step: 11
Training loss: 1.2453064918518066
Validation loss: 2.1739806681871414

Epoch: 175| Step: 0
Training loss: 1.3818390369415283
Validation loss: 2.286264012257258

Epoch: 5| Step: 1
Training loss: 1.3356199264526367
Validation loss: 2.113686596353849

Epoch: 5| Step: 2
Training loss: 1.5340951681137085
Validation loss: 2.186964919169744

Epoch: 5| Step: 3
Training loss: 1.8754560947418213
Validation loss: 2.1311683704455695

Epoch: 5| Step: 4
Training loss: 0.9954862594604492
Validation loss: 2.1706624925136566

Epoch: 5| Step: 5
Training loss: 1.0208772420883179
Validation loss: 2.3239498833815255

Epoch: 5| Step: 6
Training loss: 1.6999439001083374
Validation loss: 2.2178498903910318

Epoch: 5| Step: 7
Training loss: 1.4567116498947144
Validation loss: 2.154765243331591

Epoch: 5| Step: 8
Training loss: 1.8707950115203857
Validation loss: 2.180753846963247

Epoch: 5| Step: 9
Training loss: 1.8706884384155273
Validation loss: 2.1264742016792297

Epoch: 5| Step: 10
Training loss: 2.0733444690704346
Validation loss: 2.2460032999515533

Epoch: 5| Step: 11
Training loss: 1.89889395236969
Validation loss: 2.1836625834306083

Epoch: 176| Step: 0
Training loss: 1.1489160060882568
Validation loss: 2.136866400639216

Epoch: 5| Step: 1
Training loss: 1.604188323020935
Validation loss: 2.11970246831576

Epoch: 5| Step: 2
Training loss: 1.134121298789978
Validation loss: 2.182796726624171

Epoch: 5| Step: 3
Training loss: 1.3748157024383545
Validation loss: 2.208462526400884

Epoch: 5| Step: 4
Training loss: 1.3658088445663452
Validation loss: 2.231289952993393

Epoch: 5| Step: 5
Training loss: 1.7599971294403076
Validation loss: 2.1630849093198776

Epoch: 5| Step: 6
Training loss: 1.7035167217254639
Validation loss: 2.1809229453404746

Epoch: 5| Step: 7
Training loss: 1.2456858158111572
Validation loss: 2.2384066581726074

Epoch: 5| Step: 8
Training loss: 1.917994737625122
Validation loss: 2.1414709190527597

Epoch: 5| Step: 9
Training loss: 1.9848670959472656
Validation loss: 2.226457347472509

Epoch: 5| Step: 10
Training loss: 1.7003700733184814
Validation loss: 2.221434240539869

Epoch: 5| Step: 11
Training loss: 2.351260185241699
Validation loss: 2.2071523318688073

Epoch: 177| Step: 0
Training loss: 1.1195513010025024
Validation loss: 2.174296503265699

Epoch: 5| Step: 1
Training loss: 1.6801332235336304
Validation loss: 2.1582120458285012

Epoch: 5| Step: 2
Training loss: 1.1656169891357422
Validation loss: 2.2518938382466636

Epoch: 5| Step: 3
Training loss: 0.9875451326370239
Validation loss: 2.1528623402118683

Epoch: 5| Step: 4
Training loss: 1.958285927772522
Validation loss: 2.2226031124591827

Epoch: 5| Step: 5
Training loss: 1.5545564889907837
Validation loss: 2.182724744081497

Epoch: 5| Step: 6
Training loss: 2.050421953201294
Validation loss: 2.179068108399709

Epoch: 5| Step: 7
Training loss: 1.8860276937484741
Validation loss: 2.1378887742757797

Epoch: 5| Step: 8
Training loss: 1.716524362564087
Validation loss: 2.142443373799324

Epoch: 5| Step: 9
Training loss: 1.4718687534332275
Validation loss: 2.050472324093183

Epoch: 5| Step: 10
Training loss: 1.376042127609253
Validation loss: 2.1686109403769174

Epoch: 5| Step: 11
Training loss: 1.3331785202026367
Validation loss: 2.2249724169572196

Epoch: 178| Step: 0
Training loss: 1.4093043804168701
Validation loss: 2.1612753917773566

Epoch: 5| Step: 1
Training loss: 1.6304073333740234
Validation loss: 2.1931553284327188

Epoch: 5| Step: 2
Training loss: 1.147672414779663
Validation loss: 2.1017916252215705

Epoch: 5| Step: 3
Training loss: 1.4123703241348267
Validation loss: 2.1900383830070496

Epoch: 5| Step: 4
Training loss: 0.8196671605110168
Validation loss: 2.1748163402080536

Epoch: 5| Step: 5
Training loss: 1.6513694524765015
Validation loss: 2.1607771813869476

Epoch: 5| Step: 6
Training loss: 1.6021144390106201
Validation loss: 2.2183613777160645

Epoch: 5| Step: 7
Training loss: 2.2311999797821045
Validation loss: 2.206851065158844

Epoch: 5| Step: 8
Training loss: 2.3684160709381104
Validation loss: 2.2842540740966797

Epoch: 5| Step: 9
Training loss: 1.3671150207519531
Validation loss: 2.2187506953875222

Epoch: 5| Step: 10
Training loss: 1.84330153465271
Validation loss: 2.196608687440554

Epoch: 5| Step: 11
Training loss: 1.6106171607971191
Validation loss: 2.1828177173932395

Epoch: 179| Step: 0
Training loss: 2.4806580543518066
Validation loss: 2.069003934661547

Epoch: 5| Step: 1
Training loss: 1.0483895540237427
Validation loss: 2.2336816440025964

Epoch: 5| Step: 2
Training loss: 1.5280307531356812
Validation loss: 2.1640883634487786

Epoch: 5| Step: 3
Training loss: 1.130782127380371
Validation loss: 2.133279715975126

Epoch: 5| Step: 4
Training loss: 2.080916166305542
Validation loss: 2.057082007328669

Epoch: 5| Step: 5
Training loss: 1.6340773105621338
Validation loss: 2.2053036987781525

Epoch: 5| Step: 6
Training loss: 1.5525197982788086
Validation loss: 2.1229273627201715

Epoch: 5| Step: 7
Training loss: 1.8277546167373657
Validation loss: 2.203552077213923

Epoch: 5| Step: 8
Training loss: 1.6405423879623413
Validation loss: 2.1353567391633987

Epoch: 5| Step: 9
Training loss: 1.629416823387146
Validation loss: 2.143792524933815

Epoch: 5| Step: 10
Training loss: 1.053979516029358
Validation loss: 2.168895830710729

Epoch: 5| Step: 11
Training loss: 1.4973671436309814
Validation loss: 2.1129847317934036

Epoch: 180| Step: 0
Training loss: 1.4343335628509521
Validation loss: 2.1770149568716683

Epoch: 5| Step: 1
Training loss: 1.5286593437194824
Validation loss: 2.2078208873669305

Epoch: 5| Step: 2
Training loss: 1.3785827159881592
Validation loss: 2.2215493520100913

Epoch: 5| Step: 3
Training loss: 1.632044792175293
Validation loss: 2.1888145804405212

Epoch: 5| Step: 4
Training loss: 1.029611587524414
Validation loss: 2.2230758567651114

Epoch: 5| Step: 5
Training loss: 1.9169689416885376
Validation loss: 2.1981446047623954

Epoch: 5| Step: 6
Training loss: 1.9054584503173828
Validation loss: 2.2602598617474237

Epoch: 5| Step: 7
Training loss: 1.657525658607483
Validation loss: 2.219974309206009

Epoch: 5| Step: 8
Training loss: 1.395885705947876
Validation loss: 2.17454527815183

Epoch: 5| Step: 9
Training loss: 0.8891830444335938
Validation loss: 2.203632111350695

Epoch: 5| Step: 10
Training loss: 1.5441415309906006
Validation loss: 2.1164098232984543

Epoch: 5| Step: 11
Training loss: 1.8728587627410889
Validation loss: 2.0643156369527182

Epoch: 181| Step: 0
Training loss: 1.7625722885131836
Validation loss: 2.2591697374979653

Epoch: 5| Step: 1
Training loss: 0.8877121210098267
Validation loss: 2.1994471649328866

Epoch: 5| Step: 2
Training loss: 0.928479790687561
Validation loss: 2.2180194606383643

Epoch: 5| Step: 3
Training loss: 1.4984499216079712
Validation loss: 2.291948397954305

Epoch: 5| Step: 4
Training loss: 1.637904405593872
Validation loss: 2.123581270376841

Epoch: 5| Step: 5
Training loss: 1.751246690750122
Validation loss: 2.25003819167614

Epoch: 5| Step: 6
Training loss: 2.09328031539917
Validation loss: 2.164928341905276

Epoch: 5| Step: 7
Training loss: 1.0250084400177002
Validation loss: 2.2477398614088693

Epoch: 5| Step: 8
Training loss: 1.687920331954956
Validation loss: 2.2405934582153955

Epoch: 5| Step: 9
Training loss: 1.6341396570205688
Validation loss: 2.1284935027360916

Epoch: 5| Step: 10
Training loss: 1.688750982284546
Validation loss: 2.087869495153427

Epoch: 5| Step: 11
Training loss: 0.9547978639602661
Validation loss: 2.2663346926371255

Epoch: 182| Step: 0
Training loss: 1.0134093761444092
Validation loss: 2.2339487920204797

Epoch: 5| Step: 1
Training loss: 1.5051876306533813
Validation loss: 2.218585009376208

Epoch: 5| Step: 2
Training loss: 1.8040821552276611
Validation loss: 2.208827873071035

Epoch: 5| Step: 3
Training loss: 1.3371379375457764
Validation loss: 2.2209834357102713

Epoch: 5| Step: 4
Training loss: 1.4780532121658325
Validation loss: 2.2812381039063134

Epoch: 5| Step: 5
Training loss: 1.6081912517547607
Validation loss: 2.1884332249561944

Epoch: 5| Step: 6
Training loss: 1.5318362712860107
Validation loss: 2.125866095225016

Epoch: 5| Step: 7
Training loss: 1.915732741355896
Validation loss: 2.213924010594686

Epoch: 5| Step: 8
Training loss: 1.7896934747695923
Validation loss: 2.135896240671476

Epoch: 5| Step: 9
Training loss: 1.169579029083252
Validation loss: 2.1744002401828766

Epoch: 5| Step: 10
Training loss: 1.744318962097168
Validation loss: 2.2402617732683816

Epoch: 5| Step: 11
Training loss: 2.0247628688812256
Validation loss: 2.1561868439118066

Epoch: 183| Step: 0
Training loss: 1.7137638330459595
Validation loss: 2.1661986261606216

Epoch: 5| Step: 1
Training loss: 1.5031074285507202
Validation loss: 2.091703340411186

Epoch: 5| Step: 2
Training loss: 1.5926231145858765
Validation loss: 2.188921888669332

Epoch: 5| Step: 3
Training loss: 1.2010717391967773
Validation loss: 2.1868001023928323

Epoch: 5| Step: 4
Training loss: 2.0454041957855225
Validation loss: 2.255432595809301

Epoch: 5| Step: 5
Training loss: 1.2750060558319092
Validation loss: 2.2327711383501687

Epoch: 5| Step: 6
Training loss: 1.161010980606079
Validation loss: 2.1901767750581107

Epoch: 5| Step: 7
Training loss: 1.473204255104065
Validation loss: 2.1380076011021933

Epoch: 5| Step: 8
Training loss: 1.1058069467544556
Validation loss: 2.172479599714279

Epoch: 5| Step: 9
Training loss: 1.280311942100525
Validation loss: 2.1819246311982474

Epoch: 5| Step: 10
Training loss: 1.7202917337417603
Validation loss: 2.1556438406308494

Epoch: 5| Step: 11
Training loss: 1.4093289375305176
Validation loss: 2.1685323814551034

Epoch: 184| Step: 0
Training loss: 1.5024374723434448
Validation loss: 2.1490792830785117

Epoch: 5| Step: 1
Training loss: 1.474643349647522
Validation loss: 2.186401680111885

Epoch: 5| Step: 2
Training loss: 1.8733364343643188
Validation loss: 2.2520262598991394

Epoch: 5| Step: 3
Training loss: 2.051438093185425
Validation loss: 2.1422305703163147

Epoch: 5| Step: 4
Training loss: 1.0866010189056396
Validation loss: 2.1305508265892663

Epoch: 5| Step: 5
Training loss: 0.9736791849136353
Validation loss: 2.135564217964808

Epoch: 5| Step: 6
Training loss: 1.6673755645751953
Validation loss: 2.2174049417177835

Epoch: 5| Step: 7
Training loss: 1.777000069618225
Validation loss: 2.177346095442772

Epoch: 5| Step: 8
Training loss: 1.6611182689666748
Validation loss: 2.1846074908971786

Epoch: 5| Step: 9
Training loss: 1.3494741916656494
Validation loss: 2.1591184437274933

Epoch: 5| Step: 10
Training loss: 1.2519384622573853
Validation loss: 2.051804651816686

Epoch: 5| Step: 11
Training loss: 0.5800222158432007
Validation loss: 2.134089251359304

Epoch: 185| Step: 0
Training loss: 1.868673324584961
Validation loss: 2.1113636742035546

Epoch: 5| Step: 1
Training loss: 0.9687206149101257
Validation loss: 2.1988887389500937

Epoch: 5| Step: 2
Training loss: 2.330753803253174
Validation loss: 2.114755615592003

Epoch: 5| Step: 3
Training loss: 1.3872110843658447
Validation loss: 2.2130083491404853

Epoch: 5| Step: 4
Training loss: 1.2874939441680908
Validation loss: 2.2276557932297387

Epoch: 5| Step: 5
Training loss: 1.5598998069763184
Validation loss: 2.148066520690918

Epoch: 5| Step: 6
Training loss: 2.1431660652160645
Validation loss: 2.1301890710989633

Epoch: 5| Step: 7
Training loss: 1.3568143844604492
Validation loss: 2.1445301373799643

Epoch: 5| Step: 8
Training loss: 0.7608718872070312
Validation loss: 2.187391291062037

Epoch: 5| Step: 9
Training loss: 1.9084182977676392
Validation loss: 2.155734439690908

Epoch: 5| Step: 10
Training loss: 1.5560356378555298
Validation loss: 2.2141070663928986

Epoch: 5| Step: 11
Training loss: 0.6346725225448608
Validation loss: 2.242207412918409

Epoch: 186| Step: 0
Training loss: 1.471451997756958
Validation loss: 2.219386324286461

Epoch: 5| Step: 1
Training loss: 1.7864770889282227
Validation loss: 2.2137092649936676

Epoch: 5| Step: 2
Training loss: 1.7188230752944946
Validation loss: 2.122191444039345

Epoch: 5| Step: 3
Training loss: 1.2355711460113525
Validation loss: 2.194541320204735

Epoch: 5| Step: 4
Training loss: 1.3873555660247803
Validation loss: 2.226281409462293

Epoch: 5| Step: 5
Training loss: 1.743249535560608
Validation loss: 2.190463831027349

Epoch: 5| Step: 6
Training loss: 1.4116003513336182
Validation loss: 2.1334189573923745

Epoch: 5| Step: 7
Training loss: 0.921439528465271
Validation loss: 2.2626908967892327

Epoch: 5| Step: 8
Training loss: 1.5034685134887695
Validation loss: 2.143026724457741

Epoch: 5| Step: 9
Training loss: 1.3162195682525635
Validation loss: 2.1181418697039285

Epoch: 5| Step: 10
Training loss: 1.6809946298599243
Validation loss: 2.258803576231003

Epoch: 5| Step: 11
Training loss: 1.4945623874664307
Validation loss: 2.2214123407999673

Epoch: 187| Step: 0
Training loss: 1.3780648708343506
Validation loss: 2.2029198010762534

Epoch: 5| Step: 1
Training loss: 1.2802079916000366
Validation loss: 2.1914879977703094

Epoch: 5| Step: 2
Training loss: 1.575711965560913
Validation loss: 2.183581387003263

Epoch: 5| Step: 3
Training loss: 1.425466537475586
Validation loss: 2.2216253181298575

Epoch: 5| Step: 4
Training loss: 0.9550312757492065
Validation loss: 2.1214127838611603

Epoch: 5| Step: 5
Training loss: 1.5828125476837158
Validation loss: 2.1294645220041275

Epoch: 5| Step: 6
Training loss: 2.4016640186309814
Validation loss: 2.190710266431173

Epoch: 5| Step: 7
Training loss: 1.4243566989898682
Validation loss: 2.1292087932427726

Epoch: 5| Step: 8
Training loss: 1.681131362915039
Validation loss: 2.2145473758379617

Epoch: 5| Step: 9
Training loss: 1.5842266082763672
Validation loss: 2.1943486829598746

Epoch: 5| Step: 10
Training loss: 1.216454267501831
Validation loss: 2.2136881053447723

Epoch: 5| Step: 11
Training loss: 0.9939631819725037
Validation loss: 2.170835236708323

Epoch: 188| Step: 0
Training loss: 1.2746388912200928
Validation loss: 2.2577365984519324

Epoch: 5| Step: 1
Training loss: 1.0096852779388428
Validation loss: 2.2166411777337394

Epoch: 5| Step: 2
Training loss: 1.39258873462677
Validation loss: 2.2990834961334863

Epoch: 5| Step: 3
Training loss: 2.197949171066284
Validation loss: 2.2744445453087487

Epoch: 5| Step: 4
Training loss: 1.4057480096817017
Validation loss: 2.266019105911255

Epoch: 5| Step: 5
Training loss: 1.570514440536499
Validation loss: 2.20167143146197

Epoch: 5| Step: 6
Training loss: 1.5572760105133057
Validation loss: 2.1662775029738746

Epoch: 5| Step: 7
Training loss: 1.1422481536865234
Validation loss: 2.1520589838425317

Epoch: 5| Step: 8
Training loss: 1.7257581949234009
Validation loss: 2.2252076864242554

Epoch: 5| Step: 9
Training loss: 1.7032783031463623
Validation loss: 2.092905431985855

Epoch: 5| Step: 10
Training loss: 1.2734453678131104
Validation loss: 2.201749304930369

Epoch: 5| Step: 11
Training loss: 0.8104151487350464
Validation loss: 2.163223311305046

Epoch: 189| Step: 0
Training loss: 1.192681074142456
Validation loss: 2.166062061985334

Epoch: 5| Step: 1
Training loss: 1.597805142402649
Validation loss: 2.1791364550590515

Epoch: 5| Step: 2
Training loss: 1.2101757526397705
Validation loss: 2.1991762866576514

Epoch: 5| Step: 3
Training loss: 1.5928322076797485
Validation loss: 2.2235106825828552

Epoch: 5| Step: 4
Training loss: 1.2706056833267212
Validation loss: 2.266449362039566

Epoch: 5| Step: 5
Training loss: 1.2237540483474731
Validation loss: 2.1720065623521805

Epoch: 5| Step: 6
Training loss: 1.2576961517333984
Validation loss: 2.214002182086309

Epoch: 5| Step: 7
Training loss: 1.801946997642517
Validation loss: 2.138645018140475

Epoch: 5| Step: 8
Training loss: 1.2053771018981934
Validation loss: 2.165932834148407

Epoch: 5| Step: 9
Training loss: 1.253568172454834
Validation loss: 2.2562985022862754

Epoch: 5| Step: 10
Training loss: 2.6407532691955566
Validation loss: 2.1147801826397576

Epoch: 5| Step: 11
Training loss: 2.302534580230713
Validation loss: 2.123535151282946

Epoch: 190| Step: 0
Training loss: 1.301878571510315
Validation loss: 2.2113534907499948

Epoch: 5| Step: 1
Training loss: 1.473145842552185
Validation loss: 2.22991377611955

Epoch: 5| Step: 2
Training loss: 1.2971022129058838
Validation loss: 2.1342733005682626

Epoch: 5| Step: 3
Training loss: 1.5575588941574097
Validation loss: 2.2030224800109863

Epoch: 5| Step: 4
Training loss: 1.7612015008926392
Validation loss: 2.208429738879204

Epoch: 5| Step: 5
Training loss: 1.386665940284729
Validation loss: 2.20389324426651

Epoch: 5| Step: 6
Training loss: 2.2320210933685303
Validation loss: 2.1612516790628433

Epoch: 5| Step: 7
Training loss: 1.6005197763442993
Validation loss: 2.2341287235418954

Epoch: 5| Step: 8
Training loss: 1.0693600177764893
Validation loss: 2.1311129381259284

Epoch: 5| Step: 9
Training loss: 1.211996078491211
Validation loss: 2.2316077947616577

Epoch: 5| Step: 10
Training loss: 1.2402302026748657
Validation loss: 2.2493369380633035

Epoch: 5| Step: 11
Training loss: 0.15600037574768066
Validation loss: 2.1901788264513016

Epoch: 191| Step: 0
Training loss: 1.7530609369277954
Validation loss: 2.2332110504309335

Epoch: 5| Step: 1
Training loss: 1.4909693002700806
Validation loss: 2.179551417628924

Epoch: 5| Step: 2
Training loss: 0.7016884088516235
Validation loss: 2.2464599510033927

Epoch: 5| Step: 3
Training loss: 1.067206621170044
Validation loss: 2.2059788554906845

Epoch: 5| Step: 4
Training loss: 2.068002700805664
Validation loss: 2.232840806245804

Epoch: 5| Step: 5
Training loss: 1.5100693702697754
Validation loss: 2.2535687486330667

Epoch: 5| Step: 6
Training loss: 1.2740874290466309
Validation loss: 2.1908801992734275

Epoch: 5| Step: 7
Training loss: 1.6645641326904297
Validation loss: 2.161650687456131

Epoch: 5| Step: 8
Training loss: 1.387501835823059
Validation loss: 2.17482324441274

Epoch: 5| Step: 9
Training loss: 1.6175241470336914
Validation loss: 2.192600588003794

Epoch: 5| Step: 10
Training loss: 1.1587960720062256
Validation loss: 2.1353507141272225

Epoch: 5| Step: 11
Training loss: 0.6131705641746521
Validation loss: 2.157967448234558

Epoch: 192| Step: 0
Training loss: 1.2321901321411133
Validation loss: 2.2148360709349313

Epoch: 5| Step: 1
Training loss: 1.6314332485198975
Validation loss: 2.203398828705152

Epoch: 5| Step: 2
Training loss: 1.6270751953125
Validation loss: 2.1117651065190635

Epoch: 5| Step: 3
Training loss: 1.2171955108642578
Validation loss: 2.2256487160921097

Epoch: 5| Step: 4
Training loss: 1.4155609607696533
Validation loss: 2.1675688376029334

Epoch: 5| Step: 5
Training loss: 1.8709228038787842
Validation loss: 2.0970414529244104

Epoch: 5| Step: 6
Training loss: 1.3841917514801025
Validation loss: 2.0723396291335425

Epoch: 5| Step: 7
Training loss: 1.1469700336456299
Validation loss: 2.1961759279171624

Epoch: 5| Step: 8
Training loss: 2.112433910369873
Validation loss: 2.2180754939715066

Epoch: 5| Step: 9
Training loss: 1.1699726581573486
Validation loss: 2.1480668683846793

Epoch: 5| Step: 10
Training loss: 0.9603246450424194
Validation loss: 2.2264153957366943

Epoch: 5| Step: 11
Training loss: 1.7402245998382568
Validation loss: 2.175592377781868

Epoch: 193| Step: 0
Training loss: 1.0205647945404053
Validation loss: 2.3021581570307412

Epoch: 5| Step: 1
Training loss: 1.3414714336395264
Validation loss: 2.3368142396211624

Epoch: 5| Step: 2
Training loss: 1.5390030145645142
Validation loss: 2.2757785419623056

Epoch: 5| Step: 3
Training loss: 1.5228554010391235
Validation loss: 2.2437196721633277

Epoch: 5| Step: 4
Training loss: 1.926303505897522
Validation loss: 2.1601292192935944

Epoch: 5| Step: 5
Training loss: 1.538448452949524
Validation loss: 2.251868173480034

Epoch: 5| Step: 6
Training loss: 1.2826757431030273
Validation loss: 2.170874853928884

Epoch: 5| Step: 7
Training loss: 1.8082983493804932
Validation loss: 2.251242091258367

Epoch: 5| Step: 8
Training loss: 1.3203585147857666
Validation loss: 2.194158613681793

Epoch: 5| Step: 9
Training loss: 1.3479658365249634
Validation loss: 2.222006912032763

Epoch: 5| Step: 10
Training loss: 1.6800925731658936
Validation loss: 2.253244916598002

Epoch: 5| Step: 11
Training loss: 1.1462830305099487
Validation loss: 2.266855994860331

Epoch: 194| Step: 0
Training loss: 1.3356120586395264
Validation loss: 2.2292882750431695

Epoch: 5| Step: 1
Training loss: 1.6895313262939453
Validation loss: 2.1130289236704507

Epoch: 5| Step: 2
Training loss: 1.5549609661102295
Validation loss: 2.210089157025019

Epoch: 5| Step: 3
Training loss: 0.9493051767349243
Validation loss: 2.224158530433973

Epoch: 5| Step: 4
Training loss: 1.557102918624878
Validation loss: 2.243692616621653

Epoch: 5| Step: 5
Training loss: 1.6119966506958008
Validation loss: 2.230722884337107

Epoch: 5| Step: 6
Training loss: 1.6399484872817993
Validation loss: 2.255351021885872

Epoch: 5| Step: 7
Training loss: 1.4550278186798096
Validation loss: 2.1892132063706717

Epoch: 5| Step: 8
Training loss: 1.0051556825637817
Validation loss: 2.2119176189104715

Epoch: 5| Step: 9
Training loss: 1.2537113428115845
Validation loss: 2.220712165037791

Epoch: 5| Step: 10
Training loss: 1.2396737337112427
Validation loss: 2.220240592956543

Epoch: 5| Step: 11
Training loss: 0.8103691935539246
Validation loss: 2.2339442372322083

Epoch: 195| Step: 0
Training loss: 1.1677253246307373
Validation loss: 2.1663139859835305

Epoch: 5| Step: 1
Training loss: 1.3903577327728271
Validation loss: 2.1908400704463324

Epoch: 5| Step: 2
Training loss: 1.6003224849700928
Validation loss: 2.1035371869802475

Epoch: 5| Step: 3
Training loss: 1.334193229675293
Validation loss: 2.2491831282774606

Epoch: 5| Step: 4
Training loss: 1.4451638460159302
Validation loss: 2.1967218220233917

Epoch: 5| Step: 5
Training loss: 1.4410773515701294
Validation loss: 2.185672546426455

Epoch: 5| Step: 6
Training loss: 1.721678376197815
Validation loss: 2.281077285607656

Epoch: 5| Step: 7
Training loss: 1.9428701400756836
Validation loss: 2.199496145049731

Epoch: 5| Step: 8
Training loss: 1.1758798360824585
Validation loss: 2.224381392200788

Epoch: 5| Step: 9
Training loss: 0.902459442615509
Validation loss: 2.178830405076345

Epoch: 5| Step: 10
Training loss: 1.7976114749908447
Validation loss: 2.2495123545328775

Epoch: 5| Step: 11
Training loss: 1.0425419807434082
Validation loss: 2.1988625129063926

Epoch: 196| Step: 0
Training loss: 1.4090605974197388
Validation loss: 2.2802271445592246

Epoch: 5| Step: 1
Training loss: 1.2678706645965576
Validation loss: 2.2583599338928857

Epoch: 5| Step: 2
Training loss: 2.0206212997436523
Validation loss: 2.221061199903488

Epoch: 5| Step: 3
Training loss: 0.970014750957489
Validation loss: 2.3255464831988015

Epoch: 5| Step: 4
Training loss: 1.623949646949768
Validation loss: 2.30193555355072

Epoch: 5| Step: 5
Training loss: 1.3333290815353394
Validation loss: 2.225531836350759

Epoch: 5| Step: 6
Training loss: 1.9540830850601196
Validation loss: 2.1584425220886865

Epoch: 5| Step: 7
Training loss: 1.368471622467041
Validation loss: 2.1977580984433494

Epoch: 5| Step: 8
Training loss: 1.346283197402954
Validation loss: 2.2049100548028946

Epoch: 5| Step: 9
Training loss: 1.3050167560577393
Validation loss: 2.1707708140214286

Epoch: 5| Step: 10
Training loss: 1.2693023681640625
Validation loss: 2.2883356312910714

Epoch: 5| Step: 11
Training loss: 0.9231613278388977
Validation loss: 2.2004758516947427

Epoch: 197| Step: 0
Training loss: 1.35903799533844
Validation loss: 2.2458027601242065

Epoch: 5| Step: 1
Training loss: 1.6990673542022705
Validation loss: 2.207846681276957

Epoch: 5| Step: 2
Training loss: 0.9738742709159851
Validation loss: 2.15085431933403

Epoch: 5| Step: 3
Training loss: 1.5801665782928467
Validation loss: 2.1772722949584327

Epoch: 5| Step: 4
Training loss: 0.9305642247200012
Validation loss: 2.176565850774447

Epoch: 5| Step: 5
Training loss: 1.367256999015808
Validation loss: 2.2057466953992844

Epoch: 5| Step: 6
Training loss: 1.5669233798980713
Validation loss: 2.236540903647741

Epoch: 5| Step: 7
Training loss: 1.5225176811218262
Validation loss: 2.2258516748746238

Epoch: 5| Step: 8
Training loss: 1.4713877439498901
Validation loss: 2.236795276403427

Epoch: 5| Step: 9
Training loss: 1.4207371473312378
Validation loss: 2.1688328882058463

Epoch: 5| Step: 10
Training loss: 1.365001916885376
Validation loss: 2.153701901435852

Epoch: 5| Step: 11
Training loss: 1.9872115850448608
Validation loss: 2.154457375407219

Epoch: 198| Step: 0
Training loss: 1.8332068920135498
Validation loss: 2.2126606603463492

Epoch: 5| Step: 1
Training loss: 0.9359345436096191
Validation loss: 2.2399446864922843

Epoch: 5| Step: 2
Training loss: 1.4524208307266235
Validation loss: 2.139415110150973

Epoch: 5| Step: 3
Training loss: 1.1239075660705566
Validation loss: 2.20782832801342

Epoch: 5| Step: 4
Training loss: 1.966525673866272
Validation loss: 2.1282898038625717

Epoch: 5| Step: 5
Training loss: 1.6796257495880127
Validation loss: 2.1919563859701157

Epoch: 5| Step: 6
Training loss: 1.3496636152267456
Validation loss: 2.165108179052671

Epoch: 5| Step: 7
Training loss: 1.396030068397522
Validation loss: 2.167784517010053

Epoch: 5| Step: 8
Training loss: 1.3598501682281494
Validation loss: 2.111011192202568

Epoch: 5| Step: 9
Training loss: 1.1268376111984253
Validation loss: 2.2083639601866403

Epoch: 5| Step: 10
Training loss: 1.2059255838394165
Validation loss: 2.1904337306817374

Epoch: 5| Step: 11
Training loss: 1.2493776082992554
Validation loss: 2.1630071302254996

Epoch: 199| Step: 0
Training loss: 0.9081363677978516
Validation loss: 2.2431569745143256

Epoch: 5| Step: 1
Training loss: 1.5257540941238403
Validation loss: 2.2526837388674417

Epoch: 5| Step: 2
Training loss: 1.5078023672103882
Validation loss: 2.16140545407931

Epoch: 5| Step: 3
Training loss: 1.3807424306869507
Validation loss: 2.3037580450375876

Epoch: 5| Step: 4
Training loss: 1.6798862218856812
Validation loss: 2.263076494137446

Epoch: 5| Step: 5
Training loss: 0.9997579455375671
Validation loss: 2.2614853183428445

Epoch: 5| Step: 6
Training loss: 1.5460104942321777
Validation loss: 2.2300806244214377

Epoch: 5| Step: 7
Training loss: 1.3615825176239014
Validation loss: 2.304123272498449

Epoch: 5| Step: 8
Training loss: 1.8581571578979492
Validation loss: 2.268063396215439

Epoch: 5| Step: 9
Training loss: 1.804772138595581
Validation loss: 2.2082025607426963

Epoch: 5| Step: 10
Training loss: 1.0657782554626465
Validation loss: 2.0669312874476113

Epoch: 5| Step: 11
Training loss: 2.7936387062072754
Validation loss: 2.311296651760737

Epoch: 200| Step: 0
Training loss: 0.8236681222915649
Validation loss: 2.256392329931259

Epoch: 5| Step: 1
Training loss: 1.2903798818588257
Validation loss: 2.181272139151891

Epoch: 5| Step: 2
Training loss: 1.1240699291229248
Validation loss: 2.2238291750351586

Epoch: 5| Step: 3
Training loss: 2.024466037750244
Validation loss: 2.242021600405375

Epoch: 5| Step: 4
Training loss: 1.3422279357910156
Validation loss: 2.1579489409923553

Epoch: 5| Step: 5
Training loss: 1.5236057043075562
Validation loss: 2.18028025329113

Epoch: 5| Step: 6
Training loss: 1.2962672710418701
Validation loss: 2.2387764304876328

Epoch: 5| Step: 7
Training loss: 1.9883899688720703
Validation loss: 2.2651093006134033

Epoch: 5| Step: 8
Training loss: 1.6500835418701172
Validation loss: 2.2681033313274384

Epoch: 5| Step: 9
Training loss: 1.2903183698654175
Validation loss: 2.236253241697947

Epoch: 5| Step: 10
Training loss: 1.4088242053985596
Validation loss: 2.220921183625857

Epoch: 5| Step: 11
Training loss: 0.6737576723098755
Validation loss: 2.1944712152083716

Epoch: 201| Step: 0
Training loss: 1.451094388961792
Validation loss: 2.294108177224795

Epoch: 5| Step: 1
Training loss: 1.5651330947875977
Validation loss: 2.1449034015337625

Epoch: 5| Step: 2
Training loss: 1.1235363483428955
Validation loss: 2.2359607021013894

Epoch: 5| Step: 3
Training loss: 1.3753552436828613
Validation loss: 2.1650900840759277

Epoch: 5| Step: 4
Training loss: 1.015792965888977
Validation loss: 2.195800175269445

Epoch: 5| Step: 5
Training loss: 1.7043304443359375
Validation loss: 2.1661333988110223

Epoch: 5| Step: 6
Training loss: 1.526100516319275
Validation loss: 2.2382783194382987

Epoch: 5| Step: 7
Training loss: 1.6521332263946533
Validation loss: 2.2070298989613852

Epoch: 5| Step: 8
Training loss: 1.7589209079742432
Validation loss: 2.166596213976542

Epoch: 5| Step: 9
Training loss: 1.47677743434906
Validation loss: 2.2529670695463815

Epoch: 5| Step: 10
Training loss: 1.424739122390747
Validation loss: 2.210830027858416

Epoch: 5| Step: 11
Training loss: 1.1710989475250244
Validation loss: 2.13506056368351

Epoch: 202| Step: 0
Training loss: 1.6021928787231445
Validation loss: 2.1805706222852073

Epoch: 5| Step: 1
Training loss: 1.3782144784927368
Validation loss: 2.1444415201743445

Epoch: 5| Step: 2
Training loss: 1.3443717956542969
Validation loss: 2.2286603649457297

Epoch: 5| Step: 3
Training loss: 1.5868288278579712
Validation loss: 2.2544766714175544

Epoch: 5| Step: 4
Training loss: 1.5154187679290771
Validation loss: 2.1927090883255005

Epoch: 5| Step: 5
Training loss: 1.664146065711975
Validation loss: 2.2660409112771354

Epoch: 5| Step: 6
Training loss: 0.9604247808456421
Validation loss: 2.2718070248762765

Epoch: 5| Step: 7
Training loss: 1.4326547384262085
Validation loss: 2.1749927749236426

Epoch: 5| Step: 8
Training loss: 1.1166735887527466
Validation loss: 2.1829149574041367

Epoch: 5| Step: 9
Training loss: 1.4334802627563477
Validation loss: 2.1479719281196594

Epoch: 5| Step: 10
Training loss: 1.3384153842926025
Validation loss: 2.228026866912842

Epoch: 5| Step: 11
Training loss: 1.2316668033599854
Validation loss: 2.207694242397944

Epoch: 203| Step: 0
Training loss: 1.143749475479126
Validation loss: 2.1974119345347085

Epoch: 5| Step: 1
Training loss: 1.8087705373764038
Validation loss: 2.235541174809138

Epoch: 5| Step: 2
Training loss: 1.286176323890686
Validation loss: 2.2823564608891806

Epoch: 5| Step: 3
Training loss: 1.2706973552703857
Validation loss: 2.244637111822764

Epoch: 5| Step: 4
Training loss: 1.2750244140625
Validation loss: 2.2585079272588096

Epoch: 5| Step: 5
Training loss: 1.5634651184082031
Validation loss: 2.204244683186213

Epoch: 5| Step: 6
Training loss: 1.358925461769104
Validation loss: 2.184525579214096

Epoch: 5| Step: 7
Training loss: 1.1910724639892578
Validation loss: 2.1598115464051566

Epoch: 5| Step: 8
Training loss: 1.7320621013641357
Validation loss: 2.1883009721835456

Epoch: 5| Step: 9
Training loss: 1.2185777425765991
Validation loss: 2.2462526659170785

Epoch: 5| Step: 10
Training loss: 1.9316078424453735
Validation loss: 2.196082428097725

Epoch: 5| Step: 11
Training loss: 1.40035879611969
Validation loss: 2.2022945831219354

Epoch: 204| Step: 0
Training loss: 1.2115662097930908
Validation loss: 2.189260592063268

Epoch: 5| Step: 1
Training loss: 0.9984856843948364
Validation loss: 2.213476503888766

Epoch: 5| Step: 2
Training loss: 1.4050638675689697
Validation loss: 2.192238688468933

Epoch: 5| Step: 3
Training loss: 1.0022225379943848
Validation loss: 2.230008920033773

Epoch: 5| Step: 4
Training loss: 1.4025161266326904
Validation loss: 2.1502815584341683

Epoch: 5| Step: 5
Training loss: 1.4980642795562744
Validation loss: 2.1871785819530487

Epoch: 5| Step: 6
Training loss: 1.4911266565322876
Validation loss: 2.2437847952047982

Epoch: 5| Step: 7
Training loss: 1.1490485668182373
Validation loss: 2.1827659010887146

Epoch: 5| Step: 8
Training loss: 1.2452549934387207
Validation loss: 2.160693441828092

Epoch: 5| Step: 9
Training loss: 1.3739173412322998
Validation loss: 2.239072839419047

Epoch: 5| Step: 10
Training loss: 2.1439144611358643
Validation loss: 2.129505236943563

Epoch: 5| Step: 11
Training loss: 0.6472609043121338
Validation loss: 2.222369725505511

Epoch: 205| Step: 0
Training loss: 1.209977626800537
Validation loss: 2.2304428617159524

Epoch: 5| Step: 1
Training loss: 1.010620355606079
Validation loss: 2.2603951394557953

Epoch: 5| Step: 2
Training loss: 1.7883927822113037
Validation loss: 2.200621282060941

Epoch: 5| Step: 3
Training loss: 1.4808709621429443
Validation loss: 2.1705074260632196

Epoch: 5| Step: 4
Training loss: 1.5669400691986084
Validation loss: 2.1491814653078714

Epoch: 5| Step: 5
Training loss: 1.0415445566177368
Validation loss: 2.1612664510806403

Epoch: 5| Step: 6
Training loss: 1.9310634136199951
Validation loss: 2.1606887032588324

Epoch: 5| Step: 7
Training loss: 1.2743289470672607
Validation loss: 2.2014019042253494

Epoch: 5| Step: 8
Training loss: 1.5350027084350586
Validation loss: 2.218030114968618

Epoch: 5| Step: 9
Training loss: 1.1368038654327393
Validation loss: 2.2124186803897223

Epoch: 5| Step: 10
Training loss: 1.0648711919784546
Validation loss: 2.242212807138761

Epoch: 5| Step: 11
Training loss: 1.558685541152954
Validation loss: 2.251230408747991

Epoch: 206| Step: 0
Training loss: 1.1131230592727661
Validation loss: 2.2079553554455438

Epoch: 5| Step: 1
Training loss: 1.4134979248046875
Validation loss: 2.253968278566996

Epoch: 5| Step: 2
Training loss: 1.303428292274475
Validation loss: 2.2904664178689322

Epoch: 5| Step: 3
Training loss: 1.1599088907241821
Validation loss: 2.185602237780889

Epoch: 5| Step: 4
Training loss: 1.7318508625030518
Validation loss: 2.184438476959864

Epoch: 5| Step: 5
Training loss: 1.1118205785751343
Validation loss: 2.1563178102175393

Epoch: 5| Step: 6
Training loss: 1.8562352657318115
Validation loss: 2.1791058083375296

Epoch: 5| Step: 7
Training loss: 1.164242148399353
Validation loss: 2.18929431339105

Epoch: 5| Step: 8
Training loss: 1.257135272026062
Validation loss: 2.201068937778473

Epoch: 5| Step: 9
Training loss: 1.4066798686981201
Validation loss: 2.1520223319530487

Epoch: 5| Step: 10
Training loss: 1.6242233514785767
Validation loss: 2.101151466369629

Epoch: 5| Step: 11
Training loss: 0.891364336013794
Validation loss: 2.2084819227457047

Epoch: 207| Step: 0
Training loss: 1.2933343648910522
Validation loss: 2.16028656065464

Epoch: 5| Step: 1
Training loss: 0.9370309710502625
Validation loss: 2.145191192626953

Epoch: 5| Step: 2
Training loss: 1.5588922500610352
Validation loss: 2.13460240761439

Epoch: 5| Step: 3
Training loss: 1.531361699104309
Validation loss: 2.18317773938179

Epoch: 5| Step: 4
Training loss: 1.4608856439590454
Validation loss: 2.203932831684748

Epoch: 5| Step: 5
Training loss: 1.7310054302215576
Validation loss: 2.123996540904045

Epoch: 5| Step: 6
Training loss: 1.4543335437774658
Validation loss: 2.1846009691556296

Epoch: 5| Step: 7
Training loss: 1.057433843612671
Validation loss: 2.2004138926664987

Epoch: 5| Step: 8
Training loss: 1.5695253610610962
Validation loss: 2.2334099610646567

Epoch: 5| Step: 9
Training loss: 2.0511651039123535
Validation loss: 2.159098371863365

Epoch: 5| Step: 10
Training loss: 0.9821845889091492
Validation loss: 2.1677011847496033

Epoch: 5| Step: 11
Training loss: 0.3983316421508789
Validation loss: 2.0949106315771737

Epoch: 208| Step: 0
Training loss: 1.5745444297790527
Validation loss: 2.2004611988862357

Epoch: 5| Step: 1
Training loss: 1.3789504766464233
Validation loss: 2.175833781560262

Epoch: 5| Step: 2
Training loss: 1.4101033210754395
Validation loss: 2.194622660676638

Epoch: 5| Step: 3
Training loss: 1.3572393655776978
Validation loss: 2.2137463291486106

Epoch: 5| Step: 4
Training loss: 1.2485415935516357
Validation loss: 2.1366673707962036

Epoch: 5| Step: 5
Training loss: 1.3831757307052612
Validation loss: 2.1526280442873635

Epoch: 5| Step: 6
Training loss: 1.3216629028320312
Validation loss: 2.2560440997282663

Epoch: 5| Step: 7
Training loss: 1.5382373332977295
Validation loss: 2.2498894532521567

Epoch: 5| Step: 8
Training loss: 2.048452615737915
Validation loss: 2.331964373588562

Epoch: 5| Step: 9
Training loss: 0.8862093687057495
Validation loss: 2.1704711467027664

Epoch: 5| Step: 10
Training loss: 1.069049596786499
Validation loss: 2.282921959956487

Epoch: 5| Step: 11
Training loss: 1.245467185974121
Validation loss: 2.2615955422321954

Epoch: 209| Step: 0
Training loss: 1.0304863452911377
Validation loss: 2.217199921607971

Epoch: 5| Step: 1
Training loss: 1.4417188167572021
Validation loss: 2.2240346471468606

Epoch: 5| Step: 2
Training loss: 0.8766082525253296
Validation loss: 2.3165571292241416

Epoch: 5| Step: 3
Training loss: 0.9733127355575562
Validation loss: 2.1913548608620963

Epoch: 5| Step: 4
Training loss: 2.013859510421753
Validation loss: 2.1927654445171356

Epoch: 5| Step: 5
Training loss: 1.174589991569519
Validation loss: 2.2355248431364694

Epoch: 5| Step: 6
Training loss: 1.5888487100601196
Validation loss: 2.223156342903773

Epoch: 5| Step: 7
Training loss: 1.1291229724884033
Validation loss: 2.2684455613295236

Epoch: 5| Step: 8
Training loss: 1.8329919576644897
Validation loss: 2.216994841893514

Epoch: 5| Step: 9
Training loss: 1.5285253524780273
Validation loss: 2.1227780282497406

Epoch: 5| Step: 10
Training loss: 1.0440696477890015
Validation loss: 2.189913118879

Epoch: 5| Step: 11
Training loss: 0.9808687567710876
Validation loss: 2.202371751268705

Epoch: 210| Step: 0
Training loss: 1.5403376817703247
Validation loss: 2.254377926389376

Epoch: 5| Step: 1
Training loss: 1.7321865558624268
Validation loss: 2.2697516779104867

Epoch: 5| Step: 2
Training loss: 1.6985399723052979
Validation loss: 2.269551326831182

Epoch: 5| Step: 3
Training loss: 0.8777616620063782
Validation loss: 2.2729447782039642

Epoch: 5| Step: 4
Training loss: 1.5889384746551514
Validation loss: 2.1581651270389557

Epoch: 5| Step: 5
Training loss: 1.357790231704712
Validation loss: 2.2280821253856025

Epoch: 5| Step: 6
Training loss: 0.5711329579353333
Validation loss: 2.296132450302442

Epoch: 5| Step: 7
Training loss: 1.139051079750061
Validation loss: 2.2184905807177224

Epoch: 5| Step: 8
Training loss: 1.1651160717010498
Validation loss: 2.2241837034622827

Epoch: 5| Step: 9
Training loss: 1.2850267887115479
Validation loss: 2.2669887940088906

Epoch: 5| Step: 10
Training loss: 1.5161066055297852
Validation loss: 2.235268791516622

Epoch: 5| Step: 11
Training loss: 1.711161494255066
Validation loss: 2.227517748872439

Epoch: 211| Step: 0
Training loss: 0.7601630091667175
Validation loss: 2.195046678185463

Epoch: 5| Step: 1
Training loss: 1.2936652898788452
Validation loss: 2.2093483358621597

Epoch: 5| Step: 2
Training loss: 0.8754932284355164
Validation loss: 2.2444478621085486

Epoch: 5| Step: 3
Training loss: 1.0257512331008911
Validation loss: 2.2109828144311905

Epoch: 5| Step: 4
Training loss: 1.711785078048706
Validation loss: 2.2059102604786553

Epoch: 5| Step: 5
Training loss: 1.6264110803604126
Validation loss: 2.2681526144345603

Epoch: 5| Step: 6
Training loss: 1.9648109674453735
Validation loss: 2.20281453927358

Epoch: 5| Step: 7
Training loss: 0.9533249735832214
Validation loss: 2.1859072148799896

Epoch: 5| Step: 8
Training loss: 1.9587854146957397
Validation loss: 2.185721923907598

Epoch: 5| Step: 9
Training loss: 0.965662956237793
Validation loss: 2.14806659022967

Epoch: 5| Step: 10
Training loss: 1.0408332347869873
Validation loss: 2.2400354941685996

Epoch: 5| Step: 11
Training loss: 1.2937698364257812
Validation loss: 2.2320175965627036

Epoch: 212| Step: 0
Training loss: 1.5488722324371338
Validation loss: 2.2203301737705865

Epoch: 5| Step: 1
Training loss: 2.080681324005127
Validation loss: 2.1999381681283317

Epoch: 5| Step: 2
Training loss: 1.6463849544525146
Validation loss: 2.124919911225637

Epoch: 5| Step: 3
Training loss: 1.3959075212478638
Validation loss: 2.1471195171276727

Epoch: 5| Step: 4
Training loss: 0.7833436727523804
Validation loss: 2.2596913079420724

Epoch: 5| Step: 5
Training loss: 1.6253318786621094
Validation loss: 2.1765568455060325

Epoch: 5| Step: 6
Training loss: 1.159765601158142
Validation loss: 2.2382478515307107

Epoch: 5| Step: 7
Training loss: 1.099975824356079
Validation loss: 2.205599764982859

Epoch: 5| Step: 8
Training loss: 1.75467848777771
Validation loss: 2.1615843872229257

Epoch: 5| Step: 9
Training loss: 0.9951200485229492
Validation loss: 2.2473933547735214

Epoch: 5| Step: 10
Training loss: 1.634486198425293
Validation loss: 2.276115526755651

Epoch: 5| Step: 11
Training loss: 0.8841753005981445
Validation loss: 2.3089653799931207

Epoch: 213| Step: 0
Training loss: 2.100450277328491
Validation loss: 2.1740808288256326

Epoch: 5| Step: 1
Training loss: 1.6241871118545532
Validation loss: 2.224349002043406

Epoch: 5| Step: 2
Training loss: 0.6939089894294739
Validation loss: 2.120453894138336

Epoch: 5| Step: 3
Training loss: 1.1306546926498413
Validation loss: 2.174325088659922

Epoch: 5| Step: 4
Training loss: 1.3030316829681396
Validation loss: 2.161476577321688

Epoch: 5| Step: 5
Training loss: 1.3320200443267822
Validation loss: 2.2675174127022424

Epoch: 5| Step: 6
Training loss: 1.7498188018798828
Validation loss: 2.1289591193199158

Epoch: 5| Step: 7
Training loss: 0.9463825225830078
Validation loss: 2.1487344255050025

Epoch: 5| Step: 8
Training loss: 1.0255732536315918
Validation loss: 2.193098336458206

Epoch: 5| Step: 9
Training loss: 1.1932083368301392
Validation loss: 2.223382984598478

Epoch: 5| Step: 10
Training loss: 1.1537786722183228
Validation loss: 2.17389107743899

Epoch: 5| Step: 11
Training loss: 0.22669386863708496
Validation loss: 2.2390191157658896

Epoch: 214| Step: 0
Training loss: 1.2927334308624268
Validation loss: 2.236639549334844

Epoch: 5| Step: 1
Training loss: 1.7829859256744385
Validation loss: 2.2685661812623343

Epoch: 5| Step: 2
Training loss: 1.3720180988311768
Validation loss: 2.195501839121183

Epoch: 5| Step: 3
Training loss: 1.0937259197235107
Validation loss: 2.170449440677961

Epoch: 5| Step: 4
Training loss: 1.4576833248138428
Validation loss: 2.1977123767137527

Epoch: 5| Step: 5
Training loss: 0.9633170366287231
Validation loss: 2.191730628410975

Epoch: 5| Step: 6
Training loss: 1.6418216228485107
Validation loss: 2.1806581715742746

Epoch: 5| Step: 7
Training loss: 1.055867075920105
Validation loss: 2.2816483775774636

Epoch: 5| Step: 8
Training loss: 1.2261263132095337
Validation loss: 2.205555041631063

Epoch: 5| Step: 9
Training loss: 1.0642426013946533
Validation loss: 2.2337481329838433

Epoch: 5| Step: 10
Training loss: 1.3212060928344727
Validation loss: 2.1482257644335427

Epoch: 5| Step: 11
Training loss: 1.528606653213501
Validation loss: 2.1461786528428397

Epoch: 215| Step: 0
Training loss: 1.2297048568725586
Validation loss: 2.1896959046522775

Epoch: 5| Step: 1
Training loss: 1.1028450727462769
Validation loss: 2.1922504703203836

Epoch: 5| Step: 2
Training loss: 1.4590070247650146
Validation loss: 2.1619349171717963

Epoch: 5| Step: 3
Training loss: 1.4127341508865356
Validation loss: 2.1638725449641547

Epoch: 5| Step: 4
Training loss: 1.1610424518585205
Validation loss: 2.2858837842941284

Epoch: 5| Step: 5
Training loss: 1.3744957447052002
Validation loss: 2.1680275996526084

Epoch: 5| Step: 6
Training loss: 1.8494476079940796
Validation loss: 2.0887130995591483

Epoch: 5| Step: 7
Training loss: 1.449275016784668
Validation loss: 2.2396091918150582

Epoch: 5| Step: 8
Training loss: 1.018676996231079
Validation loss: 2.1086124181747437

Epoch: 5| Step: 9
Training loss: 1.1425764560699463
Validation loss: 2.1729998340209327

Epoch: 5| Step: 10
Training loss: 1.5171215534210205
Validation loss: 2.1984352668126426

Epoch: 5| Step: 11
Training loss: 1.223656415939331
Validation loss: 2.1610238502422967

Epoch: 216| Step: 0
Training loss: 1.5404603481292725
Validation loss: 2.1017525792121887

Epoch: 5| Step: 1
Training loss: 1.4933972358703613
Validation loss: 2.236259877681732

Epoch: 5| Step: 2
Training loss: 1.4453983306884766
Validation loss: 2.1447122941414514

Epoch: 5| Step: 3
Training loss: 1.2074956893920898
Validation loss: 2.2080765763918557

Epoch: 5| Step: 4
Training loss: 1.1684620380401611
Validation loss: 2.135176087419192

Epoch: 5| Step: 5
Training loss: 1.0739580392837524
Validation loss: 2.217265064517657

Epoch: 5| Step: 6
Training loss: 1.172929048538208
Validation loss: 2.15533476571242

Epoch: 5| Step: 7
Training loss: 1.1660771369934082
Validation loss: 2.3329937011003494

Epoch: 5| Step: 8
Training loss: 1.1382253170013428
Validation loss: 2.23626708984375

Epoch: 5| Step: 9
Training loss: 1.09037184715271
Validation loss: 2.1350623220205307

Epoch: 5| Step: 10
Training loss: 1.323340892791748
Validation loss: 2.1772676706314087

Epoch: 5| Step: 11
Training loss: 1.1586923599243164
Validation loss: 2.219186340769132

Epoch: 217| Step: 0
Training loss: 1.3919620513916016
Validation loss: 2.2251142412424088

Epoch: 5| Step: 1
Training loss: 1.2148871421813965
Validation loss: 2.1834162771701813

Epoch: 5| Step: 2
Training loss: 1.3398659229278564
Validation loss: 2.2276763717333474

Epoch: 5| Step: 3
Training loss: 1.0680067539215088
Validation loss: 2.1652161528666816

Epoch: 5| Step: 4
Training loss: 1.5167696475982666
Validation loss: 2.2183680136998496

Epoch: 5| Step: 5
Training loss: 1.4904134273529053
Validation loss: 2.1528345147768655

Epoch: 5| Step: 6
Training loss: 1.421870231628418
Validation loss: 2.255969395240148

Epoch: 5| Step: 7
Training loss: 0.9077625274658203
Validation loss: 2.286542455355326

Epoch: 5| Step: 8
Training loss: 1.208266019821167
Validation loss: 2.1947121024131775

Epoch: 5| Step: 9
Training loss: 1.322167158126831
Validation loss: 2.243141402800878

Epoch: 5| Step: 10
Training loss: 1.2851287126541138
Validation loss: 2.2355688909689584

Epoch: 5| Step: 11
Training loss: 1.5677766799926758
Validation loss: 2.2150813142458596

Epoch: 218| Step: 0
Training loss: 1.411868691444397
Validation loss: 2.244006633758545

Epoch: 5| Step: 1
Training loss: 1.3571832180023193
Validation loss: 2.226330334941546

Epoch: 5| Step: 2
Training loss: 0.9075011014938354
Validation loss: 2.2994464486837387

Epoch: 5| Step: 3
Training loss: 0.9007259607315063
Validation loss: 2.277404561638832

Epoch: 5| Step: 4
Training loss: 1.5749365091323853
Validation loss: 2.211702307065328

Epoch: 5| Step: 5
Training loss: 1.3975218534469604
Validation loss: 2.248488595088323

Epoch: 5| Step: 6
Training loss: 1.766252875328064
Validation loss: 2.2903158913056054

Epoch: 5| Step: 7
Training loss: 1.5740444660186768
Validation loss: 2.2349445521831512

Epoch: 5| Step: 8
Training loss: 1.0631465911865234
Validation loss: 2.177900413672129

Epoch: 5| Step: 9
Training loss: 1.1888720989227295
Validation loss: 2.2100183069705963

Epoch: 5| Step: 10
Training loss: 1.1796880960464478
Validation loss: 2.2159524708986282

Epoch: 5| Step: 11
Training loss: 0.7022802233695984
Validation loss: 2.1594259093205133

Epoch: 219| Step: 0
Training loss: 1.07508385181427
Validation loss: 2.141874154408773

Epoch: 5| Step: 1
Training loss: 1.7112233638763428
Validation loss: 2.300150786836942

Epoch: 5| Step: 2
Training loss: 1.1528867483139038
Validation loss: 2.230065941810608

Epoch: 5| Step: 3
Training loss: 1.0919908285140991
Validation loss: 2.2523651321729026

Epoch: 5| Step: 4
Training loss: 1.2969655990600586
Validation loss: 2.248683045307795

Epoch: 5| Step: 5
Training loss: 1.2301881313323975
Validation loss: 2.2150195936361947

Epoch: 5| Step: 6
Training loss: 1.5128239393234253
Validation loss: 2.2840230613946915

Epoch: 5| Step: 7
Training loss: 1.4644702672958374
Validation loss: 2.2966673225164413

Epoch: 5| Step: 8
Training loss: 1.5412590503692627
Validation loss: 2.2442499001820884

Epoch: 5| Step: 9
Training loss: 1.1248202323913574
Validation loss: 2.2545744478702545

Epoch: 5| Step: 10
Training loss: 0.8153641819953918
Validation loss: 2.1746113101641336

Epoch: 5| Step: 11
Training loss: 1.5335848331451416
Validation loss: 2.2452373951673508

Epoch: 220| Step: 0
Training loss: 0.8784415125846863
Validation loss: 2.196389456590017

Epoch: 5| Step: 1
Training loss: 1.1672674417495728
Validation loss: 2.310738871494929

Epoch: 5| Step: 2
Training loss: 1.3792035579681396
Validation loss: 2.2567394226789474

Epoch: 5| Step: 3
Training loss: 1.9276878833770752
Validation loss: 2.1974315494298935

Epoch: 5| Step: 4
Training loss: 0.9048736691474915
Validation loss: 2.148562471071879

Epoch: 5| Step: 5
Training loss: 0.9736725091934204
Validation loss: 2.210003832976023

Epoch: 5| Step: 6
Training loss: 1.3917169570922852
Validation loss: 2.2090347905953727

Epoch: 5| Step: 7
Training loss: 0.888957142829895
Validation loss: 2.2830054660638175

Epoch: 5| Step: 8
Training loss: 1.3639088869094849
Validation loss: 2.313387453556061

Epoch: 5| Step: 9
Training loss: 0.9795358777046204
Validation loss: 2.1959396054347358

Epoch: 5| Step: 10
Training loss: 2.0160655975341797
Validation loss: 2.2288753738005957

Epoch: 5| Step: 11
Training loss: 1.1070080995559692
Validation loss: 2.2468476990858712

Epoch: 221| Step: 0
Training loss: 1.47310471534729
Validation loss: 2.237172558903694

Epoch: 5| Step: 1
Training loss: 1.372143268585205
Validation loss: 2.281968966126442

Epoch: 5| Step: 2
Training loss: 1.4561588764190674
Validation loss: 2.226110036174456

Epoch: 5| Step: 3
Training loss: 1.0713080167770386
Validation loss: 2.2181901882092157

Epoch: 5| Step: 4
Training loss: 1.6761205196380615
Validation loss: 2.2081858019034066

Epoch: 5| Step: 5
Training loss: 1.170049786567688
Validation loss: 2.1320819705724716

Epoch: 5| Step: 6
Training loss: 1.2117902040481567
Validation loss: 2.144565070668856

Epoch: 5| Step: 7
Training loss: 1.0036265850067139
Validation loss: 2.227295388778051

Epoch: 5| Step: 8
Training loss: 1.2383818626403809
Validation loss: 2.281571944554647

Epoch: 5| Step: 9
Training loss: 1.060895562171936
Validation loss: 2.2882582346598306

Epoch: 5| Step: 10
Training loss: 1.392919898033142
Validation loss: 2.279265041152636

Epoch: 5| Step: 11
Training loss: 1.597288727760315
Validation loss: 2.210499664147695

Epoch: 222| Step: 0
Training loss: 0.8409628868103027
Validation loss: 2.271002580722173

Epoch: 5| Step: 1
Training loss: 1.5234309434890747
Validation loss: 2.193811525901159

Epoch: 5| Step: 2
Training loss: 1.7172040939331055
Validation loss: 2.187034750978152

Epoch: 5| Step: 3
Training loss: 1.07973051071167
Validation loss: 2.203642949461937

Epoch: 5| Step: 4
Training loss: 1.3550779819488525
Validation loss: 2.1872207721074424

Epoch: 5| Step: 5
Training loss: 1.4075217247009277
Validation loss: 2.188871736327807

Epoch: 5| Step: 6
Training loss: 1.3321285247802734
Validation loss: 2.249990979830424

Epoch: 5| Step: 7
Training loss: 1.6501085758209229
Validation loss: 2.179832100868225

Epoch: 5| Step: 8
Training loss: 0.9131879806518555
Validation loss: 2.2463078598181405

Epoch: 5| Step: 9
Training loss: 1.1396394968032837
Validation loss: 2.095547467470169

Epoch: 5| Step: 10
Training loss: 1.3722879886627197
Validation loss: 2.2445306877295175

Epoch: 5| Step: 11
Training loss: 0.8207037448883057
Validation loss: 2.168608784675598

Epoch: 223| Step: 0
Training loss: 1.1884031295776367
Validation loss: 2.2355237553517022

Epoch: 5| Step: 1
Training loss: 0.8451366424560547
Validation loss: 2.22721662123998

Epoch: 5| Step: 2
Training loss: 1.1320561170578003
Validation loss: 2.257412612438202

Epoch: 5| Step: 3
Training loss: 1.6384117603302002
Validation loss: 2.2454930742581687

Epoch: 5| Step: 4
Training loss: 1.3559938669204712
Validation loss: 2.2533430059750876

Epoch: 5| Step: 5
Training loss: 1.4177067279815674
Validation loss: 2.1873259196678796

Epoch: 5| Step: 6
Training loss: 1.3859885931015015
Validation loss: 2.2734188536802926

Epoch: 5| Step: 7
Training loss: 0.9279419183731079
Validation loss: 2.272012010216713

Epoch: 5| Step: 8
Training loss: 1.373942255973816
Validation loss: 2.152205357948939

Epoch: 5| Step: 9
Training loss: 0.8935952186584473
Validation loss: 2.17042937874794

Epoch: 5| Step: 10
Training loss: 1.3877108097076416
Validation loss: 2.2704648276170096

Epoch: 5| Step: 11
Training loss: 1.5794687271118164
Validation loss: 2.2345549911260605

Epoch: 224| Step: 0
Training loss: 1.007603406906128
Validation loss: 2.1971510698397956

Epoch: 5| Step: 1
Training loss: 0.8923237919807434
Validation loss: 2.228478709856669

Epoch: 5| Step: 2
Training loss: 1.0350326299667358
Validation loss: 2.2191998908917108

Epoch: 5| Step: 3
Training loss: 1.7857341766357422
Validation loss: 2.23048264781634

Epoch: 5| Step: 4
Training loss: 1.3901419639587402
Validation loss: 2.2298791110515594

Epoch: 5| Step: 5
Training loss: 0.8195809125900269
Validation loss: 2.2367247144381204

Epoch: 5| Step: 6
Training loss: 1.528120756149292
Validation loss: 2.2228659987449646

Epoch: 5| Step: 7
Training loss: 1.2028355598449707
Validation loss: 2.162555148204168

Epoch: 5| Step: 8
Training loss: 1.802211046218872
Validation loss: 2.2021539409955344

Epoch: 5| Step: 9
Training loss: 1.3719723224639893
Validation loss: 2.233021010955175

Epoch: 5| Step: 10
Training loss: 1.4579236507415771
Validation loss: 2.226172005136808

Epoch: 5| Step: 11
Training loss: 1.1436350345611572
Validation loss: 2.1827321549256644

Epoch: 225| Step: 0
Training loss: 0.8096120953559875
Validation loss: 2.210849558313688

Epoch: 5| Step: 1
Training loss: 2.0351672172546387
Validation loss: 2.1640998472770057

Epoch: 5| Step: 2
Training loss: 1.428693413734436
Validation loss: 2.213162139058113

Epoch: 5| Step: 3
Training loss: 1.2353777885437012
Validation loss: 2.150680477420489

Epoch: 5| Step: 4
Training loss: 1.3744795322418213
Validation loss: 2.2253664831320443

Epoch: 5| Step: 5
Training loss: 1.2991149425506592
Validation loss: 2.2188437084356942

Epoch: 5| Step: 6
Training loss: 1.063454031944275
Validation loss: 2.186161975065867

Epoch: 5| Step: 7
Training loss: 1.6843658685684204
Validation loss: 2.2378182957569757

Epoch: 5| Step: 8
Training loss: 0.9467437863349915
Validation loss: 2.23488716284434

Epoch: 5| Step: 9
Training loss: 1.1717441082000732
Validation loss: 2.240632822116216

Epoch: 5| Step: 10
Training loss: 1.0075016021728516
Validation loss: 2.2233771036068597

Epoch: 5| Step: 11
Training loss: 0.3557247519493103
Validation loss: 2.2033688922723136

Epoch: 226| Step: 0
Training loss: 1.0225719213485718
Validation loss: 2.1816553473472595

Epoch: 5| Step: 1
Training loss: 0.9733600616455078
Validation loss: 2.187871883312861

Epoch: 5| Step: 2
Training loss: 1.328975796699524
Validation loss: 2.256852219502131

Epoch: 5| Step: 3
Training loss: 1.9272664785385132
Validation loss: 2.1964466273784637

Epoch: 5| Step: 4
Training loss: 0.8849376440048218
Validation loss: 2.1450409491856894

Epoch: 5| Step: 5
Training loss: 1.1654162406921387
Validation loss: 2.2468345761299133

Epoch: 5| Step: 6
Training loss: 1.3473743200302124
Validation loss: 2.170819645126661

Epoch: 5| Step: 7
Training loss: 1.1437149047851562
Validation loss: 2.191787009437879

Epoch: 5| Step: 8
Training loss: 0.7469915151596069
Validation loss: 2.239886686205864

Epoch: 5| Step: 9
Training loss: 1.6997575759887695
Validation loss: 2.2172924776872

Epoch: 5| Step: 10
Training loss: 1.3245680332183838
Validation loss: 2.1676660825808844

Epoch: 5| Step: 11
Training loss: 0.7031716108322144
Validation loss: 2.2973219454288483

Epoch: 227| Step: 0
Training loss: 1.0270572900772095
Validation loss: 2.302412281433741

Epoch: 5| Step: 1
Training loss: 1.2532083988189697
Validation loss: 2.1990539928277335

Epoch: 5| Step: 2
Training loss: 1.175583004951477
Validation loss: 2.324405307571093

Epoch: 5| Step: 3
Training loss: 2.2563905715942383
Validation loss: 2.14740714430809

Epoch: 5| Step: 4
Training loss: 1.284609079360962
Validation loss: 2.2537792325019836

Epoch: 5| Step: 5
Training loss: 0.946640133857727
Validation loss: 2.19070232907931

Epoch: 5| Step: 6
Training loss: 1.0097105503082275
Validation loss: 2.19012488424778

Epoch: 5| Step: 7
Training loss: 0.955329418182373
Validation loss: 2.1717150509357452

Epoch: 5| Step: 8
Training loss: 1.150066614151001
Validation loss: 2.209378093481064

Epoch: 5| Step: 9
Training loss: 1.2201803922653198
Validation loss: 2.2277822891871133

Epoch: 5| Step: 10
Training loss: 1.1232579946517944
Validation loss: 2.1079526841640472

Epoch: 5| Step: 11
Training loss: 3.4539098739624023
Validation loss: 2.1347971906264624

Epoch: 228| Step: 0
Training loss: 1.5688297748565674
Validation loss: 2.206729158759117

Epoch: 5| Step: 1
Training loss: 1.7695003747940063
Validation loss: 2.22330412765344

Epoch: 5| Step: 2
Training loss: 1.3100093603134155
Validation loss: 2.3616931438446045

Epoch: 5| Step: 3
Training loss: 1.2348530292510986
Validation loss: 2.206787794828415

Epoch: 5| Step: 4
Training loss: 0.7895976901054382
Validation loss: 2.235181654493014

Epoch: 5| Step: 5
Training loss: 1.0730695724487305
Validation loss: 2.2318111012379327

Epoch: 5| Step: 6
Training loss: 1.21085524559021
Validation loss: 2.2377301206191382

Epoch: 5| Step: 7
Training loss: 1.1642621755599976
Validation loss: 2.182163119316101

Epoch: 5| Step: 8
Training loss: 0.9867866635322571
Validation loss: 2.2400487661361694

Epoch: 5| Step: 9
Training loss: 1.2924541234970093
Validation loss: 2.185096969207128

Epoch: 5| Step: 10
Training loss: 1.1871109008789062
Validation loss: 2.188526680072149

Epoch: 5| Step: 11
Training loss: 1.0071815252304077
Validation loss: 2.2778111348549523

Epoch: 229| Step: 0
Training loss: 1.6071021556854248
Validation loss: 2.2007419715325036

Epoch: 5| Step: 1
Training loss: 1.5546772480010986
Validation loss: 2.178408612807592

Epoch: 5| Step: 2
Training loss: 0.9293479919433594
Validation loss: 2.2425887684027352

Epoch: 5| Step: 3
Training loss: 1.0230469703674316
Validation loss: 2.15163354575634

Epoch: 5| Step: 4
Training loss: 1.2720186710357666
Validation loss: 2.181904365619024

Epoch: 5| Step: 5
Training loss: 1.092388391494751
Validation loss: 2.286246339480082

Epoch: 5| Step: 6
Training loss: 0.6980870962142944
Validation loss: 2.1985073387622833

Epoch: 5| Step: 7
Training loss: 1.2498881816864014
Validation loss: 2.1730495194594064

Epoch: 5| Step: 8
Training loss: 1.284393310546875
Validation loss: 2.1870561043421426

Epoch: 5| Step: 9
Training loss: 1.0269240140914917
Validation loss: 2.2258750796318054

Epoch: 5| Step: 10
Training loss: 1.5133966207504272
Validation loss: 2.236206740140915

Epoch: 5| Step: 11
Training loss: 2.4293813705444336
Validation loss: 2.22275181611379

Epoch: 230| Step: 0
Training loss: 1.7731870412826538
Validation loss: 2.189159572124481

Epoch: 5| Step: 1
Training loss: 1.1754863262176514
Validation loss: 2.210319538911184

Epoch: 5| Step: 2
Training loss: 1.8851600885391235
Validation loss: 2.2462972154219947

Epoch: 5| Step: 3
Training loss: 1.1300921440124512
Validation loss: 2.198172310988108

Epoch: 5| Step: 4
Training loss: 1.0747871398925781
Validation loss: 2.234559257825216

Epoch: 5| Step: 5
Training loss: 1.5144729614257812
Validation loss: 2.2339034229516983

Epoch: 5| Step: 6
Training loss: 0.4746461510658264
Validation loss: 2.1811033536990485

Epoch: 5| Step: 7
Training loss: 1.2867093086242676
Validation loss: 2.1722392539183297

Epoch: 5| Step: 8
Training loss: 1.235107421875
Validation loss: 2.253440797328949

Epoch: 5| Step: 9
Training loss: 0.9400228261947632
Validation loss: 2.2087117483218512

Epoch: 5| Step: 10
Training loss: 0.9537562131881714
Validation loss: 2.227700168887774

Epoch: 5| Step: 11
Training loss: 0.721481204032898
Validation loss: 2.246947000424067

Epoch: 231| Step: 0
Training loss: 1.3481910228729248
Validation loss: 2.2163362006346383

Epoch: 5| Step: 1
Training loss: 1.1197978258132935
Validation loss: 2.2426586051781974

Epoch: 5| Step: 2
Training loss: 1.0851184129714966
Validation loss: 2.2683857083320618

Epoch: 5| Step: 3
Training loss: 1.3543522357940674
Validation loss: 2.237814724445343

Epoch: 5| Step: 4
Training loss: 1.2706972360610962
Validation loss: 2.199807325998942

Epoch: 5| Step: 5
Training loss: 1.1936283111572266
Validation loss: 2.2814315309127173

Epoch: 5| Step: 6
Training loss: 1.1156952381134033
Validation loss: 2.207080766558647

Epoch: 5| Step: 7
Training loss: 1.0557345151901245
Validation loss: 2.2151781171560287

Epoch: 5| Step: 8
Training loss: 1.5905959606170654
Validation loss: 2.2493616491556168

Epoch: 5| Step: 9
Training loss: 0.9889251589775085
Validation loss: 2.284246653318405

Epoch: 5| Step: 10
Training loss: 1.0965455770492554
Validation loss: 2.137926936149597

Epoch: 5| Step: 11
Training loss: 1.0179524421691895
Validation loss: 2.1593687186638513

Epoch: 232| Step: 0
Training loss: 0.7820577621459961
Validation loss: 2.2848381201426187

Epoch: 5| Step: 1
Training loss: 0.9421385526657104
Validation loss: 2.2633592933416367

Epoch: 5| Step: 2
Training loss: 0.9797531366348267
Validation loss: 2.2583869993686676

Epoch: 5| Step: 3
Training loss: 1.901789903640747
Validation loss: 2.35464845597744

Epoch: 5| Step: 4
Training loss: 1.2881555557250977
Validation loss: 2.2715342144171395

Epoch: 5| Step: 5
Training loss: 1.1208813190460205
Validation loss: 2.248553698261579

Epoch: 5| Step: 6
Training loss: 1.2989991903305054
Validation loss: 2.2255013287067413

Epoch: 5| Step: 7
Training loss: 1.4195951223373413
Validation loss: 2.220248152812322

Epoch: 5| Step: 8
Training loss: 1.548365831375122
Validation loss: 2.1948024928569794

Epoch: 5| Step: 9
Training loss: 1.535426139831543
Validation loss: 2.208542302250862

Epoch: 5| Step: 10
Training loss: 1.413254976272583
Validation loss: 2.311100030938784

Epoch: 5| Step: 11
Training loss: 0.9720536470413208
Validation loss: 2.2282694578170776

Epoch: 233| Step: 0
Training loss: 1.1401382684707642
Validation loss: 2.205621918042501

Epoch: 5| Step: 1
Training loss: 1.0421631336212158
Validation loss: 2.259700119495392

Epoch: 5| Step: 2
Training loss: 0.8428369760513306
Validation loss: 2.2848923951387405

Epoch: 5| Step: 3
Training loss: 0.8616412878036499
Validation loss: 2.2103477716445923

Epoch: 5| Step: 4
Training loss: 0.9768640398979187
Validation loss: 2.256096825003624

Epoch: 5| Step: 5
Training loss: 1.8955223560333252
Validation loss: 2.243565251429876

Epoch: 5| Step: 6
Training loss: 1.459841012954712
Validation loss: 2.2026281158129373

Epoch: 5| Step: 7
Training loss: 1.1077988147735596
Validation loss: 2.181452622016271

Epoch: 5| Step: 8
Training loss: 1.4313538074493408
Validation loss: 2.2791466613610587

Epoch: 5| Step: 9
Training loss: 1.4644420146942139
Validation loss: 2.254830688238144

Epoch: 5| Step: 10
Training loss: 1.3313992023468018
Validation loss: 2.147377615173658

Epoch: 5| Step: 11
Training loss: 1.1193172931671143
Validation loss: 2.2154904504617057

Epoch: 234| Step: 0
Training loss: 1.5043046474456787
Validation loss: 2.1872199873129525

Epoch: 5| Step: 1
Training loss: 0.9749132394790649
Validation loss: 2.13764018813769

Epoch: 5| Step: 2
Training loss: 0.9641638994216919
Validation loss: 2.1597212006648383

Epoch: 5| Step: 3
Training loss: 0.9353917837142944
Validation loss: 2.178253730138143

Epoch: 5| Step: 4
Training loss: 1.0454418659210205
Validation loss: 2.1531690061092377

Epoch: 5| Step: 5
Training loss: 1.5806068181991577
Validation loss: 2.1990482012430825

Epoch: 5| Step: 6
Training loss: 1.377685785293579
Validation loss: 2.1981806556383767

Epoch: 5| Step: 7
Training loss: 1.0650230646133423
Validation loss: 2.1787578215201697

Epoch: 5| Step: 8
Training loss: 1.2054259777069092
Validation loss: 2.235611061255137

Epoch: 5| Step: 9
Training loss: 0.8242886662483215
Validation loss: 2.192851866285006

Epoch: 5| Step: 10
Training loss: 1.1500511169433594
Validation loss: 2.2296130855878196

Epoch: 5| Step: 11
Training loss: 0.4949137270450592
Validation loss: 2.2066976875066757

Epoch: 235| Step: 0
Training loss: 0.94617760181427
Validation loss: 2.2640887399514518

Epoch: 5| Step: 1
Training loss: 1.3796203136444092
Validation loss: 2.2560331324736276

Epoch: 5| Step: 2
Training loss: 0.9184503555297852
Validation loss: 2.1636840204397836

Epoch: 5| Step: 3
Training loss: 1.2203394174575806
Validation loss: 2.258916507164637

Epoch: 5| Step: 4
Training loss: 0.9641316533088684
Validation loss: 2.2584634770949683

Epoch: 5| Step: 5
Training loss: 1.2207987308502197
Validation loss: 2.3195359806219735

Epoch: 5| Step: 6
Training loss: 1.284358263015747
Validation loss: 2.2013243039449057

Epoch: 5| Step: 7
Training loss: 0.9544886350631714
Validation loss: 2.154248168071111

Epoch: 5| Step: 8
Training loss: 1.6994136571884155
Validation loss: 2.3061895271142325

Epoch: 5| Step: 9
Training loss: 1.0572190284729004
Validation loss: 2.246355563402176

Epoch: 5| Step: 10
Training loss: 1.259956955909729
Validation loss: 2.1657025068998337

Epoch: 5| Step: 11
Training loss: 1.239188313484192
Validation loss: 2.267006983359655

Epoch: 236| Step: 0
Training loss: 1.0338194370269775
Validation loss: 2.220431407292684

Epoch: 5| Step: 1
Training loss: 0.8901233673095703
Validation loss: 2.1976990153392157

Epoch: 5| Step: 2
Training loss: 1.4348541498184204
Validation loss: 2.219521110256513

Epoch: 5| Step: 3
Training loss: 1.2872140407562256
Validation loss: 2.1667010287443795

Epoch: 5| Step: 4
Training loss: 1.1171095371246338
Validation loss: 2.1830513725678125

Epoch: 5| Step: 5
Training loss: 0.9870556592941284
Validation loss: 2.2552463610967

Epoch: 5| Step: 6
Training loss: 1.5641353130340576
Validation loss: 2.2276310125986734

Epoch: 5| Step: 7
Training loss: 1.1774543523788452
Validation loss: 2.2161547342936196

Epoch: 5| Step: 8
Training loss: 1.1111204624176025
Validation loss: 2.2687197724978128

Epoch: 5| Step: 9
Training loss: 1.0232053995132446
Validation loss: 2.23767743508021

Epoch: 5| Step: 10
Training loss: 1.1659873723983765
Validation loss: 2.2346170097589493

Epoch: 5| Step: 11
Training loss: 2.4425764083862305
Validation loss: 2.290838062763214

Epoch: 237| Step: 0
Training loss: 1.1362931728363037
Validation loss: 2.22616408765316

Epoch: 5| Step: 1
Training loss: 1.0944932699203491
Validation loss: 2.1762452175219855

Epoch: 5| Step: 2
Training loss: 1.5254783630371094
Validation loss: 2.3266076743602753

Epoch: 5| Step: 3
Training loss: 0.744376003742218
Validation loss: 2.228127638498942

Epoch: 5| Step: 4
Training loss: 0.9350061416625977
Validation loss: 2.1953372259934745

Epoch: 5| Step: 5
Training loss: 1.112766981124878
Validation loss: 2.148554707566897

Epoch: 5| Step: 6
Training loss: 1.1262266635894775
Validation loss: 2.186008006334305

Epoch: 5| Step: 7
Training loss: 1.4821803569793701
Validation loss: 2.2299868563810983

Epoch: 5| Step: 8
Training loss: 0.95655357837677
Validation loss: 2.269701525568962

Epoch: 5| Step: 9
Training loss: 1.2593863010406494
Validation loss: 2.2237894237041473

Epoch: 5| Step: 10
Training loss: 1.2152386903762817
Validation loss: 2.211348131299019

Epoch: 5| Step: 11
Training loss: 0.6790516972541809
Validation loss: 2.237839008371035

Epoch: 238| Step: 0
Training loss: 1.2401015758514404
Validation loss: 2.2659289141496024

Epoch: 5| Step: 1
Training loss: 0.9005428552627563
Validation loss: 2.2670503159364066

Epoch: 5| Step: 2
Training loss: 1.4326362609863281
Validation loss: 2.1666573882102966

Epoch: 5| Step: 3
Training loss: 1.0238292217254639
Validation loss: 2.1689438968896866

Epoch: 5| Step: 4
Training loss: 0.9167461395263672
Validation loss: 2.2320718268553414

Epoch: 5| Step: 5
Training loss: 1.4737651348114014
Validation loss: 2.250034898519516

Epoch: 5| Step: 6
Training loss: 1.1587284803390503
Validation loss: 2.304785817861557

Epoch: 5| Step: 7
Training loss: 1.4944583177566528
Validation loss: 2.2264529863993325

Epoch: 5| Step: 8
Training loss: 0.6890644431114197
Validation loss: 2.1865793267885842

Epoch: 5| Step: 9
Training loss: 1.0683972835540771
Validation loss: 2.2375130405028663

Epoch: 5| Step: 10
Training loss: 1.4937188625335693
Validation loss: 2.259515811999639

Epoch: 5| Step: 11
Training loss: 0.3766958713531494
Validation loss: 2.204519599676132

Epoch: 239| Step: 0
Training loss: 1.7158229351043701
Validation loss: 2.237268328666687

Epoch: 5| Step: 1
Training loss: 1.0023330450057983
Validation loss: 2.3276295959949493

Epoch: 5| Step: 2
Training loss: 0.9171310663223267
Validation loss: 2.259726956486702

Epoch: 5| Step: 3
Training loss: 1.03253972530365
Validation loss: 2.257777993877729

Epoch: 5| Step: 4
Training loss: 1.5428099632263184
Validation loss: 2.2278405874967575

Epoch: 5| Step: 5
Training loss: 0.9782167673110962
Validation loss: 2.2345159153143563

Epoch: 5| Step: 6
Training loss: 0.8693591356277466
Validation loss: 2.2097687224547067

Epoch: 5| Step: 7
Training loss: 0.9284273982048035
Validation loss: 2.2558111598094306

Epoch: 5| Step: 8
Training loss: 1.2633717060089111
Validation loss: 2.2338555504878364

Epoch: 5| Step: 9
Training loss: 1.5120939016342163
Validation loss: 2.263419325153033

Epoch: 5| Step: 10
Training loss: 1.4690600633621216
Validation loss: 2.252508372068405

Epoch: 5| Step: 11
Training loss: 0.6486380100250244
Validation loss: 2.177145689725876

Epoch: 240| Step: 0
Training loss: 1.2855265140533447
Validation loss: 2.219829817612966

Epoch: 5| Step: 1
Training loss: 0.7204560041427612
Validation loss: 2.156511897842089

Epoch: 5| Step: 2
Training loss: 1.2438114881515503
Validation loss: 2.105221281449

Epoch: 5| Step: 3
Training loss: 1.1004291772842407
Validation loss: 2.2130313416322074

Epoch: 5| Step: 4
Training loss: 1.2885719537734985
Validation loss: 2.250560606519381

Epoch: 5| Step: 5
Training loss: 1.6693007946014404
Validation loss: 2.253841310739517

Epoch: 5| Step: 6
Training loss: 1.0633971691131592
Validation loss: 2.2087786893049874

Epoch: 5| Step: 7
Training loss: 1.110737681388855
Validation loss: 2.2774390975634256

Epoch: 5| Step: 8
Training loss: 0.7577042579650879
Validation loss: 2.251122256120046

Epoch: 5| Step: 9
Training loss: 1.5479851961135864
Validation loss: 2.280056913693746

Epoch: 5| Step: 10
Training loss: 1.18458890914917
Validation loss: 2.2587851881980896

Epoch: 5| Step: 11
Training loss: 0.9511016011238098
Validation loss: 2.2165561815102897

Epoch: 241| Step: 0
Training loss: 1.0587661266326904
Validation loss: 2.2442347506682077

Epoch: 5| Step: 1
Training loss: 1.5113935470581055
Validation loss: 2.3063560922940574

Epoch: 5| Step: 2
Training loss: 1.294340968132019
Validation loss: 2.271210471789042

Epoch: 5| Step: 3
Training loss: 1.3474605083465576
Validation loss: 2.307696968317032

Epoch: 5| Step: 4
Training loss: 1.2735949754714966
Validation loss: 2.240466217199961

Epoch: 5| Step: 5
Training loss: 0.9549492597579956
Validation loss: 2.344141403834025

Epoch: 5| Step: 6
Training loss: 0.8824948072433472
Validation loss: 2.17904099325339

Epoch: 5| Step: 7
Training loss: 0.9985917210578918
Validation loss: 2.2201968729496

Epoch: 5| Step: 8
Training loss: 0.8543705940246582
Validation loss: 2.1854867239793143

Epoch: 5| Step: 9
Training loss: 1.3309122323989868
Validation loss: 2.240928679704666

Epoch: 5| Step: 10
Training loss: 1.4521828889846802
Validation loss: 2.2213688492774963

Epoch: 5| Step: 11
Training loss: 1.5424253940582275
Validation loss: 2.248921995361646

Epoch: 242| Step: 0
Training loss: 1.15492582321167
Validation loss: 2.1963552981615067

Epoch: 5| Step: 1
Training loss: 1.7792946100234985
Validation loss: 2.2288838028907776

Epoch: 5| Step: 2
Training loss: 1.4024016857147217
Validation loss: 2.2472180972496667

Epoch: 5| Step: 3
Training loss: 1.2030630111694336
Validation loss: 2.3295694390932717

Epoch: 5| Step: 4
Training loss: 1.04225754737854
Validation loss: 2.2229552964369454

Epoch: 5| Step: 5
Training loss: 1.2679696083068848
Validation loss: 2.337592601776123

Epoch: 5| Step: 6
Training loss: 1.145159363746643
Validation loss: 2.1836134642362595

Epoch: 5| Step: 7
Training loss: 0.6493037343025208
Validation loss: 2.2963559329509735

Epoch: 5| Step: 8
Training loss: 1.056300401687622
Validation loss: 2.2174763778845468

Epoch: 5| Step: 9
Training loss: 1.1052217483520508
Validation loss: 2.273581047852834

Epoch: 5| Step: 10
Training loss: 1.2383805513381958
Validation loss: 2.2438658823569617

Epoch: 5| Step: 11
Training loss: 0.7041432857513428
Validation loss: 2.2222151309251785

Epoch: 243| Step: 0
Training loss: 1.4083164930343628
Validation loss: 2.287100081642469

Epoch: 5| Step: 1
Training loss: 0.8392817378044128
Validation loss: 2.2472559760014215

Epoch: 5| Step: 2
Training loss: 1.2612226009368896
Validation loss: 2.1857826511065164

Epoch: 5| Step: 3
Training loss: 1.3578119277954102
Validation loss: 2.2544374962647757

Epoch: 5| Step: 4
Training loss: 1.2822405099868774
Validation loss: 2.2517859439055123

Epoch: 5| Step: 5
Training loss: 1.1313352584838867
Validation loss: 2.4021566857894263

Epoch: 5| Step: 6
Training loss: 1.2660949230194092
Validation loss: 2.320146858692169

Epoch: 5| Step: 7
Training loss: 1.5792553424835205
Validation loss: 2.314813047647476

Epoch: 5| Step: 8
Training loss: 1.2468469142913818
Validation loss: 2.2159325232108436

Epoch: 5| Step: 9
Training loss: 1.1781108379364014
Validation loss: 2.216217706600825

Epoch: 5| Step: 10
Training loss: 0.5058817863464355
Validation loss: 2.2901335656642914

Epoch: 5| Step: 11
Training loss: 0.7827298045158386
Validation loss: 2.177890419960022

Epoch: 244| Step: 0
Training loss: 0.9245918393135071
Validation loss: 2.2045031984647117

Epoch: 5| Step: 1
Training loss: 1.406036138534546
Validation loss: 2.286450664202372

Epoch: 5| Step: 2
Training loss: 0.9140521883964539
Validation loss: 2.2305230647325516

Epoch: 5| Step: 3
Training loss: 1.3794058561325073
Validation loss: 2.1562335044145584

Epoch: 5| Step: 4
Training loss: 1.4245593547821045
Validation loss: 2.2041775037844977

Epoch: 5| Step: 5
Training loss: 1.38170325756073
Validation loss: 2.2152787099281945

Epoch: 5| Step: 6
Training loss: 1.5130865573883057
Validation loss: 2.252585709095001

Epoch: 5| Step: 7
Training loss: 0.684061586856842
Validation loss: 2.1977101216713586

Epoch: 5| Step: 8
Training loss: 1.3075776100158691
Validation loss: 2.224116896589597

Epoch: 5| Step: 9
Training loss: 1.2315571308135986
Validation loss: 2.2319398671388626

Epoch: 5| Step: 10
Training loss: 1.130947470664978
Validation loss: 2.2858746349811554

Epoch: 5| Step: 11
Training loss: 0.9643657207489014
Validation loss: 2.153275971611341

Epoch: 245| Step: 0
Training loss: 0.9458853006362915
Validation loss: 2.18129692475001

Epoch: 5| Step: 1
Training loss: 1.0523532629013062
Validation loss: 2.1804796904325485

Epoch: 5| Step: 2
Training loss: 1.5356991291046143
Validation loss: 2.2323211232821145

Epoch: 5| Step: 3
Training loss: 0.8430926203727722
Validation loss: 2.2497021853923798

Epoch: 5| Step: 4
Training loss: 1.5326964855194092
Validation loss: 2.214948356151581

Epoch: 5| Step: 5
Training loss: 1.2358534336090088
Validation loss: 2.171737323204676

Epoch: 5| Step: 6
Training loss: 1.3746802806854248
Validation loss: 2.1585243741671243

Epoch: 5| Step: 7
Training loss: 0.9506518244743347
Validation loss: 2.233440106113752

Epoch: 5| Step: 8
Training loss: 0.9870413541793823
Validation loss: 2.189225216706594

Epoch: 5| Step: 9
Training loss: 0.7095636129379272
Validation loss: 2.2199438512325287

Epoch: 5| Step: 10
Training loss: 1.0314160585403442
Validation loss: 2.0792448023955026

Epoch: 5| Step: 11
Training loss: 1.344154715538025
Validation loss: 2.1766524811585746

Epoch: 246| Step: 0
Training loss: 1.1875344514846802
Validation loss: 2.295103286703428

Epoch: 5| Step: 1
Training loss: 0.837786853313446
Validation loss: 2.2273745437463126

Epoch: 5| Step: 2
Training loss: 1.1500487327575684
Validation loss: 2.2220955987771354

Epoch: 5| Step: 3
Training loss: 1.4478874206542969
Validation loss: 2.260616108775139

Epoch: 5| Step: 4
Training loss: 1.1693843603134155
Validation loss: 2.1727552811304727

Epoch: 5| Step: 5
Training loss: 1.0388215780258179
Validation loss: 2.2355839908123016

Epoch: 5| Step: 6
Training loss: 1.401606559753418
Validation loss: 2.122947702805201

Epoch: 5| Step: 7
Training loss: 1.0443568229675293
Validation loss: 2.2638323853413262

Epoch: 5| Step: 8
Training loss: 0.8703945875167847
Validation loss: 2.213097636898359

Epoch: 5| Step: 9
Training loss: 1.0732576847076416
Validation loss: 2.198323984940847

Epoch: 5| Step: 10
Training loss: 1.2855336666107178
Validation loss: 2.173400789499283

Epoch: 5| Step: 11
Training loss: 2.3508617877960205
Validation loss: 2.2554984092712402

Epoch: 247| Step: 0
Training loss: 1.188866138458252
Validation loss: 2.2642001658678055

Epoch: 5| Step: 1
Training loss: 0.6601654887199402
Validation loss: 2.2448887626330056

Epoch: 5| Step: 2
Training loss: 1.1101425886154175
Validation loss: 2.2490075826644897

Epoch: 5| Step: 3
Training loss: 1.1917191743850708
Validation loss: 2.188041796286901

Epoch: 5| Step: 4
Training loss: 1.489669919013977
Validation loss: 2.1813364376624427

Epoch: 5| Step: 5
Training loss: 1.106582760810852
Validation loss: 2.2247460335493088

Epoch: 5| Step: 6
Training loss: 1.1810839176177979
Validation loss: 2.227307359377543

Epoch: 5| Step: 7
Training loss: 1.389217495918274
Validation loss: 2.1729622185230255

Epoch: 5| Step: 8
Training loss: 0.8895902633666992
Validation loss: 2.233696758747101

Epoch: 5| Step: 9
Training loss: 1.0887258052825928
Validation loss: 2.2339745461940765

Epoch: 5| Step: 10
Training loss: 0.8971355557441711
Validation loss: 2.2119634052117667

Epoch: 5| Step: 11
Training loss: 1.2790642976760864
Validation loss: 2.2609785993893943

Epoch: 248| Step: 0
Training loss: 1.2319471836090088
Validation loss: 2.1949593673149743

Epoch: 5| Step: 1
Training loss: 1.326607584953308
Validation loss: 2.286272570490837

Epoch: 5| Step: 2
Training loss: 1.2922556400299072
Validation loss: 2.216085731983185

Epoch: 5| Step: 3
Training loss: 1.1643829345703125
Validation loss: 2.2106767743825912

Epoch: 5| Step: 4
Training loss: 1.1571900844573975
Validation loss: 2.248428136110306

Epoch: 5| Step: 5
Training loss: 0.7062567472457886
Validation loss: 2.2197441260019937

Epoch: 5| Step: 6
Training loss: 0.8061440587043762
Validation loss: 2.2196508844693503

Epoch: 5| Step: 7
Training loss: 0.9151943922042847
Validation loss: 2.217627907792727

Epoch: 5| Step: 8
Training loss: 0.9844347238540649
Validation loss: 2.189570357402166

Epoch: 5| Step: 9
Training loss: 1.5673725605010986
Validation loss: 2.1937470932801566

Epoch: 5| Step: 10
Training loss: 0.9910113215446472
Validation loss: 2.2144238402446113

Epoch: 5| Step: 11
Training loss: 0.4513707160949707
Validation loss: 2.2086992810169854

Epoch: 249| Step: 0
Training loss: 1.0684236288070679
Validation loss: 2.2215294241905212

Epoch: 5| Step: 1
Training loss: 0.8501211404800415
Validation loss: 2.283024569352468

Epoch: 5| Step: 2
Training loss: 1.2672728300094604
Validation loss: 2.207057868440946

Epoch: 5| Step: 3
Training loss: 0.9803354144096375
Validation loss: 2.1938034147024155

Epoch: 5| Step: 4
Training loss: 1.1863163709640503
Validation loss: 2.151331906517347

Epoch: 5| Step: 5
Training loss: 1.2966434955596924
Validation loss: 2.2973925868670144

Epoch: 5| Step: 6
Training loss: 1.0781586170196533
Validation loss: 2.2131079733371735

Epoch: 5| Step: 7
Training loss: 0.8960283398628235
Validation loss: 2.259305457274119

Epoch: 5| Step: 8
Training loss: 1.4815984964370728
Validation loss: 2.2596631050109863

Epoch: 5| Step: 9
Training loss: 0.8793882131576538
Validation loss: 2.145545502503713

Epoch: 5| Step: 10
Training loss: 1.0523003339767456
Validation loss: 2.371397872765859

Epoch: 5| Step: 11
Training loss: 1.2144732475280762
Validation loss: 2.2978360106547675

Epoch: 250| Step: 0
Training loss: 1.2565947771072388
Validation loss: 2.187937910358111

Epoch: 5| Step: 1
Training loss: 1.1540887355804443
Validation loss: 2.2587316781282425

Epoch: 5| Step: 2
Training loss: 1.149257779121399
Validation loss: 2.211955964565277

Epoch: 5| Step: 3
Training loss: 0.8671911358833313
Validation loss: 2.2689837515354156

Epoch: 5| Step: 4
Training loss: 0.7599490284919739
Validation loss: 2.2733546992142997

Epoch: 5| Step: 5
Training loss: 1.061325192451477
Validation loss: 2.2992015232642493

Epoch: 5| Step: 6
Training loss: 1.3129136562347412
Validation loss: 2.252497191230456

Epoch: 5| Step: 7
Training loss: 1.1074128150939941
Validation loss: 2.316594883799553

Epoch: 5| Step: 8
Training loss: 1.4969393014907837
Validation loss: 2.21834168334802

Epoch: 5| Step: 9
Training loss: 0.8218674659729004
Validation loss: 2.2442456980546317

Epoch: 5| Step: 10
Training loss: 1.3148834705352783
Validation loss: 2.2896260817845664

Epoch: 5| Step: 11
Training loss: 1.1420674324035645
Validation loss: 2.2380649199088416

Epoch: 251| Step: 0
Training loss: 1.1275408267974854
Validation loss: 2.2194193502267203

Epoch: 5| Step: 1
Training loss: 0.9168475866317749
Validation loss: 2.2400742918252945

Epoch: 5| Step: 2
Training loss: 1.2888200283050537
Validation loss: 2.1824754228194556

Epoch: 5| Step: 3
Training loss: 0.7341639399528503
Validation loss: 2.246277093887329

Epoch: 5| Step: 4
Training loss: 1.1316319704055786
Validation loss: 2.2112656186024346

Epoch: 5| Step: 5
Training loss: 1.1074087619781494
Validation loss: 2.2936930855115256

Epoch: 5| Step: 6
Training loss: 1.3874731063842773
Validation loss: 2.2004142304261527

Epoch: 5| Step: 7
Training loss: 1.0293257236480713
Validation loss: 2.271297146876653

Epoch: 5| Step: 8
Training loss: 1.339276909828186
Validation loss: 2.2325993478298187

Epoch: 5| Step: 9
Training loss: 0.9844587445259094
Validation loss: 2.251998911301295

Epoch: 5| Step: 10
Training loss: 0.9693927764892578
Validation loss: 2.1291216015815735

Epoch: 5| Step: 11
Training loss: 0.34981948137283325
Validation loss: 2.216585248708725

Epoch: 252| Step: 0
Training loss: 0.8508928418159485
Validation loss: 2.1967400113741555

Epoch: 5| Step: 1
Training loss: 0.6918762922286987
Validation loss: 2.1499225795269012

Epoch: 5| Step: 2
Training loss: 1.0621761083602905
Validation loss: 2.21538537244002

Epoch: 5| Step: 3
Training loss: 0.7991043925285339
Validation loss: 2.280684620141983

Epoch: 5| Step: 4
Training loss: 0.8383838534355164
Validation loss: 2.3059621999661126

Epoch: 5| Step: 5
Training loss: 1.5161046981811523
Validation loss: 2.267330229282379

Epoch: 5| Step: 6
Training loss: 1.0747438669204712
Validation loss: 2.349924157063166

Epoch: 5| Step: 7
Training loss: 1.2836451530456543
Validation loss: 2.2946353455384574

Epoch: 5| Step: 8
Training loss: 1.128617525100708
Validation loss: 2.1499415934085846

Epoch: 5| Step: 9
Training loss: 1.175969123840332
Validation loss: 2.2791782716910043

Epoch: 5| Step: 10
Training loss: 1.044255018234253
Validation loss: 2.1165062288443246

Epoch: 5| Step: 11
Training loss: 0.5625596642494202
Validation loss: 2.2008183548847833

Epoch: 253| Step: 0
Training loss: 1.5664188861846924
Validation loss: 2.3301484137773514

Epoch: 5| Step: 1
Training loss: 1.1512188911437988
Validation loss: 2.2663965821266174

Epoch: 5| Step: 2
Training loss: 1.4195098876953125
Validation loss: 2.1631466100613275

Epoch: 5| Step: 3
Training loss: 0.7181247472763062
Validation loss: 2.226106032729149

Epoch: 5| Step: 4
Training loss: 1.154037356376648
Validation loss: 2.18694531917572

Epoch: 5| Step: 5
Training loss: 0.9990037679672241
Validation loss: 2.201116974155108

Epoch: 5| Step: 6
Training loss: 1.2410370111465454
Validation loss: 2.2902598281701407

Epoch: 5| Step: 7
Training loss: 1.0915858745574951
Validation loss: 2.319947217901548

Epoch: 5| Step: 8
Training loss: 0.8545498847961426
Validation loss: 2.1894508550564447

Epoch: 5| Step: 9
Training loss: 1.033069133758545
Validation loss: 2.2370264728864035

Epoch: 5| Step: 10
Training loss: 1.1668994426727295
Validation loss: 2.2705125312010446

Epoch: 5| Step: 11
Training loss: 1.3154062032699585
Validation loss: 2.138343781232834

Epoch: 254| Step: 0
Training loss: 1.1404995918273926
Validation loss: 2.226415822903315

Epoch: 5| Step: 1
Training loss: 1.7101138830184937
Validation loss: 2.2405146757761636

Epoch: 5| Step: 2
Training loss: 0.9055382609367371
Validation loss: 2.2685617953538895

Epoch: 5| Step: 3
Training loss: 1.4956377744674683
Validation loss: 2.2574539681275687

Epoch: 5| Step: 4
Training loss: 0.8729472160339355
Validation loss: 2.1795725524425507

Epoch: 5| Step: 5
Training loss: 1.1753469705581665
Validation loss: 2.2137624472379684

Epoch: 5| Step: 6
Training loss: 1.0579259395599365
Validation loss: 2.218677133321762

Epoch: 5| Step: 7
Training loss: 1.1112768650054932
Validation loss: 2.186196595430374

Epoch: 5| Step: 8
Training loss: 0.8643351793289185
Validation loss: 2.1701645652453103

Epoch: 5| Step: 9
Training loss: 0.8468536138534546
Validation loss: 2.1589119881391525

Epoch: 5| Step: 10
Training loss: 1.2343205213546753
Validation loss: 2.2196477353572845

Epoch: 5| Step: 11
Training loss: 0.7075491547584534
Validation loss: 2.2933324376742044

Epoch: 255| Step: 0
Training loss: 0.9294221997261047
Validation loss: 2.137869377930959

Epoch: 5| Step: 1
Training loss: 0.7614642381668091
Validation loss: 2.264445741971334

Epoch: 5| Step: 2
Training loss: 1.0028809309005737
Validation loss: 2.204866503675779

Epoch: 5| Step: 3
Training loss: 0.7269736528396606
Validation loss: 2.184694473942121

Epoch: 5| Step: 4
Training loss: 1.0279982089996338
Validation loss: 2.2069118271271386

Epoch: 5| Step: 5
Training loss: 1.6882450580596924
Validation loss: 2.1980163802703223

Epoch: 5| Step: 6
Training loss: 0.9830141067504883
Validation loss: 2.2834284802277884

Epoch: 5| Step: 7
Training loss: 1.1847018003463745
Validation loss: 2.2890029003222785

Epoch: 5| Step: 8
Training loss: 1.300023078918457
Validation loss: 2.201254576444626

Epoch: 5| Step: 9
Training loss: 0.973387598991394
Validation loss: 2.277716875076294

Epoch: 5| Step: 10
Training loss: 1.0540708303451538
Validation loss: 2.2331941723823547

Epoch: 5| Step: 11
Training loss: 2.4442310333251953
Validation loss: 2.198388854662577

Epoch: 256| Step: 0
Training loss: 0.7418226003646851
Validation loss: 2.2084804276625314

Epoch: 5| Step: 1
Training loss: 1.3782869577407837
Validation loss: 2.1734249790509543

Epoch: 5| Step: 2
Training loss: 0.8818613290786743
Validation loss: 2.2599155803521476

Epoch: 5| Step: 3
Training loss: 1.3419618606567383
Validation loss: 2.256134649117788

Epoch: 5| Step: 4
Training loss: 1.3890551328659058
Validation loss: 2.29750927289327

Epoch: 5| Step: 5
Training loss: 1.7966597080230713
Validation loss: 2.1718805531660714

Epoch: 5| Step: 6
Training loss: 0.823257565498352
Validation loss: 2.272734542687734

Epoch: 5| Step: 7
Training loss: 1.816457748413086
Validation loss: 2.25442236661911

Epoch: 5| Step: 8
Training loss: 0.9056450128555298
Validation loss: 2.1771359592676163

Epoch: 5| Step: 9
Training loss: 0.8144360780715942
Validation loss: 2.1532860646645227

Epoch: 5| Step: 10
Training loss: 0.8417328000068665
Validation loss: 2.2184676130612693

Epoch: 5| Step: 11
Training loss: 0.6949136257171631
Validation loss: 2.195691625277201

Epoch: 257| Step: 0
Training loss: 1.2478537559509277
Validation loss: 2.1879250903924308

Epoch: 5| Step: 1
Training loss: 1.1287708282470703
Validation loss: 2.24666894475619

Epoch: 5| Step: 2
Training loss: 1.0846307277679443
Validation loss: 2.1914229889710746

Epoch: 5| Step: 3
Training loss: 0.7884215712547302
Validation loss: 2.1921044240395227

Epoch: 5| Step: 4
Training loss: 1.0648406744003296
Validation loss: 2.2310450673103333

Epoch: 5| Step: 5
Training loss: 0.6919234395027161
Validation loss: 2.1924616346756616

Epoch: 5| Step: 6
Training loss: 0.8643434643745422
Validation loss: 2.1786175072193146

Epoch: 5| Step: 7
Training loss: 1.0966588258743286
Validation loss: 2.2791513899962106

Epoch: 5| Step: 8
Training loss: 1.064464807510376
Validation loss: 2.17184250553449

Epoch: 5| Step: 9
Training loss: 1.5148195028305054
Validation loss: 2.2201476792494454

Epoch: 5| Step: 10
Training loss: 1.1910849809646606
Validation loss: 2.239643414815267

Epoch: 5| Step: 11
Training loss: 1.2398664951324463
Validation loss: 2.216450725992521

Epoch: 258| Step: 0
Training loss: 1.148559331893921
Validation loss: 2.203005443016688

Epoch: 5| Step: 1
Training loss: 1.0657389163970947
Validation loss: 2.1841660290956497

Epoch: 5| Step: 2
Training loss: 0.6626914739608765
Validation loss: 2.2204929242531457

Epoch: 5| Step: 3
Training loss: 0.9742337465286255
Validation loss: 2.2634221613407135

Epoch: 5| Step: 4
Training loss: 1.3492627143859863
Validation loss: 2.2249938497940698

Epoch: 5| Step: 5
Training loss: 0.9697020649909973
Validation loss: 2.27196171383063

Epoch: 5| Step: 6
Training loss: 0.9750782251358032
Validation loss: 2.214914083480835

Epoch: 5| Step: 7
Training loss: 0.9933689832687378
Validation loss: 2.2369839946428933

Epoch: 5| Step: 8
Training loss: 1.1542695760726929
Validation loss: 2.2384601334730783

Epoch: 5| Step: 9
Training loss: 1.5353014469146729
Validation loss: 2.2087973207235336

Epoch: 5| Step: 10
Training loss: 0.8159297704696655
Validation loss: 2.2386826823155084

Epoch: 5| Step: 11
Training loss: 2.1861157417297363
Validation loss: 2.295760134855906

Epoch: 259| Step: 0
Training loss: 1.1386730670928955
Validation loss: 2.2778393526872

Epoch: 5| Step: 1
Training loss: 0.7466448545455933
Validation loss: 2.2760725766420364

Epoch: 5| Step: 2
Training loss: 1.6558338403701782
Validation loss: 2.2080278197924295

Epoch: 5| Step: 3
Training loss: 1.1979703903198242
Validation loss: 2.233445038398107

Epoch: 5| Step: 4
Training loss: 1.456374168395996
Validation loss: 2.2583435078461966

Epoch: 5| Step: 5
Training loss: 1.1327918767929077
Validation loss: 2.2299916545550027

Epoch: 5| Step: 6
Training loss: 0.5738829970359802
Validation loss: 2.2606374820073447

Epoch: 5| Step: 7
Training loss: 0.9005694389343262
Validation loss: 2.2729050517082214

Epoch: 5| Step: 8
Training loss: 0.9892891049385071
Validation loss: 2.2380978713432946

Epoch: 5| Step: 9
Training loss: 0.939482569694519
Validation loss: 2.333392560482025

Epoch: 5| Step: 10
Training loss: 0.9734058380126953
Validation loss: 2.330585300922394

Epoch: 5| Step: 11
Training loss: 0.5708643794059753
Validation loss: 2.2637461771567664

Epoch: 260| Step: 0
Training loss: 0.8115361332893372
Validation loss: 2.274696171283722

Epoch: 5| Step: 1
Training loss: 0.9319887161254883
Validation loss: 2.2538221975167594

Epoch: 5| Step: 2
Training loss: 0.6457945704460144
Validation loss: 2.33201697965463

Epoch: 5| Step: 3
Training loss: 1.4337942600250244
Validation loss: 2.1883176267147064

Epoch: 5| Step: 4
Training loss: 0.7609978914260864
Validation loss: 2.250622441371282

Epoch: 5| Step: 5
Training loss: 1.5392076969146729
Validation loss: 2.3050720592339835

Epoch: 5| Step: 6
Training loss: 0.6672273874282837
Validation loss: 2.2224069436391196

Epoch: 5| Step: 7
Training loss: 0.7033458948135376
Validation loss: 2.246679166952769

Epoch: 5| Step: 8
Training loss: 1.0110496282577515
Validation loss: 2.2207333768407502

Epoch: 5| Step: 9
Training loss: 0.9432517886161804
Validation loss: 2.2023073782523475

Epoch: 5| Step: 10
Training loss: 1.6236339807510376
Validation loss: 2.3030049204826355

Epoch: 5| Step: 11
Training loss: 1.5152560472488403
Validation loss: 2.2231973906358085

Epoch: 261| Step: 0
Training loss: 1.1547555923461914
Validation loss: 2.223199342687925

Epoch: 5| Step: 1
Training loss: 0.9847079515457153
Validation loss: 2.3012977143128714

Epoch: 5| Step: 2
Training loss: 1.5885549783706665
Validation loss: 2.3339981138706207

Epoch: 5| Step: 3
Training loss: 1.0813068151474
Validation loss: 2.358248089750608

Epoch: 5| Step: 4
Training loss: 0.7767897844314575
Validation loss: 2.222426936030388

Epoch: 5| Step: 5
Training loss: 0.7239810228347778
Validation loss: 2.223853384455045

Epoch: 5| Step: 6
Training loss: 0.9082186818122864
Validation loss: 2.3881598909695945

Epoch: 5| Step: 7
Training loss: 1.295716404914856
Validation loss: 2.2963785231113434

Epoch: 5| Step: 8
Training loss: 0.6797768473625183
Validation loss: 2.2144044836362204

Epoch: 5| Step: 9
Training loss: 1.3232572078704834
Validation loss: 2.1847687562306723

Epoch: 5| Step: 10
Training loss: 1.2215759754180908
Validation loss: 2.3056436578432717

Epoch: 5| Step: 11
Training loss: 1.616937518119812
Validation loss: 2.1886001229286194

Epoch: 262| Step: 0
Training loss: 0.7857990264892578
Validation loss: 2.2042239904403687

Epoch: 5| Step: 1
Training loss: 0.7206895351409912
Validation loss: 2.1785382330417633

Epoch: 5| Step: 2
Training loss: 1.272883653640747
Validation loss: 2.291004111369451

Epoch: 5| Step: 3
Training loss: 1.624255895614624
Validation loss: 2.212481757005056

Epoch: 5| Step: 4
Training loss: 1.0339175462722778
Validation loss: 2.2374413460493088

Epoch: 5| Step: 5
Training loss: 0.8388918042182922
Validation loss: 2.2860627869764962

Epoch: 5| Step: 6
Training loss: 1.217944622039795
Validation loss: 2.227835257848104

Epoch: 5| Step: 7
Training loss: 0.9458478689193726
Validation loss: 2.1918283700942993

Epoch: 5| Step: 8
Training loss: 1.101726770401001
Validation loss: 2.245369811852773

Epoch: 5| Step: 9
Training loss: 0.7214753031730652
Validation loss: 2.234900106986364

Epoch: 5| Step: 10
Training loss: 1.0037184953689575
Validation loss: 2.2555692195892334

Epoch: 5| Step: 11
Training loss: 1.2992974519729614
Validation loss: 2.2817048331101737

Epoch: 263| Step: 0
Training loss: 1.0447008609771729
Validation loss: 2.3223329186439514

Epoch: 5| Step: 1
Training loss: 1.6674044132232666
Validation loss: 2.269039829572042

Epoch: 5| Step: 2
Training loss: 1.0796376466751099
Validation loss: 2.3272252728541694

Epoch: 5| Step: 3
Training loss: 1.3473875522613525
Validation loss: 2.3109313448270163

Epoch: 5| Step: 4
Training loss: 1.0996434688568115
Validation loss: 2.2393467674652734

Epoch: 5| Step: 5
Training loss: 0.9928134083747864
Validation loss: 2.226240207751592

Epoch: 5| Step: 6
Training loss: 0.9666226506233215
Validation loss: 2.1948164651791253

Epoch: 5| Step: 7
Training loss: 0.9164962768554688
Validation loss: 2.2877312004566193

Epoch: 5| Step: 8
Training loss: 0.9111200571060181
Validation loss: 2.201327214638392

Epoch: 5| Step: 9
Training loss: 0.8779096603393555
Validation loss: 2.28401118516922

Epoch: 5| Step: 10
Training loss: 0.7997047305107117
Validation loss: 2.2714680234591165

Epoch: 5| Step: 11
Training loss: 1.65740168094635
Validation loss: 2.218908523519834

Epoch: 264| Step: 0
Training loss: 0.934813380241394
Validation loss: 2.211906005938848

Epoch: 5| Step: 1
Training loss: 1.318519115447998
Validation loss: 2.209146797657013

Epoch: 5| Step: 2
Training loss: 0.8041707873344421
Validation loss: 2.307283729314804

Epoch: 5| Step: 3
Training loss: 0.9003350138664246
Validation loss: 2.242805451154709

Epoch: 5| Step: 4
Training loss: 1.706134557723999
Validation loss: 2.2212310433387756

Epoch: 5| Step: 5
Training loss: 1.1067479848861694
Validation loss: 2.2452808221181235

Epoch: 5| Step: 6
Training loss: 0.7359251976013184
Validation loss: 2.2904047767321267

Epoch: 5| Step: 7
Training loss: 1.0421503782272339
Validation loss: 2.2870481510957084

Epoch: 5| Step: 8
Training loss: 1.0838487148284912
Validation loss: 2.241123785575231

Epoch: 5| Step: 9
Training loss: 1.1345418691635132
Validation loss: 2.2202228307724

Epoch: 5| Step: 10
Training loss: 1.462132215499878
Validation loss: 2.1843534062306085

Epoch: 5| Step: 11
Training loss: 0.9382184743881226
Validation loss: 2.1869041423002877

Epoch: 265| Step: 0
Training loss: 1.458557367324829
Validation loss: 2.25000990430514

Epoch: 5| Step: 1
Training loss: 0.7970136404037476
Validation loss: 2.2746447573105493

Epoch: 5| Step: 2
Training loss: 0.6942015290260315
Validation loss: 2.2539794544378915

Epoch: 5| Step: 3
Training loss: 1.2253732681274414
Validation loss: 2.2775832464297614

Epoch: 5| Step: 4
Training loss: 0.7118760943412781
Validation loss: 2.2129374146461487

Epoch: 5| Step: 5
Training loss: 1.0957854986190796
Validation loss: 2.209919815262159

Epoch: 5| Step: 6
Training loss: 1.2827365398406982
Validation loss: 2.2249981264273324

Epoch: 5| Step: 7
Training loss: 0.5896316766738892
Validation loss: 2.2817735771338143

Epoch: 5| Step: 8
Training loss: 0.9603264927864075
Validation loss: 2.319887936115265

Epoch: 5| Step: 9
Training loss: 1.5741541385650635
Validation loss: 2.2768004337946572

Epoch: 5| Step: 10
Training loss: 0.8470776677131653
Validation loss: 2.2367177853981652

Epoch: 5| Step: 11
Training loss: 1.1024718284606934
Validation loss: 2.223087047537168

Epoch: 266| Step: 0
Training loss: 0.8411763906478882
Validation loss: 2.258204827706019

Epoch: 5| Step: 1
Training loss: 1.0375242233276367
Validation loss: 2.293981065352758

Epoch: 5| Step: 2
Training loss: 1.00566565990448
Validation loss: 2.2005693316459656

Epoch: 5| Step: 3
Training loss: 0.6048847436904907
Validation loss: 2.307719628016154

Epoch: 5| Step: 4
Training loss: 1.2083015441894531
Validation loss: 2.2469168106714883

Epoch: 5| Step: 5
Training loss: 1.2924679517745972
Validation loss: 2.210369497537613

Epoch: 5| Step: 6
Training loss: 0.9108028411865234
Validation loss: 2.277314384778341

Epoch: 5| Step: 7
Training loss: 0.7653430700302124
Validation loss: 2.204104259610176

Epoch: 5| Step: 8
Training loss: 1.0504969358444214
Validation loss: 2.2699346443017325

Epoch: 5| Step: 9
Training loss: 1.2148501873016357
Validation loss: 2.239702840646108

Epoch: 5| Step: 10
Training loss: 0.6293774843215942
Validation loss: 2.3099295099576316

Epoch: 5| Step: 11
Training loss: 1.339104413986206
Validation loss: 2.2158388743797937

Epoch: 267| Step: 0
Training loss: 1.0807088613510132
Validation loss: 2.2105771899223328

Epoch: 5| Step: 1
Training loss: 1.0567371845245361
Validation loss: 2.193596844871839

Epoch: 5| Step: 2
Training loss: 1.1294023990631104
Validation loss: 2.1983533004919686

Epoch: 5| Step: 3
Training loss: 0.9319913983345032
Validation loss: 2.2471878230571747

Epoch: 5| Step: 4
Training loss: 0.6921737194061279
Validation loss: 2.147034674882889

Epoch: 5| Step: 5
Training loss: 1.2516543865203857
Validation loss: 2.254847521583239

Epoch: 5| Step: 6
Training loss: 1.6944382190704346
Validation loss: 2.261063744624456

Epoch: 5| Step: 7
Training loss: 0.8406898379325867
Validation loss: 2.304690400759379

Epoch: 5| Step: 8
Training loss: 0.776640772819519
Validation loss: 2.2578600893417993

Epoch: 5| Step: 9
Training loss: 0.8152905702590942
Validation loss: 2.2083040277163186

Epoch: 5| Step: 10
Training loss: 0.7609623074531555
Validation loss: 2.28583071132501

Epoch: 5| Step: 11
Training loss: 0.5909886956214905
Validation loss: 2.172688548763593

Epoch: 268| Step: 0
Training loss: 0.8172666430473328
Validation loss: 2.293480013807615

Epoch: 5| Step: 1
Training loss: 0.7528277039527893
Validation loss: 2.212998037536939

Epoch: 5| Step: 2
Training loss: 1.1514904499053955
Validation loss: 2.257445285717646

Epoch: 5| Step: 3
Training loss: 1.3264285326004028
Validation loss: 2.2061358839273453

Epoch: 5| Step: 4
Training loss: 1.095717430114746
Validation loss: 2.262970527013143

Epoch: 5| Step: 5
Training loss: 0.9138385653495789
Validation loss: 2.230633422732353

Epoch: 5| Step: 6
Training loss: 0.6574137210845947
Validation loss: 2.2907973726590476

Epoch: 5| Step: 7
Training loss: 1.273494839668274
Validation loss: 2.2470245907704034

Epoch: 5| Step: 8
Training loss: 1.100069284439087
Validation loss: 2.241326649983724

Epoch: 5| Step: 9
Training loss: 0.887222945690155
Validation loss: 2.2365761498610177

Epoch: 5| Step: 10
Training loss: 0.8851686716079712
Validation loss: 2.2805753350257874

Epoch: 5| Step: 11
Training loss: 1.5372384786605835
Validation loss: 2.2688414802153907

Epoch: 269| Step: 0
Training loss: 1.0886828899383545
Validation loss: 2.252388978997866

Epoch: 5| Step: 1
Training loss: 1.1826817989349365
Validation loss: 2.295995205640793

Epoch: 5| Step: 2
Training loss: 1.235447645187378
Validation loss: 2.3261280953884125

Epoch: 5| Step: 3
Training loss: 0.7771885991096497
Validation loss: 2.227081388235092

Epoch: 5| Step: 4
Training loss: 0.911266028881073
Validation loss: 2.2275814364353814

Epoch: 5| Step: 5
Training loss: 0.8690622448921204
Validation loss: 2.2451900045077005

Epoch: 5| Step: 6
Training loss: 1.4722306728363037
Validation loss: 2.260822907090187

Epoch: 5| Step: 7
Training loss: 0.8575210571289062
Validation loss: 2.2587184061606727

Epoch: 5| Step: 8
Training loss: 0.9538646936416626
Validation loss: 2.2363374829292297

Epoch: 5| Step: 9
Training loss: 0.9399898648262024
Validation loss: 2.212232396006584

Epoch: 5| Step: 10
Training loss: 0.8592438697814941
Validation loss: 2.2856901635726294

Epoch: 5| Step: 11
Training loss: 1.3727387189865112
Validation loss: 2.2154916723569236

Epoch: 270| Step: 0
Training loss: 1.2230136394500732
Validation loss: 2.1763499478499093

Epoch: 5| Step: 1
Training loss: 0.7185896039009094
Validation loss: 2.255153919259707

Epoch: 5| Step: 2
Training loss: 0.9515558481216431
Validation loss: 2.2034039994080863

Epoch: 5| Step: 3
Training loss: 0.8900810480117798
Validation loss: 2.1883264730374017

Epoch: 5| Step: 4
Training loss: 1.3441433906555176
Validation loss: 2.195447569092115

Epoch: 5| Step: 5
Training loss: 0.9054404497146606
Validation loss: 2.2772581974665322

Epoch: 5| Step: 6
Training loss: 1.1597061157226562
Validation loss: 2.199816346168518

Epoch: 5| Step: 7
Training loss: 0.9294593930244446
Validation loss: 2.2091150482495627

Epoch: 5| Step: 8
Training loss: 0.6754705309867859
Validation loss: 2.160933017730713

Epoch: 5| Step: 9
Training loss: 0.8526689410209656
Validation loss: 2.3037711828947067

Epoch: 5| Step: 10
Training loss: 1.1190017461776733
Validation loss: 2.193652222553889

Epoch: 5| Step: 11
Training loss: 0.7312737107276917
Validation loss: 2.1763207664092383

Epoch: 271| Step: 0
Training loss: 0.7254693508148193
Validation loss: 2.2480832686026893

Epoch: 5| Step: 1
Training loss: 0.7982143759727478
Validation loss: 2.2258591453234353

Epoch: 5| Step: 2
Training loss: 0.7307707667350769
Validation loss: 2.254668354988098

Epoch: 5| Step: 3
Training loss: 0.8061863780021667
Validation loss: 2.2335906426111856

Epoch: 5| Step: 4
Training loss: 1.2968456745147705
Validation loss: 2.33546773592631

Epoch: 5| Step: 5
Training loss: 0.5872150659561157
Validation loss: 2.2770145485798516

Epoch: 5| Step: 6
Training loss: 1.1225486993789673
Validation loss: 2.2848596374193826

Epoch: 5| Step: 7
Training loss: 0.905219554901123
Validation loss: 2.1928134659926095

Epoch: 5| Step: 8
Training loss: 0.8541502952575684
Validation loss: 2.269037514925003

Epoch: 5| Step: 9
Training loss: 1.7168071269989014
Validation loss: 2.169419820110003

Epoch: 5| Step: 10
Training loss: 0.9542533159255981
Validation loss: 2.2055530101060867

Epoch: 5| Step: 11
Training loss: 1.1663382053375244
Validation loss: 2.2863433957099915

Epoch: 272| Step: 0
Training loss: 0.989771842956543
Validation loss: 2.352577805519104

Epoch: 5| Step: 1
Training loss: 0.7982214689254761
Validation loss: 2.2061305145422616

Epoch: 5| Step: 2
Training loss: 0.8032161593437195
Validation loss: 2.235953619082769

Epoch: 5| Step: 3
Training loss: 0.8242877125740051
Validation loss: 2.278675784667333

Epoch: 5| Step: 4
Training loss: 1.0375096797943115
Validation loss: 2.2900851666927338

Epoch: 5| Step: 5
Training loss: 0.9372941851615906
Validation loss: 2.262537563840548

Epoch: 5| Step: 6
Training loss: 1.0960397720336914
Validation loss: 2.1501359045505524

Epoch: 5| Step: 7
Training loss: 0.7198835015296936
Validation loss: 2.323249042034149

Epoch: 5| Step: 8
Training loss: 1.1984460353851318
Validation loss: 2.3998494148254395

Epoch: 5| Step: 9
Training loss: 0.8198148608207703
Validation loss: 2.198560059070587

Epoch: 5| Step: 10
Training loss: 1.162509799003601
Validation loss: 2.2394415885210037

Epoch: 5| Step: 11
Training loss: 1.7475712299346924
Validation loss: 2.2537600696086884

Epoch: 273| Step: 0
Training loss: 0.7559657096862793
Validation loss: 2.2258346676826477

Epoch: 5| Step: 1
Training loss: 1.1935317516326904
Validation loss: 2.269868552684784

Epoch: 5| Step: 2
Training loss: 1.2810428142547607
Validation loss: 2.2836390485366187

Epoch: 5| Step: 3
Training loss: 0.6915627717971802
Validation loss: 2.226104348897934

Epoch: 5| Step: 4
Training loss: 1.1056582927703857
Validation loss: 2.222376470764478

Epoch: 5| Step: 5
Training loss: 0.7279958724975586
Validation loss: 2.1775839229424796

Epoch: 5| Step: 6
Training loss: 0.6591867208480835
Validation loss: 2.19641021390756

Epoch: 5| Step: 7
Training loss: 0.9712602496147156
Validation loss: 2.2329988876978555

Epoch: 5| Step: 8
Training loss: 1.0172431468963623
Validation loss: 2.2270146707693734

Epoch: 5| Step: 9
Training loss: 0.702349841594696
Validation loss: 2.262214203675588

Epoch: 5| Step: 10
Training loss: 1.3757833242416382
Validation loss: 2.277382026116053

Epoch: 5| Step: 11
Training loss: 0.5521311163902283
Validation loss: 2.2608060389757156

Epoch: 274| Step: 0
Training loss: 0.8747302293777466
Validation loss: 2.2734875977039337

Epoch: 5| Step: 1
Training loss: 0.5692434310913086
Validation loss: 2.2288711965084076

Epoch: 5| Step: 2
Training loss: 0.8088949918746948
Validation loss: 2.153775706887245

Epoch: 5| Step: 3
Training loss: 1.3357757329940796
Validation loss: 2.1951731741428375

Epoch: 5| Step: 4
Training loss: 0.7373080253601074
Validation loss: 2.283118113875389

Epoch: 5| Step: 5
Training loss: 0.7437613010406494
Validation loss: 2.2400094668070474

Epoch: 5| Step: 6
Training loss: 1.2565778493881226
Validation loss: 2.2882303297519684

Epoch: 5| Step: 7
Training loss: 1.0647382736206055
Validation loss: 2.286587874094645

Epoch: 5| Step: 8
Training loss: 0.9853232502937317
Validation loss: 2.335443009932836

Epoch: 5| Step: 9
Training loss: 0.6819466352462769
Validation loss: 2.249768371383349

Epoch: 5| Step: 10
Training loss: 0.949687659740448
Validation loss: 2.22987308104833

Epoch: 5| Step: 11
Training loss: 0.4690297842025757
Validation loss: 2.240554541349411

Epoch: 275| Step: 0
Training loss: 0.8453252911567688
Validation loss: 2.2949859450260797

Epoch: 5| Step: 1
Training loss: 0.8731385469436646
Validation loss: 2.282842422525088

Epoch: 5| Step: 2
Training loss: 0.9285768270492554
Validation loss: 2.3351173053185144

Epoch: 5| Step: 3
Training loss: 0.7032467126846313
Validation loss: 2.1922679940859475

Epoch: 5| Step: 4
Training loss: 1.20375657081604
Validation loss: 2.304471363623937

Epoch: 5| Step: 5
Training loss: 0.7843312621116638
Validation loss: 2.291693836450577

Epoch: 5| Step: 6
Training loss: 0.9470933079719543
Validation loss: 2.321787973244985

Epoch: 5| Step: 7
Training loss: 0.9191379547119141
Validation loss: 2.2537652204434075

Epoch: 5| Step: 8
Training loss: 1.0382394790649414
Validation loss: 2.283538614710172

Epoch: 5| Step: 9
Training loss: 0.5303654670715332
Validation loss: 2.228984256585439

Epoch: 5| Step: 10
Training loss: 1.3037017583847046
Validation loss: 2.21464496354262

Epoch: 5| Step: 11
Training loss: 1.0932016372680664
Validation loss: 2.3154931167761483

Epoch: 276| Step: 0
Training loss: 1.412294626235962
Validation loss: 2.2420640339454017

Epoch: 5| Step: 1
Training loss: 1.093363642692566
Validation loss: 2.254269003868103

Epoch: 5| Step: 2
Training loss: 0.8288215398788452
Validation loss: 2.217507133881251

Epoch: 5| Step: 3
Training loss: 0.7468123435974121
Validation loss: 2.2246880481640496

Epoch: 5| Step: 4
Training loss: 0.8958770632743835
Validation loss: 2.294626315434774

Epoch: 5| Step: 5
Training loss: 1.2533704042434692
Validation loss: 2.2992409567038217

Epoch: 5| Step: 6
Training loss: 0.8587333559989929
Validation loss: 2.217432419459025

Epoch: 5| Step: 7
Training loss: 0.9584236145019531
Validation loss: 2.2932400902112327

Epoch: 5| Step: 8
Training loss: 0.70703125
Validation loss: 2.307473431030909

Epoch: 5| Step: 9
Training loss: 0.6447674632072449
Validation loss: 2.308698217074076

Epoch: 5| Step: 10
Training loss: 1.0340375900268555
Validation loss: 2.2172122498353324

Epoch: 5| Step: 11
Training loss: 0.8083879351615906
Validation loss: 2.169097046057383

Epoch: 277| Step: 0
Training loss: 0.9318486452102661
Validation loss: 2.2237060268719993

Epoch: 5| Step: 1
Training loss: 1.062597632408142
Validation loss: 2.2266258597373962

Epoch: 5| Step: 2
Training loss: 1.265592336654663
Validation loss: 2.227493554353714

Epoch: 5| Step: 3
Training loss: 1.2239091396331787
Validation loss: 2.2689811984697976

Epoch: 5| Step: 4
Training loss: 0.7639405727386475
Validation loss: 2.281520148118337

Epoch: 5| Step: 5
Training loss: 0.5151423811912537
Validation loss: 2.3229480981826782

Epoch: 5| Step: 6
Training loss: 1.0616241693496704
Validation loss: 2.2931261509656906

Epoch: 5| Step: 7
Training loss: 0.6960910558700562
Validation loss: 2.3082204461097717

Epoch: 5| Step: 8
Training loss: 0.7600571513175964
Validation loss: 2.3130485067764917

Epoch: 5| Step: 9
Training loss: 1.1113243103027344
Validation loss: 2.2987568080425262

Epoch: 5| Step: 10
Training loss: 0.7568281888961792
Validation loss: 2.3014128456513085

Epoch: 5| Step: 11
Training loss: 0.6829229593276978
Validation loss: 2.3284697284301124

Epoch: 278| Step: 0
Training loss: 1.1421667337417603
Validation loss: 2.2592742244402566

Epoch: 5| Step: 1
Training loss: 0.5229396224021912
Validation loss: 2.2900031159321466

Epoch: 5| Step: 2
Training loss: 0.9174167513847351
Validation loss: 2.2991785208384194

Epoch: 5| Step: 3
Training loss: 0.9885730743408203
Validation loss: 2.313448150952657

Epoch: 5| Step: 4
Training loss: 0.5763460397720337
Validation loss: 2.2691101729869843

Epoch: 5| Step: 5
Training loss: 0.39857202768325806
Validation loss: 2.2396289308865867

Epoch: 5| Step: 6
Training loss: 1.0215647220611572
Validation loss: 2.2634939153989158

Epoch: 5| Step: 7
Training loss: 1.474120855331421
Validation loss: 2.3489578117926917

Epoch: 5| Step: 8
Training loss: 0.9018068313598633
Validation loss: 2.3226911624272666

Epoch: 5| Step: 9
Training loss: 1.0404043197631836
Validation loss: 2.301929304997126

Epoch: 5| Step: 10
Training loss: 1.4613170623779297
Validation loss: 2.2951232145229974

Epoch: 5| Step: 11
Training loss: 0.8202714323997498
Validation loss: 2.286223610242208

Epoch: 279| Step: 0
Training loss: 1.2990655899047852
Validation loss: 2.3392022252082825

Epoch: 5| Step: 1
Training loss: 0.8039045333862305
Validation loss: 2.232626994450887

Epoch: 5| Step: 2
Training loss: 0.9646198153495789
Validation loss: 2.3218828241030374

Epoch: 5| Step: 3
Training loss: 1.1310646533966064
Validation loss: 2.3441419204076133

Epoch: 5| Step: 4
Training loss: 0.7631188631057739
Validation loss: 2.374134505788485

Epoch: 5| Step: 5
Training loss: 1.3439929485321045
Validation loss: 2.3435801963011422

Epoch: 5| Step: 6
Training loss: 1.5029137134552002
Validation loss: 2.28998656074206

Epoch: 5| Step: 7
Training loss: 0.7977639436721802
Validation loss: 2.338816394408544

Epoch: 5| Step: 8
Training loss: 1.0230443477630615
Validation loss: 2.2684576511383057

Epoch: 5| Step: 9
Training loss: 0.6233475804328918
Validation loss: 2.3475151658058167

Epoch: 5| Step: 10
Training loss: 0.8372749090194702
Validation loss: 2.345600500702858

Epoch: 5| Step: 11
Training loss: 0.7445653080940247
Validation loss: 2.2178322772185006

Epoch: 280| Step: 0
Training loss: 1.2951815128326416
Validation loss: 2.287658909956614

Epoch: 5| Step: 1
Training loss: 0.8999101519584656
Validation loss: 2.28061780333519

Epoch: 5| Step: 2
Training loss: 0.9304391145706177
Validation loss: 2.241558939218521

Epoch: 5| Step: 3
Training loss: 0.9241346120834351
Validation loss: 2.3421155164639154

Epoch: 5| Step: 4
Training loss: 0.7490800619125366
Validation loss: 2.3267173717419305

Epoch: 5| Step: 5
Training loss: 0.8727566003799438
Validation loss: 2.2814291765292487

Epoch: 5| Step: 6
Training loss: 1.0660845041275024
Validation loss: 2.30345256626606

Epoch: 5| Step: 7
Training loss: 0.921229362487793
Validation loss: 2.333649903535843

Epoch: 5| Step: 8
Training loss: 1.1485464572906494
Validation loss: 2.212317168712616

Epoch: 5| Step: 9
Training loss: 0.7366611361503601
Validation loss: 2.3020174403985343

Epoch: 5| Step: 10
Training loss: 0.7681514620780945
Validation loss: 2.284523551662763

Epoch: 5| Step: 11
Training loss: 0.7624057531356812
Validation loss: 2.2437025010585785

Epoch: 281| Step: 0
Training loss: 0.6778304576873779
Validation loss: 2.2948401868343353

Epoch: 5| Step: 1
Training loss: 0.8309538960456848
Validation loss: 2.268064926067988

Epoch: 5| Step: 2
Training loss: 0.8531296849250793
Validation loss: 2.3006766637166343

Epoch: 5| Step: 3
Training loss: 1.0332231521606445
Validation loss: 2.3038334449132285

Epoch: 5| Step: 4
Training loss: 0.8126058578491211
Validation loss: 2.30185529589653

Epoch: 5| Step: 5
Training loss: 1.5141706466674805
Validation loss: 2.220812439918518

Epoch: 5| Step: 6
Training loss: 1.1334455013275146
Validation loss: 2.3152121106783548

Epoch: 5| Step: 7
Training loss: 1.1631639003753662
Validation loss: 2.3183367550373077

Epoch: 5| Step: 8
Training loss: 0.7090759873390198
Validation loss: 2.2404367178678513

Epoch: 5| Step: 9
Training loss: 0.7264840602874756
Validation loss: 2.2420268456141152

Epoch: 5| Step: 10
Training loss: 0.8426566123962402
Validation loss: 2.2690500815709433

Epoch: 5| Step: 11
Training loss: 0.8993608951568604
Validation loss: 2.3015850683053336

Epoch: 282| Step: 0
Training loss: 0.8343908190727234
Validation loss: 2.2962923546632132

Epoch: 5| Step: 1
Training loss: 0.7168956398963928
Validation loss: 2.241684893767039

Epoch: 5| Step: 2
Training loss: 0.8891636729240417
Validation loss: 2.2472232381502786

Epoch: 5| Step: 3
Training loss: 0.7770639657974243
Validation loss: 2.2809417992830276

Epoch: 5| Step: 4
Training loss: 0.9795769453048706
Validation loss: 2.267233818769455

Epoch: 5| Step: 5
Training loss: 0.8659436106681824
Validation loss: 2.2981383552153907

Epoch: 5| Step: 6
Training loss: 1.1495370864868164
Validation loss: 2.2373098532358804

Epoch: 5| Step: 7
Training loss: 0.8151469230651855
Validation loss: 2.343792349100113

Epoch: 5| Step: 8
Training loss: 0.6093461513519287
Validation loss: 2.365852013230324

Epoch: 5| Step: 9
Training loss: 1.1922370195388794
Validation loss: 2.330787772933642

Epoch: 5| Step: 10
Training loss: 0.8012568354606628
Validation loss: 2.2640306254227958

Epoch: 5| Step: 11
Training loss: 0.765117883682251
Validation loss: 2.2318929533163705

Epoch: 283| Step: 0
Training loss: 0.871180534362793
Validation loss: 2.2799391746520996

Epoch: 5| Step: 1
Training loss: 0.7562111616134644
Validation loss: 2.271614278356234

Epoch: 5| Step: 2
Training loss: 0.8069843053817749
Validation loss: 2.282846917708715

Epoch: 5| Step: 3
Training loss: 1.1179149150848389
Validation loss: 2.2410612305005393

Epoch: 5| Step: 4
Training loss: 0.6783612966537476
Validation loss: 2.297657325863838

Epoch: 5| Step: 5
Training loss: 1.0267199277877808
Validation loss: 2.2756623327732086

Epoch: 5| Step: 6
Training loss: 1.125171422958374
Validation loss: 2.283506433169047

Epoch: 5| Step: 7
Training loss: 1.097945213317871
Validation loss: 2.3161915987730026

Epoch: 5| Step: 8
Training loss: 1.0379607677459717
Validation loss: 2.2691059509913125

Epoch: 5| Step: 9
Training loss: 0.6766610145568848
Validation loss: 2.3167756299177804

Epoch: 5| Step: 10
Training loss: 0.9466331601142883
Validation loss: 2.294101973374685

Epoch: 5| Step: 11
Training loss: 1.0267235040664673
Validation loss: 2.2277660916248956

Epoch: 284| Step: 0
Training loss: 1.0573127269744873
Validation loss: 2.211403727531433

Epoch: 5| Step: 1
Training loss: 0.32683032751083374
Validation loss: 2.19156380991141

Epoch: 5| Step: 2
Training loss: 0.8189294934272766
Validation loss: 2.3010543982187905

Epoch: 5| Step: 3
Training loss: 1.7514126300811768
Validation loss: 2.2636510084072747

Epoch: 5| Step: 4
Training loss: 0.8610230684280396
Validation loss: 2.3080001374085746

Epoch: 5| Step: 5
Training loss: 0.8818222880363464
Validation loss: 2.314917733271917

Epoch: 5| Step: 6
Training loss: 1.011641263961792
Validation loss: 2.3160705169041953

Epoch: 5| Step: 7
Training loss: 0.6876983642578125
Validation loss: 2.3265283505121865

Epoch: 5| Step: 8
Training loss: 0.9564733505249023
Validation loss: 2.2488461832205453

Epoch: 5| Step: 9
Training loss: 1.0671138763427734
Validation loss: 2.3987655888001123

Epoch: 5| Step: 10
Training loss: 0.990063488483429
Validation loss: 2.285424758990606

Epoch: 5| Step: 11
Training loss: 0.5473114252090454
Validation loss: 2.299250622590383

Epoch: 285| Step: 0
Training loss: 1.0805442333221436
Validation loss: 2.3399775425593057

Epoch: 5| Step: 1
Training loss: 0.9819087982177734
Validation loss: 2.2853003243605294

Epoch: 5| Step: 2
Training loss: 0.8167880773544312
Validation loss: 2.2469747066497803

Epoch: 5| Step: 3
Training loss: 0.6762165427207947
Validation loss: 2.3906287252902985

Epoch: 5| Step: 4
Training loss: 0.8319040536880493
Validation loss: 2.3559446136156716

Epoch: 5| Step: 5
Training loss: 0.6585726737976074
Validation loss: 2.2193359782298407

Epoch: 5| Step: 6
Training loss: 0.7834624648094177
Validation loss: 2.3198444644610086

Epoch: 5| Step: 7
Training loss: 1.399266004562378
Validation loss: 2.316303074359894

Epoch: 5| Step: 8
Training loss: 1.1147212982177734
Validation loss: 2.251301571726799

Epoch: 5| Step: 9
Training loss: 1.1728556156158447
Validation loss: 2.2822876969973245

Epoch: 5| Step: 10
Training loss: 0.8237375020980835
Validation loss: 2.3196742782990136

Epoch: 5| Step: 11
Training loss: 0.7744368314743042
Validation loss: 2.314929723739624

Epoch: 286| Step: 0
Training loss: 0.8662542104721069
Validation loss: 2.380373994509379

Epoch: 5| Step: 1
Training loss: 0.7120857238769531
Validation loss: 2.215348646044731

Epoch: 5| Step: 2
Training loss: 0.8722014427185059
Validation loss: 2.283786401152611

Epoch: 5| Step: 3
Training loss: 1.0814533233642578
Validation loss: 2.3164505064487457

Epoch: 5| Step: 4
Training loss: 1.0742239952087402
Validation loss: 2.2983700235684714

Epoch: 5| Step: 5
Training loss: 0.8328582048416138
Validation loss: 2.2498456637064614

Epoch: 5| Step: 6
Training loss: 1.1365559101104736
Validation loss: 2.280072202285131

Epoch: 5| Step: 7
Training loss: 0.7379320859909058
Validation loss: 2.351871540149053

Epoch: 5| Step: 8
Training loss: 0.7114148139953613
Validation loss: 2.2820833077033362

Epoch: 5| Step: 9
Training loss: 1.126203179359436
Validation loss: 2.245161617795626

Epoch: 5| Step: 10
Training loss: 0.8849822282791138
Validation loss: 2.2962580422560372

Epoch: 5| Step: 11
Training loss: 0.7731717824935913
Validation loss: 2.2381019592285156

Epoch: 287| Step: 0
Training loss: 0.517184853553772
Validation loss: 2.33827372888724

Epoch: 5| Step: 1
Training loss: 0.6570346355438232
Validation loss: 2.2618535111347833

Epoch: 5| Step: 2
Training loss: 1.1869895458221436
Validation loss: 2.2181403438250222

Epoch: 5| Step: 3
Training loss: 0.9448240995407104
Validation loss: 2.218497892220815

Epoch: 5| Step: 4
Training loss: 0.8555251955986023
Validation loss: 2.307548095782598

Epoch: 5| Step: 5
Training loss: 0.7931625247001648
Validation loss: 2.2530755003293357

Epoch: 5| Step: 6
Training loss: 0.8546584248542786
Validation loss: 2.305062805612882

Epoch: 5| Step: 7
Training loss: 0.7340028882026672
Validation loss: 2.2877738227446875

Epoch: 5| Step: 8
Training loss: 1.1397663354873657
Validation loss: 2.2709256410598755

Epoch: 5| Step: 9
Training loss: 0.9033983945846558
Validation loss: 2.264330431818962

Epoch: 5| Step: 10
Training loss: 1.083832859992981
Validation loss: 2.298616717259089

Epoch: 5| Step: 11
Training loss: 2.0531444549560547
Validation loss: 2.386755953232447

Epoch: 288| Step: 0
Training loss: 1.6385929584503174
Validation loss: 2.2822087903817496

Epoch: 5| Step: 1
Training loss: 0.6472729444503784
Validation loss: 2.198276008168856

Epoch: 5| Step: 2
Training loss: 0.812436580657959
Validation loss: 2.268269345164299

Epoch: 5| Step: 3
Training loss: 1.0406503677368164
Validation loss: 2.3486995895703635

Epoch: 5| Step: 4
Training loss: 0.7592781186103821
Validation loss: 2.278899520635605

Epoch: 5| Step: 5
Training loss: 0.8436158895492554
Validation loss: 2.279232849677404

Epoch: 5| Step: 6
Training loss: 0.6025816202163696
Validation loss: 2.3016067842642465

Epoch: 5| Step: 7
Training loss: 0.8994892239570618
Validation loss: 2.2912865479787192

Epoch: 5| Step: 8
Training loss: 0.7575908899307251
Validation loss: 2.392794797817866

Epoch: 5| Step: 9
Training loss: 0.5690208673477173
Validation loss: 2.2405826350053153

Epoch: 5| Step: 10
Training loss: 0.6752870678901672
Validation loss: 2.2888660232226052

Epoch: 5| Step: 11
Training loss: 1.112152338027954
Validation loss: 2.262423853079478

Epoch: 289| Step: 0
Training loss: 0.6705845594406128
Validation loss: 2.327653626600901

Epoch: 5| Step: 1
Training loss: 0.6405436396598816
Validation loss: 2.367238054672877

Epoch: 5| Step: 2
Training loss: 0.8533501625061035
Validation loss: 2.327519898613294

Epoch: 5| Step: 3
Training loss: 0.5989004373550415
Validation loss: 2.1555026372273765

Epoch: 5| Step: 4
Training loss: 0.7473541498184204
Validation loss: 2.3340573012828827

Epoch: 5| Step: 5
Training loss: 1.0081933736801147
Validation loss: 2.257997542619705

Epoch: 5| Step: 6
Training loss: 1.11837899684906
Validation loss: 2.323214774330457

Epoch: 5| Step: 7
Training loss: 1.0846861600875854
Validation loss: 2.301016797622045

Epoch: 5| Step: 8
Training loss: 0.8872091174125671
Validation loss: 2.2397603193918862

Epoch: 5| Step: 9
Training loss: 0.7320996522903442
Validation loss: 2.217916876077652

Epoch: 5| Step: 10
Training loss: 0.9907873272895813
Validation loss: 2.316208630800247

Epoch: 5| Step: 11
Training loss: 1.307586908340454
Validation loss: 2.24082080523173

Epoch: 290| Step: 0
Training loss: 0.5705522298812866
Validation loss: 2.328961431980133

Epoch: 5| Step: 1
Training loss: 1.1311885118484497
Validation loss: 2.2615531931320825

Epoch: 5| Step: 2
Training loss: 0.8753954172134399
Validation loss: 2.2617705861727395

Epoch: 5| Step: 3
Training loss: 0.7241050601005554
Validation loss: 2.30965027709802

Epoch: 5| Step: 4
Training loss: 0.827606201171875
Validation loss: 2.310387889544169

Epoch: 5| Step: 5
Training loss: 0.7909979820251465
Validation loss: 2.326502487063408

Epoch: 5| Step: 6
Training loss: 0.8437212109565735
Validation loss: 2.2426646053791046

Epoch: 5| Step: 7
Training loss: 0.6817906498908997
Validation loss: 2.3044709165891013

Epoch: 5| Step: 8
Training loss: 0.7851937413215637
Validation loss: 2.2798048108816147

Epoch: 5| Step: 9
Training loss: 1.0221686363220215
Validation loss: 2.2312446236610413

Epoch: 5| Step: 10
Training loss: 1.0393882989883423
Validation loss: 2.290335863828659

Epoch: 5| Step: 11
Training loss: 0.6292670369148254
Validation loss: 2.386757478117943

Epoch: 291| Step: 0
Training loss: 0.8638978004455566
Validation loss: 2.292864739894867

Epoch: 5| Step: 1
Training loss: 0.5572393536567688
Validation loss: 2.318991939226786

Epoch: 5| Step: 2
Training loss: 1.169194221496582
Validation loss: 2.332400922973951

Epoch: 5| Step: 3
Training loss: 0.77481609582901
Validation loss: 2.3654719591140747

Epoch: 5| Step: 4
Training loss: 0.973981499671936
Validation loss: 2.296194309989611

Epoch: 5| Step: 5
Training loss: 1.058988332748413
Validation loss: 2.2636182407538095

Epoch: 5| Step: 6
Training loss: 0.49054259061813354
Validation loss: 2.356537808974584

Epoch: 5| Step: 7
Training loss: 0.9093486070632935
Validation loss: 2.19929767648379

Epoch: 5| Step: 8
Training loss: 0.9072870016098022
Validation loss: 2.3068329443534217

Epoch: 5| Step: 9
Training loss: 0.8321777582168579
Validation loss: 2.2939613858858743

Epoch: 5| Step: 10
Training loss: 1.0546848773956299
Validation loss: 2.323968768119812

Epoch: 5| Step: 11
Training loss: 0.8347824811935425
Validation loss: 2.320756415526072

Epoch: 292| Step: 0
Training loss: 0.7350362539291382
Validation loss: 2.301544482509295

Epoch: 5| Step: 1
Training loss: 0.5567535161972046
Validation loss: 2.2604962438344955

Epoch: 5| Step: 2
Training loss: 0.7607433199882507
Validation loss: 2.234747886657715

Epoch: 5| Step: 3
Training loss: 0.936767578125
Validation loss: 2.3392478078603745

Epoch: 5| Step: 4
Training loss: 0.621883749961853
Validation loss: 2.290364677707354

Epoch: 5| Step: 5
Training loss: 0.718490481376648
Validation loss: 2.2374229729175568

Epoch: 5| Step: 6
Training loss: 0.8511825799942017
Validation loss: 2.236351360877355

Epoch: 5| Step: 7
Training loss: 1.6653896570205688
Validation loss: 2.248361349105835

Epoch: 5| Step: 8
Training loss: 0.9395791292190552
Validation loss: 2.344910482565562

Epoch: 5| Step: 9
Training loss: 1.0853893756866455
Validation loss: 2.2626566092173257

Epoch: 5| Step: 10
Training loss: 0.9076831936836243
Validation loss: 2.268216143051783

Epoch: 5| Step: 11
Training loss: 0.31261110305786133
Validation loss: 2.378325194120407

Epoch: 293| Step: 0
Training loss: 0.925847053527832
Validation loss: 2.238993287086487

Epoch: 5| Step: 1
Training loss: 0.8718259930610657
Validation loss: 2.369272460540136

Epoch: 5| Step: 2
Training loss: 0.9102325439453125
Validation loss: 2.307585815588633

Epoch: 5| Step: 3
Training loss: 1.0583484172821045
Validation loss: 2.28303125500679

Epoch: 5| Step: 4
Training loss: 0.5637089610099792
Validation loss: 2.2878159433603287

Epoch: 5| Step: 5
Training loss: 0.7338186502456665
Validation loss: 2.2856512516736984

Epoch: 5| Step: 6
Training loss: 0.8562204241752625
Validation loss: 2.3433529436588287

Epoch: 5| Step: 7
Training loss: 1.2322081327438354
Validation loss: 2.3190146883328757

Epoch: 5| Step: 8
Training loss: 0.9166206121444702
Validation loss: 2.3622203022241592

Epoch: 5| Step: 9
Training loss: 0.6075348854064941
Validation loss: 2.3430612633625665

Epoch: 5| Step: 10
Training loss: 0.8754388689994812
Validation loss: 2.233624209960302

Epoch: 5| Step: 11
Training loss: 1.05892014503479
Validation loss: 2.3186081647872925

Epoch: 294| Step: 0
Training loss: 0.9645074605941772
Validation loss: 2.3009272317091622

Epoch: 5| Step: 1
Training loss: 1.3479971885681152
Validation loss: 2.306469519933065

Epoch: 5| Step: 2
Training loss: 0.9609935879707336
Validation loss: 2.370151008168856

Epoch: 5| Step: 3
Training loss: 0.7392796277999878
Validation loss: 2.3737140695254006

Epoch: 5| Step: 4
Training loss: 0.9861699938774109
Validation loss: 2.337210069100062

Epoch: 5| Step: 5
Training loss: 1.0192409753799438
Validation loss: 2.368929465611776

Epoch: 5| Step: 6
Training loss: 0.6959637999534607
Validation loss: 2.2525778959194818

Epoch: 5| Step: 7
Training loss: 0.5081661343574524
Validation loss: 2.2592258056004844

Epoch: 5| Step: 8
Training loss: 0.844233512878418
Validation loss: 2.315221389134725

Epoch: 5| Step: 9
Training loss: 0.9484075307846069
Validation loss: 2.417828008532524

Epoch: 5| Step: 10
Training loss: 1.3018604516983032
Validation loss: 2.376982271671295

Epoch: 5| Step: 11
Training loss: 0.9583738446235657
Validation loss: 2.32257579267025

Epoch: 295| Step: 0
Training loss: 0.7724325060844421
Validation loss: 2.3389067153135934

Epoch: 5| Step: 1
Training loss: 0.7880892753601074
Validation loss: 2.256400282184283

Epoch: 5| Step: 2
Training loss: 0.7777320742607117
Validation loss: 2.3549046566088996

Epoch: 5| Step: 3
Training loss: 0.6158837080001831
Validation loss: 2.3180941541989646

Epoch: 5| Step: 4
Training loss: 1.286498785018921
Validation loss: 2.383017510175705

Epoch: 5| Step: 5
Training loss: 1.2451541423797607
Validation loss: 2.3681045919656754

Epoch: 5| Step: 6
Training loss: 1.0754058361053467
Validation loss: 2.3694504499435425

Epoch: 5| Step: 7
Training loss: 1.1743419170379639
Validation loss: 2.3398867746194205

Epoch: 5| Step: 8
Training loss: 0.9912489652633667
Validation loss: 2.2586326400438943

Epoch: 5| Step: 9
Training loss: 1.0888066291809082
Validation loss: 2.280649945139885

Epoch: 5| Step: 10
Training loss: 0.8912512063980103
Validation loss: 2.284462789694468

Epoch: 5| Step: 11
Training loss: 0.3498347997665405
Validation loss: 2.1760791540145874

Epoch: 296| Step: 0
Training loss: 1.0489232540130615
Validation loss: 2.2921316226323447

Epoch: 5| Step: 1
Training loss: 0.7049423456192017
Validation loss: 2.3414123356342316

Epoch: 5| Step: 2
Training loss: 0.5655120015144348
Validation loss: 2.252637435992559

Epoch: 5| Step: 3
Training loss: 0.8264563679695129
Validation loss: 2.238518347342809

Epoch: 5| Step: 4
Training loss: 1.0386526584625244
Validation loss: 2.2539429515600204

Epoch: 5| Step: 5
Training loss: 0.7077546119689941
Validation loss: 2.2910261352856955

Epoch: 5| Step: 6
Training loss: 0.9457704424858093
Validation loss: 2.308107445637385

Epoch: 5| Step: 7
Training loss: 0.6473031044006348
Validation loss: 2.305132746696472

Epoch: 5| Step: 8
Training loss: 0.6881529688835144
Validation loss: 2.239661624034246

Epoch: 5| Step: 9
Training loss: 0.7751346230506897
Validation loss: 2.246168375015259

Epoch: 5| Step: 10
Training loss: 1.2107919454574585
Validation loss: 2.2581290851036706

Epoch: 5| Step: 11
Training loss: 0.6582151055335999
Validation loss: 2.2277026077111564

Epoch: 297| Step: 0
Training loss: 0.7001718878746033
Validation loss: 2.281468073527018

Epoch: 5| Step: 1
Training loss: 0.9211961627006531
Validation loss: 2.2475467324256897

Epoch: 5| Step: 2
Training loss: 0.6499699950218201
Validation loss: 2.2056555300951004

Epoch: 5| Step: 3
Training loss: 0.8044522404670715
Validation loss: 2.34110755721728

Epoch: 5| Step: 4
Training loss: 0.7152954936027527
Validation loss: 2.3307741582393646

Epoch: 5| Step: 5
Training loss: 1.1369750499725342
Validation loss: 2.287862852215767

Epoch: 5| Step: 6
Training loss: 1.092529535293579
Validation loss: 2.249886617064476

Epoch: 5| Step: 7
Training loss: 1.0277659893035889
Validation loss: 2.252897411584854

Epoch: 5| Step: 8
Training loss: 0.9996455907821655
Validation loss: 2.288676917552948

Epoch: 5| Step: 9
Training loss: 0.6061840057373047
Validation loss: 2.266184369723002

Epoch: 5| Step: 10
Training loss: 0.9869691729545593
Validation loss: 2.272179772456487

Epoch: 5| Step: 11
Training loss: 0.39838075637817383
Validation loss: 2.1719076931476593

Epoch: 298| Step: 0
Training loss: 0.9107705354690552
Validation loss: 2.3577770044406257

Epoch: 5| Step: 1
Training loss: 1.0907225608825684
Validation loss: 2.2715893189112344

Epoch: 5| Step: 2
Training loss: 0.5500954389572144
Validation loss: 2.340916017691294

Epoch: 5| Step: 3
Training loss: 0.6926801800727844
Validation loss: 2.274441123008728

Epoch: 5| Step: 4
Training loss: 0.7908905148506165
Validation loss: 2.3555452773968377

Epoch: 5| Step: 5
Training loss: 0.8505445718765259
Validation loss: 2.252268155415853

Epoch: 5| Step: 6
Training loss: 1.063637614250183
Validation loss: 2.3298243085543313

Epoch: 5| Step: 7
Training loss: 1.031246304512024
Validation loss: 2.335304076472918

Epoch: 5| Step: 8
Training loss: 0.737869143486023
Validation loss: 2.345027575890223

Epoch: 5| Step: 9
Training loss: 0.8783750534057617
Validation loss: 2.2938115100065866

Epoch: 5| Step: 10
Training loss: 0.710631251335144
Validation loss: 2.30807896455129

Epoch: 5| Step: 11
Training loss: 0.21966776251792908
Validation loss: 2.2330929090579352

Epoch: 299| Step: 0
Training loss: 0.7221012115478516
Validation loss: 2.3263282974561057

Epoch: 5| Step: 1
Training loss: 0.6065264940261841
Validation loss: 2.3002179016669593

Epoch: 5| Step: 2
Training loss: 0.707423985004425
Validation loss: 2.302541916569074

Epoch: 5| Step: 3
Training loss: 0.8713283538818359
Validation loss: 2.365728954474131

Epoch: 5| Step: 4
Training loss: 1.1653422117233276
Validation loss: 2.2848852376143136

Epoch: 5| Step: 5
Training loss: 0.7569770812988281
Validation loss: 2.256759524345398

Epoch: 5| Step: 6
Training loss: 0.7439190149307251
Validation loss: 2.2460616628328958

Epoch: 5| Step: 7
Training loss: 0.7858076095581055
Validation loss: 2.268076370159785

Epoch: 5| Step: 8
Training loss: 1.3313363790512085
Validation loss: 2.327167958021164

Epoch: 5| Step: 9
Training loss: 1.0057252645492554
Validation loss: 2.355208784341812

Epoch: 5| Step: 10
Training loss: 0.9443279504776001
Validation loss: 2.2991554886102676

Epoch: 5| Step: 11
Training loss: 0.9101364016532898
Validation loss: 2.309011364976565

Epoch: 300| Step: 0
Training loss: 0.8460448980331421
Validation loss: 2.353042413791021

Epoch: 5| Step: 1
Training loss: 0.6503258347511292
Validation loss: 2.3493633021910987

Epoch: 5| Step: 2
Training loss: 0.8743821978569031
Validation loss: 2.2290547837813697

Epoch: 5| Step: 3
Training loss: 0.5320149660110474
Validation loss: 2.3456970751285553

Epoch: 5| Step: 4
Training loss: 1.1545965671539307
Validation loss: 2.301285063227018

Epoch: 5| Step: 5
Training loss: 0.9510948061943054
Validation loss: 2.2440083424250283

Epoch: 5| Step: 6
Training loss: 1.1722065210342407
Validation loss: 2.311026632785797

Epoch: 5| Step: 7
Training loss: 0.850421130657196
Validation loss: 2.318182056148847

Epoch: 5| Step: 8
Training loss: 0.764384388923645
Validation loss: 2.3161553144454956

Epoch: 5| Step: 9
Training loss: 0.4432039260864258
Validation loss: 2.367641488711039

Epoch: 5| Step: 10
Training loss: 1.0578575134277344
Validation loss: 2.2006284246842065

Epoch: 5| Step: 11
Training loss: 1.3517744541168213
Validation loss: 2.324023276567459

Testing loss: 2.1836200275009485
