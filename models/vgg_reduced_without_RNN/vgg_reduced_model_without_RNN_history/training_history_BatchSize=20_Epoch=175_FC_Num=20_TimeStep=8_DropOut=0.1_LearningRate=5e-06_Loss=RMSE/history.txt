Epoch: 1| Step: 0
Training loss: 5.67788722328231
Validation loss: 5.0112162908275275

Epoch: 5| Step: 1
Training loss: 4.679393217739931
Validation loss: 5.000460182311891

Epoch: 5| Step: 2
Training loss: 5.429899318597668
Validation loss: 4.990841631884302

Epoch: 5| Step: 3
Training loss: 5.3373045838650865
Validation loss: 4.983242229066926

Epoch: 5| Step: 4
Training loss: 4.964213093366615
Validation loss: 4.974111555312588

Epoch: 5| Step: 5
Training loss: 5.408011970709921
Validation loss: 4.964562881092498

Epoch: 5| Step: 6
Training loss: 5.05903544614838
Validation loss: 4.956331685159954

Epoch: 5| Step: 7
Training loss: 4.318603398309417
Validation loss: 4.945738586743761

Epoch: 5| Step: 8
Training loss: 4.48795337990059
Validation loss: 4.935507424602838

Epoch: 5| Step: 9
Training loss: 4.9452008420081235
Validation loss: 4.92375823630446

Epoch: 5| Step: 10
Training loss: 5.4812992524355915
Validation loss: 4.91059002392916

Epoch: 5| Step: 11
Training loss: 4.956642033392404
Validation loss: 4.900442699623462

Epoch: 2| Step: 0
Training loss: 5.165181695155527
Validation loss: 4.887954307703665

Epoch: 5| Step: 1
Training loss: 5.26193823636271
Validation loss: 4.876504502893222

Epoch: 5| Step: 2
Training loss: 5.099278357817684
Validation loss: 4.8639803505216195

Epoch: 5| Step: 3
Training loss: 4.881188206397538
Validation loss: 4.852212777328141

Epoch: 5| Step: 4
Training loss: 5.245381094558186
Validation loss: 4.838798551717439

Epoch: 5| Step: 5
Training loss: 4.620316685973649
Validation loss: 4.824301117928748

Epoch: 5| Step: 6
Training loss: 4.716117882676469
Validation loss: 4.808499469344126

Epoch: 5| Step: 7
Training loss: 5.049588162087028
Validation loss: 4.795118161370831

Epoch: 5| Step: 8
Training loss: 4.778168526769942
Validation loss: 4.777453467293676

Epoch: 5| Step: 9
Training loss: 4.733307469436116
Validation loss: 4.762297080148279

Epoch: 5| Step: 10
Training loss: 4.845883594797862
Validation loss: 4.7448335290507435

Epoch: 5| Step: 11
Training loss: 4.353392074289913
Validation loss: 4.728569390759271

Epoch: 3| Step: 0
Training loss: 4.141913447457055
Validation loss: 4.710507341086077

Epoch: 5| Step: 1
Training loss: 5.722434935993566
Validation loss: 4.690632659207808

Epoch: 5| Step: 2
Training loss: 5.045829924569946
Validation loss: 4.671562788279403

Epoch: 5| Step: 3
Training loss: 4.316627407018181
Validation loss: 4.651231220080668

Epoch: 5| Step: 4
Training loss: 5.4809952888767794
Validation loss: 4.633245759875085

Epoch: 5| Step: 5
Training loss: 4.657850361708223
Validation loss: 4.606711614935094

Epoch: 5| Step: 6
Training loss: 4.842152190472059
Validation loss: 4.584428867265444

Epoch: 5| Step: 7
Training loss: 4.466258388098232
Validation loss: 4.5580234252541985

Epoch: 5| Step: 8
Training loss: 4.6118645620583365
Validation loss: 4.532997171593106

Epoch: 5| Step: 9
Training loss: 4.488200931477818
Validation loss: 4.5045394077452325

Epoch: 5| Step: 10
Training loss: 3.91182195376078
Validation loss: 4.471400162007223

Epoch: 5| Step: 11
Training loss: 4.185178198444407
Validation loss: 4.442287155287665

Epoch: 4| Step: 0
Training loss: 4.855325170405786
Validation loss: 4.412102341136192

Epoch: 5| Step: 1
Training loss: 5.011692870646355
Validation loss: 4.376448972628489

Epoch: 5| Step: 2
Training loss: 4.267062325808469
Validation loss: 4.336666387288708

Epoch: 5| Step: 3
Training loss: 4.346486718328095
Validation loss: 4.298730350245004

Epoch: 5| Step: 4
Training loss: 3.8580499142611124
Validation loss: 4.261579190168123

Epoch: 5| Step: 5
Training loss: 3.997781495947879
Validation loss: 4.214267275291141

Epoch: 5| Step: 6
Training loss: 3.9738970443912343
Validation loss: 4.167721255675768

Epoch: 5| Step: 7
Training loss: 3.8169755774564402
Validation loss: 4.1152319803277715

Epoch: 5| Step: 8
Training loss: 4.54826957578739
Validation loss: 4.072463542906968

Epoch: 5| Step: 9
Training loss: 3.677062959407452
Validation loss: 4.013592622566983

Epoch: 5| Step: 10
Training loss: 4.787107582045258
Validation loss: 3.954495992636868

Epoch: 5| Step: 11
Training loss: 3.7744023134115325
Validation loss: 3.89347940446635

Epoch: 5| Step: 0
Training loss: 3.748317722634635
Validation loss: 3.827357821241734

Epoch: 5| Step: 1
Training loss: 3.692285568219928
Validation loss: 3.7605271186704585

Epoch: 5| Step: 2
Training loss: 3.5966612592437888
Validation loss: 3.6837955067661494

Epoch: 5| Step: 3
Training loss: 3.270340576634583
Validation loss: 3.6041460955405773

Epoch: 5| Step: 4
Training loss: 3.407625673009868
Validation loss: 3.534973094825207

Epoch: 5| Step: 5
Training loss: 4.015830186878393
Validation loss: 3.4563289755178976

Epoch: 5| Step: 6
Training loss: 3.415447591378132
Validation loss: 3.371391421746275

Epoch: 5| Step: 7
Training loss: 3.3107066068120807
Validation loss: 3.2933186397597938

Epoch: 5| Step: 8
Training loss: 3.4628966837580952
Validation loss: 3.211403515141961

Epoch: 5| Step: 9
Training loss: 3.6120718256757205
Validation loss: 3.1180102633665605

Epoch: 5| Step: 10
Training loss: 3.082721976078822
Validation loss: 3.022664670389383

Epoch: 5| Step: 11
Training loss: 3.194866270511208
Validation loss: 2.9339548626077656

Epoch: 6| Step: 0
Training loss: 2.874168939306596
Validation loss: 2.860205361261481

Epoch: 5| Step: 1
Training loss: 3.371755241126926
Validation loss: 2.7819740374512567

Epoch: 5| Step: 2
Training loss: 2.6854924532838083
Validation loss: 2.703810628768819

Epoch: 5| Step: 3
Training loss: 2.631800425896783
Validation loss: 2.6414631711537098

Epoch: 5| Step: 4
Training loss: 2.600082297123063
Validation loss: 2.606677741879239

Epoch: 5| Step: 5
Training loss: 2.0526011502691364
Validation loss: 2.5660553512792665

Epoch: 5| Step: 6
Training loss: 2.296722718465143
Validation loss: 2.557952730672647

Epoch: 5| Step: 7
Training loss: 2.7194460273853234
Validation loss: 2.5536944085504656

Epoch: 5| Step: 8
Training loss: 2.4058406531188767
Validation loss: 2.5906171147464625

Epoch: 5| Step: 9
Training loss: 3.168151172884281
Validation loss: 2.606939591703763

Epoch: 5| Step: 10
Training loss: 2.675913385623155
Validation loss: 2.6471035654103523

Epoch: 5| Step: 11
Training loss: 1.3376142007434422
Validation loss: 2.683535931078648

Epoch: 7| Step: 0
Training loss: 2.0305787371164397
Validation loss: 2.6887219962815454

Epoch: 5| Step: 1
Training loss: 2.6290893490924714
Validation loss: 2.69468927226981

Epoch: 5| Step: 2
Training loss: 2.726620561478861
Validation loss: 2.7104686181330497

Epoch: 5| Step: 3
Training loss: 2.775332381129264
Validation loss: 2.6835641984270313

Epoch: 5| Step: 4
Training loss: 2.835901349470433
Validation loss: 2.6519463287729432

Epoch: 5| Step: 5
Training loss: 2.0885135588494625
Validation loss: 2.65436198884742

Epoch: 5| Step: 6
Training loss: 2.599423465630064
Validation loss: 2.6271275345433924

Epoch: 5| Step: 7
Training loss: 3.2264815128682915
Validation loss: 2.627872431922941

Epoch: 5| Step: 8
Training loss: 2.7113636572350273
Validation loss: 2.6046854659516696

Epoch: 5| Step: 9
Training loss: 2.0622499487760466
Validation loss: 2.5905560127278986

Epoch: 5| Step: 10
Training loss: 2.900991954183483
Validation loss: 2.58807289105469

Epoch: 5| Step: 11
Training loss: 1.4350875015695923
Validation loss: 2.5534641980602553

Epoch: 8| Step: 0
Training loss: 2.989738079323837
Validation loss: 2.5763619569454423

Epoch: 5| Step: 1
Training loss: 2.471202549572905
Validation loss: 2.565786355536244

Epoch: 5| Step: 2
Training loss: 2.4836561014581022
Validation loss: 2.5377860474927285

Epoch: 5| Step: 3
Training loss: 2.0814533397787875
Validation loss: 2.5689456710480685

Epoch: 5| Step: 4
Training loss: 2.5905352053478223
Validation loss: 2.5552613744402626

Epoch: 5| Step: 5
Training loss: 2.5179438358675705
Validation loss: 2.560537994392644

Epoch: 5| Step: 6
Training loss: 2.62052299550271
Validation loss: 2.5649181834278916

Epoch: 5| Step: 7
Training loss: 2.270298524460437
Validation loss: 2.5689632271584526

Epoch: 5| Step: 8
Training loss: 2.320773505964145
Validation loss: 2.5655439370994437

Epoch: 5| Step: 9
Training loss: 2.63647785357892
Validation loss: 2.5357014560119047

Epoch: 5| Step: 10
Training loss: 2.565438980997632
Validation loss: 2.565153914742132

Epoch: 5| Step: 11
Training loss: 2.8091887585240807
Validation loss: 2.5570709861016767

Epoch: 9| Step: 0
Training loss: 2.845534550707909
Validation loss: 2.548225883181644

Epoch: 5| Step: 1
Training loss: 2.459465143473611
Validation loss: 2.553500981935903

Epoch: 5| Step: 2
Training loss: 2.363857936644038
Validation loss: 2.5531039604026704

Epoch: 5| Step: 3
Training loss: 2.0384036347978123
Validation loss: 2.5520615336726227

Epoch: 5| Step: 4
Training loss: 2.6821094833773573
Validation loss: 2.543579813351188

Epoch: 5| Step: 5
Training loss: 2.7439731098781515
Validation loss: 2.554196624569799

Epoch: 5| Step: 6
Training loss: 2.375974956971303
Validation loss: 2.5616424102437265

Epoch: 5| Step: 7
Training loss: 2.0949533904360176
Validation loss: 2.5571442009283483

Epoch: 5| Step: 8
Training loss: 2.617210820791621
Validation loss: 2.5365497734512217

Epoch: 5| Step: 9
Training loss: 1.9367229380067983
Validation loss: 2.5454794330781354

Epoch: 5| Step: 10
Training loss: 3.4812075326407848
Validation loss: 2.5369728488226073

Epoch: 5| Step: 11
Training loss: 1.021898466534896
Validation loss: 2.5696025126754702

Epoch: 10| Step: 0
Training loss: 2.100142555847772
Validation loss: 2.552809979020414

Epoch: 5| Step: 1
Training loss: 2.0515709510042286
Validation loss: 2.5476426486943216

Epoch: 5| Step: 2
Training loss: 2.653882216736926
Validation loss: 2.5499691880303126

Epoch: 5| Step: 3
Training loss: 2.907708243131152
Validation loss: 2.5538627545346335

Epoch: 5| Step: 4
Training loss: 3.2423383930436507
Validation loss: 2.547864452605796

Epoch: 5| Step: 5
Training loss: 2.9392050806370214
Validation loss: 2.554194528221355

Epoch: 5| Step: 6
Training loss: 2.787503530731018
Validation loss: 2.544717420873448

Epoch: 5| Step: 7
Training loss: 2.0459107901625893
Validation loss: 2.527233084015216

Epoch: 5| Step: 8
Training loss: 1.7654528238523655
Validation loss: 2.5355346585362764

Epoch: 5| Step: 9
Training loss: 2.2694137989321583
Validation loss: 2.5514168212816153

Epoch: 5| Step: 10
Training loss: 2.59068494113099
Validation loss: 2.5502899927536644

Epoch: 5| Step: 11
Training loss: 1.826162866580388
Validation loss: 2.5416237379315576

Epoch: 11| Step: 0
Training loss: 2.448175089296675
Validation loss: 2.5580099357042183

Epoch: 5| Step: 1
Training loss: 2.4372563362598765
Validation loss: 2.538499955680035

Epoch: 5| Step: 2
Training loss: 2.287519853015902
Validation loss: 2.5441018962445496

Epoch: 5| Step: 3
Training loss: 2.5510344445367914
Validation loss: 2.5558767826623043

Epoch: 5| Step: 4
Training loss: 2.3606315449893343
Validation loss: 2.5612829117020253

Epoch: 5| Step: 5
Training loss: 2.702498611463954
Validation loss: 2.557549381413282

Epoch: 5| Step: 6
Training loss: 2.9073956600238953
Validation loss: 2.5541393652468587

Epoch: 5| Step: 7
Training loss: 2.7537016664090954
Validation loss: 2.5442102061258254

Epoch: 5| Step: 8
Training loss: 2.3434791917115168
Validation loss: 2.5502928869491

Epoch: 5| Step: 9
Training loss: 1.9240085575286197
Validation loss: 2.5559830952952445

Epoch: 5| Step: 10
Training loss: 2.7074412906442045
Validation loss: 2.5579902072974554

Epoch: 5| Step: 11
Training loss: 2.6387907801900874
Validation loss: 2.5415776711397347

Epoch: 12| Step: 0
Training loss: 2.3752427228071946
Validation loss: 2.572145046458007

Epoch: 5| Step: 1
Training loss: 2.33893079571647
Validation loss: 2.5527837311210946

Epoch: 5| Step: 2
Training loss: 2.519950796282744
Validation loss: 2.549344759013031

Epoch: 5| Step: 3
Training loss: 2.980345557230391
Validation loss: 2.551540637540703

Epoch: 5| Step: 4
Training loss: 2.139611331368973
Validation loss: 2.544813835483655

Epoch: 5| Step: 5
Training loss: 2.4768066285924406
Validation loss: 2.5362448135731555

Epoch: 5| Step: 6
Training loss: 2.429949093195168
Validation loss: 2.527047907923509

Epoch: 5| Step: 7
Training loss: 2.7567945119817554
Validation loss: 2.526111384868386

Epoch: 5| Step: 8
Training loss: 2.40127395752965
Validation loss: 2.549648183195408

Epoch: 5| Step: 9
Training loss: 2.0939998192992038
Validation loss: 2.5511408655068077

Epoch: 5| Step: 10
Training loss: 2.6519375969059493
Validation loss: 2.518899172963502

Epoch: 5| Step: 11
Training loss: 3.565320822256083
Validation loss: 2.535026801693076

Epoch: 13| Step: 0
Training loss: 1.8506761835886025
Validation loss: 2.5450431812385315

Epoch: 5| Step: 1
Training loss: 2.466980215283227
Validation loss: 2.5465927864783136

Epoch: 5| Step: 2
Training loss: 2.123515676556866
Validation loss: 2.543943004643717

Epoch: 5| Step: 3
Training loss: 2.592564323311538
Validation loss: 2.538331373539162

Epoch: 5| Step: 4
Training loss: 2.4786190315000427
Validation loss: 2.5372783084860933

Epoch: 5| Step: 5
Training loss: 2.7266496791947765
Validation loss: 2.552693704029619

Epoch: 5| Step: 6
Training loss: 2.7538441752478717
Validation loss: 2.545760451073266

Epoch: 5| Step: 7
Training loss: 3.023559567848325
Validation loss: 2.5501262374871687

Epoch: 5| Step: 8
Training loss: 2.082804523747504
Validation loss: 2.548202759475792

Epoch: 5| Step: 9
Training loss: 2.6688309668379566
Validation loss: 2.54192244826936

Epoch: 5| Step: 10
Training loss: 2.257634984202121
Validation loss: 2.5384935142532417

Epoch: 5| Step: 11
Training loss: 3.7533300237375666
Validation loss: 2.5413145514510016

Epoch: 14| Step: 0
Training loss: 2.2333355599956892
Validation loss: 2.559899084038027

Epoch: 5| Step: 1
Training loss: 2.715213448580074
Validation loss: 2.535495384663964

Epoch: 5| Step: 2
Training loss: 2.525495699579584
Validation loss: 2.5331775013988747

Epoch: 5| Step: 3
Training loss: 2.49513257165634
Validation loss: 2.528461140501799

Epoch: 5| Step: 4
Training loss: 2.148439386540365
Validation loss: 2.530826407573704

Epoch: 5| Step: 5
Training loss: 2.390683241988656
Validation loss: 2.540968417316303

Epoch: 5| Step: 6
Training loss: 2.1457744948335606
Validation loss: 2.5409922069708792

Epoch: 5| Step: 7
Training loss: 2.9793615922092016
Validation loss: 2.522481688107531

Epoch: 5| Step: 8
Training loss: 2.3916698491233714
Validation loss: 2.5393986640820905

Epoch: 5| Step: 9
Training loss: 2.760710233996634
Validation loss: 2.5403532923778758

Epoch: 5| Step: 10
Training loss: 2.600222405678114
Validation loss: 2.542117185739798

Epoch: 5| Step: 11
Training loss: 2.0859154403605906
Validation loss: 2.5507600208000762

Epoch: 15| Step: 0
Training loss: 2.692188254526202
Validation loss: 2.526181877151428

Epoch: 5| Step: 1
Training loss: 2.7001748275669613
Validation loss: 2.5264161543493033

Epoch: 5| Step: 2
Training loss: 3.381566335719815
Validation loss: 2.531143859317652

Epoch: 5| Step: 3
Training loss: 2.2156628905420486
Validation loss: 2.521948604462896

Epoch: 5| Step: 4
Training loss: 2.0353101792945325
Validation loss: 2.5299554269430162

Epoch: 5| Step: 5
Training loss: 2.1178879371008823
Validation loss: 2.5392920365873453

Epoch: 5| Step: 6
Training loss: 2.1010473818331676
Validation loss: 2.541623268903437

Epoch: 5| Step: 7
Training loss: 2.3393190333698555
Validation loss: 2.539457515408998

Epoch: 5| Step: 8
Training loss: 2.7838908312922364
Validation loss: 2.516621650888984

Epoch: 5| Step: 9
Training loss: 1.7563585159606578
Validation loss: 2.542018480393298

Epoch: 5| Step: 10
Training loss: 2.662856558981527
Validation loss: 2.523964621147314

Epoch: 5| Step: 11
Training loss: 3.732856090446025
Validation loss: 2.5377260808968973

Epoch: 16| Step: 0
Training loss: 2.7531193467947066
Validation loss: 2.551650007919443

Epoch: 5| Step: 1
Training loss: 2.581058012909322
Validation loss: 2.5157594190742985

Epoch: 5| Step: 2
Training loss: 2.6059028229588836
Validation loss: 2.558315857994295

Epoch: 5| Step: 3
Training loss: 3.068725952551448
Validation loss: 2.533595076145104

Epoch: 5| Step: 4
Training loss: 2.094134395101254
Validation loss: 2.5450156627128098

Epoch: 5| Step: 5
Training loss: 2.5684324304902195
Validation loss: 2.532429812633324

Epoch: 5| Step: 6
Training loss: 2.554458001237098
Validation loss: 2.539079100725729

Epoch: 5| Step: 7
Training loss: 2.340314356074372
Validation loss: 2.537999448027925

Epoch: 5| Step: 8
Training loss: 2.620849507033795
Validation loss: 2.518157919842679

Epoch: 5| Step: 9
Training loss: 2.201324159758269
Validation loss: 2.539871122270815

Epoch: 5| Step: 10
Training loss: 1.9530582874348739
Validation loss: 2.5475184012120615

Epoch: 5| Step: 11
Training loss: 2.273286899677881
Validation loss: 2.5570927145665014

Epoch: 17| Step: 0
Training loss: 2.464978004341955
Validation loss: 2.5536261209537146

Epoch: 5| Step: 1
Training loss: 2.4724044792153235
Validation loss: 2.534267498986667

Epoch: 5| Step: 2
Training loss: 2.584652307616932
Validation loss: 2.547634132536464

Epoch: 5| Step: 3
Training loss: 2.370899475283466
Validation loss: 2.5297130463260387

Epoch: 5| Step: 4
Training loss: 2.488199708761323
Validation loss: 2.541697350822297

Epoch: 5| Step: 5
Training loss: 2.5905048337890197
Validation loss: 2.52369159171144

Epoch: 5| Step: 6
Training loss: 2.5426734014474257
Validation loss: 2.5318372500482256

Epoch: 5| Step: 7
Training loss: 3.3587992329994445
Validation loss: 2.52539433053461

Epoch: 5| Step: 8
Training loss: 2.7287604536833983
Validation loss: 2.543618122715724

Epoch: 5| Step: 9
Training loss: 1.595961961799639
Validation loss: 2.540305802554697

Epoch: 5| Step: 10
Training loss: 1.9513656015993894
Validation loss: 2.5292783365834453

Epoch: 5| Step: 11
Training loss: 1.7475289200775959
Validation loss: 2.5394383313719686

Epoch: 18| Step: 0
Training loss: 2.173352953036317
Validation loss: 2.534446201508048

Epoch: 5| Step: 1
Training loss: 2.5674465167186904
Validation loss: 2.5226662267111775

Epoch: 5| Step: 2
Training loss: 2.1135146599164827
Validation loss: 2.5493254350571637

Epoch: 5| Step: 3
Training loss: 2.2605657455107586
Validation loss: 2.539431184264023

Epoch: 5| Step: 4
Training loss: 2.8385799487037713
Validation loss: 2.5709393711778024

Epoch: 5| Step: 5
Training loss: 2.593316834829587
Validation loss: 2.5644190549463635

Epoch: 5| Step: 6
Training loss: 2.8521891702241877
Validation loss: 2.568242117522204

Epoch: 5| Step: 7
Training loss: 2.8512277066949254
Validation loss: 2.5834548380692817

Epoch: 5| Step: 8
Training loss: 2.507152529951292
Validation loss: 2.5771141748631026

Epoch: 5| Step: 9
Training loss: 2.776774802863324
Validation loss: 2.5555932619819135

Epoch: 5| Step: 10
Training loss: 2.1455850426686625
Validation loss: 2.544418374933997

Epoch: 5| Step: 11
Training loss: 1.7000102687974339
Validation loss: 2.549981619419598

Epoch: 19| Step: 0
Training loss: 2.0583400968165093
Validation loss: 2.5407568652977277

Epoch: 5| Step: 1
Training loss: 2.95437934515246
Validation loss: 2.5345230761699327

Epoch: 5| Step: 2
Training loss: 2.6665216545571897
Validation loss: 2.5376016493107656

Epoch: 5| Step: 3
Training loss: 2.31177437197442
Validation loss: 2.5431298997390734

Epoch: 5| Step: 4
Training loss: 1.7992357750972072
Validation loss: 2.528642080181779

Epoch: 5| Step: 5
Training loss: 2.378649066621874
Validation loss: 2.526710163551879

Epoch: 5| Step: 6
Training loss: 2.0010310138165313
Validation loss: 2.5224314791418494

Epoch: 5| Step: 7
Training loss: 2.217780855234458
Validation loss: 2.5110586237262984

Epoch: 5| Step: 8
Training loss: 3.0432374808629707
Validation loss: 2.5288872817974744

Epoch: 5| Step: 9
Training loss: 2.974292921138956
Validation loss: 2.516651860145145

Epoch: 5| Step: 10
Training loss: 2.35783952681091
Validation loss: 2.539603812396183

Epoch: 5| Step: 11
Training loss: 3.6901551079133497
Validation loss: 2.513187080115551

Epoch: 20| Step: 0
Training loss: 2.510486258865188
Validation loss: 2.5271596531980625

Epoch: 5| Step: 1
Training loss: 2.6923976893631423
Validation loss: 2.5105462627806827

Epoch: 5| Step: 2
Training loss: 2.848043030895945
Validation loss: 2.5063771094340486

Epoch: 5| Step: 3
Training loss: 2.107383522625126
Validation loss: 2.522016650810454

Epoch: 5| Step: 4
Training loss: 2.418334144506268
Validation loss: 2.5208278188303592

Epoch: 5| Step: 5
Training loss: 2.3853328195908605
Validation loss: 2.5257947322581202

Epoch: 5| Step: 6
Training loss: 2.554565800092445
Validation loss: 2.5014176878988423

Epoch: 5| Step: 7
Training loss: 2.6193624540486815
Validation loss: 2.521960949447458

Epoch: 5| Step: 8
Training loss: 2.332883541714344
Validation loss: 2.5104980666601326

Epoch: 5| Step: 9
Training loss: 1.7349272527476938
Validation loss: 2.5391529869192677

Epoch: 5| Step: 10
Training loss: 2.8267619183374193
Validation loss: 2.5243803611094613

Epoch: 5| Step: 11
Training loss: 2.7501512832644432
Validation loss: 2.5356212908490687

Epoch: 21| Step: 0
Training loss: 2.7437824707890526
Validation loss: 2.5122433041004304

Epoch: 5| Step: 1
Training loss: 3.0305159161666926
Validation loss: 2.5109193656027577

Epoch: 5| Step: 2
Training loss: 2.7955501551324096
Validation loss: 2.5340408002932815

Epoch: 5| Step: 3
Training loss: 2.307301632505871
Validation loss: 2.5128109160722976

Epoch: 5| Step: 4
Training loss: 2.2645859012630143
Validation loss: 2.519644647456467

Epoch: 5| Step: 5
Training loss: 1.925709814019568
Validation loss: 2.5308821493290776

Epoch: 5| Step: 6
Training loss: 2.6943317785227507
Validation loss: 2.519430390145514

Epoch: 5| Step: 7
Training loss: 2.083992040132049
Validation loss: 2.5410838761816392

Epoch: 5| Step: 8
Training loss: 2.2971097865093117
Validation loss: 2.520406171899094

Epoch: 5| Step: 9
Training loss: 2.5519020690902408
Validation loss: 2.529202040928205

Epoch: 5| Step: 10
Training loss: 2.2730805946021544
Validation loss: 2.514337810601969

Epoch: 5| Step: 11
Training loss: 2.7125261472505335
Validation loss: 2.5431251887942263

Epoch: 22| Step: 0
Training loss: 2.571934336166696
Validation loss: 2.5190470306586548

Epoch: 5| Step: 1
Training loss: 2.9316684383569873
Validation loss: 2.533979910030227

Epoch: 5| Step: 2
Training loss: 2.2394430663666265
Validation loss: 2.5222233704589083

Epoch: 5| Step: 3
Training loss: 2.869582005277034
Validation loss: 2.532461802516825

Epoch: 5| Step: 4
Training loss: 2.0013162334854413
Validation loss: 2.522064778460149

Epoch: 5| Step: 5
Training loss: 2.694196475527105
Validation loss: 2.525702779526153

Epoch: 5| Step: 6
Training loss: 2.457808573259538
Validation loss: 2.5175001607324723

Epoch: 5| Step: 7
Training loss: 2.1659475991769446
Validation loss: 2.514601035057113

Epoch: 5| Step: 8
Training loss: 2.6988190328754342
Validation loss: 2.5059305618493903

Epoch: 5| Step: 9
Training loss: 2.2700238899620717
Validation loss: 2.522470015173378

Epoch: 5| Step: 10
Training loss: 1.9837080067334492
Validation loss: 2.5388756316451238

Epoch: 5| Step: 11
Training loss: 3.1730703722835045
Validation loss: 2.5146538931284366

Epoch: 23| Step: 0
Training loss: 2.6240615075334275
Validation loss: 2.5272001434987272

Epoch: 5| Step: 1
Training loss: 2.5828075078880217
Validation loss: 2.5325703846614234

Epoch: 5| Step: 2
Training loss: 2.6419658078357013
Validation loss: 2.5256126052525874

Epoch: 5| Step: 3
Training loss: 2.2504648152355187
Validation loss: 2.5214463085056034

Epoch: 5| Step: 4
Training loss: 2.0797524640536094
Validation loss: 2.533018101013829

Epoch: 5| Step: 5
Training loss: 2.867937618742353
Validation loss: 2.54786547024295

Epoch: 5| Step: 6
Training loss: 1.871292517821802
Validation loss: 2.5277109680208163

Epoch: 5| Step: 7
Training loss: 2.394709470006695
Validation loss: 2.538441336528417

Epoch: 5| Step: 8
Training loss: 2.63932903924554
Validation loss: 2.5493818556099628

Epoch: 5| Step: 9
Training loss: 2.6309231734098137
Validation loss: 2.539072559043326

Epoch: 5| Step: 10
Training loss: 2.7791550708016017
Validation loss: 2.5286811462094723

Epoch: 5| Step: 11
Training loss: 1.202058691150147
Validation loss: 2.5340477744323144

Epoch: 24| Step: 0
Training loss: 2.433001352769983
Validation loss: 2.5352017869273658

Epoch: 5| Step: 1
Training loss: 2.2535600049189424
Validation loss: 2.499791454517902

Epoch: 5| Step: 2
Training loss: 3.2314702503098642
Validation loss: 2.5241005836313044

Epoch: 5| Step: 3
Training loss: 2.3201991609063977
Validation loss: 2.513927645293794

Epoch: 5| Step: 4
Training loss: 2.713025786601043
Validation loss: 2.5237759499981536

Epoch: 5| Step: 5
Training loss: 2.2638128992080704
Validation loss: 2.5196184719868078

Epoch: 5| Step: 6
Training loss: 2.400403437878995
Validation loss: 2.518943205428787

Epoch: 5| Step: 7
Training loss: 2.511365423668712
Validation loss: 2.5270020491244902

Epoch: 5| Step: 8
Training loss: 2.154419273848927
Validation loss: 2.5096954157764655

Epoch: 5| Step: 9
Training loss: 2.8966328640082333
Validation loss: 2.5067625095702937

Epoch: 5| Step: 10
Training loss: 2.210011857980529
Validation loss: 2.521550294628538

Epoch: 5| Step: 11
Training loss: 1.6029055290869803
Validation loss: 2.510077407410806

Epoch: 25| Step: 0
Training loss: 2.675491829694443
Validation loss: 2.53137244411123

Epoch: 5| Step: 1
Training loss: 2.3348237000917766
Validation loss: 2.511972405660981

Epoch: 5| Step: 2
Training loss: 1.9610880759738163
Validation loss: 2.5082647959532802

Epoch: 5| Step: 3
Training loss: 2.588826297536379
Validation loss: 2.502697458953041

Epoch: 5| Step: 4
Training loss: 1.721932603042162
Validation loss: 2.519727233046081

Epoch: 5| Step: 5
Training loss: 2.6084611400293025
Validation loss: 2.5085430408232505

Epoch: 5| Step: 6
Training loss: 2.682037924211811
Validation loss: 2.4953098150599935

Epoch: 5| Step: 7
Training loss: 2.4971027752582864
Validation loss: 2.505023082352698

Epoch: 5| Step: 8
Training loss: 2.0480403931329816
Validation loss: 2.5229710560193137

Epoch: 5| Step: 9
Training loss: 3.262264585222821
Validation loss: 2.506267170518259

Epoch: 5| Step: 10
Training loss: 2.3358119560875745
Validation loss: 2.5243639155805098

Epoch: 5| Step: 11
Training loss: 2.5489975211609215
Validation loss: 2.5067089936833127

Epoch: 26| Step: 0
Training loss: 2.7244985031485056
Validation loss: 2.539875819694997

Epoch: 5| Step: 1
Training loss: 2.162241145170201
Validation loss: 2.546169600674235

Epoch: 5| Step: 2
Training loss: 2.253897576009631
Validation loss: 2.524187777600858

Epoch: 5| Step: 3
Training loss: 2.6412443980759206
Validation loss: 2.5578417772261552

Epoch: 5| Step: 4
Training loss: 2.723545799356311
Validation loss: 2.5735450368561827

Epoch: 5| Step: 5
Training loss: 2.451617609964299
Validation loss: 2.596265695047239

Epoch: 5| Step: 6
Training loss: 2.1742628404901128
Validation loss: 2.6072088509357942

Epoch: 5| Step: 7
Training loss: 2.1697865056785215
Validation loss: 2.6153183121870556

Epoch: 5| Step: 8
Training loss: 2.892779727687105
Validation loss: 2.597475597247382

Epoch: 5| Step: 9
Training loss: 2.619172667123166
Validation loss: 2.587428317251893

Epoch: 5| Step: 10
Training loss: 2.7714682881679447
Validation loss: 2.562251334802014

Epoch: 5| Step: 11
Training loss: 1.346798211760958
Validation loss: 2.5537738546737705

Epoch: 27| Step: 0
Training loss: 2.843344523268844
Validation loss: 2.5436125378407226

Epoch: 5| Step: 1
Training loss: 2.5433467461001924
Validation loss: 2.5352055760832375

Epoch: 5| Step: 2
Training loss: 2.762844778786438
Validation loss: 2.5347837322354745

Epoch: 5| Step: 3
Training loss: 2.4272445712471336
Validation loss: 2.535319510651255

Epoch: 5| Step: 4
Training loss: 2.5826647005987815
Validation loss: 2.5338616143980017

Epoch: 5| Step: 5
Training loss: 2.544418741935762
Validation loss: 2.50997220189886

Epoch: 5| Step: 6
Training loss: 2.3002715655347132
Validation loss: 2.5126488932495197

Epoch: 5| Step: 7
Training loss: 2.063441668466797
Validation loss: 2.513231809519333

Epoch: 5| Step: 8
Training loss: 1.5691393365301531
Validation loss: 2.5015001246729143

Epoch: 5| Step: 9
Training loss: 2.6384191384964826
Validation loss: 2.503639421216069

Epoch: 5| Step: 10
Training loss: 2.6949385673867456
Validation loss: 2.5204996894430627

Epoch: 5| Step: 11
Training loss: 1.9070482302499299
Validation loss: 2.524655381848432

Epoch: 28| Step: 0
Training loss: 2.359678438391783
Validation loss: 2.509525807125801

Epoch: 5| Step: 1
Training loss: 2.695349474667131
Validation loss: 2.5180791489981007

Epoch: 5| Step: 2
Training loss: 2.12506933660146
Validation loss: 2.5133996839349133

Epoch: 5| Step: 3
Training loss: 3.1303989312173766
Validation loss: 2.5099758352076447

Epoch: 5| Step: 4
Training loss: 2.4608191083253
Validation loss: 2.510706905877267

Epoch: 5| Step: 5
Training loss: 2.671597114969687
Validation loss: 2.5107884046073705

Epoch: 5| Step: 6
Training loss: 2.0924502081740783
Validation loss: 2.5194631049824903

Epoch: 5| Step: 7
Training loss: 2.502665148153168
Validation loss: 2.526361415066568

Epoch: 5| Step: 8
Training loss: 2.704728902040409
Validation loss: 2.5268275359202375

Epoch: 5| Step: 9
Training loss: 1.762913267234074
Validation loss: 2.5167841994922435

Epoch: 5| Step: 10
Training loss: 2.5172441851474585
Validation loss: 2.5280118881591904

Epoch: 5| Step: 11
Training loss: 1.8343907110266022
Validation loss: 2.54746366691448

Epoch: 29| Step: 0
Training loss: 2.549407448829811
Validation loss: 2.5243585753845093

Epoch: 5| Step: 1
Training loss: 2.297857372894269
Validation loss: 2.5188723764752163

Epoch: 5| Step: 2
Training loss: 2.0876985466926956
Validation loss: 2.5200211396163246

Epoch: 5| Step: 3
Training loss: 1.8420230083457554
Validation loss: 2.5306795207354726

Epoch: 5| Step: 4
Training loss: 2.700766267478375
Validation loss: 2.5288989722495114

Epoch: 5| Step: 5
Training loss: 2.3914235096669705
Validation loss: 2.5296378515852385

Epoch: 5| Step: 6
Training loss: 2.582261437386223
Validation loss: 2.518883362103648

Epoch: 5| Step: 7
Training loss: 3.6564718325883776
Validation loss: 2.5197866029492695

Epoch: 5| Step: 8
Training loss: 2.18528090044062
Validation loss: 2.5163735644288243

Epoch: 5| Step: 9
Training loss: 2.3818096114076575
Validation loss: 2.5000124195903

Epoch: 5| Step: 10
Training loss: 1.9950177004036094
Validation loss: 2.5079527287875294

Epoch: 5| Step: 11
Training loss: 2.4654499644530774
Validation loss: 2.5255671275002367

Epoch: 30| Step: 0
Training loss: 3.0698415768780163
Validation loss: 2.5096628764255597

Epoch: 5| Step: 1
Training loss: 2.18405315773238
Validation loss: 2.524442494255036

Epoch: 5| Step: 2
Training loss: 1.99063109392464
Validation loss: 2.5182220014426155

Epoch: 5| Step: 3
Training loss: 2.400896731378943
Validation loss: 2.517493322269507

Epoch: 5| Step: 4
Training loss: 2.9207967308751255
Validation loss: 2.530614412046445

Epoch: 5| Step: 5
Training loss: 2.249482731169726
Validation loss: 2.523975570836062

Epoch: 5| Step: 6
Training loss: 2.304864495156697
Validation loss: 2.533833006051373

Epoch: 5| Step: 7
Training loss: 2.7331484414191687
Validation loss: 2.5310501973450634

Epoch: 5| Step: 8
Training loss: 2.686188399938582
Validation loss: 2.5514369645610877

Epoch: 5| Step: 9
Training loss: 1.9492487169305313
Validation loss: 2.53016648041331

Epoch: 5| Step: 10
Training loss: 2.3233985800135297
Validation loss: 2.547989338212486

Epoch: 5| Step: 11
Training loss: 1.5345880364414926
Validation loss: 2.501830213884279

Epoch: 31| Step: 0
Training loss: 2.8844938673197884
Validation loss: 2.530581676495132

Epoch: 5| Step: 1
Training loss: 1.9447404257738141
Validation loss: 2.5145378251423267

Epoch: 5| Step: 2
Training loss: 2.6272299241367865
Validation loss: 2.520389314171882

Epoch: 5| Step: 3
Training loss: 2.538152349644541
Validation loss: 2.547776676947538

Epoch: 5| Step: 4
Training loss: 2.202391482049424
Validation loss: 2.5236586876331875

Epoch: 5| Step: 5
Training loss: 2.4303564395785404
Validation loss: 2.5074594076794092

Epoch: 5| Step: 6
Training loss: 2.0587492853289664
Validation loss: 2.5406061106875426

Epoch: 5| Step: 7
Training loss: 2.0295207952884593
Validation loss: 2.5265448328020548

Epoch: 5| Step: 8
Training loss: 2.997856327922706
Validation loss: 2.5349831112995656

Epoch: 5| Step: 9
Training loss: 2.8476954327937007
Validation loss: 2.5155675103546953

Epoch: 5| Step: 10
Training loss: 2.3397318665211095
Validation loss: 2.520514855614544

Epoch: 5| Step: 11
Training loss: 1.520385580472505
Validation loss: 2.5211560808547815

Epoch: 32| Step: 0
Training loss: 2.4363405453339513
Validation loss: 2.524640673384801

Epoch: 5| Step: 1
Training loss: 1.8993569490529607
Validation loss: 2.518570015268867

Epoch: 5| Step: 2
Training loss: 2.342563176071612
Validation loss: 2.533346065742302

Epoch: 5| Step: 3
Training loss: 2.559493557486127
Validation loss: 2.5220176966025125

Epoch: 5| Step: 4
Training loss: 2.206459389927264
Validation loss: 2.5294332381596805

Epoch: 5| Step: 5
Training loss: 2.7912905899971068
Validation loss: 2.5148628770571544

Epoch: 5| Step: 6
Training loss: 1.965575914118765
Validation loss: 2.5246633262718787

Epoch: 5| Step: 7
Training loss: 2.835162937117527
Validation loss: 2.512074557544411

Epoch: 5| Step: 8
Training loss: 2.113193813355499
Validation loss: 2.5246605522189838

Epoch: 5| Step: 9
Training loss: 3.3183826537772356
Validation loss: 2.515185588267352

Epoch: 5| Step: 10
Training loss: 1.9801506072862263
Validation loss: 2.5250379410023998

Epoch: 5| Step: 11
Training loss: 3.379091396661562
Validation loss: 2.535227519377131

Epoch: 33| Step: 0
Training loss: 1.762813118249994
Validation loss: 2.5029860028914306

Epoch: 5| Step: 1
Training loss: 2.739960290384388
Validation loss: 2.5043811635353372

Epoch: 5| Step: 2
Training loss: 2.979255639372675
Validation loss: 2.5100944135457706

Epoch: 5| Step: 3
Training loss: 2.6832433302418006
Validation loss: 2.5084056905330563

Epoch: 5| Step: 4
Training loss: 2.65519971839901
Validation loss: 2.5165549192397703

Epoch: 5| Step: 5
Training loss: 2.5407443535841567
Validation loss: 2.5002900511646855

Epoch: 5| Step: 6
Training loss: 2.396417717912122
Validation loss: 2.5244804171923816

Epoch: 5| Step: 7
Training loss: 2.0926249883551584
Validation loss: 2.517025291288525

Epoch: 5| Step: 8
Training loss: 2.264549473635425
Validation loss: 2.514570437706152

Epoch: 5| Step: 9
Training loss: 2.0669790242113106
Validation loss: 2.511140126865504

Epoch: 5| Step: 10
Training loss: 2.5572831619235226
Validation loss: 2.507845283206875

Epoch: 5| Step: 11
Training loss: 2.8366580604694613
Validation loss: 2.524112020755114

Epoch: 34| Step: 0
Training loss: 2.357420762511388
Validation loss: 2.513996683242712

Epoch: 5| Step: 1
Training loss: 2.582267900434236
Validation loss: 2.532496308380203

Epoch: 5| Step: 2
Training loss: 2.497138483804974
Validation loss: 2.47698038067451

Epoch: 5| Step: 3
Training loss: 2.4438734603876204
Validation loss: 2.499004479719342

Epoch: 5| Step: 4
Training loss: 2.3110198361557757
Validation loss: 2.5031895754989852

Epoch: 5| Step: 5
Training loss: 2.798218303298118
Validation loss: 2.4973127625100693

Epoch: 5| Step: 6
Training loss: 2.5251494939380996
Validation loss: 2.5041286510579983

Epoch: 5| Step: 7
Training loss: 2.6180490470645683
Validation loss: 2.5144998273176222

Epoch: 5| Step: 8
Training loss: 2.190342609309052
Validation loss: 2.5135803324548243

Epoch: 5| Step: 9
Training loss: 2.1114783079246697
Validation loss: 2.527075065862388

Epoch: 5| Step: 10
Training loss: 2.5812490320088415
Validation loss: 2.5046201135649553

Epoch: 5| Step: 11
Training loss: 2.7091793988469495
Validation loss: 2.5120570032656295

Epoch: 35| Step: 0
Training loss: 2.1800552112692304
Validation loss: 2.507274637348036

Epoch: 5| Step: 1
Training loss: 3.039212181504296
Validation loss: 2.516918619809012

Epoch: 5| Step: 2
Training loss: 2.213783723648621
Validation loss: 2.510700226963188

Epoch: 5| Step: 3
Training loss: 3.008629467479006
Validation loss: 2.5111239744051987

Epoch: 5| Step: 4
Training loss: 2.4480279342578464
Validation loss: 2.4950188962683337

Epoch: 5| Step: 5
Training loss: 2.795091539907268
Validation loss: 2.5082085812607393

Epoch: 5| Step: 6
Training loss: 2.1892750758684034
Validation loss: 2.5074612459640724

Epoch: 5| Step: 7
Training loss: 1.963121755476453
Validation loss: 2.5291967188030617

Epoch: 5| Step: 8
Training loss: 2.1292625758995682
Validation loss: 2.5070543935786698

Epoch: 5| Step: 9
Training loss: 2.1121633679032508
Validation loss: 2.5028143538783603

Epoch: 5| Step: 10
Training loss: 2.1731845557692147
Validation loss: 2.5150649511571914

Epoch: 5| Step: 11
Training loss: 3.5180746402683827
Validation loss: 2.518609168498931

Epoch: 36| Step: 0
Training loss: 2.179445642978843
Validation loss: 2.5118803424181997

Epoch: 5| Step: 1
Training loss: 2.7675413399824693
Validation loss: 2.5122210176929354

Epoch: 5| Step: 2
Training loss: 2.8018360997906946
Validation loss: 2.494834012897939

Epoch: 5| Step: 3
Training loss: 2.0587473166007624
Validation loss: 2.501786670413644

Epoch: 5| Step: 4
Training loss: 2.0727674216468963
Validation loss: 2.5018778027034285

Epoch: 5| Step: 5
Training loss: 2.956281962635252
Validation loss: 2.498752073913981

Epoch: 5| Step: 6
Training loss: 2.250120477629782
Validation loss: 2.5182973832072846

Epoch: 5| Step: 7
Training loss: 2.7451478460412213
Validation loss: 2.5134828343773736

Epoch: 5| Step: 8
Training loss: 1.9974050973398032
Validation loss: 2.5125783870102993

Epoch: 5| Step: 9
Training loss: 2.6126736560399366
Validation loss: 2.5017347436554527

Epoch: 5| Step: 10
Training loss: 2.4293383381174727
Validation loss: 2.4914935589836658

Epoch: 5| Step: 11
Training loss: 2.3455545217942544
Validation loss: 2.504108700475419

Epoch: 37| Step: 0
Training loss: 2.616174849275174
Validation loss: 2.5153920912878296

Epoch: 5| Step: 1
Training loss: 2.6470734000583795
Validation loss: 2.491689004340775

Epoch: 5| Step: 2
Training loss: 2.2489462610238475
Validation loss: 2.5145906924435297

Epoch: 5| Step: 3
Training loss: 2.1374334224571796
Validation loss: 2.491720544483469

Epoch: 5| Step: 4
Training loss: 3.3173829562389576
Validation loss: 2.5208239725953216

Epoch: 5| Step: 5
Training loss: 2.5388207892762016
Validation loss: 2.500843942768643

Epoch: 5| Step: 6
Training loss: 2.5265193107466413
Validation loss: 2.500518820492401

Epoch: 5| Step: 7
Training loss: 2.4893028282144862
Validation loss: 2.508224025723004

Epoch: 5| Step: 8
Training loss: 1.9927571996774858
Validation loss: 2.5061510153714663

Epoch: 5| Step: 9
Training loss: 2.2879479725264282
Validation loss: 2.514983575209874

Epoch: 5| Step: 10
Training loss: 2.078615173812123
Validation loss: 2.5025388025698354

Epoch: 5| Step: 11
Training loss: 1.719856322297925
Validation loss: 2.5258411163997607

Epoch: 38| Step: 0
Training loss: 2.5421150520753937
Validation loss: 2.511903798518107

Epoch: 5| Step: 1
Training loss: 2.8480035180273724
Validation loss: 2.517681367314385

Epoch: 5| Step: 2
Training loss: 2.3433992250528966
Validation loss: 2.5283562245230624

Epoch: 5| Step: 3
Training loss: 2.959318579001992
Validation loss: 2.5440603980686065

Epoch: 5| Step: 4
Training loss: 2.0416540288209655
Validation loss: 2.544135619481264

Epoch: 5| Step: 5
Training loss: 1.4229770623380356
Validation loss: 2.561259611104591

Epoch: 5| Step: 6
Training loss: 2.8239837168799546
Validation loss: 2.5651625470071

Epoch: 5| Step: 7
Training loss: 2.513277463047446
Validation loss: 2.5602363419462892

Epoch: 5| Step: 8
Training loss: 2.3299571770919996
Validation loss: 2.5581458828146184

Epoch: 5| Step: 9
Training loss: 2.420111623349265
Validation loss: 2.5596063604803714

Epoch: 5| Step: 10
Training loss: 2.577644997041665
Validation loss: 2.547778248295651

Epoch: 5| Step: 11
Training loss: 1.7389046569098474
Validation loss: 2.5421742156591565

Epoch: 39| Step: 0
Training loss: 2.449305677316296
Validation loss: 2.5482127064180538

Epoch: 5| Step: 1
Training loss: 2.347153493964755
Validation loss: 2.5211335520975893

Epoch: 5| Step: 2
Training loss: 2.193206972039937
Validation loss: 2.51483597238236

Epoch: 5| Step: 3
Training loss: 2.2055048432540207
Validation loss: 2.5422989001618355

Epoch: 5| Step: 4
Training loss: 3.530800849909781
Validation loss: 2.5218701371623085

Epoch: 5| Step: 5
Training loss: 2.3082618022903287
Validation loss: 2.5184417261451966

Epoch: 5| Step: 6
Training loss: 2.1646493054183162
Validation loss: 2.5293793496686057

Epoch: 5| Step: 7
Training loss: 2.570028086408629
Validation loss: 2.52444217157117

Epoch: 5| Step: 8
Training loss: 2.210540412317709
Validation loss: 2.511752581726957

Epoch: 5| Step: 9
Training loss: 2.4852994722254875
Validation loss: 2.5155920022573386

Epoch: 5| Step: 10
Training loss: 2.362403492243091
Validation loss: 2.522458925048246

Epoch: 5| Step: 11
Training loss: 1.5154892378890292
Validation loss: 2.511694880837338

Epoch: 40| Step: 0
Training loss: 2.021656445537411
Validation loss: 2.512510081092259

Epoch: 5| Step: 1
Training loss: 2.4706857552502077
Validation loss: 2.5137117309097987

Epoch: 5| Step: 2
Training loss: 2.6551630825668004
Validation loss: 2.530050986653244

Epoch: 5| Step: 3
Training loss: 2.0218847495644354
Validation loss: 2.5131376815801016

Epoch: 5| Step: 4
Training loss: 2.3925591915704945
Validation loss: 2.511070132120453

Epoch: 5| Step: 5
Training loss: 2.5949398207255703
Validation loss: 2.5117338347192137

Epoch: 5| Step: 6
Training loss: 2.4544361279605122
Validation loss: 2.50524386951095

Epoch: 5| Step: 7
Training loss: 2.198875061607653
Validation loss: 2.524651490291619

Epoch: 5| Step: 8
Training loss: 2.4976571549314612
Validation loss: 2.472080326353896

Epoch: 5| Step: 9
Training loss: 3.2008359591999587
Validation loss: 2.4960718049471184

Epoch: 5| Step: 10
Training loss: 2.2554268558576718
Validation loss: 2.489555300204943

Epoch: 5| Step: 11
Training loss: 1.6493842854587175
Validation loss: 2.513101417685742

Epoch: 41| Step: 0
Training loss: 2.45874507063821
Validation loss: 2.498854386580904

Epoch: 5| Step: 1
Training loss: 2.220948755105064
Validation loss: 2.4999253937397374

Epoch: 5| Step: 2
Training loss: 2.081897151557758
Validation loss: 2.5051861654293495

Epoch: 5| Step: 3
Training loss: 2.48634567314482
Validation loss: 2.5122780382348906

Epoch: 5| Step: 4
Training loss: 2.4882104405459056
Validation loss: 2.506075030408214

Epoch: 5| Step: 5
Training loss: 2.010715034231121
Validation loss: 2.5237128832831903

Epoch: 5| Step: 6
Training loss: 2.6818221684383627
Validation loss: 2.511983146614235

Epoch: 5| Step: 7
Training loss: 2.062979324592243
Validation loss: 2.518148140193823

Epoch: 5| Step: 8
Training loss: 2.7491638472967463
Validation loss: 2.5064370611116358

Epoch: 5| Step: 9
Training loss: 2.7969706428413765
Validation loss: 2.5265970792745502

Epoch: 5| Step: 10
Training loss: 2.6595716464250896
Validation loss: 2.5285173115674815

Epoch: 5| Step: 11
Training loss: 2.6186799761530395
Validation loss: 2.5018052140050973

Epoch: 42| Step: 0
Training loss: 1.890607534280605
Validation loss: 2.5299171855563305

Epoch: 5| Step: 1
Training loss: 2.1562329720087385
Validation loss: 2.503737937439841

Epoch: 5| Step: 2
Training loss: 2.610853130591425
Validation loss: 2.4990996169911157

Epoch: 5| Step: 3
Training loss: 2.4307604809309202
Validation loss: 2.5154438664400818

Epoch: 5| Step: 4
Training loss: 2.708282137655897
Validation loss: 2.526895761460403

Epoch: 5| Step: 5
Training loss: 2.9024099596565565
Validation loss: 2.4966823976256265

Epoch: 5| Step: 6
Training loss: 1.9915948921369493
Validation loss: 2.488765212363311

Epoch: 5| Step: 7
Training loss: 2.4605842457894918
Validation loss: 2.5023276182526697

Epoch: 5| Step: 8
Training loss: 2.436331737981077
Validation loss: 2.5066677582472936

Epoch: 5| Step: 9
Training loss: 2.273051750255233
Validation loss: 2.516117438696564

Epoch: 5| Step: 10
Training loss: 2.4858246418614183
Validation loss: 2.5049843651682737

Epoch: 5| Step: 11
Training loss: 3.7516844463110677
Validation loss: 2.5053329291392425

Epoch: 43| Step: 0
Training loss: 2.3956461515420924
Validation loss: 2.5112020139981546

Epoch: 5| Step: 1
Training loss: 2.3997601270011915
Validation loss: 2.5026587176985076

Epoch: 5| Step: 2
Training loss: 2.900696236792486
Validation loss: 2.5109228887411787

Epoch: 5| Step: 3
Training loss: 1.704176481944625
Validation loss: 2.51392120413152

Epoch: 5| Step: 4
Training loss: 2.328179070785693
Validation loss: 2.5074858725096885

Epoch: 5| Step: 5
Training loss: 2.371894814228832
Validation loss: 2.4821032207790092

Epoch: 5| Step: 6
Training loss: 2.1425276048767006
Validation loss: 2.5168557364976474

Epoch: 5| Step: 7
Training loss: 2.839403624712549
Validation loss: 2.493357667678853

Epoch: 5| Step: 8
Training loss: 2.371371860942238
Validation loss: 2.5174213693064207

Epoch: 5| Step: 9
Training loss: 2.7376930377779574
Validation loss: 2.508481325703137

Epoch: 5| Step: 10
Training loss: 2.3789070517753164
Validation loss: 2.5159468000735474

Epoch: 5| Step: 11
Training loss: 2.487516324550411
Validation loss: 2.5219219487014164

Epoch: 44| Step: 0
Training loss: 2.362337892006459
Validation loss: 2.517294446274408

Epoch: 5| Step: 1
Training loss: 2.2506685323406157
Validation loss: 2.526997754303428

Epoch: 5| Step: 2
Training loss: 2.2031194808566177
Validation loss: 2.5446028764431383

Epoch: 5| Step: 3
Training loss: 2.2181870726936745
Validation loss: 2.533592964710981

Epoch: 5| Step: 4
Training loss: 3.133285829170437
Validation loss: 2.5428730858282087

Epoch: 5| Step: 5
Training loss: 2.4634680921819814
Validation loss: 2.535140648290808

Epoch: 5| Step: 6
Training loss: 2.514510197959939
Validation loss: 2.530835121597129

Epoch: 5| Step: 7
Training loss: 2.3245132387949017
Validation loss: 2.5256724975973084

Epoch: 5| Step: 8
Training loss: 2.057876027487282
Validation loss: 2.529556210059919

Epoch: 5| Step: 9
Training loss: 2.777255586708322
Validation loss: 2.5134095808710315

Epoch: 5| Step: 10
Training loss: 2.4876731237233733
Validation loss: 2.513684244824463

Epoch: 5| Step: 11
Training loss: 1.3886353049311826
Validation loss: 2.5242738469607398

Epoch: 45| Step: 0
Training loss: 2.3796916598448337
Validation loss: 2.514486019481753

Epoch: 5| Step: 1
Training loss: 2.0700777892455715
Validation loss: 2.5136384326969776

Epoch: 5| Step: 2
Training loss: 2.513272055815723
Validation loss: 2.5168015944919033

Epoch: 5| Step: 3
Training loss: 1.9599490162972033
Validation loss: 2.4976458054794386

Epoch: 5| Step: 4
Training loss: 2.328165758019382
Validation loss: 2.4919799630580104

Epoch: 5| Step: 5
Training loss: 2.098811962492149
Validation loss: 2.50138813660454

Epoch: 5| Step: 6
Training loss: 2.258864741659416
Validation loss: 2.508875422552333

Epoch: 5| Step: 7
Training loss: 2.724908452727289
Validation loss: 2.5180575612457567

Epoch: 5| Step: 8
Training loss: 2.5484904215338737
Validation loss: 2.522785157562249

Epoch: 5| Step: 9
Training loss: 2.712265700667629
Validation loss: 2.502467999572874

Epoch: 5| Step: 10
Training loss: 3.103023617289757
Validation loss: 2.5301427735061433

Epoch: 5| Step: 11
Training loss: 2.041311375851002
Validation loss: 2.4955917872521156

Epoch: 46| Step: 0
Training loss: 2.8998827351505976
Validation loss: 2.510026685147326

Epoch: 5| Step: 1
Training loss: 1.7153751879311632
Validation loss: 2.5173791728340054

Epoch: 5| Step: 2
Training loss: 2.2025055792366572
Validation loss: 2.5224187544425125

Epoch: 5| Step: 3
Training loss: 2.0478386394218493
Validation loss: 2.5311189507677105

Epoch: 5| Step: 4
Training loss: 2.3953844949213314
Validation loss: 2.5383563345929194

Epoch: 5| Step: 5
Training loss: 2.925271248263232
Validation loss: 2.533916019156547

Epoch: 5| Step: 6
Training loss: 3.068845597465996
Validation loss: 2.557528288020743

Epoch: 5| Step: 7
Training loss: 2.7131090948187437
Validation loss: 2.5574340832451266

Epoch: 5| Step: 8
Training loss: 1.9567495664920427
Validation loss: 2.5490524836337936

Epoch: 5| Step: 9
Training loss: 2.2983260988043694
Validation loss: 2.533111845130248

Epoch: 5| Step: 10
Training loss: 2.5097756945931264
Validation loss: 2.531055580333481

Epoch: 5| Step: 11
Training loss: 1.9218968335904099
Validation loss: 2.5397992517708876

Epoch: 47| Step: 0
Training loss: 2.6153603623849384
Validation loss: 2.5191931051603493

Epoch: 5| Step: 1
Training loss: 2.057876027487282
Validation loss: 2.5320755864143556

Epoch: 5| Step: 2
Training loss: 2.27321096648431
Validation loss: 2.505420506640047

Epoch: 5| Step: 3
Training loss: 2.3391090729892388
Validation loss: 2.5032330826607048

Epoch: 5| Step: 4
Training loss: 2.898397687037043
Validation loss: 2.513413066923115

Epoch: 5| Step: 5
Training loss: 2.456699464165828
Validation loss: 2.5176407969240113

Epoch: 5| Step: 6
Training loss: 2.170895142752223
Validation loss: 2.4956382729903197

Epoch: 5| Step: 7
Training loss: 2.049490153482371
Validation loss: 2.4847012051765014

Epoch: 5| Step: 8
Training loss: 2.6182143289421194
Validation loss: 2.5128951217490165

Epoch: 5| Step: 9
Training loss: 2.07989896620611
Validation loss: 2.4860944655611186

Epoch: 5| Step: 10
Training loss: 2.555694008499802
Validation loss: 2.4900065877615356

Epoch: 5| Step: 11
Training loss: 3.8348282649494583
Validation loss: 2.5048620588745414

Epoch: 48| Step: 0
Training loss: 2.965768863255589
Validation loss: 2.4995572254360314

Epoch: 5| Step: 1
Training loss: 1.8877448851524052
Validation loss: 2.5076817590338014

Epoch: 5| Step: 2
Training loss: 2.9084354510227852
Validation loss: 2.5000921629765918

Epoch: 5| Step: 3
Training loss: 2.1921403984507415
Validation loss: 2.5209467753324075

Epoch: 5| Step: 4
Training loss: 1.728757196992028
Validation loss: 2.4979350264073115

Epoch: 5| Step: 5
Training loss: 2.5225666066838057
Validation loss: 2.5016784755454333

Epoch: 5| Step: 6
Training loss: 2.633290867121032
Validation loss: 2.5094713882170137

Epoch: 5| Step: 7
Training loss: 2.4807901489613333
Validation loss: 2.494766491395928

Epoch: 5| Step: 8
Training loss: 2.781974955168375
Validation loss: 2.5077788131843937

Epoch: 5| Step: 9
Training loss: 2.317572108919484
Validation loss: 2.498594496937222

Epoch: 5| Step: 10
Training loss: 2.053123197743454
Validation loss: 2.484972616008978

Epoch: 5| Step: 11
Training loss: 2.0615336148197385
Validation loss: 2.5097190605227633

Epoch: 49| Step: 0
Training loss: 2.259604933819117
Validation loss: 2.5147539945008734

Epoch: 5| Step: 1
Training loss: 3.215426460565258
Validation loss: 2.508481088090654

Epoch: 5| Step: 2
Training loss: 1.6258299248817858
Validation loss: 2.5250129073036574

Epoch: 5| Step: 3
Training loss: 2.44195384483865
Validation loss: 2.519223326957463

Epoch: 5| Step: 4
Training loss: 3.2577532207118
Validation loss: 2.5361270975472787

Epoch: 5| Step: 5
Training loss: 2.6345189391212163
Validation loss: 2.5279328152570573

Epoch: 5| Step: 6
Training loss: 2.4993298586073958
Validation loss: 2.5156354726253527

Epoch: 5| Step: 7
Training loss: 1.9375996102599642
Validation loss: 2.528350727737715

Epoch: 5| Step: 8
Training loss: 1.8274186554846512
Validation loss: 2.5195007006939534

Epoch: 5| Step: 9
Training loss: 2.538691566955574
Validation loss: 2.5329317620587877

Epoch: 5| Step: 10
Training loss: 1.9856896438618277
Validation loss: 2.5240787640056612

Epoch: 5| Step: 11
Training loss: 1.7404600054960186
Validation loss: 2.5307214483371214

Epoch: 50| Step: 0
Training loss: 2.682878646079588
Validation loss: 2.5199266818332906

Epoch: 5| Step: 1
Training loss: 2.3523825802824065
Validation loss: 2.52906976217766

Epoch: 5| Step: 2
Training loss: 2.3308675089151274
Validation loss: 2.532865228717913

Epoch: 5| Step: 3
Training loss: 2.335356879397749
Validation loss: 2.5326494069100822

Epoch: 5| Step: 4
Training loss: 2.1580251490883744
Validation loss: 2.5022750575903077

Epoch: 5| Step: 5
Training loss: 2.2007721586246145
Validation loss: 2.534699389530503

Epoch: 5| Step: 6
Training loss: 2.6608583753271393
Validation loss: 2.519382182598167

Epoch: 5| Step: 7
Training loss: 2.5925572421928567
Validation loss: 2.514301694401464

Epoch: 5| Step: 8
Training loss: 1.9368315743486315
Validation loss: 2.5003866373538983

Epoch: 5| Step: 9
Training loss: 3.2390001923106726
Validation loss: 2.5255460993679777

Epoch: 5| Step: 10
Training loss: 1.9320993524835703
Validation loss: 2.5071750317905055

Epoch: 5| Step: 11
Training loss: 2.261531209335197
Validation loss: 2.511953741365847

Epoch: 51| Step: 0
Training loss: 2.298280039670334
Validation loss: 2.511495007743332

Epoch: 5| Step: 1
Training loss: 2.3756837362581913
Validation loss: 2.510958594609645

Epoch: 5| Step: 2
Training loss: 2.060038976763525
Validation loss: 2.5182300095555115

Epoch: 5| Step: 3
Training loss: 2.78485696476659
Validation loss: 2.5087697350220446

Epoch: 5| Step: 4
Training loss: 2.75439466108901
Validation loss: 2.5192627480338836

Epoch: 5| Step: 5
Training loss: 2.284402210997198
Validation loss: 2.5105195650932406

Epoch: 5| Step: 6
Training loss: 2.3479931886304484
Validation loss: 2.5041853004837082

Epoch: 5| Step: 7
Training loss: 2.088848925381835
Validation loss: 2.5183692539440052

Epoch: 5| Step: 8
Training loss: 2.5380761680987436
Validation loss: 2.516094965503807

Epoch: 5| Step: 9
Training loss: 2.408034418512781
Validation loss: 2.503545162768506

Epoch: 5| Step: 10
Training loss: 2.7488570005399926
Validation loss: 2.540595066493247

Epoch: 5| Step: 11
Training loss: 1.5975876026281906
Validation loss: 2.5135712740551233

Epoch: 52| Step: 0
Training loss: 2.36304880055175
Validation loss: 2.5318850164216107

Epoch: 5| Step: 1
Training loss: 2.056875709943901
Validation loss: 2.4982030927553476

Epoch: 5| Step: 2
Training loss: 3.1383078458388853
Validation loss: 2.523924997990957

Epoch: 5| Step: 3
Training loss: 3.1586836695226204
Validation loss: 2.5158685641324343

Epoch: 5| Step: 4
Training loss: 2.453621006284481
Validation loss: 2.539844361258912

Epoch: 5| Step: 5
Training loss: 2.5708684349033732
Validation loss: 2.534329934587733

Epoch: 5| Step: 6
Training loss: 2.0024359888330463
Validation loss: 2.5104698054175576

Epoch: 5| Step: 7
Training loss: 2.0630670403789946
Validation loss: 2.5109566560215115

Epoch: 5| Step: 8
Training loss: 1.968687631739359
Validation loss: 2.5105249545114425

Epoch: 5| Step: 9
Training loss: 1.7292767072233592
Validation loss: 2.5061206835000633

Epoch: 5| Step: 10
Training loss: 2.676562653211421
Validation loss: 2.5200258503892363

Epoch: 5| Step: 11
Training loss: 2.181858417291711
Validation loss: 2.5087129079689827

Epoch: 53| Step: 0
Training loss: 1.8430337969599067
Validation loss: 2.5153441696899965

Epoch: 5| Step: 1
Training loss: 2.659103924823909
Validation loss: 2.529603544322152

Epoch: 5| Step: 2
Training loss: 2.6853804103237655
Validation loss: 2.5079866588484605

Epoch: 5| Step: 3
Training loss: 2.272578965463325
Validation loss: 2.4896068824601327

Epoch: 5| Step: 4
Training loss: 2.5403184806724233
Validation loss: 2.5139652368521292

Epoch: 5| Step: 5
Training loss: 2.695366015801372
Validation loss: 2.510716845081438

Epoch: 5| Step: 6
Training loss: 2.403229241658787
Validation loss: 2.4989111635230628

Epoch: 5| Step: 7
Training loss: 2.573699574655098
Validation loss: 2.4935067968878277

Epoch: 5| Step: 8
Training loss: 2.783244414441538
Validation loss: 2.5146236519687695

Epoch: 5| Step: 9
Training loss: 1.5202526743331646
Validation loss: 2.5031766894873657

Epoch: 5| Step: 10
Training loss: 2.32956205730062
Validation loss: 2.5135689165735826

Epoch: 5| Step: 11
Training loss: 2.5030245604824612
Validation loss: 2.4875882200191577

Epoch: 54| Step: 0
Training loss: 1.8936867630978935
Validation loss: 2.502552398453184

Epoch: 5| Step: 1
Training loss: 1.8498231468210065
Validation loss: 2.5004725089181297

Epoch: 5| Step: 2
Training loss: 2.0575729242243095
Validation loss: 2.5314619069820727

Epoch: 5| Step: 3
Training loss: 2.6460538056396525
Validation loss: 2.5112403188531176

Epoch: 5| Step: 4
Training loss: 2.5679536796385256
Validation loss: 2.517691059997631

Epoch: 5| Step: 5
Training loss: 3.1409199894014774
Validation loss: 2.522930696691494

Epoch: 5| Step: 6
Training loss: 2.379764596212455
Validation loss: 2.515985080071824

Epoch: 5| Step: 7
Training loss: 2.311123102974143
Validation loss: 2.5250608657198756

Epoch: 5| Step: 8
Training loss: 2.220619166522493
Validation loss: 2.508190970219841

Epoch: 5| Step: 9
Training loss: 2.9128739538504766
Validation loss: 2.522856087328769

Epoch: 5| Step: 10
Training loss: 2.2031029233435118
Validation loss: 2.5188587917752745

Epoch: 5| Step: 11
Training loss: 2.971510236398652
Validation loss: 2.522978104069856

Epoch: 55| Step: 0
Training loss: 2.689537252025969
Validation loss: 2.510066998665354

Epoch: 5| Step: 1
Training loss: 2.6878401075332867
Validation loss: 2.5198031887397097

Epoch: 5| Step: 2
Training loss: 2.442945706045627
Validation loss: 2.4973339249485793

Epoch: 5| Step: 3
Training loss: 1.7748593583601542
Validation loss: 2.504735629768903

Epoch: 5| Step: 4
Training loss: 2.404136918895965
Validation loss: 2.5119531442010263

Epoch: 5| Step: 5
Training loss: 2.8155628057759685
Validation loss: 2.50851823456886

Epoch: 5| Step: 6
Training loss: 2.5234355158842336
Validation loss: 2.5304568739641127

Epoch: 5| Step: 7
Training loss: 1.9418049025000346
Validation loss: 2.5256265843244927

Epoch: 5| Step: 8
Training loss: 2.177803127418085
Validation loss: 2.5058547842767163

Epoch: 5| Step: 9
Training loss: 2.5716106070314724
Validation loss: 2.4948234410077617

Epoch: 5| Step: 10
Training loss: 2.446523543215917
Validation loss: 2.501392812968209

Epoch: 5| Step: 11
Training loss: 2.2049758387342604
Validation loss: 2.512960060979199

Epoch: 56| Step: 0
Training loss: 2.979183134731491
Validation loss: 2.5090607045276063

Epoch: 5| Step: 1
Training loss: 2.094929035778422
Validation loss: 2.5143467358580875

Epoch: 5| Step: 2
Training loss: 1.9431691445642596
Validation loss: 2.530718311936319

Epoch: 5| Step: 3
Training loss: 1.8892062199572783
Validation loss: 2.5354036916736704

Epoch: 5| Step: 4
Training loss: 2.064811798090965
Validation loss: 2.5478132310106174

Epoch: 5| Step: 5
Training loss: 2.0768135923616766
Validation loss: 2.5515994696694366

Epoch: 5| Step: 6
Training loss: 2.861524097384488
Validation loss: 2.5732020221159675

Epoch: 5| Step: 7
Training loss: 2.598496104833705
Validation loss: 2.576836520263992

Epoch: 5| Step: 8
Training loss: 3.0379886249884285
Validation loss: 2.543239127931312

Epoch: 5| Step: 9
Training loss: 2.7099485324884998
Validation loss: 2.532029083040733

Epoch: 5| Step: 10
Training loss: 2.2621961231491543
Validation loss: 2.520244936935162

Epoch: 5| Step: 11
Training loss: 2.429960474705375
Validation loss: 2.4987526165870757

Epoch: 57| Step: 0
Training loss: 3.1938816588375936
Validation loss: 2.5255538325174043

Epoch: 5| Step: 1
Training loss: 2.3650061499614474
Validation loss: 2.5067043490337895

Epoch: 5| Step: 2
Training loss: 2.2825461063136294
Validation loss: 2.5003122889655285

Epoch: 5| Step: 3
Training loss: 2.3369060026827686
Validation loss: 2.4852517498286355

Epoch: 5| Step: 4
Training loss: 2.3726487818736395
Validation loss: 2.500402096360145

Epoch: 5| Step: 5
Training loss: 2.7094298466077626
Validation loss: 2.49970136487991

Epoch: 5| Step: 6
Training loss: 1.690444637697466
Validation loss: 2.4950587793967816

Epoch: 5| Step: 7
Training loss: 2.1908401057140003
Validation loss: 2.4952469584839485

Epoch: 5| Step: 8
Training loss: 2.576376767285654
Validation loss: 2.4845624649047466

Epoch: 5| Step: 9
Training loss: 2.29386840015805
Validation loss: 2.492717636708488

Epoch: 5| Step: 10
Training loss: 2.5103666899416806
Validation loss: 2.5017592161160107

Epoch: 5| Step: 11
Training loss: 1.2926872384898698
Validation loss: 2.5216899525041465

Epoch: 58| Step: 0
Training loss: 1.9944406371521568
Validation loss: 2.5001823597201414

Epoch: 5| Step: 1
Training loss: 2.864269133011212
Validation loss: 2.506178080667641

Epoch: 5| Step: 2
Training loss: 2.4445964508285543
Validation loss: 2.508816376514268

Epoch: 5| Step: 3
Training loss: 2.2799614180261885
Validation loss: 2.496519435508442

Epoch: 5| Step: 4
Training loss: 2.2525972634505558
Validation loss: 2.499508555110284

Epoch: 5| Step: 5
Training loss: 2.4863187275819065
Validation loss: 2.508940782583542

Epoch: 5| Step: 6
Training loss: 1.8066756621391382
Validation loss: 2.5080342496792563

Epoch: 5| Step: 7
Training loss: 2.5714834960490958
Validation loss: 2.512218886317489

Epoch: 5| Step: 8
Training loss: 2.498594556575395
Validation loss: 2.516726917899282

Epoch: 5| Step: 9
Training loss: 2.2711408097804817
Validation loss: 2.5189633579617867

Epoch: 5| Step: 10
Training loss: 2.640153470346916
Validation loss: 2.5123914309272664

Epoch: 5| Step: 11
Training loss: 3.4190928676028207
Validation loss: 2.5242042045996707

Epoch: 59| Step: 0
Training loss: 2.395927084595031
Validation loss: 2.517202044902181

Epoch: 5| Step: 1
Training loss: 2.513480083555891
Validation loss: 2.546313766161075

Epoch: 5| Step: 2
Training loss: 2.5645273144138105
Validation loss: 2.5520717906042116

Epoch: 5| Step: 3
Training loss: 2.7844110591450146
Validation loss: 2.5719117558673683

Epoch: 5| Step: 4
Training loss: 1.861289889572361
Validation loss: 2.549937741136653

Epoch: 5| Step: 5
Training loss: 2.0374251182229304
Validation loss: 2.551369607474503

Epoch: 5| Step: 6
Training loss: 2.779455656232817
Validation loss: 2.548465815062699

Epoch: 5| Step: 7
Training loss: 2.631275667985051
Validation loss: 2.5496331279792344

Epoch: 5| Step: 8
Training loss: 2.590545789292225
Validation loss: 2.5342217061522816

Epoch: 5| Step: 9
Training loss: 2.092383664815646
Validation loss: 2.5290200493142145

Epoch: 5| Step: 10
Training loss: 2.2686385534567797
Validation loss: 2.5209976423850984

Epoch: 5| Step: 11
Training loss: 1.6462248646316944
Validation loss: 2.5294829429025723

Epoch: 60| Step: 0
Training loss: 2.462366179882047
Validation loss: 2.5183506094451267

Epoch: 5| Step: 1
Training loss: 2.6173692327004354
Validation loss: 2.5194899129310455

Epoch: 5| Step: 2
Training loss: 2.571665120976252
Validation loss: 2.516211348570141

Epoch: 5| Step: 3
Training loss: 2.0642549388965477
Validation loss: 2.5047059629397985

Epoch: 5| Step: 4
Training loss: 2.2437309243074046
Validation loss: 2.5202202537447906

Epoch: 5| Step: 5
Training loss: 2.165920300187691
Validation loss: 2.523049926125992

Epoch: 5| Step: 6
Training loss: 2.1763884486419984
Validation loss: 2.5115910760161135

Epoch: 5| Step: 7
Training loss: 2.4620997999278353
Validation loss: 2.518246654908694

Epoch: 5| Step: 8
Training loss: 2.1287954879085027
Validation loss: 2.5190553121997

Epoch: 5| Step: 9
Training loss: 2.6272372747983
Validation loss: 2.511090470476992

Epoch: 5| Step: 10
Training loss: 2.8202428412882976
Validation loss: 2.524431208165551

Epoch: 5| Step: 11
Training loss: 2.6773196065419107
Validation loss: 2.512224730789812

Epoch: 61| Step: 0
Training loss: 2.4447075336176223
Validation loss: 2.4998060747272857

Epoch: 5| Step: 1
Training loss: 2.6517570644517248
Validation loss: 2.5053890596631687

Epoch: 5| Step: 2
Training loss: 2.19034522170515
Validation loss: 2.4993035657728204

Epoch: 5| Step: 3
Training loss: 2.861964319738465
Validation loss: 2.5018256475336353

Epoch: 5| Step: 4
Training loss: 2.258607928859312
Validation loss: 2.5004948205805877

Epoch: 5| Step: 5
Training loss: 1.6624606307107936
Validation loss: 2.504905166179218

Epoch: 5| Step: 6
Training loss: 2.5667953776829924
Validation loss: 2.4948302938275573

Epoch: 5| Step: 7
Training loss: 2.349398406110804
Validation loss: 2.4981101323584753

Epoch: 5| Step: 8
Training loss: 2.497904662378359
Validation loss: 2.478797361505276

Epoch: 5| Step: 9
Training loss: 2.102783982628767
Validation loss: 2.488814108747905

Epoch: 5| Step: 10
Training loss: 2.5023866705141895
Validation loss: 2.4938368526430423

Epoch: 5| Step: 11
Training loss: 3.064516299042106
Validation loss: 2.4976108260921825

Epoch: 62| Step: 0
Training loss: 2.323692659734565
Validation loss: 2.5105010858695627

Epoch: 5| Step: 1
Training loss: 2.812498813205045
Validation loss: 2.5140989346390037

Epoch: 5| Step: 2
Training loss: 1.9363631327844568
Validation loss: 2.499716520131853

Epoch: 5| Step: 3
Training loss: 2.6621778875366156
Validation loss: 2.4970338948299085

Epoch: 5| Step: 4
Training loss: 2.189486228563304
Validation loss: 2.5038552499735895

Epoch: 5| Step: 5
Training loss: 3.1848229030556983
Validation loss: 2.5065405542452663

Epoch: 5| Step: 6
Training loss: 2.4932925844517584
Validation loss: 2.5080891770498637

Epoch: 5| Step: 7
Training loss: 2.4517825395632813
Validation loss: 2.510585574776796

Epoch: 5| Step: 8
Training loss: 2.179207916550114
Validation loss: 2.5047868716461

Epoch: 5| Step: 9
Training loss: 1.7554856561407775
Validation loss: 2.5198700314831446

Epoch: 5| Step: 10
Training loss: 2.3094467420364944
Validation loss: 2.5053584727279974

Epoch: 5| Step: 11
Training loss: 2.5013487992035617
Validation loss: 2.5312298118508374

Epoch: 63| Step: 0
Training loss: 2.763145671664477
Validation loss: 2.510755345277795

Epoch: 5| Step: 1
Training loss: 2.541753850806966
Validation loss: 2.539543376281774

Epoch: 5| Step: 2
Training loss: 2.8080335968376944
Validation loss: 2.5330892011269937

Epoch: 5| Step: 3
Training loss: 2.5818251442418507
Validation loss: 2.5417618903056485

Epoch: 5| Step: 4
Training loss: 2.974980131451593
Validation loss: 2.5532811850529553

Epoch: 5| Step: 5
Training loss: 2.0477988218575147
Validation loss: 2.5343503861460897

Epoch: 5| Step: 6
Training loss: 2.175400322214201
Validation loss: 2.5411683627255313

Epoch: 5| Step: 7
Training loss: 2.1267052708333796
Validation loss: 2.5565320082464424

Epoch: 5| Step: 8
Training loss: 2.143611189460344
Validation loss: 2.535576349139124

Epoch: 5| Step: 9
Training loss: 2.288877199764506
Validation loss: 2.5438123261879118

Epoch: 5| Step: 10
Training loss: 1.9329126256544311
Validation loss: 2.5184074004781114

Epoch: 5| Step: 11
Training loss: 1.3830064109576423
Validation loss: 2.525208272150049

Epoch: 64| Step: 0
Training loss: 2.3611154768161677
Validation loss: 2.5250624826776744

Epoch: 5| Step: 1
Training loss: 2.8407801956066536
Validation loss: 2.509880508583993

Epoch: 5| Step: 2
Training loss: 2.0239948698061734
Validation loss: 2.5199261456912003

Epoch: 5| Step: 3
Training loss: 2.2471546619802605
Validation loss: 2.490654026151131

Epoch: 5| Step: 4
Training loss: 2.0652074671753455
Validation loss: 2.506347224219829

Epoch: 5| Step: 5
Training loss: 2.7033543131147884
Validation loss: 2.5053047285878955

Epoch: 5| Step: 6
Training loss: 1.9844442040098091
Validation loss: 2.494448080009477

Epoch: 5| Step: 7
Training loss: 2.48268789911393
Validation loss: 2.496171360072925

Epoch: 5| Step: 8
Training loss: 2.571954730108605
Validation loss: 2.493023495983058

Epoch: 5| Step: 9
Training loss: 2.9044275619974798
Validation loss: 2.4888368522246034

Epoch: 5| Step: 10
Training loss: 1.9656654293105356
Validation loss: 2.5138107020394598

Epoch: 5| Step: 11
Training loss: 2.0286287267026517
Validation loss: 2.5069680817482722

Epoch: 65| Step: 0
Training loss: 2.3735493697019656
Validation loss: 2.491940756195623

Epoch: 5| Step: 1
Training loss: 2.4330038026089316
Validation loss: 2.50664298495518

Epoch: 5| Step: 2
Training loss: 2.325036374699707
Validation loss: 2.5010191985655212

Epoch: 5| Step: 3
Training loss: 2.4463338942997748
Validation loss: 2.513809595531838

Epoch: 5| Step: 4
Training loss: 2.3534396464006653
Validation loss: 2.484201965064185

Epoch: 5| Step: 5
Training loss: 2.400994643097748
Validation loss: 2.492736124223057

Epoch: 5| Step: 6
Training loss: 1.6463026351450682
Validation loss: 2.501636096920902

Epoch: 5| Step: 7
Training loss: 2.037740344516426
Validation loss: 2.5082901354224636

Epoch: 5| Step: 8
Training loss: 2.91348727278567
Validation loss: 2.5054923661200137

Epoch: 5| Step: 9
Training loss: 2.5436676986839544
Validation loss: 2.5248200139964303

Epoch: 5| Step: 10
Training loss: 2.309869662154152
Validation loss: 2.4968887002479168

Epoch: 5| Step: 11
Training loss: 4.3665921755739
Validation loss: 2.517688169755056

Epoch: 66| Step: 0
Training loss: 2.472299076938322
Validation loss: 2.5201826096402065

Epoch: 5| Step: 1
Training loss: 2.896696734987511
Validation loss: 2.5151011274936494

Epoch: 5| Step: 2
Training loss: 2.724535344256347
Validation loss: 2.5245326119483162

Epoch: 5| Step: 3
Training loss: 2.386338623543314
Validation loss: 2.531387627553159

Epoch: 5| Step: 4
Training loss: 2.549742225632876
Validation loss: 2.5191168786884304

Epoch: 5| Step: 5
Training loss: 2.0356701222268554
Validation loss: 2.522260669019845

Epoch: 5| Step: 6
Training loss: 1.9174726353449618
Validation loss: 2.5164342688210892

Epoch: 5| Step: 7
Training loss: 2.190832923240038
Validation loss: 2.527581472482967

Epoch: 5| Step: 8
Training loss: 2.919598840304206
Validation loss: 2.5449936867119125

Epoch: 5| Step: 9
Training loss: 1.9237950356053461
Validation loss: 2.5294034407662864

Epoch: 5| Step: 10
Training loss: 2.185197544901078
Validation loss: 2.533698522499311

Epoch: 5| Step: 11
Training loss: 2.0967201687405543
Validation loss: 2.5091181928090354

Epoch: 67| Step: 0
Training loss: 2.5560926953254155
Validation loss: 2.530453489908669

Epoch: 5| Step: 1
Training loss: 2.1461119116037928
Validation loss: 2.512761514095278

Epoch: 5| Step: 2
Training loss: 1.917574715781275
Validation loss: 2.5212978192574624

Epoch: 5| Step: 3
Training loss: 2.1352540737372734
Validation loss: 2.5215302297459483

Epoch: 5| Step: 4
Training loss: 2.3362034674960412
Validation loss: 2.5191555837269024

Epoch: 5| Step: 5
Training loss: 2.034747706902113
Validation loss: 2.5147829166736586

Epoch: 5| Step: 6
Training loss: 2.5897933932050496
Validation loss: 2.513486834129676

Epoch: 5| Step: 7
Training loss: 2.7967710848636056
Validation loss: 2.508024688015124

Epoch: 5| Step: 8
Training loss: 2.2700489917795488
Validation loss: 2.508382912607339

Epoch: 5| Step: 9
Training loss: 2.484221639638096
Validation loss: 2.511789090529698

Epoch: 5| Step: 10
Training loss: 2.965706319065876
Validation loss: 2.5000838901431885

Epoch: 5| Step: 11
Training loss: 1.7684853938833949
Validation loss: 2.4903208758720385

Epoch: 68| Step: 0
Training loss: 2.86401108083233
Validation loss: 2.499705333033293

Epoch: 5| Step: 1
Training loss: 2.4340790437701076
Validation loss: 2.4989159041525357

Epoch: 5| Step: 2
Training loss: 2.6467740846962973
Validation loss: 2.517366738294838

Epoch: 5| Step: 3
Training loss: 1.9916501386374308
Validation loss: 2.522308539949612

Epoch: 5| Step: 4
Training loss: 2.436412960139394
Validation loss: 2.5028114047798056

Epoch: 5| Step: 5
Training loss: 2.097823322824546
Validation loss: 2.5186364332079663

Epoch: 5| Step: 6
Training loss: 2.2678247756278833
Validation loss: 2.5253431606331453

Epoch: 5| Step: 7
Training loss: 2.466326912687485
Validation loss: 2.531456263894016

Epoch: 5| Step: 8
Training loss: 2.037305754781141
Validation loss: 2.5285188241654817

Epoch: 5| Step: 9
Training loss: 2.338599280063261
Validation loss: 2.5389278043574297

Epoch: 5| Step: 10
Training loss: 2.4150426165056746
Validation loss: 2.538507629800826

Epoch: 5| Step: 11
Training loss: 2.5047118606382206
Validation loss: 2.511163087470331

Epoch: 69| Step: 0
Training loss: 2.626984618044263
Validation loss: 2.546807902569775

Epoch: 5| Step: 1
Training loss: 2.2594719830350543
Validation loss: 2.53508333670492

Epoch: 5| Step: 2
Training loss: 2.4634430255994872
Validation loss: 2.5288680273951747

Epoch: 5| Step: 3
Training loss: 2.595803240932796
Validation loss: 2.551184427159117

Epoch: 5| Step: 4
Training loss: 2.3306049221459872
Validation loss: 2.5277738956857108

Epoch: 5| Step: 5
Training loss: 2.3221468369731917
Validation loss: 2.5595388166752286

Epoch: 5| Step: 6
Training loss: 2.175299709322469
Validation loss: 2.531843292501087

Epoch: 5| Step: 7
Training loss: 2.0937106000694703
Validation loss: 2.5216796113892395

Epoch: 5| Step: 8
Training loss: 2.7268042689472014
Validation loss: 2.548906713372768

Epoch: 5| Step: 9
Training loss: 1.962675077076096
Validation loss: 2.5443119031441004

Epoch: 5| Step: 10
Training loss: 2.3956992954961853
Validation loss: 2.5301258824937447

Epoch: 5| Step: 11
Training loss: 2.4840107776758176
Validation loss: 2.5359411273678862

Epoch: 70| Step: 0
Training loss: 2.5080321028630594
Validation loss: 2.5408317505254057

Epoch: 5| Step: 1
Training loss: 2.29686835670808
Validation loss: 2.5288733757458446

Epoch: 5| Step: 2
Training loss: 1.9665528404572055
Validation loss: 2.54844878822008

Epoch: 5| Step: 3
Training loss: 2.481715380171532
Validation loss: 2.5348277297916044

Epoch: 5| Step: 4
Training loss: 2.0770546587536978
Validation loss: 2.521255352750287

Epoch: 5| Step: 5
Training loss: 2.5543233162747705
Validation loss: 2.524215113893907

Epoch: 5| Step: 6
Training loss: 2.4891670123690592
Validation loss: 2.515065527833958

Epoch: 5| Step: 7
Training loss: 2.2958896106207924
Validation loss: 2.4916154729140807

Epoch: 5| Step: 8
Training loss: 2.0610723467275047
Validation loss: 2.5047310369859956

Epoch: 5| Step: 9
Training loss: 2.2255376230563715
Validation loss: 2.5355471606957933

Epoch: 5| Step: 10
Training loss: 2.940839451947166
Validation loss: 2.523373416996323

Epoch: 5| Step: 11
Training loss: 2.9327661233201394
Validation loss: 2.5114048771104978

Epoch: 71| Step: 0
Training loss: 2.157839203268085
Validation loss: 2.505455680315872

Epoch: 5| Step: 1
Training loss: 2.8102367195526208
Validation loss: 2.519764241330439

Epoch: 5| Step: 2
Training loss: 1.5038379207793229
Validation loss: 2.491286442737815

Epoch: 5| Step: 3
Training loss: 2.2897670039288918
Validation loss: 2.519455704061613

Epoch: 5| Step: 4
Training loss: 2.037671195485038
Validation loss: 2.5004436178799136

Epoch: 5| Step: 5
Training loss: 2.7266683913165592
Validation loss: 2.517167299782738

Epoch: 5| Step: 6
Training loss: 2.3371874676829494
Validation loss: 2.5215873549490744

Epoch: 5| Step: 7
Training loss: 2.369493928307866
Validation loss: 2.5220709171952724

Epoch: 5| Step: 8
Training loss: 2.3064591144979323
Validation loss: 2.508119724742476

Epoch: 5| Step: 9
Training loss: 3.1094728387363135
Validation loss: 2.530209009372772

Epoch: 5| Step: 10
Training loss: 2.3374244269735747
Validation loss: 2.537981532905695

Epoch: 5| Step: 11
Training loss: 0.5956698298920868
Validation loss: 2.514394131242447

Epoch: 72| Step: 0
Training loss: 2.3424266894094186
Validation loss: 2.5154769332622786

Epoch: 5| Step: 1
Training loss: 1.6826598371789319
Validation loss: 2.5128534244784517

Epoch: 5| Step: 2
Training loss: 2.117271843951018
Validation loss: 2.511647040973485

Epoch: 5| Step: 3
Training loss: 3.216805472533289
Validation loss: 2.507041341195264

Epoch: 5| Step: 4
Training loss: 2.911220770591277
Validation loss: 2.51716176672422

Epoch: 5| Step: 5
Training loss: 2.065212200428879
Validation loss: 2.4990821584023983

Epoch: 5| Step: 6
Training loss: 2.0752141543262272
Validation loss: 2.5101559821519612

Epoch: 5| Step: 7
Training loss: 2.4892700721795005
Validation loss: 2.478447711035165

Epoch: 5| Step: 8
Training loss: 2.598565285316731
Validation loss: 2.514854032636282

Epoch: 5| Step: 9
Training loss: 2.109520462106876
Validation loss: 2.4874400459105974

Epoch: 5| Step: 10
Training loss: 2.2723090133734676
Validation loss: 2.5003418370827695

Epoch: 5| Step: 11
Training loss: 1.9558322301969058
Validation loss: 2.4963174300843707

Epoch: 73| Step: 0
Training loss: 2.031723671484513
Validation loss: 2.4963182637905095

Epoch: 5| Step: 1
Training loss: 2.5391013744019255
Validation loss: 2.5026578483950357

Epoch: 5| Step: 2
Training loss: 2.8211847789765394
Validation loss: 2.5248748968626002

Epoch: 5| Step: 3
Training loss: 2.1574679266003196
Validation loss: 2.527605297738957

Epoch: 5| Step: 4
Training loss: 2.6208246721166026
Validation loss: 2.5314981904035623

Epoch: 5| Step: 5
Training loss: 1.8988577922990326
Validation loss: 2.543204976803429

Epoch: 5| Step: 6
Training loss: 2.2515018537032128
Validation loss: 2.538858133552224

Epoch: 5| Step: 7
Training loss: 2.826498333069252
Validation loss: 2.5516350190197326

Epoch: 5| Step: 8
Training loss: 2.0206157790073034
Validation loss: 2.559092496838296

Epoch: 5| Step: 9
Training loss: 2.594893697424586
Validation loss: 2.5571485674897847

Epoch: 5| Step: 10
Training loss: 2.2677306814732363
Validation loss: 2.543655880835645

Epoch: 5| Step: 11
Training loss: 1.5501238681151401
Validation loss: 2.5442509189999005

Epoch: 74| Step: 0
Training loss: 2.4586032999372636
Validation loss: 2.5219899051712793

Epoch: 5| Step: 1
Training loss: 2.401236922681745
Validation loss: 2.5370431117566197

Epoch: 5| Step: 2
Training loss: 2.250568106243907
Validation loss: 2.530190642540938

Epoch: 5| Step: 3
Training loss: 2.7854186973668993
Validation loss: 2.507532106056441

Epoch: 5| Step: 4
Training loss: 2.191407120376387
Validation loss: 2.5305749518954674

Epoch: 5| Step: 5
Training loss: 1.919531781604462
Validation loss: 2.5191187045227643

Epoch: 5| Step: 6
Training loss: 1.943805095222955
Validation loss: 2.5111339950351046

Epoch: 5| Step: 7
Training loss: 2.3317670560670862
Validation loss: 2.521487991720453

Epoch: 5| Step: 8
Training loss: 2.359211189697004
Validation loss: 2.5111679651872207

Epoch: 5| Step: 9
Training loss: 2.2256380002274945
Validation loss: 2.514417176707978

Epoch: 5| Step: 10
Training loss: 2.8599477725828937
Validation loss: 2.5198876338334024

Epoch: 5| Step: 11
Training loss: 2.097748539490976
Validation loss: 2.4995622211850685

Epoch: 75| Step: 0
Training loss: 2.105360378668261
Validation loss: 2.5087860927066767

Epoch: 5| Step: 1
Training loss: 2.6989839620096037
Validation loss: 2.4725375636634843

Epoch: 5| Step: 2
Training loss: 2.18036654706761
Validation loss: 2.502231956586608

Epoch: 5| Step: 3
Training loss: 2.284742008060428
Validation loss: 2.4889219408404606

Epoch: 5| Step: 4
Training loss: 1.8099433362110537
Validation loss: 2.504665033640679

Epoch: 5| Step: 5
Training loss: 2.2718174986141113
Validation loss: 2.501520374045854

Epoch: 5| Step: 6
Training loss: 2.840697945811194
Validation loss: 2.5000219940171746

Epoch: 5| Step: 7
Training loss: 2.199584063311677
Validation loss: 2.517286016871523

Epoch: 5| Step: 8
Training loss: 2.108029989300678
Validation loss: 2.5153376057738757

Epoch: 5| Step: 9
Training loss: 2.715015696836728
Validation loss: 2.51761112433194

Epoch: 5| Step: 10
Training loss: 2.7451161452772834
Validation loss: 2.530502220655581

Epoch: 5| Step: 11
Training loss: 2.0359976817419496
Validation loss: 2.504427509929923

Epoch: 76| Step: 0
Training loss: 2.391124398920575
Validation loss: 2.4934063385430094

Epoch: 5| Step: 1
Training loss: 2.1154513401898853
Validation loss: 2.5096666289322895

Epoch: 5| Step: 2
Training loss: 2.169646622499207
Validation loss: 2.501447737247657

Epoch: 5| Step: 3
Training loss: 2.172652290721963
Validation loss: 2.5185377227144783

Epoch: 5| Step: 4
Training loss: 2.0576237921479787
Validation loss: 2.5054835817972343

Epoch: 5| Step: 5
Training loss: 2.6946097079672753
Validation loss: 2.5238236170286994

Epoch: 5| Step: 6
Training loss: 3.010931443988785
Validation loss: 2.5023052633825147

Epoch: 5| Step: 7
Training loss: 2.0766460921409777
Validation loss: 2.5184371741358116

Epoch: 5| Step: 8
Training loss: 2.5711842829605502
Validation loss: 2.4960716238618206

Epoch: 5| Step: 9
Training loss: 2.076899920304583
Validation loss: 2.489908844857256

Epoch: 5| Step: 10
Training loss: 2.3829513759478678
Validation loss: 2.5044653749799517

Epoch: 5| Step: 11
Training loss: 2.1328132825018598
Validation loss: 2.5157588386078378

Epoch: 77| Step: 0
Training loss: 1.797008741626058
Validation loss: 2.510413606465059

Epoch: 5| Step: 1
Training loss: 2.1836883033111816
Validation loss: 2.5058325798047068

Epoch: 5| Step: 2
Training loss: 2.9924829401917843
Validation loss: 2.5006477629383417

Epoch: 5| Step: 3
Training loss: 2.3431707047761567
Validation loss: 2.4970331468975373

Epoch: 5| Step: 4
Training loss: 2.210495544042542
Validation loss: 2.498106513605154

Epoch: 5| Step: 5
Training loss: 2.220275998872535
Validation loss: 2.5221678863520256

Epoch: 5| Step: 6
Training loss: 2.484739840607159
Validation loss: 2.4967991961835407

Epoch: 5| Step: 7
Training loss: 2.013025426098584
Validation loss: 2.492711021181712

Epoch: 5| Step: 8
Training loss: 2.621817157821157
Validation loss: 2.497679622995398

Epoch: 5| Step: 9
Training loss: 2.503667144547137
Validation loss: 2.515581853271471

Epoch: 5| Step: 10
Training loss: 2.592439435290046
Validation loss: 2.517893800755269

Epoch: 5| Step: 11
Training loss: 1.355229205421127
Validation loss: 2.519256281079549

Epoch: 78| Step: 0
Training loss: 2.8027512181005227
Validation loss: 2.511917875632227

Epoch: 5| Step: 1
Training loss: 2.070760426558722
Validation loss: 2.493143191401514

Epoch: 5| Step: 2
Training loss: 2.478779471371766
Validation loss: 2.4805337912374936

Epoch: 5| Step: 3
Training loss: 2.1497655474556057
Validation loss: 2.5123380191267155

Epoch: 5| Step: 4
Training loss: 2.2962439052810315
Validation loss: 2.5094691397053976

Epoch: 5| Step: 5
Training loss: 2.524000453453205
Validation loss: 2.4838691192377396

Epoch: 5| Step: 6
Training loss: 2.4748734451459384
Validation loss: 2.5272127772988875

Epoch: 5| Step: 7
Training loss: 1.962098830215823
Validation loss: 2.5004629620402024

Epoch: 5| Step: 8
Training loss: 2.5220045621317926
Validation loss: 2.4906046274230262

Epoch: 5| Step: 9
Training loss: 1.9335216161971176
Validation loss: 2.516165973317148

Epoch: 5| Step: 10
Training loss: 2.4511596193045206
Validation loss: 2.5200434674192618

Epoch: 5| Step: 11
Training loss: 3.182934052623398
Validation loss: 2.504886528542819

Epoch: 79| Step: 0
Training loss: 2.2815241191725253
Validation loss: 2.5070986261504196

Epoch: 5| Step: 1
Training loss: 2.3601155918714296
Validation loss: 2.5149492892441967

Epoch: 5| Step: 2
Training loss: 2.504023366203609
Validation loss: 2.489718335107839

Epoch: 5| Step: 3
Training loss: 1.9620714898223526
Validation loss: 2.503674871870024

Epoch: 5| Step: 4
Training loss: 2.2028288946625327
Validation loss: 2.5037290537201287

Epoch: 5| Step: 5
Training loss: 2.2152159578260378
Validation loss: 2.4968101536013263

Epoch: 5| Step: 6
Training loss: 2.2424747934275016
Validation loss: 2.511692926996912

Epoch: 5| Step: 7
Training loss: 2.3157793454354856
Validation loss: 2.5171749679029305

Epoch: 5| Step: 8
Training loss: 2.8170526744127913
Validation loss: 2.536097378802113

Epoch: 5| Step: 9
Training loss: 2.884815543639696
Validation loss: 2.533304334514266

Epoch: 5| Step: 10
Training loss: 2.1510882307159003
Validation loss: 2.5099400441163424

Epoch: 5| Step: 11
Training loss: 1.481577676833329
Validation loss: 2.5143731598037786

Epoch: 80| Step: 0
Training loss: 2.508892361603143
Validation loss: 2.5213453085578994

Epoch: 5| Step: 1
Training loss: 2.07997794469731
Validation loss: 2.5222145872962143

Epoch: 5| Step: 2
Training loss: 1.867824685138528
Validation loss: 2.5250555112609887

Epoch: 5| Step: 3
Training loss: 2.1873781442761855
Validation loss: 2.5466223671398867

Epoch: 5| Step: 4
Training loss: 2.2514709326968467
Validation loss: 2.5512743128194826

Epoch: 5| Step: 5
Training loss: 2.374490281670532
Validation loss: 2.548059578072026

Epoch: 5| Step: 6
Training loss: 2.3103417299831985
Validation loss: 2.5463539050710637

Epoch: 5| Step: 7
Training loss: 3.0364100003635244
Validation loss: 2.5341614905692014

Epoch: 5| Step: 8
Training loss: 1.7761038343301514
Validation loss: 2.4899270400340168

Epoch: 5| Step: 9
Training loss: 3.02500255994452
Validation loss: 2.5089429345614316

Epoch: 5| Step: 10
Training loss: 2.335084587215089
Validation loss: 2.5082682851951663

Epoch: 5| Step: 11
Training loss: 1.1742074769190234
Validation loss: 2.502312822217289

Epoch: 81| Step: 0
Training loss: 2.615201555292572
Validation loss: 2.495417491859414

Epoch: 5| Step: 1
Training loss: 2.6036403480182537
Validation loss: 2.49414487085103

Epoch: 5| Step: 2
Training loss: 2.613767752530102
Validation loss: 2.503340880966322

Epoch: 5| Step: 3
Training loss: 2.5373579201595384
Validation loss: 2.5079859022994553

Epoch: 5| Step: 4
Training loss: 2.4100571276593308
Validation loss: 2.509857524371806

Epoch: 5| Step: 5
Training loss: 1.4265467430823902
Validation loss: 2.491716083198183

Epoch: 5| Step: 6
Training loss: 2.5635780299859054
Validation loss: 2.4991334525972366

Epoch: 5| Step: 7
Training loss: 2.3418123500843984
Validation loss: 2.4965497129275747

Epoch: 5| Step: 8
Training loss: 2.1131248768826447
Validation loss: 2.5075121627441646

Epoch: 5| Step: 9
Training loss: 2.0590350783677716
Validation loss: 2.4920633936865992

Epoch: 5| Step: 10
Training loss: 2.2646690719736955
Validation loss: 2.5064318729661488

Epoch: 5| Step: 11
Training loss: 2.8041116022274473
Validation loss: 2.499829036112125

Epoch: 82| Step: 0
Training loss: 2.5023513226925984
Validation loss: 2.516883349774624

Epoch: 5| Step: 1
Training loss: 2.2791730230918086
Validation loss: 2.5173420584531314

Epoch: 5| Step: 2
Training loss: 1.7358318773990897
Validation loss: 2.4994868824807845

Epoch: 5| Step: 3
Training loss: 2.59849904091285
Validation loss: 2.519170123102221

Epoch: 5| Step: 4
Training loss: 1.6897724533384013
Validation loss: 2.513879668117588

Epoch: 5| Step: 5
Training loss: 2.661158615127201
Validation loss: 2.4973799466664364

Epoch: 5| Step: 6
Training loss: 1.4567577933840632
Validation loss: 2.51975160172397

Epoch: 5| Step: 7
Training loss: 2.292545623990902
Validation loss: 2.5085670706582524

Epoch: 5| Step: 8
Training loss: 2.55558747004424
Validation loss: 2.4975081621723367

Epoch: 5| Step: 9
Training loss: 2.5216900234145023
Validation loss: 2.5186201276655527

Epoch: 5| Step: 10
Training loss: 3.0971326734277893
Validation loss: 2.5219393929537137

Epoch: 5| Step: 11
Training loss: 2.4277917267461455
Validation loss: 2.5315399082395245

Epoch: 83| Step: 0
Training loss: 1.8668752752405404
Validation loss: 2.5241706657021163

Epoch: 5| Step: 1
Training loss: 2.082867252348493
Validation loss: 2.5392764739817

Epoch: 5| Step: 2
Training loss: 2.3782055955180206
Validation loss: 2.5492434809961377

Epoch: 5| Step: 3
Training loss: 2.4317446521736703
Validation loss: 2.5480320024521723

Epoch: 5| Step: 4
Training loss: 2.383129761633829
Validation loss: 2.556255625350968

Epoch: 5| Step: 5
Training loss: 2.5873973217922814
Validation loss: 2.5660005981420335

Epoch: 5| Step: 6
Training loss: 2.7108879854369086
Validation loss: 2.5604555378987737

Epoch: 5| Step: 7
Training loss: 2.646836508659074
Validation loss: 2.566079926513846

Epoch: 5| Step: 8
Training loss: 2.1509283988878694
Validation loss: 2.554929855936578

Epoch: 5| Step: 9
Training loss: 2.88218256159449
Validation loss: 2.53281359789207

Epoch: 5| Step: 10
Training loss: 1.573863933702171
Validation loss: 2.5128505919248534

Epoch: 5| Step: 11
Training loss: 1.6567338920375472
Validation loss: 2.517196456669083

Epoch: 84| Step: 0
Training loss: 2.9802717991221988
Validation loss: 2.5033735362222433

Epoch: 5| Step: 1
Training loss: 2.480409540385843
Validation loss: 2.5014307259412143

Epoch: 5| Step: 2
Training loss: 1.9545498952754667
Validation loss: 2.4922247059754383

Epoch: 5| Step: 3
Training loss: 2.5371873709984842
Validation loss: 2.484799290859611

Epoch: 5| Step: 4
Training loss: 1.633944616305973
Validation loss: 2.504747984233806

Epoch: 5| Step: 5
Training loss: 2.568261067064611
Validation loss: 2.494800250384404

Epoch: 5| Step: 6
Training loss: 2.251547281397811
Validation loss: 2.496951608990476

Epoch: 5| Step: 7
Training loss: 2.1989020598954494
Validation loss: 2.492569454664064

Epoch: 5| Step: 8
Training loss: 2.1055967047882964
Validation loss: 2.5026262555584844

Epoch: 5| Step: 9
Training loss: 2.8154769401276623
Validation loss: 2.500582372862543

Epoch: 5| Step: 10
Training loss: 2.072134231299211
Validation loss: 2.4972690925353294

Epoch: 5| Step: 11
Training loss: 2.299663071210404
Validation loss: 2.4934768769394484

Epoch: 85| Step: 0
Training loss: 2.3103351254144133
Validation loss: 2.4924012494078527

Epoch: 5| Step: 1
Training loss: 2.5088953075133484
Validation loss: 2.5173925149354606

Epoch: 5| Step: 2
Training loss: 2.4618597331061536
Validation loss: 2.5368059861346723

Epoch: 5| Step: 3
Training loss: 2.2028895042577035
Validation loss: 2.551871747698344

Epoch: 5| Step: 4
Training loss: 2.150309686757329
Validation loss: 2.5722635665495255

Epoch: 5| Step: 5
Training loss: 2.6503530231189507
Validation loss: 2.5897971715329806

Epoch: 5| Step: 6
Training loss: 2.7786626889767185
Validation loss: 2.6184834853748935

Epoch: 5| Step: 7
Training loss: 2.3630760419042334
Validation loss: 2.590643345530504

Epoch: 5| Step: 8
Training loss: 2.650933453962518
Validation loss: 2.583272392312985

Epoch: 5| Step: 9
Training loss: 2.153824257215346
Validation loss: 2.571777181514911

Epoch: 5| Step: 10
Training loss: 1.674549993161132
Validation loss: 2.559517761024772

Epoch: 5| Step: 11
Training loss: 1.8786120908150112
Validation loss: 2.5345692907790234

Epoch: 86| Step: 0
Training loss: 1.9652282459980084
Validation loss: 2.5286536853378965

Epoch: 5| Step: 1
Training loss: 2.3389210099496074
Validation loss: 2.5069665759604653

Epoch: 5| Step: 2
Training loss: 2.7375291343775983
Validation loss: 2.505510142830653

Epoch: 5| Step: 3
Training loss: 2.248255265136309
Validation loss: 2.50280331160993

Epoch: 5| Step: 4
Training loss: 1.662483576643283
Validation loss: 2.502291352526068

Epoch: 5| Step: 5
Training loss: 2.6456483991576305
Validation loss: 2.49377688884978

Epoch: 5| Step: 6
Training loss: 2.484322121495284
Validation loss: 2.4945683681340105

Epoch: 5| Step: 7
Training loss: 1.9166990844085905
Validation loss: 2.497128514424759

Epoch: 5| Step: 8
Training loss: 2.1783134477442716
Validation loss: 2.4913324505639634

Epoch: 5| Step: 9
Training loss: 1.9596807092309598
Validation loss: 2.476519747745125

Epoch: 5| Step: 10
Training loss: 3.1063885172425154
Validation loss: 2.5028259676566456

Epoch: 5| Step: 11
Training loss: 1.8592394611100473
Validation loss: 2.5009355900417276

Epoch: 87| Step: 0
Training loss: 2.0773016653858662
Validation loss: 2.49272239310198

Epoch: 5| Step: 1
Training loss: 1.8597932873988006
Validation loss: 2.480261714435079

Epoch: 5| Step: 2
Training loss: 2.054544190025094
Validation loss: 2.5034945621160953

Epoch: 5| Step: 3
Training loss: 2.8545269332686893
Validation loss: 2.4938555350157223

Epoch: 5| Step: 4
Training loss: 2.376685397790802
Validation loss: 2.495528696942165

Epoch: 5| Step: 5
Training loss: 2.705342964951748
Validation loss: 2.4936537261136413

Epoch: 5| Step: 6
Training loss: 2.136539988737426
Validation loss: 2.4787097731619023

Epoch: 5| Step: 7
Training loss: 2.2383632678172187
Validation loss: 2.5005617861554876

Epoch: 5| Step: 8
Training loss: 2.2034855540792937
Validation loss: 2.5095976420786354

Epoch: 5| Step: 9
Training loss: 2.9034820829784294
Validation loss: 2.502869342220869

Epoch: 5| Step: 10
Training loss: 1.8203345039576733
Validation loss: 2.511117777260533

Epoch: 5| Step: 11
Training loss: 3.0281957596423354
Validation loss: 2.5072835996334533

Epoch: 88| Step: 0
Training loss: 2.6191763082487225
Validation loss: 2.5124846378887944

Epoch: 5| Step: 1
Training loss: 2.500203601175865
Validation loss: 2.515542066482562

Epoch: 5| Step: 2
Training loss: 2.5024062973909094
Validation loss: 2.5124584827187606

Epoch: 5| Step: 3
Training loss: 2.1919825810902838
Validation loss: 2.5100736436450943

Epoch: 5| Step: 4
Training loss: 1.9332353356068022
Validation loss: 2.505466453171349

Epoch: 5| Step: 5
Training loss: 2.8689489956321244
Validation loss: 2.507567028260344

Epoch: 5| Step: 6
Training loss: 2.5990651834319722
Validation loss: 2.4977065454278775

Epoch: 5| Step: 7
Training loss: 2.0796464212374475
Validation loss: 2.5026588248728876

Epoch: 5| Step: 8
Training loss: 2.006359717675628
Validation loss: 2.51072400666515

Epoch: 5| Step: 9
Training loss: 1.9922152648187779
Validation loss: 2.50543132722711

Epoch: 5| Step: 10
Training loss: 2.3242017216419275
Validation loss: 2.4855674345125496

Epoch: 5| Step: 11
Training loss: 2.1892980542765264
Validation loss: 2.5161824289981123

Epoch: 89| Step: 0
Training loss: 2.197436408293458
Validation loss: 2.5149217021324644

Epoch: 5| Step: 1
Training loss: 2.0432392473739527
Validation loss: 2.5052406060459176

Epoch: 5| Step: 2
Training loss: 1.8053306985696886
Validation loss: 2.4935522299019124

Epoch: 5| Step: 3
Training loss: 2.957235069758997
Validation loss: 2.532978303766685

Epoch: 5| Step: 4
Training loss: 2.1519321941272542
Validation loss: 2.5182950123985646

Epoch: 5| Step: 5
Training loss: 2.517451411122137
Validation loss: 2.5212211796555906

Epoch: 5| Step: 6
Training loss: 2.7038514147965156
Validation loss: 2.5439559223639616

Epoch: 5| Step: 7
Training loss: 2.3476906772317117
Validation loss: 2.5267591650359327

Epoch: 5| Step: 8
Training loss: 2.2018975700718086
Validation loss: 2.5191722229643823

Epoch: 5| Step: 9
Training loss: 2.465284595271133
Validation loss: 2.5272760043137015

Epoch: 5| Step: 10
Training loss: 2.0135770344345643
Validation loss: 2.526197036736614

Epoch: 5| Step: 11
Training loss: 1.4446593587297674
Validation loss: 2.5154465341545644

Epoch: 90| Step: 0
Training loss: 2.1791059477049854
Validation loss: 2.4944112178359084

Epoch: 5| Step: 1
Training loss: 2.2748878283671115
Validation loss: 2.520924016146374

Epoch: 5| Step: 2
Training loss: 2.290999598662509
Validation loss: 2.5224366619474474

Epoch: 5| Step: 3
Training loss: 2.454532875324216
Validation loss: 2.5198823965064276

Epoch: 5| Step: 4
Training loss: 1.8335067565851733
Validation loss: 2.5219253087530724

Epoch: 5| Step: 5
Training loss: 2.323165116188252
Validation loss: 2.5279989950672497

Epoch: 5| Step: 6
Training loss: 1.9490752692918225
Validation loss: 2.502443585650728

Epoch: 5| Step: 7
Training loss: 2.721247961475483
Validation loss: 2.500055850915111

Epoch: 5| Step: 8
Training loss: 1.9492971523013034
Validation loss: 2.508714416668441

Epoch: 5| Step: 9
Training loss: 2.5023516085260424
Validation loss: 2.4931678597620195

Epoch: 5| Step: 10
Training loss: 2.7780427763950053
Validation loss: 2.4995081238852133

Epoch: 5| Step: 11
Training loss: 1.596569932437605
Validation loss: 2.500128961256878

Epoch: 91| Step: 0
Training loss: 2.5149906851442423
Validation loss: 2.5186519951602153

Epoch: 5| Step: 1
Training loss: 2.3411626139807797
Validation loss: 2.4819901373810973

Epoch: 5| Step: 2
Training loss: 2.3675223639297003
Validation loss: 2.5053034240271495

Epoch: 5| Step: 3
Training loss: 1.818860829964876
Validation loss: 2.5043845590209552

Epoch: 5| Step: 4
Training loss: 2.552266131231727
Validation loss: 2.511077265003795

Epoch: 5| Step: 5
Training loss: 2.4022508556734836
Validation loss: 2.5016436260093364

Epoch: 5| Step: 6
Training loss: 2.270950477681651
Validation loss: 2.4971954031911388

Epoch: 5| Step: 7
Training loss: 2.427749400502829
Validation loss: 2.524336970496881

Epoch: 5| Step: 8
Training loss: 2.5808352010110664
Validation loss: 2.5254796979379295

Epoch: 5| Step: 9
Training loss: 1.9199460902195575
Validation loss: 2.516661045613443

Epoch: 5| Step: 10
Training loss: 2.024382734999405
Validation loss: 2.5183037066678797

Epoch: 5| Step: 11
Training loss: 2.5593929527687087
Validation loss: 2.510613931658867

Epoch: 92| Step: 0
Training loss: 1.8789120235869907
Validation loss: 2.5456412824083

Epoch: 5| Step: 1
Training loss: 2.346548825289031
Validation loss: 2.5115572223368186

Epoch: 5| Step: 2
Training loss: 1.9894456133353304
Validation loss: 2.53984243689583

Epoch: 5| Step: 3
Training loss: 2.586497542941484
Validation loss: 2.52594394429269

Epoch: 5| Step: 4
Training loss: 2.364823070142071
Validation loss: 2.5143799040289267

Epoch: 5| Step: 5
Training loss: 2.2511466601268766
Validation loss: 2.523555388713413

Epoch: 5| Step: 6
Training loss: 2.859191388347873
Validation loss: 2.5118493045714825

Epoch: 5| Step: 7
Training loss: 1.9127531594661795
Validation loss: 2.5091297021848167

Epoch: 5| Step: 8
Training loss: 2.540307218189734
Validation loss: 2.518489545413825

Epoch: 5| Step: 9
Training loss: 2.0131785605268453
Validation loss: 2.5005589456374455

Epoch: 5| Step: 10
Training loss: 2.555934963073479
Validation loss: 2.4999076746740925

Epoch: 5| Step: 11
Training loss: 2.138302733731874
Validation loss: 2.490285213175922

Epoch: 93| Step: 0
Training loss: 2.3563647740588243
Validation loss: 2.5144456543376115

Epoch: 5| Step: 1
Training loss: 2.322714849580322
Validation loss: 2.519300405883302

Epoch: 5| Step: 2
Training loss: 2.067434015662568
Validation loss: 2.555294750186653

Epoch: 5| Step: 3
Training loss: 2.204835268471591
Validation loss: 2.5236345889321403

Epoch: 5| Step: 4
Training loss: 2.3922156732795083
Validation loss: 2.516848919965984

Epoch: 5| Step: 5
Training loss: 2.3194004925226595
Validation loss: 2.5241741880550603

Epoch: 5| Step: 6
Training loss: 1.7152772672637853
Validation loss: 2.5334414328602683

Epoch: 5| Step: 7
Training loss: 2.4283738095958083
Validation loss: 2.543137845044194

Epoch: 5| Step: 8
Training loss: 2.645992624689205
Validation loss: 2.5360714651979173

Epoch: 5| Step: 9
Training loss: 2.5966915318282426
Validation loss: 2.542281413908045

Epoch: 5| Step: 10
Training loss: 2.1501402609561704
Validation loss: 2.550624852353794

Epoch: 5| Step: 11
Training loss: 2.49505937662357
Validation loss: 2.5257520109766025

Epoch: 94| Step: 0
Training loss: 2.5129172400961615
Validation loss: 2.5188312435378326

Epoch: 5| Step: 1
Training loss: 1.9738420906833574
Validation loss: 2.5137881212838997

Epoch: 5| Step: 2
Training loss: 2.6234266016212913
Validation loss: 2.496387454460338

Epoch: 5| Step: 3
Training loss: 1.9957528915068945
Validation loss: 2.503374760438829

Epoch: 5| Step: 4
Training loss: 1.8021720761478686
Validation loss: 2.4976277619917715

Epoch: 5| Step: 5
Training loss: 2.0490012736653975
Validation loss: 2.4965555582695287

Epoch: 5| Step: 6
Training loss: 2.1492769578035342
Validation loss: 2.497024179648362

Epoch: 5| Step: 7
Training loss: 1.995603198784493
Validation loss: 2.4952694442687533

Epoch: 5| Step: 8
Training loss: 2.712341648524897
Validation loss: 2.4861825009851657

Epoch: 5| Step: 9
Training loss: 2.7985601197028642
Validation loss: 2.5201194214655134

Epoch: 5| Step: 10
Training loss: 2.2376865841945945
Validation loss: 2.506010166466751

Epoch: 5| Step: 11
Training loss: 2.913739306652424
Validation loss: 2.499086582687443

Epoch: 95| Step: 0
Training loss: 2.2452778536805353
Validation loss: 2.5045466524034845

Epoch: 5| Step: 1
Training loss: 2.265645415115457
Validation loss: 2.493390652891018

Epoch: 5| Step: 2
Training loss: 2.2405906600129586
Validation loss: 2.498760619510681

Epoch: 5| Step: 3
Training loss: 2.102922984789518
Validation loss: 2.4808082968930982

Epoch: 5| Step: 4
Training loss: 2.513777060038233
Validation loss: 2.4896069423136025

Epoch: 5| Step: 5
Training loss: 2.1667988687921804
Validation loss: 2.494451935054074

Epoch: 5| Step: 6
Training loss: 2.409733913025605
Validation loss: 2.5161288213000117

Epoch: 5| Step: 7
Training loss: 2.179192380832455
Validation loss: 2.4853330000688194

Epoch: 5| Step: 8
Training loss: 2.161311745939203
Validation loss: 2.515280887611901

Epoch: 5| Step: 9
Training loss: 2.969101092006748
Validation loss: 2.50063338203554

Epoch: 5| Step: 10
Training loss: 2.021872014274928
Validation loss: 2.493359675729367

Epoch: 5| Step: 11
Training loss: 1.7197996229068198
Validation loss: 2.4923489836191703

Epoch: 96| Step: 0
Training loss: 2.3614559470289302
Validation loss: 2.497191604097231

Epoch: 5| Step: 1
Training loss: 2.017359970130386
Validation loss: 2.505864435489626

Epoch: 5| Step: 2
Training loss: 1.9855641083810944
Validation loss: 2.49075653984426

Epoch: 5| Step: 3
Training loss: 2.3770467070539167
Validation loss: 2.5185737347828625

Epoch: 5| Step: 4
Training loss: 2.180838551012774
Validation loss: 2.5307039331179264

Epoch: 5| Step: 5
Training loss: 2.4444785356552625
Validation loss: 2.526807084411214

Epoch: 5| Step: 6
Training loss: 1.9473139872614613
Validation loss: 2.531712631051506

Epoch: 5| Step: 7
Training loss: 2.160922309562819
Validation loss: 2.529002278771008

Epoch: 5| Step: 8
Training loss: 2.9397186666292106
Validation loss: 2.5330674530458763

Epoch: 5| Step: 9
Training loss: 2.342999249062965
Validation loss: 2.534907151941493

Epoch: 5| Step: 10
Training loss: 2.359067176797031
Validation loss: 2.5456340024729465

Epoch: 5| Step: 11
Training loss: 1.9628681542168396
Validation loss: 2.5302684591998417

Epoch: 97| Step: 0
Training loss: 1.9552155559760696
Validation loss: 2.524887447870209

Epoch: 5| Step: 1
Training loss: 2.2193356667816984
Validation loss: 2.5307774043714897

Epoch: 5| Step: 2
Training loss: 2.1715335714796096
Validation loss: 2.547948751354142

Epoch: 5| Step: 3
Training loss: 2.62522206048399
Validation loss: 2.567147022716842

Epoch: 5| Step: 4
Training loss: 2.23724959266924
Validation loss: 2.5621862296932436

Epoch: 5| Step: 5
Training loss: 2.1801374511083234
Validation loss: 2.5349418067460077

Epoch: 5| Step: 6
Training loss: 2.265229289257526
Validation loss: 2.544141726437711

Epoch: 5| Step: 7
Training loss: 2.2415457947014272
Validation loss: 2.551600038089185

Epoch: 5| Step: 8
Training loss: 2.0939826266743973
Validation loss: 2.5558647802856322

Epoch: 5| Step: 9
Training loss: 2.232205811838924
Validation loss: 2.554824627103705

Epoch: 5| Step: 10
Training loss: 2.711820079478566
Validation loss: 2.5167736724395

Epoch: 5| Step: 11
Training loss: 2.4932632277147473
Validation loss: 2.508590219155227

Epoch: 98| Step: 0
Training loss: 2.587663426052693
Validation loss: 2.5278270638613387

Epoch: 5| Step: 1
Training loss: 2.57419031616623
Validation loss: 2.499372550586042

Epoch: 5| Step: 2
Training loss: 1.8491466874012725
Validation loss: 2.501522611831766

Epoch: 5| Step: 3
Training loss: 2.767315019526574
Validation loss: 2.5082581144969853

Epoch: 5| Step: 4
Training loss: 1.9747389874429535
Validation loss: 2.489709784410136

Epoch: 5| Step: 5
Training loss: 2.2482570679183516
Validation loss: 2.4827182131693903

Epoch: 5| Step: 6
Training loss: 2.2502729462266418
Validation loss: 2.4938261390956096

Epoch: 5| Step: 7
Training loss: 2.0299826556437264
Validation loss: 2.50016496034614

Epoch: 5| Step: 8
Training loss: 2.1131140454157
Validation loss: 2.488920935025234

Epoch: 5| Step: 9
Training loss: 2.700896651120094
Validation loss: 2.509260058907943

Epoch: 5| Step: 10
Training loss: 2.015445080201238
Validation loss: 2.49745384337217

Epoch: 5| Step: 11
Training loss: 1.2348128399364562
Validation loss: 2.508749571880817

Epoch: 99| Step: 0
Training loss: 2.2495625388530405
Validation loss: 2.497010995267004

Epoch: 5| Step: 1
Training loss: 1.6139188157832502
Validation loss: 2.5239772042327204

Epoch: 5| Step: 2
Training loss: 2.450008477955377
Validation loss: 2.512595273420935

Epoch: 5| Step: 3
Training loss: 2.744914988884649
Validation loss: 2.535050788178766

Epoch: 5| Step: 4
Training loss: 2.329164618512267
Validation loss: 2.5587983571328197

Epoch: 5| Step: 5
Training loss: 1.7883007976751837
Validation loss: 2.563015296732124

Epoch: 5| Step: 6
Training loss: 2.0492344426998734
Validation loss: 2.5698413243087774

Epoch: 5| Step: 7
Training loss: 2.0084424644778043
Validation loss: 2.596647440506988

Epoch: 5| Step: 8
Training loss: 2.6132949349767802
Validation loss: 2.5505295785592104

Epoch: 5| Step: 9
Training loss: 2.7254554227977597
Validation loss: 2.5863188071583116

Epoch: 5| Step: 10
Training loss: 2.1189624061004
Validation loss: 2.5429404863153167

Epoch: 5| Step: 11
Training loss: 3.1793328164723413
Validation loss: 2.5509494027000224

Epoch: 100| Step: 0
Training loss: 2.1034872890820115
Validation loss: 2.5476508762740058

Epoch: 5| Step: 1
Training loss: 1.9872748145405255
Validation loss: 2.5134333151776516

Epoch: 5| Step: 2
Training loss: 2.380354116525996
Validation loss: 2.4850102658062942

Epoch: 5| Step: 3
Training loss: 2.607411085242189
Validation loss: 2.5098861685178444

Epoch: 5| Step: 4
Training loss: 1.920184997348367
Validation loss: 2.5178572226520797

Epoch: 5| Step: 5
Training loss: 2.2329679740662574
Validation loss: 2.515392103135812

Epoch: 5| Step: 6
Training loss: 2.435160369918515
Validation loss: 2.4881008288389554

Epoch: 5| Step: 7
Training loss: 2.2645176779439598
Validation loss: 2.491426178214613

Epoch: 5| Step: 8
Training loss: 2.4826300869113584
Validation loss: 2.5205192225721555

Epoch: 5| Step: 9
Training loss: 2.4341981483242434
Validation loss: 2.5126211701776655

Epoch: 5| Step: 10
Training loss: 2.0955406616605776
Validation loss: 2.498299330182435

Epoch: 5| Step: 11
Training loss: 2.5078366477492975
Validation loss: 2.5113879292947847

Epoch: 101| Step: 0
Training loss: 2.210439996719083
Validation loss: 2.4894046692736658

Epoch: 5| Step: 1
Training loss: 2.524459112418384
Validation loss: 2.5236426507251095

Epoch: 5| Step: 2
Training loss: 2.2361624443948984
Validation loss: 2.503657022610833

Epoch: 5| Step: 3
Training loss: 2.0462293698640526
Validation loss: 2.4962451154635286

Epoch: 5| Step: 4
Training loss: 2.658645088626045
Validation loss: 2.508206715799314

Epoch: 5| Step: 5
Training loss: 2.807159949180959
Validation loss: 2.529189750926351

Epoch: 5| Step: 6
Training loss: 1.9818875198666543
Validation loss: 2.5102021150725413

Epoch: 5| Step: 7
Training loss: 2.3468448804606443
Validation loss: 2.514155355461132

Epoch: 5| Step: 8
Training loss: 1.7920927014342918
Validation loss: 2.5276570624625525

Epoch: 5| Step: 9
Training loss: 2.3017965515010124
Validation loss: 2.5364435118464783

Epoch: 5| Step: 10
Training loss: 1.868217918150146
Validation loss: 2.553984102867566

Epoch: 5| Step: 11
Training loss: 2.2024929140910063
Validation loss: 2.5456832328496453

Epoch: 102| Step: 0
Training loss: 1.9265658809387787
Validation loss: 2.5231268724042906

Epoch: 5| Step: 1
Training loss: 2.416623630359719
Validation loss: 2.5347798934599988

Epoch: 5| Step: 2
Training loss: 2.3136188790188186
Validation loss: 2.5322250011168097

Epoch: 5| Step: 3
Training loss: 2.393869230722269
Validation loss: 2.5075902553173477

Epoch: 5| Step: 4
Training loss: 1.9884448031025028
Validation loss: 2.501253834857635

Epoch: 5| Step: 5
Training loss: 1.7551839206103352
Validation loss: 2.4934142948799467

Epoch: 5| Step: 6
Training loss: 3.033964062884643
Validation loss: 2.4823241696062017

Epoch: 5| Step: 7
Training loss: 2.2785935285105516
Validation loss: 2.5011380029438497

Epoch: 5| Step: 8
Training loss: 2.3640144660946008
Validation loss: 2.5199022951372165

Epoch: 5| Step: 9
Training loss: 2.0655423469570295
Validation loss: 2.498164452794883

Epoch: 5| Step: 10
Training loss: 2.2852928186020605
Validation loss: 2.4919133010585712

Epoch: 5| Step: 11
Training loss: 1.7761611525390422
Validation loss: 2.490059174003054

Epoch: 103| Step: 0
Training loss: 2.390111431732297
Validation loss: 2.5033775560948808

Epoch: 5| Step: 1
Training loss: 2.061322193813122
Validation loss: 2.5098421592274347

Epoch: 5| Step: 2
Training loss: 2.5583480134557304
Validation loss: 2.5197450098641245

Epoch: 5| Step: 3
Training loss: 2.552030902765132
Validation loss: 2.5355805334414505

Epoch: 5| Step: 4
Training loss: 1.7768774741441031
Validation loss: 2.5512042237703882

Epoch: 5| Step: 5
Training loss: 1.5789610659272868
Validation loss: 2.5495677435154604

Epoch: 5| Step: 6
Training loss: 2.2036022994927724
Validation loss: 2.5861650157466016

Epoch: 5| Step: 7
Training loss: 2.6150473883220866
Validation loss: 2.582221593107374

Epoch: 5| Step: 8
Training loss: 2.0116623361325474
Validation loss: 2.5751519949969124

Epoch: 5| Step: 9
Training loss: 2.754681330699363
Validation loss: 2.5552247092127494

Epoch: 5| Step: 10
Training loss: 2.3256402805547065
Validation loss: 2.5560695087038816

Epoch: 5| Step: 11
Training loss: 1.3239725159676539
Validation loss: 2.5310477069976605

Epoch: 104| Step: 0
Training loss: 2.30239391964765
Validation loss: 2.528378639810632

Epoch: 5| Step: 1
Training loss: 1.7264982876121497
Validation loss: 2.4939367798001952

Epoch: 5| Step: 2
Training loss: 1.901854591222519
Validation loss: 2.497247666997937

Epoch: 5| Step: 3
Training loss: 2.882634516651703
Validation loss: 2.498556367974082

Epoch: 5| Step: 4
Training loss: 2.3383770200092884
Validation loss: 2.5135127375097666

Epoch: 5| Step: 5
Training loss: 1.8164598026379801
Validation loss: 2.4996011415832715

Epoch: 5| Step: 6
Training loss: 1.8458951981326062
Validation loss: 2.499183457858655

Epoch: 5| Step: 7
Training loss: 2.203362634707327
Validation loss: 2.495653845001524

Epoch: 5| Step: 8
Training loss: 2.4050039062151045
Validation loss: 2.507350455211543

Epoch: 5| Step: 9
Training loss: 2.38783689987922
Validation loss: 2.505511697072582

Epoch: 5| Step: 10
Training loss: 2.7075499550956357
Validation loss: 2.499258430088844

Epoch: 5| Step: 11
Training loss: 2.1781199297852796
Validation loss: 2.4938812399790544

Epoch: 105| Step: 0
Training loss: 2.125700666813213
Validation loss: 2.503431540017705

Epoch: 5| Step: 1
Training loss: 2.200363267904231
Validation loss: 2.4990188858966684

Epoch: 5| Step: 2
Training loss: 2.24986542193285
Validation loss: 2.4925102216268025

Epoch: 5| Step: 3
Training loss: 2.451616637469137
Validation loss: 2.5110589599984467

Epoch: 5| Step: 4
Training loss: 2.105362190565009
Validation loss: 2.534317818406983

Epoch: 5| Step: 5
Training loss: 1.9225047870670637
Validation loss: 2.5395535077436917

Epoch: 5| Step: 6
Training loss: 2.5321531215246775
Validation loss: 2.5469336239673237

Epoch: 5| Step: 7
Training loss: 2.1993688935273394
Validation loss: 2.582017603235544

Epoch: 5| Step: 8
Training loss: 2.5780256772416155
Validation loss: 2.5425484422740645

Epoch: 5| Step: 9
Training loss: 1.9196801406940358
Validation loss: 2.527705226166755

Epoch: 5| Step: 10
Training loss: 2.128644062660949
Validation loss: 2.5226809151834644

Epoch: 5| Step: 11
Training loss: 3.7907970115837415
Validation loss: 2.525301576457083

Epoch: 106| Step: 0
Training loss: 1.9311306765337901
Validation loss: 2.4936544053439107

Epoch: 5| Step: 1
Training loss: 1.880517470992949
Validation loss: 2.485267494843339

Epoch: 5| Step: 2
Training loss: 2.553991100340582
Validation loss: 2.492524262797711

Epoch: 5| Step: 3
Training loss: 1.987269895656751
Validation loss: 2.505963028755819

Epoch: 5| Step: 4
Training loss: 2.445336192445876
Validation loss: 2.493828017305895

Epoch: 5| Step: 5
Training loss: 2.02652601975406
Validation loss: 2.493099739269965

Epoch: 5| Step: 6
Training loss: 2.0662803683671447
Validation loss: 2.489757912126396

Epoch: 5| Step: 7
Training loss: 2.452187814703997
Validation loss: 2.4932671842006786

Epoch: 5| Step: 8
Training loss: 1.890703057813661
Validation loss: 2.4966170270409203

Epoch: 5| Step: 9
Training loss: 2.3973774011668434
Validation loss: 2.498502087866584

Epoch: 5| Step: 10
Training loss: 2.8041155133581532
Validation loss: 2.505126588297999

Epoch: 5| Step: 11
Training loss: 2.5345557960905287
Validation loss: 2.5006281421224985

Epoch: 107| Step: 0
Training loss: 2.007249686477376
Validation loss: 2.5141414864640184

Epoch: 5| Step: 1
Training loss: 1.7848770958397717
Validation loss: 2.4824172589418967

Epoch: 5| Step: 2
Training loss: 2.7808686755796854
Validation loss: 2.5033406944543404

Epoch: 5| Step: 3
Training loss: 2.4232813535814866
Validation loss: 2.5063877832047

Epoch: 5| Step: 4
Training loss: 1.625741789310047
Validation loss: 2.476768440966

Epoch: 5| Step: 5
Training loss: 2.169161301893336
Validation loss: 2.51587414346932

Epoch: 5| Step: 6
Training loss: 2.052253238466774
Validation loss: 2.520561248240457

Epoch: 5| Step: 7
Training loss: 2.0206697011027286
Validation loss: 2.513650079458297

Epoch: 5| Step: 8
Training loss: 2.511791459569195
Validation loss: 2.5545222863797936

Epoch: 5| Step: 9
Training loss: 2.6358985812078997
Validation loss: 2.543710677540466

Epoch: 5| Step: 10
Training loss: 2.3369679299318133
Validation loss: 2.5530177189961294

Epoch: 5| Step: 11
Training loss: 2.7562491765096735
Validation loss: 2.527802961670015

Epoch: 108| Step: 0
Training loss: 2.68227668437045
Validation loss: 2.4943384636242465

Epoch: 5| Step: 1
Training loss: 2.066794461739342
Validation loss: 2.5030977051604455

Epoch: 5| Step: 2
Training loss: 2.4457291805656673
Validation loss: 2.4961316499335116

Epoch: 5| Step: 3
Training loss: 2.210836671073494
Validation loss: 2.497003997252359

Epoch: 5| Step: 4
Training loss: 2.135277633482822
Validation loss: 2.50483495159665

Epoch: 5| Step: 5
Training loss: 2.4759487992201823
Validation loss: 2.492109698094637

Epoch: 5| Step: 6
Training loss: 2.039477192887039
Validation loss: 2.5243874839303393

Epoch: 5| Step: 7
Training loss: 1.8829306411083901
Validation loss: 2.5215151169584926

Epoch: 5| Step: 8
Training loss: 2.3349443959185088
Validation loss: 2.537729557033054

Epoch: 5| Step: 9
Training loss: 2.194398411403447
Validation loss: 2.5476382931354573

Epoch: 5| Step: 10
Training loss: 2.019870633618994
Validation loss: 2.5239140087228766

Epoch: 5| Step: 11
Training loss: 3.3837424182842137
Validation loss: 2.51199485048358

Epoch: 109| Step: 0
Training loss: 2.1782542339499646
Validation loss: 2.4870622145016608

Epoch: 5| Step: 1
Training loss: 2.253974159844036
Validation loss: 2.5003276649958903

Epoch: 5| Step: 2
Training loss: 2.773579424598193
Validation loss: 2.5145267237370064

Epoch: 5| Step: 3
Training loss: 2.0055922764063756
Validation loss: 2.508978128145817

Epoch: 5| Step: 4
Training loss: 2.549643199866357
Validation loss: 2.495608553744251

Epoch: 5| Step: 5
Training loss: 1.598560180132614
Validation loss: 2.5216315374513885

Epoch: 5| Step: 6
Training loss: 2.150108325802006
Validation loss: 2.506369768960864

Epoch: 5| Step: 7
Training loss: 2.133100441300358
Validation loss: 2.50283842283813

Epoch: 5| Step: 8
Training loss: 2.0991611303862463
Validation loss: 2.503599127205585

Epoch: 5| Step: 9
Training loss: 2.322601114459745
Validation loss: 2.499638066318655

Epoch: 5| Step: 10
Training loss: 2.5604172593052184
Validation loss: 2.4853747773350956

Epoch: 5| Step: 11
Training loss: 2.1044817647653735
Validation loss: 2.49066989655595

Epoch: 110| Step: 0
Training loss: 2.500240123660997
Validation loss: 2.499267526452502

Epoch: 5| Step: 1
Training loss: 2.0381455972491116
Validation loss: 2.520608179950787

Epoch: 5| Step: 2
Training loss: 2.426786893060166
Validation loss: 2.5113487109500885

Epoch: 5| Step: 3
Training loss: 2.0179411126761146
Validation loss: 2.5163022821727

Epoch: 5| Step: 4
Training loss: 2.349347360767541
Validation loss: 2.510078468071417

Epoch: 5| Step: 5
Training loss: 1.9954947153172953
Validation loss: 2.503990707520375

Epoch: 5| Step: 6
Training loss: 2.264297201497945
Validation loss: 2.518529116030002

Epoch: 5| Step: 7
Training loss: 1.8461586687746392
Validation loss: 2.5112029594622087

Epoch: 5| Step: 8
Training loss: 2.3002985138604624
Validation loss: 2.514139791359124

Epoch: 5| Step: 9
Training loss: 2.340206162752716
Validation loss: 2.504471271261652

Epoch: 5| Step: 10
Training loss: 2.2160505609769268
Validation loss: 2.5377573542073253

Epoch: 5| Step: 11
Training loss: 1.8154658026178443
Validation loss: 2.5379326052288658

Epoch: 111| Step: 0
Training loss: 2.043006211004838
Validation loss: 2.541417286838442

Epoch: 5| Step: 1
Training loss: 2.0671408488689154
Validation loss: 2.5758696121611404

Epoch: 5| Step: 2
Training loss: 1.9333315276543088
Validation loss: 2.6010888902906717

Epoch: 5| Step: 3
Training loss: 2.220760884871642
Validation loss: 2.642186449961695

Epoch: 5| Step: 4
Training loss: 2.7315926483100057
Validation loss: 2.628651112026545

Epoch: 5| Step: 5
Training loss: 2.2400616393804604
Validation loss: 2.6316666189446987

Epoch: 5| Step: 6
Training loss: 2.6956930140709345
Validation loss: 2.614999458107488

Epoch: 5| Step: 7
Training loss: 2.24625317878477
Validation loss: 2.5721302233381538

Epoch: 5| Step: 8
Training loss: 2.5495084475796084
Validation loss: 2.560087890767798

Epoch: 5| Step: 9
Training loss: 1.8867563437434438
Validation loss: 2.5423699165613636

Epoch: 5| Step: 10
Training loss: 1.9318680277426767
Validation loss: 2.516466935760459

Epoch: 5| Step: 11
Training loss: 2.1047059554641034
Validation loss: 2.513071711260728

Epoch: 112| Step: 0
Training loss: 1.8274832357115183
Validation loss: 2.510193194867323

Epoch: 5| Step: 1
Training loss: 2.7532650031908315
Validation loss: 2.525259484123747

Epoch: 5| Step: 2
Training loss: 2.3909196859006974
Validation loss: 2.4971379586829867

Epoch: 5| Step: 3
Training loss: 2.329876848658171
Validation loss: 2.499964006482735

Epoch: 5| Step: 4
Training loss: 2.0155041089140244
Validation loss: 2.5009604238406244

Epoch: 5| Step: 5
Training loss: 2.1456744928427143
Validation loss: 2.508034309092962

Epoch: 5| Step: 6
Training loss: 1.9085113370187385
Validation loss: 2.4802710747236314

Epoch: 5| Step: 7
Training loss: 2.5629184660339077
Validation loss: 2.4897146443063196

Epoch: 5| Step: 8
Training loss: 1.992015337517303
Validation loss: 2.516591520219098

Epoch: 5| Step: 9
Training loss: 2.3142239098983626
Validation loss: 2.5029314259178146

Epoch: 5| Step: 10
Training loss: 2.2076195936975407
Validation loss: 2.51226101129319

Epoch: 5| Step: 11
Training loss: 1.6079122321482955
Validation loss: 2.5225992513127946

Epoch: 113| Step: 0
Training loss: 2.435639380416725
Validation loss: 2.5248986414278094

Epoch: 5| Step: 1
Training loss: 1.7998989368253524
Validation loss: 2.5500284031302147

Epoch: 5| Step: 2
Training loss: 2.219591115636295
Validation loss: 2.560018186597746

Epoch: 5| Step: 3
Training loss: 2.2789282284089727
Validation loss: 2.549678577785105

Epoch: 5| Step: 4
Training loss: 2.297018137513538
Validation loss: 2.5590462553845867

Epoch: 5| Step: 5
Training loss: 2.231501619058475
Validation loss: 2.5759040938212023

Epoch: 5| Step: 6
Training loss: 1.9756842912600407
Validation loss: 2.5459326227329546

Epoch: 5| Step: 7
Training loss: 2.1304863062080313
Validation loss: 2.5596715098624303

Epoch: 5| Step: 8
Training loss: 2.209833091716071
Validation loss: 2.5458648449206116

Epoch: 5| Step: 9
Training loss: 2.0819326524129806
Validation loss: 2.5217725223233747

Epoch: 5| Step: 10
Training loss: 2.7129993348280768
Validation loss: 2.5259404637359735

Epoch: 5| Step: 11
Training loss: 1.2711050285115646
Validation loss: 2.528015542696301

Epoch: 114| Step: 0
Training loss: 1.4064756000543623
Validation loss: 2.489077996929911

Epoch: 5| Step: 1
Training loss: 2.66591564172636
Validation loss: 2.500783920564728

Epoch: 5| Step: 2
Training loss: 2.122010989880664
Validation loss: 2.5041514180925653

Epoch: 5| Step: 3
Training loss: 2.1115031491833562
Validation loss: 2.5025610283273876

Epoch: 5| Step: 4
Training loss: 2.283217013196907
Validation loss: 2.5108937935228934

Epoch: 5| Step: 5
Training loss: 2.690698007264358
Validation loss: 2.4857198885706797

Epoch: 5| Step: 6
Training loss: 2.1062832249587604
Validation loss: 2.4957474581274246

Epoch: 5| Step: 7
Training loss: 1.911897517031471
Validation loss: 2.504434344403564

Epoch: 5| Step: 8
Training loss: 2.5265063825142042
Validation loss: 2.5129309221433775

Epoch: 5| Step: 9
Training loss: 2.0615329209131708
Validation loss: 2.5053324295259376

Epoch: 5| Step: 10
Training loss: 2.194571047429168
Validation loss: 2.497073684111263

Epoch: 5| Step: 11
Training loss: 2.704188848638638
Validation loss: 2.502674504038249

Epoch: 115| Step: 0
Training loss: 2.422496297575618
Validation loss: 2.5108111033408806

Epoch: 5| Step: 1
Training loss: 2.1998718267730366
Validation loss: 2.490363580680331

Epoch: 5| Step: 2
Training loss: 2.2411547684954956
Validation loss: 2.5024560824328277

Epoch: 5| Step: 3
Training loss: 1.9757021512948514
Validation loss: 2.5059873846058243

Epoch: 5| Step: 4
Training loss: 2.398940043035283
Validation loss: 2.49479389124209

Epoch: 5| Step: 5
Training loss: 2.1832298016449783
Validation loss: 2.5135608086382106

Epoch: 5| Step: 6
Training loss: 1.8250179133123963
Validation loss: 2.504998399869772

Epoch: 5| Step: 7
Training loss: 2.0296119540796624
Validation loss: 2.4910951490521316

Epoch: 5| Step: 8
Training loss: 1.9630543502924591
Validation loss: 2.5047019689962626

Epoch: 5| Step: 9
Training loss: 2.2504456396650423
Validation loss: 2.50614428467686

Epoch: 5| Step: 10
Training loss: 2.5061407964416835
Validation loss: 2.5278120555288592

Epoch: 5| Step: 11
Training loss: 2.929644856460481
Validation loss: 2.523821790661952

Epoch: 116| Step: 0
Training loss: 2.161578243253985
Validation loss: 2.5404111869965225

Epoch: 5| Step: 1
Training loss: 2.1137469161161713
Validation loss: 2.533690308424635

Epoch: 5| Step: 2
Training loss: 2.3439275038578016
Validation loss: 2.5336673637656504

Epoch: 5| Step: 3
Training loss: 2.3854524590307085
Validation loss: 2.555717828224166

Epoch: 5| Step: 4
Training loss: 2.2318308824779214
Validation loss: 2.5428482355253403

Epoch: 5| Step: 5
Training loss: 2.324819073764349
Validation loss: 2.5609326104797643

Epoch: 5| Step: 6
Training loss: 2.3741754807210094
Validation loss: 2.5074084838851913

Epoch: 5| Step: 7
Training loss: 1.6020794290099007
Validation loss: 2.517529866200197

Epoch: 5| Step: 8
Training loss: 2.526361619539912
Validation loss: 2.5178365010056667

Epoch: 5| Step: 9
Training loss: 2.094130182622666
Validation loss: 2.5089851798695166

Epoch: 5| Step: 10
Training loss: 1.961812223199937
Validation loss: 2.4910229300817117

Epoch: 5| Step: 11
Training loss: 1.948035605432236
Validation loss: 2.5003945794253295

Epoch: 117| Step: 0
Training loss: 2.352260448003256
Validation loss: 2.4992542744089583

Epoch: 5| Step: 1
Training loss: 2.4586331674951287
Validation loss: 2.5130361737720266

Epoch: 5| Step: 2
Training loss: 1.7364001436176781
Validation loss: 2.518990167285133

Epoch: 5| Step: 3
Training loss: 2.4573260253298064
Validation loss: 2.5080479544035494

Epoch: 5| Step: 4
Training loss: 1.8554149740356884
Validation loss: 2.504375114323501

Epoch: 5| Step: 5
Training loss: 2.6340986330860283
Validation loss: 2.503581120671994

Epoch: 5| Step: 6
Training loss: 1.9377155799294106
Validation loss: 2.5227326982574168

Epoch: 5| Step: 7
Training loss: 2.196995860176197
Validation loss: 2.5052966989859

Epoch: 5| Step: 8
Training loss: 2.0222532127902837
Validation loss: 2.4966393492846284

Epoch: 5| Step: 9
Training loss: 1.710875279240165
Validation loss: 2.529357716971281

Epoch: 5| Step: 10
Training loss: 2.3013223164067433
Validation loss: 2.5415772763672497

Epoch: 5| Step: 11
Training loss: 2.8515140059018633
Validation loss: 2.534696990951536

Epoch: 118| Step: 0
Training loss: 1.5069515952757575
Validation loss: 2.5510405778136187

Epoch: 5| Step: 1
Training loss: 2.5960254110318144
Validation loss: 2.5450279543577357

Epoch: 5| Step: 2
Training loss: 2.487583415870818
Validation loss: 2.5325147859757426

Epoch: 5| Step: 3
Training loss: 2.7014990530511898
Validation loss: 2.529377971119884

Epoch: 5| Step: 4
Training loss: 2.1888429061892163
Validation loss: 2.5140584526400866

Epoch: 5| Step: 5
Training loss: 2.01107084340528
Validation loss: 2.510506930383921

Epoch: 5| Step: 6
Training loss: 2.298108762134394
Validation loss: 2.506152160935474

Epoch: 5| Step: 7
Training loss: 1.9162948358295882
Validation loss: 2.4934988647500678

Epoch: 5| Step: 8
Training loss: 1.7056260948974404
Validation loss: 2.497887050277043

Epoch: 5| Step: 9
Training loss: 1.9646020213506148
Validation loss: 2.477621175116735

Epoch: 5| Step: 10
Training loss: 2.3175974158560027
Validation loss: 2.4919353664495865

Epoch: 5| Step: 11
Training loss: 0.6757816689550612
Validation loss: 2.4957354651120243

Epoch: 119| Step: 0
Training loss: 1.9874255544287345
Validation loss: 2.511491748445648

Epoch: 5| Step: 1
Training loss: 1.6724493876099273
Validation loss: 2.507039149941479

Epoch: 5| Step: 2
Training loss: 2.4032528529490023
Validation loss: 2.497427868894508

Epoch: 5| Step: 3
Training loss: 1.8210379665214822
Validation loss: 2.4992212354149426

Epoch: 5| Step: 4
Training loss: 2.639777323984155
Validation loss: 2.508300274306856

Epoch: 5| Step: 5
Training loss: 2.5190211526392248
Validation loss: 2.5162063977209126

Epoch: 5| Step: 6
Training loss: 1.4094249911016876
Validation loss: 2.516288723076781

Epoch: 5| Step: 7
Training loss: 2.4195926864160335
Validation loss: 2.5340789755309436

Epoch: 5| Step: 8
Training loss: 1.87082193904995
Validation loss: 2.5387717721238094

Epoch: 5| Step: 9
Training loss: 1.996051108544965
Validation loss: 2.5367760325485467

Epoch: 5| Step: 10
Training loss: 2.617674733826852
Validation loss: 2.5306140273404223

Epoch: 5| Step: 11
Training loss: 2.1041427711665945
Validation loss: 2.5222076592104306

Epoch: 120| Step: 0
Training loss: 2.04064085225466
Validation loss: 2.5540304943167103

Epoch: 5| Step: 1
Training loss: 2.2307716604872203
Validation loss: 2.548733916313757

Epoch: 5| Step: 2
Training loss: 2.6534662357508942
Validation loss: 2.533241842263727

Epoch: 5| Step: 3
Training loss: 2.4091186268293194
Validation loss: 2.54717058093073

Epoch: 5| Step: 4
Training loss: 2.0328551772473555
Validation loss: 2.5414813526531908

Epoch: 5| Step: 5
Training loss: 2.4449489920508505
Validation loss: 2.5334702279619137

Epoch: 5| Step: 6
Training loss: 2.1605705429598814
Validation loss: 2.5128215941408594

Epoch: 5| Step: 7
Training loss: 2.3573827353122554
Validation loss: 2.5214698844274634

Epoch: 5| Step: 8
Training loss: 2.0881695752836698
Validation loss: 2.4846678387297367

Epoch: 5| Step: 9
Training loss: 1.4529587024981685
Validation loss: 2.4926147373756518

Epoch: 5| Step: 10
Training loss: 2.021576485861887
Validation loss: 2.497967819939394

Epoch: 5| Step: 11
Training loss: 1.528728511032327
Validation loss: 2.4955408641135852

Epoch: 121| Step: 0
Training loss: 1.712681269275446
Validation loss: 2.4824790437780004

Epoch: 5| Step: 1
Training loss: 1.635544312308604
Validation loss: 2.501423658877946

Epoch: 5| Step: 2
Training loss: 1.704842707406663
Validation loss: 2.5189666430854443

Epoch: 5| Step: 3
Training loss: 2.5958293255509184
Validation loss: 2.545200983504044

Epoch: 5| Step: 4
Training loss: 1.6764849272430675
Validation loss: 2.5657746356937476

Epoch: 5| Step: 5
Training loss: 2.2503693595348957
Validation loss: 2.5633078131461535

Epoch: 5| Step: 6
Training loss: 2.396300118349567
Validation loss: 2.5996315809715846

Epoch: 5| Step: 7
Training loss: 2.3179940608345944
Validation loss: 2.5635966923737232

Epoch: 5| Step: 8
Training loss: 2.6057363941723475
Validation loss: 2.5750527620311123

Epoch: 5| Step: 9
Training loss: 2.5043770619729724
Validation loss: 2.547373697489795

Epoch: 5| Step: 10
Training loss: 1.957945041173521
Validation loss: 2.5337465164720188

Epoch: 5| Step: 11
Training loss: 3.0398519319312918
Validation loss: 2.5188664310828206

Epoch: 122| Step: 0
Training loss: 1.8560455389478772
Validation loss: 2.5143325696167573

Epoch: 5| Step: 1
Training loss: 1.9732617950144928
Validation loss: 2.5167254850533065

Epoch: 5| Step: 2
Training loss: 2.275904205384621
Validation loss: 2.4838624221516317

Epoch: 5| Step: 3
Training loss: 2.1632662523603226
Validation loss: 2.498482322966742

Epoch: 5| Step: 4
Training loss: 2.2195372997981613
Validation loss: 2.5053685124528395

Epoch: 5| Step: 5
Training loss: 2.1529384006205228
Validation loss: 2.5108425931910667

Epoch: 5| Step: 6
Training loss: 2.5460685904314118
Validation loss: 2.5327410505674695

Epoch: 5| Step: 7
Training loss: 1.6703516356947976
Validation loss: 2.5328096208157924

Epoch: 5| Step: 8
Training loss: 2.4575934077815216
Validation loss: 2.5067779649233723

Epoch: 5| Step: 9
Training loss: 2.3867760883942113
Validation loss: 2.511301424231957

Epoch: 5| Step: 10
Training loss: 1.9588257867092218
Validation loss: 2.5267604526217897

Epoch: 5| Step: 11
Training loss: 1.9934359359914477
Validation loss: 2.509848310046132

Epoch: 123| Step: 0
Training loss: 2.5618784080793535
Validation loss: 2.501589841770668

Epoch: 5| Step: 1
Training loss: 2.1877407486451568
Validation loss: 2.534626178939532

Epoch: 5| Step: 2
Training loss: 1.9872828526902455
Validation loss: 2.54454965277328

Epoch: 5| Step: 3
Training loss: 2.352186760150321
Validation loss: 2.551093120894576

Epoch: 5| Step: 4
Training loss: 2.265723811658551
Validation loss: 2.5488870626093094

Epoch: 5| Step: 5
Training loss: 2.526357561527371
Validation loss: 2.5543223089886826

Epoch: 5| Step: 6
Training loss: 1.8346621364996856
Validation loss: 2.565917833245368

Epoch: 5| Step: 7
Training loss: 1.8445165301539008
Validation loss: 2.5318110789982358

Epoch: 5| Step: 8
Training loss: 1.9056957877559002
Validation loss: 2.5314212356543564

Epoch: 5| Step: 9
Training loss: 2.1162434968437234
Validation loss: 2.519366441802209

Epoch: 5| Step: 10
Training loss: 1.4167483624108408
Validation loss: 2.5203028401810306

Epoch: 5| Step: 11
Training loss: 2.2769507041155213
Validation loss: 2.5555052814226302

Epoch: 124| Step: 0
Training loss: 2.1156209520219535
Validation loss: 2.5501462974686806

Epoch: 5| Step: 1
Training loss: 2.1233355791727804
Validation loss: 2.54400429294232

Epoch: 5| Step: 2
Training loss: 2.4154497129890746
Validation loss: 2.5439319768886812

Epoch: 5| Step: 3
Training loss: 2.6805184635721173
Validation loss: 2.540136573735477

Epoch: 5| Step: 4
Training loss: 1.9342144827114223
Validation loss: 2.513814120354572

Epoch: 5| Step: 5
Training loss: 2.229845056667751
Validation loss: 2.503279597143346

Epoch: 5| Step: 6
Training loss: 1.5301579843871802
Validation loss: 2.517521782859427

Epoch: 5| Step: 7
Training loss: 2.167003409798003
Validation loss: 2.529746782701104

Epoch: 5| Step: 8
Training loss: 2.534292676461146
Validation loss: 2.509456032584379

Epoch: 5| Step: 9
Training loss: 1.7335057872788942
Validation loss: 2.5203088353968583

Epoch: 5| Step: 10
Training loss: 1.857722405510158
Validation loss: 2.520986317230129

Epoch: 5| Step: 11
Training loss: 2.163394094866811
Validation loss: 2.549894078320573

Epoch: 125| Step: 0
Training loss: 2.4678252214343224
Validation loss: 2.512898015527755

Epoch: 5| Step: 1
Training loss: 1.7445055674854675
Validation loss: 2.5253471140642434

Epoch: 5| Step: 2
Training loss: 2.1516686019278093
Validation loss: 2.5136383734157337

Epoch: 5| Step: 3
Training loss: 2.215943401577888
Validation loss: 2.5099581831352786

Epoch: 5| Step: 4
Training loss: 2.0862540815620885
Validation loss: 2.520490827359091

Epoch: 5| Step: 5
Training loss: 2.489707166925174
Validation loss: 2.500460574321797

Epoch: 5| Step: 6
Training loss: 2.3739353604535176
Validation loss: 2.518722913137329

Epoch: 5| Step: 7
Training loss: 2.269277745597444
Validation loss: 2.491466597325312

Epoch: 5| Step: 8
Training loss: 1.4064094876872026
Validation loss: 2.517540184901129

Epoch: 5| Step: 9
Training loss: 1.9683375456353362
Validation loss: 2.5121858359265423

Epoch: 5| Step: 10
Training loss: 2.040816798404717
Validation loss: 2.530607228240657

Epoch: 5| Step: 11
Training loss: 1.1904562242286818
Validation loss: 2.51672226805455

Epoch: 126| Step: 0
Training loss: 2.245738550378854
Validation loss: 2.5169405449225875

Epoch: 5| Step: 1
Training loss: 2.2672636223073686
Validation loss: 2.5378664221951914

Epoch: 5| Step: 2
Training loss: 1.7858247068869966
Validation loss: 2.540199578793989

Epoch: 5| Step: 3
Training loss: 2.042875619665651
Validation loss: 2.51513811695354

Epoch: 5| Step: 4
Training loss: 2.1133308898398213
Validation loss: 2.5335291268161457

Epoch: 5| Step: 5
Training loss: 1.7380813998090137
Validation loss: 2.5059810062819157

Epoch: 5| Step: 6
Training loss: 2.6381588768246873
Validation loss: 2.5375814823322482

Epoch: 5| Step: 7
Training loss: 1.9121038886859494
Validation loss: 2.5168600071815006

Epoch: 5| Step: 8
Training loss: 2.138953008420008
Validation loss: 2.5152131843335797

Epoch: 5| Step: 9
Training loss: 1.7991659404310865
Validation loss: 2.5561135382319367

Epoch: 5| Step: 10
Training loss: 2.1898860452346103
Validation loss: 2.5438508897905043

Epoch: 5| Step: 11
Training loss: 2.5500738731604304
Validation loss: 2.562957811940591

Epoch: 127| Step: 0
Training loss: 1.7794866701437695
Validation loss: 2.5911851442252827

Epoch: 5| Step: 1
Training loss: 2.2220139472104807
Validation loss: 2.5499683406990026

Epoch: 5| Step: 2
Training loss: 2.2591253245571976
Validation loss: 2.529144054690926

Epoch: 5| Step: 3
Training loss: 2.439624251997893
Validation loss: 2.5003281695823643

Epoch: 5| Step: 4
Training loss: 2.028277173086321
Validation loss: 2.525361956094119

Epoch: 5| Step: 5
Training loss: 2.204118112511248
Validation loss: 2.496793307645766

Epoch: 5| Step: 6
Training loss: 2.474351828886509
Validation loss: 2.518743282384883

Epoch: 5| Step: 7
Training loss: 2.158465366915425
Validation loss: 2.5021846008029893

Epoch: 5| Step: 8
Training loss: 1.6593752471291454
Validation loss: 2.5151646787234374

Epoch: 5| Step: 9
Training loss: 2.2267318928848456
Validation loss: 2.5355111546229363

Epoch: 5| Step: 10
Training loss: 1.8062324021482032
Validation loss: 2.516352704234556

Epoch: 5| Step: 11
Training loss: 1.548577652794531
Validation loss: 2.5283497533241976

Epoch: 128| Step: 0
Training loss: 1.4670788611997816
Validation loss: 2.511451722817652

Epoch: 5| Step: 1
Training loss: 2.096119920110112
Validation loss: 2.512450483887526

Epoch: 5| Step: 2
Training loss: 2.241561855527199
Validation loss: 2.522800841587862

Epoch: 5| Step: 3
Training loss: 2.1422961318103595
Validation loss: 2.5375966501542866

Epoch: 5| Step: 4
Training loss: 1.5022744577886051
Validation loss: 2.5422280400378376

Epoch: 5| Step: 5
Training loss: 2.0260265385733875
Validation loss: 2.5831820241136567

Epoch: 5| Step: 6
Training loss: 2.3369340588885392
Validation loss: 2.5759267895283173

Epoch: 5| Step: 7
Training loss: 2.3228127722892054
Validation loss: 2.5886312900330295

Epoch: 5| Step: 8
Training loss: 2.5265627189263395
Validation loss: 2.5733951530377097

Epoch: 5| Step: 9
Training loss: 2.2123465748840356
Validation loss: 2.5632111485243376

Epoch: 5| Step: 10
Training loss: 2.2450496469288366
Validation loss: 2.5497727788406435

Epoch: 5| Step: 11
Training loss: 1.8414384608471932
Validation loss: 2.539612461097249

Epoch: 129| Step: 0
Training loss: 1.8599314137600884
Validation loss: 2.519570630773671

Epoch: 5| Step: 1
Training loss: 1.6452090934580015
Validation loss: 2.5370876515911873

Epoch: 5| Step: 2
Training loss: 2.5930777908113782
Validation loss: 2.5281770483128176

Epoch: 5| Step: 3
Training loss: 2.3359262727703647
Validation loss: 2.5253166311801674

Epoch: 5| Step: 4
Training loss: 2.3059030204621815
Validation loss: 2.5356518300710054

Epoch: 5| Step: 5
Training loss: 2.1352949402392922
Validation loss: 2.522222395647517

Epoch: 5| Step: 6
Training loss: 2.425381687447043
Validation loss: 2.5142476455639775

Epoch: 5| Step: 7
Training loss: 1.7650515545023804
Validation loss: 2.516800710337798

Epoch: 5| Step: 8
Training loss: 2.1097151870504205
Validation loss: 2.5123492804595573

Epoch: 5| Step: 9
Training loss: 1.7399080700540992
Validation loss: 2.50159470042834

Epoch: 5| Step: 10
Training loss: 2.0388252441816235
Validation loss: 2.511686911215531

Epoch: 5| Step: 11
Training loss: 1.2822274922050132
Validation loss: 2.525932641314732

Epoch: 130| Step: 0
Training loss: 2.054463305407668
Validation loss: 2.5488833678435276

Epoch: 5| Step: 1
Training loss: 1.672822416444686
Validation loss: 2.5191863738208347

Epoch: 5| Step: 2
Training loss: 1.925635156254913
Validation loss: 2.5709276593698

Epoch: 5| Step: 3
Training loss: 2.587153215251426
Validation loss: 2.595960226881349

Epoch: 5| Step: 4
Training loss: 1.9063815712470653
Validation loss: 2.5946034172640364

Epoch: 5| Step: 5
Training loss: 2.080677845066937
Validation loss: 2.5730756673190798

Epoch: 5| Step: 6
Training loss: 1.8639678010124154
Validation loss: 2.587698322564752

Epoch: 5| Step: 7
Training loss: 2.3893416207367077
Validation loss: 2.573522474549397

Epoch: 5| Step: 8
Training loss: 2.6238054554800336
Validation loss: 2.5749658745908683

Epoch: 5| Step: 9
Training loss: 2.376846599464352
Validation loss: 2.5663112388608917

Epoch: 5| Step: 10
Training loss: 1.3805137536269774
Validation loss: 2.508736607513135

Epoch: 5| Step: 11
Training loss: 0.4889701865826003
Validation loss: 2.5052375368780826

Epoch: 131| Step: 0
Training loss: 2.036830572139482
Validation loss: 2.520879663614386

Epoch: 5| Step: 1
Training loss: 2.4660574800857074
Validation loss: 2.5237699551460215

Epoch: 5| Step: 2
Training loss: 2.143141888818641
Validation loss: 2.5219248754524073

Epoch: 5| Step: 3
Training loss: 2.1437396480210267
Validation loss: 2.493993306221604

Epoch: 5| Step: 4
Training loss: 1.7763216873725405
Validation loss: 2.5222789577166997

Epoch: 5| Step: 5
Training loss: 1.8226488697803527
Validation loss: 2.532311911418986

Epoch: 5| Step: 6
Training loss: 1.8112527567945815
Validation loss: 2.5205127824894196

Epoch: 5| Step: 7
Training loss: 2.5725518301292145
Validation loss: 2.5189510101177413

Epoch: 5| Step: 8
Training loss: 2.1037289255393334
Validation loss: 2.517102007338558

Epoch: 5| Step: 9
Training loss: 2.33609130761271
Validation loss: 2.500968630220921

Epoch: 5| Step: 10
Training loss: 1.599839339534754
Validation loss: 2.5040933714648546

Epoch: 5| Step: 11
Training loss: 2.339738286209661
Validation loss: 2.5396582819013385

Epoch: 132| Step: 0
Training loss: 2.3913097522885614
Validation loss: 2.573267277034895

Epoch: 5| Step: 1
Training loss: 2.029398147361709
Validation loss: 2.5965172624903636

Epoch: 5| Step: 2
Training loss: 2.328210816305855
Validation loss: 2.6299003206697944

Epoch: 5| Step: 3
Training loss: 1.5625109862895015
Validation loss: 2.660848011327207

Epoch: 5| Step: 4
Training loss: 2.078617123722811
Validation loss: 2.6514454454800314

Epoch: 5| Step: 5
Training loss: 1.788249268252067
Validation loss: 2.6491074366476526

Epoch: 5| Step: 6
Training loss: 2.0526466822744234
Validation loss: 2.6397767256294187

Epoch: 5| Step: 7
Training loss: 2.4310293141601877
Validation loss: 2.6393901375389097

Epoch: 5| Step: 8
Training loss: 2.191984538921767
Validation loss: 2.6176356790653057

Epoch: 5| Step: 9
Training loss: 1.9072501263625303
Validation loss: 2.55705838327438

Epoch: 5| Step: 10
Training loss: 2.152673491819889
Validation loss: 2.5232139937208102

Epoch: 5| Step: 11
Training loss: 2.1306210392461673
Validation loss: 2.508046742370258

Epoch: 133| Step: 0
Training loss: 1.7732068554631049
Validation loss: 2.5204184042242006

Epoch: 5| Step: 1
Training loss: 2.620608061634058
Validation loss: 2.524946904961862

Epoch: 5| Step: 2
Training loss: 2.099523753704779
Validation loss: 2.5031703555934635

Epoch: 5| Step: 3
Training loss: 2.6438348887276906
Validation loss: 2.5233019919372355

Epoch: 5| Step: 4
Training loss: 1.9182346260710548
Validation loss: 2.5131432669797196

Epoch: 5| Step: 5
Training loss: 1.824038707008746
Validation loss: 2.4931351823998087

Epoch: 5| Step: 6
Training loss: 1.7175103311908178
Validation loss: 2.512084234293084

Epoch: 5| Step: 7
Training loss: 2.026633548005863
Validation loss: 2.536119012766944

Epoch: 5| Step: 8
Training loss: 1.7172549594613717
Validation loss: 2.5192289816741216

Epoch: 5| Step: 9
Training loss: 2.382667812269576
Validation loss: 2.5290720521825127

Epoch: 5| Step: 10
Training loss: 1.679157262102142
Validation loss: 2.529638460283622

Epoch: 5| Step: 11
Training loss: 3.237705156461252
Validation loss: 2.543509098271172

Epoch: 134| Step: 0
Training loss: 2.076961794109235
Validation loss: 2.539327738675202

Epoch: 5| Step: 1
Training loss: 2.076920468581428
Validation loss: 2.5597030603284137

Epoch: 5| Step: 2
Training loss: 2.0823862084558167
Validation loss: 2.541745311010218

Epoch: 5| Step: 3
Training loss: 2.545769387132491
Validation loss: 2.5686518706847603

Epoch: 5| Step: 4
Training loss: 2.0602508766219665
Validation loss: 2.564991716479335

Epoch: 5| Step: 5
Training loss: 1.79305026132971
Validation loss: 2.5529891852274176

Epoch: 5| Step: 6
Training loss: 1.985563327886996
Validation loss: 2.5454496674160643

Epoch: 5| Step: 7
Training loss: 1.8891176883028726
Validation loss: 2.545884288791936

Epoch: 5| Step: 8
Training loss: 2.038252980396979
Validation loss: 2.552937280422155

Epoch: 5| Step: 9
Training loss: 1.8203517925949673
Validation loss: 2.539681547945024

Epoch: 5| Step: 10
Training loss: 2.025407340441511
Validation loss: 2.5316382137915525

Epoch: 5| Step: 11
Training loss: 2.266336579223379
Validation loss: 2.519179997368396

Epoch: 135| Step: 0
Training loss: 2.44263055239693
Validation loss: 2.5435005135937803

Epoch: 5| Step: 1
Training loss: 2.1512596875803265
Validation loss: 2.5399841357409048

Epoch: 5| Step: 2
Training loss: 1.4419306599721515
Validation loss: 2.531053211662992

Epoch: 5| Step: 3
Training loss: 1.5286546627831632
Validation loss: 2.5051438183847696

Epoch: 5| Step: 4
Training loss: 1.8342582652496007
Validation loss: 2.504165516967848

Epoch: 5| Step: 5
Training loss: 2.1723616898630103
Validation loss: 2.517504177778225

Epoch: 5| Step: 6
Training loss: 2.1555807208310607
Validation loss: 2.5334555236205394

Epoch: 5| Step: 7
Training loss: 2.351746814893105
Validation loss: 2.547828698582652

Epoch: 5| Step: 8
Training loss: 2.348061017324009
Validation loss: 2.5416391337315716

Epoch: 5| Step: 9
Training loss: 1.7068743950120935
Validation loss: 2.5559482399461086

Epoch: 5| Step: 10
Training loss: 2.1501309465852025
Validation loss: 2.5506559090929195

Epoch: 5| Step: 11
Training loss: 2.509034521583804
Validation loss: 2.5755787962796215

Epoch: 136| Step: 0
Training loss: 2.25555190596053
Validation loss: 2.5164673226292247

Epoch: 5| Step: 1
Training loss: 1.5422842318142531
Validation loss: 2.5098832475186112

Epoch: 5| Step: 2
Training loss: 2.6672184393171565
Validation loss: 2.4957927946280916

Epoch: 5| Step: 3
Training loss: 1.6235650402559814
Validation loss: 2.527064654403635

Epoch: 5| Step: 4
Training loss: 2.2712834696594655
Validation loss: 2.5247974175998

Epoch: 5| Step: 5
Training loss: 2.2365131951259882
Validation loss: 2.550977519235981

Epoch: 5| Step: 6
Training loss: 1.9742960242608891
Validation loss: 2.5605289314081645

Epoch: 5| Step: 7
Training loss: 2.2732737898463298
Validation loss: 2.5545821367442567

Epoch: 5| Step: 8
Training loss: 1.6690550935999093
Validation loss: 2.548237449828911

Epoch: 5| Step: 9
Training loss: 1.7038561450249998
Validation loss: 2.541358089997244

Epoch: 5| Step: 10
Training loss: 2.0050897208138054
Validation loss: 2.538843951478563

Epoch: 5| Step: 11
Training loss: 1.839117015980228
Validation loss: 2.536691434960079

Epoch: 137| Step: 0
Training loss: 2.4252529091058155
Validation loss: 2.5252723833348494

Epoch: 5| Step: 1
Training loss: 1.6600466703265766
Validation loss: 2.5375935809726813

Epoch: 5| Step: 2
Training loss: 2.071088192132596
Validation loss: 2.5458851160213785

Epoch: 5| Step: 3
Training loss: 1.9112165819618387
Validation loss: 2.540502251525524

Epoch: 5| Step: 4
Training loss: 1.8976925616757647
Validation loss: 2.5313260573275125

Epoch: 5| Step: 5
Training loss: 1.9273052878189365
Validation loss: 2.512285891309385

Epoch: 5| Step: 6
Training loss: 2.0636451316543343
Validation loss: 2.529562587846709

Epoch: 5| Step: 7
Training loss: 1.886218650360173
Validation loss: 2.5634301869875076

Epoch: 5| Step: 8
Training loss: 1.6776623249681182
Validation loss: 2.5521115684244893

Epoch: 5| Step: 9
Training loss: 2.624266567402151
Validation loss: 2.534032985236096

Epoch: 5| Step: 10
Training loss: 1.7908003583061196
Validation loss: 2.5472941453523923

Epoch: 5| Step: 11
Training loss: 2.7357723480346454
Validation loss: 2.5456052435003627

Epoch: 138| Step: 0
Training loss: 1.5719567795216127
Validation loss: 2.5701733506093545

Epoch: 5| Step: 1
Training loss: 1.576009938218398
Validation loss: 2.561825147790381

Epoch: 5| Step: 2
Training loss: 2.3493347768544597
Validation loss: 2.5531407494683713

Epoch: 5| Step: 3
Training loss: 2.0631087589635833
Validation loss: 2.5665439547479485

Epoch: 5| Step: 4
Training loss: 2.144850410100379
Validation loss: 2.571416828261789

Epoch: 5| Step: 5
Training loss: 1.346308291137571
Validation loss: 2.573397778048339

Epoch: 5| Step: 6
Training loss: 2.179703907238316
Validation loss: 2.532192415849921

Epoch: 5| Step: 7
Training loss: 2.437775229540899
Validation loss: 2.5246691222619195

Epoch: 5| Step: 8
Training loss: 2.424583348140224
Validation loss: 2.532522478232963

Epoch: 5| Step: 9
Training loss: 2.004177974846146
Validation loss: 2.527523397971902

Epoch: 5| Step: 10
Training loss: 1.9464645957362887
Validation loss: 2.5483473362069113

Epoch: 5| Step: 11
Training loss: 1.8300563684755986
Validation loss: 2.530716576904418

Epoch: 139| Step: 0
Training loss: 2.375887052619337
Validation loss: 2.570455780982853

Epoch: 5| Step: 1
Training loss: 1.5341907988885897
Validation loss: 2.5541026100124844

Epoch: 5| Step: 2
Training loss: 2.0810195153717697
Validation loss: 2.622027905794328

Epoch: 5| Step: 3
Training loss: 1.964376405381062
Validation loss: 2.630125261008363

Epoch: 5| Step: 4
Training loss: 2.036738799961846
Validation loss: 2.632187785242542

Epoch: 5| Step: 5
Training loss: 1.9346101805860079
Validation loss: 2.6188769073811975

Epoch: 5| Step: 6
Training loss: 1.7997060615230174
Validation loss: 2.602400403268341

Epoch: 5| Step: 7
Training loss: 1.9746858636698679
Validation loss: 2.5909722057553717

Epoch: 5| Step: 8
Training loss: 2.150890600581858
Validation loss: 2.5656981630847375

Epoch: 5| Step: 9
Training loss: 1.9245145705859077
Validation loss: 2.5545634434994384

Epoch: 5| Step: 10
Training loss: 2.058973244825317
Validation loss: 2.54338248501184

Epoch: 5| Step: 11
Training loss: 3.9810180883966857
Validation loss: 2.5580249027837514

Epoch: 140| Step: 0
Training loss: 2.67089254598299
Validation loss: 2.529526826477362

Epoch: 5| Step: 1
Training loss: 2.0846035581811457
Validation loss: 2.51028250629937

Epoch: 5| Step: 2
Training loss: 2.0713597366095695
Validation loss: 2.5188539920539323

Epoch: 5| Step: 3
Training loss: 1.9205043215813513
Validation loss: 2.529007880197971

Epoch: 5| Step: 4
Training loss: 2.2511884941243547
Validation loss: 2.537401119429055

Epoch: 5| Step: 5
Training loss: 1.9768128971520496
Validation loss: 2.5402563134914526

Epoch: 5| Step: 6
Training loss: 2.154618572103578
Validation loss: 2.519827083597894

Epoch: 5| Step: 7
Training loss: 1.5017428604395713
Validation loss: 2.5210218884487414

Epoch: 5| Step: 8
Training loss: 1.7795580139478746
Validation loss: 2.5576554186666582

Epoch: 5| Step: 9
Training loss: 1.9728010974242105
Validation loss: 2.528622000857296

Epoch: 5| Step: 10
Training loss: 1.2924791774880213
Validation loss: 2.5414694034654173

Epoch: 5| Step: 11
Training loss: 2.712468838842333
Validation loss: 2.5529798541917175

Epoch: 141| Step: 0
Training loss: 1.9725382854580178
Validation loss: 2.6467009771278676

Epoch: 5| Step: 1
Training loss: 2.338035636362683
Validation loss: 2.6515979270688907

Epoch: 5| Step: 2
Training loss: 2.288140537654135
Validation loss: 2.672221356524166

Epoch: 5| Step: 3
Training loss: 1.888470202056624
Validation loss: 2.6681987352414875

Epoch: 5| Step: 4
Training loss: 1.6803687554921403
Validation loss: 2.664033887752393

Epoch: 5| Step: 5
Training loss: 1.7499476152481452
Validation loss: 2.643171489568617

Epoch: 5| Step: 6
Training loss: 2.0597484614675214
Validation loss: 2.6326428744557258

Epoch: 5| Step: 7
Training loss: 2.3754148622871867
Validation loss: 2.6036354909224553

Epoch: 5| Step: 8
Training loss: 2.0402344591380657
Validation loss: 2.5903433715303623

Epoch: 5| Step: 9
Training loss: 1.8804609880972636
Validation loss: 2.5340013542956994

Epoch: 5| Step: 10
Training loss: 2.0098510368148053
Validation loss: 2.553641327686654

Epoch: 5| Step: 11
Training loss: 0.8508054535420636
Validation loss: 2.545845658438442

Epoch: 142| Step: 0
Training loss: 1.5270485360976254
Validation loss: 2.5319498354479557

Epoch: 5| Step: 1
Training loss: 1.4848004183246581
Validation loss: 2.564470181162686

Epoch: 5| Step: 2
Training loss: 1.8084174249436897
Validation loss: 2.558738684977858

Epoch: 5| Step: 3
Training loss: 2.6058881842396397
Validation loss: 2.551877487730143

Epoch: 5| Step: 4
Training loss: 1.7112143653965741
Validation loss: 2.54701890129352

Epoch: 5| Step: 5
Training loss: 1.6543669162231371
Validation loss: 2.553946054015599

Epoch: 5| Step: 6
Training loss: 1.9255524474246872
Validation loss: 2.5851117455071813

Epoch: 5| Step: 7
Training loss: 2.2824160587380966
Validation loss: 2.578213125707135

Epoch: 5| Step: 8
Training loss: 1.8791135170039588
Validation loss: 2.5744581521239187

Epoch: 5| Step: 9
Training loss: 2.8203867218310954
Validation loss: 2.586239784605275

Epoch: 5| Step: 10
Training loss: 1.9166582217928838
Validation loss: 2.5934594156274144

Epoch: 5| Step: 11
Training loss: 1.2320960531566123
Validation loss: 2.580492593268399

Epoch: 143| Step: 0
Training loss: 1.7220482131597405
Validation loss: 2.6160736066926034

Epoch: 5| Step: 1
Training loss: 2.053119946245683
Validation loss: 2.595676116764578

Epoch: 5| Step: 2
Training loss: 1.85183224544036
Validation loss: 2.571484852025444

Epoch: 5| Step: 3
Training loss: 1.923692913435358
Validation loss: 2.5683111865571795

Epoch: 5| Step: 4
Training loss: 2.1712483112546055
Validation loss: 2.5634223200796447

Epoch: 5| Step: 5
Training loss: 2.3947038946097043
Validation loss: 2.5382454951507563

Epoch: 5| Step: 6
Training loss: 2.00018428907103
Validation loss: 2.564854850206651

Epoch: 5| Step: 7
Training loss: 1.523117736122865
Validation loss: 2.5417585877436375

Epoch: 5| Step: 8
Training loss: 1.9452787955554711
Validation loss: 2.545813239705589

Epoch: 5| Step: 9
Training loss: 2.2202231661001104
Validation loss: 2.5433961750302125

Epoch: 5| Step: 10
Training loss: 1.709980318056576
Validation loss: 2.5632645117839004

Epoch: 5| Step: 11
Training loss: 2.370062061575649
Validation loss: 2.5612393278734595

Epoch: 144| Step: 0
Training loss: 2.166904167460913
Validation loss: 2.5511230971856533

Epoch: 5| Step: 1
Training loss: 2.09175914798057
Validation loss: 2.6093497284600096

Epoch: 5| Step: 2
Training loss: 2.382284237197169
Validation loss: 2.6096985210943804

Epoch: 5| Step: 3
Training loss: 2.1211620902894834
Validation loss: 2.649960098026172

Epoch: 5| Step: 4
Training loss: 1.5574945766299444
Validation loss: 2.6136108213428058

Epoch: 5| Step: 5
Training loss: 1.845647126816685
Validation loss: 2.5878494393772136

Epoch: 5| Step: 6
Training loss: 1.3223820104048076
Validation loss: 2.5920536208267704

Epoch: 5| Step: 7
Training loss: 1.472987777669612
Validation loss: 2.569203938721034

Epoch: 5| Step: 8
Training loss: 2.1336567643483138
Validation loss: 2.556548903539121

Epoch: 5| Step: 9
Training loss: 2.1170298387445476
Validation loss: 2.556605887413811

Epoch: 5| Step: 10
Training loss: 2.177129741946732
Validation loss: 2.560681120114982

Epoch: 5| Step: 11
Training loss: 2.2064882403764208
Validation loss: 2.5693705493737204

Epoch: 145| Step: 0
Training loss: 2.1391102798732065
Validation loss: 2.588417742325758

Epoch: 5| Step: 1
Training loss: 1.8516663469897434
Validation loss: 2.584842553794781

Epoch: 5| Step: 2
Training loss: 1.5282789718350422
Validation loss: 2.586280750032238

Epoch: 5| Step: 3
Training loss: 1.952762844841941
Validation loss: 2.569799996310866

Epoch: 5| Step: 4
Training loss: 2.417164214206379
Validation loss: 2.604244175075391

Epoch: 5| Step: 5
Training loss: 2.2092950873915886
Validation loss: 2.610498403521307

Epoch: 5| Step: 6
Training loss: 1.8900301919776081
Validation loss: 2.595051247532326

Epoch: 5| Step: 7
Training loss: 1.6422984716376123
Validation loss: 2.606576294297858

Epoch: 5| Step: 8
Training loss: 1.8607472076620573
Validation loss: 2.599322304374574

Epoch: 5| Step: 9
Training loss: 1.9483600934521097
Validation loss: 2.610671956476646

Epoch: 5| Step: 10
Training loss: 1.832701082737442
Validation loss: 2.573867496033618

Epoch: 5| Step: 11
Training loss: 1.2592402819193553
Validation loss: 2.58188940784944

Epoch: 146| Step: 0
Training loss: 1.8364284427119442
Validation loss: 2.5578735891110624

Epoch: 5| Step: 1
Training loss: 2.0423968300507536
Validation loss: 2.5902114653145887

Epoch: 5| Step: 2
Training loss: 1.864717901335883
Validation loss: 2.5729524761801965

Epoch: 5| Step: 3
Training loss: 1.7471607882088975
Validation loss: 2.579819709875762

Epoch: 5| Step: 4
Training loss: 1.9305946596181431
Validation loss: 2.593447700180426

Epoch: 5| Step: 5
Training loss: 1.788404985232605
Validation loss: 2.5760678725112203

Epoch: 5| Step: 6
Training loss: 1.9551533656928621
Validation loss: 2.607181453216965

Epoch: 5| Step: 7
Training loss: 1.8207928592655835
Validation loss: 2.538615405504398

Epoch: 5| Step: 8
Training loss: 2.786790622375751
Validation loss: 2.5917110778666825

Epoch: 5| Step: 9
Training loss: 2.0347944586049795
Validation loss: 2.5974334716874563

Epoch: 5| Step: 10
Training loss: 1.6927810966306982
Validation loss: 2.550380295557134

Epoch: 5| Step: 11
Training loss: 1.179833055825885
Validation loss: 2.5239192435879225

Epoch: 147| Step: 0
Training loss: 1.8587762205099756
Validation loss: 2.581482791024872

Epoch: 5| Step: 1
Training loss: 2.1347187173197306
Validation loss: 2.5433878165113506

Epoch: 5| Step: 2
Training loss: 2.263615947358343
Validation loss: 2.546850543694588

Epoch: 5| Step: 3
Training loss: 2.20495053674835
Validation loss: 2.5659814112327672

Epoch: 5| Step: 4
Training loss: 1.8136912410375041
Validation loss: 2.5566779382371014

Epoch: 5| Step: 5
Training loss: 1.8388577874784635
Validation loss: 2.554405721820829

Epoch: 5| Step: 6
Training loss: 2.0043430856103415
Validation loss: 2.5598389679707054

Epoch: 5| Step: 7
Training loss: 2.0986565561491295
Validation loss: 2.5817426596227793

Epoch: 5| Step: 8
Training loss: 1.8054157455633322
Validation loss: 2.5833929436994563

Epoch: 5| Step: 9
Training loss: 1.4539422639038138
Validation loss: 2.5825268091445555

Epoch: 5| Step: 10
Training loss: 1.6546224118436044
Validation loss: 2.6242332322573843

Epoch: 5| Step: 11
Training loss: 0.6970931408821721
Validation loss: 2.6107756801388056

Epoch: 148| Step: 0
Training loss: 1.865236100600478
Validation loss: 2.5906757036868058

Epoch: 5| Step: 1
Training loss: 2.6180363886834543
Validation loss: 2.582479571704504

Epoch: 5| Step: 2
Training loss: 1.5558495707278415
Validation loss: 2.581675367890683

Epoch: 5| Step: 3
Training loss: 1.6703213754816009
Validation loss: 2.5586111713621964

Epoch: 5| Step: 4
Training loss: 2.1585855412749955
Validation loss: 2.552905831176748

Epoch: 5| Step: 5
Training loss: 2.246466617318368
Validation loss: 2.5330451714127062

Epoch: 5| Step: 6
Training loss: 2.115547586712312
Validation loss: 2.5322037889638596

Epoch: 5| Step: 7
Training loss: 1.9273887254827557
Validation loss: 2.5874604487813277

Epoch: 5| Step: 8
Training loss: 1.5292399701557704
Validation loss: 2.578060769716341

Epoch: 5| Step: 9
Training loss: 1.9991853962389672
Validation loss: 2.5519303970185123

Epoch: 5| Step: 10
Training loss: 1.3835069022769895
Validation loss: 2.6069409368592242

Epoch: 5| Step: 11
Training loss: 1.1842521120599778
Validation loss: 2.5988956716522447

Epoch: 149| Step: 0
Training loss: 2.2831135284361195
Validation loss: 2.5808101619529755

Epoch: 5| Step: 1
Training loss: 1.7894693103683685
Validation loss: 2.631603820039089

Epoch: 5| Step: 2
Training loss: 1.518185055998712
Validation loss: 2.637854252959962

Epoch: 5| Step: 3
Training loss: 2.16524277874181
Validation loss: 2.633843651096101

Epoch: 5| Step: 4
Training loss: 1.5234572971720484
Validation loss: 2.6619849881475677

Epoch: 5| Step: 5
Training loss: 2.3062828619871953
Validation loss: 2.653326010905598

Epoch: 5| Step: 6
Training loss: 1.9011490534581885
Validation loss: 2.6261750535531045

Epoch: 5| Step: 7
Training loss: 1.94717122330258
Validation loss: 2.624176482798765

Epoch: 5| Step: 8
Training loss: 1.7396069903868538
Validation loss: 2.579056376983771

Epoch: 5| Step: 9
Training loss: 1.7400208416052323
Validation loss: 2.5566974824936546

Epoch: 5| Step: 10
Training loss: 2.052987211065877
Validation loss: 2.5503801475415244

Epoch: 5| Step: 11
Training loss: 1.5217175286696762
Validation loss: 2.5591748458605728

Epoch: 150| Step: 0
Training loss: 1.8477384456231456
Validation loss: 2.56773500383517

Epoch: 5| Step: 1
Training loss: 2.2314005440325895
Validation loss: 2.569021258143605

Epoch: 5| Step: 2
Training loss: 2.193385680288051
Validation loss: 2.559354627230849

Epoch: 5| Step: 3
Training loss: 1.8116260263025137
Validation loss: 2.560167057005619

Epoch: 5| Step: 4
Training loss: 1.843398238425351
Validation loss: 2.5416870559333167

Epoch: 5| Step: 5
Training loss: 1.4396571683741834
Validation loss: 2.5564610491294095

Epoch: 5| Step: 6
Training loss: 2.309836838810012
Validation loss: 2.5733709217469785

Epoch: 5| Step: 7
Training loss: 1.5530802791305
Validation loss: 2.569872380754305

Epoch: 5| Step: 8
Training loss: 2.356204397230754
Validation loss: 2.5937527461209755

Epoch: 5| Step: 9
Training loss: 1.3524843280610526
Validation loss: 2.6220610492336665

Epoch: 5| Step: 10
Training loss: 2.4662575030128124
Validation loss: 2.6036735080429203

Epoch: 5| Step: 11
Training loss: 1.3516055414479669
Validation loss: 2.606417817187174

Epoch: 151| Step: 0
Training loss: 1.8019939981121407
Validation loss: 2.5799559439857713

Epoch: 5| Step: 1
Training loss: 2.148498312349569
Validation loss: 2.5887205124800703

Epoch: 5| Step: 2
Training loss: 1.9069886574370352
Validation loss: 2.574682804589077

Epoch: 5| Step: 3
Training loss: 1.6190685444836639
Validation loss: 2.5855267132176007

Epoch: 5| Step: 4
Training loss: 2.0995097859738943
Validation loss: 2.550159801200752

Epoch: 5| Step: 5
Training loss: 2.1979254651609166
Validation loss: 2.556590092147212

Epoch: 5| Step: 6
Training loss: 2.053622705992241
Validation loss: 2.572344621137093

Epoch: 5| Step: 7
Training loss: 1.247575124492975
Validation loss: 2.5544595606974116

Epoch: 5| Step: 8
Training loss: 2.111446578437392
Validation loss: 2.5373192422123574

Epoch: 5| Step: 9
Training loss: 1.6323354653927542
Validation loss: 2.5902352514233367

Epoch: 5| Step: 10
Training loss: 1.681825138119832
Validation loss: 2.5580488444919958

Epoch: 5| Step: 11
Training loss: 2.244863581261481
Validation loss: 2.571323339009496

Epoch: 152| Step: 0
Training loss: 1.763463951181509
Validation loss: 2.5920339292441534

Epoch: 5| Step: 1
Training loss: 1.8661178653490453
Validation loss: 2.6000718799919267

Epoch: 5| Step: 2
Training loss: 1.5305035387089871
Validation loss: 2.66471581637971

Epoch: 5| Step: 3
Training loss: 1.8658917771466377
Validation loss: 2.6578788886580096

Epoch: 5| Step: 4
Training loss: 2.2535002291492847
Validation loss: 2.705578221849106

Epoch: 5| Step: 5
Training loss: 1.6467205344332625
Validation loss: 2.662166245007691

Epoch: 5| Step: 6
Training loss: 2.0884345606660912
Validation loss: 2.632591479765751

Epoch: 5| Step: 7
Training loss: 2.1315800386095134
Validation loss: 2.6221991385999197

Epoch: 5| Step: 8
Training loss: 2.083040547460198
Validation loss: 2.626157350323625

Epoch: 5| Step: 9
Training loss: 2.056426729996356
Validation loss: 2.571635739525153

Epoch: 5| Step: 10
Training loss: 1.7869432716096298
Validation loss: 2.537467056210896

Epoch: 5| Step: 11
Training loss: 1.4548209353503667
Validation loss: 2.575894082193382

Epoch: 153| Step: 0
Training loss: 2.08673526210386
Validation loss: 2.5598092645008315

Epoch: 5| Step: 1
Training loss: 2.1454388030478264
Validation loss: 2.5657278874312404

Epoch: 5| Step: 2
Training loss: 1.8335663762952563
Validation loss: 2.5785419512273893

Epoch: 5| Step: 3
Training loss: 2.25502406917338
Validation loss: 2.5807064580190917

Epoch: 5| Step: 4
Training loss: 1.4215658501539254
Validation loss: 2.5588513349013624

Epoch: 5| Step: 5
Training loss: 1.794920945193244
Validation loss: 2.592754264803759

Epoch: 5| Step: 6
Training loss: 1.8981770780300546
Validation loss: 2.5539019132141467

Epoch: 5| Step: 7
Training loss: 1.9819447812415216
Validation loss: 2.5696016621532625

Epoch: 5| Step: 8
Training loss: 2.0628444499601626
Validation loss: 2.5615388339189917

Epoch: 5| Step: 9
Training loss: 1.8934778804851982
Validation loss: 2.596478149657584

Epoch: 5| Step: 10
Training loss: 1.4195529295756968
Validation loss: 2.621717444176897

Epoch: 5| Step: 11
Training loss: 1.4539457894861996
Validation loss: 2.662924559865073

Epoch: 154| Step: 0
Training loss: 1.6053423680962673
Validation loss: 2.730832717351424

Epoch: 5| Step: 1
Training loss: 1.7873091455753534
Validation loss: 2.788547058632252

Epoch: 5| Step: 2
Training loss: 1.5078850763277238
Validation loss: 2.7833800106836364

Epoch: 5| Step: 3
Training loss: 2.112556714081007
Validation loss: 2.779590104219263

Epoch: 5| Step: 4
Training loss: 1.8608684792839023
Validation loss: 2.7348186205719407

Epoch: 5| Step: 5
Training loss: 1.7141275843849304
Validation loss: 2.657103463111069

Epoch: 5| Step: 6
Training loss: 1.2919475291081872
Validation loss: 2.631791513949205

Epoch: 5| Step: 7
Training loss: 1.85893231419406
Validation loss: 2.6318411124608505

Epoch: 5| Step: 8
Training loss: 2.0130045809137
Validation loss: 2.5799624474636293

Epoch: 5| Step: 9
Training loss: 2.498442641605433
Validation loss: 2.5729009200526765

Epoch: 5| Step: 10
Training loss: 2.485648734382496
Validation loss: 2.576099713837786

Epoch: 5| Step: 11
Training loss: 1.8026960871010236
Validation loss: 2.5721547598422223

Epoch: 155| Step: 0
Training loss: 2.2323913305133734
Validation loss: 2.576050765878475

Epoch: 5| Step: 1
Training loss: 2.126886315956021
Validation loss: 2.6039787199227113

Epoch: 5| Step: 2
Training loss: 1.8215392730902165
Validation loss: 2.5872625238905074

Epoch: 5| Step: 3
Training loss: 2.7004898545276443
Validation loss: 2.6249865841901157

Epoch: 5| Step: 4
Training loss: 1.4045441771852454
Validation loss: 2.6003199446194563

Epoch: 5| Step: 5
Training loss: 1.9405072776974461
Validation loss: 2.5598390320031594

Epoch: 5| Step: 6
Training loss: 1.3851270109942981
Validation loss: 2.5600052257511825

Epoch: 5| Step: 7
Training loss: 1.4672192652374545
Validation loss: 2.5962046456144385

Epoch: 5| Step: 8
Training loss: 1.8385790712119598
Validation loss: 2.5873334176809637

Epoch: 5| Step: 9
Training loss: 2.238977666766476
Validation loss: 2.608609050939302

Epoch: 5| Step: 10
Training loss: 1.5438492592472621
Validation loss: 2.641151646571506

Epoch: 5| Step: 11
Training loss: 1.9815628671156984
Validation loss: 2.637479876641859

Epoch: 156| Step: 0
Training loss: 1.8387806406586567
Validation loss: 2.640096325592079

Epoch: 5| Step: 1
Training loss: 1.4339678117818546
Validation loss: 2.618051392045717

Epoch: 5| Step: 2
Training loss: 2.1882938579399043
Validation loss: 2.5940677762220115

Epoch: 5| Step: 3
Training loss: 1.9735017380939925
Validation loss: 2.593035729809282

Epoch: 5| Step: 4
Training loss: 2.1647093319194655
Validation loss: 2.5535288836402583

Epoch: 5| Step: 5
Training loss: 1.6623687721030798
Validation loss: 2.5559433077669915

Epoch: 5| Step: 6
Training loss: 1.8096270976907185
Validation loss: 2.584788663662591

Epoch: 5| Step: 7
Training loss: 1.4987777657756576
Validation loss: 2.5855462257502393

Epoch: 5| Step: 8
Training loss: 1.773861603293893
Validation loss: 2.548782716543925

Epoch: 5| Step: 9
Training loss: 1.8959715726427464
Validation loss: 2.5607070659360356

Epoch: 5| Step: 10
Training loss: 2.199568779905598
Validation loss: 2.5422765568110677

Epoch: 5| Step: 11
Training loss: 2.1398834280546315
Validation loss: 2.5818122005220374

Epoch: 157| Step: 0
Training loss: 1.9122867988978571
Validation loss: 2.605313175862201

Epoch: 5| Step: 1
Training loss: 1.5499728231200987
Validation loss: 2.6051731161131637

Epoch: 5| Step: 2
Training loss: 1.9746056923610256
Validation loss: 2.63530656461448

Epoch: 5| Step: 3
Training loss: 2.341363938426294
Validation loss: 2.645451418028082

Epoch: 5| Step: 4
Training loss: 1.6596387348254609
Validation loss: 2.650957564623107

Epoch: 5| Step: 5
Training loss: 1.7712007777146008
Validation loss: 2.664461380079339

Epoch: 5| Step: 6
Training loss: 1.7821930513758706
Validation loss: 2.6113196529535365

Epoch: 5| Step: 7
Training loss: 2.1198661722372476
Validation loss: 2.609841333623513

Epoch: 5| Step: 8
Training loss: 1.6992313077616072
Validation loss: 2.627061511218085

Epoch: 5| Step: 9
Training loss: 1.619950371558983
Validation loss: 2.6001049728171215

Epoch: 5| Step: 10
Training loss: 1.9680621444147959
Validation loss: 2.57954316485401

Epoch: 5| Step: 11
Training loss: 1.0193233935813548
Validation loss: 2.549995176616171

Epoch: 158| Step: 0
Training loss: 2.256356162323693
Validation loss: 2.587684141354678

Epoch: 5| Step: 1
Training loss: 1.4586233486447657
Validation loss: 2.5729619239708397

Epoch: 5| Step: 2
Training loss: 2.545897688315003
Validation loss: 2.5983559108395125

Epoch: 5| Step: 3
Training loss: 1.5417973574668298
Validation loss: 2.5946808718734853

Epoch: 5| Step: 4
Training loss: 1.4271032605787046
Validation loss: 2.563999934947062

Epoch: 5| Step: 5
Training loss: 1.6178076840277986
Validation loss: 2.606888128506864

Epoch: 5| Step: 6
Training loss: 1.8370700670563478
Validation loss: 2.58743541240707

Epoch: 5| Step: 7
Training loss: 1.9431023969344832
Validation loss: 2.590228681692786

Epoch: 5| Step: 8
Training loss: 1.6656911697269978
Validation loss: 2.595838475770791

Epoch: 5| Step: 9
Training loss: 1.8283791650656978
Validation loss: 2.6309009143747284

Epoch: 5| Step: 10
Training loss: 1.7741763554576226
Validation loss: 2.593431660063774

Epoch: 5| Step: 11
Training loss: 1.3568675274601443
Validation loss: 2.594957729269723

Epoch: 159| Step: 0
Training loss: 2.025460075578196
Validation loss: 2.578909340430666

Epoch: 5| Step: 1
Training loss: 1.8830167414264887
Validation loss: 2.5862079720933364

Epoch: 5| Step: 2
Training loss: 1.3991819989241148
Validation loss: 2.57059621356255

Epoch: 5| Step: 3
Training loss: 1.6893464335892339
Validation loss: 2.5817129926812217

Epoch: 5| Step: 4
Training loss: 2.0077047949969535
Validation loss: 2.5924730987833007

Epoch: 5| Step: 5
Training loss: 1.8392800279442112
Validation loss: 2.5645189782834508

Epoch: 5| Step: 6
Training loss: 1.845371180157738
Validation loss: 2.582514926778634

Epoch: 5| Step: 7
Training loss: 1.4349768512466992
Validation loss: 2.563877386818385

Epoch: 5| Step: 8
Training loss: 1.683142440031279
Validation loss: 2.5244224602309346

Epoch: 5| Step: 9
Training loss: 2.1027901052664864
Validation loss: 2.569966491011968

Epoch: 5| Step: 10
Training loss: 2.233356056762028
Validation loss: 2.591865759027346

Epoch: 5| Step: 11
Training loss: 0.8819502611711043
Validation loss: 2.612456928701218

Epoch: 160| Step: 0
Training loss: 1.7412558489370595
Validation loss: 2.6234987371044345

Epoch: 5| Step: 1
Training loss: 2.44430472475577
Validation loss: 2.6617862638736525

Epoch: 5| Step: 2
Training loss: 1.6308547699457814
Validation loss: 2.720050431332133

Epoch: 5| Step: 3
Training loss: 2.0271773371082276
Validation loss: 2.7592366641467376

Epoch: 5| Step: 4
Training loss: 1.994902133787952
Validation loss: 2.8006805763612785

Epoch: 5| Step: 5
Training loss: 2.121487013748992
Validation loss: 2.7860297482505008

Epoch: 5| Step: 6
Training loss: 1.7954844526076141
Validation loss: 2.698509097258495

Epoch: 5| Step: 7
Training loss: 1.3037500725633668
Validation loss: 2.6340056752148824

Epoch: 5| Step: 8
Training loss: 1.8777068626335691
Validation loss: 2.592300902636346

Epoch: 5| Step: 9
Training loss: 1.859662586699762
Validation loss: 2.5876502735158065

Epoch: 5| Step: 10
Training loss: 1.3847161245174613
Validation loss: 2.5656027462637305

Epoch: 5| Step: 11
Training loss: 1.6357067685064588
Validation loss: 2.5650794917176873

Epoch: 161| Step: 0
Training loss: 2.1568599335844243
Validation loss: 2.5464953781259254

Epoch: 5| Step: 1
Training loss: 2.4279664251717885
Validation loss: 2.5633640305781427

Epoch: 5| Step: 2
Training loss: 2.0394870126155955
Validation loss: 2.5593698969639918

Epoch: 5| Step: 3
Training loss: 1.6856781343735459
Validation loss: 2.540412802004793

Epoch: 5| Step: 4
Training loss: 1.778633739454522
Validation loss: 2.581408223035822

Epoch: 5| Step: 5
Training loss: 1.4763566130950683
Validation loss: 2.5871404748193845

Epoch: 5| Step: 6
Training loss: 2.351482706838973
Validation loss: 2.569743134919518

Epoch: 5| Step: 7
Training loss: 1.3633796634512125
Validation loss: 2.594246782274209

Epoch: 5| Step: 8
Training loss: 1.3218704602319125
Validation loss: 2.593932321567298

Epoch: 5| Step: 9
Training loss: 1.606985670304754
Validation loss: 2.6012919211748446

Epoch: 5| Step: 10
Training loss: 1.2526962764550358
Validation loss: 2.609063740971122

Epoch: 5| Step: 11
Training loss: 1.8837012887996374
Validation loss: 2.6238111725524997

Epoch: 162| Step: 0
Training loss: 2.2436276373265653
Validation loss: 2.608754009888971

Epoch: 5| Step: 1
Training loss: 2.253327558197807
Validation loss: 2.5556175529923144

Epoch: 5| Step: 2
Training loss: 1.6633292001788835
Validation loss: 2.567599142717782

Epoch: 5| Step: 3
Training loss: 1.3103148117063232
Validation loss: 2.5807362712578827

Epoch: 5| Step: 4
Training loss: 1.493165739069734
Validation loss: 2.552110918376044

Epoch: 5| Step: 5
Training loss: 1.7188011855393215
Validation loss: 2.556048474999355

Epoch: 5| Step: 6
Training loss: 1.352081816466215
Validation loss: 2.5449338353018227

Epoch: 5| Step: 7
Training loss: 1.7296853111136077
Validation loss: 2.552491510926968

Epoch: 5| Step: 8
Training loss: 1.8133680961352825
Validation loss: 2.581520711082411

Epoch: 5| Step: 9
Training loss: 1.9567286091779785
Validation loss: 2.5874784436456713

Epoch: 5| Step: 10
Training loss: 1.729694408482209
Validation loss: 2.5564937758230393

Epoch: 5| Step: 11
Training loss: 1.9358176649195489
Validation loss: 2.6036385127773083

Epoch: 163| Step: 0
Training loss: 1.3456951966072912
Validation loss: 2.5899955892954893

Epoch: 5| Step: 1
Training loss: 1.031708124300453
Validation loss: 2.592434154852695

Epoch: 5| Step: 2
Training loss: 2.2382887062893912
Validation loss: 2.619358706989859

Epoch: 5| Step: 3
Training loss: 1.9648581290050713
Validation loss: 2.6270232804584275

Epoch: 5| Step: 4
Training loss: 2.2318663485788526
Validation loss: 2.6094415545779754

Epoch: 5| Step: 5
Training loss: 2.4717280135598165
Validation loss: 2.570282828672804

Epoch: 5| Step: 6
Training loss: 1.7267208113091501
Validation loss: 2.58117225197367

Epoch: 5| Step: 7
Training loss: 1.9336861020006728
Validation loss: 2.54624740887602

Epoch: 5| Step: 8
Training loss: 1.4589314278796255
Validation loss: 2.5934260541393117

Epoch: 5| Step: 9
Training loss: 1.6483441367082998
Validation loss: 2.5701988102312683

Epoch: 5| Step: 10
Training loss: 1.1684629995701366
Validation loss: 2.5547810303096123

Epoch: 5| Step: 11
Training loss: 1.433624849319949
Validation loss: 2.5689155160216197

Epoch: 164| Step: 0
Training loss: 1.5378482889322107
Validation loss: 2.5930106572351335

Epoch: 5| Step: 1
Training loss: 2.1169298303765953
Validation loss: 2.602319025086173

Epoch: 5| Step: 2
Training loss: 2.20127173859814
Validation loss: 2.581310581392305

Epoch: 5| Step: 3
Training loss: 1.6678954919097848
Validation loss: 2.569784981840418

Epoch: 5| Step: 4
Training loss: 1.6598697190693754
Validation loss: 2.607280732143475

Epoch: 5| Step: 5
Training loss: 2.0653025919451045
Validation loss: 2.60057483670249

Epoch: 5| Step: 6
Training loss: 1.7855615468779589
Validation loss: 2.626993727813395

Epoch: 5| Step: 7
Training loss: 1.1781115584277035
Validation loss: 2.5946072919637992

Epoch: 5| Step: 8
Training loss: 1.680244885603016
Validation loss: 2.6218735150411443

Epoch: 5| Step: 9
Training loss: 1.613507345026236
Validation loss: 2.645057073745359

Epoch: 5| Step: 10
Training loss: 1.5939609163630915
Validation loss: 2.635750833567605

Epoch: 5| Step: 11
Training loss: 2.653818790588161
Validation loss: 2.6271654537191433

Epoch: 165| Step: 0
Training loss: 1.3359452632210018
Validation loss: 2.624866644938497

Epoch: 5| Step: 1
Training loss: 2.290224372832819
Validation loss: 2.575126437752659

Epoch: 5| Step: 2
Training loss: 1.7191839883991527
Validation loss: 2.5989634081243738

Epoch: 5| Step: 3
Training loss: 1.3726136567352547
Validation loss: 2.5816683146243893

Epoch: 5| Step: 4
Training loss: 2.075400380492729
Validation loss: 2.571491998897514

Epoch: 5| Step: 5
Training loss: 1.5888513565447113
Validation loss: 2.603493948195415

Epoch: 5| Step: 6
Training loss: 1.8319405409230112
Validation loss: 2.6048520305304304

Epoch: 5| Step: 7
Training loss: 1.812724000966617
Validation loss: 2.6080190710463094

Epoch: 5| Step: 8
Training loss: 1.7375011279424943
Validation loss: 2.60061901041417

Epoch: 5| Step: 9
Training loss: 1.7488482636226692
Validation loss: 2.5780810496890054

Epoch: 5| Step: 10
Training loss: 1.7368957484249326
Validation loss: 2.5977412293571547

Epoch: 5| Step: 11
Training loss: 1.157529741321212
Validation loss: 2.579671796461707

Epoch: 166| Step: 0
Training loss: 1.9949289644831316
Validation loss: 2.639335676832677

Epoch: 5| Step: 1
Training loss: 1.91238996650459
Validation loss: 2.6638135411491612

Epoch: 5| Step: 2
Training loss: 1.901940336280396
Validation loss: 2.692425158950218

Epoch: 5| Step: 3
Training loss: 1.459989515554329
Validation loss: 2.6609061813676744

Epoch: 5| Step: 4
Training loss: 1.3703341213769362
Validation loss: 2.6647391518037007

Epoch: 5| Step: 5
Training loss: 1.8824163629562378
Validation loss: 2.679558160476078

Epoch: 5| Step: 6
Training loss: 2.0626294644499743
Validation loss: 2.6220116502769497

Epoch: 5| Step: 7
Training loss: 1.7611271780600162
Validation loss: 2.608661047596838

Epoch: 5| Step: 8
Training loss: 1.2713231044518487
Validation loss: 2.5884986633372

Epoch: 5| Step: 9
Training loss: 1.8898481554261515
Validation loss: 2.588898641173868

Epoch: 5| Step: 10
Training loss: 1.6433796599604884
Validation loss: 2.563745014000453

Epoch: 5| Step: 11
Training loss: 1.6636879369565396
Validation loss: 2.619375872116168

Epoch: 167| Step: 0
Training loss: 1.6526015060344077
Validation loss: 2.557637311077733

Epoch: 5| Step: 1
Training loss: 1.5612922578442183
Validation loss: 2.58331219731165

Epoch: 5| Step: 2
Training loss: 2.1689515781440902
Validation loss: 2.586855296197925

Epoch: 5| Step: 3
Training loss: 1.816553581579455
Validation loss: 2.5821556680763895

Epoch: 5| Step: 4
Training loss: 1.8436109846046513
Validation loss: 2.5656018556951823

Epoch: 5| Step: 5
Training loss: 1.904707112262197
Validation loss: 2.59031840137152

Epoch: 5| Step: 6
Training loss: 1.3736663766527568
Validation loss: 2.5592289881031087

Epoch: 5| Step: 7
Training loss: 1.4788962999141144
Validation loss: 2.608705107231501

Epoch: 5| Step: 8
Training loss: 1.933200618968117
Validation loss: 2.6330447712363827

Epoch: 5| Step: 9
Training loss: 1.817846764773911
Validation loss: 2.654824528891275

Epoch: 5| Step: 10
Training loss: 1.5361669576624686
Validation loss: 2.6533119651748307

Epoch: 5| Step: 11
Training loss: 1.5559597464750676
Validation loss: 2.7128456538596875

Epoch: 168| Step: 0
Training loss: 1.5037041070012256
Validation loss: 2.7004757947608593

Epoch: 5| Step: 1
Training loss: 2.2524989344248225
Validation loss: 2.6841301971827227

Epoch: 5| Step: 2
Training loss: 1.6410205182658835
Validation loss: 2.6789895308113083

Epoch: 5| Step: 3
Training loss: 1.8196672597575416
Validation loss: 2.6780270435783

Epoch: 5| Step: 4
Training loss: 1.9256947712699843
Validation loss: 2.682129278483314

Epoch: 5| Step: 5
Training loss: 1.4537927057450335
Validation loss: 2.6506658161489454

Epoch: 5| Step: 6
Training loss: 1.2798563192609826
Validation loss: 2.6491111378781427

Epoch: 5| Step: 7
Training loss: 2.1987488483471482
Validation loss: 2.6219549304052725

Epoch: 5| Step: 8
Training loss: 1.5813224052166315
Validation loss: 2.6003058551657126

Epoch: 5| Step: 9
Training loss: 1.517160326226221
Validation loss: 2.5908094190935764

Epoch: 5| Step: 10
Training loss: 1.8252089629012358
Validation loss: 2.604607854982081

Epoch: 5| Step: 11
Training loss: 1.033498393739911
Validation loss: 2.5871035932571997

Epoch: 169| Step: 0
Training loss: 1.6449201038054835
Validation loss: 2.5913863385148277

Epoch: 5| Step: 1
Training loss: 1.734996031501035
Validation loss: 2.625147327194276

Epoch: 5| Step: 2
Training loss: 2.1382574646657906
Validation loss: 2.614710486816964

Epoch: 5| Step: 3
Training loss: 1.5381139940397424
Validation loss: 2.597196017154086

Epoch: 5| Step: 4
Training loss: 1.7396291928518666
Validation loss: 2.6042352908947266

Epoch: 5| Step: 5
Training loss: 1.677491495761833
Validation loss: 2.612821320876752

Epoch: 5| Step: 6
Training loss: 1.844982704970598
Validation loss: 2.615994998781647

Epoch: 5| Step: 7
Training loss: 1.8969507871567606
Validation loss: 2.6553960287610083

Epoch: 5| Step: 8
Training loss: 1.561582982858585
Validation loss: 2.642292981906263

Epoch: 5| Step: 9
Training loss: 1.8486495785524704
Validation loss: 2.639384725204835

Epoch: 5| Step: 10
Training loss: 1.2087969164732628
Validation loss: 2.65269404604275

Epoch: 5| Step: 11
Training loss: 1.5241143703648479
Validation loss: 2.6188462386128815

Epoch: 170| Step: 0
Training loss: 1.7307988319147944
Validation loss: 2.5959121776830716

Epoch: 5| Step: 1
Training loss: 1.9782564646830867
Validation loss: 2.6313138256351

Epoch: 5| Step: 2
Training loss: 1.9844831302047854
Validation loss: 2.5838412405955746

Epoch: 5| Step: 3
Training loss: 0.9971702592842291
Validation loss: 2.6066134110260215

Epoch: 5| Step: 4
Training loss: 1.7139947479683921
Validation loss: 2.607389631322025

Epoch: 5| Step: 5
Training loss: 2.1450995020696118
Validation loss: 2.6084989078261813

Epoch: 5| Step: 6
Training loss: 1.4571204273249974
Validation loss: 2.6162125702677614

Epoch: 5| Step: 7
Training loss: 1.6405936828530723
Validation loss: 2.5906423466143473

Epoch: 5| Step: 8
Training loss: 1.5590331717749242
Validation loss: 2.572117230830386

Epoch: 5| Step: 9
Training loss: 1.7540338210713144
Validation loss: 2.6385467296320346

Epoch: 5| Step: 10
Training loss: 1.6351952939536873
Validation loss: 2.624831830041991

Epoch: 5| Step: 11
Training loss: 0.8536038909594619
Validation loss: 2.585196654963829

Epoch: 171| Step: 0
Training loss: 1.478477406984174
Validation loss: 2.6338152159836343

Epoch: 5| Step: 1
Training loss: 1.55058575606282
Validation loss: 2.6271040427571233

Epoch: 5| Step: 2
Training loss: 1.8926886023369665
Validation loss: 2.6082708207816223

Epoch: 5| Step: 3
Training loss: 1.8782180509191966
Validation loss: 2.6463361898040763

Epoch: 5| Step: 4
Training loss: 2.050269886022273
Validation loss: 2.6365292930825306

Epoch: 5| Step: 5
Training loss: 1.1122251621181654
Validation loss: 2.6174963033510985

Epoch: 5| Step: 6
Training loss: 1.3263461148797488
Validation loss: 2.60354031214608

Epoch: 5| Step: 7
Training loss: 1.5950233010530284
Validation loss: 2.6061580190428697

Epoch: 5| Step: 8
Training loss: 1.4846071563673613
Validation loss: 2.6042127465303855

Epoch: 5| Step: 9
Training loss: 1.8114166310536994
Validation loss: 2.5720131107357562

Epoch: 5| Step: 10
Training loss: 1.6882674273587457
Validation loss: 2.6273792398675866

Epoch: 5| Step: 11
Training loss: 3.423611970857964
Validation loss: 2.597001886768118

Epoch: 172| Step: 0
Training loss: 1.3883509955975195
Validation loss: 2.6255080965067776

Epoch: 5| Step: 1
Training loss: 2.0179853000767087
Validation loss: 2.61575655368994

Epoch: 5| Step: 2
Training loss: 1.7721846267927137
Validation loss: 2.6032304695869706

Epoch: 5| Step: 3
Training loss: 1.7028143363182455
Validation loss: 2.5858628146017124

Epoch: 5| Step: 4
Training loss: 1.3044929587779854
Validation loss: 2.6594437229826315

Epoch: 5| Step: 5
Training loss: 2.1382149822320717
Validation loss: 2.6028705264175196

Epoch: 5| Step: 6
Training loss: 1.576673387724172
Validation loss: 2.629892038772289

Epoch: 5| Step: 7
Training loss: 1.5747317100779343
Validation loss: 2.6614028056424455

Epoch: 5| Step: 8
Training loss: 1.9648708091374205
Validation loss: 2.6565010999288017

Epoch: 5| Step: 9
Training loss: 1.2516879129617207
Validation loss: 2.609473072424716

Epoch: 5| Step: 10
Training loss: 1.6438891681892789
Validation loss: 2.627675018010637

Epoch: 5| Step: 11
Training loss: 0.6246476849323678
Validation loss: 2.627048935968783

Epoch: 173| Step: 0
Training loss: 1.7792474968064358
Validation loss: 2.594135948942443

Epoch: 5| Step: 1
Training loss: 1.7704321313285707
Validation loss: 2.582977306279567

Epoch: 5| Step: 2
Training loss: 1.9390196839307796
Validation loss: 2.5823102522336754

Epoch: 5| Step: 3
Training loss: 1.4540340902380318
Validation loss: 2.578044558724737

Epoch: 5| Step: 4
Training loss: 1.363335725849045
Validation loss: 2.5779795364803766

Epoch: 5| Step: 5
Training loss: 1.6881013434573384
Validation loss: 2.6119875896669216

Epoch: 5| Step: 6
Training loss: 1.9721399821415764
Validation loss: 2.58943029510536

Epoch: 5| Step: 7
Training loss: 1.7562831074590857
Validation loss: 2.5911476608091006

Epoch: 5| Step: 8
Training loss: 1.5028153859993456
Validation loss: 2.5962717138198768

Epoch: 5| Step: 9
Training loss: 1.0025503300996588
Validation loss: 2.635163726026989

Epoch: 5| Step: 10
Training loss: 1.9915225845423976
Validation loss: 2.62945981595485

Epoch: 5| Step: 11
Training loss: 0.7441381419383195
Validation loss: 2.6117585730210076

Epoch: 174| Step: 0
Training loss: 2.141172575700493
Validation loss: 2.6559041901424525

Epoch: 5| Step: 1
Training loss: 1.4146791241235437
Validation loss: 2.6597215051680467

Epoch: 5| Step: 2
Training loss: 1.1943570974975506
Validation loss: 2.6373701369449285

Epoch: 5| Step: 3
Training loss: 1.6326166062822345
Validation loss: 2.6402125177496

Epoch: 5| Step: 4
Training loss: 1.7622684543101719
Validation loss: 2.643565269611562

Epoch: 5| Step: 5
Training loss: 1.5782509177555901
Validation loss: 2.6355933493291612

Epoch: 5| Step: 6
Training loss: 1.3674072089087383
Validation loss: 2.636677517038711

Epoch: 5| Step: 7
Training loss: 1.8684056350688365
Validation loss: 2.6290907679321722

Epoch: 5| Step: 8
Training loss: 1.4456690992728194
Validation loss: 2.597125312257411

Epoch: 5| Step: 9
Training loss: 2.074123919199633
Validation loss: 2.597324539459588

Epoch: 5| Step: 10
Training loss: 1.6988442194551914
Validation loss: 2.620416185074993

Epoch: 5| Step: 11
Training loss: 0.8332570676872955
Validation loss: 2.599008079363604

Epoch: 175| Step: 0
Training loss: 1.9461050602152772
Validation loss: 2.5934103394829116

Epoch: 5| Step: 1
Training loss: 1.274848250165969
Validation loss: 2.5973095272869156

Epoch: 5| Step: 2
Training loss: 1.095322541151399
Validation loss: 2.588843150910435

Epoch: 5| Step: 3
Training loss: 1.5262783071031452
Validation loss: 2.5997525354140625

Epoch: 5| Step: 4
Training loss: 1.651191471977168
Validation loss: 2.5665098698724322

Epoch: 5| Step: 5
Training loss: 1.0186512390195093
Validation loss: 2.62058739051485

Epoch: 5| Step: 6
Training loss: 1.8944703397102822
Validation loss: 2.635490870027958

Epoch: 5| Step: 7
Training loss: 1.6677597593932016
Validation loss: 2.6788361126445777

Epoch: 5| Step: 8
Training loss: 2.094046272837743
Validation loss: 2.677144446337194

Epoch: 5| Step: 9
Training loss: 2.504765736481821
Validation loss: 2.6622332261686346

Epoch: 5| Step: 10
Training loss: 1.4524020786074066
Validation loss: 2.6977134717669977

Epoch: 5| Step: 11
Training loss: 0.7961354283137824
Validation loss: 2.6596128494100606

Testing loss: 2.279219776894231
