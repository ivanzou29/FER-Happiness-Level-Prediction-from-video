Epoch: 1| Step: 0
Training loss: 7.875778644153795
Validation loss: 7.743627204567972

Epoch: 6| Step: 1
Training loss: 7.88227072631856
Validation loss: 7.731801354277464

Epoch: 6| Step: 2
Training loss: 8.12354300713485
Validation loss: 7.714856523591746

Epoch: 6| Step: 3
Training loss: 8.27563747013542
Validation loss: 7.698808823963789

Epoch: 6| Step: 4
Training loss: 7.683815670250981
Validation loss: 7.682676461275887

Epoch: 6| Step: 5
Training loss: 7.810377641405516
Validation loss: 7.668100167753325

Epoch: 6| Step: 6
Training loss: 7.897925778196475
Validation loss: 7.650840207834926

Epoch: 6| Step: 7
Training loss: 7.871941350920001
Validation loss: 7.634499599310791

Epoch: 6| Step: 8
Training loss: 7.5559356194939555
Validation loss: 7.61880925577688

Epoch: 6| Step: 9
Training loss: 7.647013920440714
Validation loss: 7.601204811768599

Epoch: 6| Step: 10
Training loss: 8.095647758782329
Validation loss: 7.583006030833928

Epoch: 6| Step: 11
Training loss: 6.953109089693876
Validation loss: 7.568549686787344

Epoch: 6| Step: 12
Training loss: 7.693954363416636
Validation loss: 7.550600131606236

Epoch: 6| Step: 13
Training loss: 7.060965852454695
Validation loss: 7.537739175404264

Epoch: 2| Step: 0
Training loss: 7.961021834685781
Validation loss: 7.519700476653682

Epoch: 6| Step: 1
Training loss: 8.291079808717997
Validation loss: 7.500505048913008

Epoch: 6| Step: 2
Training loss: 7.02528229821613
Validation loss: 7.485007156507952

Epoch: 6| Step: 3
Training loss: 7.281343778734877
Validation loss: 7.465346493269221

Epoch: 6| Step: 4
Training loss: 7.644822666264589
Validation loss: 7.446406569257264

Epoch: 6| Step: 5
Training loss: 7.85301894918196
Validation loss: 7.429105322030613

Epoch: 6| Step: 6
Training loss: 7.204281000480667
Validation loss: 7.408189779749492

Epoch: 6| Step: 7
Training loss: 7.068905516514987
Validation loss: 7.388852445214569

Epoch: 6| Step: 8
Training loss: 6.4405646575366475
Validation loss: 7.362182988594072

Epoch: 6| Step: 9
Training loss: 7.338411769073773
Validation loss: 7.3426076446944775

Epoch: 6| Step: 10
Training loss: 7.103052702643646
Validation loss: 7.318431871874815

Epoch: 6| Step: 11
Training loss: 8.03914791317599
Validation loss: 7.29495564716357

Epoch: 6| Step: 12
Training loss: 7.71788236243598
Validation loss: 7.272390976629885

Epoch: 6| Step: 13
Training loss: 7.725403670840858
Validation loss: 7.24516117370364

Epoch: 3| Step: 0
Training loss: 7.252349209827068
Validation loss: 7.21646416653857

Epoch: 6| Step: 1
Training loss: 7.263702072486974
Validation loss: 7.188724535138204

Epoch: 6| Step: 2
Training loss: 8.654442994492591
Validation loss: 7.158974430151352

Epoch: 6| Step: 3
Training loss: 7.609692326064391
Validation loss: 7.132810004220994

Epoch: 6| Step: 4
Training loss: 6.679347693293871
Validation loss: 7.099534330185679

Epoch: 6| Step: 5
Training loss: 7.0781570669630955
Validation loss: 7.0696939833625

Epoch: 6| Step: 6
Training loss: 7.214429478919232
Validation loss: 7.036088332795159

Epoch: 6| Step: 7
Training loss: 6.8772704103531614
Validation loss: 7.0038539631344445

Epoch: 6| Step: 8
Training loss: 6.920440318481199
Validation loss: 6.955943018745144

Epoch: 6| Step: 9
Training loss: 6.858954553600671
Validation loss: 6.929646855650488

Epoch: 6| Step: 10
Training loss: 6.840371051115821
Validation loss: 6.8850836584345565

Epoch: 6| Step: 11
Training loss: 7.001831360081413
Validation loss: 6.8464060931717166

Epoch: 6| Step: 12
Training loss: 6.329086419057836
Validation loss: 6.81107859117144

Epoch: 6| Step: 13
Training loss: 6.783623767730574
Validation loss: 6.765653003755074

Epoch: 4| Step: 0
Training loss: 7.4427048879143385
Validation loss: 6.724716021700081

Epoch: 6| Step: 1
Training loss: 6.4275328872058894
Validation loss: 6.678358538454475

Epoch: 6| Step: 2
Training loss: 6.893752999188349
Validation loss: 6.633454644069956

Epoch: 6| Step: 3
Training loss: 6.46194114408429
Validation loss: 6.57881471426556

Epoch: 6| Step: 4
Training loss: 6.823452885258588
Validation loss: 6.529624116018975

Epoch: 6| Step: 5
Training loss: 6.243247084272209
Validation loss: 6.488605782822902

Epoch: 6| Step: 6
Training loss: 5.788924448526855
Validation loss: 6.429991531445595

Epoch: 6| Step: 7
Training loss: 5.771063991669757
Validation loss: 6.381422908680857

Epoch: 6| Step: 8
Training loss: 6.66940512044699
Validation loss: 6.311082737520102

Epoch: 6| Step: 9
Training loss: 6.443186794350645
Validation loss: 6.262210743328578

Epoch: 6| Step: 10
Training loss: 5.984561767850897
Validation loss: 6.1884751241878035

Epoch: 6| Step: 11
Training loss: 6.04247318891607
Validation loss: 6.135939735002259

Epoch: 6| Step: 12
Training loss: 6.5903328814099345
Validation loss: 6.0692993784934055

Epoch: 6| Step: 13
Training loss: 6.896383150276667
Validation loss: 6.008133937932617

Epoch: 5| Step: 0
Training loss: 5.205976191873294
Validation loss: 5.932247636166667

Epoch: 6| Step: 1
Training loss: 5.93820925040222
Validation loss: 5.884112845517166

Epoch: 6| Step: 2
Training loss: 5.660317997171322
Validation loss: 5.812450176285256

Epoch: 6| Step: 3
Training loss: 5.902809392308363
Validation loss: 5.724549512616328

Epoch: 6| Step: 4
Training loss: 6.411004214366193
Validation loss: 5.648797171060139

Epoch: 6| Step: 5
Training loss: 5.721308235003763
Validation loss: 5.562573578880095

Epoch: 6| Step: 6
Training loss: 5.417411439996512
Validation loss: 5.482403233189197

Epoch: 6| Step: 7
Training loss: 6.003989482791643
Validation loss: 5.419464806881744

Epoch: 6| Step: 8
Training loss: 4.977774048890882
Validation loss: 5.315333938180112

Epoch: 6| Step: 9
Training loss: 5.511866858835693
Validation loss: 5.223449783698726

Epoch: 6| Step: 10
Training loss: 5.485900319016074
Validation loss: 5.137436423793932

Epoch: 6| Step: 11
Training loss: 5.0738473569819895
Validation loss: 5.033430081294508

Epoch: 6| Step: 12
Training loss: 5.50998596161925
Validation loss: 4.9435418420718955

Epoch: 6| Step: 13
Training loss: 4.865433917400363
Validation loss: 4.835018960204847

Epoch: 6| Step: 0
Training loss: 5.239693106480345
Validation loss: 4.747142953113518

Epoch: 6| Step: 1
Training loss: 4.939304070507072
Validation loss: 4.631451995055027

Epoch: 6| Step: 2
Training loss: 5.262999290285057
Validation loss: 4.546112136379711

Epoch: 6| Step: 3
Training loss: 4.175167541796999
Validation loss: 4.384987539043867

Epoch: 6| Step: 4
Training loss: 4.519697946228983
Validation loss: 4.254218420198974

Epoch: 6| Step: 5
Training loss: 4.662331929386344
Validation loss: 4.164813004471285

Epoch: 6| Step: 6
Training loss: 3.80183582632517
Validation loss: 4.038595402540233

Epoch: 6| Step: 7
Training loss: 3.5370836262263374
Validation loss: 3.8852042002876424

Epoch: 6| Step: 8
Training loss: 4.208934073800355
Validation loss: 3.7843915851291543

Epoch: 6| Step: 9
Training loss: 3.8580496670703375
Validation loss: 3.6832367557850327

Epoch: 6| Step: 10
Training loss: 2.5300317352174213
Validation loss: 3.525863342433942

Epoch: 6| Step: 11
Training loss: 3.5102720749655862
Validation loss: 3.3883397008257803

Epoch: 6| Step: 12
Training loss: 3.054602892550316
Validation loss: 3.2664050763029313

Epoch: 6| Step: 13
Training loss: 3.1312489401078856
Validation loss: 3.184081319906281

Epoch: 7| Step: 0
Training loss: 2.9983296512611544
Validation loss: 3.081287302303396

Epoch: 6| Step: 1
Training loss: 3.183662947388313
Validation loss: 3.0041787528660397

Epoch: 6| Step: 2
Training loss: 3.0305370003512655
Validation loss: 2.9201313738903263

Epoch: 6| Step: 3
Training loss: 2.9047926663654176
Validation loss: 2.8578356853675726

Epoch: 6| Step: 4
Training loss: 2.6468544338828
Validation loss: 2.826145118388121

Epoch: 6| Step: 5
Training loss: 2.9630969383714945
Validation loss: 2.7771023888207247

Epoch: 6| Step: 6
Training loss: 3.113120731824895
Validation loss: 2.7896124959099855

Epoch: 6| Step: 7
Training loss: 2.248790733897234
Validation loss: 2.687332384663727

Epoch: 6| Step: 8
Training loss: 3.2406655289737496
Validation loss: 2.805298082625481

Epoch: 6| Step: 9
Training loss: 3.3361157407648205
Validation loss: 2.843543775298094

Epoch: 6| Step: 10
Training loss: 1.9850402678049452
Validation loss: 2.822367939749898

Epoch: 6| Step: 11
Training loss: 2.7577915785214744
Validation loss: 2.8199752366441904

Epoch: 6| Step: 12
Training loss: 3.411375896049919
Validation loss: 2.813508559343737

Epoch: 6| Step: 13
Training loss: 2.5021671438883915
Validation loss: 2.8714298804089693

Epoch: 8| Step: 0
Training loss: 2.4947207977698995
Validation loss: 2.8621553199620307

Epoch: 6| Step: 1
Training loss: 2.820702016038073
Validation loss: 2.876942655497258

Epoch: 6| Step: 2
Training loss: 3.512353485418397
Validation loss: 2.898844852252747

Epoch: 6| Step: 3
Training loss: 2.668719385762135
Validation loss: 2.9488941948771163

Epoch: 6| Step: 4
Training loss: 3.098065997391653
Validation loss: 2.8092635995788546

Epoch: 6| Step: 5
Training loss: 2.960455621243386
Validation loss: 2.754532157165977

Epoch: 6| Step: 6
Training loss: 3.6236768478163035
Validation loss: 2.8740500387226002

Epoch: 6| Step: 7
Training loss: 3.0202503211759577
Validation loss: 2.8011960937633273

Epoch: 6| Step: 8
Training loss: 2.838964103039122
Validation loss: 2.7659063681023937

Epoch: 6| Step: 9
Training loss: 2.5212180944796585
Validation loss: 2.771426952323665

Epoch: 6| Step: 10
Training loss: 3.4300896967067223
Validation loss: 2.7299596396456556

Epoch: 6| Step: 11
Training loss: 2.380366135812144
Validation loss: 2.7311956032137874

Epoch: 6| Step: 12
Training loss: 2.578944867713691
Validation loss: 2.753184252305934

Epoch: 6| Step: 13
Training loss: 2.4558477174225266
Validation loss: 2.7375128044630217

Epoch: 9| Step: 0
Training loss: 3.085278558999348
Validation loss: 2.7108163504230283

Epoch: 6| Step: 1
Training loss: 2.7768719965961224
Validation loss: 2.795186987884927

Epoch: 6| Step: 2
Training loss: 2.7172953781113893
Validation loss: 2.763374936312541

Epoch: 6| Step: 3
Training loss: 1.9122095598075821
Validation loss: 2.8127832623287907

Epoch: 6| Step: 4
Training loss: 3.538231893251193
Validation loss: 2.734111504347577

Epoch: 6| Step: 5
Training loss: 2.1143814015552342
Validation loss: 2.7144320608066406

Epoch: 6| Step: 6
Training loss: 3.0225123683023245
Validation loss: 2.7673008469598743

Epoch: 6| Step: 7
Training loss: 3.0352426563271817
Validation loss: 2.6966338526124645

Epoch: 6| Step: 8
Training loss: 2.773484608424742
Validation loss: 2.6901734384121787

Epoch: 6| Step: 9
Training loss: 3.112587347681707
Validation loss: 2.7565767511174486

Epoch: 6| Step: 10
Training loss: 2.7976472949811737
Validation loss: 2.8025309029156267

Epoch: 6| Step: 11
Training loss: 2.9563090602789983
Validation loss: 2.7307061495560605

Epoch: 6| Step: 12
Training loss: 2.1981544426276782
Validation loss: 2.730539476518277

Epoch: 6| Step: 13
Training loss: 2.4299713655833335
Validation loss: 2.7082381060560454

Epoch: 10| Step: 0
Training loss: 2.261604688334455
Validation loss: 2.725671675493153

Epoch: 6| Step: 1
Training loss: 2.1035686688124016
Validation loss: 2.737889064505904

Epoch: 6| Step: 2
Training loss: 2.7523454720813607
Validation loss: 2.659191148845075

Epoch: 6| Step: 3
Training loss: 4.051254200708082
Validation loss: 2.7053487520688786

Epoch: 6| Step: 4
Training loss: 2.9450657586882585
Validation loss: 2.7421942671849

Epoch: 6| Step: 5
Training loss: 2.527991941366751
Validation loss: 2.751076993146105

Epoch: 6| Step: 6
Training loss: 3.915918454608018
Validation loss: 2.67523392697272

Epoch: 6| Step: 7
Training loss: 2.617623728366414
Validation loss: 2.6970787121690796

Epoch: 6| Step: 8
Training loss: 2.728422126451452
Validation loss: 2.6778810007883735

Epoch: 6| Step: 9
Training loss: 1.8820096278739915
Validation loss: 2.7408394538607697

Epoch: 6| Step: 10
Training loss: 2.661185223824473
Validation loss: 2.733204516616328

Epoch: 6| Step: 11
Training loss: 2.1953282474482467
Validation loss: 2.6961177783957604

Epoch: 6| Step: 12
Training loss: 2.679580908787925
Validation loss: 2.715747168821493

Epoch: 6| Step: 13
Training loss: 3.0008804300926237
Validation loss: 2.772086503060361

Epoch: 11| Step: 0
Training loss: 1.8749484372996363
Validation loss: 2.74087459655704

Epoch: 6| Step: 1
Training loss: 3.0037643339566764
Validation loss: 2.6744607679012167

Epoch: 6| Step: 2
Training loss: 2.7363179306722576
Validation loss: 2.7695118518288107

Epoch: 6| Step: 3
Training loss: 2.410127166622033
Validation loss: 2.728000003242306

Epoch: 6| Step: 4
Training loss: 1.9221655153106643
Validation loss: 2.7136687958579393

Epoch: 6| Step: 5
Training loss: 2.6128062456592445
Validation loss: 2.754683725257461

Epoch: 6| Step: 6
Training loss: 2.9634628598283514
Validation loss: 2.7800518269590606

Epoch: 6| Step: 7
Training loss: 3.3619596252740243
Validation loss: 2.671131290790472

Epoch: 6| Step: 8
Training loss: 3.663542427942918
Validation loss: 2.7340393150998463

Epoch: 6| Step: 9
Training loss: 2.6181512225475436
Validation loss: 2.7653082398591486

Epoch: 6| Step: 10
Training loss: 2.2125845122495176
Validation loss: 2.672330598116117

Epoch: 6| Step: 11
Training loss: 2.643453223342574
Validation loss: 2.7719669938904574

Epoch: 6| Step: 12
Training loss: 2.9094899483661316
Validation loss: 2.676282552645563

Epoch: 6| Step: 13
Training loss: 3.3167492944083077
Validation loss: 2.6977354943753302

Epoch: 12| Step: 0
Training loss: 3.326225777601993
Validation loss: 2.738524494622738

Epoch: 6| Step: 1
Training loss: 2.655241651439481
Validation loss: 2.7365964240198575

Epoch: 6| Step: 2
Training loss: 2.682358903258226
Validation loss: 2.7014817110494915

Epoch: 6| Step: 3
Training loss: 2.354672627949468
Validation loss: 2.6897777397483247

Epoch: 6| Step: 4
Training loss: 3.09599192141679
Validation loss: 2.689938747247506

Epoch: 6| Step: 5
Training loss: 2.4213312338464235
Validation loss: 2.7519257767245455

Epoch: 6| Step: 6
Training loss: 3.3741876542888036
Validation loss: 2.726002035313287

Epoch: 6| Step: 7
Training loss: 3.5315255926836753
Validation loss: 2.7404985434204603

Epoch: 6| Step: 8
Training loss: 2.596168860911018
Validation loss: 2.706663135125373

Epoch: 6| Step: 9
Training loss: 2.993218704894788
Validation loss: 2.6910124159788396

Epoch: 6| Step: 10
Training loss: 2.578000337303264
Validation loss: 2.7766083692984744

Epoch: 6| Step: 11
Training loss: 2.285022907768296
Validation loss: 2.7195862401151216

Epoch: 6| Step: 12
Training loss: 1.742207685276668
Validation loss: 2.693840384091787

Epoch: 6| Step: 13
Training loss: 1.5869812185309473
Validation loss: 2.6994491309535498

Epoch: 13| Step: 0
Training loss: 2.0250678251234198
Validation loss: 2.7686935542476085

Epoch: 6| Step: 1
Training loss: 2.3878668538200083
Validation loss: 2.725056827314264

Epoch: 6| Step: 2
Training loss: 2.3498684176678455
Validation loss: 2.673776229009253

Epoch: 6| Step: 3
Training loss: 2.5152286193563786
Validation loss: 2.644790253570608

Epoch: 6| Step: 4
Training loss: 3.090528255603181
Validation loss: 2.6967324464914566

Epoch: 6| Step: 5
Training loss: 2.5073059140793617
Validation loss: 2.7207474368344258

Epoch: 6| Step: 6
Training loss: 2.419231818260627
Validation loss: 2.736999255154125

Epoch: 6| Step: 7
Training loss: 2.840549218706059
Validation loss: 2.696961242310543

Epoch: 6| Step: 8
Training loss: 3.7382238497258533
Validation loss: 2.6970409950749334

Epoch: 6| Step: 9
Training loss: 2.3442419934456913
Validation loss: 2.7868708201243937

Epoch: 6| Step: 10
Training loss: 2.949770197565367
Validation loss: 2.6811613991539924

Epoch: 6| Step: 11
Training loss: 2.9693146821104164
Validation loss: 2.7017538749728454

Epoch: 6| Step: 12
Training loss: 2.728214670566869
Validation loss: 2.7064371709432056

Epoch: 6| Step: 13
Training loss: 2.9523081785160263
Validation loss: 2.803667738477718

Epoch: 14| Step: 0
Training loss: 4.221480778515864
Validation loss: 2.6217042123959984

Epoch: 6| Step: 1
Training loss: 2.0994786705319965
Validation loss: 2.7651871156756256

Epoch: 6| Step: 2
Training loss: 2.7194935450560576
Validation loss: 2.675211319939682

Epoch: 6| Step: 3
Training loss: 3.4469326647364396
Validation loss: 2.6949538577393186

Epoch: 6| Step: 4
Training loss: 2.2023015208016794
Validation loss: 2.707725461576106

Epoch: 6| Step: 5
Training loss: 1.5511272054142107
Validation loss: 2.672432898858713

Epoch: 6| Step: 6
Training loss: 2.6022325174178866
Validation loss: 2.684327885336775

Epoch: 6| Step: 7
Training loss: 2.9645548844374257
Validation loss: 2.6580604815790974

Epoch: 6| Step: 8
Training loss: 2.690351171438253
Validation loss: 2.7088232673203416

Epoch: 6| Step: 9
Training loss: 2.030841023280951
Validation loss: 2.711441125178874

Epoch: 6| Step: 10
Training loss: 2.7152536645345964
Validation loss: 2.690199361312685

Epoch: 6| Step: 11
Training loss: 2.705659240661083
Validation loss: 2.7750322798263385

Epoch: 6| Step: 12
Training loss: 2.3532761321351874
Validation loss: 2.6281367134985323

Epoch: 6| Step: 13
Training loss: 2.7420172570573818
Validation loss: 2.669813710653918

Epoch: 15| Step: 0
Training loss: 2.847153523761269
Validation loss: 2.6105173165132367

Epoch: 6| Step: 1
Training loss: 2.3310135708695747
Validation loss: 2.6888472115314115

Epoch: 6| Step: 2
Training loss: 2.882356602459216
Validation loss: 2.6688006525049546

Epoch: 6| Step: 3
Training loss: 1.9821845753525025
Validation loss: 2.7295072187761615

Epoch: 6| Step: 4
Training loss: 2.794295245393105
Validation loss: 2.663176462863484

Epoch: 6| Step: 5
Training loss: 1.6593044833557513
Validation loss: 2.7162885960591323

Epoch: 6| Step: 6
Training loss: 2.9053353131541204
Validation loss: 2.7555946026448757

Epoch: 6| Step: 7
Training loss: 3.2822272888927344
Validation loss: 2.691240509496038

Epoch: 6| Step: 8
Training loss: 2.7104079199221487
Validation loss: 2.680769780569452

Epoch: 6| Step: 9
Training loss: 3.2905344082062653
Validation loss: 2.680647000766324

Epoch: 6| Step: 10
Training loss: 2.9240371945333816
Validation loss: 2.6523413978832155

Epoch: 6| Step: 11
Training loss: 2.4625008597590305
Validation loss: 2.672821397835321

Epoch: 6| Step: 12
Training loss: 3.2379184054861447
Validation loss: 2.6843573951958066

Epoch: 6| Step: 13
Training loss: 2.013972114801796
Validation loss: 2.6720998345971996

Epoch: 16| Step: 0
Training loss: 2.8370950821657392
Validation loss: 2.6398453247992855

Epoch: 6| Step: 1
Training loss: 2.7445023810705917
Validation loss: 2.7945823863114945

Epoch: 6| Step: 2
Training loss: 2.8001495457631713
Validation loss: 2.680810839323759

Epoch: 6| Step: 3
Training loss: 2.9359975990368747
Validation loss: 2.6571355802023255

Epoch: 6| Step: 4
Training loss: 2.2893899416507537
Validation loss: 2.750472880656186

Epoch: 6| Step: 5
Training loss: 2.0196399770130484
Validation loss: 2.6994190721387383

Epoch: 6| Step: 6
Training loss: 1.8995953706244333
Validation loss: 2.679000269605626

Epoch: 6| Step: 7
Training loss: 2.817614165381935
Validation loss: 2.5854444312224523

Epoch: 6| Step: 8
Training loss: 2.3625739434190325
Validation loss: 2.726939964945729

Epoch: 6| Step: 9
Training loss: 2.1760998805908742
Validation loss: 2.7140979794540616

Epoch: 6| Step: 10
Training loss: 3.1745341762734456
Validation loss: 2.6900363309172355

Epoch: 6| Step: 11
Training loss: 2.8647656931774788
Validation loss: 2.7384133880701786

Epoch: 6| Step: 12
Training loss: 2.6333622118014266
Validation loss: 2.706438117944416

Epoch: 6| Step: 13
Training loss: 3.069100720783527
Validation loss: 2.7329843236271465

Epoch: 17| Step: 0
Training loss: 2.8711573587235244
Validation loss: 2.6969666054006227

Epoch: 6| Step: 1
Training loss: 2.2597004214204746
Validation loss: 2.6359029529827405

Epoch: 6| Step: 2
Training loss: 2.4296727808662877
Validation loss: 2.6277465680907803

Epoch: 6| Step: 3
Training loss: 1.353387075157341
Validation loss: 2.674245292345373

Epoch: 6| Step: 4
Training loss: 2.7735936940227393
Validation loss: 2.6731696756628494

Epoch: 6| Step: 5
Training loss: 2.815110669171178
Validation loss: 2.6123335887225245

Epoch: 6| Step: 6
Training loss: 2.0643410990625575
Validation loss: 2.5946569733721234

Epoch: 6| Step: 7
Training loss: 3.5148659119730854
Validation loss: 2.6538701335435992

Epoch: 6| Step: 8
Training loss: 3.087026669440501
Validation loss: 2.6841163552097256

Epoch: 6| Step: 9
Training loss: 2.7841721517567257
Validation loss: 2.6611827003399107

Epoch: 6| Step: 10
Training loss: 2.8751421354237707
Validation loss: 2.70856096827164

Epoch: 6| Step: 11
Training loss: 2.5902412305156415
Validation loss: 2.690751954501357

Epoch: 6| Step: 12
Training loss: 2.455011699205791
Validation loss: 2.685721333703665

Epoch: 6| Step: 13
Training loss: 3.346067392057055
Validation loss: 2.6525704123606846

Epoch: 18| Step: 0
Training loss: 2.5724309753707435
Validation loss: 2.6513617021985154

Epoch: 6| Step: 1
Training loss: 2.8249615421884506
Validation loss: 2.638740363598119

Epoch: 6| Step: 2
Training loss: 2.2936601002717496
Validation loss: 2.7035115871464512

Epoch: 6| Step: 3
Training loss: 3.0608770001339045
Validation loss: 2.6460511025347455

Epoch: 6| Step: 4
Training loss: 2.9075388357860334
Validation loss: 2.731228192996706

Epoch: 6| Step: 5
Training loss: 2.68904805509244
Validation loss: 2.6357489264601

Epoch: 6| Step: 6
Training loss: 2.848006196883243
Validation loss: 2.6816958361316137

Epoch: 6| Step: 7
Training loss: 2.751744150710905
Validation loss: 2.645178440975936

Epoch: 6| Step: 8
Training loss: 2.1738237379223477
Validation loss: 2.71627355746455

Epoch: 6| Step: 9
Training loss: 3.671195758734502
Validation loss: 2.6112208281342784

Epoch: 6| Step: 10
Training loss: 2.3920714546426516
Validation loss: 2.687195886364546

Epoch: 6| Step: 11
Training loss: 2.543950373375484
Validation loss: 2.6519214891393603

Epoch: 6| Step: 12
Training loss: 2.0257599805604642
Validation loss: 2.634705569462044

Epoch: 6| Step: 13
Training loss: 2.2322725661601783
Validation loss: 2.6624358012738147

Epoch: 19| Step: 0
Training loss: 2.3137716972203437
Validation loss: 2.5932270426734143

Epoch: 6| Step: 1
Training loss: 2.652849511535336
Validation loss: 2.655102156417676

Epoch: 6| Step: 2
Training loss: 1.5850302069399913
Validation loss: 2.6240943224292783

Epoch: 6| Step: 3
Training loss: 2.5199993319737595
Validation loss: 2.655127942821411

Epoch: 6| Step: 4
Training loss: 2.124060591449472
Validation loss: 2.7189449810397535

Epoch: 6| Step: 5
Training loss: 2.4727250943837285
Validation loss: 2.6382720215116118

Epoch: 6| Step: 6
Training loss: 3.0363974371551405
Validation loss: 2.674263984816924

Epoch: 6| Step: 7
Training loss: 2.488449306591768
Validation loss: 2.718184854516962

Epoch: 6| Step: 8
Training loss: 3.6971788270236132
Validation loss: 2.6869968416436536

Epoch: 6| Step: 9
Training loss: 2.2837101460671403
Validation loss: 2.649838252499458

Epoch: 6| Step: 10
Training loss: 2.8117730790740505
Validation loss: 2.665660449765348

Epoch: 6| Step: 11
Training loss: 2.3379385552078236
Validation loss: 2.626928892342925

Epoch: 6| Step: 12
Training loss: 3.4958504192554627
Validation loss: 2.690570289921023

Epoch: 6| Step: 13
Training loss: 2.446685697947535
Validation loss: 2.736662440147652

Epoch: 20| Step: 0
Training loss: 2.6971602588489367
Validation loss: 2.6670793472289653

Epoch: 6| Step: 1
Training loss: 2.6252595682328526
Validation loss: 2.682561980518308

Epoch: 6| Step: 2
Training loss: 2.3899887335284284
Validation loss: 2.6935605533478726

Epoch: 6| Step: 3
Training loss: 2.1387586044771623
Validation loss: 2.7382055282099707

Epoch: 6| Step: 4
Training loss: 1.959930891064224
Validation loss: 2.680407191130876

Epoch: 6| Step: 5
Training loss: 2.574891901061973
Validation loss: 2.638736749468504

Epoch: 6| Step: 6
Training loss: 2.946218983515673
Validation loss: 2.708182731744947

Epoch: 6| Step: 7
Training loss: 2.2303357727709425
Validation loss: 2.6411682111910078

Epoch: 6| Step: 8
Training loss: 3.1453281695927364
Validation loss: 2.6350097090743128

Epoch: 6| Step: 9
Training loss: 3.7511775393226263
Validation loss: 2.676936050301951

Epoch: 6| Step: 10
Training loss: 2.4486840742894356
Validation loss: 2.7024412374492157

Epoch: 6| Step: 11
Training loss: 3.202868939841401
Validation loss: 2.640656465421929

Epoch: 6| Step: 12
Training loss: 2.2252623928381974
Validation loss: 2.676696398092097

Epoch: 6| Step: 13
Training loss: 2.531648580935655
Validation loss: 2.6109292889140034

Epoch: 21| Step: 0
Training loss: 2.832036974670938
Validation loss: 2.625914611123466

Epoch: 6| Step: 1
Training loss: 2.523344717298232
Validation loss: 2.6204983091280374

Epoch: 6| Step: 2
Training loss: 3.1742182752987738
Validation loss: 2.582430502321697

Epoch: 6| Step: 3
Training loss: 2.724381850939138
Validation loss: 2.660321455058082

Epoch: 6| Step: 4
Training loss: 2.405585655550724
Validation loss: 2.7036835786088838

Epoch: 6| Step: 5
Training loss: 2.5495861577829158
Validation loss: 2.693501624319841

Epoch: 6| Step: 6
Training loss: 2.3763785126122223
Validation loss: 2.6909896609380484

Epoch: 6| Step: 7
Training loss: 2.7769962313347953
Validation loss: 2.698865632781974

Epoch: 6| Step: 8
Training loss: 2.4555240247417625
Validation loss: 2.6969948793173346

Epoch: 6| Step: 9
Training loss: 2.8267071789711387
Validation loss: 2.6625217520432685

Epoch: 6| Step: 10
Training loss: 2.537927649781152
Validation loss: 2.6328199407244095

Epoch: 6| Step: 11
Training loss: 2.350424050563698
Validation loss: 2.6749973606084714

Epoch: 6| Step: 12
Training loss: 3.0989930394043106
Validation loss: 2.706026801933076

Epoch: 6| Step: 13
Training loss: 2.855628221810173
Validation loss: 2.636874483007052

Epoch: 22| Step: 0
Training loss: 1.928146055530104
Validation loss: 2.6541442752374707

Epoch: 6| Step: 1
Training loss: 3.9645769903333035
Validation loss: 2.617365528333614

Epoch: 6| Step: 2
Training loss: 2.5420923554025325
Validation loss: 2.575074967586219

Epoch: 6| Step: 3
Training loss: 2.7645890186733344
Validation loss: 2.647828788909819

Epoch: 6| Step: 4
Training loss: 2.422988537164984
Validation loss: 2.712171612622083

Epoch: 6| Step: 5
Training loss: 2.6046447823630885
Validation loss: 2.6450420057330057

Epoch: 6| Step: 6
Training loss: 3.0702842342250114
Validation loss: 2.642749150228744

Epoch: 6| Step: 7
Training loss: 2.127402798396669
Validation loss: 2.7798257174051826

Epoch: 6| Step: 8
Training loss: 2.108667325590893
Validation loss: 2.6644806743428506

Epoch: 6| Step: 9
Training loss: 3.101327882439942
Validation loss: 2.692470080068638

Epoch: 6| Step: 10
Training loss: 2.884170667161861
Validation loss: 2.764198438177948

Epoch: 6| Step: 11
Training loss: 2.5603993807634136
Validation loss: 2.6943156292417183

Epoch: 6| Step: 12
Training loss: 2.462014099049735
Validation loss: 2.70330202114709

Epoch: 6| Step: 13
Training loss: 1.8712372217143391
Validation loss: 2.659296540097673

Epoch: 23| Step: 0
Training loss: 3.026822031657647
Validation loss: 2.6610406048866504

Epoch: 6| Step: 1
Training loss: 2.2113913349982015
Validation loss: 2.6182986505527457

Epoch: 6| Step: 2
Training loss: 1.8215172182411226
Validation loss: 2.615376292702003

Epoch: 6| Step: 3
Training loss: 3.062460918566404
Validation loss: 2.634547098918036

Epoch: 6| Step: 4
Training loss: 2.8196321549174086
Validation loss: 2.6633807864117416

Epoch: 6| Step: 5
Training loss: 2.6359813421975455
Validation loss: 2.6522535141140047

Epoch: 6| Step: 6
Training loss: 2.8824002764640038
Validation loss: 2.670565397616843

Epoch: 6| Step: 7
Training loss: 2.116622342624302
Validation loss: 2.6627887503586267

Epoch: 6| Step: 8
Training loss: 2.3953318416563563
Validation loss: 2.6198454687662296

Epoch: 6| Step: 9
Training loss: 3.030527402345134
Validation loss: 2.688446794856164

Epoch: 6| Step: 10
Training loss: 2.8443458687403873
Validation loss: 2.615265933191353

Epoch: 6| Step: 11
Training loss: 3.0236414167849603
Validation loss: 2.6229681598273857

Epoch: 6| Step: 12
Training loss: 2.9371545466751807
Validation loss: 2.6520100731531304

Epoch: 6| Step: 13
Training loss: 2.0212914121368843
Validation loss: 2.61104481581358

Epoch: 24| Step: 0
Training loss: 2.650798903905948
Validation loss: 2.6515820944786466

Epoch: 6| Step: 1
Training loss: 2.98095475180349
Validation loss: 2.596744065516634

Epoch: 6| Step: 2
Training loss: 2.4158887159094666
Validation loss: 2.6217677940544935

Epoch: 6| Step: 3
Training loss: 3.065835809799097
Validation loss: 2.6478103525312187

Epoch: 6| Step: 4
Training loss: 3.3018407080691223
Validation loss: 2.6319578992980044

Epoch: 6| Step: 5
Training loss: 2.711655139754011
Validation loss: 2.733014798405904

Epoch: 6| Step: 6
Training loss: 2.3845942605173907
Validation loss: 2.6633576423667953

Epoch: 6| Step: 7
Training loss: 2.2777756662539903
Validation loss: 2.6802496139800778

Epoch: 6| Step: 8
Training loss: 2.613810532688522
Validation loss: 2.5942462768086836

Epoch: 6| Step: 9
Training loss: 2.1757446505141
Validation loss: 2.6134189176007148

Epoch: 6| Step: 10
Training loss: 2.3259043503674235
Validation loss: 2.6261610460717724

Epoch: 6| Step: 11
Training loss: 2.0892551056572515
Validation loss: 2.673246407233197

Epoch: 6| Step: 12
Training loss: 2.3594215843199646
Validation loss: 2.661820214758621

Epoch: 6| Step: 13
Training loss: 2.8588603239201054
Validation loss: 2.611516945212502

Epoch: 25| Step: 0
Training loss: 1.6038467121176072
Validation loss: 2.6680664670148415

Epoch: 6| Step: 1
Training loss: 2.3794225373666036
Validation loss: 2.6641137648615985

Epoch: 6| Step: 2
Training loss: 2.2964380588263476
Validation loss: 2.608571277120601

Epoch: 6| Step: 3
Training loss: 2.525196796717456
Validation loss: 2.642103484788332

Epoch: 6| Step: 4
Training loss: 2.848506763848632
Validation loss: 2.726143550657336

Epoch: 6| Step: 5
Training loss: 2.986487315134533
Validation loss: 2.680121939895468

Epoch: 6| Step: 6
Training loss: 1.858625501351055
Validation loss: 2.6090656561616714

Epoch: 6| Step: 7
Training loss: 2.5673120488179575
Validation loss: 2.7019115951263495

Epoch: 6| Step: 8
Training loss: 3.472047080815075
Validation loss: 2.689561674078601

Epoch: 6| Step: 9
Training loss: 2.459299856586613
Validation loss: 2.696678957807007

Epoch: 6| Step: 10
Training loss: 3.3570156595082477
Validation loss: 2.6253469480084335

Epoch: 6| Step: 11
Training loss: 2.2140742719575566
Validation loss: 2.6166642610170356

Epoch: 6| Step: 12
Training loss: 2.7457634630898666
Validation loss: 2.6716720771695104

Epoch: 6| Step: 13
Training loss: 2.539435726024604
Validation loss: 2.6667286945122655

Epoch: 26| Step: 0
Training loss: 2.4858466054434407
Validation loss: 2.6582274761668194

Epoch: 6| Step: 1
Training loss: 2.6103846258544854
Validation loss: 2.6627576658550254

Epoch: 6| Step: 2
Training loss: 2.842381242269201
Validation loss: 2.6597705772481905

Epoch: 6| Step: 3
Training loss: 2.5209213325546673
Validation loss: 2.5357126684330797

Epoch: 6| Step: 4
Training loss: 3.119114024718291
Validation loss: 2.623384296361685

Epoch: 6| Step: 5
Training loss: 2.3778215011644894
Validation loss: 2.683183434151689

Epoch: 6| Step: 6
Training loss: 2.6807988923287103
Validation loss: 2.6715579820809587

Epoch: 6| Step: 7
Training loss: 2.5048849064927894
Validation loss: 2.6105895727747916

Epoch: 6| Step: 8
Training loss: 2.3196991903037976
Validation loss: 2.577266912518498

Epoch: 6| Step: 9
Training loss: 2.693482681782411
Validation loss: 2.60211001754855

Epoch: 6| Step: 10
Training loss: 2.94253530528134
Validation loss: 2.6406202748875223

Epoch: 6| Step: 11
Training loss: 2.114359300393305
Validation loss: 2.6563743412610035

Epoch: 6| Step: 12
Training loss: 2.6071082222983915
Validation loss: 2.544065021375725

Epoch: 6| Step: 13
Training loss: 2.570958111505223
Validation loss: 2.61888812785011

Epoch: 27| Step: 0
Training loss: 3.005820350319286
Validation loss: 2.6428064969879363

Epoch: 6| Step: 1
Training loss: 2.981670972104178
Validation loss: 2.683102440130892

Epoch: 6| Step: 2
Training loss: 2.3063363077198087
Validation loss: 2.631819495324915

Epoch: 6| Step: 3
Training loss: 2.296234975899609
Validation loss: 2.726786577841582

Epoch: 6| Step: 4
Training loss: 2.484714220987848
Validation loss: 2.6388759802340838

Epoch: 6| Step: 5
Training loss: 2.813751789839797
Validation loss: 2.6116056748891827

Epoch: 6| Step: 6
Training loss: 2.841142066419268
Validation loss: 2.7042150045423217

Epoch: 6| Step: 7
Training loss: 3.2327059802450195
Validation loss: 2.6691473707473663

Epoch: 6| Step: 8
Training loss: 1.602520837395414
Validation loss: 2.675950316496787

Epoch: 6| Step: 9
Training loss: 2.1714760393317927
Validation loss: 2.6043286438476625

Epoch: 6| Step: 10
Training loss: 2.7878676988798303
Validation loss: 2.6630368612309328

Epoch: 6| Step: 11
Training loss: 2.9575481895203266
Validation loss: 2.6532673863821032

Epoch: 6| Step: 12
Training loss: 2.48362979868754
Validation loss: 2.621629564500083

Epoch: 6| Step: 13
Training loss: 2.7532034335616986
Validation loss: 2.647834056422984

Epoch: 28| Step: 0
Training loss: 2.4289868684667355
Validation loss: 2.649127296482398

Epoch: 6| Step: 1
Training loss: 1.9152239331422345
Validation loss: 2.65142926353628

Epoch: 6| Step: 2
Training loss: 1.6043814808410355
Validation loss: 2.6646995640374205

Epoch: 6| Step: 3
Training loss: 2.7914039336354266
Validation loss: 2.672084227581183

Epoch: 6| Step: 4
Training loss: 2.9902118903771733
Validation loss: 2.6096312802489474

Epoch: 6| Step: 5
Training loss: 1.940679156888402
Validation loss: 2.684789873185078

Epoch: 6| Step: 6
Training loss: 3.1186009312171503
Validation loss: 2.6525557765195824

Epoch: 6| Step: 7
Training loss: 2.978583823502023
Validation loss: 2.659806044087445

Epoch: 6| Step: 8
Training loss: 3.2490841969070776
Validation loss: 2.722945684576553

Epoch: 6| Step: 9
Training loss: 2.8268548631846997
Validation loss: 2.661959969761031

Epoch: 6| Step: 10
Training loss: 2.4889735242478452
Validation loss: 2.609284877172535

Epoch: 6| Step: 11
Training loss: 2.6370868341168836
Validation loss: 2.6969411011599824

Epoch: 6| Step: 12
Training loss: 2.5240984071872155
Validation loss: 2.628567118732501

Epoch: 6| Step: 13
Training loss: 3.0125992374774
Validation loss: 2.5999486918155217

Epoch: 29| Step: 0
Training loss: 2.906564839034764
Validation loss: 2.5858494339282996

Epoch: 6| Step: 1
Training loss: 2.7201047131073013
Validation loss: 2.5103735280320616

Epoch: 6| Step: 2
Training loss: 2.6717217830875213
Validation loss: 2.562521585513126

Epoch: 6| Step: 3
Training loss: 2.975277761106903
Validation loss: 2.5985591380539375

Epoch: 6| Step: 4
Training loss: 1.9349449291820389
Validation loss: 2.6347264276807336

Epoch: 6| Step: 5
Training loss: 2.1295241272941774
Validation loss: 2.6440633249952197

Epoch: 6| Step: 6
Training loss: 1.9612738940094516
Validation loss: 2.602196525471648

Epoch: 6| Step: 7
Training loss: 2.5888379015106087
Validation loss: 2.6199645079569884

Epoch: 6| Step: 8
Training loss: 2.6231664884538803
Validation loss: 2.6464032037540313

Epoch: 6| Step: 9
Training loss: 2.9034636892259083
Validation loss: 2.60835089164731

Epoch: 6| Step: 10
Training loss: 2.090155177219136
Validation loss: 2.6329089259328504

Epoch: 6| Step: 11
Training loss: 2.423975077069765
Validation loss: 2.6425628924817737

Epoch: 6| Step: 12
Training loss: 2.685612570219192
Validation loss: 2.6617378391678255

Epoch: 6| Step: 13
Training loss: 3.3130009110504473
Validation loss: 2.601875645269906

Epoch: 30| Step: 0
Training loss: 2.291821168257451
Validation loss: 2.6636755430143437

Epoch: 6| Step: 1
Training loss: 2.468508358489024
Validation loss: 2.636915140255594

Epoch: 6| Step: 2
Training loss: 2.2251292116172343
Validation loss: 2.6283074538271705

Epoch: 6| Step: 3
Training loss: 2.3990932897609616
Validation loss: 2.6107333030577102

Epoch: 6| Step: 4
Training loss: 2.564580491470097
Validation loss: 2.735873816108642

Epoch: 6| Step: 5
Training loss: 2.5653008761556757
Validation loss: 2.754281395866104

Epoch: 6| Step: 6
Training loss: 2.23093175675454
Validation loss: 2.6086731383658286

Epoch: 6| Step: 7
Training loss: 2.7551188944173512
Validation loss: 2.662057586412465

Epoch: 6| Step: 8
Training loss: 2.298864839142358
Validation loss: 2.60704062504655

Epoch: 6| Step: 9
Training loss: 3.0148032852703595
Validation loss: 2.695239345276485

Epoch: 6| Step: 10
Training loss: 2.9801106769055483
Validation loss: 2.6911075538869347

Epoch: 6| Step: 11
Training loss: 3.0064848112214007
Validation loss: 2.6087911870240017

Epoch: 6| Step: 12
Training loss: 2.8184877869979394
Validation loss: 2.6411176143024635

Epoch: 6| Step: 13
Training loss: 2.7813797824025253
Validation loss: 2.5744417486623496

Epoch: 31| Step: 0
Training loss: 2.499943351103786
Validation loss: 2.6118331264897985

Epoch: 6| Step: 1
Training loss: 2.5612943650848643
Validation loss: 2.585167277437394

Epoch: 6| Step: 2
Training loss: 2.3054195986982524
Validation loss: 2.6566742202989637

Epoch: 6| Step: 3
Training loss: 2.867765862030705
Validation loss: 2.6227849212678844

Epoch: 6| Step: 4
Training loss: 3.000863268942242
Validation loss: 2.6534983126309877

Epoch: 6| Step: 5
Training loss: 2.2523076621190294
Validation loss: 2.658972373574042

Epoch: 6| Step: 6
Training loss: 2.6491709005972583
Validation loss: 2.575403383750793

Epoch: 6| Step: 7
Training loss: 2.3429228276671448
Validation loss: 2.652744792868531

Epoch: 6| Step: 8
Training loss: 3.013273122517883
Validation loss: 2.6836071208415313

Epoch: 6| Step: 9
Training loss: 2.631051490526322
Validation loss: 2.6526999218041745

Epoch: 6| Step: 10
Training loss: 2.8463366136536097
Validation loss: 2.670025428860428

Epoch: 6| Step: 11
Training loss: 1.8550734570706169
Validation loss: 2.6132686445524254

Epoch: 6| Step: 12
Training loss: 3.1298134925533416
Validation loss: 2.5984206219933785

Epoch: 6| Step: 13
Training loss: 2.5909924843552896
Validation loss: 2.684008207711785

Epoch: 32| Step: 0
Training loss: 2.1824791098662186
Validation loss: 2.629363429771956

Epoch: 6| Step: 1
Training loss: 3.3203226964457406
Validation loss: 2.650773899867545

Epoch: 6| Step: 2
Training loss: 2.870216038245409
Validation loss: 2.6763044676448846

Epoch: 6| Step: 3
Training loss: 2.328805913494521
Validation loss: 2.6456809463070754

Epoch: 6| Step: 4
Training loss: 1.9840229352886687
Validation loss: 2.642073104430317

Epoch: 6| Step: 5
Training loss: 2.760397329202733
Validation loss: 2.5848741755800666

Epoch: 6| Step: 6
Training loss: 1.7941526273445967
Validation loss: 2.6406452697337097

Epoch: 6| Step: 7
Training loss: 2.5030573270224634
Validation loss: 2.560258815690977

Epoch: 6| Step: 8
Training loss: 2.729222789701793
Validation loss: 2.592092053091564

Epoch: 6| Step: 9
Training loss: 2.528191496513267
Validation loss: 2.6332846651126993

Epoch: 6| Step: 10
Training loss: 2.9666387178054596
Validation loss: 2.5998776987850665

Epoch: 6| Step: 11
Training loss: 2.948094357009217
Validation loss: 2.637081801298069

Epoch: 6| Step: 12
Training loss: 2.2356540246987806
Validation loss: 2.6435218586343554

Epoch: 6| Step: 13
Training loss: 2.9730631766588456
Validation loss: 2.67210693542472

Epoch: 33| Step: 0
Training loss: 1.7270335249703348
Validation loss: 2.6536843868271407

Epoch: 6| Step: 1
Training loss: 2.7656036203711056
Validation loss: 2.696609730380763

Epoch: 6| Step: 2
Training loss: 3.1807328738814635
Validation loss: 2.5925362362930264

Epoch: 6| Step: 3
Training loss: 3.394796170167998
Validation loss: 2.608058155543047

Epoch: 6| Step: 4
Training loss: 2.3909771229835335
Validation loss: 2.66640429894873

Epoch: 6| Step: 5
Training loss: 2.722463417613118
Validation loss: 2.603785423346733

Epoch: 6| Step: 6
Training loss: 3.217261701768449
Validation loss: 2.6617526783081007

Epoch: 6| Step: 7
Training loss: 2.262887497907493
Validation loss: 2.5523812775333767

Epoch: 6| Step: 8
Training loss: 2.293846677151197
Validation loss: 2.648291164620233

Epoch: 6| Step: 9
Training loss: 2.41501043281908
Validation loss: 2.6280981128238063

Epoch: 6| Step: 10
Training loss: 2.330505792295914
Validation loss: 2.6536714042851606

Epoch: 6| Step: 11
Training loss: 3.3797480774845843
Validation loss: 2.610206425860186

Epoch: 6| Step: 12
Training loss: 2.0186061843334375
Validation loss: 2.6385486723672176

Epoch: 6| Step: 13
Training loss: 2.0151102754315104
Validation loss: 2.545846095471982

Epoch: 34| Step: 0
Training loss: 2.753325965292665
Validation loss: 2.641940178736078

Epoch: 6| Step: 1
Training loss: 2.663647213782671
Validation loss: 2.6413011230802392

Epoch: 6| Step: 2
Training loss: 1.9347635448990685
Validation loss: 2.628658439818139

Epoch: 6| Step: 3
Training loss: 2.8996965907312338
Validation loss: 2.606504296475915

Epoch: 6| Step: 4
Training loss: 2.121835484087587
Validation loss: 2.62767106353219

Epoch: 6| Step: 5
Training loss: 2.715234171286048
Validation loss: 2.688947879018953

Epoch: 6| Step: 6
Training loss: 2.272165368583176
Validation loss: 2.6134965063830378

Epoch: 6| Step: 7
Training loss: 2.4162751461640735
Validation loss: 2.665531383687671

Epoch: 6| Step: 8
Training loss: 2.6875741637886494
Validation loss: 2.6155842591412886

Epoch: 6| Step: 9
Training loss: 2.732911246747482
Validation loss: 2.6658078439902444

Epoch: 6| Step: 10
Training loss: 3.049970726748209
Validation loss: 2.6294230330589263

Epoch: 6| Step: 11
Training loss: 2.6577274477097563
Validation loss: 2.625951783637993

Epoch: 6| Step: 12
Training loss: 2.816746451773372
Validation loss: 2.6505341309443544

Epoch: 6| Step: 13
Training loss: 2.3531527290888827
Validation loss: 2.6498445507256565

Epoch: 35| Step: 0
Training loss: 1.9671794742726536
Validation loss: 2.5731854291974288

Epoch: 6| Step: 1
Training loss: 3.1054598442285823
Validation loss: 2.622038881668773

Epoch: 6| Step: 2
Training loss: 2.738027345909504
Validation loss: 2.664788603065258

Epoch: 6| Step: 3
Training loss: 2.8419655032121263
Validation loss: 2.6477588095283253

Epoch: 6| Step: 4
Training loss: 2.720732306045276
Validation loss: 2.6512356120715395

Epoch: 6| Step: 5
Training loss: 2.2521754450374183
Validation loss: 2.5924327830101714

Epoch: 6| Step: 6
Training loss: 2.552813574708658
Validation loss: 2.6636108134850556

Epoch: 6| Step: 7
Training loss: 2.4398733468876084
Validation loss: 2.636600067858495

Epoch: 6| Step: 8
Training loss: 2.8889544634427353
Validation loss: 2.6436510447807464

Epoch: 6| Step: 9
Training loss: 2.626346696819236
Validation loss: 2.581533271449538

Epoch: 6| Step: 10
Training loss: 2.1483063258961126
Validation loss: 2.5644184157653633

Epoch: 6| Step: 11
Training loss: 1.709211061974565
Validation loss: 2.624047908993011

Epoch: 6| Step: 12
Training loss: 3.129517913352649
Validation loss: 2.662351235784166

Epoch: 6| Step: 13
Training loss: 2.5618304796857125
Validation loss: 2.639105523291197

Epoch: 36| Step: 0
Training loss: 2.2568974208008608
Validation loss: 2.5838543048703024

Epoch: 6| Step: 1
Training loss: 3.2831132230868785
Validation loss: 2.6366670429198926

Epoch: 6| Step: 2
Training loss: 1.8178227633625406
Validation loss: 2.642906873375036

Epoch: 6| Step: 3
Training loss: 2.061671466292415
Validation loss: 2.623914827352356

Epoch: 6| Step: 4
Training loss: 2.6550252446987757
Validation loss: 2.6594623215142255

Epoch: 6| Step: 5
Training loss: 2.950289863957789
Validation loss: 2.652911418080599

Epoch: 6| Step: 6
Training loss: 2.144880645027782
Validation loss: 2.6553625681336706

Epoch: 6| Step: 7
Training loss: 3.280979544983048
Validation loss: 2.6463513105097127

Epoch: 6| Step: 8
Training loss: 2.9718196057472945
Validation loss: 2.6912618818905214

Epoch: 6| Step: 9
Training loss: 2.189524993941992
Validation loss: 2.6301184207668444

Epoch: 6| Step: 10
Training loss: 2.0396407319650005
Validation loss: 2.628920654741097

Epoch: 6| Step: 11
Training loss: 2.0980227698953287
Validation loss: 2.6457611785021005

Epoch: 6| Step: 12
Training loss: 2.092530535950259
Validation loss: 2.6356447797115528

Epoch: 6| Step: 13
Training loss: 3.3886907307652634
Validation loss: 2.682037864948771

Epoch: 37| Step: 0
Training loss: 1.9252872723333811
Validation loss: 2.629114415777542

Epoch: 6| Step: 1
Training loss: 1.9737592880291404
Validation loss: 2.609565666983935

Epoch: 6| Step: 2
Training loss: 2.5107311721850936
Validation loss: 2.6342389235642423

Epoch: 6| Step: 3
Training loss: 2.8082214872763047
Validation loss: 2.6039015571436734

Epoch: 6| Step: 4
Training loss: 3.3513873572481523
Validation loss: 2.615773850690603

Epoch: 6| Step: 5
Training loss: 2.9881172085285237
Validation loss: 2.550504528261248

Epoch: 6| Step: 6
Training loss: 1.8448238801504042
Validation loss: 2.703239482594235

Epoch: 6| Step: 7
Training loss: 2.736759911395603
Validation loss: 2.6037628369343797

Epoch: 6| Step: 8
Training loss: 1.941762358090673
Validation loss: 2.6580040843402184

Epoch: 6| Step: 9
Training loss: 3.083619147448139
Validation loss: 2.60926413538499

Epoch: 6| Step: 10
Training loss: 2.6985947236786068
Validation loss: 2.6149892580554477

Epoch: 6| Step: 11
Training loss: 2.9979244045628692
Validation loss: 2.576927338434952

Epoch: 6| Step: 12
Training loss: 2.6257134330910605
Validation loss: 2.6128361906971334

Epoch: 6| Step: 13
Training loss: 2.2181666507287665
Validation loss: 2.664423391409936

Epoch: 38| Step: 0
Training loss: 1.6724248677072493
Validation loss: 2.6374142028690373

Epoch: 6| Step: 1
Training loss: 2.4284367423816637
Validation loss: 2.6189108493420803

Epoch: 6| Step: 2
Training loss: 2.1100806292274283
Validation loss: 2.6196324026387234

Epoch: 6| Step: 3
Training loss: 2.155764760137294
Validation loss: 2.6892527697475237

Epoch: 6| Step: 4
Training loss: 2.898368567292241
Validation loss: 2.6925961060935655

Epoch: 6| Step: 5
Training loss: 2.7186714248702897
Validation loss: 2.637699892204157

Epoch: 6| Step: 6
Training loss: 3.3018811441769063
Validation loss: 2.7114097777474324

Epoch: 6| Step: 7
Training loss: 2.3718009283790793
Validation loss: 2.6264789290392363

Epoch: 6| Step: 8
Training loss: 2.4051990938952255
Validation loss: 2.6868669814157045

Epoch: 6| Step: 9
Training loss: 2.710818417267015
Validation loss: 2.6812835774249555

Epoch: 6| Step: 10
Training loss: 2.5208905006000606
Validation loss: 2.565589639386719

Epoch: 6| Step: 11
Training loss: 2.7159810490178806
Validation loss: 2.6070940323554685

Epoch: 6| Step: 12
Training loss: 2.7051160238207053
Validation loss: 2.6195922128478233

Epoch: 6| Step: 13
Training loss: 2.9305822201480463
Validation loss: 2.6682565290924627

Epoch: 39| Step: 0
Training loss: 2.61950253255583
Validation loss: 2.5767148795023718

Epoch: 6| Step: 1
Training loss: 1.7630758873266505
Validation loss: 2.6608702326493088

Epoch: 6| Step: 2
Training loss: 1.8582281855556668
Validation loss: 2.630005786512268

Epoch: 6| Step: 3
Training loss: 2.3462307834397187
Validation loss: 2.6297888745513682

Epoch: 6| Step: 4
Training loss: 2.638081787449538
Validation loss: 2.6741563007189093

Epoch: 6| Step: 5
Training loss: 2.670281185816978
Validation loss: 2.629954597144093

Epoch: 6| Step: 6
Training loss: 2.4675426186511187
Validation loss: 2.668079722057456

Epoch: 6| Step: 7
Training loss: 3.293665186678585
Validation loss: 2.6912657503126947

Epoch: 6| Step: 8
Training loss: 2.460000674239896
Validation loss: 2.625747150478556

Epoch: 6| Step: 9
Training loss: 2.0851008991371422
Validation loss: 2.6192374632302546

Epoch: 6| Step: 10
Training loss: 2.0603138290162604
Validation loss: 2.6546317762454334

Epoch: 6| Step: 11
Training loss: 3.4005227191997918
Validation loss: 2.584191246526791

Epoch: 6| Step: 12
Training loss: 2.7046987549863313
Validation loss: 2.680843508006116

Epoch: 6| Step: 13
Training loss: 2.4310097975351046
Validation loss: 2.6177865704463614

Epoch: 40| Step: 0
Training loss: 1.7386398802714331
Validation loss: 2.6519055910524

Epoch: 6| Step: 1
Training loss: 2.8036921443063547
Validation loss: 2.662810366036931

Epoch: 6| Step: 2
Training loss: 2.0761396059272026
Validation loss: 2.6668851633759574

Epoch: 6| Step: 3
Training loss: 1.6527817598752617
Validation loss: 2.622434800788806

Epoch: 6| Step: 4
Training loss: 2.6441610463160106
Validation loss: 2.644882464318309

Epoch: 6| Step: 5
Training loss: 2.4565349617397088
Validation loss: 2.670743795749831

Epoch: 6| Step: 6
Training loss: 2.2745488652221133
Validation loss: 2.604184666889288

Epoch: 6| Step: 7
Training loss: 2.774651232273057
Validation loss: 2.597425705854153

Epoch: 6| Step: 8
Training loss: 2.2886733417600693
Validation loss: 2.6101656722814335

Epoch: 6| Step: 9
Training loss: 3.0534876347440263
Validation loss: 2.678387562935278

Epoch: 6| Step: 10
Training loss: 2.7675123079021073
Validation loss: 2.5790743072275237

Epoch: 6| Step: 11
Training loss: 3.4583319851669687
Validation loss: 2.591474109091235

Epoch: 6| Step: 12
Training loss: 2.2634582682057958
Validation loss: 2.5875336483596563

Epoch: 6| Step: 13
Training loss: 3.185041189840635
Validation loss: 2.6071823105312144

Epoch: 41| Step: 0
Training loss: 2.3415166768358473
Validation loss: 2.6349426768061814

Epoch: 6| Step: 1
Training loss: 1.827112292325206
Validation loss: 2.6176081988279702

Epoch: 6| Step: 2
Training loss: 2.998769348769041
Validation loss: 2.6313443490915613

Epoch: 6| Step: 3
Training loss: 2.06030723299163
Validation loss: 2.672068330488782

Epoch: 6| Step: 4
Training loss: 2.0423021560156234
Validation loss: 2.6304124331207346

Epoch: 6| Step: 5
Training loss: 3.0606793032333868
Validation loss: 2.5858156649958857

Epoch: 6| Step: 6
Training loss: 2.846802802065443
Validation loss: 2.547603838335754

Epoch: 6| Step: 7
Training loss: 2.5872972491895982
Validation loss: 2.637724974982271

Epoch: 6| Step: 8
Training loss: 2.8079397742667886
Validation loss: 2.5625250590269895

Epoch: 6| Step: 9
Training loss: 2.9427114481051455
Validation loss: 2.73261964676214

Epoch: 6| Step: 10
Training loss: 2.480377628124513
Validation loss: 2.713779846594238

Epoch: 6| Step: 11
Training loss: 2.8669653034645415
Validation loss: 2.5724461443138322

Epoch: 6| Step: 12
Training loss: 2.465067857810332
Validation loss: 2.6751781814270656

Epoch: 6| Step: 13
Training loss: 1.9011585217099625
Validation loss: 2.662524781686374

Epoch: 42| Step: 0
Training loss: 1.5925786819064056
Validation loss: 2.716937941091327

Epoch: 6| Step: 1
Training loss: 2.6201064500222584
Validation loss: 2.605872462773536

Epoch: 6| Step: 2
Training loss: 2.5549990029529037
Validation loss: 2.6394333718286034

Epoch: 6| Step: 3
Training loss: 2.4327316594152326
Validation loss: 2.5973262261721657

Epoch: 6| Step: 4
Training loss: 2.831289807307162
Validation loss: 2.561364038403833

Epoch: 6| Step: 5
Training loss: 2.5079501580695993
Validation loss: 2.634514489634621

Epoch: 6| Step: 6
Training loss: 2.8391323956465584
Validation loss: 2.637846152323644

Epoch: 6| Step: 7
Training loss: 2.483562408566302
Validation loss: 2.599403478281922

Epoch: 6| Step: 8
Training loss: 2.3641628165937
Validation loss: 2.7018723571420864

Epoch: 6| Step: 9
Training loss: 3.1253088226311982
Validation loss: 2.6009683474675733

Epoch: 6| Step: 10
Training loss: 2.583858703186896
Validation loss: 2.584289901789954

Epoch: 6| Step: 11
Training loss: 2.642540953290854
Validation loss: 2.590541678431999

Epoch: 6| Step: 12
Training loss: 2.6364626611749182
Validation loss: 2.638201261465109

Epoch: 6| Step: 13
Training loss: 2.5187088918052707
Validation loss: 2.586662213978753

Epoch: 43| Step: 0
Training loss: 2.3462189957567485
Validation loss: 2.5932124281695015

Epoch: 6| Step: 1
Training loss: 2.9558714352060855
Validation loss: 2.7080788028150633

Epoch: 6| Step: 2
Training loss: 2.618338716025094
Validation loss: 2.6313721200326423

Epoch: 6| Step: 3
Training loss: 2.797820544112525
Validation loss: 2.6753691641366903

Epoch: 6| Step: 4
Training loss: 2.5197126456322034
Validation loss: 2.693496741170678

Epoch: 6| Step: 5
Training loss: 2.509997310409017
Validation loss: 2.6710048545080145

Epoch: 6| Step: 6
Training loss: 2.660323844929392
Validation loss: 2.6891908575466674

Epoch: 6| Step: 7
Training loss: 1.690175372848956
Validation loss: 2.693364376425854

Epoch: 6| Step: 8
Training loss: 2.513840700065861
Validation loss: 2.6954400810969807

Epoch: 6| Step: 9
Training loss: 2.70445271778156
Validation loss: 2.5938493947054324

Epoch: 6| Step: 10
Training loss: 2.795231170921139
Validation loss: 2.6338830539073985

Epoch: 6| Step: 11
Training loss: 2.5710432411038386
Validation loss: 2.6692069044443745

Epoch: 6| Step: 12
Training loss: 2.381880380889172
Validation loss: 2.5753475757073057

Epoch: 6| Step: 13
Training loss: 2.4353485393757803
Validation loss: 2.6152852599264915

Epoch: 44| Step: 0
Training loss: 3.139196422068961
Validation loss: 2.635444721379182

Epoch: 6| Step: 1
Training loss: 2.763065770413299
Validation loss: 2.5853604674603203

Epoch: 6| Step: 2
Training loss: 2.467584745426304
Validation loss: 2.6386528400343527

Epoch: 6| Step: 3
Training loss: 2.207408231424059
Validation loss: 2.6136731593742173

Epoch: 6| Step: 4
Training loss: 2.066809573411189
Validation loss: 2.5560777868882423

Epoch: 6| Step: 5
Training loss: 3.095094639035285
Validation loss: 2.590723056264262

Epoch: 6| Step: 6
Training loss: 2.452973184929645
Validation loss: 2.5876365066615725

Epoch: 6| Step: 7
Training loss: 2.7599498042089334
Validation loss: 2.6526197272103413

Epoch: 6| Step: 8
Training loss: 2.854164253475162
Validation loss: 2.5735886091481612

Epoch: 6| Step: 9
Training loss: 1.82872912214438
Validation loss: 2.6688137847877527

Epoch: 6| Step: 10
Training loss: 2.0553534411249896
Validation loss: 2.606144639652041

Epoch: 6| Step: 11
Training loss: 2.3669012419094795
Validation loss: 2.5875268145414196

Epoch: 6| Step: 12
Training loss: 2.7271194544984647
Validation loss: 2.66912553097122

Epoch: 6| Step: 13
Training loss: 2.7077352205707332
Validation loss: 2.6238262564772814

Epoch: 45| Step: 0
Training loss: 2.1089011331159675
Validation loss: 2.6409926751037727

Epoch: 6| Step: 1
Training loss: 2.932998779754437
Validation loss: 2.6936396028181653

Epoch: 6| Step: 2
Training loss: 1.647634518562792
Validation loss: 2.660516043300346

Epoch: 6| Step: 3
Training loss: 2.8873856823242736
Validation loss: 2.6656034306991057

Epoch: 6| Step: 4
Training loss: 2.7883157024141556
Validation loss: 2.688776629730018

Epoch: 6| Step: 5
Training loss: 1.5867674962364293
Validation loss: 2.7514477444658705

Epoch: 6| Step: 6
Training loss: 2.9449007672364154
Validation loss: 2.6243629136594167

Epoch: 6| Step: 7
Training loss: 3.2061098659297547
Validation loss: 2.632269519390192

Epoch: 6| Step: 8
Training loss: 2.8988693203535094
Validation loss: 2.667086424175947

Epoch: 6| Step: 9
Training loss: 3.062635613377731
Validation loss: 2.617893370527183

Epoch: 6| Step: 10
Training loss: 3.232007473200477
Validation loss: 2.6315254816262375

Epoch: 6| Step: 11
Training loss: 2.185313412603261
Validation loss: 2.6495165281896673

Epoch: 6| Step: 12
Training loss: 2.2112604451296707
Validation loss: 2.597186909966495

Epoch: 6| Step: 13
Training loss: 1.9593405737278553
Validation loss: 2.6318528627171065

Epoch: 46| Step: 0
Training loss: 3.23999302145124
Validation loss: 2.59020654468469

Epoch: 6| Step: 1
Training loss: 2.0019556259511817
Validation loss: 2.6045426033784542

Epoch: 6| Step: 2
Training loss: 1.6755945773068137
Validation loss: 2.5885135385582823

Epoch: 6| Step: 3
Training loss: 2.2605983350561187
Validation loss: 2.6575082080339896

Epoch: 6| Step: 4
Training loss: 2.2551655284410823
Validation loss: 2.5481223267974817

Epoch: 6| Step: 5
Training loss: 2.903521990451535
Validation loss: 2.5730654149680676

Epoch: 6| Step: 6
Training loss: 1.9017751733089938
Validation loss: 2.541343532929395

Epoch: 6| Step: 7
Training loss: 3.0587862814063724
Validation loss: 2.6446832324878593

Epoch: 6| Step: 8
Training loss: 2.9770523429167013
Validation loss: 2.6289083812415908

Epoch: 6| Step: 9
Training loss: 2.651891116368187
Validation loss: 2.5966441235851234

Epoch: 6| Step: 10
Training loss: 2.7059158295075245
Validation loss: 2.62115319265623

Epoch: 6| Step: 11
Training loss: 2.1390824154692307
Validation loss: 2.6534900912827095

Epoch: 6| Step: 12
Training loss: 2.5301221053621092
Validation loss: 2.6441936192870563

Epoch: 6| Step: 13
Training loss: 2.3833193380660735
Validation loss: 2.675756947205157

Epoch: 47| Step: 0
Training loss: 2.6515301227559767
Validation loss: 2.6410921424719853

Epoch: 6| Step: 1
Training loss: 3.2185372587841266
Validation loss: 2.6261132770858744

Epoch: 6| Step: 2
Training loss: 1.6434889002217135
Validation loss: 2.637573857049233

Epoch: 6| Step: 3
Training loss: 1.6929728452934865
Validation loss: 2.632137011951439

Epoch: 6| Step: 4
Training loss: 2.484367610512546
Validation loss: 2.657801889095247

Epoch: 6| Step: 5
Training loss: 2.7881100521614757
Validation loss: 2.6417607755975827

Epoch: 6| Step: 6
Training loss: 2.354171775429733
Validation loss: 2.6341810357911615

Epoch: 6| Step: 7
Training loss: 2.531752736593858
Validation loss: 2.6675210095799424

Epoch: 6| Step: 8
Training loss: 3.15392028639162
Validation loss: 2.5967523441046425

Epoch: 6| Step: 9
Training loss: 2.267794287446677
Validation loss: 2.627991379687427

Epoch: 6| Step: 10
Training loss: 3.0312259319175783
Validation loss: 2.644713605400085

Epoch: 6| Step: 11
Training loss: 1.782142214934689
Validation loss: 2.6995077608716116

Epoch: 6| Step: 12
Training loss: 3.030175559368345
Validation loss: 2.672594921542459

Epoch: 6| Step: 13
Training loss: 2.547510266793389
Validation loss: 2.5779004856570014

Epoch: 48| Step: 0
Training loss: 2.6807021286004
Validation loss: 2.6118582675042172

Epoch: 6| Step: 1
Training loss: 3.1320866911718177
Validation loss: 2.6418609585797617

Epoch: 6| Step: 2
Training loss: 2.2586036008965067
Validation loss: 2.602676489125866

Epoch: 6| Step: 3
Training loss: 2.5667442900409387
Validation loss: 2.5647281325920472

Epoch: 6| Step: 4
Training loss: 2.5464930335698015
Validation loss: 2.682956084887859

Epoch: 6| Step: 5
Training loss: 2.387898604587007
Validation loss: 2.628360580185385

Epoch: 6| Step: 6
Training loss: 2.401085202918123
Validation loss: 2.5966971020104435

Epoch: 6| Step: 7
Training loss: 2.689451174711076
Validation loss: 2.5841006913343985

Epoch: 6| Step: 8
Training loss: 2.530786354081933
Validation loss: 2.6130360943082036

Epoch: 6| Step: 9
Training loss: 1.9044707077109195
Validation loss: 2.6024919592702305

Epoch: 6| Step: 10
Training loss: 2.6347696065342414
Validation loss: 2.674774366589699

Epoch: 6| Step: 11
Training loss: 2.804210824226703
Validation loss: 2.66170494345475

Epoch: 6| Step: 12
Training loss: 2.133545690139788
Validation loss: 2.67069183982543

Epoch: 6| Step: 13
Training loss: 2.320265438745704
Validation loss: 2.6679953503527676

Epoch: 49| Step: 0
Training loss: 2.1386058779771364
Validation loss: 2.544253554557193

Epoch: 6| Step: 1
Training loss: 1.5222584392171463
Validation loss: 2.5602157227328335

Epoch: 6| Step: 2
Training loss: 2.1463571915161275
Validation loss: 2.6800593348952106

Epoch: 6| Step: 3
Training loss: 2.912491525793231
Validation loss: 2.6963517254165073

Epoch: 6| Step: 4
Training loss: 1.9856606471314293
Validation loss: 2.6597743868934445

Epoch: 6| Step: 5
Training loss: 3.8032972235697
Validation loss: 2.641657926342421

Epoch: 6| Step: 6
Training loss: 2.070463470136736
Validation loss: 2.567889461873561

Epoch: 6| Step: 7
Training loss: 2.1310642329273093
Validation loss: 2.60401593089956

Epoch: 6| Step: 8
Training loss: 3.0799867837795727
Validation loss: 2.642703229823815

Epoch: 6| Step: 9
Training loss: 2.951487253581936
Validation loss: 2.62705039372517

Epoch: 6| Step: 10
Training loss: 2.5461038931650135
Validation loss: 2.617593018349436

Epoch: 6| Step: 11
Training loss: 2.3377024639389004
Validation loss: 2.6249454356380837

Epoch: 6| Step: 12
Training loss: 2.217302306780318
Validation loss: 2.5828532470147474

Epoch: 6| Step: 13
Training loss: 1.8515967514797416
Validation loss: 2.649513843615153

Epoch: 50| Step: 0
Training loss: 2.2834973696331646
Validation loss: 2.5829500303674093

Epoch: 6| Step: 1
Training loss: 2.019220265511382
Validation loss: 2.529864289057816

Epoch: 6| Step: 2
Training loss: 3.207244605751268
Validation loss: 2.5967837749544684

Epoch: 6| Step: 3
Training loss: 2.468718033595703
Validation loss: 2.52242496517503

Epoch: 6| Step: 4
Training loss: 3.2487200637500773
Validation loss: 2.5409084554518317

Epoch: 6| Step: 5
Training loss: 2.872479038411045
Validation loss: 2.6138339748237867

Epoch: 6| Step: 6
Training loss: 3.1605858057000873
Validation loss: 2.6384185360685546

Epoch: 6| Step: 7
Training loss: 2.069479836055331
Validation loss: 2.5326199376186036

Epoch: 6| Step: 8
Training loss: 2.1009703301754614
Validation loss: 2.494425989055353

Epoch: 6| Step: 9
Training loss: 2.2584378653494737
Validation loss: 2.591783582456376

Epoch: 6| Step: 10
Training loss: 2.170373301413048
Validation loss: 2.6087218512207744

Epoch: 6| Step: 11
Training loss: 2.5543416106989194
Validation loss: 2.5919523329060525

Epoch: 6| Step: 12
Training loss: 2.708489007632812
Validation loss: 2.6726675512630034

Epoch: 6| Step: 13
Training loss: 1.8809309299124188
Validation loss: 2.680880163453894

Epoch: 51| Step: 0
Training loss: 1.281163654674372
Validation loss: 2.628480964712175

Epoch: 6| Step: 1
Training loss: 2.3667686771741003
Validation loss: 2.7035949607202214

Epoch: 6| Step: 2
Training loss: 2.7005569519354657
Validation loss: 2.558386299711606

Epoch: 6| Step: 3
Training loss: 2.950965859009148
Validation loss: 2.6469048760719818

Epoch: 6| Step: 4
Training loss: 2.292989753483979
Validation loss: 2.646568944501806

Epoch: 6| Step: 5
Training loss: 2.196656056939505
Validation loss: 2.649636761344175

Epoch: 6| Step: 6
Training loss: 2.6847818512622563
Validation loss: 2.677067342232963

Epoch: 6| Step: 7
Training loss: 2.756433244699191
Validation loss: 2.563493055502499

Epoch: 6| Step: 8
Training loss: 2.331264964201407
Validation loss: 2.7016948010813135

Epoch: 6| Step: 9
Training loss: 2.4378293132850115
Validation loss: 2.6321288748488882

Epoch: 6| Step: 10
Training loss: 3.0328388572620626
Validation loss: 2.6000277371027436

Epoch: 6| Step: 11
Training loss: 1.905618156403301
Validation loss: 2.691301850396592

Epoch: 6| Step: 12
Training loss: 2.567874389808804
Validation loss: 2.605228624616933

Epoch: 6| Step: 13
Training loss: 2.352438728596721
Validation loss: 2.6041268053182987

Epoch: 52| Step: 0
Training loss: 2.819225323644081
Validation loss: 2.6729591356344162

Epoch: 6| Step: 1
Training loss: 2.4818737946668055
Validation loss: 2.5414872861838496

Epoch: 6| Step: 2
Training loss: 2.342722247805956
Validation loss: 2.586341403792082

Epoch: 6| Step: 3
Training loss: 2.091343877843399
Validation loss: 2.618456480682315

Epoch: 6| Step: 4
Training loss: 2.7866368792126712
Validation loss: 2.6423025276506067

Epoch: 6| Step: 5
Training loss: 2.243676837376505
Validation loss: 2.6040407124895064

Epoch: 6| Step: 6
Training loss: 2.260999601469549
Validation loss: 2.5669049030646143

Epoch: 6| Step: 7
Training loss: 2.8795809530996177
Validation loss: 2.547152404655704

Epoch: 6| Step: 8
Training loss: 3.0858265530886646
Validation loss: 2.599392341861048

Epoch: 6| Step: 9
Training loss: 3.030870394189516
Validation loss: 2.6039102402641334

Epoch: 6| Step: 10
Training loss: 2.4421554514514336
Validation loss: 2.5842308413219244

Epoch: 6| Step: 11
Training loss: 1.7538658766145934
Validation loss: 2.5970409458111683

Epoch: 6| Step: 12
Training loss: 2.1292005423023967
Validation loss: 2.5805247534136444

Epoch: 6| Step: 13
Training loss: 2.5322996247413796
Validation loss: 2.596044574876026

Epoch: 53| Step: 0
Training loss: 2.4061562656129256
Validation loss: 2.594314444838523

Epoch: 6| Step: 1
Training loss: 2.723311883039599
Validation loss: 2.579413552451746

Epoch: 6| Step: 2
Training loss: 1.7543000116959404
Validation loss: 2.4808142073558965

Epoch: 6| Step: 3
Training loss: 2.2780158750669157
Validation loss: 2.5929546898696945

Epoch: 6| Step: 4
Training loss: 2.670579741326807
Validation loss: 2.5920891480798893

Epoch: 6| Step: 5
Training loss: 2.6299298633172743
Validation loss: 2.7421913835257103

Epoch: 6| Step: 6
Training loss: 2.217197896168203
Validation loss: 2.6755533163069054

Epoch: 6| Step: 7
Training loss: 1.993005442533895
Validation loss: 2.6906914059267555

Epoch: 6| Step: 8
Training loss: 3.292732130715093
Validation loss: 2.6242817244185557

Epoch: 6| Step: 9
Training loss: 3.5214071915938363
Validation loss: 2.7136690887192327

Epoch: 6| Step: 10
Training loss: 1.80960358014229
Validation loss: 2.741710045267471

Epoch: 6| Step: 11
Training loss: 2.5897445084327373
Validation loss: 2.6854616315779922

Epoch: 6| Step: 12
Training loss: 2.7726410057872
Validation loss: 2.6261730600543802

Epoch: 6| Step: 13
Training loss: 1.7181215697941514
Validation loss: 2.614103757080851

Epoch: 54| Step: 0
Training loss: 2.7607437419853245
Validation loss: 2.623500365336544

Epoch: 6| Step: 1
Training loss: 2.641567084744964
Validation loss: 2.5973293701096924

Epoch: 6| Step: 2
Training loss: 2.1530218977250883
Validation loss: 2.560441702422079

Epoch: 6| Step: 3
Training loss: 2.1673935135639675
Validation loss: 2.604120182894057

Epoch: 6| Step: 4
Training loss: 2.4975999756010885
Validation loss: 2.5277880710932528

Epoch: 6| Step: 5
Training loss: 2.6794760039476375
Validation loss: 2.717767735323474

Epoch: 6| Step: 6
Training loss: 2.2926362038589176
Validation loss: 2.5629274430469864

Epoch: 6| Step: 7
Training loss: 2.3847434302944457
Validation loss: 2.5829914287198967

Epoch: 6| Step: 8
Training loss: 2.486484807329922
Validation loss: 2.5655808730363354

Epoch: 6| Step: 9
Training loss: 2.753487110030879
Validation loss: 2.518356656644591

Epoch: 6| Step: 10
Training loss: 2.1569261458287277
Validation loss: 2.594805261511751

Epoch: 6| Step: 11
Training loss: 2.1575182073892365
Validation loss: 2.611738493693834

Epoch: 6| Step: 12
Training loss: 2.597309473740157
Validation loss: 2.564266572836048

Epoch: 6| Step: 13
Training loss: 2.7839220905254733
Validation loss: 2.527266684472029

Epoch: 55| Step: 0
Training loss: 2.352108508623769
Validation loss: 2.57662101572745

Epoch: 6| Step: 1
Training loss: 2.9346448942789616
Validation loss: 2.6202802309958284

Epoch: 6| Step: 2
Training loss: 2.486647232566074
Validation loss: 2.691064245366472

Epoch: 6| Step: 3
Training loss: 3.026292030014244
Validation loss: 2.6112966866076084

Epoch: 6| Step: 4
Training loss: 2.1625398312467023
Validation loss: 2.6077243053287154

Epoch: 6| Step: 5
Training loss: 2.204501540400001
Validation loss: 2.5986073370975844

Epoch: 6| Step: 6
Training loss: 2.802706302940862
Validation loss: 2.6747923348531435

Epoch: 6| Step: 7
Training loss: 2.490360558996659
Validation loss: 2.622826168103925

Epoch: 6| Step: 8
Training loss: 1.483283997190289
Validation loss: 2.5763013767164473

Epoch: 6| Step: 9
Training loss: 2.6728805523695045
Validation loss: 2.590294523983283

Epoch: 6| Step: 10
Training loss: 2.9049699486968934
Validation loss: 2.60822403245093

Epoch: 6| Step: 11
Training loss: 2.4903596016307707
Validation loss: 2.654135494458341

Epoch: 6| Step: 12
Training loss: 1.8255844068862606
Validation loss: 2.6251407767194532

Epoch: 6| Step: 13
Training loss: 2.062990188146308
Validation loss: 2.691727174801197

Epoch: 56| Step: 0
Training loss: 3.215950053610045
Validation loss: 2.6249099594901346

Epoch: 6| Step: 1
Training loss: 2.5614675907703566
Validation loss: 2.6156379629502866

Epoch: 6| Step: 2
Training loss: 2.115028885628335
Validation loss: 2.6424706083098934

Epoch: 6| Step: 3
Training loss: 2.019222154703733
Validation loss: 2.59322567891192

Epoch: 6| Step: 4
Training loss: 2.4184022678126116
Validation loss: 2.5665782946280937

Epoch: 6| Step: 5
Training loss: 1.9305681080337673
Validation loss: 2.6734591987245047

Epoch: 6| Step: 6
Training loss: 1.708072440842391
Validation loss: 2.5782005530181804

Epoch: 6| Step: 7
Training loss: 3.309878481567585
Validation loss: 2.5244736724052874

Epoch: 6| Step: 8
Training loss: 2.429831644670398
Validation loss: 2.647266080114303

Epoch: 6| Step: 9
Training loss: 2.2348792300781417
Validation loss: 2.5906647176424364

Epoch: 6| Step: 10
Training loss: 2.6569886022171816
Validation loss: 2.4992198124070732

Epoch: 6| Step: 11
Training loss: 2.4310286276483963
Validation loss: 2.5550882800876846

Epoch: 6| Step: 12
Training loss: 2.603194724221912
Validation loss: 2.6527891014572003

Epoch: 6| Step: 13
Training loss: 2.946860799421478
Validation loss: 2.662302369855614

Epoch: 57| Step: 0
Training loss: 1.888141798331709
Validation loss: 2.5976255639732804

Epoch: 6| Step: 1
Training loss: 2.2676294339048693
Validation loss: 2.6828136096760242

Epoch: 6| Step: 2
Training loss: 3.1124528383412393
Validation loss: 2.62178496614261

Epoch: 6| Step: 3
Training loss: 1.7272401058274183
Validation loss: 2.5730805183984393

Epoch: 6| Step: 4
Training loss: 2.7397237724791355
Validation loss: 2.65671019214153

Epoch: 6| Step: 5
Training loss: 2.3216843579401685
Validation loss: 2.6803447188067686

Epoch: 6| Step: 6
Training loss: 2.6600865202291786
Validation loss: 2.6682259699539035

Epoch: 6| Step: 7
Training loss: 2.6898259588047084
Validation loss: 2.714083221537991

Epoch: 6| Step: 8
Training loss: 2.066438786443401
Validation loss: 2.6486861450745853

Epoch: 6| Step: 9
Training loss: 3.193642177366723
Validation loss: 2.665989444590146

Epoch: 6| Step: 10
Training loss: 2.5991203140409547
Validation loss: 2.589904492923555

Epoch: 6| Step: 11
Training loss: 3.0472558981666
Validation loss: 2.6452297563524834

Epoch: 6| Step: 12
Training loss: 1.2838958774726572
Validation loss: 2.6117393304940335

Epoch: 6| Step: 13
Training loss: 2.3973935119719325
Validation loss: 2.54808452570002

Epoch: 58| Step: 0
Training loss: 2.4354195152333498
Validation loss: 2.6574441805958573

Epoch: 6| Step: 1
Training loss: 1.9323978926121048
Validation loss: 2.5963684408139205

Epoch: 6| Step: 2
Training loss: 2.05887794342581
Validation loss: 2.590563873931941

Epoch: 6| Step: 3
Training loss: 3.3667141964519085
Validation loss: 2.5842103981820923

Epoch: 6| Step: 4
Training loss: 2.4490711709176045
Validation loss: 2.5611977408324536

Epoch: 6| Step: 5
Training loss: 2.180974655479852
Validation loss: 2.510103836723378

Epoch: 6| Step: 6
Training loss: 2.1577808640223672
Validation loss: 2.6288230546518854

Epoch: 6| Step: 7
Training loss: 2.615010189962865
Validation loss: 2.641769010885817

Epoch: 6| Step: 8
Training loss: 2.3984606614376878
Validation loss: 2.6003808897964222

Epoch: 6| Step: 9
Training loss: 2.116015570916789
Validation loss: 2.6729636028883417

Epoch: 6| Step: 10
Training loss: 2.0408166815796367
Validation loss: 2.6243087751598675

Epoch: 6| Step: 11
Training loss: 2.318237918542131
Validation loss: 2.5546712612370936

Epoch: 6| Step: 12
Training loss: 2.9959567161764267
Validation loss: 2.5049732015956745

Epoch: 6| Step: 13
Training loss: 2.8263569568909928
Validation loss: 2.599654073352428

Epoch: 59| Step: 0
Training loss: 2.2422970203407933
Validation loss: 2.6753098715396555

Epoch: 6| Step: 1
Training loss: 2.789533559304334
Validation loss: 2.608555160531025

Epoch: 6| Step: 2
Training loss: 2.23195340905733
Validation loss: 2.5629362494817687

Epoch: 6| Step: 3
Training loss: 3.3386578155325095
Validation loss: 2.671449430307523

Epoch: 6| Step: 4
Training loss: 2.25569174668049
Validation loss: 2.6079553713173587

Epoch: 6| Step: 5
Training loss: 1.8334441440501552
Validation loss: 2.67765803915779

Epoch: 6| Step: 6
Training loss: 2.0107544004227815
Validation loss: 2.6192797444428964

Epoch: 6| Step: 7
Training loss: 2.7786813940449915
Validation loss: 2.607921248679446

Epoch: 6| Step: 8
Training loss: 2.3749307321184845
Validation loss: 2.636181420099986

Epoch: 6| Step: 9
Training loss: 2.636251043588098
Validation loss: 2.4913961973931507

Epoch: 6| Step: 10
Training loss: 1.9910037843600241
Validation loss: 2.619384253632773

Epoch: 6| Step: 11
Training loss: 2.6145811853488645
Validation loss: 2.6695080808326805

Epoch: 6| Step: 12
Training loss: 2.0616031199442384
Validation loss: 2.6071187923077233

Epoch: 6| Step: 13
Training loss: 2.6964206352586264
Validation loss: 2.588956424840028

Epoch: 60| Step: 0
Training loss: 1.9903843517154447
Validation loss: 2.5021270921762597

Epoch: 6| Step: 1
Training loss: 3.1898470446709504
Validation loss: 2.47485326274183

Epoch: 6| Step: 2
Training loss: 2.74857874469956
Validation loss: 2.677083729151438

Epoch: 6| Step: 3
Training loss: 2.0523023795033914
Validation loss: 2.4962209908893582

Epoch: 6| Step: 4
Training loss: 2.964379074412374
Validation loss: 2.5651472652835854

Epoch: 6| Step: 5
Training loss: 1.93559873263181
Validation loss: 2.5859713211229645

Epoch: 6| Step: 6
Training loss: 2.191307024825773
Validation loss: 2.624502922102506

Epoch: 6| Step: 7
Training loss: 2.2798628051371432
Validation loss: 2.584553604688874

Epoch: 6| Step: 8
Training loss: 1.99761164633702
Validation loss: 2.5806968422619043

Epoch: 6| Step: 9
Training loss: 2.7775004969063355
Validation loss: 2.59575802085049

Epoch: 6| Step: 10
Training loss: 2.4698591034583894
Validation loss: 2.6028290072375

Epoch: 6| Step: 11
Training loss: 2.433373895942844
Validation loss: 2.4674916178809903

Epoch: 6| Step: 12
Training loss: 2.3171324853932074
Validation loss: 2.6551303897480474

Epoch: 6| Step: 13
Training loss: 2.8609293064102186
Validation loss: 2.539184645624696

Epoch: 61| Step: 0
Training loss: 2.5551351452524287
Validation loss: 2.627686904093584

Epoch: 6| Step: 1
Training loss: 1.8786125984632862
Validation loss: 2.575989503457026

Epoch: 6| Step: 2
Training loss: 3.5307119854249565
Validation loss: 2.551616849240649

Epoch: 6| Step: 3
Training loss: 2.6436685031026252
Validation loss: 2.5443366727766668

Epoch: 6| Step: 4
Training loss: 2.2715058920211
Validation loss: 2.6460766918172025

Epoch: 6| Step: 5
Training loss: 2.068654328407294
Validation loss: 2.5735520158838203

Epoch: 6| Step: 6
Training loss: 2.231752897804031
Validation loss: 2.661978584298941

Epoch: 6| Step: 7
Training loss: 2.1654647525657147
Validation loss: 2.595839926179093

Epoch: 6| Step: 8
Training loss: 2.5986596026897897
Validation loss: 2.6866059997215195

Epoch: 6| Step: 9
Training loss: 1.83783562118809
Validation loss: 2.6589560095361864

Epoch: 6| Step: 10
Training loss: 2.7839179797422426
Validation loss: 2.6243471514538608

Epoch: 6| Step: 11
Training loss: 2.2528134875348957
Validation loss: 2.599488356572816

Epoch: 6| Step: 12
Training loss: 2.4137504894506985
Validation loss: 2.6205504110565845

Epoch: 6| Step: 13
Training loss: 2.4247781396427297
Validation loss: 2.6642409905296267

Epoch: 62| Step: 0
Training loss: 2.408615930821988
Validation loss: 2.6446845997647177

Epoch: 6| Step: 1
Training loss: 2.748204078326049
Validation loss: 2.573931989196639

Epoch: 6| Step: 2
Training loss: 1.6223563183849936
Validation loss: 2.495917507550229

Epoch: 6| Step: 3
Training loss: 2.345703328281111
Validation loss: 2.497628963171458

Epoch: 6| Step: 4
Training loss: 1.976204941565863
Validation loss: 2.5795193533238243

Epoch: 6| Step: 5
Training loss: 2.060667206202107
Validation loss: 2.520941587493434

Epoch: 6| Step: 6
Training loss: 3.4316143627605635
Validation loss: 2.529725592964354

Epoch: 6| Step: 7
Training loss: 2.9096984093500176
Validation loss: 2.5998071317785665

Epoch: 6| Step: 8
Training loss: 2.676107701345224
Validation loss: 2.6597976779000825

Epoch: 6| Step: 9
Training loss: 2.4740244859919227
Validation loss: 2.620830797478238

Epoch: 6| Step: 10
Training loss: 1.566001630545945
Validation loss: 2.544026097865565

Epoch: 6| Step: 11
Training loss: 2.325810043161857
Validation loss: 2.6365926980864955

Epoch: 6| Step: 12
Training loss: 2.3110073530409476
Validation loss: 2.604936491032834

Epoch: 6| Step: 13
Training loss: 2.713264192439139
Validation loss: 2.561033108167675

Epoch: 63| Step: 0
Training loss: 2.7779632177973155
Validation loss: 2.6935504184434866

Epoch: 6| Step: 1
Training loss: 2.313427713247991
Validation loss: 2.6120763566003133

Epoch: 6| Step: 2
Training loss: 2.560625646850415
Validation loss: 2.664199780817297

Epoch: 6| Step: 3
Training loss: 2.1324951159297205
Validation loss: 2.624367100242771

Epoch: 6| Step: 4
Training loss: 2.1447271316648457
Validation loss: 2.5341373819826987

Epoch: 6| Step: 5
Training loss: 2.995017045980355
Validation loss: 2.5828339006783905

Epoch: 6| Step: 6
Training loss: 2.586202556014529
Validation loss: 2.665322387142645

Epoch: 6| Step: 7
Training loss: 2.0462899573170232
Validation loss: 2.6383461684129457

Epoch: 6| Step: 8
Training loss: 2.904916108540185
Validation loss: 2.622542502510679

Epoch: 6| Step: 9
Training loss: 2.073860554199969
Validation loss: 2.630397923249332

Epoch: 6| Step: 10
Training loss: 2.212047823804581
Validation loss: 2.5573962177935488

Epoch: 6| Step: 11
Training loss: 2.527461855456207
Validation loss: 2.563028389642392

Epoch: 6| Step: 12
Training loss: 2.1120130079186716
Validation loss: 2.6361574833039043

Epoch: 6| Step: 13
Training loss: 2.5032522028726
Validation loss: 2.6319233405061992

Epoch: 64| Step: 0
Training loss: 2.5976240342515955
Validation loss: 2.605957214229664

Epoch: 6| Step: 1
Training loss: 2.966192971319133
Validation loss: 2.5922593118884985

Epoch: 6| Step: 2
Training loss: 2.044915112736551
Validation loss: 2.596593439573825

Epoch: 6| Step: 3
Training loss: 2.134521358716434
Validation loss: 2.553754218022241

Epoch: 6| Step: 4
Training loss: 1.6801440660830813
Validation loss: 2.5525140256181906

Epoch: 6| Step: 5
Training loss: 2.615958127191216
Validation loss: 2.556147913305019

Epoch: 6| Step: 6
Training loss: 2.791440318786115
Validation loss: 2.6509946033269842

Epoch: 6| Step: 7
Training loss: 2.350303439576932
Validation loss: 2.5713061389966962

Epoch: 6| Step: 8
Training loss: 2.847204101835653
Validation loss: 2.478727828115981

Epoch: 6| Step: 9
Training loss: 2.3062701464757747
Validation loss: 2.616305811007717

Epoch: 6| Step: 10
Training loss: 2.46158671217175
Validation loss: 2.671820314676846

Epoch: 6| Step: 11
Training loss: 2.555303470184618
Validation loss: 2.5327204605000055

Epoch: 6| Step: 12
Training loss: 2.294240361739123
Validation loss: 2.5024221131116033

Epoch: 6| Step: 13
Training loss: 2.7469273654429394
Validation loss: 2.5640350179150606

Epoch: 65| Step: 0
Training loss: 2.3959749484018276
Validation loss: 2.604519184412696

Epoch: 6| Step: 1
Training loss: 1.9218985083157953
Validation loss: 2.6749904977029555

Epoch: 6| Step: 2
Training loss: 1.8185819331903748
Validation loss: 2.5628686810262247

Epoch: 6| Step: 3
Training loss: 2.8396815446497543
Validation loss: 2.657937669357591

Epoch: 6| Step: 4
Training loss: 2.438957365557229
Validation loss: 2.611198153859893

Epoch: 6| Step: 5
Training loss: 3.261159517693256
Validation loss: 2.647660192938996

Epoch: 6| Step: 6
Training loss: 2.2452280515798555
Validation loss: 2.6629591938368034

Epoch: 6| Step: 7
Training loss: 2.199390140447729
Validation loss: 2.638261207306377

Epoch: 6| Step: 8
Training loss: 1.9953823426882284
Validation loss: 2.63171715595146

Epoch: 6| Step: 9
Training loss: 2.478022484986
Validation loss: 2.6221842574704652

Epoch: 6| Step: 10
Training loss: 1.9066426232407
Validation loss: 2.719268106370187

Epoch: 6| Step: 11
Training loss: 2.7413580093639998
Validation loss: 2.6457801022518947

Epoch: 6| Step: 12
Training loss: 2.9352777069606173
Validation loss: 2.582295045059249

Epoch: 6| Step: 13
Training loss: 2.1499284599289576
Validation loss: 2.7090462895519036

Epoch: 66| Step: 0
Training loss: 2.7470168492620126
Validation loss: 2.6589705503711563

Epoch: 6| Step: 1
Training loss: 3.0805793697842034
Validation loss: 2.55537313579622

Epoch: 6| Step: 2
Training loss: 2.781368810280519
Validation loss: 2.547815441783534

Epoch: 6| Step: 3
Training loss: 3.0505009911983714
Validation loss: 2.609419816597379

Epoch: 6| Step: 4
Training loss: 2.3877642100872594
Validation loss: 2.5618338765819697

Epoch: 6| Step: 5
Training loss: 2.5931138327048497
Validation loss: 2.544122569912667

Epoch: 6| Step: 6
Training loss: 2.1001477779889894
Validation loss: 2.5367497479755796

Epoch: 6| Step: 7
Training loss: 2.1787179410745794
Validation loss: 2.6385526632528347

Epoch: 6| Step: 8
Training loss: 1.8425299276874252
Validation loss: 2.542403275942107

Epoch: 6| Step: 9
Training loss: 2.1554203372287177
Validation loss: 2.5921595956114047

Epoch: 6| Step: 10
Training loss: 2.014388422197819
Validation loss: 2.530601253497031

Epoch: 6| Step: 11
Training loss: 2.678701680967419
Validation loss: 2.5839551105605785

Epoch: 6| Step: 12
Training loss: 2.0504354712214345
Validation loss: 2.639310189686775

Epoch: 6| Step: 13
Training loss: 2.327064426200737
Validation loss: 2.552768371402354

Epoch: 67| Step: 0
Training loss: 3.031449458845257
Validation loss: 2.5314699006812456

Epoch: 6| Step: 1
Training loss: 2.2297232696508353
Validation loss: 2.5626313323194254

Epoch: 6| Step: 2
Training loss: 1.6483087715399227
Validation loss: 2.671406219584165

Epoch: 6| Step: 3
Training loss: 2.852017969831912
Validation loss: 2.6011066285559648

Epoch: 6| Step: 4
Training loss: 2.3666246204491768
Validation loss: 2.6060640416633456

Epoch: 6| Step: 5
Training loss: 2.253627607816863
Validation loss: 2.6200778923637795

Epoch: 6| Step: 6
Training loss: 2.3055316995308273
Validation loss: 2.6292740071950083

Epoch: 6| Step: 7
Training loss: 1.829994354447792
Validation loss: 2.6614507288118077

Epoch: 6| Step: 8
Training loss: 2.288559477546801
Validation loss: 2.6548980937708717

Epoch: 6| Step: 9
Training loss: 2.844863673532334
Validation loss: 2.6922509538519708

Epoch: 6| Step: 10
Training loss: 2.280896930284135
Validation loss: 2.6603688413244035

Epoch: 6| Step: 11
Training loss: 2.8554832781671284
Validation loss: 2.6377576424951332

Epoch: 6| Step: 12
Training loss: 2.499398349844629
Validation loss: 2.6452595671847963

Epoch: 6| Step: 13
Training loss: 2.5077357770645574
Validation loss: 2.662815820293239

Epoch: 68| Step: 0
Training loss: 2.181576365017133
Validation loss: 2.62147665472196

Epoch: 6| Step: 1
Training loss: 2.878569004797498
Validation loss: 2.5715951704749207

Epoch: 6| Step: 2
Training loss: 3.236306908122969
Validation loss: 2.5918915689854205

Epoch: 6| Step: 3
Training loss: 2.2168336571150014
Validation loss: 2.581819449628762

Epoch: 6| Step: 4
Training loss: 2.0423305236654294
Validation loss: 2.612768331007693

Epoch: 6| Step: 5
Training loss: 2.612530929893397
Validation loss: 2.5213265422549376

Epoch: 6| Step: 6
Training loss: 2.6389935210604856
Validation loss: 2.6423784111438002

Epoch: 6| Step: 7
Training loss: 2.3988637141656515
Validation loss: 2.5639786989603746

Epoch: 6| Step: 8
Training loss: 2.0538186676749097
Validation loss: 2.5753602433289426

Epoch: 6| Step: 9
Training loss: 2.394011050499164
Validation loss: 2.606385595391015

Epoch: 6| Step: 10
Training loss: 1.7870281263549113
Validation loss: 2.60366398855311

Epoch: 6| Step: 11
Training loss: 2.59904197502219
Validation loss: 2.5591851014550158

Epoch: 6| Step: 12
Training loss: 2.674088035640782
Validation loss: 2.549766973681418

Epoch: 6| Step: 13
Training loss: 2.468969407773907
Validation loss: 2.5950006051451773

Epoch: 69| Step: 0
Training loss: 2.6409899216805917
Validation loss: 2.5442132126612944

Epoch: 6| Step: 1
Training loss: 2.6471532898296535
Validation loss: 2.600872555450935

Epoch: 6| Step: 2
Training loss: 2.43443369568174
Validation loss: 2.545408673203377

Epoch: 6| Step: 3
Training loss: 2.3931016248077963
Validation loss: 2.6677627744609835

Epoch: 6| Step: 4
Training loss: 2.481032612307573
Validation loss: 2.6433434873516592

Epoch: 6| Step: 5
Training loss: 3.2256836514018077
Validation loss: 2.672595441926187

Epoch: 6| Step: 6
Training loss: 2.4646760185228684
Validation loss: 2.7141470255232334

Epoch: 6| Step: 7
Training loss: 2.426644827286814
Validation loss: 2.68537122117311

Epoch: 6| Step: 8
Training loss: 2.123038227867337
Validation loss: 2.6601424326563494

Epoch: 6| Step: 9
Training loss: 1.8870333770565608
Validation loss: 2.691125745324895

Epoch: 6| Step: 10
Training loss: 1.9788881875594448
Validation loss: 2.7147845145150757

Epoch: 6| Step: 11
Training loss: 2.4129250819009487
Validation loss: 2.627888679538831

Epoch: 6| Step: 12
Training loss: 2.8757071247408272
Validation loss: 2.6501375966367453

Epoch: 6| Step: 13
Training loss: 1.8442560568254092
Validation loss: 2.6610987669840522

Epoch: 70| Step: 0
Training loss: 2.417066365654655
Validation loss: 2.6081562051156375

Epoch: 6| Step: 1
Training loss: 2.272597744458459
Validation loss: 2.6357835858507093

Epoch: 6| Step: 2
Training loss: 2.3568070944565993
Validation loss: 2.536978091983232

Epoch: 6| Step: 3
Training loss: 2.0935800967385894
Validation loss: 2.552693396591819

Epoch: 6| Step: 4
Training loss: 2.438680314124734
Validation loss: 2.553329542379661

Epoch: 6| Step: 5
Training loss: 1.7915174141159127
Validation loss: 2.4766839576244246

Epoch: 6| Step: 6
Training loss: 2.239536326306886
Validation loss: 2.652389166419258

Epoch: 6| Step: 7
Training loss: 1.9227325263116595
Validation loss: 2.5463271848815174

Epoch: 6| Step: 8
Training loss: 1.9620456679898122
Validation loss: 2.602175925699295

Epoch: 6| Step: 9
Training loss: 1.84347415735658
Validation loss: 2.5675619881936957

Epoch: 6| Step: 10
Training loss: 2.5327646880487844
Validation loss: 2.5776140573686566

Epoch: 6| Step: 11
Training loss: 2.817564156181797
Validation loss: 2.587212884794316

Epoch: 6| Step: 12
Training loss: 2.810370253473532
Validation loss: 2.5176800849496708

Epoch: 6| Step: 13
Training loss: 3.6071167854543122
Validation loss: 2.580407844707829

Epoch: 71| Step: 0
Training loss: 2.4259324080445603
Validation loss: 2.520456133488428

Epoch: 6| Step: 1
Training loss: 2.547253820412141
Validation loss: 2.627439621662034

Epoch: 6| Step: 2
Training loss: 1.9810924262794485
Validation loss: 2.6043227237989997

Epoch: 6| Step: 3
Training loss: 2.1055714541494557
Validation loss: 2.6262069077173904

Epoch: 6| Step: 4
Training loss: 2.1986074461926153
Validation loss: 2.5360086239508677

Epoch: 6| Step: 5
Training loss: 2.432320005808598
Validation loss: 2.5966936589047243

Epoch: 6| Step: 6
Training loss: 2.8680503440811638
Validation loss: 2.565561295778221

Epoch: 6| Step: 7
Training loss: 2.7743507278662802
Validation loss: 2.5634713541613756

Epoch: 6| Step: 8
Training loss: 1.8537457306208869
Validation loss: 2.5426117802256845

Epoch: 6| Step: 9
Training loss: 2.1934441595089194
Validation loss: 2.573056326613714

Epoch: 6| Step: 10
Training loss: 2.164791824340325
Validation loss: 2.6265983105574002

Epoch: 6| Step: 11
Training loss: 2.2644637716456635
Validation loss: 2.592441910730849

Epoch: 6| Step: 12
Training loss: 2.6282535553288295
Validation loss: 2.5982661781253937

Epoch: 6| Step: 13
Training loss: 2.736762437790255
Validation loss: 2.557119225141395

Epoch: 72| Step: 0
Training loss: 3.1514125805337807
Validation loss: 2.609176186546552

Epoch: 6| Step: 1
Training loss: 1.9732625199619962
Validation loss: 2.6874042612218654

Epoch: 6| Step: 2
Training loss: 2.0063906136075693
Validation loss: 2.611915159090927

Epoch: 6| Step: 3
Training loss: 1.9816106931236954
Validation loss: 2.5846795809389294

Epoch: 6| Step: 4
Training loss: 2.61313691474773
Validation loss: 2.7073511298884037

Epoch: 6| Step: 5
Training loss: 2.731013296943513
Validation loss: 2.565340359781613

Epoch: 6| Step: 6
Training loss: 1.8348072225148682
Validation loss: 2.5650209881355766

Epoch: 6| Step: 7
Training loss: 1.8804334750510072
Validation loss: 2.4945155862359654

Epoch: 6| Step: 8
Training loss: 2.8054528002496695
Validation loss: 2.590983819289473

Epoch: 6| Step: 9
Training loss: 2.111445336348121
Validation loss: 2.5292865532034803

Epoch: 6| Step: 10
Training loss: 2.437506553445467
Validation loss: 2.6800185759930177

Epoch: 6| Step: 11
Training loss: 2.3405780945421135
Validation loss: 2.6021956092509906

Epoch: 6| Step: 12
Training loss: 2.9397327784330587
Validation loss: 2.638469003991328

Epoch: 6| Step: 13
Training loss: 2.2729462292709934
Validation loss: 2.5997095086358764

Epoch: 73| Step: 0
Training loss: 2.763657036731368
Validation loss: 2.5481596127266744

Epoch: 6| Step: 1
Training loss: 2.6430109745162946
Validation loss: 2.545570429469826

Epoch: 6| Step: 2
Training loss: 2.2894466976068393
Validation loss: 2.5399335648391452

Epoch: 6| Step: 3
Training loss: 2.6977647323736393
Validation loss: 2.6042659333700997

Epoch: 6| Step: 4
Training loss: 2.6012565730762063
Validation loss: 2.637105466010722

Epoch: 6| Step: 5
Training loss: 2.0247823009502666
Validation loss: 2.5678251187046697

Epoch: 6| Step: 6
Training loss: 3.085865184081471
Validation loss: 2.522929279181415

Epoch: 6| Step: 7
Training loss: 2.1716152557275636
Validation loss: 2.5767855468836554

Epoch: 6| Step: 8
Training loss: 1.8673205467929435
Validation loss: 2.6099875334616125

Epoch: 6| Step: 9
Training loss: 2.650693579544176
Validation loss: 2.5686939094155523

Epoch: 6| Step: 10
Training loss: 2.458774160742535
Validation loss: 2.5604149701759753

Epoch: 6| Step: 11
Training loss: 1.6155070544047219
Validation loss: 2.528315817567541

Epoch: 6| Step: 12
Training loss: 1.9664865228078137
Validation loss: 2.566922240929791

Epoch: 6| Step: 13
Training loss: 2.480649638150922
Validation loss: 2.574365730315262

Epoch: 74| Step: 0
Training loss: 1.7667753809942017
Validation loss: 2.659601632669389

Epoch: 6| Step: 1
Training loss: 2.4990526311674044
Validation loss: 2.6358675564733054

Epoch: 6| Step: 2
Training loss: 2.8522876392321486
Validation loss: 2.579246554475276

Epoch: 6| Step: 3
Training loss: 1.9056299795934588
Validation loss: 2.6042527578746433

Epoch: 6| Step: 4
Training loss: 2.188201355897166
Validation loss: 2.6210468589351867

Epoch: 6| Step: 5
Training loss: 2.189684730550899
Validation loss: 2.5821108899552536

Epoch: 6| Step: 6
Training loss: 2.1135982480159545
Validation loss: 2.6230583881836558

Epoch: 6| Step: 7
Training loss: 2.761587698280721
Validation loss: 2.5347796661510085

Epoch: 6| Step: 8
Training loss: 2.2746952942742054
Validation loss: 2.5528573296260437

Epoch: 6| Step: 9
Training loss: 2.2715609956579703
Validation loss: 2.6028621890483388

Epoch: 6| Step: 10
Training loss: 2.486803415422946
Validation loss: 2.619297395547345

Epoch: 6| Step: 11
Training loss: 1.8947325294777382
Validation loss: 2.527475635638781

Epoch: 6| Step: 12
Training loss: 3.103695383501631
Validation loss: 2.586536088487327

Epoch: 6| Step: 13
Training loss: 2.3648389994558126
Validation loss: 2.602487470295573

Epoch: 75| Step: 0
Training loss: 1.7952881813892274
Validation loss: 2.61558830025835

Epoch: 6| Step: 1
Training loss: 2.119834005946823
Validation loss: 2.532524604288716

Epoch: 6| Step: 2
Training loss: 1.924443768978857
Validation loss: 2.5792762035677907

Epoch: 6| Step: 3
Training loss: 2.25123837617863
Validation loss: 2.5749492930385576

Epoch: 6| Step: 4
Training loss: 2.707241385975036
Validation loss: 2.617438483658477

Epoch: 6| Step: 5
Training loss: 2.4386557748835327
Validation loss: 2.6554399938280535

Epoch: 6| Step: 6
Training loss: 2.5950520016672924
Validation loss: 2.5956056536841365

Epoch: 6| Step: 7
Training loss: 2.8061082901889387
Validation loss: 2.6489282714081996

Epoch: 6| Step: 8
Training loss: 2.6486945913657314
Validation loss: 2.6686851243435328

Epoch: 6| Step: 9
Training loss: 2.238135527815315
Validation loss: 2.5563078397317884

Epoch: 6| Step: 10
Training loss: 2.043012162690035
Validation loss: 2.4861014583217926

Epoch: 6| Step: 11
Training loss: 2.511205071920357
Validation loss: 2.55377305333952

Epoch: 6| Step: 12
Training loss: 2.1008513995368143
Validation loss: 2.540527711313859

Epoch: 6| Step: 13
Training loss: 2.8803470479294875
Validation loss: 2.678796232568914

Epoch: 76| Step: 0
Training loss: 2.371828270252063
Validation loss: 2.58861682611313

Epoch: 6| Step: 1
Training loss: 2.41733208626436
Validation loss: 2.5546345058781403

Epoch: 6| Step: 2
Training loss: 2.900427451365534
Validation loss: 2.5235110214120704

Epoch: 6| Step: 3
Training loss: 3.1640130686725154
Validation loss: 2.6526231127040565

Epoch: 6| Step: 4
Training loss: 2.3301306156663566
Validation loss: 2.6265555571359

Epoch: 6| Step: 5
Training loss: 2.4124584609492583
Validation loss: 2.62123357681274

Epoch: 6| Step: 6
Training loss: 2.530883008938114
Validation loss: 2.6089592943253472

Epoch: 6| Step: 7
Training loss: 1.490441544157809
Validation loss: 2.5985713866900486

Epoch: 6| Step: 8
Training loss: 2.7196459992836712
Validation loss: 2.6031249340556526

Epoch: 6| Step: 9
Training loss: 1.7932610699418174
Validation loss: 2.6280231475749325

Epoch: 6| Step: 10
Training loss: 1.9555424492329367
Validation loss: 2.6248788654291606

Epoch: 6| Step: 11
Training loss: 1.9533802323466884
Validation loss: 2.530975876395658

Epoch: 6| Step: 12
Training loss: 2.8864666695797347
Validation loss: 2.6379757143300124

Epoch: 6| Step: 13
Training loss: 1.4205969631585271
Validation loss: 2.567346068871799

Epoch: 77| Step: 0
Training loss: 2.5804482829073088
Validation loss: 2.628659074716088

Epoch: 6| Step: 1
Training loss: 2.619106670845115
Validation loss: 2.6234178316288985

Epoch: 6| Step: 2
Training loss: 2.2419250547352836
Validation loss: 2.5881912076075926

Epoch: 6| Step: 3
Training loss: 1.6944731291269426
Validation loss: 2.628963112747544

Epoch: 6| Step: 4
Training loss: 2.91583672477421
Validation loss: 2.6097845186363156

Epoch: 6| Step: 5
Training loss: 2.3880530590571714
Validation loss: 2.6144212290043

Epoch: 6| Step: 6
Training loss: 2.1926255259579825
Validation loss: 2.537513910139571

Epoch: 6| Step: 7
Training loss: 2.0207147727348915
Validation loss: 2.6777915067395535

Epoch: 6| Step: 8
Training loss: 2.8570687420632708
Validation loss: 2.608499909425129

Epoch: 6| Step: 9
Training loss: 2.483581800213073
Validation loss: 2.6072313103349347

Epoch: 6| Step: 10
Training loss: 2.027929438256931
Validation loss: 2.4878239553291865

Epoch: 6| Step: 11
Training loss: 2.2941440254236887
Validation loss: 2.573357638254997

Epoch: 6| Step: 12
Training loss: 2.125027263690855
Validation loss: 2.61683644839336

Epoch: 6| Step: 13
Training loss: 1.768005926303511
Validation loss: 2.5674175590445816

Epoch: 78| Step: 0
Training loss: 2.3464980227748393
Validation loss: 2.6333082507745673

Epoch: 6| Step: 1
Training loss: 2.5496841571653635
Validation loss: 2.5528928030907747

Epoch: 6| Step: 2
Training loss: 2.2640447959444647
Validation loss: 2.57598617150463

Epoch: 6| Step: 3
Training loss: 2.141588537173967
Validation loss: 2.5345843139710085

Epoch: 6| Step: 4
Training loss: 1.7490616735115982
Validation loss: 2.638928201170664

Epoch: 6| Step: 5
Training loss: 2.4210081456459784
Validation loss: 2.527780784935845

Epoch: 6| Step: 6
Training loss: 2.420762624928099
Validation loss: 2.503704187866321

Epoch: 6| Step: 7
Training loss: 1.8640705731993292
Validation loss: 2.573550811539694

Epoch: 6| Step: 8
Training loss: 2.2087568440787337
Validation loss: 2.5649413442814417

Epoch: 6| Step: 9
Training loss: 2.3112645328574413
Validation loss: 2.566475273609237

Epoch: 6| Step: 10
Training loss: 1.8498173468866193
Validation loss: 2.632310753468698

Epoch: 6| Step: 11
Training loss: 2.305789696882875
Validation loss: 2.491724638971514

Epoch: 6| Step: 12
Training loss: 3.276512868175155
Validation loss: 2.5710067816226583

Epoch: 6| Step: 13
Training loss: 2.5201731256022497
Validation loss: 2.5868017283389277

Epoch: 79| Step: 0
Training loss: 2.390245295270701
Validation loss: 2.659398639960882

Epoch: 6| Step: 1
Training loss: 1.9333082200206058
Validation loss: 2.6451762777766032

Epoch: 6| Step: 2
Training loss: 2.232734024238432
Validation loss: 2.6064488951781217

Epoch: 6| Step: 3
Training loss: 1.9856963676808626
Validation loss: 2.5845643822479842

Epoch: 6| Step: 4
Training loss: 2.316865975110506
Validation loss: 2.571922887678436

Epoch: 6| Step: 5
Training loss: 1.9220767651846835
Validation loss: 2.608329380710845

Epoch: 6| Step: 6
Training loss: 1.9344217396452443
Validation loss: 2.6371679681593405

Epoch: 6| Step: 7
Training loss: 2.3790856404934746
Validation loss: 2.596510203629848

Epoch: 6| Step: 8
Training loss: 2.8505439506906987
Validation loss: 2.589865307073312

Epoch: 6| Step: 9
Training loss: 3.0355103432245527
Validation loss: 2.65679915492274

Epoch: 6| Step: 10
Training loss: 2.5530813225099913
Validation loss: 2.661182192656337

Epoch: 6| Step: 11
Training loss: 2.5959594691834673
Validation loss: 2.654660351370991

Epoch: 6| Step: 12
Training loss: 1.9446273271144972
Validation loss: 2.633176784046924

Epoch: 6| Step: 13
Training loss: 2.163106879483839
Validation loss: 2.5219799040412956

Epoch: 80| Step: 0
Training loss: 1.9494080843354633
Validation loss: 2.5493762054278406

Epoch: 6| Step: 1
Training loss: 2.402870281793316
Validation loss: 2.5902070969616213

Epoch: 6| Step: 2
Training loss: 2.487595108744353
Validation loss: 2.658730623897701

Epoch: 6| Step: 3
Training loss: 1.9375548201158024
Validation loss: 2.5800321672588056

Epoch: 6| Step: 4
Training loss: 2.263401071249255
Validation loss: 2.5077162235908412

Epoch: 6| Step: 5
Training loss: 1.9062627573055444
Validation loss: 2.498611430145219

Epoch: 6| Step: 6
Training loss: 2.3173575032198834
Validation loss: 2.625297756564609

Epoch: 6| Step: 7
Training loss: 1.9380481313785256
Validation loss: 2.630836258267249

Epoch: 6| Step: 8
Training loss: 1.8691683042703031
Validation loss: 2.484860770599742

Epoch: 6| Step: 9
Training loss: 2.015772141401355
Validation loss: 2.6187795323274883

Epoch: 6| Step: 10
Training loss: 2.5820914534159534
Validation loss: 2.578404297775757

Epoch: 6| Step: 11
Training loss: 2.470405506407575
Validation loss: 2.620688470092622

Epoch: 6| Step: 12
Training loss: 2.292815481129123
Validation loss: 2.593918170609351

Epoch: 6| Step: 13
Training loss: 3.4913813878845295
Validation loss: 2.663152858227633

Epoch: 81| Step: 0
Training loss: 2.044993460348627
Validation loss: 2.6382788142557434

Epoch: 6| Step: 1
Training loss: 2.9114359864461776
Validation loss: 2.6476729648272967

Epoch: 6| Step: 2
Training loss: 2.50704706697595
Validation loss: 2.589304749492462

Epoch: 6| Step: 3
Training loss: 2.928464914172618
Validation loss: 2.6112995017743406

Epoch: 6| Step: 4
Training loss: 2.3853876925600876
Validation loss: 2.6081351191695146

Epoch: 6| Step: 5
Training loss: 2.3555292782827317
Validation loss: 2.5608113159845303

Epoch: 6| Step: 6
Training loss: 2.2774268735499885
Validation loss: 2.566521985034479

Epoch: 6| Step: 7
Training loss: 2.292777006330279
Validation loss: 2.6672738968380587

Epoch: 6| Step: 8
Training loss: 1.4948447967905227
Validation loss: 2.5907837018837547

Epoch: 6| Step: 9
Training loss: 2.9306346125332197
Validation loss: 2.567976666113251

Epoch: 6| Step: 10
Training loss: 1.59413979943237
Validation loss: 2.606327218574441

Epoch: 6| Step: 11
Training loss: 2.1972916665123474
Validation loss: 2.5661407441747572

Epoch: 6| Step: 12
Training loss: 2.4070527360223997
Validation loss: 2.562467008859038

Epoch: 6| Step: 13
Training loss: 2.086965928885778
Validation loss: 2.6044210284304823

Epoch: 82| Step: 0
Training loss: 1.666679151806162
Validation loss: 2.5374273737644413

Epoch: 6| Step: 1
Training loss: 2.541490444473834
Validation loss: 2.5343516777147665

Epoch: 6| Step: 2
Training loss: 1.7195127701968709
Validation loss: 2.4602163963843653

Epoch: 6| Step: 3
Training loss: 2.5793476326786737
Validation loss: 2.596357314332044

Epoch: 6| Step: 4
Training loss: 2.775528498318258
Validation loss: 2.5046527005810515

Epoch: 6| Step: 5
Training loss: 2.322085849229659
Validation loss: 2.53400878329964

Epoch: 6| Step: 6
Training loss: 2.2952823436981515
Validation loss: 2.628349075108978

Epoch: 6| Step: 7
Training loss: 3.206092910933811
Validation loss: 2.6025426658238033

Epoch: 6| Step: 8
Training loss: 2.2498581099805306
Validation loss: 2.6645554788389734

Epoch: 6| Step: 9
Training loss: 1.9618248622548173
Validation loss: 2.5971563560941973

Epoch: 6| Step: 10
Training loss: 1.6724577271460634
Validation loss: 2.6501234571621164

Epoch: 6| Step: 11
Training loss: 2.729842958789183
Validation loss: 2.6109727547786266

Epoch: 6| Step: 12
Training loss: 2.1231245853130574
Validation loss: 2.5831397173733244

Epoch: 6| Step: 13
Training loss: 1.9842084679598893
Validation loss: 2.648204196792756

Epoch: 83| Step: 0
Training loss: 2.320116850442458
Validation loss: 2.4938654497617754

Epoch: 6| Step: 1
Training loss: 2.3257532519781443
Validation loss: 2.555893499609208

Epoch: 6| Step: 2
Training loss: 3.1509775370647937
Validation loss: 2.5964253121553784

Epoch: 6| Step: 3
Training loss: 2.610993574306218
Validation loss: 2.602935566140211

Epoch: 6| Step: 4
Training loss: 2.1891482002206466
Validation loss: 2.5631446647742355

Epoch: 6| Step: 5
Training loss: 2.0636267618667095
Validation loss: 2.541583549724723

Epoch: 6| Step: 6
Training loss: 2.5219729871278824
Validation loss: 2.544431758751357

Epoch: 6| Step: 7
Training loss: 1.808306743350158
Validation loss: 2.5230618601777905

Epoch: 6| Step: 8
Training loss: 2.454001883483512
Validation loss: 2.6419873908341462

Epoch: 6| Step: 9
Training loss: 1.6388784648901407
Validation loss: 2.5171165704156158

Epoch: 6| Step: 10
Training loss: 2.198209649637023
Validation loss: 2.6019204841356642

Epoch: 6| Step: 11
Training loss: 2.394152662707847
Validation loss: 2.550751830511157

Epoch: 6| Step: 12
Training loss: 1.9353385066362847
Validation loss: 2.6036997312911696

Epoch: 6| Step: 13
Training loss: 1.7982202552807804
Validation loss: 2.6532274889162206

Epoch: 84| Step: 0
Training loss: 2.127305631264538
Validation loss: 2.635387576298243

Epoch: 6| Step: 1
Training loss: 2.397974124842023
Validation loss: 2.5986059379310933

Epoch: 6| Step: 2
Training loss: 2.1768480627039968
Validation loss: 2.621858169810823

Epoch: 6| Step: 3
Training loss: 2.350803493547919
Validation loss: 2.557154258770855

Epoch: 6| Step: 4
Training loss: 2.3590985066673573
Validation loss: 2.6437993729642737

Epoch: 6| Step: 5
Training loss: 2.6237473905204167
Validation loss: 2.6372735388800983

Epoch: 6| Step: 6
Training loss: 2.5042178812571123
Validation loss: 2.5405701450308356

Epoch: 6| Step: 7
Training loss: 2.0195913398111234
Validation loss: 2.55213765196831

Epoch: 6| Step: 8
Training loss: 1.5070800583501234
Validation loss: 2.588139498277822

Epoch: 6| Step: 9
Training loss: 1.9107410495243469
Validation loss: 2.481015298858998

Epoch: 6| Step: 10
Training loss: 1.7292132850092525
Validation loss: 2.4926557111041094

Epoch: 6| Step: 11
Training loss: 1.812724395541665
Validation loss: 2.5574925428588178

Epoch: 6| Step: 12
Training loss: 3.130457118721763
Validation loss: 2.615682474748349

Epoch: 6| Step: 13
Training loss: 2.732809610512516
Validation loss: 2.594641566723953

Epoch: 85| Step: 0
Training loss: 2.9045621831577435
Validation loss: 2.544532353767247

Epoch: 6| Step: 1
Training loss: 1.5032727777559338
Validation loss: 2.5158225982965994

Epoch: 6| Step: 2
Training loss: 1.7836883987664558
Validation loss: 2.535743570894214

Epoch: 6| Step: 3
Training loss: 2.3924679104079
Validation loss: 2.497695480577915

Epoch: 6| Step: 4
Training loss: 1.8791886908459252
Validation loss: 2.595446311506614

Epoch: 6| Step: 5
Training loss: 2.8327910147355566
Validation loss: 2.463853285411714

Epoch: 6| Step: 6
Training loss: 2.478379218013016
Validation loss: 2.5029150021871747

Epoch: 6| Step: 7
Training loss: 2.0816191932919303
Validation loss: 2.5482011240645583

Epoch: 6| Step: 8
Training loss: 2.015507894263473
Validation loss: 2.592278641533104

Epoch: 6| Step: 9
Training loss: 2.4495876588073253
Validation loss: 2.611734416190846

Epoch: 6| Step: 10
Training loss: 2.0540972539949585
Validation loss: 2.6208541161744647

Epoch: 6| Step: 11
Training loss: 2.713250220835568
Validation loss: 2.6091045612589845

Epoch: 6| Step: 12
Training loss: 2.2502752771465566
Validation loss: 2.4913783020321234

Epoch: 6| Step: 13
Training loss: 2.4962234582765026
Validation loss: 2.6030293969545966

Epoch: 86| Step: 0
Training loss: 2.4040322921285147
Validation loss: 2.596169534365936

Epoch: 6| Step: 1
Training loss: 2.0437628696048113
Validation loss: 2.5535413871773907

Epoch: 6| Step: 2
Training loss: 2.6722411858442467
Validation loss: 2.5486640965090137

Epoch: 6| Step: 3
Training loss: 1.6708973673332708
Validation loss: 2.4998679126177623

Epoch: 6| Step: 4
Training loss: 2.2929092737441814
Validation loss: 2.6055915494744895

Epoch: 6| Step: 5
Training loss: 2.4999605175715285
Validation loss: 2.6112651717501683

Epoch: 6| Step: 6
Training loss: 2.4111634658465615
Validation loss: 2.645470734528047

Epoch: 6| Step: 7
Training loss: 2.205395549839076
Validation loss: 2.675434232981966

Epoch: 6| Step: 8
Training loss: 2.1076990321832274
Validation loss: 2.6623578924661695

Epoch: 6| Step: 9
Training loss: 2.3268701640695406
Validation loss: 2.6579909509744453

Epoch: 6| Step: 10
Training loss: 1.9574791553698025
Validation loss: 2.74550796417969

Epoch: 6| Step: 11
Training loss: 2.8139542952284717
Validation loss: 2.5571291082631116

Epoch: 6| Step: 12
Training loss: 1.9565644154754802
Validation loss: 2.6316626629145654

Epoch: 6| Step: 13
Training loss: 2.6323625763094065
Validation loss: 2.555768421079718

Epoch: 87| Step: 0
Training loss: 1.9575532076292237
Validation loss: 2.6336413096755567

Epoch: 6| Step: 1
Training loss: 2.753360688841043
Validation loss: 2.618366685610777

Epoch: 6| Step: 2
Training loss: 2.177747950490198
Validation loss: 2.555265915277972

Epoch: 6| Step: 3
Training loss: 2.135466883619401
Validation loss: 2.6139177840587573

Epoch: 6| Step: 4
Training loss: 2.404580862594531
Validation loss: 2.6258323500266294

Epoch: 6| Step: 5
Training loss: 2.544028253356423
Validation loss: 2.515093097568932

Epoch: 6| Step: 6
Training loss: 1.3908231786894705
Validation loss: 2.5792394521998654

Epoch: 6| Step: 7
Training loss: 2.7369526076306134
Validation loss: 2.5845700246896803

Epoch: 6| Step: 8
Training loss: 2.9259694832118486
Validation loss: 2.58326001729807

Epoch: 6| Step: 9
Training loss: 1.6810999409809526
Validation loss: 2.5495235347036855

Epoch: 6| Step: 10
Training loss: 1.8996005792902475
Validation loss: 2.4988878875975606

Epoch: 6| Step: 11
Training loss: 2.411672353344557
Validation loss: 2.5606872690810913

Epoch: 6| Step: 12
Training loss: 1.7777889155330389
Validation loss: 2.609465766896597

Epoch: 6| Step: 13
Training loss: 2.2640296317611286
Validation loss: 2.5367570162041666

Epoch: 88| Step: 0
Training loss: 1.2036458659065448
Validation loss: 2.6818637000327183

Epoch: 6| Step: 1
Training loss: 1.954997759376276
Validation loss: 2.586333552799772

Epoch: 6| Step: 2
Training loss: 1.698192909407602
Validation loss: 2.5170519712788963

Epoch: 6| Step: 3
Training loss: 1.9612850170036413
Validation loss: 2.587261295211503

Epoch: 6| Step: 4
Training loss: 2.6984526544884244
Validation loss: 2.5904054488103356

Epoch: 6| Step: 5
Training loss: 2.6320241772315183
Validation loss: 2.5695988554279774

Epoch: 6| Step: 6
Training loss: 2.453595644759376
Validation loss: 2.493690507859556

Epoch: 6| Step: 7
Training loss: 2.6778131719635803
Validation loss: 2.563535984864359

Epoch: 6| Step: 8
Training loss: 2.0941027443791085
Validation loss: 2.5214756759387122

Epoch: 6| Step: 9
Training loss: 2.185969116767588
Validation loss: 2.5607195615793255

Epoch: 6| Step: 10
Training loss: 1.9483354971585143
Validation loss: 2.597107028503218

Epoch: 6| Step: 11
Training loss: 1.3956481991115413
Validation loss: 2.629478297881298

Epoch: 6| Step: 12
Training loss: 2.160807340705659
Validation loss: 2.6021147973199796

Epoch: 6| Step: 13
Training loss: 3.4881491983159085
Validation loss: 2.5221965403610054

Epoch: 89| Step: 0
Training loss: 2.703482543584174
Validation loss: 2.6017988477539316

Epoch: 6| Step: 1
Training loss: 1.7210449156410919
Validation loss: 2.5474424061677228

Epoch: 6| Step: 2
Training loss: 2.0423954292338857
Validation loss: 2.500797510099199

Epoch: 6| Step: 3
Training loss: 2.544381916558674
Validation loss: 2.556522795057967

Epoch: 6| Step: 4
Training loss: 3.238949254692808
Validation loss: 2.579498541643066

Epoch: 6| Step: 5
Training loss: 1.9677698026486279
Validation loss: 2.564302027934176

Epoch: 6| Step: 6
Training loss: 1.81719914020146
Validation loss: 2.579972323939504

Epoch: 6| Step: 7
Training loss: 1.9074263148243433
Validation loss: 2.5639532976841615

Epoch: 6| Step: 8
Training loss: 2.1364924504534826
Validation loss: 2.6057684791268616

Epoch: 6| Step: 9
Training loss: 2.851955773394538
Validation loss: 2.562783535723619

Epoch: 6| Step: 10
Training loss: 2.2389475311769327
Validation loss: 2.637203113666241

Epoch: 6| Step: 11
Training loss: 1.9535897274261191
Validation loss: 2.6226085183886463

Epoch: 6| Step: 12
Training loss: 2.669723894080393
Validation loss: 2.5465836153501993

Epoch: 6| Step: 13
Training loss: 1.5410563145669751
Validation loss: 2.6129391327017206

Epoch: 90| Step: 0
Training loss: 2.3054055340023143
Validation loss: 2.5540861302716373

Epoch: 6| Step: 1
Training loss: 1.4581463103488734
Validation loss: 2.6127670686973548

Epoch: 6| Step: 2
Training loss: 1.764793943096637
Validation loss: 2.568881037232427

Epoch: 6| Step: 3
Training loss: 1.9207240434228614
Validation loss: 2.613889356413351

Epoch: 6| Step: 4
Training loss: 1.6813610167880109
Validation loss: 2.6880621506983897

Epoch: 6| Step: 5
Training loss: 2.7910310866272656
Validation loss: 2.7227410294602135

Epoch: 6| Step: 6
Training loss: 2.378653276394388
Validation loss: 2.791823643688201

Epoch: 6| Step: 7
Training loss: 2.3506662682316373
Validation loss: 2.716756433240325

Epoch: 6| Step: 8
Training loss: 3.051020692228143
Validation loss: 2.712067184548634

Epoch: 6| Step: 9
Training loss: 2.6925473389497445
Validation loss: 2.612522663279768

Epoch: 6| Step: 10
Training loss: 1.895606610780914
Validation loss: 2.593149107916524

Epoch: 6| Step: 11
Training loss: 2.4810724920393588
Validation loss: 2.5542798353786687

Epoch: 6| Step: 12
Training loss: 2.592405867159737
Validation loss: 2.6200854450833386

Epoch: 6| Step: 13
Training loss: 2.528133404579857
Validation loss: 2.564251572454649

Epoch: 91| Step: 0
Training loss: 2.1514169459534553
Validation loss: 2.5979720074332713

Epoch: 6| Step: 1
Training loss: 1.9045958298989722
Validation loss: 2.6037824703370624

Epoch: 6| Step: 2
Training loss: 2.5192799050987515
Validation loss: 2.612635047439795

Epoch: 6| Step: 3
Training loss: 2.611552534824999
Validation loss: 2.595460641680002

Epoch: 6| Step: 4
Training loss: 3.0580302726689235
Validation loss: 2.5300956338717646

Epoch: 6| Step: 5
Training loss: 2.2903795847239734
Validation loss: 2.648645428472607

Epoch: 6| Step: 6
Training loss: 2.0485805947424955
Validation loss: 2.569580283025279

Epoch: 6| Step: 7
Training loss: 2.071087616544813
Validation loss: 2.5218523398716286

Epoch: 6| Step: 8
Training loss: 1.933998142687311
Validation loss: 2.563933715747592

Epoch: 6| Step: 9
Training loss: 2.4717013909371603
Validation loss: 2.5677454844502465

Epoch: 6| Step: 10
Training loss: 2.6134833242067916
Validation loss: 2.6017699287819136

Epoch: 6| Step: 11
Training loss: 2.3833949643504972
Validation loss: 2.6122977359477213

Epoch: 6| Step: 12
Training loss: 1.6312949689608056
Validation loss: 2.496252827955544

Epoch: 6| Step: 13
Training loss: 2.1027420307426117
Validation loss: 2.575725263165108

Epoch: 92| Step: 0
Training loss: 2.1809722504947144
Validation loss: 2.6226207607649505

Epoch: 6| Step: 1
Training loss: 3.0033737921097727
Validation loss: 2.6494170846346528

Epoch: 6| Step: 2
Training loss: 1.6422827202134145
Validation loss: 2.7048892105551694

Epoch: 6| Step: 3
Training loss: 2.377927080658222
Validation loss: 2.635714417375243

Epoch: 6| Step: 4
Training loss: 3.210815130347671
Validation loss: 2.6505622480238626

Epoch: 6| Step: 5
Training loss: 2.409920605186657
Validation loss: 2.642815007177051

Epoch: 6| Step: 6
Training loss: 2.041664071632864
Validation loss: 2.671049938751932

Epoch: 6| Step: 7
Training loss: 1.5240464778431058
Validation loss: 2.5744501221196816

Epoch: 6| Step: 8
Training loss: 1.9097406914328459
Validation loss: 2.6373356302397277

Epoch: 6| Step: 9
Training loss: 1.875551269871866
Validation loss: 2.560759775334447

Epoch: 6| Step: 10
Training loss: 2.0601488063360973
Validation loss: 2.583437830339442

Epoch: 6| Step: 11
Training loss: 1.5624220256422905
Validation loss: 2.5927780658994313

Epoch: 6| Step: 12
Training loss: 2.253219632133611
Validation loss: 2.602006647116644

Epoch: 6| Step: 13
Training loss: 2.64918566013506
Validation loss: 2.6005964958195276

Epoch: 93| Step: 0
Training loss: 2.035493262680624
Validation loss: 2.57429532837795

Epoch: 6| Step: 1
Training loss: 1.5578767661839374
Validation loss: 2.5183129492270715

Epoch: 6| Step: 2
Training loss: 1.4933754551146756
Validation loss: 2.6641743954365533

Epoch: 6| Step: 3
Training loss: 2.675194089746791
Validation loss: 2.570332767673345

Epoch: 6| Step: 4
Training loss: 2.01640836884817
Validation loss: 2.5646996555138695

Epoch: 6| Step: 5
Training loss: 2.5213550206459856
Validation loss: 2.591663287202486

Epoch: 6| Step: 6
Training loss: 2.569049374104062
Validation loss: 2.593689178611614

Epoch: 6| Step: 7
Training loss: 2.027935551757328
Validation loss: 2.5175776199249555

Epoch: 6| Step: 8
Training loss: 2.898532588252396
Validation loss: 2.5449544299979108

Epoch: 6| Step: 9
Training loss: 2.6277130275793166
Validation loss: 2.655179791741699

Epoch: 6| Step: 10
Training loss: 2.096884359915888
Validation loss: 2.6315780447238915

Epoch: 6| Step: 11
Training loss: 2.408046200629052
Validation loss: 2.567654658769565

Epoch: 6| Step: 12
Training loss: 2.0788935337301333
Validation loss: 2.620466154321385

Epoch: 6| Step: 13
Training loss: 1.9146956661617414
Validation loss: 2.645056638081202

Epoch: 94| Step: 0
Training loss: 2.4621701983044755
Validation loss: 2.617155418389153

Epoch: 6| Step: 1
Training loss: 1.3891178922475647
Validation loss: 2.5575487560523373

Epoch: 6| Step: 2
Training loss: 2.5478596100510122
Validation loss: 2.604691938195493

Epoch: 6| Step: 3
Training loss: 2.393803098403413
Validation loss: 2.5822521428792937

Epoch: 6| Step: 4
Training loss: 2.818817926167813
Validation loss: 2.58157560836431

Epoch: 6| Step: 5
Training loss: 2.2720599113678155
Validation loss: 2.5747324190335577

Epoch: 6| Step: 6
Training loss: 1.9748042432127875
Validation loss: 2.6153510487640625

Epoch: 6| Step: 7
Training loss: 2.6942483321545145
Validation loss: 2.582223489735143

Epoch: 6| Step: 8
Training loss: 2.2201712985578808
Validation loss: 2.5623816486102857

Epoch: 6| Step: 9
Training loss: 1.8309575495067336
Validation loss: 2.547508816165662

Epoch: 6| Step: 10
Training loss: 2.3241227330482106
Validation loss: 2.589477198587604

Epoch: 6| Step: 11
Training loss: 1.9605616479086405
Validation loss: 2.5045999566808828

Epoch: 6| Step: 12
Training loss: 1.8843453526734661
Validation loss: 2.5568500507821836

Epoch: 6| Step: 13
Training loss: 2.0312582162544164
Validation loss: 2.5119331390975006

Epoch: 95| Step: 0
Training loss: 1.7129439342385036
Validation loss: 2.6491022766662216

Epoch: 6| Step: 1
Training loss: 1.9081738878741492
Validation loss: 2.5962740708179473

Epoch: 6| Step: 2
Training loss: 1.8319600626244628
Validation loss: 2.694736039440698

Epoch: 6| Step: 3
Training loss: 2.922901646382209
Validation loss: 2.6880104408193843

Epoch: 6| Step: 4
Training loss: 2.251848732876895
Validation loss: 2.655529986763428

Epoch: 6| Step: 5
Training loss: 2.8839600302774295
Validation loss: 2.690957558431289

Epoch: 6| Step: 6
Training loss: 2.1203710965385594
Validation loss: 2.5908300517263783

Epoch: 6| Step: 7
Training loss: 2.7173925935493397
Validation loss: 2.5864028435135813

Epoch: 6| Step: 8
Training loss: 2.5676036346528677
Validation loss: 2.6269031846074884

Epoch: 6| Step: 9
Training loss: 2.5320407903739293
Validation loss: 2.5523125344461453

Epoch: 6| Step: 10
Training loss: 1.6697934463818307
Validation loss: 2.629583096863598

Epoch: 6| Step: 11
Training loss: 2.274061818607003
Validation loss: 2.5334651500723395

Epoch: 6| Step: 12
Training loss: 2.2347503560235893
Validation loss: 2.5863220912300453

Epoch: 6| Step: 13
Training loss: 1.9304424461632128
Validation loss: 2.5457555732984467

Epoch: 96| Step: 0
Training loss: 2.1870517816470345
Validation loss: 2.599585651735606

Epoch: 6| Step: 1
Training loss: 1.9673030319405351
Validation loss: 2.4485467032346646

Epoch: 6| Step: 2
Training loss: 2.6336547228902
Validation loss: 2.6030607749095918

Epoch: 6| Step: 3
Training loss: 1.6611391277069845
Validation loss: 2.5610625724670517

Epoch: 6| Step: 4
Training loss: 1.8081674423537253
Validation loss: 2.530374320563814

Epoch: 6| Step: 5
Training loss: 2.1728426746658114
Validation loss: 2.6530699299974407

Epoch: 6| Step: 6
Training loss: 2.3226898036962096
Validation loss: 2.614923513301658

Epoch: 6| Step: 7
Training loss: 1.994103202506047
Validation loss: 2.700778994211247

Epoch: 6| Step: 8
Training loss: 1.805616461712861
Validation loss: 2.6067840901030426

Epoch: 6| Step: 9
Training loss: 2.6047177354766
Validation loss: 2.591499838616392

Epoch: 6| Step: 10
Training loss: 2.281213629445727
Validation loss: 2.5721837954972826

Epoch: 6| Step: 11
Training loss: 3.235312653044781
Validation loss: 2.5946631987959545

Epoch: 6| Step: 12
Training loss: 2.172715717312515
Validation loss: 2.5431425520593636

Epoch: 6| Step: 13
Training loss: 2.4657008015592763
Validation loss: 2.6128804308589353

Epoch: 97| Step: 0
Training loss: 2.834880369107896
Validation loss: 2.5294501023783518

Epoch: 6| Step: 1
Training loss: 2.1302179337885994
Validation loss: 2.5617263680597153

Epoch: 6| Step: 2
Training loss: 1.5387073242566531
Validation loss: 2.5062352624778566

Epoch: 6| Step: 3
Training loss: 2.0306713747298493
Validation loss: 2.6109137804349167

Epoch: 6| Step: 4
Training loss: 2.021084275018861
Validation loss: 2.6177910407758875

Epoch: 6| Step: 5
Training loss: 2.356871432410681
Validation loss: 2.610924449182626

Epoch: 6| Step: 6
Training loss: 2.7201523945695794
Validation loss: 2.6374129071553027

Epoch: 6| Step: 7
Training loss: 2.3750367412736804
Validation loss: 2.5855806225460123

Epoch: 6| Step: 8
Training loss: 2.083861729052709
Validation loss: 2.5853572859132425

Epoch: 6| Step: 9
Training loss: 2.0530406313302283
Validation loss: 2.5110421621605457

Epoch: 6| Step: 10
Training loss: 2.4915713322835895
Validation loss: 2.5547278864756735

Epoch: 6| Step: 11
Training loss: 2.4908234980229373
Validation loss: 2.5747108895919

Epoch: 6| Step: 12
Training loss: 2.193014768328952
Validation loss: 2.585599187596551

Epoch: 6| Step: 13
Training loss: 2.0268247083270206
Validation loss: 2.591163647972222

Epoch: 98| Step: 0
Training loss: 1.9517256950271342
Validation loss: 2.573061693147991

Epoch: 6| Step: 1
Training loss: 2.1469996964446
Validation loss: 2.6076444723716

Epoch: 6| Step: 2
Training loss: 2.1673140903456836
Validation loss: 2.6721583656718706

Epoch: 6| Step: 3
Training loss: 1.5928789638268501
Validation loss: 2.6722081592010887

Epoch: 6| Step: 4
Training loss: 2.249732213509248
Validation loss: 2.651634110139592

Epoch: 6| Step: 5
Training loss: 2.0655488108378397
Validation loss: 2.7059413519530597

Epoch: 6| Step: 6
Training loss: 2.7800204527397576
Validation loss: 2.7790754725541915

Epoch: 6| Step: 7
Training loss: 2.4568222272353757
Validation loss: 2.586340451226771

Epoch: 6| Step: 8
Training loss: 2.2425728177737234
Validation loss: 2.6232584747004997

Epoch: 6| Step: 9
Training loss: 1.3700729874151694
Validation loss: 2.5942557121489185

Epoch: 6| Step: 10
Training loss: 2.3035513453489984
Validation loss: 2.6048010447619934

Epoch: 6| Step: 11
Training loss: 2.646530590146522
Validation loss: 2.5539764596914196

Epoch: 6| Step: 12
Training loss: 2.223641175667738
Validation loss: 2.5541625343857692

Epoch: 6| Step: 13
Training loss: 2.3017152402790324
Validation loss: 2.5616824156137032

Epoch: 99| Step: 0
Training loss: 2.844499258748369
Validation loss: 2.5701087785897268

Epoch: 6| Step: 1
Training loss: 1.7647540214461412
Validation loss: 2.5769166522962426

Epoch: 6| Step: 2
Training loss: 2.0661271308787774
Validation loss: 2.5810782423903897

Epoch: 6| Step: 3
Training loss: 2.104058240860413
Validation loss: 2.565276936297602

Epoch: 6| Step: 4
Training loss: 2.35037799798212
Validation loss: 2.621414354465709

Epoch: 6| Step: 5
Training loss: 2.061838795418361
Validation loss: 2.497486360809892

Epoch: 6| Step: 6
Training loss: 1.7845640974175594
Validation loss: 2.6062289401026058

Epoch: 6| Step: 7
Training loss: 2.3780676455104333
Validation loss: 2.634504052165389

Epoch: 6| Step: 8
Training loss: 2.248069252678317
Validation loss: 2.539342401188712

Epoch: 6| Step: 9
Training loss: 2.8710364511182895
Validation loss: 2.530532562559902

Epoch: 6| Step: 10
Training loss: 1.484758749095127
Validation loss: 2.629228380408948

Epoch: 6| Step: 11
Training loss: 1.6719002409838937
Validation loss: 2.6544384931445544

Epoch: 6| Step: 12
Training loss: 2.494630196481977
Validation loss: 2.637563401555484

Epoch: 6| Step: 13
Training loss: 2.278401307564264
Validation loss: 2.571346542618047

Epoch: 100| Step: 0
Training loss: 1.957211484242856
Validation loss: 2.610846296932287

Epoch: 6| Step: 1
Training loss: 1.52773184370096
Validation loss: 2.629110070499545

Epoch: 6| Step: 2
Training loss: 2.652068493230453
Validation loss: 2.7077416923056687

Epoch: 6| Step: 3
Training loss: 2.3636855607148006
Validation loss: 2.7248266573260342

Epoch: 6| Step: 4
Training loss: 2.909107731098609
Validation loss: 2.686065675503956

Epoch: 6| Step: 5
Training loss: 1.5402204156407984
Validation loss: 2.6586879537540713

Epoch: 6| Step: 6
Training loss: 2.3252332508848457
Validation loss: 2.552326912187551

Epoch: 6| Step: 7
Training loss: 2.810714833302288
Validation loss: 2.5613409460430545

Epoch: 6| Step: 8
Training loss: 1.6981027731284963
Validation loss: 2.5550816005459005

Epoch: 6| Step: 9
Training loss: 1.88005554198337
Validation loss: 2.660059721283467

Epoch: 6| Step: 10
Training loss: 1.9185898779245874
Validation loss: 2.5617744535141047

Epoch: 6| Step: 11
Training loss: 2.2597099172044426
Validation loss: 2.637677792045238

Epoch: 6| Step: 12
Training loss: 2.1174507681247583
Validation loss: 2.55674787334785

Epoch: 6| Step: 13
Training loss: 2.2156632133599685
Validation loss: 2.4810099494434246

Epoch: 101| Step: 0
Training loss: 2.264645068588482
Validation loss: 2.6282889939049263

Epoch: 6| Step: 1
Training loss: 1.9241123357442917
Validation loss: 2.5327628681294128

Epoch: 6| Step: 2
Training loss: 2.6645913591977344
Validation loss: 2.5753940490641263

Epoch: 6| Step: 3
Training loss: 1.711086040302151
Validation loss: 2.555655775201305

Epoch: 6| Step: 4
Training loss: 2.121622543035968
Validation loss: 2.595054405710292

Epoch: 6| Step: 5
Training loss: 1.7070213335041629
Validation loss: 2.61650928420875

Epoch: 6| Step: 6
Training loss: 1.6059894691872612
Validation loss: 2.6112063181431187

Epoch: 6| Step: 7
Training loss: 1.8040955468565127
Validation loss: 2.622314964545122

Epoch: 6| Step: 8
Training loss: 2.1961403368524497
Validation loss: 2.664064379380981

Epoch: 6| Step: 9
Training loss: 2.3927180284351586
Validation loss: 2.576848926126999

Epoch: 6| Step: 10
Training loss: 2.4112785607402043
Validation loss: 2.525800875693605

Epoch: 6| Step: 11
Training loss: 2.0621344502494887
Validation loss: 2.5715523833788465

Epoch: 6| Step: 12
Training loss: 2.7221008347243014
Validation loss: 2.597964436311881

Epoch: 6| Step: 13
Training loss: 2.2101519911270935
Validation loss: 2.6059698092989763

Epoch: 102| Step: 0
Training loss: 2.0825008127639117
Validation loss: 2.500584128803081

Epoch: 6| Step: 1
Training loss: 2.2532286261697396
Validation loss: 2.5271838145918846

Epoch: 6| Step: 2
Training loss: 1.7529343798901331
Validation loss: 2.5676761235711667

Epoch: 6| Step: 3
Training loss: 2.1434937348964955
Validation loss: 2.6133738654830845

Epoch: 6| Step: 4
Training loss: 2.0344112738731583
Validation loss: 2.586764815064447

Epoch: 6| Step: 5
Training loss: 1.9917815150050031
Validation loss: 2.5814618027608627

Epoch: 6| Step: 6
Training loss: 2.2546239599420184
Validation loss: 2.4243718474196263

Epoch: 6| Step: 7
Training loss: 2.0028574319990473
Validation loss: 2.6172749063500276

Epoch: 6| Step: 8
Training loss: 2.0636972362628643
Validation loss: 2.5507629144622

Epoch: 6| Step: 9
Training loss: 1.8504752012754124
Validation loss: 2.5176083030499923

Epoch: 6| Step: 10
Training loss: 2.08996079732094
Validation loss: 2.543263579904028

Epoch: 6| Step: 11
Training loss: 2.3129685416978836
Validation loss: 2.626553378598973

Epoch: 6| Step: 12
Training loss: 2.3075267824083823
Validation loss: 2.608376073842574

Epoch: 6| Step: 13
Training loss: 2.83955761754871
Validation loss: 2.543026713986627

Epoch: 103| Step: 0
Training loss: 1.8753558139156503
Validation loss: 2.5130242514051737

Epoch: 6| Step: 1
Training loss: 1.8332319087092117
Validation loss: 2.586779746340038

Epoch: 6| Step: 2
Training loss: 2.0108830466081886
Validation loss: 2.602157318574232

Epoch: 6| Step: 3
Training loss: 1.8027774892427004
Validation loss: 2.602952900632251

Epoch: 6| Step: 4
Training loss: 1.966817361370776
Validation loss: 2.627564464277967

Epoch: 6| Step: 5
Training loss: 1.8398265797326119
Validation loss: 2.684903553983365

Epoch: 6| Step: 6
Training loss: 2.425517044790721
Validation loss: 2.7031112846952676

Epoch: 6| Step: 7
Training loss: 3.0133427497694134
Validation loss: 2.648883538209637

Epoch: 6| Step: 8
Training loss: 2.2586101456175376
Validation loss: 2.6106496122949086

Epoch: 6| Step: 9
Training loss: 2.068893003563227
Validation loss: 2.6205412675160136

Epoch: 6| Step: 10
Training loss: 1.6499838423660305
Validation loss: 2.530901771108271

Epoch: 6| Step: 11
Training loss: 2.7178609863391565
Validation loss: 2.595997537488313

Epoch: 6| Step: 12
Training loss: 2.1529057317738705
Validation loss: 2.588673476324262

Epoch: 6| Step: 13
Training loss: 2.2052519791406846
Validation loss: 2.464281391813964

Epoch: 104| Step: 0
Training loss: 2.1217637944470327
Validation loss: 2.6031158056321937

Epoch: 6| Step: 1
Training loss: 1.9358599089189896
Validation loss: 2.514617576039386

Epoch: 6| Step: 2
Training loss: 1.7549583490977416
Validation loss: 2.5615005715140136

Epoch: 6| Step: 3
Training loss: 2.4994879198142983
Validation loss: 2.5148281154203853

Epoch: 6| Step: 4
Training loss: 2.4206437457417866
Validation loss: 2.6509594158211187

Epoch: 6| Step: 5
Training loss: 1.818531786225753
Validation loss: 2.562933985858816

Epoch: 6| Step: 6
Training loss: 1.9187586259182061
Validation loss: 2.5666631050415427

Epoch: 6| Step: 7
Training loss: 1.586080384982149
Validation loss: 2.478036588203713

Epoch: 6| Step: 8
Training loss: 2.9150431519548365
Validation loss: 2.6438182656663316

Epoch: 6| Step: 9
Training loss: 2.41039503698335
Validation loss: 2.5979317961137296

Epoch: 6| Step: 10
Training loss: 1.5246728827668512
Validation loss: 2.5664790436878584

Epoch: 6| Step: 11
Training loss: 1.5659108127564898
Validation loss: 2.6206221556577947

Epoch: 6| Step: 12
Training loss: 2.100256304767428
Validation loss: 2.5325386707307036

Epoch: 6| Step: 13
Training loss: 2.2463424412254542
Validation loss: 2.589500423668292

Epoch: 105| Step: 0
Training loss: 2.0041357433235993
Validation loss: 2.476103233649349

Epoch: 6| Step: 1
Training loss: 2.2845473823267373
Validation loss: 2.622813176746206

Epoch: 6| Step: 2
Training loss: 2.3204467940080034
Validation loss: 2.612310444953254

Epoch: 6| Step: 3
Training loss: 2.360390551950939
Validation loss: 2.626152224686829

Epoch: 6| Step: 4
Training loss: 1.8878881649014723
Validation loss: 2.5695158430151586

Epoch: 6| Step: 5
Training loss: 2.443880582086513
Validation loss: 2.555432645518774

Epoch: 6| Step: 6
Training loss: 2.4341526032742093
Validation loss: 2.519235078028072

Epoch: 6| Step: 7
Training loss: 1.9648642567347494
Validation loss: 2.563147920402013

Epoch: 6| Step: 8
Training loss: 1.8416583594685765
Validation loss: 2.544982066288024

Epoch: 6| Step: 9
Training loss: 1.711918519139949
Validation loss: 2.59124953990539

Epoch: 6| Step: 10
Training loss: 1.8957724369315518
Validation loss: 2.5840623785669283

Epoch: 6| Step: 11
Training loss: 1.723265525005253
Validation loss: 2.5762615520842047

Epoch: 6| Step: 12
Training loss: 2.195838295088295
Validation loss: 2.5653891442227788

Epoch: 6| Step: 13
Training loss: 1.876963159889603
Validation loss: 2.663395340388254

Epoch: 106| Step: 0
Training loss: 1.9406246707442982
Validation loss: 2.6460605033210247

Epoch: 6| Step: 1
Training loss: 3.023302651880179
Validation loss: 2.605072082796238

Epoch: 6| Step: 2
Training loss: 2.156661947953704
Validation loss: 2.5402883377768766

Epoch: 6| Step: 3
Training loss: 2.1751863772460593
Validation loss: 2.5895490675296178

Epoch: 6| Step: 4
Training loss: 2.2179260873269007
Validation loss: 2.558568605876967

Epoch: 6| Step: 5
Training loss: 1.813510744494763
Validation loss: 2.5709662567430875

Epoch: 6| Step: 6
Training loss: 2.576277006952617
Validation loss: 2.526442078516372

Epoch: 6| Step: 7
Training loss: 2.1261132633975937
Validation loss: 2.5095938815518477

Epoch: 6| Step: 8
Training loss: 2.035268242330063
Validation loss: 2.57821405430355

Epoch: 6| Step: 9
Training loss: 1.7631482332328994
Validation loss: 2.658199597126761

Epoch: 6| Step: 10
Training loss: 2.0106001327157914
Validation loss: 2.6163764494015793

Epoch: 6| Step: 11
Training loss: 1.8234312657214549
Validation loss: 2.6393272250566415

Epoch: 6| Step: 12
Training loss: 1.9733078890633546
Validation loss: 2.47857330872386

Epoch: 6| Step: 13
Training loss: 2.106500093457817
Validation loss: 2.6382682787171836

Epoch: 107| Step: 0
Training loss: 1.6478538022145353
Validation loss: 2.6565617097952834

Epoch: 6| Step: 1
Training loss: 1.58418695962916
Validation loss: 2.5171576149490704

Epoch: 6| Step: 2
Training loss: 2.3098472638849534
Validation loss: 2.6645936408500948

Epoch: 6| Step: 3
Training loss: 1.993747115656282
Validation loss: 2.520050255599796

Epoch: 6| Step: 4
Training loss: 2.4103455801471423
Validation loss: 2.528555829495479

Epoch: 6| Step: 5
Training loss: 2.280921285278703
Validation loss: 2.5583450778935974

Epoch: 6| Step: 6
Training loss: 2.2241714220602407
Validation loss: 2.5352307324863665

Epoch: 6| Step: 7
Training loss: 1.4310554672037081
Validation loss: 2.546682260783453

Epoch: 6| Step: 8
Training loss: 2.7220882222764122
Validation loss: 2.529439851900199

Epoch: 6| Step: 9
Training loss: 2.3830254131311537
Validation loss: 2.4679808082298065

Epoch: 6| Step: 10
Training loss: 1.6560100165630869
Validation loss: 2.461724388626987

Epoch: 6| Step: 11
Training loss: 2.490694657216794
Validation loss: 2.45960045071586

Epoch: 6| Step: 12
Training loss: 1.9352833773483586
Validation loss: 2.5100074265662733

Epoch: 6| Step: 13
Training loss: 2.13631300063786
Validation loss: 2.5756601592288977

Epoch: 108| Step: 0
Training loss: 1.7624809155885124
Validation loss: 2.5647786096827137

Epoch: 6| Step: 1
Training loss: 1.9573708732566837
Validation loss: 2.619334616459375

Epoch: 6| Step: 2
Training loss: 2.0011571874308505
Validation loss: 2.634357712079178

Epoch: 6| Step: 3
Training loss: 2.591782708549735
Validation loss: 2.460050110048138

Epoch: 6| Step: 4
Training loss: 1.856066669697196
Validation loss: 2.546616539195499

Epoch: 6| Step: 5
Training loss: 1.3400869343442001
Validation loss: 2.5491615126093072

Epoch: 6| Step: 6
Training loss: 1.7630246348788485
Validation loss: 2.450369548823523

Epoch: 6| Step: 7
Training loss: 2.7551382785440963
Validation loss: 2.5566501991242303

Epoch: 6| Step: 8
Training loss: 2.3177152026356826
Validation loss: 2.5284177688434126

Epoch: 6| Step: 9
Training loss: 2.062404745965651
Validation loss: 2.593557281688189

Epoch: 6| Step: 10
Training loss: 2.3477708023737147
Validation loss: 2.663050656096029

Epoch: 6| Step: 11
Training loss: 2.5302429079593938
Validation loss: 2.561234052927103

Epoch: 6| Step: 12
Training loss: 1.8277470776776272
Validation loss: 2.6669557807082884

Epoch: 6| Step: 13
Training loss: 1.6335316219766174
Validation loss: 2.6420068680228543

Epoch: 109| Step: 0
Training loss: 2.11393662759571
Validation loss: 2.538562056300808

Epoch: 6| Step: 1
Training loss: 1.639512402342444
Validation loss: 2.6411571681228834

Epoch: 6| Step: 2
Training loss: 2.1580834817303596
Validation loss: 2.594409766794783

Epoch: 6| Step: 3
Training loss: 1.8149903388068374
Validation loss: 2.5685772744153215

Epoch: 6| Step: 4
Training loss: 1.901487247730218
Validation loss: 2.602507701157588

Epoch: 6| Step: 5
Training loss: 1.5718193605559858
Validation loss: 2.5385873046662946

Epoch: 6| Step: 6
Training loss: 1.7391164766145417
Validation loss: 2.4593444835251175

Epoch: 6| Step: 7
Training loss: 2.5010749413245463
Validation loss: 2.550728299349313

Epoch: 6| Step: 8
Training loss: 1.8713230956127882
Validation loss: 2.558586248721709

Epoch: 6| Step: 9
Training loss: 2.1582013574653396
Validation loss: 2.6086806555589903

Epoch: 6| Step: 10
Training loss: 2.2593763802551865
Validation loss: 2.515664742039369

Epoch: 6| Step: 11
Training loss: 2.4702636327862475
Validation loss: 2.5414738712252234

Epoch: 6| Step: 12
Training loss: 2.5346233354436873
Validation loss: 2.5769818941061784

Epoch: 6| Step: 13
Training loss: 2.0696977962357015
Validation loss: 2.5100444713011654

Epoch: 110| Step: 0
Training loss: 1.3664424064829754
Validation loss: 2.6285549720785584

Epoch: 6| Step: 1
Training loss: 1.8167178307190792
Validation loss: 2.599018697604608

Epoch: 6| Step: 2
Training loss: 2.195348556059555
Validation loss: 2.5534582106611285

Epoch: 6| Step: 3
Training loss: 2.708743568064223
Validation loss: 2.6049292147312517

Epoch: 6| Step: 4
Training loss: 1.688003959285016
Validation loss: 2.7321981138927613

Epoch: 6| Step: 5
Training loss: 1.765322634032596
Validation loss: 2.5788119239047447

Epoch: 6| Step: 6
Training loss: 2.7461178861292614
Validation loss: 2.5476920410686756

Epoch: 6| Step: 7
Training loss: 1.908654307007064
Validation loss: 2.60186333582757

Epoch: 6| Step: 8
Training loss: 1.9682479702718476
Validation loss: 2.571490666103959

Epoch: 6| Step: 9
Training loss: 1.9657124898631424
Validation loss: 2.5090435646879783

Epoch: 6| Step: 10
Training loss: 2.8859323713239484
Validation loss: 2.5586529673938005

Epoch: 6| Step: 11
Training loss: 1.240623881534101
Validation loss: 2.589235912432862

Epoch: 6| Step: 12
Training loss: 2.024353526968162
Validation loss: 2.540299889728001

Epoch: 6| Step: 13
Training loss: 1.6631878627292036
Validation loss: 2.503816473071007

Epoch: 111| Step: 0
Training loss: 2.1415994472815023
Validation loss: 2.608862653370586

Epoch: 6| Step: 1
Training loss: 1.499981959552362
Validation loss: 2.578233473836606

Epoch: 6| Step: 2
Training loss: 1.9466194756657969
Validation loss: 2.5438556833518997

Epoch: 6| Step: 3
Training loss: 1.9866479186745818
Validation loss: 2.5456293722593286

Epoch: 6| Step: 4
Training loss: 1.6561753598074909
Validation loss: 2.5099327338527977

Epoch: 6| Step: 5
Training loss: 1.9230380997040095
Validation loss: 2.6165736906780546

Epoch: 6| Step: 6
Training loss: 2.9762257463091006
Validation loss: 2.591534338472696

Epoch: 6| Step: 7
Training loss: 2.3020782700795093
Validation loss: 2.5239470826539923

Epoch: 6| Step: 8
Training loss: 1.7509810558799708
Validation loss: 2.478612803184115

Epoch: 6| Step: 9
Training loss: 1.8993698781814632
Validation loss: 2.5583377700377854

Epoch: 6| Step: 10
Training loss: 1.5962924499363758
Validation loss: 2.568241216264714

Epoch: 6| Step: 11
Training loss: 2.0184169624489776
Validation loss: 2.663403993663089

Epoch: 6| Step: 12
Training loss: 2.00592534180567
Validation loss: 2.63409925158733

Epoch: 6| Step: 13
Training loss: 1.9273208746694899
Validation loss: 2.674174295424242

Epoch: 112| Step: 0
Training loss: 1.875121557745855
Validation loss: 2.621892694558295

Epoch: 6| Step: 1
Training loss: 2.2435907631477026
Validation loss: 2.5659173802726887

Epoch: 6| Step: 2
Training loss: 1.809167363140172
Validation loss: 2.665463941269254

Epoch: 6| Step: 3
Training loss: 1.6623507726710829
Validation loss: 2.633264881966612

Epoch: 6| Step: 4
Training loss: 1.6845622452252484
Validation loss: 2.640280420818296

Epoch: 6| Step: 5
Training loss: 1.93564264424319
Validation loss: 2.617183385437725

Epoch: 6| Step: 6
Training loss: 1.7683485512373769
Validation loss: 2.639968158356504

Epoch: 6| Step: 7
Training loss: 2.255517763636562
Validation loss: 2.6368848960240494

Epoch: 6| Step: 8
Training loss: 1.9429060057297753
Validation loss: 2.589942128579413

Epoch: 6| Step: 9
Training loss: 2.753269852498347
Validation loss: 2.689312656255329

Epoch: 6| Step: 10
Training loss: 2.0374212565739818
Validation loss: 2.6543983063955694

Epoch: 6| Step: 11
Training loss: 2.0358512994840363
Validation loss: 2.5514292495111093

Epoch: 6| Step: 12
Training loss: 2.578009400521504
Validation loss: 2.5868158990253516

Epoch: 6| Step: 13
Training loss: 1.5523908511015325
Validation loss: 2.5721232829371456

Epoch: 113| Step: 0
Training loss: 1.9707487949792046
Validation loss: 2.5111843112058896

Epoch: 6| Step: 1
Training loss: 2.1757579096804096
Validation loss: 2.497491659023853

Epoch: 6| Step: 2
Training loss: 1.7826101230027036
Validation loss: 2.636479134680414

Epoch: 6| Step: 3
Training loss: 1.635973412411942
Validation loss: 2.5371832441618536

Epoch: 6| Step: 4
Training loss: 1.7547550314105442
Validation loss: 2.6676266154372583

Epoch: 6| Step: 5
Training loss: 1.8534339428540962
Validation loss: 2.489374484528962

Epoch: 6| Step: 6
Training loss: 2.460966273548306
Validation loss: 2.6491114566262204

Epoch: 6| Step: 7
Training loss: 2.2330586217009354
Validation loss: 2.5725415737597577

Epoch: 6| Step: 8
Training loss: 2.092811032312228
Validation loss: 2.5153804052002546

Epoch: 6| Step: 9
Training loss: 1.4259492958010662
Validation loss: 2.537524261108074

Epoch: 6| Step: 10
Training loss: 2.269384802920833
Validation loss: 2.5824080061060473

Epoch: 6| Step: 11
Training loss: 2.6807771919434553
Validation loss: 2.514796276499659

Epoch: 6| Step: 12
Training loss: 1.611729353455183
Validation loss: 2.590076787023901

Epoch: 6| Step: 13
Training loss: 1.5546822859326825
Validation loss: 2.6608148731372268

Epoch: 114| Step: 0
Training loss: 1.6981496670545648
Validation loss: 2.7079801524790574

Epoch: 6| Step: 1
Training loss: 2.0891385894134373
Validation loss: 2.7579967231924662

Epoch: 6| Step: 2
Training loss: 2.407603490076738
Validation loss: 2.7184558285404727

Epoch: 6| Step: 3
Training loss: 1.916300870017368
Validation loss: 2.6729064125544233

Epoch: 6| Step: 4
Training loss: 2.069148589398491
Validation loss: 2.5390004155320294

Epoch: 6| Step: 5
Training loss: 3.2368613007073828
Validation loss: 2.4935825792040855

Epoch: 6| Step: 6
Training loss: 1.7319186575379701
Validation loss: 2.624551871059135

Epoch: 6| Step: 7
Training loss: 1.9436312231344115
Validation loss: 2.5296992037186072

Epoch: 6| Step: 8
Training loss: 2.1177367451630915
Validation loss: 2.5139277006165885

Epoch: 6| Step: 9
Training loss: 2.091369984269234
Validation loss: 2.650276700754745

Epoch: 6| Step: 10
Training loss: 1.9131084322032845
Validation loss: 2.549366829994567

Epoch: 6| Step: 11
Training loss: 1.7191044528642778
Validation loss: 2.6411124838472095

Epoch: 6| Step: 12
Training loss: 1.4126569390672359
Validation loss: 2.544047785456631

Epoch: 6| Step: 13
Training loss: 1.9064968136956626
Validation loss: 2.603388423344929

Epoch: 115| Step: 0
Training loss: 1.6597720430878058
Validation loss: 2.6526357857970373

Epoch: 6| Step: 1
Training loss: 1.8241979038264542
Validation loss: 2.6119097278577734

Epoch: 6| Step: 2
Training loss: 2.4400195280450547
Validation loss: 2.674334518745531

Epoch: 6| Step: 3
Training loss: 2.2652444454100173
Validation loss: 2.6629972071239663

Epoch: 6| Step: 4
Training loss: 1.6067060543049514
Validation loss: 2.65031344161519

Epoch: 6| Step: 5
Training loss: 2.6313758801864755
Validation loss: 2.6206571136649197

Epoch: 6| Step: 6
Training loss: 2.4797333355557223
Validation loss: 2.5336689399433348

Epoch: 6| Step: 7
Training loss: 1.311447720816741
Validation loss: 2.522870829822349

Epoch: 6| Step: 8
Training loss: 1.9801647547368626
Validation loss: 2.6271167576534364

Epoch: 6| Step: 9
Training loss: 2.1534692275959926
Validation loss: 2.6343204092913606

Epoch: 6| Step: 10
Training loss: 1.9085123364092562
Validation loss: 2.5056289800832907

Epoch: 6| Step: 11
Training loss: 1.6560324759961549
Validation loss: 2.5406139074805214

Epoch: 6| Step: 12
Training loss: 2.1847117501431117
Validation loss: 2.585096839182914

Epoch: 6| Step: 13
Training loss: 1.6973943628580053
Validation loss: 2.4850565937027342

Epoch: 116| Step: 0
Training loss: 1.8604419115609938
Validation loss: 2.62230133421771

Epoch: 6| Step: 1
Training loss: 2.2864717267338603
Validation loss: 2.6025195189619543

Epoch: 6| Step: 2
Training loss: 2.6779156490656577
Validation loss: 2.5474665370237064

Epoch: 6| Step: 3
Training loss: 1.528270313554148
Validation loss: 2.6710707437469705

Epoch: 6| Step: 4
Training loss: 2.087038242642243
Validation loss: 2.490665453331418

Epoch: 6| Step: 5
Training loss: 1.9031781319152805
Validation loss: 2.6857263197624426

Epoch: 6| Step: 6
Training loss: 1.8951694318168413
Validation loss: 2.6368657728107436

Epoch: 6| Step: 7
Training loss: 1.4322775637770413
Validation loss: 2.5392971615069904

Epoch: 6| Step: 8
Training loss: 1.8426220563318103
Validation loss: 2.591442084828971

Epoch: 6| Step: 9
Training loss: 1.630216149584605
Validation loss: 2.5754582725669266

Epoch: 6| Step: 10
Training loss: 2.1554842708812796
Validation loss: 2.6428926952160414

Epoch: 6| Step: 11
Training loss: 2.6439276813652732
Validation loss: 2.65024245580511

Epoch: 6| Step: 12
Training loss: 1.4512185336964056
Validation loss: 2.5773649309067928

Epoch: 6| Step: 13
Training loss: 1.9211650250318846
Validation loss: 2.574079503030284

Epoch: 117| Step: 0
Training loss: 1.6985364925449669
Validation loss: 2.5877001345600066

Epoch: 6| Step: 1
Training loss: 2.086887786085746
Validation loss: 2.5231680396485516

Epoch: 6| Step: 2
Training loss: 1.5468217474508306
Validation loss: 2.5867969125920474

Epoch: 6| Step: 3
Training loss: 1.5250683003123748
Validation loss: 2.6425334948266834

Epoch: 6| Step: 4
Training loss: 1.4843721088582043
Validation loss: 2.5475048542319616

Epoch: 6| Step: 5
Training loss: 1.6497540030467717
Validation loss: 2.5795300748939742

Epoch: 6| Step: 6
Training loss: 2.575340940996323
Validation loss: 2.574397172084533

Epoch: 6| Step: 7
Training loss: 3.0661709640524517
Validation loss: 2.533740353094655

Epoch: 6| Step: 8
Training loss: 2.107557630011184
Validation loss: 2.551416260608181

Epoch: 6| Step: 9
Training loss: 1.9737487789099541
Validation loss: 2.5650038388120047

Epoch: 6| Step: 10
Training loss: 1.5541755178300063
Validation loss: 2.448048808542083

Epoch: 6| Step: 11
Training loss: 2.0207636188660265
Validation loss: 2.5817924385226227

Epoch: 6| Step: 12
Training loss: 1.802522227326166
Validation loss: 2.537467925334093

Epoch: 6| Step: 13
Training loss: 1.935849070896261
Validation loss: 2.5557481467428014

Epoch: 118| Step: 0
Training loss: 1.7166966049892285
Validation loss: 2.5624330248260057

Epoch: 6| Step: 1
Training loss: 1.626726187349238
Validation loss: 2.5768369366208357

Epoch: 6| Step: 2
Training loss: 1.844649725748093
Validation loss: 2.5516899324681575

Epoch: 6| Step: 3
Training loss: 2.195459435592309
Validation loss: 2.6569321747482304

Epoch: 6| Step: 4
Training loss: 1.804468050738631
Validation loss: 2.517297445493345

Epoch: 6| Step: 5
Training loss: 1.5240477293455221
Validation loss: 2.5784834718503054

Epoch: 6| Step: 6
Training loss: 2.820433891410226
Validation loss: 2.6214330598563333

Epoch: 6| Step: 7
Training loss: 2.050739629413965
Validation loss: 2.7297678326593937

Epoch: 6| Step: 8
Training loss: 1.703821582256011
Validation loss: 2.7092902302634623

Epoch: 6| Step: 9
Training loss: 2.171607131356633
Validation loss: 2.733475949668364

Epoch: 6| Step: 10
Training loss: 1.9803342754749385
Validation loss: 2.6222447058509397

Epoch: 6| Step: 11
Training loss: 2.202215778141664
Validation loss: 2.662024008001856

Epoch: 6| Step: 12
Training loss: 1.9563206279058456
Validation loss: 2.6307544682615935

Epoch: 6| Step: 13
Training loss: 1.5575002405157257
Validation loss: 2.61548823519777

Epoch: 119| Step: 0
Training loss: 1.4241713540565728
Validation loss: 2.4946147295830947

Epoch: 6| Step: 1
Training loss: 1.7759385810833992
Validation loss: 2.64705001210427

Epoch: 6| Step: 2
Training loss: 1.829056331403176
Validation loss: 2.591029812820784

Epoch: 6| Step: 3
Training loss: 2.2563406294692845
Validation loss: 2.4875542473429024

Epoch: 6| Step: 4
Training loss: 1.4802526150155093
Validation loss: 2.6616057761323133

Epoch: 6| Step: 5
Training loss: 2.148401322493699
Validation loss: 2.566479632036384

Epoch: 6| Step: 6
Training loss: 2.3297445309449216
Validation loss: 2.6326553946841633

Epoch: 6| Step: 7
Training loss: 2.1749412791776916
Validation loss: 2.514358865305436

Epoch: 6| Step: 8
Training loss: 1.9571584938088957
Validation loss: 2.596691348195659

Epoch: 6| Step: 9
Training loss: 2.8455766114314827
Validation loss: 2.5542384695028253

Epoch: 6| Step: 10
Training loss: 2.1576122458953777
Validation loss: 2.6263121852324285

Epoch: 6| Step: 11
Training loss: 1.7450192962497744
Validation loss: 2.6304860840239415

Epoch: 6| Step: 12
Training loss: 2.156311034292439
Validation loss: 2.5578935048351883

Epoch: 6| Step: 13
Training loss: 1.6826285230683171
Validation loss: 2.6911700126123312

Epoch: 120| Step: 0
Training loss: 1.8907151634217978
Validation loss: 2.5820250172042067

Epoch: 6| Step: 1
Training loss: 1.8374604097629665
Validation loss: 2.6149024287389873

Epoch: 6| Step: 2
Training loss: 1.8295029883515377
Validation loss: 2.6110191267012572

Epoch: 6| Step: 3
Training loss: 1.046284466338695
Validation loss: 2.6219713662419855

Epoch: 6| Step: 4
Training loss: 2.2095988504189963
Validation loss: 2.5163682428059904

Epoch: 6| Step: 5
Training loss: 1.7855632827128434
Validation loss: 2.576083289978753

Epoch: 6| Step: 6
Training loss: 1.9307734719410177
Validation loss: 2.6074340667630076

Epoch: 6| Step: 7
Training loss: 1.6980926640885352
Validation loss: 2.541453967548916

Epoch: 6| Step: 8
Training loss: 1.977768239999602
Validation loss: 2.4666216000959276

Epoch: 6| Step: 9
Training loss: 2.068600965588575
Validation loss: 2.592458656297731

Epoch: 6| Step: 10
Training loss: 2.0574364204826874
Validation loss: 2.6827687749630202

Epoch: 6| Step: 11
Training loss: 2.6582023177751806
Validation loss: 2.6212481070945066

Epoch: 6| Step: 12
Training loss: 2.66601169012988
Validation loss: 2.571164207455177

Epoch: 6| Step: 13
Training loss: 1.7221987715871248
Validation loss: 2.5360354724447904

Epoch: 121| Step: 0
Training loss: 2.024533832722399
Validation loss: 2.6877914093293582

Epoch: 6| Step: 1
Training loss: 1.323686430848301
Validation loss: 2.516173893219261

Epoch: 6| Step: 2
Training loss: 2.097615673162885
Validation loss: 2.570092544497433

Epoch: 6| Step: 3
Training loss: 1.3350455446368028
Validation loss: 2.540493246105426

Epoch: 6| Step: 4
Training loss: 2.060174497972725
Validation loss: 2.6570109156378496

Epoch: 6| Step: 5
Training loss: 1.9809034724396373
Validation loss: 2.5564984388181915

Epoch: 6| Step: 6
Training loss: 2.7263062802137097
Validation loss: 2.560393716095218

Epoch: 6| Step: 7
Training loss: 1.8475022362681315
Validation loss: 2.6579536659148038

Epoch: 6| Step: 8
Training loss: 1.5504562075721846
Validation loss: 2.545612396688565

Epoch: 6| Step: 9
Training loss: 2.0130197410695683
Validation loss: 2.617727650941632

Epoch: 6| Step: 10
Training loss: 1.7131329390054124
Validation loss: 2.5849116077719367

Epoch: 6| Step: 11
Training loss: 1.3234947723642831
Validation loss: 2.5426234700878303

Epoch: 6| Step: 12
Training loss: 2.031462086095843
Validation loss: 2.643852819272545

Epoch: 6| Step: 13
Training loss: 1.742238886464527
Validation loss: 2.541646837459404

Epoch: 122| Step: 0
Training loss: 1.8527745653715917
Validation loss: 2.5735992627855566

Epoch: 6| Step: 1
Training loss: 2.103911607850934
Validation loss: 2.6495128837666218

Epoch: 6| Step: 2
Training loss: 1.1693066745127467
Validation loss: 2.5160216024772284

Epoch: 6| Step: 3
Training loss: 1.434833209084117
Validation loss: 2.643362759125309

Epoch: 6| Step: 4
Training loss: 2.945734049532675
Validation loss: 2.572044940461931

Epoch: 6| Step: 5
Training loss: 2.0801086136996783
Validation loss: 2.5048562725760597

Epoch: 6| Step: 6
Training loss: 1.788349259309463
Validation loss: 2.6626759833618756

Epoch: 6| Step: 7
Training loss: 2.1701855572238986
Validation loss: 2.6593864473544033

Epoch: 6| Step: 8
Training loss: 1.9715603343100994
Validation loss: 2.6357098116069375

Epoch: 6| Step: 9
Training loss: 2.085190199814654
Validation loss: 2.604189442852873

Epoch: 6| Step: 10
Training loss: 2.2535940711084606
Validation loss: 2.6514183830999585

Epoch: 6| Step: 11
Training loss: 1.764043724426419
Validation loss: 2.6151953103849337

Epoch: 6| Step: 12
Training loss: 1.9669429417970925
Validation loss: 2.6409670064681103

Epoch: 6| Step: 13
Training loss: 1.5339273673845366
Validation loss: 2.5817322743080897

Epoch: 123| Step: 0
Training loss: 2.2855602983136944
Validation loss: 2.6115993985599624

Epoch: 6| Step: 1
Training loss: 2.0634750604511214
Validation loss: 2.5953211028438576

Epoch: 6| Step: 2
Training loss: 1.6565427701329614
Validation loss: 2.6012012738771393

Epoch: 6| Step: 3
Training loss: 1.573015003625089
Validation loss: 2.6927968840116567

Epoch: 6| Step: 4
Training loss: 1.7294335982717866
Validation loss: 2.595933508330531

Epoch: 6| Step: 5
Training loss: 1.757330323950912
Validation loss: 2.627405305917013

Epoch: 6| Step: 6
Training loss: 2.398452609632781
Validation loss: 2.7096964169182756

Epoch: 6| Step: 7
Training loss: 1.1719995051047676
Validation loss: 2.612579875010939

Epoch: 6| Step: 8
Training loss: 2.2768295518945036
Validation loss: 2.722165881328609

Epoch: 6| Step: 9
Training loss: 2.737130830859515
Validation loss: 2.7535020175351734

Epoch: 6| Step: 10
Training loss: 1.7173165325805084
Validation loss: 2.5400544483501517

Epoch: 6| Step: 11
Training loss: 2.078267486964921
Validation loss: 2.7525956735085955

Epoch: 6| Step: 12
Training loss: 2.140930265392975
Validation loss: 2.782402685519548

Epoch: 6| Step: 13
Training loss: 1.8457811450110548
Validation loss: 2.6065411741223308

Epoch: 124| Step: 0
Training loss: 2.2971072955317213
Validation loss: 2.576567192682543

Epoch: 6| Step: 1
Training loss: 1.3443604790308126
Validation loss: 2.5515677781214943

Epoch: 6| Step: 2
Training loss: 2.174330825466589
Validation loss: 2.5736392907319265

Epoch: 6| Step: 3
Training loss: 1.7475900404712896
Validation loss: 2.5450242930229017

Epoch: 6| Step: 4
Training loss: 2.6636898194008047
Validation loss: 2.714097188853449

Epoch: 6| Step: 5
Training loss: 2.3809313743663716
Validation loss: 2.675973036081379

Epoch: 6| Step: 6
Training loss: 1.6354938011040296
Validation loss: 2.632624150603357

Epoch: 6| Step: 7
Training loss: 2.0567666329438925
Validation loss: 2.6318428525438686

Epoch: 6| Step: 8
Training loss: 1.4161802840686857
Validation loss: 2.5729181904859058

Epoch: 6| Step: 9
Training loss: 1.3139314112100993
Validation loss: 2.5892742100352018

Epoch: 6| Step: 10
Training loss: 1.963493839022085
Validation loss: 2.7107096346348505

Epoch: 6| Step: 11
Training loss: 2.2060214002579386
Validation loss: 2.6610217896613113

Epoch: 6| Step: 12
Training loss: 1.5374193278912425
Validation loss: 2.5996358035621667

Epoch: 6| Step: 13
Training loss: 1.6047737492130565
Validation loss: 2.6701696802245336

Epoch: 125| Step: 0
Training loss: 1.8393482747860048
Validation loss: 2.653212916606616

Epoch: 6| Step: 1
Training loss: 1.5320549231163576
Validation loss: 2.597816160246789

Epoch: 6| Step: 2
Training loss: 1.7519224370439723
Validation loss: 2.765237030288119

Epoch: 6| Step: 3
Training loss: 1.886430358960156
Validation loss: 2.7570822147780083

Epoch: 6| Step: 4
Training loss: 2.3527249222840574
Validation loss: 2.8842671763723793

Epoch: 6| Step: 5
Training loss: 2.3433420462014514
Validation loss: 2.803351038704146

Epoch: 6| Step: 6
Training loss: 2.2206915299004675
Validation loss: 2.746404566025969

Epoch: 6| Step: 7
Training loss: 0.6858180452576466
Validation loss: 2.6628834193141837

Epoch: 6| Step: 8
Training loss: 2.8283220928495534
Validation loss: 2.5560107911224894

Epoch: 6| Step: 9
Training loss: 1.3544314590184898
Validation loss: 2.5736691433774785

Epoch: 6| Step: 10
Training loss: 2.2495629627906775
Validation loss: 2.5661154262402475

Epoch: 6| Step: 11
Training loss: 1.7213808212486554
Validation loss: 2.5796261203055657

Epoch: 6| Step: 12
Training loss: 1.260046781171017
Validation loss: 2.6591763551831016

Epoch: 6| Step: 13
Training loss: 2.0452769790024536
Validation loss: 2.6227915268654147

Epoch: 126| Step: 0
Training loss: 1.9677208526627719
Validation loss: 2.6536247145261953

Epoch: 6| Step: 1
Training loss: 2.3523252143750386
Validation loss: 2.611268230427551

Epoch: 6| Step: 2
Training loss: 1.9195224660843995
Validation loss: 2.5478921898960345

Epoch: 6| Step: 3
Training loss: 2.744447390966168
Validation loss: 2.6161099165564052

Epoch: 6| Step: 4
Training loss: 1.9040917858311424
Validation loss: 2.6136379635219176

Epoch: 6| Step: 5
Training loss: 1.7290748510534917
Validation loss: 2.520837726011206

Epoch: 6| Step: 6
Training loss: 1.696596705200277
Validation loss: 2.6385947253141717

Epoch: 6| Step: 7
Training loss: 1.4932062156819699
Validation loss: 2.567455934470164

Epoch: 6| Step: 8
Training loss: 1.569444558847849
Validation loss: 2.5725955350885794

Epoch: 6| Step: 9
Training loss: 1.4737346555834767
Validation loss: 2.70811288865685

Epoch: 6| Step: 10
Training loss: 2.4193341124067245
Validation loss: 2.6044126521599678

Epoch: 6| Step: 11
Training loss: 2.3875304494783474
Validation loss: 2.778463274825792

Epoch: 6| Step: 12
Training loss: 2.393338128654472
Validation loss: 2.7716763918031826

Epoch: 6| Step: 13
Training loss: 2.0760204012314873
Validation loss: 2.640799273998238

Epoch: 127| Step: 0
Training loss: 1.8446715040254924
Validation loss: 2.537506597100062

Epoch: 6| Step: 1
Training loss: 1.9242780594972368
Validation loss: 2.644819077756249

Epoch: 6| Step: 2
Training loss: 1.3381367477906205
Validation loss: 2.606846976271726

Epoch: 6| Step: 3
Training loss: 1.8288731796488158
Validation loss: 2.646489945484413

Epoch: 6| Step: 4
Training loss: 1.326814206599833
Validation loss: 2.5590971628620127

Epoch: 6| Step: 5
Training loss: 1.7496101762650962
Validation loss: 2.5359753116805868

Epoch: 6| Step: 6
Training loss: 1.53976300558651
Validation loss: 2.555069470017916

Epoch: 6| Step: 7
Training loss: 2.441753979142744
Validation loss: 2.583761538630661

Epoch: 6| Step: 8
Training loss: 1.1596003783756677
Validation loss: 2.5410185023923626

Epoch: 6| Step: 9
Training loss: 2.304263111416164
Validation loss: 2.637303778654741

Epoch: 6| Step: 10
Training loss: 2.3596338799534804
Validation loss: 2.5825183003144323

Epoch: 6| Step: 11
Training loss: 2.44794339645618
Validation loss: 2.6046862020414947

Epoch: 6| Step: 12
Training loss: 1.8278140594272285
Validation loss: 2.5865824837193223

Epoch: 6| Step: 13
Training loss: 1.5705458434469235
Validation loss: 2.611687646167707

Epoch: 128| Step: 0
Training loss: 1.914312105057921
Validation loss: 2.577646291967566

Epoch: 6| Step: 1
Training loss: 1.6462361611354492
Validation loss: 2.6767324571453566

Epoch: 6| Step: 2
Training loss: 1.9086382554276196
Validation loss: 2.545371159641972

Epoch: 6| Step: 3
Training loss: 1.9235049523333703
Validation loss: 2.602195800130321

Epoch: 6| Step: 4
Training loss: 2.164143364562609
Validation loss: 2.690435624851661

Epoch: 6| Step: 5
Training loss: 1.8147943379132851
Validation loss: 2.617711757703718

Epoch: 6| Step: 6
Training loss: 2.2992054022797874
Validation loss: 2.711582250080236

Epoch: 6| Step: 7
Training loss: 1.3915346149603587
Validation loss: 2.624835357346799

Epoch: 6| Step: 8
Training loss: 1.666732866244082
Validation loss: 2.679277794660588

Epoch: 6| Step: 9
Training loss: 1.6128053124764155
Validation loss: 2.5537760875164244

Epoch: 6| Step: 10
Training loss: 1.9618028653856885
Validation loss: 2.589537574157131

Epoch: 6| Step: 11
Training loss: 1.4217990393836726
Validation loss: 2.6157863073465504

Epoch: 6| Step: 12
Training loss: 1.989768920018609
Validation loss: 2.648684974893581

Epoch: 6| Step: 13
Training loss: 2.2747545130821476
Validation loss: 2.5989205326447835

Epoch: 129| Step: 0
Training loss: 2.44897936756918
Validation loss: 2.639921647700885

Epoch: 6| Step: 1
Training loss: 1.97141255368267
Validation loss: 2.6504014796702617

Epoch: 6| Step: 2
Training loss: 1.9111157837091046
Validation loss: 2.54193159713373

Epoch: 6| Step: 3
Training loss: 1.5340940571762305
Validation loss: 2.58083673298552

Epoch: 6| Step: 4
Training loss: 2.745441994302482
Validation loss: 2.684537541150239

Epoch: 6| Step: 5
Training loss: 2.4600204454518293
Validation loss: 2.7004039350398945

Epoch: 6| Step: 6
Training loss: 1.7308042730549766
Validation loss: 2.59609046344241

Epoch: 6| Step: 7
Training loss: 1.62614092755015
Validation loss: 2.597020305144346

Epoch: 6| Step: 8
Training loss: 1.6977319285363857
Validation loss: 2.5704722717160857

Epoch: 6| Step: 9
Training loss: 1.7477746165422738
Validation loss: 2.5767001597788473

Epoch: 6| Step: 10
Training loss: 1.3670849570919967
Validation loss: 2.5610946275020168

Epoch: 6| Step: 11
Training loss: 1.26527079582498
Validation loss: 2.6011804523547153

Epoch: 6| Step: 12
Training loss: 1.6785771448101816
Validation loss: 2.6188862843280925

Epoch: 6| Step: 13
Training loss: 1.62000136740356
Validation loss: 2.7316233568169856

Epoch: 130| Step: 0
Training loss: 1.6787920317000147
Validation loss: 2.570452824465711

Epoch: 6| Step: 1
Training loss: 2.0396077680309292
Validation loss: 2.651763163316726

Epoch: 6| Step: 2
Training loss: 1.2936780200044944
Validation loss: 2.70983961228976

Epoch: 6| Step: 3
Training loss: 1.5079404944611758
Validation loss: 2.644031201280947

Epoch: 6| Step: 4
Training loss: 1.5492979397831879
Validation loss: 2.5644825422580686

Epoch: 6| Step: 5
Training loss: 1.86368785076534
Validation loss: 2.6674222521428828

Epoch: 6| Step: 6
Training loss: 1.4108823983045868
Validation loss: 2.597394030345788

Epoch: 6| Step: 7
Training loss: 2.2800413091163185
Validation loss: 2.5149616290856835

Epoch: 6| Step: 8
Training loss: 1.4733592816623913
Validation loss: 2.570139522587342

Epoch: 6| Step: 9
Training loss: 1.9353401081340256
Validation loss: 2.53481163029791

Epoch: 6| Step: 10
Training loss: 2.2371894876700664
Validation loss: 2.5165540034189657

Epoch: 6| Step: 11
Training loss: 2.234702346404632
Validation loss: 2.639877348926207

Epoch: 6| Step: 12
Training loss: 2.3983571787751763
Validation loss: 2.52657177793065

Epoch: 6| Step: 13
Training loss: 0.8939286246897645
Validation loss: 2.5393047510636477

Epoch: 131| Step: 0
Training loss: 1.7077064837246048
Validation loss: 2.5756052052891913

Epoch: 6| Step: 1
Training loss: 1.610324246352424
Validation loss: 2.6614530430173207

Epoch: 6| Step: 2
Training loss: 2.7383592624407984
Validation loss: 2.597912263802777

Epoch: 6| Step: 3
Training loss: 2.451268167618067
Validation loss: 2.6229531618649156

Epoch: 6| Step: 4
Training loss: 1.1578562122077998
Validation loss: 2.6302395255376343

Epoch: 6| Step: 5
Training loss: 1.5339264348032815
Validation loss: 2.600542618909658

Epoch: 6| Step: 6
Training loss: 1.9497501359928033
Validation loss: 2.6338835366796447

Epoch: 6| Step: 7
Training loss: 1.1652542772425334
Validation loss: 2.6653071578858567

Epoch: 6| Step: 8
Training loss: 1.596832734685213
Validation loss: 2.661223673071363

Epoch: 6| Step: 9
Training loss: 2.549336092671427
Validation loss: 2.5582918333566527

Epoch: 6| Step: 10
Training loss: 1.4027903066312735
Validation loss: 2.7326492095024224

Epoch: 6| Step: 11
Training loss: 2.0168692127164847
Validation loss: 2.6105372872662436

Epoch: 6| Step: 12
Training loss: 1.8384916678772314
Validation loss: 2.5857245596716947

Epoch: 6| Step: 13
Training loss: 1.662135768371525
Validation loss: 2.595506479331522

Epoch: 132| Step: 0
Training loss: 1.5675878467919009
Validation loss: 2.5961527744700366

Epoch: 6| Step: 1
Training loss: 1.8318317361627505
Validation loss: 2.6411822932926436

Epoch: 6| Step: 2
Training loss: 2.1037631513487103
Validation loss: 2.6057662222133207

Epoch: 6| Step: 3
Training loss: 1.5817216735107391
Validation loss: 2.6551818046177402

Epoch: 6| Step: 4
Training loss: 1.2803378696362944
Validation loss: 2.591566315596037

Epoch: 6| Step: 5
Training loss: 2.6528389964160586
Validation loss: 2.5558513280730293

Epoch: 6| Step: 6
Training loss: 1.9269098839585665
Validation loss: 2.5773906085644076

Epoch: 6| Step: 7
Training loss: 1.7592755142189695
Validation loss: 2.5502688178941355

Epoch: 6| Step: 8
Training loss: 1.3272687957059366
Validation loss: 2.566732942253947

Epoch: 6| Step: 9
Training loss: 2.2502135069530134
Validation loss: 2.6518604285776135

Epoch: 6| Step: 10
Training loss: 1.6131366360114263
Validation loss: 2.5567723826278517

Epoch: 6| Step: 11
Training loss: 2.253812421039013
Validation loss: 2.6435123586301437

Epoch: 6| Step: 12
Training loss: 2.0538750844559237
Validation loss: 2.4981499502287936

Epoch: 6| Step: 13
Training loss: 1.504366875988301
Validation loss: 2.486083972387343

Epoch: 133| Step: 0
Training loss: 1.5114441457126793
Validation loss: 2.636134541158078

Epoch: 6| Step: 1
Training loss: 1.414907466437407
Validation loss: 2.575962801439616

Epoch: 6| Step: 2
Training loss: 2.0850503585186124
Validation loss: 2.709450144240855

Epoch: 6| Step: 3
Training loss: 2.0494810796694005
Validation loss: 2.728038355619219

Epoch: 6| Step: 4
Training loss: 2.5959180480294366
Validation loss: 2.6612525059091103

Epoch: 6| Step: 5
Training loss: 1.5131802061867132
Validation loss: 2.6384313150414944

Epoch: 6| Step: 6
Training loss: 1.7365658643441786
Validation loss: 2.650771381462114

Epoch: 6| Step: 7
Training loss: 1.66243495957346
Validation loss: 2.521573790785247

Epoch: 6| Step: 8
Training loss: 1.2810937274440144
Validation loss: 2.61238041562987

Epoch: 6| Step: 9
Training loss: 1.782332242157883
Validation loss: 2.6170290619068934

Epoch: 6| Step: 10
Training loss: 1.9883889879216814
Validation loss: 2.5903619292916016

Epoch: 6| Step: 11
Training loss: 1.907637169581853
Validation loss: 2.6276360400522223

Epoch: 6| Step: 12
Training loss: 1.8872166957829832
Validation loss: 2.636640910188797

Epoch: 6| Step: 13
Training loss: 1.768910549681888
Validation loss: 2.6408232514788934

Epoch: 134| Step: 0
Training loss: 1.4683066165555978
Validation loss: 2.6221781049625323

Epoch: 6| Step: 1
Training loss: 2.2588961947343233
Validation loss: 2.5711567119414664

Epoch: 6| Step: 2
Training loss: 1.5758210539814292
Validation loss: 2.5843112591744157

Epoch: 6| Step: 3
Training loss: 1.9856028325107544
Validation loss: 2.5778689633013765

Epoch: 6| Step: 4
Training loss: 1.5795782215569345
Validation loss: 2.495846572441774

Epoch: 6| Step: 5
Training loss: 1.6571830424594653
Validation loss: 2.577878242783017

Epoch: 6| Step: 6
Training loss: 1.1771645757044582
Validation loss: 2.705229849295871

Epoch: 6| Step: 7
Training loss: 2.4272756104716815
Validation loss: 2.6771901526211064

Epoch: 6| Step: 8
Training loss: 1.7577794050703996
Validation loss: 2.584635442290158

Epoch: 6| Step: 9
Training loss: 1.3848576481511377
Validation loss: 2.684411677094059

Epoch: 6| Step: 10
Training loss: 1.4393500986069592
Validation loss: 2.636237462705654

Epoch: 6| Step: 11
Training loss: 2.1681406313832214
Validation loss: 2.5867760596133373

Epoch: 6| Step: 12
Training loss: 2.259947298836428
Validation loss: 2.6107871218708203

Epoch: 6| Step: 13
Training loss: 1.753897142280431
Validation loss: 2.713245666135835

Epoch: 135| Step: 0
Training loss: 1.1147131562014152
Validation loss: 2.559482612257192

Epoch: 6| Step: 1
Training loss: 2.4866033193515324
Validation loss: 2.5577366448900967

Epoch: 6| Step: 2
Training loss: 1.8399465738708547
Validation loss: 2.6677260579378466

Epoch: 6| Step: 3
Training loss: 1.9173769533150011
Validation loss: 2.6256471774659813

Epoch: 6| Step: 4
Training loss: 1.9030405761835005
Validation loss: 2.608327400233272

Epoch: 6| Step: 5
Training loss: 1.466031012999401
Validation loss: 2.5485728558664236

Epoch: 6| Step: 6
Training loss: 1.4430160010779733
Validation loss: 2.70134719276011

Epoch: 6| Step: 7
Training loss: 1.3807093256855014
Validation loss: 2.5233988409555246

Epoch: 6| Step: 8
Training loss: 2.3343372796418542
Validation loss: 2.697534428524981

Epoch: 6| Step: 9
Training loss: 1.8749767302022842
Validation loss: 2.6558209989093933

Epoch: 6| Step: 10
Training loss: 1.6987712402363224
Validation loss: 2.631296704407114

Epoch: 6| Step: 11
Training loss: 1.8608671340002279
Validation loss: 2.650093258710238

Epoch: 6| Step: 12
Training loss: 1.8735105320532894
Validation loss: 2.6071738516849523

Epoch: 6| Step: 13
Training loss: 1.1960874551100378
Validation loss: 2.5872430108631135

Epoch: 136| Step: 0
Training loss: 1.9941862364511609
Validation loss: 2.579657790630821

Epoch: 6| Step: 1
Training loss: 1.764694508815092
Validation loss: 2.6831414120516737

Epoch: 6| Step: 2
Training loss: 1.4456924351500808
Validation loss: 2.7751378680969343

Epoch: 6| Step: 3
Training loss: 2.123599993710815
Validation loss: 2.668460143501349

Epoch: 6| Step: 4
Training loss: 1.620504469797384
Validation loss: 2.6622798321214605

Epoch: 6| Step: 5
Training loss: 2.216889259329086
Validation loss: 2.6805969118695487

Epoch: 6| Step: 6
Training loss: 1.2438083845840746
Validation loss: 2.6997204105999857

Epoch: 6| Step: 7
Training loss: 2.1044389403791643
Validation loss: 2.672339832108469

Epoch: 6| Step: 8
Training loss: 1.3772616426311972
Validation loss: 2.6481261543905843

Epoch: 6| Step: 9
Training loss: 1.722391536381609
Validation loss: 2.6118712372823865

Epoch: 6| Step: 10
Training loss: 1.7384833400565491
Validation loss: 2.555955826699504

Epoch: 6| Step: 11
Training loss: 1.7291788154389758
Validation loss: 2.564865702793579

Epoch: 6| Step: 12
Training loss: 1.6001377374252193
Validation loss: 2.6197457179949977

Epoch: 6| Step: 13
Training loss: 2.3852838426505483
Validation loss: 2.6210710398509294

Epoch: 137| Step: 0
Training loss: 1.4979587016709175
Validation loss: 2.6081672964986478

Epoch: 6| Step: 1
Training loss: 1.7293932050126557
Validation loss: 2.613175272634019

Epoch: 6| Step: 2
Training loss: 2.047824901285377
Validation loss: 2.50590519455615

Epoch: 6| Step: 3
Training loss: 1.4207752711867632
Validation loss: 2.6255702277371915

Epoch: 6| Step: 4
Training loss: 2.193512636912187
Validation loss: 2.6356824858929557

Epoch: 6| Step: 5
Training loss: 2.342261592006103
Validation loss: 2.6789363924282927

Epoch: 6| Step: 6
Training loss: 1.2877405960311363
Validation loss: 2.7209506938873367

Epoch: 6| Step: 7
Training loss: 1.4412259451718947
Validation loss: 2.6589897985483852

Epoch: 6| Step: 8
Training loss: 2.7453265793883865
Validation loss: 2.6611061136848746

Epoch: 6| Step: 9
Training loss: 1.5529307499151346
Validation loss: 2.632774692343175

Epoch: 6| Step: 10
Training loss: 1.7689769963159139
Validation loss: 2.686221535758049

Epoch: 6| Step: 11
Training loss: 1.3014137173870193
Validation loss: 2.587682352382213

Epoch: 6| Step: 12
Training loss: 1.4928052332595239
Validation loss: 2.579702877042748

Epoch: 6| Step: 13
Training loss: 1.5350271855037603
Validation loss: 2.5269740844995825

Epoch: 138| Step: 0
Training loss: 1.3217025301630625
Validation loss: 2.6803396708489404

Epoch: 6| Step: 1
Training loss: 1.9276132903097447
Validation loss: 2.5666119528384193

Epoch: 6| Step: 2
Training loss: 1.1116797991943947
Validation loss: 2.7271645217439775

Epoch: 6| Step: 3
Training loss: 1.521311680366913
Validation loss: 2.700916166929313

Epoch: 6| Step: 4
Training loss: 1.3967826471372742
Validation loss: 2.624121534101356

Epoch: 6| Step: 5
Training loss: 1.4170549458987274
Validation loss: 2.5973781503754063

Epoch: 6| Step: 6
Training loss: 2.091604471485161
Validation loss: 2.660189202207723

Epoch: 6| Step: 7
Training loss: 1.6044154366486016
Validation loss: 2.5346374294317826

Epoch: 6| Step: 8
Training loss: 1.6280031330678348
Validation loss: 2.645940242820127

Epoch: 6| Step: 9
Training loss: 1.8951618836034765
Validation loss: 2.598740384449677

Epoch: 6| Step: 10
Training loss: 2.1600810860496247
Validation loss: 2.6780427532111837

Epoch: 6| Step: 11
Training loss: 2.346580423898046
Validation loss: 2.594995483046602

Epoch: 6| Step: 12
Training loss: 1.5115827947787681
Validation loss: 2.6796181598437285

Epoch: 6| Step: 13
Training loss: 1.7911374249325194
Validation loss: 2.677759765385907

Epoch: 139| Step: 0
Training loss: 1.053670718015006
Validation loss: 2.6471187868110366

Epoch: 6| Step: 1
Training loss: 2.053464111935923
Validation loss: 2.62948341325663

Epoch: 6| Step: 2
Training loss: 2.6723865220160383
Validation loss: 2.646551760558156

Epoch: 6| Step: 3
Training loss: 1.290322168027135
Validation loss: 2.6462645792510706

Epoch: 6| Step: 4
Training loss: 1.9997639516769867
Validation loss: 2.723079332913318

Epoch: 6| Step: 5
Training loss: 1.8494361868866536
Validation loss: 2.706070105936542

Epoch: 6| Step: 6
Training loss: 1.4967387828288703
Validation loss: 2.591666553002587

Epoch: 6| Step: 7
Training loss: 2.0443889867245244
Validation loss: 2.7145285443983216

Epoch: 6| Step: 8
Training loss: 1.6920411501901387
Validation loss: 2.64899964494752

Epoch: 6| Step: 9
Training loss: 1.1633301549793391
Validation loss: 2.6810842864453877

Epoch: 6| Step: 10
Training loss: 1.0758257688398722
Validation loss: 2.5225860135423335

Epoch: 6| Step: 11
Training loss: 1.2727572724751435
Validation loss: 2.5701178232538098

Epoch: 6| Step: 12
Training loss: 2.2472172589188966
Validation loss: 2.5956269026511336

Epoch: 6| Step: 13
Training loss: 1.5738726441313695
Validation loss: 2.655570680106581

Epoch: 140| Step: 0
Training loss: 2.6232230211821226
Validation loss: 2.5757598663173695

Epoch: 6| Step: 1
Training loss: 1.9437467716104369
Validation loss: 2.6286693691114325

Epoch: 6| Step: 2
Training loss: 1.6439853949304133
Validation loss: 2.749994436894194

Epoch: 6| Step: 3
Training loss: 1.7961296857812163
Validation loss: 2.650323906782381

Epoch: 6| Step: 4
Training loss: 1.845008162193542
Validation loss: 2.6444545567565823

Epoch: 6| Step: 5
Training loss: 1.9321250192459953
Validation loss: 2.7169550089335024

Epoch: 6| Step: 6
Training loss: 1.4837760921713286
Validation loss: 2.6811346330105796

Epoch: 6| Step: 7
Training loss: 0.9876255679875469
Validation loss: 2.5692407756423425

Epoch: 6| Step: 8
Training loss: 1.64271368857579
Validation loss: 2.675182748951514

Epoch: 6| Step: 9
Training loss: 1.882395591322782
Validation loss: 2.6063056604432195

Epoch: 6| Step: 10
Training loss: 1.4633538158405448
Validation loss: 2.659652341074582

Epoch: 6| Step: 11
Training loss: 1.8456675369626245
Validation loss: 2.6199977988313936

Epoch: 6| Step: 12
Training loss: 1.3413767594221147
Validation loss: 2.729397383006213

Epoch: 6| Step: 13
Training loss: 1.6695846841817934
Validation loss: 2.7878215176714756

Epoch: 141| Step: 0
Training loss: 1.818266738187255
Validation loss: 2.6327582409377484

Epoch: 6| Step: 1
Training loss: 2.4795172841446025
Validation loss: 2.570086012178983

Epoch: 6| Step: 2
Training loss: 1.3128430054554379
Validation loss: 2.5481565094852936

Epoch: 6| Step: 3
Training loss: 1.4714697148236067
Validation loss: 2.665193289784368

Epoch: 6| Step: 4
Training loss: 1.5474551875662297
Validation loss: 2.6120713364429133

Epoch: 6| Step: 5
Training loss: 1.4465793315759508
Validation loss: 2.6284977150042943

Epoch: 6| Step: 6
Training loss: 0.9768225666894017
Validation loss: 2.680047651431876

Epoch: 6| Step: 7
Training loss: 1.5745614485756267
Validation loss: 2.6523312103469454

Epoch: 6| Step: 8
Training loss: 2.1352004771392505
Validation loss: 2.5945526780726627

Epoch: 6| Step: 9
Training loss: 1.5388767498255227
Validation loss: 2.7009212720593037

Epoch: 6| Step: 10
Training loss: 2.068153032451227
Validation loss: 2.6752448739364922

Epoch: 6| Step: 11
Training loss: 1.9835708069948763
Validation loss: 2.572352286973843

Epoch: 6| Step: 12
Training loss: 1.190765358568927
Validation loss: 2.5385042799579898

Epoch: 6| Step: 13
Training loss: 1.8803909368069796
Validation loss: 2.587912643626848

Epoch: 142| Step: 0
Training loss: 1.847443517975249
Validation loss: 2.6643996934240852

Epoch: 6| Step: 1
Training loss: 2.409433513084225
Validation loss: 2.570632504966138

Epoch: 6| Step: 2
Training loss: 1.4089900131683872
Validation loss: 2.595476594621839

Epoch: 6| Step: 3
Training loss: 2.5987813477783757
Validation loss: 2.6127345221720497

Epoch: 6| Step: 4
Training loss: 1.749805780259907
Validation loss: 2.5426585080959905

Epoch: 6| Step: 5
Training loss: 1.1608892623306202
Validation loss: 2.5929120253637294

Epoch: 6| Step: 6
Training loss: 1.522353662182349
Validation loss: 2.5902323941870535

Epoch: 6| Step: 7
Training loss: 1.2812862856309084
Validation loss: 2.6068169929210625

Epoch: 6| Step: 8
Training loss: 1.4226001944226587
Validation loss: 2.6437561461946126

Epoch: 6| Step: 9
Training loss: 1.465729061897814
Validation loss: 2.7227299961663713

Epoch: 6| Step: 10
Training loss: 2.188655003392941
Validation loss: 2.6911487502302593

Epoch: 6| Step: 11
Training loss: 1.425943109391361
Validation loss: 2.6774293005567444

Epoch: 6| Step: 12
Training loss: 1.4206787778558014
Validation loss: 2.6417963864539753

Epoch: 6| Step: 13
Training loss: 1.279821902565858
Validation loss: 2.5966504590169754

Epoch: 143| Step: 0
Training loss: 1.3285056522379795
Validation loss: 2.632010891583603

Epoch: 6| Step: 1
Training loss: 1.525841796423739
Validation loss: 2.7483783622308557

Epoch: 6| Step: 2
Training loss: 1.3796785693457423
Validation loss: 2.5987203689116507

Epoch: 6| Step: 3
Training loss: 1.805335518886834
Validation loss: 2.616016980222545

Epoch: 6| Step: 4
Training loss: 1.1832751358299405
Validation loss: 2.6382457841848943

Epoch: 6| Step: 5
Training loss: 1.1226956821808827
Validation loss: 2.698779514346301

Epoch: 6| Step: 6
Training loss: 1.6725287184366555
Validation loss: 2.6227690738261606

Epoch: 6| Step: 7
Training loss: 2.396799031114319
Validation loss: 2.6757988031187487

Epoch: 6| Step: 8
Training loss: 1.4143914108908835
Validation loss: 2.6450004368032323

Epoch: 6| Step: 9
Training loss: 1.9233451740532892
Validation loss: 2.687470118038626

Epoch: 6| Step: 10
Training loss: 1.8732705723554213
Validation loss: 2.615312244185693

Epoch: 6| Step: 11
Training loss: 2.016294383005723
Validation loss: 2.6988217420231515

Epoch: 6| Step: 12
Training loss: 1.6833515745376946
Validation loss: 2.6358189307233513

Epoch: 6| Step: 13
Training loss: 1.3572754705501582
Validation loss: 2.735278083988322

Epoch: 144| Step: 0
Training loss: 1.9426523427249724
Validation loss: 2.6681259280254017

Epoch: 6| Step: 1
Training loss: 1.3137849240148114
Validation loss: 2.7054678405531067

Epoch: 6| Step: 2
Training loss: 0.6891818282763266
Validation loss: 2.639557556853455

Epoch: 6| Step: 3
Training loss: 1.5222418372351525
Validation loss: 2.747495963394768

Epoch: 6| Step: 4
Training loss: 2.2004329385452563
Validation loss: 2.7295352211313944

Epoch: 6| Step: 5
Training loss: 1.2924991919037232
Validation loss: 2.714336093486438

Epoch: 6| Step: 6
Training loss: 2.045434109749483
Validation loss: 2.6142112320236737

Epoch: 6| Step: 7
Training loss: 1.627931664642433
Validation loss: 2.671007417062982

Epoch: 6| Step: 8
Training loss: 2.471789649618359
Validation loss: 2.620729712018161

Epoch: 6| Step: 9
Training loss: 1.0888278834344125
Validation loss: 2.633692472650675

Epoch: 6| Step: 10
Training loss: 1.7392979081258793
Validation loss: 2.6584713044032755

Epoch: 6| Step: 11
Training loss: 1.9071043632647435
Validation loss: 2.5479574653018617

Epoch: 6| Step: 12
Training loss: 1.6460433858110826
Validation loss: 2.765414723881341

Epoch: 6| Step: 13
Training loss: 1.0767514421512254
Validation loss: 2.595426990143307

Epoch: 145| Step: 0
Training loss: 1.4441916578756901
Validation loss: 2.7116738527699424

Epoch: 6| Step: 1
Training loss: 1.073756614460406
Validation loss: 2.584637317929021

Epoch: 6| Step: 2
Training loss: 1.9685976484175176
Validation loss: 2.716007925295421

Epoch: 6| Step: 3
Training loss: 1.3558993576251974
Validation loss: 2.7326016297655378

Epoch: 6| Step: 4
Training loss: 2.078357195968297
Validation loss: 2.783156552287604

Epoch: 6| Step: 5
Training loss: 1.177070797653739
Validation loss: 2.7443711153479415

Epoch: 6| Step: 6
Training loss: 1.015484022479674
Validation loss: 2.590523839063722

Epoch: 6| Step: 7
Training loss: 1.701418520438006
Validation loss: 2.5945612546431542

Epoch: 6| Step: 8
Training loss: 1.8391905838045435
Validation loss: 2.701232012127331

Epoch: 6| Step: 9
Training loss: 1.320650271938017
Validation loss: 2.6542098045336857

Epoch: 6| Step: 10
Training loss: 2.377472343564754
Validation loss: 2.6484802452696408

Epoch: 6| Step: 11
Training loss: 2.0241853370397
Validation loss: 2.683218643351672

Epoch: 6| Step: 12
Training loss: 1.6006706173498633
Validation loss: 2.6713437301383283

Epoch: 6| Step: 13
Training loss: 1.38369403908591
Validation loss: 2.7281844043418015

Epoch: 146| Step: 0
Training loss: 1.48477769709785
Validation loss: 2.6239099358525744

Epoch: 6| Step: 1
Training loss: 1.2318381787762531
Validation loss: 2.5953713064557093

Epoch: 6| Step: 2
Training loss: 1.5103457817895405
Validation loss: 2.676055173937568

Epoch: 6| Step: 3
Training loss: 1.0698604882280425
Validation loss: 2.68324093857042

Epoch: 6| Step: 4
Training loss: 1.5363382928367766
Validation loss: 2.7053023152458757

Epoch: 6| Step: 5
Training loss: 1.6530670675067278
Validation loss: 2.5298156756074612

Epoch: 6| Step: 6
Training loss: 2.9754234397293637
Validation loss: 2.5563822266719622

Epoch: 6| Step: 7
Training loss: 1.1334194267521123
Validation loss: 2.6975747607374028

Epoch: 6| Step: 8
Training loss: 1.9894405799768298
Validation loss: 2.7002484519287018

Epoch: 6| Step: 9
Training loss: 1.333654494150819
Validation loss: 2.653813669713982

Epoch: 6| Step: 10
Training loss: 1.38527735628779
Validation loss: 2.567928534319448

Epoch: 6| Step: 11
Training loss: 1.710460160786975
Validation loss: 2.6171099295436635

Epoch: 6| Step: 12
Training loss: 1.380928955051688
Validation loss: 2.6872300596475376

Epoch: 6| Step: 13
Training loss: 1.582719968480435
Validation loss: 2.6633325883850785

Epoch: 147| Step: 0
Training loss: 1.855139130878267
Validation loss: 2.5810044671401444

Epoch: 6| Step: 1
Training loss: 1.7411137851691036
Validation loss: 2.674226436293761

Epoch: 6| Step: 2
Training loss: 1.4949181621695793
Validation loss: 2.7211132374877156

Epoch: 6| Step: 3
Training loss: 1.148164937379129
Validation loss: 2.654118920939289

Epoch: 6| Step: 4
Training loss: 1.2919612774139309
Validation loss: 2.668755463260297

Epoch: 6| Step: 5
Training loss: 2.09782309552362
Validation loss: 2.700614969249184

Epoch: 6| Step: 6
Training loss: 2.301203897771745
Validation loss: 2.7623790938902313

Epoch: 6| Step: 7
Training loss: 1.5327894296572329
Validation loss: 2.6300221342646926

Epoch: 6| Step: 8
Training loss: 1.5967222435555866
Validation loss: 2.6789879214717107

Epoch: 6| Step: 9
Training loss: 1.3556706610693394
Validation loss: 2.706046787352762

Epoch: 6| Step: 10
Training loss: 1.1118475533111065
Validation loss: 2.7502547637377597

Epoch: 6| Step: 11
Training loss: 1.4635236564786063
Validation loss: 2.631491294664271

Epoch: 6| Step: 12
Training loss: 1.8830055992541577
Validation loss: 2.777785175366618

Epoch: 6| Step: 13
Training loss: 1.677936013375996
Validation loss: 2.698946786843771

Epoch: 148| Step: 0
Training loss: 2.0747016876144704
Validation loss: 2.6622491745264654

Epoch: 6| Step: 1
Training loss: 1.1080119396007109
Validation loss: 2.6181255728085895

Epoch: 6| Step: 2
Training loss: 2.0129904866038775
Validation loss: 2.5776216882642142

Epoch: 6| Step: 3
Training loss: 1.059619758260888
Validation loss: 2.718766837232346

Epoch: 6| Step: 4
Training loss: 1.6259238477988267
Validation loss: 2.7473139649738805

Epoch: 6| Step: 5
Training loss: 1.4567358622639883
Validation loss: 2.6825194228181064

Epoch: 6| Step: 6
Training loss: 2.667578561156887
Validation loss: 2.699982619229641

Epoch: 6| Step: 7
Training loss: 1.0206428985988518
Validation loss: 2.6196882304608042

Epoch: 6| Step: 8
Training loss: 1.8301017051325728
Validation loss: 2.6190569980668084

Epoch: 6| Step: 9
Training loss: 1.446279666105111
Validation loss: 2.662686049239752

Epoch: 6| Step: 10
Training loss: 1.540159115559839
Validation loss: 2.719756732912587

Epoch: 6| Step: 11
Training loss: 1.8032594786003109
Validation loss: 2.6119417293726994

Epoch: 6| Step: 12
Training loss: 1.7316689903505589
Validation loss: 2.772438320646786

Epoch: 6| Step: 13
Training loss: 0.821077698351963
Validation loss: 2.6736892132821635

Epoch: 149| Step: 0
Training loss: 1.219170228940323
Validation loss: 2.6308324444777065

Epoch: 6| Step: 1
Training loss: 1.4137833883590987
Validation loss: 2.632030140653946

Epoch: 6| Step: 2
Training loss: 1.297074360059234
Validation loss: 2.6112339152097443

Epoch: 6| Step: 3
Training loss: 1.5073911246084135
Validation loss: 2.68726785529517

Epoch: 6| Step: 4
Training loss: 1.8662463254183386
Validation loss: 2.5827938613788324

Epoch: 6| Step: 5
Training loss: 1.8746628776112262
Validation loss: 2.800382762246417

Epoch: 6| Step: 6
Training loss: 1.0438236918675392
Validation loss: 2.740741678245869

Epoch: 6| Step: 7
Training loss: 1.8499201319182184
Validation loss: 2.6886218043644767

Epoch: 6| Step: 8
Training loss: 2.207866139445386
Validation loss: 2.689213391388572

Epoch: 6| Step: 9
Training loss: 1.5222721435469957
Validation loss: 2.6603604395656935

Epoch: 6| Step: 10
Training loss: 1.4738865577646407
Validation loss: 2.6965323226418416

Epoch: 6| Step: 11
Training loss: 1.6278469382744383
Validation loss: 2.5737550324558627

Epoch: 6| Step: 12
Training loss: 1.7362320039831294
Validation loss: 2.724354867658785

Epoch: 6| Step: 13
Training loss: 1.739824548623066
Validation loss: 2.7057474458215918

Epoch: 150| Step: 0
Training loss: 1.5563597766810942
Validation loss: 2.679248065710608

Epoch: 6| Step: 1
Training loss: 1.4621169281422257
Validation loss: 2.68232700855465

Epoch: 6| Step: 2
Training loss: 1.5186063408116244
Validation loss: 2.6868266437559956

Epoch: 6| Step: 3
Training loss: 1.2524076163509612
Validation loss: 2.7958686055110724

Epoch: 6| Step: 4
Training loss: 1.5263573468672706
Validation loss: 2.7538276029859357

Epoch: 6| Step: 5
Training loss: 0.9922281392102479
Validation loss: 2.6611925329570827

Epoch: 6| Step: 6
Training loss: 1.6878903255449138
Validation loss: 2.717818835170942

Epoch: 6| Step: 7
Training loss: 1.029343316262842
Validation loss: 2.7548881782227967

Epoch: 6| Step: 8
Training loss: 1.8172264954309936
Validation loss: 2.728757439331035

Epoch: 6| Step: 9
Training loss: 2.6472347082657732
Validation loss: 2.6566525621729804

Epoch: 6| Step: 10
Training loss: 2.2692193294619756
Validation loss: 2.6658567276437237

Epoch: 6| Step: 11
Training loss: 1.2731946936039868
Validation loss: 2.613846501533613

Epoch: 6| Step: 12
Training loss: 1.4819861212632672
Validation loss: 2.75524475900456

Epoch: 6| Step: 13
Training loss: 1.4981289160991185
Validation loss: 2.5689568311797077

Epoch: 151| Step: 0
Training loss: 1.0267001844999513
Validation loss: 2.606903626638338

Epoch: 6| Step: 1
Training loss: 1.9311690106739687
Validation loss: 2.7383057887510147

Epoch: 6| Step: 2
Training loss: 1.1894276683570018
Validation loss: 2.638568988171153

Epoch: 6| Step: 3
Training loss: 1.8461321942575826
Validation loss: 2.7600376276777645

Epoch: 6| Step: 4
Training loss: 1.9683998038653265
Validation loss: 2.7283018552268836

Epoch: 6| Step: 5
Training loss: 1.4978821426395754
Validation loss: 2.607863988076642

Epoch: 6| Step: 6
Training loss: 2.444383633704899
Validation loss: 2.667305025544328

Epoch: 6| Step: 7
Training loss: 1.2349737139850423
Validation loss: 2.6359679558966875

Epoch: 6| Step: 8
Training loss: 1.1764359283250319
Validation loss: 2.708176261063965

Epoch: 6| Step: 9
Training loss: 2.227636673798414
Validation loss: 2.770037276181301

Epoch: 6| Step: 10
Training loss: 1.4766437972359499
Validation loss: 2.722624696013277

Epoch: 6| Step: 11
Training loss: 1.4478913266093745
Validation loss: 2.5792972558342044

Epoch: 6| Step: 12
Training loss: 1.823965312335135
Validation loss: 2.709121242256981

Epoch: 6| Step: 13
Training loss: 1.0443612279160834
Validation loss: 2.793784851494041

Epoch: 152| Step: 0
Training loss: 2.1904448169826916
Validation loss: 2.616615931409849

Epoch: 6| Step: 1
Training loss: 1.0280495311552873
Validation loss: 2.7451613368488923

Epoch: 6| Step: 2
Training loss: 1.3839423956817818
Validation loss: 2.63062427115013

Epoch: 6| Step: 3
Training loss: 1.3921371981762942
Validation loss: 2.722123402685454

Epoch: 6| Step: 4
Training loss: 1.3199252401480066
Validation loss: 2.70943540500651

Epoch: 6| Step: 5
Training loss: 1.2875996004855912
Validation loss: 2.7945773314189792

Epoch: 6| Step: 6
Training loss: 1.6719223443573936
Validation loss: 2.6745895813631613

Epoch: 6| Step: 7
Training loss: 1.4931919252479269
Validation loss: 2.76980166242751

Epoch: 6| Step: 8
Training loss: 1.7437310330579696
Validation loss: 2.7243922066136053

Epoch: 6| Step: 9
Training loss: 1.4395367664068737
Validation loss: 2.6861179701717433

Epoch: 6| Step: 10
Training loss: 1.6074723783881588
Validation loss: 2.6835458779912167

Epoch: 6| Step: 11
Training loss: 1.772611181863945
Validation loss: 2.6432684734159193

Epoch: 6| Step: 12
Training loss: 1.4240499776256572
Validation loss: 2.6151718500633896

Epoch: 6| Step: 13
Training loss: 1.437729526937161
Validation loss: 2.732988758193846

Epoch: 153| Step: 0
Training loss: 1.2091236927818474
Validation loss: 2.681322094141457

Epoch: 6| Step: 1
Training loss: 1.3121792991837975
Validation loss: 2.723918576555194

Epoch: 6| Step: 2
Training loss: 1.756212718744405
Validation loss: 2.7321526497250734

Epoch: 6| Step: 3
Training loss: 1.5152900561658766
Validation loss: 2.7321641976371667

Epoch: 6| Step: 4
Training loss: 2.4807791928641207
Validation loss: 2.6316904002982286

Epoch: 6| Step: 5
Training loss: 1.8816701502242617
Validation loss: 2.71942079241759

Epoch: 6| Step: 6
Training loss: 1.5967374738683007
Validation loss: 2.6312019561223305

Epoch: 6| Step: 7
Training loss: 1.5244517544687601
Validation loss: 2.6473737472722623

Epoch: 6| Step: 8
Training loss: 2.0526032410466053
Validation loss: 2.6840003833192494

Epoch: 6| Step: 9
Training loss: 1.628772098862689
Validation loss: 2.5859944470791696

Epoch: 6| Step: 10
Training loss: 1.5080874493789693
Validation loss: 2.654930340439167

Epoch: 6| Step: 11
Training loss: 1.4089353565036802
Validation loss: 2.7046960811085863

Epoch: 6| Step: 12
Training loss: 1.1482976192481245
Validation loss: 2.5966085744863565

Epoch: 6| Step: 13
Training loss: 1.630676478563568
Validation loss: 2.74061040638801

Epoch: 154| Step: 0
Training loss: 1.3529960218457076
Validation loss: 2.6619351601264305

Epoch: 6| Step: 1
Training loss: 0.8414397931651739
Validation loss: 2.661701576976952

Epoch: 6| Step: 2
Training loss: 1.167674866513504
Validation loss: 2.753618460694073

Epoch: 6| Step: 3
Training loss: 2.0333131142950314
Validation loss: 2.7609006829245613

Epoch: 6| Step: 4
Training loss: 1.562907509115482
Validation loss: 2.8414861310362753

Epoch: 6| Step: 5
Training loss: 2.2899006946137703
Validation loss: 2.7251536638056493

Epoch: 6| Step: 6
Training loss: 1.975593419798609
Validation loss: 2.836238246135138

Epoch: 6| Step: 7
Training loss: 1.2241566382391873
Validation loss: 2.7085944905668367

Epoch: 6| Step: 8
Training loss: 1.8965329007855907
Validation loss: 2.7805595541040424

Epoch: 6| Step: 9
Training loss: 1.206738433380994
Validation loss: 2.8327041422899035

Epoch: 6| Step: 10
Training loss: 1.4094730317728403
Validation loss: 2.696468698683604

Epoch: 6| Step: 11
Training loss: 1.7185205479831576
Validation loss: 2.843623706961599

Epoch: 6| Step: 12
Training loss: 1.3919421184169078
Validation loss: 2.772663506335088

Epoch: 6| Step: 13
Training loss: 1.2337735316265397
Validation loss: 2.7070185820194586

Epoch: 155| Step: 0
Training loss: 1.4290691768808084
Validation loss: 2.73347810113756

Epoch: 6| Step: 1
Training loss: 1.6851217677550383
Validation loss: 2.7363886802665602

Epoch: 6| Step: 2
Training loss: 1.26633377008982
Validation loss: 2.6782061724414867

Epoch: 6| Step: 3
Training loss: 1.8628297654663515
Validation loss: 2.650780540651346

Epoch: 6| Step: 4
Training loss: 1.415356712939417
Validation loss: 2.7435811876460225

Epoch: 6| Step: 5
Training loss: 1.1574447233047906
Validation loss: 2.695876382270803

Epoch: 6| Step: 6
Training loss: 1.5412832590986745
Validation loss: 2.8384015016626

Epoch: 6| Step: 7
Training loss: 1.184774785268948
Validation loss: 2.7908684789844784

Epoch: 6| Step: 8
Training loss: 1.520414826104613
Validation loss: 2.8496788875754926

Epoch: 6| Step: 9
Training loss: 1.9017868950249777
Validation loss: 2.9222514340129595

Epoch: 6| Step: 10
Training loss: 2.514867064221886
Validation loss: 2.9145714909329072

Epoch: 6| Step: 11
Training loss: 1.7544315630441438
Validation loss: 2.7269046718123495

Epoch: 6| Step: 12
Training loss: 1.4500451212472507
Validation loss: 2.6327615010409358

Epoch: 6| Step: 13
Training loss: 2.258992345546201
Validation loss: 2.643570485494716

Epoch: 156| Step: 0
Training loss: 1.798674702185027
Validation loss: 2.748293028983774

Epoch: 6| Step: 1
Training loss: 1.464826904200011
Validation loss: 2.750183243859711

Epoch: 6| Step: 2
Training loss: 2.009417297013031
Validation loss: 2.8016863025232097

Epoch: 6| Step: 3
Training loss: 1.7762769914223253
Validation loss: 2.8693741750303987

Epoch: 6| Step: 4
Training loss: 1.649114894443032
Validation loss: 2.8316844929595604

Epoch: 6| Step: 5
Training loss: 1.8722157469101994
Validation loss: 2.916814872972602

Epoch: 6| Step: 6
Training loss: 1.0227087789847846
Validation loss: 2.748008266847439

Epoch: 6| Step: 7
Training loss: 1.6339368827423808
Validation loss: 2.7609936860834527

Epoch: 6| Step: 8
Training loss: 1.4954053923673547
Validation loss: 2.7810764615785155

Epoch: 6| Step: 9
Training loss: 1.5371548210900046
Validation loss: 2.6961087879641044

Epoch: 6| Step: 10
Training loss: 1.2012867446185884
Validation loss: 2.6838970281335883

Epoch: 6| Step: 11
Training loss: 1.5784896580354597
Validation loss: 2.8123148821908623

Epoch: 6| Step: 12
Training loss: 2.48745967889819
Validation loss: 2.727883529900765

Epoch: 6| Step: 13
Training loss: 1.7834455778621805
Validation loss: 2.9497645936133936

Epoch: 157| Step: 0
Training loss: 1.2099626616557277
Validation loss: 2.8974679591744485

Epoch: 6| Step: 1
Training loss: 2.0288637670182856
Validation loss: 2.9580622378682486

Epoch: 6| Step: 2
Training loss: 1.452213945174682
Validation loss: 2.9001096030603004

Epoch: 6| Step: 3
Training loss: 2.168340977511858
Validation loss: 2.851803077060017

Epoch: 6| Step: 4
Training loss: 1.769020528964255
Validation loss: 2.7610471809102064

Epoch: 6| Step: 5
Training loss: 2.1745242420633737
Validation loss: 2.6506763848622943

Epoch: 6| Step: 6
Training loss: 1.5857404013242034
Validation loss: 2.686021190949804

Epoch: 6| Step: 7
Training loss: 1.7838436451251258
Validation loss: 2.7602773283333537

Epoch: 6| Step: 8
Training loss: 1.0251006379383496
Validation loss: 2.716233663824362

Epoch: 6| Step: 9
Training loss: 1.3735516028804493
Validation loss: 2.8148606883483525

Epoch: 6| Step: 10
Training loss: 1.8078706750106537
Validation loss: 2.779571355230543

Epoch: 6| Step: 11
Training loss: 1.2411536947116921
Validation loss: 2.6930827772646695

Epoch: 6| Step: 12
Training loss: 1.9941925131747062
Validation loss: 2.7074873605599263

Epoch: 6| Step: 13
Training loss: 1.8479923644217748
Validation loss: 2.746915402221975

Epoch: 158| Step: 0
Training loss: 1.9188419382143225
Validation loss: 2.8017101441125796

Epoch: 6| Step: 1
Training loss: 1.1845299068393496
Validation loss: 2.727388215028077

Epoch: 6| Step: 2
Training loss: 1.4665678330557566
Validation loss: 2.6473461591998597

Epoch: 6| Step: 3
Training loss: 1.577529946117029
Validation loss: 2.7473600460572163

Epoch: 6| Step: 4
Training loss: 1.4038445987230537
Validation loss: 2.972963455106463

Epoch: 6| Step: 5
Training loss: 2.6806380918596244
Validation loss: 2.8188110046100814

Epoch: 6| Step: 6
Training loss: 1.7362219796278138
Validation loss: 2.8541162769482433

Epoch: 6| Step: 7
Training loss: 1.825227315672142
Validation loss: 2.95504364712964

Epoch: 6| Step: 8
Training loss: 1.8693410672264992
Validation loss: 2.796520501940844

Epoch: 6| Step: 9
Training loss: 1.0689041450389427
Validation loss: 2.663465162562721

Epoch: 6| Step: 10
Training loss: 1.8040824635555985
Validation loss: 2.6631594681435917

Epoch: 6| Step: 11
Training loss: 1.260499536401466
Validation loss: 2.6676680552281855

Epoch: 6| Step: 12
Training loss: 1.2656926266534048
Validation loss: 2.58470808386644

Epoch: 6| Step: 13
Training loss: 1.3360386860323137
Validation loss: 2.6538276697413137

Epoch: 159| Step: 0
Training loss: 1.2788270043748002
Validation loss: 2.684316923603469

Epoch: 6| Step: 1
Training loss: 1.2188751938903548
Validation loss: 2.7752730335484417

Epoch: 6| Step: 2
Training loss: 1.3405746823984965
Validation loss: 2.7838472533370635

Epoch: 6| Step: 3
Training loss: 1.1917831575147502
Validation loss: 2.7939381586556804

Epoch: 6| Step: 4
Training loss: 1.393801372590568
Validation loss: 2.713880687385833

Epoch: 6| Step: 5
Training loss: 1.3447641050241175
Validation loss: 2.7096318042198835

Epoch: 6| Step: 6
Training loss: 1.6488202992940175
Validation loss: 2.589499027253733

Epoch: 6| Step: 7
Training loss: 1.760767779426119
Validation loss: 2.686218636390163

Epoch: 6| Step: 8
Training loss: 1.4378507435021202
Validation loss: 2.7569481320894327

Epoch: 6| Step: 9
Training loss: 1.8201766065699818
Validation loss: 2.718572851964874

Epoch: 6| Step: 10
Training loss: 1.2473720582781511
Validation loss: 2.702913397296049

Epoch: 6| Step: 11
Training loss: 2.3704476143858586
Validation loss: 2.821571555144757

Epoch: 6| Step: 12
Training loss: 1.9104000630241333
Validation loss: 2.8534166831100864

Epoch: 6| Step: 13
Training loss: 1.2593475831031515
Validation loss: 2.766416447213185

Epoch: 160| Step: 0
Training loss: 1.1991867906120304
Validation loss: 2.8389240578946673

Epoch: 6| Step: 1
Training loss: 1.1563643321653534
Validation loss: 2.698066601704822

Epoch: 6| Step: 2
Training loss: 0.8640655131227132
Validation loss: 2.75818671118205

Epoch: 6| Step: 3
Training loss: 2.106117049642406
Validation loss: 2.675689042259149

Epoch: 6| Step: 4
Training loss: 1.2279823006774069
Validation loss: 2.8577489450603104

Epoch: 6| Step: 5
Training loss: 1.5229152468958689
Validation loss: 2.8368991450904053

Epoch: 6| Step: 6
Training loss: 1.166586169235983
Validation loss: 2.7249669431728685

Epoch: 6| Step: 7
Training loss: 1.5765206519509447
Validation loss: 2.613782499145667

Epoch: 6| Step: 8
Training loss: 1.0947152374525715
Validation loss: 2.685610868674103

Epoch: 6| Step: 9
Training loss: 1.590768006496983
Validation loss: 2.7078305193401846

Epoch: 6| Step: 10
Training loss: 1.1796182776345767
Validation loss: 2.7443518578806003

Epoch: 6| Step: 11
Training loss: 2.006712140722395
Validation loss: 2.684615427958484

Epoch: 6| Step: 12
Training loss: 1.4060842204393615
Validation loss: 2.6272413433654815

Epoch: 6| Step: 13
Training loss: 1.7632765553977714
Validation loss: 2.7125354494980765

Epoch: 161| Step: 0
Training loss: 1.4052971896880797
Validation loss: 2.807584267243594

Epoch: 6| Step: 1
Training loss: 1.400561589614686
Validation loss: 2.730233753080673

Epoch: 6| Step: 2
Training loss: 1.4749810363067721
Validation loss: 2.6594765308690747

Epoch: 6| Step: 3
Training loss: 0.9992940616336933
Validation loss: 2.7547904540794472

Epoch: 6| Step: 4
Training loss: 1.5588670839878465
Validation loss: 2.6807847515238303

Epoch: 6| Step: 5
Training loss: 1.3269077781764935
Validation loss: 2.741880133376002

Epoch: 6| Step: 6
Training loss: 1.0529292391615281
Validation loss: 2.7931340806662224

Epoch: 6| Step: 7
Training loss: 1.1702873155967952
Validation loss: 2.735740538630857

Epoch: 6| Step: 8
Training loss: 2.4857901135672127
Validation loss: 2.7217596503370163

Epoch: 6| Step: 9
Training loss: 1.2525333006461745
Validation loss: 2.8753488024991194

Epoch: 6| Step: 10
Training loss: 1.322686042607833
Validation loss: 2.7589575503951496

Epoch: 6| Step: 11
Training loss: 1.544194374528966
Validation loss: 2.725450757277154

Epoch: 6| Step: 12
Training loss: 1.1995670173244737
Validation loss: 2.6532218127640306

Epoch: 6| Step: 13
Training loss: 1.6691669386153904
Validation loss: 2.718664175264727

Epoch: 162| Step: 0
Training loss: 1.7850087979310931
Validation loss: 2.642275247558681

Epoch: 6| Step: 1
Training loss: 1.0141656808422588
Validation loss: 2.7573876562488815

Epoch: 6| Step: 2
Training loss: 1.4634280268126083
Validation loss: 2.680749325070884

Epoch: 6| Step: 3
Training loss: 1.2858217133948606
Validation loss: 2.6894826746591374

Epoch: 6| Step: 4
Training loss: 1.3852726232846149
Validation loss: 2.6282961904174704

Epoch: 6| Step: 5
Training loss: 1.5085735870862975
Validation loss: 2.6527440738589614

Epoch: 6| Step: 6
Training loss: 2.383664238461699
Validation loss: 2.723800280175322

Epoch: 6| Step: 7
Training loss: 1.6425697063361846
Validation loss: 2.670821296279928

Epoch: 6| Step: 8
Training loss: 1.2610474681526482
Validation loss: 2.7142194071178136

Epoch: 6| Step: 9
Training loss: 1.2461032209365297
Validation loss: 2.6636418581963217

Epoch: 6| Step: 10
Training loss: 1.4822944918096468
Validation loss: 2.718589741452324

Epoch: 6| Step: 11
Training loss: 0.8255576156620742
Validation loss: 2.621804457008375

Epoch: 6| Step: 12
Training loss: 0.8637230204496622
Validation loss: 2.787620093092253

Epoch: 6| Step: 13
Training loss: 1.3632631491959608
Validation loss: 2.8035368192652133

Epoch: 163| Step: 0
Training loss: 1.6654832532734167
Validation loss: 2.759588172428758

Epoch: 6| Step: 1
Training loss: 1.4195633426412335
Validation loss: 2.741403494806609

Epoch: 6| Step: 2
Training loss: 1.3562045779730518
Validation loss: 2.939864296105968

Epoch: 6| Step: 3
Training loss: 1.2971481587089773
Validation loss: 2.7171536139871777

Epoch: 6| Step: 4
Training loss: 0.9958582581043751
Validation loss: 2.786470542714593

Epoch: 6| Step: 5
Training loss: 2.0833153406002
Validation loss: 2.784459408994451

Epoch: 6| Step: 6
Training loss: 1.2547840599062987
Validation loss: 2.669564435985355

Epoch: 6| Step: 7
Training loss: 1.544604860904745
Validation loss: 2.7474064300959493

Epoch: 6| Step: 8
Training loss: 1.0213638146992132
Validation loss: 2.7319349900856573

Epoch: 6| Step: 9
Training loss: 1.6609404742410752
Validation loss: 2.709954375754537

Epoch: 6| Step: 10
Training loss: 1.9969380304600237
Validation loss: 2.742187507245389

Epoch: 6| Step: 11
Training loss: 1.4014284339839167
Validation loss: 2.693340918330412

Epoch: 6| Step: 12
Training loss: 1.2294026433865086
Validation loss: 2.663629595504015

Epoch: 6| Step: 13
Training loss: 1.665425346962064
Validation loss: 2.682646175524615

Epoch: 164| Step: 0
Training loss: 1.1600662350653816
Validation loss: 2.803358650463631

Epoch: 6| Step: 1
Training loss: 1.0936071575077073
Validation loss: 2.68924347562023

Epoch: 6| Step: 2
Training loss: 1.135471406836162
Validation loss: 2.6989405811177005

Epoch: 6| Step: 3
Training loss: 1.2401585352981004
Validation loss: 2.6845719851010688

Epoch: 6| Step: 4
Training loss: 1.2960583057121389
Validation loss: 2.7091809095815784

Epoch: 6| Step: 5
Training loss: 1.403785920333201
Validation loss: 2.71953694146538

Epoch: 6| Step: 6
Training loss: 0.9402779429999212
Validation loss: 2.77996060489853

Epoch: 6| Step: 7
Training loss: 1.1261015902844802
Validation loss: 2.8484677596166827

Epoch: 6| Step: 8
Training loss: 1.2998489842365069
Validation loss: 2.699048005153809

Epoch: 6| Step: 9
Training loss: 1.9839584033435553
Validation loss: 2.838421234002496

Epoch: 6| Step: 10
Training loss: 1.6572449772474245
Validation loss: 2.738402592051501

Epoch: 6| Step: 11
Training loss: 2.3003333389215155
Validation loss: 2.753681247618858

Epoch: 6| Step: 12
Training loss: 1.7283387864166921
Validation loss: 2.8291725480735295

Epoch: 6| Step: 13
Training loss: 0.9369271753605058
Validation loss: 2.7400885117405136

Epoch: 165| Step: 0
Training loss: 0.9537139073813322
Validation loss: 2.8296403425623957

Epoch: 6| Step: 1
Training loss: 1.594877480013519
Validation loss: 2.6742546237386

Epoch: 6| Step: 2
Training loss: 1.5596736522587964
Validation loss: 2.7719802824982436

Epoch: 6| Step: 3
Training loss: 1.1519507303662537
Validation loss: 2.716375022476831

Epoch: 6| Step: 4
Training loss: 1.172840585268155
Validation loss: 2.789366106307906

Epoch: 6| Step: 5
Training loss: 2.459113422913166
Validation loss: 2.671690802517688

Epoch: 6| Step: 6
Training loss: 1.7423188027480923
Validation loss: 2.715695825142659

Epoch: 6| Step: 7
Training loss: 1.717681552669713
Validation loss: 2.731859514211032

Epoch: 6| Step: 8
Training loss: 1.0679946639538451
Validation loss: 2.711913725491554

Epoch: 6| Step: 9
Training loss: 0.8622978443466081
Validation loss: 2.7308384941043773

Epoch: 6| Step: 10
Training loss: 1.1909496996016251
Validation loss: 2.6691603673391557

Epoch: 6| Step: 11
Training loss: 1.4267621572273
Validation loss: 2.821046059296116

Epoch: 6| Step: 12
Training loss: 1.353021969297563
Validation loss: 2.834722295342963

Epoch: 6| Step: 13
Training loss: 1.362874098699713
Validation loss: 2.8599156353251693

Epoch: 166| Step: 0
Training loss: 1.4090597269517824
Validation loss: 2.849281269486194

Epoch: 6| Step: 1
Training loss: 1.1113050622675615
Validation loss: 2.8410033910879475

Epoch: 6| Step: 2
Training loss: 1.3724294823629895
Validation loss: 2.6555892272057675

Epoch: 6| Step: 3
Training loss: 1.7321297486361205
Validation loss: 2.6519167092344507

Epoch: 6| Step: 4
Training loss: 1.742642056819415
Validation loss: 2.719112021360584

Epoch: 6| Step: 5
Training loss: 1.3663556429268584
Validation loss: 2.6336741108243764

Epoch: 6| Step: 6
Training loss: 1.3472231403928863
Validation loss: 2.683763464420244

Epoch: 6| Step: 7
Training loss: 1.9443648761030785
Validation loss: 2.809817758818372

Epoch: 6| Step: 8
Training loss: 0.825288882396089
Validation loss: 2.641263158608676

Epoch: 6| Step: 9
Training loss: 2.1918592341812966
Validation loss: 2.7445680405340456

Epoch: 6| Step: 10
Training loss: 1.2462217928832693
Validation loss: 2.7669563321830295

Epoch: 6| Step: 11
Training loss: 1.2742005852691498
Validation loss: 2.6894073519370236

Epoch: 6| Step: 12
Training loss: 1.2440076244893348
Validation loss: 2.7279644033639654

Epoch: 6| Step: 13
Training loss: 0.9816545709362406
Validation loss: 2.7538487638060327

Epoch: 167| Step: 0
Training loss: 1.2903338087654732
Validation loss: 2.741982940550272

Epoch: 6| Step: 1
Training loss: 1.7921632773401213
Validation loss: 2.740770616943699

Epoch: 6| Step: 2
Training loss: 2.4701997387392742
Validation loss: 2.669264549930279

Epoch: 6| Step: 3
Training loss: 1.2190153860039634
Validation loss: 2.7139306158812135

Epoch: 6| Step: 4
Training loss: 1.2040548323251752
Validation loss: 2.7836935331832415

Epoch: 6| Step: 5
Training loss: 1.353766876284583
Validation loss: 2.6387315541485097

Epoch: 6| Step: 6
Training loss: 1.427143773193589
Validation loss: 2.7957594936150194

Epoch: 6| Step: 7
Training loss: 1.5992480418360393
Validation loss: 2.695193567278062

Epoch: 6| Step: 8
Training loss: 1.121544723986347
Validation loss: 2.798573516317632

Epoch: 6| Step: 9
Training loss: 1.226833483653782
Validation loss: 2.738213640322504

Epoch: 6| Step: 10
Training loss: 0.955477079291232
Validation loss: 2.6984873331368853

Epoch: 6| Step: 11
Training loss: 1.4075824359040794
Validation loss: 2.815454654713011

Epoch: 6| Step: 12
Training loss: 1.0480212867846297
Validation loss: 2.7202948934681688

Epoch: 6| Step: 13
Training loss: 0.9294808422533667
Validation loss: 2.719472328781684

Epoch: 168| Step: 0
Training loss: 1.6460018152201437
Validation loss: 2.722827462678757

Epoch: 6| Step: 1
Training loss: 1.4791709022282236
Validation loss: 2.69088963098152

Epoch: 6| Step: 2
Training loss: 1.0150908606126732
Validation loss: 2.8471573827436933

Epoch: 6| Step: 3
Training loss: 1.0592249716241044
Validation loss: 2.7618168188917385

Epoch: 6| Step: 4
Training loss: 1.1490552629041135
Validation loss: 2.7643287767637754

Epoch: 6| Step: 5
Training loss: 1.0642190378357002
Validation loss: 2.7480206157312668

Epoch: 6| Step: 6
Training loss: 1.0203157527106461
Validation loss: 2.825825594215816

Epoch: 6| Step: 7
Training loss: 1.6110580680417124
Validation loss: 2.8656328024388777

Epoch: 6| Step: 8
Training loss: 1.7264328299458098
Validation loss: 2.8456184201800183

Epoch: 6| Step: 9
Training loss: 1.7973679902860413
Validation loss: 2.803635608064611

Epoch: 6| Step: 10
Training loss: 0.7615181683272197
Validation loss: 2.594199559115226

Epoch: 6| Step: 11
Training loss: 1.2880806622747836
Validation loss: 2.7109584899148382

Epoch: 6| Step: 12
Training loss: 1.3833494275470544
Validation loss: 2.7079726247958034

Epoch: 6| Step: 13
Training loss: 2.344693311958375
Validation loss: 2.7446326849761613

Epoch: 169| Step: 0
Training loss: 1.0822925458701964
Validation loss: 2.735425387676328

Epoch: 6| Step: 1
Training loss: 0.9321115131463957
Validation loss: 2.7859897587942357

Epoch: 6| Step: 2
Training loss: 1.1182671511908482
Validation loss: 2.868508210585632

Epoch: 6| Step: 3
Training loss: 2.316650789421434
Validation loss: 2.682385390536158

Epoch: 6| Step: 4
Training loss: 0.8756393753276728
Validation loss: 2.776623467509651

Epoch: 6| Step: 5
Training loss: 1.1553964299491994
Validation loss: 2.746041613500342

Epoch: 6| Step: 6
Training loss: 1.5982174062736472
Validation loss: 2.744762591811821

Epoch: 6| Step: 7
Training loss: 1.1461908591851648
Validation loss: 2.7366866449361757

Epoch: 6| Step: 8
Training loss: 1.9141591573171275
Validation loss: 2.800463415012132

Epoch: 6| Step: 9
Training loss: 1.4856642093708023
Validation loss: 2.842794516321571

Epoch: 6| Step: 10
Training loss: 1.3914635519558207
Validation loss: 2.71504738316131

Epoch: 6| Step: 11
Training loss: 0.6988610359574889
Validation loss: 2.856149991411078

Epoch: 6| Step: 12
Training loss: 1.8102863210704434
Validation loss: 2.866202785603825

Epoch: 6| Step: 13
Training loss: 1.0219477519697582
Validation loss: 2.8260300466034

Epoch: 170| Step: 0
Training loss: 1.915302482201607
Validation loss: 2.896151783583568

Epoch: 6| Step: 1
Training loss: 0.9889721773436372
Validation loss: 2.7486421382755517

Epoch: 6| Step: 2
Training loss: 0.8761497164818483
Validation loss: 2.78404903651676

Epoch: 6| Step: 3
Training loss: 1.1290805774448338
Validation loss: 2.797442827887657

Epoch: 6| Step: 4
Training loss: 2.197694511094073
Validation loss: 2.756773236839005

Epoch: 6| Step: 5
Training loss: 1.0991907220559949
Validation loss: 2.706343988808328

Epoch: 6| Step: 6
Training loss: 1.0952379187688428
Validation loss: 2.7419471889013174

Epoch: 6| Step: 7
Training loss: 1.3518361602861502
Validation loss: 2.712968195810239

Epoch: 6| Step: 8
Training loss: 1.6112190718305255
Validation loss: 2.7987417317322687

Epoch: 6| Step: 9
Training loss: 1.5210452345843812
Validation loss: 2.771714584255989

Epoch: 6| Step: 10
Training loss: 1.1214082921288457
Validation loss: 2.743501976696109

Epoch: 6| Step: 11
Training loss: 1.2221635794779853
Validation loss: 2.6452281940723394

Epoch: 6| Step: 12
Training loss: 1.0220456742011084
Validation loss: 2.76674329199638

Epoch: 6| Step: 13
Training loss: 1.4329268648021873
Validation loss: 2.7781192789494438

Epoch: 171| Step: 0
Training loss: 1.0949239697472046
Validation loss: 2.754686740089697

Epoch: 6| Step: 1
Training loss: 1.394805026494895
Validation loss: 2.8432155428283576

Epoch: 6| Step: 2
Training loss: 1.2846630042693177
Validation loss: 2.64876817647504

Epoch: 6| Step: 3
Training loss: 2.2935973155580425
Validation loss: 2.6683288003603836

Epoch: 6| Step: 4
Training loss: 1.2368542363841677
Validation loss: 2.848413451332666

Epoch: 6| Step: 5
Training loss: 1.0298456976410142
Validation loss: 2.7074705412422384

Epoch: 6| Step: 6
Training loss: 1.016502060358499
Validation loss: 2.772446948897726

Epoch: 6| Step: 7
Training loss: 1.3825883414272615
Validation loss: 2.8017875888749537

Epoch: 6| Step: 8
Training loss: 1.0516056953162771
Validation loss: 2.77543735666146

Epoch: 6| Step: 9
Training loss: 1.2233115198354312
Validation loss: 2.844354153129724

Epoch: 6| Step: 10
Training loss: 1.33024177160731
Validation loss: 2.709801207637778

Epoch: 6| Step: 11
Training loss: 1.0904833376458476
Validation loss: 2.841142374112931

Epoch: 6| Step: 12
Training loss: 1.9248495266054544
Validation loss: 2.827819301880754

Epoch: 6| Step: 13
Training loss: 1.2833468329144837
Validation loss: 2.7568294368770405

Epoch: 172| Step: 0
Training loss: 2.319415705865115
Validation loss: 2.7550846689855866

Epoch: 6| Step: 1
Training loss: 1.4066567574433744
Validation loss: 2.7641859028096767

Epoch: 6| Step: 2
Training loss: 1.5549652771584113
Validation loss: 2.7644484292763463

Epoch: 6| Step: 3
Training loss: 1.0982577484781453
Validation loss: 2.637904276003549

Epoch: 6| Step: 4
Training loss: 1.560378503608636
Validation loss: 2.8287480266955805

Epoch: 6| Step: 5
Training loss: 1.1034472959175978
Validation loss: 2.7186687355027397

Epoch: 6| Step: 6
Training loss: 1.2054599546555402
Validation loss: 2.756813466323616

Epoch: 6| Step: 7
Training loss: 1.3865952127796322
Validation loss: 2.743307625714622

Epoch: 6| Step: 8
Training loss: 1.2936888933723916
Validation loss: 2.955715005759488

Epoch: 6| Step: 9
Training loss: 1.6115058199842214
Validation loss: 2.727899276524922

Epoch: 6| Step: 10
Training loss: 1.3508263937277492
Validation loss: 2.7183258193438644

Epoch: 6| Step: 11
Training loss: 1.1184310927398045
Validation loss: 2.810437859317929

Epoch: 6| Step: 12
Training loss: 1.0034458871192133
Validation loss: 2.834809932964347

Epoch: 6| Step: 13
Training loss: 0.982730521223265
Validation loss: 2.6666250126287525

Epoch: 173| Step: 0
Training loss: 1.5393444132273257
Validation loss: 2.864444206789551

Epoch: 6| Step: 1
Training loss: 1.2089791490383315
Validation loss: 2.6928601446589133

Epoch: 6| Step: 2
Training loss: 1.3593278635556372
Validation loss: 2.895751174383335

Epoch: 6| Step: 3
Training loss: 1.3875765873846944
Validation loss: 2.71366129859806

Epoch: 6| Step: 4
Training loss: 1.052685738255685
Validation loss: 2.7285065519946157

Epoch: 6| Step: 5
Training loss: 1.2724157809883734
Validation loss: 2.7493463953277084

Epoch: 6| Step: 6
Training loss: 2.1087258929653703
Validation loss: 2.8544130474216827

Epoch: 6| Step: 7
Training loss: 1.1187251253399535
Validation loss: 2.8466701256584335

Epoch: 6| Step: 8
Training loss: 1.0059951838687107
Validation loss: 2.7332698514203444

Epoch: 6| Step: 9
Training loss: 0.7749647609328527
Validation loss: 2.7115747030881243

Epoch: 6| Step: 10
Training loss: 1.263884678275858
Validation loss: 2.7000192135256733

Epoch: 6| Step: 11
Training loss: 1.66804507793376
Validation loss: 2.90442358072793

Epoch: 6| Step: 12
Training loss: 1.585205660934024
Validation loss: 2.7487024800840825

Epoch: 6| Step: 13
Training loss: 1.5012851613776461
Validation loss: 2.847572266116868

Epoch: 174| Step: 0
Training loss: 1.3059723061521407
Validation loss: 2.8503637293666797

Epoch: 6| Step: 1
Training loss: 2.117801253542366
Validation loss: 2.836350115839797

Epoch: 6| Step: 2
Training loss: 1.2737302853122712
Validation loss: 2.864904022761746

Epoch: 6| Step: 3
Training loss: 1.2176852343445723
Validation loss: 2.747796201535761

Epoch: 6| Step: 4
Training loss: 0.9457049855494012
Validation loss: 2.735306949744224

Epoch: 6| Step: 5
Training loss: 1.6451414158801116
Validation loss: 2.7174820117185456

Epoch: 6| Step: 6
Training loss: 1.0312525431283746
Validation loss: 2.8606350594259586

Epoch: 6| Step: 7
Training loss: 0.8638452267081655
Validation loss: 2.7227368263059266

Epoch: 6| Step: 8
Training loss: 1.2152117205635333
Validation loss: 2.7031853141744375

Epoch: 6| Step: 9
Training loss: 1.5799551445593574
Validation loss: 2.79682175001319

Epoch: 6| Step: 10
Training loss: 0.8513461196788581
Validation loss: 2.9031467208350867

Epoch: 6| Step: 11
Training loss: 1.6905217842564628
Validation loss: 2.653006828920481

Epoch: 6| Step: 12
Training loss: 1.005341390918531
Validation loss: 2.8824354991770935

Epoch: 6| Step: 13
Training loss: 1.2675404124241152
Validation loss: 2.823351095820027

Epoch: 175| Step: 0
Training loss: 1.8226140088918814
Validation loss: 2.901839125564377

Epoch: 6| Step: 1
Training loss: 1.478611407585209
Validation loss: 2.841785437002683

Epoch: 6| Step: 2
Training loss: 1.0820745466362978
Validation loss: 2.7969527846447213

Epoch: 6| Step: 3
Training loss: 1.0783044416948684
Validation loss: 2.827330841346991

Epoch: 6| Step: 4
Training loss: 1.541573040499128
Validation loss: 2.8592270220489504

Epoch: 6| Step: 5
Training loss: 1.2055518704507957
Validation loss: 2.792225686843766

Epoch: 6| Step: 6
Training loss: 1.2031937616688746
Validation loss: 2.7962711044558732

Epoch: 6| Step: 7
Training loss: 1.1246348424202879
Validation loss: 2.830602765295347

Epoch: 6| Step: 8
Training loss: 1.3595891761868566
Validation loss: 2.8068995629527453

Epoch: 6| Step: 9
Training loss: 2.29724969208097
Validation loss: 2.711802173394767

Epoch: 6| Step: 10
Training loss: 1.0116886443736541
Validation loss: 2.8102404524803277

Epoch: 6| Step: 11
Training loss: 1.580797708230925
Validation loss: 2.853679550444222

Epoch: 6| Step: 12
Training loss: 1.2423950597707827
Validation loss: 2.8606203629512597

Epoch: 6| Step: 13
Training loss: 1.1079897223625972
Validation loss: 2.8000740495608483

Epoch: 176| Step: 0
Training loss: 1.1074965786504318
Validation loss: 2.8035706516319174

Epoch: 6| Step: 1
Training loss: 1.154313140599627
Validation loss: 2.821609389096866

Epoch: 6| Step: 2
Training loss: 2.1793221334965263
Validation loss: 2.777237844974132

Epoch: 6| Step: 3
Training loss: 1.4748707924841096
Validation loss: 2.8314648993690614

Epoch: 6| Step: 4
Training loss: 1.1736908132562298
Validation loss: 2.812800186526394

Epoch: 6| Step: 5
Training loss: 1.23733315739925
Validation loss: 2.862497788918431

Epoch: 6| Step: 6
Training loss: 1.4674298461054167
Validation loss: 2.8787226555856655

Epoch: 6| Step: 7
Training loss: 1.2437852864076187
Validation loss: 2.8311355612604134

Epoch: 6| Step: 8
Training loss: 1.6621899882221047
Validation loss: 2.929508980292312

Epoch: 6| Step: 9
Training loss: 0.933737548224219
Validation loss: 2.76673800671379

Epoch: 6| Step: 10
Training loss: 1.0786711926367278
Validation loss: 2.899613148000199

Epoch: 6| Step: 11
Training loss: 1.3650968425058918
Validation loss: 2.7558584233531755

Epoch: 6| Step: 12
Training loss: 0.9419037703263171
Validation loss: 2.7754854476447335

Epoch: 6| Step: 13
Training loss: 1.3591049627677572
Validation loss: 2.702523916222786

Epoch: 177| Step: 0
Training loss: 1.2798180370334917
Validation loss: 2.73940961647196

Epoch: 6| Step: 1
Training loss: 1.2387329625441015
Validation loss: 2.824600397953073

Epoch: 6| Step: 2
Training loss: 0.9278157730533048
Validation loss: 2.8541995601197248

Epoch: 6| Step: 3
Training loss: 1.2795068466611546
Validation loss: 2.7188735729211038

Epoch: 6| Step: 4
Training loss: 1.0109122460349116
Validation loss: 2.870593135033144

Epoch: 6| Step: 5
Training loss: 1.2626703883851043
Validation loss: 2.837979354923995

Epoch: 6| Step: 6
Training loss: 0.8287200229568398
Validation loss: 2.9098504983267626

Epoch: 6| Step: 7
Training loss: 1.1356171713828456
Validation loss: 2.842306490338962

Epoch: 6| Step: 8
Training loss: 1.240999289294953
Validation loss: 2.9304696764021188

Epoch: 6| Step: 9
Training loss: 1.200848394736706
Validation loss: 2.910222657403934

Epoch: 6| Step: 10
Training loss: 2.7147041120226194
Validation loss: 2.831188502706965

Epoch: 6| Step: 11
Training loss: 0.9782992369273608
Validation loss: 2.833791433961692

Epoch: 6| Step: 12
Training loss: 1.5922880760524059
Validation loss: 2.878663893513524

Epoch: 6| Step: 13
Training loss: 1.2780993731851238
Validation loss: 2.8246573445734486

Epoch: 178| Step: 0
Training loss: 0.9791788377749403
Validation loss: 2.772531280753887

Epoch: 6| Step: 1
Training loss: 1.6710369826310119
Validation loss: 2.8150432814166795

Epoch: 6| Step: 2
Training loss: 1.3106154126865817
Validation loss: 2.8634283800821887

Epoch: 6| Step: 3
Training loss: 1.2607995337128381
Validation loss: 2.819356190866701

Epoch: 6| Step: 4
Training loss: 1.2374070990013988
Validation loss: 2.730498670742417

Epoch: 6| Step: 5
Training loss: 1.2707759448158464
Validation loss: 2.765725200439941

Epoch: 6| Step: 6
Training loss: 0.989501320636132
Validation loss: 2.8544256181031322

Epoch: 6| Step: 7
Training loss: 1.2857836087778085
Validation loss: 2.694939540545811

Epoch: 6| Step: 8
Training loss: 1.1109453289544815
Validation loss: 2.780599053604004

Epoch: 6| Step: 9
Training loss: 1.3510891300394623
Validation loss: 2.8156318464065393

Epoch: 6| Step: 10
Training loss: 1.4882931045500647
Validation loss: 2.842320260946995

Epoch: 6| Step: 11
Training loss: 0.82778715043732
Validation loss: 2.8506008390442488

Epoch: 6| Step: 12
Training loss: 1.4392261921482417
Validation loss: 2.7261269120349554

Epoch: 6| Step: 13
Training loss: 2.3288219867909374
Validation loss: 2.87354890165928

Epoch: 179| Step: 0
Training loss: 0.8286603960299704
Validation loss: 2.7794813468871276

Epoch: 6| Step: 1
Training loss: 1.1624150234871422
Validation loss: 2.7630878887375006

Epoch: 6| Step: 2
Training loss: 1.0318586691771932
Validation loss: 2.7491974526545473

Epoch: 6| Step: 3
Training loss: 1.4452478342797246
Validation loss: 2.7135825321881373

Epoch: 6| Step: 4
Training loss: 1.0526125241110935
Validation loss: 2.757392988275663

Epoch: 6| Step: 5
Training loss: 1.2745781219232888
Validation loss: 2.789893609745036

Epoch: 6| Step: 6
Training loss: 1.4208993603680422
Validation loss: 2.776005804940786

Epoch: 6| Step: 7
Training loss: 1.399739730006957
Validation loss: 2.894253242516561

Epoch: 6| Step: 8
Training loss: 1.0482660417737175
Validation loss: 2.738474738830506

Epoch: 6| Step: 9
Training loss: 1.3894738994479203
Validation loss: 2.705900072434482

Epoch: 6| Step: 10
Training loss: 2.305583818356912
Validation loss: 2.774830141682664

Epoch: 6| Step: 11
Training loss: 1.200462615724715
Validation loss: 2.8362864690335514

Epoch: 6| Step: 12
Training loss: 1.6859058338263693
Validation loss: 2.791674675621577

Epoch: 6| Step: 13
Training loss: 0.9313256713025909
Validation loss: 2.732778391871502

Epoch: 180| Step: 0
Training loss: 0.7714593424538497
Validation loss: 2.818103774286841

Epoch: 6| Step: 1
Training loss: 0.9403057709970071
Validation loss: 2.8642054961740007

Epoch: 6| Step: 2
Training loss: 1.6134623502080674
Validation loss: 2.711154954673887

Epoch: 6| Step: 3
Training loss: 1.0835614453308566
Validation loss: 2.794651276973157

Epoch: 6| Step: 4
Training loss: 0.9624430329940199
Validation loss: 2.830745234907367

Epoch: 6| Step: 5
Training loss: 1.603660586236498
Validation loss: 2.7935611407843237

Epoch: 6| Step: 6
Training loss: 1.5230098026183088
Validation loss: 2.808641499629412

Epoch: 6| Step: 7
Training loss: 0.9532704476865393
Validation loss: 2.812334154678785

Epoch: 6| Step: 8
Training loss: 1.1019343837373539
Validation loss: 2.803757239649997

Epoch: 6| Step: 9
Training loss: 1.093606285462668
Validation loss: 2.8650589334264014

Epoch: 6| Step: 10
Training loss: 1.0515169312351533
Validation loss: 2.829069201251746

Epoch: 6| Step: 11
Training loss: 2.124874560075754
Validation loss: 2.8774925152736244

Epoch: 6| Step: 12
Training loss: 1.0008607974216144
Validation loss: 2.757783646473142

Epoch: 6| Step: 13
Training loss: 0.7954097815712362
Validation loss: 2.8003463371976016

Epoch: 181| Step: 0
Training loss: 1.1416987760348984
Validation loss: 2.7662232249475744

Epoch: 6| Step: 1
Training loss: 1.2038322450739494
Validation loss: 2.765448081469531

Epoch: 6| Step: 2
Training loss: 0.9742560042268951
Validation loss: 2.792669789779761

Epoch: 6| Step: 3
Training loss: 1.1310249694914605
Validation loss: 2.7790908719259613

Epoch: 6| Step: 4
Training loss: 0.9947804788223329
Validation loss: 2.779401772280573

Epoch: 6| Step: 5
Training loss: 2.537374363687594
Validation loss: 2.751988255728014

Epoch: 6| Step: 6
Training loss: 0.9983731387889856
Validation loss: 2.9256271097607125

Epoch: 6| Step: 7
Training loss: 0.8292841805678227
Validation loss: 2.8114886408149036

Epoch: 6| Step: 8
Training loss: 0.9144071923492865
Validation loss: 2.816832292829866

Epoch: 6| Step: 9
Training loss: 0.8266538111651055
Validation loss: 2.788399796599196

Epoch: 6| Step: 10
Training loss: 1.8253544084452926
Validation loss: 2.6589784035845163

Epoch: 6| Step: 11
Training loss: 1.0107526253423909
Validation loss: 2.725370829836874

Epoch: 6| Step: 12
Training loss: 1.4591544791336626
Validation loss: 2.7186454957484143

Epoch: 6| Step: 13
Training loss: 1.2291215575825725
Validation loss: 2.759957665243133

Epoch: 182| Step: 0
Training loss: 2.102370209741808
Validation loss: 2.954266954736457

Epoch: 6| Step: 1
Training loss: 1.419300977287636
Validation loss: 2.76603279771068

Epoch: 6| Step: 2
Training loss: 1.2968401616943857
Validation loss: 2.70368659152195

Epoch: 6| Step: 3
Training loss: 1.0767103118632269
Validation loss: 2.8450060016499497

Epoch: 6| Step: 4
Training loss: 1.5917517907246552
Validation loss: 2.7442429710118152

Epoch: 6| Step: 5
Training loss: 1.161442926187777
Validation loss: 2.813968755306835

Epoch: 6| Step: 6
Training loss: 1.129454905095663
Validation loss: 2.775000447911865

Epoch: 6| Step: 7
Training loss: 1.1107519496477332
Validation loss: 2.8166273279847602

Epoch: 6| Step: 8
Training loss: 1.312588007564883
Validation loss: 2.87674092366756

Epoch: 6| Step: 9
Training loss: 1.3395909551914849
Validation loss: 2.7447605215738964

Epoch: 6| Step: 10
Training loss: 1.3125712511613628
Validation loss: 2.802801916923537

Epoch: 6| Step: 11
Training loss: 1.2379953914858528
Validation loss: 2.758525680527554

Epoch: 6| Step: 12
Training loss: 1.2213880402748558
Validation loss: 2.8412712388839862

Epoch: 6| Step: 13
Training loss: 0.7897408845743134
Validation loss: 2.797131162594679

Epoch: 183| Step: 0
Training loss: 1.229141051892991
Validation loss: 2.865905114602602

Epoch: 6| Step: 1
Training loss: 1.2649973502150214
Validation loss: 2.9386321246695393

Epoch: 6| Step: 2
Training loss: 1.5245263536677034
Validation loss: 2.7831290680251426

Epoch: 6| Step: 3
Training loss: 2.0449779542886546
Validation loss: 2.8596868362345393

Epoch: 6| Step: 4
Training loss: 0.8683368523783286
Validation loss: 2.793636044902663

Epoch: 6| Step: 5
Training loss: 0.900028710437176
Validation loss: 2.8045566708964493

Epoch: 6| Step: 6
Training loss: 1.3950304692540212
Validation loss: 2.9367156909339114

Epoch: 6| Step: 7
Training loss: 1.1243400757451074
Validation loss: 2.8593454133606695

Epoch: 6| Step: 8
Training loss: 1.0910990605613615
Validation loss: 2.9426446598332263

Epoch: 6| Step: 9
Training loss: 0.9668817039804753
Validation loss: 2.7966660576032747

Epoch: 6| Step: 10
Training loss: 1.41454673611132
Validation loss: 2.7623777848678817

Epoch: 6| Step: 11
Training loss: 0.969738486717032
Validation loss: 2.891268615552778

Epoch: 6| Step: 12
Training loss: 0.9147791864952224
Validation loss: 2.812125894602464

Epoch: 6| Step: 13
Training loss: 1.090945654133526
Validation loss: 2.7527025987727116

Epoch: 184| Step: 0
Training loss: 1.0001754606809934
Validation loss: 2.9262805303898074

Epoch: 6| Step: 1
Training loss: 1.1753061037870867
Validation loss: 2.837941270145742

Epoch: 6| Step: 2
Training loss: 1.5642658935978286
Validation loss: 2.8609773353568704

Epoch: 6| Step: 3
Training loss: 1.0697112239220634
Validation loss: 2.795526943293688

Epoch: 6| Step: 4
Training loss: 1.2183795268063815
Validation loss: 2.8801910970124984

Epoch: 6| Step: 5
Training loss: 0.7702534186743296
Validation loss: 2.7947526121212913

Epoch: 6| Step: 6
Training loss: 1.251062609105254
Validation loss: 2.887497194297055

Epoch: 6| Step: 7
Training loss: 1.2121872390388824
Validation loss: 2.870977130346605

Epoch: 6| Step: 8
Training loss: 2.1883020293104822
Validation loss: 2.83950322281438

Epoch: 6| Step: 9
Training loss: 0.7199725658435339
Validation loss: 2.864693370208435

Epoch: 6| Step: 10
Training loss: 1.3622632092139824
Validation loss: 2.8976089239176854

Epoch: 6| Step: 11
Training loss: 1.3351967525867812
Validation loss: 2.7637526357687934

Epoch: 6| Step: 12
Training loss: 1.3372347595464613
Validation loss: 2.779160303873979

Epoch: 6| Step: 13
Training loss: 1.0108682010252648
Validation loss: 2.9118938131735166

Epoch: 185| Step: 0
Training loss: 0.815765165657391
Validation loss: 2.807147124372849

Epoch: 6| Step: 1
Training loss: 1.383190900678032
Validation loss: 2.7418136559209407

Epoch: 6| Step: 2
Training loss: 1.060831555117555
Validation loss: 2.812738182437479

Epoch: 6| Step: 3
Training loss: 0.9606991914332189
Validation loss: 2.804981510262343

Epoch: 6| Step: 4
Training loss: 2.3804311390663906
Validation loss: 2.937522766349714

Epoch: 6| Step: 5
Training loss: 0.9793069955358392
Validation loss: 2.8574886666220842

Epoch: 6| Step: 6
Training loss: 1.8105468091584063
Validation loss: 2.8614066294380294

Epoch: 6| Step: 7
Training loss: 0.9101328703533857
Validation loss: 2.8334985338930556

Epoch: 6| Step: 8
Training loss: 1.473260325583526
Validation loss: 2.7823901607589896

Epoch: 6| Step: 9
Training loss: 1.3853236958373791
Validation loss: 2.80337061378314

Epoch: 6| Step: 10
Training loss: 1.1911477730950275
Validation loss: 2.874939365023981

Epoch: 6| Step: 11
Training loss: 0.7762646493435503
Validation loss: 2.7599306410445656

Epoch: 6| Step: 12
Training loss: 1.158783945534932
Validation loss: 2.9640023131050492

Epoch: 6| Step: 13
Training loss: 1.2178349116149703
Validation loss: 2.916016401736647

Epoch: 186| Step: 0
Training loss: 1.067034190658872
Validation loss: 2.8330438737175117

Epoch: 6| Step: 1
Training loss: 1.1215809152387515
Validation loss: 2.9061994377304576

Epoch: 6| Step: 2
Training loss: 0.96295927162835
Validation loss: 2.9470737227111443

Epoch: 6| Step: 3
Training loss: 1.2456305429169725
Validation loss: 2.959469420374578

Epoch: 6| Step: 4
Training loss: 1.2728873158435703
Validation loss: 2.8252868180411674

Epoch: 6| Step: 5
Training loss: 0.9701997921855565
Validation loss: 2.8516275267829148

Epoch: 6| Step: 6
Training loss: 0.9483542567617094
Validation loss: 2.7701022873594545

Epoch: 6| Step: 7
Training loss: 1.3431035638219582
Validation loss: 2.7634613855584917

Epoch: 6| Step: 8
Training loss: 1.0690012229434263
Validation loss: 2.8096980089204577

Epoch: 6| Step: 9
Training loss: 1.2273697838793347
Validation loss: 2.8617247218747406

Epoch: 6| Step: 10
Training loss: 2.259487599881835
Validation loss: 2.8331546212849945

Epoch: 6| Step: 11
Training loss: 1.2026757231259984
Validation loss: 2.7331123706622664

Epoch: 6| Step: 12
Training loss: 1.8004884295591006
Validation loss: 2.8517249631543184

Epoch: 6| Step: 13
Training loss: 1.0676550068758026
Validation loss: 2.741965318393236

Epoch: 187| Step: 0
Training loss: 1.3108907097887905
Validation loss: 2.8873795444305177

Epoch: 6| Step: 1
Training loss: 0.844451542003262
Validation loss: 2.9258079782240416

Epoch: 6| Step: 2
Training loss: 2.154100867421855
Validation loss: 2.7872707264100756

Epoch: 6| Step: 3
Training loss: 0.9363428285770742
Validation loss: 2.745783578965072

Epoch: 6| Step: 4
Training loss: 1.486647222004017
Validation loss: 2.878414117165044

Epoch: 6| Step: 5
Training loss: 1.2670208803788192
Validation loss: 2.8549091227331815

Epoch: 6| Step: 6
Training loss: 1.2682128633656222
Validation loss: 2.8552779565779702

Epoch: 6| Step: 7
Training loss: 1.139808362446792
Validation loss: 2.9053557055710346

Epoch: 6| Step: 8
Training loss: 1.0968689725443979
Validation loss: 2.7687706452138894

Epoch: 6| Step: 9
Training loss: 0.9914997751117399
Validation loss: 2.8021131795170517

Epoch: 6| Step: 10
Training loss: 1.1645808250022631
Validation loss: 2.895989535027418

Epoch: 6| Step: 11
Training loss: 1.1193666878907615
Validation loss: 2.962017469637515

Epoch: 6| Step: 12
Training loss: 1.1297704431415114
Validation loss: 2.781745566461849

Epoch: 6| Step: 13
Training loss: 1.150965807502144
Validation loss: 2.8505534019586816

Epoch: 188| Step: 0
Training loss: 0.9301892377225472
Validation loss: 2.86871222510639

Epoch: 6| Step: 1
Training loss: 1.4077833928392072
Validation loss: 2.905140654791278

Epoch: 6| Step: 2
Training loss: 2.35662863848632
Validation loss: 2.8938741345622545

Epoch: 6| Step: 3
Training loss: 1.0306947542716778
Validation loss: 2.7155517972116154

Epoch: 6| Step: 4
Training loss: 1.164356322617343
Validation loss: 2.7520108096211704

Epoch: 6| Step: 5
Training loss: 1.3550973872698582
Validation loss: 2.7733618067768315

Epoch: 6| Step: 6
Training loss: 1.3054563347107968
Validation loss: 2.8827376937464595

Epoch: 6| Step: 7
Training loss: 1.1838714978747586
Validation loss: 2.833866592788492

Epoch: 6| Step: 8
Training loss: 1.182747818703939
Validation loss: 2.8800692579321847

Epoch: 6| Step: 9
Training loss: 1.0411636218710436
Validation loss: 2.9409138071823593

Epoch: 6| Step: 10
Training loss: 0.9579242821537688
Validation loss: 2.9411041793634274

Epoch: 6| Step: 11
Training loss: 1.1125572125585836
Validation loss: 2.876950390225915

Epoch: 6| Step: 12
Training loss: 0.9105692241712895
Validation loss: 2.845499834781799

Epoch: 6| Step: 13
Training loss: 0.8952803494471104
Validation loss: 2.8466782776538464

Epoch: 189| Step: 0
Training loss: 1.1603809999546904
Validation loss: 2.9325417682418977

Epoch: 6| Step: 1
Training loss: 2.0045809734581415
Validation loss: 2.859819971700724

Epoch: 6| Step: 2
Training loss: 1.0664002135388904
Validation loss: 2.935000472190598

Epoch: 6| Step: 3
Training loss: 1.2443741080770931
Validation loss: 2.776529184634228

Epoch: 6| Step: 4
Training loss: 1.2564837148197743
Validation loss: 2.8725386048310493

Epoch: 6| Step: 5
Training loss: 1.3020726572234846
Validation loss: 2.8777144098812615

Epoch: 6| Step: 6
Training loss: 1.2703548635478197
Validation loss: 2.9700286520914885

Epoch: 6| Step: 7
Training loss: 1.2250664692965199
Validation loss: 2.8637477742761903

Epoch: 6| Step: 8
Training loss: 0.9950478541785089
Validation loss: 2.7903559772585997

Epoch: 6| Step: 9
Training loss: 0.9128626912601013
Validation loss: 2.9174585538969464

Epoch: 6| Step: 10
Training loss: 1.253107024180414
Validation loss: 2.8109604047711816

Epoch: 6| Step: 11
Training loss: 1.197508944356561
Validation loss: 2.821867439313401

Epoch: 6| Step: 12
Training loss: 1.1429012004840984
Validation loss: 2.9119245034271866

Epoch: 6| Step: 13
Training loss: 1.1481700767510379
Validation loss: 2.8065928767245616

Epoch: 190| Step: 0
Training loss: 1.2263588705933643
Validation loss: 2.933230963911126

Epoch: 6| Step: 1
Training loss: 1.3595028521166588
Validation loss: 2.7694202825915823

Epoch: 6| Step: 2
Training loss: 1.2082706248794068
Validation loss: 2.7310956054392532

Epoch: 6| Step: 3
Training loss: 0.9136561607258765
Validation loss: 2.869694610634527

Epoch: 6| Step: 4
Training loss: 1.017809762784131
Validation loss: 2.781081791052314

Epoch: 6| Step: 5
Training loss: 1.0745222737917977
Validation loss: 2.7817017549100136

Epoch: 6| Step: 6
Training loss: 0.9907376366728751
Validation loss: 2.7914810308729434

Epoch: 6| Step: 7
Training loss: 0.9124940310243793
Validation loss: 2.7771093714056905

Epoch: 6| Step: 8
Training loss: 1.352249720503753
Validation loss: 2.832662675994638

Epoch: 6| Step: 9
Training loss: 2.12857865079055
Validation loss: 2.964905575261354

Epoch: 6| Step: 10
Training loss: 0.7541022959964705
Validation loss: 2.896893702792656

Epoch: 6| Step: 11
Training loss: 1.0339398993138171
Validation loss: 2.9421699549063565

Epoch: 6| Step: 12
Training loss: 1.3302297631760294
Validation loss: 2.807707723291175

Epoch: 6| Step: 13
Training loss: 1.2650640209869775
Validation loss: 2.7665641468847095

Epoch: 191| Step: 0
Training loss: 2.0537840739028037
Validation loss: 2.904885029621484

Epoch: 6| Step: 1
Training loss: 1.0102706620166777
Validation loss: 2.8160639046449476

Epoch: 6| Step: 2
Training loss: 1.0262176956500781
Validation loss: 2.832008126701577

Epoch: 6| Step: 3
Training loss: 0.6719197990208527
Validation loss: 2.924548294640826

Epoch: 6| Step: 4
Training loss: 1.2763394014913814
Validation loss: 2.733647233298623

Epoch: 6| Step: 5
Training loss: 1.5678906340021457
Validation loss: 2.8085819787073674

Epoch: 6| Step: 6
Training loss: 1.3314427840645457
Validation loss: 2.86792054883576

Epoch: 6| Step: 7
Training loss: 1.3130134304896657
Validation loss: 2.8536659808607165

Epoch: 6| Step: 8
Training loss: 0.899586680660643
Validation loss: 2.7941737565488105

Epoch: 6| Step: 9
Training loss: 0.7013136101497971
Validation loss: 2.8893276155538743

Epoch: 6| Step: 10
Training loss: 1.0310694796611588
Validation loss: 2.836881580265311

Epoch: 6| Step: 11
Training loss: 0.9745086434393492
Validation loss: 2.6641788699630573

Epoch: 6| Step: 12
Training loss: 0.8724521258207883
Validation loss: 2.771785340692241

Epoch: 6| Step: 13
Training loss: 1.457163786804595
Validation loss: 2.8334467575333195

Epoch: 192| Step: 0
Training loss: 0.967595088780773
Validation loss: 2.7263492183829627

Epoch: 6| Step: 1
Training loss: 1.56923915942065
Validation loss: 2.810397853086111

Epoch: 6| Step: 2
Training loss: 1.2631929365534373
Validation loss: 2.8276668760623456

Epoch: 6| Step: 3
Training loss: 1.185188603823972
Validation loss: 2.860211734603455

Epoch: 6| Step: 4
Training loss: 0.9281657290272136
Validation loss: 2.8114350033263564

Epoch: 6| Step: 5
Training loss: 0.8427732606889842
Validation loss: 2.8804801734454313

Epoch: 6| Step: 6
Training loss: 0.9127758784850624
Validation loss: 2.743940888689394

Epoch: 6| Step: 7
Training loss: 1.1222851633030175
Validation loss: 2.7605903762766077

Epoch: 6| Step: 8
Training loss: 1.2412155475425797
Validation loss: 2.7631233812310296

Epoch: 6| Step: 9
Training loss: 0.8200675962080588
Validation loss: 2.826447651590958

Epoch: 6| Step: 10
Training loss: 0.7031506851591157
Validation loss: 2.8273140252110753

Epoch: 6| Step: 11
Training loss: 1.8944374297202644
Validation loss: 2.9081040624480647

Epoch: 6| Step: 12
Training loss: 1.0365256410657635
Validation loss: 2.8904673902828475

Epoch: 6| Step: 13
Training loss: 1.428816232823156
Validation loss: 2.81144034592051

Epoch: 193| Step: 0
Training loss: 1.180535775685877
Validation loss: 2.8844710061629666

Epoch: 6| Step: 1
Training loss: 1.2762192375518258
Validation loss: 2.9319063998457144

Epoch: 6| Step: 2
Training loss: 0.9231470351536807
Validation loss: 2.8677272583078026

Epoch: 6| Step: 3
Training loss: 1.372156931902183
Validation loss: 2.899647942362383

Epoch: 6| Step: 4
Training loss: 0.7709484315119597
Validation loss: 2.8461628553217517

Epoch: 6| Step: 5
Training loss: 1.97633251917893
Validation loss: 2.798427115598063

Epoch: 6| Step: 6
Training loss: 0.6878394026046767
Validation loss: 2.818305586285957

Epoch: 6| Step: 7
Training loss: 0.7056120227468474
Validation loss: 2.912777710364339

Epoch: 6| Step: 8
Training loss: 1.2444963410792313
Validation loss: 2.89425418984666

Epoch: 6| Step: 9
Training loss: 1.3260341567161202
Validation loss: 2.884744177901931

Epoch: 6| Step: 10
Training loss: 0.9854219712053454
Validation loss: 2.758617265691633

Epoch: 6| Step: 11
Training loss: 0.7269974093961669
Validation loss: 2.9159721274175405

Epoch: 6| Step: 12
Training loss: 0.9135046993128478
Validation loss: 2.9339896797149487

Epoch: 6| Step: 13
Training loss: 1.3840828356925228
Validation loss: 2.8000497399181006

Epoch: 194| Step: 0
Training loss: 1.0849563227709016
Validation loss: 2.699303551614725

Epoch: 6| Step: 1
Training loss: 0.812818244816983
Validation loss: 2.8147042855327338

Epoch: 6| Step: 2
Training loss: 1.3373966391011047
Validation loss: 3.002643599282969

Epoch: 6| Step: 3
Training loss: 1.0097362285297307
Validation loss: 2.801387421554999

Epoch: 6| Step: 4
Training loss: 0.9072918001007672
Validation loss: 2.794665509899218

Epoch: 6| Step: 5
Training loss: 2.152326026469677
Validation loss: 2.790069526503377

Epoch: 6| Step: 6
Training loss: 1.1353792773515514
Validation loss: 2.8421886056118786

Epoch: 6| Step: 7
Training loss: 1.1930476654072097
Validation loss: 2.788956185103517

Epoch: 6| Step: 8
Training loss: 1.0299011425613123
Validation loss: 2.8605925672383226

Epoch: 6| Step: 9
Training loss: 1.2593195635613443
Validation loss: 2.847437190389366

Epoch: 6| Step: 10
Training loss: 0.975856067730353
Validation loss: 2.805928387015152

Epoch: 6| Step: 11
Training loss: 1.4903817160225583
Validation loss: 2.815065132503332

Epoch: 6| Step: 12
Training loss: 1.0103093644154555
Validation loss: 2.849930694362028

Epoch: 6| Step: 13
Training loss: 1.023993421220508
Validation loss: 2.962405120360389

Epoch: 195| Step: 0
Training loss: 0.795804033355865
Validation loss: 2.823911869159782

Epoch: 6| Step: 1
Training loss: 0.8074008416627622
Validation loss: 2.8568761777739766

Epoch: 6| Step: 2
Training loss: 1.584092443427381
Validation loss: 2.7511832985944813

Epoch: 6| Step: 3
Training loss: 1.3268722909332809
Validation loss: 2.69913558721438

Epoch: 6| Step: 4
Training loss: 0.9041105206075226
Validation loss: 2.8572641999726294

Epoch: 6| Step: 5
Training loss: 1.1662094491857444
Validation loss: 2.8804032786907205

Epoch: 6| Step: 6
Training loss: 0.7920458078165935
Validation loss: 2.861944673357537

Epoch: 6| Step: 7
Training loss: 2.429991773583573
Validation loss: 2.8226308971244487

Epoch: 6| Step: 8
Training loss: 1.1707753935264855
Validation loss: 2.748653775933967

Epoch: 6| Step: 9
Training loss: 1.1289069363813062
Validation loss: 2.744293042132454

Epoch: 6| Step: 10
Training loss: 0.9732126077210046
Validation loss: 2.915614201620098

Epoch: 6| Step: 11
Training loss: 0.851035033487705
Validation loss: 2.93315213973173

Epoch: 6| Step: 12
Training loss: 0.9092380328771437
Validation loss: 2.8360721076286817

Epoch: 6| Step: 13
Training loss: 0.8631983238195102
Validation loss: 2.914743216116929

Epoch: 196| Step: 0
Training loss: 0.970101490512006
Validation loss: 2.821181736611665

Epoch: 6| Step: 1
Training loss: 0.8451083164088912
Validation loss: 2.9266153325710724

Epoch: 6| Step: 2
Training loss: 0.6982573821008448
Validation loss: 2.8251858467253785

Epoch: 6| Step: 3
Training loss: 0.9385170188543521
Validation loss: 2.8503616940050978

Epoch: 6| Step: 4
Training loss: 1.3786121951809138
Validation loss: 2.904866042864928

Epoch: 6| Step: 5
Training loss: 0.7727033039572839
Validation loss: 2.8167189143675206

Epoch: 6| Step: 6
Training loss: 1.4108441225838417
Validation loss: 2.810933248910027

Epoch: 6| Step: 7
Training loss: 1.2334155446223072
Validation loss: 2.8173347737906957

Epoch: 6| Step: 8
Training loss: 1.0439287546555813
Validation loss: 2.892563123747816

Epoch: 6| Step: 9
Training loss: 2.012104834386864
Validation loss: 3.0147686073367357

Epoch: 6| Step: 10
Training loss: 0.9147722472044743
Validation loss: 2.742130014481775

Epoch: 6| Step: 11
Training loss: 0.9875168690266732
Validation loss: 2.940440674213014

Epoch: 6| Step: 12
Training loss: 0.9849556315542194
Validation loss: 2.8325102302386727

Epoch: 6| Step: 13
Training loss: 1.1649868770400538
Validation loss: 2.8296068570072905

Epoch: 197| Step: 0
Training loss: 1.4059073136602112
Validation loss: 2.7647210204490213

Epoch: 6| Step: 1
Training loss: 1.2760846292957524
Validation loss: 2.8380619495307333

Epoch: 6| Step: 2
Training loss: 0.7911092443755208
Validation loss: 2.924911661797541

Epoch: 6| Step: 3
Training loss: 1.0519365957429743
Validation loss: 2.8338486866593318

Epoch: 6| Step: 4
Training loss: 1.1410642326890512
Validation loss: 2.802006466365471

Epoch: 6| Step: 5
Training loss: 1.255366440730632
Validation loss: 2.8950796495855617

Epoch: 6| Step: 6
Training loss: 0.7115960895851168
Validation loss: 2.9220476286511894

Epoch: 6| Step: 7
Training loss: 1.2859762990111236
Validation loss: 2.9568079163214507

Epoch: 6| Step: 8
Training loss: 0.9583406171660115
Validation loss: 2.9210022831665956

Epoch: 6| Step: 9
Training loss: 0.7040045005995853
Validation loss: 2.880387620824061

Epoch: 6| Step: 10
Training loss: 1.6659646781117001
Validation loss: 2.8282835829867627

Epoch: 6| Step: 11
Training loss: 2.244679836901118
Validation loss: 2.8193165437431915

Epoch: 6| Step: 12
Training loss: 0.8244264892277794
Validation loss: 2.8404288688294237

Epoch: 6| Step: 13
Training loss: 0.9063056731388173
Validation loss: 2.879637585195455

Epoch: 198| Step: 0
Training loss: 1.0160567906307227
Validation loss: 2.771876939316293

Epoch: 6| Step: 1
Training loss: 0.5314938041885706
Validation loss: 2.864956354071748

Epoch: 6| Step: 2
Training loss: 1.372622862633984
Validation loss: 2.8802775236146347

Epoch: 6| Step: 3
Training loss: 0.8679862939965451
Validation loss: 2.884611607329023

Epoch: 6| Step: 4
Training loss: 2.0490581721495325
Validation loss: 2.959698917073003

Epoch: 6| Step: 5
Training loss: 1.5124513098075503
Validation loss: 2.8210908514906063

Epoch: 6| Step: 6
Training loss: 1.415093736138605
Validation loss: 2.982493488190612

Epoch: 6| Step: 7
Training loss: 0.9596034147740071
Validation loss: 2.8694699494208105

Epoch: 6| Step: 8
Training loss: 1.1216135979653907
Validation loss: 3.0840771439498695

Epoch: 6| Step: 9
Training loss: 1.0010752857185077
Validation loss: 2.9204859160096905

Epoch: 6| Step: 10
Training loss: 1.0031774822065507
Validation loss: 2.8784056547040104

Epoch: 6| Step: 11
Training loss: 1.1720489372868625
Validation loss: 2.860851983390071

Epoch: 6| Step: 12
Training loss: 0.8567089340591038
Validation loss: 2.8353801211081437

Epoch: 6| Step: 13
Training loss: 1.2764922404010441
Validation loss: 3.007637646369342

Epoch: 199| Step: 0
Training loss: 1.2093899590407406
Validation loss: 2.9576881985777166

Epoch: 6| Step: 1
Training loss: 1.18887009135406
Validation loss: 2.9461783461124424

Epoch: 6| Step: 2
Training loss: 0.5699101949518526
Validation loss: 2.8571257091189275

Epoch: 6| Step: 3
Training loss: 1.0983249351593312
Validation loss: 2.8374086317680782

Epoch: 6| Step: 4
Training loss: 0.9671400289641076
Validation loss: 2.822807384970437

Epoch: 6| Step: 5
Training loss: 0.9397785471735675
Validation loss: 2.760700000161282

Epoch: 6| Step: 6
Training loss: 1.6303060175317303
Validation loss: 2.8055569037086934

Epoch: 6| Step: 7
Training loss: 0.9138541024810747
Validation loss: 2.7024933181665975

Epoch: 6| Step: 8
Training loss: 1.1066454767779939
Validation loss: 2.911768851784414

Epoch: 6| Step: 9
Training loss: 2.114747615752887
Validation loss: 2.835323775257917

Epoch: 6| Step: 10
Training loss: 1.0519155739967416
Validation loss: 2.771807568635559

Epoch: 6| Step: 11
Training loss: 1.2644803557764959
Validation loss: 2.9149160081203647

Epoch: 6| Step: 12
Training loss: 0.7482520237980375
Validation loss: 2.939823503278396

Epoch: 6| Step: 13
Training loss: 1.195661954971685
Validation loss: 2.8490245655643633

Epoch: 200| Step: 0
Training loss: 1.4942567867426813
Validation loss: 2.91521667586867

Epoch: 6| Step: 1
Training loss: 1.1727181008513219
Validation loss: 2.888051869002337

Epoch: 6| Step: 2
Training loss: 1.2387054390692176
Validation loss: 2.7796983998488605

Epoch: 6| Step: 3
Training loss: 0.98640009551392
Validation loss: 2.8754050342689537

Epoch: 6| Step: 4
Training loss: 0.8959837868492331
Validation loss: 2.9139521137292173

Epoch: 6| Step: 5
Training loss: 0.8359533290612163
Validation loss: 2.92039354272099

Epoch: 6| Step: 6
Training loss: 0.9085819889793281
Validation loss: 2.8631804042125166

Epoch: 6| Step: 7
Training loss: 1.4723350113823237
Validation loss: 2.965389745912665

Epoch: 6| Step: 8
Training loss: 2.2062604520296194
Validation loss: 2.95675979100613

Epoch: 6| Step: 9
Training loss: 0.877107194649934
Validation loss: 2.8735705844247614

Epoch: 6| Step: 10
Training loss: 1.0822614844883305
Validation loss: 2.932576876513692

Epoch: 6| Step: 11
Training loss: 0.6802695840205646
Validation loss: 2.9381750021166804

Epoch: 6| Step: 12
Training loss: 1.1946285011118059
Validation loss: 2.806449938521253

Epoch: 6| Step: 13
Training loss: 1.1312902285341095
Validation loss: 2.82514657678378

Epoch: 201| Step: 0
Training loss: 0.7771751566030564
Validation loss: 2.903982050066067

Epoch: 6| Step: 1
Training loss: 0.9936593920108592
Validation loss: 2.8037649920319687

Epoch: 6| Step: 2
Training loss: 0.968666073024679
Validation loss: 2.8731069275444807

Epoch: 6| Step: 3
Training loss: 0.9789120295689632
Validation loss: 2.8984070645197018

Epoch: 6| Step: 4
Training loss: 1.0968213690446391
Validation loss: 2.7617905466692196

Epoch: 6| Step: 5
Training loss: 0.7506826790558041
Validation loss: 2.8777432001050287

Epoch: 6| Step: 6
Training loss: 0.8706695139418756
Validation loss: 2.884095744580239

Epoch: 6| Step: 7
Training loss: 1.2058373135648432
Validation loss: 2.860216221983399

Epoch: 6| Step: 8
Training loss: 2.0098020440927034
Validation loss: 2.8552935155561876

Epoch: 6| Step: 9
Training loss: 0.7071737915005002
Validation loss: 2.903395546473968

Epoch: 6| Step: 10
Training loss: 1.3204968566394906
Validation loss: 2.93102256364314

Epoch: 6| Step: 11
Training loss: 1.3778272086466075
Validation loss: 2.8225852846878055

Epoch: 6| Step: 12
Training loss: 1.0277234090280187
Validation loss: 2.8681665008572654

Epoch: 6| Step: 13
Training loss: 1.2171256170836395
Validation loss: 2.9008924125113396

Epoch: 202| Step: 0
Training loss: 0.8019600728101448
Validation loss: 2.8650941058154844

Epoch: 6| Step: 1
Training loss: 0.9076682207549771
Validation loss: 2.8124624037878867

Epoch: 6| Step: 2
Training loss: 1.1100359814628586
Validation loss: 2.920765521631387

Epoch: 6| Step: 3
Training loss: 0.8011236435736906
Validation loss: 2.9302857055285205

Epoch: 6| Step: 4
Training loss: 1.370420546061769
Validation loss: 2.7859397667094514

Epoch: 6| Step: 5
Training loss: 2.1266461896159656
Validation loss: 2.8520294364553243

Epoch: 6| Step: 6
Training loss: 1.187703165443328
Validation loss: 2.912002148733988

Epoch: 6| Step: 7
Training loss: 1.0167444954979428
Validation loss: 2.766477852050661

Epoch: 6| Step: 8
Training loss: 1.2489880280176706
Validation loss: 2.9667167795070624

Epoch: 6| Step: 9
Training loss: 1.1160185774142235
Validation loss: 2.8616404218660705

Epoch: 6| Step: 10
Training loss: 0.8533360272665516
Validation loss: 2.9281661631575613

Epoch: 6| Step: 11
Training loss: 0.9247141293233027
Validation loss: 2.8319324555100907

Epoch: 6| Step: 12
Training loss: 1.087328178161603
Validation loss: 2.899981790792364

Epoch: 6| Step: 13
Training loss: 1.1795957415938843
Validation loss: 2.8638055242480953

Epoch: 203| Step: 0
Training loss: 1.9754111212160614
Validation loss: 2.862158651974639

Epoch: 6| Step: 1
Training loss: 0.9221842618838227
Validation loss: 3.0244906593044405

Epoch: 6| Step: 2
Training loss: 1.1076948848642423
Validation loss: 2.9102479514879502

Epoch: 6| Step: 3
Training loss: 1.0946118365292707
Validation loss: 2.903834320017688

Epoch: 6| Step: 4
Training loss: 1.2501604930842392
Validation loss: 2.9572090421347053

Epoch: 6| Step: 5
Training loss: 1.0426173386072208
Validation loss: 2.8237653256636914

Epoch: 6| Step: 6
Training loss: 1.0386380354012428
Validation loss: 2.8547459638650396

Epoch: 6| Step: 7
Training loss: 1.152801939827255
Validation loss: 2.8704605892204444

Epoch: 6| Step: 8
Training loss: 1.2124341514246588
Validation loss: 2.8685221878717657

Epoch: 6| Step: 9
Training loss: 1.0841149053940426
Validation loss: 2.878751214872328

Epoch: 6| Step: 10
Training loss: 0.8297207769987176
Validation loss: 2.8508919541495463

Epoch: 6| Step: 11
Training loss: 0.833227345561235
Validation loss: 2.8608546363251497

Epoch: 6| Step: 12
Training loss: 1.2503500924993654
Validation loss: 2.9181628386102574

Epoch: 6| Step: 13
Training loss: 0.7185403684001759
Validation loss: 2.8348916667622834

Epoch: 204| Step: 0
Training loss: 1.476258342438333
Validation loss: 2.7977372870150874

Epoch: 6| Step: 1
Training loss: 1.0853488342020212
Validation loss: 2.8947305752262014

Epoch: 6| Step: 2
Training loss: 0.6703225319562942
Validation loss: 2.818283633427991

Epoch: 6| Step: 3
Training loss: 1.0501770778475532
Validation loss: 2.9231967078600145

Epoch: 6| Step: 4
Training loss: 1.1160428245148675
Validation loss: 2.877844868024805

Epoch: 6| Step: 5
Training loss: 1.2280417591257544
Validation loss: 2.8639095600622486

Epoch: 6| Step: 6
Training loss: 1.9903076278188458
Validation loss: 2.867094629153945

Epoch: 6| Step: 7
Training loss: 0.7979256678406365
Validation loss: 2.80879173235356

Epoch: 6| Step: 8
Training loss: 1.2448130756064075
Validation loss: 2.912846629481636

Epoch: 6| Step: 9
Training loss: 0.9734590580054793
Validation loss: 2.799350197357046

Epoch: 6| Step: 10
Training loss: 1.085449328574837
Validation loss: 2.771573969204035

Epoch: 6| Step: 11
Training loss: 1.129536594637322
Validation loss: 2.8564039404500323

Epoch: 6| Step: 12
Training loss: 0.6631490820593536
Validation loss: 2.9247528156484672

Epoch: 6| Step: 13
Training loss: 0.9113061541718401
Validation loss: 2.9601894698632756

Epoch: 205| Step: 0
Training loss: 0.6944968979946807
Validation loss: 2.85288696187428

Epoch: 6| Step: 1
Training loss: 0.9142017421467133
Validation loss: 2.9057048026444257

Epoch: 6| Step: 2
Training loss: 0.4694893093070103
Validation loss: 2.848073516262073

Epoch: 6| Step: 3
Training loss: 2.3037492296918223
Validation loss: 2.8484853645972317

Epoch: 6| Step: 4
Training loss: 1.3398375219083565
Validation loss: 2.9064676688659143

Epoch: 6| Step: 5
Training loss: 0.8075095754238739
Validation loss: 2.8843715900526354

Epoch: 6| Step: 6
Training loss: 0.7034107051645402
Validation loss: 2.7370931430438965

Epoch: 6| Step: 7
Training loss: 0.8356244222885794
Validation loss: 2.8603608146562127

Epoch: 6| Step: 8
Training loss: 1.0893422275150546
Validation loss: 2.866584762985269

Epoch: 6| Step: 9
Training loss: 1.192709988033474
Validation loss: 2.7783137620291116

Epoch: 6| Step: 10
Training loss: 0.8175051653404255
Validation loss: 2.9371913585440654

Epoch: 6| Step: 11
Training loss: 0.8402833010139078
Validation loss: 3.0230772475731937

Epoch: 6| Step: 12
Training loss: 1.074000887886405
Validation loss: 2.9885127889984893

Epoch: 6| Step: 13
Training loss: 1.228675286087033
Validation loss: 2.9433825550377404

Epoch: 206| Step: 0
Training loss: 1.007403682619914
Validation loss: 2.8893124874019023

Epoch: 6| Step: 1
Training loss: 0.8841347034320428
Validation loss: 2.9105959156918604

Epoch: 6| Step: 2
Training loss: 0.8069739588207563
Validation loss: 2.9680977824346084

Epoch: 6| Step: 3
Training loss: 0.9807180566440362
Validation loss: 3.0437028331613853

Epoch: 6| Step: 4
Training loss: 1.375633527286484
Validation loss: 2.8165815054605225

Epoch: 6| Step: 5
Training loss: 0.9495423946508111
Validation loss: 2.842672835692546

Epoch: 6| Step: 6
Training loss: 1.02274211525984
Validation loss: 2.8261173069907266

Epoch: 6| Step: 7
Training loss: 1.0206960988085763
Validation loss: 2.7463583531604914

Epoch: 6| Step: 8
Training loss: 1.260746064242926
Validation loss: 2.8178179867057045

Epoch: 6| Step: 9
Training loss: 2.0012785877709183
Validation loss: 2.928139632876164

Epoch: 6| Step: 10
Training loss: 0.5520800704379798
Validation loss: 2.8799088490817146

Epoch: 6| Step: 11
Training loss: 0.8605836172134504
Validation loss: 2.9408798253301156

Epoch: 6| Step: 12
Training loss: 1.544900655299318
Validation loss: 2.8778126544712785

Epoch: 6| Step: 13
Training loss: 0.8496986780697547
Validation loss: 3.0295858632707025

Epoch: 207| Step: 0
Training loss: 0.9754798686395808
Validation loss: 2.9872930750351485

Epoch: 6| Step: 1
Training loss: 1.0123536463326044
Validation loss: 2.985018422801016

Epoch: 6| Step: 2
Training loss: 1.044509549653775
Validation loss: 2.8237272602599357

Epoch: 6| Step: 3
Training loss: 0.9749152672457584
Validation loss: 2.888623604963327

Epoch: 6| Step: 4
Training loss: 1.1370776157275007
Validation loss: 2.8125599748786563

Epoch: 6| Step: 5
Training loss: 1.2605943896048202
Validation loss: 2.917404113366237

Epoch: 6| Step: 6
Training loss: 0.642154635217255
Validation loss: 2.9202660127099573

Epoch: 6| Step: 7
Training loss: 0.7122053222970507
Validation loss: 2.8558791701021646

Epoch: 6| Step: 8
Training loss: 1.2326526456014493
Validation loss: 2.8907512877774644

Epoch: 6| Step: 9
Training loss: 0.9419174705706012
Validation loss: 2.9566861568168363

Epoch: 6| Step: 10
Training loss: 1.3664142274705484
Validation loss: 2.9091934693791055

Epoch: 6| Step: 11
Training loss: 2.2016925889750496
Validation loss: 2.860470254557714

Epoch: 6| Step: 12
Training loss: 1.0479073060807673
Validation loss: 2.875197735496419

Epoch: 6| Step: 13
Training loss: 0.8267070218459999
Validation loss: 2.7751398727174013

Epoch: 208| Step: 0
Training loss: 1.1943650823048628
Validation loss: 2.91407008165834

Epoch: 6| Step: 1
Training loss: 0.8653432118871279
Validation loss: 3.036331139196623

Epoch: 6| Step: 2
Training loss: 0.9337563153708272
Validation loss: 2.9653974777429126

Epoch: 6| Step: 3
Training loss: 2.060703419890236
Validation loss: 2.965424639489367

Epoch: 6| Step: 4
Training loss: 0.5357465898901016
Validation loss: 2.9250854968756013

Epoch: 6| Step: 5
Training loss: 1.503416462197808
Validation loss: 2.955436689831665

Epoch: 6| Step: 6
Training loss: 1.0606120108875134
Validation loss: 2.8477169775189175

Epoch: 6| Step: 7
Training loss: 1.240907597485335
Validation loss: 2.854084909386544

Epoch: 6| Step: 8
Training loss: 0.8108394600289461
Validation loss: 2.8786650806379637

Epoch: 6| Step: 9
Training loss: 0.8069382827255073
Validation loss: 2.987326422507628

Epoch: 6| Step: 10
Training loss: 0.907246140842634
Validation loss: 2.903916081509468

Epoch: 6| Step: 11
Training loss: 1.3054067490817165
Validation loss: 2.923266638705809

Epoch: 6| Step: 12
Training loss: 0.7401389510919709
Validation loss: 2.8722558262661027

Epoch: 6| Step: 13
Training loss: 0.8642722608145226
Validation loss: 2.851343294540866

Epoch: 209| Step: 0
Training loss: 0.8179368268827343
Validation loss: 2.891007640360102

Epoch: 6| Step: 1
Training loss: 0.7574218844432938
Validation loss: 2.90492601213984

Epoch: 6| Step: 2
Training loss: 1.0732644020676385
Validation loss: 2.9773734682552364

Epoch: 6| Step: 3
Training loss: 1.1312319548627128
Validation loss: 2.9906044167740706

Epoch: 6| Step: 4
Training loss: 1.3233856461239877
Validation loss: 2.9279449977529177

Epoch: 6| Step: 5
Training loss: 0.616077245364954
Validation loss: 2.9506909870444566

Epoch: 6| Step: 6
Training loss: 2.1031670666776963
Validation loss: 2.7836975229630254

Epoch: 6| Step: 7
Training loss: 1.1286505175207107
Validation loss: 2.969600796506113

Epoch: 6| Step: 8
Training loss: 0.8228350047544684
Validation loss: 2.9519139923507742

Epoch: 6| Step: 9
Training loss: 1.0207960096010702
Validation loss: 2.884832665093385

Epoch: 6| Step: 10
Training loss: 0.846793583971673
Validation loss: 2.7496699872105723

Epoch: 6| Step: 11
Training loss: 0.9844735111414116
Validation loss: 2.944458963450337

Epoch: 6| Step: 12
Training loss: 0.9215935099530517
Validation loss: 2.933608365350542

Epoch: 6| Step: 13
Training loss: 0.5637308006654386
Validation loss: 2.7876143912434843

Epoch: 210| Step: 0
Training loss: 0.8835626301568027
Validation loss: 2.9258183136151303

Epoch: 6| Step: 1
Training loss: 0.8197851756774814
Validation loss: 2.941862100551709

Epoch: 6| Step: 2
Training loss: 1.0145200734453326
Validation loss: 2.8914206913227782

Epoch: 6| Step: 3
Training loss: 0.7181670686037974
Validation loss: 2.89467386777267

Epoch: 6| Step: 4
Training loss: 1.4206252422072425
Validation loss: 2.904228847573196

Epoch: 6| Step: 5
Training loss: 1.0545975258207678
Validation loss: 2.8905659575060016

Epoch: 6| Step: 6
Training loss: 1.0227176376813694
Validation loss: 2.9815016890192694

Epoch: 6| Step: 7
Training loss: 0.8918946568889857
Validation loss: 2.898979636710421

Epoch: 6| Step: 8
Training loss: 1.0023027371514284
Validation loss: 2.997008739745081

Epoch: 6| Step: 9
Training loss: 0.6207348728403108
Validation loss: 2.9486331316169156

Epoch: 6| Step: 10
Training loss: 0.7880504652168252
Validation loss: 2.86597144508911

Epoch: 6| Step: 11
Training loss: 2.432865921835383
Validation loss: 2.789476365727699

Epoch: 6| Step: 12
Training loss: 0.942241472308404
Validation loss: 2.728364190696318

Epoch: 6| Step: 13
Training loss: 0.8083609646731501
Validation loss: 2.8845828167796737

Epoch: 211| Step: 0
Training loss: 0.8483478871154464
Validation loss: 2.8991284091052045

Epoch: 6| Step: 1
Training loss: 0.72853305171956
Validation loss: 2.8782041220570362

Epoch: 6| Step: 2
Training loss: 2.158471773437984
Validation loss: 2.949780300817266

Epoch: 6| Step: 3
Training loss: 1.2315063945435427
Validation loss: 2.7335129605173196

Epoch: 6| Step: 4
Training loss: 1.074841627386997
Validation loss: 3.03280806727006

Epoch: 6| Step: 5
Training loss: 1.056796303948661
Validation loss: 2.8707270866041474

Epoch: 6| Step: 6
Training loss: 1.1311831101510936
Validation loss: 2.871070138570358

Epoch: 6| Step: 7
Training loss: 0.8776131166328144
Validation loss: 2.927367367431563

Epoch: 6| Step: 8
Training loss: 0.921536205559523
Validation loss: 2.9762166140180604

Epoch: 6| Step: 9
Training loss: 1.010360690005045
Validation loss: 3.0205649070305762

Epoch: 6| Step: 10
Training loss: 0.9454047733386518
Validation loss: 2.8361231215078733

Epoch: 6| Step: 11
Training loss: 0.8784545755100764
Validation loss: 2.930305070000124

Epoch: 6| Step: 12
Training loss: 1.2555557762040777
Validation loss: 2.922308456174323

Epoch: 6| Step: 13
Training loss: 0.7162632840108043
Validation loss: 2.879067791254488

Epoch: 212| Step: 0
Training loss: 2.2194556605066653
Validation loss: 2.8980277046816965

Epoch: 6| Step: 1
Training loss: 0.9751049914439928
Validation loss: 2.967313653247164

Epoch: 6| Step: 2
Training loss: 0.7319810278080665
Validation loss: 3.009501154108265

Epoch: 6| Step: 3
Training loss: 0.670350452051176
Validation loss: 2.991491935766718

Epoch: 6| Step: 4
Training loss: 1.42121704304915
Validation loss: 2.886824864427524

Epoch: 6| Step: 5
Training loss: 0.859489606671298
Validation loss: 2.8848741804087297

Epoch: 6| Step: 6
Training loss: 0.966625930623882
Validation loss: 2.859851456988354

Epoch: 6| Step: 7
Training loss: 0.7429312743674394
Validation loss: 3.029793838541817

Epoch: 6| Step: 8
Training loss: 0.9396997076623731
Validation loss: 2.9801177571859383

Epoch: 6| Step: 9
Training loss: 0.7521826455720743
Validation loss: 2.9360707235029704

Epoch: 6| Step: 10
Training loss: 0.9590058489413297
Validation loss: 2.88718852004907

Epoch: 6| Step: 11
Training loss: 1.5205336062008163
Validation loss: 2.9661701838850507

Epoch: 6| Step: 12
Training loss: 0.7971996319310113
Validation loss: 2.9239424600545196

Epoch: 6| Step: 13
Training loss: 0.8866764680301575
Validation loss: 2.8937567714230195

Epoch: 213| Step: 0
Training loss: 0.6325198780298571
Validation loss: 2.8985761419076783

Epoch: 6| Step: 1
Training loss: 0.6999084651227445
Validation loss: 3.014782381022131

Epoch: 6| Step: 2
Training loss: 1.356177592651965
Validation loss: 2.875646518493278

Epoch: 6| Step: 3
Training loss: 1.1658719228248073
Validation loss: 2.9353123696188184

Epoch: 6| Step: 4
Training loss: 1.0711091689454493
Validation loss: 2.925511876172292

Epoch: 6| Step: 5
Training loss: 0.975617401562658
Validation loss: 2.939523973593336

Epoch: 6| Step: 6
Training loss: 0.725222798347228
Validation loss: 2.968681923604407

Epoch: 6| Step: 7
Training loss: 0.6481476101292795
Validation loss: 2.912354228528909

Epoch: 6| Step: 8
Training loss: 2.105512799030465
Validation loss: 2.9896332385497835

Epoch: 6| Step: 9
Training loss: 0.8149924562257211
Validation loss: 2.9339342728160753

Epoch: 6| Step: 10
Training loss: 0.9434998843986954
Validation loss: 3.0468876634644357

Epoch: 6| Step: 11
Training loss: 1.3058590226282756
Validation loss: 2.9193434466616366

Epoch: 6| Step: 12
Training loss: 1.1586896572429384
Validation loss: 2.818387812812212

Epoch: 6| Step: 13
Training loss: 0.8053402151564797
Validation loss: 2.8126329743774785

Epoch: 214| Step: 0
Training loss: 1.0055025819719683
Validation loss: 2.9085137496193925

Epoch: 6| Step: 1
Training loss: 0.9781171097604769
Validation loss: 2.9030639247814003

Epoch: 6| Step: 2
Training loss: 0.7141495966642496
Validation loss: 3.0587952970874754

Epoch: 6| Step: 3
Training loss: 0.7039761795381408
Validation loss: 2.827059972034505

Epoch: 6| Step: 4
Training loss: 2.0625727091602153
Validation loss: 2.8390487124707136

Epoch: 6| Step: 5
Training loss: 0.841877448879155
Validation loss: 2.8115800977931173

Epoch: 6| Step: 6
Training loss: 0.7916970790910822
Validation loss: 2.8960478906711176

Epoch: 6| Step: 7
Training loss: 0.7445938852548366
Validation loss: 2.9124303479249916

Epoch: 6| Step: 8
Training loss: 1.090203940097601
Validation loss: 3.0121433009946132

Epoch: 6| Step: 9
Training loss: 0.8331955120241417
Validation loss: 2.883525074571906

Epoch: 6| Step: 10
Training loss: 1.3845369610218237
Validation loss: 2.789040138874475

Epoch: 6| Step: 11
Training loss: 0.8445634100028399
Validation loss: 2.9210811495349764

Epoch: 6| Step: 12
Training loss: 0.595052294797185
Validation loss: 2.9710504018299706

Epoch: 6| Step: 13
Training loss: 1.0805507405382717
Validation loss: 2.9339210270128278

Epoch: 215| Step: 0
Training loss: 0.9176725518434783
Validation loss: 2.8822940611797754

Epoch: 6| Step: 1
Training loss: 1.429377621280083
Validation loss: 2.9365691204807636

Epoch: 6| Step: 2
Training loss: 0.5871917524686253
Validation loss: 2.900869961399306

Epoch: 6| Step: 3
Training loss: 0.7537468460042325
Validation loss: 2.9104545150258265

Epoch: 6| Step: 4
Training loss: 1.0502921742427842
Validation loss: 2.8997903495950204

Epoch: 6| Step: 5
Training loss: 0.5380299395381134
Validation loss: 2.925026443557539

Epoch: 6| Step: 6
Training loss: 0.8425790644372081
Validation loss: 2.917063145710462

Epoch: 6| Step: 7
Training loss: 1.1938471569848137
Validation loss: 2.9190858254295216

Epoch: 6| Step: 8
Training loss: 1.07107066012035
Validation loss: 3.043584158241721

Epoch: 6| Step: 9
Training loss: 1.08624740679292
Validation loss: 2.9359474543331157

Epoch: 6| Step: 10
Training loss: 2.2312732855599546
Validation loss: 2.8516235902417377

Epoch: 6| Step: 11
Training loss: 1.2001831451370382
Validation loss: 2.882056436060688

Epoch: 6| Step: 12
Training loss: 0.9470859632498906
Validation loss: 2.9517282348219798

Epoch: 6| Step: 13
Training loss: 0.8349782841536897
Validation loss: 3.0490574380876208

Epoch: 216| Step: 0
Training loss: 0.7659713195406576
Validation loss: 2.869254868018012

Epoch: 6| Step: 1
Training loss: 1.2512170588742662
Validation loss: 3.004129878509776

Epoch: 6| Step: 2
Training loss: 0.9522401423185662
Validation loss: 2.9397425377060578

Epoch: 6| Step: 3
Training loss: 2.175208518019087
Validation loss: 2.923771411088337

Epoch: 6| Step: 4
Training loss: 0.7019010699654085
Validation loss: 2.9272277000004183

Epoch: 6| Step: 5
Training loss: 0.7717258123865183
Validation loss: 2.9364018382826194

Epoch: 6| Step: 6
Training loss: 0.8690382993662482
Validation loss: 2.9120864099713826

Epoch: 6| Step: 7
Training loss: 1.343458898195984
Validation loss: 2.863442881741924

Epoch: 6| Step: 8
Training loss: 0.8126433686165334
Validation loss: 2.9815271447341853

Epoch: 6| Step: 9
Training loss: 0.8031377219888347
Validation loss: 2.8802514006905384

Epoch: 6| Step: 10
Training loss: 1.2561660321010386
Validation loss: 2.903307146011952

Epoch: 6| Step: 11
Training loss: 1.2658816418816776
Validation loss: 2.8567768654401737

Epoch: 6| Step: 12
Training loss: 0.6354789364638247
Validation loss: 2.766521330160524

Epoch: 6| Step: 13
Training loss: 0.9672560092900067
Validation loss: 2.9610021914592424

Epoch: 217| Step: 0
Training loss: 0.952999169220217
Validation loss: 2.9757663466378386

Epoch: 6| Step: 1
Training loss: 1.9800848052618991
Validation loss: 2.98920903980803

Epoch: 6| Step: 2
Training loss: 0.7709946248848025
Validation loss: 2.933150852733482

Epoch: 6| Step: 3
Training loss: 1.0582895440081175
Validation loss: 2.991157653314076

Epoch: 6| Step: 4
Training loss: 0.9837039900881548
Validation loss: 3.07748193365228

Epoch: 6| Step: 5
Training loss: 1.012306307880239
Validation loss: 3.0414888687076425

Epoch: 6| Step: 6
Training loss: 0.8882442912898815
Validation loss: 3.0017625214181147

Epoch: 6| Step: 7
Training loss: 0.9129021607544636
Validation loss: 2.8447297054002334

Epoch: 6| Step: 8
Training loss: 1.3161934247587526
Validation loss: 3.0133198573506017

Epoch: 6| Step: 9
Training loss: 0.785174241500373
Validation loss: 2.838002317558025

Epoch: 6| Step: 10
Training loss: 0.6883199527177325
Validation loss: 2.7842153392816313

Epoch: 6| Step: 11
Training loss: 0.987234654569821
Validation loss: 2.9409393034474705

Epoch: 6| Step: 12
Training loss: 0.9370601257892566
Validation loss: 2.933346713823087

Epoch: 6| Step: 13
Training loss: 0.8500222792230072
Validation loss: 2.821051137189127

Epoch: 218| Step: 0
Training loss: 1.2121256751913931
Validation loss: 2.9213838895520174

Epoch: 6| Step: 1
Training loss: 1.2140762014119122
Validation loss: 2.8753652755227264

Epoch: 6| Step: 2
Training loss: 0.6873479805113965
Validation loss: 2.880698934279281

Epoch: 6| Step: 3
Training loss: 1.2197007603355765
Validation loss: 2.8921867344499916

Epoch: 6| Step: 4
Training loss: 0.9015376796644535
Validation loss: 2.923644510915522

Epoch: 6| Step: 5
Training loss: 0.810445425280031
Validation loss: 2.865365983800359

Epoch: 6| Step: 6
Training loss: 0.9813435515983077
Validation loss: 2.965943291335286

Epoch: 6| Step: 7
Training loss: 0.9373978877088328
Validation loss: 2.9927757156457337

Epoch: 6| Step: 8
Training loss: 0.5421354087409114
Validation loss: 2.9203611453872464

Epoch: 6| Step: 9
Training loss: 1.0224773766362913
Validation loss: 2.881947746938833

Epoch: 6| Step: 10
Training loss: 0.5880424075452981
Validation loss: 2.9536819874642704

Epoch: 6| Step: 11
Training loss: 1.9054011972237217
Validation loss: 3.003681136395063

Epoch: 6| Step: 12
Training loss: 0.9270799758221696
Validation loss: 2.9710191052435744

Epoch: 6| Step: 13
Training loss: 0.9590555386059122
Validation loss: 2.7765091770184642

Epoch: 219| Step: 0
Training loss: 1.938960294158601
Validation loss: 2.8908268213698176

Epoch: 6| Step: 1
Training loss: 0.9805321539937198
Validation loss: 2.897174680065168

Epoch: 6| Step: 2
Training loss: 1.0826283263862404
Validation loss: 2.853810007314094

Epoch: 6| Step: 3
Training loss: 1.3544663122190523
Validation loss: 2.9659719084045806

Epoch: 6| Step: 4
Training loss: 0.924495141692778
Validation loss: 2.972274896168823

Epoch: 6| Step: 5
Training loss: 0.8096667923629473
Validation loss: 2.846208438941215

Epoch: 6| Step: 6
Training loss: 1.0223507534873382
Validation loss: 2.9554709479962185

Epoch: 6| Step: 7
Training loss: 0.6870143215235878
Validation loss: 2.882958399002001

Epoch: 6| Step: 8
Training loss: 0.6698071573422922
Validation loss: 2.850192900314431

Epoch: 6| Step: 9
Training loss: 1.206660241448875
Validation loss: 3.0318995956254713

Epoch: 6| Step: 10
Training loss: 0.9013581941926757
Validation loss: 2.904032226763752

Epoch: 6| Step: 11
Training loss: 0.9134856139805722
Validation loss: 2.860855386369176

Epoch: 6| Step: 12
Training loss: 0.4791843801486161
Validation loss: 2.973612380518715

Epoch: 6| Step: 13
Training loss: 1.1079741754104493
Validation loss: 2.9085146786426086

Epoch: 220| Step: 0
Training loss: 1.4999366587934493
Validation loss: 2.873848739881242

Epoch: 6| Step: 1
Training loss: 0.5435321821021531
Validation loss: 2.9275660246937805

Epoch: 6| Step: 2
Training loss: 0.7366575925650782
Validation loss: 2.9791636744842087

Epoch: 6| Step: 3
Training loss: 1.9296538933055376
Validation loss: 2.832493409780146

Epoch: 6| Step: 4
Training loss: 0.9971708570219409
Validation loss: 2.9751516153933117

Epoch: 6| Step: 5
Training loss: 0.8279192686943962
Validation loss: 3.105837216700228

Epoch: 6| Step: 6
Training loss: 1.1048829916026184
Validation loss: 2.9344260181870965

Epoch: 6| Step: 7
Training loss: 0.7536263217961888
Validation loss: 3.066402777084684

Epoch: 6| Step: 8
Training loss: 0.7928217859743075
Validation loss: 2.8772996882347397

Epoch: 6| Step: 9
Training loss: 0.89204614591765
Validation loss: 2.9966404435563097

Epoch: 6| Step: 10
Training loss: 1.1522185176753843
Validation loss: 2.972057213664256

Epoch: 6| Step: 11
Training loss: 0.7862777292065041
Validation loss: 2.9288358137035972

Epoch: 6| Step: 12
Training loss: 0.5973667615508802
Validation loss: 2.8148697512291556

Epoch: 6| Step: 13
Training loss: 1.2174651391210245
Validation loss: 3.0316180828291714

Epoch: 221| Step: 0
Training loss: 1.1969326732475034
Validation loss: 3.0031437693633554

Epoch: 6| Step: 1
Training loss: 0.5737451170005035
Validation loss: 3.003455066570661

Epoch: 6| Step: 2
Training loss: 0.8258762416862021
Validation loss: 2.890691464321582

Epoch: 6| Step: 3
Training loss: 0.6164833591130368
Validation loss: 2.962870360346852

Epoch: 6| Step: 4
Training loss: 2.0276458456356443
Validation loss: 2.9031070408917485

Epoch: 6| Step: 5
Training loss: 0.6414301395032979
Validation loss: 2.920989325616511

Epoch: 6| Step: 6
Training loss: 1.004669789681731
Validation loss: 2.9653236560314857

Epoch: 6| Step: 7
Training loss: 0.981854557477733
Validation loss: 2.854327710102884

Epoch: 6| Step: 8
Training loss: 1.0988014193536446
Validation loss: 3.0154153622511153

Epoch: 6| Step: 9
Training loss: 0.9053907596154523
Validation loss: 2.9178597984417496

Epoch: 6| Step: 10
Training loss: 0.9341963734413664
Validation loss: 3.0379422238728133

Epoch: 6| Step: 11
Training loss: 0.8359202445557702
Validation loss: 2.954714910553882

Epoch: 6| Step: 12
Training loss: 1.6242933937818167
Validation loss: 2.9325864428012602

Epoch: 6| Step: 13
Training loss: 0.6360857572828789
Validation loss: 2.9009960771376573

Epoch: 222| Step: 0
Training loss: 0.9492213873179026
Validation loss: 2.857248957684822

Epoch: 6| Step: 1
Training loss: 0.9147600625947646
Validation loss: 2.905198416288913

Epoch: 6| Step: 2
Training loss: 0.8661281885921646
Validation loss: 2.8310806959224504

Epoch: 6| Step: 3
Training loss: 0.712746550750682
Validation loss: 3.079911644564165

Epoch: 6| Step: 4
Training loss: 1.0065503163919383
Validation loss: 2.890636478435649

Epoch: 6| Step: 5
Training loss: 1.9364403318731587
Validation loss: 2.958494293956101

Epoch: 6| Step: 6
Training loss: 0.7170106324826715
Validation loss: 2.813599364559907

Epoch: 6| Step: 7
Training loss: 1.0287058687999593
Validation loss: 3.0076564335483216

Epoch: 6| Step: 8
Training loss: 0.8003006772408462
Validation loss: 2.9379658566363474

Epoch: 6| Step: 9
Training loss: 1.2462458024485155
Validation loss: 2.8138794942031424

Epoch: 6| Step: 10
Training loss: 1.1784522049946646
Validation loss: 2.756011879367076

Epoch: 6| Step: 11
Training loss: 0.8286321994148209
Validation loss: 2.8667238641917376

Epoch: 6| Step: 12
Training loss: 0.8037899900843442
Validation loss: 2.878073086513735

Epoch: 6| Step: 13
Training loss: 0.8770118812639213
Validation loss: 2.9874163537439267

Epoch: 223| Step: 0
Training loss: 1.2218009711667122
Validation loss: 2.8154016008849507

Epoch: 6| Step: 1
Training loss: 0.7565334577000735
Validation loss: 3.0108528657165787

Epoch: 6| Step: 2
Training loss: 0.8934079242519685
Validation loss: 3.0300972440954976

Epoch: 6| Step: 3
Training loss: 0.9889654572956679
Validation loss: 2.8669328983643045

Epoch: 6| Step: 4
Training loss: 0.6715192074531794
Validation loss: 2.9835313599855544

Epoch: 6| Step: 5
Training loss: 0.7208699185857248
Validation loss: 2.950751425521934

Epoch: 6| Step: 6
Training loss: 2.1268687165801134
Validation loss: 2.9221013027414493

Epoch: 6| Step: 7
Training loss: 0.8127540411307465
Validation loss: 2.9382314515333445

Epoch: 6| Step: 8
Training loss: 1.114287393563441
Validation loss: 2.973513198559825

Epoch: 6| Step: 9
Training loss: 0.8953251210333389
Validation loss: 2.9562066632159696

Epoch: 6| Step: 10
Training loss: 0.8974251392351961
Validation loss: 2.850752958584396

Epoch: 6| Step: 11
Training loss: 1.1496767377544082
Validation loss: 2.95757250785353

Epoch: 6| Step: 12
Training loss: 0.8564156643510639
Validation loss: 2.9751193735872374

Epoch: 6| Step: 13
Training loss: 0.7260385900912966
Validation loss: 2.951963798527546

Epoch: 224| Step: 0
Training loss: 0.9286502212589054
Validation loss: 3.0377733492204664

Epoch: 6| Step: 1
Training loss: 1.0207915135335779
Validation loss: 2.813243485126383

Epoch: 6| Step: 2
Training loss: 1.2491768510864354
Validation loss: 3.026653186422177

Epoch: 6| Step: 3
Training loss: 1.2886586336887682
Validation loss: 2.8674480378759473

Epoch: 6| Step: 4
Training loss: 0.6033271075378869
Validation loss: 2.8328693281092603

Epoch: 6| Step: 5
Training loss: 0.8848850935893648
Validation loss: 2.861604054483825

Epoch: 6| Step: 6
Training loss: 0.8203770203420931
Validation loss: 2.8108827532953113

Epoch: 6| Step: 7
Training loss: 0.8769369824799256
Validation loss: 2.8701665302304122

Epoch: 6| Step: 8
Training loss: 1.2544759246565507
Validation loss: 2.9514223670307365

Epoch: 6| Step: 9
Training loss: 0.8147542566034325
Validation loss: 2.932753007732845

Epoch: 6| Step: 10
Training loss: 1.248513482255901
Validation loss: 2.9542986305437053

Epoch: 6| Step: 11
Training loss: 1.0554202324864366
Validation loss: 2.890560747411955

Epoch: 6| Step: 12
Training loss: 0.7390325044186353
Validation loss: 2.96458119606554

Epoch: 6| Step: 13
Training loss: 1.8569701855946363
Validation loss: 2.9841365219620504

Epoch: 225| Step: 0
Training loss: 1.3605608097997994
Validation loss: 3.0060958719694657

Epoch: 6| Step: 1
Training loss: 0.9660193196807189
Validation loss: 2.9067533870616153

Epoch: 6| Step: 2
Training loss: 0.9006776497016163
Validation loss: 3.0152869290350104

Epoch: 6| Step: 3
Training loss: 0.88537479002413
Validation loss: 2.8842742852743224

Epoch: 6| Step: 4
Training loss: 0.8116363924191334
Validation loss: 2.9387297254496083

Epoch: 6| Step: 5
Training loss: 0.6380580086809223
Validation loss: 2.9249257091858225

Epoch: 6| Step: 6
Training loss: 0.9608758425896847
Validation loss: 2.794598994164024

Epoch: 6| Step: 7
Training loss: 0.6888010978090751
Validation loss: 2.966372143309319

Epoch: 6| Step: 8
Training loss: 0.7453554904782863
Validation loss: 2.9099583637453104

Epoch: 6| Step: 9
Training loss: 0.9667638291385163
Validation loss: 2.8362609426624408

Epoch: 6| Step: 10
Training loss: 1.1203176756330935
Validation loss: 3.0029948571222818

Epoch: 6| Step: 11
Training loss: 0.6494279673529012
Validation loss: 2.8356239278599467

Epoch: 6| Step: 12
Training loss: 1.0064537884506886
Validation loss: 2.882499023044726

Epoch: 6| Step: 13
Training loss: 1.9471343674418176
Validation loss: 2.884579744852418

Epoch: 226| Step: 0
Training loss: 0.6906526629055879
Validation loss: 2.992623758011687

Epoch: 6| Step: 1
Training loss: 0.8971752089638769
Validation loss: 2.944085024743564

Epoch: 6| Step: 2
Training loss: 0.9471587130590595
Validation loss: 3.0204439811157346

Epoch: 6| Step: 3
Training loss: 1.070160792381927
Validation loss: 2.9623403589342696

Epoch: 6| Step: 4
Training loss: 0.6718459899317082
Validation loss: 2.924462408672814

Epoch: 6| Step: 5
Training loss: 1.0909227615099546
Validation loss: 2.9863643972532152

Epoch: 6| Step: 6
Training loss: 0.6347155272448164
Validation loss: 2.725215181843157

Epoch: 6| Step: 7
Training loss: 0.9616821629175384
Validation loss: 2.9431504899197907

Epoch: 6| Step: 8
Training loss: 0.6847245590857022
Validation loss: 2.9854679869033918

Epoch: 6| Step: 9
Training loss: 2.106509148024392
Validation loss: 2.881748819924963

Epoch: 6| Step: 10
Training loss: 1.3584216490900805
Validation loss: 2.837467772066938

Epoch: 6| Step: 11
Training loss: 0.8145090353823476
Validation loss: 2.8802399774414593

Epoch: 6| Step: 12
Training loss: 0.7135140397415419
Validation loss: 2.944707644792874

Epoch: 6| Step: 13
Training loss: 0.6944721372698826
Validation loss: 2.915250125402704

Epoch: 227| Step: 0
Training loss: 0.7560468731936812
Validation loss: 2.974283889793331

Epoch: 6| Step: 1
Training loss: 0.7424667234702595
Validation loss: 3.0112973061394532

Epoch: 6| Step: 2
Training loss: 0.9053594225362763
Validation loss: 2.955586680648356

Epoch: 6| Step: 3
Training loss: 0.7937521236120937
Validation loss: 3.0111283161833873

Epoch: 6| Step: 4
Training loss: 0.7579296060904278
Validation loss: 2.9297399897641583

Epoch: 6| Step: 5
Training loss: 0.8415694847907795
Validation loss: 2.942584027840997

Epoch: 6| Step: 6
Training loss: 0.9431612110707053
Validation loss: 2.9118174886990937

Epoch: 6| Step: 7
Training loss: 0.7839766414091733
Validation loss: 3.030067488482141

Epoch: 6| Step: 8
Training loss: 0.7047618463040908
Validation loss: 2.9469281326309784

Epoch: 6| Step: 9
Training loss: 1.2645469124004451
Validation loss: 2.9355438699408687

Epoch: 6| Step: 10
Training loss: 0.9507589520964055
Validation loss: 2.917868984002948

Epoch: 6| Step: 11
Training loss: 0.6382472175107162
Validation loss: 2.857608868140094

Epoch: 6| Step: 12
Training loss: 1.2795345638864366
Validation loss: 3.0116159674707026

Epoch: 6| Step: 13
Training loss: 2.0557437401051937
Validation loss: 3.0004541795043047

Epoch: 228| Step: 0
Training loss: 1.2152402666145907
Validation loss: 2.9194668452497092

Epoch: 6| Step: 1
Training loss: 0.8549409396424963
Validation loss: 2.912866901104828

Epoch: 6| Step: 2
Training loss: 1.9604157137353293
Validation loss: 2.9288522572398166

Epoch: 6| Step: 3
Training loss: 1.4760655772933866
Validation loss: 2.9621569387903306

Epoch: 6| Step: 4
Training loss: 0.8941624976633039
Validation loss: 2.9160475868607785

Epoch: 6| Step: 5
Training loss: 0.8408561105229722
Validation loss: 2.822871997287454

Epoch: 6| Step: 6
Training loss: 1.1632414104538882
Validation loss: 3.0162054501408067

Epoch: 6| Step: 7
Training loss: 0.8736277787566493
Validation loss: 2.9195648213206096

Epoch: 6| Step: 8
Training loss: 1.0725658114677645
Validation loss: 2.904002315152509

Epoch: 6| Step: 9
Training loss: 0.607587932690471
Validation loss: 2.9948779195997406

Epoch: 6| Step: 10
Training loss: 0.7461975185272255
Validation loss: 2.9467004259759038

Epoch: 6| Step: 11
Training loss: 0.802589199183224
Validation loss: 3.06297532110332

Epoch: 6| Step: 12
Training loss: 0.6204678242507672
Validation loss: 2.9231950494544057

Epoch: 6| Step: 13
Training loss: 0.866905578976051
Validation loss: 2.9591300500444673

Epoch: 229| Step: 0
Training loss: 0.7087015475845503
Validation loss: 3.0158097469155543

Epoch: 6| Step: 1
Training loss: 0.896604442659119
Validation loss: 2.9397120162154065

Epoch: 6| Step: 2
Training loss: 0.8601090504016126
Validation loss: 2.8769070064165656

Epoch: 6| Step: 3
Training loss: 0.8515515108011907
Validation loss: 3.0019557591337596

Epoch: 6| Step: 4
Training loss: 1.0377685980512208
Validation loss: 2.934827237933975

Epoch: 6| Step: 5
Training loss: 0.7380151016633759
Validation loss: 2.8797240215103037

Epoch: 6| Step: 6
Training loss: 0.484404855238753
Validation loss: 2.863773416406501

Epoch: 6| Step: 7
Training loss: 0.9659664093697095
Validation loss: 2.8673482740681564

Epoch: 6| Step: 8
Training loss: 0.8332650077148147
Validation loss: 2.9769199053303184

Epoch: 6| Step: 9
Training loss: 0.9126730245346001
Validation loss: 2.9322451942966694

Epoch: 6| Step: 10
Training loss: 2.044988213950519
Validation loss: 2.9294447463446365

Epoch: 6| Step: 11
Training loss: 1.399940833476364
Validation loss: 2.928079121222436

Epoch: 6| Step: 12
Training loss: 0.9816019872612645
Validation loss: 2.9651690653503104

Epoch: 6| Step: 13
Training loss: 0.7526692732970538
Validation loss: 2.96351481840624

Epoch: 230| Step: 0
Training loss: 0.7324201660136311
Validation loss: 2.85756827774866

Epoch: 6| Step: 1
Training loss: 0.8303759590337482
Validation loss: 2.8916966831580537

Epoch: 6| Step: 2
Training loss: 0.9686047845105145
Validation loss: 2.7958673832312746

Epoch: 6| Step: 3
Training loss: 0.7623902320021919
Validation loss: 2.9029773073710037

Epoch: 6| Step: 4
Training loss: 1.2101000443391325
Validation loss: 2.9788839877450837

Epoch: 6| Step: 5
Training loss: 0.9542936446033318
Validation loss: 2.8889324147254816

Epoch: 6| Step: 6
Training loss: 0.9069809432293633
Validation loss: 2.913054945743903

Epoch: 6| Step: 7
Training loss: 0.6884716710126545
Validation loss: 3.1017559641371832

Epoch: 6| Step: 8
Training loss: 1.171501608807985
Validation loss: 2.9990004622766557

Epoch: 6| Step: 9
Training loss: 0.5850579335796852
Validation loss: 2.8665676572986105

Epoch: 6| Step: 10
Training loss: 0.9030279892821885
Validation loss: 2.8322029289738153

Epoch: 6| Step: 11
Training loss: 0.9846967141154036
Validation loss: 2.84291838618534

Epoch: 6| Step: 12
Training loss: 2.0394256385364065
Validation loss: 2.9306087418762377

Epoch: 6| Step: 13
Training loss: 0.651433892673495
Validation loss: 2.905706963343467

Epoch: 231| Step: 0
Training loss: 0.9274235576170596
Validation loss: 2.8504150869135296

Epoch: 6| Step: 1
Training loss: 0.6059140936357436
Validation loss: 3.06484372769979

Epoch: 6| Step: 2
Training loss: 0.8104934123228653
Validation loss: 2.9008496059394906

Epoch: 6| Step: 3
Training loss: 0.8581356475236193
Validation loss: 3.074078244428176

Epoch: 6| Step: 4
Training loss: 0.8637702903075735
Validation loss: 2.910702142570323

Epoch: 6| Step: 5
Training loss: 1.0353384181542773
Validation loss: 2.9589466524814605

Epoch: 6| Step: 6
Training loss: 0.5077212325022702
Validation loss: 3.0646587989240883

Epoch: 6| Step: 7
Training loss: 0.6831748332757509
Validation loss: 2.8989103330877692

Epoch: 6| Step: 8
Training loss: 1.4025545944630904
Validation loss: 2.92341342075421

Epoch: 6| Step: 9
Training loss: 0.8056926190488346
Validation loss: 2.8202996504641495

Epoch: 6| Step: 10
Training loss: 0.8428225188036416
Validation loss: 2.9355760997164353

Epoch: 6| Step: 11
Training loss: 0.6180419319118144
Validation loss: 2.9046348404210725

Epoch: 6| Step: 12
Training loss: 0.8133264519903257
Validation loss: 3.0128329566577876

Epoch: 6| Step: 13
Training loss: 2.0376797368629775
Validation loss: 2.895585568666828

Epoch: 232| Step: 0
Training loss: 0.6421256283843694
Validation loss: 3.0385207973980197

Epoch: 6| Step: 1
Training loss: 0.6741652598993111
Validation loss: 3.029889197846819

Epoch: 6| Step: 2
Training loss: 0.7316506763425668
Validation loss: 2.990039994366765

Epoch: 6| Step: 3
Training loss: 1.141680399030159
Validation loss: 2.93819668130938

Epoch: 6| Step: 4
Training loss: 0.7207080044878432
Validation loss: 3.0287658239043886

Epoch: 6| Step: 5
Training loss: 0.9508905014172648
Validation loss: 2.8941225217188746

Epoch: 6| Step: 6
Training loss: 1.1721978315092842
Validation loss: 2.9846591514604692

Epoch: 6| Step: 7
Training loss: 0.998570254578749
Validation loss: 3.0305723304548446

Epoch: 6| Step: 8
Training loss: 0.7138048971947133
Validation loss: 3.0644050952591004

Epoch: 6| Step: 9
Training loss: 1.9259315416601965
Validation loss: 2.8428981329511185

Epoch: 6| Step: 10
Training loss: 1.15944128129795
Validation loss: 2.9484794380562542

Epoch: 6| Step: 11
Training loss: 0.506327114589809
Validation loss: 2.959819344364554

Epoch: 6| Step: 12
Training loss: 1.1259449063538434
Validation loss: 2.959366421014045

Epoch: 6| Step: 13
Training loss: 1.0772292797639345
Validation loss: 2.971871592041372

Epoch: 233| Step: 0
Training loss: 1.1423729867263153
Validation loss: 2.9383183414843463

Epoch: 6| Step: 1
Training loss: 1.246818594744269
Validation loss: 2.8718629944017344

Epoch: 6| Step: 2
Training loss: 0.8166367419917004
Validation loss: 2.9709359135691558

Epoch: 6| Step: 3
Training loss: 0.7159235568876335
Validation loss: 2.840650077572041

Epoch: 6| Step: 4
Training loss: 2.0094727060818807
Validation loss: 2.9526249430224842

Epoch: 6| Step: 5
Training loss: 0.5937857868050774
Validation loss: 2.7834788474765104

Epoch: 6| Step: 6
Training loss: 0.6040693539044614
Validation loss: 2.956560212433371

Epoch: 6| Step: 7
Training loss: 0.6108315495477559
Validation loss: 2.964489365726175

Epoch: 6| Step: 8
Training loss: 0.9477398501360588
Validation loss: 2.8490170967322817

Epoch: 6| Step: 9
Training loss: 0.808416706550654
Validation loss: 2.8805656326454474

Epoch: 6| Step: 10
Training loss: 0.8696354518260645
Validation loss: 2.9541776822794508

Epoch: 6| Step: 11
Training loss: 0.7171155340784452
Validation loss: 2.943859028400123

Epoch: 6| Step: 12
Training loss: 1.0114731656266096
Validation loss: 2.875571677825884

Epoch: 6| Step: 13
Training loss: 0.6585144529197582
Validation loss: 2.7996489054949194

Epoch: 234| Step: 0
Training loss: 0.6375970691754744
Validation loss: 2.9394952207066734

Epoch: 6| Step: 1
Training loss: 0.750714041632213
Validation loss: 2.796569182372002

Epoch: 6| Step: 2
Training loss: 1.2648575422113466
Validation loss: 3.09683181932757

Epoch: 6| Step: 3
Training loss: 0.8806741523968387
Validation loss: 2.9917834401695456

Epoch: 6| Step: 4
Training loss: 0.7580325800076524
Validation loss: 2.8847723607609033

Epoch: 6| Step: 5
Training loss: 1.9031364152437564
Validation loss: 2.8955469653102264

Epoch: 6| Step: 6
Training loss: 0.8762918880751916
Validation loss: 3.0186128720768584

Epoch: 6| Step: 7
Training loss: 0.9609766386171709
Validation loss: 3.0396652996750255

Epoch: 6| Step: 8
Training loss: 0.898168506988756
Validation loss: 2.9106060320543516

Epoch: 6| Step: 9
Training loss: 1.1492811983465687
Validation loss: 2.8847172482755346

Epoch: 6| Step: 10
Training loss: 0.8377934468431728
Validation loss: 2.9760022241001294

Epoch: 6| Step: 11
Training loss: 0.7224308796590923
Validation loss: 2.9333918231493565

Epoch: 6| Step: 12
Training loss: 0.4736584843235984
Validation loss: 3.006820197960896

Epoch: 6| Step: 13
Training loss: 0.8770950644305853
Validation loss: 2.840422111850343

Epoch: 235| Step: 0
Training loss: 0.6109426825027949
Validation loss: 2.820419971676212

Epoch: 6| Step: 1
Training loss: 0.7623523522306261
Validation loss: 2.9554388948432244

Epoch: 6| Step: 2
Training loss: 2.1647294872337213
Validation loss: 2.800608240775631

Epoch: 6| Step: 3
Training loss: 0.991384045748289
Validation loss: 3.0329055066974884

Epoch: 6| Step: 4
Training loss: 0.7033479972714844
Validation loss: 2.9567825165737784

Epoch: 6| Step: 5
Training loss: 1.1252915216602308
Validation loss: 2.9678536249766956

Epoch: 6| Step: 6
Training loss: 0.7683060860784667
Validation loss: 2.910547108185798

Epoch: 6| Step: 7
Training loss: 0.9934421926305385
Validation loss: 3.0214272452380184

Epoch: 6| Step: 8
Training loss: 0.7910735686001683
Validation loss: 2.9671563137317873

Epoch: 6| Step: 9
Training loss: 0.6535139723424542
Validation loss: 2.9386294743399195

Epoch: 6| Step: 10
Training loss: 0.9037640115962885
Validation loss: 2.9642717281237028

Epoch: 6| Step: 11
Training loss: 0.700629787173493
Validation loss: 2.9500164376355853

Epoch: 6| Step: 12
Training loss: 0.9656624042957673
Validation loss: 2.895739222216266

Epoch: 6| Step: 13
Training loss: 0.9177795539842105
Validation loss: 2.897641541351208

Epoch: 236| Step: 0
Training loss: 1.0052149217353443
Validation loss: 3.04364958015865

Epoch: 6| Step: 1
Training loss: 0.9053386841668765
Validation loss: 2.9174936529949655

Epoch: 6| Step: 2
Training loss: 0.75125144818717
Validation loss: 2.869318614448082

Epoch: 6| Step: 3
Training loss: 0.7860207424484447
Validation loss: 3.0075045737646366

Epoch: 6| Step: 4
Training loss: 0.8080893154777172
Validation loss: 3.072015175348953

Epoch: 6| Step: 5
Training loss: 1.0367538503699993
Validation loss: 2.9451562922681433

Epoch: 6| Step: 6
Training loss: 0.6284248452451322
Validation loss: 2.9268541529161

Epoch: 6| Step: 7
Training loss: 1.9905003004076265
Validation loss: 2.978097154581199

Epoch: 6| Step: 8
Training loss: 0.9279092403046744
Validation loss: 2.9910789806864386

Epoch: 6| Step: 9
Training loss: 0.6175931732062316
Validation loss: 2.964962105447231

Epoch: 6| Step: 10
Training loss: 1.0419914438661533
Validation loss: 3.029071339537571

Epoch: 6| Step: 11
Training loss: 0.973696508591069
Validation loss: 2.8397636279837477

Epoch: 6| Step: 12
Training loss: 1.1256728279589783
Validation loss: 2.8110224056655992

Epoch: 6| Step: 13
Training loss: 0.7983061710454122
Validation loss: 2.8947003581574724

Epoch: 237| Step: 0
Training loss: 0.7811492473485129
Validation loss: 2.852977537457821

Epoch: 6| Step: 1
Training loss: 0.7135908476501339
Validation loss: 2.8828172416613556

Epoch: 6| Step: 2
Training loss: 0.8059939916897925
Validation loss: 2.8913827744851734

Epoch: 6| Step: 3
Training loss: 0.5647042319811869
Validation loss: 2.839305198707685

Epoch: 6| Step: 4
Training loss: 1.049779421480114
Validation loss: 2.9048029123749908

Epoch: 6| Step: 5
Training loss: 0.48491868915497743
Validation loss: 2.91930179539827

Epoch: 6| Step: 6
Training loss: 0.7210651098579233
Validation loss: 3.009423436362318

Epoch: 6| Step: 7
Training loss: 0.7898123926414857
Validation loss: 2.945585378187061

Epoch: 6| Step: 8
Training loss: 0.7917066028627521
Validation loss: 3.0646461310955475

Epoch: 6| Step: 9
Training loss: 1.0805016458155479
Validation loss: 2.9062652587490057

Epoch: 6| Step: 10
Training loss: 1.0837338269708792
Validation loss: 2.9001085069241457

Epoch: 6| Step: 11
Training loss: 0.7263690732032402
Validation loss: 3.0197268377852144

Epoch: 6| Step: 12
Training loss: 0.9229400753786894
Validation loss: 2.8963501741166504

Epoch: 6| Step: 13
Training loss: 1.9046835795261257
Validation loss: 2.8687744045396895

Epoch: 238| Step: 0
Training loss: 0.6892517487369196
Validation loss: 2.929163866507511

Epoch: 6| Step: 1
Training loss: 0.9577943212081529
Validation loss: 2.88745599192982

Epoch: 6| Step: 2
Training loss: 0.6211284411836533
Validation loss: 2.9950671038914205

Epoch: 6| Step: 3
Training loss: 0.8630747828698309
Validation loss: 2.9409098955736397

Epoch: 6| Step: 4
Training loss: 0.6478402708056862
Validation loss: 2.965393377329382

Epoch: 6| Step: 5
Training loss: 0.9177668572656942
Validation loss: 2.917803261322717

Epoch: 6| Step: 6
Training loss: 0.7438115471129504
Validation loss: 2.9665719592232502

Epoch: 6| Step: 7
Training loss: 1.8932320770982902
Validation loss: 2.9678246779357838

Epoch: 6| Step: 8
Training loss: 1.041389956278873
Validation loss: 2.837511198719125

Epoch: 6| Step: 9
Training loss: 1.1121569393854362
Validation loss: 2.903893120104582

Epoch: 6| Step: 10
Training loss: 0.8009078507250933
Validation loss: 2.9164079460563537

Epoch: 6| Step: 11
Training loss: 0.7017709197326066
Validation loss: 2.9742624869978953

Epoch: 6| Step: 12
Training loss: 0.7270551672419544
Validation loss: 2.887751537778001

Epoch: 6| Step: 13
Training loss: 0.7692900148831397
Validation loss: 2.876231689881145

Epoch: 239| Step: 0
Training loss: 0.9741096515031304
Validation loss: 2.8881048678161703

Epoch: 6| Step: 1
Training loss: 0.5284403384339424
Validation loss: 2.9549513186830234

Epoch: 6| Step: 2
Training loss: 0.7507612815210003
Validation loss: 2.9457394588104546

Epoch: 6| Step: 3
Training loss: 0.6023344313794999
Validation loss: 2.8702116495660466

Epoch: 6| Step: 4
Training loss: 0.9491494863851468
Validation loss: 2.834574572439214

Epoch: 6| Step: 5
Training loss: 1.9168332967335555
Validation loss: 2.966039564703512

Epoch: 6| Step: 6
Training loss: 0.7728289512428872
Validation loss: 2.926099487435949

Epoch: 6| Step: 7
Training loss: 1.2111018899883483
Validation loss: 2.966653786499123

Epoch: 6| Step: 8
Training loss: 0.8904888651353557
Validation loss: 2.940328818636879

Epoch: 6| Step: 9
Training loss: 0.8353887521609871
Validation loss: 2.9557524603151286

Epoch: 6| Step: 10
Training loss: 0.6747052220132422
Validation loss: 2.9181950833310726

Epoch: 6| Step: 11
Training loss: 0.6195657035031364
Validation loss: 2.8240290253131892

Epoch: 6| Step: 12
Training loss: 0.9281446653909327
Validation loss: 2.963070519689485

Epoch: 6| Step: 13
Training loss: 0.8490574238681231
Validation loss: 2.945500685719868

Epoch: 240| Step: 0
Training loss: 0.8561283164331199
Validation loss: 2.8754843981027793

Epoch: 6| Step: 1
Training loss: 0.8568420535152562
Validation loss: 2.8599929419788332

Epoch: 6| Step: 2
Training loss: 0.8062787664441808
Validation loss: 2.887494015377828

Epoch: 6| Step: 3
Training loss: 0.9969802203000291
Validation loss: 2.837111077003296

Epoch: 6| Step: 4
Training loss: 0.7096645150941144
Validation loss: 2.780478824183853

Epoch: 6| Step: 5
Training loss: 0.8014923659905245
Validation loss: 2.889423773737121

Epoch: 6| Step: 6
Training loss: 1.9288779966217253
Validation loss: 2.848639089677477

Epoch: 6| Step: 7
Training loss: 1.1502613454821742
Validation loss: 2.9542536117894476

Epoch: 6| Step: 8
Training loss: 0.662437245257786
Validation loss: 2.873294739239053

Epoch: 6| Step: 9
Training loss: 0.8741267478878483
Validation loss: 3.000570759520394

Epoch: 6| Step: 10
Training loss: 1.1398293842668021
Validation loss: 3.1542701050810313

Epoch: 6| Step: 11
Training loss: 0.8666262485787325
Validation loss: 2.9917597718126925

Epoch: 6| Step: 12
Training loss: 0.7040156339784276
Validation loss: 3.037821865427721

Epoch: 6| Step: 13
Training loss: 0.9989513322719452
Validation loss: 2.949636319474847

Epoch: 241| Step: 0
Training loss: 0.8909735415904728
Validation loss: 2.895679652758175

Epoch: 6| Step: 1
Training loss: 0.8497847102102525
Validation loss: 2.9669496397727264

Epoch: 6| Step: 2
Training loss: 0.6882816119847985
Validation loss: 2.9838977185746085

Epoch: 6| Step: 3
Training loss: 0.9583838421876537
Validation loss: 2.9302390702569423

Epoch: 6| Step: 4
Training loss: 0.8276536067713752
Validation loss: 2.9046097779063156

Epoch: 6| Step: 5
Training loss: 1.2366958240111872
Validation loss: 2.807503918118232

Epoch: 6| Step: 6
Training loss: 0.6064327809978654
Validation loss: 2.9232212711837446

Epoch: 6| Step: 7
Training loss: 1.9979931179955288
Validation loss: 3.0008461341772033

Epoch: 6| Step: 8
Training loss: 0.9539291241626818
Validation loss: 3.002232595029403

Epoch: 6| Step: 9
Training loss: 0.6187791701867975
Validation loss: 2.88356584390583

Epoch: 6| Step: 10
Training loss: 1.3033136684043145
Validation loss: 2.8883456341906553

Epoch: 6| Step: 11
Training loss: 0.63688620021207
Validation loss: 2.880965560421678

Epoch: 6| Step: 12
Training loss: 0.875411005221227
Validation loss: 2.9294954092841947

Epoch: 6| Step: 13
Training loss: 0.7243993819891844
Validation loss: 2.993863823942812

Epoch: 242| Step: 0
Training loss: 0.8637629412221229
Validation loss: 2.955136255069468

Epoch: 6| Step: 1
Training loss: 1.1081400700387292
Validation loss: 2.922519238824448

Epoch: 6| Step: 2
Training loss: 1.9208120492457954
Validation loss: 2.895269535718292

Epoch: 6| Step: 3
Training loss: 0.8297089597293889
Validation loss: 2.8720029329924275

Epoch: 6| Step: 4
Training loss: 0.875912360961201
Validation loss: 2.911975170977207

Epoch: 6| Step: 5
Training loss: 0.6283730799864011
Validation loss: 2.955108797057478

Epoch: 6| Step: 6
Training loss: 0.9541304241332597
Validation loss: 2.8523240278807807

Epoch: 6| Step: 7
Training loss: 0.8685899340042582
Validation loss: 2.9299934057957873

Epoch: 6| Step: 8
Training loss: 0.9554558691496201
Validation loss: 2.9947115060886427

Epoch: 6| Step: 9
Training loss: 0.6984118275543215
Validation loss: 2.899687930010919

Epoch: 6| Step: 10
Training loss: 0.5605291436876704
Validation loss: 2.91234767935725

Epoch: 6| Step: 11
Training loss: 0.8495674561430564
Validation loss: 2.8201224984286033

Epoch: 6| Step: 12
Training loss: 0.8460433310916864
Validation loss: 2.8296389663553163

Epoch: 6| Step: 13
Training loss: 0.7942096040399103
Validation loss: 2.8583136292789564

Epoch: 243| Step: 0
Training loss: 1.2972236991799493
Validation loss: 2.922575419583781

Epoch: 6| Step: 1
Training loss: 0.921016066675115
Validation loss: 2.934073702260291

Epoch: 6| Step: 2
Training loss: 0.7160322804446696
Validation loss: 2.796109348682438

Epoch: 6| Step: 3
Training loss: 0.7097382543867776
Validation loss: 2.9841830473145503

Epoch: 6| Step: 4
Training loss: 0.7206252554821081
Validation loss: 2.87515243181464

Epoch: 6| Step: 5
Training loss: 1.104726697342344
Validation loss: 2.8956800095473354

Epoch: 6| Step: 6
Training loss: 0.7982684648900794
Validation loss: 2.910702292740521

Epoch: 6| Step: 7
Training loss: 1.0416494876716573
Validation loss: 2.886150794622789

Epoch: 6| Step: 8
Training loss: 0.560595041790803
Validation loss: 2.8472033900643487

Epoch: 6| Step: 9
Training loss: 0.6414271891401837
Validation loss: 3.0419350118147044

Epoch: 6| Step: 10
Training loss: 1.12869313482294
Validation loss: 3.113614283497972

Epoch: 6| Step: 11
Training loss: 0.8558989884346592
Validation loss: 2.911030791980868

Epoch: 6| Step: 12
Training loss: 1.8036952077430661
Validation loss: 2.9432485349053095

Epoch: 6| Step: 13
Training loss: 0.6367440715973616
Validation loss: 2.9256717133400456

Epoch: 244| Step: 0
Training loss: 0.7207318225305719
Validation loss: 2.9069464611279967

Epoch: 6| Step: 1
Training loss: 1.1715950186371196
Validation loss: 2.8328147418263496

Epoch: 6| Step: 2
Training loss: 0.9363568648095992
Validation loss: 2.931695573746295

Epoch: 6| Step: 3
Training loss: 0.7306947409545371
Validation loss: 2.948789397727492

Epoch: 6| Step: 4
Training loss: 2.0150339605531755
Validation loss: 3.099341403568576

Epoch: 6| Step: 5
Training loss: 0.9688881191113046
Validation loss: 2.979887792813104

Epoch: 6| Step: 6
Training loss: 0.8240811563057319
Validation loss: 3.0154925038906515

Epoch: 6| Step: 7
Training loss: 0.7480526916437122
Validation loss: 2.9732648683443132

Epoch: 6| Step: 8
Training loss: 0.6739765169696638
Validation loss: 3.003698400508521

Epoch: 6| Step: 9
Training loss: 0.7256093489924699
Validation loss: 2.988558940409834

Epoch: 6| Step: 10
Training loss: 0.7738792622060202
Validation loss: 2.977086445775862

Epoch: 6| Step: 11
Training loss: 0.7200604806770226
Validation loss: 3.049602937127614

Epoch: 6| Step: 12
Training loss: 0.7529498343734716
Validation loss: 3.0305443299556964

Epoch: 6| Step: 13
Training loss: 0.841252693183295
Validation loss: 2.8430463877608116

Epoch: 245| Step: 0
Training loss: 0.8454183402937154
Validation loss: 2.896509768476959

Epoch: 6| Step: 1
Training loss: 2.0613385022227306
Validation loss: 2.8683286608167142

Epoch: 6| Step: 2
Training loss: 0.7026906261216782
Validation loss: 2.9246246401350757

Epoch: 6| Step: 3
Training loss: 0.6611555312520095
Validation loss: 2.8632486366680183

Epoch: 6| Step: 4
Training loss: 0.8482654333827085
Validation loss: 3.097887528433604

Epoch: 6| Step: 5
Training loss: 0.675909305853966
Validation loss: 2.853964810066904

Epoch: 6| Step: 6
Training loss: 0.7781099923153482
Validation loss: 2.9163045976337605

Epoch: 6| Step: 7
Training loss: 0.7189564201162242
Validation loss: 2.9917709286372314

Epoch: 6| Step: 8
Training loss: 0.9989482295719021
Validation loss: 2.944564279081056

Epoch: 6| Step: 9
Training loss: 1.1888259712596316
Validation loss: 3.1001645900758397

Epoch: 6| Step: 10
Training loss: 0.40119314016646523
Validation loss: 2.9366877630069936

Epoch: 6| Step: 11
Training loss: 0.6093013425473214
Validation loss: 3.058231661992281

Epoch: 6| Step: 12
Training loss: 0.6795030979509729
Validation loss: 3.0433081591450377

Epoch: 6| Step: 13
Training loss: 0.9665245520329344
Validation loss: 2.9876091228225117

Epoch: 246| Step: 0
Training loss: 0.9774629637587399
Validation loss: 2.9723323155945733

Epoch: 6| Step: 1
Training loss: 0.972298368620649
Validation loss: 2.9671215074809534

Epoch: 6| Step: 2
Training loss: 0.9660270014616299
Validation loss: 2.9933681167487505

Epoch: 6| Step: 3
Training loss: 0.8886985020264
Validation loss: 2.974639124313476

Epoch: 6| Step: 4
Training loss: 0.6257695943482714
Validation loss: 2.8095158039206796

Epoch: 6| Step: 5
Training loss: 0.5455817598947832
Validation loss: 2.9980557419835283

Epoch: 6| Step: 6
Training loss: 0.715521652555161
Validation loss: 2.9464347920482856

Epoch: 6| Step: 7
Training loss: 0.6758525347735569
Validation loss: 2.905369273082337

Epoch: 6| Step: 8
Training loss: 0.9659715616964542
Validation loss: 2.9761379736856104

Epoch: 6| Step: 9
Training loss: 0.8622438575656355
Validation loss: 2.94476017718666

Epoch: 6| Step: 10
Training loss: 0.7981904709623061
Validation loss: 2.9446333988507845

Epoch: 6| Step: 11
Training loss: 0.7892682402143053
Validation loss: 3.0363272392716287

Epoch: 6| Step: 12
Training loss: 0.8556876751589775
Validation loss: 2.9886652813982755

Epoch: 6| Step: 13
Training loss: 2.0056436305668193
Validation loss: 2.998685204294976

Epoch: 247| Step: 0
Training loss: 0.6462384358299255
Validation loss: 3.0730627941150668

Epoch: 6| Step: 1
Training loss: 0.8127779851886968
Validation loss: 3.1523589142123845

Epoch: 6| Step: 2
Training loss: 0.7702372067313623
Validation loss: 2.927273297282895

Epoch: 6| Step: 3
Training loss: 0.6348856416363572
Validation loss: 3.0411897485725072

Epoch: 6| Step: 4
Training loss: 0.6016619959207008
Validation loss: 2.980883514889095

Epoch: 6| Step: 5
Training loss: 1.0953420768368696
Validation loss: 2.9116691326515953

Epoch: 6| Step: 6
Training loss: 0.6727179850073663
Validation loss: 2.9355204791051706

Epoch: 6| Step: 7
Training loss: 0.8868518342963908
Validation loss: 2.7775794679001513

Epoch: 6| Step: 8
Training loss: 1.2269836480279908
Validation loss: 2.9618739490033588

Epoch: 6| Step: 9
Training loss: 0.4971312090251207
Validation loss: 2.9267764807398384

Epoch: 6| Step: 10
Training loss: 0.7995189859785223
Validation loss: 2.819159584709321

Epoch: 6| Step: 11
Training loss: 0.8547265303659561
Validation loss: 2.941312088457624

Epoch: 6| Step: 12
Training loss: 0.7521809022405678
Validation loss: 2.8462804079169612

Epoch: 6| Step: 13
Training loss: 1.8981496961668296
Validation loss: 2.9494159422038355

Epoch: 248| Step: 0
Training loss: 0.7559755615517897
Validation loss: 2.945542694998889

Epoch: 6| Step: 1
Training loss: 0.7977391587527607
Validation loss: 2.8914741025087394

Epoch: 6| Step: 2
Training loss: 0.7910192418898792
Validation loss: 3.0168182963696957

Epoch: 6| Step: 3
Training loss: 0.6409623723107314
Validation loss: 2.911647897371246

Epoch: 6| Step: 4
Training loss: 0.7572492885844433
Validation loss: 2.9411324166289745

Epoch: 6| Step: 5
Training loss: 0.6810739779769341
Validation loss: 3.0626041109203515

Epoch: 6| Step: 6
Training loss: 0.7079384394892294
Validation loss: 2.8817608990622405

Epoch: 6| Step: 7
Training loss: 0.8410710792668051
Validation loss: 3.1053795247885354

Epoch: 6| Step: 8
Training loss: 0.8568579833318637
Validation loss: 2.9402728419521993

Epoch: 6| Step: 9
Training loss: 0.929786484521751
Validation loss: 2.893074379439171

Epoch: 6| Step: 10
Training loss: 1.8319776319779078
Validation loss: 2.8782496400146647

Epoch: 6| Step: 11
Training loss: 1.1854114235134634
Validation loss: 3.0310677542418025

Epoch: 6| Step: 12
Training loss: 0.899419828017453
Validation loss: 3.0892816250073403

Epoch: 6| Step: 13
Training loss: 1.0618079680626153
Validation loss: 2.944619094619241

Epoch: 249| Step: 0
Training loss: 1.23002975141008
Validation loss: 2.946489619989138

Epoch: 6| Step: 1
Training loss: 0.665533792040478
Validation loss: 2.989323599206841

Epoch: 6| Step: 2
Training loss: 1.9025866218326724
Validation loss: 2.959123872966576

Epoch: 6| Step: 3
Training loss: 0.9099097511582334
Validation loss: 2.975601575172063

Epoch: 6| Step: 4
Training loss: 0.9724415002011568
Validation loss: 3.0301969999851286

Epoch: 6| Step: 5
Training loss: 0.8960221039949143
Validation loss: 3.077158303317121

Epoch: 6| Step: 6
Training loss: 0.7499558912658126
Validation loss: 2.9591626674876093

Epoch: 6| Step: 7
Training loss: 0.9239380591632808
Validation loss: 2.900227832614005

Epoch: 6| Step: 8
Training loss: 0.8881162814008341
Validation loss: 2.8888734889435095

Epoch: 6| Step: 9
Training loss: 0.7067094354987713
Validation loss: 2.922248286101607

Epoch: 6| Step: 10
Training loss: 0.7547231803973449
Validation loss: 2.8836974566384974

Epoch: 6| Step: 11
Training loss: 1.2226591750039892
Validation loss: 2.8637198493465954

Epoch: 6| Step: 12
Training loss: 0.9142949061538371
Validation loss: 2.8230184604736195

Epoch: 6| Step: 13
Training loss: 0.9650565464865595
Validation loss: 3.0150028898163077

Epoch: 250| Step: 0
Training loss: 0.5841486262892969
Validation loss: 2.9742490867922657

Epoch: 6| Step: 1
Training loss: 0.9655784558680319
Validation loss: 2.9885613603143595

Epoch: 6| Step: 2
Training loss: 0.6389041676514188
Validation loss: 3.0214983153396635

Epoch: 6| Step: 3
Training loss: 1.8348285328843865
Validation loss: 3.0354383968360037

Epoch: 6| Step: 4
Training loss: 0.6262909193623483
Validation loss: 2.88620385588112

Epoch: 6| Step: 5
Training loss: 0.887674564333124
Validation loss: 2.927941876320055

Epoch: 6| Step: 6
Training loss: 0.925587662041002
Validation loss: 3.078417988370264

Epoch: 6| Step: 7
Training loss: 0.5345948051664768
Validation loss: 2.9040589635973806

Epoch: 6| Step: 8
Training loss: 1.1602943415290687
Validation loss: 2.989400430505089

Epoch: 6| Step: 9
Training loss: 0.7084116658673434
Validation loss: 2.984720932382485

Epoch: 6| Step: 10
Training loss: 0.7366967530673115
Validation loss: 2.919943295063225

Epoch: 6| Step: 11
Training loss: 1.082930648985467
Validation loss: 2.9854176748681787

Epoch: 6| Step: 12
Training loss: 1.1267519660595688
Validation loss: 2.951861506499977

Epoch: 6| Step: 13
Training loss: 0.5159292768242438
Validation loss: 2.839124319956722

Epoch: 251| Step: 0
Training loss: 0.6281384822480305
Validation loss: 2.8367574608060524

Epoch: 6| Step: 1
Training loss: 0.9898936872523598
Validation loss: 2.939084471168036

Epoch: 6| Step: 2
Training loss: 1.3757192291195848
Validation loss: 2.8306856172516963

Epoch: 6| Step: 3
Training loss: 0.6088289602091105
Validation loss: 2.916939454718958

Epoch: 6| Step: 4
Training loss: 0.7931942924369189
Validation loss: 2.9159391903765894

Epoch: 6| Step: 5
Training loss: 1.0149914452704358
Validation loss: 2.9472373790832607

Epoch: 6| Step: 6
Training loss: 0.5263457568163846
Validation loss: 2.7022190670685515

Epoch: 6| Step: 7
Training loss: 0.7536154467808761
Validation loss: 2.927366960207997

Epoch: 6| Step: 8
Training loss: 0.6809967629009842
Validation loss: 2.987673110415582

Epoch: 6| Step: 9
Training loss: 0.7313601516835888
Validation loss: 3.0124747469148287

Epoch: 6| Step: 10
Training loss: 0.8792458111422157
Validation loss: 2.9403722126729197

Epoch: 6| Step: 11
Training loss: 0.5408949734671996
Validation loss: 3.011494128026489

Epoch: 6| Step: 12
Training loss: 0.7592413498175641
Validation loss: 2.9900091490504566

Epoch: 6| Step: 13
Training loss: 1.9325938095675796
Validation loss: 2.868047905625144

Epoch: 252| Step: 0
Training loss: 0.9580796707688074
Validation loss: 2.9453238867312774

Epoch: 6| Step: 1
Training loss: 0.7506776768022063
Validation loss: 2.943431938574643

Epoch: 6| Step: 2
Training loss: 0.74654318968564
Validation loss: 2.8889397734863813

Epoch: 6| Step: 3
Training loss: 1.8101136513325224
Validation loss: 2.9014777923528214

Epoch: 6| Step: 4
Training loss: 0.8365241514528422
Validation loss: 2.8479333924976955

Epoch: 6| Step: 5
Training loss: 0.7956765831035195
Validation loss: 3.005814170043059

Epoch: 6| Step: 6
Training loss: 0.6589836902987954
Validation loss: 2.9547390841011234

Epoch: 6| Step: 7
Training loss: 0.7768709671517345
Validation loss: 2.8818141376701094

Epoch: 6| Step: 8
Training loss: 0.49165575882832535
Validation loss: 2.9317768699776763

Epoch: 6| Step: 9
Training loss: 0.7389353927121513
Validation loss: 2.869842436538113

Epoch: 6| Step: 10
Training loss: 0.7054480852752555
Validation loss: 2.9194670630233257

Epoch: 6| Step: 11
Training loss: 0.9291517813877276
Validation loss: 2.8164827474856575

Epoch: 6| Step: 12
Training loss: 1.1114390339675886
Validation loss: 2.975150072763076

Epoch: 6| Step: 13
Training loss: 0.6925848274745743
Validation loss: 3.0125787400208215

Epoch: 253| Step: 0
Training loss: 1.8577852906463566
Validation loss: 3.0802024504977674

Epoch: 6| Step: 1
Training loss: 0.8270054933510825
Validation loss: 2.8234154845862265

Epoch: 6| Step: 2
Training loss: 1.0776040850504565
Validation loss: 2.9625786466393422

Epoch: 6| Step: 3
Training loss: 0.4904400215594545
Validation loss: 3.0506685035050913

Epoch: 6| Step: 4
Training loss: 1.009815384544488
Validation loss: 2.934579154629115

Epoch: 6| Step: 5
Training loss: 0.7524391090115402
Validation loss: 2.8404102066576153

Epoch: 6| Step: 6
Training loss: 0.8251648304743617
Validation loss: 2.942759087499027

Epoch: 6| Step: 7
Training loss: 0.5151847346920133
Validation loss: 2.9194081682789954

Epoch: 6| Step: 8
Training loss: 0.852496833236048
Validation loss: 2.9165761297797084

Epoch: 6| Step: 9
Training loss: 0.9590280992908079
Validation loss: 2.8997104450892155

Epoch: 6| Step: 10
Training loss: 0.911053489511225
Validation loss: 2.899980749417132

Epoch: 6| Step: 11
Training loss: 0.6843081419873324
Validation loss: 2.9045425786553944

Epoch: 6| Step: 12
Training loss: 0.6401575755803223
Validation loss: 3.050069396214443

Epoch: 6| Step: 13
Training loss: 0.7152499519622797
Validation loss: 2.981886700151685

Epoch: 254| Step: 0
Training loss: 0.9071090178619988
Validation loss: 2.8711542309123614

Epoch: 6| Step: 1
Training loss: 1.7890537711517749
Validation loss: 2.9609430962260563

Epoch: 6| Step: 2
Training loss: 0.647171761447102
Validation loss: 2.9500620463683633

Epoch: 6| Step: 3
Training loss: 0.7698714380567441
Validation loss: 2.9391969959960798

Epoch: 6| Step: 4
Training loss: 0.80501734815587
Validation loss: 2.8618287222522976

Epoch: 6| Step: 5
Training loss: 0.7640228635652306
Validation loss: 2.9511127377637085

Epoch: 6| Step: 6
Training loss: 0.6567842261824192
Validation loss: 2.998470684833315

Epoch: 6| Step: 7
Training loss: 0.8236079913554324
Validation loss: 2.9642428667513983

Epoch: 6| Step: 8
Training loss: 0.7573530633132199
Validation loss: 2.8842427497211203

Epoch: 6| Step: 9
Training loss: 0.6709242014817405
Validation loss: 3.017799397311379

Epoch: 6| Step: 10
Training loss: 0.6555468334297546
Validation loss: 2.956747615083121

Epoch: 6| Step: 11
Training loss: 1.1174665516022795
Validation loss: 3.000355924579404

Epoch: 6| Step: 12
Training loss: 0.7603076874141256
Validation loss: 2.774267425296296

Epoch: 6| Step: 13
Training loss: 0.8739647872256082
Validation loss: 2.9299359228984776

Epoch: 255| Step: 0
Training loss: 0.5706610463718296
Validation loss: 2.8563166871414016

Epoch: 6| Step: 1
Training loss: 1.9087065830051837
Validation loss: 2.9233407408759273

Epoch: 6| Step: 2
Training loss: 0.7155530568570224
Validation loss: 2.9916387707216363

Epoch: 6| Step: 3
Training loss: 0.827655371171637
Validation loss: 2.9378406110747597

Epoch: 6| Step: 4
Training loss: 1.1601865616765683
Validation loss: 2.9694804313611387

Epoch: 6| Step: 5
Training loss: 0.7949666753418172
Validation loss: 2.955691801442763

Epoch: 6| Step: 6
Training loss: 0.8940221012165662
Validation loss: 2.9139943732785736

Epoch: 6| Step: 7
Training loss: 1.05433377586144
Validation loss: 3.0021795527868966

Epoch: 6| Step: 8
Training loss: 0.601121914518342
Validation loss: 2.901466302025118

Epoch: 6| Step: 9
Training loss: 0.5345831538125994
Validation loss: 3.012242622513567

Epoch: 6| Step: 10
Training loss: 0.4962971788363468
Validation loss: 3.0027524322050194

Epoch: 6| Step: 11
Training loss: 0.966606167566287
Validation loss: 2.9646186458354795

Epoch: 6| Step: 12
Training loss: 1.0068651226560847
Validation loss: 2.898758191021325

Epoch: 6| Step: 13
Training loss: 0.7460066659644886
Validation loss: 3.0670385725205476

Epoch: 256| Step: 0
Training loss: 0.8781107375320493
Validation loss: 2.9034196067003863

Epoch: 6| Step: 1
Training loss: 0.8242931603565022
Validation loss: 2.9871315333852895

Epoch: 6| Step: 2
Training loss: 0.6732938777069603
Validation loss: 2.8775615338005394

Epoch: 6| Step: 3
Training loss: 0.6708050569849809
Validation loss: 2.9066563257272606

Epoch: 6| Step: 4
Training loss: 0.9996849100091885
Validation loss: 2.8891064065774414

Epoch: 6| Step: 5
Training loss: 0.6019133003225582
Validation loss: 3.0643915446155945

Epoch: 6| Step: 6
Training loss: 0.9602758409161012
Validation loss: 2.934101045635468

Epoch: 6| Step: 7
Training loss: 1.971242568075216
Validation loss: 3.1048337403124346

Epoch: 6| Step: 8
Training loss: 0.5927467403024589
Validation loss: 2.904195428447699

Epoch: 6| Step: 9
Training loss: 0.8139444862387525
Validation loss: 2.9137006165061603

Epoch: 6| Step: 10
Training loss: 0.5772497924004698
Validation loss: 2.9211055810128808

Epoch: 6| Step: 11
Training loss: 0.9454566908650298
Validation loss: 2.9830870853499976

Epoch: 6| Step: 12
Training loss: 0.92472154189164
Validation loss: 2.89042918598803

Epoch: 6| Step: 13
Training loss: 0.6308513676279867
Validation loss: 2.9870340108894453

Epoch: 257| Step: 0
Training loss: 0.707105306045311
Validation loss: 2.902480713054353

Epoch: 6| Step: 1
Training loss: 0.6830682969358252
Validation loss: 2.932313832029289

Epoch: 6| Step: 2
Training loss: 1.417554053835138
Validation loss: 2.8905347242950303

Epoch: 6| Step: 3
Training loss: 0.7160791446961788
Validation loss: 2.868232723631257

Epoch: 6| Step: 4
Training loss: 0.6856761929952595
Validation loss: 2.982196112321212

Epoch: 6| Step: 5
Training loss: 0.883263295623969
Validation loss: 2.901009171929994

Epoch: 6| Step: 6
Training loss: 0.9964443412583716
Validation loss: 3.0378175749989955

Epoch: 6| Step: 7
Training loss: 0.7016214613574645
Validation loss: 3.040068681300796

Epoch: 6| Step: 8
Training loss: 0.7960848911679727
Validation loss: 2.9678385355969805

Epoch: 6| Step: 9
Training loss: 1.0569347035820653
Validation loss: 2.960582849472155

Epoch: 6| Step: 10
Training loss: 2.014604058565073
Validation loss: 2.9820935914490034

Epoch: 6| Step: 11
Training loss: 0.6197034521930413
Validation loss: 2.880729708582146

Epoch: 6| Step: 12
Training loss: 0.6010273125673785
Validation loss: 2.9548820502832633

Epoch: 6| Step: 13
Training loss: 0.7539215876941284
Validation loss: 3.0841774085853384

Epoch: 258| Step: 0
Training loss: 0.7407075280673339
Validation loss: 2.9481134158056412

Epoch: 6| Step: 1
Training loss: 0.8802803657145678
Validation loss: 2.9164410958029463

Epoch: 6| Step: 2
Training loss: 0.6578009760701218
Validation loss: 2.9343117530731506

Epoch: 6| Step: 3
Training loss: 1.0823852290568758
Validation loss: 2.975254802851594

Epoch: 6| Step: 4
Training loss: 0.7476406737551603
Validation loss: 2.897803498578483

Epoch: 6| Step: 5
Training loss: 0.6374329615855072
Validation loss: 2.9289441602547464

Epoch: 6| Step: 6
Training loss: 1.0246501465108717
Validation loss: 3.0443184323773362

Epoch: 6| Step: 7
Training loss: 0.668123216225194
Validation loss: 3.0078959796104483

Epoch: 6| Step: 8
Training loss: 0.6598949479536477
Validation loss: 3.0205252040819093

Epoch: 6| Step: 9
Training loss: 1.8738038380162043
Validation loss: 3.0032006118258594

Epoch: 6| Step: 10
Training loss: 1.1219205565487265
Validation loss: 3.020291974898667

Epoch: 6| Step: 11
Training loss: 0.5826241206678308
Validation loss: 3.0199407815495594

Epoch: 6| Step: 12
Training loss: 0.6514956277611286
Validation loss: 2.9472691304409513

Epoch: 6| Step: 13
Training loss: 0.5457175130729067
Validation loss: 2.944575898117136

Epoch: 259| Step: 0
Training loss: 0.363905892640164
Validation loss: 2.932191638132538

Epoch: 6| Step: 1
Training loss: 1.063761187000374
Validation loss: 3.068211944295172

Epoch: 6| Step: 2
Training loss: 0.641292085140299
Validation loss: 2.9656375966476185

Epoch: 6| Step: 3
Training loss: 0.6923519498890042
Validation loss: 2.854183661045983

Epoch: 6| Step: 4
Training loss: 0.7006570950591452
Validation loss: 3.027809025275611

Epoch: 6| Step: 5
Training loss: 0.7914659136832302
Validation loss: 2.9276680051318498

Epoch: 6| Step: 6
Training loss: 0.6937784567143066
Validation loss: 2.7967362325046503

Epoch: 6| Step: 7
Training loss: 0.7529828835779906
Validation loss: 2.994353649891626

Epoch: 6| Step: 8
Training loss: 0.708343636680914
Validation loss: 2.813151503091092

Epoch: 6| Step: 9
Training loss: 0.8927639824085536
Validation loss: 3.106624108447322

Epoch: 6| Step: 10
Training loss: 0.8798340372163569
Validation loss: 2.9561524926867193

Epoch: 6| Step: 11
Training loss: 1.9187264431678497
Validation loss: 2.9537537996921754

Epoch: 6| Step: 12
Training loss: 0.7056515757757008
Validation loss: 3.158511167030548

Epoch: 6| Step: 13
Training loss: 1.0953754880373627
Validation loss: 3.047806673983398

Epoch: 260| Step: 0
Training loss: 0.7842548567111098
Validation loss: 2.8700519912166365

Epoch: 6| Step: 1
Training loss: 0.6120231991341353
Validation loss: 2.9298951478061914

Epoch: 6| Step: 2
Training loss: 0.9727547224210071
Validation loss: 3.0146392766106693

Epoch: 6| Step: 3
Training loss: 0.9855024450979185
Validation loss: 3.051180687616798

Epoch: 6| Step: 4
Training loss: 0.500265825657063
Validation loss: 2.89390214612074

Epoch: 6| Step: 5
Training loss: 0.8541129180620892
Validation loss: 3.0547436435024653

Epoch: 6| Step: 6
Training loss: 0.39892314783952376
Validation loss: 3.021175067031817

Epoch: 6| Step: 7
Training loss: 2.1294824782808557
Validation loss: 2.9348497542267555

Epoch: 6| Step: 8
Training loss: 0.7406365099950121
Validation loss: 2.917957338228257

Epoch: 6| Step: 9
Training loss: 0.8323008857060507
Validation loss: 3.016728991361701

Epoch: 6| Step: 10
Training loss: 0.6508130600425972
Validation loss: 2.9488201082462324

Epoch: 6| Step: 11
Training loss: 0.8124066812771122
Validation loss: 3.066373516321105

Epoch: 6| Step: 12
Training loss: 0.5789884099689757
Validation loss: 2.9447544827366534

Epoch: 6| Step: 13
Training loss: 0.8855627313447072
Validation loss: 2.8513600038020352

Epoch: 261| Step: 0
Training loss: 0.5967448147507314
Validation loss: 2.9417224053855753

Epoch: 6| Step: 1
Training loss: 0.7478343771361935
Validation loss: 2.9490799018562295

Epoch: 6| Step: 2
Training loss: 0.7080035189794385
Validation loss: 2.9374794790214

Epoch: 6| Step: 3
Training loss: 1.0068572492591699
Validation loss: 2.991265934392793

Epoch: 6| Step: 4
Training loss: 0.8533753164091595
Validation loss: 2.9216002200793336

Epoch: 6| Step: 5
Training loss: 0.8860483534149736
Validation loss: 2.958340246344714

Epoch: 6| Step: 6
Training loss: 0.8508685723111424
Validation loss: 2.9074577911890622

Epoch: 6| Step: 7
Training loss: 1.0150721292282685
Validation loss: 2.998618470085207

Epoch: 6| Step: 8
Training loss: 0.5076069635973969
Validation loss: 3.0230362040158076

Epoch: 6| Step: 9
Training loss: 0.7636100958691786
Validation loss: 2.8927950025429503

Epoch: 6| Step: 10
Training loss: 0.9133675044227137
Validation loss: 3.170487092388553

Epoch: 6| Step: 11
Training loss: 1.8093373559913155
Validation loss: 2.9221150236769797

Epoch: 6| Step: 12
Training loss: 0.8499107790851287
Validation loss: 3.107206754752994

Epoch: 6| Step: 13
Training loss: 0.7260510685301479
Validation loss: 3.0464672891778704

Epoch: 262| Step: 0
Training loss: 1.0328980195482131
Validation loss: 3.141196646469394

Epoch: 6| Step: 1
Training loss: 0.923023639762655
Validation loss: 3.0411504586148626

Epoch: 6| Step: 2
Training loss: 0.6630100437154407
Validation loss: 2.9590255751222734

Epoch: 6| Step: 3
Training loss: 0.5275637132576245
Validation loss: 2.9921722278919027

Epoch: 6| Step: 4
Training loss: 0.7199425961870185
Validation loss: 2.848514310743147

Epoch: 6| Step: 5
Training loss: 2.0237673928713296
Validation loss: 3.0173838992197846

Epoch: 6| Step: 6
Training loss: 0.8714839591619917
Validation loss: 2.913344969035146

Epoch: 6| Step: 7
Training loss: 0.8516935895059787
Validation loss: 3.0226525627528504

Epoch: 6| Step: 8
Training loss: 0.85206757012471
Validation loss: 2.842671298052192

Epoch: 6| Step: 9
Training loss: 0.720280013934413
Validation loss: 2.987370005111023

Epoch: 6| Step: 10
Training loss: 0.7862525990841941
Validation loss: 2.9204879297121225

Epoch: 6| Step: 11
Training loss: 0.7584373415022199
Validation loss: 2.9695307859336615

Epoch: 6| Step: 12
Training loss: 1.1373887856580092
Validation loss: 3.1198446219423266

Epoch: 6| Step: 13
Training loss: 0.6780162302145102
Validation loss: 2.9327230638684774

Epoch: 263| Step: 0
Training loss: 0.6995659078260944
Validation loss: 3.0214311775467686

Epoch: 6| Step: 1
Training loss: 0.9180517930149137
Validation loss: 2.950256421103331

Epoch: 6| Step: 2
Training loss: 0.8374286436171635
Validation loss: 2.950213468769989

Epoch: 6| Step: 3
Training loss: 0.7115180192060974
Validation loss: 2.895891481725947

Epoch: 6| Step: 4
Training loss: 0.747418889521923
Validation loss: 2.9105783314315463

Epoch: 6| Step: 5
Training loss: 0.6992236728601471
Validation loss: 2.8694215225439947

Epoch: 6| Step: 6
Training loss: 1.0327541479111915
Validation loss: 2.8824456454443403

Epoch: 6| Step: 7
Training loss: 0.731433089068843
Validation loss: 2.9769164214561834

Epoch: 6| Step: 8
Training loss: 0.570057563761203
Validation loss: 3.0095471817148667

Epoch: 6| Step: 9
Training loss: 1.868203050572484
Validation loss: 2.970959279697534

Epoch: 6| Step: 10
Training loss: 0.7869915743913618
Validation loss: 2.8261351636827876

Epoch: 6| Step: 11
Training loss: 0.8497939336855134
Validation loss: 2.946122129889156

Epoch: 6| Step: 12
Training loss: 0.6749855825862469
Validation loss: 2.9896377177503273

Epoch: 6| Step: 13
Training loss: 0.9373996998856644
Validation loss: 2.9932440609636326

Epoch: 264| Step: 0
Training loss: 0.789617362249507
Validation loss: 3.0522768959578657

Epoch: 6| Step: 1
Training loss: 0.5305620676021586
Validation loss: 3.028020331138963

Epoch: 6| Step: 2
Training loss: 0.472064506927511
Validation loss: 2.9138613879475095

Epoch: 6| Step: 3
Training loss: 0.7743449041939209
Validation loss: 2.9071224639505795

Epoch: 6| Step: 4
Training loss: 0.6064755836094347
Validation loss: 3.031291201072249

Epoch: 6| Step: 5
Training loss: 0.7247072960838057
Validation loss: 2.921526787828256

Epoch: 6| Step: 6
Training loss: 0.8825072714530348
Validation loss: 2.919235642170295

Epoch: 6| Step: 7
Training loss: 0.7189884619496673
Validation loss: 3.0243861823582434

Epoch: 6| Step: 8
Training loss: 2.035716150039163
Validation loss: 3.092763647191048

Epoch: 6| Step: 9
Training loss: 0.7220552987190553
Validation loss: 2.9094487296656353

Epoch: 6| Step: 10
Training loss: 0.7582488229492792
Validation loss: 3.0292092955649292

Epoch: 6| Step: 11
Training loss: 0.762294258439241
Validation loss: 3.0890803304262806

Epoch: 6| Step: 12
Training loss: 0.813101472506904
Validation loss: 2.994678479695594

Epoch: 6| Step: 13
Training loss: 1.007636417117433
Validation loss: 3.0181543024415025

Epoch: 265| Step: 0
Training loss: 0.6047974587545417
Validation loss: 2.97029311916096

Epoch: 6| Step: 1
Training loss: 0.8129529790688453
Validation loss: 2.8812472290334665

Epoch: 6| Step: 2
Training loss: 1.762904544152409
Validation loss: 2.994748486193739

Epoch: 6| Step: 3
Training loss: 0.9014370478941225
Validation loss: 2.9796964045476395

Epoch: 6| Step: 4
Training loss: 0.9163338895231492
Validation loss: 3.1240933310983796

Epoch: 6| Step: 5
Training loss: 0.5257154403697537
Validation loss: 2.8645931636757225

Epoch: 6| Step: 6
Training loss: 0.8888903003588702
Validation loss: 2.9876599964622237

Epoch: 6| Step: 7
Training loss: 0.5953502172501574
Validation loss: 2.9694318289548765

Epoch: 6| Step: 8
Training loss: 0.8476224971678595
Validation loss: 2.9346201963834235

Epoch: 6| Step: 9
Training loss: 0.6812695255456163
Validation loss: 3.0722077969110293

Epoch: 6| Step: 10
Training loss: 0.8620643842509642
Validation loss: 2.950923980797189

Epoch: 6| Step: 11
Training loss: 1.1335769704658705
Validation loss: 3.06027169157965

Epoch: 6| Step: 12
Training loss: 0.6110713041470559
Validation loss: 2.895733541145965

Epoch: 6| Step: 13
Training loss: 0.5165396294489659
Validation loss: 2.9879789843639415

Epoch: 266| Step: 0
Training loss: 0.8942345539451506
Validation loss: 2.975151007690587

Epoch: 6| Step: 1
Training loss: 0.7120157804937037
Validation loss: 3.0261122957392304

Epoch: 6| Step: 2
Training loss: 0.7629298046264902
Validation loss: 3.027133808034592

Epoch: 6| Step: 3
Training loss: 0.47491213086174405
Validation loss: 2.9108499609028815

Epoch: 6| Step: 4
Training loss: 0.704227388649333
Validation loss: 2.9316808539808665

Epoch: 6| Step: 5
Training loss: 0.5204567946862066
Validation loss: 3.0286621242007428

Epoch: 6| Step: 6
Training loss: 0.8613423110589503
Validation loss: 2.9262000591845845

Epoch: 6| Step: 7
Training loss: 1.118387231669717
Validation loss: 3.0435186043576947

Epoch: 6| Step: 8
Training loss: 0.6198567481826079
Validation loss: 2.931505186987781

Epoch: 6| Step: 9
Training loss: 1.8464002150661072
Validation loss: 2.980635665412667

Epoch: 6| Step: 10
Training loss: 0.9354901067597006
Validation loss: 2.94788952782386

Epoch: 6| Step: 11
Training loss: 0.8019402652978509
Validation loss: 3.008049959659807

Epoch: 6| Step: 12
Training loss: 0.7398836215754793
Validation loss: 3.1823782318545137

Epoch: 6| Step: 13
Training loss: 0.7033845210619896
Validation loss: 3.0630157840823142

Epoch: 267| Step: 0
Training loss: 0.740667573695081
Validation loss: 3.1036204341782274

Epoch: 6| Step: 1
Training loss: 0.9032143690512922
Validation loss: 2.951803729254789

Epoch: 6| Step: 2
Training loss: 0.6251996198396753
Validation loss: 2.956852519900603

Epoch: 6| Step: 3
Training loss: 0.6022724569558899
Validation loss: 2.9217676969194457

Epoch: 6| Step: 4
Training loss: 1.0014147287939248
Validation loss: 2.94185658959368

Epoch: 6| Step: 5
Training loss: 1.6769831688706769
Validation loss: 2.9954013944597264

Epoch: 6| Step: 6
Training loss: 0.8910514747401502
Validation loss: 2.775126670833119

Epoch: 6| Step: 7
Training loss: 0.7796185816576627
Validation loss: 2.916082900528118

Epoch: 6| Step: 8
Training loss: 0.5312703072649635
Validation loss: 2.893922042401269

Epoch: 6| Step: 9
Training loss: 1.0904328862928576
Validation loss: 2.9372671454374006

Epoch: 6| Step: 10
Training loss: 0.8314842969497778
Validation loss: 2.9029467415395844

Epoch: 6| Step: 11
Training loss: 0.7224933337527757
Validation loss: 3.036473941054017

Epoch: 6| Step: 12
Training loss: 0.5987646259600056
Validation loss: 3.0606921952053416

Epoch: 6| Step: 13
Training loss: 1.0374922395898523
Validation loss: 2.9511525128022047

Epoch: 268| Step: 0
Training loss: 0.5676212302298871
Validation loss: 2.857521637717553

Epoch: 6| Step: 1
Training loss: 0.6982661529909827
Validation loss: 3.0406176486944165

Epoch: 6| Step: 2
Training loss: 0.7806278803507287
Validation loss: 2.9701413692091094

Epoch: 6| Step: 3
Training loss: 0.4491435444117054
Validation loss: 3.0361038751410274

Epoch: 6| Step: 4
Training loss: 0.9166550996801983
Validation loss: 2.9811851270483034

Epoch: 6| Step: 5
Training loss: 0.4610429255294104
Validation loss: 2.9452622575462994

Epoch: 6| Step: 6
Training loss: 0.8080617656587882
Validation loss: 2.9523453398100723

Epoch: 6| Step: 7
Training loss: 0.8242021893469195
Validation loss: 2.942612642515942

Epoch: 6| Step: 8
Training loss: 0.6522254379709647
Validation loss: 3.0179852224425945

Epoch: 6| Step: 9
Training loss: 0.5882841295067984
Validation loss: 2.95655475575255

Epoch: 6| Step: 10
Training loss: 0.5274164785460238
Validation loss: 2.9968940630834533

Epoch: 6| Step: 11
Training loss: 0.8340852484346798
Validation loss: 3.0417973520779786

Epoch: 6| Step: 12
Training loss: 1.8396012780195237
Validation loss: 2.934482837627898

Epoch: 6| Step: 13
Training loss: 1.0311295988137794
Validation loss: 3.0336910394954577

Epoch: 269| Step: 0
Training loss: 0.725765693752423
Validation loss: 2.9940481484754047

Epoch: 6| Step: 1
Training loss: 0.8239875216002174
Validation loss: 3.0419513860898175

Epoch: 6| Step: 2
Training loss: 0.8871025565593794
Validation loss: 2.997209933714079

Epoch: 6| Step: 3
Training loss: 0.6847473873271033
Validation loss: 2.976520234322696

Epoch: 6| Step: 4
Training loss: 1.8347516064822
Validation loss: 2.995680096190777

Epoch: 6| Step: 5
Training loss: 0.789823297524458
Validation loss: 2.9034696699454274

Epoch: 6| Step: 6
Training loss: 0.8023315309896011
Validation loss: 3.002482804125549

Epoch: 6| Step: 7
Training loss: 0.6345847473663119
Validation loss: 3.050827110684997

Epoch: 6| Step: 8
Training loss: 0.5120062566389822
Validation loss: 2.9975401939982746

Epoch: 6| Step: 9
Training loss: 0.6324999237437448
Validation loss: 2.966853476296876

Epoch: 6| Step: 10
Training loss: 0.6094532451768886
Validation loss: 2.8995559056380777

Epoch: 6| Step: 11
Training loss: 0.5330425761324987
Validation loss: 3.033413341186687

Epoch: 6| Step: 12
Training loss: 1.0131829466300644
Validation loss: 2.994972466802374

Epoch: 6| Step: 13
Training loss: 0.5570533427047862
Validation loss: 3.0275508030462244

Epoch: 270| Step: 0
Training loss: 0.9663390337451426
Validation loss: 2.893145587765756

Epoch: 6| Step: 1
Training loss: 0.7814799923913571
Validation loss: 3.066869738755482

Epoch: 6| Step: 2
Training loss: 1.072278965934767
Validation loss: 2.88470639370542

Epoch: 6| Step: 3
Training loss: 0.5386778800026594
Validation loss: 2.996698655823011

Epoch: 6| Step: 4
Training loss: 0.9796266320893883
Validation loss: 3.0072527740327875

Epoch: 6| Step: 5
Training loss: 0.9930077113709763
Validation loss: 2.913907726224125

Epoch: 6| Step: 6
Training loss: 0.8706260417704706
Validation loss: 2.955462961630716

Epoch: 6| Step: 7
Training loss: 0.8131828006664013
Validation loss: 2.978991674516801

Epoch: 6| Step: 8
Training loss: 0.8671005480363672
Validation loss: 2.9351166600053538

Epoch: 6| Step: 9
Training loss: 0.6029412706236855
Validation loss: 2.8979486428495638

Epoch: 6| Step: 10
Training loss: 0.6771800827936914
Validation loss: 2.9727053744734713

Epoch: 6| Step: 11
Training loss: 1.8221591865225284
Validation loss: 3.039741969702462

Epoch: 6| Step: 12
Training loss: 0.5165655920417309
Validation loss: 3.12205194653409

Epoch: 6| Step: 13
Training loss: 0.5997372469164289
Validation loss: 3.0396481483317332

Epoch: 271| Step: 0
Training loss: 1.819891688613782
Validation loss: 2.9483225961952937

Epoch: 6| Step: 1
Training loss: 0.3673287586640104
Validation loss: 3.1147010593853373

Epoch: 6| Step: 2
Training loss: 0.5605528827837077
Validation loss: 3.154384326017806

Epoch: 6| Step: 3
Training loss: 0.49650642171992115
Validation loss: 3.046561533135106

Epoch: 6| Step: 4
Training loss: 1.0415417341971478
Validation loss: 3.019010129558008

Epoch: 6| Step: 5
Training loss: 0.6178587389995456
Validation loss: 3.016040766752474

Epoch: 6| Step: 6
Training loss: 0.8499894267714873
Validation loss: 2.905142241435489

Epoch: 6| Step: 7
Training loss: 0.6961962409299073
Validation loss: 2.898826997948048

Epoch: 6| Step: 8
Training loss: 0.9127946195121213
Validation loss: 2.9813929333601097

Epoch: 6| Step: 9
Training loss: 0.6923396173731343
Validation loss: 2.980862479411782

Epoch: 6| Step: 10
Training loss: 0.756762101047978
Validation loss: 3.042975331447472

Epoch: 6| Step: 11
Training loss: 0.6734290226449234
Validation loss: 3.0349498402023802

Epoch: 6| Step: 12
Training loss: 0.7585030781451477
Validation loss: 3.035749222850912

Epoch: 6| Step: 13
Training loss: 0.8486401170212102
Validation loss: 2.943033363599061

Epoch: 272| Step: 0
Training loss: 0.6361325613881623
Validation loss: 3.1712967920315847

Epoch: 6| Step: 1
Training loss: 0.7929422157997082
Validation loss: 2.995913437544789

Epoch: 6| Step: 2
Training loss: 0.9998462976112344
Validation loss: 3.085527288156838

Epoch: 6| Step: 3
Training loss: 0.6927415916279497
Validation loss: 3.1636263009009804

Epoch: 6| Step: 4
Training loss: 0.7247864129063463
Validation loss: 3.082044581266386

Epoch: 6| Step: 5
Training loss: 0.7323484663733111
Validation loss: 3.0812669522719927

Epoch: 6| Step: 6
Training loss: 0.7643598106790247
Validation loss: 2.9701488210980633

Epoch: 6| Step: 7
Training loss: 0.4570089807546146
Validation loss: 2.784315170404517

Epoch: 6| Step: 8
Training loss: 0.6637795687050263
Validation loss: 2.9753871943580203

Epoch: 6| Step: 9
Training loss: 0.7435093402186078
Validation loss: 2.9993136998461223

Epoch: 6| Step: 10
Training loss: 1.9127846325266986
Validation loss: 3.011201991480663

Epoch: 6| Step: 11
Training loss: 0.5635775999457926
Validation loss: 3.0824312402585123

Epoch: 6| Step: 12
Training loss: 1.1991833113115413
Validation loss: 2.9728420632261576

Epoch: 6| Step: 13
Training loss: 0.6087010153188396
Validation loss: 3.024174931349244

Epoch: 273| Step: 0
Training loss: 0.657564549595467
Validation loss: 3.0475949211244178

Epoch: 6| Step: 1
Training loss: 0.5112952598460234
Validation loss: 3.023776473199781

Epoch: 6| Step: 2
Training loss: 1.896363306551725
Validation loss: 3.128647735241195

Epoch: 6| Step: 3
Training loss: 0.692930491874009
Validation loss: 2.95281336248453

Epoch: 6| Step: 4
Training loss: 0.8324782196265852
Validation loss: 2.9915293873678106

Epoch: 6| Step: 5
Training loss: 1.100771139516756
Validation loss: 2.956786964905136

Epoch: 6| Step: 6
Training loss: 0.5329593758050841
Validation loss: 2.8908480996306154

Epoch: 6| Step: 7
Training loss: 0.8265424758418212
Validation loss: 3.0502992608262103

Epoch: 6| Step: 8
Training loss: 0.70340896806171
Validation loss: 2.998970424622866

Epoch: 6| Step: 9
Training loss: 0.7966230405516733
Validation loss: 2.9816427589241283

Epoch: 6| Step: 10
Training loss: 0.6546279525078387
Validation loss: 3.01297079235429

Epoch: 6| Step: 11
Training loss: 0.621017811289423
Validation loss: 3.0151467874747535

Epoch: 6| Step: 12
Training loss: 0.5713658729496894
Validation loss: 3.074359481802345

Epoch: 6| Step: 13
Training loss: 0.7795088630255594
Validation loss: 3.046673212134789

Epoch: 274| Step: 0
Training loss: 0.6978926203746277
Validation loss: 3.029904135581857

Epoch: 6| Step: 1
Training loss: 0.7345414074599361
Validation loss: 3.0031016263869255

Epoch: 6| Step: 2
Training loss: 0.40795047369891013
Validation loss: 3.0403432623410387

Epoch: 6| Step: 3
Training loss: 0.7389156300463005
Validation loss: 3.03167911651415

Epoch: 6| Step: 4
Training loss: 0.7944316805375126
Validation loss: 2.9921945118635205

Epoch: 6| Step: 5
Training loss: 0.6975515511306908
Validation loss: 2.9342920764910367

Epoch: 6| Step: 6
Training loss: 0.8477200954318439
Validation loss: 2.925166786633615

Epoch: 6| Step: 7
Training loss: 0.8793621999843361
Validation loss: 2.8885986305083198

Epoch: 6| Step: 8
Training loss: 1.1289314874382181
Validation loss: 2.923586950758542

Epoch: 6| Step: 9
Training loss: 0.5342864604570265
Validation loss: 3.027681183416461

Epoch: 6| Step: 10
Training loss: 1.7603950348678081
Validation loss: 2.9525709355699736

Epoch: 6| Step: 11
Training loss: 0.7100447194697321
Validation loss: 2.8731846952457096

Epoch: 6| Step: 12
Training loss: 0.8611832062132286
Validation loss: 2.967181022038351

Epoch: 6| Step: 13
Training loss: 0.6192577985242466
Validation loss: 3.011058914859063

Epoch: 275| Step: 0
Training loss: 0.9420313362530283
Validation loss: 2.9803551035187863

Epoch: 6| Step: 1
Training loss: 0.9270108583960425
Validation loss: 3.052859462616706

Epoch: 6| Step: 2
Training loss: 0.7247740360523212
Validation loss: 3.0728255996572296

Epoch: 6| Step: 3
Training loss: 0.6180780239402646
Validation loss: 2.9626534487958507

Epoch: 6| Step: 4
Training loss: 1.9111202124568674
Validation loss: 3.0553582277062743

Epoch: 6| Step: 5
Training loss: 0.4686793909934348
Validation loss: 2.992867906199698

Epoch: 6| Step: 6
Training loss: 0.511743355661781
Validation loss: 2.9537430508392335

Epoch: 6| Step: 7
Training loss: 0.667797579779385
Validation loss: 2.95343408867678

Epoch: 6| Step: 8
Training loss: 0.3282775751241377
Validation loss: 3.013059694418164

Epoch: 6| Step: 9
Training loss: 0.6349275822533745
Validation loss: 3.092289679511074

Epoch: 6| Step: 10
Training loss: 0.7396347314588632
Validation loss: 3.094810349082645

Epoch: 6| Step: 11
Training loss: 0.931402979836869
Validation loss: 3.051936609345645

Epoch: 6| Step: 12
Training loss: 0.785509551919594
Validation loss: 3.02870060528697

Epoch: 6| Step: 13
Training loss: 0.31019349054796586
Validation loss: 3.0216752337043062

Epoch: 276| Step: 0
Training loss: 0.8991177181488375
Validation loss: 2.9830684764512094

Epoch: 6| Step: 1
Training loss: 0.6070385180103278
Validation loss: 3.2251860089343927

Epoch: 6| Step: 2
Training loss: 1.749034751629723
Validation loss: 2.992033248125901

Epoch: 6| Step: 3
Training loss: 0.6866779614726374
Validation loss: 3.1182566556435165

Epoch: 6| Step: 4
Training loss: 0.8825542443546249
Validation loss: 2.982848744133061

Epoch: 6| Step: 5
Training loss: 0.8175742814966543
Validation loss: 3.0972763155635907

Epoch: 6| Step: 6
Training loss: 0.48502586074586773
Validation loss: 3.013230369533256

Epoch: 6| Step: 7
Training loss: 0.6711372050559065
Validation loss: 3.0212252570914537

Epoch: 6| Step: 8
Training loss: 0.9425313723778986
Validation loss: 3.015592927383351

Epoch: 6| Step: 9
Training loss: 0.7831974933069812
Validation loss: 3.0541885241619315

Epoch: 6| Step: 10
Training loss: 0.7717907261113591
Validation loss: 3.0249729249861748

Epoch: 6| Step: 11
Training loss: 0.8793857199117834
Validation loss: 3.043061319884793

Epoch: 6| Step: 12
Training loss: 0.6924240896298668
Validation loss: 3.100042827628253

Epoch: 6| Step: 13
Training loss: 0.5076507310693534
Validation loss: 3.049914260868173

Epoch: 277| Step: 0
Training loss: 0.8026503915779015
Validation loss: 3.11634260692625

Epoch: 6| Step: 1
Training loss: 1.006175937651791
Validation loss: 3.049037407276612

Epoch: 6| Step: 2
Training loss: 0.6441216525585474
Validation loss: 2.994106862374874

Epoch: 6| Step: 3
Training loss: 0.6885150222316861
Validation loss: 2.9749300026873375

Epoch: 6| Step: 4
Training loss: 1.1327778778047026
Validation loss: 3.130872041450971

Epoch: 6| Step: 5
Training loss: 0.4557294972736431
Validation loss: 2.938480098709982

Epoch: 6| Step: 6
Training loss: 1.7772986773131032
Validation loss: 2.973996622581762

Epoch: 6| Step: 7
Training loss: 0.8007062551225262
Validation loss: 2.996293281366705

Epoch: 6| Step: 8
Training loss: 0.7393587917766634
Validation loss: 3.031371438651533

Epoch: 6| Step: 9
Training loss: 0.7580104058213215
Validation loss: 2.9833400522898734

Epoch: 6| Step: 10
Training loss: 0.4661118976309537
Validation loss: 3.0989505265508885

Epoch: 6| Step: 11
Training loss: 0.7261378370067385
Validation loss: 2.9713616177428976

Epoch: 6| Step: 12
Training loss: 0.6168353367724587
Validation loss: 3.0200790033469844

Epoch: 6| Step: 13
Training loss: 0.6193995370633418
Validation loss: 3.0195131815394007

Epoch: 278| Step: 0
Training loss: 0.6731568019229459
Validation loss: 3.055501278241052

Epoch: 6| Step: 1
Training loss: 0.6225168969645548
Validation loss: 2.9815449102954603

Epoch: 6| Step: 2
Training loss: 1.7586571592595008
Validation loss: 3.0254373039911546

Epoch: 6| Step: 3
Training loss: 0.9036024488135596
Validation loss: 2.9651901451540574

Epoch: 6| Step: 4
Training loss: 0.7085215000721242
Validation loss: 2.982966225341125

Epoch: 6| Step: 5
Training loss: 0.6875797138817739
Validation loss: 3.0443912130963215

Epoch: 6| Step: 6
Training loss: 0.7029102633315936
Validation loss: 3.0845625763979307

Epoch: 6| Step: 7
Training loss: 0.5927733872239219
Validation loss: 2.9257790022647443

Epoch: 6| Step: 8
Training loss: 0.6080035402201179
Validation loss: 2.942157826651327

Epoch: 6| Step: 9
Training loss: 1.0497124209998911
Validation loss: 3.120936409267078

Epoch: 6| Step: 10
Training loss: 0.7071986974890827
Validation loss: 2.9045388643192087

Epoch: 6| Step: 11
Training loss: 0.49056229889265707
Validation loss: 2.9818122472205317

Epoch: 6| Step: 12
Training loss: 0.5278053523969273
Validation loss: 3.0093488724453423

Epoch: 6| Step: 13
Training loss: 0.878337930676941
Validation loss: 3.1272036348634864

Epoch: 279| Step: 0
Training loss: 0.4494741957453341
Validation loss: 2.9290668016523753

Epoch: 6| Step: 1
Training loss: 0.5497605897283361
Validation loss: 2.9059812496715436

Epoch: 6| Step: 2
Training loss: 0.6028422330224524
Validation loss: 3.069306834163114

Epoch: 6| Step: 3
Training loss: 0.8146605010363842
Validation loss: 2.9638490880573802

Epoch: 6| Step: 4
Training loss: 0.7977165565521837
Validation loss: 2.9672043106007333

Epoch: 6| Step: 5
Training loss: 0.9297432441989102
Validation loss: 3.0431784744040584

Epoch: 6| Step: 6
Training loss: 0.5672177519493954
Validation loss: 3.001987500925663

Epoch: 6| Step: 7
Training loss: 0.6111400912257674
Validation loss: 3.0774484914047795

Epoch: 6| Step: 8
Training loss: 1.7088678810742044
Validation loss: 2.943994228763383

Epoch: 6| Step: 9
Training loss: 0.49953892429579166
Validation loss: 3.048826821665187

Epoch: 6| Step: 10
Training loss: 0.7856713877770611
Validation loss: 2.972433929885471

Epoch: 6| Step: 11
Training loss: 0.8409574709150746
Validation loss: 3.0086593426627166

Epoch: 6| Step: 12
Training loss: 1.0302653380161488
Validation loss: 3.0930297218602463

Epoch: 6| Step: 13
Training loss: 0.8203478850952571
Validation loss: 2.978490276958397

Epoch: 280| Step: 0
Training loss: 0.6519391066939448
Validation loss: 3.106374254306391

Epoch: 6| Step: 1
Training loss: 1.76832778797964
Validation loss: 3.0046372204278526

Epoch: 6| Step: 2
Training loss: 0.8429898970870774
Validation loss: 3.0898090526177486

Epoch: 6| Step: 3
Training loss: 0.7034337107803327
Validation loss: 3.044804265538574

Epoch: 6| Step: 4
Training loss: 0.825802948377025
Validation loss: 3.046747449503672

Epoch: 6| Step: 5
Training loss: 0.7482517051639112
Validation loss: 3.069637777723258

Epoch: 6| Step: 6
Training loss: 0.6364905761776267
Validation loss: 3.0762482035214562

Epoch: 6| Step: 7
Training loss: 1.0543823931151615
Validation loss: 3.078614481623973

Epoch: 6| Step: 8
Training loss: 0.6745230367132651
Validation loss: 3.061250911996523

Epoch: 6| Step: 9
Training loss: 0.570532194698538
Validation loss: 3.0356015959160736

Epoch: 6| Step: 10
Training loss: 0.9125617659580008
Validation loss: 3.118398279859037

Epoch: 6| Step: 11
Training loss: 0.8048271132156603
Validation loss: 2.852517637777225

Epoch: 6| Step: 12
Training loss: 0.6183429236280973
Validation loss: 2.894573518527657

Epoch: 6| Step: 13
Training loss: 0.5994015311692862
Validation loss: 3.0752273578898244

Epoch: 281| Step: 0
Training loss: 0.613132361543813
Validation loss: 2.9324430265146977

Epoch: 6| Step: 1
Training loss: 0.9292291745655807
Validation loss: 3.0797453357640467

Epoch: 6| Step: 2
Training loss: 0.7891484204337699
Validation loss: 3.0708724490865884

Epoch: 6| Step: 3
Training loss: 0.45855082062396274
Validation loss: 3.038171802739139

Epoch: 6| Step: 4
Training loss: 0.9851779992820943
Validation loss: 3.0819630585102096

Epoch: 6| Step: 5
Training loss: 0.8770898657137943
Validation loss: 2.9972605250773534

Epoch: 6| Step: 6
Training loss: 0.7766253348091469
Validation loss: 3.1217702833400454

Epoch: 6| Step: 7
Training loss: 0.8845966843076521
Validation loss: 3.051826965362331

Epoch: 6| Step: 8
Training loss: 0.6556570007834825
Validation loss: 3.1208048190625246

Epoch: 6| Step: 9
Training loss: 0.7248860368278172
Validation loss: 3.0211320181324255

Epoch: 6| Step: 10
Training loss: 0.8238316209844623
Validation loss: 3.072237829885757

Epoch: 6| Step: 11
Training loss: 1.7132483079546503
Validation loss: 3.118563432024813

Epoch: 6| Step: 12
Training loss: 0.5199524742195988
Validation loss: 3.0768053030359295

Epoch: 6| Step: 13
Training loss: 0.672654675383281
Validation loss: 3.020250071199261

Epoch: 282| Step: 0
Training loss: 0.5584392200479771
Validation loss: 3.0241327201099186

Epoch: 6| Step: 1
Training loss: 0.5019926656741969
Validation loss: 3.027188191672885

Epoch: 6| Step: 2
Training loss: 0.6402713450754353
Validation loss: 3.0371622585913647

Epoch: 6| Step: 3
Training loss: 0.5835005883718105
Validation loss: 2.994439176740792

Epoch: 6| Step: 4
Training loss: 0.8540717436607431
Validation loss: 2.988121543722169

Epoch: 6| Step: 5
Training loss: 0.41058958867637796
Validation loss: 3.0725102085764395

Epoch: 6| Step: 6
Training loss: 1.7567148129755745
Validation loss: 2.974317503360923

Epoch: 6| Step: 7
Training loss: 1.0469375705524262
Validation loss: 2.9766632223233938

Epoch: 6| Step: 8
Training loss: 0.6491357651612494
Validation loss: 3.0785390959394623

Epoch: 6| Step: 9
Training loss: 0.5024551968030462
Validation loss: 2.9737799346558855

Epoch: 6| Step: 10
Training loss: 0.8980266129048468
Validation loss: 3.105040207570274

Epoch: 6| Step: 11
Training loss: 1.000464689052001
Validation loss: 2.99205578546486

Epoch: 6| Step: 12
Training loss: 0.7385473831307043
Validation loss: 3.000232528575894

Epoch: 6| Step: 13
Training loss: 0.7161492272498887
Validation loss: 3.0601355579161313

Epoch: 283| Step: 0
Training loss: 0.5259019426915986
Validation loss: 2.962226164511445

Epoch: 6| Step: 1
Training loss: 0.635128985355864
Validation loss: 3.014856467871372

Epoch: 6| Step: 2
Training loss: 0.7003082014136629
Validation loss: 2.995087124168148

Epoch: 6| Step: 3
Training loss: 0.6706082800765554
Validation loss: 2.975725258116584

Epoch: 6| Step: 4
Training loss: 0.48516384616378355
Validation loss: 2.9724710935658147

Epoch: 6| Step: 5
Training loss: 0.5704761949532436
Validation loss: 2.9879540889724545

Epoch: 6| Step: 6
Training loss: 1.0065524481929071
Validation loss: 3.0215104276014353

Epoch: 6| Step: 7
Training loss: 1.7924539994810849
Validation loss: 2.9994379947674106

Epoch: 6| Step: 8
Training loss: 1.0042355958277371
Validation loss: 3.1434083817450524

Epoch: 6| Step: 9
Training loss: 0.5124563477696864
Validation loss: 3.0367137524513215

Epoch: 6| Step: 10
Training loss: 0.8335703909978761
Validation loss: 3.1258056492207964

Epoch: 6| Step: 11
Training loss: 0.6946155827302485
Validation loss: 3.0411217519298086

Epoch: 6| Step: 12
Training loss: 0.6429747311208461
Validation loss: 3.044100758566319

Epoch: 6| Step: 13
Training loss: 0.715057966310119
Validation loss: 3.014931119634939

Epoch: 284| Step: 0
Training loss: 0.7815189661517857
Validation loss: 3.110279226534905

Epoch: 6| Step: 1
Training loss: 0.4818461144543507
Validation loss: 3.0068072864554645

Epoch: 6| Step: 2
Training loss: 0.7015909626715807
Validation loss: 3.0574783493485658

Epoch: 6| Step: 3
Training loss: 0.745900873148763
Validation loss: 3.020580140826621

Epoch: 6| Step: 4
Training loss: 0.730073015859493
Validation loss: 2.9900726201521204

Epoch: 6| Step: 5
Training loss: 0.7600010994853047
Validation loss: 3.040949689068218

Epoch: 6| Step: 6
Training loss: 0.85798247829855
Validation loss: 3.037961157183171

Epoch: 6| Step: 7
Training loss: 0.8037340014869218
Validation loss: 3.070553835636813

Epoch: 6| Step: 8
Training loss: 1.7530234649140977
Validation loss: 3.051970187922772

Epoch: 6| Step: 9
Training loss: 0.8127460107297687
Validation loss: 3.0922814682453073

Epoch: 6| Step: 10
Training loss: 0.5525114330990257
Validation loss: 2.9913162144836436

Epoch: 6| Step: 11
Training loss: 0.8331026155250564
Validation loss: 2.9910406001277465

Epoch: 6| Step: 12
Training loss: 0.7663807933752037
Validation loss: 3.0228812324520566

Epoch: 6| Step: 13
Training loss: 0.6237264771316592
Validation loss: 3.0705246791372707

Epoch: 285| Step: 0
Training loss: 0.5524068879943157
Validation loss: 3.0585803554951294

Epoch: 6| Step: 1
Training loss: 0.7294731903666608
Validation loss: 2.991393100872017

Epoch: 6| Step: 2
Training loss: 0.7554506285899419
Validation loss: 2.9688485112493357

Epoch: 6| Step: 3
Training loss: 1.8251855808119037
Validation loss: 2.9131990709799784

Epoch: 6| Step: 4
Training loss: 0.7926461075476592
Validation loss: 3.1507382627758553

Epoch: 6| Step: 5
Training loss: 0.5058612602522785
Validation loss: 3.039362385131587

Epoch: 6| Step: 6
Training loss: 0.7012007343441806
Validation loss: 2.9507884582910893

Epoch: 6| Step: 7
Training loss: 0.3585297138823249
Validation loss: 3.16300789796766

Epoch: 6| Step: 8
Training loss: 0.6879502902563972
Validation loss: 3.0781797994780016

Epoch: 6| Step: 9
Training loss: 0.9312912387805672
Validation loss: 2.9350665950205985

Epoch: 6| Step: 10
Training loss: 0.9840037841821029
Validation loss: 2.986670458449216

Epoch: 6| Step: 11
Training loss: 0.7386277208289432
Validation loss: 3.02267141436134

Epoch: 6| Step: 12
Training loss: 0.525750756477686
Validation loss: 2.968506839899595

Epoch: 6| Step: 13
Training loss: 0.42327950827520805
Validation loss: 2.9997747389675666

Epoch: 286| Step: 0
Training loss: 1.7178837760807155
Validation loss: 2.9983599073777873

Epoch: 6| Step: 1
Training loss: 0.9790458841432836
Validation loss: 2.9065114112243693

Epoch: 6| Step: 2
Training loss: 0.5880481597614711
Validation loss: 3.054834386703801

Epoch: 6| Step: 3
Training loss: 0.6441227398593425
Validation loss: 2.975122071547952

Epoch: 6| Step: 4
Training loss: 0.948646215760811
Validation loss: 3.128428904950547

Epoch: 6| Step: 5
Training loss: 0.5827811613682669
Validation loss: 2.9188686959353496

Epoch: 6| Step: 6
Training loss: 0.5024293354983025
Validation loss: 3.0337219842540075

Epoch: 6| Step: 7
Training loss: 0.7417361041221225
Validation loss: 3.1010225404135245

Epoch: 6| Step: 8
Training loss: 0.5807568724542151
Validation loss: 3.056894960069847

Epoch: 6| Step: 9
Training loss: 0.8159757145114773
Validation loss: 3.0708123755462333

Epoch: 6| Step: 10
Training loss: 0.86479310091568
Validation loss: 2.991544211138564

Epoch: 6| Step: 11
Training loss: 0.6270627790443015
Validation loss: 3.056278578631773

Epoch: 6| Step: 12
Training loss: 0.3587289684058871
Validation loss: 3.111082914674989

Epoch: 6| Step: 13
Training loss: 0.6710613114107628
Validation loss: 2.933155445282536

Epoch: 287| Step: 0
Training loss: 0.5945146305202537
Validation loss: 2.9004575642440256

Epoch: 6| Step: 1
Training loss: 0.6560208965206467
Validation loss: 3.081570550985238

Epoch: 6| Step: 2
Training loss: 0.5639457137921638
Validation loss: 2.9966099181298733

Epoch: 6| Step: 3
Training loss: 0.5475012871539867
Validation loss: 3.0305318997752893

Epoch: 6| Step: 4
Training loss: 0.5117976295303748
Validation loss: 3.035446644052229

Epoch: 6| Step: 5
Training loss: 0.5331338411248778
Validation loss: 3.035359026052431

Epoch: 6| Step: 6
Training loss: 0.6178209699591374
Validation loss: 2.8683148488304915

Epoch: 6| Step: 7
Training loss: 0.897568522948221
Validation loss: 3.100215577761648

Epoch: 6| Step: 8
Training loss: 0.7056215680480697
Validation loss: 3.104877625192081

Epoch: 6| Step: 9
Training loss: 0.7134419438829009
Validation loss: 3.037651420869232

Epoch: 6| Step: 10
Training loss: 0.7078436720428147
Validation loss: 3.0209208815592956

Epoch: 6| Step: 11
Training loss: 0.8669530534430553
Validation loss: 3.0687024762215307

Epoch: 6| Step: 12
Training loss: 0.7010679460184582
Validation loss: 3.067033999063167

Epoch: 6| Step: 13
Training loss: 1.812122963461528
Validation loss: 2.9466071146309742

Epoch: 288| Step: 0
Training loss: 0.5263363859262462
Validation loss: 3.1009106467523124

Epoch: 6| Step: 1
Training loss: 0.5107437046240015
Validation loss: 3.0280377386253474

Epoch: 6| Step: 2
Training loss: 0.6126813201717158
Validation loss: 2.9661284801499126

Epoch: 6| Step: 3
Training loss: 0.8291952307172455
Validation loss: 3.127351499203717

Epoch: 6| Step: 4
Training loss: 0.6770001702709914
Validation loss: 3.0107898722817543

Epoch: 6| Step: 5
Training loss: 0.5929593544116394
Validation loss: 3.0558712772093872

Epoch: 6| Step: 6
Training loss: 0.6097131426730661
Validation loss: 3.120896149747138

Epoch: 6| Step: 7
Training loss: 0.702829934833003
Validation loss: 3.0901079800327897

Epoch: 6| Step: 8
Training loss: 0.6298980474477817
Validation loss: 3.047825161404899

Epoch: 6| Step: 9
Training loss: 0.591331701984793
Validation loss: 2.942640635744163

Epoch: 6| Step: 10
Training loss: 0.6969994215805522
Validation loss: 3.020997882614564

Epoch: 6| Step: 11
Training loss: 0.4681223004445364
Validation loss: 3.0520398307191043

Epoch: 6| Step: 12
Training loss: 2.0426058911967595
Validation loss: 2.8424666027387446

Epoch: 6| Step: 13
Training loss: 0.8351651482960024
Validation loss: 2.9875728523809917

Epoch: 289| Step: 0
Training loss: 0.7209268858367609
Validation loss: 3.049029639926071

Epoch: 6| Step: 1
Training loss: 0.6794644132169673
Validation loss: 2.925268151145039

Epoch: 6| Step: 2
Training loss: 0.592648991148848
Validation loss: 2.9449683678940812

Epoch: 6| Step: 3
Training loss: 0.6655476287862604
Validation loss: 3.004426763088759

Epoch: 6| Step: 4
Training loss: 1.6222613071206908
Validation loss: 3.005380256446735

Epoch: 6| Step: 5
Training loss: 0.590543950287225
Validation loss: 3.0701110359597994

Epoch: 6| Step: 6
Training loss: 0.7102598377044623
Validation loss: 2.9139139446065787

Epoch: 6| Step: 7
Training loss: 0.5855289306334092
Validation loss: 3.011663044679452

Epoch: 6| Step: 8
Training loss: 0.9291163060235602
Validation loss: 2.987866966767984

Epoch: 6| Step: 9
Training loss: 0.9474406287179826
Validation loss: 2.952876839142873

Epoch: 6| Step: 10
Training loss: 0.6299574223768786
Validation loss: 3.0366957731418798

Epoch: 6| Step: 11
Training loss: 0.6209402794432576
Validation loss: 2.966021083299416

Epoch: 6| Step: 12
Training loss: 0.9642450119692635
Validation loss: 2.9849801240618183

Epoch: 6| Step: 13
Training loss: 0.7256267633671326
Validation loss: 2.973030845376006

Epoch: 290| Step: 0
Training loss: 0.7374769401177947
Validation loss: 3.071106423838906

Epoch: 6| Step: 1
Training loss: 0.6207507643954194
Validation loss: 2.9888340789783214

Epoch: 6| Step: 2
Training loss: 0.6516257806506549
Validation loss: 3.0214041247372467

Epoch: 6| Step: 3
Training loss: 0.506023836833408
Validation loss: 2.9467148414689865

Epoch: 6| Step: 4
Training loss: 0.4416037598681371
Validation loss: 3.0618096306581624

Epoch: 6| Step: 5
Training loss: 0.5637142268585736
Validation loss: 3.1011659639354

Epoch: 6| Step: 6
Training loss: 0.6031673377005997
Validation loss: 2.9128988634112103

Epoch: 6| Step: 7
Training loss: 0.6870207199667416
Validation loss: 3.028559050733921

Epoch: 6| Step: 8
Training loss: 0.6390496865925619
Validation loss: 3.098762151241137

Epoch: 6| Step: 9
Training loss: 0.6870987544884439
Validation loss: 3.0752580720488383

Epoch: 6| Step: 10
Training loss: 1.7896996575394368
Validation loss: 3.110117863489509

Epoch: 6| Step: 11
Training loss: 0.995262547172177
Validation loss: 2.8865862288144495

Epoch: 6| Step: 12
Training loss: 0.7022064354808898
Validation loss: 3.0390838517695

Epoch: 6| Step: 13
Training loss: 0.6742936005489085
Validation loss: 2.9803036385294757

Epoch: 291| Step: 0
Training loss: 0.4932340968797662
Validation loss: 2.9888114508705597

Epoch: 6| Step: 1
Training loss: 1.71938887773222
Validation loss: 2.9708260488398532

Epoch: 6| Step: 2
Training loss: 0.7850694750759999
Validation loss: 2.9901952128438207

Epoch: 6| Step: 3
Training loss: 0.6044948004695394
Validation loss: 2.980867211740595

Epoch: 6| Step: 4
Training loss: 0.6023001421271924
Validation loss: 2.992501955299939

Epoch: 6| Step: 5
Training loss: 0.8150480370903869
Validation loss: 2.987234400138164

Epoch: 6| Step: 6
Training loss: 0.6576088506285156
Validation loss: 3.0110152858260397

Epoch: 6| Step: 7
Training loss: 0.4976079315491377
Validation loss: 3.086389217231541

Epoch: 6| Step: 8
Training loss: 0.8266653836981241
Validation loss: 3.102598041457723

Epoch: 6| Step: 9
Training loss: 0.6373072987443631
Validation loss: 2.9824678941668292

Epoch: 6| Step: 10
Training loss: 0.7089204785687052
Validation loss: 2.96540101535003

Epoch: 6| Step: 11
Training loss: 0.6787886540767909
Validation loss: 3.071621668301969

Epoch: 6| Step: 12
Training loss: 0.6378222305624685
Validation loss: 2.974789856720186

Epoch: 6| Step: 13
Training loss: 1.0196906655742062
Validation loss: 2.981961484363965

Epoch: 292| Step: 0
Training loss: 0.6803307394404713
Validation loss: 3.0023615337357668

Epoch: 6| Step: 1
Training loss: 0.9060360886247196
Validation loss: 3.0333152958225345

Epoch: 6| Step: 2
Training loss: 0.9426924913174711
Validation loss: 3.0973037961776773

Epoch: 6| Step: 3
Training loss: 1.8105030239683622
Validation loss: 3.1334879108271028

Epoch: 6| Step: 4
Training loss: 0.8194028624708304
Validation loss: 3.0967343446961983

Epoch: 6| Step: 5
Training loss: 0.6314724520778039
Validation loss: 3.04501899203854

Epoch: 6| Step: 6
Training loss: 0.9178497237286809
Validation loss: 3.120602972970433

Epoch: 6| Step: 7
Training loss: 0.7210118735998376
Validation loss: 3.1284809561685254

Epoch: 6| Step: 8
Training loss: 0.5443359287400206
Validation loss: 3.078662483292066

Epoch: 6| Step: 9
Training loss: 0.48394634907182155
Validation loss: 3.1316169747075793

Epoch: 6| Step: 10
Training loss: 0.7451409452358035
Validation loss: 3.114594288342112

Epoch: 6| Step: 11
Training loss: 0.49450212004142496
Validation loss: 3.040734479187172

Epoch: 6| Step: 12
Training loss: 0.6092183327410498
Validation loss: 2.9093825572701384

Epoch: 6| Step: 13
Training loss: 0.5961013963441408
Validation loss: 2.9624277221404145

Epoch: 293| Step: 0
Training loss: 1.0896015513388055
Validation loss: 3.060702165998375

Epoch: 6| Step: 1
Training loss: 0.6309749391131423
Validation loss: 2.9546207629567456

Epoch: 6| Step: 2
Training loss: 1.6528004405215877
Validation loss: 2.9712512271222193

Epoch: 6| Step: 3
Training loss: 0.711273114142248
Validation loss: 2.977673434233127

Epoch: 6| Step: 4
Training loss: 0.6770309183422326
Validation loss: 2.9576168580667934

Epoch: 6| Step: 5
Training loss: 0.6532673949747976
Validation loss: 3.0397862387362014

Epoch: 6| Step: 6
Training loss: 0.6511021522399104
Validation loss: 3.067975579339905

Epoch: 6| Step: 7
Training loss: 0.38376495052626436
Validation loss: 3.1001657180176276

Epoch: 6| Step: 8
Training loss: 0.7222637038259502
Validation loss: 3.0419477872838177

Epoch: 6| Step: 9
Training loss: 0.5175138037678817
Validation loss: 3.035721577707717

Epoch: 6| Step: 10
Training loss: 0.7287643866975557
Validation loss: 3.001710232050159

Epoch: 6| Step: 11
Training loss: 0.8161279669491693
Validation loss: 3.0638237901213996

Epoch: 6| Step: 12
Training loss: 0.8214389151757124
Validation loss: 3.173424916795745

Epoch: 6| Step: 13
Training loss: 0.6192270453275477
Validation loss: 3.016145071667326

Epoch: 294| Step: 0
Training loss: 0.5072617111395821
Validation loss: 3.0324831548413194

Epoch: 6| Step: 1
Training loss: 0.6691772949717533
Validation loss: 3.008107898292881

Epoch: 6| Step: 2
Training loss: 0.8767497415185987
Validation loss: 3.0746225869776125

Epoch: 6| Step: 3
Training loss: 0.7459787409951802
Validation loss: 3.0411606372059827

Epoch: 6| Step: 4
Training loss: 0.7564996575243188
Validation loss: 3.0168968246362833

Epoch: 6| Step: 5
Training loss: 1.705551868183459
Validation loss: 3.074531587729707

Epoch: 6| Step: 6
Training loss: 0.6431791978544341
Validation loss: 3.0431508575780377

Epoch: 6| Step: 7
Training loss: 1.040238940593858
Validation loss: 3.053897817383245

Epoch: 6| Step: 8
Training loss: 0.7296253169681396
Validation loss: 3.1431995391502876

Epoch: 6| Step: 9
Training loss: 0.6940942013511378
Validation loss: 3.0351915721564486

Epoch: 6| Step: 10
Training loss: 0.757731207193883
Validation loss: 3.042885697177741

Epoch: 6| Step: 11
Training loss: 0.691934373094786
Validation loss: 3.152286760649379

Epoch: 6| Step: 12
Training loss: 0.4488463641279597
Validation loss: 2.97886661983727

Epoch: 6| Step: 13
Training loss: 0.935797958288556
Validation loss: 2.9962328331871575

Epoch: 295| Step: 0
Training loss: 0.6718437498055301
Validation loss: 3.171529278134062

Epoch: 6| Step: 1
Training loss: 0.48222313003276357
Validation loss: 3.066835954043263

Epoch: 6| Step: 2
Training loss: 1.0191242092414445
Validation loss: 2.8994792837959835

Epoch: 6| Step: 3
Training loss: 0.5590715032527439
Validation loss: 3.028995540740294

Epoch: 6| Step: 4
Training loss: 0.6436234525720098
Validation loss: 2.979238607075984

Epoch: 6| Step: 5
Training loss: 0.4056777591808255
Validation loss: 2.969404757390802

Epoch: 6| Step: 6
Training loss: 0.7171664831202783
Validation loss: 2.961741221778792

Epoch: 6| Step: 7
Training loss: 0.6195692630376767
Validation loss: 3.0596993933855514

Epoch: 6| Step: 8
Training loss: 0.6585064650285565
Validation loss: 3.0740917652987956

Epoch: 6| Step: 9
Training loss: 1.6687735195145517
Validation loss: 3.098131051220838

Epoch: 6| Step: 10
Training loss: 0.8854148116746806
Validation loss: 3.059402534275236

Epoch: 6| Step: 11
Training loss: 0.7810160858925264
Validation loss: 3.0464041843352847

Epoch: 6| Step: 12
Training loss: 0.709972942938169
Validation loss: 3.0625974678566674

Epoch: 6| Step: 13
Training loss: 0.7425997342131551
Validation loss: 3.075040494967489

Epoch: 296| Step: 0
Training loss: 0.829544111027467
Validation loss: 3.0806108174146223

Epoch: 6| Step: 1
Training loss: 1.8220974925366507
Validation loss: 3.038186398934505

Epoch: 6| Step: 2
Training loss: 0.6412711025506111
Validation loss: 3.071537811928349

Epoch: 6| Step: 3
Training loss: 0.5264117446753049
Validation loss: 2.9589837975496205

Epoch: 6| Step: 4
Training loss: 0.504478868522086
Validation loss: 2.9385864196708633

Epoch: 6| Step: 5
Training loss: 0.7099568237017593
Validation loss: 3.0944820398534856

Epoch: 6| Step: 6
Training loss: 0.8515306519318635
Validation loss: 3.094903095250494

Epoch: 6| Step: 7
Training loss: 0.6336094112318621
Validation loss: 3.0870442268969107

Epoch: 6| Step: 8
Training loss: 0.5386878660621023
Validation loss: 3.040164188857535

Epoch: 6| Step: 9
Training loss: 1.1442733317807887
Validation loss: 3.116879198576238

Epoch: 6| Step: 10
Training loss: 0.675839857084849
Validation loss: 2.9995942304960557

Epoch: 6| Step: 11
Training loss: 0.6466320595214878
Validation loss: 3.1160890688288214

Epoch: 6| Step: 12
Training loss: 0.6366575714863062
Validation loss: 3.0471684958447884

Epoch: 6| Step: 13
Training loss: 0.46803149151405815
Validation loss: 3.137608548803159

Epoch: 297| Step: 0
Training loss: 0.8536146442580069
Validation loss: 2.9762035296925884

Epoch: 6| Step: 1
Training loss: 0.7533032075870131
Validation loss: 3.1250936875604665

Epoch: 6| Step: 2
Training loss: 1.7362646857259194
Validation loss: 2.982978907013644

Epoch: 6| Step: 3
Training loss: 0.47622055543404224
Validation loss: 3.046755600896541

Epoch: 6| Step: 4
Training loss: 0.5004772948012907
Validation loss: 2.966074169299076

Epoch: 6| Step: 5
Training loss: 0.790592146179558
Validation loss: 2.9837703791395036

Epoch: 6| Step: 6
Training loss: 0.9518198864736824
Validation loss: 3.133662729162702

Epoch: 6| Step: 7
Training loss: 0.6336141147939055
Validation loss: 3.0955690116191263

Epoch: 6| Step: 8
Training loss: 0.7775113485802124
Validation loss: 3.0667775571165543

Epoch: 6| Step: 9
Training loss: 0.7059076981926282
Validation loss: 3.044631549402426

Epoch: 6| Step: 10
Training loss: 0.6544991707151797
Validation loss: 3.0151530738211956

Epoch: 6| Step: 11
Training loss: 0.6314725228702525
Validation loss: 3.143700228044941

Epoch: 6| Step: 12
Training loss: 0.342923471160037
Validation loss: 3.1036018694094905

Epoch: 6| Step: 13
Training loss: 0.382460062148509
Validation loss: 2.9886730194920585

Epoch: 298| Step: 0
Training loss: 1.720746146972989
Validation loss: 3.0662865876582033

Epoch: 6| Step: 1
Training loss: 0.5232586341542875
Validation loss: 2.9744554940302943

Epoch: 6| Step: 2
Training loss: 0.4141060968155657
Validation loss: 2.9920773265930434

Epoch: 6| Step: 3
Training loss: 0.4412365984029719
Validation loss: 3.072951653922524

Epoch: 6| Step: 4
Training loss: 0.4393931708234485
Validation loss: 3.0537240670896524

Epoch: 6| Step: 5
Training loss: 0.9929975071786437
Validation loss: 3.0568300166174383

Epoch: 6| Step: 6
Training loss: 0.6024724592744376
Validation loss: 3.0588681360609185

Epoch: 6| Step: 7
Training loss: 0.5229839808488863
Validation loss: 3.0580291941562976

Epoch: 6| Step: 8
Training loss: 0.6470414495781184
Validation loss: 2.982028751240657

Epoch: 6| Step: 9
Training loss: 0.5766154763712695
Validation loss: 3.029001798345234

Epoch: 6| Step: 10
Training loss: 0.587435371821226
Validation loss: 3.0802108745717125

Epoch: 6| Step: 11
Training loss: 0.639338247784822
Validation loss: 2.970356342675048

Epoch: 6| Step: 12
Training loss: 0.739995550516
Validation loss: 3.0781112644773385

Epoch: 6| Step: 13
Training loss: 0.5659190219872641
Validation loss: 3.0009498814312145

Epoch: 299| Step: 0
Training loss: 0.5550606238272578
Validation loss: 3.0361146988711303

Epoch: 6| Step: 1
Training loss: 0.6476802080644516
Validation loss: 2.9951317281735945

Epoch: 6| Step: 2
Training loss: 0.5093509843933802
Validation loss: 3.005919312327141

Epoch: 6| Step: 3
Training loss: 0.5816183481760424
Validation loss: 3.0201744851912387

Epoch: 6| Step: 4
Training loss: 1.059357540020491
Validation loss: 3.042002781277534

Epoch: 6| Step: 5
Training loss: 0.5536976430867928
Validation loss: 2.9475246388940004

Epoch: 6| Step: 6
Training loss: 0.6397038792468545
Validation loss: 3.0481817589547027

Epoch: 6| Step: 7
Training loss: 0.49683822879642314
Validation loss: 3.0888632252615804

Epoch: 6| Step: 8
Training loss: 1.6217852852471228
Validation loss: 3.0667338850249397

Epoch: 6| Step: 9
Training loss: 0.7519180884187348
Validation loss: 2.9800662614295645

Epoch: 6| Step: 10
Training loss: 0.8293291370443096
Validation loss: 2.984285795999009

Epoch: 6| Step: 11
Training loss: 0.507892191575983
Validation loss: 3.0530158604846003

Epoch: 6| Step: 12
Training loss: 0.701179440598329
Validation loss: 3.0843109093281096

Epoch: 6| Step: 13
Training loss: 0.6429559124653459
Validation loss: 3.0779204712124653

Epoch: 300| Step: 0
Training loss: 0.8671575317703271
Validation loss: 3.128097499506768

Epoch: 6| Step: 1
Training loss: 0.6017604105991438
Validation loss: 2.9565888396825186

Epoch: 6| Step: 2
Training loss: 0.5303002450816181
Validation loss: 2.959874656038087

Epoch: 6| Step: 3
Training loss: 1.7204010402751688
Validation loss: 3.108366427275226

Epoch: 6| Step: 4
Training loss: 0.5390189056460307
Validation loss: 3.062718597706984

Epoch: 6| Step: 5
Training loss: 0.6859532208911301
Validation loss: 2.91303469589066

Epoch: 6| Step: 6
Training loss: 0.9985633305163373
Validation loss: 3.1209755478471157

Epoch: 6| Step: 7
Training loss: 0.49661074755073614
Validation loss: 3.0979175689908023

Epoch: 6| Step: 8
Training loss: 0.6197341817489048
Validation loss: 3.1214830699223026

Epoch: 6| Step: 9
Training loss: 0.5473504315925947
Validation loss: 3.1161480463627824

Epoch: 6| Step: 10
Training loss: 0.7022391354870336
Validation loss: 3.081236098118205

Epoch: 6| Step: 11
Training loss: 0.6401085283603126
Validation loss: 3.127099921080637

Epoch: 6| Step: 12
Training loss: 0.7664068861714716
Validation loss: 3.074503373667856

Epoch: 6| Step: 13
Training loss: 0.7679056337639968
Validation loss: 3.0776772859290245

Testing loss: 3.1012805539380213
