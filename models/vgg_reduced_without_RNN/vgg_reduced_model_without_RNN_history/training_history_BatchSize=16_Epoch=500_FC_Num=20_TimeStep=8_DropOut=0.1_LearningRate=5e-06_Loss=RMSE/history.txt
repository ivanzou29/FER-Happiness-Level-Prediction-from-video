Epoch: 1| Step: 0
Training loss: 5.630169167560304
Validation loss: 5.502940172322531

Epoch: 6| Step: 1
Training loss: 5.9134480851374045
Validation loss: 5.4920009474636595

Epoch: 6| Step: 2
Training loss: 5.502692517210538
Validation loss: 5.480072536452513

Epoch: 6| Step: 3
Training loss: 4.982385890207175
Validation loss: 5.4699098937373245

Epoch: 6| Step: 4
Training loss: 4.718492109312522
Validation loss: 5.455042606633757

Epoch: 6| Step: 5
Training loss: 5.898220194672605
Validation loss: 5.442629911840333

Epoch: 6| Step: 6
Training loss: 5.926399857501694
Validation loss: 5.428109929179703

Epoch: 6| Step: 7
Training loss: 5.842213474572005
Validation loss: 5.4137318020695835

Epoch: 6| Step: 8
Training loss: 6.224623470332331
Validation loss: 5.400240459504292

Epoch: 6| Step: 9
Training loss: 6.117700392072025
Validation loss: 5.385588101499715

Epoch: 6| Step: 10
Training loss: 5.535999392713392
Validation loss: 5.3703811376227435

Epoch: 6| Step: 11
Training loss: 4.391713072056893
Validation loss: 5.354810455842986

Epoch: 6| Step: 12
Training loss: 5.49474846941946
Validation loss: 5.3419453509034875

Epoch: 6| Step: 13
Training loss: 5.011836727713095
Validation loss: 5.32605501090316

Epoch: 2| Step: 0
Training loss: 5.4935945143846
Validation loss: 5.303952720065045

Epoch: 6| Step: 1
Training loss: 5.653871320611584
Validation loss: 5.28811948136868

Epoch: 6| Step: 2
Training loss: 6.0993845394641175
Validation loss: 5.266136499270309

Epoch: 6| Step: 3
Training loss: 5.95379298509982
Validation loss: 5.24767360914391

Epoch: 6| Step: 4
Training loss: 4.637386746321783
Validation loss: 5.223867956300745

Epoch: 6| Step: 5
Training loss: 4.507612994190551
Validation loss: 5.198149355443395

Epoch: 6| Step: 6
Training loss: 5.6717240074383675
Validation loss: 5.1752468768954785

Epoch: 6| Step: 7
Training loss: 4.6929115084895505
Validation loss: 5.15185211357967

Epoch: 6| Step: 8
Training loss: 4.14865358871057
Validation loss: 5.128852636711249

Epoch: 6| Step: 9
Training loss: 4.308389888861991
Validation loss: 5.098076354117353

Epoch: 6| Step: 10
Training loss: 5.177567498371732
Validation loss: 5.070871566256366

Epoch: 6| Step: 11
Training loss: 5.630306199523311
Validation loss: 5.042654124678237

Epoch: 6| Step: 12
Training loss: 5.392712882574662
Validation loss: 5.012824840595069

Epoch: 6| Step: 13
Training loss: 5.880490598388401
Validation loss: 4.976820080217909

Epoch: 3| Step: 0
Training loss: 3.312062792445378
Validation loss: 4.941975942950666

Epoch: 6| Step: 1
Training loss: 4.404745074894198
Validation loss: 4.90873187357165

Epoch: 6| Step: 2
Training loss: 4.535473348356525
Validation loss: 4.868462344067313

Epoch: 6| Step: 3
Training loss: 5.554923566263209
Validation loss: 4.835897105535638

Epoch: 6| Step: 4
Training loss: 4.769162925351253
Validation loss: 4.793808311959876

Epoch: 6| Step: 5
Training loss: 5.503882338375134
Validation loss: 4.753970845519441

Epoch: 6| Step: 6
Training loss: 5.27147641486987
Validation loss: 4.708011121049104

Epoch: 6| Step: 7
Training loss: 4.647705225607122
Validation loss: 4.651683231999911

Epoch: 6| Step: 8
Training loss: 5.345478692881928
Validation loss: 4.604071545661158

Epoch: 6| Step: 9
Training loss: 5.002649558909051
Validation loss: 4.545171569338891

Epoch: 6| Step: 10
Training loss: 4.1163331508028405
Validation loss: 4.491557219144415

Epoch: 6| Step: 11
Training loss: 4.8677531444866
Validation loss: 4.432643937644186

Epoch: 6| Step: 12
Training loss: 4.23305341641188
Validation loss: 4.37314802663041

Epoch: 6| Step: 13
Training loss: 4.369699373358011
Validation loss: 4.30149502306954

Epoch: 4| Step: 0
Training loss: 4.4092877244862
Validation loss: 4.2354989900233155

Epoch: 6| Step: 1
Training loss: 4.563500072664403
Validation loss: 4.1559685633317605

Epoch: 6| Step: 2
Training loss: 4.4878341677894165
Validation loss: 4.084448246978892

Epoch: 6| Step: 3
Training loss: 4.760002847237898
Validation loss: 4.008582979915278

Epoch: 6| Step: 4
Training loss: 3.51540648734983
Validation loss: 3.9130345541012246

Epoch: 6| Step: 5
Training loss: 3.5558929746847148
Validation loss: 3.827752439054849

Epoch: 6| Step: 6
Training loss: 3.5156207953533882
Validation loss: 3.7405858444930753

Epoch: 6| Step: 7
Training loss: 4.09214972747697
Validation loss: 3.6435313050654616

Epoch: 6| Step: 8
Training loss: 3.457292346469636
Validation loss: 3.560472212451723

Epoch: 6| Step: 9
Training loss: 2.575754914222879
Validation loss: 3.471650569058617

Epoch: 6| Step: 10
Training loss: 3.671052101939749
Validation loss: 3.368417041864015

Epoch: 6| Step: 11
Training loss: 3.082719346508199
Validation loss: 3.281383826539125

Epoch: 6| Step: 12
Training loss: 3.179831911598937
Validation loss: 3.193869267157145

Epoch: 6| Step: 13
Training loss: 3.176198033459801
Validation loss: 3.080936496924178

Epoch: 5| Step: 0
Training loss: 3.5009790141204804
Validation loss: 2.984975997300079

Epoch: 6| Step: 1
Training loss: 2.75287417287831
Validation loss: 2.9022866984082896

Epoch: 6| Step: 2
Training loss: 2.9148794056989846
Validation loss: 2.8153919328144434

Epoch: 6| Step: 3
Training loss: 1.968052876890243
Validation loss: 2.7641654033349408

Epoch: 6| Step: 4
Training loss: 3.074741731047745
Validation loss: 2.7027257135631677

Epoch: 6| Step: 5
Training loss: 2.22390288403702
Validation loss: 2.676522984225064

Epoch: 6| Step: 6
Training loss: 2.164240089593868
Validation loss: 2.6284532388135724

Epoch: 6| Step: 7
Training loss: 2.897378486409026
Validation loss: 2.6072643827767776

Epoch: 6| Step: 8
Training loss: 2.183930017991952
Validation loss: 2.5897031873452883

Epoch: 6| Step: 9
Training loss: 2.638968134130794
Validation loss: 2.5814241512193488

Epoch: 6| Step: 10
Training loss: 3.092216034343616
Validation loss: 2.6038108328264418

Epoch: 6| Step: 11
Training loss: 2.393951295999396
Validation loss: 2.6351177111349444

Epoch: 6| Step: 12
Training loss: 2.3263645556744623
Validation loss: 2.6856526375954513

Epoch: 6| Step: 13
Training loss: 2.1939618174134914
Validation loss: 2.649617557699526

Epoch: 6| Step: 0
Training loss: 2.9249132648878153
Validation loss: 2.6578497762755298

Epoch: 6| Step: 1
Training loss: 2.311893589824715
Validation loss: 2.705492089428179

Epoch: 6| Step: 2
Training loss: 2.697002290305359
Validation loss: 2.6904449296301456

Epoch: 6| Step: 3
Training loss: 3.1413993829682
Validation loss: 2.717015059974968

Epoch: 6| Step: 4
Training loss: 2.36243972297753
Validation loss: 2.7321188201701765

Epoch: 6| Step: 5
Training loss: 2.638500013197103
Validation loss: 2.728912827041262

Epoch: 6| Step: 6
Training loss: 2.662901146985318
Validation loss: 2.7066528731105843

Epoch: 6| Step: 7
Training loss: 3.044026613297088
Validation loss: 2.735136983150384

Epoch: 6| Step: 8
Training loss: 2.8827254946431893
Validation loss: 2.687487032955144

Epoch: 6| Step: 9
Training loss: 1.7567695745091736
Validation loss: 2.67419077436692

Epoch: 6| Step: 10
Training loss: 3.0799005489889764
Validation loss: 2.671396565870933

Epoch: 6| Step: 11
Training loss: 1.7469732813066619
Validation loss: 2.6173027658463774

Epoch: 6| Step: 12
Training loss: 2.6274468961189394
Validation loss: 2.6141478389864163

Epoch: 6| Step: 13
Training loss: 2.6813548603316057
Validation loss: 2.5881354757153914

Epoch: 7| Step: 0
Training loss: 2.403466534496848
Validation loss: 2.599642620834206

Epoch: 6| Step: 1
Training loss: 2.7783061531658086
Validation loss: 2.5771387467919475

Epoch: 6| Step: 2
Training loss: 2.7208623462978094
Validation loss: 2.596015905590146

Epoch: 6| Step: 3
Training loss: 2.31653994709946
Validation loss: 2.5975299393388163

Epoch: 6| Step: 4
Training loss: 2.7174028588754218
Validation loss: 2.5761293027424386

Epoch: 6| Step: 5
Training loss: 3.4642495868355296
Validation loss: 2.595719260152933

Epoch: 6| Step: 6
Training loss: 2.220834531897054
Validation loss: 2.5721901911761353

Epoch: 6| Step: 7
Training loss: 2.4470633676646405
Validation loss: 2.5847619833653224

Epoch: 6| Step: 8
Training loss: 2.2781158237769583
Validation loss: 2.5835342072765064

Epoch: 6| Step: 9
Training loss: 2.1708313334840823
Validation loss: 2.5679274666050653

Epoch: 6| Step: 10
Training loss: 2.6307331329619914
Validation loss: 2.571782380758152

Epoch: 6| Step: 11
Training loss: 2.6368380145191384
Validation loss: 2.564704613460986

Epoch: 6| Step: 12
Training loss: 1.791850221088033
Validation loss: 2.587302732088956

Epoch: 6| Step: 13
Training loss: 2.9974255641829344
Validation loss: 2.5518327914411327

Epoch: 8| Step: 0
Training loss: 2.7244596488038146
Validation loss: 2.596012124833141

Epoch: 6| Step: 1
Training loss: 1.6325459970066782
Validation loss: 2.565101729390234

Epoch: 6| Step: 2
Training loss: 2.585167715508913
Validation loss: 2.5901123030382798

Epoch: 6| Step: 3
Training loss: 2.96764039836308
Validation loss: 2.5730987103471774

Epoch: 6| Step: 4
Training loss: 3.205007307071063
Validation loss: 2.601802749919628

Epoch: 6| Step: 5
Training loss: 2.1877663586440503
Validation loss: 2.582098586319698

Epoch: 6| Step: 6
Training loss: 2.07413345994904
Validation loss: 2.5774249581020627

Epoch: 6| Step: 7
Training loss: 2.265193082482757
Validation loss: 2.5646414608931063

Epoch: 6| Step: 8
Training loss: 2.4913296074979323
Validation loss: 2.57088488048478

Epoch: 6| Step: 9
Training loss: 2.7594723123777745
Validation loss: 2.5523386509656305

Epoch: 6| Step: 10
Training loss: 2.497257254013813
Validation loss: 2.588911146560334

Epoch: 6| Step: 11
Training loss: 2.020127228799793
Validation loss: 2.5728362736259407

Epoch: 6| Step: 12
Training loss: 3.003753221679179
Validation loss: 2.56681488360536

Epoch: 6| Step: 13
Training loss: 2.921908128519997
Validation loss: 2.5585512579963923

Epoch: 9| Step: 0
Training loss: 1.7744133234941017
Validation loss: 2.5834400606156165

Epoch: 6| Step: 1
Training loss: 2.102737948892792
Validation loss: 2.5650401512458747

Epoch: 6| Step: 2
Training loss: 2.060689883218677
Validation loss: 2.546063299661255

Epoch: 6| Step: 3
Training loss: 2.3831706794064536
Validation loss: 2.5794672005679087

Epoch: 6| Step: 4
Training loss: 2.177787800633901
Validation loss: 2.561102788593987

Epoch: 6| Step: 5
Training loss: 2.262609856399059
Validation loss: 2.5844679591639923

Epoch: 6| Step: 6
Training loss: 3.2763300750040396
Validation loss: 2.584927479779992

Epoch: 6| Step: 7
Training loss: 2.7241319026072754
Validation loss: 2.5835852090013622

Epoch: 6| Step: 8
Training loss: 2.250876997526876
Validation loss: 2.5937836886136982

Epoch: 6| Step: 9
Training loss: 2.992545084091845
Validation loss: 2.5856418267712917

Epoch: 6| Step: 10
Training loss: 3.529820110503113
Validation loss: 2.5888140795390457

Epoch: 6| Step: 11
Training loss: 2.561023752134404
Validation loss: 2.600781297669392

Epoch: 6| Step: 12
Training loss: 3.015776793459481
Validation loss: 2.5934434426164477

Epoch: 6| Step: 13
Training loss: 2.174519637106238
Validation loss: 2.5924791800074645

Epoch: 10| Step: 0
Training loss: 2.521479269032882
Validation loss: 2.5812726313081504

Epoch: 6| Step: 1
Training loss: 2.2328593842460553
Validation loss: 2.5832606941183176

Epoch: 6| Step: 2
Training loss: 1.7274851685479389
Validation loss: 2.55823585394955

Epoch: 6| Step: 3
Training loss: 1.8419324030116861
Validation loss: 2.5651087546267197

Epoch: 6| Step: 4
Training loss: 2.6384288074459104
Validation loss: 2.5679536641645586

Epoch: 6| Step: 5
Training loss: 2.9109848993264196
Validation loss: 2.5635203679292915

Epoch: 6| Step: 6
Training loss: 2.9188472952136224
Validation loss: 2.5578253681820025

Epoch: 6| Step: 7
Training loss: 3.010398327904692
Validation loss: 2.5663920595191896

Epoch: 6| Step: 8
Training loss: 2.278426631011592
Validation loss: 2.5538298307499074

Epoch: 6| Step: 9
Training loss: 2.1497006673696575
Validation loss: 2.582839708440709

Epoch: 6| Step: 10
Training loss: 2.534726052012809
Validation loss: 2.561963412851712

Epoch: 6| Step: 11
Training loss: 2.6199379204536983
Validation loss: 2.5517428631642085

Epoch: 6| Step: 12
Training loss: 3.512964216623943
Validation loss: 2.5610950929642353

Epoch: 6| Step: 13
Training loss: 2.2134564072887843
Validation loss: 2.5614832279773907

Epoch: 11| Step: 0
Training loss: 2.7796061940816807
Validation loss: 2.546521807873009

Epoch: 6| Step: 1
Training loss: 2.5419075856911744
Validation loss: 2.5574886196973368

Epoch: 6| Step: 2
Training loss: 2.6165647762247226
Validation loss: 2.577185966485384

Epoch: 6| Step: 3
Training loss: 1.9014669978938867
Validation loss: 2.5343450375944414

Epoch: 6| Step: 4
Training loss: 2.5707206054241567
Validation loss: 2.572055894029783

Epoch: 6| Step: 5
Training loss: 2.2560331203383246
Validation loss: 2.565211838271358

Epoch: 6| Step: 6
Training loss: 2.7827235400948735
Validation loss: 2.531487143753943

Epoch: 6| Step: 7
Training loss: 2.499167017447496
Validation loss: 2.5624602400013403

Epoch: 6| Step: 8
Training loss: 2.7616847358562184
Validation loss: 2.562082970032351

Epoch: 6| Step: 9
Training loss: 2.7232253849419776
Validation loss: 2.5566483340379063

Epoch: 6| Step: 10
Training loss: 2.6534001040403954
Validation loss: 2.57721825269367

Epoch: 6| Step: 11
Training loss: 2.262813323017756
Validation loss: 2.5590473733879517

Epoch: 6| Step: 12
Training loss: 1.8111430383116098
Validation loss: 2.565623682279632

Epoch: 6| Step: 13
Training loss: 3.3166739599508737
Validation loss: 2.5851323160166637

Epoch: 12| Step: 0
Training loss: 3.114320894920054
Validation loss: 2.565159495316927

Epoch: 6| Step: 1
Training loss: 2.735316871823487
Validation loss: 2.55840288765593

Epoch: 6| Step: 2
Training loss: 2.429966361672495
Validation loss: 2.5584465314526237

Epoch: 6| Step: 3
Training loss: 2.615710396779769
Validation loss: 2.5486707383011127

Epoch: 6| Step: 4
Training loss: 2.483440487318497
Validation loss: 2.5652025207149647

Epoch: 6| Step: 5
Training loss: 2.0578324649337594
Validation loss: 2.5478607485590836

Epoch: 6| Step: 6
Training loss: 2.380965520731681
Validation loss: 2.540216068454294

Epoch: 6| Step: 7
Training loss: 2.907705619278504
Validation loss: 2.532155192965994

Epoch: 6| Step: 8
Training loss: 2.7396901814519534
Validation loss: 2.562356448610878

Epoch: 6| Step: 9
Training loss: 2.7041135534900262
Validation loss: 2.5421839224194858

Epoch: 6| Step: 10
Training loss: 2.5981833934117855
Validation loss: 2.5532144544066884

Epoch: 6| Step: 11
Training loss: 2.40894592660253
Validation loss: 2.540731216218596

Epoch: 6| Step: 12
Training loss: 1.9176070421921094
Validation loss: 2.555284824981115

Epoch: 6| Step: 13
Training loss: 2.4859781910498997
Validation loss: 2.527945586865346

Epoch: 13| Step: 0
Training loss: 2.8442848457159378
Validation loss: 2.5448191561771094

Epoch: 6| Step: 1
Training loss: 2.2356949755323523
Validation loss: 2.5753086312524975

Epoch: 6| Step: 2
Training loss: 2.6893659811646597
Validation loss: 2.562921163792438

Epoch: 6| Step: 3
Training loss: 2.7939682672564983
Validation loss: 2.5568328000302616

Epoch: 6| Step: 4
Training loss: 2.629558419988204
Validation loss: 2.5430208309248954

Epoch: 6| Step: 5
Training loss: 2.1996662233485846
Validation loss: 2.5491503515487324

Epoch: 6| Step: 6
Training loss: 2.971872073391698
Validation loss: 2.581592039610304

Epoch: 6| Step: 7
Training loss: 1.7566733505054308
Validation loss: 2.579682690688914

Epoch: 6| Step: 8
Training loss: 1.9775080774964537
Validation loss: 2.570777456788184

Epoch: 6| Step: 9
Training loss: 2.9620790721737276
Validation loss: 2.585346734522567

Epoch: 6| Step: 10
Training loss: 3.070057322063286
Validation loss: 2.560204221842345

Epoch: 6| Step: 11
Training loss: 1.7498593273843916
Validation loss: 2.564039031794436

Epoch: 6| Step: 12
Training loss: 2.9247875690755305
Validation loss: 2.551547447046502

Epoch: 6| Step: 13
Training loss: 2.309758804081549
Validation loss: 2.567916959652896

Epoch: 14| Step: 0
Training loss: 1.8969844076413682
Validation loss: 2.544695571123956

Epoch: 6| Step: 1
Training loss: 2.4879318782520463
Validation loss: 2.5600788960369396

Epoch: 6| Step: 2
Training loss: 3.1111521793864054
Validation loss: 2.53547725202842

Epoch: 6| Step: 3
Training loss: 2.641240516569748
Validation loss: 2.5473263580471692

Epoch: 6| Step: 4
Training loss: 2.6693943398287954
Validation loss: 2.532506246405301

Epoch: 6| Step: 5
Training loss: 2.7091556376672057
Validation loss: 2.549753882804054

Epoch: 6| Step: 6
Training loss: 2.4008760760641494
Validation loss: 2.5283154089369213

Epoch: 6| Step: 7
Training loss: 2.147539873741082
Validation loss: 2.5314944270921074

Epoch: 6| Step: 8
Training loss: 2.698524308478789
Validation loss: 2.5319965501804966

Epoch: 6| Step: 9
Training loss: 2.7908749287982397
Validation loss: 2.5373007271730152

Epoch: 6| Step: 10
Training loss: 2.4988097218355665
Validation loss: 2.5366926196003408

Epoch: 6| Step: 11
Training loss: 2.331046198304871
Validation loss: 2.5385074732662125

Epoch: 6| Step: 12
Training loss: 2.1632290002775023
Validation loss: 2.560952642061265

Epoch: 6| Step: 13
Training loss: 2.549084225938832
Validation loss: 2.5336442934308208

Epoch: 15| Step: 0
Training loss: 2.6130732295289505
Validation loss: 2.519561246944736

Epoch: 6| Step: 1
Training loss: 2.0376260308914285
Validation loss: 2.5444530368458103

Epoch: 6| Step: 2
Training loss: 2.834628388876987
Validation loss: 2.540265906350041

Epoch: 6| Step: 3
Training loss: 2.2578968705513667
Validation loss: 2.5608990638242712

Epoch: 6| Step: 4
Training loss: 2.847775303742033
Validation loss: 2.5144318145975677

Epoch: 6| Step: 5
Training loss: 2.4530313073021492
Validation loss: 2.537724867379776

Epoch: 6| Step: 6
Training loss: 2.493154308331389
Validation loss: 2.542219122791772

Epoch: 6| Step: 7
Training loss: 2.6260747979835783
Validation loss: 2.5486822366678763

Epoch: 6| Step: 8
Training loss: 2.874493098146013
Validation loss: 2.5753237292419824

Epoch: 6| Step: 9
Training loss: 2.3284985543431467
Validation loss: 2.537974886625437

Epoch: 6| Step: 10
Training loss: 2.410035759434986
Validation loss: 2.5541289221467567

Epoch: 6| Step: 11
Training loss: 2.658994446185202
Validation loss: 2.5661168663496445

Epoch: 6| Step: 12
Training loss: 2.022871254890208
Validation loss: 2.5659412289819494

Epoch: 6| Step: 13
Training loss: 2.759383923698676
Validation loss: 2.532543134632661

Epoch: 16| Step: 0
Training loss: 2.1583153604866228
Validation loss: 2.543924037968864

Epoch: 6| Step: 1
Training loss: 3.022337720883003
Validation loss: 2.5339729043414665

Epoch: 6| Step: 2
Training loss: 2.4641776900377605
Validation loss: 2.5412877509119425

Epoch: 6| Step: 3
Training loss: 2.787060529338313
Validation loss: 2.5441081926623483

Epoch: 6| Step: 4
Training loss: 2.2306784616414257
Validation loss: 2.5429178399821843

Epoch: 6| Step: 5
Training loss: 2.802712938180215
Validation loss: 2.5185269821041403

Epoch: 6| Step: 6
Training loss: 2.3502658044360567
Validation loss: 2.5524305976700803

Epoch: 6| Step: 7
Training loss: 2.085461622954652
Validation loss: 2.5197090184783453

Epoch: 6| Step: 8
Training loss: 2.7104546284540008
Validation loss: 2.538263236205292

Epoch: 6| Step: 9
Training loss: 2.731939484536209
Validation loss: 2.528278867662558

Epoch: 6| Step: 10
Training loss: 1.8056342213765915
Validation loss: 2.551861022816266

Epoch: 6| Step: 11
Training loss: 2.555305616162612
Validation loss: 2.5362988107846616

Epoch: 6| Step: 12
Training loss: 2.4147442592635944
Validation loss: 2.526924629186384

Epoch: 6| Step: 13
Training loss: 2.577817216476471
Validation loss: 2.56761058340174

Epoch: 17| Step: 0
Training loss: 2.298485431391792
Validation loss: 2.539290745575422

Epoch: 6| Step: 1
Training loss: 2.2739611674728124
Validation loss: 2.5483885248352065

Epoch: 6| Step: 2
Training loss: 2.5020144929290775
Validation loss: 2.54531074338087

Epoch: 6| Step: 3
Training loss: 1.7852445952009528
Validation loss: 2.5299351970505346

Epoch: 6| Step: 4
Training loss: 3.248593099224434
Validation loss: 2.5288595678251333

Epoch: 6| Step: 5
Training loss: 1.7191037594258227
Validation loss: 2.552779703435862

Epoch: 6| Step: 6
Training loss: 3.176096244852694
Validation loss: 2.5399811320217336

Epoch: 6| Step: 7
Training loss: 2.6155280018895253
Validation loss: 2.5401640708126996

Epoch: 6| Step: 8
Training loss: 2.6513085571325927
Validation loss: 2.545216595751657

Epoch: 6| Step: 9
Training loss: 1.9529910842762317
Validation loss: 2.513256173981598

Epoch: 6| Step: 10
Training loss: 2.4041235308906708
Validation loss: 2.514698726805497

Epoch: 6| Step: 11
Training loss: 3.0365777142167034
Validation loss: 2.520739267238811

Epoch: 6| Step: 12
Training loss: 2.3696646743675176
Validation loss: 2.568396166016987

Epoch: 6| Step: 13
Training loss: 2.3933207951308497
Validation loss: 2.5332528342039127

Epoch: 18| Step: 0
Training loss: 2.79936227007333
Validation loss: 2.5425733033212317

Epoch: 6| Step: 1
Training loss: 2.2927324995413496
Validation loss: 2.531566552984282

Epoch: 6| Step: 2
Training loss: 2.5375607788624293
Validation loss: 2.524605668628051

Epoch: 6| Step: 3
Training loss: 3.541567961869437
Validation loss: 2.5383608743630828

Epoch: 6| Step: 4
Training loss: 1.1279857010577623
Validation loss: 2.534851196932757

Epoch: 6| Step: 5
Training loss: 2.2525153405347726
Validation loss: 2.5274587268018944

Epoch: 6| Step: 6
Training loss: 2.286291013488474
Validation loss: 2.5216209400247505

Epoch: 6| Step: 7
Training loss: 2.288326835243388
Validation loss: 2.5403538007456863

Epoch: 6| Step: 8
Training loss: 2.177435254821697
Validation loss: 2.5279049689975515

Epoch: 6| Step: 9
Training loss: 2.553891025706716
Validation loss: 2.5382912584434094

Epoch: 6| Step: 10
Training loss: 2.1182103237730017
Validation loss: 2.5536357180505087

Epoch: 6| Step: 11
Training loss: 2.3601177132878246
Validation loss: 2.5309730032861757

Epoch: 6| Step: 12
Training loss: 2.6063362747659107
Validation loss: 2.555150976728249

Epoch: 6| Step: 13
Training loss: 3.175532895520408
Validation loss: 2.525094967179844

Epoch: 19| Step: 0
Training loss: 2.616648513180232
Validation loss: 2.539111671949745

Epoch: 6| Step: 1
Training loss: 2.775506421867395
Validation loss: 2.5281577668897715

Epoch: 6| Step: 2
Training loss: 2.6711773770304594
Validation loss: 2.5564052394745804

Epoch: 6| Step: 3
Training loss: 1.7389027373900299
Validation loss: 2.5398830398654355

Epoch: 6| Step: 4
Training loss: 2.0653539621165584
Validation loss: 2.5295882873369355

Epoch: 6| Step: 5
Training loss: 2.40509609942452
Validation loss: 2.5242218278877733

Epoch: 6| Step: 6
Training loss: 1.1750458606941676
Validation loss: 2.5575181869799866

Epoch: 6| Step: 7
Training loss: 3.0261131886594415
Validation loss: 2.5238068332983383

Epoch: 6| Step: 8
Training loss: 2.6541127301718834
Validation loss: 2.5291790280571584

Epoch: 6| Step: 9
Training loss: 2.7593319951094357
Validation loss: 2.5338641823508268

Epoch: 6| Step: 10
Training loss: 3.196886938525866
Validation loss: 2.5472367074689304

Epoch: 6| Step: 11
Training loss: 2.8332949430071386
Validation loss: 2.526208417179953

Epoch: 6| Step: 12
Training loss: 2.089959428384312
Validation loss: 2.5042698160297467

Epoch: 6| Step: 13
Training loss: 2.244461342094358
Validation loss: 2.508949251902605

Epoch: 20| Step: 0
Training loss: 2.7165162128685765
Validation loss: 2.5104988580653145

Epoch: 6| Step: 1
Training loss: 2.7000655130986013
Validation loss: 2.511634852944705

Epoch: 6| Step: 2
Training loss: 2.297774365867543
Validation loss: 2.503035149328878

Epoch: 6| Step: 3
Training loss: 2.572898236619267
Validation loss: 2.540268503024652

Epoch: 6| Step: 4
Training loss: 2.305067541825074
Validation loss: 2.527170999824613

Epoch: 6| Step: 5
Training loss: 1.9683764875409637
Validation loss: 2.5360904142164986

Epoch: 6| Step: 6
Training loss: 1.9273492028291075
Validation loss: 2.5258000890829813

Epoch: 6| Step: 7
Training loss: 3.4679174025400092
Validation loss: 2.5455010107214857

Epoch: 6| Step: 8
Training loss: 2.322765556404066
Validation loss: 2.5322699826901074

Epoch: 6| Step: 9
Training loss: 2.693781232542165
Validation loss: 2.533492080416114

Epoch: 6| Step: 10
Training loss: 2.7407546253062667
Validation loss: 2.5150580468250903

Epoch: 6| Step: 11
Training loss: 2.5477218624159943
Validation loss: 2.5170671897976282

Epoch: 6| Step: 12
Training loss: 1.9411748675307456
Validation loss: 2.5550917014992978

Epoch: 6| Step: 13
Training loss: 2.4501172718864077
Validation loss: 2.546521917102391

Epoch: 21| Step: 0
Training loss: 2.3261700301078956
Validation loss: 2.510605996195851

Epoch: 6| Step: 1
Training loss: 2.302355397806259
Validation loss: 2.5268726253694935

Epoch: 6| Step: 2
Training loss: 2.6775024224563313
Validation loss: 2.5388785662419187

Epoch: 6| Step: 3
Training loss: 1.7644638024041488
Validation loss: 2.512307058109475

Epoch: 6| Step: 4
Training loss: 2.84409623605872
Validation loss: 2.532155067424144

Epoch: 6| Step: 5
Training loss: 2.247230096380676
Validation loss: 2.5318794645196165

Epoch: 6| Step: 6
Training loss: 2.5178697889139903
Validation loss: 2.5232247655618307

Epoch: 6| Step: 7
Training loss: 1.8677486071381644
Validation loss: 2.5301220739514276

Epoch: 6| Step: 8
Training loss: 2.232620831131934
Validation loss: 2.5527590784746974

Epoch: 6| Step: 9
Training loss: 2.289093017374699
Validation loss: 2.5334372469855366

Epoch: 6| Step: 10
Training loss: 2.349786537702119
Validation loss: 2.512580182012278

Epoch: 6| Step: 11
Training loss: 2.9882956111787267
Validation loss: 2.502782663786768

Epoch: 6| Step: 12
Training loss: 2.7015985136792198
Validation loss: 2.520625481561737

Epoch: 6| Step: 13
Training loss: 3.3868622182973405
Validation loss: 2.518479806497579

Epoch: 22| Step: 0
Training loss: 2.726850784057838
Validation loss: 2.518123499570898

Epoch: 6| Step: 1
Training loss: 2.3103632978966364
Validation loss: 2.515863253287174

Epoch: 6| Step: 2
Training loss: 2.342855969621451
Validation loss: 2.50210085652801

Epoch: 6| Step: 3
Training loss: 2.9842164961180555
Validation loss: 2.5470833878403

Epoch: 6| Step: 4
Training loss: 2.5225595181024736
Validation loss: 2.5284907054100416

Epoch: 6| Step: 5
Training loss: 2.506170858527277
Validation loss: 2.5084816187585015

Epoch: 6| Step: 6
Training loss: 2.608480791386431
Validation loss: 2.5341405651132782

Epoch: 6| Step: 7
Training loss: 2.069357252168719
Validation loss: 2.5082089753442385

Epoch: 6| Step: 8
Training loss: 2.775968959827194
Validation loss: 2.5208502340669745

Epoch: 6| Step: 9
Training loss: 1.8707199838308386
Validation loss: 2.4965079873729725

Epoch: 6| Step: 10
Training loss: 2.227395848708914
Validation loss: 2.518772352007438

Epoch: 6| Step: 11
Training loss: 2.075981239042973
Validation loss: 2.5169182764258764

Epoch: 6| Step: 12
Training loss: 2.666864079877025
Validation loss: 2.5297605582909513

Epoch: 6| Step: 13
Training loss: 2.839739644111391
Validation loss: 2.52104914873719

Epoch: 23| Step: 0
Training loss: 2.7281208121321128
Validation loss: 2.520963859856914

Epoch: 6| Step: 1
Training loss: 2.28941056140854
Validation loss: 2.5166334891079702

Epoch: 6| Step: 2
Training loss: 2.981399570767684
Validation loss: 2.5283323670521423

Epoch: 6| Step: 3
Training loss: 2.3243421505778534
Validation loss: 2.5197292043117496

Epoch: 6| Step: 4
Training loss: 2.203084093079336
Validation loss: 2.5003848415443546

Epoch: 6| Step: 5
Training loss: 2.378622204088475
Validation loss: 2.5211344110901863

Epoch: 6| Step: 6
Training loss: 2.30917511153653
Validation loss: 2.5193965905451328

Epoch: 6| Step: 7
Training loss: 2.7231376583565994
Validation loss: 2.516029893976505

Epoch: 6| Step: 8
Training loss: 2.6252877213968735
Validation loss: 2.522408069741338

Epoch: 6| Step: 9
Training loss: 2.2487456746083634
Validation loss: 2.511515496920732

Epoch: 6| Step: 10
Training loss: 2.5636341097420305
Validation loss: 2.538628894265782

Epoch: 6| Step: 11
Training loss: 2.257977647912326
Validation loss: 2.513346333086442

Epoch: 6| Step: 12
Training loss: 2.7419334359134213
Validation loss: 2.503795936761078

Epoch: 6| Step: 13
Training loss: 2.24393705900595
Validation loss: 2.506398484674388

Epoch: 24| Step: 0
Training loss: 2.1229537760966712
Validation loss: 2.5258216421254662

Epoch: 6| Step: 1
Training loss: 3.172215185103783
Validation loss: 2.5572923141033237

Epoch: 6| Step: 2
Training loss: 2.0763209263436044
Validation loss: 2.5545782130019026

Epoch: 6| Step: 3
Training loss: 2.8103863721326547
Validation loss: 2.517421310114259

Epoch: 6| Step: 4
Training loss: 3.04259295707885
Validation loss: 2.5491122071641605

Epoch: 6| Step: 5
Training loss: 1.7235534822616996
Validation loss: 2.5433976631561572

Epoch: 6| Step: 6
Training loss: 2.2910140639980296
Validation loss: 2.5240811687391647

Epoch: 6| Step: 7
Training loss: 2.3853392165047325
Validation loss: 2.536908375464978

Epoch: 6| Step: 8
Training loss: 2.347780246601932
Validation loss: 2.5367170720182477

Epoch: 6| Step: 9
Training loss: 1.9678508582396834
Validation loss: 2.5221513554993886

Epoch: 6| Step: 10
Training loss: 3.200958561379688
Validation loss: 2.5573691041076905

Epoch: 6| Step: 11
Training loss: 2.6096158401906635
Validation loss: 2.5210846678439514

Epoch: 6| Step: 12
Training loss: 2.2999088725405983
Validation loss: 2.5387737872964093

Epoch: 6| Step: 13
Training loss: 2.0486272635245184
Validation loss: 2.530160237642143

Epoch: 25| Step: 0
Training loss: 2.415938651385987
Validation loss: 2.522219400315613

Epoch: 6| Step: 1
Training loss: 2.750988435838106
Validation loss: 2.533422440501011

Epoch: 6| Step: 2
Training loss: 2.6065319357034626
Validation loss: 2.5451892352245693

Epoch: 6| Step: 3
Training loss: 2.5657710155796107
Validation loss: 2.5062858395063192

Epoch: 6| Step: 4
Training loss: 2.499486393622313
Validation loss: 2.5257796843178077

Epoch: 6| Step: 5
Training loss: 2.53386506055089
Validation loss: 2.526406477445819

Epoch: 6| Step: 6
Training loss: 2.068202372095371
Validation loss: 2.530002412128932

Epoch: 6| Step: 7
Training loss: 2.495869657817875
Validation loss: 2.5199305176112414

Epoch: 6| Step: 8
Training loss: 1.8997298500346813
Validation loss: 2.5321870803942508

Epoch: 6| Step: 9
Training loss: 2.069855607198159
Validation loss: 2.5141856812780237

Epoch: 6| Step: 10
Training loss: 2.747690444746527
Validation loss: 2.497243521895029

Epoch: 6| Step: 11
Training loss: 2.143474492200026
Validation loss: 2.4888154498923467

Epoch: 6| Step: 12
Training loss: 3.1713557076644894
Validation loss: 2.515310911548625

Epoch: 6| Step: 13
Training loss: 2.3415395867379623
Validation loss: 2.5122056867758387

Epoch: 26| Step: 0
Training loss: 2.0410324461029328
Validation loss: 2.508764844722826

Epoch: 6| Step: 1
Training loss: 2.8405881638021744
Validation loss: 2.495722671968014

Epoch: 6| Step: 2
Training loss: 2.5242629457912322
Validation loss: 2.5226557084523336

Epoch: 6| Step: 3
Training loss: 1.873251672075809
Validation loss: 2.5068513369214185

Epoch: 6| Step: 4
Training loss: 2.377215005056828
Validation loss: 2.5169189316166465

Epoch: 6| Step: 5
Training loss: 2.2470847423211175
Validation loss: 2.5125728280312773

Epoch: 6| Step: 6
Training loss: 2.097044672688908
Validation loss: 2.518259726138069

Epoch: 6| Step: 7
Training loss: 2.4435212518506666
Validation loss: 2.5119260916948227

Epoch: 6| Step: 8
Training loss: 2.8465671209519146
Validation loss: 2.5104836946986246

Epoch: 6| Step: 9
Training loss: 2.490908303415722
Validation loss: 2.551992855933483

Epoch: 6| Step: 10
Training loss: 2.4118565229947255
Validation loss: 2.5198197074003814

Epoch: 6| Step: 11
Training loss: 2.615038362298248
Validation loss: 2.511027492642597

Epoch: 6| Step: 12
Training loss: 2.498016906033582
Validation loss: 2.559285015656031

Epoch: 6| Step: 13
Training loss: 3.20988012571307
Validation loss: 2.537949099832672

Epoch: 27| Step: 0
Training loss: 2.372747658283564
Validation loss: 2.53113128634904

Epoch: 6| Step: 1
Training loss: 3.3977094900907487
Validation loss: 2.5393349995249177

Epoch: 6| Step: 2
Training loss: 2.180904581871259
Validation loss: 2.5039770916753143

Epoch: 6| Step: 3
Training loss: 2.5298844409832246
Validation loss: 2.524382989865584

Epoch: 6| Step: 4
Training loss: 2.0927632981774327
Validation loss: 2.5307853021000666

Epoch: 6| Step: 5
Training loss: 2.280720270393155
Validation loss: 2.5104485241990924

Epoch: 6| Step: 6
Training loss: 2.445578466216905
Validation loss: 2.498347896824439

Epoch: 6| Step: 7
Training loss: 2.545214246114513
Validation loss: 2.481684733628844

Epoch: 6| Step: 8
Training loss: 2.8690555318388995
Validation loss: 2.50175946627947

Epoch: 6| Step: 9
Training loss: 2.324397437655865
Validation loss: 2.516049738187152

Epoch: 6| Step: 10
Training loss: 2.1533837549114994
Validation loss: 2.5250970444112557

Epoch: 6| Step: 11
Training loss: 2.2410883851297294
Validation loss: 2.51289839899272

Epoch: 6| Step: 12
Training loss: 2.415935690813395
Validation loss: 2.5017521440243864

Epoch: 6| Step: 13
Training loss: 2.5319738412744215
Validation loss: 2.507892579635176

Epoch: 28| Step: 0
Training loss: 2.965603094150688
Validation loss: 2.527664989591446

Epoch: 6| Step: 1
Training loss: 2.908735791390096
Validation loss: 2.5282881012602463

Epoch: 6| Step: 2
Training loss: 2.3047520515324353
Validation loss: 2.502968122921701

Epoch: 6| Step: 3
Training loss: 2.329978461104614
Validation loss: 2.5269805788774

Epoch: 6| Step: 4
Training loss: 2.267800385115709
Validation loss: 2.5076350766302067

Epoch: 6| Step: 5
Training loss: 2.7154889773947786
Validation loss: 2.5167455921891726

Epoch: 6| Step: 6
Training loss: 3.034498538675803
Validation loss: 2.5144075089376816

Epoch: 6| Step: 7
Training loss: 2.334828601566686
Validation loss: 2.5218672142869782

Epoch: 6| Step: 8
Training loss: 1.755201783059535
Validation loss: 2.520738762797158

Epoch: 6| Step: 9
Training loss: 2.666449677063128
Validation loss: 2.5448043300351584

Epoch: 6| Step: 10
Training loss: 2.4001385251439906
Validation loss: 2.51486821766604

Epoch: 6| Step: 11
Training loss: 1.9653186262159297
Validation loss: 2.525958255819566

Epoch: 6| Step: 12
Training loss: 2.2935029273570615
Validation loss: 2.5406222673051877

Epoch: 6| Step: 13
Training loss: 2.3555513433902595
Validation loss: 2.493612378369529

Epoch: 29| Step: 0
Training loss: 2.5236723704913726
Validation loss: 2.527443099194225

Epoch: 6| Step: 1
Training loss: 2.027327285729148
Validation loss: 2.5339504483714035

Epoch: 6| Step: 2
Training loss: 2.2842821845991255
Validation loss: 2.5479449031717696

Epoch: 6| Step: 3
Training loss: 3.1562617839933176
Validation loss: 2.5124435921405377

Epoch: 6| Step: 4
Training loss: 2.5953932003769657
Validation loss: 2.5377506955963534

Epoch: 6| Step: 5
Training loss: 2.262786876552883
Validation loss: 2.527723296653127

Epoch: 6| Step: 6
Training loss: 2.741948565645517
Validation loss: 2.5406485274548287

Epoch: 6| Step: 7
Training loss: 1.8454257655771753
Validation loss: 2.532649724625851

Epoch: 6| Step: 8
Training loss: 2.4877399233028505
Validation loss: 2.524707077207956

Epoch: 6| Step: 9
Training loss: 2.5022808161124375
Validation loss: 2.5113455503548185

Epoch: 6| Step: 10
Training loss: 2.6162561382106873
Validation loss: 2.52126238195619

Epoch: 6| Step: 11
Training loss: 1.9846024870951002
Validation loss: 2.51019319882483

Epoch: 6| Step: 12
Training loss: 2.1241621721932757
Validation loss: 2.517826451813755

Epoch: 6| Step: 13
Training loss: 2.8867222188430612
Validation loss: 2.5446575785810994

Epoch: 30| Step: 0
Training loss: 2.6677262068902796
Validation loss: 2.5136587621291984

Epoch: 6| Step: 1
Training loss: 2.2553234702328844
Validation loss: 2.5202044866490017

Epoch: 6| Step: 2
Training loss: 2.2302323999461975
Validation loss: 2.5139507464063118

Epoch: 6| Step: 3
Training loss: 2.22763549649464
Validation loss: 2.5243504371716785

Epoch: 6| Step: 4
Training loss: 2.3270165793857345
Validation loss: 2.4982339502136712

Epoch: 6| Step: 5
Training loss: 2.2461753764040155
Validation loss: 2.5034407779613574

Epoch: 6| Step: 6
Training loss: 2.66090335521642
Validation loss: 2.535039035965565

Epoch: 6| Step: 7
Training loss: 2.5882213453182166
Validation loss: 2.5159863672488547

Epoch: 6| Step: 8
Training loss: 3.05495941434832
Validation loss: 2.5141441614873656

Epoch: 6| Step: 9
Training loss: 2.874224019026327
Validation loss: 2.5072181448929256

Epoch: 6| Step: 10
Training loss: 2.6278418643584143
Validation loss: 2.517825299724801

Epoch: 6| Step: 11
Training loss: 1.7521271720176614
Validation loss: 2.490679405189357

Epoch: 6| Step: 12
Training loss: 2.3290378905736033
Validation loss: 2.511182570589409

Epoch: 6| Step: 13
Training loss: 2.3155995809006753
Validation loss: 2.5236686073191295

Epoch: 31| Step: 0
Training loss: 2.3928616102782883
Validation loss: 2.5049883110727977

Epoch: 6| Step: 1
Training loss: 2.207320310854751
Validation loss: 2.4878528012513876

Epoch: 6| Step: 2
Training loss: 2.5734640818406
Validation loss: 2.498279806237628

Epoch: 6| Step: 3
Training loss: 3.1220386970071896
Validation loss: 2.517511690978224

Epoch: 6| Step: 4
Training loss: 2.438739950295237
Validation loss: 2.49841876091529

Epoch: 6| Step: 5
Training loss: 2.327454950570695
Validation loss: 2.4984862035950997

Epoch: 6| Step: 6
Training loss: 2.330379546527042
Validation loss: 2.507849973277796

Epoch: 6| Step: 7
Training loss: 2.5372289052385724
Validation loss: 2.5104029062825246

Epoch: 6| Step: 8
Training loss: 2.6605955592993786
Validation loss: 2.5033020782382023

Epoch: 6| Step: 9
Training loss: 2.289019066720782
Validation loss: 2.5303595746758054

Epoch: 6| Step: 10
Training loss: 2.461561529574143
Validation loss: 2.5322719206537694

Epoch: 6| Step: 11
Training loss: 2.928202748767685
Validation loss: 2.5108429848829092

Epoch: 6| Step: 12
Training loss: 2.1492414600166705
Validation loss: 2.5116815875731793

Epoch: 6| Step: 13
Training loss: 1.4903177260541003
Validation loss: 2.516889992546049

Epoch: 32| Step: 0
Training loss: 2.3012129114779096
Validation loss: 2.5478138509630046

Epoch: 6| Step: 1
Training loss: 2.459723666728155
Validation loss: 2.516966562739362

Epoch: 6| Step: 2
Training loss: 3.2362566648247415
Validation loss: 2.514468367465557

Epoch: 6| Step: 3
Training loss: 2.272421488564983
Validation loss: 2.505422560533013

Epoch: 6| Step: 4
Training loss: 2.7731902536139237
Validation loss: 2.5236645607217953

Epoch: 6| Step: 5
Training loss: 1.6434337007051063
Validation loss: 2.522863836598955

Epoch: 6| Step: 6
Training loss: 2.0759481630707537
Validation loss: 2.502905159010347

Epoch: 6| Step: 7
Training loss: 2.6196400552389734
Validation loss: 2.5112323042741527

Epoch: 6| Step: 8
Training loss: 2.9676013531365184
Validation loss: 2.496807428176922

Epoch: 6| Step: 9
Training loss: 2.497216200641543
Validation loss: 2.5008617664243222

Epoch: 6| Step: 10
Training loss: 1.9821628645644447
Validation loss: 2.5170179660819234

Epoch: 6| Step: 11
Training loss: 2.7980722603291426
Validation loss: 2.511953229227814

Epoch: 6| Step: 12
Training loss: 1.7739534005772062
Validation loss: 2.506981883440165

Epoch: 6| Step: 13
Training loss: 2.612277033294045
Validation loss: 2.5295071979597994

Epoch: 33| Step: 0
Training loss: 2.4891557100112562
Validation loss: 2.517186006324178

Epoch: 6| Step: 1
Training loss: 2.3233469634383734
Validation loss: 2.5234511368169485

Epoch: 6| Step: 2
Training loss: 2.3096539278600794
Validation loss: 2.5193561818416796

Epoch: 6| Step: 3
Training loss: 2.144576164289456
Validation loss: 2.5080250048894155

Epoch: 6| Step: 4
Training loss: 1.7210796866446254
Validation loss: 2.512338754594516

Epoch: 6| Step: 5
Training loss: 1.9206334267259793
Validation loss: 2.509349031420882

Epoch: 6| Step: 6
Training loss: 2.2483092419252872
Validation loss: 2.5082015134913855

Epoch: 6| Step: 7
Training loss: 3.0824692176834967
Validation loss: 2.5283898257702573

Epoch: 6| Step: 8
Training loss: 2.2253429620000036
Validation loss: 2.519594792000947

Epoch: 6| Step: 9
Training loss: 3.294782073667979
Validation loss: 2.5164380230733925

Epoch: 6| Step: 10
Training loss: 2.92264681327416
Validation loss: 2.5326559769502826

Epoch: 6| Step: 11
Training loss: 2.136639525567951
Validation loss: 2.5273978037411746

Epoch: 6| Step: 12
Training loss: 2.8218247858017578
Validation loss: 2.492337580101181

Epoch: 6| Step: 13
Training loss: 2.2646229599822805
Validation loss: 2.4958966674368552

Epoch: 34| Step: 0
Training loss: 2.4071089957662446
Validation loss: 2.5205452389200365

Epoch: 6| Step: 1
Training loss: 2.227762748728873
Validation loss: 2.5277410683277757

Epoch: 6| Step: 2
Training loss: 2.7289897968161605
Validation loss: 2.4942727926430712

Epoch: 6| Step: 3
Training loss: 2.533036437539458
Validation loss: 2.511482413540528

Epoch: 6| Step: 4
Training loss: 2.781197108076554
Validation loss: 2.5222021962891192

Epoch: 6| Step: 5
Training loss: 1.7159375849223424
Validation loss: 2.490199213714696

Epoch: 6| Step: 6
Training loss: 2.2162409820631357
Validation loss: 2.497403353990376

Epoch: 6| Step: 7
Training loss: 2.6986363358125023
Validation loss: 2.510053866962177

Epoch: 6| Step: 8
Training loss: 2.9426911930271467
Validation loss: 2.515102829850195

Epoch: 6| Step: 9
Training loss: 2.1740560215081306
Validation loss: 2.510127447940376

Epoch: 6| Step: 10
Training loss: 2.340743514397789
Validation loss: 2.52596027728179

Epoch: 6| Step: 11
Training loss: 2.4020892745046822
Validation loss: 2.492784960650715

Epoch: 6| Step: 12
Training loss: 1.9529864452807755
Validation loss: 2.4880853932190905

Epoch: 6| Step: 13
Training loss: 2.7890067642583984
Validation loss: 2.500265909994219

Epoch: 35| Step: 0
Training loss: 2.675732243221386
Validation loss: 2.5263759326328796

Epoch: 6| Step: 1
Training loss: 2.461313370353332
Validation loss: 2.520524476311674

Epoch: 6| Step: 2
Training loss: 2.336944975212123
Validation loss: 2.4824103498453938

Epoch: 6| Step: 3
Training loss: 2.480112509790284
Validation loss: 2.509004422540823

Epoch: 6| Step: 4
Training loss: 2.919995034618598
Validation loss: 2.493534087073612

Epoch: 6| Step: 5
Training loss: 2.860045140850514
Validation loss: 2.5346309546727896

Epoch: 6| Step: 6
Training loss: 1.9689389092774812
Validation loss: 2.5193346050320145

Epoch: 6| Step: 7
Training loss: 1.9643790148585694
Validation loss: 2.5206108993462513

Epoch: 6| Step: 8
Training loss: 2.033734254969519
Validation loss: 2.511096970329398

Epoch: 6| Step: 9
Training loss: 2.0619147655286763
Validation loss: 2.501876119142794

Epoch: 6| Step: 10
Training loss: 2.2833313526599768
Validation loss: 2.5030127412449126

Epoch: 6| Step: 11
Training loss: 2.2510959287426227
Validation loss: 2.4915783973887455

Epoch: 6| Step: 12
Training loss: 2.825402904575054
Validation loss: 2.5247647286012653

Epoch: 6| Step: 13
Training loss: 2.862277866056951
Validation loss: 2.5126614697447236

Epoch: 36| Step: 0
Training loss: 3.0472524555862077
Validation loss: 2.4781959193225043

Epoch: 6| Step: 1
Training loss: 2.329782702255252
Validation loss: 2.5070197099099305

Epoch: 6| Step: 2
Training loss: 2.5488836874331846
Validation loss: 2.501555801118947

Epoch: 6| Step: 3
Training loss: 3.3239708706053386
Validation loss: 2.5069863611475953

Epoch: 6| Step: 4
Training loss: 2.1224167774001756
Validation loss: 2.502233183346759

Epoch: 6| Step: 5
Training loss: 2.1637420967967036
Validation loss: 2.4855074111049342

Epoch: 6| Step: 6
Training loss: 2.7115389901434868
Validation loss: 2.4903921039968346

Epoch: 6| Step: 7
Training loss: 2.3811544684523547
Validation loss: 2.5082180531098177

Epoch: 6| Step: 8
Training loss: 1.941720979228359
Validation loss: 2.5120399313251496

Epoch: 6| Step: 9
Training loss: 2.31795518110654
Validation loss: 2.5075890906022327

Epoch: 6| Step: 10
Training loss: 2.4931548821070697
Validation loss: 2.4923225453937365

Epoch: 6| Step: 11
Training loss: 2.0509939900816567
Validation loss: 2.4938293836382575

Epoch: 6| Step: 12
Training loss: 2.5527134539119745
Validation loss: 2.515879031795361

Epoch: 6| Step: 13
Training loss: 2.083860813757311
Validation loss: 2.51230659942487

Epoch: 37| Step: 0
Training loss: 2.3360385426385566
Validation loss: 2.520762045827001

Epoch: 6| Step: 1
Training loss: 2.214478154763511
Validation loss: 2.498487269176422

Epoch: 6| Step: 2
Training loss: 2.0249618620872134
Validation loss: 2.5375903043040386

Epoch: 6| Step: 3
Training loss: 2.696192058847919
Validation loss: 2.5454385603288237

Epoch: 6| Step: 4
Training loss: 2.465609520693152
Validation loss: 2.5592830438051024

Epoch: 6| Step: 5
Training loss: 1.8309081972651562
Validation loss: 2.549771376253048

Epoch: 6| Step: 6
Training loss: 1.5214278047791256
Validation loss: 2.545527009802084

Epoch: 6| Step: 7
Training loss: 2.30471356910574
Validation loss: 2.5344068833308233

Epoch: 6| Step: 8
Training loss: 2.3376020031872784
Validation loss: 2.5322868515548422

Epoch: 6| Step: 9
Training loss: 2.2118672818590617
Validation loss: 2.541963424451498

Epoch: 6| Step: 10
Training loss: 2.387919571843197
Validation loss: 2.5756578913607013

Epoch: 6| Step: 11
Training loss: 2.7394572955439345
Validation loss: 2.560871226904181

Epoch: 6| Step: 12
Training loss: 2.779445791644695
Validation loss: 2.544757079426686

Epoch: 6| Step: 13
Training loss: 3.7368033585967986
Validation loss: 2.546741131031729

Epoch: 38| Step: 0
Training loss: 2.610432667440912
Validation loss: 2.529954335349686

Epoch: 6| Step: 1
Training loss: 2.4111802755808402
Validation loss: 2.509939430640794

Epoch: 6| Step: 2
Training loss: 2.7936909202114895
Validation loss: 2.5225332586731666

Epoch: 6| Step: 3
Training loss: 1.7899957746317343
Validation loss: 2.48993109557936

Epoch: 6| Step: 4
Training loss: 2.524804185129669
Validation loss: 2.502438508318952

Epoch: 6| Step: 5
Training loss: 1.9295475094321999
Validation loss: 2.5287143267159515

Epoch: 6| Step: 6
Training loss: 3.2881319084160165
Validation loss: 2.49780701774951

Epoch: 6| Step: 7
Training loss: 2.5923530769467766
Validation loss: 2.5531799736937026

Epoch: 6| Step: 8
Training loss: 2.3002442022963026
Validation loss: 2.5292749745170733

Epoch: 6| Step: 9
Training loss: 2.6386913917209394
Validation loss: 2.5036047695964694

Epoch: 6| Step: 10
Training loss: 2.3227565236905843
Validation loss: 2.5353809917346366

Epoch: 6| Step: 11
Training loss: 1.9331761997866068
Validation loss: 2.5117640434361834

Epoch: 6| Step: 12
Training loss: 2.5613795366199117
Validation loss: 2.538206509794709

Epoch: 6| Step: 13
Training loss: 2.6631802974779983
Validation loss: 2.4966863606299676

Epoch: 39| Step: 0
Training loss: 2.435908751841116
Validation loss: 2.4973170347912386

Epoch: 6| Step: 1
Training loss: 1.7569796475321053
Validation loss: 2.5192590058775757

Epoch: 6| Step: 2
Training loss: 2.2648127711303525
Validation loss: 2.4854061617846424

Epoch: 6| Step: 3
Training loss: 2.1117995280214252
Validation loss: 2.505601663040715

Epoch: 6| Step: 4
Training loss: 2.8143314756195807
Validation loss: 2.5067376817331026

Epoch: 6| Step: 5
Training loss: 2.050867278701533
Validation loss: 2.5125574399540804

Epoch: 6| Step: 6
Training loss: 2.51448838993107
Validation loss: 2.504021557133174

Epoch: 6| Step: 7
Training loss: 2.7482611620764916
Validation loss: 2.5085997806438174

Epoch: 6| Step: 8
Training loss: 2.691738158025563
Validation loss: 2.5361673056286707

Epoch: 6| Step: 9
Training loss: 2.085536389593362
Validation loss: 2.539674327201754

Epoch: 6| Step: 10
Training loss: 3.053104858956724
Validation loss: 2.543531395644103

Epoch: 6| Step: 11
Training loss: 2.0250413348841803
Validation loss: 2.541491640557878

Epoch: 6| Step: 12
Training loss: 2.4234916951497816
Validation loss: 2.53075284745957

Epoch: 6| Step: 13
Training loss: 2.5037369455120033
Validation loss: 2.5175619625483265

Epoch: 40| Step: 0
Training loss: 2.589139586586271
Validation loss: 2.521554053082802

Epoch: 6| Step: 1
Training loss: 2.47060208924467
Validation loss: 2.5611639183799064

Epoch: 6| Step: 2
Training loss: 2.6745589311560902
Validation loss: 2.5296873284682087

Epoch: 6| Step: 3
Training loss: 2.349505262850793
Validation loss: 2.538876570716467

Epoch: 6| Step: 4
Training loss: 1.9852384956313796
Validation loss: 2.5237252826182504

Epoch: 6| Step: 5
Training loss: 1.6262022119606747
Validation loss: 2.533641595866056

Epoch: 6| Step: 6
Training loss: 2.133562005224868
Validation loss: 2.5474440830122287

Epoch: 6| Step: 7
Training loss: 2.679003569847995
Validation loss: 2.5407170543752344

Epoch: 6| Step: 8
Training loss: 2.4858641569873905
Validation loss: 2.528326174760046

Epoch: 6| Step: 9
Training loss: 2.367429009635056
Validation loss: 2.5095167855522678

Epoch: 6| Step: 10
Training loss: 2.636843982124402
Validation loss: 2.5240579950417517

Epoch: 6| Step: 11
Training loss: 2.3409662626916052
Validation loss: 2.5221892616827635

Epoch: 6| Step: 12
Training loss: 2.628690577555079
Validation loss: 2.524381289831997

Epoch: 6| Step: 13
Training loss: 2.805962402967377
Validation loss: 2.4988345290557104

Epoch: 41| Step: 0
Training loss: 1.5988433829706532
Validation loss: 2.494861694712273

Epoch: 6| Step: 1
Training loss: 2.4078834241042335
Validation loss: 2.4956016632550635

Epoch: 6| Step: 2
Training loss: 2.217229832788809
Validation loss: 2.5016408145169393

Epoch: 6| Step: 3
Training loss: 2.631636722081073
Validation loss: 2.5195107156079395

Epoch: 6| Step: 4
Training loss: 2.923485296889302
Validation loss: 2.5060291227833895

Epoch: 6| Step: 5
Training loss: 2.107905122999695
Validation loss: 2.515768461697783

Epoch: 6| Step: 6
Training loss: 2.363562600278611
Validation loss: 2.5011109109105787

Epoch: 6| Step: 7
Training loss: 2.889191803171381
Validation loss: 2.503391278375554

Epoch: 6| Step: 8
Training loss: 2.494406068398592
Validation loss: 2.50520595674673

Epoch: 6| Step: 9
Training loss: 2.5469087001700617
Validation loss: 2.519625970996871

Epoch: 6| Step: 10
Training loss: 2.5804063355776843
Validation loss: 2.502645793228547

Epoch: 6| Step: 11
Training loss: 2.1510043260290534
Validation loss: 2.5036700727986165

Epoch: 6| Step: 12
Training loss: 2.9623421027360393
Validation loss: 2.510650724102434

Epoch: 6| Step: 13
Training loss: 1.4616051438598652
Validation loss: 2.511970970102998

Epoch: 42| Step: 0
Training loss: 2.2785817048267742
Validation loss: 2.5009858889531866

Epoch: 6| Step: 1
Training loss: 1.7181642401173605
Validation loss: 2.5246780227991312

Epoch: 6| Step: 2
Training loss: 2.3724200641442894
Validation loss: 2.5003323016252494

Epoch: 6| Step: 3
Training loss: 2.464248899812734
Validation loss: 2.5063429475134757

Epoch: 6| Step: 4
Training loss: 2.815267769255682
Validation loss: 2.5004554730987967

Epoch: 6| Step: 5
Training loss: 2.118045647047314
Validation loss: 2.4973752070991595

Epoch: 6| Step: 6
Training loss: 2.6808214818874125
Validation loss: 2.5101643246868

Epoch: 6| Step: 7
Training loss: 2.946168972320555
Validation loss: 2.530058733518473

Epoch: 6| Step: 8
Training loss: 2.0817848045396308
Validation loss: 2.4976082248423817

Epoch: 6| Step: 9
Training loss: 2.501520266822699
Validation loss: 2.5166348785851733

Epoch: 6| Step: 10
Training loss: 2.376095970655979
Validation loss: 2.4936308154288622

Epoch: 6| Step: 11
Training loss: 2.9278702045918163
Validation loss: 2.5058304826394417

Epoch: 6| Step: 12
Training loss: 2.313731406954803
Validation loss: 2.488600035268061

Epoch: 6| Step: 13
Training loss: 2.009704885501013
Validation loss: 2.5205546348506007

Epoch: 43| Step: 0
Training loss: 1.8015421089546906
Validation loss: 2.529981483685733

Epoch: 6| Step: 1
Training loss: 1.9296674225415222
Validation loss: 2.529508925966659

Epoch: 6| Step: 2
Training loss: 2.2597029536334343
Validation loss: 2.4984916746346766

Epoch: 6| Step: 3
Training loss: 2.191629055072747
Validation loss: 2.5262229356255053

Epoch: 6| Step: 4
Training loss: 2.6187209462304444
Validation loss: 2.52146588945889

Epoch: 6| Step: 5
Training loss: 2.849642172318115
Validation loss: 2.537216235174808

Epoch: 6| Step: 6
Training loss: 2.9189211352085027
Validation loss: 2.5452230670002183

Epoch: 6| Step: 7
Training loss: 1.970861241450178
Validation loss: 2.5261736386357225

Epoch: 6| Step: 8
Training loss: 3.0457971475924372
Validation loss: 2.5589416733266495

Epoch: 6| Step: 9
Training loss: 1.676873266991947
Validation loss: 2.5178315494064982

Epoch: 6| Step: 10
Training loss: 2.538345564347086
Validation loss: 2.529016459077487

Epoch: 6| Step: 11
Training loss: 2.7957700112946857
Validation loss: 2.501349831793422

Epoch: 6| Step: 12
Training loss: 2.592410465559445
Validation loss: 2.510278568716786

Epoch: 6| Step: 13
Training loss: 2.323382469197667
Validation loss: 2.508950289283339

Epoch: 44| Step: 0
Training loss: 1.82989644356898
Validation loss: 2.496365511989354

Epoch: 6| Step: 1
Training loss: 2.196734093695858
Validation loss: 2.494969153942989

Epoch: 6| Step: 2
Training loss: 2.3353018517789343
Validation loss: 2.5146038044051724

Epoch: 6| Step: 3
Training loss: 2.7294582958539872
Validation loss: 2.4961180270372045

Epoch: 6| Step: 4
Training loss: 2.077931560031819
Validation loss: 2.502838748307306

Epoch: 6| Step: 5
Training loss: 2.3913936999744707
Validation loss: 2.4892695613607265

Epoch: 6| Step: 6
Training loss: 2.5415312517290882
Validation loss: 2.4779292686359615

Epoch: 6| Step: 7
Training loss: 2.4558708228270243
Validation loss: 2.519828680259933

Epoch: 6| Step: 8
Training loss: 2.868800569641261
Validation loss: 2.497260515977628

Epoch: 6| Step: 9
Training loss: 2.658498194095729
Validation loss: 2.49809943117277

Epoch: 6| Step: 10
Training loss: 2.6082446911001935
Validation loss: 2.485311255787067

Epoch: 6| Step: 11
Training loss: 2.9587229798940164
Validation loss: 2.524996013449364

Epoch: 6| Step: 12
Training loss: 2.348675244873967
Validation loss: 2.5429476235601562

Epoch: 6| Step: 13
Training loss: 1.7035307094760728
Validation loss: 2.5139333514384887

Epoch: 45| Step: 0
Training loss: 2.8824664479376563
Validation loss: 2.5036797145780643

Epoch: 6| Step: 1
Training loss: 2.112799908719391
Validation loss: 2.5214454338598764

Epoch: 6| Step: 2
Training loss: 1.7401851899702645
Validation loss: 2.504473165287978

Epoch: 6| Step: 3
Training loss: 2.4282173050822045
Validation loss: 2.5119357017844814

Epoch: 6| Step: 4
Training loss: 1.9407073514852482
Validation loss: 2.5233701021781827

Epoch: 6| Step: 5
Training loss: 2.4134891162387455
Validation loss: 2.49699039502907

Epoch: 6| Step: 6
Training loss: 2.470409559819892
Validation loss: 2.5140847018035837

Epoch: 6| Step: 7
Training loss: 2.2850690254453596
Validation loss: 2.5318864249941027

Epoch: 6| Step: 8
Training loss: 2.943457386027835
Validation loss: 2.5276767328581635

Epoch: 6| Step: 9
Training loss: 3.0853351246535436
Validation loss: 2.507880664505128

Epoch: 6| Step: 10
Training loss: 1.9278112394242501
Validation loss: 2.493678843567381

Epoch: 6| Step: 11
Training loss: 1.9540162761326625
Validation loss: 2.5079343613659844

Epoch: 6| Step: 12
Training loss: 2.52308203493606
Validation loss: 2.502341334381192

Epoch: 6| Step: 13
Training loss: 2.5534457767451872
Validation loss: 2.4952755155551567

Epoch: 46| Step: 0
Training loss: 2.8287902386846464
Validation loss: 2.5058976227717262

Epoch: 6| Step: 1
Training loss: 1.8972197343516137
Validation loss: 2.508054553241196

Epoch: 6| Step: 2
Training loss: 1.6774804097380487
Validation loss: 2.507880957630682

Epoch: 6| Step: 3
Training loss: 2.777280911406741
Validation loss: 2.4987269021016725

Epoch: 6| Step: 4
Training loss: 2.527666734578305
Validation loss: 2.52333937888217

Epoch: 6| Step: 5
Training loss: 2.304049749552532
Validation loss: 2.527772186142695

Epoch: 6| Step: 6
Training loss: 2.4252549735453677
Validation loss: 2.535495635416874

Epoch: 6| Step: 7
Training loss: 2.5968754333422286
Validation loss: 2.5059502997172376

Epoch: 6| Step: 8
Training loss: 2.4191964380646778
Validation loss: 2.527727210991134

Epoch: 6| Step: 9
Training loss: 2.210770995000157
Validation loss: 2.4851914509759907

Epoch: 6| Step: 10
Training loss: 2.8130894361179037
Validation loss: 2.480334565145136

Epoch: 6| Step: 11
Training loss: 2.646602298600836
Validation loss: 2.5224527459055275

Epoch: 6| Step: 12
Training loss: 1.8316004395017245
Validation loss: 2.50952013450349

Epoch: 6| Step: 13
Training loss: 2.589397040919461
Validation loss: 2.525505682853327

Epoch: 47| Step: 0
Training loss: 2.3206967636095692
Validation loss: 2.504682859851571

Epoch: 6| Step: 1
Training loss: 2.1791453353781147
Validation loss: 2.5130200216394147

Epoch: 6| Step: 2
Training loss: 2.4601646541913453
Validation loss: 2.5178315967525124

Epoch: 6| Step: 3
Training loss: 2.105245433281019
Validation loss: 2.5036935383649683

Epoch: 6| Step: 4
Training loss: 2.883364575461177
Validation loss: 2.519090039165365

Epoch: 6| Step: 5
Training loss: 2.531768651502389
Validation loss: 2.499203221188495

Epoch: 6| Step: 6
Training loss: 3.0728730451860606
Validation loss: 2.532005581896828

Epoch: 6| Step: 7
Training loss: 1.766713439874048
Validation loss: 2.521510385329411

Epoch: 6| Step: 8
Training loss: 2.355625229630797
Validation loss: 2.5200900303435967

Epoch: 6| Step: 9
Training loss: 2.202925760986227
Validation loss: 2.5063648898331548

Epoch: 6| Step: 10
Training loss: 1.84106521393968
Validation loss: 2.513112679550682

Epoch: 6| Step: 11
Training loss: 2.7114781436985407
Validation loss: 2.5126212848344682

Epoch: 6| Step: 12
Training loss: 2.617466698173282
Validation loss: 2.5188431305307852

Epoch: 6| Step: 13
Training loss: 2.351754114195456
Validation loss: 2.5195900922503456

Epoch: 48| Step: 0
Training loss: 2.265821461545319
Validation loss: 2.5166346417425225

Epoch: 6| Step: 1
Training loss: 2.262489833071295
Validation loss: 2.5066281509822215

Epoch: 6| Step: 2
Training loss: 1.9119465245226597
Validation loss: 2.544207855559256

Epoch: 6| Step: 3
Training loss: 2.543543784290921
Validation loss: 2.528553157932303

Epoch: 6| Step: 4
Training loss: 2.711317843709121
Validation loss: 2.5491238360398802

Epoch: 6| Step: 5
Training loss: 2.694874780467074
Validation loss: 2.5330139732673205

Epoch: 6| Step: 6
Training loss: 3.05443960291275
Validation loss: 2.5702714385334646

Epoch: 6| Step: 7
Training loss: 2.1636897568274542
Validation loss: 2.543178028220392

Epoch: 6| Step: 8
Training loss: 2.967858913605378
Validation loss: 2.5284747777270122

Epoch: 6| Step: 9
Training loss: 2.075126147744453
Validation loss: 2.509502328799015

Epoch: 6| Step: 10
Training loss: 2.1275414247884044
Validation loss: 2.5080062300185397

Epoch: 6| Step: 11
Training loss: 1.9102361307428233
Validation loss: 2.490683920182106

Epoch: 6| Step: 12
Training loss: 3.069705505162952
Validation loss: 2.4941242549063287

Epoch: 6| Step: 13
Training loss: 1.6769366782692794
Validation loss: 2.494958323816732

Epoch: 49| Step: 0
Training loss: 3.1241418804719556
Validation loss: 2.482883269427925

Epoch: 6| Step: 1
Training loss: 1.7456766948974
Validation loss: 2.4777660473896077

Epoch: 6| Step: 2
Training loss: 2.1093088775443607
Validation loss: 2.498870419578698

Epoch: 6| Step: 3
Training loss: 2.2104291028084297
Validation loss: 2.5394730534339054

Epoch: 6| Step: 4
Training loss: 2.422333507820075
Validation loss: 2.5079908693761883

Epoch: 6| Step: 5
Training loss: 2.216168796108053
Validation loss: 2.4896326312899606

Epoch: 6| Step: 6
Training loss: 1.974427408197242
Validation loss: 2.5298748441003416

Epoch: 6| Step: 7
Training loss: 2.064395726902824
Validation loss: 2.517020855120694

Epoch: 6| Step: 8
Training loss: 2.092408618823054
Validation loss: 2.4986812133124747

Epoch: 6| Step: 9
Training loss: 2.720363620407001
Validation loss: 2.4895443507591444

Epoch: 6| Step: 10
Training loss: 2.401322707624859
Validation loss: 2.5379303897613363

Epoch: 6| Step: 11
Training loss: 2.826328950746815
Validation loss: 2.5085300199463605

Epoch: 6| Step: 12
Training loss: 3.0881571452620427
Validation loss: 2.491339376785581

Epoch: 6| Step: 13
Training loss: 2.336620932533717
Validation loss: 2.505712943433249

Epoch: 50| Step: 0
Training loss: 1.9630777905558612
Validation loss: 2.5072238346100963

Epoch: 6| Step: 1
Training loss: 1.9942528284920056
Validation loss: 2.4955808682722886

Epoch: 6| Step: 2
Training loss: 2.214715217211271
Validation loss: 2.4972249523860315

Epoch: 6| Step: 3
Training loss: 1.998963802847669
Validation loss: 2.492148451862939

Epoch: 6| Step: 4
Training loss: 2.59533238687538
Validation loss: 2.50852282833818

Epoch: 6| Step: 5
Training loss: 3.49162380098116
Validation loss: 2.4984690588062715

Epoch: 6| Step: 6
Training loss: 1.968802678447949
Validation loss: 2.4857270342505666

Epoch: 6| Step: 7
Training loss: 2.194116015208813
Validation loss: 2.483921257505305

Epoch: 6| Step: 8
Training loss: 2.861523264196978
Validation loss: 2.485804916033553

Epoch: 6| Step: 9
Training loss: 2.282432772094473
Validation loss: 2.513101279333279

Epoch: 6| Step: 10
Training loss: 2.5497037004848453
Validation loss: 2.4950827240974434

Epoch: 6| Step: 11
Training loss: 2.326953977463332
Validation loss: 2.497287502597749

Epoch: 6| Step: 12
Training loss: 2.3185732709878835
Validation loss: 2.5390714987570906

Epoch: 6| Step: 13
Training loss: 2.7242362255676933
Validation loss: 2.521787578417865

Epoch: 51| Step: 0
Training loss: 2.565474388915127
Validation loss: 2.5030055575977768

Epoch: 6| Step: 1
Training loss: 2.5783384292575193
Validation loss: 2.527466265437242

Epoch: 6| Step: 2
Training loss: 2.1663008038638227
Validation loss: 2.547341473694272

Epoch: 6| Step: 3
Training loss: 1.9749686709466312
Validation loss: 2.525277520971183

Epoch: 6| Step: 4
Training loss: 2.8987642088653285
Validation loss: 2.539343535691298

Epoch: 6| Step: 5
Training loss: 1.8511860138771152
Validation loss: 2.515873946040767

Epoch: 6| Step: 6
Training loss: 2.1162724505797943
Validation loss: 2.5777660081401055

Epoch: 6| Step: 7
Training loss: 2.670970562897272
Validation loss: 2.5767358601677715

Epoch: 6| Step: 8
Training loss: 1.8530405318000727
Validation loss: 2.5648179464197405

Epoch: 6| Step: 9
Training loss: 2.710246413032263
Validation loss: 2.5606115562403247

Epoch: 6| Step: 10
Training loss: 2.5953448803998618
Validation loss: 2.5354645105224116

Epoch: 6| Step: 11
Training loss: 2.531222967309596
Validation loss: 2.514771903256926

Epoch: 6| Step: 12
Training loss: 2.326605179128143
Validation loss: 2.5257397867833427

Epoch: 6| Step: 13
Training loss: 2.392919000749237
Validation loss: 2.4834982166553963

Epoch: 52| Step: 0
Training loss: 1.9665790274322754
Validation loss: 2.523120761830296

Epoch: 6| Step: 1
Training loss: 2.306754733629704
Validation loss: 2.4895889303445085

Epoch: 6| Step: 2
Training loss: 2.661536845761797
Validation loss: 2.495157311920017

Epoch: 6| Step: 3
Training loss: 2.230616148773187
Validation loss: 2.490544765301639

Epoch: 6| Step: 4
Training loss: 2.3419664844880534
Validation loss: 2.5200046143918455

Epoch: 6| Step: 5
Training loss: 2.755246879053213
Validation loss: 2.5370466005754033

Epoch: 6| Step: 6
Training loss: 2.5880914574194964
Validation loss: 2.499922719396769

Epoch: 6| Step: 7
Training loss: 2.240794955608624
Validation loss: 2.5184445425489628

Epoch: 6| Step: 8
Training loss: 2.338610800306729
Validation loss: 2.4891944538971105

Epoch: 6| Step: 9
Training loss: 2.3967549638395353
Validation loss: 2.4986392848040513

Epoch: 6| Step: 10
Training loss: 2.029376530483692
Validation loss: 2.496649961233168

Epoch: 6| Step: 11
Training loss: 2.131509012273482
Validation loss: 2.5113787621184223

Epoch: 6| Step: 12
Training loss: 2.810867853240153
Validation loss: 2.499319699231996

Epoch: 6| Step: 13
Training loss: 2.7256846066653067
Validation loss: 2.4907177584361357

Epoch: 53| Step: 0
Training loss: 2.406318465410661
Validation loss: 2.5101637706293687

Epoch: 6| Step: 1
Training loss: 2.350864851870012
Validation loss: 2.541746706301625

Epoch: 6| Step: 2
Training loss: 2.331623188655957
Validation loss: 2.533723007733363

Epoch: 6| Step: 3
Training loss: 2.1477684505124386
Validation loss: 2.530397012417429

Epoch: 6| Step: 4
Training loss: 3.025663911458531
Validation loss: 2.5069224678642557

Epoch: 6| Step: 5
Training loss: 1.8369779844382101
Validation loss: 2.537653683798777

Epoch: 6| Step: 6
Training loss: 2.7803944332591177
Validation loss: 2.5423387566483573

Epoch: 6| Step: 7
Training loss: 2.091540865008963
Validation loss: 2.5273052922132764

Epoch: 6| Step: 8
Training loss: 2.5175625938960424
Validation loss: 2.5368983352513923

Epoch: 6| Step: 9
Training loss: 2.1371075766320002
Validation loss: 2.5401218023907504

Epoch: 6| Step: 10
Training loss: 2.535245873229228
Validation loss: 2.5111359532664403

Epoch: 6| Step: 11
Training loss: 2.311562941116553
Validation loss: 2.503562733082052

Epoch: 6| Step: 12
Training loss: 2.457450988529161
Validation loss: 2.505793026734332

Epoch: 6| Step: 13
Training loss: 2.456901995681113
Validation loss: 2.493268216153177

Epoch: 54| Step: 0
Training loss: 1.8292169162854774
Validation loss: 2.491646399994998

Epoch: 6| Step: 1
Training loss: 2.1208248635393354
Validation loss: 2.515144942071528

Epoch: 6| Step: 2
Training loss: 2.3543060621554193
Validation loss: 2.479971920528702

Epoch: 6| Step: 3
Training loss: 2.1643295398755096
Validation loss: 2.4958708200415094

Epoch: 6| Step: 4
Training loss: 2.680679360156715
Validation loss: 2.501340395494847

Epoch: 6| Step: 5
Training loss: 3.2659059248560367
Validation loss: 2.4830873299260223

Epoch: 6| Step: 6
Training loss: 2.5431789422660085
Validation loss: 2.4888950072035443

Epoch: 6| Step: 7
Training loss: 2.470132464822142
Validation loss: 2.5245808155857126

Epoch: 6| Step: 8
Training loss: 2.149233805729538
Validation loss: 2.5128552054473623

Epoch: 6| Step: 9
Training loss: 2.027730857039185
Validation loss: 2.5124488667208253

Epoch: 6| Step: 10
Training loss: 2.282263439241275
Validation loss: 2.508710468704947

Epoch: 6| Step: 11
Training loss: 2.389045842014716
Validation loss: 2.4962411437994185

Epoch: 6| Step: 12
Training loss: 2.803851839920981
Validation loss: 2.498086626274929

Epoch: 6| Step: 13
Training loss: 1.9701130099728312
Validation loss: 2.495744508639104

Epoch: 55| Step: 0
Training loss: 1.8313264121299875
Validation loss: 2.4882142014505324

Epoch: 6| Step: 1
Training loss: 2.3985208006070793
Validation loss: 2.533361676542775

Epoch: 6| Step: 2
Training loss: 2.100605686579059
Validation loss: 2.5250733135142887

Epoch: 6| Step: 3
Training loss: 2.5861927839968377
Validation loss: 2.5084994792302795

Epoch: 6| Step: 4
Training loss: 2.768909465253427
Validation loss: 2.5223485764345823

Epoch: 6| Step: 5
Training loss: 2.227497533589206
Validation loss: 2.520663710212672

Epoch: 6| Step: 6
Training loss: 2.703355371437915
Validation loss: 2.522700419609789

Epoch: 6| Step: 7
Training loss: 2.255353704147211
Validation loss: 2.519501583900567

Epoch: 6| Step: 8
Training loss: 2.694579978584107
Validation loss: 2.5018693769475786

Epoch: 6| Step: 9
Training loss: 2.051785119813223
Validation loss: 2.4998932656709787

Epoch: 6| Step: 10
Training loss: 2.1715817699491398
Validation loss: 2.536487372909048

Epoch: 6| Step: 11
Training loss: 2.328903784841764
Validation loss: 2.499791375038411

Epoch: 6| Step: 12
Training loss: 2.2152222002233333
Validation loss: 2.4859924809042173

Epoch: 6| Step: 13
Training loss: 2.5914756271096437
Validation loss: 2.5173335621228894

Epoch: 56| Step: 0
Training loss: 2.0408645793017683
Validation loss: 2.5085672449014362

Epoch: 6| Step: 1
Training loss: 3.0643306632338576
Validation loss: 2.494655300121962

Epoch: 6| Step: 2
Training loss: 2.694987047974669
Validation loss: 2.492762324929036

Epoch: 6| Step: 3
Training loss: 1.8265208191435685
Validation loss: 2.514473361244571

Epoch: 6| Step: 4
Training loss: 2.1577782122009936
Validation loss: 2.5026298836542176

Epoch: 6| Step: 5
Training loss: 2.526728889870073
Validation loss: 2.5109798754613957

Epoch: 6| Step: 6
Training loss: 2.6916888217388224
Validation loss: 2.477370249753765

Epoch: 6| Step: 7
Training loss: 2.5153101374553097
Validation loss: 2.48387987973153

Epoch: 6| Step: 8
Training loss: 1.7643804299152424
Validation loss: 2.503243329334556

Epoch: 6| Step: 9
Training loss: 3.0629124266397434
Validation loss: 2.4642777233836664

Epoch: 6| Step: 10
Training loss: 2.594122342879742
Validation loss: 2.4892816693337676

Epoch: 6| Step: 11
Training loss: 2.0431998069326958
Validation loss: 2.488971720203665

Epoch: 6| Step: 12
Training loss: 1.7837831654770175
Validation loss: 2.510742828475888

Epoch: 6| Step: 13
Training loss: 2.059371540720788
Validation loss: 2.528886280092921

Epoch: 57| Step: 0
Training loss: 1.976651035180558
Validation loss: 2.5229730326254187

Epoch: 6| Step: 1
Training loss: 1.9962046493509762
Validation loss: 2.5301607245003224

Epoch: 6| Step: 2
Training loss: 2.4500218098506585
Validation loss: 2.4973463916094323

Epoch: 6| Step: 3
Training loss: 2.239552188627163
Validation loss: 2.5146055821590956

Epoch: 6| Step: 4
Training loss: 2.544136681561699
Validation loss: 2.52595635234004

Epoch: 6| Step: 5
Training loss: 2.24634785417259
Validation loss: 2.4865533567398477

Epoch: 6| Step: 6
Training loss: 2.4153605801256974
Validation loss: 2.5006863923352056

Epoch: 6| Step: 7
Training loss: 2.7288413594041927
Validation loss: 2.4837815317636354

Epoch: 6| Step: 8
Training loss: 1.9243350527793295
Validation loss: 2.4959967668504235

Epoch: 6| Step: 9
Training loss: 2.618522462997251
Validation loss: 2.5020461451053477

Epoch: 6| Step: 10
Training loss: 1.9065186358165556
Validation loss: 2.513938180312593

Epoch: 6| Step: 11
Training loss: 2.598608590994784
Validation loss: 2.492169004429474

Epoch: 6| Step: 12
Training loss: 2.372849343952169
Validation loss: 2.533558314982642

Epoch: 6| Step: 13
Training loss: 2.843950201679662
Validation loss: 2.5086648350230045

Epoch: 58| Step: 0
Training loss: 2.254103838690797
Validation loss: 2.4784642087204087

Epoch: 6| Step: 1
Training loss: 2.314222982690052
Validation loss: 2.5056128436369587

Epoch: 6| Step: 2
Training loss: 2.4667095008773834
Validation loss: 2.5174288788074266

Epoch: 6| Step: 3
Training loss: 2.906187159361354
Validation loss: 2.509445071004146

Epoch: 6| Step: 4
Training loss: 2.436974493257189
Validation loss: 2.5170493032925854

Epoch: 6| Step: 5
Training loss: 2.7835837870164464
Validation loss: 2.49799169301

Epoch: 6| Step: 6
Training loss: 2.1034827552997104
Validation loss: 2.493631938858063

Epoch: 6| Step: 7
Training loss: 2.592710539491317
Validation loss: 2.5182220290568416

Epoch: 6| Step: 8
Training loss: 1.8329197532707022
Validation loss: 2.5195286477245524

Epoch: 6| Step: 9
Training loss: 2.6120235684019404
Validation loss: 2.482095132129139

Epoch: 6| Step: 10
Training loss: 2.178104605230356
Validation loss: 2.508371768120443

Epoch: 6| Step: 11
Training loss: 2.6168161612729723
Validation loss: 2.51868592110553

Epoch: 6| Step: 12
Training loss: 1.963072689589725
Validation loss: 2.4931311818738986

Epoch: 6| Step: 13
Training loss: 1.7137035150435254
Validation loss: 2.49233625679547

Epoch: 59| Step: 0
Training loss: 2.523295395573081
Validation loss: 2.46039277360401

Epoch: 6| Step: 1
Training loss: 2.1416293941277496
Validation loss: 2.5003292979485994

Epoch: 6| Step: 2
Training loss: 2.5331440185616003
Validation loss: 2.496756690973858

Epoch: 6| Step: 3
Training loss: 2.244178977485865
Validation loss: 2.4863445703961964

Epoch: 6| Step: 4
Training loss: 2.2127599315651008
Validation loss: 2.487711195869951

Epoch: 6| Step: 5
Training loss: 2.415882202510348
Validation loss: 2.5053368348429954

Epoch: 6| Step: 6
Training loss: 2.611621369450052
Validation loss: 2.501513865194884

Epoch: 6| Step: 7
Training loss: 2.292919047920127
Validation loss: 2.4983521037152645

Epoch: 6| Step: 8
Training loss: 1.6740907621036387
Validation loss: 2.5194627382884676

Epoch: 6| Step: 9
Training loss: 1.9628487198185474
Validation loss: 2.47908472411924

Epoch: 6| Step: 10
Training loss: 2.922407295577589
Validation loss: 2.4985493265763647

Epoch: 6| Step: 11
Training loss: 2.589452837732391
Validation loss: 2.5259962621848953

Epoch: 6| Step: 12
Training loss: 2.687828753568259
Validation loss: 2.500416562025766

Epoch: 6| Step: 13
Training loss: 2.1222334411528716
Validation loss: 2.5202202695118374

Epoch: 60| Step: 0
Training loss: 3.256486142431687
Validation loss: 2.5041717690041896

Epoch: 6| Step: 1
Training loss: 1.94718958975016
Validation loss: 2.4752887454645083

Epoch: 6| Step: 2
Training loss: 2.6813423229764264
Validation loss: 2.474261878950333

Epoch: 6| Step: 3
Training loss: 1.6992350961183955
Validation loss: 2.5117233853769516

Epoch: 6| Step: 4
Training loss: 2.932169196291154
Validation loss: 2.5032329159832467

Epoch: 6| Step: 5
Training loss: 2.1816169102266927
Validation loss: 2.466836694923064

Epoch: 6| Step: 6
Training loss: 2.3428186219069134
Validation loss: 2.492509189360478

Epoch: 6| Step: 7
Training loss: 1.408550076857583
Validation loss: 2.4718467508237856

Epoch: 6| Step: 8
Training loss: 2.182576442397929
Validation loss: 2.484371465204631

Epoch: 6| Step: 9
Training loss: 2.397872013192195
Validation loss: 2.4940703164797764

Epoch: 6| Step: 10
Training loss: 2.500449140257633
Validation loss: 2.4810669505567433

Epoch: 6| Step: 11
Training loss: 2.528927997805536
Validation loss: 2.500297147257694

Epoch: 6| Step: 12
Training loss: 2.4093449492998706
Validation loss: 2.488247745913158

Epoch: 6| Step: 13
Training loss: 2.004740342523785
Validation loss: 2.506644051032142

Epoch: 61| Step: 0
Training loss: 2.1744856478352763
Validation loss: 2.5035901596664814

Epoch: 6| Step: 1
Training loss: 2.47306600975114
Validation loss: 2.505801922958935

Epoch: 6| Step: 2
Training loss: 2.1998266325178366
Validation loss: 2.5363258990441486

Epoch: 6| Step: 3
Training loss: 2.550637023493632
Validation loss: 2.530498000475753

Epoch: 6| Step: 4
Training loss: 2.5399503593399966
Validation loss: 2.5031098414933233

Epoch: 6| Step: 5
Training loss: 2.3444040021777917
Validation loss: 2.4988998535573055

Epoch: 6| Step: 6
Training loss: 1.81307744002927
Validation loss: 2.5206268451916287

Epoch: 6| Step: 7
Training loss: 2.4035408324964616
Validation loss: 2.561535847719016

Epoch: 6| Step: 8
Training loss: 2.989511752628513
Validation loss: 2.560116279452225

Epoch: 6| Step: 9
Training loss: 2.388238251473412
Validation loss: 2.5696649247732366

Epoch: 6| Step: 10
Training loss: 2.045420588587176
Validation loss: 2.5414980431158356

Epoch: 6| Step: 11
Training loss: 2.4434144084779432
Validation loss: 2.534423440077546

Epoch: 6| Step: 12
Training loss: 2.620734791401601
Validation loss: 2.5289084667737796

Epoch: 6| Step: 13
Training loss: 1.9266490412547181
Validation loss: 2.485165812028167

Epoch: 62| Step: 0
Training loss: 2.763445410194624
Validation loss: 2.4918095253228945

Epoch: 6| Step: 1
Training loss: 2.2800131802428902
Validation loss: 2.4873979438919647

Epoch: 6| Step: 2
Training loss: 2.2794751095158605
Validation loss: 2.4849121984453175

Epoch: 6| Step: 3
Training loss: 2.2692881468739223
Validation loss: 2.489274446060959

Epoch: 6| Step: 4
Training loss: 2.676322759702036
Validation loss: 2.5008381074501576

Epoch: 6| Step: 5
Training loss: 2.2397821264235582
Validation loss: 2.4953541503181977

Epoch: 6| Step: 6
Training loss: 2.3220213688631883
Validation loss: 2.5045952208605002

Epoch: 6| Step: 7
Training loss: 2.717307837323917
Validation loss: 2.516876738561651

Epoch: 6| Step: 8
Training loss: 2.568434658325123
Validation loss: 2.4779373267850726

Epoch: 6| Step: 9
Training loss: 2.2202766431668786
Validation loss: 2.511554845165653

Epoch: 6| Step: 10
Training loss: 1.7694559312837173
Validation loss: 2.492268926711309

Epoch: 6| Step: 11
Training loss: 2.183778922157501
Validation loss: 2.512320217576962

Epoch: 6| Step: 12
Training loss: 2.1934893765736825
Validation loss: 2.4996782334207563

Epoch: 6| Step: 13
Training loss: 2.2381649286692
Validation loss: 2.5059253885122605

Epoch: 63| Step: 0
Training loss: 2.703819847104182
Validation loss: 2.456757967437208

Epoch: 6| Step: 1
Training loss: 1.932040243594489
Validation loss: 2.510314216475468

Epoch: 6| Step: 2
Training loss: 2.265420838726899
Validation loss: 2.5002075268123463

Epoch: 6| Step: 3
Training loss: 2.8460861503338353
Validation loss: 2.4724607787124806

Epoch: 6| Step: 4
Training loss: 2.3146424550066134
Validation loss: 2.505282677851278

Epoch: 6| Step: 5
Training loss: 2.0300615795548342
Validation loss: 2.5097452165340384

Epoch: 6| Step: 6
Training loss: 2.175398349457129
Validation loss: 2.473364015099304

Epoch: 6| Step: 7
Training loss: 1.9484514396554287
Validation loss: 2.495106788011392

Epoch: 6| Step: 8
Training loss: 2.2278037375979993
Validation loss: 2.492274267904466

Epoch: 6| Step: 9
Training loss: 2.131233049700053
Validation loss: 2.4746528266397774

Epoch: 6| Step: 10
Training loss: 2.5800467062574133
Validation loss: 2.522989979399867

Epoch: 6| Step: 11
Training loss: 2.850693829054049
Validation loss: 2.51405836966021

Epoch: 6| Step: 12
Training loss: 2.4043818566482624
Validation loss: 2.491081925314856

Epoch: 6| Step: 13
Training loss: 2.1066978137011425
Validation loss: 2.4824754502592636

Epoch: 64| Step: 0
Training loss: 2.015395277076874
Validation loss: 2.4901147352413373

Epoch: 6| Step: 1
Training loss: 2.011937990556428
Validation loss: 2.524474254803017

Epoch: 6| Step: 2
Training loss: 1.8569865553969551
Validation loss: 2.5195593070900255

Epoch: 6| Step: 3
Training loss: 1.757409486135553
Validation loss: 2.5314353121517374

Epoch: 6| Step: 4
Training loss: 2.5066660699776016
Validation loss: 2.555824260187685

Epoch: 6| Step: 5
Training loss: 2.4450741977783825
Validation loss: 2.524029310999342

Epoch: 6| Step: 6
Training loss: 2.2963781533070375
Validation loss: 2.507374900595366

Epoch: 6| Step: 7
Training loss: 2.2672053645959567
Validation loss: 2.4832775163031386

Epoch: 6| Step: 8
Training loss: 2.901984910101538
Validation loss: 2.535264744173458

Epoch: 6| Step: 9
Training loss: 2.4853381323311003
Validation loss: 2.5204772434994482

Epoch: 6| Step: 10
Training loss: 2.322277226270696
Validation loss: 2.510870901671416

Epoch: 6| Step: 11
Training loss: 1.6903361752460542
Validation loss: 2.509120675227885

Epoch: 6| Step: 12
Training loss: 2.750290161777209
Validation loss: 2.498482704668159

Epoch: 6| Step: 13
Training loss: 2.80033839088325
Validation loss: 2.4922329092323365

Epoch: 65| Step: 0
Training loss: 1.7728096274828893
Validation loss: 2.487525126395808

Epoch: 6| Step: 1
Training loss: 2.1409762574633966
Validation loss: 2.4860218355877617

Epoch: 6| Step: 2
Training loss: 2.2929533611866484
Validation loss: 2.5029841573510767

Epoch: 6| Step: 3
Training loss: 2.6259536827285146
Validation loss: 2.495634017738248

Epoch: 6| Step: 4
Training loss: 2.0218075111599068
Validation loss: 2.4944469450003766

Epoch: 6| Step: 5
Training loss: 1.4837102104064512
Validation loss: 2.4782804272829506

Epoch: 6| Step: 6
Training loss: 2.556896969130413
Validation loss: 2.4903035153034505

Epoch: 6| Step: 7
Training loss: 1.939774439568634
Validation loss: 2.480054012679461

Epoch: 6| Step: 8
Training loss: 2.0500083411442467
Validation loss: 2.497323924525362

Epoch: 6| Step: 9
Training loss: 2.9315174948638583
Validation loss: 2.515948967775443

Epoch: 6| Step: 10
Training loss: 2.719132845878023
Validation loss: 2.4986826445785537

Epoch: 6| Step: 11
Training loss: 2.862316848692606
Validation loss: 2.490716003516772

Epoch: 6| Step: 12
Training loss: 2.3474488634871284
Validation loss: 2.4971360650603582

Epoch: 6| Step: 13
Training loss: 2.2804480410266454
Validation loss: 2.5205618551895506

Epoch: 66| Step: 0
Training loss: 2.048727347601923
Validation loss: 2.510598699742004

Epoch: 6| Step: 1
Training loss: 2.28050000129136
Validation loss: 2.4993582219658252

Epoch: 6| Step: 2
Training loss: 2.3748140764243013
Validation loss: 2.490250611096479

Epoch: 6| Step: 3
Training loss: 2.4653470693769166
Validation loss: 2.509893138530736

Epoch: 6| Step: 4
Training loss: 2.3861019255234712
Validation loss: 2.5068191826952337

Epoch: 6| Step: 5
Training loss: 2.099584733685345
Validation loss: 2.525866352303038

Epoch: 6| Step: 6
Training loss: 2.4079372881140384
Validation loss: 2.482839705756495

Epoch: 6| Step: 7
Training loss: 2.921886423670015
Validation loss: 2.495056366599102

Epoch: 6| Step: 8
Training loss: 2.0784446068990516
Validation loss: 2.5090736870170445

Epoch: 6| Step: 9
Training loss: 2.2636448066152863
Validation loss: 2.486368950615761

Epoch: 6| Step: 10
Training loss: 2.133300501848946
Validation loss: 2.509311105461803

Epoch: 6| Step: 11
Training loss: 2.3230190739203698
Validation loss: 2.503230328512711

Epoch: 6| Step: 12
Training loss: 2.214941059645849
Validation loss: 2.4930089794496566

Epoch: 6| Step: 13
Training loss: 2.2286016395812727
Validation loss: 2.5035945521774807

Epoch: 67| Step: 0
Training loss: 2.254430224041277
Validation loss: 2.491750569243959

Epoch: 6| Step: 1
Training loss: 2.8877425385045954
Validation loss: 2.5173890462326565

Epoch: 6| Step: 2
Training loss: 2.9636419421205713
Validation loss: 2.497349223847894

Epoch: 6| Step: 3
Training loss: 2.308157684400511
Validation loss: 2.4834936405983927

Epoch: 6| Step: 4
Training loss: 2.228717604234289
Validation loss: 2.501032631913506

Epoch: 6| Step: 5
Training loss: 2.1460285900376617
Validation loss: 2.4762878265649766

Epoch: 6| Step: 6
Training loss: 1.9362689999066218
Validation loss: 2.4873671357216334

Epoch: 6| Step: 7
Training loss: 2.254068510935226
Validation loss: 2.4992616834785566

Epoch: 6| Step: 8
Training loss: 2.2566013981871706
Validation loss: 2.4852774878194586

Epoch: 6| Step: 9
Training loss: 2.120745045361256
Validation loss: 2.52716307507712

Epoch: 6| Step: 10
Training loss: 1.9637981082066818
Validation loss: 2.5076122897238187

Epoch: 6| Step: 11
Training loss: 2.100106227549499
Validation loss: 2.512151179605705

Epoch: 6| Step: 12
Training loss: 2.7547494449672043
Validation loss: 2.528659711826528

Epoch: 6| Step: 13
Training loss: 1.9791534691086157
Validation loss: 2.5165753830108204

Epoch: 68| Step: 0
Training loss: 2.0844267328296557
Validation loss: 2.536832924088454

Epoch: 6| Step: 1
Training loss: 1.5582228293312221
Validation loss: 2.5394686486560367

Epoch: 6| Step: 2
Training loss: 3.244840193988216
Validation loss: 2.505185899746406

Epoch: 6| Step: 3
Training loss: 2.0649965377667754
Validation loss: 2.5024256224095724

Epoch: 6| Step: 4
Training loss: 2.9397356981081555
Validation loss: 2.5189550879496485

Epoch: 6| Step: 5
Training loss: 2.504798480244617
Validation loss: 2.489288525437409

Epoch: 6| Step: 6
Training loss: 1.2960431291974308
Validation loss: 2.488898280126966

Epoch: 6| Step: 7
Training loss: 2.5150710734037838
Validation loss: 2.500428655750646

Epoch: 6| Step: 8
Training loss: 1.835906332847153
Validation loss: 2.512520202947717

Epoch: 6| Step: 9
Training loss: 1.9149160545017565
Validation loss: 2.4832541218441184

Epoch: 6| Step: 10
Training loss: 2.444944506368435
Validation loss: 2.527312005859254

Epoch: 6| Step: 11
Training loss: 2.183677603488336
Validation loss: 2.4973568931516485

Epoch: 6| Step: 12
Training loss: 2.477171332676019
Validation loss: 2.5215628385462834

Epoch: 6| Step: 13
Training loss: 2.258573199363063
Validation loss: 2.472790819376195

Epoch: 69| Step: 0
Training loss: 2.494641091747617
Validation loss: 2.5050392860484236

Epoch: 6| Step: 1
Training loss: 2.4894985892159105
Validation loss: 2.488674641746716

Epoch: 6| Step: 2
Training loss: 1.8857077976214274
Validation loss: 2.5013891969782147

Epoch: 6| Step: 3
Training loss: 2.0314873189941123
Validation loss: 2.478549677477364

Epoch: 6| Step: 4
Training loss: 1.6051734225738588
Validation loss: 2.51439622521598

Epoch: 6| Step: 5
Training loss: 2.030464255139732
Validation loss: 2.493556524561753

Epoch: 6| Step: 6
Training loss: 2.655685454569509
Validation loss: 2.5048831456353335

Epoch: 6| Step: 7
Training loss: 2.520974389115239
Validation loss: 2.476780172864319

Epoch: 6| Step: 8
Training loss: 2.616237912211628
Validation loss: 2.479260303962244

Epoch: 6| Step: 9
Training loss: 2.400699207655642
Validation loss: 2.481070137711552

Epoch: 6| Step: 10
Training loss: 2.7289044397382525
Validation loss: 2.4909214802172115

Epoch: 6| Step: 11
Training loss: 1.9783469125377522
Validation loss: 2.4825187161992766

Epoch: 6| Step: 12
Training loss: 2.103235195951643
Validation loss: 2.4918510664342337

Epoch: 6| Step: 13
Training loss: 2.205395549839076
Validation loss: 2.488301602953559

Epoch: 70| Step: 0
Training loss: 2.3827448600799257
Validation loss: 2.5115299104426723

Epoch: 6| Step: 1
Training loss: 2.151204605643214
Validation loss: 2.4843274637788735

Epoch: 6| Step: 2
Training loss: 2.621486037527645
Validation loss: 2.4674002905336594

Epoch: 6| Step: 3
Training loss: 2.1574545550284343
Validation loss: 2.47666001955204

Epoch: 6| Step: 4
Training loss: 2.0274565266606284
Validation loss: 2.5055856295028596

Epoch: 6| Step: 5
Training loss: 2.3173179954984042
Validation loss: 2.4676851639975648

Epoch: 6| Step: 6
Training loss: 2.102452880113641
Validation loss: 2.4813773666221173

Epoch: 6| Step: 7
Training loss: 1.5583073632563333
Validation loss: 2.4802576971502113

Epoch: 6| Step: 8
Training loss: 2.255429604286096
Validation loss: 2.4865578232927725

Epoch: 6| Step: 9
Training loss: 2.0750838664927533
Validation loss: 2.487291379707521

Epoch: 6| Step: 10
Training loss: 2.2228156436558457
Validation loss: 2.4817320642848895

Epoch: 6| Step: 11
Training loss: 2.9128179679486146
Validation loss: 2.490228335304665

Epoch: 6| Step: 12
Training loss: 2.2649981453658503
Validation loss: 2.477354995892889

Epoch: 6| Step: 13
Training loss: 2.664234681592189
Validation loss: 2.5043426466647265

Epoch: 71| Step: 0
Training loss: 2.308034348204167
Validation loss: 2.515307783578255

Epoch: 6| Step: 1
Training loss: 2.2475827265738113
Validation loss: 2.5363636247210826

Epoch: 6| Step: 2
Training loss: 1.8435255657603282
Validation loss: 2.5195680758522805

Epoch: 6| Step: 3
Training loss: 2.209743325530769
Validation loss: 2.530103235324808

Epoch: 6| Step: 4
Training loss: 2.735069579053594
Validation loss: 2.5264360624661153

Epoch: 6| Step: 5
Training loss: 2.607086091440709
Validation loss: 2.5073553046875108

Epoch: 6| Step: 6
Training loss: 2.7079941659467277
Validation loss: 2.49142780902698

Epoch: 6| Step: 7
Training loss: 1.9660727447331132
Validation loss: 2.4836526136371493

Epoch: 6| Step: 8
Training loss: 1.996200528806787
Validation loss: 2.536982039030534

Epoch: 6| Step: 9
Training loss: 2.2851554153310443
Validation loss: 2.4886693886296554

Epoch: 6| Step: 10
Training loss: 2.179699641368235
Validation loss: 2.4826013083529457

Epoch: 6| Step: 11
Training loss: 2.5792990121077204
Validation loss: 2.5202428162872894

Epoch: 6| Step: 12
Training loss: 1.945569737596501
Validation loss: 2.493484558153525

Epoch: 6| Step: 13
Training loss: 2.124165427186509
Validation loss: 2.492370662515608

Epoch: 72| Step: 0
Training loss: 2.6237645647972294
Validation loss: 2.4965950666923282

Epoch: 6| Step: 1
Training loss: 1.8971589103785265
Validation loss: 2.508574167098129

Epoch: 6| Step: 2
Training loss: 1.8969970387348716
Validation loss: 2.4762440184858425

Epoch: 6| Step: 3
Training loss: 2.5454240656241627
Validation loss: 2.4982469770365574

Epoch: 6| Step: 4
Training loss: 2.0468894433829634
Validation loss: 2.493169194579928

Epoch: 6| Step: 5
Training loss: 1.8584822106134748
Validation loss: 2.4928652121922976

Epoch: 6| Step: 6
Training loss: 2.0105110765601237
Validation loss: 2.467792035399969

Epoch: 6| Step: 7
Training loss: 2.0685145218164007
Validation loss: 2.459035988514203

Epoch: 6| Step: 8
Training loss: 2.895041725767196
Validation loss: 2.4682301485009113

Epoch: 6| Step: 9
Training loss: 2.393566839715683
Validation loss: 2.4751876641099666

Epoch: 6| Step: 10
Training loss: 2.408626621255889
Validation loss: 2.4934639367493627

Epoch: 6| Step: 11
Training loss: 2.9125930312856196
Validation loss: 2.493813473587622

Epoch: 6| Step: 12
Training loss: 1.8575400265761817
Validation loss: 2.453401035725716

Epoch: 6| Step: 13
Training loss: 2.129316209989781
Validation loss: 2.4853849617363313

Epoch: 73| Step: 0
Training loss: 2.3126393868992827
Validation loss: 2.5114843279899994

Epoch: 6| Step: 1
Training loss: 1.4530962869412043
Validation loss: 2.5123405418594573

Epoch: 6| Step: 2
Training loss: 2.2599489867943032
Validation loss: 2.529741536333593

Epoch: 6| Step: 3
Training loss: 2.8160028472961858
Validation loss: 2.5477745324262173

Epoch: 6| Step: 4
Training loss: 1.976009366889714
Validation loss: 2.5393841192538824

Epoch: 6| Step: 5
Training loss: 2.555814721838127
Validation loss: 2.543307342879793

Epoch: 6| Step: 6
Training loss: 3.0500371711842247
Validation loss: 2.520956435757618

Epoch: 6| Step: 7
Training loss: 1.7227123709812133
Validation loss: 2.5245276931580554

Epoch: 6| Step: 8
Training loss: 2.6444648948469944
Validation loss: 2.497018355295356

Epoch: 6| Step: 9
Training loss: 2.5815543745758296
Validation loss: 2.51522754506922

Epoch: 6| Step: 10
Training loss: 2.0092391945611388
Validation loss: 2.484620871862984

Epoch: 6| Step: 11
Training loss: 2.000686051004159
Validation loss: 2.4860506624607663

Epoch: 6| Step: 12
Training loss: 2.050733351375157
Validation loss: 2.496606168251635

Epoch: 6| Step: 13
Training loss: 2.0806357912223206
Validation loss: 2.491491429812738

Epoch: 74| Step: 0
Training loss: 2.2230389471722107
Validation loss: 2.493961751005723

Epoch: 6| Step: 1
Training loss: 1.9658405664862595
Validation loss: 2.487258189794802

Epoch: 6| Step: 2
Training loss: 1.733762684550842
Validation loss: 2.506574061522869

Epoch: 6| Step: 3
Training loss: 2.2143093318822333
Validation loss: 2.491046464934618

Epoch: 6| Step: 4
Training loss: 2.1826273463480024
Validation loss: 2.495099223271926

Epoch: 6| Step: 5
Training loss: 2.806848060412377
Validation loss: 2.511304323802871

Epoch: 6| Step: 6
Training loss: 2.7978457678823068
Validation loss: 2.5121624575937167

Epoch: 6| Step: 7
Training loss: 2.3236005201273797
Validation loss: 2.492025850448708

Epoch: 6| Step: 8
Training loss: 1.85448575935234
Validation loss: 2.4942944747325884

Epoch: 6| Step: 9
Training loss: 2.4033637633846423
Validation loss: 2.4871809206841737

Epoch: 6| Step: 10
Training loss: 1.574768121998132
Validation loss: 2.514310513108074

Epoch: 6| Step: 11
Training loss: 2.566614987319591
Validation loss: 2.5078874459956597

Epoch: 6| Step: 12
Training loss: 2.5801650789957966
Validation loss: 2.5196915134450166

Epoch: 6| Step: 13
Training loss: 1.8622858039526686
Validation loss: 2.517942052579914

Epoch: 75| Step: 0
Training loss: 1.831486928149081
Validation loss: 2.510738357467826

Epoch: 6| Step: 1
Training loss: 2.1492044085762876
Validation loss: 2.529154675584634

Epoch: 6| Step: 2
Training loss: 1.984894812076586
Validation loss: 2.5135773011353475

Epoch: 6| Step: 3
Training loss: 2.1847189527410205
Validation loss: 2.5255650703225587

Epoch: 6| Step: 4
Training loss: 3.111142830081493
Validation loss: 2.47410838960355

Epoch: 6| Step: 5
Training loss: 1.986929383327101
Validation loss: 2.4810170446238597

Epoch: 6| Step: 6
Training loss: 3.090917041584744
Validation loss: 2.492422286148196

Epoch: 6| Step: 7
Training loss: 2.3730000558009987
Validation loss: 2.471847329545467

Epoch: 6| Step: 8
Training loss: 1.911293985922249
Validation loss: 2.4757337015709417

Epoch: 6| Step: 9
Training loss: 2.344061055205215
Validation loss: 2.4735801220289675

Epoch: 6| Step: 10
Training loss: 1.6429797032055093
Validation loss: 2.464313431893921

Epoch: 6| Step: 11
Training loss: 1.7944890642999443
Validation loss: 2.5024071786912283

Epoch: 6| Step: 12
Training loss: 2.370339388308219
Validation loss: 2.469801521898351

Epoch: 6| Step: 13
Training loss: 2.3986157279628824
Validation loss: 2.5026581778571177

Epoch: 76| Step: 0
Training loss: 2.950319117726647
Validation loss: 2.471578088764994

Epoch: 6| Step: 1
Training loss: 2.0097039364317757
Validation loss: 2.5020138894215753

Epoch: 6| Step: 2
Training loss: 2.1635353740906123
Validation loss: 2.5146430806223283

Epoch: 6| Step: 3
Training loss: 2.5608777749694576
Validation loss: 2.4919435945779034

Epoch: 6| Step: 4
Training loss: 2.0199478280534526
Validation loss: 2.508088489846276

Epoch: 6| Step: 5
Training loss: 1.585176633024138
Validation loss: 2.5159541007597337

Epoch: 6| Step: 6
Training loss: 2.275827940472704
Validation loss: 2.517449035570622

Epoch: 6| Step: 7
Training loss: 1.9997839811012927
Validation loss: 2.5376471071243194

Epoch: 6| Step: 8
Training loss: 2.6749317909172134
Validation loss: 2.5076997915829558

Epoch: 6| Step: 9
Training loss: 2.657497875826427
Validation loss: 2.508020125020883

Epoch: 6| Step: 10
Training loss: 1.4708559886423114
Validation loss: 2.4742992661447025

Epoch: 6| Step: 11
Training loss: 2.3073231255056506
Validation loss: 2.508277604338407

Epoch: 6| Step: 12
Training loss: 2.2991059555918345
Validation loss: 2.47793996472073

Epoch: 6| Step: 13
Training loss: 2.060724476758139
Validation loss: 2.4816512205447228

Epoch: 77| Step: 0
Training loss: 2.0329336378052814
Validation loss: 2.5045937215788148

Epoch: 6| Step: 1
Training loss: 2.29241011149024
Validation loss: 2.479741796465154

Epoch: 6| Step: 2
Training loss: 2.6048290376703656
Validation loss: 2.4906007744007015

Epoch: 6| Step: 3
Training loss: 1.6997093457099655
Validation loss: 2.488975679520151

Epoch: 6| Step: 4
Training loss: 2.6899013879845666
Validation loss: 2.4989971136147964

Epoch: 6| Step: 5
Training loss: 2.917218092608317
Validation loss: 2.4736801847732695

Epoch: 6| Step: 6
Training loss: 1.7525801031114856
Validation loss: 2.492025595321776

Epoch: 6| Step: 7
Training loss: 1.7561086577424108
Validation loss: 2.48645187034028

Epoch: 6| Step: 8
Training loss: 2.528613188847491
Validation loss: 2.491656494970409

Epoch: 6| Step: 9
Training loss: 1.765054593741318
Validation loss: 2.4730652867054963

Epoch: 6| Step: 10
Training loss: 2.0773615761372586
Validation loss: 2.469822196069208

Epoch: 6| Step: 11
Training loss: 2.3130018359884916
Validation loss: 2.5181318788299567

Epoch: 6| Step: 12
Training loss: 1.796883889881202
Validation loss: 2.510610752332767

Epoch: 6| Step: 13
Training loss: 2.247269563159247
Validation loss: 2.5154721547324943

Epoch: 78| Step: 0
Training loss: 2.240036307960258
Validation loss: 2.532384751519644

Epoch: 6| Step: 1
Training loss: 1.24838930306721
Validation loss: 2.5305502124380554

Epoch: 6| Step: 2
Training loss: 2.7235675091333134
Validation loss: 2.515768824981541

Epoch: 6| Step: 3
Training loss: 1.8996914462465695
Validation loss: 2.5227748445633216

Epoch: 6| Step: 4
Training loss: 2.5150461419425
Validation loss: 2.480097585227132

Epoch: 6| Step: 5
Training loss: 2.2569255208583336
Validation loss: 2.4913439065320793

Epoch: 6| Step: 6
Training loss: 1.8472799357462697
Validation loss: 2.4714897662560644

Epoch: 6| Step: 7
Training loss: 2.4681312654849927
Validation loss: 2.478524843584076

Epoch: 6| Step: 8
Training loss: 2.309401627362561
Validation loss: 2.4777562486409845

Epoch: 6| Step: 9
Training loss: 2.792486914840545
Validation loss: 2.476521231932224

Epoch: 6| Step: 10
Training loss: 2.4490414788007318
Validation loss: 2.5026536368337577

Epoch: 6| Step: 11
Training loss: 2.124343770743998
Validation loss: 2.482001044105886

Epoch: 6| Step: 12
Training loss: 1.8150781513759724
Validation loss: 2.485111567233368

Epoch: 6| Step: 13
Training loss: 1.931859882435043
Validation loss: 2.4719468194339744

Epoch: 79| Step: 0
Training loss: 2.2186554364751596
Validation loss: 2.46077681728339

Epoch: 6| Step: 1
Training loss: 2.369424801330516
Validation loss: 2.5309868193019063

Epoch: 6| Step: 2
Training loss: 1.5543345908636352
Validation loss: 2.477712819350817

Epoch: 6| Step: 3
Training loss: 2.3388097959098966
Validation loss: 2.4741327538826283

Epoch: 6| Step: 4
Training loss: 2.4444755121144888
Validation loss: 2.545952214359696

Epoch: 6| Step: 5
Training loss: 2.328489543869202
Validation loss: 2.550410276331315

Epoch: 6| Step: 6
Training loss: 1.8752677726274656
Validation loss: 2.5437712372464274

Epoch: 6| Step: 7
Training loss: 3.0528046641979936
Validation loss: 2.5266927188177712

Epoch: 6| Step: 8
Training loss: 2.4713720569559308
Validation loss: 2.508121111014677

Epoch: 6| Step: 9
Training loss: 1.6932081531201297
Validation loss: 2.513383921481754

Epoch: 6| Step: 10
Training loss: 1.931371471448962
Validation loss: 2.4929153989771327

Epoch: 6| Step: 11
Training loss: 2.49323100184324
Validation loss: 2.470883586258864

Epoch: 6| Step: 12
Training loss: 1.771389690589946
Validation loss: 2.491885973189647

Epoch: 6| Step: 13
Training loss: 2.072401151980235
Validation loss: 2.45715474039248

Epoch: 80| Step: 0
Training loss: 1.9885783694839865
Validation loss: 2.464763706558024

Epoch: 6| Step: 1
Training loss: 2.179887441126593
Validation loss: 2.4836324945743424

Epoch: 6| Step: 2
Training loss: 2.5685479968760285
Validation loss: 2.4675029550552066

Epoch: 6| Step: 3
Training loss: 2.2345279027733587
Validation loss: 2.4727674944352005

Epoch: 6| Step: 4
Training loss: 2.433140107761282
Validation loss: 2.4575182862117266

Epoch: 6| Step: 5
Training loss: 3.030802113586631
Validation loss: 2.4626251408363755

Epoch: 6| Step: 6
Training loss: 2.3457937866274357
Validation loss: 2.473166462837727

Epoch: 6| Step: 7
Training loss: 2.0175112392864065
Validation loss: 2.472981002236406

Epoch: 6| Step: 8
Training loss: 2.0431658502032497
Validation loss: 2.5009961210015117

Epoch: 6| Step: 9
Training loss: 1.9350207063025398
Validation loss: 2.4820731993882412

Epoch: 6| Step: 10
Training loss: 1.7986124014962313
Validation loss: 2.491442577997948

Epoch: 6| Step: 11
Training loss: 1.9560885109836221
Validation loss: 2.4940874277773126

Epoch: 6| Step: 12
Training loss: 2.317847589888337
Validation loss: 2.503136876173734

Epoch: 6| Step: 13
Training loss: 2.0461568955927687
Validation loss: 2.483686515689198

Epoch: 81| Step: 0
Training loss: 2.118062982042422
Validation loss: 2.5002371198736073

Epoch: 6| Step: 1
Training loss: 2.0710438714052284
Validation loss: 2.4898866737319705

Epoch: 6| Step: 2
Training loss: 1.8787739602069313
Validation loss: 2.520909006123171

Epoch: 6| Step: 3
Training loss: 2.3761753386397473
Validation loss: 2.4675464674192233

Epoch: 6| Step: 4
Training loss: 2.192321368675456
Validation loss: 2.4890064757628014

Epoch: 6| Step: 5
Training loss: 1.9093294128869651
Validation loss: 2.487060439028447

Epoch: 6| Step: 6
Training loss: 2.321669467541862
Validation loss: 2.493248852031243

Epoch: 6| Step: 7
Training loss: 2.0134672695518647
Validation loss: 2.4919508499785876

Epoch: 6| Step: 8
Training loss: 2.458225754361368
Validation loss: 2.479777498621125

Epoch: 6| Step: 9
Training loss: 2.3792099030725344
Validation loss: 2.4756005762634246

Epoch: 6| Step: 10
Training loss: 1.8578474678361292
Validation loss: 2.4359209211403967

Epoch: 6| Step: 11
Training loss: 1.9584122770373418
Validation loss: 2.492025300331228

Epoch: 6| Step: 12
Training loss: 2.6291961736781526
Validation loss: 2.468138993378859

Epoch: 6| Step: 13
Training loss: 2.3930749245059832
Validation loss: 2.4619470614529697

Epoch: 82| Step: 0
Training loss: 1.9024163140276793
Validation loss: 2.454466256689974

Epoch: 6| Step: 1
Training loss: 2.0377761466462236
Validation loss: 2.4769429617577368

Epoch: 6| Step: 2
Training loss: 2.110555360936924
Validation loss: 2.4643970372872834

Epoch: 6| Step: 3
Training loss: 2.11710123822482
Validation loss: 2.4662028020437226

Epoch: 6| Step: 4
Training loss: 2.195446729798696
Validation loss: 2.4702501849318015

Epoch: 6| Step: 5
Training loss: 2.8935499085030565
Validation loss: 2.500409895354781

Epoch: 6| Step: 6
Training loss: 2.012972246762322
Validation loss: 2.522576199865488

Epoch: 6| Step: 7
Training loss: 1.6477146823844497
Validation loss: 2.509516587623569

Epoch: 6| Step: 8
Training loss: 1.8788544138144223
Validation loss: 2.557907509442252

Epoch: 6| Step: 9
Training loss: 2.10546422048446
Validation loss: 2.5422222567266886

Epoch: 6| Step: 10
Training loss: 2.3719442686638867
Validation loss: 2.578560563102185

Epoch: 6| Step: 11
Training loss: 2.6298143652030777
Validation loss: 2.577335760900706

Epoch: 6| Step: 12
Training loss: 1.8337965799044114
Validation loss: 2.544500777214653

Epoch: 6| Step: 13
Training loss: 2.578203049836557
Validation loss: 2.5197316644491408

Epoch: 83| Step: 0
Training loss: 2.223436590691794
Validation loss: 2.4631205569174526

Epoch: 6| Step: 1
Training loss: 1.9270291569973
Validation loss: 2.4839179540277105

Epoch: 6| Step: 2
Training loss: 1.7219236723568359
Validation loss: 2.4645131449138273

Epoch: 6| Step: 3
Training loss: 2.2511601106361767
Validation loss: 2.479168825121883

Epoch: 6| Step: 4
Training loss: 2.285917445503549
Validation loss: 2.464243884880087

Epoch: 6| Step: 5
Training loss: 1.7197070838219335
Validation loss: 2.476314961510278

Epoch: 6| Step: 6
Training loss: 2.450927624938519
Validation loss: 2.4765555204178806

Epoch: 6| Step: 7
Training loss: 1.8942338533089647
Validation loss: 2.4971893087256496

Epoch: 6| Step: 8
Training loss: 2.3084049567209535
Validation loss: 2.482149114662952

Epoch: 6| Step: 9
Training loss: 1.8927457910364203
Validation loss: 2.4696013033089566

Epoch: 6| Step: 10
Training loss: 2.366603766756164
Validation loss: 2.4545110362676366

Epoch: 6| Step: 11
Training loss: 2.3811907142608053
Validation loss: 2.505385399877137

Epoch: 6| Step: 12
Training loss: 2.2028127679000735
Validation loss: 2.502546332912016

Epoch: 6| Step: 13
Training loss: 2.8028470857400087
Validation loss: 2.5040235645665154

Epoch: 84| Step: 0
Training loss: 2.1173127197171824
Validation loss: 2.489876244417429

Epoch: 6| Step: 1
Training loss: 2.5846178081434714
Validation loss: 2.5364390117267055

Epoch: 6| Step: 2
Training loss: 2.2172817691389843
Validation loss: 2.504048359806112

Epoch: 6| Step: 3
Training loss: 1.3262137629729518
Validation loss: 2.51018121546466

Epoch: 6| Step: 4
Training loss: 2.3542274759816633
Validation loss: 2.5025307640931094

Epoch: 6| Step: 5
Training loss: 2.2064683584593556
Validation loss: 2.501078682884655

Epoch: 6| Step: 6
Training loss: 2.5033527780210254
Validation loss: 2.4931587550894596

Epoch: 6| Step: 7
Training loss: 2.048567443497197
Validation loss: 2.4897388957647064

Epoch: 6| Step: 8
Training loss: 2.1688468185932295
Validation loss: 2.4726898689254493

Epoch: 6| Step: 9
Training loss: 1.8881199532283246
Validation loss: 2.4846293161288866

Epoch: 6| Step: 10
Training loss: 1.9113796817352235
Validation loss: 2.4726634977133033

Epoch: 6| Step: 11
Training loss: 2.5215307064512738
Validation loss: 2.4848134515640585

Epoch: 6| Step: 12
Training loss: 2.482095500341383
Validation loss: 2.4665129300055746

Epoch: 6| Step: 13
Training loss: 1.709521609196257
Validation loss: 2.4663568156035707

Epoch: 85| Step: 0
Training loss: 1.6644742930779992
Validation loss: 2.4763078047173828

Epoch: 6| Step: 1
Training loss: 2.568521635202423
Validation loss: 2.4698759320151136

Epoch: 6| Step: 2
Training loss: 2.86567136504459
Validation loss: 2.5011882501237217

Epoch: 6| Step: 3
Training loss: 1.9679895173506952
Validation loss: 2.4878587748390992

Epoch: 6| Step: 4
Training loss: 1.5146187657020727
Validation loss: 2.4818082141496096

Epoch: 6| Step: 5
Training loss: 1.7924005277052726
Validation loss: 2.5030250446810633

Epoch: 6| Step: 6
Training loss: 2.5178081445844502
Validation loss: 2.522896124968522

Epoch: 6| Step: 7
Training loss: 2.508843991163474
Validation loss: 2.5138983635580425

Epoch: 6| Step: 8
Training loss: 1.591641096671996
Validation loss: 2.4808615145771418

Epoch: 6| Step: 9
Training loss: 2.0551740991209853
Validation loss: 2.4977931136583997

Epoch: 6| Step: 10
Training loss: 2.0771012616954114
Validation loss: 2.500467002483624

Epoch: 6| Step: 11
Training loss: 2.0486263324868914
Validation loss: 2.4930213402254133

Epoch: 6| Step: 12
Training loss: 2.395886583703965
Validation loss: 2.4943373763572345

Epoch: 6| Step: 13
Training loss: 2.042350135637395
Validation loss: 2.4944757541592746

Epoch: 86| Step: 0
Training loss: 2.3066257408495225
Validation loss: 2.495395377639387

Epoch: 6| Step: 1
Training loss: 2.653136099892122
Validation loss: 2.474008962548175

Epoch: 6| Step: 2
Training loss: 2.341422794806723
Validation loss: 2.4990864992104393

Epoch: 6| Step: 3
Training loss: 1.9951130049592112
Validation loss: 2.4769641859329683

Epoch: 6| Step: 4
Training loss: 1.8478582485502586
Validation loss: 2.4880233463314325

Epoch: 6| Step: 5
Training loss: 2.0684603485445345
Validation loss: 2.4790538046228456

Epoch: 6| Step: 6
Training loss: 2.0744096628610604
Validation loss: 2.477413139706793

Epoch: 6| Step: 7
Training loss: 1.891047532967413
Validation loss: 2.5003724774400995

Epoch: 6| Step: 8
Training loss: 1.7445758818995776
Validation loss: 2.442805149353115

Epoch: 6| Step: 9
Training loss: 2.2021566657274216
Validation loss: 2.4647343082786803

Epoch: 6| Step: 10
Training loss: 1.7463419693011664
Validation loss: 2.4901993174360317

Epoch: 6| Step: 11
Training loss: 2.341139394873626
Validation loss: 2.468701929517718

Epoch: 6| Step: 12
Training loss: 1.8393463304665816
Validation loss: 2.5258047458143054

Epoch: 6| Step: 13
Training loss: 2.574305901911704
Validation loss: 2.530291057777079

Epoch: 87| Step: 0
Training loss: 1.9145113049041613
Validation loss: 2.5245437716641232

Epoch: 6| Step: 1
Training loss: 2.058696360627577
Validation loss: 2.513532633211229

Epoch: 6| Step: 2
Training loss: 1.9531315917857515
Validation loss: 2.4834653040576447

Epoch: 6| Step: 3
Training loss: 1.4444375353835408
Validation loss: 2.536007041392895

Epoch: 6| Step: 4
Training loss: 1.8015284777403935
Validation loss: 2.5552569268996153

Epoch: 6| Step: 5
Training loss: 1.7080832585225592
Validation loss: 2.5122673894899314

Epoch: 6| Step: 6
Training loss: 2.4362169459034893
Validation loss: 2.468830606295495

Epoch: 6| Step: 7
Training loss: 1.9980032012730518
Validation loss: 2.4707243062796365

Epoch: 6| Step: 8
Training loss: 1.7666575695499385
Validation loss: 2.497395812118472

Epoch: 6| Step: 9
Training loss: 2.7397747673964026
Validation loss: 2.500027131887074

Epoch: 6| Step: 10
Training loss: 2.191177981858423
Validation loss: 2.495240831390955

Epoch: 6| Step: 11
Training loss: 2.268328296993064
Validation loss: 2.52424450421101

Epoch: 6| Step: 12
Training loss: 2.969642103575385
Validation loss: 2.4987736555146687

Epoch: 6| Step: 13
Training loss: 1.9749374041717698
Validation loss: 2.483254713909069

Epoch: 88| Step: 0
Training loss: 2.0484308052099074
Validation loss: 2.493600793388697

Epoch: 6| Step: 1
Training loss: 1.992502404550133
Validation loss: 2.476764787019824

Epoch: 6| Step: 2
Training loss: 1.6557705023174571
Validation loss: 2.4800294261770937

Epoch: 6| Step: 3
Training loss: 1.7831040487519334
Validation loss: 2.4978176605312568

Epoch: 6| Step: 4
Training loss: 2.3465924129695384
Validation loss: 2.5015009348098296

Epoch: 6| Step: 5
Training loss: 2.016364738099127
Validation loss: 2.495303510961423

Epoch: 6| Step: 6
Training loss: 2.684478658288995
Validation loss: 2.4703696688061596

Epoch: 6| Step: 7
Training loss: 1.9424101845340724
Validation loss: 2.4582382900378503

Epoch: 6| Step: 8
Training loss: 2.1377147187475694
Validation loss: 2.4610589052963237

Epoch: 6| Step: 9
Training loss: 2.073865957484484
Validation loss: 2.458762847965083

Epoch: 6| Step: 10
Training loss: 2.2587411416095926
Validation loss: 2.4938954526824735

Epoch: 6| Step: 11
Training loss: 2.615343679888807
Validation loss: 2.434497418506523

Epoch: 6| Step: 12
Training loss: 1.968228770694523
Validation loss: 2.4966697923651746

Epoch: 6| Step: 13
Training loss: 1.8809570413903094
Validation loss: 2.492187244889616

Epoch: 89| Step: 0
Training loss: 1.927650148354702
Validation loss: 2.497402144746625

Epoch: 6| Step: 1
Training loss: 1.7448790419227236
Validation loss: 2.49607432820023

Epoch: 6| Step: 2
Training loss: 2.1718790616882546
Validation loss: 2.4856446258893006

Epoch: 6| Step: 3
Training loss: 2.324938135452038
Validation loss: 2.490689081303368

Epoch: 6| Step: 4
Training loss: 2.0937135607836557
Validation loss: 2.485918808952124

Epoch: 6| Step: 5
Training loss: 1.5570162101053682
Validation loss: 2.488155830931396

Epoch: 6| Step: 6
Training loss: 2.438262428961524
Validation loss: 2.5062382432213175

Epoch: 6| Step: 7
Training loss: 2.5195121350413467
Validation loss: 2.476471507168796

Epoch: 6| Step: 8
Training loss: 1.883259447161943
Validation loss: 2.487701508173216

Epoch: 6| Step: 9
Training loss: 1.9061688890554545
Validation loss: 2.4740637880570673

Epoch: 6| Step: 10
Training loss: 2.0945774549932072
Validation loss: 2.4750649209290074

Epoch: 6| Step: 11
Training loss: 2.2731331428170116
Validation loss: 2.5131853962253103

Epoch: 6| Step: 12
Training loss: 2.345781590199927
Validation loss: 2.4994873792880767

Epoch: 6| Step: 13
Training loss: 1.9317494237362534
Validation loss: 2.460150521203974

Epoch: 90| Step: 0
Training loss: 2.4339855974659907
Validation loss: 2.495201560309027

Epoch: 6| Step: 1
Training loss: 2.165834658383704
Validation loss: 2.477443277715001

Epoch: 6| Step: 2
Training loss: 2.2562121359059906
Validation loss: 2.490000994348902

Epoch: 6| Step: 3
Training loss: 1.8731117913509459
Validation loss: 2.469005225464843

Epoch: 6| Step: 4
Training loss: 2.063614630785232
Validation loss: 2.4602973387935982

Epoch: 6| Step: 5
Training loss: 1.6987602930830803
Validation loss: 2.453715777684008

Epoch: 6| Step: 6
Training loss: 2.1133729699726884
Validation loss: 2.4587762212785385

Epoch: 6| Step: 7
Training loss: 1.9739094294493214
Validation loss: 2.4760074093676474

Epoch: 6| Step: 8
Training loss: 1.5433372347283263
Validation loss: 2.4850469036524157

Epoch: 6| Step: 9
Training loss: 2.3342993870838504
Validation loss: 2.4652844985607634

Epoch: 6| Step: 10
Training loss: 1.6669827479411998
Validation loss: 2.4738066027775414

Epoch: 6| Step: 11
Training loss: 2.1694049648720104
Validation loss: 2.4749144356319355

Epoch: 6| Step: 12
Training loss: 2.024941139778604
Validation loss: 2.45829648189618

Epoch: 6| Step: 13
Training loss: 2.4270169708828004
Validation loss: 2.5147458153298707

Epoch: 91| Step: 0
Training loss: 2.35674922926188
Validation loss: 2.491398908800275

Epoch: 6| Step: 1
Training loss: 1.2949267541209457
Validation loss: 2.5254109621028125

Epoch: 6| Step: 2
Training loss: 1.7959008271293238
Validation loss: 2.531038251897501

Epoch: 6| Step: 3
Training loss: 1.3782427436890847
Validation loss: 2.5325847136578137

Epoch: 6| Step: 4
Training loss: 2.6013207308947717
Validation loss: 2.572197050292304

Epoch: 6| Step: 5
Training loss: 2.0950361258731025
Validation loss: 2.556176252474942

Epoch: 6| Step: 6
Training loss: 2.1009831534013936
Validation loss: 2.5557409480706808

Epoch: 6| Step: 7
Training loss: 1.8233641883475689
Validation loss: 2.5337348954350083

Epoch: 6| Step: 8
Training loss: 2.486874073198083
Validation loss: 2.5402669074779163

Epoch: 6| Step: 9
Training loss: 2.2168491441387372
Validation loss: 2.492806831026001

Epoch: 6| Step: 10
Training loss: 2.6930307653959584
Validation loss: 2.4703597602932006

Epoch: 6| Step: 11
Training loss: 1.9199581356252826
Validation loss: 2.4542949664565716

Epoch: 6| Step: 12
Training loss: 2.077124333208166
Validation loss: 2.4763530397937448

Epoch: 6| Step: 13
Training loss: 1.4167465112662387
Validation loss: 2.4735088113998365

Epoch: 92| Step: 0
Training loss: 2.123101227598872
Validation loss: 2.4986397221427787

Epoch: 6| Step: 1
Training loss: 1.6986761520311546
Validation loss: 2.4817586753736878

Epoch: 6| Step: 2
Training loss: 2.1643279976605947
Validation loss: 2.4795758099431953

Epoch: 6| Step: 3
Training loss: 2.3823401811600147
Validation loss: 2.4975090332682504

Epoch: 6| Step: 4
Training loss: 2.026985033820315
Validation loss: 2.4813198601843593

Epoch: 6| Step: 5
Training loss: 2.6324817664809177
Validation loss: 2.47885192882107

Epoch: 6| Step: 6
Training loss: 2.1651115216082926
Validation loss: 2.4991982843456046

Epoch: 6| Step: 7
Training loss: 1.8197256296451672
Validation loss: 2.480603312048915

Epoch: 6| Step: 8
Training loss: 2.011363885190818
Validation loss: 2.4761342943000306

Epoch: 6| Step: 9
Training loss: 2.528460248638066
Validation loss: 2.44590281713286

Epoch: 6| Step: 10
Training loss: 1.5316132873570492
Validation loss: 2.4458587978755233

Epoch: 6| Step: 11
Training loss: 1.7430134684162146
Validation loss: 2.5213496937771525

Epoch: 6| Step: 12
Training loss: 2.039894840297572
Validation loss: 2.5237610474700998

Epoch: 6| Step: 13
Training loss: 1.8066151550147191
Validation loss: 2.523100256651678

Epoch: 93| Step: 0
Training loss: 1.9039194838385214
Validation loss: 2.4764072437738887

Epoch: 6| Step: 1
Training loss: 1.5954497006532211
Validation loss: 2.5597441981832585

Epoch: 6| Step: 2
Training loss: 2.016247202332667
Validation loss: 2.549019953693896

Epoch: 6| Step: 3
Training loss: 1.8521704339685603
Validation loss: 2.575139754555201

Epoch: 6| Step: 4
Training loss: 2.291135090528657
Validation loss: 2.543016205719396

Epoch: 6| Step: 5
Training loss: 2.3518185903823174
Validation loss: 2.548867575387644

Epoch: 6| Step: 6
Training loss: 1.39955077797921
Validation loss: 2.522018159429368

Epoch: 6| Step: 7
Training loss: 2.2612745939301693
Validation loss: 2.498740244406351

Epoch: 6| Step: 8
Training loss: 1.383740647033675
Validation loss: 2.45589418689456

Epoch: 6| Step: 9
Training loss: 2.0345896336649787
Validation loss: 2.4918530916453743

Epoch: 6| Step: 10
Training loss: 1.534416738901931
Validation loss: 2.5063995785998263

Epoch: 6| Step: 11
Training loss: 2.3138314615394244
Validation loss: 2.473090271826844

Epoch: 6| Step: 12
Training loss: 2.534379696165501
Validation loss: 2.427428983598327

Epoch: 6| Step: 13
Training loss: 2.498742550280154
Validation loss: 2.4667509330927393

Epoch: 94| Step: 0
Training loss: 1.898905755209876
Validation loss: 2.489769108011237

Epoch: 6| Step: 1
Training loss: 2.0357843114525536
Validation loss: 2.4809711898602913

Epoch: 6| Step: 2
Training loss: 1.8932393181767864
Validation loss: 2.5035155294490434

Epoch: 6| Step: 3
Training loss: 1.5926938016572434
Validation loss: 2.4561267475657336

Epoch: 6| Step: 4
Training loss: 2.367737356853593
Validation loss: 2.47555903533624

Epoch: 6| Step: 5
Training loss: 1.4845159363345761
Validation loss: 2.512729407824286

Epoch: 6| Step: 6
Training loss: 1.9353418944184038
Validation loss: 2.4878003959806945

Epoch: 6| Step: 7
Training loss: 2.1896017604334386
Validation loss: 2.5200869083051423

Epoch: 6| Step: 8
Training loss: 2.8208784977853227
Validation loss: 2.5099723760444994

Epoch: 6| Step: 9
Training loss: 2.2806138497244937
Validation loss: 2.5179280781891062

Epoch: 6| Step: 10
Training loss: 2.537780344091982
Validation loss: 2.50845213880141

Epoch: 6| Step: 11
Training loss: 1.8489709414916364
Validation loss: 2.4953280345518394

Epoch: 6| Step: 12
Training loss: 1.6934423723307361
Validation loss: 2.4954138015252485

Epoch: 6| Step: 13
Training loss: 1.7979357698146923
Validation loss: 2.481843118058557

Epoch: 95| Step: 0
Training loss: 1.5436976003055018
Validation loss: 2.4746242604037554

Epoch: 6| Step: 1
Training loss: 1.5727791462921534
Validation loss: 2.459730904083563

Epoch: 6| Step: 2
Training loss: 1.755570537500528
Validation loss: 2.484316427312104

Epoch: 6| Step: 3
Training loss: 1.89265118941137
Validation loss: 2.499938471354865

Epoch: 6| Step: 4
Training loss: 2.2130564318605535
Validation loss: 2.4862399189244244

Epoch: 6| Step: 5
Training loss: 1.9791934630604435
Validation loss: 2.494598450210038

Epoch: 6| Step: 6
Training loss: 1.8341082611328885
Validation loss: 2.4840611753445416

Epoch: 6| Step: 7
Training loss: 2.1222570331019712
Validation loss: 2.501961185185247

Epoch: 6| Step: 8
Training loss: 2.4004961057352086
Validation loss: 2.4721345115013533

Epoch: 6| Step: 9
Training loss: 1.9013438642155802
Validation loss: 2.557872253105298

Epoch: 6| Step: 10
Training loss: 1.6328922234013574
Validation loss: 2.471485376978338

Epoch: 6| Step: 11
Training loss: 2.7975774128066146
Validation loss: 2.456230991474399

Epoch: 6| Step: 12
Training loss: 2.0492410743652094
Validation loss: 2.4689518568351905

Epoch: 6| Step: 13
Training loss: 1.8459592611212963
Validation loss: 2.509232813067687

Epoch: 96| Step: 0
Training loss: 1.8403019749552103
Validation loss: 2.4710789250184315

Epoch: 6| Step: 1
Training loss: 2.097240669668999
Validation loss: 2.484884053985068

Epoch: 6| Step: 2
Training loss: 2.015854460200913
Validation loss: 2.447709254683147

Epoch: 6| Step: 3
Training loss: 1.7997946198172028
Validation loss: 2.5076015934341793

Epoch: 6| Step: 4
Training loss: 1.6714003414988583
Validation loss: 2.5071862885777603

Epoch: 6| Step: 5
Training loss: 2.933993905277592
Validation loss: 2.5026908380516186

Epoch: 6| Step: 6
Training loss: 1.9799676445523349
Validation loss: 2.476923742733164

Epoch: 6| Step: 7
Training loss: 2.1067430818959525
Validation loss: 2.478076395886637

Epoch: 6| Step: 8
Training loss: 1.8147672744645604
Validation loss: 2.46471562281769

Epoch: 6| Step: 9
Training loss: 1.8870918742153855
Validation loss: 2.460373247642612

Epoch: 6| Step: 10
Training loss: 1.8079670753434984
Validation loss: 2.5004133041792334

Epoch: 6| Step: 11
Training loss: 2.507276721419033
Validation loss: 2.5004394145079782

Epoch: 6| Step: 12
Training loss: 1.6247989823646682
Validation loss: 2.5040054658702147

Epoch: 6| Step: 13
Training loss: 1.786811712104255
Validation loss: 2.5346644962536615

Epoch: 97| Step: 0
Training loss: 1.981267944639753
Validation loss: 2.538660942993637

Epoch: 6| Step: 1
Training loss: 2.314083382089218
Validation loss: 2.5401370547706756

Epoch: 6| Step: 2
Training loss: 1.9244583878967652
Validation loss: 2.5149949668950202

Epoch: 6| Step: 3
Training loss: 1.5232556356791915
Validation loss: 2.514644218367213

Epoch: 6| Step: 4
Training loss: 2.663618033911509
Validation loss: 2.477876749708757

Epoch: 6| Step: 5
Training loss: 2.1399618639177236
Validation loss: 2.4838666255801374

Epoch: 6| Step: 6
Training loss: 2.541880572547179
Validation loss: 2.4909599254503036

Epoch: 6| Step: 7
Training loss: 1.7212839347912745
Validation loss: 2.49699064964873

Epoch: 6| Step: 8
Training loss: 1.45304132036027
Validation loss: 2.5121973352025795

Epoch: 6| Step: 9
Training loss: 1.8967453436240644
Validation loss: 2.479353862929102

Epoch: 6| Step: 10
Training loss: 1.939170793802973
Validation loss: 2.498980600422957

Epoch: 6| Step: 11
Training loss: 2.19140625
Validation loss: 2.477668218537855

Epoch: 6| Step: 12
Training loss: 1.2400296260001833
Validation loss: 2.477814334928523

Epoch: 6| Step: 13
Training loss: 1.8091556343621966
Validation loss: 2.4527245779905504

Epoch: 98| Step: 0
Training loss: 1.7743861144262958
Validation loss: 2.447380053094611

Epoch: 6| Step: 1
Training loss: 1.846919939297996
Validation loss: 2.482177786403263

Epoch: 6| Step: 2
Training loss: 2.2066379973209704
Validation loss: 2.5373999057565197

Epoch: 6| Step: 3
Training loss: 1.7438216136597011
Validation loss: 2.494820187803164

Epoch: 6| Step: 4
Training loss: 1.6883211610411135
Validation loss: 2.5434063809788467

Epoch: 6| Step: 5
Training loss: 2.0682067526610894
Validation loss: 2.5186373443273236

Epoch: 6| Step: 6
Training loss: 2.0303848771799897
Validation loss: 2.4984760089806715

Epoch: 6| Step: 7
Training loss: 1.634572080323381
Validation loss: 2.5023163872480345

Epoch: 6| Step: 8
Training loss: 2.335316451069478
Validation loss: 2.522383651898277

Epoch: 6| Step: 9
Training loss: 1.8463528251553403
Validation loss: 2.485396760880557

Epoch: 6| Step: 10
Training loss: 2.6326650697083926
Validation loss: 2.505135490854752

Epoch: 6| Step: 11
Training loss: 1.7003873467934099
Validation loss: 2.488355299138769

Epoch: 6| Step: 12
Training loss: 1.5308103124763086
Validation loss: 2.45845586395937

Epoch: 6| Step: 13
Training loss: 2.121527583539683
Validation loss: 2.4872570794627493

Epoch: 99| Step: 0
Training loss: 1.6194914839150556
Validation loss: 2.459132037830845

Epoch: 6| Step: 1
Training loss: 1.5997106499104423
Validation loss: 2.469604328268584

Epoch: 6| Step: 2
Training loss: 1.9442281496758407
Validation loss: 2.4648365115358173

Epoch: 6| Step: 3
Training loss: 2.7526880478266076
Validation loss: 2.520394221331138

Epoch: 6| Step: 4
Training loss: 1.6190197281745846
Validation loss: 2.4893010722976183

Epoch: 6| Step: 5
Training loss: 1.9801441656475538
Validation loss: 2.4988451992650393

Epoch: 6| Step: 6
Training loss: 1.7556701490301174
Validation loss: 2.43138457434948

Epoch: 6| Step: 7
Training loss: 1.6362054789338694
Validation loss: 2.4726311158584675

Epoch: 6| Step: 8
Training loss: 1.7490006727039578
Validation loss: 2.4396698089136697

Epoch: 6| Step: 9
Training loss: 2.3663127025552675
Validation loss: 2.4912575289084056

Epoch: 6| Step: 10
Training loss: 2.2720908669783424
Validation loss: 2.514432770699672

Epoch: 6| Step: 11
Training loss: 1.5352899624198926
Validation loss: 2.4937159237170685

Epoch: 6| Step: 12
Training loss: 2.055585193706752
Validation loss: 2.472737853846546

Epoch: 6| Step: 13
Training loss: 1.8482209647132342
Validation loss: 2.489376208469239

Epoch: 100| Step: 0
Training loss: 1.7580423840565973
Validation loss: 2.5305373990156266

Epoch: 6| Step: 1
Training loss: 1.9478807769025832
Validation loss: 2.500699160085682

Epoch: 6| Step: 2
Training loss: 1.5821539183730955
Validation loss: 2.4763919679350748

Epoch: 6| Step: 3
Training loss: 2.0584907867914835
Validation loss: 2.545499707248131

Epoch: 6| Step: 4
Training loss: 1.746234316362908
Validation loss: 2.493027213764045

Epoch: 6| Step: 5
Training loss: 2.38282530734263
Validation loss: 2.4740772954882178

Epoch: 6| Step: 6
Training loss: 1.703149357892762
Validation loss: 2.4707558527008073

Epoch: 6| Step: 7
Training loss: 2.6618171246003497
Validation loss: 2.484011025627492

Epoch: 6| Step: 8
Training loss: 1.8192423019843915
Validation loss: 2.5072372584877405

Epoch: 6| Step: 9
Training loss: 1.8366039608580034
Validation loss: 2.4458034294765474

Epoch: 6| Step: 10
Training loss: 1.9084611169713297
Validation loss: 2.4557356660715763

Epoch: 6| Step: 11
Training loss: 2.3430713942717976
Validation loss: 2.48101107057938

Epoch: 6| Step: 12
Training loss: 1.504150212304455
Validation loss: 2.4962721210200636

Epoch: 6| Step: 13
Training loss: 2.0202116124570826
Validation loss: 2.523591106766829

Epoch: 101| Step: 0
Training loss: 1.758014785995189
Validation loss: 2.4831011803386533

Epoch: 6| Step: 1
Training loss: 1.783899845921379
Validation loss: 2.503805506638981

Epoch: 6| Step: 2
Training loss: 1.616885686897317
Validation loss: 2.53217345923879

Epoch: 6| Step: 3
Training loss: 2.071928840041226
Validation loss: 2.468543724101912

Epoch: 6| Step: 4
Training loss: 1.7328198308075884
Validation loss: 2.5072540580444582

Epoch: 6| Step: 5
Training loss: 1.835552873295191
Validation loss: 2.5011754928134544

Epoch: 6| Step: 6
Training loss: 2.151612754794468
Validation loss: 2.456742900996641

Epoch: 6| Step: 7
Training loss: 1.4133089702833554
Validation loss: 2.474485278311052

Epoch: 6| Step: 8
Training loss: 1.9907812802756601
Validation loss: 2.484445838797983

Epoch: 6| Step: 9
Training loss: 2.2417485143002076
Validation loss: 2.499357681411554

Epoch: 6| Step: 10
Training loss: 1.4758785217765247
Validation loss: 2.4591673847801983

Epoch: 6| Step: 11
Training loss: 1.488053752502548
Validation loss: 2.4677525931935893

Epoch: 6| Step: 12
Training loss: 2.659773341109016
Validation loss: 2.4953369282749147

Epoch: 6| Step: 13
Training loss: 2.106880917559212
Validation loss: 2.468455969124886

Epoch: 102| Step: 0
Training loss: 1.7191654050116347
Validation loss: 2.475709112289466

Epoch: 6| Step: 1
Training loss: 1.916505772292085
Validation loss: 2.472353361761566

Epoch: 6| Step: 2
Training loss: 1.6762129220979445
Validation loss: 2.492884467714673

Epoch: 6| Step: 3
Training loss: 2.2544893406361974
Validation loss: 2.485626761058797

Epoch: 6| Step: 4
Training loss: 1.9900606657969615
Validation loss: 2.4704315156876953

Epoch: 6| Step: 5
Training loss: 1.8784752746043278
Validation loss: 2.483555400656708

Epoch: 6| Step: 6
Training loss: 1.5088137133908575
Validation loss: 2.4615938633367964

Epoch: 6| Step: 7
Training loss: 1.4603660404211614
Validation loss: 2.4775369293560567

Epoch: 6| Step: 8
Training loss: 2.0916444810194794
Validation loss: 2.4433464946453065

Epoch: 6| Step: 9
Training loss: 1.4769670043390029
Validation loss: 2.4805846820482094

Epoch: 6| Step: 10
Training loss: 1.830056889592979
Validation loss: 2.4459747782613177

Epoch: 6| Step: 11
Training loss: 2.6163598417287965
Validation loss: 2.5191660535052183

Epoch: 6| Step: 12
Training loss: 2.0425233665446423
Validation loss: 2.4990847660682065

Epoch: 6| Step: 13
Training loss: 1.7248510102876797
Validation loss: 2.492708827293805

Epoch: 103| Step: 0
Training loss: 1.7917021223005103
Validation loss: 2.4978155924307304

Epoch: 6| Step: 1
Training loss: 2.149965277103103
Validation loss: 2.5471850403466623

Epoch: 6| Step: 2
Training loss: 2.302270896025601
Validation loss: 2.4777391769151755

Epoch: 6| Step: 3
Training loss: 1.189705006155239
Validation loss: 2.4598373537518166

Epoch: 6| Step: 4
Training loss: 1.5729963606630435
Validation loss: 2.4873825039103

Epoch: 6| Step: 5
Training loss: 1.5071018896559194
Validation loss: 2.4614117362225754

Epoch: 6| Step: 6
Training loss: 1.9679025915276425
Validation loss: 2.464121427055156

Epoch: 6| Step: 7
Training loss: 0.9575283083204623
Validation loss: 2.481729526449544

Epoch: 6| Step: 8
Training loss: 1.9378627314498782
Validation loss: 2.4924576631838455

Epoch: 6| Step: 9
Training loss: 2.1373150706463844
Validation loss: 2.4943102383376834

Epoch: 6| Step: 10
Training loss: 1.5282869280499138
Validation loss: 2.478977281618933

Epoch: 6| Step: 11
Training loss: 1.7123565363134643
Validation loss: 2.490808597755408

Epoch: 6| Step: 12
Training loss: 2.336659705749824
Validation loss: 2.452230399709223

Epoch: 6| Step: 13
Training loss: 2.2799885018376655
Validation loss: 2.473908198333836

Epoch: 104| Step: 0
Training loss: 2.5812963227556
Validation loss: 2.5039253888760067

Epoch: 6| Step: 1
Training loss: 1.5251367726512166
Validation loss: 2.5082403988482866

Epoch: 6| Step: 2
Training loss: 1.9327970462511241
Validation loss: 2.500569469442669

Epoch: 6| Step: 3
Training loss: 1.80629826781515
Validation loss: 2.4977005715286302

Epoch: 6| Step: 4
Training loss: 1.430882522516579
Validation loss: 2.503183261480638

Epoch: 6| Step: 5
Training loss: 1.7939990040277716
Validation loss: 2.5365831839182746

Epoch: 6| Step: 6
Training loss: 1.9241796801647288
Validation loss: 2.486497719917144

Epoch: 6| Step: 7
Training loss: 2.4637368402463484
Validation loss: 2.50110545354422

Epoch: 6| Step: 8
Training loss: 1.786474363145747
Validation loss: 2.526746424780813

Epoch: 6| Step: 9
Training loss: 2.1069374977332025
Validation loss: 2.4953837332593483

Epoch: 6| Step: 10
Training loss: 1.5364640661445177
Validation loss: 2.4659007970182767

Epoch: 6| Step: 11
Training loss: 1.6855870459798852
Validation loss: 2.4578524027513806

Epoch: 6| Step: 12
Training loss: 1.7861444254936172
Validation loss: 2.4818040512653194

Epoch: 6| Step: 13
Training loss: 1.454287730353963
Validation loss: 2.470351966962472

Epoch: 105| Step: 0
Training loss: 2.027056076425884
Validation loss: 2.457096683215154

Epoch: 6| Step: 1
Training loss: 1.8862753400370813
Validation loss: 2.5225195223780936

Epoch: 6| Step: 2
Training loss: 1.8607977544808718
Validation loss: 2.47758040984459

Epoch: 6| Step: 3
Training loss: 1.8786546058827167
Validation loss: 2.5026521284500496

Epoch: 6| Step: 4
Training loss: 1.238289192246439
Validation loss: 2.433913126766784

Epoch: 6| Step: 5
Training loss: 2.715116594175027
Validation loss: 2.5522551394391626

Epoch: 6| Step: 6
Training loss: 1.448775724984064
Validation loss: 2.501890897907612

Epoch: 6| Step: 7
Training loss: 1.9173379082039346
Validation loss: 2.529221055159839

Epoch: 6| Step: 8
Training loss: 1.3936180308861705
Validation loss: 2.515243517144233

Epoch: 6| Step: 9
Training loss: 1.6137871861033133
Validation loss: 2.514945536719575

Epoch: 6| Step: 10
Training loss: 1.9441055168981287
Validation loss: 2.5313747359573573

Epoch: 6| Step: 11
Training loss: 1.8094504121603838
Validation loss: 2.489669276926083

Epoch: 6| Step: 12
Training loss: 2.155455290810077
Validation loss: 2.4760562607962724

Epoch: 6| Step: 13
Training loss: 1.4532341864798612
Validation loss: 2.52353829417768

Epoch: 106| Step: 0
Training loss: 1.6644404165753697
Validation loss: 2.5196762476950583

Epoch: 6| Step: 1
Training loss: 1.9267748886565905
Validation loss: 2.4935492100902854

Epoch: 6| Step: 2
Training loss: 2.1413706573679225
Validation loss: 2.512481644786383

Epoch: 6| Step: 3
Training loss: 1.7643236749138322
Validation loss: 2.4957334987774153

Epoch: 6| Step: 4
Training loss: 0.975251805972432
Validation loss: 2.4520636690356548

Epoch: 6| Step: 5
Training loss: 2.546832499705306
Validation loss: 2.517047582518849

Epoch: 6| Step: 6
Training loss: 1.6713927812435696
Validation loss: 2.4939354294598943

Epoch: 6| Step: 7
Training loss: 2.485283643472749
Validation loss: 2.478254957347232

Epoch: 6| Step: 8
Training loss: 1.8734480474968933
Validation loss: 2.4873609213231638

Epoch: 6| Step: 9
Training loss: 1.4694147431885933
Validation loss: 2.5161845451719236

Epoch: 6| Step: 10
Training loss: 1.6803745018117573
Validation loss: 2.5349158911260576

Epoch: 6| Step: 11
Training loss: 1.6521257116872243
Validation loss: 2.534320225184476

Epoch: 6| Step: 12
Training loss: 1.4238799495187364
Validation loss: 2.511334593066325

Epoch: 6| Step: 13
Training loss: 1.6848806609502902
Validation loss: 2.5419297134317547

Epoch: 107| Step: 0
Training loss: 1.883958143494167
Validation loss: 2.564299254148283

Epoch: 6| Step: 1
Training loss: 2.5005911128258655
Validation loss: 2.5633699832134935

Epoch: 6| Step: 2
Training loss: 2.0345107682215695
Validation loss: 2.5761386964641093

Epoch: 6| Step: 3
Training loss: 1.6865172880289234
Validation loss: 2.5295275569474645

Epoch: 6| Step: 4
Training loss: 1.4299755535837129
Validation loss: 2.537667017170995

Epoch: 6| Step: 5
Training loss: 1.5546647266656104
Validation loss: 2.4607769545407154

Epoch: 6| Step: 6
Training loss: 1.4852067725082903
Validation loss: 2.483916410270331

Epoch: 6| Step: 7
Training loss: 1.407083391561028
Validation loss: 2.536623083217258

Epoch: 6| Step: 8
Training loss: 1.8114915212611271
Validation loss: 2.4726444784469788

Epoch: 6| Step: 9
Training loss: 1.8371596793235347
Validation loss: 2.4690453075085084

Epoch: 6| Step: 10
Training loss: 1.5569721859583427
Validation loss: 2.493348141369561

Epoch: 6| Step: 11
Training loss: 1.8191798537867507
Validation loss: 2.4825392684571095

Epoch: 6| Step: 12
Training loss: 2.078785153273531
Validation loss: 2.476963624449193

Epoch: 6| Step: 13
Training loss: 1.8884613645650026
Validation loss: 2.4716326145013734

Epoch: 108| Step: 0
Training loss: 1.5837218493915635
Validation loss: 2.4890059249779823

Epoch: 6| Step: 1
Training loss: 2.021367608720027
Validation loss: 2.4989217976269504

Epoch: 6| Step: 2
Training loss: 1.8028571685266785
Validation loss: 2.4284970637096834

Epoch: 6| Step: 3
Training loss: 1.4416801378506423
Validation loss: 2.464108510092792

Epoch: 6| Step: 4
Training loss: 1.6065833313620403
Validation loss: 2.5404141862967795

Epoch: 6| Step: 5
Training loss: 1.2453253119562282
Validation loss: 2.5070845675442954

Epoch: 6| Step: 6
Training loss: 1.8345256815017548
Validation loss: 2.538929009474159

Epoch: 6| Step: 7
Training loss: 1.7438940063954553
Validation loss: 2.5462756085438443

Epoch: 6| Step: 8
Training loss: 1.8982977168108195
Validation loss: 2.5093901396627634

Epoch: 6| Step: 9
Training loss: 1.852720325150482
Validation loss: 2.494016448583867

Epoch: 6| Step: 10
Training loss: 1.3568833414925705
Validation loss: 2.505984439241363

Epoch: 6| Step: 11
Training loss: 1.7413271845396956
Validation loss: 2.5249032408049317

Epoch: 6| Step: 12
Training loss: 2.658142133989864
Validation loss: 2.5177503654644613

Epoch: 6| Step: 13
Training loss: 2.0818017543252103
Validation loss: 2.4963364938298356

Epoch: 109| Step: 0
Training loss: 1.8066581106628483
Validation loss: 2.491876596731429

Epoch: 6| Step: 1
Training loss: 2.367183773428121
Validation loss: 2.483483160436075

Epoch: 6| Step: 2
Training loss: 1.5347955100319182
Validation loss: 2.4725239554113543

Epoch: 6| Step: 3
Training loss: 1.3530120132882846
Validation loss: 2.486764410576261

Epoch: 6| Step: 4
Training loss: 1.862060338809686
Validation loss: 2.497433199054374

Epoch: 6| Step: 5
Training loss: 1.5166402346365335
Validation loss: 2.4869095131804935

Epoch: 6| Step: 6
Training loss: 1.8996682278935222
Validation loss: 2.4765710439444373

Epoch: 6| Step: 7
Training loss: 1.7974605767140788
Validation loss: 2.5666652105583254

Epoch: 6| Step: 8
Training loss: 1.870019656195326
Validation loss: 2.5420488528797884

Epoch: 6| Step: 9
Training loss: 1.5331798770381166
Validation loss: 2.5164191372721123

Epoch: 6| Step: 10
Training loss: 1.6622429871338777
Validation loss: 2.5370630304588486

Epoch: 6| Step: 11
Training loss: 1.7346793242825205
Validation loss: 2.5299481862935647

Epoch: 6| Step: 12
Training loss: 1.5048051797991628
Validation loss: 2.4673115688419847

Epoch: 6| Step: 13
Training loss: 2.0963708217425223
Validation loss: 2.5314564404859747

Epoch: 110| Step: 0
Training loss: 1.9601052634524725
Validation loss: 2.5035106328544536

Epoch: 6| Step: 1
Training loss: 2.063585746970869
Validation loss: 2.5064153532686455

Epoch: 6| Step: 2
Training loss: 1.4141193188796215
Validation loss: 2.446907766227522

Epoch: 6| Step: 3
Training loss: 1.6502671054461537
Validation loss: 2.4957238501819026

Epoch: 6| Step: 4
Training loss: 1.9223756215671035
Validation loss: 2.470992249068471

Epoch: 6| Step: 5
Training loss: 1.6519813951917903
Validation loss: 2.4903242745721275

Epoch: 6| Step: 6
Training loss: 1.2344127600966497
Validation loss: 2.488255730722178

Epoch: 6| Step: 7
Training loss: 1.1438554454620655
Validation loss: 2.4976345156369395

Epoch: 6| Step: 8
Training loss: 1.9305636621513895
Validation loss: 2.490768427211076

Epoch: 6| Step: 9
Training loss: 1.8738940474075432
Validation loss: 2.509691985914043

Epoch: 6| Step: 10
Training loss: 2.699339227706542
Validation loss: 2.5092065962882257

Epoch: 6| Step: 11
Training loss: 1.0463599461037787
Validation loss: 2.492593483059782

Epoch: 6| Step: 12
Training loss: 1.4974652171991145
Validation loss: 2.5230778929028306

Epoch: 6| Step: 13
Training loss: 1.550009124482893
Validation loss: 2.501500394718582

Epoch: 111| Step: 0
Training loss: 1.7442520293980817
Validation loss: 2.4864708399261675

Epoch: 6| Step: 1
Training loss: 1.6009110032792366
Validation loss: 2.451135577861442

Epoch: 6| Step: 2
Training loss: 1.448303674073008
Validation loss: 2.532052544733096

Epoch: 6| Step: 3
Training loss: 1.805375137444253
Validation loss: 2.4870211426286546

Epoch: 6| Step: 4
Training loss: 1.0539425514931253
Validation loss: 2.453700830216661

Epoch: 6| Step: 5
Training loss: 2.410600667627442
Validation loss: 2.4669199409704965

Epoch: 6| Step: 6
Training loss: 1.9368933681664606
Validation loss: 2.4575153595608343

Epoch: 6| Step: 7
Training loss: 1.2906247931011487
Validation loss: 2.5326004978184162

Epoch: 6| Step: 8
Training loss: 2.1097051291505435
Validation loss: 2.4883874364499876

Epoch: 6| Step: 9
Training loss: 1.7458911069841352
Validation loss: 2.488786104209583

Epoch: 6| Step: 10
Training loss: 1.9739854621197275
Validation loss: 2.4932539042487503

Epoch: 6| Step: 11
Training loss: 1.685376986432194
Validation loss: 2.535451596556767

Epoch: 6| Step: 12
Training loss: 1.3742717201385994
Validation loss: 2.4950644649900076

Epoch: 6| Step: 13
Training loss: 1.6195390346871816
Validation loss: 2.494374813117104

Epoch: 112| Step: 0
Training loss: 1.7983262545517313
Validation loss: 2.5194305951813702

Epoch: 6| Step: 1
Training loss: 1.714003233115353
Validation loss: 2.5363791660327704

Epoch: 6| Step: 2
Training loss: 2.380388271171996
Validation loss: 2.5700019254565913

Epoch: 6| Step: 3
Training loss: 1.6068943497610368
Validation loss: 2.5428552245754847

Epoch: 6| Step: 4
Training loss: 1.2702205723231321
Validation loss: 2.47343770756322

Epoch: 6| Step: 5
Training loss: 1.4929162288192772
Validation loss: 2.5012737049489995

Epoch: 6| Step: 6
Training loss: 1.9417190146313668
Validation loss: 2.508237246218055

Epoch: 6| Step: 7
Training loss: 1.6164998237144876
Validation loss: 2.4693710254253256

Epoch: 6| Step: 8
Training loss: 1.5000017484018944
Validation loss: 2.4678285142503666

Epoch: 6| Step: 9
Training loss: 1.4622525910647872
Validation loss: 2.4370846353693607

Epoch: 6| Step: 10
Training loss: 2.2098269419855914
Validation loss: 2.5005709552462556

Epoch: 6| Step: 11
Training loss: 1.3781232042365799
Validation loss: 2.5322615246774927

Epoch: 6| Step: 12
Training loss: 1.6647756418503858
Validation loss: 2.4976704552224325

Epoch: 6| Step: 13
Training loss: 1.4972694498436747
Validation loss: 2.5077404514947697

Epoch: 113| Step: 0
Training loss: 1.453581707463821
Validation loss: 2.4864675078737495

Epoch: 6| Step: 1
Training loss: 1.7465683806165608
Validation loss: 2.501728175798747

Epoch: 6| Step: 2
Training loss: 1.445464914894315
Validation loss: 2.510304291506472

Epoch: 6| Step: 3
Training loss: 1.9334011405804925
Validation loss: 2.4683539318313064

Epoch: 6| Step: 4
Training loss: 1.6271411287965283
Validation loss: 2.59077276614479

Epoch: 6| Step: 5
Training loss: 1.6431295986408643
Validation loss: 2.4909079843639743

Epoch: 6| Step: 6
Training loss: 2.1327045119897474
Validation loss: 2.562002940157122

Epoch: 6| Step: 7
Training loss: 2.111398362253892
Validation loss: 2.545821832192805

Epoch: 6| Step: 8
Training loss: 1.4550953294389777
Validation loss: 2.5443159637561283

Epoch: 6| Step: 9
Training loss: 1.306222024645413
Validation loss: 2.517750886287362

Epoch: 6| Step: 10
Training loss: 1.3493033253944768
Validation loss: 2.5227935725286117

Epoch: 6| Step: 11
Training loss: 1.1586659939467303
Validation loss: 2.5013564721303387

Epoch: 6| Step: 12
Training loss: 2.0772052536526093
Validation loss: 2.5457096359078353

Epoch: 6| Step: 13
Training loss: 1.860757970597851
Validation loss: 2.535342459949688

Epoch: 114| Step: 0
Training loss: 2.017229491372218
Validation loss: 2.478804014165358

Epoch: 6| Step: 1
Training loss: 1.4823121041528475
Validation loss: 2.4712713058188704

Epoch: 6| Step: 2
Training loss: 1.9849211174115184
Validation loss: 2.4752735108830706

Epoch: 6| Step: 3
Training loss: 1.15286636139852
Validation loss: 2.47276920584896

Epoch: 6| Step: 4
Training loss: 1.616029481411165
Validation loss: 2.54038663326974

Epoch: 6| Step: 5
Training loss: 2.0043518879637108
Validation loss: 2.5211933420119688

Epoch: 6| Step: 6
Training loss: 1.6053208331722952
Validation loss: 2.4860090563929598

Epoch: 6| Step: 7
Training loss: 2.5858397681446843
Validation loss: 2.433857070286561

Epoch: 6| Step: 8
Training loss: 1.7540618895395923
Validation loss: 2.5284805139046367

Epoch: 6| Step: 9
Training loss: 1.5123619268779127
Validation loss: 2.5177030174779005

Epoch: 6| Step: 10
Training loss: 1.012540152424691
Validation loss: 2.4701190162535895

Epoch: 6| Step: 11
Training loss: 1.0093902539497184
Validation loss: 2.4734978391155824

Epoch: 6| Step: 12
Training loss: 1.559229823752749
Validation loss: 2.5685520965251376

Epoch: 6| Step: 13
Training loss: 1.535603077242551
Validation loss: 2.5617084831426826

Epoch: 115| Step: 0
Training loss: 1.703781561331772
Validation loss: 2.596155208105471

Epoch: 6| Step: 1
Training loss: 1.648784510531124
Validation loss: 2.6030131773574214

Epoch: 6| Step: 2
Training loss: 1.5832684235903607
Validation loss: 2.6147629320283383

Epoch: 6| Step: 3
Training loss: 1.759152050358154
Validation loss: 2.6278229928870402

Epoch: 6| Step: 4
Training loss: 1.8046485269144736
Validation loss: 2.566936111137617

Epoch: 6| Step: 5
Training loss: 1.486206370516201
Validation loss: 2.558200501173492

Epoch: 6| Step: 6
Training loss: 1.3593709222140482
Validation loss: 2.5611509788464493

Epoch: 6| Step: 7
Training loss: 1.7644693424137448
Validation loss: 2.47784825271354

Epoch: 6| Step: 8
Training loss: 1.649975967232204
Validation loss: 2.4712986727166175

Epoch: 6| Step: 9
Training loss: 1.5205013836067525
Validation loss: 2.518907068496671

Epoch: 6| Step: 10
Training loss: 2.2382485485517454
Validation loss: 2.5183546290790044

Epoch: 6| Step: 11
Training loss: 1.8153183170855163
Validation loss: 2.4672946020051603

Epoch: 6| Step: 12
Training loss: 1.7587863513305033
Validation loss: 2.5191826315510752

Epoch: 6| Step: 13
Training loss: 1.1954713105062242
Validation loss: 2.5308671826646814

Epoch: 116| Step: 0
Training loss: 1.3169778098088558
Validation loss: 2.507710867750533

Epoch: 6| Step: 1
Training loss: 1.3243026031681715
Validation loss: 2.489560232228208

Epoch: 6| Step: 2
Training loss: 1.1721213526864802
Validation loss: 2.5326041692691064

Epoch: 6| Step: 3
Training loss: 2.3258919471381216
Validation loss: 2.575408537100507

Epoch: 6| Step: 4
Training loss: 2.0363480195771886
Validation loss: 2.537346801142081

Epoch: 6| Step: 5
Training loss: 1.7247937839367735
Validation loss: 2.5423351539602628

Epoch: 6| Step: 6
Training loss: 1.991915456111442
Validation loss: 2.5682416726955855

Epoch: 6| Step: 7
Training loss: 1.668223591617634
Validation loss: 2.521487621381124

Epoch: 6| Step: 8
Training loss: 2.006085198309378
Validation loss: 2.5147045655143763

Epoch: 6| Step: 9
Training loss: 1.7425871933694914
Validation loss: 2.527265937625363

Epoch: 6| Step: 10
Training loss: 0.9898799585525788
Validation loss: 2.5032462818927455

Epoch: 6| Step: 11
Training loss: 1.4198979476738713
Validation loss: 2.5139407567620844

Epoch: 6| Step: 12
Training loss: 1.3899165717137352
Validation loss: 2.502368837870558

Epoch: 6| Step: 13
Training loss: 1.3357516153858775
Validation loss: 2.5094823457236632

Epoch: 117| Step: 0
Training loss: 1.7381915465794031
Validation loss: 2.497330416451438

Epoch: 6| Step: 1
Training loss: 1.5622266148773292
Validation loss: 2.5419359898275196

Epoch: 6| Step: 2
Training loss: 2.520786652776454
Validation loss: 2.4574091488798673

Epoch: 6| Step: 3
Training loss: 1.6167541513007755
Validation loss: 2.510085568153669

Epoch: 6| Step: 4
Training loss: 1.4066335790744242
Validation loss: 2.5303071781815607

Epoch: 6| Step: 5
Training loss: 1.8923004545081725
Validation loss: 2.597303790127946

Epoch: 6| Step: 6
Training loss: 1.6205810471476412
Validation loss: 2.5261492965158765

Epoch: 6| Step: 7
Training loss: 1.5838049470662612
Validation loss: 2.542844606212238

Epoch: 6| Step: 8
Training loss: 0.958846445517022
Validation loss: 2.533622234481177

Epoch: 6| Step: 9
Training loss: 1.4240044378682966
Validation loss: 2.507733558687849

Epoch: 6| Step: 10
Training loss: 1.365088546452039
Validation loss: 2.5386110735893235

Epoch: 6| Step: 11
Training loss: 1.5817718669983023
Validation loss: 2.533275029699427

Epoch: 6| Step: 12
Training loss: 1.429340424646987
Validation loss: 2.5374107113367335

Epoch: 6| Step: 13
Training loss: 1.6261769947316866
Validation loss: 2.506429035137183

Epoch: 118| Step: 0
Training loss: 2.202276512870681
Validation loss: 2.5188407878431818

Epoch: 6| Step: 1
Training loss: 0.9140699337388025
Validation loss: 2.5056919786295344

Epoch: 6| Step: 2
Training loss: 1.720351080327603
Validation loss: 2.5204857095258912

Epoch: 6| Step: 3
Training loss: 1.40581599001917
Validation loss: 2.4566240402812722

Epoch: 6| Step: 4
Training loss: 1.2929675514238685
Validation loss: 2.5277475214347955

Epoch: 6| Step: 5
Training loss: 1.7545375579875502
Validation loss: 2.5077216269566023

Epoch: 6| Step: 6
Training loss: 1.643482372123248
Validation loss: 2.512287714199803

Epoch: 6| Step: 7
Training loss: 1.5361877547986003
Validation loss: 2.5877213025631205

Epoch: 6| Step: 8
Training loss: 1.358643652957515
Validation loss: 2.50859336540182

Epoch: 6| Step: 9
Training loss: 1.219893774661101
Validation loss: 2.489469020139719

Epoch: 6| Step: 10
Training loss: 1.4955019265854037
Validation loss: 2.557661963312796

Epoch: 6| Step: 11
Training loss: 2.1424030799265252
Validation loss: 2.5395156143042925

Epoch: 6| Step: 12
Training loss: 1.365610968476233
Validation loss: 2.5416854300093004

Epoch: 6| Step: 13
Training loss: 1.6408896096599819
Validation loss: 2.4961120572958495

Epoch: 119| Step: 0
Training loss: 1.0039898433095575
Validation loss: 2.530635115425116

Epoch: 6| Step: 1
Training loss: 2.2649878296514614
Validation loss: 2.4821456567422433

Epoch: 6| Step: 2
Training loss: 1.5497009204145697
Validation loss: 2.599598805028462

Epoch: 6| Step: 3
Training loss: 2.37801290440888
Validation loss: 2.4986732856738474

Epoch: 6| Step: 4
Training loss: 1.4840751746691316
Validation loss: 2.5336284451966975

Epoch: 6| Step: 5
Training loss: 1.4104428832164015
Validation loss: 2.554815477749003

Epoch: 6| Step: 6
Training loss: 1.355908677005132
Validation loss: 2.5016486493600616

Epoch: 6| Step: 7
Training loss: 1.4837190483740703
Validation loss: 2.4909817958969573

Epoch: 6| Step: 8
Training loss: 1.4837084428066099
Validation loss: 2.5445964348493586

Epoch: 6| Step: 9
Training loss: 1.4731262428430583
Validation loss: 2.5313402010697494

Epoch: 6| Step: 10
Training loss: 1.3881866852212323
Validation loss: 2.4861891738409168

Epoch: 6| Step: 11
Training loss: 1.0230197782012238
Validation loss: 2.557341679370827

Epoch: 6| Step: 12
Training loss: 1.4727838192839866
Validation loss: 2.5292160433663247

Epoch: 6| Step: 13
Training loss: 1.6630503840518542
Validation loss: 2.5587241569074943

Epoch: 120| Step: 0
Training loss: 2.3280961207704434
Validation loss: 2.526499415081698

Epoch: 6| Step: 1
Training loss: 1.05244676840447
Validation loss: 2.560081783046319

Epoch: 6| Step: 2
Training loss: 1.4963972217151635
Validation loss: 2.530718932151054

Epoch: 6| Step: 3
Training loss: 1.8450657304049551
Validation loss: 2.543878426773867

Epoch: 6| Step: 4
Training loss: 1.2752900018182092
Validation loss: 2.5457573371029003

Epoch: 6| Step: 5
Training loss: 1.5759661420874052
Validation loss: 2.5256010057895026

Epoch: 6| Step: 6
Training loss: 1.3896947599667009
Validation loss: 2.587217707446297

Epoch: 6| Step: 7
Training loss: 1.3863029608830197
Validation loss: 2.57149908780235

Epoch: 6| Step: 8
Training loss: 1.6401282148717098
Validation loss: 2.567577031139824

Epoch: 6| Step: 9
Training loss: 1.7141227162163097
Validation loss: 2.5536372896835147

Epoch: 6| Step: 10
Training loss: 1.1867661969542338
Validation loss: 2.555256794717345

Epoch: 6| Step: 11
Training loss: 1.2230905364828721
Validation loss: 2.496838828068733

Epoch: 6| Step: 12
Training loss: 1.931398382319768
Validation loss: 2.57292464611551

Epoch: 6| Step: 13
Training loss: 1.1264845272174957
Validation loss: 2.474441775552861

Epoch: 121| Step: 0
Training loss: 1.3050753993325885
Validation loss: 2.5177937433299244

Epoch: 6| Step: 1
Training loss: 1.4353341081165065
Validation loss: 2.5664929085494874

Epoch: 6| Step: 2
Training loss: 1.5681342204413153
Validation loss: 2.587148776458234

Epoch: 6| Step: 3
Training loss: 1.8728936125708766
Validation loss: 2.5481750509065226

Epoch: 6| Step: 4
Training loss: 1.0195956739627956
Validation loss: 2.563537403171863

Epoch: 6| Step: 5
Training loss: 1.4075586799328204
Validation loss: 2.5579456236445566

Epoch: 6| Step: 6
Training loss: 2.2258387409898126
Validation loss: 2.563023583490087

Epoch: 6| Step: 7
Training loss: 1.186251536168349
Validation loss: 2.60357208076273

Epoch: 6| Step: 8
Training loss: 1.5573434810460225
Validation loss: 2.597773575583131

Epoch: 6| Step: 9
Training loss: 1.4002582907830532
Validation loss: 2.6375858341128975

Epoch: 6| Step: 10
Training loss: 1.7076936392504656
Validation loss: 2.587488329825751

Epoch: 6| Step: 11
Training loss: 1.7763234322366763
Validation loss: 2.5448594494314283

Epoch: 6| Step: 12
Training loss: 1.503275791146803
Validation loss: 2.5445132236078383

Epoch: 6| Step: 13
Training loss: 1.4093250561849753
Validation loss: 2.557651802596832

Epoch: 122| Step: 0
Training loss: 1.3770282264952438
Validation loss: 2.559785412993706

Epoch: 6| Step: 1
Training loss: 1.2322686972241519
Validation loss: 2.5690531326715256

Epoch: 6| Step: 2
Training loss: 1.1024171476308058
Validation loss: 2.535156532134759

Epoch: 6| Step: 3
Training loss: 1.7255356440746648
Validation loss: 2.5565907488281363

Epoch: 6| Step: 4
Training loss: 1.4832122263956913
Validation loss: 2.581708917778963

Epoch: 6| Step: 5
Training loss: 1.367040528163366
Validation loss: 2.6042383769016646

Epoch: 6| Step: 6
Training loss: 1.3934363760711592
Validation loss: 2.484387331758039

Epoch: 6| Step: 7
Training loss: 1.712156932465351
Validation loss: 2.5295127747049686

Epoch: 6| Step: 8
Training loss: 1.6151518610366657
Validation loss: 2.5430582072768897

Epoch: 6| Step: 9
Training loss: 2.403404039073876
Validation loss: 2.572549312379656

Epoch: 6| Step: 10
Training loss: 1.47339714698914
Validation loss: 2.5525790349447925

Epoch: 6| Step: 11
Training loss: 1.572692813059778
Validation loss: 2.5043680813526166

Epoch: 6| Step: 12
Training loss: 1.1079422200902318
Validation loss: 2.5295055642067736

Epoch: 6| Step: 13
Training loss: 1.2324300000970279
Validation loss: 2.522777585249853

Epoch: 123| Step: 0
Training loss: 1.7772631281079294
Validation loss: 2.5805073837512666

Epoch: 6| Step: 1
Training loss: 1.76616046179118
Validation loss: 2.531374053113009

Epoch: 6| Step: 2
Training loss: 1.1861545570173115
Validation loss: 2.544630641477706

Epoch: 6| Step: 3
Training loss: 1.4266597184044694
Validation loss: 2.499944137902802

Epoch: 6| Step: 4
Training loss: 1.5706895973289015
Validation loss: 2.5334639894104365

Epoch: 6| Step: 5
Training loss: 1.1248561979151643
Validation loss: 2.5329427671104843

Epoch: 6| Step: 6
Training loss: 1.2377156792160344
Validation loss: 2.5727579374167746

Epoch: 6| Step: 7
Training loss: 1.3053495360662173
Validation loss: 2.527997466439676

Epoch: 6| Step: 8
Training loss: 2.113877979015926
Validation loss: 2.4658421319682313

Epoch: 6| Step: 9
Training loss: 1.555414844385499
Validation loss: 2.521719592859099

Epoch: 6| Step: 10
Training loss: 1.5713995212495455
Validation loss: 2.586680740542648

Epoch: 6| Step: 11
Training loss: 1.1487947284678484
Validation loss: 2.547970549813474

Epoch: 6| Step: 12
Training loss: 1.6026750375547054
Validation loss: 2.594242470496943

Epoch: 6| Step: 13
Training loss: 1.4271730919150973
Validation loss: 2.563064140931191

Epoch: 124| Step: 0
Training loss: 1.4018135449854896
Validation loss: 2.582000578343696

Epoch: 6| Step: 1
Training loss: 1.5640460185917502
Validation loss: 2.6239278283995535

Epoch: 6| Step: 2
Training loss: 1.4433060198718395
Validation loss: 2.520724859084365

Epoch: 6| Step: 3
Training loss: 0.9268864018876541
Validation loss: 2.577019255902082

Epoch: 6| Step: 4
Training loss: 2.201300873653221
Validation loss: 2.5802426744151385

Epoch: 6| Step: 5
Training loss: 1.4464008254631184
Validation loss: 2.571733091818749

Epoch: 6| Step: 6
Training loss: 1.4475056272934288
Validation loss: 2.521737335935185

Epoch: 6| Step: 7
Training loss: 1.3717475484329378
Validation loss: 2.61110460898309

Epoch: 6| Step: 8
Training loss: 1.4020773546942578
Validation loss: 2.6077442365198737

Epoch: 6| Step: 9
Training loss: 1.7673279643203261
Validation loss: 2.568270984670995

Epoch: 6| Step: 10
Training loss: 1.358024628007183
Validation loss: 2.594148505670454

Epoch: 6| Step: 11
Training loss: 1.9352515309993876
Validation loss: 2.5388467941601807

Epoch: 6| Step: 12
Training loss: 1.3365568097474843
Validation loss: 2.567738373576171

Epoch: 6| Step: 13
Training loss: 0.990578465617261
Validation loss: 2.4918219797556436

Epoch: 125| Step: 0
Training loss: 1.4097117730031645
Validation loss: 2.4946444049183762

Epoch: 6| Step: 1
Training loss: 1.7003477357993393
Validation loss: 2.5568102029232795

Epoch: 6| Step: 2
Training loss: 1.7271611483368363
Validation loss: 2.5610574678286135

Epoch: 6| Step: 3
Training loss: 1.1188779193054648
Validation loss: 2.5423558791156906

Epoch: 6| Step: 4
Training loss: 1.6052976642418417
Validation loss: 2.5891834719599225

Epoch: 6| Step: 5
Training loss: 1.641589507921609
Validation loss: 2.5266563270712927

Epoch: 6| Step: 6
Training loss: 1.1603680555387934
Validation loss: 2.53361345946701

Epoch: 6| Step: 7
Training loss: 1.1915829386785277
Validation loss: 2.5924052080551108

Epoch: 6| Step: 8
Training loss: 1.1301589931611384
Validation loss: 2.4741541226194195

Epoch: 6| Step: 9
Training loss: 1.5913347380820633
Validation loss: 2.5406004644494047

Epoch: 6| Step: 10
Training loss: 1.5881586165400114
Validation loss: 2.4993374423395776

Epoch: 6| Step: 11
Training loss: 2.020152131196735
Validation loss: 2.5728446754752015

Epoch: 6| Step: 12
Training loss: 1.275227417952884
Validation loss: 2.5663946065343435

Epoch: 6| Step: 13
Training loss: 1.0481306488303437
Validation loss: 2.525207032947464

Epoch: 126| Step: 0
Training loss: 1.4045457897904152
Validation loss: 2.5760754771365524

Epoch: 6| Step: 1
Training loss: 1.9159889958171172
Validation loss: 2.5386035837024594

Epoch: 6| Step: 2
Training loss: 1.8965968875530015
Validation loss: 2.458231169522817

Epoch: 6| Step: 3
Training loss: 1.3224086486908595
Validation loss: 2.5615368405339396

Epoch: 6| Step: 4
Training loss: 1.2879095759341088
Validation loss: 2.513598381969814

Epoch: 6| Step: 5
Training loss: 2.179741096521275
Validation loss: 2.5384753521593044

Epoch: 6| Step: 6
Training loss: 0.7606790342548605
Validation loss: 2.541262068099829

Epoch: 6| Step: 7
Training loss: 1.6927958147967113
Validation loss: 2.5802615627752563

Epoch: 6| Step: 8
Training loss: 1.2332927933465287
Validation loss: 2.5330551759157363

Epoch: 6| Step: 9
Training loss: 1.0579250236402513
Validation loss: 2.5928582876226187

Epoch: 6| Step: 10
Training loss: 1.236297028498514
Validation loss: 2.5780549858681856

Epoch: 6| Step: 11
Training loss: 1.5283613400543423
Validation loss: 2.518517420831869

Epoch: 6| Step: 12
Training loss: 1.6429875393172666
Validation loss: 2.6373412953820043

Epoch: 6| Step: 13
Training loss: 1.0996302438385221
Validation loss: 2.552600066103804

Epoch: 127| Step: 0
Training loss: 1.187593155268843
Validation loss: 2.5893040665788876

Epoch: 6| Step: 1
Training loss: 1.1520155099745242
Validation loss: 2.567484117871731

Epoch: 6| Step: 2
Training loss: 1.626477083717266
Validation loss: 2.542887899790408

Epoch: 6| Step: 3
Training loss: 1.2268138555058368
Validation loss: 2.5574663702082763

Epoch: 6| Step: 4
Training loss: 2.081792477770469
Validation loss: 2.597960168942829

Epoch: 6| Step: 5
Training loss: 1.7152556530773535
Validation loss: 2.5789635883880413

Epoch: 6| Step: 6
Training loss: 1.798249622808974
Validation loss: 2.5298423777798345

Epoch: 6| Step: 7
Training loss: 1.2694577239826168
Validation loss: 2.5323000641127433

Epoch: 6| Step: 8
Training loss: 1.306332767182429
Validation loss: 2.5682167932267363

Epoch: 6| Step: 9
Training loss: 1.0219976765667806
Validation loss: 2.575202086459892

Epoch: 6| Step: 10
Training loss: 1.5609729170957753
Validation loss: 2.593241162925831

Epoch: 6| Step: 11
Training loss: 1.5075704745999836
Validation loss: 2.5856066719790576

Epoch: 6| Step: 12
Training loss: 1.467486791989937
Validation loss: 2.6134687659591074

Epoch: 6| Step: 13
Training loss: 1.3869090634701662
Validation loss: 2.6372619672154123

Epoch: 128| Step: 0
Training loss: 1.199721339772732
Validation loss: 2.604085926075818

Epoch: 6| Step: 1
Training loss: 1.1988742594513302
Validation loss: 2.573194609750504

Epoch: 6| Step: 2
Training loss: 1.2292048669256306
Validation loss: 2.6422217242225554

Epoch: 6| Step: 3
Training loss: 1.2891736994088965
Validation loss: 2.5718378412738163

Epoch: 6| Step: 4
Training loss: 1.009235885056507
Validation loss: 2.590173591947992

Epoch: 6| Step: 5
Training loss: 1.3874999089283957
Validation loss: 2.6010350254897303

Epoch: 6| Step: 6
Training loss: 1.2949709875767357
Validation loss: 2.695717107654292

Epoch: 6| Step: 7
Training loss: 1.0899997722555501
Validation loss: 2.6186198931339573

Epoch: 6| Step: 8
Training loss: 1.727166255836152
Validation loss: 2.5618923443711767

Epoch: 6| Step: 9
Training loss: 1.4185851887834207
Validation loss: 2.5787558660349568

Epoch: 6| Step: 10
Training loss: 1.3122249042497216
Validation loss: 2.586834862277768

Epoch: 6| Step: 11
Training loss: 1.4468687185064613
Validation loss: 2.548065905646362

Epoch: 6| Step: 12
Training loss: 2.385783560132977
Validation loss: 2.596989688108093

Epoch: 6| Step: 13
Training loss: 1.652067914444245
Validation loss: 2.5664218261493805

Epoch: 129| Step: 0
Training loss: 1.653545979366067
Validation loss: 2.57196297261424

Epoch: 6| Step: 1
Training loss: 1.2218926821158544
Validation loss: 2.56660433565559

Epoch: 6| Step: 2
Training loss: 1.342312642881426
Validation loss: 2.603145907937447

Epoch: 6| Step: 3
Training loss: 1.3017428397986686
Validation loss: 2.5563060054846245

Epoch: 6| Step: 4
Training loss: 1.2324643377131612
Validation loss: 2.563595715856799

Epoch: 6| Step: 5
Training loss: 1.1069520629903564
Validation loss: 2.6686165406256244

Epoch: 6| Step: 6
Training loss: 1.2413666610214897
Validation loss: 2.572702411786173

Epoch: 6| Step: 7
Training loss: 1.0971980105651498
Validation loss: 2.6029638538955333

Epoch: 6| Step: 8
Training loss: 2.2281458528674443
Validation loss: 2.6244317605310297

Epoch: 6| Step: 9
Training loss: 1.611535409252511
Validation loss: 2.6149716538496968

Epoch: 6| Step: 10
Training loss: 1.1615848671907376
Validation loss: 2.5497518802055774

Epoch: 6| Step: 11
Training loss: 1.0917506882071593
Validation loss: 2.55903430669312

Epoch: 6| Step: 12
Training loss: 1.6096916257627294
Validation loss: 2.514435812840312

Epoch: 6| Step: 13
Training loss: 1.0014453218325199
Validation loss: 2.547391733745884

Epoch: 130| Step: 0
Training loss: 1.2619440686546768
Validation loss: 2.5378341129119986

Epoch: 6| Step: 1
Training loss: 1.4463529398822172
Validation loss: 2.5724823053540447

Epoch: 6| Step: 2
Training loss: 1.4621655203954178
Validation loss: 2.5559226344871404

Epoch: 6| Step: 3
Training loss: 1.6294835666180172
Validation loss: 2.606193049088386

Epoch: 6| Step: 4
Training loss: 1.2411684858864513
Validation loss: 2.5442700081820337

Epoch: 6| Step: 5
Training loss: 1.4957009539385442
Validation loss: 2.601253395695496

Epoch: 6| Step: 6
Training loss: 1.315426832845942
Validation loss: 2.563091612961724

Epoch: 6| Step: 7
Training loss: 1.4495077744663964
Validation loss: 2.5308973278621334

Epoch: 6| Step: 8
Training loss: 1.0708119695786045
Validation loss: 2.522386219721282

Epoch: 6| Step: 9
Training loss: 1.2803703172518572
Validation loss: 2.6076483124552676

Epoch: 6| Step: 10
Training loss: 1.153827552462073
Validation loss: 2.5454936113548996

Epoch: 6| Step: 11
Training loss: 2.226262015428627
Validation loss: 2.540017669208275

Epoch: 6| Step: 12
Training loss: 1.1335203918655474
Validation loss: 2.558629501131825

Epoch: 6| Step: 13
Training loss: 1.0806420287273737
Validation loss: 2.61721059305052

Epoch: 131| Step: 0
Training loss: 1.8939416341479376
Validation loss: 2.6091176284897664

Epoch: 6| Step: 1
Training loss: 1.08454003740891
Validation loss: 2.594177976788469

Epoch: 6| Step: 2
Training loss: 1.3119824615271571
Validation loss: 2.5645273144138105

Epoch: 6| Step: 3
Training loss: 1.597551486957151
Validation loss: 2.6481024155994075

Epoch: 6| Step: 4
Training loss: 1.0459122287328955
Validation loss: 2.571467548786426

Epoch: 6| Step: 5
Training loss: 1.2885818510129454
Validation loss: 2.5752412022579017

Epoch: 6| Step: 6
Training loss: 1.6333893847417063
Validation loss: 2.5667705306386384

Epoch: 6| Step: 7
Training loss: 1.5070761033695863
Validation loss: 2.617901286249447

Epoch: 6| Step: 8
Training loss: 1.6117084955877585
Validation loss: 2.5820621367438044

Epoch: 6| Step: 9
Training loss: 1.3767142014151792
Validation loss: 2.5788408075623432

Epoch: 6| Step: 10
Training loss: 1.3419530519440037
Validation loss: 2.7417633728510973

Epoch: 6| Step: 11
Training loss: 1.4688027555040928
Validation loss: 2.689796811788481

Epoch: 6| Step: 12
Training loss: 1.4187427436542217
Validation loss: 2.683256850919795

Epoch: 6| Step: 13
Training loss: 1.6145652852023866
Validation loss: 2.6637952564249106

Epoch: 132| Step: 0
Training loss: 1.1553348321796724
Validation loss: 2.6945566121794755

Epoch: 6| Step: 1
Training loss: 1.7985555999450642
Validation loss: 2.6184850408488436

Epoch: 6| Step: 2
Training loss: 1.2360225257610975
Validation loss: 2.600790388450866

Epoch: 6| Step: 3
Training loss: 0.9637182366051175
Validation loss: 2.6062860536711603

Epoch: 6| Step: 4
Training loss: 1.3452033234533929
Validation loss: 2.6663320649351427

Epoch: 6| Step: 5
Training loss: 1.2622161451707952
Validation loss: 2.5932905717117434

Epoch: 6| Step: 6
Training loss: 1.5035572786574702
Validation loss: 2.564806597856268

Epoch: 6| Step: 7
Training loss: 1.4318159758425586
Validation loss: 2.666652520460118

Epoch: 6| Step: 8
Training loss: 1.0913205549365477
Validation loss: 2.633802716355699

Epoch: 6| Step: 9
Training loss: 1.23520381481219
Validation loss: 2.6397386526784006

Epoch: 6| Step: 10
Training loss: 2.209658411131521
Validation loss: 2.6086715084953553

Epoch: 6| Step: 11
Training loss: 1.6457090532081542
Validation loss: 2.6793804975245172

Epoch: 6| Step: 12
Training loss: 1.6728406595118643
Validation loss: 2.7468954682265663

Epoch: 6| Step: 13
Training loss: 1.726414117435258
Validation loss: 2.844626406927457

Epoch: 133| Step: 0
Training loss: 1.9049352896205167
Validation loss: 2.696282312738669

Epoch: 6| Step: 1
Training loss: 1.6011333355775619
Validation loss: 2.619125430645963

Epoch: 6| Step: 2
Training loss: 1.5795033544714296
Validation loss: 2.570437937480666

Epoch: 6| Step: 3
Training loss: 1.6200122580829786
Validation loss: 2.56375720809997

Epoch: 6| Step: 4
Training loss: 1.3347741130930726
Validation loss: 2.603535687616595

Epoch: 6| Step: 5
Training loss: 1.241677137411802
Validation loss: 2.606325617729242

Epoch: 6| Step: 6
Training loss: 1.0819908162078051
Validation loss: 2.6714322948478433

Epoch: 6| Step: 7
Training loss: 1.3671907261401668
Validation loss: 2.5998346435098822

Epoch: 6| Step: 8
Training loss: 1.361077656410458
Validation loss: 2.5875372111521187

Epoch: 6| Step: 9
Training loss: 1.2735406096670536
Validation loss: 2.628979618131348

Epoch: 6| Step: 10
Training loss: 1.2445376255329477
Validation loss: 2.532874884867666

Epoch: 6| Step: 11
Training loss: 1.3331247802390818
Validation loss: 2.5884695727455127

Epoch: 6| Step: 12
Training loss: 1.4313193425201158
Validation loss: 2.61027247210011

Epoch: 6| Step: 13
Training loss: 1.1981293641489987
Validation loss: 2.7092809975408354

Epoch: 134| Step: 0
Training loss: 1.4339651515402698
Validation loss: 2.6670060587517264

Epoch: 6| Step: 1
Training loss: 1.2448103463062874
Validation loss: 2.6683603411738694

Epoch: 6| Step: 2
Training loss: 1.3225529188158172
Validation loss: 2.681891214544998

Epoch: 6| Step: 3
Training loss: 1.2199525524512167
Validation loss: 2.6354450606272817

Epoch: 6| Step: 4
Training loss: 1.4761020810459597
Validation loss: 2.6317642645669284

Epoch: 6| Step: 5
Training loss: 1.0477970674392545
Validation loss: 2.60133773245147

Epoch: 6| Step: 6
Training loss: 1.0150365445177543
Validation loss: 2.6002635748851524

Epoch: 6| Step: 7
Training loss: 1.5599932589752097
Validation loss: 2.6024633610100993

Epoch: 6| Step: 8
Training loss: 1.4476484237764031
Validation loss: 2.650855754236618

Epoch: 6| Step: 9
Training loss: 1.3163507829068066
Validation loss: 2.5900527463179013

Epoch: 6| Step: 10
Training loss: 1.9904808962417153
Validation loss: 2.6240658535999697

Epoch: 6| Step: 11
Training loss: 1.3343391002676845
Validation loss: 2.5938062546845746

Epoch: 6| Step: 12
Training loss: 1.2690991884220104
Validation loss: 2.575010618786691

Epoch: 6| Step: 13
Training loss: 1.4602723264811164
Validation loss: 2.636774901745844

Epoch: 135| Step: 0
Training loss: 1.4288115606120093
Validation loss: 2.6050028310505327

Epoch: 6| Step: 1
Training loss: 1.1327858231132872
Validation loss: 2.598742823307219

Epoch: 6| Step: 2
Training loss: 1.109989801823962
Validation loss: 2.6762870811662305

Epoch: 6| Step: 3
Training loss: 1.5081385126627014
Validation loss: 2.6716016514324443

Epoch: 6| Step: 4
Training loss: 1.660830587425329
Validation loss: 2.6783420161747635

Epoch: 6| Step: 5
Training loss: 1.2925867167441203
Validation loss: 2.6574156952168884

Epoch: 6| Step: 6
Training loss: 1.2623037865629763
Validation loss: 2.612495984830311

Epoch: 6| Step: 7
Training loss: 0.9248797377171015
Validation loss: 2.649802022412306

Epoch: 6| Step: 8
Training loss: 1.8813755994672494
Validation loss: 2.6005396392975557

Epoch: 6| Step: 9
Training loss: 1.3237477593047258
Validation loss: 2.61436075932455

Epoch: 6| Step: 10
Training loss: 1.5930001982109872
Validation loss: 2.685388652417651

Epoch: 6| Step: 11
Training loss: 1.1598469228699824
Validation loss: 2.6659183395949837

Epoch: 6| Step: 12
Training loss: 0.9904328096641839
Validation loss: 2.6704374018892976

Epoch: 6| Step: 13
Training loss: 1.5200199233807317
Validation loss: 2.706346345380235

Epoch: 136| Step: 0
Training loss: 1.3938205307703966
Validation loss: 2.6273120658537725

Epoch: 6| Step: 1
Training loss: 0.9579693614464362
Validation loss: 2.644777978593989

Epoch: 6| Step: 2
Training loss: 1.2717526294972776
Validation loss: 2.5413801599792007

Epoch: 6| Step: 3
Training loss: 1.2142049698470474
Validation loss: 2.6038321827020745

Epoch: 6| Step: 4
Training loss: 2.017870339930381
Validation loss: 2.580472644075756

Epoch: 6| Step: 5
Training loss: 0.8627083374726008
Validation loss: 2.578131465711096

Epoch: 6| Step: 6
Training loss: 0.9363685137679768
Validation loss: 2.6207341545839182

Epoch: 6| Step: 7
Training loss: 1.0903475564277583
Validation loss: 2.5579711622502095

Epoch: 6| Step: 8
Training loss: 1.0866155360095073
Validation loss: 2.5984623855619495

Epoch: 6| Step: 9
Training loss: 1.0362563136038427
Validation loss: 2.6536903464964214

Epoch: 6| Step: 10
Training loss: 1.148707040309311
Validation loss: 2.6673985510056846

Epoch: 6| Step: 11
Training loss: 1.3615446205882655
Validation loss: 2.675598316482833

Epoch: 6| Step: 12
Training loss: 2.1527358457795285
Validation loss: 2.6444511006999014

Epoch: 6| Step: 13
Training loss: 1.6727830078900239
Validation loss: 2.680893399608476

Epoch: 137| Step: 0
Training loss: 1.395638333644287
Validation loss: 2.609187212676015

Epoch: 6| Step: 1
Training loss: 0.9107876008172763
Validation loss: 2.6514578881623914

Epoch: 6| Step: 2
Training loss: 1.3544599753402033
Validation loss: 2.5889700542145855

Epoch: 6| Step: 3
Training loss: 1.7410030700901928
Validation loss: 2.6398741578202927

Epoch: 6| Step: 4
Training loss: 1.4313495751270655
Validation loss: 2.5736076467039757

Epoch: 6| Step: 5
Training loss: 1.32629429922086
Validation loss: 2.605280071024842

Epoch: 6| Step: 6
Training loss: 2.399722671380202
Validation loss: 2.6282633675080165

Epoch: 6| Step: 7
Training loss: 1.0981359010783882
Validation loss: 2.6228314631053182

Epoch: 6| Step: 8
Training loss: 1.690203796490969
Validation loss: 2.6217777820700037

Epoch: 6| Step: 9
Training loss: 1.4367323774694416
Validation loss: 2.566128851744886

Epoch: 6| Step: 10
Training loss: 1.0591267725356672
Validation loss: 2.5282936649777206

Epoch: 6| Step: 11
Training loss: 0.8443547659933666
Validation loss: 2.593475373218313

Epoch: 6| Step: 12
Training loss: 1.1576721106292402
Validation loss: 2.589919728295705

Epoch: 6| Step: 13
Training loss: 0.9242569813112552
Validation loss: 2.634398966265801

Epoch: 138| Step: 0
Training loss: 1.3321866926405104
Validation loss: 2.7111238237857678

Epoch: 6| Step: 1
Training loss: 1.4246360046224102
Validation loss: 2.690362012580872

Epoch: 6| Step: 2
Training loss: 2.020701086167539
Validation loss: 2.6673160646393343

Epoch: 6| Step: 3
Training loss: 1.3657213469503466
Validation loss: 2.618653337671804

Epoch: 6| Step: 4
Training loss: 1.4703963771655062
Validation loss: 2.646540950156353

Epoch: 6| Step: 5
Training loss: 1.2377565156583699
Validation loss: 2.6114046194494125

Epoch: 6| Step: 6
Training loss: 1.2797248881447756
Validation loss: 2.606034308518266

Epoch: 6| Step: 7
Training loss: 1.2868077296589597
Validation loss: 2.604749482105215

Epoch: 6| Step: 8
Training loss: 1.178051553151875
Validation loss: 2.5299830935721257

Epoch: 6| Step: 9
Training loss: 1.0770896694998
Validation loss: 2.6217173077671254

Epoch: 6| Step: 10
Training loss: 1.6154103119870873
Validation loss: 2.568491281813547

Epoch: 6| Step: 11
Training loss: 0.9024811677209519
Validation loss: 2.573518664607413

Epoch: 6| Step: 12
Training loss: 1.2466898003810023
Validation loss: 2.552958767793182

Epoch: 6| Step: 13
Training loss: 1.1241975677594225
Validation loss: 2.572316664776149

Epoch: 139| Step: 0
Training loss: 1.0714099575878147
Validation loss: 2.584173663167904

Epoch: 6| Step: 1
Training loss: 1.646357666063396
Validation loss: 2.557231006304277

Epoch: 6| Step: 2
Training loss: 1.2339386953585654
Validation loss: 2.638466368417938

Epoch: 6| Step: 3
Training loss: 1.324664600675636
Validation loss: 2.5930198806145723

Epoch: 6| Step: 4
Training loss: 1.1735474922247322
Validation loss: 2.6827631316903546

Epoch: 6| Step: 5
Training loss: 1.0493638359416575
Validation loss: 2.656998121336786

Epoch: 6| Step: 6
Training loss: 1.0471204783030188
Validation loss: 2.596804708240273

Epoch: 6| Step: 7
Training loss: 1.112181967378271
Validation loss: 2.633002209266579

Epoch: 6| Step: 8
Training loss: 1.1315656969667376
Validation loss: 2.6624722474850193

Epoch: 6| Step: 9
Training loss: 2.1602244581936
Validation loss: 2.575637881579944

Epoch: 6| Step: 10
Training loss: 1.5069730329170083
Validation loss: 2.622121996757942

Epoch: 6| Step: 11
Training loss: 0.9874121421649994
Validation loss: 2.6454721689903424

Epoch: 6| Step: 12
Training loss: 1.0830081977533974
Validation loss: 2.6208427297628907

Epoch: 6| Step: 13
Training loss: 1.1418350281215375
Validation loss: 2.6253454193035943

Epoch: 140| Step: 0
Training loss: 1.1519600439526818
Validation loss: 2.589154672986767

Epoch: 6| Step: 1
Training loss: 1.1994826433421524
Validation loss: 2.607950312753991

Epoch: 6| Step: 2
Training loss: 0.8948564229913422
Validation loss: 2.6494932967815847

Epoch: 6| Step: 3
Training loss: 1.0276300879778117
Validation loss: 2.55693779469715

Epoch: 6| Step: 4
Training loss: 0.9906808422245874
Validation loss: 2.5933107440776966

Epoch: 6| Step: 5
Training loss: 1.2903392595512932
Validation loss: 2.6944509410015147

Epoch: 6| Step: 6
Training loss: 1.5230803242151185
Validation loss: 2.612157590533383

Epoch: 6| Step: 7
Training loss: 1.051818902553534
Validation loss: 2.5567203331536605

Epoch: 6| Step: 8
Training loss: 1.1459860035306215
Validation loss: 2.6383616210696603

Epoch: 6| Step: 9
Training loss: 1.14642988917059
Validation loss: 2.6712547311010546

Epoch: 6| Step: 10
Training loss: 1.9309968405904658
Validation loss: 2.5866140304655065

Epoch: 6| Step: 11
Training loss: 1.600428258682905
Validation loss: 2.643375356355392

Epoch: 6| Step: 12
Training loss: 1.3475048035375015
Validation loss: 2.6333974382790517

Epoch: 6| Step: 13
Training loss: 0.9389019973361472
Validation loss: 2.664325510952858

Epoch: 141| Step: 0
Training loss: 0.894805033402233
Validation loss: 2.6836403181467556

Epoch: 6| Step: 1
Training loss: 1.1776518278784198
Validation loss: 2.6155204512021966

Epoch: 6| Step: 2
Training loss: 1.515501823532432
Validation loss: 2.637464027099204

Epoch: 6| Step: 3
Training loss: 1.0867279249800839
Validation loss: 2.5586031304495664

Epoch: 6| Step: 4
Training loss: 1.1364822928294915
Validation loss: 2.5604370931664664

Epoch: 6| Step: 5
Training loss: 0.8135256529211696
Validation loss: 2.6281002144810897

Epoch: 6| Step: 6
Training loss: 1.9798838938762522
Validation loss: 2.591226077474629

Epoch: 6| Step: 7
Training loss: 1.278989985106914
Validation loss: 2.5698270561545193

Epoch: 6| Step: 8
Training loss: 1.60753897220718
Validation loss: 2.610818033702191

Epoch: 6| Step: 9
Training loss: 1.5176005122473963
Validation loss: 2.5677600079044502

Epoch: 6| Step: 10
Training loss: 1.0130207418067452
Validation loss: 2.5705655020788925

Epoch: 6| Step: 11
Training loss: 0.9275265109445356
Validation loss: 2.5976085993093907

Epoch: 6| Step: 12
Training loss: 1.211222313642248
Validation loss: 2.5669940679808807

Epoch: 6| Step: 13
Training loss: 1.2372572843869438
Validation loss: 2.6320411918213082

Epoch: 142| Step: 0
Training loss: 1.0651666612019781
Validation loss: 2.5680154973916234

Epoch: 6| Step: 1
Training loss: 2.09214584616804
Validation loss: 2.618969074636193

Epoch: 6| Step: 2
Training loss: 1.3020123678578048
Validation loss: 2.546082964415178

Epoch: 6| Step: 3
Training loss: 1.0039023907657765
Validation loss: 2.595303204462567

Epoch: 6| Step: 4
Training loss: 0.9471948656219272
Validation loss: 2.6083281314867044

Epoch: 6| Step: 5
Training loss: 1.2805435745320537
Validation loss: 2.4898655118331376

Epoch: 6| Step: 6
Training loss: 1.429806480251306
Validation loss: 2.586437672534964

Epoch: 6| Step: 7
Training loss: 1.4090593039416532
Validation loss: 2.5647520233462626

Epoch: 6| Step: 8
Training loss: 1.5422550144123315
Validation loss: 2.58442811430873

Epoch: 6| Step: 9
Training loss: 0.963915358927183
Validation loss: 2.5240742575840076

Epoch: 6| Step: 10
Training loss: 1.3819799988399266
Validation loss: 2.5706064197262357

Epoch: 6| Step: 11
Training loss: 0.9940130905156713
Validation loss: 2.599015188773827

Epoch: 6| Step: 12
Training loss: 0.9109530256201329
Validation loss: 2.630174962703909

Epoch: 6| Step: 13
Training loss: 1.0486791067976007
Validation loss: 2.6560956274315033

Epoch: 143| Step: 0
Training loss: 1.5899502205403748
Validation loss: 2.5680448351587515

Epoch: 6| Step: 1
Training loss: 0.8662299978746029
Validation loss: 2.5752119310440977

Epoch: 6| Step: 2
Training loss: 1.2366687853727332
Validation loss: 2.5825301018850357

Epoch: 6| Step: 3
Training loss: 1.4160954314795062
Validation loss: 2.5971432133815813

Epoch: 6| Step: 4
Training loss: 1.254467229640902
Validation loss: 2.653336621438997

Epoch: 6| Step: 5
Training loss: 0.9787268496293042
Validation loss: 2.593023328598461

Epoch: 6| Step: 6
Training loss: 0.8622418183059937
Validation loss: 2.6069821257169323

Epoch: 6| Step: 7
Training loss: 1.3485559528611082
Validation loss: 2.5586061744291215

Epoch: 6| Step: 8
Training loss: 1.2197613554635294
Validation loss: 2.525294877135463

Epoch: 6| Step: 9
Training loss: 2.188101658504568
Validation loss: 2.661883875699281

Epoch: 6| Step: 10
Training loss: 1.1259493001530743
Validation loss: 2.644242038436031

Epoch: 6| Step: 11
Training loss: 1.2720033960417032
Validation loss: 2.6210785290673613

Epoch: 6| Step: 12
Training loss: 1.1738024310506872
Validation loss: 2.7295441305805896

Epoch: 6| Step: 13
Training loss: 1.042771510072232
Validation loss: 2.6982952623075085

Epoch: 144| Step: 0
Training loss: 1.1734850694789858
Validation loss: 2.6192693372899036

Epoch: 6| Step: 1
Training loss: 1.4825124197788644
Validation loss: 2.6397790550725664

Epoch: 6| Step: 2
Training loss: 1.266679348171063
Validation loss: 2.6816524348840534

Epoch: 6| Step: 3
Training loss: 1.797481069770208
Validation loss: 2.630760034291828

Epoch: 6| Step: 4
Training loss: 1.1157231904744345
Validation loss: 2.5641531535195363

Epoch: 6| Step: 5
Training loss: 1.19543805429112
Validation loss: 2.629735097078502

Epoch: 6| Step: 6
Training loss: 0.8654809260368409
Validation loss: 2.5712825254943255

Epoch: 6| Step: 7
Training loss: 0.8885151148440501
Validation loss: 2.6180994902571806

Epoch: 6| Step: 8
Training loss: 1.3682576378264655
Validation loss: 2.605630575070235

Epoch: 6| Step: 9
Training loss: 1.0921460516272639
Validation loss: 2.6502071683505415

Epoch: 6| Step: 10
Training loss: 1.0195027782220858
Validation loss: 2.607383531533769

Epoch: 6| Step: 11
Training loss: 1.472759860413541
Validation loss: 2.6238943829428325

Epoch: 6| Step: 12
Training loss: 1.2308029931852427
Validation loss: 2.6142892912816142

Epoch: 6| Step: 13
Training loss: 0.8926772181557054
Validation loss: 2.646363142739469

Epoch: 145| Step: 0
Training loss: 1.3486652080338177
Validation loss: 2.6466249548253935

Epoch: 6| Step: 1
Training loss: 1.0192655019697048
Validation loss: 2.5294970812414053

Epoch: 6| Step: 2
Training loss: 1.0939679609834116
Validation loss: 2.6320037505201386

Epoch: 6| Step: 3
Training loss: 0.7254696081461649
Validation loss: 2.621401863919852

Epoch: 6| Step: 4
Training loss: 0.794485286257109
Validation loss: 2.6434690670394403

Epoch: 6| Step: 5
Training loss: 1.3487241632569507
Validation loss: 2.5653674511765505

Epoch: 6| Step: 6
Training loss: 1.041939559794448
Validation loss: 2.6428592567116276

Epoch: 6| Step: 7
Training loss: 1.107390495811079
Validation loss: 2.636524048198137

Epoch: 6| Step: 8
Training loss: 1.047154460443828
Validation loss: 2.60667799340671

Epoch: 6| Step: 9
Training loss: 1.9416281498484553
Validation loss: 2.6126008946649852

Epoch: 6| Step: 10
Training loss: 1.4375977690246882
Validation loss: 2.5773419356573415

Epoch: 6| Step: 11
Training loss: 1.029609531350764
Validation loss: 2.5892804714206177

Epoch: 6| Step: 12
Training loss: 1.413485920574504
Validation loss: 2.6487152494101522

Epoch: 6| Step: 13
Training loss: 1.1221754856470347
Validation loss: 2.653835493253831

Epoch: 146| Step: 0
Training loss: 0.9099507570567195
Validation loss: 2.696740108695468

Epoch: 6| Step: 1
Training loss: 1.6385717713762715
Validation loss: 2.7271117319406555

Epoch: 6| Step: 2
Training loss: 1.2048285177893334
Validation loss: 2.7563983364080644

Epoch: 6| Step: 3
Training loss: 1.7229510204329765
Validation loss: 2.72882311359709

Epoch: 6| Step: 4
Training loss: 1.8548233355276902
Validation loss: 2.6653608810679867

Epoch: 6| Step: 5
Training loss: 1.4450393831106627
Validation loss: 2.665012283535454

Epoch: 6| Step: 6
Training loss: 0.8627814317502919
Validation loss: 2.6035276976923374

Epoch: 6| Step: 7
Training loss: 1.0485625827723561
Validation loss: 2.6611354853532068

Epoch: 6| Step: 8
Training loss: 0.8195396779284305
Validation loss: 2.640738761302287

Epoch: 6| Step: 9
Training loss: 1.0863848526349527
Validation loss: 2.6732506733368515

Epoch: 6| Step: 10
Training loss: 1.2505129238621553
Validation loss: 2.621299405848893

Epoch: 6| Step: 11
Training loss: 1.5341779780484588
Validation loss: 2.670522366024698

Epoch: 6| Step: 12
Training loss: 1.0681455631854828
Validation loss: 2.662410996073243

Epoch: 6| Step: 13
Training loss: 1.0927885461875833
Validation loss: 2.598539533999336

Epoch: 147| Step: 0
Training loss: 1.1848234832249769
Validation loss: 2.5885497514584404

Epoch: 6| Step: 1
Training loss: 1.2326403634266996
Validation loss: 2.6442102625302892

Epoch: 6| Step: 2
Training loss: 1.7221875580337893
Validation loss: 2.7114810746761306

Epoch: 6| Step: 3
Training loss: 1.066490365647921
Validation loss: 2.6441750824228603

Epoch: 6| Step: 4
Training loss: 1.2343822430748235
Validation loss: 2.747222277807688

Epoch: 6| Step: 5
Training loss: 1.2184491886694588
Validation loss: 2.7865722252692917

Epoch: 6| Step: 6
Training loss: 1.2123012124145909
Validation loss: 2.6779450292664615

Epoch: 6| Step: 7
Training loss: 1.3196266695420158
Validation loss: 2.6270498870083854

Epoch: 6| Step: 8
Training loss: 1.1001961533177376
Validation loss: 2.630193288527162

Epoch: 6| Step: 9
Training loss: 1.1310416224651758
Validation loss: 2.663535206687074

Epoch: 6| Step: 10
Training loss: 1.2441272106076278
Validation loss: 2.6215404389491797

Epoch: 6| Step: 11
Training loss: 1.241296796732895
Validation loss: 2.6265882198444372

Epoch: 6| Step: 12
Training loss: 1.0290442487880418
Validation loss: 2.6649286795466995

Epoch: 6| Step: 13
Training loss: 1.6142316701887258
Validation loss: 2.662970623993154

Epoch: 148| Step: 0
Training loss: 1.9759623102539656
Validation loss: 2.672522156031483

Epoch: 6| Step: 1
Training loss: 1.003558562515782
Validation loss: 2.6204901813763977

Epoch: 6| Step: 2
Training loss: 1.4030097931121084
Validation loss: 2.5983279934775845

Epoch: 6| Step: 3
Training loss: 1.109210257319701
Validation loss: 2.6023385510430406

Epoch: 6| Step: 4
Training loss: 1.1513893442392056
Validation loss: 2.618810228430566

Epoch: 6| Step: 5
Training loss: 1.361068810348432
Validation loss: 2.712228744175069

Epoch: 6| Step: 6
Training loss: 1.1874290244324395
Validation loss: 2.6812317219950748

Epoch: 6| Step: 7
Training loss: 0.94634505697739
Validation loss: 2.732302550627341

Epoch: 6| Step: 8
Training loss: 1.0576378141383682
Validation loss: 2.6794089125241625

Epoch: 6| Step: 9
Training loss: 1.4939805686841154
Validation loss: 2.6366622202900443

Epoch: 6| Step: 10
Training loss: 1.495716655009482
Validation loss: 2.63573721241773

Epoch: 6| Step: 11
Training loss: 1.088768760440686
Validation loss: 2.5899598492145426

Epoch: 6| Step: 12
Training loss: 0.8251446770476057
Validation loss: 2.648675238367487

Epoch: 6| Step: 13
Training loss: 0.6108526751468806
Validation loss: 2.6216411293792383

Epoch: 149| Step: 0
Training loss: 1.3150815099394901
Validation loss: 2.617689428072717

Epoch: 6| Step: 1
Training loss: 1.4765256846848889
Validation loss: 2.6407941805424016

Epoch: 6| Step: 2
Training loss: 1.7924456861878268
Validation loss: 2.615937802879016

Epoch: 6| Step: 3
Training loss: 0.6885442822205174
Validation loss: 2.68050246825766

Epoch: 6| Step: 4
Training loss: 1.0699105726287836
Validation loss: 2.6477117753812545

Epoch: 6| Step: 5
Training loss: 0.6083374237767833
Validation loss: 2.707871109081831

Epoch: 6| Step: 6
Training loss: 1.1851400214575956
Validation loss: 2.663216927466774

Epoch: 6| Step: 7
Training loss: 1.2471629371986634
Validation loss: 2.6491670007056496

Epoch: 6| Step: 8
Training loss: 1.4898872421149592
Validation loss: 2.726406001834427

Epoch: 6| Step: 9
Training loss: 0.917155388395062
Validation loss: 2.6154588066969637

Epoch: 6| Step: 10
Training loss: 1.3418877583338282
Validation loss: 2.6843840551908245

Epoch: 6| Step: 11
Training loss: 1.0198167423104645
Validation loss: 2.6978366108410556

Epoch: 6| Step: 12
Training loss: 1.0740664842369094
Validation loss: 2.6276622396553853

Epoch: 6| Step: 13
Training loss: 1.0781405903891446
Validation loss: 2.6536387904220025

Epoch: 150| Step: 0
Training loss: 1.2098034378266518
Validation loss: 2.6328101908053902

Epoch: 6| Step: 1
Training loss: 1.9020877485721925
Validation loss: 2.6109086210676753

Epoch: 6| Step: 2
Training loss: 1.099409013995115
Validation loss: 2.7046632157030186

Epoch: 6| Step: 3
Training loss: 1.0107898350786093
Validation loss: 2.653165776958213

Epoch: 6| Step: 4
Training loss: 0.6786430489596914
Validation loss: 2.6412769167494865

Epoch: 6| Step: 5
Training loss: 0.7721687082422435
Validation loss: 2.724302665191819

Epoch: 6| Step: 6
Training loss: 0.9925627111614025
Validation loss: 2.7089351181103

Epoch: 6| Step: 7
Training loss: 1.1183622892490355
Validation loss: 2.681999847438655

Epoch: 6| Step: 8
Training loss: 1.494742557724671
Validation loss: 2.649161090858962

Epoch: 6| Step: 9
Training loss: 0.9597825343467131
Validation loss: 2.639989893152176

Epoch: 6| Step: 10
Training loss: 1.212170471559579
Validation loss: 2.6207345942913824

Epoch: 6| Step: 11
Training loss: 1.2747006382771293
Validation loss: 2.6052434348195193

Epoch: 6| Step: 12
Training loss: 0.732066401367422
Validation loss: 2.625715763660499

Epoch: 6| Step: 13
Training loss: 1.0541826523384228
Validation loss: 2.6035857862484932

Epoch: 151| Step: 0
Training loss: 1.3475573517266815
Validation loss: 2.6767733996889747

Epoch: 6| Step: 1
Training loss: 0.5270342731134662
Validation loss: 2.673730261873828

Epoch: 6| Step: 2
Training loss: 1.7907562234406396
Validation loss: 2.610241789768697

Epoch: 6| Step: 3
Training loss: 0.9315909446409698
Validation loss: 2.636349936228465

Epoch: 6| Step: 4
Training loss: 0.8412943532738127
Validation loss: 2.64322905642254

Epoch: 6| Step: 5
Training loss: 0.9692789602511198
Validation loss: 2.5910632760907197

Epoch: 6| Step: 6
Training loss: 0.946411219409519
Validation loss: 2.6044694851607115

Epoch: 6| Step: 7
Training loss: 1.090508535118231
Validation loss: 2.6353941804632712

Epoch: 6| Step: 8
Training loss: 0.8481518399764252
Validation loss: 2.6629604621986096

Epoch: 6| Step: 9
Training loss: 1.0685838536734227
Validation loss: 2.660864109857305

Epoch: 6| Step: 10
Training loss: 1.3328996886952527
Validation loss: 2.6411406335244774

Epoch: 6| Step: 11
Training loss: 1.434740486205205
Validation loss: 2.6548018453519093

Epoch: 6| Step: 12
Training loss: 1.2761942039196714
Validation loss: 2.6815278283550126

Epoch: 6| Step: 13
Training loss: 1.3880193923837747
Validation loss: 2.575205496578744

Epoch: 152| Step: 0
Training loss: 1.0479193076270454
Validation loss: 2.6477600101337795

Epoch: 6| Step: 1
Training loss: 0.9166802636496384
Validation loss: 2.641733241721476

Epoch: 6| Step: 2
Training loss: 0.6017308680746248
Validation loss: 2.6293874284181378

Epoch: 6| Step: 3
Training loss: 0.8712330180829599
Validation loss: 2.684117680193118

Epoch: 6| Step: 4
Training loss: 1.96233521759805
Validation loss: 2.6271765102245705

Epoch: 6| Step: 5
Training loss: 1.1372738036899146
Validation loss: 2.6152164989465407

Epoch: 6| Step: 6
Training loss: 0.7354414480931186
Validation loss: 2.653159838576147

Epoch: 6| Step: 7
Training loss: 0.8441864580230033
Validation loss: 2.6488986443742473

Epoch: 6| Step: 8
Training loss: 0.7048971942587635
Validation loss: 2.596540053487864

Epoch: 6| Step: 9
Training loss: 1.2747388871541394
Validation loss: 2.6993485606768908

Epoch: 6| Step: 10
Training loss: 1.4092810707341707
Validation loss: 2.650134710270799

Epoch: 6| Step: 11
Training loss: 1.532528324207713
Validation loss: 2.6391249314085634

Epoch: 6| Step: 12
Training loss: 0.9426581262247037
Validation loss: 2.5614034741207314

Epoch: 6| Step: 13
Training loss: 1.0392274080362336
Validation loss: 2.593485087152598

Epoch: 153| Step: 0
Training loss: 1.0051914404732725
Validation loss: 2.5449185804422347

Epoch: 6| Step: 1
Training loss: 1.8225936676151475
Validation loss: 2.6137269328562165

Epoch: 6| Step: 2
Training loss: 0.9801087345407816
Validation loss: 2.6009319713612755

Epoch: 6| Step: 3
Training loss: 0.9075816992037261
Validation loss: 2.608559212537396

Epoch: 6| Step: 4
Training loss: 0.9169688521433464
Validation loss: 2.6091304519789595

Epoch: 6| Step: 5
Training loss: 1.202514047441496
Validation loss: 2.5659572880203805

Epoch: 6| Step: 6
Training loss: 1.292431030942008
Validation loss: 2.6477080009072638

Epoch: 6| Step: 7
Training loss: 1.0721359869407463
Validation loss: 2.5800782944137515

Epoch: 6| Step: 8
Training loss: 0.7048157602721719
Validation loss: 2.7181378548707684

Epoch: 6| Step: 9
Training loss: 0.9260624325758606
Validation loss: 2.6321788595100717

Epoch: 6| Step: 10
Training loss: 1.1109666823190614
Validation loss: 2.6174326919407904

Epoch: 6| Step: 11
Training loss: 1.2309417299971253
Validation loss: 2.6269522022874385

Epoch: 6| Step: 12
Training loss: 1.235231561071882
Validation loss: 2.688282091354391

Epoch: 6| Step: 13
Training loss: 1.168223681743851
Validation loss: 2.6445153826148786

Epoch: 154| Step: 0
Training loss: 1.0821798615016684
Validation loss: 2.641665522658364

Epoch: 6| Step: 1
Training loss: 0.9686626579534707
Validation loss: 2.695582117426088

Epoch: 6| Step: 2
Training loss: 0.9258128293602801
Validation loss: 2.654438141354085

Epoch: 6| Step: 3
Training loss: 0.8302062889338793
Validation loss: 2.6334875809083518

Epoch: 6| Step: 4
Training loss: 0.7684837221296777
Validation loss: 2.661375635483469

Epoch: 6| Step: 5
Training loss: 0.8237496437685576
Validation loss: 2.6198402132322993

Epoch: 6| Step: 6
Training loss: 1.047687727464527
Validation loss: 2.639471370145998

Epoch: 6| Step: 7
Training loss: 1.0886203913839136
Validation loss: 2.630687727847559

Epoch: 6| Step: 8
Training loss: 0.9271356517873669
Validation loss: 2.636294762701792

Epoch: 6| Step: 9
Training loss: 1.3451757186489293
Validation loss: 2.6622081130951822

Epoch: 6| Step: 10
Training loss: 0.8824300021759428
Validation loss: 2.6422606449240615

Epoch: 6| Step: 11
Training loss: 1.0813018874579237
Validation loss: 2.629912321347977

Epoch: 6| Step: 12
Training loss: 1.2230728463431166
Validation loss: 2.5852372449720016

Epoch: 6| Step: 13
Training loss: 2.2221594391007193
Validation loss: 2.6240949584315127

Epoch: 155| Step: 0
Training loss: 0.938557727491422
Validation loss: 2.5541916812296184

Epoch: 6| Step: 1
Training loss: 1.3723852264554186
Validation loss: 2.58688635191447

Epoch: 6| Step: 2
Training loss: 0.6474969546051283
Validation loss: 2.60501054188114

Epoch: 6| Step: 3
Training loss: 0.9021359158902476
Validation loss: 2.6163583988990236

Epoch: 6| Step: 4
Training loss: 0.8832484831334037
Validation loss: 2.572868753416965

Epoch: 6| Step: 5
Training loss: 1.2323712853931827
Validation loss: 2.60602624239118

Epoch: 6| Step: 6
Training loss: 1.0093502762072495
Validation loss: 2.5998585937633814

Epoch: 6| Step: 7
Training loss: 1.0532641944245689
Validation loss: 2.5915971040333985

Epoch: 6| Step: 8
Training loss: 1.1973293467953023
Validation loss: 2.586947671171042

Epoch: 6| Step: 9
Training loss: 1.2973597436410886
Validation loss: 2.56124831852905

Epoch: 6| Step: 10
Training loss: 1.1992128850439339
Validation loss: 2.612518731495753

Epoch: 6| Step: 11
Training loss: 1.9271711243573475
Validation loss: 2.616557737278018

Epoch: 6| Step: 12
Training loss: 0.8292822040081305
Validation loss: 2.642197563923732

Epoch: 6| Step: 13
Training loss: 1.1338591903040207
Validation loss: 2.6312459403495247

Epoch: 156| Step: 0
Training loss: 1.3315401038770978
Validation loss: 2.7068506339306584

Epoch: 6| Step: 1
Training loss: 2.0075160895019932
Validation loss: 2.660601906736321

Epoch: 6| Step: 2
Training loss: 0.8294902559872732
Validation loss: 2.6653101172734543

Epoch: 6| Step: 3
Training loss: 1.0628469686013886
Validation loss: 2.6405850168545557

Epoch: 6| Step: 4
Training loss: 0.8078911350131696
Validation loss: 2.643150852089269

Epoch: 6| Step: 5
Training loss: 0.9830825434670236
Validation loss: 2.604623866319398

Epoch: 6| Step: 6
Training loss: 0.9043464070343085
Validation loss: 2.576453343213824

Epoch: 6| Step: 7
Training loss: 0.5668589657216041
Validation loss: 2.6904299238127543

Epoch: 6| Step: 8
Training loss: 1.3623277012785053
Validation loss: 2.618983625067788

Epoch: 6| Step: 9
Training loss: 1.126370760490475
Validation loss: 2.6703582459160953

Epoch: 6| Step: 10
Training loss: 1.0205531352076807
Validation loss: 2.6573849067395066

Epoch: 6| Step: 11
Training loss: 0.9481230011669356
Validation loss: 2.6894449470744743

Epoch: 6| Step: 12
Training loss: 1.1418649909588763
Validation loss: 2.6165318441180245

Epoch: 6| Step: 13
Training loss: 0.9293651502814586
Validation loss: 2.6312537705975094

Epoch: 157| Step: 0
Training loss: 0.831696599722348
Validation loss: 2.7012722891317957

Epoch: 6| Step: 1
Training loss: 0.6965026955754354
Validation loss: 2.668507630943713

Epoch: 6| Step: 2
Training loss: 1.01535024594502
Validation loss: 2.6798241879789373

Epoch: 6| Step: 3
Training loss: 0.6278656115550532
Validation loss: 2.6083267451518974

Epoch: 6| Step: 4
Training loss: 1.0456825981077684
Validation loss: 2.572307820940743

Epoch: 6| Step: 5
Training loss: 1.1092267004475864
Validation loss: 2.7271464395664875

Epoch: 6| Step: 6
Training loss: 1.305239349426994
Validation loss: 2.625612966934716

Epoch: 6| Step: 7
Training loss: 1.0142970867402104
Validation loss: 2.5837896364490964

Epoch: 6| Step: 8
Training loss: 1.3550540608534363
Validation loss: 2.5981540289040135

Epoch: 6| Step: 9
Training loss: 1.0153732574684626
Validation loss: 2.648978659106443

Epoch: 6| Step: 10
Training loss: 1.2874582191280486
Validation loss: 2.6368139781945197

Epoch: 6| Step: 11
Training loss: 1.0613075184146645
Validation loss: 2.663531693335579

Epoch: 6| Step: 12
Training loss: 0.9847484062048282
Validation loss: 2.5706391904738988

Epoch: 6| Step: 13
Training loss: 1.817004296078849
Validation loss: 2.6715852829461504

Epoch: 158| Step: 0
Training loss: 0.5773331141750427
Validation loss: 2.6264546314898367

Epoch: 6| Step: 1
Training loss: 1.0708270541550013
Validation loss: 2.5631383938033623

Epoch: 6| Step: 2
Training loss: 1.080800813192066
Validation loss: 2.6608922596503684

Epoch: 6| Step: 3
Training loss: 0.9556246638874388
Validation loss: 2.618582510314889

Epoch: 6| Step: 4
Training loss: 0.699054720088826
Validation loss: 2.5690659705353873

Epoch: 6| Step: 5
Training loss: 0.922101655672608
Validation loss: 2.621232386796528

Epoch: 6| Step: 6
Training loss: 1.2135981708955403
Validation loss: 2.7003384083730504

Epoch: 6| Step: 7
Training loss: 0.7228562361847777
Validation loss: 2.6427929497929

Epoch: 6| Step: 8
Training loss: 1.3308067622644428
Validation loss: 2.6589173033289275

Epoch: 6| Step: 9
Training loss: 1.4035037033037632
Validation loss: 2.6338733758138537

Epoch: 6| Step: 10
Training loss: 1.1602569947347319
Validation loss: 2.6231195284017064

Epoch: 6| Step: 11
Training loss: 1.7058449121084425
Validation loss: 2.630161418433437

Epoch: 6| Step: 12
Training loss: 0.9243776650741775
Validation loss: 2.581970198732381

Epoch: 6| Step: 13
Training loss: 1.041684621020398
Validation loss: 2.6614737401368282

Epoch: 159| Step: 0
Training loss: 0.9287939185005025
Validation loss: 2.73683140455952

Epoch: 6| Step: 1
Training loss: 1.200881451488266
Validation loss: 2.620329948826689

Epoch: 6| Step: 2
Training loss: 1.799402863742898
Validation loss: 2.639119142113084

Epoch: 6| Step: 3
Training loss: 1.1239638325176933
Validation loss: 2.6262251401847627

Epoch: 6| Step: 4
Training loss: 0.8470269605270786
Validation loss: 2.6989223172076464

Epoch: 6| Step: 5
Training loss: 1.236362595401545
Validation loss: 2.59350112885401

Epoch: 6| Step: 6
Training loss: 1.0022983959994687
Validation loss: 2.5967846548291624

Epoch: 6| Step: 7
Training loss: 1.058999015681572
Validation loss: 2.6474065884112705

Epoch: 6| Step: 8
Training loss: 1.390943854991731
Validation loss: 2.6673957056633015

Epoch: 6| Step: 9
Training loss: 1.1400041327485246
Validation loss: 2.6834052481008297

Epoch: 6| Step: 10
Training loss: 0.9229224768140704
Validation loss: 2.637477518802428

Epoch: 6| Step: 11
Training loss: 0.9148922276215005
Validation loss: 2.6266675980642122

Epoch: 6| Step: 12
Training loss: 1.0949540186943054
Validation loss: 2.6350567437467642

Epoch: 6| Step: 13
Training loss: 0.6146616373987277
Validation loss: 2.703018972856907

Epoch: 160| Step: 0
Training loss: 0.5352445098046607
Validation loss: 2.6445431053989017

Epoch: 6| Step: 1
Training loss: 1.0106876966742695
Validation loss: 2.591462225583067

Epoch: 6| Step: 2
Training loss: 0.80441857445933
Validation loss: 2.6631174061185066

Epoch: 6| Step: 3
Training loss: 1.0545843003257398
Validation loss: 2.7057269662083825

Epoch: 6| Step: 4
Training loss: 1.1857040275976976
Validation loss: 2.6435637514419095

Epoch: 6| Step: 5
Training loss: 1.0347152058294506
Validation loss: 2.6854066014501985

Epoch: 6| Step: 6
Training loss: 0.7589191732706255
Validation loss: 2.6531597786680634

Epoch: 6| Step: 7
Training loss: 1.8718927704185708
Validation loss: 2.7572547989875944

Epoch: 6| Step: 8
Training loss: 1.0540851144318455
Validation loss: 2.6869107568891555

Epoch: 6| Step: 9
Training loss: 0.8964371679172833
Validation loss: 2.611840337915963

Epoch: 6| Step: 10
Training loss: 0.6443911313425201
Validation loss: 2.6629703553999646

Epoch: 6| Step: 11
Training loss: 0.9773149261981191
Validation loss: 2.5975371598788137

Epoch: 6| Step: 12
Training loss: 0.8428436639022033
Validation loss: 2.659069584343803

Epoch: 6| Step: 13
Training loss: 1.5374133574100912
Validation loss: 2.7085351770943

Epoch: 161| Step: 0
Training loss: 1.265914036277449
Validation loss: 2.6753238927533776

Epoch: 6| Step: 1
Training loss: 0.9116978830075914
Validation loss: 2.6449844520462817

Epoch: 6| Step: 2
Training loss: 0.8694786186090094
Validation loss: 2.6756306478251703

Epoch: 6| Step: 3
Training loss: 0.8169552722883354
Validation loss: 2.674662513478035

Epoch: 6| Step: 4
Training loss: 1.1301020324688755
Validation loss: 2.6167621931226455

Epoch: 6| Step: 5
Training loss: 0.911205587312098
Validation loss: 2.640257439247104

Epoch: 6| Step: 6
Training loss: 1.4237657488855338
Validation loss: 2.593545545616521

Epoch: 6| Step: 7
Training loss: 1.2499933719459286
Validation loss: 2.5774588138411296

Epoch: 6| Step: 8
Training loss: 1.156115343655508
Validation loss: 2.55119693439874

Epoch: 6| Step: 9
Training loss: 0.8499924771593081
Validation loss: 2.747617050352612

Epoch: 6| Step: 10
Training loss: 0.7389302706025614
Validation loss: 2.6187931733984358

Epoch: 6| Step: 11
Training loss: 0.6624073719551989
Validation loss: 2.61294323873982

Epoch: 6| Step: 12
Training loss: 0.948672416037828
Validation loss: 2.6959658508118935

Epoch: 6| Step: 13
Training loss: 1.723521320314068
Validation loss: 2.6038549974221494

Epoch: 162| Step: 0
Training loss: 1.6047987085008226
Validation loss: 2.6636293418954273

Epoch: 6| Step: 1
Training loss: 1.0233752981604596
Validation loss: 2.6560833448600474

Epoch: 6| Step: 2
Training loss: 1.0055629849086267
Validation loss: 2.6031522962368645

Epoch: 6| Step: 3
Training loss: 0.9180353018802447
Validation loss: 2.567124566707416

Epoch: 6| Step: 4
Training loss: 0.8010777738558084
Validation loss: 2.5787443091483353

Epoch: 6| Step: 5
Training loss: 0.705837316543107
Validation loss: 2.508467924323941

Epoch: 6| Step: 6
Training loss: 1.0006637754438779
Validation loss: 2.6694063378652055

Epoch: 6| Step: 7
Training loss: 1.337916909955071
Validation loss: 2.680853098056431

Epoch: 6| Step: 8
Training loss: 1.0161974540723604
Validation loss: 2.5929768953638885

Epoch: 6| Step: 9
Training loss: 1.0686880439512851
Validation loss: 2.6984542743078292

Epoch: 6| Step: 10
Training loss: 0.8434663225063901
Validation loss: 2.6726706288759443

Epoch: 6| Step: 11
Training loss: 0.7687148977809878
Validation loss: 2.662575867218215

Epoch: 6| Step: 12
Training loss: 1.3676340300381562
Validation loss: 2.7119736830307506

Epoch: 6| Step: 13
Training loss: 0.8370042928086538
Validation loss: 2.593241048002763

Epoch: 163| Step: 0
Training loss: 1.2353476060645636
Validation loss: 2.6198240901288004

Epoch: 6| Step: 1
Training loss: 1.0853778302547779
Validation loss: 2.6016854456660226

Epoch: 6| Step: 2
Training loss: 0.449853481838035
Validation loss: 2.6923324253706844

Epoch: 6| Step: 3
Training loss: 0.9019296529895239
Validation loss: 2.6241594967138955

Epoch: 6| Step: 4
Training loss: 1.2169311351397105
Validation loss: 2.6840570226712543

Epoch: 6| Step: 5
Training loss: 0.8072513365157078
Validation loss: 2.635726433040595

Epoch: 6| Step: 6
Training loss: 1.1021605146720843
Validation loss: 2.6564359263255755

Epoch: 6| Step: 7
Training loss: 0.7391533922754578
Validation loss: 2.757373562355473

Epoch: 6| Step: 8
Training loss: 0.8601045459587706
Validation loss: 2.686410039729215

Epoch: 6| Step: 9
Training loss: 0.7252615489756833
Validation loss: 2.689698502911172

Epoch: 6| Step: 10
Training loss: 0.9649024976381941
Validation loss: 2.6140076255473077

Epoch: 6| Step: 11
Training loss: 1.3121195650514181
Validation loss: 2.638330128278812

Epoch: 6| Step: 12
Training loss: 0.8467069311279752
Validation loss: 2.665245665987987

Epoch: 6| Step: 13
Training loss: 1.7500275200996003
Validation loss: 2.6863175681544997

Epoch: 164| Step: 0
Training loss: 1.2780950360878012
Validation loss: 2.7331967821747734

Epoch: 6| Step: 1
Training loss: 1.3131245534933313
Validation loss: 2.7522513248554645

Epoch: 6| Step: 2
Training loss: 1.0519677592837962
Validation loss: 2.716689940705876

Epoch: 6| Step: 3
Training loss: 1.2240829187929585
Validation loss: 2.733854974615891

Epoch: 6| Step: 4
Training loss: 1.650450575603082
Validation loss: 2.6803256981113956

Epoch: 6| Step: 5
Training loss: 0.673309480398842
Validation loss: 2.661951998459602

Epoch: 6| Step: 6
Training loss: 0.86809162743113
Validation loss: 2.6879666980381596

Epoch: 6| Step: 7
Training loss: 0.9926258530564456
Validation loss: 2.6493591235405725

Epoch: 6| Step: 8
Training loss: 1.228576173488034
Validation loss: 2.6576163723222166

Epoch: 6| Step: 9
Training loss: 0.7668148448702098
Validation loss: 2.5795550301001966

Epoch: 6| Step: 10
Training loss: 1.2032026786003327
Validation loss: 2.6461754199777405

Epoch: 6| Step: 11
Training loss: 0.8194019895716119
Validation loss: 2.610954453850641

Epoch: 6| Step: 12
Training loss: 0.7957563214879407
Validation loss: 2.5730457865533825

Epoch: 6| Step: 13
Training loss: 0.8243174561610347
Validation loss: 2.573605963746484

Epoch: 165| Step: 0
Training loss: 1.6616269049037011
Validation loss: 2.6389914807794908

Epoch: 6| Step: 1
Training loss: 0.7613091174317423
Validation loss: 2.669970452648789

Epoch: 6| Step: 2
Training loss: 1.0592104533639106
Validation loss: 2.703305923787057

Epoch: 6| Step: 3
Training loss: 0.9538584841704476
Validation loss: 2.66564573672697

Epoch: 6| Step: 4
Training loss: 0.8053375877347995
Validation loss: 2.696555310894501

Epoch: 6| Step: 5
Training loss: 1.0673065297893027
Validation loss: 2.739796747421401

Epoch: 6| Step: 6
Training loss: 1.3269648702178583
Validation loss: 2.6983421731473793

Epoch: 6| Step: 7
Training loss: 1.4388849801280879
Validation loss: 2.685056151898667

Epoch: 6| Step: 8
Training loss: 0.8173423036953763
Validation loss: 2.647014674585217

Epoch: 6| Step: 9
Training loss: 0.9390132135796064
Validation loss: 2.655574473331837

Epoch: 6| Step: 10
Training loss: 0.9046502627811378
Validation loss: 2.710223863465162

Epoch: 6| Step: 11
Training loss: 1.1767567994679249
Validation loss: 2.6231701240357608

Epoch: 6| Step: 12
Training loss: 0.9118430424738521
Validation loss: 2.6723283676783978

Epoch: 6| Step: 13
Training loss: 0.6346629367810261
Validation loss: 2.7388860349358715

Epoch: 166| Step: 0
Training loss: 0.784465049042888
Validation loss: 2.7354986298119033

Epoch: 6| Step: 1
Training loss: 0.8594708475935406
Validation loss: 2.668604181670096

Epoch: 6| Step: 2
Training loss: 0.7614526137012368
Validation loss: 2.645310257596971

Epoch: 6| Step: 3
Training loss: 1.0645029038855067
Validation loss: 2.6265163885815963

Epoch: 6| Step: 4
Training loss: 0.8926554840421136
Validation loss: 2.732141079948078

Epoch: 6| Step: 5
Training loss: 0.9326121385048212
Validation loss: 2.7224258186689148

Epoch: 6| Step: 6
Training loss: 0.7430031560879571
Validation loss: 2.6629811662544416

Epoch: 6| Step: 7
Training loss: 0.9845803364533091
Validation loss: 2.637995718221055

Epoch: 6| Step: 8
Training loss: 0.783573358028921
Validation loss: 2.684978440669979

Epoch: 6| Step: 9
Training loss: 0.8836463096359848
Validation loss: 2.6036896891880232

Epoch: 6| Step: 10
Training loss: 1.757029515829965
Validation loss: 2.6549945632007246

Epoch: 6| Step: 11
Training loss: 1.1463803921648517
Validation loss: 2.6551077088217614

Epoch: 6| Step: 12
Training loss: 1.1394033291005237
Validation loss: 2.6271815166433234

Epoch: 6| Step: 13
Training loss: 1.099268425074561
Validation loss: 2.630515057396273

Epoch: 167| Step: 0
Training loss: 0.8257633579015653
Validation loss: 2.667659170007315

Epoch: 6| Step: 1
Training loss: 0.7428352340281358
Validation loss: 2.7333512633208548

Epoch: 6| Step: 2
Training loss: 0.8210950479397374
Validation loss: 2.645609663472706

Epoch: 6| Step: 3
Training loss: 1.1738588960648053
Validation loss: 2.64225476474665

Epoch: 6| Step: 4
Training loss: 1.9193453383940933
Validation loss: 2.6631149143068895

Epoch: 6| Step: 5
Training loss: 0.8423741036594443
Validation loss: 2.6417594293699413

Epoch: 6| Step: 6
Training loss: 0.7391212165847941
Validation loss: 2.6505910244327597

Epoch: 6| Step: 7
Training loss: 0.6037944902490867
Validation loss: 2.6566155275650334

Epoch: 6| Step: 8
Training loss: 0.598567865778435
Validation loss: 2.607864010932375

Epoch: 6| Step: 9
Training loss: 0.9282794194571851
Validation loss: 2.5902997704311757

Epoch: 6| Step: 10
Training loss: 1.0241988749725295
Validation loss: 2.684004077146004

Epoch: 6| Step: 11
Training loss: 1.207747854696369
Validation loss: 2.6786355343973676

Epoch: 6| Step: 12
Training loss: 0.9686346908362212
Validation loss: 2.6909105483887097

Epoch: 6| Step: 13
Training loss: 0.7382941673803814
Validation loss: 2.689874479834952

Epoch: 168| Step: 0
Training loss: 0.9253515864100951
Validation loss: 2.717345733744217

Epoch: 6| Step: 1
Training loss: 1.4557358452149556
Validation loss: 2.6913302281185163

Epoch: 6| Step: 2
Training loss: 0.9860354754196274
Validation loss: 2.703662855554879

Epoch: 6| Step: 3
Training loss: 0.7449298988234206
Validation loss: 2.6121185863909195

Epoch: 6| Step: 4
Training loss: 0.6835923549092907
Validation loss: 2.6319265714478597

Epoch: 6| Step: 5
Training loss: 0.7040136443761178
Validation loss: 2.64549932599364

Epoch: 6| Step: 6
Training loss: 0.9105856541476927
Validation loss: 2.563584059626062

Epoch: 6| Step: 7
Training loss: 0.5896283444812566
Validation loss: 2.653406408787677

Epoch: 6| Step: 8
Training loss: 0.93831081296164
Validation loss: 2.7088816356726992

Epoch: 6| Step: 9
Training loss: 0.8656176542665882
Validation loss: 2.701441231236577

Epoch: 6| Step: 10
Training loss: 1.1422991028833027
Validation loss: 2.632437991589044

Epoch: 6| Step: 11
Training loss: 1.313443344433579
Validation loss: 2.6846543557139206

Epoch: 6| Step: 12
Training loss: 1.236333717466123
Validation loss: 2.744645353081467

Epoch: 6| Step: 13
Training loss: 0.8425209489362949
Validation loss: 2.671711208387074

Epoch: 169| Step: 0
Training loss: 0.6780094391058858
Validation loss: 2.6255492438078463

Epoch: 6| Step: 1
Training loss: 0.6311085684184818
Validation loss: 2.6214134449619517

Epoch: 6| Step: 2
Training loss: 0.864123628188967
Validation loss: 2.6984490761566575

Epoch: 6| Step: 3
Training loss: 1.8565763039004322
Validation loss: 2.692229080100497

Epoch: 6| Step: 4
Training loss: 0.9561652800485833
Validation loss: 2.6626648131029644

Epoch: 6| Step: 5
Training loss: 0.8338580426696499
Validation loss: 2.706789623374135

Epoch: 6| Step: 6
Training loss: 0.9518326299183052
Validation loss: 2.717150747625733

Epoch: 6| Step: 7
Training loss: 1.0131775931674718
Validation loss: 2.6566881678591443

Epoch: 6| Step: 8
Training loss: 1.0648395361925407
Validation loss: 2.6238714850150493

Epoch: 6| Step: 9
Training loss: 0.8422785042762692
Validation loss: 2.697859705810953

Epoch: 6| Step: 10
Training loss: 0.7846454078265254
Validation loss: 2.6245783739718864

Epoch: 6| Step: 11
Training loss: 0.9541147440035903
Validation loss: 2.628475484561841

Epoch: 6| Step: 12
Training loss: 0.7856085693777691
Validation loss: 2.60585245627021

Epoch: 6| Step: 13
Training loss: 1.2188516232108346
Validation loss: 2.689669908528303

Epoch: 170| Step: 0
Training loss: 0.6625358985675542
Validation loss: 2.6912572309175697

Epoch: 6| Step: 1
Training loss: 0.7205207407849591
Validation loss: 2.6361465096874475

Epoch: 6| Step: 2
Training loss: 1.2657770136211473
Validation loss: 2.6784038824329777

Epoch: 6| Step: 3
Training loss: 0.5667703444872515
Validation loss: 2.615143284102754

Epoch: 6| Step: 4
Training loss: 0.7094217427856034
Validation loss: 2.6436708554204356

Epoch: 6| Step: 5
Training loss: 1.842533939002409
Validation loss: 2.716882802599425

Epoch: 6| Step: 6
Training loss: 0.8999036684404249
Validation loss: 2.6687123280352134

Epoch: 6| Step: 7
Training loss: 0.5846736246946969
Validation loss: 2.6845869940587193

Epoch: 6| Step: 8
Training loss: 0.7876214569525496
Validation loss: 2.5939828852390616

Epoch: 6| Step: 9
Training loss: 0.8184614095148599
Validation loss: 2.645111606312874

Epoch: 6| Step: 10
Training loss: 1.0918226972607425
Validation loss: 2.6529257973278724

Epoch: 6| Step: 11
Training loss: 1.1466422549040771
Validation loss: 2.678180407941707

Epoch: 6| Step: 12
Training loss: 0.70534590605258
Validation loss: 2.6380149537473168

Epoch: 6| Step: 13
Training loss: 0.8862639617896245
Validation loss: 2.616791318447259

Epoch: 171| Step: 0
Training loss: 0.7570321696209907
Validation loss: 2.6785381584523296

Epoch: 6| Step: 1
Training loss: 0.8588273470831789
Validation loss: 2.6733688431884124

Epoch: 6| Step: 2
Training loss: 1.070528551557457
Validation loss: 2.6776270679107177

Epoch: 6| Step: 3
Training loss: 0.9684490843994312
Validation loss: 2.681862796212502

Epoch: 6| Step: 4
Training loss: 0.9878061230510067
Validation loss: 2.689696722696261

Epoch: 6| Step: 5
Training loss: 1.8291324545659442
Validation loss: 2.6524280502863027

Epoch: 6| Step: 6
Training loss: 0.8024335979904879
Validation loss: 2.5847406143316687

Epoch: 6| Step: 7
Training loss: 0.7037414815194047
Validation loss: 2.655961294005148

Epoch: 6| Step: 8
Training loss: 0.6193964577046083
Validation loss: 2.622548684467408

Epoch: 6| Step: 9
Training loss: 0.9405548551138367
Validation loss: 2.7537893716886717

Epoch: 6| Step: 10
Training loss: 0.6149791854344411
Validation loss: 2.653936919824097

Epoch: 6| Step: 11
Training loss: 0.9076115476081292
Validation loss: 2.6000864845955225

Epoch: 6| Step: 12
Training loss: 0.7417832729384173
Validation loss: 2.5949693058259107

Epoch: 6| Step: 13
Training loss: 0.6009101302826914
Validation loss: 2.594107453866985

Epoch: 172| Step: 0
Training loss: 0.9314579494688545
Validation loss: 2.640388372830609

Epoch: 6| Step: 1
Training loss: 1.1132852119241454
Validation loss: 2.6302042945352397

Epoch: 6| Step: 2
Training loss: 0.7892088046265765
Validation loss: 2.73176442822244

Epoch: 6| Step: 3
Training loss: 0.7054053733298721
Validation loss: 2.5598830607274436

Epoch: 6| Step: 4
Training loss: 1.0618380560238265
Validation loss: 2.6535718843278406

Epoch: 6| Step: 5
Training loss: 1.091050549749536
Validation loss: 2.6650013392709275

Epoch: 6| Step: 6
Training loss: 1.5977877164067946
Validation loss: 2.644399094014649

Epoch: 6| Step: 7
Training loss: 0.7894628283523922
Validation loss: 2.679499731723577

Epoch: 6| Step: 8
Training loss: 0.9158721355957289
Validation loss: 2.62373675876891

Epoch: 6| Step: 9
Training loss: 0.6796588891683343
Validation loss: 2.7729655835895284

Epoch: 6| Step: 10
Training loss: 0.9710710776053874
Validation loss: 2.6806254103282194

Epoch: 6| Step: 11
Training loss: 0.8851604801625703
Validation loss: 2.66848809403619

Epoch: 6| Step: 12
Training loss: 0.7809068307582474
Validation loss: 2.6316343363571204

Epoch: 6| Step: 13
Training loss: 0.662774306316012
Validation loss: 2.7098191269436627

Epoch: 173| Step: 0
Training loss: 0.7443183025992703
Validation loss: 2.6408418118706

Epoch: 6| Step: 1
Training loss: 0.9456872748866981
Validation loss: 2.715643646445456

Epoch: 6| Step: 2
Training loss: 1.1124290015035703
Validation loss: 2.74371440287955

Epoch: 6| Step: 3
Training loss: 0.6696233501317868
Validation loss: 2.570742338312629

Epoch: 6| Step: 4
Training loss: 1.0196147899090766
Validation loss: 2.7004628090922873

Epoch: 6| Step: 5
Training loss: 0.643271260808255
Validation loss: 2.669814611111351

Epoch: 6| Step: 6
Training loss: 0.8667871736840571
Validation loss: 2.6513527698253636

Epoch: 6| Step: 7
Training loss: 0.7051286124542812
Validation loss: 2.6152570598626004

Epoch: 6| Step: 8
Training loss: 0.8052965470355936
Validation loss: 2.638492272225035

Epoch: 6| Step: 9
Training loss: 1.1505426329099815
Validation loss: 2.7455277852273623

Epoch: 6| Step: 10
Training loss: 1.5495033668316542
Validation loss: 2.759543130719929

Epoch: 6| Step: 11
Training loss: 0.9096800905199134
Validation loss: 2.591097091650873

Epoch: 6| Step: 12
Training loss: 0.8980916560068417
Validation loss: 2.602602165750179

Epoch: 6| Step: 13
Training loss: 0.9707570665442699
Validation loss: 2.68020100766152

Epoch: 174| Step: 0
Training loss: 0.6836725026135315
Validation loss: 2.6557852394561956

Epoch: 6| Step: 1
Training loss: 1.572324763542297
Validation loss: 2.6591492481990153

Epoch: 6| Step: 2
Training loss: 0.7866495838842842
Validation loss: 2.6932312084498373

Epoch: 6| Step: 3
Training loss: 0.9253042738734674
Validation loss: 2.6740547866178055

Epoch: 6| Step: 4
Training loss: 0.45419387699415237
Validation loss: 2.627720596158644

Epoch: 6| Step: 5
Training loss: 1.0113140460316605
Validation loss: 2.5996875440699405

Epoch: 6| Step: 6
Training loss: 0.9149204368602807
Validation loss: 2.7176576663512013

Epoch: 6| Step: 7
Training loss: 0.8346021450193417
Validation loss: 2.668578428698747

Epoch: 6| Step: 8
Training loss: 0.6185848979119055
Validation loss: 2.6685849432784394

Epoch: 6| Step: 9
Training loss: 1.3205233975424409
Validation loss: 2.647594073794235

Epoch: 6| Step: 10
Training loss: 1.074605254952656
Validation loss: 2.687717724637755

Epoch: 6| Step: 11
Training loss: 1.0588519355136214
Validation loss: 2.7206252781378333

Epoch: 6| Step: 12
Training loss: 0.8362302534911006
Validation loss: 2.6549694340413734

Epoch: 6| Step: 13
Training loss: 0.4934476131685685
Validation loss: 2.6691209009752686

Epoch: 175| Step: 0
Training loss: 0.9263452992596987
Validation loss: 2.6263741801851

Epoch: 6| Step: 1
Training loss: 0.6700917020358244
Validation loss: 2.673944827854203

Epoch: 6| Step: 2
Training loss: 0.8665507272662808
Validation loss: 2.6802020380623506

Epoch: 6| Step: 3
Training loss: 0.6737155986205953
Validation loss: 2.6604169436827783

Epoch: 6| Step: 4
Training loss: 0.8790406866042078
Validation loss: 2.679006936832649

Epoch: 6| Step: 5
Training loss: 0.6889851957109302
Validation loss: 2.7447135861104814

Epoch: 6| Step: 6
Training loss: 1.1672355876857226
Validation loss: 2.603823316191704

Epoch: 6| Step: 7
Training loss: 0.6503671636158807
Validation loss: 2.7416930445723002

Epoch: 6| Step: 8
Training loss: 1.0314188154356978
Validation loss: 2.6220119817912466

Epoch: 6| Step: 9
Training loss: 0.884700410641566
Validation loss: 2.7157662194351864

Epoch: 6| Step: 10
Training loss: 1.1000520347078775
Validation loss: 2.646842881585437

Epoch: 6| Step: 11
Training loss: 0.8142503078789227
Validation loss: 2.612898436953006

Epoch: 6| Step: 12
Training loss: 0.7996778003243009
Validation loss: 2.7475634603602455

Epoch: 6| Step: 13
Training loss: 1.544379176369998
Validation loss: 2.636823231075202

Epoch: 176| Step: 0
Training loss: 0.510442875818516
Validation loss: 2.65220082140899

Epoch: 6| Step: 1
Training loss: 1.6702406551086533
Validation loss: 2.660201346322774

Epoch: 6| Step: 2
Training loss: 0.716412849354274
Validation loss: 2.689905553811831

Epoch: 6| Step: 3
Training loss: 1.1978528323649615
Validation loss: 2.700834049513911

Epoch: 6| Step: 4
Training loss: 0.7521371195220707
Validation loss: 2.7125318091735067

Epoch: 6| Step: 5
Training loss: 0.43079749568266207
Validation loss: 2.6766454261809542

Epoch: 6| Step: 6
Training loss: 0.9391477092351649
Validation loss: 2.7509380821323615

Epoch: 6| Step: 7
Training loss: 0.949083420639398
Validation loss: 2.670752544242487

Epoch: 6| Step: 8
Training loss: 0.6357194747031835
Validation loss: 2.7314211340043117

Epoch: 6| Step: 9
Training loss: 0.7825502257026209
Validation loss: 2.6412096899867876

Epoch: 6| Step: 10
Training loss: 1.0341538091921285
Validation loss: 2.644133049019538

Epoch: 6| Step: 11
Training loss: 0.9032556459116865
Validation loss: 2.7159251522388796

Epoch: 6| Step: 12
Training loss: 0.848066555868421
Validation loss: 2.6887745163853696

Epoch: 6| Step: 13
Training loss: 0.7623817101949619
Validation loss: 2.7289269514342522

Epoch: 177| Step: 0
Training loss: 0.8435622465550594
Validation loss: 2.687730631432114

Epoch: 6| Step: 1
Training loss: 0.6905264995636148
Validation loss: 2.691341375372797

Epoch: 6| Step: 2
Training loss: 0.9065927317804499
Validation loss: 2.697121983044994

Epoch: 6| Step: 3
Training loss: 0.9120294507315924
Validation loss: 2.6923979845381667

Epoch: 6| Step: 4
Training loss: 0.7906544932416801
Validation loss: 2.7445029746913003

Epoch: 6| Step: 5
Training loss: 0.9414824458900106
Validation loss: 2.7065630090843174

Epoch: 6| Step: 6
Training loss: 0.6963699529242732
Validation loss: 2.6774299238896777

Epoch: 6| Step: 7
Training loss: 0.6462551528828531
Validation loss: 2.717724398390891

Epoch: 6| Step: 8
Training loss: 1.2608782918612336
Validation loss: 2.6927908928399638

Epoch: 6| Step: 9
Training loss: 0.796369205097508
Validation loss: 2.7387673113931768

Epoch: 6| Step: 10
Training loss: 0.823579440831182
Validation loss: 2.68532671031716

Epoch: 6| Step: 11
Training loss: 1.7529992559967813
Validation loss: 2.624089575122019

Epoch: 6| Step: 12
Training loss: 0.8617270447650842
Validation loss: 2.717811261634739

Epoch: 6| Step: 13
Training loss: 0.9446740634882579
Validation loss: 2.6286370799477767

Epoch: 178| Step: 0
Training loss: 0.7556085687938029
Validation loss: 2.6612015816205115

Epoch: 6| Step: 1
Training loss: 1.1116505240698602
Validation loss: 2.599921762071784

Epoch: 6| Step: 2
Training loss: 0.5716030203678745
Validation loss: 2.6582587033342207

Epoch: 6| Step: 3
Training loss: 1.4819534627220343
Validation loss: 2.633132447254012

Epoch: 6| Step: 4
Training loss: 1.086421666512573
Validation loss: 2.6527319405430854

Epoch: 6| Step: 5
Training loss: 0.8804280648228612
Validation loss: 2.693337554511297

Epoch: 6| Step: 6
Training loss: 0.9463083995500732
Validation loss: 2.6349581494226006

Epoch: 6| Step: 7
Training loss: 0.7690686612151737
Validation loss: 2.6737909641846227

Epoch: 6| Step: 8
Training loss: 0.6069661973342675
Validation loss: 2.6963138802544604

Epoch: 6| Step: 9
Training loss: 1.1405364224255232
Validation loss: 2.652257739073735

Epoch: 6| Step: 10
Training loss: 0.7677521253610432
Validation loss: 2.656896998576788

Epoch: 6| Step: 11
Training loss: 0.9230777846693028
Validation loss: 2.6573384616688753

Epoch: 6| Step: 12
Training loss: 0.6487584526231671
Validation loss: 2.6910085619588595

Epoch: 6| Step: 13
Training loss: 0.8069022357105536
Validation loss: 2.695748173244645

Epoch: 179| Step: 0
Training loss: 0.9786368350186634
Validation loss: 2.6898497282359335

Epoch: 6| Step: 1
Training loss: 0.7502969312979038
Validation loss: 2.6685620714496956

Epoch: 6| Step: 2
Training loss: 0.5638517720540257
Validation loss: 2.7342141022346484

Epoch: 6| Step: 3
Training loss: 0.7445155523352533
Validation loss: 2.6649908720985005

Epoch: 6| Step: 4
Training loss: 0.6633501158640801
Validation loss: 2.6694164379074006

Epoch: 6| Step: 5
Training loss: 0.8212167751146687
Validation loss: 2.727003453548955

Epoch: 6| Step: 6
Training loss: 0.5856869988614875
Validation loss: 2.662054981656491

Epoch: 6| Step: 7
Training loss: 0.6509560083623148
Validation loss: 2.705931226707876

Epoch: 6| Step: 8
Training loss: 1.327053221037063
Validation loss: 2.5940492756089095

Epoch: 6| Step: 9
Training loss: 0.847328544591412
Validation loss: 2.7112123568078883

Epoch: 6| Step: 10
Training loss: 0.6274525444734266
Validation loss: 2.713919290539128

Epoch: 6| Step: 11
Training loss: 1.1269887194640118
Validation loss: 2.7463085511994674

Epoch: 6| Step: 12
Training loss: 0.8458000990879508
Validation loss: 2.7089129463502197

Epoch: 6| Step: 13
Training loss: 1.5671029765040636
Validation loss: 2.693466837221214

Epoch: 180| Step: 0
Training loss: 0.8018005211033677
Validation loss: 2.72612962319717

Epoch: 6| Step: 1
Training loss: 0.8158022457768044
Validation loss: 2.7152988262829547

Epoch: 6| Step: 2
Training loss: 0.5298008507719946
Validation loss: 2.671954058988883

Epoch: 6| Step: 3
Training loss: 0.8811478575903338
Validation loss: 2.6092932758744114

Epoch: 6| Step: 4
Training loss: 0.9131873089826239
Validation loss: 2.7511255966223547

Epoch: 6| Step: 5
Training loss: 1.4952307221343972
Validation loss: 2.739173333899083

Epoch: 6| Step: 6
Training loss: 0.5673404487381442
Validation loss: 2.728115335500523

Epoch: 6| Step: 7
Training loss: 1.046789478965133
Validation loss: 2.711772251508056

Epoch: 6| Step: 8
Training loss: 0.7186439270032584
Validation loss: 2.729389674172956

Epoch: 6| Step: 9
Training loss: 0.9352183551609681
Validation loss: 2.695069277196742

Epoch: 6| Step: 10
Training loss: 1.1735795911560298
Validation loss: 2.663643797546383

Epoch: 6| Step: 11
Training loss: 0.8267641221816575
Validation loss: 2.7193191634109257

Epoch: 6| Step: 12
Training loss: 0.7148256977074025
Validation loss: 2.613397129076509

Epoch: 6| Step: 13
Training loss: 0.7234374901130955
Validation loss: 2.675286826980558

Epoch: 181| Step: 0
Training loss: 0.7833082932332102
Validation loss: 2.641039046531758

Epoch: 6| Step: 1
Training loss: 1.4472244400980416
Validation loss: 2.585327476010205

Epoch: 6| Step: 2
Training loss: 0.7428297777296935
Validation loss: 2.7207279537370614

Epoch: 6| Step: 3
Training loss: 0.9694900762159273
Validation loss: 2.6099107767130376

Epoch: 6| Step: 4
Training loss: 0.719157725249483
Validation loss: 2.6946849000176436

Epoch: 6| Step: 5
Training loss: 0.5932666919641089
Validation loss: 2.688048417668586

Epoch: 6| Step: 6
Training loss: 0.6292780849083373
Validation loss: 2.704255854267824

Epoch: 6| Step: 7
Training loss: 0.5718205254046081
Validation loss: 2.6378602069682833

Epoch: 6| Step: 8
Training loss: 1.0291008373525095
Validation loss: 2.756275047424873

Epoch: 6| Step: 9
Training loss: 0.7639882244680571
Validation loss: 2.6806006400336426

Epoch: 6| Step: 10
Training loss: 0.8050691014598096
Validation loss: 2.7256256650979123

Epoch: 6| Step: 11
Training loss: 0.6398138167351062
Validation loss: 2.7016056325781275

Epoch: 6| Step: 12
Training loss: 0.9324921049750283
Validation loss: 2.653927225024974

Epoch: 6| Step: 13
Training loss: 0.9175820692813135
Validation loss: 2.6830434443183604

Epoch: 182| Step: 0
Training loss: 0.5181865355114926
Validation loss: 2.7563329803823944

Epoch: 6| Step: 1
Training loss: 0.6524037773245165
Validation loss: 2.624620077099342

Epoch: 6| Step: 2
Training loss: 0.8044903708166775
Validation loss: 2.7093570363975625

Epoch: 6| Step: 3
Training loss: 0.6994053256062532
Validation loss: 2.744889365574129

Epoch: 6| Step: 4
Training loss: 0.7360547516997954
Validation loss: 2.675148065277954

Epoch: 6| Step: 5
Training loss: 0.6887590843196989
Validation loss: 2.7219786564753727

Epoch: 6| Step: 6
Training loss: 1.0901356514680567
Validation loss: 2.6622462938287517

Epoch: 6| Step: 7
Training loss: 0.6679252699593188
Validation loss: 2.6521194954979057

Epoch: 6| Step: 8
Training loss: 0.9923703483244763
Validation loss: 2.650263034314111

Epoch: 6| Step: 9
Training loss: 0.97066011084078
Validation loss: 2.6837990139526267

Epoch: 6| Step: 10
Training loss: 1.7163244298255904
Validation loss: 2.7269552507234214

Epoch: 6| Step: 11
Training loss: 0.8135219529254838
Validation loss: 2.728976065893582

Epoch: 6| Step: 12
Training loss: 0.8313299814624203
Validation loss: 2.726364077513834

Epoch: 6| Step: 13
Training loss: 0.4967162514450049
Validation loss: 2.633113100604637

Epoch: 183| Step: 0
Training loss: 0.8604737626929475
Validation loss: 2.7043226598722323

Epoch: 6| Step: 1
Training loss: 0.821960247535763
Validation loss: 2.686518852278969

Epoch: 6| Step: 2
Training loss: 0.8973009301008503
Validation loss: 2.669668956312491

Epoch: 6| Step: 3
Training loss: 0.7012774247231371
Validation loss: 2.6795553132161465

Epoch: 6| Step: 4
Training loss: 0.9854018895101113
Validation loss: 2.5931062627228645

Epoch: 6| Step: 5
Training loss: 0.48302588700883897
Validation loss: 2.6982889593605788

Epoch: 6| Step: 6
Training loss: 0.7345573523548863
Validation loss: 2.6754573282541125

Epoch: 6| Step: 7
Training loss: 0.9980005302045557
Validation loss: 2.655046018116646

Epoch: 6| Step: 8
Training loss: 0.6183801547503218
Validation loss: 2.618512667429786

Epoch: 6| Step: 9
Training loss: 0.792057133468235
Validation loss: 2.698826335789153

Epoch: 6| Step: 10
Training loss: 0.6983952707926898
Validation loss: 2.6330706793337595

Epoch: 6| Step: 11
Training loss: 1.4656831091319342
Validation loss: 2.611843076427012

Epoch: 6| Step: 12
Training loss: 0.6343924966287827
Validation loss: 2.6349659837195607

Epoch: 6| Step: 13
Training loss: 0.6193385725347258
Validation loss: 2.625127123221991

Epoch: 184| Step: 0
Training loss: 0.8560055655316328
Validation loss: 2.6629491513743515

Epoch: 6| Step: 1
Training loss: 0.8817030425280652
Validation loss: 2.6358701720323237

Epoch: 6| Step: 2
Training loss: 1.0006644902249056
Validation loss: 2.585280120670207

Epoch: 6| Step: 3
Training loss: 0.7959276814149078
Validation loss: 2.677604748208211

Epoch: 6| Step: 4
Training loss: 0.8812391388676991
Validation loss: 2.670086431187804

Epoch: 6| Step: 5
Training loss: 0.5894659992730804
Validation loss: 2.683376816185988

Epoch: 6| Step: 6
Training loss: 0.8992229511285476
Validation loss: 2.641119359557697

Epoch: 6| Step: 7
Training loss: 0.8543565391772944
Validation loss: 2.6838497685705405

Epoch: 6| Step: 8
Training loss: 1.5079332214413668
Validation loss: 2.6909056679210246

Epoch: 6| Step: 9
Training loss: 0.969335625129817
Validation loss: 2.645259905174166

Epoch: 6| Step: 10
Training loss: 0.40814204877029153
Validation loss: 2.605639885310649

Epoch: 6| Step: 11
Training loss: 0.6329234226168426
Validation loss: 2.700697188963024

Epoch: 6| Step: 12
Training loss: 0.8403494443535592
Validation loss: 2.614101051339675

Epoch: 6| Step: 13
Training loss: 1.255161595826439
Validation loss: 2.766064969858891

Epoch: 185| Step: 0
Training loss: 0.710237346924512
Validation loss: 2.6736479857132625

Epoch: 6| Step: 1
Training loss: 0.5194672279778515
Validation loss: 2.6922680306045903

Epoch: 6| Step: 2
Training loss: 1.5756145943309787
Validation loss: 2.744108861918134

Epoch: 6| Step: 3
Training loss: 0.8203644872268202
Validation loss: 2.714496661715546

Epoch: 6| Step: 4
Training loss: 1.1275319112249944
Validation loss: 2.6229844453965865

Epoch: 6| Step: 5
Training loss: 0.38879193315928495
Validation loss: 2.652525485914337

Epoch: 6| Step: 6
Training loss: 0.9345769453461074
Validation loss: 2.7433012161561074

Epoch: 6| Step: 7
Training loss: 0.813731031240711
Validation loss: 2.731323239459672

Epoch: 6| Step: 8
Training loss: 0.6587436166124673
Validation loss: 2.5954736704335057

Epoch: 6| Step: 9
Training loss: 0.5564148829967976
Validation loss: 2.6754293762659254

Epoch: 6| Step: 10
Training loss: 0.7883715484287134
Validation loss: 2.6979200198669413

Epoch: 6| Step: 11
Training loss: 0.808478895498171
Validation loss: 2.6950140156614424

Epoch: 6| Step: 12
Training loss: 0.8361949346000715
Validation loss: 2.712824975160711

Epoch: 6| Step: 13
Training loss: 0.6195137993181619
Validation loss: 2.6473894174095176

Epoch: 186| Step: 0
Training loss: 0.833753996214662
Validation loss: 2.7100550289830974

Epoch: 6| Step: 1
Training loss: 0.524124150616435
Validation loss: 2.7108224336827376

Epoch: 6| Step: 2
Training loss: 0.8556718977008024
Validation loss: 2.698623370741935

Epoch: 6| Step: 3
Training loss: 0.9846792810424531
Validation loss: 2.6752584350384514

Epoch: 6| Step: 4
Training loss: 0.6973220417696147
Validation loss: 2.70780902091168

Epoch: 6| Step: 5
Training loss: 0.5875809573133283
Validation loss: 2.714546725264647

Epoch: 6| Step: 6
Training loss: 1.4689205151861324
Validation loss: 2.721390753443813

Epoch: 6| Step: 7
Training loss: 0.5362397245387417
Validation loss: 2.714732779377787

Epoch: 6| Step: 8
Training loss: 0.6455332510086574
Validation loss: 2.678886138048434

Epoch: 6| Step: 9
Training loss: 0.9742937513418675
Validation loss: 2.6804732495081796

Epoch: 6| Step: 10
Training loss: 1.0160045794774273
Validation loss: 2.755328953968478

Epoch: 6| Step: 11
Training loss: 0.5399808662609845
Validation loss: 2.6441636010733394

Epoch: 6| Step: 12
Training loss: 0.8017340225611789
Validation loss: 2.5943266292735205

Epoch: 6| Step: 13
Training loss: 0.79291109523797
Validation loss: 2.6527581843861454

Epoch: 187| Step: 0
Training loss: 0.8578567965940028
Validation loss: 2.6250412044621516

Epoch: 6| Step: 1
Training loss: 0.7608286817003873
Validation loss: 2.693932545813127

Epoch: 6| Step: 2
Training loss: 0.8406672853520007
Validation loss: 2.686419572928994

Epoch: 6| Step: 3
Training loss: 1.0094483576239028
Validation loss: 2.6491393113101394

Epoch: 6| Step: 4
Training loss: 0.8660495612034177
Validation loss: 2.675788437585389

Epoch: 6| Step: 5
Training loss: 0.763691309220626
Validation loss: 2.722598979681473

Epoch: 6| Step: 6
Training loss: 0.7044024413212198
Validation loss: 2.6906281238261602

Epoch: 6| Step: 7
Training loss: 0.4411887586742928
Validation loss: 2.6864180789775016

Epoch: 6| Step: 8
Training loss: 1.0995773934139679
Validation loss: 2.6734697516476706

Epoch: 6| Step: 9
Training loss: 1.5027499422953252
Validation loss: 2.6826545593302606

Epoch: 6| Step: 10
Training loss: 0.7760610684693995
Validation loss: 2.658890223593332

Epoch: 6| Step: 11
Training loss: 0.7670424050292973
Validation loss: 2.6998526550637103

Epoch: 6| Step: 12
Training loss: 0.4493525761831091
Validation loss: 2.6256812362139144

Epoch: 6| Step: 13
Training loss: 0.8488756541301716
Validation loss: 2.6904256406408615

Epoch: 188| Step: 0
Training loss: 0.527722060527889
Validation loss: 2.5973921945160248

Epoch: 6| Step: 1
Training loss: 0.5954647650443963
Validation loss: 2.624473079899682

Epoch: 6| Step: 2
Training loss: 0.9535373358655588
Validation loss: 2.6826626320512186

Epoch: 6| Step: 3
Training loss: 1.52200821561764
Validation loss: 2.640658361461201

Epoch: 6| Step: 4
Training loss: 1.0163814955093178
Validation loss: 2.6103165654268334

Epoch: 6| Step: 5
Training loss: 0.6644876129152592
Validation loss: 2.658619979025038

Epoch: 6| Step: 6
Training loss: 0.5114014202184728
Validation loss: 2.676554918399071

Epoch: 6| Step: 7
Training loss: 1.0271962571242286
Validation loss: 2.722657213251937

Epoch: 6| Step: 8
Training loss: 0.8234970404219123
Validation loss: 2.642819983971061

Epoch: 6| Step: 9
Training loss: 0.8384767985082578
Validation loss: 2.6604999127927162

Epoch: 6| Step: 10
Training loss: 0.6347148698909129
Validation loss: 2.676882967643509

Epoch: 6| Step: 11
Training loss: 0.5341487226978525
Validation loss: 2.644199066861272

Epoch: 6| Step: 12
Training loss: 1.0918669703711843
Validation loss: 2.6704265393793705

Epoch: 6| Step: 13
Training loss: 0.6885806606945196
Validation loss: 2.6939497594087505

Epoch: 189| Step: 0
Training loss: 0.945510276093058
Validation loss: 2.6701712279117604

Epoch: 6| Step: 1
Training loss: 0.7105129777017053
Validation loss: 2.5597978005923436

Epoch: 6| Step: 2
Training loss: 0.8726138890980758
Validation loss: 2.601255037851877

Epoch: 6| Step: 3
Training loss: 0.42864233697675824
Validation loss: 2.6526355910572956

Epoch: 6| Step: 4
Training loss: 1.402102733929404
Validation loss: 2.622125042770969

Epoch: 6| Step: 5
Training loss: 0.7779096144438448
Validation loss: 2.626150999071825

Epoch: 6| Step: 6
Training loss: 0.621275293460872
Validation loss: 2.648113714810369

Epoch: 6| Step: 7
Training loss: 0.5892857824053044
Validation loss: 2.6536639771045554

Epoch: 6| Step: 8
Training loss: 0.9510455037792022
Validation loss: 2.7340310743296588

Epoch: 6| Step: 9
Training loss: 0.5855977662959126
Validation loss: 2.674138008701935

Epoch: 6| Step: 10
Training loss: 0.72806222014676
Validation loss: 2.5977469445173496

Epoch: 6| Step: 11
Training loss: 0.8646464190772973
Validation loss: 2.683858992541847

Epoch: 6| Step: 12
Training loss: 0.8455188012945604
Validation loss: 2.6752510083755756

Epoch: 6| Step: 13
Training loss: 1.0520529160335832
Validation loss: 2.7160476613186457

Epoch: 190| Step: 0
Training loss: 1.4154619068233412
Validation loss: 2.6290830616018654

Epoch: 6| Step: 1
Training loss: 0.6907370394451408
Validation loss: 2.6764315146845115

Epoch: 6| Step: 2
Training loss: 0.7347444862841568
Validation loss: 2.6531028204456244

Epoch: 6| Step: 3
Training loss: 0.8901357478117133
Validation loss: 2.6493104979364954

Epoch: 6| Step: 4
Training loss: 0.674038022286163
Validation loss: 2.6291482935856445

Epoch: 6| Step: 5
Training loss: 0.7537269181343873
Validation loss: 2.668360512428449

Epoch: 6| Step: 6
Training loss: 0.8402177199837194
Validation loss: 2.652129556493301

Epoch: 6| Step: 7
Training loss: 1.0578159980208965
Validation loss: 2.6152715853645194

Epoch: 6| Step: 8
Training loss: 0.6154454187182234
Validation loss: 2.5917742684362266

Epoch: 6| Step: 9
Training loss: 0.8101546476048483
Validation loss: 2.6726947144200457

Epoch: 6| Step: 10
Training loss: 0.7080278485850314
Validation loss: 2.71782004868926

Epoch: 6| Step: 11
Training loss: 0.8834783018261787
Validation loss: 2.6875870490946867

Epoch: 6| Step: 12
Training loss: 0.6588086928002564
Validation loss: 2.6553741058126388

Epoch: 6| Step: 13
Training loss: 1.0449353368729806
Validation loss: 2.7278160995265615

Epoch: 191| Step: 0
Training loss: 0.7153695262677526
Validation loss: 2.7225590765609065

Epoch: 6| Step: 1
Training loss: 0.5743681525153278
Validation loss: 2.756496745949447

Epoch: 6| Step: 2
Training loss: 0.8212687413880153
Validation loss: 2.7056113441717766

Epoch: 6| Step: 3
Training loss: 0.6445364056005332
Validation loss: 2.721794893390388

Epoch: 6| Step: 4
Training loss: 0.8000175742364785
Validation loss: 2.7054911053775164

Epoch: 6| Step: 5
Training loss: 0.6425310946706886
Validation loss: 2.736749849352384

Epoch: 6| Step: 6
Training loss: 0.6494260629104461
Validation loss: 2.6407735508172534

Epoch: 6| Step: 7
Training loss: 1.5343970831313267
Validation loss: 2.6297171609361363

Epoch: 6| Step: 8
Training loss: 1.171471386386242
Validation loss: 2.677350284511672

Epoch: 6| Step: 9
Training loss: 0.8556857595890639
Validation loss: 2.649289559554482

Epoch: 6| Step: 10
Training loss: 0.7165900823422674
Validation loss: 2.724364027418511

Epoch: 6| Step: 11
Training loss: 0.4205307914809059
Validation loss: 2.6573827684298696

Epoch: 6| Step: 12
Training loss: 0.582688773064111
Validation loss: 2.6370458856789676

Epoch: 6| Step: 13
Training loss: 0.5875726391140964
Validation loss: 2.655526739648693

Epoch: 192| Step: 0
Training loss: 0.8524577832885779
Validation loss: 2.6486644141289

Epoch: 6| Step: 1
Training loss: 1.4652256175435188
Validation loss: 2.696404999540016

Epoch: 6| Step: 2
Training loss: 0.6664406770889637
Validation loss: 2.692662359813027

Epoch: 6| Step: 3
Training loss: 0.5426571178127284
Validation loss: 2.611315784030495

Epoch: 6| Step: 4
Training loss: 0.7370307868339825
Validation loss: 2.5971894267817146

Epoch: 6| Step: 5
Training loss: 0.7706222159156721
Validation loss: 2.643900207629255

Epoch: 6| Step: 6
Training loss: 0.9128869477354264
Validation loss: 2.5668249925687148

Epoch: 6| Step: 7
Training loss: 0.5061186196133961
Validation loss: 2.647758824535897

Epoch: 6| Step: 8
Training loss: 0.533292155116586
Validation loss: 2.6580161861149776

Epoch: 6| Step: 9
Training loss: 1.0282599711306841
Validation loss: 2.703365822356544

Epoch: 6| Step: 10
Training loss: 0.8380242087843686
Validation loss: 2.686421688126221

Epoch: 6| Step: 11
Training loss: 0.6921375954163808
Validation loss: 2.6427021923201837

Epoch: 6| Step: 12
Training loss: 0.5895148364425311
Validation loss: 2.655399201213631

Epoch: 6| Step: 13
Training loss: 0.9812821741357015
Validation loss: 2.7242695695640307

Epoch: 193| Step: 0
Training loss: 0.5474044961240834
Validation loss: 2.6878786042139646

Epoch: 6| Step: 1
Training loss: 0.798615966081835
Validation loss: 2.751459731306253

Epoch: 6| Step: 2
Training loss: 0.7099384792296611
Validation loss: 2.731203896186506

Epoch: 6| Step: 3
Training loss: 0.8747364396567533
Validation loss: 2.688255026572186

Epoch: 6| Step: 4
Training loss: 0.5553864387228872
Validation loss: 2.6492789853086993

Epoch: 6| Step: 5
Training loss: 0.6946288830818678
Validation loss: 2.685138152491316

Epoch: 6| Step: 6
Training loss: 0.5847273218406218
Validation loss: 2.681136085443823

Epoch: 6| Step: 7
Training loss: 0.7808070262099353
Validation loss: 2.7155508972873923

Epoch: 6| Step: 8
Training loss: 0.8620870970183996
Validation loss: 2.680975898064245

Epoch: 6| Step: 9
Training loss: 0.758103619531108
Validation loss: 2.6863968973184282

Epoch: 6| Step: 10
Training loss: 1.4183151620641443
Validation loss: 2.7062102775213366

Epoch: 6| Step: 11
Training loss: 0.581186385416508
Validation loss: 2.6805995060200636

Epoch: 6| Step: 12
Training loss: 0.9150735203332305
Validation loss: 2.72537380419441

Epoch: 6| Step: 13
Training loss: 0.804314610275072
Validation loss: 2.713160472802892

Epoch: 194| Step: 0
Training loss: 0.6937543576765237
Validation loss: 2.6905680302973503

Epoch: 6| Step: 1
Training loss: 0.5919221802047032
Validation loss: 2.653032800445073

Epoch: 6| Step: 2
Training loss: 0.490824674563411
Validation loss: 2.7295021016003984

Epoch: 6| Step: 3
Training loss: 0.9582356251096962
Validation loss: 2.739147011323031

Epoch: 6| Step: 4
Training loss: 0.4514270242655689
Validation loss: 2.6240527245198364

Epoch: 6| Step: 5
Training loss: 0.6996188164717689
Validation loss: 2.660566106993819

Epoch: 6| Step: 6
Training loss: 0.844913880852258
Validation loss: 2.7094650300528675

Epoch: 6| Step: 7
Training loss: 0.3931596917763648
Validation loss: 2.6820332276118197

Epoch: 6| Step: 8
Training loss: 0.8594626988832249
Validation loss: 2.6783169280354673

Epoch: 6| Step: 9
Training loss: 0.4666224357244307
Validation loss: 2.71214603159565

Epoch: 6| Step: 10
Training loss: 0.9582776419725453
Validation loss: 2.6617905968621924

Epoch: 6| Step: 11
Training loss: 1.1777257207296303
Validation loss: 2.6917703397959114

Epoch: 6| Step: 12
Training loss: 1.4874929508074255
Validation loss: 2.7247531720753235

Epoch: 6| Step: 13
Training loss: 1.0053071811809242
Validation loss: 2.747673264126221

Epoch: 195| Step: 0
Training loss: 0.8520272063133646
Validation loss: 2.758806159492561

Epoch: 6| Step: 1
Training loss: 0.7577767117888385
Validation loss: 2.6550225207947533

Epoch: 6| Step: 2
Training loss: 0.5445330473378975
Validation loss: 2.5440090725475057

Epoch: 6| Step: 3
Training loss: 1.0936982278832341
Validation loss: 2.6952985680261534

Epoch: 6| Step: 4
Training loss: 0.8008218150215238
Validation loss: 2.685928121612905

Epoch: 6| Step: 5
Training loss: 1.6214877098010607
Validation loss: 2.6892401657801788

Epoch: 6| Step: 6
Training loss: 0.5322508360200823
Validation loss: 2.6750681425785703

Epoch: 6| Step: 7
Training loss: 0.7708919906636589
Validation loss: 2.5918728113728617

Epoch: 6| Step: 8
Training loss: 0.5591756550719764
Validation loss: 2.6055074800418003

Epoch: 6| Step: 9
Training loss: 0.8097031947874399
Validation loss: 2.629174500789749

Epoch: 6| Step: 10
Training loss: 0.5441705863902986
Validation loss: 2.65424923810768

Epoch: 6| Step: 11
Training loss: 0.7047441912259775
Validation loss: 2.6670265451623285

Epoch: 6| Step: 12
Training loss: 0.656712051491766
Validation loss: 2.750185071613086

Epoch: 6| Step: 13
Training loss: 0.7263289045321678
Validation loss: 2.7571790073861644

Epoch: 196| Step: 0
Training loss: 0.7856103144011316
Validation loss: 2.6643472931331234

Epoch: 6| Step: 1
Training loss: 0.8131894341052129
Validation loss: 2.729005952039047

Epoch: 6| Step: 2
Training loss: 0.9782999985121004
Validation loss: 2.6556505461807998

Epoch: 6| Step: 3
Training loss: 0.918782689038501
Validation loss: 2.7289057502560468

Epoch: 6| Step: 4
Training loss: 0.7581356971784825
Validation loss: 2.7402436049385903

Epoch: 6| Step: 5
Training loss: 0.8485939359374977
Validation loss: 2.710607400487694

Epoch: 6| Step: 6
Training loss: 0.9648768307346887
Validation loss: 2.6600515500907913

Epoch: 6| Step: 7
Training loss: 0.5789063045692161
Validation loss: 2.6675129580696937

Epoch: 6| Step: 8
Training loss: 0.7259840354504026
Validation loss: 2.65513992301258

Epoch: 6| Step: 9
Training loss: 0.6661846136676058
Validation loss: 2.6843793034842847

Epoch: 6| Step: 10
Training loss: 0.6690551222172161
Validation loss: 2.753320618173675

Epoch: 6| Step: 11
Training loss: 0.6651853828959209
Validation loss: 2.7456127051096915

Epoch: 6| Step: 12
Training loss: 1.4753753895638273
Validation loss: 2.6681346180833994

Epoch: 6| Step: 13
Training loss: 0.5920558903978683
Validation loss: 2.693789139158666

Epoch: 197| Step: 0
Training loss: 0.6162837691272265
Validation loss: 2.636940501742892

Epoch: 6| Step: 1
Training loss: 0.764351310830768
Validation loss: 2.635147764537399

Epoch: 6| Step: 2
Training loss: 0.6973006082088192
Validation loss: 2.6752352489286606

Epoch: 6| Step: 3
Training loss: 0.7286029180432173
Validation loss: 2.7022400217696996

Epoch: 6| Step: 4
Training loss: 0.932253717825799
Validation loss: 2.642362252623793

Epoch: 6| Step: 5
Training loss: 0.6644015624656655
Validation loss: 2.698963703448068

Epoch: 6| Step: 6
Training loss: 1.451136058504001
Validation loss: 2.738465248996701

Epoch: 6| Step: 7
Training loss: 1.0061904510505952
Validation loss: 2.6326714542992917

Epoch: 6| Step: 8
Training loss: 0.6073085519745353
Validation loss: 2.6673392004081857

Epoch: 6| Step: 9
Training loss: 0.7274851939080955
Validation loss: 2.7276245569983657

Epoch: 6| Step: 10
Training loss: 0.7330861245699494
Validation loss: 2.798950185552128

Epoch: 6| Step: 11
Training loss: 0.5770697887038434
Validation loss: 2.705317664529081

Epoch: 6| Step: 12
Training loss: 0.7089599100731164
Validation loss: 2.7176964863501523

Epoch: 6| Step: 13
Training loss: 0.4929133618368425
Validation loss: 2.6827628428611194

Epoch: 198| Step: 0
Training loss: 1.3827073224257351
Validation loss: 2.684150175391147

Epoch: 6| Step: 1
Training loss: 0.7411922407242323
Validation loss: 2.699286202868216

Epoch: 6| Step: 2
Training loss: 0.5871778964667791
Validation loss: 2.6466299094411023

Epoch: 6| Step: 3
Training loss: 0.8715213359140439
Validation loss: 2.6469949039832428

Epoch: 6| Step: 4
Training loss: 0.8125743098389925
Validation loss: 2.7516338812085825

Epoch: 6| Step: 5
Training loss: 0.5506509396768005
Validation loss: 2.6998163749513417

Epoch: 6| Step: 6
Training loss: 0.6490740581543084
Validation loss: 2.723316165557905

Epoch: 6| Step: 7
Training loss: 0.9315999979881526
Validation loss: 2.6822226111155327

Epoch: 6| Step: 8
Training loss: 0.5812205358441203
Validation loss: 2.6649683421904506

Epoch: 6| Step: 9
Training loss: 0.7189785137971801
Validation loss: 2.708812089321989

Epoch: 6| Step: 10
Training loss: 0.670767558962442
Validation loss: 2.689408267996924

Epoch: 6| Step: 11
Training loss: 0.8499128829967085
Validation loss: 2.7113566005955314

Epoch: 6| Step: 12
Training loss: 0.7415002150326273
Validation loss: 2.648382188187529

Epoch: 6| Step: 13
Training loss: 0.5726109787349157
Validation loss: 2.6376781837333745

Epoch: 199| Step: 0
Training loss: 0.5648039153471255
Validation loss: 2.629712892206894

Epoch: 6| Step: 1
Training loss: 0.6149343576522549
Validation loss: 2.7092995802880684

Epoch: 6| Step: 2
Training loss: 0.60072535935698
Validation loss: 2.6311157675578754

Epoch: 6| Step: 3
Training loss: 0.4001563154203398
Validation loss: 2.6584920583671767

Epoch: 6| Step: 4
Training loss: 0.6655597636889928
Validation loss: 2.593469121960605

Epoch: 6| Step: 5
Training loss: 0.7935343637194648
Validation loss: 2.6840958067802045

Epoch: 6| Step: 6
Training loss: 0.5458593746942564
Validation loss: 2.6706978656932194

Epoch: 6| Step: 7
Training loss: 0.9246255606494507
Validation loss: 2.677838012559533

Epoch: 6| Step: 8
Training loss: 1.3313458152998348
Validation loss: 2.7086193569466737

Epoch: 6| Step: 9
Training loss: 0.6010200234344804
Validation loss: 2.678318137197187

Epoch: 6| Step: 10
Training loss: 0.7328350071815991
Validation loss: 2.71336552102526

Epoch: 6| Step: 11
Training loss: 0.9534907655393795
Validation loss: 2.7140282446661947

Epoch: 6| Step: 12
Training loss: 0.5674407981880067
Validation loss: 2.6984208027511376

Epoch: 6| Step: 13
Training loss: 0.7269293566491937
Validation loss: 2.6315210874788804

Epoch: 200| Step: 0
Training loss: 0.4248815708084389
Validation loss: 2.690957159731695

Epoch: 6| Step: 1
Training loss: 1.0151360141592072
Validation loss: 2.619815467337052

Epoch: 6| Step: 2
Training loss: 0.6391932141619387
Validation loss: 2.633757077500137

Epoch: 6| Step: 3
Training loss: 0.7279127556561668
Validation loss: 2.6296221592945774

Epoch: 6| Step: 4
Training loss: 0.6763692073147451
Validation loss: 2.6247075160128137

Epoch: 6| Step: 5
Training loss: 1.3739775410722592
Validation loss: 2.6245689643708365

Epoch: 6| Step: 6
Training loss: 0.546512429074215
Validation loss: 2.6743040736356747

Epoch: 6| Step: 7
Training loss: 0.40043362642441704
Validation loss: 2.668764843627721

Epoch: 6| Step: 8
Training loss: 0.9788294915064832
Validation loss: 2.5997988782024

Epoch: 6| Step: 9
Training loss: 0.7117259505710594
Validation loss: 2.59844141975332

Epoch: 6| Step: 10
Training loss: 1.0061687104934913
Validation loss: 2.65482152787987

Epoch: 6| Step: 11
Training loss: 0.6475337981457481
Validation loss: 2.664306159636829

Epoch: 6| Step: 12
Training loss: 0.4963545226515794
Validation loss: 2.6595991375638004

Epoch: 6| Step: 13
Training loss: 0.7344145662727939
Validation loss: 2.7180727703485195

Epoch: 201| Step: 0
Training loss: 0.617790555279634
Validation loss: 2.6986171789968765

Epoch: 6| Step: 1
Training loss: 0.3773751539979957
Validation loss: 2.6794825884265245

Epoch: 6| Step: 2
Training loss: 1.3438509526145441
Validation loss: 2.6694767508126995

Epoch: 6| Step: 3
Training loss: 0.7280878442280565
Validation loss: 2.693386196697259

Epoch: 6| Step: 4
Training loss: 0.7772809487282706
Validation loss: 2.7404001901332435

Epoch: 6| Step: 5
Training loss: 0.8442933487679526
Validation loss: 2.696807137317317

Epoch: 6| Step: 6
Training loss: 0.8280749755721171
Validation loss: 2.716932844118524

Epoch: 6| Step: 7
Training loss: 0.5530261021363866
Validation loss: 2.699665067644074

Epoch: 6| Step: 8
Training loss: 0.4560071605937891
Validation loss: 2.6565832340424698

Epoch: 6| Step: 9
Training loss: 0.8556412475024158
Validation loss: 2.677654759517057

Epoch: 6| Step: 10
Training loss: 0.6053871099744382
Validation loss: 2.67590281263746

Epoch: 6| Step: 11
Training loss: 0.782948098078746
Validation loss: 2.6472622899944525

Epoch: 6| Step: 12
Training loss: 0.5357712323711569
Validation loss: 2.756868325075982

Epoch: 6| Step: 13
Training loss: 0.6042040013145128
Validation loss: 2.673637961105564

Epoch: 202| Step: 0
Training loss: 0.6022702054695609
Validation loss: 2.7333086532160853

Epoch: 6| Step: 1
Training loss: 0.6985492591282227
Validation loss: 2.716550909591249

Epoch: 6| Step: 2
Training loss: 0.6850690562182735
Validation loss: 2.6185958489180234

Epoch: 6| Step: 3
Training loss: 0.6478030306486989
Validation loss: 2.741782970966585

Epoch: 6| Step: 4
Training loss: 1.3176910741025034
Validation loss: 2.7234604613313222

Epoch: 6| Step: 5
Training loss: 0.598560745854878
Validation loss: 2.6160654727887214

Epoch: 6| Step: 6
Training loss: 0.6322957507467163
Validation loss: 2.722203177322754

Epoch: 6| Step: 7
Training loss: 0.7171489464197889
Validation loss: 2.7001521203079935

Epoch: 6| Step: 8
Training loss: 0.6646776155383394
Validation loss: 2.652211204217019

Epoch: 6| Step: 9
Training loss: 0.7823496899037415
Validation loss: 2.681487640069751

Epoch: 6| Step: 10
Training loss: 0.548954959209962
Validation loss: 2.708412291525129

Epoch: 6| Step: 11
Training loss: 0.7288484605652418
Validation loss: 2.6236230478261455

Epoch: 6| Step: 12
Training loss: 1.0526936086146643
Validation loss: 2.6002971027035917

Epoch: 6| Step: 13
Training loss: 0.6271662364751777
Validation loss: 2.6896843719611967

Epoch: 203| Step: 0
Training loss: 0.5082695005028067
Validation loss: 2.7050408573085276

Epoch: 6| Step: 1
Training loss: 0.4551006851825657
Validation loss: 2.7271304554628624

Epoch: 6| Step: 2
Training loss: 0.5741348724346967
Validation loss: 2.7605825314383354

Epoch: 6| Step: 3
Training loss: 0.5516702498101599
Validation loss: 2.6596133461876907

Epoch: 6| Step: 4
Training loss: 0.5401586362274579
Validation loss: 2.7009896018976685

Epoch: 6| Step: 5
Training loss: 0.5884557396831732
Validation loss: 2.7199926203973557

Epoch: 6| Step: 6
Training loss: 0.9801891277727571
Validation loss: 2.687885737274934

Epoch: 6| Step: 7
Training loss: 0.772764356126227
Validation loss: 2.6641232510647495

Epoch: 6| Step: 8
Training loss: 0.6559594283089251
Validation loss: 2.646199138514762

Epoch: 6| Step: 9
Training loss: 1.06750872847408
Validation loss: 2.748509002848456

Epoch: 6| Step: 10
Training loss: 0.6610873726537413
Validation loss: 2.6792645653556595

Epoch: 6| Step: 11
Training loss: 0.7422947856256905
Validation loss: 2.658242394696578

Epoch: 6| Step: 12
Training loss: 1.6288822455890166
Validation loss: 2.673119164217368

Epoch: 6| Step: 13
Training loss: 0.5975138675405189
Validation loss: 2.6173572314438225

Epoch: 204| Step: 0
Training loss: 0.8805655858591401
Validation loss: 2.6337587069340485

Epoch: 6| Step: 1
Training loss: 0.8408825859021389
Validation loss: 2.6645597588572723

Epoch: 6| Step: 2
Training loss: 0.9100819176702845
Validation loss: 2.70873126750079

Epoch: 6| Step: 3
Training loss: 0.5560986473680306
Validation loss: 2.805749746931325

Epoch: 6| Step: 4
Training loss: 0.5710558814815129
Validation loss: 2.7268257050507096

Epoch: 6| Step: 5
Training loss: 1.3227598542917207
Validation loss: 2.7356172337522393

Epoch: 6| Step: 6
Training loss: 0.870712265165196
Validation loss: 2.6469020987740723

Epoch: 6| Step: 7
Training loss: 0.5349452305772349
Validation loss: 2.745062101144584

Epoch: 6| Step: 8
Training loss: 0.7586245953842746
Validation loss: 2.7365355466344625

Epoch: 6| Step: 9
Training loss: 0.36567422828851076
Validation loss: 2.6493852208132265

Epoch: 6| Step: 10
Training loss: 1.0038531693849475
Validation loss: 2.674827669362258

Epoch: 6| Step: 11
Training loss: 0.6941917688251034
Validation loss: 2.6354083386517044

Epoch: 6| Step: 12
Training loss: 0.7759389019883173
Validation loss: 2.668754599669257

Epoch: 6| Step: 13
Training loss: 0.6808937156014113
Validation loss: 2.7004470202009427

Epoch: 205| Step: 0
Training loss: 0.8888397393612424
Validation loss: 2.598688762702318

Epoch: 6| Step: 1
Training loss: 0.6079809431050903
Validation loss: 2.598787762097058

Epoch: 6| Step: 2
Training loss: 0.4985927806284156
Validation loss: 2.7035281224359933

Epoch: 6| Step: 3
Training loss: 0.6786259440164119
Validation loss: 2.733852641756332

Epoch: 6| Step: 4
Training loss: 0.70232273532884
Validation loss: 2.7046764383102695

Epoch: 6| Step: 5
Training loss: 0.6023601346688096
Validation loss: 2.579651752349779

Epoch: 6| Step: 6
Training loss: 0.880327660562432
Validation loss: 2.588396837160036

Epoch: 6| Step: 7
Training loss: 0.6789024686543432
Validation loss: 2.6382985598051176

Epoch: 6| Step: 8
Training loss: 0.6442399262457446
Validation loss: 2.6199488557914816

Epoch: 6| Step: 9
Training loss: 0.7174706060256854
Validation loss: 2.72891963442536

Epoch: 6| Step: 10
Training loss: 1.423785089959632
Validation loss: 2.714794906798899

Epoch: 6| Step: 11
Training loss: 0.6364671643066432
Validation loss: 2.682739454995734

Epoch: 6| Step: 12
Training loss: 0.7306224232963504
Validation loss: 2.678139791073158

Epoch: 6| Step: 13
Training loss: 0.7430603516405075
Validation loss: 2.671007792705811

Epoch: 206| Step: 0
Training loss: 0.8747058442084199
Validation loss: 2.6192529375960913

Epoch: 6| Step: 1
Training loss: 0.7258251509513641
Validation loss: 2.6209480559727507

Epoch: 6| Step: 2
Training loss: 1.3434809925593156
Validation loss: 2.573019478683287

Epoch: 6| Step: 3
Training loss: 0.799772008058237
Validation loss: 2.726936759147355

Epoch: 6| Step: 4
Training loss: 0.9324867037420921
Validation loss: 2.6935978987399043

Epoch: 6| Step: 5
Training loss: 0.7713934736177018
Validation loss: 2.713305462437108

Epoch: 6| Step: 6
Training loss: 0.806888939273907
Validation loss: 2.6370986627101143

Epoch: 6| Step: 7
Training loss: 0.5526444594506288
Validation loss: 2.662985351811574

Epoch: 6| Step: 8
Training loss: 0.45995643435337114
Validation loss: 2.6338492445434256

Epoch: 6| Step: 9
Training loss: 0.6719504025753078
Validation loss: 2.5955006922578434

Epoch: 6| Step: 10
Training loss: 0.821726352607881
Validation loss: 2.695866875142578

Epoch: 6| Step: 11
Training loss: 0.6012079506919419
Validation loss: 2.6312277653253826

Epoch: 6| Step: 12
Training loss: 0.6770981322407402
Validation loss: 2.7025843173273603

Epoch: 6| Step: 13
Training loss: 0.6170602015303062
Validation loss: 2.630777434668603

Epoch: 207| Step: 0
Training loss: 0.4705548982982832
Validation loss: 2.6693595139573727

Epoch: 6| Step: 1
Training loss: 0.8460020105392158
Validation loss: 2.7121674370414626

Epoch: 6| Step: 2
Training loss: 0.7406690624666423
Validation loss: 2.668385463358666

Epoch: 6| Step: 3
Training loss: 0.6968032628927907
Validation loss: 2.608139651748184

Epoch: 6| Step: 4
Training loss: 0.7666817204061723
Validation loss: 2.661122240517991

Epoch: 6| Step: 5
Training loss: 0.6114512066748037
Validation loss: 2.5925121340932105

Epoch: 6| Step: 6
Training loss: 0.5105801502174426
Validation loss: 2.693097170726341

Epoch: 6| Step: 7
Training loss: 1.4445477911258449
Validation loss: 2.7132112493472738

Epoch: 6| Step: 8
Training loss: 0.7788299844608463
Validation loss: 2.7192272921962517

Epoch: 6| Step: 9
Training loss: 0.7206026332854755
Validation loss: 2.684109093696949

Epoch: 6| Step: 10
Training loss: 0.5838146154350863
Validation loss: 2.709631730895474

Epoch: 6| Step: 11
Training loss: 0.5420920340181612
Validation loss: 2.6032319387731757

Epoch: 6| Step: 12
Training loss: 0.8279133292253942
Validation loss: 2.5607368482178563

Epoch: 6| Step: 13
Training loss: 0.5165134636046473
Validation loss: 2.714416243377216

Epoch: 208| Step: 0
Training loss: 0.607935893421672
Validation loss: 2.6818586771591346

Epoch: 6| Step: 1
Training loss: 0.5620990489782688
Validation loss: 2.7832459278050057

Epoch: 6| Step: 2
Training loss: 0.4946422819869036
Validation loss: 2.673016964068077

Epoch: 6| Step: 3
Training loss: 0.6083122425037648
Validation loss: 2.7336385843358473

Epoch: 6| Step: 4
Training loss: 0.7855404725043855
Validation loss: 2.619586554828125

Epoch: 6| Step: 5
Training loss: 0.6604972049168855
Validation loss: 2.6658070092562536

Epoch: 6| Step: 6
Training loss: 1.4682937075622404
Validation loss: 2.646024596943114

Epoch: 6| Step: 7
Training loss: 0.4202325071203615
Validation loss: 2.6494788389141366

Epoch: 6| Step: 8
Training loss: 0.6102912323699001
Validation loss: 2.6369515926077964

Epoch: 6| Step: 9
Training loss: 0.6430735200272696
Validation loss: 2.60819616739121

Epoch: 6| Step: 10
Training loss: 0.4472656583161321
Validation loss: 2.6020563934088123

Epoch: 6| Step: 11
Training loss: 1.0037393987910532
Validation loss: 2.635131350566546

Epoch: 6| Step: 12
Training loss: 0.683980472712602
Validation loss: 2.7103690834960767

Epoch: 6| Step: 13
Training loss: 0.8965536186387336
Validation loss: 2.7047347051628368

Epoch: 209| Step: 0
Training loss: 0.7639030633439755
Validation loss: 2.674747937647194

Epoch: 6| Step: 1
Training loss: 0.6672105557391139
Validation loss: 2.6639886661265533

Epoch: 6| Step: 2
Training loss: 0.4641908821259075
Validation loss: 2.677065664943076

Epoch: 6| Step: 3
Training loss: 0.8098145635292546
Validation loss: 2.7374953857801034

Epoch: 6| Step: 4
Training loss: 1.297808207985431
Validation loss: 2.7332084274440462

Epoch: 6| Step: 5
Training loss: 0.7205580898827924
Validation loss: 2.667752720290894

Epoch: 6| Step: 6
Training loss: 0.8205762166778412
Validation loss: 2.66693023531464

Epoch: 6| Step: 7
Training loss: 0.6010190812952053
Validation loss: 2.590989363401295

Epoch: 6| Step: 8
Training loss: 0.5712469623409784
Validation loss: 2.7277548877932274

Epoch: 6| Step: 9
Training loss: 0.4688438162699038
Validation loss: 2.7150514372278867

Epoch: 6| Step: 10
Training loss: 0.36161817301725235
Validation loss: 2.6539286025121047

Epoch: 6| Step: 11
Training loss: 0.554689756576891
Validation loss: 2.754595687816194

Epoch: 6| Step: 12
Training loss: 0.6236106211521836
Validation loss: 2.6335831748971126

Epoch: 6| Step: 13
Training loss: 0.8418827588375895
Validation loss: 2.714503688234278

Epoch: 210| Step: 0
Training loss: 0.9660188260702183
Validation loss: 2.6829834474974095

Epoch: 6| Step: 1
Training loss: 0.6614363634160468
Validation loss: 2.679400429580873

Epoch: 6| Step: 2
Training loss: 0.7849503811868911
Validation loss: 2.7055503240278433

Epoch: 6| Step: 3
Training loss: 0.5434995293602051
Validation loss: 2.739040035627895

Epoch: 6| Step: 4
Training loss: 1.3285935865552636
Validation loss: 2.6782770624838887

Epoch: 6| Step: 5
Training loss: 0.6240032353959204
Validation loss: 2.6216517393152428

Epoch: 6| Step: 6
Training loss: 0.7264418142847511
Validation loss: 2.6881531357920645

Epoch: 6| Step: 7
Training loss: 0.6285618852147887
Validation loss: 2.6334564070571553

Epoch: 6| Step: 8
Training loss: 0.7529505864074276
Validation loss: 2.6726936662573664

Epoch: 6| Step: 9
Training loss: 0.4965089277173569
Validation loss: 2.6566755963617763

Epoch: 6| Step: 10
Training loss: 0.6806111034659573
Validation loss: 2.6228984715984796

Epoch: 6| Step: 11
Training loss: 0.5109294015785052
Validation loss: 2.6170714547160454

Epoch: 6| Step: 12
Training loss: 0.32739592343526475
Validation loss: 2.62246233272745

Epoch: 6| Step: 13
Training loss: 0.6624196768597226
Validation loss: 2.697588931371585

Epoch: 211| Step: 0
Training loss: 0.5615790032799448
Validation loss: 2.6685959100721037

Epoch: 6| Step: 1
Training loss: 0.47365621921866136
Validation loss: 2.6646212591276326

Epoch: 6| Step: 2
Training loss: 0.7730304147626614
Validation loss: 2.621680446555398

Epoch: 6| Step: 3
Training loss: 0.6322044936727896
Validation loss: 2.728511882206892

Epoch: 6| Step: 4
Training loss: 0.5390986278424484
Validation loss: 2.7401142161990553

Epoch: 6| Step: 5
Training loss: 0.4939763546228767
Validation loss: 2.620143287880351

Epoch: 6| Step: 6
Training loss: 0.6787598297292543
Validation loss: 2.699289853695582

Epoch: 6| Step: 7
Training loss: 0.5658213785600611
Validation loss: 2.6651676305853775

Epoch: 6| Step: 8
Training loss: 0.44661975853890096
Validation loss: 2.702290209456428

Epoch: 6| Step: 9
Training loss: 0.49561923905207794
Validation loss: 2.7085321402330256

Epoch: 6| Step: 10
Training loss: 1.3870500195758695
Validation loss: 2.6290202463269323

Epoch: 6| Step: 11
Training loss: 0.9049073500654382
Validation loss: 2.6849858848252848

Epoch: 6| Step: 12
Training loss: 0.5265480254586424
Validation loss: 2.6418654558574755

Epoch: 6| Step: 13
Training loss: 0.8103054560345223
Validation loss: 2.7032362707385573

Epoch: 212| Step: 0
Training loss: 0.32703088954462783
Validation loss: 2.632057074018825

Epoch: 6| Step: 1
Training loss: 0.6289262946115407
Validation loss: 2.707656245080745

Epoch: 6| Step: 2
Training loss: 1.0947969058438036
Validation loss: 2.7300491993002574

Epoch: 6| Step: 3
Training loss: 0.47520757581736006
Validation loss: 2.7432164419987317

Epoch: 6| Step: 4
Training loss: 0.6188926320454563
Validation loss: 2.7420920258481685

Epoch: 6| Step: 5
Training loss: 0.7611255389916611
Validation loss: 2.6490626539739033

Epoch: 6| Step: 6
Training loss: 0.5313237083014787
Validation loss: 2.7419765278952153

Epoch: 6| Step: 7
Training loss: 0.671208605635426
Validation loss: 2.754340762947062

Epoch: 6| Step: 8
Training loss: 0.5746976710669763
Validation loss: 2.7415848202841993

Epoch: 6| Step: 9
Training loss: 1.228878434649128
Validation loss: 2.6528580644007627

Epoch: 6| Step: 10
Training loss: 0.6930778254148351
Validation loss: 2.779884889172566

Epoch: 6| Step: 11
Training loss: 0.7079137279216742
Validation loss: 2.7087772494642612

Epoch: 6| Step: 12
Training loss: 0.6787491163314772
Validation loss: 2.6930550524815136

Epoch: 6| Step: 13
Training loss: 0.3428488971649631
Validation loss: 2.7102274555739148

Epoch: 213| Step: 0
Training loss: 0.6808745443259603
Validation loss: 2.6805895963515747

Epoch: 6| Step: 1
Training loss: 0.6086285739087847
Validation loss: 2.714340141295657

Epoch: 6| Step: 2
Training loss: 0.34741999066997525
Validation loss: 2.67755581932641

Epoch: 6| Step: 3
Training loss: 0.49771073909905683
Validation loss: 2.718674640414955

Epoch: 6| Step: 4
Training loss: 0.5052045907212942
Validation loss: 2.6062824021603825

Epoch: 6| Step: 5
Training loss: 0.8233394904685074
Validation loss: 2.627863434828581

Epoch: 6| Step: 6
Training loss: 0.805003983564768
Validation loss: 2.679408571427311

Epoch: 6| Step: 7
Training loss: 0.8839353324444411
Validation loss: 2.717028222471108

Epoch: 6| Step: 8
Training loss: 0.6236658161054908
Validation loss: 2.6750155724758464

Epoch: 6| Step: 9
Training loss: 0.6179437470713052
Validation loss: 2.752720325416614

Epoch: 6| Step: 10
Training loss: 0.6302561754925093
Validation loss: 2.7113690944255175

Epoch: 6| Step: 11
Training loss: 1.3132879072085275
Validation loss: 2.7225629297041305

Epoch: 6| Step: 12
Training loss: 0.9534494441911847
Validation loss: 2.6916553251029507

Epoch: 6| Step: 13
Training loss: 0.5255012821105648
Validation loss: 2.709911742350954

Epoch: 214| Step: 0
Training loss: 0.4188848776453812
Validation loss: 2.7116309459922787

Epoch: 6| Step: 1
Training loss: 0.8888468475797467
Validation loss: 2.702009158169059

Epoch: 6| Step: 2
Training loss: 0.4467306811035988
Validation loss: 2.6506452782450474

Epoch: 6| Step: 3
Training loss: 1.3506215077734145
Validation loss: 2.7437481763597598

Epoch: 6| Step: 4
Training loss: 0.5367320729563586
Validation loss: 2.6913446088061286

Epoch: 6| Step: 5
Training loss: 0.5595429365508362
Validation loss: 2.7139663852033302

Epoch: 6| Step: 6
Training loss: 0.9461438015362278
Validation loss: 2.71079601904393

Epoch: 6| Step: 7
Training loss: 0.6942450655719595
Validation loss: 2.7216029854998434

Epoch: 6| Step: 8
Training loss: 0.550189545871684
Validation loss: 2.7626607781943355

Epoch: 6| Step: 9
Training loss: 0.5437021859291874
Validation loss: 2.6905415275760807

Epoch: 6| Step: 10
Training loss: 0.7568214464338511
Validation loss: 2.6886228684867635

Epoch: 6| Step: 11
Training loss: 0.592874609469133
Validation loss: 2.6545692661503253

Epoch: 6| Step: 12
Training loss: 0.6632741399772595
Validation loss: 2.772274522111783

Epoch: 6| Step: 13
Training loss: 0.44008794073707486
Validation loss: 2.7214463408464193

Epoch: 215| Step: 0
Training loss: 0.36289477556398847
Validation loss: 2.7176604810025387

Epoch: 6| Step: 1
Training loss: 0.6646657783965652
Validation loss: 2.6173413131836427

Epoch: 6| Step: 2
Training loss: 0.6222067882358828
Validation loss: 2.683541250663942

Epoch: 6| Step: 3
Training loss: 0.8101382041105836
Validation loss: 2.686065039381503

Epoch: 6| Step: 4
Training loss: 0.3817613924046582
Validation loss: 2.7509870347290986

Epoch: 6| Step: 5
Training loss: 0.6826640973870102
Validation loss: 2.6272335162836145

Epoch: 6| Step: 6
Training loss: 0.6862965367559567
Validation loss: 2.711721330790023

Epoch: 6| Step: 7
Training loss: 0.7124261884771047
Validation loss: 2.660547124123075

Epoch: 6| Step: 8
Training loss: 0.5354237131726269
Validation loss: 2.64703462517966

Epoch: 6| Step: 9
Training loss: 0.5119741253945822
Validation loss: 2.7887931715061502

Epoch: 6| Step: 10
Training loss: 1.1720641937121572
Validation loss: 2.699412867498413

Epoch: 6| Step: 11
Training loss: 0.825264001278582
Validation loss: 2.7121694735535153

Epoch: 6| Step: 12
Training loss: 0.6541077753354587
Validation loss: 2.8548465995530075

Epoch: 6| Step: 13
Training loss: 0.42306946388584854
Validation loss: 2.6924092601998666

Epoch: 216| Step: 0
Training loss: 0.6012608155608159
Validation loss: 2.7380586933674733

Epoch: 6| Step: 1
Training loss: 0.7252124836740923
Validation loss: 2.7375277844416868

Epoch: 6| Step: 2
Training loss: 0.8501224766174837
Validation loss: 2.7504923553138654

Epoch: 6| Step: 3
Training loss: 0.7124477317109477
Validation loss: 2.8198591662246373

Epoch: 6| Step: 4
Training loss: 0.5345132961118195
Validation loss: 2.7788655207032456

Epoch: 6| Step: 5
Training loss: 0.37478868173015284
Validation loss: 2.6570899532914205

Epoch: 6| Step: 6
Training loss: 0.63628122005797
Validation loss: 2.8100460367063054

Epoch: 6| Step: 7
Training loss: 0.603524316027632
Validation loss: 2.7151721051383544

Epoch: 6| Step: 8
Training loss: 0.7999744724134727
Validation loss: 2.812138004318862

Epoch: 6| Step: 9
Training loss: 1.314623930717832
Validation loss: 2.7548947699700985

Epoch: 6| Step: 10
Training loss: 0.7194326724640328
Validation loss: 2.7790972775819394

Epoch: 6| Step: 11
Training loss: 0.734958498036079
Validation loss: 2.736989230286559

Epoch: 6| Step: 12
Training loss: 0.543277789750269
Validation loss: 2.7122091632564924

Epoch: 6| Step: 13
Training loss: 0.5359399445147136
Validation loss: 2.738218385679517

Epoch: 217| Step: 0
Training loss: 0.8829803644785755
Validation loss: 2.694556752275279

Epoch: 6| Step: 1
Training loss: 0.6391937736605445
Validation loss: 2.7024785189343907

Epoch: 6| Step: 2
Training loss: 0.4981765279120383
Validation loss: 2.7141705746418086

Epoch: 6| Step: 3
Training loss: 0.8013574527574094
Validation loss: 2.7088456671860826

Epoch: 6| Step: 4
Training loss: 0.6384672251170577
Validation loss: 2.6871985628684283

Epoch: 6| Step: 5
Training loss: 0.8765680023945435
Validation loss: 2.664538888110732

Epoch: 6| Step: 6
Training loss: 0.4148004900831934
Validation loss: 2.751959333915917

Epoch: 6| Step: 7
Training loss: 1.3458142947492935
Validation loss: 2.62918657657039

Epoch: 6| Step: 8
Training loss: 0.577963290924832
Validation loss: 2.6898929824482103

Epoch: 6| Step: 9
Training loss: 0.5032990811969231
Validation loss: 2.639156768542576

Epoch: 6| Step: 10
Training loss: 0.7187448584331215
Validation loss: 2.68608089801725

Epoch: 6| Step: 11
Training loss: 0.39911935468481036
Validation loss: 2.6718349565327304

Epoch: 6| Step: 12
Training loss: 0.644012103378693
Validation loss: 2.78346912562933

Epoch: 6| Step: 13
Training loss: 0.8000529629341772
Validation loss: 2.653572273669884

Epoch: 218| Step: 0
Training loss: 0.7194141967859478
Validation loss: 2.6767967654574822

Epoch: 6| Step: 1
Training loss: 0.6480104349938598
Validation loss: 2.6132990404558396

Epoch: 6| Step: 2
Training loss: 0.5466138488657977
Validation loss: 2.733952531421562

Epoch: 6| Step: 3
Training loss: 0.6165314821541292
Validation loss: 2.6683161124492387

Epoch: 6| Step: 4
Training loss: 0.7527981060547471
Validation loss: 2.6963725193974244

Epoch: 6| Step: 5
Training loss: 0.3253450478533473
Validation loss: 2.6883530334922288

Epoch: 6| Step: 6
Training loss: 0.6254239551781114
Validation loss: 2.7405816834875014

Epoch: 6| Step: 7
Training loss: 0.5965808343243078
Validation loss: 2.7331374792161145

Epoch: 6| Step: 8
Training loss: 0.5549377629034256
Validation loss: 2.7387632343965467

Epoch: 6| Step: 9
Training loss: 1.1501947569752649
Validation loss: 2.7089729116316916

Epoch: 6| Step: 10
Training loss: 0.7450805495067603
Validation loss: 2.6779067013950173

Epoch: 6| Step: 11
Training loss: 0.6534092362219004
Validation loss: 2.633999278772053

Epoch: 6| Step: 12
Training loss: 0.8277174468602514
Validation loss: 2.680402298951113

Epoch: 6| Step: 13
Training loss: 0.5875111619416574
Validation loss: 2.734411352006779

Epoch: 219| Step: 0
Training loss: 0.6207961323065813
Validation loss: 2.763190136946846

Epoch: 6| Step: 1
Training loss: 0.6933836596897051
Validation loss: 2.7321519079809407

Epoch: 6| Step: 2
Training loss: 0.6753154097198262
Validation loss: 2.72387527912988

Epoch: 6| Step: 3
Training loss: 0.5998928878463693
Validation loss: 2.7908609328258356

Epoch: 6| Step: 4
Training loss: 0.7235953749883697
Validation loss: 2.8449160242900042

Epoch: 6| Step: 5
Training loss: 0.7813776674861288
Validation loss: 2.671151790191011

Epoch: 6| Step: 6
Training loss: 0.5044891180106789
Validation loss: 2.6998677262530655

Epoch: 6| Step: 7
Training loss: 0.6277898036410711
Validation loss: 2.6200996708293287

Epoch: 6| Step: 8
Training loss: 1.2095369176383186
Validation loss: 2.653924589830211

Epoch: 6| Step: 9
Training loss: 0.5442165061691951
Validation loss: 2.688217096986892

Epoch: 6| Step: 10
Training loss: 0.7306631309015922
Validation loss: 2.7623568691958647

Epoch: 6| Step: 11
Training loss: 0.5027290017908637
Validation loss: 2.6710047206153797

Epoch: 6| Step: 12
Training loss: 0.3902697282725025
Validation loss: 2.705734191733214

Epoch: 6| Step: 13
Training loss: 0.7859527950429126
Validation loss: 2.716697692888949

Epoch: 220| Step: 0
Training loss: 0.7386348220835786
Validation loss: 2.8045443584216483

Epoch: 6| Step: 1
Training loss: 0.8121650812475537
Validation loss: 2.7077423380108

Epoch: 6| Step: 2
Training loss: 0.6724616527969053
Validation loss: 2.62771218074391

Epoch: 6| Step: 3
Training loss: 0.7644303011910427
Validation loss: 2.6773911137171886

Epoch: 6| Step: 4
Training loss: 1.187935548514317
Validation loss: 2.744983236925259

Epoch: 6| Step: 5
Training loss: 0.3681645077163878
Validation loss: 2.684079810577579

Epoch: 6| Step: 6
Training loss: 0.6283069859384834
Validation loss: 2.5973843616277907

Epoch: 6| Step: 7
Training loss: 0.5649352868753497
Validation loss: 2.6126415722344216

Epoch: 6| Step: 8
Training loss: 0.6262064257327106
Validation loss: 2.7211193123309587

Epoch: 6| Step: 9
Training loss: 0.5524165719249393
Validation loss: 2.606505836230994

Epoch: 6| Step: 10
Training loss: 0.5242698087428972
Validation loss: 2.662690168105421

Epoch: 6| Step: 11
Training loss: 0.640909248186937
Validation loss: 2.7885997042757404

Epoch: 6| Step: 12
Training loss: 0.989703033970976
Validation loss: 2.637383851360938

Epoch: 6| Step: 13
Training loss: 0.6108762149365488
Validation loss: 2.6660250746264915

Epoch: 221| Step: 0
Training loss: 0.6823779820790897
Validation loss: 2.7047912812812385

Epoch: 6| Step: 1
Training loss: 0.5976860188568855
Validation loss: 2.693857487645664

Epoch: 6| Step: 2
Training loss: 0.5563200981462111
Validation loss: 2.638917472472624

Epoch: 6| Step: 3
Training loss: 0.7492287962302617
Validation loss: 2.719421267310575

Epoch: 6| Step: 4
Training loss: 0.6535556979300108
Validation loss: 2.728856925762496

Epoch: 6| Step: 5
Training loss: 0.6910823127823071
Validation loss: 2.6840446496860633

Epoch: 6| Step: 6
Training loss: 1.2227363438316514
Validation loss: 2.6723768941480395

Epoch: 6| Step: 7
Training loss: 1.0176810946507486
Validation loss: 2.768517829340189

Epoch: 6| Step: 8
Training loss: 0.6098344977789005
Validation loss: 2.748665680990691

Epoch: 6| Step: 9
Training loss: 0.6117473542016311
Validation loss: 2.656447967931101

Epoch: 6| Step: 10
Training loss: 0.5468460892801069
Validation loss: 2.7061528500452114

Epoch: 6| Step: 11
Training loss: 0.5546626770482793
Validation loss: 2.658212295953653

Epoch: 6| Step: 12
Training loss: 0.4299128548342908
Validation loss: 2.662088119336149

Epoch: 6| Step: 13
Training loss: 0.47952626217969885
Validation loss: 2.7001929873501895

Epoch: 222| Step: 0
Training loss: 0.4355728757478825
Validation loss: 2.603270160219534

Epoch: 6| Step: 1
Training loss: 0.6141272862549256
Validation loss: 2.6237427410275513

Epoch: 6| Step: 2
Training loss: 0.6398602549900917
Validation loss: 2.574975156818532

Epoch: 6| Step: 3
Training loss: 0.44614752062931906
Validation loss: 2.6990857678128513

Epoch: 6| Step: 4
Training loss: 1.123087528985636
Validation loss: 2.5870262919440257

Epoch: 6| Step: 5
Training loss: 0.7062265442860726
Validation loss: 2.665058281758024

Epoch: 6| Step: 6
Training loss: 0.8031327124793076
Validation loss: 2.7195999965290687

Epoch: 6| Step: 7
Training loss: 0.988094387557451
Validation loss: 2.6559970361269842

Epoch: 6| Step: 8
Training loss: 0.5082521442812801
Validation loss: 2.707761283517819

Epoch: 6| Step: 9
Training loss: 0.8498308265855049
Validation loss: 2.666938310933599

Epoch: 6| Step: 10
Training loss: 0.6176367464660555
Validation loss: 2.6540687281466147

Epoch: 6| Step: 11
Training loss: 0.4573583817821291
Validation loss: 2.631036840701185

Epoch: 6| Step: 12
Training loss: 0.4478643482910183
Validation loss: 2.6309972102499497

Epoch: 6| Step: 13
Training loss: 0.4616566559788424
Validation loss: 2.711651637460254

Epoch: 223| Step: 0
Training loss: 0.5362592871068496
Validation loss: 2.689421698581255

Epoch: 6| Step: 1
Training loss: 0.48050884916868053
Validation loss: 2.650962233836663

Epoch: 6| Step: 2
Training loss: 0.6313159813720257
Validation loss: 2.657875431369034

Epoch: 6| Step: 3
Training loss: 0.5637761580664029
Validation loss: 2.725624294687664

Epoch: 6| Step: 4
Training loss: 0.6805368575513977
Validation loss: 2.5932634655661597

Epoch: 6| Step: 5
Training loss: 1.2255463004826745
Validation loss: 2.69603174168317

Epoch: 6| Step: 6
Training loss: 0.4833252514240209
Validation loss: 2.659478219252144

Epoch: 6| Step: 7
Training loss: 0.5471767138208333
Validation loss: 2.7333364421741515

Epoch: 6| Step: 8
Training loss: 0.6493424454974293
Validation loss: 2.7462195217945666

Epoch: 6| Step: 9
Training loss: 0.8561886758493416
Validation loss: 2.718851840278612

Epoch: 6| Step: 10
Training loss: 0.728451150695072
Validation loss: 2.6900814802623243

Epoch: 6| Step: 11
Training loss: 0.6031448064526559
Validation loss: 2.612392500592804

Epoch: 6| Step: 12
Training loss: 0.6100864658672167
Validation loss: 2.657966874214479

Epoch: 6| Step: 13
Training loss: 0.5622524140451595
Validation loss: 2.6914195082088326

Epoch: 224| Step: 0
Training loss: 0.8324310345192777
Validation loss: 2.6915809932651995

Epoch: 6| Step: 1
Training loss: 0.5605383151261444
Validation loss: 2.6390076411169034

Epoch: 6| Step: 2
Training loss: 0.5651990456338858
Validation loss: 2.7172630891820724

Epoch: 6| Step: 3
Training loss: 0.5108895025544594
Validation loss: 2.685153964806314

Epoch: 6| Step: 4
Training loss: 0.43679896455666495
Validation loss: 2.687290286967686

Epoch: 6| Step: 5
Training loss: 0.6573742138092104
Validation loss: 2.721281312882964

Epoch: 6| Step: 6
Training loss: 0.4627588140760102
Validation loss: 2.674842019927233

Epoch: 6| Step: 7
Training loss: 0.611778848748094
Validation loss: 2.729197120981917

Epoch: 6| Step: 8
Training loss: 0.6866442382800764
Validation loss: 2.7128577856314995

Epoch: 6| Step: 9
Training loss: 0.7458408186623936
Validation loss: 2.6673235282930667

Epoch: 6| Step: 10
Training loss: 0.5733437651232254
Validation loss: 2.722092791375974

Epoch: 6| Step: 11
Training loss: 0.6137111639100471
Validation loss: 2.7001115616956306

Epoch: 6| Step: 12
Training loss: 1.1283300704758619
Validation loss: 2.6814470584780437

Epoch: 6| Step: 13
Training loss: 0.5327367174953254
Validation loss: 2.746577748839254

Epoch: 225| Step: 0
Training loss: 0.7153453630370292
Validation loss: 2.712396659581878

Epoch: 6| Step: 1
Training loss: 0.88131789899557
Validation loss: 2.64945251759397

Epoch: 6| Step: 2
Training loss: 0.5193923821966238
Validation loss: 2.739160749287641

Epoch: 6| Step: 3
Training loss: 1.1616485964456487
Validation loss: 2.597627147234276

Epoch: 6| Step: 4
Training loss: 0.5310127064932109
Validation loss: 2.749828354940731

Epoch: 6| Step: 5
Training loss: 0.32161962322450965
Validation loss: 2.7333555228410384

Epoch: 6| Step: 6
Training loss: 0.6176059125503601
Validation loss: 2.7253558559386004

Epoch: 6| Step: 7
Training loss: 0.6905007548359164
Validation loss: 2.7696021411253895

Epoch: 6| Step: 8
Training loss: 0.47590750098159534
Validation loss: 2.696623611373684

Epoch: 6| Step: 9
Training loss: 0.638368610394173
Validation loss: 2.7481108736865587

Epoch: 6| Step: 10
Training loss: 0.5246525227632821
Validation loss: 2.7571380626251827

Epoch: 6| Step: 11
Training loss: 0.4913897937633108
Validation loss: 2.7252169607275882

Epoch: 6| Step: 12
Training loss: 0.8588470918276478
Validation loss: 2.6486664319563573

Epoch: 6| Step: 13
Training loss: 0.7050574555894153
Validation loss: 2.6625067828693463

Epoch: 226| Step: 0
Training loss: 1.2763179661571302
Validation loss: 2.6994090917138682

Epoch: 6| Step: 1
Training loss: 0.5332733778731583
Validation loss: 2.7857560791005898

Epoch: 6| Step: 2
Training loss: 0.5573529955431568
Validation loss: 2.749362019026014

Epoch: 6| Step: 3
Training loss: 0.7461785872393857
Validation loss: 2.712241922573791

Epoch: 6| Step: 4
Training loss: 0.5557130815441802
Validation loss: 2.7396720078963894

Epoch: 6| Step: 5
Training loss: 0.7182471133159835
Validation loss: 2.748137146552256

Epoch: 6| Step: 6
Training loss: 0.546848241968844
Validation loss: 2.7422848762981276

Epoch: 6| Step: 7
Training loss: 0.48237418120453857
Validation loss: 2.7123729705364625

Epoch: 6| Step: 8
Training loss: 0.5287954059340674
Validation loss: 2.7589571903276995

Epoch: 6| Step: 9
Training loss: 0.651263478957846
Validation loss: 2.7205529428233692

Epoch: 6| Step: 10
Training loss: 0.7758127596046568
Validation loss: 2.7363872426390707

Epoch: 6| Step: 11
Training loss: 0.6540005140827503
Validation loss: 2.6955718279673504

Epoch: 6| Step: 12
Training loss: 0.44763075404768526
Validation loss: 2.657119997451628

Epoch: 6| Step: 13
Training loss: 0.6860775103001249
Validation loss: 2.709015948517957

Epoch: 227| Step: 0
Training loss: 0.5455345073523381
Validation loss: 2.6759662647743845

Epoch: 6| Step: 1
Training loss: 0.6192207164285581
Validation loss: 2.7282688372412123

Epoch: 6| Step: 2
Training loss: 0.6606169678660808
Validation loss: 2.6847653929249016

Epoch: 6| Step: 3
Training loss: 0.6077049062076673
Validation loss: 2.7217756659816343

Epoch: 6| Step: 4
Training loss: 0.8450257229134546
Validation loss: 2.7839081452396726

Epoch: 6| Step: 5
Training loss: 0.6881597994148159
Validation loss: 2.7469560364569388

Epoch: 6| Step: 6
Training loss: 0.6458526936572277
Validation loss: 2.7910682311994335

Epoch: 6| Step: 7
Training loss: 0.7360915150423237
Validation loss: 2.74225637380213

Epoch: 6| Step: 8
Training loss: 1.2183503204723511
Validation loss: 2.6808891604888134

Epoch: 6| Step: 9
Training loss: 0.7909355217205434
Validation loss: 2.731107885299149

Epoch: 6| Step: 10
Training loss: 0.5080948264909899
Validation loss: 2.8322962845183244

Epoch: 6| Step: 11
Training loss: 0.5595040007440539
Validation loss: 2.7305930586402147

Epoch: 6| Step: 12
Training loss: 0.5147366819062239
Validation loss: 2.7163706631871527

Epoch: 6| Step: 13
Training loss: 0.4874431130645739
Validation loss: 2.736005184513519

Epoch: 228| Step: 0
Training loss: 0.49338984089564464
Validation loss: 2.681755654316822

Epoch: 6| Step: 1
Training loss: 0.7651774597032714
Validation loss: 2.701224642164876

Epoch: 6| Step: 2
Training loss: 1.133443091257512
Validation loss: 2.691285225223833

Epoch: 6| Step: 3
Training loss: 0.700280262836205
Validation loss: 2.6842303976147512

Epoch: 6| Step: 4
Training loss: 0.538901429369063
Validation loss: 2.745472540665812

Epoch: 6| Step: 5
Training loss: 0.30381061843888985
Validation loss: 2.679473868437497

Epoch: 6| Step: 6
Training loss: 0.618682691978349
Validation loss: 2.66664302835319

Epoch: 6| Step: 7
Training loss: 0.4349888875243465
Validation loss: 2.722845245179605

Epoch: 6| Step: 8
Training loss: 0.5160321160106315
Validation loss: 2.7207528041549525

Epoch: 6| Step: 9
Training loss: 0.4679896864243686
Validation loss: 2.736659303818655

Epoch: 6| Step: 10
Training loss: 0.6364200335985449
Validation loss: 2.7215970212392713

Epoch: 6| Step: 11
Training loss: 0.4902820184057165
Validation loss: 2.7109323111272836

Epoch: 6| Step: 12
Training loss: 0.5884648557068893
Validation loss: 2.7191871934638745

Epoch: 6| Step: 13
Training loss: 0.7740736762892826
Validation loss: 2.7411733420212587

Epoch: 229| Step: 0
Training loss: 0.7469149159893966
Validation loss: 2.7129963029638704

Epoch: 6| Step: 1
Training loss: 0.6865040761461264
Validation loss: 2.703064118510057

Epoch: 6| Step: 2
Training loss: 1.1984493011331245
Validation loss: 2.694179425746708

Epoch: 6| Step: 3
Training loss: 0.45896570695289174
Validation loss: 2.7115699550667887

Epoch: 6| Step: 4
Training loss: 0.5618551584714269
Validation loss: 2.6474687347991464

Epoch: 6| Step: 5
Training loss: 0.4334529269992765
Validation loss: 2.688837280535683

Epoch: 6| Step: 6
Training loss: 0.5776705115293618
Validation loss: 2.604755691035396

Epoch: 6| Step: 7
Training loss: 0.5603099681246009
Validation loss: 2.6792773793919196

Epoch: 6| Step: 8
Training loss: 0.5592754978784255
Validation loss: 2.6299871420938814

Epoch: 6| Step: 9
Training loss: 0.5285840178430175
Validation loss: 2.631328462592173

Epoch: 6| Step: 10
Training loss: 0.6470947841319714
Validation loss: 2.719232720969711

Epoch: 6| Step: 11
Training loss: 0.6406391653960395
Validation loss: 2.7327002928148456

Epoch: 6| Step: 12
Training loss: 0.6730613436834658
Validation loss: 2.713256093604324

Epoch: 6| Step: 13
Training loss: 0.6784192892588609
Validation loss: 2.7193030017839255

Epoch: 230| Step: 0
Training loss: 0.6271687074591388
Validation loss: 2.751345940869359

Epoch: 6| Step: 1
Training loss: 0.659785510814277
Validation loss: 2.6766386491521357

Epoch: 6| Step: 2
Training loss: 0.5273501360471258
Validation loss: 2.6497465816221055

Epoch: 6| Step: 3
Training loss: 0.5576812653877624
Validation loss: 2.7597826439507527

Epoch: 6| Step: 4
Training loss: 0.8668824080169257
Validation loss: 2.768431760468608

Epoch: 6| Step: 5
Training loss: 0.47775248183639313
Validation loss: 2.6925330532339173

Epoch: 6| Step: 6
Training loss: 0.5053002939065229
Validation loss: 2.7508572340509296

Epoch: 6| Step: 7
Training loss: 0.6733936623026098
Validation loss: 2.7344124637035483

Epoch: 6| Step: 8
Training loss: 0.6419077800043324
Validation loss: 2.731665185874024

Epoch: 6| Step: 9
Training loss: 0.4467553305283886
Validation loss: 2.7301423728647096

Epoch: 6| Step: 10
Training loss: 0.6964143316678559
Validation loss: 2.6659643818049203

Epoch: 6| Step: 11
Training loss: 1.1285665456362697
Validation loss: 2.660621008696373

Epoch: 6| Step: 12
Training loss: 0.6600884848580943
Validation loss: 2.608335961979363

Epoch: 6| Step: 13
Training loss: 0.40601239224956825
Validation loss: 2.673588803571196

Epoch: 231| Step: 0
Training loss: 0.43351899610959294
Validation loss: 2.765365947652762

Epoch: 6| Step: 1
Training loss: 0.5975100020445338
Validation loss: 2.6514660258923524

Epoch: 6| Step: 2
Training loss: 0.3872435890440367
Validation loss: 2.692975735007445

Epoch: 6| Step: 3
Training loss: 0.8280668418183661
Validation loss: 2.682564809774129

Epoch: 6| Step: 4
Training loss: 0.5290143712476744
Validation loss: 2.68375349240312

Epoch: 6| Step: 5
Training loss: 0.6915888572114041
Validation loss: 2.6379620670100716

Epoch: 6| Step: 6
Training loss: 0.6906663631981045
Validation loss: 2.7359156455389484

Epoch: 6| Step: 7
Training loss: 0.5136261546163051
Validation loss: 2.676188120108031

Epoch: 6| Step: 8
Training loss: 0.4873203588500037
Validation loss: 2.5376819633047245

Epoch: 6| Step: 9
Training loss: 0.5358326111408467
Validation loss: 2.7466435467648185

Epoch: 6| Step: 10
Training loss: 0.5022437000458677
Validation loss: 2.6711561637727947

Epoch: 6| Step: 11
Training loss: 0.49855019063818734
Validation loss: 2.6940238193911763

Epoch: 6| Step: 12
Training loss: 0.38297163322169603
Validation loss: 2.6631123478876972

Epoch: 6| Step: 13
Training loss: 1.0127305086322935
Validation loss: 2.7292199578554355

Epoch: 232| Step: 0
Training loss: 1.1332180481131586
Validation loss: 2.7346047150531914

Epoch: 6| Step: 1
Training loss: 0.6519914692367447
Validation loss: 2.6324400897815052

Epoch: 6| Step: 2
Training loss: 0.688147889812449
Validation loss: 2.7456029794378574

Epoch: 6| Step: 3
Training loss: 0.5911687154724536
Validation loss: 2.774116139370517

Epoch: 6| Step: 4
Training loss: 0.5873999591629955
Validation loss: 2.7096912696626503

Epoch: 6| Step: 5
Training loss: 0.6739472214865165
Validation loss: 2.724766428441896

Epoch: 6| Step: 6
Training loss: 0.4662383181358778
Validation loss: 2.711875291601457

Epoch: 6| Step: 7
Training loss: 0.4689127321694571
Validation loss: 2.7817187682160385

Epoch: 6| Step: 8
Training loss: 0.6792015881911851
Validation loss: 2.6476285856273787

Epoch: 6| Step: 9
Training loss: 0.6237914798987616
Validation loss: 2.6749957265849456

Epoch: 6| Step: 10
Training loss: 0.524747007584093
Validation loss: 2.622890396733996

Epoch: 6| Step: 11
Training loss: 0.46524610656757226
Validation loss: 2.7017725094915055

Epoch: 6| Step: 12
Training loss: 0.465746427870406
Validation loss: 2.7059786659813216

Epoch: 6| Step: 13
Training loss: 0.5080168092980368
Validation loss: 2.784631430894399

Epoch: 233| Step: 0
Training loss: 0.41454147130713825
Validation loss: 2.663886249935614

Epoch: 6| Step: 1
Training loss: 0.5753345418144182
Validation loss: 2.7486226938791907

Epoch: 6| Step: 2
Training loss: 0.6311958053666454
Validation loss: 2.776590952587017

Epoch: 6| Step: 3
Training loss: 0.7584996205318258
Validation loss: 2.661110615768953

Epoch: 6| Step: 4
Training loss: 0.46470027600742564
Validation loss: 2.7044586684259464

Epoch: 6| Step: 5
Training loss: 0.6195465105252963
Validation loss: 2.721101905532343

Epoch: 6| Step: 6
Training loss: 0.6821404403552409
Validation loss: 2.7123362279342627

Epoch: 6| Step: 7
Training loss: 0.3962055033600996
Validation loss: 2.8687867322244753

Epoch: 6| Step: 8
Training loss: 1.103419152828155
Validation loss: 2.6644439871597356

Epoch: 6| Step: 9
Training loss: 0.6031580733090903
Validation loss: 2.767039696888775

Epoch: 6| Step: 10
Training loss: 0.6287691665898143
Validation loss: 2.6715363851215272

Epoch: 6| Step: 11
Training loss: 0.5350633248170302
Validation loss: 2.7565925644767164

Epoch: 6| Step: 12
Training loss: 0.4829262016261294
Validation loss: 2.6824658210783525

Epoch: 6| Step: 13
Training loss: 0.5274676142147593
Validation loss: 2.714782018897332

Epoch: 234| Step: 0
Training loss: 0.715316116103885
Validation loss: 2.7872655442060146

Epoch: 6| Step: 1
Training loss: 1.059696875541698
Validation loss: 2.7670196493784034

Epoch: 6| Step: 2
Training loss: 0.5506333497504409
Validation loss: 2.7040536127032944

Epoch: 6| Step: 3
Training loss: 0.354419396023018
Validation loss: 2.753228207348531

Epoch: 6| Step: 4
Training loss: 0.5122254171062653
Validation loss: 2.675089696170614

Epoch: 6| Step: 5
Training loss: 0.6825240566918533
Validation loss: 2.7890247873130534

Epoch: 6| Step: 6
Training loss: 0.3837517290666625
Validation loss: 2.759134741087376

Epoch: 6| Step: 7
Training loss: 0.4302376779457544
Validation loss: 2.7273455700394287

Epoch: 6| Step: 8
Training loss: 0.32389619017610166
Validation loss: 2.7392811094801797

Epoch: 6| Step: 9
Training loss: 0.6223340875065625
Validation loss: 2.7233600992835245

Epoch: 6| Step: 10
Training loss: 0.502339344390962
Validation loss: 2.718142152850401

Epoch: 6| Step: 11
Training loss: 0.7183620815838039
Validation loss: 2.7129975259626415

Epoch: 6| Step: 12
Training loss: 0.6090559980300824
Validation loss: 2.73338205383268

Epoch: 6| Step: 13
Training loss: 0.5965755390482759
Validation loss: 2.712609221783555

Epoch: 235| Step: 0
Training loss: 0.4430273047604725
Validation loss: 2.789944335696684

Epoch: 6| Step: 1
Training loss: 0.5678910360992115
Validation loss: 2.717607850195546

Epoch: 6| Step: 2
Training loss: 0.6536543466892536
Validation loss: 2.710592015190113

Epoch: 6| Step: 3
Training loss: 0.618053649394588
Validation loss: 2.7282319445948677

Epoch: 6| Step: 4
Training loss: 0.33793580298952763
Validation loss: 2.7421440490584077

Epoch: 6| Step: 5
Training loss: 0.45588697335219946
Validation loss: 2.75381527292748

Epoch: 6| Step: 6
Training loss: 0.8065615562128977
Validation loss: 2.7683269211933883

Epoch: 6| Step: 7
Training loss: 0.595301132894611
Validation loss: 2.814899777107077

Epoch: 6| Step: 8
Training loss: 0.4826602269753175
Validation loss: 2.7244366334689447

Epoch: 6| Step: 9
Training loss: 0.4988662263064795
Validation loss: 2.7078105324108668

Epoch: 6| Step: 10
Training loss: 1.2349210086842881
Validation loss: 2.6733078414418228

Epoch: 6| Step: 11
Training loss: 0.43610127835146517
Validation loss: 2.7835774916121325

Epoch: 6| Step: 12
Training loss: 0.5254132857984068
Validation loss: 2.743783223871372

Epoch: 6| Step: 13
Training loss: 0.8871837858557008
Validation loss: 2.806327956376379

Epoch: 236| Step: 0
Training loss: 0.709332215283464
Validation loss: 2.6801347127668187

Epoch: 6| Step: 1
Training loss: 0.6098062994108937
Validation loss: 2.7186827961884585

Epoch: 6| Step: 2
Training loss: 0.3587365491518639
Validation loss: 2.729518523114788

Epoch: 6| Step: 3
Training loss: 0.5627343960991998
Validation loss: 2.6951244343922065

Epoch: 6| Step: 4
Training loss: 0.6340309939164197
Validation loss: 2.724289486791466

Epoch: 6| Step: 5
Training loss: 0.5196149658214361
Validation loss: 2.69233685309998

Epoch: 6| Step: 6
Training loss: 0.4556243630654654
Validation loss: 2.769589300224297

Epoch: 6| Step: 7
Training loss: 0.33810931499012975
Validation loss: 2.637738058607009

Epoch: 6| Step: 8
Training loss: 0.6871084919154492
Validation loss: 2.6626573214668605

Epoch: 6| Step: 9
Training loss: 0.5624182429768007
Validation loss: 2.656365994183429

Epoch: 6| Step: 10
Training loss: 1.1701121995386927
Validation loss: 2.7070361821293454

Epoch: 6| Step: 11
Training loss: 0.4356908859495661
Validation loss: 2.7386086667700162

Epoch: 6| Step: 12
Training loss: 0.529197261206214
Validation loss: 2.596218458867796

Epoch: 6| Step: 13
Training loss: 0.4271129291638439
Validation loss: 2.7074680168679133

Epoch: 237| Step: 0
Training loss: 0.2967346261082518
Validation loss: 2.6525835426038626

Epoch: 6| Step: 1
Training loss: 0.6580925008025691
Validation loss: 2.6867808777108646

Epoch: 6| Step: 2
Training loss: 0.6787090932697516
Validation loss: 2.678838871668211

Epoch: 6| Step: 3
Training loss: 0.6276376855111827
Validation loss: 2.6836897283619883

Epoch: 6| Step: 4
Training loss: 0.7697423655028206
Validation loss: 2.714100321973042

Epoch: 6| Step: 5
Training loss: 0.598295978913781
Validation loss: 2.6695657012088843

Epoch: 6| Step: 6
Training loss: 0.6712023006661215
Validation loss: 2.6941386444761504

Epoch: 6| Step: 7
Training loss: 0.6186794886245213
Validation loss: 2.7278487296846268

Epoch: 6| Step: 8
Training loss: 0.7014771118535781
Validation loss: 2.629813277284638

Epoch: 6| Step: 9
Training loss: 0.43366313069935203
Validation loss: 2.804669294236227

Epoch: 6| Step: 10
Training loss: 1.1432971745844742
Validation loss: 2.7853146401443514

Epoch: 6| Step: 11
Training loss: 0.6984004341547994
Validation loss: 2.660645457212936

Epoch: 6| Step: 12
Training loss: 0.2884621442886251
Validation loss: 2.775870861264361

Epoch: 6| Step: 13
Training loss: 0.3936432769495878
Validation loss: 2.7158176056776258

Epoch: 238| Step: 0
Training loss: 0.4538271495291795
Validation loss: 2.785217241686774

Epoch: 6| Step: 1
Training loss: 0.6073788446719622
Validation loss: 2.7231864029933193

Epoch: 6| Step: 2
Training loss: 0.792095737296608
Validation loss: 2.7406852063098106

Epoch: 6| Step: 3
Training loss: 0.7409668370958598
Validation loss: 2.772402503085434

Epoch: 6| Step: 4
Training loss: 0.4375729500032588
Validation loss: 2.726371153608995

Epoch: 6| Step: 5
Training loss: 1.1898382656399324
Validation loss: 2.716287820725066

Epoch: 6| Step: 6
Training loss: 0.7308997448404972
Validation loss: 2.698996417415993

Epoch: 6| Step: 7
Training loss: 0.8747033910749065
Validation loss: 2.7284643322677455

Epoch: 6| Step: 8
Training loss: 0.5496538948079327
Validation loss: 2.7661018607029244

Epoch: 6| Step: 9
Training loss: 0.4859747157917637
Validation loss: 2.671376953404648

Epoch: 6| Step: 10
Training loss: 0.5960831227486391
Validation loss: 2.618255503602771

Epoch: 6| Step: 11
Training loss: 0.37160841739121986
Validation loss: 2.6208997977784105

Epoch: 6| Step: 12
Training loss: 0.697513546931746
Validation loss: 2.5860331921961164

Epoch: 6| Step: 13
Training loss: 0.6671753795157137
Validation loss: 2.658864369063025

Epoch: 239| Step: 0
Training loss: 0.6384807615705116
Validation loss: 2.7345102476550043

Epoch: 6| Step: 1
Training loss: 0.5177464049659776
Validation loss: 2.6204143767473993

Epoch: 6| Step: 2
Training loss: 0.8065290396961345
Validation loss: 2.616050207410645

Epoch: 6| Step: 3
Training loss: 0.4605783906334046
Validation loss: 2.619862410776419

Epoch: 6| Step: 4
Training loss: 0.4150178432650189
Validation loss: 2.717488855048391

Epoch: 6| Step: 5
Training loss: 0.7180148802041502
Validation loss: 2.6559373110560043

Epoch: 6| Step: 6
Training loss: 0.39363589525695475
Validation loss: 2.5867141218191065

Epoch: 6| Step: 7
Training loss: 1.1100741050658705
Validation loss: 2.667672955865424

Epoch: 6| Step: 8
Training loss: 0.3229657515269898
Validation loss: 2.707645319088287

Epoch: 6| Step: 9
Training loss: 0.43682683518204946
Validation loss: 2.671419844796479

Epoch: 6| Step: 10
Training loss: 0.3445363479029496
Validation loss: 2.749878071480597

Epoch: 6| Step: 11
Training loss: 0.6332944753504963
Validation loss: 2.682751052677075

Epoch: 6| Step: 12
Training loss: 0.44781934619789393
Validation loss: 2.795059460182067

Epoch: 6| Step: 13
Training loss: 0.5493269584489949
Validation loss: 2.776662121418335

Epoch: 240| Step: 0
Training loss: 0.5974852373382356
Validation loss: 2.7029423661174334

Epoch: 6| Step: 1
Training loss: 0.5981873041546618
Validation loss: 2.7651350230290874

Epoch: 6| Step: 2
Training loss: 0.4648756609309628
Validation loss: 2.8323305379639687

Epoch: 6| Step: 3
Training loss: 0.5294626405718412
Validation loss: 2.7033500871676175

Epoch: 6| Step: 4
Training loss: 0.7861392571795228
Validation loss: 2.689467515724556

Epoch: 6| Step: 5
Training loss: 1.1997222340497367
Validation loss: 2.729746608898438

Epoch: 6| Step: 6
Training loss: 0.4558881827358079
Validation loss: 2.7590401342242066

Epoch: 6| Step: 7
Training loss: 0.5769256058356294
Validation loss: 2.701022019163427

Epoch: 6| Step: 8
Training loss: 0.4806674453386903
Validation loss: 2.7443952087107726

Epoch: 6| Step: 9
Training loss: 0.4933618432207503
Validation loss: 2.7624033394612817

Epoch: 6| Step: 10
Training loss: 0.74988078123504
Validation loss: 2.809859590529408

Epoch: 6| Step: 11
Training loss: 0.8481006775687675
Validation loss: 2.727691897417026

Epoch: 6| Step: 12
Training loss: 0.5819674975407279
Validation loss: 2.738786999864433

Epoch: 6| Step: 13
Training loss: 0.630910605603242
Validation loss: 2.697615990889318

Epoch: 241| Step: 0
Training loss: 0.673193812700444
Validation loss: 2.6717976043972937

Epoch: 6| Step: 1
Training loss: 0.6685045781303345
Validation loss: 2.7125431549577113

Epoch: 6| Step: 2
Training loss: 0.7698269580877979
Validation loss: 2.6751922775993653

Epoch: 6| Step: 3
Training loss: 1.1536331979764312
Validation loss: 2.738502148884456

Epoch: 6| Step: 4
Training loss: 0.36375886018193804
Validation loss: 2.725646848053794

Epoch: 6| Step: 5
Training loss: 0.40847024892841777
Validation loss: 2.7419955556844156

Epoch: 6| Step: 6
Training loss: 0.5322158392429635
Validation loss: 2.6972618093792784

Epoch: 6| Step: 7
Training loss: 0.37360717478092265
Validation loss: 2.674432278042256

Epoch: 6| Step: 8
Training loss: 0.4294827406860437
Validation loss: 2.726447393543535

Epoch: 6| Step: 9
Training loss: 0.6502247504333606
Validation loss: 2.7123148970724142

Epoch: 6| Step: 10
Training loss: 0.4793565795323536
Validation loss: 2.7908262629479688

Epoch: 6| Step: 11
Training loss: 0.5495326180396298
Validation loss: 2.6808606870672955

Epoch: 6| Step: 12
Training loss: 0.5234951727680088
Validation loss: 2.706495502662927

Epoch: 6| Step: 13
Training loss: 0.4062802230156514
Validation loss: 2.7746475946772104

Epoch: 242| Step: 0
Training loss: 0.45504989863927825
Validation loss: 2.6404995559300017

Epoch: 6| Step: 1
Training loss: 0.7036794383854986
Validation loss: 2.7867453644179148

Epoch: 6| Step: 2
Training loss: 0.47224496649527875
Validation loss: 2.724768980540268

Epoch: 6| Step: 3
Training loss: 0.44284469710882635
Validation loss: 2.611158633194213

Epoch: 6| Step: 4
Training loss: 0.5622594371951813
Validation loss: 2.6383947099336913

Epoch: 6| Step: 5
Training loss: 0.4190320367571733
Validation loss: 2.7239646668418254

Epoch: 6| Step: 6
Training loss: 1.125440511289648
Validation loss: 2.7121399366534162

Epoch: 6| Step: 7
Training loss: 0.47622232334186376
Validation loss: 2.699450764895204

Epoch: 6| Step: 8
Training loss: 0.6702204447671622
Validation loss: 2.7118253399177035

Epoch: 6| Step: 9
Training loss: 0.4474042319537175
Validation loss: 2.7400286183289726

Epoch: 6| Step: 10
Training loss: 0.4364539652251511
Validation loss: 2.69509598604115

Epoch: 6| Step: 11
Training loss: 0.567181760060084
Validation loss: 2.657182021341961

Epoch: 6| Step: 12
Training loss: 0.4017115320115861
Validation loss: 2.73528706189572

Epoch: 6| Step: 13
Training loss: 0.44072966921885953
Validation loss: 2.732352520614901

Epoch: 243| Step: 0
Training loss: 1.1791325962999168
Validation loss: 2.6932907925643814

Epoch: 6| Step: 1
Training loss: 0.37041119495651514
Validation loss: 2.662812447758509

Epoch: 6| Step: 2
Training loss: 0.35477343875132084
Validation loss: 2.6691544570985015

Epoch: 6| Step: 3
Training loss: 0.4715630207349608
Validation loss: 2.596186615573169

Epoch: 6| Step: 4
Training loss: 0.5120893694172948
Validation loss: 2.6405006695432127

Epoch: 6| Step: 5
Training loss: 0.5123425241765711
Validation loss: 2.732477237994014

Epoch: 6| Step: 6
Training loss: 0.5081644159304498
Validation loss: 2.725752563558861

Epoch: 6| Step: 7
Training loss: 0.4988004182366405
Validation loss: 2.704749690383417

Epoch: 6| Step: 8
Training loss: 0.5780850473981307
Validation loss: 2.771274507626717

Epoch: 6| Step: 9
Training loss: 0.47744601850804036
Validation loss: 2.700739320446631

Epoch: 6| Step: 10
Training loss: 0.7115134536666806
Validation loss: 2.7138457661767403

Epoch: 6| Step: 11
Training loss: 0.5656388444418057
Validation loss: 2.650347115916902

Epoch: 6| Step: 12
Training loss: 0.5200245458513354
Validation loss: 2.712500891853807

Epoch: 6| Step: 13
Training loss: 0.5796000247565686
Validation loss: 2.689820160449809

Epoch: 244| Step: 0
Training loss: 0.6304285332049727
Validation loss: 2.645779974592131

Epoch: 6| Step: 1
Training loss: 0.397035807223477
Validation loss: 2.743966260191939

Epoch: 6| Step: 2
Training loss: 0.444061429252649
Validation loss: 2.7434475386623074

Epoch: 6| Step: 3
Training loss: 0.7046599270655614
Validation loss: 2.6644668421410618

Epoch: 6| Step: 4
Training loss: 0.4349846739645144
Validation loss: 2.624111857862981

Epoch: 6| Step: 5
Training loss: 0.564624535956286
Validation loss: 2.7173577028491414

Epoch: 6| Step: 6
Training loss: 0.41158400399026696
Validation loss: 2.725947080163354

Epoch: 6| Step: 7
Training loss: 1.0404920567544316
Validation loss: 2.5973312289322794

Epoch: 6| Step: 8
Training loss: 0.4842068010981131
Validation loss: 2.6676438498210207

Epoch: 6| Step: 9
Training loss: 0.6585180055767824
Validation loss: 2.786525209759248

Epoch: 6| Step: 10
Training loss: 0.47932182439831406
Validation loss: 2.7408792358232095

Epoch: 6| Step: 11
Training loss: 0.45648976388257767
Validation loss: 2.676404537922164

Epoch: 6| Step: 12
Training loss: 0.3557852080488951
Validation loss: 2.628401195272525

Epoch: 6| Step: 13
Training loss: 0.39802904323059884
Validation loss: 2.6901750041329153

Epoch: 245| Step: 0
Training loss: 0.46206185232762326
Validation loss: 2.6636063678408504

Epoch: 6| Step: 1
Training loss: 0.4842554529392133
Validation loss: 2.758240289261702

Epoch: 6| Step: 2
Training loss: 0.4385851277481318
Validation loss: 2.7006086864300944

Epoch: 6| Step: 3
Training loss: 0.6760122973660949
Validation loss: 2.7401277100369086

Epoch: 6| Step: 4
Training loss: 0.39241658393441525
Validation loss: 2.7362602782749845

Epoch: 6| Step: 5
Training loss: 0.6236769500797352
Validation loss: 2.7359911620176725

Epoch: 6| Step: 6
Training loss: 0.5637875232769349
Validation loss: 2.756113798967246

Epoch: 6| Step: 7
Training loss: 0.4627554329893758
Validation loss: 2.7425171164039646

Epoch: 6| Step: 8
Training loss: 0.6167559986449028
Validation loss: 2.738831642984965

Epoch: 6| Step: 9
Training loss: 0.9346757628004589
Validation loss: 2.659500706021791

Epoch: 6| Step: 10
Training loss: 0.5031667502477846
Validation loss: 2.7238158607544163

Epoch: 6| Step: 11
Training loss: 0.4846969426733736
Validation loss: 2.6630438295492205

Epoch: 6| Step: 12
Training loss: 0.4684909104531112
Validation loss: 2.7078720188955323

Epoch: 6| Step: 13
Training loss: 0.40096866471678627
Validation loss: 2.6446332587848675

Epoch: 246| Step: 0
Training loss: 0.5307056499158888
Validation loss: 2.6703633573840455

Epoch: 6| Step: 1
Training loss: 0.3195205294948855
Validation loss: 2.7232324473053118

Epoch: 6| Step: 2
Training loss: 0.4633069962396288
Validation loss: 2.7571325427464095

Epoch: 6| Step: 3
Training loss: 0.5471429985594718
Validation loss: 2.7003375990285763

Epoch: 6| Step: 4
Training loss: 0.4111683483577758
Validation loss: 2.6358600112870705

Epoch: 6| Step: 5
Training loss: 0.5673371656115086
Validation loss: 2.662573442058102

Epoch: 6| Step: 6
Training loss: 0.3535017358570024
Validation loss: 2.706355272437758

Epoch: 6| Step: 7
Training loss: 0.6735698038940358
Validation loss: 2.7258394916814335

Epoch: 6| Step: 8
Training loss: 0.6647487908761576
Validation loss: 2.6945412827051793

Epoch: 6| Step: 9
Training loss: 1.133137728603303
Validation loss: 2.717567683701523

Epoch: 6| Step: 10
Training loss: 0.45262404406598566
Validation loss: 2.7953123987864914

Epoch: 6| Step: 11
Training loss: 0.4715679976317913
Validation loss: 2.7618167253711268

Epoch: 6| Step: 12
Training loss: 0.39498993676682015
Validation loss: 2.6670551364788597

Epoch: 6| Step: 13
Training loss: 0.40685385061633283
Validation loss: 2.6830603204966077

Epoch: 247| Step: 0
Training loss: 0.504563250762861
Validation loss: 2.6904412372615822

Epoch: 6| Step: 1
Training loss: 0.7389749164582929
Validation loss: 2.6893485609240324

Epoch: 6| Step: 2
Training loss: 0.40375345907707755
Validation loss: 2.7296815173020406

Epoch: 6| Step: 3
Training loss: 0.5497268160866384
Validation loss: 2.717627794313469

Epoch: 6| Step: 4
Training loss: 0.3045845591437378
Validation loss: 2.6822901654779376

Epoch: 6| Step: 5
Training loss: 0.5640701261728694
Validation loss: 2.7182699780903725

Epoch: 6| Step: 6
Training loss: 0.9602010432473069
Validation loss: 2.7606623606233316

Epoch: 6| Step: 7
Training loss: 0.5460541695807162
Validation loss: 2.749971317372873

Epoch: 6| Step: 8
Training loss: 0.5080102388821932
Validation loss: 2.7102343392139145

Epoch: 6| Step: 9
Training loss: 0.4462340339775015
Validation loss: 2.688210910836583

Epoch: 6| Step: 10
Training loss: 0.337816913921728
Validation loss: 2.721803346399545

Epoch: 6| Step: 11
Training loss: 0.6797574325188852
Validation loss: 2.7441983218027204

Epoch: 6| Step: 12
Training loss: 0.48836043669420903
Validation loss: 2.7457132451179413

Epoch: 6| Step: 13
Training loss: 0.607643798323886
Validation loss: 2.7637192002053537

Epoch: 248| Step: 0
Training loss: 0.27560528714969673
Validation loss: 2.740461554414615

Epoch: 6| Step: 1
Training loss: 0.5216949266430889
Validation loss: 2.6799412524725805

Epoch: 6| Step: 2
Training loss: 0.4965452707613386
Validation loss: 2.7152063068199004

Epoch: 6| Step: 3
Training loss: 0.552063551734312
Validation loss: 2.757776838293572

Epoch: 6| Step: 4
Training loss: 0.44793647530099073
Validation loss: 2.7454046304492663

Epoch: 6| Step: 5
Training loss: 0.5249741616021536
Validation loss: 2.7286265520663466

Epoch: 6| Step: 6
Training loss: 0.5748774066102446
Validation loss: 2.701221611795238

Epoch: 6| Step: 7
Training loss: 0.4305996143792477
Validation loss: 2.69978949938946

Epoch: 6| Step: 8
Training loss: 0.9549572952069351
Validation loss: 2.7279101578115417

Epoch: 6| Step: 9
Training loss: 0.5038364569066311
Validation loss: 2.644374006922286

Epoch: 6| Step: 10
Training loss: 0.5732509995779114
Validation loss: 2.8083002594114284

Epoch: 6| Step: 11
Training loss: 0.7274699952797281
Validation loss: 2.6785822777301327

Epoch: 6| Step: 12
Training loss: 0.8267996276619326
Validation loss: 2.6465820294482905

Epoch: 6| Step: 13
Training loss: 0.39134466634751375
Validation loss: 2.712699156509493

Epoch: 249| Step: 0
Training loss: 0.47206144502113545
Validation loss: 2.7168498652263544

Epoch: 6| Step: 1
Training loss: 0.6235882072613406
Validation loss: 2.6875611231750622

Epoch: 6| Step: 2
Training loss: 0.4544230481891318
Validation loss: 2.7217017333587905

Epoch: 6| Step: 3
Training loss: 1.006998369081118
Validation loss: 2.671460898509506

Epoch: 6| Step: 4
Training loss: 0.6052716088059636
Validation loss: 2.673388938975559

Epoch: 6| Step: 5
Training loss: 0.4328232009886884
Validation loss: 2.702428584712328

Epoch: 6| Step: 6
Training loss: 0.45855694611757847
Validation loss: 2.7808797211207934

Epoch: 6| Step: 7
Training loss: 0.5905653726663523
Validation loss: 2.7016003963650532

Epoch: 6| Step: 8
Training loss: 0.5258998176008606
Validation loss: 2.6795995343805585

Epoch: 6| Step: 9
Training loss: 0.5649054803528069
Validation loss: 2.70230760508812

Epoch: 6| Step: 10
Training loss: 0.5003572915951117
Validation loss: 2.6635469327438703

Epoch: 6| Step: 11
Training loss: 0.29459896472877195
Validation loss: 2.6812116405289195

Epoch: 6| Step: 12
Training loss: 0.23790958999179326
Validation loss: 2.702537546288134

Epoch: 6| Step: 13
Training loss: 0.5845568858349883
Validation loss: 2.678443872199933

Epoch: 250| Step: 0
Training loss: 0.46014601432154356
Validation loss: 2.7272074464007567

Epoch: 6| Step: 1
Training loss: 0.7026994477053397
Validation loss: 2.6073317532436637

Epoch: 6| Step: 2
Training loss: 0.7880663863431209
Validation loss: 2.725470075396484

Epoch: 6| Step: 3
Training loss: 0.5906772408769569
Validation loss: 2.68532417252505

Epoch: 6| Step: 4
Training loss: 0.49176455293811916
Validation loss: 2.7000947258662835

Epoch: 6| Step: 5
Training loss: 0.5358000732034517
Validation loss: 2.699088660719914

Epoch: 6| Step: 6
Training loss: 0.43334816516044555
Validation loss: 2.7920849804592773

Epoch: 6| Step: 7
Training loss: 0.9276633145071532
Validation loss: 2.746120794605336

Epoch: 6| Step: 8
Training loss: 0.6461374325728626
Validation loss: 2.724918995974411

Epoch: 6| Step: 9
Training loss: 0.4793622371063789
Validation loss: 2.797115493181147

Epoch: 6| Step: 10
Training loss: 0.5700812720198443
Validation loss: 2.689929263450538

Epoch: 6| Step: 11
Training loss: 0.7824969449455903
Validation loss: 2.6982454568440652

Epoch: 6| Step: 12
Training loss: 0.49514364138024525
Validation loss: 2.641486093344309

Epoch: 6| Step: 13
Training loss: 0.3884715613594173
Validation loss: 2.7768917082493467

Epoch: 251| Step: 0
Training loss: 0.5181854715248925
Validation loss: 2.796491799129559

Epoch: 6| Step: 1
Training loss: 0.4512425487040482
Validation loss: 2.7114838957390686

Epoch: 6| Step: 2
Training loss: 0.35304009083465543
Validation loss: 2.6740476166625737

Epoch: 6| Step: 3
Training loss: 0.6506440410704348
Validation loss: 2.6856079464528473

Epoch: 6| Step: 4
Training loss: 0.5145017642907531
Validation loss: 2.7322671086124766

Epoch: 6| Step: 5
Training loss: 0.46201955546342716
Validation loss: 2.7093103456097687

Epoch: 6| Step: 6
Training loss: 0.6317740974645948
Validation loss: 2.758529800340732

Epoch: 6| Step: 7
Training loss: 0.4523904041746538
Validation loss: 2.7459529878616507

Epoch: 6| Step: 8
Training loss: 0.3837061785240008
Validation loss: 2.7319548005209078

Epoch: 6| Step: 9
Training loss: 0.7020572183960999
Validation loss: 2.7806080137959963

Epoch: 6| Step: 10
Training loss: 0.4221214351735099
Validation loss: 2.789444912322018

Epoch: 6| Step: 11
Training loss: 0.4039878585685891
Validation loss: 2.7112152807446503

Epoch: 6| Step: 12
Training loss: 1.0760144570311834
Validation loss: 2.72484430282444

Epoch: 6| Step: 13
Training loss: 0.5855725995928437
Validation loss: 2.67492340518944

Epoch: 252| Step: 0
Training loss: 0.4617517036774191
Validation loss: 2.65008756085054

Epoch: 6| Step: 1
Training loss: 0.6742783963196568
Validation loss: 2.7835704396003704

Epoch: 6| Step: 2
Training loss: 1.1250270204478072
Validation loss: 2.691602193180301

Epoch: 6| Step: 3
Training loss: 0.447334917189802
Validation loss: 2.7869028372670743

Epoch: 6| Step: 4
Training loss: 0.7504168782365392
Validation loss: 2.7120044525141815

Epoch: 6| Step: 5
Training loss: 0.5991091054697846
Validation loss: 2.7012211999000733

Epoch: 6| Step: 6
Training loss: 0.4700796818402329
Validation loss: 2.6196675482913205

Epoch: 6| Step: 7
Training loss: 0.3027327629784765
Validation loss: 2.7816871128127003

Epoch: 6| Step: 8
Training loss: 0.48958702965281187
Validation loss: 2.7347952528846466

Epoch: 6| Step: 9
Training loss: 0.3293046183371448
Validation loss: 2.7495045215564655

Epoch: 6| Step: 10
Training loss: 0.3240883231657198
Validation loss: 2.726034585148893

Epoch: 6| Step: 11
Training loss: 0.6638113107759516
Validation loss: 2.6589061994751186

Epoch: 6| Step: 12
Training loss: 0.6026455925693186
Validation loss: 2.6392559588156277

Epoch: 6| Step: 13
Training loss: 0.403585868401094
Validation loss: 2.6950518643325703

Epoch: 253| Step: 0
Training loss: 0.4269819914752365
Validation loss: 2.707267233510938

Epoch: 6| Step: 1
Training loss: 0.49449627407587277
Validation loss: 2.700624930503825

Epoch: 6| Step: 2
Training loss: 0.6293517720426114
Validation loss: 2.6500255133642248

Epoch: 6| Step: 3
Training loss: 0.5347351032070766
Validation loss: 2.725875709699549

Epoch: 6| Step: 4
Training loss: 0.6352971126045843
Validation loss: 2.674959926364476

Epoch: 6| Step: 5
Training loss: 0.5940815853000965
Validation loss: 2.720906772372113

Epoch: 6| Step: 6
Training loss: 0.3647704824850131
Validation loss: 2.7170766599078204

Epoch: 6| Step: 7
Training loss: 0.5194916387386279
Validation loss: 2.717856380884326

Epoch: 6| Step: 8
Training loss: 0.967451640652882
Validation loss: 2.6562467088865946

Epoch: 6| Step: 9
Training loss: 0.5583182235590086
Validation loss: 2.6280972207529403

Epoch: 6| Step: 10
Training loss: 0.3549068327329043
Validation loss: 2.7267549550686536

Epoch: 6| Step: 11
Training loss: 0.3749414835414776
Validation loss: 2.7124606204360613

Epoch: 6| Step: 12
Training loss: 0.4833459690788137
Validation loss: 2.6856181631163247

Epoch: 6| Step: 13
Training loss: 0.5153015740730145
Validation loss: 2.737376151919531

Epoch: 254| Step: 0
Training loss: 0.6157955940238873
Validation loss: 2.712255049631038

Epoch: 6| Step: 1
Training loss: 0.37666914921479777
Validation loss: 2.6893740485152207

Epoch: 6| Step: 2
Training loss: 0.4067288657537727
Validation loss: 2.7486686445972817

Epoch: 6| Step: 3
Training loss: 0.44920050542519346
Validation loss: 2.717386890573649

Epoch: 6| Step: 4
Training loss: 0.5197126889160101
Validation loss: 2.637656113522673

Epoch: 6| Step: 5
Training loss: 0.31535958612432397
Validation loss: 2.7465353945693347

Epoch: 6| Step: 6
Training loss: 0.5546615487058965
Validation loss: 2.729785446217743

Epoch: 6| Step: 7
Training loss: 0.5004452868346861
Validation loss: 2.667751148857923

Epoch: 6| Step: 8
Training loss: 0.5728973703313727
Validation loss: 2.747496086328396

Epoch: 6| Step: 9
Training loss: 0.5105204346982215
Validation loss: 2.738645274534997

Epoch: 6| Step: 10
Training loss: 0.5171654837725224
Validation loss: 2.736958843316658

Epoch: 6| Step: 11
Training loss: 0.7176845780987265
Validation loss: 2.664239230591135

Epoch: 6| Step: 12
Training loss: 0.9106001201364801
Validation loss: 2.7715049350397973

Epoch: 6| Step: 13
Training loss: 0.3855191128986227
Validation loss: 2.681236286617325

Epoch: 255| Step: 0
Training loss: 0.4815121308360338
Validation loss: 2.682453496304137

Epoch: 6| Step: 1
Training loss: 0.43181109622225256
Validation loss: 2.686851963010414

Epoch: 6| Step: 2
Training loss: 0.3592479107914796
Validation loss: 2.773762686564179

Epoch: 6| Step: 3
Training loss: 0.4528068214623828
Validation loss: 2.684502193825888

Epoch: 6| Step: 4
Training loss: 0.41375375429046335
Validation loss: 2.728316128427379

Epoch: 6| Step: 5
Training loss: 0.4270963569919376
Validation loss: 2.705478253936745

Epoch: 6| Step: 6
Training loss: 0.5634492176633734
Validation loss: 2.645743020586362

Epoch: 6| Step: 7
Training loss: 0.9602943376982973
Validation loss: 2.7285614701581267

Epoch: 6| Step: 8
Training loss: 0.388177470992643
Validation loss: 2.6845489090350396

Epoch: 6| Step: 9
Training loss: 0.4849908973881806
Validation loss: 2.674662298057116

Epoch: 6| Step: 10
Training loss: 0.5947768216749675
Validation loss: 2.7030261394673034

Epoch: 6| Step: 11
Training loss: 0.29490363462516644
Validation loss: 2.729285482678847

Epoch: 6| Step: 12
Training loss: 0.6089899117913617
Validation loss: 2.654916503381159

Epoch: 6| Step: 13
Training loss: 0.44776944764765814
Validation loss: 2.71444974459825

Epoch: 256| Step: 0
Training loss: 0.3723424882183074
Validation loss: 2.65199998922909

Epoch: 6| Step: 1
Training loss: 0.670300212827521
Validation loss: 2.73016531826823

Epoch: 6| Step: 2
Training loss: 0.48743270385080845
Validation loss: 2.695795165258029

Epoch: 6| Step: 3
Training loss: 0.3503040253484443
Validation loss: 2.686907030086082

Epoch: 6| Step: 4
Training loss: 0.3576709109026666
Validation loss: 2.666271401456703

Epoch: 6| Step: 5
Training loss: 0.34383345804583576
Validation loss: 2.8164476170281785

Epoch: 6| Step: 6
Training loss: 0.4925299164840085
Validation loss: 2.713637810954504

Epoch: 6| Step: 7
Training loss: 0.8650211734605839
Validation loss: 2.687091130936281

Epoch: 6| Step: 8
Training loss: 0.5580699038249929
Validation loss: 2.653766533250138

Epoch: 6| Step: 9
Training loss: 0.4900939709950461
Validation loss: 2.674331413330482

Epoch: 6| Step: 10
Training loss: 0.4406031501709353
Validation loss: 2.7041102177665217

Epoch: 6| Step: 11
Training loss: 0.5262061953945085
Validation loss: 2.790385740018675

Epoch: 6| Step: 12
Training loss: 0.4378225125536802
Validation loss: 2.7159167979820173

Epoch: 6| Step: 13
Training loss: 0.4801782179330938
Validation loss: 2.7624132289463654

Epoch: 257| Step: 0
Training loss: 0.421522452372988
Validation loss: 2.769086420934346

Epoch: 6| Step: 1
Training loss: 0.532165607846588
Validation loss: 2.7821493373519988

Epoch: 6| Step: 2
Training loss: 0.3619093679009363
Validation loss: 2.707959256870067

Epoch: 6| Step: 3
Training loss: 0.38940680332632804
Validation loss: 2.6941777591101363

Epoch: 6| Step: 4
Training loss: 0.3389990602201753
Validation loss: 2.6635296718509833

Epoch: 6| Step: 5
Training loss: 0.814856120790113
Validation loss: 2.7130887806210433

Epoch: 6| Step: 6
Training loss: 0.9515685834517926
Validation loss: 2.723114340003016

Epoch: 6| Step: 7
Training loss: 0.6818030090161005
Validation loss: 2.6633653371779484

Epoch: 6| Step: 8
Training loss: 0.3943422072329241
Validation loss: 2.775877489074506

Epoch: 6| Step: 9
Training loss: 0.5319193942305716
Validation loss: 2.691716752506527

Epoch: 6| Step: 10
Training loss: 0.5539715673246223
Validation loss: 2.700819748778893

Epoch: 6| Step: 11
Training loss: 0.59684431486494
Validation loss: 2.7171319260854165

Epoch: 6| Step: 12
Training loss: 0.2961588302392028
Validation loss: 2.6935387713701746

Epoch: 6| Step: 13
Training loss: 0.45670164889966586
Validation loss: 2.713602535177717

Epoch: 258| Step: 0
Training loss: 0.43070212128991237
Validation loss: 2.682402322702628

Epoch: 6| Step: 1
Training loss: 0.5298196948346947
Validation loss: 2.710363820230548

Epoch: 6| Step: 2
Training loss: 0.44734324485545096
Validation loss: 2.7613964621165845

Epoch: 6| Step: 3
Training loss: 0.44910927143367135
Validation loss: 2.6927864806138637

Epoch: 6| Step: 4
Training loss: 0.5917349301390715
Validation loss: 2.704569671256276

Epoch: 6| Step: 5
Training loss: 0.5226839819423352
Validation loss: 2.64551446650276

Epoch: 6| Step: 6
Training loss: 0.44870190949821165
Validation loss: 2.754947517804382

Epoch: 6| Step: 7
Training loss: 0.4535200764440067
Validation loss: 2.753214474630264

Epoch: 6| Step: 8
Training loss: 0.511900483685947
Validation loss: 2.6586347832559905

Epoch: 6| Step: 9
Training loss: 0.3298423421550506
Validation loss: 2.7219604887532034

Epoch: 6| Step: 10
Training loss: 0.9394986464798756
Validation loss: 2.7893811212190873

Epoch: 6| Step: 11
Training loss: 0.7731025047390949
Validation loss: 2.730856595487894

Epoch: 6| Step: 12
Training loss: 0.4315421911346135
Validation loss: 2.7362506718443766

Epoch: 6| Step: 13
Training loss: 0.22816569278907206
Validation loss: 2.7083409431546235

Epoch: 259| Step: 0
Training loss: 0.44837211770247115
Validation loss: 2.659875930603114

Epoch: 6| Step: 1
Training loss: 0.3744110807758774
Validation loss: 2.731956335023664

Epoch: 6| Step: 2
Training loss: 0.30703254728552787
Validation loss: 2.697617493369556

Epoch: 6| Step: 3
Training loss: 0.39071072591441147
Validation loss: 2.6919172934032196

Epoch: 6| Step: 4
Training loss: 0.6618241452500174
Validation loss: 2.6851075708991448

Epoch: 6| Step: 5
Training loss: 0.5233980135471459
Validation loss: 2.638615974457217

Epoch: 6| Step: 6
Training loss: 0.3999612506336559
Validation loss: 2.705860260818782

Epoch: 6| Step: 7
Training loss: 0.3698809229449699
Validation loss: 2.6757712482349

Epoch: 6| Step: 8
Training loss: 0.42431380750696573
Validation loss: 2.73748711912472

Epoch: 6| Step: 9
Training loss: 0.4224288448536915
Validation loss: 2.6215842290755282

Epoch: 6| Step: 10
Training loss: 0.4431058015686338
Validation loss: 2.68707782918901

Epoch: 6| Step: 11
Training loss: 0.6056271253613478
Validation loss: 2.714885566810179

Epoch: 6| Step: 12
Training loss: 0.8168384192987574
Validation loss: 2.6639699985110226

Epoch: 6| Step: 13
Training loss: 0.4378267498542714
Validation loss: 2.6885570546867226

Epoch: 260| Step: 0
Training loss: 0.45951390663994907
Validation loss: 2.7523346152123787

Epoch: 6| Step: 1
Training loss: 0.44503037399935447
Validation loss: 2.696909378911179

Epoch: 6| Step: 2
Training loss: 0.3959630536125844
Validation loss: 2.786224759493686

Epoch: 6| Step: 3
Training loss: 0.6609841747351715
Validation loss: 2.7780579168733075

Epoch: 6| Step: 4
Training loss: 0.9910949939886564
Validation loss: 2.7175915029281557

Epoch: 6| Step: 5
Training loss: 0.6198379007827491
Validation loss: 2.777139576606861

Epoch: 6| Step: 6
Training loss: 0.37417894123790285
Validation loss: 2.71886218778574

Epoch: 6| Step: 7
Training loss: 0.43437001616548476
Validation loss: 2.725652577482949

Epoch: 6| Step: 8
Training loss: 0.45833996926907944
Validation loss: 2.697996032804302

Epoch: 6| Step: 9
Training loss: 0.45613803142813436
Validation loss: 2.699580505537611

Epoch: 6| Step: 10
Training loss: 0.4412991216512065
Validation loss: 2.7926506661637966

Epoch: 6| Step: 11
Training loss: 0.42812764800429237
Validation loss: 2.719766448736922

Epoch: 6| Step: 12
Training loss: 0.5396059862436093
Validation loss: 2.703008410341099

Epoch: 6| Step: 13
Training loss: 0.4340501222157029
Validation loss: 2.780120991925801

Epoch: 261| Step: 0
Training loss: 0.45536039054738253
Validation loss: 2.698782827210943

Epoch: 6| Step: 1
Training loss: 0.5125206931518861
Validation loss: 2.758811820057315

Epoch: 6| Step: 2
Training loss: 0.9879181688721775
Validation loss: 2.7081222941020258

Epoch: 6| Step: 3
Training loss: 0.5144031671295288
Validation loss: 2.7852103650300646

Epoch: 6| Step: 4
Training loss: 0.5629447662131906
Validation loss: 2.777876869394544

Epoch: 6| Step: 5
Training loss: 0.38854869251529484
Validation loss: 2.7933249648779865

Epoch: 6| Step: 6
Training loss: 0.44980135745407246
Validation loss: 2.7134794397718016

Epoch: 6| Step: 7
Training loss: 0.36462097881873534
Validation loss: 2.662290936830212

Epoch: 6| Step: 8
Training loss: 0.2755734263066739
Validation loss: 2.7480579512462606

Epoch: 6| Step: 9
Training loss: 0.6180339754697147
Validation loss: 2.6893574705268475

Epoch: 6| Step: 10
Training loss: 0.3415164451053468
Validation loss: 2.6290104143007285

Epoch: 6| Step: 11
Training loss: 0.5562288065955526
Validation loss: 2.7923470754480695

Epoch: 6| Step: 12
Training loss: 0.46243661433255095
Validation loss: 2.6976953265934434

Epoch: 6| Step: 13
Training loss: 0.43356034433709645
Validation loss: 2.7216482535925106

Epoch: 262| Step: 0
Training loss: 0.5255438712306268
Validation loss: 2.7005687820950186

Epoch: 6| Step: 1
Training loss: 0.3689948909439428
Validation loss: 2.725325222614833

Epoch: 6| Step: 2
Training loss: 0.9816255166788221
Validation loss: 2.70109370061732

Epoch: 6| Step: 3
Training loss: 0.5247828715779849
Validation loss: 2.7599962934063704

Epoch: 6| Step: 4
Training loss: 0.5542555188053523
Validation loss: 2.719023394814761

Epoch: 6| Step: 5
Training loss: 0.3614435990854761
Validation loss: 2.7800323306749113

Epoch: 6| Step: 6
Training loss: 0.5114706180389463
Validation loss: 2.649669274499419

Epoch: 6| Step: 7
Training loss: 0.41016961938776153
Validation loss: 2.6972065338357725

Epoch: 6| Step: 8
Training loss: 0.37469243311239475
Validation loss: 2.765488084180605

Epoch: 6| Step: 9
Training loss: 0.5823380858378973
Validation loss: 2.778695322660828

Epoch: 6| Step: 10
Training loss: 0.33139547176720663
Validation loss: 2.7827538271528023

Epoch: 6| Step: 11
Training loss: 0.36184173371784173
Validation loss: 2.734166542463252

Epoch: 6| Step: 12
Training loss: 0.34434011048954455
Validation loss: 2.7802195408122246

Epoch: 6| Step: 13
Training loss: 0.4211889445999987
Validation loss: 2.6747705188846878

Epoch: 263| Step: 0
Training loss: 0.4326790793344888
Validation loss: 2.6959351783236296

Epoch: 6| Step: 1
Training loss: 0.5381162049907284
Validation loss: 2.7690837948804767

Epoch: 6| Step: 2
Training loss: 0.32875733526915946
Validation loss: 2.7261293826909534

Epoch: 6| Step: 3
Training loss: 0.4378224955363261
Validation loss: 2.733696742632832

Epoch: 6| Step: 4
Training loss: 0.5084902715230615
Validation loss: 2.74927837845201

Epoch: 6| Step: 5
Training loss: 0.8898827655601832
Validation loss: 2.8173090192892327

Epoch: 6| Step: 6
Training loss: 0.4979243707526379
Validation loss: 2.7565596042593774

Epoch: 6| Step: 7
Training loss: 0.7887722274622732
Validation loss: 2.714338735908692

Epoch: 6| Step: 8
Training loss: 0.5075381491561912
Validation loss: 2.777611971251155

Epoch: 6| Step: 9
Training loss: 0.42087262775918416
Validation loss: 2.7136883442799355

Epoch: 6| Step: 10
Training loss: 0.3894317138969346
Validation loss: 2.749882449903329

Epoch: 6| Step: 11
Training loss: 0.6379512722995011
Validation loss: 2.636194217454068

Epoch: 6| Step: 12
Training loss: 0.4865311654547952
Validation loss: 2.6623916383043063

Epoch: 6| Step: 13
Training loss: 0.48995475849694753
Validation loss: 2.7265879822043955

Epoch: 264| Step: 0
Training loss: 0.3660556311305666
Validation loss: 2.692626196803255

Epoch: 6| Step: 1
Training loss: 0.37247597114456354
Validation loss: 2.7163250511393633

Epoch: 6| Step: 2
Training loss: 0.5006006328734216
Validation loss: 2.7480671042985807

Epoch: 6| Step: 3
Training loss: 0.48120030480959425
Validation loss: 2.710149982262236

Epoch: 6| Step: 4
Training loss: 0.4940780328604733
Validation loss: 2.661361697558321

Epoch: 6| Step: 5
Training loss: 0.9425399095903867
Validation loss: 2.6565515982749672

Epoch: 6| Step: 6
Training loss: 0.46342836202511234
Validation loss: 2.72863693531962

Epoch: 6| Step: 7
Training loss: 0.46924231425287866
Validation loss: 2.6960458393642885

Epoch: 6| Step: 8
Training loss: 0.42656541061805675
Validation loss: 2.7934066607001324

Epoch: 6| Step: 9
Training loss: 0.4391208664188917
Validation loss: 2.7255134641223444

Epoch: 6| Step: 10
Training loss: 0.5406767406951883
Validation loss: 2.6889004274476265

Epoch: 6| Step: 11
Training loss: 0.4949038796589404
Validation loss: 2.686451544770953

Epoch: 6| Step: 12
Training loss: 0.4978178806816354
Validation loss: 2.748851319475803

Epoch: 6| Step: 13
Training loss: 0.5537585148899385
Validation loss: 2.785537065934409

Epoch: 265| Step: 0
Training loss: 0.5120029388321039
Validation loss: 2.643259588858885

Epoch: 6| Step: 1
Training loss: 0.9218338456100432
Validation loss: 2.7593438180937935

Epoch: 6| Step: 2
Training loss: 0.5258458374166994
Validation loss: 2.671823646096511

Epoch: 6| Step: 3
Training loss: 0.5267374014232671
Validation loss: 2.6585348811223803

Epoch: 6| Step: 4
Training loss: 0.3503025896948849
Validation loss: 2.706085480232935

Epoch: 6| Step: 5
Training loss: 0.5848951605240668
Validation loss: 2.708686245641975

Epoch: 6| Step: 6
Training loss: 0.3579257269538925
Validation loss: 2.7462464204677195

Epoch: 6| Step: 7
Training loss: 0.36692191725650525
Validation loss: 2.6852382931140526

Epoch: 6| Step: 8
Training loss: 0.559185621501257
Validation loss: 2.710679832621041

Epoch: 6| Step: 9
Training loss: 0.4549428059189525
Validation loss: 2.690717102317518

Epoch: 6| Step: 10
Training loss: 0.35025189139994284
Validation loss: 2.7645399619645636

Epoch: 6| Step: 11
Training loss: 0.4621696329693408
Validation loss: 2.71391997137874

Epoch: 6| Step: 12
Training loss: 0.5000574853753175
Validation loss: 2.7158440738952137

Epoch: 6| Step: 13
Training loss: 0.4017555603943395
Validation loss: 2.6444563899674227

Epoch: 266| Step: 0
Training loss: 0.5349133629481688
Validation loss: 2.7418011631388395

Epoch: 6| Step: 1
Training loss: 0.5792036047026391
Validation loss: 2.730300366944968

Epoch: 6| Step: 2
Training loss: 0.4392126145777401
Validation loss: 2.670978418020949

Epoch: 6| Step: 3
Training loss: 0.55721143935333
Validation loss: 2.6508070886298705

Epoch: 6| Step: 4
Training loss: 0.3755918045101472
Validation loss: 2.774570684903022

Epoch: 6| Step: 5
Training loss: 0.4754498735555059
Validation loss: 2.7009402139198326

Epoch: 6| Step: 6
Training loss: 0.31189246726955144
Validation loss: 2.6695738507225397

Epoch: 6| Step: 7
Training loss: 0.39940147100248397
Validation loss: 2.659959626178235

Epoch: 6| Step: 8
Training loss: 0.3851584351266774
Validation loss: 2.7190302013832786

Epoch: 6| Step: 9
Training loss: 0.44039294307383564
Validation loss: 2.666475398436277

Epoch: 6| Step: 10
Training loss: 0.8055088332939164
Validation loss: 2.772405892802441

Epoch: 6| Step: 11
Training loss: 0.5126460169753619
Validation loss: 2.7413444853440163

Epoch: 6| Step: 12
Training loss: 0.5554149853832824
Validation loss: 2.667518931532908

Epoch: 6| Step: 13
Training loss: 0.4704205468099146
Validation loss: 2.7137052129174153

Epoch: 267| Step: 0
Training loss: 0.5687626721993037
Validation loss: 2.742378365883203

Epoch: 6| Step: 1
Training loss: 0.39383823602005696
Validation loss: 2.748870675521677

Epoch: 6| Step: 2
Training loss: 0.4069363591443713
Validation loss: 2.685074480528541

Epoch: 6| Step: 3
Training loss: 0.5571981749739543
Validation loss: 2.703410565354512

Epoch: 6| Step: 4
Training loss: 0.43707842610746717
Validation loss: 2.647399623962446

Epoch: 6| Step: 5
Training loss: 0.48071465751048126
Validation loss: 2.8061505312095387

Epoch: 6| Step: 6
Training loss: 0.4476774060907314
Validation loss: 2.7272459701949847

Epoch: 6| Step: 7
Training loss: 0.40116247817997386
Validation loss: 2.7952626160800738

Epoch: 6| Step: 8
Training loss: 0.4760539358660063
Validation loss: 2.718268340842594

Epoch: 6| Step: 9
Training loss: 0.45549053120428507
Validation loss: 2.7178689837294785

Epoch: 6| Step: 10
Training loss: 0.5464858714281581
Validation loss: 2.818407917904422

Epoch: 6| Step: 11
Training loss: 0.6631271282093582
Validation loss: 2.7908669555163583

Epoch: 6| Step: 12
Training loss: 0.7718457884415441
Validation loss: 2.742411047363119

Epoch: 6| Step: 13
Training loss: 0.32154295840631486
Validation loss: 2.7325015380240787

Epoch: 268| Step: 0
Training loss: 0.5661479755724887
Validation loss: 2.705193670676449

Epoch: 6| Step: 1
Training loss: 0.5626416292968438
Validation loss: 2.7063692796364296

Epoch: 6| Step: 2
Training loss: 0.30873299125200276
Validation loss: 2.680316758486194

Epoch: 6| Step: 3
Training loss: 0.4363000797557998
Validation loss: 2.6789941808331927

Epoch: 6| Step: 4
Training loss: 0.595910858454952
Validation loss: 2.74457520723817

Epoch: 6| Step: 5
Training loss: 0.2717322857398988
Validation loss: 2.7169894806751023

Epoch: 6| Step: 6
Training loss: 0.7893505514893853
Validation loss: 2.709670372584258

Epoch: 6| Step: 7
Training loss: 0.5808078530093975
Validation loss: 2.7049604736890656

Epoch: 6| Step: 8
Training loss: 0.5926017198284683
Validation loss: 2.662461904692001

Epoch: 6| Step: 9
Training loss: 0.42458758890504417
Validation loss: 2.762726624573094

Epoch: 6| Step: 10
Training loss: 0.3503749818403802
Validation loss: 2.783339354990158

Epoch: 6| Step: 11
Training loss: 0.5275993857837107
Validation loss: 2.769134033872588

Epoch: 6| Step: 12
Training loss: 0.5845385317538789
Validation loss: 2.710811762316915

Epoch: 6| Step: 13
Training loss: 0.5627163365046929
Validation loss: 2.688907557797931

Epoch: 269| Step: 0
Training loss: 0.5427064330591869
Validation loss: 2.70000358392925

Epoch: 6| Step: 1
Training loss: 0.6594109249723924
Validation loss: 2.7212998355875007

Epoch: 6| Step: 2
Training loss: 0.5514945153113241
Validation loss: 2.6455211279989164

Epoch: 6| Step: 3
Training loss: 0.5062381401556618
Validation loss: 2.75682315244648

Epoch: 6| Step: 4
Training loss: 0.515767511267447
Validation loss: 2.7594685395724845

Epoch: 6| Step: 5
Training loss: 0.45461298538455225
Validation loss: 2.709682045638793

Epoch: 6| Step: 6
Training loss: 0.5258345873052493
Validation loss: 2.722642530920272

Epoch: 6| Step: 7
Training loss: 0.40503606623901556
Validation loss: 2.6943507298386904

Epoch: 6| Step: 8
Training loss: 0.49270106573034117
Validation loss: 2.740662689703776

Epoch: 6| Step: 9
Training loss: 0.4158236100768014
Validation loss: 2.765596637472636

Epoch: 6| Step: 10
Training loss: 0.5413377264346463
Validation loss: 2.6635921059254652

Epoch: 6| Step: 11
Training loss: 0.4195829043564534
Validation loss: 2.663985638148264

Epoch: 6| Step: 12
Training loss: 0.5002729743627133
Validation loss: 2.696098544730845

Epoch: 6| Step: 13
Training loss: 0.8292777118094913
Validation loss: 2.668070592467747

Epoch: 270| Step: 0
Training loss: 0.5822055734807274
Validation loss: 2.6747284908892284

Epoch: 6| Step: 1
Training loss: 0.620458938263603
Validation loss: 2.7155242432989652

Epoch: 6| Step: 2
Training loss: 0.3985826377560842
Validation loss: 2.681946642761892

Epoch: 6| Step: 3
Training loss: 0.457314069571362
Validation loss: 2.7387882766358698

Epoch: 6| Step: 4
Training loss: 0.4017404829784013
Validation loss: 2.76590651176752

Epoch: 6| Step: 5
Training loss: 0.9346763048486791
Validation loss: 2.652672816048041

Epoch: 6| Step: 6
Training loss: 0.5629510131040775
Validation loss: 2.781793848364026

Epoch: 6| Step: 7
Training loss: 0.5829353479178168
Validation loss: 2.6755920491769625

Epoch: 6| Step: 8
Training loss: 0.32718610404371706
Validation loss: 2.7106535925048725

Epoch: 6| Step: 9
Training loss: 0.7076254186906976
Validation loss: 2.6878964922688984

Epoch: 6| Step: 10
Training loss: 0.5237464846854948
Validation loss: 2.668635183182786

Epoch: 6| Step: 11
Training loss: 0.32218186417024763
Validation loss: 2.705450255943697

Epoch: 6| Step: 12
Training loss: 0.4628441380846935
Validation loss: 2.669546291125485

Epoch: 6| Step: 13
Training loss: 0.40914920520362635
Validation loss: 2.6822714548676574

Epoch: 271| Step: 0
Training loss: 0.6374237276712623
Validation loss: 2.6806097195368337

Epoch: 6| Step: 1
Training loss: 0.8615171609985888
Validation loss: 2.704076551709979

Epoch: 6| Step: 2
Training loss: 0.5731649785465732
Validation loss: 2.727451430953864

Epoch: 6| Step: 3
Training loss: 0.4224597445897488
Validation loss: 2.713902562329421

Epoch: 6| Step: 4
Training loss: 0.4954999087811876
Validation loss: 2.756294545961975

Epoch: 6| Step: 5
Training loss: 0.5406869378744557
Validation loss: 2.7290016493279197

Epoch: 6| Step: 6
Training loss: 0.4312125797898757
Validation loss: 2.6943273466977296

Epoch: 6| Step: 7
Training loss: 0.4328139398048222
Validation loss: 2.721863670048161

Epoch: 6| Step: 8
Training loss: 0.6142910704228727
Validation loss: 2.658351022388436

Epoch: 6| Step: 9
Training loss: 0.3931349037147994
Validation loss: 2.7325531621463273

Epoch: 6| Step: 10
Training loss: 0.36345947159849806
Validation loss: 2.779230141570164

Epoch: 6| Step: 11
Training loss: 0.6342430898389941
Validation loss: 2.652512947120432

Epoch: 6| Step: 12
Training loss: 0.4761588779393718
Validation loss: 2.738092260872464

Epoch: 6| Step: 13
Training loss: 0.34507407592166617
Validation loss: 2.666371423549947

Epoch: 272| Step: 0
Training loss: 0.447774955229794
Validation loss: 2.7133453698402885

Epoch: 6| Step: 1
Training loss: 0.5133261732070663
Validation loss: 2.6986756429342336

Epoch: 6| Step: 2
Training loss: 0.5069272468065216
Validation loss: 2.742030205340676

Epoch: 6| Step: 3
Training loss: 0.5849875824580352
Validation loss: 2.705436012656762

Epoch: 6| Step: 4
Training loss: 0.347431152851219
Validation loss: 2.733748242436248

Epoch: 6| Step: 5
Training loss: 0.7224079839724638
Validation loss: 2.8070939913896487

Epoch: 6| Step: 6
Training loss: 0.6049332742702082
Validation loss: 2.687049118189322

Epoch: 6| Step: 7
Training loss: 0.39476412330642285
Validation loss: 2.7286202900571945

Epoch: 6| Step: 8
Training loss: 0.497167356719624
Validation loss: 2.6978998564168215

Epoch: 6| Step: 9
Training loss: 0.40752654153007983
Validation loss: 2.66224601023658

Epoch: 6| Step: 10
Training loss: 0.4977493594274226
Validation loss: 2.7431999069303776

Epoch: 6| Step: 11
Training loss: 0.5391274565108525
Validation loss: 2.719242942816566

Epoch: 6| Step: 12
Training loss: 0.45462204832409453
Validation loss: 2.694535118447544

Epoch: 6| Step: 13
Training loss: 0.3780004942653593
Validation loss: 2.692272192769883

Epoch: 273| Step: 0
Training loss: 0.44491167601030895
Validation loss: 2.7123069638828516

Epoch: 6| Step: 1
Training loss: 0.7664330169638701
Validation loss: 2.7128581811124324

Epoch: 6| Step: 2
Training loss: 0.4826299859406648
Validation loss: 2.698479145776418

Epoch: 6| Step: 3
Training loss: 0.35694851824533974
Validation loss: 2.619376850593245

Epoch: 6| Step: 4
Training loss: 0.4985162953723632
Validation loss: 2.6434324490155103

Epoch: 6| Step: 5
Training loss: 0.3949020078889598
Validation loss: 2.7052911300434994

Epoch: 6| Step: 6
Training loss: 0.3772645563144837
Validation loss: 2.750818983138993

Epoch: 6| Step: 7
Training loss: 0.3914000261310652
Validation loss: 2.685760866829382

Epoch: 6| Step: 8
Training loss: 0.44622184531033715
Validation loss: 2.7213109403885403

Epoch: 6| Step: 9
Training loss: 0.41515739997816486
Validation loss: 2.703537521784387

Epoch: 6| Step: 10
Training loss: 0.40751317684540606
Validation loss: 2.7399990336910687

Epoch: 6| Step: 11
Training loss: 0.5477869604308053
Validation loss: 2.7352673918142054

Epoch: 6| Step: 12
Training loss: 0.3042507219878057
Validation loss: 2.673442804452794

Epoch: 6| Step: 13
Training loss: 0.495893993861094
Validation loss: 2.6808176576841665

Epoch: 274| Step: 0
Training loss: 0.8109443884760944
Validation loss: 2.766596470846205

Epoch: 6| Step: 1
Training loss: 0.46656329004791885
Validation loss: 2.684104215666632

Epoch: 6| Step: 2
Training loss: 0.4916065359792308
Validation loss: 2.756894211801257

Epoch: 6| Step: 3
Training loss: 0.4133813942217737
Validation loss: 2.651223591755865

Epoch: 6| Step: 4
Training loss: 0.4992438947288072
Validation loss: 2.724135782699426

Epoch: 6| Step: 5
Training loss: 0.41882446964876785
Validation loss: 2.701234660013124

Epoch: 6| Step: 6
Training loss: 0.39656907853966944
Validation loss: 2.7316221930712383

Epoch: 6| Step: 7
Training loss: 0.5944894402498955
Validation loss: 2.7615520565475373

Epoch: 6| Step: 8
Training loss: 0.42237284214025134
Validation loss: 2.702994135810869

Epoch: 6| Step: 9
Training loss: 0.3823564498781372
Validation loss: 2.6554873250453985

Epoch: 6| Step: 10
Training loss: 0.45166378535281865
Validation loss: 2.6864792711423906

Epoch: 6| Step: 11
Training loss: 0.31899981059394644
Validation loss: 2.733402115452636

Epoch: 6| Step: 12
Training loss: 0.37926336547042705
Validation loss: 2.660022061885084

Epoch: 6| Step: 13
Training loss: 0.5493021916563631
Validation loss: 2.699341995215311

Epoch: 275| Step: 0
Training loss: 0.35593321083438517
Validation loss: 2.6802318083210372

Epoch: 6| Step: 1
Training loss: 0.40404559817739916
Validation loss: 2.6861772239037203

Epoch: 6| Step: 2
Training loss: 0.4342938175769722
Validation loss: 2.6843993908592263

Epoch: 6| Step: 3
Training loss: 0.46186546086125213
Validation loss: 2.6706147967916696

Epoch: 6| Step: 4
Training loss: 0.4192678281625022
Validation loss: 2.6785646538421695

Epoch: 6| Step: 5
Training loss: 0.5121745634743625
Validation loss: 2.6899919563419

Epoch: 6| Step: 6
Training loss: 0.44887552832729316
Validation loss: 2.8024059922929703

Epoch: 6| Step: 7
Training loss: 0.4246713363232525
Validation loss: 2.7188866752675604

Epoch: 6| Step: 8
Training loss: 0.47419614030963825
Validation loss: 2.730311151339507

Epoch: 6| Step: 9
Training loss: 0.34115041360862175
Validation loss: 2.6517482832602806

Epoch: 6| Step: 10
Training loss: 0.355395865042197
Validation loss: 2.751419004720205

Epoch: 6| Step: 11
Training loss: 0.8177268923133475
Validation loss: 2.7148110367155636

Epoch: 6| Step: 12
Training loss: 0.4655441169125739
Validation loss: 2.680761820730952

Epoch: 6| Step: 13
Training loss: 0.27652234685763305
Validation loss: 2.65267798406381

Epoch: 276| Step: 0
Training loss: 0.3032874193305958
Validation loss: 2.6972912882238433

Epoch: 6| Step: 1
Training loss: 0.5718811618493813
Validation loss: 2.6648234961284376

Epoch: 6| Step: 2
Training loss: 0.36564525401429765
Validation loss: 2.689461591010527

Epoch: 6| Step: 3
Training loss: 0.5297065922719936
Validation loss: 2.6351686343352445

Epoch: 6| Step: 4
Training loss: 0.46350991393929747
Validation loss: 2.6949793439249263

Epoch: 6| Step: 5
Training loss: 0.7685563161364971
Validation loss: 2.701892505653458

Epoch: 6| Step: 6
Training loss: 0.4165908883645854
Validation loss: 2.6702324054834676

Epoch: 6| Step: 7
Training loss: 0.48730387716283297
Validation loss: 2.7085943658676013

Epoch: 6| Step: 8
Training loss: 0.4444059044383477
Validation loss: 2.6910575784798185

Epoch: 6| Step: 9
Training loss: 0.40381693341316455
Validation loss: 2.6854866233771424

Epoch: 6| Step: 10
Training loss: 0.5084245954211165
Validation loss: 2.7705055893880237

Epoch: 6| Step: 11
Training loss: 0.52536509852458
Validation loss: 2.6649734714516495

Epoch: 6| Step: 12
Training loss: 0.4281631828600459
Validation loss: 2.690594673059668

Epoch: 6| Step: 13
Training loss: 0.47343491027929485
Validation loss: 2.74907784461776

Epoch: 277| Step: 0
Training loss: 0.420458198310065
Validation loss: 2.714497496115597

Epoch: 6| Step: 1
Training loss: 0.460870527800839
Validation loss: 2.807313573370808

Epoch: 6| Step: 2
Training loss: 0.5315154758669255
Validation loss: 2.7038231831859187

Epoch: 6| Step: 3
Training loss: 0.46078666546712416
Validation loss: 2.722847069393477

Epoch: 6| Step: 4
Training loss: 0.37828721279280486
Validation loss: 2.7548289888179878

Epoch: 6| Step: 5
Training loss: 0.4891017733517782
Validation loss: 2.729899494896828

Epoch: 6| Step: 6
Training loss: 0.4617171724812108
Validation loss: 2.6883915376087595

Epoch: 6| Step: 7
Training loss: 0.41903486384010447
Validation loss: 2.7066119861560347

Epoch: 6| Step: 8
Training loss: 0.4929818298248994
Validation loss: 2.6807177373240885

Epoch: 6| Step: 9
Training loss: 0.43039270965187637
Validation loss: 2.6571530172219213

Epoch: 6| Step: 10
Training loss: 0.46974055215857125
Validation loss: 2.6706152431655896

Epoch: 6| Step: 11
Training loss: 0.9134797088653686
Validation loss: 2.6169458078408

Epoch: 6| Step: 12
Training loss: 0.5518481425384814
Validation loss: 2.737633251622429

Epoch: 6| Step: 13
Training loss: 0.2541512847503559
Validation loss: 2.7530220361768287

Epoch: 278| Step: 0
Training loss: 0.5692603452041501
Validation loss: 2.6902968469076423

Epoch: 6| Step: 1
Training loss: 0.46110696425290376
Validation loss: 2.7091147884852975

Epoch: 6| Step: 2
Training loss: 0.6134541261803309
Validation loss: 2.7478960832273676

Epoch: 6| Step: 3
Training loss: 0.31607766220328176
Validation loss: 2.7193875350902887

Epoch: 6| Step: 4
Training loss: 0.3417683289732714
Validation loss: 2.6299251416531537

Epoch: 6| Step: 5
Training loss: 0.5394371223700312
Validation loss: 2.7102755160648804

Epoch: 6| Step: 6
Training loss: 0.375175097435749
Validation loss: 2.7125763130879594

Epoch: 6| Step: 7
Training loss: 0.47989483803884
Validation loss: 2.6968009487695874

Epoch: 6| Step: 8
Training loss: 0.569847989015578
Validation loss: 2.7731852457011943

Epoch: 6| Step: 9
Training loss: 0.35557862564375525
Validation loss: 2.7100164367674684

Epoch: 6| Step: 10
Training loss: 0.8375452926117225
Validation loss: 2.7367222765508608

Epoch: 6| Step: 11
Training loss: 0.5075075260788178
Validation loss: 2.7092179809853176

Epoch: 6| Step: 12
Training loss: 0.502670310087348
Validation loss: 2.711181864136594

Epoch: 6| Step: 13
Training loss: 0.5552105385293402
Validation loss: 2.6966952329198466

Epoch: 279| Step: 0
Training loss: 0.4153543688276506
Validation loss: 2.72639349675082

Epoch: 6| Step: 1
Training loss: 0.38705306581900073
Validation loss: 2.669526434345049

Epoch: 6| Step: 2
Training loss: 0.5034432760957459
Validation loss: 2.6835930540629023

Epoch: 6| Step: 3
Training loss: 0.39748245668385096
Validation loss: 2.713238079834419

Epoch: 6| Step: 4
Training loss: 0.45698850382904843
Validation loss: 2.743564676501194

Epoch: 6| Step: 5
Training loss: 0.3732059598914479
Validation loss: 2.6332485241652974

Epoch: 6| Step: 6
Training loss: 0.5639980554090619
Validation loss: 2.6775057171244985

Epoch: 6| Step: 7
Training loss: 0.7889788366097487
Validation loss: 2.7127263948857667

Epoch: 6| Step: 8
Training loss: 0.47550336994417014
Validation loss: 2.677785281665026

Epoch: 6| Step: 9
Training loss: 0.3143309598755925
Validation loss: 2.729196771547876

Epoch: 6| Step: 10
Training loss: 0.43460868066008473
Validation loss: 2.7384940521368804

Epoch: 6| Step: 11
Training loss: 0.3588819230985392
Validation loss: 2.7297664352151876

Epoch: 6| Step: 12
Training loss: 0.4077198142473967
Validation loss: 2.7020380116830705

Epoch: 6| Step: 13
Training loss: 0.333010989534767
Validation loss: 2.7641383196443226

Epoch: 280| Step: 0
Training loss: 0.4804295159424971
Validation loss: 2.7852780216057105

Epoch: 6| Step: 1
Training loss: 0.4456093284076953
Validation loss: 2.712356298715649

Epoch: 6| Step: 2
Training loss: 0.35326889026588376
Validation loss: 2.7234674501331595

Epoch: 6| Step: 3
Training loss: 0.5020450849196939
Validation loss: 2.745593572133216

Epoch: 6| Step: 4
Training loss: 0.442544027767498
Validation loss: 2.643863325042411

Epoch: 6| Step: 5
Training loss: 0.2792635410930935
Validation loss: 2.7126065557033368

Epoch: 6| Step: 6
Training loss: 0.7816039999979563
Validation loss: 2.6851659072230243

Epoch: 6| Step: 7
Training loss: 0.44950021964843273
Validation loss: 2.753783816238033

Epoch: 6| Step: 8
Training loss: 0.5051905212670675
Validation loss: 2.627425719226569

Epoch: 6| Step: 9
Training loss: 0.4810797675127416
Validation loss: 2.7865674339160345

Epoch: 6| Step: 10
Training loss: 0.5091238842152808
Validation loss: 2.7220017144905277

Epoch: 6| Step: 11
Training loss: 0.4620335688450573
Validation loss: 2.741283735145095

Epoch: 6| Step: 12
Training loss: 0.4734657700914239
Validation loss: 2.695876514928169

Epoch: 6| Step: 13
Training loss: 0.4427457419653261
Validation loss: 2.760374591914598

Epoch: 281| Step: 0
Training loss: 0.37107557954974896
Validation loss: 2.7008206609679557

Epoch: 6| Step: 1
Training loss: 0.427263427382757
Validation loss: 2.7381312700629525

Epoch: 6| Step: 2
Training loss: 0.4262303425012092
Validation loss: 2.7589760794027214

Epoch: 6| Step: 3
Training loss: 0.36184992873025223
Validation loss: 2.757851604872437

Epoch: 6| Step: 4
Training loss: 0.35213367898812553
Validation loss: 2.6818332663123106

Epoch: 6| Step: 5
Training loss: 0.4346875150558502
Validation loss: 2.7679018752413826

Epoch: 6| Step: 6
Training loss: 0.5366468345292831
Validation loss: 2.6550760854055

Epoch: 6| Step: 7
Training loss: 0.41921735702891755
Validation loss: 2.69697933532998

Epoch: 6| Step: 8
Training loss: 0.6861922440605054
Validation loss: 2.7255446930802036

Epoch: 6| Step: 9
Training loss: 0.5553808848318035
Validation loss: 2.6650562316110373

Epoch: 6| Step: 10
Training loss: 0.3290359476938677
Validation loss: 2.6273925640597704

Epoch: 6| Step: 11
Training loss: 0.44640387262412967
Validation loss: 2.7670980076074536

Epoch: 6| Step: 12
Training loss: 0.4811253287100419
Validation loss: 2.754014552807224

Epoch: 6| Step: 13
Training loss: 0.3865391092462876
Validation loss: 2.6878533020222353

Epoch: 282| Step: 0
Training loss: 0.39403612397972004
Validation loss: 2.6879069145931256

Epoch: 6| Step: 1
Training loss: 0.38381622063057613
Validation loss: 2.690017725887298

Epoch: 6| Step: 2
Training loss: 0.3894748348815811
Validation loss: 2.708851571507535

Epoch: 6| Step: 3
Training loss: 0.41195972491598054
Validation loss: 2.7136654938446663

Epoch: 6| Step: 4
Training loss: 0.3883158716312974
Validation loss: 2.736807150233846

Epoch: 6| Step: 5
Training loss: 0.4302219881318399
Validation loss: 2.6640699429375423

Epoch: 6| Step: 6
Training loss: 0.38634544233460455
Validation loss: 2.721858691791858

Epoch: 6| Step: 7
Training loss: 0.5447660654105329
Validation loss: 2.6816801293767965

Epoch: 6| Step: 8
Training loss: 0.3902106758077236
Validation loss: 2.684588651847712

Epoch: 6| Step: 9
Training loss: 0.6005223186261706
Validation loss: 2.6790935721939544

Epoch: 6| Step: 10
Training loss: 0.7312636512721071
Validation loss: 2.6745932659014855

Epoch: 6| Step: 11
Training loss: 0.35461646389562285
Validation loss: 2.637006458550863

Epoch: 6| Step: 12
Training loss: 0.4106969992630879
Validation loss: 2.6763407101463184

Epoch: 6| Step: 13
Training loss: 0.500696769646642
Validation loss: 2.688336589627581

Epoch: 283| Step: 0
Training loss: 0.4735399135445823
Validation loss: 2.665377369775309

Epoch: 6| Step: 1
Training loss: 0.2500560220891399
Validation loss: 2.6954100955118996

Epoch: 6| Step: 2
Training loss: 0.35217994934016783
Validation loss: 2.683098596963827

Epoch: 6| Step: 3
Training loss: 0.7025242040068796
Validation loss: 2.738798403733679

Epoch: 6| Step: 4
Training loss: 0.6607692287864303
Validation loss: 2.6452263764183184

Epoch: 6| Step: 5
Training loss: 0.28843233651512423
Validation loss: 2.698130261620269

Epoch: 6| Step: 6
Training loss: 0.43841499627044134
Validation loss: 2.6772698858153494

Epoch: 6| Step: 7
Training loss: 0.3985665243339545
Validation loss: 2.747856518538071

Epoch: 6| Step: 8
Training loss: 0.5352779723354414
Validation loss: 2.713286116288399

Epoch: 6| Step: 9
Training loss: 0.3783534628740762
Validation loss: 2.6925309797327075

Epoch: 6| Step: 10
Training loss: 0.36872264873772204
Validation loss: 2.7782112265537267

Epoch: 6| Step: 11
Training loss: 0.47180557940318363
Validation loss: 2.778105983947964

Epoch: 6| Step: 12
Training loss: 0.3800508181572815
Validation loss: 2.6783557693010165

Epoch: 6| Step: 13
Training loss: 0.4454122398175512
Validation loss: 2.7384392461031486

Epoch: 284| Step: 0
Training loss: 0.4515161563099094
Validation loss: 2.7052310464282767

Epoch: 6| Step: 1
Training loss: 0.5622309995216558
Validation loss: 2.6731477423963934

Epoch: 6| Step: 2
Training loss: 0.4469028984377874
Validation loss: 2.642674149495273

Epoch: 6| Step: 3
Training loss: 0.47529522668174023
Validation loss: 2.719470326962127

Epoch: 6| Step: 4
Training loss: 0.40060112234840156
Validation loss: 2.7586299271949577

Epoch: 6| Step: 5
Training loss: 0.33326170072168165
Validation loss: 2.6840052393309257

Epoch: 6| Step: 6
Training loss: 0.48226978823621225
Validation loss: 2.766430006667651

Epoch: 6| Step: 7
Training loss: 0.46560231992030526
Validation loss: 2.7640049961650353

Epoch: 6| Step: 8
Training loss: 0.7915676498396164
Validation loss: 2.7247542002116716

Epoch: 6| Step: 9
Training loss: 0.3606512172894208
Validation loss: 2.7369983114679397

Epoch: 6| Step: 10
Training loss: 0.47109971809718865
Validation loss: 2.7654023880096834

Epoch: 6| Step: 11
Training loss: 0.30025895088854837
Validation loss: 2.7483376044415038

Epoch: 6| Step: 12
Training loss: 0.3472982234694388
Validation loss: 2.755078481535981

Epoch: 6| Step: 13
Training loss: 0.4126856241745399
Validation loss: 2.742361546831914

Epoch: 285| Step: 0
Training loss: 0.8702651046914929
Validation loss: 2.7044764908948755

Epoch: 6| Step: 1
Training loss: 0.2686655127994151
Validation loss: 2.6985455863729992

Epoch: 6| Step: 2
Training loss: 0.4876269266979855
Validation loss: 2.6823485482613445

Epoch: 6| Step: 3
Training loss: 0.4178789701920764
Validation loss: 2.750839683188716

Epoch: 6| Step: 4
Training loss: 0.6712285857807321
Validation loss: 2.7560770411586573

Epoch: 6| Step: 5
Training loss: 0.3337272635941306
Validation loss: 2.681634475541664

Epoch: 6| Step: 6
Training loss: 0.49892225938122553
Validation loss: 2.661375956495347

Epoch: 6| Step: 7
Training loss: 0.5270866332371763
Validation loss: 2.6944186880141294

Epoch: 6| Step: 8
Training loss: 0.45228393370022507
Validation loss: 2.65353711285804

Epoch: 6| Step: 9
Training loss: 0.47558639181691115
Validation loss: 2.7477506194559544

Epoch: 6| Step: 10
Training loss: 0.3403292618889242
Validation loss: 2.6685842136463047

Epoch: 6| Step: 11
Training loss: 0.5684508679345328
Validation loss: 2.7056453913378986

Epoch: 6| Step: 12
Training loss: 0.2709347217245773
Validation loss: 2.763807040482396

Epoch: 6| Step: 13
Training loss: 0.3477770670436077
Validation loss: 2.7522930497556386

Epoch: 286| Step: 0
Training loss: 0.45337683158106984
Validation loss: 2.795554064026889

Epoch: 6| Step: 1
Training loss: 0.46487667063335697
Validation loss: 2.7408833459165214

Epoch: 6| Step: 2
Training loss: 0.4468694539826374
Validation loss: 2.7755072665597313

Epoch: 6| Step: 3
Training loss: 0.45969516016466416
Validation loss: 2.7806795371004758

Epoch: 6| Step: 4
Training loss: 0.5809657181016448
Validation loss: 2.814588308341719

Epoch: 6| Step: 5
Training loss: 0.30904981255404507
Validation loss: 2.7267907310356656

Epoch: 6| Step: 6
Training loss: 0.5080219423762873
Validation loss: 2.6955255544002252

Epoch: 6| Step: 7
Training loss: 0.448388800817814
Validation loss: 2.686867543402653

Epoch: 6| Step: 8
Training loss: 0.40426549006470053
Validation loss: 2.737899180416296

Epoch: 6| Step: 9
Training loss: 0.46859169512149024
Validation loss: 2.682601500952385

Epoch: 6| Step: 10
Training loss: 0.7848370790587278
Validation loss: 2.711457978486839

Epoch: 6| Step: 11
Training loss: 0.3862541953417635
Validation loss: 2.7991087320965984

Epoch: 6| Step: 12
Training loss: 0.32196158892533766
Validation loss: 2.7400783096502086

Epoch: 6| Step: 13
Training loss: 0.37247525104130447
Validation loss: 2.6789587381181996

Epoch: 287| Step: 0
Training loss: 0.45692196378931066
Validation loss: 2.706185455081153

Epoch: 6| Step: 1
Training loss: 0.38280662220704786
Validation loss: 2.7733494131221206

Epoch: 6| Step: 2
Training loss: 0.39160953427997847
Validation loss: 2.721713938803811

Epoch: 6| Step: 3
Training loss: 0.3610719339605171
Validation loss: 2.7712365815476305

Epoch: 6| Step: 4
Training loss: 0.35561367895144186
Validation loss: 2.654589264750846

Epoch: 6| Step: 5
Training loss: 0.7509365591994991
Validation loss: 2.7210417329348977

Epoch: 6| Step: 6
Training loss: 0.37248783264513985
Validation loss: 2.7387301684238587

Epoch: 6| Step: 7
Training loss: 0.37601805618993395
Validation loss: 2.770468556382933

Epoch: 6| Step: 8
Training loss: 0.5602318014485556
Validation loss: 2.671830725349507

Epoch: 6| Step: 9
Training loss: 0.46267701704987535
Validation loss: 2.74226932820155

Epoch: 6| Step: 10
Training loss: 0.44528445774593245
Validation loss: 2.7289430196625437

Epoch: 6| Step: 11
Training loss: 0.38728285596667383
Validation loss: 2.7326107909650954

Epoch: 6| Step: 12
Training loss: 0.5143090708997604
Validation loss: 2.7047086718175226

Epoch: 6| Step: 13
Training loss: 0.46058190093666956
Validation loss: 2.7870573641783376

Epoch: 288| Step: 0
Training loss: 0.41927827706057397
Validation loss: 2.6406444119975743

Epoch: 6| Step: 1
Training loss: 0.7228698002540667
Validation loss: 2.607540422237808

Epoch: 6| Step: 2
Training loss: 0.4737641929020305
Validation loss: 2.6913740860226407

Epoch: 6| Step: 3
Training loss: 0.5374025689023555
Validation loss: 2.687445144684913

Epoch: 6| Step: 4
Training loss: 0.42303977107937085
Validation loss: 2.7263015724235333

Epoch: 6| Step: 5
Training loss: 0.49691885568702887
Validation loss: 2.7051468052046723

Epoch: 6| Step: 6
Training loss: 0.37796702434623686
Validation loss: 2.733745495223136

Epoch: 6| Step: 7
Training loss: 0.34290956581770166
Validation loss: 2.6845875713246454

Epoch: 6| Step: 8
Training loss: 0.4545072158800905
Validation loss: 2.665695100364175

Epoch: 6| Step: 9
Training loss: 0.5644752471707032
Validation loss: 2.730657728328952

Epoch: 6| Step: 10
Training loss: 0.4084679506562701
Validation loss: 2.682440645592834

Epoch: 6| Step: 11
Training loss: 0.42373765252277507
Validation loss: 2.6881651240126465

Epoch: 6| Step: 12
Training loss: 0.420345678048111
Validation loss: 2.680663365802315

Epoch: 6| Step: 13
Training loss: 0.3185152011818928
Validation loss: 2.660761424055792

Epoch: 289| Step: 0
Training loss: 0.295315776282004
Validation loss: 2.728781568618674

Epoch: 6| Step: 1
Training loss: 0.39855042895455634
Validation loss: 2.6941223760429924

Epoch: 6| Step: 2
Training loss: 0.46295532546984475
Validation loss: 2.6515799514894565

Epoch: 6| Step: 3
Training loss: 0.4888535159702984
Validation loss: 2.679539742209881

Epoch: 6| Step: 4
Training loss: 0.5015915930560617
Validation loss: 2.780400421454886

Epoch: 6| Step: 5
Training loss: 0.48253898897913916
Validation loss: 2.7176328607394664

Epoch: 6| Step: 6
Training loss: 0.3279843710222908
Validation loss: 2.687979455806924

Epoch: 6| Step: 7
Training loss: 0.3841964268104191
Validation loss: 2.770265095508313

Epoch: 6| Step: 8
Training loss: 0.48007834475630967
Validation loss: 2.664360782932259

Epoch: 6| Step: 9
Training loss: 0.7903194047981451
Validation loss: 2.7731433551241915

Epoch: 6| Step: 10
Training loss: 0.40416982746199204
Validation loss: 2.678577219033416

Epoch: 6| Step: 11
Training loss: 0.36210330600035245
Validation loss: 2.6835325586708185

Epoch: 6| Step: 12
Training loss: 0.46047505926153254
Validation loss: 2.7359753748234503

Epoch: 6| Step: 13
Training loss: 0.48519921166327634
Validation loss: 2.7907635997885207

Epoch: 290| Step: 0
Training loss: 0.4306528864165114
Validation loss: 2.7016725404861046

Epoch: 6| Step: 1
Training loss: 0.6031774913102533
Validation loss: 2.746146934576679

Epoch: 6| Step: 2
Training loss: 0.2745850054372102
Validation loss: 2.77487053898517

Epoch: 6| Step: 3
Training loss: 0.5418001951791124
Validation loss: 2.751638950005753

Epoch: 6| Step: 4
Training loss: 0.19101313684945356
Validation loss: 2.761519292223104

Epoch: 6| Step: 5
Training loss: 0.427267996090385
Validation loss: 2.7326372710216043

Epoch: 6| Step: 6
Training loss: 0.37866356540107315
Validation loss: 2.7039791808257982

Epoch: 6| Step: 7
Training loss: 0.3685357117733364
Validation loss: 2.704536077035316

Epoch: 6| Step: 8
Training loss: 0.5794361813863201
Validation loss: 2.8235712078490005

Epoch: 6| Step: 9
Training loss: 0.41199495435606487
Validation loss: 2.759889391557862

Epoch: 6| Step: 10
Training loss: 0.7733948435724689
Validation loss: 2.6964523632572246

Epoch: 6| Step: 11
Training loss: 0.31480710026902387
Validation loss: 2.704753275070937

Epoch: 6| Step: 12
Training loss: 0.3770776651634372
Validation loss: 2.7316386527540706

Epoch: 6| Step: 13
Training loss: 0.6281223505827792
Validation loss: 2.660266845913636

Epoch: 291| Step: 0
Training loss: 0.6734842722287573
Validation loss: 2.7306483422967753

Epoch: 6| Step: 1
Training loss: 0.4251638363151196
Validation loss: 2.715754660323005

Epoch: 6| Step: 2
Training loss: 0.3938987118076509
Validation loss: 2.7164662295004214

Epoch: 6| Step: 3
Training loss: 0.3771852954335486
Validation loss: 2.620049364726613

Epoch: 6| Step: 4
Training loss: 0.26751928308986067
Validation loss: 2.743576451564643

Epoch: 6| Step: 5
Training loss: 0.37202749731869983
Validation loss: 2.7358489941061506

Epoch: 6| Step: 6
Training loss: 0.4269453461576222
Validation loss: 2.747299038355543

Epoch: 6| Step: 7
Training loss: 0.5536024199217898
Validation loss: 2.666963252820049

Epoch: 6| Step: 8
Training loss: 0.3905996695888702
Validation loss: 2.766265220318669

Epoch: 6| Step: 9
Training loss: 0.38033736229957144
Validation loss: 2.7753060364008113

Epoch: 6| Step: 10
Training loss: 0.5658482664166833
Validation loss: 2.702054747168262

Epoch: 6| Step: 11
Training loss: 0.41101458519095485
Validation loss: 2.6959579358399193

Epoch: 6| Step: 12
Training loss: 0.5200394747496112
Validation loss: 2.6688394089312815

Epoch: 6| Step: 13
Training loss: 0.5799146222711067
Validation loss: 2.6431097645717756

Epoch: 292| Step: 0
Training loss: 0.4981335433648519
Validation loss: 2.6585388494789086

Epoch: 6| Step: 1
Training loss: 0.4217479832493038
Validation loss: 2.703080208173907

Epoch: 6| Step: 2
Training loss: 0.48674979562466114
Validation loss: 2.695892905432491

Epoch: 6| Step: 3
Training loss: 0.3521146147655286
Validation loss: 2.7388055855353626

Epoch: 6| Step: 4
Training loss: 0.4023451203258104
Validation loss: 2.6994520161111173

Epoch: 6| Step: 5
Training loss: 0.5569883364803737
Validation loss: 2.706515176304513

Epoch: 6| Step: 6
Training loss: 0.4126698989373101
Validation loss: 2.6849231194417893

Epoch: 6| Step: 7
Training loss: 0.5051565700899309
Validation loss: 2.748955831831333

Epoch: 6| Step: 8
Training loss: 0.6412925963354676
Validation loss: 2.7236711971933274

Epoch: 6| Step: 9
Training loss: 0.3156422940794485
Validation loss: 2.6426921706155855

Epoch: 6| Step: 10
Training loss: 0.42245237259773644
Validation loss: 2.5665496368067284

Epoch: 6| Step: 11
Training loss: 0.440097929178613
Validation loss: 2.703067859788086

Epoch: 6| Step: 12
Training loss: 0.5822445267468788
Validation loss: 2.6902585103803403

Epoch: 6| Step: 13
Training loss: 0.5130719064246863
Validation loss: 2.7942114281835293

Epoch: 293| Step: 0
Training loss: 0.3975441772875573
Validation loss: 2.7555295808612144

Epoch: 6| Step: 1
Training loss: 0.4198894931816428
Validation loss: 2.7392153232880805

Epoch: 6| Step: 2
Training loss: 0.4482463429243831
Validation loss: 2.678983175026714

Epoch: 6| Step: 3
Training loss: 0.4959267012124128
Validation loss: 2.7869463246695934

Epoch: 6| Step: 4
Training loss: 0.47687159348317315
Validation loss: 2.73782132903241

Epoch: 6| Step: 5
Training loss: 0.3376198494005294
Validation loss: 2.721653458535389

Epoch: 6| Step: 6
Training loss: 0.42879966564957195
Validation loss: 2.717121718233575

Epoch: 6| Step: 7
Training loss: 0.46348006307033096
Validation loss: 2.8193546264155858

Epoch: 6| Step: 8
Training loss: 0.7638277250907095
Validation loss: 2.7038289147704813

Epoch: 6| Step: 9
Training loss: 0.48871663328456716
Validation loss: 2.637813561227687

Epoch: 6| Step: 10
Training loss: 0.42548479031051567
Validation loss: 2.685810874216184

Epoch: 6| Step: 11
Training loss: 0.31152979924991764
Validation loss: 2.7058310662406853

Epoch: 6| Step: 12
Training loss: 0.3712843556033021
Validation loss: 2.6727618554452732

Epoch: 6| Step: 13
Training loss: 0.3515989284715501
Validation loss: 2.7048495309690916

Epoch: 294| Step: 0
Training loss: 0.7514837608410243
Validation loss: 2.727102603266287

Epoch: 6| Step: 1
Training loss: 0.5342095626482878
Validation loss: 2.7585430024278748

Epoch: 6| Step: 2
Training loss: 0.3733204941620903
Validation loss: 2.638866290335905

Epoch: 6| Step: 3
Training loss: 0.45091965466227657
Validation loss: 2.823341497194031

Epoch: 6| Step: 4
Training loss: 0.33703941556388095
Validation loss: 2.7395446300794486

Epoch: 6| Step: 5
Training loss: 0.36600881466387064
Validation loss: 2.774106843081217

Epoch: 6| Step: 6
Training loss: 0.4758261635914372
Validation loss: 2.702909692557601

Epoch: 6| Step: 7
Training loss: 0.35845075843854246
Validation loss: 2.6786366469905447

Epoch: 6| Step: 8
Training loss: 0.4453560322682027
Validation loss: 2.7133620355839123

Epoch: 6| Step: 9
Training loss: 0.4835328811029262
Validation loss: 2.762353201025234

Epoch: 6| Step: 10
Training loss: 0.4031371284848641
Validation loss: 2.7397538677171682

Epoch: 6| Step: 11
Training loss: 0.5176295704735409
Validation loss: 2.664482061287425

Epoch: 6| Step: 12
Training loss: 0.28631924229019345
Validation loss: 2.7660456766709207

Epoch: 6| Step: 13
Training loss: 0.4608504811276034
Validation loss: 2.697581536725613

Epoch: 295| Step: 0
Training loss: 0.5434381116673875
Validation loss: 2.7043800527456225

Epoch: 6| Step: 1
Training loss: 0.623719333819849
Validation loss: 2.754540105790283

Epoch: 6| Step: 2
Training loss: 0.4042782433681024
Validation loss: 2.7684466233824225

Epoch: 6| Step: 3
Training loss: 0.4460438194323917
Validation loss: 2.6968110861927315

Epoch: 6| Step: 4
Training loss: 0.6727916541371725
Validation loss: 2.65220699416556

Epoch: 6| Step: 5
Training loss: 0.3813590464435637
Validation loss: 2.701268148189166

Epoch: 6| Step: 6
Training loss: 0.4764652934759339
Validation loss: 2.76326211827969

Epoch: 6| Step: 7
Training loss: 0.4662448699709858
Validation loss: 2.72974190704155

Epoch: 6| Step: 8
Training loss: 0.503805934176567
Validation loss: 2.7289500017041624

Epoch: 6| Step: 9
Training loss: 0.5190011668844464
Validation loss: 2.747436224232248

Epoch: 6| Step: 10
Training loss: 0.46025451880272
Validation loss: 2.6946634441748443

Epoch: 6| Step: 11
Training loss: 0.38138776463240026
Validation loss: 2.753319369789473

Epoch: 6| Step: 12
Training loss: 0.4056808446168692
Validation loss: 2.7143891097933297

Epoch: 6| Step: 13
Training loss: 0.40342928912777437
Validation loss: 2.7843154130204697

Epoch: 296| Step: 0
Training loss: 0.4378530236059105
Validation loss: 2.7184230271663936

Epoch: 6| Step: 1
Training loss: 0.505307607302691
Validation loss: 2.7790151325036656

Epoch: 6| Step: 2
Training loss: 0.4459249400860874
Validation loss: 2.7323803992824005

Epoch: 6| Step: 3
Training loss: 0.31940332337518396
Validation loss: 2.763551886911446

Epoch: 6| Step: 4
Training loss: 0.8207635638475405
Validation loss: 2.6963837268592568

Epoch: 6| Step: 5
Training loss: 0.32042447900776616
Validation loss: 2.6619812264481433

Epoch: 6| Step: 6
Training loss: 0.40038262335992714
Validation loss: 2.700143430279232

Epoch: 6| Step: 7
Training loss: 0.4706626178201011
Validation loss: 2.7474640076963768

Epoch: 6| Step: 8
Training loss: 0.4174871076089462
Validation loss: 2.7323564617479144

Epoch: 6| Step: 9
Training loss: 0.33819923199488033
Validation loss: 2.6674687003981052

Epoch: 6| Step: 10
Training loss: 0.46688224299173287
Validation loss: 2.7443801069461893

Epoch: 6| Step: 11
Training loss: 0.33523468309155835
Validation loss: 2.7644560619074703

Epoch: 6| Step: 12
Training loss: 0.2987538663063297
Validation loss: 2.7931745831241392

Epoch: 6| Step: 13
Training loss: 0.3674795936900478
Validation loss: 2.709264468028727

Epoch: 297| Step: 0
Training loss: 0.41976201762841936
Validation loss: 2.7276926112384112

Epoch: 6| Step: 1
Training loss: 0.35472204569492977
Validation loss: 2.7521563514265592

Epoch: 6| Step: 2
Training loss: 0.5289545394963737
Validation loss: 2.743574887352483

Epoch: 6| Step: 3
Training loss: 0.45486500870229496
Validation loss: 2.68571738331818

Epoch: 6| Step: 4
Training loss: 0.3460106209491937
Validation loss: 2.6973172163765446

Epoch: 6| Step: 5
Training loss: 0.37960993912571117
Validation loss: 2.7781161751193957

Epoch: 6| Step: 6
Training loss: 0.7738033161682865
Validation loss: 2.6819169285795663

Epoch: 6| Step: 7
Training loss: 0.4003708625196179
Validation loss: 2.7605380817318443

Epoch: 6| Step: 8
Training loss: 0.36026539586462736
Validation loss: 2.72910131614038

Epoch: 6| Step: 9
Training loss: 0.317345837126517
Validation loss: 2.6917873199533924

Epoch: 6| Step: 10
Training loss: 0.3501616011231538
Validation loss: 2.6816457223716426

Epoch: 6| Step: 11
Training loss: 0.32326931565880224
Validation loss: 2.750070968347984

Epoch: 6| Step: 12
Training loss: 0.39028809323749736
Validation loss: 2.768181368300622

Epoch: 6| Step: 13
Training loss: 0.42985111936064274
Validation loss: 2.682255188530336

Epoch: 298| Step: 0
Training loss: 0.3768386864762089
Validation loss: 2.7260732567054546

Epoch: 6| Step: 1
Training loss: 0.36190776212162423
Validation loss: 2.7313211663094417

Epoch: 6| Step: 2
Training loss: 0.4782194038141853
Validation loss: 2.7305793212273777

Epoch: 6| Step: 3
Training loss: 0.40729802005557253
Validation loss: 2.756948405940116

Epoch: 6| Step: 4
Training loss: 0.37225577470490295
Validation loss: 2.7511346239193784

Epoch: 6| Step: 5
Training loss: 0.2909598841184496
Validation loss: 2.7081363361801327

Epoch: 6| Step: 6
Training loss: 0.5501729974903449
Validation loss: 2.763078958018027

Epoch: 6| Step: 7
Training loss: 0.25387728599259163
Validation loss: 2.673784343397264

Epoch: 6| Step: 8
Training loss: 0.43748085797531544
Validation loss: 2.6863744433941172

Epoch: 6| Step: 9
Training loss: 0.3791407026931051
Validation loss: 2.7152908066883876

Epoch: 6| Step: 10
Training loss: 0.2814572153744541
Validation loss: 2.749457233503098

Epoch: 6| Step: 11
Training loss: 0.35137613443091764
Validation loss: 2.7603755204115137

Epoch: 6| Step: 12
Training loss: 0.6458792721396837
Validation loss: 2.7445347549295924

Epoch: 6| Step: 13
Training loss: 0.3942162984559363
Validation loss: 2.7440008704820813

Epoch: 299| Step: 0
Training loss: 0.6337656919052779
Validation loss: 2.6793200479111468

Epoch: 6| Step: 1
Training loss: 0.7235267139240394
Validation loss: 2.768046603039738

Epoch: 6| Step: 2
Training loss: 0.4771729608605417
Validation loss: 2.7166467474770806

Epoch: 6| Step: 3
Training loss: 0.35322360628446936
Validation loss: 2.747687089616996

Epoch: 6| Step: 4
Training loss: 0.3496503219920219
Validation loss: 2.6861679857034653

Epoch: 6| Step: 5
Training loss: 0.433890129726756
Validation loss: 2.7203017808475485

Epoch: 6| Step: 6
Training loss: 0.5986087912489726
Validation loss: 2.757650916361164

Epoch: 6| Step: 7
Training loss: 0.738145765356475
Validation loss: 2.679799306481437

Epoch: 6| Step: 8
Training loss: 0.6112899037073258
Validation loss: 2.7359639374018263

Epoch: 6| Step: 9
Training loss: 0.468321556747022
Validation loss: 2.7324057036169664

Epoch: 6| Step: 10
Training loss: 0.5032994068734964
Validation loss: 2.7493447476799737

Epoch: 6| Step: 11
Training loss: 0.4293319444849867
Validation loss: 2.7364136861511583

Epoch: 6| Step: 12
Training loss: 0.5678698079692425
Validation loss: 2.766975130748578

Epoch: 6| Step: 13
Training loss: 0.49131440121504005
Validation loss: 2.7315143844241567

Epoch: 300| Step: 0
Training loss: 0.32103652072836303
Validation loss: 2.6751868114423165

Epoch: 6| Step: 1
Training loss: 0.39542039446719957
Validation loss: 2.7125676115900235

Epoch: 6| Step: 2
Training loss: 0.34406469851977234
Validation loss: 2.7740531846915983

Epoch: 6| Step: 3
Training loss: 0.566479119184526
Validation loss: 2.7135417057166706

Epoch: 6| Step: 4
Training loss: 0.4712002926319587
Validation loss: 2.7369518381503264

Epoch: 6| Step: 5
Training loss: 0.602687477368951
Validation loss: 2.6517005706128582

Epoch: 6| Step: 6
Training loss: 0.47797567304552546
Validation loss: 2.645953169434225

Epoch: 6| Step: 7
Training loss: 0.4670442221133149
Validation loss: 2.753295166899507

Epoch: 6| Step: 8
Training loss: 0.3473214455400365
Validation loss: 2.687974473927602

Epoch: 6| Step: 9
Training loss: 0.5018513201475097
Validation loss: 2.736119039290593

Epoch: 6| Step: 10
Training loss: 0.47447621867676953
Validation loss: 2.708502130872482

Epoch: 6| Step: 11
Training loss: 0.5179513413393572
Validation loss: 2.7239481024370686

Epoch: 6| Step: 12
Training loss: 0.3916697454669688
Validation loss: 2.6457831060092563

Epoch: 6| Step: 13
Training loss: 0.6474324445942318
Validation loss: 2.6606206129182945

Epoch: 301| Step: 0
Training loss: 0.36413829980323503
Validation loss: 2.7455690116797866

Epoch: 6| Step: 1
Training loss: 0.33828108613536645
Validation loss: 2.66977254975066

Epoch: 6| Step: 2
Training loss: 0.39267499876667755
Validation loss: 2.69050143700645

Epoch: 6| Step: 3
Training loss: 0.5259125963503967
Validation loss: 2.692919242661303

Epoch: 6| Step: 4
Training loss: 0.28163570870646776
Validation loss: 2.776075714837713

Epoch: 6| Step: 5
Training loss: 0.33667986926348187
Validation loss: 2.6538759804984173

Epoch: 6| Step: 6
Training loss: 0.3604869846515576
Validation loss: 2.746411192603546

Epoch: 6| Step: 7
Training loss: 0.3924410756339046
Validation loss: 2.6820104260205246

Epoch: 6| Step: 8
Training loss: 0.27294984657065263
Validation loss: 2.8204512346264243

Epoch: 6| Step: 9
Training loss: 0.6461351263780757
Validation loss: 2.662869183371621

Epoch: 6| Step: 10
Training loss: 0.31740239009630317
Validation loss: 2.7221051994351337

Epoch: 6| Step: 11
Training loss: 0.5019828104822448
Validation loss: 2.666949403695054

Epoch: 6| Step: 12
Training loss: 0.45297962355943383
Validation loss: 2.723187577640016

Epoch: 6| Step: 13
Training loss: 0.3791398183867896
Validation loss: 2.721648706196634

Epoch: 302| Step: 0
Training loss: 0.4013732389935948
Validation loss: 2.6933268064909246

Epoch: 6| Step: 1
Training loss: 0.4706535788137905
Validation loss: 2.710343851982589

Epoch: 6| Step: 2
Training loss: 0.2890876037419329
Validation loss: 2.7217825569136758

Epoch: 6| Step: 3
Training loss: 0.6292283080601552
Validation loss: 2.705005866048473

Epoch: 6| Step: 4
Training loss: 0.3989672971902043
Validation loss: 2.7375705611194294

Epoch: 6| Step: 5
Training loss: 0.3655111314876245
Validation loss: 2.7452190339112765

Epoch: 6| Step: 6
Training loss: 0.41971224498159915
Validation loss: 2.700612497322106

Epoch: 6| Step: 7
Training loss: 0.5609453492956948
Validation loss: 2.6948906683581413

Epoch: 6| Step: 8
Training loss: 0.43364574361203534
Validation loss: 2.6495526122065716

Epoch: 6| Step: 9
Training loss: 0.3818283665679656
Validation loss: 2.6788250246042735

Epoch: 6| Step: 10
Training loss: 0.39367764731609783
Validation loss: 2.670159010087224

Epoch: 6| Step: 11
Training loss: 0.4204908198330896
Validation loss: 2.7558192181021464

Epoch: 6| Step: 12
Training loss: 0.5026722073000887
Validation loss: 2.7661253194611537

Epoch: 6| Step: 13
Training loss: 0.2475871007633847
Validation loss: 2.680513616067992

Epoch: 303| Step: 0
Training loss: 0.39143927581398913
Validation loss: 2.6752375809167614

Epoch: 6| Step: 1
Training loss: 0.3307672789032845
Validation loss: 2.728112378697515

Epoch: 6| Step: 2
Training loss: 0.5820300723070352
Validation loss: 2.736325917684394

Epoch: 6| Step: 3
Training loss: 0.431380042219912
Validation loss: 2.751731154273242

Epoch: 6| Step: 4
Training loss: 0.4188367084861032
Validation loss: 2.7347930879216995

Epoch: 6| Step: 5
Training loss: 0.4492261305492967
Validation loss: 2.789541579131797

Epoch: 6| Step: 6
Training loss: 0.6793406686820437
Validation loss: 2.7147496634813137

Epoch: 6| Step: 7
Training loss: 0.43339391347579126
Validation loss: 2.708853617846998

Epoch: 6| Step: 8
Training loss: 0.3231657692739557
Validation loss: 2.6729517100161133

Epoch: 6| Step: 9
Training loss: 0.38113997466463834
Validation loss: 2.6339593760834257

Epoch: 6| Step: 10
Training loss: 0.2767693656496743
Validation loss: 2.750608218008303

Epoch: 6| Step: 11
Training loss: 0.3972139458064552
Validation loss: 2.6806742461242132

Epoch: 6| Step: 12
Training loss: 0.4981877146528875
Validation loss: 2.67678003535045

Epoch: 6| Step: 13
Training loss: 0.3302535995760818
Validation loss: 2.706949817190443

Epoch: 304| Step: 0
Training loss: 0.43210200856436537
Validation loss: 2.743122213227079

Epoch: 6| Step: 1
Training loss: 0.49756545192196006
Validation loss: 2.689784875159506

Epoch: 6| Step: 2
Training loss: 0.34758852181090494
Validation loss: 2.7338525036742394

Epoch: 6| Step: 3
Training loss: 0.5362705130310552
Validation loss: 2.6668318806569937

Epoch: 6| Step: 4
Training loss: 0.38036200496602884
Validation loss: 2.6900515900478066

Epoch: 6| Step: 5
Training loss: 0.4342784973362535
Validation loss: 2.6939647751204245

Epoch: 6| Step: 6
Training loss: 0.32394409035940075
Validation loss: 2.613257095841113

Epoch: 6| Step: 7
Training loss: 0.2781651382200496
Validation loss: 2.639557285877824

Epoch: 6| Step: 8
Training loss: 0.5215073198278409
Validation loss: 2.6194948037063157

Epoch: 6| Step: 9
Training loss: 0.32943276512262065
Validation loss: 2.6264586558815455

Epoch: 6| Step: 10
Training loss: 0.4839786015028417
Validation loss: 2.651411893782659

Epoch: 6| Step: 11
Training loss: 0.32133548482363256
Validation loss: 2.747546915296492

Epoch: 6| Step: 12
Training loss: 0.4420845761163317
Validation loss: 2.700747052205057

Epoch: 6| Step: 13
Training loss: 0.7566368185645737
Validation loss: 2.7238137454188505

Epoch: 305| Step: 0
Training loss: 0.4033321351172774
Validation loss: 2.6410766004724646

Epoch: 6| Step: 1
Training loss: 0.44813937003213766
Validation loss: 2.687572581767471

Epoch: 6| Step: 2
Training loss: 0.36254917748431187
Validation loss: 2.732808956189745

Epoch: 6| Step: 3
Training loss: 0.3994617387069322
Validation loss: 2.7191967067370477

Epoch: 6| Step: 4
Training loss: 0.40795693890682605
Validation loss: 2.710054369166399

Epoch: 6| Step: 5
Training loss: 0.46979748989423653
Validation loss: 2.6505775919827768

Epoch: 6| Step: 6
Training loss: 0.275183295264384
Validation loss: 2.748805292304018

Epoch: 6| Step: 7
Training loss: 0.4562012398152309
Validation loss: 2.7611682132681232

Epoch: 6| Step: 8
Training loss: 0.49756729372933184
Validation loss: 2.73797264663839

Epoch: 6| Step: 9
Training loss: 0.6077549747811081
Validation loss: 2.685115843428078

Epoch: 6| Step: 10
Training loss: 0.3000459104416281
Validation loss: 2.694808514786527

Epoch: 6| Step: 11
Training loss: 0.5200448616556657
Validation loss: 2.7253235312837383

Epoch: 6| Step: 12
Training loss: 0.2652048827728722
Validation loss: 2.6795670878027074

Epoch: 6| Step: 13
Training loss: 0.5852033720918629
Validation loss: 2.69492618169522

Epoch: 306| Step: 0
Training loss: 0.390584962700376
Validation loss: 2.779552291603766

Epoch: 6| Step: 1
Training loss: 0.3535672987797202
Validation loss: 2.660564912167239

Epoch: 6| Step: 2
Training loss: 0.39401611841702394
Validation loss: 2.7245647613628248

Epoch: 6| Step: 3
Training loss: 0.41955447425706877
Validation loss: 2.72225763147598

Epoch: 6| Step: 4
Training loss: 0.6262290790436434
Validation loss: 2.6768971439039144

Epoch: 6| Step: 5
Training loss: 0.5070154243432868
Validation loss: 2.683028885844997

Epoch: 6| Step: 6
Training loss: 0.43951154532473846
Validation loss: 2.67158103649375

Epoch: 6| Step: 7
Training loss: 0.40118862737428007
Validation loss: 2.761339059904206

Epoch: 6| Step: 8
Training loss: 0.6281668302737041
Validation loss: 2.748289370959198

Epoch: 6| Step: 9
Training loss: 0.5807794255517152
Validation loss: 2.7851994222654

Epoch: 6| Step: 10
Training loss: 0.5135395474290226
Validation loss: 2.7583951181558652

Epoch: 6| Step: 11
Training loss: 0.39342375439666477
Validation loss: 2.5898798062138635

Epoch: 6| Step: 12
Training loss: 0.2970855744082512
Validation loss: 2.752271523251182

Epoch: 6| Step: 13
Training loss: 0.3043179349259227
Validation loss: 2.7185837121146714

Epoch: 307| Step: 0
Training loss: 0.43189804893409794
Validation loss: 2.749868375344716

Epoch: 6| Step: 1
Training loss: 0.4387351889705141
Validation loss: 2.659281597596568

Epoch: 6| Step: 2
Training loss: 0.3755924988013344
Validation loss: 2.6610764803742377

Epoch: 6| Step: 3
Training loss: 0.5272176803786942
Validation loss: 2.74018936319648

Epoch: 6| Step: 4
Training loss: 0.41319998391050766
Validation loss: 2.7867286812423786

Epoch: 6| Step: 5
Training loss: 0.394533856071703
Validation loss: 2.6935903898719347

Epoch: 6| Step: 6
Training loss: 0.5055228627408687
Validation loss: 2.6148497583787353

Epoch: 6| Step: 7
Training loss: 0.2945750262160631
Validation loss: 2.73003690012306

Epoch: 6| Step: 8
Training loss: 0.39767040010169546
Validation loss: 2.7860272415720666

Epoch: 6| Step: 9
Training loss: 0.4107916859737265
Validation loss: 2.8050031989040254

Epoch: 6| Step: 10
Training loss: 0.4943985548568873
Validation loss: 2.73884668829258

Epoch: 6| Step: 11
Training loss: 0.7118081850039496
Validation loss: 2.7676818225200135

Epoch: 6| Step: 12
Training loss: 0.2968224428736144
Validation loss: 2.684209531777148

Epoch: 6| Step: 13
Training loss: 0.4793144253950635
Validation loss: 2.6957266447917614

Epoch: 308| Step: 0
Training loss: 0.41030441514451427
Validation loss: 2.7532027840856985

Epoch: 6| Step: 1
Training loss: 0.2954885709742116
Validation loss: 2.7137502247233205

Epoch: 6| Step: 2
Training loss: 0.37290250770853994
Validation loss: 2.717429048441935

Epoch: 6| Step: 3
Training loss: 0.37794100328010577
Validation loss: 2.770810619538409

Epoch: 6| Step: 4
Training loss: 0.37225769610932435
Validation loss: 2.8405717548881912

Epoch: 6| Step: 5
Training loss: 0.531523634057658
Validation loss: 2.7104093713293236

Epoch: 6| Step: 6
Training loss: 0.4077297733337391
Validation loss: 2.727315570995695

Epoch: 6| Step: 7
Training loss: 0.40037142079516436
Validation loss: 2.7067774093535326

Epoch: 6| Step: 8
Training loss: 0.447994571017468
Validation loss: 2.715096280361957

Epoch: 6| Step: 9
Training loss: 0.46770680695633726
Validation loss: 2.7265122781553215

Epoch: 6| Step: 10
Training loss: 0.466898727477924
Validation loss: 2.678784454594062

Epoch: 6| Step: 11
Training loss: 0.4395769241582914
Validation loss: 2.7021839363313167

Epoch: 6| Step: 12
Training loss: 0.6786599558612139
Validation loss: 2.7150090887644684

Epoch: 6| Step: 13
Training loss: 0.417763240595247
Validation loss: 2.831120353745109

Epoch: 309| Step: 0
Training loss: 0.3506318808711709
Validation loss: 2.7497023797097766

Epoch: 6| Step: 1
Training loss: 0.6092704781122379
Validation loss: 2.6810689614568743

Epoch: 6| Step: 2
Training loss: 0.4891392912615737
Validation loss: 2.76594456839672

Epoch: 6| Step: 3
Training loss: 0.33638594880176803
Validation loss: 2.7956682439766043

Epoch: 6| Step: 4
Training loss: 0.4059499586277055
Validation loss: 2.7161973538119315

Epoch: 6| Step: 5
Training loss: 0.3261358275452909
Validation loss: 2.70679320536011

Epoch: 6| Step: 6
Training loss: 0.3571987393630894
Validation loss: 2.7544606978591877

Epoch: 6| Step: 7
Training loss: 0.3799702560868068
Validation loss: 2.732225106975406

Epoch: 6| Step: 8
Training loss: 0.40558669151831983
Validation loss: 2.718404908768909

Epoch: 6| Step: 9
Training loss: 0.38479298528222616
Validation loss: 2.66531788471847

Epoch: 6| Step: 10
Training loss: 0.449877943599024
Validation loss: 2.732285258704605

Epoch: 6| Step: 11
Training loss: 0.5261692672925417
Validation loss: 2.7261994565592538

Epoch: 6| Step: 12
Training loss: 0.34382684888995124
Validation loss: 2.6926410944578243

Epoch: 6| Step: 13
Training loss: 0.3667812128755216
Validation loss: 2.7524306508173826

Epoch: 310| Step: 0
Training loss: 0.4702426668454207
Validation loss: 2.7130531828083053

Epoch: 6| Step: 1
Training loss: 0.6168863551709305
Validation loss: 2.7111306465227663

Epoch: 6| Step: 2
Training loss: 0.35514250655294505
Validation loss: 2.719577926327233

Epoch: 6| Step: 3
Training loss: 0.5650480626349084
Validation loss: 2.7152028969154873

Epoch: 6| Step: 4
Training loss: 0.45950267016721513
Validation loss: 2.789989940552254

Epoch: 6| Step: 5
Training loss: 0.5080813943092737
Validation loss: 2.6779269411910724

Epoch: 6| Step: 6
Training loss: 0.32718405458518085
Validation loss: 2.7879495831231416

Epoch: 6| Step: 7
Training loss: 0.37439128028357277
Validation loss: 2.694743825288493

Epoch: 6| Step: 8
Training loss: 0.46898146318799167
Validation loss: 2.7622900933426324

Epoch: 6| Step: 9
Training loss: 0.488293548429103
Validation loss: 2.7542525414156804

Epoch: 6| Step: 10
Training loss: 0.29310708912378464
Validation loss: 2.7430296109309857

Epoch: 6| Step: 11
Training loss: 0.380145259311031
Validation loss: 2.7649235671035175

Epoch: 6| Step: 12
Training loss: 0.35099768301750633
Validation loss: 2.663066450345444

Epoch: 6| Step: 13
Training loss: 0.3985514384399651
Validation loss: 2.7326390741572517

Epoch: 311| Step: 0
Training loss: 0.35968897414050377
Validation loss: 2.7744479921963547

Epoch: 6| Step: 1
Training loss: 0.3348129657402452
Validation loss: 2.713249239598651

Epoch: 6| Step: 2
Training loss: 0.497552109845472
Validation loss: 2.7090671914443187

Epoch: 6| Step: 3
Training loss: 0.37503427110473436
Validation loss: 2.7201901710170566

Epoch: 6| Step: 4
Training loss: 0.6805226686753529
Validation loss: 2.680153823774641

Epoch: 6| Step: 5
Training loss: 0.48159929950574454
Validation loss: 2.7287758457592535

Epoch: 6| Step: 6
Training loss: 0.2887176441254439
Validation loss: 2.779236697030011

Epoch: 6| Step: 7
Training loss: 0.3312229640292041
Validation loss: 2.7509493778516463

Epoch: 6| Step: 8
Training loss: 0.45952139746912696
Validation loss: 2.7637450874615066

Epoch: 6| Step: 9
Training loss: 0.5859393819142955
Validation loss: 2.8228111857359064

Epoch: 6| Step: 10
Training loss: 0.41259659084205086
Validation loss: 2.747275042778762

Epoch: 6| Step: 11
Training loss: 0.509493905213489
Validation loss: 2.715684221834255

Epoch: 6| Step: 12
Training loss: 0.33988465687766817
Validation loss: 2.71162474731356

Epoch: 6| Step: 13
Training loss: 0.5790774001022828
Validation loss: 2.6588782154655806

Epoch: 312| Step: 0
Training loss: 0.47940824127330767
Validation loss: 2.68192561840068

Epoch: 6| Step: 1
Training loss: 0.43473281393801566
Validation loss: 2.691312481003851

Epoch: 6| Step: 2
Training loss: 0.3722291742433965
Validation loss: 2.6591265193626614

Epoch: 6| Step: 3
Training loss: 0.4115818860260986
Validation loss: 2.6268777640309486

Epoch: 6| Step: 4
Training loss: 0.2863974795582887
Validation loss: 2.635830765006444

Epoch: 6| Step: 5
Training loss: 0.42800053715560754
Validation loss: 2.6908197820548065

Epoch: 6| Step: 6
Training loss: 0.33065759705443176
Validation loss: 2.699575162359928

Epoch: 6| Step: 7
Training loss: 0.3269114418758885
Validation loss: 2.757100215923783

Epoch: 6| Step: 8
Training loss: 0.3431728459614433
Validation loss: 2.7136526591518098

Epoch: 6| Step: 9
Training loss: 0.3793651515430236
Validation loss: 2.6713196026628716

Epoch: 6| Step: 10
Training loss: 0.6420988945268716
Validation loss: 2.708944718726822

Epoch: 6| Step: 11
Training loss: 0.4078514738204271
Validation loss: 2.6518859767873946

Epoch: 6| Step: 12
Training loss: 0.21007176512670256
Validation loss: 2.7385666027846707

Epoch: 6| Step: 13
Training loss: 0.3940386009683286
Validation loss: 2.715004193072655

Epoch: 313| Step: 0
Training loss: 0.30109438759024104
Validation loss: 2.7059828511117856

Epoch: 6| Step: 1
Training loss: 0.3182995745890031
Validation loss: 2.6885675113997016

Epoch: 6| Step: 2
Training loss: 0.2591829002198499
Validation loss: 2.7575462508163184

Epoch: 6| Step: 3
Training loss: 0.45268298656441963
Validation loss: 2.736347279196842

Epoch: 6| Step: 4
Training loss: 0.3726108659343394
Validation loss: 2.735643844487295

Epoch: 6| Step: 5
Training loss: 0.2708185800177549
Validation loss: 2.695573921241508

Epoch: 6| Step: 6
Training loss: 0.28602642385920096
Validation loss: 2.719133021241703

Epoch: 6| Step: 7
Training loss: 0.3572481911161635
Validation loss: 2.7002916425798476

Epoch: 6| Step: 8
Training loss: 0.5718006419216581
Validation loss: 2.706614621437975

Epoch: 6| Step: 9
Training loss: 0.35992323480824906
Validation loss: 2.748758136782906

Epoch: 6| Step: 10
Training loss: 0.45497735999446026
Validation loss: 2.7429247134157917

Epoch: 6| Step: 11
Training loss: 0.4024328670137275
Validation loss: 2.7047039117430884

Epoch: 6| Step: 12
Training loss: 0.42133517519192665
Validation loss: 2.7348516720865534

Epoch: 6| Step: 13
Training loss: 0.425532697172156
Validation loss: 2.683419256631425

Epoch: 314| Step: 0
Training loss: 0.4519317635093124
Validation loss: 2.667259080965835

Epoch: 6| Step: 1
Training loss: 0.42385923913054996
Validation loss: 2.744408587385816

Epoch: 6| Step: 2
Training loss: 0.3998272537698399
Validation loss: 2.6170994530286475

Epoch: 6| Step: 3
Training loss: 0.4438588022441944
Validation loss: 2.6857958647003937

Epoch: 6| Step: 4
Training loss: 0.44016496437771047
Validation loss: 2.7263565058530483

Epoch: 6| Step: 5
Training loss: 0.5322515079356881
Validation loss: 2.674505533882673

Epoch: 6| Step: 6
Training loss: 0.3104019546649408
Validation loss: 2.658916137650625

Epoch: 6| Step: 7
Training loss: 0.3591063365952972
Validation loss: 2.7086163201797806

Epoch: 6| Step: 8
Training loss: 0.4146280924279508
Validation loss: 2.7670643898797476

Epoch: 6| Step: 9
Training loss: 0.49046548206107127
Validation loss: 2.687466643370391

Epoch: 6| Step: 10
Training loss: 0.26631466306422547
Validation loss: 2.6881940817749896

Epoch: 6| Step: 11
Training loss: 0.6135034340915464
Validation loss: 2.7507664161577576

Epoch: 6| Step: 12
Training loss: 0.3843449456785384
Validation loss: 2.717459039645545

Epoch: 6| Step: 13
Training loss: 0.2434991113903038
Validation loss: 2.669966092007478

Epoch: 315| Step: 0
Training loss: 0.2976067459311566
Validation loss: 2.6711126954071682

Epoch: 6| Step: 1
Training loss: 0.18908752480710558
Validation loss: 2.745065843085472

Epoch: 6| Step: 2
Training loss: 0.3205192178002176
Validation loss: 2.6748950391005386

Epoch: 6| Step: 3
Training loss: 0.565904750455664
Validation loss: 2.7314375876248245

Epoch: 6| Step: 4
Training loss: 0.6284882477273804
Validation loss: 2.70366411951875

Epoch: 6| Step: 5
Training loss: 0.4176713652039516
Validation loss: 2.7236727947201493

Epoch: 6| Step: 6
Training loss: 0.23639044452281877
Validation loss: 2.692958758654466

Epoch: 6| Step: 7
Training loss: 0.3499068055226416
Validation loss: 2.7758140661517086

Epoch: 6| Step: 8
Training loss: 0.21308912419944176
Validation loss: 2.6779183496834267

Epoch: 6| Step: 9
Training loss: 0.3436682126976768
Validation loss: 2.715804554366477

Epoch: 6| Step: 10
Training loss: 0.3028927050605924
Validation loss: 2.7124667073329376

Epoch: 6| Step: 11
Training loss: 0.3942177537322638
Validation loss: 2.6481314663286257

Epoch: 6| Step: 12
Training loss: 0.3896881695139746
Validation loss: 2.7390071470880684

Epoch: 6| Step: 13
Training loss: 0.3099763295535016
Validation loss: 2.650538013832589

Epoch: 316| Step: 0
Training loss: 0.28305581306414196
Validation loss: 2.697040044774148

Epoch: 6| Step: 1
Training loss: 0.37951709235629855
Validation loss: 2.67960228520353

Epoch: 6| Step: 2
Training loss: 0.3655392603316517
Validation loss: 2.7039830310541144

Epoch: 6| Step: 3
Training loss: 0.6312306731636341
Validation loss: 2.737592384660709

Epoch: 6| Step: 4
Training loss: 0.25600829413415055
Validation loss: 2.7004146769647304

Epoch: 6| Step: 5
Training loss: 0.29519110510678404
Validation loss: 2.743524701739047

Epoch: 6| Step: 6
Training loss: 0.3934197963764377
Validation loss: 2.8377111684054404

Epoch: 6| Step: 7
Training loss: 0.44210358622135526
Validation loss: 2.704746546432256

Epoch: 6| Step: 8
Training loss: 0.3551400729655978
Validation loss: 2.7159868719900744

Epoch: 6| Step: 9
Training loss: 0.35285179236995895
Validation loss: 2.6462687086604153

Epoch: 6| Step: 10
Training loss: 0.4906305786593169
Validation loss: 2.721833077716292

Epoch: 6| Step: 11
Training loss: 0.24567078770284875
Validation loss: 2.6262552499574903

Epoch: 6| Step: 12
Training loss: 0.3505925679974497
Validation loss: 2.6605517242332186

Epoch: 6| Step: 13
Training loss: 0.48254073373781065
Validation loss: 2.7572525723958075

Epoch: 317| Step: 0
Training loss: 0.35615356210804083
Validation loss: 2.7035950342083543

Epoch: 6| Step: 1
Training loss: 0.3227297590632525
Validation loss: 2.667186557238486

Epoch: 6| Step: 2
Training loss: 0.5136774157091119
Validation loss: 2.770560406506246

Epoch: 6| Step: 3
Training loss: 0.5075229699710327
Validation loss: 2.789054507289515

Epoch: 6| Step: 4
Training loss: 0.4644657168594431
Validation loss: 2.7455347974585917

Epoch: 6| Step: 5
Training loss: 0.5344487546472478
Validation loss: 2.730259848677122

Epoch: 6| Step: 6
Training loss: 0.275960332956163
Validation loss: 2.685860481215746

Epoch: 6| Step: 7
Training loss: 0.3443966764907772
Validation loss: 2.6431863239493145

Epoch: 6| Step: 8
Training loss: 0.5366343946951873
Validation loss: 2.679341493145978

Epoch: 6| Step: 9
Training loss: 0.46302212485042826
Validation loss: 2.678579844809737

Epoch: 6| Step: 10
Training loss: 0.420553628185914
Validation loss: 2.7434795556279696

Epoch: 6| Step: 11
Training loss: 0.3606740857308473
Validation loss: 2.6379275492185235

Epoch: 6| Step: 12
Training loss: 0.4156462771483592
Validation loss: 2.747065177412734

Epoch: 6| Step: 13
Training loss: 0.4769129324559145
Validation loss: 2.6414231066733356

Epoch: 318| Step: 0
Training loss: 0.41967649165619164
Validation loss: 2.758939309318999

Epoch: 6| Step: 1
Training loss: 0.42888055804349917
Validation loss: 2.6247346683404076

Epoch: 6| Step: 2
Training loss: 0.2974842120036455
Validation loss: 2.6655335750904143

Epoch: 6| Step: 3
Training loss: 0.6465351511212369
Validation loss: 2.629566444153743

Epoch: 6| Step: 4
Training loss: 0.38630004333325013
Validation loss: 2.6756762258890294

Epoch: 6| Step: 5
Training loss: 0.29072786992183763
Validation loss: 2.641377584442323

Epoch: 6| Step: 6
Training loss: 0.4427802382772683
Validation loss: 2.6450926101783248

Epoch: 6| Step: 7
Training loss: 0.34961592811964065
Validation loss: 2.695649285399074

Epoch: 6| Step: 8
Training loss: 0.4282858094087864
Validation loss: 2.7361836727695334

Epoch: 6| Step: 9
Training loss: 0.4296429697717678
Validation loss: 2.789416150949058

Epoch: 6| Step: 10
Training loss: 0.48616797326563743
Validation loss: 2.6573505290914263

Epoch: 6| Step: 11
Training loss: 0.43310312917737603
Validation loss: 2.7225538806470153

Epoch: 6| Step: 12
Training loss: 0.44388941871559456
Validation loss: 2.7498152266185105

Epoch: 6| Step: 13
Training loss: 0.64450436160326
Validation loss: 2.6723341965517133

Epoch: 319| Step: 0
Training loss: 0.4180944378550156
Validation loss: 2.6844679118054176

Epoch: 6| Step: 1
Training loss: 0.43952798841495594
Validation loss: 2.753933607466065

Epoch: 6| Step: 2
Training loss: 0.5485047986508323
Validation loss: 2.752899361008429

Epoch: 6| Step: 3
Training loss: 0.4011086701076398
Validation loss: 2.705575409315278

Epoch: 6| Step: 4
Training loss: 0.4197905934070028
Validation loss: 2.7169913234457495

Epoch: 6| Step: 5
Training loss: 0.5322732887405035
Validation loss: 2.7183700383708036

Epoch: 6| Step: 6
Training loss: 0.42373462823539304
Validation loss: 2.752627836695264

Epoch: 6| Step: 7
Training loss: 0.38204957882963164
Validation loss: 2.787288881868792

Epoch: 6| Step: 8
Training loss: 0.38349250809265994
Validation loss: 2.669348513085435

Epoch: 6| Step: 9
Training loss: 0.5826371898280294
Validation loss: 2.6939967237923197

Epoch: 6| Step: 10
Training loss: 0.27193019131356155
Validation loss: 2.764818063030799

Epoch: 6| Step: 11
Training loss: 0.33147583676503095
Validation loss: 2.632039651907327

Epoch: 6| Step: 12
Training loss: 0.5586144236760388
Validation loss: 2.6674667563805485

Epoch: 6| Step: 13
Training loss: 0.41636986493002165
Validation loss: 2.698649897165491

Epoch: 320| Step: 0
Training loss: 0.30289713268358603
Validation loss: 2.691651988702993

Epoch: 6| Step: 1
Training loss: 0.4170174870197719
Validation loss: 2.681470361292929

Epoch: 6| Step: 2
Training loss: 0.3512638306864404
Validation loss: 2.7309791768203353

Epoch: 6| Step: 3
Training loss: 0.5017306654948819
Validation loss: 2.677608910906203

Epoch: 6| Step: 4
Training loss: 0.3744732415478177
Validation loss: 2.729992964680774

Epoch: 6| Step: 5
Training loss: 0.5699057500282416
Validation loss: 2.794558242185458

Epoch: 6| Step: 6
Training loss: 0.37577481492335996
Validation loss: 2.7036099302117123

Epoch: 6| Step: 7
Training loss: 0.5785753197429805
Validation loss: 2.7694407288213827

Epoch: 6| Step: 8
Training loss: 0.3004829116158038
Validation loss: 2.6631900928787253

Epoch: 6| Step: 9
Training loss: 0.3241784633747123
Validation loss: 2.755456323165711

Epoch: 6| Step: 10
Training loss: 0.4040312332010513
Validation loss: 2.7072608046749798

Epoch: 6| Step: 11
Training loss: 0.3400898732759475
Validation loss: 2.6912075757434493

Epoch: 6| Step: 12
Training loss: 0.30178727928902177
Validation loss: 2.7250070006021057

Epoch: 6| Step: 13
Training loss: 0.25757462191087
Validation loss: 2.6607156801082947

Epoch: 321| Step: 0
Training loss: 0.32342526417314754
Validation loss: 2.7754636929848986

Epoch: 6| Step: 1
Training loss: 0.3400982966751363
Validation loss: 2.691162142597438

Epoch: 6| Step: 2
Training loss: 0.41127997367410996
Validation loss: 2.709186431822835

Epoch: 6| Step: 3
Training loss: 0.2818779293508628
Validation loss: 2.699454128456667

Epoch: 6| Step: 4
Training loss: 0.2937010069836338
Validation loss: 2.728625925866078

Epoch: 6| Step: 5
Training loss: 0.4056752246979486
Validation loss: 2.6582843769033944

Epoch: 6| Step: 6
Training loss: 0.4019500509873002
Validation loss: 2.7289194087262665

Epoch: 6| Step: 7
Training loss: 0.26421908357713103
Validation loss: 2.7073316678043073

Epoch: 6| Step: 8
Training loss: 0.35991064870163003
Validation loss: 2.7340123544631054

Epoch: 6| Step: 9
Training loss: 0.5527444306122778
Validation loss: 2.74016756758907

Epoch: 6| Step: 10
Training loss: 0.5778671927018552
Validation loss: 2.7091465291597148

Epoch: 6| Step: 11
Training loss: 0.41772912188555683
Validation loss: 2.7300252704359034

Epoch: 6| Step: 12
Training loss: 0.4604884400961866
Validation loss: 2.711292906814883

Epoch: 6| Step: 13
Training loss: 0.4693994791019867
Validation loss: 2.7424779957271355

Epoch: 322| Step: 0
Training loss: 0.3873440859517329
Validation loss: 2.7061973120278933

Epoch: 6| Step: 1
Training loss: 0.6086321974082166
Validation loss: 2.820285057293636

Epoch: 6| Step: 2
Training loss: 0.40473845687602766
Validation loss: 2.7473364270674274

Epoch: 6| Step: 3
Training loss: 0.40711417351096213
Validation loss: 2.6816511012736535

Epoch: 6| Step: 4
Training loss: 0.421722101832126
Validation loss: 2.7546359779529337

Epoch: 6| Step: 5
Training loss: 0.4046235538465072
Validation loss: 2.7418433514123453

Epoch: 6| Step: 6
Training loss: 0.5439256428256056
Validation loss: 2.697634477230131

Epoch: 6| Step: 7
Training loss: 0.36842792071442587
Validation loss: 2.7750743853133226

Epoch: 6| Step: 8
Training loss: 0.3733665335033411
Validation loss: 2.7417978442811246

Epoch: 6| Step: 9
Training loss: 0.42478478045242823
Validation loss: 2.735069462825675

Epoch: 6| Step: 10
Training loss: 0.3088610372803034
Validation loss: 2.692943575019939

Epoch: 6| Step: 11
Training loss: 0.4331843187190296
Validation loss: 2.7729220202303786

Epoch: 6| Step: 12
Training loss: 0.47863613868777416
Validation loss: 2.6245646494178025

Epoch: 6| Step: 13
Training loss: 0.3787715711840146
Validation loss: 2.6980559829816655

Epoch: 323| Step: 0
Training loss: 0.41970841060988523
Validation loss: 2.69274545689466

Epoch: 6| Step: 1
Training loss: 0.6110527222607917
Validation loss: 2.72217658117098

Epoch: 6| Step: 2
Training loss: 0.4754046460782026
Validation loss: 2.671221528628226

Epoch: 6| Step: 3
Training loss: 0.3834362398109775
Validation loss: 2.674720706203937

Epoch: 6| Step: 4
Training loss: 0.4250827624575091
Validation loss: 2.7209139429821265

Epoch: 6| Step: 5
Training loss: 0.2784784503540482
Validation loss: 2.6953127358846514

Epoch: 6| Step: 6
Training loss: 0.3586733644488199
Validation loss: 2.716770737844745

Epoch: 6| Step: 7
Training loss: 0.35236094193902867
Validation loss: 2.7229575925834006

Epoch: 6| Step: 8
Training loss: 0.3264772732873523
Validation loss: 2.699608752078061

Epoch: 6| Step: 9
Training loss: 0.4162849843728477
Validation loss: 2.6750155873305

Epoch: 6| Step: 10
Training loss: 0.45938055917399334
Validation loss: 2.721680782497201

Epoch: 6| Step: 11
Training loss: 0.5145492892516089
Validation loss: 2.6977768988226445

Epoch: 6| Step: 12
Training loss: 0.41348964722714515
Validation loss: 2.6791008695489493

Epoch: 6| Step: 13
Training loss: 0.4723024226162671
Validation loss: 2.7203863926696443

Epoch: 324| Step: 0
Training loss: 0.2880674970511645
Validation loss: 2.6922881033991723

Epoch: 6| Step: 1
Training loss: 0.3086012102987793
Validation loss: 2.747620694810154

Epoch: 6| Step: 2
Training loss: 0.4827809869796508
Validation loss: 2.6785240353826887

Epoch: 6| Step: 3
Training loss: 0.3908035442485879
Validation loss: 2.7247724368068247

Epoch: 6| Step: 4
Training loss: 0.4973548719173452
Validation loss: 2.693448278017038

Epoch: 6| Step: 5
Training loss: 0.3351146467659251
Validation loss: 2.7346033418771913

Epoch: 6| Step: 6
Training loss: 0.3074338336252129
Validation loss: 2.72033764168217

Epoch: 6| Step: 7
Training loss: 0.4520455525545608
Validation loss: 2.6454395366582784

Epoch: 6| Step: 8
Training loss: 0.5062840862337179
Validation loss: 2.734653015535388

Epoch: 6| Step: 9
Training loss: 0.414257615380283
Validation loss: 2.7240657651490086

Epoch: 6| Step: 10
Training loss: 0.22065008420694085
Validation loss: 2.609590137011337

Epoch: 6| Step: 11
Training loss: 0.3830593636624453
Validation loss: 2.691993505359541

Epoch: 6| Step: 12
Training loss: 0.5879678263620243
Validation loss: 2.7454437745547318

Epoch: 6| Step: 13
Training loss: 0.3119290619971746
Validation loss: 2.746008808817375

Epoch: 325| Step: 0
Training loss: 0.3817069184464062
Validation loss: 2.6898719315608792

Epoch: 6| Step: 1
Training loss: 0.46885918299357404
Validation loss: 2.762997343423114

Epoch: 6| Step: 2
Training loss: 0.4152481091184701
Validation loss: 2.724101240932804

Epoch: 6| Step: 3
Training loss: 0.2829081347297496
Validation loss: 2.6496379610986898

Epoch: 6| Step: 4
Training loss: 0.44436626959593095
Validation loss: 2.7299813857509414

Epoch: 6| Step: 5
Training loss: 0.3360008579211976
Validation loss: 2.758250978821249

Epoch: 6| Step: 6
Training loss: 0.5923103647929179
Validation loss: 2.703800962158599

Epoch: 6| Step: 7
Training loss: 0.28585632818849727
Validation loss: 2.6345103493428867

Epoch: 6| Step: 8
Training loss: 0.3199890410886234
Validation loss: 2.727263359634129

Epoch: 6| Step: 9
Training loss: 0.3698732483111044
Validation loss: 2.723057429540778

Epoch: 6| Step: 10
Training loss: 0.6562953206716362
Validation loss: 2.650254742955934

Epoch: 6| Step: 11
Training loss: 0.44292495887843575
Validation loss: 2.5976391784565918

Epoch: 6| Step: 12
Training loss: 0.3637992897918568
Validation loss: 2.725254273289978

Epoch: 6| Step: 13
Training loss: 0.48144802069530995
Validation loss: 2.682545730755622

Epoch: 326| Step: 0
Training loss: 0.4514220233721709
Validation loss: 2.772164524559243

Epoch: 6| Step: 1
Training loss: 0.3749715476368446
Validation loss: 2.686230019349677

Epoch: 6| Step: 2
Training loss: 0.32771090081299026
Validation loss: 2.7181022427780803

Epoch: 6| Step: 3
Training loss: 0.46238945335781406
Validation loss: 2.739508527500754

Epoch: 6| Step: 4
Training loss: 0.5974192679303306
Validation loss: 2.7557244253156834

Epoch: 6| Step: 5
Training loss: 0.4666750920619374
Validation loss: 2.7190817049622087

Epoch: 6| Step: 6
Training loss: 0.3469747335520478
Validation loss: 2.7057804889725245

Epoch: 6| Step: 7
Training loss: 0.263002025133212
Validation loss: 2.721287803509979

Epoch: 6| Step: 8
Training loss: 0.3770211114006382
Validation loss: 2.6906349099242943

Epoch: 6| Step: 9
Training loss: 0.38896649183364246
Validation loss: 2.716613909632315

Epoch: 6| Step: 10
Training loss: 0.2621741531757797
Validation loss: 2.7169871625848545

Epoch: 6| Step: 11
Training loss: 0.36459480222192325
Validation loss: 2.77372063995863

Epoch: 6| Step: 12
Training loss: 0.3207522838983966
Validation loss: 2.6489858594137536

Epoch: 6| Step: 13
Training loss: 0.555505605942314
Validation loss: 2.694097523351177

Epoch: 327| Step: 0
Training loss: 0.3083831454756439
Validation loss: 2.6681780753952036

Epoch: 6| Step: 1
Training loss: 0.3294043011634385
Validation loss: 2.6294813504846135

Epoch: 6| Step: 2
Training loss: 0.5527762676848845
Validation loss: 2.7083219063346613

Epoch: 6| Step: 3
Training loss: 0.461929853302493
Validation loss: 2.658323727613292

Epoch: 6| Step: 4
Training loss: 0.5406356193072831
Validation loss: 2.763338986894494

Epoch: 6| Step: 5
Training loss: 0.4888621117773765
Validation loss: 2.6836986863647265

Epoch: 6| Step: 6
Training loss: 0.4125178694466929
Validation loss: 2.6983835314706823

Epoch: 6| Step: 7
Training loss: 0.34406243560748834
Validation loss: 2.7781298991711862

Epoch: 6| Step: 8
Training loss: 0.6425546566466228
Validation loss: 2.67653969366954

Epoch: 6| Step: 9
Training loss: 0.4372646516206699
Validation loss: 2.653939659814959

Epoch: 6| Step: 10
Training loss: 0.30909690399303996
Validation loss: 2.6632629343173106

Epoch: 6| Step: 11
Training loss: 0.27778952328698203
Validation loss: 2.731266769194754

Epoch: 6| Step: 12
Training loss: 0.3572313812081025
Validation loss: 2.714648767142813

Epoch: 6| Step: 13
Training loss: 0.4462785782198146
Validation loss: 2.6477952476613837

Epoch: 328| Step: 0
Training loss: 0.3820752615823108
Validation loss: 2.784862308408612

Epoch: 6| Step: 1
Training loss: 0.4830415892061169
Validation loss: 2.671654519247646

Epoch: 6| Step: 2
Training loss: 0.3340399400321382
Validation loss: 2.692071796395074

Epoch: 6| Step: 3
Training loss: 0.24705306283194461
Validation loss: 2.6580885040961317

Epoch: 6| Step: 4
Training loss: 0.5359582390957017
Validation loss: 2.706552159427236

Epoch: 6| Step: 5
Training loss: 0.32540917452435203
Validation loss: 2.6564991852806754

Epoch: 6| Step: 6
Training loss: 0.36407977705796335
Validation loss: 2.6911767604304138

Epoch: 6| Step: 7
Training loss: 0.4829132265122555
Validation loss: 2.6643972102686226

Epoch: 6| Step: 8
Training loss: 0.30353473568798756
Validation loss: 2.730082217586534

Epoch: 6| Step: 9
Training loss: 0.3824178646761883
Validation loss: 2.8110774645929886

Epoch: 6| Step: 10
Training loss: 0.2844928968662446
Validation loss: 2.6476334633235465

Epoch: 6| Step: 11
Training loss: 0.21864183340159205
Validation loss: 2.668865553939783

Epoch: 6| Step: 12
Training loss: 0.45792817682142173
Validation loss: 2.655928229495963

Epoch: 6| Step: 13
Training loss: 0.3222152323770846
Validation loss: 2.6950595902912697

Epoch: 329| Step: 0
Training loss: 0.289458030010471
Validation loss: 2.718755539344026

Epoch: 6| Step: 1
Training loss: 0.37403867605854574
Validation loss: 2.7731632723920967

Epoch: 6| Step: 2
Training loss: 0.420527372069223
Validation loss: 2.641283528755577

Epoch: 6| Step: 3
Training loss: 0.3375482533539809
Validation loss: 2.704932731090485

Epoch: 6| Step: 4
Training loss: 0.3937252044439345
Validation loss: 2.697463882529753

Epoch: 6| Step: 5
Training loss: 0.44131946554549906
Validation loss: 2.6931291518227685

Epoch: 6| Step: 6
Training loss: 0.7328353731859957
Validation loss: 2.689474873580667

Epoch: 6| Step: 7
Training loss: 0.5361600219270155
Validation loss: 2.768358492529278

Epoch: 6| Step: 8
Training loss: 0.2719586024599851
Validation loss: 2.766117511868363

Epoch: 6| Step: 9
Training loss: 0.44077999283842206
Validation loss: 2.7132011585550124

Epoch: 6| Step: 10
Training loss: 0.4345210529654895
Validation loss: 2.7348668192017787

Epoch: 6| Step: 11
Training loss: 0.46853408609174463
Validation loss: 2.7365887136853013

Epoch: 6| Step: 12
Training loss: 0.47004042071159946
Validation loss: 2.733492565362855

Epoch: 6| Step: 13
Training loss: 0.4001815249896463
Validation loss: 2.730738512355817

Epoch: 330| Step: 0
Training loss: 0.3625123490499209
Validation loss: 2.772328143261229

Epoch: 6| Step: 1
Training loss: 0.3367811300109893
Validation loss: 2.741168782981745

Epoch: 6| Step: 2
Training loss: 0.38598165684189095
Validation loss: 2.708320006313302

Epoch: 6| Step: 3
Training loss: 0.6487444415433165
Validation loss: 2.6563226428103017

Epoch: 6| Step: 4
Training loss: 0.4248263123368475
Validation loss: 2.6633958028915856

Epoch: 6| Step: 5
Training loss: 0.5093604629876166
Validation loss: 2.7451410861373367

Epoch: 6| Step: 6
Training loss: 0.46224921489584947
Validation loss: 2.6346460856812732

Epoch: 6| Step: 7
Training loss: 0.3827842779850276
Validation loss: 2.676196962163904

Epoch: 6| Step: 8
Training loss: 0.46162353799042516
Validation loss: 2.6986087785209993

Epoch: 6| Step: 9
Training loss: 0.3672032048539528
Validation loss: 2.7125684465834605

Epoch: 6| Step: 10
Training loss: 0.3581199915603944
Validation loss: 2.7191101800271573

Epoch: 6| Step: 11
Training loss: 0.46947299513376306
Validation loss: 2.728155900183748

Epoch: 6| Step: 12
Training loss: 0.4391181347172147
Validation loss: 2.6681665632975586

Epoch: 6| Step: 13
Training loss: 0.29286067240694824
Validation loss: 2.6862743303331102

Epoch: 331| Step: 0
Training loss: 0.6043230106592921
Validation loss: 2.7515090212227244

Epoch: 6| Step: 1
Training loss: 0.5133980140663972
Validation loss: 2.7182581591858352

Epoch: 6| Step: 2
Training loss: 0.25357841454732144
Validation loss: 2.7261472894139636

Epoch: 6| Step: 3
Training loss: 0.1305572381006991
Validation loss: 2.6606979378758537

Epoch: 6| Step: 4
Training loss: 0.31554611466635635
Validation loss: 2.64170856552912

Epoch: 6| Step: 5
Training loss: 0.46015547022081504
Validation loss: 2.7442265652088045

Epoch: 6| Step: 6
Training loss: 0.43072031912275316
Validation loss: 2.7614158021771056

Epoch: 6| Step: 7
Training loss: 0.3404531605387116
Validation loss: 2.7462777319856335

Epoch: 6| Step: 8
Training loss: 0.4192380971350578
Validation loss: 2.708076286344391

Epoch: 6| Step: 9
Training loss: 0.4956997185147402
Validation loss: 2.654638317566383

Epoch: 6| Step: 10
Training loss: 0.45943714292427
Validation loss: 2.725280547792918

Epoch: 6| Step: 11
Training loss: 0.4033885833372954
Validation loss: 2.718492766155932

Epoch: 6| Step: 12
Training loss: 0.3071900566126628
Validation loss: 2.672851205699647

Epoch: 6| Step: 13
Training loss: 0.2825985868774673
Validation loss: 2.7123807350577525

Epoch: 332| Step: 0
Training loss: 0.44958461292262697
Validation loss: 2.7216983169923656

Epoch: 6| Step: 1
Training loss: 0.24561849752948164
Validation loss: 2.7488047429801026

Epoch: 6| Step: 2
Training loss: 0.4541104879835202
Validation loss: 2.679340084231945

Epoch: 6| Step: 3
Training loss: 0.420267610386321
Validation loss: 2.744626857628086

Epoch: 6| Step: 4
Training loss: 0.26012539150753006
Validation loss: 2.6794130353435457

Epoch: 6| Step: 5
Training loss: 0.4044207139095987
Validation loss: 2.695128533171082

Epoch: 6| Step: 6
Training loss: 0.4846403871582345
Validation loss: 2.695833916838483

Epoch: 6| Step: 7
Training loss: 0.4766903064885743
Validation loss: 2.69187982874522

Epoch: 6| Step: 8
Training loss: 0.3862851341712079
Validation loss: 2.7024480747547783

Epoch: 6| Step: 9
Training loss: 0.23961781257124246
Validation loss: 2.693276665708317

Epoch: 6| Step: 10
Training loss: 0.4781524214018188
Validation loss: 2.666232637508927

Epoch: 6| Step: 11
Training loss: 0.42524622628557596
Validation loss: 2.733838709964809

Epoch: 6| Step: 12
Training loss: 0.3787603392307137
Validation loss: 2.7087220182031224

Epoch: 6| Step: 13
Training loss: 0.5162759198015862
Validation loss: 2.7029001587132866

Epoch: 333| Step: 0
Training loss: 0.44447767072231725
Validation loss: 2.6830489537098536

Epoch: 6| Step: 1
Training loss: 0.4527000210147092
Validation loss: 2.6504241034188474

Epoch: 6| Step: 2
Training loss: 0.3170189282695831
Validation loss: 2.659761628295328

Epoch: 6| Step: 3
Training loss: 0.5292608664112922
Validation loss: 2.6934024695770176

Epoch: 6| Step: 4
Training loss: 0.2742835443789078
Validation loss: 2.7208104273331846

Epoch: 6| Step: 5
Training loss: 0.35993573767576215
Validation loss: 2.6571458839095534

Epoch: 6| Step: 6
Training loss: 0.399789423947043
Validation loss: 2.697999817930441

Epoch: 6| Step: 7
Training loss: 0.2718042643376746
Validation loss: 2.694659506898542

Epoch: 6| Step: 8
Training loss: 0.310309433283255
Validation loss: 2.7011983837519593

Epoch: 6| Step: 9
Training loss: 0.35452346033286936
Validation loss: 2.71287318005044

Epoch: 6| Step: 10
Training loss: 0.42088976362101804
Validation loss: 2.6983352149908124

Epoch: 6| Step: 11
Training loss: 0.32672524480872556
Validation loss: 2.6705773159953683

Epoch: 6| Step: 12
Training loss: 0.33217114138225
Validation loss: 2.761573625822535

Epoch: 6| Step: 13
Training loss: 0.521380296243543
Validation loss: 2.6944935314605534

Epoch: 334| Step: 0
Training loss: 0.3735117786546935
Validation loss: 2.7118290910881258

Epoch: 6| Step: 1
Training loss: 0.34794083209640997
Validation loss: 2.6772088913226018

Epoch: 6| Step: 2
Training loss: 0.3070161912831232
Validation loss: 2.6719047143187353

Epoch: 6| Step: 3
Training loss: 0.2946391613736739
Validation loss: 2.708760731547758

Epoch: 6| Step: 4
Training loss: 0.3243928809373462
Validation loss: 2.710215403663698

Epoch: 6| Step: 5
Training loss: 0.5073875116072954
Validation loss: 2.751657882097233

Epoch: 6| Step: 6
Training loss: 0.300094638241986
Validation loss: 2.7135584288291112

Epoch: 6| Step: 7
Training loss: 0.5130805321311763
Validation loss: 2.720440839368997

Epoch: 6| Step: 8
Training loss: 0.30591582633564407
Validation loss: 2.753228113536184

Epoch: 6| Step: 9
Training loss: 0.29875535016476507
Validation loss: 2.7572723882789285

Epoch: 6| Step: 10
Training loss: 0.37926470131942924
Validation loss: 2.7535205471763105

Epoch: 6| Step: 11
Training loss: 0.3730302777018422
Validation loss: 2.648224033391301

Epoch: 6| Step: 12
Training loss: 0.3326687135059294
Validation loss: 2.77188951874851

Epoch: 6| Step: 13
Training loss: 0.22537199006157363
Validation loss: 2.700404920944366

Epoch: 335| Step: 0
Training loss: 0.4166481331835965
Validation loss: 2.6940290850801767

Epoch: 6| Step: 1
Training loss: 0.27444218936007403
Validation loss: 2.697432652558711

Epoch: 6| Step: 2
Training loss: 0.36346531378606084
Validation loss: 2.7344203981536386

Epoch: 6| Step: 3
Training loss: 0.4560715960159745
Validation loss: 2.761886440511516

Epoch: 6| Step: 4
Training loss: 0.25827846899456586
Validation loss: 2.745129534914015

Epoch: 6| Step: 5
Training loss: 0.3974410668357177
Validation loss: 2.7859283632537615

Epoch: 6| Step: 6
Training loss: 0.37628389158352094
Validation loss: 2.6834720619149444

Epoch: 6| Step: 7
Training loss: 0.34175622970872044
Validation loss: 2.698014855285724

Epoch: 6| Step: 8
Training loss: 0.42928746415324065
Validation loss: 2.7932471930150795

Epoch: 6| Step: 9
Training loss: 0.38744053768955383
Validation loss: 2.7468154125383206

Epoch: 6| Step: 10
Training loss: 0.3815440943134813
Validation loss: 2.6754796955752336

Epoch: 6| Step: 11
Training loss: 0.32972430841791484
Validation loss: 2.755456063587737

Epoch: 6| Step: 12
Training loss: 0.2529045004068273
Validation loss: 2.715567673874472

Epoch: 6| Step: 13
Training loss: 0.32275544135901596
Validation loss: 2.712284365519465

Epoch: 336| Step: 0
Training loss: 0.5391551504816526
Validation loss: 2.7845544508203344

Epoch: 6| Step: 1
Training loss: 0.3208746280764604
Validation loss: 2.688462299494305

Epoch: 6| Step: 2
Training loss: 0.35955880481844277
Validation loss: 2.755004519524072

Epoch: 6| Step: 3
Training loss: 0.2947151267814205
Validation loss: 2.675938570544404

Epoch: 6| Step: 4
Training loss: 0.4154382199952205
Validation loss: 2.6597508491743995

Epoch: 6| Step: 5
Training loss: 0.4413240069175096
Validation loss: 2.7716194748965988

Epoch: 6| Step: 6
Training loss: 0.43693222942619303
Validation loss: 2.7536823154604035

Epoch: 6| Step: 7
Training loss: 0.29048929686616615
Validation loss: 2.7586509143369775

Epoch: 6| Step: 8
Training loss: 0.31353136575872187
Validation loss: 2.6753805709785854

Epoch: 6| Step: 9
Training loss: 0.3824041290374018
Validation loss: 2.6952704827171066

Epoch: 6| Step: 10
Training loss: 0.6107562623142101
Validation loss: 2.6513839430774273

Epoch: 6| Step: 11
Training loss: 0.34813233256536474
Validation loss: 2.606288599815523

Epoch: 6| Step: 12
Training loss: 0.37794261979246374
Validation loss: 2.63886827048116

Epoch: 6| Step: 13
Training loss: 0.39332549281643764
Validation loss: 2.621092840384995

Epoch: 337| Step: 0
Training loss: 0.3555648799487355
Validation loss: 2.6597409813476403

Epoch: 6| Step: 1
Training loss: 0.4009844028990327
Validation loss: 2.62145980651405

Epoch: 6| Step: 2
Training loss: 0.683367969829151
Validation loss: 2.69695520145455

Epoch: 6| Step: 3
Training loss: 0.5018880482802831
Validation loss: 2.708016484628762

Epoch: 6| Step: 4
Training loss: 0.4153285733421423
Validation loss: 2.651362706339253

Epoch: 6| Step: 5
Training loss: 0.469031662559493
Validation loss: 2.653280797726614

Epoch: 6| Step: 6
Training loss: 0.2304759671002576
Validation loss: 2.672629028764504

Epoch: 6| Step: 7
Training loss: 0.40040588349831924
Validation loss: 2.6894553707854945

Epoch: 6| Step: 8
Training loss: 0.39402475988582725
Validation loss: 2.658257357987514

Epoch: 6| Step: 9
Training loss: 0.3849870073925268
Validation loss: 2.6617643674317777

Epoch: 6| Step: 10
Training loss: 0.43778801701859943
Validation loss: 2.70857228667722

Epoch: 6| Step: 11
Training loss: 0.4179719764371035
Validation loss: 2.6561259371638433

Epoch: 6| Step: 12
Training loss: 0.3832055817971524
Validation loss: 2.6863832741100615

Epoch: 6| Step: 13
Training loss: 0.3675234657697738
Validation loss: 2.7146248562248285

Epoch: 338| Step: 0
Training loss: 0.444390631023898
Validation loss: 2.6702104257680235

Epoch: 6| Step: 1
Training loss: 0.33513231036356267
Validation loss: 2.8494589515117252

Epoch: 6| Step: 2
Training loss: 0.44033064648479653
Validation loss: 2.7471594228167815

Epoch: 6| Step: 3
Training loss: 0.37137609080921935
Validation loss: 2.725025315706676

Epoch: 6| Step: 4
Training loss: 0.3955446390973706
Validation loss: 2.764525875787117

Epoch: 6| Step: 5
Training loss: 0.48203898691061253
Validation loss: 2.6801416514572542

Epoch: 6| Step: 6
Training loss: 0.3163487417446561
Validation loss: 2.7493911271411053

Epoch: 6| Step: 7
Training loss: 0.3971641988694946
Validation loss: 2.8180091448198477

Epoch: 6| Step: 8
Training loss: 0.42004022039542804
Validation loss: 2.7079980178034075

Epoch: 6| Step: 9
Training loss: 0.6757201459304186
Validation loss: 2.7149534500608876

Epoch: 6| Step: 10
Training loss: 0.3977272772169732
Validation loss: 2.6715954639928046

Epoch: 6| Step: 11
Training loss: 0.4075570537844983
Validation loss: 2.6781151313258653

Epoch: 6| Step: 12
Training loss: 0.4840659724702644
Validation loss: 2.7918542732475378

Epoch: 6| Step: 13
Training loss: 0.29364850340178794
Validation loss: 2.7111660057600644

Epoch: 339| Step: 0
Training loss: 0.4354536187616288
Validation loss: 2.7008556770248706

Epoch: 6| Step: 1
Training loss: 0.4029987521945009
Validation loss: 2.6651209409443175

Epoch: 6| Step: 2
Training loss: 0.3302680377755665
Validation loss: 2.7030442212921613

Epoch: 6| Step: 3
Training loss: 0.32673267876640505
Validation loss: 2.725715673300542

Epoch: 6| Step: 4
Training loss: 0.3585470655383176
Validation loss: 2.644105802841997

Epoch: 6| Step: 5
Training loss: 0.3649676567928137
Validation loss: 2.6754189053343755

Epoch: 6| Step: 6
Training loss: 0.5311157112934338
Validation loss: 2.700603963270756

Epoch: 6| Step: 7
Training loss: 0.481637618402779
Validation loss: 2.7354913521705915

Epoch: 6| Step: 8
Training loss: 0.46469084845582614
Validation loss: 2.6863911285415596

Epoch: 6| Step: 9
Training loss: 0.7556913913686244
Validation loss: 2.685728331937844

Epoch: 6| Step: 10
Training loss: 0.22021044538550327
Validation loss: 2.7351410437601333

Epoch: 6| Step: 11
Training loss: 0.27241519831184563
Validation loss: 2.6913768026644633

Epoch: 6| Step: 12
Training loss: 0.24767216592181632
Validation loss: 2.721645815369001

Epoch: 6| Step: 13
Training loss: 0.32100207837046946
Validation loss: 2.716068231358561

Epoch: 340| Step: 0
Training loss: 0.3902730309754691
Validation loss: 2.768729226039455

Epoch: 6| Step: 1
Training loss: 0.43595661681997094
Validation loss: 2.6440774743343254

Epoch: 6| Step: 2
Training loss: 0.3530856093658263
Validation loss: 2.6854664701505127

Epoch: 6| Step: 3
Training loss: 0.4431661445229161
Validation loss: 2.734520172625064

Epoch: 6| Step: 4
Training loss: 0.4053318211428978
Validation loss: 2.6240470912611626

Epoch: 6| Step: 5
Training loss: 0.3944880206908567
Validation loss: 2.6984004368801764

Epoch: 6| Step: 6
Training loss: 0.4462958738111927
Validation loss: 2.6838585853848738

Epoch: 6| Step: 7
Training loss: 0.23912362987616334
Validation loss: 2.6884749218886883

Epoch: 6| Step: 8
Training loss: 0.34135226078139697
Validation loss: 2.7517726704561896

Epoch: 6| Step: 9
Training loss: 0.3006076311657394
Validation loss: 2.7748615316262355

Epoch: 6| Step: 10
Training loss: 0.42779411699967956
Validation loss: 2.7372850028836453

Epoch: 6| Step: 11
Training loss: 0.4856096805576581
Validation loss: 2.7159799663533324

Epoch: 6| Step: 12
Training loss: 0.39038437107551216
Validation loss: 2.7551305551974403

Epoch: 6| Step: 13
Training loss: 0.2728938693190355
Validation loss: 2.7857117885769376

Epoch: 341| Step: 0
Training loss: 0.3409951971868091
Validation loss: 2.686285690868127

Epoch: 6| Step: 1
Training loss: 0.4305125724793084
Validation loss: 2.7515987026324855

Epoch: 6| Step: 2
Training loss: 0.4344647740141881
Validation loss: 2.792075373969332

Epoch: 6| Step: 3
Training loss: 0.4252853830845724
Validation loss: 2.7952130883729813

Epoch: 6| Step: 4
Training loss: 0.3198714825599653
Validation loss: 2.701660435704885

Epoch: 6| Step: 5
Training loss: 0.3337110773171319
Validation loss: 2.7234458271015303

Epoch: 6| Step: 6
Training loss: 0.4142782980508771
Validation loss: 2.619062846880566

Epoch: 6| Step: 7
Training loss: 0.35662993783804847
Validation loss: 2.7426729995145678

Epoch: 6| Step: 8
Training loss: 0.5306089685037985
Validation loss: 2.70843952166409

Epoch: 6| Step: 9
Training loss: 0.3972341279303405
Validation loss: 2.707281191958372

Epoch: 6| Step: 10
Training loss: 0.3758264018827201
Validation loss: 2.7346222974574355

Epoch: 6| Step: 11
Training loss: 0.42170803863502027
Validation loss: 2.6979673569874625

Epoch: 6| Step: 12
Training loss: 0.46337993529258764
Validation loss: 2.68217541464324

Epoch: 6| Step: 13
Training loss: 0.3922466947709258
Validation loss: 2.690581130180749

Epoch: 342| Step: 0
Training loss: 0.37712506340843127
Validation loss: 2.7226682906247164

Epoch: 6| Step: 1
Training loss: 0.3430904867536671
Validation loss: 2.7096407131208684

Epoch: 6| Step: 2
Training loss: 0.33968676306426154
Validation loss: 2.706410155575317

Epoch: 6| Step: 3
Training loss: 0.608908156542966
Validation loss: 2.642678622834476

Epoch: 6| Step: 4
Training loss: 0.35433948264852316
Validation loss: 2.6847734889002193

Epoch: 6| Step: 5
Training loss: 0.5202844938696842
Validation loss: 2.6487964998213855

Epoch: 6| Step: 6
Training loss: 0.4182281402283927
Validation loss: 2.6040695757250765

Epoch: 6| Step: 7
Training loss: 0.40773805106808847
Validation loss: 2.726916693678278

Epoch: 6| Step: 8
Training loss: 0.3831508075802673
Validation loss: 2.684281129272647

Epoch: 6| Step: 9
Training loss: 0.39571838424799466
Validation loss: 2.751171758296873

Epoch: 6| Step: 10
Training loss: 0.2886681057034789
Validation loss: 2.7207423543007376

Epoch: 6| Step: 11
Training loss: 0.36285703768476546
Validation loss: 2.719083904355579

Epoch: 6| Step: 12
Training loss: 0.3713935644786234
Validation loss: 2.6751230437361597

Epoch: 6| Step: 13
Training loss: 0.44216789094290765
Validation loss: 2.6470699249036866

Epoch: 343| Step: 0
Training loss: 0.3815315574890342
Validation loss: 2.6758287931427702

Epoch: 6| Step: 1
Training loss: 0.42015486175432604
Validation loss: 2.765355601722584

Epoch: 6| Step: 2
Training loss: 0.32122342908939616
Validation loss: 2.662215934369016

Epoch: 6| Step: 3
Training loss: 0.3579802190840688
Validation loss: 2.7049779917044363

Epoch: 6| Step: 4
Training loss: 0.4281444934945712
Validation loss: 2.671163988598528

Epoch: 6| Step: 5
Training loss: 0.33838924375654555
Validation loss: 2.7533788658522855

Epoch: 6| Step: 6
Training loss: 0.5439099449288642
Validation loss: 2.714929666234561

Epoch: 6| Step: 7
Training loss: 0.4968505553464424
Validation loss: 2.7519034964872

Epoch: 6| Step: 8
Training loss: 0.45871713853224655
Validation loss: 2.7255586235293316

Epoch: 6| Step: 9
Training loss: 0.544504094370291
Validation loss: 2.7186634225323965

Epoch: 6| Step: 10
Training loss: 0.3796988387435946
Validation loss: 2.7388919035147206

Epoch: 6| Step: 11
Training loss: 0.46074868230377725
Validation loss: 2.7793916501586673

Epoch: 6| Step: 12
Training loss: 0.4396163806726537
Validation loss: 2.722469241316184

Epoch: 6| Step: 13
Training loss: 0.2948467841141353
Validation loss: 2.6412546584639935

Epoch: 344| Step: 0
Training loss: 0.4993295943489877
Validation loss: 2.710607906243969

Epoch: 6| Step: 1
Training loss: 0.3945089277241155
Validation loss: 2.619992323687036

Epoch: 6| Step: 2
Training loss: 0.44475384855937167
Validation loss: 2.6862272013505475

Epoch: 6| Step: 3
Training loss: 0.37890440163702277
Validation loss: 2.6672564961873375

Epoch: 6| Step: 4
Training loss: 0.35936365938952003
Validation loss: 2.670326706379942

Epoch: 6| Step: 5
Training loss: 0.36602644278418667
Validation loss: 2.715978005851566

Epoch: 6| Step: 6
Training loss: 0.24761613105708638
Validation loss: 2.6861400638082014

Epoch: 6| Step: 7
Training loss: 0.5719285825214052
Validation loss: 2.6747345819439814

Epoch: 6| Step: 8
Training loss: 0.2985165411449152
Validation loss: 2.715266952644834

Epoch: 6| Step: 9
Training loss: 0.4039673683365378
Validation loss: 2.7610835343494777

Epoch: 6| Step: 10
Training loss: 0.28382770461648
Validation loss: 2.7277697319832326

Epoch: 6| Step: 11
Training loss: 0.27476373298173656
Validation loss: 2.761297917800026

Epoch: 6| Step: 12
Training loss: 0.2758487651192297
Validation loss: 2.771547703448461

Epoch: 6| Step: 13
Training loss: 0.32525290589203654
Validation loss: 2.642837259838864

Epoch: 345| Step: 0
Training loss: 0.4804287405335805
Validation loss: 2.725527329123991

Epoch: 6| Step: 1
Training loss: 0.4387904617476076
Validation loss: 2.755753841132267

Epoch: 6| Step: 2
Training loss: 0.31035838614777134
Validation loss: 2.6769579451075183

Epoch: 6| Step: 3
Training loss: 0.34888569825559246
Validation loss: 2.7730060510442107

Epoch: 6| Step: 4
Training loss: 0.2633339305661668
Validation loss: 2.6570016732383497

Epoch: 6| Step: 5
Training loss: 0.32881135908232345
Validation loss: 2.698452993178017

Epoch: 6| Step: 6
Training loss: 0.4686819980886963
Validation loss: 2.7036116057313753

Epoch: 6| Step: 7
Training loss: 0.49130986698222984
Validation loss: 2.696178042990671

Epoch: 6| Step: 8
Training loss: 0.3163076176382457
Validation loss: 2.7003834369743465

Epoch: 6| Step: 9
Training loss: 0.3466078240499571
Validation loss: 2.733646390207657

Epoch: 6| Step: 10
Training loss: 0.498434133129647
Validation loss: 2.757625742812406

Epoch: 6| Step: 11
Training loss: 0.3848071390596077
Validation loss: 2.7754640079598016

Epoch: 6| Step: 12
Training loss: 0.16497897572303022
Validation loss: 2.6996157658292996

Epoch: 6| Step: 13
Training loss: 0.3926134805273754
Validation loss: 2.744007821450055

Epoch: 346| Step: 0
Training loss: 0.4702159687476401
Validation loss: 2.720186825792106

Epoch: 6| Step: 1
Training loss: 0.2599254346029925
Validation loss: 2.689453730771272

Epoch: 6| Step: 2
Training loss: 0.41796081749349573
Validation loss: 2.6897934952427995

Epoch: 6| Step: 3
Training loss: 0.41263106171397446
Validation loss: 2.667198811026428

Epoch: 6| Step: 4
Training loss: 0.3975776294863329
Validation loss: 2.6887714276478953

Epoch: 6| Step: 5
Training loss: 0.3546701200150989
Validation loss: 2.773287429689492

Epoch: 6| Step: 6
Training loss: 0.24464778103984752
Validation loss: 2.671566988199441

Epoch: 6| Step: 7
Training loss: 0.48013101508343536
Validation loss: 2.6303795837450386

Epoch: 6| Step: 8
Training loss: 0.32127269019063237
Validation loss: 2.7349197571656783

Epoch: 6| Step: 9
Training loss: 0.3364839877198778
Validation loss: 2.642254486528213

Epoch: 6| Step: 10
Training loss: 0.34837982872243445
Validation loss: 2.6711936810747283

Epoch: 6| Step: 11
Training loss: 0.19731137717685457
Validation loss: 2.6524939590490777

Epoch: 6| Step: 12
Training loss: 0.4094435175856876
Validation loss: 2.6495233670934573

Epoch: 6| Step: 13
Training loss: 0.37348145740957217
Validation loss: 2.71225477126776

Epoch: 347| Step: 0
Training loss: 0.396004917784942
Validation loss: 2.730253968821051

Epoch: 6| Step: 1
Training loss: 0.36771571941720266
Validation loss: 2.746016861701516

Epoch: 6| Step: 2
Training loss: 0.31432127705894114
Validation loss: 2.6563204737271535

Epoch: 6| Step: 3
Training loss: 0.5747702668305764
Validation loss: 2.712560645976863

Epoch: 6| Step: 4
Training loss: 0.34805121114065535
Validation loss: 2.694018745440218

Epoch: 6| Step: 5
Training loss: 0.3532326340155971
Validation loss: 2.7104829669166923

Epoch: 6| Step: 6
Training loss: 0.39330342414795055
Validation loss: 2.706713005907925

Epoch: 6| Step: 7
Training loss: 0.37353240367398804
Validation loss: 2.6651099896710595

Epoch: 6| Step: 8
Training loss: 0.42170918702925286
Validation loss: 2.6547624274702777

Epoch: 6| Step: 9
Training loss: 0.4095550854444149
Validation loss: 2.6411961045117027

Epoch: 6| Step: 10
Training loss: 0.29683218195472555
Validation loss: 2.664732698653933

Epoch: 6| Step: 11
Training loss: 0.37766187380358535
Validation loss: 2.7079699394768304

Epoch: 6| Step: 12
Training loss: 0.5696966948737595
Validation loss: 2.7202000751960655

Epoch: 6| Step: 13
Training loss: 0.27678181578488004
Validation loss: 2.6826477456386204

Epoch: 348| Step: 0
Training loss: 0.44640123556095984
Validation loss: 2.6945939437667534

Epoch: 6| Step: 1
Training loss: 0.3160747156903612
Validation loss: 2.6861111208856427

Epoch: 6| Step: 2
Training loss: 0.27221411459931316
Validation loss: 2.680926734270401

Epoch: 6| Step: 3
Training loss: 0.40922331292928327
Validation loss: 2.6835841993581186

Epoch: 6| Step: 4
Training loss: 0.3480012874524647
Validation loss: 2.7204868717242583

Epoch: 6| Step: 5
Training loss: 0.34593710012852164
Validation loss: 2.6403960179472694

Epoch: 6| Step: 6
Training loss: 0.49120922353760216
Validation loss: 2.645955636108857

Epoch: 6| Step: 7
Training loss: 0.38319070778423214
Validation loss: 2.7260508526326728

Epoch: 6| Step: 8
Training loss: 0.3460880765600593
Validation loss: 2.6619030132433377

Epoch: 6| Step: 9
Training loss: 0.4482160905542223
Validation loss: 2.748148923712942

Epoch: 6| Step: 10
Training loss: 0.2934691669411186
Validation loss: 2.6849910794423084

Epoch: 6| Step: 11
Training loss: 0.4740483457027669
Validation loss: 2.68040834746297

Epoch: 6| Step: 12
Training loss: 0.4201505171617718
Validation loss: 2.6970781375766797

Epoch: 6| Step: 13
Training loss: 0.43866052995042143
Validation loss: 2.7153886499774638

Epoch: 349| Step: 0
Training loss: 0.5451289504725282
Validation loss: 2.6902865372344875

Epoch: 6| Step: 1
Training loss: 0.41611046224989734
Validation loss: 2.738262312493026

Epoch: 6| Step: 2
Training loss: 0.3332699278291203
Validation loss: 2.734625225425344

Epoch: 6| Step: 3
Training loss: 0.42015200674142283
Validation loss: 2.762545075775217

Epoch: 6| Step: 4
Training loss: 0.3975811150997414
Validation loss: 2.7837113194204215

Epoch: 6| Step: 5
Training loss: 0.44787897091829165
Validation loss: 2.678853371329042

Epoch: 6| Step: 6
Training loss: 0.492803112925143
Validation loss: 2.726741431485144

Epoch: 6| Step: 7
Training loss: 0.4029784150460313
Validation loss: 2.656033473445906

Epoch: 6| Step: 8
Training loss: 0.4004839160442234
Validation loss: 2.685450785449506

Epoch: 6| Step: 9
Training loss: 0.3009563778415825
Validation loss: 2.6124168376675736

Epoch: 6| Step: 10
Training loss: 0.43391983554934027
Validation loss: 2.697577088143968

Epoch: 6| Step: 11
Training loss: 0.4018404507061418
Validation loss: 2.730415347354298

Epoch: 6| Step: 12
Training loss: 0.32618740752921077
Validation loss: 2.7718571633299405

Epoch: 6| Step: 13
Training loss: 0.41097729566378355
Validation loss: 2.7102393901377884

Epoch: 350| Step: 0
Training loss: 0.48354787347018513
Validation loss: 2.7531453986680527

Epoch: 6| Step: 1
Training loss: 0.45003061322880455
Validation loss: 2.6640538637798756

Epoch: 6| Step: 2
Training loss: 0.3435520122135479
Validation loss: 2.673356104878246

Epoch: 6| Step: 3
Training loss: 0.22801724723992212
Validation loss: 2.730420448265288

Epoch: 6| Step: 4
Training loss: 0.5703230556399544
Validation loss: 2.6917701183630265

Epoch: 6| Step: 5
Training loss: 0.4254790467281696
Validation loss: 2.6804331121222367

Epoch: 6| Step: 6
Training loss: 0.3606499157897944
Validation loss: 2.729764411831163

Epoch: 6| Step: 7
Training loss: 0.38820917776958397
Validation loss: 2.6739530011728103

Epoch: 6| Step: 8
Training loss: 0.3296155001226496
Validation loss: 2.7580599002977015

Epoch: 6| Step: 9
Training loss: 0.35087059599338255
Validation loss: 2.6784597091991325

Epoch: 6| Step: 10
Training loss: 0.38190363993532
Validation loss: 2.7416505931008177

Epoch: 6| Step: 11
Training loss: 0.3801167216605352
Validation loss: 2.6272767350967348

Epoch: 6| Step: 12
Training loss: 0.35785960924295546
Validation loss: 2.6804481071938113

Epoch: 6| Step: 13
Training loss: 0.38720185515707095
Validation loss: 2.695917992144503

Epoch: 351| Step: 0
Training loss: 0.2870703949709504
Validation loss: 2.7462685295617733

Epoch: 6| Step: 1
Training loss: 0.34361587421959083
Validation loss: 2.6874733413438654

Epoch: 6| Step: 2
Training loss: 0.3534375520768536
Validation loss: 2.693733158044171

Epoch: 6| Step: 3
Training loss: 0.3433927500261072
Validation loss: 2.606772550772229

Epoch: 6| Step: 4
Training loss: 0.3014341797848498
Validation loss: 2.7001757252576564

Epoch: 6| Step: 5
Training loss: 0.36773393431994306
Validation loss: 2.690920811370546

Epoch: 6| Step: 6
Training loss: 0.35377947829394
Validation loss: 2.7324125822834966

Epoch: 6| Step: 7
Training loss: 0.5135720739847544
Validation loss: 2.7106855643668037

Epoch: 6| Step: 8
Training loss: 0.3957656208480961
Validation loss: 2.647209145187985

Epoch: 6| Step: 9
Training loss: 0.3790219120583478
Validation loss: 2.7377979325463295

Epoch: 6| Step: 10
Training loss: 0.39933291032866386
Validation loss: 2.7402471286932766

Epoch: 6| Step: 11
Training loss: 0.36565436220867636
Validation loss: 2.7234619057824414

Epoch: 6| Step: 12
Training loss: 0.3834531444787226
Validation loss: 2.736305180448206

Epoch: 6| Step: 13
Training loss: 0.5713616219112126
Validation loss: 2.736275381287414

Epoch: 352| Step: 0
Training loss: 0.29218597105717586
Validation loss: 2.690320745109809

Epoch: 6| Step: 1
Training loss: 0.3482990751158914
Validation loss: 2.7557419450677867

Epoch: 6| Step: 2
Training loss: 0.24591503011580565
Validation loss: 2.6727856948610356

Epoch: 6| Step: 3
Training loss: 0.41209469448174313
Validation loss: 2.6525670118193396

Epoch: 6| Step: 4
Training loss: 0.6079555019640144
Validation loss: 2.7066648234359527

Epoch: 6| Step: 5
Training loss: 0.3613949481930328
Validation loss: 2.7310310770690305

Epoch: 6| Step: 6
Training loss: 0.3769573349791723
Validation loss: 2.7191036476675605

Epoch: 6| Step: 7
Training loss: 0.24822080326491772
Validation loss: 2.69891567709363

Epoch: 6| Step: 8
Training loss: 0.48067032842105506
Validation loss: 2.7251993905476666

Epoch: 6| Step: 9
Training loss: 0.4812893256926763
Validation loss: 2.6208687546908327

Epoch: 6| Step: 10
Training loss: 0.3570000707922793
Validation loss: 2.712878028322237

Epoch: 6| Step: 11
Training loss: 0.33690272878850663
Validation loss: 2.735374500523952

Epoch: 6| Step: 12
Training loss: 0.20746657649546613
Validation loss: 2.7074764852538826

Epoch: 6| Step: 13
Training loss: 0.2979437763488493
Validation loss: 2.73382033035658

Epoch: 353| Step: 0
Training loss: 0.36180042638252735
Validation loss: 2.710115284233037

Epoch: 6| Step: 1
Training loss: 0.30720869522861566
Validation loss: 2.715176934670215

Epoch: 6| Step: 2
Training loss: 0.2858304975237365
Validation loss: 2.6558951047287587

Epoch: 6| Step: 3
Training loss: 0.4899759105191018
Validation loss: 2.757790814855688

Epoch: 6| Step: 4
Training loss: 0.21668577354498175
Validation loss: 2.72956435142846

Epoch: 6| Step: 5
Training loss: 0.405148939750091
Validation loss: 2.684442237008982

Epoch: 6| Step: 6
Training loss: 0.3111015979460949
Validation loss: 2.7000911423523433

Epoch: 6| Step: 7
Training loss: 0.3735276165369579
Validation loss: 2.7906787936902027

Epoch: 6| Step: 8
Training loss: 0.4606321099041857
Validation loss: 2.7049722111391596

Epoch: 6| Step: 9
Training loss: 0.38238828860309415
Validation loss: 2.7034988732772725

Epoch: 6| Step: 10
Training loss: 0.2650980771957335
Validation loss: 2.603275571317451

Epoch: 6| Step: 11
Training loss: 0.39885581253893077
Validation loss: 2.7150177458481157

Epoch: 6| Step: 12
Training loss: 0.26415269597883845
Validation loss: 2.7527660128610103

Epoch: 6| Step: 13
Training loss: 0.28410291126213766
Validation loss: 2.6330305060167123

Epoch: 354| Step: 0
Training loss: 0.3520609183578138
Validation loss: 2.6880565037559845

Epoch: 6| Step: 1
Training loss: 0.26206715012019904
Validation loss: 2.6586137912655117

Epoch: 6| Step: 2
Training loss: 0.385048447663205
Validation loss: 2.77684548044552

Epoch: 6| Step: 3
Training loss: 0.5582183696995602
Validation loss: 2.68848792850943

Epoch: 6| Step: 4
Training loss: 0.36669576468028287
Validation loss: 2.689978114988035

Epoch: 6| Step: 5
Training loss: 0.4325612120226803
Validation loss: 2.6441968878329325

Epoch: 6| Step: 6
Training loss: 0.27890289635872595
Validation loss: 2.734449440079084

Epoch: 6| Step: 7
Training loss: 0.216904905398309
Validation loss: 2.7142278397994084

Epoch: 6| Step: 8
Training loss: 0.2554158888089863
Validation loss: 2.6476420930716755

Epoch: 6| Step: 9
Training loss: 0.4568647912916189
Validation loss: 2.7199899469451623

Epoch: 6| Step: 10
Training loss: 0.39540780769342204
Validation loss: 2.704882790757869

Epoch: 6| Step: 11
Training loss: 0.3411427369110679
Validation loss: 2.708375201757518

Epoch: 6| Step: 12
Training loss: 0.35566328824758703
Validation loss: 2.7061319990619537

Epoch: 6| Step: 13
Training loss: 0.42727734260722644
Validation loss: 2.7331743056470876

Epoch: 355| Step: 0
Training loss: 0.33752514251023336
Validation loss: 2.6938735585445084

Epoch: 6| Step: 1
Training loss: 0.323914086007389
Validation loss: 2.7028485930434414

Epoch: 6| Step: 2
Training loss: 0.31239507821146456
Validation loss: 2.6742752775027228

Epoch: 6| Step: 3
Training loss: 0.4998505637255092
Validation loss: 2.7286533620407316

Epoch: 6| Step: 4
Training loss: 0.3066592970101642
Validation loss: 2.6676177822138314

Epoch: 6| Step: 5
Training loss: 0.2964615201119776
Validation loss: 2.7184703288435004

Epoch: 6| Step: 6
Training loss: 0.3881777972862236
Validation loss: 2.7625194146119942

Epoch: 6| Step: 7
Training loss: 0.4119163712083664
Validation loss: 2.7598232543140497

Epoch: 6| Step: 8
Training loss: 0.2407803882135395
Validation loss: 2.6975417938388735

Epoch: 6| Step: 9
Training loss: 0.3358987076118662
Validation loss: 2.6956359669183447

Epoch: 6| Step: 10
Training loss: 0.3241738782418033
Validation loss: 2.7356842103865593

Epoch: 6| Step: 11
Training loss: 0.33112895886382837
Validation loss: 2.6536481194054238

Epoch: 6| Step: 12
Training loss: 0.3890808867127527
Validation loss: 2.636742380295347

Epoch: 6| Step: 13
Training loss: 0.43184355026429316
Validation loss: 2.6728367552453385

Epoch: 356| Step: 0
Training loss: 0.34904487684905655
Validation loss: 2.7073117065470798

Epoch: 6| Step: 1
Training loss: 0.40602371442647767
Validation loss: 2.7455560583763154

Epoch: 6| Step: 2
Training loss: 0.4383957072518572
Validation loss: 2.7075570583465964

Epoch: 6| Step: 3
Training loss: 0.3413780698341394
Validation loss: 2.7638537954746822

Epoch: 6| Step: 4
Training loss: 0.3094880268472538
Validation loss: 2.69435647419957

Epoch: 6| Step: 5
Training loss: 0.45384483053174246
Validation loss: 2.72865999532074

Epoch: 6| Step: 6
Training loss: 0.38510411279107193
Validation loss: 2.702287717004676

Epoch: 6| Step: 7
Training loss: 0.2982842101624139
Validation loss: 2.7312603168307246

Epoch: 6| Step: 8
Training loss: 0.3077599451540575
Validation loss: 2.8140447965859723

Epoch: 6| Step: 9
Training loss: 0.35157690018725807
Validation loss: 2.7474449454644128

Epoch: 6| Step: 10
Training loss: 0.3686273427405669
Validation loss: 2.7388699162281536

Epoch: 6| Step: 11
Training loss: 0.32601468073079465
Validation loss: 2.7191851841277255

Epoch: 6| Step: 12
Training loss: 0.39997455098734785
Validation loss: 2.748528505878509

Epoch: 6| Step: 13
Training loss: 0.3908509745239332
Validation loss: 2.6371353988180855

Epoch: 357| Step: 0
Training loss: 0.4122658021372403
Validation loss: 2.6861378818200534

Epoch: 6| Step: 1
Training loss: 0.3777430662557674
Validation loss: 2.67121708077458

Epoch: 6| Step: 2
Training loss: 0.3407237181096192
Validation loss: 2.7068824451936915

Epoch: 6| Step: 3
Training loss: 0.26751464591975943
Validation loss: 2.7595184208256884

Epoch: 6| Step: 4
Training loss: 0.49895954656221175
Validation loss: 2.7385958836817177

Epoch: 6| Step: 5
Training loss: 0.23259809369212572
Validation loss: 2.7467062905919417

Epoch: 6| Step: 6
Training loss: 0.39859435789868675
Validation loss: 2.710359539238235

Epoch: 6| Step: 7
Training loss: 0.39001294823695337
Validation loss: 2.7281475833804354

Epoch: 6| Step: 8
Training loss: 0.45551135353025124
Validation loss: 2.69525942542853

Epoch: 6| Step: 9
Training loss: 0.44635820583562014
Validation loss: 2.6569545783765656

Epoch: 6| Step: 10
Training loss: 0.33273281701630747
Validation loss: 2.6423769073303798

Epoch: 6| Step: 11
Training loss: 0.5768700459144608
Validation loss: 2.742028162023033

Epoch: 6| Step: 12
Training loss: 0.475008086712916
Validation loss: 2.6272410106204465

Epoch: 6| Step: 13
Training loss: 0.2902859879368957
Validation loss: 2.6257210604015295

Epoch: 358| Step: 0
Training loss: 0.26690447021469815
Validation loss: 2.700539471455592

Epoch: 6| Step: 1
Training loss: 0.37471514055048505
Validation loss: 2.6496744258783163

Epoch: 6| Step: 2
Training loss: 0.32692737227256896
Validation loss: 2.674571143738278

Epoch: 6| Step: 3
Training loss: 0.6301156256927551
Validation loss: 2.700988910442788

Epoch: 6| Step: 4
Training loss: 0.2111993418424775
Validation loss: 2.6682330364134947

Epoch: 6| Step: 5
Training loss: 0.5270561847052837
Validation loss: 2.737579197659726

Epoch: 6| Step: 6
Training loss: 0.3621432209348961
Validation loss: 2.677086653255873

Epoch: 6| Step: 7
Training loss: 0.5046348626999287
Validation loss: 2.666502475650825

Epoch: 6| Step: 8
Training loss: 0.47639265316896146
Validation loss: 2.677294805662083

Epoch: 6| Step: 9
Training loss: 0.2468153048423806
Validation loss: 2.7024368850908576

Epoch: 6| Step: 10
Training loss: 0.39914065379129404
Validation loss: 2.696435475107508

Epoch: 6| Step: 11
Training loss: 0.31749129568768986
Validation loss: 2.619280715370513

Epoch: 6| Step: 12
Training loss: 0.2601963430446392
Validation loss: 2.6754742003011827

Epoch: 6| Step: 13
Training loss: 0.35494789278399286
Validation loss: 2.6786255655418794

Epoch: 359| Step: 0
Training loss: 0.29723904274026336
Validation loss: 2.7237301956444147

Epoch: 6| Step: 1
Training loss: 0.37768059538028714
Validation loss: 2.696769062789054

Epoch: 6| Step: 2
Training loss: 0.3626747606213698
Validation loss: 2.700493187365867

Epoch: 6| Step: 3
Training loss: 0.3488835306795538
Validation loss: 2.677180133855607

Epoch: 6| Step: 4
Training loss: 0.32685305797097014
Validation loss: 2.653185726230148

Epoch: 6| Step: 5
Training loss: 0.4138599476129267
Validation loss: 2.688844048986157

Epoch: 6| Step: 6
Training loss: 0.32257598035510116
Validation loss: 2.649610719038851

Epoch: 6| Step: 7
Training loss: 0.3339287784100759
Validation loss: 2.739893853366041

Epoch: 6| Step: 8
Training loss: 0.44683930848046705
Validation loss: 2.7270005246833247

Epoch: 6| Step: 9
Training loss: 0.35145902170424026
Validation loss: 2.7094398927818752

Epoch: 6| Step: 10
Training loss: 0.35744217778476906
Validation loss: 2.631067356043911

Epoch: 6| Step: 11
Training loss: 0.31364576580224673
Validation loss: 2.69680055093389

Epoch: 6| Step: 12
Training loss: 0.4944516134397198
Validation loss: 2.6138820898319164

Epoch: 6| Step: 13
Training loss: 0.39086708196971137
Validation loss: 2.674983746191063

Epoch: 360| Step: 0
Training loss: 0.22805437993726096
Validation loss: 2.6160885757437344

Epoch: 6| Step: 1
Training loss: 0.35577940728033275
Validation loss: 2.672103277199705

Epoch: 6| Step: 2
Training loss: 0.3153226806728627
Validation loss: 2.6486267877412746

Epoch: 6| Step: 3
Training loss: 0.35887339041736593
Validation loss: 2.678768397007136

Epoch: 6| Step: 4
Training loss: 0.2708138755386602
Validation loss: 2.663277876861039

Epoch: 6| Step: 5
Training loss: 0.34514535207195435
Validation loss: 2.670962514346967

Epoch: 6| Step: 6
Training loss: 0.36535781161648345
Validation loss: 2.6628011064599417

Epoch: 6| Step: 7
Training loss: 0.47036889584057945
Validation loss: 2.7085858056181418

Epoch: 6| Step: 8
Training loss: 0.45616346283225323
Validation loss: 2.6826330887367544

Epoch: 6| Step: 9
Training loss: 0.4602390752321498
Validation loss: 2.643332814156031

Epoch: 6| Step: 10
Training loss: 0.3444080556384839
Validation loss: 2.6574177288288676

Epoch: 6| Step: 11
Training loss: 0.2996640947448664
Validation loss: 2.6690938131048907

Epoch: 6| Step: 12
Training loss: 0.5117243992151496
Validation loss: 2.6869766849556393

Epoch: 6| Step: 13
Training loss: 0.2812530067071204
Validation loss: 2.6713720521249424

Epoch: 361| Step: 0
Training loss: 0.456598027627071
Validation loss: 2.713734447247841

Epoch: 6| Step: 1
Training loss: 0.2875696243070214
Validation loss: 2.731965680199568

Epoch: 6| Step: 2
Training loss: 0.3912670200046234
Validation loss: 2.6480407717774606

Epoch: 6| Step: 3
Training loss: 0.43982123322386013
Validation loss: 2.632705618389622

Epoch: 6| Step: 4
Training loss: 0.3982744631333061
Validation loss: 2.6745414887583103

Epoch: 6| Step: 5
Training loss: 0.21033348034113247
Validation loss: 2.6709070739048557

Epoch: 6| Step: 6
Training loss: 0.3739241425903472
Validation loss: 2.6620826785156986

Epoch: 6| Step: 7
Training loss: 0.3139484573288385
Validation loss: 2.6585304120433415

Epoch: 6| Step: 8
Training loss: 0.3138471652791575
Validation loss: 2.6913042644340086

Epoch: 6| Step: 9
Training loss: 0.29741772183082976
Validation loss: 2.6652708771668037

Epoch: 6| Step: 10
Training loss: 0.37454643237836666
Validation loss: 2.6575718526495837

Epoch: 6| Step: 11
Training loss: 0.3414594674261289
Validation loss: 2.674432233468575

Epoch: 6| Step: 12
Training loss: 0.40179785944732577
Validation loss: 2.691722930599669

Epoch: 6| Step: 13
Training loss: 0.39261173465013743
Validation loss: 2.692128955974247

Epoch: 362| Step: 0
Training loss: 0.27391677814450816
Validation loss: 2.7374039068441336

Epoch: 6| Step: 1
Training loss: 0.3241776015125735
Validation loss: 2.645706922159587

Epoch: 6| Step: 2
Training loss: 0.25547298346228586
Validation loss: 2.649924221994668

Epoch: 6| Step: 3
Training loss: 0.3679017364320995
Validation loss: 2.6385138986970973

Epoch: 6| Step: 4
Training loss: 0.39040780705048567
Validation loss: 2.709676370428862

Epoch: 6| Step: 5
Training loss: 0.49040725213086217
Validation loss: 2.710663179705257

Epoch: 6| Step: 6
Training loss: 0.3272528524449341
Validation loss: 2.719882451537395

Epoch: 6| Step: 7
Training loss: 0.31394724700168447
Validation loss: 2.6345739160558748

Epoch: 6| Step: 8
Training loss: 0.30944371568126766
Validation loss: 2.695677646836617

Epoch: 6| Step: 9
Training loss: 0.36016727273420196
Validation loss: 2.626749575834578

Epoch: 6| Step: 10
Training loss: 0.44186618777259973
Validation loss: 2.6603469070772103

Epoch: 6| Step: 11
Training loss: 0.2630495993617853
Validation loss: 2.645758790495485

Epoch: 6| Step: 12
Training loss: 0.3378463120702542
Validation loss: 2.6523205433552683

Epoch: 6| Step: 13
Training loss: 0.39637078222402444
Validation loss: 2.752514888551078

Epoch: 363| Step: 0
Training loss: 0.485168299625173
Validation loss: 2.719585728722927

Epoch: 6| Step: 1
Training loss: 0.38703389283541906
Validation loss: 2.7136745359335337

Epoch: 6| Step: 2
Training loss: 0.38180444299711475
Validation loss: 2.6493055033374766

Epoch: 6| Step: 3
Training loss: 0.32454590205551365
Validation loss: 2.7167866293236105

Epoch: 6| Step: 4
Training loss: 0.39985192508546535
Validation loss: 2.668931525769749

Epoch: 6| Step: 5
Training loss: 0.30403112969095675
Validation loss: 2.658292949652785

Epoch: 6| Step: 6
Training loss: 0.2895080123115441
Validation loss: 2.6276863294495896

Epoch: 6| Step: 7
Training loss: 0.3205628579692363
Validation loss: 2.6635143353717536

Epoch: 6| Step: 8
Training loss: 0.376396123449813
Validation loss: 2.6716147699469737

Epoch: 6| Step: 9
Training loss: 0.3035579185524965
Validation loss: 2.69774477397587

Epoch: 6| Step: 10
Training loss: 0.2795355783791626
Validation loss: 2.6639494214712225

Epoch: 6| Step: 11
Training loss: 0.3328979176615741
Validation loss: 2.681030937618192

Epoch: 6| Step: 12
Training loss: 0.48201736294173003
Validation loss: 2.695684073815296

Epoch: 6| Step: 13
Training loss: 0.39825493238858556
Validation loss: 2.655909407976119

Epoch: 364| Step: 0
Training loss: 0.4301546158709319
Validation loss: 2.682698966400967

Epoch: 6| Step: 1
Training loss: 0.29578780318636677
Validation loss: 2.6455883954029638

Epoch: 6| Step: 2
Training loss: 0.3727380762694022
Validation loss: 2.724782455580044

Epoch: 6| Step: 3
Training loss: 0.3222645615068863
Validation loss: 2.6893279342675975

Epoch: 6| Step: 4
Training loss: 0.38589878042487524
Validation loss: 2.699590676681329

Epoch: 6| Step: 5
Training loss: 0.4159450202451214
Validation loss: 2.6900654014805205

Epoch: 6| Step: 6
Training loss: 0.39428858328623506
Validation loss: 2.654826003202368

Epoch: 6| Step: 7
Training loss: 0.3165513400627143
Validation loss: 2.673547871710107

Epoch: 6| Step: 8
Training loss: 0.45979315740945453
Validation loss: 2.6489776690626567

Epoch: 6| Step: 9
Training loss: 0.2838559748507429
Validation loss: 2.6713208968054953

Epoch: 6| Step: 10
Training loss: 0.357336086129295
Validation loss: 2.6719683803726157

Epoch: 6| Step: 11
Training loss: 0.4811417433118969
Validation loss: 2.6895424156907928

Epoch: 6| Step: 12
Training loss: 0.3115339486671735
Validation loss: 2.662797912980314

Epoch: 6| Step: 13
Training loss: 0.29904814953788783
Validation loss: 2.7417523726272788

Epoch: 365| Step: 0
Training loss: 0.3719579972683375
Validation loss: 2.7061628202825414

Epoch: 6| Step: 1
Training loss: 0.424839553279148
Validation loss: 2.6822384776548422

Epoch: 6| Step: 2
Training loss: 0.31363079994497617
Validation loss: 2.714913463840941

Epoch: 6| Step: 3
Training loss: 0.37686504066175447
Validation loss: 2.6830440219163867

Epoch: 6| Step: 4
Training loss: 0.23428583038338416
Validation loss: 2.679114262813411

Epoch: 6| Step: 5
Training loss: 0.42068111181445755
Validation loss: 2.727309349685965

Epoch: 6| Step: 6
Training loss: 0.33334653301727674
Validation loss: 2.677241589114945

Epoch: 6| Step: 7
Training loss: 0.47089151118661843
Validation loss: 2.7032496546703304

Epoch: 6| Step: 8
Training loss: 0.43588062722085635
Validation loss: 2.705218186407662

Epoch: 6| Step: 9
Training loss: 0.2904349941648771
Validation loss: 2.780248240106702

Epoch: 6| Step: 10
Training loss: 0.3511644759369331
Validation loss: 2.772282548866826

Epoch: 6| Step: 11
Training loss: 0.35747200452788863
Validation loss: 2.7257059349471193

Epoch: 6| Step: 12
Training loss: 0.37042901584234894
Validation loss: 2.6570996290734805

Epoch: 6| Step: 13
Training loss: 0.363646682374754
Validation loss: 2.6734383454313115

Epoch: 366| Step: 0
Training loss: 0.35211402229812316
Validation loss: 2.70970550891287

Epoch: 6| Step: 1
Training loss: 0.3841522284557685
Validation loss: 2.649745074492192

Epoch: 6| Step: 2
Training loss: 0.5402313772961022
Validation loss: 2.6472687969889557

Epoch: 6| Step: 3
Training loss: 0.26951876901671146
Validation loss: 2.6362248916599955

Epoch: 6| Step: 4
Training loss: 0.40670195528366554
Validation loss: 2.7012009286961463

Epoch: 6| Step: 5
Training loss: 0.5519026844602182
Validation loss: 2.7086905292788708

Epoch: 6| Step: 6
Training loss: 0.4945653062998969
Validation loss: 2.7713226995251126

Epoch: 6| Step: 7
Training loss: 0.31641132444857245
Validation loss: 2.6886315588030087

Epoch: 6| Step: 8
Training loss: 0.45350433782418664
Validation loss: 2.633082329782879

Epoch: 6| Step: 9
Training loss: 0.47961203637000654
Validation loss: 2.640065760335329

Epoch: 6| Step: 10
Training loss: 0.3486287413287274
Validation loss: 2.6259736268790923

Epoch: 6| Step: 11
Training loss: 0.460851127808093
Validation loss: 2.7215327202781068

Epoch: 6| Step: 12
Training loss: 0.5714610305575992
Validation loss: 2.733687832181714

Epoch: 6| Step: 13
Training loss: 0.3903609909526831
Validation loss: 2.6201968527507464

Epoch: 367| Step: 0
Training loss: 0.40747198306934607
Validation loss: 2.6445123173135987

Epoch: 6| Step: 1
Training loss: 0.3446484550191578
Validation loss: 2.6703768763139837

Epoch: 6| Step: 2
Training loss: 0.40517924489572554
Validation loss: 2.694085495155983

Epoch: 6| Step: 3
Training loss: 0.4309974642798494
Validation loss: 2.708238091383617

Epoch: 6| Step: 4
Training loss: 0.49488301354164127
Validation loss: 2.694991176451592

Epoch: 6| Step: 5
Training loss: 0.3377290129737786
Validation loss: 2.713013454189702

Epoch: 6| Step: 6
Training loss: 0.3215224742909736
Validation loss: 2.637237053309276

Epoch: 6| Step: 7
Training loss: 0.2967581770074817
Validation loss: 2.6503085688513233

Epoch: 6| Step: 8
Training loss: 0.2635405743366467
Validation loss: 2.7186260560528988

Epoch: 6| Step: 9
Training loss: 0.37828589318761124
Validation loss: 2.739857958432381

Epoch: 6| Step: 10
Training loss: 0.42285533313083196
Validation loss: 2.6642014662071034

Epoch: 6| Step: 11
Training loss: 0.3627769497483368
Validation loss: 2.641431290362006

Epoch: 6| Step: 12
Training loss: 0.37589439385950774
Validation loss: 2.70992032040695

Epoch: 6| Step: 13
Training loss: 0.37383618161758586
Validation loss: 2.7307016603514325

Epoch: 368| Step: 0
Training loss: 0.2694273762332945
Validation loss: 2.711116627281949

Epoch: 6| Step: 1
Training loss: 0.27913817318411543
Validation loss: 2.716739802946026

Epoch: 6| Step: 2
Training loss: 0.30047351402913786
Validation loss: 2.661090912561959

Epoch: 6| Step: 3
Training loss: 0.3505869575846928
Validation loss: 2.7710381171671226

Epoch: 6| Step: 4
Training loss: 0.3922855558576156
Validation loss: 2.7081030649939786

Epoch: 6| Step: 5
Training loss: 0.24987411309753232
Validation loss: 2.6963677888176996

Epoch: 6| Step: 6
Training loss: 0.22880787379191858
Validation loss: 2.7680826707596418

Epoch: 6| Step: 7
Training loss: 0.4076443182886766
Validation loss: 2.7096909983682793

Epoch: 6| Step: 8
Training loss: 0.35552801958554364
Validation loss: 2.682449733681495

Epoch: 6| Step: 9
Training loss: 0.4436432521996072
Validation loss: 2.6875000295712965

Epoch: 6| Step: 10
Training loss: 0.3136539492110837
Validation loss: 2.7229069904913348

Epoch: 6| Step: 11
Training loss: 0.34545645022052524
Validation loss: 2.681489744338568

Epoch: 6| Step: 12
Training loss: 0.5159828216036789
Validation loss: 2.6687625357626032

Epoch: 6| Step: 13
Training loss: 0.24825333841101738
Validation loss: 2.688354770254083

Epoch: 369| Step: 0
Training loss: 0.31714364063343825
Validation loss: 2.706012837015112

Epoch: 6| Step: 1
Training loss: 0.33675242430430974
Validation loss: 2.650437731547955

Epoch: 6| Step: 2
Training loss: 0.28696232877283295
Validation loss: 2.6976311703203013

Epoch: 6| Step: 3
Training loss: 0.3492928782562687
Validation loss: 2.6957359386776534

Epoch: 6| Step: 4
Training loss: 0.3792852885149212
Validation loss: 2.6685969300635213

Epoch: 6| Step: 5
Training loss: 0.4341186748266824
Validation loss: 2.7450474879842157

Epoch: 6| Step: 6
Training loss: 0.2790536421579996
Validation loss: 2.6698293755932188

Epoch: 6| Step: 7
Training loss: 0.25673125131529373
Validation loss: 2.72107621861857

Epoch: 6| Step: 8
Training loss: 0.27931869528304437
Validation loss: 2.693992512666341

Epoch: 6| Step: 9
Training loss: 0.19160034109303747
Validation loss: 2.719270619790162

Epoch: 6| Step: 10
Training loss: 0.28545186644822773
Validation loss: 2.6694002569812834

Epoch: 6| Step: 11
Training loss: 0.35241980397946315
Validation loss: 2.6526446239702537

Epoch: 6| Step: 12
Training loss: 0.33801267327018936
Validation loss: 2.7490485525028556

Epoch: 6| Step: 13
Training loss: 0.29780977299933775
Validation loss: 2.7201897619941393

Epoch: 370| Step: 0
Training loss: 0.4294230948086176
Validation loss: 2.7278052761334606

Epoch: 6| Step: 1
Training loss: 0.25824025820575625
Validation loss: 2.6818559656924936

Epoch: 6| Step: 2
Training loss: 0.38958844939695825
Validation loss: 2.6823084389368987

Epoch: 6| Step: 3
Training loss: 0.2522225233430741
Validation loss: 2.662964983530486

Epoch: 6| Step: 4
Training loss: 0.3439575132494615
Validation loss: 2.7189173153661463

Epoch: 6| Step: 5
Training loss: 0.2592116019313656
Validation loss: 2.7265165192116285

Epoch: 6| Step: 6
Training loss: 0.4018024766543758
Validation loss: 2.8390115658115893

Epoch: 6| Step: 7
Training loss: 0.3284166039408156
Validation loss: 2.7198372344094963

Epoch: 6| Step: 8
Training loss: 0.3440851939804615
Validation loss: 2.7535855153847137

Epoch: 6| Step: 9
Training loss: 0.43172968295236647
Validation loss: 2.7305553387986445

Epoch: 6| Step: 10
Training loss: 0.3444485826856858
Validation loss: 2.7125092126833428

Epoch: 6| Step: 11
Training loss: 0.2506133393835608
Validation loss: 2.7284364718418255

Epoch: 6| Step: 12
Training loss: 0.37584886240049264
Validation loss: 2.6874489446714063

Epoch: 6| Step: 13
Training loss: 0.43211312992586665
Validation loss: 2.711536967812484

Epoch: 371| Step: 0
Training loss: 0.3647772636525824
Validation loss: 2.764576140113869

Epoch: 6| Step: 1
Training loss: 0.45305175847031276
Validation loss: 2.664378187580485

Epoch: 6| Step: 2
Training loss: 0.3240456291265646
Validation loss: 2.708679856849018

Epoch: 6| Step: 3
Training loss: 0.3797820283619226
Validation loss: 2.7295645115641665

Epoch: 6| Step: 4
Training loss: 0.3712274410959049
Validation loss: 2.6376566633970597

Epoch: 6| Step: 5
Training loss: 0.4194024355309659
Validation loss: 2.696123246332155

Epoch: 6| Step: 6
Training loss: 0.37979591768319654
Validation loss: 2.663334110205787

Epoch: 6| Step: 7
Training loss: 0.4679170678692686
Validation loss: 2.7948917340195756

Epoch: 6| Step: 8
Training loss: 0.26739141814021117
Validation loss: 2.664843052446745

Epoch: 6| Step: 9
Training loss: 0.3412259046725217
Validation loss: 2.640254075522947

Epoch: 6| Step: 10
Training loss: 0.4139059238569358
Validation loss: 2.724769345125555

Epoch: 6| Step: 11
Training loss: 0.43108093430708017
Validation loss: 2.7359609745571896

Epoch: 6| Step: 12
Training loss: 0.2954673018235938
Validation loss: 2.7739308522880948

Epoch: 6| Step: 13
Training loss: 0.55238139605612
Validation loss: 2.6747984777580194

Epoch: 372| Step: 0
Training loss: 0.3522826342643911
Validation loss: 2.6902881915113515

Epoch: 6| Step: 1
Training loss: 0.3565908474565445
Validation loss: 2.720713319414752

Epoch: 6| Step: 2
Training loss: 0.415462627817692
Validation loss: 2.729162803433623

Epoch: 6| Step: 3
Training loss: 0.44500480863566216
Validation loss: 2.704829918666979

Epoch: 6| Step: 4
Training loss: 0.34184124249916903
Validation loss: 2.7613117758070445

Epoch: 6| Step: 5
Training loss: 0.27738398945060055
Validation loss: 2.770559660702392

Epoch: 6| Step: 6
Training loss: 0.42694737045723835
Validation loss: 2.63165019081117

Epoch: 6| Step: 7
Training loss: 0.4614909292581925
Validation loss: 2.6726959038240072

Epoch: 6| Step: 8
Training loss: 0.38295937659357704
Validation loss: 2.674104515115029

Epoch: 6| Step: 9
Training loss: 0.3857772231789881
Validation loss: 2.674525695415854

Epoch: 6| Step: 10
Training loss: 0.2691940188215316
Validation loss: 2.703746834381409

Epoch: 6| Step: 11
Training loss: 0.3959719724634665
Validation loss: 2.6784823629921224

Epoch: 6| Step: 12
Training loss: 0.2571856797155065
Validation loss: 2.735525386961409

Epoch: 6| Step: 13
Training loss: 0.34891722802377506
Validation loss: 2.6931422761351334

Epoch: 373| Step: 0
Training loss: 0.3279275527166662
Validation loss: 2.7078352152199434

Epoch: 6| Step: 1
Training loss: 0.39140695507115497
Validation loss: 2.6759558404919654

Epoch: 6| Step: 2
Training loss: 0.31527939041334907
Validation loss: 2.803938061567461

Epoch: 6| Step: 3
Training loss: 0.3748020802179071
Validation loss: 2.6914946860376054

Epoch: 6| Step: 4
Training loss: 0.3182698574471116
Validation loss: 2.742699281006529

Epoch: 6| Step: 5
Training loss: 0.42807209495499293
Validation loss: 2.7386924590893034

Epoch: 6| Step: 6
Training loss: 0.35418012771082635
Validation loss: 2.6804258999299075

Epoch: 6| Step: 7
Training loss: 0.2663302315908134
Validation loss: 2.5997525889105013

Epoch: 6| Step: 8
Training loss: 0.3396175552551858
Validation loss: 2.656384842385858

Epoch: 6| Step: 9
Training loss: 0.42701971541681777
Validation loss: 2.7386536610250256

Epoch: 6| Step: 10
Training loss: 0.49001380244103115
Validation loss: 2.657690263613828

Epoch: 6| Step: 11
Training loss: 0.3045437302437083
Validation loss: 2.6961359507668936

Epoch: 6| Step: 12
Training loss: 0.33732413063050376
Validation loss: 2.6811283045422654

Epoch: 6| Step: 13
Training loss: 0.42095337971595753
Validation loss: 2.7442928249375473

Epoch: 374| Step: 0
Training loss: 0.3251888858744373
Validation loss: 2.700765671600973

Epoch: 6| Step: 1
Training loss: 0.5089867147536818
Validation loss: 2.749613416838318

Epoch: 6| Step: 2
Training loss: 0.3300958888222863
Validation loss: 2.6712035735348323

Epoch: 6| Step: 3
Training loss: 0.31739031269308077
Validation loss: 2.800461208585423

Epoch: 6| Step: 4
Training loss: 0.3915608449110899
Validation loss: 2.672033130509836

Epoch: 6| Step: 5
Training loss: 0.38423526829244214
Validation loss: 2.6736809945709643

Epoch: 6| Step: 6
Training loss: 0.40169417155868486
Validation loss: 2.7003565964867104

Epoch: 6| Step: 7
Training loss: 0.290917399169938
Validation loss: 2.684894718400568

Epoch: 6| Step: 8
Training loss: 0.361225051612383
Validation loss: 2.6946078720104065

Epoch: 6| Step: 9
Training loss: 0.4674959255489741
Validation loss: 2.6505360648932594

Epoch: 6| Step: 10
Training loss: 0.41915379740839964
Validation loss: 2.670465874847739

Epoch: 6| Step: 11
Training loss: 0.31515318381577306
Validation loss: 2.7000098387221048

Epoch: 6| Step: 12
Training loss: 0.43369865866672
Validation loss: 2.6451863877138533

Epoch: 6| Step: 13
Training loss: 0.31510359262251253
Validation loss: 2.7249002937134463

Epoch: 375| Step: 0
Training loss: 0.2263805958131547
Validation loss: 2.646684094314786

Epoch: 6| Step: 1
Training loss: 0.2746737191797873
Validation loss: 2.6262201773348126

Epoch: 6| Step: 2
Training loss: 0.22098081555318821
Validation loss: 2.665195824380972

Epoch: 6| Step: 3
Training loss: 0.3235530223110465
Validation loss: 2.6158132560553344

Epoch: 6| Step: 4
Training loss: 0.24373888149334597
Validation loss: 2.6754135881647936

Epoch: 6| Step: 5
Training loss: 0.2545547712872834
Validation loss: 2.742106017145609

Epoch: 6| Step: 6
Training loss: 0.35529320962254035
Validation loss: 2.645360331169568

Epoch: 6| Step: 7
Training loss: 0.31350484464938827
Validation loss: 2.712691825025658

Epoch: 6| Step: 8
Training loss: 0.3217029630280875
Validation loss: 2.705777493076808

Epoch: 6| Step: 9
Training loss: 0.26646570789510476
Validation loss: 2.689031401208166

Epoch: 6| Step: 10
Training loss: 0.521442911735653
Validation loss: 2.751508746830673

Epoch: 6| Step: 11
Training loss: 0.46532253643968613
Validation loss: 2.6692834894143878

Epoch: 6| Step: 12
Training loss: 0.43195024665677995
Validation loss: 2.7104653891881254

Epoch: 6| Step: 13
Training loss: 0.326130630261066
Validation loss: 2.6337360758172714

Epoch: 376| Step: 0
Training loss: 0.3555947593944842
Validation loss: 2.6713941859054535

Epoch: 6| Step: 1
Training loss: 0.35015966486084893
Validation loss: 2.7554557895887375

Epoch: 6| Step: 2
Training loss: 0.4042844908655826
Validation loss: 2.7650030841315822

Epoch: 6| Step: 3
Training loss: 0.4178702692967372
Validation loss: 2.694133504369853

Epoch: 6| Step: 4
Training loss: 0.31839321401291976
Validation loss: 2.645433505828789

Epoch: 6| Step: 5
Training loss: 0.3162650982641426
Validation loss: 2.6744576626327605

Epoch: 6| Step: 6
Training loss: 0.2713632519251138
Validation loss: 2.6748844323788727

Epoch: 6| Step: 7
Training loss: 0.3148107094856738
Validation loss: 2.7032825960586973

Epoch: 6| Step: 8
Training loss: 0.28473555219015784
Validation loss: 2.6884393455034634

Epoch: 6| Step: 9
Training loss: 0.3259518160835099
Validation loss: 2.6708381827355536

Epoch: 6| Step: 10
Training loss: 0.2848641977174472
Validation loss: 2.6985808086499095

Epoch: 6| Step: 11
Training loss: 0.26915003589847447
Validation loss: 2.6739458680961405

Epoch: 6| Step: 12
Training loss: 0.2703474650618847
Validation loss: 2.7188966426544803

Epoch: 6| Step: 13
Training loss: 0.2729451378805581
Validation loss: 2.6500067623819885

Epoch: 377| Step: 0
Training loss: 0.3035587653255713
Validation loss: 2.709553947244408

Epoch: 6| Step: 1
Training loss: 0.3918368995129133
Validation loss: 2.735420521261071

Epoch: 6| Step: 2
Training loss: 0.38187757494318986
Validation loss: 2.6409790508970956

Epoch: 6| Step: 3
Training loss: 0.36161075570052625
Validation loss: 2.6880947386460288

Epoch: 6| Step: 4
Training loss: 0.2646924788086718
Validation loss: 2.682508283343388

Epoch: 6| Step: 5
Training loss: 0.3259465701486124
Validation loss: 2.6433116179636986

Epoch: 6| Step: 6
Training loss: 0.35625379459970247
Validation loss: 2.699680287070047

Epoch: 6| Step: 7
Training loss: 0.3146989465732235
Validation loss: 2.706606774309545

Epoch: 6| Step: 8
Training loss: 0.22307892884720626
Validation loss: 2.685950623650895

Epoch: 6| Step: 9
Training loss: 0.34877361798726636
Validation loss: 2.7469253546996484

Epoch: 6| Step: 10
Training loss: 0.31322319272865917
Validation loss: 2.691581465688525

Epoch: 6| Step: 11
Training loss: 0.3094445945028169
Validation loss: 2.702468682142067

Epoch: 6| Step: 12
Training loss: 0.5167545027312905
Validation loss: 2.7607025910092613

Epoch: 6| Step: 13
Training loss: 0.22387234382502028
Validation loss: 2.735173615588729

Epoch: 378| Step: 0
Training loss: 0.29566155447584735
Validation loss: 2.7397486971612377

Epoch: 6| Step: 1
Training loss: 0.29784638447247314
Validation loss: 2.7156179664324656

Epoch: 6| Step: 2
Training loss: 0.30404205916131377
Validation loss: 2.643244826297068

Epoch: 6| Step: 3
Training loss: 0.3693273566513568
Validation loss: 2.678072243300317

Epoch: 6| Step: 4
Training loss: 0.2832257755034904
Validation loss: 2.6460146403831537

Epoch: 6| Step: 5
Training loss: 0.42022576979453674
Validation loss: 2.723222028853808

Epoch: 6| Step: 6
Training loss: 0.39128600460661583
Validation loss: 2.740536822383395

Epoch: 6| Step: 7
Training loss: 0.3241844848542608
Validation loss: 2.7224171486523603

Epoch: 6| Step: 8
Training loss: 0.4302322922131989
Validation loss: 2.758834332570129

Epoch: 6| Step: 9
Training loss: 0.29330813776979314
Validation loss: 2.657829376113302

Epoch: 6| Step: 10
Training loss: 0.33193052671473966
Validation loss: 2.7129507074186554

Epoch: 6| Step: 11
Training loss: 0.4249930829999935
Validation loss: 2.679472029524623

Epoch: 6| Step: 12
Training loss: 0.36487328942771224
Validation loss: 2.6528630523113024

Epoch: 6| Step: 13
Training loss: 0.33415637132825643
Validation loss: 2.694502851720535

Epoch: 379| Step: 0
Training loss: 0.40068264988326213
Validation loss: 2.7182934549456053

Epoch: 6| Step: 1
Training loss: 0.32252680280849977
Validation loss: 2.661913619443873

Epoch: 6| Step: 2
Training loss: 0.3784022174141173
Validation loss: 2.7578604156394833

Epoch: 6| Step: 3
Training loss: 0.5242382586014337
Validation loss: 2.742425384781499

Epoch: 6| Step: 4
Training loss: 0.39535919034346234
Validation loss: 2.7114323101243314

Epoch: 6| Step: 5
Training loss: 0.3219526447236094
Validation loss: 2.686940859507811

Epoch: 6| Step: 6
Training loss: 0.39662508041640704
Validation loss: 2.6924439871701824

Epoch: 6| Step: 7
Training loss: 0.2958645691074477
Validation loss: 2.6536062734922656

Epoch: 6| Step: 8
Training loss: 0.4265047104084581
Validation loss: 2.653691035301556

Epoch: 6| Step: 9
Training loss: 0.25877149990155535
Validation loss: 2.631849382563156

Epoch: 6| Step: 10
Training loss: 0.29291394038896434
Validation loss: 2.670877021178325

Epoch: 6| Step: 11
Training loss: 0.23389226154297907
Validation loss: 2.677109259295566

Epoch: 6| Step: 12
Training loss: 0.42388778477576766
Validation loss: 2.614182404760676

Epoch: 6| Step: 13
Training loss: 0.2786787569197793
Validation loss: 2.6974818985231215

Epoch: 380| Step: 0
Training loss: 0.3598392431960007
Validation loss: 2.7064949007059673

Epoch: 6| Step: 1
Training loss: 0.5150697203543096
Validation loss: 2.672576886466641

Epoch: 6| Step: 2
Training loss: 0.38128403683674067
Validation loss: 2.674039220732011

Epoch: 6| Step: 3
Training loss: 0.32953009169742614
Validation loss: 2.6368164722559455

Epoch: 6| Step: 4
Training loss: 0.22215478878960002
Validation loss: 2.73337435623724

Epoch: 6| Step: 5
Training loss: 0.3386487229121375
Validation loss: 2.6886999127771047

Epoch: 6| Step: 6
Training loss: 0.4743457580117781
Validation loss: 2.7560865352307014

Epoch: 6| Step: 7
Training loss: 0.34594285056258867
Validation loss: 2.7159448014667675

Epoch: 6| Step: 8
Training loss: 0.2419111536418731
Validation loss: 2.701947126482539

Epoch: 6| Step: 9
Training loss: 0.30790754874275034
Validation loss: 2.6458185425793

Epoch: 6| Step: 10
Training loss: 0.28413237344981185
Validation loss: 2.6571732356468356

Epoch: 6| Step: 11
Training loss: 0.2854586917794395
Validation loss: 2.68851771047788

Epoch: 6| Step: 12
Training loss: 0.2924276313755314
Validation loss: 2.6563972432334046

Epoch: 6| Step: 13
Training loss: 0.35285045154421557
Validation loss: 2.6409574521349684

Epoch: 381| Step: 0
Training loss: 0.303730770825009
Validation loss: 2.686431302638082

Epoch: 6| Step: 1
Training loss: 0.31984721093851387
Validation loss: 2.6181695566448164

Epoch: 6| Step: 2
Training loss: 0.24074453753516342
Validation loss: 2.656853588565065

Epoch: 6| Step: 3
Training loss: 0.2755823482547346
Validation loss: 2.7026575672938704

Epoch: 6| Step: 4
Training loss: 0.503378244011133
Validation loss: 2.661837352382855

Epoch: 6| Step: 5
Training loss: 0.43322786582145506
Validation loss: 2.681223748707697

Epoch: 6| Step: 6
Training loss: 0.34648594345202244
Validation loss: 2.6746074691549504

Epoch: 6| Step: 7
Training loss: 0.2585421842118544
Validation loss: 2.7029559720210323

Epoch: 6| Step: 8
Training loss: 0.3456859261065352
Validation loss: 2.59847260078889

Epoch: 6| Step: 9
Training loss: 0.36471342989960603
Validation loss: 2.621444648339724

Epoch: 6| Step: 10
Training loss: 0.30439771418640593
Validation loss: 2.620328637082707

Epoch: 6| Step: 11
Training loss: 0.32167528586048444
Validation loss: 2.659688750726783

Epoch: 6| Step: 12
Training loss: 0.36450620471189243
Validation loss: 2.6985922940755915

Epoch: 6| Step: 13
Training loss: 0.2631227780427241
Validation loss: 2.68393233901205

Epoch: 382| Step: 0
Training loss: 0.37927104653793636
Validation loss: 2.6665332333639498

Epoch: 6| Step: 1
Training loss: 0.43917895771587906
Validation loss: 2.6834643322103764

Epoch: 6| Step: 2
Training loss: 0.347275139299639
Validation loss: 2.648420185643916

Epoch: 6| Step: 3
Training loss: 0.4134519321924257
Validation loss: 2.6774129899600783

Epoch: 6| Step: 4
Training loss: 0.391563699085686
Validation loss: 2.649867134242237

Epoch: 6| Step: 5
Training loss: 0.2395247313451659
Validation loss: 2.713029155302231

Epoch: 6| Step: 6
Training loss: 0.29995336170070946
Validation loss: 2.741498746531797

Epoch: 6| Step: 7
Training loss: 0.37787270917333715
Validation loss: 2.6904369467229463

Epoch: 6| Step: 8
Training loss: 0.49905611890464757
Validation loss: 2.7018525320367983

Epoch: 6| Step: 9
Training loss: 0.36027898290130805
Validation loss: 2.6883481040386417

Epoch: 6| Step: 10
Training loss: 0.3632119225420984
Validation loss: 2.679333603217852

Epoch: 6| Step: 11
Training loss: 0.24848264427999975
Validation loss: 2.672394521669938

Epoch: 6| Step: 12
Training loss: 0.34761630053781595
Validation loss: 2.641924521399707

Epoch: 6| Step: 13
Training loss: 0.32304147902644437
Validation loss: 2.7165867468032947

Epoch: 383| Step: 0
Training loss: 0.44816605330671505
Validation loss: 2.691671401768664

Epoch: 6| Step: 1
Training loss: 0.29228568237950686
Validation loss: 2.6462317614797026

Epoch: 6| Step: 2
Training loss: 0.2825974004708602
Validation loss: 2.632477562613415

Epoch: 6| Step: 3
Training loss: 0.28669923565223465
Validation loss: 2.6756657410724554

Epoch: 6| Step: 4
Training loss: 0.36468934379837215
Validation loss: 2.677758771143881

Epoch: 6| Step: 5
Training loss: 0.3865637998628464
Validation loss: 2.712504114713346

Epoch: 6| Step: 6
Training loss: 0.25886530202993757
Validation loss: 2.7060100102484994

Epoch: 6| Step: 7
Training loss: 0.3908663004403272
Validation loss: 2.6526502564178216

Epoch: 6| Step: 8
Training loss: 0.35615331107307113
Validation loss: 2.7104871890730475

Epoch: 6| Step: 9
Training loss: 0.3308279222943517
Validation loss: 2.6624405324440708

Epoch: 6| Step: 10
Training loss: 0.39501745650191006
Validation loss: 2.7439425251004597

Epoch: 6| Step: 11
Training loss: 0.37014987770994734
Validation loss: 2.729257921823823

Epoch: 6| Step: 12
Training loss: 0.34851742285423143
Validation loss: 2.695235062375947

Epoch: 6| Step: 13
Training loss: 0.32116720097359946
Validation loss: 2.699100475231837

Epoch: 384| Step: 0
Training loss: 0.35035895860486743
Validation loss: 2.707157177952535

Epoch: 6| Step: 1
Training loss: 0.3812184133108369
Validation loss: 2.6660913105003923

Epoch: 6| Step: 2
Training loss: 0.389715260677028
Validation loss: 2.681795645963461

Epoch: 6| Step: 3
Training loss: 0.4103812917319412
Validation loss: 2.74273031428524

Epoch: 6| Step: 4
Training loss: 0.35024145729720774
Validation loss: 2.6712618267372905

Epoch: 6| Step: 5
Training loss: 0.3200718627086171
Validation loss: 2.706905095994371

Epoch: 6| Step: 6
Training loss: 0.40988440814771493
Validation loss: 2.7249671837816822

Epoch: 6| Step: 7
Training loss: 0.31077164486962827
Validation loss: 2.661585143490395

Epoch: 6| Step: 8
Training loss: 0.328516227367815
Validation loss: 2.672143011798306

Epoch: 6| Step: 9
Training loss: 0.3167493396472144
Validation loss: 2.699199214557299

Epoch: 6| Step: 10
Training loss: 0.2923460254957819
Validation loss: 2.614148424206715

Epoch: 6| Step: 11
Training loss: 0.4468024575100987
Validation loss: 2.7200363302375754

Epoch: 6| Step: 12
Training loss: 0.1576523258318199
Validation loss: 2.6914807785928607

Epoch: 6| Step: 13
Training loss: 0.3030607986300168
Validation loss: 2.689819325781132

Epoch: 385| Step: 0
Training loss: 0.4353214587229739
Validation loss: 2.6043147134024527

Epoch: 6| Step: 1
Training loss: 0.2752845776413418
Validation loss: 2.6631392802449674

Epoch: 6| Step: 2
Training loss: 0.35188160295541754
Validation loss: 2.643505376405914

Epoch: 6| Step: 3
Training loss: 0.3900794988692431
Validation loss: 2.698886245438149

Epoch: 6| Step: 4
Training loss: 0.25882406897667115
Validation loss: 2.7232715307348965

Epoch: 6| Step: 5
Training loss: 0.43723023135567174
Validation loss: 2.7380408718011284

Epoch: 6| Step: 6
Training loss: 0.34040899514776124
Validation loss: 2.6614382022063965

Epoch: 6| Step: 7
Training loss: 0.36571536292429424
Validation loss: 2.6597646909620507

Epoch: 6| Step: 8
Training loss: 0.3553189391640576
Validation loss: 2.72934719876636

Epoch: 6| Step: 9
Training loss: 0.31139312458083096
Validation loss: 2.6658012480939943

Epoch: 6| Step: 10
Training loss: 0.2350469335145021
Validation loss: 2.6719208800780714

Epoch: 6| Step: 11
Training loss: 0.375552545214629
Validation loss: 2.656539422517476

Epoch: 6| Step: 12
Training loss: 0.31524957764375666
Validation loss: 2.690652617203138

Epoch: 6| Step: 13
Training loss: 0.28775913646752693
Validation loss: 2.693444648777743

Epoch: 386| Step: 0
Training loss: 0.39923970490345445
Validation loss: 2.729580554202773

Epoch: 6| Step: 1
Training loss: 0.33225113936473594
Validation loss: 2.7248928419386185

Epoch: 6| Step: 2
Training loss: 0.31422847518401376
Validation loss: 2.679711678176216

Epoch: 6| Step: 3
Training loss: 0.2654170737171096
Validation loss: 2.705017742855621

Epoch: 6| Step: 4
Training loss: 0.327039421478845
Validation loss: 2.759923485418644

Epoch: 6| Step: 5
Training loss: 0.380447007954273
Validation loss: 2.7271098814377064

Epoch: 6| Step: 6
Training loss: 0.2982346244607513
Validation loss: 2.68795759164474

Epoch: 6| Step: 7
Training loss: 0.3789200141215797
Validation loss: 2.660131617734058

Epoch: 6| Step: 8
Training loss: 0.3348879720774741
Validation loss: 2.7231864540649253

Epoch: 6| Step: 9
Training loss: 0.2681574154534979
Validation loss: 2.74673195482021

Epoch: 6| Step: 10
Training loss: 0.2688469285050979
Validation loss: 2.7362818073034805

Epoch: 6| Step: 11
Training loss: 0.3672671941753298
Validation loss: 2.6440066517372545

Epoch: 6| Step: 12
Training loss: 0.32176415701489464
Validation loss: 2.649343945008585

Epoch: 6| Step: 13
Training loss: 0.3362005889140252
Validation loss: 2.722052997618801

Epoch: 387| Step: 0
Training loss: 0.25850564083718297
Validation loss: 2.651869449146655

Epoch: 6| Step: 1
Training loss: 0.36151911868458164
Validation loss: 2.6528575775921746

Epoch: 6| Step: 2
Training loss: 0.27399160916731113
Validation loss: 2.6694197202268133

Epoch: 6| Step: 3
Training loss: 0.32920102390823025
Validation loss: 2.6961059655519177

Epoch: 6| Step: 4
Training loss: 0.19871925866004475
Validation loss: 2.662885702429966

Epoch: 6| Step: 5
Training loss: 0.3652359049555919
Validation loss: 2.6883967478163324

Epoch: 6| Step: 6
Training loss: 0.35316673471043
Validation loss: 2.6737624969119036

Epoch: 6| Step: 7
Training loss: 0.22635557327559067
Validation loss: 2.688379720377138

Epoch: 6| Step: 8
Training loss: 0.3693657042532617
Validation loss: 2.691303751358959

Epoch: 6| Step: 9
Training loss: 0.3036976409650919
Validation loss: 2.7651012018019823

Epoch: 6| Step: 10
Training loss: 0.2416139086049
Validation loss: 2.711982606216886

Epoch: 6| Step: 11
Training loss: 0.28741129097474166
Validation loss: 2.6812356197087146

Epoch: 6| Step: 12
Training loss: 0.3782079889323164
Validation loss: 2.687650498900274

Epoch: 6| Step: 13
Training loss: 0.26191408070586253
Validation loss: 2.6991961451097795

Epoch: 388| Step: 0
Training loss: 0.31286859232353065
Validation loss: 2.6851459809677496

Epoch: 6| Step: 1
Training loss: 0.37957305831834653
Validation loss: 2.6658043336339325

Epoch: 6| Step: 2
Training loss: 0.211876931870917
Validation loss: 2.682072874361626

Epoch: 6| Step: 3
Training loss: 0.46752357579010206
Validation loss: 2.626742102787109

Epoch: 6| Step: 4
Training loss: 0.41284666955239097
Validation loss: 2.779529753896588

Epoch: 6| Step: 5
Training loss: 0.2593503227904065
Validation loss: 2.6489460174678268

Epoch: 6| Step: 6
Training loss: 0.31079300537431354
Validation loss: 2.669502275559191

Epoch: 6| Step: 7
Training loss: 0.2854217181953713
Validation loss: 2.734913291626008

Epoch: 6| Step: 8
Training loss: 0.31670850280836144
Validation loss: 2.673817053345374

Epoch: 6| Step: 9
Training loss: 0.476825891468457
Validation loss: 2.7292672980783212

Epoch: 6| Step: 10
Training loss: 0.32005152887224425
Validation loss: 2.7091077699911406

Epoch: 6| Step: 11
Training loss: 0.329010676390462
Validation loss: 2.675600663005899

Epoch: 6| Step: 12
Training loss: 0.36634618677612407
Validation loss: 2.6537031642322395

Epoch: 6| Step: 13
Training loss: 0.27193621899867043
Validation loss: 2.674563247166264

Epoch: 389| Step: 0
Training loss: 0.4159292570195849
Validation loss: 2.702975259797265

Epoch: 6| Step: 1
Training loss: 0.3449522041819625
Validation loss: 2.6814604770712194

Epoch: 6| Step: 2
Training loss: 0.4557723942191542
Validation loss: 2.6907316782645765

Epoch: 6| Step: 3
Training loss: 0.3096013339411291
Validation loss: 2.7136682174567914

Epoch: 6| Step: 4
Training loss: 0.29261516850938196
Validation loss: 2.7117915571705966

Epoch: 6| Step: 5
Training loss: 0.46162547478030364
Validation loss: 2.7708365050754225

Epoch: 6| Step: 6
Training loss: 0.36610997143315427
Validation loss: 2.724773793062124

Epoch: 6| Step: 7
Training loss: 0.3619387441701688
Validation loss: 2.766559450147927

Epoch: 6| Step: 8
Training loss: 0.36266557759555046
Validation loss: 2.768117266618542

Epoch: 6| Step: 9
Training loss: 0.4032580533131042
Validation loss: 2.740686264716231

Epoch: 6| Step: 10
Training loss: 0.35227799193162307
Validation loss: 2.6902834797736785

Epoch: 6| Step: 11
Training loss: 0.46146033425108995
Validation loss: 2.6828008865878243

Epoch: 6| Step: 12
Training loss: 0.38006583465433136
Validation loss: 2.6801343569360556

Epoch: 6| Step: 13
Training loss: 0.31094179294248864
Validation loss: 2.7228278202271077

Epoch: 390| Step: 0
Training loss: 0.555447420550387
Validation loss: 2.7037835320450787

Epoch: 6| Step: 1
Training loss: 0.30647355892204486
Validation loss: 2.6867132292026428

Epoch: 6| Step: 2
Training loss: 0.33795058539786155
Validation loss: 2.6702159839596025

Epoch: 6| Step: 3
Training loss: 0.20094063811276705
Validation loss: 2.6437631503019343

Epoch: 6| Step: 4
Training loss: 0.42727676717459584
Validation loss: 2.7195685020553952

Epoch: 6| Step: 5
Training loss: 0.2788418885241241
Validation loss: 2.675202081005224

Epoch: 6| Step: 6
Training loss: 0.3203433417381935
Validation loss: 2.7005127796628092

Epoch: 6| Step: 7
Training loss: 0.46394826080164014
Validation loss: 2.6821995815037747

Epoch: 6| Step: 8
Training loss: 0.2948049477707101
Validation loss: 2.631111183944675

Epoch: 6| Step: 9
Training loss: 0.43850235555183587
Validation loss: 2.671233116814147

Epoch: 6| Step: 10
Training loss: 0.4597692069770559
Validation loss: 2.677665325585043

Epoch: 6| Step: 11
Training loss: 0.4463660843577582
Validation loss: 2.7131839938700604

Epoch: 6| Step: 12
Training loss: 0.4205077232009928
Validation loss: 2.6881904602240247

Epoch: 6| Step: 13
Training loss: 0.3095736097286576
Validation loss: 2.696133165228902

Epoch: 391| Step: 0
Training loss: 0.36658489207683365
Validation loss: 2.7071281735021646

Epoch: 6| Step: 1
Training loss: 0.40337425037523617
Validation loss: 2.670998665685879

Epoch: 6| Step: 2
Training loss: 0.3574817794878317
Validation loss: 2.6877213320412734

Epoch: 6| Step: 3
Training loss: 0.4273571458631263
Validation loss: 2.692477533027707

Epoch: 6| Step: 4
Training loss: 0.42899141282599396
Validation loss: 2.681962414628687

Epoch: 6| Step: 5
Training loss: 0.2762079757555377
Validation loss: 2.748668912044548

Epoch: 6| Step: 6
Training loss: 0.34622243895477667
Validation loss: 2.7118015726157645

Epoch: 6| Step: 7
Training loss: 0.42344384417408887
Validation loss: 2.6993057229603825

Epoch: 6| Step: 8
Training loss: 0.3646909169001871
Validation loss: 2.699023094759684

Epoch: 6| Step: 9
Training loss: 0.21939844003525297
Validation loss: 2.641647765295557

Epoch: 6| Step: 10
Training loss: 0.3470869009919156
Validation loss: 2.6867922656831387

Epoch: 6| Step: 11
Training loss: 0.4613756909506065
Validation loss: 2.7171887486056265

Epoch: 6| Step: 12
Training loss: 0.38579838983121645
Validation loss: 2.6293010745829433

Epoch: 6| Step: 13
Training loss: 0.4161321270929076
Validation loss: 2.650623226055741

Epoch: 392| Step: 0
Training loss: 0.3700282007502041
Validation loss: 2.7620385401645153

Epoch: 6| Step: 1
Training loss: 0.37516177184884214
Validation loss: 2.632005245162932

Epoch: 6| Step: 2
Training loss: 0.3032443765180173
Validation loss: 2.7660529098364606

Epoch: 6| Step: 3
Training loss: 0.3651371790843999
Validation loss: 2.6747694492514236

Epoch: 6| Step: 4
Training loss: 0.32400305593633005
Validation loss: 2.7076665693326345

Epoch: 6| Step: 5
Training loss: 0.34948641996441565
Validation loss: 2.5934201685759226

Epoch: 6| Step: 6
Training loss: 0.44010375284329734
Validation loss: 2.7730141473302186

Epoch: 6| Step: 7
Training loss: 0.2544039616511733
Validation loss: 2.7112254228968506

Epoch: 6| Step: 8
Training loss: 0.31656231975267857
Validation loss: 2.68318348598471

Epoch: 6| Step: 9
Training loss: 0.22804693917943006
Validation loss: 2.6455631168180345

Epoch: 6| Step: 10
Training loss: 0.4484777724893736
Validation loss: 2.713372616374169

Epoch: 6| Step: 11
Training loss: 0.389685798708606
Validation loss: 2.645538814302477

Epoch: 6| Step: 12
Training loss: 0.35520183057603294
Validation loss: 2.6893029338386945

Epoch: 6| Step: 13
Training loss: 0.37882965336178803
Validation loss: 2.6786849330891966

Epoch: 393| Step: 0
Training loss: 0.3155717559321332
Validation loss: 2.668752202458184

Epoch: 6| Step: 1
Training loss: 0.2237683514309799
Validation loss: 2.6247911067376375

Epoch: 6| Step: 2
Training loss: 0.3173937869008596
Validation loss: 2.661137531054685

Epoch: 6| Step: 3
Training loss: 0.296108888626605
Validation loss: 2.676806251248115

Epoch: 6| Step: 4
Training loss: 0.32413310333005735
Validation loss: 2.659270256182181

Epoch: 6| Step: 5
Training loss: 0.5093890732301335
Validation loss: 2.686769060789904

Epoch: 6| Step: 6
Training loss: 0.3902197643213996
Validation loss: 2.604784904844853

Epoch: 6| Step: 7
Training loss: 0.41276971062466605
Validation loss: 2.715774866789471

Epoch: 6| Step: 8
Training loss: 0.25524795802006695
Validation loss: 2.7130922883827004

Epoch: 6| Step: 9
Training loss: 0.37269139953804553
Validation loss: 2.727641550686485

Epoch: 6| Step: 10
Training loss: 0.36610677636514405
Validation loss: 2.6870049678665233

Epoch: 6| Step: 11
Training loss: 0.39838573643149605
Validation loss: 2.7752950975379123

Epoch: 6| Step: 12
Training loss: 0.321841290014229
Validation loss: 2.6678806958764127

Epoch: 6| Step: 13
Training loss: 0.3599980385382517
Validation loss: 2.6459810085585818

Epoch: 394| Step: 0
Training loss: 0.2636089532444176
Validation loss: 2.681052539611802

Epoch: 6| Step: 1
Training loss: 0.41117153755535096
Validation loss: 2.6721331822987904

Epoch: 6| Step: 2
Training loss: 0.24395406079697673
Validation loss: 2.7405597315069783

Epoch: 6| Step: 3
Training loss: 0.3498972767562295
Validation loss: 2.700822544196013

Epoch: 6| Step: 4
Training loss: 0.2813302031707491
Validation loss: 2.660525751429092

Epoch: 6| Step: 5
Training loss: 0.3899363742181736
Validation loss: 2.686078190812738

Epoch: 6| Step: 6
Training loss: 0.3156561024137431
Validation loss: 2.6435669681567737

Epoch: 6| Step: 7
Training loss: 0.31900074483521423
Validation loss: 2.657417549392579

Epoch: 6| Step: 8
Training loss: 0.25004949675762794
Validation loss: 2.681762573996014

Epoch: 6| Step: 9
Training loss: 0.3068360355991374
Validation loss: 2.705121723287347

Epoch: 6| Step: 10
Training loss: 0.24185657965826923
Validation loss: 2.6651324885622034

Epoch: 6| Step: 11
Training loss: 0.3595573957569304
Validation loss: 2.708118317700953

Epoch: 6| Step: 12
Training loss: 0.3478992984152263
Validation loss: 2.693488302595969

Epoch: 6| Step: 13
Training loss: 0.35646546189303324
Validation loss: 2.6619036775315927

Epoch: 395| Step: 0
Training loss: 0.36751182923125186
Validation loss: 2.6541385261884343

Epoch: 6| Step: 1
Training loss: 0.31901535367713607
Validation loss: 2.7075260035004924

Epoch: 6| Step: 2
Training loss: 0.23350540008569948
Validation loss: 2.708384415560496

Epoch: 6| Step: 3
Training loss: 0.28815577032406947
Validation loss: 2.6389884768204688

Epoch: 6| Step: 4
Training loss: 0.31868322551888334
Validation loss: 2.6494830533006577

Epoch: 6| Step: 5
Training loss: 0.28352760930826276
Validation loss: 2.6693314087980204

Epoch: 6| Step: 6
Training loss: 0.4614158346728875
Validation loss: 2.672960585077024

Epoch: 6| Step: 7
Training loss: 0.34918572954582844
Validation loss: 2.6965583317721085

Epoch: 6| Step: 8
Training loss: 0.3080466527161654
Validation loss: 2.6903251392246177

Epoch: 6| Step: 9
Training loss: 0.30866483280120816
Validation loss: 2.649729965654894

Epoch: 6| Step: 10
Training loss: 0.396219888800579
Validation loss: 2.684298330743476

Epoch: 6| Step: 11
Training loss: 0.36928981208543615
Validation loss: 2.6866639559387404

Epoch: 6| Step: 12
Training loss: 0.3723066085239152
Validation loss: 2.664279820741154

Epoch: 6| Step: 13
Training loss: 0.4616534604870312
Validation loss: 2.6875079842382306

Epoch: 396| Step: 0
Training loss: 0.3292825919749637
Validation loss: 2.732922573355598

Epoch: 6| Step: 1
Training loss: 0.3380811848518501
Validation loss: 2.720513425969991

Epoch: 6| Step: 2
Training loss: 0.29021343294269675
Validation loss: 2.6865270465071784

Epoch: 6| Step: 3
Training loss: 0.3979536559436768
Validation loss: 2.7411666158044996

Epoch: 6| Step: 4
Training loss: 0.363297595404971
Validation loss: 2.6409764704900125

Epoch: 6| Step: 5
Training loss: 0.3662027383522245
Validation loss: 2.6745992384084714

Epoch: 6| Step: 6
Training loss: 0.4353936101050303
Validation loss: 2.6709558939870393

Epoch: 6| Step: 7
Training loss: 0.3191471533416942
Validation loss: 2.6554263764072252

Epoch: 6| Step: 8
Training loss: 0.26136650750124923
Validation loss: 2.756164966404722

Epoch: 6| Step: 9
Training loss: 0.49543700714106065
Validation loss: 2.7284696188716024

Epoch: 6| Step: 10
Training loss: 0.3769961120129255
Validation loss: 2.719369810346805

Epoch: 6| Step: 11
Training loss: 0.39966966802503034
Validation loss: 2.712004276689554

Epoch: 6| Step: 12
Training loss: 0.337378593525329
Validation loss: 2.662253249290447

Epoch: 6| Step: 13
Training loss: 0.3962139278382888
Validation loss: 2.7177250709666487

Epoch: 397| Step: 0
Training loss: 0.39597558510539194
Validation loss: 2.7895974608774154

Epoch: 6| Step: 1
Training loss: 0.3939279154320116
Validation loss: 2.6918227745902317

Epoch: 6| Step: 2
Training loss: 0.45975309888034926
Validation loss: 2.690053067209772

Epoch: 6| Step: 3
Training loss: 0.46384704546113376
Validation loss: 2.67804229323741

Epoch: 6| Step: 4
Training loss: 0.23851606649488516
Validation loss: 2.679642642640182

Epoch: 6| Step: 5
Training loss: 0.517736734523321
Validation loss: 2.74179387324085

Epoch: 6| Step: 6
Training loss: 0.31845217797290293
Validation loss: 2.7093261121821977

Epoch: 6| Step: 7
Training loss: 0.304706328372696
Validation loss: 2.798685322659221

Epoch: 6| Step: 8
Training loss: 0.34077342894130913
Validation loss: 2.730209432866354

Epoch: 6| Step: 9
Training loss: 0.3993098862270348
Validation loss: 2.709109376105828

Epoch: 6| Step: 10
Training loss: 0.322435241913879
Validation loss: 2.6789226719488366

Epoch: 6| Step: 11
Training loss: 0.3173885521002956
Validation loss: 2.731733968587216

Epoch: 6| Step: 12
Training loss: 0.33604076927350607
Validation loss: 2.6941183494800005

Epoch: 6| Step: 13
Training loss: 0.36938926356187235
Validation loss: 2.7056937388259863

Epoch: 398| Step: 0
Training loss: 0.2668034414485854
Validation loss: 2.7055289543518666

Epoch: 6| Step: 1
Training loss: 0.34291501938635516
Validation loss: 2.684376342915209

Epoch: 6| Step: 2
Training loss: 0.43626992120045244
Validation loss: 2.6841235130731236

Epoch: 6| Step: 3
Training loss: 0.3226600198779499
Validation loss: 2.7272799767532714

Epoch: 6| Step: 4
Training loss: 0.33054828453259316
Validation loss: 2.682101023790839

Epoch: 6| Step: 5
Training loss: 0.35461658995710105
Validation loss: 2.658976752244717

Epoch: 6| Step: 6
Training loss: 0.2894969716498413
Validation loss: 2.651883834043772

Epoch: 6| Step: 7
Training loss: 0.3436396161492457
Validation loss: 2.7536565861360645

Epoch: 6| Step: 8
Training loss: 0.2634419604429523
Validation loss: 2.6248411554383937

Epoch: 6| Step: 9
Training loss: 0.2772229966031991
Validation loss: 2.6603770787562944

Epoch: 6| Step: 10
Training loss: 0.26321409540590984
Validation loss: 2.7108390709618604

Epoch: 6| Step: 11
Training loss: 0.4197156532826041
Validation loss: 2.7138905413815757

Epoch: 6| Step: 12
Training loss: 0.4757997474770359
Validation loss: 2.7086653774852096

Epoch: 6| Step: 13
Training loss: 0.28849101924636456
Validation loss: 2.7018362659293085

Epoch: 399| Step: 0
Training loss: 0.24712567971801283
Validation loss: 2.6552066324577006

Epoch: 6| Step: 1
Training loss: 0.35763716337205403
Validation loss: 2.718476380358381

Epoch: 6| Step: 2
Training loss: 0.28728294316206465
Validation loss: 2.7224200240649514

Epoch: 6| Step: 3
Training loss: 0.29047797288457605
Validation loss: 2.7542827808721215

Epoch: 6| Step: 4
Training loss: 0.36214854945153396
Validation loss: 2.6975517369807283

Epoch: 6| Step: 5
Training loss: 0.34785380804503346
Validation loss: 2.7055701807850934

Epoch: 6| Step: 6
Training loss: 0.28361522025811625
Validation loss: 2.690543189080626

Epoch: 6| Step: 7
Training loss: 0.2756362252750047
Validation loss: 2.729435293552098

Epoch: 6| Step: 8
Training loss: 0.28571175330393633
Validation loss: 2.712990898327969

Epoch: 6| Step: 9
Training loss: 0.2937303688713212
Validation loss: 2.78112829849345

Epoch: 6| Step: 10
Training loss: 0.34388251351399124
Validation loss: 2.672392975270308

Epoch: 6| Step: 11
Training loss: 0.41396582572516377
Validation loss: 2.6625577866636627

Epoch: 6| Step: 12
Training loss: 0.4822829505951233
Validation loss: 2.6838985975158294

Epoch: 6| Step: 13
Training loss: 0.411757766641119
Validation loss: 2.6994629531855283

Epoch: 400| Step: 0
Training loss: 0.34969891301979644
Validation loss: 2.693790717528957

Epoch: 6| Step: 1
Training loss: 0.25201474404723545
Validation loss: 2.701886814081896

Epoch: 6| Step: 2
Training loss: 0.21819845558576234
Validation loss: 2.6804949375297618

Epoch: 6| Step: 3
Training loss: 0.35409361656266575
Validation loss: 2.7438640486780628

Epoch: 6| Step: 4
Training loss: 0.2543144026661908
Validation loss: 2.6501479725340804

Epoch: 6| Step: 5
Training loss: 0.31514076015173137
Validation loss: 2.654242486235098

Epoch: 6| Step: 6
Training loss: 0.29150370177704304
Validation loss: 2.7041624132856668

Epoch: 6| Step: 7
Training loss: 0.3332218142564167
Validation loss: 2.7061496196217028

Epoch: 6| Step: 8
Training loss: 0.4282076581810005
Validation loss: 2.6930961747691438

Epoch: 6| Step: 9
Training loss: 0.38406195414716204
Validation loss: 2.6451288371686457

Epoch: 6| Step: 10
Training loss: 0.5116278006996353
Validation loss: 2.6485071088707373

Epoch: 6| Step: 11
Training loss: 0.3250719930615493
Validation loss: 2.6997994489714876

Epoch: 6| Step: 12
Training loss: 0.2925039546242759
Validation loss: 2.7332428977318326

Epoch: 6| Step: 13
Training loss: 0.31490520890277596
Validation loss: 2.697093828325161

Epoch: 401| Step: 0
Training loss: 0.21464978912733246
Validation loss: 2.6728422856753515

Epoch: 6| Step: 1
Training loss: 0.5279849639868521
Validation loss: 2.7243835793185287

Epoch: 6| Step: 2
Training loss: 0.2954598881498531
Validation loss: 2.699148041921084

Epoch: 6| Step: 3
Training loss: 0.44333383091681144
Validation loss: 2.7026548619911934

Epoch: 6| Step: 4
Training loss: 0.3896538296663438
Validation loss: 2.6839415182838295

Epoch: 6| Step: 5
Training loss: 0.37211084019966956
Validation loss: 2.771065671162094

Epoch: 6| Step: 6
Training loss: 0.35561623500487827
Validation loss: 2.7019775836597333

Epoch: 6| Step: 7
Training loss: 0.4587450418022448
Validation loss: 2.7016846599211086

Epoch: 6| Step: 8
Training loss: 0.3198279577138613
Validation loss: 2.705719454285584

Epoch: 6| Step: 9
Training loss: 0.25780420578995095
Validation loss: 2.6589045256734836

Epoch: 6| Step: 10
Training loss: 0.29120593920587895
Validation loss: 2.717032302831964

Epoch: 6| Step: 11
Training loss: 0.3131929582338297
Validation loss: 2.71651119555708

Epoch: 6| Step: 12
Training loss: 0.13910368727336275
Validation loss: 2.751949601794971

Epoch: 6| Step: 13
Training loss: 0.4906262051512866
Validation loss: 2.709463460813487

Epoch: 402| Step: 0
Training loss: 0.24044384391750906
Validation loss: 2.673680028536343

Epoch: 6| Step: 1
Training loss: 0.28264331077367955
Validation loss: 2.660543188632922

Epoch: 6| Step: 2
Training loss: 0.37814460971520747
Validation loss: 2.674819936960702

Epoch: 6| Step: 3
Training loss: 0.2761582841995739
Validation loss: 2.695385092527117

Epoch: 6| Step: 4
Training loss: 0.29742975854307935
Validation loss: 2.686034638470039

Epoch: 6| Step: 5
Training loss: 0.22587279869362234
Validation loss: 2.6113534610863036

Epoch: 6| Step: 6
Training loss: 0.2835549635412184
Validation loss: 2.681980690320752

Epoch: 6| Step: 7
Training loss: 0.3678448656826974
Validation loss: 2.638245505543687

Epoch: 6| Step: 8
Training loss: 0.4353042919154605
Validation loss: 2.6977266639956534

Epoch: 6| Step: 9
Training loss: 0.3247543415222808
Validation loss: 2.651629929143192

Epoch: 6| Step: 10
Training loss: 0.18194038513579777
Validation loss: 2.6815147212905517

Epoch: 6| Step: 11
Training loss: 0.26233904195335905
Validation loss: 2.654531094750566

Epoch: 6| Step: 12
Training loss: 0.2000608225069563
Validation loss: 2.647209512949809

Epoch: 6| Step: 13
Training loss: 0.4173327625275071
Validation loss: 2.6750373641639964

Epoch: 403| Step: 0
Training loss: 0.3536067655479799
Validation loss: 2.6230327409830716

Epoch: 6| Step: 1
Training loss: 0.275260664663982
Validation loss: 2.666333413659122

Epoch: 6| Step: 2
Training loss: 0.24382736708288888
Validation loss: 2.740164957325061

Epoch: 6| Step: 3
Training loss: 0.26754032341349027
Validation loss: 2.6823791094603506

Epoch: 6| Step: 4
Training loss: 0.16417332720638417
Validation loss: 2.6628486873604826

Epoch: 6| Step: 5
Training loss: 0.25995064363225673
Validation loss: 2.7421645175300413

Epoch: 6| Step: 6
Training loss: 0.19197981397740782
Validation loss: 2.687334306917209

Epoch: 6| Step: 7
Training loss: 0.3223979100461928
Validation loss: 2.6989733763412587

Epoch: 6| Step: 8
Training loss: 0.24714027138066286
Validation loss: 2.655695315021398

Epoch: 6| Step: 9
Training loss: 0.3576335176148907
Validation loss: 2.6596760813598275

Epoch: 6| Step: 10
Training loss: 0.3206768754631403
Validation loss: 2.7330641447268462

Epoch: 6| Step: 11
Training loss: 0.3323456117535712
Validation loss: 2.7755287417022765

Epoch: 6| Step: 12
Training loss: 0.35172350693429927
Validation loss: 2.652109247177429

Epoch: 6| Step: 13
Training loss: 0.27171680737108644
Validation loss: 2.6461843473026336

Epoch: 404| Step: 0
Training loss: 0.30641197378209634
Validation loss: 2.705121414811367

Epoch: 6| Step: 1
Training loss: 0.27590234707521527
Validation loss: 2.7527695783263533

Epoch: 6| Step: 2
Training loss: 0.24808988423572456
Validation loss: 2.618635386323696

Epoch: 6| Step: 3
Training loss: 0.3340286649371443
Validation loss: 2.7143282394017842

Epoch: 6| Step: 4
Training loss: 0.3849685830760699
Validation loss: 2.7089392693359815

Epoch: 6| Step: 5
Training loss: 0.23828059337087742
Validation loss: 2.7892501582708973

Epoch: 6| Step: 6
Training loss: 0.2987246490041318
Validation loss: 2.679155791889939

Epoch: 6| Step: 7
Training loss: 0.27840879941015606
Validation loss: 2.6584288393600537

Epoch: 6| Step: 8
Training loss: 0.33532792609603357
Validation loss: 2.706323249418784

Epoch: 6| Step: 9
Training loss: 0.27092546797086536
Validation loss: 2.693361853583885

Epoch: 6| Step: 10
Training loss: 0.39785228086845853
Validation loss: 2.7162821300588242

Epoch: 6| Step: 11
Training loss: 0.19251900901077304
Validation loss: 2.6602962641902246

Epoch: 6| Step: 12
Training loss: 0.27980997398246826
Validation loss: 2.6674957377367847

Epoch: 6| Step: 13
Training loss: 0.2962235279569189
Validation loss: 2.7003268641548313

Epoch: 405| Step: 0
Training loss: 0.22341435185814648
Validation loss: 2.725445071163117

Epoch: 6| Step: 1
Training loss: 0.24138108711824877
Validation loss: 2.6652611565039885

Epoch: 6| Step: 2
Training loss: 0.3091624729282492
Validation loss: 2.6702116683633967

Epoch: 6| Step: 3
Training loss: 0.2790926473380284
Validation loss: 2.6470280800802235

Epoch: 6| Step: 4
Training loss: 0.39936093301132225
Validation loss: 2.681453793716253

Epoch: 6| Step: 5
Training loss: 0.31594178760007635
Validation loss: 2.671927022148665

Epoch: 6| Step: 6
Training loss: 0.4678418899814098
Validation loss: 2.6824001895221854

Epoch: 6| Step: 7
Training loss: 0.229763909041331
Validation loss: 2.596060631374597

Epoch: 6| Step: 8
Training loss: 0.3372138196414905
Validation loss: 2.6408379072023527

Epoch: 6| Step: 9
Training loss: 0.26969552217135406
Validation loss: 2.597129412696748

Epoch: 6| Step: 10
Training loss: 0.3850913436085141
Validation loss: 2.7108981581296656

Epoch: 6| Step: 11
Training loss: 0.3101167158783213
Validation loss: 2.7124163197209694

Epoch: 6| Step: 12
Training loss: 0.31731268474790625
Validation loss: 2.6593464325006617

Epoch: 6| Step: 13
Training loss: 0.43493354276009943
Validation loss: 2.658951735442132

Epoch: 406| Step: 0
Training loss: 0.3739944725673637
Validation loss: 2.7261527918632216

Epoch: 6| Step: 1
Training loss: 0.3153766552068613
Validation loss: 2.6847957934079503

Epoch: 6| Step: 2
Training loss: 0.29976504681978594
Validation loss: 2.6240190459331663

Epoch: 6| Step: 3
Training loss: 0.31229372369107006
Validation loss: 2.6971727668749637

Epoch: 6| Step: 4
Training loss: 0.513685306039876
Validation loss: 2.6581302047021977

Epoch: 6| Step: 5
Training loss: 0.28224451344566154
Validation loss: 2.704122987540394

Epoch: 6| Step: 6
Training loss: 0.37367130366430645
Validation loss: 2.680196960183921

Epoch: 6| Step: 7
Training loss: 0.26250229448496426
Validation loss: 2.7103820143724424

Epoch: 6| Step: 8
Training loss: 0.3790196711095478
Validation loss: 2.68350521646799

Epoch: 6| Step: 9
Training loss: 0.3859506743804124
Validation loss: 2.6818497130103367

Epoch: 6| Step: 10
Training loss: 0.4417396400404788
Validation loss: 2.6713859601334375

Epoch: 6| Step: 11
Training loss: 0.3781534759581139
Validation loss: 2.6850049169058505

Epoch: 6| Step: 12
Training loss: 0.40781058826217675
Validation loss: 2.6458337788819266

Epoch: 6| Step: 13
Training loss: 0.31434202897256497
Validation loss: 2.746203699348156

Epoch: 407| Step: 0
Training loss: 0.29883784857993007
Validation loss: 2.6948493891371847

Epoch: 6| Step: 1
Training loss: 0.237725281530509
Validation loss: 2.7399084432531446

Epoch: 6| Step: 2
Training loss: 0.4235047895730408
Validation loss: 2.7475688909953804

Epoch: 6| Step: 3
Training loss: 0.2147642335260357
Validation loss: 2.6831853223539484

Epoch: 6| Step: 4
Training loss: 0.3584643726868101
Validation loss: 2.7055790222824805

Epoch: 6| Step: 5
Training loss: 0.25598602945700855
Validation loss: 2.6919209985085186

Epoch: 6| Step: 6
Training loss: 0.3612867589417868
Validation loss: 2.7565774070060765

Epoch: 6| Step: 7
Training loss: 0.42361541543486547
Validation loss: 2.7559013408562993

Epoch: 6| Step: 8
Training loss: 0.37098043619097437
Validation loss: 2.7677616264046923

Epoch: 6| Step: 9
Training loss: 0.31432062520622284
Validation loss: 2.7732952959022814

Epoch: 6| Step: 10
Training loss: 0.4211497253696054
Validation loss: 2.7329361826711693

Epoch: 6| Step: 11
Training loss: 0.3629953428355882
Validation loss: 2.6657494119796574

Epoch: 6| Step: 12
Training loss: 0.2918355770565846
Validation loss: 2.6646400638493395

Epoch: 6| Step: 13
Training loss: 0.415530696725373
Validation loss: 2.6679630009527338

Epoch: 408| Step: 0
Training loss: 0.3125283228437037
Validation loss: 2.6801718523429106

Epoch: 6| Step: 1
Training loss: 0.36865905351406264
Validation loss: 2.6680747179142736

Epoch: 6| Step: 2
Training loss: 0.2735675502500058
Validation loss: 2.644319421575874

Epoch: 6| Step: 3
Training loss: 0.3637345674852568
Validation loss: 2.6105446849301797

Epoch: 6| Step: 4
Training loss: 0.3194802800870054
Validation loss: 2.6480177525139417

Epoch: 6| Step: 5
Training loss: 0.3447639077682137
Validation loss: 2.679078057832529

Epoch: 6| Step: 6
Training loss: 0.2944638693760382
Validation loss: 2.676490173728479

Epoch: 6| Step: 7
Training loss: 0.24063915173914502
Validation loss: 2.701988642868468

Epoch: 6| Step: 8
Training loss: 0.37226508141524983
Validation loss: 2.6891680205981765

Epoch: 6| Step: 9
Training loss: 0.2714940762330233
Validation loss: 2.695393716813991

Epoch: 6| Step: 10
Training loss: 0.3401903270671948
Validation loss: 2.722090295159592

Epoch: 6| Step: 11
Training loss: 0.39512989214216143
Validation loss: 2.6823023873025416

Epoch: 6| Step: 12
Training loss: 0.32226702371929533
Validation loss: 2.684789754780487

Epoch: 6| Step: 13
Training loss: 0.2951035476854922
Validation loss: 2.701909580296209

Epoch: 409| Step: 0
Training loss: 0.45356344517975594
Validation loss: 2.6617391230403737

Epoch: 6| Step: 1
Training loss: 0.4267982446298369
Validation loss: 2.682392056756186

Epoch: 6| Step: 2
Training loss: 0.40341462517384447
Validation loss: 2.734276993221276

Epoch: 6| Step: 3
Training loss: 0.3254147954529623
Validation loss: 2.621012019831732

Epoch: 6| Step: 4
Training loss: 0.403966575264361
Validation loss: 2.7273679634767025

Epoch: 6| Step: 5
Training loss: 0.3854169029372582
Validation loss: 2.705264999232908

Epoch: 6| Step: 6
Training loss: 0.2667919778444222
Validation loss: 2.719497103003219

Epoch: 6| Step: 7
Training loss: 0.2644995661292096
Validation loss: 2.667936132184168

Epoch: 6| Step: 8
Training loss: 0.38971357828843844
Validation loss: 2.652935218688251

Epoch: 6| Step: 9
Training loss: 0.3694932252704191
Validation loss: 2.691546269923752

Epoch: 6| Step: 10
Training loss: 0.423912250941736
Validation loss: 2.7321161294954193

Epoch: 6| Step: 11
Training loss: 0.41037410218451154
Validation loss: 2.644929683990962

Epoch: 6| Step: 12
Training loss: 0.24018951710527256
Validation loss: 2.7262525992633986

Epoch: 6| Step: 13
Training loss: 0.23883899700162625
Validation loss: 2.707685287900739

Epoch: 410| Step: 0
Training loss: 0.2582491154189345
Validation loss: 2.7198520122385124

Epoch: 6| Step: 1
Training loss: 0.5019839384959484
Validation loss: 2.7363762643678817

Epoch: 6| Step: 2
Training loss: 0.2325788977279871
Validation loss: 2.7667195368697963

Epoch: 6| Step: 3
Training loss: 0.49206253766341124
Validation loss: 2.705021569570873

Epoch: 6| Step: 4
Training loss: 0.2516523088350043
Validation loss: 2.6279979721982767

Epoch: 6| Step: 5
Training loss: 0.3589490979018183
Validation loss: 2.704787843555541

Epoch: 6| Step: 6
Training loss: 0.3014005008463631
Validation loss: 2.6538591732760466

Epoch: 6| Step: 7
Training loss: 0.36003764882844347
Validation loss: 2.6726150677528246

Epoch: 6| Step: 8
Training loss: 0.4242496064768165
Validation loss: 2.6509706428971564

Epoch: 6| Step: 9
Training loss: 0.30023763503469414
Validation loss: 2.6960261630195266

Epoch: 6| Step: 10
Training loss: 0.3621509976626217
Validation loss: 2.70620475654871

Epoch: 6| Step: 11
Training loss: 0.3161036374727876
Validation loss: 2.682275928833849

Epoch: 6| Step: 12
Training loss: 0.31044514507298115
Validation loss: 2.7402465196495807

Epoch: 6| Step: 13
Training loss: 0.41003081810661524
Validation loss: 2.746286789687182

Epoch: 411| Step: 0
Training loss: 0.39078221018603454
Validation loss: 2.6651341360878553

Epoch: 6| Step: 1
Training loss: 0.3448456836675609
Validation loss: 2.6505109984073685

Epoch: 6| Step: 2
Training loss: 0.408891344101216
Validation loss: 2.6746838920608447

Epoch: 6| Step: 3
Training loss: 0.27217415103522413
Validation loss: 2.7009996206176674

Epoch: 6| Step: 4
Training loss: 0.26188281596134755
Validation loss: 2.6402588313911948

Epoch: 6| Step: 5
Training loss: 0.4557344345514919
Validation loss: 2.6719373654826106

Epoch: 6| Step: 6
Training loss: 0.3513439452800091
Validation loss: 2.6490688715432835

Epoch: 6| Step: 7
Training loss: 0.33022547711454797
Validation loss: 2.6893001559989145

Epoch: 6| Step: 8
Training loss: 0.3021954446239404
Validation loss: 2.6827074018838535

Epoch: 6| Step: 9
Training loss: 0.36629450543901587
Validation loss: 2.670344741772475

Epoch: 6| Step: 10
Training loss: 0.2751801680871048
Validation loss: 2.6121127296343687

Epoch: 6| Step: 11
Training loss: 0.36173135064013245
Validation loss: 2.694296412208576

Epoch: 6| Step: 12
Training loss: 0.31473231508855154
Validation loss: 2.733207162604467

Epoch: 6| Step: 13
Training loss: 0.2783079847316061
Validation loss: 2.691085434586477

Epoch: 412| Step: 0
Training loss: 0.34102103326273375
Validation loss: 2.7035841799894422

Epoch: 6| Step: 1
Training loss: 0.39543565633508915
Validation loss: 2.6934773560138603

Epoch: 6| Step: 2
Training loss: 0.3262747642282405
Validation loss: 2.715170348942821

Epoch: 6| Step: 3
Training loss: 0.35543772803122015
Validation loss: 2.6659500803360157

Epoch: 6| Step: 4
Training loss: 0.2777992591234219
Validation loss: 2.7373629856513424

Epoch: 6| Step: 5
Training loss: 0.3399995249506493
Validation loss: 2.707580862907128

Epoch: 6| Step: 6
Training loss: 0.31567208156117277
Validation loss: 2.6377301722848414

Epoch: 6| Step: 7
Training loss: 0.46160413736343664
Validation loss: 2.6508904634435626

Epoch: 6| Step: 8
Training loss: 0.28679904904706666
Validation loss: 2.636169067353582

Epoch: 6| Step: 9
Training loss: 0.33140817410541334
Validation loss: 2.7827245682323722

Epoch: 6| Step: 10
Training loss: 0.2996197854114658
Validation loss: 2.728606266017125

Epoch: 6| Step: 11
Training loss: 0.3394405999193997
Validation loss: 2.647949743977182

Epoch: 6| Step: 12
Training loss: 0.3723519128184018
Validation loss: 2.733149829864827

Epoch: 6| Step: 13
Training loss: 0.28756126860131287
Validation loss: 2.677808824093639

Epoch: 413| Step: 0
Training loss: 0.26764455374455903
Validation loss: 2.6665829754650576

Epoch: 6| Step: 1
Training loss: 0.3515167418477141
Validation loss: 2.72525494400741

Epoch: 6| Step: 2
Training loss: 0.3221284747885538
Validation loss: 2.67096345161008

Epoch: 6| Step: 3
Training loss: 0.26896363073392227
Validation loss: 2.734122622514111

Epoch: 6| Step: 4
Training loss: 0.3693060529491194
Validation loss: 2.6958025058436115

Epoch: 6| Step: 5
Training loss: 0.20134199227183497
Validation loss: 2.6800361013590486

Epoch: 6| Step: 6
Training loss: 0.2509373734451298
Validation loss: 2.6587038112849566

Epoch: 6| Step: 7
Training loss: 0.36521377097370633
Validation loss: 2.657779567364218

Epoch: 6| Step: 8
Training loss: 0.2579710790574072
Validation loss: 2.6343948333343588

Epoch: 6| Step: 9
Training loss: 0.31812851381141255
Validation loss: 2.7120935208747627

Epoch: 6| Step: 10
Training loss: 0.2822453053728512
Validation loss: 2.624279135164211

Epoch: 6| Step: 11
Training loss: 0.2667971023178808
Validation loss: 2.707697945424415

Epoch: 6| Step: 12
Training loss: 0.28500262786256036
Validation loss: 2.703590367707933

Epoch: 6| Step: 13
Training loss: 0.23647273187169657
Validation loss: 2.588404290425563

Epoch: 414| Step: 0
Training loss: 0.2654840010987862
Validation loss: 2.681442242290732

Epoch: 6| Step: 1
Training loss: 0.36910699761836224
Validation loss: 2.723917540809456

Epoch: 6| Step: 2
Training loss: 0.33687058320272906
Validation loss: 2.647223060058945

Epoch: 6| Step: 3
Training loss: 0.25379865273898883
Validation loss: 2.6378245053129037

Epoch: 6| Step: 4
Training loss: 0.282313481974166
Validation loss: 2.722517786286085

Epoch: 6| Step: 5
Training loss: 0.3780803330892156
Validation loss: 2.6406796692375036

Epoch: 6| Step: 6
Training loss: 0.283861591813618
Validation loss: 2.630676429314084

Epoch: 6| Step: 7
Training loss: 0.36647831629012434
Validation loss: 2.6935010415880045

Epoch: 6| Step: 8
Training loss: 0.42342105777250144
Validation loss: 2.699839600166649

Epoch: 6| Step: 9
Training loss: 0.3932357518063665
Validation loss: 2.688825505903565

Epoch: 6| Step: 10
Training loss: 0.40728850774035935
Validation loss: 2.5936722035211854

Epoch: 6| Step: 11
Training loss: 0.4386191359329358
Validation loss: 2.6822549440900882

Epoch: 6| Step: 12
Training loss: 0.27556860022347746
Validation loss: 2.6913569962156827

Epoch: 6| Step: 13
Training loss: 0.2670023215100092
Validation loss: 2.672933119864208

Epoch: 415| Step: 0
Training loss: 0.25642433109726176
Validation loss: 2.646797767842511

Epoch: 6| Step: 1
Training loss: 0.37084050823442855
Validation loss: 2.6959788802495974

Epoch: 6| Step: 2
Training loss: 0.2665671162132906
Validation loss: 2.7226467342201297

Epoch: 6| Step: 3
Training loss: 0.32883019961234905
Validation loss: 2.7158379214110417

Epoch: 6| Step: 4
Training loss: 0.33291973839887623
Validation loss: 2.715181076352817

Epoch: 6| Step: 5
Training loss: 0.3674419414305689
Validation loss: 2.6431517240457634

Epoch: 6| Step: 6
Training loss: 0.37522503935148876
Validation loss: 2.745518370428475

Epoch: 6| Step: 7
Training loss: 0.30271032914678386
Validation loss: 2.689996003853478

Epoch: 6| Step: 8
Training loss: 0.2928692966773652
Validation loss: 2.745211275420521

Epoch: 6| Step: 9
Training loss: 0.2772573685780493
Validation loss: 2.696071602630807

Epoch: 6| Step: 10
Training loss: 0.48821251957681855
Validation loss: 2.7223464373601733

Epoch: 6| Step: 11
Training loss: 0.33569519042469376
Validation loss: 2.720180398274104

Epoch: 6| Step: 12
Training loss: 0.16462257132299218
Validation loss: 2.6600720900611905

Epoch: 6| Step: 13
Training loss: 0.27445838271658396
Validation loss: 2.7668929489124574

Epoch: 416| Step: 0
Training loss: 0.28042526651849126
Validation loss: 2.6542506453694252

Epoch: 6| Step: 1
Training loss: 0.22661563644801577
Validation loss: 2.724438996268933

Epoch: 6| Step: 2
Training loss: 0.20914550167093796
Validation loss: 2.6315324276861314

Epoch: 6| Step: 3
Training loss: 0.28088317897552983
Validation loss: 2.7258800537885395

Epoch: 6| Step: 4
Training loss: 0.4371444415360721
Validation loss: 2.729890601163475

Epoch: 6| Step: 5
Training loss: 0.41947462527356505
Validation loss: 2.614130624330724

Epoch: 6| Step: 6
Training loss: 0.3060151055696553
Validation loss: 2.6454373361205934

Epoch: 6| Step: 7
Training loss: 0.3297373123866016
Validation loss: 2.6253114545823317

Epoch: 6| Step: 8
Training loss: 0.2761845338933631
Validation loss: 2.6579541443150316

Epoch: 6| Step: 9
Training loss: 0.2574544211668306
Validation loss: 2.6413290902178614

Epoch: 6| Step: 10
Training loss: 0.40516830367559603
Validation loss: 2.6720803983089194

Epoch: 6| Step: 11
Training loss: 0.3918919426086087
Validation loss: 2.63721458011614

Epoch: 6| Step: 12
Training loss: 0.34355216402186456
Validation loss: 2.7655667659857053

Epoch: 6| Step: 13
Training loss: 0.3943648601201759
Validation loss: 2.6376404307555994

Epoch: 417| Step: 0
Training loss: 0.43332548692214046
Validation loss: 2.658326014645187

Epoch: 6| Step: 1
Training loss: 0.2105966392406069
Validation loss: 2.7456485971718623

Epoch: 6| Step: 2
Training loss: 0.28683198776757024
Validation loss: 2.6708814175265148

Epoch: 6| Step: 3
Training loss: 0.30206516501720937
Validation loss: 2.717095437957175

Epoch: 6| Step: 4
Training loss: 0.3565336144170233
Validation loss: 2.6932541584858707

Epoch: 6| Step: 5
Training loss: 0.2885363791195891
Validation loss: 2.698605347644277

Epoch: 6| Step: 6
Training loss: 0.30982704227201957
Validation loss: 2.631067620342537

Epoch: 6| Step: 7
Training loss: 0.3234694681632275
Validation loss: 2.630472488483748

Epoch: 6| Step: 8
Training loss: 0.38307756861548936
Validation loss: 2.6349426315644795

Epoch: 6| Step: 9
Training loss: 0.3627571509278851
Validation loss: 2.691053185560981

Epoch: 6| Step: 10
Training loss: 0.4016406202214257
Validation loss: 2.691147746169174

Epoch: 6| Step: 11
Training loss: 0.36995186044720396
Validation loss: 2.6406757718534153

Epoch: 6| Step: 12
Training loss: 0.2300913031387216
Validation loss: 2.6859220115595264

Epoch: 6| Step: 13
Training loss: 0.3939226763401155
Validation loss: 2.699456402722327

Epoch: 418| Step: 0
Training loss: 0.3029724907410504
Validation loss: 2.627767610082206

Epoch: 6| Step: 1
Training loss: 0.3329949809983485
Validation loss: 2.6722778626353056

Epoch: 6| Step: 2
Training loss: 0.18604303578588155
Validation loss: 2.6027204592280904

Epoch: 6| Step: 3
Training loss: 0.3121512851578035
Validation loss: 2.676894650075065

Epoch: 6| Step: 4
Training loss: 0.41550324456409016
Validation loss: 2.7104211218345515

Epoch: 6| Step: 5
Training loss: 0.39563931763159055
Validation loss: 2.7060751426067764

Epoch: 6| Step: 6
Training loss: 0.26445501374735186
Validation loss: 2.584340189000121

Epoch: 6| Step: 7
Training loss: 0.2874447038589274
Validation loss: 2.7044672196993975

Epoch: 6| Step: 8
Training loss: 0.24356366456839698
Validation loss: 2.7477698675647573

Epoch: 6| Step: 9
Training loss: 0.3624095302353404
Validation loss: 2.6500481778089924

Epoch: 6| Step: 10
Training loss: 0.2987291384041012
Validation loss: 2.6708610499506547

Epoch: 6| Step: 11
Training loss: 0.29033255578643913
Validation loss: 2.708189275773935

Epoch: 6| Step: 12
Training loss: 0.3049485726462111
Validation loss: 2.650938632863966

Epoch: 6| Step: 13
Training loss: 0.3238495022444075
Validation loss: 2.6966735057327567

Epoch: 419| Step: 0
Training loss: 0.34375089948709886
Validation loss: 2.6845181061002705

Epoch: 6| Step: 1
Training loss: 0.34981912043203706
Validation loss: 2.692682842869379

Epoch: 6| Step: 2
Training loss: 0.3723093301389346
Validation loss: 2.6604507440123597

Epoch: 6| Step: 3
Training loss: 0.3712312945396209
Validation loss: 2.6979588440257953

Epoch: 6| Step: 4
Training loss: 0.26599782136333255
Validation loss: 2.680899995428188

Epoch: 6| Step: 5
Training loss: 0.3966816942022402
Validation loss: 2.6656749689353623

Epoch: 6| Step: 6
Training loss: 0.34015926973038985
Validation loss: 2.649374511963479

Epoch: 6| Step: 7
Training loss: 0.38090158864363766
Validation loss: 2.732226997644692

Epoch: 6| Step: 8
Training loss: 0.2108629324472656
Validation loss: 2.6585930681447287

Epoch: 6| Step: 9
Training loss: 0.295932679665773
Validation loss: 2.734163141671741

Epoch: 6| Step: 10
Training loss: 0.2933834066084548
Validation loss: 2.6987512812126244

Epoch: 6| Step: 11
Training loss: 0.3670841436813769
Validation loss: 2.663377451891317

Epoch: 6| Step: 12
Training loss: 0.33808465579454927
Validation loss: 2.727876577904793

Epoch: 6| Step: 13
Training loss: 0.30660591414978483
Validation loss: 2.659562315808257

Epoch: 420| Step: 0
Training loss: 0.3541602690436778
Validation loss: 2.635580552826727

Epoch: 6| Step: 1
Training loss: 0.30129423612081824
Validation loss: 2.6641808685824677

Epoch: 6| Step: 2
Training loss: 0.38618308836477117
Validation loss: 2.6598354749303033

Epoch: 6| Step: 3
Training loss: 0.4591666001921581
Validation loss: 2.6231349647180613

Epoch: 6| Step: 4
Training loss: 0.32173699457386834
Validation loss: 2.6538265467471933

Epoch: 6| Step: 5
Training loss: 0.22966302235244482
Validation loss: 2.6277258737365234

Epoch: 6| Step: 6
Training loss: 0.2807937471116746
Validation loss: 2.630077242967964

Epoch: 6| Step: 7
Training loss: 0.2919492913316768
Validation loss: 2.674141337234239

Epoch: 6| Step: 8
Training loss: 0.36964140332964796
Validation loss: 2.665016577730512

Epoch: 6| Step: 9
Training loss: 0.33559444565456253
Validation loss: 2.690389299868422

Epoch: 6| Step: 10
Training loss: 0.3815419072335842
Validation loss: 2.6594308245873934

Epoch: 6| Step: 11
Training loss: 0.3006020916519883
Validation loss: 2.6582051879067583

Epoch: 6| Step: 12
Training loss: 0.29018254696564527
Validation loss: 2.6906212417156867

Epoch: 6| Step: 13
Training loss: 0.34621729572375315
Validation loss: 2.699026488299124

Epoch: 421| Step: 0
Training loss: 0.29676098893024594
Validation loss: 2.6231961334474962

Epoch: 6| Step: 1
Training loss: 0.22305850451293463
Validation loss: 2.5889392652326384

Epoch: 6| Step: 2
Training loss: 0.36875235104215476
Validation loss: 2.6196255994659152

Epoch: 6| Step: 3
Training loss: 0.34760551939737183
Validation loss: 2.6486996171212165

Epoch: 6| Step: 4
Training loss: 0.28063525461521405
Validation loss: 2.66434179726945

Epoch: 6| Step: 5
Training loss: 0.20512921741364581
Validation loss: 2.593371459424079

Epoch: 6| Step: 6
Training loss: 0.28748914034692397
Validation loss: 2.6648724202053025

Epoch: 6| Step: 7
Training loss: 0.28621961299076004
Validation loss: 2.6837600737905163

Epoch: 6| Step: 8
Training loss: 0.306103570146749
Validation loss: 2.6797658095117804

Epoch: 6| Step: 9
Training loss: 0.3500733094415188
Validation loss: 2.678136986817309

Epoch: 6| Step: 10
Training loss: 0.3028390272821488
Validation loss: 2.7097819024591936

Epoch: 6| Step: 11
Training loss: 0.23847618102996834
Validation loss: 2.615498938460424

Epoch: 6| Step: 12
Training loss: 0.23631087153483288
Validation loss: 2.6366196225217777

Epoch: 6| Step: 13
Training loss: 0.32637506426398216
Validation loss: 2.687494085734166

Epoch: 422| Step: 0
Training loss: 0.31941880017238256
Validation loss: 2.6617631134286306

Epoch: 6| Step: 1
Training loss: 0.48736304352274146
Validation loss: 2.6576326175182987

Epoch: 6| Step: 2
Training loss: 0.2720055825593211
Validation loss: 2.610025625529375

Epoch: 6| Step: 3
Training loss: 0.2769778349577667
Validation loss: 2.689547342955423

Epoch: 6| Step: 4
Training loss: 0.3115248485760435
Validation loss: 2.68906931930762

Epoch: 6| Step: 5
Training loss: 0.3520489823590375
Validation loss: 2.6488971517630095

Epoch: 6| Step: 6
Training loss: 0.3179765634724896
Validation loss: 2.6432541167987447

Epoch: 6| Step: 7
Training loss: 0.2991213886634402
Validation loss: 2.7469746391848595

Epoch: 6| Step: 8
Training loss: 0.4609246494635548
Validation loss: 2.6980836416489535

Epoch: 6| Step: 9
Training loss: 0.2243864777878169
Validation loss: 2.715899255422062

Epoch: 6| Step: 10
Training loss: 0.3356038033062741
Validation loss: 2.6766209159692482

Epoch: 6| Step: 11
Training loss: 0.27241414533128827
Validation loss: 2.7206985535666535

Epoch: 6| Step: 12
Training loss: 0.3578192997582012
Validation loss: 2.702767291500096

Epoch: 6| Step: 13
Training loss: 0.24203609533120524
Validation loss: 2.681336372899053

Epoch: 423| Step: 0
Training loss: 0.502105096158056
Validation loss: 2.721364426783639

Epoch: 6| Step: 1
Training loss: 0.30767664259111555
Validation loss: 2.6994377374950638

Epoch: 6| Step: 2
Training loss: 0.3425262407532219
Validation loss: 2.7031829695466842

Epoch: 6| Step: 3
Training loss: 0.5185098000044484
Validation loss: 2.737035971553245

Epoch: 6| Step: 4
Training loss: 0.2050087584392349
Validation loss: 2.7035915141245312

Epoch: 6| Step: 5
Training loss: 0.29154426129240457
Validation loss: 2.6761066470950254

Epoch: 6| Step: 6
Training loss: 0.29815557005232685
Validation loss: 2.663481081165504

Epoch: 6| Step: 7
Training loss: 0.2857446869892723
Validation loss: 2.701172948889014

Epoch: 6| Step: 8
Training loss: 0.44699194918386714
Validation loss: 2.7028211595591576

Epoch: 6| Step: 9
Training loss: 0.41710754156915436
Validation loss: 2.735800438771377

Epoch: 6| Step: 10
Training loss: 0.3341424467560235
Validation loss: 2.680948174064041

Epoch: 6| Step: 11
Training loss: 0.19510691313092762
Validation loss: 2.7012497087814173

Epoch: 6| Step: 12
Training loss: 0.32024269971708624
Validation loss: 2.6794058574812474

Epoch: 6| Step: 13
Training loss: 0.1952139510439164
Validation loss: 2.6963009261225253

Epoch: 424| Step: 0
Training loss: 0.3275922355642323
Validation loss: 2.7006303083889525

Epoch: 6| Step: 1
Training loss: 0.2622967500827806
Validation loss: 2.718745184123133

Epoch: 6| Step: 2
Training loss: 0.3595189345338157
Validation loss: 2.75117593245266

Epoch: 6| Step: 3
Training loss: 0.3365462908122304
Validation loss: 2.687230000499002

Epoch: 6| Step: 4
Training loss: 0.32316670299932804
Validation loss: 2.713742903400398

Epoch: 6| Step: 5
Training loss: 0.2615951844215826
Validation loss: 2.709793105785048

Epoch: 6| Step: 6
Training loss: 0.21166342755026987
Validation loss: 2.737500546076472

Epoch: 6| Step: 7
Training loss: 0.22992983542118678
Validation loss: 2.740549567419453

Epoch: 6| Step: 8
Training loss: 0.40864570024838087
Validation loss: 2.7081950127908248

Epoch: 6| Step: 9
Training loss: 0.3414602420284944
Validation loss: 2.700927958735142

Epoch: 6| Step: 10
Training loss: 0.31354141752839354
Validation loss: 2.700114151813905

Epoch: 6| Step: 11
Training loss: 0.3093156338577469
Validation loss: 2.7088853322437703

Epoch: 6| Step: 12
Training loss: 0.3936369930559036
Validation loss: 2.6295536372112216

Epoch: 6| Step: 13
Training loss: 0.24411543906954228
Validation loss: 2.684231870578357

Epoch: 425| Step: 0
Training loss: 0.2882314023803279
Validation loss: 2.6935297797066142

Epoch: 6| Step: 1
Training loss: 0.39308795751404985
Validation loss: 2.680971407106927

Epoch: 6| Step: 2
Training loss: 0.36750134792210437
Validation loss: 2.6609179003432915

Epoch: 6| Step: 3
Training loss: 0.32051782307633325
Validation loss: 2.7232207156007897

Epoch: 6| Step: 4
Training loss: 0.24103241464755618
Validation loss: 2.6435869598015875

Epoch: 6| Step: 5
Training loss: 0.29336747058004364
Validation loss: 2.6362902483845394

Epoch: 6| Step: 6
Training loss: 0.32591249808941797
Validation loss: 2.6761052142050055

Epoch: 6| Step: 7
Training loss: 0.47443157366319066
Validation loss: 2.6719413436773127

Epoch: 6| Step: 8
Training loss: 0.33665022539997813
Validation loss: 2.7288540425709327

Epoch: 6| Step: 9
Training loss: 0.23608319539803208
Validation loss: 2.746547771777073

Epoch: 6| Step: 10
Training loss: 0.22864310466438686
Validation loss: 2.733023027701057

Epoch: 6| Step: 11
Training loss: 0.4427100649033136
Validation loss: 2.7180301107797664

Epoch: 6| Step: 12
Training loss: 0.3292315082223378
Validation loss: 2.714309866757122

Epoch: 6| Step: 13
Training loss: 0.3003574953300711
Validation loss: 2.6770711940584158

Epoch: 426| Step: 0
Training loss: 0.32449297051537906
Validation loss: 2.730563997527489

Epoch: 6| Step: 1
Training loss: 0.3511332752709793
Validation loss: 2.673111969454715

Epoch: 6| Step: 2
Training loss: 0.31702794116057487
Validation loss: 2.689738590675198

Epoch: 6| Step: 3
Training loss: 0.26723367559732564
Validation loss: 2.725337557635732

Epoch: 6| Step: 4
Training loss: 0.2953054952042988
Validation loss: 2.7795372021536844

Epoch: 6| Step: 5
Training loss: 0.3595166549140648
Validation loss: 2.711550142246053

Epoch: 6| Step: 6
Training loss: 0.37792456177382444
Validation loss: 2.6859250813822713

Epoch: 6| Step: 7
Training loss: 0.3406242418718213
Validation loss: 2.647610755695389

Epoch: 6| Step: 8
Training loss: 0.30189093952469587
Validation loss: 2.7094661153206925

Epoch: 6| Step: 9
Training loss: 0.2868887124700847
Validation loss: 2.5981788358172326

Epoch: 6| Step: 10
Training loss: 0.27043395979494594
Validation loss: 2.668813367890879

Epoch: 6| Step: 11
Training loss: 0.45061696594314316
Validation loss: 2.655766970528798

Epoch: 6| Step: 12
Training loss: 0.2422361709541929
Validation loss: 2.662087790946753

Epoch: 6| Step: 13
Training loss: 0.3401985946743985
Validation loss: 2.718422208588717

Epoch: 427| Step: 0
Training loss: 0.33947029641006476
Validation loss: 2.663820451496664

Epoch: 6| Step: 1
Training loss: 0.30571314993413073
Validation loss: 2.691287248007889

Epoch: 6| Step: 2
Training loss: 0.29587527143484477
Validation loss: 2.652975764606169

Epoch: 6| Step: 3
Training loss: 0.3069771663215288
Validation loss: 2.6379451207363824

Epoch: 6| Step: 4
Training loss: 0.39940171350914805
Validation loss: 2.673431493387139

Epoch: 6| Step: 5
Training loss: 0.346372011150459
Validation loss: 2.6881566391370235

Epoch: 6| Step: 6
Training loss: 0.3822236105327812
Validation loss: 2.6475254765318295

Epoch: 6| Step: 7
Training loss: 0.2955901047110507
Validation loss: 2.6493575861932173

Epoch: 6| Step: 8
Training loss: 0.36545594782136437
Validation loss: 2.646694453723752

Epoch: 6| Step: 9
Training loss: 0.3431727916842673
Validation loss: 2.692879578527166

Epoch: 6| Step: 10
Training loss: 0.1989972247979728
Validation loss: 2.6907333322677647

Epoch: 6| Step: 11
Training loss: 0.4779676452703763
Validation loss: 2.679080149161823

Epoch: 6| Step: 12
Training loss: 0.28105898834606724
Validation loss: 2.6803860360954204

Epoch: 6| Step: 13
Training loss: 0.40158832333428973
Validation loss: 2.7039868004517165

Epoch: 428| Step: 0
Training loss: 0.27716493886759674
Validation loss: 2.64731445807833

Epoch: 6| Step: 1
Training loss: 0.3679257134865781
Validation loss: 2.7019113745245824

Epoch: 6| Step: 2
Training loss: 0.40361130679552365
Validation loss: 2.7139301253858

Epoch: 6| Step: 3
Training loss: 0.3197714492711064
Validation loss: 2.715665170645342

Epoch: 6| Step: 4
Training loss: 0.2561525165238781
Validation loss: 2.7076111980086632

Epoch: 6| Step: 5
Training loss: 0.33220183534453945
Validation loss: 2.7473113181085207

Epoch: 6| Step: 6
Training loss: 0.18532278683690584
Validation loss: 2.689946450961397

Epoch: 6| Step: 7
Training loss: 0.31630474393267805
Validation loss: 2.6921121514053277

Epoch: 6| Step: 8
Training loss: 0.3916201694091981
Validation loss: 2.683468522838413

Epoch: 6| Step: 9
Training loss: 0.37470907608917836
Validation loss: 2.7016925360539092

Epoch: 6| Step: 10
Training loss: 0.18930389976927933
Validation loss: 2.67821543068666

Epoch: 6| Step: 11
Training loss: 0.26811590241512395
Validation loss: 2.677545564479281

Epoch: 6| Step: 12
Training loss: 0.29426797792292775
Validation loss: 2.668227526214788

Epoch: 6| Step: 13
Training loss: 0.2960453235410205
Validation loss: 2.702180833510891

Epoch: 429| Step: 0
Training loss: 0.31076113189359905
Validation loss: 2.706679797970656

Epoch: 6| Step: 1
Training loss: 0.23660837061324416
Validation loss: 2.7230516654660906

Epoch: 6| Step: 2
Training loss: 0.2641342629876867
Validation loss: 2.7189719997400923

Epoch: 6| Step: 3
Training loss: 0.3563370631727226
Validation loss: 2.7631925097506653

Epoch: 6| Step: 4
Training loss: 0.2814618478400772
Validation loss: 2.703103375945578

Epoch: 6| Step: 5
Training loss: 0.31621020330540583
Validation loss: 2.7166231101197167

Epoch: 6| Step: 6
Training loss: 0.3277220863520933
Validation loss: 2.7607031955401067

Epoch: 6| Step: 7
Training loss: 0.3158900795466902
Validation loss: 2.6792061153689484

Epoch: 6| Step: 8
Training loss: 0.2981080248736298
Validation loss: 2.6902357637333405

Epoch: 6| Step: 9
Training loss: 0.209626468127847
Validation loss: 2.6455258368479746

Epoch: 6| Step: 10
Training loss: 0.25669633675804626
Validation loss: 2.721891597751213

Epoch: 6| Step: 11
Training loss: 0.2949350871985563
Validation loss: 2.6714854486259427

Epoch: 6| Step: 12
Training loss: 0.304161926726855
Validation loss: 2.702659022863212

Epoch: 6| Step: 13
Training loss: 0.4461527643400896
Validation loss: 2.6596593332007474

Epoch: 430| Step: 0
Training loss: 0.3369972679115164
Validation loss: 2.676472075820917

Epoch: 6| Step: 1
Training loss: 0.3760158567826147
Validation loss: 2.695893266553092

Epoch: 6| Step: 2
Training loss: 0.38834202250526717
Validation loss: 2.632252702524012

Epoch: 6| Step: 3
Training loss: 0.2037247277307511
Validation loss: 2.692741502057045

Epoch: 6| Step: 4
Training loss: 0.18599164759368927
Validation loss: 2.680562120362601

Epoch: 6| Step: 5
Training loss: 0.48034149903893064
Validation loss: 2.6836812959667995

Epoch: 6| Step: 6
Training loss: 0.3417583334854834
Validation loss: 2.6282394039550416

Epoch: 6| Step: 7
Training loss: 0.2618044243261675
Validation loss: 2.61658276455805

Epoch: 6| Step: 8
Training loss: 0.32958030404307476
Validation loss: 2.6111197663111887

Epoch: 6| Step: 9
Training loss: 0.4217926580815677
Validation loss: 2.5750028104056915

Epoch: 6| Step: 10
Training loss: 0.36789126623150054
Validation loss: 2.613548268968299

Epoch: 6| Step: 11
Training loss: 0.33758420776734815
Validation loss: 2.6808101426642192

Epoch: 6| Step: 12
Training loss: 0.382696172984465
Validation loss: 2.6683949678817314

Epoch: 6| Step: 13
Training loss: 0.2468711970434744
Validation loss: 2.6148318796958807

Epoch: 431| Step: 0
Training loss: 0.21909963391006612
Validation loss: 2.6157347029844784

Epoch: 6| Step: 1
Training loss: 0.2111198908321464
Validation loss: 2.668666094995355

Epoch: 6| Step: 2
Training loss: 0.26175757732190086
Validation loss: 2.6209970409973824

Epoch: 6| Step: 3
Training loss: 0.3910718269619838
Validation loss: 2.6635820807676898

Epoch: 6| Step: 4
Training loss: 0.3533189764045011
Validation loss: 2.6753510437930603

Epoch: 6| Step: 5
Training loss: 0.26726966676440844
Validation loss: 2.669685984015746

Epoch: 6| Step: 6
Training loss: 0.33169495999041027
Validation loss: 2.6469885614467685

Epoch: 6| Step: 7
Training loss: 0.29505851561270746
Validation loss: 2.6025251530125875

Epoch: 6| Step: 8
Training loss: 0.3580432972072742
Validation loss: 2.5875293330742855

Epoch: 6| Step: 9
Training loss: 0.334403527905652
Validation loss: 2.598267952163915

Epoch: 6| Step: 10
Training loss: 0.3347793064415316
Validation loss: 2.597929027643192

Epoch: 6| Step: 11
Training loss: 0.29132307056923024
Validation loss: 2.6483569362693706

Epoch: 6| Step: 12
Training loss: 0.364562860549861
Validation loss: 2.608558953574771

Epoch: 6| Step: 13
Training loss: 0.2638387364000739
Validation loss: 2.62145364472676

Epoch: 432| Step: 0
Training loss: 0.2613761139330121
Validation loss: 2.6695775421835517

Epoch: 6| Step: 1
Training loss: 0.37353864680635235
Validation loss: 2.6739439956603617

Epoch: 6| Step: 2
Training loss: 0.22429115309370945
Validation loss: 2.6548159449418978

Epoch: 6| Step: 3
Training loss: 0.33119058211059216
Validation loss: 2.6641974689976866

Epoch: 6| Step: 4
Training loss: 0.17624571684272825
Validation loss: 2.6361683664333504

Epoch: 6| Step: 5
Training loss: 0.35768259680528636
Validation loss: 2.6145042062972266

Epoch: 6| Step: 6
Training loss: 0.32177397475845054
Validation loss: 2.674280596935564

Epoch: 6| Step: 7
Training loss: 0.31939319948795747
Validation loss: 2.70991348729104

Epoch: 6| Step: 8
Training loss: 0.26422358119885775
Validation loss: 2.650860783389769

Epoch: 6| Step: 9
Training loss: 0.3116350123621332
Validation loss: 2.6960777191596357

Epoch: 6| Step: 10
Training loss: 0.25558905845484486
Validation loss: 2.717964219581781

Epoch: 6| Step: 11
Training loss: 0.2853551458385737
Validation loss: 2.626336158804986

Epoch: 6| Step: 12
Training loss: 0.33755061511804574
Validation loss: 2.6844064369477665

Epoch: 6| Step: 13
Training loss: 0.2812434831500035
Validation loss: 2.6416023146275114

Epoch: 433| Step: 0
Training loss: 0.33819658836626904
Validation loss: 2.6565534680116536

Epoch: 6| Step: 1
Training loss: 0.31768874462378444
Validation loss: 2.748662449933035

Epoch: 6| Step: 2
Training loss: 0.37446500444580394
Validation loss: 2.6822316925356064

Epoch: 6| Step: 3
Training loss: 0.2135419506365741
Validation loss: 2.6268566165861387

Epoch: 6| Step: 4
Training loss: 0.44789006649550095
Validation loss: 2.671182940647992

Epoch: 6| Step: 5
Training loss: 0.27727264513644867
Validation loss: 2.6962954659151634

Epoch: 6| Step: 6
Training loss: 0.32332995971946665
Validation loss: 2.658702346597096

Epoch: 6| Step: 7
Training loss: 0.26761035307438596
Validation loss: 2.642621220671706

Epoch: 6| Step: 8
Training loss: 0.33056036578791487
Validation loss: 2.6617023682115843

Epoch: 6| Step: 9
Training loss: 0.2710883730924042
Validation loss: 2.705927599525982

Epoch: 6| Step: 10
Training loss: 0.3439456859545438
Validation loss: 2.678699441000401

Epoch: 6| Step: 11
Training loss: 0.31516344390359835
Validation loss: 2.6651484121159035

Epoch: 6| Step: 12
Training loss: 0.3043860142103415
Validation loss: 2.7225099631022993

Epoch: 6| Step: 13
Training loss: 0.2729852887991458
Validation loss: 2.677298939158008

Epoch: 434| Step: 0
Training loss: 0.249671138590216
Validation loss: 2.675437233150772

Epoch: 6| Step: 1
Training loss: 0.31398163271520607
Validation loss: 2.7103412129960818

Epoch: 6| Step: 2
Training loss: 0.33364811081376455
Validation loss: 2.659124636491765

Epoch: 6| Step: 3
Training loss: 0.3055018033928095
Validation loss: 2.7084379665018865

Epoch: 6| Step: 4
Training loss: 0.3423275996080581
Validation loss: 2.664468818174285

Epoch: 6| Step: 5
Training loss: 0.3100912962961269
Validation loss: 2.666079103787734

Epoch: 6| Step: 6
Training loss: 0.21939049345444103
Validation loss: 2.6318197293510845

Epoch: 6| Step: 7
Training loss: 0.22531859339385638
Validation loss: 2.7011265653210583

Epoch: 6| Step: 8
Training loss: 0.3157529444138161
Validation loss: 2.7222573176433427

Epoch: 6| Step: 9
Training loss: 0.19220745014136886
Validation loss: 2.6244063765801804

Epoch: 6| Step: 10
Training loss: 0.2656600872875967
Validation loss: 2.660401439897003

Epoch: 6| Step: 11
Training loss: 0.3122491783638277
Validation loss: 2.6663865051522047

Epoch: 6| Step: 12
Training loss: 0.3992906673622836
Validation loss: 2.712854607134501

Epoch: 6| Step: 13
Training loss: 0.3702883764851727
Validation loss: 2.719399151821574

Epoch: 435| Step: 0
Training loss: 0.2973707226353011
Validation loss: 2.7251009298292503

Epoch: 6| Step: 1
Training loss: 0.3217268978048694
Validation loss: 2.7290150088233815

Epoch: 6| Step: 2
Training loss: 0.2994303400899122
Validation loss: 2.6801396795662864

Epoch: 6| Step: 3
Training loss: 0.258683755429565
Validation loss: 2.6928954412997226

Epoch: 6| Step: 4
Training loss: 0.3135665217820865
Validation loss: 2.735167441208554

Epoch: 6| Step: 5
Training loss: 0.2881267712635863
Validation loss: 2.6887613633638527

Epoch: 6| Step: 6
Training loss: 0.319341816979275
Validation loss: 2.716225369033517

Epoch: 6| Step: 7
Training loss: 0.320721737023027
Validation loss: 2.7262678597442593

Epoch: 6| Step: 8
Training loss: 0.38922838405108545
Validation loss: 2.7426604382053705

Epoch: 6| Step: 9
Training loss: 0.3384533314511206
Validation loss: 2.6701525067887593

Epoch: 6| Step: 10
Training loss: 0.20217567297232786
Validation loss: 2.7132966021817317

Epoch: 6| Step: 11
Training loss: 0.43775755249514603
Validation loss: 2.6717337706720112

Epoch: 6| Step: 12
Training loss: 0.3400486624303121
Validation loss: 2.657236192922491

Epoch: 6| Step: 13
Training loss: 0.3991088073795728
Validation loss: 2.6448303233853965

Epoch: 436| Step: 0
Training loss: 0.30772830227905285
Validation loss: 2.6770428061973863

Epoch: 6| Step: 1
Training loss: 0.22861828087672767
Validation loss: 2.6832963018843556

Epoch: 6| Step: 2
Training loss: 0.23149181655267528
Validation loss: 2.666513756500568

Epoch: 6| Step: 3
Training loss: 0.2733913518927916
Validation loss: 2.650084711916097

Epoch: 6| Step: 4
Training loss: 0.3201552796058228
Validation loss: 2.7080613121950363

Epoch: 6| Step: 5
Training loss: 0.275309422201907
Validation loss: 2.6962479299585387

Epoch: 6| Step: 6
Training loss: 0.3222335337063844
Validation loss: 2.714939779874787

Epoch: 6| Step: 7
Training loss: 0.21523178777507052
Validation loss: 2.777400764205621

Epoch: 6| Step: 8
Training loss: 0.223652401528448
Validation loss: 2.6684141145717817

Epoch: 6| Step: 9
Training loss: 0.2695771744897666
Validation loss: 2.68772026756205

Epoch: 6| Step: 10
Training loss: 0.348621592621618
Validation loss: 2.649925301656623

Epoch: 6| Step: 11
Training loss: 0.15262992585064983
Validation loss: 2.6865502091181686

Epoch: 6| Step: 12
Training loss: 0.2628819961605464
Validation loss: 2.6762112459942955

Epoch: 6| Step: 13
Training loss: 0.26489253593479645
Validation loss: 2.6557826509917324

Epoch: 437| Step: 0
Training loss: 0.24023116505036782
Validation loss: 2.724897982352984

Epoch: 6| Step: 1
Training loss: 0.29624100800239195
Validation loss: 2.6664579478677686

Epoch: 6| Step: 2
Training loss: 0.3103407409586625
Validation loss: 2.6870584420886816

Epoch: 6| Step: 3
Training loss: 0.2919520602514355
Validation loss: 2.746704496691033

Epoch: 6| Step: 4
Training loss: 0.2529076378832677
Validation loss: 2.720613973361372

Epoch: 6| Step: 5
Training loss: 0.4062195729818781
Validation loss: 2.675877330382285

Epoch: 6| Step: 6
Training loss: 0.345947782506671
Validation loss: 2.730187717686413

Epoch: 6| Step: 7
Training loss: 0.2900702591375904
Validation loss: 2.7400661570040814

Epoch: 6| Step: 8
Training loss: 0.33591711736544905
Validation loss: 2.683946167128852

Epoch: 6| Step: 9
Training loss: 0.29385159034415487
Validation loss: 2.6661270360525586

Epoch: 6| Step: 10
Training loss: 0.2807577248994129
Validation loss: 2.7289730809012704

Epoch: 6| Step: 11
Training loss: 0.23476404643361137
Validation loss: 2.7195538030483912

Epoch: 6| Step: 12
Training loss: 0.3680095398925822
Validation loss: 2.699332603338923

Epoch: 6| Step: 13
Training loss: 0.28497503349052344
Validation loss: 2.7123261851627176

Epoch: 438| Step: 0
Training loss: 0.27506982772954747
Validation loss: 2.651488325842039

Epoch: 6| Step: 1
Training loss: 0.3243231547824289
Validation loss: 2.658844970527809

Epoch: 6| Step: 2
Training loss: 0.3623088003578045
Validation loss: 2.67456068430392

Epoch: 6| Step: 3
Training loss: 0.28314418837174005
Validation loss: 2.7167193257507543

Epoch: 6| Step: 4
Training loss: 0.30287824104108413
Validation loss: 2.653648149353953

Epoch: 6| Step: 5
Training loss: 0.2793017833785264
Validation loss: 2.635305957705399

Epoch: 6| Step: 6
Training loss: 0.35832271763505785
Validation loss: 2.658323069904409

Epoch: 6| Step: 7
Training loss: 0.2822780364195812
Validation loss: 2.690792772332549

Epoch: 6| Step: 8
Training loss: 0.3376336415924549
Validation loss: 2.6724479165159947

Epoch: 6| Step: 9
Training loss: 0.2219858953553175
Validation loss: 2.7429837685592804

Epoch: 6| Step: 10
Training loss: 0.5550902610273581
Validation loss: 2.700973683678745

Epoch: 6| Step: 11
Training loss: 0.3826122538709523
Validation loss: 2.662511327358262

Epoch: 6| Step: 12
Training loss: 0.4330168658158813
Validation loss: 2.6454595366830804

Epoch: 6| Step: 13
Training loss: 0.300684727626049
Validation loss: 2.6165947541805132

Epoch: 439| Step: 0
Training loss: 0.2918577107816492
Validation loss: 2.6861152186247823

Epoch: 6| Step: 1
Training loss: 0.4431285173090921
Validation loss: 2.6358813201639903

Epoch: 6| Step: 2
Training loss: 0.2870159386385933
Validation loss: 2.682611395782525

Epoch: 6| Step: 3
Training loss: 0.42449515454972014
Validation loss: 2.6833019292269262

Epoch: 6| Step: 4
Training loss: 0.3858831992926391
Validation loss: 2.650806076783502

Epoch: 6| Step: 5
Training loss: 0.30639245991894454
Validation loss: 2.619033147515944

Epoch: 6| Step: 6
Training loss: 0.3214750244523598
Validation loss: 2.6831141621266883

Epoch: 6| Step: 7
Training loss: 0.4987777433590589
Validation loss: 2.6565953348109015

Epoch: 6| Step: 8
Training loss: 0.37357494665902535
Validation loss: 2.66033495780278

Epoch: 6| Step: 9
Training loss: 0.3837042173604713
Validation loss: 2.633517781167846

Epoch: 6| Step: 10
Training loss: 0.29053283173322453
Validation loss: 2.6463953657771615

Epoch: 6| Step: 11
Training loss: 0.23597624883708243
Validation loss: 2.6939254951398075

Epoch: 6| Step: 12
Training loss: 0.24255842598804017
Validation loss: 2.697021826927679

Epoch: 6| Step: 13
Training loss: 0.3159212940636549
Validation loss: 2.720933015836537

Epoch: 440| Step: 0
Training loss: 0.3674060495785998
Validation loss: 2.713302987426535

Epoch: 6| Step: 1
Training loss: 0.37402696333933966
Validation loss: 2.6637802049036288

Epoch: 6| Step: 2
Training loss: 0.29143004384198135
Validation loss: 2.7195624091366852

Epoch: 6| Step: 3
Training loss: 0.29411815238306166
Validation loss: 2.6617660842208424

Epoch: 6| Step: 4
Training loss: 0.3212348869123341
Validation loss: 2.7126859656836717

Epoch: 6| Step: 5
Training loss: 0.20340674374394893
Validation loss: 2.6796751327896557

Epoch: 6| Step: 6
Training loss: 0.2973314716131325
Validation loss: 2.7071362246168387

Epoch: 6| Step: 7
Training loss: 0.4140681680255391
Validation loss: 2.677429330239268

Epoch: 6| Step: 8
Training loss: 0.21508603739291887
Validation loss: 2.713971363295112

Epoch: 6| Step: 9
Training loss: 0.3314109168472723
Validation loss: 2.647645312335731

Epoch: 6| Step: 10
Training loss: 0.4122372831022181
Validation loss: 2.714861138377318

Epoch: 6| Step: 11
Training loss: 0.2582081590816748
Validation loss: 2.70263141102027

Epoch: 6| Step: 12
Training loss: 0.34641046950782
Validation loss: 2.637133281759311

Epoch: 6| Step: 13
Training loss: 0.46011617191305276
Validation loss: 2.675778443272365

Epoch: 441| Step: 0
Training loss: 0.2787549556839062
Validation loss: 2.724865433523005

Epoch: 6| Step: 1
Training loss: 0.34283893318120107
Validation loss: 2.652068350890202

Epoch: 6| Step: 2
Training loss: 0.15524898792403813
Validation loss: 2.6920056536087515

Epoch: 6| Step: 3
Training loss: 0.33330895910951974
Validation loss: 2.6895880313263945

Epoch: 6| Step: 4
Training loss: 0.3341438626517594
Validation loss: 2.6519595182953006

Epoch: 6| Step: 5
Training loss: 0.30743582086788945
Validation loss: 2.7719955062618777

Epoch: 6| Step: 6
Training loss: 0.21836601342771383
Validation loss: 2.780432105798748

Epoch: 6| Step: 7
Training loss: 0.22697751903913388
Validation loss: 2.6976061952868613

Epoch: 6| Step: 8
Training loss: 0.19317846794143026
Validation loss: 2.710335245944895

Epoch: 6| Step: 9
Training loss: 0.21251124078808245
Validation loss: 2.702064453113941

Epoch: 6| Step: 10
Training loss: 0.28310610983948037
Validation loss: 2.6937591868256456

Epoch: 6| Step: 11
Training loss: 0.3088758482996655
Validation loss: 2.7160406095336844

Epoch: 6| Step: 12
Training loss: 0.3856901689052887
Validation loss: 2.7269165188151536

Epoch: 6| Step: 13
Training loss: 0.34871695008109505
Validation loss: 2.7770495466813157

Epoch: 442| Step: 0
Training loss: 0.22980985366899462
Validation loss: 2.6548881555216908

Epoch: 6| Step: 1
Training loss: 0.2751768107316807
Validation loss: 2.7324051219107575

Epoch: 6| Step: 2
Training loss: 0.20874474950000768
Validation loss: 2.744570320851024

Epoch: 6| Step: 3
Training loss: 0.17758042091936266
Validation loss: 2.756178806968455

Epoch: 6| Step: 4
Training loss: 0.18002905725349885
Validation loss: 2.763459861360344

Epoch: 6| Step: 5
Training loss: 0.3373135727339985
Validation loss: 2.731463686267863

Epoch: 6| Step: 6
Training loss: 0.31647542503431453
Validation loss: 2.7473859500556586

Epoch: 6| Step: 7
Training loss: 0.2650712355649608
Validation loss: 2.7222425455731734

Epoch: 6| Step: 8
Training loss: 0.21395483790114322
Validation loss: 2.68673612399121

Epoch: 6| Step: 9
Training loss: 0.20248953748095092
Validation loss: 2.719109259359976

Epoch: 6| Step: 10
Training loss: 0.37274113454068547
Validation loss: 2.665031152594432

Epoch: 6| Step: 11
Training loss: 0.3544777270854035
Validation loss: 2.754737573414859

Epoch: 6| Step: 12
Training loss: 0.4373091042803712
Validation loss: 2.7530582935162813

Epoch: 6| Step: 13
Training loss: 0.302111026985302
Validation loss: 2.6682353372903975

Epoch: 443| Step: 0
Training loss: 0.28975508174192127
Validation loss: 2.6378720019659596

Epoch: 6| Step: 1
Training loss: 0.23742279598588423
Validation loss: 2.7288278752839723

Epoch: 6| Step: 2
Training loss: 0.27507008504778246
Validation loss: 2.6910070262558734

Epoch: 6| Step: 3
Training loss: 0.31355814600037885
Validation loss: 2.701952450263043

Epoch: 6| Step: 4
Training loss: 0.34296787757154307
Validation loss: 2.6787114196101953

Epoch: 6| Step: 5
Training loss: 0.3542817807583494
Validation loss: 2.6825640691315322

Epoch: 6| Step: 6
Training loss: 0.23814449137916754
Validation loss: 2.658431679352431

Epoch: 6| Step: 7
Training loss: 0.24616361564840955
Validation loss: 2.7528545346376037

Epoch: 6| Step: 8
Training loss: 0.31728298084362155
Validation loss: 2.7361970335049883

Epoch: 6| Step: 9
Training loss: 0.2374037704519055
Validation loss: 2.6085262707618297

Epoch: 6| Step: 10
Training loss: 0.2628604554185475
Validation loss: 2.662024918557808

Epoch: 6| Step: 11
Training loss: 0.45845054262066526
Validation loss: 2.6928593773354965

Epoch: 6| Step: 12
Training loss: 0.3265968113081313
Validation loss: 2.6960484481273066

Epoch: 6| Step: 13
Training loss: 0.298351081599031
Validation loss: 2.677891209834861

Epoch: 444| Step: 0
Training loss: 0.31715323728219946
Validation loss: 2.6856736623717037

Epoch: 6| Step: 1
Training loss: 0.2636907923941124
Validation loss: 2.683686219185822

Epoch: 6| Step: 2
Training loss: 0.26272829550686216
Validation loss: 2.6837858217404564

Epoch: 6| Step: 3
Training loss: 0.25336376338126004
Validation loss: 2.6603373327253466

Epoch: 6| Step: 4
Training loss: 0.3575897239585764
Validation loss: 2.680716773825258

Epoch: 6| Step: 5
Training loss: 0.2648452927536043
Validation loss: 2.734369281581167

Epoch: 6| Step: 6
Training loss: 0.3619803444639662
Validation loss: 2.639511385215354

Epoch: 6| Step: 7
Training loss: 0.2418900016203482
Validation loss: 2.6822654401861166

Epoch: 6| Step: 8
Training loss: 0.27703146747853824
Validation loss: 2.6211556637193603

Epoch: 6| Step: 9
Training loss: 0.30711847478621007
Validation loss: 2.724722998652857

Epoch: 6| Step: 10
Training loss: 0.3085691466362215
Validation loss: 2.6585427655160787

Epoch: 6| Step: 11
Training loss: 0.30793181783870044
Validation loss: 2.657019514928901

Epoch: 6| Step: 12
Training loss: 0.15995824599650785
Validation loss: 2.677555893529213

Epoch: 6| Step: 13
Training loss: 0.21589744708443315
Validation loss: 2.6799731310878214

Epoch: 445| Step: 0
Training loss: 0.25541813491899196
Validation loss: 2.7048436399479687

Epoch: 6| Step: 1
Training loss: 0.30631525551133126
Validation loss: 2.703692661429297

Epoch: 6| Step: 2
Training loss: 0.4103094269055628
Validation loss: 2.677508403314914

Epoch: 6| Step: 3
Training loss: 0.26434170447916766
Validation loss: 2.595359019751161

Epoch: 6| Step: 4
Training loss: 0.3834552040769647
Validation loss: 2.70852913271005

Epoch: 6| Step: 5
Training loss: 0.23393862950589686
Validation loss: 2.655160658118895

Epoch: 6| Step: 6
Training loss: 0.22357763417596838
Validation loss: 2.666509405108435

Epoch: 6| Step: 7
Training loss: 0.35524948400074735
Validation loss: 2.6228223199416987

Epoch: 6| Step: 8
Training loss: 0.30621978406345157
Validation loss: 2.6227570897029167

Epoch: 6| Step: 9
Training loss: 0.37862267648582804
Validation loss: 2.717418695477635

Epoch: 6| Step: 10
Training loss: 0.2651565431942777
Validation loss: 2.6513219259296603

Epoch: 6| Step: 11
Training loss: 0.3963731506386317
Validation loss: 2.652802747394779

Epoch: 6| Step: 12
Training loss: 0.2913411131562227
Validation loss: 2.6736665634635917

Epoch: 6| Step: 13
Training loss: 0.3415004207530299
Validation loss: 2.7625097340776223

Epoch: 446| Step: 0
Training loss: 0.3868171874868839
Validation loss: 2.6469520146298633

Epoch: 6| Step: 1
Training loss: 0.35051775511041383
Validation loss: 2.6511169652731206

Epoch: 6| Step: 2
Training loss: 0.3678588208935383
Validation loss: 2.678954295694194

Epoch: 6| Step: 3
Training loss: 0.4068713937766589
Validation loss: 2.7131248612847974

Epoch: 6| Step: 4
Training loss: 0.3352101236006728
Validation loss: 2.7010580697660633

Epoch: 6| Step: 5
Training loss: 0.25521491327691337
Validation loss: 2.677078519190951

Epoch: 6| Step: 6
Training loss: 0.4062712370383393
Validation loss: 2.706957736721278

Epoch: 6| Step: 7
Training loss: 0.3386291305336541
Validation loss: 2.714007424904982

Epoch: 6| Step: 8
Training loss: 0.26795062012135307
Validation loss: 2.7061480998529457

Epoch: 6| Step: 9
Training loss: 0.2928038450893761
Validation loss: 2.6735323251672862

Epoch: 6| Step: 10
Training loss: 0.3405076152752367
Validation loss: 2.690796722650571

Epoch: 6| Step: 11
Training loss: 0.2652283399566678
Validation loss: 2.7432489034593215

Epoch: 6| Step: 12
Training loss: 0.23330094284364988
Validation loss: 2.7500219849950356

Epoch: 6| Step: 13
Training loss: 0.4039465819537065
Validation loss: 2.6989555028097922

Epoch: 447| Step: 0
Training loss: 0.33003243575936486
Validation loss: 2.7277380914729714

Epoch: 6| Step: 1
Training loss: 0.34218140905872957
Validation loss: 2.7224757656003122

Epoch: 6| Step: 2
Training loss: 0.22542424207451872
Validation loss: 2.713036625016033

Epoch: 6| Step: 3
Training loss: 0.4063483816010653
Validation loss: 2.7258438431169743

Epoch: 6| Step: 4
Training loss: 0.2632272715941248
Validation loss: 2.717898187893719

Epoch: 6| Step: 5
Training loss: 0.3509607887863015
Validation loss: 2.6791605825241405

Epoch: 6| Step: 6
Training loss: 0.3556016317309198
Validation loss: 2.725278550239716

Epoch: 6| Step: 7
Training loss: 0.42922694059207994
Validation loss: 2.652474925899131

Epoch: 6| Step: 8
Training loss: 0.31459984999154134
Validation loss: 2.7017645159311683

Epoch: 6| Step: 9
Training loss: 0.2891964988454356
Validation loss: 2.710246222432027

Epoch: 6| Step: 10
Training loss: 0.2147028200716341
Validation loss: 2.665666084524497

Epoch: 6| Step: 11
Training loss: 0.2409409854132147
Validation loss: 2.6534195124306588

Epoch: 6| Step: 12
Training loss: 0.2893323412074674
Validation loss: 2.6942653741245994

Epoch: 6| Step: 13
Training loss: 0.3425196933827525
Validation loss: 2.6833693231416063

Epoch: 448| Step: 0
Training loss: 0.33650982696941273
Validation loss: 2.626671259056311

Epoch: 6| Step: 1
Training loss: 0.3884532064145706
Validation loss: 2.699213656371445

Epoch: 6| Step: 2
Training loss: 0.36482730150413706
Validation loss: 2.668476948106806

Epoch: 6| Step: 3
Training loss: 0.32670597502052645
Validation loss: 2.614038636105684

Epoch: 6| Step: 4
Training loss: 0.39134493288517685
Validation loss: 2.639923122808694

Epoch: 6| Step: 5
Training loss: 0.45267849331272253
Validation loss: 2.6373361274468508

Epoch: 6| Step: 6
Training loss: 0.2952490375084818
Validation loss: 2.6550304343268634

Epoch: 6| Step: 7
Training loss: 0.29551730143861643
Validation loss: 2.6885183016798697

Epoch: 6| Step: 8
Training loss: 0.38453764381967737
Validation loss: 2.6928211436937723

Epoch: 6| Step: 9
Training loss: 0.37500109275022875
Validation loss: 2.651102493777432

Epoch: 6| Step: 10
Training loss: 0.3205600921375315
Validation loss: 2.72790858461616

Epoch: 6| Step: 11
Training loss: 0.2201628951483743
Validation loss: 2.6732625277180584

Epoch: 6| Step: 12
Training loss: 0.3209635700383151
Validation loss: 2.701150102911473

Epoch: 6| Step: 13
Training loss: 0.2383821305147159
Validation loss: 2.6741051615125353

Epoch: 449| Step: 0
Training loss: 0.23238700316589786
Validation loss: 2.649793444686698

Epoch: 6| Step: 1
Training loss: 0.33388148502020176
Validation loss: 2.7382164410999614

Epoch: 6| Step: 2
Training loss: 0.4365835127145994
Validation loss: 2.7026406885133447

Epoch: 6| Step: 3
Training loss: 0.4162583516116471
Validation loss: 2.772578906193938

Epoch: 6| Step: 4
Training loss: 0.27865334378872736
Validation loss: 2.640325706118712

Epoch: 6| Step: 5
Training loss: 0.261705625973635
Validation loss: 2.7056088364211512

Epoch: 6| Step: 6
Training loss: 0.21579200248252645
Validation loss: 2.6979399033261346

Epoch: 6| Step: 7
Training loss: 0.5008459683166416
Validation loss: 2.7525790720757835

Epoch: 6| Step: 8
Training loss: 0.2704714533749528
Validation loss: 2.701115259849246

Epoch: 6| Step: 9
Training loss: 0.3499255641905454
Validation loss: 2.6851200832742625

Epoch: 6| Step: 10
Training loss: 0.3050169508554288
Validation loss: 2.67821897670478

Epoch: 6| Step: 11
Training loss: 0.26086612856046426
Validation loss: 2.7028302893830727

Epoch: 6| Step: 12
Training loss: 0.37872046408984217
Validation loss: 2.688776023806198

Epoch: 6| Step: 13
Training loss: 0.32309165053862027
Validation loss: 2.6207434490742663

Epoch: 450| Step: 0
Training loss: 0.2349150792855711
Validation loss: 2.7113904913495976

Epoch: 6| Step: 1
Training loss: 0.24148689731501172
Validation loss: 2.620249127490038

Epoch: 6| Step: 2
Training loss: 0.274996265472717
Validation loss: 2.7009010795218895

Epoch: 6| Step: 3
Training loss: 0.40465931149847
Validation loss: 2.691123943905518

Epoch: 6| Step: 4
Training loss: 0.26576767623839115
Validation loss: 2.676416964785928

Epoch: 6| Step: 5
Training loss: 0.3400532087947298
Validation loss: 2.7605887209456172

Epoch: 6| Step: 6
Training loss: 0.41517159533755954
Validation loss: 2.692366467042199

Epoch: 6| Step: 7
Training loss: 0.28484471168711456
Validation loss: 2.6050480279381767

Epoch: 6| Step: 8
Training loss: 0.345429349780713
Validation loss: 2.7254569974091614

Epoch: 6| Step: 9
Training loss: 0.30796192773223174
Validation loss: 2.6857930462457382

Epoch: 6| Step: 10
Training loss: 0.30736226009139395
Validation loss: 2.728664298570607

Epoch: 6| Step: 11
Training loss: 0.3715737701580456
Validation loss: 2.723603589582867

Epoch: 6| Step: 12
Training loss: 0.2914731314562826
Validation loss: 2.7121006708318185

Epoch: 6| Step: 13
Training loss: 0.30236822566438737
Validation loss: 2.7312029723214937

Epoch: 451| Step: 0
Training loss: 0.3481055795673339
Validation loss: 2.6814447244806576

Epoch: 6| Step: 1
Training loss: 0.24813013856981495
Validation loss: 2.716202678920679

Epoch: 6| Step: 2
Training loss: 0.4018900266599652
Validation loss: 2.6733598580039426

Epoch: 6| Step: 3
Training loss: 0.2998999155505851
Validation loss: 2.706217531122508

Epoch: 6| Step: 4
Training loss: 0.38352176589074677
Validation loss: 2.6871902893574813

Epoch: 6| Step: 5
Training loss: 0.3180853126254591
Validation loss: 2.6639137562145883

Epoch: 6| Step: 6
Training loss: 0.2619042948722804
Validation loss: 2.753247409946922

Epoch: 6| Step: 7
Training loss: 0.21223740586332038
Validation loss: 2.6664307807861727

Epoch: 6| Step: 8
Training loss: 0.36291604502230873
Validation loss: 2.6932401937331414

Epoch: 6| Step: 9
Training loss: 0.22816203548325803
Validation loss: 2.652386027819883

Epoch: 6| Step: 10
Training loss: 0.24202348939238807
Validation loss: 2.699987071206492

Epoch: 6| Step: 11
Training loss: 0.3585065631797719
Validation loss: 2.6839719132935564

Epoch: 6| Step: 12
Training loss: 0.28487639869406833
Validation loss: 2.691408538448282

Epoch: 6| Step: 13
Training loss: 0.25228568610755664
Validation loss: 2.662688966770259

Epoch: 452| Step: 0
Training loss: 0.31330356994038444
Validation loss: 2.572751404143308

Epoch: 6| Step: 1
Training loss: 0.3272191668673452
Validation loss: 2.664053170196216

Epoch: 6| Step: 2
Training loss: 0.27112309684542735
Validation loss: 2.690334067748399

Epoch: 6| Step: 3
Training loss: 0.22879555665475013
Validation loss: 2.6247217242772587

Epoch: 6| Step: 4
Training loss: 0.3440472444760742
Validation loss: 2.652565865820944

Epoch: 6| Step: 5
Training loss: 0.2595122399392733
Validation loss: 2.7103553681964128

Epoch: 6| Step: 6
Training loss: 0.34886609348189224
Validation loss: 2.6354005961374223

Epoch: 6| Step: 7
Training loss: 0.2638746259136431
Validation loss: 2.602480217684102

Epoch: 6| Step: 8
Training loss: 0.31264897610173226
Validation loss: 2.6995752138782207

Epoch: 6| Step: 9
Training loss: 0.3011240801260751
Validation loss: 2.684524767024333

Epoch: 6| Step: 10
Training loss: 0.32353618885339525
Validation loss: 2.677749897146462

Epoch: 6| Step: 11
Training loss: 0.23820573360557393
Validation loss: 2.6593623757576355

Epoch: 6| Step: 12
Training loss: 0.4089943368130271
Validation loss: 2.6696288574284237

Epoch: 6| Step: 13
Training loss: 0.2615536838217011
Validation loss: 2.6988823437688803

Epoch: 453| Step: 0
Training loss: 0.3361931981002579
Validation loss: 2.6744336078233895

Epoch: 6| Step: 1
Training loss: 0.406043697206611
Validation loss: 2.7152922115825775

Epoch: 6| Step: 2
Training loss: 0.3175247344572535
Validation loss: 2.6977019107922935

Epoch: 6| Step: 3
Training loss: 0.2713200325586993
Validation loss: 2.675125568924637

Epoch: 6| Step: 4
Training loss: 0.23696475544102782
Validation loss: 2.6715532968050026

Epoch: 6| Step: 5
Training loss: 0.31572080470638675
Validation loss: 2.671399109456695

Epoch: 6| Step: 6
Training loss: 0.3010536421909501
Validation loss: 2.641960994878207

Epoch: 6| Step: 7
Training loss: 0.4113419062233975
Validation loss: 2.636357246389189

Epoch: 6| Step: 8
Training loss: 0.24638078238660913
Validation loss: 2.6619622909875775

Epoch: 6| Step: 9
Training loss: 0.32003728161389317
Validation loss: 2.650158220941931

Epoch: 6| Step: 10
Training loss: 0.22791302937988184
Validation loss: 2.6515306173013906

Epoch: 6| Step: 11
Training loss: 0.3696228389670367
Validation loss: 2.657216019839087

Epoch: 6| Step: 12
Training loss: 0.311451691404647
Validation loss: 2.6293276429707984

Epoch: 6| Step: 13
Training loss: 0.28304262546062625
Validation loss: 2.6779300053404125

Epoch: 454| Step: 0
Training loss: 0.3294293500297074
Validation loss: 2.6990133852382376

Epoch: 6| Step: 1
Training loss: 0.2575700660395916
Validation loss: 2.681371206227921

Epoch: 6| Step: 2
Training loss: 0.29293482266116794
Validation loss: 2.728892586804279

Epoch: 6| Step: 3
Training loss: 0.32765099939187786
Validation loss: 2.6796986660293736

Epoch: 6| Step: 4
Training loss: 0.32515853811372775
Validation loss: 2.625558945017807

Epoch: 6| Step: 5
Training loss: 0.33578575388646775
Validation loss: 2.6726757656568

Epoch: 6| Step: 6
Training loss: 0.29972571162194145
Validation loss: 2.6644710850181403

Epoch: 6| Step: 7
Training loss: 0.32256126714528843
Validation loss: 2.6265556932943976

Epoch: 6| Step: 8
Training loss: 0.3868644324355388
Validation loss: 2.7062161802508884

Epoch: 6| Step: 9
Training loss: 0.2693670297757917
Validation loss: 2.7186535931444844

Epoch: 6| Step: 10
Training loss: 0.2558465037129547
Validation loss: 2.686232082921968

Epoch: 6| Step: 11
Training loss: 0.3289405700646148
Validation loss: 2.688525388703599

Epoch: 6| Step: 12
Training loss: 0.24038565919722832
Validation loss: 2.642544938147156

Epoch: 6| Step: 13
Training loss: 0.317786549753094
Validation loss: 2.678164101919447

Epoch: 455| Step: 0
Training loss: 0.37068097095595737
Validation loss: 2.7030522331189757

Epoch: 6| Step: 1
Training loss: 0.24790689318222575
Validation loss: 2.6332722308719445

Epoch: 6| Step: 2
Training loss: 0.3231001020169252
Validation loss: 2.64529230688792

Epoch: 6| Step: 3
Training loss: 0.33176783041840163
Validation loss: 2.6051696956493995

Epoch: 6| Step: 4
Training loss: 0.25578542907507346
Validation loss: 2.6444803718544816

Epoch: 6| Step: 5
Training loss: 0.32386112022030894
Validation loss: 2.7555103148528803

Epoch: 6| Step: 6
Training loss: 0.33721028449828255
Validation loss: 2.647136927784221

Epoch: 6| Step: 7
Training loss: 0.32599408906568583
Validation loss: 2.6745083493748822

Epoch: 6| Step: 8
Training loss: 0.3167929346895527
Validation loss: 2.7059030902221175

Epoch: 6| Step: 9
Training loss: 0.2926320111674451
Validation loss: 2.6341635070471283

Epoch: 6| Step: 10
Training loss: 0.35819030455897627
Validation loss: 2.7185742697796247

Epoch: 6| Step: 11
Training loss: 0.2642813667124797
Validation loss: 2.7108705056127245

Epoch: 6| Step: 12
Training loss: 0.39047058868280593
Validation loss: 2.6857418253104077

Epoch: 6| Step: 13
Training loss: 0.2665620432197977
Validation loss: 2.6910620156897176

Epoch: 456| Step: 0
Training loss: 0.3113480076968246
Validation loss: 2.7333534948450553

Epoch: 6| Step: 1
Training loss: 0.32470168489342693
Validation loss: 2.716413656010158

Epoch: 6| Step: 2
Training loss: 0.4700717411175197
Validation loss: 2.652241078909784

Epoch: 6| Step: 3
Training loss: 0.3471566156819274
Validation loss: 2.653440627879194

Epoch: 6| Step: 4
Training loss: 0.343975394220748
Validation loss: 2.692925572932222

Epoch: 6| Step: 5
Training loss: 0.2910102229289011
Validation loss: 2.6746225043159764

Epoch: 6| Step: 6
Training loss: 0.2964980719095167
Validation loss: 2.7060117797313223

Epoch: 6| Step: 7
Training loss: 0.2487452505247734
Validation loss: 2.682294439419298

Epoch: 6| Step: 8
Training loss: 0.3295708544876907
Validation loss: 2.7094561279071394

Epoch: 6| Step: 9
Training loss: 0.27021081919373446
Validation loss: 2.697369086665805

Epoch: 6| Step: 10
Training loss: 0.40540155430953584
Validation loss: 2.707002589159825

Epoch: 6| Step: 11
Training loss: 0.3362681846062146
Validation loss: 2.692685646733845

Epoch: 6| Step: 12
Training loss: 0.2687055268195565
Validation loss: 2.6758324536995604

Epoch: 6| Step: 13
Training loss: 0.35260784714476345
Validation loss: 2.6901753143227647

Epoch: 457| Step: 0
Training loss: 0.3184291669487129
Validation loss: 2.7183222525546387

Epoch: 6| Step: 1
Training loss: 0.34310124690277616
Validation loss: 2.7372026627474075

Epoch: 6| Step: 2
Training loss: 0.2469696623958979
Validation loss: 2.697771198568259

Epoch: 6| Step: 3
Training loss: 0.27915641614020126
Validation loss: 2.6923696254499063

Epoch: 6| Step: 4
Training loss: 0.2626666652559225
Validation loss: 2.6161692825918013

Epoch: 6| Step: 5
Training loss: 0.33062128375007416
Validation loss: 2.7496201223922174

Epoch: 6| Step: 6
Training loss: 0.279715444458135
Validation loss: 2.6977364812549998

Epoch: 6| Step: 7
Training loss: 0.28004553963099593
Validation loss: 2.726028200572281

Epoch: 6| Step: 8
Training loss: 0.2667521795364331
Validation loss: 2.6646703509532026

Epoch: 6| Step: 9
Training loss: 0.3927120720392779
Validation loss: 2.7014683698409536

Epoch: 6| Step: 10
Training loss: 0.36491277887126394
Validation loss: 2.705473612715702

Epoch: 6| Step: 11
Training loss: 0.34336691881730724
Validation loss: 2.6697964233006792

Epoch: 6| Step: 12
Training loss: 0.31023064593089106
Validation loss: 2.6979731304686703

Epoch: 6| Step: 13
Training loss: 0.27121202268936906
Validation loss: 2.664737858192608

Epoch: 458| Step: 0
Training loss: 0.2229279733996001
Validation loss: 2.6956315298669864

Epoch: 6| Step: 1
Training loss: 0.2076414400937699
Validation loss: 2.681725975062006

Epoch: 6| Step: 2
Training loss: 0.3554433038008638
Validation loss: 2.637285878919699

Epoch: 6| Step: 3
Training loss: 0.3044239151166788
Validation loss: 2.5880327907835436

Epoch: 6| Step: 4
Training loss: 0.3053014145696226
Validation loss: 2.7643103770712676

Epoch: 6| Step: 5
Training loss: 0.3775284680312249
Validation loss: 2.7323846603160655

Epoch: 6| Step: 6
Training loss: 0.21766857650423077
Validation loss: 2.6688793707884417

Epoch: 6| Step: 7
Training loss: 0.2734874679686064
Validation loss: 2.692005993109461

Epoch: 6| Step: 8
Training loss: 0.296065217407299
Validation loss: 2.6839046825647093

Epoch: 6| Step: 9
Training loss: 0.30251754871413067
Validation loss: 2.7092190370178746

Epoch: 6| Step: 10
Training loss: 0.3327207474650838
Validation loss: 2.6603762572547125

Epoch: 6| Step: 11
Training loss: 0.3061139388385545
Validation loss: 2.6446504326564044

Epoch: 6| Step: 12
Training loss: 0.27501852179055464
Validation loss: 2.6291772817003443

Epoch: 6| Step: 13
Training loss: 0.27271043299213243
Validation loss: 2.6821060017644203

Epoch: 459| Step: 0
Training loss: 0.4080524440256076
Validation loss: 2.6727182347851217

Epoch: 6| Step: 1
Training loss: 0.1698352000726183
Validation loss: 2.677518309546329

Epoch: 6| Step: 2
Training loss: 0.4061564741316733
Validation loss: 2.7448553745083486

Epoch: 6| Step: 3
Training loss: 0.29536447723571524
Validation loss: 2.72468130365405

Epoch: 6| Step: 4
Training loss: 0.4031722787737428
Validation loss: 2.6980193915135664

Epoch: 6| Step: 5
Training loss: 0.24407422497923334
Validation loss: 2.6742215773842126

Epoch: 6| Step: 6
Training loss: 0.22715192613358132
Validation loss: 2.648386711901448

Epoch: 6| Step: 7
Training loss: 0.2674962635536921
Validation loss: 2.724052483491846

Epoch: 6| Step: 8
Training loss: 0.22537699018521082
Validation loss: 2.6728550636009336

Epoch: 6| Step: 9
Training loss: 0.2385484026425631
Validation loss: 2.6867555134173218

Epoch: 6| Step: 10
Training loss: 0.2850439294621995
Validation loss: 2.715832478535898

Epoch: 6| Step: 11
Training loss: 0.3024582865225782
Validation loss: 2.681410344093318

Epoch: 6| Step: 12
Training loss: 0.32783804562130875
Validation loss: 2.695271492613869

Epoch: 6| Step: 13
Training loss: 0.14058949764118273
Validation loss: 2.69725025935933

Epoch: 460| Step: 0
Training loss: 0.3702921793388171
Validation loss: 2.7190941486826503

Epoch: 6| Step: 1
Training loss: 0.3246411249491348
Validation loss: 2.679209378279254

Epoch: 6| Step: 2
Training loss: 0.18600374492277202
Validation loss: 2.6936514191021494

Epoch: 6| Step: 3
Training loss: 0.2569013447025843
Validation loss: 2.7160497534421975

Epoch: 6| Step: 4
Training loss: 0.3032626434349418
Validation loss: 2.686516515292336

Epoch: 6| Step: 5
Training loss: 0.23423594482294835
Validation loss: 2.710532635478529

Epoch: 6| Step: 6
Training loss: 0.30427109556481746
Validation loss: 2.6958525849077

Epoch: 6| Step: 7
Training loss: 0.31682128529983333
Validation loss: 2.7487778548858515

Epoch: 6| Step: 8
Training loss: 0.3990954781738983
Validation loss: 2.710373818960227

Epoch: 6| Step: 9
Training loss: 0.30797335880107624
Validation loss: 2.7595591862727122

Epoch: 6| Step: 10
Training loss: 0.21332524932194957
Validation loss: 2.716564498532605

Epoch: 6| Step: 11
Training loss: 0.2289852956273741
Validation loss: 2.6828017604689203

Epoch: 6| Step: 12
Training loss: 0.3814764843151431
Validation loss: 2.7763596162392004

Epoch: 6| Step: 13
Training loss: 0.2555566117505578
Validation loss: 2.7035192154392593

Epoch: 461| Step: 0
Training loss: 0.3883606512907824
Validation loss: 2.7047021046756003

Epoch: 6| Step: 1
Training loss: 0.23617935226874437
Validation loss: 2.6581972950374624

Epoch: 6| Step: 2
Training loss: 0.34650066212732594
Validation loss: 2.7789203588030857

Epoch: 6| Step: 3
Training loss: 0.4026498833575968
Validation loss: 2.7018192643596675

Epoch: 6| Step: 4
Training loss: 0.27781505566377296
Validation loss: 2.6586530698424102

Epoch: 6| Step: 5
Training loss: 0.38004354494086084
Validation loss: 2.712046825917097

Epoch: 6| Step: 6
Training loss: 0.1966065169357611
Validation loss: 2.687985605532463

Epoch: 6| Step: 7
Training loss: 0.33877039909526546
Validation loss: 2.637025023203632

Epoch: 6| Step: 8
Training loss: 0.3356579793145545
Validation loss: 2.6867607489820733

Epoch: 6| Step: 9
Training loss: 0.27652547232823166
Validation loss: 2.634105376250914

Epoch: 6| Step: 10
Training loss: 0.2953303836271742
Validation loss: 2.6617085189331595

Epoch: 6| Step: 11
Training loss: 0.25945053494431913
Validation loss: 2.6849504768047745

Epoch: 6| Step: 12
Training loss: 0.2783902130689141
Validation loss: 2.6461838592663067

Epoch: 6| Step: 13
Training loss: 0.3140309977508118
Validation loss: 2.614220298903584

Epoch: 462| Step: 0
Training loss: 0.35069947808286406
Validation loss: 2.6724830069505727

Epoch: 6| Step: 1
Training loss: 0.43299392932596353
Validation loss: 2.667176433853884

Epoch: 6| Step: 2
Training loss: 0.1841728937346285
Validation loss: 2.6126752377864526

Epoch: 6| Step: 3
Training loss: 0.3450999844488905
Validation loss: 2.6870655181746907

Epoch: 6| Step: 4
Training loss: 0.2856684878483953
Validation loss: 2.6947441128335776

Epoch: 6| Step: 5
Training loss: 0.29548552001050277
Validation loss: 2.69396692864392

Epoch: 6| Step: 6
Training loss: 0.30822816754267607
Validation loss: 2.679794168527222

Epoch: 6| Step: 7
Training loss: 0.317027882407226
Validation loss: 2.7512136151156494

Epoch: 6| Step: 8
Training loss: 0.3693422443047093
Validation loss: 2.753026784876248

Epoch: 6| Step: 9
Training loss: 0.3170406081283538
Validation loss: 2.6920944832474136

Epoch: 6| Step: 10
Training loss: 0.2621279549302527
Validation loss: 2.6806993344365684

Epoch: 6| Step: 11
Training loss: 0.16060669868014066
Validation loss: 2.6228822233702394

Epoch: 6| Step: 12
Training loss: 0.43534146584277206
Validation loss: 2.722805214322726

Epoch: 6| Step: 13
Training loss: 0.3128011682765393
Validation loss: 2.651143967029273

Epoch: 463| Step: 0
Training loss: 0.24965122600365544
Validation loss: 2.6453471951163157

Epoch: 6| Step: 1
Training loss: 0.3985396983404985
Validation loss: 2.6848742573287727

Epoch: 6| Step: 2
Training loss: 0.2439488687859242
Validation loss: 2.7664646375574575

Epoch: 6| Step: 3
Training loss: 0.2799910342109371
Validation loss: 2.683681806797464

Epoch: 6| Step: 4
Training loss: 0.30343021285856436
Validation loss: 2.7158710539466044

Epoch: 6| Step: 5
Training loss: 0.29525202782925364
Validation loss: 2.7358524363750663

Epoch: 6| Step: 6
Training loss: 0.24384886283407947
Validation loss: 2.6836435016312534

Epoch: 6| Step: 7
Training loss: 0.16408318434615352
Validation loss: 2.692760995808595

Epoch: 6| Step: 8
Training loss: 0.2707449221579551
Validation loss: 2.6816410250847524

Epoch: 6| Step: 9
Training loss: 0.3038864977578554
Validation loss: 2.6938799603260652

Epoch: 6| Step: 10
Training loss: 0.2808080220395019
Validation loss: 2.667272518794088

Epoch: 6| Step: 11
Training loss: 0.31714522639102105
Validation loss: 2.638563265425306

Epoch: 6| Step: 12
Training loss: 0.33640248255340943
Validation loss: 2.695187345538386

Epoch: 6| Step: 13
Training loss: 0.2891677587476624
Validation loss: 2.7307736395290214

Epoch: 464| Step: 0
Training loss: 0.32072087748711264
Validation loss: 2.6870432029310827

Epoch: 6| Step: 1
Training loss: 0.3640091075137735
Validation loss: 2.672908531012063

Epoch: 6| Step: 2
Training loss: 0.32810682291818366
Validation loss: 2.701564419188442

Epoch: 6| Step: 3
Training loss: 0.26256445990168975
Validation loss: 2.7119355430388783

Epoch: 6| Step: 4
Training loss: 0.23089534266331757
Validation loss: 2.699348928695565

Epoch: 6| Step: 5
Training loss: 0.3278961178090253
Validation loss: 2.6838046772561386

Epoch: 6| Step: 6
Training loss: 0.267382222879232
Validation loss: 2.687639343730153

Epoch: 6| Step: 7
Training loss: 0.32512173665164135
Validation loss: 2.669982440655007

Epoch: 6| Step: 8
Training loss: 0.24839322997272176
Validation loss: 2.647301234155487

Epoch: 6| Step: 9
Training loss: 0.2776428544006886
Validation loss: 2.6356741637433707

Epoch: 6| Step: 10
Training loss: 0.3270649589957872
Validation loss: 2.6695680083796582

Epoch: 6| Step: 11
Training loss: 0.24112360836762584
Validation loss: 2.631551287656281

Epoch: 6| Step: 12
Training loss: 0.3272589084230151
Validation loss: 2.7024335914096027

Epoch: 6| Step: 13
Training loss: 0.23672039799384126
Validation loss: 2.651930157377539

Epoch: 465| Step: 0
Training loss: 0.21568112610380596
Validation loss: 2.6933237746119447

Epoch: 6| Step: 1
Training loss: 0.2778416315173239
Validation loss: 2.686780426627852

Epoch: 6| Step: 2
Training loss: 0.40716618152006034
Validation loss: 2.6618631033964824

Epoch: 6| Step: 3
Training loss: 0.3208021747436915
Validation loss: 2.672800063823085

Epoch: 6| Step: 4
Training loss: 0.23226227610021788
Validation loss: 2.661695456097319

Epoch: 6| Step: 5
Training loss: 0.2661185587788395
Validation loss: 2.714233739732933

Epoch: 6| Step: 6
Training loss: 0.33917482906184565
Validation loss: 2.6250950629565626

Epoch: 6| Step: 7
Training loss: 0.25419497579813793
Validation loss: 2.6702323459584165

Epoch: 6| Step: 8
Training loss: 0.32791473827174733
Validation loss: 2.6589676810657226

Epoch: 6| Step: 9
Training loss: 0.2573637959050376
Validation loss: 2.6802431944680145

Epoch: 6| Step: 10
Training loss: 0.3169945322491791
Validation loss: 2.669579693052635

Epoch: 6| Step: 11
Training loss: 0.20492560755202274
Validation loss: 2.680662891454852

Epoch: 6| Step: 12
Training loss: 0.3436063444631792
Validation loss: 2.7076792049306286

Epoch: 6| Step: 13
Training loss: 0.3507474883044657
Validation loss: 2.6938229264066953

Epoch: 466| Step: 0
Training loss: 0.42749297066536646
Validation loss: 2.757320687996714

Epoch: 6| Step: 1
Training loss: 0.368670633632852
Validation loss: 2.673862766350767

Epoch: 6| Step: 2
Training loss: 0.39550110611115885
Validation loss: 2.71674028562091

Epoch: 6| Step: 3
Training loss: 0.2613707834046867
Validation loss: 2.6623661909074223

Epoch: 6| Step: 4
Training loss: 0.15698672299106595
Validation loss: 2.6557188213531178

Epoch: 6| Step: 5
Training loss: 0.3748998706971559
Validation loss: 2.6570955464062127

Epoch: 6| Step: 6
Training loss: 0.33908871931668993
Validation loss: 2.638522874534564

Epoch: 6| Step: 7
Training loss: 0.30332446270502644
Validation loss: 2.6763005924446506

Epoch: 6| Step: 8
Training loss: 0.2888037322363922
Validation loss: 2.6729591059022515

Epoch: 6| Step: 9
Training loss: 0.2803266787052878
Validation loss: 2.6861135469846604

Epoch: 6| Step: 10
Training loss: 0.25709459747438146
Validation loss: 2.6375628064648957

Epoch: 6| Step: 11
Training loss: 0.3741744013173079
Validation loss: 2.7408658834140422

Epoch: 6| Step: 12
Training loss: 0.467632232569296
Validation loss: 2.6378491048597064

Epoch: 6| Step: 13
Training loss: 0.48152735632035737
Validation loss: 2.661520990180362

Epoch: 467| Step: 0
Training loss: 0.32843724788870243
Validation loss: 2.746170556562056

Epoch: 6| Step: 1
Training loss: 0.31391778240219925
Validation loss: 2.6142740307317798

Epoch: 6| Step: 2
Training loss: 0.22135363560033183
Validation loss: 2.6856813783197317

Epoch: 6| Step: 3
Training loss: 0.3169826508484216
Validation loss: 2.67232463540845

Epoch: 6| Step: 4
Training loss: 0.38042201826350075
Validation loss: 2.6657561645198036

Epoch: 6| Step: 5
Training loss: 0.2861033870421864
Validation loss: 2.6753005735332533

Epoch: 6| Step: 6
Training loss: 0.3066903092290854
Validation loss: 2.6278003030899857

Epoch: 6| Step: 7
Training loss: 0.432962043349582
Validation loss: 2.6677298264318496

Epoch: 6| Step: 8
Training loss: 0.2234307004654261
Validation loss: 2.636290896517375

Epoch: 6| Step: 9
Training loss: 0.3113593503448833
Validation loss: 2.6348331896143065

Epoch: 6| Step: 10
Training loss: 0.43734932757245576
Validation loss: 2.712828431996871

Epoch: 6| Step: 11
Training loss: 0.39012293021384253
Validation loss: 2.7201975626348927

Epoch: 6| Step: 12
Training loss: 0.4333911972506975
Validation loss: 2.6973519832810484

Epoch: 6| Step: 13
Training loss: 0.3250817109056647
Validation loss: 2.699598573642753

Epoch: 468| Step: 0
Training loss: 0.28100673433460926
Validation loss: 2.729078325390037

Epoch: 6| Step: 1
Training loss: 0.31556044664355193
Validation loss: 2.6763066502264543

Epoch: 6| Step: 2
Training loss: 0.35039410881768634
Validation loss: 2.70741735276462

Epoch: 6| Step: 3
Training loss: 0.38498638810209285
Validation loss: 2.691786696254654

Epoch: 6| Step: 4
Training loss: 0.31841907058559815
Validation loss: 2.70213509958328

Epoch: 6| Step: 5
Training loss: 0.25881131634306825
Validation loss: 2.6211185217272823

Epoch: 6| Step: 6
Training loss: 0.23820319226077272
Validation loss: 2.648445001852238

Epoch: 6| Step: 7
Training loss: 0.3611380618483938
Validation loss: 2.6713921926827333

Epoch: 6| Step: 8
Training loss: 0.3506843195084169
Validation loss: 2.682364295544064

Epoch: 6| Step: 9
Training loss: 0.32476386239768984
Validation loss: 2.6632724160909245

Epoch: 6| Step: 10
Training loss: 0.32754700707369844
Validation loss: 2.6395824789654543

Epoch: 6| Step: 11
Training loss: 0.37976531342048475
Validation loss: 2.636948450703113

Epoch: 6| Step: 12
Training loss: 0.339123521754484
Validation loss: 2.6787563444825793

Epoch: 6| Step: 13
Training loss: 0.341952555487971
Validation loss: 2.6192103980412025

Epoch: 469| Step: 0
Training loss: 0.2246396832127652
Validation loss: 2.6029362607433892

Epoch: 6| Step: 1
Training loss: 0.28055458721118626
Validation loss: 2.6720917597065346

Epoch: 6| Step: 2
Training loss: 0.268871384199544
Validation loss: 2.6805767515285526

Epoch: 6| Step: 3
Training loss: 0.3577720719199052
Validation loss: 2.6156285667622994

Epoch: 6| Step: 4
Training loss: 0.3340409660357385
Validation loss: 2.675174289741545

Epoch: 6| Step: 5
Training loss: 0.31725261658746057
Validation loss: 2.695539780031868

Epoch: 6| Step: 6
Training loss: 0.3495221588630475
Validation loss: 2.5838063227483845

Epoch: 6| Step: 7
Training loss: 0.35238984561350734
Validation loss: 2.6780068898576497

Epoch: 6| Step: 8
Training loss: 0.34601659625208425
Validation loss: 2.63443488026204

Epoch: 6| Step: 9
Training loss: 0.2756215473313451
Validation loss: 2.6275725399013137

Epoch: 6| Step: 10
Training loss: 0.3790909621708751
Validation loss: 2.6333336319098324

Epoch: 6| Step: 11
Training loss: 0.37438696184615416
Validation loss: 2.6700998994328384

Epoch: 6| Step: 12
Training loss: 0.2600175023606868
Validation loss: 2.6575008065290353

Epoch: 6| Step: 13
Training loss: 0.3114072648839113
Validation loss: 2.690287689320268

Epoch: 470| Step: 0
Training loss: 0.3649971747615635
Validation loss: 2.6449096424002256

Epoch: 6| Step: 1
Training loss: 0.3507083371005187
Validation loss: 2.735895239247461

Epoch: 6| Step: 2
Training loss: 0.4832111342559649
Validation loss: 2.682854296492543

Epoch: 6| Step: 3
Training loss: 0.27044460783897295
Validation loss: 2.694857882430954

Epoch: 6| Step: 4
Training loss: 0.19131683674570002
Validation loss: 2.7177137102624864

Epoch: 6| Step: 5
Training loss: 0.36359898198276897
Validation loss: 2.6571967139501744

Epoch: 6| Step: 6
Training loss: 0.3267705528388594
Validation loss: 2.706251229277839

Epoch: 6| Step: 7
Training loss: 0.30461647966605987
Validation loss: 2.7026306832282616

Epoch: 6| Step: 8
Training loss: 0.3359047518892034
Validation loss: 2.6690276517425398

Epoch: 6| Step: 9
Training loss: 0.2662919171115814
Validation loss: 2.7203957410737813

Epoch: 6| Step: 10
Training loss: 0.3787115717740426
Validation loss: 2.715752333862834

Epoch: 6| Step: 11
Training loss: 0.2826155124026774
Validation loss: 2.6680614479534275

Epoch: 6| Step: 12
Training loss: 0.2938203007194632
Validation loss: 2.627023870373485

Epoch: 6| Step: 13
Training loss: 0.26637772885683114
Validation loss: 2.5997447784187484

Epoch: 471| Step: 0
Training loss: 0.30949892009059854
Validation loss: 2.6582225431676174

Epoch: 6| Step: 1
Training loss: 0.4263959175107668
Validation loss: 2.7200647587874216

Epoch: 6| Step: 2
Training loss: 0.2774994641376167
Validation loss: 2.624129332608666

Epoch: 6| Step: 3
Training loss: 0.27306490444313064
Validation loss: 2.6338871423820613

Epoch: 6| Step: 4
Training loss: 0.24085162501405635
Validation loss: 2.684445752598098

Epoch: 6| Step: 5
Training loss: 0.270080807788116
Validation loss: 2.6445060589791196

Epoch: 6| Step: 6
Training loss: 0.26120160380100377
Validation loss: 2.7021065853376296

Epoch: 6| Step: 7
Training loss: 0.3583358585283476
Validation loss: 2.7032475305911285

Epoch: 6| Step: 8
Training loss: 0.3242506448155494
Validation loss: 2.658897225195996

Epoch: 6| Step: 9
Training loss: 0.37229430097228944
Validation loss: 2.723711492515135

Epoch: 6| Step: 10
Training loss: 0.3495954798489137
Validation loss: 2.691261210083814

Epoch: 6| Step: 11
Training loss: 0.3690540070812236
Validation loss: 2.6900118540865465

Epoch: 6| Step: 12
Training loss: 0.2722525808310106
Validation loss: 2.705829421466349

Epoch: 6| Step: 13
Training loss: 0.26522815736384775
Validation loss: 2.739045679012105

Epoch: 472| Step: 0
Training loss: 0.26381152657982443
Validation loss: 2.6665022372175544

Epoch: 6| Step: 1
Training loss: 0.3012930367819832
Validation loss: 2.6920040446700253

Epoch: 6| Step: 2
Training loss: 0.14935587080168955
Validation loss: 2.662687071495051

Epoch: 6| Step: 3
Training loss: 0.23114699440919934
Validation loss: 2.7178230020689265

Epoch: 6| Step: 4
Training loss: 0.20295322931515922
Validation loss: 2.6962543924219546

Epoch: 6| Step: 5
Training loss: 0.2859830757465496
Validation loss: 2.709683101490492

Epoch: 6| Step: 6
Training loss: 0.2743354902083205
Validation loss: 2.6547818333848987

Epoch: 6| Step: 7
Training loss: 0.3163853391165943
Validation loss: 2.7517095656105672

Epoch: 6| Step: 8
Training loss: 0.4033413158794609
Validation loss: 2.6930596191964047

Epoch: 6| Step: 9
Training loss: 0.27016791186691924
Validation loss: 2.698597234266091

Epoch: 6| Step: 10
Training loss: 0.3647830030362723
Validation loss: 2.7751070755127287

Epoch: 6| Step: 11
Training loss: 0.22276417308461846
Validation loss: 2.672716056706913

Epoch: 6| Step: 12
Training loss: 0.34163137516294334
Validation loss: 2.749435345160255

Epoch: 6| Step: 13
Training loss: 0.2612630948522016
Validation loss: 2.6928861449885355

Epoch: 473| Step: 0
Training loss: 0.2947008302450701
Validation loss: 2.7078813738170706

Epoch: 6| Step: 1
Training loss: 0.31333455467028365
Validation loss: 2.7018922703432438

Epoch: 6| Step: 2
Training loss: 0.29257949400964756
Validation loss: 2.69463585362693

Epoch: 6| Step: 3
Training loss: 0.33334563898180913
Validation loss: 2.7409524119594195

Epoch: 6| Step: 4
Training loss: 0.23673308961700734
Validation loss: 2.6893355584656278

Epoch: 6| Step: 5
Training loss: 0.17386731766760363
Validation loss: 2.673876527655131

Epoch: 6| Step: 6
Training loss: 0.20995124084792327
Validation loss: 2.6244597333150868

Epoch: 6| Step: 7
Training loss: 0.2230886310033385
Validation loss: 2.660706032410717

Epoch: 6| Step: 8
Training loss: 0.3890683820961584
Validation loss: 2.6964002395435864

Epoch: 6| Step: 9
Training loss: 0.25367049496166344
Validation loss: 2.649526051658322

Epoch: 6| Step: 10
Training loss: 0.23853858747257903
Validation loss: 2.673723217373928

Epoch: 6| Step: 11
Training loss: 0.18366743191919063
Validation loss: 2.7367657046764324

Epoch: 6| Step: 12
Training loss: 0.3173666964620746
Validation loss: 2.6762255149005125

Epoch: 6| Step: 13
Training loss: 0.29353175425844064
Validation loss: 2.67102715497654

Epoch: 474| Step: 0
Training loss: 0.3544183659468318
Validation loss: 2.655741549428912

Epoch: 6| Step: 1
Training loss: 0.186650078407545
Validation loss: 2.6272054671581455

Epoch: 6| Step: 2
Training loss: 0.36077386771703696
Validation loss: 2.716239062007972

Epoch: 6| Step: 3
Training loss: 0.23790732733811903
Validation loss: 2.6445405960856974

Epoch: 6| Step: 4
Training loss: 0.29106045064108427
Validation loss: 2.6671645151767

Epoch: 6| Step: 5
Training loss: 0.34625643830906644
Validation loss: 2.686427338505053

Epoch: 6| Step: 6
Training loss: 0.24882677577924012
Validation loss: 2.6191173669065444

Epoch: 6| Step: 7
Training loss: 0.22419341173451954
Validation loss: 2.705953599117055

Epoch: 6| Step: 8
Training loss: 0.30773322929097385
Validation loss: 2.6615627788397096

Epoch: 6| Step: 9
Training loss: 0.3272885036963189
Validation loss: 2.6678314694951597

Epoch: 6| Step: 10
Training loss: 0.32998767719597116
Validation loss: 2.6546640036959332

Epoch: 6| Step: 11
Training loss: 0.33440348334523035
Validation loss: 2.647984671350984

Epoch: 6| Step: 12
Training loss: 0.3377285938178466
Validation loss: 2.650155829400411

Epoch: 6| Step: 13
Training loss: 0.30199715464795773
Validation loss: 2.6923947597492717

Epoch: 475| Step: 0
Training loss: 0.34462727962206224
Validation loss: 2.6127063858304407

Epoch: 6| Step: 1
Training loss: 0.3179946050043828
Validation loss: 2.641452930379826

Epoch: 6| Step: 2
Training loss: 0.30096224503868974
Validation loss: 2.7088880386586776

Epoch: 6| Step: 3
Training loss: 0.304174259931464
Validation loss: 2.7086816906028437

Epoch: 6| Step: 4
Training loss: 0.23708512309448618
Validation loss: 2.724546676515937

Epoch: 6| Step: 5
Training loss: 0.3824581530374851
Validation loss: 2.726889057879482

Epoch: 6| Step: 6
Training loss: 0.3493768355538016
Validation loss: 2.7206771130036063

Epoch: 6| Step: 7
Training loss: 0.4642026631775656
Validation loss: 2.6990195834356414

Epoch: 6| Step: 8
Training loss: 0.2868467803863161
Validation loss: 2.598240813830105

Epoch: 6| Step: 9
Training loss: 0.3222193251208716
Validation loss: 2.6711122863072805

Epoch: 6| Step: 10
Training loss: 0.25073200586093164
Validation loss: 2.6289655008955686

Epoch: 6| Step: 11
Training loss: 0.30385071215116916
Validation loss: 2.6466196098356227

Epoch: 6| Step: 12
Training loss: 0.30781447124334105
Validation loss: 2.6813194414111203

Epoch: 6| Step: 13
Training loss: 0.21364016219104107
Validation loss: 2.653198097099708

Epoch: 476| Step: 0
Training loss: 0.2529633842026419
Validation loss: 2.635237289375379

Epoch: 6| Step: 1
Training loss: 0.249055478895677
Validation loss: 2.637045659650867

Epoch: 6| Step: 2
Training loss: 0.36138936116709547
Validation loss: 2.657834676133861

Epoch: 6| Step: 3
Training loss: 0.26885468805985047
Validation loss: 2.6348849930056093

Epoch: 6| Step: 4
Training loss: 0.29193207750407124
Validation loss: 2.6944557191890333

Epoch: 6| Step: 5
Training loss: 0.3107773267633553
Validation loss: 2.595525685281193

Epoch: 6| Step: 6
Training loss: 0.27686697315352116
Validation loss: 2.6437804876422843

Epoch: 6| Step: 7
Training loss: 0.2935583539519336
Validation loss: 2.7019780983845485

Epoch: 6| Step: 8
Training loss: 0.519308228773934
Validation loss: 2.6546407724286665

Epoch: 6| Step: 9
Training loss: 0.33220607418550635
Validation loss: 2.6616055820488724

Epoch: 6| Step: 10
Training loss: 0.3134601267846532
Validation loss: 2.6737860078840687

Epoch: 6| Step: 11
Training loss: 0.24991066647884808
Validation loss: 2.673494825820572

Epoch: 6| Step: 12
Training loss: 0.28767116882990085
Validation loss: 2.658396298809806

Epoch: 6| Step: 13
Training loss: 0.2793047977204119
Validation loss: 2.613235625290232

Epoch: 477| Step: 0
Training loss: 0.2282382063654741
Validation loss: 2.6936322858422956

Epoch: 6| Step: 1
Training loss: 0.3459935988450117
Validation loss: 2.6558119767998805

Epoch: 6| Step: 2
Training loss: 0.23354924489270615
Validation loss: 2.6049693943063565

Epoch: 6| Step: 3
Training loss: 0.2690232922235271
Validation loss: 2.716799661290751

Epoch: 6| Step: 4
Training loss: 0.3271884267478723
Validation loss: 2.7253370764834806

Epoch: 6| Step: 5
Training loss: 0.32258964202047896
Validation loss: 2.610005247408

Epoch: 6| Step: 6
Training loss: 0.21068290074493426
Validation loss: 2.586897657377673

Epoch: 6| Step: 7
Training loss: 0.24770984881931785
Validation loss: 2.628957384206414

Epoch: 6| Step: 8
Training loss: 0.29849091995429006
Validation loss: 2.66961023669507

Epoch: 6| Step: 9
Training loss: 0.3675624880570979
Validation loss: 2.659993170894375

Epoch: 6| Step: 10
Training loss: 0.2791310064589469
Validation loss: 2.6829852247614503

Epoch: 6| Step: 11
Training loss: 0.2743756956382744
Validation loss: 2.6424270064137922

Epoch: 6| Step: 12
Training loss: 0.236143568186812
Validation loss: 2.69947127004287

Epoch: 6| Step: 13
Training loss: 0.5573604814580944
Validation loss: 2.648470635520979

Epoch: 478| Step: 0
Training loss: 0.29470860430974993
Validation loss: 2.6641311562082395

Epoch: 6| Step: 1
Training loss: 0.23857809556269716
Validation loss: 2.6424635857389176

Epoch: 6| Step: 2
Training loss: 0.2465538386478339
Validation loss: 2.6294963414356007

Epoch: 6| Step: 3
Training loss: 0.28865450340932797
Validation loss: 2.650465219975793

Epoch: 6| Step: 4
Training loss: 0.3001792630414337
Validation loss: 2.7360577301093727

Epoch: 6| Step: 5
Training loss: 0.24826702350839813
Validation loss: 2.6450928280074497

Epoch: 6| Step: 6
Training loss: 0.24449855506651386
Validation loss: 2.624640924629646

Epoch: 6| Step: 7
Training loss: 0.18940145240136677
Validation loss: 2.6894982471988693

Epoch: 6| Step: 8
Training loss: 0.2019216583057148
Validation loss: 2.626408895206445

Epoch: 6| Step: 9
Training loss: 0.26649671456099283
Validation loss: 2.6494887824559252

Epoch: 6| Step: 10
Training loss: 0.18908282596313553
Validation loss: 2.6446844945896

Epoch: 6| Step: 11
Training loss: 0.29488430668114635
Validation loss: 2.692791283889754

Epoch: 6| Step: 12
Training loss: 0.22386257578902666
Validation loss: 2.679598125602202

Epoch: 6| Step: 13
Training loss: 0.35172870733739536
Validation loss: 2.692468648507802

Epoch: 479| Step: 0
Training loss: 0.37835610160853084
Validation loss: 2.655498323484435

Epoch: 6| Step: 1
Training loss: 0.22907128390062675
Validation loss: 2.678988351617873

Epoch: 6| Step: 2
Training loss: 0.38629813391254264
Validation loss: 2.6787290054474053

Epoch: 6| Step: 3
Training loss: 0.23040081898051973
Validation loss: 2.69466365062363

Epoch: 6| Step: 4
Training loss: 0.338548438909236
Validation loss: 2.6887333723376092

Epoch: 6| Step: 5
Training loss: 0.28418493102174935
Validation loss: 2.6889161215822686

Epoch: 6| Step: 6
Training loss: 0.39022619870835296
Validation loss: 2.649014960456404

Epoch: 6| Step: 7
Training loss: 0.3960837233137708
Validation loss: 2.690030510858184

Epoch: 6| Step: 8
Training loss: 0.2843629436242793
Validation loss: 2.670900460846278

Epoch: 6| Step: 9
Training loss: 0.35746564753416893
Validation loss: 2.692308176044099

Epoch: 6| Step: 10
Training loss: 0.3820019139296833
Validation loss: 2.67600010628883

Epoch: 6| Step: 11
Training loss: 0.4471769453198653
Validation loss: 2.713278962132611

Epoch: 6| Step: 12
Training loss: 0.31835750275043795
Validation loss: 2.6538659261238395

Epoch: 6| Step: 13
Training loss: 0.3288255660523269
Validation loss: 2.684639613558115

Epoch: 480| Step: 0
Training loss: 0.2920236857594414
Validation loss: 2.63451111103639

Epoch: 6| Step: 1
Training loss: 0.3731810642978664
Validation loss: 2.70971273849325

Epoch: 6| Step: 2
Training loss: 0.31741851605819404
Validation loss: 2.658218813515174

Epoch: 6| Step: 3
Training loss: 0.23840596109188494
Validation loss: 2.686481948360226

Epoch: 6| Step: 4
Training loss: 0.32215533825831066
Validation loss: 2.6565742444371603

Epoch: 6| Step: 5
Training loss: 0.4115263987227809
Validation loss: 2.684364448796039

Epoch: 6| Step: 6
Training loss: 0.2747189602938392
Validation loss: 2.6478768114341498

Epoch: 6| Step: 7
Training loss: 0.23540602247823955
Validation loss: 2.6217154434995344

Epoch: 6| Step: 8
Training loss: 0.2626191209537226
Validation loss: 2.711895541625929

Epoch: 6| Step: 9
Training loss: 0.26333476521660026
Validation loss: 2.6764753569108612

Epoch: 6| Step: 10
Training loss: 0.23284767320415256
Validation loss: 2.663705632236936

Epoch: 6| Step: 11
Training loss: 0.27490827916515104
Validation loss: 2.69850717560259

Epoch: 6| Step: 12
Training loss: 0.3752717186070555
Validation loss: 2.756210805797365

Epoch: 6| Step: 13
Training loss: 0.38009233752001315
Validation loss: 2.6764232747006393

Epoch: 481| Step: 0
Training loss: 0.321598576393197
Validation loss: 2.711211667960172

Epoch: 6| Step: 1
Training loss: 0.42881763147270324
Validation loss: 2.6900751802274367

Epoch: 6| Step: 2
Training loss: 0.2577513708990216
Validation loss: 2.6942288786618405

Epoch: 6| Step: 3
Training loss: 0.27232620025134935
Validation loss: 2.687210747581689

Epoch: 6| Step: 4
Training loss: 0.21462114245603361
Validation loss: 2.6207019420209257

Epoch: 6| Step: 5
Training loss: 0.18526852459056864
Validation loss: 2.660792815627421

Epoch: 6| Step: 6
Training loss: 0.21941164973995092
Validation loss: 2.715028034789061

Epoch: 6| Step: 7
Training loss: 0.2856536472528742
Validation loss: 2.6733096994590437

Epoch: 6| Step: 8
Training loss: 0.2492761638481624
Validation loss: 2.7138859804355424

Epoch: 6| Step: 9
Training loss: 0.23315162057988284
Validation loss: 2.661096109026319

Epoch: 6| Step: 10
Training loss: 0.16020150243134101
Validation loss: 2.7109457230237095

Epoch: 6| Step: 11
Training loss: 0.24525219971917564
Validation loss: 2.642305648150337

Epoch: 6| Step: 12
Training loss: 0.41663586582145923
Validation loss: 2.7102553419052247

Epoch: 6| Step: 13
Training loss: 0.27146778467655963
Validation loss: 2.6843656404307645

Epoch: 482| Step: 0
Training loss: 0.1696707964240294
Validation loss: 2.6695863912497506

Epoch: 6| Step: 1
Training loss: 0.2686818186080976
Validation loss: 2.721964780696901

Epoch: 6| Step: 2
Training loss: 0.28838557808221443
Validation loss: 2.720617376483776

Epoch: 6| Step: 3
Training loss: 0.26078053167483056
Validation loss: 2.6839529183034636

Epoch: 6| Step: 4
Training loss: 0.28004732215290995
Validation loss: 2.658103744812921

Epoch: 6| Step: 5
Training loss: 0.25287583414827386
Validation loss: 2.604214016801788

Epoch: 6| Step: 6
Training loss: 0.17993726165148846
Validation loss: 2.6883986619184226

Epoch: 6| Step: 7
Training loss: 0.2235724021909138
Validation loss: 2.649051441311896

Epoch: 6| Step: 8
Training loss: 0.26493147463380096
Validation loss: 2.7283838959818594

Epoch: 6| Step: 9
Training loss: 0.2738243772111475
Validation loss: 2.634284712457353

Epoch: 6| Step: 10
Training loss: 0.2546011731634283
Validation loss: 2.676499482448696

Epoch: 6| Step: 11
Training loss: 0.2774944299061525
Validation loss: 2.636996761782947

Epoch: 6| Step: 12
Training loss: 0.20280831666226284
Validation loss: 2.678565477182952

Epoch: 6| Step: 13
Training loss: 0.2547146472621556
Validation loss: 2.6637883646586253

Epoch: 483| Step: 0
Training loss: 0.2904837054649698
Validation loss: 2.7488645825017715

Epoch: 6| Step: 1
Training loss: 0.2699350566378057
Validation loss: 2.733295198403253

Epoch: 6| Step: 2
Training loss: 0.2163318251282686
Validation loss: 2.682201485213498

Epoch: 6| Step: 3
Training loss: 0.24966796044199924
Validation loss: 2.6486075917766065

Epoch: 6| Step: 4
Training loss: 0.26078767415448484
Validation loss: 2.7233215861804476

Epoch: 6| Step: 5
Training loss: 0.2142358850405459
Validation loss: 2.709689685889722

Epoch: 6| Step: 6
Training loss: 0.4218525527351027
Validation loss: 2.665703418229658

Epoch: 6| Step: 7
Training loss: 0.30281175424348156
Validation loss: 2.6705618711950216

Epoch: 6| Step: 8
Training loss: 0.22828679976874722
Validation loss: 2.627439992190991

Epoch: 6| Step: 9
Training loss: 0.4763493608468241
Validation loss: 2.788223354073071

Epoch: 6| Step: 10
Training loss: 0.2118163344935801
Validation loss: 2.716541621093837

Epoch: 6| Step: 11
Training loss: 0.30649509742761283
Validation loss: 2.727242458782423

Epoch: 6| Step: 12
Training loss: 0.34064102922573686
Validation loss: 2.7004029785650636

Epoch: 6| Step: 13
Training loss: 0.2832045982585602
Validation loss: 2.7021266144575637

Epoch: 484| Step: 0
Training loss: 0.27537267369410223
Validation loss: 2.6458890763866183

Epoch: 6| Step: 1
Training loss: 0.30559097732548446
Validation loss: 2.6884472678302416

Epoch: 6| Step: 2
Training loss: 0.36103119893132696
Validation loss: 2.6254733430885477

Epoch: 6| Step: 3
Training loss: 0.24194003352122498
Validation loss: 2.6832970423248415

Epoch: 6| Step: 4
Training loss: 0.2947534244296365
Validation loss: 2.6877790941914417

Epoch: 6| Step: 5
Training loss: 0.3566316927306245
Validation loss: 2.7263902611604065

Epoch: 6| Step: 6
Training loss: 0.37741775734703753
Validation loss: 2.653467823131298

Epoch: 6| Step: 7
Training loss: 0.3610552608060758
Validation loss: 2.7006661140898354

Epoch: 6| Step: 8
Training loss: 0.37973217563975614
Validation loss: 2.67953704322626

Epoch: 6| Step: 9
Training loss: 0.31405081988198635
Validation loss: 2.6887285248652364

Epoch: 6| Step: 10
Training loss: 0.3241721889659626
Validation loss: 2.7355224672200316

Epoch: 6| Step: 11
Training loss: 0.2162959523521982
Validation loss: 2.6631308946870282

Epoch: 6| Step: 12
Training loss: 0.34193054855035704
Validation loss: 2.6932583117501823

Epoch: 6| Step: 13
Training loss: 0.2656840931851876
Validation loss: 2.6975475829614775

Epoch: 485| Step: 0
Training loss: 0.26499960710388426
Validation loss: 2.7057452869883543

Epoch: 6| Step: 1
Training loss: 0.26506904314416235
Validation loss: 2.7292756842662356

Epoch: 6| Step: 2
Training loss: 0.3388632738398596
Validation loss: 2.6746102473975926

Epoch: 6| Step: 3
Training loss: 0.2851006440593251
Validation loss: 2.6733246824627157

Epoch: 6| Step: 4
Training loss: 0.2813388895921901
Validation loss: 2.7234094089759853

Epoch: 6| Step: 5
Training loss: 0.26177465496519564
Validation loss: 2.6390048743296086

Epoch: 6| Step: 6
Training loss: 0.24108341259157856
Validation loss: 2.687657004213365

Epoch: 6| Step: 7
Training loss: 0.1950108965097292
Validation loss: 2.701168241427155

Epoch: 6| Step: 8
Training loss: 0.3669071750731552
Validation loss: 2.7239695026662263

Epoch: 6| Step: 9
Training loss: 0.3302605480383733
Validation loss: 2.6417936789928422

Epoch: 6| Step: 10
Training loss: 0.2941621506554159
Validation loss: 2.6993152989419205

Epoch: 6| Step: 11
Training loss: 0.24295715353420946
Validation loss: 2.757052423992733

Epoch: 6| Step: 12
Training loss: 0.3355594215223435
Validation loss: 2.642039580352607

Epoch: 6| Step: 13
Training loss: 0.33956125729812836
Validation loss: 2.62262421528654

Epoch: 486| Step: 0
Training loss: 0.37856133483208604
Validation loss: 2.7230822076266814

Epoch: 6| Step: 1
Training loss: 0.27284093903030854
Validation loss: 2.6733948398547804

Epoch: 6| Step: 2
Training loss: 0.2742444257317496
Validation loss: 2.6784985187235173

Epoch: 6| Step: 3
Training loss: 0.3536998416333522
Validation loss: 2.682931039894808

Epoch: 6| Step: 4
Training loss: 0.27720845643207115
Validation loss: 2.6635824984833505

Epoch: 6| Step: 5
Training loss: 0.35516184878352197
Validation loss: 2.7001817294762716

Epoch: 6| Step: 6
Training loss: 0.30213081737547387
Validation loss: 2.71297005595916

Epoch: 6| Step: 7
Training loss: 0.21571957062309996
Validation loss: 2.7084863374968884

Epoch: 6| Step: 8
Training loss: 0.2985405254785875
Validation loss: 2.680316550932353

Epoch: 6| Step: 9
Training loss: 0.28116794554817703
Validation loss: 2.7550415440477325

Epoch: 6| Step: 10
Training loss: 0.3764581939466198
Validation loss: 2.712647103277603

Epoch: 6| Step: 11
Training loss: 0.3295897194191027
Validation loss: 2.731941797211767

Epoch: 6| Step: 12
Training loss: 0.38687288699705447
Validation loss: 2.7083614836966015

Epoch: 6| Step: 13
Training loss: 0.3236392253638646
Validation loss: 2.723612890470439

Epoch: 487| Step: 0
Training loss: 0.2827014030463557
Validation loss: 2.6753283634850984

Epoch: 6| Step: 1
Training loss: 0.22512463885791456
Validation loss: 2.714387279895255

Epoch: 6| Step: 2
Training loss: 0.22635586128501675
Validation loss: 2.69626237284286

Epoch: 6| Step: 3
Training loss: 0.3286948478328601
Validation loss: 2.697780949383686

Epoch: 6| Step: 4
Training loss: 0.3262315798269327
Validation loss: 2.672918640120133

Epoch: 6| Step: 5
Training loss: 0.43127850839122
Validation loss: 2.687328362713533

Epoch: 6| Step: 6
Training loss: 0.23980395207445337
Validation loss: 2.6272547590051887

Epoch: 6| Step: 7
Training loss: 0.2826838237498951
Validation loss: 2.6162816468019963

Epoch: 6| Step: 8
Training loss: 0.327483708544281
Validation loss: 2.638041750695365

Epoch: 6| Step: 9
Training loss: 0.22289452435398244
Validation loss: 2.6872317305931124

Epoch: 6| Step: 10
Training loss: 0.25005967202907925
Validation loss: 2.695053397730715

Epoch: 6| Step: 11
Training loss: 0.27014857928283564
Validation loss: 2.7067802279785633

Epoch: 6| Step: 12
Training loss: 0.2514815982310973
Validation loss: 2.684049253938487

Epoch: 6| Step: 13
Training loss: 0.38166758540652335
Validation loss: 2.6369500103541075

Epoch: 488| Step: 0
Training loss: 0.27820483037120075
Validation loss: 2.6811579311305453

Epoch: 6| Step: 1
Training loss: 0.23397379550356825
Validation loss: 2.674886400716254

Epoch: 6| Step: 2
Training loss: 0.296675037500783
Validation loss: 2.723086818835688

Epoch: 6| Step: 3
Training loss: 0.28133377840717266
Validation loss: 2.719289748009086

Epoch: 6| Step: 4
Training loss: 0.38268577658031405
Validation loss: 2.721118582182248

Epoch: 6| Step: 5
Training loss: 0.28286141135953535
Validation loss: 2.649583476698919

Epoch: 6| Step: 6
Training loss: 0.19864717467231416
Validation loss: 2.701121982822572

Epoch: 6| Step: 7
Training loss: 0.3857259819393082
Validation loss: 2.6965196200745774

Epoch: 6| Step: 8
Training loss: 0.2539431911885128
Validation loss: 2.7330686809379148

Epoch: 6| Step: 9
Training loss: 0.26835482009065004
Validation loss: 2.7154479015505637

Epoch: 6| Step: 10
Training loss: 0.3762774959922176
Validation loss: 2.680260318074545

Epoch: 6| Step: 11
Training loss: 0.3067109458618427
Validation loss: 2.6394895260427145

Epoch: 6| Step: 12
Training loss: 0.28874730633226486
Validation loss: 2.7087833373032892

Epoch: 6| Step: 13
Training loss: 0.31084976779676887
Validation loss: 2.630253945638144

Epoch: 489| Step: 0
Training loss: 0.28677060128750037
Validation loss: 2.688444784715405

Epoch: 6| Step: 1
Training loss: 0.27588714317245816
Validation loss: 2.6663721984960156

Epoch: 6| Step: 2
Training loss: 0.3147817635866685
Validation loss: 2.6628257587999475

Epoch: 6| Step: 3
Training loss: 0.32192760426548533
Validation loss: 2.632583140297803

Epoch: 6| Step: 4
Training loss: 0.2619479727074816
Validation loss: 2.6860214276504126

Epoch: 6| Step: 5
Training loss: 0.2849754125881078
Validation loss: 2.633722866698904

Epoch: 6| Step: 6
Training loss: 0.2585306568911295
Validation loss: 2.6301316706497864

Epoch: 6| Step: 7
Training loss: 0.3393736580563986
Validation loss: 2.683426601455453

Epoch: 6| Step: 8
Training loss: 0.2873903184527304
Validation loss: 2.6499840376031307

Epoch: 6| Step: 9
Training loss: 0.2719377806952923
Validation loss: 2.676141110467373

Epoch: 6| Step: 10
Training loss: 0.2670816144773864
Validation loss: 2.701602735012034

Epoch: 6| Step: 11
Training loss: 0.2527708637482034
Validation loss: 2.682100757113422

Epoch: 6| Step: 12
Training loss: 0.31698974918689865
Validation loss: 2.7092823468843106

Epoch: 6| Step: 13
Training loss: 0.25469633566853095
Validation loss: 2.7128817780370804

Epoch: 490| Step: 0
Training loss: 0.3009680378552641
Validation loss: 2.6164498727327907

Epoch: 6| Step: 1
Training loss: 0.26255606041330043
Validation loss: 2.6374997336340797

Epoch: 6| Step: 2
Training loss: 0.29509548104903627
Validation loss: 2.6440254603000257

Epoch: 6| Step: 3
Training loss: 0.3686945000601698
Validation loss: 2.658912550944952

Epoch: 6| Step: 4
Training loss: 0.3139496913830935
Validation loss: 2.675599875881302

Epoch: 6| Step: 5
Training loss: 0.2956269910757424
Validation loss: 2.6439477604578556

Epoch: 6| Step: 6
Training loss: 0.27567487615733205
Validation loss: 2.655318212698676

Epoch: 6| Step: 7
Training loss: 0.22268340296567077
Validation loss: 2.6456860754129337

Epoch: 6| Step: 8
Training loss: 0.32044387077276737
Validation loss: 2.6093152890254783

Epoch: 6| Step: 9
Training loss: 0.2633652493645818
Validation loss: 2.663749415401906

Epoch: 6| Step: 10
Training loss: 0.41061114562190776
Validation loss: 2.6856104469866753

Epoch: 6| Step: 11
Training loss: 0.3788416305969811
Validation loss: 2.6691843059130433

Epoch: 6| Step: 12
Training loss: 0.39249168696985015
Validation loss: 2.7415978793140567

Epoch: 6| Step: 13
Training loss: 0.34511384471230777
Validation loss: 2.559159458510064

Epoch: 491| Step: 0
Training loss: 0.21887153416922708
Validation loss: 2.6151113065708116

Epoch: 6| Step: 1
Training loss: 0.29609887413080116
Validation loss: 2.757573319996783

Epoch: 6| Step: 2
Training loss: 0.2794053993924659
Validation loss: 2.6750945089407083

Epoch: 6| Step: 3
Training loss: 0.37331903725454474
Validation loss: 2.7302027378561022

Epoch: 6| Step: 4
Training loss: 0.28127030458271823
Validation loss: 2.640467245893567

Epoch: 6| Step: 5
Training loss: 0.27359099848053725
Validation loss: 2.6725917248973334

Epoch: 6| Step: 6
Training loss: 0.30674589986244993
Validation loss: 2.6673382842176783

Epoch: 6| Step: 7
Training loss: 0.31579742018396034
Validation loss: 2.7002881549788023

Epoch: 6| Step: 8
Training loss: 0.38122619179351674
Validation loss: 2.7246365453534374

Epoch: 6| Step: 9
Training loss: 0.1540125266923828
Validation loss: 2.7039835968314776

Epoch: 6| Step: 10
Training loss: 0.3530736235994963
Validation loss: 2.634732000401737

Epoch: 6| Step: 11
Training loss: 0.291382027711074
Validation loss: 2.670040489823203

Epoch: 6| Step: 12
Training loss: 0.3870263080797328
Validation loss: 2.7214106333348456

Epoch: 6| Step: 13
Training loss: 0.23414847235119177
Validation loss: 2.673237979057186

Epoch: 492| Step: 0
Training loss: 0.35764855872767376
Validation loss: 2.703894092319758

Epoch: 6| Step: 1
Training loss: 0.33869616455480595
Validation loss: 2.7045302514478746

Epoch: 6| Step: 2
Training loss: 0.3581040131908886
Validation loss: 2.6958457235044695

Epoch: 6| Step: 3
Training loss: 0.23005549508995646
Validation loss: 2.657163462928854

Epoch: 6| Step: 4
Training loss: 0.30423433887919743
Validation loss: 2.6333856609634063

Epoch: 6| Step: 5
Training loss: 0.43535137493117526
Validation loss: 2.666953180736276

Epoch: 6| Step: 6
Training loss: 0.30414686165742116
Validation loss: 2.6791954218941414

Epoch: 6| Step: 7
Training loss: 0.3499771293763108
Validation loss: 2.619417976640314

Epoch: 6| Step: 8
Training loss: 0.33709334979639605
Validation loss: 2.688750013289074

Epoch: 6| Step: 9
Training loss: 0.2176521545156294
Validation loss: 2.685528593983707

Epoch: 6| Step: 10
Training loss: 0.279360877219861
Validation loss: 2.7132526592809962

Epoch: 6| Step: 11
Training loss: 0.3326143194087273
Validation loss: 2.6258341357069406

Epoch: 6| Step: 12
Training loss: 0.24705277633253472
Validation loss: 2.7313249852691714

Epoch: 6| Step: 13
Training loss: 0.3650379570729442
Validation loss: 2.6885925703958207

Epoch: 493| Step: 0
Training loss: 0.2711326736078317
Validation loss: 2.73123123372001

Epoch: 6| Step: 1
Training loss: 0.29477046086004294
Validation loss: 2.683407883961009

Epoch: 6| Step: 2
Training loss: 0.38589982300606274
Validation loss: 2.6817519499844353

Epoch: 6| Step: 3
Training loss: 0.2486789939165787
Validation loss: 2.6927924717953733

Epoch: 6| Step: 4
Training loss: 0.23323711102886283
Validation loss: 2.6254945622144894

Epoch: 6| Step: 5
Training loss: 0.2828331339142688
Validation loss: 2.7122133534237967

Epoch: 6| Step: 6
Training loss: 0.2914001049999488
Validation loss: 2.70313903863749

Epoch: 6| Step: 7
Training loss: 0.30363468304549535
Validation loss: 2.6612178795893193

Epoch: 6| Step: 8
Training loss: 0.2692751289531699
Validation loss: 2.6734185324225854

Epoch: 6| Step: 9
Training loss: 0.2008189652046579
Validation loss: 2.7139486982622043

Epoch: 6| Step: 10
Training loss: 0.2510558867615077
Validation loss: 2.717295304993776

Epoch: 6| Step: 11
Training loss: 0.2063261386468063
Validation loss: 2.687299735717662

Epoch: 6| Step: 12
Training loss: 0.17915013028133978
Validation loss: 2.661682049828849

Epoch: 6| Step: 13
Training loss: 0.28743962348457197
Validation loss: 2.694418761752538

Epoch: 494| Step: 0
Training loss: 0.25849976113675444
Validation loss: 2.624652271854142

Epoch: 6| Step: 1
Training loss: 0.31851136493617593
Validation loss: 2.6782284871318707

Epoch: 6| Step: 2
Training loss: 0.3175635190187985
Validation loss: 2.631864095807351

Epoch: 6| Step: 3
Training loss: 0.20720164466491925
Validation loss: 2.6642209748893895

Epoch: 6| Step: 4
Training loss: 0.3698762295526229
Validation loss: 2.6724581165796475

Epoch: 6| Step: 5
Training loss: 0.2990900275736417
Validation loss: 2.6245080698860295

Epoch: 6| Step: 6
Training loss: 0.258735032109393
Validation loss: 2.6783206816277336

Epoch: 6| Step: 7
Training loss: 0.3458686367748255
Validation loss: 2.67802977005012

Epoch: 6| Step: 8
Training loss: 0.2770256447910805
Validation loss: 2.7208626968022207

Epoch: 6| Step: 9
Training loss: 0.2711528153069522
Validation loss: 2.690116023098771

Epoch: 6| Step: 10
Training loss: 0.28537940086015795
Validation loss: 2.660866469373941

Epoch: 6| Step: 11
Training loss: 0.4308667905969976
Validation loss: 2.680065302634432

Epoch: 6| Step: 12
Training loss: 0.2420467767728183
Validation loss: 2.6828036785628706

Epoch: 6| Step: 13
Training loss: 0.23677365418558058
Validation loss: 2.6670016783642385

Epoch: 495| Step: 0
Training loss: 0.25138858268401837
Validation loss: 2.7040649793654583

Epoch: 6| Step: 1
Training loss: 0.342770122718542
Validation loss: 2.6669978939420447

Epoch: 6| Step: 2
Training loss: 0.3460677212470598
Validation loss: 2.671861168898092

Epoch: 6| Step: 3
Training loss: 0.30628623650707504
Validation loss: 2.703371951779475

Epoch: 6| Step: 4
Training loss: 0.32932882640402134
Validation loss: 2.666502475650825

Epoch: 6| Step: 5
Training loss: 0.2516320570748723
Validation loss: 2.662043338590034

Epoch: 6| Step: 6
Training loss: 0.33315487520116543
Validation loss: 2.686348069408022

Epoch: 6| Step: 7
Training loss: 0.36609769977778495
Validation loss: 2.6486101572476994

Epoch: 6| Step: 8
Training loss: 0.35653305019018144
Validation loss: 2.6966256006821023

Epoch: 6| Step: 9
Training loss: 0.22115398873648306
Validation loss: 2.710790873876232

Epoch: 6| Step: 10
Training loss: 0.23967814988023844
Validation loss: 2.7208342838918553

Epoch: 6| Step: 11
Training loss: 0.25534423628543557
Validation loss: 2.6800427808359895

Epoch: 6| Step: 12
Training loss: 0.28241364505326155
Validation loss: 2.712731609623035

Epoch: 6| Step: 13
Training loss: 0.3993180959455416
Validation loss: 2.71235468719854

Epoch: 496| Step: 0
Training loss: 0.20495475509622316
Validation loss: 2.6933084307438397

Epoch: 6| Step: 1
Training loss: 0.35355617227433267
Validation loss: 2.700210690813841

Epoch: 6| Step: 2
Training loss: 0.30394294438789643
Validation loss: 2.6409671870221048

Epoch: 6| Step: 3
Training loss: 0.33360363635169893
Validation loss: 2.738118978164461

Epoch: 6| Step: 4
Training loss: 0.23279351086588998
Validation loss: 2.6885788105159247

Epoch: 6| Step: 5
Training loss: 0.2983822207158469
Validation loss: 2.6733254108010316

Epoch: 6| Step: 6
Training loss: 0.31498626862600165
Validation loss: 2.6953064923058236

Epoch: 6| Step: 7
Training loss: 0.2007901635028292
Validation loss: 2.659175040186943

Epoch: 6| Step: 8
Training loss: 0.2178620470358228
Validation loss: 2.6785287010478602

Epoch: 6| Step: 9
Training loss: 0.281221123378559
Validation loss: 2.722447157884978

Epoch: 6| Step: 10
Training loss: 0.3078450040550661
Validation loss: 2.719912393774297

Epoch: 6| Step: 11
Training loss: 0.22903017653886315
Validation loss: 2.628144477412215

Epoch: 6| Step: 12
Training loss: 0.320901375941117
Validation loss: 2.6445564032165585

Epoch: 6| Step: 13
Training loss: 0.31665679054586815
Validation loss: 2.724897792777591

Epoch: 497| Step: 0
Training loss: 0.4344557364648905
Validation loss: 2.690929139862287

Epoch: 6| Step: 1
Training loss: 0.398865264448604
Validation loss: 2.690889512845331

Epoch: 6| Step: 2
Training loss: 0.21957483775252193
Validation loss: 2.67106751552454

Epoch: 6| Step: 3
Training loss: 0.2668853479027481
Validation loss: 2.642361523269931

Epoch: 6| Step: 4
Training loss: 0.24139863406516265
Validation loss: 2.6592165668539183

Epoch: 6| Step: 5
Training loss: 0.33777356187137214
Validation loss: 2.6562395880999983

Epoch: 6| Step: 6
Training loss: 0.41172287882810266
Validation loss: 2.6538021701710437

Epoch: 6| Step: 7
Training loss: 0.22021045384398083
Validation loss: 2.650557533130518

Epoch: 6| Step: 8
Training loss: 0.21833843444702442
Validation loss: 2.678768167082559

Epoch: 6| Step: 9
Training loss: 0.2936921153967231
Validation loss: 2.690588588372229

Epoch: 6| Step: 10
Training loss: 0.3793132994500845
Validation loss: 2.6976634953741527

Epoch: 6| Step: 11
Training loss: 0.2277916827979558
Validation loss: 2.7011100888857293

Epoch: 6| Step: 12
Training loss: 0.18093947990928622
Validation loss: 2.732591436077231

Epoch: 6| Step: 13
Training loss: 0.3250850685366356
Validation loss: 2.6879292817993305

Epoch: 498| Step: 0
Training loss: 0.2910068689859611
Validation loss: 2.7120329359533972

Epoch: 6| Step: 1
Training loss: 0.39353355937877815
Validation loss: 2.6226744492738088

Epoch: 6| Step: 2
Training loss: 0.3219140765163852
Validation loss: 2.698511850893307

Epoch: 6| Step: 3
Training loss: 0.22360469191547067
Validation loss: 2.6833397357777415

Epoch: 6| Step: 4
Training loss: 0.3314651824983607
Validation loss: 2.670489913317619

Epoch: 6| Step: 5
Training loss: 0.32023547572300165
Validation loss: 2.65811745316132

Epoch: 6| Step: 6
Training loss: 0.2985538395709023
Validation loss: 2.7101352468340023

Epoch: 6| Step: 7
Training loss: 0.28614055896467266
Validation loss: 2.707575124588931

Epoch: 6| Step: 8
Training loss: 0.21902006372228092
Validation loss: 2.637014806633296

Epoch: 6| Step: 9
Training loss: 0.3613920413010178
Validation loss: 2.657404076683309

Epoch: 6| Step: 10
Training loss: 0.2431724500933046
Validation loss: 2.6698323225263976

Epoch: 6| Step: 11
Training loss: 0.3057975477574063
Validation loss: 2.703966285460114

Epoch: 6| Step: 12
Training loss: 0.34447900458140673
Validation loss: 2.6455161337559083

Epoch: 6| Step: 13
Training loss: 0.3443474238097844
Validation loss: 2.6455542549871716

Epoch: 499| Step: 0
Training loss: 0.1985889089971254
Validation loss: 2.6540868590456657

Epoch: 6| Step: 1
Training loss: 0.24067962292787878
Validation loss: 2.6783853375415236

Epoch: 6| Step: 2
Training loss: 0.3289166618746968
Validation loss: 2.655410424482582

Epoch: 6| Step: 3
Training loss: 0.2990994686289065
Validation loss: 2.680652596611882

Epoch: 6| Step: 4
Training loss: 0.2737540728557814
Validation loss: 2.669787076325228

Epoch: 6| Step: 5
Training loss: 0.30765068235149623
Validation loss: 2.681288897773867

Epoch: 6| Step: 6
Training loss: 0.3153226806728627
Validation loss: 2.7180951378466163

Epoch: 6| Step: 7
Training loss: 0.23389016708348564
Validation loss: 2.7293415134903998

Epoch: 6| Step: 8
Training loss: 0.4275802787616392
Validation loss: 2.6353595310295113

Epoch: 6| Step: 9
Training loss: 0.23589501219408915
Validation loss: 2.7509049097167595

Epoch: 6| Step: 10
Training loss: 0.30687430158329754
Validation loss: 2.6483171073683778

Epoch: 6| Step: 11
Training loss: 0.2775369964887806
Validation loss: 2.634894720166382

Epoch: 6| Step: 12
Training loss: 0.444153733676521
Validation loss: 2.614492169091544

Epoch: 6| Step: 13
Training loss: 0.3565035837696882
Validation loss: 2.6762570294628327

Epoch: 500| Step: 0
Training loss: 0.30367624753213873
Validation loss: 2.6454135732011306

Epoch: 6| Step: 1
Training loss: 0.2963726662536278
Validation loss: 2.690212182347221

Epoch: 6| Step: 2
Training loss: 0.23681289041013293
Validation loss: 2.6342691076678477

Epoch: 6| Step: 3
Training loss: 0.26602574579869076
Validation loss: 2.6848209394091174

Epoch: 6| Step: 4
Training loss: 0.3505432931790572
Validation loss: 2.6614060866471316

Epoch: 6| Step: 5
Training loss: 0.38402177583895464
Validation loss: 2.66069765411865

Epoch: 6| Step: 6
Training loss: 0.3732178780440853
Validation loss: 2.6555912771797368

Epoch: 6| Step: 7
Training loss: 0.29478734465936557
Validation loss: 2.744704045460078

Epoch: 6| Step: 8
Training loss: 0.20967328971432708
Validation loss: 2.717518333810716

Epoch: 6| Step: 9
Training loss: 0.2636403948040696
Validation loss: 2.665628951540452

Epoch: 6| Step: 10
Training loss: 0.3279957062437303
Validation loss: 2.6825577440354254

Epoch: 6| Step: 11
Training loss: 0.32974893756822554
Validation loss: 2.71479063279403

Epoch: 6| Step: 12
Training loss: 0.3408072176715783
Validation loss: 2.7095788928101174

Epoch: 6| Step: 13
Training loss: 0.27023716411491183
Validation loss: 2.7450037566056804

Testing loss: 2.6452809137089175
