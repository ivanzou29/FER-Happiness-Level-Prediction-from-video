Epoch: 1| Step: 0
Training loss: 6.519192695617676
Validation loss: 5.671870667299778
Epoch: 5| Step: 1
Training loss: 5.861006736755371
Validation loss: 5.6679845405139515
Epoch: 5| Step: 2
Training loss: 5.563240051269531
Validation loss: 5.667275963927344
Epoch: 5| Step: 3
Training loss: 5.623037815093994
Validation loss: 5.66696638683621
Epoch: 5| Step: 4
Training loss: 6.387336730957031
Validation loss: 5.663487557884601
Epoch: 5| Step: 5
Training loss: 5.221662521362305
Validation loss: 5.661632939208325
Epoch: 5| Step: 6
Training loss: 5.630255699157715
Validation loss: 5.660152171155532
Epoch: 5| Step: 7
Training loss: 6.217748165130615
Validation loss: 5.661195158100814
Epoch: 5| Step: 8
Training loss: 5.18754768371582
Validation loss: 5.656955372515342
Epoch: 5| Step: 9
Training loss: 5.837218284606934
Validation loss: 5.655524319024395
Epoch: 2| Step: 0
Training loss: 5.465582847595215
Validation loss: 5.654298888693611
Epoch: 5| Step: 1
Training loss: 6.109373569488525
Validation loss: 5.6506160935052
Epoch: 5| Step: 2
Training loss: 5.109309196472168
Validation loss: 5.6499431767909645
Epoch: 5| Step: 3
Training loss: 5.114130973815918
Validation loss: 5.647075505565397
Epoch: 5| Step: 4
Training loss: 5.296324729919434
Validation loss: 5.646420485681767
Epoch: 5| Step: 5
Training loss: 5.959699630737305
Validation loss: 5.645873080054633
Epoch: 5| Step: 6
Training loss: 5.845696449279785
Validation loss: 5.641922871843517
Epoch: 5| Step: 7
Training loss: 6.657040596008301
Validation loss: 5.640916731717775
Epoch: 5| Step: 8
Training loss: 6.842266082763672
Validation loss: 5.638775575075218
Epoch: 5| Step: 9
Training loss: 5.482260704040527
Validation loss: 5.6376640436460645
Epoch: 3| Step: 0
Training loss: 6.679844856262207
Validation loss: 5.6356910904534425
Epoch: 5| Step: 1
Training loss: 5.629505157470703
Validation loss: 5.631059348154411
Epoch: 5| Step: 2
Training loss: 5.498042106628418
Validation loss: 5.62952154145824
Epoch: 5| Step: 3
Training loss: 5.511192321777344
Validation loss: 5.628324446918295
Epoch: 5| Step: 4
Training loss: 5.091928958892822
Validation loss: 5.626275957917138
Epoch: 5| Step: 5
Training loss: 5.939213752746582
Validation loss: 5.621679515289745
Epoch: 5| Step: 6
Training loss: 5.590301036834717
Validation loss: 5.621242571220123
Epoch: 5| Step: 7
Training loss: 5.652828216552734
Validation loss: 5.617033159132484
Epoch: 5| Step: 8
Training loss: 6.04323673248291
Validation loss: 5.616581141519889
Epoch: 5| Step: 9
Training loss: 6.044903755187988
Validation loss: 5.609993272548099
Epoch: 4| Step: 0
Training loss: 5.465604782104492
Validation loss: 5.608564929138843
Epoch: 5| Step: 1
Training loss: 5.363769054412842
Validation loss: 5.607932080467828
Epoch: 5| Step: 2
Training loss: 5.901256561279297
Validation loss: 5.605341949051232
Epoch: 5| Step: 3
Training loss: 5.312708377838135
Validation loss: 5.602796485955767
Epoch: 5| Step: 4
Training loss: 5.740762233734131
Validation loss: 5.597980015569454
Epoch: 5| Step: 5
Training loss: 5.993870735168457
Validation loss: 5.598756251575278
Epoch: 5| Step: 6
Training loss: 6.0590009689331055
Validation loss: 5.593162111241183
Epoch: 5| Step: 7
Training loss: 5.524943828582764
Validation loss: 5.59258110403157
Epoch: 5| Step: 8
Training loss: 5.6225385665893555
Validation loss: 5.586509100824809
Epoch: 5| Step: 9
Training loss: 6.459291458129883
Validation loss: 5.584380293921601
Epoch: 5| Step: 0
Training loss: 6.470401763916016
Validation loss: 5.582157189897496
Epoch: 5| Step: 1
Training loss: 5.906632423400879
Validation loss: 5.578333247479775
Epoch: 5| Step: 2
Training loss: 5.313778877258301
Validation loss: 5.572199382370324
Epoch: 5| Step: 3
Training loss: 5.376728057861328
Validation loss: 5.569766075491048
Epoch: 5| Step: 4
Training loss: 5.565075874328613
Validation loss: 5.565872532000645
Epoch: 5| Step: 5
Training loss: 5.955811500549316
Validation loss: 5.562809498190022
Epoch: 5| Step: 6
Training loss: 5.563647270202637
Validation loss: 5.561211222367321
Epoch: 5| Step: 7
Training loss: 5.858646869659424
Validation loss: 5.556251632223884
Epoch: 5| Step: 8
Training loss: 5.777464866638184
Validation loss: 5.550776217481215
Epoch: 5| Step: 9
Training loss: 5.3523712158203125
Validation loss: 5.548517357531211
Epoch: 6| Step: 0
Training loss: 5.89927864074707
Validation loss: 5.545521317626075
Epoch: 5| Step: 1
Training loss: 6.29384708404541
Validation loss: 5.536275146676482
Epoch: 5| Step: 2
Training loss: 5.866645336151123
Validation loss: 5.536694094431486
Epoch: 5| Step: 3
Training loss: 5.514149188995361
Validation loss: 5.536155861916302
Epoch: 5| Step: 4
Training loss: 5.0978546142578125
Validation loss: 5.527086782798492
Epoch: 5| Step: 5
Training loss: 6.662966251373291
Validation loss: 5.526501439458174
Epoch: 5| Step: 6
Training loss: 5.083984851837158
Validation loss: 5.520968416611925
Epoch: 5| Step: 7
Training loss: 5.812774658203125
Validation loss: 5.514592328517557
Epoch: 5| Step: 8
Training loss: 5.338730335235596
Validation loss: 5.512629430071056
Epoch: 5| Step: 9
Training loss: 5.199866771697998
Validation loss: 5.510131654121893
Epoch: 7| Step: 0
Training loss: 5.0833892822265625
Validation loss: 5.506015321333631
Epoch: 5| Step: 1
Training loss: 5.452659606933594
Validation loss: 5.497831011847627
Epoch: 5| Step: 2
Training loss: 5.3633623123168945
Validation loss: 5.492278795448138
Epoch: 5| Step: 3
Training loss: 5.8951568603515625
Validation loss: 5.491887747812614
Epoch: 5| Step: 4
Training loss: 5.714947700500488
Validation loss: 5.487134909458297
Epoch: 5| Step: 5
Training loss: 6.260393142700195
Validation loss: 5.480679831058859
Epoch: 5| Step: 6
Training loss: 5.652952194213867
Validation loss: 5.479717409010414
Epoch: 5| Step: 7
Training loss: 5.7723236083984375
Validation loss: 5.479038032696401
Epoch: 5| Step: 8
Training loss: 5.449091911315918
Validation loss: 5.473888880914921
Epoch: 5| Step: 9
Training loss: 5.70313835144043
Validation loss: 5.463690634254071
Epoch: 8| Step: 0
Training loss: 6.457642078399658
Validation loss: 5.4620815798533044
Epoch: 5| Step: 1
Training loss: 5.306634902954102
Validation loss: 5.457433690270074
Epoch: 5| Step: 2
Training loss: 5.397409439086914
Validation loss: 5.446622821066877
Epoch: 5| Step: 3
Training loss: 5.9226837158203125
Validation loss: 5.444148073951117
Epoch: 5| Step: 4
Training loss: 6.317717552185059
Validation loss: 5.441183786598041
Epoch: 5| Step: 5
Training loss: 5.174599647521973
Validation loss: 5.43464101132729
Epoch: 5| Step: 6
Training loss: 6.022547245025635
Validation loss: 5.433822594100623
Epoch: 5| Step: 7
Training loss: 4.8053083419799805
Validation loss: 5.425933669796951
Epoch: 5| Step: 8
Training loss: 5.4015350341796875
Validation loss: 5.420046840640281
Epoch: 5| Step: 9
Training loss: 5.09611701965332
Validation loss: 5.414552595975588
Epoch: 9| Step: 0
Training loss: 6.250461101531982
Validation loss: 5.409152473477151
Epoch: 5| Step: 1
Training loss: 6.446902275085449
Validation loss: 5.405545358177569
Epoch: 5| Step: 2
Training loss: 5.206977367401123
Validation loss: 5.397177898626533
Epoch: 5| Step: 3
Training loss: 5.03701114654541
Validation loss: 5.394280426793819
Epoch: 5| Step: 4
Training loss: 5.1054205894470215
Validation loss: 5.388566041164261
Epoch: 5| Step: 5
Training loss: 5.830350875854492
Validation loss: 5.382551251555518
Epoch: 5| Step: 6
Training loss: 5.840847969055176
Validation loss: 5.38044964838371
Epoch: 5| Step: 7
Training loss: 5.078739643096924
Validation loss: 5.368540564886958
Epoch: 5| Step: 8
Training loss: 5.048861980438232
Validation loss: 5.369184922828949
Epoch: 5| Step: 9
Training loss: 5.569161415100098
Validation loss: 5.361053408478662
Epoch: 10| Step: 0
Training loss: 5.950521945953369
Validation loss: 5.353581733840833
Epoch: 5| Step: 1
Training loss: 6.027772903442383
Validation loss: 5.351668364710087
Epoch: 5| Step: 2
Training loss: 4.895319938659668
Validation loss: 5.345852800410428
Epoch: 5| Step: 3
Training loss: 5.676519393920898
Validation loss: 5.344229873135793
Epoch: 5| Step: 4
Training loss: 6.1203508377075195
Validation loss: 5.330031343501249
Epoch: 5| Step: 5
Training loss: 5.114249229431152
Validation loss: 5.324532886203245
Epoch: 5| Step: 6
Training loss: 5.162891387939453
Validation loss: 5.316088827393895
Epoch: 5| Step: 7
Training loss: 5.99687385559082
Validation loss: 5.314349273983523
Epoch: 5| Step: 8
Training loss: 4.78116512298584
Validation loss: 5.314603417897396
Epoch: 5| Step: 9
Training loss: 5.1692352294921875
Validation loss: 5.303191363382682
Epoch: 11| Step: 0
Training loss: 5.2504072189331055
Validation loss: 5.2967567855505635
Epoch: 5| Step: 1
Training loss: 5.864317417144775
Validation loss: 5.288258765241225
Epoch: 5| Step: 2
Training loss: 5.736705780029297
Validation loss: 5.284076381930344
Epoch: 5| Step: 3
Training loss: 5.2269463539123535
Validation loss: 5.276917193433364
Epoch: 5| Step: 4
Training loss: 5.270644187927246
Validation loss: 5.272085875915966
Epoch: 5| Step: 5
Training loss: 5.572432994842529
Validation loss: 5.2647944079886235
Epoch: 5| Step: 6
Training loss: 5.769034385681152
Validation loss: 5.262385104199965
Epoch: 5| Step: 7
Training loss: 5.721089839935303
Validation loss: 5.2531931108708
Epoch: 5| Step: 8
Training loss: 4.651508331298828
Validation loss: 5.243760256458529
Epoch: 5| Step: 9
Training loss: 5.255882263183594
Validation loss: 5.2389584925534916
Epoch: 12| Step: 0
Training loss: 5.77686071395874
Validation loss: 5.235667863338113
Epoch: 5| Step: 1
Training loss: 5.293230056762695
Validation loss: 5.2207904582400975
Epoch: 5| Step: 2
Training loss: 4.968056678771973
Validation loss: 5.2205542454616625
Epoch: 5| Step: 3
Training loss: 5.628023147583008
Validation loss: 5.209398712185647
Epoch: 5| Step: 4
Training loss: 5.511991500854492
Validation loss: 5.207112113348872
Epoch: 5| Step: 5
Training loss: 4.923483848571777
Validation loss: 5.202087090169783
Epoch: 5| Step: 6
Training loss: 5.177743911743164
Validation loss: 5.191365266017777
Epoch: 5| Step: 7
Training loss: 5.999114990234375
Validation loss: 5.1886287490240965
Epoch: 5| Step: 8
Training loss: 5.0596160888671875
Validation loss: 5.17862853043371
Epoch: 5| Step: 9
Training loss: 5.336888790130615
Validation loss: 5.175588717563547
Epoch: 13| Step: 0
Training loss: 5.391368865966797
Validation loss: 5.164440161890263
Epoch: 5| Step: 1
Training loss: 5.139868259429932
Validation loss: 5.152198300944815
Epoch: 5| Step: 2
Training loss: 5.343357086181641
Validation loss: 5.149343590084597
Epoch: 5| Step: 3
Training loss: 5.643778324127197
Validation loss: 5.139455987395142
Epoch: 5| Step: 4
Training loss: 5.415525436401367
Validation loss: 5.136976221482531
Epoch: 5| Step: 5
Training loss: 5.021920204162598
Validation loss: 5.118374076678599
Epoch: 5| Step: 6
Training loss: 5.335221290588379
Validation loss: 5.120253827074449
Epoch: 5| Step: 7
Training loss: 5.266730308532715
Validation loss: 5.108925963477265
Epoch: 5| Step: 8
Training loss: 5.350654125213623
Validation loss: 5.105855996660192
Epoch: 5| Step: 9
Training loss: 5.056909084320068
Validation loss: 5.096338131444917
Epoch: 14| Step: 0
Training loss: 5.895288944244385
Validation loss: 5.0819306613730015
Epoch: 5| Step: 1
Training loss: 4.992132186889648
Validation loss: 5.074000612437296
Epoch: 5| Step: 2
Training loss: 5.552431106567383
Validation loss: 5.065023480559424
Epoch: 5| Step: 3
Training loss: 4.893152236938477
Validation loss: 5.061620352079543
Epoch: 5| Step: 4
Training loss: 4.9320807456970215
Validation loss: 5.041962781398416
Epoch: 5| Step: 5
Training loss: 5.559864044189453
Validation loss: 5.042514344771131
Epoch: 5| Step: 6
Training loss: 5.52284049987793
Validation loss: 5.031159109348874
Epoch: 5| Step: 7
Training loss: 4.932885646820068
Validation loss: 5.020345138988906
Epoch: 5| Step: 8
Training loss: 4.293023109436035
Validation loss: 5.015020181806825
Epoch: 5| Step: 9
Training loss: 5.642959117889404
Validation loss: 5.009080128704044
Epoch: 15| Step: 0
Training loss: 5.042613983154297
Validation loss: 4.9958955881406935
Epoch: 5| Step: 1
Training loss: 5.327531337738037
Validation loss: 4.977973330792763
Epoch: 5| Step: 2
Training loss: 4.941866874694824
Validation loss: 4.977736970503553
Epoch: 5| Step: 3
Training loss: 5.2688069343566895
Validation loss: 4.965910172290939
Epoch: 5| Step: 4
Training loss: 5.424337387084961
Validation loss: 4.954443475325331
Epoch: 5| Step: 5
Training loss: 4.76183557510376
Validation loss: 4.952163963866749
Epoch: 5| Step: 6
Training loss: 4.968247413635254
Validation loss: 4.932520365543502
Epoch: 5| Step: 7
Training loss: 4.565857887268066
Validation loss: 4.927908214733755
Epoch: 5| Step: 8
Training loss: 4.910105228424072
Validation loss: 4.915856701006993
Epoch: 5| Step: 9
Training loss: 6.1461639404296875
Validation loss: 4.909890819796555
Epoch: 16| Step: 0
Training loss: 4.947774887084961
Validation loss: 4.8981786528937254
Epoch: 5| Step: 1
Training loss: 5.78045654296875
Validation loss: 4.881492467235319
Epoch: 5| Step: 2
Training loss: 4.461082458496094
Validation loss: 4.8697823997881775
Epoch: 5| Step: 3
Training loss: 4.593589782714844
Validation loss: 4.863134627719577
Epoch: 5| Step: 4
Training loss: 5.1380438804626465
Validation loss: 4.850347717888921
Epoch: 5| Step: 5
Training loss: 5.961998462677002
Validation loss: 4.840603334440602
Epoch: 5| Step: 6
Training loss: 4.364885330200195
Validation loss: 4.82913089999192
Epoch: 5| Step: 7
Training loss: 4.7130560874938965
Validation loss: 4.822039501272517
Epoch: 5| Step: 8
Training loss: 5.445498466491699
Validation loss: 4.810616997506121
Epoch: 5| Step: 9
Training loss: 4.949014186859131
Validation loss: 4.805717951959843
Epoch: 17| Step: 0
Training loss: 4.559916019439697
Validation loss: 4.787479716239216
Epoch: 5| Step: 1
Training loss: 5.070168495178223
Validation loss: 4.769405059677234
Epoch: 5| Step: 2
Training loss: 4.7132439613342285
Validation loss: 4.76548774979955
Epoch: 5| Step: 3
Training loss: 5.636648654937744
Validation loss: 4.754192872013119
Epoch: 5| Step: 4
Training loss: 5.490139007568359
Validation loss: 4.746171151991371
Epoch: 5| Step: 5
Training loss: 4.721138000488281
Validation loss: 4.722853283230349
Epoch: 5| Step: 6
Training loss: 4.810055732727051
Validation loss: 4.710310922252188
Epoch: 5| Step: 7
Training loss: 4.686774730682373
Validation loss: 4.707745658407966
Epoch: 5| Step: 8
Training loss: 4.294890403747559
Validation loss: 4.6757612159783895
Epoch: 5| Step: 9
Training loss: 5.347400188446045
Validation loss: 4.666223803870112
Epoch: 18| Step: 0
Training loss: 5.91617488861084
Validation loss: 4.6645818545663955
Epoch: 5| Step: 1
Training loss: 5.098077297210693
Validation loss: 4.646197631204728
Epoch: 5| Step: 2
Training loss: 4.630295753479004
Validation loss: 4.634777091389937
Epoch: 5| Step: 3
Training loss: 4.709942817687988
Validation loss: 4.613040123054449
Epoch: 5| Step: 4
Training loss: 4.224519729614258
Validation loss: 4.596412888533777
Epoch: 5| Step: 5
Training loss: 4.571412563323975
Validation loss: 4.597416243107199
Epoch: 5| Step: 6
Training loss: 5.197283744812012
Validation loss: 4.579801545726309
Epoch: 5| Step: 7
Training loss: 5.331831932067871
Validation loss: 4.5610097466612896
Epoch: 5| Step: 8
Training loss: 4.736120223999023
Validation loss: 4.536820542040489
Epoch: 5| Step: 9
Training loss: 3.777047634124756
Validation loss: 4.53587703910663
Epoch: 19| Step: 0
Training loss: 4.550640106201172
Validation loss: 4.518372672924892
Epoch: 5| Step: 1
Training loss: 5.461545944213867
Validation loss: 4.498307605441526
Epoch: 5| Step: 2
Training loss: 4.553285598754883
Validation loss: 4.479822141661061
Epoch: 5| Step: 3
Training loss: 4.158779144287109
Validation loss: 4.4717703002819915
Epoch: 5| Step: 4
Training loss: 4.296966552734375
Validation loss: 4.458924022509898
Epoch: 5| Step: 5
Training loss: 4.842118740081787
Validation loss: 4.435483047430464
Epoch: 5| Step: 6
Training loss: 4.506659507751465
Validation loss: 4.422016826464976
Epoch: 5| Step: 7
Training loss: 4.827766418457031
Validation loss: 4.4064956397461374
Epoch: 5| Step: 8
Training loss: 4.605157852172852
Validation loss: 4.383976878022119
Epoch: 5| Step: 9
Training loss: 5.000374794006348
Validation loss: 4.373329124862342
Epoch: 20| Step: 0
Training loss: 4.627021789550781
Validation loss: 4.363358027643437
Epoch: 5| Step: 1
Training loss: 4.984352111816406
Validation loss: 4.34204803439353
Epoch: 5| Step: 2
Training loss: 3.963487148284912
Validation loss: 4.320895306498027
Epoch: 5| Step: 3
Training loss: 4.761998176574707
Validation loss: 4.298785322861706
Epoch: 5| Step: 4
Training loss: 4.7979865074157715
Validation loss: 4.272998257506665
Epoch: 5| Step: 5
Training loss: 4.7313666343688965
Validation loss: 4.2682303936361405
Epoch: 5| Step: 6
Training loss: 3.727966070175171
Validation loss: 4.242134896971339
Epoch: 5| Step: 7
Training loss: 4.448269844055176
Validation loss: 4.2265124869861195
Epoch: 5| Step: 8
Training loss: 4.514037132263184
Validation loss: 4.2160270248385645
Epoch: 5| Step: 9
Training loss: 4.682066917419434
Validation loss: 4.186042665577621
Epoch: 21| Step: 0
Training loss: 4.380252838134766
Validation loss: 4.17642856673371
Epoch: 5| Step: 1
Training loss: 4.9956512451171875
Validation loss: 4.158101702765595
Epoch: 5| Step: 2
Training loss: 4.0586090087890625
Validation loss: 4.144823064049371
Epoch: 5| Step: 3
Training loss: 4.667627334594727
Validation loss: 4.111117743759704
Epoch: 5| Step: 4
Training loss: 4.134450912475586
Validation loss: 4.079610855459309
Epoch: 5| Step: 5
Training loss: 4.689150810241699
Validation loss: 4.055545894362086
Epoch: 5| Step: 6
Training loss: 4.711803436279297
Validation loss: 4.054080357654489
Epoch: 5| Step: 7
Training loss: 3.762868642807007
Validation loss: 4.031871567527167
Epoch: 5| Step: 8
Training loss: 4.259293079376221
Validation loss: 4.008695935173858
Epoch: 5| Step: 9
Training loss: 4.022452354431152
Validation loss: 3.988134516228875
Epoch: 22| Step: 0
Training loss: 3.497091293334961
Validation loss: 3.9658979786385733
Epoch: 5| Step: 1
Training loss: 4.360725402832031
Validation loss: 3.9388679583295643
Epoch: 5| Step: 2
Training loss: 3.9427268505096436
Validation loss: 3.926398778133255
Epoch: 5| Step: 3
Training loss: 4.264983177185059
Validation loss: 3.9011310313245375
Epoch: 5| Step: 4
Training loss: 4.250199317932129
Validation loss: 3.8827778383982268
Epoch: 5| Step: 5
Training loss: 4.404735088348389
Validation loss: 3.846309720183448
Epoch: 5| Step: 6
Training loss: 4.131069183349609
Validation loss: 3.8370416353074766
Epoch: 5| Step: 7
Training loss: 4.353958606719971
Validation loss: 3.8049023923256415
Epoch: 5| Step: 8
Training loss: 4.514543533325195
Validation loss: 3.7879875015011795
Epoch: 5| Step: 9
Training loss: 4.19790506362915
Validation loss: 3.766603886652336
Epoch: 23| Step: 0
Training loss: 4.119865417480469
Validation loss: 3.7312493530108775
Epoch: 5| Step: 1
Training loss: 4.261181831359863
Validation loss: 3.702417202133069
Epoch: 5| Step: 2
Training loss: 4.673990726470947
Validation loss: 3.6757127295295113
Epoch: 5| Step: 3
Training loss: 3.517559051513672
Validation loss: 3.655520946859456
Epoch: 5| Step: 4
Training loss: 3.570162773132324
Validation loss: 3.6167448047253727
Epoch: 5| Step: 5
Training loss: 3.557987689971924
Validation loss: 3.6047058002554255
Epoch: 5| Step: 6
Training loss: 4.362050533294678
Validation loss: 3.5833627079888215
Epoch: 5| Step: 7
Training loss: 4.144518852233887
Validation loss: 3.5687684309568337
Epoch: 5| Step: 8
Training loss: 3.937912940979004
Validation loss: 3.5432237532499027
Epoch: 5| Step: 9
Training loss: 3.9589791297912598
Validation loss: 3.486854772773578
Epoch: 24| Step: 0
Training loss: 4.386721611022949
Validation loss: 3.488308719593844
Epoch: 5| Step: 1
Training loss: 3.203571319580078
Validation loss: 3.4808346916445725
Epoch: 5| Step: 2
Training loss: 3.8949131965637207
Validation loss: 3.4087057628219934
Epoch: 5| Step: 3
Training loss: 4.302048206329346
Validation loss: 3.3926657206720585
Epoch: 5| Step: 4
Training loss: 3.3496017456054688
Validation loss: 3.3652143392631477
Epoch: 5| Step: 5
Training loss: 3.831641674041748
Validation loss: 3.3551752910339574
Epoch: 5| Step: 6
Training loss: 3.436171531677246
Validation loss: 3.3333193483970147
Epoch: 5| Step: 7
Training loss: 3.85821795463562
Validation loss: 3.2885576752449968
Epoch: 5| Step: 8
Training loss: 3.9595696926116943
Validation loss: 3.2612580309668893
Epoch: 5| Step: 9
Training loss: 3.83135986328125
Validation loss: 3.225252326443899
Epoch: 25| Step: 0
Training loss: 3.3482494354248047
Validation loss: 3.218800109067409
Epoch: 5| Step: 1
Training loss: 3.1085939407348633
Validation loss: 3.1809564271419166
Epoch: 5| Step: 2
Training loss: 4.091198921203613
Validation loss: 3.1692623440310252
Epoch: 5| Step: 3
Training loss: 3.881103038787842
Validation loss: 3.1130498424708413
Epoch: 5| Step: 4
Training loss: 4.1969170570373535
Validation loss: 3.1017108289457913
Epoch: 5| Step: 5
Training loss: 3.5628175735473633
Validation loss: 3.062480159800687
Epoch: 5| Step: 6
Training loss: 2.9826855659484863
Validation loss: 3.0641503882922714
Epoch: 5| Step: 7
Training loss: 3.7267754077911377
Validation loss: 3.022981605941443
Epoch: 5| Step: 8
Training loss: 3.699812889099121
Validation loss: 2.9885860878786596
Epoch: 5| Step: 9
Training loss: 3.1708426475524902
Validation loss: 2.979416003330148
Epoch: 26| Step: 0
Training loss: 3.8007898330688477
Validation loss: 2.9762468423774773
Epoch: 5| Step: 1
Training loss: 3.3321375846862793
Validation loss: 2.9253547946326166
Epoch: 5| Step: 2
Training loss: 3.1836013793945312
Validation loss: 2.850419926128799
Epoch: 5| Step: 3
Training loss: 3.4031317234039307
Validation loss: 2.860245598305901
Epoch: 5| Step: 4
Training loss: 3.3990859985351562
Validation loss: 2.8257334712597966
Epoch: 5| Step: 5
Training loss: 3.083571434020996
Validation loss: 2.8106330247234097
Epoch: 5| Step: 6
Training loss: 3.638613224029541
Validation loss: 2.7575748138290517
Epoch: 5| Step: 7
Training loss: 3.7439370155334473
Validation loss: 2.7665190370820407
Epoch: 5| Step: 8
Training loss: 2.9365663528442383
Validation loss: 2.7260009916566257
Epoch: 5| Step: 9
Training loss: 3.084855079650879
Validation loss: 2.6450616026953826
Epoch: 27| Step: 0
Training loss: 3.525209903717041
Validation loss: 2.645740152262955
Epoch: 5| Step: 1
Training loss: 3.528167486190796
Validation loss: 2.6080697474719807
Epoch: 5| Step: 2
Training loss: 3.7116942405700684
Validation loss: 2.633998839975261
Epoch: 5| Step: 3
Training loss: 2.9680674076080322
Validation loss: 2.546641116519626
Epoch: 5| Step: 4
Training loss: 3.3262038230895996
Validation loss: 2.5557781243495805
Epoch: 5| Step: 5
Training loss: 2.827763080596924
Validation loss: 2.5326093546778177
Epoch: 5| Step: 6
Training loss: 2.5588622093200684
Validation loss: 2.473229032626255
Epoch: 5| Step: 7
Training loss: 2.562608242034912
Validation loss: 2.469515466003967
Epoch: 5| Step: 8
Training loss: 3.4723591804504395
Validation loss: 2.4505961593106496
Epoch: 5| Step: 9
Training loss: 3.051084280014038
Validation loss: 2.426576719009619
Epoch: 28| Step: 0
Training loss: 2.422203540802002
Validation loss: 2.3935197385952627
Epoch: 5| Step: 1
Training loss: 3.1904232501983643
Validation loss: 2.3801061026483987
Epoch: 5| Step: 2
Training loss: 2.544137954711914
Validation loss: 2.3497827962148103
Epoch: 5| Step: 3
Training loss: 3.13604474067688
Validation loss: 2.3330436584760816
Epoch: 5| Step: 4
Training loss: 2.9980931282043457
Validation loss: 2.2627736458675467
Epoch: 5| Step: 5
Training loss: 2.711906909942627
Validation loss: 2.248452642838732
Epoch: 5| Step: 6
Training loss: 3.2723631858825684
Validation loss: 2.2487712506767656
Epoch: 5| Step: 7
Training loss: 3.1631019115448
Validation loss: 2.2058505008546567
Epoch: 5| Step: 8
Training loss: 2.778028726577759
Validation loss: 2.2524337854316765
Epoch: 5| Step: 9
Training loss: 2.7735981941223145
Validation loss: 2.153494634216638
Epoch: 29| Step: 0
Training loss: 2.1978626251220703
Validation loss: 2.1420856431233797
Epoch: 5| Step: 1
Training loss: 2.6032333374023438
Validation loss: 2.1261825287084783
Epoch: 5| Step: 2
Training loss: 3.046633720397949
Validation loss: 2.1325581296742393
Epoch: 5| Step: 3
Training loss: 2.8094918727874756
Validation loss: 2.0894043274063
Epoch: 5| Step: 4
Training loss: 2.3544561862945557
Validation loss: 2.069174848872123
Epoch: 5| Step: 5
Training loss: 2.7566800117492676
Validation loss: 2.056179573210023
Epoch: 5| Step: 6
Training loss: 2.5567545890808105
Validation loss: 2.0272807628988363
Epoch: 5| Step: 7
Training loss: 3.029024124145508
Validation loss: 1.9864448411859197
Epoch: 5| Step: 8
Training loss: 2.829758644104004
Validation loss: 1.9817531023094122
Epoch: 5| Step: 9
Training loss: 2.810072898864746
Validation loss: 2.026054360026078
Epoch: 30| Step: 0
Training loss: 2.4417123794555664
Validation loss: 1.9687480480550863
Epoch: 5| Step: 1
Training loss: 2.6679553985595703
Validation loss: 1.92743147362908
Epoch: 5| Step: 2
Training loss: 2.5469799041748047
Validation loss: 1.9416477405767647
Epoch: 5| Step: 3
Training loss: 2.615805149078369
Validation loss: 1.8863856037743658
Epoch: 5| Step: 4
Training loss: 2.627436637878418
Validation loss: 1.8776688112629403
Epoch: 5| Step: 5
Training loss: 2.538112163543701
Validation loss: 1.9180387472934861
Epoch: 5| Step: 6
Training loss: 2.353727340698242
Validation loss: 1.888003475374455
Epoch: 5| Step: 7
Training loss: 2.4651384353637695
Validation loss: 1.8788341292374426
Epoch: 5| Step: 8
Training loss: 2.4304921627044678
Validation loss: 1.8615336538218765
Epoch: 5| Step: 9
Training loss: 2.5666489601135254
Validation loss: 1.8353271741661237
Epoch: 31| Step: 0
Training loss: 2.1337668895721436
Validation loss: 1.837189384501615
Epoch: 5| Step: 1
Training loss: 2.0970280170440674
Validation loss: 1.8188021783348467
Epoch: 5| Step: 2
Training loss: 2.383937120437622
Validation loss: 1.8536721099194864
Epoch: 5| Step: 3
Training loss: 2.213878631591797
Validation loss: 1.847436036994989
Epoch: 5| Step: 4
Training loss: 2.3076539039611816
Validation loss: 1.7993840579506304
Epoch: 5| Step: 5
Training loss: 2.936535358428955
Validation loss: 1.7401272024182106
Epoch: 5| Step: 6
Training loss: 2.8331971168518066
Validation loss: 1.7764525636494588
Epoch: 5| Step: 7
Training loss: 2.1960949897766113
Validation loss: 1.7787830366505135
Epoch: 5| Step: 8
Training loss: 2.309720993041992
Validation loss: 1.8058675446098658
Epoch: 5| Step: 9
Training loss: 2.3955588340759277
Validation loss: 1.8144289460971201
Epoch: 32| Step: 0
Training loss: 2.263760805130005
Validation loss: 1.7601233060411412
Epoch: 5| Step: 1
Training loss: 2.135812997817993
Validation loss: 1.7684017574186806
Epoch: 5| Step: 2
Training loss: 2.507652759552002
Validation loss: 1.8059678146307416
Epoch: 5| Step: 3
Training loss: 2.504189968109131
Validation loss: 1.8424994619630224
Epoch: 5| Step: 4
Training loss: 2.730238437652588
Validation loss: 1.7677776856388119
Epoch: 5| Step: 5
Training loss: 2.423470973968506
Validation loss: 1.7386125986524623
Epoch: 5| Step: 6
Training loss: 2.097107172012329
Validation loss: 1.8353639549488643
Epoch: 5| Step: 7
Training loss: 2.221484661102295
Validation loss: 1.7889786598493727
Epoch: 5| Step: 8
Training loss: 2.0014610290527344
Validation loss: 1.76797431492977
Epoch: 5| Step: 9
Training loss: 1.7406169176101685
Validation loss: 1.7684156062791674
Epoch: 33| Step: 0
Training loss: 2.0853755474090576
Validation loss: 1.8028834929569162
Epoch: 5| Step: 1
Training loss: 2.6304826736450195
Validation loss: 1.819710304411195
Epoch: 5| Step: 2
Training loss: 2.2135229110717773
Validation loss: 1.78301659162096
Epoch: 5| Step: 3
Training loss: 2.254493236541748
Validation loss: 1.8658601397233043
Epoch: 5| Step: 4
Training loss: 2.284292459487915
Validation loss: 1.7992388207277805
Epoch: 5| Step: 5
Training loss: 1.9179872274398804
Validation loss: 1.8269829801518283
Epoch: 5| Step: 6
Training loss: 1.7141050100326538
Validation loss: 1.8117266035766053
Epoch: 5| Step: 7
Training loss: 2.704000473022461
Validation loss: 1.8590397423119853
Epoch: 5| Step: 8
Training loss: 2.306896448135376
Validation loss: 1.8438907329984706
Epoch: 5| Step: 9
Training loss: 2.008298873901367
Validation loss: 1.8839551047455492
Epoch: 34| Step: 0
Training loss: 1.6992061138153076
Validation loss: 1.8858977581957261
Epoch: 5| Step: 1
Training loss: 1.7788126468658447
Validation loss: 1.8483040255608318
Epoch: 5| Step: 2
Training loss: 2.41239857673645
Validation loss: 1.8805655927109204
Epoch: 5| Step: 3
Training loss: 2.6232399940490723
Validation loss: 1.8859067795087965
Epoch: 5| Step: 4
Training loss: 2.4898133277893066
Validation loss: 1.9599584624064055
Epoch: 5| Step: 5
Training loss: 2.1320767402648926
Validation loss: 1.9181626820735793
Epoch: 5| Step: 6
Training loss: 2.3560051918029785
Validation loss: 1.8780794057914678
Epoch: 5| Step: 7
Training loss: 1.9195749759674072
Validation loss: 1.9310995074484845
Epoch: 5| Step: 8
Training loss: 2.3869426250457764
Validation loss: 1.8845324722125376
Epoch: 5| Step: 9
Training loss: 2.3750996589660645
Validation loss: 1.8655828331871855
Epoch: 35| Step: 0
Training loss: 2.04561448097229
Validation loss: 1.8602966293156575
Epoch: 5| Step: 1
Training loss: 2.3218002319335938
Validation loss: 1.8883093458285434
Epoch: 5| Step: 2
Training loss: 2.1812009811401367
Validation loss: 1.880616444477932
Epoch: 5| Step: 3
Training loss: 2.0401971340179443
Validation loss: 1.8919692485452555
Epoch: 5| Step: 4
Training loss: 2.6346588134765625
Validation loss: 1.8981553118863552
Epoch: 5| Step: 5
Training loss: 2.241626262664795
Validation loss: 1.8962411820459708
Epoch: 5| Step: 6
Training loss: 2.6312050819396973
Validation loss: 1.9012157925598914
Epoch: 5| Step: 7
Training loss: 2.3166966438293457
Validation loss: 1.9124245686496761
Epoch: 5| Step: 8
Training loss: 1.9220339059829712
Validation loss: 1.9211779824263757
Epoch: 5| Step: 9
Training loss: 1.792868971824646
Validation loss: 1.828342893140779
Epoch: 36| Step: 0
Training loss: 2.0183119773864746
Validation loss: 1.8762065326567177
Epoch: 5| Step: 1
Training loss: 2.001356363296509
Validation loss: 1.8933373904056687
Epoch: 5| Step: 2
Training loss: 2.286792755126953
Validation loss: 1.8793969300153444
Epoch: 5| Step: 3
Training loss: 2.1832876205444336
Validation loss: 1.863266770788234
Epoch: 5| Step: 4
Training loss: 1.511448621749878
Validation loss: 1.8578089964475564
Epoch: 5| Step: 5
Training loss: 2.255795955657959
Validation loss: 1.8842021561355042
Epoch: 5| Step: 6
Training loss: 2.234414577484131
Validation loss: 1.898170544946794
Epoch: 5| Step: 7
Training loss: 2.353949785232544
Validation loss: 1.8854899269213778
Epoch: 5| Step: 8
Training loss: 2.570857048034668
Validation loss: 1.8740608709321604
Epoch: 5| Step: 9
Training loss: 2.455460548400879
Validation loss: 1.8832763339118135
Epoch: 37| Step: 0
Training loss: 2.572075843811035
Validation loss: 1.9076428456272152
Epoch: 5| Step: 1
Training loss: 2.1392226219177246
Validation loss: 1.8836267251762555
Epoch: 5| Step: 2
Training loss: 2.090968608856201
Validation loss: 1.8617675724647027
Epoch: 5| Step: 3
Training loss: 2.135761260986328
Validation loss: 1.8943632283656717
Epoch: 5| Step: 4
Training loss: 1.8183300495147705
Validation loss: 1.8474867069463936
Epoch: 5| Step: 5
Training loss: 2.0006892681121826
Validation loss: 1.8492256145683124
Epoch: 5| Step: 6
Training loss: 2.3121423721313477
Validation loss: 1.900387880613478
Epoch: 5| Step: 7
Training loss: 2.0229859352111816
Validation loss: 1.9037920245163733
Epoch: 5| Step: 8
Training loss: 2.466338634490967
Validation loss: 1.9169592299907328
Epoch: 5| Step: 9
Training loss: 2.4150490760803223
Validation loss: 1.923113817791287
Epoch: 38| Step: 0
Training loss: 2.332080602645874
Validation loss: 1.910962478720027
Epoch: 5| Step: 1
Training loss: 1.9720423221588135
Validation loss: 1.913319759231677
Epoch: 5| Step: 2
Training loss: 1.9921720027923584
Validation loss: 1.8520207722410023
Epoch: 5| Step: 3
Training loss: 2.3294425010681152
Validation loss: 1.9248378516958773
Epoch: 5| Step: 4
Training loss: 2.0182862281799316
Validation loss: 1.9244451951637542
Epoch: 5| Step: 5
Training loss: 2.335019111633301
Validation loss: 1.9172010533243633
Epoch: 5| Step: 6
Training loss: 2.3768937587738037
Validation loss: 1.8794942245208959
Epoch: 5| Step: 7
Training loss: 2.404021739959717
Validation loss: 1.8994221515792737
Epoch: 5| Step: 8
Training loss: 1.9810781478881836
Validation loss: 1.888315108182619
Epoch: 5| Step: 9
Training loss: 2.4172396659851074
Validation loss: 1.9572467083553615
Epoch: 39| Step: 0
Training loss: 2.187648296356201
Validation loss: 1.9223619759511605
Epoch: 5| Step: 1
Training loss: 2.330678701400757
Validation loss: 1.9109284517576368
Epoch: 5| Step: 2
Training loss: 1.961269497871399
Validation loss: 1.8942073043301808
Epoch: 5| Step: 3
Training loss: 1.990404725074768
Validation loss: 1.8998500211633367
Epoch: 5| Step: 4
Training loss: 2.1776890754699707
Validation loss: 1.9081197642593932
Epoch: 5| Step: 5
Training loss: 2.6206631660461426
Validation loss: 1.9277981691223254
Epoch: 5| Step: 6
Training loss: 2.3999903202056885
Validation loss: 1.9572200637927157
Epoch: 5| Step: 7
Training loss: 2.261570930480957
Validation loss: 1.9230324707442907
Epoch: 5| Step: 8
Training loss: 1.8053388595581055
Validation loss: 1.9433111818574316
Epoch: 5| Step: 9
Training loss: 2.556154727935791
Validation loss: 1.8865135522197476
Epoch: 40| Step: 0
Training loss: 2.498227596282959
Validation loss: 1.8826004695549285
Epoch: 5| Step: 1
Training loss: 1.7309552431106567
Validation loss: 1.8885518526859422
Epoch: 5| Step: 2
Training loss: 2.1775126457214355
Validation loss: 1.8816940715844683
Epoch: 5| Step: 3
Training loss: 2.182089328765869
Validation loss: 1.9108034964088056
Epoch: 5| Step: 4
Training loss: 1.9819128513336182
Validation loss: 1.8765005662286882
Epoch: 5| Step: 5
Training loss: 2.6980247497558594
Validation loss: 1.8854880856095457
Epoch: 5| Step: 6
Training loss: 2.3983235359191895
Validation loss: 1.9032393505247376
Epoch: 5| Step: 7
Training loss: 2.2504844665527344
Validation loss: 1.948162046267832
Epoch: 5| Step: 8
Training loss: 2.0232882499694824
Validation loss: 1.9298583620743786
Epoch: 5| Step: 9
Training loss: 1.8917899131774902
Validation loss: 1.877515969516562
Epoch: 41| Step: 0
Training loss: 1.9544281959533691
Validation loss: 1.8810908785826868
Epoch: 5| Step: 1
Training loss: 2.945202112197876
Validation loss: 1.879031307405705
Epoch: 5| Step: 2
Training loss: 2.0332064628601074
Validation loss: 1.8733402705021043
Epoch: 5| Step: 3
Training loss: 1.996882438659668
Validation loss: 1.8976784712976689
Epoch: 5| Step: 4
Training loss: 2.2250001430511475
Validation loss: 1.9322718956487641
Epoch: 5| Step: 5
Training loss: 1.925054907798767
Validation loss: 1.8861658967656196
Epoch: 5| Step: 6
Training loss: 2.161731243133545
Validation loss: 1.9433469017632574
Epoch: 5| Step: 7
Training loss: 2.095099925994873
Validation loss: 1.874544900098293
Epoch: 5| Step: 8
Training loss: 2.3088245391845703
Validation loss: 1.9255661304048497
Epoch: 5| Step: 9
Training loss: 2.270061492919922
Validation loss: 1.9392974342373634
Epoch: 42| Step: 0
Training loss: 2.6610684394836426
Validation loss: 1.8934365262230524
Epoch: 5| Step: 1
Training loss: 2.569521188735962
Validation loss: 1.92043880764529
Epoch: 5| Step: 2
Training loss: 2.2659878730773926
Validation loss: 1.9210298567367114
Epoch: 5| Step: 3
Training loss: 2.246196746826172
Validation loss: 1.9128574690372824
Epoch: 5| Step: 4
Training loss: 1.8092447519302368
Validation loss: 1.8963518923135112
Epoch: 5| Step: 5
Training loss: 1.6724798679351807
Validation loss: 1.8543278502045775
Epoch: 5| Step: 6
Training loss: 1.7211284637451172
Validation loss: 1.869349167501326
Epoch: 5| Step: 7
Training loss: 1.8659141063690186
Validation loss: 1.8971760427351478
Epoch: 5| Step: 8
Training loss: 2.59379243850708
Validation loss: 1.9022963698819386
Epoch: 5| Step: 9
Training loss: 2.5675816535949707
Validation loss: 1.9103676003517864
Epoch: 43| Step: 0
Training loss: 1.9253158569335938
Validation loss: 1.9242322496373019
Epoch: 5| Step: 1
Training loss: 2.214763879776001
Validation loss: 1.9165038213455419
Epoch: 5| Step: 2
Training loss: 2.0756964683532715
Validation loss: 1.925920519897406
Epoch: 5| Step: 3
Training loss: 2.25846004486084
Validation loss: 1.9455504434571849
Epoch: 5| Step: 4
Training loss: 1.693223476409912
Validation loss: 1.8837074324381438
Epoch: 5| Step: 5
Training loss: 2.493410110473633
Validation loss: 1.9374149420278535
Epoch: 5| Step: 6
Training loss: 2.3477091789245605
Validation loss: 1.9098250076925154
Epoch: 5| Step: 7
Training loss: 2.18123197555542
Validation loss: 1.863596707796879
Epoch: 5| Step: 8
Training loss: 2.338766098022461
Validation loss: 1.9083978829623984
Epoch: 5| Step: 9
Training loss: 2.268832206726074
Validation loss: 1.9234488902332114
Epoch: 44| Step: 0
Training loss: 1.978034496307373
Validation loss: 1.9348356217789136
Epoch: 5| Step: 1
Training loss: 1.9443200826644897
Validation loss: 1.9257124568061006
Epoch: 5| Step: 2
Training loss: 2.391111135482788
Validation loss: 1.8906739993061092
Epoch: 5| Step: 3
Training loss: 2.002054214477539
Validation loss: 1.8725513099766464
Epoch: 5| Step: 4
Training loss: 2.4206290245056152
Validation loss: 1.9404383100194038
Epoch: 5| Step: 5
Training loss: 2.0494914054870605
Validation loss: 1.8682838266702007
Epoch: 5| Step: 6
Training loss: 2.138566255569458
Validation loss: 1.888731744649599
Epoch: 5| Step: 7
Training loss: 2.2627410888671875
Validation loss: 1.9156906055889542
Epoch: 5| Step: 8
Training loss: 2.345492362976074
Validation loss: 1.8808923470888206
Epoch: 5| Step: 9
Training loss: 2.264599323272705
Validation loss: 1.87182945827786
Epoch: 45| Step: 0
Training loss: 1.9009701013565063
Validation loss: 1.8376730826261232
Epoch: 5| Step: 1
Training loss: 2.3556008338928223
Validation loss: 1.905851708899299
Epoch: 5| Step: 2
Training loss: 2.024641990661621
Validation loss: 1.8763358404310486
Epoch: 5| Step: 3
Training loss: 2.0734360218048096
Validation loss: 1.9086522781591622
Epoch: 5| Step: 4
Training loss: 1.88509202003479
Validation loss: 1.9084930162635638
Epoch: 5| Step: 5
Training loss: 2.4375948905944824
Validation loss: 1.8882207287301263
Epoch: 5| Step: 6
Training loss: 2.1482162475585938
Validation loss: 1.8662105738687857
Epoch: 5| Step: 7
Training loss: 2.50069522857666
Validation loss: 1.9108480798254768
Epoch: 5| Step: 8
Training loss: 1.9973750114440918
Validation loss: 1.8601799808817803
Epoch: 5| Step: 9
Training loss: 2.5707950592041016
Validation loss: 1.8836835168248458
Epoch: 46| Step: 0
Training loss: 1.9159774780273438
Validation loss: 1.8870800879361818
Epoch: 5| Step: 1
Training loss: 2.4195377826690674
Validation loss: 1.9039065975079434
Epoch: 5| Step: 2
Training loss: 2.062915802001953
Validation loss: 1.8624666165962493
Epoch: 5| Step: 3
Training loss: 2.1518497467041016
Validation loss: 1.8680858852194369
Epoch: 5| Step: 4
Training loss: 2.1053617000579834
Validation loss: 1.8915501464185098
Epoch: 5| Step: 5
Training loss: 2.1344029903411865
Validation loss: 1.9034198582601205
Epoch: 5| Step: 6
Training loss: 1.7587553262710571
Validation loss: 1.8918518394017392
Epoch: 5| Step: 7
Training loss: 1.8334214687347412
Validation loss: 1.8884735390436735
Epoch: 5| Step: 8
Training loss: 2.9855494499206543
Validation loss: 1.8828395390682082
Epoch: 5| Step: 9
Training loss: 2.0448155403137207
Validation loss: 1.9104079745656295
Epoch: 47| Step: 0
Training loss: 2.0105061531066895
Validation loss: 1.8609747629371478
Epoch: 5| Step: 1
Training loss: 1.6178337335586548
Validation loss: 1.870340497373677
Epoch: 5| Step: 2
Training loss: 2.2386937141418457
Validation loss: 1.8130295551080498
Epoch: 5| Step: 3
Training loss: 2.0293338298797607
Validation loss: 1.822147489451676
Epoch: 5| Step: 4
Training loss: 1.7131160497665405
Validation loss: 1.8749425977254086
Epoch: 5| Step: 5
Training loss: 2.667917251586914
Validation loss: 1.8638360620402603
Epoch: 5| Step: 6
Training loss: 2.530569076538086
Validation loss: 1.8787106815859569
Epoch: 5| Step: 7
Training loss: 2.023587226867676
Validation loss: 1.8163502610844673
Epoch: 5| Step: 8
Training loss: 1.8950345516204834
Validation loss: 1.8767736935787063
Epoch: 5| Step: 9
Training loss: 2.845442295074463
Validation loss: 1.864519914277166
Epoch: 48| Step: 0
Training loss: 1.8250620365142822
Validation loss: 1.8805606073612788
Epoch: 5| Step: 1
Training loss: 2.4067442417144775
Validation loss: 1.886651472222033
Epoch: 5| Step: 2
Training loss: 2.442997932434082
Validation loss: 1.9281588749919865
Epoch: 5| Step: 3
Training loss: 2.221282958984375
Validation loss: 1.8830481184472283
Epoch: 5| Step: 4
Training loss: 2.0873031616210938
Validation loss: 1.8627977628502057
Epoch: 5| Step: 5
Training loss: 2.047617197036743
Validation loss: 1.907587312108321
Epoch: 5| Step: 6
Training loss: 2.152519702911377
Validation loss: 1.853432811421456
Epoch: 5| Step: 7
Training loss: 1.868837833404541
Validation loss: 1.8851218635229756
Epoch: 5| Step: 8
Training loss: 2.308073043823242
Validation loss: 1.8221470160450008
Epoch: 5| Step: 9
Training loss: 2.4829659461975098
Validation loss: 1.888530289526466
Epoch: 49| Step: 0
Training loss: 2.381408214569092
Validation loss: 1.8596969199695175
Epoch: 5| Step: 1
Training loss: 2.317161798477173
Validation loss: 1.8682749820270126
Epoch: 5| Step: 2
Training loss: 2.4701647758483887
Validation loss: 1.8255941439017975
Epoch: 5| Step: 3
Training loss: 1.8702969551086426
Validation loss: 1.8800770198698524
Epoch: 5| Step: 4
Training loss: 1.8993597030639648
Validation loss: 1.8537963294296813
Epoch: 5| Step: 5
Training loss: 2.065462350845337
Validation loss: 1.8730647435291208
Epoch: 5| Step: 6
Training loss: 2.160400867462158
Validation loss: 1.8328343878547064
Epoch: 5| Step: 7
Training loss: 2.350989580154419
Validation loss: 1.8789205945653022
Epoch: 5| Step: 8
Training loss: 1.711172103881836
Validation loss: 1.8875899949519754
Epoch: 5| Step: 9
Training loss: 2.528189182281494
Validation loss: 1.8668553554754463
Epoch: 50| Step: 0
Training loss: 1.8188080787658691
Validation loss: 1.8431886820484409
Epoch: 5| Step: 1
Training loss: 2.3224503993988037
Validation loss: 1.87406764956687
Epoch: 5| Step: 2
Training loss: 1.8279573917388916
Validation loss: 1.8613244603863723
Epoch: 5| Step: 3
Training loss: 1.9611635208129883
Validation loss: 1.8720407914772308
Epoch: 5| Step: 4
Training loss: 2.2590231895446777
Validation loss: 1.7989455229944462
Epoch: 5| Step: 5
Training loss: 2.6057872772216797
Validation loss: 1.8526154696512565
Epoch: 5| Step: 6
Training loss: 2.3055613040924072
Validation loss: 1.8795784283027375
Epoch: 5| Step: 7
Training loss: 1.8532929420471191
Validation loss: 1.8397836273522685
Epoch: 5| Step: 8
Training loss: 2.4701147079467773
Validation loss: 1.8704499237828975
Epoch: 5| Step: 9
Training loss: 2.2277262210845947
Validation loss: 1.8786260738647242
Epoch: 51| Step: 0
Training loss: 1.7859761714935303
Validation loss: 1.8941675604676171
Epoch: 5| Step: 1
Training loss: 2.2464261054992676
Validation loss: 1.8962693969122797
Epoch: 5| Step: 2
Training loss: 2.302644968032837
Validation loss: 1.8434921134290079
Epoch: 5| Step: 3
Training loss: 2.829251289367676
Validation loss: 1.8662038312541496
Epoch: 5| Step: 4
Training loss: 2.2724411487579346
Validation loss: 1.9149035515545083
Epoch: 5| Step: 5
Training loss: 2.0314788818359375
Validation loss: 1.8701287430824993
Epoch: 5| Step: 6
Training loss: 2.0659682750701904
Validation loss: 1.9094025548413502
Epoch: 5| Step: 7
Training loss: 2.299376964569092
Validation loss: 1.883828064520582
Epoch: 5| Step: 8
Training loss: 2.012631893157959
Validation loss: 1.878605413779938
Epoch: 5| Step: 9
Training loss: 2.050448417663574
Validation loss: 1.8704038987056815
Epoch: 52| Step: 0
Training loss: 2.1546597480773926
Validation loss: 1.866062604266105
Epoch: 5| Step: 1
Training loss: 1.9158313274383545
Validation loss: 1.880491933376669
Epoch: 5| Step: 2
Training loss: 2.1298913955688477
Validation loss: 1.8691800120923159
Epoch: 5| Step: 3
Training loss: 2.105417490005493
Validation loss: 1.8987284778691025
Epoch: 5| Step: 4
Training loss: 1.6965681314468384
Validation loss: 1.8584091817732338
Epoch: 5| Step: 5
Training loss: 2.213456630706787
Validation loss: 1.820923576252066
Epoch: 5| Step: 6
Training loss: 2.0004563331604004
Validation loss: 1.8854976892471313
Epoch: 5| Step: 7
Training loss: 2.2711493968963623
Validation loss: 1.8931310648540798
Epoch: 5| Step: 8
Training loss: 2.3385825157165527
Validation loss: 1.8748485467416778
Epoch: 5| Step: 9
Training loss: 2.810708522796631
Validation loss: 1.836006497307647
Epoch: 53| Step: 0
Training loss: 2.3501663208007812
Validation loss: 1.912729506869968
Epoch: 5| Step: 1
Training loss: 2.2479875087738037
Validation loss: 1.854668058937402
Epoch: 5| Step: 2
Training loss: 2.263652801513672
Validation loss: 1.9133985145486516
Epoch: 5| Step: 3
Training loss: 1.859748125076294
Validation loss: 1.9268141024404293
Epoch: 5| Step: 4
Training loss: 1.9161064624786377
Validation loss: 1.8795316939731297
Epoch: 5| Step: 5
Training loss: 2.7741451263427734
Validation loss: 1.8518783857496521
Epoch: 5| Step: 6
Training loss: 2.6215696334838867
Validation loss: 1.8975086495173064
Epoch: 5| Step: 7
Training loss: 1.8485229015350342
Validation loss: 1.8583445892059545
Epoch: 5| Step: 8
Training loss: 1.4613072872161865
Validation loss: 1.9361805778613193
Epoch: 5| Step: 9
Training loss: 2.343740463256836
Validation loss: 1.860989273880883
Epoch: 54| Step: 0
Training loss: 2.3183369636535645
Validation loss: 1.8709157722459422
Epoch: 5| Step: 1
Training loss: 2.263237953186035
Validation loss: 1.8731744795394458
Epoch: 5| Step: 2
Training loss: 2.0541720390319824
Validation loss: 1.915735838224562
Epoch: 5| Step: 3
Training loss: 2.008002758026123
Validation loss: 1.850118729708006
Epoch: 5| Step: 4
Training loss: 2.2294058799743652
Validation loss: 1.83641988339184
Epoch: 5| Step: 5
Training loss: 2.2603373527526855
Validation loss: 1.9621914427915066
Epoch: 5| Step: 6
Training loss: 2.2286415100097656
Validation loss: 1.904598496800704
Epoch: 5| Step: 7
Training loss: 2.411111831665039
Validation loss: 1.896218695228906
Epoch: 5| Step: 8
Training loss: 2.1836962699890137
Validation loss: 1.9162905567841564
Epoch: 5| Step: 9
Training loss: 1.5840561389923096
Validation loss: 1.9238109408522681
Epoch: 55| Step: 0
Training loss: 2.0681324005126953
Validation loss: 1.907297455149589
Epoch: 5| Step: 1
Training loss: 2.2235097885131836
Validation loss: 1.8471656840482205
Epoch: 5| Step: 2
Training loss: 2.044424295425415
Validation loss: 1.8923503203357723
Epoch: 5| Step: 3
Training loss: 2.4636197090148926
Validation loss: 1.94665373915391
Epoch: 5| Step: 4
Training loss: 2.3490419387817383
Validation loss: 1.9277416587733536
Epoch: 5| Step: 5
Training loss: 2.111082077026367
Validation loss: 1.9002699303112442
Epoch: 5| Step: 6
Training loss: 1.7051548957824707
Validation loss: 1.8986266474072024
Epoch: 5| Step: 7
Training loss: 2.412454128265381
Validation loss: 1.9250678724522212
Epoch: 5| Step: 8
Training loss: 1.74234938621521
Validation loss: 1.8880479232870417
Epoch: 5| Step: 9
Training loss: 2.6482291221618652
Validation loss: 1.9225045622681542
Epoch: 56| Step: 0
Training loss: 2.3999924659729004
Validation loss: 1.9049630388081502
Epoch: 5| Step: 1
Training loss: 2.3269758224487305
Validation loss: 1.9386975936752429
Epoch: 5| Step: 2
Training loss: 1.9553107023239136
Validation loss: 1.8798592639483993
Epoch: 5| Step: 3
Training loss: 2.63143253326416
Validation loss: 1.9462190566303061
Epoch: 5| Step: 4
Training loss: 1.7954976558685303
Validation loss: 1.956710486103305
Epoch: 5| Step: 5
Training loss: 2.4688854217529297
Validation loss: 1.9218148859284765
Epoch: 5| Step: 6
Training loss: 2.1568307876586914
Validation loss: 1.968680014713205
Epoch: 5| Step: 7
Training loss: 2.0833332538604736
Validation loss: 1.9171301529561873
Epoch: 5| Step: 8
Training loss: 2.1519417762756348
Validation loss: 1.9499616742991714
Epoch: 5| Step: 9
Training loss: 1.6983788013458252
Validation loss: 1.9811196798900905
Epoch: 57| Step: 0
Training loss: 2.107600212097168
Validation loss: 1.974222406208944
Epoch: 5| Step: 1
Training loss: 2.1790812015533447
Validation loss: 1.932362946674978
Epoch: 5| Step: 2
Training loss: 2.4100704193115234
Validation loss: 1.9375503217573646
Epoch: 5| Step: 3
Training loss: 2.3590450286865234
Validation loss: 1.9005321229962135
Epoch: 5| Step: 4
Training loss: 2.1306073665618896
Validation loss: 1.9437557707587592
Epoch: 5| Step: 5
Training loss: 1.9705836772918701
Validation loss: 1.8966252692311787
Epoch: 5| Step: 6
Training loss: 2.067208766937256
Validation loss: 1.8491634422068974
Epoch: 5| Step: 7
Training loss: 1.8097209930419922
Validation loss: 1.9329113308474315
Epoch: 5| Step: 8
Training loss: 2.192256450653076
Validation loss: 1.8516973763061084
Epoch: 5| Step: 9
Training loss: 2.6773552894592285
Validation loss: 1.870655672155696
Epoch: 58| Step: 0
Training loss: 2.267772674560547
Validation loss: 1.8831205402346824
Epoch: 5| Step: 1
Training loss: 2.0428972244262695
Validation loss: 1.8746174496712444
Epoch: 5| Step: 2
Training loss: 2.0645790100097656
Validation loss: 1.8795501654096645
Epoch: 5| Step: 3
Training loss: 2.679028034210205
Validation loss: 1.8026250180580634
Epoch: 5| Step: 4
Training loss: 2.0241270065307617
Validation loss: 1.863947856340477
Epoch: 5| Step: 5
Training loss: 2.1696584224700928
Validation loss: 1.884457182541168
Epoch: 5| Step: 6
Training loss: 2.6183371543884277
Validation loss: 1.8905401641516377
Epoch: 5| Step: 7
Training loss: 2.007032871246338
Validation loss: 1.9344436299029013
Epoch: 5| Step: 8
Training loss: 1.7901108264923096
Validation loss: 1.913089580673108
Epoch: 5| Step: 9
Training loss: 1.9741575717926025
Validation loss: 1.8361474661518344
Epoch: 59| Step: 0
Training loss: 2.007205009460449
Validation loss: 1.8915644258046322
Epoch: 5| Step: 1
Training loss: 1.9970238208770752
Validation loss: 1.8591940574508776
Epoch: 5| Step: 2
Training loss: 1.685680866241455
Validation loss: 1.8925046920776367
Epoch: 5| Step: 3
Training loss: 2.130451202392578
Validation loss: 1.8967130578679146
Epoch: 5| Step: 4
Training loss: 1.8441190719604492
Validation loss: 1.894366380122068
Epoch: 5| Step: 5
Training loss: 2.5689592361450195
Validation loss: 1.8775801590020709
Epoch: 5| Step: 6
Training loss: 2.5790328979492188
Validation loss: 1.8817728877925186
Epoch: 5| Step: 7
Training loss: 2.156564712524414
Validation loss: 1.9021289262840215
Epoch: 5| Step: 8
Training loss: 2.2896318435668945
Validation loss: 1.8766737687501975
Epoch: 5| Step: 9
Training loss: 2.315220355987549
Validation loss: 1.8888938135380366
Epoch: 60| Step: 0
Training loss: 2.242644786834717
Validation loss: 1.9334097972019113
Epoch: 5| Step: 1
Training loss: 2.418517827987671
Validation loss: 1.8537422512932646
Epoch: 5| Step: 2
Training loss: 1.6883240938186646
Validation loss: 1.8982098848699667
Epoch: 5| Step: 3
Training loss: 2.2523717880249023
Validation loss: 1.844289459770532
Epoch: 5| Step: 4
Training loss: 2.0170094966888428
Validation loss: 1.8524542643869524
Epoch: 5| Step: 5
Training loss: 1.979842185974121
Validation loss: 1.888361829647915
Epoch: 5| Step: 6
Training loss: 2.33795428276062
Validation loss: 1.8308700829101123
Epoch: 5| Step: 7
Training loss: 2.8183231353759766
Validation loss: 1.8731904870314564
Epoch: 5| Step: 8
Training loss: 1.9529571533203125
Validation loss: 1.8648029274220088
Epoch: 5| Step: 9
Training loss: 1.848024606704712
Validation loss: 1.8867233374135957
Epoch: 61| Step: 0
Training loss: 1.7790063619613647
Validation loss: 1.8714563434930156
Epoch: 5| Step: 1
Training loss: 2.0022292137145996
Validation loss: 1.858504134116413
Epoch: 5| Step: 2
Training loss: 2.3899917602539062
Validation loss: 1.903359436302734
Epoch: 5| Step: 3
Training loss: 2.4765524864196777
Validation loss: 1.8515653009894941
Epoch: 5| Step: 4
Training loss: 2.5257771015167236
Validation loss: 1.8622079152855084
Epoch: 5| Step: 5
Training loss: 1.8255164623260498
Validation loss: 1.899784722774149
Epoch: 5| Step: 6
Training loss: 2.352646827697754
Validation loss: 1.8761314290890592
Epoch: 5| Step: 7
Training loss: 2.101097345352173
Validation loss: 1.8299874333168964
Epoch: 5| Step: 8
Training loss: 2.1554207801818848
Validation loss: 1.8713420372215106
Epoch: 5| Step: 9
Training loss: 2.11867356300354
Validation loss: 1.8440072896669237
Epoch: 62| Step: 0
Training loss: 2.1364235877990723
Validation loss: 1.8713821129833195
Epoch: 5| Step: 1
Training loss: 2.210462808609009
Validation loss: 1.9205988894263617
Epoch: 5| Step: 2
Training loss: 2.1546337604522705
Validation loss: 1.8718662510672919
Epoch: 5| Step: 3
Training loss: 2.556089162826538
Validation loss: 1.9249233830746988
Epoch: 5| Step: 4
Training loss: 2.312721014022827
Validation loss: 1.8742748250206598
Epoch: 5| Step: 5
Training loss: 2.6754150390625
Validation loss: 1.8447707771397324
Epoch: 5| Step: 6
Training loss: 1.778342604637146
Validation loss: 1.8762285417790034
Epoch: 5| Step: 7
Training loss: 2.304107189178467
Validation loss: 1.8488266742486748
Epoch: 5| Step: 8
Training loss: 1.9399311542510986
Validation loss: 1.8485166263237274
Epoch: 5| Step: 9
Training loss: 1.5621306896209717
Validation loss: 1.926392774787738
Epoch: 63| Step: 0
Training loss: 2.2848024368286133
Validation loss: 1.8873181814770046
Epoch: 5| Step: 1
Training loss: 1.963836908340454
Validation loss: 1.9393209579179613
Epoch: 5| Step: 2
Training loss: 2.3950014114379883
Validation loss: 1.924286549039882
Epoch: 5| Step: 3
Training loss: 2.4127159118652344
Validation loss: 1.8984819238992046
Epoch: 5| Step: 4
Training loss: 2.213336944580078
Validation loss: 1.9032640131257421
Epoch: 5| Step: 5
Training loss: 1.9940112829208374
Validation loss: 1.9169570233324449
Epoch: 5| Step: 6
Training loss: 1.8194553852081299
Validation loss: 1.8986518674617192
Epoch: 5| Step: 7
Training loss: 2.023033857345581
Validation loss: 1.8824275491906584
Epoch: 5| Step: 8
Training loss: 2.4558849334716797
Validation loss: 1.8820422630515887
Epoch: 5| Step: 9
Training loss: 2.055802822113037
Validation loss: 1.8875758742256987
Epoch: 64| Step: 0
Training loss: 1.8927030563354492
Validation loss: 1.9048986100464416
Epoch: 5| Step: 1
Training loss: 1.8727340698242188
Validation loss: 1.8708281294047404
Epoch: 5| Step: 2
Training loss: 2.3335397243499756
Validation loss: 1.8411969615401125
Epoch: 5| Step: 3
Training loss: 2.350940227508545
Validation loss: 1.8659385271209608
Epoch: 5| Step: 4
Training loss: 2.3137669563293457
Validation loss: 1.9437769042502204
Epoch: 5| Step: 5
Training loss: 1.7352418899536133
Validation loss: 1.9506707045671752
Epoch: 5| Step: 6
Training loss: 2.215266227722168
Validation loss: 1.9283844344049907
Epoch: 5| Step: 7
Training loss: 2.6957643032073975
Validation loss: 1.8650838153825389
Epoch: 5| Step: 8
Training loss: 1.9804919958114624
Validation loss: 1.9053229393718911
Epoch: 5| Step: 9
Training loss: 2.4163975715637207
Validation loss: 1.840886812415912
Epoch: 65| Step: 0
Training loss: 2.3852295875549316
Validation loss: 1.9488293061153494
Epoch: 5| Step: 1
Training loss: 1.9129329919815063
Validation loss: 1.9135732256251274
Epoch: 5| Step: 2
Training loss: 2.355931282043457
Validation loss: 1.860297089858021
Epoch: 5| Step: 3
Training loss: 2.1213998794555664
Validation loss: 1.8751910607591808
Epoch: 5| Step: 4
Training loss: 2.4848673343658447
Validation loss: 1.8895261133317467
Epoch: 5| Step: 5
Training loss: 1.8670753240585327
Validation loss: 1.9130830841956379
Epoch: 5| Step: 6
Training loss: 2.3447508811950684
Validation loss: 1.8992839185454005
Epoch: 5| Step: 7
Training loss: 1.4694468975067139
Validation loss: 1.9410109451348834
Epoch: 5| Step: 8
Training loss: 1.8112388849258423
Validation loss: 1.9628067565478866
Epoch: 5| Step: 9
Training loss: 2.692498207092285
Validation loss: 1.9221196809260965
Epoch: 66| Step: 0
Training loss: 1.8865671157836914
Validation loss: 1.8744909300220955
Epoch: 5| Step: 1
Training loss: 2.046961784362793
Validation loss: 1.9154212389060918
Epoch: 5| Step: 2
Training loss: 2.4208812713623047
Validation loss: 1.892166977306064
Epoch: 5| Step: 3
Training loss: 2.2959842681884766
Validation loss: 1.9175620053311904
Epoch: 5| Step: 4
Training loss: 1.6646556854248047
Validation loss: 1.9612762936585242
Epoch: 5| Step: 5
Training loss: 2.2831459045410156
Validation loss: 1.925789354516448
Epoch: 5| Step: 6
Training loss: 2.4443914890289307
Validation loss: 1.8979282053254491
Epoch: 5| Step: 7
Training loss: 2.0815024375915527
Validation loss: 1.8798398302613402
Epoch: 5| Step: 8
Training loss: 1.8788442611694336
Validation loss: 1.8850786274285625
Epoch: 5| Step: 9
Training loss: 2.3368194103240967
Validation loss: 1.9472901212225715
Epoch: 67| Step: 0
Training loss: 1.9034843444824219
Validation loss: 1.876714618943578
Epoch: 5| Step: 1
Training loss: 2.1728930473327637
Validation loss: 1.9127448428449014
Epoch: 5| Step: 2
Training loss: 2.2894287109375
Validation loss: 1.8693461572523598
Epoch: 5| Step: 3
Training loss: 1.8766443729400635
Validation loss: 1.9230773629044458
Epoch: 5| Step: 4
Training loss: 2.195880889892578
Validation loss: 1.8917772624132445
Epoch: 5| Step: 5
Training loss: 2.5002942085266113
Validation loss: 1.9239347435587602
Epoch: 5| Step: 6
Training loss: 2.117314338684082
Validation loss: 1.868079314128958
Epoch: 5| Step: 7
Training loss: 1.9988958835601807
Validation loss: 1.8765873008494756
Epoch: 5| Step: 8
Training loss: 2.6901655197143555
Validation loss: 1.90473888760848
Epoch: 5| Step: 9
Training loss: 2.1315884590148926
Validation loss: 1.8940984842588575
Epoch: 68| Step: 0
Training loss: 2.491365909576416
Validation loss: 1.8788123748285308
Epoch: 5| Step: 1
Training loss: 2.181926727294922
Validation loss: 1.9079279839563712
Epoch: 5| Step: 2
Training loss: 1.9279582500457764
Validation loss: 1.8509292786927531
Epoch: 5| Step: 3
Training loss: 2.0006043910980225
Validation loss: 1.9064907907582016
Epoch: 5| Step: 4
Training loss: 2.429555892944336
Validation loss: 1.9225452323611691
Epoch: 5| Step: 5
Training loss: 2.0561342239379883
Validation loss: 1.8198079153788176
Epoch: 5| Step: 6
Training loss: 2.3520383834838867
Validation loss: 1.8939554048099105
Epoch: 5| Step: 7
Training loss: 2.058171272277832
Validation loss: 1.8821216418588762
Epoch: 5| Step: 8
Training loss: 2.064016103744507
Validation loss: 1.8316972024149174
Epoch: 5| Step: 9
Training loss: 1.9769155979156494
Validation loss: 1.871291431591665
Epoch: 69| Step: 0
Training loss: 2.0639877319335938
Validation loss: 1.8927227224377419
Epoch: 5| Step: 1
Training loss: 2.3589248657226562
Validation loss: 1.9004613366916026
Epoch: 5| Step: 2
Training loss: 2.281345844268799
Validation loss: 1.85949302234238
Epoch: 5| Step: 3
Training loss: 2.4741005897521973
Validation loss: 1.9183188959848967
Epoch: 5| Step: 4
Training loss: 2.1413521766662598
Validation loss: 1.8551245739134095
Epoch: 5| Step: 5
Training loss: 2.344212770462036
Validation loss: 1.8603410918077976
Epoch: 5| Step: 6
Training loss: 1.8290092945098877
Validation loss: 1.8889551574377705
Epoch: 5| Step: 7
Training loss: 1.842688798904419
Validation loss: 1.8740203474923003
Epoch: 5| Step: 8
Training loss: 1.8638325929641724
Validation loss: 1.8653963718482915
Epoch: 5| Step: 9
Training loss: 2.495192050933838
Validation loss: 1.899951315612244
Epoch: 70| Step: 0
Training loss: 2.5656585693359375
Validation loss: 1.909480142936432
Epoch: 5| Step: 1
Training loss: 2.9778623580932617
Validation loss: 1.9084076049516527
Epoch: 5| Step: 2
Training loss: 2.1341757774353027
Validation loss: 1.8817416789720385
Epoch: 5| Step: 3
Training loss: 2.2004761695861816
Validation loss: 1.896089261384319
Epoch: 5| Step: 4
Training loss: 2.298417806625366
Validation loss: 1.894333211638087
Epoch: 5| Step: 5
Training loss: 2.1031837463378906
Validation loss: 1.9003438237759707
Epoch: 5| Step: 6
Training loss: 1.881810188293457
Validation loss: 1.8981386097215063
Epoch: 5| Step: 7
Training loss: 1.797234058380127
Validation loss: 1.8125690256091331
Epoch: 5| Step: 8
Training loss: 1.8112541437149048
Validation loss: 1.868668482457991
Epoch: 5| Step: 9
Training loss: 1.7808587551116943
Validation loss: 1.8386953091449876
Epoch: 71| Step: 0
Training loss: 1.5727274417877197
Validation loss: 1.8957814852968395
Epoch: 5| Step: 1
Training loss: 1.9319583177566528
Validation loss: 1.8929128012211203
Epoch: 5| Step: 2
Training loss: 3.0172066688537598
Validation loss: 1.908986045302247
Epoch: 5| Step: 3
Training loss: 1.6534315347671509
Validation loss: 1.8906571462000017
Epoch: 5| Step: 4
Training loss: 2.5428755283355713
Validation loss: 1.9369977258092208
Epoch: 5| Step: 5
Training loss: 2.1688125133514404
Validation loss: 1.8384951824764553
Epoch: 5| Step: 6
Training loss: 1.768874168395996
Validation loss: 1.8745402294954807
Epoch: 5| Step: 7
Training loss: 2.033374309539795
Validation loss: 1.885757670985709
Epoch: 5| Step: 8
Training loss: 2.3075344562530518
Validation loss: 1.8836126258904986
Epoch: 5| Step: 9
Training loss: 2.3499183654785156
Validation loss: 1.7972847617787422
Epoch: 72| Step: 0
Training loss: 1.3977034091949463
Validation loss: 1.8323952431301418
Epoch: 5| Step: 1
Training loss: 2.0233869552612305
Validation loss: 1.89008430182505
Epoch: 5| Step: 2
Training loss: 2.081928253173828
Validation loss: 1.8715454768791473
Epoch: 5| Step: 3
Training loss: 2.0342679023742676
Validation loss: 1.8583373628931938
Epoch: 5| Step: 4
Training loss: 2.1990773677825928
Validation loss: 1.877162830435115
Epoch: 5| Step: 5
Training loss: 2.8622512817382812
Validation loss: 1.883892358635827
Epoch: 5| Step: 6
Training loss: 2.157693386077881
Validation loss: 1.8533261045277547
Epoch: 5| Step: 7
Training loss: 2.182464599609375
Validation loss: 1.8816279884722593
Epoch: 5| Step: 8
Training loss: 2.2453789710998535
Validation loss: 1.9304768653224698
Epoch: 5| Step: 9
Training loss: 2.2014269828796387
Validation loss: 1.9125462847647907
Epoch: 73| Step: 0
Training loss: 1.7560560703277588
Validation loss: 1.8565119830824488
Epoch: 5| Step: 1
Training loss: 1.6988048553466797
Validation loss: 1.8871258848862682
Epoch: 5| Step: 2
Training loss: 2.166750431060791
Validation loss: 1.8608738629938029
Epoch: 5| Step: 3
Training loss: 2.2125353813171387
Validation loss: 1.860862896596785
Epoch: 5| Step: 4
Training loss: 2.042004108428955
Validation loss: 1.8870800785023532
Epoch: 5| Step: 5
Training loss: 2.922377109527588
Validation loss: 1.8697826810877958
Epoch: 5| Step: 6
Training loss: 1.98134183883667
Validation loss: 1.8696332921227106
Epoch: 5| Step: 7
Training loss: 2.577658176422119
Validation loss: 1.8768133911297475
Epoch: 5| Step: 8
Training loss: 1.757540225982666
Validation loss: 1.9024420161899045
Epoch: 5| Step: 9
Training loss: 2.271998882293701
Validation loss: 1.8676076835865596
Epoch: 74| Step: 0
Training loss: 2.310480833053589
Validation loss: 1.8992592876763652
Epoch: 5| Step: 1
Training loss: 1.7279125452041626
Validation loss: 1.907945431393685
Epoch: 5| Step: 2
Training loss: 2.5494742393493652
Validation loss: 1.8738425798553358
Epoch: 5| Step: 3
Training loss: 2.575198173522949
Validation loss: 1.8484489566130604
Epoch: 5| Step: 4
Training loss: 2.0016822814941406
Validation loss: 1.9068661576552357
Epoch: 5| Step: 5
Training loss: 1.632396936416626
Validation loss: 1.9186015386375592
Epoch: 5| Step: 6
Training loss: 2.1343836784362793
Validation loss: 1.9421066448842879
Epoch: 5| Step: 7
Training loss: 2.178656578063965
Validation loss: 1.8331885346405798
Epoch: 5| Step: 8
Training loss: 2.1412198543548584
Validation loss: 1.8861298303809955
Epoch: 5| Step: 9
Training loss: 2.1181020736694336
Validation loss: 1.8981771083186856
Epoch: 75| Step: 0
Training loss: 1.831360101699829
Validation loss: 1.8496574334961047
Epoch: 5| Step: 1
Training loss: 2.614609718322754
Validation loss: 1.9270438513309835
Epoch: 5| Step: 2
Training loss: 1.7563936710357666
Validation loss: 1.892783170981373
Epoch: 5| Step: 3
Training loss: 2.2249159812927246
Validation loss: 1.8790736438559115
Epoch: 5| Step: 4
Training loss: 1.776733160018921
Validation loss: 1.8334901298550392
Epoch: 5| Step: 5
Training loss: 2.190396547317505
Validation loss: 1.8772350678340994
Epoch: 5| Step: 6
Training loss: 2.3184359073638916
Validation loss: 1.8794563828612403
Epoch: 5| Step: 7
Training loss: 2.542818546295166
Validation loss: 1.898531481516447
Epoch: 5| Step: 8
Training loss: 2.276482105255127
Validation loss: 1.8875900378330148
Epoch: 5| Step: 9
Training loss: 2.325273036956787
Validation loss: 1.8461901661303404
Epoch: 76| Step: 0
Training loss: 1.897705078125
Validation loss: 1.861207536656222
Epoch: 5| Step: 1
Training loss: 2.333310127258301
Validation loss: 1.8518479565064685
Epoch: 5| Step: 2
Training loss: 2.066439151763916
Validation loss: 1.8472912157182213
Epoch: 5| Step: 3
Training loss: 2.3088908195495605
Validation loss: 1.8303219791796568
Epoch: 5| Step: 4
Training loss: 1.9006471633911133
Validation loss: 1.8425312633994673
Epoch: 5| Step: 5
Training loss: 2.0457725524902344
Validation loss: 1.8762567129066523
Epoch: 5| Step: 6
Training loss: 2.052070140838623
Validation loss: 1.87722560141584
Epoch: 5| Step: 7
Training loss: 2.2314910888671875
Validation loss: 1.8517021704063141
Epoch: 5| Step: 8
Training loss: 2.38301420211792
Validation loss: 1.894892765463685
Epoch: 5| Step: 9
Training loss: 2.3046789169311523
Validation loss: 1.922914670525695
Epoch: 77| Step: 0
Training loss: 2.0069847106933594
Validation loss: 1.8437278922513234
Epoch: 5| Step: 1
Training loss: 3.0447020530700684
Validation loss: 1.8844528043870445
Epoch: 5| Step: 2
Training loss: 2.204044818878174
Validation loss: 1.8531663280596835
Epoch: 5| Step: 3
Training loss: 1.501798391342163
Validation loss: 1.9137395911937138
Epoch: 5| Step: 4
Training loss: 2.095052719116211
Validation loss: 1.9090129145615393
Epoch: 5| Step: 5
Training loss: 2.1235404014587402
Validation loss: 1.8998274194250862
Epoch: 5| Step: 6
Training loss: 1.8325140476226807
Validation loss: 1.8289673148299292
Epoch: 5| Step: 7
Training loss: 2.1199886798858643
Validation loss: 1.9047125414978685
Epoch: 5| Step: 8
Training loss: 2.428799867630005
Validation loss: 1.9115464970362273
Epoch: 5| Step: 9
Training loss: 2.202205181121826
Validation loss: 1.885476426254931
Epoch: 78| Step: 0
Training loss: 2.1940157413482666
Validation loss: 1.8712684010430205
Epoch: 5| Step: 1
Training loss: 1.6884381771087646
Validation loss: 1.8911804398186773
Epoch: 5| Step: 2
Training loss: 2.242133855819702
Validation loss: 1.9299058442493138
Epoch: 5| Step: 3
Training loss: 2.3950037956237793
Validation loss: 1.8826506892554193
Epoch: 5| Step: 4
Training loss: 1.9391868114471436
Validation loss: 1.8615340105921245
Epoch: 5| Step: 5
Training loss: 1.7517101764678955
Validation loss: 1.8583054868437403
Epoch: 5| Step: 6
Training loss: 2.176138401031494
Validation loss: 1.878774793027974
Epoch: 5| Step: 7
Training loss: 2.350067138671875
Validation loss: 1.9269167707978392
Epoch: 5| Step: 8
Training loss: 2.7195167541503906
Validation loss: 1.9685400141228875
Epoch: 5| Step: 9
Training loss: 1.9152021408081055
Validation loss: 1.9075131261949059
Epoch: 79| Step: 0
Training loss: 2.5058627128601074
Validation loss: 1.8695997214145799
Epoch: 5| Step: 1
Training loss: 2.1862781047821045
Validation loss: 1.8763631616564964
Epoch: 5| Step: 2
Training loss: 2.072434425354004
Validation loss: 1.9135824013099396
Epoch: 5| Step: 3
Training loss: 2.309577226638794
Validation loss: 1.883247599327307
Epoch: 5| Step: 4
Training loss: 1.8692817687988281
Validation loss: 1.8430853061538806
Epoch: 5| Step: 5
Training loss: 1.6010351181030273
Validation loss: 1.8708875865387402
Epoch: 5| Step: 6
Training loss: 2.1062591075897217
Validation loss: 1.9062616430598198
Epoch: 5| Step: 7
Training loss: 2.4985547065734863
Validation loss: 1.9236938155812324
Epoch: 5| Step: 8
Training loss: 2.0814368724823
Validation loss: 1.8841117680501596
Epoch: 5| Step: 9
Training loss: 2.1882805824279785
Validation loss: 1.8436000441475737
Epoch: 80| Step: 0
Training loss: 1.8781288862228394
Validation loss: 1.9054272775169756
Epoch: 5| Step: 1
Training loss: 2.0631964206695557
Validation loss: 1.8703989022069698
Epoch: 5| Step: 2
Training loss: 2.349212408065796
Validation loss: 1.889016284359445
Epoch: 5| Step: 3
Training loss: 1.6775870323181152
Validation loss: 1.9012137668595896
Epoch: 5| Step: 4
Training loss: 2.0282065868377686
Validation loss: 1.9102667424318602
Epoch: 5| Step: 5
Training loss: 2.5729293823242188
Validation loss: 1.920847712660865
Epoch: 5| Step: 6
Training loss: 2.1963205337524414
Validation loss: 1.8579994817431882
Epoch: 5| Step: 7
Training loss: 1.9263763427734375
Validation loss: 1.9145579852646204
Epoch: 5| Step: 8
Training loss: 2.1374073028564453
Validation loss: 1.903380004622096
Epoch: 5| Step: 9
Training loss: 2.6106173992156982
Validation loss: 1.8918232231689014
Epoch: 81| Step: 0
Training loss: 1.824428677558899
Validation loss: 1.8586092020967881
Epoch: 5| Step: 1
Training loss: 2.432767868041992
Validation loss: 1.9076291742942315
Epoch: 5| Step: 2
Training loss: 1.9199693202972412
Validation loss: 1.859473984876125
Epoch: 5| Step: 3
Training loss: 2.1422650814056396
Validation loss: 1.910513822980922
Epoch: 5| Step: 4
Training loss: 2.044409990310669
Validation loss: 1.8727793076055512
Epoch: 5| Step: 5
Training loss: 2.227600336074829
Validation loss: 1.8848562720868227
Epoch: 5| Step: 6
Training loss: 2.0384960174560547
Validation loss: 1.9777747512721329
Epoch: 5| Step: 7
Training loss: 2.365619659423828
Validation loss: 1.8863320436409052
Epoch: 5| Step: 8
Training loss: 2.274228572845459
Validation loss: 1.8895871441998928
Epoch: 5| Step: 9
Training loss: 2.1923599243164062
Validation loss: 1.911832494701413
Epoch: 82| Step: 0
Training loss: 2.1741974353790283
Validation loss: 1.8935833946406413
Epoch: 5| Step: 1
Training loss: 2.418330430984497
Validation loss: 1.8597143965659382
Epoch: 5| Step: 2
Training loss: 2.31451153755188
Validation loss: 1.9268928380321255
Epoch: 5| Step: 3
Training loss: 1.6802363395690918
Validation loss: 1.925981976145463
Epoch: 5| Step: 4
Training loss: 1.9909979104995728
Validation loss: 1.9024230644857283
Epoch: 5| Step: 5
Training loss: 2.8544349670410156
Validation loss: 1.8588348790038405
Epoch: 5| Step: 6
Training loss: 2.083944797515869
Validation loss: 1.8832387375317032
Epoch: 5| Step: 7
Training loss: 2.0933609008789062
Validation loss: 1.8908267655818582
Epoch: 5| Step: 8
Training loss: 1.470226764678955
Validation loss: 1.9188991484882163
Epoch: 5| Step: 9
Training loss: 2.04620361328125
Validation loss: 1.8666403190695124
Epoch: 83| Step: 0
Training loss: 1.9724446535110474
Validation loss: 1.868493793679656
Epoch: 5| Step: 1
Training loss: 1.5719355344772339
Validation loss: 1.8463428680845302
Epoch: 5| Step: 2
Training loss: 2.3203420639038086
Validation loss: 1.885623986772496
Epoch: 5| Step: 3
Training loss: 2.734618663787842
Validation loss: 1.8395213686304985
Epoch: 5| Step: 4
Training loss: 2.383596897125244
Validation loss: 1.8830320492065211
Epoch: 5| Step: 5
Training loss: 2.361812114715576
Validation loss: 1.8870721026290236
Epoch: 5| Step: 6
Training loss: 2.2901148796081543
Validation loss: 1.79423470977399
Epoch: 5| Step: 7
Training loss: 1.6472997665405273
Validation loss: 1.897652637186668
Epoch: 5| Step: 8
Training loss: 1.9364595413208008
Validation loss: 1.8827190261950595
Epoch: 5| Step: 9
Training loss: 2.1458024978637695
Validation loss: 1.8743094111518037
Epoch: 84| Step: 0
Training loss: 2.357020378112793
Validation loss: 1.9336415383455565
Epoch: 5| Step: 1
Training loss: 2.2038488388061523
Validation loss: 1.8602506934310035
Epoch: 5| Step: 2
Training loss: 1.7396917343139648
Validation loss: 1.8661498371645702
Epoch: 5| Step: 3
Training loss: 2.1183462142944336
Validation loss: 1.8954288522116571
Epoch: 5| Step: 4
Training loss: 2.5788512229919434
Validation loss: 1.889314787850963
Epoch: 5| Step: 5
Training loss: 2.3064002990722656
Validation loss: 1.8569896624242659
Epoch: 5| Step: 6
Training loss: 2.1661782264709473
Validation loss: 1.910718572225502
Epoch: 5| Step: 7
Training loss: 1.7563368082046509
Validation loss: 1.8425272711746985
Epoch: 5| Step: 8
Training loss: 1.6455641984939575
Validation loss: 1.896175312481338
Epoch: 5| Step: 9
Training loss: 2.411586284637451
Validation loss: 1.8480676103838913
Epoch: 85| Step: 0
Training loss: 2.6003530025482178
Validation loss: 1.8598697468531218
Epoch: 5| Step: 1
Training loss: 1.9310928583145142
Validation loss: 1.8990997238982497
Epoch: 5| Step: 2
Training loss: 1.9186639785766602
Validation loss: 1.8802371085118905
Epoch: 5| Step: 3
Training loss: 2.2480006217956543
Validation loss: 1.8237796867494103
Epoch: 5| Step: 4
Training loss: 1.9011614322662354
Validation loss: 1.8223438991917122
Epoch: 5| Step: 5
Training loss: 2.315782070159912
Validation loss: 1.9047991028792566
Epoch: 5| Step: 6
Training loss: 2.225797414779663
Validation loss: 1.8301141587950343
Epoch: 5| Step: 7
Training loss: 2.4045135974884033
Validation loss: 1.8658415439317553
Epoch: 5| Step: 8
Training loss: 2.2128090858459473
Validation loss: 1.9075552199384291
Epoch: 5| Step: 9
Training loss: 1.6377570629119873
Validation loss: 1.883708613381969
Epoch: 86| Step: 0
Training loss: 2.0983824729919434
Validation loss: 1.8550787520923202
Epoch: 5| Step: 1
Training loss: 1.9895198345184326
Validation loss: 1.883113327643854
Epoch: 5| Step: 2
Training loss: 2.3770551681518555
Validation loss: 1.923091878136285
Epoch: 5| Step: 3
Training loss: 2.129683256149292
Validation loss: 1.8985292465566732
Epoch: 5| Step: 4
Training loss: 2.396648645401001
Validation loss: 1.8918636805719609
Epoch: 5| Step: 5
Training loss: 2.2060699462890625
Validation loss: 1.9217382986768543
Epoch: 5| Step: 6
Training loss: 2.608384132385254
Validation loss: 1.9327535980896984
Epoch: 5| Step: 7
Training loss: 1.7984342575073242
Validation loss: 1.9459239115817941
Epoch: 5| Step: 8
Training loss: 1.8767459392547607
Validation loss: 1.8960447242791705
Epoch: 5| Step: 9
Training loss: 1.8358479738235474
Validation loss: 1.9177489915340067
Epoch: 87| Step: 0
Training loss: 2.344930648803711
Validation loss: 1.8663488309160412
Epoch: 5| Step: 1
Training loss: 2.4864706993103027
Validation loss: 1.9135555243320603
Epoch: 5| Step: 2
Training loss: 1.9535346031188965
Validation loss: 1.7992615939901888
Epoch: 5| Step: 3
Training loss: 2.1234028339385986
Validation loss: 1.8839134929849088
Epoch: 5| Step: 4
Training loss: 1.9249889850616455
Validation loss: 1.8654675629499147
Epoch: 5| Step: 5
Training loss: 2.1698880195617676
Validation loss: 1.882051086254257
Epoch: 5| Step: 6
Training loss: 2.0710196495056152
Validation loss: 1.9214423191633156
Epoch: 5| Step: 7
Training loss: 2.58664608001709
Validation loss: 1.8834098946276328
Epoch: 5| Step: 8
Training loss: 1.74570894241333
Validation loss: 1.8876436468508604
Epoch: 5| Step: 9
Training loss: 2.1663320064544678
Validation loss: 1.8747730520989399
Epoch: 88| Step: 0
Training loss: 2.505901336669922
Validation loss: 1.8546122852846874
Epoch: 5| Step: 1
Training loss: 1.641603946685791
Validation loss: 1.8592230458911374
Epoch: 5| Step: 2
Training loss: 1.9974400997161865
Validation loss: 1.8714053210594672
Epoch: 5| Step: 3
Training loss: 1.9199695587158203
Validation loss: 1.8555961238394538
Epoch: 5| Step: 4
Training loss: 1.9211143255233765
Validation loss: 1.817021548319206
Epoch: 5| Step: 5
Training loss: 2.479052782058716
Validation loss: 1.8300743223094253
Epoch: 5| Step: 6
Training loss: 2.289670705795288
Validation loss: 1.87367830430861
Epoch: 5| Step: 7
Training loss: 2.3715949058532715
Validation loss: 1.8934270276440133
Epoch: 5| Step: 8
Training loss: 1.7858986854553223
Validation loss: 1.8589815681786845
Epoch: 5| Step: 9
Training loss: 2.286133289337158
Validation loss: 1.9173050835835848
Epoch: 89| Step: 0
Training loss: 1.838915228843689
Validation loss: 1.8942356787139563
Epoch: 5| Step: 1
Training loss: 2.411362648010254
Validation loss: 1.8909310248258302
Epoch: 5| Step: 2
Training loss: 2.1508841514587402
Validation loss: 1.8742903976989307
Epoch: 5| Step: 3
Training loss: 2.1292004585266113
Validation loss: 1.8721466038724501
Epoch: 5| Step: 4
Training loss: 1.4809455871582031
Validation loss: 1.9185034062364976
Epoch: 5| Step: 5
Training loss: 2.29297137260437
Validation loss: 1.8336306561669
Epoch: 5| Step: 6
Training loss: 1.9937117099761963
Validation loss: 1.8309048414230347
Epoch: 5| Step: 7
Training loss: 2.4117431640625
Validation loss: 1.880689822512565
Epoch: 5| Step: 8
Training loss: 1.8696701526641846
Validation loss: 1.9163711002404742
Epoch: 5| Step: 9
Training loss: 2.7579216957092285
Validation loss: 1.8777408762801466
Epoch: 90| Step: 0
Training loss: 2.0999550819396973
Validation loss: 1.8581054365034584
Epoch: 5| Step: 1
Training loss: 2.21448016166687
Validation loss: 1.8556974362983978
Epoch: 5| Step: 2
Training loss: 2.091109037399292
Validation loss: 1.8361831654747613
Epoch: 5| Step: 3
Training loss: 1.874976396560669
Validation loss: 1.8471700913614506
Epoch: 5| Step: 4
Training loss: 2.6608192920684814
Validation loss: 1.9103296111813552
Epoch: 5| Step: 5
Training loss: 1.6974601745605469
Validation loss: 1.8853800519764852
Epoch: 5| Step: 6
Training loss: 1.9954297542572021
Validation loss: 1.8538458261558477
Epoch: 5| Step: 7
Training loss: 2.125424861907959
Validation loss: 1.864897215966698
Epoch: 5| Step: 8
Training loss: 2.01969051361084
Validation loss: 1.8864698101290696
Epoch: 5| Step: 9
Training loss: 2.288888454437256
Validation loss: 1.8453472012238537
Epoch: 91| Step: 0
Training loss: 2.3535923957824707
Validation loss: 1.9078818036497927
Epoch: 5| Step: 1
Training loss: 2.462162971496582
Validation loss: 1.88776294190249
Epoch: 5| Step: 2
Training loss: 1.8364856243133545
Validation loss: 1.9142322660350113
Epoch: 5| Step: 3
Training loss: 1.868919014930725
Validation loss: 1.9200241033979457
Epoch: 5| Step: 4
Training loss: 2.7762465476989746
Validation loss: 1.8806078862800872
Epoch: 5| Step: 5
Training loss: 1.7733819484710693
Validation loss: 1.8720206416768135
Epoch: 5| Step: 6
Training loss: 1.869053840637207
Validation loss: 1.8777712283374595
Epoch: 5| Step: 7
Training loss: 2.4059605598449707
Validation loss: 1.8965457737874643
Epoch: 5| Step: 8
Training loss: 2.012864351272583
Validation loss: 1.8803342786624277
Epoch: 5| Step: 9
Training loss: 1.8000669479370117
Validation loss: 1.9261818017890986
Epoch: 92| Step: 0
Training loss: 1.798771619796753
Validation loss: 1.8797485888433114
Epoch: 5| Step: 1
Training loss: 1.8674418926239014
Validation loss: 1.9113999150639815
Epoch: 5| Step: 2
Training loss: 2.1059584617614746
Validation loss: 1.8916425447669818
Epoch: 5| Step: 3
Training loss: 1.5621240139007568
Validation loss: 1.9441316402215751
Epoch: 5| Step: 4
Training loss: 1.9944689273834229
Validation loss: 1.8832910318168805
Epoch: 5| Step: 5
Training loss: 2.350707530975342
Validation loss: 1.9410170119443386
Epoch: 5| Step: 6
Training loss: 2.1516361236572266
Validation loss: 1.9057152708657354
Epoch: 5| Step: 7
Training loss: 2.085566997528076
Validation loss: 1.8537795869566553
Epoch: 5| Step: 8
Training loss: 2.3874595165252686
Validation loss: 1.9439353668432442
Epoch: 5| Step: 9
Training loss: 2.7057838439941406
Validation loss: 1.8506039252384103
Epoch: 93| Step: 0
Training loss: 1.8366498947143555
Validation loss: 1.9248232206852316
Epoch: 5| Step: 1
Training loss: 2.3125
Validation loss: 1.9038025183643368
Epoch: 5| Step: 2
Training loss: 2.1435863971710205
Validation loss: 1.9323567795238907
Epoch: 5| Step: 3
Training loss: 2.605431318283081
Validation loss: 1.9286618429979832
Epoch: 5| Step: 4
Training loss: 2.313110113143921
Validation loss: 1.9182123914897014
Epoch: 5| Step: 5
Training loss: 2.1104652881622314
Validation loss: 1.9092327905215805
Epoch: 5| Step: 6
Training loss: 1.8998956680297852
Validation loss: 1.9130176863224386
Epoch: 5| Step: 7
Training loss: 2.1846747398376465
Validation loss: 1.9044265772798936
Epoch: 5| Step: 8
Training loss: 1.924943447113037
Validation loss: 1.876060379494866
Epoch: 5| Step: 9
Training loss: 2.1558074951171875
Validation loss: 1.8892397365981726
Epoch: 94| Step: 0
Training loss: 1.8949406147003174
Validation loss: 1.9286665461903854
Epoch: 5| Step: 1
Training loss: 2.4438509941101074
Validation loss: 1.874825180863305
Epoch: 5| Step: 2
Training loss: 1.8240309953689575
Validation loss: 1.9332601749639717
Epoch: 5| Step: 3
Training loss: 2.0454306602478027
Validation loss: 1.896682268424
Epoch: 5| Step: 4
Training loss: 1.631744146347046
Validation loss: 1.855553465781452
Epoch: 5| Step: 5
Training loss: 1.8798611164093018
Validation loss: 1.8958851279114648
Epoch: 5| Step: 6
Training loss: 1.681443214416504
Validation loss: 1.8649020683851174
Epoch: 5| Step: 7
Training loss: 2.482329845428467
Validation loss: 1.8604096525864635
Epoch: 5| Step: 8
Training loss: 2.6100716590881348
Validation loss: 1.8863295299543752
Epoch: 5| Step: 9
Training loss: 2.680391311645508
Validation loss: 1.8267542038032476
Epoch: 95| Step: 0
Training loss: 2.2855629920959473
Validation loss: 1.8674807093983932
Epoch: 5| Step: 1
Training loss: 2.1629860401153564
Validation loss: 1.8593876070255855
Epoch: 5| Step: 2
Training loss: 2.213618516921997
Validation loss: 1.8875158124690434
Epoch: 5| Step: 3
Training loss: 1.7047393321990967
Validation loss: 1.9005239421515157
Epoch: 5| Step: 4
Training loss: 2.5074195861816406
Validation loss: 1.9195793026642833
Epoch: 5| Step: 5
Training loss: 2.0103204250335693
Validation loss: 1.9517467313533208
Epoch: 5| Step: 6
Training loss: 1.8585963249206543
Validation loss: 1.9324075403830987
Epoch: 5| Step: 7
Training loss: 2.3200392723083496
Validation loss: 1.9502147015907783
Epoch: 5| Step: 8
Training loss: 2.069167375564575
Validation loss: 1.9098092729239156
Epoch: 5| Step: 9
Training loss: 1.9468289613723755
Validation loss: 1.9241124854671012
Epoch: 96| Step: 0
Training loss: 2.4428045749664307
Validation loss: 1.8761083873913442
Epoch: 5| Step: 1
Training loss: 2.3980400562286377
Validation loss: 1.9718866862839075
Epoch: 5| Step: 2
Training loss: 2.132195234298706
Validation loss: 1.8716229809273919
Epoch: 5| Step: 3
Training loss: 1.6058510541915894
Validation loss: 1.8471856704718774
Epoch: 5| Step: 4
Training loss: 2.0378875732421875
Validation loss: 1.928748607635498
Epoch: 5| Step: 5
Training loss: 2.802628993988037
Validation loss: 1.9391145809091253
Epoch: 5| Step: 6
Training loss: 2.0390706062316895
Validation loss: 1.897949736752956
Epoch: 5| Step: 7
Training loss: 2.1648921966552734
Validation loss: 1.9295665411640415
Epoch: 5| Step: 8
Training loss: 1.9245829582214355
Validation loss: 1.9078495107966362
Epoch: 5| Step: 9
Training loss: 1.604242205619812
Validation loss: 1.8627712057648802
Epoch: 97| Step: 0
Training loss: 2.607753038406372
Validation loss: 1.8453251132004553
Epoch: 5| Step: 1
Training loss: 2.111222743988037
Validation loss: 1.9007149668906231
Epoch: 5| Step: 2
Training loss: 2.326592445373535
Validation loss: 1.9213948807270407
Epoch: 5| Step: 3
Training loss: 2.2956275939941406
Validation loss: 1.8547798849695878
Epoch: 5| Step: 4
Training loss: 1.510765552520752
Validation loss: 1.9058122703497358
Epoch: 5| Step: 5
Training loss: 1.8424872159957886
Validation loss: 1.8855282882992312
Epoch: 5| Step: 6
Training loss: 1.9534082412719727
Validation loss: 1.8402503102803403
Epoch: 5| Step: 7
Training loss: 2.3385963439941406
Validation loss: 1.867316439855013
Epoch: 5| Step: 8
Training loss: 2.2025694847106934
Validation loss: 1.8596566460973067
Epoch: 5| Step: 9
Training loss: 2.1575777530670166
Validation loss: 1.8353975779718632
Epoch: 98| Step: 0
Training loss: 1.7899829149246216
Validation loss: 1.891641195729482
Epoch: 5| Step: 1
Training loss: 2.669983386993408
Validation loss: 1.9290666237151881
Epoch: 5| Step: 2
Training loss: 2.3398191928863525
Validation loss: 1.8616787898454734
Epoch: 5| Step: 3
Training loss: 1.9817880392074585
Validation loss: 1.8462365942893268
Epoch: 5| Step: 4
Training loss: 1.9388647079467773
Validation loss: 1.890978212836835
Epoch: 5| Step: 5
Training loss: 2.306791305541992
Validation loss: 1.9201394722616072
Epoch: 5| Step: 6
Training loss: 2.116525173187256
Validation loss: 1.8593125214679636
Epoch: 5| Step: 7
Training loss: 2.2746384143829346
Validation loss: 1.8904926862648066
Epoch: 5| Step: 8
Training loss: 2.053025007247925
Validation loss: 1.8844222387821554
Epoch: 5| Step: 9
Training loss: 1.971637487411499
Validation loss: 1.9242462683067048
Epoch: 99| Step: 0
Training loss: 2.419140338897705
Validation loss: 1.9081896191878285
Epoch: 5| Step: 1
Training loss: 2.2932300567626953
Validation loss: 1.8950393482935515
Epoch: 5| Step: 2
Training loss: 2.499222993850708
Validation loss: 1.9209334738820576
Epoch: 5| Step: 3
Training loss: 1.9440017938613892
Validation loss: 1.8501613809050417
Epoch: 5| Step: 4
Training loss: 1.8738503456115723
Validation loss: 1.8688406129535153
Epoch: 5| Step: 5
Training loss: 1.8127062320709229
Validation loss: 1.808222378758218
Epoch: 5| Step: 6
Training loss: 2.1841602325439453
Validation loss: 1.8820285076717678
Epoch: 5| Step: 7
Training loss: 1.6631903648376465
Validation loss: 1.8882537762895764
Epoch: 5| Step: 8
Training loss: 2.2181406021118164
Validation loss: 1.875480375701575
Epoch: 5| Step: 9
Training loss: 2.1885645389556885
Validation loss: 1.8490962450452846
Epoch: 100| Step: 0
Training loss: 2.176074504852295
Validation loss: 1.876545697665043
Epoch: 5| Step: 1
Training loss: 2.287227153778076
Validation loss: 1.8931571185160025
Epoch: 5| Step: 2
Training loss: 2.072254180908203
Validation loss: 1.8487508579981413
Epoch: 5| Step: 3
Training loss: 2.297518730163574
Validation loss: 1.8324133826674318
Epoch: 5| Step: 4
Training loss: 2.4068503379821777
Validation loss: 1.8381857726213744
Epoch: 5| Step: 5
Training loss: 2.020223617553711
Validation loss: 1.8393289614066803
Epoch: 5| Step: 6
Training loss: 2.2489566802978516
Validation loss: 1.8785414455605924
Epoch: 5| Step: 7
Training loss: 1.846224308013916
Validation loss: 1.8137195676350766
Epoch: 5| Step: 8
Training loss: 1.8179676532745361
Validation loss: 1.838549260612872
Epoch: 5| Step: 9
Training loss: 2.050741672515869
Validation loss: 1.8549444804088675
