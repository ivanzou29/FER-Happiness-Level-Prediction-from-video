Epoch: 1| Step: 0
Training loss: 4.642625331878662
Validation loss: 4.453481087581717
Epoch: 4| Step: 1
Training loss: 5.735951900482178
Validation loss: 4.448953427856774
Epoch: 4| Step: 2
Training loss: 4.1468825340271
Validation loss: 4.446080283295337
Epoch: 4| Step: 3
Training loss: 3.8677101135253906
Validation loss: 4.444329203461572
Epoch: 4| Step: 4
Training loss: 5.27518367767334
Validation loss: 4.4369736541089395
Epoch: 4| Step: 5
Training loss: 4.156527042388916
Validation loss: 4.432014472192997
Epoch: 4| Step: 6
Training loss: 4.0166425704956055
Validation loss: 4.42944212954679
Epoch: 4| Step: 7
Training loss: 5.067359924316406
Validation loss: 4.425690750423953
Epoch: 2| Step: 0
Training loss: 4.9741106033325195
Validation loss: 4.420279365649327
Epoch: 4| Step: 1
Training loss: 4.201109886169434
Validation loss: 4.414028750906746
Epoch: 4| Step: 2
Training loss: 4.327425956726074
Validation loss: 4.413204992417809
Epoch: 4| Step: 3
Training loss: 4.7360358238220215
Validation loss: 4.411519928801831
Epoch: 4| Step: 4
Training loss: 4.950974941253662
Validation loss: 4.405251293731251
Epoch: 4| Step: 5
Training loss: 4.382350921630859
Validation loss: 4.399836437307673
Epoch: 4| Step: 6
Training loss: 4.823266506195068
Validation loss: 4.395575739496904
Epoch: 4| Step: 7
Training loss: 4.266039848327637
Validation loss: 4.3921008796143015
Epoch: 3| Step: 0
Training loss: 5.096999168395996
Validation loss: 4.3859833178760335
Epoch: 4| Step: 1
Training loss: 3.900373935699463
Validation loss: 4.381157072327977
Epoch: 4| Step: 2
Training loss: 4.8672051429748535
Validation loss: 4.377993937018964
Epoch: 4| Step: 3
Training loss: 3.9414830207824707
Validation loss: 4.374641758074864
Epoch: 4| Step: 4
Training loss: 4.741913795471191
Validation loss: 4.372215082319521
Epoch: 4| Step: 5
Training loss: 4.655791282653809
Validation loss: 4.370076121186181
Epoch: 4| Step: 6
Training loss: 3.909022092819214
Validation loss: 4.36243477828211
Epoch: 4| Step: 7
Training loss: 5.321037292480469
Validation loss: 4.3581478681495724
Epoch: 4| Step: 0
Training loss: 4.459271430969238
Validation loss: 4.354319466103752
Epoch: 4| Step: 1
Training loss: 4.457769870758057
Validation loss: 4.349184125447445
Epoch: 4| Step: 2
Training loss: 4.518506050109863
Validation loss: 4.344464696568551
Epoch: 4| Step: 3
Training loss: 5.049908638000488
Validation loss: 4.340990931010075
Epoch: 4| Step: 4
Training loss: 4.179930686950684
Validation loss: 4.337736846731721
Epoch: 4| Step: 5
Training loss: 4.2536940574646
Validation loss: 4.335618749796915
Epoch: 4| Step: 6
Training loss: 4.573429584503174
Validation loss: 4.329043335194211
Epoch: 4| Step: 7
Training loss: 4.715658664703369
Validation loss: 4.322744314619105
Epoch: 5| Step: 0
Training loss: 3.794673204421997
Validation loss: 4.32151978650539
Epoch: 4| Step: 1
Training loss: 4.788741111755371
Validation loss: 4.316896726759218
Epoch: 4| Step: 2
Training loss: 4.453517913818359
Validation loss: 4.310494803696227
Epoch: 4| Step: 3
Training loss: 4.935183525085449
Validation loss: 4.306644288756007
Epoch: 4| Step: 4
Training loss: 4.381295204162598
Validation loss: 4.301413271924575
Epoch: 4| Step: 5
Training loss: 4.388800621032715
Validation loss: 4.299964599472156
Epoch: 4| Step: 6
Training loss: 4.535699844360352
Validation loss: 4.2939861249580655
Epoch: 4| Step: 7
Training loss: 4.677487850189209
Validation loss: 4.28827240484224
Epoch: 6| Step: 0
Training loss: 4.5804762840271
Validation loss: 4.286117413061128
Epoch: 4| Step: 1
Training loss: 4.843438625335693
Validation loss: 4.280466992220433
Epoch: 4| Step: 2
Training loss: 4.7987060546875
Validation loss: 4.274902844600541
Epoch: 4| Step: 3
Training loss: 4.072988986968994
Validation loss: 4.270401251401832
Epoch: 4| Step: 4
Training loss: 4.253355503082275
Validation loss: 4.265968775577682
Epoch: 4| Step: 5
Training loss: 4.412120819091797
Validation loss: 4.25967834321715
Epoch: 4| Step: 6
Training loss: 4.394423484802246
Validation loss: 4.257485098118405
Epoch: 4| Step: 7
Training loss: 4.363766670227051
Validation loss: 4.253363708797976
Epoch: 7| Step: 0
Training loss: 4.290035247802734
Validation loss: 4.245580031717424
Epoch: 4| Step: 1
Training loss: 4.178560733795166
Validation loss: 4.241260556008318
Epoch: 4| Step: 2
Training loss: 4.279022216796875
Validation loss: 4.240708203624479
Epoch: 4| Step: 3
Training loss: 4.382556438446045
Validation loss: 4.231232351536374
Epoch: 4| Step: 4
Training loss: 4.665440559387207
Validation loss: 4.228824708101561
Epoch: 4| Step: 5
Training loss: 4.0916314125061035
Validation loss: 4.225964731449704
Epoch: 4| Step: 6
Training loss: 4.4697265625
Validation loss: 4.220230733747963
Epoch: 4| Step: 7
Training loss: 5.08429479598999
Validation loss: 4.211799625012515
Epoch: 8| Step: 0
Training loss: 4.252209663391113
Validation loss: 4.2085337227197
Epoch: 4| Step: 1
Training loss: 4.398958206176758
Validation loss: 4.200876807137359
Epoch: 4| Step: 2
Training loss: 4.4828782081604
Validation loss: 4.196444574877512
Epoch: 4| Step: 3
Training loss: 4.145617485046387
Validation loss: 4.191037908732462
Epoch: 4| Step: 4
Training loss: 4.2318925857543945
Validation loss: 4.189271944032298
Epoch: 4| Step: 5
Training loss: 4.382114410400391
Validation loss: 4.182449591245582
Epoch: 4| Step: 6
Training loss: 4.418520927429199
Validation loss: 4.175011226599165
Epoch: 4| Step: 7
Training loss: 4.836110591888428
Validation loss: 4.169806816595064
Epoch: 9| Step: 0
Training loss: 4.492491722106934
Validation loss: 4.164039845089261
Epoch: 4| Step: 1
Training loss: 4.649641990661621
Validation loss: 4.1590863886497
Epoch: 4| Step: 2
Training loss: 5.123359680175781
Validation loss: 4.154424049871431
Epoch: 4| Step: 3
Training loss: 3.844715118408203
Validation loss: 4.145139749101598
Epoch: 4| Step: 4
Training loss: 3.9213180541992188
Validation loss: 4.139288267643332
Epoch: 4| Step: 5
Training loss: 4.709043025970459
Validation loss: 4.135194229565078
Epoch: 4| Step: 6
Training loss: 3.9406158924102783
Validation loss: 4.130489057774167
Epoch: 4| Step: 7
Training loss: 4.164445877075195
Validation loss: 4.1212415523666275
Epoch: 10| Step: 0
Training loss: 4.397131443023682
Validation loss: 4.118448048186817
Epoch: 4| Step: 1
Training loss: 4.338188648223877
Validation loss: 4.112283389345348
Epoch: 4| Step: 2
Training loss: 4.613025665283203
Validation loss: 4.102418899536133
Epoch: 4| Step: 3
Training loss: 4.060214042663574
Validation loss: 4.09946674923245
Epoch: 4| Step: 4
Training loss: 4.787617206573486
Validation loss: 4.091128808988942
Epoch: 4| Step: 5
Training loss: 4.222541809082031
Validation loss: 4.084464558594519
Epoch: 4| Step: 6
Training loss: 4.558775901794434
Validation loss: 4.0787000947719
Epoch: 4| Step: 7
Training loss: 3.536280870437622
Validation loss: 4.07091127368186
Epoch: 11| Step: 0
Training loss: 4.827838897705078
Validation loss: 4.067097619283113
Epoch: 4| Step: 1
Training loss: 4.195491790771484
Validation loss: 4.058331362635112
Epoch: 4| Step: 2
Training loss: 3.694542646408081
Validation loss: 4.055194923345991
Epoch: 4| Step: 3
Training loss: 4.3311567306518555
Validation loss: 4.04586878440363
Epoch: 4| Step: 4
Training loss: 4.152138710021973
Validation loss: 4.037045878472088
Epoch: 4| Step: 5
Training loss: 4.431805610656738
Validation loss: 4.031245152727306
Epoch: 4| Step: 6
Training loss: 3.721078872680664
Validation loss: 4.023156564012706
Epoch: 4| Step: 7
Training loss: 4.7841901779174805
Validation loss: 4.017748077996343
Epoch: 12| Step: 0
Training loss: 4.145832061767578
Validation loss: 4.00870847358978
Epoch: 4| Step: 1
Training loss: 4.025664329528809
Validation loss: 4.001023160467903
Epoch: 4| Step: 2
Training loss: 4.238524436950684
Validation loss: 3.9929365528573233
Epoch: 4| Step: 3
Training loss: 3.535443067550659
Validation loss: 3.984493423708909
Epoch: 4| Step: 4
Training loss: 4.0254693031311035
Validation loss: 3.9824732293327934
Epoch: 4| Step: 5
Training loss: 4.6594319343566895
Validation loss: 3.9703347254142485
Epoch: 4| Step: 6
Training loss: 4.623489856719971
Validation loss: 3.9621399152193137
Epoch: 4| Step: 7
Training loss: 4.483928203582764
Validation loss: 3.954448792574217
Epoch: 13| Step: 0
Training loss: 3.8574676513671875
Validation loss: 3.9454578289882742
Epoch: 4| Step: 1
Training loss: 4.181002616882324
Validation loss: 3.9334721633856247
Epoch: 4| Step: 2
Training loss: 4.046482086181641
Validation loss: 3.9328025262132824
Epoch: 4| Step: 3
Training loss: 4.237512588500977
Validation loss: 3.922309597619146
Epoch: 4| Step: 4
Training loss: 3.8648743629455566
Validation loss: 3.9112700524090007
Epoch: 4| Step: 5
Training loss: 4.032498836517334
Validation loss: 3.90015154433765
Epoch: 4| Step: 6
Training loss: 4.540407180786133
Validation loss: 3.896970935862699
Epoch: 4| Step: 7
Training loss: 4.534241199493408
Validation loss: 3.8850219232572925
Epoch: 14| Step: 0
Training loss: 3.896092176437378
Validation loss: 3.874974995208301
Epoch: 4| Step: 1
Training loss: 4.084221839904785
Validation loss: 3.8630443648468678
Epoch: 4| Step: 2
Training loss: 3.7404263019561768
Validation loss: 3.8576497122538176
Epoch: 4| Step: 3
Training loss: 4.006703853607178
Validation loss: 3.8443475781584815
Epoch: 4| Step: 4
Training loss: 4.585365295410156
Validation loss: 3.831079115970529
Epoch: 4| Step: 5
Training loss: 4.539845943450928
Validation loss: 3.824420592767729
Epoch: 4| Step: 6
Training loss: 3.8314616680145264
Validation loss: 3.8158510623218342
Epoch: 4| Step: 7
Training loss: 4.1120476722717285
Validation loss: 3.8068352088653783
Epoch: 15| Step: 0
Training loss: 3.6122238636016846
Validation loss: 3.793558158462854
Epoch: 4| Step: 1
Training loss: 4.3189697265625
Validation loss: 3.783540780595738
Epoch: 4| Step: 2
Training loss: 3.808946132659912
Validation loss: 3.773227928353728
Epoch: 4| Step: 3
Training loss: 4.413512706756592
Validation loss: 3.7655557196774927
Epoch: 4| Step: 4
Training loss: 3.8411247730255127
Validation loss: 3.753131125470717
Epoch: 4| Step: 5
Training loss: 4.347128868103027
Validation loss: 3.7460612101520567
Epoch: 4| Step: 6
Training loss: 3.647099018096924
Validation loss: 3.7313871898239466
Epoch: 4| Step: 7
Training loss: 4.284541130065918
Validation loss: 3.7213826574009956
Epoch: 16| Step: 0
Training loss: 4.199408531188965
Validation loss: 3.7069877377516933
Epoch: 4| Step: 1
Training loss: 4.356723785400391
Validation loss: 3.7011448925347636
Epoch: 4| Step: 2
Training loss: 3.707210063934326
Validation loss: 3.6830425022317352
Epoch: 4| Step: 3
Training loss: 4.734382629394531
Validation loss: 3.670210296301533
Epoch: 4| Step: 4
Training loss: 3.835550308227539
Validation loss: 3.659889890135621
Epoch: 4| Step: 5
Training loss: 3.510180950164795
Validation loss: 3.6512605783750685
Epoch: 4| Step: 6
Training loss: 3.480595111846924
Validation loss: 3.6332226417047515
Epoch: 4| Step: 7
Training loss: 3.871649980545044
Validation loss: 3.6216289722662176
Epoch: 17| Step: 0
Training loss: 4.478687286376953
Validation loss: 3.6077936879164882
Epoch: 4| Step: 1
Training loss: 3.420788526535034
Validation loss: 3.5989926667522183
Epoch: 4| Step: 2
Training loss: 4.026210784912109
Validation loss: 3.5845135784835267
Epoch: 4| Step: 3
Training loss: 4.011815071105957
Validation loss: 3.5700203652004543
Epoch: 4| Step: 4
Training loss: 3.340203046798706
Validation loss: 3.552774770654363
Epoch: 4| Step: 5
Training loss: 4.350766181945801
Validation loss: 3.543501922552534
Epoch: 4| Step: 6
Training loss: 3.862443208694458
Validation loss: 3.5266023642725224
Epoch: 4| Step: 7
Training loss: 3.551640033721924
Validation loss: 3.5149454092807906
Epoch: 18| Step: 0
Training loss: 3.4523239135742188
Validation loss: 3.4972528124884734
Epoch: 4| Step: 1
Training loss: 3.987536668777466
Validation loss: 3.486510170449456
Epoch: 4| Step: 2
Training loss: 4.321750640869141
Validation loss: 3.463992187445112
Epoch: 4| Step: 3
Training loss: 3.96893310546875
Validation loss: 3.455263727860485
Epoch: 4| Step: 4
Training loss: 3.8406434059143066
Validation loss: 3.437705943910338
Epoch: 4| Step: 5
Training loss: 3.631193161010742
Validation loss: 3.422667719477372
Epoch: 4| Step: 6
Training loss: 3.7054877281188965
Validation loss: 3.4069866979722496
Epoch: 4| Step: 7
Training loss: 3.415536880493164
Validation loss: 3.3911951325780194
Epoch: 19| Step: 0
Training loss: 2.9769439697265625
Validation loss: 3.378669740484773
Epoch: 4| Step: 1
Training loss: 4.122171878814697
Validation loss: 3.350844950984708
Epoch: 4| Step: 2
Training loss: 3.6356494426727295
Validation loss: 3.3456724719177906
Epoch: 4| Step: 3
Training loss: 3.3528847694396973
Validation loss: 3.328665054101738
Epoch: 4| Step: 4
Training loss: 3.7467598915100098
Validation loss: 3.3091553612578686
Epoch: 4| Step: 5
Training loss: 3.7975025177001953
Validation loss: 3.2961696617894893
Epoch: 4| Step: 6
Training loss: 3.8143506050109863
Validation loss: 3.2763443765022773
Epoch: 4| Step: 7
Training loss: 4.0970563888549805
Validation loss: 3.258574501215983
Epoch: 20| Step: 0
Training loss: 3.9128775596618652
Validation loss: 3.2417230331640448
Epoch: 4| Step: 1
Training loss: 3.5197906494140625
Validation loss: 3.2188665300822086
Epoch: 4| Step: 2
Training loss: 3.672527313232422
Validation loss: 3.205131270044999
Epoch: 4| Step: 3
Training loss: 3.8142409324645996
Validation loss: 3.1840377780173323
Epoch: 4| Step: 4
Training loss: 3.399766445159912
Validation loss: 3.164435002443602
Epoch: 4| Step: 5
Training loss: 3.6711204051971436
Validation loss: 3.144708345262267
Epoch: 4| Step: 6
Training loss: 3.287811279296875
Validation loss: 3.123131035043181
Epoch: 4| Step: 7
Training loss: 3.404412031173706
Validation loss: 3.1041292286605286
Epoch: 21| Step: 0
Training loss: 3.4084746837615967
Validation loss: 3.0868192902571865
Epoch: 4| Step: 1
Training loss: 3.813671112060547
Validation loss: 3.0634615661428986
Epoch: 4| Step: 2
Training loss: 3.6480820178985596
Validation loss: 3.0430267629005927
Epoch: 4| Step: 3
Training loss: 3.175724506378174
Validation loss: 3.0340684523685373
Epoch: 4| Step: 4
Training loss: 3.438936710357666
Validation loss: 3.006667461326654
Epoch: 4| Step: 5
Training loss: 3.674494981765747
Validation loss: 2.9777802752076292
Epoch: 4| Step: 6
Training loss: 3.5374035835266113
Validation loss: 2.9605788086815705
Epoch: 4| Step: 7
Training loss: 2.9788239002227783
Validation loss: 2.937594839137235
Epoch: 22| Step: 0
Training loss: 3.030538320541382
Validation loss: 2.928114510268616
Epoch: 4| Step: 1
Training loss: 2.7843096256256104
Validation loss: 2.9027329108697906
Epoch: 4| Step: 2
Training loss: 3.3383617401123047
Validation loss: 2.8875107799502584
Epoch: 4| Step: 3
Training loss: 3.6773781776428223
Validation loss: 2.8586487238355676
Epoch: 4| Step: 4
Training loss: 3.567004680633545
Validation loss: 2.8446194490940453
Epoch: 4| Step: 5
Training loss: 3.366062879562378
Validation loss: 2.8244894185512184
Epoch: 4| Step: 6
Training loss: 3.4700989723205566
Validation loss: 2.8026523041210587
Epoch: 4| Step: 7
Training loss: 3.321138381958008
Validation loss: 2.775909998434053
Epoch: 23| Step: 0
Training loss: 3.171846389770508
Validation loss: 2.7539729248705527
Epoch: 4| Step: 1
Training loss: 3.2773056030273438
Validation loss: 2.734685728018232
Epoch: 4| Step: 2
Training loss: 3.2402477264404297
Validation loss: 2.7180817127227783
Epoch: 4| Step: 3
Training loss: 2.6633048057556152
Validation loss: 2.6968753921042246
Epoch: 4| Step: 4
Training loss: 2.9773266315460205
Validation loss: 2.677913003688236
Epoch: 4| Step: 5
Training loss: 3.728884220123291
Validation loss: 2.6556272026446224
Epoch: 4| Step: 6
Training loss: 3.2453436851501465
Validation loss: 2.6374652042663356
Epoch: 4| Step: 7
Training loss: 3.1583220958709717
Validation loss: 2.613224250807179
Epoch: 24| Step: 0
Training loss: 2.9522831439971924
Validation loss: 2.592493715903742
Epoch: 4| Step: 1
Training loss: 3.30578351020813
Validation loss: 2.5703981368661784
Epoch: 4| Step: 2
Training loss: 3.02553129196167
Validation loss: 2.534441682074567
Epoch: 4| Step: 3
Training loss: 2.9265215396881104
Validation loss: 2.532752294334576
Epoch: 4| Step: 4
Training loss: 3.0859174728393555
Validation loss: 2.5078235735996164
Epoch: 4| Step: 5
Training loss: 3.1432464122772217
Validation loss: 2.4854268598899565
Epoch: 4| Step: 6
Training loss: 3.0527448654174805
Validation loss: 2.467558593201123
Epoch: 4| Step: 7
Training loss: 2.864370822906494
Validation loss: 2.44737118782757
Epoch: 25| Step: 0
Training loss: 2.822671413421631
Validation loss: 2.4141607696203877
Epoch: 4| Step: 1
Training loss: 2.789815902709961
Validation loss: 2.406820443036745
Epoch: 4| Step: 2
Training loss: 3.0743978023529053
Validation loss: 2.380308362219831
Epoch: 4| Step: 3
Training loss: 2.942239284515381
Validation loss: 2.374391077233733
Epoch: 4| Step: 4
Training loss: 3.0700876712799072
Validation loss: 2.3339187670097075
Epoch: 4| Step: 5
Training loss: 2.8235554695129395
Validation loss: 2.3289613878126625
Epoch: 4| Step: 6
Training loss: 2.7279000282287598
Validation loss: 2.3004513181370796
Epoch: 4| Step: 7
Training loss: 2.7868714332580566
Validation loss: 2.279505251122893
Epoch: 26| Step: 0
Training loss: 2.572061777114868
Validation loss: 2.258419017997577
Epoch: 4| Step: 1
Training loss: 2.494384288787842
Validation loss: 2.238266118138814
Epoch: 4| Step: 2
Training loss: 2.3485500812530518
Validation loss: 2.2103315857674577
Epoch: 4| Step: 3
Training loss: 3.0081005096435547
Validation loss: 2.1987923237917233
Epoch: 4| Step: 4
Training loss: 2.9806325435638428
Validation loss: 2.1713331260269495
Epoch: 4| Step: 5
Training loss: 2.782505512237549
Validation loss: 2.1458745963281864
Epoch: 4| Step: 6
Training loss: 2.7537732124328613
Validation loss: 2.139361809483535
Epoch: 4| Step: 7
Training loss: 2.8723690509796143
Validation loss: 2.1190521253956307
Epoch: 27| Step: 0
Training loss: 2.8419806957244873
Validation loss: 2.0917977712137237
Epoch: 4| Step: 1
Training loss: 2.544686794281006
Validation loss: 2.070429907428275
Epoch: 4| Step: 2
Training loss: 2.432039976119995
Validation loss: 2.0510527778872483
Epoch: 4| Step: 3
Training loss: 2.47900652885437
Validation loss: 2.0325186201136747
Epoch: 4| Step: 4
Training loss: 2.434182643890381
Validation loss: 2.014870625605686
Epoch: 4| Step: 5
Training loss: 2.993284225463867
Validation loss: 2.0095155873744606
Epoch: 4| Step: 6
Training loss: 2.6821250915527344
Validation loss: 1.9893273132310496
Epoch: 4| Step: 7
Training loss: 2.195756435394287
Validation loss: 1.9755520477569362
Epoch: 28| Step: 0
Training loss: 2.647061586380005
Validation loss: 1.9681211238284764
Epoch: 4| Step: 1
Training loss: 2.8099961280822754
Validation loss: 1.937085096784633
Epoch: 4| Step: 2
Training loss: 2.3280818462371826
Validation loss: 1.9248552974179494
Epoch: 4| Step: 3
Training loss: 2.3137571811676025
Validation loss: 1.8967174368796589
Epoch: 4| Step: 4
Training loss: 2.465266704559326
Validation loss: 1.879665452799351
Epoch: 4| Step: 5
Training loss: 2.451915979385376
Validation loss: 1.8818447178216289
Epoch: 4| Step: 6
Training loss: 2.2118141651153564
Validation loss: 1.8810506930454172
Epoch: 4| Step: 7
Training loss: 2.2874951362609863
Validation loss: 1.8608657215996611
Epoch: 29| Step: 0
Training loss: 2.219874620437622
Validation loss: 1.841480555294229
Epoch: 4| Step: 1
Training loss: 2.451464891433716
Validation loss: 1.8350193106013237
Epoch: 4| Step: 2
Training loss: 2.4553275108337402
Validation loss: 1.8232188705060122
Epoch: 4| Step: 3
Training loss: 2.711052417755127
Validation loss: 1.8121728691265737
Epoch: 4| Step: 4
Training loss: 2.068934440612793
Validation loss: 1.810143641430697
Epoch: 4| Step: 5
Training loss: 2.3401851654052734
Validation loss: 1.7943362846648951
Epoch: 4| Step: 6
Training loss: 2.24676775932312
Validation loss: 1.8033657862985735
Epoch: 4| Step: 7
Training loss: 2.081808567047119
Validation loss: 1.7818835321947826
Epoch: 30| Step: 0
Training loss: 2.778315305709839
Validation loss: 1.7918083341859228
Epoch: 4| Step: 1
Training loss: 2.1938395500183105
Validation loss: 1.7981704756510344
Epoch: 4| Step: 2
Training loss: 2.2770838737487793
Validation loss: 1.7813238694513445
Epoch: 4| Step: 3
Training loss: 2.035551071166992
Validation loss: 1.7926570803141422
Epoch: 4| Step: 4
Training loss: 2.1135177612304688
Validation loss: 1.7951633046856887
Epoch: 4| Step: 5
Training loss: 1.9813880920410156
Validation loss: 1.7849454365188269
Epoch: 4| Step: 6
Training loss: 2.411975145339966
Validation loss: 1.7863069704110675
Epoch: 4| Step: 7
Training loss: 2.2952990531921387
Validation loss: 1.801266839178346
Epoch: 31| Step: 0
Training loss: 2.022864818572998
Validation loss: 1.7959603517175577
Epoch: 4| Step: 1
Training loss: 2.1538524627685547
Validation loss: 1.7833294062305698
Epoch: 4| Step: 2
Training loss: 2.3436665534973145
Validation loss: 1.7817441962605758
Epoch: 4| Step: 3
Training loss: 1.7948544025421143
Validation loss: 1.793227888697343
Epoch: 4| Step: 4
Training loss: 2.5055336952209473
Validation loss: 1.8146735592711745
Epoch: 4| Step: 5
Training loss: 2.22227144241333
Validation loss: 1.8237434291153503
Epoch: 4| Step: 6
Training loss: 2.2766902446746826
Validation loss: 1.8033827543258667
Epoch: 4| Step: 7
Training loss: 2.3555800914764404
Validation loss: 1.8189647858091396
Epoch: 32| Step: 0
Training loss: 2.031604290008545
Validation loss: 1.8161979304800788
Epoch: 4| Step: 1
Training loss: 2.1411471366882324
Validation loss: 1.8313181640432894
Epoch: 4| Step: 2
Training loss: 2.309673547744751
Validation loss: 1.8340628455868728
Epoch: 4| Step: 3
Training loss: 2.005551815032959
Validation loss: 1.8341194159692997
Epoch: 4| Step: 4
Training loss: 2.173398017883301
Validation loss: 1.847491546500501
Epoch: 4| Step: 5
Training loss: 2.531728506088257
Validation loss: 1.8398361386155053
Epoch: 4| Step: 6
Training loss: 2.2852683067321777
Validation loss: 1.8464050593136025
Epoch: 4| Step: 7
Training loss: 1.9335601329803467
Validation loss: 1.8703166572310084
Epoch: 33| Step: 0
Training loss: 2.429126739501953
Validation loss: 1.863978455392577
Epoch: 4| Step: 1
Training loss: 2.201233386993408
Validation loss: 1.884582066707474
Epoch: 4| Step: 2
Training loss: 2.455599784851074
Validation loss: 1.8594268131599152
Epoch: 4| Step: 3
Training loss: 2.3009636402130127
Validation loss: 1.8765144142315542
Epoch: 4| Step: 4
Training loss: 1.7428309917449951
Validation loss: 1.8753585746820025
Epoch: 4| Step: 5
Training loss: 1.6818498373031616
Validation loss: 1.8680181237433453
Epoch: 4| Step: 6
Training loss: 2.4193191528320312
Validation loss: 1.8850342970100238
Epoch: 4| Step: 7
Training loss: 2.0909314155578613
Validation loss: 1.8925826772511434
Epoch: 34| Step: 0
Training loss: 2.4867186546325684
Validation loss: 1.862354902054766
Epoch: 4| Step: 1
Training loss: 2.064594268798828
Validation loss: 1.9111746969840508
Epoch: 4| Step: 2
Training loss: 2.4032883644104004
Validation loss: 1.884542950623327
Epoch: 4| Step: 3
Training loss: 1.65542471408844
Validation loss: 1.8733398897184743
Epoch: 4| Step: 4
Training loss: 2.223004102706909
Validation loss: 1.8843436661384088
Epoch: 4| Step: 5
Training loss: 2.071012020111084
Validation loss: 1.895260388902623
Epoch: 4| Step: 6
Training loss: 2.1893184185028076
Validation loss: 1.8816553071248445
Epoch: 4| Step: 7
Training loss: 2.2661752700805664
Validation loss: 1.8899464778762927
Epoch: 35| Step: 0
Training loss: 1.880833387374878
Validation loss: 1.9327531041001245
Epoch: 4| Step: 1
Training loss: 2.300293445587158
Validation loss: 1.8894283479923824
Epoch: 4| Step: 2
Training loss: 2.4069201946258545
Validation loss: 1.8687505987908344
Epoch: 4| Step: 3
Training loss: 2.6143412590026855
Validation loss: 1.9176289460641875
Epoch: 4| Step: 4
Training loss: 2.011518955230713
Validation loss: 1.8823590501606893
Epoch: 4| Step: 5
Training loss: 2.3021910190582275
Validation loss: 1.9140119981422699
Epoch: 4| Step: 6
Training loss: 1.9402077198028564
Validation loss: 1.8953683625022284
Epoch: 4| Step: 7
Training loss: 1.8951034545898438
Validation loss: 1.8937579702130325
Epoch: 36| Step: 0
Training loss: 2.2061798572540283
Validation loss: 1.9223047297635525
Epoch: 4| Step: 1
Training loss: 2.1794581413269043
Validation loss: 1.8959065787226177
Epoch: 4| Step: 2
Training loss: 2.101088762283325
Validation loss: 1.9168314316289887
Epoch: 4| Step: 3
Training loss: 2.7193498611450195
Validation loss: 1.923603653050155
Epoch: 4| Step: 4
Training loss: 2.2733232975006104
Validation loss: 1.9013831220942436
Epoch: 4| Step: 5
Training loss: 2.032820463180542
Validation loss: 1.8841807970897757
Epoch: 4| Step: 6
Training loss: 1.8429406881332397
Validation loss: 1.8990320859195517
Epoch: 4| Step: 7
Training loss: 1.9379892349243164
Validation loss: 1.904192749544871
Epoch: 37| Step: 0
Training loss: 2.4994378089904785
Validation loss: 1.8919631963153538
Epoch: 4| Step: 1
Training loss: 2.5367493629455566
Validation loss: 1.8988653138387117
Epoch: 4| Step: 2
Training loss: 1.5036320686340332
Validation loss: 1.9081959544325904
Epoch: 4| Step: 3
Training loss: 2.2281272411346436
Validation loss: 1.9049531006984572
Epoch: 4| Step: 4
Training loss: 2.0205256938934326
Validation loss: 1.93085891994641
Epoch: 4| Step: 5
Training loss: 2.120523452758789
Validation loss: 1.9072066768467855
Epoch: 4| Step: 6
Training loss: 2.2113354206085205
Validation loss: 1.9220093402931158
Epoch: 4| Step: 7
Training loss: 2.2055845260620117
Validation loss: 1.9169288067508945
Epoch: 38| Step: 0
Training loss: 2.180898666381836
Validation loss: 1.9201504292247964
Epoch: 4| Step: 1
Training loss: 2.3797945976257324
Validation loss: 1.9067434244018664
Epoch: 4| Step: 2
Training loss: 1.9506536722183228
Validation loss: 1.9396898557813904
Epoch: 4| Step: 3
Training loss: 2.1628193855285645
Validation loss: 1.8990560795763414
Epoch: 4| Step: 4
Training loss: 2.1496658325195312
Validation loss: 1.924288585031633
Epoch: 4| Step: 5
Training loss: 2.3454430103302
Validation loss: 1.9282353979220492
Epoch: 4| Step: 6
Training loss: 2.2206809520721436
Validation loss: 1.9391005047791297
Epoch: 4| Step: 7
Training loss: 1.9064804315567017
Validation loss: 1.911250085281811
Epoch: 39| Step: 0
Training loss: 2.450160503387451
Validation loss: 1.9185183957326326
Epoch: 4| Step: 1
Training loss: 2.38344144821167
Validation loss: 1.880880533362464
Epoch: 4| Step: 2
Training loss: 2.3807945251464844
Validation loss: 1.9171542683951288
Epoch: 4| Step: 3
Training loss: 2.059039354324341
Validation loss: 1.8975419620815799
Epoch: 4| Step: 4
Training loss: 2.7040627002716064
Validation loss: 1.9131864866764425
Epoch: 4| Step: 5
Training loss: 2.122509241104126
Validation loss: 1.9207550561685356
Epoch: 4| Step: 6
Training loss: 1.5231783390045166
Validation loss: 1.8953788349096723
Epoch: 4| Step: 7
Training loss: 1.7307418584823608
Validation loss: 1.9073171564143339
Epoch: 40| Step: 0
Training loss: 1.9030907154083252
Validation loss: 1.9114259850206992
Epoch: 4| Step: 1
Training loss: 2.100222110748291
Validation loss: 1.8960996385958555
Epoch: 4| Step: 2
Training loss: 1.8994386196136475
Validation loss: 1.891089426527778
Epoch: 4| Step: 3
Training loss: 2.311523675918579
Validation loss: 1.889601796651058
Epoch: 4| Step: 4
Training loss: 2.262514352798462
Validation loss: 1.9238238497603712
Epoch: 4| Step: 5
Training loss: 2.346755266189575
Validation loss: 1.9117634999666282
Epoch: 4| Step: 6
Training loss: 2.4968650341033936
Validation loss: 1.9007913671809136
Epoch: 4| Step: 7
Training loss: 2.09055757522583
Validation loss: 1.905164874714913
Epoch: 41| Step: 0
Training loss: 1.9334239959716797
Validation loss: 1.9060368160549686
Epoch: 4| Step: 1
Training loss: 2.075601100921631
Validation loss: 1.9046480106792862
Epoch: 4| Step: 2
Training loss: 1.99642014503479
Validation loss: 1.897033173403294
Epoch: 4| Step: 3
Training loss: 2.2347538471221924
Validation loss: 1.8997361059669111
Epoch: 4| Step: 4
Training loss: 2.2076148986816406
Validation loss: 1.902161244008181
Epoch: 4| Step: 5
Training loss: 2.0630409717559814
Validation loss: 1.9073806709522823
Epoch: 4| Step: 6
Training loss: 2.3997602462768555
Validation loss: 1.8941529586160784
Epoch: 4| Step: 7
Training loss: 2.3078558444976807
Validation loss: 1.9272522720501577
Epoch: 42| Step: 0
Training loss: 1.9650503396987915
Validation loss: 1.9136320172453956
Epoch: 4| Step: 1
Training loss: 2.5635323524475098
Validation loss: 1.9193548641616491
Epoch: 4| Step: 2
Training loss: 2.4689881801605225
Validation loss: 1.888670603148371
Epoch: 4| Step: 3
Training loss: 2.0844919681549072
Validation loss: 1.9081392622680116
Epoch: 4| Step: 4
Training loss: 1.6011626720428467
Validation loss: 1.9193140731441032
Epoch: 4| Step: 5
Training loss: 2.1663079261779785
Validation loss: 1.8999434006299905
Epoch: 4| Step: 6
Training loss: 2.208744764328003
Validation loss: 1.89161430502967
Epoch: 4| Step: 7
Training loss: 2.1981496810913086
Validation loss: 1.9000267939601871
Epoch: 43| Step: 0
Training loss: 2.266308307647705
Validation loss: 1.904801788947565
Epoch: 4| Step: 1
Training loss: 2.292397975921631
Validation loss: 1.8902110830485392
Epoch: 4| Step: 2
Training loss: 2.1161677837371826
Validation loss: 1.8898967135724405
Epoch: 4| Step: 3
Training loss: 2.1005260944366455
Validation loss: 1.903308439597809
Epoch: 4| Step: 4
Training loss: 2.0882248878479004
Validation loss: 1.8889129822202724
Epoch: 4| Step: 5
Training loss: 2.1477482318878174
Validation loss: 1.9058040166072707
Epoch: 4| Step: 6
Training loss: 2.3429675102233887
Validation loss: 1.9103221164332878
Epoch: 4| Step: 7
Training loss: 1.8600361347198486
Validation loss: 1.8924539029169425
Epoch: 44| Step: 0
Training loss: 2.1809215545654297
Validation loss: 1.8866148612482085
Epoch: 4| Step: 1
Training loss: 2.1048386096954346
Validation loss: 1.8923012163999269
Epoch: 4| Step: 2
Training loss: 1.8971809148788452
Validation loss: 1.8853539991721833
Epoch: 4| Step: 3
Training loss: 2.5210800170898438
Validation loss: 1.8913798126385366
Epoch: 4| Step: 4
Training loss: 1.9592918157577515
Validation loss: 1.894809348977727
Epoch: 4| Step: 5
Training loss: 2.20402455329895
Validation loss: 1.8957698430946406
Epoch: 4| Step: 6
Training loss: 1.9502770900726318
Validation loss: 1.8679874552239617
Epoch: 4| Step: 7
Training loss: 2.343383312225342
Validation loss: 1.8651783629287062
Epoch: 45| Step: 0
Training loss: 2.4099504947662354
Validation loss: 1.8995160541946081
Epoch: 4| Step: 1
Training loss: 2.2129669189453125
Validation loss: 1.8878238012464783
Epoch: 4| Step: 2
Training loss: 2.327620029449463
Validation loss: 1.8762242965561022
Epoch: 4| Step: 3
Training loss: 1.797298789024353
Validation loss: 1.9027556686950244
Epoch: 4| Step: 4
Training loss: 1.7450180053710938
Validation loss: 1.8767704397654361
Epoch: 4| Step: 5
Training loss: 2.420182228088379
Validation loss: 1.8990198450980427
Epoch: 4| Step: 6
Training loss: 2.4587855339050293
Validation loss: 1.8811879826964235
Epoch: 4| Step: 7
Training loss: 1.7979872226715088
Validation loss: 1.8801232550641616
Epoch: 46| Step: 0
Training loss: 1.998291015625
Validation loss: 1.873002464822728
Epoch: 4| Step: 1
Training loss: 1.919264554977417
Validation loss: 1.8935504148332336
Epoch: 4| Step: 2
Training loss: 2.1416175365448
Validation loss: 1.8822230623780394
Epoch: 4| Step: 3
Training loss: 2.0221962928771973
Validation loss: 1.901921413785262
Epoch: 4| Step: 4
Training loss: 2.466762065887451
Validation loss: 1.891310530600788
Epoch: 4| Step: 5
Training loss: 2.1947145462036133
Validation loss: 1.9082749550291103
Epoch: 4| Step: 6
Training loss: 2.2551491260528564
Validation loss: 1.885736147276789
Epoch: 4| Step: 7
Training loss: 2.1754231452941895
Validation loss: 1.8901163519715234
Epoch: 47| Step: 0
Training loss: 2.137880325317383
Validation loss: 1.8753418888119484
Epoch: 4| Step: 1
Training loss: 2.0515027046203613
Validation loss: 1.8837287769043187
Epoch: 4| Step: 2
Training loss: 2.2920846939086914
Validation loss: 1.902825700293342
Epoch: 4| Step: 3
Training loss: 2.5926966667175293
Validation loss: 1.904578868433726
Epoch: 4| Step: 4
Training loss: 1.768387794494629
Validation loss: 1.8883774143328769
Epoch: 4| Step: 5
Training loss: 1.9791545867919922
Validation loss: 1.9019981854253536
Epoch: 4| Step: 6
Training loss: 1.9070838689804077
Validation loss: 1.8897087694072037
Epoch: 4| Step: 7
Training loss: 2.3918936252593994
Validation loss: 1.897969187592431
Epoch: 48| Step: 0
Training loss: 2.4024651050567627
Validation loss: 1.8977237219433132
Epoch: 4| Step: 1
Training loss: 1.932531714439392
Validation loss: 1.9133370548701114
Epoch: 4| Step: 2
Training loss: 2.152137279510498
Validation loss: 1.8743472939772572
Epoch: 4| Step: 3
Training loss: 1.905308485031128
Validation loss: 1.8854161792521855
Epoch: 4| Step: 4
Training loss: 2.3751893043518066
Validation loss: 1.9030084164022543
Epoch: 4| Step: 5
Training loss: 2.319741725921631
Validation loss: 1.8823446987344206
Epoch: 4| Step: 6
Training loss: 2.098062515258789
Validation loss: 1.8740651204431658
Epoch: 4| Step: 7
Training loss: 1.973257303237915
Validation loss: 1.8736602608248485
Epoch: 49| Step: 0
Training loss: 2.513249158859253
Validation loss: 1.8825717538380795
Epoch: 4| Step: 1
Training loss: 2.0975961685180664
Validation loss: 1.9079914281694152
Epoch: 4| Step: 2
Training loss: 2.1685843467712402
Validation loss: 1.8895397349227248
Epoch: 4| Step: 3
Training loss: 1.9929249286651611
Validation loss: 1.9082619920908976
Epoch: 4| Step: 4
Training loss: 2.0706536769866943
Validation loss: 1.887431486047429
Epoch: 4| Step: 5
Training loss: 2.1275224685668945
Validation loss: 1.8876077374108404
Epoch: 4| Step: 6
Training loss: 2.138084888458252
Validation loss: 1.8990168588624583
Epoch: 4| Step: 7
Training loss: 1.9442460536956787
Validation loss: 1.91395986423218
Epoch: 50| Step: 0
Training loss: 2.334277629852295
Validation loss: 1.9202816469206228
Epoch: 4| Step: 1
Training loss: 2.1057372093200684
Validation loss: 1.9054387250392557
Epoch: 4| Step: 2
Training loss: 2.2241148948669434
Validation loss: 1.9293319458584133
Epoch: 4| Step: 3
Training loss: 2.469834327697754
Validation loss: 1.9199064755611281
Epoch: 4| Step: 4
Training loss: 1.8867967128753662
Validation loss: 1.9016037175981262
Epoch: 4| Step: 5
Training loss: 1.9769055843353271
Validation loss: 1.88234344660807
Epoch: 4| Step: 6
Training loss: 1.7983167171478271
Validation loss: 1.9159038221235756
Epoch: 4| Step: 7
Training loss: 2.359264373779297
Validation loss: 1.8988988956959127
Epoch: 51| Step: 0
Training loss: 2.282559633255005
Validation loss: 1.888135553263932
Epoch: 4| Step: 1
Training loss: 2.1734206676483154
Validation loss: 1.892156100101608
Epoch: 4| Step: 2
Training loss: 2.354166030883789
Validation loss: 1.8818351613531867
Epoch: 4| Step: 3
Training loss: 2.2151384353637695
Validation loss: 1.8812765088870371
Epoch: 4| Step: 4
Training loss: 2.0091946125030518
Validation loss: 1.892500481159567
Epoch: 4| Step: 5
Training loss: 2.218597173690796
Validation loss: 1.8785702093042058
Epoch: 4| Step: 6
Training loss: 1.829215407371521
Validation loss: 1.8968253530186714
Epoch: 4| Step: 7
Training loss: 1.9187860488891602
Validation loss: 1.9070648255108071
Epoch: 52| Step: 0
Training loss: 1.9420238733291626
Validation loss: 1.8877646614321701
Epoch: 4| Step: 1
Training loss: 2.5808682441711426
Validation loss: 1.8956768521302039
Epoch: 4| Step: 2
Training loss: 2.1640589237213135
Validation loss: 1.9056015983759929
Epoch: 4| Step: 3
Training loss: 2.1249265670776367
Validation loss: 1.9029792487192496
Epoch: 4| Step: 4
Training loss: 2.0375568866729736
Validation loss: 1.8927946699609002
Epoch: 4| Step: 5
Training loss: 2.1665637493133545
Validation loss: 1.895323156452865
Epoch: 4| Step: 6
Training loss: 2.2261855602264404
Validation loss: 1.9095621940900953
Epoch: 4| Step: 7
Training loss: 1.8474502563476562
Validation loss: 1.8867101532092196
Epoch: 53| Step: 0
Training loss: 2.0235862731933594
Validation loss: 1.867835963372704
Epoch: 4| Step: 1
Training loss: 2.330435037612915
Validation loss: 1.8944414536729992
Epoch: 4| Step: 2
Training loss: 2.348482131958008
Validation loss: 1.8956825990471051
Epoch: 4| Step: 3
Training loss: 1.9776830673217773
Validation loss: 1.867706800536286
Epoch: 4| Step: 4
Training loss: 1.9930976629257202
Validation loss: 1.8909819477753673
Epoch: 4| Step: 5
Training loss: 2.3574862480163574
Validation loss: 1.8897566375114936
Epoch: 4| Step: 6
Training loss: 1.9471330642700195
Validation loss: 1.889658969940899
Epoch: 4| Step: 7
Training loss: 2.097796678543091
Validation loss: 1.866715609598503
Epoch: 54| Step: 0
Training loss: 1.6141154766082764
Validation loss: 1.8710504667364436
Epoch: 4| Step: 1
Training loss: 1.9876216650009155
Validation loss: 1.8836041260108674
Epoch: 4| Step: 2
Training loss: 2.282057762145996
Validation loss: 1.8981260069840247
Epoch: 4| Step: 3
Training loss: 1.7816574573516846
Validation loss: 1.8855744746091554
Epoch: 4| Step: 4
Training loss: 2.392711639404297
Validation loss: 1.8951140179050912
Epoch: 4| Step: 5
Training loss: 2.5901119709014893
Validation loss: 1.8853167784299782
Epoch: 4| Step: 6
Training loss: 2.1968631744384766
Validation loss: 1.8881269307445279
Epoch: 4| Step: 7
Training loss: 2.1531264781951904
Validation loss: 1.8952940299356584
Epoch: 55| Step: 0
Training loss: 2.226107120513916
Validation loss: 1.9082915508489815
Epoch: 4| Step: 1
Training loss: 2.255279541015625
Validation loss: 1.891255271520546
Epoch: 4| Step: 2
Training loss: 1.9920545816421509
Validation loss: 1.9118204931561038
Epoch: 4| Step: 3
Training loss: 2.5002036094665527
Validation loss: 1.875664424553192
Epoch: 4| Step: 4
Training loss: 2.0118091106414795
Validation loss: 1.8860182916517738
Epoch: 4| Step: 5
Training loss: 1.8892714977264404
Validation loss: 1.8893205064663785
Epoch: 4| Step: 6
Training loss: 2.2103970050811768
Validation loss: 1.9136137301973302
Epoch: 4| Step: 7
Training loss: 1.951704740524292
Validation loss: 1.9082773109134152
Epoch: 56| Step: 0
Training loss: 2.0117733478546143
Validation loss: 1.8887195089738147
Epoch: 4| Step: 1
Training loss: 2.2092785835266113
Validation loss: 1.8773498072041024
Epoch: 4| Step: 2
Training loss: 2.011730909347534
Validation loss: 1.8904878467106991
Epoch: 4| Step: 3
Training loss: 2.2004647254943848
Validation loss: 1.9010028418877143
Epoch: 4| Step: 4
Training loss: 2.1251816749572754
Validation loss: 1.9229239045287208
Epoch: 4| Step: 5
Training loss: 2.070345878601074
Validation loss: 1.9157372147059268
Epoch: 4| Step: 6
Training loss: 2.1747992038726807
Validation loss: 1.913526246015974
Epoch: 4| Step: 7
Training loss: 2.1664109230041504
Validation loss: 1.9119914066877297
Epoch: 57| Step: 0
Training loss: 2.1318135261535645
Validation loss: 1.9110202120362425
Epoch: 4| Step: 1
Training loss: 2.2438857555389404
Validation loss: 1.9120986255810415
Epoch: 4| Step: 2
Training loss: 1.8664348125457764
Validation loss: 1.894927658623071
Epoch: 4| Step: 3
Training loss: 1.9511191844940186
Validation loss: 1.8935340908791523
Epoch: 4| Step: 4
Training loss: 2.1861767768859863
Validation loss: 1.8829425418977257
Epoch: 4| Step: 5
Training loss: 2.380927562713623
Validation loss: 1.9007864675933508
Epoch: 4| Step: 6
Training loss: 2.16808819770813
Validation loss: 1.9069971832440054
Epoch: 4| Step: 7
Training loss: 1.9632580280303955
Validation loss: 1.9112033715351022
Epoch: 58| Step: 0
Training loss: 1.846178412437439
Validation loss: 1.8989392999264834
Epoch: 4| Step: 1
Training loss: 2.2486977577209473
Validation loss: 1.910228425650288
Epoch: 4| Step: 2
Training loss: 2.1822521686553955
Validation loss: 1.8949681168837513
Epoch: 4| Step: 3
Training loss: 1.879045844078064
Validation loss: 1.9044128064628985
Epoch: 4| Step: 4
Training loss: 2.48966121673584
Validation loss: 1.910670373079588
Epoch: 4| Step: 5
Training loss: 1.9450479745864868
Validation loss: 1.8984081427828015
Epoch: 4| Step: 6
Training loss: 2.4043335914611816
Validation loss: 1.9156350094637424
Epoch: 4| Step: 7
Training loss: 1.9631999731063843
Validation loss: 1.9054939764009104
Epoch: 59| Step: 0
Training loss: 1.9747190475463867
Validation loss: 1.9252683421690686
Epoch: 4| Step: 1
Training loss: 1.950491189956665
Validation loss: 1.9239716161069254
Epoch: 4| Step: 2
Training loss: 2.1799237728118896
Validation loss: 1.9051396092064947
Epoch: 4| Step: 3
Training loss: 2.2147717475891113
Validation loss: 1.905404983664588
Epoch: 4| Step: 4
Training loss: 2.5020620822906494
Validation loss: 1.9121421455479355
Epoch: 4| Step: 5
Training loss: 1.6367263793945312
Validation loss: 1.905586608022237
Epoch: 4| Step: 6
Training loss: 2.174938917160034
Validation loss: 1.91059916568317
Epoch: 4| Step: 7
Training loss: 2.267634391784668
Validation loss: 1.9101430615075201
Epoch: 60| Step: 0
Training loss: 2.1132075786590576
Validation loss: 1.8842057632885392
Epoch: 4| Step: 1
Training loss: 2.0426673889160156
Validation loss: 1.870686942724873
Epoch: 4| Step: 2
Training loss: 1.8075065612792969
Validation loss: 1.878451721273738
Epoch: 4| Step: 3
Training loss: 2.1250128746032715
Validation loss: 1.9038894622445963
Epoch: 4| Step: 4
Training loss: 2.347407579421997
Validation loss: 1.8867578986737368
Epoch: 4| Step: 5
Training loss: 1.8898584842681885
Validation loss: 1.8952856852853899
Epoch: 4| Step: 6
Training loss: 2.082679271697998
Validation loss: 1.9027512030635807
Epoch: 4| Step: 7
Training loss: 2.468172550201416
Validation loss: 1.9107646316075497
Epoch: 61| Step: 0
Training loss: 2.2039923667907715
Validation loss: 1.9028082305578877
Epoch: 4| Step: 1
Training loss: 1.8529736995697021
Validation loss: 1.8969602799244065
Epoch: 4| Step: 2
Training loss: 2.0289604663848877
Validation loss: 1.9010688212278077
Epoch: 4| Step: 3
Training loss: 2.3606159687042236
Validation loss: 1.907653763997469
Epoch: 4| Step: 4
Training loss: 2.1254193782806396
Validation loss: 1.9161227203959184
Epoch: 4| Step: 5
Training loss: 1.9171924591064453
Validation loss: 1.9238914500037543
Epoch: 4| Step: 6
Training loss: 2.083503246307373
Validation loss: 1.8920261139492336
Epoch: 4| Step: 7
Training loss: 2.335486888885498
Validation loss: 1.9222040802454776
Epoch: 62| Step: 0
Training loss: 2.188220500946045
Validation loss: 1.9078937940460314
Epoch: 4| Step: 1
Training loss: 1.716448187828064
Validation loss: 1.9213260420792395
Epoch: 4| Step: 2
Training loss: 2.1394925117492676
Validation loss: 1.9078596770334586
Epoch: 4| Step: 3
Training loss: 1.9742380380630493
Validation loss: 1.947582013315434
Epoch: 4| Step: 4
Training loss: 2.3080952167510986
Validation loss: 1.9199217274892244
Epoch: 4| Step: 5
Training loss: 1.851449966430664
Validation loss: 1.9025176163199995
Epoch: 4| Step: 6
Training loss: 2.2605514526367188
Validation loss: 1.921821878110762
Epoch: 4| Step: 7
Training loss: 2.386343002319336
Validation loss: 1.9427644974893803
Epoch: 63| Step: 0
Training loss: 2.1162168979644775
Validation loss: 1.9131973244303422
Epoch: 4| Step: 1
Training loss: 1.8585764169692993
Validation loss: 1.9247978162422454
Epoch: 4| Step: 2
Training loss: 2.2924582958221436
Validation loss: 1.915600405322562
Epoch: 4| Step: 3
Training loss: 2.027083158493042
Validation loss: 1.9036664310976756
Epoch: 4| Step: 4
Training loss: 2.0006606578826904
Validation loss: 1.9200313897441617
Epoch: 4| Step: 5
Training loss: 2.785472869873047
Validation loss: 1.8990499818925377
Epoch: 4| Step: 6
Training loss: 1.8548309803009033
Validation loss: 1.9252975527331126
Epoch: 4| Step: 7
Training loss: 1.9071903228759766
Validation loss: 1.8998822222510687
Epoch: 64| Step: 0
Training loss: 1.8363984823226929
Validation loss: 1.8802266000843735
Epoch: 4| Step: 1
Training loss: 1.9097038507461548
Validation loss: 1.9282145054220297
Epoch: 4| Step: 2
Training loss: 1.8784282207489014
Validation loss: 1.9197519160003114
Epoch: 4| Step: 3
Training loss: 2.225599765777588
Validation loss: 1.921108615484169
Epoch: 4| Step: 4
Training loss: 2.5619137287139893
Validation loss: 1.903353137078045
Epoch: 4| Step: 5
Training loss: 2.2838053703308105
Validation loss: 1.8966070267793944
Epoch: 4| Step: 6
Training loss: 2.2570271492004395
Validation loss: 1.9088154576665206
Epoch: 4| Step: 7
Training loss: 1.9535315036773682
Validation loss: 1.8905464050581129
Epoch: 65| Step: 0
Training loss: 2.328941822052002
Validation loss: 1.9073373722515519
Epoch: 4| Step: 1
Training loss: 2.450373888015747
Validation loss: 1.8924683778406046
Epoch: 4| Step: 2
Training loss: 2.30329966545105
Validation loss: 1.888360607538292
Epoch: 4| Step: 3
Training loss: 1.9328107833862305
Validation loss: 1.8998433943275068
Epoch: 4| Step: 4
Training loss: 2.0209832191467285
Validation loss: 1.8781328295632231
Epoch: 4| Step: 5
Training loss: 2.0207648277282715
Validation loss: 1.9072467474628696
Epoch: 4| Step: 6
Training loss: 1.8394050598144531
Validation loss: 1.8819235983512383
Epoch: 4| Step: 7
Training loss: 1.9270429611206055
Validation loss: 1.9109707101643514
Epoch: 66| Step: 0
Training loss: 1.8769843578338623
Validation loss: 1.8794737891327562
Epoch: 4| Step: 1
Training loss: 2.29520845413208
Validation loss: 1.8772147062013476
Epoch: 4| Step: 2
Training loss: 2.0658836364746094
Validation loss: 1.8888833102562446
Epoch: 4| Step: 3
Training loss: 2.137052059173584
Validation loss: 1.892224838407777
Epoch: 4| Step: 4
Training loss: 2.2249112129211426
Validation loss: 1.8911195667527563
Epoch: 4| Step: 5
Training loss: 1.983268141746521
Validation loss: 1.8999800176071606
Epoch: 4| Step: 6
Training loss: 2.472608804702759
Validation loss: 1.9284003021048128
Epoch: 4| Step: 7
Training loss: 1.7120170593261719
Validation loss: 1.8915429106719202
Epoch: 67| Step: 0
Training loss: 1.864161729812622
Validation loss: 1.9110447502822328
Epoch: 4| Step: 1
Training loss: 1.8329954147338867
Validation loss: 1.9158817280968317
Epoch: 4| Step: 2
Training loss: 2.4437427520751953
Validation loss: 1.8884977977052868
Epoch: 4| Step: 3
Training loss: 2.301041603088379
Validation loss: 1.9262775225605038
Epoch: 4| Step: 4
Training loss: 1.9853824377059937
Validation loss: 1.9025957026927591
Epoch: 4| Step: 5
Training loss: 2.078784704208374
Validation loss: 1.8995284193711315
Epoch: 4| Step: 6
Training loss: 2.135822057723999
Validation loss: 1.9236876733011479
Epoch: 4| Step: 7
Training loss: 2.174813985824585
Validation loss: 1.9289377207378688
Epoch: 68| Step: 0
Training loss: 2.0593223571777344
Validation loss: 1.9250784709299211
Epoch: 4| Step: 1
Training loss: 1.8107502460479736
Validation loss: 1.9209898675946022
Epoch: 4| Step: 2
Training loss: 2.510308265686035
Validation loss: 1.9120312723324453
Epoch: 4| Step: 3
Training loss: 2.388780117034912
Validation loss: 1.907625594585062
Epoch: 4| Step: 4
Training loss: 2.038604259490967
Validation loss: 1.9128384795977915
Epoch: 4| Step: 5
Training loss: 2.0070149898529053
Validation loss: 1.9082939839191575
Epoch: 4| Step: 6
Training loss: 2.041577100753784
Validation loss: 1.9027847180263602
Epoch: 4| Step: 7
Training loss: 1.9664547443389893
Validation loss: 1.8949724298586947
Epoch: 69| Step: 0
Training loss: 2.1183342933654785
Validation loss: 1.8860382905109323
Epoch: 4| Step: 1
Training loss: 2.046440839767456
Validation loss: 1.9083125394025295
Epoch: 4| Step: 2
Training loss: 2.241344928741455
Validation loss: 1.8902986993034967
Epoch: 4| Step: 3
Training loss: 1.886526107788086
Validation loss: 1.8994972637231402
Epoch: 4| Step: 4
Training loss: 2.073148727416992
Validation loss: 1.884283626679894
Epoch: 4| Step: 5
Training loss: 2.0620124340057373
Validation loss: 1.8987826683538422
Epoch: 4| Step: 6
Training loss: 1.9729223251342773
Validation loss: 1.904806545312456
Epoch: 4| Step: 7
Training loss: 2.3552792072296143
Validation loss: 1.8822655214680184
Epoch: 70| Step: 0
Training loss: 2.2187514305114746
Validation loss: 1.8900086605291573
Epoch: 4| Step: 1
Training loss: 1.537522315979004
Validation loss: 1.8900520261243092
Epoch: 4| Step: 2
Training loss: 2.27095365524292
Validation loss: 1.885648408382059
Epoch: 4| Step: 3
Training loss: 2.39104962348938
Validation loss: 1.9013937857511232
Epoch: 4| Step: 4
Training loss: 1.9766861200332642
Validation loss: 1.9043432053902167
Epoch: 4| Step: 5
Training loss: 2.164310932159424
Validation loss: 1.8937653980666784
Epoch: 4| Step: 6
Training loss: 2.072525978088379
Validation loss: 1.90193977973444
Epoch: 4| Step: 7
Training loss: 2.1175849437713623
Validation loss: 1.8862604425965452
Epoch: 71| Step: 0
Training loss: 2.1703484058380127
Validation loss: 1.9038345470702907
Epoch: 4| Step: 1
Training loss: 2.210134506225586
Validation loss: 1.900563631126349
Epoch: 4| Step: 2
Training loss: 1.7960933446884155
Validation loss: 1.9067113519572525
Epoch: 4| Step: 3
Training loss: 2.148864269256592
Validation loss: 1.8769954846059675
Epoch: 4| Step: 4
Training loss: 1.8911689519882202
Validation loss: 1.9001612560354548
Epoch: 4| Step: 5
Training loss: 1.9882055521011353
Validation loss: 1.8891392877633624
Epoch: 4| Step: 6
Training loss: 2.342092514038086
Validation loss: 1.8950823485422477
Epoch: 4| Step: 7
Training loss: 2.206327438354492
Validation loss: 1.894535690760441
Epoch: 72| Step: 0
Training loss: 2.475116729736328
Validation loss: 1.8859606535314657
Epoch: 4| Step: 1
Training loss: 2.03397536277771
Validation loss: 1.8929609875027225
Epoch: 4| Step: 2
Training loss: 1.7722692489624023
Validation loss: 1.8875120192122974
Epoch: 4| Step: 3
Training loss: 2.072876453399658
Validation loss: 1.8984666591067967
Epoch: 4| Step: 4
Training loss: 2.403318405151367
Validation loss: 1.8887044928914352
Epoch: 4| Step: 5
Training loss: 2.3699676990509033
Validation loss: 1.9125781762514182
Epoch: 4| Step: 6
Training loss: 2.0175395011901855
Validation loss: 1.88440545342809
Epoch: 4| Step: 7
Training loss: 1.541516661643982
Validation loss: 1.8949402159066508
Epoch: 73| Step: 0
Training loss: 2.082087278366089
Validation loss: 1.9003224904588658
Epoch: 4| Step: 1
Training loss: 2.3922364711761475
Validation loss: 1.886421451465689
Epoch: 4| Step: 2
Training loss: 2.1999590396881104
Validation loss: 1.9026205153774014
Epoch: 4| Step: 3
Training loss: 2.0424435138702393
Validation loss: 1.8898183407543374
Epoch: 4| Step: 4
Training loss: 2.136195659637451
Validation loss: 1.9067573684582608
Epoch: 4| Step: 5
Training loss: 2.1005496978759766
Validation loss: 1.9019690940705993
Epoch: 4| Step: 6
Training loss: 2.003145456314087
Validation loss: 1.9159038598588902
Epoch: 4| Step: 7
Training loss: 1.8244597911834717
Validation loss: 1.9174324754330752
Epoch: 74| Step: 0
Training loss: 2.2061634063720703
Validation loss: 1.9258269011545524
Epoch: 4| Step: 1
Training loss: 2.206881284713745
Validation loss: 1.9030438515779784
Epoch: 4| Step: 2
Training loss: 1.5669453144073486
Validation loss: 1.9077208393769298
Epoch: 4| Step: 3
Training loss: 2.102753162384033
Validation loss: 1.9162372650860025
Epoch: 4| Step: 4
Training loss: 2.2463207244873047
Validation loss: 1.9043735171393525
Epoch: 4| Step: 5
Training loss: 2.2273025512695312
Validation loss: 1.8967477769302807
Epoch: 4| Step: 6
Training loss: 2.2360424995422363
Validation loss: 1.910613381605354
Epoch: 4| Step: 7
Training loss: 1.8098541498184204
Validation loss: 1.8876409590673104
Epoch: 75| Step: 0
Training loss: 2.3098835945129395
Validation loss: 1.902019938119024
Epoch: 4| Step: 1
Training loss: 1.9417225122451782
Validation loss: 1.919297821230168
Epoch: 4| Step: 2
Training loss: 1.9812252521514893
Validation loss: 1.91171726562994
Epoch: 4| Step: 3
Training loss: 2.1484787464141846
Validation loss: 1.8930709422063485
Epoch: 4| Step: 4
Training loss: 2.252178907394409
Validation loss: 1.9111518568272212
Epoch: 4| Step: 5
Training loss: 1.963854193687439
Validation loss: 1.8933082741799114
Epoch: 4| Step: 6
Training loss: 2.3336405754089355
Validation loss: 1.8995579738411115
Epoch: 4| Step: 7
Training loss: 1.850242257118225
Validation loss: 1.903403939103051
Epoch: 76| Step: 0
Training loss: 1.8943824768066406
Validation loss: 1.8925203796770933
Epoch: 4| Step: 1
Training loss: 1.976910948753357
Validation loss: 1.8980847511360113
Epoch: 4| Step: 2
Training loss: 2.2612996101379395
Validation loss: 1.8896802046316132
Epoch: 4| Step: 3
Training loss: 2.342081069946289
Validation loss: 1.8838147122225315
Epoch: 4| Step: 4
Training loss: 1.8743584156036377
Validation loss: 1.9061044497455624
Epoch: 4| Step: 5
Training loss: 2.1666226387023926
Validation loss: 1.9014362679968635
Epoch: 4| Step: 6
Training loss: 2.0679125785827637
Validation loss: 1.8907816830298882
Epoch: 4| Step: 7
Training loss: 2.1219801902770996
Validation loss: 1.8898629524724946
Epoch: 77| Step: 0
Training loss: 1.8518407344818115
Validation loss: 1.888897978144584
Epoch: 4| Step: 1
Training loss: 1.8132463693618774
Validation loss: 1.893966555595398
Epoch: 4| Step: 2
Training loss: 2.432947874069214
Validation loss: 1.8977958624311488
Epoch: 4| Step: 3
Training loss: 2.117544651031494
Validation loss: 1.9075214331098598
Epoch: 4| Step: 4
Training loss: 2.3290181159973145
Validation loss: 1.8993582245257261
Epoch: 4| Step: 5
Training loss: 2.0979645252227783
Validation loss: 1.8918398987475058
Epoch: 4| Step: 6
Training loss: 1.9935203790664673
Validation loss: 1.903056283648923
Epoch: 4| Step: 7
Training loss: 2.0178322792053223
Validation loss: 1.8993992539618512
Epoch: 78| Step: 0
Training loss: 2.031987428665161
Validation loss: 1.8710377602268466
Epoch: 4| Step: 1
Training loss: 2.0013175010681152
Validation loss: 1.8805243351476655
Epoch: 4| Step: 2
Training loss: 2.271674633026123
Validation loss: 1.8948745393066955
Epoch: 4| Step: 3
Training loss: 2.1908233165740967
Validation loss: 1.8980571391771166
Epoch: 4| Step: 4
Training loss: 1.8065564632415771
Validation loss: 1.9138093011842356
Epoch: 4| Step: 5
Training loss: 2.289332389831543
Validation loss: 1.896873039307354
Epoch: 4| Step: 6
Training loss: 2.2024338245391846
Validation loss: 1.8826344201890686
Epoch: 4| Step: 7
Training loss: 1.8701595067977905
Validation loss: 1.8987857283448144
Epoch: 79| Step: 0
Training loss: 1.755976915359497
Validation loss: 1.9058009583315403
Epoch: 4| Step: 1
Training loss: 2.526811122894287
Validation loss: 1.8904748554710005
Epoch: 4| Step: 2
Training loss: 1.8468612432479858
Validation loss: 1.9088427969020048
Epoch: 4| Step: 3
Training loss: 2.0886454582214355
Validation loss: 1.8812116427387264
Epoch: 4| Step: 4
Training loss: 2.1874585151672363
Validation loss: 1.9134057614443114
Epoch: 4| Step: 5
Training loss: 2.1172919273376465
Validation loss: 1.9107613872281082
Epoch: 4| Step: 6
Training loss: 1.9997459650039673
Validation loss: 1.8997830452678872
Epoch: 4| Step: 7
Training loss: 2.0785276889801025
Validation loss: 1.9156341432667465
Epoch: 80| Step: 0
Training loss: 2.3931961059570312
Validation loss: 1.9244018741648832
Epoch: 4| Step: 1
Training loss: 1.9773495197296143
Validation loss: 1.9165986613403978
Epoch: 4| Step: 2
Training loss: 2.083927631378174
Validation loss: 1.8933758855723648
Epoch: 4| Step: 3
Training loss: 2.0256049633026123
Validation loss: 1.9113118031042085
Epoch: 4| Step: 4
Training loss: 1.988258719444275
Validation loss: 1.91338869736349
Epoch: 4| Step: 5
Training loss: 1.8691446781158447
Validation loss: 1.8962470172978134
Epoch: 4| Step: 6
Training loss: 2.261448383331299
Validation loss: 1.9035067386764417
Epoch: 4| Step: 7
Training loss: 1.9610557556152344
Validation loss: 1.9270660825770536
Epoch: 81| Step: 0
Training loss: 2.3482069969177246
Validation loss: 1.9018125799920063
Epoch: 4| Step: 1
Training loss: 1.927345871925354
Validation loss: 1.903930821864725
Epoch: 4| Step: 2
Training loss: 1.7263519763946533
Validation loss: 1.8990182018966126
Epoch: 4| Step: 3
Training loss: 2.3966851234436035
Validation loss: 1.9314475771334532
Epoch: 4| Step: 4
Training loss: 2.0884854793548584
Validation loss: 1.9178278051691948
Epoch: 4| Step: 5
Training loss: 2.0062451362609863
Validation loss: 1.9210923644278546
Epoch: 4| Step: 6
Training loss: 1.9611648321151733
Validation loss: 1.907665098313805
Epoch: 4| Step: 7
Training loss: 2.2234628200531006
Validation loss: 1.907739896568463
Epoch: 82| Step: 0
Training loss: 2.458611249923706
Validation loss: 1.895001574385938
Epoch: 4| Step: 1
Training loss: 1.9305317401885986
Validation loss: 1.9013960035584814
Epoch: 4| Step: 2
Training loss: 2.112607479095459
Validation loss: 1.9181391395253242
Epoch: 4| Step: 3
Training loss: 2.0777838230133057
Validation loss: 1.9100775650079302
Epoch: 4| Step: 4
Training loss: 2.0537877082824707
Validation loss: 1.9069848077760325
Epoch: 4| Step: 5
Training loss: 1.6799522638320923
Validation loss: 1.8784357326493846
Epoch: 4| Step: 6
Training loss: 2.054056406021118
Validation loss: 1.9109751577857588
Epoch: 4| Step: 7
Training loss: 2.2262935638427734
Validation loss: 1.9104502269689985
Epoch: 83| Step: 0
Training loss: 2.1588547229766846
Validation loss: 1.9018014832366286
Epoch: 4| Step: 1
Training loss: 2.2049357891082764
Validation loss: 1.910241861137555
Epoch: 4| Step: 2
Training loss: 2.536332607269287
Validation loss: 1.9145874556877631
Epoch: 4| Step: 3
Training loss: 2.1396870613098145
Validation loss: 1.907312533838286
Epoch: 4| Step: 4
Training loss: 1.8360822200775146
Validation loss: 1.9201577395843945
Epoch: 4| Step: 5
Training loss: 1.6338484287261963
Validation loss: 1.9070557947639082
Epoch: 4| Step: 6
Training loss: 2.104750156402588
Validation loss: 1.91275688727125
Epoch: 4| Step: 7
Training loss: 1.986364722251892
Validation loss: 1.920561882231733
Epoch: 84| Step: 0
Training loss: 1.924261450767517
Validation loss: 1.9034428390667593
Epoch: 4| Step: 1
Training loss: 1.6983261108398438
Validation loss: 1.90053202093934
Epoch: 4| Step: 2
Training loss: 2.394421100616455
Validation loss: 1.922347619379167
Epoch: 4| Step: 3
Training loss: 1.9757211208343506
Validation loss: 1.9272754483943364
Epoch: 4| Step: 4
Training loss: 2.239866256713867
Validation loss: 1.9183972567963086
Epoch: 4| Step: 5
Training loss: 2.1221508979797363
Validation loss: 1.9111371897965026
Epoch: 4| Step: 6
Training loss: 2.2796571254730225
Validation loss: 1.9232163189126432
Epoch: 4| Step: 7
Training loss: 1.9028972387313843
Validation loss: 1.8982695692734752
Epoch: 85| Step: 0
Training loss: 2.155524730682373
Validation loss: 1.9187153792209763
Epoch: 4| Step: 1
Training loss: 1.7409223318099976
Validation loss: 1.9254806899338317
Epoch: 4| Step: 2
Training loss: 2.3876049518585205
Validation loss: 1.9112242829027792
Epoch: 4| Step: 3
Training loss: 2.012880325317383
Validation loss: 1.9057965741740714
Epoch: 4| Step: 4
Training loss: 1.9877220392227173
Validation loss: 1.912564414868252
Epoch: 4| Step: 5
Training loss: 2.261889696121216
Validation loss: 1.8987755998433065
Epoch: 4| Step: 6
Training loss: 2.1151561737060547
Validation loss: 1.8984288114437955
Epoch: 4| Step: 7
Training loss: 1.8835623264312744
Validation loss: 1.9049072076948426
Epoch: 86| Step: 0
Training loss: 2.244459629058838
Validation loss: 1.916646718121261
Epoch: 4| Step: 1
Training loss: 2.1496291160583496
Validation loss: 1.9201017575298283
Epoch: 4| Step: 2
Training loss: 1.989937424659729
Validation loss: 1.9240893717292402
Epoch: 4| Step: 3
Training loss: 2.152803421020508
Validation loss: 1.9040640318136421
Epoch: 4| Step: 4
Training loss: 1.984135627746582
Validation loss: 1.8919974805639803
Epoch: 4| Step: 5
Training loss: 1.9936645030975342
Validation loss: 1.9015934415858426
Epoch: 4| Step: 6
Training loss: 2.124901294708252
Validation loss: 1.9036616181298125
Epoch: 4| Step: 7
Training loss: 1.847778558731079
Validation loss: 1.8960797512273995
Epoch: 87| Step: 0
Training loss: 2.0383834838867188
Validation loss: 1.898815835122582
Epoch: 4| Step: 1
Training loss: 2.106877326965332
Validation loss: 1.908912647542336
Epoch: 4| Step: 2
Training loss: 1.7311944961547852
Validation loss: 1.9122507254854382
Epoch: 4| Step: 3
Training loss: 2.244767665863037
Validation loss: 1.925045003136285
Epoch: 4| Step: 4
Training loss: 1.721334457397461
Validation loss: 1.9288705904706775
Epoch: 4| Step: 5
Training loss: 2.42000150680542
Validation loss: 1.9024011625660409
Epoch: 4| Step: 6
Training loss: 2.412018299102783
Validation loss: 1.9239194496072454
Epoch: 4| Step: 7
Training loss: 1.8421733379364014
Validation loss: 1.9207829580032567
Epoch: 88| Step: 0
Training loss: 2.25954270362854
Validation loss: 1.8879153857128226
Epoch: 4| Step: 1
Training loss: 2.0793747901916504
Validation loss: 1.9315277775414557
Epoch: 4| Step: 2
Training loss: 2.3931918144226074
Validation loss: 1.9035818722608278
Epoch: 4| Step: 3
Training loss: 2.182185649871826
Validation loss: 1.9020176002447553
Epoch: 4| Step: 4
Training loss: 1.969233512878418
Validation loss: 1.898923146638939
Epoch: 4| Step: 5
Training loss: 1.919159173965454
Validation loss: 1.922197419962437
Epoch: 4| Step: 6
Training loss: 2.25594425201416
Validation loss: 1.9003378178575914
Epoch: 4| Step: 7
Training loss: 1.357178807258606
Validation loss: 1.9231789257886598
Epoch: 89| Step: 0
Training loss: 1.9143222570419312
Validation loss: 1.9085415164343744
Epoch: 4| Step: 1
Training loss: 1.7858327627182007
Validation loss: 1.902548083298498
Epoch: 4| Step: 2
Training loss: 2.4926958084106445
Validation loss: 1.908527156431898
Epoch: 4| Step: 3
Training loss: 2.473818302154541
Validation loss: 1.928808590491041
Epoch: 4| Step: 4
Training loss: 2.1654751300811768
Validation loss: 1.913063876062846
Epoch: 4| Step: 5
Training loss: 2.0173144340515137
Validation loss: 1.9228137448537264
Epoch: 4| Step: 6
Training loss: 1.5540740489959717
Validation loss: 1.905081895615557
Epoch: 4| Step: 7
Training loss: 2.0718016624450684
Validation loss: 1.9289028558799688
Epoch: 90| Step: 0
Training loss: 2.140056610107422
Validation loss: 1.942482606970149
Epoch: 4| Step: 1
Training loss: 1.930320382118225
Validation loss: 1.9123161559482273
Epoch: 4| Step: 2
Training loss: 2.0935897827148438
Validation loss: 1.9275685325800944
Epoch: 4| Step: 3
Training loss: 2.2123656272888184
Validation loss: 1.919843138550683
Epoch: 4| Step: 4
Training loss: 2.1951467990875244
Validation loss: 1.924266053618287
Epoch: 4| Step: 5
Training loss: 2.0866715908050537
Validation loss: 1.890739456355143
Epoch: 4| Step: 6
Training loss: 1.7789344787597656
Validation loss: 1.891605287147083
Epoch: 4| Step: 7
Training loss: 2.0920040607452393
Validation loss: 1.8892400419111732
Epoch: 91| Step: 0
Training loss: 2.0607707500457764
Validation loss: 1.894399683252513
Epoch: 4| Step: 1
Training loss: 2.1251707077026367
Validation loss: 1.8981163407401216
Epoch: 4| Step: 2
Training loss: 2.2699198722839355
Validation loss: 1.8853826051135716
Epoch: 4| Step: 3
Training loss: 2.0874457359313965
Validation loss: 1.8870362755205992
Epoch: 4| Step: 4
Training loss: 2.2711830139160156
Validation loss: 1.9144649471310402
Epoch: 4| Step: 5
Training loss: 2.051881790161133
Validation loss: 1.8998502484328454
Epoch: 4| Step: 6
Training loss: 1.2134817838668823
Validation loss: 1.9051978708171158
Epoch: 4| Step: 7
Training loss: 2.3072144985198975
Validation loss: 1.9019706026255656
Epoch: 92| Step: 0
Training loss: 1.8617843389511108
Validation loss: 1.8968383108111595
Epoch: 4| Step: 1
Training loss: 1.8423370122909546
Validation loss: 1.9066579067449776
Epoch: 4| Step: 2
Training loss: 2.2376410961151123
Validation loss: 1.9058454645623406
Epoch: 4| Step: 3
Training loss: 2.1204237937927246
Validation loss: 1.8877601108962683
Epoch: 4| Step: 4
Training loss: 1.9342539310455322
Validation loss: 1.9074991958604441
Epoch: 4| Step: 5
Training loss: 2.0606741905212402
Validation loss: 1.8854630911092964
Epoch: 4| Step: 6
Training loss: 2.2233169078826904
Validation loss: 1.8864997616774744
Epoch: 4| Step: 7
Training loss: 2.190002918243408
Validation loss: 1.8769857094442244
Epoch: 93| Step: 0
Training loss: 2.111516237258911
Validation loss: 1.8846148655568953
Epoch: 4| Step: 1
Training loss: 2.44246768951416
Validation loss: 1.892494214524468
Epoch: 4| Step: 2
Training loss: 2.17185378074646
Validation loss: 1.8980573973209738
Epoch: 4| Step: 3
Training loss: 2.120368480682373
Validation loss: 1.8831359216635175
Epoch: 4| Step: 4
Training loss: 1.6874094009399414
Validation loss: 1.8933634929519763
Epoch: 4| Step: 5
Training loss: 1.7757877111434937
Validation loss: 1.9177038129285084
Epoch: 4| Step: 6
Training loss: 2.2618517875671387
Validation loss: 1.9032899235649932
Epoch: 4| Step: 7
Training loss: 1.9296573400497437
Validation loss: 1.8788980897382008
Epoch: 94| Step: 0
Training loss: 1.9953914880752563
Validation loss: 1.9122331408287983
Epoch: 4| Step: 1
Training loss: 2.4250056743621826
Validation loss: 1.8907281855027454
Epoch: 4| Step: 2
Training loss: 2.154191732406616
Validation loss: 1.8780198037195548
Epoch: 4| Step: 3
Training loss: 2.1335949897766113
Validation loss: 1.8793025059665707
Epoch: 4| Step: 4
Training loss: 1.7034852504730225
Validation loss: 1.902091674667468
Epoch: 4| Step: 5
Training loss: 2.1935553550720215
Validation loss: 1.9071353648206313
Epoch: 4| Step: 6
Training loss: 2.1385581493377686
Validation loss: 1.9162546259036166
Epoch: 4| Step: 7
Training loss: 1.6888892650604248
Validation loss: 1.8922538963153208
Epoch: 95| Step: 0
Training loss: 2.2890994548797607
Validation loss: 1.902723161436671
Epoch: 4| Step: 1
Training loss: 1.9141756296157837
Validation loss: 1.898273079515361
Epoch: 4| Step: 2
Training loss: 1.9422390460968018
Validation loss: 1.8929058347674583
Epoch: 4| Step: 3
Training loss: 1.5064398050308228
Validation loss: 1.8905249774027213
Epoch: 4| Step: 4
Training loss: 2.218766450881958
Validation loss: 1.909660654102298
Epoch: 4| Step: 5
Training loss: 2.097362995147705
Validation loss: 1.8846853088131912
Epoch: 4| Step: 6
Training loss: 2.2384490966796875
Validation loss: 1.9079960001458367
Epoch: 4| Step: 7
Training loss: 2.2744622230529785
Validation loss: 1.9171604621324607
Epoch: 96| Step: 0
Training loss: 1.9410326480865479
Validation loss: 1.8910126789010686
Epoch: 4| Step: 1
Training loss: 1.829350233078003
Validation loss: 1.8857604050807815
Epoch: 4| Step: 2
Training loss: 1.9251819849014282
Validation loss: 1.892607650310873
Epoch: 4| Step: 3
Training loss: 2.1611921787261963
Validation loss: 1.893661339505971
Epoch: 4| Step: 4
Training loss: 1.8788219690322876
Validation loss: 1.900600652900531
Epoch: 4| Step: 5
Training loss: 2.5160727500915527
Validation loss: 1.9035298395499909
Epoch: 4| Step: 6
Training loss: 1.9027820825576782
Validation loss: 1.9209494076186804
Epoch: 4| Step: 7
Training loss: 2.251028299331665
Validation loss: 1.9256714796848435
Epoch: 97| Step: 0
Training loss: 2.0127570629119873
Validation loss: 1.9117386907124692
Epoch: 4| Step: 1
Training loss: 2.2202095985412598
Validation loss: 1.9078922434676466
Epoch: 4| Step: 2
Training loss: 2.134549617767334
Validation loss: 1.9122583111413092
Epoch: 4| Step: 3
Training loss: 1.7132619619369507
Validation loss: 1.9123530473640498
Epoch: 4| Step: 4
Training loss: 1.9156230688095093
Validation loss: 1.9131014630091276
Epoch: 4| Step: 5
Training loss: 2.376265048980713
Validation loss: 1.9159717165308892
Epoch: 4| Step: 6
Training loss: 2.1690337657928467
Validation loss: 1.8917299328948096
Epoch: 4| Step: 7
Training loss: 1.827633261680603
Validation loss: 1.904138850651199
Epoch: 98| Step: 0
Training loss: 2.0821728706359863
Validation loss: 1.905541035768797
Epoch: 4| Step: 1
Training loss: 2.492058038711548
Validation loss: 1.9025619450232965
Epoch: 4| Step: 2
Training loss: 1.9009153842926025
Validation loss: 1.890959737969817
Epoch: 4| Step: 3
Training loss: 1.9259666204452515
Validation loss: 1.9008748857237452
Epoch: 4| Step: 4
Training loss: 1.8372180461883545
Validation loss: 1.8744741137936818
Epoch: 4| Step: 5
Training loss: 1.9779090881347656
Validation loss: 1.879941701889038
Epoch: 4| Step: 6
Training loss: 1.860947608947754
Validation loss: 1.872428305715108
Epoch: 4| Step: 7
Training loss: 2.3266289234161377
Validation loss: 1.8792973662451875
Epoch: 99| Step: 0
Training loss: 2.054145574569702
Validation loss: 1.8848406548122707
Epoch: 4| Step: 1
Training loss: 1.8144843578338623
Validation loss: 1.894025493868821
Epoch: 4| Step: 2
Training loss: 2.4316482543945312
Validation loss: 1.8874071193255966
Epoch: 4| Step: 3
Training loss: 2.0303540229797363
Validation loss: 1.8892731263483171
Epoch: 4| Step: 4
Training loss: 2.1980347633361816
Validation loss: 1.8693281755172948
Epoch: 4| Step: 5
Training loss: 2.2115819454193115
Validation loss: 1.8830325963685839
Epoch: 4| Step: 6
Training loss: 1.6653751134872437
Validation loss: 1.874176543393581
Epoch: 4| Step: 7
Training loss: 1.9414081573486328
Validation loss: 1.8824078127634611
Epoch: 100| Step: 0
Training loss: 1.7978483438491821
Validation loss: 1.8767688428755287
Epoch: 4| Step: 1
Training loss: 1.741058111190796
Validation loss: 1.872471777655238
Epoch: 4| Step: 2
Training loss: 2.3718762397766113
Validation loss: 1.8842018319548464
Epoch: 4| Step: 3
Training loss: 2.0991783142089844
Validation loss: 1.903635328622173
Epoch: 4| Step: 4
Training loss: 2.0789012908935547
Validation loss: 1.8772840740011751
Epoch: 4| Step: 5
Training loss: 2.236043930053711
Validation loss: 1.882840779187868
Epoch: 4| Step: 6
Training loss: 2.213519334793091
Validation loss: 1.8897757830379678
Epoch: 4| Step: 7
Training loss: 1.786023497581482
Validation loss: 1.8945710444621902
