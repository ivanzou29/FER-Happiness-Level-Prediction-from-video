Epoch: 1| Step: 0
Training loss: 5.429836750030518
Validation loss: 5.9102198683100635
Epoch: 9| Step: 1
Training loss: 6.706771373748779
Validation loss: 5.906694082905062
Epoch: 9| Step: 2
Training loss: 5.266358375549316
Validation loss: 5.902114967648074
Epoch: 9| Step: 3
Training loss: 6.164002895355225
Validation loss: 5.898048301394895
Epoch: 9| Step: 4
Training loss: 7.176679611206055
Validation loss: 5.893719007643007
Epoch: 9| Step: 5
Training loss: 7.132578372955322
Validation loss: 5.88901487528849
Epoch: 9| Step: 6
Training loss: 6.272842884063721
Validation loss: 5.886198006087928
Epoch: 9| Step: 7
Training loss: 6.114304542541504
Validation loss: 5.882324266776764
Epoch: 9| Step: 8
Training loss: 5.65556526184082
Validation loss: 5.878111544272882
Epoch: 9| Step: 9
Training loss: 4.972248077392578
Validation loss: 5.876578629445687
Epoch: 9| Step: 10
Training loss: 5.511720657348633
Validation loss: 5.871561894313895
Epoch: 9| Step: 11
Training loss: 5.177572250366211
Validation loss: 5.8680552681573
Epoch: 9| Step: 12
Training loss: 6.348149299621582
Validation loss: 5.864056247601406
Epoch: 9| Step: 13
Training loss: 5.714719295501709
Validation loss: 5.861372295901072
Epoch: 9| Step: 14
Training loss: 6.041029930114746
Validation loss: 5.858304208988766
Epoch: 9| Step: 15
Training loss: 5.7312822341918945
Validation loss: 5.855200180904471
Epoch: 9| Step: 16
Training loss: 6.383761405944824
Validation loss: 5.849063862999566
Epoch: 9| Step: 17
Training loss: 5.719501495361328
Validation loss: 5.8459904759907895
Epoch: 9| Step: 18
Training loss: 6.309582710266113
Validation loss: 5.844031025179856
Epoch: 9| Step: 19
Training loss: 6.496794700622559
Validation loss: 5.839404318830092
Epoch: 2| Step: 0
Training loss: 5.513587951660156
Validation loss: 5.837000750809264
Epoch: 9| Step: 1
Training loss: 6.524595737457275
Validation loss: 5.833344586461568
Epoch: 9| Step: 2
Training loss: 5.102320671081543
Validation loss: 5.830271110260229
Epoch: 9| Step: 3
Training loss: 6.036670207977295
Validation loss: 5.827991550774883
Epoch: 9| Step: 4
Training loss: 6.050425052642822
Validation loss: 5.823745466822343
Epoch: 9| Step: 5
Training loss: 5.3288750648498535
Validation loss: 5.820151884778798
Epoch: 9| Step: 6
Training loss: 5.400527477264404
Validation loss: 5.818244148501389
Epoch: 9| Step: 7
Training loss: 5.6036224365234375
Validation loss: 5.813940312364976
Epoch: 9| Step: 8
Training loss: 7.398313522338867
Validation loss: 5.80926417961395
Epoch: 9| Step: 9
Training loss: 6.394869327545166
Validation loss: 5.807433207258046
Epoch: 9| Step: 10
Training loss: 5.7973456382751465
Validation loss: 5.805002874607663
Epoch: 9| Step: 11
Training loss: 4.8207855224609375
Validation loss: 5.801058882432018
Epoch: 9| Step: 12
Training loss: 6.028654098510742
Validation loss: 5.796591738145128
Epoch: 9| Step: 13
Training loss: 5.875021457672119
Validation loss: 5.793060848181196
Epoch: 9| Step: 14
Training loss: 5.41562557220459
Validation loss: 5.790641798389902
Epoch: 9| Step: 15
Training loss: 6.072016716003418
Validation loss: 5.786158736661184
Epoch: 9| Step: 16
Training loss: 5.118471145629883
Validation loss: 5.783923636237494
Epoch: 9| Step: 17
Training loss: 6.1552734375
Validation loss: 5.780534373770515
Epoch: 9| Step: 18
Training loss: 7.886261940002441
Validation loss: 5.7769835904347815
Epoch: 9| Step: 19
Training loss: 6.473456859588623
Validation loss: 5.772029372427961
Epoch: 3| Step: 0
Training loss: 7.103484153747559
Validation loss: 5.768238311191257
Epoch: 9| Step: 1
Training loss: 6.272672176361084
Validation loss: 5.765715441257834
Epoch: 9| Step: 2
Training loss: 5.430020332336426
Validation loss: 5.7605386775174585
Epoch: 9| Step: 3
Training loss: 5.322799205780029
Validation loss: 5.757105748430431
Epoch: 9| Step: 4
Training loss: 6.93559455871582
Validation loss: 5.754781009481965
Epoch: 9| Step: 5
Training loss: 6.056474685668945
Validation loss: 5.750999388934897
Epoch: 9| Step: 6
Training loss: 5.420698165893555
Validation loss: 5.746484382547063
Epoch: 9| Step: 7
Training loss: 5.8510050773620605
Validation loss: 5.743367486720462
Epoch: 9| Step: 8
Training loss: 5.98573637008667
Validation loss: 5.740715092034649
Epoch: 9| Step: 9
Training loss: 5.758103370666504
Validation loss: 5.735922782541179
Epoch: 9| Step: 10
Training loss: 5.274862289428711
Validation loss: 5.732858952858465
Epoch: 9| Step: 11
Training loss: 5.423344612121582
Validation loss: 5.727845922648478
Epoch: 9| Step: 12
Training loss: 6.438521385192871
Validation loss: 5.7255637079691715
Epoch: 9| Step: 13
Training loss: 6.088082790374756
Validation loss: 5.71973774930556
Epoch: 9| Step: 14
Training loss: 5.880212783813477
Validation loss: 5.716141367987763
Epoch: 9| Step: 15
Training loss: 4.747689247131348
Validation loss: 5.714113252626048
Epoch: 9| Step: 16
Training loss: 6.2657904624938965
Validation loss: 5.710017763453422
Epoch: 9| Step: 17
Training loss: 5.3601884841918945
Validation loss: 5.70552200893704
Epoch: 9| Step: 18
Training loss: 5.918166637420654
Validation loss: 5.702845690061721
Epoch: 9| Step: 19
Training loss: 6.109579086303711
Validation loss: 5.698947055734319
Epoch: 4| Step: 0
Training loss: 5.620138645172119
Validation loss: 5.69310441806162
Epoch: 9| Step: 1
Training loss: 4.962279796600342
Validation loss: 5.688661643927046
Epoch: 9| Step: 2
Training loss: 4.754951477050781
Validation loss: 5.686586057539467
Epoch: 9| Step: 3
Training loss: 5.082243919372559
Validation loss: 5.6819636187107445
Epoch: 9| Step: 4
Training loss: 5.988932132720947
Validation loss: 5.677966210481932
Epoch: 9| Step: 5
Training loss: 6.002504825592041
Validation loss: 5.674289253975847
Epoch: 9| Step: 6
Training loss: 6.632874488830566
Validation loss: 5.670693442118254
Epoch: 9| Step: 7
Training loss: 6.37459659576416
Validation loss: 5.664120801061177
Epoch: 9| Step: 8
Training loss: 6.901571750640869
Validation loss: 5.661481473085692
Epoch: 9| Step: 9
Training loss: 5.633808135986328
Validation loss: 5.658055549045261
Epoch: 9| Step: 10
Training loss: 5.715031147003174
Validation loss: 5.653441600662341
Epoch: 9| Step: 11
Training loss: 6.005250930786133
Validation loss: 5.647709589210345
Epoch: 9| Step: 12
Training loss: 6.2345733642578125
Validation loss: 5.64127362203255
Epoch: 9| Step: 13
Training loss: 5.938380241394043
Validation loss: 5.638113773126396
Epoch: 9| Step: 14
Training loss: 6.0718183517456055
Validation loss: 5.6356476742586645
Epoch: 9| Step: 15
Training loss: 6.15435791015625
Validation loss: 5.630536319540559
Epoch: 9| Step: 16
Training loss: 5.316469192504883
Validation loss: 5.6254790772637016
Epoch: 9| Step: 17
Training loss: 5.46788215637207
Validation loss: 5.621020080374299
Epoch: 9| Step: 18
Training loss: 5.300261974334717
Validation loss: 5.617419640794933
Epoch: 9| Step: 19
Training loss: 5.984755516052246
Validation loss: 5.612919358040789
Epoch: 5| Step: 0
Training loss: 6.324704170227051
Validation loss: 5.609487557582718
Epoch: 9| Step: 1
Training loss: 3.6730117797851562
Validation loss: 5.603036496279051
Epoch: 9| Step: 2
Training loss: 6.49656343460083
Validation loss: 5.599682372251003
Epoch: 9| Step: 3
Training loss: 6.134975910186768
Validation loss: 5.594898906543101
Epoch: 9| Step: 4
Training loss: 6.197211265563965
Validation loss: 5.590652184520694
Epoch: 9| Step: 5
Training loss: 5.79496955871582
Validation loss: 5.582926832514701
Epoch: 9| Step: 6
Training loss: 5.734618663787842
Validation loss: 5.576961435002389
Epoch: 9| Step: 7
Training loss: 4.7291412353515625
Validation loss: 5.574806172213108
Epoch: 9| Step: 8
Training loss: 5.944907188415527
Validation loss: 5.570383030733616
Epoch: 9| Step: 9
Training loss: 5.995197296142578
Validation loss: 5.564208593299921
Epoch: 9| Step: 10
Training loss: 5.441337585449219
Validation loss: 5.559275603122848
Epoch: 9| Step: 11
Training loss: 4.514734268188477
Validation loss: 5.553973726231417
Epoch: 9| Step: 12
Training loss: 6.414520263671875
Validation loss: 5.548654995376258
Epoch: 9| Step: 13
Training loss: 5.926105976104736
Validation loss: 5.543288361254356
Epoch: 9| Step: 14
Training loss: 6.3877668380737305
Validation loss: 5.538085429788493
Epoch: 9| Step: 15
Training loss: 5.6761579513549805
Validation loss: 5.5333485912076
Epoch: 9| Step: 16
Training loss: 5.936542987823486
Validation loss: 5.526890644924246
Epoch: 9| Step: 17
Training loss: 4.998800277709961
Validation loss: 5.522057279408407
Epoch: 9| Step: 18
Training loss: 5.950839996337891
Validation loss: 5.514680653167286
Epoch: 9| Step: 19
Training loss: 6.095232009887695
Validation loss: 5.511054759402927
Epoch: 6| Step: 0
Training loss: 4.62188720703125
Validation loss: 5.506030748216368
Epoch: 9| Step: 1
Training loss: 5.1905741691589355
Validation loss: 5.498078606969161
Epoch: 9| Step: 2
Training loss: 5.199511528015137
Validation loss: 5.4940290451049805
Epoch: 9| Step: 3
Training loss: 4.594752311706543
Validation loss: 5.486906295200046
Epoch: 9| Step: 4
Training loss: 5.518596172332764
Validation loss: 5.485963173049817
Epoch: 9| Step: 5
Training loss: 5.842940330505371
Validation loss: 5.4776390919582445
Epoch: 9| Step: 6
Training loss: 6.555540084838867
Validation loss: 5.469565689992562
Epoch: 9| Step: 7
Training loss: 6.065225601196289
Validation loss: 5.464023768473014
Epoch: 9| Step: 8
Training loss: 5.862653732299805
Validation loss: 5.459726021444197
Epoch: 9| Step: 9
Training loss: 5.953616619110107
Validation loss: 5.454177763822267
Epoch: 9| Step: 10
Training loss: 6.006959915161133
Validation loss: 5.446795888941923
Epoch: 9| Step: 11
Training loss: 4.98712682723999
Validation loss: 5.43805425630199
Epoch: 9| Step: 12
Training loss: 4.697751998901367
Validation loss: 5.434811032933297
Epoch: 9| Step: 13
Training loss: 5.975854873657227
Validation loss: 5.426237915917266
Epoch: 9| Step: 14
Training loss: 6.1783647537231445
Validation loss: 5.420795413229963
Epoch: 9| Step: 15
Training loss: 5.5226545333862305
Validation loss: 5.414983502394861
Epoch: 9| Step: 16
Training loss: 5.7909836769104
Validation loss: 5.4097407601720136
Epoch: 9| Step: 17
Training loss: 6.1083831787109375
Validation loss: 5.399829957124998
Epoch: 9| Step: 18
Training loss: 5.6468658447265625
Validation loss: 5.395690499449805
Epoch: 9| Step: 19
Training loss: 5.888312339782715
Validation loss: 5.3844536362792095
Epoch: 7| Step: 0
Training loss: 5.61419153213501
Validation loss: 5.378918170928955
Epoch: 9| Step: 1
Training loss: 6.81904935836792
Validation loss: 5.369270009102581
Epoch: 9| Step: 2
Training loss: 6.476691246032715
Validation loss: 5.360848996279051
Epoch: 9| Step: 3
Training loss: 4.75994348526001
Validation loss: 5.360822509518631
Epoch: 9| Step: 4
Training loss: 5.723895072937012
Validation loss: 5.349814277758702
Epoch: 9| Step: 5
Training loss: 5.690990924835205
Validation loss: 5.34243663952505
Epoch: 9| Step: 6
Training loss: 6.480546951293945
Validation loss: 5.335464793143513
Epoch: 9| Step: 7
Training loss: 5.417734146118164
Validation loss: 5.330228462493677
Epoch: 9| Step: 8
Training loss: 6.112395286560059
Validation loss: 5.317734416440237
Epoch: 9| Step: 9
Training loss: 6.4027228355407715
Validation loss: 5.3125446648906465
Epoch: 9| Step: 10
Training loss: 5.796174049377441
Validation loss: 5.307667293136926
Epoch: 9| Step: 11
Training loss: 4.535460948944092
Validation loss: 5.299339726674471
Epoch: 9| Step: 12
Training loss: 5.15569543838501
Validation loss: 5.29011817287198
Epoch: 9| Step: 13
Training loss: 5.249977111816406
Validation loss: 5.279733112390093
Epoch: 9| Step: 14
Training loss: 4.441564559936523
Validation loss: 5.268763442691282
Epoch: 9| Step: 15
Training loss: 4.676093101501465
Validation loss: 5.264590194757036
Epoch: 9| Step: 16
Training loss: 5.714691162109375
Validation loss: 5.2573890823254485
Epoch: 9| Step: 17
Training loss: 3.5243844985961914
Validation loss: 5.246363921131161
Epoch: 9| Step: 18
Training loss: 5.71434211730957
Validation loss: 5.239228135390247
Epoch: 9| Step: 19
Training loss: 5.238467216491699
Validation loss: 5.230503727206223
Epoch: 8| Step: 0
Training loss: 5.117831230163574
Validation loss: 5.224405511677694
Epoch: 9| Step: 1
Training loss: 4.27564001083374
Validation loss: 5.214583698794138
Epoch: 9| Step: 2
Training loss: 5.96708869934082
Validation loss: 5.2016437722624635
Epoch: 9| Step: 3
Training loss: 6.415934085845947
Validation loss: 5.196842461181202
Epoch: 9| Step: 4
Training loss: 6.088881969451904
Validation loss: 5.191065753964211
Epoch: 9| Step: 5
Training loss: 5.74310302734375
Validation loss: 5.177695305227376
Epoch: 9| Step: 6
Training loss: 4.282195568084717
Validation loss: 5.1700547719173295
Epoch: 9| Step: 7
Training loss: 5.692535400390625
Validation loss: 5.159389684526182
Epoch: 9| Step: 8
Training loss: 5.994096279144287
Validation loss: 5.150491021519942
Epoch: 9| Step: 9
Training loss: 5.748244285583496
Validation loss: 5.140046037358346
Epoch: 9| Step: 10
Training loss: 4.568850040435791
Validation loss: 5.131408156250878
Epoch: 9| Step: 11
Training loss: 4.998721122741699
Validation loss: 5.125083556278146
Epoch: 9| Step: 12
Training loss: 5.488722324371338
Validation loss: 5.114154297670872
Epoch: 9| Step: 13
Training loss: 5.33309268951416
Validation loss: 5.09959285722362
Epoch: 9| Step: 14
Training loss: 3.303208351135254
Validation loss: 5.093460559844971
Epoch: 9| Step: 15
Training loss: 5.2191619873046875
Validation loss: 5.0825559526896305
Epoch: 9| Step: 16
Training loss: 5.540633201599121
Validation loss: 5.069740981506786
Epoch: 9| Step: 17
Training loss: 5.133187294006348
Validation loss: 5.061096105644171
Epoch: 9| Step: 18
Training loss: 5.806244850158691
Validation loss: 5.045021719212155
Epoch: 9| Step: 19
Training loss: 5.511191368103027
Validation loss: 5.03860925770492
Epoch: 9| Step: 0
Training loss: 5.703006744384766
Validation loss: 5.024965574415468
Epoch: 9| Step: 1
Training loss: 4.807883262634277
Validation loss: 5.016628515806129
Epoch: 9| Step: 2
Training loss: 4.673903465270996
Validation loss: 4.999609072431386
Epoch: 9| Step: 3
Training loss: 5.369961738586426
Validation loss: 4.993781937112053
Epoch: 9| Step: 4
Training loss: 4.809189319610596
Validation loss: 4.986805644824351
Epoch: 9| Step: 5
Training loss: 5.529890537261963
Validation loss: 4.969621678908094
Epoch: 9| Step: 6
Training loss: 4.621620178222656
Validation loss: 4.966249740381035
Epoch: 9| Step: 7
Training loss: 4.518896102905273
Validation loss: 4.95178816815932
Epoch: 9| Step: 8
Training loss: 5.43491268157959
Validation loss: 4.937918416030115
Epoch: 9| Step: 9
Training loss: 4.647765159606934
Validation loss: 4.926500509111143
Epoch: 9| Step: 10
Training loss: 5.2387495040893555
Validation loss: 4.912253115674575
Epoch: 9| Step: 11
Training loss: 4.929404258728027
Validation loss: 4.901133050163873
Epoch: 9| Step: 12
Training loss: 5.721156120300293
Validation loss: 4.886840878630713
Epoch: 9| Step: 13
Training loss: 5.048054218292236
Validation loss: 4.874342925256962
Epoch: 9| Step: 14
Training loss: 4.9954633712768555
Validation loss: 4.857732820853912
Epoch: 9| Step: 15
Training loss: 5.511678218841553
Validation loss: 4.8536442989925686
Epoch: 9| Step: 16
Training loss: 5.780666351318359
Validation loss: 4.841605519219268
Epoch: 9| Step: 17
Training loss: 5.128887176513672
Validation loss: 4.83113020615612
Epoch: 9| Step: 18
Training loss: 5.512894630432129
Validation loss: 4.821930031124636
Epoch: 9| Step: 19
Training loss: 4.261056900024414
Validation loss: 4.80450679929994
Epoch: 10| Step: 0
Training loss: 4.02804708480835
Validation loss: 4.7853444137161585
Epoch: 9| Step: 1
Training loss: 4.151721954345703
Validation loss: 4.768432576021702
Epoch: 9| Step: 2
Training loss: 5.489312648773193
Validation loss: 4.758605360127182
Epoch: 9| Step: 3
Training loss: 5.647383213043213
Validation loss: 4.748018285353407
Epoch: 9| Step: 4
Training loss: 4.733299732208252
Validation loss: 4.733928495173831
Epoch: 9| Step: 5
Training loss: 4.816714286804199
Validation loss: 4.7193294943665425
Epoch: 9| Step: 6
Training loss: 4.3423686027526855
Validation loss: 4.7127483182673835
Epoch: 9| Step: 7
Training loss: 5.07661247253418
Validation loss: 4.694060823042616
Epoch: 9| Step: 8
Training loss: 5.366861343383789
Validation loss: 4.673166762153022
Epoch: 9| Step: 9
Training loss: 4.2598466873168945
Validation loss: 4.6665651266523405
Epoch: 9| Step: 10
Training loss: 5.5767927169799805
Validation loss: 4.650724736906642
Epoch: 9| Step: 11
Training loss: 4.778018951416016
Validation loss: 4.63256575906877
Epoch: 9| Step: 12
Training loss: 5.170506954193115
Validation loss: 4.618837514369607
Epoch: 9| Step: 13
Training loss: 3.9239449501037598
Validation loss: 4.609398344437853
Epoch: 9| Step: 14
Training loss: 5.117987632751465
Validation loss: 4.581131991722601
Epoch: 9| Step: 15
Training loss: 5.4756879806518555
Validation loss: 4.568840805575144
Epoch: 9| Step: 16
Training loss: 4.904384613037109
Validation loss: 4.556075325972742
Epoch: 9| Step: 17
Training loss: 4.550123691558838
Validation loss: 4.53689902120357
Epoch: 9| Step: 18
Training loss: 4.611745834350586
Validation loss: 4.516274212075652
Epoch: 9| Step: 19
Training loss: 5.228649616241455
Validation loss: 4.508208082734252
Epoch: 11| Step: 0
Training loss: 4.869205474853516
Validation loss: 4.488496121742743
Epoch: 9| Step: 1
Training loss: 4.559942245483398
Validation loss: 4.480822299024184
Epoch: 9| Step: 2
Training loss: 5.469479560852051
Validation loss: 4.4627972438181045
Epoch: 9| Step: 3
Training loss: 4.006570339202881
Validation loss: 4.433547863857352
Epoch: 9| Step: 4
Training loss: 4.385551452636719
Validation loss: 4.428664735752902
Epoch: 9| Step: 5
Training loss: 4.779080390930176
Validation loss: 4.402841543979782
Epoch: 9| Step: 6
Training loss: 4.608306884765625
Validation loss: 4.385927159151585
Epoch: 9| Step: 7
Training loss: 4.09974479675293
Validation loss: 4.363399165997402
Epoch: 9| Step: 8
Training loss: 3.9913711547851562
Validation loss: 4.352311604314571
Epoch: 9| Step: 9
Training loss: 4.337324619293213
Validation loss: 4.328812084609656
Epoch: 9| Step: 10
Training loss: 4.992605209350586
Validation loss: 4.315498540727354
Epoch: 9| Step: 11
Training loss: 4.048892974853516
Validation loss: 4.300261243641805
Epoch: 9| Step: 12
Training loss: 3.9302923679351807
Validation loss: 4.272123070929548
Epoch: 9| Step: 13
Training loss: 5.275264263153076
Validation loss: 4.258686614551133
Epoch: 9| Step: 14
Training loss: 4.386739730834961
Validation loss: 4.244383208185649
Epoch: 9| Step: 15
Training loss: 4.599896430969238
Validation loss: 4.2116811052500776
Epoch: 9| Step: 16
Training loss: 4.95319128036499
Validation loss: 4.2104850741599105
Epoch: 9| Step: 17
Training loss: 5.000988960266113
Validation loss: 4.192158709327094
Epoch: 9| Step: 18
Training loss: 4.169922351837158
Validation loss: 4.158684123334267
Epoch: 9| Step: 19
Training loss: 4.831023216247559
Validation loss: 4.145375917283751
Epoch: 12| Step: 0
Training loss: 4.760279655456543
Validation loss: 4.136289826399988
Epoch: 9| Step: 1
Training loss: 3.8895654678344727
Validation loss: 4.085000003842141
Epoch: 9| Step: 2
Training loss: 4.113344192504883
Validation loss: 4.080098918873629
Epoch: 9| Step: 3
Training loss: 4.684183120727539
Validation loss: 4.061730302495064
Epoch: 9| Step: 4
Training loss: 4.946310997009277
Validation loss: 4.0429031248572915
Epoch: 9| Step: 5
Training loss: 3.715850353240967
Validation loss: 4.010941471127297
Epoch: 9| Step: 6
Training loss: 4.449411392211914
Validation loss: 3.9857226481540597
Epoch: 9| Step: 7
Training loss: 4.261678695678711
Validation loss: 3.963795353182786
Epoch: 9| Step: 8
Training loss: 4.11775016784668
Validation loss: 3.943400571672179
Epoch: 9| Step: 9
Training loss: 4.525509834289551
Validation loss: 3.9426215535445177
Epoch: 9| Step: 10
Training loss: 3.448357343673706
Validation loss: 3.9043741329110784
Epoch: 9| Step: 11
Training loss: 3.7292134761810303
Validation loss: 3.902129423704079
Epoch: 9| Step: 12
Training loss: 3.4977221488952637
Validation loss: 3.850416962191355
Epoch: 9| Step: 13
Training loss: 4.704802989959717
Validation loss: 3.8295364174053823
Epoch: 9| Step: 14
Training loss: 4.706715106964111
Validation loss: 3.8110547100039693
Epoch: 9| Step: 15
Training loss: 3.7223849296569824
Validation loss: 3.8042753720455034
Epoch: 9| Step: 16
Training loss: 4.253655433654785
Validation loss: 3.782963776759964
Epoch: 9| Step: 17
Training loss: 4.566527366638184
Validation loss: 3.7462339572769277
Epoch: 9| Step: 18
Training loss: 4.715163707733154
Validation loss: 3.744414825233624
Epoch: 9| Step: 19
Training loss: 3.74867582321167
Validation loss: 3.7227150536269593
Epoch: 13| Step: 0
Training loss: 3.830704689025879
Validation loss: 3.690462225632702
Epoch: 9| Step: 1
Training loss: 3.6832947731018066
Validation loss: 3.65393280811447
Epoch: 9| Step: 2
Training loss: 4.398791313171387
Validation loss: 3.6514322774873365
Epoch: 9| Step: 3
Training loss: 4.2527031898498535
Validation loss: 3.6210756130355723
Epoch: 9| Step: 4
Training loss: 4.667415618896484
Validation loss: 3.591767664435956
Epoch: 9| Step: 5
Training loss: 5.190883159637451
Validation loss: 3.578365360232566
Epoch: 9| Step: 6
Training loss: 3.901336431503296
Validation loss: 3.5400679643205604
Epoch: 9| Step: 7
Training loss: 4.240374565124512
Validation loss: 3.515922963190422
Epoch: 9| Step: 8
Training loss: 4.197659492492676
Validation loss: 3.5089288135226684
Epoch: 9| Step: 9
Training loss: 3.759409189224243
Validation loss: 3.4612989168372943
Epoch: 9| Step: 10
Training loss: 3.583986282348633
Validation loss: 3.41768100621889
Epoch: 9| Step: 11
Training loss: 4.056796073913574
Validation loss: 3.415396813866046
Epoch: 9| Step: 12
Training loss: 3.6797614097595215
Validation loss: 3.3732647792898494
Epoch: 9| Step: 13
Training loss: 2.9831032752990723
Validation loss: 3.359491217908242
Epoch: 9| Step: 14
Training loss: 4.157191276550293
Validation loss: 3.3174452301409603
Epoch: 9| Step: 15
Training loss: 2.876183032989502
Validation loss: 3.3144668537935766
Epoch: 9| Step: 16
Training loss: 2.581265926361084
Validation loss: 3.2781150958520904
Epoch: 9| Step: 17
Training loss: 3.3391621112823486
Validation loss: 3.2484826852949404
Epoch: 9| Step: 18
Training loss: 4.290715217590332
Validation loss: 3.2340208386345735
Epoch: 9| Step: 19
Training loss: 3.2033891677856445
Validation loss: 3.2310344435328204
Epoch: 14| Step: 0
Training loss: 2.778174638748169
Validation loss: 3.1814853390343756
Epoch: 9| Step: 1
Training loss: 3.6190593242645264
Validation loss: 3.1781474017410827
Epoch: 9| Step: 2
Training loss: 4.07263708114624
Validation loss: 3.140902663306367
Epoch: 9| Step: 3
Training loss: 3.939530849456787
Validation loss: 3.099583051187529
Epoch: 9| Step: 4
Training loss: 3.947408676147461
Validation loss: 3.071785305901397
Epoch: 9| Step: 5
Training loss: 1.7791569232940674
Validation loss: 3.0443990985266596
Epoch: 9| Step: 6
Training loss: 4.698033809661865
Validation loss: 3.019242480504427
Epoch: 9| Step: 7
Training loss: 3.239584445953369
Validation loss: 2.980499106345417
Epoch: 9| Step: 8
Training loss: 3.355192184448242
Validation loss: 2.9763226714923228
Epoch: 9| Step: 9
Training loss: 2.89677357673645
Validation loss: 2.912879665978521
Epoch: 9| Step: 10
Training loss: 3.455504894256592
Validation loss: 2.9183583362497014
Epoch: 9| Step: 11
Training loss: 3.6393258571624756
Validation loss: 2.8827759636391836
Epoch: 9| Step: 12
Training loss: 3.2166943550109863
Validation loss: 2.8621694664303345
Epoch: 9| Step: 13
Training loss: 3.7779908180236816
Validation loss: 2.824190136340025
Epoch: 9| Step: 14
Training loss: 2.585681438446045
Validation loss: 2.8091572840436756
Epoch: 9| Step: 15
Training loss: 3.687725305557251
Validation loss: 2.786192005486797
Epoch: 9| Step: 16
Training loss: 3.6709413528442383
Validation loss: 2.7674101411009864
Epoch: 9| Step: 17
Training loss: 3.7124507427215576
Validation loss: 2.7489373306576295
Epoch: 9| Step: 18
Training loss: 2.8764097690582275
Validation loss: 2.674037384472305
Epoch: 9| Step: 19
Training loss: 3.2407987117767334
Validation loss: 2.681984470902587
Epoch: 15| Step: 0
Training loss: 3.254356861114502
Validation loss: 2.6426003871204182
Epoch: 9| Step: 1
Training loss: 2.327561855316162
Validation loss: 2.6247277551417727
Epoch: 9| Step: 2
Training loss: 4.015500545501709
Validation loss: 2.5945887531307963
Epoch: 9| Step: 3
Training loss: 3.0440165996551514
Validation loss: 2.617989773372952
Epoch: 9| Step: 4
Training loss: 3.2714099884033203
Validation loss: 2.535366144111688
Epoch: 9| Step: 5
Training loss: 3.104165554046631
Validation loss: 2.5157946150937525
Epoch: 9| Step: 6
Training loss: 2.7348287105560303
Validation loss: 2.5011581774238203
Epoch: 9| Step: 7
Training loss: 3.4480502605438232
Validation loss: 2.4744100313392474
Epoch: 9| Step: 8
Training loss: 3.0219149589538574
Validation loss: 2.4664076729644115
Epoch: 9| Step: 9
Training loss: 2.8200876712799072
Validation loss: 2.411871290893006
Epoch: 9| Step: 10
Training loss: 2.393832206726074
Validation loss: 2.4096666188548794
Epoch: 9| Step: 11
Training loss: 2.987257957458496
Validation loss: 2.3704370500372467
Epoch: 9| Step: 12
Training loss: 3.2613470554351807
Validation loss: 2.351228268026448
Epoch: 9| Step: 13
Training loss: 2.9144325256347656
Validation loss: 2.3329713516098134
Epoch: 9| Step: 14
Training loss: 3.000833511352539
Validation loss: 2.306140783021776
Epoch: 9| Step: 15
Training loss: 3.100182056427002
Validation loss: 2.26839678407573
Epoch: 9| Step: 16
Training loss: 2.858962297439575
Validation loss: 2.2569169432139224
Epoch: 9| Step: 17
Training loss: 2.9656424522399902
Validation loss: 2.2128108268161473
Epoch: 9| Step: 18
Training loss: 2.3468635082244873
Validation loss: 2.198626917900799
Epoch: 9| Step: 19
Training loss: 3.2164101600646973
Validation loss: 2.1851279083773387
Epoch: 16| Step: 0
Training loss: 2.61102032661438
Validation loss: 2.146646379566879
Epoch: 9| Step: 1
Training loss: 2.6513545513153076
Validation loss: 2.123909123509908
Epoch: 9| Step: 2
Training loss: 2.1926777362823486
Validation loss: 2.102023611823432
Epoch: 9| Step: 3
Training loss: 2.7900054454803467
Validation loss: 2.0886911110912294
Epoch: 9| Step: 4
Training loss: 2.991596221923828
Validation loss: 2.1069299145568188
Epoch: 9| Step: 5
Training loss: 2.7691292762756348
Validation loss: 2.0758542491377687
Epoch: 9| Step: 6
Training loss: 2.0550124645233154
Validation loss: 2.00642303339869
Epoch: 9| Step: 7
Training loss: 2.126225233078003
Validation loss: 2.018931082684359
Epoch: 9| Step: 8
Training loss: 2.5044734477996826
Validation loss: 1.977122114716674
Epoch: 9| Step: 9
Training loss: 2.690187454223633
Validation loss: 2.0079244040756774
Epoch: 9| Step: 10
Training loss: 2.5061392784118652
Validation loss: 1.9511084916780321
Epoch: 9| Step: 11
Training loss: 2.7110581398010254
Validation loss: 1.9583509440044704
Epoch: 9| Step: 12
Training loss: 2.8930673599243164
Validation loss: 1.9356522568695838
Epoch: 9| Step: 13
Training loss: 2.592162609100342
Validation loss: 1.9177225991118727
Epoch: 9| Step: 14
Training loss: 2.546398401260376
Validation loss: 1.8784715417477724
Epoch: 9| Step: 15
Training loss: 2.9804415702819824
Validation loss: 1.8715459965973449
Epoch: 9| Step: 16
Training loss: 1.5960896015167236
Validation loss: 1.8655265741211047
Epoch: 9| Step: 17
Training loss: 2.0120930671691895
Validation loss: 1.8832237437474642
Epoch: 9| Step: 18
Training loss: 3.3239738941192627
Validation loss: 1.8467528571327814
Epoch: 9| Step: 19
Training loss: 2.7351486682891846
Validation loss: 1.824904417820114
Epoch: 17| Step: 0
Training loss: 2.4934420585632324
Validation loss: 1.808012644163996
Epoch: 9| Step: 1
Training loss: 1.9022451639175415
Validation loss: 1.843089971610968
Epoch: 9| Step: 2
Training loss: 2.6613869667053223
Validation loss: 1.7972544791887133
Epoch: 9| Step: 3
Training loss: 2.806936740875244
Validation loss: 1.8076703831446257
Epoch: 9| Step: 4
Training loss: 2.2081618309020996
Validation loss: 1.8327371182201577
Epoch: 9| Step: 5
Training loss: 1.574292540550232
Validation loss: 1.8095550777243197
Epoch: 9| Step: 6
Training loss: 2.3335487842559814
Validation loss: 1.795167518176621
Epoch: 9| Step: 7
Training loss: 2.464344024658203
Validation loss: 1.7852038951228848
Epoch: 9| Step: 8
Training loss: 2.3386895656585693
Validation loss: 1.7858596216860434
Epoch: 9| Step: 9
Training loss: 2.7199301719665527
Validation loss: 1.817753472774149
Epoch: 9| Step: 10
Training loss: 2.6327333450317383
Validation loss: 1.8192160343952317
Epoch: 9| Step: 11
Training loss: 2.0841798782348633
Validation loss: 1.769533140196217
Epoch: 9| Step: 12
Training loss: 2.362539529800415
Validation loss: 1.8061423421763687
Epoch: 9| Step: 13
Training loss: 2.9417500495910645
Validation loss: 1.7631698409430414
Epoch: 9| Step: 14
Training loss: 2.0349655151367188
Validation loss: 1.7672674347170823
Epoch: 9| Step: 15
Training loss: 2.839047431945801
Validation loss: 1.8075404818967091
Epoch: 9| Step: 16
Training loss: 1.7707624435424805
Validation loss: 1.7761278701343124
Epoch: 9| Step: 17
Training loss: 2.1139073371887207
Validation loss: 1.8531324117303751
Epoch: 9| Step: 18
Training loss: 2.1935107707977295
Validation loss: 1.7435693586472985
Epoch: 9| Step: 19
Training loss: 1.8559846878051758
Validation loss: 1.7827607899261035
Epoch: 18| Step: 0
Training loss: 2.500896453857422
Validation loss: 1.8216679272034186
Epoch: 9| Step: 1
Training loss: 1.972945213317871
Validation loss: 1.8182883348396357
Epoch: 9| Step: 2
Training loss: 1.6466007232666016
Validation loss: 1.8349566665484751
Epoch: 9| Step: 3
Training loss: 2.271543502807617
Validation loss: 1.817700314007217
Epoch: 9| Step: 4
Training loss: 2.505490303039551
Validation loss: 1.8475155607401896
Epoch: 9| Step: 5
Training loss: 1.6861181259155273
Validation loss: 1.8246306961388896
Epoch: 9| Step: 6
Training loss: 2.2696614265441895
Validation loss: 1.8090053719582317
Epoch: 9| Step: 7
Training loss: 2.2196996212005615
Validation loss: 1.8168473715404811
Epoch: 9| Step: 8
Training loss: 2.3008968830108643
Validation loss: 1.8496464885396064
Epoch: 9| Step: 9
Training loss: 2.5883705615997314
Validation loss: 1.8467713251388331
Epoch: 9| Step: 10
Training loss: 2.23720121383667
Validation loss: 1.8904603067919505
Epoch: 9| Step: 11
Training loss: 2.6255083084106445
Validation loss: 1.8684295475911752
Epoch: 9| Step: 12
Training loss: 2.018571376800537
Validation loss: 1.8443043000406498
Epoch: 9| Step: 13
Training loss: 2.2434000968933105
Validation loss: 1.8428447555294998
Epoch: 9| Step: 14
Training loss: 1.8635013103485107
Validation loss: 1.8187928928745736
Epoch: 9| Step: 15
Training loss: 3.1150012016296387
Validation loss: 1.8581928555056346
Epoch: 9| Step: 16
Training loss: 2.1918654441833496
Validation loss: 1.911107674777079
Epoch: 9| Step: 17
Training loss: 2.241323471069336
Validation loss: 1.8903864510625386
Epoch: 9| Step: 18
Training loss: 1.0379539728164673
Validation loss: 1.8637864486776667
Epoch: 9| Step: 19
Training loss: 1.982222080230713
Validation loss: 1.8992218559594463
Epoch: 19| Step: 0
Training loss: 2.0319387912750244
Validation loss: 1.8778743212171596
Epoch: 9| Step: 1
Training loss: 1.3959712982177734
Validation loss: 1.872564115112634
Epoch: 9| Step: 2
Training loss: 1.9405146837234497
Validation loss: 1.9193330840241136
Epoch: 9| Step: 3
Training loss: 1.7820147275924683
Validation loss: 1.8939229455783213
Epoch: 9| Step: 4
Training loss: 2.1003637313842773
Validation loss: 1.9022502916322337
Epoch: 9| Step: 5
Training loss: 1.815965175628662
Validation loss: 1.873911936506093
Epoch: 9| Step: 6
Training loss: 2.461508274078369
Validation loss: 1.8985096310540068
Epoch: 9| Step: 7
Training loss: 2.395372152328491
Validation loss: 1.91697739954475
Epoch: 9| Step: 8
Training loss: 1.3601765632629395
Validation loss: 1.9097073000969647
Epoch: 9| Step: 9
Training loss: 3.4354231357574463
Validation loss: 1.9267228910391279
Epoch: 9| Step: 10
Training loss: 2.3287558555603027
Validation loss: 1.9084819906907116
Epoch: 9| Step: 11
Training loss: 2.8399081230163574
Validation loss: 1.8981136932647487
Epoch: 9| Step: 12
Training loss: 1.5169286727905273
Validation loss: 1.9194651970760428
Epoch: 9| Step: 13
Training loss: 2.211714744567871
Validation loss: 1.9101084427867863
Epoch: 9| Step: 14
Training loss: 2.679985284805298
Validation loss: 1.8950385961601202
Epoch: 9| Step: 15
Training loss: 2.1674749851226807
Validation loss: 1.9313977725214238
Epoch: 9| Step: 16
Training loss: 2.11765456199646
Validation loss: 1.9089779699449059
Epoch: 9| Step: 17
Training loss: 2.0519046783447266
Validation loss: 1.9338261618031014
Epoch: 9| Step: 18
Training loss: 2.224353790283203
Validation loss: 1.8569062347892378
Epoch: 9| Step: 19
Training loss: 1.934037446975708
Validation loss: 1.9218707753599977
Epoch: 20| Step: 0
Training loss: 2.1294212341308594
Validation loss: 1.8612059363358313
Epoch: 9| Step: 1
Training loss: 2.356046676635742
Validation loss: 1.9589015639943184
Epoch: 9| Step: 2
Training loss: 1.337324857711792
Validation loss: 1.8771028501524343
Epoch: 9| Step: 3
Training loss: 1.9633638858795166
Validation loss: 1.9313338480407385
Epoch: 9| Step: 4
Training loss: 1.8293840885162354
Validation loss: 1.9125249094242671
Epoch: 9| Step: 5
Training loss: 1.9150068759918213
Validation loss: 1.9121652781534537
Epoch: 9| Step: 6
Training loss: 2.1173646450042725
Validation loss: 1.9039021335917412
Epoch: 9| Step: 7
Training loss: 2.9930224418640137
Validation loss: 1.8847121746420004
Epoch: 9| Step: 8
Training loss: 1.660529375076294
Validation loss: 1.8848209775609077
Epoch: 9| Step: 9
Training loss: 2.329143524169922
Validation loss: 1.948479595801813
Epoch: 9| Step: 10
Training loss: 2.4013571739196777
Validation loss: 1.9385753904315208
Epoch: 9| Step: 11
Training loss: 2.1666693687438965
Validation loss: 1.911271366284048
Epoch: 9| Step: 12
Training loss: 2.8779335021972656
Validation loss: 1.8966821046184292
Epoch: 9| Step: 13
Training loss: 1.9054707288742065
Validation loss: 1.8655574321746826
Epoch: 9| Step: 14
Training loss: 2.646782398223877
Validation loss: 1.9238772735321263
Epoch: 9| Step: 15
Training loss: 2.110494613647461
Validation loss: 1.9262187995498987
Epoch: 9| Step: 16
Training loss: 1.7118825912475586
Validation loss: 1.9136043624054613
Epoch: 9| Step: 17
Training loss: 2.1472301483154297
Validation loss: 1.8864724533163386
Epoch: 9| Step: 18
Training loss: 2.645904541015625
Validation loss: 1.9244560826596597
Epoch: 9| Step: 19
Training loss: 1.8049793243408203
Validation loss: 1.8971412696426722
Epoch: 21| Step: 0
Training loss: 2.0516955852508545
Validation loss: 1.9249433879372027
Epoch: 9| Step: 1
Training loss: 2.3692691326141357
Validation loss: 1.865651764458032
Epoch: 9| Step: 2
Training loss: 2.2450625896453857
Validation loss: 1.858323404257246
Epoch: 9| Step: 3
Training loss: 2.758089065551758
Validation loss: 1.8889352606354857
Epoch: 9| Step: 4
Training loss: 1.8066614866256714
Validation loss: 1.8484034478235587
Epoch: 9| Step: 5
Training loss: 2.409097671508789
Validation loss: 1.8146447655108335
Epoch: 9| Step: 6
Training loss: 2.6776139736175537
Validation loss: 1.8967961578918018
Epoch: 9| Step: 7
Training loss: 2.388148784637451
Validation loss: 1.8758631284288365
Epoch: 9| Step: 8
Training loss: 2.017515182495117
Validation loss: 1.8883738757895052
Epoch: 9| Step: 9
Training loss: 1.4443004131317139
Validation loss: 1.8359698683237857
Epoch: 9| Step: 10
Training loss: 1.9905409812927246
Validation loss: 1.8885397645209332
Epoch: 9| Step: 11
Training loss: 1.8840596675872803
Validation loss: 1.844401340690448
Epoch: 9| Step: 12
Training loss: 1.9552631378173828
Validation loss: 1.8593290829830031
Epoch: 9| Step: 13
Training loss: 1.6566448211669922
Validation loss: 1.8640342976549547
Epoch: 9| Step: 14
Training loss: 2.346858024597168
Validation loss: 1.8988839447927133
Epoch: 9| Step: 15
Training loss: 2.760408401489258
Validation loss: 1.8112670466196623
Epoch: 9| Step: 16
Training loss: 1.900456428527832
Validation loss: 1.8716547540623507
Epoch: 9| Step: 17
Training loss: 2.212712526321411
Validation loss: 1.9130161940622672
Epoch: 9| Step: 18
Training loss: 2.281372547149658
Validation loss: 1.8957020516018215
Epoch: 9| Step: 19
Training loss: 1.8653497695922852
Validation loss: 1.8455415260877541
Epoch: 22| Step: 0
Training loss: 2.2125489711761475
Validation loss: 1.87921114276639
Epoch: 9| Step: 1
Training loss: 1.688022494316101
Validation loss: 1.8830308682626957
Epoch: 9| Step: 2
Training loss: 2.998757839202881
Validation loss: 1.8782520800185718
Epoch: 9| Step: 3
Training loss: 2.0535292625427246
Validation loss: 1.9153169333505973
Epoch: 9| Step: 4
Training loss: 2.6216821670532227
Validation loss: 1.862003575983665
Epoch: 9| Step: 5
Training loss: 2.1441118717193604
Validation loss: 1.957752904446005
Epoch: 9| Step: 6
Training loss: 1.6946372985839844
Validation loss: 1.8943504549616532
Epoch: 9| Step: 7
Training loss: 2.2539806365966797
Validation loss: 1.90540537731253
Epoch: 9| Step: 8
Training loss: 1.700662612915039
Validation loss: 1.8898096204661636
Epoch: 9| Step: 9
Training loss: 1.8757874965667725
Validation loss: 1.8378905546750954
Epoch: 9| Step: 10
Training loss: 2.8690052032470703
Validation loss: 1.8726691856658717
Epoch: 9| Step: 11
Training loss: 2.0330471992492676
Validation loss: 1.870707882394036
Epoch: 9| Step: 12
Training loss: 2.059659004211426
Validation loss: 1.8743956423491883
Epoch: 9| Step: 13
Training loss: 2.448209762573242
Validation loss: 1.8955551463065388
Epoch: 9| Step: 14
Training loss: 1.7206130027770996
Validation loss: 1.9109399520235955
Epoch: 9| Step: 15
Training loss: 2.128455638885498
Validation loss: 1.8898162807492043
Epoch: 9| Step: 16
Training loss: 2.100937843322754
Validation loss: 1.8615552572895298
Epoch: 9| Step: 17
Training loss: 1.8972173929214478
Validation loss: 1.8855586257769907
Epoch: 9| Step: 18
Training loss: 2.2214274406433105
Validation loss: 1.8984326878897577
Epoch: 9| Step: 19
Training loss: 1.8777029514312744
Validation loss: 1.8991633181949314
Epoch: 23| Step: 0
Training loss: 2.233146905899048
Validation loss: 1.83262506148798
Epoch: 9| Step: 1
Training loss: 2.3989956378936768
Validation loss: 1.865798170618016
Epoch: 9| Step: 2
Training loss: 1.6728003025054932
Validation loss: 1.8540459656886916
Epoch: 9| Step: 3
Training loss: 1.9771502017974854
Validation loss: 1.8483896083969007
Epoch: 9| Step: 4
Training loss: 2.7352828979492188
Validation loss: 1.896056404216684
Epoch: 9| Step: 5
Training loss: 2.049210548400879
Validation loss: 1.8949237212860326
Epoch: 9| Step: 6
Training loss: 1.9119207859039307
Validation loss: 1.9204895616435318
Epoch: 9| Step: 7
Training loss: 1.7211743593215942
Validation loss: 1.9001793792779498
Epoch: 9| Step: 8
Training loss: 1.9345852136611938
Validation loss: 1.8898387778577188
Epoch: 9| Step: 9
Training loss: 2.0053176879882812
Validation loss: 1.8988349592085365
Epoch: 9| Step: 10
Training loss: 2.7169275283813477
Validation loss: 1.8756086946391373
Epoch: 9| Step: 11
Training loss: 2.2105860710144043
Validation loss: 1.9257678599666348
Epoch: 9| Step: 12
Training loss: 2.0890181064605713
Validation loss: 1.8774853533120464
Epoch: 9| Step: 13
Training loss: 1.824073314666748
Validation loss: 1.8772527125241945
Epoch: 9| Step: 14
Training loss: 2.8947739601135254
Validation loss: 1.9100511502876556
Epoch: 9| Step: 15
Training loss: 1.8462607860565186
Validation loss: 1.9181358119566663
Epoch: 9| Step: 16
Training loss: 2.29488468170166
Validation loss: 1.8865688224490598
Epoch: 9| Step: 17
Training loss: 2.0058536529541016
Validation loss: 1.8485440298807707
Epoch: 9| Step: 18
Training loss: 2.223432779312134
Validation loss: 1.859180649407476
Epoch: 9| Step: 19
Training loss: 2.0926289558410645
Validation loss: 1.8689168185638867
Epoch: 24| Step: 0
Training loss: 2.988384246826172
Validation loss: 1.8790110787041754
Epoch: 9| Step: 1
Training loss: 2.3669159412384033
Validation loss: 1.8927177499524124
Epoch: 9| Step: 2
Training loss: 1.8325231075286865
Validation loss: 1.8815232961297892
Epoch: 9| Step: 3
Training loss: 2.5718181133270264
Validation loss: 1.8937327201417882
Epoch: 9| Step: 4
Training loss: 1.4788610935211182
Validation loss: 1.8732472100703836
Epoch: 9| Step: 5
Training loss: 2.031860589981079
Validation loss: 1.8974066157992795
Epoch: 9| Step: 6
Training loss: 2.4327077865600586
Validation loss: 1.8127735870347605
Epoch: 9| Step: 7
Training loss: 2.810621500015259
Validation loss: 1.8355832297167332
Epoch: 9| Step: 8
Training loss: 1.7675282955169678
Validation loss: 1.799129131886599
Epoch: 9| Step: 9
Training loss: 1.8471198081970215
Validation loss: 1.9029861602851812
Epoch: 9| Step: 10
Training loss: 2.623173236846924
Validation loss: 1.8922333991784843
Epoch: 9| Step: 11
Training loss: 1.940543532371521
Validation loss: 1.8661879970015383
Epoch: 9| Step: 12
Training loss: 2.3095688819885254
Validation loss: 1.9089296910402587
Epoch: 9| Step: 13
Training loss: 2.178651809692383
Validation loss: 1.7980688784619887
Epoch: 9| Step: 14
Training loss: 2.4093689918518066
Validation loss: 1.8974066415279032
Epoch: 9| Step: 15
Training loss: 1.9721201658248901
Validation loss: 1.918444178944869
Epoch: 9| Step: 16
Training loss: 1.76011061668396
Validation loss: 1.864946184398459
Epoch: 9| Step: 17
Training loss: 2.403029441833496
Validation loss: 1.8293340849361832
Epoch: 9| Step: 18
Training loss: 2.208507537841797
Validation loss: 1.8444796886375483
Epoch: 9| Step: 19
Training loss: 1.6645617485046387
Validation loss: 1.8910265852221482
Epoch: 25| Step: 0
Training loss: 2.731005907058716
Validation loss: 1.8510987810093722
Epoch: 9| Step: 1
Training loss: 2.882887840270996
Validation loss: 1.8994593911891362
Epoch: 9| Step: 2
Training loss: 2.406696081161499
Validation loss: 1.9008798993748726
Epoch: 9| Step: 3
Training loss: 2.285987377166748
Validation loss: 1.908753109492844
Epoch: 9| Step: 4
Training loss: 1.8183544874191284
Validation loss: 1.8684552376218837
Epoch: 9| Step: 5
Training loss: 2.8490428924560547
Validation loss: 1.925169732930849
Epoch: 9| Step: 6
Training loss: 1.7885428667068481
Validation loss: 1.8370738243885179
Epoch: 9| Step: 7
Training loss: 1.3430161476135254
Validation loss: 1.8732836169304607
Epoch: 9| Step: 8
Training loss: 1.6881494522094727
Validation loss: 1.9049283514777533
Epoch: 9| Step: 9
Training loss: 3.0772268772125244
Validation loss: 1.8801340885299573
Epoch: 9| Step: 10
Training loss: 1.7064812183380127
Validation loss: 1.8917445793426295
Epoch: 9| Step: 11
Training loss: 2.0725197792053223
Validation loss: 1.9132606125564027
Epoch: 9| Step: 12
Training loss: 1.6937756538391113
Validation loss: 1.8765913556805618
Epoch: 9| Step: 13
Training loss: 2.318702459335327
Validation loss: 1.906996690969673
Epoch: 9| Step: 14
Training loss: 2.880073070526123
Validation loss: 1.9024955059984605
Epoch: 9| Step: 15
Training loss: 1.7896901369094849
Validation loss: 1.9176596789051303
Epoch: 9| Step: 16
Training loss: 2.0211830139160156
Validation loss: 1.9528538383168281
Epoch: 9| Step: 17
Training loss: 2.0774903297424316
Validation loss: 1.9035392622295901
Epoch: 9| Step: 18
Training loss: 1.540257453918457
Validation loss: 1.9072953196738263
Epoch: 9| Step: 19
Training loss: 1.9619814157485962
Validation loss: 1.891345780530422
Epoch: 26| Step: 0
Training loss: 3.0033106803894043
Validation loss: 1.916106688032905
Epoch: 9| Step: 1
Training loss: 2.1863174438476562
Validation loss: 1.9074578765484926
Epoch: 9| Step: 2
Training loss: 1.6460613012313843
Validation loss: 1.8335331180970447
Epoch: 9| Step: 3
Training loss: 2.248504877090454
Validation loss: 1.917176806669441
Epoch: 9| Step: 4
Training loss: 2.001004457473755
Validation loss: 1.9097376264256538
Epoch: 9| Step: 5
Training loss: 2.6650922298431396
Validation loss: 1.8692682698476228
Epoch: 9| Step: 6
Training loss: 2.1279211044311523
Validation loss: 1.9286689320914179
Epoch: 9| Step: 7
Training loss: 1.7025907039642334
Validation loss: 1.9464680942700063
Epoch: 9| Step: 8
Training loss: 1.6844661235809326
Validation loss: 1.8887842876448049
Epoch: 9| Step: 9
Training loss: 2.0625972747802734
Validation loss: 1.8449433261542012
Epoch: 9| Step: 10
Training loss: 1.618301510810852
Validation loss: 1.8557686342609871
Epoch: 9| Step: 11
Training loss: 2.72617244720459
Validation loss: 1.8734229897423613
Epoch: 9| Step: 12
Training loss: 1.9519898891448975
Validation loss: 1.8870215844764984
Epoch: 9| Step: 13
Training loss: 1.7017040252685547
Validation loss: 1.8818298320976092
Epoch: 9| Step: 14
Training loss: 2.432804584503174
Validation loss: 1.9153469269224208
Epoch: 9| Step: 15
Training loss: 2.3053059577941895
Validation loss: 1.9251097029061626
Epoch: 9| Step: 16
Training loss: 2.223508834838867
Validation loss: 1.900243027604741
Epoch: 9| Step: 17
Training loss: 1.915836215019226
Validation loss: 1.92047217080919
Epoch: 9| Step: 18
Training loss: 2.279109477996826
Validation loss: 1.8925744063562626
Epoch: 9| Step: 19
Training loss: 2.5088138580322266
Validation loss: 1.8729888706756153
Epoch: 27| Step: 0
Training loss: 1.1744794845581055
Validation loss: 1.943199002485481
Epoch: 9| Step: 1
Training loss: 2.0741817951202393
Validation loss: 1.9244419061880318
Epoch: 9| Step: 2
Training loss: 1.805964469909668
Validation loss: 1.9302237711364416
Epoch: 9| Step: 3
Training loss: 2.1193137168884277
Validation loss: 1.898603753220263
Epoch: 9| Step: 4
Training loss: 2.3853776454925537
Validation loss: 1.8734572534080889
Epoch: 9| Step: 5
Training loss: 2.524548292160034
Validation loss: 1.9027579045124192
Epoch: 9| Step: 6
Training loss: 2.5972225666046143
Validation loss: 1.9473404412646946
Epoch: 9| Step: 7
Training loss: 2.05505108833313
Validation loss: 1.9065055941506255
Epoch: 9| Step: 8
Training loss: 1.9476171731948853
Validation loss: 1.9233442244769858
Epoch: 9| Step: 9
Training loss: 1.293185830116272
Validation loss: 1.8945769457508335
Epoch: 9| Step: 10
Training loss: 2.041334629058838
Validation loss: 1.9346685315207612
Epoch: 9| Step: 11
Training loss: 1.0280122756958008
Validation loss: 1.9454041899537011
Epoch: 9| Step: 12
Training loss: 2.4325859546661377
Validation loss: 1.918992572551151
Epoch: 9| Step: 13
Training loss: 2.6226744651794434
Validation loss: 1.9627114268515606
Epoch: 9| Step: 14
Training loss: 2.6733129024505615
Validation loss: 1.9367083654129247
Epoch: 9| Step: 15
Training loss: 2.553072690963745
Validation loss: 1.9733764439178028
Epoch: 9| Step: 16
Training loss: 2.812669277191162
Validation loss: 1.934336138286179
Epoch: 9| Step: 17
Training loss: 2.123046636581421
Validation loss: 1.8744238366325983
Epoch: 9| Step: 18
Training loss: 1.4244627952575684
Validation loss: 1.931589575980207
Epoch: 9| Step: 19
Training loss: 2.934141159057617
Validation loss: 1.9195338985045178
Epoch: 28| Step: 0
Training loss: 1.8071770668029785
Validation loss: 1.9508861569191913
Epoch: 9| Step: 1
Training loss: 2.096766471862793
Validation loss: 1.8829021085080484
Epoch: 9| Step: 2
Training loss: 1.973389744758606
Validation loss: 1.885878684709398
Epoch: 9| Step: 3
Training loss: 2.1891238689422607
Validation loss: 1.9127761528646345
Epoch: 9| Step: 4
Training loss: 2.2538959980010986
Validation loss: 1.840303598548011
Epoch: 9| Step: 5
Training loss: 2.5068469047546387
Validation loss: 1.8711456274814744
Epoch: 9| Step: 6
Training loss: 1.8899879455566406
Validation loss: 1.9536897690176107
Epoch: 9| Step: 7
Training loss: 1.349692702293396
Validation loss: 1.8121746075239114
Epoch: 9| Step: 8
Training loss: 1.7441763877868652
Validation loss: 1.8529547693060457
Epoch: 9| Step: 9
Training loss: 2.0899200439453125
Validation loss: 1.8477851915702546
Epoch: 9| Step: 10
Training loss: 2.5824732780456543
Validation loss: 1.8978903499438609
Epoch: 9| Step: 11
Training loss: 2.6682686805725098
Validation loss: 1.919355177193237
Epoch: 9| Step: 12
Training loss: 2.628054141998291
Validation loss: 1.8091934207532046
Epoch: 9| Step: 13
Training loss: 1.993289589881897
Validation loss: 1.8593161294786194
Epoch: 9| Step: 14
Training loss: 1.3614765405654907
Validation loss: 1.841650504860089
Epoch: 9| Step: 15
Training loss: 1.6081559658050537
Validation loss: 1.843627877372632
Epoch: 9| Step: 16
Training loss: 2.687559127807617
Validation loss: 1.8718172303206628
Epoch: 9| Step: 17
Training loss: 3.3391919136047363
Validation loss: 1.8646050554385287
Epoch: 9| Step: 18
Training loss: 2.245647430419922
Validation loss: 1.865765326314693
Epoch: 9| Step: 19
Training loss: 2.019047737121582
Validation loss: 1.854044304477225
Epoch: 29| Step: 0
Training loss: 2.4997873306274414
Validation loss: 1.832202365072511
Epoch: 9| Step: 1
Training loss: 2.344203472137451
Validation loss: 1.845347102597463
Epoch: 9| Step: 2
Training loss: 1.7949166297912598
Validation loss: 1.8338015259598657
Epoch: 9| Step: 3
Training loss: 1.8578120470046997
Validation loss: 1.8545375865140408
Epoch: 9| Step: 4
Training loss: 2.5121805667877197
Validation loss: 1.8634836527941039
Epoch: 9| Step: 5
Training loss: 2.0743370056152344
Validation loss: 1.8866409354930302
Epoch: 9| Step: 6
Training loss: 1.7718186378479004
Validation loss: 1.8651367683204816
Epoch: 9| Step: 7
Training loss: 2.403902292251587
Validation loss: 1.8323631766888735
Epoch: 9| Step: 8
Training loss: 2.4113271236419678
Validation loss: 1.859771274834228
Epoch: 9| Step: 9
Training loss: 1.9145050048828125
Validation loss: 1.8214435886136062
Epoch: 9| Step: 10
Training loss: 1.6204355955123901
Validation loss: 1.850326390575162
Epoch: 9| Step: 11
Training loss: 1.8931559324264526
Validation loss: 1.8683217969729746
Epoch: 9| Step: 12
Training loss: 2.055704116821289
Validation loss: 1.8365926365200564
Epoch: 9| Step: 13
Training loss: 2.162705898284912
Validation loss: 1.8233390351851209
Epoch: 9| Step: 14
Training loss: 2.5829010009765625
Validation loss: 1.8213597295953214
Epoch: 9| Step: 15
Training loss: 2.099555253982544
Validation loss: 1.8956858648670663
Epoch: 9| Step: 16
Training loss: 1.8002444505691528
Validation loss: 1.8820436927054425
Epoch: 9| Step: 17
Training loss: 1.981386423110962
Validation loss: 1.8315912013431248
Epoch: 9| Step: 18
Training loss: 2.5161843299865723
Validation loss: 1.8893179679088454
Epoch: 9| Step: 19
Training loss: 2.7543582916259766
Validation loss: 1.8413207599585004
Epoch: 30| Step: 0
Training loss: 1.7731597423553467
Validation loss: 1.8885072787030994
Epoch: 9| Step: 1
Training loss: 2.208841323852539
Validation loss: 1.8437300525980889
Epoch: 9| Step: 2
Training loss: 1.9935437440872192
Validation loss: 1.8822837184659011
Epoch: 9| Step: 3
Training loss: 1.8015856742858887
Validation loss: 1.8760379235521496
Epoch: 9| Step: 4
Training loss: 1.6405491828918457
Validation loss: 1.817417589022959
Epoch: 9| Step: 5
Training loss: 2.2630162239074707
Validation loss: 1.8467554154155923
Epoch: 9| Step: 6
Training loss: 2.2589311599731445
Validation loss: 1.9082444520305386
Epoch: 9| Step: 7
Training loss: 2.6532809734344482
Validation loss: 1.8653361068355094
Epoch: 9| Step: 8
Training loss: 1.911179780960083
Validation loss: 1.8468325403954486
Epoch: 9| Step: 9
Training loss: 1.9317084550857544
Validation loss: 1.8854497362383835
Epoch: 9| Step: 10
Training loss: 2.5423777103424072
Validation loss: 1.8422415050671255
Epoch: 9| Step: 11
Training loss: 1.6211555004119873
Validation loss: 1.8180039057628714
Epoch: 9| Step: 12
Training loss: 2.3151278495788574
Validation loss: 1.8596972613025913
Epoch: 9| Step: 13
Training loss: 1.4515962600708008
Validation loss: 1.9010636180424862
Epoch: 9| Step: 14
Training loss: 2.1641054153442383
Validation loss: 1.8517429734305513
Epoch: 9| Step: 15
Training loss: 2.4324300289154053
Validation loss: 1.8727526235923493
Epoch: 9| Step: 16
Training loss: 2.1801586151123047
Validation loss: 1.8436945119350077
Epoch: 9| Step: 17
Training loss: 2.5670318603515625
Validation loss: 1.8455599469246624
Epoch: 9| Step: 18
Training loss: 2.893742561340332
Validation loss: 1.8899956984485653
Epoch: 9| Step: 19
Training loss: 2.360520124435425
Validation loss: 1.8624418124878148
Epoch: 31| Step: 0
Training loss: 1.846640706062317
Validation loss: 1.889122352325659
Epoch: 9| Step: 1
Training loss: 1.5062015056610107
Validation loss: 1.8555340826940194
Epoch: 9| Step: 2
Training loss: 2.771271228790283
Validation loss: 1.8860049170555828
Epoch: 9| Step: 3
Training loss: 2.1171317100524902
Validation loss: 1.9130855481401623
Epoch: 9| Step: 4
Training loss: 2.5294547080993652
Validation loss: 1.878645124195291
Epoch: 9| Step: 5
Training loss: 2.6423850059509277
Validation loss: 1.8809516661458736
Epoch: 9| Step: 6
Training loss: 1.5984712839126587
Validation loss: 1.8788961060613178
Epoch: 9| Step: 7
Training loss: 1.5722572803497314
Validation loss: 1.9014289370543664
Epoch: 9| Step: 8
Training loss: 1.8995319604873657
Validation loss: 1.870194705270177
Epoch: 9| Step: 9
Training loss: 2.102264881134033
Validation loss: 1.8617144411416362
Epoch: 9| Step: 10
Training loss: 1.626030445098877
Validation loss: 1.8659174913982692
Epoch: 9| Step: 11
Training loss: 2.1097517013549805
Validation loss: 1.9415483440426613
Epoch: 9| Step: 12
Training loss: 2.95329213142395
Validation loss: 1.9373111296043122
Epoch: 9| Step: 13
Training loss: 2.0121662616729736
Validation loss: 1.8553333848500424
Epoch: 9| Step: 14
Training loss: 2.0690765380859375
Validation loss: 1.9120034691241148
Epoch: 9| Step: 15
Training loss: 2.499838352203369
Validation loss: 1.9278929087755492
Epoch: 9| Step: 16
Training loss: 2.0603487491607666
Validation loss: 1.8021704318712084
Epoch: 9| Step: 17
Training loss: 1.8048568964004517
Validation loss: 1.8975815404233316
Epoch: 9| Step: 18
Training loss: 2.041767120361328
Validation loss: 1.831384669104926
Epoch: 9| Step: 19
Training loss: 2.4782791137695312
Validation loss: 1.8864628625430648
Epoch: 32| Step: 0
Training loss: 1.9116114377975464
Validation loss: 1.8788010156411918
Epoch: 9| Step: 1
Training loss: 2.238551616668701
Validation loss: 1.8871150951591327
Epoch: 9| Step: 2
Training loss: 2.495720386505127
Validation loss: 1.8871700317739584
Epoch: 9| Step: 3
Training loss: 1.8807432651519775
Validation loss: 1.9070701316106233
Epoch: 9| Step: 4
Training loss: 2.2284584045410156
Validation loss: 1.8735072972963183
Epoch: 9| Step: 5
Training loss: 1.8343498706817627
Validation loss: 1.930459838976963
Epoch: 9| Step: 6
Training loss: 2.6486124992370605
Validation loss: 1.8929157625857016
Epoch: 9| Step: 7
Training loss: 2.1456737518310547
Validation loss: 1.8854868351984366
Epoch: 9| Step: 8
Training loss: 2.1074442863464355
Validation loss: 1.91296348640387
Epoch: 9| Step: 9
Training loss: 2.586876630783081
Validation loss: 1.8614374107594112
Epoch: 9| Step: 10
Training loss: 2.702174186706543
Validation loss: 1.8447280899226237
Epoch: 9| Step: 11
Training loss: 2.1304290294647217
Validation loss: 1.936141966058196
Epoch: 9| Step: 12
Training loss: 1.4747493267059326
Validation loss: 1.87475005928561
Epoch: 9| Step: 13
Training loss: 2.2946646213531494
Validation loss: 1.867162835683754
Epoch: 9| Step: 14
Training loss: 1.8377504348754883
Validation loss: 1.886573104549655
Epoch: 9| Step: 15
Training loss: 2.221010208129883
Validation loss: 1.9290553923133467
Epoch: 9| Step: 16
Training loss: 2.093430757522583
Validation loss: 1.89096468129604
Epoch: 9| Step: 17
Training loss: 1.9872719049453735
Validation loss: 1.9102606121584667
Epoch: 9| Step: 18
Training loss: 1.894205093383789
Validation loss: 1.9139006763911075
Epoch: 9| Step: 19
Training loss: 2.0100436210632324
Validation loss: 1.9165280396989781
Epoch: 33| Step: 0
Training loss: 2.27500581741333
Validation loss: 1.8619489626918766
Epoch: 9| Step: 1
Training loss: 1.9370211362838745
Validation loss: 1.8616490621360944
Epoch: 9| Step: 2
Training loss: 2.2503974437713623
Validation loss: 1.93848061047012
Epoch: 9| Step: 3
Training loss: 2.294019937515259
Validation loss: 1.9141282537858264
Epoch: 9| Step: 4
Training loss: 1.7132468223571777
Validation loss: 1.8620052783609293
Epoch: 9| Step: 5
Training loss: 1.9129741191864014
Validation loss: 1.8766364519544643
Epoch: 9| Step: 6
Training loss: 1.951615571975708
Validation loss: 1.8477963037628065
Epoch: 9| Step: 7
Training loss: 1.9431631565093994
Validation loss: 1.833411997170757
Epoch: 9| Step: 8
Training loss: 2.050304651260376
Validation loss: 1.8678659397921116
Epoch: 9| Step: 9
Training loss: 2.9029219150543213
Validation loss: 1.8495642178350216
Epoch: 9| Step: 10
Training loss: 2.5442700386047363
Validation loss: 1.89942690279844
Epoch: 9| Step: 11
Training loss: 1.597064733505249
Validation loss: 1.875135967199751
Epoch: 9| Step: 12
Training loss: 2.042640447616577
Validation loss: 1.9260456210417713
Epoch: 9| Step: 13
Training loss: 2.4117560386657715
Validation loss: 1.9063389935939432
Epoch: 9| Step: 14
Training loss: 2.2356250286102295
Validation loss: 1.9142741170718516
Epoch: 9| Step: 15
Training loss: 1.7119108438491821
Validation loss: 1.9048370594600978
Epoch: 9| Step: 16
Training loss: 2.0281267166137695
Validation loss: 1.8512674775912608
Epoch: 9| Step: 17
Training loss: 2.4689550399780273
Validation loss: 1.849715254289641
Epoch: 9| Step: 18
Training loss: 2.613607883453369
Validation loss: 1.8826583426633328
Epoch: 9| Step: 19
Training loss: 1.282377004623413
Validation loss: 1.8624404394369332
Epoch: 34| Step: 0
Training loss: 1.6977143287658691
Validation loss: 1.8472986315651763
Epoch: 9| Step: 1
Training loss: 1.5439996719360352
Validation loss: 1.9096180826639957
Epoch: 9| Step: 2
Training loss: 1.9991955757141113
Validation loss: 1.877903610682316
Epoch: 9| Step: 3
Training loss: 1.395620346069336
Validation loss: 1.8662006923620649
Epoch: 9| Step: 4
Training loss: 1.4977588653564453
Validation loss: 1.8622637000872935
Epoch: 9| Step: 5
Training loss: 1.8542016744613647
Validation loss: 1.8812874152505998
Epoch: 9| Step: 6
Training loss: 2.8871612548828125
Validation loss: 1.8428422752901805
Epoch: 9| Step: 7
Training loss: 2.0759363174438477
Validation loss: 1.8860735876097097
Epoch: 9| Step: 8
Training loss: 1.74618399143219
Validation loss: 1.8799792691100417
Epoch: 9| Step: 9
Training loss: 2.6697473526000977
Validation loss: 1.8272311490216702
Epoch: 9| Step: 10
Training loss: 2.4545507431030273
Validation loss: 1.8267004850099413
Epoch: 9| Step: 11
Training loss: 1.912624716758728
Validation loss: 1.8824539047350985
Epoch: 9| Step: 12
Training loss: 2.6038804054260254
Validation loss: 1.8442498351172578
Epoch: 9| Step: 13
Training loss: 2.2285029888153076
Validation loss: 1.8010354350796707
Epoch: 9| Step: 14
Training loss: 3.236672878265381
Validation loss: 1.882791956551641
Epoch: 9| Step: 15
Training loss: 2.3485145568847656
Validation loss: 1.8503574836168357
Epoch: 9| Step: 16
Training loss: 1.7472097873687744
Validation loss: 1.8382700904667806
Epoch: 9| Step: 17
Training loss: 2.3199892044067383
Validation loss: 1.8294664312609665
Epoch: 9| Step: 18
Training loss: 2.554246425628662
Validation loss: 1.830350491640379
Epoch: 9| Step: 19
Training loss: 1.807943344116211
Validation loss: 1.8673745796834822
Epoch: 35| Step: 0
Training loss: 2.027858257293701
Validation loss: 1.7950025025031549
Epoch: 9| Step: 1
Training loss: 1.798835277557373
Validation loss: 1.832767651235457
Epoch: 9| Step: 2
Training loss: 2.522618293762207
Validation loss: 1.8081704206603895
Epoch: 9| Step: 3
Training loss: 2.193526268005371
Validation loss: 1.860424263871831
Epoch: 9| Step: 4
Training loss: 2.0494842529296875
Validation loss: 1.8952188989241345
Epoch: 9| Step: 5
Training loss: 1.6166713237762451
Validation loss: 1.824852065216723
Epoch: 9| Step: 6
Training loss: 1.6502010822296143
Validation loss: 1.8817735678858036
Epoch: 9| Step: 7
Training loss: 1.8549168109893799
Validation loss: 1.8459318850537856
Epoch: 9| Step: 8
Training loss: 2.540053367614746
Validation loss: 1.85878153670606
Epoch: 9| Step: 9
Training loss: 2.738102912902832
Validation loss: 1.8963338050910894
Epoch: 9| Step: 10
Training loss: 2.7218804359436035
Validation loss: 1.8453119169893881
Epoch: 9| Step: 11
Training loss: 1.9977812767028809
Validation loss: 1.8823347520485199
Epoch: 9| Step: 12
Training loss: 2.0266170501708984
Validation loss: 1.8651391306369425
Epoch: 9| Step: 13
Training loss: 1.5609400272369385
Validation loss: 1.848451552631186
Epoch: 9| Step: 14
Training loss: 2.2110819816589355
Validation loss: 1.8765329902978252
Epoch: 9| Step: 15
Training loss: 2.391037940979004
Validation loss: 1.8171221086447187
Epoch: 9| Step: 16
Training loss: 1.769106149673462
Validation loss: 1.894756296555773
Epoch: 9| Step: 17
Training loss: 2.1525962352752686
Validation loss: 1.8473364432081043
Epoch: 9| Step: 18
Training loss: 2.8196399211883545
Validation loss: 1.8229405219606358
Epoch: 9| Step: 19
Training loss: 1.4859819412231445
Validation loss: 1.835901044255538
Epoch: 36| Step: 0
Training loss: 1.340615153312683
Validation loss: 1.8337831514344798
Epoch: 9| Step: 1
Training loss: 2.116246461868286
Validation loss: 1.904618230655039
Epoch: 9| Step: 2
Training loss: 2.0063443183898926
Validation loss: 1.8397289788980278
Epoch: 9| Step: 3
Training loss: 2.441662073135376
Validation loss: 1.9072978093469743
Epoch: 9| Step: 4
Training loss: 1.524761438369751
Validation loss: 1.8503905406101144
Epoch: 9| Step: 5
Training loss: 2.4702401161193848
Validation loss: 1.8799315270760077
Epoch: 9| Step: 6
Training loss: 2.0163652896881104
Validation loss: 1.8618796060411194
Epoch: 9| Step: 7
Training loss: 2.278730869293213
Validation loss: 1.903650112289319
Epoch: 9| Step: 8
Training loss: 3.2122135162353516
Validation loss: 1.85344384985862
Epoch: 9| Step: 9
Training loss: 2.3878493309020996
Validation loss: 1.9261648277584598
Epoch: 9| Step: 10
Training loss: 2.313581943511963
Validation loss: 1.8774346121781165
Epoch: 9| Step: 11
Training loss: 2.0789687633514404
Validation loss: 1.9244693766394965
Epoch: 9| Step: 12
Training loss: 2.0773086547851562
Validation loss: 1.8957388040830763
Epoch: 9| Step: 13
Training loss: 2.1406755447387695
Validation loss: 1.9445144315417722
Epoch: 9| Step: 14
Training loss: 1.8476399183273315
Validation loss: 1.8822108490003957
Epoch: 9| Step: 15
Training loss: 2.0109329223632812
Validation loss: 1.8970188142584383
Epoch: 9| Step: 16
Training loss: 2.3785877227783203
Validation loss: 1.8683791460750772
Epoch: 9| Step: 17
Training loss: 1.545785903930664
Validation loss: 1.8664240253915032
Epoch: 9| Step: 18
Training loss: 1.5971968173980713
Validation loss: 1.9586289812335007
Epoch: 9| Step: 19
Training loss: 2.5593502521514893
Validation loss: 1.9156167541476463
Epoch: 37| Step: 0
Training loss: 1.931612253189087
Validation loss: 1.892827523698052
Epoch: 9| Step: 1
Training loss: 2.317410945892334
Validation loss: 1.8945703626536636
Epoch: 9| Step: 2
Training loss: 1.6171011924743652
Validation loss: 1.8540926073952544
Epoch: 9| Step: 3
Training loss: 2.082803964614868
Validation loss: 1.8739884723004678
Epoch: 9| Step: 4
Training loss: 1.9234881401062012
Validation loss: 1.9167702712601038
Epoch: 9| Step: 5
Training loss: 2.21919846534729
Validation loss: 1.846603545353567
Epoch: 9| Step: 6
Training loss: 2.0458035469055176
Validation loss: 1.8640152370329384
Epoch: 9| Step: 7
Training loss: 2.3836252689361572
Validation loss: 1.8881304469897593
Epoch: 9| Step: 8
Training loss: 1.9731686115264893
Validation loss: 1.8935301235253863
Epoch: 9| Step: 9
Training loss: 1.4581966400146484
Validation loss: 1.910644514955205
Epoch: 9| Step: 10
Training loss: 1.8384095430374146
Validation loss: 1.8852031779803817
Epoch: 9| Step: 11
Training loss: 2.875654697418213
Validation loss: 1.8515631835237683
Epoch: 9| Step: 12
Training loss: 2.5965986251831055
Validation loss: 1.918733842938924
Epoch: 9| Step: 13
Training loss: 2.0383994579315186
Validation loss: 1.8702790582780358
Epoch: 9| Step: 14
Training loss: 2.317106246948242
Validation loss: 1.9109357235242994
Epoch: 9| Step: 15
Training loss: 2.164541244506836
Validation loss: 1.8412497009304787
Epoch: 9| Step: 16
Training loss: 2.083820343017578
Validation loss: 1.902787750573467
Epoch: 9| Step: 17
Training loss: 1.7035093307495117
Validation loss: 1.9298852639232609
Epoch: 9| Step: 18
Training loss: 2.2996530532836914
Validation loss: 1.8962180134203794
Epoch: 9| Step: 19
Training loss: 1.7897911071777344
Validation loss: 1.9172060485366438
Epoch: 38| Step: 0
Training loss: 1.7079811096191406
Validation loss: 1.8488619087411344
Epoch: 9| Step: 1
Training loss: 1.204390287399292
Validation loss: 1.9021728398988573
Epoch: 9| Step: 2
Training loss: 2.5887205600738525
Validation loss: 1.8975934947994972
Epoch: 9| Step: 3
Training loss: 2.318903923034668
Validation loss: 1.9520836065141418
Epoch: 9| Step: 4
Training loss: 2.31437349319458
Validation loss: 1.9706344175681794
Epoch: 9| Step: 5
Training loss: 2.121218204498291
Validation loss: 1.8903096399718908
Epoch: 9| Step: 6
Training loss: 2.3805017471313477
Validation loss: 1.8956100220302883
Epoch: 9| Step: 7
Training loss: 1.2058237791061401
Validation loss: 1.8749321904971445
Epoch: 9| Step: 8
Training loss: 2.5245351791381836
Validation loss: 1.9091542487521824
Epoch: 9| Step: 9
Training loss: 2.1626014709472656
Validation loss: 1.8676765205191195
Epoch: 9| Step: 10
Training loss: 2.334181308746338
Validation loss: 1.902991804287588
Epoch: 9| Step: 11
Training loss: 2.2490556240081787
Validation loss: 1.910289290997622
Epoch: 9| Step: 12
Training loss: 2.1988184452056885
Validation loss: 1.9080073627636587
Epoch: 9| Step: 13
Training loss: 1.7834393978118896
Validation loss: 1.8933080717814055
Epoch: 9| Step: 14
Training loss: 1.585935115814209
Validation loss: 1.863412116071303
Epoch: 9| Step: 15
Training loss: 1.5325944423675537
Validation loss: 1.8935780293649906
Epoch: 9| Step: 16
Training loss: 2.398911952972412
Validation loss: 1.8447790454617508
Epoch: 9| Step: 17
Training loss: 2.4504008293151855
Validation loss: 1.8949784297737287
Epoch: 9| Step: 18
Training loss: 2.2821426391601562
Validation loss: 1.9214371348456514
Epoch: 9| Step: 19
Training loss: 2.3079864978790283
Validation loss: 1.9015803542926157
Epoch: 39| Step: 0
Training loss: 2.23052978515625
Validation loss: 1.903354809438582
Epoch: 9| Step: 1
Training loss: 2.1921920776367188
Validation loss: 1.9096421903843501
Epoch: 9| Step: 2
Training loss: 1.4952601194381714
Validation loss: 1.8885362105403873
Epoch: 9| Step: 3
Training loss: 1.7512733936309814
Validation loss: 1.8735838245144851
Epoch: 9| Step: 4
Training loss: 2.2288753986358643
Validation loss: 1.815433613687968
Epoch: 9| Step: 5
Training loss: 2.3147776126861572
Validation loss: 1.908265091532426
Epoch: 9| Step: 6
Training loss: 2.380615711212158
Validation loss: 1.8960849166774063
Epoch: 9| Step: 7
Training loss: 2.90500545501709
Validation loss: 1.882847737922943
Epoch: 9| Step: 8
Training loss: 1.6052062511444092
Validation loss: 1.9586849898743115
Epoch: 9| Step: 9
Training loss: 2.198646068572998
Validation loss: 1.8936289488840445
Epoch: 9| Step: 10
Training loss: 1.9261269569396973
Validation loss: 1.8523646250045558
Epoch: 9| Step: 11
Training loss: 1.9827656745910645
Validation loss: 1.8902657563737828
Epoch: 9| Step: 12
Training loss: 1.5887435674667358
Validation loss: 1.8807226076400538
Epoch: 9| Step: 13
Training loss: 2.371401071548462
Validation loss: 1.9189517823912257
Epoch: 9| Step: 14
Training loss: 1.8656219244003296
Validation loss: 1.8680263611910155
Epoch: 9| Step: 15
Training loss: 1.8925795555114746
Validation loss: 1.8904070974253921
Epoch: 9| Step: 16
Training loss: 2.1356780529022217
Validation loss: 1.8868781165253343
Epoch: 9| Step: 17
Training loss: 2.2491917610168457
Validation loss: 1.9142897060449175
Epoch: 9| Step: 18
Training loss: 2.6609320640563965
Validation loss: 1.8849844649541292
Epoch: 9| Step: 19
Training loss: 2.5785140991210938
Validation loss: 1.8916226299546606
Epoch: 40| Step: 0
Training loss: 1.7931084632873535
Validation loss: 1.8826720525892517
Epoch: 9| Step: 1
Training loss: 1.7438042163848877
Validation loss: 1.85991748288381
Epoch: 9| Step: 2
Training loss: 2.218541145324707
Validation loss: 1.8967143640243749
Epoch: 9| Step: 3
Training loss: 1.9737604856491089
Validation loss: 1.8416796776888182
Epoch: 9| Step: 4
Training loss: 2.577242136001587
Validation loss: 1.8147359837731012
Epoch: 9| Step: 5
Training loss: 2.741267204284668
Validation loss: 1.8824474245524234
Epoch: 9| Step: 6
Training loss: 2.6671485900878906
Validation loss: 1.871284639235023
Epoch: 9| Step: 7
Training loss: 2.3330070972442627
Validation loss: 1.8358023286723404
Epoch: 9| Step: 8
Training loss: 2.349146604537964
Validation loss: 1.9027450033229032
Epoch: 9| Step: 9
Training loss: 2.2857141494750977
Validation loss: 1.851217241595975
Epoch: 9| Step: 10
Training loss: 2.0646204948425293
Validation loss: 1.8818603582519422
Epoch: 9| Step: 11
Training loss: 1.9261462688446045
Validation loss: 1.875418550676579
Epoch: 9| Step: 12
Training loss: 1.9995611906051636
Validation loss: 1.9098355675772798
Epoch: 9| Step: 13
Training loss: 2.708740472793579
Validation loss: 1.9031002521514893
Epoch: 9| Step: 14
Training loss: 2.2530181407928467
Validation loss: 1.8527283162521802
Epoch: 9| Step: 15
Training loss: 1.9691994190216064
Validation loss: 1.8838740561505873
Epoch: 9| Step: 16
Training loss: 1.969475507736206
Validation loss: 1.8861849033575264
Epoch: 9| Step: 17
Training loss: 1.4056892395019531
Validation loss: 1.9051415928833777
Epoch: 9| Step: 18
Training loss: 1.7618944644927979
Validation loss: 1.875661841399378
Epoch: 9| Step: 19
Training loss: 2.1337218284606934
Validation loss: 1.9262199247483727
Epoch: 41| Step: 0
Training loss: 2.103339195251465
Validation loss: 1.8796907448940139
Epoch: 9| Step: 1
Training loss: 2.4462757110595703
Validation loss: 1.9025321649990494
Epoch: 9| Step: 2
Training loss: 2.2074995040893555
Validation loss: 1.8862528440763624
Epoch: 9| Step: 3
Training loss: 2.683659553527832
Validation loss: 1.8865249645795754
Epoch: 9| Step: 4
Training loss: 2.0601158142089844
Validation loss: 1.874070126375706
Epoch: 9| Step: 5
Training loss: 1.9318146705627441
Validation loss: 1.872780693520745
Epoch: 9| Step: 6
Training loss: 1.7869699001312256
Validation loss: 1.8163298154048781
Epoch: 9| Step: 7
Training loss: 1.7873789072036743
Validation loss: 1.8920682745871784
Epoch: 9| Step: 8
Training loss: 1.5283963680267334
Validation loss: 1.8416722635571048
Epoch: 9| Step: 9
Training loss: 1.714714527130127
Validation loss: 1.8364099555735967
Epoch: 9| Step: 10
Training loss: 1.986057996749878
Validation loss: 1.9021548144251323
Epoch: 9| Step: 11
Training loss: 2.322334051132202
Validation loss: 1.8904160509864203
Epoch: 9| Step: 12
Training loss: 1.4424488544464111
Validation loss: 1.9155004153148734
Epoch: 9| Step: 13
Training loss: 2.245954751968384
Validation loss: 1.9049795703064623
Epoch: 9| Step: 14
Training loss: 3.3884525299072266
Validation loss: 1.9143154158009041
Epoch: 9| Step: 15
Training loss: 2.273221492767334
Validation loss: 1.876510791641345
Epoch: 9| Step: 16
Training loss: 1.3752716779708862
Validation loss: 1.851896881199569
Epoch: 9| Step: 17
Training loss: 2.208977222442627
Validation loss: 1.9225571009752562
Epoch: 9| Step: 18
Training loss: 2.349766254425049
Validation loss: 1.9375493989573966
Epoch: 9| Step: 19
Training loss: 1.906766414642334
Validation loss: 1.89801966672321
Epoch: 42| Step: 0
Training loss: 2.0943822860717773
Validation loss: 1.8544161645628565
Epoch: 9| Step: 1
Training loss: 2.1733522415161133
Validation loss: 1.9142569423579483
Epoch: 9| Step: 2
Training loss: 1.6072195768356323
Validation loss: 1.992116166533326
Epoch: 9| Step: 3
Training loss: 2.3951308727264404
Validation loss: 1.9001542655684107
Epoch: 9| Step: 4
Training loss: 2.2223966121673584
Validation loss: 1.9486179025910741
Epoch: 9| Step: 5
Training loss: 2.6161320209503174
Validation loss: 1.928852025553477
Epoch: 9| Step: 6
Training loss: 1.903322696685791
Validation loss: 1.9564111138419282
Epoch: 9| Step: 7
Training loss: 1.9894185066223145
Validation loss: 1.893205838237735
Epoch: 9| Step: 8
Training loss: 2.2655136585235596
Validation loss: 1.907104180013533
Epoch: 9| Step: 9
Training loss: 1.9837778806686401
Validation loss: 1.8949162059550664
Epoch: 9| Step: 10
Training loss: 2.6315433979034424
Validation loss: 1.8994567274189682
Epoch: 9| Step: 11
Training loss: 1.850256323814392
Validation loss: 1.9277103933499014
Epoch: 9| Step: 12
Training loss: 2.7884368896484375
Validation loss: 1.8765789004538556
Epoch: 9| Step: 13
Training loss: 2.1193690299987793
Validation loss: 1.892311554160907
Epoch: 9| Step: 14
Training loss: 2.3390750885009766
Validation loss: 1.8724624390224758
Epoch: 9| Step: 15
Training loss: 1.59486722946167
Validation loss: 1.821309581077356
Epoch: 9| Step: 16
Training loss: 2.183867931365967
Validation loss: 1.8779348881124593
Epoch: 9| Step: 17
Training loss: 1.8595610857009888
Validation loss: 1.870909612813442
Epoch: 9| Step: 18
Training loss: 2.1413002014160156
Validation loss: 1.8781102166759025
Epoch: 9| Step: 19
Training loss: 1.978824496269226
Validation loss: 1.942477709097828
Epoch: 43| Step: 0
Training loss: 2.4528207778930664
Validation loss: 1.8265899874323563
Epoch: 9| Step: 1
Training loss: 1.9415855407714844
Validation loss: 1.9017222810992234
Epoch: 9| Step: 2
Training loss: 1.9792537689208984
Validation loss: 1.8478980801945968
Epoch: 9| Step: 3
Training loss: 2.830552577972412
Validation loss: 1.8723350060071877
Epoch: 9| Step: 4
Training loss: 1.902783989906311
Validation loss: 1.860557060447528
Epoch: 9| Step: 5
Training loss: 1.4525930881500244
Validation loss: 1.8825558827077742
Epoch: 9| Step: 6
Training loss: 2.2803564071655273
Validation loss: 1.8862345604587802
Epoch: 9| Step: 7
Training loss: 2.248525857925415
Validation loss: 1.8862231652513683
Epoch: 9| Step: 8
Training loss: 2.2154130935668945
Validation loss: 1.8674135979988593
Epoch: 9| Step: 9
Training loss: 1.2164456844329834
Validation loss: 1.845670833862085
Epoch: 9| Step: 10
Training loss: 2.076897621154785
Validation loss: 1.9210592859940563
Epoch: 9| Step: 11
Training loss: 2.1366662979125977
Validation loss: 1.9160055145085286
Epoch: 9| Step: 12
Training loss: 2.290710926055908
Validation loss: 1.9400118863839897
Epoch: 9| Step: 13
Training loss: 2.437775135040283
Validation loss: 1.8825207734279494
Epoch: 9| Step: 14
Training loss: 1.7688300609588623
Validation loss: 1.9219613778505393
Epoch: 9| Step: 15
Training loss: 2.582411289215088
Validation loss: 1.8966054641943184
Epoch: 9| Step: 16
Training loss: 2.0173680782318115
Validation loss: 1.9087752202431933
Epoch: 9| Step: 17
Training loss: 1.871199607849121
Validation loss: 1.9750497126750808
Epoch: 9| Step: 18
Training loss: 2.9139516353607178
Validation loss: 1.9366405130290298
Epoch: 9| Step: 19
Training loss: 1.732922911643982
Validation loss: 1.957908014599368
Epoch: 44| Step: 0
Training loss: 1.8592655658721924
Validation loss: 1.9002125846396247
Epoch: 9| Step: 1
Training loss: 2.2657461166381836
Validation loss: 1.8952889622544213
Epoch: 9| Step: 2
Training loss: 2.2682762145996094
Validation loss: 1.9094140375260826
Epoch: 9| Step: 3
Training loss: 1.8816945552825928
Validation loss: 1.9248108469325005
Epoch: 9| Step: 4
Training loss: 2.4361531734466553
Validation loss: 1.8839397421843713
Epoch: 9| Step: 5
Training loss: 2.068669319152832
Validation loss: 1.9262316072587486
Epoch: 9| Step: 6
Training loss: 2.234124183654785
Validation loss: 1.9526626206130433
Epoch: 9| Step: 7
Training loss: 2.3552722930908203
Validation loss: 1.9545463289288307
Epoch: 9| Step: 8
Training loss: 1.722376823425293
Validation loss: 1.8887644928993939
Epoch: 9| Step: 9
Training loss: 1.3465458154678345
Validation loss: 1.9371166400772204
Epoch: 9| Step: 10
Training loss: 1.686172604560852
Validation loss: 1.9034614631597944
Epoch: 9| Step: 11
Training loss: 2.350025177001953
Validation loss: 1.9276124642049666
Epoch: 9| Step: 12
Training loss: 2.0531651973724365
Validation loss: 1.9298985055882296
Epoch: 9| Step: 13
Training loss: 1.9130897521972656
Validation loss: 1.931951795550559
Epoch: 9| Step: 14
Training loss: 3.3667266368865967
Validation loss: 1.9429289051097074
Epoch: 9| Step: 15
Training loss: 2.1084818840026855
Validation loss: 1.9213731151690585
Epoch: 9| Step: 16
Training loss: 1.451563835144043
Validation loss: 1.9309331941947663
Epoch: 9| Step: 17
Training loss: 2.2792115211486816
Validation loss: 1.9325144874106208
Epoch: 9| Step: 18
Training loss: 2.8466827869415283
Validation loss: 1.9298891266472906
Epoch: 9| Step: 19
Training loss: 1.6443567276000977
Validation loss: 1.890653441278197
Epoch: 45| Step: 0
Training loss: 1.756967544555664
Validation loss: 1.9386170570798915
Epoch: 9| Step: 1
Training loss: 1.413062334060669
Validation loss: 1.9080384669544028
Epoch: 9| Step: 2
Training loss: 1.8786818981170654
Validation loss: 1.9038756974309468
Epoch: 9| Step: 3
Training loss: 1.49469792842865
Validation loss: 1.8579045062442479
Epoch: 9| Step: 4
Training loss: 2.3831310272216797
Validation loss: 1.9188822104776506
Epoch: 9| Step: 5
Training loss: 1.894892930984497
Validation loss: 1.8491979142744763
Epoch: 9| Step: 6
Training loss: 1.9383821487426758
Validation loss: 1.8733821910062283
Epoch: 9| Step: 7
Training loss: 2.3928580284118652
Validation loss: 1.8678605650826323
Epoch: 9| Step: 8
Training loss: 2.2823352813720703
Validation loss: 1.8384552868150121
Epoch: 9| Step: 9
Training loss: 2.223602294921875
Validation loss: 1.8852916136920024
Epoch: 9| Step: 10
Training loss: 2.474198341369629
Validation loss: 1.8416513376098742
Epoch: 9| Step: 11
Training loss: 1.5169756412506104
Validation loss: 1.8663845508218668
Epoch: 9| Step: 12
Training loss: 2.0028746128082275
Validation loss: 1.8833802569684366
Epoch: 9| Step: 13
Training loss: 2.442668914794922
Validation loss: 1.870776641283104
Epoch: 9| Step: 14
Training loss: 1.818730115890503
Validation loss: 1.8576201037537279
Epoch: 9| Step: 15
Training loss: 2.5746192932128906
Validation loss: 1.837183393162789
Epoch: 9| Step: 16
Training loss: 2.933398485183716
Validation loss: 1.8501383795155038
Epoch: 9| Step: 17
Training loss: 2.1177165508270264
Validation loss: 1.83746690458531
Epoch: 9| Step: 18
Training loss: 2.2985243797302246
Validation loss: 1.863732572939756
Epoch: 9| Step: 19
Training loss: 2.3319921493530273
Validation loss: 1.8578722339739902
Epoch: 46| Step: 0
Training loss: 2.2871978282928467
Validation loss: 1.8266080429228089
Epoch: 9| Step: 1
Training loss: 2.246999740600586
Validation loss: 1.8461886910225849
Epoch: 9| Step: 2
Training loss: 1.8224155902862549
Validation loss: 1.831599065725752
Epoch: 9| Step: 3
Training loss: 2.1790242195129395
Validation loss: 1.7839422886320155
Epoch: 9| Step: 4
Training loss: 1.7660534381866455
Validation loss: 1.8280698326851825
Epoch: 9| Step: 5
Training loss: 2.924132823944092
Validation loss: 1.8210467082991018
Epoch: 9| Step: 6
Training loss: 2.3568849563598633
Validation loss: 1.8298410940513337
Epoch: 9| Step: 7
Training loss: 1.266174077987671
Validation loss: 1.8437821384814146
Epoch: 9| Step: 8
Training loss: 2.1191656589508057
Validation loss: 1.8876407060691778
Epoch: 9| Step: 9
Training loss: 2.2488694190979004
Validation loss: 1.842953477832053
Epoch: 9| Step: 10
Training loss: 1.7560222148895264
Validation loss: 1.8381305804355539
Epoch: 9| Step: 11
Training loss: 2.1619820594787598
Validation loss: 1.8846107386856628
Epoch: 9| Step: 12
Training loss: 1.7990080118179321
Validation loss: 1.8369102761042204
Epoch: 9| Step: 13
Training loss: 2.3211910724639893
Validation loss: 1.8130120081867245
Epoch: 9| Step: 14
Training loss: 2.6365251541137695
Validation loss: 1.8113815269881872
Epoch: 9| Step: 15
Training loss: 1.9185853004455566
Validation loss: 1.8755605280828134
Epoch: 9| Step: 16
Training loss: 2.511899471282959
Validation loss: 1.850515191503566
Epoch: 9| Step: 17
Training loss: 2.1365976333618164
Validation loss: 1.8616149022424822
Epoch: 9| Step: 18
Training loss: 2.29229736328125
Validation loss: 1.8698588326680574
Epoch: 9| Step: 19
Training loss: 1.75132417678833
Validation loss: 1.8813990020065856
Epoch: 47| Step: 0
Training loss: 1.729887843132019
Validation loss: 1.8647972662671863
Epoch: 9| Step: 1
Training loss: 2.0124704837799072
Validation loss: 1.84678434725288
Epoch: 9| Step: 2
Training loss: 2.1183958053588867
Validation loss: 1.8783615150040003
Epoch: 9| Step: 3
Training loss: 2.543717622756958
Validation loss: 1.8574919666317726
Epoch: 9| Step: 4
Training loss: 1.3112633228302002
Validation loss: 1.853938632731815
Epoch: 9| Step: 5
Training loss: 2.700723886489868
Validation loss: 1.8386601123878423
Epoch: 9| Step: 6
Training loss: 2.0816941261291504
Validation loss: 1.820527057853534
Epoch: 9| Step: 7
Training loss: 2.3748579025268555
Validation loss: 1.8518711920264814
Epoch: 9| Step: 8
Training loss: 1.875125527381897
Validation loss: 1.828268329874217
Epoch: 9| Step: 9
Training loss: 2.375152826309204
Validation loss: 1.9044475538267507
Epoch: 9| Step: 10
Training loss: 2.078230142593384
Validation loss: 1.8735640254809702
Epoch: 9| Step: 11
Training loss: 1.8910850286483765
Validation loss: 1.8661508148522685
Epoch: 9| Step: 12
Training loss: 2.383145570755005
Validation loss: 1.8604498141103512
Epoch: 9| Step: 13
Training loss: 1.8622581958770752
Validation loss: 1.8660454381284097
Epoch: 9| Step: 14
Training loss: 2.313622236251831
Validation loss: 1.8752262780992248
Epoch: 9| Step: 15
Training loss: 1.6829843521118164
Validation loss: 1.78660846013817
Epoch: 9| Step: 16
Training loss: 2.6034669876098633
Validation loss: 1.8508958919442815
Epoch: 9| Step: 17
Training loss: 1.388671875
Validation loss: 1.8623291682853973
Epoch: 9| Step: 18
Training loss: 2.2190489768981934
Validation loss: 1.8346283058468387
Epoch: 9| Step: 19
Training loss: 2.935882091522217
Validation loss: 1.8809087216425284
Epoch: 48| Step: 0
Training loss: 1.5079514980316162
Validation loss: 1.8181128870669028
Epoch: 9| Step: 1
Training loss: 2.0627574920654297
Validation loss: 1.879463399914529
Epoch: 9| Step: 2
Training loss: 2.9113059043884277
Validation loss: 1.849210703115669
Epoch: 9| Step: 3
Training loss: 2.376506805419922
Validation loss: 1.8233646231589558
Epoch: 9| Step: 4
Training loss: 2.313432216644287
Validation loss: 1.8095606994285858
Epoch: 9| Step: 5
Training loss: 1.7697111368179321
Validation loss: 1.8829178381309235
Epoch: 9| Step: 6
Training loss: 1.8973383903503418
Validation loss: 1.841218663634156
Epoch: 9| Step: 7
Training loss: 1.4219894409179688
Validation loss: 1.8731392227488457
Epoch: 9| Step: 8
Training loss: 2.188295364379883
Validation loss: 1.888505382503537
Epoch: 9| Step: 9
Training loss: 2.115765333175659
Validation loss: 1.9180753093829257
Epoch: 9| Step: 10
Training loss: 2.5875208377838135
Validation loss: 1.887078387274159
Epoch: 9| Step: 11
Training loss: 1.9229737520217896
Validation loss: 1.9016991647885
Epoch: 9| Step: 12
Training loss: 2.3438806533813477
Validation loss: 1.8215759572365302
Epoch: 9| Step: 13
Training loss: 3.2806577682495117
Validation loss: 1.8790406691942283
Epoch: 9| Step: 14
Training loss: 1.4604203701019287
Validation loss: 1.9024993875901477
Epoch: 9| Step: 15
Training loss: 2.517078161239624
Validation loss: 1.8823113913158718
Epoch: 9| Step: 16
Training loss: 2.645204544067383
Validation loss: 1.8130572751271639
Epoch: 9| Step: 17
Training loss: 1.2122926712036133
Validation loss: 1.8550007823559878
Epoch: 9| Step: 18
Training loss: 1.8342015743255615
Validation loss: 1.8360993038836142
Epoch: 9| Step: 19
Training loss: 2.0971457958221436
Validation loss: 1.848068433699848
Epoch: 49| Step: 0
Training loss: 2.2869625091552734
Validation loss: 1.8253754694684803
Epoch: 9| Step: 1
Training loss: 2.1288552284240723
Validation loss: 1.8131776833705764
Epoch: 9| Step: 2
Training loss: 1.7571978569030762
Validation loss: 1.8602962734030306
Epoch: 9| Step: 3
Training loss: 1.873811960220337
Validation loss: 1.8741556088701428
Epoch: 9| Step: 4
Training loss: 2.4176435470581055
Validation loss: 1.8031697727793412
Epoch: 9| Step: 5
Training loss: 2.439723491668701
Validation loss: 1.8583735579209362
Epoch: 9| Step: 6
Training loss: 2.7567458152770996
Validation loss: 1.8375647170938176
Epoch: 9| Step: 7
Training loss: 1.5501983165740967
Validation loss: 1.8482867136276027
Epoch: 9| Step: 8
Training loss: 2.2534801959991455
Validation loss: 1.822580118831113
Epoch: 9| Step: 9
Training loss: 1.7439658641815186
Validation loss: 1.8223550105266433
Epoch: 9| Step: 10
Training loss: 3.015355110168457
Validation loss: 1.8384810651806618
Epoch: 9| Step: 11
Training loss: 2.5343213081359863
Validation loss: 1.8410770215576502
Epoch: 9| Step: 12
Training loss: 1.9255073070526123
Validation loss: 1.810713047603909
Epoch: 9| Step: 13
Training loss: 1.887639045715332
Validation loss: 1.842959995750043
Epoch: 9| Step: 14
Training loss: 1.886523723602295
Validation loss: 1.8328286066329738
Epoch: 9| Step: 15
Training loss: 2.106257200241089
Validation loss: 1.8283997945648303
Epoch: 9| Step: 16
Training loss: 2.1662774085998535
Validation loss: 1.8500110005303252
Epoch: 9| Step: 17
Training loss: 1.7071576118469238
Validation loss: 1.8424432217645987
Epoch: 9| Step: 18
Training loss: 1.8433938026428223
Validation loss: 1.8635357515417414
Epoch: 9| Step: 19
Training loss: 1.8705787658691406
Validation loss: 1.8456313850210726
Epoch: 50| Step: 0
Training loss: 1.717320203781128
Validation loss: 1.865182880875018
Epoch: 9| Step: 1
Training loss: 2.225614309310913
Validation loss: 1.83885444497033
Epoch: 9| Step: 2
Training loss: 2.153592109680176
Validation loss: 1.837273448491268
Epoch: 9| Step: 3
Training loss: 2.398582935333252
Validation loss: 1.8597806855071364
Epoch: 9| Step: 4
Training loss: 2.005551338195801
Validation loss: 1.8454847584525458
Epoch: 9| Step: 5
Training loss: 2.4731435775756836
Validation loss: 1.8637263620500084
Epoch: 9| Step: 6
Training loss: 2.592710018157959
Validation loss: 1.7930921723516724
Epoch: 9| Step: 7
Training loss: 2.3211708068847656
Validation loss: 1.820098075935309
Epoch: 9| Step: 8
Training loss: 1.7059369087219238
Validation loss: 1.9235857442128572
Epoch: 9| Step: 9
Training loss: 2.2768712043762207
Validation loss: 1.9074591389662927
Epoch: 9| Step: 10
Training loss: 2.2786946296691895
Validation loss: 1.9146340708080813
Epoch: 9| Step: 11
Training loss: 2.1740565299987793
Validation loss: 1.8252193387463795
Epoch: 9| Step: 12
Training loss: 2.9265763759613037
Validation loss: 1.9028243829878113
Epoch: 9| Step: 13
Training loss: 1.264173150062561
Validation loss: 1.878199184541222
Epoch: 9| Step: 14
Training loss: 1.298717737197876
Validation loss: 1.9823129846037721
Epoch: 9| Step: 15
Training loss: 2.462092399597168
Validation loss: 1.8565540219382417
Epoch: 9| Step: 16
Training loss: 1.8529515266418457
Validation loss: 1.9131241530823193
Epoch: 9| Step: 17
Training loss: 2.601942539215088
Validation loss: 1.9341393031662317
Epoch: 9| Step: 18
Training loss: 1.793660283088684
Validation loss: 1.8797894621924531
Epoch: 9| Step: 19
Training loss: 1.7266967296600342
Validation loss: 1.9293527105729358
Epoch: 51| Step: 0
Training loss: 2.9807167053222656
Validation loss: 1.8940108251228607
Epoch: 9| Step: 1
Training loss: 1.9659802913665771
Validation loss: 1.8381221105726502
Epoch: 9| Step: 2
Training loss: 2.3001317977905273
Validation loss: 1.8717920977434666
Epoch: 9| Step: 3
Training loss: 1.946850061416626
Validation loss: 1.9521551938365689
Epoch: 9| Step: 4
Training loss: 1.4696362018585205
Validation loss: 1.9317403148404129
Epoch: 9| Step: 5
Training loss: 2.2961175441741943
Validation loss: 1.8594916870268128
Epoch: 9| Step: 6
Training loss: 2.4166171550750732
Validation loss: 1.8674843843034703
Epoch: 9| Step: 7
Training loss: 2.2526469230651855
Validation loss: 1.8722691574542643
Epoch: 9| Step: 8
Training loss: 1.7779390811920166
Validation loss: 1.8653350716872181
Epoch: 9| Step: 9
Training loss: 2.2686240673065186
Validation loss: 1.9341383314818787
Epoch: 9| Step: 10
Training loss: 2.743490695953369
Validation loss: 1.8719143241429501
Epoch: 9| Step: 11
Training loss: 1.458465337753296
Validation loss: 1.8594471619283552
Epoch: 9| Step: 12
Training loss: 1.4603151082992554
Validation loss: 1.863270061479198
Epoch: 9| Step: 13
Training loss: 2.3452253341674805
Validation loss: 1.8765609881860748
Epoch: 9| Step: 14
Training loss: 1.5483835935592651
Validation loss: 1.8165707862634453
Epoch: 9| Step: 15
Training loss: 2.615812063217163
Validation loss: 1.8451189879033205
Epoch: 9| Step: 16
Training loss: 1.2914209365844727
Validation loss: 1.8505382820856657
Epoch: 9| Step: 17
Training loss: 1.7534115314483643
Validation loss: 1.9006690044197248
Epoch: 9| Step: 18
Training loss: 2.7309231758117676
Validation loss: 1.8553976652433546
Epoch: 9| Step: 19
Training loss: 2.261713981628418
Validation loss: 1.8229390116904278
Epoch: 52| Step: 0
Training loss: 1.5524247884750366
Validation loss: 1.8856324832216442
Epoch: 9| Step: 1
Training loss: 1.8888736963272095
Validation loss: 1.8785977680906116
Epoch: 9| Step: 2
Training loss: 1.6118921041488647
Validation loss: 1.8594804933602862
Epoch: 9| Step: 3
Training loss: 2.4645543098449707
Validation loss: 1.86432352683527
Epoch: 9| Step: 4
Training loss: 2.4941415786743164
Validation loss: 1.847278157584101
Epoch: 9| Step: 5
Training loss: 1.7911776304244995
Validation loss: 1.8651813714624308
Epoch: 9| Step: 6
Training loss: 2.4548113346099854
Validation loss: 1.8722899217399762
Epoch: 9| Step: 7
Training loss: 2.6438636779785156
Validation loss: 1.788727065642103
Epoch: 9| Step: 8
Training loss: 2.147810935974121
Validation loss: 1.8801757774764685
Epoch: 9| Step: 9
Training loss: 2.244950771331787
Validation loss: 1.8551378070021705
Epoch: 9| Step: 10
Training loss: 1.7722501754760742
Validation loss: 1.831602902721158
Epoch: 9| Step: 11
Training loss: 2.205650568008423
Validation loss: 1.8542062944645503
Epoch: 9| Step: 12
Training loss: 1.552191972732544
Validation loss: 1.8610350065094103
Epoch: 9| Step: 13
Training loss: 2.5026192665100098
Validation loss: 1.8200008929204599
Epoch: 9| Step: 14
Training loss: 2.0458974838256836
Validation loss: 1.8503340036748983
Epoch: 9| Step: 15
Training loss: 2.2499990463256836
Validation loss: 1.8484111578344442
Epoch: 9| Step: 16
Training loss: 1.9821752309799194
Validation loss: 1.861420612541034
Epoch: 9| Step: 17
Training loss: 2.3843870162963867
Validation loss: 1.8357446708267542
Epoch: 9| Step: 18
Training loss: 2.546739101409912
Validation loss: 1.849330389242378
Epoch: 9| Step: 19
Training loss: 1.7784810066223145
Validation loss: 1.8325763829320454
Epoch: 53| Step: 0
Training loss: 2.595040798187256
Validation loss: 1.8374458414187533
Epoch: 9| Step: 1
Training loss: 2.241434097290039
Validation loss: 1.8182744542471796
Epoch: 9| Step: 2
Training loss: 1.7744083404541016
Validation loss: 1.8661724080284723
Epoch: 9| Step: 3
Training loss: 1.9548836946487427
Validation loss: 1.8587766928638485
Epoch: 9| Step: 4
Training loss: 2.528179168701172
Validation loss: 1.8527154124898018
Epoch: 9| Step: 5
Training loss: 1.93092942237854
Validation loss: 1.8294576895322732
Epoch: 9| Step: 6
Training loss: 2.754420757293701
Validation loss: 1.830555071933664
Epoch: 9| Step: 7
Training loss: 1.5329811573028564
Validation loss: 1.8207919108781883
Epoch: 9| Step: 8
Training loss: 1.8509882688522339
Validation loss: 1.8617780706007703
Epoch: 9| Step: 9
Training loss: 2.0145962238311768
Validation loss: 1.8488798861880955
Epoch: 9| Step: 10
Training loss: 2.8800930976867676
Validation loss: 1.8982055272987421
Epoch: 9| Step: 11
Training loss: 1.8809289932250977
Validation loss: 1.8471383002164552
Epoch: 9| Step: 12
Training loss: 2.106509208679199
Validation loss: 1.8719733944899744
Epoch: 9| Step: 13
Training loss: 1.9115055799484253
Validation loss: 1.8334004793235723
Epoch: 9| Step: 14
Training loss: 1.5957967042922974
Validation loss: 1.8757848002070145
Epoch: 9| Step: 15
Training loss: 1.7742156982421875
Validation loss: 1.872827419274145
Epoch: 9| Step: 16
Training loss: 2.270582675933838
Validation loss: 1.8743187480693242
Epoch: 9| Step: 17
Training loss: 2.3048763275146484
Validation loss: 1.8525555751306548
Epoch: 9| Step: 18
Training loss: 1.8820668458938599
Validation loss: 1.866192728066616
Epoch: 9| Step: 19
Training loss: 1.6519678831100464
Validation loss: 1.876793303078027
Epoch: 54| Step: 0
Training loss: 1.642911672592163
Validation loss: 1.9042251504582466
Epoch: 9| Step: 1
Training loss: 2.267298698425293
Validation loss: 1.8270297890944447
Epoch: 9| Step: 2
Training loss: 2.5828099250793457
Validation loss: 1.9259674257511714
Epoch: 9| Step: 3
Training loss: 1.7635096311569214
Validation loss: 1.9090436491177236
Epoch: 9| Step: 4
Training loss: 2.145153045654297
Validation loss: 1.9120802913638328
Epoch: 9| Step: 5
Training loss: 1.7014182806015015
Validation loss: 1.8584600181030713
Epoch: 9| Step: 6
Training loss: 1.9968092441558838
Validation loss: 1.9002090889772922
Epoch: 9| Step: 7
Training loss: 2.27079439163208
Validation loss: 1.8856028721486922
Epoch: 9| Step: 8
Training loss: 2.7140321731567383
Validation loss: 1.8725345100430275
Epoch: 9| Step: 9
Training loss: 1.9342929124832153
Validation loss: 1.925170660018921
Epoch: 9| Step: 10
Training loss: 1.9393551349639893
Validation loss: 1.88302098161025
Epoch: 9| Step: 11
Training loss: 2.287259578704834
Validation loss: 1.9031943794634703
Epoch: 9| Step: 12
Training loss: 1.380312204360962
Validation loss: 1.9010064018716057
Epoch: 9| Step: 13
Training loss: 1.951265811920166
Validation loss: 1.9066901284156086
Epoch: 9| Step: 14
Training loss: 1.857657790184021
Validation loss: 1.905465246104508
Epoch: 9| Step: 15
Training loss: 3.0757901668548584
Validation loss: 1.8983606434554505
Epoch: 9| Step: 16
Training loss: 2.163682699203491
Validation loss: 1.8660560417518341
Epoch: 9| Step: 17
Training loss: 1.697913408279419
Validation loss: 1.8855557107239318
Epoch: 9| Step: 18
Training loss: 1.5216090679168701
Validation loss: 1.930346139900976
Epoch: 9| Step: 19
Training loss: 2.5116870403289795
Validation loss: 1.8957559359159402
Epoch: 55| Step: 0
Training loss: 2.807246685028076
Validation loss: 1.97068679161209
Epoch: 9| Step: 1
Training loss: 1.9032318592071533
Validation loss: 1.912024477402941
Epoch: 9| Step: 2
Training loss: 1.79656982421875
Validation loss: 1.8787234202563334
Epoch: 9| Step: 3
Training loss: 2.351654052734375
Validation loss: 1.9381076826466073
Epoch: 9| Step: 4
Training loss: 2.322943687438965
Validation loss: 1.8818705039058659
Epoch: 9| Step: 5
Training loss: 1.7251273393630981
Validation loss: 1.9055778671511643
Epoch: 9| Step: 6
Training loss: 2.232485771179199
Validation loss: 1.9009903780848003
Epoch: 9| Step: 7
Training loss: 2.062310218811035
Validation loss: 1.8275516016020192
Epoch: 9| Step: 8
Training loss: 2.6427712440490723
Validation loss: 1.8726162069993053
Epoch: 9| Step: 9
Training loss: 2.060063600540161
Validation loss: 1.8969544352387353
Epoch: 9| Step: 10
Training loss: 2.8196523189544678
Validation loss: 1.8911480509119927
Epoch: 9| Step: 11
Training loss: 2.8450000286102295
Validation loss: 1.898244189701492
Epoch: 9| Step: 12
Training loss: 1.6047768592834473
Validation loss: 1.9283447214167753
Epoch: 9| Step: 13
Training loss: 1.8720674514770508
Validation loss: 1.8605741485417318
Epoch: 9| Step: 14
Training loss: 1.5786296129226685
Validation loss: 1.908423860296071
Epoch: 9| Step: 15
Training loss: 1.6338756084442139
Validation loss: 1.904134515378115
Epoch: 9| Step: 16
Training loss: 2.53855562210083
Validation loss: 1.9160496914129463
Epoch: 9| Step: 17
Training loss: 2.537130117416382
Validation loss: 1.8609260826659717
Epoch: 9| Step: 18
Training loss: 1.817845344543457
Validation loss: 1.8886572019659358
Epoch: 9| Step: 19
Training loss: 1.1556485891342163
Validation loss: 1.886605585221764
Epoch: 56| Step: 0
Training loss: 1.9745259284973145
Validation loss: 1.8910508721852475
Epoch: 9| Step: 1
Training loss: 1.6504346132278442
Validation loss: 1.8885196370186565
Epoch: 9| Step: 2
Training loss: 2.483267307281494
Validation loss: 1.8600385772238532
Epoch: 9| Step: 3
Training loss: 1.6839210987091064
Validation loss: 1.893260279147745
Epoch: 9| Step: 4
Training loss: 2.54844331741333
Validation loss: 1.9128780639428886
Epoch: 9| Step: 5
Training loss: 1.3424904346466064
Validation loss: 1.9160292200047335
Epoch: 9| Step: 6
Training loss: 1.9098706245422363
Validation loss: 1.8788286404643986
Epoch: 9| Step: 7
Training loss: 1.5423154830932617
Validation loss: 1.8796107108644444
Epoch: 9| Step: 8
Training loss: 2.103698492050171
Validation loss: 1.8872130380260002
Epoch: 9| Step: 9
Training loss: 2.6040234565734863
Validation loss: 1.8990199591616075
Epoch: 9| Step: 10
Training loss: 2.0021069049835205
Validation loss: 1.8793331307472942
Epoch: 9| Step: 11
Training loss: 2.527573585510254
Validation loss: 1.8521237836467277
Epoch: 9| Step: 12
Training loss: 1.7381542921066284
Validation loss: 1.8812121058539522
Epoch: 9| Step: 13
Training loss: 2.04947566986084
Validation loss: 1.906529661562803
Epoch: 9| Step: 14
Training loss: 2.7702980041503906
Validation loss: 1.9402884433595398
Epoch: 9| Step: 15
Training loss: 1.7884910106658936
Validation loss: 1.8968089175738876
Epoch: 9| Step: 16
Training loss: 1.8436801433563232
Validation loss: 1.8988171807295984
Epoch: 9| Step: 17
Training loss: 2.3834586143493652
Validation loss: 1.892946137798776
Epoch: 9| Step: 18
Training loss: 2.323833465576172
Validation loss: 1.9133977401170799
Epoch: 9| Step: 19
Training loss: 2.5986456871032715
Validation loss: 1.9036265543038897
Epoch: 57| Step: 0
Training loss: 1.9710273742675781
Validation loss: 1.9287801406366363
Epoch: 9| Step: 1
Training loss: 2.5804147720336914
Validation loss: 1.889417323277151
Epoch: 9| Step: 2
Training loss: 1.681764006614685
Validation loss: 1.8684464392902183
Epoch: 9| Step: 3
Training loss: 2.23447322845459
Validation loss: 1.901962860882711
Epoch: 9| Step: 4
Training loss: 1.7810084819793701
Validation loss: 1.874729632473678
Epoch: 9| Step: 5
Training loss: 1.7055250406265259
Validation loss: 1.8412688516026778
Epoch: 9| Step: 6
Training loss: 2.4939279556274414
Validation loss: 1.904849416918034
Epoch: 9| Step: 7
Training loss: 2.50056791305542
Validation loss: 1.8331757054912101
Epoch: 9| Step: 8
Training loss: 1.8528932332992554
Validation loss: 1.9229150487364626
Epoch: 9| Step: 9
Training loss: 1.6141042709350586
Validation loss: 1.862986676126933
Epoch: 9| Step: 10
Training loss: 2.2987875938415527
Validation loss: 1.883289690497968
Epoch: 9| Step: 11
Training loss: 2.013505458831787
Validation loss: 1.848056228898412
Epoch: 9| Step: 12
Training loss: 2.1844422817230225
Validation loss: 1.8855094978277631
Epoch: 9| Step: 13
Training loss: 2.4423274993896484
Validation loss: 1.8445924889269492
Epoch: 9| Step: 14
Training loss: 2.495109796524048
Validation loss: 1.8845732074847323
Epoch: 9| Step: 15
Training loss: 1.858709692955017
Validation loss: 1.9432682167711874
Epoch: 9| Step: 16
Training loss: 1.6099886894226074
Validation loss: 1.871727879098851
Epoch: 9| Step: 17
Training loss: 2.758988857269287
Validation loss: 1.8777891680491057
Epoch: 9| Step: 18
Training loss: 2.040963649749756
Validation loss: 1.8839151353287182
Epoch: 9| Step: 19
Training loss: 1.8128554821014404
Validation loss: 1.8399584782209328
Epoch: 58| Step: 0
Training loss: 2.3475241661071777
Validation loss: 1.8409136370789232
Epoch: 9| Step: 1
Training loss: 2.372971296310425
Validation loss: 1.8333116735485817
Epoch: 9| Step: 2
Training loss: 2.1968915462493896
Validation loss: 1.9059567074123904
Epoch: 9| Step: 3
Training loss: 2.108319044113159
Validation loss: 1.8890058891378718
Epoch: 9| Step: 4
Training loss: 2.273319959640503
Validation loss: 1.8668439268208237
Epoch: 9| Step: 5
Training loss: 1.8487492799758911
Validation loss: 1.829710998981119
Epoch: 9| Step: 6
Training loss: 2.420896053314209
Validation loss: 1.874245516687846
Epoch: 9| Step: 7
Training loss: 2.389472246170044
Validation loss: 1.87772986785971
Epoch: 9| Step: 8
Training loss: 1.8247835636138916
Validation loss: 1.809178121655965
Epoch: 9| Step: 9
Training loss: 1.6583675146102905
Validation loss: 1.8596388144458798
Epoch: 9| Step: 10
Training loss: 1.4591021537780762
Validation loss: 1.8903808662359662
Epoch: 9| Step: 11
Training loss: 2.5319876670837402
Validation loss: 1.8679451041942021
Epoch: 9| Step: 12
Training loss: 2.22434401512146
Validation loss: 1.8646873398650465
Epoch: 9| Step: 13
Training loss: 1.7246372699737549
Validation loss: 1.8554062363055113
Epoch: 9| Step: 14
Training loss: 1.7626278400421143
Validation loss: 1.8717024506424829
Epoch: 9| Step: 15
Training loss: 2.758551836013794
Validation loss: 1.8575104629393104
Epoch: 9| Step: 16
Training loss: 1.8116170167922974
Validation loss: 1.8493850925843494
Epoch: 9| Step: 17
Training loss: 1.9034111499786377
Validation loss: 1.8826581548443801
Epoch: 9| Step: 18
Training loss: 1.9376485347747803
Validation loss: 1.8156943338380442
Epoch: 9| Step: 19
Training loss: 2.2834489345550537
Validation loss: 1.789989548621418
Epoch: 59| Step: 0
Training loss: 2.254619598388672
Validation loss: 1.8326060343131745
Epoch: 9| Step: 1
Training loss: 1.6685476303100586
Validation loss: 1.8441584641984898
Epoch: 9| Step: 2
Training loss: 1.9259073734283447
Validation loss: 1.8524953873037435
Epoch: 9| Step: 3
Training loss: 2.062331199645996
Validation loss: 1.9150195885047638
Epoch: 9| Step: 4
Training loss: 1.4461369514465332
Validation loss: 1.8254286428149655
Epoch: 9| Step: 5
Training loss: 1.8148763179779053
Validation loss: 1.8512071190978125
Epoch: 9| Step: 6
Training loss: 2.214423656463623
Validation loss: 1.806140819041849
Epoch: 9| Step: 7
Training loss: 2.7130680084228516
Validation loss: 1.817826817361571
Epoch: 9| Step: 8
Training loss: 1.9383479356765747
Validation loss: 1.827336692123962
Epoch: 9| Step: 9
Training loss: 1.715169072151184
Validation loss: 1.8903295376317963
Epoch: 9| Step: 10
Training loss: 3.6866164207458496
Validation loss: 1.8884974709517663
Epoch: 9| Step: 11
Training loss: 2.219029188156128
Validation loss: 1.811987612744887
Epoch: 9| Step: 12
Training loss: 1.879492998123169
Validation loss: 1.874834418296814
Epoch: 9| Step: 13
Training loss: 1.8864505290985107
Validation loss: 1.86088234743626
Epoch: 9| Step: 14
Training loss: 2.559194564819336
Validation loss: 1.8838474647604304
Epoch: 9| Step: 15
Training loss: 1.5071736574172974
Validation loss: 1.8353562355041504
Epoch: 9| Step: 16
Training loss: 1.7360490560531616
Validation loss: 1.855046211386756
Epoch: 9| Step: 17
Training loss: 2.3733415603637695
Validation loss: 1.922812026181667
Epoch: 9| Step: 18
Training loss: 2.281160354614258
Validation loss: 1.8093254077348777
Epoch: 9| Step: 19
Training loss: 1.5662174224853516
Validation loss: 1.8479276269459897
Epoch: 60| Step: 0
Training loss: 1.5469622611999512
Validation loss: 1.8731846620710633
Epoch: 9| Step: 1
Training loss: 2.9234118461608887
Validation loss: 1.8445431757316315
Epoch: 9| Step: 2
Training loss: 2.031057834625244
Validation loss: 1.844826940152285
Epoch: 9| Step: 3
Training loss: 2.236677408218384
Validation loss: 1.8735276709357611
Epoch: 9| Step: 4
Training loss: 2.512934684753418
Validation loss: 1.8590871232876676
Epoch: 9| Step: 5
Training loss: 1.7100915908813477
Validation loss: 1.8399106435638537
Epoch: 9| Step: 6
Training loss: 1.6645587682724
Validation loss: 1.8530731364119826
Epoch: 9| Step: 7
Training loss: 2.21303653717041
Validation loss: 1.8643560023616543
Epoch: 9| Step: 8
Training loss: 2.4634103775024414
Validation loss: 1.909204765189466
Epoch: 9| Step: 9
Training loss: 1.9099740982055664
Validation loss: 1.8829293371104507
Epoch: 9| Step: 10
Training loss: 2.1281509399414062
Validation loss: 1.856748293629653
Epoch: 9| Step: 11
Training loss: 2.2965235710144043
Validation loss: 1.9478831454146681
Epoch: 9| Step: 12
Training loss: 1.7776702642440796
Validation loss: 1.9048171094853243
Epoch: 9| Step: 13
Training loss: 1.5967966318130493
Validation loss: 1.8703114540456869
Epoch: 9| Step: 14
Training loss: 2.014754295349121
Validation loss: 1.8527115077423535
Epoch: 9| Step: 15
Training loss: 2.045438766479492
Validation loss: 1.8434228622656075
Epoch: 9| Step: 16
Training loss: 2.2889299392700195
Validation loss: 1.895356665412299
Epoch: 9| Step: 17
Training loss: 2.156172752380371
Validation loss: 1.8491921587813673
Epoch: 9| Step: 18
Training loss: 2.301211357116699
Validation loss: 1.8228100675473111
Epoch: 9| Step: 19
Training loss: 1.8589091300964355
Validation loss: 1.8487338153578394
Epoch: 61| Step: 0
Training loss: 2.288001298904419
Validation loss: 1.8289250778637345
Epoch: 9| Step: 1
Training loss: 2.056898593902588
Validation loss: 1.8922107374067787
Epoch: 9| Step: 2
Training loss: 2.672667980194092
Validation loss: 1.8904392582049472
Epoch: 9| Step: 3
Training loss: 2.1899335384368896
Validation loss: 1.9261574007624345
Epoch: 9| Step: 4
Training loss: 2.2950334548950195
Validation loss: 1.8673978212068407
Epoch: 9| Step: 5
Training loss: 2.167891025543213
Validation loss: 1.8446542719285266
Epoch: 9| Step: 6
Training loss: 2.1596286296844482
Validation loss: 1.8406922902992304
Epoch: 9| Step: 7
Training loss: 1.8981653451919556
Validation loss: 1.8387999654673843
Epoch: 9| Step: 8
Training loss: 1.7615083456039429
Validation loss: 1.8817060405401875
Epoch: 9| Step: 9
Training loss: 1.992075800895691
Validation loss: 1.9049659401392764
Epoch: 9| Step: 10
Training loss: 1.3798081874847412
Validation loss: 1.8671514970793142
Epoch: 9| Step: 11
Training loss: 2.263162851333618
Validation loss: 1.8778612828083177
Epoch: 9| Step: 12
Training loss: 1.3106964826583862
Validation loss: 1.8799081105980084
Epoch: 9| Step: 13
Training loss: 1.2327520847320557
Validation loss: 1.8711567439621302
Epoch: 9| Step: 14
Training loss: 1.5648736953735352
Validation loss: 1.837214761500736
Epoch: 9| Step: 15
Training loss: 3.1754531860351562
Validation loss: 1.890522165264157
Epoch: 9| Step: 16
Training loss: 2.638906955718994
Validation loss: 1.9000411822641496
Epoch: 9| Step: 17
Training loss: 2.3218140602111816
Validation loss: 1.8861526293720272
Epoch: 9| Step: 18
Training loss: 2.0096094608306885
Validation loss: 1.8760561102585827
Epoch: 9| Step: 19
Training loss: 2.2610180377960205
Validation loss: 1.8854681639362583
Epoch: 62| Step: 0
Training loss: 2.104879856109619
Validation loss: 1.8824064560073743
Epoch: 9| Step: 1
Training loss: 1.9775089025497437
Validation loss: 1.9170001642309504
Epoch: 9| Step: 2
Training loss: 1.4718031883239746
Validation loss: 1.8671791982307708
Epoch: 9| Step: 3
Training loss: 2.0103797912597656
Validation loss: 1.9206439591140199
Epoch: 9| Step: 4
Training loss: 1.7841949462890625
Validation loss: 1.9134451356723154
Epoch: 9| Step: 5
Training loss: 2.1782917976379395
Validation loss: 1.9191254162959914
Epoch: 9| Step: 6
Training loss: 1.972856879234314
Validation loss: 1.974870808690572
Epoch: 9| Step: 7
Training loss: 2.151346445083618
Validation loss: 1.9356884424634975
Epoch: 9| Step: 8
Training loss: 1.9318068027496338
Validation loss: 1.906959409336392
Epoch: 9| Step: 9
Training loss: 2.083946943283081
Validation loss: 1.9138721270526913
Epoch: 9| Step: 10
Training loss: 2.321381092071533
Validation loss: 1.8929341851378516
Epoch: 9| Step: 11
Training loss: 2.383371353149414
Validation loss: 1.881288045601879
Epoch: 9| Step: 12
Training loss: 1.9951521158218384
Validation loss: 1.8705986712476332
Epoch: 9| Step: 13
Training loss: 2.162393808364868
Validation loss: 1.8912720268578838
Epoch: 9| Step: 14
Training loss: 2.4387309551239014
Validation loss: 1.8654440547064912
Epoch: 9| Step: 15
Training loss: 2.3782637119293213
Validation loss: 1.8790826471589452
Epoch: 9| Step: 16
Training loss: 2.4507999420166016
Validation loss: 1.8798994949395709
Epoch: 9| Step: 17
Training loss: 1.7855021953582764
Validation loss: 1.855788073093771
Epoch: 9| Step: 18
Training loss: 1.9256007671356201
Validation loss: 1.8029834289344953
Epoch: 9| Step: 19
Training loss: 1.6093454360961914
Validation loss: 1.8970278441477164
Epoch: 63| Step: 0
Training loss: 2.3947982788085938
Validation loss: 1.8778186916447372
Epoch: 9| Step: 1
Training loss: 2.5153465270996094
Validation loss: 1.8508828046510546
Epoch: 9| Step: 2
Training loss: 1.9370448589324951
Validation loss: 1.8210869890322787
Epoch: 9| Step: 3
Training loss: 2.1238625049591064
Validation loss: 1.844365649943729
Epoch: 9| Step: 4
Training loss: 2.1608664989471436
Validation loss: 1.8266233420200486
Epoch: 9| Step: 5
Training loss: 1.7621099948883057
Validation loss: 1.781796798431616
Epoch: 9| Step: 6
Training loss: 2.204965591430664
Validation loss: 1.8205493654278542
Epoch: 9| Step: 7
Training loss: 2.319413661956787
Validation loss: 1.7931798482112746
Epoch: 9| Step: 8
Training loss: 2.54599666595459
Validation loss: 1.816243190559552
Epoch: 9| Step: 9
Training loss: 2.3571362495422363
Validation loss: 1.8579302674574818
Epoch: 9| Step: 10
Training loss: 2.297663450241089
Validation loss: 1.8244343258494096
Epoch: 9| Step: 11
Training loss: 1.7128278017044067
Validation loss: 1.781098193401913
Epoch: 9| Step: 12
Training loss: 2.003473997116089
Validation loss: 1.8209512988440424
Epoch: 9| Step: 13
Training loss: 1.826019048690796
Validation loss: 1.7784779449161008
Epoch: 9| Step: 14
Training loss: 1.7696235179901123
Validation loss: 1.8297785632044292
Epoch: 9| Step: 15
Training loss: 2.0749123096466064
Validation loss: 1.8428933041558848
Epoch: 9| Step: 16
Training loss: 1.7869622707366943
Validation loss: 1.7602994604934035
Epoch: 9| Step: 17
Training loss: 2.2119555473327637
Validation loss: 1.8527248385998842
Epoch: 9| Step: 18
Training loss: 2.059022903442383
Validation loss: 1.8530376189046627
Epoch: 9| Step: 19
Training loss: 1.9724634885787964
Validation loss: 1.7800287471400749
Epoch: 64| Step: 0
Training loss: 2.821058750152588
Validation loss: 1.830529574010012
Epoch: 9| Step: 1
Training loss: 2.2977278232574463
Validation loss: 1.7651273226566453
Epoch: 9| Step: 2
Training loss: 1.8099521398544312
Validation loss: 1.8344135464524194
Epoch: 9| Step: 3
Training loss: 2.036785125732422
Validation loss: 1.8214297929256082
Epoch: 9| Step: 4
Training loss: 2.503995895385742
Validation loss: 1.8395305417424483
Epoch: 9| Step: 5
Training loss: 1.9521013498306274
Validation loss: 1.8402105792820882
Epoch: 9| Step: 6
Training loss: 2.509136438369751
Validation loss: 1.8447785617636263
Epoch: 9| Step: 7
Training loss: 1.7856485843658447
Validation loss: 1.8045111894607544
Epoch: 9| Step: 8
Training loss: 1.8756957054138184
Validation loss: 1.7993470190240324
Epoch: 9| Step: 9
Training loss: 2.3263156414031982
Validation loss: 1.8388529055410152
Epoch: 9| Step: 10
Training loss: 2.838258743286133
Validation loss: 1.8426973665360924
Epoch: 9| Step: 11
Training loss: 2.1190881729125977
Validation loss: 1.8599005191446207
Epoch: 9| Step: 12
Training loss: 2.080714225769043
Validation loss: 1.8282432230256445
Epoch: 9| Step: 13
Training loss: 1.5860321521759033
Validation loss: 1.8753839559692274
Epoch: 9| Step: 14
Training loss: 1.3059673309326172
Validation loss: 1.8941085081306293
Epoch: 9| Step: 15
Training loss: 1.4814664125442505
Validation loss: 1.8742252819829708
Epoch: 9| Step: 16
Training loss: 2.5087294578552246
Validation loss: 1.961317145567146
Epoch: 9| Step: 17
Training loss: 1.8208132982254028
Validation loss: 1.9409401168068536
Epoch: 9| Step: 18
Training loss: 1.7480027675628662
Validation loss: 1.870734991787149
Epoch: 9| Step: 19
Training loss: 1.7318921089172363
Validation loss: 1.8855424004493
Epoch: 65| Step: 0
Training loss: 1.912151575088501
Validation loss: 1.8799861412254169
Epoch: 9| Step: 1
Training loss: 1.8401210308074951
Validation loss: 1.844805680590568
Epoch: 9| Step: 2
Training loss: 2.010500192642212
Validation loss: 1.8510485818917803
Epoch: 9| Step: 3
Training loss: 1.971971035003662
Validation loss: 1.8817686537186877
Epoch: 9| Step: 4
Training loss: 2.2918481826782227
Validation loss: 1.8934122298261244
Epoch: 9| Step: 5
Training loss: 2.4099531173706055
Validation loss: 1.812202175744146
Epoch: 9| Step: 6
Training loss: 2.4545695781707764
Validation loss: 1.903085631432293
Epoch: 9| Step: 7
Training loss: 1.845297932624817
Validation loss: 1.8521600318469589
Epoch: 9| Step: 8
Training loss: 1.6293039321899414
Validation loss: 1.9113534543154052
Epoch: 9| Step: 9
Training loss: 2.045046806335449
Validation loss: 1.88310050449783
Epoch: 9| Step: 10
Training loss: 1.5080146789550781
Validation loss: 1.832816542481347
Epoch: 9| Step: 11
Training loss: 2.513465404510498
Validation loss: 1.8519392948356463
Epoch: 9| Step: 12
Training loss: 3.181283473968506
Validation loss: 1.855938694459929
Epoch: 9| Step: 13
Training loss: 2.0200862884521484
Validation loss: 1.8547297518887966
Epoch: 9| Step: 14
Training loss: 2.101263999938965
Validation loss: 1.8749722370998465
Epoch: 9| Step: 15
Training loss: 1.7189667224884033
Validation loss: 1.8789082714121976
Epoch: 9| Step: 16
Training loss: 2.1161413192749023
Validation loss: 1.921592767290074
Epoch: 9| Step: 17
Training loss: 2.1736061573028564
Validation loss: 1.8480043822912862
Epoch: 9| Step: 18
Training loss: 1.6807687282562256
Validation loss: 1.834513213137071
Epoch: 9| Step: 19
Training loss: 2.2317569255828857
Validation loss: 1.9032335298524485
Epoch: 66| Step: 0
Training loss: 2.8345694541931152
Validation loss: 1.8544344095875034
Epoch: 9| Step: 1
Training loss: 2.5065371990203857
Validation loss: 1.8534201889586963
Epoch: 9| Step: 2
Training loss: 2.259564161300659
Validation loss: 1.8634307710386866
Epoch: 9| Step: 3
Training loss: 1.7829298973083496
Validation loss: 1.8640352410378216
Epoch: 9| Step: 4
Training loss: 2.367499351501465
Validation loss: 1.8654420650262626
Epoch: 9| Step: 5
Training loss: 1.4983375072479248
Validation loss: 1.8584367834406792
Epoch: 9| Step: 6
Training loss: 2.143618106842041
Validation loss: 1.8214087795010574
Epoch: 9| Step: 7
Training loss: 2.3728559017181396
Validation loss: 1.8656172649465876
Epoch: 9| Step: 8
Training loss: 2.0634610652923584
Validation loss: 1.891787444944862
Epoch: 9| Step: 9
Training loss: 2.4113850593566895
Validation loss: 1.7921570265035836
Epoch: 9| Step: 10
Training loss: 2.2249298095703125
Validation loss: 1.8547434137879515
Epoch: 9| Step: 11
Training loss: 2.178579330444336
Validation loss: 1.8059271256700695
Epoch: 9| Step: 12
Training loss: 1.5301858186721802
Validation loss: 1.8214891111250404
Epoch: 9| Step: 13
Training loss: 1.974161148071289
Validation loss: 1.8262535024889939
Epoch: 9| Step: 14
Training loss: 1.678386926651001
Validation loss: 1.8585491077505427
Epoch: 9| Step: 15
Training loss: 1.8226358890533447
Validation loss: 1.8592648128811404
Epoch: 9| Step: 16
Training loss: 1.489944577217102
Validation loss: 1.8748123131209997
Epoch: 9| Step: 17
Training loss: 2.3976240158081055
Validation loss: 1.8400110701005237
Epoch: 9| Step: 18
Training loss: 1.979477047920227
Validation loss: 1.8419049815308275
Epoch: 9| Step: 19
Training loss: 2.1234755516052246
Validation loss: 1.839924843191243
Epoch: 67| Step: 0
Training loss: 2.4592437744140625
Validation loss: 1.8536191552663022
Epoch: 9| Step: 1
Training loss: 1.7912909984588623
Validation loss: 1.88825136465992
Epoch: 9| Step: 2
Training loss: 1.9746379852294922
Validation loss: 1.8849085029080617
Epoch: 9| Step: 3
Training loss: 1.5818397998809814
Validation loss: 1.859165966939583
Epoch: 9| Step: 4
Training loss: 2.608428478240967
Validation loss: 1.9242006343045681
Epoch: 9| Step: 5
Training loss: 2.204540729522705
Validation loss: 1.8420864043475913
Epoch: 9| Step: 6
Training loss: 2.8177132606506348
Validation loss: 1.8776721182486993
Epoch: 9| Step: 7
Training loss: 1.7528891563415527
Validation loss: 1.8611860712655157
Epoch: 9| Step: 8
Training loss: 1.9872198104858398
Validation loss: 1.8216465359969105
Epoch: 9| Step: 9
Training loss: 1.769578456878662
Validation loss: 1.8531734094345311
Epoch: 9| Step: 10
Training loss: 2.1497693061828613
Validation loss: 1.8216619843201671
Epoch: 9| Step: 11
Training loss: 1.6069514751434326
Validation loss: 1.8528847874497338
Epoch: 9| Step: 12
Training loss: 2.669215202331543
Validation loss: 1.7999194474529019
Epoch: 9| Step: 13
Training loss: 2.253535747528076
Validation loss: 1.812152927728008
Epoch: 9| Step: 14
Training loss: 1.0795310735702515
Validation loss: 1.7758131456032074
Epoch: 9| Step: 15
Training loss: 2.300992012023926
Validation loss: 1.8385736350532915
Epoch: 9| Step: 16
Training loss: 2.315732002258301
Validation loss: 1.871513544226722
Epoch: 9| Step: 17
Training loss: 2.5008304119110107
Validation loss: 1.8689849265187763
Epoch: 9| Step: 18
Training loss: 2.2788784503936768
Validation loss: 1.8694962966356345
Epoch: 9| Step: 19
Training loss: 1.5152391195297241
Validation loss: 1.8061739129128216
Epoch: 68| Step: 0
Training loss: 2.276501178741455
Validation loss: 1.911400471659873
Epoch: 9| Step: 1
Training loss: 2.6747219562530518
Validation loss: 1.8592337918796127
Epoch: 9| Step: 2
Training loss: 2.3518571853637695
Validation loss: 1.8692862661622411
Epoch: 9| Step: 3
Training loss: 1.7015706300735474
Validation loss: 1.874442886963165
Epoch: 9| Step: 4
Training loss: 1.9907431602478027
Validation loss: 1.808812578805059
Epoch: 9| Step: 5
Training loss: 1.6281086206436157
Validation loss: 1.8567218085844739
Epoch: 9| Step: 6
Training loss: 1.6727796792984009
Validation loss: 1.8777270102672439
Epoch: 9| Step: 7
Training loss: 1.6106994152069092
Validation loss: 1.9324995356498005
Epoch: 9| Step: 8
Training loss: 2.0094802379608154
Validation loss: 1.888799105616782
Epoch: 9| Step: 9
Training loss: 2.130460739135742
Validation loss: 1.8680545511863214
Epoch: 9| Step: 10
Training loss: 2.116264820098877
Validation loss: 1.9201473803828946
Epoch: 9| Step: 11
Training loss: 2.8106026649475098
Validation loss: 1.8937860684429142
Epoch: 9| Step: 12
Training loss: 2.5688974857330322
Validation loss: 1.9241071150457258
Epoch: 9| Step: 13
Training loss: 2.4249353408813477
Validation loss: 1.8645242701331488
Epoch: 9| Step: 14
Training loss: 1.880608320236206
Validation loss: 1.8797686185768183
Epoch: 9| Step: 15
Training loss: 2.0396010875701904
Validation loss: 1.8757042730454918
Epoch: 9| Step: 16
Training loss: 2.0809316635131836
Validation loss: 1.8564148935482656
Epoch: 9| Step: 17
Training loss: 1.9845597743988037
Validation loss: 1.844973877179537
Epoch: 9| Step: 18
Training loss: 2.146399974822998
Validation loss: 1.9142631163700021
Epoch: 9| Step: 19
Training loss: 1.8751848936080933
Validation loss: 1.8440900500729787
Epoch: 69| Step: 0
Training loss: 1.627590298652649
Validation loss: 1.8780803843367873
Epoch: 9| Step: 1
Training loss: 2.7853498458862305
Validation loss: 1.8900895333118577
Epoch: 9| Step: 2
Training loss: 2.0783655643463135
Validation loss: 1.8671603048448082
Epoch: 9| Step: 3
Training loss: 1.605679988861084
Validation loss: 1.865039978953574
Epoch: 9| Step: 4
Training loss: 1.3596431016921997
Validation loss: 1.8628430237872995
Epoch: 9| Step: 5
Training loss: 1.9631932973861694
Validation loss: 1.8461699863131955
Epoch: 9| Step: 6
Training loss: 2.5942330360412598
Validation loss: 1.8524633954754837
Epoch: 9| Step: 7
Training loss: 2.4343667030334473
Validation loss: 1.8413772763108178
Epoch: 9| Step: 8
Training loss: 1.916479229927063
Validation loss: 1.889712294228643
Epoch: 9| Step: 9
Training loss: 2.288839340209961
Validation loss: 1.8131685316991464
Epoch: 9| Step: 10
Training loss: 2.351558208465576
Validation loss: 1.807350487160168
Epoch: 9| Step: 11
Training loss: 1.8206431865692139
Validation loss: 1.8631899511213783
Epoch: 9| Step: 12
Training loss: 2.0914764404296875
Validation loss: 1.8793410465871687
Epoch: 9| Step: 13
Training loss: 1.8808214664459229
Validation loss: 1.8483017674452966
Epoch: 9| Step: 14
Training loss: 3.328791379928589
Validation loss: 1.8040612344261553
Epoch: 9| Step: 15
Training loss: 1.2553640604019165
Validation loss: 1.869132517053069
Epoch: 9| Step: 16
Training loss: 2.3946456909179688
Validation loss: 1.8170614602754442
Epoch: 9| Step: 17
Training loss: 1.8271677494049072
Validation loss: 1.8233269204338678
Epoch: 9| Step: 18
Training loss: 2.12539005279541
Validation loss: 1.850859413044058
Epoch: 9| Step: 19
Training loss: 1.7328705787658691
Validation loss: 1.8758206564745457
Epoch: 70| Step: 0
Training loss: 3.0323736667633057
Validation loss: 1.858754961610698
Epoch: 9| Step: 1
Training loss: 2.3557121753692627
Validation loss: 1.8155806836464423
Epoch: 9| Step: 2
Training loss: 1.7469135522842407
Validation loss: 1.8623263784449735
Epoch: 9| Step: 3
Training loss: 1.83729887008667
Validation loss: 1.8409090625296394
Epoch: 9| Step: 4
Training loss: 1.5900840759277344
Validation loss: 1.866892917550725
Epoch: 9| Step: 5
Training loss: 1.7357177734375
Validation loss: 1.8659576820812638
Epoch: 9| Step: 6
Training loss: 1.9022715091705322
Validation loss: 1.8518272509677804
Epoch: 9| Step: 7
Training loss: 1.7064530849456787
Validation loss: 1.8225571783326513
Epoch: 9| Step: 8
Training loss: 2.428318500518799
Validation loss: 1.861389131854764
Epoch: 9| Step: 9
Training loss: 2.039320707321167
Validation loss: 1.8053320809233961
Epoch: 9| Step: 10
Training loss: 2.3675665855407715
Validation loss: 1.8742916858453544
Epoch: 9| Step: 11
Training loss: 1.9619956016540527
Validation loss: 1.821561255043359
Epoch: 9| Step: 12
Training loss: 2.54579496383667
Validation loss: 1.8151421478326373
Epoch: 9| Step: 13
Training loss: 2.2447237968444824
Validation loss: 1.8391987754286623
Epoch: 9| Step: 14
Training loss: 1.6462323665618896
Validation loss: 1.8083447149331622
Epoch: 9| Step: 15
Training loss: 1.8085541725158691
Validation loss: 1.8482123887796196
Epoch: 9| Step: 16
Training loss: 2.9459362030029297
Validation loss: 1.826862777737405
Epoch: 9| Step: 17
Training loss: 1.1699326038360596
Validation loss: 1.8615814095778431
Epoch: 9| Step: 18
Training loss: 2.0767879486083984
Validation loss: 1.8124764154283264
Epoch: 9| Step: 19
Training loss: 2.0643534660339355
Validation loss: 1.8634567243589772
Epoch: 71| Step: 0
Training loss: 2.4211368560791016
Validation loss: 1.8812368344917572
Epoch: 9| Step: 1
Training loss: 2.4550466537475586
Validation loss: 1.8479000321395105
Epoch: 9| Step: 2
Training loss: 2.252476692199707
Validation loss: 1.8341239356308532
Epoch: 9| Step: 3
Training loss: 1.7472856044769287
Validation loss: 1.8621382996332732
Epoch: 9| Step: 4
Training loss: 2.2500152587890625
Validation loss: 1.823887917635252
Epoch: 9| Step: 5
Training loss: 1.816965103149414
Validation loss: 1.848507438632224
Epoch: 9| Step: 6
Training loss: 1.978246808052063
Validation loss: 1.8191219568252563
Epoch: 9| Step: 7
Training loss: 1.4547910690307617
Validation loss: 1.8789524543199607
Epoch: 9| Step: 8
Training loss: 2.2552666664123535
Validation loss: 1.8252188584787383
Epoch: 9| Step: 9
Training loss: 2.1063497066497803
Validation loss: 1.8532619579232854
Epoch: 9| Step: 10
Training loss: 2.0352649688720703
Validation loss: 1.8644268358354088
Epoch: 9| Step: 11
Training loss: 2.068319797515869
Validation loss: 1.862369559651656
Epoch: 9| Step: 12
Training loss: 1.9949655532836914
Validation loss: 1.814010780492275
Epoch: 9| Step: 13
Training loss: 1.8245269060134888
Validation loss: 1.8323825168952668
Epoch: 9| Step: 14
Training loss: 1.8036519289016724
Validation loss: 1.8889647705091848
Epoch: 9| Step: 15
Training loss: 1.6527270078659058
Validation loss: 1.8625285651186387
Epoch: 9| Step: 16
Training loss: 2.305091142654419
Validation loss: 1.844016566550989
Epoch: 9| Step: 17
Training loss: 2.3628571033477783
Validation loss: 1.8494113700852977
Epoch: 9| Step: 18
Training loss: 1.3205842971801758
Validation loss: 1.8773481339859448
Epoch: 9| Step: 19
Training loss: 3.0519251823425293
Validation loss: 1.8381100918749254
Epoch: 72| Step: 0
Training loss: 2.1828832626342773
Validation loss: 1.8610757932388524
Epoch: 9| Step: 1
Training loss: 2.348419666290283
Validation loss: 1.863651120405403
Epoch: 9| Step: 2
Training loss: 2.137446641921997
Validation loss: 1.8171536510796855
Epoch: 9| Step: 3
Training loss: 2.924450159072876
Validation loss: 1.868419873628685
Epoch: 9| Step: 4
Training loss: 1.6896238327026367
Validation loss: 1.8591680363785448
Epoch: 9| Step: 5
Training loss: 1.502305269241333
Validation loss: 1.8394285929288796
Epoch: 9| Step: 6
Training loss: 1.939063549041748
Validation loss: 1.8868627153712212
Epoch: 9| Step: 7
Training loss: 2.1482348442077637
Validation loss: 1.8547117624351446
Epoch: 9| Step: 8
Training loss: 2.443305015563965
Validation loss: 1.836268383821995
Epoch: 9| Step: 9
Training loss: 2.2379231452941895
Validation loss: 1.8851685017990552
Epoch: 9| Step: 10
Training loss: 2.268883228302002
Validation loss: 1.8639656065179289
Epoch: 9| Step: 11
Training loss: 1.9971333742141724
Validation loss: 1.8647911419971384
Epoch: 9| Step: 12
Training loss: 2.8948850631713867
Validation loss: 1.8738816401941314
Epoch: 9| Step: 13
Training loss: 2.1535191535949707
Validation loss: 1.8630088885053455
Epoch: 9| Step: 14
Training loss: 1.618805170059204
Validation loss: 1.8807754902530918
Epoch: 9| Step: 15
Training loss: 1.2561235427856445
Validation loss: 1.8148257646629278
Epoch: 9| Step: 16
Training loss: 1.4137065410614014
Validation loss: 1.8655625195811978
Epoch: 9| Step: 17
Training loss: 1.9518461227416992
Validation loss: 1.8558262595169837
Epoch: 9| Step: 18
Training loss: 2.129207134246826
Validation loss: 1.8613912150156584
Epoch: 9| Step: 19
Training loss: 1.7830119132995605
Validation loss: 1.8534039953629748
Epoch: 73| Step: 0
Training loss: 1.8468526601791382
Validation loss: 1.8406248487156929
Epoch: 9| Step: 1
Training loss: 2.7293806076049805
Validation loss: 1.8698866110053851
Epoch: 9| Step: 2
Training loss: 2.5003275871276855
Validation loss: 1.8467862811877573
Epoch: 9| Step: 3
Training loss: 1.8935670852661133
Validation loss: 1.8496155584458824
Epoch: 9| Step: 4
Training loss: 1.600722312927246
Validation loss: 1.8002392456685896
Epoch: 9| Step: 5
Training loss: 1.5909826755523682
Validation loss: 1.8860460039523008
Epoch: 9| Step: 6
Training loss: 2.5347156524658203
Validation loss: 1.832633063947554
Epoch: 9| Step: 7
Training loss: 2.057163715362549
Validation loss: 1.855238862174878
Epoch: 9| Step: 8
Training loss: 1.9097050428390503
Validation loss: 1.8364005371821013
Epoch: 9| Step: 9
Training loss: 2.1269078254699707
Validation loss: 1.8458365150492826
Epoch: 9| Step: 10
Training loss: 2.115297794342041
Validation loss: 1.8005899928456588
Epoch: 9| Step: 11
Training loss: 2.074761390686035
Validation loss: 1.8342511036413178
Epoch: 9| Step: 12
Training loss: 1.8667731285095215
Validation loss: 1.8190725904574496
Epoch: 9| Step: 13
Training loss: 1.7737067937850952
Validation loss: 1.8336265944748473
Epoch: 9| Step: 14
Training loss: 2.2277891635894775
Validation loss: 1.8187446336952044
Epoch: 9| Step: 15
Training loss: 2.7024192810058594
Validation loss: 1.849252498407158
Epoch: 9| Step: 16
Training loss: 2.176511764526367
Validation loss: 1.863296619422144
Epoch: 9| Step: 17
Training loss: 1.3548829555511475
Validation loss: 1.844999917119527
Epoch: 9| Step: 18
Training loss: 1.76710844039917
Validation loss: 1.9212194055104428
Epoch: 9| Step: 19
Training loss: 2.335141181945801
Validation loss: 1.8481586399695855
Epoch: 74| Step: 0
Training loss: 1.9933738708496094
Validation loss: 1.8790645273469335
Epoch: 9| Step: 1
Training loss: 1.9761968851089478
Validation loss: 1.8353017465673762
Epoch: 9| Step: 2
Training loss: 1.9009408950805664
Validation loss: 1.8900305830317436
Epoch: 9| Step: 3
Training loss: 2.4795117378234863
Validation loss: 1.8772455513906137
Epoch: 9| Step: 4
Training loss: 2.030001640319824
Validation loss: 1.9059883004469838
Epoch: 9| Step: 5
Training loss: 2.0493316650390625
Validation loss: 1.947070994823099
Epoch: 9| Step: 6
Training loss: 1.756514072418213
Validation loss: 1.9040322320924388
Epoch: 9| Step: 7
Training loss: 2.2792551517486572
Validation loss: 1.846635624659147
Epoch: 9| Step: 8
Training loss: 2.309825897216797
Validation loss: 1.8319365823869225
Epoch: 9| Step: 9
Training loss: 1.6233237981796265
Validation loss: 1.9536777091540878
Epoch: 9| Step: 10
Training loss: 2.0529372692108154
Validation loss: 1.9319421147271025
Epoch: 9| Step: 11
Training loss: 2.6627037525177
Validation loss: 1.9059165278784662
Epoch: 9| Step: 12
Training loss: 1.7703769207000732
Validation loss: 1.8935484920474266
Epoch: 9| Step: 13
Training loss: 1.5825743675231934
Validation loss: 1.9476206688572177
Epoch: 9| Step: 14
Training loss: 2.2499008178710938
Validation loss: 1.9041359904858706
Epoch: 9| Step: 15
Training loss: 2.0896666049957275
Validation loss: 1.9287031262898617
Epoch: 9| Step: 16
Training loss: 1.920650601387024
Validation loss: 1.9563731855625728
Epoch: 9| Step: 17
Training loss: 2.241640090942383
Validation loss: 1.9124817856781775
Epoch: 9| Step: 18
Training loss: 2.3466339111328125
Validation loss: 1.9260297010270813
Epoch: 9| Step: 19
Training loss: 1.546101450920105
Validation loss: 1.9866469901242703
Epoch: 75| Step: 0
Training loss: 2.0794663429260254
Validation loss: 1.9061500219990024
Epoch: 9| Step: 1
Training loss: 1.8858187198638916
Validation loss: 1.9463707037109266
Epoch: 9| Step: 2
Training loss: 2.1152915954589844
Validation loss: 1.9387925031373827
Epoch: 9| Step: 3
Training loss: 1.865638256072998
Validation loss: 1.8663705381558096
Epoch: 9| Step: 4
Training loss: 2.386416435241699
Validation loss: 1.8641466965778268
Epoch: 9| Step: 5
Training loss: 2.1157071590423584
Validation loss: 1.9478733848324783
Epoch: 9| Step: 6
Training loss: 1.6393746137619019
Validation loss: 1.8820034642871335
Epoch: 9| Step: 7
Training loss: 2.6072349548339844
Validation loss: 1.9124554695842935
Epoch: 9| Step: 8
Training loss: 1.5162889957427979
Validation loss: 1.8654436885024146
Epoch: 9| Step: 9
Training loss: 2.195345163345337
Validation loss: 1.8703121950300476
Epoch: 9| Step: 10
Training loss: 1.9856724739074707
Validation loss: 1.8949910565245924
Epoch: 9| Step: 11
Training loss: 2.3024325370788574
Validation loss: 1.8364285642294575
Epoch: 9| Step: 12
Training loss: 1.666067361831665
Validation loss: 1.8721509194202561
Epoch: 9| Step: 13
Training loss: 1.800389289855957
Validation loss: 1.854827767653431
Epoch: 9| Step: 14
Training loss: 1.8795650005340576
Validation loss: 1.8686616635151048
Epoch: 9| Step: 15
Training loss: 2.310500144958496
Validation loss: 1.872191520903608
Epoch: 9| Step: 16
Training loss: 2.155367374420166
Validation loss: 1.8805229175005027
Epoch: 9| Step: 17
Training loss: 2.1909945011138916
Validation loss: 1.8260810375213623
Epoch: 9| Step: 18
Training loss: 2.624112367630005
Validation loss: 1.9233276621043254
Epoch: 9| Step: 19
Training loss: 1.7831372022628784
Validation loss: 1.834030100767561
Epoch: 76| Step: 0
Training loss: 1.858574390411377
Validation loss: 1.895281305416025
Epoch: 9| Step: 1
Training loss: 2.249769687652588
Validation loss: 1.8598687262843838
Epoch: 9| Step: 2
Training loss: 2.2255043983459473
Validation loss: 1.8740144805084886
Epoch: 9| Step: 3
Training loss: 1.6622467041015625
Validation loss: 1.867835145202472
Epoch: 9| Step: 4
Training loss: 1.6482164859771729
Validation loss: 1.863071703224731
Epoch: 9| Step: 5
Training loss: 2.6192541122436523
Validation loss: 1.8660199127608923
Epoch: 9| Step: 6
Training loss: 1.9732931852340698
Validation loss: 1.883278440228469
Epoch: 9| Step: 7
Training loss: 2.1848816871643066
Validation loss: 1.8419361294602319
Epoch: 9| Step: 8
Training loss: 1.734765887260437
Validation loss: 1.8455615806922638
Epoch: 9| Step: 9
Training loss: 2.073085069656372
Validation loss: 1.8127503275013657
Epoch: 9| Step: 10
Training loss: 1.2877787351608276
Validation loss: 1.873317760529278
Epoch: 9| Step: 11
Training loss: 2.38448429107666
Validation loss: 1.7930237775226292
Epoch: 9| Step: 12
Training loss: 2.1744508743286133
Validation loss: 1.8191767424988232
Epoch: 9| Step: 13
Training loss: 1.7655612230300903
Validation loss: 1.812800917694037
Epoch: 9| Step: 14
Training loss: 2.0697896480560303
Validation loss: 1.855293951446204
Epoch: 9| Step: 15
Training loss: 2.1445107460021973
Validation loss: 1.8483696687135764
Epoch: 9| Step: 16
Training loss: 1.7811921834945679
Validation loss: 1.8413923001117845
Epoch: 9| Step: 17
Training loss: 2.2934110164642334
Validation loss: 1.8143436951602963
Epoch: 9| Step: 18
Training loss: 2.295043468475342
Validation loss: 1.8345680082444664
Epoch: 9| Step: 19
Training loss: 2.48811411857605
Validation loss: 1.8500848288158718
Epoch: 77| Step: 0
Training loss: 1.429409384727478
Validation loss: 1.7890186618557937
Epoch: 9| Step: 1
Training loss: 1.8097509145736694
Validation loss: 1.823382259272843
Epoch: 9| Step: 2
Training loss: 2.1640288829803467
Validation loss: 1.8489813658830931
Epoch: 9| Step: 3
Training loss: 1.701494812965393
Validation loss: 1.855887888146819
Epoch: 9| Step: 4
Training loss: 2.258451223373413
Validation loss: 1.8443272774168056
Epoch: 9| Step: 5
Training loss: 1.493116021156311
Validation loss: 1.8323002667735806
Epoch: 9| Step: 6
Training loss: 2.3397464752197266
Validation loss: 1.8552280518648436
Epoch: 9| Step: 7
Training loss: 1.672330617904663
Validation loss: 1.8767782235317092
Epoch: 9| Step: 8
Training loss: 2.530428171157837
Validation loss: 1.833558852724034
Epoch: 9| Step: 9
Training loss: 2.393401861190796
Validation loss: 1.8369753515120033
Epoch: 9| Step: 10
Training loss: 2.9491207599639893
Validation loss: 1.9005233040816492
Epoch: 9| Step: 11
Training loss: 2.166133403778076
Validation loss: 1.852234939019457
Epoch: 9| Step: 12
Training loss: 2.2745139598846436
Validation loss: 1.8970602519220585
Epoch: 9| Step: 13
Training loss: 2.361687183380127
Validation loss: 1.8377549313812804
Epoch: 9| Step: 14
Training loss: 2.023366928100586
Validation loss: 1.8269515191908363
Epoch: 9| Step: 15
Training loss: 2.540968179702759
Validation loss: 1.8442115560710002
Epoch: 9| Step: 16
Training loss: 1.2850117683410645
Validation loss: 1.8472074793397093
Epoch: 9| Step: 17
Training loss: 2.2649707794189453
Validation loss: 1.8933799215357938
Epoch: 9| Step: 18
Training loss: 1.6752281188964844
Validation loss: 1.8744110134865741
Epoch: 9| Step: 19
Training loss: 2.154195785522461
Validation loss: 1.8414219008932868
Epoch: 78| Step: 0
Training loss: 1.9769996404647827
Validation loss: 1.8166853438178412
Epoch: 9| Step: 1
Training loss: 1.4737296104431152
Validation loss: 1.849628059984111
Epoch: 9| Step: 2
Training loss: 1.6639553308486938
Validation loss: 1.898749938114084
Epoch: 9| Step: 3
Training loss: 2.3926429748535156
Validation loss: 1.8533958025115858
Epoch: 9| Step: 4
Training loss: 1.9396615028381348
Validation loss: 1.8420405902450891
Epoch: 9| Step: 5
Training loss: 1.5959566831588745
Validation loss: 1.8317959771739494
Epoch: 9| Step: 6
Training loss: 2.2239294052124023
Validation loss: 1.8612282636354296
Epoch: 9| Step: 7
Training loss: 1.830046534538269
Validation loss: 1.8999207208482483
Epoch: 9| Step: 8
Training loss: 2.0651369094848633
Validation loss: 1.8740965042182867
Epoch: 9| Step: 9
Training loss: 2.0748984813690186
Validation loss: 1.8793029922375577
Epoch: 9| Step: 10
Training loss: 2.9766879081726074
Validation loss: 1.8509475807491824
Epoch: 9| Step: 11
Training loss: 2.14812970161438
Validation loss: 1.8548884734832982
Epoch: 9| Step: 12
Training loss: 2.2472848892211914
Validation loss: 1.8693805418426184
Epoch: 9| Step: 13
Training loss: 2.6577467918395996
Validation loss: 1.865376381565341
Epoch: 9| Step: 14
Training loss: 2.0332605838775635
Validation loss: 1.8588589352669476
Epoch: 9| Step: 15
Training loss: 1.9261865615844727
Validation loss: 1.9099632518754588
Epoch: 9| Step: 16
Training loss: 2.878787040710449
Validation loss: 1.891526282262459
Epoch: 9| Step: 17
Training loss: 1.7298227548599243
Validation loss: 1.8855864933068804
Epoch: 9| Step: 18
Training loss: 1.5566564798355103
Validation loss: 1.841490885336622
Epoch: 9| Step: 19
Training loss: 2.0014894008636475
Validation loss: 1.8251525206531551
Epoch: 79| Step: 0
Training loss: 1.3081154823303223
Validation loss: 1.8848272459112483
Epoch: 9| Step: 1
Training loss: 1.9871611595153809
Validation loss: 1.9020486323953532
Epoch: 9| Step: 2
Training loss: 2.1566002368927
Validation loss: 1.8368483138598983
Epoch: 9| Step: 3
Training loss: 2.4383745193481445
Validation loss: 1.8878884512743503
Epoch: 9| Step: 4
Training loss: 2.316041946411133
Validation loss: 1.8381549282897292
Epoch: 9| Step: 5
Training loss: 2.0633544921875
Validation loss: 1.9001968455829208
Epoch: 9| Step: 6
Training loss: 2.165935516357422
Validation loss: 1.877588282386176
Epoch: 9| Step: 7
Training loss: 1.4704272747039795
Validation loss: 1.8718928587522439
Epoch: 9| Step: 8
Training loss: 2.1788418292999268
Validation loss: 1.8570365837152056
Epoch: 9| Step: 9
Training loss: 1.7599236965179443
Validation loss: 1.8527610396309722
Epoch: 9| Step: 10
Training loss: 2.6802830696105957
Validation loss: 1.830944538974076
Epoch: 9| Step: 11
Training loss: 1.9260402917861938
Validation loss: 1.882480122202592
Epoch: 9| Step: 12
Training loss: 1.957819938659668
Validation loss: 1.9203470036280241
Epoch: 9| Step: 13
Training loss: 1.979604721069336
Validation loss: 1.917062452371172
Epoch: 9| Step: 14
Training loss: 1.394918441772461
Validation loss: 1.9250319904560664
Epoch: 9| Step: 15
Training loss: 2.447598695755005
Validation loss: 1.9348533728139863
Epoch: 9| Step: 16
Training loss: 2.1275649070739746
Validation loss: 1.8683167224307713
Epoch: 9| Step: 17
Training loss: 2.3131163120269775
Validation loss: 1.8726700304223478
Epoch: 9| Step: 18
Training loss: 1.7574965953826904
Validation loss: 1.8620351630149128
Epoch: 9| Step: 19
Training loss: 2.37860369682312
Validation loss: 1.8244601599604107
Epoch: 80| Step: 0
Training loss: 2.805375337600708
Validation loss: 1.8611148870248588
Epoch: 9| Step: 1
Training loss: 1.9516456127166748
Validation loss: 1.8525738570329955
Epoch: 9| Step: 2
Training loss: 2.366927146911621
Validation loss: 1.832501800797826
Epoch: 9| Step: 3
Training loss: 1.9466238021850586
Validation loss: 1.875172163942735
Epoch: 9| Step: 4
Training loss: 2.2711997032165527
Validation loss: 1.8950208725689126
Epoch: 9| Step: 5
Training loss: 2.6923508644104004
Validation loss: 1.8848654374801854
Epoch: 9| Step: 6
Training loss: 2.161764144897461
Validation loss: 1.8739006759451449
Epoch: 9| Step: 7
Training loss: 1.5818754434585571
Validation loss: 1.866129480677543
Epoch: 9| Step: 8
Training loss: 1.9680817127227783
Validation loss: 1.8794372390500076
Epoch: 9| Step: 9
Training loss: 2.352745294570923
Validation loss: 1.9201106381930892
Epoch: 9| Step: 10
Training loss: 2.0331709384918213
Validation loss: 1.9276695851799395
Epoch: 9| Step: 11
Training loss: 2.3724231719970703
Validation loss: 1.9165598925926703
Epoch: 9| Step: 12
Training loss: 1.4296534061431885
Validation loss: 1.8845250452165123
Epoch: 9| Step: 13
Training loss: 1.7460379600524902
Validation loss: 1.8915873997503048
Epoch: 9| Step: 14
Training loss: 2.4052939414978027
Validation loss: 1.876155992206052
Epoch: 9| Step: 15
Training loss: 2.1659979820251465
Validation loss: 1.8456908704565584
Epoch: 9| Step: 16
Training loss: 1.9786834716796875
Validation loss: 1.8784628583372927
Epoch: 9| Step: 17
Training loss: 1.547046184539795
Validation loss: 1.9246008164591069
Epoch: 9| Step: 18
Training loss: 1.517164945602417
Validation loss: 1.9012546650797344
Epoch: 9| Step: 19
Training loss: 1.8947086334228516
Validation loss: 1.9443774240480052
Epoch: 81| Step: 0
Training loss: 2.135681629180908
Validation loss: 1.9367022591529133
Epoch: 9| Step: 1
Training loss: 2.106794595718384
Validation loss: 1.9190273259183486
Epoch: 9| Step: 2
Training loss: 1.903947353363037
Validation loss: 1.9198364602576057
Epoch: 9| Step: 3
Training loss: 3.0016212463378906
Validation loss: 1.856588334488354
Epoch: 9| Step: 4
Training loss: 2.248030185699463
Validation loss: 1.8628895763013003
Epoch: 9| Step: 5
Training loss: 2.050286293029785
Validation loss: 1.84713191780255
Epoch: 9| Step: 6
Training loss: 1.671856164932251
Validation loss: 1.8953215750001318
Epoch: 9| Step: 7
Training loss: 1.6190083026885986
Validation loss: 1.8525716495170867
Epoch: 9| Step: 8
Training loss: 2.195343255996704
Validation loss: 1.8310502861901152
Epoch: 9| Step: 9
Training loss: 1.722280740737915
Validation loss: 1.8655340337067199
Epoch: 9| Step: 10
Training loss: 1.917232632637024
Validation loss: 1.8775304067049094
Epoch: 9| Step: 11
Training loss: 2.5819554328918457
Validation loss: 1.9081840052021493
Epoch: 9| Step: 12
Training loss: 2.448181629180908
Validation loss: 1.7900504268330635
Epoch: 9| Step: 13
Training loss: 1.6616237163543701
Validation loss: 1.8482681264122613
Epoch: 9| Step: 14
Training loss: 1.5645790100097656
Validation loss: 1.8661253246472036
Epoch: 9| Step: 15
Training loss: 2.185596466064453
Validation loss: 1.802129370703114
Epoch: 9| Step: 16
Training loss: 2.2744617462158203
Validation loss: 1.8697381637079253
Epoch: 9| Step: 17
Training loss: 2.4917666912078857
Validation loss: 1.8392602745577586
Epoch: 9| Step: 18
Training loss: 1.9984763860702515
Validation loss: 1.8267316466612782
Epoch: 9| Step: 19
Training loss: 2.025829792022705
Validation loss: 1.831797411115907
Epoch: 82| Step: 0
Training loss: 1.7392066717147827
Validation loss: 1.8494276674531347
Epoch: 9| Step: 1
Training loss: 1.9658608436584473
Validation loss: 1.8495694690471074
Epoch: 9| Step: 2
Training loss: 2.2168729305267334
Validation loss: 1.90837310715545
Epoch: 9| Step: 3
Training loss: 1.403090000152588
Validation loss: 1.8458956248468632
Epoch: 9| Step: 4
Training loss: 1.3657944202423096
Validation loss: 1.8819377508094843
Epoch: 9| Step: 5
Training loss: 1.9684865474700928
Validation loss: 1.865915792451488
Epoch: 9| Step: 6
Training loss: 2.730245351791382
Validation loss: 1.8942159328529302
Epoch: 9| Step: 7
Training loss: 2.061974048614502
Validation loss: 1.8726500667256416
Epoch: 9| Step: 8
Training loss: 1.9944112300872803
Validation loss: 1.8762785976739238
Epoch: 9| Step: 9
Training loss: 2.001784324645996
Validation loss: 1.923240866592462
Epoch: 9| Step: 10
Training loss: 2.5118556022644043
Validation loss: 1.8313026694085102
Epoch: 9| Step: 11
Training loss: 2.140629529953003
Validation loss: 1.8620386380943463
Epoch: 9| Step: 12
Training loss: 2.768369436264038
Validation loss: 1.8669682886960695
Epoch: 9| Step: 13
Training loss: 2.621213912963867
Validation loss: 1.9369370208369743
Epoch: 9| Step: 14
Training loss: 1.592188835144043
Validation loss: 1.885289062698968
Epoch: 9| Step: 15
Training loss: 1.8572578430175781
Validation loss: 1.8877668217789354
Epoch: 9| Step: 16
Training loss: 2.5841875076293945
Validation loss: 1.9121789932250977
Epoch: 9| Step: 17
Training loss: 1.9382869005203247
Validation loss: 1.8457393080210514
Epoch: 9| Step: 18
Training loss: 2.1707842350006104
Validation loss: 1.8890724190705115
Epoch: 9| Step: 19
Training loss: 1.9368836879730225
Validation loss: 1.905434190798149
Epoch: 83| Step: 0
Training loss: 1.8023086786270142
Validation loss: 1.8586518378566494
Epoch: 9| Step: 1
Training loss: 1.966980218887329
Validation loss: 1.8940213035336502
Epoch: 9| Step: 2
Training loss: 1.316344976425171
Validation loss: 1.8871410356151115
Epoch: 9| Step: 3
Training loss: 2.5294551849365234
Validation loss: 1.9204717968865264
Epoch: 9| Step: 4
Training loss: 2.2215592861175537
Validation loss: 1.875461673565048
Epoch: 9| Step: 5
Training loss: 1.5557705163955688
Validation loss: 1.9154487831129445
Epoch: 9| Step: 6
Training loss: 2.339056968688965
Validation loss: 1.8646079224648235
Epoch: 9| Step: 7
Training loss: 2.046510934829712
Validation loss: 1.8579426549321456
Epoch: 9| Step: 8
Training loss: 2.4733681678771973
Validation loss: 1.9155689109143594
Epoch: 9| Step: 9
Training loss: 2.6577117443084717
Validation loss: 1.9125525882775836
Epoch: 9| Step: 10
Training loss: 1.963661551475525
Validation loss: 1.8964612964245913
Epoch: 9| Step: 11
Training loss: 1.787613034248352
Validation loss: 1.8412746731325877
Epoch: 9| Step: 12
Training loss: 2.0019774436950684
Validation loss: 1.8518689416295333
Epoch: 9| Step: 13
Training loss: 2.132956027984619
Validation loss: 1.8544635223827775
Epoch: 9| Step: 14
Training loss: 2.3490333557128906
Validation loss: 1.8343074613337895
Epoch: 9| Step: 15
Training loss: 2.337937355041504
Validation loss: 1.8506734388337718
Epoch: 9| Step: 16
Training loss: 1.8251194953918457
Validation loss: 1.8215258507419834
Epoch: 9| Step: 17
Training loss: 1.8363975286483765
Validation loss: 1.8779298272921885
Epoch: 9| Step: 18
Training loss: 2.635470151901245
Validation loss: 1.8571823955439835
Epoch: 9| Step: 19
Training loss: 1.389427900314331
Validation loss: 1.8424196672096527
Epoch: 84| Step: 0
Training loss: 1.691689372062683
Validation loss: 1.8829799341640885
Epoch: 9| Step: 1
Training loss: 2.068755865097046
Validation loss: 1.829951253726328
Epoch: 9| Step: 2
Training loss: 2.490480899810791
Validation loss: 1.8198104016214824
Epoch: 9| Step: 3
Training loss: 1.850892186164856
Validation loss: 1.8625902134737522
Epoch: 9| Step: 4
Training loss: 1.8895666599273682
Validation loss: 1.8482155542579486
Epoch: 9| Step: 5
Training loss: 2.492964744567871
Validation loss: 1.8366999137315818
Epoch: 9| Step: 6
Training loss: 1.8496488332748413
Validation loss: 1.8421925486420556
Epoch: 9| Step: 7
Training loss: 1.8797407150268555
Validation loss: 1.826766394882751
Epoch: 9| Step: 8
Training loss: 1.853935956954956
Validation loss: 1.7937783508849658
Epoch: 9| Step: 9
Training loss: 2.0105795860290527
Validation loss: 1.8135013648931928
Epoch: 9| Step: 10
Training loss: 2.168985605239868
Validation loss: 1.8012759256705964
Epoch: 9| Step: 11
Training loss: 2.7140955924987793
Validation loss: 1.8321012472934861
Epoch: 9| Step: 12
Training loss: 2.077556610107422
Validation loss: 1.8155077104088213
Epoch: 9| Step: 13
Training loss: 1.8912725448608398
Validation loss: 1.82196522616654
Epoch: 9| Step: 14
Training loss: 1.792415976524353
Validation loss: 1.778217837964888
Epoch: 9| Step: 15
Training loss: 2.1831698417663574
Validation loss: 1.8031305314825594
Epoch: 9| Step: 16
Training loss: 1.7616467475891113
Validation loss: 1.78699628226191
Epoch: 9| Step: 17
Training loss: 2.0276191234588623
Validation loss: 1.8267727043988893
Epoch: 9| Step: 18
Training loss: 2.533763885498047
Validation loss: 1.827810448708294
Epoch: 9| Step: 19
Training loss: 2.1537234783172607
Validation loss: 1.8341854990815087
Epoch: 85| Step: 0
Training loss: 2.551469087600708
Validation loss: 1.8424532945207555
Epoch: 9| Step: 1
Training loss: 2.2634530067443848
Validation loss: 1.8954093473420726
Epoch: 9| Step: 2
Training loss: 2.4499802589416504
Validation loss: 1.8474869007686916
Epoch: 9| Step: 3
Training loss: 3.0443837642669678
Validation loss: 1.763374774576091
Epoch: 9| Step: 4
Training loss: 2.6926379203796387
Validation loss: 1.786702620039741
Epoch: 9| Step: 5
Training loss: 1.5314276218414307
Validation loss: 1.8122252911972485
Epoch: 9| Step: 6
Training loss: 1.598609447479248
Validation loss: 1.821050203961434
Epoch: 9| Step: 7
Training loss: 1.430433988571167
Validation loss: 1.8497395661237428
Epoch: 9| Step: 8
Training loss: 1.894423246383667
Validation loss: 1.7944228760630108
Epoch: 9| Step: 9
Training loss: 2.0829694271087646
Validation loss: 1.8358718817182582
Epoch: 9| Step: 10
Training loss: 1.8792760372161865
Validation loss: 1.8672458422269753
Epoch: 9| Step: 11
Training loss: 1.8790130615234375
Validation loss: 1.8553979002314507
Epoch: 9| Step: 12
Training loss: 1.839214563369751
Validation loss: 1.817133268006414
Epoch: 9| Step: 13
Training loss: 2.0146074295043945
Validation loss: 1.8325838553819724
Epoch: 9| Step: 14
Training loss: 1.1848978996276855
Validation loss: 1.8293793973305243
Epoch: 9| Step: 15
Training loss: 1.345293641090393
Validation loss: 1.8413476695259698
Epoch: 9| Step: 16
Training loss: 2.5980334281921387
Validation loss: 1.8297275424861221
Epoch: 9| Step: 17
Training loss: 2.1908421516418457
Validation loss: 1.7898737706726404
Epoch: 9| Step: 18
Training loss: 2.052206039428711
Validation loss: 1.7849163211506904
Epoch: 9| Step: 19
Training loss: 2.0444183349609375
Validation loss: 1.8556166518506387
Epoch: 86| Step: 0
Training loss: 1.0766100883483887
Validation loss: 1.8673441976094418
Epoch: 9| Step: 1
Training loss: 1.8518273830413818
Validation loss: 1.8569465601186959
Epoch: 9| Step: 2
Training loss: 2.64328932762146
Validation loss: 1.846161921247304
Epoch: 9| Step: 3
Training loss: 2.679455280303955
Validation loss: 1.853556966610092
Epoch: 9| Step: 4
Training loss: 2.1269514560699463
Validation loss: 1.8622562756641305
Epoch: 9| Step: 5
Training loss: 2.0251126289367676
Validation loss: 1.8619453512507378
Epoch: 9| Step: 6
Training loss: 1.3099777698516846
Validation loss: 1.850591568638095
Epoch: 9| Step: 7
Training loss: 1.9132161140441895
Validation loss: 1.9267959680488642
Epoch: 9| Step: 8
Training loss: 1.8313742876052856
Validation loss: 1.8705885959186141
Epoch: 9| Step: 9
Training loss: 2.505445957183838
Validation loss: 1.8654705431821534
Epoch: 9| Step: 10
Training loss: 2.786048650741577
Validation loss: 1.9109204175660937
Epoch: 9| Step: 11
Training loss: 2.5997023582458496
Validation loss: 1.831642921022374
Epoch: 9| Step: 12
Training loss: 1.9879533052444458
Validation loss: 1.8171990509513472
Epoch: 9| Step: 13
Training loss: 1.2988547086715698
Validation loss: 1.8535902551609835
Epoch: 9| Step: 14
Training loss: 1.9635676145553589
Validation loss: 1.8356663700487974
Epoch: 9| Step: 15
Training loss: 2.4032809734344482
Validation loss: 1.852059314576842
Epoch: 9| Step: 16
Training loss: 2.0752663612365723
Validation loss: 1.8816665290928574
Epoch: 9| Step: 17
Training loss: 2.3804304599761963
Validation loss: 1.8297903331921255
Epoch: 9| Step: 18
Training loss: 2.0941038131713867
Validation loss: 1.8789686805052723
Epoch: 9| Step: 19
Training loss: 1.8289240598678589
Validation loss: 1.9168847276152468
Epoch: 87| Step: 0
Training loss: 2.183976650238037
Validation loss: 1.869859741746093
Epoch: 9| Step: 1
Training loss: 2.313676357269287
Validation loss: 1.8429764449167594
Epoch: 9| Step: 2
Training loss: 2.0375423431396484
Validation loss: 1.8600443378626872
Epoch: 9| Step: 3
Training loss: 3.075819253921509
Validation loss: 1.8740786734244805
Epoch: 9| Step: 4
Training loss: 1.8873412609100342
Validation loss: 1.8391985584506028
Epoch: 9| Step: 5
Training loss: 1.3114829063415527
Validation loss: 1.8239148709413817
Epoch: 9| Step: 6
Training loss: 1.8139811754226685
Validation loss: 1.868743176082913
Epoch: 9| Step: 7
Training loss: 1.8507784605026245
Validation loss: 1.8481592222941008
Epoch: 9| Step: 8
Training loss: 2.311757802963257
Validation loss: 1.8808712307497752
Epoch: 9| Step: 9
Training loss: 1.396016001701355
Validation loss: 1.890422809038231
Epoch: 9| Step: 10
Training loss: 2.209700107574463
Validation loss: 1.817854853842756
Epoch: 9| Step: 11
Training loss: 2.280496597290039
Validation loss: 1.8641468260785659
Epoch: 9| Step: 12
Training loss: 1.874780297279358
Validation loss: 1.8204895841131965
Epoch: 9| Step: 13
Training loss: 2.080423355102539
Validation loss: 1.858257981513044
Epoch: 9| Step: 14
Training loss: 1.656891107559204
Validation loss: 1.8628529730460626
Epoch: 9| Step: 15
Training loss: 2.267617702484131
Validation loss: 1.8379995334062644
Epoch: 9| Step: 16
Training loss: 2.431020498275757
Validation loss: 1.9090092748189145
Epoch: 9| Step: 17
Training loss: 1.9070087671279907
Validation loss: 1.8470467740683247
Epoch: 9| Step: 18
Training loss: 2.167877674102783
Validation loss: 1.8057838566869282
Epoch: 9| Step: 19
Training loss: 2.4240493774414062
Validation loss: 1.8533252786389358
Epoch: 88| Step: 0
Training loss: 1.5759844779968262
Validation loss: 1.8133028462636385
Epoch: 9| Step: 1
Training loss: 1.959313988685608
Validation loss: 1.827165171396818
Epoch: 9| Step: 2
Training loss: 1.9622182846069336
Validation loss: 1.8051066655906842
Epoch: 9| Step: 3
Training loss: 2.148094654083252
Validation loss: 1.8678480069414318
Epoch: 9| Step: 4
Training loss: 1.6745535135269165
Validation loss: 1.7840971629396618
Epoch: 9| Step: 5
Training loss: 2.059610366821289
Validation loss: 1.8053661576277917
Epoch: 9| Step: 6
Training loss: 1.441922664642334
Validation loss: 1.8307117326654119
Epoch: 9| Step: 7
Training loss: 2.090033531188965
Validation loss: 1.8831951686804242
Epoch: 9| Step: 8
Training loss: 1.416548728942871
Validation loss: 1.8057640130571324
Epoch: 9| Step: 9
Training loss: 2.4379143714904785
Validation loss: 1.8169038724556243
Epoch: 9| Step: 10
Training loss: 2.7252860069274902
Validation loss: 1.887775202449277
Epoch: 9| Step: 11
Training loss: 1.8587653636932373
Validation loss: 1.8281713698407729
Epoch: 9| Step: 12
Training loss: 2.0584044456481934
Validation loss: 1.8451112242911358
Epoch: 9| Step: 13
Training loss: 1.9436976909637451
Validation loss: 1.855804366173504
Epoch: 9| Step: 14
Training loss: 2.8834095001220703
Validation loss: 1.8660173184580082
Epoch: 9| Step: 15
Training loss: 2.47186017036438
Validation loss: 1.875078166989114
Epoch: 9| Step: 16
Training loss: 1.629427194595337
Validation loss: 1.847777757713263
Epoch: 9| Step: 17
Training loss: 1.9426403045654297
Validation loss: 1.8377013652444742
Epoch: 9| Step: 18
Training loss: 2.2638862133026123
Validation loss: 1.8153057578656313
Epoch: 9| Step: 19
Training loss: 2.7190065383911133
Validation loss: 1.8299106985544986
Epoch: 89| Step: 0
Training loss: 1.5309040546417236
Validation loss: 1.871573073400868
Epoch: 9| Step: 1
Training loss: 2.2126572132110596
Validation loss: 1.8593955400178759
Epoch: 9| Step: 2
Training loss: 1.7523573637008667
Validation loss: 1.8015394665354447
Epoch: 9| Step: 3
Training loss: 1.5204542875289917
Validation loss: 1.8616571597915759
Epoch: 9| Step: 4
Training loss: 2.0356597900390625
Validation loss: 1.8426940518317463
Epoch: 9| Step: 5
Training loss: 1.958865761756897
Validation loss: 1.8723347581547798
Epoch: 9| Step: 6
Training loss: 2.3380539417266846
Validation loss: 1.8549391245670457
Epoch: 9| Step: 7
Training loss: 2.357677936553955
Validation loss: 1.781905005304076
Epoch: 9| Step: 8
Training loss: 2.2566661834716797
Validation loss: 1.8205589990821673
Epoch: 9| Step: 9
Training loss: 1.7767536640167236
Validation loss: 1.7881249095038545
Epoch: 9| Step: 10
Training loss: 2.531010150909424
Validation loss: 1.8535572779264382
Epoch: 9| Step: 11
Training loss: 2.436196804046631
Validation loss: 1.8129738715055177
Epoch: 9| Step: 12
Training loss: 2.3205513954162598
Validation loss: 1.868803158938456
Epoch: 9| Step: 13
Training loss: 2.3015403747558594
Validation loss: 1.8673145230725514
Epoch: 9| Step: 14
Training loss: 1.8189388513565063
Validation loss: 1.8421029675778726
Epoch: 9| Step: 15
Training loss: 1.8073186874389648
Validation loss: 1.83033855527425
Epoch: 9| Step: 16
Training loss: 2.1170711517333984
Validation loss: 1.8473670293958924
Epoch: 9| Step: 17
Training loss: 2.1441121101379395
Validation loss: 1.8213461140076892
Epoch: 9| Step: 18
Training loss: 2.2615232467651367
Validation loss: 1.8612922455767076
Epoch: 9| Step: 19
Training loss: 1.5639501810073853
Validation loss: 1.856819607371049
Epoch: 90| Step: 0
Training loss: 2.2844114303588867
Validation loss: 1.8360498054422063
Epoch: 9| Step: 1
Training loss: 1.6450064182281494
Validation loss: 1.8808887442238897
Epoch: 9| Step: 2
Training loss: 2.001218557357788
Validation loss: 1.8544823214304533
Epoch: 9| Step: 3
Training loss: 1.9511593580245972
Validation loss: 1.828808603526877
Epoch: 9| Step: 4
Training loss: 2.117595672607422
Validation loss: 1.8296701076219408
Epoch: 9| Step: 5
Training loss: 2.0731372833251953
Validation loss: 1.846503212297563
Epoch: 9| Step: 6
Training loss: 2.063277244567871
Validation loss: 1.8694069171123366
Epoch: 9| Step: 7
Training loss: 2.3322200775146484
Validation loss: 1.820512587217976
Epoch: 9| Step: 8
Training loss: 2.128622531890869
Validation loss: 1.864036020615118
Epoch: 9| Step: 9
Training loss: 2.5441017150878906
Validation loss: 1.8450534489515016
Epoch: 9| Step: 10
Training loss: 1.6664001941680908
Validation loss: 1.8429401769912501
Epoch: 9| Step: 11
Training loss: 1.8596487045288086
Validation loss: 1.8700829804372445
Epoch: 9| Step: 12
Training loss: 1.9297270774841309
Validation loss: 1.828683472365784
Epoch: 9| Step: 13
Training loss: 2.068096399307251
Validation loss: 1.80039557192823
Epoch: 9| Step: 14
Training loss: 2.0806915760040283
Validation loss: 1.8313545940591276
Epoch: 9| Step: 15
Training loss: 1.6878252029418945
Validation loss: 1.8015265070277153
Epoch: 9| Step: 16
Training loss: 1.8984986543655396
Validation loss: 1.8616622514861951
Epoch: 9| Step: 17
Training loss: 2.7669548988342285
Validation loss: 1.835305131596627
Epoch: 9| Step: 18
Training loss: 2.25004243850708
Validation loss: 1.835145589259031
Epoch: 9| Step: 19
Training loss: 1.97092866897583
Validation loss: 1.8480769473014118
Epoch: 91| Step: 0
Training loss: 2.116330146789551
Validation loss: 1.8125844310513504
Epoch: 9| Step: 1
Training loss: 1.7793374061584473
Validation loss: 1.8386693875566662
Epoch: 9| Step: 2
Training loss: 2.091367244720459
Validation loss: 1.7905070884622258
Epoch: 9| Step: 3
Training loss: 2.0587024688720703
Validation loss: 1.8203800410675488
Epoch: 9| Step: 4
Training loss: 1.7614960670471191
Validation loss: 1.8023881577759338
Epoch: 9| Step: 5
Training loss: 1.8285870552062988
Validation loss: 1.8235721150748163
Epoch: 9| Step: 6
Training loss: 2.518843650817871
Validation loss: 1.7985042290721867
Epoch: 9| Step: 7
Training loss: 1.2324670553207397
Validation loss: 1.8410772110918443
Epoch: 9| Step: 8
Training loss: 1.8640741109848022
Validation loss: 1.8081793870857295
Epoch: 9| Step: 9
Training loss: 2.0752921104431152
Validation loss: 1.813358718542744
Epoch: 9| Step: 10
Training loss: 1.5765137672424316
Validation loss: 1.8489007057903482
Epoch: 9| Step: 11
Training loss: 2.4092304706573486
Validation loss: 1.8547694134197648
Epoch: 9| Step: 12
Training loss: 1.329870581626892
Validation loss: 1.78886636898672
Epoch: 9| Step: 13
Training loss: 2.6033430099487305
Validation loss: 1.7913004888905038
Epoch: 9| Step: 14
Training loss: 2.44502592086792
Validation loss: 1.8428630605876017
Epoch: 9| Step: 15
Training loss: 1.8323651552200317
Validation loss: 1.7715732219407885
Epoch: 9| Step: 16
Training loss: 2.3860042095184326
Validation loss: 1.8560884024599473
Epoch: 9| Step: 17
Training loss: 1.7591561079025269
Validation loss: 1.9218467671236545
Epoch: 9| Step: 18
Training loss: 3.1696085929870605
Validation loss: 1.8616421908783398
Epoch: 9| Step: 19
Training loss: 2.3240509033203125
Validation loss: 1.8582015757938084
Epoch: 92| Step: 0
Training loss: 2.184316873550415
Validation loss: 1.8984354708692153
Epoch: 9| Step: 1
Training loss: 1.678647518157959
Validation loss: 1.8267488994186731
Epoch: 9| Step: 2
Training loss: 1.857837438583374
Validation loss: 1.835489147858654
Epoch: 9| Step: 3
Training loss: 1.8194228410720825
Validation loss: 1.8900145703940083
Epoch: 9| Step: 4
Training loss: 1.7180500030517578
Validation loss: 1.8240974884239032
Epoch: 9| Step: 5
Training loss: 1.7458473443984985
Validation loss: 1.8311161068703632
Epoch: 9| Step: 6
Training loss: 1.8844740390777588
Validation loss: 1.9077543380449145
Epoch: 9| Step: 7
Training loss: 2.179022789001465
Validation loss: 1.8501922758363134
Epoch: 9| Step: 8
Training loss: 2.6627471446990967
Validation loss: 1.8593840015877923
Epoch: 9| Step: 9
Training loss: 2.374112129211426
Validation loss: 1.7934728577840242
Epoch: 9| Step: 10
Training loss: 2.1463871002197266
Validation loss: 1.8407175660990982
Epoch: 9| Step: 11
Training loss: 1.6821918487548828
Validation loss: 1.8724501656113768
Epoch: 9| Step: 12
Training loss: 1.797858715057373
Validation loss: 1.864184203765375
Epoch: 9| Step: 13
Training loss: 1.7889857292175293
Validation loss: 1.854183121550855
Epoch: 9| Step: 14
Training loss: 1.682413101196289
Validation loss: 1.833914600687919
Epoch: 9| Step: 15
Training loss: 2.008356809616089
Validation loss: 1.831500469351844
Epoch: 9| Step: 16
Training loss: 2.4356181621551514
Validation loss: 1.8953113761737193
Epoch: 9| Step: 17
Training loss: 1.5841245651245117
Validation loss: 1.8750820142759694
Epoch: 9| Step: 18
Training loss: 3.1523218154907227
Validation loss: 1.8538196249831496
Epoch: 9| Step: 19
Training loss: 2.4834039211273193
Validation loss: 1.8749762799242418
Epoch: 93| Step: 0
Training loss: 2.245778799057007
Validation loss: 1.8832574662544745
Epoch: 9| Step: 1
Training loss: 1.3305299282073975
Validation loss: 1.8466224807629483
Epoch: 9| Step: 2
Training loss: 1.561767578125
Validation loss: 1.8681647365899394
Epoch: 9| Step: 3
Training loss: 2.1627440452575684
Validation loss: 1.9152787409240393
Epoch: 9| Step: 4
Training loss: 1.7487999200820923
Validation loss: 1.9037409720660972
Epoch: 9| Step: 5
Training loss: 2.2707808017730713
Validation loss: 1.9017976102211493
Epoch: 9| Step: 6
Training loss: 1.877644658088684
Validation loss: 1.8857668492433837
Epoch: 9| Step: 7
Training loss: 1.6245970726013184
Validation loss: 1.8764494383077828
Epoch: 9| Step: 8
Training loss: 1.5010716915130615
Validation loss: 1.8647461597868007
Epoch: 9| Step: 9
Training loss: 1.8484258651733398
Validation loss: 1.8713525233508872
Epoch: 9| Step: 10
Training loss: 1.9150538444519043
Validation loss: 1.8778411124250014
Epoch: 9| Step: 11
Training loss: 2.074211359024048
Validation loss: 1.8488250293320032
Epoch: 9| Step: 12
Training loss: 2.1110191345214844
Validation loss: 1.8668919201377485
Epoch: 9| Step: 13
Training loss: 3.102036952972412
Validation loss: 1.903302918235175
Epoch: 9| Step: 14
Training loss: 2.6060845851898193
Validation loss: 1.8602707265949936
Epoch: 9| Step: 15
Training loss: 1.3753117322921753
Validation loss: 1.942344789882358
Epoch: 9| Step: 16
Training loss: 2.0931997299194336
Validation loss: 1.903927729284163
Epoch: 9| Step: 17
Training loss: 2.957750082015991
Validation loss: 1.843181556934933
Epoch: 9| Step: 18
Training loss: 2.236025333404541
Validation loss: 1.8391440377818595
Epoch: 9| Step: 19
Training loss: 1.7089710235595703
Validation loss: 1.837001867431531
Epoch: 94| Step: 0
Training loss: 2.0917410850524902
Validation loss: 1.8972074252238376
Epoch: 9| Step: 1
Training loss: 2.847958564758301
Validation loss: 1.8970436175092518
Epoch: 9| Step: 2
Training loss: 1.929447889328003
Validation loss: 1.8663488866613924
Epoch: 9| Step: 3
Training loss: 2.10945987701416
Validation loss: 1.8793536896328273
Epoch: 9| Step: 4
Training loss: 1.7274342775344849
Validation loss: 1.886230557942562
Epoch: 9| Step: 5
Training loss: 1.7596806287765503
Validation loss: 1.8528469929592215
Epoch: 9| Step: 6
Training loss: 2.1839921474456787
Validation loss: 1.8305697518286945
Epoch: 9| Step: 7
Training loss: 2.9085183143615723
Validation loss: 1.8411597931127754
Epoch: 9| Step: 8
Training loss: 1.7591495513916016
Validation loss: 1.89597865060079
Epoch: 9| Step: 9
Training loss: 1.3473531007766724
Validation loss: 1.8284991079097173
Epoch: 9| Step: 10
Training loss: 2.138439416885376
Validation loss: 1.8527036056244115
Epoch: 9| Step: 11
Training loss: 1.821352481842041
Validation loss: 1.8605715662455387
Epoch: 9| Step: 12
Training loss: 2.816315174102783
Validation loss: 1.8983685464310132
Epoch: 9| Step: 13
Training loss: 1.8582477569580078
Validation loss: 1.8664003790711328
Epoch: 9| Step: 14
Training loss: 1.9849941730499268
Validation loss: 1.8333221236578852
Epoch: 9| Step: 15
Training loss: 1.2035465240478516
Validation loss: 1.8593936824112487
Epoch: 9| Step: 16
Training loss: 2.6506400108337402
Validation loss: 1.8745439189801114
Epoch: 9| Step: 17
Training loss: 2.2527337074279785
Validation loss: 1.8752710201757417
Epoch: 9| Step: 18
Training loss: 1.8228743076324463
Validation loss: 1.801369689351363
Epoch: 9| Step: 19
Training loss: 1.9968914985656738
Validation loss: 1.8341982055911057
Epoch: 95| Step: 0
Training loss: 2.5025415420532227
Validation loss: 1.8109567731404477
Epoch: 9| Step: 1
Training loss: 2.3275861740112305
Validation loss: 1.8365422444377872
Epoch: 9| Step: 2
Training loss: 1.7328704595565796
Validation loss: 1.8563067664345392
Epoch: 9| Step: 3
Training loss: 2.1552419662475586
Validation loss: 1.845466739839787
Epoch: 9| Step: 4
Training loss: 2.0624613761901855
Validation loss: 1.9239898585587096
Epoch: 9| Step: 5
Training loss: 2.2459661960601807
Validation loss: 1.8303344352639837
Epoch: 9| Step: 6
Training loss: 1.9876810312271118
Validation loss: 1.8793751438744635
Epoch: 9| Step: 7
Training loss: 1.8321092128753662
Validation loss: 1.8339091693754677
Epoch: 9| Step: 8
Training loss: 2.064802646636963
Validation loss: 1.8211684364209073
Epoch: 9| Step: 9
Training loss: 1.7714879512786865
Validation loss: 1.8495442644297648
Epoch: 9| Step: 10
Training loss: 2.5681159496307373
Validation loss: 1.8419998704100684
Epoch: 9| Step: 11
Training loss: 2.351411819458008
Validation loss: 1.8104142533789436
Epoch: 9| Step: 12
Training loss: 2.1513895988464355
Validation loss: 1.8488156915568619
Epoch: 9| Step: 13
Training loss: 1.6908257007598877
Validation loss: 1.823909797256799
Epoch: 9| Step: 14
Training loss: 1.9559028148651123
Validation loss: 1.8469456288454345
Epoch: 9| Step: 15
Training loss: 2.025054693222046
Validation loss: 1.8714102000641308
Epoch: 9| Step: 16
Training loss: 1.7436389923095703
Validation loss: 1.8123541367139748
Epoch: 9| Step: 17
Training loss: 1.8486084938049316
Validation loss: 1.858620864881886
Epoch: 9| Step: 18
Training loss: 2.0854406356811523
Validation loss: 1.78361812941462
Epoch: 9| Step: 19
Training loss: 2.022695541381836
Validation loss: 1.8508445804925273
Epoch: 96| Step: 0
Training loss: 2.321002960205078
Validation loss: 1.8418243505971894
Epoch: 9| Step: 1
Training loss: 1.6392228603363037
Validation loss: 1.8240700291215086
Epoch: 9| Step: 2
Training loss: 2.2273898124694824
Validation loss: 1.8564100762922986
Epoch: 9| Step: 3
Training loss: 1.76534903049469
Validation loss: 1.8609973063571847
Epoch: 9| Step: 4
Training loss: 1.7443149089813232
Validation loss: 1.8364026340649282
Epoch: 9| Step: 5
Training loss: 1.6117441654205322
Validation loss: 1.854710478576825
Epoch: 9| Step: 6
Training loss: 2.20639705657959
Validation loss: 1.8630732014882478
Epoch: 9| Step: 7
Training loss: 2.895953416824341
Validation loss: 1.8469478663780707
Epoch: 9| Step: 8
Training loss: 1.9048420190811157
Validation loss: 1.8365845731694064
Epoch: 9| Step: 9
Training loss: 2.070955276489258
Validation loss: 1.9014579057693481
Epoch: 9| Step: 10
Training loss: 2.0301737785339355
Validation loss: 1.867667045524652
Epoch: 9| Step: 11
Training loss: 2.002387523651123
Validation loss: 1.8269051570686505
Epoch: 9| Step: 12
Training loss: 1.7621656656265259
Validation loss: 1.8584146962749015
Epoch: 9| Step: 13
Training loss: 2.5013515949249268
Validation loss: 1.8270859718322754
Epoch: 9| Step: 14
Training loss: 2.8164706230163574
Validation loss: 1.8207216142750473
Epoch: 9| Step: 15
Training loss: 1.5464704036712646
Validation loss: 1.8491771572785412
Epoch: 9| Step: 16
Training loss: 1.8539801836013794
Validation loss: 1.8679548459087345
Epoch: 9| Step: 17
Training loss: 1.908576250076294
Validation loss: 1.8553844638865629
Epoch: 9| Step: 18
Training loss: 1.9034292697906494
Validation loss: 1.8526472616538727
Epoch: 9| Step: 19
Training loss: 2.3090808391571045
Validation loss: 1.8074375811240655
Epoch: 97| Step: 0
Training loss: 2.286444902420044
Validation loss: 1.825594749382074
Epoch: 9| Step: 1
Training loss: 1.9757719039916992
Validation loss: 1.807616827299269
Epoch: 9| Step: 2
Training loss: 2.3673665523529053
Validation loss: 1.8997549041569661
Epoch: 9| Step: 3
Training loss: 1.8527623414993286
Validation loss: 1.8237651217755655
Epoch: 9| Step: 4
Training loss: 1.9008550643920898
Validation loss: 1.8997790976393996
Epoch: 9| Step: 5
Training loss: 2.0358834266662598
Validation loss: 1.915929144234966
Epoch: 9| Step: 6
Training loss: 2.9992120265960693
Validation loss: 1.886845589541703
Epoch: 9| Step: 7
Training loss: 2.204456329345703
Validation loss: 1.8795376878848178
Epoch: 9| Step: 8
Training loss: 1.8077627420425415
Validation loss: 1.8068464471281862
Epoch: 9| Step: 9
Training loss: 1.8157391548156738
Validation loss: 1.8785733044576303
Epoch: 9| Step: 10
Training loss: 2.1647400856018066
Validation loss: 1.89201938505653
Epoch: 9| Step: 11
Training loss: 2.359389543533325
Validation loss: 1.8980430235965646
Epoch: 9| Step: 12
Training loss: 2.3690738677978516
Validation loss: 1.9086392208826628
Epoch: 9| Step: 13
Training loss: 1.6720566749572754
Validation loss: 1.879072050396487
Epoch: 9| Step: 14
Training loss: 2.8865725994110107
Validation loss: 1.8894385836964889
Epoch: 9| Step: 15
Training loss: 1.507925033569336
Validation loss: 1.8459008571912916
Epoch: 9| Step: 16
Training loss: 1.4350780248641968
Validation loss: 1.933858947788211
Epoch: 9| Step: 17
Training loss: 1.9921107292175293
Validation loss: 1.8902541459035531
Epoch: 9| Step: 18
Training loss: 2.043893575668335
Validation loss: 1.875510557092351
Epoch: 9| Step: 19
Training loss: 1.8522874116897583
Validation loss: 1.832514301478434
Epoch: 98| Step: 0
Training loss: 1.812182903289795
Validation loss: 1.8444227288952835
Epoch: 9| Step: 1
Training loss: 1.5168169736862183
Validation loss: 1.8625142634343759
Epoch: 9| Step: 2
Training loss: 1.9732400178909302
Validation loss: 1.8779942457624477
Epoch: 9| Step: 3
Training loss: 2.566371440887451
Validation loss: 1.829920967705816
Epoch: 9| Step: 4
Training loss: 3.0831706523895264
Validation loss: 1.8411499699242682
Epoch: 9| Step: 5
Training loss: 2.0571045875549316
Validation loss: 1.8875546884193695
Epoch: 9| Step: 6
Training loss: 1.8383499383926392
Validation loss: 1.8830649981395804
Epoch: 9| Step: 7
Training loss: 1.786329984664917
Validation loss: 1.8746150697735573
Epoch: 9| Step: 8
Training loss: 2.1179447174072266
Validation loss: 1.8388259016352593
Epoch: 9| Step: 9
Training loss: 1.8690481185913086
Validation loss: 1.828742176508732
Epoch: 9| Step: 10
Training loss: 2.143528938293457
Validation loss: 1.8606396699123244
Epoch: 9| Step: 11
Training loss: 2.1847004890441895
Validation loss: 1.8416421773622362
Epoch: 9| Step: 12
Training loss: 2.5611586570739746
Validation loss: 1.8296767876302595
Epoch: 9| Step: 13
Training loss: 1.507521390914917
Validation loss: 1.8086097540615274
Epoch: 9| Step: 14
Training loss: 1.6397271156311035
Validation loss: 1.7719141742308362
Epoch: 9| Step: 15
Training loss: 2.1713624000549316
Validation loss: 1.8206751706788866
Epoch: 9| Step: 16
Training loss: 1.5431313514709473
Validation loss: 1.815389118606238
Epoch: 9| Step: 17
Training loss: 1.3183636665344238
Validation loss: 1.8686863767157356
Epoch: 9| Step: 18
Training loss: 2.106355667114258
Validation loss: 1.7683171394059984
Epoch: 9| Step: 19
Training loss: 3.3403701782226562
Validation loss: 1.8779098918969683
Epoch: 99| Step: 0
Training loss: 1.7130104303359985
Validation loss: 1.8359193784727468
Epoch: 9| Step: 1
Training loss: 2.1962387561798096
Validation loss: 1.815388159786197
Epoch: 9| Step: 2
Training loss: 2.0620360374450684
Validation loss: 1.8481902338617997
Epoch: 9| Step: 3
Training loss: 1.8774168491363525
Validation loss: 1.8158206133533725
Epoch: 9| Step: 4
Training loss: 2.3704888820648193
Validation loss: 1.85790471550372
Epoch: 9| Step: 5
Training loss: 2.4315667152404785
Validation loss: 1.8666282266163998
Epoch: 9| Step: 6
Training loss: 2.6063177585601807
Validation loss: 1.8257781035608525
Epoch: 9| Step: 7
Training loss: 1.9243009090423584
Validation loss: 1.8159805107459748
Epoch: 9| Step: 8
Training loss: 2.12027645111084
Validation loss: 1.845520614720077
Epoch: 9| Step: 9
Training loss: 1.7718428373336792
Validation loss: 1.8372867416134842
Epoch: 9| Step: 10
Training loss: 1.667529582977295
Validation loss: 1.8681105864133767
Epoch: 9| Step: 11
Training loss: 1.75130033493042
Validation loss: 1.9137077022799485
Epoch: 9| Step: 12
Training loss: 2.900200128555298
Validation loss: 1.8576875907911672
Epoch: 9| Step: 13
Training loss: 1.6093863248825073
Validation loss: 1.86311949414315
Epoch: 9| Step: 14
Training loss: 2.267246961593628
Validation loss: 1.8594162592784964
Epoch: 9| Step: 15
Training loss: 2.113186836242676
Validation loss: 1.9248922994668536
Epoch: 9| Step: 16
Training loss: 1.9408855438232422
Validation loss: 1.8332013500680169
Epoch: 9| Step: 17
Training loss: 1.9031116962432861
Validation loss: 1.8645695490802792
Epoch: 9| Step: 18
Training loss: 1.672640323638916
Validation loss: 1.88776772999935
Epoch: 9| Step: 19
Training loss: 2.0473692417144775
Validation loss: 1.8651079754177615
Epoch: 100| Step: 0
Training loss: 1.914060354232788
Validation loss: 1.8388577425222603
Epoch: 9| Step: 1
Training loss: 1.5241186618804932
Validation loss: 1.8571161820734148
Epoch: 9| Step: 2
Training loss: 1.4161978960037231
Validation loss: 1.8326273410440348
Epoch: 9| Step: 3
Training loss: 2.2265756130218506
Validation loss: 1.817411468183394
Epoch: 9| Step: 4
Training loss: 1.8595221042633057
Validation loss: 1.8329921334767514
Epoch: 9| Step: 5
Training loss: 2.3723273277282715
Validation loss: 1.8789752816124785
Epoch: 9| Step: 6
Training loss: 1.8859268426895142
Validation loss: 1.8153652655992576
Epoch: 9| Step: 7
Training loss: 2.2970075607299805
Validation loss: 1.8430644419553468
Epoch: 9| Step: 8
Training loss: 2.9579224586486816
Validation loss: 1.7864850973911424
Epoch: 9| Step: 9
Training loss: 1.9777748584747314
Validation loss: 1.842688105946822
Epoch: 9| Step: 10
Training loss: 2.653866767883301
Validation loss: 1.9133407709409864
Epoch: 9| Step: 11
Training loss: 2.1878323554992676
Validation loss: 1.8244621367763272
Epoch: 9| Step: 12
Training loss: 1.888587474822998
Validation loss: 1.8059826789142417
Epoch: 9| Step: 13
Training loss: 1.2359187602996826
Validation loss: 1.8249023303711156
Epoch: 9| Step: 14
Training loss: 2.271091938018799
Validation loss: 1.8788656476590273
Epoch: 9| Step: 15
Training loss: 2.376511335372925
Validation loss: 1.800163924265251
Epoch: 9| Step: 16
Training loss: 2.121222496032715
Validation loss: 1.8255333634589215
Epoch: 9| Step: 17
Training loss: 2.2329578399658203
Validation loss: 1.8374538713221928
Epoch: 9| Step: 18
Training loss: 1.8024193048477173
Validation loss: 1.8222879617334269
Epoch: 9| Step: 19
Training loss: 1.8982057571411133
Validation loss: 1.8131615249373072
