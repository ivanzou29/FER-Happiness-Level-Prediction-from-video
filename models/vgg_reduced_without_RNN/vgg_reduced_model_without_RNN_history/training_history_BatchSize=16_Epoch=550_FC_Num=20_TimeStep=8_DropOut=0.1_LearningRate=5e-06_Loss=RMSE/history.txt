Epoch: 1| Step: 0
Training loss: 3.8342191805964245
Validation loss: 3.65597670096104

Epoch: 6| Step: 1
Training loss: 3.7276958925286934
Validation loss: 3.6398707360242084

Epoch: 6| Step: 2
Training loss: 3.55400115712608
Validation loss: 3.626880618322275

Epoch: 6| Step: 3
Training loss: 3.4420867835923676
Validation loss: 3.6074381333807284

Epoch: 6| Step: 4
Training loss: 3.753407519631042
Validation loss: 3.592253000028107

Epoch: 6| Step: 5
Training loss: 4.072190450070516
Validation loss: 3.5763440759972545

Epoch: 6| Step: 6
Training loss: 3.7902306712467735
Validation loss: 3.556685024084202

Epoch: 6| Step: 7
Training loss: 3.156424791387256
Validation loss: 3.5453165582482606

Epoch: 6| Step: 8
Training loss: 4.000200266593107
Validation loss: 3.5288367788680284

Epoch: 6| Step: 9
Training loss: 3.508185080131537
Validation loss: 3.51078368097437

Epoch: 6| Step: 10
Training loss: 2.77489551313111
Validation loss: 3.495771249000824

Epoch: 6| Step: 11
Training loss: 4.242487157421197
Validation loss: 3.4822832794194953

Epoch: 6| Step: 12
Training loss: 3.9157491921521026
Validation loss: 3.4659507155820655

Epoch: 6| Step: 13
Training loss: 3.57640520769036
Validation loss: 3.4463458828968014

Epoch: 2| Step: 0
Training loss: 3.483369417018867
Validation loss: 3.431092967068866

Epoch: 6| Step: 1
Training loss: 3.964372999686035
Validation loss: 3.406443785775034

Epoch: 6| Step: 2
Training loss: 3.063433135201834
Validation loss: 3.3928387705943663

Epoch: 6| Step: 3
Training loss: 3.3254327764878875
Validation loss: 3.3710878209326784

Epoch: 6| Step: 4
Training loss: 3.9896775808066876
Validation loss: 3.345766974361561

Epoch: 6| Step: 5
Training loss: 3.9978897965830122
Validation loss: 3.323408052630545

Epoch: 6| Step: 6
Training loss: 3.2855710596653287
Validation loss: 3.29824440284134

Epoch: 6| Step: 7
Training loss: 3.673008780244863
Validation loss: 3.2781574389486394

Epoch: 6| Step: 8
Training loss: 3.1121951402022083
Validation loss: 3.2468936698114907

Epoch: 6| Step: 9
Training loss: 3.0007510834488316
Validation loss: 3.222334745148786

Epoch: 6| Step: 10
Training loss: 3.1802630079417358
Validation loss: 3.189826141490695

Epoch: 6| Step: 11
Training loss: 3.273051746736737
Validation loss: 3.163363168299047

Epoch: 6| Step: 12
Training loss: 3.131935967327937
Validation loss: 3.129061221612001

Epoch: 6| Step: 13
Training loss: 2.951807929316321
Validation loss: 3.0974804514467444

Epoch: 3| Step: 0
Training loss: 2.904647056950579
Validation loss: 3.0645796144118433

Epoch: 6| Step: 1
Training loss: 2.943818297677146
Validation loss: 3.021230202398117

Epoch: 6| Step: 2
Training loss: 2.98275585090793
Validation loss: 2.9937321831605055

Epoch: 6| Step: 3
Training loss: 3.0756082072862534
Validation loss: 2.9580595982307694

Epoch: 6| Step: 4
Training loss: 3.0591293781875644
Validation loss: 2.915783698535421

Epoch: 6| Step: 5
Training loss: 3.6814138327444748
Validation loss: 2.8776691872455977

Epoch: 6| Step: 6
Training loss: 2.8748009654270525
Validation loss: 2.8415136381841513

Epoch: 6| Step: 7
Training loss: 2.7790378817144883
Validation loss: 2.799868326269982

Epoch: 6| Step: 8
Training loss: 2.66146446471183
Validation loss: 2.772076239550759

Epoch: 6| Step: 9
Training loss: 2.279408900785728
Validation loss: 2.72616915338514

Epoch: 6| Step: 10
Training loss: 2.0305519665246994
Validation loss: 2.6816793292189

Epoch: 6| Step: 11
Training loss: 3.2236035243671037
Validation loss: 2.6574976814429765

Epoch: 6| Step: 12
Training loss: 3.0636949348870774
Validation loss: 2.624935285587967

Epoch: 6| Step: 13
Training loss: 2.91074737075337
Validation loss: 2.600622700436031

Epoch: 4| Step: 0
Training loss: 2.8267718708355853
Validation loss: 2.573525489301925

Epoch: 6| Step: 1
Training loss: 1.7554709882259318
Validation loss: 2.5408156226085024

Epoch: 6| Step: 2
Training loss: 2.3488912523478915
Validation loss: 2.5412451806298706

Epoch: 6| Step: 3
Training loss: 2.4464588342411813
Validation loss: 2.536539320596038

Epoch: 6| Step: 4
Training loss: 2.476242477967855
Validation loss: 2.526455769892379

Epoch: 6| Step: 5
Training loss: 2.2912641229522035
Validation loss: 2.5360779578233292

Epoch: 6| Step: 6
Training loss: 3.435561587251756
Validation loss: 2.5479988317791364

Epoch: 6| Step: 7
Training loss: 1.8822568334647198
Validation loss: 2.5605768725250306

Epoch: 6| Step: 8
Training loss: 2.929310522621228
Validation loss: 2.560871661373486

Epoch: 6| Step: 9
Training loss: 2.4533009071211276
Validation loss: 2.57635832857262

Epoch: 6| Step: 10
Training loss: 2.700812436542533
Validation loss: 2.572465066749835

Epoch: 6| Step: 11
Training loss: 2.8193327240088197
Validation loss: 2.5876427566535543

Epoch: 6| Step: 12
Training loss: 2.950180280963444
Validation loss: 2.594471015449219

Epoch: 6| Step: 13
Training loss: 2.2452420684874843
Validation loss: 2.6059982165986537

Epoch: 5| Step: 0
Training loss: 2.4805691916487405
Validation loss: 2.586121981860062

Epoch: 6| Step: 1
Training loss: 2.669307166371754
Validation loss: 2.5741969692792597

Epoch: 6| Step: 2
Training loss: 2.769109997907536
Validation loss: 2.5659659756550157

Epoch: 6| Step: 3
Training loss: 2.064815031177387
Validation loss: 2.5812672356622004

Epoch: 6| Step: 4
Training loss: 2.528270899237105
Validation loss: 2.5507103606845476

Epoch: 6| Step: 5
Training loss: 2.8346946662220973
Validation loss: 2.5415707606580793

Epoch: 6| Step: 6
Training loss: 3.0361797713178587
Validation loss: 2.55275221382802

Epoch: 6| Step: 7
Training loss: 3.3461432047842523
Validation loss: 2.548304649958366

Epoch: 6| Step: 8
Training loss: 2.9937214318427507
Validation loss: 2.539653392406413

Epoch: 6| Step: 9
Training loss: 2.1130867408463905
Validation loss: 2.5241931614493325

Epoch: 6| Step: 10
Training loss: 2.0347665717535954
Validation loss: 2.5262198211664253

Epoch: 6| Step: 11
Training loss: 1.7776646586364548
Validation loss: 2.5240349628205325

Epoch: 6| Step: 12
Training loss: 2.129697991930949
Validation loss: 2.5242758382884234

Epoch: 6| Step: 13
Training loss: 2.291134570221917
Validation loss: 2.512700199103172

Epoch: 6| Step: 0
Training loss: 2.5977957551825606
Validation loss: 2.519423103475793

Epoch: 6| Step: 1
Training loss: 1.7007520751133003
Validation loss: 2.5129148839776514

Epoch: 6| Step: 2
Training loss: 2.1604635009790143
Validation loss: 2.4973496693682584

Epoch: 6| Step: 3
Training loss: 2.3089091284024614
Validation loss: 2.493689249010978

Epoch: 6| Step: 4
Training loss: 2.3330078125
Validation loss: 2.5082593145464633

Epoch: 6| Step: 5
Training loss: 2.5893543177945064
Validation loss: 2.511423808529939

Epoch: 6| Step: 6
Training loss: 2.111819285131708
Validation loss: 2.521421526759192

Epoch: 6| Step: 7
Training loss: 3.4001433903246
Validation loss: 2.5313791940630574

Epoch: 6| Step: 8
Training loss: 2.879984142736649
Validation loss: 2.5013557890342923

Epoch: 6| Step: 9
Training loss: 2.3119186495424207
Validation loss: 2.5092860850998258

Epoch: 6| Step: 10
Training loss: 2.2972655710325087
Validation loss: 2.529975083395553

Epoch: 6| Step: 11
Training loss: 2.3858117410808832
Validation loss: 2.5058330991402573

Epoch: 6| Step: 12
Training loss: 2.773035068596988
Validation loss: 2.507927263115711

Epoch: 6| Step: 13
Training loss: 2.7969808718286737
Validation loss: 2.519272523355906

Epoch: 7| Step: 0
Training loss: 2.245775495455583
Validation loss: 2.513960143274341

Epoch: 6| Step: 1
Training loss: 3.0073939440919504
Validation loss: 2.5243688071429093

Epoch: 6| Step: 2
Training loss: 2.2987444270088715
Validation loss: 2.513497268236157

Epoch: 6| Step: 3
Training loss: 2.4120981069448346
Validation loss: 2.532845516252429

Epoch: 6| Step: 4
Training loss: 2.7522060042558696
Validation loss: 2.524013433879623

Epoch: 6| Step: 5
Training loss: 2.218565597393172
Validation loss: 2.5399734662639992

Epoch: 6| Step: 6
Training loss: 2.582782399486202
Validation loss: 2.5327772078035005

Epoch: 6| Step: 7
Training loss: 3.0761064601179675
Validation loss: 2.5487885103033787

Epoch: 6| Step: 8
Training loss: 1.9888004007432676
Validation loss: 2.538696606999775

Epoch: 6| Step: 9
Training loss: 2.4782900395702585
Validation loss: 2.5722607125225965

Epoch: 6| Step: 10
Training loss: 2.951118877750477
Validation loss: 2.5365684584589574

Epoch: 6| Step: 11
Training loss: 2.2781764188178157
Validation loss: 2.525785882852956

Epoch: 6| Step: 12
Training loss: 2.5321489786369615
Validation loss: 2.5183831174092313

Epoch: 6| Step: 13
Training loss: 2.1593652970666026
Validation loss: 2.527173515612271

Epoch: 8| Step: 0
Training loss: 2.780688196940156
Validation loss: 2.524999050731921

Epoch: 6| Step: 1
Training loss: 2.1553269774161037
Validation loss: 2.510903233482445

Epoch: 6| Step: 2
Training loss: 2.787928075379853
Validation loss: 2.5308193578282934

Epoch: 6| Step: 3
Training loss: 2.604046709476756
Validation loss: 2.50107123947825

Epoch: 6| Step: 4
Training loss: 2.2124305240046214
Validation loss: 2.506653324693655

Epoch: 6| Step: 5
Training loss: 2.8534659943386687
Validation loss: 2.5044233053112195

Epoch: 6| Step: 6
Training loss: 2.5951341359892854
Validation loss: 2.5127239835990958

Epoch: 6| Step: 7
Training loss: 1.5875663473126882
Validation loss: 2.49186176654691

Epoch: 6| Step: 8
Training loss: 2.395764181272453
Validation loss: 2.5085811367963244

Epoch: 6| Step: 9
Training loss: 2.2687415424956425
Validation loss: 2.5089108447567177

Epoch: 6| Step: 10
Training loss: 2.4277449812469443
Validation loss: 2.491593739602285

Epoch: 6| Step: 11
Training loss: 2.549055979398726
Validation loss: 2.5056270215127907

Epoch: 6| Step: 12
Training loss: 2.7749562577932676
Validation loss: 2.510507753442399

Epoch: 6| Step: 13
Training loss: 2.6709070069560883
Validation loss: 2.5020890726303695

Epoch: 9| Step: 0
Training loss: 2.2495983613015036
Validation loss: 2.5066804162706866

Epoch: 6| Step: 1
Training loss: 2.6543588525807746
Validation loss: 2.5170592253457227

Epoch: 6| Step: 2
Training loss: 2.2291327381820074
Validation loss: 2.509378437500686

Epoch: 6| Step: 3
Training loss: 2.3226493601820324
Validation loss: 2.5125935851803507

Epoch: 6| Step: 4
Training loss: 2.57818363007434
Validation loss: 2.510253494679179

Epoch: 6| Step: 5
Training loss: 2.613235267953084
Validation loss: 2.4947748575195132

Epoch: 6| Step: 6
Training loss: 2.382999800527983
Validation loss: 2.5201260281136513

Epoch: 6| Step: 7
Training loss: 2.262928482705668
Validation loss: 2.495834886383779

Epoch: 6| Step: 8
Training loss: 2.3268447530554712
Validation loss: 2.5034443334494854

Epoch: 6| Step: 9
Training loss: 2.5451560743398476
Validation loss: 2.510684578134612

Epoch: 6| Step: 10
Training loss: 3.816466472544934
Validation loss: 2.501803875853313

Epoch: 6| Step: 11
Training loss: 1.8252751234473215
Validation loss: 2.508671598554121

Epoch: 6| Step: 12
Training loss: 2.183014548909822
Validation loss: 2.510473089784405

Epoch: 6| Step: 13
Training loss: 2.4212511797396457
Validation loss: 2.502571436535342

Epoch: 10| Step: 0
Training loss: 2.140202612866617
Validation loss: 2.4836715326071683

Epoch: 6| Step: 1
Training loss: 2.7134104945328157
Validation loss: 2.498913051825188

Epoch: 6| Step: 2
Training loss: 2.5194131513019307
Validation loss: 2.4898334414784706

Epoch: 6| Step: 3
Training loss: 2.3894574674024627
Validation loss: 2.5126396298555163

Epoch: 6| Step: 4
Training loss: 2.6459983914371135
Validation loss: 2.498894097182494

Epoch: 6| Step: 5
Training loss: 2.4911449009402222
Validation loss: 2.4949010189250385

Epoch: 6| Step: 6
Training loss: 2.185183142836503
Validation loss: 2.488710598955449

Epoch: 6| Step: 7
Training loss: 2.3298088998972175
Validation loss: 2.497752116820217

Epoch: 6| Step: 8
Training loss: 2.384266894128366
Validation loss: 2.4889677129858088

Epoch: 6| Step: 9
Training loss: 2.3504962721784737
Validation loss: 2.4884055848649735

Epoch: 6| Step: 10
Training loss: 2.424647755946723
Validation loss: 2.500208957204674

Epoch: 6| Step: 11
Training loss: 3.040164698606528
Validation loss: 2.4878153941273373

Epoch: 6| Step: 12
Training loss: 2.3916354568341367
Validation loss: 2.4757878228105628

Epoch: 6| Step: 13
Training loss: 2.7879202076947354
Validation loss: 2.5078235122898387

Epoch: 11| Step: 0
Training loss: 2.7588734085557522
Validation loss: 2.499807143719942

Epoch: 6| Step: 1
Training loss: 2.051113021898373
Validation loss: 2.4891984128593165

Epoch: 6| Step: 2
Training loss: 2.512914583532851
Validation loss: 2.497898426471849

Epoch: 6| Step: 3
Training loss: 1.5218765478106702
Validation loss: 2.493619947619544

Epoch: 6| Step: 4
Training loss: 2.126616143889091
Validation loss: 2.5029394194490293

Epoch: 6| Step: 5
Training loss: 2.281245610481115
Validation loss: 2.503058057279612

Epoch: 6| Step: 6
Training loss: 3.112430164212461
Validation loss: 2.4931662619641197

Epoch: 6| Step: 7
Training loss: 2.731386218831405
Validation loss: 2.502908874020343

Epoch: 6| Step: 8
Training loss: 2.5683379313803014
Validation loss: 2.51021034268714

Epoch: 6| Step: 9
Training loss: 2.543381805391319
Validation loss: 2.502792586829541

Epoch: 6| Step: 10
Training loss: 3.2975386543697995
Validation loss: 2.498904019765058

Epoch: 6| Step: 11
Training loss: 1.7875256329812625
Validation loss: 2.51378923175282

Epoch: 6| Step: 12
Training loss: 2.8900995550200768
Validation loss: 2.490399635166926

Epoch: 6| Step: 13
Training loss: 1.7710984050351333
Validation loss: 2.5150689957914496

Epoch: 12| Step: 0
Training loss: 3.0492350510189117
Validation loss: 2.4888905687931993

Epoch: 6| Step: 1
Training loss: 2.052082339317223
Validation loss: 2.485730343316844

Epoch: 6| Step: 2
Training loss: 2.6238138152745027
Validation loss: 2.480540020737293

Epoch: 6| Step: 3
Training loss: 2.671123019579963
Validation loss: 2.4773670578390177

Epoch: 6| Step: 4
Training loss: 1.9135472441044987
Validation loss: 2.480193892341708

Epoch: 6| Step: 5
Training loss: 1.6742392961929748
Validation loss: 2.4923963867787196

Epoch: 6| Step: 6
Training loss: 2.257979548521316
Validation loss: 2.499944948543953

Epoch: 6| Step: 7
Training loss: 2.6720591699136325
Validation loss: 2.484834576530469

Epoch: 6| Step: 8
Training loss: 2.3525123072108705
Validation loss: 2.48930720203839

Epoch: 6| Step: 9
Training loss: 3.116090203758387
Validation loss: 2.4840957516650497

Epoch: 6| Step: 10
Training loss: 2.0676026081053256
Validation loss: 2.5035435993696824

Epoch: 6| Step: 11
Training loss: 2.366796480119933
Validation loss: 2.493351081739926

Epoch: 6| Step: 12
Training loss: 2.936535940850917
Validation loss: 2.4985156182439745

Epoch: 6| Step: 13
Training loss: 2.4107956988599937
Validation loss: 2.4872635497360838

Epoch: 13| Step: 0
Training loss: 1.5242292645285804
Validation loss: 2.483839893093413

Epoch: 6| Step: 1
Training loss: 2.9457780788766548
Validation loss: 2.4886556889591374

Epoch: 6| Step: 2
Training loss: 2.0753689035850993
Validation loss: 2.4902012961191473

Epoch: 6| Step: 3
Training loss: 2.002791959359935
Validation loss: 2.474203990317702

Epoch: 6| Step: 4
Training loss: 2.9040422154765624
Validation loss: 2.4752081407822457

Epoch: 6| Step: 5
Training loss: 2.5759199480566912
Validation loss: 2.459729143211105

Epoch: 6| Step: 6
Training loss: 2.576568503572353
Validation loss: 2.4799852355522667

Epoch: 6| Step: 7
Training loss: 2.389064903083426
Validation loss: 2.49514971548279

Epoch: 6| Step: 8
Training loss: 2.4262797017075277
Validation loss: 2.483671892586173

Epoch: 6| Step: 9
Training loss: 2.9284176935656365
Validation loss: 2.478017898817181

Epoch: 6| Step: 10
Training loss: 2.4571385686146265
Validation loss: 2.4788667406583804

Epoch: 6| Step: 11
Training loss: 2.5139085114370676
Validation loss: 2.480814767968168

Epoch: 6| Step: 12
Training loss: 2.61175163903326
Validation loss: 2.464870865839442

Epoch: 6| Step: 13
Training loss: 2.369958043109336
Validation loss: 2.477067865741029

Epoch: 14| Step: 0
Training loss: 2.5362920582585033
Validation loss: 2.467698738548613

Epoch: 6| Step: 1
Training loss: 1.8517033004341557
Validation loss: 2.4780414790108956

Epoch: 6| Step: 2
Training loss: 2.3432941247726653
Validation loss: 2.50126696907323

Epoch: 6| Step: 3
Training loss: 1.7965500911032621
Validation loss: 2.497045599146666

Epoch: 6| Step: 4
Training loss: 2.4624181743523703
Validation loss: 2.507080573427612

Epoch: 6| Step: 5
Training loss: 2.5011190770784646
Validation loss: 2.501207258871923

Epoch: 6| Step: 6
Training loss: 3.3231131915072254
Validation loss: 2.5157563074566047

Epoch: 6| Step: 7
Training loss: 2.5051670084272435
Validation loss: 2.493133253860231

Epoch: 6| Step: 8
Training loss: 3.00416307876803
Validation loss: 2.4940119555568394

Epoch: 6| Step: 9
Training loss: 2.6947512719589928
Validation loss: 2.482472208884894

Epoch: 6| Step: 10
Training loss: 2.3291905160227704
Validation loss: 2.4956443354182976

Epoch: 6| Step: 11
Training loss: 2.091576772128452
Validation loss: 2.480803916093835

Epoch: 6| Step: 12
Training loss: 2.442146762696066
Validation loss: 2.492153753452763

Epoch: 6| Step: 13
Training loss: 2.32422336609967
Validation loss: 2.4787732675049945

Epoch: 15| Step: 0
Training loss: 2.0081565948004956
Validation loss: 2.4773632804672574

Epoch: 6| Step: 1
Training loss: 2.6129951263393965
Validation loss: 2.47819939878882

Epoch: 6| Step: 2
Training loss: 2.624661015012336
Validation loss: 2.4837731326106995

Epoch: 6| Step: 3
Training loss: 2.387591163532498
Validation loss: 2.479193844900033

Epoch: 6| Step: 4
Training loss: 2.014748197776972
Validation loss: 2.472500443132269

Epoch: 6| Step: 5
Training loss: 2.73582916829581
Validation loss: 2.4904871673927325

Epoch: 6| Step: 6
Training loss: 2.4118472308210848
Validation loss: 2.478211857482983

Epoch: 6| Step: 7
Training loss: 2.5551703227207367
Validation loss: 2.4897374433970794

Epoch: 6| Step: 8
Training loss: 2.855625884067852
Validation loss: 2.480583881099212

Epoch: 6| Step: 9
Training loss: 2.510234673156844
Validation loss: 2.4736035597886628

Epoch: 6| Step: 10
Training loss: 2.6579664182414473
Validation loss: 2.483872128821167

Epoch: 6| Step: 11
Training loss: 2.23128931347489
Validation loss: 2.479438804201038

Epoch: 6| Step: 12
Training loss: 2.2291311338450774
Validation loss: 2.4801010620254984

Epoch: 6| Step: 13
Training loss: 2.389483110564929
Validation loss: 2.4689215266520375

Epoch: 16| Step: 0
Training loss: 2.2109037470852804
Validation loss: 2.473672072596885

Epoch: 6| Step: 1
Training loss: 3.048869414358468
Validation loss: 2.4760976649975754

Epoch: 6| Step: 2
Training loss: 2.859955608850376
Validation loss: 2.470200591314224

Epoch: 6| Step: 3
Training loss: 2.17550662925515
Validation loss: 2.471420614128417

Epoch: 6| Step: 4
Training loss: 2.384227095150032
Validation loss: 2.4672169331491496

Epoch: 6| Step: 5
Training loss: 2.209065645782005
Validation loss: 2.4675901722559836

Epoch: 6| Step: 6
Training loss: 2.553735024683247
Validation loss: 2.466305830591507

Epoch: 6| Step: 7
Training loss: 2.2613311066429103
Validation loss: 2.466466096722502

Epoch: 6| Step: 8
Training loss: 2.78515625
Validation loss: 2.468332649718539

Epoch: 6| Step: 9
Training loss: 3.0663246095322245
Validation loss: 2.4744435580729305

Epoch: 6| Step: 10
Training loss: 2.23382881798255
Validation loss: 2.4574977510738854

Epoch: 6| Step: 11
Training loss: 2.1605627081081735
Validation loss: 2.483682883920006

Epoch: 6| Step: 12
Training loss: 2.0945656169958884
Validation loss: 2.4746443643883818

Epoch: 6| Step: 13
Training loss: 2.0450848621024713
Validation loss: 2.4748580073074744

Epoch: 17| Step: 0
Training loss: 2.500282653088829
Validation loss: 2.4699750025896137

Epoch: 6| Step: 1
Training loss: 2.3267592962384045
Validation loss: 2.466258671135151

Epoch: 6| Step: 2
Training loss: 2.3941067541822654
Validation loss: 2.4733538615290818

Epoch: 6| Step: 3
Training loss: 2.002447299906744
Validation loss: 2.4711557247668905

Epoch: 6| Step: 4
Training loss: 2.908312978008343
Validation loss: 2.462221567514006

Epoch: 6| Step: 5
Training loss: 2.5425553461913166
Validation loss: 2.4768283031475775

Epoch: 6| Step: 6
Training loss: 2.1307511761098263
Validation loss: 2.4715941901801375

Epoch: 6| Step: 7
Training loss: 2.6375014210195467
Validation loss: 2.456738347888799

Epoch: 6| Step: 8
Training loss: 2.881901625553884
Validation loss: 2.475707491185957

Epoch: 6| Step: 9
Training loss: 2.6946735896393292
Validation loss: 2.4548150495434076

Epoch: 6| Step: 10
Training loss: 1.8678263445234673
Validation loss: 2.481767241457688

Epoch: 6| Step: 11
Training loss: 2.7123489443297824
Validation loss: 2.469143703309711

Epoch: 6| Step: 12
Training loss: 2.442717811766714
Validation loss: 2.464850907836774

Epoch: 6| Step: 13
Training loss: 1.9810264148366417
Validation loss: 2.4608828664699693

Epoch: 18| Step: 0
Training loss: 2.6066366663553597
Validation loss: 2.459413458181338

Epoch: 6| Step: 1
Training loss: 2.443615601885418
Validation loss: 2.4736166841945257

Epoch: 6| Step: 2
Training loss: 2.809213201257539
Validation loss: 2.461236400718439

Epoch: 6| Step: 3
Training loss: 2.359671567757752
Validation loss: 2.4611464638774536

Epoch: 6| Step: 4
Training loss: 2.178471160921922
Validation loss: 2.4724781038493107

Epoch: 6| Step: 5
Training loss: 2.867937618742353
Validation loss: 2.4720844734644056

Epoch: 6| Step: 6
Training loss: 2.2897541967012605
Validation loss: 2.4766637257968833

Epoch: 6| Step: 7
Training loss: 1.5541561886568012
Validation loss: 2.477674280831424

Epoch: 6| Step: 8
Training loss: 1.5391696950693015
Validation loss: 2.4838945895970737

Epoch: 6| Step: 9
Training loss: 2.6499800339432467
Validation loss: 2.474295877551999

Epoch: 6| Step: 10
Training loss: 2.843194928335498
Validation loss: 2.4900018720607027

Epoch: 6| Step: 11
Training loss: 1.9217201728793822
Validation loss: 2.4923243310689323

Epoch: 6| Step: 12
Training loss: 2.3488830306225617
Validation loss: 2.4952766143568876

Epoch: 6| Step: 13
Training loss: 3.3007555356801634
Validation loss: 2.492433852692567

Epoch: 19| Step: 0
Training loss: 2.617003294881832
Validation loss: 2.4857152366740762

Epoch: 6| Step: 1
Training loss: 1.9950931078951009
Validation loss: 2.473295541956138

Epoch: 6| Step: 2
Training loss: 2.7683053686515917
Validation loss: 2.466249076403551

Epoch: 6| Step: 3
Training loss: 1.98526293495306
Validation loss: 2.468867335368026

Epoch: 6| Step: 4
Training loss: 2.355069507779889
Validation loss: 2.454112208614389

Epoch: 6| Step: 5
Training loss: 2.7388796948254317
Validation loss: 2.460170719237029

Epoch: 6| Step: 6
Training loss: 2.2045640506692967
Validation loss: 2.450019028323751

Epoch: 6| Step: 7
Training loss: 2.781912306889172
Validation loss: 2.470246549494464

Epoch: 6| Step: 8
Training loss: 3.021858374659379
Validation loss: 2.4535675783471538

Epoch: 6| Step: 9
Training loss: 2.3624106576970454
Validation loss: 2.461208106608385

Epoch: 6| Step: 10
Training loss: 2.6295051062665453
Validation loss: 2.4665413163098395

Epoch: 6| Step: 11
Training loss: 1.981957652793427
Validation loss: 2.469740793537344

Epoch: 6| Step: 12
Training loss: 2.76747138679689
Validation loss: 2.466697853982361

Epoch: 6| Step: 13
Training loss: 2.0502847706321274
Validation loss: 2.454031450813628

Epoch: 20| Step: 0
Training loss: 2.3917205893079014
Validation loss: 2.4382978176999197

Epoch: 6| Step: 1
Training loss: 2.885717897264522
Validation loss: 2.45814528527301

Epoch: 6| Step: 2
Training loss: 2.301708921707111
Validation loss: 2.44099416281286

Epoch: 6| Step: 3
Training loss: 2.289188733054134
Validation loss: 2.4661654693455555

Epoch: 6| Step: 4
Training loss: 2.2748238966975727
Validation loss: 2.4632668022605584

Epoch: 6| Step: 5
Training loss: 2.027756959410567
Validation loss: 2.446482239467016

Epoch: 6| Step: 6
Training loss: 1.8930330940170976
Validation loss: 2.4718157568646983

Epoch: 6| Step: 7
Training loss: 2.0498873842522314
Validation loss: 2.4844846241434837

Epoch: 6| Step: 8
Training loss: 2.1179982564989213
Validation loss: 2.4833368335502928

Epoch: 6| Step: 9
Training loss: 2.6594612008994143
Validation loss: 2.4754958558355766

Epoch: 6| Step: 10
Training loss: 2.627740972994634
Validation loss: 2.486869487374456

Epoch: 6| Step: 11
Training loss: 2.6855462535510646
Validation loss: 2.4690874569260077

Epoch: 6| Step: 12
Training loss: 2.4647446988814203
Validation loss: 2.505635791456227

Epoch: 6| Step: 13
Training loss: 3.060745515201433
Validation loss: 2.487173731251701

Epoch: 21| Step: 0
Training loss: 2.0479966213675285
Validation loss: 2.480871036778228

Epoch: 6| Step: 1
Training loss: 2.4803352380099386
Validation loss: 2.4837894989338856

Epoch: 6| Step: 2
Training loss: 2.2658086241927107
Validation loss: 2.4606910541800042

Epoch: 6| Step: 3
Training loss: 2.7203241811432504
Validation loss: 2.469567368800493

Epoch: 6| Step: 4
Training loss: 1.9848059238906646
Validation loss: 2.4485297280837943

Epoch: 6| Step: 5
Training loss: 2.7136884907095316
Validation loss: 2.4664893604252467

Epoch: 6| Step: 6
Training loss: 2.83244811048393
Validation loss: 2.473157015408397

Epoch: 6| Step: 7
Training loss: 2.539952706024333
Validation loss: 2.4839357191666425

Epoch: 6| Step: 8
Training loss: 2.907401728326426
Validation loss: 2.464856211715931

Epoch: 6| Step: 9
Training loss: 3.071607476787208
Validation loss: 2.458326385509781

Epoch: 6| Step: 10
Training loss: 2.00988923370182
Validation loss: 2.4477676562685233

Epoch: 6| Step: 11
Training loss: 1.8243325175520437
Validation loss: 2.4567687314345106

Epoch: 6| Step: 12
Training loss: 1.9712524253428747
Validation loss: 2.4412166918598173

Epoch: 6| Step: 13
Training loss: 2.3940791688096534
Validation loss: 2.4420267603379338

Epoch: 22| Step: 0
Training loss: 2.2809536885163832
Validation loss: 2.4610271215518975

Epoch: 6| Step: 1
Training loss: 1.8925018452644171
Validation loss: 2.461084617778798

Epoch: 6| Step: 2
Training loss: 2.1997591103539507
Validation loss: 2.4454450479969547

Epoch: 6| Step: 3
Training loss: 2.2491907147816437
Validation loss: 2.4465489293266707

Epoch: 6| Step: 4
Training loss: 2.0377649146732173
Validation loss: 2.444670262767448

Epoch: 6| Step: 5
Training loss: 2.5276141957974185
Validation loss: 2.466989251470944

Epoch: 6| Step: 6
Training loss: 2.531360011594712
Validation loss: 2.4485746486855877

Epoch: 6| Step: 7
Training loss: 2.4810191587594788
Validation loss: 2.444928448858127

Epoch: 6| Step: 8
Training loss: 2.483915946343055
Validation loss: 2.4396522996526953

Epoch: 6| Step: 9
Training loss: 2.9430544669334466
Validation loss: 2.461401896583783

Epoch: 6| Step: 10
Training loss: 2.9131818570782135
Validation loss: 2.473422702561096

Epoch: 6| Step: 11
Training loss: 2.4271815093216897
Validation loss: 2.454199375480809

Epoch: 6| Step: 12
Training loss: 2.435936255023435
Validation loss: 2.4684770650526446

Epoch: 6| Step: 13
Training loss: 2.2875363206325035
Validation loss: 2.4623724896357673

Epoch: 23| Step: 0
Training loss: 2.346615273317464
Validation loss: 2.468459856713068

Epoch: 6| Step: 1
Training loss: 2.330674995915233
Validation loss: 2.482820500368353

Epoch: 6| Step: 2
Training loss: 2.643351304312666
Validation loss: 2.4800053040898935

Epoch: 6| Step: 3
Training loss: 2.0758498508199996
Validation loss: 2.4720285109971405

Epoch: 6| Step: 4
Training loss: 2.4686804652984344
Validation loss: 2.449730583869984

Epoch: 6| Step: 5
Training loss: 2.431038336868571
Validation loss: 2.4645531790902138

Epoch: 6| Step: 6
Training loss: 1.901203416884434
Validation loss: 2.4645274463636224

Epoch: 6| Step: 7
Training loss: 2.829538908690074
Validation loss: 2.448067101800356

Epoch: 6| Step: 8
Training loss: 2.724446784743271
Validation loss: 2.472028093062129

Epoch: 6| Step: 9
Training loss: 2.1163853325695507
Validation loss: 2.454821330144898

Epoch: 6| Step: 10
Training loss: 2.8733628628917898
Validation loss: 2.4612794345886426

Epoch: 6| Step: 11
Training loss: 2.1169496522303324
Validation loss: 2.4654800875278755

Epoch: 6| Step: 12
Training loss: 2.3087172628497137
Validation loss: 2.441737868103028

Epoch: 6| Step: 13
Training loss: 2.6661866073834037
Validation loss: 2.442952952442139

Epoch: 24| Step: 0
Training loss: 2.370412511859359
Validation loss: 2.444772126409987

Epoch: 6| Step: 1
Training loss: 2.077772870740802
Validation loss: 2.4489904010273578

Epoch: 6| Step: 2
Training loss: 2.2546206817983205
Validation loss: 2.461646261533115

Epoch: 6| Step: 3
Training loss: 1.9319812563032364
Validation loss: 2.456035903646486

Epoch: 6| Step: 4
Training loss: 2.919386186229171
Validation loss: 2.46137184467888

Epoch: 6| Step: 5
Training loss: 2.2440753923966668
Validation loss: 2.465903351144086

Epoch: 6| Step: 6
Training loss: 3.050960677142004
Validation loss: 2.452162859676907

Epoch: 6| Step: 7
Training loss: 2.425011357546293
Validation loss: 2.4565719797899135

Epoch: 6| Step: 8
Training loss: 1.508418460502139
Validation loss: 2.476432419819418

Epoch: 6| Step: 9
Training loss: 1.9897314752147042
Validation loss: 2.4555723774690024

Epoch: 6| Step: 10
Training loss: 2.7336822504161367
Validation loss: 2.446408035522285

Epoch: 6| Step: 11
Training loss: 2.5577299800324576
Validation loss: 2.459437289452924

Epoch: 6| Step: 12
Training loss: 3.2077204791888305
Validation loss: 2.4581852857547695

Epoch: 6| Step: 13
Training loss: 2.095307297668143
Validation loss: 2.4530889099446815

Epoch: 25| Step: 0
Training loss: 2.5881156852313194
Validation loss: 2.4511593275015002

Epoch: 6| Step: 1
Training loss: 2.2035985126672455
Validation loss: 2.4568681688067375

Epoch: 6| Step: 2
Training loss: 1.8649778179659744
Validation loss: 2.4596196112352957

Epoch: 6| Step: 3
Training loss: 3.235542713140961
Validation loss: 2.438301378546146

Epoch: 6| Step: 4
Training loss: 2.957014479394319
Validation loss: 2.4439658620055726

Epoch: 6| Step: 5
Training loss: 2.70375362429506
Validation loss: 2.4617968476761254

Epoch: 6| Step: 6
Training loss: 2.1609303637736357
Validation loss: 2.4472392720891323

Epoch: 6| Step: 7
Training loss: 2.362687974344333
Validation loss: 2.4398698453375958

Epoch: 6| Step: 8
Training loss: 2.511517506275075
Validation loss: 2.4477459273077327

Epoch: 6| Step: 9
Training loss: 2.1429275047012846
Validation loss: 2.442046449264801

Epoch: 6| Step: 10
Training loss: 2.0456215318276865
Validation loss: 2.444380610046738

Epoch: 6| Step: 11
Training loss: 2.302406345910611
Validation loss: 2.4505169199886283

Epoch: 6| Step: 12
Training loss: 2.0751738280137855
Validation loss: 2.48314681174083

Epoch: 6| Step: 13
Training loss: 2.29988699925683
Validation loss: 2.461245030155463

Epoch: 26| Step: 0
Training loss: 1.8839999051752088
Validation loss: 2.4649919323276555

Epoch: 6| Step: 1
Training loss: 2.4486077381538025
Validation loss: 2.4600337715466973

Epoch: 6| Step: 2
Training loss: 2.666332094741205
Validation loss: 2.4578727085881638

Epoch: 6| Step: 3
Training loss: 2.958009263318809
Validation loss: 2.4543652487064804

Epoch: 6| Step: 4
Training loss: 1.4200583789806442
Validation loss: 2.4653565185281723

Epoch: 6| Step: 5
Training loss: 2.7760998479437253
Validation loss: 2.4810501818908928

Epoch: 6| Step: 6
Training loss: 2.3294305405112223
Validation loss: 2.4768732880733944

Epoch: 6| Step: 7
Training loss: 2.7299803377498404
Validation loss: 2.4690347338304015

Epoch: 6| Step: 8
Training loss: 2.3375561059756373
Validation loss: 2.4815093653595235

Epoch: 6| Step: 9
Training loss: 2.270279831464191
Validation loss: 2.470041613170343

Epoch: 6| Step: 10
Training loss: 1.7244814936573116
Validation loss: 2.455055659557284

Epoch: 6| Step: 11
Training loss: 2.696947392523093
Validation loss: 2.467189472657523

Epoch: 6| Step: 12
Training loss: 2.876671015211983
Validation loss: 2.4499156230228496

Epoch: 6| Step: 13
Training loss: 2.056954761072572
Validation loss: 2.4579985816326557

Epoch: 27| Step: 0
Training loss: 2.1196160271039557
Validation loss: 2.440119989941622

Epoch: 6| Step: 1
Training loss: 2.430861995694996
Validation loss: 2.440548596100012

Epoch: 6| Step: 2
Training loss: 2.0440164654809476
Validation loss: 2.4562532924795044

Epoch: 6| Step: 3
Training loss: 2.289647362889473
Validation loss: 2.446614561678142

Epoch: 6| Step: 4
Training loss: 2.3400815610446806
Validation loss: 2.4431504349040436

Epoch: 6| Step: 5
Training loss: 2.37753421698656
Validation loss: 2.42801099793532

Epoch: 6| Step: 6
Training loss: 2.629235256970936
Validation loss: 2.445137870817494

Epoch: 6| Step: 7
Training loss: 2.747542844096387
Validation loss: 2.439887312321971

Epoch: 6| Step: 8
Training loss: 2.5529962476858916
Validation loss: 2.4488227844585713

Epoch: 6| Step: 9
Training loss: 2.5810820296272166
Validation loss: 2.444390965247599

Epoch: 6| Step: 10
Training loss: 2.0653087102572707
Validation loss: 2.4381398314900347

Epoch: 6| Step: 11
Training loss: 2.5090032584821844
Validation loss: 2.4661469558557507

Epoch: 6| Step: 12
Training loss: 2.530775897048722
Validation loss: 2.458334378603266

Epoch: 6| Step: 13
Training loss: 2.368504123457866
Validation loss: 2.441572129781369

Epoch: 28| Step: 0
Training loss: 2.2467920959203234
Validation loss: 2.4510462917463114

Epoch: 6| Step: 1
Training loss: 2.527987037166727
Validation loss: 2.443342819178106

Epoch: 6| Step: 2
Training loss: 1.9290911413229708
Validation loss: 2.4356602793021125

Epoch: 6| Step: 3
Training loss: 2.124436920960502
Validation loss: 2.454350839471181

Epoch: 6| Step: 4
Training loss: 3.056428457093357
Validation loss: 2.463545846969144

Epoch: 6| Step: 5
Training loss: 2.720964253553547
Validation loss: 2.48067659723737

Epoch: 6| Step: 6
Training loss: 2.0563371077525723
Validation loss: 2.455464229808162

Epoch: 6| Step: 7
Training loss: 2.2343553662271116
Validation loss: 2.458871060629638

Epoch: 6| Step: 8
Training loss: 2.6429570300693443
Validation loss: 2.464878676500043

Epoch: 6| Step: 9
Training loss: 2.2688314964432528
Validation loss: 2.4528873595771157

Epoch: 6| Step: 10
Training loss: 1.7282280116912487
Validation loss: 2.46686618895818

Epoch: 6| Step: 11
Training loss: 2.584353050867532
Validation loss: 2.4561056183627485

Epoch: 6| Step: 12
Training loss: 2.3539773195352223
Validation loss: 2.4701086241277395

Epoch: 6| Step: 13
Training loss: 2.764777446985537
Validation loss: 2.442021358059172

Epoch: 29| Step: 0
Training loss: 1.9427091651348825
Validation loss: 2.450471483653232

Epoch: 6| Step: 1
Training loss: 1.6340288805936496
Validation loss: 2.455335799285468

Epoch: 6| Step: 2
Training loss: 2.23351714198646
Validation loss: 2.4489275826671166

Epoch: 6| Step: 3
Training loss: 2.61946111961209
Validation loss: 2.448782720290396

Epoch: 6| Step: 4
Training loss: 2.266424419510394
Validation loss: 2.4548318679221257

Epoch: 6| Step: 5
Training loss: 1.815409134393977
Validation loss: 2.4496314975082463

Epoch: 6| Step: 6
Training loss: 2.816125863730365
Validation loss: 2.464483348616565

Epoch: 6| Step: 7
Training loss: 2.3903429450900138
Validation loss: 2.4608450413042275

Epoch: 6| Step: 8
Training loss: 3.0850770161071344
Validation loss: 2.472360570182127

Epoch: 6| Step: 9
Training loss: 2.7041650436075177
Validation loss: 2.4537941491820288

Epoch: 6| Step: 10
Training loss: 2.5789109390340967
Validation loss: 2.4327380051964465

Epoch: 6| Step: 11
Training loss: 2.6108428116070423
Validation loss: 2.4441089694937346

Epoch: 6| Step: 12
Training loss: 2.3001396178286933
Validation loss: 2.459118674531815

Epoch: 6| Step: 13
Training loss: 2.2194890685270967
Validation loss: 2.4558967595172208

Epoch: 30| Step: 0
Training loss: 2.337503884052171
Validation loss: 2.439426443352633

Epoch: 6| Step: 1
Training loss: 2.70077694911024
Validation loss: 2.432573393380671

Epoch: 6| Step: 2
Training loss: 2.6636849860246143
Validation loss: 2.438410499257373

Epoch: 6| Step: 3
Training loss: 2.3442732163384448
Validation loss: 2.4512621048611076

Epoch: 6| Step: 4
Training loss: 1.9896710827501989
Validation loss: 2.4251089510743413

Epoch: 6| Step: 5
Training loss: 2.8213028371018445
Validation loss: 2.4622545381384713

Epoch: 6| Step: 6
Training loss: 1.6984375308825534
Validation loss: 2.446932774848647

Epoch: 6| Step: 7
Training loss: 2.678869361656841
Validation loss: 2.447774993909139

Epoch: 6| Step: 8
Training loss: 2.134529512545844
Validation loss: 2.4438693954816895

Epoch: 6| Step: 9
Training loss: 2.547716715451057
Validation loss: 2.4334822741959488

Epoch: 6| Step: 10
Training loss: 2.59625573515316
Validation loss: 2.4357818514638234

Epoch: 6| Step: 11
Training loss: 1.4375771211585708
Validation loss: 2.445857327574791

Epoch: 6| Step: 12
Training loss: 2.2889766742122757
Validation loss: 2.4326024125859145

Epoch: 6| Step: 13
Training loss: 3.0400252594651307
Validation loss: 2.4370605039926794

Epoch: 31| Step: 0
Training loss: 2.133590835686631
Validation loss: 2.455279252769634

Epoch: 6| Step: 1
Training loss: 2.4491638469474304
Validation loss: 2.457039570756417

Epoch: 6| Step: 2
Training loss: 2.823199456233607
Validation loss: 2.4541485831647423

Epoch: 6| Step: 3
Training loss: 2.719626099188042
Validation loss: 2.4582400438959358

Epoch: 6| Step: 4
Training loss: 2.7716299264766247
Validation loss: 2.4790506629624383

Epoch: 6| Step: 5
Training loss: 2.149207403776337
Validation loss: 2.4455010419640706

Epoch: 6| Step: 6
Training loss: 2.1430244085334325
Validation loss: 2.462431277689377

Epoch: 6| Step: 7
Training loss: 2.1097116837424226
Validation loss: 2.4505616420113996

Epoch: 6| Step: 8
Training loss: 2.356195391520504
Validation loss: 2.4519684124260817

Epoch: 6| Step: 9
Training loss: 2.541600106623728
Validation loss: 2.4516620363735906

Epoch: 6| Step: 10
Training loss: 1.9047139341978152
Validation loss: 2.4426020508983313

Epoch: 6| Step: 11
Training loss: 2.634125424619054
Validation loss: 2.45025674421876

Epoch: 6| Step: 12
Training loss: 2.1339468262616132
Validation loss: 2.444554374912988

Epoch: 6| Step: 13
Training loss: 2.304699500101174
Validation loss: 2.452369687049659

Epoch: 32| Step: 0
Training loss: 1.9644647008919287
Validation loss: 2.4373682345126824

Epoch: 6| Step: 1
Training loss: 1.854028403738437
Validation loss: 2.4472902240414984

Epoch: 6| Step: 2
Training loss: 2.2961830602035143
Validation loss: 2.454924731139864

Epoch: 6| Step: 3
Training loss: 2.6515845221985734
Validation loss: 2.4603314011604147

Epoch: 6| Step: 4
Training loss: 2.8638374236011304
Validation loss: 2.4427675810720544

Epoch: 6| Step: 5
Training loss: 2.4997449744801896
Validation loss: 2.4548774420737423

Epoch: 6| Step: 6
Training loss: 2.959904714545631
Validation loss: 2.4451778403225277

Epoch: 6| Step: 7
Training loss: 2.576205562113901
Validation loss: 2.4567876148169656

Epoch: 6| Step: 8
Training loss: 2.793475509233044
Validation loss: 2.443792908951167

Epoch: 6| Step: 9
Training loss: 1.9884404866245446
Validation loss: 2.4580767761667897

Epoch: 6| Step: 10
Training loss: 1.892587258205678
Validation loss: 2.4352641651538

Epoch: 6| Step: 11
Training loss: 2.5414682112797147
Validation loss: 2.444438221470782

Epoch: 6| Step: 12
Training loss: 2.177228846698761
Validation loss: 2.436705027650984

Epoch: 6| Step: 13
Training loss: 2.0294261079819558
Validation loss: 2.4343969286158287

Epoch: 33| Step: 0
Training loss: 2.480188741423668
Validation loss: 2.436525785945762

Epoch: 6| Step: 1
Training loss: 1.6321577739838833
Validation loss: 2.4495541040301316

Epoch: 6| Step: 2
Training loss: 2.660649504563277
Validation loss: 2.453499265333923

Epoch: 6| Step: 3
Training loss: 1.6339063858801166
Validation loss: 2.434053560254336

Epoch: 6| Step: 4
Training loss: 2.533656730421922
Validation loss: 2.4487983955351043

Epoch: 6| Step: 5
Training loss: 2.418666165892617
Validation loss: 2.440162883257008

Epoch: 6| Step: 6
Training loss: 2.5182199303747907
Validation loss: 2.4429414444062156

Epoch: 6| Step: 7
Training loss: 3.05070075442981
Validation loss: 2.434742468153556

Epoch: 6| Step: 8
Training loss: 1.9411130871853992
Validation loss: 2.454819946147754

Epoch: 6| Step: 9
Training loss: 2.6078403551409375
Validation loss: 2.4395026758565925

Epoch: 6| Step: 10
Training loss: 2.0042444728200786
Validation loss: 2.454603765926385

Epoch: 6| Step: 11
Training loss: 2.7961883554497597
Validation loss: 2.438798916976402

Epoch: 6| Step: 12
Training loss: 2.488164255215358
Validation loss: 2.4457782874555196

Epoch: 6| Step: 13
Training loss: 2.1879531391014315
Validation loss: 2.4492878070122504

Epoch: 34| Step: 0
Training loss: 1.9912402126074116
Validation loss: 2.44134733001819

Epoch: 6| Step: 1
Training loss: 2.32144373794464
Validation loss: 2.4585064379851067

Epoch: 6| Step: 2
Training loss: 2.595471282088758
Validation loss: 2.4604223448849067

Epoch: 6| Step: 3
Training loss: 1.5235026810224659
Validation loss: 2.4385352748269438

Epoch: 6| Step: 4
Training loss: 2.055685634907592
Validation loss: 2.4481147253116133

Epoch: 6| Step: 5
Training loss: 2.0138991900067307
Validation loss: 2.4525674400947035

Epoch: 6| Step: 6
Training loss: 2.2998588021101543
Validation loss: 2.4624420572296146

Epoch: 6| Step: 7
Training loss: 2.948068316078284
Validation loss: 2.4505749546821503

Epoch: 6| Step: 8
Training loss: 3.017872975582791
Validation loss: 2.462375894636813

Epoch: 6| Step: 9
Training loss: 2.7298733521872283
Validation loss: 2.4720178536322828

Epoch: 6| Step: 10
Training loss: 2.2691243474990173
Validation loss: 2.4720531529634755

Epoch: 6| Step: 11
Training loss: 2.5547441482096165
Validation loss: 2.472199054733288

Epoch: 6| Step: 12
Training loss: 2.607407976320635
Validation loss: 2.4844533240169664

Epoch: 6| Step: 13
Training loss: 1.8635972112996266
Validation loss: 2.4611487565367867

Epoch: 35| Step: 0
Training loss: 2.8789423574101027
Validation loss: 2.4448662575155646

Epoch: 6| Step: 1
Training loss: 2.61048427006122
Validation loss: 2.4254808224509867

Epoch: 6| Step: 2
Training loss: 2.8468007920744753
Validation loss: 2.4267650171757573

Epoch: 6| Step: 3
Training loss: 2.1018502984933565
Validation loss: 2.434426219892669

Epoch: 6| Step: 4
Training loss: 2.464392183898409
Validation loss: 2.443182865946399

Epoch: 6| Step: 5
Training loss: 2.5784708426888754
Validation loss: 2.4304307984319977

Epoch: 6| Step: 6
Training loss: 2.5441013515304634
Validation loss: 2.4589422382423853

Epoch: 6| Step: 7
Training loss: 2.2611286665130534
Validation loss: 2.460763688988529

Epoch: 6| Step: 8
Training loss: 2.6457667204714124
Validation loss: 2.447644049432135

Epoch: 6| Step: 9
Training loss: 1.572412557429805
Validation loss: 2.447899649270069

Epoch: 6| Step: 10
Training loss: 2.20967394844467
Validation loss: 2.4485233339715955

Epoch: 6| Step: 11
Training loss: 2.155890393332074
Validation loss: 2.416859007996956

Epoch: 6| Step: 12
Training loss: 1.9515483137948288
Validation loss: 2.433449044372287

Epoch: 6| Step: 13
Training loss: 2.7430581995526113
Validation loss: 2.43134912584596

Epoch: 36| Step: 0
Training loss: 1.9488549514119993
Validation loss: 2.455609256301993

Epoch: 6| Step: 1
Training loss: 2.507476879252886
Validation loss: 2.447415805195848

Epoch: 6| Step: 2
Training loss: 2.5676119917204887
Validation loss: 2.465423467447394

Epoch: 6| Step: 3
Training loss: 2.454006935538865
Validation loss: 2.468814688048323

Epoch: 6| Step: 4
Training loss: 2.7843564290841303
Validation loss: 2.51574851260046

Epoch: 6| Step: 5
Training loss: 2.24411278982139
Validation loss: 2.5279356053677606

Epoch: 6| Step: 6
Training loss: 2.1754443799893495
Validation loss: 2.523593901677769

Epoch: 6| Step: 7
Training loss: 2.706614100254285
Validation loss: 2.511677735242479

Epoch: 6| Step: 8
Training loss: 2.5479518743428584
Validation loss: 2.49789528465081

Epoch: 6| Step: 9
Training loss: 1.8311377585322892
Validation loss: 2.488671592066125

Epoch: 6| Step: 10
Training loss: 2.5820162912648197
Validation loss: 2.4691856096536475

Epoch: 6| Step: 11
Training loss: 2.586030987205039
Validation loss: 2.479095479333184

Epoch: 6| Step: 12
Training loss: 2.019863433376065
Validation loss: 2.4473437565465788

Epoch: 6| Step: 13
Training loss: 2.374884452016752
Validation loss: 2.469457999646239

Epoch: 37| Step: 0
Training loss: 2.89493482816138
Validation loss: 2.433687178694556

Epoch: 6| Step: 1
Training loss: 1.8845992731396781
Validation loss: 2.4520540754786904

Epoch: 6| Step: 2
Training loss: 1.9045716698767263
Validation loss: 2.442835307667707

Epoch: 6| Step: 3
Training loss: 2.4980589961040467
Validation loss: 2.4316952537109517

Epoch: 6| Step: 4
Training loss: 2.248779071579656
Validation loss: 2.4380132998718382

Epoch: 6| Step: 5
Training loss: 1.987176854476573
Validation loss: 2.424377207075247

Epoch: 6| Step: 6
Training loss: 2.8565279435163666
Validation loss: 2.4254228098789943

Epoch: 6| Step: 7
Training loss: 2.5947934545150675
Validation loss: 2.4364587972726715

Epoch: 6| Step: 8
Training loss: 2.263764768707109
Validation loss: 2.43154283605244

Epoch: 6| Step: 9
Training loss: 2.2452499264125727
Validation loss: 2.445336956190312

Epoch: 6| Step: 10
Training loss: 2.2230292947463135
Validation loss: 2.4255348772545196

Epoch: 6| Step: 11
Training loss: 2.365219859575608
Validation loss: 2.43186531713985

Epoch: 6| Step: 12
Training loss: 2.297075016369482
Validation loss: 2.441903692811956

Epoch: 6| Step: 13
Training loss: 2.5885227338276326
Validation loss: 2.437927893225544

Epoch: 38| Step: 0
Training loss: 2.321339595053676
Validation loss: 2.441860675481722

Epoch: 6| Step: 1
Training loss: 2.5126666568881943
Validation loss: 2.44895465568765

Epoch: 6| Step: 2
Training loss: 2.1230112755395614
Validation loss: 2.434922102244175

Epoch: 6| Step: 3
Training loss: 2.6057605494220057
Validation loss: 2.4544850363664774

Epoch: 6| Step: 4
Training loss: 1.8591586716413184
Validation loss: 2.4547744680531314

Epoch: 6| Step: 5
Training loss: 2.645580990589968
Validation loss: 2.4642785135075767

Epoch: 6| Step: 6
Training loss: 2.61881672266627
Validation loss: 2.4282548448300965

Epoch: 6| Step: 7
Training loss: 2.698289018266693
Validation loss: 2.4366194202219154

Epoch: 6| Step: 8
Training loss: 2.345871740628678
Validation loss: 2.441812466205623

Epoch: 6| Step: 9
Training loss: 1.9541287703862356
Validation loss: 2.465592920878713

Epoch: 6| Step: 10
Training loss: 2.3685765990549728
Validation loss: 2.4586508244169916

Epoch: 6| Step: 11
Training loss: 2.1910163954204496
Validation loss: 2.4640532373074033

Epoch: 6| Step: 12
Training loss: 1.9668022087502155
Validation loss: 2.4631858606376844

Epoch: 6| Step: 13
Training loss: 2.660453611718306
Validation loss: 2.449307234776472

Epoch: 39| Step: 0
Training loss: 2.5044704521691954
Validation loss: 2.455209660249874

Epoch: 6| Step: 1
Training loss: 3.075249272609309
Validation loss: 2.4561523256302764

Epoch: 6| Step: 2
Training loss: 2.5868951689511546
Validation loss: 2.426249976337478

Epoch: 6| Step: 3
Training loss: 1.4315945772725418
Validation loss: 2.435814935269099

Epoch: 6| Step: 4
Training loss: 2.0916302326975655
Validation loss: 2.4533234777157578

Epoch: 6| Step: 5
Training loss: 2.2897657544464227
Validation loss: 2.4262023822318124

Epoch: 6| Step: 6
Training loss: 2.640369470636124
Validation loss: 2.4454129394443913

Epoch: 6| Step: 7
Training loss: 2.1575730176396193
Validation loss: 2.4452366842555993

Epoch: 6| Step: 8
Training loss: 2.6506901616040883
Validation loss: 2.442310379461223

Epoch: 6| Step: 9
Training loss: 1.7788479319224522
Validation loss: 2.460062357795778

Epoch: 6| Step: 10
Training loss: 2.3493744565451142
Validation loss: 2.4460023794508325

Epoch: 6| Step: 11
Training loss: 1.5237575879428311
Validation loss: 2.4371792182793066

Epoch: 6| Step: 12
Training loss: 2.554347397683361
Validation loss: 2.4608658714567557

Epoch: 6| Step: 13
Training loss: 2.7738757149949542
Validation loss: 2.4435051199391884

Epoch: 40| Step: 0
Training loss: 2.6107369711738118
Validation loss: 2.4766067436750783

Epoch: 6| Step: 1
Training loss: 2.3004234048636105
Validation loss: 2.4442995551065327

Epoch: 6| Step: 2
Training loss: 2.8508296495146386
Validation loss: 2.441036007082303

Epoch: 6| Step: 3
Training loss: 2.2838261311520114
Validation loss: 2.4448065513631243

Epoch: 6| Step: 4
Training loss: 2.173708683650073
Validation loss: 2.4410457253336233

Epoch: 6| Step: 5
Training loss: 2.035210138292072
Validation loss: 2.4370807711041627

Epoch: 6| Step: 6
Training loss: 2.639579611165695
Validation loss: 2.452120046629752

Epoch: 6| Step: 7
Training loss: 2.008345596254933
Validation loss: 2.4380109610082976

Epoch: 6| Step: 8
Training loss: 2.4562775588491537
Validation loss: 2.43582545739109

Epoch: 6| Step: 9
Training loss: 1.9602467813639324
Validation loss: 2.443893687259008

Epoch: 6| Step: 10
Training loss: 2.7635190025077954
Validation loss: 2.4340993030564078

Epoch: 6| Step: 11
Training loss: 2.308326150582313
Validation loss: 2.423075306740091

Epoch: 6| Step: 12
Training loss: 2.1874506263610463
Validation loss: 2.432907187257246

Epoch: 6| Step: 13
Training loss: 2.0175606356635485
Validation loss: 2.441649100877332

Epoch: 41| Step: 0
Training loss: 1.8037105409531913
Validation loss: 2.427948152311663

Epoch: 6| Step: 1
Training loss: 2.506540992187025
Validation loss: 2.429773024579879

Epoch: 6| Step: 2
Training loss: 2.3061784479883736
Validation loss: 2.44700930938488

Epoch: 6| Step: 3
Training loss: 1.7409432248713173
Validation loss: 2.4636706801674144

Epoch: 6| Step: 4
Training loss: 2.217563043018611
Validation loss: 2.4652180576404006

Epoch: 6| Step: 5
Training loss: 2.8030178019801752
Validation loss: 2.4756417312705152

Epoch: 6| Step: 6
Training loss: 1.7351149621522965
Validation loss: 2.488991708301564

Epoch: 6| Step: 7
Training loss: 2.9024544819261715
Validation loss: 2.4887954763450044

Epoch: 6| Step: 8
Training loss: 2.214243758810533
Validation loss: 2.4853611314510657

Epoch: 6| Step: 9
Training loss: 2.5972681659118644
Validation loss: 2.4572310454903774

Epoch: 6| Step: 10
Training loss: 2.34860702786002
Validation loss: 2.4444669291396584

Epoch: 6| Step: 11
Training loss: 2.711536000610167
Validation loss: 2.44795892286691

Epoch: 6| Step: 12
Training loss: 2.3060956370893084
Validation loss: 2.4508641995956486

Epoch: 6| Step: 13
Training loss: 2.5497945889784703
Validation loss: 2.4312394920716964

Epoch: 42| Step: 0
Training loss: 2.4822132614203194
Validation loss: 2.4352933236229513

Epoch: 6| Step: 1
Training loss: 3.1138348823043542
Validation loss: 2.444029856573856

Epoch: 6| Step: 2
Training loss: 1.9375932732557466
Validation loss: 2.430526048995857

Epoch: 6| Step: 3
Training loss: 2.899286932260443
Validation loss: 2.422599241194271

Epoch: 6| Step: 4
Training loss: 2.063403307457976
Validation loss: 2.426531402853698

Epoch: 6| Step: 5
Training loss: 1.66237070828535
Validation loss: 2.434562257706729

Epoch: 6| Step: 6
Training loss: 2.089817282250618
Validation loss: 2.4261019664153647

Epoch: 6| Step: 7
Training loss: 2.4561776769342574
Validation loss: 2.4325052748881353

Epoch: 6| Step: 8
Training loss: 2.3386023385405115
Validation loss: 2.4276763344391985

Epoch: 6| Step: 9
Training loss: 1.4342147770905693
Validation loss: 2.44867318550064

Epoch: 6| Step: 10
Training loss: 2.444575286985499
Validation loss: 2.4533855680506074

Epoch: 6| Step: 11
Training loss: 2.777382379577082
Validation loss: 2.457412156507406

Epoch: 6| Step: 12
Training loss: 2.2253448904814275
Validation loss: 2.4549258318158196

Epoch: 6| Step: 13
Training loss: 2.461734703155127
Validation loss: 2.436028916929585

Epoch: 43| Step: 0
Training loss: 2.384261294312279
Validation loss: 2.4381993912442907

Epoch: 6| Step: 1
Training loss: 2.1489554595804776
Validation loss: 2.4580469503458167

Epoch: 6| Step: 2
Training loss: 2.475358351379234
Validation loss: 2.441045595106056

Epoch: 6| Step: 3
Training loss: 2.359664191907776
Validation loss: 2.439941650537185

Epoch: 6| Step: 4
Training loss: 2.356403020043705
Validation loss: 2.4381075452414294

Epoch: 6| Step: 5
Training loss: 1.7834928346173953
Validation loss: 2.433379203111479

Epoch: 6| Step: 6
Training loss: 3.109019656939127
Validation loss: 2.4565659543860607

Epoch: 6| Step: 7
Training loss: 1.7979561911519184
Validation loss: 2.4414088053372045

Epoch: 6| Step: 8
Training loss: 2.087016537354499
Validation loss: 2.4411330250758825

Epoch: 6| Step: 9
Training loss: 2.5409062191209806
Validation loss: 2.4564333432325967

Epoch: 6| Step: 10
Training loss: 2.409013919516159
Validation loss: 2.4361364349050407

Epoch: 6| Step: 11
Training loss: 2.0631446986744426
Validation loss: 2.4470918172018816

Epoch: 6| Step: 12
Training loss: 2.739196885463245
Validation loss: 2.4547640514355584

Epoch: 6| Step: 13
Training loss: 2.1675456416022607
Validation loss: 2.4342482224091913

Epoch: 44| Step: 0
Training loss: 2.0016660903222587
Validation loss: 2.421425545938785

Epoch: 6| Step: 1
Training loss: 2.666854514022541
Validation loss: 2.4536035641909577

Epoch: 6| Step: 2
Training loss: 2.6556530449962676
Validation loss: 2.425724800833152

Epoch: 6| Step: 3
Training loss: 1.417822291689536
Validation loss: 2.4371426475256275

Epoch: 6| Step: 4
Training loss: 1.9100535234471472
Validation loss: 2.4438559487246923

Epoch: 6| Step: 5
Training loss: 2.657760280519994
Validation loss: 2.4454902364956714

Epoch: 6| Step: 6
Training loss: 2.564764929218832
Validation loss: 2.437175818836484

Epoch: 6| Step: 7
Training loss: 2.406637779795125
Validation loss: 2.449719667291218

Epoch: 6| Step: 8
Training loss: 2.5575951877156156
Validation loss: 2.4741924509735185

Epoch: 6| Step: 9
Training loss: 2.106921202798877
Validation loss: 2.4406669127919085

Epoch: 6| Step: 10
Training loss: 2.800407523062858
Validation loss: 2.4426156509699686

Epoch: 6| Step: 11
Training loss: 2.628112310317676
Validation loss: 2.4567625285958425

Epoch: 6| Step: 12
Training loss: 1.9263274557593093
Validation loss: 2.4361638050283934

Epoch: 6| Step: 13
Training loss: 2.070830888446104
Validation loss: 2.4336035224632613

Epoch: 45| Step: 0
Training loss: 2.2784485010350566
Validation loss: 2.41954320408454

Epoch: 6| Step: 1
Training loss: 2.7794953715681645
Validation loss: 2.451818827124109

Epoch: 6| Step: 2
Training loss: 2.380287909203566
Validation loss: 2.4169494173009753

Epoch: 6| Step: 3
Training loss: 2.2459300636687494
Validation loss: 2.433918955195217

Epoch: 6| Step: 4
Training loss: 2.7475509141781114
Validation loss: 2.434332346185453

Epoch: 6| Step: 5
Training loss: 2.3782258462263797
Validation loss: 2.4242706427683833

Epoch: 6| Step: 6
Training loss: 2.0477634278170247
Validation loss: 2.423371113356294

Epoch: 6| Step: 7
Training loss: 2.4424420654235464
Validation loss: 2.4224642949315687

Epoch: 6| Step: 8
Training loss: 2.2328814870268916
Validation loss: 2.417547153248417

Epoch: 6| Step: 9
Training loss: 2.0356507972626336
Validation loss: 2.436119471146223

Epoch: 6| Step: 10
Training loss: 2.363225359295198
Validation loss: 2.437399479024127

Epoch: 6| Step: 11
Training loss: 2.322572987767726
Validation loss: 2.4478320627945784

Epoch: 6| Step: 12
Training loss: 2.189349128642159
Validation loss: 2.4360739457057394

Epoch: 6| Step: 13
Training loss: 2.0052425100873648
Validation loss: 2.4530687750915137

Epoch: 46| Step: 0
Training loss: 2.0723424783993405
Validation loss: 2.4642561077527145

Epoch: 6| Step: 1
Training loss: 2.520011725928258
Validation loss: 2.4534720966972405

Epoch: 6| Step: 2
Training loss: 2.6916969707031075
Validation loss: 2.4673913766360096

Epoch: 6| Step: 3
Training loss: 2.0176249200466283
Validation loss: 2.474344786860763

Epoch: 6| Step: 4
Training loss: 2.6173997479817377
Validation loss: 2.462840512093843

Epoch: 6| Step: 5
Training loss: 1.8748369781832188
Validation loss: 2.465844952047894

Epoch: 6| Step: 6
Training loss: 1.9300003724764925
Validation loss: 2.466067405884974

Epoch: 6| Step: 7
Training loss: 1.8503668421383987
Validation loss: 2.4621396635382298

Epoch: 6| Step: 8
Training loss: 2.100447688747345
Validation loss: 2.485165484244459

Epoch: 6| Step: 9
Training loss: 2.579803013193749
Validation loss: 2.471740697788233

Epoch: 6| Step: 10
Training loss: 2.606655325348646
Validation loss: 2.4863046074149815

Epoch: 6| Step: 11
Training loss: 2.57326414616461
Validation loss: 2.4678898532159415

Epoch: 6| Step: 12
Training loss: 2.7713145552821765
Validation loss: 2.453754959697378

Epoch: 6| Step: 13
Training loss: 2.0283226633953637
Validation loss: 2.4634026104404403

Epoch: 47| Step: 0
Training loss: 2.7542913938626588
Validation loss: 2.4327512112286067

Epoch: 6| Step: 1
Training loss: 2.240266302491537
Validation loss: 2.4395682534507266

Epoch: 6| Step: 2
Training loss: 2.397055958030637
Validation loss: 2.4164455959447984

Epoch: 6| Step: 3
Training loss: 1.9590807631446534
Validation loss: 2.4285018988414637

Epoch: 6| Step: 4
Training loss: 1.9876511930142426
Validation loss: 2.425529774086952

Epoch: 6| Step: 5
Training loss: 2.5241474298562965
Validation loss: 2.4368974641943613

Epoch: 6| Step: 6
Training loss: 1.9971744127819184
Validation loss: 2.4264669549770885

Epoch: 6| Step: 7
Training loss: 2.4177558571022018
Validation loss: 2.4393712058767996

Epoch: 6| Step: 8
Training loss: 2.2663091218603952
Validation loss: 2.426014780955036

Epoch: 6| Step: 9
Training loss: 1.666933546951159
Validation loss: 2.452398058826784

Epoch: 6| Step: 10
Training loss: 2.540683827299795
Validation loss: 2.4354164233396576

Epoch: 6| Step: 11
Training loss: 2.1365767018525617
Validation loss: 2.4487039855559436

Epoch: 6| Step: 12
Training loss: 3.064474286893153
Validation loss: 2.4162241815647

Epoch: 6| Step: 13
Training loss: 2.0079244738277473
Validation loss: 2.427605508671501

Epoch: 48| Step: 0
Training loss: 1.9095584737530313
Validation loss: 2.4257572437026074

Epoch: 6| Step: 1
Training loss: 2.829246003766569
Validation loss: 2.447657540316241

Epoch: 6| Step: 2
Training loss: 2.1894806750399263
Validation loss: 2.417865568146197

Epoch: 6| Step: 3
Training loss: 2.368905831799842
Validation loss: 2.4119736688614797

Epoch: 6| Step: 4
Training loss: 2.049054565135072
Validation loss: 2.434184305331079

Epoch: 6| Step: 5
Training loss: 2.2594739879065586
Validation loss: 2.415331641672616

Epoch: 6| Step: 6
Training loss: 1.6804585660930016
Validation loss: 2.415087584097963

Epoch: 6| Step: 7
Training loss: 2.543292375120619
Validation loss: 2.434458440706261

Epoch: 6| Step: 8
Training loss: 2.6897811080193157
Validation loss: 2.424524781439595

Epoch: 6| Step: 9
Training loss: 2.5190894870710867
Validation loss: 2.422588678028817

Epoch: 6| Step: 10
Training loss: 2.386077744834508
Validation loss: 2.438428571496405

Epoch: 6| Step: 11
Training loss: 2.300257054767004
Validation loss: 2.402886884952479

Epoch: 6| Step: 12
Training loss: 2.4551472680697093
Validation loss: 2.451436257257427

Epoch: 6| Step: 13
Training loss: 2.055039408322157
Validation loss: 2.4669457695475203

Epoch: 49| Step: 0
Training loss: 1.8836680640896863
Validation loss: 2.4781122904031094

Epoch: 6| Step: 1
Training loss: 2.277838049714048
Validation loss: 2.464385153723488

Epoch: 6| Step: 2
Training loss: 2.6386792841425404
Validation loss: 2.4842354917243035

Epoch: 6| Step: 3
Training loss: 1.488645493997586
Validation loss: 2.4789345950543784

Epoch: 6| Step: 4
Training loss: 2.523717433649418
Validation loss: 2.4814702052389483

Epoch: 6| Step: 5
Training loss: 1.841414184294266
Validation loss: 2.4905367559214673

Epoch: 6| Step: 6
Training loss: 1.5443344832153343
Validation loss: 2.4682718932674406

Epoch: 6| Step: 7
Training loss: 3.1677047299623093
Validation loss: 2.4451068470757553

Epoch: 6| Step: 8
Training loss: 2.4273177485305757
Validation loss: 2.467215644687168

Epoch: 6| Step: 9
Training loss: 3.1212365949691963
Validation loss: 2.464509775112561

Epoch: 6| Step: 10
Training loss: 2.120473078899759
Validation loss: 2.4408705711150698

Epoch: 6| Step: 11
Training loss: 2.4152676928778054
Validation loss: 2.4421199314941986

Epoch: 6| Step: 12
Training loss: 1.5072531972254246
Validation loss: 2.4256198028715845

Epoch: 6| Step: 13
Training loss: 2.3373156918572424
Validation loss: 2.425525866839037

Epoch: 50| Step: 0
Training loss: 2.428349657110759
Validation loss: 2.421424027981349

Epoch: 6| Step: 1
Training loss: 2.4990781037946705
Validation loss: 2.4325779835510164

Epoch: 6| Step: 2
Training loss: 2.300671197561605
Validation loss: 2.408036060421797

Epoch: 6| Step: 3
Training loss: 2.2928886854500257
Validation loss: 2.4107740899393244

Epoch: 6| Step: 4
Training loss: 1.5561824492842107
Validation loss: 2.4185349105103993

Epoch: 6| Step: 5
Training loss: 2.14544002545679
Validation loss: 2.4190273319775053

Epoch: 6| Step: 6
Training loss: 2.61828134936379
Validation loss: 2.436736142054755

Epoch: 6| Step: 7
Training loss: 2.389640555546104
Validation loss: 2.422020840099209

Epoch: 6| Step: 8
Training loss: 2.5566771805541673
Validation loss: 2.4356971007114963

Epoch: 6| Step: 9
Training loss: 2.8038470780959885
Validation loss: 2.4169551962131424

Epoch: 6| Step: 10
Training loss: 2.1806517078341803
Validation loss: 2.420403334881388

Epoch: 6| Step: 11
Training loss: 2.122600771754991
Validation loss: 2.4248281214781686

Epoch: 6| Step: 12
Training loss: 2.0045897747669215
Validation loss: 2.432949595262544

Epoch: 6| Step: 13
Training loss: 2.374259331303962
Validation loss: 2.4653677325485313

Epoch: 51| Step: 0
Training loss: 2.245831655054639
Validation loss: 2.4659164681901595

Epoch: 6| Step: 1
Training loss: 1.900765643700543
Validation loss: 2.4501563735934964

Epoch: 6| Step: 2
Training loss: 2.3972431402471286
Validation loss: 2.4536063821420417

Epoch: 6| Step: 3
Training loss: 2.138645788582344
Validation loss: 2.4721739159435345

Epoch: 6| Step: 4
Training loss: 1.3705116623107758
Validation loss: 2.468809778962512

Epoch: 6| Step: 5
Training loss: 1.817217245867086
Validation loss: 2.4592521749909984

Epoch: 6| Step: 6
Training loss: 2.8718415201288248
Validation loss: 2.4505907319680924

Epoch: 6| Step: 7
Training loss: 2.3949946939811784
Validation loss: 2.4491537552950002

Epoch: 6| Step: 8
Training loss: 2.5712404749966953
Validation loss: 2.456249838546735

Epoch: 6| Step: 9
Training loss: 3.134008925901749
Validation loss: 2.445880007474496

Epoch: 6| Step: 10
Training loss: 2.58897143556611
Validation loss: 2.4388210270776094

Epoch: 6| Step: 11
Training loss: 2.236399340432673
Validation loss: 2.435819959791937

Epoch: 6| Step: 12
Training loss: 2.1229133458683993
Validation loss: 2.4258144292441015

Epoch: 6| Step: 13
Training loss: 1.7466913007256084
Validation loss: 2.442791761805038

Epoch: 52| Step: 0
Training loss: 2.660672713235656
Validation loss: 2.4667531883255482

Epoch: 6| Step: 1
Training loss: 2.7849353847164746
Validation loss: 2.431848576857313

Epoch: 6| Step: 2
Training loss: 1.8883658538918064
Validation loss: 2.4475134632466355

Epoch: 6| Step: 3
Training loss: 2.0888541757571604
Validation loss: 2.450269977460246

Epoch: 6| Step: 4
Training loss: 2.238357089956427
Validation loss: 2.398260435181015

Epoch: 6| Step: 5
Training loss: 1.8142509553130652
Validation loss: 2.428993952016367

Epoch: 6| Step: 6
Training loss: 1.9541171186248312
Validation loss: 2.444306204118791

Epoch: 6| Step: 7
Training loss: 2.25943072449489
Validation loss: 2.437425685630037

Epoch: 6| Step: 8
Training loss: 2.804460691669285
Validation loss: 2.481408401288795

Epoch: 6| Step: 9
Training loss: 2.548946450947164
Validation loss: 2.480492282865936

Epoch: 6| Step: 10
Training loss: 1.5486894235163726
Validation loss: 2.488526280833143

Epoch: 6| Step: 11
Training loss: 2.5615474512194054
Validation loss: 2.4532204141709455

Epoch: 6| Step: 12
Training loss: 2.146585894224067
Validation loss: 2.4517654733652865

Epoch: 6| Step: 13
Training loss: 2.5197763249872613
Validation loss: 2.4529536809040664

Epoch: 53| Step: 0
Training loss: 2.2155699170237124
Validation loss: 2.438606390134182

Epoch: 6| Step: 1
Training loss: 1.9026338641959737
Validation loss: 2.458973725739988

Epoch: 6| Step: 2
Training loss: 2.3051218431752245
Validation loss: 2.4269129539139733

Epoch: 6| Step: 3
Training loss: 1.8622250552422686
Validation loss: 2.424608775497747

Epoch: 6| Step: 4
Training loss: 2.4752548086606865
Validation loss: 2.433542396979207

Epoch: 6| Step: 5
Training loss: 1.5542147123599392
Validation loss: 2.4492787623011787

Epoch: 6| Step: 6
Training loss: 2.3104121087467604
Validation loss: 2.4481436008749493

Epoch: 6| Step: 7
Training loss: 2.770421324957549
Validation loss: 2.4381417464863007

Epoch: 6| Step: 8
Training loss: 2.4577430943258287
Validation loss: 2.4248710476780677

Epoch: 6| Step: 9
Training loss: 1.9985250160077468
Validation loss: 2.4171580494699874

Epoch: 6| Step: 10
Training loss: 2.2538240573117365
Validation loss: 2.421714900477856

Epoch: 6| Step: 11
Training loss: 2.745249372873564
Validation loss: 2.438504912599005

Epoch: 6| Step: 12
Training loss: 2.4301425716192036
Validation loss: 2.4466716576307914

Epoch: 6| Step: 13
Training loss: 2.2146058400524535
Validation loss: 2.413088358156541

Epoch: 54| Step: 0
Training loss: 1.9826525323787698
Validation loss: 2.4243939169958413

Epoch: 6| Step: 1
Training loss: 2.614139797894246
Validation loss: 2.42289526993632

Epoch: 6| Step: 2
Training loss: 2.834932511752512
Validation loss: 2.418305586697989

Epoch: 6| Step: 3
Training loss: 1.5836465759951406
Validation loss: 2.433959345657498

Epoch: 6| Step: 4
Training loss: 1.2225604034978417
Validation loss: 2.456716657834706

Epoch: 6| Step: 5
Training loss: 1.838435514877936
Validation loss: 2.429041867679137

Epoch: 6| Step: 6
Training loss: 2.1933176337301536
Validation loss: 2.4309307813896877

Epoch: 6| Step: 7
Training loss: 2.14102414162008
Validation loss: 2.4376748095697667

Epoch: 6| Step: 8
Training loss: 2.4174583278405657
Validation loss: 2.4593350799435774

Epoch: 6| Step: 9
Training loss: 2.4814249433441833
Validation loss: 2.486312958061024

Epoch: 6| Step: 10
Training loss: 2.3124482432579074
Validation loss: 2.469272059357366

Epoch: 6| Step: 11
Training loss: 3.01376522609388
Validation loss: 2.520910180446928

Epoch: 6| Step: 12
Training loss: 2.270472950001169
Validation loss: 2.490443864375716

Epoch: 6| Step: 13
Training loss: 2.404259787551586
Validation loss: 2.4999283144527866

Epoch: 55| Step: 0
Training loss: 1.94078235080443
Validation loss: 2.502573008480607

Epoch: 6| Step: 1
Training loss: 2.687082036363554
Validation loss: 2.4650192883390063

Epoch: 6| Step: 2
Training loss: 2.1613874186330624
Validation loss: 2.4574126496932904

Epoch: 6| Step: 3
Training loss: 2.483388356958257
Validation loss: 2.446344119408609

Epoch: 6| Step: 4
Training loss: 1.7162635851584234
Validation loss: 2.4264155002535337

Epoch: 6| Step: 5
Training loss: 2.0863306482268023
Validation loss: 2.4267350030104695

Epoch: 6| Step: 6
Training loss: 2.5523332019374267
Validation loss: 2.4282070445531723

Epoch: 6| Step: 7
Training loss: 2.3685105658229686
Validation loss: 2.4188532282366104

Epoch: 6| Step: 8
Training loss: 2.3663179418257894
Validation loss: 2.4283579370547805

Epoch: 6| Step: 9
Training loss: 2.7364168227616688
Validation loss: 2.405630865990958

Epoch: 6| Step: 10
Training loss: 1.7722573407731843
Validation loss: 2.419527207920244

Epoch: 6| Step: 11
Training loss: 2.770485954211887
Validation loss: 2.43070625625144

Epoch: 6| Step: 12
Training loss: 1.9342628015077554
Validation loss: 2.4292406527821058

Epoch: 6| Step: 13
Training loss: 1.9855330684946588
Validation loss: 2.44003249110284

Epoch: 56| Step: 0
Training loss: 2.4553690565736734
Validation loss: 2.4265296178891838

Epoch: 6| Step: 1
Training loss: 1.5286159826566879
Validation loss: 2.4413517246515433

Epoch: 6| Step: 2
Training loss: 2.024052824627743
Validation loss: 2.440623914365897

Epoch: 6| Step: 3
Training loss: 2.552498629249257
Validation loss: 2.4584205956785237

Epoch: 6| Step: 4
Training loss: 2.214365535826758
Validation loss: 2.43010862570776

Epoch: 6| Step: 5
Training loss: 1.573293560759217
Validation loss: 2.4204172484829014

Epoch: 6| Step: 6
Training loss: 2.4175459040610146
Validation loss: 2.4456108163171613

Epoch: 6| Step: 7
Training loss: 1.9486655021587438
Validation loss: 2.4079014449181098

Epoch: 6| Step: 8
Training loss: 2.2609912710379847
Validation loss: 2.4468934754721188

Epoch: 6| Step: 9
Training loss: 2.923214691985009
Validation loss: 2.455124576668332

Epoch: 6| Step: 10
Training loss: 2.916220022244489
Validation loss: 2.4601949227391517

Epoch: 6| Step: 11
Training loss: 2.44620807079624
Validation loss: 2.4611025154455453

Epoch: 6| Step: 12
Training loss: 1.4025916940290577
Validation loss: 2.4422168576165517

Epoch: 6| Step: 13
Training loss: 2.3798508546082133
Validation loss: 2.439132746764828

Epoch: 57| Step: 0
Training loss: 2.508684523658885
Validation loss: 2.4713627312970394

Epoch: 6| Step: 1
Training loss: 2.3989994745098904
Validation loss: 2.4531129322443603

Epoch: 6| Step: 2
Training loss: 2.249980926432827
Validation loss: 2.4504755294995637

Epoch: 6| Step: 3
Training loss: 2.2713948410113978
Validation loss: 2.4369092861286794

Epoch: 6| Step: 4
Training loss: 2.156196704150562
Validation loss: 2.471607928149371

Epoch: 6| Step: 5
Training loss: 2.0534847786197368
Validation loss: 2.4288215197891434

Epoch: 6| Step: 6
Training loss: 2.183421665569373
Validation loss: 2.4309614629741736

Epoch: 6| Step: 7
Training loss: 2.1081357353201753
Validation loss: 2.4306127783684763

Epoch: 6| Step: 8
Training loss: 2.744973443880848
Validation loss: 2.4196214589493446

Epoch: 6| Step: 9
Training loss: 2.1152703307698304
Validation loss: 2.4055791307732584

Epoch: 6| Step: 10
Training loss: 2.22397535497746
Validation loss: 2.4040175398838914

Epoch: 6| Step: 11
Training loss: 2.2885815632716318
Validation loss: 2.4296782923745766

Epoch: 6| Step: 12
Training loss: 1.7179451184904784
Validation loss: 2.4342855630490177

Epoch: 6| Step: 13
Training loss: 2.642454518023305
Validation loss: 2.4317900625778432

Epoch: 58| Step: 0
Training loss: 2.1022032714542473
Validation loss: 2.436217451535469

Epoch: 6| Step: 1
Training loss: 2.2859661525513344
Validation loss: 2.4356064084304165

Epoch: 6| Step: 2
Training loss: 2.3673504562439045
Validation loss: 2.437276552832063

Epoch: 6| Step: 3
Training loss: 2.421835622159712
Validation loss: 2.4474657955643546

Epoch: 6| Step: 4
Training loss: 1.7706850850002407
Validation loss: 2.436106454643498

Epoch: 6| Step: 5
Training loss: 2.3835250039378595
Validation loss: 2.458829172421211

Epoch: 6| Step: 6
Training loss: 2.4946883040155328
Validation loss: 2.462009862347023

Epoch: 6| Step: 7
Training loss: 2.4779689898455612
Validation loss: 2.4541745704389757

Epoch: 6| Step: 8
Training loss: 1.9321368653290392
Validation loss: 2.453875060532514

Epoch: 6| Step: 9
Training loss: 1.9482986633222577
Validation loss: 2.4697921661758295

Epoch: 6| Step: 10
Training loss: 2.044576737827474
Validation loss: 2.4456961496364666

Epoch: 6| Step: 11
Training loss: 2.4985402613936754
Validation loss: 2.4495418483515152

Epoch: 6| Step: 12
Training loss: 2.0259272159784367
Validation loss: 2.43356008899283

Epoch: 6| Step: 13
Training loss: 2.332227842392717
Validation loss: 2.465430333487151

Epoch: 59| Step: 0
Training loss: 2.2298366098461355
Validation loss: 2.4616458539420845

Epoch: 6| Step: 1
Training loss: 2.1716032887381727
Validation loss: 2.4849608428346612

Epoch: 6| Step: 2
Training loss: 2.211313276404451
Validation loss: 2.475121978682402

Epoch: 6| Step: 3
Training loss: 1.4173764339459616
Validation loss: 2.4988911871868664

Epoch: 6| Step: 4
Training loss: 2.1684150854948663
Validation loss: 2.4672510932520266

Epoch: 6| Step: 5
Training loss: 1.8710899273349522
Validation loss: 2.4727604318278593

Epoch: 6| Step: 6
Training loss: 1.9743956498300617
Validation loss: 2.474289823040686

Epoch: 6| Step: 7
Training loss: 1.9662398427420804
Validation loss: 2.5436010556116386

Epoch: 6| Step: 8
Training loss: 2.6832687425441297
Validation loss: 2.499877561114089

Epoch: 6| Step: 9
Training loss: 2.5841184366501104
Validation loss: 2.495734915812229

Epoch: 6| Step: 10
Training loss: 2.7706248460696896
Validation loss: 2.4607765266207933

Epoch: 6| Step: 11
Training loss: 2.888892401994705
Validation loss: 2.4499875392726693

Epoch: 6| Step: 12
Training loss: 2.0946322048605373
Validation loss: 2.4295846604542213

Epoch: 6| Step: 13
Training loss: 1.9405252157655284
Validation loss: 2.425982505324858

Epoch: 60| Step: 0
Training loss: 2.209778175095836
Validation loss: 2.4213197297188147

Epoch: 6| Step: 1
Training loss: 2.1395927223462623
Validation loss: 2.4106294320998503

Epoch: 6| Step: 2
Training loss: 2.4980626228796527
Validation loss: 2.4462369526219674

Epoch: 6| Step: 3
Training loss: 1.8526768932236442
Validation loss: 2.442014670281861

Epoch: 6| Step: 4
Training loss: 2.2973683145368615
Validation loss: 2.460193113743556

Epoch: 6| Step: 5
Training loss: 2.706616919049383
Validation loss: 2.458593893520859

Epoch: 6| Step: 6
Training loss: 2.317271079204287
Validation loss: 2.4380377640870083

Epoch: 6| Step: 7
Training loss: 1.9855530013208103
Validation loss: 2.4436664505226804

Epoch: 6| Step: 8
Training loss: 1.6066673241346183
Validation loss: 2.433492234890078

Epoch: 6| Step: 9
Training loss: 1.7909485316631537
Validation loss: 2.426615204640953

Epoch: 6| Step: 10
Training loss: 2.6219511036972913
Validation loss: 2.4403306549930175

Epoch: 6| Step: 11
Training loss: 2.9087431683560525
Validation loss: 2.410959597288745

Epoch: 6| Step: 12
Training loss: 2.540530206054389
Validation loss: 2.454425815140104

Epoch: 6| Step: 13
Training loss: 2.0706791391154664
Validation loss: 2.442742049927359

Epoch: 61| Step: 0
Training loss: 2.0761672815682957
Validation loss: 2.450306222553513

Epoch: 6| Step: 1
Training loss: 2.1127694403914385
Validation loss: 2.490791471909556

Epoch: 6| Step: 2
Training loss: 2.3243957964999464
Validation loss: 2.534644421525824

Epoch: 6| Step: 3
Training loss: 3.1106495760881336
Validation loss: 2.527590999468099

Epoch: 6| Step: 4
Training loss: 1.154386720210599
Validation loss: 2.5375564882101327

Epoch: 6| Step: 5
Training loss: 2.4262722335496374
Validation loss: 2.519290867262426

Epoch: 6| Step: 6
Training loss: 2.3968072874210535
Validation loss: 2.508503138433192

Epoch: 6| Step: 7
Training loss: 2.2094236117657537
Validation loss: 2.4671002843483105

Epoch: 6| Step: 8
Training loss: 1.7454893017509032
Validation loss: 2.4476181551682687

Epoch: 6| Step: 9
Training loss: 2.24686584470791
Validation loss: 2.409031156618983

Epoch: 6| Step: 10
Training loss: 2.512085883330722
Validation loss: 2.4196442780183016

Epoch: 6| Step: 11
Training loss: 2.8173161278936636
Validation loss: 2.4173168727230507

Epoch: 6| Step: 12
Training loss: 2.150415349362576
Validation loss: 2.3930427442687305

Epoch: 6| Step: 13
Training loss: 1.9641295816866606
Validation loss: 2.4482663385077243

Epoch: 62| Step: 0
Training loss: 1.7950714347885024
Validation loss: 2.4310266498395325

Epoch: 6| Step: 1
Training loss: 1.9996661861313332
Validation loss: 2.4157544968650138

Epoch: 6| Step: 2
Training loss: 2.3234866231357185
Validation loss: 2.4162713061776557

Epoch: 6| Step: 3
Training loss: 2.4170215828389243
Validation loss: 2.437120375455811

Epoch: 6| Step: 4
Training loss: 2.137677244455964
Validation loss: 2.4296174770130876

Epoch: 6| Step: 5
Training loss: 2.1896861460243158
Validation loss: 2.41356629968376

Epoch: 6| Step: 6
Training loss: 2.194202291699517
Validation loss: 2.409841045952029

Epoch: 6| Step: 7
Training loss: 2.4440103299536036
Validation loss: 2.4080529662439925

Epoch: 6| Step: 8
Training loss: 1.7535559085562038
Validation loss: 2.42777732346698

Epoch: 6| Step: 9
Training loss: 2.378656884764899
Validation loss: 2.3974983621591033

Epoch: 6| Step: 10
Training loss: 1.6231275187264613
Validation loss: 2.4566270650452107

Epoch: 6| Step: 11
Training loss: 2.179810113773811
Validation loss: 2.4437507866795567

Epoch: 6| Step: 12
Training loss: 2.880916644028228
Validation loss: 2.471691769103535

Epoch: 6| Step: 13
Training loss: 2.4629070816881797
Validation loss: 2.4844343550207455

Epoch: 63| Step: 0
Training loss: 2.301585654293112
Validation loss: 2.488767990502004

Epoch: 6| Step: 1
Training loss: 2.35557563501273
Validation loss: 2.497779623116158

Epoch: 6| Step: 2
Training loss: 2.280534710506818
Validation loss: 2.4839308559624915

Epoch: 6| Step: 3
Training loss: 2.535684539344129
Validation loss: 2.4897723159461536

Epoch: 6| Step: 4
Training loss: 1.913164761269352
Validation loss: 2.4584040766305555

Epoch: 6| Step: 5
Training loss: 1.819817078588924
Validation loss: 2.463035819210465

Epoch: 6| Step: 6
Training loss: 1.9028054055144163
Validation loss: 2.437962773400549

Epoch: 6| Step: 7
Training loss: 2.6936918389575673
Validation loss: 2.4437561526143834

Epoch: 6| Step: 8
Training loss: 2.2893791109965136
Validation loss: 2.414851647105654

Epoch: 6| Step: 9
Training loss: 2.5741963363852567
Validation loss: 2.4281631872577374

Epoch: 6| Step: 10
Training loss: 1.9278564414478032
Validation loss: 2.4023759710533983

Epoch: 6| Step: 11
Training loss: 1.9013029850806684
Validation loss: 2.417425239377451

Epoch: 6| Step: 12
Training loss: 2.516310888577974
Validation loss: 2.409374982188184

Epoch: 6| Step: 13
Training loss: 1.9306959227739153
Validation loss: 2.4158546684018702

Epoch: 64| Step: 0
Training loss: 2.397778349023813
Validation loss: 2.43786026664209

Epoch: 6| Step: 1
Training loss: 2.1428665342579265
Validation loss: 2.424018338035445

Epoch: 6| Step: 2
Training loss: 2.440722658203672
Validation loss: 2.3998891804858995

Epoch: 6| Step: 3
Training loss: 1.9192311780154958
Validation loss: 2.415794714015556

Epoch: 6| Step: 4
Training loss: 2.7796116836269364
Validation loss: 2.4308855510914302

Epoch: 6| Step: 5
Training loss: 1.4172309237959513
Validation loss: 2.4409032685000684

Epoch: 6| Step: 6
Training loss: 1.7280172028126781
Validation loss: 2.4636470672663258

Epoch: 6| Step: 7
Training loss: 2.298006777986602
Validation loss: 2.4900120295574886

Epoch: 6| Step: 8
Training loss: 2.221619590533335
Validation loss: 2.467524566399268

Epoch: 6| Step: 9
Training loss: 2.6606369592506725
Validation loss: 2.452762018064062

Epoch: 6| Step: 10
Training loss: 2.303918535646711
Validation loss: 2.4668181945249996

Epoch: 6| Step: 11
Training loss: 2.2631697406365396
Validation loss: 2.459819802272247

Epoch: 6| Step: 12
Training loss: 1.6908528962311047
Validation loss: 2.425206507905574

Epoch: 6| Step: 13
Training loss: 2.279795561877222
Validation loss: 2.448009770563985

Epoch: 65| Step: 0
Training loss: 2.351377359497061
Validation loss: 2.4296024712406488

Epoch: 6| Step: 1
Training loss: 2.128758976593176
Validation loss: 2.4376718346434787

Epoch: 6| Step: 2
Training loss: 2.149336304356499
Validation loss: 2.429765837000392

Epoch: 6| Step: 3
Training loss: 2.072881177537725
Validation loss: 2.409907513132531

Epoch: 6| Step: 4
Training loss: 1.948481479567525
Validation loss: 2.3859434726043274

Epoch: 6| Step: 5
Training loss: 1.916826704503317
Validation loss: 2.4252943614046654

Epoch: 6| Step: 6
Training loss: 1.8116589271897143
Validation loss: 2.4364686887166846

Epoch: 6| Step: 7
Training loss: 2.573909109939916
Validation loss: 2.4350560643858845

Epoch: 6| Step: 8
Training loss: 2.124128948528791
Validation loss: 2.4595745692376196

Epoch: 6| Step: 9
Training loss: 2.7570881959563756
Validation loss: 2.4653207969195488

Epoch: 6| Step: 10
Training loss: 1.6285145240536576
Validation loss: 2.460789880916871

Epoch: 6| Step: 11
Training loss: 3.0200517015894675
Validation loss: 2.4360047669387552

Epoch: 6| Step: 12
Training loss: 1.549089484273147
Validation loss: 2.44734050923356

Epoch: 6| Step: 13
Training loss: 2.111192273648873
Validation loss: 2.429254180439792

Epoch: 66| Step: 0
Training loss: 2.532949748194757
Validation loss: 2.4192268742624883

Epoch: 6| Step: 1
Training loss: 1.6568465687928837
Validation loss: 2.4172228195151506

Epoch: 6| Step: 2
Training loss: 2.634811593256339
Validation loss: 2.3877690944180414

Epoch: 6| Step: 3
Training loss: 2.6430549952558264
Validation loss: 2.4293410778956837

Epoch: 6| Step: 4
Training loss: 2.256471228915048
Validation loss: 2.424771871356236

Epoch: 6| Step: 5
Training loss: 1.9714675192115214
Validation loss: 2.4067956380110056

Epoch: 6| Step: 6
Training loss: 2.183090452220637
Validation loss: 2.4094672225408287

Epoch: 6| Step: 7
Training loss: 2.253248307111801
Validation loss: 2.422234834580828

Epoch: 6| Step: 8
Training loss: 2.4198077823815503
Validation loss: 2.4188539428456752

Epoch: 6| Step: 9
Training loss: 2.0463267749698475
Validation loss: 2.4243608740204667

Epoch: 6| Step: 10
Training loss: 1.7425135149219557
Validation loss: 2.4351105185669284

Epoch: 6| Step: 11
Training loss: 1.9020324703016154
Validation loss: 2.4492839863356837

Epoch: 6| Step: 12
Training loss: 1.8594739871563497
Validation loss: 2.4398278914917575

Epoch: 6| Step: 13
Training loss: 2.1927602464294935
Validation loss: 2.4322306579736708

Epoch: 67| Step: 0
Training loss: 2.074396560432769
Validation loss: 2.4598946758663036

Epoch: 6| Step: 1
Training loss: 1.8505141755132908
Validation loss: 2.4401237598285306

Epoch: 6| Step: 2
Training loss: 2.055285000680197
Validation loss: 2.442408941231605

Epoch: 6| Step: 3
Training loss: 2.409420748225594
Validation loss: 2.4623533666751207

Epoch: 6| Step: 4
Training loss: 2.8223316013319906
Validation loss: 2.4277600394191867

Epoch: 6| Step: 5
Training loss: 2.016276646040096
Validation loss: 2.431807791850566

Epoch: 6| Step: 6
Training loss: 2.0194677346606578
Validation loss: 2.396707928010103

Epoch: 6| Step: 7
Training loss: 2.3201047245592954
Validation loss: 2.4282661197325903

Epoch: 6| Step: 8
Training loss: 2.0537096604920544
Validation loss: 2.4077176328895744

Epoch: 6| Step: 9
Training loss: 1.9149086463791585
Validation loss: 2.4184486516864725

Epoch: 6| Step: 10
Training loss: 2.2072373555588474
Validation loss: 2.412373286133005

Epoch: 6| Step: 11
Training loss: 2.1013108567247625
Validation loss: 2.422667326579462

Epoch: 6| Step: 12
Training loss: 1.7172598187505625
Validation loss: 2.446217070006858

Epoch: 6| Step: 13
Training loss: 2.776130336087327
Validation loss: 2.4099398721419965

Epoch: 68| Step: 0
Training loss: 2.4665419929373966
Validation loss: 2.4266411920230393

Epoch: 6| Step: 1
Training loss: 1.5599864578881946
Validation loss: 2.436061809794389

Epoch: 6| Step: 2
Training loss: 2.6317655479629223
Validation loss: 2.4523890336882777

Epoch: 6| Step: 3
Training loss: 2.4615584301597093
Validation loss: 2.494102945742657

Epoch: 6| Step: 4
Training loss: 1.5923106856231168
Validation loss: 2.452819513628503

Epoch: 6| Step: 5
Training loss: 1.9923792728048217
Validation loss: 2.444702299803789

Epoch: 6| Step: 6
Training loss: 2.0881218492243816
Validation loss: 2.4736493985212014

Epoch: 6| Step: 7
Training loss: 1.9572149559798313
Validation loss: 2.4661166556276126

Epoch: 6| Step: 8
Training loss: 2.3007476752378357
Validation loss: 2.4382944524102625

Epoch: 6| Step: 9
Training loss: 2.4833037748007096
Validation loss: 2.448783353143834

Epoch: 6| Step: 10
Training loss: 1.9242295519285153
Validation loss: 2.4732710167993672

Epoch: 6| Step: 11
Training loss: 2.109138532029141
Validation loss: 2.442749012253872

Epoch: 6| Step: 12
Training loss: 1.8811735879074467
Validation loss: 2.458669976175147

Epoch: 6| Step: 13
Training loss: 2.2828045081821844
Validation loss: 2.4424397063972294

Epoch: 69| Step: 0
Training loss: 2.2796541667799497
Validation loss: 2.4471390862210907

Epoch: 6| Step: 1
Training loss: 2.6179401283441304
Validation loss: 2.4228080018840386

Epoch: 6| Step: 2
Training loss: 2.0436494761718604
Validation loss: 2.386822221160303

Epoch: 6| Step: 3
Training loss: 2.2518948946965205
Validation loss: 2.4251864119125206

Epoch: 6| Step: 4
Training loss: 2.482203176065426
Validation loss: 2.4248822317989127

Epoch: 6| Step: 5
Training loss: 1.962443104301898
Validation loss: 2.4071422755591194

Epoch: 6| Step: 6
Training loss: 2.4619963774790015
Validation loss: 2.395659462521405

Epoch: 6| Step: 7
Training loss: 2.1520505175776656
Validation loss: 2.3994509101949943

Epoch: 6| Step: 8
Training loss: 2.060201346547922
Validation loss: 2.4404662415615124

Epoch: 6| Step: 9
Training loss: 1.9955627571241275
Validation loss: 2.415415593488621

Epoch: 6| Step: 10
Training loss: 1.7542872365560624
Validation loss: 2.421571577200108

Epoch: 6| Step: 11
Training loss: 2.4872425732085235
Validation loss: 2.422859418416283

Epoch: 6| Step: 12
Training loss: 1.837445033801839
Validation loss: 2.428820832653314

Epoch: 6| Step: 13
Training loss: 1.8055633137202072
Validation loss: 2.420869105649799

Epoch: 70| Step: 0
Training loss: 1.334260434452088
Validation loss: 2.4387442844518765

Epoch: 6| Step: 1
Training loss: 2.2599417074669605
Validation loss: 2.5074747240358923

Epoch: 6| Step: 2
Training loss: 1.9390240489457928
Validation loss: 2.494417514233216

Epoch: 6| Step: 3
Training loss: 2.3472001176905586
Validation loss: 2.565572896560754

Epoch: 6| Step: 4
Training loss: 2.8727205611129687
Validation loss: 2.583541313126041

Epoch: 6| Step: 5
Training loss: 2.0128990488525704
Validation loss: 2.588979079031226

Epoch: 6| Step: 6
Training loss: 2.257015100661007
Validation loss: 2.578564377152262

Epoch: 6| Step: 7
Training loss: 2.675652226588217
Validation loss: 2.5541016570919663

Epoch: 6| Step: 8
Training loss: 1.815728567718319
Validation loss: 2.539241733582764

Epoch: 6| Step: 9
Training loss: 2.162759657248575
Validation loss: 2.5045018035847653

Epoch: 6| Step: 10
Training loss: 2.5315231364257347
Validation loss: 2.4747020982062127

Epoch: 6| Step: 11
Training loss: 2.2937393063496043
Validation loss: 2.408506186154967

Epoch: 6| Step: 12
Training loss: 1.5935401030306833
Validation loss: 2.4233595205288703

Epoch: 6| Step: 13
Training loss: 1.8360004820064668
Validation loss: 2.404593917549286

Epoch: 71| Step: 0
Training loss: 2.6055513794934884
Validation loss: 2.433395598107015

Epoch: 6| Step: 1
Training loss: 2.2227236129126386
Validation loss: 2.412270878006737

Epoch: 6| Step: 2
Training loss: 1.5396368049279892
Validation loss: 2.416332901454906

Epoch: 6| Step: 3
Training loss: 1.9308961488562368
Validation loss: 2.429647888972815

Epoch: 6| Step: 4
Training loss: 2.1152209618760436
Validation loss: 2.4367550420672743

Epoch: 6| Step: 5
Training loss: 1.922787953453665
Validation loss: 2.414347001217135

Epoch: 6| Step: 6
Training loss: 1.823910803604945
Validation loss: 2.4291348334746323

Epoch: 6| Step: 7
Training loss: 2.104171551487858
Validation loss: 2.3985132791515915

Epoch: 6| Step: 8
Training loss: 2.2025372959057825
Validation loss: 2.431171042002725

Epoch: 6| Step: 9
Training loss: 2.2375363480156936
Validation loss: 2.431714846539197

Epoch: 6| Step: 10
Training loss: 2.161464412328299
Validation loss: 2.4467696945506305

Epoch: 6| Step: 11
Training loss: 2.4536890244061516
Validation loss: 2.4533089570807465

Epoch: 6| Step: 12
Training loss: 2.0339660092779805
Validation loss: 2.456622681562569

Epoch: 6| Step: 13
Training loss: 2.4573348544601283
Validation loss: 2.4802355879485485

Epoch: 72| Step: 0
Training loss: 2.0282168704063377
Validation loss: 2.4813758132772072

Epoch: 6| Step: 1
Training loss: 2.3843749880009524
Validation loss: 2.4764295957505738

Epoch: 6| Step: 2
Training loss: 2.3257202427467436
Validation loss: 2.4478536935917377

Epoch: 6| Step: 3
Training loss: 1.9447084277959577
Validation loss: 2.4447063877059243

Epoch: 6| Step: 4
Training loss: 1.7224264878308873
Validation loss: 2.435736686776395

Epoch: 6| Step: 5
Training loss: 2.7993167043459852
Validation loss: 2.405536000723154

Epoch: 6| Step: 6
Training loss: 1.863295645028416
Validation loss: 2.3878519184992784

Epoch: 6| Step: 7
Training loss: 2.3413189296076604
Validation loss: 2.4003335952709204

Epoch: 6| Step: 8
Training loss: 2.0362374916886767
Validation loss: 2.413487305164109

Epoch: 6| Step: 9
Training loss: 1.951190936937668
Validation loss: 2.4372898402458416

Epoch: 6| Step: 10
Training loss: 2.5280543747740007
Validation loss: 2.4480834471248962

Epoch: 6| Step: 11
Training loss: 1.861660298251487
Validation loss: 2.402812988437314

Epoch: 6| Step: 12
Training loss: 1.9739826237803657
Validation loss: 2.3995008565492206

Epoch: 6| Step: 13
Training loss: 1.770907441626773
Validation loss: 2.4247856124023173

Epoch: 73| Step: 0
Training loss: 1.4927769640070212
Validation loss: 2.437665697318323

Epoch: 6| Step: 1
Training loss: 2.2009264209170025
Validation loss: 2.4293328749087113

Epoch: 6| Step: 2
Training loss: 1.7078661240991517
Validation loss: 2.4703561732730295

Epoch: 6| Step: 3
Training loss: 2.0193625403645306
Validation loss: 2.46230303304181

Epoch: 6| Step: 4
Training loss: 2.2351700228680436
Validation loss: 2.4993901383085473

Epoch: 6| Step: 5
Training loss: 1.974514650512191
Validation loss: 2.4966564469537866

Epoch: 6| Step: 6
Training loss: 2.2668561024137137
Validation loss: 2.4846000009690226

Epoch: 6| Step: 7
Training loss: 1.973791781388517
Validation loss: 2.473156083517154

Epoch: 6| Step: 8
Training loss: 2.240002035582844
Validation loss: 2.4540971218827443

Epoch: 6| Step: 9
Training loss: 1.8544572181076338
Validation loss: 2.466413817033104

Epoch: 6| Step: 10
Training loss: 2.067280402370207
Validation loss: 2.429744854707016

Epoch: 6| Step: 11
Training loss: 2.4483344080095764
Validation loss: 2.4349753599728325

Epoch: 6| Step: 12
Training loss: 2.334790512751377
Validation loss: 2.435418634166418

Epoch: 6| Step: 13
Training loss: 2.5210522222984895
Validation loss: 2.408841228278527

Epoch: 74| Step: 0
Training loss: 2.047652002451718
Validation loss: 2.403887939383389

Epoch: 6| Step: 1
Training loss: 2.3982628376638133
Validation loss: 2.4265319105039165

Epoch: 6| Step: 2
Training loss: 2.361934057195406
Validation loss: 2.4221657199083

Epoch: 6| Step: 3
Training loss: 1.8833513557224426
Validation loss: 2.406592703851282

Epoch: 6| Step: 4
Training loss: 2.445274864614034
Validation loss: 2.412234522652811

Epoch: 6| Step: 5
Training loss: 2.1602459797494546
Validation loss: 2.424488273846614

Epoch: 6| Step: 6
Training loss: 2.2623812902510547
Validation loss: 2.4538823313307945

Epoch: 6| Step: 7
Training loss: 2.274377268145112
Validation loss: 2.4417292510942135

Epoch: 6| Step: 8
Training loss: 2.2879354677369745
Validation loss: 2.440368089818235

Epoch: 6| Step: 9
Training loss: 2.0708494245900524
Validation loss: 2.4821129503372754

Epoch: 6| Step: 10
Training loss: 1.3943974620423936
Validation loss: 2.4856934557709076

Epoch: 6| Step: 11
Training loss: 1.5950621644823855
Validation loss: 2.4385161930683603

Epoch: 6| Step: 12
Training loss: 1.8748054403451972
Validation loss: 2.4784927467310345

Epoch: 6| Step: 13
Training loss: 2.3899605020746786
Validation loss: 2.4876489399804824

Epoch: 75| Step: 0
Training loss: 2.5638104321272985
Validation loss: 2.4461447098933866

Epoch: 6| Step: 1
Training loss: 2.2481585490629556
Validation loss: 2.435988829934245

Epoch: 6| Step: 2
Training loss: 2.5499191346155694
Validation loss: 2.4157840635265493

Epoch: 6| Step: 3
Training loss: 2.140099453976987
Validation loss: 2.4132826449759746

Epoch: 6| Step: 4
Training loss: 2.2331416854427224
Validation loss: 2.41004604786295

Epoch: 6| Step: 5
Training loss: 2.5446776289703337
Validation loss: 2.4333709810776076

Epoch: 6| Step: 6
Training loss: 2.4467115208761205
Validation loss: 2.414162198572717

Epoch: 6| Step: 7
Training loss: 1.7189591713983698
Validation loss: 2.4340258888700457

Epoch: 6| Step: 8
Training loss: 1.6194414289623442
Validation loss: 2.3960824311723625

Epoch: 6| Step: 9
Training loss: 1.8692897310645373
Validation loss: 2.396511965849051

Epoch: 6| Step: 10
Training loss: 2.1914272477339045
Validation loss: 2.4358577902009055

Epoch: 6| Step: 11
Training loss: 1.8214077908268151
Validation loss: 2.4404663555376858

Epoch: 6| Step: 12
Training loss: 1.2600978206325357
Validation loss: 2.394595511955151

Epoch: 6| Step: 13
Training loss: 1.6338386778927771
Validation loss: 2.4299375153973304

Epoch: 76| Step: 0
Training loss: 2.207214671927312
Validation loss: 2.4661119264704103

Epoch: 6| Step: 1
Training loss: 2.1886051111286604
Validation loss: 2.4774011902619635

Epoch: 6| Step: 2
Training loss: 2.209088526259599
Validation loss: 2.508195532903274

Epoch: 6| Step: 3
Training loss: 1.136982785526562
Validation loss: 2.491616066979197

Epoch: 6| Step: 4
Training loss: 2.026154215088356
Validation loss: 2.5074213897487496

Epoch: 6| Step: 5
Training loss: 2.091073674294649
Validation loss: 2.507805654926406

Epoch: 6| Step: 6
Training loss: 1.8994660279684525
Validation loss: 2.5134910235867247

Epoch: 6| Step: 7
Training loss: 1.9496592174984917
Validation loss: 2.4672424606634267

Epoch: 6| Step: 8
Training loss: 2.467906566390748
Validation loss: 2.4849680706508352

Epoch: 6| Step: 9
Training loss: 2.5859155567540477
Validation loss: 2.478012206183239

Epoch: 6| Step: 10
Training loss: 1.6188913114278403
Validation loss: 2.4419104459839316

Epoch: 6| Step: 11
Training loss: 2.630952715899383
Validation loss: 2.4145631980769586

Epoch: 6| Step: 12
Training loss: 2.0762558181745483
Validation loss: 2.4298562730269375

Epoch: 6| Step: 13
Training loss: 1.845078200050214
Validation loss: 2.395302793943909

Epoch: 77| Step: 0
Training loss: 1.5880736448473478
Validation loss: 2.41310422410035

Epoch: 6| Step: 1
Training loss: 2.256530925982574
Validation loss: 2.3882790817235926

Epoch: 6| Step: 2
Training loss: 1.9828903772137467
Validation loss: 2.401817541203623

Epoch: 6| Step: 3
Training loss: 2.3119304058595893
Validation loss: 2.394465741687046

Epoch: 6| Step: 4
Training loss: 2.4152745040726105
Validation loss: 2.407314123040416

Epoch: 6| Step: 5
Training loss: 1.789555244388193
Validation loss: 2.4009189091633423

Epoch: 6| Step: 6
Training loss: 2.6768947985173233
Validation loss: 2.400267069911079

Epoch: 6| Step: 7
Training loss: 1.7780439737157911
Validation loss: 2.400520008760458

Epoch: 6| Step: 8
Training loss: 1.6059520578698836
Validation loss: 2.3937986579776944

Epoch: 6| Step: 9
Training loss: 1.864917348712617
Validation loss: 2.472043122603691

Epoch: 6| Step: 10
Training loss: 2.0187909006988884
Validation loss: 2.478629884924376

Epoch: 6| Step: 11
Training loss: 2.1438826672844677
Validation loss: 2.4508787347150287

Epoch: 6| Step: 12
Training loss: 1.9978639401455096
Validation loss: 2.493097009789379

Epoch: 6| Step: 13
Training loss: 1.9894947478327387
Validation loss: 2.4862606721664666

Epoch: 78| Step: 0
Training loss: 2.6299725618853005
Validation loss: 2.507013575926578

Epoch: 6| Step: 1
Training loss: 1.7695249174227887
Validation loss: 2.4702407102631185

Epoch: 6| Step: 2
Training loss: 2.5186910958418847
Validation loss: 2.4402829609888657

Epoch: 6| Step: 3
Training loss: 1.931032893251836
Validation loss: 2.430841725774887

Epoch: 6| Step: 4
Training loss: 1.8714120231820286
Validation loss: 2.4122611838483534

Epoch: 6| Step: 5
Training loss: 2.0334216906418248
Validation loss: 2.427137887257014

Epoch: 6| Step: 6
Training loss: 1.851956804356745
Validation loss: 2.419128829900197

Epoch: 6| Step: 7
Training loss: 2.0407249718285243
Validation loss: 2.4349067619744855

Epoch: 6| Step: 8
Training loss: 2.252207944270924
Validation loss: 2.4423121610273655

Epoch: 6| Step: 9
Training loss: 2.4380502324300153
Validation loss: 2.419275443268084

Epoch: 6| Step: 10
Training loss: 2.0186952376836094
Validation loss: 2.4438971342654106

Epoch: 6| Step: 11
Training loss: 1.525056731622784
Validation loss: 2.427629234797265

Epoch: 6| Step: 12
Training loss: 1.7290752647172791
Validation loss: 2.40297646396248

Epoch: 6| Step: 13
Training loss: 1.982442320168587
Validation loss: 2.4342892032206414

Epoch: 79| Step: 0
Training loss: 2.099945921428646
Validation loss: 2.427019737840303

Epoch: 6| Step: 1
Training loss: 1.7925133885265334
Validation loss: 2.437606532059295

Epoch: 6| Step: 2
Training loss: 2.1544637606767343
Validation loss: 2.46274697925771

Epoch: 6| Step: 3
Training loss: 1.5792377439152854
Validation loss: 2.477411070612418

Epoch: 6| Step: 4
Training loss: 2.0984419446998954
Validation loss: 2.4715819232103673

Epoch: 6| Step: 5
Training loss: 1.667973466996038
Validation loss: 2.492652188051502

Epoch: 6| Step: 6
Training loss: 2.0080559133974747
Validation loss: 2.5035211244116895

Epoch: 6| Step: 7
Training loss: 2.4223992549391173
Validation loss: 2.522941005115835

Epoch: 6| Step: 8
Training loss: 2.3180693498824096
Validation loss: 2.500226805253461

Epoch: 6| Step: 9
Training loss: 2.3560668793206068
Validation loss: 2.4528594956610354

Epoch: 6| Step: 10
Training loss: 1.8268015709135428
Validation loss: 2.4002564995180404

Epoch: 6| Step: 11
Training loss: 1.8915878240256774
Validation loss: 2.4176467738654814

Epoch: 6| Step: 12
Training loss: 1.842574375157668
Validation loss: 2.415390332573995

Epoch: 6| Step: 13
Training loss: 2.6548731208556458
Validation loss: 2.403885112740188

Epoch: 80| Step: 0
Training loss: 1.885303543097365
Validation loss: 2.405428576941854

Epoch: 6| Step: 1
Training loss: 1.6126482370534367
Validation loss: 2.4299594444846626

Epoch: 6| Step: 2
Training loss: 2.078278958920411
Validation loss: 2.3985542161274656

Epoch: 6| Step: 3
Training loss: 1.6527048712855676
Validation loss: 2.4064736695805844

Epoch: 6| Step: 4
Training loss: 2.151878680542638
Validation loss: 2.426647136167735

Epoch: 6| Step: 5
Training loss: 2.2661931871045984
Validation loss: 2.4025804191147313

Epoch: 6| Step: 6
Training loss: 2.092326121335405
Validation loss: 2.391126451280119

Epoch: 6| Step: 7
Training loss: 1.560641900560365
Validation loss: 2.395454133473347

Epoch: 6| Step: 8
Training loss: 1.6669098040934638
Validation loss: 2.417613260639766

Epoch: 6| Step: 9
Training loss: 1.8942420345449553
Validation loss: 2.4100241271930978

Epoch: 6| Step: 10
Training loss: 1.9388702223473402
Validation loss: 2.4374141351949112

Epoch: 6| Step: 11
Training loss: 2.2957924088593935
Validation loss: 2.4810028702589757

Epoch: 6| Step: 12
Training loss: 2.0533615881763483
Validation loss: 2.4633520966083235

Epoch: 6| Step: 13
Training loss: 3.0634608415778484
Validation loss: 2.5331135393045483

Epoch: 81| Step: 0
Training loss: 2.7462651292872935
Validation loss: 2.4972197968166268

Epoch: 6| Step: 1
Training loss: 1.7806502553930263
Validation loss: 2.5201531009992215

Epoch: 6| Step: 2
Training loss: 2.047658173503067
Validation loss: 2.4674871731791574

Epoch: 6| Step: 3
Training loss: 1.953904385510531
Validation loss: 2.4496489273306574

Epoch: 6| Step: 4
Training loss: 2.1229602897836526
Validation loss: 2.4283902547479594

Epoch: 6| Step: 5
Training loss: 2.611625386268698
Validation loss: 2.4017755182718012

Epoch: 6| Step: 6
Training loss: 1.611256952736875
Validation loss: 2.376299561102935

Epoch: 6| Step: 7
Training loss: 2.203603273246856
Validation loss: 2.4149904247486376

Epoch: 6| Step: 8
Training loss: 1.7360471620438
Validation loss: 2.40603139635711

Epoch: 6| Step: 9
Training loss: 1.9958640487101915
Validation loss: 2.4187285955436493

Epoch: 6| Step: 10
Training loss: 2.013037625169157
Validation loss: 2.447910346706159

Epoch: 6| Step: 11
Training loss: 1.6398404379888913
Validation loss: 2.4232392273234504

Epoch: 6| Step: 12
Training loss: 1.908295206524756
Validation loss: 2.448139194086716

Epoch: 6| Step: 13
Training loss: 1.5994325943028238
Validation loss: 2.4359829901459986

Epoch: 82| Step: 0
Training loss: 2.12685358324234
Validation loss: 2.391374956566169

Epoch: 6| Step: 1
Training loss: 2.251805111205252
Validation loss: 2.3953534239947354

Epoch: 6| Step: 2
Training loss: 2.3050704379293743
Validation loss: 2.4335422336928336

Epoch: 6| Step: 3
Training loss: 1.7247579128284583
Validation loss: 2.405852099130625

Epoch: 6| Step: 4
Training loss: 2.1133559349528164
Validation loss: 2.406250412845989

Epoch: 6| Step: 5
Training loss: 1.697943970006302
Validation loss: 2.44782108904879

Epoch: 6| Step: 6
Training loss: 1.8750186283457764
Validation loss: 2.448583184805032

Epoch: 6| Step: 7
Training loss: 1.9044280178200443
Validation loss: 2.446374307189077

Epoch: 6| Step: 8
Training loss: 1.788419916285477
Validation loss: 2.456582016704995

Epoch: 6| Step: 9
Training loss: 2.127003790862342
Validation loss: 2.438690449117773

Epoch: 6| Step: 10
Training loss: 1.4718956235181835
Validation loss: 2.464574123009578

Epoch: 6| Step: 11
Training loss: 2.1313572205004476
Validation loss: 2.3969477729078226

Epoch: 6| Step: 12
Training loss: 1.8766251197041952
Validation loss: 2.440401323124897

Epoch: 6| Step: 13
Training loss: 2.3369986378931427
Validation loss: 2.468271796674118

Epoch: 83| Step: 0
Training loss: 2.0874726436444306
Validation loss: 2.4486337355488508

Epoch: 6| Step: 1
Training loss: 1.768559405838198
Validation loss: 2.4102448169462733

Epoch: 6| Step: 2
Training loss: 1.925281390146359
Validation loss: 2.426101073775296

Epoch: 6| Step: 3
Training loss: 2.469654738353595
Validation loss: 2.432101989037562

Epoch: 6| Step: 4
Training loss: 1.650734986263103
Validation loss: 2.3924495075973904

Epoch: 6| Step: 5
Training loss: 2.0434262873844697
Validation loss: 2.406026061895935

Epoch: 6| Step: 6
Training loss: 2.0155996868111345
Validation loss: 2.4284737224051223

Epoch: 6| Step: 7
Training loss: 2.0915445127444703
Validation loss: 2.4262194153294154

Epoch: 6| Step: 8
Training loss: 2.029380289957279
Validation loss: 2.40596680399

Epoch: 6| Step: 9
Training loss: 1.7625417880251555
Validation loss: 2.413250610710311

Epoch: 6| Step: 10
Training loss: 2.278871733594023
Validation loss: 2.411792943381878

Epoch: 6| Step: 11
Training loss: 1.9089608850003779
Validation loss: 2.4261820651931427

Epoch: 6| Step: 12
Training loss: 1.1919538396435763
Validation loss: 2.4142447755674183

Epoch: 6| Step: 13
Training loss: 1.9828592353525503
Validation loss: 2.4426340337215695

Epoch: 84| Step: 0
Training loss: 1.691198604955973
Validation loss: 2.470701259366061

Epoch: 6| Step: 1
Training loss: 2.459720177281331
Validation loss: 2.4421680289395535

Epoch: 6| Step: 2
Training loss: 1.7266778001217684
Validation loss: 2.4268727327150046

Epoch: 6| Step: 3
Training loss: 1.6532766896332691
Validation loss: 2.421132127593692

Epoch: 6| Step: 4
Training loss: 1.631748418555612
Validation loss: 2.4351511258742566

Epoch: 6| Step: 5
Training loss: 1.654258250176304
Validation loss: 2.462359450536093

Epoch: 6| Step: 6
Training loss: 1.818379632527634
Validation loss: 2.418846804959448

Epoch: 6| Step: 7
Training loss: 2.2304489749492804
Validation loss: 2.3959233695541

Epoch: 6| Step: 8
Training loss: 2.1156193743001275
Validation loss: 2.3638751163920704

Epoch: 6| Step: 9
Training loss: 1.4158845406728895
Validation loss: 2.408600719968511

Epoch: 6| Step: 10
Training loss: 2.352110738625589
Validation loss: 2.436911960323799

Epoch: 6| Step: 11
Training loss: 2.1922542678768844
Validation loss: 2.43499626455732

Epoch: 6| Step: 12
Training loss: 2.029271849844192
Validation loss: 2.470273493427257

Epoch: 6| Step: 13
Training loss: 2.141576625054309
Validation loss: 2.4404741547517337

Epoch: 85| Step: 0
Training loss: 1.7554429422882878
Validation loss: 2.484789511850595

Epoch: 6| Step: 1
Training loss: 2.173415700993754
Validation loss: 2.533376420641776

Epoch: 6| Step: 2
Training loss: 1.7526744433554908
Validation loss: 2.5053433932394586

Epoch: 6| Step: 3
Training loss: 2.048342346262625
Validation loss: 2.5289225768987316

Epoch: 6| Step: 4
Training loss: 2.3445904051535806
Validation loss: 2.466043977067368

Epoch: 6| Step: 5
Training loss: 1.7543269207287737
Validation loss: 2.4593635167811514

Epoch: 6| Step: 6
Training loss: 1.9407210493659377
Validation loss: 2.416883850752253

Epoch: 6| Step: 7
Training loss: 1.9037898714094477
Validation loss: 2.3847348906098396

Epoch: 6| Step: 8
Training loss: 2.4913953520715024
Validation loss: 2.4219943929796868

Epoch: 6| Step: 9
Training loss: 2.070662328566121
Validation loss: 2.387966764136785

Epoch: 6| Step: 10
Training loss: 1.8426449583838638
Validation loss: 2.4073623299114333

Epoch: 6| Step: 11
Training loss: 2.0091657419834146
Validation loss: 2.38925374248824

Epoch: 6| Step: 12
Training loss: 1.8610220274157125
Validation loss: 2.4063461829444504

Epoch: 6| Step: 13
Training loss: 1.586186506895962
Validation loss: 2.426314724768499

Epoch: 86| Step: 0
Training loss: 2.097805138672634
Validation loss: 2.433574482538929

Epoch: 6| Step: 1
Training loss: 1.6853270492335954
Validation loss: 2.437541961308742

Epoch: 6| Step: 2
Training loss: 1.882149100661683
Validation loss: 2.462624818120329

Epoch: 6| Step: 3
Training loss: 2.2117226220962443
Validation loss: 2.4668285924584454

Epoch: 6| Step: 4
Training loss: 1.4896109340573738
Validation loss: 2.4769641378057927

Epoch: 6| Step: 5
Training loss: 2.156853522274202
Validation loss: 2.4786170756341783

Epoch: 6| Step: 6
Training loss: 2.074846592942916
Validation loss: 2.473206630076534

Epoch: 6| Step: 7
Training loss: 2.2031544351978667
Validation loss: 2.473783552454032

Epoch: 6| Step: 8
Training loss: 1.972477608325184
Validation loss: 2.457067225546132

Epoch: 6| Step: 9
Training loss: 2.0741146083054884
Validation loss: 2.4667441995996553

Epoch: 6| Step: 10
Training loss: 2.092179349807921
Validation loss: 2.4151081507747767

Epoch: 6| Step: 11
Training loss: 1.7013624677963752
Validation loss: 2.4373765245773225

Epoch: 6| Step: 12
Training loss: 1.6992413398731898
Validation loss: 2.4223329664815982

Epoch: 6| Step: 13
Training loss: 1.3692235118901133
Validation loss: 2.3879410547694997

Epoch: 87| Step: 0
Training loss: 1.9133380375227214
Validation loss: 2.367827015386257

Epoch: 6| Step: 1
Training loss: 1.8489831913812786
Validation loss: 2.4006250368922903

Epoch: 6| Step: 2
Training loss: 2.2104238176245135
Validation loss: 2.411826694001814

Epoch: 6| Step: 3
Training loss: 1.87390677052655
Validation loss: 2.4392890722303133

Epoch: 6| Step: 4
Training loss: 1.7733593894124602
Validation loss: 2.414594589571406

Epoch: 6| Step: 5
Training loss: 2.0824318906492754
Validation loss: 2.43813112027527

Epoch: 6| Step: 6
Training loss: 2.1193181539261716
Validation loss: 2.4084257387519434

Epoch: 6| Step: 7
Training loss: 2.1819575258031905
Validation loss: 2.4890723774840304

Epoch: 6| Step: 8
Training loss: 1.361140890941822
Validation loss: 2.4603045744614644

Epoch: 6| Step: 9
Training loss: 2.8585003625169905
Validation loss: 2.504706347658949

Epoch: 6| Step: 10
Training loss: 1.8981952277171272
Validation loss: 2.492598098206965

Epoch: 6| Step: 11
Training loss: 1.8183460009745818
Validation loss: 2.4333501196852727

Epoch: 6| Step: 12
Training loss: 1.6947650640830791
Validation loss: 2.4841142513585384

Epoch: 6| Step: 13
Training loss: 1.2725893718459727
Validation loss: 2.436595993643514

Epoch: 88| Step: 0
Training loss: 1.5122036414990665
Validation loss: 2.4112971988723566

Epoch: 6| Step: 1
Training loss: 2.0501323145523145
Validation loss: 2.4100095105544144

Epoch: 6| Step: 2
Training loss: 2.2907983232942644
Validation loss: 2.4379526353824357

Epoch: 6| Step: 3
Training loss: 1.5051543370189884
Validation loss: 2.4682535243692283

Epoch: 6| Step: 4
Training loss: 1.7433916386809802
Validation loss: 2.4179207956779636

Epoch: 6| Step: 5
Training loss: 1.8163286746287315
Validation loss: 2.4303301567439166

Epoch: 6| Step: 6
Training loss: 1.4453402129944453
Validation loss: 2.4366783322195507

Epoch: 6| Step: 7
Training loss: 1.2291523991850495
Validation loss: 2.4529719537831145

Epoch: 6| Step: 8
Training loss: 2.1011286291213302
Validation loss: 2.425457919037074

Epoch: 6| Step: 9
Training loss: 2.236376099717399
Validation loss: 2.4240953993284946

Epoch: 6| Step: 10
Training loss: 2.2812881466537154
Validation loss: 2.4095892587037318

Epoch: 6| Step: 11
Training loss: 1.6988572010070335
Validation loss: 2.4440549434182

Epoch: 6| Step: 12
Training loss: 1.7451897314157323
Validation loss: 2.4060173252451196

Epoch: 6| Step: 13
Training loss: 2.6462352677675334
Validation loss: 2.4202265061496906

Epoch: 89| Step: 0
Training loss: 1.668604709429578
Validation loss: 2.424658179033954

Epoch: 6| Step: 1
Training loss: 1.9004488991940498
Validation loss: 2.391812131580632

Epoch: 6| Step: 2
Training loss: 2.271421817039462
Validation loss: 2.432987894944028

Epoch: 6| Step: 3
Training loss: 2.467450343041078
Validation loss: 2.423042647568031

Epoch: 6| Step: 4
Training loss: 2.2881607518845444
Validation loss: 2.4201280261294142

Epoch: 6| Step: 5
Training loss: 1.5726909180717616
Validation loss: 2.461034181502143

Epoch: 6| Step: 6
Training loss: 1.7422146645382575
Validation loss: 2.4476471827006567

Epoch: 6| Step: 7
Training loss: 2.0339082197039273
Validation loss: 2.3957425031168182

Epoch: 6| Step: 8
Training loss: 2.0652732699710667
Validation loss: 2.4390650069626885

Epoch: 6| Step: 9
Training loss: 1.575891935501848
Validation loss: 2.4315847530865695

Epoch: 6| Step: 10
Training loss: 1.9491571022941758
Validation loss: 2.4829729710537976

Epoch: 6| Step: 11
Training loss: 1.798858940531552
Validation loss: 2.5220892171151967

Epoch: 6| Step: 12
Training loss: 1.703977878749337
Validation loss: 2.461937514479277

Epoch: 6| Step: 13
Training loss: 1.4770938785034875
Validation loss: 2.461775880128684

Epoch: 90| Step: 0
Training loss: 1.6427327739838216
Validation loss: 2.4676854055382718

Epoch: 6| Step: 1
Training loss: 1.4715969009250651
Validation loss: 2.467952422381557

Epoch: 6| Step: 2
Training loss: 1.5064059006669108
Validation loss: 2.4671374982099907

Epoch: 6| Step: 3
Training loss: 1.8417144789322175
Validation loss: 2.501039860947315

Epoch: 6| Step: 4
Training loss: 1.7955543640668354
Validation loss: 2.428588013298509

Epoch: 6| Step: 5
Training loss: 1.6310304106608462
Validation loss: 2.4244126591777864

Epoch: 6| Step: 6
Training loss: 1.6627552467530686
Validation loss: 2.4452688357483794

Epoch: 6| Step: 7
Training loss: 1.9472308524039237
Validation loss: 2.451630163221382

Epoch: 6| Step: 8
Training loss: 1.5222259398845808
Validation loss: 2.43421475001765

Epoch: 6| Step: 9
Training loss: 1.8018421018986543
Validation loss: 2.451701259312801

Epoch: 6| Step: 10
Training loss: 2.688020434001047
Validation loss: 2.427471953837968

Epoch: 6| Step: 11
Training loss: 2.25657582981561
Validation loss: 2.4374549894171107

Epoch: 6| Step: 12
Training loss: 2.0236293156850156
Validation loss: 2.420871239484128

Epoch: 6| Step: 13
Training loss: 2.1677916858295805
Validation loss: 2.4333483560525164

Epoch: 91| Step: 0
Training loss: 2.1024847453286313
Validation loss: 2.3848871923355235

Epoch: 6| Step: 1
Training loss: 1.7020267130081164
Validation loss: 2.440745939350954

Epoch: 6| Step: 2
Training loss: 1.963516727629792
Validation loss: 2.373127098454293

Epoch: 6| Step: 3
Training loss: 1.5224798077777395
Validation loss: 2.3927161933350214

Epoch: 6| Step: 4
Training loss: 1.870531861866711
Validation loss: 2.456601718378764

Epoch: 6| Step: 5
Training loss: 1.4695790974089349
Validation loss: 2.4024961841882417

Epoch: 6| Step: 6
Training loss: 1.4307315537088277
Validation loss: 2.4377583912888316

Epoch: 6| Step: 7
Training loss: 2.007631286280634
Validation loss: 2.470181786338032

Epoch: 6| Step: 8
Training loss: 2.0498037569971683
Validation loss: 2.4572968614843247

Epoch: 6| Step: 9
Training loss: 1.4899922145409688
Validation loss: 2.4794529314152545

Epoch: 6| Step: 10
Training loss: 2.2055049513556075
Validation loss: 2.5018695675399187

Epoch: 6| Step: 11
Training loss: 1.9905542597635018
Validation loss: 2.528741009090152

Epoch: 6| Step: 12
Training loss: 1.938089650166031
Validation loss: 2.5056083872634427

Epoch: 6| Step: 13
Training loss: 2.3706061224735198
Validation loss: 2.481907785058694

Epoch: 92| Step: 0
Training loss: 1.9762183330780778
Validation loss: 2.4607746211651427

Epoch: 6| Step: 1
Training loss: 1.940179571610789
Validation loss: 2.42338557561771

Epoch: 6| Step: 2
Training loss: 1.159290954340275
Validation loss: 2.420535465721633

Epoch: 6| Step: 3
Training loss: 1.2030047071686671
Validation loss: 2.403298776905472

Epoch: 6| Step: 4
Training loss: 1.8437487068818295
Validation loss: 2.3890145223193993

Epoch: 6| Step: 5
Training loss: 2.2398443971811934
Validation loss: 2.4178941065000763

Epoch: 6| Step: 6
Training loss: 1.8436440906171212
Validation loss: 2.424386115222825

Epoch: 6| Step: 7
Training loss: 1.8179935861816408
Validation loss: 2.4289775273108125

Epoch: 6| Step: 8
Training loss: 1.6491440980641472
Validation loss: 2.402227424761906

Epoch: 6| Step: 9
Training loss: 1.865679846489359
Validation loss: 2.4544175583766745

Epoch: 6| Step: 10
Training loss: 2.2549100917985014
Validation loss: 2.4612141610102154

Epoch: 6| Step: 11
Training loss: 2.3717405137847147
Validation loss: 2.503408611675206

Epoch: 6| Step: 12
Training loss: 1.9466162299890262
Validation loss: 2.528778604360436

Epoch: 6| Step: 13
Training loss: 1.908190630556587
Validation loss: 2.5670162039298474

Epoch: 93| Step: 0
Training loss: 1.92244308883503
Validation loss: 2.511786057048482

Epoch: 6| Step: 1
Training loss: 1.7280795651856025
Validation loss: 2.502624897998335

Epoch: 6| Step: 2
Training loss: 1.5502654402083438
Validation loss: 2.461840234920817

Epoch: 6| Step: 3
Training loss: 1.8624430756542574
Validation loss: 2.4723686384450967

Epoch: 6| Step: 4
Training loss: 1.7215736776291317
Validation loss: 2.4292396549712403

Epoch: 6| Step: 5
Training loss: 2.1687203968677102
Validation loss: 2.398818798592663

Epoch: 6| Step: 6
Training loss: 1.8524057262901343
Validation loss: 2.3891270251445405

Epoch: 6| Step: 7
Training loss: 1.8355468983801406
Validation loss: 2.39710157799791

Epoch: 6| Step: 8
Training loss: 1.5760826265198395
Validation loss: 2.4432260389002356

Epoch: 6| Step: 9
Training loss: 2.6441969329162958
Validation loss: 2.4043147243701775

Epoch: 6| Step: 10
Training loss: 1.942684129115899
Validation loss: 2.4158522176207335

Epoch: 6| Step: 11
Training loss: 1.8100391651363217
Validation loss: 2.399575591973771

Epoch: 6| Step: 12
Training loss: 1.5837947106316541
Validation loss: 2.4011897760636933

Epoch: 6| Step: 13
Training loss: 1.764764964526478
Validation loss: 2.3824299989966167

Epoch: 94| Step: 0
Training loss: 1.488023550395824
Validation loss: 2.4533693390342965

Epoch: 6| Step: 1
Training loss: 1.5378712337745128
Validation loss: 2.4700631299104483

Epoch: 6| Step: 2
Training loss: 2.0598527507560735
Validation loss: 2.552355947660941

Epoch: 6| Step: 3
Training loss: 2.234906540181752
Validation loss: 2.5678251187046697

Epoch: 6| Step: 4
Training loss: 1.9797994171036901
Validation loss: 2.5841184827816215

Epoch: 6| Step: 5
Training loss: 1.4811723390976184
Validation loss: 2.5447082586018346

Epoch: 6| Step: 6
Training loss: 1.9832454079551145
Validation loss: 2.4721102641563495

Epoch: 6| Step: 7
Training loss: 1.6334895870179265
Validation loss: 2.4475977155527326

Epoch: 6| Step: 8
Training loss: 2.125157069964826
Validation loss: 2.452355144563785

Epoch: 6| Step: 9
Training loss: 1.7151671085185964
Validation loss: 2.4174649191792716

Epoch: 6| Step: 10
Training loss: 1.5128124135093608
Validation loss: 2.4082784318660995

Epoch: 6| Step: 11
Training loss: 2.1940053937875246
Validation loss: 2.4467898000383475

Epoch: 6| Step: 12
Training loss: 2.09071061168599
Validation loss: 2.436323110006371

Epoch: 6| Step: 13
Training loss: 1.6384450325800914
Validation loss: 2.4123277325965997

Epoch: 95| Step: 0
Training loss: 1.621028007185362
Validation loss: 2.4135204970071147

Epoch: 6| Step: 1
Training loss: 1.2170502963616177
Validation loss: 2.411309459421849

Epoch: 6| Step: 2
Training loss: 1.6544418541659052
Validation loss: 2.425999040394316

Epoch: 6| Step: 3
Training loss: 1.7965335023868507
Validation loss: 2.412080076299689

Epoch: 6| Step: 4
Training loss: 1.727824858664216
Validation loss: 2.414110851935267

Epoch: 6| Step: 5
Training loss: 1.7291694395969939
Validation loss: 2.4436312533615405

Epoch: 6| Step: 6
Training loss: 2.13815778014148
Validation loss: 2.4633771318543327

Epoch: 6| Step: 7
Training loss: 1.989818765448209
Validation loss: 2.436307330030297

Epoch: 6| Step: 8
Training loss: 1.5307126562113544
Validation loss: 2.4767825713789113

Epoch: 6| Step: 9
Training loss: 1.789186831489337
Validation loss: 2.5272029658652873

Epoch: 6| Step: 10
Training loss: 2.3550012735092056
Validation loss: 2.566169499470805

Epoch: 6| Step: 11
Training loss: 2.1656970519923373
Validation loss: 2.556510896745191

Epoch: 6| Step: 12
Training loss: 1.896057898108208
Validation loss: 2.56820932779184

Epoch: 6| Step: 13
Training loss: 1.8866723096356512
Validation loss: 2.5182780695325095

Epoch: 96| Step: 0
Training loss: 1.710918478664064
Validation loss: 2.513054918970519

Epoch: 6| Step: 1
Training loss: 1.643485708710148
Validation loss: 2.4900396612499116

Epoch: 6| Step: 2
Training loss: 1.0102339641654876
Validation loss: 2.451615778431423

Epoch: 6| Step: 3
Training loss: 1.742659705791469
Validation loss: 2.3992673699419074

Epoch: 6| Step: 4
Training loss: 1.3444330120826626
Validation loss: 2.4334158140948507

Epoch: 6| Step: 5
Training loss: 2.3628529562511904
Validation loss: 2.452914510390864

Epoch: 6| Step: 6
Training loss: 2.1935548092333685
Validation loss: 2.3926242621508216

Epoch: 6| Step: 7
Training loss: 1.9198241417536164
Validation loss: 2.433933901703502

Epoch: 6| Step: 8
Training loss: 1.6094524772290546
Validation loss: 2.407356354655744

Epoch: 6| Step: 9
Training loss: 1.7600040591800004
Validation loss: 2.409842076528854

Epoch: 6| Step: 10
Training loss: 2.150834289850108
Validation loss: 2.42043938695123

Epoch: 6| Step: 11
Training loss: 2.128391700647293
Validation loss: 2.4409149896367346

Epoch: 6| Step: 12
Training loss: 1.2954009537813918
Validation loss: 2.419666456403389

Epoch: 6| Step: 13
Training loss: 1.774609753866657
Validation loss: 2.41611175633684

Epoch: 97| Step: 0
Training loss: 1.5949895189951393
Validation loss: 2.420201812636407

Epoch: 6| Step: 1
Training loss: 1.7603804755770056
Validation loss: 2.429598889467641

Epoch: 6| Step: 2
Training loss: 1.517737185121718
Validation loss: 2.428184412323884

Epoch: 6| Step: 3
Training loss: 1.4841795140088232
Validation loss: 2.3992900679205453

Epoch: 6| Step: 4
Training loss: 2.0784127172478937
Validation loss: 2.414317170076866

Epoch: 6| Step: 5
Training loss: 1.9717162054722468
Validation loss: 2.47306371207203

Epoch: 6| Step: 6
Training loss: 2.003003487792004
Validation loss: 2.414420059208916

Epoch: 6| Step: 7
Training loss: 1.2482883655528172
Validation loss: 2.462645778439712

Epoch: 6| Step: 8
Training loss: 1.2350753535707053
Validation loss: 2.4947281486267068

Epoch: 6| Step: 9
Training loss: 2.5070092171437564
Validation loss: 2.524785959972995

Epoch: 6| Step: 10
Training loss: 2.0430091284997483
Validation loss: 2.5199097341689396

Epoch: 6| Step: 11
Training loss: 1.7055940142564072
Validation loss: 2.503410659282349

Epoch: 6| Step: 12
Training loss: 2.0670448859535866
Validation loss: 2.4784661005762265

Epoch: 6| Step: 13
Training loss: 1.9664714888798027
Validation loss: 2.481085112479586

Epoch: 98| Step: 0
Training loss: 1.8783964548051513
Validation loss: 2.438317740445485

Epoch: 6| Step: 1
Training loss: 1.9982183388442825
Validation loss: 2.4391992140061283

Epoch: 6| Step: 2
Training loss: 2.100522602993949
Validation loss: 2.4164360418661044

Epoch: 6| Step: 3
Training loss: 1.7391919440038148
Validation loss: 2.414454143404431

Epoch: 6| Step: 4
Training loss: 1.6200617067335021
Validation loss: 2.4100014726019614

Epoch: 6| Step: 5
Training loss: 1.8927636778960413
Validation loss: 2.436681218666984

Epoch: 6| Step: 6
Training loss: 2.043454406080303
Validation loss: 2.418363375653516

Epoch: 6| Step: 7
Training loss: 1.5401577223478256
Validation loss: 2.4253072393263886

Epoch: 6| Step: 8
Training loss: 1.904073692350238
Validation loss: 2.4300549751572658

Epoch: 6| Step: 9
Training loss: 1.718877406166539
Validation loss: 2.4292657614943804

Epoch: 6| Step: 10
Training loss: 1.5595716119329668
Validation loss: 2.463516377701647

Epoch: 6| Step: 11
Training loss: 1.6918141355583072
Validation loss: 2.516132027213021

Epoch: 6| Step: 12
Training loss: 2.16024112362225
Validation loss: 2.52071469923667

Epoch: 6| Step: 13
Training loss: 1.701180283955968
Validation loss: 2.5495126246022366

Epoch: 99| Step: 0
Training loss: 1.6727268508771131
Validation loss: 2.500674411088787

Epoch: 6| Step: 1
Training loss: 1.682814769690213
Validation loss: 2.5407075531494963

Epoch: 6| Step: 2
Training loss: 1.3803126265750523
Validation loss: 2.4673122211005873

Epoch: 6| Step: 3
Training loss: 1.3509705410335484
Validation loss: 2.479695269118383

Epoch: 6| Step: 4
Training loss: 2.257417743320648
Validation loss: 2.466018952781816

Epoch: 6| Step: 5
Training loss: 1.6001667919245635
Validation loss: 2.4331745094784183

Epoch: 6| Step: 6
Training loss: 1.3498758364905419
Validation loss: 2.4167843220012086

Epoch: 6| Step: 7
Training loss: 1.8699261998592143
Validation loss: 2.4438122421884603

Epoch: 6| Step: 8
Training loss: 2.731406556973894
Validation loss: 2.3833283246483448

Epoch: 6| Step: 9
Training loss: 2.081471323153434
Validation loss: 2.4227194759676767

Epoch: 6| Step: 10
Training loss: 1.6707087932541353
Validation loss: 2.421962843091495

Epoch: 6| Step: 11
Training loss: 1.794017210938432
Validation loss: 2.454579256367658

Epoch: 6| Step: 12
Training loss: 1.7898673699967143
Validation loss: 2.4472087377546443

Epoch: 6| Step: 13
Training loss: 1.4023421348626233
Validation loss: 2.440359451689654

Epoch: 100| Step: 0
Training loss: 1.4160221915257227
Validation loss: 2.4647244738431855

Epoch: 6| Step: 1
Training loss: 1.7805039031176915
Validation loss: 2.484563312551144

Epoch: 6| Step: 2
Training loss: 2.316496411477827
Validation loss: 2.5268978332801297

Epoch: 6| Step: 3
Training loss: 1.7118564036746067
Validation loss: 2.4653030265864317

Epoch: 6| Step: 4
Training loss: 1.6620474780309755
Validation loss: 2.4777921157212046

Epoch: 6| Step: 5
Training loss: 2.2438737330415863
Validation loss: 2.4779438935558646

Epoch: 6| Step: 6
Training loss: 1.313824893185046
Validation loss: 2.4646202586598336

Epoch: 6| Step: 7
Training loss: 2.1812314270453004
Validation loss: 2.4342150356898498

Epoch: 6| Step: 8
Training loss: 1.9126525668456311
Validation loss: 2.411321736388109

Epoch: 6| Step: 9
Training loss: 1.31942615440586
Validation loss: 2.424569663309555

Epoch: 6| Step: 10
Training loss: 1.508850214931838
Validation loss: 2.4007141375344707

Epoch: 6| Step: 11
Training loss: 1.8649569160250756
Validation loss: 2.397753962927455

Epoch: 6| Step: 12
Training loss: 1.7949489720139091
Validation loss: 2.414934932748347

Epoch: 6| Step: 13
Training loss: 1.7335817739752937
Validation loss: 2.38875488403183

Epoch: 101| Step: 0
Training loss: 2.2699672785681875
Validation loss: 2.4284700244281168

Epoch: 6| Step: 1
Training loss: 2.171531595209736
Validation loss: 2.4746376122296523

Epoch: 6| Step: 2
Training loss: 1.7642354307736663
Validation loss: 2.4683477420072957

Epoch: 6| Step: 3
Training loss: 1.5879063153870012
Validation loss: 2.4998617769812883

Epoch: 6| Step: 4
Training loss: 1.9159387228928724
Validation loss: 2.4627402186821823

Epoch: 6| Step: 5
Training loss: 1.566957295968501
Validation loss: 2.4914404248596833

Epoch: 6| Step: 6
Training loss: 1.0114360988908728
Validation loss: 2.4398270608765023

Epoch: 6| Step: 7
Training loss: 1.2851658968577906
Validation loss: 2.450663382383594

Epoch: 6| Step: 8
Training loss: 1.5170820645469607
Validation loss: 2.492161510495445

Epoch: 6| Step: 9
Training loss: 2.42024382757947
Validation loss: 2.4382347727490146

Epoch: 6| Step: 10
Training loss: 1.9935590024721843
Validation loss: 2.483106093175872

Epoch: 6| Step: 11
Training loss: 1.3611403654592065
Validation loss: 2.4455913023199503

Epoch: 6| Step: 12
Training loss: 1.3291794574006517
Validation loss: 2.442896086764284

Epoch: 6| Step: 13
Training loss: 1.7208357899473572
Validation loss: 2.416979750270505

Epoch: 102| Step: 0
Training loss: 1.5917002642748805
Validation loss: 2.448380054415881

Epoch: 6| Step: 1
Training loss: 1.8413189523790436
Validation loss: 2.396236523965278

Epoch: 6| Step: 2
Training loss: 1.8420217787317672
Validation loss: 2.4363178908007903

Epoch: 6| Step: 3
Training loss: 1.8051728095602062
Validation loss: 2.433304003534399

Epoch: 6| Step: 4
Training loss: 2.1268151328701603
Validation loss: 2.4633256334959626

Epoch: 6| Step: 5
Training loss: 1.3168433394787988
Validation loss: 2.453376943362192

Epoch: 6| Step: 6
Training loss: 1.672127178817234
Validation loss: 2.4029405467689697

Epoch: 6| Step: 7
Training loss: 1.548522534234482
Validation loss: 2.42983946166585

Epoch: 6| Step: 8
Training loss: 1.562250727796942
Validation loss: 2.424330100705594

Epoch: 6| Step: 9
Training loss: 1.4040795849173062
Validation loss: 2.47300458225289

Epoch: 6| Step: 10
Training loss: 2.0214443921544096
Validation loss: 2.4089148573919497

Epoch: 6| Step: 11
Training loss: 2.549000981925934
Validation loss: 2.4024936536214883

Epoch: 6| Step: 12
Training loss: 1.230250069698649
Validation loss: 2.4263543656451634

Epoch: 6| Step: 13
Training loss: 1.2049702946970497
Validation loss: 2.4674628238009593

Epoch: 103| Step: 0
Training loss: 2.0664968200334237
Validation loss: 2.494041399076041

Epoch: 6| Step: 1
Training loss: 1.6526488976045886
Validation loss: 2.48205159464851

Epoch: 6| Step: 2
Training loss: 1.8841291074230344
Validation loss: 2.469037341042908

Epoch: 6| Step: 3
Training loss: 2.131689873102532
Validation loss: 2.481363394489897

Epoch: 6| Step: 4
Training loss: 1.3076882489063744
Validation loss: 2.4870672293578524

Epoch: 6| Step: 5
Training loss: 1.6365009609071572
Validation loss: 2.513397083216001

Epoch: 6| Step: 6
Training loss: 1.2583380128550306
Validation loss: 2.44387523268449

Epoch: 6| Step: 7
Training loss: 1.756798481396156
Validation loss: 2.430002500797026

Epoch: 6| Step: 8
Training loss: 1.742470688320223
Validation loss: 2.41165454195354

Epoch: 6| Step: 9
Training loss: 1.8335252863646374
Validation loss: 2.471384678696834

Epoch: 6| Step: 10
Training loss: 1.824918886237198
Validation loss: 2.410781062175168

Epoch: 6| Step: 11
Training loss: 1.2596590691975238
Validation loss: 2.4049585931138573

Epoch: 6| Step: 12
Training loss: 2.0033654269516155
Validation loss: 2.461858264291279

Epoch: 6| Step: 13
Training loss: 1.2481367529562617
Validation loss: 2.4122350662575167

Epoch: 104| Step: 0
Training loss: 1.5008130254365286
Validation loss: 2.3912457593078287

Epoch: 6| Step: 1
Training loss: 1.87227776322707
Validation loss: 2.406470268043124

Epoch: 6| Step: 2
Training loss: 1.718916867565537
Validation loss: 2.4400202445977857

Epoch: 6| Step: 3
Training loss: 1.3061714185231013
Validation loss: 2.445995913749852

Epoch: 6| Step: 4
Training loss: 1.7672588924217154
Validation loss: 2.443078967988201

Epoch: 6| Step: 5
Training loss: 1.3959092883420476
Validation loss: 2.467965834453777

Epoch: 6| Step: 6
Training loss: 1.8250456738962044
Validation loss: 2.504866695042364

Epoch: 6| Step: 7
Training loss: 2.0699748213706366
Validation loss: 2.399214329866085

Epoch: 6| Step: 8
Training loss: 1.7781044474454786
Validation loss: 2.4576641050091106

Epoch: 6| Step: 9
Training loss: 1.633518632122229
Validation loss: 2.4328244107117554

Epoch: 6| Step: 10
Training loss: 1.33891010285205
Validation loss: 2.4310765767618214

Epoch: 6| Step: 11
Training loss: 2.3408143031902946
Validation loss: 2.4276131855185286

Epoch: 6| Step: 12
Training loss: 1.5678472953708096
Validation loss: 2.492270696481056

Epoch: 6| Step: 13
Training loss: 1.590711202327885
Validation loss: 2.473272711798372

Epoch: 105| Step: 0
Training loss: 1.6295374098045103
Validation loss: 2.470930673527015

Epoch: 6| Step: 1
Training loss: 2.58395180425783
Validation loss: 2.4674261221346723

Epoch: 6| Step: 2
Training loss: 1.4409502336696003
Validation loss: 2.5444046396596702

Epoch: 6| Step: 3
Training loss: 1.8840703284587694
Validation loss: 2.5051678332401224

Epoch: 6| Step: 4
Training loss: 1.909044000433256
Validation loss: 2.5286721811909096

Epoch: 6| Step: 5
Training loss: 1.5889999812458053
Validation loss: 2.48866432710516

Epoch: 6| Step: 6
Training loss: 1.3804552061391258
Validation loss: 2.432613757179687

Epoch: 6| Step: 7
Training loss: 1.769278400873982
Validation loss: 2.414883553176809

Epoch: 6| Step: 8
Training loss: 1.6509595623921418
Validation loss: 2.430739425486044

Epoch: 6| Step: 9
Training loss: 1.8241630725409852
Validation loss: 2.48121112117207

Epoch: 6| Step: 10
Training loss: 1.2790644543761218
Validation loss: 2.384277060427529

Epoch: 6| Step: 11
Training loss: 1.729876483631304
Validation loss: 2.402581312223988

Epoch: 6| Step: 12
Training loss: 1.3994548655895065
Validation loss: 2.441203621148521

Epoch: 6| Step: 13
Training loss: 1.6086883561566194
Validation loss: 2.464579927297535

Epoch: 106| Step: 0
Training loss: 1.826411104087309
Validation loss: 2.4561010802521777

Epoch: 6| Step: 1
Training loss: 1.0669060398764292
Validation loss: 2.513792693567373

Epoch: 6| Step: 2
Training loss: 2.258696914158807
Validation loss: 2.5422294702330253

Epoch: 6| Step: 3
Training loss: 1.7601513032466967
Validation loss: 2.5468002495590767

Epoch: 6| Step: 4
Training loss: 2.270729995849417
Validation loss: 2.483621783006825

Epoch: 6| Step: 5
Training loss: 1.3412869968626702
Validation loss: 2.4581238339483846

Epoch: 6| Step: 6
Training loss: 1.522938729825214
Validation loss: 2.427590220379308

Epoch: 6| Step: 7
Training loss: 1.131277425444085
Validation loss: 2.3966337000454625

Epoch: 6| Step: 8
Training loss: 1.6520848713980303
Validation loss: 2.456721105847985

Epoch: 6| Step: 9
Training loss: 1.4880750618429688
Validation loss: 2.477754436429546

Epoch: 6| Step: 10
Training loss: 1.8656443200317088
Validation loss: 2.4437380628627605

Epoch: 6| Step: 11
Training loss: 1.938682441444356
Validation loss: 2.4214430310988018

Epoch: 6| Step: 12
Training loss: 1.2736255530302716
Validation loss: 2.423861716235178

Epoch: 6| Step: 13
Training loss: 1.4567140944824983
Validation loss: 2.433948268550129

Epoch: 107| Step: 0
Training loss: 1.9040274248472138
Validation loss: 2.4284500045300614

Epoch: 6| Step: 1
Training loss: 1.4436500679869857
Validation loss: 2.4187629640217017

Epoch: 6| Step: 2
Training loss: 1.0932500514046364
Validation loss: 2.4221268881790614

Epoch: 6| Step: 3
Training loss: 2.0330174899120594
Validation loss: 2.4262306096125767

Epoch: 6| Step: 4
Training loss: 1.1814448423001576
Validation loss: 2.444424046325347

Epoch: 6| Step: 5
Training loss: 2.1183023930812936
Validation loss: 2.483007858589632

Epoch: 6| Step: 6
Training loss: 1.5194694290726058
Validation loss: 2.4541881063806095

Epoch: 6| Step: 7
Training loss: 1.4959609169419168
Validation loss: 2.462918076953367

Epoch: 6| Step: 8
Training loss: 1.9610790186421347
Validation loss: 2.521959492001884

Epoch: 6| Step: 9
Training loss: 1.1379669781940436
Validation loss: 2.48340590987517

Epoch: 6| Step: 10
Training loss: 1.6291917875390598
Validation loss: 2.4892147514935794

Epoch: 6| Step: 11
Training loss: 1.9339297224292216
Validation loss: 2.451939517081617

Epoch: 6| Step: 12
Training loss: 1.4897557761228701
Validation loss: 2.451684776030079

Epoch: 6| Step: 13
Training loss: 1.6997795494979575
Validation loss: 2.4414926742515677

Epoch: 108| Step: 0
Training loss: 1.5158505616022522
Validation loss: 2.47053248604016

Epoch: 6| Step: 1
Training loss: 1.3137709503971466
Validation loss: 2.4892782452656235

Epoch: 6| Step: 2
Training loss: 1.4667633093436026
Validation loss: 2.4787090397392344

Epoch: 6| Step: 3
Training loss: 1.8765551157987914
Validation loss: 2.4249893345549127

Epoch: 6| Step: 4
Training loss: 1.633225238233383
Validation loss: 2.4126705119302714

Epoch: 6| Step: 5
Training loss: 1.471395018243957
Validation loss: 2.444489516278608

Epoch: 6| Step: 6
Training loss: 1.2759337035717566
Validation loss: 2.442320662089922

Epoch: 6| Step: 7
Training loss: 2.3979565265523193
Validation loss: 2.4670411485070782

Epoch: 6| Step: 8
Training loss: 1.7391266899224058
Validation loss: 2.4788458373471416

Epoch: 6| Step: 9
Training loss: 1.5672293994965645
Validation loss: 2.5387734586081723

Epoch: 6| Step: 10
Training loss: 1.685654796977713
Validation loss: 2.450095361034472

Epoch: 6| Step: 11
Training loss: 1.705555502711712
Validation loss: 2.468962076791753

Epoch: 6| Step: 12
Training loss: 1.1889625376966857
Validation loss: 2.4791049361891586

Epoch: 6| Step: 13
Training loss: 1.3934847968578978
Validation loss: 2.462103479672757

Epoch: 109| Step: 0
Training loss: 1.5447298839695927
Validation loss: 2.5186185775685805

Epoch: 6| Step: 1
Training loss: 1.5549977055376303
Validation loss: 2.4737071716240413

Epoch: 6| Step: 2
Training loss: 1.5356182150716098
Validation loss: 2.450813767818665

Epoch: 6| Step: 3
Training loss: 1.828507864221941
Validation loss: 2.463533056027699

Epoch: 6| Step: 4
Training loss: 1.5351539980651023
Validation loss: 2.438193027082211

Epoch: 6| Step: 5
Training loss: 2.3733776976514354
Validation loss: 2.4057560616048557

Epoch: 6| Step: 6
Training loss: 1.7233739210006291
Validation loss: 2.475079386173281

Epoch: 6| Step: 7
Training loss: 1.428078585147987
Validation loss: 2.5048207533735347

Epoch: 6| Step: 8
Training loss: 1.0930784616220484
Validation loss: 2.4710247649667085

Epoch: 6| Step: 9
Training loss: 1.7103565919511812
Validation loss: 2.476353344674393

Epoch: 6| Step: 10
Training loss: 1.2198763801917918
Validation loss: 2.483306559049253

Epoch: 6| Step: 11
Training loss: 1.6018106407902823
Validation loss: 2.4985514894922867

Epoch: 6| Step: 12
Training loss: 1.840538072071554
Validation loss: 2.5238250655255245

Epoch: 6| Step: 13
Training loss: 1.4770956540187963
Validation loss: 2.452527404694261

Epoch: 110| Step: 0
Training loss: 1.7562970898380028
Validation loss: 2.5197033096430017

Epoch: 6| Step: 1
Training loss: 2.0222358817849044
Validation loss: 2.4238757411348497

Epoch: 6| Step: 2
Training loss: 1.3584191480493455
Validation loss: 2.42318964727234

Epoch: 6| Step: 3
Training loss: 1.4850600418642657
Validation loss: 2.447597959075765

Epoch: 6| Step: 4
Training loss: 1.7367906673091038
Validation loss: 2.475069889854303

Epoch: 6| Step: 5
Training loss: 1.6633044741591765
Validation loss: 2.400905478387778

Epoch: 6| Step: 6
Training loss: 1.9556786284708605
Validation loss: 2.4834190304795274

Epoch: 6| Step: 7
Training loss: 1.4325141687674445
Validation loss: 2.4283988781812433

Epoch: 6| Step: 8
Training loss: 1.3395948262213564
Validation loss: 2.4082381799461197

Epoch: 6| Step: 9
Training loss: 1.1419630693820972
Validation loss: 2.4589910812629876

Epoch: 6| Step: 10
Training loss: 1.49517459372973
Validation loss: 2.537681783231348

Epoch: 6| Step: 11
Training loss: 1.690468120523708
Validation loss: 2.527952801813076

Epoch: 6| Step: 12
Training loss: 2.1817575558273354
Validation loss: 2.563715452658606

Epoch: 6| Step: 13
Training loss: 0.7738794547574952
Validation loss: 2.531267048342714

Epoch: 111| Step: 0
Training loss: 1.4995275389154479
Validation loss: 2.4745999250505033

Epoch: 6| Step: 1
Training loss: 0.9030846530653214
Validation loss: 2.5020544987990836

Epoch: 6| Step: 2
Training loss: 1.43899872645785
Validation loss: 2.489579577157181

Epoch: 6| Step: 3
Training loss: 1.7240451049480299
Validation loss: 2.4335605053700045

Epoch: 6| Step: 4
Training loss: 1.3927539430890117
Validation loss: 2.47013373567591

Epoch: 6| Step: 5
Training loss: 1.3424247594168675
Validation loss: 2.466902512367216

Epoch: 6| Step: 6
Training loss: 1.6089551804003837
Validation loss: 2.497347664525992

Epoch: 6| Step: 7
Training loss: 1.6662741278284419
Validation loss: 2.448806233119831

Epoch: 6| Step: 8
Training loss: 1.5319030303445
Validation loss: 2.530102685633722

Epoch: 6| Step: 9
Training loss: 1.3081302562157842
Validation loss: 2.546432105562375

Epoch: 6| Step: 10
Training loss: 1.2976355563080622
Validation loss: 2.482530785069123

Epoch: 6| Step: 11
Training loss: 1.6105725915721367
Validation loss: 2.4753519141985003

Epoch: 6| Step: 12
Training loss: 1.507038214130042
Validation loss: 2.470239632497146

Epoch: 6| Step: 13
Training loss: 2.4274995526078635
Validation loss: 2.4331256054912513

Epoch: 112| Step: 0
Training loss: 1.51784934194147
Validation loss: 2.440885458776344

Epoch: 6| Step: 1
Training loss: 2.0505941832464107
Validation loss: 2.437334120233118

Epoch: 6| Step: 2
Training loss: 1.4140374197237382
Validation loss: 2.483269275462075

Epoch: 6| Step: 3
Training loss: 1.3157312490731523
Validation loss: 2.4828477239620854

Epoch: 6| Step: 4
Training loss: 1.3283021247784168
Validation loss: 2.461437775962848

Epoch: 6| Step: 5
Training loss: 1.215014773777437
Validation loss: 2.50453084613247

Epoch: 6| Step: 6
Training loss: 1.8993833720809428
Validation loss: 2.592217908255126

Epoch: 6| Step: 7
Training loss: 1.6959204923958906
Validation loss: 2.536568035492374

Epoch: 6| Step: 8
Training loss: 1.308319609665217
Validation loss: 2.487290628845559

Epoch: 6| Step: 9
Training loss: 1.6945507957699528
Validation loss: 2.514878701343104

Epoch: 6| Step: 10
Training loss: 1.391083631002023
Validation loss: 2.5173276111229956

Epoch: 6| Step: 11
Training loss: 1.2132346729542167
Validation loss: 2.476569110528605

Epoch: 6| Step: 12
Training loss: 1.4067587885740565
Validation loss: 2.4553707801142886

Epoch: 6| Step: 13
Training loss: 2.3859607348157
Validation loss: 2.4592140904499638

Epoch: 113| Step: 0
Training loss: 2.0850302334064006
Validation loss: 2.43924701065277

Epoch: 6| Step: 1
Training loss: 1.1249692700745477
Validation loss: 2.42513508567917

Epoch: 6| Step: 2
Training loss: 1.6959618937556973
Validation loss: 2.475205058455893

Epoch: 6| Step: 3
Training loss: 1.8556848661145728
Validation loss: 2.486356636676992

Epoch: 6| Step: 4
Training loss: 1.6012173164361407
Validation loss: 2.441549011125504

Epoch: 6| Step: 5
Training loss: 1.7706582225910363
Validation loss: 2.476921183928577

Epoch: 6| Step: 6
Training loss: 1.5671790445086347
Validation loss: 2.5078922468996

Epoch: 6| Step: 7
Training loss: 1.4711815206687453
Validation loss: 2.5249777424652815

Epoch: 6| Step: 8
Training loss: 1.4450496950150997
Validation loss: 2.5194181983680735

Epoch: 6| Step: 9
Training loss: 1.5459243473428832
Validation loss: 2.5270587302506984

Epoch: 6| Step: 10
Training loss: 1.5783754659881473
Validation loss: 2.5151574152427765

Epoch: 6| Step: 11
Training loss: 1.2388380465507447
Validation loss: 2.4504527867295134

Epoch: 6| Step: 12
Training loss: 1.1433541034854562
Validation loss: 2.4408986370076353

Epoch: 6| Step: 13
Training loss: 1.5377918555663321
Validation loss: 2.4820973253925693

Epoch: 114| Step: 0
Training loss: 1.9962750555961006
Validation loss: 2.487061525482398

Epoch: 6| Step: 1
Training loss: 1.2707225198845769
Validation loss: 2.4411379735413314

Epoch: 6| Step: 2
Training loss: 1.4933305925673357
Validation loss: 2.430815014993012

Epoch: 6| Step: 3
Training loss: 1.4436893731140645
Validation loss: 2.4743965858313817

Epoch: 6| Step: 4
Training loss: 1.5178999982922703
Validation loss: 2.443917287773931

Epoch: 6| Step: 5
Training loss: 1.9490448103911304
Validation loss: 2.4519870653812172

Epoch: 6| Step: 6
Training loss: 1.5330168203885561
Validation loss: 2.4589223129201256

Epoch: 6| Step: 7
Training loss: 1.5616714569610006
Validation loss: 2.458961815966649

Epoch: 6| Step: 8
Training loss: 1.4197081099300388
Validation loss: 2.5291947549164164

Epoch: 6| Step: 9
Training loss: 1.104776873608515
Validation loss: 2.5202181409596784

Epoch: 6| Step: 10
Training loss: 1.40187494203973
Validation loss: 2.5315578257821265

Epoch: 6| Step: 11
Training loss: 1.7566141748759174
Validation loss: 2.458785053281924

Epoch: 6| Step: 12
Training loss: 0.9535812786648769
Validation loss: 2.4745127381301177

Epoch: 6| Step: 13
Training loss: 1.5862576767515493
Validation loss: 2.432899518948601

Epoch: 115| Step: 0
Training loss: 1.1720870779777528
Validation loss: 2.448039783601222

Epoch: 6| Step: 1
Training loss: 1.6789512262581687
Validation loss: 2.4330173665059407

Epoch: 6| Step: 2
Training loss: 1.3073472192316355
Validation loss: 2.4718949771657384

Epoch: 6| Step: 3
Training loss: 1.3443283788027096
Validation loss: 2.476566695762313

Epoch: 6| Step: 4
Training loss: 2.131076986947702
Validation loss: 2.5142770634952365

Epoch: 6| Step: 5
Training loss: 1.773105136462915
Validation loss: 2.498665278494757

Epoch: 6| Step: 6
Training loss: 1.3885474813253227
Validation loss: 2.486884091675335

Epoch: 6| Step: 7
Training loss: 1.4142718081182837
Validation loss: 2.4508299894373846

Epoch: 6| Step: 8
Training loss: 1.0942857247739974
Validation loss: 2.547649008498769

Epoch: 6| Step: 9
Training loss: 1.6757344414991635
Validation loss: 2.5433391373577696

Epoch: 6| Step: 10
Training loss: 1.431516217789101
Validation loss: 2.5661327229846185

Epoch: 6| Step: 11
Training loss: 1.5265652362716968
Validation loss: 2.574976267905886

Epoch: 6| Step: 12
Training loss: 2.199310029813616
Validation loss: 2.570985669198362

Epoch: 6| Step: 13
Training loss: 1.0613525028398547
Validation loss: 2.4926719712823884

Epoch: 116| Step: 0
Training loss: 1.8524589460923007
Validation loss: 2.491810984456199

Epoch: 6| Step: 1
Training loss: 1.047769306861487
Validation loss: 2.484849592578314

Epoch: 6| Step: 2
Training loss: 1.629222738499459
Validation loss: 2.4811867303092363

Epoch: 6| Step: 3
Training loss: 1.425906909996565
Validation loss: 2.4365538366507105

Epoch: 6| Step: 4
Training loss: 1.4569875593001205
Validation loss: 2.4842075315448056

Epoch: 6| Step: 5
Training loss: 1.7190650651167507
Validation loss: 2.5269476743820074

Epoch: 6| Step: 6
Training loss: 1.5082850531057181
Validation loss: 2.488492756093193

Epoch: 6| Step: 7
Training loss: 2.124780194751231
Validation loss: 2.500277011147309

Epoch: 6| Step: 8
Training loss: 1.7350964119807315
Validation loss: 2.5224467991063353

Epoch: 6| Step: 9
Training loss: 1.2845413916999158
Validation loss: 2.5096993879194143

Epoch: 6| Step: 10
Training loss: 1.3983435572605467
Validation loss: 2.4924109826091425

Epoch: 6| Step: 11
Training loss: 1.3025189955162746
Validation loss: 2.4773112227254237

Epoch: 6| Step: 12
Training loss: 1.252083091714659
Validation loss: 2.446515682076383

Epoch: 6| Step: 13
Training loss: 1.001499898920992
Validation loss: 2.472057959163116

Epoch: 117| Step: 0
Training loss: 2.0950706074909062
Validation loss: 2.455619119151831

Epoch: 6| Step: 1
Training loss: 1.5008172352104165
Validation loss: 2.4141166211823624

Epoch: 6| Step: 2
Training loss: 1.5037519896027174
Validation loss: 2.424369421638876

Epoch: 6| Step: 3
Training loss: 1.8210106685478835
Validation loss: 2.431245065404596

Epoch: 6| Step: 4
Training loss: 1.275302387357296
Validation loss: 2.4305429618751386

Epoch: 6| Step: 5
Training loss: 0.804659352226904
Validation loss: 2.45184154911967

Epoch: 6| Step: 6
Training loss: 1.4058189579187812
Validation loss: 2.4449019082277954

Epoch: 6| Step: 7
Training loss: 1.3312292285426999
Validation loss: 2.511965931802098

Epoch: 6| Step: 8
Training loss: 1.4021479647941553
Validation loss: 2.4255094104574595

Epoch: 6| Step: 9
Training loss: 1.5542891102165701
Validation loss: 2.4478448627302827

Epoch: 6| Step: 10
Training loss: 1.4091387853152018
Validation loss: 2.449110338000933

Epoch: 6| Step: 11
Training loss: 1.403302982995818
Validation loss: 2.4920966471631223

Epoch: 6| Step: 12
Training loss: 1.319724318731212
Validation loss: 2.5085703812766753

Epoch: 6| Step: 13
Training loss: 1.7000723262435715
Validation loss: 2.539860972519456

Epoch: 118| Step: 0
Training loss: 1.0972092556623187
Validation loss: 2.5046129900565726

Epoch: 6| Step: 1
Training loss: 1.2415082501902786
Validation loss: 2.468797361346141

Epoch: 6| Step: 2
Training loss: 1.147253866788092
Validation loss: 2.5179213631945068

Epoch: 6| Step: 3
Training loss: 1.2838914671064594
Validation loss: 2.421892555747443

Epoch: 6| Step: 4
Training loss: 2.4348421522672714
Validation loss: 2.47400431272377

Epoch: 6| Step: 5
Training loss: 1.3751538364010827
Validation loss: 2.52881866608243

Epoch: 6| Step: 6
Training loss: 1.2491369128781953
Validation loss: 2.498639022400778

Epoch: 6| Step: 7
Training loss: 1.6671532953645118
Validation loss: 2.457072077231532

Epoch: 6| Step: 8
Training loss: 1.5183104487319574
Validation loss: 2.4855879855419407

Epoch: 6| Step: 9
Training loss: 1.134594219873271
Validation loss: 2.465506342170896

Epoch: 6| Step: 10
Training loss: 1.767340915000786
Validation loss: 2.471457642350921

Epoch: 6| Step: 11
Training loss: 1.7533919296094584
Validation loss: 2.4359019983431653

Epoch: 6| Step: 12
Training loss: 1.332642714138393
Validation loss: 2.443280807032867

Epoch: 6| Step: 13
Training loss: 1.3065112496091353
Validation loss: 2.4480627679174516

Epoch: 119| Step: 0
Training loss: 1.533599296944566
Validation loss: 2.528520713929504

Epoch: 6| Step: 1
Training loss: 1.222448946895081
Validation loss: 2.4737382703917152

Epoch: 6| Step: 2
Training loss: 1.463246606517502
Validation loss: 2.558380304416878

Epoch: 6| Step: 3
Training loss: 2.032774837065829
Validation loss: 2.5342776789796133

Epoch: 6| Step: 4
Training loss: 0.9528344133508965
Validation loss: 2.6092539395633403

Epoch: 6| Step: 5
Training loss: 1.4072784901342577
Validation loss: 2.554827018451105

Epoch: 6| Step: 6
Training loss: 1.3820204109556098
Validation loss: 2.5354838970196796

Epoch: 6| Step: 7
Training loss: 1.2917132317958235
Validation loss: 2.511514595084008

Epoch: 6| Step: 8
Training loss: 1.483654369302999
Validation loss: 2.521843342698574

Epoch: 6| Step: 9
Training loss: 1.2812475344006145
Validation loss: 2.4035654987922537

Epoch: 6| Step: 10
Training loss: 1.950682188183943
Validation loss: 2.4465679646764458

Epoch: 6| Step: 11
Training loss: 1.598874474064968
Validation loss: 2.4945277404282584

Epoch: 6| Step: 12
Training loss: 1.505975582720222
Validation loss: 2.502117325305452

Epoch: 6| Step: 13
Training loss: 1.2746678592920377
Validation loss: 2.4811816214901308

Epoch: 120| Step: 0
Training loss: 1.6336747224680856
Validation loss: 2.4546312377102395

Epoch: 6| Step: 1
Training loss: 1.6729749822211015
Validation loss: 2.447130285256802

Epoch: 6| Step: 2
Training loss: 1.8233513740655927
Validation loss: 2.4570783763221167

Epoch: 6| Step: 3
Training loss: 1.7922706325310234
Validation loss: 2.457854827820327

Epoch: 6| Step: 4
Training loss: 1.132713050423186
Validation loss: 2.5084447489566752

Epoch: 6| Step: 5
Training loss: 1.5410462583100693
Validation loss: 2.55271491714841

Epoch: 6| Step: 6
Training loss: 1.455015122246565
Validation loss: 2.497853772472152

Epoch: 6| Step: 7
Training loss: 1.3612550910174936
Validation loss: 2.506487859979503

Epoch: 6| Step: 8
Training loss: 1.2957271413845797
Validation loss: 2.5126990051281934

Epoch: 6| Step: 9
Training loss: 1.2265370360239944
Validation loss: 2.5037881919574887

Epoch: 6| Step: 10
Training loss: 1.2793429999735884
Validation loss: 2.4743247527098293

Epoch: 6| Step: 11
Training loss: 1.316148228926819
Validation loss: 2.4654001533927055

Epoch: 6| Step: 12
Training loss: 1.034913693206576
Validation loss: 2.4582291166122685

Epoch: 6| Step: 13
Training loss: 1.2180871383552931
Validation loss: 2.4814265847328234

Epoch: 121| Step: 0
Training loss: 1.563897995200483
Validation loss: 2.4581224356452918

Epoch: 6| Step: 1
Training loss: 0.8389448811586396
Validation loss: 2.465830908019212

Epoch: 6| Step: 2
Training loss: 1.1179962432061201
Validation loss: 2.496409858343977

Epoch: 6| Step: 3
Training loss: 1.3718196327663268
Validation loss: 2.4847898796635683

Epoch: 6| Step: 4
Training loss: 1.1575969376972348
Validation loss: 2.462011242302421

Epoch: 6| Step: 5
Training loss: 1.8367581744974628
Validation loss: 2.448610610538729

Epoch: 6| Step: 6
Training loss: 0.8767656155564267
Validation loss: 2.5006496539017293

Epoch: 6| Step: 7
Training loss: 1.6453336448071483
Validation loss: 2.5163679585646914

Epoch: 6| Step: 8
Training loss: 1.2962376510635185
Validation loss: 2.5279172770349225

Epoch: 6| Step: 9
Training loss: 1.1872500106287796
Validation loss: 2.576697260546282

Epoch: 6| Step: 10
Training loss: 1.1784703626276463
Validation loss: 2.559340226865234

Epoch: 6| Step: 11
Training loss: 1.997666905463858
Validation loss: 2.4802998482777725

Epoch: 6| Step: 12
Training loss: 1.8720328695883883
Validation loss: 2.534768018497523

Epoch: 6| Step: 13
Training loss: 1.281717168724929
Validation loss: 2.5235239334971933

Epoch: 122| Step: 0
Training loss: 1.21211844664316
Validation loss: 2.4846628530152515

Epoch: 6| Step: 1
Training loss: 1.7714738771911938
Validation loss: 2.4926843496705287

Epoch: 6| Step: 2
Training loss: 2.08894833785655
Validation loss: 2.528582497827287

Epoch: 6| Step: 3
Training loss: 1.4542560072655601
Validation loss: 2.516815212004743

Epoch: 6| Step: 4
Training loss: 1.1813260250755302
Validation loss: 2.519202435153625

Epoch: 6| Step: 5
Training loss: 1.6127152084928769
Validation loss: 2.491572097803852

Epoch: 6| Step: 6
Training loss: 1.048901603298615
Validation loss: 2.4467744204919177

Epoch: 6| Step: 7
Training loss: 1.3949627889777012
Validation loss: 2.4746040920250354

Epoch: 6| Step: 8
Training loss: 1.3330786382283244
Validation loss: 2.484294802093033

Epoch: 6| Step: 9
Training loss: 0.9527192111839875
Validation loss: 2.50973845589623

Epoch: 6| Step: 10
Training loss: 1.3599017646316378
Validation loss: 2.4996069281239652

Epoch: 6| Step: 11
Training loss: 1.1833933544159947
Validation loss: 2.532318988392695

Epoch: 6| Step: 12
Training loss: 1.3370295294308912
Validation loss: 2.601824482813684

Epoch: 6| Step: 13
Training loss: 1.342535712266166
Validation loss: 2.489146882003998

Epoch: 123| Step: 0
Training loss: 1.3064367936470092
Validation loss: 2.5751678692933777

Epoch: 6| Step: 1
Training loss: 1.5704549089071753
Validation loss: 2.5542346735784416

Epoch: 6| Step: 2
Training loss: 1.1465057423044798
Validation loss: 2.504263389695557

Epoch: 6| Step: 3
Training loss: 1.1449151030138134
Validation loss: 2.5458991242527205

Epoch: 6| Step: 4
Training loss: 1.1976799053685303
Validation loss: 2.444609795984091

Epoch: 6| Step: 5
Training loss: 1.4800644778047585
Validation loss: 2.5097853524982625

Epoch: 6| Step: 6
Training loss: 1.749839775380007
Validation loss: 2.5019343204471576

Epoch: 6| Step: 7
Training loss: 1.2025242085706576
Validation loss: 2.5209134118047767

Epoch: 6| Step: 8
Training loss: 0.9667186975178536
Validation loss: 2.4616324921829085

Epoch: 6| Step: 9
Training loss: 1.4880116135851584
Validation loss: 2.5219899721342056

Epoch: 6| Step: 10
Training loss: 1.0335659262674248
Validation loss: 2.492178746510024

Epoch: 6| Step: 11
Training loss: 1.3844438832800476
Validation loss: 2.513833697528691

Epoch: 6| Step: 12
Training loss: 2.1137988008520106
Validation loss: 2.5252027134365562

Epoch: 6| Step: 13
Training loss: 1.480429616124022
Validation loss: 2.4663847687021114

Epoch: 124| Step: 0
Training loss: 1.4271539638146562
Validation loss: 2.5319002595669606

Epoch: 6| Step: 1
Training loss: 0.9435697838205924
Validation loss: 2.5041820039030864

Epoch: 6| Step: 2
Training loss: 1.4570873750814761
Validation loss: 2.5239416038178106

Epoch: 6| Step: 3
Training loss: 1.298139254657499
Validation loss: 2.492868746898879

Epoch: 6| Step: 4
Training loss: 1.1797030618411701
Validation loss: 2.518419407809023

Epoch: 6| Step: 5
Training loss: 1.3474168647783111
Validation loss: 2.5411591778844143

Epoch: 6| Step: 6
Training loss: 1.8609467603067114
Validation loss: 2.518889116179621

Epoch: 6| Step: 7
Training loss: 1.364029905578682
Validation loss: 2.5147609450964237

Epoch: 6| Step: 8
Training loss: 0.864117351260299
Validation loss: 2.4754050485308032

Epoch: 6| Step: 9
Training loss: 1.3884151774107418
Validation loss: 2.4788016176067353

Epoch: 6| Step: 10
Training loss: 0.7904699633427462
Validation loss: 2.4745465245303073

Epoch: 6| Step: 11
Training loss: 1.9874932726860155
Validation loss: 2.4930295568000176

Epoch: 6| Step: 12
Training loss: 1.7103364489659627
Validation loss: 2.4542089606517483

Epoch: 6| Step: 13
Training loss: 1.1295926340457345
Validation loss: 2.523167244342812

Epoch: 125| Step: 0
Training loss: 1.148953120939456
Validation loss: 2.5048943849609833

Epoch: 6| Step: 1
Training loss: 0.8656261581798752
Validation loss: 2.492601964083607

Epoch: 6| Step: 2
Training loss: 1.6638695690085594
Validation loss: 2.4530650331979356

Epoch: 6| Step: 3
Training loss: 0.9502591683081703
Validation loss: 2.432051642022286

Epoch: 6| Step: 4
Training loss: 1.2963415680402495
Validation loss: 2.4313270785445913

Epoch: 6| Step: 5
Training loss: 1.0342665393586659
Validation loss: 2.4808845792232974

Epoch: 6| Step: 6
Training loss: 0.9934759709870132
Validation loss: 2.4772607599170327

Epoch: 6| Step: 7
Training loss: 1.472220439829837
Validation loss: 2.482986037933695

Epoch: 6| Step: 8
Training loss: 1.4358243712981136
Validation loss: 2.5065421732422464

Epoch: 6| Step: 9
Training loss: 1.2200847554861765
Validation loss: 2.49024602351238

Epoch: 6| Step: 10
Training loss: 1.6853812303185323
Validation loss: 2.5399470896228724

Epoch: 6| Step: 11
Training loss: 2.085354041176409
Validation loss: 2.506994524027288

Epoch: 6| Step: 12
Training loss: 1.5650008977332908
Validation loss: 2.4942526397604445

Epoch: 6| Step: 13
Training loss: 1.2290553134113544
Validation loss: 2.508886960758782

Epoch: 126| Step: 0
Training loss: 0.8570891758026205
Validation loss: 2.4429330105673737

Epoch: 6| Step: 1
Training loss: 1.4173556597115393
Validation loss: 2.5700133051942213

Epoch: 6| Step: 2
Training loss: 1.0099108829462256
Validation loss: 2.527947638176109

Epoch: 6| Step: 3
Training loss: 1.2867080919650045
Validation loss: 2.506116941539627

Epoch: 6| Step: 4
Training loss: 1.377400686695963
Validation loss: 2.4384340958060435

Epoch: 6| Step: 5
Training loss: 0.9680057250712684
Validation loss: 2.4522559535981974

Epoch: 6| Step: 6
Training loss: 2.139881088304329
Validation loss: 2.5083786274906603

Epoch: 6| Step: 7
Training loss: 1.508261974325754
Validation loss: 2.5726921869079615

Epoch: 6| Step: 8
Training loss: 1.2995230515076834
Validation loss: 2.4797232881882763

Epoch: 6| Step: 9
Training loss: 1.5853266549676914
Validation loss: 2.4693906250638515

Epoch: 6| Step: 10
Training loss: 1.2889055561124385
Validation loss: 2.4597217927665866

Epoch: 6| Step: 11
Training loss: 1.2807218812308934
Validation loss: 2.463966435164602

Epoch: 6| Step: 12
Training loss: 1.227669623206089
Validation loss: 2.4634887630489484

Epoch: 6| Step: 13
Training loss: 1.3484356823817232
Validation loss: 2.4899167565138782

Epoch: 127| Step: 0
Training loss: 1.3848029859315623
Validation loss: 2.481011935455343

Epoch: 6| Step: 1
Training loss: 1.434512226131083
Validation loss: 2.4086609771515968

Epoch: 6| Step: 2
Training loss: 1.2321840470894738
Validation loss: 2.5100298434455284

Epoch: 6| Step: 3
Training loss: 1.2134586300362231
Validation loss: 2.4942226252049493

Epoch: 6| Step: 4
Training loss: 1.3572120559231124
Validation loss: 2.5367551991489723

Epoch: 6| Step: 5
Training loss: 0.8460173342531893
Validation loss: 2.5715037390404643

Epoch: 6| Step: 6
Training loss: 1.035105059815501
Validation loss: 2.540551243110647

Epoch: 6| Step: 7
Training loss: 1.616098083059504
Validation loss: 2.5089614153627173

Epoch: 6| Step: 8
Training loss: 2.0072913773804877
Validation loss: 2.5240024686117137

Epoch: 6| Step: 9
Training loss: 1.4658445474449773
Validation loss: 2.564629081196153

Epoch: 6| Step: 10
Training loss: 1.1452278386944459
Validation loss: 2.5372316381426714

Epoch: 6| Step: 11
Training loss: 1.3812589809073972
Validation loss: 2.5244682261929903

Epoch: 6| Step: 12
Training loss: 1.183568922732983
Validation loss: 2.5109220183424776

Epoch: 6| Step: 13
Training loss: 1.1904580767706703
Validation loss: 2.4537279558349434

Epoch: 128| Step: 0
Training loss: 1.3092924615523949
Validation loss: 2.504099488798645

Epoch: 6| Step: 1
Training loss: 1.3649127455829584
Validation loss: 2.5532536658274396

Epoch: 6| Step: 2
Training loss: 1.5297429200401498
Validation loss: 2.532240371676256

Epoch: 6| Step: 3
Training loss: 0.9333878932627907
Validation loss: 2.5361030350656693

Epoch: 6| Step: 4
Training loss: 0.9838358901456628
Validation loss: 2.4846570636566083

Epoch: 6| Step: 5
Training loss: 1.185405993064378
Validation loss: 2.4847613500086454

Epoch: 6| Step: 6
Training loss: 1.0487366251041483
Validation loss: 2.5281290271980015

Epoch: 6| Step: 7
Training loss: 0.8585883962171003
Validation loss: 2.5202535692937733

Epoch: 6| Step: 8
Training loss: 1.687298515441889
Validation loss: 2.523833315643765

Epoch: 6| Step: 9
Training loss: 0.9137989544572566
Validation loss: 2.533857376290014

Epoch: 6| Step: 10
Training loss: 2.2481478379261173
Validation loss: 2.5046785366749114

Epoch: 6| Step: 11
Training loss: 1.1787302541848739
Validation loss: 2.4727394286875177

Epoch: 6| Step: 12
Training loss: 1.1856287216264856
Validation loss: 2.4916090418511057

Epoch: 6| Step: 13
Training loss: 1.9176733717942354
Validation loss: 2.497827348764001

Epoch: 129| Step: 0
Training loss: 1.1730376516024652
Validation loss: 2.533733985823924

Epoch: 6| Step: 1
Training loss: 1.4957869491540303
Validation loss: 2.518292294447053

Epoch: 6| Step: 2
Training loss: 1.3603902949551478
Validation loss: 2.520783287266157

Epoch: 6| Step: 3
Training loss: 1.276864104670246
Validation loss: 2.4920838592567858

Epoch: 6| Step: 4
Training loss: 1.2507059488020986
Validation loss: 2.5439550125025003

Epoch: 6| Step: 5
Training loss: 1.1514088086863237
Validation loss: 2.500366859539623

Epoch: 6| Step: 6
Training loss: 1.4368788994482755
Validation loss: 2.5078945602031673

Epoch: 6| Step: 7
Training loss: 1.8348470493154774
Validation loss: 2.532130963273675

Epoch: 6| Step: 8
Training loss: 1.1882075159595087
Validation loss: 2.5421429380681935

Epoch: 6| Step: 9
Training loss: 0.8840321580595694
Validation loss: 2.4990361978459266

Epoch: 6| Step: 10
Training loss: 1.5488278171303287
Validation loss: 2.4811162629106995

Epoch: 6| Step: 11
Training loss: 1.4650345741592776
Validation loss: 2.5049615819095417

Epoch: 6| Step: 12
Training loss: 1.0484650905293198
Validation loss: 2.5260230047316576

Epoch: 6| Step: 13
Training loss: 0.9448731086955273
Validation loss: 2.477033343718397

Epoch: 130| Step: 0
Training loss: 1.2963344412570286
Validation loss: 2.467391143118836

Epoch: 6| Step: 1
Training loss: 1.3997798423004617
Validation loss: 2.5347442840823753

Epoch: 6| Step: 2
Training loss: 1.0524490904104977
Validation loss: 2.554949623527005

Epoch: 6| Step: 3
Training loss: 0.944813052562409
Validation loss: 2.4350624938611323

Epoch: 6| Step: 4
Training loss: 2.0600536750541245
Validation loss: 2.4691766136896893

Epoch: 6| Step: 5
Training loss: 1.0130355101685062
Validation loss: 2.5555837227701876

Epoch: 6| Step: 6
Training loss: 1.141638057702982
Validation loss: 2.515132263452179

Epoch: 6| Step: 7
Training loss: 1.473527645456246
Validation loss: 2.5132007646465095

Epoch: 6| Step: 8
Training loss: 1.503838079319391
Validation loss: 2.5352213282527303

Epoch: 6| Step: 9
Training loss: 1.043674016231154
Validation loss: 2.565127661479621

Epoch: 6| Step: 10
Training loss: 0.9406009886455592
Validation loss: 2.5418659090420905

Epoch: 6| Step: 11
Training loss: 1.4196825835915141
Validation loss: 2.5521706365068138

Epoch: 6| Step: 12
Training loss: 0.5725360010313406
Validation loss: 2.4733665173374626

Epoch: 6| Step: 13
Training loss: 1.6228096945900177
Validation loss: 2.507430256424803

Epoch: 131| Step: 0
Training loss: 1.505442837550047
Validation loss: 2.475211471937921

Epoch: 6| Step: 1
Training loss: 1.3680789330169227
Validation loss: 2.5414184595036184

Epoch: 6| Step: 2
Training loss: 1.003433531851631
Validation loss: 2.5387964666820104

Epoch: 6| Step: 3
Training loss: 0.984387140350561
Validation loss: 2.4836553174987737

Epoch: 6| Step: 4
Training loss: 0.8658820972044377
Validation loss: 2.5009203408865837

Epoch: 6| Step: 5
Training loss: 0.9511870710032447
Validation loss: 2.4967717785560066

Epoch: 6| Step: 6
Training loss: 1.467773356282225
Validation loss: 2.471841558398196

Epoch: 6| Step: 7
Training loss: 1.6047279152242677
Validation loss: 2.571364843418352

Epoch: 6| Step: 8
Training loss: 1.2297784715905633
Validation loss: 2.4928264934773012

Epoch: 6| Step: 9
Training loss: 1.042999552868375
Validation loss: 2.5230283612181674

Epoch: 6| Step: 10
Training loss: 1.0747307129624735
Validation loss: 2.563618826657572

Epoch: 6| Step: 11
Training loss: 0.8758477463944272
Validation loss: 2.4824325997485843

Epoch: 6| Step: 12
Training loss: 1.9713734903400542
Validation loss: 2.5226051997216126

Epoch: 6| Step: 13
Training loss: 1.559847296552458
Validation loss: 2.564750226124763

Epoch: 132| Step: 0
Training loss: 1.370963413749247
Validation loss: 2.6079104381323766

Epoch: 6| Step: 1
Training loss: 1.4295067177795135
Validation loss: 2.5831964415509874

Epoch: 6| Step: 2
Training loss: 0.9789580907589313
Validation loss: 2.514324325858771

Epoch: 6| Step: 3
Training loss: 1.8859473126273887
Validation loss: 2.5323055876319547

Epoch: 6| Step: 4
Training loss: 1.052989921623029
Validation loss: 2.5250477333089343

Epoch: 6| Step: 5
Training loss: 1.4887969958160772
Validation loss: 2.5298713885853155

Epoch: 6| Step: 6
Training loss: 1.1027785278518478
Validation loss: 2.5501161714033924

Epoch: 6| Step: 7
Training loss: 1.2112625178112477
Validation loss: 2.4791764384699557

Epoch: 6| Step: 8
Training loss: 1.2224302235292226
Validation loss: 2.4864950910604544

Epoch: 6| Step: 9
Training loss: 1.096543858201992
Validation loss: 2.4915891624653064

Epoch: 6| Step: 10
Training loss: 1.214689484151285
Validation loss: 2.4694883312859246

Epoch: 6| Step: 11
Training loss: 1.561472745815723
Validation loss: 2.5277881103928586

Epoch: 6| Step: 12
Training loss: 0.6850752118162149
Validation loss: 2.5056319853362634

Epoch: 6| Step: 13
Training loss: 1.0847637502058598
Validation loss: 2.4394231692109667

Epoch: 133| Step: 0
Training loss: 1.221842485858684
Validation loss: 2.4856240993079597

Epoch: 6| Step: 1
Training loss: 1.0959978710174767
Validation loss: 2.5086849671661997

Epoch: 6| Step: 2
Training loss: 1.353370647730303
Validation loss: 2.517786901718776

Epoch: 6| Step: 3
Training loss: 2.258053037508782
Validation loss: 2.594712021528166

Epoch: 6| Step: 4
Training loss: 1.1689384798058975
Validation loss: 2.5508093450224836

Epoch: 6| Step: 5
Training loss: 1.1194818585635196
Validation loss: 2.550727395798222

Epoch: 6| Step: 6
Training loss: 1.2251634333054164
Validation loss: 2.525754606840142

Epoch: 6| Step: 7
Training loss: 1.4362809360980469
Validation loss: 2.53239597078022

Epoch: 6| Step: 8
Training loss: 1.290154058513002
Validation loss: 2.532207872915386

Epoch: 6| Step: 9
Training loss: 0.8170263317468603
Validation loss: 2.492136780353266

Epoch: 6| Step: 10
Training loss: 1.1177490530332113
Validation loss: 2.4938071477806494

Epoch: 6| Step: 11
Training loss: 1.2784228884790467
Validation loss: 2.501036270265002

Epoch: 6| Step: 12
Training loss: 1.3198114832730448
Validation loss: 2.512570851150994

Epoch: 6| Step: 13
Training loss: 1.1856303303487643
Validation loss: 2.520972466110264

Epoch: 134| Step: 0
Training loss: 1.8836437622164686
Validation loss: 2.493866891758521

Epoch: 6| Step: 1
Training loss: 1.3480264790931153
Validation loss: 2.524138377893696

Epoch: 6| Step: 2
Training loss: 1.3961500074326145
Validation loss: 2.472297799161285

Epoch: 6| Step: 3
Training loss: 0.6996282731511776
Validation loss: 2.482214862266534

Epoch: 6| Step: 4
Training loss: 1.2187636937081259
Validation loss: 2.5038812391090306

Epoch: 6| Step: 5
Training loss: 1.1468244369960825
Validation loss: 2.5184327956788137

Epoch: 6| Step: 6
Training loss: 1.112285181800547
Validation loss: 2.5232384428989674

Epoch: 6| Step: 7
Training loss: 1.3084972289059325
Validation loss: 2.4985030778966824

Epoch: 6| Step: 8
Training loss: 1.2028829157637309
Validation loss: 2.5374287753452416

Epoch: 6| Step: 9
Training loss: 1.2204688251706806
Validation loss: 2.4760996068055237

Epoch: 6| Step: 10
Training loss: 1.280638665218992
Validation loss: 2.4819695525585477

Epoch: 6| Step: 11
Training loss: 1.371099923057462
Validation loss: 2.552485241026869

Epoch: 6| Step: 12
Training loss: 1.122352557959628
Validation loss: 2.520847664679361

Epoch: 6| Step: 13
Training loss: 1.1316234794057853
Validation loss: 2.5023046520051744

Epoch: 135| Step: 0
Training loss: 1.3751518859204557
Validation loss: 2.439760439726135

Epoch: 6| Step: 1
Training loss: 0.9898240181537638
Validation loss: 2.5334371685615884

Epoch: 6| Step: 2
Training loss: 1.170931932544529
Validation loss: 2.512642302524129

Epoch: 6| Step: 3
Training loss: 0.976918971804295
Validation loss: 2.540468399895903

Epoch: 6| Step: 4
Training loss: 1.1470169312176164
Validation loss: 2.5490879983559265

Epoch: 6| Step: 5
Training loss: 1.260180832208627
Validation loss: 2.5194849685242757

Epoch: 6| Step: 6
Training loss: 0.8755782124274083
Validation loss: 2.4760727744153743

Epoch: 6| Step: 7
Training loss: 0.8204749536870004
Validation loss: 2.5329622984102316

Epoch: 6| Step: 8
Training loss: 1.1630712295230043
Validation loss: 2.5119821618969422

Epoch: 6| Step: 9
Training loss: 2.2081515279343047
Validation loss: 2.578517837650602

Epoch: 6| Step: 10
Training loss: 1.5554105524569184
Validation loss: 2.5419830271296564

Epoch: 6| Step: 11
Training loss: 1.179610091947614
Validation loss: 2.4903072810252977

Epoch: 6| Step: 12
Training loss: 0.9740392817892751
Validation loss: 2.5426007545109996

Epoch: 6| Step: 13
Training loss: 1.107902516741786
Validation loss: 2.5846543984793113

Epoch: 136| Step: 0
Training loss: 1.1620354636914692
Validation loss: 2.5393125753251145

Epoch: 6| Step: 1
Training loss: 1.0096357546138255
Validation loss: 2.495630037140406

Epoch: 6| Step: 2
Training loss: 1.5003219894684339
Validation loss: 2.5275757028226975

Epoch: 6| Step: 3
Training loss: 1.0139068742721642
Validation loss: 2.5159914922600715

Epoch: 6| Step: 4
Training loss: 1.3458380333943374
Validation loss: 2.4829873902278106

Epoch: 6| Step: 5
Training loss: 1.3604371755240936
Validation loss: 2.516488726643142

Epoch: 6| Step: 6
Training loss: 0.8620017395444519
Validation loss: 2.4876571024193277

Epoch: 6| Step: 7
Training loss: 1.3182400119576012
Validation loss: 2.539052296153375

Epoch: 6| Step: 8
Training loss: 1.1972124047453363
Validation loss: 2.5262150550928233

Epoch: 6| Step: 9
Training loss: 1.0826401632542206
Validation loss: 2.5303110963744415

Epoch: 6| Step: 10
Training loss: 1.0104966017313446
Validation loss: 2.565766346205599

Epoch: 6| Step: 11
Training loss: 0.9656334243950123
Validation loss: 2.602128143983493

Epoch: 6| Step: 12
Training loss: 1.8125079582302726
Validation loss: 2.5965099740730864

Epoch: 6| Step: 13
Training loss: 1.190826575169074
Validation loss: 2.634192568192963

Epoch: 137| Step: 0
Training loss: 0.8624121317126049
Validation loss: 2.582442627423683

Epoch: 6| Step: 1
Training loss: 1.5110645702307013
Validation loss: 2.628175177531731

Epoch: 6| Step: 2
Training loss: 1.9034091856295228
Validation loss: 2.488386015231083

Epoch: 6| Step: 3
Training loss: 1.2162742900873211
Validation loss: 2.5634340196742667

Epoch: 6| Step: 4
Training loss: 1.0444432383444655
Validation loss: 2.5531346134547976

Epoch: 6| Step: 5
Training loss: 0.7014405737194922
Validation loss: 2.551114429097154

Epoch: 6| Step: 6
Training loss: 1.1461786385623238
Validation loss: 2.5254224404958876

Epoch: 6| Step: 7
Training loss: 1.2923639271604284
Validation loss: 2.4954883237206484

Epoch: 6| Step: 8
Training loss: 1.4155733246455728
Validation loss: 2.4894152122989373

Epoch: 6| Step: 9
Training loss: 1.6864674552810581
Validation loss: 2.5395729842899573

Epoch: 6| Step: 10
Training loss: 1.4656193421992758
Validation loss: 2.5045796727105234

Epoch: 6| Step: 11
Training loss: 0.6381601972895462
Validation loss: 2.495376619213078

Epoch: 6| Step: 12
Training loss: 1.0384259102352817
Validation loss: 2.5619550916441844

Epoch: 6| Step: 13
Training loss: 0.8225317590025756
Validation loss: 2.5696319019108462

Epoch: 138| Step: 0
Training loss: 1.18447551049181
Validation loss: 2.589885467760995

Epoch: 6| Step: 1
Training loss: 0.7284567556041394
Validation loss: 2.5693410102255765

Epoch: 6| Step: 2
Training loss: 1.571087698068823
Validation loss: 2.5922428716134225

Epoch: 6| Step: 3
Training loss: 0.9261925664848493
Validation loss: 2.642909369204271

Epoch: 6| Step: 4
Training loss: 1.6851370480097312
Validation loss: 2.579493735368721

Epoch: 6| Step: 5
Training loss: 0.7847185575536568
Validation loss: 2.5351838441982

Epoch: 6| Step: 6
Training loss: 1.505126299707127
Validation loss: 2.515330982599273

Epoch: 6| Step: 7
Training loss: 1.4976681226758222
Validation loss: 2.59760836220104

Epoch: 6| Step: 8
Training loss: 0.8896903102496737
Validation loss: 2.5094052779673865

Epoch: 6| Step: 9
Training loss: 0.9873474896639806
Validation loss: 2.515061751783689

Epoch: 6| Step: 10
Training loss: 1.1926463192916505
Validation loss: 2.5487518727868

Epoch: 6| Step: 11
Training loss: 1.1648311765262098
Validation loss: 2.5540928824275473

Epoch: 6| Step: 12
Training loss: 0.8376863670805382
Validation loss: 2.5421189833311297

Epoch: 6| Step: 13
Training loss: 2.1102210714587386
Validation loss: 2.5577878192323733

Epoch: 139| Step: 0
Training loss: 1.149862171289386
Validation loss: 2.546285143612671

Epoch: 6| Step: 1
Training loss: 1.2893071260398987
Validation loss: 2.522717273706922

Epoch: 6| Step: 2
Training loss: 1.208819549121858
Validation loss: 2.5272597191356083

Epoch: 6| Step: 3
Training loss: 0.8869023742107218
Validation loss: 2.538006387804238

Epoch: 6| Step: 4
Training loss: 1.222221857971561
Validation loss: 2.537931673636748

Epoch: 6| Step: 5
Training loss: 1.2135176704009825
Validation loss: 2.5314696338325886

Epoch: 6| Step: 6
Training loss: 1.137723917458259
Validation loss: 2.497788341069237

Epoch: 6| Step: 7
Training loss: 1.149612085596506
Validation loss: 2.540847401349074

Epoch: 6| Step: 8
Training loss: 1.9368416682942289
Validation loss: 2.495520233826392

Epoch: 6| Step: 9
Training loss: 1.178708965359913
Validation loss: 2.535764733848226

Epoch: 6| Step: 10
Training loss: 0.7456460778070244
Validation loss: 2.530757911164554

Epoch: 6| Step: 11
Training loss: 1.0070697501837842
Validation loss: 2.4978814367292097

Epoch: 6| Step: 12
Training loss: 0.7820032684472505
Validation loss: 2.563265236515127

Epoch: 6| Step: 13
Training loss: 1.5708007053592226
Validation loss: 2.521388163603666

Epoch: 140| Step: 0
Training loss: 1.378041198673795
Validation loss: 2.5688338427694006

Epoch: 6| Step: 1
Training loss: 1.1654194341214577
Validation loss: 2.485642835415433

Epoch: 6| Step: 2
Training loss: 1.1352513335824344
Validation loss: 2.5100139331810856

Epoch: 6| Step: 3
Training loss: 1.004465741353267
Validation loss: 2.452196346348187

Epoch: 6| Step: 4
Training loss: 0.9080977183875902
Validation loss: 2.479873898284266

Epoch: 6| Step: 5
Training loss: 1.1344866779094966
Validation loss: 2.509083490157604

Epoch: 6| Step: 6
Training loss: 1.1267579965893797
Validation loss: 2.4682842652309547

Epoch: 6| Step: 7
Training loss: 1.250898324513577
Validation loss: 2.4770193871879167

Epoch: 6| Step: 8
Training loss: 1.3108973482187054
Validation loss: 2.5332882057319854

Epoch: 6| Step: 9
Training loss: 1.3090811206169903
Validation loss: 2.549795508444277

Epoch: 6| Step: 10
Training loss: 0.9554318824074397
Validation loss: 2.5617248944589557

Epoch: 6| Step: 11
Training loss: 0.9562794126088636
Validation loss: 2.5050006603257864

Epoch: 6| Step: 12
Training loss: 1.7713936611110788
Validation loss: 2.4684581986534324

Epoch: 6| Step: 13
Training loss: 1.1966618918391807
Validation loss: 2.527182124304216

Epoch: 141| Step: 0
Training loss: 1.2973156835218604
Validation loss: 2.5433360360465764

Epoch: 6| Step: 1
Training loss: 1.3408275140067438
Validation loss: 2.528232094060709

Epoch: 6| Step: 2
Training loss: 1.7838784617605001
Validation loss: 2.5546690525084936

Epoch: 6| Step: 3
Training loss: 1.1934149147008224
Validation loss: 2.5102775239702195

Epoch: 6| Step: 4
Training loss: 0.8826813727024845
Validation loss: 2.4667602681322918

Epoch: 6| Step: 5
Training loss: 1.072758517908698
Validation loss: 2.4865268688774007

Epoch: 6| Step: 6
Training loss: 0.719584478176011
Validation loss: 2.469928363656989

Epoch: 6| Step: 7
Training loss: 1.2330805111268186
Validation loss: 2.489343006446582

Epoch: 6| Step: 8
Training loss: 0.905790936186444
Validation loss: 2.5135828104668567

Epoch: 6| Step: 9
Training loss: 1.459987555934182
Validation loss: 2.596108027313797

Epoch: 6| Step: 10
Training loss: 0.8278640479875777
Validation loss: 2.571707767134239

Epoch: 6| Step: 11
Training loss: 1.262723870776842
Validation loss: 2.5631821507523385

Epoch: 6| Step: 12
Training loss: 0.7435753144353368
Validation loss: 2.6119748562707197

Epoch: 6| Step: 13
Training loss: 1.2819615225976313
Validation loss: 2.5330842518911516

Epoch: 142| Step: 0
Training loss: 1.0712399328019169
Validation loss: 2.5654596898870947

Epoch: 6| Step: 1
Training loss: 1.0433171294074268
Validation loss: 2.5232356790907042

Epoch: 6| Step: 2
Training loss: 0.8102620187284083
Validation loss: 2.5575634461677987

Epoch: 6| Step: 3
Training loss: 0.9013480104863439
Validation loss: 2.5495662706800295

Epoch: 6| Step: 4
Training loss: 1.1723911420315067
Validation loss: 2.5028084794928804

Epoch: 6| Step: 5
Training loss: 1.0456841941262764
Validation loss: 2.530276044429298

Epoch: 6| Step: 6
Training loss: 1.3025067314955134
Validation loss: 2.57663242791915

Epoch: 6| Step: 7
Training loss: 1.144111426108831
Validation loss: 2.4982941688774423

Epoch: 6| Step: 8
Training loss: 0.7657875355616478
Validation loss: 2.541389119258308

Epoch: 6| Step: 9
Training loss: 1.170172561000041
Validation loss: 2.5573135240375637

Epoch: 6| Step: 10
Training loss: 1.7387449181905457
Validation loss: 2.4870805463382775

Epoch: 6| Step: 11
Training loss: 0.897328330652605
Validation loss: 2.5390951614235426

Epoch: 6| Step: 12
Training loss: 1.625499501852794
Validation loss: 2.5243584809373156

Epoch: 6| Step: 13
Training loss: 1.083872306460515
Validation loss: 2.5717334008432555

Epoch: 143| Step: 0
Training loss: 0.7973469103541789
Validation loss: 2.5234055886155256

Epoch: 6| Step: 1
Training loss: 1.2655779982893305
Validation loss: 2.573101937937552

Epoch: 6| Step: 2
Training loss: 0.7844735209079053
Validation loss: 2.539866495240833

Epoch: 6| Step: 3
Training loss: 1.759820630296699
Validation loss: 2.5687246007351976

Epoch: 6| Step: 4
Training loss: 0.7178087705881493
Validation loss: 2.591188966529473

Epoch: 6| Step: 5
Training loss: 1.2444420274264463
Validation loss: 2.602706092689588

Epoch: 6| Step: 6
Training loss: 1.3330004793181993
Validation loss: 2.580025883428965

Epoch: 6| Step: 7
Training loss: 1.2702879543208698
Validation loss: 2.526410952182716

Epoch: 6| Step: 8
Training loss: 0.9877010044313325
Validation loss: 2.545836628996552

Epoch: 6| Step: 9
Training loss: 0.8250617466563295
Validation loss: 2.5320641421047503

Epoch: 6| Step: 10
Training loss: 1.6339602292379094
Validation loss: 2.546141099406623

Epoch: 6| Step: 11
Training loss: 0.734882382369591
Validation loss: 2.521064138223795

Epoch: 6| Step: 12
Training loss: 0.8988579471155119
Validation loss: 2.561423090914276

Epoch: 6| Step: 13
Training loss: 1.3511298043769728
Validation loss: 2.50229030444471

Epoch: 144| Step: 0
Training loss: 1.2773990910758743
Validation loss: 2.564961158651695

Epoch: 6| Step: 1
Training loss: 1.1337771813479007
Validation loss: 2.5601724893603772

Epoch: 6| Step: 2
Training loss: 1.2058577774477188
Validation loss: 2.5518134980051097

Epoch: 6| Step: 3
Training loss: 1.0803115895923754
Validation loss: 2.5385328865342935

Epoch: 6| Step: 4
Training loss: 1.793132500245559
Validation loss: 2.5430165963620777

Epoch: 6| Step: 5
Training loss: 0.9218444819167342
Validation loss: 2.5848290563860328

Epoch: 6| Step: 6
Training loss: 1.155634793724371
Validation loss: 2.570171951424401

Epoch: 6| Step: 7
Training loss: 0.728561972608831
Validation loss: 2.568276616492829

Epoch: 6| Step: 8
Training loss: 1.0649983820656679
Validation loss: 2.492341653646278

Epoch: 6| Step: 9
Training loss: 1.3326781819001752
Validation loss: 2.521975240247547

Epoch: 6| Step: 10
Training loss: 1.0657538909375766
Validation loss: 2.527259569765881

Epoch: 6| Step: 11
Training loss: 0.6416568122660288
Validation loss: 2.5532144310617455

Epoch: 6| Step: 12
Training loss: 1.0935790337047795
Validation loss: 2.4695018476525763

Epoch: 6| Step: 13
Training loss: 1.0967619704564329
Validation loss: 2.438773629422587

Epoch: 145| Step: 0
Training loss: 1.0868459510540727
Validation loss: 2.517199290252105

Epoch: 6| Step: 1
Training loss: 1.868170826446524
Validation loss: 2.529265909484073

Epoch: 6| Step: 2
Training loss: 1.3536040482255358
Validation loss: 2.594576646453031

Epoch: 6| Step: 3
Training loss: 1.3961065034545312
Validation loss: 2.5513508167124668

Epoch: 6| Step: 4
Training loss: 1.037780314804759
Validation loss: 2.565201103328109

Epoch: 6| Step: 5
Training loss: 1.0556802104381873
Validation loss: 2.543093629926214

Epoch: 6| Step: 6
Training loss: 0.9515003992120945
Validation loss: 2.540780285495961

Epoch: 6| Step: 7
Training loss: 0.8748555064105517
Validation loss: 2.490380567859502

Epoch: 6| Step: 8
Training loss: 1.0121381913812233
Validation loss: 2.57506854820984

Epoch: 6| Step: 9
Training loss: 0.9847842380046318
Validation loss: 2.4910407861223796

Epoch: 6| Step: 10
Training loss: 0.8359169645550085
Validation loss: 2.5349151073439185

Epoch: 6| Step: 11
Training loss: 1.232826613815607
Validation loss: 2.5639018124463266

Epoch: 6| Step: 12
Training loss: 0.8515958167041899
Validation loss: 2.5929521766064747

Epoch: 6| Step: 13
Training loss: 0.7258799638744313
Validation loss: 2.5723895306435023

Epoch: 146| Step: 0
Training loss: 0.8283645355429394
Validation loss: 2.5734928479522345

Epoch: 6| Step: 1
Training loss: 1.0469783902711767
Validation loss: 2.504941300867473

Epoch: 6| Step: 2
Training loss: 0.8511097955845736
Validation loss: 2.558092653548617

Epoch: 6| Step: 3
Training loss: 0.9782783692748118
Validation loss: 2.5621707828834164

Epoch: 6| Step: 4
Training loss: 1.030383526312451
Validation loss: 2.5021130532800573

Epoch: 6| Step: 5
Training loss: 0.9011758289159474
Validation loss: 2.571630447274381

Epoch: 6| Step: 6
Training loss: 1.3198422378851113
Validation loss: 2.5713255488859987

Epoch: 6| Step: 7
Training loss: 0.8847631997586793
Validation loss: 2.56399059361425

Epoch: 6| Step: 8
Training loss: 1.2676673234728397
Validation loss: 2.59398549707506

Epoch: 6| Step: 9
Training loss: 1.417673043347394
Validation loss: 2.5785095852771165

Epoch: 6| Step: 10
Training loss: 0.9971513705879758
Validation loss: 2.613352699994644

Epoch: 6| Step: 11
Training loss: 1.0406654441695167
Validation loss: 2.594628556764419

Epoch: 6| Step: 12
Training loss: 1.9413423278232558
Validation loss: 2.5304338214689963

Epoch: 6| Step: 13
Training loss: 0.6613432916838737
Validation loss: 2.482374397422082

Epoch: 147| Step: 0
Training loss: 1.1455936643619735
Validation loss: 2.5549891193678285

Epoch: 6| Step: 1
Training loss: 1.2268824069032258
Validation loss: 2.5947444036021383

Epoch: 6| Step: 2
Training loss: 0.8747980702229352
Validation loss: 2.560329634633435

Epoch: 6| Step: 3
Training loss: 1.3823643189774828
Validation loss: 2.5142115695556786

Epoch: 6| Step: 4
Training loss: 1.173835183120809
Validation loss: 2.552231645491516

Epoch: 6| Step: 5
Training loss: 0.9246892484420846
Validation loss: 2.5493093764617294

Epoch: 6| Step: 6
Training loss: 0.9381026556211854
Validation loss: 2.584946764330793

Epoch: 6| Step: 7
Training loss: 1.1937783562452964
Validation loss: 2.5840798473525526

Epoch: 6| Step: 8
Training loss: 1.0417552274568704
Validation loss: 2.6106298783268675

Epoch: 6| Step: 9
Training loss: 1.1218015981479523
Validation loss: 2.6118815522036796

Epoch: 6| Step: 10
Training loss: 0.9849517888406948
Validation loss: 2.5817186913769934

Epoch: 6| Step: 11
Training loss: 1.781642268304918
Validation loss: 2.521015016193047

Epoch: 6| Step: 12
Training loss: 0.7661155374857233
Validation loss: 2.538608670879853

Epoch: 6| Step: 13
Training loss: 1.1569391207491746
Validation loss: 2.5505978886905885

Epoch: 148| Step: 0
Training loss: 0.9127233101362586
Validation loss: 2.4973101609497994

Epoch: 6| Step: 1
Training loss: 1.3382653372954827
Validation loss: 2.5005804500665123

Epoch: 6| Step: 2
Training loss: 1.2900573128529025
Validation loss: 2.4761526609029256

Epoch: 6| Step: 3
Training loss: 1.2877052328733503
Validation loss: 2.554211594547915

Epoch: 6| Step: 4
Training loss: 1.2267859188626207
Validation loss: 2.518343639171761

Epoch: 6| Step: 5
Training loss: 0.8888915073501908
Validation loss: 2.534073922382478

Epoch: 6| Step: 6
Training loss: 1.2276981223395054
Validation loss: 2.5764648795310108

Epoch: 6| Step: 7
Training loss: 0.7986643280505594
Validation loss: 2.5558105395676813

Epoch: 6| Step: 8
Training loss: 0.9618121252895198
Validation loss: 2.572117381457338

Epoch: 6| Step: 9
Training loss: 1.434858798214301
Validation loss: 2.620353416043047

Epoch: 6| Step: 10
Training loss: 0.9050219535272457
Validation loss: 2.536538905457401

Epoch: 6| Step: 11
Training loss: 0.9240914225639784
Validation loss: 2.569880216320491

Epoch: 6| Step: 12
Training loss: 1.7892442635900887
Validation loss: 2.4755540433154613

Epoch: 6| Step: 13
Training loss: 1.188720928763264
Validation loss: 2.5658568283331844

Epoch: 149| Step: 0
Training loss: 1.7620759927424297
Validation loss: 2.5506334870532266

Epoch: 6| Step: 1
Training loss: 1.1932068273061893
Validation loss: 2.499077014614611

Epoch: 6| Step: 2
Training loss: 0.9215802513526576
Validation loss: 2.549710214891384

Epoch: 6| Step: 3
Training loss: 0.9165078408467254
Validation loss: 2.5491996406683017

Epoch: 6| Step: 4
Training loss: 0.8805567185494183
Validation loss: 2.5102130179422577

Epoch: 6| Step: 5
Training loss: 0.8527060713288699
Validation loss: 2.5387469442835315

Epoch: 6| Step: 6
Training loss: 1.2364653259610952
Validation loss: 2.5462481579581184

Epoch: 6| Step: 7
Training loss: 1.2459403395016444
Validation loss: 2.5821880806575206

Epoch: 6| Step: 8
Training loss: 0.9737929477451174
Validation loss: 2.54242765780706

Epoch: 6| Step: 9
Training loss: 0.8745570083213475
Validation loss: 2.565417582668851

Epoch: 6| Step: 10
Training loss: 1.0622886559717477
Validation loss: 2.628186305386033

Epoch: 6| Step: 11
Training loss: 0.9042113821923601
Validation loss: 2.5872442011543204

Epoch: 6| Step: 12
Training loss: 1.2562044657335858
Validation loss: 2.4797281436197327

Epoch: 6| Step: 13
Training loss: 1.1822605997224673
Validation loss: 2.567935853566959

Epoch: 150| Step: 0
Training loss: 1.158973219110369
Validation loss: 2.5498894480508136

Epoch: 6| Step: 1
Training loss: 1.2062504783194588
Validation loss: 2.5451532094314615

Epoch: 6| Step: 2
Training loss: 1.1095342924707277
Validation loss: 2.615641836874068

Epoch: 6| Step: 3
Training loss: 0.5442970001890746
Validation loss: 2.5812462764340594

Epoch: 6| Step: 4
Training loss: 1.0659968669802375
Validation loss: 2.5985793689162175

Epoch: 6| Step: 5
Training loss: 1.0478833025758454
Validation loss: 2.5407984193843003

Epoch: 6| Step: 6
Training loss: 0.9916218624625561
Validation loss: 2.5833502481788697

Epoch: 6| Step: 7
Training loss: 0.9607180212943959
Validation loss: 2.6067001201071607

Epoch: 6| Step: 8
Training loss: 1.0634902378740798
Validation loss: 2.5575488104315562

Epoch: 6| Step: 9
Training loss: 1.0210167596769701
Validation loss: 2.515482793859967

Epoch: 6| Step: 10
Training loss: 1.2993758115265897
Validation loss: 2.6032277258318124

Epoch: 6| Step: 11
Training loss: 0.8496106027177731
Validation loss: 2.5400701469837608

Epoch: 6| Step: 12
Training loss: 0.9985864304340091
Validation loss: 2.579202461507844

Epoch: 6| Step: 13
Training loss: 1.808170936546848
Validation loss: 2.5603207726726915

Epoch: 151| Step: 0
Training loss: 0.9069314236377242
Validation loss: 2.5290974149277914

Epoch: 6| Step: 1
Training loss: 1.5234966560029106
Validation loss: 2.5932850631652427

Epoch: 6| Step: 2
Training loss: 1.0719376081415797
Validation loss: 2.556345799025944

Epoch: 6| Step: 3
Training loss: 1.0505622153326317
Validation loss: 2.4870226445150734

Epoch: 6| Step: 4
Training loss: 0.7345723637717304
Validation loss: 2.5343708688974322

Epoch: 6| Step: 5
Training loss: 0.9525754000639566
Validation loss: 2.5683379081728237

Epoch: 6| Step: 6
Training loss: 0.8020095708708803
Validation loss: 2.6061384645254155

Epoch: 6| Step: 7
Training loss: 0.5769808246675733
Validation loss: 2.6124642030493264

Epoch: 6| Step: 8
Training loss: 1.3934162715399288
Validation loss: 2.5635191666226533

Epoch: 6| Step: 9
Training loss: 1.6093783332271687
Validation loss: 2.5811287076345426

Epoch: 6| Step: 10
Training loss: 0.832369596790032
Validation loss: 2.560227153728664

Epoch: 6| Step: 11
Training loss: 1.1057680621188823
Validation loss: 2.561188354370905

Epoch: 6| Step: 12
Training loss: 0.854754877311401
Validation loss: 2.5371300801956163

Epoch: 6| Step: 13
Training loss: 1.1891188378841544
Validation loss: 2.4937307747440007

Epoch: 152| Step: 0
Training loss: 1.1643996806454524
Validation loss: 2.556291455816429

Epoch: 6| Step: 1
Training loss: 0.9862879074508719
Validation loss: 2.507731482919294

Epoch: 6| Step: 2
Training loss: 0.9481602170736816
Validation loss: 2.566286174223772

Epoch: 6| Step: 3
Training loss: 1.0968883176685231
Validation loss: 2.573668162962501

Epoch: 6| Step: 4
Training loss: 0.9452357300410421
Validation loss: 2.481700209059379

Epoch: 6| Step: 5
Training loss: 0.9435504222308377
Validation loss: 2.549752823063422

Epoch: 6| Step: 6
Training loss: 0.7453008302938611
Validation loss: 2.50353198892046

Epoch: 6| Step: 7
Training loss: 1.1239366804458386
Validation loss: 2.4955954693617746

Epoch: 6| Step: 8
Training loss: 0.7903519471785564
Validation loss: 2.5931267200120094

Epoch: 6| Step: 9
Training loss: 1.2470391492900537
Validation loss: 2.557008068470315

Epoch: 6| Step: 10
Training loss: 1.0752955363143104
Validation loss: 2.54326693910236

Epoch: 6| Step: 11
Training loss: 0.8964597744360908
Validation loss: 2.53858321141145

Epoch: 6| Step: 12
Training loss: 1.745128800193945
Validation loss: 2.5279365720814555

Epoch: 6| Step: 13
Training loss: 0.9847484364687227
Validation loss: 2.5512679425832374

Epoch: 153| Step: 0
Training loss: 0.9351078030458632
Validation loss: 2.62036077083012

Epoch: 6| Step: 1
Training loss: 1.1859995749088446
Validation loss: 2.5892864105148505

Epoch: 6| Step: 2
Training loss: 1.0978440093598585
Validation loss: 2.4748924392549974

Epoch: 6| Step: 3
Training loss: 1.0136741682258201
Validation loss: 2.5879468074434095

Epoch: 6| Step: 4
Training loss: 1.1220501266270675
Validation loss: 2.5056714576911197

Epoch: 6| Step: 5
Training loss: 1.187788677262709
Validation loss: 2.563237029979616

Epoch: 6| Step: 6
Training loss: 1.1663830560012098
Validation loss: 2.4952330441087525

Epoch: 6| Step: 7
Training loss: 0.7221187757924099
Validation loss: 2.5575473188868543

Epoch: 6| Step: 8
Training loss: 1.8101552068438136
Validation loss: 2.535549358656043

Epoch: 6| Step: 9
Training loss: 0.8225771932119316
Validation loss: 2.586300320253307

Epoch: 6| Step: 10
Training loss: 0.713894656966574
Validation loss: 2.5700437874904436

Epoch: 6| Step: 11
Training loss: 0.7268369833007479
Validation loss: 2.5799717617707416

Epoch: 6| Step: 12
Training loss: 0.9157932556542145
Validation loss: 2.5307134208704896

Epoch: 6| Step: 13
Training loss: 1.1039571503326149
Validation loss: 2.5764355451044367

Epoch: 154| Step: 0
Training loss: 0.8982445551141606
Validation loss: 2.575706086987092

Epoch: 6| Step: 1
Training loss: 1.7998546939056481
Validation loss: 2.513191467711582

Epoch: 6| Step: 2
Training loss: 0.8337536387671545
Validation loss: 2.5570479909455863

Epoch: 6| Step: 3
Training loss: 1.0090274436817694
Validation loss: 2.548754967508032

Epoch: 6| Step: 4
Training loss: 0.8429347444168094
Validation loss: 2.548563056502

Epoch: 6| Step: 5
Training loss: 1.0708505433674995
Validation loss: 2.540632824574864

Epoch: 6| Step: 6
Training loss: 0.9840309510635639
Validation loss: 2.6174216929554093

Epoch: 6| Step: 7
Training loss: 0.6460006609904447
Validation loss: 2.5658784010933937

Epoch: 6| Step: 8
Training loss: 1.0494655611404193
Validation loss: 2.5555837694167867

Epoch: 6| Step: 9
Training loss: 0.97852561473506
Validation loss: 2.5315044416478685

Epoch: 6| Step: 10
Training loss: 1.0629101130035385
Validation loss: 2.5516376002313352

Epoch: 6| Step: 11
Training loss: 1.0159837529317648
Validation loss: 2.5344111166002206

Epoch: 6| Step: 12
Training loss: 1.3480627359116537
Validation loss: 2.5473457790634124

Epoch: 6| Step: 13
Training loss: 0.9275662239678018
Validation loss: 2.53543561073149

Epoch: 155| Step: 0
Training loss: 1.611801540302734
Validation loss: 2.5560638888507703

Epoch: 6| Step: 1
Training loss: 1.2830523397959586
Validation loss: 2.529631721395287

Epoch: 6| Step: 2
Training loss: 0.7259328020775557
Validation loss: 2.57579695272861

Epoch: 6| Step: 3
Training loss: 0.9259617625471707
Validation loss: 2.5715350535525023

Epoch: 6| Step: 4
Training loss: 0.792038922042248
Validation loss: 2.570594540227038

Epoch: 6| Step: 5
Training loss: 0.9505159909199034
Validation loss: 2.6280058272440856

Epoch: 6| Step: 6
Training loss: 0.7421775415655918
Validation loss: 2.538888747310101

Epoch: 6| Step: 7
Training loss: 0.5764686725223704
Validation loss: 2.530688337326555

Epoch: 6| Step: 8
Training loss: 1.1432008790475283
Validation loss: 2.633308039515578

Epoch: 6| Step: 9
Training loss: 1.2858657038172685
Validation loss: 2.5625636085120873

Epoch: 6| Step: 10
Training loss: 1.2751911001417782
Validation loss: 2.560033293274116

Epoch: 6| Step: 11
Training loss: 0.9790408615024789
Validation loss: 2.607580089174238

Epoch: 6| Step: 12
Training loss: 1.025997774118013
Validation loss: 2.552578412257947

Epoch: 6| Step: 13
Training loss: 1.146623385318562
Validation loss: 2.5936417920931056

Epoch: 156| Step: 0
Training loss: 1.0514694286043464
Validation loss: 2.574377214246049

Epoch: 6| Step: 1
Training loss: 0.6718321054649756
Validation loss: 2.6006499590688668

Epoch: 6| Step: 2
Training loss: 1.2191021728318527
Validation loss: 2.5186517328698383

Epoch: 6| Step: 3
Training loss: 1.003897165932727
Validation loss: 2.532309691034023

Epoch: 6| Step: 4
Training loss: 0.780462822113589
Validation loss: 2.5451639430634545

Epoch: 6| Step: 5
Training loss: 1.475680617722704
Validation loss: 2.635124451692055

Epoch: 6| Step: 6
Training loss: 0.7126536354262873
Validation loss: 2.6087933803936822

Epoch: 6| Step: 7
Training loss: 0.6637576132587374
Validation loss: 2.644763600121752

Epoch: 6| Step: 8
Training loss: 0.7552211935768021
Validation loss: 2.5710143084845662

Epoch: 6| Step: 9
Training loss: 0.8771242514252782
Validation loss: 2.5397472299497554

Epoch: 6| Step: 10
Training loss: 1.8184953386752047
Validation loss: 2.5341685702178673

Epoch: 6| Step: 11
Training loss: 0.6585550244803008
Validation loss: 2.553046941167022

Epoch: 6| Step: 12
Training loss: 1.2916528280603845
Validation loss: 2.549971431996007

Epoch: 6| Step: 13
Training loss: 1.015840536868617
Validation loss: 2.584261855539689

Epoch: 157| Step: 0
Training loss: 0.4676883596249003
Validation loss: 2.5436068357878603

Epoch: 6| Step: 1
Training loss: 0.9999462947729316
Validation loss: 2.52917939727026

Epoch: 6| Step: 2
Training loss: 1.1804687237439762
Validation loss: 2.520052392177807

Epoch: 6| Step: 3
Training loss: 1.159663856900605
Validation loss: 2.5943293939299386

Epoch: 6| Step: 4
Training loss: 1.7523533120576857
Validation loss: 2.5371632676718145

Epoch: 6| Step: 5
Training loss: 1.0160682297947645
Validation loss: 2.5548419030802076

Epoch: 6| Step: 6
Training loss: 0.6835507188604728
Validation loss: 2.580160458772182

Epoch: 6| Step: 7
Training loss: 0.9584451002100105
Validation loss: 2.624915908798673

Epoch: 6| Step: 8
Training loss: 0.5783045464157057
Validation loss: 2.5269541688277

Epoch: 6| Step: 9
Training loss: 0.9502931017214543
Validation loss: 2.5782913462601056

Epoch: 6| Step: 10
Training loss: 1.1744595826990973
Validation loss: 2.6058566497192253

Epoch: 6| Step: 11
Training loss: 0.668424172217286
Validation loss: 2.5566142959734965

Epoch: 6| Step: 12
Training loss: 0.8212753095167047
Validation loss: 2.5291795622377986

Epoch: 6| Step: 13
Training loss: 0.9390075324754774
Validation loss: 2.4795550167761937

Epoch: 158| Step: 0
Training loss: 0.6808637110035327
Validation loss: 2.6376421933767227

Epoch: 6| Step: 1
Training loss: 0.9178549838080466
Validation loss: 2.575099364156722

Epoch: 6| Step: 2
Training loss: 1.2733220709224424
Validation loss: 2.540351829842223

Epoch: 6| Step: 3
Training loss: 1.9230622136947308
Validation loss: 2.6218283960188695

Epoch: 6| Step: 4
Training loss: 0.7433965772900467
Validation loss: 2.5876789203156947

Epoch: 6| Step: 5
Training loss: 0.9293423180134424
Validation loss: 2.558153591199717

Epoch: 6| Step: 6
Training loss: 0.9108000348965215
Validation loss: 2.5418716150002867

Epoch: 6| Step: 7
Training loss: 1.09665294692744
Validation loss: 2.6475485751192878

Epoch: 6| Step: 8
Training loss: 1.4127337709600787
Validation loss: 2.6106385847314644

Epoch: 6| Step: 9
Training loss: 0.679250159914
Validation loss: 2.5204320593467053

Epoch: 6| Step: 10
Training loss: 1.0869863919631981
Validation loss: 2.593969213268709

Epoch: 6| Step: 11
Training loss: 0.6891639254222198
Validation loss: 2.5546655683130175

Epoch: 6| Step: 12
Training loss: 0.842980351690828
Validation loss: 2.6091472351201874

Epoch: 6| Step: 13
Training loss: 0.76778865188744
Validation loss: 2.578223748676034

Epoch: 159| Step: 0
Training loss: 1.058038094157462
Validation loss: 2.5835728239494897

Epoch: 6| Step: 1
Training loss: 1.149301113390269
Validation loss: 2.5069386196567804

Epoch: 6| Step: 2
Training loss: 0.8918633134232634
Validation loss: 2.5567475314285217

Epoch: 6| Step: 3
Training loss: 0.9449168867063906
Validation loss: 2.544008752345478

Epoch: 6| Step: 4
Training loss: 0.8124687849064086
Validation loss: 2.5647171167413068

Epoch: 6| Step: 5
Training loss: 0.9868772281285766
Validation loss: 2.539991856221538

Epoch: 6| Step: 6
Training loss: 0.8551569331183999
Validation loss: 2.596926081247211

Epoch: 6| Step: 7
Training loss: 1.7067233229089311
Validation loss: 2.5606620756839926

Epoch: 6| Step: 8
Training loss: 0.9557866625767429
Validation loss: 2.6103666328654476

Epoch: 6| Step: 9
Training loss: 0.7000355132494964
Validation loss: 2.5901853586390597

Epoch: 6| Step: 10
Training loss: 0.9643814894630305
Validation loss: 2.6418291465137766

Epoch: 6| Step: 11
Training loss: 1.094889945940234
Validation loss: 2.586473730141058

Epoch: 6| Step: 12
Training loss: 0.9088862321474637
Validation loss: 2.5496207104760127

Epoch: 6| Step: 13
Training loss: 0.8519887994558341
Validation loss: 2.5835369604110046

Epoch: 160| Step: 0
Training loss: 1.2948960982068667
Validation loss: 2.5385054617955696

Epoch: 6| Step: 1
Training loss: 0.7737599480995511
Validation loss: 2.5705940996720105

Epoch: 6| Step: 2
Training loss: 1.2141778721725403
Validation loss: 2.5756171619592547

Epoch: 6| Step: 3
Training loss: 1.123354450068856
Validation loss: 2.5449840960602135

Epoch: 6| Step: 4
Training loss: 0.7641139007316389
Validation loss: 2.594916667298468

Epoch: 6| Step: 5
Training loss: 1.0033471595301555
Validation loss: 2.6088543522863206

Epoch: 6| Step: 6
Training loss: 1.6231054118740438
Validation loss: 2.5649814686096493

Epoch: 6| Step: 7
Training loss: 0.9977279720947759
Validation loss: 2.5353653816128845

Epoch: 6| Step: 8
Training loss: 0.8802179001207386
Validation loss: 2.5461523985099532

Epoch: 6| Step: 9
Training loss: 0.7296781698606568
Validation loss: 2.625144666893647

Epoch: 6| Step: 10
Training loss: 0.4840828414396148
Validation loss: 2.5575717428218483

Epoch: 6| Step: 11
Training loss: 0.7360348307074999
Validation loss: 2.576007906246097

Epoch: 6| Step: 12
Training loss: 0.744086916930238
Validation loss: 2.597418798622161

Epoch: 6| Step: 13
Training loss: 1.1052950126077787
Validation loss: 2.5505893512413502

Epoch: 161| Step: 0
Training loss: 0.7822211142741952
Validation loss: 2.608842654566777

Epoch: 6| Step: 1
Training loss: 0.7409973238795009
Validation loss: 2.4908307327566637

Epoch: 6| Step: 2
Training loss: 1.0449487985725348
Validation loss: 2.5134466149867083

Epoch: 6| Step: 3
Training loss: 0.7608600177521286
Validation loss: 2.5312661535430507

Epoch: 6| Step: 4
Training loss: 1.708866695167062
Validation loss: 2.597918764392421

Epoch: 6| Step: 5
Training loss: 0.9407865455274395
Validation loss: 2.596355141065919

Epoch: 6| Step: 6
Training loss: 0.6905539480400181
Validation loss: 2.5992470519108544

Epoch: 6| Step: 7
Training loss: 1.030236642189508
Validation loss: 2.592638091477781

Epoch: 6| Step: 8
Training loss: 1.0862010389033296
Validation loss: 2.587445974477033

Epoch: 6| Step: 9
Training loss: 0.61343313875363
Validation loss: 2.562657483231639

Epoch: 6| Step: 10
Training loss: 1.023875717809251
Validation loss: 2.585764023416114

Epoch: 6| Step: 11
Training loss: 1.0190770683194779
Validation loss: 2.5091854389653596

Epoch: 6| Step: 12
Training loss: 1.1165212498584602
Validation loss: 2.5082596155488828

Epoch: 6| Step: 13
Training loss: 0.8697218762264446
Validation loss: 2.6087695578631176

Epoch: 162| Step: 0
Training loss: 0.9795706842066353
Validation loss: 2.561159225091454

Epoch: 6| Step: 1
Training loss: 0.9894887611306042
Validation loss: 2.5817008603045726

Epoch: 6| Step: 2
Training loss: 0.5906623818410381
Validation loss: 2.513784220807328

Epoch: 6| Step: 3
Training loss: 1.0262596299048365
Validation loss: 2.5249495567344202

Epoch: 6| Step: 4
Training loss: 0.778790302121598
Validation loss: 2.606428100330915

Epoch: 6| Step: 5
Training loss: 0.7461312169758493
Validation loss: 2.614175944613319

Epoch: 6| Step: 6
Training loss: 0.7591263697621428
Validation loss: 2.5105378977732444

Epoch: 6| Step: 7
Training loss: 1.4507826107185158
Validation loss: 2.5700753826312224

Epoch: 6| Step: 8
Training loss: 0.7913442046988886
Validation loss: 2.538528495778408

Epoch: 6| Step: 9
Training loss: 0.6437855886603222
Validation loss: 2.5829986899009905

Epoch: 6| Step: 10
Training loss: 0.973541837094014
Validation loss: 2.559860443977898

Epoch: 6| Step: 11
Training loss: 1.571062582608825
Validation loss: 2.617941995300168

Epoch: 6| Step: 12
Training loss: 0.9927293694513233
Validation loss: 2.5715752063424477

Epoch: 6| Step: 13
Training loss: 1.0370050582578447
Validation loss: 2.6158712085105735

Epoch: 163| Step: 0
Training loss: 1.0224946316156087
Validation loss: 2.58400734958253

Epoch: 6| Step: 1
Training loss: 1.1426707694812
Validation loss: 2.5102857078066876

Epoch: 6| Step: 2
Training loss: 0.679504567225688
Validation loss: 2.6065284979666306

Epoch: 6| Step: 3
Training loss: 0.6997414026117236
Validation loss: 2.53046766208281

Epoch: 6| Step: 4
Training loss: 0.9360847599296348
Validation loss: 2.511015592388162

Epoch: 6| Step: 5
Training loss: 0.790998444547221
Validation loss: 2.574934416617832

Epoch: 6| Step: 6
Training loss: 0.6430565348847276
Validation loss: 2.5657774737047876

Epoch: 6| Step: 7
Training loss: 0.8638950772045078
Validation loss: 2.6200772402203065

Epoch: 6| Step: 8
Training loss: 1.1664006349973952
Validation loss: 2.5857622407989034

Epoch: 6| Step: 9
Training loss: 0.9635270744799652
Validation loss: 2.5075376048997082

Epoch: 6| Step: 10
Training loss: 1.5169879251702383
Validation loss: 2.6024773013651608

Epoch: 6| Step: 11
Training loss: 1.03309368282237
Validation loss: 2.512069970270063

Epoch: 6| Step: 12
Training loss: 1.1187004568542165
Validation loss: 2.5317500684041345

Epoch: 6| Step: 13
Training loss: 0.8413356924978612
Validation loss: 2.6015341817328417

Epoch: 164| Step: 0
Training loss: 0.9377788764699594
Validation loss: 2.6045134097363327

Epoch: 6| Step: 1
Training loss: 0.5595598735800948
Validation loss: 2.524502996751056

Epoch: 6| Step: 2
Training loss: 1.7029290742782257
Validation loss: 2.5387444712686498

Epoch: 6| Step: 3
Training loss: 0.8136108946967265
Validation loss: 2.5534415750327466

Epoch: 6| Step: 4
Training loss: 0.8748128895290974
Validation loss: 2.561822274378913

Epoch: 6| Step: 5
Training loss: 0.9938090132938898
Validation loss: 2.534451065772092

Epoch: 6| Step: 6
Training loss: 0.6652849277858952
Validation loss: 2.5558667742076815

Epoch: 6| Step: 7
Training loss: 0.4791355243873515
Validation loss: 2.579293296511452

Epoch: 6| Step: 8
Training loss: 1.4546795804866326
Validation loss: 2.574994292144869

Epoch: 6| Step: 9
Training loss: 0.7696597384155723
Validation loss: 2.627406334337217

Epoch: 6| Step: 10
Training loss: 0.5590986091121594
Validation loss: 2.5454517592584134

Epoch: 6| Step: 11
Training loss: 1.2482880313090794
Validation loss: 2.5840479621166095

Epoch: 6| Step: 12
Training loss: 0.836034252236217
Validation loss: 2.6028913019795814

Epoch: 6| Step: 13
Training loss: 1.0016643264116907
Validation loss: 2.571802080618605

Epoch: 165| Step: 0
Training loss: 0.9392525187101448
Validation loss: 2.5681941492966702

Epoch: 6| Step: 1
Training loss: 0.9800217053870721
Validation loss: 2.547300650321644

Epoch: 6| Step: 2
Training loss: 0.9714982213167487
Validation loss: 2.5641420112228688

Epoch: 6| Step: 3
Training loss: 0.619913094644075
Validation loss: 2.5151458979025456

Epoch: 6| Step: 4
Training loss: 0.6724626056385651
Validation loss: 2.6295311587984576

Epoch: 6| Step: 5
Training loss: 1.5475919969171845
Validation loss: 2.5816160359680835

Epoch: 6| Step: 6
Training loss: 1.0811369467489917
Validation loss: 2.628022769568058

Epoch: 6| Step: 7
Training loss: 1.2448672773096958
Validation loss: 2.5993577322814767

Epoch: 6| Step: 8
Training loss: 0.8327074839956918
Validation loss: 2.5647372736980905

Epoch: 6| Step: 9
Training loss: 1.027700036061342
Validation loss: 2.591937569405027

Epoch: 6| Step: 10
Training loss: 0.690720298716684
Validation loss: 2.6449143523379366

Epoch: 6| Step: 11
Training loss: 0.7129425029951972
Validation loss: 2.5308122452590136

Epoch: 6| Step: 12
Training loss: 0.6382254343830116
Validation loss: 2.522035167765022

Epoch: 6| Step: 13
Training loss: 0.908085903683472
Validation loss: 2.572532151456598

Epoch: 166| Step: 0
Training loss: 1.1880454768136686
Validation loss: 2.5975192002782204

Epoch: 6| Step: 1
Training loss: 0.9311861093097106
Validation loss: 2.484486895266599

Epoch: 6| Step: 2
Training loss: 0.730477317719014
Validation loss: 2.576029301444144

Epoch: 6| Step: 3
Training loss: 0.9271923208288152
Validation loss: 2.5524099153992355

Epoch: 6| Step: 4
Training loss: 0.9142247895501094
Validation loss: 2.4990065031085322

Epoch: 6| Step: 5
Training loss: 0.4941094731700295
Validation loss: 2.6100287465574477

Epoch: 6| Step: 6
Training loss: 0.7500425167748224
Validation loss: 2.565136468106258

Epoch: 6| Step: 7
Training loss: 0.9855452952937387
Validation loss: 2.5826908563706352

Epoch: 6| Step: 8
Training loss: 1.1226377056928956
Validation loss: 2.589487763838441

Epoch: 6| Step: 9
Training loss: 0.8493297599101487
Validation loss: 2.546581384003102

Epoch: 6| Step: 10
Training loss: 0.969820323456503
Validation loss: 2.5695611383098016

Epoch: 6| Step: 11
Training loss: 0.7068373693539699
Validation loss: 2.5756484496022582

Epoch: 6| Step: 12
Training loss: 0.8405735127730777
Validation loss: 2.5758724660460635

Epoch: 6| Step: 13
Training loss: 1.5422748019196288
Validation loss: 2.577263535963359

Epoch: 167| Step: 0
Training loss: 1.0042208761142548
Validation loss: 2.5712915042141686

Epoch: 6| Step: 1
Training loss: 0.8645676224594794
Validation loss: 2.6179449399273103

Epoch: 6| Step: 2
Training loss: 0.5060577592716015
Validation loss: 2.57460302360707

Epoch: 6| Step: 3
Training loss: 0.7546527309582891
Validation loss: 2.6217119271538034

Epoch: 6| Step: 4
Training loss: 1.5312180807718305
Validation loss: 2.6523986121577363

Epoch: 6| Step: 5
Training loss: 0.930038257755385
Validation loss: 2.590794116099971

Epoch: 6| Step: 6
Training loss: 0.7551589204254386
Validation loss: 2.5586847031906643

Epoch: 6| Step: 7
Training loss: 0.9541982642748654
Validation loss: 2.514008960584494

Epoch: 6| Step: 8
Training loss: 0.750682917257525
Validation loss: 2.5733600007991244

Epoch: 6| Step: 9
Training loss: 0.7370091534412341
Validation loss: 2.474249898226429

Epoch: 6| Step: 10
Training loss: 1.1690860367205156
Validation loss: 2.5153650579950018

Epoch: 6| Step: 11
Training loss: 0.9812708153916243
Validation loss: 2.640436109299

Epoch: 6| Step: 12
Training loss: 0.7261579063840866
Validation loss: 2.601069971759877

Epoch: 6| Step: 13
Training loss: 1.3127271818910518
Validation loss: 2.5591256867554737

Epoch: 168| Step: 0
Training loss: 1.2074931720674862
Validation loss: 2.572845138811678

Epoch: 6| Step: 1
Training loss: 0.9249506576368305
Validation loss: 2.6124476541631982

Epoch: 6| Step: 2
Training loss: 1.6188591320116414
Validation loss: 2.5914789851472064

Epoch: 6| Step: 3
Training loss: 0.5712303196628412
Validation loss: 2.545133490655739

Epoch: 6| Step: 4
Training loss: 0.6183025813574338
Validation loss: 2.5651356548306588

Epoch: 6| Step: 5
Training loss: 0.9105807775521674
Validation loss: 2.603583161149902

Epoch: 6| Step: 6
Training loss: 0.7429401797347938
Validation loss: 2.5614367039033445

Epoch: 6| Step: 7
Training loss: 0.7743456354492761
Validation loss: 2.623702076544986

Epoch: 6| Step: 8
Training loss: 0.949588499541971
Validation loss: 2.6119918645446796

Epoch: 6| Step: 9
Training loss: 1.03355594949376
Validation loss: 2.642885861707156

Epoch: 6| Step: 10
Training loss: 0.7659021382007271
Validation loss: 2.617106513293375

Epoch: 6| Step: 11
Training loss: 1.1998116583841325
Validation loss: 2.6296512479619802

Epoch: 6| Step: 12
Training loss: 1.0292421503738274
Validation loss: 2.6000908248883263

Epoch: 6| Step: 13
Training loss: 0.6282897439006352
Validation loss: 2.527460409043639

Epoch: 169| Step: 0
Training loss: 0.9105505355309705
Validation loss: 2.546305508901968

Epoch: 6| Step: 1
Training loss: 0.39172848288058754
Validation loss: 2.5972310495028252

Epoch: 6| Step: 2
Training loss: 0.6747203724544683
Validation loss: 2.5926111087882133

Epoch: 6| Step: 3
Training loss: 0.7693079900495491
Validation loss: 2.553065579367631

Epoch: 6| Step: 4
Training loss: 1.7175893853039466
Validation loss: 2.6019036391074364

Epoch: 6| Step: 5
Training loss: 0.714156106702376
Validation loss: 2.5238523978749945

Epoch: 6| Step: 6
Training loss: 0.5561889422048948
Validation loss: 2.52499717800373

Epoch: 6| Step: 7
Training loss: 0.9439664352519443
Validation loss: 2.5839103751568593

Epoch: 6| Step: 8
Training loss: 1.1042051608495154
Validation loss: 2.600407753662065

Epoch: 6| Step: 9
Training loss: 0.9698556312803072
Validation loss: 2.517228573054193

Epoch: 6| Step: 10
Training loss: 0.8864258269742538
Validation loss: 2.5239757912462752

Epoch: 6| Step: 11
Training loss: 0.7890346635497395
Validation loss: 2.5200029902465677

Epoch: 6| Step: 12
Training loss: 0.8588247791920175
Validation loss: 2.6014915815582915

Epoch: 6| Step: 13
Training loss: 0.9099900581005418
Validation loss: 2.531763299458515

Epoch: 170| Step: 0
Training loss: 0.9322706607320405
Validation loss: 2.6543128485873826

Epoch: 6| Step: 1
Training loss: 0.7250317270637358
Validation loss: 2.60764494476315

Epoch: 6| Step: 2
Training loss: 1.2914295542899514
Validation loss: 2.5204589161101545

Epoch: 6| Step: 3
Training loss: 0.6309965474658465
Validation loss: 2.6414703054482978

Epoch: 6| Step: 4
Training loss: 0.9445920673791655
Validation loss: 2.5681223403373483

Epoch: 6| Step: 5
Training loss: 1.064977674115921
Validation loss: 2.599098107523384

Epoch: 6| Step: 6
Training loss: 0.9839449048881015
Validation loss: 2.6131649172006775

Epoch: 6| Step: 7
Training loss: 0.7261545820470274
Validation loss: 2.734110225392187

Epoch: 6| Step: 8
Training loss: 0.6572984313213712
Validation loss: 2.64324498414567

Epoch: 6| Step: 9
Training loss: 0.5560758703904743
Validation loss: 2.609756776821053

Epoch: 6| Step: 10
Training loss: 1.5286616812495908
Validation loss: 2.5790685603187176

Epoch: 6| Step: 11
Training loss: 0.793418568779313
Validation loss: 2.6161311280884476

Epoch: 6| Step: 12
Training loss: 0.5745747559036064
Validation loss: 2.562181561540655

Epoch: 6| Step: 13
Training loss: 0.7831370261594013
Validation loss: 2.561894833817662

Epoch: 171| Step: 0
Training loss: 1.0031596572926011
Validation loss: 2.5776842453401314

Epoch: 6| Step: 1
Training loss: 0.620222380118876
Validation loss: 2.537415378080337

Epoch: 6| Step: 2
Training loss: 0.745033189431103
Validation loss: 2.60064120394496

Epoch: 6| Step: 3
Training loss: 0.8482745328459126
Validation loss: 2.548686906159297

Epoch: 6| Step: 4
Training loss: 0.9916915254656046
Validation loss: 2.618530445105688

Epoch: 6| Step: 5
Training loss: 0.5963805802227529
Validation loss: 2.5803881951483048

Epoch: 6| Step: 6
Training loss: 1.007818414241973
Validation loss: 2.6290698517769475

Epoch: 6| Step: 7
Training loss: 0.664003593973694
Validation loss: 2.563789771912429

Epoch: 6| Step: 8
Training loss: 0.7863172610916266
Validation loss: 2.5217288977471615

Epoch: 6| Step: 9
Training loss: 1.4918778183027095
Validation loss: 2.596594281254796

Epoch: 6| Step: 10
Training loss: 0.8915647267214528
Validation loss: 2.5931471848015826

Epoch: 6| Step: 11
Training loss: 1.1281899684468812
Validation loss: 2.5248753847399232

Epoch: 6| Step: 12
Training loss: 0.7278723446199622
Validation loss: 2.5758585359724084

Epoch: 6| Step: 13
Training loss: 0.8854668135560407
Validation loss: 2.572613460162909

Epoch: 172| Step: 0
Training loss: 0.7599873354132659
Validation loss: 2.5436466014820334

Epoch: 6| Step: 1
Training loss: 1.0386232867573972
Validation loss: 2.6092388246984135

Epoch: 6| Step: 2
Training loss: 0.7851075873786092
Validation loss: 2.5494301894837657

Epoch: 6| Step: 3
Training loss: 1.0066796966892595
Validation loss: 2.541464630810439

Epoch: 6| Step: 4
Training loss: 0.6001357958028588
Validation loss: 2.6145557893515514

Epoch: 6| Step: 5
Training loss: 0.8966320306855164
Validation loss: 2.5950597650338016

Epoch: 6| Step: 6
Training loss: 0.9810489290597381
Validation loss: 2.5996623082817956

Epoch: 6| Step: 7
Training loss: 0.9183808396012141
Validation loss: 2.5590583049506717

Epoch: 6| Step: 8
Training loss: 0.6361695477821258
Validation loss: 2.5624550683649105

Epoch: 6| Step: 9
Training loss: 0.9094158976164283
Validation loss: 2.6077971875301347

Epoch: 6| Step: 10
Training loss: 1.462490867521024
Validation loss: 2.5311520561452503

Epoch: 6| Step: 11
Training loss: 0.90185335383144
Validation loss: 2.607074904007281

Epoch: 6| Step: 12
Training loss: 0.8201003390655356
Validation loss: 2.610283836116943

Epoch: 6| Step: 13
Training loss: 0.8775314089596066
Validation loss: 2.565751919876982

Epoch: 173| Step: 0
Training loss: 0.7262806089191686
Validation loss: 2.5653509547351394

Epoch: 6| Step: 1
Training loss: 0.6355114589921612
Validation loss: 2.5472691548843702

Epoch: 6| Step: 2
Training loss: 1.2059705202950102
Validation loss: 2.61013488973924

Epoch: 6| Step: 3
Training loss: 0.6116675266533539
Validation loss: 2.5854492571731384

Epoch: 6| Step: 4
Training loss: 0.7384987162667328
Validation loss: 2.584728530756746

Epoch: 6| Step: 5
Training loss: 1.1124676860445368
Validation loss: 2.53529273686025

Epoch: 6| Step: 6
Training loss: 0.9546242476017419
Validation loss: 2.600311895149673

Epoch: 6| Step: 7
Training loss: 1.5897948611379042
Validation loss: 2.5240228247711265

Epoch: 6| Step: 8
Training loss: 0.6729443933150351
Validation loss: 2.5701814210314566

Epoch: 6| Step: 9
Training loss: 0.5704952104084919
Validation loss: 2.5549582941566906

Epoch: 6| Step: 10
Training loss: 0.738779132223428
Validation loss: 2.6192099960057367

Epoch: 6| Step: 11
Training loss: 0.6788194747972495
Validation loss: 2.5900899809349087

Epoch: 6| Step: 12
Training loss: 0.7090336385798754
Validation loss: 2.6394315200741176

Epoch: 6| Step: 13
Training loss: 0.9273080267770337
Validation loss: 2.558761622233692

Epoch: 174| Step: 0
Training loss: 0.7518044064582678
Validation loss: 2.6455797514458093

Epoch: 6| Step: 1
Training loss: 0.9399154064991763
Validation loss: 2.5965064388963928

Epoch: 6| Step: 2
Training loss: 0.7800045767674297
Validation loss: 2.669145688480573

Epoch: 6| Step: 3
Training loss: 0.725603188146634
Validation loss: 2.595663276559763

Epoch: 6| Step: 4
Training loss: 1.0419702214765294
Validation loss: 2.5999797936412374

Epoch: 6| Step: 5
Training loss: 1.1006112827743788
Validation loss: 2.5724338099

Epoch: 6| Step: 6
Training loss: 0.6865246964032066
Validation loss: 2.610629360812393

Epoch: 6| Step: 7
Training loss: 1.1549963469674607
Validation loss: 2.56446831014243

Epoch: 6| Step: 8
Training loss: 0.7578128932676573
Validation loss: 2.5967705232404112

Epoch: 6| Step: 9
Training loss: 1.5385367952793547
Validation loss: 2.613836597228567

Epoch: 6| Step: 10
Training loss: 0.6824270919661531
Validation loss: 2.575807211562561

Epoch: 6| Step: 11
Training loss: 0.6210546181305218
Validation loss: 2.59644101430308

Epoch: 6| Step: 12
Training loss: 1.0082849977010717
Validation loss: 2.598133550022211

Epoch: 6| Step: 13
Training loss: 0.8456967818306429
Validation loss: 2.615946119460831

Epoch: 175| Step: 0
Training loss: 1.3427674893334165
Validation loss: 2.606442278653825

Epoch: 6| Step: 1
Training loss: 0.560791706488337
Validation loss: 2.6128670554747844

Epoch: 6| Step: 2
Training loss: 0.8195236045691697
Validation loss: 2.654537411780899

Epoch: 6| Step: 3
Training loss: 0.7717099017052873
Validation loss: 2.5872548292786255

Epoch: 6| Step: 4
Training loss: 0.5257436707714722
Validation loss: 2.554495910242042

Epoch: 6| Step: 5
Training loss: 0.5823272617995625
Validation loss: 2.528610501630187

Epoch: 6| Step: 6
Training loss: 0.6035543879927386
Validation loss: 2.6269322353132787

Epoch: 6| Step: 7
Training loss: 0.9235271584607303
Validation loss: 2.5484330729826756

Epoch: 6| Step: 8
Training loss: 0.6188885148417478
Validation loss: 2.5722730091464974

Epoch: 6| Step: 9
Training loss: 0.8314480954231858
Validation loss: 2.6211846644272674

Epoch: 6| Step: 10
Training loss: 1.5757845907407573
Validation loss: 2.544731985967618

Epoch: 6| Step: 11
Training loss: 0.6403970545452605
Validation loss: 2.6353214885025054

Epoch: 6| Step: 12
Training loss: 0.7701787016079001
Validation loss: 2.5237770875620527

Epoch: 6| Step: 13
Training loss: 0.868204843187653
Validation loss: 2.5870633934834806

Epoch: 176| Step: 0
Training loss: 0.7486073757102815
Validation loss: 2.5964096175649045

Epoch: 6| Step: 1
Training loss: 1.1419695937255836
Validation loss: 2.5763475860913494

Epoch: 6| Step: 2
Training loss: 0.8302121761014511
Validation loss: 2.5788509695404604

Epoch: 6| Step: 3
Training loss: 0.7290438457772649
Validation loss: 2.5621960312351217

Epoch: 6| Step: 4
Training loss: 0.5254221059450591
Validation loss: 2.5536487890282573

Epoch: 6| Step: 5
Training loss: 0.8392770674007888
Validation loss: 2.5183044443381686

Epoch: 6| Step: 6
Training loss: 0.49710489089096865
Validation loss: 2.564963350771604

Epoch: 6| Step: 7
Training loss: 0.7604742986360261
Validation loss: 2.664540327220689

Epoch: 6| Step: 8
Training loss: 1.1881046261713644
Validation loss: 2.5894615539576256

Epoch: 6| Step: 9
Training loss: 0.55967546310559
Validation loss: 2.581236762751027

Epoch: 6| Step: 10
Training loss: 1.4789091163603447
Validation loss: 2.5623776786575947

Epoch: 6| Step: 11
Training loss: 0.6257723804088189
Validation loss: 2.548757345062094

Epoch: 6| Step: 12
Training loss: 0.7252940929728227
Validation loss: 2.5748165133140857

Epoch: 6| Step: 13
Training loss: 1.030710310311313
Validation loss: 2.546761336647406

Epoch: 177| Step: 0
Training loss: 0.5603236641226399
Validation loss: 2.608439462430289

Epoch: 6| Step: 1
Training loss: 1.543206923246501
Validation loss: 2.582321050696532

Epoch: 6| Step: 2
Training loss: 0.6973418506662263
Validation loss: 2.6301071424501536

Epoch: 6| Step: 3
Training loss: 0.7170893932384232
Validation loss: 2.5860237038065157

Epoch: 6| Step: 4
Training loss: 0.7344139575770495
Validation loss: 2.573954003728058

Epoch: 6| Step: 5
Training loss: 0.9223494521114558
Validation loss: 2.53846259439442

Epoch: 6| Step: 6
Training loss: 0.7374596439246974
Validation loss: 2.561486780464491

Epoch: 6| Step: 7
Training loss: 0.6131309276453702
Validation loss: 2.596838234810643

Epoch: 6| Step: 8
Training loss: 0.7486145813491337
Validation loss: 2.5096766039228986

Epoch: 6| Step: 9
Training loss: 0.793862163698803
Validation loss: 2.6077780948149853

Epoch: 6| Step: 10
Training loss: 0.9870908903769567
Validation loss: 2.5531287692480698

Epoch: 6| Step: 11
Training loss: 1.2144847474347749
Validation loss: 2.613702440745883

Epoch: 6| Step: 12
Training loss: 0.8629597889581551
Validation loss: 2.544616306137732

Epoch: 6| Step: 13
Training loss: 0.7750700088382106
Validation loss: 2.5382482073914776

Epoch: 178| Step: 0
Training loss: 0.47509934992552044
Validation loss: 2.605627433523785

Epoch: 6| Step: 1
Training loss: 0.7841110484485813
Validation loss: 2.6354251353815084

Epoch: 6| Step: 2
Training loss: 0.8204734644321228
Validation loss: 2.6802201033708264

Epoch: 6| Step: 3
Training loss: 1.027856213065448
Validation loss: 2.557972575876043

Epoch: 6| Step: 4
Training loss: 0.917158442854181
Validation loss: 2.5924334421077875

Epoch: 6| Step: 5
Training loss: 0.5891517723292524
Validation loss: 2.4807632391623544

Epoch: 6| Step: 6
Training loss: 1.0983023048865037
Validation loss: 2.5456133410796133

Epoch: 6| Step: 7
Training loss: 0.7258995066572637
Validation loss: 2.571465080196955

Epoch: 6| Step: 8
Training loss: 1.4871145566464756
Validation loss: 2.5485615519025346

Epoch: 6| Step: 9
Training loss: 0.5716099025618671
Validation loss: 2.618396506353779

Epoch: 6| Step: 10
Training loss: 0.7648171035442259
Validation loss: 2.5538017456169815

Epoch: 6| Step: 11
Training loss: 0.6128378072801329
Validation loss: 2.634986048160222

Epoch: 6| Step: 12
Training loss: 0.9916641777605725
Validation loss: 2.5617347132774966

Epoch: 6| Step: 13
Training loss: 0.7727874952961179
Validation loss: 2.568715141226931

Epoch: 179| Step: 0
Training loss: 0.45454853988814103
Validation loss: 2.6136862645769603

Epoch: 6| Step: 1
Training loss: 0.7765039095660434
Validation loss: 2.6110323974116936

Epoch: 6| Step: 2
Training loss: 0.8978463923546284
Validation loss: 2.5575108223813836

Epoch: 6| Step: 3
Training loss: 1.0737486764457813
Validation loss: 2.6381582065574913

Epoch: 6| Step: 4
Training loss: 0.6829182366179908
Validation loss: 2.6139285013528455

Epoch: 6| Step: 5
Training loss: 0.6476141056572127
Validation loss: 2.61585147595765

Epoch: 6| Step: 6
Training loss: 0.5656233539873484
Validation loss: 2.6007257439009237

Epoch: 6| Step: 7
Training loss: 0.6930876723369203
Validation loss: 2.5524876929449425

Epoch: 6| Step: 8
Training loss: 0.8141508204604482
Validation loss: 2.5539270138180905

Epoch: 6| Step: 9
Training loss: 0.9615750562599943
Validation loss: 2.617147781298426

Epoch: 6| Step: 10
Training loss: 0.8697763239864574
Validation loss: 2.626850762435063

Epoch: 6| Step: 11
Training loss: 0.5865865799803679
Validation loss: 2.637934907729531

Epoch: 6| Step: 12
Training loss: 1.312468528370239
Validation loss: 2.6602188827453253

Epoch: 6| Step: 13
Training loss: 1.07637705984418
Validation loss: 2.6162464784469996

Epoch: 180| Step: 0
Training loss: 0.7617000479725335
Validation loss: 2.6821717368168683

Epoch: 6| Step: 1
Training loss: 0.9806700723961931
Validation loss: 2.6129460521325703

Epoch: 6| Step: 2
Training loss: 0.9386279949547373
Validation loss: 2.593285990195445

Epoch: 6| Step: 3
Training loss: 0.8004158116590416
Validation loss: 2.602045115629778

Epoch: 6| Step: 4
Training loss: 0.8094597937746704
Validation loss: 2.5909800925354403

Epoch: 6| Step: 5
Training loss: 0.6901950248550558
Validation loss: 2.6110532316822623

Epoch: 6| Step: 6
Training loss: 0.8049566318842758
Validation loss: 2.653118396836186

Epoch: 6| Step: 7
Training loss: 0.4428304466428172
Validation loss: 2.5406352644709482

Epoch: 6| Step: 8
Training loss: 0.7023636404579521
Validation loss: 2.58457843451861

Epoch: 6| Step: 9
Training loss: 0.8390959493267225
Validation loss: 2.688259017573036

Epoch: 6| Step: 10
Training loss: 0.8167196156081376
Validation loss: 2.6581928104421944

Epoch: 6| Step: 11
Training loss: 0.7829240791764375
Validation loss: 2.664218245472252

Epoch: 6| Step: 12
Training loss: 0.8238883418381975
Validation loss: 2.6184515941614026

Epoch: 6| Step: 13
Training loss: 1.5602499210239678
Validation loss: 2.516785103387858

Epoch: 181| Step: 0
Training loss: 0.4828700559068212
Validation loss: 2.5535951664723515

Epoch: 6| Step: 1
Training loss: 0.5666408184644978
Validation loss: 2.625575093442258

Epoch: 6| Step: 2
Training loss: 0.7951065336379014
Validation loss: 2.6424543074955413

Epoch: 6| Step: 3
Training loss: 1.424901403395833
Validation loss: 2.531445703672486

Epoch: 6| Step: 4
Training loss: 0.6661218015995217
Validation loss: 2.513946162555503

Epoch: 6| Step: 5
Training loss: 1.0133341849683228
Validation loss: 2.5680397289259056

Epoch: 6| Step: 6
Training loss: 0.7824779397091264
Validation loss: 2.5979419369502255

Epoch: 6| Step: 7
Training loss: 0.770211862795558
Validation loss: 2.656834422127461

Epoch: 6| Step: 8
Training loss: 1.1083741844985628
Validation loss: 2.5448170247781325

Epoch: 6| Step: 9
Training loss: 0.7520866374597504
Validation loss: 2.5407249446665583

Epoch: 6| Step: 10
Training loss: 0.5060131178124283
Validation loss: 2.6456957553528273

Epoch: 6| Step: 11
Training loss: 0.5665218892931488
Validation loss: 2.590938729806698

Epoch: 6| Step: 12
Training loss: 0.3902923311836225
Validation loss: 2.6421307816932535

Epoch: 6| Step: 13
Training loss: 0.8936629766499272
Validation loss: 2.606129011216804

Epoch: 182| Step: 0
Training loss: 0.6401775006674632
Validation loss: 2.59284888551066

Epoch: 6| Step: 1
Training loss: 0.4731982882641251
Validation loss: 2.6125879361138864

Epoch: 6| Step: 2
Training loss: 1.0138284492477458
Validation loss: 2.603282859873031

Epoch: 6| Step: 3
Training loss: 0.6835572587218904
Validation loss: 2.5764680412132

Epoch: 6| Step: 4
Training loss: 0.5407538486472498
Validation loss: 2.558059924009603

Epoch: 6| Step: 5
Training loss: 0.7679663688180356
Validation loss: 2.6178594988585147

Epoch: 6| Step: 6
Training loss: 0.9240979693729483
Validation loss: 2.582335969196867

Epoch: 6| Step: 7
Training loss: 1.588944689379203
Validation loss: 2.5819931912370575

Epoch: 6| Step: 8
Training loss: 0.7485078830316624
Validation loss: 2.6095006611731772

Epoch: 6| Step: 9
Training loss: 0.7863927944403322
Validation loss: 2.60373058991287

Epoch: 6| Step: 10
Training loss: 0.7244645459811242
Validation loss: 2.6197380429512633

Epoch: 6| Step: 11
Training loss: 0.7376660806541798
Validation loss: 2.6232729028804567

Epoch: 6| Step: 12
Training loss: 0.812526519049177
Validation loss: 2.6398435410703356

Epoch: 6| Step: 13
Training loss: 0.7055207445621552
Validation loss: 2.584393903977593

Epoch: 183| Step: 0
Training loss: 0.49481152611747825
Validation loss: 2.5673963706731198

Epoch: 6| Step: 1
Training loss: 0.5960941969643613
Validation loss: 2.622570806055939

Epoch: 6| Step: 2
Training loss: 1.3837850135846288
Validation loss: 2.5025468727775326

Epoch: 6| Step: 3
Training loss: 1.0198494133398261
Validation loss: 2.5966985940215044

Epoch: 6| Step: 4
Training loss: 0.8033014971873595
Validation loss: 2.5545350942151694

Epoch: 6| Step: 5
Training loss: 0.7084708127139034
Validation loss: 2.646282147966217

Epoch: 6| Step: 6
Training loss: 0.7811426470431646
Validation loss: 2.6216851451761745

Epoch: 6| Step: 7
Training loss: 0.5428228937097203
Validation loss: 2.664180361470222

Epoch: 6| Step: 8
Training loss: 0.6491577101380552
Validation loss: 2.590976902552421

Epoch: 6| Step: 9
Training loss: 0.90221572562271
Validation loss: 2.6183535051894187

Epoch: 6| Step: 10
Training loss: 0.7652574941697501
Validation loss: 2.6222905602233966

Epoch: 6| Step: 11
Training loss: 0.6878972639709043
Validation loss: 2.617791192569625

Epoch: 6| Step: 12
Training loss: 0.9424748034865769
Validation loss: 2.5697066453946285

Epoch: 6| Step: 13
Training loss: 0.6156000897165175
Validation loss: 2.5820391910217335

Epoch: 184| Step: 0
Training loss: 0.681338967629718
Validation loss: 2.5987031055774152

Epoch: 6| Step: 1
Training loss: 0.8406560473753273
Validation loss: 2.576698964616882

Epoch: 6| Step: 2
Training loss: 0.9810545489770396
Validation loss: 2.690009357644105

Epoch: 6| Step: 3
Training loss: 1.1295647729924558
Validation loss: 2.602100702313824

Epoch: 6| Step: 4
Training loss: 0.6189632703271157
Validation loss: 2.6523996608498623

Epoch: 6| Step: 5
Training loss: 1.672333698985624
Validation loss: 2.594690098887364

Epoch: 6| Step: 6
Training loss: 0.7753921239727914
Validation loss: 2.575260613348526

Epoch: 6| Step: 7
Training loss: 0.8326802476147499
Validation loss: 2.5963808987439236

Epoch: 6| Step: 8
Training loss: 0.8786775418574765
Validation loss: 2.6245063362953527

Epoch: 6| Step: 9
Training loss: 0.44979267775171783
Validation loss: 2.571171981129819

Epoch: 6| Step: 10
Training loss: 0.6258900027601613
Validation loss: 2.6061040817627115

Epoch: 6| Step: 11
Training loss: 0.5799169348560664
Validation loss: 2.5734078302701637

Epoch: 6| Step: 12
Training loss: 0.5568829995896208
Validation loss: 2.6288736614382113

Epoch: 6| Step: 13
Training loss: 0.6866429144916305
Validation loss: 2.5715175150003375

Epoch: 185| Step: 0
Training loss: 0.9537813084514442
Validation loss: 2.6176222710529404

Epoch: 6| Step: 1
Training loss: 0.5983076846204816
Validation loss: 2.536502568814184

Epoch: 6| Step: 2
Training loss: 0.5131886751484125
Validation loss: 2.5685268333003237

Epoch: 6| Step: 3
Training loss: 0.8866156967709748
Validation loss: 2.5281395973441145

Epoch: 6| Step: 4
Training loss: 0.6872412021083542
Validation loss: 2.6239371721525715

Epoch: 6| Step: 5
Training loss: 1.4556783577429362
Validation loss: 2.589162599834403

Epoch: 6| Step: 6
Training loss: 0.8879915756521907
Validation loss: 2.5934189887802876

Epoch: 6| Step: 7
Training loss: 0.7524939239611504
Validation loss: 2.551477233122326

Epoch: 6| Step: 8
Training loss: 0.7918393967233804
Validation loss: 2.538755944159126

Epoch: 6| Step: 9
Training loss: 0.6793397035527816
Validation loss: 2.5920096230789405

Epoch: 6| Step: 10
Training loss: 0.6132020109460309
Validation loss: 2.6379381162447926

Epoch: 6| Step: 11
Training loss: 0.5801637117587685
Validation loss: 2.5669460493431178

Epoch: 6| Step: 12
Training loss: 0.871489738471789
Validation loss: 2.648079629460935

Epoch: 6| Step: 13
Training loss: 0.8979751724217935
Validation loss: 2.5673966802196153

Epoch: 186| Step: 0
Training loss: 0.49377679812465247
Validation loss: 2.5806126778363003

Epoch: 6| Step: 1
Training loss: 0.7378420052936101
Validation loss: 2.6333313986211824

Epoch: 6| Step: 2
Training loss: 0.5811806422045481
Validation loss: 2.6340334030114994

Epoch: 6| Step: 3
Training loss: 0.9922520473840668
Validation loss: 2.6480898108450304

Epoch: 6| Step: 4
Training loss: 0.9326743223254667
Validation loss: 2.5742825165927274

Epoch: 6| Step: 5
Training loss: 1.3784316761877113
Validation loss: 2.5463703334204366

Epoch: 6| Step: 6
Training loss: 0.832063987696792
Validation loss: 2.6196346248529925

Epoch: 6| Step: 7
Training loss: 0.5792549020348228
Validation loss: 2.6255401933487614

Epoch: 6| Step: 8
Training loss: 0.7490454002850778
Validation loss: 2.6504092908074064

Epoch: 6| Step: 9
Training loss: 0.6060323737533412
Validation loss: 2.577169229612211

Epoch: 6| Step: 10
Training loss: 0.5854934535682659
Validation loss: 2.6605277826638556

Epoch: 6| Step: 11
Training loss: 0.735200012720604
Validation loss: 2.6115704131347917

Epoch: 6| Step: 12
Training loss: 0.9069251472389532
Validation loss: 2.6241530762707446

Epoch: 6| Step: 13
Training loss: 0.5500491261216874
Validation loss: 2.598801745104007

Epoch: 187| Step: 0
Training loss: 0.5237926018807479
Validation loss: 2.5867695463833247

Epoch: 6| Step: 1
Training loss: 0.8055264072150551
Validation loss: 2.61786799907199

Epoch: 6| Step: 2
Training loss: 1.1041705593304425
Validation loss: 2.650379605365241

Epoch: 6| Step: 3
Training loss: 0.6676902859808311
Validation loss: 2.526450312224679

Epoch: 6| Step: 4
Training loss: 0.5344470817626857
Validation loss: 2.5163681401633027

Epoch: 6| Step: 5
Training loss: 0.589252377574463
Validation loss: 2.6654262687776904

Epoch: 6| Step: 6
Training loss: 0.7176486575079872
Validation loss: 2.6672489504075383

Epoch: 6| Step: 7
Training loss: 0.6255629150270337
Validation loss: 2.656316689046798

Epoch: 6| Step: 8
Training loss: 1.3737262114251894
Validation loss: 2.6131039926639033

Epoch: 6| Step: 9
Training loss: 0.9084766263248677
Validation loss: 2.5453956379669407

Epoch: 6| Step: 10
Training loss: 0.8472683629949781
Validation loss: 2.6631135415713505

Epoch: 6| Step: 11
Training loss: 0.6114812543386572
Validation loss: 2.631011739470968

Epoch: 6| Step: 12
Training loss: 0.8727615197327577
Validation loss: 2.624756196219855

Epoch: 6| Step: 13
Training loss: 0.47880021021220087
Validation loss: 2.5931295855519845

Epoch: 188| Step: 0
Training loss: 0.8874228618571673
Validation loss: 2.614659833865435

Epoch: 6| Step: 1
Training loss: 1.0336756067595703
Validation loss: 2.619168373622777

Epoch: 6| Step: 2
Training loss: 1.1234830589765799
Validation loss: 2.571385392546802

Epoch: 6| Step: 3
Training loss: 0.5297591101928365
Validation loss: 2.63364322585326

Epoch: 6| Step: 4
Training loss: 0.738767635244696
Validation loss: 2.600312223699948

Epoch: 6| Step: 5
Training loss: 0.5780648380627792
Validation loss: 2.6187459983582677

Epoch: 6| Step: 6
Training loss: 0.688920028386078
Validation loss: 2.57542586400611

Epoch: 6| Step: 7
Training loss: 0.8323475411144186
Validation loss: 2.5947723786627366

Epoch: 6| Step: 8
Training loss: 0.6064540598264576
Validation loss: 2.643969537684543

Epoch: 6| Step: 9
Training loss: 0.6978708413485469
Validation loss: 2.6345775132721045

Epoch: 6| Step: 10
Training loss: 0.5987099975809527
Validation loss: 2.567858342759668

Epoch: 6| Step: 11
Training loss: 0.5057441845388385
Validation loss: 2.6413421409459445

Epoch: 6| Step: 12
Training loss: 1.3532113397905126
Validation loss: 2.5830322879816694

Epoch: 6| Step: 13
Training loss: 0.7486042306859461
Validation loss: 2.653572019100093

Epoch: 189| Step: 0
Training loss: 0.6640726874074961
Validation loss: 2.5773028209065525

Epoch: 6| Step: 1
Training loss: 0.4898090417176922
Validation loss: 2.6427297386552557

Epoch: 6| Step: 2
Training loss: 0.4733323550158227
Validation loss: 2.530643563171473

Epoch: 6| Step: 3
Training loss: 0.7151953661045265
Validation loss: 2.625397061790019

Epoch: 6| Step: 4
Training loss: 0.6972613294453097
Validation loss: 2.634433266329834

Epoch: 6| Step: 5
Training loss: 0.7482266919615884
Validation loss: 2.605733085007701

Epoch: 6| Step: 6
Training loss: 0.6899224863880115
Validation loss: 2.6136199777262896

Epoch: 6| Step: 7
Training loss: 0.8609865856543453
Validation loss: 2.5981738652771464

Epoch: 6| Step: 8
Training loss: 0.5983472830794154
Validation loss: 2.629059339792189

Epoch: 6| Step: 9
Training loss: 0.8998391868712745
Validation loss: 2.6027823672621127

Epoch: 6| Step: 10
Training loss: 0.8396097611337414
Validation loss: 2.5771588297224

Epoch: 6| Step: 11
Training loss: 0.7808066063550628
Validation loss: 2.5873830544647247

Epoch: 6| Step: 12
Training loss: 0.9489106985308554
Validation loss: 2.622548775378428

Epoch: 6| Step: 13
Training loss: 1.403235022090626
Validation loss: 2.5900973142656887

Epoch: 190| Step: 0
Training loss: 0.852628338346278
Validation loss: 2.666405058982621

Epoch: 6| Step: 1
Training loss: 0.8572499443892991
Validation loss: 2.6540407305612606

Epoch: 6| Step: 2
Training loss: 0.4543501470923435
Validation loss: 2.640811605086237

Epoch: 6| Step: 3
Training loss: 0.5969507878306077
Validation loss: 2.636827910247615

Epoch: 6| Step: 4
Training loss: 0.5862805188985089
Validation loss: 2.6087806314066206

Epoch: 6| Step: 5
Training loss: 0.7224819901145539
Validation loss: 2.661477319658394

Epoch: 6| Step: 6
Training loss: 0.7700196086566623
Validation loss: 2.5730424662323936

Epoch: 6| Step: 7
Training loss: 0.7905188613634442
Validation loss: 2.5485717098806444

Epoch: 6| Step: 8
Training loss: 0.7520476839135266
Validation loss: 2.6395362851818165

Epoch: 6| Step: 9
Training loss: 0.7919595243630637
Validation loss: 2.61714444101317

Epoch: 6| Step: 10
Training loss: 1.2763904432237247
Validation loss: 2.612316316477718

Epoch: 6| Step: 11
Training loss: 0.675456547870676
Validation loss: 2.5662611519233205

Epoch: 6| Step: 12
Training loss: 0.7971477041924834
Validation loss: 2.6127641030260897

Epoch: 6| Step: 13
Training loss: 0.5930260712230175
Validation loss: 2.6362790492268946

Epoch: 191| Step: 0
Training loss: 0.6620124138247292
Validation loss: 2.586999388963185

Epoch: 6| Step: 1
Training loss: 0.6524254296614448
Validation loss: 2.6460340353669474

Epoch: 6| Step: 2
Training loss: 0.4877999947684375
Validation loss: 2.6465147948071053

Epoch: 6| Step: 3
Training loss: 0.7265308332207817
Validation loss: 2.6224396950400797

Epoch: 6| Step: 4
Training loss: 0.5878856063070926
Validation loss: 2.6059965850552023

Epoch: 6| Step: 5
Training loss: 0.6742038729585561
Validation loss: 2.616841573295969

Epoch: 6| Step: 6
Training loss: 1.6465806672706156
Validation loss: 2.611595062178236

Epoch: 6| Step: 7
Training loss: 0.7713554177970622
Validation loss: 2.6167615553381878

Epoch: 6| Step: 8
Training loss: 0.9047309048111443
Validation loss: 2.616890430196918

Epoch: 6| Step: 9
Training loss: 0.5356079756747605
Validation loss: 2.595551045490437

Epoch: 6| Step: 10
Training loss: 0.7399651835602248
Validation loss: 2.556239567543386

Epoch: 6| Step: 11
Training loss: 0.8189248837361895
Validation loss: 2.594178872864515

Epoch: 6| Step: 12
Training loss: 0.7353148432222927
Validation loss: 2.6119061830972714

Epoch: 6| Step: 13
Training loss: 0.5712738295912517
Validation loss: 2.604854436969967

Epoch: 192| Step: 0
Training loss: 0.7948381909460421
Validation loss: 2.633889903230366

Epoch: 6| Step: 1
Training loss: 0.5196744965138168
Validation loss: 2.5953775607870244

Epoch: 6| Step: 2
Training loss: 0.687896982366157
Validation loss: 2.5322845213044034

Epoch: 6| Step: 3
Training loss: 0.8174334912558011
Validation loss: 2.5979240183865175

Epoch: 6| Step: 4
Training loss: 0.5443780297634109
Validation loss: 2.637909759161359

Epoch: 6| Step: 5
Training loss: 0.38501847377646004
Validation loss: 2.5852107383816647

Epoch: 6| Step: 6
Training loss: 0.6653839874921883
Validation loss: 2.59778744932716

Epoch: 6| Step: 7
Training loss: 0.8202816911997247
Validation loss: 2.588453177481713

Epoch: 6| Step: 8
Training loss: 1.0426613572571675
Validation loss: 2.6175681525353873

Epoch: 6| Step: 9
Training loss: 1.4068577618688882
Validation loss: 2.5907174885755424

Epoch: 6| Step: 10
Training loss: 0.6603358774880751
Validation loss: 2.573920758007972

Epoch: 6| Step: 11
Training loss: 0.5190055309728596
Validation loss: 2.6404009090043883

Epoch: 6| Step: 12
Training loss: 0.7534592246962517
Validation loss: 2.6412205071644865

Epoch: 6| Step: 13
Training loss: 0.5032444829813677
Validation loss: 2.6234583036117787

Epoch: 193| Step: 0
Training loss: 0.9197252067382566
Validation loss: 2.662543466896723

Epoch: 6| Step: 1
Training loss: 0.6985342202006324
Validation loss: 2.6614180161818437

Epoch: 6| Step: 2
Training loss: 0.5337722033097008
Validation loss: 2.6886401012973833

Epoch: 6| Step: 3
Training loss: 0.8107881118092949
Validation loss: 2.6197387255153526

Epoch: 6| Step: 4
Training loss: 0.6361582810969656
Validation loss: 2.651962799745373

Epoch: 6| Step: 5
Training loss: 0.8189394404107313
Validation loss: 2.6376990561074454

Epoch: 6| Step: 6
Training loss: 0.7554575717102973
Validation loss: 2.605329243872813

Epoch: 6| Step: 7
Training loss: 1.3326125680350556
Validation loss: 2.7031766118467746

Epoch: 6| Step: 8
Training loss: 0.6160278048185076
Validation loss: 2.6375726367415804

Epoch: 6| Step: 9
Training loss: 0.9260179241270635
Validation loss: 2.7622252939038714

Epoch: 6| Step: 10
Training loss: 0.4841034958917084
Validation loss: 2.6794012007586456

Epoch: 6| Step: 11
Training loss: 0.7254531348620633
Validation loss: 2.726758714846119

Epoch: 6| Step: 12
Training loss: 0.5103662686541222
Validation loss: 2.6131853010945956

Epoch: 6| Step: 13
Training loss: 0.7289469160734147
Validation loss: 2.679918373772191

Epoch: 194| Step: 0
Training loss: 0.9113703803360128
Validation loss: 2.695041189498231

Epoch: 6| Step: 1
Training loss: 0.8005467885727369
Validation loss: 2.6712826077689438

Epoch: 6| Step: 2
Training loss: 0.5231524588101916
Validation loss: 2.6254594945650807

Epoch: 6| Step: 3
Training loss: 0.7717731176929405
Validation loss: 2.6862237694526017

Epoch: 6| Step: 4
Training loss: 0.7581583787153836
Validation loss: 2.612364588731055

Epoch: 6| Step: 5
Training loss: 0.40251667047417183
Validation loss: 2.6864712542641866

Epoch: 6| Step: 6
Training loss: 0.5143489943705781
Validation loss: 2.6031827644695293

Epoch: 6| Step: 7
Training loss: 0.8041588611586332
Validation loss: 2.609560383133334

Epoch: 6| Step: 8
Training loss: 0.7646228693442401
Validation loss: 2.588171517344761

Epoch: 6| Step: 9
Training loss: 0.6529626023842261
Validation loss: 2.585400735978672

Epoch: 6| Step: 10
Training loss: 0.6699321290057197
Validation loss: 2.6315608610401697

Epoch: 6| Step: 11
Training loss: 0.4757927948000485
Validation loss: 2.6165517917451755

Epoch: 6| Step: 12
Training loss: 1.5196431175181762
Validation loss: 2.6671204230573236

Epoch: 6| Step: 13
Training loss: 0.6366213858648088
Validation loss: 2.655465328030665

Epoch: 195| Step: 0
Training loss: 0.6515308271801279
Validation loss: 2.6115324348939675

Epoch: 6| Step: 1
Training loss: 0.5363260556686056
Validation loss: 2.5779347590375803

Epoch: 6| Step: 2
Training loss: 0.6133429623794727
Validation loss: 2.6152810512078126

Epoch: 6| Step: 3
Training loss: 0.719176497592972
Validation loss: 2.7161732005090498

Epoch: 6| Step: 4
Training loss: 0.7068532224314155
Validation loss: 2.57361047221729

Epoch: 6| Step: 5
Training loss: 0.8056998320066238
Validation loss: 2.601258574213027

Epoch: 6| Step: 6
Training loss: 0.6448809050977115
Validation loss: 2.5825384798903657

Epoch: 6| Step: 7
Training loss: 0.5888532950057843
Validation loss: 2.593516741455713

Epoch: 6| Step: 8
Training loss: 1.4286603729624454
Validation loss: 2.574510248145656

Epoch: 6| Step: 9
Training loss: 1.0010803466585503
Validation loss: 2.568938006646838

Epoch: 6| Step: 10
Training loss: 0.7735193767944005
Validation loss: 2.651850943461124

Epoch: 6| Step: 11
Training loss: 0.56937603294036
Validation loss: 2.633380077848541

Epoch: 6| Step: 12
Training loss: 0.5158308080828127
Validation loss: 2.56013567329048

Epoch: 6| Step: 13
Training loss: 0.4834806276057896
Validation loss: 2.646457153030161

Epoch: 196| Step: 0
Training loss: 0.7369343010463587
Validation loss: 2.629337617381567

Epoch: 6| Step: 1
Training loss: 0.5719311879388836
Validation loss: 2.7381706124745415

Epoch: 6| Step: 2
Training loss: 1.035323392221787
Validation loss: 2.6460311595420904

Epoch: 6| Step: 3
Training loss: 0.8752704270590669
Validation loss: 2.637014520327657

Epoch: 6| Step: 4
Training loss: 0.8026408491389231
Validation loss: 2.659388778298199

Epoch: 6| Step: 5
Training loss: 0.40735914967249653
Validation loss: 2.6483865018452515

Epoch: 6| Step: 6
Training loss: 0.9006323169355435
Validation loss: 2.607524924081419

Epoch: 6| Step: 7
Training loss: 0.7645043716056185
Validation loss: 2.6172871812654823

Epoch: 6| Step: 8
Training loss: 0.6501424504956063
Validation loss: 2.5628352527424747

Epoch: 6| Step: 9
Training loss: 0.74705048578419
Validation loss: 2.6614021001699197

Epoch: 6| Step: 10
Training loss: 0.4560004780018125
Validation loss: 2.585483184581738

Epoch: 6| Step: 11
Training loss: 0.37428756431571647
Validation loss: 2.686553248641378

Epoch: 6| Step: 12
Training loss: 0.6572791612728232
Validation loss: 2.6177129720901533

Epoch: 6| Step: 13
Training loss: 1.396935876804153
Validation loss: 2.5979348246029823

Epoch: 197| Step: 0
Training loss: 0.565997114069695
Validation loss: 2.6664086803175957

Epoch: 6| Step: 1
Training loss: 0.6006622266000219
Validation loss: 2.6088467822836985

Epoch: 6| Step: 2
Training loss: 0.9487573577635762
Validation loss: 2.5595971544768075

Epoch: 6| Step: 3
Training loss: 0.5396190479295813
Validation loss: 2.651495781596554

Epoch: 6| Step: 4
Training loss: 0.7833382354407086
Validation loss: 2.638383655256958

Epoch: 6| Step: 5
Training loss: 0.8147555368427876
Validation loss: 2.7516443653770284

Epoch: 6| Step: 6
Training loss: 0.6821186171392603
Validation loss: 2.6127086063311156

Epoch: 6| Step: 7
Training loss: 0.5873475972805886
Validation loss: 2.605722715247951

Epoch: 6| Step: 8
Training loss: 0.9107546169636236
Validation loss: 2.574818457836441

Epoch: 6| Step: 9
Training loss: 0.417672096576898
Validation loss: 2.5942651704303783

Epoch: 6| Step: 10
Training loss: 0.6419021157960361
Validation loss: 2.5381330304964775

Epoch: 6| Step: 11
Training loss: 0.4746190136845169
Validation loss: 2.5790020154205804

Epoch: 6| Step: 12
Training loss: 0.43796147123038986
Validation loss: 2.657988319808559

Epoch: 6| Step: 13
Training loss: 1.433855578551987
Validation loss: 2.638335565368068

Epoch: 198| Step: 0
Training loss: 0.578940460800413
Validation loss: 2.6073183341547903

Epoch: 6| Step: 1
Training loss: 0.9417853007797969
Validation loss: 2.5835127973259864

Epoch: 6| Step: 2
Training loss: 0.8025828123294614
Validation loss: 2.5481858653737683

Epoch: 6| Step: 3
Training loss: 0.4415246922747593
Validation loss: 2.663128596860493

Epoch: 6| Step: 4
Training loss: 0.48818419445570915
Validation loss: 2.5967445398911515

Epoch: 6| Step: 5
Training loss: 0.8039427338413256
Validation loss: 2.5895794809874904

Epoch: 6| Step: 6
Training loss: 0.7687855316882696
Validation loss: 2.593745587816277

Epoch: 6| Step: 7
Training loss: 0.8293509495804764
Validation loss: 2.633172920829853

Epoch: 6| Step: 8
Training loss: 0.5519664268753603
Validation loss: 2.5825880780483916

Epoch: 6| Step: 9
Training loss: 0.8477375325552026
Validation loss: 2.5851112728408325

Epoch: 6| Step: 10
Training loss: 0.5310765432032155
Validation loss: 2.6289170422268726

Epoch: 6| Step: 11
Training loss: 0.7515830974968317
Validation loss: 2.617993427138678

Epoch: 6| Step: 12
Training loss: 0.5013965831382254
Validation loss: 2.472519969750255

Epoch: 6| Step: 13
Training loss: 1.2126343682154044
Validation loss: 2.544635373059121

Epoch: 199| Step: 0
Training loss: 0.448476891997221
Validation loss: 2.6610250300707134

Epoch: 6| Step: 1
Training loss: 0.5175090815719372
Validation loss: 2.623612551882

Epoch: 6| Step: 2
Training loss: 0.5410160656868692
Validation loss: 2.540536376420914

Epoch: 6| Step: 3
Training loss: 0.8623320250103726
Validation loss: 2.6251729272467403

Epoch: 6| Step: 4
Training loss: 0.7976319700724775
Validation loss: 2.706539357069573

Epoch: 6| Step: 5
Training loss: 0.696300918456763
Validation loss: 2.6016221903539263

Epoch: 6| Step: 6
Training loss: 0.7258868613872743
Validation loss: 2.557969142783377

Epoch: 6| Step: 7
Training loss: 1.425537924709959
Validation loss: 2.6602928959298078

Epoch: 6| Step: 8
Training loss: 0.6934510506212364
Validation loss: 2.608378115219801

Epoch: 6| Step: 9
Training loss: 0.9287720669143888
Validation loss: 2.6386209290520775

Epoch: 6| Step: 10
Training loss: 0.4192757004007152
Validation loss: 2.5935825309156084

Epoch: 6| Step: 11
Training loss: 0.660479156253328
Validation loss: 2.6042459145249914

Epoch: 6| Step: 12
Training loss: 0.6362791825892241
Validation loss: 2.595209806287248

Epoch: 6| Step: 13
Training loss: 0.7024725748118629
Validation loss: 2.660896948764681

Epoch: 200| Step: 0
Training loss: 1.214509089945121
Validation loss: 2.6903252647706495

Epoch: 6| Step: 1
Training loss: 0.5648344659108258
Validation loss: 2.59657380537485

Epoch: 6| Step: 2
Training loss: 0.5795713323707706
Validation loss: 2.675604108529708

Epoch: 6| Step: 3
Training loss: 0.847636139099349
Validation loss: 2.6858638396046124

Epoch: 6| Step: 4
Training loss: 0.5205522987006451
Validation loss: 2.6187182983688904

Epoch: 6| Step: 5
Training loss: 0.7680404086360239
Validation loss: 2.612299348344427

Epoch: 6| Step: 6
Training loss: 0.5369932846842878
Validation loss: 2.6054569913264225

Epoch: 6| Step: 7
Training loss: 0.9498460682587933
Validation loss: 2.6440367017902413

Epoch: 6| Step: 8
Training loss: 0.6805213548755695
Validation loss: 2.6076064217131174

Epoch: 6| Step: 9
Training loss: 0.6808509515360539
Validation loss: 2.6630015418725894

Epoch: 6| Step: 10
Training loss: 0.635414847908127
Validation loss: 2.6020784525116674

Epoch: 6| Step: 11
Training loss: 0.702064859352844
Validation loss: 2.577631754845413

Epoch: 6| Step: 12
Training loss: 0.792514614608258
Validation loss: 2.6396623470661083

Epoch: 6| Step: 13
Training loss: 0.5007927094337141
Validation loss: 2.5958914897725176

Epoch: 201| Step: 0
Training loss: 0.6550801158276528
Validation loss: 2.619110403092788

Epoch: 6| Step: 1
Training loss: 0.7845066096925156
Validation loss: 2.5773149547141996

Epoch: 6| Step: 2
Training loss: 0.5551230372836783
Validation loss: 2.631294831825034

Epoch: 6| Step: 3
Training loss: 0.6196898903081658
Validation loss: 2.608468650216598

Epoch: 6| Step: 4
Training loss: 0.9701093242918725
Validation loss: 2.5745330989085757

Epoch: 6| Step: 5
Training loss: 0.5186544778500183
Validation loss: 2.6622019635278638

Epoch: 6| Step: 6
Training loss: 0.48422534230346337
Validation loss: 2.6191449640604594

Epoch: 6| Step: 7
Training loss: 0.7390037109994175
Validation loss: 2.5988384262485527

Epoch: 6| Step: 8
Training loss: 0.6223428748888686
Validation loss: 2.630244344836176

Epoch: 6| Step: 9
Training loss: 0.5119851270802794
Validation loss: 2.6208323894634478

Epoch: 6| Step: 10
Training loss: 1.2845038523395365
Validation loss: 2.6062630848971584

Epoch: 6| Step: 11
Training loss: 0.3489158400478795
Validation loss: 2.6814122335441555

Epoch: 6| Step: 12
Training loss: 0.7861985078455415
Validation loss: 2.621367029534568

Epoch: 6| Step: 13
Training loss: 0.6304899379946809
Validation loss: 2.5731261061291604

Epoch: 202| Step: 0
Training loss: 0.5142110453433855
Validation loss: 2.5967089156540295

Epoch: 6| Step: 1
Training loss: 0.6185750453864317
Validation loss: 2.590655430276442

Epoch: 6| Step: 2
Training loss: 0.6927069589892835
Validation loss: 2.627587118304585

Epoch: 6| Step: 3
Training loss: 1.252129219513431
Validation loss: 2.578137977644499

Epoch: 6| Step: 4
Training loss: 0.7236307532812721
Validation loss: 2.5584933428682395

Epoch: 6| Step: 5
Training loss: 0.8076864856293551
Validation loss: 2.550437962564089

Epoch: 6| Step: 6
Training loss: 0.7454151842569189
Validation loss: 2.6238708641028494

Epoch: 6| Step: 7
Training loss: 0.42392084540196084
Validation loss: 2.599643079394464

Epoch: 6| Step: 8
Training loss: 0.7623496548376467
Validation loss: 2.604269046042558

Epoch: 6| Step: 9
Training loss: 0.8434562171648555
Validation loss: 2.5832955655034118

Epoch: 6| Step: 10
Training loss: 0.42616123777098597
Validation loss: 2.6164140156140587

Epoch: 6| Step: 11
Training loss: 0.5847004101712814
Validation loss: 2.595997040017081

Epoch: 6| Step: 12
Training loss: 0.7143087417432912
Validation loss: 2.5945473942785147

Epoch: 6| Step: 13
Training loss: 0.6013304275125653
Validation loss: 2.641658768707246

Epoch: 203| Step: 0
Training loss: 0.76765717155204
Validation loss: 2.6341163734559436

Epoch: 6| Step: 1
Training loss: 1.1852233545848208
Validation loss: 2.6789490448730153

Epoch: 6| Step: 2
Training loss: 0.6630250119069875
Validation loss: 2.678054935068501

Epoch: 6| Step: 3
Training loss: 0.49234362048671304
Validation loss: 2.6662548661161507

Epoch: 6| Step: 4
Training loss: 0.5136572542031624
Validation loss: 2.6038639553880203

Epoch: 6| Step: 5
Training loss: 0.5993270457856972
Validation loss: 2.6314207222494903

Epoch: 6| Step: 6
Training loss: 0.5536591036316573
Validation loss: 2.6362933232458783

Epoch: 6| Step: 7
Training loss: 0.6328254980942282
Validation loss: 2.6169479336387065

Epoch: 6| Step: 8
Training loss: 0.4379214062450888
Validation loss: 2.6534857784340824

Epoch: 6| Step: 9
Training loss: 0.5483223155643352
Validation loss: 2.6594155391796352

Epoch: 6| Step: 10
Training loss: 0.7091869138508643
Validation loss: 2.5825788001033554

Epoch: 6| Step: 11
Training loss: 0.7431387577435661
Validation loss: 2.6361847211902

Epoch: 6| Step: 12
Training loss: 0.9474701336202241
Validation loss: 2.6183663365619014

Epoch: 6| Step: 13
Training loss: 0.6792824513865711
Validation loss: 2.6100923842672294

Epoch: 204| Step: 0
Training loss: 0.40721670088502376
Validation loss: 2.577978218601172

Epoch: 6| Step: 1
Training loss: 1.4116661040850302
Validation loss: 2.6004396369513274

Epoch: 6| Step: 2
Training loss: 0.6590138770771116
Validation loss: 2.638989169462953

Epoch: 6| Step: 3
Training loss: 0.607167696745225
Validation loss: 2.606496369009625

Epoch: 6| Step: 4
Training loss: 0.5594518246453798
Validation loss: 2.6501295148041737

Epoch: 6| Step: 5
Training loss: 0.48866784622397835
Validation loss: 2.610993224271673

Epoch: 6| Step: 6
Training loss: 0.4862102534222734
Validation loss: 2.646348382475148

Epoch: 6| Step: 7
Training loss: 0.8606263500194724
Validation loss: 2.5846161938520185

Epoch: 6| Step: 8
Training loss: 0.6298010957924598
Validation loss: 2.6580321672500937

Epoch: 6| Step: 9
Training loss: 0.4623872941819856
Validation loss: 2.67461063367709

Epoch: 6| Step: 10
Training loss: 0.6396707778407273
Validation loss: 2.6303470814181686

Epoch: 6| Step: 11
Training loss: 0.7824805677152172
Validation loss: 2.5863422795373006

Epoch: 6| Step: 12
Training loss: 0.8116609202135184
Validation loss: 2.6643577553768716

Epoch: 6| Step: 13
Training loss: 0.6505491046448136
Validation loss: 2.6267006527046175

Epoch: 205| Step: 0
Training loss: 0.494403769045455
Validation loss: 2.639431806117578

Epoch: 6| Step: 1
Training loss: 0.4279409110244073
Validation loss: 2.6131952002650927

Epoch: 6| Step: 2
Training loss: 0.6166731707341632
Validation loss: 2.6488982543452613

Epoch: 6| Step: 3
Training loss: 0.7477502458853207
Validation loss: 2.5624223402707487

Epoch: 6| Step: 4
Training loss: 0.4516868954553249
Validation loss: 2.602166931381347

Epoch: 6| Step: 5
Training loss: 0.707906992080738
Validation loss: 2.6550808296902604

Epoch: 6| Step: 6
Training loss: 1.361740422035347
Validation loss: 2.684691921202812

Epoch: 6| Step: 7
Training loss: 0.9096653805673895
Validation loss: 2.6810719849625118

Epoch: 6| Step: 8
Training loss: 0.867252587977375
Validation loss: 2.7028908159542757

Epoch: 6| Step: 9
Training loss: 0.5581170295325624
Validation loss: 2.706080370161304

Epoch: 6| Step: 10
Training loss: 0.4570143280809074
Validation loss: 2.584361830419883

Epoch: 6| Step: 11
Training loss: 0.638629876951993
Validation loss: 2.5979748829240985

Epoch: 6| Step: 12
Training loss: 1.0011463746965852
Validation loss: 2.696631929620235

Epoch: 6| Step: 13
Training loss: 0.5629458779530799
Validation loss: 2.6250351494751882

Epoch: 206| Step: 0
Training loss: 0.6855811955482121
Validation loss: 2.5440888640744843

Epoch: 6| Step: 1
Training loss: 0.770332538893469
Validation loss: 2.643122573482193

Epoch: 6| Step: 2
Training loss: 0.34416518280703884
Validation loss: 2.639757634655208

Epoch: 6| Step: 3
Training loss: 0.6758065852890056
Validation loss: 2.6695364222943

Epoch: 6| Step: 4
Training loss: 0.5643468578584053
Validation loss: 2.6734944245167522

Epoch: 6| Step: 5
Training loss: 0.49531647473013035
Validation loss: 2.586639170803673

Epoch: 6| Step: 6
Training loss: 0.5340226969610207
Validation loss: 2.617602468207668

Epoch: 6| Step: 7
Training loss: 0.5488879351081017
Validation loss: 2.6021285868349993

Epoch: 6| Step: 8
Training loss: 1.2381406397363688
Validation loss: 2.6466836889457843

Epoch: 6| Step: 9
Training loss: 0.4058966200098327
Validation loss: 2.66865610378874

Epoch: 6| Step: 10
Training loss: 0.6314380224097933
Validation loss: 2.618865838595661

Epoch: 6| Step: 11
Training loss: 0.4222512862940835
Validation loss: 2.6312719529928277

Epoch: 6| Step: 12
Training loss: 0.8688048324844854
Validation loss: 2.6012656774725165

Epoch: 6| Step: 13
Training loss: 0.8298197624691501
Validation loss: 2.60203095916091

Epoch: 207| Step: 0
Training loss: 1.2487124487621655
Validation loss: 2.650028917166844

Epoch: 6| Step: 1
Training loss: 0.5124589066196585
Validation loss: 2.6855374866668282

Epoch: 6| Step: 2
Training loss: 0.7872900365035486
Validation loss: 2.6589019103563194

Epoch: 6| Step: 3
Training loss: 0.512775262320991
Validation loss: 2.645142237198598

Epoch: 6| Step: 4
Training loss: 0.5966873543054777
Validation loss: 2.626647477644653

Epoch: 6| Step: 5
Training loss: 0.4938149566415471
Validation loss: 2.6757315452395716

Epoch: 6| Step: 6
Training loss: 0.5939019410324043
Validation loss: 2.67753827772612

Epoch: 6| Step: 7
Training loss: 0.868372854521992
Validation loss: 2.63812564944136

Epoch: 6| Step: 8
Training loss: 0.83837087246351
Validation loss: 2.62887275451513

Epoch: 6| Step: 9
Training loss: 0.6110175809547247
Validation loss: 2.609240545589215

Epoch: 6| Step: 10
Training loss: 0.5005333261455741
Validation loss: 2.652257222190725

Epoch: 6| Step: 11
Training loss: 0.8403031268293955
Validation loss: 2.617617322253215

Epoch: 6| Step: 12
Training loss: 0.2990932410533474
Validation loss: 2.6383584883746387

Epoch: 6| Step: 13
Training loss: 0.4167039039979582
Validation loss: 2.692342919077293

Epoch: 208| Step: 0
Training loss: 0.5168459337726812
Validation loss: 2.6504962912260526

Epoch: 6| Step: 1
Training loss: 0.36767225529777214
Validation loss: 2.6237522368885746

Epoch: 6| Step: 2
Training loss: 0.9316190001339187
Validation loss: 2.6419087436441187

Epoch: 6| Step: 3
Training loss: 0.5145185331967743
Validation loss: 2.673851791436857

Epoch: 6| Step: 4
Training loss: 0.4998391458931911
Validation loss: 2.667981126792874

Epoch: 6| Step: 5
Training loss: 0.7917358886839189
Validation loss: 2.6641012134890074

Epoch: 6| Step: 6
Training loss: 0.6992371412874056
Validation loss: 2.6573325699953294

Epoch: 6| Step: 7
Training loss: 0.6313932775549195
Validation loss: 2.6613601372825646

Epoch: 6| Step: 8
Training loss: 0.7678288251781611
Validation loss: 2.5839879888200272

Epoch: 6| Step: 9
Training loss: 1.2597396966202847
Validation loss: 2.631442112376747

Epoch: 6| Step: 10
Training loss: 0.910779813070664
Validation loss: 2.6440172846407575

Epoch: 6| Step: 11
Training loss: 0.5640702054245057
Validation loss: 2.603508924707909

Epoch: 6| Step: 12
Training loss: 0.39257043859444146
Validation loss: 2.6049035415802826

Epoch: 6| Step: 13
Training loss: 0.5243788268685085
Validation loss: 2.651827118137366

Epoch: 209| Step: 0
Training loss: 0.5636763458180393
Validation loss: 2.6220446859441764

Epoch: 6| Step: 1
Training loss: 0.639018463445599
Validation loss: 2.6179268167572074

Epoch: 6| Step: 2
Training loss: 0.4870116398093965
Validation loss: 2.636650510305232

Epoch: 6| Step: 3
Training loss: 1.2623832535349722
Validation loss: 2.638196200648321

Epoch: 6| Step: 4
Training loss: 0.6792426133159588
Validation loss: 2.618089419909583

Epoch: 6| Step: 5
Training loss: 0.5046061305538139
Validation loss: 2.5721199768742093

Epoch: 6| Step: 6
Training loss: 0.7884568259901746
Validation loss: 2.632726424533582

Epoch: 6| Step: 7
Training loss: 0.569931791557859
Validation loss: 2.6141257069226085

Epoch: 6| Step: 8
Training loss: 0.5963153132368401
Validation loss: 2.5913506712850776

Epoch: 6| Step: 9
Training loss: 0.49104101377898834
Validation loss: 2.607466405138245

Epoch: 6| Step: 10
Training loss: 0.5424662398455989
Validation loss: 2.68110195305459

Epoch: 6| Step: 11
Training loss: 0.6024406760834802
Validation loss: 2.617197247387399

Epoch: 6| Step: 12
Training loss: 0.7746798238493227
Validation loss: 2.67057853610103

Epoch: 6| Step: 13
Training loss: 0.8629488412914811
Validation loss: 2.634882172876314

Epoch: 210| Step: 0
Training loss: 0.6061279891812249
Validation loss: 2.6586729256297366

Epoch: 6| Step: 1
Training loss: 0.7946191159616027
Validation loss: 2.6473513676338025

Epoch: 6| Step: 2
Training loss: 0.6411257391806551
Validation loss: 2.5790013374827065

Epoch: 6| Step: 3
Training loss: 0.7619918724838108
Validation loss: 2.5907774901442835

Epoch: 6| Step: 4
Training loss: 0.7231685163086412
Validation loss: 2.643924953542652

Epoch: 6| Step: 5
Training loss: 0.5294030283654313
Validation loss: 2.6143967054005457

Epoch: 6| Step: 6
Training loss: 0.4836288981690989
Validation loss: 2.620314427744536

Epoch: 6| Step: 7
Training loss: 0.3382758662123567
Validation loss: 2.6055243932757914

Epoch: 6| Step: 8
Training loss: 0.733653911687104
Validation loss: 2.5531144894057114

Epoch: 6| Step: 9
Training loss: 0.6285950263814273
Validation loss: 2.6392273825224093

Epoch: 6| Step: 10
Training loss: 0.8726514223626046
Validation loss: 2.5693445363825766

Epoch: 6| Step: 11
Training loss: 0.4862692770532291
Validation loss: 2.6465520158032207

Epoch: 6| Step: 12
Training loss: 1.2484547600728704
Validation loss: 2.625570386648386

Epoch: 6| Step: 13
Training loss: 0.7948651867647841
Validation loss: 2.614086557335749

Epoch: 211| Step: 0
Training loss: 0.630707808200399
Validation loss: 2.5961553152466013

Epoch: 6| Step: 1
Training loss: 0.6361053882528385
Validation loss: 2.6719413808566745

Epoch: 6| Step: 2
Training loss: 1.104160572730948
Validation loss: 2.595287648540757

Epoch: 6| Step: 3
Training loss: 0.4853730686266225
Validation loss: 2.6370099997081913

Epoch: 6| Step: 4
Training loss: 0.8929656541825745
Validation loss: 2.6190061864217853

Epoch: 6| Step: 5
Training loss: 0.7414521439299243
Validation loss: 2.639328753190942

Epoch: 6| Step: 6
Training loss: 0.46165233076241186
Validation loss: 2.649689130123102

Epoch: 6| Step: 7
Training loss: 0.4003779897789588
Validation loss: 2.6681418709464686

Epoch: 6| Step: 8
Training loss: 0.40520824229706015
Validation loss: 2.593948617094413

Epoch: 6| Step: 9
Training loss: 0.5459422467554362
Validation loss: 2.595906108327956

Epoch: 6| Step: 10
Training loss: 0.6000359474778238
Validation loss: 2.6226755098513155

Epoch: 6| Step: 11
Training loss: 0.8703912202856844
Validation loss: 2.6562622818008417

Epoch: 6| Step: 12
Training loss: 0.6492018503498237
Validation loss: 2.5423242677155433

Epoch: 6| Step: 13
Training loss: 0.676357112129817
Validation loss: 2.670755728210593

Epoch: 212| Step: 0
Training loss: 0.3585244978311553
Validation loss: 2.6943275163018163

Epoch: 6| Step: 1
Training loss: 0.5752583907923349
Validation loss: 2.651767134314653

Epoch: 6| Step: 2
Training loss: 0.7552594310092109
Validation loss: 2.604560781537983

Epoch: 6| Step: 3
Training loss: 0.5352393872359471
Validation loss: 2.6313492418724347

Epoch: 6| Step: 4
Training loss: 0.6737531979684891
Validation loss: 2.568372092560006

Epoch: 6| Step: 5
Training loss: 0.4148073155267529
Validation loss: 2.6690610229407112

Epoch: 6| Step: 6
Training loss: 0.41351263855620213
Validation loss: 2.638451255236267

Epoch: 6| Step: 7
Training loss: 0.633131794379965
Validation loss: 2.6142057827605174

Epoch: 6| Step: 8
Training loss: 0.6459850215179239
Validation loss: 2.6130140668814232

Epoch: 6| Step: 9
Training loss: 0.6265817891336232
Validation loss: 2.653840891089691

Epoch: 6| Step: 10
Training loss: 1.2094142562448622
Validation loss: 2.6127532136606746

Epoch: 6| Step: 11
Training loss: 0.8147033746048492
Validation loss: 2.629855040941759

Epoch: 6| Step: 12
Training loss: 0.707425845138725
Validation loss: 2.677860849678315

Epoch: 6| Step: 13
Training loss: 0.8223618838401766
Validation loss: 2.6309198506141596

Epoch: 213| Step: 0
Training loss: 0.3507756965554438
Validation loss: 2.6441794630555133

Epoch: 6| Step: 1
Training loss: 1.1566064645965513
Validation loss: 2.661926397582901

Epoch: 6| Step: 2
Training loss: 0.47122423126839624
Validation loss: 2.6239338102225784

Epoch: 6| Step: 3
Training loss: 0.8488156524458097
Validation loss: 2.592679074588367

Epoch: 6| Step: 4
Training loss: 0.7305505064228567
Validation loss: 2.6847101191101896

Epoch: 6| Step: 5
Training loss: 0.565033795476918
Validation loss: 2.6235137395211208

Epoch: 6| Step: 6
Training loss: 0.5569279782304596
Validation loss: 2.611624595077635

Epoch: 6| Step: 7
Training loss: 1.0183027912394211
Validation loss: 2.599654115386936

Epoch: 6| Step: 8
Training loss: 0.6779977687894629
Validation loss: 2.569847103449231

Epoch: 6| Step: 9
Training loss: 0.5236064865853609
Validation loss: 2.656408118235418

Epoch: 6| Step: 10
Training loss: 0.6751640456035848
Validation loss: 2.624006764650348

Epoch: 6| Step: 11
Training loss: 0.6070356950633962
Validation loss: 2.651626707223906

Epoch: 6| Step: 12
Training loss: 0.5914555437112476
Validation loss: 2.6384291086587193

Epoch: 6| Step: 13
Training loss: 0.5462957311556683
Validation loss: 2.601657747314074

Epoch: 214| Step: 0
Training loss: 0.45079978032098306
Validation loss: 2.6449751075289605

Epoch: 6| Step: 1
Training loss: 0.6808361344958812
Validation loss: 2.5904294555636347

Epoch: 6| Step: 2
Training loss: 0.6106476332687732
Validation loss: 2.6276745567811437

Epoch: 6| Step: 3
Training loss: 1.2909527415601907
Validation loss: 2.671727018366768

Epoch: 6| Step: 4
Training loss: 0.4266076423876137
Validation loss: 2.646553186927319

Epoch: 6| Step: 5
Training loss: 0.47916085474663633
Validation loss: 2.6584111715498557

Epoch: 6| Step: 6
Training loss: 0.5360877290819548
Validation loss: 2.6151963891899954

Epoch: 6| Step: 7
Training loss: 0.5549063720857667
Validation loss: 2.6298380877571526

Epoch: 6| Step: 8
Training loss: 0.7129320524537125
Validation loss: 2.616377831471106

Epoch: 6| Step: 9
Training loss: 0.38125120694329
Validation loss: 2.6633788244908336

Epoch: 6| Step: 10
Training loss: 0.6284319824932585
Validation loss: 2.53669135859482

Epoch: 6| Step: 11
Training loss: 0.5045905383241663
Validation loss: 2.6566942030541765

Epoch: 6| Step: 12
Training loss: 1.0070496266702957
Validation loss: 2.645880410884435

Epoch: 6| Step: 13
Training loss: 0.5108952192725345
Validation loss: 2.636713113661028

Epoch: 215| Step: 0
Training loss: 0.6851505100962401
Validation loss: 2.6272428407176163

Epoch: 6| Step: 1
Training loss: 0.7523824679829081
Validation loss: 2.6238561211809834

Epoch: 6| Step: 2
Training loss: 0.5870278703532891
Validation loss: 2.6553264283867746

Epoch: 6| Step: 3
Training loss: 0.45942180161582097
Validation loss: 2.6835960303032675

Epoch: 6| Step: 4
Training loss: 1.1939940317985602
Validation loss: 2.6965474565968828

Epoch: 6| Step: 5
Training loss: 0.7402014813122567
Validation loss: 2.646766788292861

Epoch: 6| Step: 6
Training loss: 0.6818400968295284
Validation loss: 2.626030817933745

Epoch: 6| Step: 7
Training loss: 0.6033483230149596
Validation loss: 2.6291864329913466

Epoch: 6| Step: 8
Training loss: 0.665945815737505
Validation loss: 2.6746750970009057

Epoch: 6| Step: 9
Training loss: 0.5077917828368674
Validation loss: 2.6209663098617693

Epoch: 6| Step: 10
Training loss: 0.41032004945757866
Validation loss: 2.615136993471627

Epoch: 6| Step: 11
Training loss: 0.6402672955263384
Validation loss: 2.6408194596357606

Epoch: 6| Step: 12
Training loss: 0.5530712597274304
Validation loss: 2.570361731153412

Epoch: 6| Step: 13
Training loss: 0.4804420308693084
Validation loss: 2.642006191211755

Epoch: 216| Step: 0
Training loss: 0.5532743694111358
Validation loss: 2.5775493865487937

Epoch: 6| Step: 1
Training loss: 0.6834616615200266
Validation loss: 2.666953910814633

Epoch: 6| Step: 2
Training loss: 0.6281581718074207
Validation loss: 2.6255684948478284

Epoch: 6| Step: 3
Training loss: 0.7324319660763176
Validation loss: 2.6098967466477747

Epoch: 6| Step: 4
Training loss: 0.5784430015875259
Validation loss: 2.597828725954353

Epoch: 6| Step: 5
Training loss: 0.5618514985122516
Validation loss: 2.5963454531743726

Epoch: 6| Step: 6
Training loss: 1.3112842287699913
Validation loss: 2.569590180075897

Epoch: 6| Step: 7
Training loss: 0.6490039189974188
Validation loss: 2.622955252495131

Epoch: 6| Step: 8
Training loss: 0.7618911939218962
Validation loss: 2.640403888782438

Epoch: 6| Step: 9
Training loss: 0.5140323606891078
Validation loss: 2.6360205736167814

Epoch: 6| Step: 10
Training loss: 0.4661474938247629
Validation loss: 2.6579011759167295

Epoch: 6| Step: 11
Training loss: 0.533241522108628
Validation loss: 2.6519660512238596

Epoch: 6| Step: 12
Training loss: 0.4046710765849453
Validation loss: 2.5842646694041926

Epoch: 6| Step: 13
Training loss: 0.5340957436167537
Validation loss: 2.593246487689063

Epoch: 217| Step: 0
Training loss: 0.6766461256821285
Validation loss: 2.7012595647230366

Epoch: 6| Step: 1
Training loss: 0.41153329657289717
Validation loss: 2.5944021393292194

Epoch: 6| Step: 2
Training loss: 0.51723687780411
Validation loss: 2.6463276158601126

Epoch: 6| Step: 3
Training loss: 0.5627934432205618
Validation loss: 2.5526238057309163

Epoch: 6| Step: 4
Training loss: 0.8695497728484465
Validation loss: 2.573622407274822

Epoch: 6| Step: 5
Training loss: 0.40665564092492146
Validation loss: 2.633001243398807

Epoch: 6| Step: 6
Training loss: 1.2064280561361993
Validation loss: 2.629661546028668

Epoch: 6| Step: 7
Training loss: 0.9100179608113106
Validation loss: 2.6036656368199695

Epoch: 6| Step: 8
Training loss: 0.6673837520513488
Validation loss: 2.660191674353719

Epoch: 6| Step: 9
Training loss: 0.7616508649262319
Validation loss: 2.6640495382014144

Epoch: 6| Step: 10
Training loss: 0.5097952647745384
Validation loss: 2.606630080796428

Epoch: 6| Step: 11
Training loss: 0.5133405421832499
Validation loss: 2.611830311898235

Epoch: 6| Step: 12
Training loss: 0.7421400757746278
Validation loss: 2.626830779562705

Epoch: 6| Step: 13
Training loss: 0.6472009105020539
Validation loss: 2.6229516696387063

Epoch: 218| Step: 0
Training loss: 0.5738679502000571
Validation loss: 2.6661076307431912

Epoch: 6| Step: 1
Training loss: 0.8011683575103336
Validation loss: 2.5950028407963934

Epoch: 6| Step: 2
Training loss: 0.7271047230136521
Validation loss: 2.6553352351571733

Epoch: 6| Step: 3
Training loss: 1.138360427480013
Validation loss: 2.6136740715714315

Epoch: 6| Step: 4
Training loss: 0.532204891778569
Validation loss: 2.5648046534898428

Epoch: 6| Step: 5
Training loss: 0.6463734050370314
Validation loss: 2.6262581701331658

Epoch: 6| Step: 6
Training loss: 0.620569067486986
Validation loss: 2.6419942492273982

Epoch: 6| Step: 7
Training loss: 0.7472217680548793
Validation loss: 2.6112747586374447

Epoch: 6| Step: 8
Training loss: 0.4467760429988749
Validation loss: 2.6100992122881777

Epoch: 6| Step: 9
Training loss: 0.42912942885289407
Validation loss: 2.580688450579036

Epoch: 6| Step: 10
Training loss: 0.5262180322283927
Validation loss: 2.5354045477906357

Epoch: 6| Step: 11
Training loss: 0.5918295067581373
Validation loss: 2.599072590815577

Epoch: 6| Step: 12
Training loss: 0.8083264190011059
Validation loss: 2.559668084869939

Epoch: 6| Step: 13
Training loss: 0.6638964052608348
Validation loss: 2.5982909916145274

Epoch: 219| Step: 0
Training loss: 0.49588762341397524
Validation loss: 2.6116544167288738

Epoch: 6| Step: 1
Training loss: 0.23947118470135187
Validation loss: 2.6618427862406713

Epoch: 6| Step: 2
Training loss: 0.6614683530954715
Validation loss: 2.6267549461288406

Epoch: 6| Step: 3
Training loss: 1.1805838406982825
Validation loss: 2.664055758082714

Epoch: 6| Step: 4
Training loss: 0.4921589343546221
Validation loss: 2.6392133953830688

Epoch: 6| Step: 5
Training loss: 0.4697747473478894
Validation loss: 2.5975789682465584

Epoch: 6| Step: 6
Training loss: 0.3732790998075184
Validation loss: 2.6068739335551734

Epoch: 6| Step: 7
Training loss: 0.7667808371687085
Validation loss: 2.6020640900640717

Epoch: 6| Step: 8
Training loss: 0.40502307926163095
Validation loss: 2.5749877491137974

Epoch: 6| Step: 9
Training loss: 0.705225963362765
Validation loss: 2.707753256274251

Epoch: 6| Step: 10
Training loss: 0.7201728834439927
Validation loss: 2.638253864767111

Epoch: 6| Step: 11
Training loss: 0.663364896678306
Validation loss: 2.6587995597669307

Epoch: 6| Step: 12
Training loss: 0.3978369057024432
Validation loss: 2.619202289049787

Epoch: 6| Step: 13
Training loss: 0.4916550920492575
Validation loss: 2.658806905348218

Epoch: 220| Step: 0
Training loss: 0.6245889026944069
Validation loss: 2.6450889371258928

Epoch: 6| Step: 1
Training loss: 0.5046621168621038
Validation loss: 2.5727581150350884

Epoch: 6| Step: 2
Training loss: 0.5006562932552983
Validation loss: 2.653612091079535

Epoch: 6| Step: 3
Training loss: 0.5790789955206521
Validation loss: 2.678451445783598

Epoch: 6| Step: 4
Training loss: 0.4166696091389073
Validation loss: 2.60904742562286

Epoch: 6| Step: 5
Training loss: 1.1570666238862441
Validation loss: 2.66126077793436

Epoch: 6| Step: 6
Training loss: 0.5649760902460097
Validation loss: 2.647326323528355

Epoch: 6| Step: 7
Training loss: 0.3665798516162716
Validation loss: 2.5593797558688673

Epoch: 6| Step: 8
Training loss: 0.6830522408787861
Validation loss: 2.56732426079998

Epoch: 6| Step: 9
Training loss: 0.5758173999799411
Validation loss: 2.619402700459919

Epoch: 6| Step: 10
Training loss: 0.7510054127641612
Validation loss: 2.5847429049775426

Epoch: 6| Step: 11
Training loss: 0.6865058126127103
Validation loss: 2.6077959075759485

Epoch: 6| Step: 12
Training loss: 0.4542473015670952
Validation loss: 2.58004967873327

Epoch: 6| Step: 13
Training loss: 0.6423145437687846
Validation loss: 2.6057429667403573

Epoch: 221| Step: 0
Training loss: 0.7340142195776839
Validation loss: 2.5520981197837083

Epoch: 6| Step: 1
Training loss: 0.42785653238118765
Validation loss: 2.6258626307631996

Epoch: 6| Step: 2
Training loss: 1.0095001402954489
Validation loss: 2.587041382988357

Epoch: 6| Step: 3
Training loss: 0.4857697249376973
Validation loss: 2.6361960111889573

Epoch: 6| Step: 4
Training loss: 0.4141598712944448
Validation loss: 2.5742869852889108

Epoch: 6| Step: 5
Training loss: 0.6774344096510543
Validation loss: 2.633229163278373

Epoch: 6| Step: 6
Training loss: 0.4450157079978183
Validation loss: 2.6684825173545623

Epoch: 6| Step: 7
Training loss: 0.5270238400483213
Validation loss: 2.6876028765719453

Epoch: 6| Step: 8
Training loss: 0.5464131175900363
Validation loss: 2.6716658601464167

Epoch: 6| Step: 9
Training loss: 0.5326618619283575
Validation loss: 2.6057277933854555

Epoch: 6| Step: 10
Training loss: 1.0861163095044686
Validation loss: 2.6005595033137525

Epoch: 6| Step: 11
Training loss: 0.8407053586421291
Validation loss: 2.686852709865639

Epoch: 6| Step: 12
Training loss: 0.5002515875139645
Validation loss: 2.6122373311993914

Epoch: 6| Step: 13
Training loss: 0.5819068366088173
Validation loss: 2.6182374888198616

Epoch: 222| Step: 0
Training loss: 0.5154652781628318
Validation loss: 2.5667603750173082

Epoch: 6| Step: 1
Training loss: 0.4941351517083937
Validation loss: 2.6247628422735514

Epoch: 6| Step: 2
Training loss: 0.7522298328514578
Validation loss: 2.619910862500773

Epoch: 6| Step: 3
Training loss: 0.6342996383401945
Validation loss: 2.5786537938209237

Epoch: 6| Step: 4
Training loss: 0.5300584220176117
Validation loss: 2.62784302113891

Epoch: 6| Step: 5
Training loss: 0.8249793136777527
Validation loss: 2.6478565970589614

Epoch: 6| Step: 6
Training loss: 0.641908151426081
Validation loss: 2.5821064732723125

Epoch: 6| Step: 7
Training loss: 0.43798033708153106
Validation loss: 2.6675888915595767

Epoch: 6| Step: 8
Training loss: 1.2153642036345305
Validation loss: 2.5779470517176564

Epoch: 6| Step: 9
Training loss: 0.6530452314516559
Validation loss: 2.704603683786127

Epoch: 6| Step: 10
Training loss: 0.6436290321764623
Validation loss: 2.6429753875423554

Epoch: 6| Step: 11
Training loss: 0.5063196393375977
Validation loss: 2.6208896093184078

Epoch: 6| Step: 12
Training loss: 0.4550833967828535
Validation loss: 2.6802948021657476

Epoch: 6| Step: 13
Training loss: 0.6031481417233532
Validation loss: 2.6505312375142878

Epoch: 223| Step: 0
Training loss: 0.6432208988621025
Validation loss: 2.606991179633379

Epoch: 6| Step: 1
Training loss: 0.5930807960205489
Validation loss: 2.643335640302167

Epoch: 6| Step: 2
Training loss: 0.6644197288521403
Validation loss: 2.6182484767898098

Epoch: 6| Step: 3
Training loss: 0.38154067699563277
Validation loss: 2.6751718388679877

Epoch: 6| Step: 4
Training loss: 0.6172920573071641
Validation loss: 2.646634864047536

Epoch: 6| Step: 5
Training loss: 1.2104906303582021
Validation loss: 2.641150292510823

Epoch: 6| Step: 6
Training loss: 0.41022392804500174
Validation loss: 2.6165016604189297

Epoch: 6| Step: 7
Training loss: 0.5621997243708882
Validation loss: 2.5631658805409234

Epoch: 6| Step: 8
Training loss: 0.3609623888030041
Validation loss: 2.5825908321914977

Epoch: 6| Step: 9
Training loss: 0.5386436051107645
Validation loss: 2.5729389163971588

Epoch: 6| Step: 10
Training loss: 0.46792541137647065
Validation loss: 2.567327186095034

Epoch: 6| Step: 11
Training loss: 0.5786807765304371
Validation loss: 2.5732284284944065

Epoch: 6| Step: 12
Training loss: 0.7888491880436991
Validation loss: 2.62598668582734

Epoch: 6| Step: 13
Training loss: 0.4846428468993166
Validation loss: 2.558186925329134

Epoch: 224| Step: 0
Training loss: 0.5413243208377295
Validation loss: 2.560692095136263

Epoch: 6| Step: 1
Training loss: 0.3188919574052342
Validation loss: 2.625633935220757

Epoch: 6| Step: 2
Training loss: 0.5625539859720364
Validation loss: 2.6117194373985435

Epoch: 6| Step: 3
Training loss: 0.5760641740905202
Validation loss: 2.576111903443346

Epoch: 6| Step: 4
Training loss: 0.33343404748446653
Validation loss: 2.563414402768194

Epoch: 6| Step: 5
Training loss: 0.6474108554348338
Validation loss: 2.6988649996764713

Epoch: 6| Step: 6
Training loss: 1.1151037991538133
Validation loss: 2.7173464868415604

Epoch: 6| Step: 7
Training loss: 0.6259232853967112
Validation loss: 2.6712720833940913

Epoch: 6| Step: 8
Training loss: 0.4871463556637487
Validation loss: 2.672358389213996

Epoch: 6| Step: 9
Training loss: 0.527464958672238
Validation loss: 2.644790937181462

Epoch: 6| Step: 10
Training loss: 0.43680657201519657
Validation loss: 2.6065010645118

Epoch: 6| Step: 11
Training loss: 0.4833261146773676
Validation loss: 2.6586620225266375

Epoch: 6| Step: 12
Training loss: 0.6437711915907641
Validation loss: 2.700186320928557

Epoch: 6| Step: 13
Training loss: 0.4593316732462204
Validation loss: 2.652015474704398

Epoch: 225| Step: 0
Training loss: 0.649984719940463
Validation loss: 2.6803238894334127

Epoch: 6| Step: 1
Training loss: 1.2795722024512766
Validation loss: 2.627184579477887

Epoch: 6| Step: 2
Training loss: 0.41160172567357983
Validation loss: 2.619479618991495

Epoch: 6| Step: 3
Training loss: 0.6485442567751744
Validation loss: 2.6520571209695185

Epoch: 6| Step: 4
Training loss: 0.5334984656582678
Validation loss: 2.571016843192857

Epoch: 6| Step: 5
Training loss: 0.5315741503749046
Validation loss: 2.745404666633759

Epoch: 6| Step: 6
Training loss: 0.6435551968979158
Validation loss: 2.6781310370372386

Epoch: 6| Step: 7
Training loss: 0.5175881726711198
Validation loss: 2.54791452299097

Epoch: 6| Step: 8
Training loss: 0.3118172100473731
Validation loss: 2.62717616990875

Epoch: 6| Step: 9
Training loss: 0.6234552366558865
Validation loss: 2.637900630601115

Epoch: 6| Step: 10
Training loss: 0.6040051397805967
Validation loss: 2.7021616577075034

Epoch: 6| Step: 11
Training loss: 0.5834508902306025
Validation loss: 2.744035299322944

Epoch: 6| Step: 12
Training loss: 0.4486511791357447
Validation loss: 2.66795008789208

Epoch: 6| Step: 13
Training loss: 0.4503947910404001
Validation loss: 2.555045434295243

Epoch: 226| Step: 0
Training loss: 0.764501447909514
Validation loss: 2.628495402019045

Epoch: 6| Step: 1
Training loss: 0.8863742848292413
Validation loss: 2.6383354222869153

Epoch: 6| Step: 2
Training loss: 0.3593339274611778
Validation loss: 2.6920462605420656

Epoch: 6| Step: 3
Training loss: 0.4554174083477983
Validation loss: 2.600493462513576

Epoch: 6| Step: 4
Training loss: 0.6540323206559099
Validation loss: 2.648758080208974

Epoch: 6| Step: 5
Training loss: 1.0429001117651737
Validation loss: 2.593535004556488

Epoch: 6| Step: 6
Training loss: 0.553099009878472
Validation loss: 2.611131956026278

Epoch: 6| Step: 7
Training loss: 0.43318218596807717
Validation loss: 2.5653857520341474

Epoch: 6| Step: 8
Training loss: 0.5439993867414888
Validation loss: 2.5952897308349083

Epoch: 6| Step: 9
Training loss: 0.6419050639762636
Validation loss: 2.5903356975753584

Epoch: 6| Step: 10
Training loss: 0.6577029719198141
Validation loss: 2.622316813233322

Epoch: 6| Step: 11
Training loss: 0.6983530236687365
Validation loss: 2.587607406377284

Epoch: 6| Step: 12
Training loss: 0.4268121051951292
Validation loss: 2.657171500935939

Epoch: 6| Step: 13
Training loss: 0.49788588371515397
Validation loss: 2.594717534702433

Epoch: 227| Step: 0
Training loss: 0.6361711874078246
Validation loss: 2.5994841375642905

Epoch: 6| Step: 1
Training loss: 0.6662586249890039
Validation loss: 2.650661716076464

Epoch: 6| Step: 2
Training loss: 0.5450473490541466
Validation loss: 2.6567965076200357

Epoch: 6| Step: 3
Training loss: 0.3739850694384163
Validation loss: 2.6929332459679314

Epoch: 6| Step: 4
Training loss: 0.49506141604302567
Validation loss: 2.6187617715162825

Epoch: 6| Step: 5
Training loss: 0.5514285024777729
Validation loss: 2.5680045265898617

Epoch: 6| Step: 6
Training loss: 0.4927542617338727
Validation loss: 2.6633122227595605

Epoch: 6| Step: 7
Training loss: 1.2042519381909238
Validation loss: 2.5886659317328293

Epoch: 6| Step: 8
Training loss: 0.49917241987416633
Validation loss: 2.6130605470436135

Epoch: 6| Step: 9
Training loss: 0.4380484277089812
Validation loss: 2.6448084180275626

Epoch: 6| Step: 10
Training loss: 0.6023794299689265
Validation loss: 2.6056842171538825

Epoch: 6| Step: 11
Training loss: 0.4630835891464586
Validation loss: 2.675350954676313

Epoch: 6| Step: 12
Training loss: 0.46646783316739304
Validation loss: 2.6021027333432545

Epoch: 6| Step: 13
Training loss: 0.5259432244173475
Validation loss: 2.5966556620170818

Epoch: 228| Step: 0
Training loss: 0.6668027103215669
Validation loss: 2.606727734392688

Epoch: 6| Step: 1
Training loss: 0.21346488983546388
Validation loss: 2.6563722021378884

Epoch: 6| Step: 2
Training loss: 0.537974766706757
Validation loss: 2.640807903508822

Epoch: 6| Step: 3
Training loss: 0.7079211372726786
Validation loss: 2.6501916498183307

Epoch: 6| Step: 4
Training loss: 0.5110931357762265
Validation loss: 2.668756207735106

Epoch: 6| Step: 5
Training loss: 0.4564681863990888
Validation loss: 2.566667021920646

Epoch: 6| Step: 6
Training loss: 0.6579687001036492
Validation loss: 2.591754467408098

Epoch: 6| Step: 7
Training loss: 0.5238699194430364
Validation loss: 2.5965929039585194

Epoch: 6| Step: 8
Training loss: 0.47321392294517656
Validation loss: 2.6689868806983683

Epoch: 6| Step: 9
Training loss: 1.182863822438353
Validation loss: 2.608258387267875

Epoch: 6| Step: 10
Training loss: 0.7003524369883233
Validation loss: 2.6885271105741135

Epoch: 6| Step: 11
Training loss: 0.5795703553648854
Validation loss: 2.618790700106085

Epoch: 6| Step: 12
Training loss: 0.5017610471865463
Validation loss: 2.6368848056072913

Epoch: 6| Step: 13
Training loss: 0.7702973710561117
Validation loss: 2.6326213657868522

Epoch: 229| Step: 0
Training loss: 0.6400860170585327
Validation loss: 2.6276223995205004

Epoch: 6| Step: 1
Training loss: 0.6555197603839374
Validation loss: 2.6041388446593223

Epoch: 6| Step: 2
Training loss: 0.5723099414734506
Validation loss: 2.5695956079734095

Epoch: 6| Step: 3
Training loss: 0.4556204221048079
Validation loss: 2.63166468622843

Epoch: 6| Step: 4
Training loss: 0.4242560340416275
Validation loss: 2.59009314132687

Epoch: 6| Step: 5
Training loss: 0.6366617844262924
Validation loss: 2.651903673086362

Epoch: 6| Step: 6
Training loss: 0.4750265477943209
Validation loss: 2.600935760244466

Epoch: 6| Step: 7
Training loss: 0.45260919612757594
Validation loss: 2.6254149366343924

Epoch: 6| Step: 8
Training loss: 0.6710228728234826
Validation loss: 2.650058501575515

Epoch: 6| Step: 9
Training loss: 0.3669403136958807
Validation loss: 2.6656596597055735

Epoch: 6| Step: 10
Training loss: 0.6449337944902477
Validation loss: 2.6322864644631077

Epoch: 6| Step: 11
Training loss: 1.0652828797228304
Validation loss: 2.5732132487204993

Epoch: 6| Step: 12
Training loss: 0.46649343611810506
Validation loss: 2.599227460688572

Epoch: 6| Step: 13
Training loss: 0.5832995223282915
Validation loss: 2.614568586168583

Epoch: 230| Step: 0
Training loss: 0.7482889047813824
Validation loss: 2.6201885496609267

Epoch: 6| Step: 1
Training loss: 1.0507803424136415
Validation loss: 2.5503192072270924

Epoch: 6| Step: 2
Training loss: 0.5739674439950447
Validation loss: 2.5726721077237302

Epoch: 6| Step: 3
Training loss: 0.3675778120406437
Validation loss: 2.673018406046451

Epoch: 6| Step: 4
Training loss: 0.616034408408752
Validation loss: 2.5965802174951276

Epoch: 6| Step: 5
Training loss: 0.5040668556890767
Validation loss: 2.6918180803006115

Epoch: 6| Step: 6
Training loss: 0.36866180205685384
Validation loss: 2.6217294482090105

Epoch: 6| Step: 7
Training loss: 0.4925103869286851
Validation loss: 2.67382585122769

Epoch: 6| Step: 8
Training loss: 0.64407485061642
Validation loss: 2.575723743577771

Epoch: 6| Step: 9
Training loss: 0.5884507004872331
Validation loss: 2.615083583276445

Epoch: 6| Step: 10
Training loss: 0.46421489332632804
Validation loss: 2.6591328852496288

Epoch: 6| Step: 11
Training loss: 0.771184471846
Validation loss: 2.662382802637469

Epoch: 6| Step: 12
Training loss: 0.5964060404064838
Validation loss: 2.611269843459952

Epoch: 6| Step: 13
Training loss: 0.4897916702255364
Validation loss: 2.6242228977465487

Epoch: 231| Step: 0
Training loss: 0.7632395503543616
Validation loss: 2.6391375563951027

Epoch: 6| Step: 1
Training loss: 0.5792600469528772
Validation loss: 2.6084606068508833

Epoch: 6| Step: 2
Training loss: 0.4864715456614843
Validation loss: 2.7122247664690446

Epoch: 6| Step: 3
Training loss: 0.6355751157932696
Validation loss: 2.634291628615308

Epoch: 6| Step: 4
Training loss: 0.5982034708684425
Validation loss: 2.6847679386455487

Epoch: 6| Step: 5
Training loss: 0.5855451669089131
Validation loss: 2.6656564174766877

Epoch: 6| Step: 6
Training loss: 0.6823434349008667
Validation loss: 2.6705441497389164

Epoch: 6| Step: 7
Training loss: 0.5082488312864962
Validation loss: 2.633929535416865

Epoch: 6| Step: 8
Training loss: 0.6155361827934088
Validation loss: 2.5723675336180256

Epoch: 6| Step: 9
Training loss: 0.6516148955503694
Validation loss: 2.6300178131496246

Epoch: 6| Step: 10
Training loss: 1.0765700252806993
Validation loss: 2.6902131276745376

Epoch: 6| Step: 11
Training loss: 0.5785677992574033
Validation loss: 2.647707933371895

Epoch: 6| Step: 12
Training loss: 0.8216364031925609
Validation loss: 2.6646702540230893

Epoch: 6| Step: 13
Training loss: 0.3742654281524598
Validation loss: 2.587927030871087

Epoch: 232| Step: 0
Training loss: 0.6139548423295905
Validation loss: 2.6016385484487845

Epoch: 6| Step: 1
Training loss: 0.5288278113031887
Validation loss: 2.6629472264403735

Epoch: 6| Step: 2
Training loss: 0.7814179049307107
Validation loss: 2.646783137613341

Epoch: 6| Step: 3
Training loss: 0.23548135304785256
Validation loss: 2.5799622741917854

Epoch: 6| Step: 4
Training loss: 0.5128936965048542
Validation loss: 2.7011273155849174

Epoch: 6| Step: 5
Training loss: 0.8052297450315844
Validation loss: 2.656659577151627

Epoch: 6| Step: 6
Training loss: 0.5191611212020419
Validation loss: 2.6834332206647233

Epoch: 6| Step: 7
Training loss: 1.01528596354355
Validation loss: 2.644888616595137

Epoch: 6| Step: 8
Training loss: 0.4520033074084949
Validation loss: 2.6026253805822104

Epoch: 6| Step: 9
Training loss: 0.5793278269817023
Validation loss: 2.6092090515849518

Epoch: 6| Step: 10
Training loss: 0.6344233602496976
Validation loss: 2.58012893322556

Epoch: 6| Step: 11
Training loss: 0.44059885502076435
Validation loss: 2.6094523740097535

Epoch: 6| Step: 12
Training loss: 0.4206875939012762
Validation loss: 2.6033357795169816

Epoch: 6| Step: 13
Training loss: 0.648121883381162
Validation loss: 2.613763617381729

Epoch: 233| Step: 0
Training loss: 0.2646172705734639
Validation loss: 2.610517286069899

Epoch: 6| Step: 1
Training loss: 0.535049762015882
Validation loss: 2.629678409686879

Epoch: 6| Step: 2
Training loss: 0.5155561285551264
Validation loss: 2.6372229124722395

Epoch: 6| Step: 3
Training loss: 0.4857942646058682
Validation loss: 2.6062254638492695

Epoch: 6| Step: 4
Training loss: 0.547255628822624
Validation loss: 2.631867417410873

Epoch: 6| Step: 5
Training loss: 0.30347535296997113
Validation loss: 2.5956233356536935

Epoch: 6| Step: 6
Training loss: 0.7926014392445059
Validation loss: 2.671956319482383

Epoch: 6| Step: 7
Training loss: 0.7366092863505829
Validation loss: 2.612002513675931

Epoch: 6| Step: 8
Training loss: 0.4710597037037133
Validation loss: 2.6267665640799867

Epoch: 6| Step: 9
Training loss: 0.3471574526882809
Validation loss: 2.662496007399931

Epoch: 6| Step: 10
Training loss: 0.6440538198671857
Validation loss: 2.615749818291631

Epoch: 6| Step: 11
Training loss: 0.5876737936130116
Validation loss: 2.648644078242954

Epoch: 6| Step: 12
Training loss: 1.0669557601852595
Validation loss: 2.6303964730131213

Epoch: 6| Step: 13
Training loss: 0.5873452124713167
Validation loss: 2.6584101850189215

Epoch: 234| Step: 0
Training loss: 0.48178221886730344
Validation loss: 2.6543686056842257

Epoch: 6| Step: 1
Training loss: 0.6542687708953708
Validation loss: 2.5694821764492417

Epoch: 6| Step: 2
Training loss: 0.4407776601943373
Validation loss: 2.587004549933523

Epoch: 6| Step: 3
Training loss: 1.1779767193558195
Validation loss: 2.6970142097244967

Epoch: 6| Step: 4
Training loss: 0.32758195535943646
Validation loss: 2.6815796558314564

Epoch: 6| Step: 5
Training loss: 0.5980228471569801
Validation loss: 2.665294955036294

Epoch: 6| Step: 6
Training loss: 0.6749020849842033
Validation loss: 2.6428782162752826

Epoch: 6| Step: 7
Training loss: 0.41978832161503815
Validation loss: 2.6205877923390033

Epoch: 6| Step: 8
Training loss: 0.5242398503657628
Validation loss: 2.5801265922805015

Epoch: 6| Step: 9
Training loss: 0.6364403800700644
Validation loss: 2.5437788915594597

Epoch: 6| Step: 10
Training loss: 0.7732249266453255
Validation loss: 2.637708448998511

Epoch: 6| Step: 11
Training loss: 0.5375929718783623
Validation loss: 2.589361576478591

Epoch: 6| Step: 12
Training loss: 0.5460830403643495
Validation loss: 2.6265293691869

Epoch: 6| Step: 13
Training loss: 0.44808298911607086
Validation loss: 2.5704574466792485

Epoch: 235| Step: 0
Training loss: 0.8429439721341615
Validation loss: 2.5906525619997858

Epoch: 6| Step: 1
Training loss: 0.26218392893708775
Validation loss: 2.696698482036542

Epoch: 6| Step: 2
Training loss: 0.7036727890698211
Validation loss: 2.604806994233633

Epoch: 6| Step: 3
Training loss: 0.43389504077184676
Validation loss: 2.5689928711905736

Epoch: 6| Step: 4
Training loss: 0.6186003870173199
Validation loss: 2.689212844668085

Epoch: 6| Step: 5
Training loss: 0.3689694285147034
Validation loss: 2.71341846110704

Epoch: 6| Step: 6
Training loss: 0.49412991960712416
Validation loss: 2.693931712418602

Epoch: 6| Step: 7
Training loss: 0.5324110918639338
Validation loss: 2.6773926869129405

Epoch: 6| Step: 8
Training loss: 0.4776731587550228
Validation loss: 2.6628381818811704

Epoch: 6| Step: 9
Training loss: 0.44716178321600714
Validation loss: 2.649038511066151

Epoch: 6| Step: 10
Training loss: 1.1437703490401312
Validation loss: 2.68122281503123

Epoch: 6| Step: 11
Training loss: 0.4148150029971217
Validation loss: 2.6434753954724646

Epoch: 6| Step: 12
Training loss: 0.49712543893842187
Validation loss: 2.6215676468153593

Epoch: 6| Step: 13
Training loss: 0.7338141064689225
Validation loss: 2.601702429566148

Epoch: 236| Step: 0
Training loss: 0.36443418676433487
Validation loss: 2.662604834652245

Epoch: 6| Step: 1
Training loss: 0.5652568862745273
Validation loss: 2.687111138887931

Epoch: 6| Step: 2
Training loss: 0.8628154205527058
Validation loss: 2.6727109497384194

Epoch: 6| Step: 3
Training loss: 0.5132051966046539
Validation loss: 2.684111166301988

Epoch: 6| Step: 4
Training loss: 0.4202563351114522
Validation loss: 2.5367520271313975

Epoch: 6| Step: 5
Training loss: 0.5168242812728921
Validation loss: 2.690642995622794

Epoch: 6| Step: 6
Training loss: 0.7888566305687138
Validation loss: 2.67664924892239

Epoch: 6| Step: 7
Training loss: 0.5294876599373298
Validation loss: 2.725926803328232

Epoch: 6| Step: 8
Training loss: 0.4147759534821982
Validation loss: 2.6433633303613857

Epoch: 6| Step: 9
Training loss: 0.4995196836848941
Validation loss: 2.6432036650731923

Epoch: 6| Step: 10
Training loss: 0.7099576632543566
Validation loss: 2.711311116705878

Epoch: 6| Step: 11
Training loss: 0.5949166030299536
Validation loss: 2.6372623137633995

Epoch: 6| Step: 12
Training loss: 1.1670857028921238
Validation loss: 2.6579620453813493

Epoch: 6| Step: 13
Training loss: 0.5186604250129456
Validation loss: 2.5865950809565406

Epoch: 237| Step: 0
Training loss: 1.1305388159349647
Validation loss: 2.6201135173501284

Epoch: 6| Step: 1
Training loss: 0.6045463426825283
Validation loss: 2.588394918190154

Epoch: 6| Step: 2
Training loss: 0.5653906826869487
Validation loss: 2.670414322722949

Epoch: 6| Step: 3
Training loss: 0.7330648626197888
Validation loss: 2.727327620189871

Epoch: 6| Step: 4
Training loss: 0.8550800851491852
Validation loss: 2.5776301824264385

Epoch: 6| Step: 5
Training loss: 0.6122131522598747
Validation loss: 2.5972886057193834

Epoch: 6| Step: 6
Training loss: 0.5113143487739968
Validation loss: 2.5789094983650247

Epoch: 6| Step: 7
Training loss: 0.5871317328119204
Validation loss: 2.6088466908952026

Epoch: 6| Step: 8
Training loss: 0.7948271673897496
Validation loss: 2.601336372942039

Epoch: 6| Step: 9
Training loss: 0.5977474467192283
Validation loss: 2.635871626794574

Epoch: 6| Step: 10
Training loss: 0.9374489770356227
Validation loss: 2.597114303769782

Epoch: 6| Step: 11
Training loss: 0.4417748051939822
Validation loss: 2.595206743995082

Epoch: 6| Step: 12
Training loss: 0.6344454618136096
Validation loss: 2.604124714831359

Epoch: 6| Step: 13
Training loss: 0.5461050062424752
Validation loss: 2.625077670325799

Epoch: 238| Step: 0
Training loss: 1.022500985571799
Validation loss: 2.6670752500405506

Epoch: 6| Step: 1
Training loss: 0.630168240955925
Validation loss: 2.624872598129814

Epoch: 6| Step: 2
Training loss: 0.4549246926394843
Validation loss: 2.6043488146340783

Epoch: 6| Step: 3
Training loss: 0.4728915992120514
Validation loss: 2.6618038831568938

Epoch: 6| Step: 4
Training loss: 0.4018502588502174
Validation loss: 2.641888829545445

Epoch: 6| Step: 5
Training loss: 0.7093614988680701
Validation loss: 2.6172744356965882

Epoch: 6| Step: 6
Training loss: 0.6048702604514519
Validation loss: 2.6255928762689904

Epoch: 6| Step: 7
Training loss: 0.6244612756180735
Validation loss: 2.5891989110856852

Epoch: 6| Step: 8
Training loss: 0.4895044188782192
Validation loss: 2.648639802511178

Epoch: 6| Step: 9
Training loss: 0.5223387102847611
Validation loss: 2.62127424169175

Epoch: 6| Step: 10
Training loss: 0.5821905238205606
Validation loss: 2.6370461945840074

Epoch: 6| Step: 11
Training loss: 0.7095659881132421
Validation loss: 2.588166504556071

Epoch: 6| Step: 12
Training loss: 0.5573039603140024
Validation loss: 2.630715641663401

Epoch: 6| Step: 13
Training loss: 0.6155652080100237
Validation loss: 2.6580164402591313

Epoch: 239| Step: 0
Training loss: 0.5548931331675048
Validation loss: 2.639655979384227

Epoch: 6| Step: 1
Training loss: 0.460595650714866
Validation loss: 2.6205646646051215

Epoch: 6| Step: 2
Training loss: 0.9850035583121999
Validation loss: 2.572499760095445

Epoch: 6| Step: 3
Training loss: 0.606284201532292
Validation loss: 2.6568780194031087

Epoch: 6| Step: 4
Training loss: 0.6298200235934812
Validation loss: 2.638573235042942

Epoch: 6| Step: 5
Training loss: 0.5630748778126065
Validation loss: 2.6194775938505486

Epoch: 6| Step: 6
Training loss: 0.4165182524845535
Validation loss: 2.625814568821687

Epoch: 6| Step: 7
Training loss: 0.6340977603213455
Validation loss: 2.635600620127165

Epoch: 6| Step: 8
Training loss: 0.6398411118449505
Validation loss: 2.6740842463875283

Epoch: 6| Step: 9
Training loss: 0.5756657850829006
Validation loss: 2.572776533215447

Epoch: 6| Step: 10
Training loss: 0.5734740637989901
Validation loss: 2.6202521605151374

Epoch: 6| Step: 11
Training loss: 0.48375419087529087
Validation loss: 2.637996712386382

Epoch: 6| Step: 12
Training loss: 0.8306199403584319
Validation loss: 2.6507854425284902

Epoch: 6| Step: 13
Training loss: 0.6008245226848508
Validation loss: 2.5197114628652146

Epoch: 240| Step: 0
Training loss: 1.2303462860685108
Validation loss: 2.610671933645495

Epoch: 6| Step: 1
Training loss: 0.5840862784895371
Validation loss: 2.6694732490023725

Epoch: 6| Step: 2
Training loss: 0.3819499321263974
Validation loss: 2.6141494958435447

Epoch: 6| Step: 3
Training loss: 0.48465031828630284
Validation loss: 2.6277772501765075

Epoch: 6| Step: 4
Training loss: 0.49127600297709484
Validation loss: 2.6718357522026404

Epoch: 6| Step: 5
Training loss: 0.5452477905879324
Validation loss: 2.6356910793894075

Epoch: 6| Step: 6
Training loss: 0.643044531471154
Validation loss: 2.5872415287578137

Epoch: 6| Step: 7
Training loss: 0.558583586273561
Validation loss: 2.6274878126733467

Epoch: 6| Step: 8
Training loss: 0.4614671476683378
Validation loss: 2.5441479895670764

Epoch: 6| Step: 9
Training loss: 0.6091054417996651
Validation loss: 2.597698805993441

Epoch: 6| Step: 10
Training loss: 0.5902230514763069
Validation loss: 2.648896229193834

Epoch: 6| Step: 11
Training loss: 0.44610044136974714
Validation loss: 2.677287770541238

Epoch: 6| Step: 12
Training loss: 0.4386061580956235
Validation loss: 2.564390911462324

Epoch: 6| Step: 13
Training loss: 0.31952022636070554
Validation loss: 2.6148116226129776

Epoch: 241| Step: 0
Training loss: 0.5420979439596323
Validation loss: 2.617390153165464

Epoch: 6| Step: 1
Training loss: 0.38065205335390195
Validation loss: 2.5828619239726103

Epoch: 6| Step: 2
Training loss: 0.5429105109946352
Validation loss: 2.5926179828485383

Epoch: 6| Step: 3
Training loss: 0.4822438177866401
Validation loss: 2.6220003730827974

Epoch: 6| Step: 4
Training loss: 0.6443618551813494
Validation loss: 2.577629334553064

Epoch: 6| Step: 5
Training loss: 0.5680664198903133
Validation loss: 2.62988427812904

Epoch: 6| Step: 6
Training loss: 0.6842639362670723
Validation loss: 2.6416188162512237

Epoch: 6| Step: 7
Training loss: 0.6190048694696384
Validation loss: 2.6012619654490092

Epoch: 6| Step: 8
Training loss: 1.1025416033760302
Validation loss: 2.644329730140536

Epoch: 6| Step: 9
Training loss: 0.5729973187175816
Validation loss: 2.646071631045644

Epoch: 6| Step: 10
Training loss: 0.6220010572176102
Validation loss: 2.704030791064078

Epoch: 6| Step: 11
Training loss: 0.39530152015364795
Validation loss: 2.644813676531932

Epoch: 6| Step: 12
Training loss: 0.7022390081700404
Validation loss: 2.6577484392253594

Epoch: 6| Step: 13
Training loss: 0.6349891386454879
Validation loss: 2.539089762223433

Epoch: 242| Step: 0
Training loss: 0.6048264819365338
Validation loss: 2.6691800779715744

Epoch: 6| Step: 1
Training loss: 0.6272420484830219
Validation loss: 2.6364919456611147

Epoch: 6| Step: 2
Training loss: 0.6534884340565943
Validation loss: 2.6765954628195314

Epoch: 6| Step: 3
Training loss: 0.8768924275825951
Validation loss: 2.6647637899423557

Epoch: 6| Step: 4
Training loss: 0.33411757283745236
Validation loss: 2.6232373359481373

Epoch: 6| Step: 5
Training loss: 0.45774339147784004
Validation loss: 2.572802534673697

Epoch: 6| Step: 6
Training loss: 0.5054465122431245
Validation loss: 2.639915084966357

Epoch: 6| Step: 7
Training loss: 0.35673534142520064
Validation loss: 2.6030477536003063

Epoch: 6| Step: 8
Training loss: 1.0722246005856013
Validation loss: 2.673286087680136

Epoch: 6| Step: 9
Training loss: 0.6324516727621114
Validation loss: 2.639224687481951

Epoch: 6| Step: 10
Training loss: 0.5187094649598416
Validation loss: 2.686207490066626

Epoch: 6| Step: 11
Training loss: 0.4867399379471964
Validation loss: 2.6526572819806056

Epoch: 6| Step: 12
Training loss: 0.62097137973089
Validation loss: 2.6521693431235285

Epoch: 6| Step: 13
Training loss: 0.43277828756135606
Validation loss: 2.6618546988901444

Epoch: 243| Step: 0
Training loss: 0.6108102036564413
Validation loss: 2.5746438462204

Epoch: 6| Step: 1
Training loss: 0.42962056418896166
Validation loss: 2.685049151912538

Epoch: 6| Step: 2
Training loss: 0.6975203831404995
Validation loss: 2.6144091610185565

Epoch: 6| Step: 3
Training loss: 0.6685174172143249
Validation loss: 2.6418516180554317

Epoch: 6| Step: 4
Training loss: 0.6008616737140218
Validation loss: 2.615064604540432

Epoch: 6| Step: 5
Training loss: 1.0316810285116031
Validation loss: 2.638591502537631

Epoch: 6| Step: 6
Training loss: 0.5603209249498139
Validation loss: 2.621184588628658

Epoch: 6| Step: 7
Training loss: 0.5411103093441387
Validation loss: 2.6297896451674605

Epoch: 6| Step: 8
Training loss: 0.5616875184864463
Validation loss: 2.6429124363646816

Epoch: 6| Step: 9
Training loss: 0.7293819972391531
Validation loss: 2.6569340591728436

Epoch: 6| Step: 10
Training loss: 0.4838185652113792
Validation loss: 2.6024683080887896

Epoch: 6| Step: 11
Training loss: 0.2934810736482236
Validation loss: 2.670227211917741

Epoch: 6| Step: 12
Training loss: 0.3884173187451446
Validation loss: 2.6336633380910217

Epoch: 6| Step: 13
Training loss: 0.45277147643002186
Validation loss: 2.584735125997389

Epoch: 244| Step: 0
Training loss: 0.4129487659874235
Validation loss: 2.6793187131398195

Epoch: 6| Step: 1
Training loss: 0.5376046411543848
Validation loss: 2.60550036547008

Epoch: 6| Step: 2
Training loss: 0.4544647569169464
Validation loss: 2.609614637263155

Epoch: 6| Step: 3
Training loss: 0.4022546317650024
Validation loss: 2.6679438621957554

Epoch: 6| Step: 4
Training loss: 0.9249661233214421
Validation loss: 2.66380899515255

Epoch: 6| Step: 5
Training loss: 0.6138473619202249
Validation loss: 2.6356561926350626

Epoch: 6| Step: 6
Training loss: 0.622992845064044
Validation loss: 2.6594767251078895

Epoch: 6| Step: 7
Training loss: 0.3747369519164069
Validation loss: 2.6337982505720112

Epoch: 6| Step: 8
Training loss: 0.491878745708236
Validation loss: 2.6114317959711593

Epoch: 6| Step: 9
Training loss: 0.5278684478251955
Validation loss: 2.6857190552048813

Epoch: 6| Step: 10
Training loss: 0.5945714488330958
Validation loss: 2.6157385767649872

Epoch: 6| Step: 11
Training loss: 0.5992380290803173
Validation loss: 2.6319965943398516

Epoch: 6| Step: 12
Training loss: 0.6286218367334114
Validation loss: 2.621771992360034

Epoch: 6| Step: 13
Training loss: 0.27690494102062735
Validation loss: 2.564242336638985

Epoch: 245| Step: 0
Training loss: 0.6917129310585473
Validation loss: 2.6041787922894786

Epoch: 6| Step: 1
Training loss: 0.7742056836855048
Validation loss: 2.6413949449626903

Epoch: 6| Step: 2
Training loss: 0.3825432161152226
Validation loss: 2.6566677587770955

Epoch: 6| Step: 3
Training loss: 0.3321661731121673
Validation loss: 2.632956752730524

Epoch: 6| Step: 4
Training loss: 0.3915891574026827
Validation loss: 2.7251565800748576

Epoch: 6| Step: 5
Training loss: 0.43562962725246485
Validation loss: 2.6159231899351445

Epoch: 6| Step: 6
Training loss: 0.3795943746450932
Validation loss: 2.626731180602564

Epoch: 6| Step: 7
Training loss: 0.49110916630539425
Validation loss: 2.591848358049259

Epoch: 6| Step: 8
Training loss: 0.5520243583225259
Validation loss: 2.6079951919246107

Epoch: 6| Step: 9
Training loss: 0.2884575209276712
Validation loss: 2.6338829483009576

Epoch: 6| Step: 10
Training loss: 0.421877366518518
Validation loss: 2.607929468931545

Epoch: 6| Step: 11
Training loss: 0.9701656334832247
Validation loss: 2.6315778937254017

Epoch: 6| Step: 12
Training loss: 0.6267256992728019
Validation loss: 2.6514051721520366

Epoch: 6| Step: 13
Training loss: 0.47075201706598496
Validation loss: 2.6653573328518085

Epoch: 246| Step: 0
Training loss: 0.5154559696459793
Validation loss: 2.576285706059327

Epoch: 6| Step: 1
Training loss: 0.34172254571607535
Validation loss: 2.560949476740452

Epoch: 6| Step: 2
Training loss: 0.9041319134328047
Validation loss: 2.6141430204143052

Epoch: 6| Step: 3
Training loss: 0.5855799537766734
Validation loss: 2.6668516978999635

Epoch: 6| Step: 4
Training loss: 0.4637450047247083
Validation loss: 2.6763964240546514

Epoch: 6| Step: 5
Training loss: 0.5970501787449117
Validation loss: 2.6844638115517228

Epoch: 6| Step: 6
Training loss: 0.4763278070604872
Validation loss: 2.607748503115923

Epoch: 6| Step: 7
Training loss: 0.6825946591306631
Validation loss: 2.6718877751154673

Epoch: 6| Step: 8
Training loss: 0.8045883858388904
Validation loss: 2.7364991284599105

Epoch: 6| Step: 9
Training loss: 0.44310304399016
Validation loss: 2.60347530088607

Epoch: 6| Step: 10
Training loss: 0.4702663373629
Validation loss: 2.6492755355456254

Epoch: 6| Step: 11
Training loss: 0.387312846980325
Validation loss: 2.6463947651649495

Epoch: 6| Step: 12
Training loss: 0.430058735090756
Validation loss: 2.6899243294993287

Epoch: 6| Step: 13
Training loss: 0.8424863890049319
Validation loss: 2.7225675563878413

Epoch: 247| Step: 0
Training loss: 0.512021099196001
Validation loss: 2.6720002500092317

Epoch: 6| Step: 1
Training loss: 0.38896220113175983
Validation loss: 2.656156224110127

Epoch: 6| Step: 2
Training loss: 0.45343496967348423
Validation loss: 2.6664934747800753

Epoch: 6| Step: 3
Training loss: 0.4245976963209368
Validation loss: 2.594315402134356

Epoch: 6| Step: 4
Training loss: 0.4153350313330782
Validation loss: 2.5827300741463213

Epoch: 6| Step: 5
Training loss: 0.5607380291855351
Validation loss: 2.662576643268985

Epoch: 6| Step: 6
Training loss: 0.4374689704245374
Validation loss: 2.6462651198286604

Epoch: 6| Step: 7
Training loss: 0.6872422862364154
Validation loss: 2.6839023729127445

Epoch: 6| Step: 8
Training loss: 0.6862279654962481
Validation loss: 2.6331347561660103

Epoch: 6| Step: 9
Training loss: 0.5283551442621208
Validation loss: 2.604213932879973

Epoch: 6| Step: 10
Training loss: 0.929722665073606
Validation loss: 2.6385854033469553

Epoch: 6| Step: 11
Training loss: 0.5851538440364579
Validation loss: 2.724585223347258

Epoch: 6| Step: 12
Training loss: 0.5856398271375242
Validation loss: 2.591581165542889

Epoch: 6| Step: 13
Training loss: 0.3856182044000815
Validation loss: 2.671080413514314

Epoch: 248| Step: 0
Training loss: 0.5136730063538367
Validation loss: 2.686626173981095

Epoch: 6| Step: 1
Training loss: 0.4987002705517653
Validation loss: 2.6872999870924033

Epoch: 6| Step: 2
Training loss: 0.4145918108043029
Validation loss: 2.6632116456176047

Epoch: 6| Step: 3
Training loss: 0.5085332597191058
Validation loss: 2.6439008388670944

Epoch: 6| Step: 4
Training loss: 0.9209964251039856
Validation loss: 2.6259587822715664

Epoch: 6| Step: 5
Training loss: 0.6772161915839793
Validation loss: 2.6540079864864734

Epoch: 6| Step: 6
Training loss: 0.46402148441199426
Validation loss: 2.615816430941301

Epoch: 6| Step: 7
Training loss: 0.5293311920865388
Validation loss: 2.587488099468587

Epoch: 6| Step: 8
Training loss: 0.3045948694712836
Validation loss: 2.6522484051998085

Epoch: 6| Step: 9
Training loss: 0.3002061423716563
Validation loss: 2.592015448607611

Epoch: 6| Step: 10
Training loss: 0.6369335771675128
Validation loss: 2.614619408063518

Epoch: 6| Step: 11
Training loss: 0.5463962366606352
Validation loss: 2.646257536716267

Epoch: 6| Step: 12
Training loss: 0.7556058078849612
Validation loss: 2.7063378000442975

Epoch: 6| Step: 13
Training loss: 0.48424051325125966
Validation loss: 2.648321998800802

Epoch: 249| Step: 0
Training loss: 0.6354010116232893
Validation loss: 2.7089232071376976

Epoch: 6| Step: 1
Training loss: 0.5168661727059248
Validation loss: 2.680444475177253

Epoch: 6| Step: 2
Training loss: 0.5445635311239974
Validation loss: 2.6851305533718506

Epoch: 6| Step: 3
Training loss: 0.46330323319923855
Validation loss: 2.6580346339274965

Epoch: 6| Step: 4
Training loss: 0.5392632041697537
Validation loss: 2.6775900562812174

Epoch: 6| Step: 5
Training loss: 1.038528362458061
Validation loss: 2.606113024374131

Epoch: 6| Step: 6
Training loss: 0.4806642367266944
Validation loss: 2.668946354690536

Epoch: 6| Step: 7
Training loss: 0.4792926007789853
Validation loss: 2.694359637648535

Epoch: 6| Step: 8
Training loss: 0.3919561973057503
Validation loss: 2.6436842402944003

Epoch: 6| Step: 9
Training loss: 0.6866190641609484
Validation loss: 2.654827529899287

Epoch: 6| Step: 10
Training loss: 0.3459456288279469
Validation loss: 2.601496469387142

Epoch: 6| Step: 11
Training loss: 0.5640132734633987
Validation loss: 2.6931011619288965

Epoch: 6| Step: 12
Training loss: 0.6557889408644938
Validation loss: 2.687270309923699

Epoch: 6| Step: 13
Training loss: 0.4737046806631267
Validation loss: 2.642034707369159

Epoch: 250| Step: 0
Training loss: 0.5049583039208068
Validation loss: 2.6254596232129024

Epoch: 6| Step: 1
Training loss: 0.5822158623102109
Validation loss: 2.6702484474364523

Epoch: 6| Step: 2
Training loss: 0.37145344217317605
Validation loss: 2.6955297410187846

Epoch: 6| Step: 3
Training loss: 0.5166179459683506
Validation loss: 2.6559373260173627

Epoch: 6| Step: 4
Training loss: 0.5420395839003196
Validation loss: 2.666832074360081

Epoch: 6| Step: 5
Training loss: 0.3932116317207802
Validation loss: 2.644570076609056

Epoch: 6| Step: 6
Training loss: 0.37839971682924034
Validation loss: 2.687265711190102

Epoch: 6| Step: 7
Training loss: 0.5025874186148263
Validation loss: 2.5957864250937184

Epoch: 6| Step: 8
Training loss: 0.5194383122200618
Validation loss: 2.5714604791107245

Epoch: 6| Step: 9
Training loss: 0.5695254499561329
Validation loss: 2.588250929983699

Epoch: 6| Step: 10
Training loss: 0.43322659317992507
Validation loss: 2.6925888674494196

Epoch: 6| Step: 11
Training loss: 0.4400156955466304
Validation loss: 2.695838220897491

Epoch: 6| Step: 12
Training loss: 0.5575745360836337
Validation loss: 2.628781047860807

Epoch: 6| Step: 13
Training loss: 1.0296939901746511
Validation loss: 2.6133615341740954

Epoch: 251| Step: 0
Training loss: 0.7114067624913646
Validation loss: 2.680637884330663

Epoch: 6| Step: 1
Training loss: 0.7213590371602108
Validation loss: 2.651142003546979

Epoch: 6| Step: 2
Training loss: 0.5727808589073377
Validation loss: 2.5875399753842703

Epoch: 6| Step: 3
Training loss: 0.39968376101250414
Validation loss: 2.693915155102255

Epoch: 6| Step: 4
Training loss: 0.5649424085550475
Validation loss: 2.61303163865453

Epoch: 6| Step: 5
Training loss: 0.32290520058035616
Validation loss: 2.6294292895122164

Epoch: 6| Step: 6
Training loss: 0.9546730727184153
Validation loss: 2.6544702738528976

Epoch: 6| Step: 7
Training loss: 0.5181511064585521
Validation loss: 2.6258317901096713

Epoch: 6| Step: 8
Training loss: 0.36609312069651967
Validation loss: 2.5462211986667573

Epoch: 6| Step: 9
Training loss: 0.5493222113408541
Validation loss: 2.5902194617976426

Epoch: 6| Step: 10
Training loss: 0.3757719399613445
Validation loss: 2.6611125270991938

Epoch: 6| Step: 11
Training loss: 0.4926477883650022
Validation loss: 2.590956213576834

Epoch: 6| Step: 12
Training loss: 0.5166338962755328
Validation loss: 2.708099888252953

Epoch: 6| Step: 13
Training loss: 0.3650262004776383
Validation loss: 2.672597597800553

Epoch: 252| Step: 0
Training loss: 0.6133351150474723
Validation loss: 2.642989490084488

Epoch: 6| Step: 1
Training loss: 0.5574472038005254
Validation loss: 2.6821223727135743

Epoch: 6| Step: 2
Training loss: 0.5268324457181416
Validation loss: 2.7248785289323494

Epoch: 6| Step: 3
Training loss: 0.4514220728862385
Validation loss: 2.6314209865126243

Epoch: 6| Step: 4
Training loss: 0.4859819214072131
Validation loss: 2.7117783912365123

Epoch: 6| Step: 5
Training loss: 0.6314260577196193
Validation loss: 2.6418317937735964

Epoch: 6| Step: 6
Training loss: 0.5488701529378982
Validation loss: 2.6903463268808347

Epoch: 6| Step: 7
Training loss: 0.5177978624981212
Validation loss: 2.658905452242376

Epoch: 6| Step: 8
Training loss: 0.3680680248359522
Validation loss: 2.6468274859502796

Epoch: 6| Step: 9
Training loss: 0.8583936463310189
Validation loss: 2.567600005510402

Epoch: 6| Step: 10
Training loss: 0.45051173015357343
Validation loss: 2.7109608498043185

Epoch: 6| Step: 11
Training loss: 0.6349314077005995
Validation loss: 2.5723530902440794

Epoch: 6| Step: 12
Training loss: 0.5616071821044243
Validation loss: 2.683173208217544

Epoch: 6| Step: 13
Training loss: 0.7073886031484093
Validation loss: 2.6280459639692273

Epoch: 253| Step: 0
Training loss: 0.38536329372393185
Validation loss: 2.592587283169391

Epoch: 6| Step: 1
Training loss: 0.5347108867263953
Validation loss: 2.653439055457966

Epoch: 6| Step: 2
Training loss: 0.7581231178706896
Validation loss: 2.573184711120828

Epoch: 6| Step: 3
Training loss: 0.6892553375364011
Validation loss: 2.6085760298198766

Epoch: 6| Step: 4
Training loss: 0.6487544560509089
Validation loss: 2.548386014398397

Epoch: 6| Step: 5
Training loss: 0.4227550299495815
Validation loss: 2.680279635743489

Epoch: 6| Step: 6
Training loss: 0.88750637884937
Validation loss: 2.6854438086874994

Epoch: 6| Step: 7
Training loss: 0.6119408994573831
Validation loss: 2.702533399932488

Epoch: 6| Step: 8
Training loss: 0.6018095871425713
Validation loss: 2.6099204523136703

Epoch: 6| Step: 9
Training loss: 0.6187199026552044
Validation loss: 2.673687519011036

Epoch: 6| Step: 10
Training loss: 0.8443759786062266
Validation loss: 2.5963659308551863

Epoch: 6| Step: 11
Training loss: 0.633746458717098
Validation loss: 2.5800700701333468

Epoch: 6| Step: 12
Training loss: 0.28970925688700394
Validation loss: 2.6319134362864873

Epoch: 6| Step: 13
Training loss: 0.5149161639538569
Validation loss: 2.675054075461022

Epoch: 254| Step: 0
Training loss: 0.7841892265604242
Validation loss: 2.6405577641642037

Epoch: 6| Step: 1
Training loss: 0.4802415822476407
Validation loss: 2.749602144534137

Epoch: 6| Step: 2
Training loss: 0.3440389719028987
Validation loss: 2.6433547693235644

Epoch: 6| Step: 3
Training loss: 0.8637707733438639
Validation loss: 2.689374639528962

Epoch: 6| Step: 4
Training loss: 0.7181874437133777
Validation loss: 2.613131942247112

Epoch: 6| Step: 5
Training loss: 0.4650497621140888
Validation loss: 2.617137320118098

Epoch: 6| Step: 6
Training loss: 0.46212699127800083
Validation loss: 2.562430597931661

Epoch: 6| Step: 7
Training loss: 0.5810170137389569
Validation loss: 2.60306424012395

Epoch: 6| Step: 8
Training loss: 0.43158353885467243
Validation loss: 2.6593710272132136

Epoch: 6| Step: 9
Training loss: 0.36885126065166374
Validation loss: 2.602226088685051

Epoch: 6| Step: 10
Training loss: 0.3014145784824258
Validation loss: 2.727547352021693

Epoch: 6| Step: 11
Training loss: 0.7070759079460295
Validation loss: 2.571244724894472

Epoch: 6| Step: 12
Training loss: 0.4894731241997752
Validation loss: 2.6803488698369193

Epoch: 6| Step: 13
Training loss: 0.48392477954028434
Validation loss: 2.6064463568130676

Epoch: 255| Step: 0
Training loss: 0.4171999161547835
Validation loss: 2.578579702642058

Epoch: 6| Step: 1
Training loss: 0.3829811269751499
Validation loss: 2.644534991443416

Epoch: 6| Step: 2
Training loss: 0.8971496639956702
Validation loss: 2.60724891346104

Epoch: 6| Step: 3
Training loss: 0.3158230056600683
Validation loss: 2.6247600264077526

Epoch: 6| Step: 4
Training loss: 0.391636112049399
Validation loss: 2.604786140513122

Epoch: 6| Step: 5
Training loss: 0.4814799453009175
Validation loss: 2.6667900777115223

Epoch: 6| Step: 6
Training loss: 0.7723796044512001
Validation loss: 2.626313524248089

Epoch: 6| Step: 7
Training loss: 0.4839549088764047
Validation loss: 2.6137754299021956

Epoch: 6| Step: 8
Training loss: 0.5498574809175409
Validation loss: 2.615551003245358

Epoch: 6| Step: 9
Training loss: 0.34665579915015227
Validation loss: 2.6479193256483877

Epoch: 6| Step: 10
Training loss: 0.5902920465677044
Validation loss: 2.6760020515318086

Epoch: 6| Step: 11
Training loss: 0.6322122953476772
Validation loss: 2.6236243957870697

Epoch: 6| Step: 12
Training loss: 0.6335932307117748
Validation loss: 2.6613556356205894

Epoch: 6| Step: 13
Training loss: 0.4375210654773057
Validation loss: 2.6159326838008994

Epoch: 256| Step: 0
Training loss: 0.43928151488650635
Validation loss: 2.574872085949647

Epoch: 6| Step: 1
Training loss: 0.5124953106921519
Validation loss: 2.6630723740974043

Epoch: 6| Step: 2
Training loss: 0.594259445076853
Validation loss: 2.7188829265268075

Epoch: 6| Step: 3
Training loss: 0.5542365107824114
Validation loss: 2.6060605041992484

Epoch: 6| Step: 4
Training loss: 0.5244396920929494
Validation loss: 2.632605705855986

Epoch: 6| Step: 5
Training loss: 0.5763264335616811
Validation loss: 2.61224638211315

Epoch: 6| Step: 6
Training loss: 0.37043261612037476
Validation loss: 2.6481582059227096

Epoch: 6| Step: 7
Training loss: 0.41789462421562507
Validation loss: 2.592431265552233

Epoch: 6| Step: 8
Training loss: 0.33820489369663725
Validation loss: 2.6779371723200933

Epoch: 6| Step: 9
Training loss: 0.6843286324387734
Validation loss: 2.6107860260236997

Epoch: 6| Step: 10
Training loss: 0.48842127508842165
Validation loss: 2.650023039231824

Epoch: 6| Step: 11
Training loss: 0.51558413488115
Validation loss: 2.6137618994689005

Epoch: 6| Step: 12
Training loss: 0.8807820965010152
Validation loss: 2.7042696813192975

Epoch: 6| Step: 13
Training loss: 0.4917401293921249
Validation loss: 2.6404396157583965

Epoch: 257| Step: 0
Training loss: 0.5734935774655557
Validation loss: 2.661655371452288

Epoch: 6| Step: 1
Training loss: 0.5764403154291385
Validation loss: 2.6740409445004367

Epoch: 6| Step: 2
Training loss: 0.6725037316569774
Validation loss: 2.6846481983574852

Epoch: 6| Step: 3
Training loss: 0.6799675813829068
Validation loss: 2.6706054378012976

Epoch: 6| Step: 4
Training loss: 0.5175269047566396
Validation loss: 2.620600950150598

Epoch: 6| Step: 5
Training loss: 0.31933337102669457
Validation loss: 2.6666801770185913

Epoch: 6| Step: 6
Training loss: 0.5532785708931646
Validation loss: 2.659965459747545

Epoch: 6| Step: 7
Training loss: 0.7866241246643967
Validation loss: 2.691801856890744

Epoch: 6| Step: 8
Training loss: 0.4960052531448718
Validation loss: 2.6658693899959953

Epoch: 6| Step: 9
Training loss: 0.3062747789595898
Validation loss: 2.6646217363307763

Epoch: 6| Step: 10
Training loss: 0.491671397568954
Validation loss: 2.6289868883270535

Epoch: 6| Step: 11
Training loss: 0.5311008692839685
Validation loss: 2.6382777298276983

Epoch: 6| Step: 12
Training loss: 0.3939601806497794
Validation loss: 2.6412726065250003

Epoch: 6| Step: 13
Training loss: 0.5457216908185009
Validation loss: 2.6720313310899204

Epoch: 258| Step: 0
Training loss: 0.4529877158724657
Validation loss: 2.6016597481423207

Epoch: 6| Step: 1
Training loss: 0.5538222858617818
Validation loss: 2.6457972836979673

Epoch: 6| Step: 2
Training loss: 0.27669228348044894
Validation loss: 2.6243094035392933

Epoch: 6| Step: 3
Training loss: 0.3060617754029664
Validation loss: 2.6704439044939607

Epoch: 6| Step: 4
Training loss: 0.478841149291024
Validation loss: 2.6358326946679482

Epoch: 6| Step: 5
Training loss: 0.47954705074029036
Validation loss: 2.6329645250690357

Epoch: 6| Step: 6
Training loss: 1.1878353448490993
Validation loss: 2.6681563319349357

Epoch: 6| Step: 7
Training loss: 0.4847006779643347
Validation loss: 2.752541963902407

Epoch: 6| Step: 8
Training loss: 0.3710012420995952
Validation loss: 2.699539290670084

Epoch: 6| Step: 9
Training loss: 0.6781482587069002
Validation loss: 2.6335636203203796

Epoch: 6| Step: 10
Training loss: 0.5423867104280031
Validation loss: 2.6453717397300722

Epoch: 6| Step: 11
Training loss: 0.3265604799381546
Validation loss: 2.6755038523690535

Epoch: 6| Step: 12
Training loss: 0.30276699505693
Validation loss: 2.6104213573497894

Epoch: 6| Step: 13
Training loss: 0.28740573042424106
Validation loss: 2.659843079090062

Epoch: 259| Step: 0
Training loss: 0.4405879647673092
Validation loss: 2.5848639373584383

Epoch: 6| Step: 1
Training loss: 0.3300653037566316
Validation loss: 2.6223339741497034

Epoch: 6| Step: 2
Training loss: 0.35542837898809254
Validation loss: 2.5834131125980266

Epoch: 6| Step: 3
Training loss: 0.6546908886077514
Validation loss: 2.617611432258525

Epoch: 6| Step: 4
Training loss: 0.35390899438193957
Validation loss: 2.6785014561187563

Epoch: 6| Step: 5
Training loss: 0.3936725563002541
Validation loss: 2.5496926820607824

Epoch: 6| Step: 6
Training loss: 0.3825601797197112
Validation loss: 2.6355045188363775

Epoch: 6| Step: 7
Training loss: 0.5317342738761558
Validation loss: 2.5773009861835248

Epoch: 6| Step: 8
Training loss: 0.4263871807280933
Validation loss: 2.664700115787333

Epoch: 6| Step: 9
Training loss: 0.8986226430117294
Validation loss: 2.679631194625105

Epoch: 6| Step: 10
Training loss: 0.5112378430495036
Validation loss: 2.5892656159521343

Epoch: 6| Step: 11
Training loss: 0.5654027533828142
Validation loss: 2.58696200234085

Epoch: 6| Step: 12
Training loss: 0.4498672779710453
Validation loss: 2.7305163523499805

Epoch: 6| Step: 13
Training loss: 0.46181941927828196
Validation loss: 2.651790825314571

Epoch: 260| Step: 0
Training loss: 0.5135454377609152
Validation loss: 2.7016366819364688

Epoch: 6| Step: 1
Training loss: 0.43422965081016224
Validation loss: 2.656763887249865

Epoch: 6| Step: 2
Training loss: 0.2599314110408041
Validation loss: 2.5771348381189596

Epoch: 6| Step: 3
Training loss: 0.36162221127017274
Validation loss: 2.639572069063266

Epoch: 6| Step: 4
Training loss: 0.28682848106478964
Validation loss: 2.609045559917258

Epoch: 6| Step: 5
Training loss: 0.3421184879543168
Validation loss: 2.5941586919315385

Epoch: 6| Step: 6
Training loss: 0.5622843752945736
Validation loss: 2.6806852968691652

Epoch: 6| Step: 7
Training loss: 0.5072553659515304
Validation loss: 2.653100671196093

Epoch: 6| Step: 8
Training loss: 0.49733936694985564
Validation loss: 2.576327998106395

Epoch: 6| Step: 9
Training loss: 0.8830163433402853
Validation loss: 2.6239711168035083

Epoch: 6| Step: 10
Training loss: 0.6256754563113385
Validation loss: 2.6889074765194327

Epoch: 6| Step: 11
Training loss: 0.33145857398365874
Validation loss: 2.679898882981914

Epoch: 6| Step: 12
Training loss: 0.44644476180009673
Validation loss: 2.648232691224723

Epoch: 6| Step: 13
Training loss: 0.6567295229870228
Validation loss: 2.7005490062768227

Epoch: 261| Step: 0
Training loss: 0.4448534456569164
Validation loss: 2.6493934099044156

Epoch: 6| Step: 1
Training loss: 0.41716644791195895
Validation loss: 2.662325922330214

Epoch: 6| Step: 2
Training loss: 0.315448288029572
Validation loss: 2.6667657078788505

Epoch: 6| Step: 3
Training loss: 0.4365223963509588
Validation loss: 2.6244842083102733

Epoch: 6| Step: 4
Training loss: 0.3691900512868059
Validation loss: 2.617493857297882

Epoch: 6| Step: 5
Training loss: 0.6583279001840698
Validation loss: 2.583778302007383

Epoch: 6| Step: 6
Training loss: 0.367735149965428
Validation loss: 2.6169740884037673

Epoch: 6| Step: 7
Training loss: 0.4857157026248188
Validation loss: 2.6627140678469567

Epoch: 6| Step: 8
Training loss: 0.5480564706605358
Validation loss: 2.633260758572861

Epoch: 6| Step: 9
Training loss: 0.885889951583795
Validation loss: 2.6058127401611952

Epoch: 6| Step: 10
Training loss: 0.6297648001427519
Validation loss: 2.6101641194615905

Epoch: 6| Step: 11
Training loss: 0.43489727621543445
Validation loss: 2.588322717833586

Epoch: 6| Step: 12
Training loss: 0.4892798930837198
Validation loss: 2.6887079673471694

Epoch: 6| Step: 13
Training loss: 0.5517766358532131
Validation loss: 2.5648646492967893

Epoch: 262| Step: 0
Training loss: 0.519128743904735
Validation loss: 2.643584870456309

Epoch: 6| Step: 1
Training loss: 0.5199356226318009
Validation loss: 2.5657962130167626

Epoch: 6| Step: 2
Training loss: 0.4312316026771627
Validation loss: 2.6352789670732597

Epoch: 6| Step: 3
Training loss: 0.624974083363114
Validation loss: 2.5981601312431026

Epoch: 6| Step: 4
Training loss: 0.5046987290210869
Validation loss: 2.681638239308199

Epoch: 6| Step: 5
Training loss: 0.4607958171788749
Validation loss: 2.616892464932292

Epoch: 6| Step: 6
Training loss: 0.5226120204486201
Validation loss: 2.709200299712406

Epoch: 6| Step: 7
Training loss: 0.5022873711873694
Validation loss: 2.6825231260906794

Epoch: 6| Step: 8
Training loss: 0.5348171357005984
Validation loss: 2.654866026319652

Epoch: 6| Step: 9
Training loss: 0.3005941973586818
Validation loss: 2.6201177486381635

Epoch: 6| Step: 10
Training loss: 0.4041484431290953
Validation loss: 2.6182533636898055

Epoch: 6| Step: 11
Training loss: 0.4355314790887005
Validation loss: 2.587856575603931

Epoch: 6| Step: 12
Training loss: 0.7784801209005855
Validation loss: 2.5828210774006375

Epoch: 6| Step: 13
Training loss: 0.886636335265239
Validation loss: 2.586255948069244

Epoch: 263| Step: 0
Training loss: 0.5514336367924365
Validation loss: 2.6867713014240917

Epoch: 6| Step: 1
Training loss: 0.5977174814808804
Validation loss: 2.6235914689928532

Epoch: 6| Step: 2
Training loss: 0.6057962331820351
Validation loss: 2.663538906517185

Epoch: 6| Step: 3
Training loss: 0.369977597608765
Validation loss: 2.688179802488593

Epoch: 6| Step: 4
Training loss: 0.27748720730257
Validation loss: 2.645045806545812

Epoch: 6| Step: 5
Training loss: 0.3904695773869633
Validation loss: 2.646902924457539

Epoch: 6| Step: 6
Training loss: 0.5546660620616558
Validation loss: 2.6567784251259345

Epoch: 6| Step: 7
Training loss: 0.505301385024766
Validation loss: 2.6227195007133335

Epoch: 6| Step: 8
Training loss: 0.6249939918229281
Validation loss: 2.6119768644090104

Epoch: 6| Step: 9
Training loss: 0.7988902023556941
Validation loss: 2.599460634809955

Epoch: 6| Step: 10
Training loss: 0.4788190696981634
Validation loss: 2.5950112550965474

Epoch: 6| Step: 11
Training loss: 0.4789001476900961
Validation loss: 2.619859779235918

Epoch: 6| Step: 12
Training loss: 0.681953249181954
Validation loss: 2.657742159729525

Epoch: 6| Step: 13
Training loss: 0.6645740558211882
Validation loss: 2.693586082221136

Epoch: 264| Step: 0
Training loss: 0.5563642920185925
Validation loss: 2.6522928044815584

Epoch: 6| Step: 1
Training loss: 0.40328037165797764
Validation loss: 2.6311733829703097

Epoch: 6| Step: 2
Training loss: 0.6692487710564565
Validation loss: 2.6030253745039214

Epoch: 6| Step: 3
Training loss: 0.4798753066324028
Validation loss: 2.6650594596599433

Epoch: 6| Step: 4
Training loss: 0.8278857191343097
Validation loss: 2.677368421007704

Epoch: 6| Step: 5
Training loss: 0.6069303038332244
Validation loss: 2.7265916620569555

Epoch: 6| Step: 6
Training loss: 0.4165665108787398
Validation loss: 2.627029028343091

Epoch: 6| Step: 7
Training loss: 0.3804329269745986
Validation loss: 2.6985217168345375

Epoch: 6| Step: 8
Training loss: 0.6729049772146811
Validation loss: 2.659723202733146

Epoch: 6| Step: 9
Training loss: 0.5366161787035345
Validation loss: 2.617691856865743

Epoch: 6| Step: 10
Training loss: 0.5335978350057105
Validation loss: 2.6460938713374795

Epoch: 6| Step: 11
Training loss: 0.6771387566599822
Validation loss: 2.715747739463937

Epoch: 6| Step: 12
Training loss: 0.5439529281439217
Validation loss: 2.6853624093251938

Epoch: 6| Step: 13
Training loss: 0.43588360142186455
Validation loss: 2.6329292927993797

Epoch: 265| Step: 0
Training loss: 0.3310874652671126
Validation loss: 2.6805797162940905

Epoch: 6| Step: 1
Training loss: 0.5473254120085467
Validation loss: 2.6411816914949644

Epoch: 6| Step: 2
Training loss: 0.4581273132463577
Validation loss: 2.6492172488695154

Epoch: 6| Step: 3
Training loss: 0.43763509435705905
Validation loss: 2.6652258069849593

Epoch: 6| Step: 4
Training loss: 0.5210151418619895
Validation loss: 2.6241350565468555

Epoch: 6| Step: 5
Training loss: 0.3069789866259336
Validation loss: 2.666498317967615

Epoch: 6| Step: 6
Training loss: 0.4966064717177584
Validation loss: 2.6960967392648336

Epoch: 6| Step: 7
Training loss: 0.5097178001916496
Validation loss: 2.71298323808032

Epoch: 6| Step: 8
Training loss: 0.5509763872483714
Validation loss: 2.5880231024464186

Epoch: 6| Step: 9
Training loss: 0.29439945560766506
Validation loss: 2.6224208149987525

Epoch: 6| Step: 10
Training loss: 0.7675739317335366
Validation loss: 2.6410192311963865

Epoch: 6| Step: 11
Training loss: 0.4394496154645018
Validation loss: 2.6488100988204764

Epoch: 6| Step: 12
Training loss: 0.39106077682361773
Validation loss: 2.630405189524974

Epoch: 6| Step: 13
Training loss: 0.762584644059575
Validation loss: 2.6051922774910055

Epoch: 266| Step: 0
Training loss: 0.459716440323232
Validation loss: 2.608705369987678

Epoch: 6| Step: 1
Training loss: 0.4117481764062222
Validation loss: 2.688862743416962

Epoch: 6| Step: 2
Training loss: 0.6405307188670678
Validation loss: 2.6153840261256587

Epoch: 6| Step: 3
Training loss: 0.5076322969402061
Validation loss: 2.6665527398886653

Epoch: 6| Step: 4
Training loss: 0.47436920808314564
Validation loss: 2.6460679518436265

Epoch: 6| Step: 5
Training loss: 0.3658773301431256
Validation loss: 2.5916828206122084

Epoch: 6| Step: 6
Training loss: 0.4466798269440934
Validation loss: 2.6959680985417838

Epoch: 6| Step: 7
Training loss: 0.4641662436739617
Validation loss: 2.5671271129958013

Epoch: 6| Step: 8
Training loss: 0.5361049624020726
Validation loss: 2.6562883561300854

Epoch: 6| Step: 9
Training loss: 0.549978306732648
Validation loss: 2.552990784496585

Epoch: 6| Step: 10
Training loss: 0.48016161522442036
Validation loss: 2.6579409583772167

Epoch: 6| Step: 11
Training loss: 0.32378683850866924
Validation loss: 2.6057051018114468

Epoch: 6| Step: 12
Training loss: 0.8279037899890364
Validation loss: 2.6425122320733556

Epoch: 6| Step: 13
Training loss: 0.45313868008713765
Validation loss: 2.4589459307924835

Epoch: 267| Step: 0
Training loss: 0.7535443796353856
Validation loss: 2.618875185236007

Epoch: 6| Step: 1
Training loss: 0.4868462188989154
Validation loss: 2.6571409189932065

Epoch: 6| Step: 2
Training loss: 0.5090550113827349
Validation loss: 2.6557137490305225

Epoch: 6| Step: 3
Training loss: 0.45692238774574306
Validation loss: 2.5918475684866897

Epoch: 6| Step: 4
Training loss: 0.6166541535379514
Validation loss: 2.5850051858802

Epoch: 6| Step: 5
Training loss: 0.3938353037392725
Validation loss: 2.565280878528354

Epoch: 6| Step: 6
Training loss: 0.5107371401127121
Validation loss: 2.630995949133946

Epoch: 6| Step: 7
Training loss: 0.3868802436633483
Validation loss: 2.6445454494258516

Epoch: 6| Step: 8
Training loss: 0.6616754150613013
Validation loss: 2.623058941118178

Epoch: 6| Step: 9
Training loss: 0.2643918133973786
Validation loss: 2.5879836731503305

Epoch: 6| Step: 10
Training loss: 0.7043613584157052
Validation loss: 2.600727424587894

Epoch: 6| Step: 11
Training loss: 0.3968966177812358
Validation loss: 2.661995870176685

Epoch: 6| Step: 12
Training loss: 0.7059203002847277
Validation loss: 2.648166338787226

Epoch: 6| Step: 13
Training loss: 0.3290313057092849
Validation loss: 2.607035076964285

Epoch: 268| Step: 0
Training loss: 0.34202303352437535
Validation loss: 2.656849512997828

Epoch: 6| Step: 1
Training loss: 0.49671410648735015
Validation loss: 2.5821410524660586

Epoch: 6| Step: 2
Training loss: 0.37306129467642124
Validation loss: 2.654742437658266

Epoch: 6| Step: 3
Training loss: 0.4049561694940717
Validation loss: 2.5921643554071214

Epoch: 6| Step: 4
Training loss: 0.6134958559905156
Validation loss: 2.62342735138612

Epoch: 6| Step: 5
Training loss: 0.5892830514228403
Validation loss: 2.639992670195933

Epoch: 6| Step: 6
Training loss: 0.5008862806325102
Validation loss: 2.691751827943827

Epoch: 6| Step: 7
Training loss: 0.7588385881244382
Validation loss: 2.633897099526279

Epoch: 6| Step: 8
Training loss: 0.5541277196530431
Validation loss: 2.6648542583090262

Epoch: 6| Step: 9
Training loss: 0.4707881328384752
Validation loss: 2.6878693792531583

Epoch: 6| Step: 10
Training loss: 0.3418177353079096
Validation loss: 2.7511249033247185

Epoch: 6| Step: 11
Training loss: 0.5613805439789316
Validation loss: 2.6284961578968016

Epoch: 6| Step: 12
Training loss: 0.46263195810184826
Validation loss: 2.603358812276667

Epoch: 6| Step: 13
Training loss: 0.5065449079392224
Validation loss: 2.6193406542831617

Epoch: 269| Step: 0
Training loss: 0.21402455118818695
Validation loss: 2.7318039496020354

Epoch: 6| Step: 1
Training loss: 0.39168956652446607
Validation loss: 2.616752527634365

Epoch: 6| Step: 2
Training loss: 0.36272284958370443
Validation loss: 2.6132413654866573

Epoch: 6| Step: 3
Training loss: 0.42286290953038225
Validation loss: 2.624025300127851

Epoch: 6| Step: 4
Training loss: 0.4279553439215701
Validation loss: 2.6470178120475807

Epoch: 6| Step: 5
Training loss: 0.5063053359883487
Validation loss: 2.6798447765761853

Epoch: 6| Step: 6
Training loss: 0.4021533960200676
Validation loss: 2.652346753814899

Epoch: 6| Step: 7
Training loss: 0.4637345294993908
Validation loss: 2.6754238363313596

Epoch: 6| Step: 8
Training loss: 0.6899130262624487
Validation loss: 2.5776106118962896

Epoch: 6| Step: 9
Training loss: 0.581218023343506
Validation loss: 2.6203521270576196

Epoch: 6| Step: 10
Training loss: 0.7276604672719916
Validation loss: 2.7314489057960736

Epoch: 6| Step: 11
Training loss: 0.5712683258205645
Validation loss: 2.67139851446609

Epoch: 6| Step: 12
Training loss: 0.49887121458058326
Validation loss: 2.69473954897336

Epoch: 6| Step: 13
Training loss: 0.4443134176395313
Validation loss: 2.6774222657892945

Epoch: 270| Step: 0
Training loss: 0.38173221437908356
Validation loss: 2.651616172269796

Epoch: 6| Step: 1
Training loss: 0.44458403315871886
Validation loss: 2.6535347093868964

Epoch: 6| Step: 2
Training loss: 0.486234387782098
Validation loss: 2.6296537261504582

Epoch: 6| Step: 3
Training loss: 0.3004818454136283
Validation loss: 2.6315817215344377

Epoch: 6| Step: 4
Training loss: 0.6748902726173696
Validation loss: 2.621589496270589

Epoch: 6| Step: 5
Training loss: 0.7500608340069165
Validation loss: 2.6862054560609905

Epoch: 6| Step: 6
Training loss: 0.7791313435372612
Validation loss: 2.6782138579741916

Epoch: 6| Step: 7
Training loss: 0.6571425317606505
Validation loss: 2.662998885814029

Epoch: 6| Step: 8
Training loss: 0.3682082172497361
Validation loss: 2.629236949660359

Epoch: 6| Step: 9
Training loss: 0.35242236205642186
Validation loss: 2.6650655877235527

Epoch: 6| Step: 10
Training loss: 0.49727737221098556
Validation loss: 2.6414225951919517

Epoch: 6| Step: 11
Training loss: 0.30413788350102156
Validation loss: 2.6342356049510385

Epoch: 6| Step: 12
Training loss: 0.390579755070137
Validation loss: 2.6474076841095253

Epoch: 6| Step: 13
Training loss: 0.5554419745793738
Validation loss: 2.6188925583668543

Epoch: 271| Step: 0
Training loss: 0.5076785571174663
Validation loss: 2.652357443173493

Epoch: 6| Step: 1
Training loss: 0.41690048174209193
Validation loss: 2.6924086846109496

Epoch: 6| Step: 2
Training loss: 0.7360645095501062
Validation loss: 2.6375422945895095

Epoch: 6| Step: 3
Training loss: 0.4472619435521167
Validation loss: 2.6038846944105027

Epoch: 6| Step: 4
Training loss: 0.38466276933768895
Validation loss: 2.6400463516086936

Epoch: 6| Step: 5
Training loss: 0.5061545964992585
Validation loss: 2.6318586151523746

Epoch: 6| Step: 6
Training loss: 0.49710773859229823
Validation loss: 2.6646724237655484

Epoch: 6| Step: 7
Training loss: 0.35690428565229343
Validation loss: 2.6316210411913064

Epoch: 6| Step: 8
Training loss: 0.29137940679463736
Validation loss: 2.5854094735495576

Epoch: 6| Step: 9
Training loss: 0.4178699126988013
Validation loss: 2.5863104145116034

Epoch: 6| Step: 10
Training loss: 0.5304969330662153
Validation loss: 2.623063962970215

Epoch: 6| Step: 11
Training loss: 0.6897166021556527
Validation loss: 2.6559642563256984

Epoch: 6| Step: 12
Training loss: 0.5214994049763783
Validation loss: 2.647973649206942

Epoch: 6| Step: 13
Training loss: 0.4249818629714394
Validation loss: 2.6076435275882437

Epoch: 272| Step: 0
Training loss: 0.4057943282812543
Validation loss: 2.6147594443252578

Epoch: 6| Step: 1
Training loss: 0.5453094963275197
Validation loss: 2.564673997984402

Epoch: 6| Step: 2
Training loss: 0.5607467188796549
Validation loss: 2.595019401399365

Epoch: 6| Step: 3
Training loss: 0.6361851943236885
Validation loss: 2.6054999689446112

Epoch: 6| Step: 4
Training loss: 0.5196369608552528
Validation loss: 2.6217015296556463

Epoch: 6| Step: 5
Training loss: 0.5290652398152844
Validation loss: 2.6497938945681017

Epoch: 6| Step: 6
Training loss: 0.5619045390680146
Validation loss: 2.662948658949513

Epoch: 6| Step: 7
Training loss: 0.3281595575209368
Validation loss: 2.6018676120672413

Epoch: 6| Step: 8
Training loss: 0.38465581575958463
Validation loss: 2.614627341296496

Epoch: 6| Step: 9
Training loss: 0.36654261509911856
Validation loss: 2.553853053265047

Epoch: 6| Step: 10
Training loss: 0.8701568491723547
Validation loss: 2.6442118780088175

Epoch: 6| Step: 11
Training loss: 0.35163287412097116
Validation loss: 2.645804357495176

Epoch: 6| Step: 12
Training loss: 0.4047674306340707
Validation loss: 2.6730967474137057

Epoch: 6| Step: 13
Training loss: 0.5637225006061641
Validation loss: 2.5756088771499033

Epoch: 273| Step: 0
Training loss: 0.5822990620597847
Validation loss: 2.602129735957952

Epoch: 6| Step: 1
Training loss: 0.7039842653385577
Validation loss: 2.6259252643220696

Epoch: 6| Step: 2
Training loss: 0.43569081754711453
Validation loss: 2.67019566339312

Epoch: 6| Step: 3
Training loss: 0.3445777031339747
Validation loss: 2.696070629880365

Epoch: 6| Step: 4
Training loss: 0.2990238321751457
Validation loss: 2.720873883710964

Epoch: 6| Step: 5
Training loss: 0.32937474896821334
Validation loss: 2.6634443951328435

Epoch: 6| Step: 6
Training loss: 0.4675695177909753
Validation loss: 2.6344805526252117

Epoch: 6| Step: 7
Training loss: 0.7737874482048605
Validation loss: 2.6112920910316113

Epoch: 6| Step: 8
Training loss: 0.4426100864973648
Validation loss: 2.627706328498908

Epoch: 6| Step: 9
Training loss: 0.2713776248205768
Validation loss: 2.598234107582215

Epoch: 6| Step: 10
Training loss: 0.4966732155231568
Validation loss: 2.6713434475119486

Epoch: 6| Step: 11
Training loss: 0.509164360585378
Validation loss: 2.6013949152187648

Epoch: 6| Step: 12
Training loss: 0.4816345400089402
Validation loss: 2.620705376328093

Epoch: 6| Step: 13
Training loss: 0.4908273158273957
Validation loss: 2.642471254926839

Epoch: 274| Step: 0
Training loss: 0.6160102432780284
Validation loss: 2.7089108120428667

Epoch: 6| Step: 1
Training loss: 0.40349931416222806
Validation loss: 2.6049673197496945

Epoch: 6| Step: 2
Training loss: 0.42241422312913945
Validation loss: 2.64539337004546

Epoch: 6| Step: 3
Training loss: 0.5060127349860509
Validation loss: 2.7079693892062204

Epoch: 6| Step: 4
Training loss: 0.48758470826364514
Validation loss: 2.5767157199659754

Epoch: 6| Step: 5
Training loss: 0.38146349604286867
Validation loss: 2.6457736141243555

Epoch: 6| Step: 6
Training loss: 0.41505367477723976
Validation loss: 2.643651382975765

Epoch: 6| Step: 7
Training loss: 0.7386156566091537
Validation loss: 2.6558282405140927

Epoch: 6| Step: 8
Training loss: 0.41241808713780237
Validation loss: 2.6560427715771877

Epoch: 6| Step: 9
Training loss: 0.44545751853868115
Validation loss: 2.6238069093592458

Epoch: 6| Step: 10
Training loss: 0.5846294552867973
Validation loss: 2.5946191610673783

Epoch: 6| Step: 11
Training loss: 0.3745701233285221
Validation loss: 2.637122794382598

Epoch: 6| Step: 12
Training loss: 0.42664789665492303
Validation loss: 2.713056383042218

Epoch: 6| Step: 13
Training loss: 0.5711242438027678
Validation loss: 2.634190969197167

Epoch: 275| Step: 0
Training loss: 0.32916719817871126
Validation loss: 2.6277954717483523

Epoch: 6| Step: 1
Training loss: 0.4758227031169502
Validation loss: 2.604435187165289

Epoch: 6| Step: 2
Training loss: 0.2757171967121201
Validation loss: 2.637731497971974

Epoch: 6| Step: 3
Training loss: 0.37993611645780007
Validation loss: 2.675979465837293

Epoch: 6| Step: 4
Training loss: 0.4558398539229618
Validation loss: 2.667550519162751

Epoch: 6| Step: 5
Training loss: 0.5950056151117108
Validation loss: 2.6609337147185332

Epoch: 6| Step: 6
Training loss: 0.6420963649636169
Validation loss: 2.6384378739363923

Epoch: 6| Step: 7
Training loss: 0.582726287601565
Validation loss: 2.6747782737130614

Epoch: 6| Step: 8
Training loss: 0.614105860802656
Validation loss: 2.6807272685323227

Epoch: 6| Step: 9
Training loss: 0.45551076469514806
Validation loss: 2.5936481808206815

Epoch: 6| Step: 10
Training loss: 0.5347441039899498
Validation loss: 2.6227010620640203

Epoch: 6| Step: 11
Training loss: 0.4036781441667027
Validation loss: 2.6550479487790724

Epoch: 6| Step: 12
Training loss: 0.741341801727363
Validation loss: 2.667124035971697

Epoch: 6| Step: 13
Training loss: 0.41279709188740854
Validation loss: 2.596483528998298

Epoch: 276| Step: 0
Training loss: 0.7699389854012408
Validation loss: 2.609193075999363

Epoch: 6| Step: 1
Training loss: 0.3473489775030479
Validation loss: 2.6102572870171374

Epoch: 6| Step: 2
Training loss: 0.5515989902085985
Validation loss: 2.619728077495314

Epoch: 6| Step: 3
Training loss: 0.409777875486228
Validation loss: 2.7097994919533392

Epoch: 6| Step: 4
Training loss: 0.5132105971762329
Validation loss: 2.6974959370674125

Epoch: 6| Step: 5
Training loss: 0.4845517820346173
Validation loss: 2.593507119569015

Epoch: 6| Step: 6
Training loss: 0.48012603384143504
Validation loss: 2.6581347790970296

Epoch: 6| Step: 7
Training loss: 0.39947330250056207
Validation loss: 2.624418860397009

Epoch: 6| Step: 8
Training loss: 0.528474711140628
Validation loss: 2.62635792319996

Epoch: 6| Step: 9
Training loss: 0.43028642355170277
Validation loss: 2.6636426637726727

Epoch: 6| Step: 10
Training loss: 0.5200072094527566
Validation loss: 2.6510490587252598

Epoch: 6| Step: 11
Training loss: 0.26588994725047893
Validation loss: 2.6155300072998005

Epoch: 6| Step: 12
Training loss: 0.4442364256378349
Validation loss: 2.681825442982715

Epoch: 6| Step: 13
Training loss: 0.5360134804920019
Validation loss: 2.5958055983562405

Epoch: 277| Step: 0
Training loss: 0.3312018525922085
Validation loss: 2.589753162301456

Epoch: 6| Step: 1
Training loss: 0.21657267137891878
Validation loss: 2.7265484945234477

Epoch: 6| Step: 2
Training loss: 0.4455737635836494
Validation loss: 2.653527746046994

Epoch: 6| Step: 3
Training loss: 0.4848175949285332
Validation loss: 2.585644032094238

Epoch: 6| Step: 4
Training loss: 0.2512850665061309
Validation loss: 2.6001471257764615

Epoch: 6| Step: 5
Training loss: 0.3905252710827797
Validation loss: 2.6154761493460525

Epoch: 6| Step: 6
Training loss: 0.8000176487406442
Validation loss: 2.631255114649304

Epoch: 6| Step: 7
Training loss: 0.4620680602719625
Validation loss: 2.6432198560328373

Epoch: 6| Step: 8
Training loss: 0.35871671425854634
Validation loss: 2.605545431721569

Epoch: 6| Step: 9
Training loss: 0.5899205947233627
Validation loss: 2.6140569382429955

Epoch: 6| Step: 10
Training loss: 0.5916762779914798
Validation loss: 2.694239615709282

Epoch: 6| Step: 11
Training loss: 0.3110996221450858
Validation loss: 2.6878640127950457

Epoch: 6| Step: 12
Training loss: 0.3902235829614702
Validation loss: 2.534747337118179

Epoch: 6| Step: 13
Training loss: 0.5632333743083625
Validation loss: 2.703397909805029

Epoch: 278| Step: 0
Training loss: 0.8107402157282809
Validation loss: 2.642249147736314

Epoch: 6| Step: 1
Training loss: 0.2188501214054957
Validation loss: 2.6691737955954737

Epoch: 6| Step: 2
Training loss: 0.4890400445676169
Validation loss: 2.6182951447947453

Epoch: 6| Step: 3
Training loss: 0.5325842259289687
Validation loss: 2.5701095052562217

Epoch: 6| Step: 4
Training loss: 0.42620410395225683
Validation loss: 2.7136200925851273

Epoch: 6| Step: 5
Training loss: 0.2648726495374775
Validation loss: 2.6971825198538326

Epoch: 6| Step: 6
Training loss: 0.3560060904228351
Validation loss: 2.613294311551618

Epoch: 6| Step: 7
Training loss: 0.5536582423841389
Validation loss: 2.6611776533636085

Epoch: 6| Step: 8
Training loss: 0.5302547219698813
Validation loss: 2.6630839529800623

Epoch: 6| Step: 9
Training loss: 0.42039330212772663
Validation loss: 2.6398034708247216

Epoch: 6| Step: 10
Training loss: 0.5932327326220028
Validation loss: 2.663702432382861

Epoch: 6| Step: 11
Training loss: 0.39026648281461473
Validation loss: 2.6001971292347306

Epoch: 6| Step: 12
Training loss: 0.4084110004494075
Validation loss: 2.5893486013746423

Epoch: 6| Step: 13
Training loss: 0.4849627835457149
Validation loss: 2.721659021170211

Epoch: 279| Step: 0
Training loss: 0.5839219841433466
Validation loss: 2.604933104580538

Epoch: 6| Step: 1
Training loss: 0.40362398847309666
Validation loss: 2.6540892545309096

Epoch: 6| Step: 2
Training loss: 0.4223214718626525
Validation loss: 2.6219000298718966

Epoch: 6| Step: 3
Training loss: 0.5843025795027819
Validation loss: 2.5271006825462954

Epoch: 6| Step: 4
Training loss: 0.5373982432987277
Validation loss: 2.639089359788943

Epoch: 6| Step: 5
Training loss: 0.48477946591348664
Validation loss: 2.6002347381704323

Epoch: 6| Step: 6
Training loss: 0.669884994870759
Validation loss: 2.6755702323034014

Epoch: 6| Step: 7
Training loss: 0.3963978489762579
Validation loss: 2.6524395557866813

Epoch: 6| Step: 8
Training loss: 0.5381817464116703
Validation loss: 2.6774100365293108

Epoch: 6| Step: 9
Training loss: 0.4556740227897096
Validation loss: 2.574442273451259

Epoch: 6| Step: 10
Training loss: 0.4854432754290913
Validation loss: 2.627527488494534

Epoch: 6| Step: 11
Training loss: 0.31624552094073316
Validation loss: 2.6382695966031515

Epoch: 6| Step: 12
Training loss: 0.4347900863579748
Validation loss: 2.6371157651046024

Epoch: 6| Step: 13
Training loss: 0.6278064660275575
Validation loss: 2.6327041090510552

Epoch: 280| Step: 0
Training loss: 0.5611631879807272
Validation loss: 2.6660219595325003

Epoch: 6| Step: 1
Training loss: 0.4106422814342724
Validation loss: 2.6639470870597854

Epoch: 6| Step: 2
Training loss: 0.47651966090034403
Validation loss: 2.6546215076862145

Epoch: 6| Step: 3
Training loss: 0.26904532263638214
Validation loss: 2.644158266136113

Epoch: 6| Step: 4
Training loss: 0.5014122746891105
Validation loss: 2.618679080873821

Epoch: 6| Step: 5
Training loss: 0.5918545332917823
Validation loss: 2.651692133896495

Epoch: 6| Step: 6
Training loss: 0.45584291037774227
Validation loss: 2.7462202018610937

Epoch: 6| Step: 7
Training loss: 0.32811757488023957
Validation loss: 2.6883782275149137

Epoch: 6| Step: 8
Training loss: 0.42381249675854804
Validation loss: 2.5574847120671462

Epoch: 6| Step: 9
Training loss: 0.34781417045980423
Validation loss: 2.6242666733955766

Epoch: 6| Step: 10
Training loss: 0.5979878122975949
Validation loss: 2.712044173935851

Epoch: 6| Step: 11
Training loss: 0.6146681586957367
Validation loss: 2.6321788595100717

Epoch: 6| Step: 12
Training loss: 0.6650188291723497
Validation loss: 2.613159359311675

Epoch: 6| Step: 13
Training loss: 0.35703154131921283
Validation loss: 2.6266455412352414

Epoch: 281| Step: 0
Training loss: 0.39632059106296436
Validation loss: 2.588758437804343

Epoch: 6| Step: 1
Training loss: 0.4566137575153889
Validation loss: 2.6902204244085857

Epoch: 6| Step: 2
Training loss: 0.5414383541568526
Validation loss: 2.6043313139683

Epoch: 6| Step: 3
Training loss: 0.46775322474250397
Validation loss: 2.6009173352203367

Epoch: 6| Step: 4
Training loss: 0.500932033411422
Validation loss: 2.6304951929965603

Epoch: 6| Step: 5
Training loss: 0.3410155275569746
Validation loss: 2.589528090935548

Epoch: 6| Step: 6
Training loss: 0.4703026488530266
Validation loss: 2.637014429915344

Epoch: 6| Step: 7
Training loss: 0.36508175522191005
Validation loss: 2.6832282841498323

Epoch: 6| Step: 8
Training loss: 0.7295954170366495
Validation loss: 2.6368309317377885

Epoch: 6| Step: 9
Training loss: 0.5673707839294835
Validation loss: 2.6030116050052157

Epoch: 6| Step: 10
Training loss: 0.48408644294998654
Validation loss: 2.5761152660830056

Epoch: 6| Step: 11
Training loss: 0.46427329506612647
Validation loss: 2.668886308963484

Epoch: 6| Step: 12
Training loss: 0.3047627820642899
Validation loss: 2.627857953390447

Epoch: 6| Step: 13
Training loss: 0.37844214577504715
Validation loss: 2.541550920279412

Epoch: 282| Step: 0
Training loss: 0.4828432999203225
Validation loss: 2.623295381902437

Epoch: 6| Step: 1
Training loss: 0.4449709033829569
Validation loss: 2.587727583061747

Epoch: 6| Step: 2
Training loss: 0.3305708914470807
Validation loss: 2.669466297467305

Epoch: 6| Step: 3
Training loss: 0.31175323907413
Validation loss: 2.6507563159510843

Epoch: 6| Step: 4
Training loss: 0.6930913487719627
Validation loss: 2.6010629443509172

Epoch: 6| Step: 5
Training loss: 0.3783441286955555
Validation loss: 2.6435390397261536

Epoch: 6| Step: 6
Training loss: 0.5371930421340283
Validation loss: 2.5876475170795796

Epoch: 6| Step: 7
Training loss: 0.42705120764448723
Validation loss: 2.591444223881088

Epoch: 6| Step: 8
Training loss: 0.620485355690063
Validation loss: 2.6152858069074836

Epoch: 6| Step: 9
Training loss: 0.4705543599553903
Validation loss: 2.5923518966655013

Epoch: 6| Step: 10
Training loss: 0.5112780063391726
Validation loss: 2.626616979030605

Epoch: 6| Step: 11
Training loss: 0.4631123233197949
Validation loss: 2.6683013768241293

Epoch: 6| Step: 12
Training loss: 0.48095317393658626
Validation loss: 2.673730737451211

Epoch: 6| Step: 13
Training loss: 0.43386021579709455
Validation loss: 2.6925498846917675

Epoch: 283| Step: 0
Training loss: 0.631740887197656
Validation loss: 2.725899106472916

Epoch: 6| Step: 1
Training loss: 0.5257800336032984
Validation loss: 2.735270268245591

Epoch: 6| Step: 2
Training loss: 0.49157598138693875
Validation loss: 2.587970468501009

Epoch: 6| Step: 3
Training loss: 0.4128985509770329
Validation loss: 2.656598483394887

Epoch: 6| Step: 4
Training loss: 0.36705838632121557
Validation loss: 2.5822418788733335

Epoch: 6| Step: 5
Training loss: 0.43587334547065226
Validation loss: 2.632348839506643

Epoch: 6| Step: 6
Training loss: 0.5315294652650178
Validation loss: 2.6647093314852035

Epoch: 6| Step: 7
Training loss: 0.6045452827960518
Validation loss: 2.6461731299526243

Epoch: 6| Step: 8
Training loss: 0.4946675563221169
Validation loss: 2.67311190256117

Epoch: 6| Step: 9
Training loss: 0.4071270937843816
Validation loss: 2.6339466583887114

Epoch: 6| Step: 10
Training loss: 0.51083749498204
Validation loss: 2.578954235771834

Epoch: 6| Step: 11
Training loss: 0.5453145242997773
Validation loss: 2.6540496389159096

Epoch: 6| Step: 12
Training loss: 0.39423332674259737
Validation loss: 2.5874835844640267

Epoch: 6| Step: 13
Training loss: 0.39349646883110856
Validation loss: 2.6855347493215835

Epoch: 284| Step: 0
Training loss: 0.48507151209212235
Validation loss: 2.6235771713049574

Epoch: 6| Step: 1
Training loss: 0.40562916046736197
Validation loss: 2.6236851971919832

Epoch: 6| Step: 2
Training loss: 0.2586947575168833
Validation loss: 2.611098415149999

Epoch: 6| Step: 3
Training loss: 0.3661426531389949
Validation loss: 2.703343509375834

Epoch: 6| Step: 4
Training loss: 0.4837110491160021
Validation loss: 2.6083346213519376

Epoch: 6| Step: 5
Training loss: 0.49908605134221434
Validation loss: 2.627952791998644

Epoch: 6| Step: 6
Training loss: 0.407487012972152
Validation loss: 2.731036620603315

Epoch: 6| Step: 7
Training loss: 0.7345785305351589
Validation loss: 2.5972126899947767

Epoch: 6| Step: 8
Training loss: 0.6454696297714602
Validation loss: 2.6865477834134803

Epoch: 6| Step: 9
Training loss: 0.4375940119688011
Validation loss: 2.627993269743834

Epoch: 6| Step: 10
Training loss: 0.5062847337463409
Validation loss: 2.628240477405938

Epoch: 6| Step: 11
Training loss: 0.3541711451677388
Validation loss: 2.659791209026457

Epoch: 6| Step: 12
Training loss: 0.6022259905104065
Validation loss: 2.63498704346108

Epoch: 6| Step: 13
Training loss: 0.4140331689774432
Validation loss: 2.6415569910412966

Epoch: 285| Step: 0
Training loss: 0.5165270515459127
Validation loss: 2.674322557677333

Epoch: 6| Step: 1
Training loss: 0.46730009591227945
Validation loss: 2.651287679492919

Epoch: 6| Step: 2
Training loss: 0.4270404080784814
Validation loss: 2.6284010970048786

Epoch: 6| Step: 3
Training loss: 0.795523226237664
Validation loss: 2.661956058750953

Epoch: 6| Step: 4
Training loss: 0.3292795147284872
Validation loss: 2.6156107541710027

Epoch: 6| Step: 5
Training loss: 0.5648813174511336
Validation loss: 2.6600339677501403

Epoch: 6| Step: 6
Training loss: 0.38643973332326886
Validation loss: 2.7058304567931684

Epoch: 6| Step: 7
Training loss: 0.45856529745449925
Validation loss: 2.696623920821757

Epoch: 6| Step: 8
Training loss: 0.3865946753702582
Validation loss: 2.630329247644523

Epoch: 6| Step: 9
Training loss: 0.4240417469487254
Validation loss: 2.6457658343578574

Epoch: 6| Step: 10
Training loss: 0.3567200320567929
Validation loss: 2.649085896658575

Epoch: 6| Step: 11
Training loss: 0.35290284553465895
Validation loss: 2.5995306379974776

Epoch: 6| Step: 12
Training loss: 0.5194330911477933
Validation loss: 2.608308737966908

Epoch: 6| Step: 13
Training loss: 0.4325532543052457
Validation loss: 2.6454432392653375

Epoch: 286| Step: 0
Training loss: 0.5814557398436753
Validation loss: 2.6041184433604725

Epoch: 6| Step: 1
Training loss: 0.33275168181079623
Validation loss: 2.6590994865883797

Epoch: 6| Step: 2
Training loss: 0.3032307523915064
Validation loss: 2.6302952566356264

Epoch: 6| Step: 3
Training loss: 0.6331254632614866
Validation loss: 2.782827815578267

Epoch: 6| Step: 4
Training loss: 0.4910070098388222
Validation loss: 2.7451214142880715

Epoch: 6| Step: 5
Training loss: 0.4285804358739273
Validation loss: 2.68277534395444

Epoch: 6| Step: 6
Training loss: 0.5713055208883908
Validation loss: 2.677886060800291

Epoch: 6| Step: 7
Training loss: 0.48660840150562856
Validation loss: 2.665421043485032

Epoch: 6| Step: 8
Training loss: 0.45070653921055115
Validation loss: 2.644212621879994

Epoch: 6| Step: 9
Training loss: 0.32827101592098995
Validation loss: 2.625268642363584

Epoch: 6| Step: 10
Training loss: 0.49492658147704216
Validation loss: 2.5754064850193714

Epoch: 6| Step: 11
Training loss: 0.7445613442710348
Validation loss: 2.666800277064837

Epoch: 6| Step: 12
Training loss: 0.43026817273535006
Validation loss: 2.632130263743868

Epoch: 6| Step: 13
Training loss: 0.39471510578424557
Validation loss: 2.6369287779246537

Epoch: 287| Step: 0
Training loss: 0.4312468583918595
Validation loss: 2.6694197648841924

Epoch: 6| Step: 1
Training loss: 0.6842520024106905
Validation loss: 2.6492414426455095

Epoch: 6| Step: 2
Training loss: 0.5507852270104505
Validation loss: 2.6331668241788817

Epoch: 6| Step: 3
Training loss: 0.29475762043712395
Validation loss: 2.605769714328715

Epoch: 6| Step: 4
Training loss: 0.592560480065067
Validation loss: 2.670911976037823

Epoch: 6| Step: 5
Training loss: 0.37860043956279676
Validation loss: 2.6424246078750917

Epoch: 6| Step: 6
Training loss: 0.43112887602689864
Validation loss: 2.6380117001364423

Epoch: 6| Step: 7
Training loss: 0.47580164222049043
Validation loss: 2.634207577587317

Epoch: 6| Step: 8
Training loss: 0.4498327620006682
Validation loss: 2.634870077956013

Epoch: 6| Step: 9
Training loss: 0.4610633678244539
Validation loss: 2.630131051215469

Epoch: 6| Step: 10
Training loss: 0.3782215814750011
Validation loss: 2.599436520380984

Epoch: 6| Step: 11
Training loss: 0.33905943987823456
Validation loss: 2.613175766835025

Epoch: 6| Step: 12
Training loss: 0.47137766897153544
Validation loss: 2.633111832956502

Epoch: 6| Step: 13
Training loss: 0.36266268088815795
Validation loss: 2.589256131734497

Epoch: 288| Step: 0
Training loss: 0.31185736143806814
Validation loss: 2.650584233258408

Epoch: 6| Step: 1
Training loss: 0.4348368823667049
Validation loss: 2.643848986685162

Epoch: 6| Step: 2
Training loss: 0.33073756690383466
Validation loss: 2.606168333705834

Epoch: 6| Step: 3
Training loss: 0.35960264873823333
Validation loss: 2.6942401761583854

Epoch: 6| Step: 4
Training loss: 0.6734980120102075
Validation loss: 2.6698648576431734

Epoch: 6| Step: 5
Training loss: 0.4001217567386291
Validation loss: 2.705781384803443

Epoch: 6| Step: 6
Training loss: 0.38441943555328545
Validation loss: 2.6564197560837184

Epoch: 6| Step: 7
Training loss: 0.40922353140887735
Validation loss: 2.653381698884842

Epoch: 6| Step: 8
Training loss: 0.6760235390684286
Validation loss: 2.637573013379805

Epoch: 6| Step: 9
Training loss: 0.41765233121860923
Validation loss: 2.609500356621178

Epoch: 6| Step: 10
Training loss: 0.38705891762481154
Validation loss: 2.640031315203578

Epoch: 6| Step: 11
Training loss: 0.44170487691429355
Validation loss: 2.698554421435487

Epoch: 6| Step: 12
Training loss: 0.5556587795549474
Validation loss: 2.6825514781760997

Epoch: 6| Step: 13
Training loss: 0.3486156833404993
Validation loss: 2.6596930833973884

Epoch: 289| Step: 0
Training loss: 0.4126915097005011
Validation loss: 2.666967305482078

Epoch: 6| Step: 1
Training loss: 0.37288322653984535
Validation loss: 2.5741461211529293

Epoch: 6| Step: 2
Training loss: 0.6577292527827279
Validation loss: 2.7230021814773493

Epoch: 6| Step: 3
Training loss: 0.406295938828818
Validation loss: 2.58671040427535

Epoch: 6| Step: 4
Training loss: 0.5083876360618884
Validation loss: 2.6757267039138886

Epoch: 6| Step: 5
Training loss: 0.38049191085222317
Validation loss: 2.6502495252344165

Epoch: 6| Step: 6
Training loss: 0.36064756068329323
Validation loss: 2.600919703286303

Epoch: 6| Step: 7
Training loss: 0.44986154757581215
Validation loss: 2.650768593224739

Epoch: 6| Step: 8
Training loss: 0.39363759873677173
Validation loss: 2.6706534524966195

Epoch: 6| Step: 9
Training loss: 0.2623536678436593
Validation loss: 2.6109016810177836

Epoch: 6| Step: 10
Training loss: 0.4365242738310378
Validation loss: 2.587446865205789

Epoch: 6| Step: 11
Training loss: 0.6817509253159536
Validation loss: 2.6467607229545305

Epoch: 6| Step: 12
Training loss: 0.6178614642624496
Validation loss: 2.600278581464443

Epoch: 6| Step: 13
Training loss: 0.4511192918661032
Validation loss: 2.702539854717421

Epoch: 290| Step: 0
Training loss: 0.3669637850763634
Validation loss: 2.615975458935097

Epoch: 6| Step: 1
Training loss: 0.26505056144041056
Validation loss: 2.6412099156585414

Epoch: 6| Step: 2
Training loss: 0.39667814433832116
Validation loss: 2.6323951820597244

Epoch: 6| Step: 3
Training loss: 0.4164531001490063
Validation loss: 2.667601545689754

Epoch: 6| Step: 4
Training loss: 0.5148157068698929
Validation loss: 2.6307715590334126

Epoch: 6| Step: 5
Training loss: 0.37896665111359074
Validation loss: 2.566229889189017

Epoch: 6| Step: 6
Training loss: 0.5023626890513074
Validation loss: 2.639037450713308

Epoch: 6| Step: 7
Training loss: 0.36836213063314704
Validation loss: 2.6254734036283804

Epoch: 6| Step: 8
Training loss: 0.5651671964826082
Validation loss: 2.611368403936075

Epoch: 6| Step: 9
Training loss: 0.43271090007027446
Validation loss: 2.6498599813165766

Epoch: 6| Step: 10
Training loss: 0.4847552437481454
Validation loss: 2.5944599420936414

Epoch: 6| Step: 11
Training loss: 0.6285779581876445
Validation loss: 2.6548039857403483

Epoch: 6| Step: 12
Training loss: 0.49934217273490034
Validation loss: 2.5452978013131164

Epoch: 6| Step: 13
Training loss: 0.33291365111651916
Validation loss: 2.6777004812049245

Epoch: 291| Step: 0
Training loss: 0.6199229259037372
Validation loss: 2.615055092327891

Epoch: 6| Step: 1
Training loss: 0.3803262745377445
Validation loss: 2.5892946976003173

Epoch: 6| Step: 2
Training loss: 0.33599602389111777
Validation loss: 2.634743756617534

Epoch: 6| Step: 3
Training loss: 0.3823156441108218
Validation loss: 2.6789687873139365

Epoch: 6| Step: 4
Training loss: 0.2549201382605044
Validation loss: 2.62434674263459

Epoch: 6| Step: 5
Training loss: 0.37470458235945797
Validation loss: 2.6909201542455436

Epoch: 6| Step: 6
Training loss: 0.3366516528798768
Validation loss: 2.6460681395581394

Epoch: 6| Step: 7
Training loss: 0.41613298650143693
Validation loss: 2.63184661202516

Epoch: 6| Step: 8
Training loss: 0.6575786899937218
Validation loss: 2.5955002406205985

Epoch: 6| Step: 9
Training loss: 0.4208662193340879
Validation loss: 2.633207448131387

Epoch: 6| Step: 10
Training loss: 0.6076767071051217
Validation loss: 2.6716298219500465

Epoch: 6| Step: 11
Training loss: 0.2719424109360705
Validation loss: 2.6619957656855338

Epoch: 6| Step: 12
Training loss: 0.3946195824571144
Validation loss: 2.6331149568025904

Epoch: 6| Step: 13
Training loss: 0.49816445851285945
Validation loss: 2.7037361350889304

Epoch: 292| Step: 0
Training loss: 0.3205642641182217
Validation loss: 2.7051431696263823

Epoch: 6| Step: 1
Training loss: 0.44309340914527445
Validation loss: 2.6654052035552502

Epoch: 6| Step: 2
Training loss: 0.3402404552490161
Validation loss: 2.609824014433128

Epoch: 6| Step: 3
Training loss: 0.41439108136992914
Validation loss: 2.7025731870402696

Epoch: 6| Step: 4
Training loss: 0.5647013821185887
Validation loss: 2.6596623511640543

Epoch: 6| Step: 5
Training loss: 0.2796225616253268
Validation loss: 2.598204743647606

Epoch: 6| Step: 6
Training loss: 0.32209847479230863
Validation loss: 2.655590918060324

Epoch: 6| Step: 7
Training loss: 0.5111221446468075
Validation loss: 2.5966753262027353

Epoch: 6| Step: 8
Training loss: 0.38261984823722317
Validation loss: 2.591734857878459

Epoch: 6| Step: 9
Training loss: 0.37035625859149873
Validation loss: 2.633567324535684

Epoch: 6| Step: 10
Training loss: 0.47745446077860226
Validation loss: 2.630872016995308

Epoch: 6| Step: 11
Training loss: 0.43777412954347056
Validation loss: 2.6611098766213432

Epoch: 6| Step: 12
Training loss: 0.5420391165546551
Validation loss: 2.658435386285285

Epoch: 6| Step: 13
Training loss: 0.4959097092839739
Validation loss: 2.5899609385310147

Epoch: 293| Step: 0
Training loss: 0.28546058405078556
Validation loss: 2.6726417556722035

Epoch: 6| Step: 1
Training loss: 0.4429052775017105
Validation loss: 2.5903565755886335

Epoch: 6| Step: 2
Training loss: 0.3854838218262876
Validation loss: 2.6056998253821844

Epoch: 6| Step: 3
Training loss: 0.34580751771783275
Validation loss: 2.633518324361948

Epoch: 6| Step: 4
Training loss: 0.4228211319261487
Validation loss: 2.6771747830773402

Epoch: 6| Step: 5
Training loss: 0.5205102745126752
Validation loss: 2.5694774751573486

Epoch: 6| Step: 6
Training loss: 0.47065245486216695
Validation loss: 2.6527864950901177

Epoch: 6| Step: 7
Training loss: 0.3353013735913414
Validation loss: 2.6457481120244393

Epoch: 6| Step: 8
Training loss: 0.4099353558763002
Validation loss: 2.5853869878851903

Epoch: 6| Step: 9
Training loss: 0.41983151905343713
Validation loss: 2.648224618583707

Epoch: 6| Step: 10
Training loss: 0.4547623942984079
Validation loss: 2.6627139260757846

Epoch: 6| Step: 11
Training loss: 0.2895603532157838
Validation loss: 2.598818442046005

Epoch: 6| Step: 12
Training loss: 0.4011171030543343
Validation loss: 2.5983932635100584

Epoch: 6| Step: 13
Training loss: 0.3820817551256128
Validation loss: 2.7045350118279567

Epoch: 294| Step: 0
Training loss: 0.3152617370566894
Validation loss: 2.6080647908219228

Epoch: 6| Step: 1
Training loss: 0.25338837555545907
Validation loss: 2.64679379689554

Epoch: 6| Step: 2
Training loss: 0.23963750955775553
Validation loss: 2.6523729640155205

Epoch: 6| Step: 3
Training loss: 0.44681983287117816
Validation loss: 2.609712438027601

Epoch: 6| Step: 4
Training loss: 0.4465437481669036
Validation loss: 2.6712964418664527

Epoch: 6| Step: 5
Training loss: 0.381910546079719
Validation loss: 2.6258929716807446

Epoch: 6| Step: 6
Training loss: 0.30471728252690905
Validation loss: 2.5907628119748014

Epoch: 6| Step: 7
Training loss: 0.47032809057406993
Validation loss: 2.6840911359877184

Epoch: 6| Step: 8
Training loss: 0.5828271582756944
Validation loss: 2.63080706942038

Epoch: 6| Step: 9
Training loss: 0.5398939603429218
Validation loss: 2.6496965084589394

Epoch: 6| Step: 10
Training loss: 0.6376646306132853
Validation loss: 2.625504150115645

Epoch: 6| Step: 11
Training loss: 0.2797882319575911
Validation loss: 2.644180477437683

Epoch: 6| Step: 12
Training loss: 0.3738841302867093
Validation loss: 2.592928974780965

Epoch: 6| Step: 13
Training loss: 0.38187462886286555
Validation loss: 2.6401321282219583

Epoch: 295| Step: 0
Training loss: 0.4564646281381866
Validation loss: 2.63588013676077

Epoch: 6| Step: 1
Training loss: 0.5021143850904871
Validation loss: 2.528525404938457

Epoch: 6| Step: 2
Training loss: 0.5335257256462675
Validation loss: 2.708013828700569

Epoch: 6| Step: 3
Training loss: 0.30388685326346776
Validation loss: 2.641950857557802

Epoch: 6| Step: 4
Training loss: 0.4137824388966198
Validation loss: 2.614562157371656

Epoch: 6| Step: 5
Training loss: 0.3510387545992151
Validation loss: 2.607642460896946

Epoch: 6| Step: 6
Training loss: 0.32660824031000385
Validation loss: 2.6022462604989487

Epoch: 6| Step: 7
Training loss: 0.608486897756152
Validation loss: 2.651325927563208

Epoch: 6| Step: 8
Training loss: 0.5064688586238872
Validation loss: 2.625383296109306

Epoch: 6| Step: 9
Training loss: 0.5147436875395821
Validation loss: 2.643736388800463

Epoch: 6| Step: 10
Training loss: 0.46003421272674916
Validation loss: 2.6005622537040365

Epoch: 6| Step: 11
Training loss: 0.4250134711374544
Validation loss: 2.6516223538802337

Epoch: 6| Step: 12
Training loss: 0.3444445702123583
Validation loss: 2.6567627804535716

Epoch: 6| Step: 13
Training loss: 0.3770164871329278
Validation loss: 2.6361661053990746

Epoch: 296| Step: 0
Training loss: 0.423920159960607
Validation loss: 2.5738617992528536

Epoch: 6| Step: 1
Training loss: 0.445319911828181
Validation loss: 2.61367883019507

Epoch: 6| Step: 2
Training loss: 0.59985232323981
Validation loss: 2.666280224237286

Epoch: 6| Step: 3
Training loss: 0.5392015526592839
Validation loss: 2.62191744358171

Epoch: 6| Step: 4
Training loss: 0.5693355187337654
Validation loss: 2.619306050385782

Epoch: 6| Step: 5
Training loss: 0.48201864587760357
Validation loss: 2.640550917088458

Epoch: 6| Step: 6
Training loss: 0.4101970833933687
Validation loss: 2.6228511734457323

Epoch: 6| Step: 7
Training loss: 0.2834415221638644
Validation loss: 2.6289394276430382

Epoch: 6| Step: 8
Training loss: 0.3271958501819621
Validation loss: 2.6370918066529856

Epoch: 6| Step: 9
Training loss: 0.36475553079063155
Validation loss: 2.6885029008256254

Epoch: 6| Step: 10
Training loss: 0.3539298986487313
Validation loss: 2.6953581211817834

Epoch: 6| Step: 11
Training loss: 0.5014293624672184
Validation loss: 2.648990944619

Epoch: 6| Step: 12
Training loss: 0.40057549279339827
Validation loss: 2.6389325829842663

Epoch: 6| Step: 13
Training loss: 0.34176654136115253
Validation loss: 2.7218066166412953

Epoch: 297| Step: 0
Training loss: 0.34763301814604486
Validation loss: 2.675617385636001

Epoch: 6| Step: 1
Training loss: 0.5552708687791639
Validation loss: 2.698727038027982

Epoch: 6| Step: 2
Training loss: 0.3396463588236398
Validation loss: 2.6368958665676625

Epoch: 6| Step: 3
Training loss: 0.38457647021291036
Validation loss: 2.624603695699364

Epoch: 6| Step: 4
Training loss: 0.47126976508018126
Validation loss: 2.6301257784637895

Epoch: 6| Step: 5
Training loss: 0.5859010812249716
Validation loss: 2.6276778534360705

Epoch: 6| Step: 6
Training loss: 0.5168978557123012
Validation loss: 2.6749734889110117

Epoch: 6| Step: 7
Training loss: 0.48814964046635
Validation loss: 2.6557784017151205

Epoch: 6| Step: 8
Training loss: 0.5233910952822546
Validation loss: 2.623797913468691

Epoch: 6| Step: 9
Training loss: 0.45867198296287226
Validation loss: 2.594255068831356

Epoch: 6| Step: 10
Training loss: 0.3601395311426282
Validation loss: 2.631808216748723

Epoch: 6| Step: 11
Training loss: 0.4452384083999084
Validation loss: 2.6714940533846394

Epoch: 6| Step: 12
Training loss: 0.4129851197928825
Validation loss: 2.652921543475338

Epoch: 6| Step: 13
Training loss: 0.44889946246965823
Validation loss: 2.6352534538863797

Epoch: 298| Step: 0
Training loss: 0.570234633055144
Validation loss: 2.6676116451172653

Epoch: 6| Step: 1
Training loss: 0.3553854247304143
Validation loss: 2.611364401938868

Epoch: 6| Step: 2
Training loss: 0.3198877868377376
Validation loss: 2.5855617653590435

Epoch: 6| Step: 3
Training loss: 0.5254268137440812
Validation loss: 2.5921912201127912

Epoch: 6| Step: 4
Training loss: 0.3630259652598247
Validation loss: 2.6321951635735936

Epoch: 6| Step: 5
Training loss: 0.5434085519285485
Validation loss: 2.6108572855691943

Epoch: 6| Step: 6
Training loss: 0.41401231209673023
Validation loss: 2.629032594876545

Epoch: 6| Step: 7
Training loss: 0.44563280264616223
Validation loss: 2.619094594104814

Epoch: 6| Step: 8
Training loss: 0.5082069039112662
Validation loss: 2.6810924528203177

Epoch: 6| Step: 9
Training loss: 0.5515395011105259
Validation loss: 2.5856345806969383

Epoch: 6| Step: 10
Training loss: 0.384673577156641
Validation loss: 2.6486718028204614

Epoch: 6| Step: 11
Training loss: 0.45085180579973816
Validation loss: 2.650544025551801

Epoch: 6| Step: 12
Training loss: 0.605725338618438
Validation loss: 2.6502667226857235

Epoch: 6| Step: 13
Training loss: 0.3662628340506779
Validation loss: 2.669641025583289

Epoch: 299| Step: 0
Training loss: 0.5023862105915269
Validation loss: 2.6468426038492723

Epoch: 6| Step: 1
Training loss: 0.5796638062356997
Validation loss: 2.6389409099158367

Epoch: 6| Step: 2
Training loss: 0.3251232376644853
Validation loss: 2.6001496320851585

Epoch: 6| Step: 3
Training loss: 0.485714858957862
Validation loss: 2.70476126714404

Epoch: 6| Step: 4
Training loss: 0.39915997320720586
Validation loss: 2.580990210661268

Epoch: 6| Step: 5
Training loss: 0.5409321359052202
Validation loss: 2.6455556518540075

Epoch: 6| Step: 6
Training loss: 0.37812185207349186
Validation loss: 2.580213113430515

Epoch: 6| Step: 7
Training loss: 0.40809031118563405
Validation loss: 2.632463124503886

Epoch: 6| Step: 8
Training loss: 0.6083263519835832
Validation loss: 2.6750683951027074

Epoch: 6| Step: 9
Training loss: 0.6096558046143291
Validation loss: 2.6203328983526673

Epoch: 6| Step: 10
Training loss: 0.30098498244145816
Validation loss: 2.580052281572011

Epoch: 6| Step: 11
Training loss: 0.3136768711210011
Validation loss: 2.6214392141128844

Epoch: 6| Step: 12
Training loss: 0.3240737245982925
Validation loss: 2.6302901806072683

Epoch: 6| Step: 13
Training loss: 0.4844813691524336
Validation loss: 2.5943109832538434

Epoch: 300| Step: 0
Training loss: 0.39106818807158905
Validation loss: 2.61696342154276

Epoch: 6| Step: 1
Training loss: 0.33992690680358234
Validation loss: 2.618151981411733

Epoch: 6| Step: 2
Training loss: 0.41733183417810166
Validation loss: 2.593093268046392

Epoch: 6| Step: 3
Training loss: 0.5508572140517243
Validation loss: 2.6271231406027202

Epoch: 6| Step: 4
Training loss: 0.4665751868514097
Validation loss: 2.632798207109332

Epoch: 6| Step: 5
Training loss: 0.5464304615882074
Validation loss: 2.620795273213865

Epoch: 6| Step: 6
Training loss: 0.35698151690723584
Validation loss: 2.5797029232532203

Epoch: 6| Step: 7
Training loss: 0.47696549933000076
Validation loss: 2.703910728141532

Epoch: 6| Step: 8
Training loss: 0.29160953569594317
Validation loss: 2.6181943256849265

Epoch: 6| Step: 9
Training loss: 0.4081227894266032
Validation loss: 2.667742546921702

Epoch: 6| Step: 10
Training loss: 0.31747488006957814
Validation loss: 2.6677593932850487

Epoch: 6| Step: 11
Training loss: 0.3325976533468068
Validation loss: 2.615452987806021

Epoch: 6| Step: 12
Training loss: 0.34400449348719697
Validation loss: 2.68545114797429

Epoch: 6| Step: 13
Training loss: 0.3851011333530126
Validation loss: 2.641670727250341

Epoch: 301| Step: 0
Training loss: 0.268836660607148
Validation loss: 2.664790422287534

Epoch: 6| Step: 1
Training loss: 0.5159638765132766
Validation loss: 2.680471292685571

Epoch: 6| Step: 2
Training loss: 0.584033925687727
Validation loss: 2.722515363436793

Epoch: 6| Step: 3
Training loss: 0.3156221115811063
Validation loss: 2.7398365372721556

Epoch: 6| Step: 4
Training loss: 0.34026645811330775
Validation loss: 2.6651036082412487

Epoch: 6| Step: 5
Training loss: 0.43643530653645857
Validation loss: 2.6458699882150962

Epoch: 6| Step: 6
Training loss: 0.5910313253088518
Validation loss: 2.662947092142602

Epoch: 6| Step: 7
Training loss: 0.5222583413596967
Validation loss: 2.6786643133255965

Epoch: 6| Step: 8
Training loss: 0.2464066816748283
Validation loss: 2.6489492576484652

Epoch: 6| Step: 9
Training loss: 0.3986427675954481
Validation loss: 2.6177626172433426

Epoch: 6| Step: 10
Training loss: 0.2914880591706436
Validation loss: 2.6624170556080724

Epoch: 6| Step: 11
Training loss: 0.34672556828743756
Validation loss: 2.6211074699880377

Epoch: 6| Step: 12
Training loss: 0.41658886739467677
Validation loss: 2.649677687663269

Epoch: 6| Step: 13
Training loss: 0.3707579046681289
Validation loss: 2.6459573331195974

Epoch: 302| Step: 0
Training loss: 0.5695909612722049
Validation loss: 2.6849968512272144

Epoch: 6| Step: 1
Training loss: 0.4020305636800756
Validation loss: 2.654512368110225

Epoch: 6| Step: 2
Training loss: 0.5383315728614453
Validation loss: 2.609746240335351

Epoch: 6| Step: 3
Training loss: 0.39338900199773824
Validation loss: 2.6122964886212845

Epoch: 6| Step: 4
Training loss: 0.5963930231176221
Validation loss: 2.584972189895702

Epoch: 6| Step: 5
Training loss: 0.4382065449249828
Validation loss: 2.6756974033110867

Epoch: 6| Step: 6
Training loss: 0.47796546293925996
Validation loss: 2.6371535105254647

Epoch: 6| Step: 7
Training loss: 0.46456936343391286
Validation loss: 2.6487055129953463

Epoch: 6| Step: 8
Training loss: 0.406812461875296
Validation loss: 2.675774270301496

Epoch: 6| Step: 9
Training loss: 0.41635164829714455
Validation loss: 2.630503048138332

Epoch: 6| Step: 10
Training loss: 0.38559277695077737
Validation loss: 2.561014132296729

Epoch: 6| Step: 11
Training loss: 0.5966094080216123
Validation loss: 2.597050103237575

Epoch: 6| Step: 12
Training loss: 0.36731301861022614
Validation loss: 2.6019827013635566

Epoch: 6| Step: 13
Training loss: 0.40286489641620854
Validation loss: 2.6241069364447984

Epoch: 303| Step: 0
Training loss: 0.4750424359840704
Validation loss: 2.64290915871274

Epoch: 6| Step: 1
Training loss: 0.7010029028670519
Validation loss: 2.6489795291446154

Epoch: 6| Step: 2
Training loss: 0.3602704833082365
Validation loss: 2.6168145516593806

Epoch: 6| Step: 3
Training loss: 0.29043767490960426
Validation loss: 2.621116080949373

Epoch: 6| Step: 4
Training loss: 0.448356630430248
Validation loss: 2.6086469536879835

Epoch: 6| Step: 5
Training loss: 0.4170517711371295
Validation loss: 2.586740682131244

Epoch: 6| Step: 6
Training loss: 0.34109370243423415
Validation loss: 2.6182227369423914

Epoch: 6| Step: 7
Training loss: 0.5429345813126936
Validation loss: 2.5775570176358107

Epoch: 6| Step: 8
Training loss: 0.46145815458215333
Validation loss: 2.678036625167005

Epoch: 6| Step: 9
Training loss: 0.35965792258425006
Validation loss: 2.615973727284868

Epoch: 6| Step: 10
Training loss: 0.34497424513286884
Validation loss: 2.6219558927646185

Epoch: 6| Step: 11
Training loss: 0.39881028706173227
Validation loss: 2.6364613348497787

Epoch: 6| Step: 12
Training loss: 0.4559868510927106
Validation loss: 2.6373357055741464

Epoch: 6| Step: 13
Training loss: 0.41546225122000796
Validation loss: 2.680733449717682

Epoch: 304| Step: 0
Training loss: 0.3977651345822052
Validation loss: 2.6350354960618616

Epoch: 6| Step: 1
Training loss: 0.5418595710238578
Validation loss: 2.5396480726252415

Epoch: 6| Step: 2
Training loss: 0.3574187898763283
Validation loss: 2.6666734715215963

Epoch: 6| Step: 3
Training loss: 0.4641994049602197
Validation loss: 2.6219417377112233

Epoch: 6| Step: 4
Training loss: 0.24699334314001453
Validation loss: 2.625112954994334

Epoch: 6| Step: 5
Training loss: 0.4362081118478752
Validation loss: 2.6520234683807464

Epoch: 6| Step: 6
Training loss: 0.5345965333360957
Validation loss: 2.6450555414090404

Epoch: 6| Step: 7
Training loss: 0.38521087367470236
Validation loss: 2.59848235721066

Epoch: 6| Step: 8
Training loss: 0.2502818902548456
Validation loss: 2.6707784919841324

Epoch: 6| Step: 9
Training loss: 0.27588214703572167
Validation loss: 2.5796870113983092

Epoch: 6| Step: 10
Training loss: 0.5758515841669045
Validation loss: 2.693071238831847

Epoch: 6| Step: 11
Training loss: 0.39065124423557485
Validation loss: 2.6674850271103283

Epoch: 6| Step: 12
Training loss: 0.3869814125225192
Validation loss: 2.566994663951238

Epoch: 6| Step: 13
Training loss: 0.3397419656501102
Validation loss: 2.596736215370909

Epoch: 305| Step: 0
Training loss: 0.4746059370505063
Validation loss: 2.548492206833746

Epoch: 6| Step: 1
Training loss: 0.5184165641323851
Validation loss: 2.640008677651372

Epoch: 6| Step: 2
Training loss: 0.4240075008678031
Validation loss: 2.5621354223657464

Epoch: 6| Step: 3
Training loss: 0.3386032659780398
Validation loss: 2.6024240894221746

Epoch: 6| Step: 4
Training loss: 0.4656983541785989
Validation loss: 2.6252958040236662

Epoch: 6| Step: 5
Training loss: 0.3100438152005186
Validation loss: 2.6579308446288836

Epoch: 6| Step: 6
Training loss: 0.266640600902468
Validation loss: 2.590371946362277

Epoch: 6| Step: 7
Training loss: 0.4019810235932141
Validation loss: 2.638841256051968

Epoch: 6| Step: 8
Training loss: 0.4361911336646605
Validation loss: 2.6088402784610856

Epoch: 6| Step: 9
Training loss: 0.35111192864151497
Validation loss: 2.637586858563617

Epoch: 6| Step: 10
Training loss: 0.45411872421157684
Validation loss: 2.6119190081092647

Epoch: 6| Step: 11
Training loss: 0.44715566824402575
Validation loss: 2.6154458319197746

Epoch: 6| Step: 12
Training loss: 0.35227053657672797
Validation loss: 2.594432067047408

Epoch: 6| Step: 13
Training loss: 0.48577245503706634
Validation loss: 2.5920791529752716

Epoch: 306| Step: 0
Training loss: 0.35286612938498824
Validation loss: 2.6837087548279817

Epoch: 6| Step: 1
Training loss: 0.42234744003665337
Validation loss: 2.660527259919763

Epoch: 6| Step: 2
Training loss: 0.5884689072276564
Validation loss: 2.6247716229109455

Epoch: 6| Step: 3
Training loss: 0.3771952508668886
Validation loss: 2.638226708490489

Epoch: 6| Step: 4
Training loss: 0.43238683212249424
Validation loss: 2.6759384814472233

Epoch: 6| Step: 5
Training loss: 0.4500016563438026
Validation loss: 2.6426150104874075

Epoch: 6| Step: 6
Training loss: 0.5738484752310704
Validation loss: 2.616161148985385

Epoch: 6| Step: 7
Training loss: 0.2992877044109205
Validation loss: 2.6060857085261655

Epoch: 6| Step: 8
Training loss: 0.44183099616627036
Validation loss: 2.678999780131131

Epoch: 6| Step: 9
Training loss: 0.45859644302539243
Validation loss: 2.6995743822256624

Epoch: 6| Step: 10
Training loss: 0.4272808823727262
Validation loss: 2.65643306176169

Epoch: 6| Step: 11
Training loss: 0.3685002701718234
Validation loss: 2.6992471475390922

Epoch: 6| Step: 12
Training loss: 0.5092052434281215
Validation loss: 2.601955059627113

Epoch: 6| Step: 13
Training loss: 0.2986998438530467
Validation loss: 2.659211142572599

Epoch: 307| Step: 0
Training loss: 0.3973551241453932
Validation loss: 2.665922416203443

Epoch: 6| Step: 1
Training loss: 0.4436013153978956
Validation loss: 2.71403347154319

Epoch: 6| Step: 2
Training loss: 0.4029899149051674
Validation loss: 2.6799667405678993

Epoch: 6| Step: 3
Training loss: 0.4701122358162003
Validation loss: 2.655069799589292

Epoch: 6| Step: 4
Training loss: 0.3440540009851245
Validation loss: 2.6160995423610287

Epoch: 6| Step: 5
Training loss: 0.4252176141388004
Validation loss: 2.6194657463653983

Epoch: 6| Step: 6
Training loss: 0.3874207300198854
Validation loss: 2.6850580017862447

Epoch: 6| Step: 7
Training loss: 0.6134709593265911
Validation loss: 2.6267753682743646

Epoch: 6| Step: 8
Training loss: 0.4276982470718399
Validation loss: 2.65586592945611

Epoch: 6| Step: 9
Training loss: 0.40727120207409634
Validation loss: 2.627961138600041

Epoch: 6| Step: 10
Training loss: 0.30918636640129227
Validation loss: 2.631975027548038

Epoch: 6| Step: 11
Training loss: 0.4060177505963081
Validation loss: 2.685383221812853

Epoch: 6| Step: 12
Training loss: 0.5304842647480353
Validation loss: 2.6704911037035717

Epoch: 6| Step: 13
Training loss: 0.3791790992494105
Validation loss: 2.65215624828646

Epoch: 308| Step: 0
Training loss: 0.38770015530960716
Validation loss: 2.6292809214202673

Epoch: 6| Step: 1
Training loss: 0.5610247180256531
Validation loss: 2.6280916339632587

Epoch: 6| Step: 2
Training loss: 0.47464218340217695
Validation loss: 2.6556114326789455

Epoch: 6| Step: 3
Training loss: 0.46812581784185825
Validation loss: 2.6155286247822755

Epoch: 6| Step: 4
Training loss: 0.4594296182873087
Validation loss: 2.6775500166608617

Epoch: 6| Step: 5
Training loss: 0.36896403695811336
Validation loss: 2.5643214753431853

Epoch: 6| Step: 6
Training loss: 0.32231461123754596
Validation loss: 2.6123796550891116

Epoch: 6| Step: 7
Training loss: 0.4401958546883533
Validation loss: 2.6275658858314426

Epoch: 6| Step: 8
Training loss: 0.520049045065491
Validation loss: 2.6707210465590996

Epoch: 6| Step: 9
Training loss: 0.44331252064766025
Validation loss: 2.6514973326905875

Epoch: 6| Step: 10
Training loss: 0.3691047368441483
Validation loss: 2.6012165041882183

Epoch: 6| Step: 11
Training loss: 0.37141894096161493
Validation loss: 2.730678013689834

Epoch: 6| Step: 12
Training loss: 0.3582059462840755
Validation loss: 2.676423334088001

Epoch: 6| Step: 13
Training loss: 0.3524606252891073
Validation loss: 2.6203093323814493

Epoch: 309| Step: 0
Training loss: 0.5909006111496925
Validation loss: 2.6587435518445734

Epoch: 6| Step: 1
Training loss: 0.4169712284726067
Validation loss: 2.678746301906856

Epoch: 6| Step: 2
Training loss: 0.2627168384226995
Validation loss: 2.646439885777844

Epoch: 6| Step: 3
Training loss: 0.46740070696129665
Validation loss: 2.6816067953955693

Epoch: 6| Step: 4
Training loss: 0.3941066458868898
Validation loss: 2.6674491111908862

Epoch: 6| Step: 5
Training loss: 0.3408033372209413
Validation loss: 2.6555199012420023

Epoch: 6| Step: 6
Training loss: 0.37199817669072976
Validation loss: 2.592332153699045

Epoch: 6| Step: 7
Training loss: 0.38181197537604533
Validation loss: 2.6955360504175694

Epoch: 6| Step: 8
Training loss: 0.3403425940211231
Validation loss: 2.562304543585

Epoch: 6| Step: 9
Training loss: 0.3724016131328223
Validation loss: 2.6590218685714677

Epoch: 6| Step: 10
Training loss: 0.41657298544917604
Validation loss: 2.6444056005412158

Epoch: 6| Step: 11
Training loss: 0.5059221147786253
Validation loss: 2.603128292330476

Epoch: 6| Step: 12
Training loss: 0.30545256003479243
Validation loss: 2.649691147170204

Epoch: 6| Step: 13
Training loss: 0.3233050259364679
Validation loss: 2.627595647540364

Epoch: 310| Step: 0
Training loss: 0.30602524596909403
Validation loss: 2.710091699876351

Epoch: 6| Step: 1
Training loss: 0.4466868824915169
Validation loss: 2.6611123180475156

Epoch: 6| Step: 2
Training loss: 0.40726622610159396
Validation loss: 2.6386137983480227

Epoch: 6| Step: 3
Training loss: 0.21484983608988864
Validation loss: 2.6520353726957104

Epoch: 6| Step: 4
Training loss: 0.4659192122229136
Validation loss: 2.6404537318439703

Epoch: 6| Step: 5
Training loss: 0.36592766550663114
Validation loss: 2.597927742827134

Epoch: 6| Step: 6
Training loss: 0.4306742349059041
Validation loss: 2.617930323008448

Epoch: 6| Step: 7
Training loss: 0.4154269929914159
Validation loss: 2.5962445928829223

Epoch: 6| Step: 8
Training loss: 0.3121042606856184
Validation loss: 2.664009832046167

Epoch: 6| Step: 9
Training loss: 0.5257031386964014
Validation loss: 2.6568958694020055

Epoch: 6| Step: 10
Training loss: 0.4290019722384132
Validation loss: 2.650619778042187

Epoch: 6| Step: 11
Training loss: 0.3908283657939024
Validation loss: 2.6916633265408634

Epoch: 6| Step: 12
Training loss: 0.45118842156523903
Validation loss: 2.5895946338761973

Epoch: 6| Step: 13
Training loss: 0.49202319839106606
Validation loss: 2.7263409252183086

Epoch: 311| Step: 0
Training loss: 0.4431483905252116
Validation loss: 2.658936581780579

Epoch: 6| Step: 1
Training loss: 0.39019973494219123
Validation loss: 2.6245260189169524

Epoch: 6| Step: 2
Training loss: 0.3200747840638085
Validation loss: 2.6265324857329353

Epoch: 6| Step: 3
Training loss: 0.519280595474028
Validation loss: 2.603362322884832

Epoch: 6| Step: 4
Training loss: 0.3498172568188133
Validation loss: 2.6037489187232556

Epoch: 6| Step: 5
Training loss: 0.5203431174861075
Validation loss: 2.6936255441755645

Epoch: 6| Step: 6
Training loss: 0.4531457337206933
Validation loss: 2.650674900747644

Epoch: 6| Step: 7
Training loss: 0.38809489070430736
Validation loss: 2.662736400443091

Epoch: 6| Step: 8
Training loss: 0.47154654130165763
Validation loss: 2.62465442925952

Epoch: 6| Step: 9
Training loss: 0.4456727762279045
Validation loss: 2.6618458017284095

Epoch: 6| Step: 10
Training loss: 0.6718184868754031
Validation loss: 2.688290383677148

Epoch: 6| Step: 11
Training loss: 0.3570759668039204
Validation loss: 2.667659788175358

Epoch: 6| Step: 12
Training loss: 0.28721335208582305
Validation loss: 2.6485294412353615

Epoch: 6| Step: 13
Training loss: 0.4311833613504365
Validation loss: 2.6626812140414886

Epoch: 312| Step: 0
Training loss: 0.5099050981448162
Validation loss: 2.5819285223720003

Epoch: 6| Step: 1
Training loss: 0.596538021170918
Validation loss: 2.678419133655489

Epoch: 6| Step: 2
Training loss: 0.36748212803312197
Validation loss: 2.693135437336165

Epoch: 6| Step: 3
Training loss: 0.24996237173621305
Validation loss: 2.665747727568523

Epoch: 6| Step: 4
Training loss: 0.3752489852840725
Validation loss: 2.6711401718998604

Epoch: 6| Step: 5
Training loss: 0.3739051731475104
Validation loss: 2.658054980191368

Epoch: 6| Step: 6
Training loss: 0.28818021621715584
Validation loss: 2.698704215517282

Epoch: 6| Step: 7
Training loss: 0.4186074911142583
Validation loss: 2.6182343775768997

Epoch: 6| Step: 8
Training loss: 0.38927265680607553
Validation loss: 2.6923845688006227

Epoch: 6| Step: 9
Training loss: 0.4503155959298886
Validation loss: 2.702392375942706

Epoch: 6| Step: 10
Training loss: 0.38197749409111326
Validation loss: 2.6969272807370275

Epoch: 6| Step: 11
Training loss: 0.554085982933638
Validation loss: 2.5955490858815327

Epoch: 6| Step: 12
Training loss: 0.28789159394182684
Validation loss: 2.6813754297660726

Epoch: 6| Step: 13
Training loss: 0.49148805055712846
Validation loss: 2.5904995110599733

Epoch: 313| Step: 0
Training loss: 0.44815245417900007
Validation loss: 2.5966283920594764

Epoch: 6| Step: 1
Training loss: 0.5529598679250928
Validation loss: 2.6692345345362827

Epoch: 6| Step: 2
Training loss: 0.461059327917058
Validation loss: 2.5953679381437387

Epoch: 6| Step: 3
Training loss: 0.31878549340793805
Validation loss: 2.616750652236981

Epoch: 6| Step: 4
Training loss: 0.32027074495168467
Validation loss: 2.628974327955515

Epoch: 6| Step: 5
Training loss: 0.460422244045371
Validation loss: 2.589407414675338

Epoch: 6| Step: 6
Training loss: 0.3447128487687816
Validation loss: 2.6892498736477104

Epoch: 6| Step: 7
Training loss: 0.3909105782878758
Validation loss: 2.63480014651159

Epoch: 6| Step: 8
Training loss: 0.3358711909123213
Validation loss: 2.6597178765956704

Epoch: 6| Step: 9
Training loss: 0.2630575016006364
Validation loss: 2.6191830594889645

Epoch: 6| Step: 10
Training loss: 0.3595498115957077
Validation loss: 2.6803385812004086

Epoch: 6| Step: 11
Training loss: 0.5833916862002645
Validation loss: 2.6159290077801667

Epoch: 6| Step: 12
Training loss: 0.4637018491316948
Validation loss: 2.641390003093077

Epoch: 6| Step: 13
Training loss: 0.41218577033917103
Validation loss: 2.648728301250588

Epoch: 314| Step: 0
Training loss: 0.4602193248375039
Validation loss: 2.650312646980463

Epoch: 6| Step: 1
Training loss: 0.31641915377454116
Validation loss: 2.662193918320045

Epoch: 6| Step: 2
Training loss: 0.39944342246490055
Validation loss: 2.649182345246027

Epoch: 6| Step: 3
Training loss: 0.4696281631409907
Validation loss: 2.6847801639913054

Epoch: 6| Step: 4
Training loss: 0.3364937856123039
Validation loss: 2.6139367255161

Epoch: 6| Step: 5
Training loss: 0.39692685847252474
Validation loss: 2.625876212339457

Epoch: 6| Step: 6
Training loss: 0.528364479348259
Validation loss: 2.640204191065921

Epoch: 6| Step: 7
Training loss: 0.4991015468315868
Validation loss: 2.6300844270332377

Epoch: 6| Step: 8
Training loss: 0.4490523983981275
Validation loss: 2.6035715771076475

Epoch: 6| Step: 9
Training loss: 0.373588528279532
Validation loss: 2.633818218299433

Epoch: 6| Step: 10
Training loss: 0.37692539330497576
Validation loss: 2.615407841584337

Epoch: 6| Step: 11
Training loss: 0.43470422631669225
Validation loss: 2.588335721108374

Epoch: 6| Step: 12
Training loss: 0.43508729508213456
Validation loss: 2.6204159538214293

Epoch: 6| Step: 13
Training loss: 0.40743638083217487
Validation loss: 2.5814963598044045

Epoch: 315| Step: 0
Training loss: 0.5184465428461046
Validation loss: 2.6385522415746396

Epoch: 6| Step: 1
Training loss: 0.2938324467636065
Validation loss: 2.630696005351981

Epoch: 6| Step: 2
Training loss: 0.27354892095479527
Validation loss: 2.5750216831911574

Epoch: 6| Step: 3
Training loss: 0.6052342360616879
Validation loss: 2.5964782644373745

Epoch: 6| Step: 4
Training loss: 0.45778538359968995
Validation loss: 2.686888366415149

Epoch: 6| Step: 5
Training loss: 0.2974333907539091
Validation loss: 2.6179744922647443

Epoch: 6| Step: 6
Training loss: 0.591300378391139
Validation loss: 2.564505203465908

Epoch: 6| Step: 7
Training loss: 0.37880672052150877
Validation loss: 2.5914924095872367

Epoch: 6| Step: 8
Training loss: 0.23917085273969305
Validation loss: 2.627155236619752

Epoch: 6| Step: 9
Training loss: 0.5556799646659756
Validation loss: 2.6878967288043647

Epoch: 6| Step: 10
Training loss: 0.3723739226326623
Validation loss: 2.6225587907231276

Epoch: 6| Step: 11
Training loss: 0.5788439842025529
Validation loss: 2.613369136714259

Epoch: 6| Step: 12
Training loss: 0.404719992846549
Validation loss: 2.717747850716856

Epoch: 6| Step: 13
Training loss: 0.4699092041996368
Validation loss: 2.6485821019609803

Epoch: 316| Step: 0
Training loss: 0.37075282046144886
Validation loss: 2.610541884170991

Epoch: 6| Step: 1
Training loss: 0.5667400560352225
Validation loss: 2.6064405940291726

Epoch: 6| Step: 2
Training loss: 0.48385093394973117
Validation loss: 2.5915066159577473

Epoch: 6| Step: 3
Training loss: 0.3558838694545469
Validation loss: 2.56505352041266

Epoch: 6| Step: 4
Training loss: 0.44139386049960666
Validation loss: 2.62997714748293

Epoch: 6| Step: 5
Training loss: 0.3311314001634887
Validation loss: 2.6769762030118422

Epoch: 6| Step: 6
Training loss: 0.4106042141349252
Validation loss: 2.625155156712062

Epoch: 6| Step: 7
Training loss: 0.48205215557151787
Validation loss: 2.6477422711327976

Epoch: 6| Step: 8
Training loss: 0.2853608768935148
Validation loss: 2.5456563456230668

Epoch: 6| Step: 9
Training loss: 0.25621049390365647
Validation loss: 2.6211113055077604

Epoch: 6| Step: 10
Training loss: 0.3849691056266063
Validation loss: 2.663528523109976

Epoch: 6| Step: 11
Training loss: 0.39617584701951125
Validation loss: 2.6211084553987787

Epoch: 6| Step: 12
Training loss: 0.5128317515161116
Validation loss: 2.656241749769376

Epoch: 6| Step: 13
Training loss: 0.4704519210942432
Validation loss: 2.699470607639242

Epoch: 317| Step: 0
Training loss: 0.41472150434657723
Validation loss: 2.693807046969189

Epoch: 6| Step: 1
Training loss: 0.5632906496319225
Validation loss: 2.6345171744104827

Epoch: 6| Step: 2
Training loss: 0.34178346880098137
Validation loss: 2.6577774891761035

Epoch: 6| Step: 3
Training loss: 0.37461901225719807
Validation loss: 2.6293468512341716

Epoch: 6| Step: 4
Training loss: 0.5075077022475385
Validation loss: 2.622863687389752

Epoch: 6| Step: 5
Training loss: 0.4338699354746042
Validation loss: 2.6402427201003484

Epoch: 6| Step: 6
Training loss: 0.2851432771213969
Validation loss: 2.608991621410718

Epoch: 6| Step: 7
Training loss: 0.3455432802479499
Validation loss: 2.6440815620740645

Epoch: 6| Step: 8
Training loss: 0.4806272198857705
Validation loss: 2.678437841505362

Epoch: 6| Step: 9
Training loss: 0.2271693176617807
Validation loss: 2.6711758745542187

Epoch: 6| Step: 10
Training loss: 0.3619344624237247
Validation loss: 2.5917965223728485

Epoch: 6| Step: 11
Training loss: 0.3961437246484009
Validation loss: 2.6473095647842735

Epoch: 6| Step: 12
Training loss: 0.35935600894008496
Validation loss: 2.66423219828293

Epoch: 6| Step: 13
Training loss: 0.3383558741626005
Validation loss: 2.7506165102384377

Epoch: 318| Step: 0
Training loss: 0.49220790517985313
Validation loss: 2.619795286708224

Epoch: 6| Step: 1
Training loss: 0.4189386256113343
Validation loss: 2.688012599113244

Epoch: 6| Step: 2
Training loss: 0.4792005658252254
Validation loss: 2.7603240135525984

Epoch: 6| Step: 3
Training loss: 0.545012162361575
Validation loss: 2.6528010847211783

Epoch: 6| Step: 4
Training loss: 0.5649654083296608
Validation loss: 2.6361301245459825

Epoch: 6| Step: 5
Training loss: 0.3556293292527923
Validation loss: 2.6138205055032797

Epoch: 6| Step: 6
Training loss: 0.4119260841377125
Validation loss: 2.651635983343726

Epoch: 6| Step: 7
Training loss: 0.444092266634063
Validation loss: 2.6443440508641105

Epoch: 6| Step: 8
Training loss: 0.3019080914353461
Validation loss: 2.6281134594192554

Epoch: 6| Step: 9
Training loss: 0.33730803964580425
Validation loss: 2.6641874312028238

Epoch: 6| Step: 10
Training loss: 0.3982206764417073
Validation loss: 2.67204306447566

Epoch: 6| Step: 11
Training loss: 0.3946792211744098
Validation loss: 2.6688193384434618

Epoch: 6| Step: 12
Training loss: 0.35732209527405645
Validation loss: 2.6467123048420382

Epoch: 6| Step: 13
Training loss: 0.37613044661168954
Validation loss: 2.6749634766981982

Epoch: 319| Step: 0
Training loss: 0.3624817037897936
Validation loss: 2.685597729750503

Epoch: 6| Step: 1
Training loss: 0.37994949030228903
Validation loss: 2.5830560402072575

Epoch: 6| Step: 2
Training loss: 0.41412783053369506
Validation loss: 2.6563342660739617

Epoch: 6| Step: 3
Training loss: 0.48748260797141046
Validation loss: 2.6560115183567095

Epoch: 6| Step: 4
Training loss: 0.4314210082738263
Validation loss: 2.7029924599084514

Epoch: 6| Step: 5
Training loss: 0.3652715001132903
Validation loss: 2.67605123155626

Epoch: 6| Step: 6
Training loss: 0.3995697165878287
Validation loss: 2.625242085874213

Epoch: 6| Step: 7
Training loss: 0.30321915481683465
Validation loss: 2.682849793868294

Epoch: 6| Step: 8
Training loss: 0.3894210572656786
Validation loss: 2.6334649851841814

Epoch: 6| Step: 9
Training loss: 0.36853364966287394
Validation loss: 2.6342599514070972

Epoch: 6| Step: 10
Training loss: 0.4189354244034501
Validation loss: 2.632209293680291

Epoch: 6| Step: 11
Training loss: 0.3548272181178533
Validation loss: 2.6385842889254074

Epoch: 6| Step: 12
Training loss: 0.3025075986002403
Validation loss: 2.6694225857404614

Epoch: 6| Step: 13
Training loss: 0.46337575479285953
Validation loss: 2.666543612521869

Epoch: 320| Step: 0
Training loss: 0.39368654224153893
Validation loss: 2.7171227346331492

Epoch: 6| Step: 1
Training loss: 0.20241279639111245
Validation loss: 2.640314644476941

Epoch: 6| Step: 2
Training loss: 0.3123799808817962
Validation loss: 2.6636526737844104

Epoch: 6| Step: 3
Training loss: 0.2955365627747507
Validation loss: 2.6842936973116642

Epoch: 6| Step: 4
Training loss: 0.5320644306697655
Validation loss: 2.643082673221079

Epoch: 6| Step: 5
Training loss: 0.38016848377090084
Validation loss: 2.6090859350115365

Epoch: 6| Step: 6
Training loss: 0.4352527531948141
Validation loss: 2.615847693488241

Epoch: 6| Step: 7
Training loss: 0.39086283119346465
Validation loss: 2.674577138580297

Epoch: 6| Step: 8
Training loss: 0.3933722402065503
Validation loss: 2.6692079614197466

Epoch: 6| Step: 9
Training loss: 0.5053422560273148
Validation loss: 2.6570352926861918

Epoch: 6| Step: 10
Training loss: 0.4654202932929683
Validation loss: 2.5849738423950437

Epoch: 6| Step: 11
Training loss: 0.2855650310249733
Validation loss: 2.7298338174136143

Epoch: 6| Step: 12
Training loss: 0.48225285584715055
Validation loss: 2.6076129133745525

Epoch: 6| Step: 13
Training loss: 0.3614827624190823
Validation loss: 2.6194635315927033

Epoch: 321| Step: 0
Training loss: 0.3338726258295239
Validation loss: 2.65076451579706

Epoch: 6| Step: 1
Training loss: 0.40996627040845646
Validation loss: 2.5770369266247113

Epoch: 6| Step: 2
Training loss: 0.4022260512257698
Validation loss: 2.624507328000203

Epoch: 6| Step: 3
Training loss: 0.39250918869634066
Validation loss: 2.652354147230097

Epoch: 6| Step: 4
Training loss: 0.24359954384207494
Validation loss: 2.645338264966253

Epoch: 6| Step: 5
Training loss: 0.4438179602094379
Validation loss: 2.5962141809761357

Epoch: 6| Step: 6
Training loss: 0.43198118971783345
Validation loss: 2.6382224761226984

Epoch: 6| Step: 7
Training loss: 0.28841368571756765
Validation loss: 2.62518606586113

Epoch: 6| Step: 8
Training loss: 0.3993380597840008
Validation loss: 2.589118668064551

Epoch: 6| Step: 9
Training loss: 0.3088370462639767
Validation loss: 2.65094549058331

Epoch: 6| Step: 10
Training loss: 0.5123791982586249
Validation loss: 2.6967147349288614

Epoch: 6| Step: 11
Training loss: 0.4389623656749262
Validation loss: 2.6532217828106885

Epoch: 6| Step: 12
Training loss: 0.39329463422186267
Validation loss: 2.57532329721081

Epoch: 6| Step: 13
Training loss: 0.4343495011564025
Validation loss: 2.6234803115050696

Epoch: 322| Step: 0
Training loss: 0.41577182485283143
Validation loss: 2.6574862127942276

Epoch: 6| Step: 1
Training loss: 0.3162739559569151
Validation loss: 2.645433145330451

Epoch: 6| Step: 2
Training loss: 0.5245443285327767
Validation loss: 2.6671667722802797

Epoch: 6| Step: 3
Training loss: 0.32018681130380783
Validation loss: 2.6035891897154007

Epoch: 6| Step: 4
Training loss: 0.22358466550444608
Validation loss: 2.620774789306911

Epoch: 6| Step: 5
Training loss: 0.36824672185911006
Validation loss: 2.6771616695436338

Epoch: 6| Step: 6
Training loss: 0.35640517753496576
Validation loss: 2.6252716317492415

Epoch: 6| Step: 7
Training loss: 0.49514036105547754
Validation loss: 2.6419726662849814

Epoch: 6| Step: 8
Training loss: 0.44466295889009677
Validation loss: 2.6734975903563623

Epoch: 6| Step: 9
Training loss: 0.5977286251351478
Validation loss: 2.6465480820236102

Epoch: 6| Step: 10
Training loss: 0.37303640940101285
Validation loss: 2.6463505146852544

Epoch: 6| Step: 11
Training loss: 0.3796107242024043
Validation loss: 2.562075246327801

Epoch: 6| Step: 12
Training loss: 0.4561242616176509
Validation loss: 2.6213596548327054

Epoch: 6| Step: 13
Training loss: 0.5295981081360479
Validation loss: 2.6181873821816946

Epoch: 323| Step: 0
Training loss: 0.6120738882795055
Validation loss: 2.6287104858243864

Epoch: 6| Step: 1
Training loss: 0.3134747680422561
Validation loss: 2.6831025586099435

Epoch: 6| Step: 2
Training loss: 0.49976143510072013
Validation loss: 2.5986564068426166

Epoch: 6| Step: 3
Training loss: 0.5323449519361896
Validation loss: 2.682412566389245

Epoch: 6| Step: 4
Training loss: 0.4255858856803369
Validation loss: 2.612839110662149

Epoch: 6| Step: 5
Training loss: 0.42371125961267553
Validation loss: 2.602053239911541

Epoch: 6| Step: 6
Training loss: 0.33472218359599193
Validation loss: 2.596284118646106

Epoch: 6| Step: 7
Training loss: 0.33801805155137954
Validation loss: 2.582050140665716

Epoch: 6| Step: 8
Training loss: 0.47626454779164995
Validation loss: 2.619766452635108

Epoch: 6| Step: 9
Training loss: 0.36016723136130896
Validation loss: 2.640871025226545

Epoch: 6| Step: 10
Training loss: 0.36510701942508395
Validation loss: 2.6427685165519215

Epoch: 6| Step: 11
Training loss: 0.3102257946079544
Validation loss: 2.663116510857116

Epoch: 6| Step: 12
Training loss: 0.49519245245278304
Validation loss: 2.6167885319664617

Epoch: 6| Step: 13
Training loss: 0.47679113938095957
Validation loss: 2.61159635548582

Epoch: 324| Step: 0
Training loss: 0.37428019901104825
Validation loss: 2.5979397726573725

Epoch: 6| Step: 1
Training loss: 0.3770929581202403
Validation loss: 2.6218322229059496

Epoch: 6| Step: 2
Training loss: 0.4757682247289408
Validation loss: 2.550963756970258

Epoch: 6| Step: 3
Training loss: 0.418381852259396
Validation loss: 2.62405207336421

Epoch: 6| Step: 4
Training loss: 0.4843635250085925
Validation loss: 2.5927675676967845

Epoch: 6| Step: 5
Training loss: 0.2948691592565839
Validation loss: 2.599158106727933

Epoch: 6| Step: 6
Training loss: 0.34244966566947005
Validation loss: 2.686543849034146

Epoch: 6| Step: 7
Training loss: 0.4965403341455941
Validation loss: 2.6739914451563087

Epoch: 6| Step: 8
Training loss: 0.4212614472189384
Validation loss: 2.6584644436766594

Epoch: 6| Step: 9
Training loss: 0.40041206116397887
Validation loss: 2.6199877281969295

Epoch: 6| Step: 10
Training loss: 0.4886230798109281
Validation loss: 2.6304715216871024

Epoch: 6| Step: 11
Training loss: 0.22445912518764943
Validation loss: 2.6295494437740086

Epoch: 6| Step: 12
Training loss: 0.4208237477743676
Validation loss: 2.653270171993576

Epoch: 6| Step: 13
Training loss: 0.507002139908979
Validation loss: 2.6215675558703158

Epoch: 325| Step: 0
Training loss: 0.29276522878752476
Validation loss: 2.6657612475464663

Epoch: 6| Step: 1
Training loss: 0.38041651482734
Validation loss: 2.6022547353627576

Epoch: 6| Step: 2
Training loss: 0.6294375242904281
Validation loss: 2.64543791441907

Epoch: 6| Step: 3
Training loss: 0.48142228448667207
Validation loss: 2.6308428360972114

Epoch: 6| Step: 4
Training loss: 0.3932128064960658
Validation loss: 2.6717596047748353

Epoch: 6| Step: 5
Training loss: 0.32808698706465256
Validation loss: 2.655719404894034

Epoch: 6| Step: 6
Training loss: 0.4197464687478331
Validation loss: 2.698468940991994

Epoch: 6| Step: 7
Training loss: 0.4721190812878912
Validation loss: 2.610414339893113

Epoch: 6| Step: 8
Training loss: 0.3347843026967677
Validation loss: 2.5947643349544323

Epoch: 6| Step: 9
Training loss: 0.5141159284938182
Validation loss: 2.6428691800529474

Epoch: 6| Step: 10
Training loss: 0.5038949240661073
Validation loss: 2.621430164622269

Epoch: 6| Step: 11
Training loss: 0.2824690941556245
Validation loss: 2.667445610442886

Epoch: 6| Step: 12
Training loss: 0.3200825703344576
Validation loss: 2.6473756985396197

Epoch: 6| Step: 13
Training loss: 0.4421789107819592
Validation loss: 2.5822972763224232

Epoch: 326| Step: 0
Training loss: 0.39543859559014843
Validation loss: 2.6579591376122758

Epoch: 6| Step: 1
Training loss: 0.3127124421897878
Validation loss: 2.674073324392223

Epoch: 6| Step: 2
Training loss: 0.2860164731306699
Validation loss: 2.65249670802088

Epoch: 6| Step: 3
Training loss: 0.3933425596671801
Validation loss: 2.62995367548459

Epoch: 6| Step: 4
Training loss: 0.4066888016626712
Validation loss: 2.6090193942075235

Epoch: 6| Step: 5
Training loss: 0.5038350372857697
Validation loss: 2.6793380079362303

Epoch: 6| Step: 6
Training loss: 0.5547180167386692
Validation loss: 2.6273234696011514

Epoch: 6| Step: 7
Training loss: 0.3049739078398667
Validation loss: 2.606777032367806

Epoch: 6| Step: 8
Training loss: 0.276132463721291
Validation loss: 2.661349066017309

Epoch: 6| Step: 9
Training loss: 0.6034798719562429
Validation loss: 2.6741037572694784

Epoch: 6| Step: 10
Training loss: 0.2734105233100366
Validation loss: 2.6798958507389616

Epoch: 6| Step: 11
Training loss: 0.32073409550096604
Validation loss: 2.6397984130795646

Epoch: 6| Step: 12
Training loss: 0.4389317110688308
Validation loss: 2.622014512664724

Epoch: 6| Step: 13
Training loss: 0.3988144157661369
Validation loss: 2.621846545265449

Epoch: 327| Step: 0
Training loss: 0.4784465506387153
Validation loss: 2.7084552786345433

Epoch: 6| Step: 1
Training loss: 0.37742705521436803
Validation loss: 2.617820124295344

Epoch: 6| Step: 2
Training loss: 0.4381839651025874
Validation loss: 2.5873805818628224

Epoch: 6| Step: 3
Training loss: 0.33556878015073605
Validation loss: 2.645156290632418

Epoch: 6| Step: 4
Training loss: 0.366988229451094
Validation loss: 2.6288011368345656

Epoch: 6| Step: 5
Training loss: 0.4197570477292158
Validation loss: 2.67264473667395

Epoch: 6| Step: 6
Training loss: 0.2852487022293485
Validation loss: 2.645178193109435

Epoch: 6| Step: 7
Training loss: 0.36003009547825
Validation loss: 2.6599308465510982

Epoch: 6| Step: 8
Training loss: 0.30067318052402836
Validation loss: 2.637268928301035

Epoch: 6| Step: 9
Training loss: 0.41520500904646757
Validation loss: 2.6109284670734585

Epoch: 6| Step: 10
Training loss: 0.22499212741324479
Validation loss: 2.6920906898182717

Epoch: 6| Step: 11
Training loss: 0.42030363250794583
Validation loss: 2.613776228043545

Epoch: 6| Step: 12
Training loss: 0.4268351120415839
Validation loss: 2.6039647189356363

Epoch: 6| Step: 13
Training loss: 0.3549474939617608
Validation loss: 2.6264524679985124

Epoch: 328| Step: 0
Training loss: 0.36449349068427195
Validation loss: 2.6619269200522337

Epoch: 6| Step: 1
Training loss: 0.33996802283075245
Validation loss: 2.688968715476754

Epoch: 6| Step: 2
Training loss: 0.3618054304633206
Validation loss: 2.602617700854712

Epoch: 6| Step: 3
Training loss: 0.43074329019413843
Validation loss: 2.5928754902575464

Epoch: 6| Step: 4
Training loss: 0.26454954657507657
Validation loss: 2.6140013929887256

Epoch: 6| Step: 5
Training loss: 0.4290664693227871
Validation loss: 2.6017636058162408

Epoch: 6| Step: 6
Training loss: 0.44539067770049795
Validation loss: 2.6357223926473172

Epoch: 6| Step: 7
Training loss: 0.34532890971276586
Validation loss: 2.6459111229782595

Epoch: 6| Step: 8
Training loss: 0.16453960844872814
Validation loss: 2.751389455904884

Epoch: 6| Step: 9
Training loss: 0.49965986961520015
Validation loss: 2.678326156225204

Epoch: 6| Step: 10
Training loss: 0.33276647061397563
Validation loss: 2.628272438827527

Epoch: 6| Step: 11
Training loss: 0.437188241779388
Validation loss: 2.6686658865353907

Epoch: 6| Step: 12
Training loss: 0.41455042179662716
Validation loss: 2.6176218156423134

Epoch: 6| Step: 13
Training loss: 0.2834614989184171
Validation loss: 2.6616455629388365

Epoch: 329| Step: 0
Training loss: 0.38877788612339925
Validation loss: 2.6318220318655134

Epoch: 6| Step: 1
Training loss: 0.3499016632150116
Validation loss: 2.706472980572293

Epoch: 6| Step: 2
Training loss: 0.4942410785359967
Validation loss: 2.6442799300845725

Epoch: 6| Step: 3
Training loss: 0.43756395962355504
Validation loss: 2.6519859495859994

Epoch: 6| Step: 4
Training loss: 0.33439521728430993
Validation loss: 2.6602210785243328

Epoch: 6| Step: 5
Training loss: 0.2833615879154381
Validation loss: 2.6884963975593372

Epoch: 6| Step: 6
Training loss: 0.3041054104933329
Validation loss: 2.6555903644178

Epoch: 6| Step: 7
Training loss: 0.2977253630892565
Validation loss: 2.6091494434202067

Epoch: 6| Step: 8
Training loss: 0.40265069752699906
Validation loss: 2.6562001840744602

Epoch: 6| Step: 9
Training loss: 0.2237116495623679
Validation loss: 2.5977476940456232

Epoch: 6| Step: 10
Training loss: 0.5383044455171605
Validation loss: 2.624987117796275

Epoch: 6| Step: 11
Training loss: 0.3692390068589864
Validation loss: 2.6650146542898314

Epoch: 6| Step: 12
Training loss: 0.29128552408462066
Validation loss: 2.6825793929852075

Epoch: 6| Step: 13
Training loss: 0.5693660093449796
Validation loss: 2.683345607370141

Epoch: 330| Step: 0
Training loss: 0.4358509182831811
Validation loss: 2.6873047188478525

Epoch: 6| Step: 1
Training loss: 0.39371110633220474
Validation loss: 2.5903290245525277

Epoch: 6| Step: 2
Training loss: 0.3375831925325862
Validation loss: 2.62066408853138

Epoch: 6| Step: 3
Training loss: 0.4721177241073033
Validation loss: 2.6740608569172064

Epoch: 6| Step: 4
Training loss: 0.3404871998725279
Validation loss: 2.7394860157283327

Epoch: 6| Step: 5
Training loss: 0.3420864840121189
Validation loss: 2.6588037070711694

Epoch: 6| Step: 6
Training loss: 0.46566883559269145
Validation loss: 2.6744663841192193

Epoch: 6| Step: 7
Training loss: 0.3217736621698175
Validation loss: 2.7037127669814898

Epoch: 6| Step: 8
Training loss: 0.3672289723452253
Validation loss: 2.624493065582938

Epoch: 6| Step: 9
Training loss: 0.32650055001111755
Validation loss: 2.6745711585953997

Epoch: 6| Step: 10
Training loss: 0.38864706909152263
Validation loss: 2.634626237346066

Epoch: 6| Step: 11
Training loss: 0.26290557558079064
Validation loss: 2.6892040232437875

Epoch: 6| Step: 12
Training loss: 0.4574025105222335
Validation loss: 2.6788523181593895

Epoch: 6| Step: 13
Training loss: 0.33905138621596076
Validation loss: 2.600446306950176

Epoch: 331| Step: 0
Training loss: 0.5058637346352316
Validation loss: 2.6312777973074972

Epoch: 6| Step: 1
Training loss: 0.47207708578810054
Validation loss: 2.6585731519748808

Epoch: 6| Step: 2
Training loss: 0.44798314540101286
Validation loss: 2.6900128733434454

Epoch: 6| Step: 3
Training loss: 0.4369791199870155
Validation loss: 2.659618037556828

Epoch: 6| Step: 4
Training loss: 0.43821722232737575
Validation loss: 2.6254776716830843

Epoch: 6| Step: 5
Training loss: 0.365787597105809
Validation loss: 2.6465654086273673

Epoch: 6| Step: 6
Training loss: 0.3279554292209945
Validation loss: 2.6705989802276098

Epoch: 6| Step: 7
Training loss: 0.27557010077940786
Validation loss: 2.627424611414432

Epoch: 6| Step: 8
Training loss: 0.5219637492662643
Validation loss: 2.6633938335220035

Epoch: 6| Step: 9
Training loss: 0.3309946146336769
Validation loss: 2.675232619869574

Epoch: 6| Step: 10
Training loss: 0.46621067157381396
Validation loss: 2.6488860584099188

Epoch: 6| Step: 11
Training loss: 0.3635298585841321
Validation loss: 2.618313113651922

Epoch: 6| Step: 12
Training loss: 0.5370066596564808
Validation loss: 2.646663360361425

Epoch: 6| Step: 13
Training loss: 0.35513587708618144
Validation loss: 2.68710827744943

Epoch: 332| Step: 0
Training loss: 0.413404770043605
Validation loss: 2.6254062640959708

Epoch: 6| Step: 1
Training loss: 0.45882807566160055
Validation loss: 2.64193805800719

Epoch: 6| Step: 2
Training loss: 0.2839031381389274
Validation loss: 2.6393970440826164

Epoch: 6| Step: 3
Training loss: 0.31546371087503455
Validation loss: 2.633841640771268

Epoch: 6| Step: 4
Training loss: 0.44797832227311934
Validation loss: 2.6214081546755077

Epoch: 6| Step: 5
Training loss: 0.5897262152985188
Validation loss: 2.679613273638011

Epoch: 6| Step: 6
Training loss: 0.3394328735772387
Validation loss: 2.6222688454139833

Epoch: 6| Step: 7
Training loss: 0.4868743464082339
Validation loss: 2.6329159438038725

Epoch: 6| Step: 8
Training loss: 0.21831996405111787
Validation loss: 2.570325006920282

Epoch: 6| Step: 9
Training loss: 0.23241846899534205
Validation loss: 2.6195521968857705

Epoch: 6| Step: 10
Training loss: 0.4359177007246627
Validation loss: 2.7324439505284532

Epoch: 6| Step: 11
Training loss: 0.5080095935689114
Validation loss: 2.7029486361614743

Epoch: 6| Step: 12
Training loss: 0.4550137781320735
Validation loss: 2.657836298281906

Epoch: 6| Step: 13
Training loss: 0.4685662545242898
Validation loss: 2.631541925638354

Epoch: 333| Step: 0
Training loss: 0.3222624345101301
Validation loss: 2.6127098838785936

Epoch: 6| Step: 1
Training loss: 0.28890110355825316
Validation loss: 2.597357604181024

Epoch: 6| Step: 2
Training loss: 0.4016894974624023
Validation loss: 2.6273490597930924

Epoch: 6| Step: 3
Training loss: 0.26243101530519053
Validation loss: 2.6457848632057317

Epoch: 6| Step: 4
Training loss: 0.47783813784509804
Validation loss: 2.6268184962985033

Epoch: 6| Step: 5
Training loss: 0.36476227138445844
Validation loss: 2.6576942855616403

Epoch: 6| Step: 6
Training loss: 0.3971307681285851
Validation loss: 2.6862523931223707

Epoch: 6| Step: 7
Training loss: 0.3595648139893742
Validation loss: 2.6716980457267776

Epoch: 6| Step: 8
Training loss: 0.4736845479808548
Validation loss: 2.6675323978448016

Epoch: 6| Step: 9
Training loss: 0.3820505929118302
Validation loss: 2.5983285287352214

Epoch: 6| Step: 10
Training loss: 0.4639962910131906
Validation loss: 2.646119820611178

Epoch: 6| Step: 11
Training loss: 0.30957861567291683
Validation loss: 2.682019434079756

Epoch: 6| Step: 12
Training loss: 0.4725639000831411
Validation loss: 2.6794923019863317

Epoch: 6| Step: 13
Training loss: 0.5268860420074566
Validation loss: 2.5901694804970514

Epoch: 334| Step: 0
Training loss: 0.32657538940691483
Validation loss: 2.6908021940160474

Epoch: 6| Step: 1
Training loss: 0.4014221673514261
Validation loss: 2.6416967951824457

Epoch: 6| Step: 2
Training loss: 0.2755970823547384
Validation loss: 2.645973529755836

Epoch: 6| Step: 3
Training loss: 0.4593429139018908
Validation loss: 2.632509615990156

Epoch: 6| Step: 4
Training loss: 0.32673872158283784
Validation loss: 2.6528933240837063

Epoch: 6| Step: 5
Training loss: 0.3688413830042635
Validation loss: 2.6544247358569932

Epoch: 6| Step: 6
Training loss: 0.39539734981465874
Validation loss: 2.71295439844536

Epoch: 6| Step: 7
Training loss: 0.4898636924906493
Validation loss: 2.6289544065692865

Epoch: 6| Step: 8
Training loss: 0.5414310334052954
Validation loss: 2.6210093288025167

Epoch: 6| Step: 9
Training loss: 0.4199864182660421
Validation loss: 2.59557381052608

Epoch: 6| Step: 10
Training loss: 0.2727149135144467
Validation loss: 2.6879938839869326

Epoch: 6| Step: 11
Training loss: 0.5371568970897989
Validation loss: 2.7207154079505953

Epoch: 6| Step: 12
Training loss: 0.5223289536945956
Validation loss: 2.6477385342214967

Epoch: 6| Step: 13
Training loss: 0.5398332089666114
Validation loss: 2.687155960299541

Epoch: 335| Step: 0
Training loss: 0.36716067439358446
Validation loss: 2.660393770119865

Epoch: 6| Step: 1
Training loss: 0.4059003645875303
Validation loss: 2.7152450374722648

Epoch: 6| Step: 2
Training loss: 0.37443549662464626
Validation loss: 2.6678857748552827

Epoch: 6| Step: 3
Training loss: 0.34011640244342195
Validation loss: 2.676367880564955

Epoch: 6| Step: 4
Training loss: 0.44084640040378015
Validation loss: 2.6187359987793535

Epoch: 6| Step: 5
Training loss: 0.3845863505555422
Validation loss: 2.6478178936783956

Epoch: 6| Step: 6
Training loss: 0.4042672409032989
Validation loss: 2.6365278989691623

Epoch: 6| Step: 7
Training loss: 0.35751652115880866
Validation loss: 2.6376782590580095

Epoch: 6| Step: 8
Training loss: 0.39211954310751385
Validation loss: 2.6628126865221704

Epoch: 6| Step: 9
Training loss: 0.3160685397101551
Validation loss: 2.6177721575662454

Epoch: 6| Step: 10
Training loss: 0.4350473250482779
Validation loss: 2.671855502587281

Epoch: 6| Step: 11
Training loss: 0.3010605097794593
Validation loss: 2.6476616787435048

Epoch: 6| Step: 12
Training loss: 0.3889891513179556
Validation loss: 2.5962393584482526

Epoch: 6| Step: 13
Training loss: 0.36944037080054964
Validation loss: 2.6231221490977346

Epoch: 336| Step: 0
Training loss: 0.37229259989656543
Validation loss: 2.653041382674992

Epoch: 6| Step: 1
Training loss: 0.2828152861905768
Validation loss: 2.5540959784562007

Epoch: 6| Step: 2
Training loss: 0.3765621232786708
Validation loss: 2.6085702717407986

Epoch: 6| Step: 3
Training loss: 0.46842255281569645
Validation loss: 2.5752881635761113

Epoch: 6| Step: 4
Training loss: 0.4392077290642671
Validation loss: 2.5802231545010432

Epoch: 6| Step: 5
Training loss: 0.3023699997933589
Validation loss: 2.5997428296133323

Epoch: 6| Step: 6
Training loss: 0.3128137682223073
Validation loss: 2.5649392528417176

Epoch: 6| Step: 7
Training loss: 0.36503665080327513
Validation loss: 2.638977499918576

Epoch: 6| Step: 8
Training loss: 0.48728926028369235
Validation loss: 2.6403282645870805

Epoch: 6| Step: 9
Training loss: 0.4969424399906534
Validation loss: 2.685572938734792

Epoch: 6| Step: 10
Training loss: 0.5153603886270879
Validation loss: 2.6610843871023993

Epoch: 6| Step: 11
Training loss: 0.38334867336152606
Validation loss: 2.5679707628409933

Epoch: 6| Step: 12
Training loss: 0.34786218266068786
Validation loss: 2.621831798538549

Epoch: 6| Step: 13
Training loss: 0.38254954590636475
Validation loss: 2.6646837421872553

Epoch: 337| Step: 0
Training loss: 0.4279769140149367
Validation loss: 2.6545468423906264

Epoch: 6| Step: 1
Training loss: 0.6480815324029486
Validation loss: 2.687601161501846

Epoch: 6| Step: 2
Training loss: 0.26121200068425593
Validation loss: 2.715909387398161

Epoch: 6| Step: 3
Training loss: 0.2983100988665864
Validation loss: 2.650524970903626

Epoch: 6| Step: 4
Training loss: 0.37689979452682726
Validation loss: 2.626075494032119

Epoch: 6| Step: 5
Training loss: 0.46228971791497736
Validation loss: 2.5890446998599748

Epoch: 6| Step: 6
Training loss: 0.47749668549590624
Validation loss: 2.6698547518556635

Epoch: 6| Step: 7
Training loss: 0.4566923335733062
Validation loss: 2.586525257692496

Epoch: 6| Step: 8
Training loss: 0.45653368282564233
Validation loss: 2.6253290121579904

Epoch: 6| Step: 9
Training loss: 0.2574207334825968
Validation loss: 2.6554277306703358

Epoch: 6| Step: 10
Training loss: 0.43653383178624705
Validation loss: 2.643748142551404

Epoch: 6| Step: 11
Training loss: 0.4178137447250188
Validation loss: 2.6359744907716465

Epoch: 6| Step: 12
Training loss: 0.348158056309425
Validation loss: 2.676414025102936

Epoch: 6| Step: 13
Training loss: 0.4253550154648903
Validation loss: 2.6306639147721693

Epoch: 338| Step: 0
Training loss: 0.3500277610395818
Validation loss: 2.6335528471350553

Epoch: 6| Step: 1
Training loss: 0.3738057870279646
Validation loss: 2.6821125131177035

Epoch: 6| Step: 2
Training loss: 0.28336029952881553
Validation loss: 2.627708853887885

Epoch: 6| Step: 3
Training loss: 0.2817462807615484
Validation loss: 2.601959916041851

Epoch: 6| Step: 4
Training loss: 0.3922653090660526
Validation loss: 2.6373350275643013

Epoch: 6| Step: 5
Training loss: 0.35843078301013576
Validation loss: 2.623444459598073

Epoch: 6| Step: 6
Training loss: 0.37927293240284904
Validation loss: 2.6249935740437644

Epoch: 6| Step: 7
Training loss: 0.3296047631171876
Validation loss: 2.656825478241139

Epoch: 6| Step: 8
Training loss: 0.3950766014113495
Validation loss: 2.6132937337427986

Epoch: 6| Step: 9
Training loss: 0.48317801333948524
Validation loss: 2.6344804319595094

Epoch: 6| Step: 10
Training loss: 0.38225768230145757
Validation loss: 2.6104689263797956

Epoch: 6| Step: 11
Training loss: 0.45142070299503245
Validation loss: 2.6490586564215883

Epoch: 6| Step: 12
Training loss: 0.5165332539905125
Validation loss: 2.590102162230285

Epoch: 6| Step: 13
Training loss: 0.4028885310460552
Validation loss: 2.6100960837323015

Epoch: 339| Step: 0
Training loss: 0.4236152395540577
Validation loss: 2.5793637623044146

Epoch: 6| Step: 1
Training loss: 0.3694178836798734
Validation loss: 2.623438113138484

Epoch: 6| Step: 2
Training loss: 0.4352904107814601
Validation loss: 2.6595811488290844

Epoch: 6| Step: 3
Training loss: 0.40099179795907164
Validation loss: 2.6056300870632683

Epoch: 6| Step: 4
Training loss: 0.4918190318624131
Validation loss: 2.6854241508417083

Epoch: 6| Step: 5
Training loss: 0.5215518921995612
Validation loss: 2.631973842388448

Epoch: 6| Step: 6
Training loss: 0.26267707506142407
Validation loss: 2.6114619393635095

Epoch: 6| Step: 7
Training loss: 0.5407069733935668
Validation loss: 2.650930845770983

Epoch: 6| Step: 8
Training loss: 0.4454628539991413
Validation loss: 2.649680776982327

Epoch: 6| Step: 9
Training loss: 0.46817890982385285
Validation loss: 2.656264585567147

Epoch: 6| Step: 10
Training loss: 0.6019655586557711
Validation loss: 2.615250420040399

Epoch: 6| Step: 11
Training loss: 0.8071709983636461
Validation loss: 2.625525527906518

Epoch: 6| Step: 12
Training loss: 0.434203741219848
Validation loss: 2.629523391423258

Epoch: 6| Step: 13
Training loss: 0.42664120824802265
Validation loss: 2.6383718324247254

Epoch: 340| Step: 0
Training loss: 0.5334135485715257
Validation loss: 2.6350811127755773

Epoch: 6| Step: 1
Training loss: 0.5509946152827236
Validation loss: 2.6646957912579277

Epoch: 6| Step: 2
Training loss: 0.3987888021633611
Validation loss: 2.6313927177572176

Epoch: 6| Step: 3
Training loss: 0.48859993262507145
Validation loss: 2.62587083268172

Epoch: 6| Step: 4
Training loss: 0.42548745194433757
Validation loss: 2.6805247045354683

Epoch: 6| Step: 5
Training loss: 0.34962664726682124
Validation loss: 2.6705172027822317

Epoch: 6| Step: 6
Training loss: 0.45136841295538965
Validation loss: 2.649709585458971

Epoch: 6| Step: 7
Training loss: 0.3487666965575997
Validation loss: 2.6608595326877387

Epoch: 6| Step: 8
Training loss: 0.2823800062535367
Validation loss: 2.6706139040436057

Epoch: 6| Step: 9
Training loss: 0.35361879645226113
Validation loss: 2.6598987874874345

Epoch: 6| Step: 10
Training loss: 0.48825994826581454
Validation loss: 2.6606861843284406

Epoch: 6| Step: 11
Training loss: 0.34292733848315626
Validation loss: 2.612865983311976

Epoch: 6| Step: 12
Training loss: 0.4015695103727317
Validation loss: 2.6198495715638894

Epoch: 6| Step: 13
Training loss: 0.3187665617137022
Validation loss: 2.676434246493385

Epoch: 341| Step: 0
Training loss: 0.48029595656189095
Validation loss: 2.6164710663218025

Epoch: 6| Step: 1
Training loss: 0.3705952558756261
Validation loss: 2.6436282954298203

Epoch: 6| Step: 2
Training loss: 0.48735565958639787
Validation loss: 2.664856390623459

Epoch: 6| Step: 3
Training loss: 0.29720661815838467
Validation loss: 2.6787311267173086

Epoch: 6| Step: 4
Training loss: 0.4029407886153771
Validation loss: 2.6381521741450644

Epoch: 6| Step: 5
Training loss: 0.4898679359220672
Validation loss: 2.653990783333316

Epoch: 6| Step: 6
Training loss: 0.5160361875700835
Validation loss: 2.6719642906810415

Epoch: 6| Step: 7
Training loss: 0.4273451161755024
Validation loss: 2.6275425132774743

Epoch: 6| Step: 8
Training loss: 0.2792981687929291
Validation loss: 2.590270492968459

Epoch: 6| Step: 9
Training loss: 0.3721469790150914
Validation loss: 2.695297609739591

Epoch: 6| Step: 10
Training loss: 0.28911141677594804
Validation loss: 2.5797811255899035

Epoch: 6| Step: 11
Training loss: 0.42152077320604797
Validation loss: 2.6005499380448938

Epoch: 6| Step: 12
Training loss: 0.5089966392649713
Validation loss: 2.7068285845571265

Epoch: 6| Step: 13
Training loss: 0.24146674950512634
Validation loss: 2.5633571710788576

Epoch: 342| Step: 0
Training loss: 0.45773001178329326
Validation loss: 2.6524944983571217

Epoch: 6| Step: 1
Training loss: 0.3230020720331265
Validation loss: 2.6374143836662522

Epoch: 6| Step: 2
Training loss: 0.38874649405048434
Validation loss: 2.6063190771229263

Epoch: 6| Step: 3
Training loss: 0.3703873787998991
Validation loss: 2.6448555789260135

Epoch: 6| Step: 4
Training loss: 0.449762048990367
Validation loss: 2.6304362484727624

Epoch: 6| Step: 5
Training loss: 0.2680572758354786
Validation loss: 2.642801805847238

Epoch: 6| Step: 6
Training loss: 0.6627153082725082
Validation loss: 2.6247664150881733

Epoch: 6| Step: 7
Training loss: 0.37255859375
Validation loss: 2.6788732479744115

Epoch: 6| Step: 8
Training loss: 0.38746478628313574
Validation loss: 2.6383009395028445

Epoch: 6| Step: 9
Training loss: 0.4556169062812602
Validation loss: 2.700833519858409

Epoch: 6| Step: 10
Training loss: 0.37557406989445014
Validation loss: 2.6227986854356975

Epoch: 6| Step: 11
Training loss: 0.33053638316277656
Validation loss: 2.6661983441348918

Epoch: 6| Step: 12
Training loss: 0.44115342858391776
Validation loss: 2.6205594484218855

Epoch: 6| Step: 13
Training loss: 0.483699989666287
Validation loss: 2.6236981993770527

Epoch: 343| Step: 0
Training loss: 0.3145986421704319
Validation loss: 2.6674053217165854

Epoch: 6| Step: 1
Training loss: 0.26634696009830905
Validation loss: 2.6234175438393597

Epoch: 6| Step: 2
Training loss: 0.42033199421086725
Validation loss: 2.6051410581455845

Epoch: 6| Step: 3
Training loss: 0.3561580388686202
Validation loss: 2.6545205114456794

Epoch: 6| Step: 4
Training loss: 0.41761864946384386
Validation loss: 2.5921895875437593

Epoch: 6| Step: 5
Training loss: 0.43523315284350617
Validation loss: 2.6294150084557404

Epoch: 6| Step: 6
Training loss: 0.321379118475681
Validation loss: 2.6352627725612843

Epoch: 6| Step: 7
Training loss: 0.43133465032853047
Validation loss: 2.6300260247730596

Epoch: 6| Step: 8
Training loss: 0.37533081880278246
Validation loss: 2.6560320521679426

Epoch: 6| Step: 9
Training loss: 0.2855277189412383
Validation loss: 2.705247798882002

Epoch: 6| Step: 10
Training loss: 0.4904131924169351
Validation loss: 2.6513728301548496

Epoch: 6| Step: 11
Training loss: 0.3580686210605858
Validation loss: 2.596282458040479

Epoch: 6| Step: 12
Training loss: 0.38594596405632203
Validation loss: 2.6198357084805393

Epoch: 6| Step: 13
Training loss: 0.22135272680076085
Validation loss: 2.6849571958548033

Epoch: 344| Step: 0
Training loss: 0.2613412212289168
Validation loss: 2.643585622019549

Epoch: 6| Step: 1
Training loss: 0.24843174819765818
Validation loss: 2.6325823704994296

Epoch: 6| Step: 2
Training loss: 0.3190055444565921
Validation loss: 2.6938496844853512

Epoch: 6| Step: 3
Training loss: 0.3387979112329634
Validation loss: 2.653789442754228

Epoch: 6| Step: 4
Training loss: 0.3729181516962301
Validation loss: 2.7164613730047433

Epoch: 6| Step: 5
Training loss: 0.42943423349856197
Validation loss: 2.630212362053433

Epoch: 6| Step: 6
Training loss: 0.27573531473384105
Validation loss: 2.629638826762589

Epoch: 6| Step: 7
Training loss: 0.4447895459460312
Validation loss: 2.6309571109960177

Epoch: 6| Step: 8
Training loss: 0.4656080486104999
Validation loss: 2.6497697283305546

Epoch: 6| Step: 9
Training loss: 0.3343203343956645
Validation loss: 2.6589523332179374

Epoch: 6| Step: 10
Training loss: 0.35546761816494343
Validation loss: 2.7075144532376485

Epoch: 6| Step: 11
Training loss: 0.559635498084738
Validation loss: 2.645401984569739

Epoch: 6| Step: 12
Training loss: 0.38804201627254287
Validation loss: 2.622436422105255

Epoch: 6| Step: 13
Training loss: 0.4002288119219696
Validation loss: 2.65138362834931

Epoch: 345| Step: 0
Training loss: 0.34882669907777175
Validation loss: 2.5942808933110233

Epoch: 6| Step: 1
Training loss: 0.4152093874427799
Validation loss: 2.682815883236653

Epoch: 6| Step: 2
Training loss: 0.2960269258727571
Validation loss: 2.6903290016086823

Epoch: 6| Step: 3
Training loss: 0.5584984544683125
Validation loss: 2.6828126765528633

Epoch: 6| Step: 4
Training loss: 0.467686208981908
Validation loss: 2.6433824817310287

Epoch: 6| Step: 5
Training loss: 0.37272844155137835
Validation loss: 2.6812405251881706

Epoch: 6| Step: 6
Training loss: 0.4676654029916578
Validation loss: 2.6292379320242567

Epoch: 6| Step: 7
Training loss: 0.40541026551752907
Validation loss: 2.666285395684631

Epoch: 6| Step: 8
Training loss: 0.42552735694482174
Validation loss: 2.6821372842649165

Epoch: 6| Step: 9
Training loss: 0.3759077529363439
Validation loss: 2.6154962189698763

Epoch: 6| Step: 10
Training loss: 0.4876692942567874
Validation loss: 2.651745690855199

Epoch: 6| Step: 11
Training loss: 0.33082269737761444
Validation loss: 2.667263207667524

Epoch: 6| Step: 12
Training loss: 0.2543011601990873
Validation loss: 2.587853804032471

Epoch: 6| Step: 13
Training loss: 0.3882607245440918
Validation loss: 2.6572722767882992

Epoch: 346| Step: 0
Training loss: 0.454439394400631
Validation loss: 2.6077357642584547

Epoch: 6| Step: 1
Training loss: 0.43207100518032027
Validation loss: 2.745066277352943

Epoch: 6| Step: 2
Training loss: 0.26611967866539743
Validation loss: 2.710463879169428

Epoch: 6| Step: 3
Training loss: 0.35376625239372766
Validation loss: 2.7317298810936057

Epoch: 6| Step: 4
Training loss: 0.37258027139894523
Validation loss: 2.6553340304944677

Epoch: 6| Step: 5
Training loss: 0.3757713649663019
Validation loss: 2.6625387135229803

Epoch: 6| Step: 6
Training loss: 0.37815487483523014
Validation loss: 2.697539598977437

Epoch: 6| Step: 7
Training loss: 0.24719517082243328
Validation loss: 2.683513893742065

Epoch: 6| Step: 8
Training loss: 0.3248907043004887
Validation loss: 2.6408888856151385

Epoch: 6| Step: 9
Training loss: 0.44971952307102325
Validation loss: 2.6258249197675494

Epoch: 6| Step: 10
Training loss: 0.27809657423079426
Validation loss: 2.64784439632576

Epoch: 6| Step: 11
Training loss: 0.5224463344921815
Validation loss: 2.682339852403326

Epoch: 6| Step: 12
Training loss: 0.2675868680319169
Validation loss: 2.6450882986602258

Epoch: 6| Step: 13
Training loss: 0.3400110622142105
Validation loss: 2.6874445532468427

Epoch: 347| Step: 0
Training loss: 0.34736753112063534
Validation loss: 2.625693910707383

Epoch: 6| Step: 1
Training loss: 0.3671719162251562
Validation loss: 2.6066698530507755

Epoch: 6| Step: 2
Training loss: 0.3315094831183335
Validation loss: 2.6112991974321376

Epoch: 6| Step: 3
Training loss: 0.43030841354501953
Validation loss: 2.7234757520477366

Epoch: 6| Step: 4
Training loss: 0.2939919976455851
Validation loss: 2.6860555419074323

Epoch: 6| Step: 5
Training loss: 0.22067562708412825
Validation loss: 2.670390707663491

Epoch: 6| Step: 6
Training loss: 0.29739745496495934
Validation loss: 2.6845500191774594

Epoch: 6| Step: 7
Training loss: 0.4155834980371451
Validation loss: 2.599033344437494

Epoch: 6| Step: 8
Training loss: 0.3150289369529812
Validation loss: 2.66243757732925

Epoch: 6| Step: 9
Training loss: 0.479622133752979
Validation loss: 2.6591061887694822

Epoch: 6| Step: 10
Training loss: 0.447894042205151
Validation loss: 2.634832707016062

Epoch: 6| Step: 11
Training loss: 0.490286926857171
Validation loss: 2.7147349091079462

Epoch: 6| Step: 12
Training loss: 0.433172382058461
Validation loss: 2.6652236749660787

Epoch: 6| Step: 13
Training loss: 0.40215719397832245
Validation loss: 2.652991791081828

Epoch: 348| Step: 0
Training loss: 0.21432354109260998
Validation loss: 2.70915725108724

Epoch: 6| Step: 1
Training loss: 0.34078771659386087
Validation loss: 2.6304469286779515

Epoch: 6| Step: 2
Training loss: 0.3544226964510432
Validation loss: 2.6131070339823386

Epoch: 6| Step: 3
Training loss: 0.5058451175521564
Validation loss: 2.6358623253474827

Epoch: 6| Step: 4
Training loss: 0.38646273374836987
Validation loss: 2.6946660395298596

Epoch: 6| Step: 5
Training loss: 0.5327465072438577
Validation loss: 2.6313553653862956

Epoch: 6| Step: 6
Training loss: 0.32040755094418305
Validation loss: 2.662031105851893

Epoch: 6| Step: 7
Training loss: 0.23848515525539773
Validation loss: 2.656082035812846

Epoch: 6| Step: 8
Training loss: 0.33656387927411174
Validation loss: 2.664350790495013

Epoch: 6| Step: 9
Training loss: 0.29457602527371674
Validation loss: 2.626697022009302

Epoch: 6| Step: 10
Training loss: 0.7071219538892277
Validation loss: 2.69904256522625

Epoch: 6| Step: 11
Training loss: 0.5014065984461433
Validation loss: 2.6309969610474337

Epoch: 6| Step: 12
Training loss: 0.18367339496640775
Validation loss: 2.6827538150803716

Epoch: 6| Step: 13
Training loss: 0.2854766091286441
Validation loss: 2.667364548220764

Epoch: 349| Step: 0
Training loss: 0.4426590854703425
Validation loss: 2.6686230476671606

Epoch: 6| Step: 1
Training loss: 0.4972016886011882
Validation loss: 2.65018956568003

Epoch: 6| Step: 2
Training loss: 0.45505939494214365
Validation loss: 2.6347905245717365

Epoch: 6| Step: 3
Training loss: 0.3974835438590869
Validation loss: 2.692936064327481

Epoch: 6| Step: 4
Training loss: 0.257377705815021
Validation loss: 2.6325513066831445

Epoch: 6| Step: 5
Training loss: 0.3939400577525679
Validation loss: 2.655155599695766

Epoch: 6| Step: 6
Training loss: 0.3773930013987146
Validation loss: 2.7070528279995427

Epoch: 6| Step: 7
Training loss: 0.40538310210312034
Validation loss: 2.608724303594988

Epoch: 6| Step: 8
Training loss: 0.2584770913339906
Validation loss: 2.6104628071483575

Epoch: 6| Step: 9
Training loss: 0.4012349785758948
Validation loss: 2.5892435704639736

Epoch: 6| Step: 10
Training loss: 0.3462219870421418
Validation loss: 2.5732858884552137

Epoch: 6| Step: 11
Training loss: 0.27479919883598747
Validation loss: 2.631382245253911

Epoch: 6| Step: 12
Training loss: 0.25733646602547966
Validation loss: 2.6450973047675657

Epoch: 6| Step: 13
Training loss: 0.3720062881612499
Validation loss: 2.7041716267481974

Epoch: 350| Step: 0
Training loss: 0.394938042042815
Validation loss: 2.6324834268935215

Epoch: 6| Step: 1
Training loss: 0.2688725203307094
Validation loss: 2.6081558089939434

Epoch: 6| Step: 2
Training loss: 0.30768705513143446
Validation loss: 2.524475293674309

Epoch: 6| Step: 3
Training loss: 0.3558211623276016
Validation loss: 2.706013674031153

Epoch: 6| Step: 4
Training loss: 0.44196903169789264
Validation loss: 2.6908776992002483

Epoch: 6| Step: 5
Training loss: 0.32357938759472843
Validation loss: 2.5708581022638746

Epoch: 6| Step: 6
Training loss: 0.2768790152626718
Validation loss: 2.6130456746982214

Epoch: 6| Step: 7
Training loss: 0.3065054285663946
Validation loss: 2.666994318105116

Epoch: 6| Step: 8
Training loss: 0.24727999417947735
Validation loss: 2.639822346966612

Epoch: 6| Step: 9
Training loss: 0.33785909163789485
Validation loss: 2.6243190184828276

Epoch: 6| Step: 10
Training loss: 0.399095254149831
Validation loss: 2.607006261803165

Epoch: 6| Step: 11
Training loss: 0.5174063919471766
Validation loss: 2.6327654403269016

Epoch: 6| Step: 12
Training loss: 0.3535660765670806
Validation loss: 2.609873870552165

Epoch: 6| Step: 13
Training loss: 0.3379659403394502
Validation loss: 2.6309632731809978

Epoch: 351| Step: 0
Training loss: 0.3367757098529916
Validation loss: 2.5716195614279678

Epoch: 6| Step: 1
Training loss: 0.3849413320502697
Validation loss: 2.603028519190748

Epoch: 6| Step: 2
Training loss: 0.23223077306627882
Validation loss: 2.64550880384233

Epoch: 6| Step: 3
Training loss: 0.4983703460418653
Validation loss: 2.6088066624262436

Epoch: 6| Step: 4
Training loss: 0.42844412110580504
Validation loss: 2.608057264235643

Epoch: 6| Step: 5
Training loss: 0.41544589579124286
Validation loss: 2.5996011055103807

Epoch: 6| Step: 6
Training loss: 0.43620529358352755
Validation loss: 2.628332686713443

Epoch: 6| Step: 7
Training loss: 0.42196710781977675
Validation loss: 2.614562723501571

Epoch: 6| Step: 8
Training loss: 0.3933397184004561
Validation loss: 2.639117064287422

Epoch: 6| Step: 9
Training loss: 0.47027549471335095
Validation loss: 2.6312305893714387

Epoch: 6| Step: 10
Training loss: 0.461295764508413
Validation loss: 2.6388118319944818

Epoch: 6| Step: 11
Training loss: 0.3187244989441621
Validation loss: 2.6116742456561917

Epoch: 6| Step: 12
Training loss: 0.31081912264968314
Validation loss: 2.63529963981126

Epoch: 6| Step: 13
Training loss: 0.35228424161819877
Validation loss: 2.6166030383017493

Epoch: 352| Step: 0
Training loss: 0.3875781441926711
Validation loss: 2.626580568577095

Epoch: 6| Step: 1
Training loss: 0.2428933517263738
Validation loss: 2.6329108501896696

Epoch: 6| Step: 2
Training loss: 0.4162370513356841
Validation loss: 2.6927721371399342

Epoch: 6| Step: 3
Training loss: 0.33979009884430295
Validation loss: 2.5909855983141994

Epoch: 6| Step: 4
Training loss: 0.39105868107249586
Validation loss: 2.6824038040769373

Epoch: 6| Step: 5
Training loss: 0.369371594221289
Validation loss: 2.6898154257329074

Epoch: 6| Step: 6
Training loss: 0.33653388203659557
Validation loss: 2.6388932668638443

Epoch: 6| Step: 7
Training loss: 0.3026427714901807
Validation loss: 2.7098421857779087

Epoch: 6| Step: 8
Training loss: 0.3996009482709938
Validation loss: 2.6483652110628952

Epoch: 6| Step: 9
Training loss: 0.20735971916813473
Validation loss: 2.667124967134402

Epoch: 6| Step: 10
Training loss: 0.4706409619070119
Validation loss: 2.714032373460623

Epoch: 6| Step: 11
Training loss: 0.34829871146308466
Validation loss: 2.6385667894334275

Epoch: 6| Step: 12
Training loss: 0.3014810274189872
Validation loss: 2.6442013811376803

Epoch: 6| Step: 13
Training loss: 0.3754789949020323
Validation loss: 2.627650406389335

Epoch: 353| Step: 0
Training loss: 0.29843305514555696
Validation loss: 2.64232902546363

Epoch: 6| Step: 1
Training loss: 0.4481686467365422
Validation loss: 2.6593052963643045

Epoch: 6| Step: 2
Training loss: 0.3734393626529735
Validation loss: 2.6514138046109963

Epoch: 6| Step: 3
Training loss: 0.4014318557953012
Validation loss: 2.6208680383075484

Epoch: 6| Step: 4
Training loss: 0.3870783588444288
Validation loss: 2.6752356796782077

Epoch: 6| Step: 5
Training loss: 0.423838602103545
Validation loss: 2.6365922610237056

Epoch: 6| Step: 6
Training loss: 0.39406567665289916
Validation loss: 2.636974030369827

Epoch: 6| Step: 7
Training loss: 0.4913861093199309
Validation loss: 2.6247064486866996

Epoch: 6| Step: 8
Training loss: 0.42940761814297856
Validation loss: 2.6426457229392857

Epoch: 6| Step: 9
Training loss: 0.3904569264270801
Validation loss: 2.5970860517530343

Epoch: 6| Step: 10
Training loss: 0.23863615901946506
Validation loss: 2.6698025404914194

Epoch: 6| Step: 11
Training loss: 0.3816461506095076
Validation loss: 2.6185769563372348

Epoch: 6| Step: 12
Training loss: 0.5331038218380376
Validation loss: 2.6219873852109905

Epoch: 6| Step: 13
Training loss: 0.3001496507990539
Validation loss: 2.6202509397229568

Epoch: 354| Step: 0
Training loss: 0.40312489354331804
Validation loss: 2.6428280430496414

Epoch: 6| Step: 1
Training loss: 0.3593676193142824
Validation loss: 2.665750872795532

Epoch: 6| Step: 2
Training loss: 0.38384225103068065
Validation loss: 2.67927209954181

Epoch: 6| Step: 3
Training loss: 0.41877931805362795
Validation loss: 2.621036428477585

Epoch: 6| Step: 4
Training loss: 0.4508799149086989
Validation loss: 2.613396878195724

Epoch: 6| Step: 5
Training loss: 0.3841057555482767
Validation loss: 2.6430636023673277

Epoch: 6| Step: 6
Training loss: 0.42305681916135346
Validation loss: 2.651097877271251

Epoch: 6| Step: 7
Training loss: 0.43938194546154696
Validation loss: 2.6309111962221423

Epoch: 6| Step: 8
Training loss: 0.26415381009698835
Validation loss: 2.6950136691674516

Epoch: 6| Step: 9
Training loss: 0.38048313826470853
Validation loss: 2.6431756125350723

Epoch: 6| Step: 10
Training loss: 0.4360268518355512
Validation loss: 2.617858117571218

Epoch: 6| Step: 11
Training loss: 0.3451728093780156
Validation loss: 2.61867437685934

Epoch: 6| Step: 12
Training loss: 0.3804579355320438
Validation loss: 2.69906808641527

Epoch: 6| Step: 13
Training loss: 0.3516694859795455
Validation loss: 2.6114820094050364

Epoch: 355| Step: 0
Training loss: 0.37514008448676744
Validation loss: 2.603337779055555

Epoch: 6| Step: 1
Training loss: 0.4125566812066486
Validation loss: 2.6333068926807677

Epoch: 6| Step: 2
Training loss: 0.3322954136787663
Validation loss: 2.6555672609620125

Epoch: 6| Step: 3
Training loss: 0.29873675775907016
Validation loss: 2.5722976022179513

Epoch: 6| Step: 4
Training loss: 0.35988572359952087
Validation loss: 2.6231898318315165

Epoch: 6| Step: 5
Training loss: 0.45604325143333385
Validation loss: 2.5862421353815024

Epoch: 6| Step: 6
Training loss: 0.5033778295785565
Validation loss: 2.5778945819884367

Epoch: 6| Step: 7
Training loss: 0.3658069874973661
Validation loss: 2.679469923671233

Epoch: 6| Step: 8
Training loss: 0.39997557550605034
Validation loss: 2.634679296618986

Epoch: 6| Step: 9
Training loss: 0.2799169419769844
Validation loss: 2.6849227494457892

Epoch: 6| Step: 10
Training loss: 0.4022080831588514
Validation loss: 2.6815293250309944

Epoch: 6| Step: 11
Training loss: 0.3636238779422447
Validation loss: 2.636566820830248

Epoch: 6| Step: 12
Training loss: 0.4263794572631332
Validation loss: 2.622464188887927

Epoch: 6| Step: 13
Training loss: 0.3839556693972846
Validation loss: 2.6445531125763813

Epoch: 356| Step: 0
Training loss: 0.4396794393379407
Validation loss: 2.67270214818612

Epoch: 6| Step: 1
Training loss: 0.4893674137604163
Validation loss: 2.6977831735073443

Epoch: 6| Step: 2
Training loss: 0.21297703310558824
Validation loss: 2.68527588002978

Epoch: 6| Step: 3
Training loss: 0.4080703921098971
Validation loss: 2.6530439588363217

Epoch: 6| Step: 4
Training loss: 0.29367670352068587
Validation loss: 2.7025378256522923

Epoch: 6| Step: 5
Training loss: 0.34009835144297895
Validation loss: 2.6040774266529203

Epoch: 6| Step: 6
Training loss: 0.33608389037925007
Validation loss: 2.656535481090165

Epoch: 6| Step: 7
Training loss: 0.26064178591126014
Validation loss: 2.6390278668085707

Epoch: 6| Step: 8
Training loss: 0.2542135726270205
Validation loss: 2.594260843366621

Epoch: 6| Step: 9
Training loss: 0.36800642205418943
Validation loss: 2.6626169528258448

Epoch: 6| Step: 10
Training loss: 0.3589971048217109
Validation loss: 2.6411917640655647

Epoch: 6| Step: 11
Training loss: 0.43439917462816735
Validation loss: 2.617306060383014

Epoch: 6| Step: 12
Training loss: 0.4458383500479452
Validation loss: 2.6081654987227365

Epoch: 6| Step: 13
Training loss: 0.3292473942516681
Validation loss: 2.617377620642816

Epoch: 357| Step: 0
Training loss: 0.3426324277181935
Validation loss: 2.61885551325046

Epoch: 6| Step: 1
Training loss: 0.5818343629588437
Validation loss: 2.612129113307344

Epoch: 6| Step: 2
Training loss: 0.5631931061368826
Validation loss: 2.667047254901099

Epoch: 6| Step: 3
Training loss: 0.36268207400580593
Validation loss: 2.6036850572930486

Epoch: 6| Step: 4
Training loss: 0.343213594842683
Validation loss: 2.663389894778471

Epoch: 6| Step: 5
Training loss: 0.3639362337266294
Validation loss: 2.6373538912398424

Epoch: 6| Step: 6
Training loss: 0.24926129369631775
Validation loss: 2.651006901980864

Epoch: 6| Step: 7
Training loss: 0.3226699604511287
Validation loss: 2.6350092340484905

Epoch: 6| Step: 8
Training loss: 0.3272010191608333
Validation loss: 2.6177109911219905

Epoch: 6| Step: 9
Training loss: 0.2166727673072127
Validation loss: 2.5861670170372983

Epoch: 6| Step: 10
Training loss: 0.4367639958345093
Validation loss: 2.629019052278056

Epoch: 6| Step: 11
Training loss: 0.33396773268968666
Validation loss: 2.7125021516993555

Epoch: 6| Step: 12
Training loss: 0.3097259419098592
Validation loss: 2.6365483433794514

Epoch: 6| Step: 13
Training loss: 0.3105833643942339
Validation loss: 2.641031365662003

Epoch: 358| Step: 0
Training loss: 0.37331616333805884
Validation loss: 2.620984139119012

Epoch: 6| Step: 1
Training loss: 0.33836430769966674
Validation loss: 2.622544335886621

Epoch: 6| Step: 2
Training loss: 0.40535641475705725
Validation loss: 2.6239090802177745

Epoch: 6| Step: 3
Training loss: 0.41355663563936157
Validation loss: 2.7307576475538373

Epoch: 6| Step: 4
Training loss: 0.34346490655178047
Validation loss: 2.6418197457117314

Epoch: 6| Step: 5
Training loss: 0.2258566021163505
Validation loss: 2.6833999763727028

Epoch: 6| Step: 6
Training loss: 0.4122599828238945
Validation loss: 2.705164909577349

Epoch: 6| Step: 7
Training loss: 0.4199764837198272
Validation loss: 2.6497301606081822

Epoch: 6| Step: 8
Training loss: 0.3393542721953669
Validation loss: 2.6126799982293245

Epoch: 6| Step: 9
Training loss: 0.3215111773455283
Validation loss: 2.6112435326466468

Epoch: 6| Step: 10
Training loss: 0.37651121098898116
Validation loss: 2.5849486397437604

Epoch: 6| Step: 11
Training loss: 0.40302371001956744
Validation loss: 2.611166835645714

Epoch: 6| Step: 12
Training loss: 0.4342494165573637
Validation loss: 2.691822257923536

Epoch: 6| Step: 13
Training loss: 0.261895219891707
Validation loss: 2.6625379001504847

Epoch: 359| Step: 0
Training loss: 0.33112741757320724
Validation loss: 2.5917196945047962

Epoch: 6| Step: 1
Training loss: 0.2898925513957742
Validation loss: 2.637937950546917

Epoch: 6| Step: 2
Training loss: 0.3118767364277786
Validation loss: 2.6766095292591086

Epoch: 6| Step: 3
Training loss: 0.3900797853715285
Validation loss: 2.6143510013615443

Epoch: 6| Step: 4
Training loss: 0.3565658365573286
Validation loss: 2.6015348537988476

Epoch: 6| Step: 5
Training loss: 0.36967987958804377
Validation loss: 2.6729878270188037

Epoch: 6| Step: 6
Training loss: 0.4132671274465581
Validation loss: 2.6583835186501275

Epoch: 6| Step: 7
Training loss: 0.32366346583582684
Validation loss: 2.6194525487196163

Epoch: 6| Step: 8
Training loss: 0.32228883601899594
Validation loss: 2.603874179945134

Epoch: 6| Step: 9
Training loss: 0.3589852334096315
Validation loss: 2.7074268340101737

Epoch: 6| Step: 10
Training loss: 0.2808600742718689
Validation loss: 2.6248805760662375

Epoch: 6| Step: 11
Training loss: 0.31269695512672546
Validation loss: 2.6439436123943403

Epoch: 6| Step: 12
Training loss: 0.3653031146799379
Validation loss: 2.626028850806101

Epoch: 6| Step: 13
Training loss: 0.3875054728213812
Validation loss: 2.648961010770436

Epoch: 360| Step: 0
Training loss: 0.26139522597649595
Validation loss: 2.646234276697354

Epoch: 6| Step: 1
Training loss: 0.3228295449689604
Validation loss: 2.6426655937430663

Epoch: 6| Step: 2
Training loss: 0.3194959280548541
Validation loss: 2.626829887061453

Epoch: 6| Step: 3
Training loss: 0.28425683616228326
Validation loss: 2.615453451190761

Epoch: 6| Step: 4
Training loss: 0.45759537922061744
Validation loss: 2.640241847183137

Epoch: 6| Step: 5
Training loss: 0.38914857318253415
Validation loss: 2.694025899118314

Epoch: 6| Step: 6
Training loss: 0.22114646741429073
Validation loss: 2.6399513604278404

Epoch: 6| Step: 7
Training loss: 0.26128736215118875
Validation loss: 2.610628630203549

Epoch: 6| Step: 8
Training loss: 0.2736671573233378
Validation loss: 2.648085399166824

Epoch: 6| Step: 9
Training loss: 0.3007352719525708
Validation loss: 2.6372458752848105

Epoch: 6| Step: 10
Training loss: 0.22200640158831322
Validation loss: 2.6192053005303526

Epoch: 6| Step: 11
Training loss: 0.3790488220665516
Validation loss: 2.5751342226125646

Epoch: 6| Step: 12
Training loss: 0.4337513267870572
Validation loss: 2.657238032269401

Epoch: 6| Step: 13
Training loss: 0.3174011342555693
Validation loss: 2.710137680751055

Epoch: 361| Step: 0
Training loss: 0.39236451975524295
Validation loss: 2.6569459340083093

Epoch: 6| Step: 1
Training loss: 0.6156335171725154
Validation loss: 2.6123329346457616

Epoch: 6| Step: 2
Training loss: 0.32203980828267786
Validation loss: 2.636802525072486

Epoch: 6| Step: 3
Training loss: 0.3474036274006574
Validation loss: 2.683359357063989

Epoch: 6| Step: 4
Training loss: 0.3855702656894345
Validation loss: 2.648394393945194

Epoch: 6| Step: 5
Training loss: 0.34430430976210064
Validation loss: 2.692900074687283

Epoch: 6| Step: 6
Training loss: 0.19628781939819853
Validation loss: 2.633195511514971

Epoch: 6| Step: 7
Training loss: 0.267928305039911
Validation loss: 2.6180183572147424

Epoch: 6| Step: 8
Training loss: 0.3280686943245574
Validation loss: 2.6506338848866684

Epoch: 6| Step: 9
Training loss: 0.32550059700689926
Validation loss: 2.606067579122641

Epoch: 6| Step: 10
Training loss: 0.36682849946766405
Validation loss: 2.6430858754873254

Epoch: 6| Step: 11
Training loss: 0.2774430755274987
Validation loss: 2.630326248899849

Epoch: 6| Step: 12
Training loss: 0.4090229544528808
Validation loss: 2.6301783997497377

Epoch: 6| Step: 13
Training loss: 0.26403920053924906
Validation loss: 2.652878270623041

Epoch: 362| Step: 0
Training loss: 0.4350565729404702
Validation loss: 2.660248757134225

Epoch: 6| Step: 1
Training loss: 0.4986703597805808
Validation loss: 2.670344994743286

Epoch: 6| Step: 2
Training loss: 0.23391817395046613
Validation loss: 2.688820381502539

Epoch: 6| Step: 3
Training loss: 0.41406330972268446
Validation loss: 2.693926778422727

Epoch: 6| Step: 4
Training loss: 0.2974205275180154
Validation loss: 2.6636247023458277

Epoch: 6| Step: 5
Training loss: 0.4126433759108899
Validation loss: 2.6716935317373816

Epoch: 6| Step: 6
Training loss: 0.5191219122666463
Validation loss: 2.6156582440170633

Epoch: 6| Step: 7
Training loss: 0.36458147820500286
Validation loss: 2.6234413393835827

Epoch: 6| Step: 8
Training loss: 0.25960954838901074
Validation loss: 2.65080311619376

Epoch: 6| Step: 9
Training loss: 0.3505009200101742
Validation loss: 2.5772466068667943

Epoch: 6| Step: 10
Training loss: 0.46625150161276363
Validation loss: 2.6333932811416196

Epoch: 6| Step: 11
Training loss: 0.28462101073018
Validation loss: 2.6166619147927777

Epoch: 6| Step: 12
Training loss: 0.3235122382385839
Validation loss: 2.72501348964607

Epoch: 6| Step: 13
Training loss: 0.3824030574419982
Validation loss: 2.6215327085290028

Epoch: 363| Step: 0
Training loss: 0.462337082443814
Validation loss: 2.662210456494524

Epoch: 6| Step: 1
Training loss: 0.30768683719815454
Validation loss: 2.6469194680974453

Epoch: 6| Step: 2
Training loss: 0.3741724698431593
Validation loss: 2.620499643532614

Epoch: 6| Step: 3
Training loss: 0.3801774008025844
Validation loss: 2.6948174284558974

Epoch: 6| Step: 4
Training loss: 0.4921271271992725
Validation loss: 2.672939066348294

Epoch: 6| Step: 5
Training loss: 0.32480763189159134
Validation loss: 2.7011894543623476

Epoch: 6| Step: 6
Training loss: 0.2881502112117935
Validation loss: 2.6582851616810794

Epoch: 6| Step: 7
Training loss: 0.35281954779398156
Validation loss: 2.570289464845408

Epoch: 6| Step: 8
Training loss: 0.30295724356069736
Validation loss: 2.635354359208114

Epoch: 6| Step: 9
Training loss: 0.42807192090528967
Validation loss: 2.6255445066985375

Epoch: 6| Step: 10
Training loss: 0.5311755801415436
Validation loss: 2.6104033037246013

Epoch: 6| Step: 11
Training loss: 0.3755117342089462
Validation loss: 2.6664424792068595

Epoch: 6| Step: 12
Training loss: 0.22345613388576194
Validation loss: 2.6100516289078213

Epoch: 6| Step: 13
Training loss: 0.36063718976818016
Validation loss: 2.6886972229887

Epoch: 364| Step: 0
Training loss: 0.38019460714289083
Validation loss: 2.6782191695842923

Epoch: 6| Step: 1
Training loss: 0.39846663275033456
Validation loss: 2.643921444190953

Epoch: 6| Step: 2
Training loss: 0.41439462333347715
Validation loss: 2.654240180713697

Epoch: 6| Step: 3
Training loss: 0.2633380189133716
Validation loss: 2.5960304392586218

Epoch: 6| Step: 4
Training loss: 0.3816441202930955
Validation loss: 2.630024657429998

Epoch: 6| Step: 5
Training loss: 0.5349453698546637
Validation loss: 2.6476060280417673

Epoch: 6| Step: 6
Training loss: 0.408438199632975
Validation loss: 2.60930828382287

Epoch: 6| Step: 7
Training loss: 0.3658674740266534
Validation loss: 2.662698584898063

Epoch: 6| Step: 8
Training loss: 0.4247867799689554
Validation loss: 2.6610432927651244

Epoch: 6| Step: 9
Training loss: 0.30804999043966635
Validation loss: 2.635291874359766

Epoch: 6| Step: 10
Training loss: 0.40237228514581147
Validation loss: 2.6909240083921437

Epoch: 6| Step: 11
Training loss: 0.526384427667645
Validation loss: 2.63191201708122

Epoch: 6| Step: 12
Training loss: 0.19108561499272214
Validation loss: 2.6240607806644527

Epoch: 6| Step: 13
Training loss: 0.32431993858759317
Validation loss: 2.682609692333829

Epoch: 365| Step: 0
Training loss: 0.36653344766883433
Validation loss: 2.6109862540087883

Epoch: 6| Step: 1
Training loss: 0.2943170927478809
Validation loss: 2.649678422501624

Epoch: 6| Step: 2
Training loss: 0.38837041617771084
Validation loss: 2.707130224813965

Epoch: 6| Step: 3
Training loss: 0.30825981953102377
Validation loss: 2.6495098692400676

Epoch: 6| Step: 4
Training loss: 0.3671520703043979
Validation loss: 2.706123754068968

Epoch: 6| Step: 5
Training loss: 0.4285587744604443
Validation loss: 2.6941922130921214

Epoch: 6| Step: 6
Training loss: 0.3396083191687838
Validation loss: 2.6214582982796313

Epoch: 6| Step: 7
Training loss: 0.35937296825332177
Validation loss: 2.724324558552754

Epoch: 6| Step: 8
Training loss: 0.4429077166941668
Validation loss: 2.6358920536823143

Epoch: 6| Step: 9
Training loss: 0.4235525509826931
Validation loss: 2.6253974250395493

Epoch: 6| Step: 10
Training loss: 0.5089671286459161
Validation loss: 2.615104886705555

Epoch: 6| Step: 11
Training loss: 0.45028323227319444
Validation loss: 2.6023282135654555

Epoch: 6| Step: 12
Training loss: 0.32448624296519085
Validation loss: 2.596103810464883

Epoch: 6| Step: 13
Training loss: 0.5416597188601809
Validation loss: 2.630263017646196

Epoch: 366| Step: 0
Training loss: 0.3222614866048795
Validation loss: 2.6457179237085886

Epoch: 6| Step: 1
Training loss: 0.41482031948208065
Validation loss: 2.590740894260765

Epoch: 6| Step: 2
Training loss: 0.4782465431210084
Validation loss: 2.613545859130643

Epoch: 6| Step: 3
Training loss: 0.3003512194201509
Validation loss: 2.6633033006269433

Epoch: 6| Step: 4
Training loss: 0.3068884558747895
Validation loss: 2.6517725438532054

Epoch: 6| Step: 5
Training loss: 0.4397218857247345
Validation loss: 2.6374368626900457

Epoch: 6| Step: 6
Training loss: 0.40999643754574433
Validation loss: 2.703256335586767

Epoch: 6| Step: 7
Training loss: 0.5127011834671293
Validation loss: 2.664127621269616

Epoch: 6| Step: 8
Training loss: 0.4016927433683688
Validation loss: 2.6414342840211966

Epoch: 6| Step: 9
Training loss: 0.41084509633784433
Validation loss: 2.6160446632463077

Epoch: 6| Step: 10
Training loss: 0.4852275421295328
Validation loss: 2.6559485956365627

Epoch: 6| Step: 11
Training loss: 0.4108479253519468
Validation loss: 2.642926441515145

Epoch: 6| Step: 12
Training loss: 0.25382442623131063
Validation loss: 2.6438097136166516

Epoch: 6| Step: 13
Training loss: 0.2620731061467259
Validation loss: 2.6562134384930163

Epoch: 367| Step: 0
Training loss: 0.3578601297386321
Validation loss: 2.6877744371918117

Epoch: 6| Step: 1
Training loss: 0.274732411849931
Validation loss: 2.6397586733161384

Epoch: 6| Step: 2
Training loss: 0.325101592617892
Validation loss: 2.64673161213974

Epoch: 6| Step: 3
Training loss: 0.35534468780976214
Validation loss: 2.6644752607780884

Epoch: 6| Step: 4
Training loss: 0.44459779170955516
Validation loss: 2.648354948214491

Epoch: 6| Step: 5
Training loss: 0.3431323745157416
Validation loss: 2.58333042103593

Epoch: 6| Step: 6
Training loss: 0.29270151029668934
Validation loss: 2.6184897148528115

Epoch: 6| Step: 7
Training loss: 0.4517959967810327
Validation loss: 2.6550412288704583

Epoch: 6| Step: 8
Training loss: 0.35221171305164706
Validation loss: 2.646451627521677

Epoch: 6| Step: 9
Training loss: 0.3652755591688157
Validation loss: 2.6523046102056407

Epoch: 6| Step: 10
Training loss: 0.20809045681092697
Validation loss: 2.629298369367983

Epoch: 6| Step: 11
Training loss: 0.32982885665917216
Validation loss: 2.6752210638617098

Epoch: 6| Step: 12
Training loss: 0.30222744491308307
Validation loss: 2.661327931194932

Epoch: 6| Step: 13
Training loss: 0.41071898593937894
Validation loss: 2.6068199501148506

Epoch: 368| Step: 0
Training loss: 0.437888671026711
Validation loss: 2.6229009410173636

Epoch: 6| Step: 1
Training loss: 0.2337889018811126
Validation loss: 2.6643184565009435

Epoch: 6| Step: 2
Training loss: 0.41461558559978223
Validation loss: 2.6197788448032613

Epoch: 6| Step: 3
Training loss: 0.29761257902563554
Validation loss: 2.7314491094645357

Epoch: 6| Step: 4
Training loss: 0.3410130259271704
Validation loss: 2.6251388997461853

Epoch: 6| Step: 5
Training loss: 0.2905972564950084
Validation loss: 2.6558330881888503

Epoch: 6| Step: 6
Training loss: 0.4241135862047436
Validation loss: 2.6325230198765697

Epoch: 6| Step: 7
Training loss: 0.4224963733698023
Validation loss: 2.6412022653753424

Epoch: 6| Step: 8
Training loss: 0.3835565770428349
Validation loss: 2.568703670656276

Epoch: 6| Step: 9
Training loss: 0.400482018437376
Validation loss: 2.636538637390941

Epoch: 6| Step: 10
Training loss: 0.3761600987699469
Validation loss: 2.589115383703163

Epoch: 6| Step: 11
Training loss: 0.3959547743307019
Validation loss: 2.641252040714812

Epoch: 6| Step: 12
Training loss: 0.4308422178585805
Validation loss: 2.633176814228285

Epoch: 6| Step: 13
Training loss: 0.24624868087608875
Validation loss: 2.630525827916822

Epoch: 369| Step: 0
Training loss: 0.34931136061789203
Validation loss: 2.7119309421737916

Epoch: 6| Step: 1
Training loss: 0.4594573485594323
Validation loss: 2.568850595278842

Epoch: 6| Step: 2
Training loss: 0.36969140757722974
Validation loss: 2.6483568687505503

Epoch: 6| Step: 3
Training loss: 0.3590091833730515
Validation loss: 2.6154512634063485

Epoch: 6| Step: 4
Training loss: 0.3309491194575437
Validation loss: 2.603513488234463

Epoch: 6| Step: 5
Training loss: 0.30271984188512596
Validation loss: 2.6472149393071103

Epoch: 6| Step: 6
Training loss: 0.3535817542845882
Validation loss: 2.6473376110418276

Epoch: 6| Step: 7
Training loss: 0.35694766245198284
Validation loss: 2.611212960639902

Epoch: 6| Step: 8
Training loss: 0.3238475236960873
Validation loss: 2.5899035723543906

Epoch: 6| Step: 9
Training loss: 0.44691540195320045
Validation loss: 2.568466760592703

Epoch: 6| Step: 10
Training loss: 0.29405684272115956
Validation loss: 2.6713356603996754

Epoch: 6| Step: 11
Training loss: 0.38370691638491183
Validation loss: 2.6012098667165695

Epoch: 6| Step: 12
Training loss: 0.34339943262640993
Validation loss: 2.613346526694892

Epoch: 6| Step: 13
Training loss: 0.36154860909170294
Validation loss: 2.670952702818921

Epoch: 370| Step: 0
Training loss: 0.3430323696001785
Validation loss: 2.6480785340407116

Epoch: 6| Step: 1
Training loss: 0.4137773071451535
Validation loss: 2.6201483456520482

Epoch: 6| Step: 2
Training loss: 0.47094077921069316
Validation loss: 2.6374470625592332

Epoch: 6| Step: 3
Training loss: 0.527890719980703
Validation loss: 2.63649196073282

Epoch: 6| Step: 4
Training loss: 0.2925360727074627
Validation loss: 2.636224273657404

Epoch: 6| Step: 5
Training loss: 0.4153640551748077
Validation loss: 2.615388029568804

Epoch: 6| Step: 6
Training loss: 0.46982768471199987
Validation loss: 2.7149319494909294

Epoch: 6| Step: 7
Training loss: 0.22197001934373317
Validation loss: 2.6559087945539113

Epoch: 6| Step: 8
Training loss: 0.37146884633048016
Validation loss: 2.689858591860685

Epoch: 6| Step: 9
Training loss: 0.27375458996552215
Validation loss: 2.657144986636202

Epoch: 6| Step: 10
Training loss: 0.3883467421379187
Validation loss: 2.6463160988023477

Epoch: 6| Step: 11
Training loss: 0.4177980163391997
Validation loss: 2.6647880960686647

Epoch: 6| Step: 12
Training loss: 0.2655054833300326
Validation loss: 2.703701744219197

Epoch: 6| Step: 13
Training loss: 0.483462150305292
Validation loss: 2.633171547575544

Epoch: 371| Step: 0
Training loss: 0.22411168562812256
Validation loss: 2.6410262275162877

Epoch: 6| Step: 1
Training loss: 0.34692634082289603
Validation loss: 2.607055623099947

Epoch: 6| Step: 2
Training loss: 0.30760711169014526
Validation loss: 2.6216614549475503

Epoch: 6| Step: 3
Training loss: 0.2653220356282388
Validation loss: 2.5968650435139384

Epoch: 6| Step: 4
Training loss: 0.540213751519931
Validation loss: 2.6613490062935683

Epoch: 6| Step: 5
Training loss: 0.3289791071788679
Validation loss: 2.5700316580073075

Epoch: 6| Step: 6
Training loss: 0.4291189420268581
Validation loss: 2.6853079098819435

Epoch: 6| Step: 7
Training loss: 0.44528236621826817
Validation loss: 2.6795171715049206

Epoch: 6| Step: 8
Training loss: 0.4086425460357781
Validation loss: 2.595462034887084

Epoch: 6| Step: 9
Training loss: 0.31974120482307905
Validation loss: 2.590231841915516

Epoch: 6| Step: 10
Training loss: 0.3866018253389891
Validation loss: 2.6477870536273893

Epoch: 6| Step: 11
Training loss: 0.3352058449532892
Validation loss: 2.644942551693867

Epoch: 6| Step: 12
Training loss: 0.41859430222654637
Validation loss: 2.6533694786296715

Epoch: 6| Step: 13
Training loss: 0.23753329438939616
Validation loss: 2.703725259391096

Epoch: 372| Step: 0
Training loss: 0.3459437551165503
Validation loss: 2.680514364689232

Epoch: 6| Step: 1
Training loss: 0.4195400720162463
Validation loss: 2.6795978883341958

Epoch: 6| Step: 2
Training loss: 0.28427775155932244
Validation loss: 2.626401088338172

Epoch: 6| Step: 3
Training loss: 0.2643753979952727
Validation loss: 2.591889292322888

Epoch: 6| Step: 4
Training loss: 0.41390718390135134
Validation loss: 2.6253316609199873

Epoch: 6| Step: 5
Training loss: 0.3785520451427614
Validation loss: 2.6516658495316925

Epoch: 6| Step: 6
Training loss: 0.3843771236640136
Validation loss: 2.6904690037489507

Epoch: 6| Step: 7
Training loss: 0.40894221513919576
Validation loss: 2.6287581622664677

Epoch: 6| Step: 8
Training loss: 0.36493125617632205
Validation loss: 2.7249013217942837

Epoch: 6| Step: 9
Training loss: 0.30744370912523417
Validation loss: 2.727968831524705

Epoch: 6| Step: 10
Training loss: 0.36946453032511506
Validation loss: 2.6597808632778523

Epoch: 6| Step: 11
Training loss: 0.33794091793030007
Validation loss: 2.6856732111027246

Epoch: 6| Step: 12
Training loss: 0.3847655088163094
Validation loss: 2.641058771444597

Epoch: 6| Step: 13
Training loss: 0.36133299128374285
Validation loss: 2.652799901376269

Epoch: 373| Step: 0
Training loss: 0.33505917101293037
Validation loss: 2.6296058846114523

Epoch: 6| Step: 1
Training loss: 0.4266772685217692
Validation loss: 2.593317861445478

Epoch: 6| Step: 2
Training loss: 0.5958032242519011
Validation loss: 2.6744566077321292

Epoch: 6| Step: 3
Training loss: 0.36392622267610786
Validation loss: 2.6639365337046

Epoch: 6| Step: 4
Training loss: 0.32346832801113956
Validation loss: 2.6394380388463405

Epoch: 6| Step: 5
Training loss: 0.3668698499275849
Validation loss: 2.6486623512925505

Epoch: 6| Step: 6
Training loss: 0.4507929213680614
Validation loss: 2.687945159002613

Epoch: 6| Step: 7
Training loss: 0.3718752612585865
Validation loss: 2.63313664253052

Epoch: 6| Step: 8
Training loss: 0.48859877371210586
Validation loss: 2.637821884159671

Epoch: 6| Step: 9
Training loss: 0.30281421469959774
Validation loss: 2.6224937963639623

Epoch: 6| Step: 10
Training loss: 0.37913235082898705
Validation loss: 2.6125464135629883

Epoch: 6| Step: 11
Training loss: 0.46311013533795164
Validation loss: 2.6019771577681308

Epoch: 6| Step: 12
Training loss: 0.4280090843377448
Validation loss: 2.5997773882126367

Epoch: 6| Step: 13
Training loss: 0.4200178879379981
Validation loss: 2.609274529142751

Epoch: 374| Step: 0
Training loss: 0.47341430972369347
Validation loss: 2.6609573390398085

Epoch: 6| Step: 1
Training loss: 0.38930326006034116
Validation loss: 2.692939576205933

Epoch: 6| Step: 2
Training loss: 0.33286980596766763
Validation loss: 2.5907996222739538

Epoch: 6| Step: 3
Training loss: 0.3268597254092703
Validation loss: 2.6243275431985773

Epoch: 6| Step: 4
Training loss: 0.360890592689445
Validation loss: 2.678834577380196

Epoch: 6| Step: 5
Training loss: 0.4213815911998831
Validation loss: 2.603248088318574

Epoch: 6| Step: 6
Training loss: 0.4464250353264409
Validation loss: 2.6036932756578786

Epoch: 6| Step: 7
Training loss: 0.398567253377564
Validation loss: 2.691233104789207

Epoch: 6| Step: 8
Training loss: 0.45203414691902655
Validation loss: 2.6214079121406297

Epoch: 6| Step: 9
Training loss: 0.24451316638660905
Validation loss: 2.5996754382590757

Epoch: 6| Step: 10
Training loss: 0.43362144862876306
Validation loss: 2.6424719316188225

Epoch: 6| Step: 11
Training loss: 0.46888985137077327
Validation loss: 2.6687085534837247

Epoch: 6| Step: 12
Training loss: 0.5955484658512394
Validation loss: 2.5810070382246053

Epoch: 6| Step: 13
Training loss: 0.5770850751921696
Validation loss: 2.6324062241470485

Epoch: 375| Step: 0
Training loss: 0.6227092246539195
Validation loss: 2.6917307768313306

Epoch: 6| Step: 1
Training loss: 0.5069908537444113
Validation loss: 2.641510764093398

Epoch: 6| Step: 2
Training loss: 0.29406916901650465
Validation loss: 2.6686643081951305

Epoch: 6| Step: 3
Training loss: 0.4356303455785554
Validation loss: 2.6192106256084196

Epoch: 6| Step: 4
Training loss: 0.5848793393190352
Validation loss: 2.6673640193678927

Epoch: 6| Step: 5
Training loss: 0.3615592011455367
Validation loss: 2.609434085260756

Epoch: 6| Step: 6
Training loss: 0.5496801096303912
Validation loss: 2.532907076997002

Epoch: 6| Step: 7
Training loss: 0.43361330417839017
Validation loss: 2.632276637088895

Epoch: 6| Step: 8
Training loss: 0.45497264376345187
Validation loss: 2.6135824397710072

Epoch: 6| Step: 9
Training loss: 0.3288502398572537
Validation loss: 2.5853289592127844

Epoch: 6| Step: 10
Training loss: 0.3195599228322116
Validation loss: 2.584345224586439

Epoch: 6| Step: 11
Training loss: 0.3598868208371821
Validation loss: 2.6047048292401658

Epoch: 6| Step: 12
Training loss: 0.4095586510391106
Validation loss: 2.631826538748582

Epoch: 6| Step: 13
Training loss: 0.3530962548329551
Validation loss: 2.550850225181028

Epoch: 376| Step: 0
Training loss: 0.40040322260693517
Validation loss: 2.604501242443698

Epoch: 6| Step: 1
Training loss: 0.32634527200184854
Validation loss: 2.57083849563781

Epoch: 6| Step: 2
Training loss: 0.3155336592481119
Validation loss: 2.6035839853090468

Epoch: 6| Step: 3
Training loss: 0.4830654037453462
Validation loss: 2.619563983303529

Epoch: 6| Step: 4
Training loss: 0.3964157796818677
Validation loss: 2.599348819934388

Epoch: 6| Step: 5
Training loss: 0.37348744206082246
Validation loss: 2.617183992753597

Epoch: 6| Step: 6
Training loss: 0.3778443153811875
Validation loss: 2.6175148678527065

Epoch: 6| Step: 7
Training loss: 0.47028937298762424
Validation loss: 2.5786261947974003

Epoch: 6| Step: 8
Training loss: 0.2521061838974736
Validation loss: 2.6364624200249427

Epoch: 6| Step: 9
Training loss: 0.27995486879218173
Validation loss: 2.7119571406260783

Epoch: 6| Step: 10
Training loss: 0.2698515357356029
Validation loss: 2.649216191417974

Epoch: 6| Step: 11
Training loss: 0.4003010533324446
Validation loss: 2.618415172600233

Epoch: 6| Step: 12
Training loss: 0.3237001108518192
Validation loss: 2.6548144032706302

Epoch: 6| Step: 13
Training loss: 0.34305704235976514
Validation loss: 2.6181866916246284

Epoch: 377| Step: 0
Training loss: 0.3172510431090657
Validation loss: 2.646844150163765

Epoch: 6| Step: 1
Training loss: 0.32629906007787424
Validation loss: 2.7299196112211916

Epoch: 6| Step: 2
Training loss: 0.2630288229883943
Validation loss: 2.7221525247132896

Epoch: 6| Step: 3
Training loss: 0.421352663575813
Validation loss: 2.6278898438592395

Epoch: 6| Step: 4
Training loss: 0.35052659746544296
Validation loss: 2.638223131311751

Epoch: 6| Step: 5
Training loss: 0.3781500674048826
Validation loss: 2.637599935340784

Epoch: 6| Step: 6
Training loss: 0.33127954324297565
Validation loss: 2.6391223491886118

Epoch: 6| Step: 7
Training loss: 0.3382778374585706
Validation loss: 2.656517778250599

Epoch: 6| Step: 8
Training loss: 0.3986742214019458
Validation loss: 2.6603151517622035

Epoch: 6| Step: 9
Training loss: 0.4124698237738891
Validation loss: 2.6294194590155224

Epoch: 6| Step: 10
Training loss: 0.28488229629928036
Validation loss: 2.676350256942332

Epoch: 6| Step: 11
Training loss: 0.2381428332171664
Validation loss: 2.613383155740328

Epoch: 6| Step: 12
Training loss: 0.36862178448464367
Validation loss: 2.683098130451843

Epoch: 6| Step: 13
Training loss: 0.3830290201512349
Validation loss: 2.618392348163682

Epoch: 378| Step: 0
Training loss: 0.27195499986080646
Validation loss: 2.645215004785886

Epoch: 6| Step: 1
Training loss: 0.2928467814551459
Validation loss: 2.677931823054466

Epoch: 6| Step: 2
Training loss: 0.27089102142898186
Validation loss: 2.6686432685325023

Epoch: 6| Step: 3
Training loss: 0.46593766563612143
Validation loss: 2.623169086380613

Epoch: 6| Step: 4
Training loss: 0.4026322487845064
Validation loss: 2.5945278364888655

Epoch: 6| Step: 5
Training loss: 0.40049636188978704
Validation loss: 2.638469907615884

Epoch: 6| Step: 6
Training loss: 0.3954663478638195
Validation loss: 2.58036840684349

Epoch: 6| Step: 7
Training loss: 0.31549957257074096
Validation loss: 2.612405916433313

Epoch: 6| Step: 8
Training loss: 0.41396805747823673
Validation loss: 2.6599292032720485

Epoch: 6| Step: 9
Training loss: 0.524470775528284
Validation loss: 2.6368260943378896

Epoch: 6| Step: 10
Training loss: 0.45152208021949836
Validation loss: 2.611959430066001

Epoch: 6| Step: 11
Training loss: 0.33149699817998574
Validation loss: 2.610813589483083

Epoch: 6| Step: 12
Training loss: 0.3475143700311117
Validation loss: 2.6290494927978143

Epoch: 6| Step: 13
Training loss: 0.2862915796374064
Validation loss: 2.6191645352578137

Epoch: 379| Step: 0
Training loss: 0.5438674788887632
Validation loss: 2.6242556803403403

Epoch: 6| Step: 1
Training loss: 0.4972267129660942
Validation loss: 2.680305417127733

Epoch: 6| Step: 2
Training loss: 0.489895844313194
Validation loss: 2.62082091956744

Epoch: 6| Step: 3
Training loss: 0.2904135986263669
Validation loss: 2.6743361977483375

Epoch: 6| Step: 4
Training loss: 0.3445273842454145
Validation loss: 2.6338777886668407

Epoch: 6| Step: 5
Training loss: 0.38406744414484634
Validation loss: 2.6012202086385634

Epoch: 6| Step: 6
Training loss: 0.3769745301805396
Validation loss: 2.6079474330252816

Epoch: 6| Step: 7
Training loss: 0.30762316985595384
Validation loss: 2.6713682515816823

Epoch: 6| Step: 8
Training loss: 0.33889034972609927
Validation loss: 2.637421668277051

Epoch: 6| Step: 9
Training loss: 0.3677877430455711
Validation loss: 2.5191866380272354

Epoch: 6| Step: 10
Training loss: 0.421934618092887
Validation loss: 2.612908991143031

Epoch: 6| Step: 11
Training loss: 0.22109104768159737
Validation loss: 2.650345571646175

Epoch: 6| Step: 12
Training loss: 0.2753305166673293
Validation loss: 2.644710187244103

Epoch: 6| Step: 13
Training loss: 0.24483765092421386
Validation loss: 2.6085266972938363

Epoch: 380| Step: 0
Training loss: 0.36622135401852274
Validation loss: 2.6493905902201966

Epoch: 6| Step: 1
Training loss: 0.3941759643741767
Validation loss: 2.6451253970154758

Epoch: 6| Step: 2
Training loss: 0.39202519284035553
Validation loss: 2.6361795133039836

Epoch: 6| Step: 3
Training loss: 0.44133160390375775
Validation loss: 2.6021271819265133

Epoch: 6| Step: 4
Training loss: 0.24699563567749874
Validation loss: 2.65188491290791

Epoch: 6| Step: 5
Training loss: 0.430592883536006
Validation loss: 2.5837503578593033

Epoch: 6| Step: 6
Training loss: 0.2257805022388998
Validation loss: 2.638554892122175

Epoch: 6| Step: 7
Training loss: 0.4384942168014269
Validation loss: 2.664812976067114

Epoch: 6| Step: 8
Training loss: 0.3503877297306264
Validation loss: 2.683841980730598

Epoch: 6| Step: 9
Training loss: 0.4533691241911935
Validation loss: 2.651115181633694

Epoch: 6| Step: 10
Training loss: 0.40604791750271124
Validation loss: 2.5715003240126366

Epoch: 6| Step: 11
Training loss: 0.3185923841146887
Validation loss: 2.6763646141904167

Epoch: 6| Step: 12
Training loss: 0.401249332249166
Validation loss: 2.6221475392103475

Epoch: 6| Step: 13
Training loss: 0.24766685631600568
Validation loss: 2.6995909857892935

Epoch: 381| Step: 0
Training loss: 0.36994283791976923
Validation loss: 2.6696842276667625

Epoch: 6| Step: 1
Training loss: 0.3525299536038099
Validation loss: 2.6538568225023837

Epoch: 6| Step: 2
Training loss: 0.21689929776577074
Validation loss: 2.6360463167985304

Epoch: 6| Step: 3
Training loss: 0.35164018408479236
Validation loss: 2.615181194711504

Epoch: 6| Step: 4
Training loss: 0.3595742834100888
Validation loss: 2.6314905849478984

Epoch: 6| Step: 5
Training loss: 0.2834153399694861
Validation loss: 2.641610287165968

Epoch: 6| Step: 6
Training loss: 0.2985765981813325
Validation loss: 2.623331129815591

Epoch: 6| Step: 7
Training loss: 0.29134016693916887
Validation loss: 2.6662313483483473

Epoch: 6| Step: 8
Training loss: 0.3351772710792512
Validation loss: 2.588544524489935

Epoch: 6| Step: 9
Training loss: 0.20953638490078527
Validation loss: 2.6211557395188056

Epoch: 6| Step: 10
Training loss: 0.3272309953512957
Validation loss: 2.572137851191895

Epoch: 6| Step: 11
Training loss: 0.37755826693029293
Validation loss: 2.6725005966009814

Epoch: 6| Step: 12
Training loss: 0.2915064621498607
Validation loss: 2.6443880644388176

Epoch: 6| Step: 13
Training loss: 0.4731166583375279
Validation loss: 2.6056635305792377

Epoch: 382| Step: 0
Training loss: 0.21794069820635892
Validation loss: 2.6283135466313614

Epoch: 6| Step: 1
Training loss: 0.46376044400425853
Validation loss: 2.61491760204322

Epoch: 6| Step: 2
Training loss: 0.3575565522153807
Validation loss: 2.6296752288707337

Epoch: 6| Step: 3
Training loss: 0.20361596158319478
Validation loss: 2.6436769729400216

Epoch: 6| Step: 4
Training loss: 0.40228985916250537
Validation loss: 2.5993206151354524

Epoch: 6| Step: 5
Training loss: 0.3247176319198883
Validation loss: 2.6664747278358396

Epoch: 6| Step: 6
Training loss: 0.3380347589446624
Validation loss: 2.6471731493140642

Epoch: 6| Step: 7
Training loss: 0.39173620482586424
Validation loss: 2.6202997785489552

Epoch: 6| Step: 8
Training loss: 0.28653601402343726
Validation loss: 2.585784800036423

Epoch: 6| Step: 9
Training loss: 0.2972710753052739
Validation loss: 2.6269677975988164

Epoch: 6| Step: 10
Training loss: 0.22991749737610115
Validation loss: 2.605372071081004

Epoch: 6| Step: 11
Training loss: 0.4185250938018025
Validation loss: 2.6237345627464927

Epoch: 6| Step: 12
Training loss: 0.31577875763949115
Validation loss: 2.5361471487880562

Epoch: 6| Step: 13
Training loss: 0.32651038506919927
Validation loss: 2.6756092990841394

Epoch: 383| Step: 0
Training loss: 0.2771862818746024
Validation loss: 2.633273709704625

Epoch: 6| Step: 1
Training loss: 0.497141085459656
Validation loss: 2.649772765055727

Epoch: 6| Step: 2
Training loss: 0.33078802391039297
Validation loss: 2.6010469798404405

Epoch: 6| Step: 3
Training loss: 0.3397209778811696
Validation loss: 2.6089992062236163

Epoch: 6| Step: 4
Training loss: 0.36416647330932955
Validation loss: 2.637773678578326

Epoch: 6| Step: 5
Training loss: 0.26431067051573454
Validation loss: 2.5984359144801235

Epoch: 6| Step: 6
Training loss: 0.29492167289676435
Validation loss: 2.690066007113915

Epoch: 6| Step: 7
Training loss: 0.36511256996892527
Validation loss: 2.643622869226022

Epoch: 6| Step: 8
Training loss: 0.3100811206714249
Validation loss: 2.652831701714809

Epoch: 6| Step: 9
Training loss: 0.42151831630762926
Validation loss: 2.6800004129504362

Epoch: 6| Step: 10
Training loss: 0.38282585120760715
Validation loss: 2.6532847701972764

Epoch: 6| Step: 11
Training loss: 0.38390597050384545
Validation loss: 2.6254402200231297

Epoch: 6| Step: 12
Training loss: 0.37492099565520903
Validation loss: 2.6307882947412624

Epoch: 6| Step: 13
Training loss: 0.45209708859426573
Validation loss: 2.709589759677863

Epoch: 384| Step: 0
Training loss: 0.2716921279000583
Validation loss: 2.598154021256963

Epoch: 6| Step: 1
Training loss: 0.3761768550681796
Validation loss: 2.6462179089694966

Epoch: 6| Step: 2
Training loss: 0.2996405360244656
Validation loss: 2.613738000599874

Epoch: 6| Step: 3
Training loss: 0.35569680412536225
Validation loss: 2.6529501969347593

Epoch: 6| Step: 4
Training loss: 0.36110340037835237
Validation loss: 2.6675935018705768

Epoch: 6| Step: 5
Training loss: 0.4165857554395395
Validation loss: 2.670470108193477

Epoch: 6| Step: 6
Training loss: 0.4740052636634931
Validation loss: 2.688583421783198

Epoch: 6| Step: 7
Training loss: 0.4628285555530548
Validation loss: 2.6279170011083983

Epoch: 6| Step: 8
Training loss: 0.2493379439402152
Validation loss: 2.5770158944420007

Epoch: 6| Step: 9
Training loss: 0.4006373133976443
Validation loss: 2.6665261176939357

Epoch: 6| Step: 10
Training loss: 0.3326900006002659
Validation loss: 2.6301076939027976

Epoch: 6| Step: 11
Training loss: 0.3270219928581323
Validation loss: 2.6398541531108983

Epoch: 6| Step: 12
Training loss: 0.2796844514222465
Validation loss: 2.6248340327157207

Epoch: 6| Step: 13
Training loss: 0.4101726165412535
Validation loss: 2.616560235460839

Epoch: 385| Step: 0
Training loss: 0.39423228730111626
Validation loss: 2.6591481573388553

Epoch: 6| Step: 1
Training loss: 0.41192489038220426
Validation loss: 2.654013062069104

Epoch: 6| Step: 2
Training loss: 0.36663846301212144
Validation loss: 2.62048440398537

Epoch: 6| Step: 3
Training loss: 0.3769740756048499
Validation loss: 2.632510189581288

Epoch: 6| Step: 4
Training loss: 0.4232168403925484
Validation loss: 2.6539213706966938

Epoch: 6| Step: 5
Training loss: 0.3824171438109585
Validation loss: 2.5834595639141944

Epoch: 6| Step: 6
Training loss: 0.2918696194097661
Validation loss: 2.608853476482312

Epoch: 6| Step: 7
Training loss: 0.3452307496459966
Validation loss: 2.614232261360901

Epoch: 6| Step: 8
Training loss: 0.39569287150317217
Validation loss: 2.6407926758268325

Epoch: 6| Step: 9
Training loss: 0.43658617494758695
Validation loss: 2.6394382947793327

Epoch: 6| Step: 10
Training loss: 0.3154067512416759
Validation loss: 2.632665960231457

Epoch: 6| Step: 11
Training loss: 0.3043569214208531
Validation loss: 2.6306840724449803

Epoch: 6| Step: 12
Training loss: 0.49284898116134257
Validation loss: 2.624940674732066

Epoch: 6| Step: 13
Training loss: 0.26848601416883505
Validation loss: 2.682016263483411

Epoch: 386| Step: 0
Training loss: 0.22509921191292356
Validation loss: 2.616229877543385

Epoch: 6| Step: 1
Training loss: 0.39503433709046976
Validation loss: 2.6023874282797888

Epoch: 6| Step: 2
Training loss: 0.3167161248300135
Validation loss: 2.5772091327288327

Epoch: 6| Step: 3
Training loss: 0.405776187716794
Validation loss: 2.6806661970619916

Epoch: 6| Step: 4
Training loss: 0.3986106571094499
Validation loss: 2.616782905847688

Epoch: 6| Step: 5
Training loss: 0.31003016544287304
Validation loss: 2.6341294825470847

Epoch: 6| Step: 6
Training loss: 0.40716709645019994
Validation loss: 2.5679346311148095

Epoch: 6| Step: 7
Training loss: 0.24735079740218788
Validation loss: 2.6198411081147235

Epoch: 6| Step: 8
Training loss: 0.3459595951960254
Validation loss: 2.6084877531107686

Epoch: 6| Step: 9
Training loss: 0.33867915980546154
Validation loss: 2.637181596987068

Epoch: 6| Step: 10
Training loss: 0.3515641848205885
Validation loss: 2.5941437724919183

Epoch: 6| Step: 11
Training loss: 0.4621610082187554
Validation loss: 2.6050480736990558

Epoch: 6| Step: 12
Training loss: 0.34842342211419486
Validation loss: 2.6348508345519197

Epoch: 6| Step: 13
Training loss: 0.29120674514055417
Validation loss: 2.6445945082310636

Epoch: 387| Step: 0
Training loss: 0.31729317206169444
Validation loss: 2.659767947842794

Epoch: 6| Step: 1
Training loss: 0.3441575408830977
Validation loss: 2.6586789712653034

Epoch: 6| Step: 2
Training loss: 0.3266596316574286
Validation loss: 2.652565603664378

Epoch: 6| Step: 3
Training loss: 0.31287085462347086
Validation loss: 2.633297982059073

Epoch: 6| Step: 4
Training loss: 0.21832975824780285
Validation loss: 2.641820227033609

Epoch: 6| Step: 5
Training loss: 0.3589887824218631
Validation loss: 2.60273766538185

Epoch: 6| Step: 6
Training loss: 0.39998818618494775
Validation loss: 2.6029726317387616

Epoch: 6| Step: 7
Training loss: 0.19962282900624007
Validation loss: 2.5639976838865643

Epoch: 6| Step: 8
Training loss: 0.3095786878734438
Validation loss: 2.6354651515757683

Epoch: 6| Step: 9
Training loss: 0.42391233882053414
Validation loss: 2.583595921388907

Epoch: 6| Step: 10
Training loss: 0.40380671176679417
Validation loss: 2.60372933848231

Epoch: 6| Step: 11
Training loss: 0.36767726051873945
Validation loss: 2.6074285957164087

Epoch: 6| Step: 12
Training loss: 0.40222058679550876
Validation loss: 2.566458583009835

Epoch: 6| Step: 13
Training loss: 0.4281562222978519
Validation loss: 2.6605552489875572

Epoch: 388| Step: 0
Training loss: 0.4226914734891236
Validation loss: 2.616850494398791

Epoch: 6| Step: 1
Training loss: 0.41495087528175517
Validation loss: 2.5929856687037685

Epoch: 6| Step: 2
Training loss: 0.3681413152735265
Validation loss: 2.6306303132724733

Epoch: 6| Step: 3
Training loss: 0.3004057881629415
Validation loss: 2.629039698667055

Epoch: 6| Step: 4
Training loss: 0.329118971548131
Validation loss: 2.5720727954942992

Epoch: 6| Step: 5
Training loss: 0.23774548003516113
Validation loss: 2.614919060864025

Epoch: 6| Step: 6
Training loss: 0.40875963669245907
Validation loss: 2.6019788605542082

Epoch: 6| Step: 7
Training loss: 0.40495044752436077
Validation loss: 2.6396915960552954

Epoch: 6| Step: 8
Training loss: 0.2264280166719641
Validation loss: 2.681101404680048

Epoch: 6| Step: 9
Training loss: 0.34825235331658283
Validation loss: 2.5758573327066974

Epoch: 6| Step: 10
Training loss: 0.3268694015008905
Validation loss: 2.678451401276803

Epoch: 6| Step: 11
Training loss: 0.4045861172441168
Validation loss: 2.6478415374742412

Epoch: 6| Step: 12
Training loss: 0.33457357178997266
Validation loss: 2.60034701159066

Epoch: 6| Step: 13
Training loss: 0.3068882616522227
Validation loss: 2.5744034542182272

Epoch: 389| Step: 0
Training loss: 0.4932935186001689
Validation loss: 2.6019437279574733

Epoch: 6| Step: 1
Training loss: 0.373245645663751
Validation loss: 2.6264848899229967

Epoch: 6| Step: 2
Training loss: 0.3304100512054379
Validation loss: 2.581085801463248

Epoch: 6| Step: 3
Training loss: 0.35617414637345707
Validation loss: 2.648626945269131

Epoch: 6| Step: 4
Training loss: 0.3504622408551117
Validation loss: 2.6335827825999325

Epoch: 6| Step: 5
Training loss: 0.35486324846321193
Validation loss: 2.605462939300234

Epoch: 6| Step: 6
Training loss: 0.35630873062155416
Validation loss: 2.628137106608637

Epoch: 6| Step: 7
Training loss: 0.332329414230659
Validation loss: 2.5789296368425747

Epoch: 6| Step: 8
Training loss: 0.46091370601987164
Validation loss: 2.631910326112242

Epoch: 6| Step: 9
Training loss: 0.38192705008846806
Validation loss: 2.5906498624423846

Epoch: 6| Step: 10
Training loss: 0.31993320151599436
Validation loss: 2.61340389524618

Epoch: 6| Step: 11
Training loss: 0.2639906192886607
Validation loss: 2.596060952809684

Epoch: 6| Step: 12
Training loss: 0.3551318070357818
Validation loss: 2.601650477116041

Epoch: 6| Step: 13
Training loss: 0.40540517481322647
Validation loss: 2.6588030644262513

Epoch: 390| Step: 0
Training loss: 0.4430388245501136
Validation loss: 2.584191677075399

Epoch: 6| Step: 1
Training loss: 0.2880788640592492
Validation loss: 2.643137938079234

Epoch: 6| Step: 2
Training loss: 0.3783496425841226
Validation loss: 2.6464376785644266

Epoch: 6| Step: 3
Training loss: 0.30995874674551077
Validation loss: 2.648282521982578

Epoch: 6| Step: 4
Training loss: 0.4273448895259637
Validation loss: 2.5678617239447052

Epoch: 6| Step: 5
Training loss: 0.26984108517672306
Validation loss: 2.6359428865490386

Epoch: 6| Step: 6
Training loss: 0.328143289601268
Validation loss: 2.5781270499173115

Epoch: 6| Step: 7
Training loss: 0.35450650020741253
Validation loss: 2.6440531281064437

Epoch: 6| Step: 8
Training loss: 0.2991560215348922
Validation loss: 2.6608683062113925

Epoch: 6| Step: 9
Training loss: 0.4767889204116472
Validation loss: 2.621653088289744

Epoch: 6| Step: 10
Training loss: 0.29285455385461007
Validation loss: 2.6434531181184635

Epoch: 6| Step: 11
Training loss: 0.2658529285430676
Validation loss: 2.6399940399020765

Epoch: 6| Step: 12
Training loss: 0.38513142968109515
Validation loss: 2.6892094165803386

Epoch: 6| Step: 13
Training loss: 0.37723329242392484
Validation loss: 2.64130435007277

Epoch: 391| Step: 0
Training loss: 0.3023297959688196
Validation loss: 2.651515735939919

Epoch: 6| Step: 1
Training loss: 0.23779839699441901
Validation loss: 2.6154227536734167

Epoch: 6| Step: 2
Training loss: 0.37063908079009067
Validation loss: 2.636662838189986

Epoch: 6| Step: 3
Training loss: 0.15692106029546282
Validation loss: 2.6303767512319465

Epoch: 6| Step: 4
Training loss: 0.32310990222655644
Validation loss: 2.6236036310537494

Epoch: 6| Step: 5
Training loss: 0.42163227304156464
Validation loss: 2.5847227041781675

Epoch: 6| Step: 6
Training loss: 0.5165405814337474
Validation loss: 2.6351505240649495

Epoch: 6| Step: 7
Training loss: 0.42679000488650926
Validation loss: 2.5987276320162263

Epoch: 6| Step: 8
Training loss: 0.3328697612019306
Validation loss: 2.608076050188782

Epoch: 6| Step: 9
Training loss: 0.2851551264910578
Validation loss: 2.6760580323459955

Epoch: 6| Step: 10
Training loss: 0.3273292269705703
Validation loss: 2.641132117940238

Epoch: 6| Step: 11
Training loss: 0.5038699942860412
Validation loss: 2.5968696034142416

Epoch: 6| Step: 12
Training loss: 0.29101309039145035
Validation loss: 2.649777983716041

Epoch: 6| Step: 13
Training loss: 0.4862312465522829
Validation loss: 2.66863579367966

Epoch: 392| Step: 0
Training loss: 0.3668912544743837
Validation loss: 2.651157913707077

Epoch: 6| Step: 1
Training loss: 0.3670597665880802
Validation loss: 2.6284998314596018

Epoch: 6| Step: 2
Training loss: 0.288172808981494
Validation loss: 2.638334029127918

Epoch: 6| Step: 3
Training loss: 0.40286010644353115
Validation loss: 2.62510726346255

Epoch: 6| Step: 4
Training loss: 0.33587308754073025
Validation loss: 2.637637613572384

Epoch: 6| Step: 5
Training loss: 0.22673149218989688
Validation loss: 2.6541590370615515

Epoch: 6| Step: 6
Training loss: 0.3188837799125629
Validation loss: 2.5923853122133234

Epoch: 6| Step: 7
Training loss: 0.401751480460629
Validation loss: 2.6366904626906633

Epoch: 6| Step: 8
Training loss: 0.4213250071931704
Validation loss: 2.6346146012654357

Epoch: 6| Step: 9
Training loss: 0.4060859348885187
Validation loss: 2.5790239327478797

Epoch: 6| Step: 10
Training loss: 0.4569962153904088
Validation loss: 2.6072993598567433

Epoch: 6| Step: 11
Training loss: 0.36136202266566186
Validation loss: 2.6537775238473693

Epoch: 6| Step: 12
Training loss: 0.30632672370603753
Validation loss: 2.5598377726979358

Epoch: 6| Step: 13
Training loss: 0.38754911572913214
Validation loss: 2.6116196653433055

Epoch: 393| Step: 0
Training loss: 0.38372083838930837
Validation loss: 2.689717390844943

Epoch: 6| Step: 1
Training loss: 0.3597497437458305
Validation loss: 2.622645760489555

Epoch: 6| Step: 2
Training loss: 0.2678399301856729
Validation loss: 2.6717130377686265

Epoch: 6| Step: 3
Training loss: 0.6038633906267715
Validation loss: 2.586079004878086

Epoch: 6| Step: 4
Training loss: 0.2948784322510597
Validation loss: 2.584202948197359

Epoch: 6| Step: 5
Training loss: 0.23990414570398214
Validation loss: 2.609677554195995

Epoch: 6| Step: 6
Training loss: 0.32653418422756597
Validation loss: 2.5739159413182295

Epoch: 6| Step: 7
Training loss: 0.2992570578651887
Validation loss: 2.6460330517300763

Epoch: 6| Step: 8
Training loss: 0.2874627177280146
Validation loss: 2.6547862638707764

Epoch: 6| Step: 9
Training loss: 0.34908062893774666
Validation loss: 2.627946214495171

Epoch: 6| Step: 10
Training loss: 0.4422852195896365
Validation loss: 2.6432227724997066

Epoch: 6| Step: 11
Training loss: 0.34053421035464226
Validation loss: 2.669211534291145

Epoch: 6| Step: 12
Training loss: 0.3194876027783962
Validation loss: 2.597107900618266

Epoch: 6| Step: 13
Training loss: 0.34504712898968154
Validation loss: 2.6343013277986023

Epoch: 394| Step: 0
Training loss: 0.2850942021627373
Validation loss: 2.530724215746366

Epoch: 6| Step: 1
Training loss: 0.36052825648217424
Validation loss: 2.7050954512903114

Epoch: 6| Step: 2
Training loss: 0.3618137292595595
Validation loss: 2.5950047319108163

Epoch: 6| Step: 3
Training loss: 0.2846281831921012
Validation loss: 2.6355688531129875

Epoch: 6| Step: 4
Training loss: 0.3621844068893787
Validation loss: 2.6576348154341183

Epoch: 6| Step: 5
Training loss: 0.3451368575651455
Validation loss: 2.600990606765965

Epoch: 6| Step: 6
Training loss: 0.405749158974726
Validation loss: 2.716916558604753

Epoch: 6| Step: 7
Training loss: 0.3006760053925338
Validation loss: 2.6602398023213616

Epoch: 6| Step: 8
Training loss: 0.3510895833140414
Validation loss: 2.6646500999391254

Epoch: 6| Step: 9
Training loss: 0.4332531630955841
Validation loss: 2.6535251628678673

Epoch: 6| Step: 10
Training loss: 0.35952925481329695
Validation loss: 2.6744301013599783

Epoch: 6| Step: 11
Training loss: 0.30169393116331766
Validation loss: 2.6389089421854406

Epoch: 6| Step: 12
Training loss: 0.3745137081565887
Validation loss: 2.6055024091003873

Epoch: 6| Step: 13
Training loss: 0.3088153574567567
Validation loss: 2.6006994792061593

Epoch: 395| Step: 0
Training loss: 0.36927508372814055
Validation loss: 2.6735356395907854

Epoch: 6| Step: 1
Training loss: 0.2505493238404955
Validation loss: 2.651322053322582

Epoch: 6| Step: 2
Training loss: 0.26090041371017003
Validation loss: 2.6552786902445518

Epoch: 6| Step: 3
Training loss: 0.4567331988737216
Validation loss: 2.646694716461858

Epoch: 6| Step: 4
Training loss: 0.2889433434762117
Validation loss: 2.6176881833154177

Epoch: 6| Step: 5
Training loss: 0.4815301568905612
Validation loss: 2.581012088011781

Epoch: 6| Step: 6
Training loss: 0.46009963874180887
Validation loss: 2.6059756188685435

Epoch: 6| Step: 7
Training loss: 0.29713905035812177
Validation loss: 2.5921503365956653

Epoch: 6| Step: 8
Training loss: 0.5330512420864535
Validation loss: 2.6349074709870846

Epoch: 6| Step: 9
Training loss: 0.40066606305212316
Validation loss: 2.6518889961050145

Epoch: 6| Step: 10
Training loss: 0.3537992109233301
Validation loss: 2.6364520806989877

Epoch: 6| Step: 11
Training loss: 0.3436093259284636
Validation loss: 2.6279399091488003

Epoch: 6| Step: 12
Training loss: 0.3361699165288963
Validation loss: 2.6533450454384733

Epoch: 6| Step: 13
Training loss: 0.2696194159009526
Validation loss: 2.6860026246808624

Epoch: 396| Step: 0
Training loss: 0.3991703138437009
Validation loss: 2.6127019600323704

Epoch: 6| Step: 1
Training loss: 0.3126883177776116
Validation loss: 2.6570086723399546

Epoch: 6| Step: 2
Training loss: 0.36364278953602036
Validation loss: 2.6466068628922916

Epoch: 6| Step: 3
Training loss: 0.36931630147441946
Validation loss: 2.633689153348909

Epoch: 6| Step: 4
Training loss: 0.25111119855966657
Validation loss: 2.656298034832029

Epoch: 6| Step: 5
Training loss: 0.3730091255621091
Validation loss: 2.6520973506855716

Epoch: 6| Step: 6
Training loss: 0.3096003593038906
Validation loss: 2.6519559671324284

Epoch: 6| Step: 7
Training loss: 0.33565724681467923
Validation loss: 2.6590665208764683

Epoch: 6| Step: 8
Training loss: 0.33335256769396676
Validation loss: 2.6444252402367843

Epoch: 6| Step: 9
Training loss: 0.2638713647157402
Validation loss: 2.6775790818043648

Epoch: 6| Step: 10
Training loss: 0.32161380855245614
Validation loss: 2.617955731805688

Epoch: 6| Step: 11
Training loss: 0.363094671594757
Validation loss: 2.6875529912411342

Epoch: 6| Step: 12
Training loss: 0.31491363166348635
Validation loss: 2.5980692370250598

Epoch: 6| Step: 13
Training loss: 0.3239475057802064
Validation loss: 2.691682163780487

Epoch: 397| Step: 0
Training loss: 0.4143052379289933
Validation loss: 2.6908009535454975

Epoch: 6| Step: 1
Training loss: 0.2308073708170662
Validation loss: 2.7074868101912366

Epoch: 6| Step: 2
Training loss: 0.454429130950366
Validation loss: 2.6459885248842197

Epoch: 6| Step: 3
Training loss: 0.20219155556622093
Validation loss: 2.6404871857624803

Epoch: 6| Step: 4
Training loss: 0.4429365990759966
Validation loss: 2.654284988313079

Epoch: 6| Step: 5
Training loss: 0.45203653685203943
Validation loss: 2.6537549436609713

Epoch: 6| Step: 6
Training loss: 0.42896188677365366
Validation loss: 2.6341339779396113

Epoch: 6| Step: 7
Training loss: 0.4177327247246013
Validation loss: 2.6211395487074354

Epoch: 6| Step: 8
Training loss: 0.36175106143202534
Validation loss: 2.655632223956035

Epoch: 6| Step: 9
Training loss: 0.4686369282722267
Validation loss: 2.61819856007458

Epoch: 6| Step: 10
Training loss: 0.3381494622186911
Validation loss: 2.603197899233098

Epoch: 6| Step: 11
Training loss: 0.28072610380428104
Validation loss: 2.6373486404619193

Epoch: 6| Step: 12
Training loss: 0.4067539976822704
Validation loss: 2.5931709593056524

Epoch: 6| Step: 13
Training loss: 0.2664319291701299
Validation loss: 2.706919181085608

Epoch: 398| Step: 0
Training loss: 0.32253063749453487
Validation loss: 2.616442719572993

Epoch: 6| Step: 1
Training loss: 0.31042396464292304
Validation loss: 2.5969725356776583

Epoch: 6| Step: 2
Training loss: 0.3352638187604244
Validation loss: 2.6829768419890727

Epoch: 6| Step: 3
Training loss: 0.43193737893426454
Validation loss: 2.639220667500287

Epoch: 6| Step: 4
Training loss: 0.307665551637349
Validation loss: 2.647381957595208

Epoch: 6| Step: 5
Training loss: 0.278397372101776
Validation loss: 2.5606965953081313

Epoch: 6| Step: 6
Training loss: 0.3337622232734793
Validation loss: 2.6670562390039487

Epoch: 6| Step: 7
Training loss: 0.3419972731442522
Validation loss: 2.615777147152888

Epoch: 6| Step: 8
Training loss: 0.24061295677366434
Validation loss: 2.6368537095934257

Epoch: 6| Step: 9
Training loss: 0.2754719255711165
Validation loss: 2.667998820591999

Epoch: 6| Step: 10
Training loss: 0.4228299600135588
Validation loss: 2.6039013129781803

Epoch: 6| Step: 11
Training loss: 0.29844707303895845
Validation loss: 2.6876247288348187

Epoch: 6| Step: 12
Training loss: 0.3178245873717336
Validation loss: 2.6904152280738565

Epoch: 6| Step: 13
Training loss: 0.22583970332898046
Validation loss: 2.6094334000012247

Epoch: 399| Step: 0
Training loss: 0.33449890701973545
Validation loss: 2.682425165403522

Epoch: 6| Step: 1
Training loss: 0.20510168394372055
Validation loss: 2.6489908696160436

Epoch: 6| Step: 2
Training loss: 0.2508862403400488
Validation loss: 2.6082301036122524

Epoch: 6| Step: 3
Training loss: 0.33470046923857805
Validation loss: 2.617019480915418

Epoch: 6| Step: 4
Training loss: 0.4902080665611431
Validation loss: 2.6804161897533656

Epoch: 6| Step: 5
Training loss: 0.4588730210303413
Validation loss: 2.6600855492575985

Epoch: 6| Step: 6
Training loss: 0.25414980431158357
Validation loss: 2.626907949520076

Epoch: 6| Step: 7
Training loss: 0.37456260444872624
Validation loss: 2.7037072703029774

Epoch: 6| Step: 8
Training loss: 0.36028744093477544
Validation loss: 2.656710730593686

Epoch: 6| Step: 9
Training loss: 0.3225369322869187
Validation loss: 2.6025112281823386

Epoch: 6| Step: 10
Training loss: 0.2777490475154995
Validation loss: 2.681514728699877

Epoch: 6| Step: 11
Training loss: 0.3182478282199603
Validation loss: 2.6582534490040537

Epoch: 6| Step: 12
Training loss: 0.2603426955387977
Validation loss: 2.598267760996029

Epoch: 6| Step: 13
Training loss: 0.2563120208676224
Validation loss: 2.6608930212586692

Epoch: 400| Step: 0
Training loss: 0.27147874894933466
Validation loss: 2.677130751925819

Epoch: 6| Step: 1
Training loss: 0.33698727461874095
Validation loss: 2.618978724357937

Epoch: 6| Step: 2
Training loss: 0.3407011944305649
Validation loss: 2.6163324733905573

Epoch: 6| Step: 3
Training loss: 0.3778127642205437
Validation loss: 2.6641972005281827

Epoch: 6| Step: 4
Training loss: 0.32353393204420283
Validation loss: 2.593750206820928

Epoch: 6| Step: 5
Training loss: 0.4151232106791376
Validation loss: 2.5815977732054867

Epoch: 6| Step: 6
Training loss: 0.33785930113497653
Validation loss: 2.6517939870955156

Epoch: 6| Step: 7
Training loss: 0.3205527242172873
Validation loss: 2.6765733275126777

Epoch: 6| Step: 8
Training loss: 0.2770078532348572
Validation loss: 2.658516070583448

Epoch: 6| Step: 9
Training loss: 0.2822905207302206
Validation loss: 2.670275568237029

Epoch: 6| Step: 10
Training loss: 0.3976745593759143
Validation loss: 2.633939281192463

Epoch: 6| Step: 11
Training loss: 0.5041301732477703
Validation loss: 2.6330411756990113

Epoch: 6| Step: 12
Training loss: 0.3159239354226077
Validation loss: 2.609771850621145

Epoch: 6| Step: 13
Training loss: 0.4016476878487742
Validation loss: 2.577273696451523

Epoch: 401| Step: 0
Training loss: 0.2962165608023846
Validation loss: 2.6351020283402655

Epoch: 6| Step: 1
Training loss: 0.36294934277126173
Validation loss: 2.6548908122109207

Epoch: 6| Step: 2
Training loss: 0.35703947112052814
Validation loss: 2.604636849237186

Epoch: 6| Step: 3
Training loss: 0.25796888405734575
Validation loss: 2.6109876693693512

Epoch: 6| Step: 4
Training loss: 0.2670990909182118
Validation loss: 2.6403496352260243

Epoch: 6| Step: 5
Training loss: 0.35976393012725516
Validation loss: 2.629295936183434

Epoch: 6| Step: 6
Training loss: 0.3549201630759512
Validation loss: 2.562915985333902

Epoch: 6| Step: 7
Training loss: 0.38990979523884095
Validation loss: 2.667714692842668

Epoch: 6| Step: 8
Training loss: 0.3309967755552475
Validation loss: 2.5862221921271153

Epoch: 6| Step: 9
Training loss: 0.3467536524997637
Validation loss: 2.605815568877021

Epoch: 6| Step: 10
Training loss: 0.2730665142543965
Validation loss: 2.6485073114157034

Epoch: 6| Step: 11
Training loss: 0.4372741422765938
Validation loss: 2.5846422837532095

Epoch: 6| Step: 12
Training loss: 0.30596006399843845
Validation loss: 2.602161235472919

Epoch: 6| Step: 13
Training loss: 0.39695247960164864
Validation loss: 2.6156295922169543

Epoch: 402| Step: 0
Training loss: 0.3491419005696112
Validation loss: 2.6136785717396958

Epoch: 6| Step: 1
Training loss: 0.2934285307133977
Validation loss: 2.600186890218573

Epoch: 6| Step: 2
Training loss: 0.354844918797129
Validation loss: 2.6354000005584584

Epoch: 6| Step: 3
Training loss: 0.31020169297551986
Validation loss: 2.6443515042215595

Epoch: 6| Step: 4
Training loss: 0.3697295159062243
Validation loss: 2.5958247178997595

Epoch: 6| Step: 5
Training loss: 0.2288251801623962
Validation loss: 2.5725125962058053

Epoch: 6| Step: 6
Training loss: 0.37371395045673095
Validation loss: 2.599826420589582

Epoch: 6| Step: 7
Training loss: 0.36461268261442575
Validation loss: 2.5796133195919757

Epoch: 6| Step: 8
Training loss: 0.4376930764450567
Validation loss: 2.5980849904153382

Epoch: 6| Step: 9
Training loss: 0.37977080667488555
Validation loss: 2.6033076179136305

Epoch: 6| Step: 10
Training loss: 0.2650735966132335
Validation loss: 2.5900493864311986

Epoch: 6| Step: 11
Training loss: 0.2446834328314626
Validation loss: 2.608726679806313

Epoch: 6| Step: 12
Training loss: 0.35081077315508485
Validation loss: 2.6162246830944507

Epoch: 6| Step: 13
Training loss: 0.39087045587131347
Validation loss: 2.5788079176103382

Epoch: 403| Step: 0
Training loss: 0.2603196853616861
Validation loss: 2.6255479725077846

Epoch: 6| Step: 1
Training loss: 0.2393913052336788
Validation loss: 2.6080444049974916

Epoch: 6| Step: 2
Training loss: 0.40599534416230465
Validation loss: 2.616540462544302

Epoch: 6| Step: 3
Training loss: 0.2966546068771894
Validation loss: 2.63097188209173

Epoch: 6| Step: 4
Training loss: 0.23857434023316484
Validation loss: 2.629574694965092

Epoch: 6| Step: 5
Training loss: 0.4357225209324467
Validation loss: 2.6563636306692433

Epoch: 6| Step: 6
Training loss: 0.268578781434274
Validation loss: 2.579751813469253

Epoch: 6| Step: 7
Training loss: 0.3434531382192855
Validation loss: 2.5721835637694896

Epoch: 6| Step: 8
Training loss: 0.28677553763077723
Validation loss: 2.6444372914544325

Epoch: 6| Step: 9
Training loss: 0.29839717732390747
Validation loss: 2.643327853360294

Epoch: 6| Step: 10
Training loss: 0.5201423607413126
Validation loss: 2.64132064293989

Epoch: 6| Step: 11
Training loss: 0.33198211530763005
Validation loss: 2.620878753713275

Epoch: 6| Step: 12
Training loss: 0.34293771268790385
Validation loss: 2.5952580981569042

Epoch: 6| Step: 13
Training loss: 0.3190607874541321
Validation loss: 2.6445126028074952

Epoch: 404| Step: 0
Training loss: 0.44837544108173166
Validation loss: 2.614690707510872

Epoch: 6| Step: 1
Training loss: 0.35752796203792553
Validation loss: 2.6403490558130946

Epoch: 6| Step: 2
Training loss: 0.2208221418465905
Validation loss: 2.6397619849859404

Epoch: 6| Step: 3
Training loss: 0.3175066896920304
Validation loss: 2.5890107308712134

Epoch: 6| Step: 4
Training loss: 0.3472752143900394
Validation loss: 2.6619845403264866

Epoch: 6| Step: 5
Training loss: 0.4194319595109679
Validation loss: 2.610072288315974

Epoch: 6| Step: 6
Training loss: 0.32364081382644666
Validation loss: 2.616153797580799

Epoch: 6| Step: 7
Training loss: 0.3115187258947064
Validation loss: 2.6264644730834736

Epoch: 6| Step: 8
Training loss: 0.34832296841241883
Validation loss: 2.6141237156357016

Epoch: 6| Step: 9
Training loss: 0.287224337858303
Validation loss: 2.616929758010871

Epoch: 6| Step: 10
Training loss: 0.3171649008719468
Validation loss: 2.62470920405252

Epoch: 6| Step: 11
Training loss: 0.18687145859734078
Validation loss: 2.638577813223314

Epoch: 6| Step: 12
Training loss: 0.22734696133629737
Validation loss: 2.600006799199922

Epoch: 6| Step: 13
Training loss: 0.2021291050903982
Validation loss: 2.6391481863309725

Epoch: 405| Step: 0
Training loss: 0.2528216746284049
Validation loss: 2.6026886267803926

Epoch: 6| Step: 1
Training loss: 0.29605030657039333
Validation loss: 2.6730167113501375

Epoch: 6| Step: 2
Training loss: 0.2345671025421029
Validation loss: 2.5742099204174886

Epoch: 6| Step: 3
Training loss: 0.31649880174135814
Validation loss: 2.6582332612178567

Epoch: 6| Step: 4
Training loss: 0.28254992693709585
Validation loss: 2.701559109351974

Epoch: 6| Step: 5
Training loss: 0.38312881402486654
Validation loss: 2.6377737689646157

Epoch: 6| Step: 6
Training loss: 0.28398093912808775
Validation loss: 2.66160907554864

Epoch: 6| Step: 7
Training loss: 0.3062073750902451
Validation loss: 2.5959086493459482

Epoch: 6| Step: 8
Training loss: 0.2881184963642511
Validation loss: 2.623913509828544

Epoch: 6| Step: 9
Training loss: 0.40925466355851575
Validation loss: 2.6067103868933534

Epoch: 6| Step: 10
Training loss: 0.3606050834907838
Validation loss: 2.6333109443251983

Epoch: 6| Step: 11
Training loss: 0.3227868575503625
Validation loss: 2.598302300981345

Epoch: 6| Step: 12
Training loss: 0.2995769617484579
Validation loss: 2.572316958282829

Epoch: 6| Step: 13
Training loss: 0.36026351390590194
Validation loss: 2.6115351280806816

Epoch: 406| Step: 0
Training loss: 0.2762518328610199
Validation loss: 2.5790867716586483

Epoch: 6| Step: 1
Training loss: 0.42374646151592843
Validation loss: 2.644365554344301

Epoch: 6| Step: 2
Training loss: 0.2532584509686904
Validation loss: 2.673209461301604

Epoch: 6| Step: 3
Training loss: 0.4423845472154437
Validation loss: 2.649547948007603

Epoch: 6| Step: 4
Training loss: 0.28072753698174396
Validation loss: 2.6631279254173

Epoch: 6| Step: 5
Training loss: 0.3381964671994624
Validation loss: 2.717620805115782

Epoch: 6| Step: 6
Training loss: 0.3735531871158793
Validation loss: 2.621703439403297

Epoch: 6| Step: 7
Training loss: 0.28829446777807494
Validation loss: 2.6522255572959637

Epoch: 6| Step: 8
Training loss: 0.3452709103908386
Validation loss: 2.6920298613780997

Epoch: 6| Step: 9
Training loss: 0.3109012716839716
Validation loss: 2.672852335567267

Epoch: 6| Step: 10
Training loss: 0.3409578652422776
Validation loss: 2.702704431822155

Epoch: 6| Step: 11
Training loss: 0.27460616911621627
Validation loss: 2.652842171926558

Epoch: 6| Step: 12
Training loss: 0.4556877408045979
Validation loss: 2.619357523707012

Epoch: 6| Step: 13
Training loss: 0.526371065879221
Validation loss: 2.618864078510305

Epoch: 407| Step: 0
Training loss: 0.243311595971902
Validation loss: 2.642429795934119

Epoch: 6| Step: 1
Training loss: 0.33178255079448626
Validation loss: 2.68057056998186

Epoch: 6| Step: 2
Training loss: 0.2840093777444766
Validation loss: 2.639733444277077

Epoch: 6| Step: 3
Training loss: 0.25540168243491085
Validation loss: 2.6307627682128136

Epoch: 6| Step: 4
Training loss: 0.3159241712571546
Validation loss: 2.6214299751434886

Epoch: 6| Step: 5
Training loss: 0.33021082270473123
Validation loss: 2.5876173112601255

Epoch: 6| Step: 6
Training loss: 0.3475169213380875
Validation loss: 2.6378561246515653

Epoch: 6| Step: 7
Training loss: 0.30497209999800173
Validation loss: 2.637509164899719

Epoch: 6| Step: 8
Training loss: 0.2875461629419186
Validation loss: 2.6527104749236265

Epoch: 6| Step: 9
Training loss: 0.40228546979699065
Validation loss: 2.612062901035494

Epoch: 6| Step: 10
Training loss: 0.2881238104284724
Validation loss: 2.6775838455787464

Epoch: 6| Step: 11
Training loss: 0.39858303030232345
Validation loss: 2.6261473676166034

Epoch: 6| Step: 12
Training loss: 0.26622267408240635
Validation loss: 2.643875258584435

Epoch: 6| Step: 13
Training loss: 0.2151293330368511
Validation loss: 2.6243003033791847

Epoch: 408| Step: 0
Training loss: 0.27738228382467955
Validation loss: 2.626876856418788

Epoch: 6| Step: 1
Training loss: 0.26842542832112926
Validation loss: 2.669218158977541

Epoch: 6| Step: 2
Training loss: 0.3187838573799793
Validation loss: 2.588260556057777

Epoch: 6| Step: 3
Training loss: 0.13956055843840906
Validation loss: 2.651460211089697

Epoch: 6| Step: 4
Training loss: 0.23015139438041832
Validation loss: 2.595186073428447

Epoch: 6| Step: 5
Training loss: 0.26588530968574564
Validation loss: 2.757833896802508

Epoch: 6| Step: 6
Training loss: 0.45691539241430573
Validation loss: 2.617308140341796

Epoch: 6| Step: 7
Training loss: 0.20847836850152257
Validation loss: 2.6330343543512393

Epoch: 6| Step: 8
Training loss: 0.2953842403929545
Validation loss: 2.5886328135561043

Epoch: 6| Step: 9
Training loss: 0.41391996413509063
Validation loss: 2.616890225204833

Epoch: 6| Step: 10
Training loss: 0.20950023762978526
Validation loss: 2.6391590872405715

Epoch: 6| Step: 11
Training loss: 0.37475363267864537
Validation loss: 2.6572625418193074

Epoch: 6| Step: 12
Training loss: 0.3372965093260709
Validation loss: 2.6723435420529325

Epoch: 6| Step: 13
Training loss: 0.2510551003202989
Validation loss: 2.620812133274746

Epoch: 409| Step: 0
Training loss: 0.38738197713540484
Validation loss: 2.6377880198308334

Epoch: 6| Step: 1
Training loss: 0.3378364982691188
Validation loss: 2.6198410626122346

Epoch: 6| Step: 2
Training loss: 0.3067376778932775
Validation loss: 2.6558161661746102

Epoch: 6| Step: 3
Training loss: 0.2621045045357513
Validation loss: 2.6131104478580647

Epoch: 6| Step: 4
Training loss: 0.33843544491807015
Validation loss: 2.6290295719811443

Epoch: 6| Step: 5
Training loss: 0.44729504217832433
Validation loss: 2.5997773423589834

Epoch: 6| Step: 6
Training loss: 0.39741339621808336
Validation loss: 2.6154773495776964

Epoch: 6| Step: 7
Training loss: 0.3343636439525224
Validation loss: 2.588847909129151

Epoch: 6| Step: 8
Training loss: 0.2782524026036962
Validation loss: 2.636783762942709

Epoch: 6| Step: 9
Training loss: 0.3153675360610959
Validation loss: 2.5649631338834986

Epoch: 6| Step: 10
Training loss: 0.24553081674769414
Validation loss: 2.615054218600563

Epoch: 6| Step: 11
Training loss: 0.3233479905779934
Validation loss: 2.5846934327245137

Epoch: 6| Step: 12
Training loss: 0.3242098106163015
Validation loss: 2.6032045697968695

Epoch: 6| Step: 13
Training loss: 0.42546297128978916
Validation loss: 2.6470755316844867

Epoch: 410| Step: 0
Training loss: 0.3441232475543755
Validation loss: 2.6336317438542034

Epoch: 6| Step: 1
Training loss: 0.3433366153885776
Validation loss: 2.5978690688833947

Epoch: 6| Step: 2
Training loss: 0.27086912737801405
Validation loss: 2.6244042492531374

Epoch: 6| Step: 3
Training loss: 0.2650719944756276
Validation loss: 2.5616914357377967

Epoch: 6| Step: 4
Training loss: 0.2809025286972163
Validation loss: 2.574700610956263

Epoch: 6| Step: 5
Training loss: 0.35966187926913584
Validation loss: 2.62699833751849

Epoch: 6| Step: 6
Training loss: 0.2962357137953524
Validation loss: 2.5904988821489026

Epoch: 6| Step: 7
Training loss: 0.39390294873716575
Validation loss: 2.6333425801352224

Epoch: 6| Step: 8
Training loss: 0.3752451929538046
Validation loss: 2.5940335589835875

Epoch: 6| Step: 9
Training loss: 0.2864409990556828
Validation loss: 2.675397450935982

Epoch: 6| Step: 10
Training loss: 0.2848695201798672
Validation loss: 2.588153185690561

Epoch: 6| Step: 11
Training loss: 0.34056569291814714
Validation loss: 2.6171900810874242

Epoch: 6| Step: 12
Training loss: 0.3268822797179818
Validation loss: 2.7067480338210945

Epoch: 6| Step: 13
Training loss: 0.4294417632280954
Validation loss: 2.5843058468085855

Epoch: 411| Step: 0
Training loss: 0.3087251118038172
Validation loss: 2.657177333149113

Epoch: 6| Step: 1
Training loss: 0.32467807267778626
Validation loss: 2.5989189425269186

Epoch: 6| Step: 2
Training loss: 0.29186667101655134
Validation loss: 2.6114992643439643

Epoch: 6| Step: 3
Training loss: 0.3054489622024151
Validation loss: 2.619126864365612

Epoch: 6| Step: 4
Training loss: 0.3004388470382442
Validation loss: 2.699672957028403

Epoch: 6| Step: 5
Training loss: 0.17623963459120193
Validation loss: 2.7189802751909475

Epoch: 6| Step: 6
Training loss: 0.3270475317359889
Validation loss: 2.6191662041128367

Epoch: 6| Step: 7
Training loss: 0.2682943295826887
Validation loss: 2.595362426351085

Epoch: 6| Step: 8
Training loss: 0.2089758541473519
Validation loss: 2.7047840679286934

Epoch: 6| Step: 9
Training loss: 0.2788713588314456
Validation loss: 2.668569591180646

Epoch: 6| Step: 10
Training loss: 0.3768025626287768
Validation loss: 2.617015593847068

Epoch: 6| Step: 11
Training loss: 0.3030674978163922
Validation loss: 2.6249430665396662

Epoch: 6| Step: 12
Training loss: 0.3132636990470615
Validation loss: 2.6802450032004517

Epoch: 6| Step: 13
Training loss: 0.3118634057995518
Validation loss: 2.6505540250645274

Epoch: 412| Step: 0
Training loss: 0.3252850428783484
Validation loss: 2.629068808893206

Epoch: 6| Step: 1
Training loss: 0.31002350856489014
Validation loss: 2.6159350078939863

Epoch: 6| Step: 2
Training loss: 0.3415323378149177
Validation loss: 2.639396321436928

Epoch: 6| Step: 3
Training loss: 0.3332811727045312
Validation loss: 2.644218798256833

Epoch: 6| Step: 4
Training loss: 0.36730186223581784
Validation loss: 2.6197897656372535

Epoch: 6| Step: 5
Training loss: 0.3085566872661002
Validation loss: 2.6676162702847983

Epoch: 6| Step: 6
Training loss: 0.40540559750951904
Validation loss: 2.6128168002216667

Epoch: 6| Step: 7
Training loss: 0.2604645526092403
Validation loss: 2.611349398198923

Epoch: 6| Step: 8
Training loss: 0.3549492781630013
Validation loss: 2.627706888016436

Epoch: 6| Step: 9
Training loss: 0.4005925111496298
Validation loss: 2.611062362793008

Epoch: 6| Step: 10
Training loss: 0.2916046939587176
Validation loss: 2.6372840105901845

Epoch: 6| Step: 11
Training loss: 0.4688121436569961
Validation loss: 2.642145595597981

Epoch: 6| Step: 12
Training loss: 0.2766437292692401
Validation loss: 2.6001170804487677

Epoch: 6| Step: 13
Training loss: 0.30923753294875006
Validation loss: 2.6186463043391726

Epoch: 413| Step: 0
Training loss: 0.3126549455843304
Validation loss: 2.6577612672921656

Epoch: 6| Step: 1
Training loss: 0.34533449767458335
Validation loss: 2.638878781037185

Epoch: 6| Step: 2
Training loss: 0.30191132427626777
Validation loss: 2.6005056103572066

Epoch: 6| Step: 3
Training loss: 0.3944301664577052
Validation loss: 2.6156368691354746

Epoch: 6| Step: 4
Training loss: 0.27505243787626477
Validation loss: 2.658210853417808

Epoch: 6| Step: 5
Training loss: 0.29274418171281286
Validation loss: 2.616498349682568

Epoch: 6| Step: 6
Training loss: 0.30901198474780434
Validation loss: 2.600340837977429

Epoch: 6| Step: 7
Training loss: 0.4611023107165099
Validation loss: 2.6331063926263267

Epoch: 6| Step: 8
Training loss: 0.36555878618388415
Validation loss: 2.6142820790109464

Epoch: 6| Step: 9
Training loss: 0.25908832161374146
Validation loss: 2.62386307997158

Epoch: 6| Step: 10
Training loss: 0.3229818188662712
Validation loss: 2.645149643239837

Epoch: 6| Step: 11
Training loss: 0.3074939299193658
Validation loss: 2.6052222947930304

Epoch: 6| Step: 12
Training loss: 0.3889559565435583
Validation loss: 2.6028072979977708

Epoch: 6| Step: 13
Training loss: 0.26669553001978924
Validation loss: 2.5969774626139652

Epoch: 414| Step: 0
Training loss: 0.41252189708157916
Validation loss: 2.666200944842991

Epoch: 6| Step: 1
Training loss: 0.3188835112199596
Validation loss: 2.6800169746848237

Epoch: 6| Step: 2
Training loss: 0.27994784273841533
Validation loss: 2.604872574816724

Epoch: 6| Step: 3
Training loss: 0.3214587775013283
Validation loss: 2.6150053121975976

Epoch: 6| Step: 4
Training loss: 0.3392483768677307
Validation loss: 2.626477869997559

Epoch: 6| Step: 5
Training loss: 0.32733720486090423
Validation loss: 2.6709965382749576

Epoch: 6| Step: 6
Training loss: 0.3540801919757535
Validation loss: 2.628986646491345

Epoch: 6| Step: 7
Training loss: 0.2930430254560066
Validation loss: 2.5989267707900896

Epoch: 6| Step: 8
Training loss: 0.27946512449809835
Validation loss: 2.646752668343901

Epoch: 6| Step: 9
Training loss: 0.24591840067599743
Validation loss: 2.5694401119527863

Epoch: 6| Step: 10
Training loss: 0.3544505701778054
Validation loss: 2.6669039446846337

Epoch: 6| Step: 11
Training loss: 0.36083509470456143
Validation loss: 2.654197992312639

Epoch: 6| Step: 12
Training loss: 0.2882804084910281
Validation loss: 2.594705505247364

Epoch: 6| Step: 13
Training loss: 0.30268459526068725
Validation loss: 2.5917876760151373

Epoch: 415| Step: 0
Training loss: 0.4228663981524385
Validation loss: 2.681667578724512

Epoch: 6| Step: 1
Training loss: 0.3587256660582319
Validation loss: 2.643609160872079

Epoch: 6| Step: 2
Training loss: 0.3405294953768652
Validation loss: 2.619656346329375

Epoch: 6| Step: 3
Training loss: 0.32837029779506843
Validation loss: 2.6212447796140346

Epoch: 6| Step: 4
Training loss: 0.2598439865661755
Validation loss: 2.622142007937993

Epoch: 6| Step: 5
Training loss: 0.3558872819127084
Validation loss: 2.547090844991391

Epoch: 6| Step: 6
Training loss: 0.3903670031180105
Validation loss: 2.6153215731384662

Epoch: 6| Step: 7
Training loss: 0.22361494600980936
Validation loss: 2.675016389481673

Epoch: 6| Step: 8
Training loss: 0.25003073920574537
Validation loss: 2.6066146534497148

Epoch: 6| Step: 9
Training loss: 0.2823917209255921
Validation loss: 2.6333115101968296

Epoch: 6| Step: 10
Training loss: 0.24716852520383054
Validation loss: 2.6295746042969763

Epoch: 6| Step: 11
Training loss: 0.38848930173059826
Validation loss: 2.594096363641457

Epoch: 6| Step: 12
Training loss: 0.29573792488392997
Validation loss: 2.595478079679574

Epoch: 6| Step: 13
Training loss: 0.3223768446922403
Validation loss: 2.6567347963022003

Epoch: 416| Step: 0
Training loss: 0.2875118030322883
Validation loss: 2.6547073372497683

Epoch: 6| Step: 1
Training loss: 0.34387419364471355
Validation loss: 2.635290245873832

Epoch: 6| Step: 2
Training loss: 0.3115026293654321
Validation loss: 2.6418420518803414

Epoch: 6| Step: 3
Training loss: 0.21132001808397308
Validation loss: 2.6250476227330846

Epoch: 6| Step: 4
Training loss: 0.28317271102178176
Validation loss: 2.6205966741533846

Epoch: 6| Step: 5
Training loss: 0.21554629160908212
Validation loss: 2.6454501638025625

Epoch: 6| Step: 6
Training loss: 0.41917349196780623
Validation loss: 2.6047819605958744

Epoch: 6| Step: 7
Training loss: 0.3754504597717835
Validation loss: 2.6127084846598945

Epoch: 6| Step: 8
Training loss: 0.33647360274956334
Validation loss: 2.6613877069965035

Epoch: 6| Step: 9
Training loss: 0.2961209156387536
Validation loss: 2.577533862227293

Epoch: 6| Step: 10
Training loss: 0.4400410089564037
Validation loss: 2.6082884073704835

Epoch: 6| Step: 11
Training loss: 0.27365355811211406
Validation loss: 2.6214539782063935

Epoch: 6| Step: 12
Training loss: 0.3676723160903384
Validation loss: 2.612455822146751

Epoch: 6| Step: 13
Training loss: 0.3545497290619243
Validation loss: 2.6245205305084633

Epoch: 417| Step: 0
Training loss: 0.34654089070017263
Validation loss: 2.654128734810629

Epoch: 6| Step: 1
Training loss: 0.36164600720194373
Validation loss: 2.6118925821260692

Epoch: 6| Step: 2
Training loss: 0.3367280308269771
Validation loss: 2.630426670995869

Epoch: 6| Step: 3
Training loss: 0.35790287026018885
Validation loss: 2.6085720463882187

Epoch: 6| Step: 4
Training loss: 0.3431289763472102
Validation loss: 2.679716015544456

Epoch: 6| Step: 5
Training loss: 0.34064346797119477
Validation loss: 2.7091630080554405

Epoch: 6| Step: 6
Training loss: 0.41491124597236445
Validation loss: 2.633900237527565

Epoch: 6| Step: 7
Training loss: 0.35585265336456456
Validation loss: 2.649863055427455

Epoch: 6| Step: 8
Training loss: 0.3829237523251793
Validation loss: 2.6656801266502326

Epoch: 6| Step: 9
Training loss: 0.2811043150073585
Validation loss: 2.594377571998546

Epoch: 6| Step: 10
Training loss: 0.2937554034283978
Validation loss: 2.6323432843836305

Epoch: 6| Step: 11
Training loss: 0.27609465948105105
Validation loss: 2.63104159812757

Epoch: 6| Step: 12
Training loss: 0.32575146198164207
Validation loss: 2.6026755578066396

Epoch: 6| Step: 13
Training loss: 0.5241386784488811
Validation loss: 2.6754847229984984

Epoch: 418| Step: 0
Training loss: 0.37586285741949454
Validation loss: 2.5871830041180273

Epoch: 6| Step: 1
Training loss: 0.3446261554196387
Validation loss: 2.6136550217868426

Epoch: 6| Step: 2
Training loss: 0.37771943623964976
Validation loss: 2.6114600677748223

Epoch: 6| Step: 3
Training loss: 0.39983528515828426
Validation loss: 2.629209246847325

Epoch: 6| Step: 4
Training loss: 0.3791818894310273
Validation loss: 2.5849389398472544

Epoch: 6| Step: 5
Training loss: 0.21083388609461892
Validation loss: 2.6462324372100525

Epoch: 6| Step: 6
Training loss: 0.3234395925481802
Validation loss: 2.6357104221920693

Epoch: 6| Step: 7
Training loss: 0.4464030881829158
Validation loss: 2.5746489084880206

Epoch: 6| Step: 8
Training loss: 0.24185624079445128
Validation loss: 2.6210073351650065

Epoch: 6| Step: 9
Training loss: 0.36467197793780715
Validation loss: 2.6213951335525074

Epoch: 6| Step: 10
Training loss: 0.2768720726133982
Validation loss: 2.647340020139202

Epoch: 6| Step: 11
Training loss: 0.35141916532007356
Validation loss: 2.640086914857022

Epoch: 6| Step: 12
Training loss: 0.3495235337730242
Validation loss: 2.635494703461819

Epoch: 6| Step: 13
Training loss: 0.24394973921901636
Validation loss: 2.6868544106242886

Epoch: 419| Step: 0
Training loss: 0.4276338920839583
Validation loss: 2.5479749632867414

Epoch: 6| Step: 1
Training loss: 0.3891871884480913
Validation loss: 2.61343121822955

Epoch: 6| Step: 2
Training loss: 0.30505329573207285
Validation loss: 2.650977927730138

Epoch: 6| Step: 3
Training loss: 0.36481694729557895
Validation loss: 2.6037271713694294

Epoch: 6| Step: 4
Training loss: 0.3200661595877817
Validation loss: 2.5925099882585165

Epoch: 6| Step: 5
Training loss: 0.3787450939276179
Validation loss: 2.6602277704110806

Epoch: 6| Step: 6
Training loss: 0.31648571288146915
Validation loss: 2.6319804400216764

Epoch: 6| Step: 7
Training loss: 0.32230270634792313
Validation loss: 2.669233016079607

Epoch: 6| Step: 8
Training loss: 0.38241685156791067
Validation loss: 2.600538447451759

Epoch: 6| Step: 9
Training loss: 0.49449521938400687
Validation loss: 2.6263572120964054

Epoch: 6| Step: 10
Training loss: 0.3095560762519474
Validation loss: 2.635641922703812

Epoch: 6| Step: 11
Training loss: 0.3863534068599555
Validation loss: 2.56351948438769

Epoch: 6| Step: 12
Training loss: 0.28863795781941165
Validation loss: 2.6349638347568805

Epoch: 6| Step: 13
Training loss: 0.4178204852805502
Validation loss: 2.643732834107182

Epoch: 420| Step: 0
Training loss: 0.2567297132012055
Validation loss: 2.5559315194705436

Epoch: 6| Step: 1
Training loss: 0.3836885859462733
Validation loss: 2.628303311317

Epoch: 6| Step: 2
Training loss: 0.35399877084098397
Validation loss: 2.5500212623295666

Epoch: 6| Step: 3
Training loss: 0.361834197437081
Validation loss: 2.643629407725068

Epoch: 6| Step: 4
Training loss: 0.2723852619918257
Validation loss: 2.564563695572619

Epoch: 6| Step: 5
Training loss: 0.24650202293513793
Validation loss: 2.594138441911577

Epoch: 6| Step: 6
Training loss: 0.17478918827328407
Validation loss: 2.5914764627860647

Epoch: 6| Step: 7
Training loss: 0.47771243203300384
Validation loss: 2.6157424505397593

Epoch: 6| Step: 8
Training loss: 0.3767796448294276
Validation loss: 2.6006276204570344

Epoch: 6| Step: 9
Training loss: 0.2532923098390369
Validation loss: 2.5854066839852807

Epoch: 6| Step: 10
Training loss: 0.3507982211690972
Validation loss: 2.642881937505948

Epoch: 6| Step: 11
Training loss: 0.32978960553286457
Validation loss: 2.5877701718110457

Epoch: 6| Step: 12
Training loss: 0.20102071175215933
Validation loss: 2.6394998835795898

Epoch: 6| Step: 13
Training loss: 0.43346296520276945
Validation loss: 2.6311793936274253

Epoch: 421| Step: 0
Training loss: 0.44394225401859044
Validation loss: 2.632934839139963

Epoch: 6| Step: 1
Training loss: 0.31035854218918624
Validation loss: 2.6376569722305696

Epoch: 6| Step: 2
Training loss: 0.15400212540259062
Validation loss: 2.6061347899369482

Epoch: 6| Step: 3
Training loss: 0.22391540463374318
Validation loss: 2.5636502297323833

Epoch: 6| Step: 4
Training loss: 0.36185421147696617
Validation loss: 2.6226973728035046

Epoch: 6| Step: 5
Training loss: 0.21965354553936992
Validation loss: 2.617296146396175

Epoch: 6| Step: 6
Training loss: 0.1819762748578749
Validation loss: 2.55438765730902

Epoch: 6| Step: 7
Training loss: 0.33291432251341674
Validation loss: 2.587610400880746

Epoch: 6| Step: 8
Training loss: 0.32967623108321337
Validation loss: 2.6508170121989734

Epoch: 6| Step: 9
Training loss: 0.3538917942757932
Validation loss: 2.6243936655862043

Epoch: 6| Step: 10
Training loss: 0.2634457218792229
Validation loss: 2.6036265436170014

Epoch: 6| Step: 11
Training loss: 0.19907859472188377
Validation loss: 2.7021997738947627

Epoch: 6| Step: 12
Training loss: 0.46164782797538884
Validation loss: 2.5899292714539586

Epoch: 6| Step: 13
Training loss: 0.2783420755008992
Validation loss: 2.645834522297109

Epoch: 422| Step: 0
Training loss: 0.38805322917223306
Validation loss: 2.648105746845898

Epoch: 6| Step: 1
Training loss: 0.36644245204738285
Validation loss: 2.651372268137973

Epoch: 6| Step: 2
Training loss: 0.2531977525404158
Validation loss: 2.6395667399000535

Epoch: 6| Step: 3
Training loss: 0.27138319805946004
Validation loss: 2.661641457385945

Epoch: 6| Step: 4
Training loss: 0.3326105449772597
Validation loss: 2.611056161250439

Epoch: 6| Step: 5
Training loss: 0.3852006611937694
Validation loss: 2.624649213634357

Epoch: 6| Step: 6
Training loss: 0.36407077272372607
Validation loss: 2.65559441947253

Epoch: 6| Step: 7
Training loss: 0.2564790225625198
Validation loss: 2.6337217653074014

Epoch: 6| Step: 8
Training loss: 0.22392719998681748
Validation loss: 2.6575750000766316

Epoch: 6| Step: 9
Training loss: 0.2873060111009514
Validation loss: 2.6381345211635363

Epoch: 6| Step: 10
Training loss: 0.3203086736497056
Validation loss: 2.6501471478616456

Epoch: 6| Step: 11
Training loss: 0.34249153391266385
Validation loss: 2.599372530073304

Epoch: 6| Step: 12
Training loss: 0.50246198814061
Validation loss: 2.598467875486809

Epoch: 6| Step: 13
Training loss: 0.3434913702690066
Validation loss: 2.625535728645916

Epoch: 423| Step: 0
Training loss: 0.3846963732987503
Validation loss: 2.624940977492642

Epoch: 6| Step: 1
Training loss: 0.21648588299097002
Validation loss: 2.620252956683644

Epoch: 6| Step: 2
Training loss: 0.28012711164401183
Validation loss: 2.6227794216407356

Epoch: 6| Step: 3
Training loss: 0.35237154586671476
Validation loss: 2.604397509198176

Epoch: 6| Step: 4
Training loss: 0.3312729310249837
Validation loss: 2.6408085956740988

Epoch: 6| Step: 5
Training loss: 0.34670427262077896
Validation loss: 2.6270603994709107

Epoch: 6| Step: 6
Training loss: 0.45119393695213883
Validation loss: 2.6958387073146866

Epoch: 6| Step: 7
Training loss: 0.35686453635246634
Validation loss: 2.5964398205758883

Epoch: 6| Step: 8
Training loss: 0.3798313841538899
Validation loss: 2.62520680294129

Epoch: 6| Step: 9
Training loss: 0.2729581991775813
Validation loss: 2.623823538045436

Epoch: 6| Step: 10
Training loss: 0.41862884875556117
Validation loss: 2.618167401484412

Epoch: 6| Step: 11
Training loss: 0.43101231341241936
Validation loss: 2.6081500347516484

Epoch: 6| Step: 12
Training loss: 0.3678399842720663
Validation loss: 2.571191129305678

Epoch: 6| Step: 13
Training loss: 0.5275518501254358
Validation loss: 2.597821261487803

Epoch: 424| Step: 0
Training loss: 0.218010418508429
Validation loss: 2.642719093053253

Epoch: 6| Step: 1
Training loss: 0.34275115720496513
Validation loss: 2.5940446035226343

Epoch: 6| Step: 2
Training loss: 0.3502698126552489
Validation loss: 2.623838197856236

Epoch: 6| Step: 3
Training loss: 0.4315951224115996
Validation loss: 2.630398316021502

Epoch: 6| Step: 4
Training loss: 0.5155752042365168
Validation loss: 2.723926774979391

Epoch: 6| Step: 5
Training loss: 0.3126477369134142
Validation loss: 2.5806384694585636

Epoch: 6| Step: 6
Training loss: 0.3008136112589692
Validation loss: 2.651460301009423

Epoch: 6| Step: 7
Training loss: 0.195599650059818
Validation loss: 2.6233086359524855

Epoch: 6| Step: 8
Training loss: 0.41528962594009905
Validation loss: 2.6739152253711636

Epoch: 6| Step: 9
Training loss: 0.38764680419631914
Validation loss: 2.6658624439691176

Epoch: 6| Step: 10
Training loss: 0.37252527490417153
Validation loss: 2.6387299880210553

Epoch: 6| Step: 11
Training loss: 0.38365862233726566
Validation loss: 2.65639689918172

Epoch: 6| Step: 12
Training loss: 0.37406401252281446
Validation loss: 2.556523968565894

Epoch: 6| Step: 13
Training loss: 0.4101702006556051
Validation loss: 2.598322793826231

Epoch: 425| Step: 0
Training loss: 0.4127102669977562
Validation loss: 2.6041219529445816

Epoch: 6| Step: 1
Training loss: 0.29292841315739426
Validation loss: 2.6352847120298506

Epoch: 6| Step: 2
Training loss: 0.30343835256989093
Validation loss: 2.618194894823719

Epoch: 6| Step: 3
Training loss: 0.4005772969594129
Validation loss: 2.6095120970750227

Epoch: 6| Step: 4
Training loss: 0.33045105492222465
Validation loss: 2.5776728532207893

Epoch: 6| Step: 5
Training loss: 0.42544894418557405
Validation loss: 2.6285978365913247

Epoch: 6| Step: 6
Training loss: 0.38253949609679505
Validation loss: 2.6299916747847423

Epoch: 6| Step: 7
Training loss: 0.27870296474887823
Validation loss: 2.685636613675862

Epoch: 6| Step: 8
Training loss: 0.3666855648256938
Validation loss: 2.5929450352476877

Epoch: 6| Step: 9
Training loss: 0.34362733342879553
Validation loss: 2.6263931604094335

Epoch: 6| Step: 10
Training loss: 0.2468284433262238
Validation loss: 2.5917362530883636

Epoch: 6| Step: 11
Training loss: 0.4419628785951792
Validation loss: 2.58759254130367

Epoch: 6| Step: 12
Training loss: 0.3492976242531778
Validation loss: 2.6143454763928213

Epoch: 6| Step: 13
Training loss: 0.3218653186712453
Validation loss: 2.6102109320068902

Epoch: 426| Step: 0
Training loss: 0.3876636021327032
Validation loss: 2.5783263619132835

Epoch: 6| Step: 1
Training loss: 0.31124853842365313
Validation loss: 2.599788240221135

Epoch: 6| Step: 2
Training loss: 0.27157813449712775
Validation loss: 2.652567086721178

Epoch: 6| Step: 3
Training loss: 0.2684036801342082
Validation loss: 2.6538588438683974

Epoch: 6| Step: 4
Training loss: 0.3236749523770648
Validation loss: 2.668884514866302

Epoch: 6| Step: 5
Training loss: 0.3445392023842569
Validation loss: 2.6263460159725

Epoch: 6| Step: 6
Training loss: 0.3463167251579766
Validation loss: 2.636527650289403

Epoch: 6| Step: 7
Training loss: 0.24409438649051712
Validation loss: 2.569885187466523

Epoch: 6| Step: 8
Training loss: 0.2995781306521107
Validation loss: 2.6257997081818703

Epoch: 6| Step: 9
Training loss: 0.29957346744544866
Validation loss: 2.6679928184157164

Epoch: 6| Step: 10
Training loss: 0.2477012689629562
Validation loss: 2.5989996856477906

Epoch: 6| Step: 11
Training loss: 0.41060145602379206
Validation loss: 2.6143812022909616

Epoch: 6| Step: 12
Training loss: 0.3046056319557365
Validation loss: 2.6303447020779758

Epoch: 6| Step: 13
Training loss: 0.2974152417817262
Validation loss: 2.694408585833056

Epoch: 427| Step: 0
Training loss: 0.3688628751338471
Validation loss: 2.652527643120216

Epoch: 6| Step: 1
Training loss: 0.21842668686654512
Validation loss: 2.561817078188048

Epoch: 6| Step: 2
Training loss: 0.24359611061082848
Validation loss: 2.668574921986979

Epoch: 6| Step: 3
Training loss: 0.38637213152583033
Validation loss: 2.679807654709271

Epoch: 6| Step: 4
Training loss: 0.2489811954947622
Validation loss: 2.700409673881767

Epoch: 6| Step: 5
Training loss: 0.19981275152525285
Validation loss: 2.6152765537969724

Epoch: 6| Step: 6
Training loss: 0.390069757666332
Validation loss: 2.6055451267072582

Epoch: 6| Step: 7
Training loss: 0.4129171906065993
Validation loss: 2.623867918553947

Epoch: 6| Step: 8
Training loss: 0.331989947723399
Validation loss: 2.550530834670449

Epoch: 6| Step: 9
Training loss: 0.33078966813869787
Validation loss: 2.61190180158408

Epoch: 6| Step: 10
Training loss: 0.52777991447797
Validation loss: 2.6393834492774526

Epoch: 6| Step: 11
Training loss: 0.3191066000087011
Validation loss: 2.635835445940697

Epoch: 6| Step: 12
Training loss: 0.3123507381647876
Validation loss: 2.6423458082769944

Epoch: 6| Step: 13
Training loss: 0.3952791282831496
Validation loss: 2.682592865165115

Epoch: 428| Step: 0
Training loss: 0.3435102840699836
Validation loss: 2.6422074521524155

Epoch: 6| Step: 1
Training loss: 0.20563060274578523
Validation loss: 2.6225515481630133

Epoch: 6| Step: 2
Training loss: 0.29005349890747717
Validation loss: 2.5791093276577537

Epoch: 6| Step: 3
Training loss: 0.26796324365591573
Validation loss: 2.5465721387154505

Epoch: 6| Step: 4
Training loss: 0.2859706093426831
Validation loss: 2.5981031755208748

Epoch: 6| Step: 5
Training loss: 0.22201395250627837
Validation loss: 2.6355689134209235

Epoch: 6| Step: 6
Training loss: 0.2833313224291032
Validation loss: 2.650880555139323

Epoch: 6| Step: 7
Training loss: 0.34238777309377727
Validation loss: 2.6210057508664364

Epoch: 6| Step: 8
Training loss: 0.29320075703210274
Validation loss: 2.617247426120329

Epoch: 6| Step: 9
Training loss: 0.35422722448333965
Validation loss: 2.6034574890895645

Epoch: 6| Step: 10
Training loss: 0.3988412046015771
Validation loss: 2.6498487495348058

Epoch: 6| Step: 11
Training loss: 0.4013592053290254
Validation loss: 2.616355938492733

Epoch: 6| Step: 12
Training loss: 0.3146852146205858
Validation loss: 2.5880663542193356

Epoch: 6| Step: 13
Training loss: 0.42212514172552484
Validation loss: 2.5866364286521706

Epoch: 429| Step: 0
Training loss: 0.24397812585220785
Validation loss: 2.62392827514377

Epoch: 6| Step: 1
Training loss: 0.3110657202347203
Validation loss: 2.5836563421141614

Epoch: 6| Step: 2
Training loss: 0.41508058228098343
Validation loss: 2.5844628315660843

Epoch: 6| Step: 3
Training loss: 0.37358777043412605
Validation loss: 2.6198931321098873

Epoch: 6| Step: 4
Training loss: 0.3612652698180338
Validation loss: 2.6302327800155982

Epoch: 6| Step: 5
Training loss: 0.3006607904363953
Validation loss: 2.7080869904993783

Epoch: 6| Step: 6
Training loss: 0.21919538932200985
Validation loss: 2.581135650762061

Epoch: 6| Step: 7
Training loss: 0.3356219073460341
Validation loss: 2.629928979422396

Epoch: 6| Step: 8
Training loss: 0.34233819874345944
Validation loss: 2.653276327285976

Epoch: 6| Step: 9
Training loss: 0.37016120991054846
Validation loss: 2.6338025202234663

Epoch: 6| Step: 10
Training loss: 0.4219975117004399
Validation loss: 2.6740026201108367

Epoch: 6| Step: 11
Training loss: 0.2900702206094363
Validation loss: 2.595264008260592

Epoch: 6| Step: 12
Training loss: 0.3847823550851989
Validation loss: 2.589052043825383

Epoch: 6| Step: 13
Training loss: 0.29305020789353997
Validation loss: 2.6486463736329546

Epoch: 430| Step: 0
Training loss: 0.3939646438598882
Validation loss: 2.618533358720957

Epoch: 6| Step: 1
Training loss: 0.3276079281751209
Validation loss: 2.5935295807966967

Epoch: 6| Step: 2
Training loss: 0.42590167591130673
Validation loss: 2.56161717970367

Epoch: 6| Step: 3
Training loss: 0.26978475286886777
Validation loss: 2.678555233618809

Epoch: 6| Step: 4
Training loss: 0.193981681632964
Validation loss: 2.586435613840963

Epoch: 6| Step: 5
Training loss: 0.2735252375848978
Validation loss: 2.619508691347949

Epoch: 6| Step: 6
Training loss: 0.22147344666554317
Validation loss: 2.6047203899428313

Epoch: 6| Step: 7
Training loss: 0.33464709557168143
Validation loss: 2.606605278090655

Epoch: 6| Step: 8
Training loss: 0.365732597755817
Validation loss: 2.6214323777334125

Epoch: 6| Step: 9
Training loss: 0.37379179472058766
Validation loss: 2.5851498236854433

Epoch: 6| Step: 10
Training loss: 0.21915409536321068
Validation loss: 2.5966130430179812

Epoch: 6| Step: 11
Training loss: 0.2991026570974037
Validation loss: 2.662716149643821

Epoch: 6| Step: 12
Training loss: 0.2171135556977378
Validation loss: 2.5762615520842047

Epoch: 6| Step: 13
Training loss: 0.2800649605268164
Validation loss: 2.6203779673032517

Epoch: 431| Step: 0
Training loss: 0.23132291204987573
Validation loss: 2.675544048849958

Epoch: 6| Step: 1
Training loss: 0.28782409147597804
Validation loss: 2.6135602421035196

Epoch: 6| Step: 2
Training loss: 0.31929769491151544
Validation loss: 2.660432671419384

Epoch: 6| Step: 3
Training loss: 0.39171769852985944
Validation loss: 2.630269196564658

Epoch: 6| Step: 4
Training loss: 0.37417239019452675
Validation loss: 2.618252991860779

Epoch: 6| Step: 5
Training loss: 0.2949550812071305
Validation loss: 2.6233721257104046

Epoch: 6| Step: 6
Training loss: 0.19876563208662246
Validation loss: 2.6651454600035813

Epoch: 6| Step: 7
Training loss: 0.318809436885086
Validation loss: 2.636072210469935

Epoch: 6| Step: 8
Training loss: 0.37607250228089933
Validation loss: 2.6934615851859474

Epoch: 6| Step: 9
Training loss: 0.405770844541679
Validation loss: 2.5983562702229337

Epoch: 6| Step: 10
Training loss: 0.27610720750084133
Validation loss: 2.5767748601569225

Epoch: 6| Step: 11
Training loss: 0.34129091143339213
Validation loss: 2.6173559485737945

Epoch: 6| Step: 12
Training loss: 0.3516436801007287
Validation loss: 2.595080972533993

Epoch: 6| Step: 13
Training loss: 0.36643747062494303
Validation loss: 2.5905484582800735

Epoch: 432| Step: 0
Training loss: 0.20362380112657466
Validation loss: 2.621616696049026

Epoch: 6| Step: 1
Training loss: 0.4277506786008855
Validation loss: 2.630513947108688

Epoch: 6| Step: 2
Training loss: 0.32886002730007946
Validation loss: 2.615765981699323

Epoch: 6| Step: 3
Training loss: 0.32123873702020783
Validation loss: 2.636312247129719

Epoch: 6| Step: 4
Training loss: 0.38629508653469063
Validation loss: 2.554272998154316

Epoch: 6| Step: 5
Training loss: 0.25680466378112554
Validation loss: 2.6244813770048436

Epoch: 6| Step: 6
Training loss: 0.3152758810898412
Validation loss: 2.5846142105782817

Epoch: 6| Step: 7
Training loss: 0.27394876366691573
Validation loss: 2.6346327076784535

Epoch: 6| Step: 8
Training loss: 0.24358792112667108
Validation loss: 2.621119128131379

Epoch: 6| Step: 9
Training loss: 0.4708688689496777
Validation loss: 2.5768598053026452

Epoch: 6| Step: 10
Training loss: 0.32886788876195144
Validation loss: 2.666720677861964

Epoch: 6| Step: 11
Training loss: 0.37369508996973266
Validation loss: 2.622019392545611

Epoch: 6| Step: 12
Training loss: 0.2693890735640622
Validation loss: 2.550841817092953

Epoch: 6| Step: 13
Training loss: 0.31865133460139633
Validation loss: 2.600347179683885

Epoch: 433| Step: 0
Training loss: 0.2436990788652123
Validation loss: 2.653938080203086

Epoch: 6| Step: 1
Training loss: 0.37018365187724356
Validation loss: 2.6149651424669194

Epoch: 6| Step: 2
Training loss: 0.24348249612105452
Validation loss: 2.642564005225466

Epoch: 6| Step: 3
Training loss: 0.2687879347088037
Validation loss: 2.5959015467352002

Epoch: 6| Step: 4
Training loss: 0.3145217346783573
Validation loss: 2.655284511650163

Epoch: 6| Step: 5
Training loss: 0.3541857022424446
Validation loss: 2.667665314442339

Epoch: 6| Step: 6
Training loss: 0.3437519073433412
Validation loss: 2.6602412288198414

Epoch: 6| Step: 7
Training loss: 0.3581804033267648
Validation loss: 2.605147052599864

Epoch: 6| Step: 8
Training loss: 0.2232517010120977
Validation loss: 2.6403434497983143

Epoch: 6| Step: 9
Training loss: 0.2921034049326706
Validation loss: 2.620363257804996

Epoch: 6| Step: 10
Training loss: 0.3284260640208636
Validation loss: 2.593577551566795

Epoch: 6| Step: 11
Training loss: 0.3564559725904891
Validation loss: 2.609379659865553

Epoch: 6| Step: 12
Training loss: 0.25830898740601343
Validation loss: 2.64073718131776

Epoch: 6| Step: 13
Training loss: 0.2969426404290869
Validation loss: 2.636045152312207

Epoch: 434| Step: 0
Training loss: 0.48850818700967763
Validation loss: 2.650272630066961

Epoch: 6| Step: 1
Training loss: 0.4616192124636902
Validation loss: 2.5800950355177745

Epoch: 6| Step: 2
Training loss: 0.2837743851186627
Validation loss: 2.6785035256452856

Epoch: 6| Step: 3
Training loss: 0.278682205761594
Validation loss: 2.653761711747615

Epoch: 6| Step: 4
Training loss: 0.4729622410004044
Validation loss: 2.6711179765091884

Epoch: 6| Step: 5
Training loss: 0.27253500639193684
Validation loss: 2.6839511268750136

Epoch: 6| Step: 6
Training loss: 0.4014932847393729
Validation loss: 2.63867484167136

Epoch: 6| Step: 7
Training loss: 0.2996142898017199
Validation loss: 2.5846699953368546

Epoch: 6| Step: 8
Training loss: 0.34837447139506894
Validation loss: 2.669129237939681

Epoch: 6| Step: 9
Training loss: 0.2787805733571491
Validation loss: 2.6386483523404864

Epoch: 6| Step: 10
Training loss: 0.27436544456005446
Validation loss: 2.631822364031363

Epoch: 6| Step: 11
Training loss: 0.30838507828095
Validation loss: 2.6438629417854456

Epoch: 6| Step: 12
Training loss: 0.4069901839204315
Validation loss: 2.578706895298799

Epoch: 6| Step: 13
Training loss: 0.29737821394284775
Validation loss: 2.648482030683584

Epoch: 435| Step: 0
Training loss: 0.27022001470395784
Validation loss: 2.65982837869088

Epoch: 6| Step: 1
Training loss: 0.32789248220787126
Validation loss: 2.6465566252245614

Epoch: 6| Step: 2
Training loss: 0.2660945640771031
Validation loss: 2.6394285090884404

Epoch: 6| Step: 3
Training loss: 0.26420773343897114
Validation loss: 2.6381888805211466

Epoch: 6| Step: 4
Training loss: 0.3796273674462449
Validation loss: 2.5807734901684327

Epoch: 6| Step: 5
Training loss: 0.41274804980246477
Validation loss: 2.638501850545115

Epoch: 6| Step: 6
Training loss: 0.25993138237716173
Validation loss: 2.6244087991569196

Epoch: 6| Step: 7
Training loss: 0.37283454964112084
Validation loss: 2.6380786845474966

Epoch: 6| Step: 8
Training loss: 0.2743517849122834
Validation loss: 2.6442208194767773

Epoch: 6| Step: 9
Training loss: 0.18509647515123281
Validation loss: 2.653402649902146

Epoch: 6| Step: 10
Training loss: 0.5196568616872297
Validation loss: 2.642410171483322

Epoch: 6| Step: 11
Training loss: 0.34241156753807456
Validation loss: 2.6339679148570467

Epoch: 6| Step: 12
Training loss: 0.3394813249329588
Validation loss: 2.634149259199797

Epoch: 6| Step: 13
Training loss: 0.3691428048205729
Validation loss: 2.5841009066162552

Epoch: 436| Step: 0
Training loss: 0.3150188262172834
Validation loss: 2.611460767718716

Epoch: 6| Step: 1
Training loss: 0.3264479011705973
Validation loss: 2.609559301998319

Epoch: 6| Step: 2
Training loss: 0.2820983516300471
Validation loss: 2.5827786762832883

Epoch: 6| Step: 3
Training loss: 0.5265839082797562
Validation loss: 2.586299966876732

Epoch: 6| Step: 4
Training loss: 0.3419736677435131
Validation loss: 2.6094056392249017

Epoch: 6| Step: 5
Training loss: 0.23547735058038247
Validation loss: 2.6315034051141413

Epoch: 6| Step: 6
Training loss: 0.29278930254621854
Validation loss: 2.6765206088180022

Epoch: 6| Step: 7
Training loss: 0.3002634297550856
Validation loss: 2.6744527298544027

Epoch: 6| Step: 8
Training loss: 0.39888237445054947
Validation loss: 2.6220240450943963

Epoch: 6| Step: 9
Training loss: 0.3375431986819019
Validation loss: 2.5565000708644856

Epoch: 6| Step: 10
Training loss: 0.2315150047351092
Validation loss: 2.6258966186202986

Epoch: 6| Step: 11
Training loss: 0.32012869050245807
Validation loss: 2.660919117411391

Epoch: 6| Step: 12
Training loss: 0.2919719778358355
Validation loss: 2.643029842785075

Epoch: 6| Step: 13
Training loss: 0.3462068476279883
Validation loss: 2.6505174374585176

Epoch: 437| Step: 0
Training loss: 0.24124164617483834
Validation loss: 2.5646807532525613

Epoch: 6| Step: 1
Training loss: 0.30807228937458697
Validation loss: 2.6701838921264214

Epoch: 6| Step: 2
Training loss: 0.3448081311773152
Validation loss: 2.6221635571031006

Epoch: 6| Step: 3
Training loss: 0.3878471788121564
Validation loss: 2.6484078224642373

Epoch: 6| Step: 4
Training loss: 0.24617219613168412
Validation loss: 2.6683762901401797

Epoch: 6| Step: 5
Training loss: 0.4647274352654897
Validation loss: 2.673032127100723

Epoch: 6| Step: 6
Training loss: 0.2944831110624112
Validation loss: 2.5679528595181567

Epoch: 6| Step: 7
Training loss: 0.298536020763719
Validation loss: 2.6306009408749826

Epoch: 6| Step: 8
Training loss: 0.24821123549982674
Validation loss: 2.6326119547455926

Epoch: 6| Step: 9
Training loss: 0.2375794613445297
Validation loss: 2.629062188838939

Epoch: 6| Step: 10
Training loss: 0.3203869709810196
Validation loss: 2.6388554635078165

Epoch: 6| Step: 11
Training loss: 0.3229715418591133
Validation loss: 2.599621954967957

Epoch: 6| Step: 12
Training loss: 0.4168220905659777
Validation loss: 2.613153368030947

Epoch: 6| Step: 13
Training loss: 0.29170222860340894
Validation loss: 2.6166149974589232

Epoch: 438| Step: 0
Training loss: 0.2927864015850548
Validation loss: 2.6065201208461395

Epoch: 6| Step: 1
Training loss: 0.38019425440113586
Validation loss: 2.6064486969875458

Epoch: 6| Step: 2
Training loss: 0.2313435568230933
Validation loss: 2.633158177171985

Epoch: 6| Step: 3
Training loss: 0.3171005519777629
Validation loss: 2.6614728704504653

Epoch: 6| Step: 4
Training loss: 0.3930922979511057
Validation loss: 2.6399476275402884

Epoch: 6| Step: 5
Training loss: 0.3357067091628212
Validation loss: 2.616714419599399

Epoch: 6| Step: 6
Training loss: 0.4164962141751056
Validation loss: 2.6345763142005736

Epoch: 6| Step: 7
Training loss: 0.24727346338560793
Validation loss: 2.6367509552672477

Epoch: 6| Step: 8
Training loss: 0.25834844254075384
Validation loss: 2.6341486256251243

Epoch: 6| Step: 9
Training loss: 0.24718723621426672
Validation loss: 2.639554335252488

Epoch: 6| Step: 10
Training loss: 0.4215005696520231
Validation loss: 2.6811029164149995

Epoch: 6| Step: 11
Training loss: 0.4556729272927642
Validation loss: 2.6204996738599826

Epoch: 6| Step: 12
Training loss: 0.2590853021201708
Validation loss: 2.6597922398641853

Epoch: 6| Step: 13
Training loss: 0.31913098632376663
Validation loss: 2.6312993169589176

Epoch: 439| Step: 0
Training loss: 0.2391602531361257
Validation loss: 2.6283806572546022

Epoch: 6| Step: 1
Training loss: 0.35001106202151094
Validation loss: 2.7230573419853044

Epoch: 6| Step: 2
Training loss: 0.30058120912200176
Validation loss: 2.707598547417406

Epoch: 6| Step: 3
Training loss: 0.4081129494679972
Validation loss: 2.6338460008734637

Epoch: 6| Step: 4
Training loss: 0.3188831724333111
Validation loss: 2.6069602833951317

Epoch: 6| Step: 5
Training loss: 0.2512061556949865
Validation loss: 2.652759158039711

Epoch: 6| Step: 6
Training loss: 0.21998175319136443
Validation loss: 2.6624983206969026

Epoch: 6| Step: 7
Training loss: 0.4264058597516783
Validation loss: 2.632567849946771

Epoch: 6| Step: 8
Training loss: 0.2781408567944614
Validation loss: 2.626266612902604

Epoch: 6| Step: 9
Training loss: 0.3939850869854075
Validation loss: 2.67021014302169

Epoch: 6| Step: 10
Training loss: 0.4650587017681927
Validation loss: 2.6160696954347897

Epoch: 6| Step: 11
Training loss: 0.42670906539202086
Validation loss: 2.6269429448910167

Epoch: 6| Step: 12
Training loss: 0.37954253423758244
Validation loss: 2.6401501892698165

Epoch: 6| Step: 13
Training loss: 0.4149617560700964
Validation loss: 2.616883885626888

Epoch: 440| Step: 0
Training loss: 0.3409248563343363
Validation loss: 2.636569774798957

Epoch: 6| Step: 1
Training loss: 0.31736670820020046
Validation loss: 2.591238514122884

Epoch: 6| Step: 2
Training loss: 0.37214571771942195
Validation loss: 2.57686501742155

Epoch: 6| Step: 3
Training loss: 0.2467423022034741
Validation loss: 2.6252312785397334

Epoch: 6| Step: 4
Training loss: 0.2638724800217225
Validation loss: 2.611224693393625

Epoch: 6| Step: 5
Training loss: 0.28065605497252577
Validation loss: 2.6194744082324073

Epoch: 6| Step: 6
Training loss: 0.413737907578702
Validation loss: 2.6277177002912064

Epoch: 6| Step: 7
Training loss: 0.3340101510970888
Validation loss: 2.573607175784789

Epoch: 6| Step: 8
Training loss: 0.37896071367038753
Validation loss: 2.634356701456627

Epoch: 6| Step: 9
Training loss: 0.34123553365918285
Validation loss: 2.579954326777364

Epoch: 6| Step: 10
Training loss: 0.24760875156160653
Validation loss: 2.6279840764966957

Epoch: 6| Step: 11
Training loss: 0.21400530809878282
Validation loss: 2.6285974435501225

Epoch: 6| Step: 12
Training loss: 0.42528424434713535
Validation loss: 2.5871021302713246

Epoch: 6| Step: 13
Training loss: 0.3683280680713068
Validation loss: 2.576465666096211

Epoch: 441| Step: 0
Training loss: 0.3113554498606267
Validation loss: 2.624314082311492

Epoch: 6| Step: 1
Training loss: 0.303720602881397
Validation loss: 2.6038223242394407

Epoch: 6| Step: 2
Training loss: 0.2834558083152951
Validation loss: 2.630326150704122

Epoch: 6| Step: 3
Training loss: 0.3317184657932525
Validation loss: 2.5706324663215336

Epoch: 6| Step: 4
Training loss: 0.2521951976296203
Validation loss: 2.601713021537656

Epoch: 6| Step: 5
Training loss: 0.3597758172628252
Validation loss: 2.5707914453079135

Epoch: 6| Step: 6
Training loss: 0.28218347557129925
Validation loss: 2.6421117114885404

Epoch: 6| Step: 7
Training loss: 0.3273685682625544
Validation loss: 2.613152546889878

Epoch: 6| Step: 8
Training loss: 0.32690698623975445
Validation loss: 2.5683828065139367

Epoch: 6| Step: 9
Training loss: 0.27337748005042506
Validation loss: 2.6139775571153985

Epoch: 6| Step: 10
Training loss: 0.22739920185673734
Validation loss: 2.637848396853911

Epoch: 6| Step: 11
Training loss: 0.3304828893283536
Validation loss: 2.6513785627201885

Epoch: 6| Step: 12
Training loss: 0.36519685848348304
Validation loss: 2.5877896347973572

Epoch: 6| Step: 13
Training loss: 0.2401902615743042
Validation loss: 2.639316799092115

Epoch: 442| Step: 0
Training loss: 0.2827715512131234
Validation loss: 2.616780445840537

Epoch: 6| Step: 1
Training loss: 0.2537698379288092
Validation loss: 2.6160773660513983

Epoch: 6| Step: 2
Training loss: 0.2919098600853075
Validation loss: 2.6472958004699727

Epoch: 6| Step: 3
Training loss: 0.3418202310484048
Validation loss: 2.618510338036933

Epoch: 6| Step: 4
Training loss: 0.27965749121422584
Validation loss: 2.6556067791214413

Epoch: 6| Step: 5
Training loss: 0.34120164540853914
Validation loss: 2.6355722755861697

Epoch: 6| Step: 6
Training loss: 0.24670363345472196
Validation loss: 2.5920923750187788

Epoch: 6| Step: 7
Training loss: 0.4107969457066142
Validation loss: 2.6075817502045133

Epoch: 6| Step: 8
Training loss: 0.33214269899365984
Validation loss: 2.66498586215527

Epoch: 6| Step: 9
Training loss: 0.3029515379668813
Validation loss: 2.6133144739583116

Epoch: 6| Step: 10
Training loss: 0.2956255419203971
Validation loss: 2.600070384185514

Epoch: 6| Step: 11
Training loss: 0.26867288935925454
Validation loss: 2.6360354972310307

Epoch: 6| Step: 12
Training loss: 0.34209291988713597
Validation loss: 2.6775930243537744

Epoch: 6| Step: 13
Training loss: 0.24644354528935378
Validation loss: 2.63588159151752

Epoch: 443| Step: 0
Training loss: 0.2943880416022212
Validation loss: 2.604463290805279

Epoch: 6| Step: 1
Training loss: 0.28837233709338544
Validation loss: 2.652946167794763

Epoch: 6| Step: 2
Training loss: 0.3406419806666249
Validation loss: 2.641590716797475

Epoch: 6| Step: 3
Training loss: 0.24472640144848223
Validation loss: 2.590449397106479

Epoch: 6| Step: 4
Training loss: 0.29201763896950816
Validation loss: 2.5885715111918732

Epoch: 6| Step: 5
Training loss: 0.33879715253490217
Validation loss: 2.5839743946792884

Epoch: 6| Step: 6
Training loss: 0.2460471063642964
Validation loss: 2.5590048733886332

Epoch: 6| Step: 7
Training loss: 0.24226295157258054
Validation loss: 2.686517639412742

Epoch: 6| Step: 8
Training loss: 0.40453784782536867
Validation loss: 2.599815813289666

Epoch: 6| Step: 9
Training loss: 0.31422657832139983
Validation loss: 2.5769771139776463

Epoch: 6| Step: 10
Training loss: 0.305048142252969
Validation loss: 2.658253292046663

Epoch: 6| Step: 11
Training loss: 0.40682114287171095
Validation loss: 2.591028900319515

Epoch: 6| Step: 12
Training loss: 0.2906630511651416
Validation loss: 2.623507468960624

Epoch: 6| Step: 13
Training loss: 0.2531983704842958
Validation loss: 2.561714129391903

Epoch: 444| Step: 0
Training loss: 0.31074895222012316
Validation loss: 2.6432665341496726

Epoch: 6| Step: 1
Training loss: 0.22480465236898856
Validation loss: 2.645790870706234

Epoch: 6| Step: 2
Training loss: 0.2649464917143041
Validation loss: 2.6541693223813203

Epoch: 6| Step: 3
Training loss: 0.26026953673527686
Validation loss: 2.658645865824197

Epoch: 6| Step: 4
Training loss: 0.34268926472742595
Validation loss: 2.6146512776294304

Epoch: 6| Step: 5
Training loss: 0.3201148307113053
Validation loss: 2.647601157799288

Epoch: 6| Step: 6
Training loss: 0.21266236448501702
Validation loss: 2.640532279408823

Epoch: 6| Step: 7
Training loss: 0.2903094588614214
Validation loss: 2.613830797529832

Epoch: 6| Step: 8
Training loss: 0.3213235436578281
Validation loss: 2.634927588655596

Epoch: 6| Step: 9
Training loss: 0.34539886059247304
Validation loss: 2.640857054316055

Epoch: 6| Step: 10
Training loss: 0.20105714211337603
Validation loss: 2.6196321523550874

Epoch: 6| Step: 11
Training loss: 0.282316332205182
Validation loss: 2.6305487434498622

Epoch: 6| Step: 12
Training loss: 0.27220105865554334
Validation loss: 2.6606297456691395

Epoch: 6| Step: 13
Training loss: 0.35976832054362656
Validation loss: 2.6156022846020988

Epoch: 445| Step: 0
Training loss: 0.34923874799915766
Validation loss: 2.7332778909534254

Epoch: 6| Step: 1
Training loss: 0.2672969426659911
Validation loss: 2.6505432609698154

Epoch: 6| Step: 2
Training loss: 0.2599323856027641
Validation loss: 2.6244868882061825

Epoch: 6| Step: 3
Training loss: 0.26037875217365825
Validation loss: 2.669450950438208

Epoch: 6| Step: 4
Training loss: 0.3244142287757443
Validation loss: 2.637783681308889

Epoch: 6| Step: 5
Training loss: 0.29372765476378737
Validation loss: 2.6319024449746395

Epoch: 6| Step: 6
Training loss: 0.1799421993144148
Validation loss: 2.6332351390622453

Epoch: 6| Step: 7
Training loss: 0.31266501361512294
Validation loss: 2.639543631680855

Epoch: 6| Step: 8
Training loss: 0.42422955044368404
Validation loss: 2.6299670470703127

Epoch: 6| Step: 9
Training loss: 0.3758932046011674
Validation loss: 2.6942531107013545

Epoch: 6| Step: 10
Training loss: 0.30484623319943066
Validation loss: 2.6016353180768577

Epoch: 6| Step: 11
Training loss: 0.2365067650158087
Validation loss: 2.6199057663528063

Epoch: 6| Step: 12
Training loss: 0.3058066111881941
Validation loss: 2.6328387009159315

Epoch: 6| Step: 13
Training loss: 0.27759454697384284
Validation loss: 2.643092144701561

Epoch: 446| Step: 0
Training loss: 0.25385110696465213
Validation loss: 2.6153271036419885

Epoch: 6| Step: 1
Training loss: 0.342685873035755
Validation loss: 2.679371866186249

Epoch: 6| Step: 2
Training loss: 0.27095152342340423
Validation loss: 2.6348818561771137

Epoch: 6| Step: 3
Training loss: 0.22511619938334518
Validation loss: 2.6840765387835304

Epoch: 6| Step: 4
Training loss: 0.3782299731487703
Validation loss: 2.6338486108965844

Epoch: 6| Step: 5
Training loss: 0.24896367421799107
Validation loss: 2.6514276899222184

Epoch: 6| Step: 6
Training loss: 0.2916404876994789
Validation loss: 2.660886301177903

Epoch: 6| Step: 7
Training loss: 0.38140122431812107
Validation loss: 2.589895755174717

Epoch: 6| Step: 8
Training loss: 0.3329882909696579
Validation loss: 2.67841554339497

Epoch: 6| Step: 9
Training loss: 0.36105511635706683
Validation loss: 2.630386910498088

Epoch: 6| Step: 10
Training loss: 0.272205602304502
Validation loss: 2.608193112728777

Epoch: 6| Step: 11
Training loss: 0.38244065890291046
Validation loss: 2.6920942913620216

Epoch: 6| Step: 12
Training loss: 0.38258232281099336
Validation loss: 2.6467909594288375

Epoch: 6| Step: 13
Training loss: 0.3709505105890364
Validation loss: 2.649505504919427

Epoch: 447| Step: 0
Training loss: 0.17999435222229204
Validation loss: 2.6018048880901308

Epoch: 6| Step: 1
Training loss: 0.570534310252805
Validation loss: 2.597248116079121

Epoch: 6| Step: 2
Training loss: 0.22904117175282337
Validation loss: 2.5888234579315896

Epoch: 6| Step: 3
Training loss: 0.266190893771841
Validation loss: 2.6259116300360037

Epoch: 6| Step: 4
Training loss: 0.36727070372996806
Validation loss: 2.641839675372353

Epoch: 6| Step: 5
Training loss: 0.3200205426029898
Validation loss: 2.551466627280103

Epoch: 6| Step: 6
Training loss: 0.2266830830481594
Validation loss: 2.6741979959455064

Epoch: 6| Step: 7
Training loss: 0.3462591495062488
Validation loss: 2.6404214212468

Epoch: 6| Step: 8
Training loss: 0.3994401582806417
Validation loss: 2.6117323317932026

Epoch: 6| Step: 9
Training loss: 0.3073155453127439
Validation loss: 2.689688560285005

Epoch: 6| Step: 10
Training loss: 0.4679201409722434
Validation loss: 2.659327104722165

Epoch: 6| Step: 11
Training loss: 0.4400698085969549
Validation loss: 2.6412485955122227

Epoch: 6| Step: 12
Training loss: 0.3370156950316727
Validation loss: 2.5875855540753085

Epoch: 6| Step: 13
Training loss: 0.3449092953419533
Validation loss: 2.585353005419813

Epoch: 448| Step: 0
Training loss: 0.259640254693342
Validation loss: 2.652816303388404

Epoch: 6| Step: 1
Training loss: 0.32770808163314114
Validation loss: 2.61526704235533

Epoch: 6| Step: 2
Training loss: 0.2927571231706779
Validation loss: 2.5844516230782615

Epoch: 6| Step: 3
Training loss: 0.3035495979609911
Validation loss: 2.6598998481616114

Epoch: 6| Step: 4
Training loss: 0.25776439275711227
Validation loss: 2.5693707194934854

Epoch: 6| Step: 5
Training loss: 0.2277931137627447
Validation loss: 2.595343089052619

Epoch: 6| Step: 6
Training loss: 0.3459585291631335
Validation loss: 2.6163576698899935

Epoch: 6| Step: 7
Training loss: 0.26926882034129773
Validation loss: 2.586049564388132

Epoch: 6| Step: 8
Training loss: 0.3209620379657096
Validation loss: 2.6600816803057827

Epoch: 6| Step: 9
Training loss: 0.2728429188106723
Validation loss: 2.6291531451119905

Epoch: 6| Step: 10
Training loss: 0.3826604463309016
Validation loss: 2.5966946306261343

Epoch: 6| Step: 11
Training loss: 0.2884905802033508
Validation loss: 2.668054507633365

Epoch: 6| Step: 12
Training loss: 0.35649904865041654
Validation loss: 2.6338573310706814

Epoch: 6| Step: 13
Training loss: 0.23451429836963658
Validation loss: 2.6193509397901265

Epoch: 449| Step: 0
Training loss: 0.3249717608434429
Validation loss: 2.6548751339641994

Epoch: 6| Step: 1
Training loss: 0.40381106614597934
Validation loss: 2.6465793719256685

Epoch: 6| Step: 2
Training loss: 0.2780207577921218
Validation loss: 2.6143882546973076

Epoch: 6| Step: 3
Training loss: 0.31712028796657704
Validation loss: 2.6634867503731363

Epoch: 6| Step: 4
Training loss: 0.35456714940969025
Validation loss: 2.6804226459128326

Epoch: 6| Step: 5
Training loss: 0.39905100693130546
Validation loss: 2.673734334002435

Epoch: 6| Step: 6
Training loss: 0.4285546193771718
Validation loss: 2.5785985800683937

Epoch: 6| Step: 7
Training loss: 0.249032054078868
Validation loss: 2.636340651541499

Epoch: 6| Step: 8
Training loss: 0.42897505217040044
Validation loss: 2.6642755179013475

Epoch: 6| Step: 9
Training loss: 0.37404170377663926
Validation loss: 2.6168090242995103

Epoch: 6| Step: 10
Training loss: 0.28931449525367203
Validation loss: 2.6460451106423566

Epoch: 6| Step: 11
Training loss: 0.2653358652949133
Validation loss: 2.637058520618993

Epoch: 6| Step: 12
Training loss: 0.32291154575389275
Validation loss: 2.634510447382657

Epoch: 6| Step: 13
Training loss: 0.34928369536904325
Validation loss: 2.660499106264768

Epoch: 450| Step: 0
Training loss: 0.2790843448440235
Validation loss: 2.6155471139946447

Epoch: 6| Step: 1
Training loss: 0.37984462438221467
Validation loss: 2.613412151469937

Epoch: 6| Step: 2
Training loss: 0.2860357621207028
Validation loss: 2.675372060409747

Epoch: 6| Step: 3
Training loss: 0.6368440376070316
Validation loss: 2.6867162907263675

Epoch: 6| Step: 4
Training loss: 0.3126184477441666
Validation loss: 2.6482771353243546

Epoch: 6| Step: 5
Training loss: 0.3710886904722935
Validation loss: 2.65570813056159

Epoch: 6| Step: 6
Training loss: 0.2559344931252346
Validation loss: 2.6346459122352224

Epoch: 6| Step: 7
Training loss: 0.2870348360006881
Validation loss: 2.5894837433704363

Epoch: 6| Step: 8
Training loss: 0.45589275875285806
Validation loss: 2.7120686643712366

Epoch: 6| Step: 9
Training loss: 0.39743757999405566
Validation loss: 2.618525983626025

Epoch: 6| Step: 10
Training loss: 0.2458697995453803
Validation loss: 2.6500365869527562

Epoch: 6| Step: 11
Training loss: 0.3126161955341396
Validation loss: 2.6411307112112237

Epoch: 6| Step: 12
Training loss: 0.40747977235825344
Validation loss: 2.645020665494861

Epoch: 6| Step: 13
Training loss: 0.3057144416022763
Validation loss: 2.6150386510099306

Epoch: 451| Step: 0
Training loss: 0.41593679836451897
Validation loss: 2.6752103098969537

Epoch: 6| Step: 1
Training loss: 0.36841625207358375
Validation loss: 2.596163473265387

Epoch: 6| Step: 2
Training loss: 0.29221009253808156
Validation loss: 2.6817339616736118

Epoch: 6| Step: 3
Training loss: 0.30890029457692
Validation loss: 2.6105385354332338

Epoch: 6| Step: 4
Training loss: 0.284638653614919
Validation loss: 2.6196538283462303

Epoch: 6| Step: 5
Training loss: 0.3014718092301215
Validation loss: 2.689890892139397

Epoch: 6| Step: 6
Training loss: 0.23638423537313286
Validation loss: 2.596700728743531

Epoch: 6| Step: 7
Training loss: 0.30842312791881865
Validation loss: 2.6278508766478907

Epoch: 6| Step: 8
Training loss: 0.3768530599176586
Validation loss: 2.6352639637811057

Epoch: 6| Step: 9
Training loss: 0.375371351749604
Validation loss: 2.6842535060260304

Epoch: 6| Step: 10
Training loss: 0.3133954807842388
Validation loss: 2.634380006012359

Epoch: 6| Step: 11
Training loss: 0.32583783799461713
Validation loss: 2.6903429593174892

Epoch: 6| Step: 12
Training loss: 0.3541399884928267
Validation loss: 2.6094466178644415

Epoch: 6| Step: 13
Training loss: 0.33774570157543954
Validation loss: 2.6726299208394484

Epoch: 452| Step: 0
Training loss: 0.3080128018030143
Validation loss: 2.6143186873486535

Epoch: 6| Step: 1
Training loss: 0.2979725576316504
Validation loss: 2.6447688286661553

Epoch: 6| Step: 2
Training loss: 0.30061320775432643
Validation loss: 2.6586235661254154

Epoch: 6| Step: 3
Training loss: 0.3030762864326665
Validation loss: 2.638580463745162

Epoch: 6| Step: 4
Training loss: 0.2535391868610046
Validation loss: 2.6473485307647127

Epoch: 6| Step: 5
Training loss: 0.28888470104638153
Validation loss: 2.6374791384048195

Epoch: 6| Step: 6
Training loss: 0.34934749065047743
Validation loss: 2.650088130637061

Epoch: 6| Step: 7
Training loss: 0.2857549209521435
Validation loss: 2.6619757630180843

Epoch: 6| Step: 8
Training loss: 0.22887569164929972
Validation loss: 2.5871497901625404

Epoch: 6| Step: 9
Training loss: 0.3622896751727837
Validation loss: 2.6157512462658814

Epoch: 6| Step: 10
Training loss: 0.2799366911774023
Validation loss: 2.607333452532785

Epoch: 6| Step: 11
Training loss: 0.2244127988987234
Validation loss: 2.62444270742601

Epoch: 6| Step: 12
Training loss: 0.28403524286915866
Validation loss: 2.632992958049772

Epoch: 6| Step: 13
Training loss: 0.32401236894039115
Validation loss: 2.6784114338759895

Epoch: 453| Step: 0
Training loss: 0.37841204238680964
Validation loss: 2.6600679820797986

Epoch: 6| Step: 1
Training loss: 0.30672764606371394
Validation loss: 2.7138778761353173

Epoch: 6| Step: 2
Training loss: 0.44119102159514006
Validation loss: 2.651011263829777

Epoch: 6| Step: 3
Training loss: 0.3802072272437045
Validation loss: 2.645575883810309

Epoch: 6| Step: 4
Training loss: 0.3095643918406863
Validation loss: 2.66257998625433

Epoch: 6| Step: 5
Training loss: 0.3862958580250271
Validation loss: 2.632730499711183

Epoch: 6| Step: 6
Training loss: 0.4301475143238416
Validation loss: 2.633445407096122

Epoch: 6| Step: 7
Training loss: 0.24069263975241936
Validation loss: 2.6082202693902685

Epoch: 6| Step: 8
Training loss: 0.3241446536777578
Validation loss: 2.6973681364806077

Epoch: 6| Step: 9
Training loss: 0.27591039427257597
Validation loss: 2.635824787569459

Epoch: 6| Step: 10
Training loss: 0.2351628571909643
Validation loss: 2.646250659340098

Epoch: 6| Step: 11
Training loss: 0.3738029168537668
Validation loss: 2.681227853916241

Epoch: 6| Step: 12
Training loss: 0.26281057899126825
Validation loss: 2.608431959775875

Epoch: 6| Step: 13
Training loss: 0.29535423569213065
Validation loss: 2.6684512385811248

Epoch: 454| Step: 0
Training loss: 0.407846577999981
Validation loss: 2.6983796217115077

Epoch: 6| Step: 1
Training loss: 0.19991245290803017
Validation loss: 2.658078405858504

Epoch: 6| Step: 2
Training loss: 0.24662319632893942
Validation loss: 2.6172242422988377

Epoch: 6| Step: 3
Training loss: 0.34863606085452725
Validation loss: 2.606337509698673

Epoch: 6| Step: 4
Training loss: 0.3300002643916487
Validation loss: 2.595468587543327

Epoch: 6| Step: 5
Training loss: 0.26471057739449483
Validation loss: 2.6312921739643107

Epoch: 6| Step: 6
Training loss: 0.4410117420333067
Validation loss: 2.619330550781245

Epoch: 6| Step: 7
Training loss: 0.29089040430358426
Validation loss: 2.6407922846006446

Epoch: 6| Step: 8
Training loss: 0.21706002391399157
Validation loss: 2.6398449710641043

Epoch: 6| Step: 9
Training loss: 0.35801114561003816
Validation loss: 2.616361922439805

Epoch: 6| Step: 10
Training loss: 0.3629141973388847
Validation loss: 2.5961073997613977

Epoch: 6| Step: 11
Training loss: 0.44130227881495193
Validation loss: 2.6695782343319236

Epoch: 6| Step: 12
Training loss: 0.31375239468226784
Validation loss: 2.6013814655050265

Epoch: 6| Step: 13
Training loss: 0.3203222343082191
Validation loss: 2.605198088794462

Epoch: 455| Step: 0
Training loss: 0.37900475077054596
Validation loss: 2.640029095106478

Epoch: 6| Step: 1
Training loss: 0.2737354834727005
Validation loss: 2.665499615599276

Epoch: 6| Step: 2
Training loss: 0.3459751976652123
Validation loss: 2.605523592606685

Epoch: 6| Step: 3
Training loss: 0.3568643275734475
Validation loss: 2.620420192203181

Epoch: 6| Step: 4
Training loss: 0.38225965088636105
Validation loss: 2.597376467521218

Epoch: 6| Step: 5
Training loss: 0.382330064984636
Validation loss: 2.5916034441368114

Epoch: 6| Step: 6
Training loss: 0.2691167878998935
Validation loss: 2.615053010577081

Epoch: 6| Step: 7
Training loss: 0.3568330510967005
Validation loss: 2.6168721478767605

Epoch: 6| Step: 8
Training loss: 0.2914292385248288
Validation loss: 2.628450714139793

Epoch: 6| Step: 9
Training loss: 0.32377266357143814
Validation loss: 2.602098594928228

Epoch: 6| Step: 10
Training loss: 0.25958987435712455
Validation loss: 2.5758120555692026

Epoch: 6| Step: 11
Training loss: 0.22369242377563114
Validation loss: 2.6444535725322047

Epoch: 6| Step: 12
Training loss: 0.33823132840378095
Validation loss: 2.597660372546756

Epoch: 6| Step: 13
Training loss: 0.3790648020511676
Validation loss: 2.668419669059306

Epoch: 456| Step: 0
Training loss: 0.2834026291666719
Validation loss: 2.690676239033821

Epoch: 6| Step: 1
Training loss: 0.35208251429167214
Validation loss: 2.6505111033512847

Epoch: 6| Step: 2
Training loss: 0.29882096924036805
Validation loss: 2.621551428232744

Epoch: 6| Step: 3
Training loss: 0.21250225654974686
Validation loss: 2.6556503217361813

Epoch: 6| Step: 4
Training loss: 0.2385142234913508
Validation loss: 2.6315588225465185

Epoch: 6| Step: 5
Training loss: 0.3032554940396649
Validation loss: 2.6053713695013565

Epoch: 6| Step: 6
Training loss: 0.3565270735102918
Validation loss: 2.651736085447805

Epoch: 6| Step: 7
Training loss: 0.2728165797292306
Validation loss: 2.635921020395999

Epoch: 6| Step: 8
Training loss: 0.31085822853707207
Validation loss: 2.6917367260754643

Epoch: 6| Step: 9
Training loss: 0.34817259730224026
Validation loss: 2.649007205209789

Epoch: 6| Step: 10
Training loss: 0.379238572830518
Validation loss: 2.6207845233522367

Epoch: 6| Step: 11
Training loss: 0.1784582592634994
Validation loss: 2.675666944006755

Epoch: 6| Step: 12
Training loss: 0.2937929385842138
Validation loss: 2.594711324723362

Epoch: 6| Step: 13
Training loss: 0.28699805248908955
Validation loss: 2.639524889035265

Epoch: 457| Step: 0
Training loss: 0.36398683752245087
Validation loss: 2.6289736931337

Epoch: 6| Step: 1
Training loss: 0.3573890837755928
Validation loss: 2.618988829217125

Epoch: 6| Step: 2
Training loss: 0.3762311197530812
Validation loss: 2.6226766764860767

Epoch: 6| Step: 3
Training loss: 0.22407712484324996
Validation loss: 2.6327197306633496

Epoch: 6| Step: 4
Training loss: 0.23844242898288587
Validation loss: 2.654168454044365

Epoch: 6| Step: 5
Training loss: 0.47908066067547583
Validation loss: 2.624545625689403

Epoch: 6| Step: 6
Training loss: 0.3400040391022923
Validation loss: 2.600324104966876

Epoch: 6| Step: 7
Training loss: 0.29601932486071625
Validation loss: 2.6173503160837446

Epoch: 6| Step: 8
Training loss: 0.2656860842311471
Validation loss: 2.6177605755945454

Epoch: 6| Step: 9
Training loss: 0.28289295179773905
Validation loss: 2.6002722090274015

Epoch: 6| Step: 10
Training loss: 0.40425056155395195
Validation loss: 2.592092681616089

Epoch: 6| Step: 11
Training loss: 0.2623318281071953
Validation loss: 2.6285768163630254

Epoch: 6| Step: 12
Training loss: 0.3846532008717857
Validation loss: 2.6490079102331467

Epoch: 6| Step: 13
Training loss: 0.33208965461024237
Validation loss: 2.6419978363404617

Epoch: 458| Step: 0
Training loss: 0.35019562227115236
Validation loss: 2.596551584730514

Epoch: 6| Step: 1
Training loss: 0.29476982896255216
Validation loss: 2.6706725123207056

Epoch: 6| Step: 2
Training loss: 0.24394072168701889
Validation loss: 2.615819271625479

Epoch: 6| Step: 3
Training loss: 0.44177863355731894
Validation loss: 2.604104122682375

Epoch: 6| Step: 4
Training loss: 0.27755468701724384
Validation loss: 2.643728084488404

Epoch: 6| Step: 5
Training loss: 0.3737764464306421
Validation loss: 2.619914775607662

Epoch: 6| Step: 6
Training loss: 0.1592183095497276
Validation loss: 2.6240038268257164

Epoch: 6| Step: 7
Training loss: 0.3187065104193332
Validation loss: 2.5767934269668973

Epoch: 6| Step: 8
Training loss: 0.3065347427960965
Validation loss: 2.6320769039854732

Epoch: 6| Step: 9
Training loss: 0.30660398227894936
Validation loss: 2.6447260384356865

Epoch: 6| Step: 10
Training loss: 0.18973484918924177
Validation loss: 2.6381864404742417

Epoch: 6| Step: 11
Training loss: 0.24914649466020566
Validation loss: 2.609719944613942

Epoch: 6| Step: 12
Training loss: 0.18494684675253295
Validation loss: 2.6443414361732533

Epoch: 6| Step: 13
Training loss: 0.2789266707053106
Validation loss: 2.695247070697768

Epoch: 459| Step: 0
Training loss: 0.3222293486551582
Validation loss: 2.6484816405932454

Epoch: 6| Step: 1
Training loss: 0.23016225510459223
Validation loss: 2.6091507683993216

Epoch: 6| Step: 2
Training loss: 0.3190482357210413
Validation loss: 2.602823419644579

Epoch: 6| Step: 3
Training loss: 0.2337000187308239
Validation loss: 2.675667196474379

Epoch: 6| Step: 4
Training loss: 0.37853340603190716
Validation loss: 2.582675378339993

Epoch: 6| Step: 5
Training loss: 0.22332940487970956
Validation loss: 2.625245287197944

Epoch: 6| Step: 6
Training loss: 0.26751176331404697
Validation loss: 2.6711605373474177

Epoch: 6| Step: 7
Training loss: 0.3260174002874448
Validation loss: 2.595184856156612

Epoch: 6| Step: 8
Training loss: 0.4921058253989778
Validation loss: 2.607563890263873

Epoch: 6| Step: 9
Training loss: 0.24241569750896877
Validation loss: 2.6453354634916026

Epoch: 6| Step: 10
Training loss: 0.3133312613506664
Validation loss: 2.6226410787410823

Epoch: 6| Step: 11
Training loss: 0.2442762837211977
Validation loss: 2.6526747783972437

Epoch: 6| Step: 12
Training loss: 0.3009960844032366
Validation loss: 2.597211037632687

Epoch: 6| Step: 13
Training loss: 0.43453353554770296
Validation loss: 2.65814587122436

Epoch: 460| Step: 0
Training loss: 0.5463776643086345
Validation loss: 2.5757073057508446

Epoch: 6| Step: 1
Training loss: 0.26190511985492193
Validation loss: 2.6588713184268014

Epoch: 6| Step: 2
Training loss: 0.40951928224218265
Validation loss: 2.6544743455883153

Epoch: 6| Step: 3
Training loss: 0.36533223845295765
Validation loss: 2.5953049728710043

Epoch: 6| Step: 4
Training loss: 0.40722784321169636
Validation loss: 2.607505890329693

Epoch: 6| Step: 5
Training loss: 0.34796446093145716
Validation loss: 2.624916574878179

Epoch: 6| Step: 6
Training loss: 0.2712119952179432
Validation loss: 2.636872312995438

Epoch: 6| Step: 7
Training loss: 0.27989250640160146
Validation loss: 2.6241342236994827

Epoch: 6| Step: 8
Training loss: 0.2515234721456718
Validation loss: 2.6103543025729166

Epoch: 6| Step: 9
Training loss: 0.2091181674395181
Validation loss: 2.6331398946197604

Epoch: 6| Step: 10
Training loss: 0.40331068789472424
Validation loss: 2.6185160894331196

Epoch: 6| Step: 11
Training loss: 0.2590216976562388
Validation loss: 2.6381234653965193

Epoch: 6| Step: 12
Training loss: 0.3374391085831352
Validation loss: 2.6808467392788335

Epoch: 6| Step: 13
Training loss: 0.24719408576284546
Validation loss: 2.64906356148494

Epoch: 461| Step: 0
Training loss: 0.4097463466884073
Validation loss: 2.5603598830214738

Epoch: 6| Step: 1
Training loss: 0.25238725682820723
Validation loss: 2.6672041073270742

Epoch: 6| Step: 2
Training loss: 0.29703058382187353
Validation loss: 2.6284845475904928

Epoch: 6| Step: 3
Training loss: 0.3436195386061966
Validation loss: 2.601401361280654

Epoch: 6| Step: 4
Training loss: 0.29617754673941976
Validation loss: 2.5669921252713532

Epoch: 6| Step: 5
Training loss: 0.34950124677482086
Validation loss: 2.6107453880348466

Epoch: 6| Step: 6
Training loss: 0.3203339336946527
Validation loss: 2.6282606839033265

Epoch: 6| Step: 7
Training loss: 0.21742394975775048
Validation loss: 2.598946998790623

Epoch: 6| Step: 8
Training loss: 0.32406097617752117
Validation loss: 2.6303074556815753

Epoch: 6| Step: 9
Training loss: 0.2507198668608026
Validation loss: 2.6000683133614237

Epoch: 6| Step: 10
Training loss: 0.27971230135871955
Validation loss: 2.610823893363081

Epoch: 6| Step: 11
Training loss: 0.33323539720708417
Validation loss: 2.6517399815610827

Epoch: 6| Step: 12
Training loss: 0.4509484865115194
Validation loss: 2.6258987296058174

Epoch: 6| Step: 13
Training loss: 0.31943284177210574
Validation loss: 2.6208278712552824

Epoch: 462| Step: 0
Training loss: 0.28546023169776114
Validation loss: 2.650103454849649

Epoch: 6| Step: 1
Training loss: 0.282332839227238
Validation loss: 2.591375995682104

Epoch: 6| Step: 2
Training loss: 0.31520022617376753
Validation loss: 2.5952423122958366

Epoch: 6| Step: 3
Training loss: 0.2870398456696427
Validation loss: 2.6172283567968813

Epoch: 6| Step: 4
Training loss: 0.2927622512400669
Validation loss: 2.6037271713694294

Epoch: 6| Step: 5
Training loss: 0.2535209520012471
Validation loss: 2.585528538261355

Epoch: 6| Step: 6
Training loss: 0.2874960080159892
Validation loss: 2.653048961375015

Epoch: 6| Step: 7
Training loss: 0.1988728737079068
Validation loss: 2.6113220686498733

Epoch: 6| Step: 8
Training loss: 0.22100028566303173
Validation loss: 2.599565367561434

Epoch: 6| Step: 9
Training loss: 0.37473172287145035
Validation loss: 2.615919210096371

Epoch: 6| Step: 10
Training loss: 0.2741023699729652
Validation loss: 2.5643984732381395

Epoch: 6| Step: 11
Training loss: 0.2546897975841399
Validation loss: 2.6334732690481397

Epoch: 6| Step: 12
Training loss: 0.29792085685762076
Validation loss: 2.6311117200843577

Epoch: 6| Step: 13
Training loss: 0.30236861991616953
Validation loss: 2.5740653857255524

Epoch: 463| Step: 0
Training loss: 0.2482661607092984
Validation loss: 2.614075346658822

Epoch: 6| Step: 1
Training loss: 0.25862375413789085
Validation loss: 2.648495893856776

Epoch: 6| Step: 2
Training loss: 0.3279438654167494
Validation loss: 2.6493370156498535

Epoch: 6| Step: 3
Training loss: 0.3880344704230685
Validation loss: 2.5989171765775723

Epoch: 6| Step: 4
Training loss: 0.33545118439610705
Validation loss: 2.6484843712244093

Epoch: 6| Step: 5
Training loss: 0.3000344380838206
Validation loss: 2.648771401871393

Epoch: 6| Step: 6
Training loss: 0.3020486756975038
Validation loss: 2.605133019759036

Epoch: 6| Step: 7
Training loss: 0.27909057841166296
Validation loss: 2.6155198435000555

Epoch: 6| Step: 8
Training loss: 0.2533907719536599
Validation loss: 2.6429823035105864

Epoch: 6| Step: 9
Training loss: 0.33389542047542486
Validation loss: 2.6443648105161452

Epoch: 6| Step: 10
Training loss: 0.19175594848796107
Validation loss: 2.6557796660252455

Epoch: 6| Step: 11
Training loss: 0.3173919911157762
Validation loss: 2.588560312819276

Epoch: 6| Step: 12
Training loss: 0.29162191433670065
Validation loss: 2.600302298407051

Epoch: 6| Step: 13
Training loss: 0.23435443152137658
Validation loss: 2.6212422252582783

Epoch: 464| Step: 0
Training loss: 0.32145473301853894
Validation loss: 2.6032068747245423

Epoch: 6| Step: 1
Training loss: 0.233153242338502
Validation loss: 2.5809179340284016

Epoch: 6| Step: 2
Training loss: 0.2656692580208781
Validation loss: 2.6121733198082584

Epoch: 6| Step: 3
Training loss: 0.35877326677217525
Validation loss: 2.6737696453393465

Epoch: 6| Step: 4
Training loss: 0.2932303595758614
Validation loss: 2.6502210674805107

Epoch: 6| Step: 5
Training loss: 0.34663326328689076
Validation loss: 2.625361039295277

Epoch: 6| Step: 6
Training loss: 0.2659726112308651
Validation loss: 2.6292817904199697

Epoch: 6| Step: 7
Training loss: 0.30300080665396023
Validation loss: 2.6804142328891016

Epoch: 6| Step: 8
Training loss: 0.34439728223434996
Validation loss: 2.629014502795722

Epoch: 6| Step: 9
Training loss: 0.24176971486375415
Validation loss: 2.6022080087431925

Epoch: 6| Step: 10
Training loss: 0.23880495304032126
Validation loss: 2.614945471458278

Epoch: 6| Step: 11
Training loss: 0.2422863696927824
Validation loss: 2.6145883891954718

Epoch: 6| Step: 12
Training loss: 0.2508318443005955
Validation loss: 2.6244104873887624

Epoch: 6| Step: 13
Training loss: 0.3080443308002262
Validation loss: 2.6164414286609676

Epoch: 465| Step: 0
Training loss: 0.35643799656715164
Validation loss: 2.6009085657185627

Epoch: 6| Step: 1
Training loss: 0.2548608733925908
Validation loss: 2.6111670182602964

Epoch: 6| Step: 2
Training loss: 0.25880244958188486
Validation loss: 2.6043324888205133

Epoch: 6| Step: 3
Training loss: 0.2926718797191375
Validation loss: 2.639038459543361

Epoch: 6| Step: 4
Training loss: 0.4355267917809696
Validation loss: 2.6239449787797016

Epoch: 6| Step: 5
Training loss: 0.2582568760498417
Validation loss: 2.6354088060666387

Epoch: 6| Step: 6
Training loss: 0.24202981553166694
Validation loss: 2.593874778963368

Epoch: 6| Step: 7
Training loss: 0.3130328642087683
Validation loss: 2.6262414055571233

Epoch: 6| Step: 8
Training loss: 0.30295750178546205
Validation loss: 2.6214615724356585

Epoch: 6| Step: 9
Training loss: 0.22099659405970695
Validation loss: 2.5974364376521373

Epoch: 6| Step: 10
Training loss: 0.2819104123338428
Validation loss: 2.652024457287486

Epoch: 6| Step: 11
Training loss: 0.21617461591223022
Validation loss: 2.618044736543579

Epoch: 6| Step: 12
Training loss: 0.3441247739399681
Validation loss: 2.6709371411705765

Epoch: 6| Step: 13
Training loss: 0.2849569538719128
Validation loss: 2.6627927496827195

Epoch: 466| Step: 0
Training loss: 0.3961500628166433
Validation loss: 2.6599246506368335

Epoch: 6| Step: 1
Training loss: 0.2562465504669984
Validation loss: 2.6008543897088305

Epoch: 6| Step: 2
Training loss: 0.33856903723577286
Validation loss: 2.600313942857686

Epoch: 6| Step: 3
Training loss: 0.2797184676602664
Validation loss: 2.617389545897428

Epoch: 6| Step: 4
Training loss: 0.23936827309023417
Validation loss: 2.6578387128137977

Epoch: 6| Step: 5
Training loss: 0.3033403054726869
Validation loss: 2.63050665847447

Epoch: 6| Step: 6
Training loss: 0.30450437618033055
Validation loss: 2.5647280783650497

Epoch: 6| Step: 7
Training loss: 0.22218483661713165
Validation loss: 2.5972629182407205

Epoch: 6| Step: 8
Training loss: 0.30854813926771185
Validation loss: 2.629523391423258

Epoch: 6| Step: 9
Training loss: 0.3495126942197026
Validation loss: 2.592483732294478

Epoch: 6| Step: 10
Training loss: 0.3513759860028655
Validation loss: 2.632975330845232

Epoch: 6| Step: 11
Training loss: 0.37795291011147675
Validation loss: 2.6240400951004896

Epoch: 6| Step: 12
Training loss: 0.27542168191872834
Validation loss: 2.6296965651980155

Epoch: 6| Step: 13
Training loss: 0.24449137097423634
Validation loss: 2.6439314988092857

Epoch: 467| Step: 0
Training loss: 0.3856742509338242
Validation loss: 2.602109849569202

Epoch: 6| Step: 1
Training loss: 0.2969928683145575
Validation loss: 2.5609728286475524

Epoch: 6| Step: 2
Training loss: 0.3628201994296645
Validation loss: 2.5667506605705843

Epoch: 6| Step: 3
Training loss: 0.2911937219864261
Validation loss: 2.523850366852294

Epoch: 6| Step: 4
Training loss: 0.30653318721918615
Validation loss: 2.618047240896426

Epoch: 6| Step: 5
Training loss: 0.3002446453631829
Validation loss: 2.589861501994409

Epoch: 6| Step: 6
Training loss: 0.30325978124022573
Validation loss: 2.6277924474298207

Epoch: 6| Step: 7
Training loss: 0.42392736582711443
Validation loss: 2.61217047515918

Epoch: 6| Step: 8
Training loss: 0.21805302245311528
Validation loss: 2.588782528903593

Epoch: 6| Step: 9
Training loss: 0.2813510183539298
Validation loss: 2.6692000043202175

Epoch: 6| Step: 10
Training loss: 0.30710437961767056
Validation loss: 2.641706437093318

Epoch: 6| Step: 11
Training loss: 0.25409969883322553
Validation loss: 2.64605596812159

Epoch: 6| Step: 12
Training loss: 0.23378365939851337
Validation loss: 2.6434814382851077

Epoch: 6| Step: 13
Training loss: 0.326591974963357
Validation loss: 2.595403626717903

Epoch: 468| Step: 0
Training loss: 0.3233683590540693
Validation loss: 2.612207211966446

Epoch: 6| Step: 1
Training loss: 0.230528855972094
Validation loss: 2.6216806132807955

Epoch: 6| Step: 2
Training loss: 0.35995250408458346
Validation loss: 2.5792478485971055

Epoch: 6| Step: 3
Training loss: 0.26772304425224736
Validation loss: 2.5711354848371673

Epoch: 6| Step: 4
Training loss: 0.32346309938342455
Validation loss: 2.6264183814279423

Epoch: 6| Step: 5
Training loss: 0.3025421763014213
Validation loss: 2.6199618841024344

Epoch: 6| Step: 6
Training loss: 0.269795440343046
Validation loss: 2.676723876648936

Epoch: 6| Step: 7
Training loss: 0.30384252218366986
Validation loss: 2.638432000299933

Epoch: 6| Step: 8
Training loss: 0.2555622530502429
Validation loss: 2.616222488360734

Epoch: 6| Step: 9
Training loss: 0.1766286029967879
Validation loss: 2.5994241076685274

Epoch: 6| Step: 10
Training loss: 0.2621015197895776
Validation loss: 2.5948872505101073

Epoch: 6| Step: 11
Training loss: 0.3476944270228232
Validation loss: 2.6050776121789485

Epoch: 6| Step: 12
Training loss: 0.29641610365974924
Validation loss: 2.6152038040634467

Epoch: 6| Step: 13
Training loss: 0.3019833755638474
Validation loss: 2.6138420928683117

Epoch: 469| Step: 0
Training loss: 0.33016829980036794
Validation loss: 2.5985263524067683

Epoch: 6| Step: 1
Training loss: 0.18808062378536328
Validation loss: 2.639029387587608

Epoch: 6| Step: 2
Training loss: 0.23827645812922757
Validation loss: 2.666589532173699

Epoch: 6| Step: 3
Training loss: 0.3670067443721676
Validation loss: 2.6590907595312574

Epoch: 6| Step: 4
Training loss: 0.287237359410401
Validation loss: 2.5962667855442705

Epoch: 6| Step: 5
Training loss: 0.3027859551572743
Validation loss: 2.614140846733758

Epoch: 6| Step: 6
Training loss: 0.2566348546974704
Validation loss: 2.656850200983929

Epoch: 6| Step: 7
Training loss: 0.2576916729396969
Validation loss: 2.634579775669733

Epoch: 6| Step: 8
Training loss: 0.3001514752756377
Validation loss: 2.6611577042748293

Epoch: 6| Step: 9
Training loss: 0.2729256880824637
Validation loss: 2.671065507181428

Epoch: 6| Step: 10
Training loss: 0.32954625724527303
Validation loss: 2.600246138414899

Epoch: 6| Step: 11
Training loss: 0.1973818634813642
Validation loss: 2.66032642897533

Epoch: 6| Step: 12
Training loss: 0.15202523827305936
Validation loss: 2.5590544074812516

Epoch: 6| Step: 13
Training loss: 0.29161297213084353
Validation loss: 2.653196846536217

Epoch: 470| Step: 0
Training loss: 0.33482707382166027
Validation loss: 2.646232114361129

Epoch: 6| Step: 1
Training loss: 0.27440928390523484
Validation loss: 2.6416006599467035

Epoch: 6| Step: 2
Training loss: 0.29949780143589966
Validation loss: 2.6198302178298722

Epoch: 6| Step: 3
Training loss: 0.17994391763073886
Validation loss: 2.6632223734302314

Epoch: 6| Step: 4
Training loss: 0.28883845435924327
Validation loss: 2.609260373824359

Epoch: 6| Step: 5
Training loss: 0.39136966298283055
Validation loss: 2.6194671723139504

Epoch: 6| Step: 6
Training loss: 0.2815395824746089
Validation loss: 2.6040010068972546

Epoch: 6| Step: 7
Training loss: 0.23453363771894148
Validation loss: 2.6124734204900784

Epoch: 6| Step: 8
Training loss: 0.2828306445207695
Validation loss: 2.635791410156389

Epoch: 6| Step: 9
Training loss: 0.2754067084844165
Validation loss: 2.6376228798057983

Epoch: 6| Step: 10
Training loss: 0.2415481866146647
Validation loss: 2.7009190873002438

Epoch: 6| Step: 11
Training loss: 0.21210493992898488
Validation loss: 2.640189908089605

Epoch: 6| Step: 12
Training loss: 0.35493901363559893
Validation loss: 2.58452207123

Epoch: 6| Step: 13
Training loss: 0.2489160343505249
Validation loss: 2.6329510781543246

Epoch: 471| Step: 0
Training loss: 0.43797970766587735
Validation loss: 2.649078486621843

Epoch: 6| Step: 1
Training loss: 0.29268884639198156
Validation loss: 2.6961875195456626

Epoch: 6| Step: 2
Training loss: 0.33129361063503976
Validation loss: 2.645656885185806

Epoch: 6| Step: 3
Training loss: 0.2374391214245578
Validation loss: 2.6195194312759185

Epoch: 6| Step: 4
Training loss: 0.2527413274407187
Validation loss: 2.594478964343378

Epoch: 6| Step: 5
Training loss: 0.35776170095132775
Validation loss: 2.682623319893109

Epoch: 6| Step: 6
Training loss: 0.29410181283401815
Validation loss: 2.681233085454483

Epoch: 6| Step: 7
Training loss: 0.3219882812040916
Validation loss: 2.6437455347863645

Epoch: 6| Step: 8
Training loss: 0.3368466738326152
Validation loss: 2.644337153484368

Epoch: 6| Step: 9
Training loss: 0.3251710831147354
Validation loss: 2.6265096561911103

Epoch: 6| Step: 10
Training loss: 0.30716392184061037
Validation loss: 2.6594103842569154

Epoch: 6| Step: 11
Training loss: 0.43312184540451637
Validation loss: 2.612223001789449

Epoch: 6| Step: 12
Training loss: 0.26895910157070074
Validation loss: 2.5953282682861136

Epoch: 6| Step: 13
Training loss: 0.2600867502209509
Validation loss: 2.671506131236005

Epoch: 472| Step: 0
Training loss: 0.3673641713192608
Validation loss: 2.6537620711145644

Epoch: 6| Step: 1
Training loss: 0.19869023696103874
Validation loss: 2.6287272724445527

Epoch: 6| Step: 2
Training loss: 0.24422814898425443
Validation loss: 2.6338173734269916

Epoch: 6| Step: 3
Training loss: 0.2346452902869705
Validation loss: 2.5671310136880043

Epoch: 6| Step: 4
Training loss: 0.32974827102369814
Validation loss: 2.5904299234246677

Epoch: 6| Step: 5
Training loss: 0.25972423367109565
Validation loss: 2.6497156290507125

Epoch: 6| Step: 6
Training loss: 0.29264699433492614
Validation loss: 2.696763824552408

Epoch: 6| Step: 7
Training loss: 0.27916597086312045
Validation loss: 2.6462094998222385

Epoch: 6| Step: 8
Training loss: 0.25505334987927025
Validation loss: 2.654165340006051

Epoch: 6| Step: 9
Training loss: 0.24798863395527032
Validation loss: 2.6332395152590045

Epoch: 6| Step: 10
Training loss: 0.3148007337466514
Validation loss: 2.650210751844099

Epoch: 6| Step: 11
Training loss: 0.39678278625195684
Validation loss: 2.6311003478586508

Epoch: 6| Step: 12
Training loss: 0.3235289693114754
Validation loss: 2.599045797238319

Epoch: 6| Step: 13
Training loss: 0.34173153933997324
Validation loss: 2.6469637691140084

Epoch: 473| Step: 0
Training loss: 0.3530547050963469
Validation loss: 2.655278645349343

Epoch: 6| Step: 1
Training loss: 0.3031268866962039
Validation loss: 2.6353071413664586

Epoch: 6| Step: 2
Training loss: 0.14467983083400138
Validation loss: 2.6191856082672724

Epoch: 6| Step: 3
Training loss: 0.30085957733440705
Validation loss: 2.673462498375379

Epoch: 6| Step: 4
Training loss: 0.24531539562970406
Validation loss: 2.6640414538255994

Epoch: 6| Step: 5
Training loss: 0.2605315368346943
Validation loss: 2.683123914373489

Epoch: 6| Step: 6
Training loss: 0.25724710253574995
Validation loss: 2.600715812546655

Epoch: 6| Step: 7
Training loss: 0.33893629573176876
Validation loss: 2.684370214526848

Epoch: 6| Step: 8
Training loss: 0.18971242561788784
Validation loss: 2.683290852236091

Epoch: 6| Step: 9
Training loss: 0.2696089701620471
Validation loss: 2.65604372906593

Epoch: 6| Step: 10
Training loss: 0.2790491032134702
Validation loss: 2.6164701019450916

Epoch: 6| Step: 11
Training loss: 0.27073076335518825
Validation loss: 2.6748264214834045

Epoch: 6| Step: 12
Training loss: 0.34161942371503046
Validation loss: 2.67073623750521

Epoch: 6| Step: 13
Training loss: 0.26718355588623105
Validation loss: 2.6971610028497515

Epoch: 474| Step: 0
Training loss: 0.24737313149678047
Validation loss: 2.6104065613019536

Epoch: 6| Step: 1
Training loss: 0.4626093464542563
Validation loss: 2.634252409158521

Epoch: 6| Step: 2
Training loss: 0.3453411103388398
Validation loss: 2.657069315493259

Epoch: 6| Step: 3
Training loss: 0.25195512105461604
Validation loss: 2.622151342900456

Epoch: 6| Step: 4
Training loss: 0.2758113542070929
Validation loss: 2.6666810561825027

Epoch: 6| Step: 5
Training loss: 0.2982274294776078
Validation loss: 2.6245351939962713

Epoch: 6| Step: 6
Training loss: 0.23102479871970832
Validation loss: 2.5924201681560666

Epoch: 6| Step: 7
Training loss: 0.27020239544571834
Validation loss: 2.603923760847485

Epoch: 6| Step: 8
Training loss: 0.2958720985499184
Validation loss: 2.662926052074778

Epoch: 6| Step: 9
Training loss: 0.2876620390608404
Validation loss: 2.664324959125369

Epoch: 6| Step: 10
Training loss: 0.28841433154096513
Validation loss: 2.652273934690355

Epoch: 6| Step: 11
Training loss: 0.32950889441029485
Validation loss: 2.653236609673595

Epoch: 6| Step: 12
Training loss: 0.21912117530065708
Validation loss: 2.627116477831845

Epoch: 6| Step: 13
Training loss: 0.3200272476248481
Validation loss: 2.64879141424284

Epoch: 475| Step: 0
Training loss: 0.24575685723207585
Validation loss: 2.6593978032151653

Epoch: 6| Step: 1
Training loss: 0.30326737275328264
Validation loss: 2.667563009617265

Epoch: 6| Step: 2
Training loss: 0.26129647249997057
Validation loss: 2.65933648099097

Epoch: 6| Step: 3
Training loss: 0.253090030703598
Validation loss: 2.5809809423681838

Epoch: 6| Step: 4
Training loss: 0.30254955187370186
Validation loss: 2.6555242257506873

Epoch: 6| Step: 5
Training loss: 0.256198643562313
Validation loss: 2.6447891718124117

Epoch: 6| Step: 6
Training loss: 0.33404714429514304
Validation loss: 2.693736668883436

Epoch: 6| Step: 7
Training loss: 0.23225464133766996
Validation loss: 2.67493164236602

Epoch: 6| Step: 8
Training loss: 0.3021172786691892
Validation loss: 2.596567255507717

Epoch: 6| Step: 9
Training loss: 0.25498945555670827
Validation loss: 2.602848105722736

Epoch: 6| Step: 10
Training loss: 0.34043649523302966
Validation loss: 2.5816319975014004

Epoch: 6| Step: 11
Training loss: 0.32075917106192237
Validation loss: 2.637300516632955

Epoch: 6| Step: 12
Training loss: 0.3661072444341754
Validation loss: 2.6101530670113116

Epoch: 6| Step: 13
Training loss: 0.26292769353527334
Validation loss: 2.5993527639957024

Epoch: 476| Step: 0
Training loss: 0.2752149034813685
Validation loss: 2.639234790105469

Epoch: 6| Step: 1
Training loss: 0.33193296211903095
Validation loss: 2.6208818618171037

Epoch: 6| Step: 2
Training loss: 0.30275416155726165
Validation loss: 2.673127830610307

Epoch: 6| Step: 3
Training loss: 0.29304667390202715
Validation loss: 2.685828672478593

Epoch: 6| Step: 4
Training loss: 0.27746375268181717
Validation loss: 2.6674287323040105

Epoch: 6| Step: 5
Training loss: 0.27270734576014166
Validation loss: 2.5698747117121097

Epoch: 6| Step: 6
Training loss: 0.38238519058166126
Validation loss: 2.603108081556572

Epoch: 6| Step: 7
Training loss: 0.3690131840392344
Validation loss: 2.628163157581828

Epoch: 6| Step: 8
Training loss: 0.3187191457400917
Validation loss: 2.6168233893368944

Epoch: 6| Step: 9
Training loss: 0.27274247803530116
Validation loss: 2.590433075732048

Epoch: 6| Step: 10
Training loss: 0.1950712526032849
Validation loss: 2.6342988992350636

Epoch: 6| Step: 11
Training loss: 0.3568730544322839
Validation loss: 2.6796130363713457

Epoch: 6| Step: 12
Training loss: 0.3106651920474102
Validation loss: 2.6535456784820437

Epoch: 6| Step: 13
Training loss: 0.2816237641682877
Validation loss: 2.6630124197477016

Epoch: 477| Step: 0
Training loss: 0.38503983694042965
Validation loss: 2.6081056838787107

Epoch: 6| Step: 1
Training loss: 0.1934570971069532
Validation loss: 2.666485368009553

Epoch: 6| Step: 2
Training loss: 0.31841661371648117
Validation loss: 2.6189692946381067

Epoch: 6| Step: 3
Training loss: 0.28332395935446436
Validation loss: 2.626050557221481

Epoch: 6| Step: 4
Training loss: 0.3915022345926132
Validation loss: 2.651287304802981

Epoch: 6| Step: 5
Training loss: 0.3360683164279446
Validation loss: 2.6784890834321704

Epoch: 6| Step: 6
Training loss: 0.3284344122584534
Validation loss: 2.646620563226443

Epoch: 6| Step: 7
Training loss: 0.3779413581248742
Validation loss: 2.658671707533391

Epoch: 6| Step: 8
Training loss: 0.4851591623068365
Validation loss: 2.625379671159939

Epoch: 6| Step: 9
Training loss: 0.41876593886829416
Validation loss: 2.6212034472550685

Epoch: 6| Step: 10
Training loss: 0.2595079477678872
Validation loss: 2.5951322985608445

Epoch: 6| Step: 11
Training loss: 0.40482305296417476
Validation loss: 2.630489256306543

Epoch: 6| Step: 12
Training loss: 0.3432276615269972
Validation loss: 2.6249678170789594

Epoch: 6| Step: 13
Training loss: 0.3126136573097411
Validation loss: 2.5883459455973363

Epoch: 478| Step: 0
Training loss: 0.23352612310698345
Validation loss: 2.6637278371790236

Epoch: 6| Step: 1
Training loss: 0.4040929676320033
Validation loss: 2.632944181113063

Epoch: 6| Step: 2
Training loss: 0.3117529044884024
Validation loss: 2.563633226239629

Epoch: 6| Step: 3
Training loss: 0.34830861551859127
Validation loss: 2.5908621065593747

Epoch: 6| Step: 4
Training loss: 0.23078063293250564
Validation loss: 2.6197458469234056

Epoch: 6| Step: 5
Training loss: 0.4292438123709151
Validation loss: 2.582962829928892

Epoch: 6| Step: 6
Training loss: 0.29840679010695303
Validation loss: 2.614553836387624

Epoch: 6| Step: 7
Training loss: 0.34336500933541003
Validation loss: 2.64691697604941

Epoch: 6| Step: 8
Training loss: 0.1910152918962878
Validation loss: 2.6719727377462053

Epoch: 6| Step: 9
Training loss: 0.26086702822837204
Validation loss: 2.6703671593575002

Epoch: 6| Step: 10
Training loss: 0.24096338797247993
Validation loss: 2.6580858207043834

Epoch: 6| Step: 11
Training loss: 0.3933838504272027
Validation loss: 2.6426585115440995

Epoch: 6| Step: 12
Training loss: 0.3681700931125988
Validation loss: 2.6643139598373855

Epoch: 6| Step: 13
Training loss: 0.2964237824695784
Validation loss: 2.608818832486161

Epoch: 479| Step: 0
Training loss: 0.33110741389524917
Validation loss: 2.6182832464295633

Epoch: 6| Step: 1
Training loss: 0.39204606017215476
Validation loss: 2.7009356384612246

Epoch: 6| Step: 2
Training loss: 0.28970515492619325
Validation loss: 2.624307548683928

Epoch: 6| Step: 3
Training loss: 0.31179381688051294
Validation loss: 2.616888418236876

Epoch: 6| Step: 4
Training loss: 0.22529497414412794
Validation loss: 2.6181524519074197

Epoch: 6| Step: 5
Training loss: 0.27309033289512236
Validation loss: 2.6592498669170186

Epoch: 6| Step: 6
Training loss: 0.27633034558276215
Validation loss: 2.619548397006192

Epoch: 6| Step: 7
Training loss: 0.4175368243098684
Validation loss: 2.657180077275755

Epoch: 6| Step: 8
Training loss: 0.536952269725654
Validation loss: 2.586349116485392

Epoch: 6| Step: 9
Training loss: 0.3562996762759494
Validation loss: 2.6626940183436547

Epoch: 6| Step: 10
Training loss: 0.32563453087431443
Validation loss: 2.5953912636144545

Epoch: 6| Step: 11
Training loss: 0.24878783955380523
Validation loss: 2.638303063155332

Epoch: 6| Step: 12
Training loss: 0.29082586515004955
Validation loss: 2.637029016395143

Epoch: 6| Step: 13
Training loss: 0.3406973455752825
Validation loss: 2.614067974187451

Epoch: 480| Step: 0
Training loss: 0.299538024702354
Validation loss: 2.634574964301782

Epoch: 6| Step: 1
Training loss: 0.2056486277933526
Validation loss: 2.588183362226475

Epoch: 6| Step: 2
Training loss: 0.41906647608475855
Validation loss: 2.6247544552235085

Epoch: 6| Step: 3
Training loss: 0.2973868951049992
Validation loss: 2.655724686681621

Epoch: 6| Step: 4
Training loss: 0.22050262728896985
Validation loss: 2.643142327947698

Epoch: 6| Step: 5
Training loss: 0.24186344924966022
Validation loss: 2.6161688497114244

Epoch: 6| Step: 6
Training loss: 0.31010753815987674
Validation loss: 2.6327870383762404

Epoch: 6| Step: 7
Training loss: 0.5572831043286784
Validation loss: 2.610591528704355

Epoch: 6| Step: 8
Training loss: 0.25034237305954515
Validation loss: 2.6372621932249745

Epoch: 6| Step: 9
Training loss: 0.4118146158622267
Validation loss: 2.6574239791853564

Epoch: 6| Step: 10
Training loss: 0.26196155387772
Validation loss: 2.6094629345237577

Epoch: 6| Step: 11
Training loss: 0.3705866108998103
Validation loss: 2.711764199504202

Epoch: 6| Step: 12
Training loss: 0.3069285723390468
Validation loss: 2.6488501753323144

Epoch: 6| Step: 13
Training loss: 0.4383565657802181
Validation loss: 2.664285972969708

Epoch: 481| Step: 0
Training loss: 0.4397743746316911
Validation loss: 2.642693110386949

Epoch: 6| Step: 1
Training loss: 0.23845320891082689
Validation loss: 2.6576356602108033

Epoch: 6| Step: 2
Training loss: 0.42472221187740955
Validation loss: 2.6771702189515043

Epoch: 6| Step: 3
Training loss: 0.38433507851559806
Validation loss: 2.6181326303062007

Epoch: 6| Step: 4
Training loss: 0.3169792896591852
Validation loss: 2.583674467287217

Epoch: 6| Step: 5
Training loss: 0.34895145589779214
Validation loss: 2.6179809430387793

Epoch: 6| Step: 6
Training loss: 0.250131900085945
Validation loss: 2.7037170291041956

Epoch: 6| Step: 7
Training loss: 0.4455591321901654
Validation loss: 2.616803481742862

Epoch: 6| Step: 8
Training loss: 0.20251221106351866
Validation loss: 2.7204550442642406

Epoch: 6| Step: 9
Training loss: 0.17223901564769167
Validation loss: 2.58157483105219

Epoch: 6| Step: 10
Training loss: 0.3230058203444437
Validation loss: 2.6643694927275883

Epoch: 6| Step: 11
Training loss: 0.20385207666025168
Validation loss: 2.6376969545658917

Epoch: 6| Step: 12
Training loss: 0.3394331369781626
Validation loss: 2.5964521863386567

Epoch: 6| Step: 13
Training loss: 0.30131028454608416
Validation loss: 2.661445712204561

Epoch: 482| Step: 0
Training loss: 0.18675580953781812
Validation loss: 2.6867925023158166

Epoch: 6| Step: 1
Training loss: 0.3103816234513326
Validation loss: 2.658649602350603

Epoch: 6| Step: 2
Training loss: 0.23662606681607426
Validation loss: 2.617521608197281

Epoch: 6| Step: 3
Training loss: 0.31675152718643274
Validation loss: 2.627573749730389

Epoch: 6| Step: 4
Training loss: 0.34904449262761844
Validation loss: 2.602926727107756

Epoch: 6| Step: 5
Training loss: 0.3190902091164113
Validation loss: 2.6696170836624806

Epoch: 6| Step: 6
Training loss: 0.23589733362926596
Validation loss: 2.6163415405132397

Epoch: 6| Step: 7
Training loss: 0.2735128979954217
Validation loss: 2.6189935705978247

Epoch: 6| Step: 8
Training loss: 0.3013403390432043
Validation loss: 2.5967648460997257

Epoch: 6| Step: 9
Training loss: 0.27670283878705165
Validation loss: 2.5731590300990526

Epoch: 6| Step: 10
Training loss: 0.3080289476650529
Validation loss: 2.6221237925421694

Epoch: 6| Step: 11
Training loss: 0.26693097398605176
Validation loss: 2.641584233422827

Epoch: 6| Step: 12
Training loss: 0.32217424426481167
Validation loss: 2.635778836983334

Epoch: 6| Step: 13
Training loss: 0.3100288196595735
Validation loss: 2.64451586344613

Epoch: 483| Step: 0
Training loss: 0.32694345001891256
Validation loss: 2.613099597952512

Epoch: 6| Step: 1
Training loss: 0.340691812769637
Validation loss: 2.601259612970464

Epoch: 6| Step: 2
Training loss: 0.28253982740035244
Validation loss: 2.592439588568183

Epoch: 6| Step: 3
Training loss: 0.3632143635856233
Validation loss: 2.634145684026434

Epoch: 6| Step: 4
Training loss: 0.33989344704846686
Validation loss: 2.588324429602537

Epoch: 6| Step: 5
Training loss: 0.1510137862474934
Validation loss: 2.6590432085216205

Epoch: 6| Step: 6
Training loss: 0.26456230422926735
Validation loss: 2.6025730190483327

Epoch: 6| Step: 7
Training loss: 0.3175738771912291
Validation loss: 2.6110356237668824

Epoch: 6| Step: 8
Training loss: 0.3086788929204477
Validation loss: 2.6578117416951876

Epoch: 6| Step: 9
Training loss: 0.24500247657263746
Validation loss: 2.606942266771449

Epoch: 6| Step: 10
Training loss: 0.22318853365985386
Validation loss: 2.618074955574649

Epoch: 6| Step: 11
Training loss: 0.2990554119733046
Validation loss: 2.6164459012887358

Epoch: 6| Step: 12
Training loss: 0.3618192067726469
Validation loss: 2.573952845885725

Epoch: 6| Step: 13
Training loss: 0.33482528252881294
Validation loss: 2.6583367920696594

Epoch: 484| Step: 0
Training loss: 0.33235189999091375
Validation loss: 2.5404109171766387

Epoch: 6| Step: 1
Training loss: 0.2723708191735032
Validation loss: 2.6031683623208264

Epoch: 6| Step: 2
Training loss: 0.24956569349116733
Validation loss: 2.6245220445533306

Epoch: 6| Step: 3
Training loss: 0.2658061363594006
Validation loss: 2.641235927960132

Epoch: 6| Step: 4
Training loss: 0.1957949782579428
Validation loss: 2.5801583488673123

Epoch: 6| Step: 5
Training loss: 0.31101639959051536
Validation loss: 2.5852203604052875

Epoch: 6| Step: 6
Training loss: 0.2680569561958505
Validation loss: 2.590234864066656

Epoch: 6| Step: 7
Training loss: 0.2813504357616086
Validation loss: 2.5885244224378194

Epoch: 6| Step: 8
Training loss: 0.23266396616686552
Validation loss: 2.64993490613007

Epoch: 6| Step: 9
Training loss: 0.31356081914650813
Validation loss: 2.5578764475396563

Epoch: 6| Step: 10
Training loss: 0.35056940321332253
Validation loss: 2.6497472789505814

Epoch: 6| Step: 11
Training loss: 0.33171609619631554
Validation loss: 2.670924726004653

Epoch: 6| Step: 12
Training loss: 0.24902527004390443
Validation loss: 2.634463357706913

Epoch: 6| Step: 13
Training loss: 0.22563791708281883
Validation loss: 2.617139703874043

Epoch: 485| Step: 0
Training loss: 0.3413480591230028
Validation loss: 2.61569657252508

Epoch: 6| Step: 1
Training loss: 0.3386712070973288
Validation loss: 2.626434690991826

Epoch: 6| Step: 2
Training loss: 0.3469609368897996
Validation loss: 2.627970588977232

Epoch: 6| Step: 3
Training loss: 0.3894949015380396
Validation loss: 2.647222827394498

Epoch: 6| Step: 4
Training loss: 0.32393505139523016
Validation loss: 2.6826125215393306

Epoch: 6| Step: 5
Training loss: 0.3138153883248953
Validation loss: 2.673418487832002

Epoch: 6| Step: 6
Training loss: 0.48406175513607314
Validation loss: 2.639176808650825

Epoch: 6| Step: 7
Training loss: 0.34177019287595045
Validation loss: 2.625253877018925

Epoch: 6| Step: 8
Training loss: 0.3610253999035191
Validation loss: 2.57790204249685

Epoch: 6| Step: 9
Training loss: 0.28083200652962725
Validation loss: 2.5904469044220186

Epoch: 6| Step: 10
Training loss: 0.3702778329194977
Validation loss: 2.62871719746206

Epoch: 6| Step: 11
Training loss: 0.3312525425219576
Validation loss: 2.6191751400548244

Epoch: 6| Step: 12
Training loss: 0.21664315005900217
Validation loss: 2.618714815933716

Epoch: 6| Step: 13
Training loss: 0.2511137205346888
Validation loss: 2.6186844070219526

Epoch: 486| Step: 0
Training loss: 0.23962002798005458
Validation loss: 2.5795539209850467

Epoch: 6| Step: 1
Training loss: 0.2620932333875072
Validation loss: 2.5709096800371323

Epoch: 6| Step: 2
Training loss: 0.4586030390511893
Validation loss: 2.550666031467314

Epoch: 6| Step: 3
Training loss: 0.2486801773588497
Validation loss: 2.5482023092017667

Epoch: 6| Step: 4
Training loss: 0.23411313368730738
Validation loss: 2.6128791533948448

Epoch: 6| Step: 5
Training loss: 0.26344792780934523
Validation loss: 2.629521895369758

Epoch: 6| Step: 6
Training loss: 0.23194628229066663
Validation loss: 2.605596536365136

Epoch: 6| Step: 7
Training loss: 0.3263063096637624
Validation loss: 2.6374822269461586

Epoch: 6| Step: 8
Training loss: 0.312980675567722
Validation loss: 2.643848986685162

Epoch: 6| Step: 9
Training loss: 0.26490579739120534
Validation loss: 2.621961227411596

Epoch: 6| Step: 10
Training loss: 0.2497579624836993
Validation loss: 2.656001404741789

Epoch: 6| Step: 11
Training loss: 0.3650402022130165
Validation loss: 2.6258384939724317

Epoch: 6| Step: 12
Training loss: 0.16017303146273776
Validation loss: 2.5847843053614588

Epoch: 6| Step: 13
Training loss: 0.24324604934951963
Validation loss: 2.5988783789028007

Epoch: 487| Step: 0
Training loss: 0.18831328004826772
Validation loss: 2.6787936144215494

Epoch: 6| Step: 1
Training loss: 0.3106810681688934
Validation loss: 2.5898531553501365

Epoch: 6| Step: 2
Training loss: 0.4263774127931079
Validation loss: 2.5621458599728233

Epoch: 6| Step: 3
Training loss: 0.3407552378266608
Validation loss: 2.6393756732583005

Epoch: 6| Step: 4
Training loss: 0.25413768197861286
Validation loss: 2.5798281043844757

Epoch: 6| Step: 5
Training loss: 0.25627124919247213
Validation loss: 2.647911131998356

Epoch: 6| Step: 6
Training loss: 0.2806924883862765
Validation loss: 2.6291985465009695

Epoch: 6| Step: 7
Training loss: 0.3305894401334987
Validation loss: 2.5947654605391035

Epoch: 6| Step: 8
Training loss: 0.27826358150057634
Validation loss: 2.622634457613279

Epoch: 6| Step: 9
Training loss: 0.3634906288471191
Validation loss: 2.549417143636494

Epoch: 6| Step: 10
Training loss: 0.19984421996179935
Validation loss: 2.618312574891528

Epoch: 6| Step: 11
Training loss: 0.20818464615857618
Validation loss: 2.6403653320006435

Epoch: 6| Step: 12
Training loss: 0.3707585075338625
Validation loss: 2.638230707394031

Epoch: 6| Step: 13
Training loss: 0.24025670389751916
Validation loss: 2.5792427260277284

Epoch: 488| Step: 0
Training loss: 0.26296685234559225
Validation loss: 2.6670233865405546

Epoch: 6| Step: 1
Training loss: 0.26021869127738567
Validation loss: 2.5983486390493953

Epoch: 6| Step: 2
Training loss: 0.24981822915912505
Validation loss: 2.6169696622311323

Epoch: 6| Step: 3
Training loss: 0.2924504845841336
Validation loss: 2.652760288975328

Epoch: 6| Step: 4
Training loss: 0.3126427562800551
Validation loss: 2.6268556787126838

Epoch: 6| Step: 5
Training loss: 0.37120470094946384
Validation loss: 2.6558725126225537

Epoch: 6| Step: 6
Training loss: 0.31654392590874986
Validation loss: 2.6456459059123203

Epoch: 6| Step: 7
Training loss: 0.24873902778292403
Validation loss: 2.536359175376412

Epoch: 6| Step: 8
Training loss: 0.33044537310513256
Validation loss: 2.6659386256909454

Epoch: 6| Step: 9
Training loss: 0.3347922253361717
Validation loss: 2.6090951491571066

Epoch: 6| Step: 10
Training loss: 0.1984165345778567
Validation loss: 2.582317096009996

Epoch: 6| Step: 11
Training loss: 0.40539260399159494
Validation loss: 2.5978169862355194

Epoch: 6| Step: 12
Training loss: 0.2730179292455733
Validation loss: 2.632547367076754

Epoch: 6| Step: 13
Training loss: 0.2784838012233941
Validation loss: 2.6318324044793076

Epoch: 489| Step: 0
Training loss: 0.23390571978960611
Validation loss: 2.6136592483272523

Epoch: 6| Step: 1
Training loss: 0.32625823105553914
Validation loss: 2.5770598552089767

Epoch: 6| Step: 2
Training loss: 0.29996614116094983
Validation loss: 2.646515710699133

Epoch: 6| Step: 3
Training loss: 0.3455724630901443
Validation loss: 2.584757701886041

Epoch: 6| Step: 4
Training loss: 0.21741507428766663
Validation loss: 2.6082771870071793

Epoch: 6| Step: 5
Training loss: 0.3932781146913056
Validation loss: 2.6131266656076675

Epoch: 6| Step: 6
Training loss: 0.36371037559068464
Validation loss: 2.6397041054313957

Epoch: 6| Step: 7
Training loss: 0.32377388319271044
Validation loss: 2.613883001956218

Epoch: 6| Step: 8
Training loss: 0.3034220606512936
Validation loss: 2.6048977944513694

Epoch: 6| Step: 9
Training loss: 0.21273668655669448
Validation loss: 2.545720890098883

Epoch: 6| Step: 10
Training loss: 0.23712895797981545
Validation loss: 2.60530326962118

Epoch: 6| Step: 11
Training loss: 0.32683003431779123
Validation loss: 2.6000826333437286

Epoch: 6| Step: 12
Training loss: 0.2220374090533722
Validation loss: 2.623162504456283

Epoch: 6| Step: 13
Training loss: 0.19614313879068254
Validation loss: 2.584713964285673

Epoch: 490| Step: 0
Training loss: 0.26274031923609914
Validation loss: 2.6342326483648444

Epoch: 6| Step: 1
Training loss: 0.19962104681122067
Validation loss: 2.644982634224759

Epoch: 6| Step: 2
Training loss: 0.280391894040301
Validation loss: 2.6305774593370064

Epoch: 6| Step: 3
Training loss: 0.183457547250739
Validation loss: 2.6019121761752633

Epoch: 6| Step: 4
Training loss: 0.16320581085164404
Validation loss: 2.6518415632019723

Epoch: 6| Step: 5
Training loss: 0.3495366004769661
Validation loss: 2.6606632147301204

Epoch: 6| Step: 6
Training loss: 0.2817293691299893
Validation loss: 2.622413632668047

Epoch: 6| Step: 7
Training loss: 0.543366211245524
Validation loss: 2.7152916408444008

Epoch: 6| Step: 8
Training loss: 0.2894746574187004
Validation loss: 2.629197564122356

Epoch: 6| Step: 9
Training loss: 0.286685786834049
Validation loss: 2.5954738311874004

Epoch: 6| Step: 10
Training loss: 0.48120176023992123
Validation loss: 2.6092910486600926

Epoch: 6| Step: 11
Training loss: 0.20952816207795066
Validation loss: 2.637203422552864

Epoch: 6| Step: 12
Training loss: 0.22752017650894252
Validation loss: 2.61351260770534

Epoch: 6| Step: 13
Training loss: 0.35272913323750105
Validation loss: 2.6022235996464573

Epoch: 491| Step: 0
Training loss: 0.243560177298364
Validation loss: 2.6358369082598383

Epoch: 6| Step: 1
Training loss: 0.27690537152647693
Validation loss: 2.6163264134367736

Epoch: 6| Step: 2
Training loss: 0.4074892436404088
Validation loss: 2.5929606511977132

Epoch: 6| Step: 3
Training loss: 0.3710938303094074
Validation loss: 2.595850832917411

Epoch: 6| Step: 4
Training loss: 0.2595168478435852
Validation loss: 2.557532776280425

Epoch: 6| Step: 5
Training loss: 0.3588817777747673
Validation loss: 2.635592056489469

Epoch: 6| Step: 6
Training loss: 0.32252616753984487
Validation loss: 2.590904222019413

Epoch: 6| Step: 7
Training loss: 0.24086191818819944
Validation loss: 2.5952178754098

Epoch: 6| Step: 8
Training loss: 0.28620002399857003
Validation loss: 2.639116717982986

Epoch: 6| Step: 9
Training loss: 0.25589446198507154
Validation loss: 2.6770390211265043

Epoch: 6| Step: 10
Training loss: 0.29992593804737633
Validation loss: 2.6630193284436654

Epoch: 6| Step: 11
Training loss: 0.21674225952644446
Validation loss: 2.60940320271919

Epoch: 6| Step: 12
Training loss: 0.21194391875304605
Validation loss: 2.6368052753333022

Epoch: 6| Step: 13
Training loss: 0.20780164503845236
Validation loss: 2.6470765074282587

Epoch: 492| Step: 0
Training loss: 0.25506012693879543
Validation loss: 2.6134508322151007

Epoch: 6| Step: 1
Training loss: 0.28577013433163795
Validation loss: 2.5999350130077885

Epoch: 6| Step: 2
Training loss: 0.23273003609035908
Validation loss: 2.651224521009145

Epoch: 6| Step: 3
Training loss: 0.42263820278256753
Validation loss: 2.650129934640239

Epoch: 6| Step: 4
Training loss: 0.3124696001525234
Validation loss: 2.6241387967854357

Epoch: 6| Step: 5
Training loss: 0.2637388073774579
Validation loss: 2.637478596026455

Epoch: 6| Step: 6
Training loss: 0.3988839434532915
Validation loss: 2.6486052213391185

Epoch: 6| Step: 7
Training loss: 0.3277810655692094
Validation loss: 2.5861594190386783

Epoch: 6| Step: 8
Training loss: 0.2874326637443489
Validation loss: 2.6048768003524554

Epoch: 6| Step: 9
Training loss: 0.3394732264107976
Validation loss: 2.599113327225935

Epoch: 6| Step: 10
Training loss: 0.35933877928271857
Validation loss: 2.587449783108188

Epoch: 6| Step: 11
Training loss: 0.2725733043346058
Validation loss: 2.5761240737101163

Epoch: 6| Step: 12
Training loss: 0.270745568849437
Validation loss: 2.674877078954712

Epoch: 6| Step: 13
Training loss: 0.3291337990749073
Validation loss: 2.633494106849367

Epoch: 493| Step: 0
Training loss: 0.25049779922219106
Validation loss: 2.6207751228729252

Epoch: 6| Step: 1
Training loss: 0.3560147964638668
Validation loss: 2.5605482561663977

Epoch: 6| Step: 2
Training loss: 0.387466439978095
Validation loss: 2.642058530758356

Epoch: 6| Step: 3
Training loss: 0.38077841656319034
Validation loss: 2.6836710571229774

Epoch: 6| Step: 4
Training loss: 0.32895400137864517
Validation loss: 2.638645927777873

Epoch: 6| Step: 5
Training loss: 0.2955679227880443
Validation loss: 2.603549553549203

Epoch: 6| Step: 6
Training loss: 0.2456782708992856
Validation loss: 2.6420834292792943

Epoch: 6| Step: 7
Training loss: 0.2649233470573239
Validation loss: 2.596964456705968

Epoch: 6| Step: 8
Training loss: 0.2697517764428079
Validation loss: 2.67621970192657

Epoch: 6| Step: 9
Training loss: 0.318647897486482
Validation loss: 2.5946084329315986

Epoch: 6| Step: 10
Training loss: 0.3802434783090363
Validation loss: 2.589233802249968

Epoch: 6| Step: 11
Training loss: 0.26720343759753906
Validation loss: 2.5767433240310607

Epoch: 6| Step: 12
Training loss: 0.38789946516245477
Validation loss: 2.6062458943945295

Epoch: 6| Step: 13
Training loss: 0.2351546670854084
Validation loss: 2.623668832672948

Epoch: 494| Step: 0
Training loss: 0.2683139346102383
Validation loss: 2.699555217347061

Epoch: 6| Step: 1
Training loss: 0.28149576840091345
Validation loss: 2.585045052584028

Epoch: 6| Step: 2
Training loss: 0.3770124951980928
Validation loss: 2.6295230740786475

Epoch: 6| Step: 3
Training loss: 0.3552716725427744
Validation loss: 2.6116849455308393

Epoch: 6| Step: 4
Training loss: 0.2781972780499693
Validation loss: 2.6497036918190098

Epoch: 6| Step: 5
Training loss: 0.46351012290467886
Validation loss: 2.614410262946518

Epoch: 6| Step: 6
Training loss: 0.3092178118798982
Validation loss: 2.594611534217378

Epoch: 6| Step: 7
Training loss: 0.41288748950182735
Validation loss: 2.6288968029863304

Epoch: 6| Step: 8
Training loss: 0.2948060218676712
Validation loss: 2.6491487161372786

Epoch: 6| Step: 9
Training loss: 0.35343151251041066
Validation loss: 2.647535630029307

Epoch: 6| Step: 10
Training loss: 0.311894306663171
Validation loss: 2.6079378415249805

Epoch: 6| Step: 11
Training loss: 0.3468026816098331
Validation loss: 2.6533157148287443

Epoch: 6| Step: 12
Training loss: 0.1502871343063922
Validation loss: 2.5937128102650604

Epoch: 6| Step: 13
Training loss: 0.38558147317695846
Validation loss: 2.6249263995312586

Epoch: 495| Step: 0
Training loss: 0.4065778583085788
Validation loss: 2.611086012221386

Epoch: 6| Step: 1
Training loss: 0.3649821711131187
Validation loss: 2.6017102265443155

Epoch: 6| Step: 2
Training loss: 0.30704413428220706
Validation loss: 2.577083739576459

Epoch: 6| Step: 3
Training loss: 0.41162071363764147
Validation loss: 2.6043738219201518

Epoch: 6| Step: 4
Training loss: 0.29386292377032297
Validation loss: 2.5922551884167135

Epoch: 6| Step: 5
Training loss: 0.3472235483568087
Validation loss: 2.608332838925771

Epoch: 6| Step: 6
Training loss: 0.4058364450477718
Validation loss: 2.5786671771606535

Epoch: 6| Step: 7
Training loss: 0.29179920721590225
Validation loss: 2.594968624403068

Epoch: 6| Step: 8
Training loss: 0.4248844115765603
Validation loss: 2.6012841840456566

Epoch: 6| Step: 9
Training loss: 0.3193075768245608
Validation loss: 2.59305704197713

Epoch: 6| Step: 10
Training loss: 0.2698196305814384
Validation loss: 2.5890842588005714

Epoch: 6| Step: 11
Training loss: 0.310965945030598
Validation loss: 2.6409164659105366

Epoch: 6| Step: 12
Training loss: 0.3630009051435131
Validation loss: 2.603526056969422

Epoch: 6| Step: 13
Training loss: 0.2881468110507285
Validation loss: 2.6218944222992966

Epoch: 496| Step: 0
Training loss: 0.34587111405553
Validation loss: 2.5385084124737487

Epoch: 6| Step: 1
Training loss: 0.29195833807362226
Validation loss: 2.5849044595718307

Epoch: 6| Step: 2
Training loss: 0.366203389407889
Validation loss: 2.6131608495265755

Epoch: 6| Step: 3
Training loss: 0.40696167964515756
Validation loss: 2.648838789254174

Epoch: 6| Step: 4
Training loss: 0.3256255159538706
Validation loss: 2.6380512628686286

Epoch: 6| Step: 5
Training loss: 0.28515685094482646
Validation loss: 2.6100285943122623

Epoch: 6| Step: 6
Training loss: 0.19708654565558928
Validation loss: 2.6238365016839698

Epoch: 6| Step: 7
Training loss: 0.17784893619601524
Validation loss: 2.5661929122686993

Epoch: 6| Step: 8
Training loss: 0.3577538912886058
Validation loss: 2.6383873752963973

Epoch: 6| Step: 9
Training loss: 0.2623725099004719
Validation loss: 2.5860289589189036

Epoch: 6| Step: 10
Training loss: 0.3771285207379869
Validation loss: 2.622792602546006

Epoch: 6| Step: 11
Training loss: 0.25828797393372827
Validation loss: 2.590080453710564

Epoch: 6| Step: 12
Training loss: 0.4012097794883105
Validation loss: 2.5796335295945156

Epoch: 6| Step: 13
Training loss: 0.3135438175486721
Validation loss: 2.6081205082152406

Epoch: 497| Step: 0
Training loss: 0.2770183561737929
Validation loss: 2.6456150856015537

Epoch: 6| Step: 1
Training loss: 0.42610200122080405
Validation loss: 2.6160190536114283

Epoch: 6| Step: 2
Training loss: 0.2863584286421275
Validation loss: 2.6259215720251747

Epoch: 6| Step: 3
Training loss: 0.24292427710841424
Validation loss: 2.5744689295001386

Epoch: 6| Step: 4
Training loss: 0.3182223908763873
Validation loss: 2.612311768329091

Epoch: 6| Step: 5
Training loss: 0.3840664159887081
Validation loss: 2.6026590535532628

Epoch: 6| Step: 6
Training loss: 0.4516913325916613
Validation loss: 2.56625288336199

Epoch: 6| Step: 7
Training loss: 0.29897689855840215
Validation loss: 2.699746315423586

Epoch: 6| Step: 8
Training loss: 0.327836102507819
Validation loss: 2.6074847991246695

Epoch: 6| Step: 9
Training loss: 0.38922650813789944
Validation loss: 2.657464822959206

Epoch: 6| Step: 10
Training loss: 0.19299860734881838
Validation loss: 2.6314814039188525

Epoch: 6| Step: 11
Training loss: 0.2528395621075857
Validation loss: 2.609479190170152

Epoch: 6| Step: 12
Training loss: 0.40518610369482766
Validation loss: 2.610404551955656

Epoch: 6| Step: 13
Training loss: 0.2183302530648956
Validation loss: 2.6017650872854214

Epoch: 498| Step: 0
Training loss: 0.32322357446838734
Validation loss: 2.6315145339946193

Epoch: 6| Step: 1
Training loss: 0.21060689873834745
Validation loss: 2.623913449252721

Epoch: 6| Step: 2
Training loss: 0.29185353690310073
Validation loss: 2.5926127870721816

Epoch: 6| Step: 3
Training loss: 0.26612414416618574
Validation loss: 2.581815571128333

Epoch: 6| Step: 4
Training loss: 0.2328718301840933
Validation loss: 2.6323892798450435

Epoch: 6| Step: 5
Training loss: 0.2861828809033411
Validation loss: 2.639363704316676

Epoch: 6| Step: 6
Training loss: 0.3324246488246998
Validation loss: 2.598446343904463

Epoch: 6| Step: 7
Training loss: 0.21724197301477807
Validation loss: 2.6411520828798007

Epoch: 6| Step: 8
Training loss: 0.36222096012965965
Validation loss: 2.5750553390581006

Epoch: 6| Step: 9
Training loss: 0.20466111792103153
Validation loss: 2.5642935206148594

Epoch: 6| Step: 10
Training loss: 0.3597045921221859
Validation loss: 2.645848692201105

Epoch: 6| Step: 11
Training loss: 0.25120071316772713
Validation loss: 2.6088179947491876

Epoch: 6| Step: 12
Training loss: 0.3493983521615875
Validation loss: 2.628928401224528

Epoch: 6| Step: 13
Training loss: 0.23637050847608032
Validation loss: 2.6168684883604567

Epoch: 499| Step: 0
Training loss: 0.3221842923268316
Validation loss: 2.6155717255618187

Epoch: 6| Step: 1
Training loss: 0.33454396399650194
Validation loss: 2.605085688869981

Epoch: 6| Step: 2
Training loss: 0.19381590614413474
Validation loss: 2.5919468138500905

Epoch: 6| Step: 3
Training loss: 0.31948057159862847
Validation loss: 2.622054703214324

Epoch: 6| Step: 4
Training loss: 0.22264841969424157
Validation loss: 2.598938436693212

Epoch: 6| Step: 5
Training loss: 0.31342144062588934
Validation loss: 2.6172433420173653

Epoch: 6| Step: 6
Training loss: 0.3182803564943966
Validation loss: 2.6555964245526544

Epoch: 6| Step: 7
Training loss: 0.27573835455374124
Validation loss: 2.6818240205567

Epoch: 6| Step: 8
Training loss: 0.1763243180617393
Validation loss: 2.621873424106711

Epoch: 6| Step: 9
Training loss: 0.2583958499516505
Validation loss: 2.5824140687169694

Epoch: 6| Step: 10
Training loss: 0.260934822845431
Validation loss: 2.657420659619865

Epoch: 6| Step: 11
Training loss: 0.238786458856637
Validation loss: 2.6003266111049927

Epoch: 6| Step: 12
Training loss: 0.2381719354120038
Validation loss: 2.5696619325528975

Epoch: 6| Step: 13
Training loss: 0.29827480574970733
Validation loss: 2.6111988690916896

Epoch: 500| Step: 0
Training loss: 0.2899305095532978
Validation loss: 2.6190193711446015

Epoch: 6| Step: 1
Training loss: 0.39832730732965804
Validation loss: 2.642572335751196

Epoch: 6| Step: 2
Training loss: 0.27963076820614247
Validation loss: 2.6067803325854735

Epoch: 6| Step: 3
Training loss: 0.2928269106515752
Validation loss: 2.631896798321309

Epoch: 6| Step: 4
Training loss: 0.21752068259568247
Validation loss: 2.5784842346835783

Epoch: 6| Step: 5
Training loss: 0.29261341162300064
Validation loss: 2.6446959135779715

Epoch: 6| Step: 6
Training loss: 0.21387129827581128
Validation loss: 2.657992221707037

Epoch: 6| Step: 7
Training loss: 0.26384048722131653
Validation loss: 2.635942245868058

Epoch: 6| Step: 8
Training loss: 0.20195663493369465
Validation loss: 2.619388835011509

Epoch: 6| Step: 9
Training loss: 0.220702787415913
Validation loss: 2.6921220112792996

Epoch: 6| Step: 10
Training loss: 0.2872644252300755
Validation loss: 2.6191311427624386

Epoch: 6| Step: 11
Training loss: 0.2913242725906319
Validation loss: 2.621635642509774

Epoch: 6| Step: 12
Training loss: 0.2829132174720308
Validation loss: 2.6040674317843986

Epoch: 6| Step: 13
Training loss: 0.275759645863976
Validation loss: 2.6146430861090457

Epoch: 501| Step: 0
Training loss: 0.3335980752311669
Validation loss: 2.637893738969113

Epoch: 6| Step: 1
Training loss: 0.25160253514227854
Validation loss: 2.5911421553746994

Epoch: 6| Step: 2
Training loss: 0.1840784593635296
Validation loss: 2.5808164785161374

Epoch: 6| Step: 3
Training loss: 0.2015144985913159
Validation loss: 2.6282488684506506

Epoch: 6| Step: 4
Training loss: 0.2854099843131654
Validation loss: 2.5959380239456546

Epoch: 6| Step: 5
Training loss: 0.3230488824378378
Validation loss: 2.648772624520612

Epoch: 6| Step: 6
Training loss: 0.31566077586699276
Validation loss: 2.568756250774516

Epoch: 6| Step: 7
Training loss: 0.3344331035756344
Validation loss: 2.596349248750723

Epoch: 6| Step: 8
Training loss: 0.2871682891605221
Validation loss: 2.5984715609173246

Epoch: 6| Step: 9
Training loss: 0.305400064068296
Validation loss: 2.5658487210788508

Epoch: 6| Step: 10
Training loss: 0.251954026922933
Validation loss: 2.6782505494122546

Epoch: 6| Step: 11
Training loss: 0.2725070791243661
Validation loss: 2.642532773038711

Epoch: 6| Step: 12
Training loss: 0.2515984930032741
Validation loss: 2.618233755327864

Epoch: 6| Step: 13
Training loss: 0.4031677511745205
Validation loss: 2.560451821028195

Epoch: 502| Step: 0
Training loss: 0.25990522548596995
Validation loss: 2.598360139326406

Epoch: 6| Step: 1
Training loss: 0.35253415936470883
Validation loss: 2.5973451662345637

Epoch: 6| Step: 2
Training loss: 0.18642031230468176
Validation loss: 2.570589369497487

Epoch: 6| Step: 3
Training loss: 0.3364561645784348
Validation loss: 2.544308154881092

Epoch: 6| Step: 4
Training loss: 0.27515261760872367
Validation loss: 2.613387207863463

Epoch: 6| Step: 5
Training loss: 0.29010746210350763
Validation loss: 2.552431749707338

Epoch: 6| Step: 6
Training loss: 0.3081510724687955
Validation loss: 2.6128509729864686

Epoch: 6| Step: 7
Training loss: 0.32870303057784245
Validation loss: 2.6273976910578294

Epoch: 6| Step: 8
Training loss: 0.3133826664799773
Validation loss: 2.5273101662905844

Epoch: 6| Step: 9
Training loss: 0.25647971974893885
Validation loss: 2.577197021550663

Epoch: 6| Step: 10
Training loss: 0.22758574272996768
Validation loss: 2.6261641327929532

Epoch: 6| Step: 11
Training loss: 0.2687627783775884
Validation loss: 2.637473503690815

Epoch: 6| Step: 12
Training loss: 0.31936639529691047
Validation loss: 2.6331697366896463

Epoch: 6| Step: 13
Training loss: 0.24508012438205706
Validation loss: 2.5993456860829527

Epoch: 503| Step: 0
Training loss: 0.24662327940747175
Validation loss: 2.6171933454002274

Epoch: 6| Step: 1
Training loss: 0.25851399900467453
Validation loss: 2.6024436489457576

Epoch: 6| Step: 2
Training loss: 0.3155999683613997
Validation loss: 2.6628388160909693

Epoch: 6| Step: 3
Training loss: 0.23880205927480883
Validation loss: 2.6100898646697033

Epoch: 6| Step: 4
Training loss: 0.3283712734450948
Validation loss: 2.6196808434487178

Epoch: 6| Step: 5
Training loss: 0.35585413990713344
Validation loss: 2.5902599462509586

Epoch: 6| Step: 6
Training loss: 0.32649292820783044
Validation loss: 2.592150842469896

Epoch: 6| Step: 7
Training loss: 0.3099757526897747
Validation loss: 2.560799352253041

Epoch: 6| Step: 8
Training loss: 0.24344740296569253
Validation loss: 2.5903755896211016

Epoch: 6| Step: 9
Training loss: 0.42230446466601124
Validation loss: 2.596297059089515

Epoch: 6| Step: 10
Training loss: 0.1881778504346945
Validation loss: 2.556976366255367

Epoch: 6| Step: 11
Training loss: 0.26358826335901914
Validation loss: 2.6546642955823407

Epoch: 6| Step: 12
Training loss: 0.26164685870376514
Validation loss: 2.6371469710381468

Epoch: 6| Step: 13
Training loss: 0.36323895772229714
Validation loss: 2.5992345159916437

Epoch: 504| Step: 0
Training loss: 0.3042676061968217
Validation loss: 2.584868549175002

Epoch: 6| Step: 1
Training loss: 0.3335581173057605
Validation loss: 2.5557296291672484

Epoch: 6| Step: 2
Training loss: 0.2777107523812555
Validation loss: 2.599138186136578

Epoch: 6| Step: 3
Training loss: 0.2354226697448939
Validation loss: 2.6035325359111012

Epoch: 6| Step: 4
Training loss: 0.3160939382457314
Validation loss: 2.580983790601328

Epoch: 6| Step: 5
Training loss: 0.2313265435378291
Validation loss: 2.584587121059068

Epoch: 6| Step: 6
Training loss: 0.2663911680947345
Validation loss: 2.5647690039286153

Epoch: 6| Step: 7
Training loss: 0.2522423437107827
Validation loss: 2.5786162784931967

Epoch: 6| Step: 8
Training loss: 0.38560174244342554
Validation loss: 2.5980879804897947

Epoch: 6| Step: 9
Training loss: 0.21717727211670118
Validation loss: 2.6361111918177946

Epoch: 6| Step: 10
Training loss: 0.2891445558946099
Validation loss: 2.6014436192505115

Epoch: 6| Step: 11
Training loss: 0.28531723181486984
Validation loss: 2.5704243025962863

Epoch: 6| Step: 12
Training loss: 0.22505555824616927
Validation loss: 2.6313417214832637

Epoch: 6| Step: 13
Training loss: 0.2315330821822192
Validation loss: 2.6154235816982863

Epoch: 505| Step: 0
Training loss: 0.2068587250084501
Validation loss: 2.5771393558351336

Epoch: 6| Step: 1
Training loss: 0.24947832485022436
Validation loss: 2.6056532825433507

Epoch: 6| Step: 2
Training loss: 0.3170034870759164
Validation loss: 2.6403211610687904

Epoch: 6| Step: 3
Training loss: 0.23759113495669676
Validation loss: 2.6034860459040376

Epoch: 6| Step: 4
Training loss: 0.3161433976575528
Validation loss: 2.579537445947602

Epoch: 6| Step: 5
Training loss: 0.36071324999146637
Validation loss: 2.576510692697876

Epoch: 6| Step: 6
Training loss: 0.30610077102655003
Validation loss: 2.580677456663308

Epoch: 6| Step: 7
Training loss: 0.35882945739246236
Validation loss: 2.6672833271090406

Epoch: 6| Step: 8
Training loss: 0.2888929153137845
Validation loss: 2.629155971386451

Epoch: 6| Step: 9
Training loss: 0.1977118741801363
Validation loss: 2.625355817506073

Epoch: 6| Step: 10
Training loss: 0.25382401528499493
Validation loss: 2.568997016532792

Epoch: 6| Step: 11
Training loss: 0.23603960821382647
Validation loss: 2.6331675108073576

Epoch: 6| Step: 12
Training loss: 0.2116796277910744
Validation loss: 2.595592533737969

Epoch: 6| Step: 13
Training loss: 0.35843015940964457
Validation loss: 2.6091872431348717

Epoch: 506| Step: 0
Training loss: 0.3189830988910533
Validation loss: 2.5748647632702495

Epoch: 6| Step: 1
Training loss: 0.3767126235242239
Validation loss: 2.5377343719435133

Epoch: 6| Step: 2
Training loss: 0.2426448165204315
Validation loss: 2.6109919154464367

Epoch: 6| Step: 3
Training loss: 0.23914110100794428
Validation loss: 2.637377154244974

Epoch: 6| Step: 4
Training loss: 0.3511806109299726
Validation loss: 2.59665680973629

Epoch: 6| Step: 5
Training loss: 0.35739235677930375
Validation loss: 2.615760163491706

Epoch: 6| Step: 6
Training loss: 0.28475955909579126
Validation loss: 2.6517427537920444

Epoch: 6| Step: 7
Training loss: 0.21929131526986517
Validation loss: 2.6596433020808234

Epoch: 6| Step: 8
Training loss: 0.2516443149138602
Validation loss: 2.6366237293594152

Epoch: 6| Step: 9
Training loss: 0.28925015827692263
Validation loss: 2.5697095138557566

Epoch: 6| Step: 10
Training loss: 0.33179083703468426
Validation loss: 2.5825828159344026

Epoch: 6| Step: 11
Training loss: 0.2269953342128387
Validation loss: 2.6117843803780962

Epoch: 6| Step: 12
Training loss: 0.3031117333134058
Validation loss: 2.635710241277971

Epoch: 6| Step: 13
Training loss: 0.28201375679861146
Validation loss: 2.5965779066851105

Epoch: 507| Step: 0
Training loss: 0.26785228077699136
Validation loss: 2.6367306254555105

Epoch: 6| Step: 1
Training loss: 0.32914571720569297
Validation loss: 2.630743192671716

Epoch: 6| Step: 2
Training loss: 0.23322505975565685
Validation loss: 2.619949682385894

Epoch: 6| Step: 3
Training loss: 0.20697796333768242
Validation loss: 2.6412561478718524

Epoch: 6| Step: 4
Training loss: 0.2744987737154017
Validation loss: 2.6449468033554395

Epoch: 6| Step: 5
Training loss: 0.2606653964801567
Validation loss: 2.620791179477682

Epoch: 6| Step: 6
Training loss: 0.3668503532384051
Validation loss: 2.5725579159676646

Epoch: 6| Step: 7
Training loss: 0.30435157254901524
Validation loss: 2.6333088770064723

Epoch: 6| Step: 8
Training loss: 0.21518489455818207
Validation loss: 2.6215096990258084

Epoch: 6| Step: 9
Training loss: 0.3791232126962935
Validation loss: 2.656149738887905

Epoch: 6| Step: 10
Training loss: 0.3019595043105626
Validation loss: 2.5911226255569253

Epoch: 6| Step: 11
Training loss: 0.25983256001099453
Validation loss: 2.617172787753075

Epoch: 6| Step: 12
Training loss: 0.23058007671152925
Validation loss: 2.5772113992319836

Epoch: 6| Step: 13
Training loss: 0.24087671917171682
Validation loss: 2.6508192532415364

Epoch: 508| Step: 0
Training loss: 0.1430324019293377
Validation loss: 2.6271710424783863

Epoch: 6| Step: 1
Training loss: 0.2558959032147805
Validation loss: 2.606762025089734

Epoch: 6| Step: 2
Training loss: 0.2798641020223506
Validation loss: 2.603784339813858

Epoch: 6| Step: 3
Training loss: 0.3142325533998597
Validation loss: 2.6117873623760985

Epoch: 6| Step: 4
Training loss: 0.38603481347715146
Validation loss: 2.5971131486026353

Epoch: 6| Step: 5
Training loss: 0.2807532002359205
Validation loss: 2.6093667614591673

Epoch: 6| Step: 6
Training loss: 0.26508468482650255
Validation loss: 2.6510228804026985

Epoch: 6| Step: 7
Training loss: 0.2551192871110151
Validation loss: 2.610709939624657

Epoch: 6| Step: 8
Training loss: 0.2633220612677676
Validation loss: 2.6352814173515524

Epoch: 6| Step: 9
Training loss: 0.26401249112937025
Validation loss: 2.62777940501628

Epoch: 6| Step: 10
Training loss: 0.31842119985683237
Validation loss: 2.551383741338174

Epoch: 6| Step: 11
Training loss: 0.25644003520570535
Validation loss: 2.5868208990701635

Epoch: 6| Step: 12
Training loss: 0.341093855336654
Validation loss: 2.624572264926615

Epoch: 6| Step: 13
Training loss: 0.26089330287495044
Validation loss: 2.55706175931528

Epoch: 509| Step: 0
Training loss: 0.2959357008431195
Validation loss: 2.6102709421784587

Epoch: 6| Step: 1
Training loss: 0.23139494335774688
Validation loss: 2.5963173841028273

Epoch: 6| Step: 2
Training loss: 0.3530821170762678
Validation loss: 2.5937248596443747

Epoch: 6| Step: 3
Training loss: 0.32405804477450595
Validation loss: 2.6570323764253145

Epoch: 6| Step: 4
Training loss: 0.21170489804325499
Validation loss: 2.5429231529230205

Epoch: 6| Step: 5
Training loss: 0.2320652638174977
Validation loss: 2.5773442020437063

Epoch: 6| Step: 6
Training loss: 0.276102970921367
Validation loss: 2.6796780392375052

Epoch: 6| Step: 7
Training loss: 0.27274758631742274
Validation loss: 2.6360219604612625

Epoch: 6| Step: 8
Training loss: 0.2857076721830944
Validation loss: 2.6587166646336153

Epoch: 6| Step: 9
Training loss: 0.3458345669797166
Validation loss: 2.635570896043549

Epoch: 6| Step: 10
Training loss: 0.2658455578141779
Validation loss: 2.6160097727150706

Epoch: 6| Step: 11
Training loss: 0.28681463566390414
Validation loss: 2.5627616035472376

Epoch: 6| Step: 12
Training loss: 0.18884449953697138
Validation loss: 2.6292394735791715

Epoch: 6| Step: 13
Training loss: 0.2426879388538512
Validation loss: 2.5900415313366043

Epoch: 510| Step: 0
Training loss: 0.3584844501613167
Validation loss: 2.595442438059412

Epoch: 6| Step: 1
Training loss: 0.2989404753868507
Validation loss: 2.6418691108300454

Epoch: 6| Step: 2
Training loss: 0.22623818303435128
Validation loss: 2.6238416583471458

Epoch: 6| Step: 3
Training loss: 0.29319972787703913
Validation loss: 2.603180925089846

Epoch: 6| Step: 4
Training loss: 0.30420482746666555
Validation loss: 2.627666300003405

Epoch: 6| Step: 5
Training loss: 0.30516760242946483
Validation loss: 2.623273932920715

Epoch: 6| Step: 6
Training loss: 0.3657477335869428
Validation loss: 2.5844147223633787

Epoch: 6| Step: 7
Training loss: 0.31049282875241496
Validation loss: 2.6281051662209225

Epoch: 6| Step: 8
Training loss: 0.25140074866744055
Validation loss: 2.6025779124802177

Epoch: 6| Step: 9
Training loss: 0.22785417078841383
Validation loss: 2.6127957290751747

Epoch: 6| Step: 10
Training loss: 0.24431307233615057
Validation loss: 2.603887319205105

Epoch: 6| Step: 11
Training loss: 0.3408086386706184
Validation loss: 2.58796416556034

Epoch: 6| Step: 12
Training loss: 0.24075280826679626
Validation loss: 2.557730166462278

Epoch: 6| Step: 13
Training loss: 0.14344405757649517
Validation loss: 2.54934201571384

Epoch: 511| Step: 0
Training loss: 0.3869783320189041
Validation loss: 2.6334899121423168

Epoch: 6| Step: 1
Training loss: 0.13583258493583938
Validation loss: 2.593952875744086

Epoch: 6| Step: 2
Training loss: 0.20900505177538906
Validation loss: 2.589936229345408

Epoch: 6| Step: 3
Training loss: 0.35822366720054544
Validation loss: 2.590931000102291

Epoch: 6| Step: 4
Training loss: 0.22301626379530542
Validation loss: 2.5987166532524086

Epoch: 6| Step: 5
Training loss: 0.25042139242212264
Validation loss: 2.6188682966439196

Epoch: 6| Step: 6
Training loss: 0.2767522441166536
Validation loss: 2.6219796788412393

Epoch: 6| Step: 7
Training loss: 0.21551804066583796
Validation loss: 2.539578726693644

Epoch: 6| Step: 8
Training loss: 0.24242226696812533
Validation loss: 2.634999183085229

Epoch: 6| Step: 9
Training loss: 0.15255079505140276
Validation loss: 2.6047744931722714

Epoch: 6| Step: 10
Training loss: 0.3852853895118622
Validation loss: 2.6210556368608002

Epoch: 6| Step: 11
Training loss: 0.24332970795042727
Validation loss: 2.622133279111858

Epoch: 6| Step: 12
Training loss: 0.2083399096086798
Validation loss: 2.6154234297671373

Epoch: 6| Step: 13
Training loss: 0.3062803253418309
Validation loss: 2.638347697115475

Epoch: 512| Step: 0
Training loss: 0.27840973605397906
Validation loss: 2.607929705101519

Epoch: 6| Step: 1
Training loss: 0.2970538102782534
Validation loss: 2.6607617227404265

Epoch: 6| Step: 2
Training loss: 0.3730909710930856
Validation loss: 2.577598086370693

Epoch: 6| Step: 3
Training loss: 0.31211949070661726
Validation loss: 2.650390729948682

Epoch: 6| Step: 4
Training loss: 0.25305558536209266
Validation loss: 2.662403742523268

Epoch: 6| Step: 5
Training loss: 0.3538773093274546
Validation loss: 2.6234204520269335

Epoch: 6| Step: 6
Training loss: 0.3303708465782727
Validation loss: 2.658848960838988

Epoch: 6| Step: 7
Training loss: 0.19762080858648898
Validation loss: 2.5904147140628924

Epoch: 6| Step: 8
Training loss: 0.23983190519676673
Validation loss: 2.577045977811801

Epoch: 6| Step: 9
Training loss: 0.21462226201301107
Validation loss: 2.6090391708173555

Epoch: 6| Step: 10
Training loss: 0.272572538975173
Validation loss: 2.596386997598181

Epoch: 6| Step: 11
Training loss: 0.2104795217270965
Validation loss: 2.6277526924391217

Epoch: 6| Step: 12
Training loss: 0.28794028269269994
Validation loss: 2.6019479124342197

Epoch: 6| Step: 13
Training loss: 0.31990349638784993
Validation loss: 2.6380770879071602

Epoch: 513| Step: 0
Training loss: 0.2754791333972809
Validation loss: 2.6458213285238905

Epoch: 6| Step: 1
Training loss: 0.16011822644557624
Validation loss: 2.677814626198367

Epoch: 6| Step: 2
Training loss: 0.18206704242145583
Validation loss: 2.6403353229369606

Epoch: 6| Step: 3
Training loss: 0.2793347393058735
Validation loss: 2.6117502697301567

Epoch: 6| Step: 4
Training loss: 0.29963660731886627
Validation loss: 2.647747711405886

Epoch: 6| Step: 5
Training loss: 0.2594808580784218
Validation loss: 2.566810765700759

Epoch: 6| Step: 6
Training loss: 0.1680651044601216
Validation loss: 2.608204897154901

Epoch: 6| Step: 7
Training loss: 0.1930664135822455
Validation loss: 2.622913182028793

Epoch: 6| Step: 8
Training loss: 0.2179527399889842
Validation loss: 2.607970790733109

Epoch: 6| Step: 9
Training loss: 0.3656840692390831
Validation loss: 2.610827698330643

Epoch: 6| Step: 10
Training loss: 0.2146408163007206
Validation loss: 2.625808818278577

Epoch: 6| Step: 11
Training loss: 0.2186442528301494
Validation loss: 2.6210465481445357

Epoch: 6| Step: 12
Training loss: 0.23489972028173647
Validation loss: 2.603451414430156

Epoch: 6| Step: 13
Training loss: 0.29261394632866816
Validation loss: 2.650787616140837

Epoch: 514| Step: 0
Training loss: 0.3233465043663363
Validation loss: 2.640551707136565

Epoch: 6| Step: 1
Training loss: 0.21343346603122476
Validation loss: 2.621853501811833

Epoch: 6| Step: 2
Training loss: 0.339163504995064
Validation loss: 2.5907916314159576

Epoch: 6| Step: 3
Training loss: 0.3770418211003968
Validation loss: 2.5892831724057306

Epoch: 6| Step: 4
Training loss: 0.31738518347221367
Validation loss: 2.631531733080967

Epoch: 6| Step: 5
Training loss: 0.35184052388228115
Validation loss: 2.6269222366426757

Epoch: 6| Step: 6
Training loss: 0.1974450419109439
Validation loss: 2.6078282262268138

Epoch: 6| Step: 7
Training loss: 0.331167376308388
Validation loss: 2.6195332656945127

Epoch: 6| Step: 8
Training loss: 0.23324824332836067
Validation loss: 2.6340072441513174

Epoch: 6| Step: 9
Training loss: 0.2039079614910924
Validation loss: 2.5859297246134205

Epoch: 6| Step: 10
Training loss: 0.2459607673287958
Validation loss: 2.614894397565359

Epoch: 6| Step: 11
Training loss: 0.24348850895989715
Validation loss: 2.588946893444241

Epoch: 6| Step: 12
Training loss: 0.30777119005943854
Validation loss: 2.6239130100779597

Epoch: 6| Step: 13
Training loss: 0.3813698892791705
Validation loss: 2.660980888486343

Epoch: 515| Step: 0
Training loss: 0.27907187729103106
Validation loss: 2.579169321957538

Epoch: 6| Step: 1
Training loss: 0.319102560735928
Validation loss: 2.609265247100252

Epoch: 6| Step: 2
Training loss: 0.2435886246225812
Validation loss: 2.607444551633601

Epoch: 6| Step: 3
Training loss: 0.20037824135155843
Validation loss: 2.6508518043585267

Epoch: 6| Step: 4
Training loss: 0.2585829435781586
Validation loss: 2.621287869780335

Epoch: 6| Step: 5
Training loss: 0.38539963976734826
Validation loss: 2.5807451747445276

Epoch: 6| Step: 6
Training loss: 0.23403987767558632
Validation loss: 2.595779834969585

Epoch: 6| Step: 7
Training loss: 0.382832156863887
Validation loss: 2.645206817781146

Epoch: 6| Step: 8
Training loss: 0.18994339694276852
Validation loss: 2.6125106245491057

Epoch: 6| Step: 9
Training loss: 0.31372248430154626
Validation loss: 2.6115419142902545

Epoch: 6| Step: 10
Training loss: 0.256090860263238
Validation loss: 2.5984391258909056

Epoch: 6| Step: 11
Training loss: 0.3164542715106202
Validation loss: 2.6184440670802918

Epoch: 6| Step: 12
Training loss: 0.31812949745131813
Validation loss: 2.615454712204556

Epoch: 6| Step: 13
Training loss: 0.30187958664499726
Validation loss: 2.6030631410256224

Epoch: 516| Step: 0
Training loss: 0.2823933435276599
Validation loss: 2.6404410454293465

Epoch: 6| Step: 1
Training loss: 0.3394540437745192
Validation loss: 2.612053309434538

Epoch: 6| Step: 2
Training loss: 0.38242065071011294
Validation loss: 2.5859075047039317

Epoch: 6| Step: 3
Training loss: 0.32221267727621566
Validation loss: 2.6225538663904984

Epoch: 6| Step: 4
Training loss: 0.25391226541289263
Validation loss: 2.590050368316348

Epoch: 6| Step: 5
Training loss: 0.2304360802981515
Validation loss: 2.5992039403253666

Epoch: 6| Step: 6
Training loss: 0.2499497258777378
Validation loss: 2.601809912783895

Epoch: 6| Step: 7
Training loss: 0.20285501326944907
Validation loss: 2.6023940093058977

Epoch: 6| Step: 8
Training loss: 0.18146389392854248
Validation loss: 2.5778712600532656

Epoch: 6| Step: 9
Training loss: 0.34493833742352836
Validation loss: 2.5991655597111616

Epoch: 6| Step: 10
Training loss: 0.2618089492003392
Validation loss: 2.6072713629896893

Epoch: 6| Step: 11
Training loss: 0.4788840763254533
Validation loss: 2.5937899850727733

Epoch: 6| Step: 12
Training loss: 0.27624146260580407
Validation loss: 2.5882098153440354

Epoch: 6| Step: 13
Training loss: 0.2464420034319736
Validation loss: 2.6540139454291016

Epoch: 517| Step: 0
Training loss: 0.2379452259060933
Validation loss: 2.620410934476749

Epoch: 6| Step: 1
Training loss: 0.45871507576679954
Validation loss: 2.5892218240519354

Epoch: 6| Step: 2
Training loss: 0.23960420873474816
Validation loss: 2.5964226951215292

Epoch: 6| Step: 3
Training loss: 0.19470323903128142
Validation loss: 2.5971628126760327

Epoch: 6| Step: 4
Training loss: 0.3410446172146561
Validation loss: 2.6026544121902577

Epoch: 6| Step: 5
Training loss: 0.3287388418573995
Validation loss: 2.5899579467452387

Epoch: 6| Step: 6
Training loss: 0.25417249365417227
Validation loss: 2.6093590330446297

Epoch: 6| Step: 7
Training loss: 0.31071792546185606
Validation loss: 2.6346371343419235

Epoch: 6| Step: 8
Training loss: 0.4110659365957667
Validation loss: 2.6017572828352016

Epoch: 6| Step: 9
Training loss: 0.38597412862204333
Validation loss: 2.588316408074582

Epoch: 6| Step: 10
Training loss: 0.22380339267825017
Validation loss: 2.625525928974914

Epoch: 6| Step: 11
Training loss: 0.259944481332395
Validation loss: 2.59599542514827

Epoch: 6| Step: 12
Training loss: 0.36857448538857035
Validation loss: 2.6678878898524294

Epoch: 6| Step: 13
Training loss: 0.2799859250311717
Validation loss: 2.600634878235

Epoch: 518| Step: 0
Training loss: 0.210673060494686
Validation loss: 2.614298760681594

Epoch: 6| Step: 1
Training loss: 0.20487802825374782
Validation loss: 2.5998023783332704

Epoch: 6| Step: 2
Training loss: 0.2732696563023752
Validation loss: 2.600694322494099

Epoch: 6| Step: 3
Training loss: 0.2614530096740596
Validation loss: 2.5819953765916392

Epoch: 6| Step: 4
Training loss: 0.2655829228004113
Validation loss: 2.6141073292629455

Epoch: 6| Step: 5
Training loss: 0.378477246963712
Validation loss: 2.5550138088184116

Epoch: 6| Step: 6
Training loss: 0.23396365307992895
Validation loss: 2.595983868474855

Epoch: 6| Step: 7
Training loss: 0.30182955484712637
Validation loss: 2.5856412274149045

Epoch: 6| Step: 8
Training loss: 0.2858865609160296
Validation loss: 2.6110966726562235

Epoch: 6| Step: 9
Training loss: 0.5197002451532934
Validation loss: 2.6084908912123814

Epoch: 6| Step: 10
Training loss: 0.24500300114846832
Validation loss: 2.611897404849913

Epoch: 6| Step: 11
Training loss: 0.24706391940685019
Validation loss: 2.5776090548804205

Epoch: 6| Step: 12
Training loss: 0.31960733062903407
Validation loss: 2.5699753776934284

Epoch: 6| Step: 13
Training loss: 0.3746262316844245
Validation loss: 2.5833437263115635

Epoch: 519| Step: 0
Training loss: 0.2424324089414594
Validation loss: 2.6449007708679804

Epoch: 6| Step: 1
Training loss: 0.30632931402355573
Validation loss: 2.6450778202899072

Epoch: 6| Step: 2
Training loss: 0.32725596013189545
Validation loss: 2.5854659250768477

Epoch: 6| Step: 3
Training loss: 0.3064528576789382
Validation loss: 2.5948712326912595

Epoch: 6| Step: 4
Training loss: 0.3250664464259562
Validation loss: 2.619078906396699

Epoch: 6| Step: 5
Training loss: 0.28503041561018383
Validation loss: 2.6149870015022474

Epoch: 6| Step: 6
Training loss: 0.28895752521411977
Validation loss: 2.6338931317596854

Epoch: 6| Step: 7
Training loss: 0.2014321707980174
Validation loss: 2.580067236292827

Epoch: 6| Step: 8
Training loss: 0.36094550416997095
Validation loss: 2.641169836052721

Epoch: 6| Step: 9
Training loss: 0.26189068228349616
Validation loss: 2.602366791845225

Epoch: 6| Step: 10
Training loss: 0.2992471238271348
Validation loss: 2.559409114996873

Epoch: 6| Step: 11
Training loss: 0.1991576587280606
Validation loss: 2.6254824467502473

Epoch: 6| Step: 12
Training loss: 0.16434719724461624
Validation loss: 2.5882760928035733

Epoch: 6| Step: 13
Training loss: 0.24572578804768033
Validation loss: 2.6244492785692533

Epoch: 520| Step: 0
Training loss: 0.25148534598611916
Validation loss: 2.6352691659373053

Epoch: 6| Step: 1
Training loss: 0.35077795863996913
Validation loss: 2.644720404136765

Epoch: 6| Step: 2
Training loss: 0.21993596589121706
Validation loss: 2.589308939048201

Epoch: 6| Step: 3
Training loss: 0.1953110980937236
Validation loss: 2.6010259737563155

Epoch: 6| Step: 4
Training loss: 0.24297010967205376
Validation loss: 2.6337127655636867

Epoch: 6| Step: 5
Training loss: 0.2056476677050271
Validation loss: 2.6327924265412284

Epoch: 6| Step: 6
Training loss: 0.36150508362083045
Validation loss: 2.5961511367392465

Epoch: 6| Step: 7
Training loss: 0.3403832001715737
Validation loss: 2.6741370428324105

Epoch: 6| Step: 8
Training loss: 0.2588608552208046
Validation loss: 2.6112090649279156

Epoch: 6| Step: 9
Training loss: 0.2706526633565526
Validation loss: 2.5741561550157512

Epoch: 6| Step: 10
Training loss: 0.3148784249192528
Validation loss: 2.647613066989643

Epoch: 6| Step: 11
Training loss: 0.3235511225460577
Validation loss: 2.5811234117553203

Epoch: 6| Step: 12
Training loss: 0.2766849726175258
Validation loss: 2.6311826481357867

Epoch: 6| Step: 13
Training loss: 0.3190912364905179
Validation loss: 2.6280473399018476

Epoch: 521| Step: 0
Training loss: 0.20934879758198896
Validation loss: 2.5772840033701385

Epoch: 6| Step: 1
Training loss: 0.3042636515313838
Validation loss: 2.6185516446177637

Epoch: 6| Step: 2
Training loss: 0.24802536007545786
Validation loss: 2.6208694748643078

Epoch: 6| Step: 3
Training loss: 0.26434071798780795
Validation loss: 2.5897189916266665

Epoch: 6| Step: 4
Training loss: 0.3471889462685527
Validation loss: 2.5860425115278836

Epoch: 6| Step: 5
Training loss: 0.28133963110354715
Validation loss: 2.6535590509831213

Epoch: 6| Step: 6
Training loss: 0.20993909500415614
Validation loss: 2.692869868988653

Epoch: 6| Step: 7
Training loss: 0.36285194543971677
Validation loss: 2.6035642664668384

Epoch: 6| Step: 8
Training loss: 0.23940872571078656
Validation loss: 2.6083495129417593

Epoch: 6| Step: 9
Training loss: 0.1746857094374386
Validation loss: 2.608067525679371

Epoch: 6| Step: 10
Training loss: 0.30318321671819093
Validation loss: 2.60776537895867

Epoch: 6| Step: 11
Training loss: 0.32869414514997075
Validation loss: 2.659927320969344

Epoch: 6| Step: 12
Training loss: 0.1869100289223473
Validation loss: 2.571957372039248

Epoch: 6| Step: 13
Training loss: 0.32971137172819615
Validation loss: 2.6149570810942513

Epoch: 522| Step: 0
Training loss: 0.32988636383078385
Validation loss: 2.6204807950049833

Epoch: 6| Step: 1
Training loss: 0.25452769596061026
Validation loss: 2.665958196186826

Epoch: 6| Step: 2
Training loss: 0.2847148928564706
Validation loss: 2.654340813361763

Epoch: 6| Step: 3
Training loss: 0.31340258904990104
Validation loss: 2.624808788904274

Epoch: 6| Step: 4
Training loss: 0.3156710666615367
Validation loss: 2.6022883291459533

Epoch: 6| Step: 5
Training loss: 0.33642139625736717
Validation loss: 2.6413046810461402

Epoch: 6| Step: 6
Training loss: 0.2456158812118773
Validation loss: 2.6325273368795106

Epoch: 6| Step: 7
Training loss: 0.21565728913297158
Validation loss: 2.5734222677243648

Epoch: 6| Step: 8
Training loss: 0.23671992588065902
Validation loss: 2.6157788789332534

Epoch: 6| Step: 9
Training loss: 0.421522381671357
Validation loss: 2.6264117168692103

Epoch: 6| Step: 10
Training loss: 0.2788147132322215
Validation loss: 2.584678827621048

Epoch: 6| Step: 11
Training loss: 0.2638257460731202
Validation loss: 2.6764980868850485

Epoch: 6| Step: 12
Training loss: 0.22045685523136105
Validation loss: 2.6240193185133904

Epoch: 6| Step: 13
Training loss: 0.20243310465079237
Validation loss: 2.6392993797353066

Epoch: 523| Step: 0
Training loss: 0.2142805172653321
Validation loss: 2.6332845142120713

Epoch: 6| Step: 1
Training loss: 0.22535834453161765
Validation loss: 2.6461870803044008

Epoch: 6| Step: 2
Training loss: 0.16844525503378127
Validation loss: 2.6389398859907676

Epoch: 6| Step: 3
Training loss: 0.3233467232661566
Validation loss: 2.595982123489233

Epoch: 6| Step: 4
Training loss: 0.3412775290217973
Validation loss: 2.562011377533171

Epoch: 6| Step: 5
Training loss: 0.443614399030637
Validation loss: 2.5982499823211618

Epoch: 6| Step: 6
Training loss: 0.22707545648848343
Validation loss: 2.5905873116826013

Epoch: 6| Step: 7
Training loss: 0.3085183643056201
Validation loss: 2.6278287919473553

Epoch: 6| Step: 8
Training loss: 0.25476796569965526
Validation loss: 2.617999232794035

Epoch: 6| Step: 9
Training loss: 0.27601838763463515
Validation loss: 2.6129565453004338

Epoch: 6| Step: 10
Training loss: 0.26812719826586334
Validation loss: 2.6387722129013333

Epoch: 6| Step: 11
Training loss: 0.264811068180977
Validation loss: 2.6128678082696846

Epoch: 6| Step: 12
Training loss: 0.2578673015495647
Validation loss: 2.624375208416857

Epoch: 6| Step: 13
Training loss: 0.22074820471645973
Validation loss: 2.595764710533168

Epoch: 524| Step: 0
Training loss: 0.3332109922171237
Validation loss: 2.575168864568001

Epoch: 6| Step: 1
Training loss: 0.21473325141924224
Validation loss: 2.6594577195197227

Epoch: 6| Step: 2
Training loss: 0.2910285153190349
Validation loss: 2.5810412164693313

Epoch: 6| Step: 3
Training loss: 0.34011192264252016
Validation loss: 2.610749771488799

Epoch: 6| Step: 4
Training loss: 0.28990736774732
Validation loss: 2.593044560415991

Epoch: 6| Step: 5
Training loss: 0.25046110842370023
Validation loss: 2.6039243865161215

Epoch: 6| Step: 6
Training loss: 0.3069489016767861
Validation loss: 2.644153141580642

Epoch: 6| Step: 7
Training loss: 0.25876355315386124
Validation loss: 2.607051965046099

Epoch: 6| Step: 8
Training loss: 0.2446472404751584
Validation loss: 2.5804522558569225

Epoch: 6| Step: 9
Training loss: 0.22879559736019497
Validation loss: 2.6338008304682408

Epoch: 6| Step: 10
Training loss: 0.39832334192000696
Validation loss: 2.6449067728646862

Epoch: 6| Step: 11
Training loss: 0.18317043931973248
Validation loss: 2.6373304622934732

Epoch: 6| Step: 12
Training loss: 0.2252171379292079
Validation loss: 2.6322579181793704

Epoch: 6| Step: 13
Training loss: 0.23786865533815676
Validation loss: 2.6064666255509743

Epoch: 525| Step: 0
Training loss: 0.280210826938316
Validation loss: 2.590205654904942

Epoch: 6| Step: 1
Training loss: 0.32583536846634287
Validation loss: 2.620671669886913

Epoch: 6| Step: 2
Training loss: 0.23307881356705518
Validation loss: 2.607568378118826

Epoch: 6| Step: 3
Training loss: 0.19740664285605905
Validation loss: 2.644778489426465

Epoch: 6| Step: 4
Training loss: 0.29591042270874757
Validation loss: 2.6116131532108513

Epoch: 6| Step: 5
Training loss: 0.14838648220504033
Validation loss: 2.628154146363204

Epoch: 6| Step: 6
Training loss: 0.25536730090619686
Validation loss: 2.640706762669453

Epoch: 6| Step: 7
Training loss: 0.21589048461732802
Validation loss: 2.586245392662678

Epoch: 6| Step: 8
Training loss: 0.29386409004888225
Validation loss: 2.641907811114147

Epoch: 6| Step: 9
Training loss: 0.25430302063156396
Validation loss: 2.6566332746255505

Epoch: 6| Step: 10
Training loss: 0.28231899767296437
Validation loss: 2.6326269127761672

Epoch: 6| Step: 11
Training loss: 0.22148675967754294
Validation loss: 2.6083144966233447

Epoch: 6| Step: 12
Training loss: 0.2838219819794083
Validation loss: 2.6121165479368824

Epoch: 6| Step: 13
Training loss: 0.34301001923944585
Validation loss: 2.6114012870345027

Epoch: 526| Step: 0
Training loss: 0.29862318304091157
Validation loss: 2.633027638626545

Epoch: 6| Step: 1
Training loss: 0.22219149286837797
Validation loss: 2.6025711410673504

Epoch: 6| Step: 2
Training loss: 0.25853185287455094
Validation loss: 2.6297527460022945

Epoch: 6| Step: 3
Training loss: 0.23176206972219995
Validation loss: 2.6372020589311576

Epoch: 6| Step: 4
Training loss: 0.3265347090216742
Validation loss: 2.657774199954183

Epoch: 6| Step: 5
Training loss: 0.2649530860247108
Validation loss: 2.5813563585883323

Epoch: 6| Step: 6
Training loss: 0.21044535976332485
Validation loss: 2.6406541781346453

Epoch: 6| Step: 7
Training loss: 0.2337491899364123
Validation loss: 2.660690500440194

Epoch: 6| Step: 8
Training loss: 0.19873461144930604
Validation loss: 2.592967853812254

Epoch: 6| Step: 9
Training loss: 0.18805353592667454
Validation loss: 2.623465437642835

Epoch: 6| Step: 10
Training loss: 0.3472399415687158
Validation loss: 2.593203850968825

Epoch: 6| Step: 11
Training loss: 0.27827103831142824
Validation loss: 2.5989468535409914

Epoch: 6| Step: 12
Training loss: 0.22664883218374354
Validation loss: 2.6045332434457404

Epoch: 6| Step: 13
Training loss: 0.30007797856961677
Validation loss: 2.5963862859383844

Epoch: 527| Step: 0
Training loss: 0.23917480118610585
Validation loss: 2.5720244545384587

Epoch: 6| Step: 1
Training loss: 0.29779095893042035
Validation loss: 2.5719564604962337

Epoch: 6| Step: 2
Training loss: 0.2622431440720917
Validation loss: 2.55100456845303

Epoch: 6| Step: 3
Training loss: 0.28174803930140246
Validation loss: 2.6127329252526637

Epoch: 6| Step: 4
Training loss: 0.3052720795330906
Validation loss: 2.6118655168954965

Epoch: 6| Step: 5
Training loss: 0.19062212488476404
Validation loss: 2.585003518028989

Epoch: 6| Step: 6
Training loss: 0.344311710399
Validation loss: 2.574268300067264

Epoch: 6| Step: 7
Training loss: 0.2574002987700583
Validation loss: 2.5915473869653085

Epoch: 6| Step: 8
Training loss: 0.3187124716414043
Validation loss: 2.6023136005470286

Epoch: 6| Step: 9
Training loss: 0.26553063960553497
Validation loss: 2.57143443317603

Epoch: 6| Step: 10
Training loss: 0.2396973989722945
Validation loss: 2.5993566010418583

Epoch: 6| Step: 11
Training loss: 0.2096611011163937
Validation loss: 2.5736278343881107

Epoch: 6| Step: 12
Training loss: 0.2786390119531699
Validation loss: 2.656216580049795

Epoch: 6| Step: 13
Training loss: 0.20235793457979556
Validation loss: 2.6178648266741176

Epoch: 528| Step: 0
Training loss: 0.2964476722244361
Validation loss: 2.60256266723387

Epoch: 6| Step: 1
Training loss: 0.2506803850444876
Validation loss: 2.6423690273340665

Epoch: 6| Step: 2
Training loss: 0.24225258721701237
Validation loss: 2.6101600547229205

Epoch: 6| Step: 3
Training loss: 0.34109232630937136
Validation loss: 2.582318650187139

Epoch: 6| Step: 4
Training loss: 0.2390787349748244
Validation loss: 2.61896734496533

Epoch: 6| Step: 5
Training loss: 0.2778749483076726
Validation loss: 2.6009290685841298

Epoch: 6| Step: 6
Training loss: 0.27597439893993486
Validation loss: 2.6283226480147874

Epoch: 6| Step: 7
Training loss: 0.2767490942853186
Validation loss: 2.6205398269884705

Epoch: 6| Step: 8
Training loss: 0.21507168729371037
Validation loss: 2.5859458439165093

Epoch: 6| Step: 9
Training loss: 0.2986706087932244
Validation loss: 2.5980301666754895

Epoch: 6| Step: 10
Training loss: 0.23674148475576157
Validation loss: 2.608741348293686

Epoch: 6| Step: 11
Training loss: 0.26986593392724834
Validation loss: 2.634261836965867

Epoch: 6| Step: 12
Training loss: 0.29236790396701434
Validation loss: 2.615093475261188

Epoch: 6| Step: 13
Training loss: 0.29257539409182926
Validation loss: 2.632922342878565

Epoch: 529| Step: 0
Training loss: 0.311194075343899
Validation loss: 2.637453571170063

Epoch: 6| Step: 1
Training loss: 0.27442866927942533
Validation loss: 2.6824460895616222

Epoch: 6| Step: 2
Training loss: 0.3129943870865344
Validation loss: 2.6132937185373013

Epoch: 6| Step: 3
Training loss: 0.37474973592818855
Validation loss: 2.604491653509077

Epoch: 6| Step: 4
Training loss: 0.21658507302400026
Validation loss: 2.6474767271945536

Epoch: 6| Step: 5
Training loss: 0.33049563801277615
Validation loss: 2.6502680570953268

Epoch: 6| Step: 6
Training loss: 0.19556502230204165
Validation loss: 2.6055967117449086

Epoch: 6| Step: 7
Training loss: 0.370126769412371
Validation loss: 2.6070590830044886

Epoch: 6| Step: 8
Training loss: 0.3437234261384818
Validation loss: 2.6569058076192142

Epoch: 6| Step: 9
Training loss: 0.25078432907163206
Validation loss: 2.6284656504979043

Epoch: 6| Step: 10
Training loss: 0.41375051296697896
Validation loss: 2.5947966321491607

Epoch: 6| Step: 11
Training loss: 0.3883071414903813
Validation loss: 2.5991535202660927

Epoch: 6| Step: 12
Training loss: 0.18820758264819948
Validation loss: 2.604570271051346

Epoch: 6| Step: 13
Training loss: 0.1527208405178514
Validation loss: 2.6066988167483376

Epoch: 530| Step: 0
Training loss: 0.27076260242209266
Validation loss: 2.599465641105519

Epoch: 6| Step: 1
Training loss: 0.20666229913182985
Validation loss: 2.6487237256126988

Epoch: 6| Step: 2
Training loss: 0.2417146157649071
Validation loss: 2.6465648530967716

Epoch: 6| Step: 3
Training loss: 0.4288771357148199
Validation loss: 2.5811601901806194

Epoch: 6| Step: 4
Training loss: 0.23235161304316204
Validation loss: 2.6138938106049556

Epoch: 6| Step: 5
Training loss: 0.1909415384168334
Validation loss: 2.56540937334587

Epoch: 6| Step: 6
Training loss: 0.25104502475175644
Validation loss: 2.5944814454961054

Epoch: 6| Step: 7
Training loss: 0.3810249164473832
Validation loss: 2.567439799681743

Epoch: 6| Step: 8
Training loss: 0.34691012608464294
Validation loss: 2.5979432676452894

Epoch: 6| Step: 9
Training loss: 0.3701167848932095
Validation loss: 2.596628590999598

Epoch: 6| Step: 10
Training loss: 0.2700863388220527
Validation loss: 2.593766698821826

Epoch: 6| Step: 11
Training loss: 0.24310419962047494
Validation loss: 2.5857185816609967

Epoch: 6| Step: 12
Training loss: 0.3538719825912429
Validation loss: 2.5855690270060054

Epoch: 6| Step: 13
Training loss: 0.2965784850801923
Validation loss: 2.596209375035773

Epoch: 531| Step: 0
Training loss: 0.368978394074825
Validation loss: 2.6539079551028752

Epoch: 6| Step: 1
Training loss: 0.3549492151913455
Validation loss: 2.619090664600673

Epoch: 6| Step: 2
Training loss: 0.21812382551549256
Validation loss: 2.637529503776329

Epoch: 6| Step: 3
Training loss: 0.2839196972347009
Validation loss: 2.583698021363278

Epoch: 6| Step: 4
Training loss: 0.28307747519904336
Validation loss: 2.6170154268244703

Epoch: 6| Step: 5
Training loss: 0.2382196987888338
Validation loss: 2.6558708069855412

Epoch: 6| Step: 6
Training loss: 0.2715783539721632
Validation loss: 2.605016033259942

Epoch: 6| Step: 7
Training loss: 0.40426305730795503
Validation loss: 2.619779709370945

Epoch: 6| Step: 8
Training loss: 0.3388248054318913
Validation loss: 2.587317061292078

Epoch: 6| Step: 9
Training loss: 0.32154144068008855
Validation loss: 2.620231444883809

Epoch: 6| Step: 10
Training loss: 0.2928200280678265
Validation loss: 2.6182514969557906

Epoch: 6| Step: 11
Training loss: 0.29902667262484434
Validation loss: 2.6034278177543704

Epoch: 6| Step: 12
Training loss: 0.4725159523556834
Validation loss: 2.5886224213456424

Epoch: 6| Step: 13
Training loss: 0.263380228448759
Validation loss: 2.5765416301979376

Epoch: 532| Step: 0
Training loss: 0.2693113729382965
Validation loss: 2.6087935479426796

Epoch: 6| Step: 1
Training loss: 0.28353021083302055
Validation loss: 2.637397087343258

Epoch: 6| Step: 2
Training loss: 0.23608753473872685
Validation loss: 2.605172845374278

Epoch: 6| Step: 3
Training loss: 0.38060949882800665
Validation loss: 2.645260716348478

Epoch: 6| Step: 4
Training loss: 0.3044465897670936
Validation loss: 2.6347396091452104

Epoch: 6| Step: 5
Training loss: 0.2495110618149681
Validation loss: 2.5826851175092593

Epoch: 6| Step: 6
Training loss: 0.30859534347702217
Validation loss: 2.6131124171072906

Epoch: 6| Step: 7
Training loss: 0.20547658267158325
Validation loss: 2.5940038411276953

Epoch: 6| Step: 8
Training loss: 0.31693278171470307
Validation loss: 2.5940603047628046

Epoch: 6| Step: 9
Training loss: 0.41425962973793645
Validation loss: 2.6187179569538817

Epoch: 6| Step: 10
Training loss: 0.3566635299965081
Validation loss: 2.592042161554967

Epoch: 6| Step: 11
Training loss: 0.3363708096841783
Validation loss: 2.5795739003890468

Epoch: 6| Step: 12
Training loss: 0.3264580573296045
Validation loss: 2.6137452523790268

Epoch: 6| Step: 13
Training loss: 0.27047751356854405
Validation loss: 2.5665084222422156

Epoch: 533| Step: 0
Training loss: 0.3871722981483613
Validation loss: 2.6064102553535853

Epoch: 6| Step: 1
Training loss: 0.2103055388274924
Validation loss: 2.608899330138665

Epoch: 6| Step: 2
Training loss: 0.3338124574483742
Validation loss: 2.5822997230156877

Epoch: 6| Step: 3
Training loss: 0.21037972845224995
Validation loss: 2.627221832335413

Epoch: 6| Step: 4
Training loss: 0.27734896157969313
Validation loss: 2.6642031217659636

Epoch: 6| Step: 5
Training loss: 0.18146585444693536
Validation loss: 2.604573780026631

Epoch: 6| Step: 6
Training loss: 0.3685074679434487
Validation loss: 2.6101838645627495

Epoch: 6| Step: 7
Training loss: 0.3412423895067584
Validation loss: 2.6073961120932876

Epoch: 6| Step: 8
Training loss: 0.31888241308261894
Validation loss: 2.5959902973591307

Epoch: 6| Step: 9
Training loss: 0.14575184449873924
Validation loss: 2.6495239220037363

Epoch: 6| Step: 10
Training loss: 0.244989620312435
Validation loss: 2.6435989847782815

Epoch: 6| Step: 11
Training loss: 0.18139456418074884
Validation loss: 2.612453555800057

Epoch: 6| Step: 12
Training loss: 0.3606840011355586
Validation loss: 2.6305686527621237

Epoch: 6| Step: 13
Training loss: 0.33874876827987327
Validation loss: 2.6194461394940856

Epoch: 534| Step: 0
Training loss: 0.17358487500526945
Validation loss: 2.6214635733067735

Epoch: 6| Step: 1
Training loss: 0.21295462530011922
Validation loss: 2.615654157432738

Epoch: 6| Step: 2
Training loss: 0.2638671716877829
Validation loss: 2.6290709248887714

Epoch: 6| Step: 3
Training loss: 0.24078136293085559
Validation loss: 2.6881726110801303

Epoch: 6| Step: 4
Training loss: 0.3498146690422724
Validation loss: 2.6269489047218655

Epoch: 6| Step: 5
Training loss: 0.3034139082249872
Validation loss: 2.6648768190039247

Epoch: 6| Step: 6
Training loss: 0.16906785655041368
Validation loss: 2.648952977850977

Epoch: 6| Step: 7
Training loss: 0.2841017311375775
Validation loss: 2.589422821774528

Epoch: 6| Step: 8
Training loss: 0.3279773743373771
Validation loss: 2.633829518442284

Epoch: 6| Step: 9
Training loss: 0.3107888340779803
Validation loss: 2.625232292675253

Epoch: 6| Step: 10
Training loss: 0.22643498416738092
Validation loss: 2.6628897314530415

Epoch: 6| Step: 11
Training loss: 0.2551802584068864
Validation loss: 2.6109947081134437

Epoch: 6| Step: 12
Training loss: 0.3166071054113426
Validation loss: 2.62658158597379

Epoch: 6| Step: 13
Training loss: 0.1475584831717056
Validation loss: 2.6846037051169827

Epoch: 535| Step: 0
Training loss: 0.21511835408626098
Validation loss: 2.60581980050817

Epoch: 6| Step: 1
Training loss: 0.23834950610760444
Validation loss: 2.632548287828201

Epoch: 6| Step: 2
Training loss: 0.23863350517658233
Validation loss: 2.6142703219791215

Epoch: 6| Step: 3
Training loss: 0.2130008901915507
Validation loss: 2.63215008561084

Epoch: 6| Step: 4
Training loss: 0.2958946605479091
Validation loss: 2.598317456526226

Epoch: 6| Step: 5
Training loss: 0.16657475952421347
Validation loss: 2.6069172460168852

Epoch: 6| Step: 6
Training loss: 0.2565679275923628
Validation loss: 2.6134249842963375

Epoch: 6| Step: 7
Training loss: 0.3112486102368071
Validation loss: 2.6113300119001845

Epoch: 6| Step: 8
Training loss: 0.25527666435741436
Validation loss: 2.574165092839083

Epoch: 6| Step: 9
Training loss: 0.25952009198881976
Validation loss: 2.6034249940757346

Epoch: 6| Step: 10
Training loss: 0.30117362302676104
Validation loss: 2.629688632093712

Epoch: 6| Step: 11
Training loss: 0.25874904107178726
Validation loss: 2.586199252585007

Epoch: 6| Step: 12
Training loss: 0.37524582832071063
Validation loss: 2.6175701487923053

Epoch: 6| Step: 13
Training loss: 0.34455093362161654
Validation loss: 2.659457465513301

Epoch: 536| Step: 0
Training loss: 0.3722618190895059
Validation loss: 2.681607047303969

Epoch: 6| Step: 1
Training loss: 0.3495962257682912
Validation loss: 2.6101422124243707

Epoch: 6| Step: 2
Training loss: 0.1841750377986388
Validation loss: 2.6519475611963

Epoch: 6| Step: 3
Training loss: 0.27490325168710383
Validation loss: 2.598148859492769

Epoch: 6| Step: 4
Training loss: 0.32887348455836046
Validation loss: 2.588738222290341

Epoch: 6| Step: 5
Training loss: 0.3746782750639759
Validation loss: 2.631007978796717

Epoch: 6| Step: 6
Training loss: 0.2996870176532193
Validation loss: 2.6017612996099606

Epoch: 6| Step: 7
Training loss: 0.2655523004339562
Validation loss: 2.6166199177820046

Epoch: 6| Step: 8
Training loss: 0.19505598389443823
Validation loss: 2.5679175631461577

Epoch: 6| Step: 9
Training loss: 0.36646597564576133
Validation loss: 2.57666138998415

Epoch: 6| Step: 10
Training loss: 0.25408009666417763
Validation loss: 2.60484752655442

Epoch: 6| Step: 11
Training loss: 0.28536570707822717
Validation loss: 2.6194394723659165

Epoch: 6| Step: 12
Training loss: 0.1977612529378963
Validation loss: 2.6182741405013172

Epoch: 6| Step: 13
Training loss: 0.23557630073623856
Validation loss: 2.621723271898847

Epoch: 537| Step: 0
Training loss: 0.18489351181578698
Validation loss: 2.6109824949291593

Epoch: 6| Step: 1
Training loss: 0.21119208337620052
Validation loss: 2.569912200026636

Epoch: 6| Step: 2
Training loss: 0.34567923382462856
Validation loss: 2.5966339623771217

Epoch: 6| Step: 3
Training loss: 0.29836921110318737
Validation loss: 2.621107303226183

Epoch: 6| Step: 4
Training loss: 0.2672686632034421
Validation loss: 2.557055069388701

Epoch: 6| Step: 5
Training loss: 0.21474104073457295
Validation loss: 2.6642128015444735

Epoch: 6| Step: 6
Training loss: 0.37428059713933043
Validation loss: 2.638688334713228

Epoch: 6| Step: 7
Training loss: 0.2741723676183489
Validation loss: 2.598983891934162

Epoch: 6| Step: 8
Training loss: 0.20893991300403064
Validation loss: 2.617275953933185

Epoch: 6| Step: 9
Training loss: 0.26416055111670467
Validation loss: 2.5928615442549154

Epoch: 6| Step: 10
Training loss: 0.27758454897034224
Validation loss: 2.607214164318623

Epoch: 6| Step: 11
Training loss: 0.12301179976313924
Validation loss: 2.5903856986787535

Epoch: 6| Step: 12
Training loss: 0.1916800312033713
Validation loss: 2.5698336355191564

Epoch: 6| Step: 13
Training loss: 0.4061395971963017
Validation loss: 2.5989001209617397

Epoch: 538| Step: 0
Training loss: 0.3529457747271485
Validation loss: 2.5986361001237737

Epoch: 6| Step: 1
Training loss: 0.2806804904364041
Validation loss: 2.640919294642497

Epoch: 6| Step: 2
Training loss: 0.28059820306356204
Validation loss: 2.6111619126561143

Epoch: 6| Step: 3
Training loss: 0.3467331536126131
Validation loss: 2.605247964802878

Epoch: 6| Step: 4
Training loss: 0.2707035169282088
Validation loss: 2.602424929217386

Epoch: 6| Step: 5
Training loss: 0.2249650212755321
Validation loss: 2.6339817601330062

Epoch: 6| Step: 6
Training loss: 0.2834174824788631
Validation loss: 2.6187471212221043

Epoch: 6| Step: 7
Training loss: 0.20849920266042424
Validation loss: 2.5930891305767716

Epoch: 6| Step: 8
Training loss: 0.22651820736402667
Validation loss: 2.6307180584300616

Epoch: 6| Step: 9
Training loss: 0.4166232046666049
Validation loss: 2.6457099184904354

Epoch: 6| Step: 10
Training loss: 0.30951295435607007
Validation loss: 2.659336264328558

Epoch: 6| Step: 11
Training loss: 0.23381584543089864
Validation loss: 2.6049451554492973

Epoch: 6| Step: 12
Training loss: 0.2845987330626987
Validation loss: 2.60999747520997

Epoch: 6| Step: 13
Training loss: 0.3091412769201817
Validation loss: 2.597535752486999

Epoch: 539| Step: 0
Training loss: 0.27903113360834575
Validation loss: 2.627539534036956

Epoch: 6| Step: 1
Training loss: 0.3719850777945355
Validation loss: 2.648538668190293

Epoch: 6| Step: 2
Training loss: 0.39941880053109313
Validation loss: 2.611941371858535

Epoch: 6| Step: 3
Training loss: 0.22088547996610636
Validation loss: 2.615308871168519

Epoch: 6| Step: 4
Training loss: 0.28865904618226645
Validation loss: 2.65278674973529

Epoch: 6| Step: 5
Training loss: 0.252376894944225
Validation loss: 2.6056281960354073

Epoch: 6| Step: 6
Training loss: 0.28337720585062537
Validation loss: 2.5733522568963876

Epoch: 6| Step: 7
Training loss: 0.29491437182450275
Validation loss: 2.6013973515876363

Epoch: 6| Step: 8
Training loss: 0.2696685165053799
Validation loss: 2.580768208957417

Epoch: 6| Step: 9
Training loss: 0.35574606673317455
Validation loss: 2.6193530332954467

Epoch: 6| Step: 10
Training loss: 0.21205789984681006
Validation loss: 2.6470568498747453

Epoch: 6| Step: 11
Training loss: 0.24302646466655464
Validation loss: 2.6003201165347707

Epoch: 6| Step: 12
Training loss: 0.3036980948232042
Validation loss: 2.594617277329403

Epoch: 6| Step: 13
Training loss: 0.3567796158463729
Validation loss: 2.5806933085198756

Epoch: 540| Step: 0
Training loss: 0.31299429186972494
Validation loss: 2.619079771195435

Epoch: 6| Step: 1
Training loss: 0.36059936025698164
Validation loss: 2.6505958067283197

Epoch: 6| Step: 2
Training loss: 0.23941999893932234
Validation loss: 2.5719964753854034

Epoch: 6| Step: 3
Training loss: 0.4165469792444348
Validation loss: 2.5273132479604192

Epoch: 6| Step: 4
Training loss: 0.3237191913188184
Validation loss: 2.6022120095519607

Epoch: 6| Step: 5
Training loss: 0.26218523613335437
Validation loss: 2.626262088913036

Epoch: 6| Step: 6
Training loss: 0.17942803765104515
Validation loss: 2.6042445946795674

Epoch: 6| Step: 7
Training loss: 0.24183185675617402
Validation loss: 2.6071239058296616

Epoch: 6| Step: 8
Training loss: 0.2649489101158571
Validation loss: 2.600171218332922

Epoch: 6| Step: 9
Training loss: 0.28610442870298053
Validation loss: 2.63606881879408

Epoch: 6| Step: 10
Training loss: 0.2870351734422759
Validation loss: 2.5740372126333924

Epoch: 6| Step: 11
Training loss: 0.2095890833117737
Validation loss: 2.586027130386857

Epoch: 6| Step: 12
Training loss: 0.2836440238843555
Validation loss: 2.5807838446980216

Epoch: 6| Step: 13
Training loss: 0.2536751355524698
Validation loss: 2.5421481822888325

Epoch: 541| Step: 0
Training loss: 0.1598655807711901
Validation loss: 2.6067602187228607

Epoch: 6| Step: 1
Training loss: 0.26963620284783
Validation loss: 2.650703563501826

Epoch: 6| Step: 2
Training loss: 0.28355966683700873
Validation loss: 2.610175194700565

Epoch: 6| Step: 3
Training loss: 0.3496775001343772
Validation loss: 2.6218546839682073

Epoch: 6| Step: 4
Training loss: 0.28259738728853656
Validation loss: 2.62204831550412

Epoch: 6| Step: 5
Training loss: 0.253399798673476
Validation loss: 2.603540579239116

Epoch: 6| Step: 6
Training loss: 0.3583042530339729
Validation loss: 2.5999921884174864

Epoch: 6| Step: 7
Training loss: 0.34862917943605526
Validation loss: 2.622485508122631

Epoch: 6| Step: 8
Training loss: 0.3707018338694463
Validation loss: 2.610318590063688

Epoch: 6| Step: 9
Training loss: 0.2450964185571149
Validation loss: 2.6444622652493415

Epoch: 6| Step: 10
Training loss: 0.21612282519462517
Validation loss: 2.574675377194753

Epoch: 6| Step: 11
Training loss: 0.2303479734868607
Validation loss: 2.599309371348443

Epoch: 6| Step: 12
Training loss: 0.3180021376268048
Validation loss: 2.618091544778917

Epoch: 6| Step: 13
Training loss: 0.4062427006579255
Validation loss: 2.6127420961192747

Epoch: 542| Step: 0
Training loss: 0.2199745812958024
Validation loss: 2.614759824249566

Epoch: 6| Step: 1
Training loss: 0.2780945514770714
Validation loss: 2.6522288533991594

Epoch: 6| Step: 2
Training loss: 0.20803435250333008
Validation loss: 2.5983169977320175

Epoch: 6| Step: 3
Training loss: 0.3250751674364459
Validation loss: 2.584884552114664

Epoch: 6| Step: 4
Training loss: 0.23495903363173937
Validation loss: 2.610200275566319

Epoch: 6| Step: 5
Training loss: 0.25787637381712386
Validation loss: 2.6212378290318594

Epoch: 6| Step: 6
Training loss: 0.291821113917642
Validation loss: 2.6858873851954113

Epoch: 6| Step: 7
Training loss: 0.3494167756369236
Validation loss: 2.6317694962890257

Epoch: 6| Step: 8
Training loss: 0.23877911850729647
Validation loss: 2.645338310030164

Epoch: 6| Step: 9
Training loss: 0.25357703360075234
Validation loss: 2.62848849328628

Epoch: 6| Step: 10
Training loss: 0.25544575753992654
Validation loss: 2.621006728735045

Epoch: 6| Step: 11
Training loss: 0.3253432730558668
Validation loss: 2.581451397074949

Epoch: 6| Step: 12
Training loss: 0.32575312019589886
Validation loss: 2.6027667797059366

Epoch: 6| Step: 13
Training loss: 0.3745914260016943
Validation loss: 2.623373678285738

Epoch: 543| Step: 0
Training loss: 0.2697859265785871
Validation loss: 2.6280661492821378

Epoch: 6| Step: 1
Training loss: 0.18437545824802154
Validation loss: 2.599211905321076

Epoch: 6| Step: 2
Training loss: 0.3548343992827963
Validation loss: 2.662834846681272

Epoch: 6| Step: 3
Training loss: 0.2477079463877649
Validation loss: 2.597442189816411

Epoch: 6| Step: 4
Training loss: 0.22752256702012552
Validation loss: 2.6482560312221706

Epoch: 6| Step: 5
Training loss: 0.26881480710853994
Validation loss: 2.6249651982255973

Epoch: 6| Step: 6
Training loss: 0.24414782704220894
Validation loss: 2.6559602018356263

Epoch: 6| Step: 7
Training loss: 0.1687862110139855
Validation loss: 2.662558062760549

Epoch: 6| Step: 8
Training loss: 0.2039516665132476
Validation loss: 2.608826082707637

Epoch: 6| Step: 9
Training loss: 0.36699111231818454
Validation loss: 2.6040556438939766

Epoch: 6| Step: 10
Training loss: 0.3439984290868908
Validation loss: 2.6655799519055536

Epoch: 6| Step: 11
Training loss: 0.24269244407384383
Validation loss: 2.632840678048201

Epoch: 6| Step: 12
Training loss: 0.2947452344598138
Validation loss: 2.624021665730817

Epoch: 6| Step: 13
Training loss: 0.19706956165726444
Validation loss: 2.6599927077994145

Epoch: 544| Step: 0
Training loss: 0.2894653400103746
Validation loss: 2.6462986954869785

Epoch: 6| Step: 1
Training loss: 0.23996241612998012
Validation loss: 2.612504540520088

Epoch: 6| Step: 2
Training loss: 0.24415377009289632
Validation loss: 2.570021267888278

Epoch: 6| Step: 3
Training loss: 0.20711909535727815
Validation loss: 2.614414701051674

Epoch: 6| Step: 4
Training loss: 0.3122728953065126
Validation loss: 2.6853129411014334

Epoch: 6| Step: 5
Training loss: 0.24638178030803543
Validation loss: 2.6557362826373523

Epoch: 6| Step: 6
Training loss: 0.28264188731043094
Validation loss: 2.638715900361642

Epoch: 6| Step: 7
Training loss: 0.27741212404990784
Validation loss: 2.5742463576862913

Epoch: 6| Step: 8
Training loss: 0.31415090787423366
Validation loss: 2.6265149437666655

Epoch: 6| Step: 9
Training loss: 0.2544781626117983
Validation loss: 2.632842738188261

Epoch: 6| Step: 10
Training loss: 0.21184504391446282
Validation loss: 2.6334474365848446

Epoch: 6| Step: 11
Training loss: 0.31545387387922524
Validation loss: 2.636984488200399

Epoch: 6| Step: 12
Training loss: 0.22831570610052987
Validation loss: 2.652493921597126

Epoch: 6| Step: 13
Training loss: 0.3087576539523341
Validation loss: 2.6136424941592886

Epoch: 545| Step: 0
Training loss: 0.2229679168332739
Validation loss: 2.609850430910444

Epoch: 6| Step: 1
Training loss: 0.3735559195937266
Validation loss: 2.635551122519975

Epoch: 6| Step: 2
Training loss: 0.2298625554677743
Validation loss: 2.635090266183004

Epoch: 6| Step: 3
Training loss: 0.2503639939022618
Validation loss: 2.5599690087623066

Epoch: 6| Step: 4
Training loss: 0.30022613277829907
Validation loss: 2.613388827190463

Epoch: 6| Step: 5
Training loss: 0.16986204606785155
Validation loss: 2.6502758836190248

Epoch: 6| Step: 6
Training loss: 0.23095775708977678
Validation loss: 2.573667113068882

Epoch: 6| Step: 7
Training loss: 0.1712732183768836
Validation loss: 2.6403336825119124

Epoch: 6| Step: 8
Training loss: 0.29544450544424655
Validation loss: 2.617962865653047

Epoch: 6| Step: 9
Training loss: 0.20772025778762532
Validation loss: 2.6374664527483116

Epoch: 6| Step: 10
Training loss: 0.24215328067096706
Validation loss: 2.643704125838284

Epoch: 6| Step: 11
Training loss: 0.38205525375501165
Validation loss: 2.657027456162528

Epoch: 6| Step: 12
Training loss: 0.30553101883011663
Validation loss: 2.673266563398224

Epoch: 6| Step: 13
Training loss: 0.31725949752815924
Validation loss: 2.6262943770157348

Epoch: 546| Step: 0
Training loss: 0.3103821035425668
Validation loss: 2.624478727384696

Epoch: 6| Step: 1
Training loss: 0.21828977673314306
Validation loss: 2.5842141577637574

Epoch: 6| Step: 2
Training loss: 0.2850613501462221
Validation loss: 2.621902833653699

Epoch: 6| Step: 3
Training loss: 0.3026978378397315
Validation loss: 2.6282156442923275

Epoch: 6| Step: 4
Training loss: 0.2821179877387071
Validation loss: 2.6218088522846767

Epoch: 6| Step: 5
Training loss: 0.25617306531307915
Validation loss: 2.644430965323338

Epoch: 6| Step: 6
Training loss: 0.31724573549751695
Validation loss: 2.6000831147505146

Epoch: 6| Step: 7
Training loss: 0.21571164394468978
Validation loss: 2.5743698978767116

Epoch: 6| Step: 8
Training loss: 0.258680227174202
Validation loss: 2.6199220861250287

Epoch: 6| Step: 9
Training loss: 0.23592297844060595
Validation loss: 2.6001310639481328

Epoch: 6| Step: 10
Training loss: 0.2136241803820374
Validation loss: 2.6232720697593632

Epoch: 6| Step: 11
Training loss: 0.3027712891745705
Validation loss: 2.627216251246672

Epoch: 6| Step: 12
Training loss: 0.25771746184192607
Validation loss: 2.6264953138724896

Epoch: 6| Step: 13
Training loss: 0.2914245599716384
Validation loss: 2.5865284454843374

Epoch: 547| Step: 0
Training loss: 0.25813263466191794
Validation loss: 2.6076498667732397

Epoch: 6| Step: 1
Training loss: 0.22887060519321564
Validation loss: 2.6150852699308675

Epoch: 6| Step: 2
Training loss: 0.2967398611978393
Validation loss: 2.6419319515017348

Epoch: 6| Step: 3
Training loss: 0.4020719628711089
Validation loss: 2.614703769620302

Epoch: 6| Step: 4
Training loss: 0.23433662736209
Validation loss: 2.614998534975924

Epoch: 6| Step: 5
Training loss: 0.3556986264606882
Validation loss: 2.6096848477113452

Epoch: 6| Step: 6
Training loss: 0.2728349449869985
Validation loss: 2.626447475319424

Epoch: 6| Step: 7
Training loss: 0.28160705683810805
Validation loss: 2.6228362278399238

Epoch: 6| Step: 8
Training loss: 0.31342840567542324
Validation loss: 2.6604037998239813

Epoch: 6| Step: 9
Training loss: 0.22097242854868843
Validation loss: 2.634694876356043

Epoch: 6| Step: 10
Training loss: 0.23157045546339658
Validation loss: 2.6411545201868787

Epoch: 6| Step: 11
Training loss: 0.27323603701537297
Validation loss: 2.7010041076975413

Epoch: 6| Step: 12
Training loss: 0.22285353971468438
Validation loss: 2.632680797207003

Epoch: 6| Step: 13
Training loss: 0.34990054531204823
Validation loss: 2.661955745272797

Epoch: 548| Step: 0
Training loss: 0.28428683276574296
Validation loss: 2.6332876076732186

Epoch: 6| Step: 1
Training loss: 0.3323569439455703
Validation loss: 2.597655546336449

Epoch: 6| Step: 2
Training loss: 0.24978980526351224
Validation loss: 2.599713115881573

Epoch: 6| Step: 3
Training loss: 0.16755028095428137
Validation loss: 2.658495055235145

Epoch: 6| Step: 4
Training loss: 0.23713361594202553
Validation loss: 2.601446017386902

Epoch: 6| Step: 5
Training loss: 0.2753734312709778
Validation loss: 2.6555641186370833

Epoch: 6| Step: 6
Training loss: 0.26906418067681914
Validation loss: 2.589737833886579

Epoch: 6| Step: 7
Training loss: 0.34864017468113373
Validation loss: 2.601248385202645

Epoch: 6| Step: 8
Training loss: 0.29479222258300847
Validation loss: 2.5883477878433054

Epoch: 6| Step: 9
Training loss: 0.29465624233904886
Validation loss: 2.608345155922743

Epoch: 6| Step: 10
Training loss: 0.3629097218000459
Validation loss: 2.5916670896360126

Epoch: 6| Step: 11
Training loss: 0.20882528256737776
Validation loss: 2.5588370947588945

Epoch: 6| Step: 12
Training loss: 0.26256419032768863
Validation loss: 2.6139852946771858

Epoch: 6| Step: 13
Training loss: 0.26450373504810254
Validation loss: 2.560546719812718

Epoch: 549| Step: 0
Training loss: 0.3573349810593131
Validation loss: 2.6021401620303934

Epoch: 6| Step: 1
Training loss: 0.21517129551814537
Validation loss: 2.6125504061446363

Epoch: 6| Step: 2
Training loss: 0.21569922662325758
Validation loss: 2.5992633179402946

Epoch: 6| Step: 3
Training loss: 0.30966683215820223
Validation loss: 2.661404742891435

Epoch: 6| Step: 4
Training loss: 0.20751919017090537
Validation loss: 2.6069120711187006

Epoch: 6| Step: 5
Training loss: 0.29759686946545827
Validation loss: 2.6122175483787102

Epoch: 6| Step: 6
Training loss: 0.23020200325100873
Validation loss: 2.6412713427929275

Epoch: 6| Step: 7
Training loss: 0.20435232974374826
Validation loss: 2.5898003284464055

Epoch: 6| Step: 8
Training loss: 0.2016118248018525
Validation loss: 2.651207419699042

Epoch: 6| Step: 9
Training loss: 0.23482077644196467
Validation loss: 2.601215266824247

Epoch: 6| Step: 10
Training loss: 0.2175659508441052
Validation loss: 2.65493840017417

Epoch: 6| Step: 11
Training loss: 0.30931480284454305
Validation loss: 2.630570571178032

Epoch: 6| Step: 12
Training loss: 0.28415585447439307
Validation loss: 2.671068408120994

Epoch: 6| Step: 13
Training loss: 0.296201003586069
Validation loss: 2.6174369882882966

Epoch: 550| Step: 0
Training loss: 0.18309054504613115
Validation loss: 2.6141491614320986

Epoch: 6| Step: 1
Training loss: 0.23247932877990593
Validation loss: 2.5700894677388586

Epoch: 6| Step: 2
Training loss: 0.29323984954418264
Validation loss: 2.6117300191748924

Epoch: 6| Step: 3
Training loss: 0.2490369980055725
Validation loss: 2.5825070987738026

Epoch: 6| Step: 4
Training loss: 0.2713121924759977
Validation loss: 2.633967492444868

Epoch: 6| Step: 5
Training loss: 0.21682788867611813
Validation loss: 2.6079324629557608

Epoch: 6| Step: 6
Training loss: 0.2653717769412703
Validation loss: 2.6007535056546764

Epoch: 6| Step: 7
Training loss: 0.2371029565435766
Validation loss: 2.6375953102668688

Epoch: 6| Step: 8
Training loss: 0.34494268974496106
Validation loss: 2.6135829871083716

Epoch: 6| Step: 9
Training loss: 0.29832950455501406
Validation loss: 2.6475278029094134

Epoch: 6| Step: 10
Training loss: 0.3307457892177983
Validation loss: 2.612824852989538

Epoch: 6| Step: 11
Training loss: 0.27370837282678073
Validation loss: 2.6041679280595904

Epoch: 6| Step: 12
Training loss: 0.28246621908916636
Validation loss: 2.633903722514996

Epoch: 6| Step: 13
Training loss: 0.2915707612170533
Validation loss: 2.6138067776706664

Testing loss: 2.491122645997987
