Epoch: 1| Step: 0
Training loss: 5.76492977142334
Validation loss: 4.964572509129842

Epoch: 6| Step: 1
Training loss: 5.229426383972168
Validation loss: 4.929469267527263

Epoch: 6| Step: 2
Training loss: 4.683568954467773
Validation loss: 4.895169178644816

Epoch: 6| Step: 3
Training loss: 6.069026947021484
Validation loss: 4.867297013600667

Epoch: 6| Step: 4
Training loss: 4.864123344421387
Validation loss: 4.835233449935913

Epoch: 6| Step: 5
Training loss: 5.681164264678955
Validation loss: 4.807300329208374

Epoch: 6| Step: 6
Training loss: 4.990123748779297
Validation loss: 4.7801016966501875

Epoch: 6| Step: 7
Training loss: 3.9516165256500244
Validation loss: 4.7507191101710005

Epoch: 6| Step: 8
Training loss: 3.475456714630127
Validation loss: 4.715190927187602

Epoch: 6| Step: 9
Training loss: 4.598199367523193
Validation loss: 4.692148844401042

Epoch: 6| Step: 10
Training loss: 4.487029075622559
Validation loss: 4.657697836558024

Epoch: 6| Step: 11
Training loss: 4.6628265380859375
Validation loss: 4.627128839492798

Epoch: 6| Step: 12
Training loss: 4.741640567779541
Validation loss: 4.591630299886067

Epoch: 6| Step: 13
Training loss: 4.691348075866699
Validation loss: 4.561717748641968

Epoch: 2| Step: 0
Training loss: 4.9643874168396
Validation loss: 4.526095271110535

Epoch: 6| Step: 1
Training loss: 3.4494311809539795
Validation loss: 4.484594345092773

Epoch: 6| Step: 2
Training loss: 4.299985885620117
Validation loss: 4.442920366923015

Epoch: 6| Step: 3
Training loss: 4.5766730308532715
Validation loss: 4.409100929896037

Epoch: 6| Step: 4
Training loss: 5.503575325012207
Validation loss: 4.365182677904765

Epoch: 6| Step: 5
Training loss: 3.7732973098754883
Validation loss: 4.321542421976726

Epoch: 6| Step: 6
Training loss: 3.416444778442383
Validation loss: 4.28216548760732

Epoch: 6| Step: 7
Training loss: 5.206561088562012
Validation loss: 4.237970511118571

Epoch: 6| Step: 8
Training loss: 3.928187131881714
Validation loss: 4.191540479660034

Epoch: 6| Step: 9
Training loss: 3.6367743015289307
Validation loss: 4.143978198369344

Epoch: 6| Step: 10
Training loss: 4.448241233825684
Validation loss: 4.096235791842143

Epoch: 6| Step: 11
Training loss: 4.307002067565918
Validation loss: 4.042113582293193

Epoch: 6| Step: 12
Training loss: 4.265864372253418
Validation loss: 3.9953107436498008

Epoch: 6| Step: 13
Training loss: 5.148595809936523
Validation loss: 3.9383191665013633

Epoch: 3| Step: 0
Training loss: 4.12116813659668
Validation loss: 3.8821739753087363

Epoch: 6| Step: 1
Training loss: 4.134015083312988
Validation loss: 3.8251599868138633

Epoch: 6| Step: 2
Training loss: 3.7039566040039062
Validation loss: 3.769944190979004

Epoch: 6| Step: 3
Training loss: 4.3733744621276855
Validation loss: 3.701530615488688

Epoch: 6| Step: 4
Training loss: 4.340653419494629
Validation loss: 3.64362366994222

Epoch: 6| Step: 5
Training loss: 3.859297752380371
Validation loss: 3.5853782494862876

Epoch: 6| Step: 6
Training loss: 2.431307792663574
Validation loss: 3.505147337913513

Epoch: 6| Step: 7
Training loss: 2.764380931854248
Validation loss: 3.4496750434239707

Epoch: 6| Step: 8
Training loss: 3.426630973815918
Validation loss: 3.3699013392130532

Epoch: 6| Step: 9
Training loss: 2.922153949737549
Validation loss: 3.3101311922073364

Epoch: 6| Step: 10
Training loss: 3.745943546295166
Validation loss: 3.2331382830937705

Epoch: 6| Step: 11
Training loss: 3.6288466453552246
Validation loss: 3.157230099042257

Epoch: 6| Step: 12
Training loss: 3.6170971393585205
Validation loss: 3.083616614341736

Epoch: 6| Step: 13
Training loss: 2.8527166843414307
Validation loss: 2.992337385813395

Epoch: 4| Step: 0
Training loss: 3.269406795501709
Validation loss: 2.927765369415283

Epoch: 6| Step: 1
Training loss: 2.1966495513916016
Validation loss: 2.835163950920105

Epoch: 6| Step: 2
Training loss: 2.808825969696045
Validation loss: 2.783215641975403

Epoch: 6| Step: 3
Training loss: 2.7970492839813232
Validation loss: 2.6997844775517783

Epoch: 6| Step: 4
Training loss: 2.2583093643188477
Validation loss: 2.641895890235901

Epoch: 6| Step: 5
Training loss: 2.9215574264526367
Validation loss: 2.5622796217600503

Epoch: 6| Step: 6
Training loss: 2.6618969440460205
Validation loss: 2.4851736227671304

Epoch: 6| Step: 7
Training loss: 2.626004695892334
Validation loss: 2.4289787213007608

Epoch: 6| Step: 8
Training loss: 1.9793591499328613
Validation loss: 2.3531470696131387

Epoch: 6| Step: 9
Training loss: 2.1175646781921387
Validation loss: 2.295767148335775

Epoch: 6| Step: 10
Training loss: 2.6304850578308105
Validation loss: 2.2395764191945395

Epoch: 6| Step: 11
Training loss: 1.7758013010025024
Validation loss: 2.24114598830541

Epoch: 6| Step: 12
Training loss: 2.4412975311279297
Validation loss: 2.213644325733185

Epoch: 6| Step: 13
Training loss: 1.8784996271133423
Validation loss: 2.1941091219584146

Epoch: 5| Step: 0
Training loss: 2.0278377532958984
Validation loss: 2.192068596680959

Epoch: 6| Step: 1
Training loss: 1.5558913946151733
Validation loss: 2.2175161242485046

Epoch: 6| Step: 2
Training loss: 2.9532201290130615
Validation loss: 2.2385648091634116

Epoch: 6| Step: 3
Training loss: 2.3173019886016846
Validation loss: 2.2230314215024314

Epoch: 6| Step: 4
Training loss: 1.907562017440796
Validation loss: 2.2241682012875876

Epoch: 6| Step: 5
Training loss: 2.103835344314575
Validation loss: 2.228628238042196

Epoch: 6| Step: 6
Training loss: 2.302828788757324
Validation loss: 2.2293684681256614

Epoch: 6| Step: 7
Training loss: 1.8015964031219482
Validation loss: 2.2325079441070557

Epoch: 6| Step: 8
Training loss: 1.958749532699585
Validation loss: 2.22738254070282

Epoch: 6| Step: 9
Training loss: 2.1610867977142334
Validation loss: 2.239734331766764

Epoch: 6| Step: 10
Training loss: 2.9693922996520996
Validation loss: 2.238561272621155

Epoch: 6| Step: 11
Training loss: 2.637948989868164
Validation loss: 2.231032053629557

Epoch: 6| Step: 12
Training loss: 1.633737325668335
Validation loss: 2.2053669492403665

Epoch: 6| Step: 13
Training loss: 2.420379161834717
Validation loss: 2.2075697779655457

Epoch: 6| Step: 0
Training loss: 2.029728889465332
Validation loss: 2.1900660196940103

Epoch: 6| Step: 1
Training loss: 2.0639808177948
Validation loss: 2.17659060160319

Epoch: 6| Step: 2
Training loss: 2.6810178756713867
Validation loss: 2.1970019737879434

Epoch: 6| Step: 3
Training loss: 2.3197927474975586
Validation loss: 2.207553486029307

Epoch: 6| Step: 4
Training loss: 2.2831263542175293
Validation loss: 2.2023982206980386

Epoch: 6| Step: 5
Training loss: 1.729691505432129
Validation loss: 2.1944079399108887

Epoch: 6| Step: 6
Training loss: 2.2010960578918457
Validation loss: 2.2169103026390076

Epoch: 6| Step: 7
Training loss: 2.5457048416137695
Validation loss: 2.1841102043787637

Epoch: 6| Step: 8
Training loss: 1.2826879024505615
Validation loss: 2.1768966913223267

Epoch: 6| Step: 9
Training loss: 2.6349406242370605
Validation loss: 2.1686593691507974

Epoch: 6| Step: 10
Training loss: 2.0309367179870605
Validation loss: 2.1918158332506814

Epoch: 6| Step: 11
Training loss: 2.1190505027770996
Validation loss: 2.195709149042765

Epoch: 6| Step: 12
Training loss: 1.8582563400268555
Validation loss: 2.177975296974182

Epoch: 6| Step: 13
Training loss: 2.1329126358032227
Validation loss: 2.185660938421885

Epoch: 7| Step: 0
Training loss: 2.3472447395324707
Validation loss: 2.180753310521444

Epoch: 6| Step: 1
Training loss: 2.2355759143829346
Validation loss: 2.2070024808247886

Epoch: 6| Step: 2
Training loss: 2.121339797973633
Validation loss: 2.1679325501124063

Epoch: 6| Step: 3
Training loss: 2.0724058151245117
Validation loss: 2.1653853257497153

Epoch: 6| Step: 4
Training loss: 2.660435676574707
Validation loss: 2.1717951695124307

Epoch: 6| Step: 5
Training loss: 1.899375319480896
Validation loss: 2.1611066261927285

Epoch: 6| Step: 6
Training loss: 1.918290376663208
Validation loss: 2.1608548561731973

Epoch: 6| Step: 7
Training loss: 2.0219433307647705
Validation loss: 2.164159576098124

Epoch: 6| Step: 8
Training loss: 2.332963466644287
Validation loss: 2.2026268243789673

Epoch: 6| Step: 9
Training loss: 2.1385550498962402
Validation loss: 2.1900589863459268

Epoch: 6| Step: 10
Training loss: 1.373920202255249
Validation loss: 2.166856348514557

Epoch: 6| Step: 11
Training loss: 2.3986167907714844
Validation loss: 2.155776778856913

Epoch: 6| Step: 12
Training loss: 1.904417872428894
Validation loss: 2.182815114657084

Epoch: 6| Step: 13
Training loss: 2.4877071380615234
Validation loss: 2.145929217338562

Epoch: 8| Step: 0
Training loss: 1.6190743446350098
Validation loss: 2.170000652472178

Epoch: 6| Step: 1
Training loss: 2.9213361740112305
Validation loss: 2.1676560640335083

Epoch: 6| Step: 2
Training loss: 2.042226791381836
Validation loss: 2.169885039329529

Epoch: 6| Step: 3
Training loss: 2.8510115146636963
Validation loss: 2.1716087063153586

Epoch: 6| Step: 4
Training loss: 2.797447681427002
Validation loss: 2.20408304532369

Epoch: 6| Step: 5
Training loss: 1.4651577472686768
Validation loss: 2.194233318169912

Epoch: 6| Step: 6
Training loss: 1.5276908874511719
Validation loss: 2.1718245148658752

Epoch: 6| Step: 7
Training loss: 2.2079877853393555
Validation loss: 2.1923661629358926

Epoch: 6| Step: 8
Training loss: 1.7389975786209106
Validation loss: 2.1696197390556335

Epoch: 6| Step: 9
Training loss: 2.0904035568237305
Validation loss: 2.1890377600987754

Epoch: 6| Step: 10
Training loss: 2.3676648139953613
Validation loss: 2.1992271145184836

Epoch: 6| Step: 11
Training loss: 2.218787908554077
Validation loss: 2.149240791797638

Epoch: 6| Step: 12
Training loss: 1.8295207023620605
Validation loss: 2.1722151041030884

Epoch: 6| Step: 13
Training loss: 2.0472002029418945
Validation loss: 2.156388302644094

Epoch: 9| Step: 0
Training loss: 2.4262568950653076
Validation loss: 2.160776138305664

Epoch: 6| Step: 1
Training loss: 1.6801652908325195
Validation loss: 2.179745535055796

Epoch: 6| Step: 2
Training loss: 2.026015281677246
Validation loss: 2.1476043860117593

Epoch: 6| Step: 3
Training loss: 1.9525502920150757
Validation loss: 2.171311676502228

Epoch: 6| Step: 4
Training loss: 1.8355391025543213
Validation loss: 2.1903587579727173

Epoch: 6| Step: 5
Training loss: 1.7960705757141113
Validation loss: 2.1598387161890664

Epoch: 6| Step: 6
Training loss: 2.3876304626464844
Validation loss: 2.1746570666631064

Epoch: 6| Step: 7
Training loss: 2.2206923961639404
Validation loss: 2.1703158020973206

Epoch: 6| Step: 8
Training loss: 2.4744157791137695
Validation loss: 2.1785661975542703

Epoch: 6| Step: 9
Training loss: 2.1762514114379883
Validation loss: 2.1676736076672873

Epoch: 6| Step: 10
Training loss: 2.5570621490478516
Validation loss: 2.1650405327479043

Epoch: 6| Step: 11
Training loss: 1.399713158607483
Validation loss: 2.204791525999705

Epoch: 6| Step: 12
Training loss: 2.2774085998535156
Validation loss: 2.16016819079717

Epoch: 6| Step: 13
Training loss: 2.3883724212646484
Validation loss: 2.171417752901713

Epoch: 10| Step: 0
Training loss: 2.035682201385498
Validation loss: 2.155503769715627

Epoch: 6| Step: 1
Training loss: 2.426586627960205
Validation loss: 2.19497416416804

Epoch: 6| Step: 2
Training loss: 1.87418532371521
Validation loss: 2.1820985277493796

Epoch: 6| Step: 3
Training loss: 1.9240639209747314
Validation loss: 2.165996571381887

Epoch: 6| Step: 4
Training loss: 2.1084487438201904
Validation loss: 2.140190621217092

Epoch: 6| Step: 5
Training loss: 1.6556708812713623
Validation loss: 2.1367748181025186

Epoch: 6| Step: 6
Training loss: 2.552029609680176
Validation loss: 2.1527435978253684

Epoch: 6| Step: 7
Training loss: 2.845327377319336
Validation loss: 2.171455999215444

Epoch: 6| Step: 8
Training loss: 2.1168198585510254
Validation loss: 2.1861560543378196

Epoch: 6| Step: 9
Training loss: 2.1792712211608887
Validation loss: 2.1541492541631064

Epoch: 6| Step: 10
Training loss: 1.8771328926086426
Validation loss: 2.14589915672938

Epoch: 6| Step: 11
Training loss: 2.0347847938537598
Validation loss: 2.1544156869252524

Epoch: 6| Step: 12
Training loss: 1.6582125425338745
Validation loss: 2.1639936367670694

Epoch: 6| Step: 13
Training loss: 1.8915687799453735
Validation loss: 2.1371238629023233

Epoch: 11| Step: 0
Training loss: 1.600695013999939
Validation loss: 2.172181705633799

Epoch: 6| Step: 1
Training loss: 1.6050074100494385
Validation loss: 2.150432745615641

Epoch: 6| Step: 2
Training loss: 1.884324312210083
Validation loss: 2.1540773510932922

Epoch: 6| Step: 3
Training loss: 2.521462917327881
Validation loss: 2.178540269533793

Epoch: 6| Step: 4
Training loss: 1.8854953050613403
Validation loss: 2.141661783059438

Epoch: 6| Step: 5
Training loss: 2.238335371017456
Validation loss: 2.1613059838612876

Epoch: 6| Step: 6
Training loss: 2.1649069786071777
Validation loss: 2.1597666144371033

Epoch: 6| Step: 7
Training loss: 1.9830738306045532
Validation loss: 2.17914080619812

Epoch: 6| Step: 8
Training loss: 2.296154022216797
Validation loss: 2.159135580062866

Epoch: 6| Step: 9
Training loss: 2.1733884811401367
Validation loss: 2.14690371354421

Epoch: 6| Step: 10
Training loss: 2.3008041381835938
Validation loss: 2.1764367818832397

Epoch: 6| Step: 11
Training loss: 2.2391064167022705
Validation loss: 2.170521597067515

Epoch: 6| Step: 12
Training loss: 2.046292781829834
Validation loss: 2.1468239625295005

Epoch: 6| Step: 13
Training loss: 2.5657620429992676
Validation loss: 2.164543648560842

Epoch: 12| Step: 0
Training loss: 1.5206462144851685
Validation loss: 2.1723630825678506

Epoch: 6| Step: 1
Training loss: 1.973435401916504
Validation loss: 2.1581571896870932

Epoch: 6| Step: 2
Training loss: 1.734321117401123
Validation loss: 2.177240471045176

Epoch: 6| Step: 3
Training loss: 2.3048949241638184
Validation loss: 2.1611759662628174

Epoch: 6| Step: 4
Training loss: 1.8610378503799438
Validation loss: 2.1628758708635965

Epoch: 6| Step: 5
Training loss: 2.2741827964782715
Validation loss: 2.177817145983378

Epoch: 6| Step: 6
Training loss: 2.0755467414855957
Validation loss: 2.1605823040008545

Epoch: 6| Step: 7
Training loss: 2.137314558029175
Validation loss: 2.1659749348958335

Epoch: 6| Step: 8
Training loss: 2.0928547382354736
Validation loss: 2.1552662452061973

Epoch: 6| Step: 9
Training loss: 1.8582894802093506
Validation loss: 2.1854483087857566

Epoch: 6| Step: 10
Training loss: 1.9982962608337402
Validation loss: 2.1644505858421326

Epoch: 6| Step: 11
Training loss: 3.69966721534729
Validation loss: 2.1850772698720298

Epoch: 6| Step: 12
Training loss: 1.6319013833999634
Validation loss: 2.1683289408683777

Epoch: 6| Step: 13
Training loss: 2.184929847717285
Validation loss: 2.1598641673723855

Epoch: 13| Step: 0
Training loss: 2.140803337097168
Validation loss: 2.183262666066488

Epoch: 6| Step: 1
Training loss: 1.8437204360961914
Validation loss: 2.153575897216797

Epoch: 6| Step: 2
Training loss: 2.16045880317688
Validation loss: 2.1692482630411782

Epoch: 6| Step: 3
Training loss: 1.7404264211654663
Validation loss: 2.1384924054145813

Epoch: 6| Step: 4
Training loss: 2.079373359680176
Validation loss: 2.158466398715973

Epoch: 6| Step: 5
Training loss: 1.336184024810791
Validation loss: 2.1370593110720315

Epoch: 6| Step: 6
Training loss: 1.7660737037658691
Validation loss: 2.1446988383928933

Epoch: 6| Step: 7
Training loss: 1.8382467031478882
Validation loss: 2.1673166751861572

Epoch: 6| Step: 8
Training loss: 2.160348892211914
Validation loss: 2.161599814891815

Epoch: 6| Step: 9
Training loss: 2.6548595428466797
Validation loss: 2.1611671646436057

Epoch: 6| Step: 10
Training loss: 3.077927350997925
Validation loss: 2.189710021018982

Epoch: 6| Step: 11
Training loss: 1.962222695350647
Validation loss: 2.1517800092697144

Epoch: 6| Step: 12
Training loss: 2.3765811920166016
Validation loss: 2.1501724123954773

Epoch: 6| Step: 13
Training loss: 2.0476415157318115
Validation loss: 2.165658632914225

Epoch: 14| Step: 0
Training loss: 1.871692180633545
Validation loss: 2.148741900920868

Epoch: 6| Step: 1
Training loss: 1.7978260517120361
Validation loss: 2.147359470526377

Epoch: 6| Step: 2
Training loss: 2.6118931770324707
Validation loss: 2.1422518491744995

Epoch: 6| Step: 3
Training loss: 2.2347562313079834
Validation loss: 2.1631048123041787

Epoch: 6| Step: 4
Training loss: 2.1529531478881836
Validation loss: 2.1788753271102905

Epoch: 6| Step: 5
Training loss: 1.829798936843872
Validation loss: 2.1654945611953735

Epoch: 6| Step: 6
Training loss: 1.6535029411315918
Validation loss: 2.1656315128008523

Epoch: 6| Step: 7
Training loss: 2.0975661277770996
Validation loss: 2.1578557093938193

Epoch: 6| Step: 8
Training loss: 2.2280447483062744
Validation loss: 2.1428722143173218

Epoch: 6| Step: 9
Training loss: 1.8103724718093872
Validation loss: 2.1599751313527427

Epoch: 6| Step: 10
Training loss: 2.124960422515869
Validation loss: 2.150967021783193

Epoch: 6| Step: 11
Training loss: 2.1852588653564453
Validation loss: 2.1741280555725098

Epoch: 6| Step: 12
Training loss: 1.6144858598709106
Validation loss: 2.153440793355306

Epoch: 6| Step: 13
Training loss: 3.021524429321289
Validation loss: 2.167291045188904

Epoch: 15| Step: 0
Training loss: 2.176553249359131
Validation loss: 2.1505114436149597

Epoch: 6| Step: 1
Training loss: 2.538705587387085
Validation loss: 2.1401429573694863

Epoch: 6| Step: 2
Training loss: 1.721236228942871
Validation loss: 2.1054794987042746

Epoch: 6| Step: 3
Training loss: 1.5432560443878174
Validation loss: 2.1297163565953574

Epoch: 6| Step: 4
Training loss: 2.700082778930664
Validation loss: 2.1500744024912515

Epoch: 6| Step: 5
Training loss: 2.0547256469726562
Validation loss: 2.16948930422465

Epoch: 6| Step: 6
Training loss: 2.0375568866729736
Validation loss: 2.1256156961123147

Epoch: 6| Step: 7
Training loss: 2.4392948150634766
Validation loss: 2.1657117009162903

Epoch: 6| Step: 8
Training loss: 1.6559147834777832
Validation loss: 2.1654691298802695

Epoch: 6| Step: 9
Training loss: 1.4092035293579102
Validation loss: 2.1525837580362954

Epoch: 6| Step: 10
Training loss: 2.404723644256592
Validation loss: 2.152738849322001

Epoch: 6| Step: 11
Training loss: 1.3551256656646729
Validation loss: 2.1443998614947

Epoch: 6| Step: 12
Training loss: 2.393094301223755
Validation loss: 2.1716291507085166

Epoch: 6| Step: 13
Training loss: 2.6671934127807617
Validation loss: 2.1682806809743247

Epoch: 16| Step: 0
Training loss: 2.177194595336914
Validation loss: 2.162160038948059

Epoch: 6| Step: 1
Training loss: 2.2359466552734375
Validation loss: 2.1443864504496255

Epoch: 6| Step: 2
Training loss: 2.2080843448638916
Validation loss: 2.134598890940348

Epoch: 6| Step: 3
Training loss: 1.400580883026123
Validation loss: 2.1587324738502502

Epoch: 6| Step: 4
Training loss: 1.8366825580596924
Validation loss: 2.1428276101748147

Epoch: 6| Step: 5
Training loss: 2.684751272201538
Validation loss: 2.1194209655125937

Epoch: 6| Step: 6
Training loss: 2.3657033443450928
Validation loss: 2.1669066747029624

Epoch: 6| Step: 7
Training loss: 2.756255626678467
Validation loss: 2.168271243572235

Epoch: 6| Step: 8
Training loss: 1.862854242324829
Validation loss: 2.1540516217549643

Epoch: 6| Step: 9
Training loss: 1.6155545711517334
Validation loss: 2.1455222964286804

Epoch: 6| Step: 10
Training loss: 1.7269498109817505
Validation loss: 2.1291542847951255

Epoch: 6| Step: 11
Training loss: 2.2620034217834473
Validation loss: 2.1649062633514404

Epoch: 6| Step: 12
Training loss: 2.393019437789917
Validation loss: 2.161852935949961

Epoch: 6| Step: 13
Training loss: 1.831408977508545
Validation loss: 2.1558308601379395

Epoch: 17| Step: 0
Training loss: 1.9514613151550293
Validation loss: 2.1480743686358132

Epoch: 6| Step: 1
Training loss: 1.6686384677886963
Validation loss: 2.1306553284327188

Epoch: 6| Step: 2
Training loss: 2.268825054168701
Validation loss: 2.113898992538452

Epoch: 6| Step: 3
Training loss: 1.8293404579162598
Validation loss: 2.153808852036794

Epoch: 6| Step: 4
Training loss: 2.456620454788208
Validation loss: 2.1478452682495117

Epoch: 6| Step: 5
Training loss: 1.8415082693099976
Validation loss: 2.161215821901957

Epoch: 6| Step: 6
Training loss: 1.9617104530334473
Validation loss: 2.1497979760169983

Epoch: 6| Step: 7
Training loss: 1.7678433656692505
Validation loss: 2.1412116487820945

Epoch: 6| Step: 8
Training loss: 1.5728435516357422
Validation loss: 2.157023787498474

Epoch: 6| Step: 9
Training loss: 1.958343267440796
Validation loss: 2.1220199863115945

Epoch: 6| Step: 10
Training loss: 2.1787109375
Validation loss: 2.1384481390317283

Epoch: 6| Step: 11
Training loss: 2.3542966842651367
Validation loss: 2.1420949498812356

Epoch: 6| Step: 12
Training loss: 2.61802339553833
Validation loss: 2.1614468495051065

Epoch: 6| Step: 13
Training loss: 2.4601120948791504
Validation loss: 2.151333828767141

Epoch: 18| Step: 0
Training loss: 2.025921106338501
Validation loss: 2.1465601126352944

Epoch: 6| Step: 1
Training loss: 1.6776407957077026
Validation loss: 2.1951461831728616

Epoch: 6| Step: 2
Training loss: 2.584172248840332
Validation loss: 2.1468300223350525

Epoch: 6| Step: 3
Training loss: 2.1987228393554688
Validation loss: 2.1262510220209756

Epoch: 6| Step: 4
Training loss: 2.4211034774780273
Validation loss: 2.1632208625475564

Epoch: 6| Step: 5
Training loss: 2.568885326385498
Validation loss: 2.1459884444872537

Epoch: 6| Step: 6
Training loss: 2.079479217529297
Validation loss: 2.1357858975728354

Epoch: 6| Step: 7
Training loss: 2.6146867275238037
Validation loss: 2.1682039697964988

Epoch: 6| Step: 8
Training loss: 2.1401374340057373
Validation loss: 2.1605493227640786

Epoch: 6| Step: 9
Training loss: 1.7598090171813965
Validation loss: 2.14951761563619

Epoch: 6| Step: 10
Training loss: 1.5373486280441284
Validation loss: 2.1402626434961953

Epoch: 6| Step: 11
Training loss: 1.9371633529663086
Validation loss: 2.1448291142781577

Epoch: 6| Step: 12
Training loss: 1.743281364440918
Validation loss: 2.1246641874313354

Epoch: 6| Step: 13
Training loss: 1.8560783863067627
Validation loss: 2.136224865913391

Epoch: 19| Step: 0
Training loss: 1.6100927591323853
Validation loss: 2.126046816507975

Epoch: 6| Step: 1
Training loss: 1.8007166385650635
Validation loss: 2.151650627454122

Epoch: 6| Step: 2
Training loss: 2.302900791168213
Validation loss: 2.121793786684672

Epoch: 6| Step: 3
Training loss: 2.587311267852783
Validation loss: 2.1566201647122702

Epoch: 6| Step: 4
Training loss: 2.0858497619628906
Validation loss: 2.1407457987467446

Epoch: 6| Step: 5
Training loss: 1.9962518215179443
Validation loss: 2.137378454208374

Epoch: 6| Step: 6
Training loss: 1.746362566947937
Validation loss: 2.1514341235160828

Epoch: 6| Step: 7
Training loss: 1.9714583158493042
Validation loss: 2.135678847630819

Epoch: 6| Step: 8
Training loss: 2.1482458114624023
Validation loss: 2.1510581175486245

Epoch: 6| Step: 9
Training loss: 2.006345748901367
Validation loss: 2.129317065080007

Epoch: 6| Step: 10
Training loss: 1.2580980062484741
Validation loss: 2.152225613594055

Epoch: 6| Step: 11
Training loss: 2.6301021575927734
Validation loss: 2.1389017899831138

Epoch: 6| Step: 12
Training loss: 2.1698660850524902
Validation loss: 2.121274491151174

Epoch: 6| Step: 13
Training loss: 2.544548988342285
Validation loss: 2.1443703969319663

Epoch: 20| Step: 0
Training loss: 1.9588863849639893
Validation loss: 2.1584232648213706

Epoch: 6| Step: 1
Training loss: 2.1106066703796387
Validation loss: 2.146098534266154

Epoch: 6| Step: 2
Training loss: 1.687587022781372
Validation loss: 2.1396734515825906

Epoch: 6| Step: 3
Training loss: 1.6403939723968506
Validation loss: 2.1188522974650064

Epoch: 6| Step: 4
Training loss: 1.7890384197235107
Validation loss: 2.1402613520622253

Epoch: 6| Step: 5
Training loss: 2.288865566253662
Validation loss: 2.1222126483917236

Epoch: 6| Step: 6
Training loss: 2.4597411155700684
Validation loss: 2.1452757914861045

Epoch: 6| Step: 7
Training loss: 2.143126964569092
Validation loss: 2.1522374153137207

Epoch: 6| Step: 8
Training loss: 2.2215206623077393
Validation loss: 2.1476733485857644

Epoch: 6| Step: 9
Training loss: 2.0180141925811768
Validation loss: 2.144853353500366

Epoch: 6| Step: 10
Training loss: 1.8838000297546387
Validation loss: 2.1289694905281067

Epoch: 6| Step: 11
Training loss: 2.369419813156128
Validation loss: 2.133333762486776

Epoch: 6| Step: 12
Training loss: 2.090280771255493
Validation loss: 2.108030080795288

Epoch: 6| Step: 13
Training loss: 1.9934828281402588
Validation loss: 2.138024906317393

Epoch: 21| Step: 0
Training loss: 2.1735825538635254
Validation loss: 2.127555767695109

Epoch: 6| Step: 1
Training loss: 2.553530216217041
Validation loss: 2.1039692163467407

Epoch: 6| Step: 2
Training loss: 2.2156949043273926
Validation loss: 2.119116942087809

Epoch: 6| Step: 3
Training loss: 2.3549692630767822
Validation loss: 2.1335947513580322

Epoch: 6| Step: 4
Training loss: 1.6126710176467896
Validation loss: 2.1234047214190164

Epoch: 6| Step: 5
Training loss: 1.9599730968475342
Validation loss: 2.142310380935669

Epoch: 6| Step: 6
Training loss: 1.868727445602417
Validation loss: 2.1198736826578775

Epoch: 6| Step: 7
Training loss: 2.3971753120422363
Validation loss: 2.1525461276372275

Epoch: 6| Step: 8
Training loss: 2.272812843322754
Validation loss: 2.127483288447062

Epoch: 6| Step: 9
Training loss: 1.1769864559173584
Validation loss: 2.1377341747283936

Epoch: 6| Step: 10
Training loss: 2.0127930641174316
Validation loss: 2.1203261613845825

Epoch: 6| Step: 11
Training loss: 1.7797281742095947
Validation loss: 2.1194233496983848

Epoch: 6| Step: 12
Training loss: 2.1733169555664062
Validation loss: 2.112045248349508

Epoch: 6| Step: 13
Training loss: 2.239011764526367
Validation loss: 2.131174067656199

Epoch: 22| Step: 0
Training loss: 2.031473398208618
Validation loss: 2.121737539768219

Epoch: 6| Step: 1
Training loss: 1.959686517715454
Validation loss: 2.1231327652931213

Epoch: 6| Step: 2
Training loss: 2.00407338142395
Validation loss: 2.128180742263794

Epoch: 6| Step: 3
Training loss: 1.8209991455078125
Validation loss: 2.1311758557955423

Epoch: 6| Step: 4
Training loss: 1.939908504486084
Validation loss: 2.1337323983510337

Epoch: 6| Step: 5
Training loss: 2.2593271732330322
Validation loss: 2.143786867459615

Epoch: 6| Step: 6
Training loss: 1.9593076705932617
Validation loss: 2.112249791622162

Epoch: 6| Step: 7
Training loss: 2.475339889526367
Validation loss: 2.123434921105703

Epoch: 6| Step: 8
Training loss: 1.277017593383789
Validation loss: 2.1415345072746277

Epoch: 6| Step: 9
Training loss: 2.0819783210754395
Validation loss: 2.168351948261261

Epoch: 6| Step: 10
Training loss: 2.4134817123413086
Validation loss: 2.1397831638654075

Epoch: 6| Step: 11
Training loss: 1.6822736263275146
Validation loss: 2.1169158021608987

Epoch: 6| Step: 12
Training loss: 1.5688657760620117
Validation loss: 2.1388602455457053

Epoch: 6| Step: 13
Training loss: 3.2047231197357178
Validation loss: 2.1167260011037192

Epoch: 23| Step: 0
Training loss: 2.00622820854187
Validation loss: 2.1409884691238403

Epoch: 6| Step: 1
Training loss: 1.5936636924743652
Validation loss: 2.1184093952178955

Epoch: 6| Step: 2
Training loss: 2.3836097717285156
Validation loss: 2.118275304635366

Epoch: 6| Step: 3
Training loss: 2.5393338203430176
Validation loss: 2.1400545835494995

Epoch: 6| Step: 4
Training loss: 1.776322603225708
Validation loss: 2.119027614593506

Epoch: 6| Step: 5
Training loss: 2.1117377281188965
Validation loss: 2.1264469226201377

Epoch: 6| Step: 6
Training loss: 1.2727047204971313
Validation loss: 2.131690959135691

Epoch: 6| Step: 7
Training loss: 2.5985894203186035
Validation loss: 2.116325318813324

Epoch: 6| Step: 8
Training loss: 1.7615844011306763
Validation loss: 2.143651783466339

Epoch: 6| Step: 9
Training loss: 1.8219609260559082
Validation loss: 2.1471022367477417

Epoch: 6| Step: 10
Training loss: 2.4672160148620605
Validation loss: 2.138273060321808

Epoch: 6| Step: 11
Training loss: 2.278472900390625
Validation loss: 2.151617626349131

Epoch: 6| Step: 12
Training loss: 2.4330663681030273
Validation loss: 2.1202023228009543

Epoch: 6| Step: 13
Training loss: 1.8739910125732422
Validation loss: 2.103497862815857

Epoch: 24| Step: 0
Training loss: 1.9610062837600708
Validation loss: 2.115656852722168

Epoch: 6| Step: 1
Training loss: 1.824692726135254
Validation loss: 2.1219658056894937

Epoch: 6| Step: 2
Training loss: 2.4218530654907227
Validation loss: 2.1264288425445557

Epoch: 6| Step: 3
Training loss: 2.072787284851074
Validation loss: 2.129974623521169

Epoch: 6| Step: 4
Training loss: 2.315237522125244
Validation loss: 2.1407960255940757

Epoch: 6| Step: 5
Training loss: 1.8322595357894897
Validation loss: 2.1478317379951477

Epoch: 6| Step: 6
Training loss: 2.4678006172180176
Validation loss: 2.1227975487709045

Epoch: 6| Step: 7
Training loss: 1.1645381450653076
Validation loss: 2.096688210964203

Epoch: 6| Step: 8
Training loss: 1.9165325164794922
Validation loss: 2.1316008965174356

Epoch: 6| Step: 9
Training loss: 2.611309051513672
Validation loss: 2.1258919835090637

Epoch: 6| Step: 10
Training loss: 1.709043264389038
Validation loss: 2.1428558627764382

Epoch: 6| Step: 11
Training loss: 2.7994112968444824
Validation loss: 2.1129220922787986

Epoch: 6| Step: 12
Training loss: 1.7289472818374634
Validation loss: 2.1275571386019387

Epoch: 6| Step: 13
Training loss: 2.0811617374420166
Validation loss: 2.1062047878901162

Epoch: 25| Step: 0
Training loss: 1.9340811967849731
Validation loss: 2.1572919885317483

Epoch: 6| Step: 1
Training loss: 1.7498785257339478
Validation loss: 2.1400028268496194

Epoch: 6| Step: 2
Training loss: 2.0940017700195312
Validation loss: 2.122413674990336

Epoch: 6| Step: 3
Training loss: 2.478126049041748
Validation loss: 2.1367095510164895

Epoch: 6| Step: 4
Training loss: 1.7576658725738525
Validation loss: 2.133119265238444

Epoch: 6| Step: 5
Training loss: 2.2495827674865723
Validation loss: 2.1138824820518494

Epoch: 6| Step: 6
Training loss: 2.1193251609802246
Validation loss: 2.133421858151754

Epoch: 6| Step: 7
Training loss: 2.5931665897369385
Validation loss: 2.1327860156695047

Epoch: 6| Step: 8
Training loss: 1.6559174060821533
Validation loss: 2.117473085721334

Epoch: 6| Step: 9
Training loss: 1.7166903018951416
Validation loss: 2.13422954082489

Epoch: 6| Step: 10
Training loss: 1.5282278060913086
Validation loss: 2.1383607387542725

Epoch: 6| Step: 11
Training loss: 1.8612602949142456
Validation loss: 2.130706032117208

Epoch: 6| Step: 12
Training loss: 2.482067108154297
Validation loss: 2.144122064113617

Epoch: 6| Step: 13
Training loss: 2.3001046180725098
Validation loss: 2.1030346155166626

Epoch: 26| Step: 0
Training loss: 1.7436296939849854
Validation loss: 2.0930438240369162

Epoch: 6| Step: 1
Training loss: 1.9841487407684326
Validation loss: 2.137387196222941

Epoch: 6| Step: 2
Training loss: 2.199066638946533
Validation loss: 2.1167420744895935

Epoch: 6| Step: 3
Training loss: 1.8880236148834229
Validation loss: 2.1208067337671914

Epoch: 6| Step: 4
Training loss: 1.7002683877944946
Validation loss: 2.1258829633394876

Epoch: 6| Step: 5
Training loss: 2.237691879272461
Validation loss: 2.0958047906557717

Epoch: 6| Step: 6
Training loss: 1.7708313465118408
Validation loss: 2.101331134637197

Epoch: 6| Step: 7
Training loss: 1.544301986694336
Validation loss: 2.1185186306635537

Epoch: 6| Step: 8
Training loss: 2.804065704345703
Validation loss: 2.112324376900991

Epoch: 6| Step: 9
Training loss: 2.209707260131836
Validation loss: 2.1147828896840415

Epoch: 6| Step: 10
Training loss: 1.940692663192749
Validation loss: 2.113378425439199

Epoch: 6| Step: 11
Training loss: 2.0478596687316895
Validation loss: 2.122418145338694

Epoch: 6| Step: 12
Training loss: 2.551537036895752
Validation loss: 2.1148845752080283

Epoch: 6| Step: 13
Training loss: 1.9090975522994995
Validation loss: 2.111476937929789

Epoch: 27| Step: 0
Training loss: 1.826789379119873
Validation loss: 2.094562590122223

Epoch: 6| Step: 1
Training loss: 2.2183876037597656
Validation loss: 2.1321178873380027

Epoch: 6| Step: 2
Training loss: 1.2743984460830688
Validation loss: 2.1078720688819885

Epoch: 6| Step: 3
Training loss: 2.067774772644043
Validation loss: 2.133011778195699

Epoch: 6| Step: 4
Training loss: 2.5560319423675537
Validation loss: 2.138997475306193

Epoch: 6| Step: 5
Training loss: 1.785041093826294
Validation loss: 2.1082929770151773

Epoch: 6| Step: 6
Training loss: 2.3453915119171143
Validation loss: 2.1290525992711387

Epoch: 6| Step: 7
Training loss: 1.7863701581954956
Validation loss: 2.1197587052981057

Epoch: 6| Step: 8
Training loss: 1.9787203073501587
Validation loss: 2.135847330093384

Epoch: 6| Step: 9
Training loss: 1.7535219192504883
Validation loss: 2.143624166647593

Epoch: 6| Step: 10
Training loss: 2.690835475921631
Validation loss: 2.1297609210014343

Epoch: 6| Step: 11
Training loss: 1.984122633934021
Validation loss: 2.1378352642059326

Epoch: 6| Step: 12
Training loss: 2.1628880500793457
Validation loss: 2.1273187597592673

Epoch: 6| Step: 13
Training loss: 2.1759698390960693
Validation loss: 2.1183196107546487

Epoch: 28| Step: 0
Training loss: 2.12191104888916
Validation loss: 2.1126870115598044

Epoch: 6| Step: 1
Training loss: 1.823585033416748
Validation loss: 2.1175656914711

Epoch: 6| Step: 2
Training loss: 2.573607921600342
Validation loss: 2.102769374847412

Epoch: 6| Step: 3
Training loss: 2.1983885765075684
Validation loss: 2.1194087266921997

Epoch: 6| Step: 4
Training loss: 2.8803186416625977
Validation loss: 2.1269879738489785

Epoch: 6| Step: 5
Training loss: 2.2625608444213867
Validation loss: 2.104080617427826

Epoch: 6| Step: 6
Training loss: 1.2682678699493408
Validation loss: 2.0979762276013694

Epoch: 6| Step: 7
Training loss: 2.5496785640716553
Validation loss: 2.1127138336499534

Epoch: 6| Step: 8
Training loss: 1.1561713218688965
Validation loss: 2.125877062479655

Epoch: 6| Step: 9
Training loss: 1.9702682495117188
Validation loss: 2.131720324357351

Epoch: 6| Step: 10
Training loss: 2.366255044937134
Validation loss: 2.109392841657003

Epoch: 6| Step: 11
Training loss: 1.6881911754608154
Validation loss: 2.1202411452929177

Epoch: 6| Step: 12
Training loss: 1.3904515504837036
Validation loss: 2.131228784720103

Epoch: 6| Step: 13
Training loss: 2.3115758895874023
Validation loss: 2.1057701905568442

Epoch: 29| Step: 0
Training loss: 1.6369824409484863
Validation loss: 2.097736656665802

Epoch: 6| Step: 1
Training loss: 1.7271356582641602
Validation loss: 2.1181213657061257

Epoch: 6| Step: 2
Training loss: 1.9121105670928955
Validation loss: 2.106971104939779

Epoch: 6| Step: 3
Training loss: 2.418949604034424
Validation loss: 2.131520171960195

Epoch: 6| Step: 4
Training loss: 1.5612256526947021
Validation loss: 2.105356971422831

Epoch: 6| Step: 5
Training loss: 2.2412219047546387
Validation loss: 2.102470576763153

Epoch: 6| Step: 6
Training loss: 2.2237284183502197
Validation loss: 2.099976062774658

Epoch: 6| Step: 7
Training loss: 2.114584445953369
Validation loss: 2.1480979124704995

Epoch: 6| Step: 8
Training loss: 1.8135805130004883
Validation loss: 2.1012951334317527

Epoch: 6| Step: 9
Training loss: 1.8174571990966797
Validation loss: 2.113341728846232

Epoch: 6| Step: 10
Training loss: 2.4574763774871826
Validation loss: 2.0973739624023438

Epoch: 6| Step: 11
Training loss: 2.1209025382995605
Validation loss: 2.1246787309646606

Epoch: 6| Step: 12
Training loss: 2.3762216567993164
Validation loss: 2.093361814816793

Epoch: 6| Step: 13
Training loss: 1.9379820823669434
Validation loss: 2.0748345057169595

Epoch: 30| Step: 0
Training loss: 2.1603376865386963
Validation loss: 2.125523010889689

Epoch: 6| Step: 1
Training loss: 2.123469352722168
Validation loss: 2.112544814745585

Epoch: 6| Step: 2
Training loss: 1.4480515718460083
Validation loss: 2.1090670426686606

Epoch: 6| Step: 3
Training loss: 1.4813357591629028
Validation loss: 2.0863089164098105

Epoch: 6| Step: 4
Training loss: 2.280658721923828
Validation loss: 2.110089421272278

Epoch: 6| Step: 5
Training loss: 1.6725599765777588
Validation loss: 2.1090786457061768

Epoch: 6| Step: 6
Training loss: 2.171293020248413
Validation loss: 2.094588120778402

Epoch: 6| Step: 7
Training loss: 2.2870097160339355
Validation loss: 2.1154715418815613

Epoch: 6| Step: 8
Training loss: 1.8475306034088135
Validation loss: 2.1168744762738547

Epoch: 6| Step: 9
Training loss: 1.616147518157959
Validation loss: 2.099794407685598

Epoch: 6| Step: 10
Training loss: 2.45328426361084
Validation loss: 2.104308764139811

Epoch: 6| Step: 11
Training loss: 2.3592867851257324
Validation loss: 2.105897625287374

Epoch: 6| Step: 12
Training loss: 2.4349541664123535
Validation loss: 2.0948113600413003

Epoch: 6| Step: 13
Training loss: 1.8110398054122925
Validation loss: 2.107625683148702

Epoch: 31| Step: 0
Training loss: 1.8291574716567993
Validation loss: 2.089060147603353

Epoch: 6| Step: 1
Training loss: 2.4604244232177734
Validation loss: 2.09183406829834

Epoch: 6| Step: 2
Training loss: 1.6589792966842651
Validation loss: 2.091461976369222

Epoch: 6| Step: 3
Training loss: 2.0518317222595215
Validation loss: 2.1033952633539834

Epoch: 6| Step: 4
Training loss: 2.905186176300049
Validation loss: 2.1052565375963845

Epoch: 6| Step: 5
Training loss: 2.4809277057647705
Validation loss: 2.1087003548940024

Epoch: 6| Step: 6
Training loss: 1.7902727127075195
Validation loss: 2.1308817863464355

Epoch: 6| Step: 7
Training loss: 2.072917938232422
Validation loss: 2.1349171797434487

Epoch: 6| Step: 8
Training loss: 1.3199565410614014
Validation loss: 2.1233646472295127

Epoch: 6| Step: 9
Training loss: 1.5558578968048096
Validation loss: 2.1262866854667664

Epoch: 6| Step: 10
Training loss: 1.8971805572509766
Validation loss: 2.0901511311531067

Epoch: 6| Step: 11
Training loss: 2.2873497009277344
Validation loss: 2.1142513354619346

Epoch: 6| Step: 12
Training loss: 1.8597931861877441
Validation loss: 2.102190355459849

Epoch: 6| Step: 13
Training loss: 2.3407888412475586
Validation loss: 2.082206050554911

Epoch: 32| Step: 0
Training loss: 1.7792919874191284
Validation loss: 2.1147884527842202

Epoch: 6| Step: 1
Training loss: 2.1675050258636475
Validation loss: 2.12147980928421

Epoch: 6| Step: 2
Training loss: 1.9122265577316284
Validation loss: 2.147764027118683

Epoch: 6| Step: 3
Training loss: 2.010586738586426
Validation loss: 2.1064239541689553

Epoch: 6| Step: 4
Training loss: 2.295093059539795
Validation loss: 2.137633442878723

Epoch: 6| Step: 5
Training loss: 2.8939027786254883
Validation loss: 2.1104081074396768

Epoch: 6| Step: 6
Training loss: 1.4626305103302002
Validation loss: 2.10573947429657

Epoch: 6| Step: 7
Training loss: 1.426788091659546
Validation loss: 2.125291625658671

Epoch: 6| Step: 8
Training loss: 1.9414236545562744
Validation loss: 2.1415688594182334

Epoch: 6| Step: 9
Training loss: 2.286224842071533
Validation loss: 2.155373275279999

Epoch: 6| Step: 10
Training loss: 2.67431640625
Validation loss: 2.142390251159668

Epoch: 6| Step: 11
Training loss: 1.5748176574707031
Validation loss: 2.1128639777501426

Epoch: 6| Step: 12
Training loss: 2.08109974861145
Validation loss: 2.117372473080953

Epoch: 6| Step: 13
Training loss: 1.7897875308990479
Validation loss: 2.1109765768051147

Epoch: 33| Step: 0
Training loss: 2.3443000316619873
Validation loss: 2.1141032377878823

Epoch: 6| Step: 1
Training loss: 1.8429274559020996
Validation loss: 2.104425013065338

Epoch: 6| Step: 2
Training loss: 1.8415905237197876
Validation loss: 2.0897579987843833

Epoch: 6| Step: 3
Training loss: 1.8753000497817993
Validation loss: 2.1097569465637207

Epoch: 6| Step: 4
Training loss: 1.4432001113891602
Validation loss: 2.1298582951227822

Epoch: 6| Step: 5
Training loss: 1.8291945457458496
Validation loss: 2.091969132423401

Epoch: 6| Step: 6
Training loss: 1.8618669509887695
Validation loss: 2.088095506032308

Epoch: 6| Step: 7
Training loss: 2.407492160797119
Validation loss: 2.105303327242533

Epoch: 6| Step: 8
Training loss: 1.5704154968261719
Validation loss: 2.087558150291443

Epoch: 6| Step: 9
Training loss: 2.5160505771636963
Validation loss: 2.083442986011505

Epoch: 6| Step: 10
Training loss: 2.4472060203552246
Validation loss: 2.0980119506518045

Epoch: 6| Step: 11
Training loss: 1.4147673845291138
Validation loss: 2.1049502889315286

Epoch: 6| Step: 12
Training loss: 2.2882823944091797
Validation loss: 2.111187696456909

Epoch: 6| Step: 13
Training loss: 2.249723434448242
Validation loss: 2.100457410017649

Epoch: 34| Step: 0
Training loss: 1.3095883131027222
Validation loss: 2.0966113805770874

Epoch: 6| Step: 1
Training loss: 2.1033291816711426
Validation loss: 2.0917150576909385

Epoch: 6| Step: 2
Training loss: 2.109036922454834
Validation loss: 2.0833943684895835

Epoch: 6| Step: 3
Training loss: 1.8099448680877686
Validation loss: 2.121289590994517

Epoch: 6| Step: 4
Training loss: 1.3355540037155151
Validation loss: 2.0942200819651284

Epoch: 6| Step: 5
Training loss: 1.8894059658050537
Validation loss: 2.0824047724405923

Epoch: 6| Step: 6
Training loss: 1.9693751335144043
Validation loss: 2.0637876788775125

Epoch: 6| Step: 7
Training loss: 2.31325101852417
Validation loss: 2.119392971197764

Epoch: 6| Step: 8
Training loss: 1.5140900611877441
Validation loss: 2.096291184425354

Epoch: 6| Step: 9
Training loss: 3.136441707611084
Validation loss: 2.089582939942678

Epoch: 6| Step: 10
Training loss: 1.7824698686599731
Validation loss: 2.076580047607422

Epoch: 6| Step: 11
Training loss: 1.960176706314087
Validation loss: 2.0720221400260925

Epoch: 6| Step: 12
Training loss: 2.5445380210876465
Validation loss: 2.0884641806284585

Epoch: 6| Step: 13
Training loss: 2.1610865592956543
Validation loss: 2.067717353502909

Epoch: 35| Step: 0
Training loss: 2.0251448154449463
Validation loss: 2.100036382675171

Epoch: 6| Step: 1
Training loss: 1.966762900352478
Validation loss: 2.09990386168162

Epoch: 6| Step: 2
Training loss: 2.4639596939086914
Validation loss: 2.126034418741862

Epoch: 6| Step: 3
Training loss: 1.7752199172973633
Validation loss: 2.116292874018351

Epoch: 6| Step: 4
Training loss: 1.808643102645874
Validation loss: 2.135498503843943

Epoch: 6| Step: 5
Training loss: 2.1819448471069336
Validation loss: 2.10120282570521

Epoch: 6| Step: 6
Training loss: 2.589883804321289
Validation loss: 2.103152334690094

Epoch: 6| Step: 7
Training loss: 1.858876347541809
Validation loss: 2.1197859048843384

Epoch: 6| Step: 8
Training loss: 1.8983031511306763
Validation loss: 2.122015635172526

Epoch: 6| Step: 9
Training loss: 1.8856807947158813
Validation loss: 2.096092144648234

Epoch: 6| Step: 10
Training loss: 1.9370330572128296
Validation loss: 2.1135533452033997

Epoch: 6| Step: 11
Training loss: 2.5522916316986084
Validation loss: 2.1006802717844644

Epoch: 6| Step: 12
Training loss: 1.3398792743682861
Validation loss: 2.0738372008005777

Epoch: 6| Step: 13
Training loss: 2.015650749206543
Validation loss: 2.09361340602239

Epoch: 36| Step: 0
Training loss: 1.4936165809631348
Validation loss: 2.0930788119633994

Epoch: 6| Step: 1
Training loss: 2.475895881652832
Validation loss: 2.09961732228597

Epoch: 6| Step: 2
Training loss: 1.9853013753890991
Validation loss: 2.1126530170440674

Epoch: 6| Step: 3
Training loss: 2.6262059211730957
Validation loss: 2.0807185967763266

Epoch: 6| Step: 4
Training loss: 1.3957343101501465
Validation loss: 2.1035078366597495

Epoch: 6| Step: 5
Training loss: 2.431370735168457
Validation loss: 2.0906046628952026

Epoch: 6| Step: 6
Training loss: 2.296536445617676
Validation loss: 2.1125263571739197

Epoch: 6| Step: 7
Training loss: 1.8928008079528809
Validation loss: 2.1035804947217307

Epoch: 6| Step: 8
Training loss: 1.775467872619629
Validation loss: 2.0941132307052612

Epoch: 6| Step: 9
Training loss: 1.8964333534240723
Validation loss: 2.100252389907837

Epoch: 6| Step: 10
Training loss: 2.037034034729004
Validation loss: 2.114290416240692

Epoch: 6| Step: 11
Training loss: 2.2773776054382324
Validation loss: 2.0788060824076333

Epoch: 6| Step: 12
Training loss: 1.9587273597717285
Validation loss: 2.1036391258239746

Epoch: 6| Step: 13
Training loss: 1.7409307956695557
Validation loss: 2.100225845972697

Epoch: 37| Step: 0
Training loss: 2.3582353591918945
Validation loss: 2.089953124523163

Epoch: 6| Step: 1
Training loss: 2.3027477264404297
Validation loss: 2.1057928005854287

Epoch: 6| Step: 2
Training loss: 1.872597336769104
Validation loss: 2.071320116519928

Epoch: 6| Step: 3
Training loss: 1.9239795207977295
Validation loss: 2.1126861770947776

Epoch: 6| Step: 4
Training loss: 1.666327953338623
Validation loss: 2.1023910442988076

Epoch: 6| Step: 5
Training loss: 1.4529019594192505
Validation loss: 2.1076244513193765

Epoch: 6| Step: 6
Training loss: 2.021832227706909
Validation loss: 2.1075080235799155

Epoch: 6| Step: 7
Training loss: 1.708435297012329
Validation loss: 2.1018131971359253

Epoch: 6| Step: 8
Training loss: 2.2554931640625
Validation loss: 2.086057186126709

Epoch: 6| Step: 9
Training loss: 1.8085464239120483
Validation loss: 2.069717009862264

Epoch: 6| Step: 10
Training loss: 2.017439365386963
Validation loss: 2.078189810117086

Epoch: 6| Step: 11
Training loss: 2.142362594604492
Validation loss: 2.105830669403076

Epoch: 6| Step: 12
Training loss: 1.9324449300765991
Validation loss: 2.0811731417973838

Epoch: 6| Step: 13
Training loss: 2.3820137977600098
Validation loss: 2.094817022482554

Epoch: 38| Step: 0
Training loss: 1.5576658248901367
Validation loss: 2.075195292631785

Epoch: 6| Step: 1
Training loss: 1.6808589696884155
Validation loss: 2.088361084461212

Epoch: 6| Step: 2
Training loss: 1.77994966506958
Validation loss: 2.0648474295934043

Epoch: 6| Step: 3
Training loss: 2.122384548187256
Validation loss: 2.099691947301229

Epoch: 6| Step: 4
Training loss: 1.486572504043579
Validation loss: 2.073588212331136

Epoch: 6| Step: 5
Training loss: 2.723776340484619
Validation loss: 2.0764059821764627

Epoch: 6| Step: 6
Training loss: 2.350785970687866
Validation loss: 2.079453686873118

Epoch: 6| Step: 7
Training loss: 2.1189804077148438
Validation loss: 2.0675586462020874

Epoch: 6| Step: 8
Training loss: 2.5263257026672363
Validation loss: 2.0714902877807617

Epoch: 6| Step: 9
Training loss: 1.9940954446792603
Validation loss: 2.1005210677782693

Epoch: 6| Step: 10
Training loss: 1.3151479959487915
Validation loss: 2.0827945272127786

Epoch: 6| Step: 11
Training loss: 2.163482666015625
Validation loss: 2.061224043369293

Epoch: 6| Step: 12
Training loss: 2.4636478424072266
Validation loss: 2.0778653621673584

Epoch: 6| Step: 13
Training loss: 1.560847282409668
Validation loss: 2.08469690879186

Epoch: 39| Step: 0
Training loss: 1.7180665731430054
Validation loss: 2.10526450475057

Epoch: 6| Step: 1
Training loss: 2.102138042449951
Validation loss: 2.0734806855519614

Epoch: 6| Step: 2
Training loss: 2.19294810295105
Validation loss: 2.0814757545789084

Epoch: 6| Step: 3
Training loss: 2.4796814918518066
Validation loss: 2.0946122805277505

Epoch: 6| Step: 4
Training loss: 1.7037558555603027
Validation loss: 2.0929199854532876

Epoch: 6| Step: 5
Training loss: 1.401540756225586
Validation loss: 2.091262400150299

Epoch: 6| Step: 6
Training loss: 1.8048439025878906
Validation loss: 2.0834996104240417

Epoch: 6| Step: 7
Training loss: 2.0478081703186035
Validation loss: 2.087650159994761

Epoch: 6| Step: 8
Training loss: 1.5694220066070557
Validation loss: 2.098330835501353

Epoch: 6| Step: 9
Training loss: 2.7077980041503906
Validation loss: 2.0944002072016397

Epoch: 6| Step: 10
Training loss: 2.3372297286987305
Validation loss: 2.0741861859957376

Epoch: 6| Step: 11
Training loss: 1.5929447412490845
Validation loss: 2.0869815746943154

Epoch: 6| Step: 12
Training loss: 1.6067254543304443
Validation loss: 2.073941707611084

Epoch: 6| Step: 13
Training loss: 2.455751419067383
Validation loss: 2.081993877887726

Epoch: 40| Step: 0
Training loss: 2.059234142303467
Validation loss: 2.0768103202184043

Epoch: 6| Step: 1
Training loss: 2.3156166076660156
Validation loss: 2.076648235321045

Epoch: 6| Step: 2
Training loss: 2.04213285446167
Validation loss: 2.0741541385650635

Epoch: 6| Step: 3
Training loss: 1.6165573596954346
Validation loss: 2.1063141028086343

Epoch: 6| Step: 4
Training loss: 2.00813364982605
Validation loss: 2.0813976923624673

Epoch: 6| Step: 5
Training loss: 1.8122798204421997
Validation loss: 2.083395997683207

Epoch: 6| Step: 6
Training loss: 2.231776237487793
Validation loss: 2.083590507507324

Epoch: 6| Step: 7
Training loss: 2.3847408294677734
Validation loss: 2.0874412854512534

Epoch: 6| Step: 8
Training loss: 1.8877592086791992
Validation loss: 2.082826872666677

Epoch: 6| Step: 9
Training loss: 1.945101022720337
Validation loss: 2.101753294467926

Epoch: 6| Step: 10
Training loss: 2.0244154930114746
Validation loss: 2.083527167638143

Epoch: 6| Step: 11
Training loss: 2.3683643341064453
Validation loss: 2.105624179045359

Epoch: 6| Step: 12
Training loss: 1.5598654747009277
Validation loss: 2.0929582715034485

Epoch: 6| Step: 13
Training loss: 1.508415699005127
Validation loss: 2.0696260134379068

Epoch: 41| Step: 0
Training loss: 2.125230550765991
Validation loss: 2.0667871038118997

Epoch: 6| Step: 1
Training loss: 1.8211967945098877
Validation loss: 2.060085654258728

Epoch: 6| Step: 2
Training loss: 1.6351770162582397
Validation loss: 2.053789814313253

Epoch: 6| Step: 3
Training loss: 1.8385119438171387
Validation loss: 2.0824140508969626

Epoch: 6| Step: 4
Training loss: 1.9212628602981567
Validation loss: 2.07839302221934

Epoch: 6| Step: 5
Training loss: 2.0908267498016357
Validation loss: 2.054271856943766

Epoch: 6| Step: 6
Training loss: 2.2641215324401855
Validation loss: 2.0798629919687905

Epoch: 6| Step: 7
Training loss: 2.1070728302001953
Validation loss: 2.064993361632029

Epoch: 6| Step: 8
Training loss: 1.7354812622070312
Validation loss: 2.0537535349527993

Epoch: 6| Step: 9
Training loss: 2.217196464538574
Validation loss: 2.083536962668101

Epoch: 6| Step: 10
Training loss: 1.748591423034668
Validation loss: 2.071699241797129

Epoch: 6| Step: 11
Training loss: 2.461435079574585
Validation loss: 2.099332650502523

Epoch: 6| Step: 12
Training loss: 1.9722176790237427
Validation loss: 2.088587979475657

Epoch: 6| Step: 13
Training loss: 1.9510266780853271
Validation loss: 2.080216427644094

Epoch: 42| Step: 0
Training loss: 1.94222891330719
Validation loss: 2.074116508165995

Epoch: 6| Step: 1
Training loss: 1.8119556903839111
Validation loss: 2.0665823221206665

Epoch: 6| Step: 2
Training loss: 1.9481374025344849
Validation loss: 2.0912083983421326

Epoch: 6| Step: 3
Training loss: 2.162740707397461
Validation loss: 2.1017844478289285

Epoch: 6| Step: 4
Training loss: 1.9205074310302734
Validation loss: 2.0697401960690818

Epoch: 6| Step: 5
Training loss: 2.0484089851379395
Validation loss: 2.0798646807670593

Epoch: 6| Step: 6
Training loss: 2.0007236003875732
Validation loss: 2.083425521850586

Epoch: 6| Step: 7
Training loss: 1.9652245044708252
Validation loss: 2.106247305870056

Epoch: 6| Step: 8
Training loss: 2.326615333557129
Validation loss: 2.089531103769938

Epoch: 6| Step: 9
Training loss: 0.9314872026443481
Validation loss: 2.1063191493352256

Epoch: 6| Step: 10
Training loss: 2.264765739440918
Validation loss: 2.0878624518712363

Epoch: 6| Step: 11
Training loss: 2.301403522491455
Validation loss: 2.088078478972117

Epoch: 6| Step: 12
Training loss: 1.902958631515503
Validation loss: 2.1028397480646768

Epoch: 6| Step: 13
Training loss: 2.1768288612365723
Validation loss: 2.105842431386312

Epoch: 43| Step: 0
Training loss: 2.3615212440490723
Validation loss: 2.0930200815200806

Epoch: 6| Step: 1
Training loss: 2.0103955268859863
Validation loss: 2.0860363841056824

Epoch: 6| Step: 2
Training loss: 1.722862958908081
Validation loss: 2.0947407285372415

Epoch: 6| Step: 3
Training loss: 1.6332582235336304
Validation loss: 2.0778364737828574

Epoch: 6| Step: 4
Training loss: 2.84212589263916
Validation loss: 2.069904327392578

Epoch: 6| Step: 5
Training loss: 2.1946167945861816
Validation loss: 2.0896126429239907

Epoch: 6| Step: 6
Training loss: 2.1148059368133545
Validation loss: 2.0863295594851174

Epoch: 6| Step: 7
Training loss: 2.029602527618408
Validation loss: 2.1011444330215454

Epoch: 6| Step: 8
Training loss: 1.4538772106170654
Validation loss: 2.070298433303833

Epoch: 6| Step: 9
Training loss: 1.879323124885559
Validation loss: 2.0754757722218833

Epoch: 6| Step: 10
Training loss: 1.849057674407959
Validation loss: 2.089698056379954

Epoch: 6| Step: 11
Training loss: 2.338656425476074
Validation loss: 2.0705644687016806

Epoch: 6| Step: 12
Training loss: 1.6132664680480957
Validation loss: 2.0711004535357156

Epoch: 6| Step: 13
Training loss: 1.7867224216461182
Validation loss: 2.067506273587545

Epoch: 44| Step: 0
Training loss: 1.5726447105407715
Validation loss: 2.0954474806785583

Epoch: 6| Step: 1
Training loss: 1.4611124992370605
Validation loss: 2.0671717325846353

Epoch: 6| Step: 2
Training loss: 1.2446613311767578
Validation loss: 2.093692402044932

Epoch: 6| Step: 3
Training loss: 2.0946788787841797
Validation loss: 2.086367885271708

Epoch: 6| Step: 4
Training loss: 2.16939640045166
Validation loss: 2.0761021773020425

Epoch: 6| Step: 5
Training loss: 2.1343531608581543
Validation loss: 2.0964302817980447

Epoch: 6| Step: 6
Training loss: 1.9343626499176025
Validation loss: 2.0925145347913108

Epoch: 6| Step: 7
Training loss: 2.3122470378875732
Validation loss: 2.0831172466278076

Epoch: 6| Step: 8
Training loss: 2.2299437522888184
Validation loss: 2.111352026462555

Epoch: 6| Step: 9
Training loss: 1.6877168416976929
Validation loss: 2.112132648626963

Epoch: 6| Step: 10
Training loss: 2.1520395278930664
Validation loss: 2.1082921425501504

Epoch: 6| Step: 11
Training loss: 2.8347983360290527
Validation loss: 2.0990277528762817

Epoch: 6| Step: 12
Training loss: 1.750637412071228
Validation loss: 2.10102778673172

Epoch: 6| Step: 13
Training loss: 2.0651040077209473
Validation loss: 2.0869093338648477

Epoch: 45| Step: 0
Training loss: 2.022151470184326
Validation loss: 2.071576774120331

Epoch: 6| Step: 1
Training loss: 1.941908597946167
Validation loss: 2.078890879948934

Epoch: 6| Step: 2
Training loss: 2.134456157684326
Validation loss: 2.0819175839424133

Epoch: 6| Step: 3
Training loss: 2.552797317504883
Validation loss: 2.052158296108246

Epoch: 6| Step: 4
Training loss: 1.658879280090332
Validation loss: 2.0736079017321267

Epoch: 6| Step: 5
Training loss: 1.7173383235931396
Validation loss: 2.0636524756749473

Epoch: 6| Step: 6
Training loss: 1.7576913833618164
Validation loss: 2.0744632879892984

Epoch: 6| Step: 7
Training loss: 2.4697377681732178
Validation loss: 2.0749740997950235

Epoch: 6| Step: 8
Training loss: 2.829040765762329
Validation loss: 2.0697901844978333

Epoch: 6| Step: 9
Training loss: 1.7500643730163574
Validation loss: 2.0544177691141763

Epoch: 6| Step: 10
Training loss: 1.5486526489257812
Validation loss: 2.075184166431427

Epoch: 6| Step: 11
Training loss: 1.9286752939224243
Validation loss: 2.054101288318634

Epoch: 6| Step: 12
Training loss: 2.2268176078796387
Validation loss: 2.0739951729774475

Epoch: 6| Step: 13
Training loss: 1.045255184173584
Validation loss: 2.0386086304982505

Epoch: 46| Step: 0
Training loss: 2.0522890090942383
Validation loss: 2.056110143661499

Epoch: 6| Step: 1
Training loss: 1.782257080078125
Validation loss: 2.0598634680112204

Epoch: 6| Step: 2
Training loss: 1.746011734008789
Validation loss: 2.0851107835769653

Epoch: 6| Step: 3
Training loss: 2.1594431400299072
Validation loss: 2.0663270552953086

Epoch: 6| Step: 4
Training loss: 2.4742331504821777
Validation loss: 2.1015849510828652

Epoch: 6| Step: 5
Training loss: 2.498417615890503
Validation loss: 2.0739468932151794

Epoch: 6| Step: 6
Training loss: 1.9814612865447998
Validation loss: 2.107807238896688

Epoch: 6| Step: 7
Training loss: 2.1517603397369385
Validation loss: 2.081145385901133

Epoch: 6| Step: 8
Training loss: 1.5106390714645386
Validation loss: 2.087242921193441

Epoch: 6| Step: 9
Training loss: 1.806789755821228
Validation loss: 2.0970515608787537

Epoch: 6| Step: 10
Training loss: 1.5056664943695068
Validation loss: 2.076572000980377

Epoch: 6| Step: 11
Training loss: 1.8834705352783203
Validation loss: 2.079180339972178

Epoch: 6| Step: 12
Training loss: 2.2515690326690674
Validation loss: 2.0860220988591514

Epoch: 6| Step: 13
Training loss: 1.835000991821289
Validation loss: 2.064296762148539

Epoch: 47| Step: 0
Training loss: 1.5433464050292969
Validation loss: 2.088772475719452

Epoch: 6| Step: 1
Training loss: 2.1918063163757324
Validation loss: 2.1003246903419495

Epoch: 6| Step: 2
Training loss: 2.132324695587158
Validation loss: 2.061064342657725

Epoch: 6| Step: 3
Training loss: 1.8018574714660645
Validation loss: 2.0645246307055154

Epoch: 6| Step: 4
Training loss: 1.649357795715332
Validation loss: 2.079834262530009

Epoch: 6| Step: 5
Training loss: 1.310157299041748
Validation loss: 2.0783082445462546

Epoch: 6| Step: 6
Training loss: 2.2195916175842285
Validation loss: 2.074446419874827

Epoch: 6| Step: 7
Training loss: 2.015838146209717
Validation loss: 2.060866594314575

Epoch: 6| Step: 8
Training loss: 1.9577276706695557
Validation loss: 2.0715020298957825

Epoch: 6| Step: 9
Training loss: 2.079310417175293
Validation loss: 2.0771777828534446

Epoch: 6| Step: 10
Training loss: 2.3029403686523438
Validation loss: 2.0739702582359314

Epoch: 6| Step: 11
Training loss: 2.397505760192871
Validation loss: 2.0609391729036965

Epoch: 6| Step: 12
Training loss: 2.277812957763672
Validation loss: 2.090398689111074

Epoch: 6| Step: 13
Training loss: 1.4443509578704834
Validation loss: 2.063784380753835

Epoch: 48| Step: 0
Training loss: 1.867013931274414
Validation loss: 2.0639730095863342

Epoch: 6| Step: 1
Training loss: 1.2472612857818604
Validation loss: 2.080319881439209

Epoch: 6| Step: 2
Training loss: 1.6095342636108398
Validation loss: 2.0513875683148703

Epoch: 6| Step: 3
Training loss: 1.925935983657837
Validation loss: 2.073718031247457

Epoch: 6| Step: 4
Training loss: 2.293614625930786
Validation loss: 2.0630925496419272

Epoch: 6| Step: 5
Training loss: 2.167431116104126
Validation loss: 2.082285722096761

Epoch: 6| Step: 6
Training loss: 2.0735437870025635
Validation loss: 2.081743081410726

Epoch: 6| Step: 7
Training loss: 2.0232083797454834
Validation loss: 2.100094278653463

Epoch: 6| Step: 8
Training loss: 2.926884651184082
Validation loss: 2.0701348781585693

Epoch: 6| Step: 9
Training loss: 1.905192494392395
Validation loss: 2.0707606871922812

Epoch: 6| Step: 10
Training loss: 1.8697806596755981
Validation loss: 2.0526731610298157

Epoch: 6| Step: 11
Training loss: 1.3675999641418457
Validation loss: 2.0811623533566794

Epoch: 6| Step: 12
Training loss: 2.0373716354370117
Validation loss: 2.0757493376731873

Epoch: 6| Step: 13
Training loss: 1.9277446269989014
Validation loss: 2.0611089070638022

Epoch: 49| Step: 0
Training loss: 2.1921563148498535
Validation loss: 2.064804037412008

Epoch: 6| Step: 1
Training loss: 1.7226386070251465
Validation loss: 2.072129944960276

Epoch: 6| Step: 2
Training loss: 1.8181688785552979
Validation loss: 2.0442113478978476

Epoch: 6| Step: 3
Training loss: 2.4370133876800537
Validation loss: 2.0643641551335654

Epoch: 6| Step: 4
Training loss: 1.0460271835327148
Validation loss: 2.0822373429934182

Epoch: 6| Step: 5
Training loss: 1.407204031944275
Validation loss: 2.06332274278005

Epoch: 6| Step: 6
Training loss: 2.311039447784424
Validation loss: 2.060247858365377

Epoch: 6| Step: 7
Training loss: 1.3971264362335205
Validation loss: 2.0738620162010193

Epoch: 6| Step: 8
Training loss: 2.4041624069213867
Validation loss: 2.069074889024099

Epoch: 6| Step: 9
Training loss: 2.135376453399658
Validation loss: 2.068852682908376

Epoch: 6| Step: 10
Training loss: 1.5870871543884277
Validation loss: 2.0820551117261252

Epoch: 6| Step: 11
Training loss: 1.8862488269805908
Validation loss: 2.0678726633389792

Epoch: 6| Step: 12
Training loss: 2.6638808250427246
Validation loss: 2.0802321831385293

Epoch: 6| Step: 13
Training loss: 2.212414264678955
Validation loss: 2.0490792791048684

Epoch: 50| Step: 0
Training loss: 1.6978051662445068
Validation loss: 2.0485695401827493

Epoch: 6| Step: 1
Training loss: 2.0238828659057617
Validation loss: 2.0803601344426474

Epoch: 6| Step: 2
Training loss: 2.4441657066345215
Validation loss: 2.072350343068441

Epoch: 6| Step: 3
Training loss: 1.9099209308624268
Validation loss: 2.0535248517990112

Epoch: 6| Step: 4
Training loss: 1.7110339403152466
Validation loss: 2.0388630429903665

Epoch: 6| Step: 5
Training loss: 2.452609062194824
Validation loss: 2.046282927195231

Epoch: 6| Step: 6
Training loss: 1.8758883476257324
Validation loss: 2.048326234022776

Epoch: 6| Step: 7
Training loss: 2.2159957885742188
Validation loss: 2.0544228553771973

Epoch: 6| Step: 8
Training loss: 1.8511844873428345
Validation loss: 2.0580825010935464

Epoch: 6| Step: 9
Training loss: 2.0622057914733887
Validation loss: 2.082813262939453

Epoch: 6| Step: 10
Training loss: 2.1819162368774414
Validation loss: 2.0677208503087363

Epoch: 6| Step: 11
Training loss: 1.7516858577728271
Validation loss: 2.061288138230642

Epoch: 6| Step: 12
Training loss: 2.038947105407715
Validation loss: 2.0757095416386924

Epoch: 6| Step: 13
Training loss: 1.0898528099060059
Validation loss: 2.0447208682696023

Epoch: 51| Step: 0
Training loss: 2.1003270149230957
Validation loss: 2.0730269948641458

Epoch: 6| Step: 1
Training loss: 1.6229180097579956
Validation loss: 2.0480236212412515

Epoch: 6| Step: 2
Training loss: 1.854256510734558
Validation loss: 2.075348178545634

Epoch: 6| Step: 3
Training loss: 1.8026697635650635
Validation loss: 2.0749653776486716

Epoch: 6| Step: 4
Training loss: 1.7292883396148682
Validation loss: 2.0851837396621704

Epoch: 6| Step: 5
Training loss: 1.7371203899383545
Validation loss: 2.1076958378156028

Epoch: 6| Step: 6
Training loss: 1.9412305355072021
Validation loss: 2.1405088702837625

Epoch: 6| Step: 7
Training loss: 2.7782602310180664
Validation loss: 2.140754997730255

Epoch: 6| Step: 8
Training loss: 1.2364197969436646
Validation loss: 2.1175955335299173

Epoch: 6| Step: 9
Training loss: 1.9527053833007812
Validation loss: 2.1044971346855164

Epoch: 6| Step: 10
Training loss: 2.4136996269226074
Validation loss: 2.110816180706024

Epoch: 6| Step: 11
Training loss: 1.7148398160934448
Validation loss: 2.0971785187721252

Epoch: 6| Step: 12
Training loss: 2.478032112121582
Validation loss: 2.073659896850586

Epoch: 6| Step: 13
Training loss: 2.0317275524139404
Validation loss: 2.0820219119389853

Epoch: 52| Step: 0
Training loss: 1.8665508031845093
Validation loss: 2.0562352538108826

Epoch: 6| Step: 1
Training loss: 1.8597071170806885
Validation loss: 2.048482358455658

Epoch: 6| Step: 2
Training loss: 1.4562076330184937
Validation loss: 2.061147073904673

Epoch: 6| Step: 3
Training loss: 2.1140313148498535
Validation loss: 2.050911525885264

Epoch: 6| Step: 4
Training loss: 2.122561454772949
Validation loss: 2.0533337394396463

Epoch: 6| Step: 5
Training loss: 2.282712459564209
Validation loss: 2.058180888493856

Epoch: 6| Step: 6
Training loss: 2.8269097805023193
Validation loss: 2.0676581660906472

Epoch: 6| Step: 7
Training loss: 1.9304434061050415
Validation loss: 2.061119019985199

Epoch: 6| Step: 8
Training loss: 2.095574140548706
Validation loss: 2.072129468123118

Epoch: 6| Step: 9
Training loss: 1.6627930402755737
Validation loss: 2.055582900842031

Epoch: 6| Step: 10
Training loss: 1.8391873836517334
Validation loss: 2.0636494557062783

Epoch: 6| Step: 11
Training loss: 1.7504581212997437
Validation loss: 2.0507749716440835

Epoch: 6| Step: 12
Training loss: 1.7257810831069946
Validation loss: 2.058955192565918

Epoch: 6| Step: 13
Training loss: 1.6120492219924927
Validation loss: 2.038431147734324

Epoch: 53| Step: 0
Training loss: 1.9797604084014893
Validation loss: 2.0531362891197205

Epoch: 6| Step: 1
Training loss: 1.508674144744873
Validation loss: 2.057455758253733

Epoch: 6| Step: 2
Training loss: 1.710853099822998
Validation loss: 2.0700647036234536

Epoch: 6| Step: 3
Training loss: 1.9737138748168945
Validation loss: 2.105148514111837

Epoch: 6| Step: 4
Training loss: 1.3308684825897217
Validation loss: 2.087389647960663

Epoch: 6| Step: 5
Training loss: 1.5188204050064087
Validation loss: 2.075679918130239

Epoch: 6| Step: 6
Training loss: 2.2345495223999023
Validation loss: 2.0852618416150412

Epoch: 6| Step: 7
Training loss: 2.5876736640930176
Validation loss: 2.085015038649241

Epoch: 6| Step: 8
Training loss: 1.5601308345794678
Validation loss: 2.1095429261525473

Epoch: 6| Step: 9
Training loss: 1.9892847537994385
Validation loss: 2.0515787601470947

Epoch: 6| Step: 10
Training loss: 2.1093859672546387
Validation loss: 2.067192236582438

Epoch: 6| Step: 11
Training loss: 2.53550124168396
Validation loss: 2.0607431729634604

Epoch: 6| Step: 12
Training loss: 1.9122474193572998
Validation loss: 2.0587961077690125

Epoch: 6| Step: 13
Training loss: 2.266075611114502
Validation loss: 2.071302831172943

Epoch: 54| Step: 0
Training loss: 1.664859414100647
Validation loss: 2.0657156705856323

Epoch: 6| Step: 1
Training loss: 2.0836973190307617
Validation loss: 2.069960276285807

Epoch: 6| Step: 2
Training loss: 2.2470104694366455
Validation loss: 2.052913467089335

Epoch: 6| Step: 3
Training loss: 2.1675682067871094
Validation loss: 2.055432756741842

Epoch: 6| Step: 4
Training loss: 1.8799259662628174
Validation loss: 2.0629303654034934

Epoch: 6| Step: 5
Training loss: 1.367056131362915
Validation loss: 2.0472028851509094

Epoch: 6| Step: 6
Training loss: 1.7736787796020508
Validation loss: 2.013692935307821

Epoch: 6| Step: 7
Training loss: 1.9337527751922607
Validation loss: 2.075486203034719

Epoch: 6| Step: 8
Training loss: 1.8178143501281738
Validation loss: 2.0600412289301553

Epoch: 6| Step: 9
Training loss: 1.983750343322754
Validation loss: 2.0361177722613015

Epoch: 6| Step: 10
Training loss: 1.7531828880310059
Validation loss: 2.0757482647895813

Epoch: 6| Step: 11
Training loss: 2.0296967029571533
Validation loss: 2.044651428858439

Epoch: 6| Step: 12
Training loss: 2.428642749786377
Validation loss: 2.0441083312034607

Epoch: 6| Step: 13
Training loss: 2.0314154624938965
Validation loss: 2.091141084829966

Epoch: 55| Step: 0
Training loss: 1.7885639667510986
Validation loss: 2.0773775378863015

Epoch: 6| Step: 1
Training loss: 2.7007791996002197
Validation loss: 2.0746732354164124

Epoch: 6| Step: 2
Training loss: 0.9477834701538086
Validation loss: 2.0555434226989746

Epoch: 6| Step: 3
Training loss: 2.0970652103424072
Validation loss: 2.0628705422083535

Epoch: 6| Step: 4
Training loss: 1.9549992084503174
Validation loss: 2.0474698742230735

Epoch: 6| Step: 5
Training loss: 2.0489864349365234
Validation loss: 2.0668099323908486

Epoch: 6| Step: 6
Training loss: 2.0381784439086914
Validation loss: 2.065579911073049

Epoch: 6| Step: 7
Training loss: 1.5924012660980225
Validation loss: 2.0824271043141684

Epoch: 6| Step: 8
Training loss: 2.069507598876953
Validation loss: 2.0672411918640137

Epoch: 6| Step: 9
Training loss: 1.808683156967163
Validation loss: 2.0756839513778687

Epoch: 6| Step: 10
Training loss: 2.3901047706604004
Validation loss: 2.092474182446798

Epoch: 6| Step: 11
Training loss: 2.1557090282440186
Validation loss: 2.070787568887075

Epoch: 6| Step: 12
Training loss: 1.5600090026855469
Validation loss: 2.0829984148343406

Epoch: 6| Step: 13
Training loss: 1.837548851966858
Validation loss: 2.0683783491452536

Epoch: 56| Step: 0
Training loss: 1.8039205074310303
Validation loss: 2.056463678677877

Epoch: 6| Step: 1
Training loss: 1.4238369464874268
Validation loss: 2.052992284297943

Epoch: 6| Step: 2
Training loss: 1.9970440864562988
Validation loss: 2.065384050210317

Epoch: 6| Step: 3
Training loss: 2.2828919887542725
Validation loss: 2.04555873076121

Epoch: 6| Step: 4
Training loss: 2.4087255001068115
Validation loss: 2.0397505164146423

Epoch: 6| Step: 5
Training loss: 2.115536689758301
Validation loss: 2.053862690925598

Epoch: 6| Step: 6
Training loss: 1.9300404787063599
Validation loss: 2.0583157936731973

Epoch: 6| Step: 7
Training loss: 1.7673354148864746
Validation loss: 2.055684189001719

Epoch: 6| Step: 8
Training loss: 1.4578306674957275
Validation loss: 2.059657176335653

Epoch: 6| Step: 9
Training loss: 2.081538677215576
Validation loss: 2.03986648718516

Epoch: 6| Step: 10
Training loss: 2.4507100582122803
Validation loss: 2.062750438849131

Epoch: 6| Step: 11
Training loss: 1.792728304862976
Validation loss: 2.064808170000712

Epoch: 6| Step: 12
Training loss: 1.9253501892089844
Validation loss: 2.065874536832174

Epoch: 6| Step: 13
Training loss: 1.5506746768951416
Validation loss: 2.041070799032847

Epoch: 57| Step: 0
Training loss: 1.6037005186080933
Validation loss: 2.049362579981486

Epoch: 6| Step: 1
Training loss: 1.8088688850402832
Validation loss: 2.0843492348988852

Epoch: 6| Step: 2
Training loss: 2.0391507148742676
Validation loss: 2.0423715909322104

Epoch: 6| Step: 3
Training loss: 1.8533940315246582
Validation loss: 2.0631061792373657

Epoch: 6| Step: 4
Training loss: 2.006371021270752
Validation loss: 2.070239543914795

Epoch: 6| Step: 5
Training loss: 1.7717654705047607
Validation loss: 2.064430375893911

Epoch: 6| Step: 6
Training loss: 2.16757869720459
Validation loss: 2.0777748028437295

Epoch: 6| Step: 7
Training loss: 2.1051883697509766
Validation loss: 2.0547723372777305

Epoch: 6| Step: 8
Training loss: 2.2036900520324707
Validation loss: 2.1060990492502847

Epoch: 6| Step: 9
Training loss: 1.9337279796600342
Validation loss: 2.085413416226705

Epoch: 6| Step: 10
Training loss: 2.537715435028076
Validation loss: 2.0510369737943015

Epoch: 6| Step: 11
Training loss: 1.156928300857544
Validation loss: 2.0924335519472756

Epoch: 6| Step: 12
Training loss: 2.145382881164551
Validation loss: 2.064844230810801

Epoch: 6| Step: 13
Training loss: 1.3747844696044922
Validation loss: 2.0733070969581604

Epoch: 58| Step: 0
Training loss: 1.6419754028320312
Validation loss: 2.05331281820933

Epoch: 6| Step: 1
Training loss: 1.730502963066101
Validation loss: 2.081686317920685

Epoch: 6| Step: 2
Training loss: 1.701451301574707
Validation loss: 2.0590968132019043

Epoch: 6| Step: 3
Training loss: 2.404425621032715
Validation loss: 2.0423924922943115

Epoch: 6| Step: 4
Training loss: 1.8640573024749756
Validation loss: 2.06940629084905

Epoch: 6| Step: 5
Training loss: 1.5103577375411987
Validation loss: 2.0748322208722434

Epoch: 6| Step: 6
Training loss: 2.027589797973633
Validation loss: 2.062091290950775

Epoch: 6| Step: 7
Training loss: 2.6908769607543945
Validation loss: 2.0461531281471252

Epoch: 6| Step: 8
Training loss: 1.6150487661361694
Validation loss: 2.0810129245122275

Epoch: 6| Step: 9
Training loss: 1.8729114532470703
Validation loss: 2.066328843434652

Epoch: 6| Step: 10
Training loss: 2.360387086868286
Validation loss: 2.0808360973993936

Epoch: 6| Step: 11
Training loss: 1.907106637954712
Validation loss: 2.06189493338267

Epoch: 6| Step: 12
Training loss: 1.525714635848999
Validation loss: 2.0670915842056274

Epoch: 6| Step: 13
Training loss: 1.8464781045913696
Validation loss: 2.0658173163731894

Epoch: 59| Step: 0
Training loss: 2.4597246646881104
Validation loss: 2.0416554609934487

Epoch: 6| Step: 1
Training loss: 2.552025318145752
Validation loss: 2.081492026646932

Epoch: 6| Step: 2
Training loss: 1.9766324758529663
Validation loss: 2.079066753387451

Epoch: 6| Step: 3
Training loss: 1.1455317735671997
Validation loss: 2.048133214314779

Epoch: 6| Step: 4
Training loss: 1.8014934062957764
Validation loss: 2.0468191703160605

Epoch: 6| Step: 5
Training loss: 2.4184837341308594
Validation loss: 2.063822329044342

Epoch: 6| Step: 6
Training loss: 1.7408212423324585
Validation loss: 2.044354240099589

Epoch: 6| Step: 7
Training loss: 1.3926217555999756
Validation loss: 2.0486339330673218

Epoch: 6| Step: 8
Training loss: 1.6164653301239014
Validation loss: 2.0428547064463296

Epoch: 6| Step: 9
Training loss: 1.7668960094451904
Validation loss: 2.0598604877789817

Epoch: 6| Step: 10
Training loss: 2.219905376434326
Validation loss: 2.066148797671

Epoch: 6| Step: 11
Training loss: 1.5246676206588745
Validation loss: 2.052118420600891

Epoch: 6| Step: 12
Training loss: 2.030648708343506
Validation loss: 2.0479992429415383

Epoch: 6| Step: 13
Training loss: 2.0127272605895996
Validation loss: 2.0578235189119973

Epoch: 60| Step: 0
Training loss: 1.1673659086227417
Validation loss: 2.09768279393514

Epoch: 6| Step: 1
Training loss: 2.5205373764038086
Validation loss: 2.102569361527761

Epoch: 6| Step: 2
Training loss: 1.6613585948944092
Validation loss: 2.089445253213247

Epoch: 6| Step: 3
Training loss: 1.7138690948486328
Validation loss: 2.075986921787262

Epoch: 6| Step: 4
Training loss: 2.357438325881958
Validation loss: 2.0900593598683677

Epoch: 6| Step: 5
Training loss: 1.7667527198791504
Validation loss: 2.076470375061035

Epoch: 6| Step: 6
Training loss: 1.9305808544158936
Validation loss: 2.100607693195343

Epoch: 6| Step: 7
Training loss: 1.3254220485687256
Validation loss: 2.07472030321757

Epoch: 6| Step: 8
Training loss: 2.2340564727783203
Validation loss: 2.044579048951467

Epoch: 6| Step: 9
Training loss: 2.4576096534729004
Validation loss: 2.0996158917744956

Epoch: 6| Step: 10
Training loss: 1.9091839790344238
Validation loss: 2.079411824544271

Epoch: 6| Step: 11
Training loss: 1.4063761234283447
Validation loss: 2.047048568725586

Epoch: 6| Step: 12
Training loss: 1.5382555723190308
Validation loss: 2.0519785284996033

Epoch: 6| Step: 13
Training loss: 2.2379395961761475
Validation loss: 2.0535146991411843

Epoch: 61| Step: 0
Training loss: 2.0507819652557373
Validation loss: 2.090089976787567

Epoch: 6| Step: 1
Training loss: 1.691983938217163
Validation loss: 2.0599739154179892

Epoch: 6| Step: 2
Training loss: 2.0458388328552246
Validation loss: 2.0751317143440247

Epoch: 6| Step: 3
Training loss: 2.391129732131958
Validation loss: 2.077868163585663

Epoch: 6| Step: 4
Training loss: 2.0367698669433594
Validation loss: 2.0661352276802063

Epoch: 6| Step: 5
Training loss: 1.683455228805542
Validation loss: 2.0844776233037314

Epoch: 6| Step: 6
Training loss: 1.5776219367980957
Validation loss: 2.0751030842463174

Epoch: 6| Step: 7
Training loss: 1.9325189590454102
Validation loss: 2.056987206141154

Epoch: 6| Step: 8
Training loss: 1.9870073795318604
Validation loss: 2.0489770770072937

Epoch: 6| Step: 9
Training loss: 1.6195253133773804
Validation loss: 2.059633413950602

Epoch: 6| Step: 10
Training loss: 1.533515214920044
Validation loss: 2.043515940507253

Epoch: 6| Step: 11
Training loss: 2.0551748275756836
Validation loss: 2.030412971973419

Epoch: 6| Step: 12
Training loss: 2.4033634662628174
Validation loss: 2.032384177049001

Epoch: 6| Step: 13
Training loss: 2.234257698059082
Validation loss: 2.048286497592926

Epoch: 62| Step: 0
Training loss: 2.052919387817383
Validation loss: 2.0565605560938516

Epoch: 6| Step: 1
Training loss: 2.05442214012146
Validation loss: 2.065787216027578

Epoch: 6| Step: 2
Training loss: 1.5071934461593628
Validation loss: 2.085303465525309

Epoch: 6| Step: 3
Training loss: 1.692600965499878
Validation loss: 2.0901429057121277

Epoch: 6| Step: 4
Training loss: 1.4950981140136719
Validation loss: 2.0903722047805786

Epoch: 6| Step: 5
Training loss: 2.0407676696777344
Validation loss: 2.063826243082682

Epoch: 6| Step: 6
Training loss: 1.678269386291504
Validation loss: 2.0622673630714417

Epoch: 6| Step: 7
Training loss: 2.66605806350708
Validation loss: 2.062265932559967

Epoch: 6| Step: 8
Training loss: 1.893332839012146
Validation loss: 2.0572893222173056

Epoch: 6| Step: 9
Training loss: 1.933336853981018
Validation loss: 2.0794138511021933

Epoch: 6| Step: 10
Training loss: 1.9418498277664185
Validation loss: 2.0640565355618796

Epoch: 6| Step: 11
Training loss: 1.4877419471740723
Validation loss: 2.058226148287455

Epoch: 6| Step: 12
Training loss: 2.378683567047119
Validation loss: 2.053453246752421

Epoch: 6| Step: 13
Training loss: 1.5335967540740967
Validation loss: 2.065582831700643

Epoch: 63| Step: 0
Training loss: 1.9282703399658203
Validation loss: 2.029356280962626

Epoch: 6| Step: 1
Training loss: 1.5237219333648682
Validation loss: 2.0453527371088662

Epoch: 6| Step: 2
Training loss: 1.9183908700942993
Validation loss: 2.070498983065287

Epoch: 6| Step: 3
Training loss: 2.3469433784484863
Validation loss: 2.0526957909266152

Epoch: 6| Step: 4
Training loss: 1.605634331703186
Validation loss: 2.034300963083903

Epoch: 6| Step: 5
Training loss: 1.597066879272461
Validation loss: 2.0352429151535034

Epoch: 6| Step: 6
Training loss: 2.729466676712036
Validation loss: 2.021151681741079

Epoch: 6| Step: 7
Training loss: 1.9760751724243164
Validation loss: 2.056265672047933

Epoch: 6| Step: 8
Training loss: 1.7736179828643799
Validation loss: 2.0664899746576944

Epoch: 6| Step: 9
Training loss: 1.268692970275879
Validation loss: 2.0484857757886252

Epoch: 6| Step: 10
Training loss: 1.45401930809021
Validation loss: 2.0463717778523765

Epoch: 6| Step: 11
Training loss: 2.2022976875305176
Validation loss: 2.053080896536509

Epoch: 6| Step: 12
Training loss: 2.0869815349578857
Validation loss: 2.045946478843689

Epoch: 6| Step: 13
Training loss: 1.6649596691131592
Validation loss: 2.071834087371826

Epoch: 64| Step: 0
Training loss: 1.865307092666626
Validation loss: 2.0454058249791465

Epoch: 6| Step: 1
Training loss: 1.3067153692245483
Validation loss: 2.052139321962992

Epoch: 6| Step: 2
Training loss: 2.059605836868286
Validation loss: 2.0482390920321145

Epoch: 6| Step: 3
Training loss: 2.3382298946380615
Validation loss: 2.0512775977452598

Epoch: 6| Step: 4
Training loss: 2.057292938232422
Validation loss: 2.0586347381273904

Epoch: 6| Step: 5
Training loss: 1.4036269187927246
Validation loss: 2.055021087328593

Epoch: 6| Step: 6
Training loss: 2.3721275329589844
Validation loss: 2.0463982820510864

Epoch: 6| Step: 7
Training loss: 1.816546082496643
Validation loss: 2.0684203505516052

Epoch: 6| Step: 8
Training loss: 2.1121559143066406
Validation loss: 2.0445997516314187

Epoch: 6| Step: 9
Training loss: 1.8478432893753052
Validation loss: 2.0613584319750466

Epoch: 6| Step: 10
Training loss: 1.9744913578033447
Validation loss: 2.04955126841863

Epoch: 6| Step: 11
Training loss: 1.9462416172027588
Validation loss: 2.0633933742841086

Epoch: 6| Step: 12
Training loss: 1.7237272262573242
Validation loss: 2.0284239053726196

Epoch: 6| Step: 13
Training loss: 1.4549347162246704
Validation loss: 2.0382864077885947

Epoch: 65| Step: 0
Training loss: 1.9725613594055176
Validation loss: 2.0188563068707785

Epoch: 6| Step: 1
Training loss: 2.414034605026245
Validation loss: 2.0363354484240213

Epoch: 6| Step: 2
Training loss: 1.8111324310302734
Validation loss: 2.080645759900411

Epoch: 6| Step: 3
Training loss: 2.250345468521118
Validation loss: 2.045613090197245

Epoch: 6| Step: 4
Training loss: 1.364486813545227
Validation loss: 2.0744239489237466

Epoch: 6| Step: 5
Training loss: 1.4417130947113037
Validation loss: 2.0731621980667114

Epoch: 6| Step: 6
Training loss: 2.52810001373291
Validation loss: 2.0653750697771707

Epoch: 6| Step: 7
Training loss: 1.9658156633377075
Validation loss: 2.0689884424209595

Epoch: 6| Step: 8
Training loss: 1.5597376823425293
Validation loss: 2.0894567171732583

Epoch: 6| Step: 9
Training loss: 1.8622400760650635
Validation loss: 2.0601865649223328

Epoch: 6| Step: 10
Training loss: 1.677514910697937
Validation loss: 2.0757521589597068

Epoch: 6| Step: 11
Training loss: 2.381828784942627
Validation loss: 2.055679460366567

Epoch: 6| Step: 12
Training loss: 1.929763674736023
Validation loss: 2.048987547556559

Epoch: 6| Step: 13
Training loss: 1.0863232612609863
Validation loss: 2.024152676264445

Epoch: 66| Step: 0
Training loss: 1.8597148656845093
Validation loss: 2.030988355477651

Epoch: 6| Step: 1
Training loss: 1.6039786338806152
Validation loss: 2.0414106448491416

Epoch: 6| Step: 2
Training loss: 2.608752727508545
Validation loss: 2.04333504041036

Epoch: 6| Step: 3
Training loss: 1.4803005456924438
Validation loss: 2.046112895011902

Epoch: 6| Step: 4
Training loss: 1.9563014507293701
Validation loss: 2.005935311317444

Epoch: 6| Step: 5
Training loss: 2.3827438354492188
Validation loss: 2.031690319379171

Epoch: 6| Step: 6
Training loss: 1.3414150476455688
Validation loss: 2.037850042184194

Epoch: 6| Step: 7
Training loss: 1.2162339687347412
Validation loss: 2.037014901638031

Epoch: 6| Step: 8
Training loss: 1.1138105392456055
Validation loss: 2.0381548007329306

Epoch: 6| Step: 9
Training loss: 1.8057570457458496
Validation loss: 2.0386485854784646

Epoch: 6| Step: 10
Training loss: 1.8159884214401245
Validation loss: 2.082395772139231

Epoch: 6| Step: 11
Training loss: 2.6568732261657715
Validation loss: 2.07099058230718

Epoch: 6| Step: 12
Training loss: 2.1684956550598145
Validation loss: 2.0980269511540732

Epoch: 6| Step: 13
Training loss: 2.4480466842651367
Validation loss: 2.0425860484441123

Epoch: 67| Step: 0
Training loss: 2.0975756645202637
Validation loss: 2.0545868078867593

Epoch: 6| Step: 1
Training loss: 2.083357810974121
Validation loss: 2.058590054512024

Epoch: 6| Step: 2
Training loss: 1.5053119659423828
Validation loss: 2.0257701476415

Epoch: 6| Step: 3
Training loss: 2.1638574600219727
Validation loss: 2.071813960870107

Epoch: 6| Step: 4
Training loss: 2.0139272212982178
Validation loss: 2.040703773498535

Epoch: 6| Step: 5
Training loss: 1.7990694046020508
Validation loss: 2.04023277759552

Epoch: 6| Step: 6
Training loss: 1.4243812561035156
Validation loss: 2.0553543170293174

Epoch: 6| Step: 7
Training loss: 2.043517589569092
Validation loss: 2.0300957361857095

Epoch: 6| Step: 8
Training loss: 1.758251667022705
Validation loss: 2.0021936496098838

Epoch: 6| Step: 9
Training loss: 1.74226975440979
Validation loss: 2.0435532132784524

Epoch: 6| Step: 10
Training loss: 1.9048588275909424
Validation loss: 2.043070395787557

Epoch: 6| Step: 11
Training loss: 2.293994903564453
Validation loss: 2.0555872519810996

Epoch: 6| Step: 12
Training loss: 1.7673370838165283
Validation loss: 2.0235453248023987

Epoch: 6| Step: 13
Training loss: 1.6901180744171143
Validation loss: 2.021039525667826

Epoch: 68| Step: 0
Training loss: 2.4250571727752686
Validation loss: 2.052304446697235

Epoch: 6| Step: 1
Training loss: 2.4368228912353516
Validation loss: 2.0408082207043967

Epoch: 6| Step: 2
Training loss: 2.014679431915283
Validation loss: 2.0687719782193503

Epoch: 6| Step: 3
Training loss: 1.4600398540496826
Validation loss: 2.051836093266805

Epoch: 6| Step: 4
Training loss: 1.5481302738189697
Validation loss: 2.084874431292216

Epoch: 6| Step: 5
Training loss: 1.664011001586914
Validation loss: 2.079055110613505

Epoch: 6| Step: 6
Training loss: 2.0039570331573486
Validation loss: 2.084139049053192

Epoch: 6| Step: 7
Training loss: 1.3367117643356323
Validation loss: 2.0876049399375916

Epoch: 6| Step: 8
Training loss: 1.8209941387176514
Validation loss: 2.096080799897512

Epoch: 6| Step: 9
Training loss: 2.0343422889709473
Validation loss: 2.074287017186483

Epoch: 6| Step: 10
Training loss: 2.0416884422302246
Validation loss: 2.065200606981913

Epoch: 6| Step: 11
Training loss: 1.4420616626739502
Validation loss: 2.052428185939789

Epoch: 6| Step: 12
Training loss: 1.8495280742645264
Validation loss: 2.0615740219751992

Epoch: 6| Step: 13
Training loss: 1.8758797645568848
Validation loss: 2.0317709843317666

Epoch: 69| Step: 0
Training loss: 1.2924716472625732
Validation loss: 2.0306628942489624

Epoch: 6| Step: 1
Training loss: 1.819866418838501
Validation loss: 2.0269056955973306

Epoch: 6| Step: 2
Training loss: 2.7243831157684326
Validation loss: 2.0480724573135376

Epoch: 6| Step: 3
Training loss: 1.8455156087875366
Validation loss: 2.058800478776296

Epoch: 6| Step: 4
Training loss: 1.8010735511779785
Validation loss: 2.0172524650891623

Epoch: 6| Step: 5
Training loss: 1.9592338800430298
Validation loss: 2.0502302249272666

Epoch: 6| Step: 6
Training loss: 1.8329697847366333
Validation loss: 2.029938797156016

Epoch: 6| Step: 7
Training loss: 0.9922009110450745
Validation loss: 2.048823376496633

Epoch: 6| Step: 8
Training loss: 2.487117290496826
Validation loss: 2.0391568144162497

Epoch: 6| Step: 9
Training loss: 2.374920129776001
Validation loss: 2.050155599912008

Epoch: 6| Step: 10
Training loss: 1.2823283672332764
Validation loss: 2.0381577412287393

Epoch: 6| Step: 11
Training loss: 2.3236217498779297
Validation loss: 2.0488990545272827

Epoch: 6| Step: 12
Training loss: 1.9821237325668335
Validation loss: 2.0469204783439636

Epoch: 6| Step: 13
Training loss: 1.344346046447754
Validation loss: 2.051910698413849

Epoch: 70| Step: 0
Training loss: 2.102553367614746
Validation loss: 2.0213497281074524

Epoch: 6| Step: 1
Training loss: 1.7485555410385132
Validation loss: 2.0543078978856406

Epoch: 6| Step: 2
Training loss: 1.77598237991333
Validation loss: 2.039416511853536

Epoch: 6| Step: 3
Training loss: 1.9650756120681763
Validation loss: 2.038068652153015

Epoch: 6| Step: 4
Training loss: 1.8279527425765991
Validation loss: 2.0462456742922464

Epoch: 6| Step: 5
Training loss: 2.110102415084839
Validation loss: 2.0343651175498962

Epoch: 6| Step: 6
Training loss: 1.6920565366744995
Validation loss: 2.0488494833310447

Epoch: 6| Step: 7
Training loss: 1.7846810817718506
Validation loss: 2.062435527642568

Epoch: 6| Step: 8
Training loss: 1.8578146696090698
Validation loss: 2.0480283896128335

Epoch: 6| Step: 9
Training loss: 2.040375232696533
Validation loss: 2.0950732032457986

Epoch: 6| Step: 10
Training loss: 1.6595301628112793
Validation loss: 2.0098522106806436

Epoch: 6| Step: 11
Training loss: 1.6894779205322266
Validation loss: 2.0652968088785806

Epoch: 6| Step: 12
Training loss: 1.6922603845596313
Validation loss: 2.0568888783454895

Epoch: 6| Step: 13
Training loss: 1.818120002746582
Validation loss: 2.06120228767395

Epoch: 71| Step: 0
Training loss: 1.2665518522262573
Validation loss: 2.0573315421740213

Epoch: 6| Step: 1
Training loss: 1.956663966178894
Validation loss: 2.0781355102856955

Epoch: 6| Step: 2
Training loss: 1.2845118045806885
Validation loss: 2.0607622067133584

Epoch: 6| Step: 3
Training loss: 2.3128128051757812
Validation loss: 2.0754478176434836

Epoch: 6| Step: 4
Training loss: 1.9721829891204834
Validation loss: 2.0394168297449746

Epoch: 6| Step: 5
Training loss: 1.5464715957641602
Validation loss: 2.052302281061808

Epoch: 6| Step: 6
Training loss: 2.065338134765625
Validation loss: 2.0144229729970298

Epoch: 6| Step: 7
Training loss: 1.5807193517684937
Validation loss: 2.0311272939046225

Epoch: 6| Step: 8
Training loss: 1.3088366985321045
Validation loss: 2.0360818107922873

Epoch: 6| Step: 9
Training loss: 1.547349452972412
Validation loss: 2.014745910962423

Epoch: 6| Step: 10
Training loss: 1.794996976852417
Validation loss: 2.067450245221456

Epoch: 6| Step: 11
Training loss: 2.031175374984741
Validation loss: 2.0410080353418985

Epoch: 6| Step: 12
Training loss: 2.7379422187805176
Validation loss: 2.0173091888427734

Epoch: 6| Step: 13
Training loss: 2.305093765258789
Validation loss: 2.0502419670422873

Epoch: 72| Step: 0
Training loss: 2.250056266784668
Validation loss: 2.0635469555854797

Epoch: 6| Step: 1
Training loss: 1.1333630084991455
Validation loss: 2.0121190349260965

Epoch: 6| Step: 2
Training loss: 1.5186082124710083
Validation loss: 2.058532238006592

Epoch: 6| Step: 3
Training loss: 1.8680391311645508
Validation loss: 2.042807678381602

Epoch: 6| Step: 4
Training loss: 1.9887058734893799
Validation loss: 2.0472766160964966

Epoch: 6| Step: 5
Training loss: 1.7044386863708496
Validation loss: 2.0404433806737265

Epoch: 6| Step: 6
Training loss: 3.218416213989258
Validation loss: 2.029887775580088

Epoch: 6| Step: 7
Training loss: 1.7996830940246582
Validation loss: 2.0116514762242637

Epoch: 6| Step: 8
Training loss: 1.3640577793121338
Validation loss: 2.0298970341682434

Epoch: 6| Step: 9
Training loss: 1.9978392124176025
Validation loss: 2.0315752824147544

Epoch: 6| Step: 10
Training loss: 1.6484037637710571
Validation loss: 2.0181931257247925

Epoch: 6| Step: 11
Training loss: 1.8775359392166138
Validation loss: 2.0193939010302224

Epoch: 6| Step: 12
Training loss: 1.7003331184387207
Validation loss: 2.031954606374105

Epoch: 6| Step: 13
Training loss: 1.7074410915374756
Validation loss: 2.0554693142573037

Epoch: 73| Step: 0
Training loss: 1.9837149381637573
Validation loss: 2.009132206439972

Epoch: 6| Step: 1
Training loss: 1.9362021684646606
Validation loss: 2.0532637437184653

Epoch: 6| Step: 2
Training loss: 1.536597728729248
Validation loss: 2.0370220144589744

Epoch: 6| Step: 3
Training loss: 2.0987772941589355
Validation loss: 2.029038449128469

Epoch: 6| Step: 4
Training loss: 1.8709897994995117
Validation loss: 2.0334525108337402

Epoch: 6| Step: 5
Training loss: 2.0866003036499023
Validation loss: 2.046191473801931

Epoch: 6| Step: 6
Training loss: 1.4374076128005981
Validation loss: 2.0528668959935508

Epoch: 6| Step: 7
Training loss: 2.0041048526763916
Validation loss: 2.0203817486763

Epoch: 6| Step: 8
Training loss: 1.5322827100753784
Validation loss: 2.0656220515569053

Epoch: 6| Step: 9
Training loss: 2.0307443141937256
Validation loss: 2.05065381526947

Epoch: 6| Step: 10
Training loss: 1.4295063018798828
Validation loss: 2.0494807759920755

Epoch: 6| Step: 11
Training loss: 1.979602336883545
Validation loss: 2.0473288695017495

Epoch: 6| Step: 12
Training loss: 1.5872433185577393
Validation loss: 2.0408406257629395

Epoch: 6| Step: 13
Training loss: 1.848733901977539
Validation loss: 2.0292235016822815

Epoch: 74| Step: 0
Training loss: 1.5528813600540161
Validation loss: 2.0477277835210166

Epoch: 6| Step: 1
Training loss: 1.7004907131195068
Validation loss: 2.039274533589681

Epoch: 6| Step: 2
Training loss: 1.9397964477539062
Validation loss: 2.014896889527639

Epoch: 6| Step: 3
Training loss: 2.105647563934326
Validation loss: 2.0391803781191506

Epoch: 6| Step: 4
Training loss: 1.5399720668792725
Validation loss: 2.0158585707346597

Epoch: 6| Step: 5
Training loss: 1.6970946788787842
Validation loss: 2.014428496360779

Epoch: 6| Step: 6
Training loss: 1.784195899963379
Validation loss: 2.0351889530817666

Epoch: 6| Step: 7
Training loss: 1.7272322177886963
Validation loss: 2.0177902777989707

Epoch: 6| Step: 8
Training loss: 2.234680414199829
Validation loss: 2.0472340981165567

Epoch: 6| Step: 9
Training loss: 1.5765929222106934
Validation loss: 2.0341195861498513

Epoch: 6| Step: 10
Training loss: 1.8971281051635742
Validation loss: 2.0543907483418784

Epoch: 6| Step: 11
Training loss: 2.2409911155700684
Validation loss: 2.050140102704366

Epoch: 6| Step: 12
Training loss: 0.9765775203704834
Validation loss: 2.024340808391571

Epoch: 6| Step: 13
Training loss: 2.266704797744751
Validation loss: 2.0680906772613525

Epoch: 75| Step: 0
Training loss: 1.860602617263794
Validation loss: 2.0891597270965576

Epoch: 6| Step: 1
Training loss: 1.5737035274505615
Validation loss: 2.0638820131619773

Epoch: 6| Step: 2
Training loss: 1.10653555393219
Validation loss: 2.0368691086769104

Epoch: 6| Step: 3
Training loss: 1.730206847190857
Validation loss: 2.029782295227051

Epoch: 6| Step: 4
Training loss: 1.6015715599060059
Validation loss: 2.061003108819326

Epoch: 6| Step: 5
Training loss: 3.0752739906311035
Validation loss: 2.0656194488207498

Epoch: 6| Step: 6
Training loss: 2.22878098487854
Validation loss: 2.0026716788609824

Epoch: 6| Step: 7
Training loss: 1.9116917848587036
Validation loss: 2.034909168879191

Epoch: 6| Step: 8
Training loss: 1.5475783348083496
Validation loss: 2.0241455833117166

Epoch: 6| Step: 9
Training loss: 2.093273878097534
Validation loss: 2.0451085964838662

Epoch: 6| Step: 10
Training loss: 1.2562556266784668
Validation loss: 2.0240246057510376

Epoch: 6| Step: 11
Training loss: 1.9874441623687744
Validation loss: 2.042967756589254

Epoch: 6| Step: 12
Training loss: 1.4016554355621338
Validation loss: 2.059032678604126

Epoch: 6| Step: 13
Training loss: 2.0368993282318115
Validation loss: 2.0340783397356668

Epoch: 76| Step: 0
Training loss: 1.6677420139312744
Validation loss: 2.0322247743606567

Epoch: 6| Step: 1
Training loss: 2.2325503826141357
Validation loss: 2.033768117427826

Epoch: 6| Step: 2
Training loss: 2.145500659942627
Validation loss: 2.05993781487147

Epoch: 6| Step: 3
Training loss: 1.8324705362319946
Validation loss: 2.056224544843038

Epoch: 6| Step: 4
Training loss: 1.3113154172897339
Validation loss: 2.077242076396942

Epoch: 6| Step: 5
Training loss: 1.8576409816741943
Validation loss: 2.047185182571411

Epoch: 6| Step: 6
Training loss: 1.7212729454040527
Validation loss: 2.0342348416646323

Epoch: 6| Step: 7
Training loss: 1.194901704788208
Validation loss: 2.0189925034840903

Epoch: 6| Step: 8
Training loss: 2.192296266555786
Validation loss: 2.036665995915731

Epoch: 6| Step: 9
Training loss: 1.389285922050476
Validation loss: 2.014951527118683

Epoch: 6| Step: 10
Training loss: 2.262523889541626
Validation loss: 2.007823328177134

Epoch: 6| Step: 11
Training loss: 2.020458698272705
Validation loss: 2.017449220021566

Epoch: 6| Step: 12
Training loss: 1.5448894500732422
Validation loss: 2.038784384727478

Epoch: 6| Step: 13
Training loss: 1.5261878967285156
Validation loss: 2.0269830028216043

Epoch: 77| Step: 0
Training loss: 2.1125755310058594
Validation loss: 1.9982865651448567

Epoch: 6| Step: 1
Training loss: 2.132741928100586
Validation loss: 2.075855573018392

Epoch: 6| Step: 2
Training loss: 1.5077754259109497
Validation loss: 2.0569516817728677

Epoch: 6| Step: 3
Training loss: 1.6318622827529907
Validation loss: 2.0247559547424316

Epoch: 6| Step: 4
Training loss: 1.3443657159805298
Validation loss: 2.055656651655833

Epoch: 6| Step: 5
Training loss: 2.5703182220458984
Validation loss: 2.039146582285563

Epoch: 6| Step: 6
Training loss: 1.6154217720031738
Validation loss: 2.0433385968208313

Epoch: 6| Step: 7
Training loss: 1.85435152053833
Validation loss: 2.0284698406855264

Epoch: 6| Step: 8
Training loss: 1.0963411331176758
Validation loss: 2.024705797433853

Epoch: 6| Step: 9
Training loss: 1.8311477899551392
Validation loss: 2.028702119986216

Epoch: 6| Step: 10
Training loss: 1.5079350471496582
Validation loss: 2.016423304875692

Epoch: 6| Step: 11
Training loss: 1.7176434993743896
Validation loss: 2.044108827908834

Epoch: 6| Step: 12
Training loss: 1.9374675750732422
Validation loss: 2.0303120811780295

Epoch: 6| Step: 13
Training loss: 2.0089468955993652
Validation loss: 2.025081773598989

Epoch: 78| Step: 0
Training loss: 2.033174753189087
Validation loss: 2.028648873170217

Epoch: 6| Step: 1
Training loss: 2.067228078842163
Validation loss: 2.006280700365702

Epoch: 6| Step: 2
Training loss: 2.0044710636138916
Validation loss: 2.00621489683787

Epoch: 6| Step: 3
Training loss: 1.8034448623657227
Validation loss: 2.0216121077537537

Epoch: 6| Step: 4
Training loss: 1.3261719942092896
Validation loss: 2.0084388653437295

Epoch: 6| Step: 5
Training loss: 1.8651883602142334
Validation loss: 2.0061838825543723

Epoch: 6| Step: 6
Training loss: 1.5401839017868042
Validation loss: 2.025762140750885

Epoch: 6| Step: 7
Training loss: 2.032700777053833
Validation loss: 2.0242026646931968

Epoch: 6| Step: 8
Training loss: 1.3713595867156982
Validation loss: 2.0513542890548706

Epoch: 6| Step: 9
Training loss: 1.7790906429290771
Validation loss: 2.04587189356486

Epoch: 6| Step: 10
Training loss: 1.3335052728652954
Validation loss: 2.0764658451080322

Epoch: 6| Step: 11
Training loss: 2.3232059478759766
Validation loss: 2.080308278401693

Epoch: 6| Step: 12
Training loss: 1.6532998085021973
Validation loss: 2.054088532924652

Epoch: 6| Step: 13
Training loss: 1.8783408403396606
Validation loss: 2.0373810529708862

Epoch: 79| Step: 0
Training loss: 2.021641254425049
Validation loss: 2.0319683949152627

Epoch: 6| Step: 1
Training loss: 1.2614938020706177
Validation loss: 2.047602037588755

Epoch: 6| Step: 2
Training loss: 1.9253113269805908
Validation loss: 2.0296236872673035

Epoch: 6| Step: 3
Training loss: 1.526700735092163
Validation loss: 2.0154776771863303

Epoch: 6| Step: 4
Training loss: 1.7769417762756348
Validation loss: 1.997897982597351

Epoch: 6| Step: 5
Training loss: 1.5815038681030273
Validation loss: 2.01734189192454

Epoch: 6| Step: 6
Training loss: 1.5859732627868652
Validation loss: 2.0044162472089133

Epoch: 6| Step: 7
Training loss: 1.654874563217163
Validation loss: 2.0292054613431296

Epoch: 6| Step: 8
Training loss: 1.31354820728302
Validation loss: 2.0302621523539224

Epoch: 6| Step: 9
Training loss: 1.7480336427688599
Validation loss: 2.013586858908335

Epoch: 6| Step: 10
Training loss: 1.525686502456665
Validation loss: 2.0531136194864907

Epoch: 6| Step: 11
Training loss: 2.476626396179199
Validation loss: 2.0229198733965554

Epoch: 6| Step: 12
Training loss: 2.0308454036712646
Validation loss: 2.034335196018219

Epoch: 6| Step: 13
Training loss: 2.379983901977539
Validation loss: 2.0441256761550903

Epoch: 80| Step: 0
Training loss: 1.917540431022644
Validation loss: 2.0511069893836975

Epoch: 6| Step: 1
Training loss: 1.5976344347000122
Validation loss: 2.0057488679885864

Epoch: 6| Step: 2
Training loss: 2.0132079124450684
Validation loss: 1.98514990011851

Epoch: 6| Step: 3
Training loss: 1.9683916568756104
Validation loss: 2.014898935953776

Epoch: 6| Step: 4
Training loss: 2.3722872734069824
Validation loss: 2.006916960080465

Epoch: 6| Step: 5
Training loss: 2.0545597076416016
Validation loss: 2.021701474984487

Epoch: 6| Step: 6
Training loss: 2.418468713760376
Validation loss: 2.0527666211128235

Epoch: 6| Step: 7
Training loss: 1.237638235092163
Validation loss: 2.0309818387031555

Epoch: 6| Step: 8
Training loss: 1.417182445526123
Validation loss: 2.029715895652771

Epoch: 6| Step: 9
Training loss: 1.7036011219024658
Validation loss: 2.0331681172053018

Epoch: 6| Step: 10
Training loss: 1.8764320611953735
Validation loss: 2.0431368748346963

Epoch: 6| Step: 11
Training loss: 1.5433621406555176
Validation loss: 2.0270186265309653

Epoch: 6| Step: 12
Training loss: 1.6935205459594727
Validation loss: 1.98028165102005

Epoch: 6| Step: 13
Training loss: 1.2462663650512695
Validation loss: 2.0371347864468894

Epoch: 81| Step: 0
Training loss: 1.3614168167114258
Validation loss: 2.046044925848643

Epoch: 6| Step: 1
Training loss: 1.4860830307006836
Validation loss: 2.104188938935598

Epoch: 6| Step: 2
Training loss: 1.920517086982727
Validation loss: 2.113836725552877

Epoch: 6| Step: 3
Training loss: 2.871811866760254
Validation loss: 2.144320805867513

Epoch: 6| Step: 4
Training loss: 2.2965850830078125
Validation loss: 2.091593027114868

Epoch: 6| Step: 5
Training loss: 1.5425441265106201
Validation loss: 2.0712785124778748

Epoch: 6| Step: 6
Training loss: 1.800358772277832
Validation loss: 2.096354881922404

Epoch: 6| Step: 7
Training loss: 2.6335299015045166
Validation loss: 2.015248497327169

Epoch: 6| Step: 8
Training loss: 1.958835244178772
Validation loss: 2.0109238823254905

Epoch: 6| Step: 9
Training loss: 1.5890928506851196
Validation loss: 2.012834827105204

Epoch: 6| Step: 10
Training loss: 1.3650829792022705
Validation loss: 1.9987877408663433

Epoch: 6| Step: 11
Training loss: 1.614343523979187
Validation loss: 2.012067178885142

Epoch: 6| Step: 12
Training loss: 1.5996193885803223
Validation loss: 1.9907824595769246

Epoch: 6| Step: 13
Training loss: 1.5902934074401855
Validation loss: 2.0108219186464944

Epoch: 82| Step: 0
Training loss: 1.5609784126281738
Validation loss: 2.016642212867737

Epoch: 6| Step: 1
Training loss: 1.054961085319519
Validation loss: 2.011584162712097

Epoch: 6| Step: 2
Training loss: 1.7576773166656494
Validation loss: 1.9735123713811238

Epoch: 6| Step: 3
Training loss: 1.8235905170440674
Validation loss: 2.0041114489237466

Epoch: 6| Step: 4
Training loss: 1.9287447929382324
Validation loss: 2.038554847240448

Epoch: 6| Step: 5
Training loss: 1.6981288194656372
Validation loss: 2.041375716527303

Epoch: 6| Step: 6
Training loss: 2.107213020324707
Validation loss: 2.03981606165568

Epoch: 6| Step: 7
Training loss: 2.1966471672058105
Validation loss: 2.0381924907366433

Epoch: 6| Step: 8
Training loss: 2.4315218925476074
Validation loss: 2.0304636359214783

Epoch: 6| Step: 9
Training loss: 1.9468538761138916
Validation loss: 2.0533584554990134

Epoch: 6| Step: 10
Training loss: 1.9056265354156494
Validation loss: 2.036851425965627

Epoch: 6| Step: 11
Training loss: 1.5563431978225708
Validation loss: 2.064151386419932

Epoch: 6| Step: 12
Training loss: 1.2169753313064575
Validation loss: 2.003413498401642

Epoch: 6| Step: 13
Training loss: 1.2572498321533203
Validation loss: 2.0411774118741355

Epoch: 83| Step: 0
Training loss: 1.6403744220733643
Validation loss: 2.0206972559293113

Epoch: 6| Step: 1
Training loss: 1.8181098699569702
Validation loss: 2.0349876483281455

Epoch: 6| Step: 2
Training loss: 2.2561960220336914
Validation loss: 2.015910029411316

Epoch: 6| Step: 3
Training loss: 2.4336671829223633
Validation loss: 2.0048144857088723

Epoch: 6| Step: 4
Training loss: 1.8726557493209839
Validation loss: 2.019467214743296

Epoch: 6| Step: 5
Training loss: 1.7199294567108154
Validation loss: 2.019721726576487

Epoch: 6| Step: 6
Training loss: 1.9900884628295898
Validation loss: 2.0288767417271933

Epoch: 6| Step: 7
Training loss: 1.3556716442108154
Validation loss: 2.015757660071055

Epoch: 6| Step: 8
Training loss: 1.5231294631958008
Validation loss: 2.012668708960215

Epoch: 6| Step: 9
Training loss: 1.4012798070907593
Validation loss: 1.9783625205357869

Epoch: 6| Step: 10
Training loss: 1.8032166957855225
Validation loss: 2.0125362873077393

Epoch: 6| Step: 11
Training loss: 1.3680181503295898
Validation loss: 2.018351952234904

Epoch: 6| Step: 12
Training loss: 1.741091251373291
Validation loss: 2.0211197336514792

Epoch: 6| Step: 13
Training loss: 2.038883686065674
Validation loss: 2.0632866819699607

Epoch: 84| Step: 0
Training loss: 1.6209259033203125
Validation loss: 2.066674788792928

Epoch: 6| Step: 1
Training loss: 1.8914706707000732
Validation loss: 2.1044246554374695

Epoch: 6| Step: 2
Training loss: 1.8225750923156738
Validation loss: 2.1053484678268433

Epoch: 6| Step: 3
Training loss: 2.027688503265381
Validation loss: 2.1298239628473916

Epoch: 6| Step: 4
Training loss: 1.958997368812561
Validation loss: 2.09416534503301

Epoch: 6| Step: 5
Training loss: 2.2958385944366455
Validation loss: 2.0700027545293174

Epoch: 6| Step: 6
Training loss: 1.2861990928649902
Validation loss: 2.0368099013964334

Epoch: 6| Step: 7
Training loss: 1.5139293670654297
Validation loss: 2.0388559699058533

Epoch: 6| Step: 8
Training loss: 1.6069653034210205
Validation loss: 2.0300415754318237

Epoch: 6| Step: 9
Training loss: 1.4207109212875366
Validation loss: 1.9921106298764546

Epoch: 6| Step: 10
Training loss: 2.0003268718719482
Validation loss: 1.9982675711313884

Epoch: 6| Step: 11
Training loss: 1.285193920135498
Validation loss: 2.0253563125928244

Epoch: 6| Step: 12
Training loss: 1.7434700727462769
Validation loss: 2.011927902698517

Epoch: 6| Step: 13
Training loss: 1.9197657108306885
Validation loss: 2.0297136704126992

Epoch: 85| Step: 0
Training loss: 1.5139957666397095
Validation loss: 2.0033894181251526

Epoch: 6| Step: 1
Training loss: 1.4797232151031494
Validation loss: 2.0164758563041687

Epoch: 6| Step: 2
Training loss: 1.1173590421676636
Validation loss: 2.0054288506507874

Epoch: 6| Step: 3
Training loss: 2.1345701217651367
Validation loss: 2.0087677439053855

Epoch: 6| Step: 4
Training loss: 1.5716698169708252
Validation loss: 2.0228202740351358

Epoch: 6| Step: 5
Training loss: 1.870499610900879
Validation loss: 2.0043728152910867

Epoch: 6| Step: 6
Training loss: 1.5893480777740479
Validation loss: 2.0415827433268228

Epoch: 6| Step: 7
Training loss: 1.4877111911773682
Validation loss: 2.017056961854299

Epoch: 6| Step: 8
Training loss: 1.6285572052001953
Validation loss: 2.0179766019185386

Epoch: 6| Step: 9
Training loss: 2.6666383743286133
Validation loss: 2.0416752298672995

Epoch: 6| Step: 10
Training loss: 1.772183895111084
Validation loss: 2.017629782358805

Epoch: 6| Step: 11
Training loss: 1.974104881286621
Validation loss: 2.0022583603858948

Epoch: 6| Step: 12
Training loss: 1.3742570877075195
Validation loss: 2.0160305897394815

Epoch: 6| Step: 13
Training loss: 1.9317606687545776
Validation loss: 1.9954746166865032

Epoch: 86| Step: 0
Training loss: 1.9139461517333984
Validation loss: 2.028439482053121

Epoch: 6| Step: 1
Training loss: 1.247124433517456
Validation loss: 2.0311827262242637

Epoch: 6| Step: 2
Training loss: 1.333807349205017
Validation loss: 2.0251912673314414

Epoch: 6| Step: 3
Training loss: 1.4673748016357422
Validation loss: 2.0156978368759155

Epoch: 6| Step: 4
Training loss: 1.4751704931259155
Validation loss: 2.0137513081232705

Epoch: 6| Step: 5
Training loss: 1.5737860202789307
Validation loss: 2.0330931742986045

Epoch: 6| Step: 6
Training loss: 1.216806173324585
Validation loss: 2.0293243328730264

Epoch: 6| Step: 7
Training loss: 2.9569859504699707
Validation loss: 2.022343873977661

Epoch: 6| Step: 8
Training loss: 2.0819149017333984
Validation loss: 2.0375268260637918

Epoch: 6| Step: 9
Training loss: 1.616172194480896
Validation loss: 2.034235119819641

Epoch: 6| Step: 10
Training loss: 1.7500379085540771
Validation loss: 2.005467335383097

Epoch: 6| Step: 11
Training loss: 1.7915728092193604
Validation loss: 1.988627036412557

Epoch: 6| Step: 12
Training loss: 1.2977867126464844
Validation loss: 2.05352912346522

Epoch: 6| Step: 13
Training loss: 2.0076537132263184
Validation loss: 1.9895619948705037

Epoch: 87| Step: 0
Training loss: 1.410994529724121
Validation loss: 2.0307783285776773

Epoch: 6| Step: 1
Training loss: 0.941581130027771
Validation loss: 2.0098753571510315

Epoch: 6| Step: 2
Training loss: 2.3778228759765625
Validation loss: 2.0236113468805947

Epoch: 6| Step: 3
Training loss: 2.338484287261963
Validation loss: 2.0308428208033242

Epoch: 6| Step: 4
Training loss: 2.0509896278381348
Validation loss: 2.0186010599136353

Epoch: 6| Step: 5
Training loss: 1.5742758512496948
Validation loss: 1.9949701428413391

Epoch: 6| Step: 6
Training loss: 1.3859426975250244
Validation loss: 1.9770111838976543

Epoch: 6| Step: 7
Training loss: 1.6039077043533325
Validation loss: 2.009679635365804

Epoch: 6| Step: 8
Training loss: 1.735393762588501
Validation loss: 2.0228481690088906

Epoch: 6| Step: 9
Training loss: 1.8186936378479004
Validation loss: 2.002546509106954

Epoch: 6| Step: 10
Training loss: 1.7994518280029297
Validation loss: 1.9964728951454163

Epoch: 6| Step: 11
Training loss: 1.8446396589279175
Validation loss: 2.0169872641563416

Epoch: 6| Step: 12
Training loss: 1.3634285926818848
Validation loss: 2.0523554484049478

Epoch: 6| Step: 13
Training loss: 1.3875455856323242
Validation loss: 2.027873714764913

Epoch: 88| Step: 0
Training loss: 1.4179887771606445
Validation loss: 2.074530065059662

Epoch: 6| Step: 1
Training loss: 2.2230656147003174
Validation loss: 2.0264530777931213

Epoch: 6| Step: 2
Training loss: 1.4689158201217651
Validation loss: 2.065748373667399

Epoch: 6| Step: 3
Training loss: 1.3763943910598755
Validation loss: 2.0191162625948587

Epoch: 6| Step: 4
Training loss: 2.062455177307129
Validation loss: 2.0247178276379905

Epoch: 6| Step: 5
Training loss: 1.6426987648010254
Validation loss: 2.083248575528463

Epoch: 6| Step: 6
Training loss: 2.1488895416259766
Validation loss: 2.0379240910212197

Epoch: 6| Step: 7
Training loss: 1.4237782955169678
Validation loss: 2.024838844935099

Epoch: 6| Step: 8
Training loss: 2.229147434234619
Validation loss: 2.0060426394144693

Epoch: 6| Step: 9
Training loss: 1.7513066530227661
Validation loss: 2.003374457359314

Epoch: 6| Step: 10
Training loss: 1.4196012020111084
Validation loss: 2.022237777709961

Epoch: 6| Step: 11
Training loss: 1.506330966949463
Validation loss: 2.0001456141471863

Epoch: 6| Step: 12
Training loss: 1.24301278591156
Validation loss: 1.967113773028056

Epoch: 6| Step: 13
Training loss: 1.553528070449829
Validation loss: 1.9808419148127239

Epoch: 89| Step: 0
Training loss: 1.3733372688293457
Validation loss: 2.0075171192487082

Epoch: 6| Step: 1
Training loss: 1.5690072774887085
Validation loss: 2.010555108388265

Epoch: 6| Step: 2
Training loss: 1.7334049940109253
Validation loss: 2.0342686772346497

Epoch: 6| Step: 3
Training loss: 1.5196539163589478
Validation loss: 2.0264651576677957

Epoch: 6| Step: 4
Training loss: 1.5863767862319946
Validation loss: 2.0329230427742004

Epoch: 6| Step: 5
Training loss: 1.6628448963165283
Validation loss: 2.0254878997802734

Epoch: 6| Step: 6
Training loss: 1.1457316875457764
Validation loss: 2.008155643939972

Epoch: 6| Step: 7
Training loss: 1.084518313407898
Validation loss: 2.043769578138987

Epoch: 6| Step: 8
Training loss: 1.5801602602005005
Validation loss: 2.0471444527308145

Epoch: 6| Step: 9
Training loss: 1.8983349800109863
Validation loss: 2.0689584612846375

Epoch: 6| Step: 10
Training loss: 2.144439458847046
Validation loss: 2.031447649002075

Epoch: 6| Step: 11
Training loss: 2.095712423324585
Validation loss: 2.032619595527649

Epoch: 6| Step: 12
Training loss: 1.5698127746582031
Validation loss: 2.040045917034149

Epoch: 6| Step: 13
Training loss: 2.1443498134613037
Validation loss: 2.0485873421033225

Epoch: 90| Step: 0
Training loss: 1.618983507156372
Validation loss: 2.028781851132711

Epoch: 6| Step: 1
Training loss: 2.482919692993164
Validation loss: 2.0072920521100364

Epoch: 6| Step: 2
Training loss: 1.2772430181503296
Validation loss: 2.028542955716451

Epoch: 6| Step: 3
Training loss: 2.0004115104675293
Validation loss: 2.0272244215011597

Epoch: 6| Step: 4
Training loss: 1.4607501029968262
Validation loss: 1.9874319235483806

Epoch: 6| Step: 5
Training loss: 2.0824337005615234
Validation loss: 2.026287237803141

Epoch: 6| Step: 6
Training loss: 1.964626669883728
Validation loss: 2.037648320198059

Epoch: 6| Step: 7
Training loss: 1.243550181388855
Validation loss: 2.031855344772339

Epoch: 6| Step: 8
Training loss: 1.5064935684204102
Validation loss: 1.991358995437622

Epoch: 6| Step: 9
Training loss: 1.734929084777832
Validation loss: 2.015070100625356

Epoch: 6| Step: 10
Training loss: 1.6710610389709473
Validation loss: 2.0172048807144165

Epoch: 6| Step: 11
Training loss: 1.0771520137786865
Validation loss: 2.003099183241526

Epoch: 6| Step: 12
Training loss: 1.7895288467407227
Validation loss: 2.021566331386566

Epoch: 6| Step: 13
Training loss: 1.3158149719238281
Validation loss: 2.0298713048299155

Epoch: 91| Step: 0
Training loss: 1.218314528465271
Validation loss: 2.0104785760243735

Epoch: 6| Step: 1
Training loss: 1.9743682146072388
Validation loss: 2.0269772013028464

Epoch: 6| Step: 2
Training loss: 2.342839241027832
Validation loss: 2.052641212940216

Epoch: 6| Step: 3
Training loss: 2.173196315765381
Validation loss: 2.020738144715627

Epoch: 6| Step: 4
Training loss: 2.0276541709899902
Validation loss: 2.0193164944648743

Epoch: 6| Step: 5
Training loss: 1.058693289756775
Validation loss: 2.0074228048324585

Epoch: 6| Step: 6
Training loss: 0.9140444397926331
Validation loss: 1.996887981891632

Epoch: 6| Step: 7
Training loss: 1.4772098064422607
Validation loss: 2.0380823214848838

Epoch: 6| Step: 8
Training loss: 1.1183507442474365
Validation loss: 1.9920463562011719

Epoch: 6| Step: 9
Training loss: 1.205955982208252
Validation loss: 2.024997433026632

Epoch: 6| Step: 10
Training loss: 2.3245849609375
Validation loss: 2.0061287681261697

Epoch: 6| Step: 11
Training loss: 1.9747419357299805
Validation loss: 2.0433005889256797

Epoch: 6| Step: 12
Training loss: 1.454092025756836
Validation loss: 1.974332590897878

Epoch: 6| Step: 13
Training loss: 1.6473469734191895
Validation loss: 2.027804513772329

Epoch: 92| Step: 0
Training loss: 1.7413309812545776
Validation loss: 2.0420284271240234

Epoch: 6| Step: 1
Training loss: 1.6833956241607666
Validation loss: 2.050411899884542

Epoch: 6| Step: 2
Training loss: 1.0623326301574707
Validation loss: 1.9847091635068257

Epoch: 6| Step: 3
Training loss: 1.6787171363830566
Validation loss: 1.9587189356486003

Epoch: 6| Step: 4
Training loss: 1.990000605583191
Validation loss: 2.0052230755488076

Epoch: 6| Step: 5
Training loss: 1.5601556301116943
Validation loss: 1.9602404634157817

Epoch: 6| Step: 6
Training loss: 2.356938123703003
Validation loss: 1.9785407781600952

Epoch: 6| Step: 7
Training loss: 1.5279130935668945
Validation loss: 1.9754112362861633

Epoch: 6| Step: 8
Training loss: 1.6366491317749023
Validation loss: 1.986889084180196

Epoch: 6| Step: 9
Training loss: 1.0372411012649536
Validation loss: 1.9935644070307414

Epoch: 6| Step: 10
Training loss: 1.389909267425537
Validation loss: 2.0726401607195535

Epoch: 6| Step: 11
Training loss: 1.5086629390716553
Validation loss: 2.0275805791219077

Epoch: 6| Step: 12
Training loss: 1.9524229764938354
Validation loss: 2.0126494566599527

Epoch: 6| Step: 13
Training loss: 1.8534787893295288
Validation loss: 2.044148008028666

Epoch: 93| Step: 0
Training loss: 1.3481287956237793
Validation loss: 2.0455456177393594

Epoch: 6| Step: 1
Training loss: 1.883724331855774
Validation loss: 2.0272058844566345

Epoch: 6| Step: 2
Training loss: 1.3821423053741455
Validation loss: 2.052242934703827

Epoch: 6| Step: 3
Training loss: 2.0917718410491943
Validation loss: 2.0051767031351724

Epoch: 6| Step: 4
Training loss: 0.6083163022994995
Validation loss: 2.0030373533566794

Epoch: 6| Step: 5
Training loss: 1.3468823432922363
Validation loss: 2.011580844720205

Epoch: 6| Step: 6
Training loss: 1.9614084959030151
Validation loss: 2.012926975886027

Epoch: 6| Step: 7
Training loss: 1.8870431184768677
Validation loss: 2.0003106196721396

Epoch: 6| Step: 8
Training loss: 1.7739098072052002
Validation loss: 1.9792758226394653

Epoch: 6| Step: 9
Training loss: 1.5408540964126587
Validation loss: 2.0024433533350625

Epoch: 6| Step: 10
Training loss: 1.7200002670288086
Validation loss: 2.0038214524586997

Epoch: 6| Step: 11
Training loss: 1.7994710206985474
Validation loss: 2.0014962553977966

Epoch: 6| Step: 12
Training loss: 2.085765838623047
Validation loss: 1.9894327918688457

Epoch: 6| Step: 13
Training loss: 1.4375450611114502
Validation loss: 2.0201846162478128

Epoch: 94| Step: 0
Training loss: 1.103624939918518
Validation loss: 2.010673681894938

Epoch: 6| Step: 1
Training loss: 1.6928263902664185
Validation loss: 1.9911519785722096

Epoch: 6| Step: 2
Training loss: 1.6270383596420288
Validation loss: 2.010871112346649

Epoch: 6| Step: 3
Training loss: 1.380207896232605
Validation loss: 2.027040700117747

Epoch: 6| Step: 4
Training loss: 1.7624331712722778
Validation loss: 2.040129860242208

Epoch: 6| Step: 5
Training loss: 1.4378622770309448
Validation loss: 1.9973896145820618

Epoch: 6| Step: 6
Training loss: 1.5685877799987793
Validation loss: 2.004418055216471

Epoch: 6| Step: 7
Training loss: 1.7516157627105713
Validation loss: 2.028734723726908

Epoch: 6| Step: 8
Training loss: 2.0030720233917236
Validation loss: 2.004164715607961

Epoch: 6| Step: 9
Training loss: 0.9885743260383606
Validation loss: 1.9947903156280518

Epoch: 6| Step: 10
Training loss: 1.0559208393096924
Validation loss: 2.008309086163839

Epoch: 6| Step: 11
Training loss: 1.7054619789123535
Validation loss: 1.9797657132148743

Epoch: 6| Step: 12
Training loss: 2.3931310176849365
Validation loss: 1.9976432919502258

Epoch: 6| Step: 13
Training loss: 1.5986524820327759
Validation loss: 1.9533404111862183

Epoch: 95| Step: 0
Training loss: 1.0796113014221191
Validation loss: 2.0036024848620095

Epoch: 6| Step: 1
Training loss: 1.0419812202453613
Validation loss: 2.0256595412890115

Epoch: 6| Step: 2
Training loss: 1.723932147026062
Validation loss: 2.001322587331136

Epoch: 6| Step: 3
Training loss: 1.5755468606948853
Validation loss: 2.001741131146749

Epoch: 6| Step: 4
Training loss: 1.2061998844146729
Validation loss: 1.9994429349899292

Epoch: 6| Step: 5
Training loss: 1.1406071186065674
Validation loss: 2.022780696551005

Epoch: 6| Step: 6
Training loss: 1.7985275983810425
Validation loss: 2.0194679299990335

Epoch: 6| Step: 7
Training loss: 1.0807486772537231
Validation loss: 1.9995599786440532

Epoch: 6| Step: 8
Training loss: 1.6535043716430664
Validation loss: 2.0364834467569985

Epoch: 6| Step: 9
Training loss: 2.112048864364624
Validation loss: 2.026069680849711

Epoch: 6| Step: 10
Training loss: 1.6952786445617676
Validation loss: 2.022539754708608

Epoch: 6| Step: 11
Training loss: 2.190662145614624
Validation loss: 2.017434279123942

Epoch: 6| Step: 12
Training loss: 1.9292265176773071
Validation loss: 2.029401401678721

Epoch: 6| Step: 13
Training loss: 2.1288700103759766
Validation loss: 1.995080053806305

Epoch: 96| Step: 0
Training loss: 1.1052864789962769
Validation loss: 2.064405918121338

Epoch: 6| Step: 1
Training loss: 1.6754789352416992
Validation loss: 2.0147234002749124

Epoch: 6| Step: 2
Training loss: 1.1923401355743408
Validation loss: 2.0228185455004373

Epoch: 6| Step: 3
Training loss: 1.652073860168457
Validation loss: 1.9780380924542744

Epoch: 6| Step: 4
Training loss: 1.4157757759094238
Validation loss: 1.997890869776408

Epoch: 6| Step: 5
Training loss: 1.4806715250015259
Validation loss: 1.9807800849278767

Epoch: 6| Step: 6
Training loss: 1.0668327808380127
Validation loss: 1.9654256502787273

Epoch: 6| Step: 7
Training loss: 2.2818222045898438
Validation loss: 2.019298791885376

Epoch: 6| Step: 8
Training loss: 2.0047459602355957
Validation loss: 1.9874193867047627

Epoch: 6| Step: 9
Training loss: 1.4570322036743164
Validation loss: 1.9965909123420715

Epoch: 6| Step: 10
Training loss: 1.2984716892242432
Validation loss: 1.9838345448176067

Epoch: 6| Step: 11
Training loss: 1.7199583053588867
Validation loss: 1.97542671362559

Epoch: 6| Step: 12
Training loss: 1.5069842338562012
Validation loss: 1.9914802710215251

Epoch: 6| Step: 13
Training loss: 2.0439562797546387
Validation loss: 1.9785503546396892

Epoch: 97| Step: 0
Training loss: 1.1586647033691406
Validation loss: 1.9997301896413167

Epoch: 6| Step: 1
Training loss: 1.6658985614776611
Validation loss: 2.0260159571965537

Epoch: 6| Step: 2
Training loss: 1.9606916904449463
Validation loss: 1.9755280415217082

Epoch: 6| Step: 3
Training loss: 1.8300520181655884
Validation loss: 2.0076776345570884

Epoch: 6| Step: 4
Training loss: 1.7675515413284302
Validation loss: 1.9918161829312642

Epoch: 6| Step: 5
Training loss: 1.7055108547210693
Validation loss: 1.9854886929194133

Epoch: 6| Step: 6
Training loss: 1.380878210067749
Validation loss: 2.021756907304128

Epoch: 6| Step: 7
Training loss: 1.283637285232544
Validation loss: 1.9949132800102234

Epoch: 6| Step: 8
Training loss: 2.0668883323669434
Validation loss: 2.015703499317169

Epoch: 6| Step: 9
Training loss: 1.658326268196106
Validation loss: 1.9903982877731323

Epoch: 6| Step: 10
Training loss: 1.0077253580093384
Validation loss: 1.997778018315633

Epoch: 6| Step: 11
Training loss: 1.9838522672653198
Validation loss: 1.997538407643636

Epoch: 6| Step: 12
Training loss: 0.9501371383666992
Validation loss: 1.9960952599843342

Epoch: 6| Step: 13
Training loss: 1.829402208328247
Validation loss: 1.9786564509073894

Epoch: 98| Step: 0
Training loss: 1.1004257202148438
Validation loss: 1.9824111262957256

Epoch: 6| Step: 1
Training loss: 1.962518572807312
Validation loss: 1.9732942183812459

Epoch: 6| Step: 2
Training loss: 1.68391752243042
Validation loss: 1.958582838376363

Epoch: 6| Step: 3
Training loss: 1.8036680221557617
Validation loss: 1.973262886206309

Epoch: 6| Step: 4
Training loss: 1.8290220499038696
Validation loss: 1.9870775540669758

Epoch: 6| Step: 5
Training loss: 0.633694052696228
Validation loss: 1.9830358425776164

Epoch: 6| Step: 6
Training loss: 1.593266487121582
Validation loss: 1.9896303415298462

Epoch: 6| Step: 7
Training loss: 1.7117066383361816
Validation loss: 1.9652542074521382

Epoch: 6| Step: 8
Training loss: 2.2823991775512695
Validation loss: 1.9906434814135234

Epoch: 6| Step: 9
Training loss: 1.3764575719833374
Validation loss: 2.03741862376531

Epoch: 6| Step: 10
Training loss: 1.752411127090454
Validation loss: 2.0084070563316345

Epoch: 6| Step: 11
Training loss: 0.8998318910598755
Validation loss: 2.0327828923861184

Epoch: 6| Step: 12
Training loss: 1.5935947895050049
Validation loss: 2.0239105423291526

Epoch: 6| Step: 13
Training loss: 1.3932511806488037
Validation loss: 2.022086501121521

Epoch: 99| Step: 0
Training loss: 1.5990800857543945
Validation loss: 2.0132456024487815

Epoch: 6| Step: 1
Training loss: 1.55800461769104
Validation loss: 2.02016814549764

Epoch: 6| Step: 2
Training loss: 1.2088491916656494
Validation loss: 2.025292992591858

Epoch: 6| Step: 3
Training loss: 1.5660665035247803
Validation loss: 1.9993676741917927

Epoch: 6| Step: 4
Training loss: 2.0803258419036865
Validation loss: 2.0194863080978394

Epoch: 6| Step: 5
Training loss: 1.9727381467819214
Validation loss: 1.9923419952392578

Epoch: 6| Step: 6
Training loss: 1.5316832065582275
Validation loss: 1.9954057534535725

Epoch: 6| Step: 7
Training loss: 2.03544545173645
Validation loss: 2.0191261370976767

Epoch: 6| Step: 8
Training loss: 1.3936824798583984
Validation loss: 1.9728184342384338

Epoch: 6| Step: 9
Training loss: 1.4080328941345215
Validation loss: 2.003081758817037

Epoch: 6| Step: 10
Training loss: 1.3586441278457642
Validation loss: 1.9857827027638753

Epoch: 6| Step: 11
Training loss: 1.1070127487182617
Validation loss: 1.9606773257255554

Epoch: 6| Step: 12
Training loss: 1.3186744451522827
Validation loss: 1.9818713863690693

Epoch: 6| Step: 13
Training loss: 1.5783839225769043
Validation loss: 1.9705322980880737

Epoch: 100| Step: 0
Training loss: 1.8987767696380615
Validation loss: 1.9958710273106892

Epoch: 6| Step: 1
Training loss: 2.4540507793426514
Validation loss: 1.9900751908620198

Epoch: 6| Step: 2
Training loss: 1.1287040710449219
Validation loss: 2.045850376288096

Epoch: 6| Step: 3
Training loss: 1.280434250831604
Validation loss: 2.0154612263043723

Epoch: 6| Step: 4
Training loss: 1.0957025289535522
Validation loss: 2.0020331144332886

Epoch: 6| Step: 5
Training loss: 1.0164977312088013
Validation loss: 2.0426175395647683

Epoch: 6| Step: 6
Training loss: 1.272892713546753
Validation loss: 2.0240564942359924

Epoch: 6| Step: 7
Training loss: 2.003700017929077
Validation loss: 1.9921191732088726

Epoch: 6| Step: 8
Training loss: 1.3159581422805786
Validation loss: 2.0206364393234253

Epoch: 6| Step: 9
Training loss: 1.5205620527267456
Validation loss: 1.9719762007395427

Epoch: 6| Step: 10
Training loss: 1.7862194776535034
Validation loss: 1.9908912579218547

Epoch: 6| Step: 11
Training loss: 1.470010757446289
Validation loss: 1.9619486133257549

Epoch: 6| Step: 12
Training loss: 1.3067104816436768
Validation loss: 1.9591015378634136

Epoch: 6| Step: 13
Training loss: 2.061798572540283
Validation loss: 2.0036189556121826

Epoch: 101| Step: 0
Training loss: 1.6367249488830566
Validation loss: 1.9810839295387268

Epoch: 6| Step: 1
Training loss: 1.0462045669555664
Validation loss: 2.007351259390513

Epoch: 6| Step: 2
Training loss: 1.638541340827942
Validation loss: 1.9638544917106628

Epoch: 6| Step: 3
Training loss: 1.5488990545272827
Validation loss: 1.971072753270467

Epoch: 6| Step: 4
Training loss: 1.8230226039886475
Validation loss: 2.0254025061925254

Epoch: 6| Step: 5
Training loss: 1.3070268630981445
Validation loss: 2.0216854413350425

Epoch: 6| Step: 6
Training loss: 1.7918496131896973
Validation loss: 2.030432164669037

Epoch: 6| Step: 7
Training loss: 1.5205373764038086
Validation loss: 2.005703091621399

Epoch: 6| Step: 8
Training loss: 1.4847187995910645
Validation loss: 2.0056285858154297

Epoch: 6| Step: 9
Training loss: 1.1456727981567383
Validation loss: 2.0366325775782266

Epoch: 6| Step: 10
Training loss: 2.1002655029296875
Validation loss: 1.9853997031847637

Epoch: 6| Step: 11
Training loss: 1.2453523874282837
Validation loss: 1.9559959570566814

Epoch: 6| Step: 12
Training loss: 1.2750529050827026
Validation loss: 1.9753763874371846

Epoch: 6| Step: 13
Training loss: 1.7412841320037842
Validation loss: 1.9752926031748455

Epoch: 102| Step: 0
Training loss: 1.6804794073104858
Validation loss: 1.9688899119695027

Epoch: 6| Step: 1
Training loss: 1.424486517906189
Validation loss: 1.9878392616907756

Epoch: 6| Step: 2
Training loss: 2.0006375312805176
Validation loss: 1.9822561542193096

Epoch: 6| Step: 3
Training loss: 1.2765988111495972
Validation loss: 1.9879371722539265

Epoch: 6| Step: 4
Training loss: 1.6261980533599854
Validation loss: 1.996665318806966

Epoch: 6| Step: 5
Training loss: 1.5403530597686768
Validation loss: 2.0174856384595237

Epoch: 6| Step: 6
Training loss: 1.3491542339324951
Validation loss: 2.0367301305135093

Epoch: 6| Step: 7
Training loss: 1.1328678131103516
Validation loss: 2.007147490978241

Epoch: 6| Step: 8
Training loss: 2.0115771293640137
Validation loss: 2.0374481876691184

Epoch: 6| Step: 9
Training loss: 1.3543236255645752
Validation loss: 2.000314990679423

Epoch: 6| Step: 10
Training loss: 1.1173927783966064
Validation loss: 1.9829125205675762

Epoch: 6| Step: 11
Training loss: 1.2705867290496826
Validation loss: 1.99673193693161

Epoch: 6| Step: 12
Training loss: 1.7235133647918701
Validation loss: 1.980482319990794

Epoch: 6| Step: 13
Training loss: 1.523844599723816
Validation loss: 1.989743133385976

Epoch: 103| Step: 0
Training loss: 1.4768261909484863
Validation loss: 1.9754924376805623

Epoch: 6| Step: 1
Training loss: 1.3845829963684082
Validation loss: 2.002130369345347

Epoch: 6| Step: 2
Training loss: 1.7846349477767944
Validation loss: 1.994987666606903

Epoch: 6| Step: 3
Training loss: 1.6783901453018188
Validation loss: 2.0063628355662027

Epoch: 6| Step: 4
Training loss: 1.8357274532318115
Validation loss: 2.0011481046676636

Epoch: 6| Step: 5
Training loss: 1.4029033184051514
Validation loss: 1.9847230315208435

Epoch: 6| Step: 6
Training loss: 1.7014756202697754
Validation loss: 1.9823840061823528

Epoch: 6| Step: 7
Training loss: 1.5867420434951782
Validation loss: 1.9818246165911357

Epoch: 6| Step: 8
Training loss: 1.6900358200073242
Validation loss: 1.982446312904358

Epoch: 6| Step: 9
Training loss: 0.7175766825675964
Validation loss: 1.9898457129796345

Epoch: 6| Step: 10
Training loss: 2.1352500915527344
Validation loss: 1.9694841305414836

Epoch: 6| Step: 11
Training loss: 1.8610796928405762
Validation loss: 1.9675671458244324

Epoch: 6| Step: 12
Training loss: 1.4795562028884888
Validation loss: 1.9893064896265666

Epoch: 6| Step: 13
Training loss: 0.8555186986923218
Validation loss: 2.0492045879364014

Epoch: 104| Step: 0
Training loss: 2.0870916843414307
Validation loss: 2.015755772590637

Epoch: 6| Step: 1
Training loss: 1.586521863937378
Validation loss: 1.9988620678583782

Epoch: 6| Step: 2
Training loss: 1.2976083755493164
Validation loss: 1.9824274977048237

Epoch: 6| Step: 3
Training loss: 1.4671961069107056
Validation loss: 1.9790792266527812

Epoch: 6| Step: 4
Training loss: 0.8572300672531128
Validation loss: 1.9586749076843262

Epoch: 6| Step: 5
Training loss: 1.5446105003356934
Validation loss: 1.981745719909668

Epoch: 6| Step: 6
Training loss: 1.159254550933838
Validation loss: 1.9518076181411743

Epoch: 6| Step: 7
Training loss: 1.2485601902008057
Validation loss: 1.9889544248580933

Epoch: 6| Step: 8
Training loss: 1.5343124866485596
Validation loss: 1.9850338300069172

Epoch: 6| Step: 9
Training loss: 1.6701273918151855
Validation loss: 1.98582528034846

Epoch: 6| Step: 10
Training loss: 1.5626649856567383
Validation loss: 1.9388383229573567

Epoch: 6| Step: 11
Training loss: 1.548722743988037
Validation loss: 1.984907607237498

Epoch: 6| Step: 12
Training loss: 1.8416938781738281
Validation loss: 1.9819095929463704

Epoch: 6| Step: 13
Training loss: 1.1286674737930298
Validation loss: 1.941537578900655

Epoch: 105| Step: 0
Training loss: 2.070432662963867
Validation loss: 2.027290085951487

Epoch: 6| Step: 1
Training loss: 1.470334768295288
Validation loss: 2.021975894769033

Epoch: 6| Step: 2
Training loss: 2.0566563606262207
Validation loss: 2.0155606865882874

Epoch: 6| Step: 3
Training loss: 1.5150120258331299
Validation loss: 2.0645799239476523

Epoch: 6| Step: 4
Training loss: 1.3608232736587524
Validation loss: 2.0362117290496826

Epoch: 6| Step: 5
Training loss: 1.1667609214782715
Validation loss: 2.0244632363319397

Epoch: 6| Step: 6
Training loss: 1.519313097000122
Validation loss: 1.9503133098284404

Epoch: 6| Step: 7
Training loss: 1.5833759307861328
Validation loss: 2.0154360930124917

Epoch: 6| Step: 8
Training loss: 1.4884940385818481
Validation loss: 1.9556358257929485

Epoch: 6| Step: 9
Training loss: 1.6012628078460693
Validation loss: 1.9562226335207622

Epoch: 6| Step: 10
Training loss: 0.970094621181488
Validation loss: 1.9819323619206746

Epoch: 6| Step: 11
Training loss: 1.1914993524551392
Validation loss: 2.0012153784434

Epoch: 6| Step: 12
Training loss: 1.5385115146636963
Validation loss: 1.9715516765912373

Epoch: 6| Step: 13
Training loss: 1.5538370609283447
Validation loss: 2.030378500620524

Epoch: 106| Step: 0
Training loss: 1.826768159866333
Validation loss: 2.0342931151390076

Epoch: 6| Step: 1
Training loss: 0.7642935514450073
Validation loss: 2.017431159814199

Epoch: 6| Step: 2
Training loss: 1.6334929466247559
Validation loss: 1.9904572367668152

Epoch: 6| Step: 3
Training loss: 1.1029367446899414
Validation loss: 1.9790445566177368

Epoch: 6| Step: 4
Training loss: 1.3141435384750366
Validation loss: 2.0039310654004416

Epoch: 6| Step: 5
Training loss: 1.9102294445037842
Validation loss: 2.0083417097727456

Epoch: 6| Step: 6
Training loss: 1.1091293096542358
Validation loss: 1.9620646834373474

Epoch: 6| Step: 7
Training loss: 1.7757501602172852
Validation loss: 1.9891768892606099

Epoch: 6| Step: 8
Training loss: 1.6364701986312866
Validation loss: 1.9711108406384785

Epoch: 6| Step: 9
Training loss: 1.40731942653656
Validation loss: 1.996832251548767

Epoch: 6| Step: 10
Training loss: 1.383086919784546
Validation loss: 1.9757805864016216

Epoch: 6| Step: 11
Training loss: 1.345438003540039
Validation loss: 1.9936290582021077

Epoch: 6| Step: 12
Training loss: 1.555742859840393
Validation loss: 2.013498584429423

Epoch: 6| Step: 13
Training loss: 1.324249505996704
Validation loss: 1.9619438846906025

Epoch: 107| Step: 0
Training loss: 1.3159339427947998
Validation loss: 1.9961847066879272

Epoch: 6| Step: 1
Training loss: 1.616623044013977
Validation loss: 2.0142712195714316

Epoch: 6| Step: 2
Training loss: 1.4689180850982666
Validation loss: 2.010719080766042

Epoch: 6| Step: 3
Training loss: 1.677544355392456
Validation loss: 2.0284372766812644

Epoch: 6| Step: 4
Training loss: 1.3485217094421387
Validation loss: 2.0436927477518716

Epoch: 6| Step: 5
Training loss: 1.597617745399475
Validation loss: 2.015954375267029

Epoch: 6| Step: 6
Training loss: 2.1167922019958496
Validation loss: 2.017880837122599

Epoch: 6| Step: 7
Training loss: 1.1948580741882324
Validation loss: 2.015048325061798

Epoch: 6| Step: 8
Training loss: 1.274708867073059
Validation loss: 2.01275634765625

Epoch: 6| Step: 9
Training loss: 1.4157201051712036
Validation loss: 2.0018564065297446

Epoch: 6| Step: 10
Training loss: 1.308137059211731
Validation loss: 1.9724137783050537

Epoch: 6| Step: 11
Training loss: 1.4507842063903809
Validation loss: 2.0330658753712973

Epoch: 6| Step: 12
Training loss: 1.1122651100158691
Validation loss: 1.9891858498255413

Epoch: 6| Step: 13
Training loss: 1.464046835899353
Validation loss: 2.0135639111200967

Epoch: 108| Step: 0
Training loss: 1.3266551494598389
Validation loss: 1.9723910291989644

Epoch: 6| Step: 1
Training loss: 0.9833860397338867
Validation loss: 1.9764596819877625

Epoch: 6| Step: 2
Training loss: 1.218932032585144
Validation loss: 1.9645917415618896

Epoch: 6| Step: 3
Training loss: 1.315721035003662
Validation loss: 2.0233380794525146

Epoch: 6| Step: 4
Training loss: 2.1973981857299805
Validation loss: 2.0067065159479776

Epoch: 6| Step: 5
Training loss: 1.6278955936431885
Validation loss: 2.004500170548757

Epoch: 6| Step: 6
Training loss: 1.3819143772125244
Validation loss: 2.023777663707733

Epoch: 6| Step: 7
Training loss: 1.3199245929718018
Validation loss: 1.9606865445772808

Epoch: 6| Step: 8
Training loss: 1.2499333620071411
Validation loss: 1.9793369968732197

Epoch: 6| Step: 9
Training loss: 1.3754626512527466
Validation loss: 1.963250954945882

Epoch: 6| Step: 10
Training loss: 1.696486473083496
Validation loss: 1.9890243212382

Epoch: 6| Step: 11
Training loss: 1.5409897565841675
Validation loss: 1.9732196132342021

Epoch: 6| Step: 12
Training loss: 2.030425548553467
Validation loss: 1.971720556418101

Epoch: 6| Step: 13
Training loss: 1.7399592399597168
Validation loss: 1.9916993180910747

Epoch: 109| Step: 0
Training loss: 1.1353750228881836
Validation loss: 2.029897371927897

Epoch: 6| Step: 1
Training loss: 1.321281909942627
Validation loss: 1.9842843810717266

Epoch: 6| Step: 2
Training loss: 1.3390556573867798
Validation loss: 1.9700875878334045

Epoch: 6| Step: 3
Training loss: 1.3191877603530884
Validation loss: 1.9961832364400227

Epoch: 6| Step: 4
Training loss: 1.5089131593704224
Validation loss: 1.9982610543568928

Epoch: 6| Step: 5
Training loss: 1.5199228525161743
Validation loss: 1.9658348560333252

Epoch: 6| Step: 6
Training loss: 1.4909911155700684
Validation loss: 1.9740583499272664

Epoch: 6| Step: 7
Training loss: 1.1655869483947754
Validation loss: 1.9686423738797505

Epoch: 6| Step: 8
Training loss: 1.6525191068649292
Validation loss: 1.9474146962165833

Epoch: 6| Step: 9
Training loss: 1.9631249904632568
Validation loss: 1.96407550573349

Epoch: 6| Step: 10
Training loss: 1.5479094982147217
Validation loss: 1.9829503695170085

Epoch: 6| Step: 11
Training loss: 1.1916158199310303
Validation loss: 2.0006160537401834

Epoch: 6| Step: 12
Training loss: 1.3458589315414429
Validation loss: 1.9715208212534587

Epoch: 6| Step: 13
Training loss: 1.3400499820709229
Validation loss: 1.9769291877746582

Epoch: 110| Step: 0
Training loss: 0.9824950695037842
Validation loss: 1.9760107398033142

Epoch: 6| Step: 1
Training loss: 1.4402351379394531
Validation loss: 2.0007864435513816

Epoch: 6| Step: 2
Training loss: 1.1965864896774292
Validation loss: 2.0038952430089316

Epoch: 6| Step: 3
Training loss: 1.4274530410766602
Validation loss: 1.965502659479777

Epoch: 6| Step: 4
Training loss: 1.3864918947219849
Validation loss: 2.0154167215029397

Epoch: 6| Step: 5
Training loss: 1.2291874885559082
Validation loss: 1.958292285601298

Epoch: 6| Step: 6
Training loss: 0.7480589151382446
Validation loss: 2.0245863993962607

Epoch: 6| Step: 7
Training loss: 1.6754226684570312
Validation loss: 1.9908444086710613

Epoch: 6| Step: 8
Training loss: 2.057692050933838
Validation loss: 1.9716679851214092

Epoch: 6| Step: 9
Training loss: 1.6053916215896606
Validation loss: 1.9522557059923809

Epoch: 6| Step: 10
Training loss: 1.4060964584350586
Validation loss: 1.9668326775232952

Epoch: 6| Step: 11
Training loss: 1.5491280555725098
Validation loss: 1.9844664732615154

Epoch: 6| Step: 12
Training loss: 1.6319139003753662
Validation loss: 1.9630744457244873

Epoch: 6| Step: 13
Training loss: 1.4355800151824951
Validation loss: 1.9727230668067932

Epoch: 111| Step: 0
Training loss: 1.9182000160217285
Validation loss: 1.971011181672414

Epoch: 6| Step: 1
Training loss: 1.0768828392028809
Validation loss: 1.962053120136261

Epoch: 6| Step: 2
Training loss: 1.1932231187820435
Validation loss: 1.9683365225791931

Epoch: 6| Step: 3
Training loss: 1.081648826599121
Validation loss: 1.9797186652819316

Epoch: 6| Step: 4
Training loss: 1.7250040769577026
Validation loss: 1.9817791978518169

Epoch: 6| Step: 5
Training loss: 1.4314348697662354
Validation loss: 1.9720917741457622

Epoch: 6| Step: 6
Training loss: 1.2060798406600952
Validation loss: 1.9771912296613057

Epoch: 6| Step: 7
Training loss: 1.2387566566467285
Validation loss: 1.982453982035319

Epoch: 6| Step: 8
Training loss: 1.8273718357086182
Validation loss: 1.9887224435806274

Epoch: 6| Step: 9
Training loss: 1.287616491317749
Validation loss: 1.9681763052940369

Epoch: 6| Step: 10
Training loss: 1.5302202701568604
Validation loss: 2.020619531472524

Epoch: 6| Step: 11
Training loss: 1.3334654569625854
Validation loss: 1.97093000014623

Epoch: 6| Step: 12
Training loss: 0.8594340085983276
Validation loss: 1.9521557490030925

Epoch: 6| Step: 13
Training loss: 1.4432908296585083
Validation loss: 1.976346492767334

Epoch: 112| Step: 0
Training loss: 1.329817295074463
Validation loss: 1.8999765018622081

Epoch: 6| Step: 1
Training loss: 1.212076187133789
Validation loss: 1.9820686380068462

Epoch: 6| Step: 2
Training loss: 1.9707380533218384
Validation loss: 1.955599069595337

Epoch: 6| Step: 3
Training loss: 0.7726610898971558
Validation loss: 1.965027908484141

Epoch: 6| Step: 4
Training loss: 1.4061797857284546
Validation loss: 1.9903473059336345

Epoch: 6| Step: 5
Training loss: 1.4588229656219482
Validation loss: 1.9847680926322937

Epoch: 6| Step: 6
Training loss: 0.9219394326210022
Validation loss: 1.9817038377126057

Epoch: 6| Step: 7
Training loss: 1.8434406518936157
Validation loss: 1.9816174109776814

Epoch: 6| Step: 8
Training loss: 1.6761763095855713
Validation loss: 2.020841896533966

Epoch: 6| Step: 9
Training loss: 1.2541841268539429
Validation loss: 1.9926813840866089

Epoch: 6| Step: 10
Training loss: 1.6201694011688232
Validation loss: 1.971363604068756

Epoch: 6| Step: 11
Training loss: 1.0993624925613403
Validation loss: 1.941555102666219

Epoch: 6| Step: 12
Training loss: 1.3343586921691895
Validation loss: 1.9636840025583904

Epoch: 6| Step: 13
Training loss: 1.1729999780654907
Validation loss: 1.9643319447835286

Epoch: 113| Step: 0
Training loss: 2.2398009300231934
Validation loss: 1.9578812917073567

Epoch: 6| Step: 1
Training loss: 1.4323643445968628
Validation loss: 1.9625461101531982

Epoch: 6| Step: 2
Training loss: 1.197746753692627
Validation loss: 1.938338041305542

Epoch: 6| Step: 3
Training loss: 1.042470932006836
Validation loss: 1.996286670366923

Epoch: 6| Step: 4
Training loss: 1.406322717666626
Validation loss: 1.9692683219909668

Epoch: 6| Step: 5
Training loss: 1.5932128429412842
Validation loss: 1.9632087349891663

Epoch: 6| Step: 6
Training loss: 1.4214961528778076
Validation loss: 1.990903874238332

Epoch: 6| Step: 7
Training loss: 0.9826452732086182
Validation loss: 1.9043283462524414

Epoch: 6| Step: 8
Training loss: 1.30156409740448
Validation loss: 1.9819931586583455

Epoch: 6| Step: 9
Training loss: 0.865351676940918
Validation loss: 1.9516350229581196

Epoch: 6| Step: 10
Training loss: 1.4228758811950684
Validation loss: 1.9857221643129985

Epoch: 6| Step: 11
Training loss: 1.576413631439209
Validation loss: 1.9713493585586548

Epoch: 6| Step: 12
Training loss: 1.560530662536621
Validation loss: 2.007976452509562

Epoch: 6| Step: 13
Training loss: 1.0065820217132568
Validation loss: 1.9929004708925884

Epoch: 114| Step: 0
Training loss: 1.7871623039245605
Validation loss: 2.0283239483833313

Epoch: 6| Step: 1
Training loss: 1.5478157997131348
Validation loss: 2.002613087495168

Epoch: 6| Step: 2
Training loss: 1.8430241346359253
Validation loss: 1.9917401472727458

Epoch: 6| Step: 3
Training loss: 1.093597650527954
Validation loss: 2.0331068634986877

Epoch: 6| Step: 4
Training loss: 1.057045340538025
Validation loss: 1.9760899941126506

Epoch: 6| Step: 5
Training loss: 0.7055076956748962
Validation loss: 1.994459589322408

Epoch: 6| Step: 6
Training loss: 1.4112279415130615
Validation loss: 1.9792559544245403

Epoch: 6| Step: 7
Training loss: 0.886948823928833
Validation loss: 1.9515937964121501

Epoch: 6| Step: 8
Training loss: 1.6726629734039307
Validation loss: 1.9821909467379253

Epoch: 6| Step: 9
Training loss: 1.1882212162017822
Validation loss: 1.9792169729868572

Epoch: 6| Step: 10
Training loss: 1.221914529800415
Validation loss: 2.0105676651000977

Epoch: 6| Step: 11
Training loss: 1.4631645679473877
Validation loss: 2.008745531241099

Epoch: 6| Step: 12
Training loss: 1.2853362560272217
Validation loss: 1.9234585364659627

Epoch: 6| Step: 13
Training loss: 1.416992425918579
Validation loss: 1.9768543442090352

Epoch: 115| Step: 0
Training loss: 1.654503583908081
Validation loss: 1.984560211499532

Epoch: 6| Step: 1
Training loss: 1.1492104530334473
Validation loss: 1.9536134998003643

Epoch: 6| Step: 2
Training loss: 1.0014498233795166
Validation loss: 1.9762904644012451

Epoch: 6| Step: 3
Training loss: 1.3279770612716675
Validation loss: 1.9700620571772258

Epoch: 6| Step: 4
Training loss: 1.8522496223449707
Validation loss: 1.998707155386607

Epoch: 6| Step: 5
Training loss: 1.4196772575378418
Validation loss: 1.9570041298866272

Epoch: 6| Step: 6
Training loss: 0.829954206943512
Validation loss: 1.9890148838361104

Epoch: 6| Step: 7
Training loss: 1.6259512901306152
Validation loss: 1.9725297689437866

Epoch: 6| Step: 8
Training loss: 1.4393781423568726
Validation loss: 1.9659891724586487

Epoch: 6| Step: 9
Training loss: 1.2282750606536865
Validation loss: 1.9668340881665547

Epoch: 6| Step: 10
Training loss: 1.6054110527038574
Validation loss: 1.9495402971903484

Epoch: 6| Step: 11
Training loss: 1.0055208206176758
Validation loss: 1.9395830829938252

Epoch: 6| Step: 12
Training loss: 1.0908267498016357
Validation loss: 1.9678290685017903

Epoch: 6| Step: 13
Training loss: 1.4408040046691895
Validation loss: 1.981094479560852

Epoch: 116| Step: 0
Training loss: 1.3420220613479614
Validation loss: 1.969694435596466

Epoch: 6| Step: 1
Training loss: 1.568102478981018
Validation loss: 1.9850658774375916

Epoch: 6| Step: 2
Training loss: 1.3344169855117798
Validation loss: 1.99655685822169

Epoch: 6| Step: 3
Training loss: 1.1824448108673096
Validation loss: 1.95963188012441

Epoch: 6| Step: 4
Training loss: 0.5473431944847107
Validation loss: 1.9923683802286785

Epoch: 6| Step: 5
Training loss: 0.9682682156562805
Validation loss: 1.9727592865626018

Epoch: 6| Step: 6
Training loss: 1.1631228923797607
Validation loss: 1.9944423635800679

Epoch: 6| Step: 7
Training loss: 1.5185308456420898
Validation loss: 1.9684833884239197

Epoch: 6| Step: 8
Training loss: 1.3864407539367676
Validation loss: 1.9578057328859966

Epoch: 6| Step: 9
Training loss: 1.3748054504394531
Validation loss: 2.020259896914164

Epoch: 6| Step: 10
Training loss: 1.918336272239685
Validation loss: 1.9888062278429668

Epoch: 6| Step: 11
Training loss: 1.4372066259384155
Validation loss: 1.94546240568161

Epoch: 6| Step: 12
Training loss: 1.0804119110107422
Validation loss: 1.974008560180664

Epoch: 6| Step: 13
Training loss: 1.5542800426483154
Validation loss: 1.9586780865987141

Epoch: 117| Step: 0
Training loss: 1.013149619102478
Validation loss: 1.9450006286303203

Epoch: 6| Step: 1
Training loss: 1.1735174655914307
Validation loss: 1.9653985500335693

Epoch: 6| Step: 2
Training loss: 1.6401653289794922
Validation loss: 1.948443333307902

Epoch: 6| Step: 3
Training loss: 1.4056066274642944
Validation loss: 1.9903260270754497

Epoch: 6| Step: 4
Training loss: 0.9797888398170471
Validation loss: 1.9798058867454529

Epoch: 6| Step: 5
Training loss: 1.863753080368042
Validation loss: 1.97646959622701

Epoch: 6| Step: 6
Training loss: 1.3453648090362549
Validation loss: 1.9991299907366435

Epoch: 6| Step: 7
Training loss: 1.6576688289642334
Validation loss: 1.986997902393341

Epoch: 6| Step: 8
Training loss: 1.5662760734558105
Validation loss: 2.0246515472730002

Epoch: 6| Step: 9
Training loss: 1.2823482751846313
Validation loss: 2.0339395006497702

Epoch: 6| Step: 10
Training loss: 1.2086453437805176
Validation loss: 2.0395893653233848

Epoch: 6| Step: 11
Training loss: 0.9569276571273804
Validation loss: 2.04408198595047

Epoch: 6| Step: 12
Training loss: 1.465125560760498
Validation loss: 2.026322285334269

Epoch: 6| Step: 13
Training loss: 0.9881604909896851
Validation loss: 1.9254969954490662

Epoch: 118| Step: 0
Training loss: 1.067323923110962
Validation loss: 1.9504376848538716

Epoch: 6| Step: 1
Training loss: 1.104680061340332
Validation loss: 1.9528939127922058

Epoch: 6| Step: 2
Training loss: 1.0931464433670044
Validation loss: 1.9748408198356628

Epoch: 6| Step: 3
Training loss: 1.3658084869384766
Validation loss: 1.9969181418418884

Epoch: 6| Step: 4
Training loss: 1.398716926574707
Validation loss: 1.9645093480745952

Epoch: 6| Step: 5
Training loss: 2.3951454162597656
Validation loss: 1.9612538417180378

Epoch: 6| Step: 6
Training loss: 1.4879449605941772
Validation loss: 1.9815643231074016

Epoch: 6| Step: 7
Training loss: 0.991851806640625
Validation loss: 1.9269513885180156

Epoch: 6| Step: 8
Training loss: 1.1073787212371826
Validation loss: 1.9357963999112446

Epoch: 6| Step: 9
Training loss: 1.3944625854492188
Validation loss: 1.993331531683604

Epoch: 6| Step: 10
Training loss: 0.7981711626052856
Validation loss: 1.9712371031443279

Epoch: 6| Step: 11
Training loss: 0.3552590012550354
Validation loss: 1.968630572160085

Epoch: 6| Step: 12
Training loss: 1.2998453378677368
Validation loss: 2.000337858994802

Epoch: 6| Step: 13
Training loss: 1.9835801124572754
Validation loss: 1.9963069558143616

Epoch: 119| Step: 0
Training loss: 1.4250835180282593
Validation loss: 1.9553942879041035

Epoch: 6| Step: 1
Training loss: 0.888595700263977
Validation loss: 1.9952544768651326

Epoch: 6| Step: 2
Training loss: 1.4759708642959595
Validation loss: 2.002194325129191

Epoch: 6| Step: 3
Training loss: 1.1118857860565186
Validation loss: 1.9634737769762676

Epoch: 6| Step: 4
Training loss: 1.3313062191009521
Validation loss: 1.9863729079564412

Epoch: 6| Step: 5
Training loss: 0.8372880220413208
Validation loss: 1.9705851276715596

Epoch: 6| Step: 6
Training loss: 1.4739811420440674
Validation loss: 1.9639522631963093

Epoch: 6| Step: 7
Training loss: 1.1418547630310059
Validation loss: 1.9579360882441204

Epoch: 6| Step: 8
Training loss: 1.5653579235076904
Validation loss: 1.9800650080045064

Epoch: 6| Step: 9
Training loss: 1.2103266716003418
Validation loss: 2.003168225288391

Epoch: 6| Step: 10
Training loss: 0.8837525248527527
Validation loss: 2.0164414644241333

Epoch: 6| Step: 11
Training loss: 1.306362271308899
Validation loss: 2.015133718649546

Epoch: 6| Step: 12
Training loss: 2.4287400245666504
Validation loss: 2.028655151526133

Epoch: 6| Step: 13
Training loss: 1.3570759296417236
Validation loss: 1.9790804783503215

Epoch: 120| Step: 0
Training loss: 1.6611422300338745
Validation loss: 1.951609194278717

Epoch: 6| Step: 1
Training loss: 1.1731414794921875
Validation loss: 1.9517568945884705

Epoch: 6| Step: 2
Training loss: 0.9877550601959229
Validation loss: 1.991423745950063

Epoch: 6| Step: 3
Training loss: 0.7453999519348145
Validation loss: 1.952938934167226

Epoch: 6| Step: 4
Training loss: 1.3059954643249512
Validation loss: 1.936329424381256

Epoch: 6| Step: 5
Training loss: 1.3499921560287476
Validation loss: 1.924649755160014

Epoch: 6| Step: 6
Training loss: 0.9789221882820129
Validation loss: 1.9521791736284893

Epoch: 6| Step: 7
Training loss: 1.2016839981079102
Validation loss: 1.9201066493988037

Epoch: 6| Step: 8
Training loss: 1.5537465810775757
Validation loss: 2.0051307876904807

Epoch: 6| Step: 9
Training loss: 1.6315314769744873
Validation loss: 1.953511377175649

Epoch: 6| Step: 10
Training loss: 1.2742586135864258
Validation loss: 1.9478285908699036

Epoch: 6| Step: 11
Training loss: 0.9712766408920288
Validation loss: 1.9440060655275981

Epoch: 6| Step: 12
Training loss: 0.9382302761077881
Validation loss: 1.963257650534312

Epoch: 6| Step: 13
Training loss: 1.6491209268569946
Validation loss: 1.949638565381368

Epoch: 121| Step: 0
Training loss: 1.4250764846801758
Validation loss: 1.937101682027181

Epoch: 6| Step: 1
Training loss: 1.5694373846054077
Validation loss: 1.9636485576629639

Epoch: 6| Step: 2
Training loss: 0.8415168523788452
Validation loss: 1.9192777872085571

Epoch: 6| Step: 3
Training loss: 0.8556649684906006
Validation loss: 2.007835566997528

Epoch: 6| Step: 4
Training loss: 0.9384900331497192
Validation loss: 1.9593387643496196

Epoch: 6| Step: 5
Training loss: 1.5136783123016357
Validation loss: 1.9288653333981831

Epoch: 6| Step: 6
Training loss: 0.7142659425735474
Validation loss: 1.9622913599014282

Epoch: 6| Step: 7
Training loss: 1.5079861879348755
Validation loss: 1.9780227343241374

Epoch: 6| Step: 8
Training loss: 1.7521671056747437
Validation loss: 1.9447964827219646

Epoch: 6| Step: 9
Training loss: 1.092605710029602
Validation loss: 1.944464902083079

Epoch: 6| Step: 10
Training loss: 1.3223470449447632
Validation loss: 1.9510100682576497

Epoch: 6| Step: 11
Training loss: 1.1810753345489502
Validation loss: 1.9699198206265767

Epoch: 6| Step: 12
Training loss: 0.7631980776786804
Validation loss: 1.9679293235143025

Epoch: 6| Step: 13
Training loss: 1.471663236618042
Validation loss: 1.9421908259391785

Epoch: 122| Step: 0
Training loss: 1.3169541358947754
Validation loss: 1.9620667497316997

Epoch: 6| Step: 1
Training loss: 1.627001404762268
Validation loss: 1.941869854927063

Epoch: 6| Step: 2
Training loss: 1.0326249599456787
Validation loss: 1.9727693796157837

Epoch: 6| Step: 3
Training loss: 0.9836574196815491
Validation loss: 1.9617671767870586

Epoch: 6| Step: 4
Training loss: 1.0327849388122559
Validation loss: 1.9777750571568806

Epoch: 6| Step: 5
Training loss: 1.38285493850708
Validation loss: 1.9697256286938984

Epoch: 6| Step: 6
Training loss: 1.1108580827713013
Validation loss: 1.9865182042121887

Epoch: 6| Step: 7
Training loss: 1.1641156673431396
Validation loss: 2.018481949965159

Epoch: 6| Step: 8
Training loss: 1.1995320320129395
Validation loss: 1.9655061562856038

Epoch: 6| Step: 9
Training loss: 0.7979267835617065
Validation loss: 1.960893193880717

Epoch: 6| Step: 10
Training loss: 1.4943981170654297
Validation loss: 1.9549256364504497

Epoch: 6| Step: 11
Training loss: 1.1755820512771606
Validation loss: 1.9438703656196594

Epoch: 6| Step: 12
Training loss: 1.6433944702148438
Validation loss: 1.9524651765823364

Epoch: 6| Step: 13
Training loss: 1.1127115488052368
Validation loss: 1.9874065319697063

Epoch: 123| Step: 0
Training loss: 0.5420739650726318
Validation loss: 1.942400872707367

Epoch: 6| Step: 1
Training loss: 1.2563676834106445
Validation loss: 1.9754397869110107

Epoch: 6| Step: 2
Training loss: 1.5430965423583984
Validation loss: 1.961071530977885

Epoch: 6| Step: 3
Training loss: 1.269571304321289
Validation loss: 1.9519047737121582

Epoch: 6| Step: 4
Training loss: 1.568350911140442
Validation loss: 1.9474587837855022

Epoch: 6| Step: 5
Training loss: 0.9430398941040039
Validation loss: 1.9720983703931172

Epoch: 6| Step: 6
Training loss: 1.2025874853134155
Validation loss: 1.9519259134928386

Epoch: 6| Step: 7
Training loss: 2.0797181129455566
Validation loss: 1.9772947231928508

Epoch: 6| Step: 8
Training loss: 1.895698070526123
Validation loss: 2.0138776103655496

Epoch: 6| Step: 9
Training loss: 0.7856031060218811
Validation loss: 2.0036908388137817

Epoch: 6| Step: 10
Training loss: 1.0681262016296387
Validation loss: 1.9694395661354065

Epoch: 6| Step: 11
Training loss: 0.875076174736023
Validation loss: 1.9752431114514668

Epoch: 6| Step: 12
Training loss: 1.0996087789535522
Validation loss: 1.9805415272712708

Epoch: 6| Step: 13
Training loss: 1.0261253118515015
Validation loss: 2.000857730706533

Epoch: 124| Step: 0
Training loss: 1.2916686534881592
Validation loss: 1.9424693584442139

Epoch: 6| Step: 1
Training loss: 1.2623486518859863
Validation loss: 1.9913610617319744

Epoch: 6| Step: 2
Training loss: 0.8067977428436279
Validation loss: 1.9654571811358135

Epoch: 6| Step: 3
Training loss: 1.0480961799621582
Validation loss: 1.9616162578264873

Epoch: 6| Step: 4
Training loss: 1.2833797931671143
Validation loss: 1.9334797461827595

Epoch: 6| Step: 5
Training loss: 1.2316298484802246
Validation loss: 1.9116679231325786

Epoch: 6| Step: 6
Training loss: 1.5525323152542114
Validation loss: 1.8989927570025127

Epoch: 6| Step: 7
Training loss: 0.8673413395881653
Validation loss: 1.9477262496948242

Epoch: 6| Step: 8
Training loss: 1.8570263385772705
Validation loss: 1.922041078408559

Epoch: 6| Step: 9
Training loss: 1.174386978149414
Validation loss: 1.9780540466308594

Epoch: 6| Step: 10
Training loss: 1.0085155963897705
Validation loss: 1.9057637850443523

Epoch: 6| Step: 11
Training loss: 1.098478078842163
Validation loss: 2.007486720879873

Epoch: 6| Step: 12
Training loss: 1.3207168579101562
Validation loss: 1.969792862733205

Epoch: 6| Step: 13
Training loss: 1.018700122833252
Validation loss: 1.9762801329294841

Epoch: 125| Step: 0
Training loss: 1.2530326843261719
Validation loss: 1.9799081683158875

Epoch: 6| Step: 1
Training loss: 1.1705492734909058
Validation loss: 1.9611554344495137

Epoch: 6| Step: 2
Training loss: 0.8631621599197388
Validation loss: 1.971276303132375

Epoch: 6| Step: 3
Training loss: 1.438339114189148
Validation loss: 1.969407359759013

Epoch: 6| Step: 4
Training loss: 0.9867663383483887
Validation loss: 1.9615488251050313

Epoch: 6| Step: 5
Training loss: 0.9627951383590698
Validation loss: 1.972336192925771

Epoch: 6| Step: 6
Training loss: 1.3294527530670166
Validation loss: 1.90168297290802

Epoch: 6| Step: 7
Training loss: 1.040818214416504
Validation loss: 1.9352112611134846

Epoch: 6| Step: 8
Training loss: 1.2982747554779053
Validation loss: 1.9747504393259685

Epoch: 6| Step: 9
Training loss: 1.148958683013916
Validation loss: 2.0009344617525735

Epoch: 6| Step: 10
Training loss: 1.3517683744430542
Validation loss: 1.912201722462972

Epoch: 6| Step: 11
Training loss: 1.322291612625122
Validation loss: 1.968974510828654

Epoch: 6| Step: 12
Training loss: 1.4636986255645752
Validation loss: 1.9845760464668274

Epoch: 6| Step: 13
Training loss: 1.236802339553833
Validation loss: 1.9656826655069988

Epoch: 126| Step: 0
Training loss: 0.9405405521392822
Validation loss: 2.0073214371999106

Epoch: 6| Step: 1
Training loss: 1.0131559371948242
Validation loss: 1.9998478293418884

Epoch: 6| Step: 2
Training loss: 1.25821852684021
Validation loss: 2.097136676311493

Epoch: 6| Step: 3
Training loss: 1.4803431034088135
Validation loss: 1.9818474849065144

Epoch: 6| Step: 4
Training loss: 1.266026258468628
Validation loss: 1.9796248078346252

Epoch: 6| Step: 5
Training loss: 2.0219545364379883
Validation loss: 1.9895419875780742

Epoch: 6| Step: 6
Training loss: 1.2384026050567627
Validation loss: 1.9309845368067424

Epoch: 6| Step: 7
Training loss: 1.1949591636657715
Validation loss: 1.9534578720728557

Epoch: 6| Step: 8
Training loss: 0.8217573761940002
Validation loss: 1.94394451379776

Epoch: 6| Step: 9
Training loss: 1.3197288513183594
Validation loss: 1.9849571188290913

Epoch: 6| Step: 10
Training loss: 0.7818312048912048
Validation loss: 1.9143252968788147

Epoch: 6| Step: 11
Training loss: 1.3087518215179443
Validation loss: 1.9531034231185913

Epoch: 6| Step: 12
Training loss: 1.1932497024536133
Validation loss: 1.958306074142456

Epoch: 6| Step: 13
Training loss: 1.243788480758667
Validation loss: 1.937821865081787

Epoch: 127| Step: 0
Training loss: 1.5370795726776123
Validation loss: 1.8801807761192322

Epoch: 6| Step: 1
Training loss: 1.4229300022125244
Validation loss: 1.9837039113044739

Epoch: 6| Step: 2
Training loss: 1.265188217163086
Validation loss: 1.9740415414174397

Epoch: 6| Step: 3
Training loss: 0.9184004068374634
Validation loss: 1.977765957514445

Epoch: 6| Step: 4
Training loss: 1.211722731590271
Validation loss: 1.9971346457799275

Epoch: 6| Step: 5
Training loss: 1.6736361980438232
Validation loss: 1.9608450333277385

Epoch: 6| Step: 6
Training loss: 1.5775349140167236
Validation loss: 2.002086341381073

Epoch: 6| Step: 7
Training loss: 0.9158700108528137
Validation loss: 1.993337074915568

Epoch: 6| Step: 8
Training loss: 1.0688185691833496
Validation loss: 1.9983254075050354

Epoch: 6| Step: 9
Training loss: 0.8752699494361877
Validation loss: 1.995481272538503

Epoch: 6| Step: 10
Training loss: 0.595247209072113
Validation loss: 1.9441773891448975

Epoch: 6| Step: 11
Training loss: 0.9352537393569946
Validation loss: 1.9254461924235027

Epoch: 6| Step: 12
Training loss: 1.1542046070098877
Validation loss: 1.9285289446512859

Epoch: 6| Step: 13
Training loss: 1.2452638149261475
Validation loss: 1.9644902149836223

Epoch: 128| Step: 0
Training loss: 1.1676115989685059
Validation loss: 1.9688604871431987

Epoch: 6| Step: 1
Training loss: 1.2836923599243164
Validation loss: 2.0014639695485434

Epoch: 6| Step: 2
Training loss: 1.729616641998291
Validation loss: 2.0027867356936135

Epoch: 6| Step: 3
Training loss: 1.1288056373596191
Validation loss: 1.9940390388170879

Epoch: 6| Step: 4
Training loss: 1.1777631044387817
Validation loss: 1.957041084766388

Epoch: 6| Step: 5
Training loss: 1.0935429334640503
Validation loss: 1.9658467769622803

Epoch: 6| Step: 6
Training loss: 1.083438515663147
Validation loss: 1.913332204023997

Epoch: 6| Step: 7
Training loss: 1.121317744255066
Validation loss: 2.0136406620343528

Epoch: 6| Step: 8
Training loss: 1.6134014129638672
Validation loss: 1.9673773050308228

Epoch: 6| Step: 9
Training loss: 1.2295448780059814
Validation loss: 2.0188485383987427

Epoch: 6| Step: 10
Training loss: 1.3968055248260498
Validation loss: 1.9818778435389202

Epoch: 6| Step: 11
Training loss: 1.2164512872695923
Validation loss: 1.9525615572929382

Epoch: 6| Step: 12
Training loss: 1.0112595558166504
Validation loss: 1.9609790643056233

Epoch: 6| Step: 13
Training loss: 0.8979260921478271
Validation loss: 1.943084756533305

Epoch: 129| Step: 0
Training loss: 1.045601487159729
Validation loss: 1.9694042007128398

Epoch: 6| Step: 1
Training loss: 2.0980935096740723
Validation loss: 1.9703437089920044

Epoch: 6| Step: 2
Training loss: 1.3663575649261475
Validation loss: 1.9463084141413372

Epoch: 6| Step: 3
Training loss: 1.0929157733917236
Validation loss: 1.9278592467308044

Epoch: 6| Step: 4
Training loss: 1.0133557319641113
Validation loss: 1.93382594982783

Epoch: 6| Step: 5
Training loss: 0.7178361415863037
Validation loss: 1.9875454703966777

Epoch: 6| Step: 6
Training loss: 1.741274356842041
Validation loss: 1.9263164003690083

Epoch: 6| Step: 7
Training loss: 0.9273184537887573
Validation loss: 1.9639995495478313

Epoch: 6| Step: 8
Training loss: 1.3994741439819336
Validation loss: 1.9673540194829304

Epoch: 6| Step: 9
Training loss: 0.8926651477813721
Validation loss: 1.9496047496795654

Epoch: 6| Step: 10
Training loss: 1.104400634765625
Validation loss: 1.9448556502660115

Epoch: 6| Step: 11
Training loss: 1.1364216804504395
Validation loss: 2.0102922916412354

Epoch: 6| Step: 12
Training loss: 1.1763710975646973
Validation loss: 1.9586553970972698

Epoch: 6| Step: 13
Training loss: 0.9052171111106873
Validation loss: 1.9250948826471965

Epoch: 130| Step: 0
Training loss: 0.9534545540809631
Validation loss: 1.8929421703020732

Epoch: 6| Step: 1
Training loss: 0.8289839029312134
Validation loss: 1.930495023727417

Epoch: 6| Step: 2
Training loss: 1.0712528228759766
Validation loss: 1.948660413424174

Epoch: 6| Step: 3
Training loss: 1.4139655828475952
Validation loss: 1.931892216205597

Epoch: 6| Step: 4
Training loss: 1.2516570091247559
Validation loss: 1.9447968006134033

Epoch: 6| Step: 5
Training loss: 0.9032058715820312
Validation loss: 1.9707796971003215

Epoch: 6| Step: 6
Training loss: 0.6930104494094849
Validation loss: 1.9539273977279663

Epoch: 6| Step: 7
Training loss: 1.5423808097839355
Validation loss: 1.8945524096488953

Epoch: 6| Step: 8
Training loss: 1.2541476488113403
Validation loss: 2.0036317110061646

Epoch: 6| Step: 9
Training loss: 1.4106495380401611
Validation loss: 1.9410806099573772

Epoch: 6| Step: 10
Training loss: 0.676081657409668
Validation loss: 1.9412318468093872

Epoch: 6| Step: 11
Training loss: 1.1196829080581665
Validation loss: 1.9450724323590596

Epoch: 6| Step: 12
Training loss: 1.1272857189178467
Validation loss: 1.9829576810201008

Epoch: 6| Step: 13
Training loss: 1.643566608428955
Validation loss: 1.9743428428967793

Epoch: 131| Step: 0
Training loss: 1.3558828830718994
Validation loss: 1.964939574400584

Epoch: 6| Step: 1
Training loss: 1.124037742614746
Validation loss: 1.931327482064565

Epoch: 6| Step: 2
Training loss: 0.7050427198410034
Validation loss: 1.9565220673878987

Epoch: 6| Step: 3
Training loss: 0.42122355103492737
Validation loss: 1.9570135076840718

Epoch: 6| Step: 4
Training loss: 1.0536205768585205
Validation loss: 1.9059466322263081

Epoch: 6| Step: 5
Training loss: 1.4436182975769043
Validation loss: 1.9686345060666401

Epoch: 6| Step: 6
Training loss: 1.4206817150115967
Validation loss: 1.9760996301968892

Epoch: 6| Step: 7
Training loss: 1.2728047370910645
Validation loss: 1.9465514818827312

Epoch: 6| Step: 8
Training loss: 1.3423506021499634
Validation loss: 1.9460963010787964

Epoch: 6| Step: 9
Training loss: 0.9927424788475037
Validation loss: 1.980103035767873

Epoch: 6| Step: 10
Training loss: 1.2237520217895508
Validation loss: 1.961055040359497

Epoch: 6| Step: 11
Training loss: 0.8189054727554321
Validation loss: 1.9817386468251545

Epoch: 6| Step: 12
Training loss: 1.0085742473602295
Validation loss: 1.9731293121973674

Epoch: 6| Step: 13
Training loss: 1.5799696445465088
Validation loss: 1.9764374494552612

Epoch: 132| Step: 0
Training loss: 0.5515340566635132
Validation loss: 2.009542485078176

Epoch: 6| Step: 1
Training loss: 1.483119249343872
Validation loss: 1.98400882879893

Epoch: 6| Step: 2
Training loss: 1.6282597780227661
Validation loss: 2.0447438955307007

Epoch: 6| Step: 3
Training loss: 1.332993745803833
Validation loss: 1.9663590987523396

Epoch: 6| Step: 4
Training loss: 1.239364743232727
Validation loss: 2.003670116265615

Epoch: 6| Step: 5
Training loss: 0.7858918309211731
Validation loss: 2.0093875924746194

Epoch: 6| Step: 6
Training loss: 1.0448755025863647
Validation loss: 1.9655329585075378

Epoch: 6| Step: 7
Training loss: 1.0451738834381104
Validation loss: 1.969614307085673

Epoch: 6| Step: 8
Training loss: 0.9384400248527527
Validation loss: 1.9677021503448486

Epoch: 6| Step: 9
Training loss: 1.368497371673584
Validation loss: 1.9720587134361267

Epoch: 6| Step: 10
Training loss: 0.8486534357070923
Validation loss: 1.9400983254114788

Epoch: 6| Step: 11
Training loss: 1.5330936908721924
Validation loss: 1.9801768064498901

Epoch: 6| Step: 12
Training loss: 0.9386664628982544
Validation loss: 1.987886667251587

Epoch: 6| Step: 13
Training loss: 1.10015070438385
Validation loss: 1.9605213801066081

Epoch: 133| Step: 0
Training loss: 1.1167885065078735
Validation loss: 1.9817858537038167

Epoch: 6| Step: 1
Training loss: 1.422993779182434
Validation loss: 1.9757121801376343

Epoch: 6| Step: 2
Training loss: 0.44086509943008423
Validation loss: 2.047647774219513

Epoch: 6| Step: 3
Training loss: 1.2840453386306763
Validation loss: 1.995051383972168

Epoch: 6| Step: 4
Training loss: 0.8121426105499268
Validation loss: 2.053647458553314

Epoch: 6| Step: 5
Training loss: 1.8546075820922852
Validation loss: 1.957399308681488

Epoch: 6| Step: 6
Training loss: 1.3975989818572998
Validation loss: 1.9538821578025818

Epoch: 6| Step: 7
Training loss: 1.414614200592041
Validation loss: 1.9530107776323955

Epoch: 6| Step: 8
Training loss: 1.2475340366363525
Validation loss: 1.9397345185279846

Epoch: 6| Step: 9
Training loss: 1.1619070768356323
Validation loss: 1.9674991567929585

Epoch: 6| Step: 10
Training loss: 1.2048492431640625
Validation loss: 1.9741840759913127

Epoch: 6| Step: 11
Training loss: 0.5975367426872253
Validation loss: 1.9502895871798198

Epoch: 6| Step: 12
Training loss: 1.4903664588928223
Validation loss: 1.9766352375348408

Epoch: 6| Step: 13
Training loss: 0.7022597789764404
Validation loss: 1.9411229689915974

Epoch: 134| Step: 0
Training loss: 0.6695999503135681
Validation loss: 1.932464877764384

Epoch: 6| Step: 1
Training loss: 1.3134958744049072
Validation loss: 1.94921871026357

Epoch: 6| Step: 2
Training loss: 1.1220946311950684
Validation loss: 1.9710617860158284

Epoch: 6| Step: 3
Training loss: 0.9287147521972656
Validation loss: 1.9816372593243916

Epoch: 6| Step: 4
Training loss: 1.3733798265457153
Validation loss: 1.904486894607544

Epoch: 6| Step: 5
Training loss: 0.6475096940994263
Validation loss: 1.9307966629664104

Epoch: 6| Step: 6
Training loss: 1.2054427862167358
Validation loss: 1.9314359823862712

Epoch: 6| Step: 7
Training loss: 1.341002345085144
Validation loss: 1.8944801688194275

Epoch: 6| Step: 8
Training loss: 1.4085689783096313
Validation loss: 1.9629260500272114

Epoch: 6| Step: 9
Training loss: 0.6583486795425415
Validation loss: 1.9104236563046773

Epoch: 6| Step: 10
Training loss: 1.1427720785140991
Validation loss: 1.9282081921895344

Epoch: 6| Step: 11
Training loss: 1.6840604543685913
Validation loss: 1.953938404719035

Epoch: 6| Step: 12
Training loss: 0.8821958303451538
Validation loss: 1.9503296216328938

Epoch: 6| Step: 13
Training loss: 1.0376033782958984
Validation loss: 1.9591349363327026

Epoch: 135| Step: 0
Training loss: 1.4638044834136963
Validation loss: 1.9818580150604248

Epoch: 6| Step: 1
Training loss: 1.124891996383667
Validation loss: 1.9471170703570049

Epoch: 6| Step: 2
Training loss: 1.180556058883667
Validation loss: 1.9827866951624553

Epoch: 6| Step: 3
Training loss: 0.9261353015899658
Validation loss: 1.9611202677090962

Epoch: 6| Step: 4
Training loss: 1.2063188552856445
Validation loss: 1.9882825414339702

Epoch: 6| Step: 5
Training loss: 0.9608365893363953
Validation loss: 1.9751923084259033

Epoch: 6| Step: 6
Training loss: 1.471529245376587
Validation loss: 1.9433844884236653

Epoch: 6| Step: 7
Training loss: 0.8520516157150269
Validation loss: 1.926966389020284

Epoch: 6| Step: 8
Training loss: 0.8130842447280884
Validation loss: 1.9380195339520772

Epoch: 6| Step: 9
Training loss: 1.2907307147979736
Validation loss: 1.9601421157519023

Epoch: 6| Step: 10
Training loss: 1.2543489933013916
Validation loss: 1.8893417318662007

Epoch: 6| Step: 11
Training loss: 1.5069557428359985
Validation loss: 1.9741405248641968

Epoch: 6| Step: 12
Training loss: 0.5446169376373291
Validation loss: 1.9635229110717773

Epoch: 6| Step: 13
Training loss: 0.7396993041038513
Validation loss: 1.9232258796691895

Epoch: 136| Step: 0
Training loss: 1.64571213722229
Validation loss: 1.9393991827964783

Epoch: 6| Step: 1
Training loss: 0.6035847663879395
Validation loss: 1.9725871880849202

Epoch: 6| Step: 2
Training loss: 1.0786834955215454
Validation loss: 1.9256905317306519

Epoch: 6| Step: 3
Training loss: 0.9180588722229004
Validation loss: 1.9653845230738323

Epoch: 6| Step: 4
Training loss: 0.8391438722610474
Validation loss: 1.938391109307607

Epoch: 6| Step: 5
Training loss: 0.9125843048095703
Validation loss: 1.9454487164815266

Epoch: 6| Step: 6
Training loss: 1.159997582435608
Validation loss: 1.9685786366462708

Epoch: 6| Step: 7
Training loss: 1.0635696649551392
Validation loss: 1.9182853897412617

Epoch: 6| Step: 8
Training loss: 1.2224552631378174
Validation loss: 1.9498233993848164

Epoch: 6| Step: 9
Training loss: 0.8856502771377563
Validation loss: 1.9529670476913452

Epoch: 6| Step: 10
Training loss: 1.084559679031372
Validation loss: 1.9636115431785583

Epoch: 6| Step: 11
Training loss: 1.2084156274795532
Validation loss: 1.9634072383244832

Epoch: 6| Step: 12
Training loss: 1.047853708267212
Validation loss: 1.9126038551330566

Epoch: 6| Step: 13
Training loss: 1.1904133558273315
Validation loss: 1.9379283388455708

Epoch: 137| Step: 0
Training loss: 1.178267002105713
Validation loss: 1.9850619633992512

Epoch: 6| Step: 1
Training loss: 1.3210585117340088
Validation loss: 1.9928661386171977

Epoch: 6| Step: 2
Training loss: 1.2026374340057373
Validation loss: 1.9745991031328838

Epoch: 6| Step: 3
Training loss: 0.9411810636520386
Validation loss: 1.9113198518753052

Epoch: 6| Step: 4
Training loss: 1.1971238851547241
Validation loss: 1.9833118716875713

Epoch: 6| Step: 5
Training loss: 1.0726674795150757
Validation loss: 1.9715461730957031

Epoch: 6| Step: 6
Training loss: 0.8458211421966553
Validation loss: 1.9350955684979756

Epoch: 6| Step: 7
Training loss: 0.9079858064651489
Validation loss: 1.9744399984677632

Epoch: 6| Step: 8
Training loss: 0.8641044497489929
Validation loss: 1.9381000598271687

Epoch: 6| Step: 9
Training loss: 1.0817285776138306
Validation loss: 1.935623049736023

Epoch: 6| Step: 10
Training loss: 1.1531414985656738
Validation loss: 1.9245101412137349

Epoch: 6| Step: 11
Training loss: 0.8747525811195374
Validation loss: 1.9654310743014018

Epoch: 6| Step: 12
Training loss: 0.84288489818573
Validation loss: 1.9446534911791484

Epoch: 6| Step: 13
Training loss: 0.8890039920806885
Validation loss: 1.9777582089106243

Epoch: 138| Step: 0
Training loss: 1.1744178533554077
Validation loss: 1.9604040384292603

Epoch: 6| Step: 1
Training loss: 0.8151842355728149
Validation loss: 1.9296324650446575

Epoch: 6| Step: 2
Training loss: 0.784928023815155
Validation loss: 1.9490714867909749

Epoch: 6| Step: 3
Training loss: 1.1138722896575928
Validation loss: 1.9475223819414775

Epoch: 6| Step: 4
Training loss: 0.628167450428009
Validation loss: 1.8950392007827759

Epoch: 6| Step: 5
Training loss: 0.6055585145950317
Validation loss: 1.9531397024790447

Epoch: 6| Step: 6
Training loss: 0.6218054294586182
Validation loss: 1.9379271268844604

Epoch: 6| Step: 7
Training loss: 0.9157924652099609
Validation loss: 1.9183527032534282

Epoch: 6| Step: 8
Training loss: 0.8732905387878418
Validation loss: 1.9992339412371318

Epoch: 6| Step: 9
Training loss: 1.4688054323196411
Validation loss: 1.9722628990809123

Epoch: 6| Step: 10
Training loss: 1.8673778772354126
Validation loss: 1.9844218889872234

Epoch: 6| Step: 11
Training loss: 1.1472114324569702
Validation loss: 1.912410835425059

Epoch: 6| Step: 12
Training loss: 1.1098158359527588
Validation loss: 1.9211518963177998

Epoch: 6| Step: 13
Training loss: 1.7259974479675293
Validation loss: 1.951985756556193

Epoch: 139| Step: 0
Training loss: 0.5440871715545654
Validation loss: 1.989746868610382

Epoch: 6| Step: 1
Training loss: 0.7659198045730591
Validation loss: 1.937467873096466

Epoch: 6| Step: 2
Training loss: 0.8705630898475647
Validation loss: 1.9340801040331523

Epoch: 6| Step: 3
Training loss: 1.2275021076202393
Validation loss: 1.9954343835512798

Epoch: 6| Step: 4
Training loss: 1.20188307762146
Validation loss: 1.9297302762667339

Epoch: 6| Step: 5
Training loss: 1.3340907096862793
Validation loss: 1.9497551918029785

Epoch: 6| Step: 6
Training loss: 0.81055748462677
Validation loss: 1.965295135974884

Epoch: 6| Step: 7
Training loss: 0.9702942967414856
Validation loss: 1.9254548748334248

Epoch: 6| Step: 8
Training loss: 0.9106764793395996
Validation loss: 1.9251593947410583

Epoch: 6| Step: 9
Training loss: 1.4423487186431885
Validation loss: 1.959607720375061

Epoch: 6| Step: 10
Training loss: 1.1100118160247803
Validation loss: 1.935037652651469

Epoch: 6| Step: 11
Training loss: 1.2734131813049316
Validation loss: 1.9309270580609639

Epoch: 6| Step: 12
Training loss: 0.6090291738510132
Validation loss: 1.9689806699752808

Epoch: 6| Step: 13
Training loss: 1.8355168104171753
Validation loss: 1.9452276825904846

Epoch: 140| Step: 0
Training loss: 1.1796026229858398
Validation loss: 1.9358368118604024

Epoch: 6| Step: 1
Training loss: 0.9490031003952026
Validation loss: 1.9140962362289429

Epoch: 6| Step: 2
Training loss: 0.65545654296875
Validation loss: 1.9215940435727437

Epoch: 6| Step: 3
Training loss: 1.2468163967132568
Validation loss: 1.9531215627988179

Epoch: 6| Step: 4
Training loss: 1.042209506034851
Validation loss: 1.9736661314964294

Epoch: 6| Step: 5
Training loss: 0.9339635372161865
Validation loss: 1.9546883702278137

Epoch: 6| Step: 6
Training loss: 1.1921360492706299
Validation loss: 1.9638211528460185

Epoch: 6| Step: 7
Training loss: 1.747343897819519
Validation loss: 1.9296065370241802

Epoch: 6| Step: 8
Training loss: 1.1340954303741455
Validation loss: 1.8960770567258198

Epoch: 6| Step: 9
Training loss: 0.9975003004074097
Validation loss: 1.8841137687365215

Epoch: 6| Step: 10
Training loss: 1.330432653427124
Validation loss: 1.8674514889717102

Epoch: 6| Step: 11
Training loss: 0.5470896363258362
Validation loss: 1.9351174036661785

Epoch: 6| Step: 12
Training loss: 0.6765797734260559
Validation loss: 1.9303552110989888

Epoch: 6| Step: 13
Training loss: 0.834551215171814
Validation loss: 1.9325812061627705

Epoch: 141| Step: 0
Training loss: 1.305832028388977
Validation loss: 1.974056641260783

Epoch: 6| Step: 1
Training loss: 1.1546200513839722
Validation loss: 1.9575706919034321

Epoch: 6| Step: 2
Training loss: 0.679591178894043
Validation loss: 1.9358351429303486

Epoch: 6| Step: 3
Training loss: 0.7559551000595093
Validation loss: 1.9733213583628337

Epoch: 6| Step: 4
Training loss: 1.0655736923217773
Validation loss: 1.990063726902008

Epoch: 6| Step: 5
Training loss: 0.9001315832138062
Validation loss: 1.9583126505215962

Epoch: 6| Step: 6
Training loss: 1.038845181465149
Validation loss: 1.9698546131451924

Epoch: 6| Step: 7
Training loss: 1.2888643741607666
Validation loss: 1.9196702043215434

Epoch: 6| Step: 8
Training loss: 0.7021981477737427
Validation loss: 1.9499062299728394

Epoch: 6| Step: 9
Training loss: 1.086483120918274
Validation loss: 1.9666430950164795

Epoch: 6| Step: 10
Training loss: 1.3587148189544678
Validation loss: 1.9201289614041646

Epoch: 6| Step: 11
Training loss: 0.8573484420776367
Validation loss: 1.90564759572347

Epoch: 6| Step: 12
Training loss: 1.0167198181152344
Validation loss: 1.939566969871521

Epoch: 6| Step: 13
Training loss: 1.048079252243042
Validation loss: 1.903374969959259

Epoch: 142| Step: 0
Training loss: 0.9781054258346558
Validation loss: 1.9336372017860413

Epoch: 6| Step: 1
Training loss: 0.7511823177337646
Validation loss: 1.9067115982373555

Epoch: 6| Step: 2
Training loss: 1.0412707328796387
Validation loss: 1.977250615755717

Epoch: 6| Step: 3
Training loss: 0.4777955710887909
Validation loss: 1.9493080774943035

Epoch: 6| Step: 4
Training loss: 0.9230208396911621
Validation loss: 1.9599347710609436

Epoch: 6| Step: 5
Training loss: 0.9800546169281006
Validation loss: 1.9449362754821777

Epoch: 6| Step: 6
Training loss: 0.8672728538513184
Validation loss: 1.9213547507921855

Epoch: 6| Step: 7
Training loss: 1.429884672164917
Validation loss: 1.9139063954353333

Epoch: 6| Step: 8
Training loss: 0.8322889804840088
Validation loss: 1.934400200843811

Epoch: 6| Step: 9
Training loss: 1.1749740839004517
Validation loss: 1.9368164936701457

Epoch: 6| Step: 10
Training loss: 1.737455129623413
Validation loss: 1.8827829162279766

Epoch: 6| Step: 11
Training loss: 0.7818580269813538
Validation loss: 1.9312704006830852

Epoch: 6| Step: 12
Training loss: 0.7021543979644775
Validation loss: 1.9496127367019653

Epoch: 6| Step: 13
Training loss: 1.4028249979019165
Validation loss: 1.9339804450670879

Epoch: 143| Step: 0
Training loss: 1.2160954475402832
Validation loss: 1.9984692335128784

Epoch: 6| Step: 1
Training loss: 0.666107177734375
Validation loss: 1.9369332194328308

Epoch: 6| Step: 2
Training loss: 0.8087958097457886
Validation loss: 2.0074352025985718

Epoch: 6| Step: 3
Training loss: 0.9364656805992126
Validation loss: 1.9580464561780293

Epoch: 6| Step: 4
Training loss: 0.6839278936386108
Validation loss: 1.9626792470614116

Epoch: 6| Step: 5
Training loss: 1.0740255117416382
Validation loss: 1.9556308786074321

Epoch: 6| Step: 6
Training loss: 0.9072041511535645
Validation loss: 1.9388373295466106

Epoch: 6| Step: 7
Training loss: 0.6819348335266113
Validation loss: 1.9658766587575276

Epoch: 6| Step: 8
Training loss: 0.970603346824646
Validation loss: 1.9792184233665466

Epoch: 6| Step: 9
Training loss: 0.7201635837554932
Validation loss: 1.9358016649882

Epoch: 6| Step: 10
Training loss: 1.135035753250122
Validation loss: 1.942102571328481

Epoch: 6| Step: 11
Training loss: 0.9842319488525391
Validation loss: 1.9864550431569417

Epoch: 6| Step: 12
Training loss: 1.2393596172332764
Validation loss: 1.933252493540446

Epoch: 6| Step: 13
Training loss: 1.684311866760254
Validation loss: 1.9406222701072693

Epoch: 144| Step: 0
Training loss: 1.2561109066009521
Validation loss: 1.9339481393496196

Epoch: 6| Step: 1
Training loss: 0.8703246712684631
Validation loss: 1.9403599898020427

Epoch: 6| Step: 2
Training loss: 0.8773450255393982
Validation loss: 1.908212920029958

Epoch: 6| Step: 3
Training loss: 1.0610504150390625
Validation loss: 1.933937708536784

Epoch: 6| Step: 4
Training loss: 0.8892993927001953
Validation loss: 1.9174513419469197

Epoch: 6| Step: 5
Training loss: 0.6309115886688232
Validation loss: 1.996112048625946

Epoch: 6| Step: 6
Training loss: 0.8199685215950012
Validation loss: 1.9393901228904724

Epoch: 6| Step: 7
Training loss: 1.1154749393463135
Validation loss: 1.9208197991053264

Epoch: 6| Step: 8
Training loss: 1.3119902610778809
Validation loss: 1.9207172989845276

Epoch: 6| Step: 9
Training loss: 0.8311028480529785
Validation loss: 1.9757295648256938

Epoch: 6| Step: 10
Training loss: 0.9736860394477844
Validation loss: 1.9250851670900981

Epoch: 6| Step: 11
Training loss: 1.0229779481887817
Validation loss: 1.9413331151008606

Epoch: 6| Step: 12
Training loss: 1.0898122787475586
Validation loss: 1.9286028146743774

Epoch: 6| Step: 13
Training loss: 1.1334030628204346
Validation loss: 1.94646817445755

Epoch: 145| Step: 0
Training loss: 1.2507390975952148
Validation loss: 1.8972520629564922

Epoch: 6| Step: 1
Training loss: 0.7299776077270508
Validation loss: 1.9821915030479431

Epoch: 6| Step: 2
Training loss: 0.8132150173187256
Validation loss: 1.8892068068186443

Epoch: 6| Step: 3
Training loss: 0.5861690044403076
Validation loss: 1.9483323693275452

Epoch: 6| Step: 4
Training loss: 1.1372970342636108
Validation loss: 1.9372554222742717

Epoch: 6| Step: 5
Training loss: 0.9027034640312195
Validation loss: 1.968749423821767

Epoch: 6| Step: 6
Training loss: 1.2817462682724
Validation loss: 1.924716591835022

Epoch: 6| Step: 7
Training loss: 0.7447700500488281
Validation loss: 1.9597975611686707

Epoch: 6| Step: 8
Training loss: 1.2110071182250977
Validation loss: 1.9801433483759563

Epoch: 6| Step: 9
Training loss: 0.9444329738616943
Validation loss: 1.9266472061475117

Epoch: 6| Step: 10
Training loss: 0.9807916879653931
Validation loss: 1.9383031129837036

Epoch: 6| Step: 11
Training loss: 1.123349905014038
Validation loss: 1.9263300895690918

Epoch: 6| Step: 12
Training loss: 1.103951096534729
Validation loss: 1.932559311389923

Epoch: 6| Step: 13
Training loss: 0.8606839179992676
Validation loss: 1.9532023072242737

Epoch: 146| Step: 0
Training loss: 1.5152673721313477
Validation loss: 1.94240536292394

Epoch: 6| Step: 1
Training loss: 0.8877667188644409
Validation loss: 1.9332524538040161

Epoch: 6| Step: 2
Training loss: 0.5547586679458618
Validation loss: 1.9562596678733826

Epoch: 6| Step: 3
Training loss: 1.4102357625961304
Validation loss: 2.020918389161428

Epoch: 6| Step: 4
Training loss: 1.2112162113189697
Validation loss: 2.006278951962789

Epoch: 6| Step: 5
Training loss: 1.0402253866195679
Validation loss: 1.9955212871233623

Epoch: 6| Step: 6
Training loss: 0.9816567301750183
Validation loss: 2.03809130191803

Epoch: 6| Step: 7
Training loss: 1.0686508417129517
Validation loss: 1.9784523248672485

Epoch: 6| Step: 8
Training loss: 0.4666052758693695
Validation loss: 1.9958537817001343

Epoch: 6| Step: 9
Training loss: 0.9391750693321228
Validation loss: 1.9383196433385212

Epoch: 6| Step: 10
Training loss: 0.7572258710861206
Validation loss: 1.9410631855328877

Epoch: 6| Step: 11
Training loss: 0.6404129862785339
Validation loss: 1.907290021578471

Epoch: 6| Step: 12
Training loss: 0.9503335952758789
Validation loss: 1.9599922895431519

Epoch: 6| Step: 13
Training loss: 1.577248215675354
Validation loss: 1.9668004512786865

Epoch: 147| Step: 0
Training loss: 1.810306429862976
Validation loss: 1.9838089148203533

Epoch: 6| Step: 1
Training loss: 0.9623271226882935
Validation loss: 2.0206241607666016

Epoch: 6| Step: 2
Training loss: 0.9475057125091553
Validation loss: 1.9864716132481892

Epoch: 6| Step: 3
Training loss: 1.2407691478729248
Validation loss: 2.0061519344647727

Epoch: 6| Step: 4
Training loss: 0.9806075096130371
Validation loss: 1.9665515224138896

Epoch: 6| Step: 5
Training loss: 1.0818853378295898
Validation loss: 1.998301903406779

Epoch: 6| Step: 6
Training loss: 1.0404988527297974
Validation loss: 2.001060167948405

Epoch: 6| Step: 7
Training loss: 0.9352183938026428
Validation loss: 1.9515944123268127

Epoch: 6| Step: 8
Training loss: 0.45380520820617676
Validation loss: 1.9497094949086506

Epoch: 6| Step: 9
Training loss: 1.1469018459320068
Validation loss: 1.9358925819396973

Epoch: 6| Step: 10
Training loss: 0.6692310571670532
Validation loss: 1.9881585240364075

Epoch: 6| Step: 11
Training loss: 0.8400146961212158
Validation loss: 1.9934203426043193

Epoch: 6| Step: 12
Training loss: 0.4973125457763672
Validation loss: 1.9610976775487263

Epoch: 6| Step: 13
Training loss: 0.8417906165122986
Validation loss: 1.9220108389854431

Epoch: 148| Step: 0
Training loss: 0.9883771538734436
Validation loss: 1.889818012714386

Epoch: 6| Step: 1
Training loss: 0.5925960540771484
Validation loss: 1.9765884478886921

Epoch: 6| Step: 2
Training loss: 0.7023327350616455
Validation loss: 1.990941007932027

Epoch: 6| Step: 3
Training loss: 0.6346463561058044
Validation loss: 1.914520025253296

Epoch: 6| Step: 4
Training loss: 1.2498537302017212
Validation loss: 1.9430059393246968

Epoch: 6| Step: 5
Training loss: 0.502408504486084
Validation loss: 1.9698384205500286

Epoch: 6| Step: 6
Training loss: 0.9542397856712341
Validation loss: 1.9667530059814453

Epoch: 6| Step: 7
Training loss: 0.373771995306015
Validation loss: 1.9474113583564758

Epoch: 6| Step: 8
Training loss: 1.312079668045044
Validation loss: 1.956766704718272

Epoch: 6| Step: 9
Training loss: 1.2542136907577515
Validation loss: 1.940972129503886

Epoch: 6| Step: 10
Training loss: 1.3376508951187134
Validation loss: 1.9508891503016155

Epoch: 6| Step: 11
Training loss: 1.3033733367919922
Validation loss: 1.9591911435127258

Epoch: 6| Step: 12
Training loss: 0.8938626050949097
Validation loss: 1.9793440103530884

Epoch: 6| Step: 13
Training loss: 1.0158573389053345
Validation loss: 1.9754090706507366

Epoch: 149| Step: 0
Training loss: 0.25869882106781006
Validation loss: 1.9274037679036458

Epoch: 6| Step: 1
Training loss: 0.6089794635772705
Validation loss: 1.9372725089391072

Epoch: 6| Step: 2
Training loss: 1.397701621055603
Validation loss: 1.9671894311904907

Epoch: 6| Step: 3
Training loss: 0.7893519997596741
Validation loss: 1.9592524568239849

Epoch: 6| Step: 4
Training loss: 1.2684741020202637
Validation loss: 1.918142835299174

Epoch: 6| Step: 5
Training loss: 0.8727676868438721
Validation loss: 1.955908974011739

Epoch: 6| Step: 6
Training loss: 0.8631615042686462
Validation loss: 1.9147949814796448

Epoch: 6| Step: 7
Training loss: 1.0472979545593262
Validation loss: 1.927397867043813

Epoch: 6| Step: 8
Training loss: 1.439046025276184
Validation loss: 1.933248519897461

Epoch: 6| Step: 9
Training loss: 0.9493962526321411
Validation loss: 1.8977723916371663

Epoch: 6| Step: 10
Training loss: 0.7447947859764099
Validation loss: 1.9233050346374512

Epoch: 6| Step: 11
Training loss: 1.235360860824585
Validation loss: 1.9302224516868591

Epoch: 6| Step: 12
Training loss: 0.5426934957504272
Validation loss: 1.896641691525777

Epoch: 6| Step: 13
Training loss: 1.1622629165649414
Validation loss: 1.9544242024421692

Epoch: 150| Step: 0
Training loss: 0.9008787274360657
Validation loss: 1.9491700927416484

Epoch: 6| Step: 1
Training loss: 1.2665958404541016
Validation loss: 1.9667520920435588

Epoch: 6| Step: 2
Training loss: 0.7670687437057495
Validation loss: 1.970613996187846

Epoch: 6| Step: 3
Training loss: 0.634305477142334
Validation loss: 1.985981007417043

Epoch: 6| Step: 4
Training loss: 0.9183870553970337
Validation loss: 1.979472557703654

Epoch: 6| Step: 5
Training loss: 0.996379554271698
Validation loss: 1.9526497721672058

Epoch: 6| Step: 6
Training loss: 0.6214133501052856
Validation loss: 1.9244876106580098

Epoch: 6| Step: 7
Training loss: 0.8812243342399597
Validation loss: 1.9562498132387798

Epoch: 6| Step: 8
Training loss: 1.2645297050476074
Validation loss: 1.8794703086217244

Epoch: 6| Step: 9
Training loss: 1.4374586343765259
Validation loss: 1.9203535119692485

Epoch: 6| Step: 10
Training loss: 0.8476880192756653
Validation loss: 2.01535693804423

Epoch: 6| Step: 11
Training loss: 1.1169517040252686
Validation loss: 1.9666818380355835

Epoch: 6| Step: 12
Training loss: 0.8904291391372681
Validation loss: 1.944684346516927

Epoch: 6| Step: 13
Training loss: 1.015982747077942
Validation loss: 1.9185609022776287

Epoch: 151| Step: 0
Training loss: 0.6208121180534363
Validation loss: 1.9085241556167603

Epoch: 6| Step: 1
Training loss: 1.1788206100463867
Validation loss: 2.0007694562276206

Epoch: 6| Step: 2
Training loss: 0.6678189039230347
Validation loss: 1.8916519681612651

Epoch: 6| Step: 3
Training loss: 1.1043825149536133
Validation loss: 1.9608453909556072

Epoch: 6| Step: 4
Training loss: 1.5254907608032227
Validation loss: 1.936847984790802

Epoch: 6| Step: 5
Training loss: 0.7787090539932251
Validation loss: 1.934948245684306

Epoch: 6| Step: 6
Training loss: 0.9295307397842407
Validation loss: 1.989417831103007

Epoch: 6| Step: 7
Training loss: 1.0226699113845825
Validation loss: 1.9524620374043782

Epoch: 6| Step: 8
Training loss: 1.4297823905944824
Validation loss: 1.9902972181638081

Epoch: 6| Step: 9
Training loss: 1.25922429561615
Validation loss: 1.9431591828664143

Epoch: 6| Step: 10
Training loss: 1.0039385557174683
Validation loss: 1.941602349281311

Epoch: 6| Step: 11
Training loss: 0.6031070947647095
Validation loss: 1.9341733853022258

Epoch: 6| Step: 12
Training loss: 0.6903983354568481
Validation loss: 1.960789680480957

Epoch: 6| Step: 13
Training loss: 0.6569662094116211
Validation loss: 1.9341660141944885

Epoch: 152| Step: 0
Training loss: 0.740276038646698
Validation loss: 1.913539707660675

Epoch: 6| Step: 1
Training loss: 0.5381188988685608
Validation loss: 1.8768328825632732

Epoch: 6| Step: 2
Training loss: 1.0331517457962036
Validation loss: 1.958729366461436

Epoch: 6| Step: 3
Training loss: 0.6348913908004761
Validation loss: 1.959359049797058

Epoch: 6| Step: 4
Training loss: 1.5348705053329468
Validation loss: 1.9762057065963745

Epoch: 6| Step: 5
Training loss: 1.0303335189819336
Validation loss: 1.9311264157295227

Epoch: 6| Step: 6
Training loss: 0.7788510322570801
Validation loss: 1.981383999188741

Epoch: 6| Step: 7
Training loss: 1.0078840255737305
Validation loss: 1.9394213159879048

Epoch: 6| Step: 8
Training loss: 0.9398025274276733
Validation loss: 1.9835320909818013

Epoch: 6| Step: 9
Training loss: 0.8243998885154724
Validation loss: 1.9960236152013142

Epoch: 6| Step: 10
Training loss: 0.45181789994239807
Validation loss: 1.9719735185305278

Epoch: 6| Step: 11
Training loss: 1.2046071290969849
Validation loss: 1.935986081759135

Epoch: 6| Step: 12
Training loss: 1.5117768049240112
Validation loss: 1.9557358622550964

Epoch: 6| Step: 13
Training loss: 0.5011698007583618
Validation loss: 1.9563225309054058

Epoch: 153| Step: 0
Training loss: 0.9525893926620483
Validation loss: 1.940795401732127

Epoch: 6| Step: 1
Training loss: 0.7487350702285767
Validation loss: 1.9186425407727559

Epoch: 6| Step: 2
Training loss: 1.2407598495483398
Validation loss: 1.9451916217803955

Epoch: 6| Step: 3
Training loss: 1.210940957069397
Validation loss: 1.956730584303538

Epoch: 6| Step: 4
Training loss: 0.6718343496322632
Validation loss: 1.9452637036641438

Epoch: 6| Step: 5
Training loss: 0.6544665098190308
Validation loss: 1.9635613361994426

Epoch: 6| Step: 6
Training loss: 1.2141023874282837
Validation loss: 1.9468329151471455

Epoch: 6| Step: 7
Training loss: 0.7612994909286499
Validation loss: 1.9680444200833638

Epoch: 6| Step: 8
Training loss: 0.8100519776344299
Validation loss: 1.8979433178901672

Epoch: 6| Step: 9
Training loss: 0.6562682390213013
Validation loss: 1.9471851587295532

Epoch: 6| Step: 10
Training loss: 1.3932504653930664
Validation loss: 1.9243170420328777

Epoch: 6| Step: 11
Training loss: 0.8585485219955444
Validation loss: 1.8901209632555644

Epoch: 6| Step: 12
Training loss: 1.016092300415039
Validation loss: 1.910573701063792

Epoch: 6| Step: 13
Training loss: 0.831595778465271
Validation loss: 1.9562092622121174

Epoch: 154| Step: 0
Training loss: 0.9305737614631653
Validation loss: 1.9166345000267029

Epoch: 6| Step: 1
Training loss: 1.0127027034759521
Validation loss: 1.980824629465739

Epoch: 6| Step: 2
Training loss: 0.8578087091445923
Validation loss: 1.9939029812812805

Epoch: 6| Step: 3
Training loss: 0.8200310468673706
Validation loss: 1.9249166250228882

Epoch: 6| Step: 4
Training loss: 0.7028219699859619
Validation loss: 1.9182870388031006

Epoch: 6| Step: 5
Training loss: 1.381121039390564
Validation loss: 1.9690269827842712

Epoch: 6| Step: 6
Training loss: 0.5184625387191772
Validation loss: 1.9433696071306865

Epoch: 6| Step: 7
Training loss: 0.48803091049194336
Validation loss: 1.948700765768687

Epoch: 6| Step: 8
Training loss: 1.1137945652008057
Validation loss: 1.9271334409713745

Epoch: 6| Step: 9
Training loss: 0.6117601990699768
Validation loss: 1.913146475950877

Epoch: 6| Step: 10
Training loss: 0.898786187171936
Validation loss: 1.9458580414454143

Epoch: 6| Step: 11
Training loss: 1.113187313079834
Validation loss: 1.9115117192268372

Epoch: 6| Step: 12
Training loss: 1.0984256267547607
Validation loss: 1.8956197500228882

Epoch: 6| Step: 13
Training loss: 1.0996296405792236
Validation loss: 2.027722338835398

Epoch: 155| Step: 0
Training loss: 0.8608686923980713
Validation loss: 1.889612853527069

Epoch: 6| Step: 1
Training loss: 0.8331807851791382
Validation loss: 1.9583677848180134

Epoch: 6| Step: 2
Training loss: 0.9477307796478271
Validation loss: 1.9427423477172852

Epoch: 6| Step: 3
Training loss: 1.1940973997116089
Validation loss: 1.9469410975774128

Epoch: 6| Step: 4
Training loss: 0.9735515713691711
Validation loss: 1.9897354245185852

Epoch: 6| Step: 5
Training loss: 0.6969047784805298
Validation loss: 1.9339938759803772

Epoch: 6| Step: 6
Training loss: 1.017499327659607
Validation loss: 1.9991481701533

Epoch: 6| Step: 7
Training loss: 0.6136192083358765
Validation loss: 1.9525556365648906

Epoch: 6| Step: 8
Training loss: 0.715286135673523
Validation loss: 1.9571692148844402

Epoch: 6| Step: 9
Training loss: 0.588172435760498
Validation loss: 1.8747374216715496

Epoch: 6| Step: 10
Training loss: 0.7651650905609131
Validation loss: 1.9429705739021301

Epoch: 6| Step: 11
Training loss: 1.4912817478179932
Validation loss: 1.8850111564000447

Epoch: 6| Step: 12
Training loss: 1.1496543884277344
Validation loss: 1.9760740200678508

Epoch: 6| Step: 13
Training loss: 0.8524526953697205
Validation loss: 1.9075843294461567

Epoch: 156| Step: 0
Training loss: 0.8556182980537415
Validation loss: 1.929073452949524

Epoch: 6| Step: 1
Training loss: 0.7170836925506592
Validation loss: 1.973695456981659

Epoch: 6| Step: 2
Training loss: 1.088475227355957
Validation loss: 1.9406151572863262

Epoch: 6| Step: 3
Training loss: 1.1868481636047363
Validation loss: 1.9146266380945842

Epoch: 6| Step: 4
Training loss: 0.5536168813705444
Validation loss: 1.954738934834798

Epoch: 6| Step: 5
Training loss: 0.6733949184417725
Validation loss: 1.898014744122823

Epoch: 6| Step: 6
Training loss: 0.8937381505966187
Validation loss: 1.9686045447985332

Epoch: 6| Step: 7
Training loss: 0.7810326814651489
Validation loss: 1.920260747273763

Epoch: 6| Step: 8
Training loss: 0.8678308725357056
Validation loss: 1.9278160134951274

Epoch: 6| Step: 9
Training loss: 0.9548255801200867
Validation loss: 1.9283567269643147

Epoch: 6| Step: 10
Training loss: 0.9907147288322449
Validation loss: 1.9323596556981404

Epoch: 6| Step: 11
Training loss: 1.0582878589630127
Validation loss: 1.9252001841862996

Epoch: 6| Step: 12
Training loss: 1.0167187452316284
Validation loss: 1.9016117652257283

Epoch: 6| Step: 13
Training loss: 0.878555417060852
Validation loss: 1.8990285595258076

Epoch: 157| Step: 0
Training loss: 0.9084722995758057
Validation loss: 1.90303373336792

Epoch: 6| Step: 1
Training loss: 1.355234146118164
Validation loss: 1.9935635924339294

Epoch: 6| Step: 2
Training loss: 1.0774765014648438
Validation loss: 1.9320242007573445

Epoch: 6| Step: 3
Training loss: 0.8362454175949097
Validation loss: 1.9366113940874736

Epoch: 6| Step: 4
Training loss: 0.7083793878555298
Validation loss: 1.915018121401469

Epoch: 6| Step: 5
Training loss: 0.6577800512313843
Validation loss: 1.938409427801768

Epoch: 6| Step: 6
Training loss: 0.6645402908325195
Validation loss: 1.927122672398885

Epoch: 6| Step: 7
Training loss: 1.3115893602371216
Validation loss: 1.9746495683987935

Epoch: 6| Step: 8
Training loss: 0.72601318359375
Validation loss: 1.9458507299423218

Epoch: 6| Step: 9
Training loss: 1.0367785692214966
Validation loss: 1.9672054449717205

Epoch: 6| Step: 10
Training loss: 1.3248728513717651
Validation loss: 1.9605400164922078

Epoch: 6| Step: 11
Training loss: 0.3189358711242676
Validation loss: 1.9775763551394145

Epoch: 6| Step: 12
Training loss: 0.9670579433441162
Validation loss: 1.9679694771766663

Epoch: 6| Step: 13
Training loss: 0.9515078067779541
Validation loss: 1.9192987084388733

Epoch: 158| Step: 0
Training loss: 0.8254256248474121
Validation loss: 1.9163480003674824

Epoch: 6| Step: 1
Training loss: 0.40113961696624756
Validation loss: 1.9084862073262532

Epoch: 6| Step: 2
Training loss: 1.1809862852096558
Validation loss: 1.9602489074071248

Epoch: 6| Step: 3
Training loss: 1.044474482536316
Validation loss: 1.9723957578341167

Epoch: 6| Step: 4
Training loss: 0.8498651385307312
Validation loss: 1.928788165251414

Epoch: 6| Step: 5
Training loss: 1.1205317974090576
Validation loss: 1.9156755010286968

Epoch: 6| Step: 6
Training loss: 1.1979061365127563
Validation loss: 1.9240884979565938

Epoch: 6| Step: 7
Training loss: 0.9194557070732117
Validation loss: 1.9115195671717327

Epoch: 6| Step: 8
Training loss: 0.6624417304992676
Validation loss: 1.9358511567115784

Epoch: 6| Step: 9
Training loss: 0.6733967065811157
Validation loss: 1.9591066042582195

Epoch: 6| Step: 10
Training loss: 0.9693474769592285
Validation loss: 1.952922026316325

Epoch: 6| Step: 11
Training loss: 0.6481966972351074
Validation loss: 1.9921188751856487

Epoch: 6| Step: 12
Training loss: 1.062107801437378
Validation loss: 1.923645297686259

Epoch: 6| Step: 13
Training loss: 0.7061935067176819
Validation loss: 1.9433383146921794

Epoch: 159| Step: 0
Training loss: 0.6876763701438904
Validation loss: 1.9302145044008892

Epoch: 6| Step: 1
Training loss: 0.9885319471359253
Validation loss: 1.926183541615804

Epoch: 6| Step: 2
Training loss: 1.071360468864441
Validation loss: 1.942879815896352

Epoch: 6| Step: 3
Training loss: 0.8138386011123657
Validation loss: 1.958678166071574

Epoch: 6| Step: 4
Training loss: 1.0603129863739014
Validation loss: 1.981101632118225

Epoch: 6| Step: 5
Training loss: 0.8474220037460327
Validation loss: 1.9141339461008708

Epoch: 6| Step: 6
Training loss: 0.5312498807907104
Validation loss: 1.9691200653711955

Epoch: 6| Step: 7
Training loss: 1.107149600982666
Validation loss: 1.9672956864039104

Epoch: 6| Step: 8
Training loss: 0.9465272426605225
Validation loss: 1.8961341778437297

Epoch: 6| Step: 9
Training loss: 0.661101758480072
Validation loss: 1.8824493686358135

Epoch: 6| Step: 10
Training loss: 0.6579638719558716
Validation loss: 1.963135580221812

Epoch: 6| Step: 11
Training loss: 0.9174401164054871
Validation loss: 1.9710320035616558

Epoch: 6| Step: 12
Training loss: 0.48114338517189026
Validation loss: 1.958681086699168

Epoch: 6| Step: 13
Training loss: 0.89683598279953
Validation loss: 1.9508015314737956

Epoch: 160| Step: 0
Training loss: 0.698991060256958
Validation loss: 1.9622071385383606

Epoch: 6| Step: 1
Training loss: 1.066170573234558
Validation loss: 1.9020698269208272

Epoch: 6| Step: 2
Training loss: 1.2094731330871582
Validation loss: 1.9605650901794434

Epoch: 6| Step: 3
Training loss: 0.9291229844093323
Validation loss: 1.927298088868459

Epoch: 6| Step: 4
Training loss: 0.6721546649932861
Validation loss: 1.9501779278119404

Epoch: 6| Step: 5
Training loss: 1.3027783632278442
Validation loss: 1.9238401651382446

Epoch: 6| Step: 6
Training loss: 0.8273521661758423
Validation loss: 1.9228686292966206

Epoch: 6| Step: 7
Training loss: 0.7610650658607483
Validation loss: 1.9232579270998638

Epoch: 6| Step: 8
Training loss: 0.5722277760505676
Validation loss: 1.9916325608889263

Epoch: 6| Step: 9
Training loss: 1.0888144969940186
Validation loss: 2.0009023547172546

Epoch: 6| Step: 10
Training loss: 0.8761008977890015
Validation loss: 1.9337827960650127

Epoch: 6| Step: 11
Training loss: 0.752034068107605
Validation loss: 1.9451830585797627

Epoch: 6| Step: 12
Training loss: 0.7691411972045898
Validation loss: 1.9665647745132446

Epoch: 6| Step: 13
Training loss: 0.92024827003479
Validation loss: 1.9742491642634075

Epoch: 161| Step: 0
Training loss: 0.816022515296936
Validation loss: 1.9434871077537537

Epoch: 6| Step: 1
Training loss: 0.663540780544281
Validation loss: 1.8953482309977214

Epoch: 6| Step: 2
Training loss: 0.8470803499221802
Validation loss: 1.9017661611239116

Epoch: 6| Step: 3
Training loss: 1.149048089981079
Validation loss: 1.9787723024686177

Epoch: 6| Step: 4
Training loss: 0.6500279307365417
Validation loss: 1.9368946552276611

Epoch: 6| Step: 5
Training loss: 0.8901848793029785
Validation loss: 1.9138415853182476

Epoch: 6| Step: 6
Training loss: 0.7023906111717224
Validation loss: 1.9137115677197774

Epoch: 6| Step: 7
Training loss: 0.8501685857772827
Validation loss: 1.9298179546991985

Epoch: 6| Step: 8
Training loss: 0.8755950927734375
Validation loss: 1.8880717754364014

Epoch: 6| Step: 9
Training loss: 1.3804445266723633
Validation loss: 1.9001550277074177

Epoch: 6| Step: 10
Training loss: 0.7813446521759033
Validation loss: 1.9513124028841655

Epoch: 6| Step: 11
Training loss: 0.890003502368927
Validation loss: 1.903509795665741

Epoch: 6| Step: 12
Training loss: 0.941739559173584
Validation loss: 1.9859288930892944

Epoch: 6| Step: 13
Training loss: 0.5458835959434509
Validation loss: 1.98895663022995

Epoch: 162| Step: 0
Training loss: 0.9596476554870605
Validation loss: 1.9799384276072185

Epoch: 6| Step: 1
Training loss: 0.9184854030609131
Validation loss: 1.9052338202794392

Epoch: 6| Step: 2
Training loss: 0.6574368476867676
Validation loss: 1.9208699464797974

Epoch: 6| Step: 3
Training loss: 0.9329487681388855
Validation loss: 1.9374764362970989

Epoch: 6| Step: 4
Training loss: 0.9162105321884155
Validation loss: 1.9434511065483093

Epoch: 6| Step: 5
Training loss: 0.6776046752929688
Validation loss: 1.9096242984135945

Epoch: 6| Step: 6
Training loss: 0.8593201637268066
Validation loss: 1.958387553691864

Epoch: 6| Step: 7
Training loss: 0.6641308665275574
Validation loss: 1.8844338655471802

Epoch: 6| Step: 8
Training loss: 1.1321603059768677
Validation loss: 1.9201039671897888

Epoch: 6| Step: 9
Training loss: 0.9989678859710693
Validation loss: 1.913711945215861

Epoch: 6| Step: 10
Training loss: 0.7411713600158691
Validation loss: 1.973954161008199

Epoch: 6| Step: 11
Training loss: 0.9153228998184204
Validation loss: 1.9832639892896016

Epoch: 6| Step: 12
Training loss: 0.38604187965393066
Validation loss: 1.8849932154019673

Epoch: 6| Step: 13
Training loss: 1.1205015182495117
Validation loss: 1.9458361466725667

Epoch: 163| Step: 0
Training loss: 0.5180366039276123
Validation loss: 1.9108110666275024

Epoch: 6| Step: 1
Training loss: 0.8781943321228027
Validation loss: 1.8903072675069172

Epoch: 6| Step: 2
Training loss: 1.2106178998947144
Validation loss: 1.9594300786654155

Epoch: 6| Step: 3
Training loss: 0.6856859922409058
Validation loss: 1.9164428114891052

Epoch: 6| Step: 4
Training loss: 1.0209459066390991
Validation loss: 1.93719881772995

Epoch: 6| Step: 5
Training loss: 1.1249078512191772
Validation loss: 1.9575011730194092

Epoch: 6| Step: 6
Training loss: 0.8657007217407227
Validation loss: 1.9323177138964336

Epoch: 6| Step: 7
Training loss: 0.8536059856414795
Validation loss: 1.9539521932601929

Epoch: 6| Step: 8
Training loss: 0.5268007516860962
Validation loss: 1.9913095633188884

Epoch: 6| Step: 9
Training loss: 1.0031774044036865
Validation loss: 1.9089893698692322

Epoch: 6| Step: 10
Training loss: 1.1958551406860352
Validation loss: 2.0379602511723838

Epoch: 6| Step: 11
Training loss: 0.8455789089202881
Validation loss: 1.9938864707946777

Epoch: 6| Step: 12
Training loss: 0.7854155898094177
Validation loss: 2.0059010982513428

Epoch: 6| Step: 13
Training loss: 0.6606150269508362
Validation loss: 1.9526861906051636

Epoch: 164| Step: 0
Training loss: 0.9499392509460449
Validation loss: 1.9311333100001018

Epoch: 6| Step: 1
Training loss: 1.0131490230560303
Validation loss: 1.928439199924469

Epoch: 6| Step: 2
Training loss: 0.618649423122406
Validation loss: 1.9224841793378193

Epoch: 6| Step: 3
Training loss: 1.0825936794281006
Validation loss: 1.9256466627120972

Epoch: 6| Step: 4
Training loss: 0.9702041149139404
Validation loss: 1.934892972310384

Epoch: 6| Step: 5
Training loss: 0.5148099064826965
Validation loss: 1.9550849596659343

Epoch: 6| Step: 6
Training loss: 0.8546193242073059
Validation loss: 1.9526067177454631

Epoch: 6| Step: 7
Training loss: 0.8472009897232056
Validation loss: 1.9825345675150554

Epoch: 6| Step: 8
Training loss: 0.8206866979598999
Validation loss: 1.932637631893158

Epoch: 6| Step: 9
Training loss: 1.1455358266830444
Validation loss: 1.9931668043136597

Epoch: 6| Step: 10
Training loss: 0.4990275502204895
Validation loss: 1.9818197687466939

Epoch: 6| Step: 11
Training loss: 0.5949602127075195
Validation loss: 1.9290846586227417

Epoch: 6| Step: 12
Training loss: 0.6905249357223511
Validation loss: 1.9590020179748535

Epoch: 6| Step: 13
Training loss: 1.227651834487915
Validation loss: 1.9277179837226868

Epoch: 165| Step: 0
Training loss: 0.6186013221740723
Validation loss: 1.9406530062357585

Epoch: 6| Step: 1
Training loss: 1.0507193803787231
Validation loss: 1.9849626620610554

Epoch: 6| Step: 2
Training loss: 1.3568394184112549
Validation loss: 1.912164529164632

Epoch: 6| Step: 3
Training loss: 1.3016204833984375
Validation loss: 1.9541948040326436

Epoch: 6| Step: 4
Training loss: 0.9126158356666565
Validation loss: 1.9480443199475606

Epoch: 6| Step: 5
Training loss: 1.0011502504348755
Validation loss: 1.9937461415926616

Epoch: 6| Step: 6
Training loss: 0.7382300496101379
Validation loss: 2.0213330189387

Epoch: 6| Step: 7
Training loss: 1.0044589042663574
Validation loss: 1.9691308736801147

Epoch: 6| Step: 8
Training loss: 1.241702914237976
Validation loss: 1.9753669102986653

Epoch: 6| Step: 9
Training loss: 0.7036332488059998
Validation loss: 1.9541570742925007

Epoch: 6| Step: 10
Training loss: 0.681775689125061
Validation loss: 1.9655277331670125

Epoch: 6| Step: 11
Training loss: 0.4963216185569763
Validation loss: 1.9442758361498516

Epoch: 6| Step: 12
Training loss: 0.45135071873664856
Validation loss: 1.9496834675470989

Epoch: 6| Step: 13
Training loss: 0.650139570236206
Validation loss: 1.9340306719144185

Epoch: 166| Step: 0
Training loss: 1.1107137203216553
Validation loss: 1.9455616474151611

Epoch: 6| Step: 1
Training loss: 0.8466930389404297
Validation loss: 1.9619991381963093

Epoch: 6| Step: 2
Training loss: 0.6874492168426514
Validation loss: 1.9847751259803772

Epoch: 6| Step: 3
Training loss: 1.3105943202972412
Validation loss: 1.992948293685913

Epoch: 6| Step: 4
Training loss: 0.4677014946937561
Validation loss: 1.9779408772786458

Epoch: 6| Step: 5
Training loss: 0.8278033137321472
Validation loss: 1.951619843641917

Epoch: 6| Step: 6
Training loss: 0.9642012119293213
Validation loss: 1.9099040826161702

Epoch: 6| Step: 7
Training loss: 1.2835493087768555
Validation loss: 1.9628807107607524

Epoch: 6| Step: 8
Training loss: 0.42352595925331116
Validation loss: 1.943206548690796

Epoch: 6| Step: 9
Training loss: 1.0441088676452637
Validation loss: 1.9716832637786865

Epoch: 6| Step: 10
Training loss: 0.8825721144676208
Validation loss: 1.9921666781107585

Epoch: 6| Step: 11
Training loss: 0.6350984573364258
Validation loss: 1.9371472597122192

Epoch: 6| Step: 12
Training loss: 1.1270012855529785
Validation loss: 1.9252207279205322

Epoch: 6| Step: 13
Training loss: 0.5410284399986267
Validation loss: 1.9352581302324932

Epoch: 167| Step: 0
Training loss: 0.6644598245620728
Validation loss: 1.9134127696355183

Epoch: 6| Step: 1
Training loss: 0.9938734769821167
Validation loss: 1.9925082723299663

Epoch: 6| Step: 2
Training loss: 0.7570841908454895
Validation loss: 1.9822863539059956

Epoch: 6| Step: 3
Training loss: 1.1384046077728271
Validation loss: 1.9888022740681965

Epoch: 6| Step: 4
Training loss: 0.9050720930099487
Validation loss: 1.94778706630071

Epoch: 6| Step: 5
Training loss: 0.9557608366012573
Validation loss: 1.9798546036084492

Epoch: 6| Step: 6
Training loss: 1.1238690614700317
Validation loss: 1.9364527861277263

Epoch: 6| Step: 7
Training loss: 0.47316107153892517
Validation loss: 1.9190812905629475

Epoch: 6| Step: 8
Training loss: 1.042327642440796
Validation loss: 1.969303846359253

Epoch: 6| Step: 9
Training loss: 0.9773666858673096
Validation loss: 1.9672985871632893

Epoch: 6| Step: 10
Training loss: 0.6310942769050598
Validation loss: 1.9298282265663147

Epoch: 6| Step: 11
Training loss: 0.9762932062149048
Validation loss: 1.9133101503054302

Epoch: 6| Step: 12
Training loss: 0.6508797407150269
Validation loss: 1.9276172320048015

Epoch: 6| Step: 13
Training loss: 0.6234751343727112
Validation loss: 1.9842935800552368

Epoch: 168| Step: 0
Training loss: 1.4445527791976929
Validation loss: 1.9833191831906636

Epoch: 6| Step: 1
Training loss: 0.5308641195297241
Validation loss: 1.9705620805422466

Epoch: 6| Step: 2
Training loss: 1.062021255493164
Validation loss: 1.9957600831985474

Epoch: 6| Step: 3
Training loss: 0.5231413841247559
Validation loss: 1.9790069460868835

Epoch: 6| Step: 4
Training loss: 0.8253045082092285
Validation loss: 1.997393250465393

Epoch: 6| Step: 5
Training loss: 0.5573675632476807
Validation loss: 1.9790616432825725

Epoch: 6| Step: 6
Training loss: 0.6180242300033569
Validation loss: 1.9695572058359783

Epoch: 6| Step: 7
Training loss: 1.0686743259429932
Validation loss: 1.9763433734575908

Epoch: 6| Step: 8
Training loss: 0.47190558910369873
Validation loss: 1.9634607632954915

Epoch: 6| Step: 9
Training loss: 0.5459799766540527
Validation loss: 1.9589630961418152

Epoch: 6| Step: 10
Training loss: 0.8985289931297302
Validation loss: 1.9220608870188396

Epoch: 6| Step: 11
Training loss: 0.8737316727638245
Validation loss: 1.9600580930709839

Epoch: 6| Step: 12
Training loss: 0.6166267395019531
Validation loss: 1.9576805432637532

Epoch: 6| Step: 13
Training loss: 1.636955976486206
Validation loss: 1.9582415223121643

Epoch: 169| Step: 0
Training loss: 0.4889821708202362
Validation loss: 1.9758450786272685

Epoch: 6| Step: 1
Training loss: 1.1144886016845703
Validation loss: 1.9689328074455261

Epoch: 6| Step: 2
Training loss: 0.6113207340240479
Validation loss: 1.949894110361735

Epoch: 6| Step: 3
Training loss: 0.6812138557434082
Validation loss: 1.9295134544372559

Epoch: 6| Step: 4
Training loss: 1.0987087488174438
Validation loss: 1.8934101064999898

Epoch: 6| Step: 5
Training loss: 0.6702857613563538
Validation loss: 1.9664655923843384

Epoch: 6| Step: 6
Training loss: 0.7777794003486633
Validation loss: 1.9727586309115093

Epoch: 6| Step: 7
Training loss: 0.8351709246635437
Validation loss: 1.9840595722198486

Epoch: 6| Step: 8
Training loss: 0.7280680537223816
Validation loss: 1.9559649626413982

Epoch: 6| Step: 9
Training loss: 1.3170607089996338
Validation loss: 1.9297073086102803

Epoch: 6| Step: 10
Training loss: 1.0524238348007202
Validation loss: 1.9897706309954326

Epoch: 6| Step: 11
Training loss: 0.5651679635047913
Validation loss: 1.9316580096880596

Epoch: 6| Step: 12
Training loss: 0.7565217018127441
Validation loss: 1.981971760590871

Epoch: 6| Step: 13
Training loss: 0.8658877611160278
Validation loss: 1.9810005625089009

Epoch: 170| Step: 0
Training loss: 1.0410041809082031
Validation loss: 1.9778979420661926

Epoch: 6| Step: 1
Training loss: 0.7718610763549805
Validation loss: 1.9477304816246033

Epoch: 6| Step: 2
Training loss: 0.6270186305046082
Validation loss: 1.9275681177775066

Epoch: 6| Step: 3
Training loss: 1.3806228637695312
Validation loss: 1.9575400352478027

Epoch: 6| Step: 4
Training loss: 0.48306459188461304
Validation loss: 1.9729987780253093

Epoch: 6| Step: 5
Training loss: 0.5395570397377014
Validation loss: 1.9323482314745586

Epoch: 6| Step: 6
Training loss: 0.8720821738243103
Validation loss: 1.931810160477956

Epoch: 6| Step: 7
Training loss: 0.9064618349075317
Validation loss: 1.9116183718045552

Epoch: 6| Step: 8
Training loss: 0.8650475144386292
Validation loss: 1.9285123944282532

Epoch: 6| Step: 9
Training loss: 0.6737741827964783
Validation loss: 1.9387306769688923

Epoch: 6| Step: 10
Training loss: 0.5172154903411865
Validation loss: 1.9775111675262451

Epoch: 6| Step: 11
Training loss: 1.00136399269104
Validation loss: 1.9019163052241008

Epoch: 6| Step: 12
Training loss: 0.7914434671401978
Validation loss: 1.9611302614212036

Epoch: 6| Step: 13
Training loss: 1.1311039924621582
Validation loss: 1.9625758131345112

Epoch: 171| Step: 0
Training loss: 1.3601586818695068
Validation loss: 1.9624261458714802

Epoch: 6| Step: 1
Training loss: 1.5539894104003906
Validation loss: 1.9907593925793965

Epoch: 6| Step: 2
Training loss: 0.34146249294281006
Validation loss: 1.946795920530955

Epoch: 6| Step: 3
Training loss: 0.7434989213943481
Validation loss: 1.935071070988973

Epoch: 6| Step: 4
Training loss: 0.7603756189346313
Validation loss: 1.947802186012268

Epoch: 6| Step: 5
Training loss: 0.4725172519683838
Validation loss: 1.9841471314430237

Epoch: 6| Step: 6
Training loss: 1.2490324974060059
Validation loss: 1.8860864043235779

Epoch: 6| Step: 7
Training loss: 0.8404651284217834
Validation loss: 1.961615264415741

Epoch: 6| Step: 8
Training loss: 0.7633398771286011
Validation loss: 1.9655878345171611

Epoch: 6| Step: 9
Training loss: 0.48972803354263306
Validation loss: 1.9984724124272664

Epoch: 6| Step: 10
Training loss: 0.9441301822662354
Validation loss: 1.995206594467163

Epoch: 6| Step: 11
Training loss: 0.43052804470062256
Validation loss: 1.9523889223734539

Epoch: 6| Step: 12
Training loss: 0.7159699201583862
Validation loss: 1.9663572112719219

Epoch: 6| Step: 13
Training loss: 0.42904233932495117
Validation loss: 1.9218191901842754

Epoch: 172| Step: 0
Training loss: 0.7714825868606567
Validation loss: 1.9150945742925007

Epoch: 6| Step: 1
Training loss: 0.36239415407180786
Validation loss: 1.9118494391441345

Epoch: 6| Step: 2
Training loss: 0.7444591522216797
Validation loss: 1.9364214936892192

Epoch: 6| Step: 3
Training loss: 0.42781680822372437
Validation loss: 1.9401112993558247

Epoch: 6| Step: 4
Training loss: 0.8688753843307495
Validation loss: 1.955865462621053

Epoch: 6| Step: 5
Training loss: 1.2223246097564697
Validation loss: 1.9373465180397034

Epoch: 6| Step: 6
Training loss: 1.117971420288086
Validation loss: 1.9724364678064983

Epoch: 6| Step: 7
Training loss: 0.41067710518836975
Validation loss: 1.9092010259628296

Epoch: 6| Step: 8
Training loss: 0.8513612747192383
Validation loss: 1.972719967365265

Epoch: 6| Step: 9
Training loss: 0.6515061855316162
Validation loss: 1.9258014559745789

Epoch: 6| Step: 10
Training loss: 1.0900938510894775
Validation loss: 1.9322352011998494

Epoch: 6| Step: 11
Training loss: 0.6413032412528992
Validation loss: 1.979641278584798

Epoch: 6| Step: 12
Training loss: 1.3961803913116455
Validation loss: 1.9409550229708354

Epoch: 6| Step: 13
Training loss: 0.6321169137954712
Validation loss: 1.9415459632873535

Epoch: 173| Step: 0
Training loss: 0.3962038457393646
Validation loss: 1.9432395696640015

Epoch: 6| Step: 1
Training loss: 0.656018853187561
Validation loss: 1.990919589996338

Epoch: 6| Step: 2
Training loss: 0.7822365164756775
Validation loss: 1.9158604145050049

Epoch: 6| Step: 3
Training loss: 0.9860268831253052
Validation loss: 1.9616433382034302

Epoch: 6| Step: 4
Training loss: 0.7254763245582581
Validation loss: 1.9577622810999553

Epoch: 6| Step: 5
Training loss: 0.8730205297470093
Validation loss: 1.9438932538032532

Epoch: 6| Step: 6
Training loss: 1.0666937828063965
Validation loss: 1.9385583599408467

Epoch: 6| Step: 7
Training loss: 0.47310125827789307
Validation loss: 1.9429681698481243

Epoch: 6| Step: 8
Training loss: 0.7154901027679443
Validation loss: 1.9114215175310771

Epoch: 6| Step: 9
Training loss: 1.0048125982284546
Validation loss: 1.9094273646672566

Epoch: 6| Step: 10
Training loss: 0.8924509882926941
Validation loss: 1.9407736261685689

Epoch: 6| Step: 11
Training loss: 0.6790220737457275
Validation loss: 1.935787280400594

Epoch: 6| Step: 12
Training loss: 0.8006956577301025
Validation loss: 1.9815293550491333

Epoch: 6| Step: 13
Training loss: 0.8180927634239197
Validation loss: 1.9772464632987976

Epoch: 174| Step: 0
Training loss: 0.8372540473937988
Validation loss: 2.0039638678232827

Epoch: 6| Step: 1
Training loss: 0.811301589012146
Validation loss: 1.999766727288564

Epoch: 6| Step: 2
Training loss: 0.9231811165809631
Validation loss: 1.9452950557072957

Epoch: 6| Step: 3
Training loss: 1.0059200525283813
Validation loss: 1.9508901635805767

Epoch: 6| Step: 4
Training loss: 0.6722955107688904
Validation loss: 1.9394163489341736

Epoch: 6| Step: 5
Training loss: 0.9777100086212158
Validation loss: 1.932022472222646

Epoch: 6| Step: 6
Training loss: 0.5886654853820801
Validation loss: 1.9759742816289265

Epoch: 6| Step: 7
Training loss: 0.41466379165649414
Validation loss: 1.9656480352083843

Epoch: 6| Step: 8
Training loss: 0.5224930644035339
Validation loss: 1.9453272819519043

Epoch: 6| Step: 9
Training loss: 0.7041875123977661
Validation loss: 1.9089654286702473

Epoch: 6| Step: 10
Training loss: 0.8319634795188904
Validation loss: 1.8898409803708394

Epoch: 6| Step: 11
Training loss: 1.0665650367736816
Validation loss: 2.0044315457344055

Epoch: 6| Step: 12
Training loss: 0.9111979603767395
Validation loss: 1.9573474923769634

Epoch: 6| Step: 13
Training loss: 0.7066570520401001
Validation loss: 1.9966398080190022

Epoch: 175| Step: 0
Training loss: 0.6153466701507568
Validation loss: 1.9532019297281902

Epoch: 6| Step: 1
Training loss: 0.7819404602050781
Validation loss: 1.9119869867960613

Epoch: 6| Step: 2
Training loss: 0.5934990644454956
Validation loss: 1.9006391962369282

Epoch: 6| Step: 3
Training loss: 0.45053765177726746
Validation loss: 1.8611816962560017

Epoch: 6| Step: 4
Training loss: 1.3099467754364014
Validation loss: 1.9393752415974934

Epoch: 6| Step: 5
Training loss: 1.0309510231018066
Validation loss: 1.9151081641515095

Epoch: 6| Step: 6
Training loss: 1.1645469665527344
Validation loss: 1.919476310412089

Epoch: 6| Step: 7
Training loss: 0.27553659677505493
Validation loss: 1.9166824221611023

Epoch: 6| Step: 8
Training loss: 0.6504014730453491
Validation loss: 1.8898545702298482

Epoch: 6| Step: 9
Training loss: 0.9288167953491211
Validation loss: 1.9503411650657654

Epoch: 6| Step: 10
Training loss: 0.4453910291194916
Validation loss: 2.0065345764160156

Epoch: 6| Step: 11
Training loss: 0.7773470282554626
Validation loss: 1.9525347749392192

Epoch: 6| Step: 12
Training loss: 0.3284321129322052
Validation loss: 1.9105930924415588

Epoch: 6| Step: 13
Training loss: 1.2539371252059937
Validation loss: 1.946576754252116

Testing loss: 1.843399799127373
