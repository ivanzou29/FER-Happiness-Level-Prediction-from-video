Epoch: 1| Step: 0
Training loss: 8.124487288510696
Validation loss: 7.077357549384849
Epoch: 9| Step: 1
Training loss: 7.530590994086377
Validation loss: 7.070956485851714
Epoch: 9| Step: 2
Training loss: 6.475116342802809
Validation loss: 7.073984451651078
Epoch: 9| Step: 3
Training loss: 7.508417365153972
Validation loss: 7.074019998623753
Epoch: 9| Step: 4
Training loss: 7.830620099648528
Validation loss: 7.073345364404743
Epoch: 9| Step: 5
Training loss: 7.5982911146223415
Validation loss: 7.075405156944786
Epoch: 9| Step: 6
Training loss: 7.9229706678038925
Validation loss: 7.069211620613203
Epoch: 9| Step: 7
Training loss: 7.501564371354693
Validation loss: 7.061161015605927
Epoch: 9| Step: 8
Training loss: 7.477679799939931
Validation loss: 7.074893728896787
Epoch: 9| Step: 9
Training loss: 8.35979116954709
Validation loss: 7.065662034483936
Epoch: 9| Step: 10
Training loss: 6.9455316463949845
Validation loss: 7.063704885197594
Epoch: 9| Step: 11
Training loss: 6.290336148205585
Validation loss: 7.072578203482758
Epoch: 9| Step: 12
Training loss: 6.343058430977052
Validation loss: 7.05299879651779
Epoch: 9| Step: 13
Training loss: 6.531384334369108
Validation loss: 7.067253486975806
Epoch: 9| Step: 14
Training loss: 7.7622333081514485
Validation loss: 7.064391873991562
Epoch: 9| Step: 15
Training loss: 6.933155796027678
Validation loss: 7.05471457204968
Epoch: 9| Step: 16
Training loss: 7.479327130168085
Validation loss: 7.0500460717808515
Epoch: 9| Step: 17
Training loss: 7.237601893206809
Validation loss: 7.06248617096685
Epoch: 9| Step: 18
Training loss: 8.309193347840504
Validation loss: 7.065223528204542
Epoch: 9| Step: 19
Training loss: 7.155385860592344
Validation loss: 7.03652702984654
Epoch: 2| Step: 0
Training loss: 6.280785994211085
Validation loss: 7.053816792989361
Epoch: 9| Step: 1
Training loss: 7.2605493023513725
Validation loss: 7.032612649331276
Epoch: 9| Step: 2
Training loss: 7.121947588347718
Validation loss: 7.058709458042968
Epoch: 9| Step: 3
Training loss: 7.664998688520405
Validation loss: 7.057349810100312
Epoch: 9| Step: 4
Training loss: 8.147962313115901
Validation loss: 7.052810051654872
Epoch: 9| Step: 5
Training loss: 7.721365419908185
Validation loss: 7.046569071765929
Epoch: 9| Step: 6
Training loss: 7.573265798742207
Validation loss: 7.041076065163273
Epoch: 9| Step: 7
Training loss: 5.934591444265693
Validation loss: 7.053152366191254
Epoch: 9| Step: 8
Training loss: 7.280554218365694
Validation loss: 7.042092980818948
Epoch: 9| Step: 9
Training loss: 7.137473982514698
Validation loss: 7.0421016510399
Epoch: 9| Step: 10
Training loss: 7.942681971438493
Validation loss: 7.044990402269102
Epoch: 9| Step: 11
Training loss: 7.264347218369535
Validation loss: 7.054711856012829
Epoch: 9| Step: 12
Training loss: 7.5853581781881765
Validation loss: 7.043885023618479
Epoch: 9| Step: 13
Training loss: 7.78539879435903
Validation loss: 7.037234376190826
Epoch: 9| Step: 14
Training loss: 8.041019183036012
Validation loss: 7.039295795358189
Epoch: 9| Step: 15
Training loss: 6.677607269282421
Validation loss: 7.035812906318601
Epoch: 9| Step: 16
Training loss: 7.912310663401665
Validation loss: 7.04087632472882
Epoch: 9| Step: 17
Training loss: 8.02345699319078
Validation loss: 7.041645328114504
Epoch: 9| Step: 18
Training loss: 6.991725390630576
Validation loss: 7.0460452649973995
Epoch: 9| Step: 19
Training loss: 6.664657512544923
Validation loss: 7.041409305917967
Epoch: 3| Step: 0
Training loss: 7.761627826436493
Validation loss: 7.050402621176052
Epoch: 9| Step: 1
Training loss: 7.4345163723947945
Validation loss: 7.03222805292857
Epoch: 9| Step: 2
Training loss: 8.44086937209882
Validation loss: 7.0397899881815365
Epoch: 9| Step: 3
Training loss: 7.512163090569613
Validation loss: 7.040790040179561
Epoch: 9| Step: 4
Training loss: 6.645993349387107
Validation loss: 7.037803982845066
Epoch: 9| Step: 5
Training loss: 7.894215709150444
Validation loss: 7.0312829066406985
Epoch: 9| Step: 6
Training loss: 8.40460347780552
Validation loss: 7.03606995712782
Epoch: 9| Step: 7
Training loss: 6.201590475536863
Validation loss: 7.028637984684682
Epoch: 9| Step: 8
Training loss: 6.576034684955241
Validation loss: 6.998244708034723
Epoch: 9| Step: 9
Training loss: 7.2438733752772615
Validation loss: 7.027041071382272
Epoch: 9| Step: 10
Training loss: 7.699546741174525
Validation loss: 7.014687030634247
Epoch: 9| Step: 11
Training loss: 8.140737463234673
Validation loss: 7.026286006674692
Epoch: 9| Step: 12
Training loss: 6.535603363739648
Validation loss: 7.019664727281341
Epoch: 9| Step: 13
Training loss: 6.815736614224645
Validation loss: 7.026788061679236
Epoch: 9| Step: 14
Training loss: 8.271112419691784
Validation loss: 7.019846918071009
Epoch: 9| Step: 15
Training loss: 6.891608135646752
Validation loss: 7.019870994436036
Epoch: 9| Step: 16
Training loss: 5.934006476346998
Validation loss: 7.024575123320651
Epoch: 9| Step: 17
Training loss: 6.920096623181639
Validation loss: 6.997706010709847
Epoch: 9| Step: 18
Training loss: 7.359535166947377
Validation loss: 7.020465919576193
Epoch: 9| Step: 19
Training loss: 7.657219027484017
Validation loss: 7.010362507224834
Epoch: 4| Step: 0
Training loss: 7.094617345275142
Validation loss: 6.9946230690382025
Epoch: 9| Step: 1
Training loss: 7.601730611418311
Validation loss: 7.012293223875051
Epoch: 9| Step: 2
Training loss: 7.224780185615944
Validation loss: 7.010483319148758
Epoch: 9| Step: 3
Training loss: 7.208630094501692
Validation loss: 7.010718548248101
Epoch: 9| Step: 4
Training loss: 7.8471057294302735
Validation loss: 7.005056236586632
Epoch: 9| Step: 5
Training loss: 6.578748369921599
Validation loss: 7.002464219258946
Epoch: 9| Step: 6
Training loss: 7.326695414594645
Validation loss: 7.001936573827434
Epoch: 9| Step: 7
Training loss: 8.298488194305946
Validation loss: 6.994082881975175
Epoch: 9| Step: 8
Training loss: 6.772020097066189
Validation loss: 6.982585368416674
Epoch: 9| Step: 9
Training loss: 8.243348185454781
Validation loss: 6.988206120162892
Epoch: 9| Step: 10
Training loss: 6.791789359952276
Validation loss: 6.9964630612587495
Epoch: 9| Step: 11
Training loss: 7.850365755343873
Validation loss: 6.997131968025004
Epoch: 9| Step: 12
Training loss: 7.462073498268071
Validation loss: 6.976413371164359
Epoch: 9| Step: 13
Training loss: 6.653762567520098
Validation loss: 6.993803711257143
Epoch: 9| Step: 14
Training loss: 7.4195799802778755
Validation loss: 6.983097866586268
Epoch: 9| Step: 15
Training loss: 6.729493250367243
Validation loss: 6.982242626098242
Epoch: 9| Step: 16
Training loss: 6.523495391771565
Validation loss: 6.9729789670939075
Epoch: 9| Step: 17
Training loss: 7.786544285600711
Validation loss: 6.97629887139373
Epoch: 9| Step: 18
Training loss: 6.6512532709605106
Validation loss: 6.98863692056049
Epoch: 9| Step: 19
Training loss: 7.918665128402102
Validation loss: 6.982442085300143
Epoch: 5| Step: 0
Training loss: 7.672590979828783
Validation loss: 6.984542930576481
Epoch: 9| Step: 1
Training loss: 7.457084963301836
Validation loss: 6.950849709429261
Epoch: 9| Step: 2
Training loss: 6.988678086657432
Validation loss: 6.972130040862385
Epoch: 9| Step: 3
Training loss: 8.080394197422684
Validation loss: 6.9688434544356985
Epoch: 9| Step: 4
Training loss: 7.407576172636902
Validation loss: 6.975418680095741
Epoch: 9| Step: 5
Training loss: 5.931900435740726
Validation loss: 6.964617037285853
Epoch: 9| Step: 6
Training loss: 7.782715196045266
Validation loss: 6.94637167512574
Epoch: 9| Step: 7
Training loss: 6.211578067399809
Validation loss: 6.942329205748047
Epoch: 9| Step: 8
Training loss: 7.653677870320056
Validation loss: 6.957591815299565
Epoch: 9| Step: 9
Training loss: 7.029764925633571
Validation loss: 6.95764941651314
Epoch: 9| Step: 10
Training loss: 8.063870099187021
Validation loss: 6.967239712475349
Epoch: 9| Step: 11
Training loss: 7.923326468437322
Validation loss: 6.940148503591252
Epoch: 9| Step: 12
Training loss: 5.554289169086187
Validation loss: 6.955902748728729
Epoch: 9| Step: 13
Training loss: 8.300620402853369
Validation loss: 6.949070803736275
Epoch: 9| Step: 14
Training loss: 7.2332216995461405
Validation loss: 6.937638594905154
Epoch: 9| Step: 15
Training loss: 7.108809429770154
Validation loss: 6.954832817843935
Epoch: 9| Step: 16
Training loss: 8.402622957791262
Validation loss: 6.94142136998782
Epoch: 9| Step: 17
Training loss: 6.6951082392084444
Validation loss: 6.939783331016642
Epoch: 9| Step: 18
Training loss: 6.59315755632307
Validation loss: 6.944813506614924
Epoch: 9| Step: 19
Training loss: 6.7745944644289
Validation loss: 6.928566982661059
Epoch: 6| Step: 0
Training loss: 7.519545961836258
Validation loss: 6.926731099203498
Epoch: 9| Step: 1
Training loss: 7.601413956667865
Validation loss: 6.916605615895721
Epoch: 9| Step: 2
Training loss: 7.251048045207414
Validation loss: 6.926477849528189
Epoch: 9| Step: 3
Training loss: 7.060968553711588
Validation loss: 6.933949072028979
Epoch: 9| Step: 4
Training loss: 7.757557291402657
Validation loss: 6.927087459438763
Epoch: 9| Step: 5
Training loss: 6.933554137210787
Validation loss: 6.914434405062785
Epoch: 9| Step: 6
Training loss: 6.544221836629736
Validation loss: 6.925433568064772
Epoch: 9| Step: 7
Training loss: 6.962001663536568
Validation loss: 6.918159004542442
Epoch: 9| Step: 8
Training loss: 7.2324181828913074
Validation loss: 6.9085580919564125
Epoch: 9| Step: 9
Training loss: 7.624398129582355
Validation loss: 6.925989409416486
Epoch: 9| Step: 10
Training loss: 6.32480562537146
Validation loss: 6.908893679352949
Epoch: 9| Step: 11
Training loss: 7.3413863903271075
Validation loss: 6.905155991664375
Epoch: 9| Step: 12
Training loss: 6.796828977933271
Validation loss: 6.9028734028047785
Epoch: 9| Step: 13
Training loss: 8.101328479473242
Validation loss: 6.910987466258209
Epoch: 9| Step: 14
Training loss: 7.574026356182069
Validation loss: 6.88771164455763
Epoch: 9| Step: 15
Training loss: 7.121850103826055
Validation loss: 6.904472627332621
Epoch: 9| Step: 16
Training loss: 7.536020880927377
Validation loss: 6.895171933170027
Epoch: 9| Step: 17
Training loss: 7.701312302565104
Validation loss: 6.896128134877796
Epoch: 9| Step: 18
Training loss: 7.011674138089276
Validation loss: 6.89533435542266
Epoch: 9| Step: 19
Training loss: 6.612205963231584
Validation loss: 6.902410039936645
Epoch: 7| Step: 0
Training loss: 6.479515663225182
Validation loss: 6.894150371160822
Epoch: 9| Step: 1
Training loss: 7.977811560504665
Validation loss: 6.888527512980543
Epoch: 9| Step: 2
Training loss: 7.253622794172352
Validation loss: 6.884339672137002
Epoch: 9| Step: 3
Training loss: 6.839018836785168
Validation loss: 6.885055960969592
Epoch: 9| Step: 4
Training loss: 6.598666559245695
Validation loss: 6.875270772974432
Epoch: 9| Step: 5
Training loss: 7.041995370028577
Validation loss: 6.878309906876876
Epoch: 9| Step: 6
Training loss: 7.5697057774157
Validation loss: 6.878930937913309
Epoch: 9| Step: 7
Training loss: 8.487458794427775
Validation loss: 6.8783775518272225
Epoch: 9| Step: 8
Training loss: 6.808141591591082
Validation loss: 6.8596568714981005
Epoch: 9| Step: 9
Training loss: 7.563132015332514
Validation loss: 6.880870764983113
Epoch: 9| Step: 10
Training loss: 6.7095117264538615
Validation loss: 6.8681652985722215
Epoch: 9| Step: 11
Training loss: 7.696370783036669
Validation loss: 6.871008863312665
Epoch: 9| Step: 12
Training loss: 7.561203017818008
Validation loss: 6.858569368077249
Epoch: 9| Step: 13
Training loss: 7.310666107012593
Validation loss: 6.861537069405751
Epoch: 9| Step: 14
Training loss: 7.317735672398515
Validation loss: 6.842303978212712
Epoch: 9| Step: 15
Training loss: 7.374366345096996
Validation loss: 6.848534913037498
Epoch: 9| Step: 16
Training loss: 6.251375581044019
Validation loss: 6.848588418853283
Epoch: 9| Step: 17
Training loss: 6.057062916086772
Validation loss: 6.856905133061823
Epoch: 9| Step: 18
Training loss: 6.945292177803508
Validation loss: 6.847792068168668
Epoch: 9| Step: 19
Training loss: 7.661904998628462
Validation loss: 6.850415759971957
Epoch: 8| Step: 0
Training loss: 8.226796203945373
Validation loss: 6.83365074059711
Epoch: 9| Step: 1
Training loss: 6.926838148170999
Validation loss: 6.842657932734733
Epoch: 9| Step: 2
Training loss: 6.881943404266796
Validation loss: 6.840336737930826
Epoch: 9| Step: 3
Training loss: 7.577728827434306
Validation loss: 6.8226151985724455
Epoch: 9| Step: 4
Training loss: 6.697313470410898
Validation loss: 6.840303186166295
Epoch: 9| Step: 5
Training loss: 7.107253342842487
Validation loss: 6.822265184150441
Epoch: 9| Step: 6
Training loss: 5.510880545096602
Validation loss: 6.819076248247927
Epoch: 9| Step: 7
Training loss: 8.071448276654868
Validation loss: 6.810846564307569
Epoch: 9| Step: 8
Training loss: 6.999793185857379
Validation loss: 6.825753587863697
Epoch: 9| Step: 9
Training loss: 6.54497870247263
Validation loss: 6.826510162553353
Epoch: 9| Step: 10
Training loss: 7.376023819543604
Validation loss: 6.8002338596745435
Epoch: 9| Step: 11
Training loss: 7.198831399814085
Validation loss: 6.802992555163633
Epoch: 9| Step: 12
Training loss: 8.340444760252785
Validation loss: 6.806615518383998
Epoch: 9| Step: 13
Training loss: 6.786203289338488
Validation loss: 6.796491604139775
Epoch: 9| Step: 14
Training loss: 6.590083399984404
Validation loss: 6.790857322944506
Epoch: 9| Step: 15
Training loss: 6.703791374037612
Validation loss: 6.805749800094361
Epoch: 9| Step: 16
Training loss: 7.31457672625875
Validation loss: 6.785274123777038
Epoch: 9| Step: 17
Training loss: 6.013015934306236
Validation loss: 6.787702121445203
Epoch: 9| Step: 18
Training loss: 6.527839025476141
Validation loss: 6.780482919529121
Epoch: 9| Step: 19
Training loss: 8.676346239623234
Validation loss: 6.754480104519968
Epoch: 9| Step: 0
Training loss: 7.282546554191387
Validation loss: 6.7628413495856785
Epoch: 9| Step: 1
Training loss: 6.432454622703881
Validation loss: 6.7734244088266875
Epoch: 9| Step: 2
Training loss: 6.9704927053033705
Validation loss: 6.780580063900303
Epoch: 9| Step: 3
Training loss: 7.998263647474476
Validation loss: 6.75706462508903
Epoch: 9| Step: 4
Training loss: 7.0987009928671325
Validation loss: 6.76500573440151
Epoch: 9| Step: 5
Training loss: 7.455442696007865
Validation loss: 6.76764648101108
Epoch: 9| Step: 6
Training loss: 6.9289145742846605
Validation loss: 6.762776242546748
Epoch: 9| Step: 7
Training loss: 7.259445877156146
Validation loss: 6.769169284804605
Epoch: 9| Step: 8
Training loss: 5.720775474854035
Validation loss: 6.763277344005831
Epoch: 9| Step: 9
Training loss: 6.820512451876411
Validation loss: 6.752359016162685
Epoch: 9| Step: 10
Training loss: 5.824833735765889
Validation loss: 6.7589939875360106
Epoch: 9| Step: 11
Training loss: 7.908238096906496
Validation loss: 6.750417448604254
Epoch: 9| Step: 12
Training loss: 7.171903722368956
Validation loss: 6.738382162919527
Epoch: 9| Step: 13
Training loss: 7.249870562220081
Validation loss: 6.7383868819757495
Epoch: 9| Step: 14
Training loss: 7.419747330715525
Validation loss: 6.727355435292966
Epoch: 9| Step: 15
Training loss: 7.842182625941776
Validation loss: 6.730162295716986
Epoch: 9| Step: 16
Training loss: 7.419773808242305
Validation loss: 6.71927944207619
Epoch: 9| Step: 17
Training loss: 6.197636479901973
Validation loss: 6.72073392566273
Epoch: 9| Step: 18
Training loss: 7.430137773060481
Validation loss: 6.70432653190139
Epoch: 9| Step: 19
Training loss: 6.79672851404647
Validation loss: 6.715990185821935
Epoch: 10| Step: 0
Training loss: 6.545458947767838
Validation loss: 6.708628641213732
Epoch: 9| Step: 1
Training loss: 6.5351127627625125
Validation loss: 6.717032460247175
Epoch: 9| Step: 2
Training loss: 6.450059213292578
Validation loss: 6.7021195076404245
Epoch: 9| Step: 3
Training loss: 7.012409110338737
Validation loss: 6.71517667248324
Epoch: 9| Step: 4
Training loss: 7.570258078364758
Validation loss: 6.708664219944169
Epoch: 9| Step: 5
Training loss: 7.162154381420494
Validation loss: 6.683146539969414
Epoch: 9| Step: 6
Training loss: 7.296023856274603
Validation loss: 6.690641623156479
Epoch: 9| Step: 7
Training loss: 6.10400466790777
Validation loss: 6.690687913505067
Epoch: 9| Step: 8
Training loss: 7.462001161500078
Validation loss: 6.670949113876922
Epoch: 9| Step: 9
Training loss: 7.372258598175929
Validation loss: 6.690556629696894
Epoch: 9| Step: 10
Training loss: 7.088189050189793
Validation loss: 6.690424854208433
Epoch: 9| Step: 11
Training loss: 6.397163608974702
Validation loss: 6.678445735797579
Epoch: 9| Step: 12
Training loss: 7.3061430597759385
Validation loss: 6.670599302998021
Epoch: 9| Step: 13
Training loss: 6.332340597683321
Validation loss: 6.672577274995746
Epoch: 9| Step: 14
Training loss: 7.455540679421564
Validation loss: 6.660502703465531
Epoch: 9| Step: 15
Training loss: 7.109992031946023
Validation loss: 6.657659686708689
Epoch: 9| Step: 16
Training loss: 7.9698516682566725
Validation loss: 6.666301633167605
Epoch: 9| Step: 17
Training loss: 6.750562291213866
Validation loss: 6.652406856783109
Epoch: 9| Step: 18
Training loss: 7.118137735859019
Validation loss: 6.6554463068376535
Epoch: 9| Step: 19
Training loss: 7.064063515227477
Validation loss: 6.649038595591583
Epoch: 11| Step: 0
Training loss: 6.957192729123293
Validation loss: 6.62636879046609
Epoch: 9| Step: 1
Training loss: 7.13079865721548
Validation loss: 6.630173685497532
Epoch: 9| Step: 2
Training loss: 6.124649972061541
Validation loss: 6.640809260464499
Epoch: 9| Step: 3
Training loss: 6.2332184371286825
Validation loss: 6.629679197113066
Epoch: 9| Step: 4
Training loss: 6.996646077618134
Validation loss: 6.622576092976075
Epoch: 9| Step: 5
Training loss: 6.6801769054995495
Validation loss: 6.62841991487918
Epoch: 9| Step: 6
Training loss: 6.363035755796208
Validation loss: 6.616696287650677
Epoch: 9| Step: 7
Training loss: 8.587072156884386
Validation loss: 6.627212202540014
Epoch: 9| Step: 8
Training loss: 6.857513383663856
Validation loss: 6.602714014374009
Epoch: 9| Step: 9
Training loss: 7.758508748967968
Validation loss: 6.618931407739308
Epoch: 9| Step: 10
Training loss: 6.1235589648301705
Validation loss: 6.612859365475027
Epoch: 9| Step: 11
Training loss: 6.769156787374669
Validation loss: 6.588567003270587
Epoch: 9| Step: 12
Training loss: 6.615340190049044
Validation loss: 6.606973219167047
Epoch: 9| Step: 13
Training loss: 7.379622740161544
Validation loss: 6.597348357401306
Epoch: 9| Step: 14
Training loss: 7.623122187288107
Validation loss: 6.578839126394502
Epoch: 9| Step: 15
Training loss: 6.541478375035316
Validation loss: 6.5834466991612395
Epoch: 9| Step: 16
Training loss: 8.278395365889718
Validation loss: 6.56236570839866
Epoch: 9| Step: 17
Training loss: 6.2471447335384624
Validation loss: 6.572304014440281
Epoch: 9| Step: 18
Training loss: 6.897257339948725
Validation loss: 6.5803295718437775
Epoch: 9| Step: 19
Training loss: 6.1619657520901265
Validation loss: 6.5672851936500525
Epoch: 12| Step: 0
Training loss: 8.19887585261431
Validation loss: 6.545401170998277
Epoch: 9| Step: 1
Training loss: 6.247997726146953
Validation loss: 6.553651448676973
Epoch: 9| Step: 2
Training loss: 7.673235304554559
Validation loss: 6.546629967989913
Epoch: 9| Step: 3
Training loss: 6.115042240873404
Validation loss: 6.540822331559738
Epoch: 9| Step: 4
Training loss: 5.637979071787693
Validation loss: 6.530597445416165
Epoch: 9| Step: 5
Training loss: 7.247531865376546
Validation loss: 6.52603778440261
Epoch: 9| Step: 6
Training loss: 6.761813528365213
Validation loss: 6.534855662594494
Epoch: 9| Step: 7
Training loss: 7.088794742040101
Validation loss: 6.531142137393314
Epoch: 9| Step: 8
Training loss: 7.337292238377685
Validation loss: 6.525045962643671
Epoch: 9| Step: 9
Training loss: 5.946978903186993
Validation loss: 6.536299084850389
Epoch: 9| Step: 10
Training loss: 5.922620258390508
Validation loss: 6.5164517932908215
Epoch: 9| Step: 11
Training loss: 6.937614921099112
Validation loss: 6.512438740229425
Epoch: 9| Step: 12
Training loss: 6.568755737650622
Validation loss: 6.506807862970865
Epoch: 9| Step: 13
Training loss: 6.321427481514973
Validation loss: 6.519430093416827
Epoch: 9| Step: 14
Training loss: 7.556212530682147
Validation loss: 6.511496311053875
Epoch: 9| Step: 15
Training loss: 6.86939135569202
Validation loss: 6.50684354901235
Epoch: 9| Step: 16
Training loss: 7.568129028752721
Validation loss: 6.495847428062495
Epoch: 9| Step: 17
Training loss: 6.8070096631486585
Validation loss: 6.490224915894771
Epoch: 9| Step: 18
Training loss: 6.419547817194455
Validation loss: 6.480679534460078
Epoch: 9| Step: 19
Training loss: 7.425423185574226
Validation loss: 6.472653459843059
Epoch: 13| Step: 0
Training loss: 6.644886041012809
Validation loss: 6.477591069327429
Epoch: 9| Step: 1
Training loss: 7.568132305061406
Validation loss: 6.474128667094147
Epoch: 9| Step: 2
Training loss: 6.335308904545667
Validation loss: 6.466569330239839
Epoch: 9| Step: 3
Training loss: 7.241020166169612
Validation loss: 6.455376108271317
Epoch: 9| Step: 4
Training loss: 6.04119085433299
Validation loss: 6.4471940340630445
Epoch: 9| Step: 5
Training loss: 6.522623744622712
Validation loss: 6.458734800382873
Epoch: 9| Step: 6
Training loss: 6.732601489843649
Validation loss: 6.448536622246678
Epoch: 9| Step: 7
Training loss: 7.0662658913644725
Validation loss: 6.4340517168368025
Epoch: 9| Step: 8
Training loss: 7.800304935070047
Validation loss: 6.441732723629686
Epoch: 9| Step: 9
Training loss: 6.563633412168594
Validation loss: 6.430070390804137
Epoch: 9| Step: 10
Training loss: 6.365848330221111
Validation loss: 6.420360517095071
Epoch: 9| Step: 11
Training loss: 7.18976112955762
Validation loss: 6.427705104906744
Epoch: 9| Step: 12
Training loss: 7.215591069765802
Validation loss: 6.398384085198987
Epoch: 9| Step: 13
Training loss: 6.29399251158117
Validation loss: 6.420945073828923
Epoch: 9| Step: 14
Training loss: 6.71100969020398
Validation loss: 6.401952370061648
Epoch: 9| Step: 15
Training loss: 6.042237072907256
Validation loss: 6.401352041053879
Epoch: 9| Step: 16
Training loss: 7.1693722548806695
Validation loss: 6.399815612586138
Epoch: 9| Step: 17
Training loss: 5.930837004646443
Validation loss: 6.377851799101218
Epoch: 9| Step: 18
Training loss: 6.556130651618663
Validation loss: 6.388990942233886
Epoch: 9| Step: 19
Training loss: 7.177593801769722
Validation loss: 6.375592546730971
Epoch: 14| Step: 0
Training loss: 7.481213501193469
Validation loss: 6.354380333032107
Epoch: 9| Step: 1
Training loss: 7.076695582072761
Validation loss: 6.368540220569747
Epoch: 9| Step: 2
Training loss: 6.604130533241879
Validation loss: 6.369473797046984
Epoch: 9| Step: 3
Training loss: 6.391951220501721
Validation loss: 6.36063667402605
Epoch: 9| Step: 4
Training loss: 4.948451198682985
Validation loss: 6.361967065632864
Epoch: 9| Step: 5
Training loss: 6.632433481698867
Validation loss: 6.344006357254919
Epoch: 9| Step: 6
Training loss: 7.757739232880356
Validation loss: 6.343778371849652
Epoch: 9| Step: 7
Training loss: 7.018066253375468
Validation loss: 6.33895243301131
Epoch: 9| Step: 8
Training loss: 6.171255655237813
Validation loss: 6.317558240712059
Epoch: 9| Step: 9
Training loss: 6.993191268733735
Validation loss: 6.332448030677301
Epoch: 9| Step: 10
Training loss: 6.368074732087951
Validation loss: 6.280429753979781
Epoch: 9| Step: 11
Training loss: 6.402679192516611
Validation loss: 6.320699327854419
Epoch: 9| Step: 12
Training loss: 6.638861208777757
Validation loss: 6.30439206516581
Epoch: 9| Step: 13
Training loss: 6.06450501940357
Validation loss: 6.286716114580685
Epoch: 9| Step: 14
Training loss: 6.394453697223673
Validation loss: 6.304180252045006
Epoch: 9| Step: 15
Training loss: 7.435617417005148
Validation loss: 6.2803864275578105
Epoch: 9| Step: 16
Training loss: 6.66133203056166
Validation loss: 6.30038780987752
Epoch: 9| Step: 17
Training loss: 6.214643953517703
Validation loss: 6.257135275264095
Epoch: 9| Step: 18
Training loss: 7.4721590186766385
Validation loss: 6.270404825428004
Epoch: 9| Step: 19
Training loss: 6.007197196018745
Validation loss: 6.262092276766217
Epoch: 15| Step: 0
Training loss: 5.864435965367388
Validation loss: 6.257796263352277
Epoch: 9| Step: 1
Training loss: 6.574503647087467
Validation loss: 6.236093439882922
Epoch: 9| Step: 2
Training loss: 6.73403795288376
Validation loss: 6.239429120929287
Epoch: 9| Step: 3
Training loss: 6.958042831600472
Validation loss: 6.232987683519471
Epoch: 9| Step: 4
Training loss: 6.67356833202647
Validation loss: 6.188827882455493
Epoch: 9| Step: 5
Training loss: 5.681884005078595
Validation loss: 6.210508366699063
Epoch: 9| Step: 6
Training loss: 6.830849669122315
Validation loss: 6.210666851367839
Epoch: 9| Step: 7
Training loss: 7.3236827928903985
Validation loss: 6.195806502022714
Epoch: 9| Step: 8
Training loss: 6.485806741409588
Validation loss: 6.206264002288901
Epoch: 9| Step: 9
Training loss: 7.226468010361988
Validation loss: 6.189271768160567
Epoch: 9| Step: 10
Training loss: 7.074619932716019
Validation loss: 6.16818447360656
Epoch: 9| Step: 11
Training loss: 5.28710215990457
Validation loss: 6.180563765209691
Epoch: 9| Step: 12
Training loss: 6.380380491671783
Validation loss: 6.166153634401807
Epoch: 9| Step: 13
Training loss: 6.158981724090887
Validation loss: 6.162716067846795
Epoch: 9| Step: 14
Training loss: 6.281605269220662
Validation loss: 6.13115279321555
Epoch: 9| Step: 15
Training loss: 6.955214968553385
Validation loss: 6.121697725328801
Epoch: 9| Step: 16
Training loss: 7.11283612521339
Validation loss: 6.140302564530867
Epoch: 9| Step: 17
Training loss: 5.911272123879816
Validation loss: 6.129464951609908
Epoch: 9| Step: 18
Training loss: 6.5383793372601255
Validation loss: 6.1286718390781685
Epoch: 9| Step: 19
Training loss: 6.173154596881724
Validation loss: 6.08032119920177
Epoch: 16| Step: 0
Training loss: 7.032380009023161
Validation loss: 6.09026599333182
Epoch: 9| Step: 1
Training loss: 6.3961560626621425
Validation loss: 6.09300975493352
Epoch: 9| Step: 2
Training loss: 5.82989785891744
Validation loss: 6.061400459336312
Epoch: 9| Step: 3
Training loss: 6.194743530777475
Validation loss: 6.046986662218304
Epoch: 9| Step: 4
Training loss: 6.145797298347306
Validation loss: 6.07399560948316
Epoch: 9| Step: 5
Training loss: 6.581438331046725
Validation loss: 6.054366000833168
Epoch: 9| Step: 6
Training loss: 5.6917427083972925
Validation loss: 6.038859648664257
Epoch: 9| Step: 7
Training loss: 5.785203066783895
Validation loss: 6.0320021213087225
Epoch: 9| Step: 8
Training loss: 6.296670839393462
Validation loss: 6.027109917776224
Epoch: 9| Step: 9
Training loss: 7.527973902901342
Validation loss: 6.0189599861527965
Epoch: 9| Step: 10
Training loss: 7.584433283697819
Validation loss: 5.989104998904131
Epoch: 9| Step: 11
Training loss: 6.060981481657579
Validation loss: 5.97846613317643
Epoch: 9| Step: 12
Training loss: 5.8121147438269105
Validation loss: 5.982104085733189
Epoch: 9| Step: 13
Training loss: 5.422978093838292
Validation loss: 5.956168474440266
Epoch: 9| Step: 14
Training loss: 6.964430766289338
Validation loss: 5.965080066892468
Epoch: 9| Step: 15
Training loss: 6.350430283273319
Validation loss: 5.956955183224742
Epoch: 9| Step: 16
Training loss: 7.31958447136831
Validation loss: 5.9531203232399115
Epoch: 9| Step: 17
Training loss: 6.016312359269328
Validation loss: 5.9361268019816045
Epoch: 9| Step: 18
Training loss: 5.170457536237311
Validation loss: 5.932205031622255
Epoch: 9| Step: 19
Training loss: 6.422781998563724
Validation loss: 5.910464902820441
Epoch: 17| Step: 0
Training loss: 6.385401598698405
Validation loss: 5.889292469345446
Epoch: 9| Step: 1
Training loss: 6.7584664265438725
Validation loss: 5.8837776597187545
Epoch: 9| Step: 2
Training loss: 5.996610001696889
Validation loss: 5.8826310728949185
Epoch: 9| Step: 3
Training loss: 7.413304055977145
Validation loss: 5.874744913884941
Epoch: 9| Step: 4
Training loss: 5.328028345210194
Validation loss: 5.852884032635325
Epoch: 9| Step: 5
Training loss: 7.233537596647257
Validation loss: 5.845722627953245
Epoch: 9| Step: 6
Training loss: 6.615702889280796
Validation loss: 5.830614136819708
Epoch: 9| Step: 7
Training loss: 7.232195334269349
Validation loss: 5.839451208043479
Epoch: 9| Step: 8
Training loss: 5.696355276836357
Validation loss: 5.815059199878869
Epoch: 9| Step: 9
Training loss: 5.207334539648139
Validation loss: 5.819416411850855
Epoch: 9| Step: 10
Training loss: 5.90438635755464
Validation loss: 5.780670338716338
Epoch: 9| Step: 11
Training loss: 6.27930082377403
Validation loss: 5.785861862170512
Epoch: 9| Step: 12
Training loss: 6.056404746394385
Validation loss: 5.753836580468217
Epoch: 9| Step: 13
Training loss: 6.419986345032998
Validation loss: 5.7477742700511385
Epoch: 9| Step: 14
Training loss: 5.13210845717299
Validation loss: 5.737932933523723
Epoch: 9| Step: 15
Training loss: 5.652732809368521
Validation loss: 5.7343405357038035
Epoch: 9| Step: 16
Training loss: 7.09610282429509
Validation loss: 5.722779582410884
Epoch: 9| Step: 17
Training loss: 5.161543100265978
Validation loss: 5.713316009729074
Epoch: 9| Step: 18
Training loss: 5.468794642674928
Validation loss: 5.682834606561113
Epoch: 9| Step: 19
Training loss: 5.8328285362172405
Validation loss: 5.701584952107002
Epoch: 18| Step: 0
Training loss: 6.229001590578516
Validation loss: 5.664224665883427
Epoch: 9| Step: 1
Training loss: 6.153895203688353
Validation loss: 5.649343540344189
Epoch: 9| Step: 2
Training loss: 5.511039924589101
Validation loss: 5.6180676844591115
Epoch: 9| Step: 3
Training loss: 5.827753213677742
Validation loss: 5.614556367494447
Epoch: 9| Step: 4
Training loss: 6.278686000126427
Validation loss: 5.627117271989923
Epoch: 9| Step: 5
Training loss: 5.271068623031855
Validation loss: 5.563656014161289
Epoch: 9| Step: 6
Training loss: 6.1698733403638695
Validation loss: 5.5758152502697245
Epoch: 9| Step: 7
Training loss: 6.255587712158764
Validation loss: 5.571042202272878
Epoch: 9| Step: 8
Training loss: 6.807498320692446
Validation loss: 5.572349423846248
Epoch: 9| Step: 9
Training loss: 5.4908443886919684
Validation loss: 5.531608256970094
Epoch: 9| Step: 10
Training loss: 6.13923485626355
Validation loss: 5.541317468637789
Epoch: 9| Step: 11
Training loss: 5.492803720820006
Validation loss: 5.515753057602627
Epoch: 9| Step: 12
Training loss: 5.877817979629869
Validation loss: 5.510956314760837
Epoch: 9| Step: 13
Training loss: 5.526360888763198
Validation loss: 5.481316567071064
Epoch: 9| Step: 14
Training loss: 5.680657599086275
Validation loss: 5.457391906953023
Epoch: 9| Step: 15
Training loss: 5.8706733517567935
Validation loss: 5.463771283421557
Epoch: 9| Step: 16
Training loss: 5.571872829708547
Validation loss: 5.451672990507434
Epoch: 9| Step: 17
Training loss: 5.937017481421714
Validation loss: 5.412580795690373
Epoch: 9| Step: 18
Training loss: 6.006301114344158
Validation loss: 5.421505167980448
Epoch: 9| Step: 19
Training loss: 6.064019396224996
Validation loss: 5.387188772083577
Epoch: 19| Step: 0
Training loss: 5.851163516938586
Validation loss: 5.347484872836502
Epoch: 9| Step: 1
Training loss: 5.6610734300458505
Validation loss: 5.350820258336517
Epoch: 9| Step: 2
Training loss: 4.886137149392737
Validation loss: 5.33904182314317
Epoch: 9| Step: 3
Training loss: 5.375599317627909
Validation loss: 5.307900316638118
Epoch: 9| Step: 4
Training loss: 4.625093613785487
Validation loss: 5.3069537131687055
Epoch: 9| Step: 5
Training loss: 6.383753134101321
Validation loss: 5.30055004305578
Epoch: 9| Step: 6
Training loss: 5.489946714048845
Validation loss: 5.281152519008133
Epoch: 9| Step: 7
Training loss: 5.861871863837257
Validation loss: 5.290410266179359
Epoch: 9| Step: 8
Training loss: 5.4526709774728035
Validation loss: 5.230437748571811
Epoch: 9| Step: 9
Training loss: 6.622319092920321
Validation loss: 5.217453084899361
Epoch: 9| Step: 10
Training loss: 5.3210065167750455
Validation loss: 5.1930875266043435
Epoch: 9| Step: 11
Training loss: 6.008506784391291
Validation loss: 5.148082567862692
Epoch: 9| Step: 12
Training loss: 5.8576377632980705
Validation loss: 5.140650801734847
Epoch: 9| Step: 13
Training loss: 5.746506666418085
Validation loss: 5.1429649435605915
Epoch: 9| Step: 14
Training loss: 5.9611825955100315
Validation loss: 5.104458599992236
Epoch: 9| Step: 15
Training loss: 5.720175310129339
Validation loss: 5.081764346813962
Epoch: 9| Step: 16
Training loss: 5.376075459609185
Validation loss: 5.045990866449408
Epoch: 9| Step: 17
Training loss: 5.091107016282915
Validation loss: 5.021131162569087
Epoch: 9| Step: 18
Training loss: 4.961369821529277
Validation loss: 5.025790662490527
Epoch: 9| Step: 19
Training loss: 5.1625078547605
Validation loss: 5.001484812077221
Epoch: 20| Step: 0
Training loss: 5.594772160231581
Validation loss: 4.980312353114369
Epoch: 9| Step: 1
Training loss: 4.961538011144846
Validation loss: 4.975239180709718
Epoch: 9| Step: 2
Training loss: 6.6512501165414735
Validation loss: 4.909911231093762
Epoch: 9| Step: 3
Training loss: 4.4042527021066435
Validation loss: 4.894987627336258
Epoch: 9| Step: 4
Training loss: 5.221943318018835
Validation loss: 4.877401148465341
Epoch: 9| Step: 5
Training loss: 5.542792222677962
Validation loss: 4.869259996540104
Epoch: 9| Step: 6
Training loss: 5.4009514570902875
Validation loss: 4.8519635844440065
Epoch: 9| Step: 7
Training loss: 5.41275180292595
Validation loss: 4.831962421337442
Epoch: 9| Step: 8
Training loss: 4.690250861122333
Validation loss: 4.785208297113812
Epoch: 9| Step: 9
Training loss: 5.097778225312735
Validation loss: 4.788786329876743
Epoch: 9| Step: 10
Training loss: 5.239068048316664
Validation loss: 4.792105008888598
Epoch: 9| Step: 11
Training loss: 5.526458561518193
Validation loss: 4.767329108920396
Epoch: 9| Step: 12
Training loss: 5.069794474090788
Validation loss: 4.7368578301667865
Epoch: 9| Step: 13
Training loss: 5.350068222038739
Validation loss: 4.690334910520754
Epoch: 9| Step: 14
Training loss: 4.587009597053077
Validation loss: 4.650779542000698
Epoch: 9| Step: 15
Training loss: 4.947049527394006
Validation loss: 4.599925331300992
Epoch: 9| Step: 16
Training loss: 5.701327440387855
Validation loss: 4.591778841231932
Epoch: 9| Step: 17
Training loss: 3.897326844426523
Validation loss: 4.6078558550362185
Epoch: 9| Step: 18
Training loss: 4.759742382996189
Validation loss: 4.5730276126989855
Epoch: 9| Step: 19
Training loss: 4.827714328522078
Validation loss: 4.516204039310209
Epoch: 21| Step: 0
Training loss: 5.277247610847098
Validation loss: 4.512892034558166
Epoch: 9| Step: 1
Training loss: 4.819188214079692
Validation loss: 4.488747083747497
Epoch: 9| Step: 2
Training loss: 4.56624084120865
Validation loss: 4.480736936630362
Epoch: 9| Step: 3
Training loss: 5.259581949714883
Validation loss: 4.4121731713931505
Epoch: 9| Step: 4
Training loss: 5.340924146029653
Validation loss: 4.382112880736826
Epoch: 9| Step: 5
Training loss: 3.7636505902356103
Validation loss: 4.366733656619324
Epoch: 9| Step: 6
Training loss: 4.7585933652109516
Validation loss: 4.400405194219905
Epoch: 9| Step: 7
Training loss: 4.614876467290279
Validation loss: 4.333220718269041
Epoch: 9| Step: 8
Training loss: 4.855461679148109
Validation loss: 4.2943484995207495
Epoch: 9| Step: 9
Training loss: 4.728491826019209
Validation loss: 4.27858593845639
Epoch: 9| Step: 10
Training loss: 4.570895478977432
Validation loss: 4.207106248484639
Epoch: 9| Step: 11
Training loss: 5.291227948282288
Validation loss: 4.209689705539797
Epoch: 9| Step: 12
Training loss: 5.503543579195188
Validation loss: 4.1459970451000405
Epoch: 9| Step: 13
Training loss: 3.965672298356749
Validation loss: 4.196077887163861
Epoch: 9| Step: 14
Training loss: 4.582958599145794
Validation loss: 4.172488862926906
Epoch: 9| Step: 15
Training loss: 4.578736144015472
Validation loss: 4.088911743106774
Epoch: 9| Step: 16
Training loss: 4.219995837458144
Validation loss: 4.0783851246007
Epoch: 9| Step: 17
Training loss: 4.802515149785164
Validation loss: 4.089058109580626
Epoch: 9| Step: 18
Training loss: 4.54500622705887
Validation loss: 4.016505636894463
Epoch: 9| Step: 19
Training loss: 4.086203805330356
Validation loss: 4.0098914557281224
Epoch: 22| Step: 0
Training loss: 3.6481789736262114
Validation loss: 3.933119935239912
Epoch: 9| Step: 1
Training loss: 3.9427434734087043
Validation loss: 3.9377991067044262
Epoch: 9| Step: 2
Training loss: 4.8957145947065035
Validation loss: 3.8945494192296026
Epoch: 9| Step: 3
Training loss: 4.020271670522972
Validation loss: 3.8947438191258468
Epoch: 9| Step: 4
Training loss: 4.712013944051476
Validation loss: 3.850842096684689
Epoch: 9| Step: 5
Training loss: 4.724467874263333
Validation loss: 3.7648353168012583
Epoch: 9| Step: 6
Training loss: 3.1106322540633973
Validation loss: 3.7683456472289
Epoch: 9| Step: 7
Training loss: 4.293184450265214
Validation loss: 3.7821249547819704
Epoch: 9| Step: 8
Training loss: 5.122287125267068
Validation loss: 3.681828590178379
Epoch: 9| Step: 9
Training loss: 4.071273953745353
Validation loss: 3.6604870621554437
Epoch: 9| Step: 10
Training loss: 4.835402845861211
Validation loss: 3.6138171120834253
Epoch: 9| Step: 11
Training loss: 5.2800752134456905
Validation loss: 3.621248838242084
Epoch: 9| Step: 12
Training loss: 4.173712279408366
Validation loss: 3.6241367112327003
Epoch: 9| Step: 13
Training loss: 4.749025746869941
Validation loss: 3.5853511679304733
Epoch: 9| Step: 14
Training loss: 1.8659072381336592
Validation loss: 3.5134282161728683
Epoch: 9| Step: 15
Training loss: 3.4957108783454776
Validation loss: 3.4904453251127587
Epoch: 9| Step: 16
Training loss: 3.946773205771136
Validation loss: 3.452122312453037
Epoch: 9| Step: 17
Training loss: 3.298557521094744
Validation loss: 3.4737099784940115
Epoch: 9| Step: 18
Training loss: 3.8473653770526473
Validation loss: 3.3876152997582665
Epoch: 9| Step: 19
Training loss: 4.117238458828377
Validation loss: 3.385493090371713
Epoch: 23| Step: 0
Training loss: 4.13774889978133
Validation loss: 3.3832693575194464
Epoch: 9| Step: 1
Training loss: 3.6420638879643055
Validation loss: 3.3282100118473026
Epoch: 9| Step: 2
Training loss: 4.009873601961904
Validation loss: 3.2785922570954877
Epoch: 9| Step: 3
Training loss: 4.4896090596015865
Validation loss: 3.2663590417618305
Epoch: 9| Step: 4
Training loss: 4.226194016616945
Validation loss: 3.2542574559342645
Epoch: 9| Step: 5
Training loss: 3.225348366544502
Validation loss: 3.242281296107726
Epoch: 9| Step: 6
Training loss: 3.4935079036900047
Validation loss: 3.2327921157132278
Epoch: 9| Step: 7
Training loss: 2.8316904428556726
Validation loss: 3.2195410540453215
Epoch: 9| Step: 8
Training loss: 2.936939429505731
Validation loss: 3.1190770569735147
Epoch: 9| Step: 9
Training loss: 3.2583447943158226
Validation loss: 3.115611191866333
Epoch: 9| Step: 10
Training loss: 3.5762612098856827
Validation loss: 3.1763461771131887
Epoch: 9| Step: 11
Training loss: 4.1053203116748636
Validation loss: 3.0992687585254646
Epoch: 9| Step: 12
Training loss: 4.127144458413739
Validation loss: 2.9665966844013845
Epoch: 9| Step: 13
Training loss: 3.532652179871406
Validation loss: 3.0476914449801784
Epoch: 9| Step: 14
Training loss: 3.2860238361852367
Validation loss: 2.984095846040023
Epoch: 9| Step: 15
Training loss: 3.9107481425612027
Validation loss: 2.9553765365953124
Epoch: 9| Step: 16
Training loss: 2.4579237149461886
Validation loss: 2.9805283355359187
Epoch: 9| Step: 17
Training loss: 3.0906624848625763
Validation loss: 2.9528148508349314
Epoch: 9| Step: 18
Training loss: 2.7593824548501806
Validation loss: 2.869724481305889
Epoch: 9| Step: 19
Training loss: 4.639462103742259
Validation loss: 2.9272594484573644
Epoch: 24| Step: 0
Training loss: 3.8922254342305997
Validation loss: 2.842214403867008
Epoch: 9| Step: 1
Training loss: 3.5482074402610024
Validation loss: 2.837238417234435
Epoch: 9| Step: 2
Training loss: 2.1243826025355146
Validation loss: 2.903618208415064
Epoch: 9| Step: 3
Training loss: 3.327664768831245
Validation loss: 2.7401952590982503
Epoch: 9| Step: 4
Training loss: 3.6128557604207603
Validation loss: 2.7862031496043205
Epoch: 9| Step: 5
Training loss: 3.480119098949215
Validation loss: 2.691896936759511
Epoch: 9| Step: 6
Training loss: 2.992361038793083
Validation loss: 2.7501714450841344
Epoch: 9| Step: 7
Training loss: 3.1624126135773594
Validation loss: 2.6763199418131767
Epoch: 9| Step: 8
Training loss: 3.8157342418681925
Validation loss: 2.7347963977713645
Epoch: 9| Step: 9
Training loss: 3.0983461090475664
Validation loss: 2.6629620916893333
Epoch: 9| Step: 10
Training loss: 3.3825011076999383
Validation loss: 2.714646347273241
Epoch: 9| Step: 11
Training loss: 3.427716568685944
Validation loss: 2.705973821909538
Epoch: 9| Step: 12
Training loss: 3.649079554260602
Validation loss: 2.555703033832997
Epoch: 9| Step: 13
Training loss: 3.1065845332387467
Validation loss: 2.6279433392629334
Epoch: 9| Step: 14
Training loss: 2.9722234383300323
Validation loss: 2.6390148580959822
Epoch: 9| Step: 15
Training loss: 3.039834520202915
Validation loss: 2.6056640023405593
Epoch: 9| Step: 16
Training loss: 2.4099778862092953
Validation loss: 2.6151430663992192
Epoch: 9| Step: 17
Training loss: 2.5695182709498043
Validation loss: 2.6266040604440763
Epoch: 9| Step: 18
Training loss: 3.0043249743720706
Validation loss: 2.5710610712852047
Epoch: 9| Step: 19
Training loss: 2.8286729144871665
Validation loss: 2.5235976821556445
Epoch: 25| Step: 0
Training loss: 2.180604475192093
Validation loss: 2.474475037396716
Epoch: 9| Step: 1
Training loss: 3.3763814853796443
Validation loss: 2.5378145312857856
Epoch: 9| Step: 2
Training loss: 3.1349910476775773
Validation loss: 2.48178966403113
Epoch: 9| Step: 3
Training loss: 2.9674911239221324
Validation loss: 2.520363146284244
Epoch: 9| Step: 4
Training loss: 2.250062305859334
Validation loss: 2.4960848352263856
Epoch: 9| Step: 5
Training loss: 3.506772573223142
Validation loss: 2.4087515317026233
Epoch: 9| Step: 6
Training loss: 2.8470255672698968
Validation loss: 2.5051480372014163
Epoch: 9| Step: 7
Training loss: 3.090702443941322
Validation loss: 2.4651357476410185
Epoch: 9| Step: 8
Training loss: 2.7408756258948994
Validation loss: 2.426555956155774
Epoch: 9| Step: 9
Training loss: 2.9950891673167632
Validation loss: 2.530407501801999
Epoch: 9| Step: 10
Training loss: 3.29176027832837
Validation loss: 2.545294359237307
Epoch: 9| Step: 11
Training loss: 3.238461920802496
Validation loss: 2.4289278631591875
Epoch: 9| Step: 12
Training loss: 3.1973730033129466
Validation loss: 2.418683903422758
Epoch: 9| Step: 13
Training loss: 3.3190124120615243
Validation loss: 2.452345534875601
Epoch: 9| Step: 14
Training loss: 2.817815716307895
Validation loss: 2.4358392198353394
Epoch: 9| Step: 15
Training loss: 2.9710848009454693
Validation loss: 2.418657301411135
Epoch: 9| Step: 16
Training loss: 1.8843151127296303
Validation loss: 2.4709803166329323
Epoch: 9| Step: 17
Training loss: 3.2493509965066156
Validation loss: 2.390822896929814
Epoch: 9| Step: 18
Training loss: 2.8727887813734676
Validation loss: 2.5071237163404887
Epoch: 9| Step: 19
Training loss: 3.6577554847415956
Validation loss: 2.445630183245686
Epoch: 26| Step: 0
Training loss: 2.6575325954731386
Validation loss: 2.3878991760226285
Epoch: 9| Step: 1
Training loss: 3.110155170654171
Validation loss: 2.5242142716104214
Epoch: 9| Step: 2
Training loss: 2.541660892500859
Validation loss: 2.421378511306513
Epoch: 9| Step: 3
Training loss: 2.542811797611795
Validation loss: 2.405613152539022
Epoch: 9| Step: 4
Training loss: 3.6388878341039113
Validation loss: 2.540258536705267
Epoch: 9| Step: 5
Training loss: 2.764561421686732
Validation loss: 2.418167935359694
Epoch: 9| Step: 6
Training loss: 2.3157766686318206
Validation loss: 2.4091136933672654
Epoch: 9| Step: 7
Training loss: 2.71829833740435
Validation loss: 2.4432893555577566
Epoch: 9| Step: 8
Training loss: 2.5042017912556735
Validation loss: 2.498723884565859
Epoch: 9| Step: 9
Training loss: 2.4339795243115883
Validation loss: 2.4549353541152508
Epoch: 9| Step: 10
Training loss: 2.455618593242052
Validation loss: 2.4555162930787686
Epoch: 9| Step: 11
Training loss: 3.2516333070494254
Validation loss: 2.418036527721221
Epoch: 9| Step: 12
Training loss: 3.148750990034177
Validation loss: 2.4542454801433746
Epoch: 9| Step: 13
Training loss: 3.156670570679949
Validation loss: 2.4948835177617146
Epoch: 9| Step: 14
Training loss: 2.3933207951308497
Validation loss: 2.4651323112325425
Epoch: 9| Step: 15
Training loss: 2.271825894293384
Validation loss: 2.3557256241466913
Epoch: 9| Step: 16
Training loss: 3.212260546832985
Validation loss: 2.3653130542346044
Epoch: 9| Step: 17
Training loss: 3.2125299593348577
Validation loss: 2.4223207212920306
Epoch: 9| Step: 18
Training loss: 2.598325714808125
Validation loss: 2.4684946130690713
Epoch: 9| Step: 19
Training loss: 3.2632643640988634
Validation loss: 2.4494210974184742
Epoch: 27| Step: 0
Training loss: 2.869162230283698
Validation loss: 2.4595724180651017
Epoch: 9| Step: 1
Training loss: 4.286320489062961
Validation loss: 2.412828831068844
Epoch: 9| Step: 2
Training loss: 3.4418016741291306
Validation loss: 2.4642753277882923
Epoch: 9| Step: 3
Training loss: 2.3903955087650193
Validation loss: 2.4779816504130356
Epoch: 9| Step: 4
Training loss: 3.0479202433886936
Validation loss: 2.528127976845909
Epoch: 9| Step: 5
Training loss: 1.6595860119005572
Validation loss: 2.540542390166387
Epoch: 9| Step: 6
Training loss: 3.4376186003599245
Validation loss: 2.4374592198592673
Epoch: 9| Step: 7
Training loss: 3.7149545229853245
Validation loss: 2.52822040259313
Epoch: 9| Step: 8
Training loss: 2.198517438550876
Validation loss: 2.4824440058952923
Epoch: 9| Step: 9
Training loss: 2.2133954407507552
Validation loss: 2.5226625550530115
Epoch: 9| Step: 10
Training loss: 3.4673637850738985
Validation loss: 2.4715387368791575
Epoch: 9| Step: 11
Training loss: 3.13624867566576
Validation loss: 2.422238925154336
Epoch: 9| Step: 12
Training loss: 1.8807765352222217
Validation loss: 2.461682180362762
Epoch: 9| Step: 13
Training loss: 2.2162498034344287
Validation loss: 2.485556017690773
Epoch: 9| Step: 14
Training loss: 3.4363376386171876
Validation loss: 2.47077679880304
Epoch: 9| Step: 15
Training loss: 2.6362360307550374
Validation loss: 2.4982908147759706
Epoch: 9| Step: 16
Training loss: 2.742916781835792
Validation loss: 2.4685212815739246
Epoch: 9| Step: 17
Training loss: 2.751040608585091
Validation loss: 2.444822324465786
Epoch: 9| Step: 18
Training loss: 1.4613216119583876
Validation loss: 2.572790519684326
Epoch: 9| Step: 19
Training loss: 2.307389876526584
Validation loss: 2.45374794388447
Epoch: 28| Step: 0
Training loss: 2.973878626693381
Validation loss: 2.462932247676191
Epoch: 9| Step: 1
Training loss: 3.0850720701037724
Validation loss: 2.5265030847916377
Epoch: 9| Step: 2
Training loss: 2.4570161124583376
Validation loss: 2.45177725749101
Epoch: 9| Step: 3
Training loss: 2.579156010553864
Validation loss: 2.3927562371375166
Epoch: 9| Step: 4
Training loss: 2.8575031428015274
Validation loss: 2.4934829078270457
Epoch: 9| Step: 5
Training loss: 2.459352012827372
Validation loss: 2.482976174037559
Epoch: 9| Step: 6
Training loss: 3.0359972717715182
Validation loss: 2.4634488338283536
Epoch: 9| Step: 7
Training loss: 3.5205315153935075
Validation loss: 2.393890479605797
Epoch: 9| Step: 8
Training loss: 3.016383574745612
Validation loss: 2.5183688846063115
Epoch: 9| Step: 9
Training loss: 3.6069089713882243
Validation loss: 2.4585077610152175
Epoch: 9| Step: 10
Training loss: 2.6307208981280503
Validation loss: 2.521888435619597
Epoch: 9| Step: 11
Training loss: 2.8483376858497373
Validation loss: 2.466353785362863
Epoch: 9| Step: 12
Training loss: 2.324037176140163
Validation loss: 2.511994156596749
Epoch: 9| Step: 13
Training loss: 3.1346004264298224
Validation loss: 2.4144650173844138
Epoch: 9| Step: 14
Training loss: 2.67001009992768
Validation loss: 2.4412075393391923
Epoch: 9| Step: 15
Training loss: 3.2706406328005193
Validation loss: 2.3414176711765053
Epoch: 9| Step: 16
Training loss: 2.238097391349738
Validation loss: 2.490973649797404
Epoch: 9| Step: 17
Training loss: 2.9839429292922874
Validation loss: 2.4846289798777375
Epoch: 9| Step: 18
Training loss: 2.8707097426019113
Validation loss: 2.4019578276485283
Epoch: 9| Step: 19
Training loss: 2.5823136029549834
Validation loss: 2.4537048115265288
Epoch: 29| Step: 0
Training loss: 2.5730622491048587
Validation loss: 2.45693900474216
Epoch: 9| Step: 1
Training loss: 2.613982923246145
Validation loss: 2.454033967643375
Epoch: 9| Step: 2
Training loss: 2.2771483872437597
Validation loss: 2.400066844928349
Epoch: 9| Step: 3
Training loss: 2.9614143088323743
Validation loss: 2.4869502067529186
Epoch: 9| Step: 4
Training loss: 2.858116998817694
Validation loss: 2.4399726851443733
Epoch: 9| Step: 5
Training loss: 2.558262740993021
Validation loss: 2.463525759217901
Epoch: 9| Step: 6
Training loss: 3.1190051752251158
Validation loss: 2.532556707114095
Epoch: 9| Step: 7
Training loss: 2.8506285927885164
Validation loss: 2.4090423304258546
Epoch: 9| Step: 8
Training loss: 2.2983807668938767
Validation loss: 2.497562337216844
Epoch: 9| Step: 9
Training loss: 3.691577919495343
Validation loss: 2.4108654258272293
Epoch: 9| Step: 10
Training loss: 2.7780977022526976
Validation loss: 2.54998731995688
Epoch: 9| Step: 11
Training loss: 3.5186675744710225
Validation loss: 2.4067069331857596
Epoch: 9| Step: 12
Training loss: 3.468296605627104
Validation loss: 2.458049213068208
Epoch: 9| Step: 13
Training loss: 2.9569082095954795
Validation loss: 2.4362350668386203
Epoch: 9| Step: 14
Training loss: 2.5792028774827567
Validation loss: 2.4007677181393787
Epoch: 9| Step: 15
Training loss: 2.984232474713518
Validation loss: 2.359102544426614
Epoch: 9| Step: 16
Training loss: 3.192778760289883
Validation loss: 2.4572693882899217
Epoch: 9| Step: 17
Training loss: 2.4713744687585373
Validation loss: 2.401804108453402
Epoch: 9| Step: 18
Training loss: 2.4434058217757637
Validation loss: 2.5019285391808785
Epoch: 9| Step: 19
Training loss: 3.0741180829987997
Validation loss: 2.502970443876555
Epoch: 30| Step: 0
Training loss: 2.7379948660814235
Validation loss: 2.4865493683464597
Epoch: 9| Step: 1
Training loss: 3.2985766028668286
Validation loss: 2.449890051131774
Epoch: 9| Step: 2
Training loss: 3.2904629659291666
Validation loss: 2.5079204548624032
Epoch: 9| Step: 3
Training loss: 2.3962951436215527
Validation loss: 2.400611817496407
Epoch: 9| Step: 4
Training loss: 2.9339401101602816
Validation loss: 2.4903338691349957
Epoch: 9| Step: 5
Training loss: 3.082272751004439
Validation loss: 2.5563455548085208
Epoch: 9| Step: 6
Training loss: 2.000700351162463
Validation loss: 2.4840144785161633
Epoch: 9| Step: 7
Training loss: 2.8983157561611725
Validation loss: 2.4907628784764997
Epoch: 9| Step: 8
Training loss: 2.2052018136811196
Validation loss: 2.3616459143174082
Epoch: 9| Step: 9
Training loss: 2.7196743150277713
Validation loss: 2.478198098593515
Epoch: 9| Step: 10
Training loss: 3.1216565365957067
Validation loss: 2.4160726313751972
Epoch: 9| Step: 11
Training loss: 3.4330962670216074
Validation loss: 2.314098815569607
Epoch: 9| Step: 12
Training loss: 2.1646747480468154
Validation loss: 2.452840731040213
Epoch: 9| Step: 13
Training loss: 2.7388928392943632
Validation loss: 2.4780045586568678
Epoch: 9| Step: 14
Training loss: 2.2139215719293337
Validation loss: 2.4357322398621024
Epoch: 9| Step: 15
Training loss: 2.9157340238902605
Validation loss: 2.460944445817798
Epoch: 9| Step: 16
Training loss: 3.28549733245328
Validation loss: 2.4752746301324304
Epoch: 9| Step: 17
Training loss: 3.339039988033538
Validation loss: 2.4391501448933983
Epoch: 9| Step: 18
Training loss: 3.0522487105176954
Validation loss: 2.5425523277148367
Epoch: 9| Step: 19
Training loss: 2.8288165348199765
Validation loss: 2.401306665518472
Epoch: 31| Step: 0
Training loss: 2.9933999894274237
Validation loss: 2.4044093296960014
Epoch: 9| Step: 1
Training loss: 2.3674060481441606
Validation loss: 2.499760581458744
Epoch: 9| Step: 2
Training loss: 2.828311471429366
Validation loss: 2.4279703337599225
Epoch: 9| Step: 3
Training loss: 2.3228853391807167
Validation loss: 2.5004953403907546
Epoch: 9| Step: 4
Training loss: 2.7827478725804595
Validation loss: 2.4534540898625448
Epoch: 9| Step: 5
Training loss: 3.1072371144397013
Validation loss: 2.4025778166341185
Epoch: 9| Step: 6
Training loss: 2.4775605221466654
Validation loss: 2.48138449451038
Epoch: 9| Step: 7
Training loss: 3.2375605279279442
Validation loss: 2.3842678224851825
Epoch: 9| Step: 8
Training loss: 3.7762316987024453
Validation loss: 2.4516465626548474
Epoch: 9| Step: 9
Training loss: 3.0144439123709166
Validation loss: 2.420492559825205
Epoch: 9| Step: 10
Training loss: 3.4824509033773317
Validation loss: 2.5060890521924444
Epoch: 9| Step: 11
Training loss: 3.0891479789086995
Validation loss: 2.538149021940939
Epoch: 9| Step: 12
Training loss: 1.9639352324774697
Validation loss: 2.4201372644853327
Epoch: 9| Step: 13
Training loss: 3.4154463348707202
Validation loss: 2.491553582363606
Epoch: 9| Step: 14
Training loss: 3.871940881939871
Validation loss: 2.486041310691913
Epoch: 9| Step: 15
Training loss: 2.6884733699581482
Validation loss: 2.5496669932340947
Epoch: 9| Step: 16
Training loss: 2.9435498860043947
Validation loss: 2.4157611557789305
Epoch: 9| Step: 17
Training loss: 1.4072845044672637
Validation loss: 2.4457772979843786
Epoch: 9| Step: 18
Training loss: 2.7422624452788287
Validation loss: 2.461840444106088
Epoch: 9| Step: 19
Training loss: 1.8646922017570893
Validation loss: 2.4275697417512587
Epoch: 32| Step: 0
Training loss: 2.299947331696241
Validation loss: 2.39382666727202
Epoch: 9| Step: 1
Training loss: 3.108251013871688
Validation loss: 2.4373675832459947
Epoch: 9| Step: 2
Training loss: 3.0338667753336885
Validation loss: 2.444818232752622
Epoch: 9| Step: 3
Training loss: 2.8300548734163886
Validation loss: 2.487631332204594
Epoch: 9| Step: 4
Training loss: 2.459428500183705
Validation loss: 2.4375384573976007
Epoch: 9| Step: 5
Training loss: 3.0250884681564836
Validation loss: 2.537401545617084
Epoch: 9| Step: 6
Training loss: 2.1298591930788593
Validation loss: 2.3732375921838433
Epoch: 9| Step: 7
Training loss: 3.0049016962459127
Validation loss: 2.395700091206508
Epoch: 9| Step: 8
Training loss: 2.646797054723929
Validation loss: 2.4272897389162433
Epoch: 9| Step: 9
Training loss: 3.49192860302904
Validation loss: 2.469155411034085
Epoch: 9| Step: 10
Training loss: 2.8844900651755054
Validation loss: 2.4023553867633223
Epoch: 9| Step: 11
Training loss: 2.5671623428421575
Validation loss: 2.449199270776674
Epoch: 9| Step: 12
Training loss: 3.1077714168389683
Validation loss: 2.427452861063225
Epoch: 9| Step: 13
Training loss: 3.296710114175084
Validation loss: 2.4187600804862543
Epoch: 9| Step: 14
Training loss: 2.0971643876388226
Validation loss: 2.490035309898595
Epoch: 9| Step: 15
Training loss: 1.4982356185082821
Validation loss: 2.4035977357137037
Epoch: 9| Step: 16
Training loss: 3.871768219024184
Validation loss: 2.4502495881516033
Epoch: 9| Step: 17
Training loss: 3.1434874893310862
Validation loss: 2.5067433872623583
Epoch: 9| Step: 18
Training loss: 2.500280936668531
Validation loss: 2.4588706966728537
Epoch: 9| Step: 19
Training loss: 2.9413310290846644
Validation loss: 2.4920837985949125
Epoch: 33| Step: 0
Training loss: 3.543448116085743
Validation loss: 2.443607283090979
Epoch: 9| Step: 1
Training loss: 2.2101350547985112
Validation loss: 2.4573116232118926
Epoch: 9| Step: 2
Training loss: 3.0716968938782565
Validation loss: 2.419505652971232
Epoch: 9| Step: 3
Training loss: 2.6520924062840883
Validation loss: 2.4262859627360798
Epoch: 9| Step: 4
Training loss: 3.6098299606727604
Validation loss: 2.488857616089694
Epoch: 9| Step: 5
Training loss: 2.6722319069006364
Validation loss: 2.5625195060753576
Epoch: 9| Step: 6
Training loss: 2.4504491705690867
Validation loss: 2.502505601767288
Epoch: 9| Step: 7
Training loss: 1.7967226046746347
Validation loss: 2.419745564499338
Epoch: 9| Step: 8
Training loss: 3.2512377802741277
Validation loss: 2.443372440796155
Epoch: 9| Step: 9
Training loss: 2.967088736466835
Validation loss: 2.4630364348972322
Epoch: 9| Step: 10
Training loss: 2.265104878673206
Validation loss: 2.521666214880081
Epoch: 9| Step: 11
Training loss: 3.5102454501241347
Validation loss: 2.4081013810125005
Epoch: 9| Step: 12
Training loss: 2.878896643365078
Validation loss: 2.3579478200361876
Epoch: 9| Step: 13
Training loss: 2.221973495339055
Validation loss: 2.377901447708079
Epoch: 9| Step: 14
Training loss: 2.6145410622957646
Validation loss: 2.380127470483185
Epoch: 9| Step: 15
Training loss: 2.8648154609725296
Validation loss: 2.440369801037768
Epoch: 9| Step: 16
Training loss: 2.70900400123005
Validation loss: 2.4577177465812423
Epoch: 9| Step: 17
Training loss: 2.4947254806584303
Validation loss: 2.4250726505369986
Epoch: 9| Step: 18
Training loss: 3.028844449109167
Validation loss: 2.4585120475590507
Epoch: 9| Step: 19
Training loss: 3.307003283005046
Validation loss: 2.3721189489257406
Epoch: 34| Step: 0
Training loss: 2.6938427442264214
Validation loss: 2.4781931622240596
Epoch: 9| Step: 1
Training loss: 3.5822492926242355
Validation loss: 2.4537122406197027
Epoch: 9| Step: 2
Training loss: 2.523725841570967
Validation loss: 2.481141773435686
Epoch: 9| Step: 3
Training loss: 3.3919728496292643
Validation loss: 2.4306649363608277
Epoch: 9| Step: 4
Training loss: 2.3553941502943765
Validation loss: 2.5347096348403118
Epoch: 9| Step: 5
Training loss: 2.5838792798273196
Validation loss: 2.468101851069517
Epoch: 9| Step: 6
Training loss: 2.2044759085141945
Validation loss: 2.3964589177946376
Epoch: 9| Step: 7
Training loss: 3.447562730645852
Validation loss: 2.425646409489629
Epoch: 9| Step: 8
Training loss: 2.9982918008667085
Validation loss: 2.4439642006864757
Epoch: 9| Step: 9
Training loss: 2.930936908064999
Validation loss: 2.422565843515631
Epoch: 9| Step: 10
Training loss: 2.2439455589993553
Validation loss: 2.4228790698956337
Epoch: 9| Step: 11
Training loss: 2.9541265817638864
Validation loss: 2.4763536768440844
Epoch: 9| Step: 12
Training loss: 3.3461416372452537
Validation loss: 2.4408806900580546
Epoch: 9| Step: 13
Training loss: 2.366451740803673
Validation loss: 2.4629670976531424
Epoch: 9| Step: 14
Training loss: 3.092535840307107
Validation loss: 2.4421792201179837
Epoch: 9| Step: 15
Training loss: 2.3321234654480154
Validation loss: 2.3242866917062543
Epoch: 9| Step: 16
Training loss: 2.943969906248861
Validation loss: 2.493797583969594
Epoch: 9| Step: 17
Training loss: 3.0314463129085554
Validation loss: 2.4753886136467247
Epoch: 9| Step: 18
Training loss: 2.103386410115552
Validation loss: 2.3251721560283642
Epoch: 9| Step: 19
Training loss: 3.3513840847944416
Validation loss: 2.4096497309874625
Epoch: 35| Step: 0
Training loss: 2.920185110417071
Validation loss: 2.372435412860134
Epoch: 9| Step: 1
Training loss: 2.211296348970158
Validation loss: 2.5147667120672397
Epoch: 9| Step: 2
Training loss: 2.96123605798134
Validation loss: 2.4804761792516334
Epoch: 9| Step: 3
Training loss: 2.2334929105579118
Validation loss: 2.528736038602755
Epoch: 9| Step: 4
Training loss: 1.9429881599171537
Validation loss: 2.509727416915162
Epoch: 9| Step: 5
Training loss: 3.2244637154317974
Validation loss: 2.416660302069871
Epoch: 9| Step: 6
Training loss: 3.381484125461344
Validation loss: 2.367646333622563
Epoch: 9| Step: 7
Training loss: 1.784207214911482
Validation loss: 2.4704117509282173
Epoch: 9| Step: 8
Training loss: 2.4985650712891805
Validation loss: 2.379842836654431
Epoch: 9| Step: 9
Training loss: 2.875657711261698
Validation loss: 2.515910737073087
Epoch: 9| Step: 10
Training loss: 2.88684676406573
Validation loss: 2.387938037252356
Epoch: 9| Step: 11
Training loss: 3.236725031768132
Validation loss: 2.5094891200491167
Epoch: 9| Step: 12
Training loss: 2.9852022153005566
Validation loss: 2.4457026790208722
Epoch: 9| Step: 13
Training loss: 2.4568274675777166
Validation loss: 2.433367373690063
Epoch: 9| Step: 14
Training loss: 3.2098740350363877
Validation loss: 2.4510476086744206
Epoch: 9| Step: 15
Training loss: 3.4134599166981987
Validation loss: 2.4185435613948596
Epoch: 9| Step: 16
Training loss: 2.139804766475005
Validation loss: 2.3980220008878397
Epoch: 9| Step: 17
Training loss: 3.1476192499648086
Validation loss: 2.4654506469112705
Epoch: 9| Step: 18
Training loss: 3.3346027500270976
Validation loss: 2.505091138165008
Epoch: 9| Step: 19
Training loss: 2.3356158695343616
Validation loss: 2.391552787184758
Epoch: 36| Step: 0
Training loss: 2.6914005805455528
Validation loss: 2.4324903099074247
Epoch: 9| Step: 1
Training loss: 2.443069160235112
Validation loss: 2.4053684054326805
Epoch: 9| Step: 2
Training loss: 3.4968470949861232
Validation loss: 2.4194233688537143
Epoch: 9| Step: 3
Training loss: 2.39079912336926
Validation loss: 2.442577510833273
Epoch: 9| Step: 4
Training loss: 3.02070655995214
Validation loss: 2.4730818889428723
Epoch: 9| Step: 5
Training loss: 3.0104816434155177
Validation loss: 2.446484412427789
Epoch: 9| Step: 6
Training loss: 2.3174226277592602
Validation loss: 2.4626194543416813
Epoch: 9| Step: 7
Training loss: 2.3495191650323366
Validation loss: 2.350124479575832
Epoch: 9| Step: 8
Training loss: 2.86590114914445
Validation loss: 2.4760132647647497
Epoch: 9| Step: 9
Training loss: 2.1338024706386514
Validation loss: 2.424326264325302
Epoch: 9| Step: 10
Training loss: 2.8397757457792188
Validation loss: 2.396781379359377
Epoch: 9| Step: 11
Training loss: 2.562084257314179
Validation loss: 2.3924188595898555
Epoch: 9| Step: 12
Training loss: 3.4784701139288368
Validation loss: 2.356973635333194
Epoch: 9| Step: 13
Training loss: 3.421045768978016
Validation loss: 2.4853693217405852
Epoch: 9| Step: 14
Training loss: 3.405894129650494
Validation loss: 2.3645479692376172
Epoch: 9| Step: 15
Training loss: 3.014129900537137
Validation loss: 2.40663792145284
Epoch: 9| Step: 16
Training loss: 2.893230686593651
Validation loss: 2.405516675004076
Epoch: 9| Step: 17
Training loss: 2.562524469770505
Validation loss: 2.3081717774226918
Epoch: 9| Step: 18
Training loss: 2.7574330357905152
Validation loss: 2.4186649832377163
Epoch: 9| Step: 19
Training loss: 1.9677162483935264
Validation loss: 2.414620941963794
Epoch: 37| Step: 0
Training loss: 2.9277021267611896
Validation loss: 2.4010884861972697
Epoch: 9| Step: 1
Training loss: 2.6461701266379922
Validation loss: 2.492886950590286
Epoch: 9| Step: 2
Training loss: 2.8818634042235636
Validation loss: 2.508584392933352
Epoch: 9| Step: 3
Training loss: 3.071731511254505
Validation loss: 2.4887431785338046
Epoch: 9| Step: 4
Training loss: 3.3632048311313154
Validation loss: 2.4829075357227
Epoch: 9| Step: 5
Training loss: 2.9408473969538798
Validation loss: 2.427750573359212
Epoch: 9| Step: 6
Training loss: 2.1444224067680047
Validation loss: 2.495295126943452
Epoch: 9| Step: 7
Training loss: 3.1867556731377884
Validation loss: 2.4156611614832104
Epoch: 9| Step: 8
Training loss: 2.5748971788932775
Validation loss: 2.4239950270927624
Epoch: 9| Step: 9
Training loss: 3.1050824002989814
Validation loss: 2.348267997702825
Epoch: 9| Step: 10
Training loss: 2.81801353019244
Validation loss: 2.4390008531515885
Epoch: 9| Step: 11
Training loss: 1.6922743333849846
Validation loss: 2.396971617911933
Epoch: 9| Step: 12
Training loss: 2.2980175679782815
Validation loss: 2.421261813190381
Epoch: 9| Step: 13
Training loss: 3.0459693540858668
Validation loss: 2.4186752198128234
Epoch: 9| Step: 14
Training loss: 2.5586368003892526
Validation loss: 2.566112520257507
Epoch: 9| Step: 15
Training loss: 3.3628666674283103
Validation loss: 2.443909804570128
Epoch: 9| Step: 16
Training loss: 2.1996008640965363
Validation loss: 2.5049846789243104
Epoch: 9| Step: 17
Training loss: 2.9878475098822515
Validation loss: 2.4264513903035874
Epoch: 9| Step: 18
Training loss: 3.2972004083520483
Validation loss: 2.383836025879152
Epoch: 9| Step: 19
Training loss: 2.9971678398823123
Validation loss: 2.3925660868325687
Epoch: 38| Step: 0
Training loss: 2.5599995020031443
Validation loss: 2.4596570764182695
Epoch: 9| Step: 1
Training loss: 3.157373511649426
Validation loss: 2.438704769924336
Epoch: 9| Step: 2
Training loss: 2.9459946548195886
Validation loss: 2.447765268780443
Epoch: 9| Step: 3
Training loss: 3.0768894872299164
Validation loss: 2.504018776787542
Epoch: 9| Step: 4
Training loss: 2.575893476712331
Validation loss: 2.421758835283355
Epoch: 9| Step: 5
Training loss: 3.0313410794447395
Validation loss: 2.405914089823607
Epoch: 9| Step: 6
Training loss: 3.394526192998247
Validation loss: 2.4353640426325938
Epoch: 9| Step: 7
Training loss: 2.598151275964394
Validation loss: 2.5173167116733293
Epoch: 9| Step: 8
Training loss: 2.7263960910502694
Validation loss: 2.4218180310622226
Epoch: 9| Step: 9
Training loss: 2.6276073222650207
Validation loss: 2.435197716240634
Epoch: 9| Step: 10
Training loss: 2.760220953763037
Validation loss: 2.410737450712091
Epoch: 9| Step: 11
Training loss: 2.435000776725504
Validation loss: 2.418727254596842
Epoch: 9| Step: 12
Training loss: 3.510580419386721
Validation loss: 2.444420477845266
Epoch: 9| Step: 13
Training loss: 2.282490327779075
Validation loss: 2.274716359479732
Epoch: 9| Step: 14
Training loss: 3.243569247404396
Validation loss: 2.459433260007135
Epoch: 9| Step: 15
Training loss: 3.3025398941575923
Validation loss: 2.450933559611475
Epoch: 9| Step: 16
Training loss: 2.1504080318678427
Validation loss: 2.391786007759484
Epoch: 9| Step: 17
Training loss: 2.1006918312525893
Validation loss: 2.4922844494615295
Epoch: 9| Step: 18
Training loss: 2.535784580323253
Validation loss: 2.4363416260356514
Epoch: 9| Step: 19
Training loss: 2.5962964162777635
Validation loss: 2.376930168692461
Epoch: 39| Step: 0
Training loss: 2.640501301593745
Validation loss: 2.424946564527719
Epoch: 9| Step: 1
Training loss: 2.9493980504788526
Validation loss: 2.3996174724051254
Epoch: 9| Step: 2
Training loss: 3.7074639376367444
Validation loss: 2.3360660700073246
Epoch: 9| Step: 3
Training loss: 2.670426182255006
Validation loss: 2.379067326509277
Epoch: 9| Step: 4
Training loss: 2.498543887470698
Validation loss: 2.4390499741011284
Epoch: 9| Step: 5
Training loss: 2.540499330535182
Validation loss: 2.4595252247860944
Epoch: 9| Step: 6
Training loss: 2.57580665619816
Validation loss: 2.4590907693543893
Epoch: 9| Step: 7
Training loss: 3.472410315611244
Validation loss: 2.4836527116611418
Epoch: 9| Step: 8
Training loss: 2.6291190935557416
Validation loss: 2.4630007481187617
Epoch: 9| Step: 9
Training loss: 3.1714128430048913
Validation loss: 2.48240357075268
Epoch: 9| Step: 10
Training loss: 2.067529037991247
Validation loss: 2.472617724847747
Epoch: 9| Step: 11
Training loss: 3.147702417629203
Validation loss: 2.418146093999277
Epoch: 9| Step: 12
Training loss: 2.7511027465957465
Validation loss: 2.447192302229779
Epoch: 9| Step: 13
Training loss: 3.2489572466112286
Validation loss: 2.4454380121764823
Epoch: 9| Step: 14
Training loss: 2.855028361164596
Validation loss: 2.528964443803688
Epoch: 9| Step: 15
Training loss: 2.680931847821267
Validation loss: 2.387135515495383
Epoch: 9| Step: 16
Training loss: 2.1492086240418264
Validation loss: 2.401568618703448
Epoch: 9| Step: 17
Training loss: 2.2623840302309732
Validation loss: 2.4238641587471417
Epoch: 9| Step: 18
Training loss: 2.7556630692563684
Validation loss: 2.397057076862436
Epoch: 9| Step: 19
Training loss: 2.7270760913244674
Validation loss: 2.4918493283414427
Epoch: 40| Step: 0
Training loss: 2.000003337857322
Validation loss: 2.354441780602189
Epoch: 9| Step: 1
Training loss: 2.4846205679968203
Validation loss: 2.49254490028318
Epoch: 9| Step: 2
Training loss: 3.333581597301788
Validation loss: 2.3607583747671232
Epoch: 9| Step: 3
Training loss: 3.3324323549151678
Validation loss: 2.3656544459599163
Epoch: 9| Step: 4
Training loss: 3.451936681314801
Validation loss: 2.4435925104155123
Epoch: 9| Step: 5
Training loss: 2.5408634313208442
Validation loss: 2.3722547042099755
Epoch: 9| Step: 6
Training loss: 2.8746360880205
Validation loss: 2.471900471844121
Epoch: 9| Step: 7
Training loss: 2.519224636139855
Validation loss: 2.3601987266928677
Epoch: 9| Step: 8
Training loss: 2.2722391332584118
Validation loss: 2.5120019883137963
Epoch: 9| Step: 9
Training loss: 2.501610523265667
Validation loss: 2.401706638261934
Epoch: 9| Step: 10
Training loss: 3.159000369234658
Validation loss: 2.3469810670598776
Epoch: 9| Step: 11
Training loss: 2.224878363552709
Validation loss: 2.4252363629662073
Epoch: 9| Step: 12
Training loss: 2.902071666671258
Validation loss: 2.478256894184217
Epoch: 9| Step: 13
Training loss: 2.5991493924435165
Validation loss: 2.4116087300908524
Epoch: 9| Step: 14
Training loss: 3.483974006056579
Validation loss: 2.3261453398829883
Epoch: 9| Step: 15
Training loss: 1.9553802896959822
Validation loss: 2.3920022531003284
Epoch: 9| Step: 16
Training loss: 3.5040665571780725
Validation loss: 2.412335119728418
Epoch: 9| Step: 17
Training loss: 3.0671452694753376
Validation loss: 2.3364799715540054
Epoch: 9| Step: 18
Training loss: 2.519221323749354
Validation loss: 2.484254933994943
Epoch: 9| Step: 19
Training loss: 2.5850638674256063
Validation loss: 2.436644708584739
Epoch: 41| Step: 0
Training loss: 2.65164080871148
Validation loss: 2.3596322256352438
Epoch: 9| Step: 1
Training loss: 2.3323602236686467
Validation loss: 2.45119928937883
Epoch: 9| Step: 2
Training loss: 3.4746513685805533
Validation loss: 2.396003621716615
Epoch: 9| Step: 3
Training loss: 2.064066783083357
Validation loss: 2.4091316256904327
Epoch: 9| Step: 4
Training loss: 2.5404025722982566
Validation loss: 2.4254453400193685
Epoch: 9| Step: 5
Training loss: 2.450771393298586
Validation loss: 2.393246426365319
Epoch: 9| Step: 6
Training loss: 2.2711919332250163
Validation loss: 2.3836519336578617
Epoch: 9| Step: 7
Training loss: 2.5833843800413256
Validation loss: 2.429642247684011
Epoch: 9| Step: 8
Training loss: 2.306983554035726
Validation loss: 2.3790438117668193
Epoch: 9| Step: 9
Training loss: 2.3940036808581566
Validation loss: 2.444739603778694
Epoch: 9| Step: 10
Training loss: 3.4234407927211317
Validation loss: 2.466649272165454
Epoch: 9| Step: 11
Training loss: 3.2037878327623317
Validation loss: 2.391864611311769
Epoch: 9| Step: 12
Training loss: 3.2889975498337636
Validation loss: 2.4008939516788077
Epoch: 9| Step: 13
Training loss: 2.8334681160975514
Validation loss: 2.468611290470395
Epoch: 9| Step: 14
Training loss: 2.984671533042832
Validation loss: 2.4342055921289782
Epoch: 9| Step: 15
Training loss: 3.4915268377621667
Validation loss: 2.4400653281594717
Epoch: 9| Step: 16
Training loss: 3.390028096760582
Validation loss: 2.5194018672839906
Epoch: 9| Step: 17
Training loss: 2.8970030656508006
Validation loss: 2.387819083316866
Epoch: 9| Step: 18
Training loss: 2.6648926993520883
Validation loss: 2.403537394915441
Epoch: 9| Step: 19
Training loss: 2.36651218966809
Validation loss: 2.431841412331521
Epoch: 42| Step: 0
Training loss: 3.1086170288656207
Validation loss: 2.3606066133058516
Epoch: 9| Step: 1
Training loss: 3.27853208328892
Validation loss: 2.4077469597101184
Epoch: 9| Step: 2
Training loss: 2.886175576857586
Validation loss: 2.3870300298350977
Epoch: 9| Step: 3
Training loss: 2.838021009565014
Validation loss: 2.400304520705223
Epoch: 9| Step: 4
Training loss: 3.316006801529226
Validation loss: 2.4272611128067214
Epoch: 9| Step: 5
Training loss: 2.6426790814452943
Validation loss: 2.3439132053019467
Epoch: 9| Step: 6
Training loss: 2.2586809751754737
Validation loss: 2.439619104647717
Epoch: 9| Step: 7
Training loss: 2.6523988518588304
Validation loss: 2.460196482829206
Epoch: 9| Step: 8
Training loss: 2.2944699106145046
Validation loss: 2.3435045847277802
Epoch: 9| Step: 9
Training loss: 2.947963179546004
Validation loss: 2.3671242154147216
Epoch: 9| Step: 10
Training loss: 3.3773496007857604
Validation loss: 2.3985331739521816
Epoch: 9| Step: 11
Training loss: 2.6999372086464426
Validation loss: 2.4266157439903675
Epoch: 9| Step: 12
Training loss: 2.8392956400215374
Validation loss: 2.426804416152652
Epoch: 9| Step: 13
Training loss: 2.6310156058613816
Validation loss: 2.4544942834468384
Epoch: 9| Step: 14
Training loss: 2.233029367153852
Validation loss: 2.3569916055741142
Epoch: 9| Step: 15
Training loss: 2.9634573890399154
Validation loss: 2.4114124352418447
Epoch: 9| Step: 16
Training loss: 2.4075818029907188
Validation loss: 2.355858027012095
Epoch: 9| Step: 17
Training loss: 2.63783288093451
Validation loss: 2.4478797712144265
Epoch: 9| Step: 18
Training loss: 2.546569618686075
Validation loss: 2.504509703122842
Epoch: 9| Step: 19
Training loss: 2.1912404369922442
Validation loss: 2.4403533609054637
Epoch: 43| Step: 0
Training loss: 2.9914141818499567
Validation loss: 2.367992726949728
Epoch: 9| Step: 1
Training loss: 2.4109860665651692
Validation loss: 2.438683740820966
Epoch: 9| Step: 2
Training loss: 2.690420294051206
Validation loss: 2.456454012706896
Epoch: 9| Step: 3
Training loss: 2.6565592866238026
Validation loss: 2.4012521624561116
Epoch: 9| Step: 4
Training loss: 3.08655829643789
Validation loss: 2.342635278711552
Epoch: 9| Step: 5
Training loss: 3.135451273341686
Validation loss: 2.3904110968300976
Epoch: 9| Step: 6
Training loss: 3.0268759089107595
Validation loss: 2.342517273036408
Epoch: 9| Step: 7
Training loss: 2.462151412689725
Validation loss: 2.4200663370957027
Epoch: 9| Step: 8
Training loss: 2.7918172102993917
Validation loss: 2.371001062869228
Epoch: 9| Step: 9
Training loss: 1.9708947503464915
Validation loss: 2.4840472758230008
Epoch: 9| Step: 10
Training loss: 3.334300727338797
Validation loss: 2.3815269625726847
Epoch: 9| Step: 11
Training loss: 2.617501766637809
Validation loss: 2.402415762765584
Epoch: 9| Step: 12
Training loss: 3.2687049468748506
Validation loss: 2.434579903447388
Epoch: 9| Step: 13
Training loss: 2.882207543391203
Validation loss: 2.415008236400856
Epoch: 9| Step: 14
Training loss: 2.5315461162154227
Validation loss: 2.3288519779532635
Epoch: 9| Step: 15
Training loss: 2.48026179854566
Validation loss: 2.3944642124891495
Epoch: 9| Step: 16
Training loss: 3.7634040329416045
Validation loss: 2.510519750683254
Epoch: 9| Step: 17
Training loss: 2.6032228412535807
Validation loss: 2.5169405259257593
Epoch: 9| Step: 18
Training loss: 2.9921903684916082
Validation loss: 2.3729340500847673
Epoch: 9| Step: 19
Training loss: 2.128550536509436
Validation loss: 2.4758664809023134
Epoch: 44| Step: 0
Training loss: 2.8003816412644467
Validation loss: 2.4223811183722668
Epoch: 9| Step: 1
Training loss: 2.6832777167612254
Validation loss: 2.455013907530364
Epoch: 9| Step: 2
Training loss: 2.7594389617522754
Validation loss: 2.310892395530226
Epoch: 9| Step: 3
Training loss: 2.4638897338754875
Validation loss: 2.466140674650671
Epoch: 9| Step: 4
Training loss: 2.4243124232878914
Validation loss: 2.3797213324807935
Epoch: 9| Step: 5
Training loss: 3.189002935590616
Validation loss: 2.403822906978667
Epoch: 9| Step: 6
Training loss: 3.125252217605008
Validation loss: 2.389130668478832
Epoch: 9| Step: 7
Training loss: 3.738556248865026
Validation loss: 2.3966237523788645
Epoch: 9| Step: 8
Training loss: 2.056325745274496
Validation loss: 2.42457550500893
Epoch: 9| Step: 9
Training loss: 1.690969503279982
Validation loss: 2.446857128764517
Epoch: 9| Step: 10
Training loss: 3.072396306522167
Validation loss: 2.3962328721745063
Epoch: 9| Step: 11
Training loss: 2.6822693067686556
Validation loss: 2.3822399231025644
Epoch: 9| Step: 12
Training loss: 2.6398834451319693
Validation loss: 2.458110504261104
Epoch: 9| Step: 13
Training loss: 2.5591318278134256
Validation loss: 2.4456171047593154
Epoch: 9| Step: 14
Training loss: 2.4676443593814743
Validation loss: 2.4435354530811657
Epoch: 9| Step: 15
Training loss: 2.995451658197254
Validation loss: 2.465650864665957
Epoch: 9| Step: 16
Training loss: 3.4439503578569206
Validation loss: 2.451836862477159
Epoch: 9| Step: 17
Training loss: 2.362335974433678
Validation loss: 2.467538177921049
Epoch: 9| Step: 18
Training loss: 2.585602614739484
Validation loss: 2.4876834310450042
Epoch: 9| Step: 19
Training loss: 2.7320032787554656
Validation loss: 2.392774541458062
Epoch: 45| Step: 0
Training loss: 2.8110855784490116
Validation loss: 2.4181693179479646
Epoch: 9| Step: 1
Training loss: 3.0074998569250666
Validation loss: 2.446700083399012
Epoch: 9| Step: 2
Training loss: 2.4431070247758853
Validation loss: 2.411105495032548
Epoch: 9| Step: 3
Training loss: 2.040201738517566
Validation loss: 2.400333554261427
Epoch: 9| Step: 4
Training loss: 2.5216030385456563
Validation loss: 2.3927000895374726
Epoch: 9| Step: 5
Training loss: 3.5439365667517464
Validation loss: 2.4128567543399315
Epoch: 9| Step: 6
Training loss: 2.8274270561111554
Validation loss: 2.3948324367950145
Epoch: 9| Step: 7
Training loss: 2.888867973186713
Validation loss: 2.48675588854002
Epoch: 9| Step: 8
Training loss: 2.0545690234007044
Validation loss: 2.3138143686183086
Epoch: 9| Step: 9
Training loss: 2.4206815670937756
Validation loss: 2.4351660654491525
Epoch: 9| Step: 10
Training loss: 1.9560042254318437
Validation loss: 2.4293644922600754
Epoch: 9| Step: 11
Training loss: 3.2933607128359133
Validation loss: 2.3292933940393135
Epoch: 9| Step: 12
Training loss: 2.3826796197580062
Validation loss: 2.331559190710244
Epoch: 9| Step: 13
Training loss: 3.4542469256149184
Validation loss: 2.5486991289492207
Epoch: 9| Step: 14
Training loss: 1.9047236350733616
Validation loss: 2.497926929694615
Epoch: 9| Step: 15
Training loss: 2.8837564881859037
Validation loss: 2.38538173027046
Epoch: 9| Step: 16
Training loss: 3.173225153059467
Validation loss: 2.4995785305612253
Epoch: 9| Step: 17
Training loss: 3.064928921097818
Validation loss: 2.4065121764836226
Epoch: 9| Step: 18
Training loss: 2.2659789762540155
Validation loss: 2.438647296577538
Epoch: 9| Step: 19
Training loss: 2.998315656213
Validation loss: 2.4525474498543622
Epoch: 46| Step: 0
Training loss: 3.0489178973610676
Validation loss: 2.4065251956839404
Epoch: 9| Step: 1
Training loss: 2.748467018094713
Validation loss: 2.490289942563366
Epoch: 9| Step: 2
Training loss: 3.0378757699625547
Validation loss: 2.3999452752474326
Epoch: 9| Step: 3
Training loss: 2.1173539325006754
Validation loss: 2.370914437399478
Epoch: 9| Step: 4
Training loss: 3.3237904004829746
Validation loss: 2.483534490983094
Epoch: 9| Step: 5
Training loss: 2.861708892380391
Validation loss: 2.3616804027449994
Epoch: 9| Step: 6
Training loss: 2.9589697104112687
Validation loss: 2.4718858861261808
Epoch: 9| Step: 7
Training loss: 3.231271037581117
Validation loss: 2.3883125491969963
Epoch: 9| Step: 8
Training loss: 2.663931029535271
Validation loss: 2.422559001338541
Epoch: 9| Step: 9
Training loss: 2.0483700482911598
Validation loss: 2.3596554325663215
Epoch: 9| Step: 10
Training loss: 3.7405363832460186
Validation loss: 2.3783632934492926
Epoch: 9| Step: 11
Training loss: 2.5282492099045166
Validation loss: 2.4145087804900784
Epoch: 9| Step: 12
Training loss: 2.7108354796635545
Validation loss: 2.4583348414613084
Epoch: 9| Step: 13
Training loss: 2.8606944557510925
Validation loss: 2.4377462534951033
Epoch: 9| Step: 14
Training loss: 2.231529504702747
Validation loss: 2.359914873610056
Epoch: 9| Step: 15
Training loss: 3.0280008107515606
Validation loss: 2.3870690448210556
Epoch: 9| Step: 16
Training loss: 2.8528892461470092
Validation loss: 2.40360199264511
Epoch: 9| Step: 17
Training loss: 2.9607864381608917
Validation loss: 2.461216381206025
Epoch: 9| Step: 18
Training loss: 1.9189441942983383
Validation loss: 2.473801156742509
Epoch: 9| Step: 19
Training loss: 2.2290155115901333
Validation loss: 2.4428908007185512
Epoch: 47| Step: 0
Training loss: 2.48801285330712
Validation loss: 2.403568335424551
Epoch: 9| Step: 1
Training loss: 2.3516401613914986
Validation loss: 2.4698080736170516
Epoch: 9| Step: 2
Training loss: 2.652889953913366
Validation loss: 2.3694219913618606
Epoch: 9| Step: 3
Training loss: 2.664226896074332
Validation loss: 2.4099139300317267
Epoch: 9| Step: 4
Training loss: 2.4341195948236187
Validation loss: 2.345044304230691
Epoch: 9| Step: 5
Training loss: 2.6289544972587917
Validation loss: 2.4002179450955854
Epoch: 9| Step: 6
Training loss: 2.735436108285962
Validation loss: 2.3034471714924893
Epoch: 9| Step: 7
Training loss: 2.9703689176528236
Validation loss: 2.4085643688431264
Epoch: 9| Step: 8
Training loss: 3.1188703311189427
Validation loss: 2.380579135366925
Epoch: 9| Step: 9
Training loss: 2.8566688280605597
Validation loss: 2.5081685299006673
Epoch: 9| Step: 10
Training loss: 1.9948964568685537
Validation loss: 2.368148240581979
Epoch: 9| Step: 11
Training loss: 2.707941075798201
Validation loss: 2.4307280976438657
Epoch: 9| Step: 12
Training loss: 3.212666067143015
Validation loss: 2.4234060238681137
Epoch: 9| Step: 13
Training loss: 3.274454546051558
Validation loss: 2.3687637239604014
Epoch: 9| Step: 14
Training loss: 2.249838081467701
Validation loss: 2.373371650902627
Epoch: 9| Step: 15
Training loss: 2.4700084327831795
Validation loss: 2.3316580930802537
Epoch: 9| Step: 16
Training loss: 3.0330220184985905
Validation loss: 2.471982140607481
Epoch: 9| Step: 17
Training loss: 3.19852023481248
Validation loss: 2.4696409870381024
Epoch: 9| Step: 18
Training loss: 4.050827629390348
Validation loss: 2.418470824265069
Epoch: 9| Step: 19
Training loss: 2.337795883464363
Validation loss: 2.430407965735724
Epoch: 48| Step: 0
Training loss: 3.5184674110567595
Validation loss: 2.4393426278771217
Epoch: 9| Step: 1
Training loss: 3.2093264211155756
Validation loss: 2.391458067137789
Epoch: 9| Step: 2
Training loss: 2.4918237498428257
Validation loss: 2.3169024732163295
Epoch: 9| Step: 3
Training loss: 2.8025205098608854
Validation loss: 2.3478511172695176
Epoch: 9| Step: 4
Training loss: 3.201764669220758
Validation loss: 2.39965312622529
Epoch: 9| Step: 5
Training loss: 2.8954682886214793
Validation loss: 2.406502607869947
Epoch: 9| Step: 6
Training loss: 2.958241868731909
Validation loss: 2.3789280377631483
Epoch: 9| Step: 7
Training loss: 1.9809369919994861
Validation loss: 2.409728552140745
Epoch: 9| Step: 8
Training loss: 1.7176574702585168
Validation loss: 2.43787682776005
Epoch: 9| Step: 9
Training loss: 2.7467182691905583
Validation loss: 2.384046454293662
Epoch: 9| Step: 10
Training loss: 2.3240340984948555
Validation loss: 2.416548790853531
Epoch: 9| Step: 11
Training loss: 2.256404239528699
Validation loss: 2.3473371666836034
Epoch: 9| Step: 12
Training loss: 2.9348244352324055
Validation loss: 2.4216018806445594
Epoch: 9| Step: 13
Training loss: 2.734114105857262
Validation loss: 2.349405767348051
Epoch: 9| Step: 14
Training loss: 2.8307637923485047
Validation loss: 2.4551430131696996
Epoch: 9| Step: 15
Training loss: 3.7478439490809374
Validation loss: 2.387415987775845
Epoch: 9| Step: 16
Training loss: 2.1929632357374116
Validation loss: 2.4094545298318906
Epoch: 9| Step: 17
Training loss: 1.944143104666611
Validation loss: 2.3969938175438914
Epoch: 9| Step: 18
Training loss: 3.3818795060632
Validation loss: 2.4691802095027633
Epoch: 9| Step: 19
Training loss: 2.414025068764467
Validation loss: 2.25677523385688
Epoch: 49| Step: 0
Training loss: 3.081332786330017
Validation loss: 2.417045034563247
Epoch: 9| Step: 1
Training loss: 2.35893700178308
Validation loss: 2.4153775242085165
Epoch: 9| Step: 2
Training loss: 2.4117335470750914
Validation loss: 2.357406425781512
Epoch: 9| Step: 3
Training loss: 3.065077806141736
Validation loss: 2.4281119618520464
Epoch: 9| Step: 4
Training loss: 2.457091799234062
Validation loss: 2.350329541335893
Epoch: 9| Step: 5
Training loss: 2.9644549973125427
Validation loss: 2.4432745170127275
Epoch: 9| Step: 6
Training loss: 3.312990260281741
Validation loss: 2.4763422130730324
Epoch: 9| Step: 7
Training loss: 2.17031507938196
Validation loss: 2.3964992119198705
Epoch: 9| Step: 8
Training loss: 2.0417724374374577
Validation loss: 2.387025132203539
Epoch: 9| Step: 9
Training loss: 2.6192631475932946
Validation loss: 2.465768030962354
Epoch: 9| Step: 10
Training loss: 2.651876911321774
Validation loss: 2.3400684862307215
Epoch: 9| Step: 11
Training loss: 2.9449770303811635
Validation loss: 2.477849988289474
Epoch: 9| Step: 12
Training loss: 2.3003337535024
Validation loss: 2.4259344567813472
Epoch: 9| Step: 13
Training loss: 3.8342676820791888
Validation loss: 2.3748702470426704
Epoch: 9| Step: 14
Training loss: 2.7489119891651725
Validation loss: 2.426786804313358
Epoch: 9| Step: 15
Training loss: 2.9106166398622757
Validation loss: 2.3693845484820786
Epoch: 9| Step: 16
Training loss: 2.260604663068708
Validation loss: 2.379988280754204
Epoch: 9| Step: 17
Training loss: 3.4895670572537094
Validation loss: 2.328577971184162
Epoch: 9| Step: 18
Training loss: 2.64424129457313
Validation loss: 2.4587003069643742
Epoch: 9| Step: 19
Training loss: 2.112972667114716
Validation loss: 2.43028956411801
Epoch: 50| Step: 0
Training loss: 2.1934470942986204
Validation loss: 2.434776994161564
Epoch: 9| Step: 1
Training loss: 2.9847935887317205
Validation loss: 2.3853517681848624
Epoch: 9| Step: 2
Training loss: 3.0797703407173884
Validation loss: 2.4013461647530345
Epoch: 9| Step: 3
Training loss: 3.1923838580699573
Validation loss: 2.4327989770064047
Epoch: 9| Step: 4
Training loss: 3.6656084845675743
Validation loss: 2.3595297963777537
Epoch: 9| Step: 5
Training loss: 2.811661319723813
Validation loss: 2.4421692478991797
Epoch: 9| Step: 6
Training loss: 2.4860584625219793
Validation loss: 2.3943468342870373
Epoch: 9| Step: 7
Training loss: 2.617731476233771
Validation loss: 2.4531429817822
Epoch: 9| Step: 8
Training loss: 2.0960674840167934
Validation loss: 2.3543889620060248
Epoch: 9| Step: 9
Training loss: 2.32283371120064
Validation loss: 2.361560024968869
Epoch: 9| Step: 10
Training loss: 2.0515047087014495
Validation loss: 2.4330587340069836
Epoch: 9| Step: 11
Training loss: 2.621499497778286
Validation loss: 2.408050640474105
Epoch: 9| Step: 12
Training loss: 2.6689663051166272
Validation loss: 2.4524404368114463
Epoch: 9| Step: 13
Training loss: 2.604133046251075
Validation loss: 2.4499748640188894
Epoch: 9| Step: 14
Training loss: 3.004216092602975
Validation loss: 2.4805976085102905
Epoch: 9| Step: 15
Training loss: 2.567608556040426
Validation loss: 2.4245609324602313
Epoch: 9| Step: 16
Training loss: 2.5026585747993275
Validation loss: 2.387678247255885
Epoch: 9| Step: 17
Training loss: 2.508619517310147
Validation loss: 2.424414760146962
Epoch: 9| Step: 18
Training loss: 2.6957565163030637
Validation loss: 2.3792349351371596
Epoch: 9| Step: 19
Training loss: 3.599247451114673
Validation loss: 2.360001913989113
Epoch: 51| Step: 0
Training loss: 2.5028006125577567
Validation loss: 2.4287695708859447
Epoch: 9| Step: 1
Training loss: 2.6371511147243893
Validation loss: 2.508138009224541
Epoch: 9| Step: 2
Training loss: 2.0571761344307125
Validation loss: 2.5092913981385476
Epoch: 9| Step: 3
Training loss: 3.210222819072798
Validation loss: 2.3494324632032195
Epoch: 9| Step: 4
Training loss: 2.572771467263681
Validation loss: 2.3264190655080976
Epoch: 9| Step: 5
Training loss: 3.030354947743575
Validation loss: 2.435929355141904
Epoch: 9| Step: 6
Training loss: 2.555669100169376
Validation loss: 2.325332988782753
Epoch: 9| Step: 7
Training loss: 3.172722012783022
Validation loss: 2.399619790891405
Epoch: 9| Step: 8
Training loss: 2.7082773838621947
Validation loss: 2.361409869321133
Epoch: 9| Step: 9
Training loss: 3.3537215101330786
Validation loss: 2.4485071451856975
Epoch: 9| Step: 10
Training loss: 2.1909636188169563
Validation loss: 2.3434388207678736
Epoch: 9| Step: 11
Training loss: 2.0825160394350855
Validation loss: 2.3074584861471523
Epoch: 9| Step: 12
Training loss: 2.8466285975797043
Validation loss: 2.4105985001284003
Epoch: 9| Step: 13
Training loss: 3.467325966448061
Validation loss: 2.323440327497621
Epoch: 9| Step: 14
Training loss: 2.5727907425391243
Validation loss: 2.4719378816813546
Epoch: 9| Step: 15
Training loss: 3.450039412784739
Validation loss: 2.5010813744387104
Epoch: 9| Step: 16
Training loss: 2.3608145458992316
Validation loss: 2.302776118408401
Epoch: 9| Step: 17
Training loss: 2.064217517007239
Validation loss: 2.406924083550912
Epoch: 9| Step: 18
Training loss: 3.5219992939798317
Validation loss: 2.3693683547219444
Epoch: 9| Step: 19
Training loss: 2.212828996411245
Validation loss: 2.3588738554230764
Epoch: 52| Step: 0
Training loss: 2.5263310427267975
Validation loss: 2.3847044206826813
Epoch: 9| Step: 1
Training loss: 3.068167910560401
Validation loss: 2.4110506070537774
Epoch: 9| Step: 2
Training loss: 2.4582120790050257
Validation loss: 2.368946233903098
Epoch: 9| Step: 3
Training loss: 3.0233532797741796
Validation loss: 2.3948247909573106
Epoch: 9| Step: 4
Training loss: 2.7835030163268435
Validation loss: 2.4134278157861573
Epoch: 9| Step: 5
Training loss: 3.1893883889537915
Validation loss: 2.3165868300906296
Epoch: 9| Step: 6
Training loss: 3.091375653604987
Validation loss: 2.4052566089771568
Epoch: 9| Step: 7
Training loss: 3.216546647067888
Validation loss: 2.361902759950139
Epoch: 9| Step: 8
Training loss: 2.2183126099055817
Validation loss: 2.4061210497039904
Epoch: 9| Step: 9
Training loss: 2.7412986075444423
Validation loss: 2.423192063794315
Epoch: 9| Step: 10
Training loss: 2.2336964677352973
Validation loss: 2.35064496637815
Epoch: 9| Step: 11
Training loss: 2.753403031927143
Validation loss: 2.3946945594415383
Epoch: 9| Step: 12
Training loss: 3.0275822108704333
Validation loss: 2.436798248383648
Epoch: 9| Step: 13
Training loss: 2.07661440449322
Validation loss: 2.41790456641601
Epoch: 9| Step: 14
Training loss: 2.3172280717668845
Validation loss: 2.3850514702410908
Epoch: 9| Step: 15
Training loss: 2.413167843264203
Validation loss: 2.3361703311304014
Epoch: 9| Step: 16
Training loss: 3.115278151632071
Validation loss: 2.3409412032995025
Epoch: 9| Step: 17
Training loss: 2.4060504384703534
Validation loss: 2.4017750681384538
Epoch: 9| Step: 18
Training loss: 2.7834229285463814
Validation loss: 2.3940305142337883
Epoch: 9| Step: 19
Training loss: 2.9310159748413844
Validation loss: 2.385197847434331
Epoch: 53| Step: 0
Training loss: 3.279752116954791
Validation loss: 2.4422606174500228
Epoch: 9| Step: 1
Training loss: 3.4275272317662937
Validation loss: 2.3563112887782123
Epoch: 9| Step: 2
Training loss: 2.141692848886639
Validation loss: 2.3882080408197774
Epoch: 9| Step: 3
Training loss: 2.631218945825136
Validation loss: 2.3587338073756534
Epoch: 9| Step: 4
Training loss: 2.475326277679215
Validation loss: 2.3397278253577896
Epoch: 9| Step: 5
Training loss: 2.931822138992661
Validation loss: 2.3674995162290107
Epoch: 9| Step: 6
Training loss: 2.984502979350572
Validation loss: 2.400226649977924
Epoch: 9| Step: 7
Training loss: 2.1353895108116743
Validation loss: 2.3605258710474217
Epoch: 9| Step: 8
Training loss: 1.8888245513966782
Validation loss: 2.4129758447122542
Epoch: 9| Step: 9
Training loss: 3.8145561302016495
Validation loss: 2.3646711610012634
Epoch: 9| Step: 10
Training loss: 2.4201036435781837
Validation loss: 2.49972097074999
Epoch: 9| Step: 11
Training loss: 2.7724890578168404
Validation loss: 2.3553766850268008
Epoch: 9| Step: 12
Training loss: 2.2703206828128084
Validation loss: 2.463880784597161
Epoch: 9| Step: 13
Training loss: 3.0319351523115174
Validation loss: 2.516832238666374
Epoch: 9| Step: 14
Training loss: 2.6368765324608257
Validation loss: 2.4124664832305855
Epoch: 9| Step: 15
Training loss: 2.6102379382771574
Validation loss: 2.3797923547567503
Epoch: 9| Step: 16
Training loss: 3.3928566896825503
Validation loss: 2.3180363899815832
Epoch: 9| Step: 17
Training loss: 2.466323722592061
Validation loss: 2.41630133465911
Epoch: 9| Step: 18
Training loss: 2.886231418713365
Validation loss: 2.349940581673345
Epoch: 9| Step: 19
Training loss: 2.228220753799123
Validation loss: 2.45950469518893
Epoch: 54| Step: 0
Training loss: 2.7659930830156694
Validation loss: 2.419834361954314
Epoch: 9| Step: 1
Training loss: 2.3693854574195603
Validation loss: 2.4313793344026235
Epoch: 9| Step: 2
Training loss: 3.587458933950771
Validation loss: 2.3891660717932552
Epoch: 9| Step: 3
Training loss: 2.794408296520237
Validation loss: 2.38915393463508
Epoch: 9| Step: 4
Training loss: 2.0554311588667553
Validation loss: 2.3410746835585043
Epoch: 9| Step: 5
Training loss: 2.4535821379397893
Validation loss: 2.3134251709845945
Epoch: 9| Step: 6
Training loss: 2.429996581212531
Validation loss: 2.394401405822973
Epoch: 9| Step: 7
Training loss: 3.0582533996558148
Validation loss: 2.472384080067948
Epoch: 9| Step: 8
Training loss: 3.224359457588928
Validation loss: 2.3763700980948816
Epoch: 9| Step: 9
Training loss: 3.0852215286423665
Validation loss: 2.3923455810557077
Epoch: 9| Step: 10
Training loss: 2.6399636427947866
Validation loss: 2.3384727418284976
Epoch: 9| Step: 11
Training loss: 2.5908497601275964
Validation loss: 2.372450903459386
Epoch: 9| Step: 12
Training loss: 1.9437529658941965
Validation loss: 2.3660226651732432
Epoch: 9| Step: 13
Training loss: 2.953949989654841
Validation loss: 2.3624327044721385
Epoch: 9| Step: 14
Training loss: 2.1891146559019172
Validation loss: 2.401998516004531
Epoch: 9| Step: 15
Training loss: 2.319531036202205
Validation loss: 2.349501654053233
Epoch: 9| Step: 16
Training loss: 2.6792379730686497
Validation loss: 2.4668886197947035
Epoch: 9| Step: 17
Training loss: 3.288441941532803
Validation loss: 2.3697352893715875
Epoch: 9| Step: 18
Training loss: 3.574464349698856
Validation loss: 2.3031944834694986
Epoch: 9| Step: 19
Training loss: 2.6338121457727337
Validation loss: 2.4622134569369303
Epoch: 55| Step: 0
Training loss: 3.0456654813327955
Validation loss: 2.3826368711071026
Epoch: 9| Step: 1
Training loss: 2.404792641565127
Validation loss: 2.430757143276869
Epoch: 9| Step: 2
Training loss: 2.7807663057605936
Validation loss: 2.4730778949934313
Epoch: 9| Step: 3
Training loss: 2.9222669695517225
Validation loss: 2.465885828124579
Epoch: 9| Step: 4
Training loss: 2.5388363781522623
Validation loss: 2.3460298467903504
Epoch: 9| Step: 5
Training loss: 3.764429306203506
Validation loss: 2.401331412132914
Epoch: 9| Step: 6
Training loss: 3.0127918592714766
Validation loss: 2.4010321482322574
Epoch: 9| Step: 7
Training loss: 2.710279225396206
Validation loss: 2.4621230435617867
Epoch: 9| Step: 8
Training loss: 2.956691304146846
Validation loss: 2.376037595277226
Epoch: 9| Step: 9
Training loss: 2.5473284171498847
Validation loss: 2.437715028317182
Epoch: 9| Step: 10
Training loss: 2.72066491751259
Validation loss: 2.335613563815876
Epoch: 9| Step: 11
Training loss: 2.817857513897381
Validation loss: 2.477214394448902
Epoch: 9| Step: 12
Training loss: 2.438487806435581
Validation loss: 2.444362233272334
Epoch: 9| Step: 13
Training loss: 3.1351741726570004
Validation loss: 2.363869119608731
Epoch: 9| Step: 14
Training loss: 2.676647541679317
Validation loss: 2.386640488210756
Epoch: 9| Step: 15
Training loss: 3.1196838937696714
Validation loss: 2.4043143694541955
Epoch: 9| Step: 16
Training loss: 2.420437195276522
Validation loss: 2.4452654482749847
Epoch: 9| Step: 17
Training loss: 2.565612670274071
Validation loss: 2.339354505248043
Epoch: 9| Step: 18
Training loss: 2.987971829619893
Validation loss: 2.4009017094057845
Epoch: 9| Step: 19
Training loss: 2.683269986496806
Validation loss: 2.404791280391249
Epoch: 56| Step: 0
Training loss: 3.4326692796989726
Validation loss: 2.3297686648253264
Epoch: 9| Step: 1
Training loss: 1.6548230484006272
Validation loss: 2.417694296055022
Epoch: 9| Step: 2
Training loss: 2.2066183328473254
Validation loss: 2.3747157941338695
Epoch: 9| Step: 3
Training loss: 2.49192057648009
Validation loss: 2.397417757984247
Epoch: 9| Step: 4
Training loss: 3.567815863480845
Validation loss: 2.338143206450324
Epoch: 9| Step: 5
Training loss: 2.3268279488453443
Validation loss: 2.3729174895106353
Epoch: 9| Step: 6
Training loss: 3.5753272166923264
Validation loss: 2.420411056992321
Epoch: 9| Step: 7
Training loss: 2.8154716051932858
Validation loss: 2.3851770307571787
Epoch: 9| Step: 8
Training loss: 2.651527425233912
Validation loss: 2.422048002364179
Epoch: 9| Step: 9
Training loss: 2.287982568754473
Validation loss: 2.472098554334575
Epoch: 9| Step: 10
Training loss: 3.1535478865987256
Validation loss: 2.3757005314573068
Epoch: 9| Step: 11
Training loss: 3.0372467500583067
Validation loss: 2.389904418555314
Epoch: 9| Step: 12
Training loss: 3.1901186489892357
Validation loss: 2.419678402023995
Epoch: 9| Step: 13
Training loss: 2.0400154547012437
Validation loss: 2.391159858327374
Epoch: 9| Step: 14
Training loss: 3.120558825356017
Validation loss: 2.4586920084093147
Epoch: 9| Step: 15
Training loss: 2.2245630756815027
Validation loss: 2.3052031459966407
Epoch: 9| Step: 16
Training loss: 2.0658372409296826
Validation loss: 2.324951949653652
Epoch: 9| Step: 17
Training loss: 2.6114726515201054
Validation loss: 2.487012043733237
Epoch: 9| Step: 18
Training loss: 2.165971705659614
Validation loss: 2.349948895996623
Epoch: 9| Step: 19
Training loss: 2.76226378246511
Validation loss: 2.459982820741782
Epoch: 57| Step: 0
Training loss: 2.1971183761424777
Validation loss: 2.313047279697757
Epoch: 9| Step: 1
Training loss: 2.6308770465894527
Validation loss: 2.409718026400846
Epoch: 9| Step: 2
Training loss: 2.9690525904591367
Validation loss: 2.322459579118841
Epoch: 9| Step: 3
Training loss: 2.381265106553747
Validation loss: 2.3234259396723553
Epoch: 9| Step: 4
Training loss: 2.6673100609266642
Validation loss: 2.381109471831163
Epoch: 9| Step: 5
Training loss: 2.990048592724377
Validation loss: 2.442386042932059
Epoch: 9| Step: 6
Training loss: 2.620601056292284
Validation loss: 2.3652062395848876
Epoch: 9| Step: 7
Training loss: 3.4564709225456127
Validation loss: 2.4371645221365723
Epoch: 9| Step: 8
Training loss: 2.511658948124107
Validation loss: 2.458584849504603
Epoch: 9| Step: 9
Training loss: 1.8462889695235616
Validation loss: 2.3663049712947
Epoch: 9| Step: 10
Training loss: 3.2908384190514695
Validation loss: 2.3782415847744494
Epoch: 9| Step: 11
Training loss: 3.1601675667577807
Validation loss: 2.431547523897712
Epoch: 9| Step: 12
Training loss: 2.8186397928486415
Validation loss: 2.3628036536918304
Epoch: 9| Step: 13
Training loss: 2.978093592026801
Validation loss: 2.4423888059637804
Epoch: 9| Step: 14
Training loss: 2.2021546086734483
Validation loss: 2.4436638363382004
Epoch: 9| Step: 15
Training loss: 2.9140049005701543
Validation loss: 2.3989305398121448
Epoch: 9| Step: 16
Training loss: 2.4802920781693807
Validation loss: 2.404681908300754
Epoch: 9| Step: 17
Training loss: 2.6734307650777236
Validation loss: 2.462260059706729
Epoch: 9| Step: 18
Training loss: 2.5441128783585034
Validation loss: 2.4673454418748055
Epoch: 9| Step: 19
Training loss: 3.111021899654812
Validation loss: 2.4347252040028455
Epoch: 58| Step: 0
Training loss: 3.052641278370923
Validation loss: 2.3551965493902403
Epoch: 9| Step: 1
Training loss: 2.4423117461422157
Validation loss: 2.3922731774348067
Epoch: 9| Step: 2
Training loss: 3.0456421534233113
Validation loss: 2.345430407737182
Epoch: 9| Step: 3
Training loss: 3.4162919994331027
Validation loss: 2.4067822833377024
Epoch: 9| Step: 4
Training loss: 3.262168697913623
Validation loss: 2.52374820368705
Epoch: 9| Step: 5
Training loss: 2.1762516191313286
Validation loss: 2.328924446797056
Epoch: 9| Step: 6
Training loss: 2.528708418213389
Validation loss: 2.4741080705314724
Epoch: 9| Step: 7
Training loss: 2.560250294936686
Validation loss: 2.3531947080470155
Epoch: 9| Step: 8
Training loss: 2.681574654653307
Validation loss: 2.491462141900037
Epoch: 9| Step: 9
Training loss: 2.9042417088741863
Validation loss: 2.3475008101604775
Epoch: 9| Step: 10
Training loss: 1.6017201415842865
Validation loss: 2.3478585893495927
Epoch: 9| Step: 11
Training loss: 2.7068764998775987
Validation loss: 2.3831339198293113
Epoch: 9| Step: 12
Training loss: 3.3711330725364466
Validation loss: 2.357499959281854
Epoch: 9| Step: 13
Training loss: 3.656917674080181
Validation loss: 2.4122709679455574
Epoch: 9| Step: 14
Training loss: 2.536474511149132
Validation loss: 2.3948001498527245
Epoch: 9| Step: 15
Training loss: 3.1754103628177
Validation loss: 2.399074158113489
Epoch: 9| Step: 16
Training loss: 2.7428658453343484
Validation loss: 2.359476064602799
Epoch: 9| Step: 17
Training loss: 2.0694387067449282
Validation loss: 2.439531750920122
Epoch: 9| Step: 18
Training loss: 2.6840153658635963
Validation loss: 2.3329741386380443
Epoch: 9| Step: 19
Training loss: 2.16650187036824
Validation loss: 2.457512098379624
Epoch: 59| Step: 0
Training loss: 2.7346984671955945
Validation loss: 2.3690747687549334
Epoch: 9| Step: 1
Training loss: 3.6756598263021303
Validation loss: 2.359693354883321
Epoch: 9| Step: 2
Training loss: 3.0715439828626363
Validation loss: 2.489475335211505
Epoch: 9| Step: 3
Training loss: 2.9708355454645754
Validation loss: 2.292706805271756
Epoch: 9| Step: 4
Training loss: 2.7416127355154534
Validation loss: 2.42194894056282
Epoch: 9| Step: 5
Training loss: 2.0070792317548163
Validation loss: 2.3978026826418244
Epoch: 9| Step: 6
Training loss: 2.6674147291774597
Validation loss: 2.393876171552021
Epoch: 9| Step: 7
Training loss: 2.760827510177807
Validation loss: 2.46780636346799
Epoch: 9| Step: 8
Training loss: 3.2713899240096875
Validation loss: 2.382842812343132
Epoch: 9| Step: 9
Training loss: 2.3989794985430644
Validation loss: 2.357076965115844
Epoch: 9| Step: 10
Training loss: 2.9133106724303675
Validation loss: 2.412471766466588
Epoch: 9| Step: 11
Training loss: 2.632119922497353
Validation loss: 2.4004498598081745
Epoch: 9| Step: 12
Training loss: 2.2904572387714164
Validation loss: 2.37140615690183
Epoch: 9| Step: 13
Training loss: 2.726077236069327
Validation loss: 2.4041842006852527
Epoch: 9| Step: 14
Training loss: 3.0730747677924115
Validation loss: 2.4153150745741945
Epoch: 9| Step: 15
Training loss: 2.4514043325406605
Validation loss: 2.3951743148948275
Epoch: 9| Step: 16
Training loss: 2.309121421757089
Validation loss: 2.372744732391835
Epoch: 9| Step: 17
Training loss: 3.485587965242011
Validation loss: 2.3834410960491383
Epoch: 9| Step: 18
Training loss: 2.134797119578405
Validation loss: 2.4339914664203706
Epoch: 9| Step: 19
Training loss: 2.886706856792144
Validation loss: 2.398651994563029
Epoch: 60| Step: 0
Training loss: 2.914129752439018
Validation loss: 2.384303580302952
Epoch: 9| Step: 1
Training loss: 2.5991991093371913
Validation loss: 2.3929394712864682
Epoch: 9| Step: 2
Training loss: 2.1519063792515407
Validation loss: 2.366892091237722
Epoch: 9| Step: 3
Training loss: 2.579573530686754
Validation loss: 2.4160517511477777
Epoch: 9| Step: 4
Training loss: 2.486602456420333
Validation loss: 2.313349556320499
Epoch: 9| Step: 5
Training loss: 2.5624806473164035
Validation loss: 2.412985638072009
Epoch: 9| Step: 6
Training loss: 2.854210029513968
Validation loss: 2.3486130836155543
Epoch: 9| Step: 7
Training loss: 2.6861423345533075
Validation loss: 2.438941699262908
Epoch: 9| Step: 8
Training loss: 3.3452792369573237
Validation loss: 2.328058209550964
Epoch: 9| Step: 9
Training loss: 3.180777847836148
Validation loss: 2.389329281419308
Epoch: 9| Step: 10
Training loss: 2.3159788615525407
Validation loss: 2.3447050239284857
Epoch: 9| Step: 11
Training loss: 2.309915903055133
Validation loss: 2.38633035654864
Epoch: 9| Step: 12
Training loss: 2.7813625527228054
Validation loss: 2.3187593811913865
Epoch: 9| Step: 13
Training loss: 2.0861523692586963
Validation loss: 2.3956016491755774
Epoch: 9| Step: 14
Training loss: 2.515345397953987
Validation loss: 2.345672091453674
Epoch: 9| Step: 15
Training loss: 3.116423472607681
Validation loss: 2.3267776235703916
Epoch: 9| Step: 16
Training loss: 2.293639830560318
Validation loss: 2.342012434003907
Epoch: 9| Step: 17
Training loss: 3.411096047924911
Validation loss: 2.493706115957508
Epoch: 9| Step: 18
Training loss: 2.855935952181678
Validation loss: 2.422525027228302
Epoch: 9| Step: 19
Training loss: 3.016023125334703
Validation loss: 2.347397838407381
Epoch: 61| Step: 0
Training loss: 2.798617113441949
Validation loss: 2.400420711573192
Epoch: 9| Step: 1
Training loss: 3.2449345360781345
Validation loss: 2.525301868712567
Epoch: 9| Step: 2
Training loss: 2.8675797945076704
Validation loss: 2.388401183611995
Epoch: 9| Step: 3
Training loss: 1.8637982496927776
Validation loss: 2.3781678064106493
Epoch: 9| Step: 4
Training loss: 2.852140519595426
Validation loss: 2.2904060700564193
Epoch: 9| Step: 5
Training loss: 3.4079434446200123
Validation loss: 2.4176725694223005
Epoch: 9| Step: 6
Training loss: 2.6949342324011867
Validation loss: 2.367556716558466
Epoch: 9| Step: 7
Training loss: 1.8070888643691008
Validation loss: 2.327066491906935
Epoch: 9| Step: 8
Training loss: 2.910234898266107
Validation loss: 2.429888046839646
Epoch: 9| Step: 9
Training loss: 2.5854378301065273
Validation loss: 2.380254467238637
Epoch: 9| Step: 10
Training loss: 2.968026484615477
Validation loss: 2.4427973082523557
Epoch: 9| Step: 11
Training loss: 2.215877123693263
Validation loss: 2.3976168483354576
Epoch: 9| Step: 12
Training loss: 2.915101385169207
Validation loss: 2.5221993925197648
Epoch: 9| Step: 13
Training loss: 3.284219905483377
Validation loss: 2.3660201259550213
Epoch: 9| Step: 14
Training loss: 2.499711783007775
Validation loss: 2.435301345422983
Epoch: 9| Step: 15
Training loss: 3.0415603061700645
Validation loss: 2.3755167144529232
Epoch: 9| Step: 16
Training loss: 2.9770986319474306
Validation loss: 2.32855950009356
Epoch: 9| Step: 17
Training loss: 2.599617629177824
Validation loss: 2.450055970846668
Epoch: 9| Step: 18
Training loss: 2.893699207230895
Validation loss: 2.3955157291011915
Epoch: 9| Step: 19
Training loss: 2.214438964884609
Validation loss: 2.3769219519641713
Epoch: 62| Step: 0
Training loss: 2.6345114277801582
Validation loss: 2.283347935856527
Epoch: 9| Step: 1
Training loss: 2.3941642143891104
Validation loss: 2.4201719557169694
Epoch: 9| Step: 2
Training loss: 2.083931976775078
Validation loss: 2.4057016825534596
Epoch: 9| Step: 3
Training loss: 3.736250019603128
Validation loss: 2.344242123091095
Epoch: 9| Step: 4
Training loss: 2.579582680802922
Validation loss: 2.4081659366299046
Epoch: 9| Step: 5
Training loss: 2.4166319175940463
Validation loss: 2.3340681265625003
Epoch: 9| Step: 6
Training loss: 2.69323066254496
Validation loss: 2.3935760810923754
Epoch: 9| Step: 7
Training loss: 2.353954328114995
Validation loss: 2.3430014264359293
Epoch: 9| Step: 8
Training loss: 3.091769731008452
Validation loss: 2.500713063898336
Epoch: 9| Step: 9
Training loss: 2.383388062051036
Validation loss: 2.3433025810953687
Epoch: 9| Step: 10
Training loss: 2.373478452267664
Validation loss: 2.4159612375099004
Epoch: 9| Step: 11
Training loss: 2.454818821143653
Validation loss: 2.3429580597569823
Epoch: 9| Step: 12
Training loss: 2.5941461467411306
Validation loss: 2.3790412351047743
Epoch: 9| Step: 13
Training loss: 2.9130898660089164
Validation loss: 2.493882873489097
Epoch: 9| Step: 14
Training loss: 2.354447024595367
Validation loss: 2.466036183030808
Epoch: 9| Step: 15
Training loss: 3.060150179200801
Validation loss: 2.4211117002279505
Epoch: 9| Step: 16
Training loss: 3.308123594565195
Validation loss: 2.3913857401356586
Epoch: 9| Step: 17
Training loss: 2.9673926211744686
Validation loss: 2.421323999172881
Epoch: 9| Step: 18
Training loss: 3.131708497611754
Validation loss: 2.347805952910467
Epoch: 9| Step: 19
Training loss: 3.0386677071253074
Validation loss: 2.391825544013236
Epoch: 63| Step: 0
Training loss: 2.809284067008306
Validation loss: 2.422956527418104
Epoch: 9| Step: 1
Training loss: 2.171514906636861
Validation loss: 2.437653113028745
Epoch: 9| Step: 2
Training loss: 2.552331800756866
Validation loss: 2.4106383387470425
Epoch: 9| Step: 3
Training loss: 2.929610513311384
Validation loss: 2.448561884179255
Epoch: 9| Step: 4
Training loss: 3.3496681675325046
Validation loss: 2.341439301881853
Epoch: 9| Step: 5
Training loss: 2.92358478968217
Validation loss: 2.399667786295246
Epoch: 9| Step: 6
Training loss: 2.0857753047676924
Validation loss: 2.439683426405539
Epoch: 9| Step: 7
Training loss: 1.9673118788323753
Validation loss: 2.384240273147831
Epoch: 9| Step: 8
Training loss: 3.680686086263374
Validation loss: 2.458842545134462
Epoch: 9| Step: 9
Training loss: 2.881640519096514
Validation loss: 2.3895642427693353
Epoch: 9| Step: 10
Training loss: 2.1975759329495537
Validation loss: 2.371669401558508
Epoch: 9| Step: 11
Training loss: 2.3295929652272895
Validation loss: 2.3052814309134417
Epoch: 9| Step: 12
Training loss: 2.1610449951091324
Validation loss: 2.4335723123226622
Epoch: 9| Step: 13
Training loss: 2.478372484046281
Validation loss: 2.3719589180873806
Epoch: 9| Step: 14
Training loss: 2.49289054879452
Validation loss: 2.3912733498865006
Epoch: 9| Step: 15
Training loss: 3.0080223902011056
Validation loss: 2.38132000635129
Epoch: 9| Step: 16
Training loss: 2.7275289227344643
Validation loss: 2.363083630977749
Epoch: 9| Step: 17
Training loss: 2.177795901947552
Validation loss: 2.3306024413569704
Epoch: 9| Step: 18
Training loss: 2.97650611003016
Validation loss: 2.4054041343866404
Epoch: 9| Step: 19
Training loss: 3.2337644433818555
Validation loss: 2.400467932746864
Epoch: 64| Step: 0
Training loss: 2.7049242327051033
Validation loss: 2.369497714089404
Epoch: 9| Step: 1
Training loss: 3.154357040351123
Validation loss: 2.412063446056825
Epoch: 9| Step: 2
Training loss: 2.311938758995986
Validation loss: 2.421745437087701
Epoch: 9| Step: 3
Training loss: 2.397755479297457
Validation loss: 2.3802504124314843
Epoch: 9| Step: 4
Training loss: 3.0450178697684964
Validation loss: 2.30385377236179
Epoch: 9| Step: 5
Training loss: 3.52159297054201
Validation loss: 2.3014792082828293
Epoch: 9| Step: 6
Training loss: 3.0293439397838884
Validation loss: 2.330844079023673
Epoch: 9| Step: 7
Training loss: 2.0280233725079393
Validation loss: 2.3896234342700917
Epoch: 9| Step: 8
Training loss: 3.122992213893911
Validation loss: 2.394485582779236
Epoch: 9| Step: 9
Training loss: 2.4938522088466053
Validation loss: 2.4026082499227766
Epoch: 9| Step: 10
Training loss: 2.6043281403388927
Validation loss: 2.3441053181277827
Epoch: 9| Step: 11
Training loss: 3.416227514065251
Validation loss: 2.394066357146149
Epoch: 9| Step: 12
Training loss: 2.7123017410039263
Validation loss: 2.3339128811319827
Epoch: 9| Step: 13
Training loss: 3.397160292281281
Validation loss: 2.30612617778664
Epoch: 9| Step: 14
Training loss: 2.0269208110439747
Validation loss: 2.3700358088750773
Epoch: 9| Step: 15
Training loss: 2.515513921145257
Validation loss: 2.376014470726009
Epoch: 9| Step: 16
Training loss: 2.1605503488477202
Validation loss: 2.3458672944244134
Epoch: 9| Step: 17
Training loss: 2.6505160207186873
Validation loss: 2.4584108692431466
Epoch: 9| Step: 18
Training loss: 2.7424677952811582
Validation loss: 2.3389242300804525
Epoch: 9| Step: 19
Training loss: 1.9347326758398122
Validation loss: 2.3443569092864505
Epoch: 65| Step: 0
Training loss: 3.3477187801828525
Validation loss: 2.3748334311304173
Epoch: 9| Step: 1
Training loss: 2.219627958860862
Validation loss: 2.375248664564306
Epoch: 9| Step: 2
Training loss: 2.5010354758655637
Validation loss: 2.389408599192439
Epoch: 9| Step: 3
Training loss: 3.1454794644698234
Validation loss: 2.436033462640715
Epoch: 9| Step: 4
Training loss: 2.5481040189102413
Validation loss: 2.382436612637161
Epoch: 9| Step: 5
Training loss: 3.0678255137594665
Validation loss: 2.3972628507498164
Epoch: 9| Step: 6
Training loss: 2.6576875274897187
Validation loss: 2.345538626251338
Epoch: 9| Step: 7
Training loss: 2.9768719850180907
Validation loss: 2.434033928536507
Epoch: 9| Step: 8
Training loss: 2.2227044125452435
Validation loss: 2.4476597381228595
Epoch: 9| Step: 9
Training loss: 2.504851592763535
Validation loss: 2.3624743259892615
Epoch: 9| Step: 10
Training loss: 2.664119596792378
Validation loss: 2.372208397557099
Epoch: 9| Step: 11
Training loss: 2.8676015778354045
Validation loss: 2.355311696359541
Epoch: 9| Step: 12
Training loss: 2.8304988108762
Validation loss: 2.4584970136688296
Epoch: 9| Step: 13
Training loss: 2.3420115826627366
Validation loss: 2.3270775208161245
Epoch: 9| Step: 14
Training loss: 2.9175520143554814
Validation loss: 2.3406182371908772
Epoch: 9| Step: 15
Training loss: 2.3772936336513766
Validation loss: 2.4476876895219473
Epoch: 9| Step: 16
Training loss: 3.0225907749273273
Validation loss: 2.376513328115439
Epoch: 9| Step: 17
Training loss: 3.1170042361737647
Validation loss: 2.3605373102291614
Epoch: 9| Step: 18
Training loss: 1.9196587165861756
Validation loss: 2.365134211751129
Epoch: 9| Step: 19
Training loss: 2.5761653041105075
Validation loss: 2.296842848218542
Epoch: 66| Step: 0
Training loss: 3.0709774471785205
Validation loss: 2.4175712014398174
Epoch: 9| Step: 1
Training loss: 3.2111299554549815
Validation loss: 2.378280407998146
Epoch: 9| Step: 2
Training loss: 2.2087908456821985
Validation loss: 2.3687586425659246
Epoch: 9| Step: 3
Training loss: 2.8213838777227096
Validation loss: 2.4044259240288306
Epoch: 9| Step: 4
Training loss: 2.881593193086827
Validation loss: 2.37393781086318
Epoch: 9| Step: 5
Training loss: 3.2948576192237855
Validation loss: 2.4264143660651465
Epoch: 9| Step: 6
Training loss: 2.351619073434413
Validation loss: 2.3163189077113127
Epoch: 9| Step: 7
Training loss: 2.2415187782183463
Validation loss: 2.3115578533268293
Epoch: 9| Step: 8
Training loss: 2.297669357682669
Validation loss: 2.3972936577352613
Epoch: 9| Step: 9
Training loss: 2.245003450556697
Validation loss: 2.3452484196645167
Epoch: 9| Step: 10
Training loss: 2.3139802473802824
Validation loss: 2.408523439114289
Epoch: 9| Step: 11
Training loss: 2.792218983989834
Validation loss: 2.345930887822175
Epoch: 9| Step: 12
Training loss: 2.3935167363308634
Validation loss: 2.3953059065245097
Epoch: 9| Step: 13
Training loss: 1.6904348354602794
Validation loss: 2.3859101558295728
Epoch: 9| Step: 14
Training loss: 2.808864702463977
Validation loss: 2.422524705306703
Epoch: 9| Step: 15
Training loss: 3.33018036179205
Validation loss: 2.4191053383552017
Epoch: 9| Step: 16
Training loss: 2.956010972535619
Validation loss: 2.366531598758858
Epoch: 9| Step: 17
Training loss: 2.7594707571762185
Validation loss: 2.379821890308261
Epoch: 9| Step: 18
Training loss: 2.6609055056303292
Validation loss: 2.4169463757093177
Epoch: 9| Step: 19
Training loss: 3.3055609231971164
Validation loss: 2.3479978580841085
Epoch: 67| Step: 0
Training loss: 2.16774758250388
Validation loss: 2.445322622494878
Epoch: 9| Step: 1
Training loss: 2.124746419698704
Validation loss: 2.398605839759642
Epoch: 9| Step: 2
Training loss: 2.262307098764147
Validation loss: 2.4251449879302456
Epoch: 9| Step: 3
Training loss: 2.3936234164321637
Validation loss: 2.3463778825402835
Epoch: 9| Step: 4
Training loss: 2.6410142058713
Validation loss: 2.399612782655805
Epoch: 9| Step: 5
Training loss: 2.181899175802287
Validation loss: 2.400695656937758
Epoch: 9| Step: 6
Training loss: 2.1528782674107587
Validation loss: 2.4043421141192347
Epoch: 9| Step: 7
Training loss: 3.3875572284214
Validation loss: 2.4735998153907146
Epoch: 9| Step: 8
Training loss: 3.3938209484123956
Validation loss: 2.4377677534961077
Epoch: 9| Step: 9
Training loss: 2.7822638388988894
Validation loss: 2.458235161230528
Epoch: 9| Step: 10
Training loss: 3.056923128668335
Validation loss: 2.369023841157553
Epoch: 9| Step: 11
Training loss: 2.4985617315099042
Validation loss: 2.4513023864027397
Epoch: 9| Step: 12
Training loss: 2.784979387956976
Validation loss: 2.3536532687315823
Epoch: 9| Step: 13
Training loss: 2.9602507345866993
Validation loss: 2.330638903705096
Epoch: 9| Step: 14
Training loss: 2.9672995788715846
Validation loss: 2.3530469889686856
Epoch: 9| Step: 15
Training loss: 2.694123202003888
Validation loss: 2.474300250200948
Epoch: 9| Step: 16
Training loss: 3.4271595182134797
Validation loss: 2.414180934829737
Epoch: 9| Step: 17
Training loss: 2.8793149991798317
Validation loss: 2.4601368552595546
Epoch: 9| Step: 18
Training loss: 2.8760934491845678
Validation loss: 2.3645731656156146
Epoch: 9| Step: 19
Training loss: 2.553441668404209
Validation loss: 2.2977056805853215
Epoch: 68| Step: 0
Training loss: 3.936039002651715
Validation loss: 2.4156779432227897
Epoch: 9| Step: 1
Training loss: 2.95457624672803
Validation loss: 2.4880199083391457
Epoch: 9| Step: 2
Training loss: 2.5010408142249387
Validation loss: 2.421973864963459
Epoch: 9| Step: 3
Training loss: 2.5508117206617067
Validation loss: 2.3478511995360165
Epoch: 9| Step: 4
Training loss: 2.9221700427574473
Validation loss: 2.3669417915969944
Epoch: 9| Step: 5
Training loss: 2.4782400135803813
Validation loss: 2.431781738424902
Epoch: 9| Step: 6
Training loss: 2.625783894068514
Validation loss: 2.353647224125672
Epoch: 9| Step: 7
Training loss: 3.746616617413751
Validation loss: 2.38548921525572
Epoch: 9| Step: 8
Training loss: 2.8694518915674503
Validation loss: 2.291656075147182
Epoch: 9| Step: 9
Training loss: 2.8928278596933263
Validation loss: 2.4194186466751604
Epoch: 9| Step: 10
Training loss: 2.068903836065307
Validation loss: 2.418359910678734
Epoch: 9| Step: 11
Training loss: 2.327407214223655
Validation loss: 2.402297670455771
Epoch: 9| Step: 12
Training loss: 2.7468643518096103
Validation loss: 2.355746315557109
Epoch: 9| Step: 13
Training loss: 2.494057267841586
Validation loss: 2.4406793995993405
Epoch: 9| Step: 14
Training loss: 2.3277659299311733
Validation loss: 2.384708778031113
Epoch: 9| Step: 15
Training loss: 2.9578008217235943
Validation loss: 2.391069781011026
Epoch: 9| Step: 16
Training loss: 1.8347781152687883
Validation loss: 2.452789909980702
Epoch: 9| Step: 17
Training loss: 2.963391256063099
Validation loss: 2.3722958115200545
Epoch: 9| Step: 18
Training loss: 2.609767313264216
Validation loss: 2.34405628022001
Epoch: 9| Step: 19
Training loss: 2.9537864630503194
Validation loss: 2.433613806542897
Epoch: 69| Step: 0
Training loss: 2.807269764509852
Validation loss: 2.3734093328821984
Epoch: 9| Step: 1
Training loss: 2.4804105977127757
Validation loss: 2.4443668690407803
Epoch: 9| Step: 2
Training loss: 3.060359284495092
Validation loss: 2.3554636049352347
Epoch: 9| Step: 3
Training loss: 2.9831708306181324
Validation loss: 2.287682008453776
Epoch: 9| Step: 4
Training loss: 2.8361580923159724
Validation loss: 2.39819510781651
Epoch: 9| Step: 5
Training loss: 2.7051808912677133
Validation loss: 2.365672000743953
Epoch: 9| Step: 6
Training loss: 3.2029136029708485
Validation loss: 2.393058387908427
Epoch: 9| Step: 7
Training loss: 2.2390802099215654
Validation loss: 2.3060684733033154
Epoch: 9| Step: 8
Training loss: 2.6315561800523986
Validation loss: 2.4159119598367624
Epoch: 9| Step: 9
Training loss: 3.2595184031290443
Validation loss: 2.270283636254394
Epoch: 9| Step: 10
Training loss: 2.2982272365093808
Validation loss: 2.457871201745499
Epoch: 9| Step: 11
Training loss: 3.0081155995821067
Validation loss: 2.428580000688514
Epoch: 9| Step: 12
Training loss: 2.5995369205366003
Validation loss: 2.3335896859105127
Epoch: 9| Step: 13
Training loss: 2.6488990944076214
Validation loss: 2.417624679735156
Epoch: 9| Step: 14
Training loss: 2.906066888762695
Validation loss: 2.336366824781185
Epoch: 9| Step: 15
Training loss: 1.760663513694019
Validation loss: 2.4584796880892212
Epoch: 9| Step: 16
Training loss: 2.572415775443956
Validation loss: 2.3166189789386866
Epoch: 9| Step: 17
Training loss: 2.4751186072703977
Validation loss: 2.326747579913721
Epoch: 9| Step: 18
Training loss: 2.937300979690043
Validation loss: 2.3373140529185124
Epoch: 9| Step: 19
Training loss: 2.746759759874678
Validation loss: 2.3097545973881193
Epoch: 70| Step: 0
Training loss: 2.539682916989374
Validation loss: 2.4574504470681298
Epoch: 9| Step: 1
Training loss: 2.9009820919437472
Validation loss: 2.442177210378405
Epoch: 9| Step: 2
Training loss: 2.307609645267774
Validation loss: 2.408853539777777
Epoch: 9| Step: 3
Training loss: 2.5792960541726884
Validation loss: 2.3118255389966578
Epoch: 9| Step: 4
Training loss: 2.6417675368087132
Validation loss: 2.4293966178482953
Epoch: 9| Step: 5
Training loss: 3.1225304573229034
Validation loss: 2.4290122021618465
Epoch: 9| Step: 6
Training loss: 3.088157454078668
Validation loss: 2.430435975402574
Epoch: 9| Step: 7
Training loss: 2.3482266207676146
Validation loss: 2.383613776117017
Epoch: 9| Step: 8
Training loss: 3.01587229292884
Validation loss: 2.3178111488728956
Epoch: 9| Step: 9
Training loss: 2.7354613843537487
Validation loss: 2.3802809902460567
Epoch: 9| Step: 10
Training loss: 2.880339267139071
Validation loss: 2.3832188700395847
Epoch: 9| Step: 11
Training loss: 2.166267566114414
Validation loss: 2.4227119514433633
Epoch: 9| Step: 12
Training loss: 2.5406414111218503
Validation loss: 2.4527801694464064
Epoch: 9| Step: 13
Training loss: 3.842825553569724
Validation loss: 2.4250090226499594
Epoch: 9| Step: 14
Training loss: 2.4008248342275107
Validation loss: 2.3392718028843054
Epoch: 9| Step: 15
Training loss: 2.9738800697695527
Validation loss: 2.3446122180381206
Epoch: 9| Step: 16
Training loss: 2.4932928713237046
Validation loss: 2.410142860754521
Epoch: 9| Step: 17
Training loss: 2.9905341538170878
Validation loss: 2.386722032509296
Epoch: 9| Step: 18
Training loss: 2.46360145372638
Validation loss: 2.3492718640428287
Epoch: 9| Step: 19
Training loss: 2.843079204882336
Validation loss: 2.3740093113557266
Epoch: 71| Step: 0
Training loss: 3.1936282916683085
Validation loss: 2.3608385916940198
Epoch: 9| Step: 1
Training loss: 2.676783998925632
Validation loss: 2.389453292271202
Epoch: 9| Step: 2
Training loss: 1.790861666020209
Validation loss: 2.3757465043041823
Epoch: 9| Step: 3
Training loss: 2.254505943765967
Validation loss: 2.347572822824312
Epoch: 9| Step: 4
Training loss: 3.1203036304819642
Validation loss: 2.34324604809945
Epoch: 9| Step: 5
Training loss: 2.413416705122826
Validation loss: 2.4580724608652695
Epoch: 9| Step: 6
Training loss: 2.804058121218972
Validation loss: 2.29092048036126
Epoch: 9| Step: 7
Training loss: 2.143426885249051
Validation loss: 2.4148848454558385
Epoch: 9| Step: 8
Training loss: 3.027772304596071
Validation loss: 2.34620452935966
Epoch: 9| Step: 9
Training loss: 2.6376869063118087
Validation loss: 2.3532147008190596
Epoch: 9| Step: 10
Training loss: 3.6332836871007124
Validation loss: 2.39191210240723
Epoch: 9| Step: 11
Training loss: 2.9533361934650886
Validation loss: 2.3683332265898485
Epoch: 9| Step: 12
Training loss: 2.7015136149513626
Validation loss: 2.278119727718161
Epoch: 9| Step: 13
Training loss: 2.7734478157818714
Validation loss: 2.397264774247493
Epoch: 9| Step: 14
Training loss: 2.487604501340664
Validation loss: 2.3985484589981607
Epoch: 9| Step: 15
Training loss: 1.7049857657501197
Validation loss: 2.3159205247261223
Epoch: 9| Step: 16
Training loss: 3.1641339329320792
Validation loss: 2.3635500527965356
Epoch: 9| Step: 17
Training loss: 3.032904104807793
Validation loss: 2.4528213983137652
Epoch: 9| Step: 18
Training loss: 2.84812590568282
Validation loss: 2.3629644393893505
Epoch: 9| Step: 19
Training loss: 3.0561649427689055
Validation loss: 2.3606505338464325
Epoch: 72| Step: 0
Training loss: 2.334259961828796
Validation loss: 2.4455588162518924
Epoch: 9| Step: 1
Training loss: 3.0080870664048716
Validation loss: 2.4663744847754305
Epoch: 9| Step: 2
Training loss: 3.4065921156676944
Validation loss: 2.3382704757245305
Epoch: 9| Step: 3
Training loss: 2.289516781460737
Validation loss: 2.425163122112677
Epoch: 9| Step: 4
Training loss: 2.313271574227538
Validation loss: 2.3447904058147198
Epoch: 9| Step: 5
Training loss: 3.0641898339330913
Validation loss: 2.383116837474375
Epoch: 9| Step: 6
Training loss: 3.11339520062792
Validation loss: 2.3468552449067435
Epoch: 9| Step: 7
Training loss: 1.9729142124223868
Validation loss: 2.369852844381969
Epoch: 9| Step: 8
Training loss: 3.1552324826632536
Validation loss: 2.34421705597231
Epoch: 9| Step: 9
Training loss: 2.654638631908631
Validation loss: 2.3938350794103886
Epoch: 9| Step: 10
Training loss: 2.822510261888661
Validation loss: 2.439747757068691
Epoch: 9| Step: 11
Training loss: 3.46255462272884
Validation loss: 2.3528654117187684
Epoch: 9| Step: 12
Training loss: 2.0096902935119583
Validation loss: 2.3277237993986417
Epoch: 9| Step: 13
Training loss: 3.1973261748809896
Validation loss: 2.372637927645026
Epoch: 9| Step: 14
Training loss: 2.3591231660146015
Validation loss: 2.335597945790052
Epoch: 9| Step: 15
Training loss: 2.1037543116234643
Validation loss: 2.4118622469047857
Epoch: 9| Step: 16
Training loss: 2.5030429440882456
Validation loss: 2.345846050799187
Epoch: 9| Step: 17
Training loss: 2.6370315931306068
Validation loss: 2.432470723833244
Epoch: 9| Step: 18
Training loss: 2.136902851772302
Validation loss: 2.3309142894726063
Epoch: 9| Step: 19
Training loss: 2.9315986604882935
Validation loss: 2.3384500729998003
Epoch: 73| Step: 0
Training loss: 2.1185492046260985
Validation loss: 2.3297778634090798
Epoch: 9| Step: 1
Training loss: 3.339974526862127
Validation loss: 2.273597358912802
Epoch: 9| Step: 2
Training loss: 3.5339231922414656
Validation loss: 2.3710967900989752
Epoch: 9| Step: 3
Training loss: 2.675152291214271
Validation loss: 2.4106483426103984
Epoch: 9| Step: 4
Training loss: 3.396540811869384
Validation loss: 2.2810762983281347
Epoch: 9| Step: 5
Training loss: 2.353734024487947
Validation loss: 2.318418649509556
Epoch: 9| Step: 6
Training loss: 2.003859848466794
Validation loss: 2.3262692911043787
Epoch: 9| Step: 7
Training loss: 3.035592969505904
Validation loss: 2.4491948609721126
Epoch: 9| Step: 8
Training loss: 2.1105750167300656
Validation loss: 2.398174929223809
Epoch: 9| Step: 9
Training loss: 2.3738582275852265
Validation loss: 2.4064768897316053
Epoch: 9| Step: 10
Training loss: 2.5106287084489876
Validation loss: 2.3407786175419307
Epoch: 9| Step: 11
Training loss: 1.7897675969654443
Validation loss: 2.409023921171714
Epoch: 9| Step: 12
Training loss: 3.1965950255044944
Validation loss: 2.4121129381670525
Epoch: 9| Step: 13
Training loss: 2.648579551465633
Validation loss: 2.3245189411041016
Epoch: 9| Step: 14
Training loss: 3.293873654673795
Validation loss: 2.3069700323680293
Epoch: 9| Step: 15
Training loss: 2.448999227758109
Validation loss: 2.452018505352727
Epoch: 9| Step: 16
Training loss: 2.8778042592810804
Validation loss: 2.342086921611279
Epoch: 9| Step: 17
Training loss: 2.8323322846471064
Validation loss: 2.315105682944185
Epoch: 9| Step: 18
Training loss: 2.5018280974810607
Validation loss: 2.3422682567286275
Epoch: 9| Step: 19
Training loss: 2.9035026115824847
Validation loss: 2.4101150149135666
Epoch: 74| Step: 0
Training loss: 1.7838745190278493
Validation loss: 2.3481379630700943
Epoch: 9| Step: 1
Training loss: 2.8283853147634486
Validation loss: 2.3414224791759968
Epoch: 9| Step: 2
Training loss: 2.143006719182633
Validation loss: 2.3861859411539434
Epoch: 9| Step: 3
Training loss: 2.5856655012374574
Validation loss: 2.362235809924201
Epoch: 9| Step: 4
Training loss: 2.772417337545733
Validation loss: 2.3739330447558973
Epoch: 9| Step: 5
Training loss: 2.9080614576811112
Validation loss: 2.398721619801933
Epoch: 9| Step: 6
Training loss: 2.901842610566435
Validation loss: 2.3943355219336606
Epoch: 9| Step: 7
Training loss: 2.608436461371113
Validation loss: 2.3401465194258653
Epoch: 9| Step: 8
Training loss: 2.627425753254921
Validation loss: 2.423019306959978
Epoch: 9| Step: 9
Training loss: 2.8247508791567575
Validation loss: 2.2838544977299486
Epoch: 9| Step: 10
Training loss: 3.1173199694792735
Validation loss: 2.381143636096414
Epoch: 9| Step: 11
Training loss: 2.2063155642701306
Validation loss: 2.330857194514701
Epoch: 9| Step: 12
Training loss: 2.690358969975773
Validation loss: 2.3279862906525945
Epoch: 9| Step: 13
Training loss: 2.7717560305002937
Validation loss: 2.4148935563893312
Epoch: 9| Step: 14
Training loss: 2.490112684679865
Validation loss: 2.461595683563901
Epoch: 9| Step: 15
Training loss: 3.219325042022984
Validation loss: 2.3442856969899113
Epoch: 9| Step: 16
Training loss: 2.4881840900992724
Validation loss: 2.314807466746012
Epoch: 9| Step: 17
Training loss: 3.4925698022004066
Validation loss: 2.2847720961590925
Epoch: 9| Step: 18
Training loss: 3.0931550041403795
Validation loss: 2.4341884677404932
Epoch: 9| Step: 19
Training loss: 2.323835068777447
Validation loss: 2.3991494559844986
Epoch: 75| Step: 0
Training loss: 2.8919959863764135
Validation loss: 2.3645287248080527
Epoch: 9| Step: 1
Training loss: 2.53187609806004
Validation loss: 2.317775988987779
Epoch: 9| Step: 2
Training loss: 2.6005378973688993
Validation loss: 2.277797122767458
Epoch: 9| Step: 3
Training loss: 2.685360877792002
Validation loss: 2.4437837871984938
Epoch: 9| Step: 4
Training loss: 2.7696258571806096
Validation loss: 2.4267617204211644
Epoch: 9| Step: 5
Training loss: 3.3766061704989903
Validation loss: 2.3675514686667714
Epoch: 9| Step: 6
Training loss: 3.2169744538682337
Validation loss: 2.3402911247776443
Epoch: 9| Step: 7
Training loss: 3.2066061316610055
Validation loss: 2.3813801524983917
Epoch: 9| Step: 8
Training loss: 2.9288283245376907
Validation loss: 2.3852155074741472
Epoch: 9| Step: 9
Training loss: 2.08826536664192
Validation loss: 2.3051680442657165
Epoch: 9| Step: 10
Training loss: 2.729346660085151
Validation loss: 2.316378139154261
Epoch: 9| Step: 11
Training loss: 2.4249314249312075
Validation loss: 2.3552389341613527
Epoch: 9| Step: 12
Training loss: 2.426855663268699
Validation loss: 2.324727176236272
Epoch: 9| Step: 13
Training loss: 2.6995750446038267
Validation loss: 2.3530106436635494
Epoch: 9| Step: 14
Training loss: 2.1938877029890147
Validation loss: 2.4055870766101584
Epoch: 9| Step: 15
Training loss: 3.015604602171542
Validation loss: 2.4082065752322954
Epoch: 9| Step: 16
Training loss: 2.6674777426680425
Validation loss: 2.3432336876478104
Epoch: 9| Step: 17
Training loss: 2.1938670548295214
Validation loss: 2.363553435241008
Epoch: 9| Step: 18
Training loss: 2.6791662482166902
Validation loss: 2.3802515459138753
Epoch: 9| Step: 19
Training loss: 3.4373518478372387
Validation loss: 2.3928422420177076
Epoch: 76| Step: 0
Training loss: 2.9722340267656047
Validation loss: 2.2724777571265937
Epoch: 9| Step: 1
Training loss: 3.8804071908810056
Validation loss: 2.361365633719415
Epoch: 9| Step: 2
Training loss: 3.3921328237547157
Validation loss: 2.4283468359830405
Epoch: 9| Step: 3
Training loss: 2.6136729769347364
Validation loss: 2.3892366205242204
Epoch: 9| Step: 4
Training loss: 2.2732820752686616
Validation loss: 2.3924736567640994
Epoch: 9| Step: 5
Training loss: 2.3356588446227233
Validation loss: 2.3810038957924227
Epoch: 9| Step: 6
Training loss: 1.732925359079375
Validation loss: 2.4254985976666967
Epoch: 9| Step: 7
Training loss: 2.837197772496015
Validation loss: 2.361757355744647
Epoch: 9| Step: 8
Training loss: 2.724778430575143
Validation loss: 2.4831897069720954
Epoch: 9| Step: 9
Training loss: 2.8275521894338516
Validation loss: 2.364960534368385
Epoch: 9| Step: 10
Training loss: 2.2798659424103316
Validation loss: 2.4148746687037264
Epoch: 9| Step: 11
Training loss: 2.700775624943294
Validation loss: 2.367448025959776
Epoch: 9| Step: 12
Training loss: 3.0107136792155
Validation loss: 2.3185719429076124
Epoch: 9| Step: 13
Training loss: 2.6303548237007255
Validation loss: 2.3031238613351377
Epoch: 9| Step: 14
Training loss: 2.882224914711615
Validation loss: 2.3600504452822455
Epoch: 9| Step: 15
Training loss: 2.1254352796953917
Validation loss: 2.445749131135149
Epoch: 9| Step: 16
Training loss: 2.6269769036447035
Validation loss: 2.5682329590799133
Epoch: 9| Step: 17
Training loss: 2.6305469760757103
Validation loss: 2.411291098716835
Epoch: 9| Step: 18
Training loss: 2.757383750892995
Validation loss: 2.3640625224123513
Epoch: 9| Step: 19
Training loss: 2.6654187103624625
Validation loss: 2.3870540437496635
Epoch: 77| Step: 0
Training loss: 3.862977111385199
Validation loss: 2.4497060820956214
Epoch: 9| Step: 1
Training loss: 3.1127112810972712
Validation loss: 2.365769842601327
Epoch: 9| Step: 2
Training loss: 2.6480425424817504
Validation loss: 2.4015476906150326
Epoch: 9| Step: 3
Training loss: 1.9821731486515883
Validation loss: 2.4238445819973755
Epoch: 9| Step: 4
Training loss: 1.667744176965108
Validation loss: 2.404892047441432
Epoch: 9| Step: 5
Training loss: 3.0455411681300424
Validation loss: 2.415842869699389
Epoch: 9| Step: 6
Training loss: 2.2014991767391385
Validation loss: 2.31218867636562
Epoch: 9| Step: 7
Training loss: 2.0726887435465344
Validation loss: 2.364622629485163
Epoch: 9| Step: 8
Training loss: 3.6736536790720713
Validation loss: 2.380942301763859
Epoch: 9| Step: 9
Training loss: 3.3645173214951094
Validation loss: 2.4195443867719453
Epoch: 9| Step: 10
Training loss: 2.416075031163846
Validation loss: 2.4083285154638583
Epoch: 9| Step: 11
Training loss: 2.9500891203268917
Validation loss: 2.384710606689881
Epoch: 9| Step: 12
Training loss: 2.3872895752213834
Validation loss: 2.4123084797527334
Epoch: 9| Step: 13
Training loss: 3.0743679606618244
Validation loss: 2.3382106440696155
Epoch: 9| Step: 14
Training loss: 2.309429707995434
Validation loss: 2.340573651993621
Epoch: 9| Step: 15
Training loss: 2.5800550230206265
Validation loss: 2.388210099022471
Epoch: 9| Step: 16
Training loss: 2.293654695032883
Validation loss: 2.3970919812090035
Epoch: 9| Step: 17
Training loss: 2.186447326235048
Validation loss: 2.356097731575967
Epoch: 9| Step: 18
Training loss: 2.5070453551868317
Validation loss: 2.4070408520765896
Epoch: 9| Step: 19
Training loss: 3.173163692470634
Validation loss: 2.3617293890112276
Epoch: 78| Step: 0
Training loss: 1.7323258124966243
Validation loss: 2.389575174732412
Epoch: 9| Step: 1
Training loss: 3.1886839818158013
Validation loss: 2.425931118231438
Epoch: 9| Step: 2
Training loss: 2.5896140524611666
Validation loss: 2.3478384466258846
Epoch: 9| Step: 3
Training loss: 2.542110081333792
Validation loss: 2.4168322787618868
Epoch: 9| Step: 4
Training loss: 3.726876491538016
Validation loss: 2.3820222861213423
Epoch: 9| Step: 5
Training loss: 2.1021085689102357
Validation loss: 2.417341508342423
Epoch: 9| Step: 6
Training loss: 2.8774912448090326
Validation loss: 2.4972937597773632
Epoch: 9| Step: 7
Training loss: 2.866422878663183
Validation loss: 2.3813780985001403
Epoch: 9| Step: 8
Training loss: 2.256872595271031
Validation loss: 2.3386121882596687
Epoch: 9| Step: 9
Training loss: 3.1633568247601844
Validation loss: 2.380060902954928
Epoch: 9| Step: 10
Training loss: 2.1529967603433193
Validation loss: 2.3198574911742975
Epoch: 9| Step: 11
Training loss: 2.529179420837052
Validation loss: 2.323839379698476
Epoch: 9| Step: 12
Training loss: 2.8093748743992863
Validation loss: 2.3651991963258934
Epoch: 9| Step: 13
Training loss: 3.065755553970215
Validation loss: 2.433462055266064
Epoch: 9| Step: 14
Training loss: 2.8341334466091177
Validation loss: 2.3321709063227636
Epoch: 9| Step: 15
Training loss: 2.937717348539452
Validation loss: 2.4080897234942618
Epoch: 9| Step: 16
Training loss: 2.7048055904002326
Validation loss: 2.4215786074614862
Epoch: 9| Step: 17
Training loss: 2.7667246211159786
Validation loss: 2.4384718945269395
Epoch: 9| Step: 18
Training loss: 2.3793062021075495
Validation loss: 2.324533539450387
Epoch: 9| Step: 19
Training loss: 2.3648174242835984
Validation loss: 2.3078242377154745
Epoch: 79| Step: 0
Training loss: 2.6272207584683107
Validation loss: 2.3646680521962935
Epoch: 9| Step: 1
Training loss: 3.129853256490714
Validation loss: 2.3800479328805206
Epoch: 9| Step: 2
Training loss: 2.837400957303159
Validation loss: 2.449755868265614
Epoch: 9| Step: 3
Training loss: 3.155407632650025
Validation loss: 2.4142975971343996
Epoch: 9| Step: 4
Training loss: 2.8681976451472826
Validation loss: 2.3308647806002663
Epoch: 9| Step: 5
Training loss: 2.8224140484598648
Validation loss: 2.360083851703765
Epoch: 9| Step: 6
Training loss: 2.072463045055356
Validation loss: 2.4135622226309357
Epoch: 9| Step: 7
Training loss: 2.5144919930097522
Validation loss: 2.3642066245205986
Epoch: 9| Step: 8
Training loss: 2.2568899203504245
Validation loss: 2.397223986958352
Epoch: 9| Step: 9
Training loss: 2.3658977557910092
Validation loss: 2.331042978970364
Epoch: 9| Step: 10
Training loss: 2.660087237254118
Validation loss: 2.336974320334378
Epoch: 9| Step: 11
Training loss: 2.948094518753411
Validation loss: 2.3271159704933497
Epoch: 9| Step: 12
Training loss: 3.3012377180674837
Validation loss: 2.353114852795717
Epoch: 9| Step: 13
Training loss: 2.675007907463579
Validation loss: 2.4077327407145765
Epoch: 9| Step: 14
Training loss: 1.9858189533186295
Validation loss: 2.381098964093463
Epoch: 9| Step: 15
Training loss: 2.5639207204503016
Validation loss: 2.336584922854219
Epoch: 9| Step: 16
Training loss: 2.8385119142052164
Validation loss: 2.402479086493589
Epoch: 9| Step: 17
Training loss: 3.2629500389284187
Validation loss: 2.4301577727843213
Epoch: 9| Step: 18
Training loss: 2.8630873964476296
Validation loss: 2.4006041079178244
Epoch: 9| Step: 19
Training loss: 2.5824627998974163
Validation loss: 2.3791419220770726
Epoch: 80| Step: 0
Training loss: 2.5797858235078586
Validation loss: 2.408936828026801
Epoch: 9| Step: 1
Training loss: 2.618011253874788
Validation loss: 2.342452955850845
Epoch: 9| Step: 2
Training loss: 3.5236754072778176
Validation loss: 2.3984402139641245
Epoch: 9| Step: 3
Training loss: 2.357470217179877
Validation loss: 2.444246543049885
Epoch: 9| Step: 4
Training loss: 2.1587461314914944
Validation loss: 2.347328873598022
Epoch: 9| Step: 5
Training loss: 2.5290648836355363
Validation loss: 2.36462450430334
Epoch: 9| Step: 6
Training loss: 3.3493292065775204
Validation loss: 2.3605449375177026
Epoch: 9| Step: 7
Training loss: 2.861359288172875
Validation loss: 2.4025229034909645
Epoch: 9| Step: 8
Training loss: 3.0507149780734033
Validation loss: 2.400969109438547
Epoch: 9| Step: 9
Training loss: 1.9527187077412098
Validation loss: 2.3775506436534983
Epoch: 9| Step: 10
Training loss: 2.3922206564909603
Validation loss: 2.3969031736577042
Epoch: 9| Step: 11
Training loss: 2.4362126398720543
Validation loss: 2.3667484037588244
Epoch: 9| Step: 12
Training loss: 3.260371897494693
Validation loss: 2.3787256514822674
Epoch: 9| Step: 13
Training loss: 2.0797107354176627
Validation loss: 2.308835201379581
Epoch: 9| Step: 14
Training loss: 2.7080408280702417
Validation loss: 2.4374257475944847
Epoch: 9| Step: 15
Training loss: 2.953292438261256
Validation loss: 2.374061896778484
Epoch: 9| Step: 16
Training loss: 2.7949176950909957
Validation loss: 2.3835319070962417
Epoch: 9| Step: 17
Training loss: 1.7446630022425658
Validation loss: 2.350901816449946
Epoch: 9| Step: 18
Training loss: 3.2306804103309705
Validation loss: 2.402000306150739
Epoch: 9| Step: 19
Training loss: 2.5318164897967215
Validation loss: 2.3314286090424847
Epoch: 81| Step: 0
Training loss: 2.299781050833949
Validation loss: 2.375334693159352
Epoch: 9| Step: 1
Training loss: 2.7060157445434045
Validation loss: 2.3827047422898615
Epoch: 9| Step: 2
Training loss: 2.0871212918432014
Validation loss: 2.3543696531520277
Epoch: 9| Step: 3
Training loss: 3.0672338838806037
Validation loss: 2.3908286445687716
Epoch: 9| Step: 4
Training loss: 2.3448531542838733
Validation loss: 2.3984511278714264
Epoch: 9| Step: 5
Training loss: 1.8750269570002291
Validation loss: 2.427135672261318
Epoch: 9| Step: 6
Training loss: 2.6536863634023553
Validation loss: 2.4061465001770355
Epoch: 9| Step: 7
Training loss: 2.8945694687928927
Validation loss: 2.348676806294663
Epoch: 9| Step: 8
Training loss: 3.234145299154019
Validation loss: 2.374417161702717
Epoch: 9| Step: 9
Training loss: 3.920786794020746
Validation loss: 2.4102652648739364
Epoch: 9| Step: 10
Training loss: 2.3622736020071313
Validation loss: 2.28620908029402
Epoch: 9| Step: 11
Training loss: 2.5740986218591884
Validation loss: 2.3825345431172433
Epoch: 9| Step: 12
Training loss: 3.442261605800546
Validation loss: 2.379823762431629
Epoch: 9| Step: 13
Training loss: 2.7069498685683824
Validation loss: 2.3298043787460307
Epoch: 9| Step: 14
Training loss: 2.7475390259849455
Validation loss: 2.351208060440856
Epoch: 9| Step: 15
Training loss: 3.0025889034274806
Validation loss: 2.3827769803816747
Epoch: 9| Step: 16
Training loss: 2.294019416141573
Validation loss: 2.4095943496326857
Epoch: 9| Step: 17
Training loss: 1.9302032028709228
Validation loss: 2.3373603677584316
Epoch: 9| Step: 18
Training loss: 2.837244494525685
Validation loss: 2.298475171287912
Epoch: 9| Step: 19
Training loss: 1.9141785878380562
Validation loss: 2.38962577984411
Epoch: 82| Step: 0
Training loss: 2.9932338389093642
Validation loss: 2.385929820982481
Epoch: 9| Step: 1
Training loss: 2.7439249734547646
Validation loss: 2.370585097586078
Epoch: 9| Step: 2
Training loss: 2.644156177242267
Validation loss: 2.454310675934008
Epoch: 9| Step: 3
Training loss: 1.975933291436642
Validation loss: 2.428880583588998
Epoch: 9| Step: 4
Training loss: 2.2025098009356903
Validation loss: 2.410192324005566
Epoch: 9| Step: 5
Training loss: 2.4506433654268216
Validation loss: 2.2575104821807903
Epoch: 9| Step: 6
Training loss: 2.6098809579762694
Validation loss: 2.374515583443451
Epoch: 9| Step: 7
Training loss: 2.415383579285702
Validation loss: 2.3486575690327864
Epoch: 9| Step: 8
Training loss: 2.855172492860853
Validation loss: 2.3582771426526676
Epoch: 9| Step: 9
Training loss: 2.3059329013905265
Validation loss: 2.4131156134491003
Epoch: 9| Step: 10
Training loss: 2.4059693804510416
Validation loss: 2.35684972397477
Epoch: 9| Step: 11
Training loss: 1.9842450557424613
Validation loss: 2.3944227678993504
Epoch: 9| Step: 12
Training loss: 2.383931881987517
Validation loss: 2.3934375912728876
Epoch: 9| Step: 13
Training loss: 4.230726633991199
Validation loss: 2.4458019785311915
Epoch: 9| Step: 14
Training loss: 2.553182269309691
Validation loss: 2.367615319929126
Epoch: 9| Step: 15
Training loss: 2.5764451536311013
Validation loss: 2.441235714405394
Epoch: 9| Step: 16
Training loss: 3.212900568706117
Validation loss: 2.3991089545293294
Epoch: 9| Step: 17
Training loss: 2.488450647932819
Validation loss: 2.3573435294821308
Epoch: 9| Step: 18
Training loss: 2.454873597723178
Validation loss: 2.4899446497483
Epoch: 9| Step: 19
Training loss: 3.3443664267794917
Validation loss: 2.429770996383997
Epoch: 83| Step: 0
Training loss: 4.021744277359105
Validation loss: 2.3772723707787993
Epoch: 9| Step: 1
Training loss: 2.2375293154367752
Validation loss: 2.400636694260804
Epoch: 9| Step: 2
Training loss: 2.216064116917217
Validation loss: 2.338396947585427
Epoch: 9| Step: 3
Training loss: 2.24173394377578
Validation loss: 2.3332044776084753
Epoch: 9| Step: 4
Training loss: 2.891162059483906
Validation loss: 2.408782854534402
Epoch: 9| Step: 5
Training loss: 2.8659063070120223
Validation loss: 2.3987548326263712
Epoch: 9| Step: 6
Training loss: 3.3275134460498546
Validation loss: 2.4304450033197083
Epoch: 9| Step: 7
Training loss: 2.2638679794666894
Validation loss: 2.3989319038721137
Epoch: 9| Step: 8
Training loss: 2.2256393928351685
Validation loss: 2.291570383339645
Epoch: 9| Step: 9
Training loss: 2.1270084986909237
Validation loss: 2.279941502408482
Epoch: 9| Step: 10
Training loss: 2.0818198492142685
Validation loss: 2.372246159461323
Epoch: 9| Step: 11
Training loss: 3.6785166309100514
Validation loss: 2.394432834992483
Epoch: 9| Step: 12
Training loss: 2.227983844239646
Validation loss: 2.287293814404571
Epoch: 9| Step: 13
Training loss: 2.356913615304673
Validation loss: 2.3539358277259455
Epoch: 9| Step: 14
Training loss: 2.4224420683461987
Validation loss: 2.4259458820852435
Epoch: 9| Step: 15
Training loss: 2.8163257433936173
Validation loss: 2.4391743653550013
Epoch: 9| Step: 16
Training loss: 3.49073860441218
Validation loss: 2.4282709815456824
Epoch: 9| Step: 17
Training loss: 3.3327322576907727
Validation loss: 2.4267518739492657
Epoch: 9| Step: 18
Training loss: 2.0843605052438297
Validation loss: 2.372539648747934
Epoch: 9| Step: 19
Training loss: 1.6247942867650043
Validation loss: 2.3070538080356013
Epoch: 84| Step: 0
Training loss: 2.282419505877867
Validation loss: 2.246090614588717
Epoch: 9| Step: 1
Training loss: 2.457263929451196
Validation loss: 2.3781054686059617
Epoch: 9| Step: 2
Training loss: 2.568421755421158
Validation loss: 2.427300531491917
Epoch: 9| Step: 3
Training loss: 3.648195181075655
Validation loss: 2.3498722675682227
Epoch: 9| Step: 4
Training loss: 1.9887017365646817
Validation loss: 2.3820108906007444
Epoch: 9| Step: 5
Training loss: 2.571865180959765
Validation loss: 2.2942513963759597
Epoch: 9| Step: 6
Training loss: 3.0317221991465266
Validation loss: 2.3402956522165126
Epoch: 9| Step: 7
Training loss: 3.2711135517447576
Validation loss: 2.352566863500206
Epoch: 9| Step: 8
Training loss: 2.6031291471633757
Validation loss: 2.4219214362468513
Epoch: 9| Step: 9
Training loss: 3.3009190637835113
Validation loss: 2.35393645508169
Epoch: 9| Step: 10
Training loss: 2.3471351083193577
Validation loss: 2.3684321557923056
Epoch: 9| Step: 11
Training loss: 2.806708242813692
Validation loss: 2.2858177081903883
Epoch: 9| Step: 12
Training loss: 2.273793195971629
Validation loss: 2.3970815922990725
Epoch: 9| Step: 13
Training loss: 2.5671047612960307
Validation loss: 2.3496673210725305
Epoch: 9| Step: 14
Training loss: 2.592525147009845
Validation loss: 2.464430109610759
Epoch: 9| Step: 15
Training loss: 1.9808192798767004
Validation loss: 2.4158812887228382
Epoch: 9| Step: 16
Training loss: 2.917656939288932
Validation loss: 2.360819909774903
Epoch: 9| Step: 17
Training loss: 2.6440640238225614
Validation loss: 2.4138466195382025
Epoch: 9| Step: 18
Training loss: 2.640573896105439
Validation loss: 2.3782461849670975
Epoch: 9| Step: 19
Training loss: 2.84448182467231
Validation loss: 2.359178559371476
Epoch: 85| Step: 0
Training loss: 2.1871813950805663
Validation loss: 2.396075698396697
Epoch: 9| Step: 1
Training loss: 2.2564689043955175
Validation loss: 2.4032050209275724
Epoch: 9| Step: 2
Training loss: 2.416236861144377
Validation loss: 2.4115850562573633
Epoch: 9| Step: 3
Training loss: 3.9986404254158714
Validation loss: 2.4289181935180344
Epoch: 9| Step: 4
Training loss: 2.3689884599216997
Validation loss: 2.2757291267676942
Epoch: 9| Step: 5
Training loss: 2.9778193025714454
Validation loss: 2.388380851969642
Epoch: 9| Step: 6
Training loss: 2.1685941876553163
Validation loss: 2.401174857118107
Epoch: 9| Step: 7
Training loss: 2.65972852138994
Validation loss: 2.4041509930471787
Epoch: 9| Step: 8
Training loss: 3.1777181689430027
Validation loss: 2.386861183559674
Epoch: 9| Step: 9
Training loss: 2.583513858599265
Validation loss: 2.3474504789288253
Epoch: 9| Step: 10
Training loss: 2.180287815133045
Validation loss: 2.415360417229505
Epoch: 9| Step: 11
Training loss: 3.255657260710769
Validation loss: 2.452385346219047
Epoch: 9| Step: 12
Training loss: 2.2475666026938828
Validation loss: 2.3836961631779316
Epoch: 9| Step: 13
Training loss: 2.336026703525137
Validation loss: 2.335773928857301
Epoch: 9| Step: 14
Training loss: 1.7361208402572985
Validation loss: 2.3790568333238995
Epoch: 9| Step: 15
Training loss: 3.780162181907146
Validation loss: 2.339611584752474
Epoch: 9| Step: 16
Training loss: 2.6469205489850203
Validation loss: 2.3550174212542436
Epoch: 9| Step: 17
Training loss: 3.0687469295944734
Validation loss: 2.3336857280766883
Epoch: 9| Step: 18
Training loss: 2.089759554013645
Validation loss: 2.486266174243051
Epoch: 9| Step: 19
Training loss: 2.9063440123088147
Validation loss: 2.349179327167874
Epoch: 86| Step: 0
Training loss: 2.5781058570844704
Validation loss: 2.361783115010107
Epoch: 9| Step: 1
Training loss: 2.4620050930215327
Validation loss: 2.3637224098267797
Epoch: 9| Step: 2
Training loss: 2.9866385139546283
Validation loss: 2.4333390568707323
Epoch: 9| Step: 3
Training loss: 2.9694470039105267
Validation loss: 2.379136598314406
Epoch: 9| Step: 4
Training loss: 2.3813282831095037
Validation loss: 2.301762212977695
Epoch: 9| Step: 5
Training loss: 2.5521191860457293
Validation loss: 2.3814650044344945
Epoch: 9| Step: 6
Training loss: 2.470071270026436
Validation loss: 2.4309983799792745
Epoch: 9| Step: 7
Training loss: 3.5097309804999237
Validation loss: 2.300685262350888
Epoch: 9| Step: 8
Training loss: 2.7873736913144134
Validation loss: 2.332983434293313
Epoch: 9| Step: 9
Training loss: 2.7931200106549126
Validation loss: 2.3711108428976786
Epoch: 9| Step: 10
Training loss: 2.902159077864689
Validation loss: 2.299108468817779
Epoch: 9| Step: 11
Training loss: 3.6432892706028093
Validation loss: 2.3067031801391447
Epoch: 9| Step: 12
Training loss: 2.586192138673615
Validation loss: 2.3974637544296664
Epoch: 9| Step: 13
Training loss: 2.403438064561241
Validation loss: 2.397746969242916
Epoch: 9| Step: 14
Training loss: 2.546963742822221
Validation loss: 2.3835665980115266
Epoch: 9| Step: 15
Training loss: 2.268241055994302
Validation loss: 2.342491608893653
Epoch: 9| Step: 16
Training loss: 3.1626945646844975
Validation loss: 2.368375313457433
Epoch: 9| Step: 17
Training loss: 2.0437827011431984
Validation loss: 2.352985821505673
Epoch: 9| Step: 18
Training loss: 3.1840454530011573
Validation loss: 2.403829316078932
Epoch: 9| Step: 19
Training loss: 1.916940137454826
Validation loss: 2.3969046088248844
Epoch: 87| Step: 0
Training loss: 2.6675814212002806
Validation loss: 2.3534622693067178
Epoch: 9| Step: 1
Training loss: 2.8395811271705558
Validation loss: 2.372871061258485
Epoch: 9| Step: 2
Training loss: 3.600222787321247
Validation loss: 2.3718263013709504
Epoch: 9| Step: 3
Training loss: 3.3776940789923184
Validation loss: 2.4071029448506125
Epoch: 9| Step: 4
Training loss: 2.1850255867793336
Validation loss: 2.425318129723772
Epoch: 9| Step: 5
Training loss: 2.5898553494154837
Validation loss: 2.2306732162449845
Epoch: 9| Step: 6
Training loss: 2.910118563619237
Validation loss: 2.396923029360029
Epoch: 9| Step: 7
Training loss: 3.3081374320988117
Validation loss: 2.2656774623687146
Epoch: 9| Step: 8
Training loss: 2.749735212582995
Validation loss: 2.2972404119872083
Epoch: 9| Step: 9
Training loss: 2.324743900755858
Validation loss: 2.306542591342009
Epoch: 9| Step: 10
Training loss: 3.2023647987956383
Validation loss: 2.3204685785347676
Epoch: 9| Step: 11
Training loss: 2.928638809704939
Validation loss: 2.389187221432436
Epoch: 9| Step: 12
Training loss: 2.0036638793714387
Validation loss: 2.3789111783528045
Epoch: 9| Step: 13
Training loss: 2.6801734239064374
Validation loss: 2.252750505629733
Epoch: 9| Step: 14
Training loss: 2.0226526100476616
Validation loss: 2.3525224303999868
Epoch: 9| Step: 15
Training loss: 2.191374372226642
Validation loss: 2.346510179988065
Epoch: 9| Step: 16
Training loss: 2.1415706133052117
Validation loss: 2.3339707284952196
Epoch: 9| Step: 17
Training loss: 2.4609391469798556
Validation loss: 2.3485822224702417
Epoch: 9| Step: 18
Training loss: 2.0921836801712
Validation loss: 2.2828719791169303
Epoch: 9| Step: 19
Training loss: 2.444987315045549
Validation loss: 2.360386061270046
Epoch: 88| Step: 0
Training loss: 2.166303225136898
Validation loss: 2.3600003480964045
Epoch: 9| Step: 1
Training loss: 1.9572610015930256
Validation loss: 2.390782897041594
Epoch: 9| Step: 2
Training loss: 2.51786619066895
Validation loss: 2.2945496018860934
Epoch: 9| Step: 3
Training loss: 2.6956535676414877
Validation loss: 2.3736709073337003
Epoch: 9| Step: 4
Training loss: 2.183151500594574
Validation loss: 2.40477960731698
Epoch: 9| Step: 5
Training loss: 2.5030839971453487
Validation loss: 2.3729425357980714
Epoch: 9| Step: 6
Training loss: 2.6538444846497797
Validation loss: 2.3636555882433603
Epoch: 9| Step: 7
Training loss: 2.8965877583960484
Validation loss: 2.306567060431394
Epoch: 9| Step: 8
Training loss: 2.9562700266895656
Validation loss: 2.3022752910800093
Epoch: 9| Step: 9
Training loss: 3.4662004328477356
Validation loss: 2.2992025199300183
Epoch: 9| Step: 10
Training loss: 2.4375404941423016
Validation loss: 2.3056911765028683
Epoch: 9| Step: 11
Training loss: 2.156625908412929
Validation loss: 2.328939296550301
Epoch: 9| Step: 12
Training loss: 3.1910944101108516
Validation loss: 2.316288406814948
Epoch: 9| Step: 13
Training loss: 2.7889505144819267
Validation loss: 2.3714063776827516
Epoch: 9| Step: 14
Training loss: 3.1597639106729805
Validation loss: 2.3867114062235837
Epoch: 9| Step: 15
Training loss: 3.2106493892563885
Validation loss: 2.3669368807353686
Epoch: 9| Step: 16
Training loss: 2.9098732625098345
Validation loss: 2.3394233414388452
Epoch: 9| Step: 17
Training loss: 2.1774732493039557
Validation loss: 2.406972534053542
Epoch: 9| Step: 18
Training loss: 3.0596689646060784
Validation loss: 2.4333413086037963
Epoch: 9| Step: 19
Training loss: 2.5606546037418454
Validation loss: 2.443035637824521
Epoch: 89| Step: 0
Training loss: 2.6199659488008575
Validation loss: 2.444692275957382
Epoch: 9| Step: 1
Training loss: 2.649129591453705
Validation loss: 2.358550710162788
Epoch: 9| Step: 2
Training loss: 2.8729640551986337
Validation loss: 2.328501688856822
Epoch: 9| Step: 3
Training loss: 3.620969175564153
Validation loss: 2.3078564826350982
Epoch: 9| Step: 4
Training loss: 1.976489763090073
Validation loss: 2.4379108987188998
Epoch: 9| Step: 5
Training loss: 2.4868000598477336
Validation loss: 2.3704421785944496
Epoch: 9| Step: 6
Training loss: 2.612257319225915
Validation loss: 2.343995794435415
Epoch: 9| Step: 7
Training loss: 3.199999666213972
Validation loss: 2.4011666468581874
Epoch: 9| Step: 8
Training loss: 2.2862354306048256
Validation loss: 2.405024744792955
Epoch: 9| Step: 9
Training loss: 1.8508457132355118
Validation loss: 2.294484066207627
Epoch: 9| Step: 10
Training loss: 2.894637833047388
Validation loss: 2.372877054014675
Epoch: 9| Step: 11
Training loss: 3.04703337428936
Validation loss: 2.4673154498232868
Epoch: 9| Step: 12
Training loss: 2.832392555077698
Validation loss: 2.4003726522239583
Epoch: 9| Step: 13
Training loss: 2.768636583196804
Validation loss: 2.379618347171476
Epoch: 9| Step: 14
Training loss: 2.391999690920194
Validation loss: 2.3228636468106965
Epoch: 9| Step: 15
Training loss: 2.4906215232145197
Validation loss: 2.382822236335436
Epoch: 9| Step: 16
Training loss: 2.6188837276719523
Validation loss: 2.3982399015770723
Epoch: 9| Step: 17
Training loss: 2.527028932376347
Validation loss: 2.4238453512598115
Epoch: 9| Step: 18
Training loss: 3.1080759679968177
Validation loss: 2.3231115829018787
Epoch: 9| Step: 19
Training loss: 2.8202762337252323
Validation loss: 2.3661127722996653
Epoch: 90| Step: 0
Training loss: 1.6047626065485403
Validation loss: 2.3894271593663703
Epoch: 9| Step: 1
Training loss: 2.4812519909444744
Validation loss: 2.3523955786834057
Epoch: 9| Step: 2
Training loss: 2.66946141500787
Validation loss: 2.4038578864330864
Epoch: 9| Step: 3
Training loss: 2.439914876516141
Validation loss: 2.4008120285268917
Epoch: 9| Step: 4
Training loss: 2.9126761976653515
Validation loss: 2.4130278212444485
Epoch: 9| Step: 5
Training loss: 3.199294912621724
Validation loss: 2.4217884895481796
Epoch: 9| Step: 6
Training loss: 2.9583368077503986
Validation loss: 2.341969949810937
Epoch: 9| Step: 7
Training loss: 3.0024080149006154
Validation loss: 2.3136500867598544
Epoch: 9| Step: 8
Training loss: 2.1764127681190084
Validation loss: 2.393510834656649
Epoch: 9| Step: 9
Training loss: 2.1639494608197145
Validation loss: 2.338283065404666
Epoch: 9| Step: 10
Training loss: 3.5619910696475676
Validation loss: 2.3154181536332032
Epoch: 9| Step: 11
Training loss: 2.4883167018790227
Validation loss: 2.3243197594753497
Epoch: 9| Step: 12
Training loss: 1.8571589110277926
Validation loss: 2.3327898316693068
Epoch: 9| Step: 13
Training loss: 2.902449389007414
Validation loss: 2.332780299500239
Epoch: 9| Step: 14
Training loss: 2.8802371216221103
Validation loss: 2.441593508562979
Epoch: 9| Step: 15
Training loss: 2.012214910560738
Validation loss: 2.380967575290434
Epoch: 9| Step: 16
Training loss: 2.8823698370760034
Validation loss: 2.3574342811276283
Epoch: 9| Step: 17
Training loss: 2.9886801459662053
Validation loss: 2.3839910022274298
Epoch: 9| Step: 18
Training loss: 2.5969347417870527
Validation loss: 2.3930424720793777
Epoch: 9| Step: 19
Training loss: 2.741001666118974
Validation loss: 2.2783992190457756
Epoch: 91| Step: 0
Training loss: 2.459241397626621
Validation loss: 2.314117436301922
Epoch: 9| Step: 1
Training loss: 2.5542580713176495
Validation loss: 2.2584470610884964
Epoch: 9| Step: 2
Training loss: 3.5554442553848897
Validation loss: 2.3045535381647135
Epoch: 9| Step: 3
Training loss: 2.8553024222676346
Validation loss: 2.330703184894842
Epoch: 9| Step: 4
Training loss: 2.106630928162946
Validation loss: 2.332451358871418
Epoch: 9| Step: 5
Training loss: 2.9031168137877383
Validation loss: 2.386629190051644
Epoch: 9| Step: 6
Training loss: 2.3960437074155094
Validation loss: 2.260957404577224
Epoch: 9| Step: 7
Training loss: 3.041779311371776
Validation loss: 2.4647041152371436
Epoch: 9| Step: 8
Training loss: 3.304014168900596
Validation loss: 2.4232557955695473
Epoch: 9| Step: 9
Training loss: 2.7368588746286844
Validation loss: 2.4155418497225205
Epoch: 9| Step: 10
Training loss: 3.0322053328061163
Validation loss: 2.315101317635284
Epoch: 9| Step: 11
Training loss: 2.246070397297079
Validation loss: 2.345570521789471
Epoch: 9| Step: 12
Training loss: 2.2554774898284404
Validation loss: 2.3709803874827866
Epoch: 9| Step: 13
Training loss: 3.0859282288230987
Validation loss: 2.2799097955697825
Epoch: 9| Step: 14
Training loss: 2.5309211611547116
Validation loss: 2.3809417225282394
Epoch: 9| Step: 15
Training loss: 1.765393874983352
Validation loss: 2.371199151139431
Epoch: 9| Step: 16
Training loss: 2.013276025175421
Validation loss: 2.314972022622197
Epoch: 9| Step: 17
Training loss: 2.8345974364895494
Validation loss: 2.3519324365209213
Epoch: 9| Step: 18
Training loss: 2.1072348581508438
Validation loss: 2.286794039879565
Epoch: 9| Step: 19
Training loss: 2.317046979063229
Validation loss: 2.4432490906062827
Epoch: 92| Step: 0
Training loss: 3.248756464224854
Validation loss: 2.321213029555143
Epoch: 9| Step: 1
Training loss: 2.64493944181694
Validation loss: 2.325544549476076
Epoch: 9| Step: 2
Training loss: 2.11392602585754
Validation loss: 2.3013972983623887
Epoch: 9| Step: 3
Training loss: 1.831941907448884
Validation loss: 2.3569799769663766
Epoch: 9| Step: 4
Training loss: 2.2054033335255006
Validation loss: 2.3268922596988366
Epoch: 9| Step: 5
Training loss: 2.5992655193499927
Validation loss: 2.4207116238751754
Epoch: 9| Step: 6
Training loss: 2.9645934872555015
Validation loss: 2.330736575208479
Epoch: 9| Step: 7
Training loss: 2.8035383075010722
Validation loss: 2.3574298758342693
Epoch: 9| Step: 8
Training loss: 3.4437511132544847
Validation loss: 2.4224351412854332
Epoch: 9| Step: 9
Training loss: 2.571907638398327
Validation loss: 2.3526672634356753
Epoch: 9| Step: 10
Training loss: 2.847559462839921
Validation loss: 2.3135498514442605
Epoch: 9| Step: 11
Training loss: 2.050667430807268
Validation loss: 2.321923843977389
Epoch: 9| Step: 12
Training loss: 3.207273597249275
Validation loss: 2.3869758601854802
Epoch: 9| Step: 13
Training loss: 2.242468201614887
Validation loss: 2.352613962079383
Epoch: 9| Step: 14
Training loss: 2.7577121273286624
Validation loss: 2.320568106159185
Epoch: 9| Step: 15
Training loss: 2.7161130723352085
Validation loss: 2.3839052534004876
Epoch: 9| Step: 16
Training loss: 2.5286838097802917
Validation loss: 2.3450346647213296
Epoch: 9| Step: 17
Training loss: 2.8384581573987857
Validation loss: 2.511031907052025
Epoch: 9| Step: 18
Training loss: 2.941677612918303
Validation loss: 2.3645403975942285
Epoch: 9| Step: 19
Training loss: 2.8821155563684866
Validation loss: 2.3797200686989375
Epoch: 93| Step: 0
Training loss: 2.9955210629535944
Validation loss: 2.3793048067117426
Epoch: 9| Step: 1
Training loss: 2.8294531301231984
Validation loss: 2.3358932049828285
Epoch: 9| Step: 2
Training loss: 2.419089013129195
Validation loss: 2.298133653748486
Epoch: 9| Step: 3
Training loss: 2.4900756306633216
Validation loss: 2.3716200714472366
Epoch: 9| Step: 4
Training loss: 2.8649714166570175
Validation loss: 2.3375994730212994
Epoch: 9| Step: 5
Training loss: 2.5144936997294316
Validation loss: 2.305582336658257
Epoch: 9| Step: 6
Training loss: 2.8895910114900487
Validation loss: 2.3382547488616128
Epoch: 9| Step: 7
Training loss: 2.494222354371329
Validation loss: 2.3720000787392665
Epoch: 9| Step: 8
Training loss: 3.01247371804577
Validation loss: 2.3531472725679956
Epoch: 9| Step: 9
Training loss: 2.7643609040582495
Validation loss: 2.3172089740481763
Epoch: 9| Step: 10
Training loss: 2.4426506594184767
Validation loss: 2.3212523610256324
Epoch: 9| Step: 11
Training loss: 2.186936660163345
Validation loss: 2.408581413835971
Epoch: 9| Step: 12
Training loss: 2.824419491968884
Validation loss: 2.3374480647157543
Epoch: 9| Step: 13
Training loss: 2.6791275373560843
Validation loss: 2.3143880958745626
Epoch: 9| Step: 14
Training loss: 2.640506899748999
Validation loss: 2.3638400697104056
Epoch: 9| Step: 15
Training loss: 2.4476326852121315
Validation loss: 2.379940914473399
Epoch: 9| Step: 16
Training loss: 2.610714323138128
Validation loss: 2.361479448739056
Epoch: 9| Step: 17
Training loss: 2.095797775705087
Validation loss: 2.347690486882097
Epoch: 9| Step: 18
Training loss: 3.2386178461789634
Validation loss: 2.372027202731619
Epoch: 9| Step: 19
Training loss: 2.5251440177108044
Validation loss: 2.377430938502147
Epoch: 94| Step: 0
Training loss: 3.0541738873474893
Validation loss: 2.3606516186321267
Epoch: 9| Step: 1
Training loss: 2.3277247552085583
Validation loss: 2.317556612770819
Epoch: 9| Step: 2
Training loss: 1.9766533269105073
Validation loss: 2.2726422300976576
Epoch: 9| Step: 3
Training loss: 3.151946807412494
Validation loss: 2.335661286743569
Epoch: 9| Step: 4
Training loss: 2.392657544121934
Validation loss: 2.330160358329429
Epoch: 9| Step: 5
Training loss: 2.985792053289351
Validation loss: 2.381933235377695
Epoch: 9| Step: 6
Training loss: 2.6679378301077077
Validation loss: 2.310256027978218
Epoch: 9| Step: 7
Training loss: 2.7061399723794524
Validation loss: 2.2942016009677952
Epoch: 9| Step: 8
Training loss: 3.2620995579068093
Validation loss: 2.2765351925997503
Epoch: 9| Step: 9
Training loss: 2.3947757764114597
Validation loss: 2.333563397798063
Epoch: 9| Step: 10
Training loss: 2.7327782028427805
Validation loss: 2.3122259112468107
Epoch: 9| Step: 11
Training loss: 2.6567671328525515
Validation loss: 2.3534465757854703
Epoch: 9| Step: 12
Training loss: 3.0162846135391543
Validation loss: 2.3560475330471857
Epoch: 9| Step: 13
Training loss: 2.657531608616059
Validation loss: 2.3839898956703025
Epoch: 9| Step: 14
Training loss: 2.263279404407364
Validation loss: 2.3572539561527184
Epoch: 9| Step: 15
Training loss: 3.0986246565150304
Validation loss: 2.323877774091446
Epoch: 9| Step: 16
Training loss: 2.6553798372220756
Validation loss: 2.2983770190265798
Epoch: 9| Step: 17
Training loss: 2.7556536386151986
Validation loss: 2.283524619285026
Epoch: 9| Step: 18
Training loss: 2.5675731775539967
Validation loss: 2.344348873985571
Epoch: 9| Step: 19
Training loss: 2.230306696307646
Validation loss: 2.3302991494619563
Epoch: 95| Step: 0
Training loss: 2.1964210616458546
Validation loss: 2.4199358167555114
Epoch: 9| Step: 1
Training loss: 2.86650422397464
Validation loss: 2.3607802118616887
Epoch: 9| Step: 2
Training loss: 1.9098322618936843
Validation loss: 2.38749870111983
Epoch: 9| Step: 3
Training loss: 2.3523718369503883
Validation loss: 2.3431578851138837
Epoch: 9| Step: 4
Training loss: 2.561765425926649
Validation loss: 2.3167159777768127
Epoch: 9| Step: 5
Training loss: 2.886564960435325
Validation loss: 2.32259990417028
Epoch: 9| Step: 6
Training loss: 2.1498287620662433
Validation loss: 2.3485336477094827
Epoch: 9| Step: 7
Training loss: 3.4190941227701424
Validation loss: 2.4482725136706867
Epoch: 9| Step: 8
Training loss: 2.9612328374517496
Validation loss: 2.3194309618110913
Epoch: 9| Step: 9
Training loss: 2.7797164117811617
Validation loss: 2.2721071579865173
Epoch: 9| Step: 10
Training loss: 1.6590446071410758
Validation loss: 2.323785386873683
Epoch: 9| Step: 11
Training loss: 2.693209593482971
Validation loss: 2.4636131498096683
Epoch: 9| Step: 12
Training loss: 2.803141303211717
Validation loss: 2.291566709789102
Epoch: 9| Step: 13
Training loss: 3.3656605668167714
Validation loss: 2.2966707448841897
Epoch: 9| Step: 14
Training loss: 2.4653233758234623
Validation loss: 2.3315386839999417
Epoch: 9| Step: 15
Training loss: 1.9305662555840208
Validation loss: 2.349663537771876
Epoch: 9| Step: 16
Training loss: 2.9963878502166206
Validation loss: 2.3189803959817334
Epoch: 9| Step: 17
Training loss: 3.5276703371789857
Validation loss: 2.2714027537322345
Epoch: 9| Step: 18
Training loss: 2.638855199989194
Validation loss: 2.3829740777584707
Epoch: 9| Step: 19
Training loss: 3.3743771578786625
Validation loss: 2.334401755990724
Epoch: 96| Step: 0
Training loss: 3.2569335922859324
Validation loss: 2.3380775918637178
Epoch: 9| Step: 1
Training loss: 3.382360414950414
Validation loss: 2.350303578178411
Epoch: 9| Step: 2
Training loss: 2.287078831156796
Validation loss: 2.3662002352727454
Epoch: 9| Step: 3
Training loss: 2.631378779578533
Validation loss: 2.2535318571980296
Epoch: 9| Step: 4
Training loss: 2.2615703211226514
Validation loss: 2.2819493563970736
Epoch: 9| Step: 5
Training loss: 2.3066662585895745
Validation loss: 2.369228709810405
Epoch: 9| Step: 6
Training loss: 2.3362661277251067
Validation loss: 2.2908982427248477
Epoch: 9| Step: 7
Training loss: 2.7991881794475235
Validation loss: 2.348621870908604
Epoch: 9| Step: 8
Training loss: 3.345323709240182
Validation loss: 2.3280929798768724
Epoch: 9| Step: 9
Training loss: 2.902312698300833
Validation loss: 2.302554227683442
Epoch: 9| Step: 10
Training loss: 1.9015471182759793
Validation loss: 2.353034509293172
Epoch: 9| Step: 11
Training loss: 2.8976498584980233
Validation loss: 2.4071117330789114
Epoch: 9| Step: 12
Training loss: 2.8539968472565613
Validation loss: 2.335051830016507
Epoch: 9| Step: 13
Training loss: 2.407950951954342
Validation loss: 2.382978168754654
Epoch: 9| Step: 14
Training loss: 2.7000912968776833
Validation loss: 2.339129746638901
Epoch: 9| Step: 15
Training loss: 2.610508107387401
Validation loss: 2.3848473335978593
Epoch: 9| Step: 16
Training loss: 2.4174891968478827
Validation loss: 2.3979580560758964
Epoch: 9| Step: 17
Training loss: 2.9040545302806815
Validation loss: 2.3110296618181705
Epoch: 9| Step: 18
Training loss: 2.5908525208255235
Validation loss: 2.267437834234006
Epoch: 9| Step: 19
Training loss: 2.618110334619831
Validation loss: 2.3061558650178537
Epoch: 97| Step: 0
Training loss: 2.6682626498135247
Validation loss: 2.3326861738296274
Epoch: 9| Step: 1
Training loss: 2.237318647483455
Validation loss: 2.40554280180816
Epoch: 9| Step: 2
Training loss: 3.0053397975751692
Validation loss: 2.369928554014705
Epoch: 9| Step: 3
Training loss: 2.454453515569018
Validation loss: 2.393443062819314
Epoch: 9| Step: 4
Training loss: 2.7486091044052774
Validation loss: 2.418091204708598
Epoch: 9| Step: 5
Training loss: 3.5208923214517385
Validation loss: 2.3220637245495404
Epoch: 9| Step: 6
Training loss: 2.0587547282736147
Validation loss: 2.3631294271002483
Epoch: 9| Step: 7
Training loss: 1.87344893833006
Validation loss: 2.3626589533889715
Epoch: 9| Step: 8
Training loss: 2.4624418958595995
Validation loss: 2.314950945899014
Epoch: 9| Step: 9
Training loss: 2.967879960915256
Validation loss: 2.2927461257079496
Epoch: 9| Step: 10
Training loss: 2.6461342667979575
Validation loss: 2.2467416301789527
Epoch: 9| Step: 11
Training loss: 2.236294542085452
Validation loss: 2.419093309163547
Epoch: 9| Step: 12
Training loss: 3.7020772103491737
Validation loss: 2.3362255720825296
Epoch: 9| Step: 13
Training loss: 2.8119413032862974
Validation loss: 2.344902340288515
Epoch: 9| Step: 14
Training loss: 2.400952440260291
Validation loss: 2.3607600788170746
Epoch: 9| Step: 15
Training loss: 2.823777371392525
Validation loss: 2.290217968125103
Epoch: 9| Step: 16
Training loss: 2.285804799961408
Validation loss: 2.2773664556856423
Epoch: 9| Step: 17
Training loss: 1.9621688198871745
Validation loss: 2.3621888350861098
Epoch: 9| Step: 18
Training loss: 2.9692409711718
Validation loss: 2.295973406330847
Epoch: 9| Step: 19
Training loss: 2.910977200428333
Validation loss: 2.2154143132132007
Epoch: 98| Step: 0
Training loss: 2.888187019558936
Validation loss: 2.345424582164335
Epoch: 9| Step: 1
Training loss: 2.3271210829343305
Validation loss: 2.3186321813189945
Epoch: 9| Step: 2
Training loss: 2.6512185408089524
Validation loss: 2.2835477940891695
Epoch: 9| Step: 3
Training loss: 2.834601810216975
Validation loss: 2.2647702872871083
Epoch: 9| Step: 4
Training loss: 3.146996861875974
Validation loss: 2.339777423023858
Epoch: 9| Step: 5
Training loss: 2.577905264073354
Validation loss: 2.29440685686226
Epoch: 9| Step: 6
Training loss: 3.171337664711559
Validation loss: 2.3544476425250527
Epoch: 9| Step: 7
Training loss: 2.2620501497815986
Validation loss: 2.418825610903025
Epoch: 9| Step: 8
Training loss: 2.818495738536678
Validation loss: 2.3767051292516204
Epoch: 9| Step: 9
Training loss: 2.074604465519751
Validation loss: 2.2507154723479643
Epoch: 9| Step: 10
Training loss: 2.580753350681863
Validation loss: 2.372836333301335
Epoch: 9| Step: 11
Training loss: 2.523512328370033
Validation loss: 2.294739082142746
Epoch: 9| Step: 12
Training loss: 2.432306674908249
Validation loss: 2.325305485010527
Epoch: 9| Step: 13
Training loss: 3.1844045530974996
Validation loss: 2.2896831412405425
Epoch: 9| Step: 14
Training loss: 2.592308655081028
Validation loss: 2.3792462928307723
Epoch: 9| Step: 15
Training loss: 2.5154852976421487
Validation loss: 2.3753338206166217
Epoch: 9| Step: 16
Training loss: 2.5021292202373613
Validation loss: 2.353545941580224
Epoch: 9| Step: 17
Training loss: 2.4908636995848785
Validation loss: 2.371667325750826
Epoch: 9| Step: 18
Training loss: 3.1674486667053308
Validation loss: 2.3686065086510126
Epoch: 9| Step: 19
Training loss: 2.446858560207285
Validation loss: 2.4172917383560044
Epoch: 99| Step: 0
Training loss: 2.9893846257505623
Validation loss: 2.3449522869678088
Epoch: 9| Step: 1
Training loss: 2.1697093677586294
Validation loss: 2.3192618741334807
Epoch: 9| Step: 2
Training loss: 2.739286360702396
Validation loss: 2.3243622736139615
Epoch: 9| Step: 3
Training loss: 2.72304187380745
Validation loss: 2.297851990413264
Epoch: 9| Step: 4
Training loss: 1.875177247888459
Validation loss: 2.290715220457376
Epoch: 9| Step: 5
Training loss: 2.0230485107745246
Validation loss: 2.358961471271444
Epoch: 9| Step: 6
Training loss: 2.628465998205635
Validation loss: 2.3480808202176973
Epoch: 9| Step: 7
Training loss: 2.5145730609151964
Validation loss: 2.2516555250585375
Epoch: 9| Step: 8
Training loss: 2.940003322677292
Validation loss: 2.2763270458223834
Epoch: 9| Step: 9
Training loss: 2.707896172870081
Validation loss: 2.3834951216118614
Epoch: 9| Step: 10
Training loss: 2.086258881346013
Validation loss: 2.239701276104995
Epoch: 9| Step: 11
Training loss: 2.8844609703403
Validation loss: 2.3044243408634855
Epoch: 9| Step: 12
Training loss: 2.7496545748078463
Validation loss: 2.388072000190213
Epoch: 9| Step: 13
Training loss: 2.4996162119964316
Validation loss: 2.411865540926042
Epoch: 9| Step: 14
Training loss: 2.5579285200927346
Validation loss: 2.34905915940104
Epoch: 9| Step: 15
Training loss: 2.0462612950147854
Validation loss: 2.3233511564292346
Epoch: 9| Step: 16
Training loss: 3.8668587593069277
Validation loss: 2.3722325650496363
Epoch: 9| Step: 17
Training loss: 3.3757347437438905
Validation loss: 2.443377217606067
Epoch: 9| Step: 18
Training loss: 3.4156755700167682
Validation loss: 2.3432110013361185
Epoch: 9| Step: 19
Training loss: 2.568113644524445
Validation loss: 2.4414144842902266
Epoch: 100| Step: 0
Training loss: 2.7366815048850106
Validation loss: 2.3409095067511188
Epoch: 9| Step: 1
Training loss: 4.265919210606992
Validation loss: 2.3055387868693558
Epoch: 9| Step: 2
Training loss: 2.080190564192548
Validation loss: 2.3205940932159606
Epoch: 9| Step: 3
Training loss: 2.584655074934425
Validation loss: 2.4252600690473813
Epoch: 9| Step: 4
Training loss: 2.639228225662993
Validation loss: 2.4165359218790616
Epoch: 9| Step: 5
Training loss: 2.3387538301078714
Validation loss: 2.400436929572954
Epoch: 9| Step: 6
Training loss: 2.05014696757417
Validation loss: 2.318828686054729
Epoch: 9| Step: 7
Training loss: 2.7581072857787317
Validation loss: 2.3032998407019902
Epoch: 9| Step: 8
Training loss: 3.1955928912639635
Validation loss: 2.37456666897079
Epoch: 9| Step: 9
Training loss: 1.7848045620393607
Validation loss: 2.365968229670103
Epoch: 9| Step: 10
Training loss: 2.4737778661391077
Validation loss: 2.226539941932229
Epoch: 9| Step: 11
Training loss: 1.9860363711304492
Validation loss: 2.3350637684745275
Epoch: 9| Step: 12
Training loss: 2.506475835123999
Validation loss: 2.325003027382842
Epoch: 9| Step: 13
Training loss: 2.641163607410726
Validation loss: 2.3596271597600675
Epoch: 9| Step: 14
Training loss: 2.92528119162053
Validation loss: 2.3311795064043563
Epoch: 9| Step: 15
Training loss: 2.8085561439426447
Validation loss: 2.3696299035573443
Epoch: 9| Step: 16
Training loss: 2.564899530655335
Validation loss: 2.3327790654172875
Epoch: 9| Step: 17
Training loss: 3.0999831783699663
Validation loss: 2.388595226793586
Epoch: 9| Step: 18
Training loss: 2.3285902953658195
Validation loss: 2.2885194908583566
Epoch: 9| Step: 19
Training loss: 3.3627267130039127
Validation loss: 2.3753479699322337
