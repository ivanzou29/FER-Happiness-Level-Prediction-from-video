Epoch: 1| Step: 0
Training loss: 4.708370208740234
Validation loss: 4.338929255803426

Epoch: 6| Step: 1
Training loss: 3.8630318641662598
Validation loss: 4.322595596313477

Epoch: 6| Step: 2
Training loss: 4.647576808929443
Validation loss: 4.307789882024129

Epoch: 6| Step: 3
Training loss: 5.332803726196289
Validation loss: 4.288996299107869

Epoch: 6| Step: 4
Training loss: 5.074347496032715
Validation loss: 4.274718602498372

Epoch: 6| Step: 5
Training loss: 4.658657073974609
Validation loss: 4.258546193440755

Epoch: 6| Step: 6
Training loss: 4.174915313720703
Validation loss: 4.242551883061727

Epoch: 6| Step: 7
Training loss: 3.8370320796966553
Validation loss: 4.227347175280253

Epoch: 6| Step: 8
Training loss: 4.660504341125488
Validation loss: 4.216475645701091

Epoch: 6| Step: 9
Training loss: 4.132119655609131
Validation loss: 4.19970949490865

Epoch: 6| Step: 10
Training loss: 3.2736268043518066
Validation loss: 4.183678984642029

Epoch: 6| Step: 11
Training loss: 3.328933000564575
Validation loss: 4.171690781911214

Epoch: 6| Step: 12
Training loss: 3.745958089828491
Validation loss: 4.158255497614543

Epoch: 6| Step: 13
Training loss: 5.6470818519592285
Validation loss: 4.14470648765564

Epoch: 2| Step: 0
Training loss: 4.511430740356445
Validation loss: 4.125438491503398

Epoch: 6| Step: 1
Training loss: 4.832242012023926
Validation loss: 4.108687400817871

Epoch: 6| Step: 2
Training loss: 3.879222869873047
Validation loss: 4.092327833175659

Epoch: 6| Step: 3
Training loss: 5.129342555999756
Validation loss: 4.073819200197856

Epoch: 6| Step: 4
Training loss: 4.344829559326172
Validation loss: 4.0582947333653765

Epoch: 6| Step: 5
Training loss: 4.357039451599121
Validation loss: 4.037121097246806

Epoch: 6| Step: 6
Training loss: 3.8360345363616943
Validation loss: 4.015211701393127

Epoch: 6| Step: 7
Training loss: 4.502942085266113
Validation loss: 3.9973275661468506

Epoch: 6| Step: 8
Training loss: 4.16864538192749
Validation loss: 3.9749350547790527

Epoch: 6| Step: 9
Training loss: 2.496777057647705
Validation loss: 3.953445792198181

Epoch: 6| Step: 10
Training loss: 3.4002132415771484
Validation loss: 3.925294796625773

Epoch: 6| Step: 11
Training loss: 3.3316383361816406
Validation loss: 3.9049320618311563

Epoch: 6| Step: 12
Training loss: 4.77667236328125
Validation loss: 3.881747603416443

Epoch: 6| Step: 13
Training loss: 4.387997627258301
Validation loss: 3.8594587246576944

Epoch: 3| Step: 0
Training loss: 3.984797716140747
Validation loss: 3.825859308242798

Epoch: 6| Step: 1
Training loss: 3.331056833267212
Validation loss: 3.801769495010376

Epoch: 6| Step: 2
Training loss: 3.3827028274536133
Validation loss: 3.771808465321859

Epoch: 6| Step: 3
Training loss: 3.3166096210479736
Validation loss: 3.7392099301020303

Epoch: 6| Step: 4
Training loss: 4.817208766937256
Validation loss: 3.708845376968384

Epoch: 6| Step: 5
Training loss: 3.74957275390625
Validation loss: 3.6797802448272705

Epoch: 6| Step: 6
Training loss: 3.6572208404541016
Validation loss: 3.6418537298838296

Epoch: 6| Step: 7
Training loss: 4.625561714172363
Validation loss: 3.6062349875768027

Epoch: 6| Step: 8
Training loss: 3.733322858810425
Validation loss: 3.563544829686483

Epoch: 6| Step: 9
Training loss: 3.673581838607788
Validation loss: 3.5194834073384604

Epoch: 6| Step: 10
Training loss: 2.8368024826049805
Validation loss: 3.4774484237035117

Epoch: 6| Step: 11
Training loss: 3.919595241546631
Validation loss: 3.4364111026128135

Epoch: 6| Step: 12
Training loss: 3.1717190742492676
Validation loss: 3.380582809448242

Epoch: 6| Step: 13
Training loss: 3.668020248413086
Validation loss: 3.334968010584513

Epoch: 4| Step: 0
Training loss: 3.1830062866210938
Validation loss: 3.2686352729797363

Epoch: 6| Step: 1
Training loss: 3.812220573425293
Validation loss: 3.225358525911967

Epoch: 6| Step: 2
Training loss: 2.7717032432556152
Validation loss: 3.162789742151896

Epoch: 6| Step: 3
Training loss: 3.3143997192382812
Validation loss: 3.098776658376058

Epoch: 6| Step: 4
Training loss: 2.315350294113159
Validation loss: 3.0459971825281777

Epoch: 6| Step: 5
Training loss: 3.21439790725708
Validation loss: 2.9823787609736123

Epoch: 6| Step: 6
Training loss: 2.90041446685791
Validation loss: 2.918694178263346

Epoch: 6| Step: 7
Training loss: 3.5218186378479004
Validation loss: 2.8510119120279946

Epoch: 6| Step: 8
Training loss: 2.6740221977233887
Validation loss: 2.802740772565206

Epoch: 6| Step: 9
Training loss: 2.4386000633239746
Validation loss: 2.715190331141154

Epoch: 6| Step: 10
Training loss: 2.566528558731079
Validation loss: 2.627941906452179

Epoch: 6| Step: 11
Training loss: 2.4271111488342285
Validation loss: 2.570370356241862

Epoch: 6| Step: 12
Training loss: 2.169036865234375
Validation loss: 2.476485013961792

Epoch: 6| Step: 13
Training loss: 2.884827136993408
Validation loss: 2.403837283452352

Epoch: 5| Step: 0
Training loss: 2.4964890480041504
Validation loss: 2.3535891572634378

Epoch: 6| Step: 1
Training loss: 2.166365146636963
Validation loss: 2.320512592792511

Epoch: 6| Step: 2
Training loss: 2.1606459617614746
Validation loss: 2.300284266471863

Epoch: 6| Step: 3
Training loss: 2.6239261627197266
Validation loss: 2.2411623199780784

Epoch: 6| Step: 4
Training loss: 2.2563440799713135
Validation loss: 2.2438467343648276

Epoch: 6| Step: 5
Training loss: 1.2055082321166992
Validation loss: 2.2496981223424277

Epoch: 6| Step: 6
Training loss: 2.5011396408081055
Validation loss: 2.272813002268473

Epoch: 6| Step: 7
Training loss: 2.4279136657714844
Validation loss: 2.3329453468322754

Epoch: 6| Step: 8
Training loss: 2.4981207847595215
Validation loss: 2.3435281912485757

Epoch: 6| Step: 9
Training loss: 2.526233673095703
Validation loss: 2.355476955572764

Epoch: 6| Step: 10
Training loss: 2.382303237915039
Validation loss: 2.350050449371338

Epoch: 6| Step: 11
Training loss: 2.127500295639038
Validation loss: 2.3322292963663735

Epoch: 6| Step: 12
Training loss: 2.4779233932495117
Validation loss: 2.311665415763855

Epoch: 6| Step: 13
Training loss: 2.4567484855651855
Validation loss: 2.3453020254770913

Epoch: 6| Step: 0
Training loss: 2.347203493118286
Validation loss: 2.2935901284217834

Epoch: 6| Step: 1
Training loss: 2.8279483318328857
Validation loss: 2.2981889049212136

Epoch: 6| Step: 2
Training loss: 2.70974063873291
Validation loss: 2.2435117761294046

Epoch: 6| Step: 3
Training loss: 1.9382188320159912
Validation loss: 2.2248387138048806

Epoch: 6| Step: 4
Training loss: 2.3045060634613037
Validation loss: 2.2108540336290994

Epoch: 6| Step: 5
Training loss: 2.4600181579589844
Validation loss: 2.2208878993988037

Epoch: 6| Step: 6
Training loss: 1.4807270765304565
Validation loss: 2.1975533962249756

Epoch: 6| Step: 7
Training loss: 2.5568766593933105
Validation loss: 2.2198626001675925

Epoch: 6| Step: 8
Training loss: 2.1891777515411377
Validation loss: 2.2419907450675964

Epoch: 6| Step: 9
Training loss: 1.5270705223083496
Validation loss: 2.229662279287974

Epoch: 6| Step: 10
Training loss: 2.503842830657959
Validation loss: 2.205241580804189

Epoch: 6| Step: 11
Training loss: 1.9943897724151611
Validation loss: 2.192924420038859

Epoch: 6| Step: 12
Training loss: 1.7800863981246948
Validation loss: 2.2092943588892617

Epoch: 6| Step: 13
Training loss: 2.045640230178833
Validation loss: 2.2135299245516458

Epoch: 7| Step: 0
Training loss: 2.2944817543029785
Validation loss: 2.226854701836904

Epoch: 6| Step: 1
Training loss: 2.4521660804748535
Validation loss: 2.2316232124964395

Epoch: 6| Step: 2
Training loss: 2.4561004638671875
Validation loss: 2.2110055685043335

Epoch: 6| Step: 3
Training loss: 2.2918384075164795
Validation loss: 2.192381978034973

Epoch: 6| Step: 4
Training loss: 2.0998520851135254
Validation loss: 2.1889406045277915

Epoch: 6| Step: 5
Training loss: 2.549266815185547
Validation loss: 2.2227904001871743

Epoch: 6| Step: 6
Training loss: 2.084573268890381
Validation loss: 2.1969477335611978

Epoch: 6| Step: 7
Training loss: 2.1982033252716064
Validation loss: 2.1972166498502097

Epoch: 6| Step: 8
Training loss: 2.161691665649414
Validation loss: 2.2170738577842712

Epoch: 6| Step: 9
Training loss: 1.9446759223937988
Validation loss: 2.21334969997406

Epoch: 6| Step: 10
Training loss: 1.643083930015564
Validation loss: 2.2023621598879495

Epoch: 6| Step: 11
Training loss: 2.3233284950256348
Validation loss: 2.1948070923487344

Epoch: 6| Step: 12
Training loss: 2.266674041748047
Validation loss: 2.2220502297083535

Epoch: 6| Step: 13
Training loss: 1.6955640316009521
Validation loss: 2.2020010948181152

Epoch: 8| Step: 0
Training loss: 2.268231153488159
Validation loss: 2.19731867313385

Epoch: 6| Step: 1
Training loss: 2.0064549446105957
Validation loss: 2.1940051913261414

Epoch: 6| Step: 2
Training loss: 2.2355518341064453
Validation loss: 2.2041386564572654

Epoch: 6| Step: 3
Training loss: 1.665954828262329
Validation loss: 2.1860260566075644

Epoch: 6| Step: 4
Training loss: 2.6039323806762695
Validation loss: 2.193292498588562

Epoch: 6| Step: 5
Training loss: 1.8570232391357422
Validation loss: 2.1938669880231223

Epoch: 6| Step: 6
Training loss: 2.293595790863037
Validation loss: 2.204132397969564

Epoch: 6| Step: 7
Training loss: 2.3889737129211426
Validation loss: 2.20905464887619

Epoch: 6| Step: 8
Training loss: 2.2306394577026367
Validation loss: 2.224089741706848

Epoch: 6| Step: 9
Training loss: 2.4431381225585938
Validation loss: 2.1717538634936013

Epoch: 6| Step: 10
Training loss: 1.7668743133544922
Validation loss: 2.2047348817189536

Epoch: 6| Step: 11
Training loss: 2.177152633666992
Validation loss: 2.161215901374817

Epoch: 6| Step: 12
Training loss: 2.0680437088012695
Validation loss: 2.212698837121328

Epoch: 6| Step: 13
Training loss: 2.5223071575164795
Validation loss: 2.2090103228886924

Epoch: 9| Step: 0
Training loss: 1.9374732971191406
Validation loss: 2.1734009782473245

Epoch: 6| Step: 1
Training loss: 2.5321455001831055
Validation loss: 2.2055059671401978

Epoch: 6| Step: 2
Training loss: 2.207895278930664
Validation loss: 2.216011087099711

Epoch: 6| Step: 3
Training loss: 2.6258668899536133
Validation loss: 2.1889588634173074

Epoch: 6| Step: 4
Training loss: 2.267744541168213
Validation loss: 2.192423085371653

Epoch: 6| Step: 5
Training loss: 1.5943586826324463
Validation loss: 2.178191582361857

Epoch: 6| Step: 6
Training loss: 2.4833760261535645
Validation loss: 2.192000428835551

Epoch: 6| Step: 7
Training loss: 1.7739181518554688
Validation loss: 2.179342190424601

Epoch: 6| Step: 8
Training loss: 2.0488908290863037
Validation loss: 2.173210839430491

Epoch: 6| Step: 9
Training loss: 1.8935884237289429
Validation loss: 2.1814640164375305

Epoch: 6| Step: 10
Training loss: 2.8005852699279785
Validation loss: 2.1696045200030007

Epoch: 6| Step: 11
Training loss: 2.6409263610839844
Validation loss: 2.175660729408264

Epoch: 6| Step: 12
Training loss: 1.6517027616500854
Validation loss: 2.168293317159017

Epoch: 6| Step: 13
Training loss: 1.4681367874145508
Validation loss: 2.196235795815786

Epoch: 10| Step: 0
Training loss: 2.285909652709961
Validation loss: 2.1849976976712546

Epoch: 6| Step: 1
Training loss: 2.6100213527679443
Validation loss: 2.1969728668530784

Epoch: 6| Step: 2
Training loss: 1.841719627380371
Validation loss: 2.1923980911572776

Epoch: 6| Step: 3
Training loss: 2.0507731437683105
Validation loss: 2.1913257241249084

Epoch: 6| Step: 4
Training loss: 2.8806633949279785
Validation loss: 2.174427847067515

Epoch: 6| Step: 5
Training loss: 1.9441044330596924
Validation loss: 2.1745384136835733

Epoch: 6| Step: 6
Training loss: 2.78145170211792
Validation loss: 2.168124516805013

Epoch: 6| Step: 7
Training loss: 1.697943925857544
Validation loss: 2.1924980084101358

Epoch: 6| Step: 8
Training loss: 1.7152135372161865
Validation loss: 2.1532259384791055

Epoch: 6| Step: 9
Training loss: 2.2015514373779297
Validation loss: 2.160016715526581

Epoch: 6| Step: 10
Training loss: 2.6340906620025635
Validation loss: 2.1779605746269226

Epoch: 6| Step: 11
Training loss: 1.4913978576660156
Validation loss: 2.1787041425704956

Epoch: 6| Step: 12
Training loss: 1.6210402250289917
Validation loss: 2.17020720243454

Epoch: 6| Step: 13
Training loss: 2.257436752319336
Validation loss: 2.1794010996818542

Epoch: 11| Step: 0
Training loss: 1.8261146545410156
Validation loss: 2.185137629508972

Epoch: 6| Step: 1
Training loss: 1.603193998336792
Validation loss: 2.156201640764872

Epoch: 6| Step: 2
Training loss: 2.0485923290252686
Validation loss: 2.1509658098220825

Epoch: 6| Step: 3
Training loss: 2.412552833557129
Validation loss: 2.1475733319918313

Epoch: 6| Step: 4
Training loss: 1.976132869720459
Validation loss: 2.173276742299398

Epoch: 6| Step: 5
Training loss: 2.2066688537597656
Validation loss: 2.179352819919586

Epoch: 6| Step: 6
Training loss: 2.633012294769287
Validation loss: 2.1875123580296836

Epoch: 6| Step: 7
Training loss: 2.568814754486084
Validation loss: 2.170170466105143

Epoch: 6| Step: 8
Training loss: 1.929566740989685
Validation loss: 2.1792491475741067

Epoch: 6| Step: 9
Training loss: 1.8219207525253296
Validation loss: 2.1581528385480246

Epoch: 6| Step: 10
Training loss: 2.688061237335205
Validation loss: 2.180023670196533

Epoch: 6| Step: 11
Training loss: 1.9945062398910522
Validation loss: 2.1931519309679666

Epoch: 6| Step: 12
Training loss: 2.0229620933532715
Validation loss: 2.172769029935201

Epoch: 6| Step: 13
Training loss: 1.9435632228851318
Validation loss: 2.174140731493632

Epoch: 12| Step: 0
Training loss: 1.3423432111740112
Validation loss: 2.1637399196624756

Epoch: 6| Step: 1
Training loss: 2.647353172302246
Validation loss: 2.1581456859906516

Epoch: 6| Step: 2
Training loss: 2.406022071838379
Validation loss: 2.181777616341909

Epoch: 6| Step: 3
Training loss: 2.335286855697632
Validation loss: 2.156180222829183

Epoch: 6| Step: 4
Training loss: 1.9181138277053833
Validation loss: 2.151466488838196

Epoch: 6| Step: 5
Training loss: 2.15850567817688
Validation loss: 2.1163105765978494

Epoch: 6| Step: 6
Training loss: 1.37148118019104
Validation loss: 2.134763995806376

Epoch: 6| Step: 7
Training loss: 2.71150541305542
Validation loss: 2.153974692026774

Epoch: 6| Step: 8
Training loss: 2.0595669746398926
Validation loss: 2.1560837825139365

Epoch: 6| Step: 9
Training loss: 2.0846104621887207
Validation loss: 2.1647173961003623

Epoch: 6| Step: 10
Training loss: 2.4627466201782227
Validation loss: 2.163233478864034

Epoch: 6| Step: 11
Training loss: 1.9153873920440674
Validation loss: 2.1725929578145347

Epoch: 6| Step: 12
Training loss: 2.9136502742767334
Validation loss: 2.1351845264434814

Epoch: 6| Step: 13
Training loss: 1.265999436378479
Validation loss: 2.126756966114044

Epoch: 13| Step: 0
Training loss: 1.8430769443511963
Validation loss: 2.155582308769226

Epoch: 6| Step: 1
Training loss: 2.4750027656555176
Validation loss: 2.156840523084005

Epoch: 6| Step: 2
Training loss: 2.293999195098877
Validation loss: 2.1436152259508767

Epoch: 6| Step: 3
Training loss: 1.7587814331054688
Validation loss: 2.166649103164673

Epoch: 6| Step: 4
Training loss: 1.6039323806762695
Validation loss: 2.166343371073405

Epoch: 6| Step: 5
Training loss: 2.4328510761260986
Validation loss: 2.1487701733907065

Epoch: 6| Step: 6
Training loss: 1.9693045616149902
Validation loss: 2.150714556376139

Epoch: 6| Step: 7
Training loss: 2.1207234859466553
Validation loss: 2.138498326142629

Epoch: 6| Step: 8
Training loss: 2.3262739181518555
Validation loss: 2.149284859498342

Epoch: 6| Step: 9
Training loss: 2.104419469833374
Validation loss: 2.147890627384186

Epoch: 6| Step: 10
Training loss: 1.5570882558822632
Validation loss: 2.1490887999534607

Epoch: 6| Step: 11
Training loss: 2.2133712768554688
Validation loss: 2.1497159202893577

Epoch: 6| Step: 12
Training loss: 2.398344039916992
Validation loss: 2.1562146743138633

Epoch: 6| Step: 13
Training loss: 2.1051690578460693
Validation loss: 2.1669220527013144

Epoch: 14| Step: 0
Training loss: 1.4779131412506104
Validation loss: 2.1523254911104837

Epoch: 6| Step: 1
Training loss: 2.1220767498016357
Validation loss: 2.143994410832723

Epoch: 6| Step: 2
Training loss: 2.3031411170959473
Validation loss: 2.140882392724355

Epoch: 6| Step: 3
Training loss: 2.1720056533813477
Validation loss: 2.137769639492035

Epoch: 6| Step: 4
Training loss: 1.604172706604004
Validation loss: 2.138980766137441

Epoch: 6| Step: 5
Training loss: 2.846860408782959
Validation loss: 2.139011879762014

Epoch: 6| Step: 6
Training loss: 1.9945628643035889
Validation loss: 2.141060690085093

Epoch: 6| Step: 7
Training loss: 2.815086841583252
Validation loss: 2.1332366863886514

Epoch: 6| Step: 8
Training loss: 2.3950695991516113
Validation loss: 2.1209760308265686

Epoch: 6| Step: 9
Training loss: 1.6538364887237549
Validation loss: 2.14033571879069

Epoch: 6| Step: 10
Training loss: 1.6419076919555664
Validation loss: 2.1507838368415833

Epoch: 6| Step: 11
Training loss: 1.7725322246551514
Validation loss: 2.151470959186554

Epoch: 6| Step: 12
Training loss: 2.153745412826538
Validation loss: 2.1483596364657083

Epoch: 6| Step: 13
Training loss: 2.0195679664611816
Validation loss: 2.1342820525169373

Epoch: 15| Step: 0
Training loss: 2.804659605026245
Validation loss: 2.1401280562082925

Epoch: 6| Step: 1
Training loss: 1.9043841361999512
Validation loss: 2.1212968230247498

Epoch: 6| Step: 2
Training loss: 1.724593162536621
Validation loss: 2.1452365120251975

Epoch: 6| Step: 3
Training loss: 2.5629818439483643
Validation loss: 2.1472548047701516

Epoch: 6| Step: 4
Training loss: 1.5139210224151611
Validation loss: 2.133575956026713

Epoch: 6| Step: 5
Training loss: 2.7572591304779053
Validation loss: 2.163176119327545

Epoch: 6| Step: 6
Training loss: 1.6496121883392334
Validation loss: 2.1120551427205405

Epoch: 6| Step: 7
Training loss: 1.6271438598632812
Validation loss: 2.120623509089152

Epoch: 6| Step: 8
Training loss: 1.610168218612671
Validation loss: 2.11108269294103

Epoch: 6| Step: 9
Training loss: 2.58303165435791
Validation loss: 2.145535667737325

Epoch: 6| Step: 10
Training loss: 1.8558378219604492
Validation loss: 2.125427703062693

Epoch: 6| Step: 11
Training loss: 1.8204412460327148
Validation loss: 2.117940684159597

Epoch: 6| Step: 12
Training loss: 3.090663194656372
Validation loss: 2.116264561812083

Epoch: 6| Step: 13
Training loss: 1.5058176517486572
Validation loss: 2.1101787288983664

Epoch: 16| Step: 0
Training loss: 2.3259010314941406
Validation loss: 2.122377177079519

Epoch: 6| Step: 1
Training loss: 1.5933163166046143
Validation loss: 2.105387806892395

Epoch: 6| Step: 2
Training loss: 1.6240794658660889
Validation loss: 2.1089660127957663

Epoch: 6| Step: 3
Training loss: 1.811323881149292
Validation loss: 2.1184587478637695

Epoch: 6| Step: 4
Training loss: 1.7854758501052856
Validation loss: 2.128419041633606

Epoch: 6| Step: 5
Training loss: 2.0443918704986572
Validation loss: 2.1152830918629966

Epoch: 6| Step: 6
Training loss: 2.116171360015869
Validation loss: 2.146301488081614

Epoch: 6| Step: 7
Training loss: 2.5674517154693604
Validation loss: 2.1317566633224487

Epoch: 6| Step: 8
Training loss: 2.3391666412353516
Validation loss: 2.1057644883791604

Epoch: 6| Step: 9
Training loss: 1.6749978065490723
Validation loss: 2.1243642965952554

Epoch: 6| Step: 10
Training loss: 1.6530042886734009
Validation loss: 2.1133872071901956

Epoch: 6| Step: 11
Training loss: 2.1385810375213623
Validation loss: 2.135749797026316

Epoch: 6| Step: 12
Training loss: 2.8287644386291504
Validation loss: 2.1033959786097207

Epoch: 6| Step: 13
Training loss: 2.388140916824341
Validation loss: 2.128909965356191

Epoch: 17| Step: 0
Training loss: 2.2121317386627197
Validation loss: 2.1588579416275024

Epoch: 6| Step: 1
Training loss: 2.185612678527832
Validation loss: 2.119409203529358

Epoch: 6| Step: 2
Training loss: 2.182577610015869
Validation loss: 2.139412760734558

Epoch: 6| Step: 3
Training loss: 2.070903778076172
Validation loss: 2.1207799712816873

Epoch: 6| Step: 4
Training loss: 1.6190611124038696
Validation loss: 2.1360914508501687

Epoch: 6| Step: 5
Training loss: 1.712020754814148
Validation loss: 2.0810431639353433

Epoch: 6| Step: 6
Training loss: 1.937575101852417
Validation loss: 2.121694564819336

Epoch: 6| Step: 7
Training loss: 2.187328815460205
Validation loss: 2.0991589029630027

Epoch: 6| Step: 8
Training loss: 2.6877410411834717
Validation loss: 2.1392988165219626

Epoch: 6| Step: 9
Training loss: 2.0508317947387695
Validation loss: 2.1038904786109924

Epoch: 6| Step: 10
Training loss: 2.46346116065979
Validation loss: 2.1206748684247336

Epoch: 6| Step: 11
Training loss: 2.1214354038238525
Validation loss: 2.1080925663312278

Epoch: 6| Step: 12
Training loss: 1.8115031719207764
Validation loss: 2.1185870369275412

Epoch: 6| Step: 13
Training loss: 1.4539618492126465
Validation loss: 2.0914544264475503

Epoch: 18| Step: 0
Training loss: 2.0375099182128906
Validation loss: 2.0949870149294534

Epoch: 6| Step: 1
Training loss: 2.490743398666382
Validation loss: 2.100083649158478

Epoch: 6| Step: 2
Training loss: 2.470860004425049
Validation loss: 2.1046999096870422

Epoch: 6| Step: 3
Training loss: 1.7838084697723389
Validation loss: 2.102113127708435

Epoch: 6| Step: 4
Training loss: 1.4974778890609741
Validation loss: 2.0840459068616233

Epoch: 6| Step: 5
Training loss: 1.6887589693069458
Validation loss: 2.112151841322581

Epoch: 6| Step: 6
Training loss: 2.1820366382598877
Validation loss: 2.1144930322964988

Epoch: 6| Step: 7
Training loss: 1.7096540927886963
Validation loss: 2.117834230264028

Epoch: 6| Step: 8
Training loss: 1.6202408075332642
Validation loss: 2.0956342418988547

Epoch: 6| Step: 9
Training loss: 2.3559441566467285
Validation loss: 2.106958270072937

Epoch: 6| Step: 10
Training loss: 1.7583513259887695
Validation loss: 2.093820571899414

Epoch: 6| Step: 11
Training loss: 2.2121152877807617
Validation loss: 2.092433134714762

Epoch: 6| Step: 12
Training loss: 1.9910802841186523
Validation loss: 2.113181173801422

Epoch: 6| Step: 13
Training loss: 2.935014486312866
Validation loss: 2.1170790592829385

Epoch: 19| Step: 0
Training loss: 1.7445546388626099
Validation loss: 2.0875802040100098

Epoch: 6| Step: 1
Training loss: 2.1068503856658936
Validation loss: 2.12017152706782

Epoch: 6| Step: 2
Training loss: 2.123828172683716
Validation loss: 2.075467308362325

Epoch: 6| Step: 3
Training loss: 1.7490373849868774
Validation loss: 2.0861905018488565

Epoch: 6| Step: 4
Training loss: 1.5877455472946167
Validation loss: 2.0735043485959372

Epoch: 6| Step: 5
Training loss: 2.2045044898986816
Validation loss: 2.08235627412796

Epoch: 6| Step: 6
Training loss: 1.0314325094223022
Validation loss: 2.08415957291921

Epoch: 6| Step: 7
Training loss: 1.731801152229309
Validation loss: 2.1056803663571677

Epoch: 6| Step: 8
Training loss: 2.6690845489501953
Validation loss: 2.0989553729693093

Epoch: 6| Step: 9
Training loss: 2.541208267211914
Validation loss: 2.125030755996704

Epoch: 6| Step: 10
Training loss: 2.470879316329956
Validation loss: 2.0992416938145957

Epoch: 6| Step: 11
Training loss: 2.265890121459961
Validation loss: 2.0847970644632974

Epoch: 6| Step: 12
Training loss: 2.1371731758117676
Validation loss: 2.0758185982704163

Epoch: 6| Step: 13
Training loss: 2.451862096786499
Validation loss: 2.1209572553634644

Epoch: 20| Step: 0
Training loss: 1.9054592847824097
Validation loss: 2.102420926094055

Epoch: 6| Step: 1
Training loss: 2.36761474609375
Validation loss: 2.087624192237854

Epoch: 6| Step: 2
Training loss: 1.8742992877960205
Validation loss: 2.0800573229789734

Epoch: 6| Step: 3
Training loss: 2.0990779399871826
Validation loss: 2.068599204222361

Epoch: 6| Step: 4
Training loss: 1.319068431854248
Validation loss: 2.0805026292800903

Epoch: 6| Step: 5
Training loss: 2.3373498916625977
Validation loss: 2.100693941116333

Epoch: 6| Step: 6
Training loss: 1.9454562664031982
Validation loss: 2.098851978778839

Epoch: 6| Step: 7
Training loss: 2.1989145278930664
Validation loss: 2.1041601498921714

Epoch: 6| Step: 8
Training loss: 1.9557139873504639
Validation loss: 2.1220247944196067

Epoch: 6| Step: 9
Training loss: 2.4068026542663574
Validation loss: 2.1263325611750283

Epoch: 6| Step: 10
Training loss: 1.8282058238983154
Validation loss: 2.1108936270078025

Epoch: 6| Step: 11
Training loss: 1.8643664121627808
Validation loss: 2.1083581248919168

Epoch: 6| Step: 12
Training loss: 2.290557384490967
Validation loss: 2.1132298906644187

Epoch: 6| Step: 13
Training loss: 2.0465359687805176
Validation loss: 2.0893133083979287

Epoch: 21| Step: 0
Training loss: 1.8278371095657349
Validation loss: 2.1073562701543174

Epoch: 6| Step: 1
Training loss: 2.5458269119262695
Validation loss: 2.0797184705734253

Epoch: 6| Step: 2
Training loss: 2.059407949447632
Validation loss: 2.0806912978490195

Epoch: 6| Step: 3
Training loss: 1.3623619079589844
Validation loss: 2.064314921696981

Epoch: 6| Step: 4
Training loss: 1.2766436338424683
Validation loss: 2.074104686578115

Epoch: 6| Step: 5
Training loss: 2.1384806632995605
Validation loss: 2.056802451610565

Epoch: 6| Step: 6
Training loss: 1.7442960739135742
Validation loss: 2.0561842719713845

Epoch: 6| Step: 7
Training loss: 1.434345006942749
Validation loss: 2.0706024169921875

Epoch: 6| Step: 8
Training loss: 2.3839988708496094
Validation loss: 2.044790784517924

Epoch: 6| Step: 9
Training loss: 1.8965383768081665
Validation loss: 2.0479308565457663

Epoch: 6| Step: 10
Training loss: 2.3210716247558594
Validation loss: 2.0739214420318604

Epoch: 6| Step: 11
Training loss: 2.409090518951416
Validation loss: 2.0714999437332153

Epoch: 6| Step: 12
Training loss: 2.456915855407715
Validation loss: 2.073444147904714

Epoch: 6| Step: 13
Training loss: 2.300609827041626
Validation loss: 2.094363351662954

Epoch: 22| Step: 0
Training loss: 1.8971049785614014
Validation loss: 2.075327217578888

Epoch: 6| Step: 1
Training loss: 2.03494930267334
Validation loss: 2.088709314664205

Epoch: 6| Step: 2
Training loss: 1.4048868417739868
Validation loss: 2.0479841232299805

Epoch: 6| Step: 3
Training loss: 1.9082515239715576
Validation loss: 2.0804404417673745

Epoch: 6| Step: 4
Training loss: 1.8504890203475952
Validation loss: 2.0741778214772544

Epoch: 6| Step: 5
Training loss: 1.9895236492156982
Validation loss: 2.0502549608548484

Epoch: 6| Step: 6
Training loss: 1.9808051586151123
Validation loss: 2.069723645846049

Epoch: 6| Step: 7
Training loss: 2.1054441928863525
Validation loss: 2.0458118319511414

Epoch: 6| Step: 8
Training loss: 2.5233078002929688
Validation loss: 2.066953182220459

Epoch: 6| Step: 9
Training loss: 2.3783764839172363
Validation loss: 2.0804556608200073

Epoch: 6| Step: 10
Training loss: 2.166830062866211
Validation loss: 2.063823660214742

Epoch: 6| Step: 11
Training loss: 2.09663987159729
Validation loss: 2.0656472047170005

Epoch: 6| Step: 12
Training loss: 1.5932148694992065
Validation loss: 2.0637965401013694

Epoch: 6| Step: 13
Training loss: 2.4539387226104736
Validation loss: 2.0564048687616983

Epoch: 23| Step: 0
Training loss: 1.3386403322219849
Validation loss: 2.0627710819244385

Epoch: 6| Step: 1
Training loss: 2.509035587310791
Validation loss: 2.0509005387624106

Epoch: 6| Step: 2
Training loss: 2.0585219860076904
Validation loss: 2.0727701584498086

Epoch: 6| Step: 3
Training loss: 2.151871681213379
Validation loss: 2.086289167404175

Epoch: 6| Step: 4
Training loss: 1.956128478050232
Validation loss: 2.0769771138827005

Epoch: 6| Step: 5
Training loss: 1.3158068656921387
Validation loss: 2.072561422983805

Epoch: 6| Step: 6
Training loss: 2.3225059509277344
Validation loss: 2.0509225527445474

Epoch: 6| Step: 7
Training loss: 2.434190034866333
Validation loss: 2.0452147126197815

Epoch: 6| Step: 8
Training loss: 2.2484753131866455
Validation loss: 2.056814511617025

Epoch: 6| Step: 9
Training loss: 1.824450135231018
Validation loss: 2.0735519528388977

Epoch: 6| Step: 10
Training loss: 1.8569729328155518
Validation loss: 2.057517866293589

Epoch: 6| Step: 11
Training loss: 2.0236501693725586
Validation loss: 2.0548956791559854

Epoch: 6| Step: 12
Training loss: 1.5433268547058105
Validation loss: 2.063718100388845

Epoch: 6| Step: 13
Training loss: 2.327716827392578
Validation loss: 2.0539470513661704

Epoch: 24| Step: 0
Training loss: 1.2135915756225586
Validation loss: 2.0886141459147134

Epoch: 6| Step: 1
Training loss: 2.1752471923828125
Validation loss: 2.1110331217447915

Epoch: 6| Step: 2
Training loss: 1.942366123199463
Validation loss: 2.115068038304647

Epoch: 6| Step: 3
Training loss: 2.894418716430664
Validation loss: 2.0964402556419373

Epoch: 6| Step: 4
Training loss: 1.9641852378845215
Validation loss: 2.0775276025136313

Epoch: 6| Step: 5
Training loss: 2.0209193229675293
Validation loss: 2.07620632648468

Epoch: 6| Step: 6
Training loss: 1.8145763874053955
Validation loss: 2.083247105280558

Epoch: 6| Step: 7
Training loss: 2.6297950744628906
Validation loss: 2.051811635494232

Epoch: 6| Step: 8
Training loss: 2.414828300476074
Validation loss: 2.0519729256629944

Epoch: 6| Step: 9
Training loss: 1.3286004066467285
Validation loss: 2.05559370915095

Epoch: 6| Step: 10
Training loss: 2.231869697570801
Validation loss: 2.0465966065724692

Epoch: 6| Step: 11
Training loss: 1.8094254732131958
Validation loss: 2.057103991508484

Epoch: 6| Step: 12
Training loss: 1.7480597496032715
Validation loss: 2.078029672304789

Epoch: 6| Step: 13
Training loss: 2.0261452198028564
Validation loss: 2.0639744798342385

Epoch: 25| Step: 0
Training loss: 1.4038177728652954
Validation loss: 2.0424934029579163

Epoch: 6| Step: 1
Training loss: 1.293637752532959
Validation loss: 2.0545946955680847

Epoch: 6| Step: 2
Training loss: 1.7291271686553955
Validation loss: 2.0610969265302024

Epoch: 6| Step: 3
Training loss: 1.465519666671753
Validation loss: 2.065312663714091

Epoch: 6| Step: 4
Training loss: 1.7134370803833008
Validation loss: 2.077579657236735

Epoch: 6| Step: 5
Training loss: 2.592355251312256
Validation loss: 2.0543278654416404

Epoch: 6| Step: 6
Training loss: 2.045807361602783
Validation loss: 2.0729507207870483

Epoch: 6| Step: 7
Training loss: 1.7278132438659668
Validation loss: 2.083886424700419

Epoch: 6| Step: 8
Training loss: 2.84731388092041
Validation loss: 2.089338739713033

Epoch: 6| Step: 9
Training loss: 2.0860860347747803
Validation loss: 2.096361219882965

Epoch: 6| Step: 10
Training loss: 1.965430498123169
Validation loss: 2.1225059628486633

Epoch: 6| Step: 11
Training loss: 2.7348623275756836
Validation loss: 2.06678436199824

Epoch: 6| Step: 12
Training loss: 2.0871529579162598
Validation loss: 2.0722230275472007

Epoch: 6| Step: 13
Training loss: 2.160088539123535
Validation loss: 2.034915645917257

Epoch: 26| Step: 0
Training loss: 1.9722598791122437
Validation loss: 2.044275641441345

Epoch: 6| Step: 1
Training loss: 2.1357502937316895
Validation loss: 2.0549145142237344

Epoch: 6| Step: 2
Training loss: 1.5178155899047852
Validation loss: 2.0507137775421143

Epoch: 6| Step: 3
Training loss: 1.8509678840637207
Validation loss: 2.03304390112559

Epoch: 6| Step: 4
Training loss: 1.9653661251068115
Validation loss: 2.0559338331222534

Epoch: 6| Step: 5
Training loss: 1.4068351984024048
Validation loss: 2.0570462942123413

Epoch: 6| Step: 6
Training loss: 2.2228879928588867
Validation loss: 2.0388587514559426

Epoch: 6| Step: 7
Training loss: 2.1238300800323486
Validation loss: 2.042233467102051

Epoch: 6| Step: 8
Training loss: 2.4524495601654053
Validation loss: 2.016609251499176

Epoch: 6| Step: 9
Training loss: 1.7741079330444336
Validation loss: 2.0344138741493225

Epoch: 6| Step: 10
Training loss: 2.127356767654419
Validation loss: 2.0338462193806968

Epoch: 6| Step: 11
Training loss: 2.334127187728882
Validation loss: 2.0438935359319053

Epoch: 6| Step: 12
Training loss: 1.8228622674942017
Validation loss: 2.0281271735827127

Epoch: 6| Step: 13
Training loss: 2.3250083923339844
Validation loss: 2.045286317666372

Epoch: 27| Step: 0
Training loss: 2.1869072914123535
Validation loss: 2.044531067212423

Epoch: 6| Step: 1
Training loss: 2.0499534606933594
Validation loss: 2.019481917222341

Epoch: 6| Step: 2
Training loss: 2.550762176513672
Validation loss: 2.053828795750936

Epoch: 6| Step: 3
Training loss: 1.35087251663208
Validation loss: 2.0342020193735757

Epoch: 6| Step: 4
Training loss: 2.200040102005005
Validation loss: 2.0506173968315125

Epoch: 6| Step: 5
Training loss: 1.8807058334350586
Validation loss: 2.0288668076197305

Epoch: 6| Step: 6
Training loss: 1.6744844913482666
Validation loss: 2.0662171641985574

Epoch: 6| Step: 7
Training loss: 1.638814926147461
Validation loss: 2.076923966407776

Epoch: 6| Step: 8
Training loss: 2.325801134109497
Validation loss: 2.0608908931414285

Epoch: 6| Step: 9
Training loss: 1.1822028160095215
Validation loss: 2.050238092740377

Epoch: 6| Step: 10
Training loss: 2.236279010772705
Validation loss: 2.0917252898216248

Epoch: 6| Step: 11
Training loss: 2.0560660362243652
Validation loss: 2.0802719791730246

Epoch: 6| Step: 12
Training loss: 1.808059573173523
Validation loss: 2.069400211175283

Epoch: 6| Step: 13
Training loss: 2.5086348056793213
Validation loss: 2.0559584697087607

Epoch: 28| Step: 0
Training loss: 2.031155824661255
Validation loss: 2.0857251485188804

Epoch: 6| Step: 1
Training loss: 1.911232829093933
Validation loss: 2.0596919655799866

Epoch: 6| Step: 2
Training loss: 1.683674931526184
Validation loss: 2.049919287363688

Epoch: 6| Step: 3
Training loss: 2.2102913856506348
Validation loss: 2.0407217144966125

Epoch: 6| Step: 4
Training loss: 2.174844264984131
Validation loss: 2.0405581990877786

Epoch: 6| Step: 5
Training loss: 2.5763018131256104
Validation loss: 2.0522143642107644

Epoch: 6| Step: 6
Training loss: 1.67289137840271
Validation loss: 2.066695988178253

Epoch: 6| Step: 7
Training loss: 1.8602744340896606
Validation loss: 2.0516992807388306

Epoch: 6| Step: 8
Training loss: 1.5156505107879639
Validation loss: 2.0400827527046204

Epoch: 6| Step: 9
Training loss: 2.3794476985931396
Validation loss: 2.0467034777005515

Epoch: 6| Step: 10
Training loss: 1.4554367065429688
Validation loss: 2.026311933994293

Epoch: 6| Step: 11
Training loss: 2.0914926528930664
Validation loss: 2.0347134470939636

Epoch: 6| Step: 12
Training loss: 2.3086676597595215
Validation loss: 2.041420022646586

Epoch: 6| Step: 13
Training loss: 1.707824945449829
Validation loss: 2.0459158023198447

Epoch: 29| Step: 0
Training loss: 1.600881814956665
Validation loss: 2.0347655415534973

Epoch: 6| Step: 1
Training loss: 2.194870710372925
Validation loss: 2.0398916800816855

Epoch: 6| Step: 2
Training loss: 1.9272091388702393
Validation loss: 2.0466084480285645

Epoch: 6| Step: 3
Training loss: 1.8287004232406616
Validation loss: 2.0593645373980203

Epoch: 6| Step: 4
Training loss: 1.8955830335617065
Validation loss: 2.0621909499168396

Epoch: 6| Step: 5
Training loss: 1.9584109783172607
Validation loss: 2.031221111615499

Epoch: 6| Step: 6
Training loss: 2.1656572818756104
Validation loss: 2.0578724344571433

Epoch: 6| Step: 7
Training loss: 2.171923875808716
Validation loss: 2.038273791472117

Epoch: 6| Step: 8
Training loss: 1.3694170713424683
Validation loss: 2.0458699663480124

Epoch: 6| Step: 9
Training loss: 3.0058748722076416
Validation loss: 2.0463637709617615

Epoch: 6| Step: 10
Training loss: 2.108156681060791
Validation loss: 2.0297714471817017

Epoch: 6| Step: 11
Training loss: 1.7129675149917603
Validation loss: 2.0544433991114297

Epoch: 6| Step: 12
Training loss: 1.602913737297058
Validation loss: 2.039732058842977

Epoch: 6| Step: 13
Training loss: 1.9343615770339966
Validation loss: 2.038507103919983

Epoch: 30| Step: 0
Training loss: 2.323194980621338
Validation loss: 2.057285745938619

Epoch: 6| Step: 1
Training loss: 2.4726152420043945
Validation loss: 2.035966177781423

Epoch: 6| Step: 2
Training loss: 1.8899259567260742
Validation loss: 2.0777408679326377

Epoch: 6| Step: 3
Training loss: 1.896237850189209
Validation loss: 2.0551147063573203

Epoch: 6| Step: 4
Training loss: 1.771719217300415
Validation loss: 2.0676747957865396

Epoch: 6| Step: 5
Training loss: 2.231497049331665
Validation loss: 2.0779972076416016

Epoch: 6| Step: 6
Training loss: 1.7901289463043213
Validation loss: 2.0690114895502725

Epoch: 6| Step: 7
Training loss: 1.7531826496124268
Validation loss: 2.088091492652893

Epoch: 6| Step: 8
Training loss: 1.9183988571166992
Validation loss: 2.106207489967346

Epoch: 6| Step: 9
Training loss: 2.819119453430176
Validation loss: 2.0536742011706033

Epoch: 6| Step: 10
Training loss: 1.0624210834503174
Validation loss: 2.0476513504981995

Epoch: 6| Step: 11
Training loss: 1.5069278478622437
Validation loss: 2.0623270074526467

Epoch: 6| Step: 12
Training loss: 1.8946864604949951
Validation loss: 2.026911477247874

Epoch: 6| Step: 13
Training loss: 2.2677206993103027
Validation loss: 2.0475178956985474

Epoch: 31| Step: 0
Training loss: 1.7757930755615234
Validation loss: 2.0289844075838723

Epoch: 6| Step: 1
Training loss: 2.1260321140289307
Validation loss: 2.0201945106188455

Epoch: 6| Step: 2
Training loss: 1.7273108959197998
Validation loss: 2.0189767281214395

Epoch: 6| Step: 3
Training loss: 1.3993287086486816
Validation loss: 2.00351889928182

Epoch: 6| Step: 4
Training loss: 1.983705997467041
Validation loss: 2.0236935019493103

Epoch: 6| Step: 5
Training loss: 2.5054614543914795
Validation loss: 2.022248844305674

Epoch: 6| Step: 6
Training loss: 2.126556158065796
Validation loss: 2.0711193084716797

Epoch: 6| Step: 7
Training loss: 2.016400098800659
Validation loss: 2.092534919579824

Epoch: 6| Step: 8
Training loss: 1.6851797103881836
Validation loss: 2.0967849691708884

Epoch: 6| Step: 9
Training loss: 2.303231716156006
Validation loss: 2.044801394144694

Epoch: 6| Step: 10
Training loss: 2.363175868988037
Validation loss: 2.050571839014689

Epoch: 6| Step: 11
Training loss: 1.580274224281311
Validation loss: 2.0335028767585754

Epoch: 6| Step: 12
Training loss: 2.144815683364868
Validation loss: 2.0304102698961892

Epoch: 6| Step: 13
Training loss: 2.2786314487457275
Validation loss: 2.0364028016726174

Epoch: 32| Step: 0
Training loss: 1.663513422012329
Validation loss: 2.0216911832491555

Epoch: 6| Step: 1
Training loss: 2.302633047103882
Validation loss: 2.0461267034212747

Epoch: 6| Step: 2
Training loss: 2.5226898193359375
Validation loss: 2.033290982246399

Epoch: 6| Step: 3
Training loss: 1.5356148481369019
Validation loss: 2.02388995885849

Epoch: 6| Step: 4
Training loss: 2.739776134490967
Validation loss: 2.0472916960716248

Epoch: 6| Step: 5
Training loss: 2.3878331184387207
Validation loss: 2.0387379924456277

Epoch: 6| Step: 6
Training loss: 1.8820738792419434
Validation loss: 2.0520652333895364

Epoch: 6| Step: 7
Training loss: 2.0093307495117188
Validation loss: 2.0411638816197715

Epoch: 6| Step: 8
Training loss: 1.6197268962860107
Validation loss: 2.0497265656789145

Epoch: 6| Step: 9
Training loss: 1.7668330669403076
Validation loss: 2.037199020385742

Epoch: 6| Step: 10
Training loss: 1.046407699584961
Validation loss: 2.0384631752967834

Epoch: 6| Step: 11
Training loss: 1.5688979625701904
Validation loss: 2.035584886868795

Epoch: 6| Step: 12
Training loss: 2.654860734939575
Validation loss: 2.035477856794993

Epoch: 6| Step: 13
Training loss: 1.5886316299438477
Validation loss: 2.0504736502965293

Epoch: 33| Step: 0
Training loss: 1.6648942232131958
Validation loss: 2.0227646231651306

Epoch: 6| Step: 1
Training loss: 1.729508876800537
Validation loss: 2.040642778078715

Epoch: 6| Step: 2
Training loss: 2.431248664855957
Validation loss: 2.0323017636934915

Epoch: 6| Step: 3
Training loss: 1.7668817043304443
Validation loss: 2.0552597641944885

Epoch: 6| Step: 4
Training loss: 1.6488208770751953
Validation loss: 2.0402570962905884

Epoch: 6| Step: 5
Training loss: 2.08052396774292
Validation loss: 2.03645267089208

Epoch: 6| Step: 6
Training loss: 1.6392064094543457
Validation loss: 2.0584702690442405

Epoch: 6| Step: 7
Training loss: 1.7069802284240723
Validation loss: 2.0277056296666465

Epoch: 6| Step: 8
Training loss: 2.083465814590454
Validation loss: 2.0251267353693643

Epoch: 6| Step: 9
Training loss: 2.125178098678589
Validation loss: 2.0324355562527976

Epoch: 6| Step: 10
Training loss: 2.287510633468628
Validation loss: 2.0634004871050515

Epoch: 6| Step: 11
Training loss: 2.293180465698242
Validation loss: 2.026653607686361

Epoch: 6| Step: 12
Training loss: 2.347079277038574
Validation loss: 2.0287670493125916

Epoch: 6| Step: 13
Training loss: 1.7736537456512451
Validation loss: 2.0461002786954245

Epoch: 34| Step: 0
Training loss: 2.147158145904541
Validation loss: 2.044627010822296

Epoch: 6| Step: 1
Training loss: 1.6923120021820068
Validation loss: 2.061945597330729

Epoch: 6| Step: 2
Training loss: 1.6700820922851562
Validation loss: 2.0630695621172586

Epoch: 6| Step: 3
Training loss: 2.5126757621765137
Validation loss: 2.031344254811605

Epoch: 6| Step: 4
Training loss: 1.3121311664581299
Validation loss: 2.044068435827891

Epoch: 6| Step: 5
Training loss: 1.6888319253921509
Validation loss: 2.035198231538137

Epoch: 6| Step: 6
Training loss: 1.9071171283721924
Validation loss: 2.039692302544912

Epoch: 6| Step: 7
Training loss: 2.0618629455566406
Validation loss: 2.0318697690963745

Epoch: 6| Step: 8
Training loss: 2.296320915222168
Validation loss: 2.049661656220754

Epoch: 6| Step: 9
Training loss: 2.298008918762207
Validation loss: 2.0387088457743325

Epoch: 6| Step: 10
Training loss: 2.169674873352051
Validation loss: 2.0519198179244995

Epoch: 6| Step: 11
Training loss: 1.2347121238708496
Validation loss: 2.0372742414474487

Epoch: 6| Step: 12
Training loss: 2.075833797454834
Validation loss: 2.025902291138967

Epoch: 6| Step: 13
Training loss: 2.515091896057129
Validation loss: 2.037409166495005

Epoch: 35| Step: 0
Training loss: 1.7525825500488281
Validation loss: 2.06654155254364

Epoch: 6| Step: 1
Training loss: 1.7998265027999878
Validation loss: 2.025060017903646

Epoch: 6| Step: 2
Training loss: 1.847097635269165
Validation loss: 2.025369147459666

Epoch: 6| Step: 3
Training loss: 2.0436370372772217
Validation loss: 2.042290369669596

Epoch: 6| Step: 4
Training loss: 2.0431437492370605
Validation loss: 2.0221469402313232

Epoch: 6| Step: 5
Training loss: 2.2223877906799316
Validation loss: 2.02932345867157

Epoch: 6| Step: 6
Training loss: 2.1166560649871826
Validation loss: 2.025874118010203

Epoch: 6| Step: 7
Training loss: 2.034929037094116
Validation loss: 2.0317183335622153

Epoch: 6| Step: 8
Training loss: 2.477214813232422
Validation loss: 2.0342392524083457

Epoch: 6| Step: 9
Training loss: 1.5263314247131348
Validation loss: 2.0411579608917236

Epoch: 6| Step: 10
Training loss: 2.096808910369873
Validation loss: 2.023999551932017

Epoch: 6| Step: 11
Training loss: 2.2763168811798096
Validation loss: 2.03760435183843

Epoch: 6| Step: 12
Training loss: 1.506483554840088
Validation loss: 2.0242690245310464

Epoch: 6| Step: 13
Training loss: 2.0317769050598145
Validation loss: 2.0221156080563865

Epoch: 36| Step: 0
Training loss: 1.727240800857544
Validation loss: 2.0474791129430137

Epoch: 6| Step: 1
Training loss: 1.7381749153137207
Validation loss: 2.0333810249964395

Epoch: 6| Step: 2
Training loss: 1.766677975654602
Validation loss: 2.049069027105967

Epoch: 6| Step: 3
Training loss: 2.300518035888672
Validation loss: 2.0759243965148926

Epoch: 6| Step: 4
Training loss: 2.2203750610351562
Validation loss: 2.0743083159128823

Epoch: 6| Step: 5
Training loss: 1.8698174953460693
Validation loss: 2.1012962261835733

Epoch: 6| Step: 6
Training loss: 2.2292089462280273
Validation loss: 2.0927830735842385

Epoch: 6| Step: 7
Training loss: 2.268918037414551
Validation loss: 2.1056849161783853

Epoch: 6| Step: 8
Training loss: 1.8545217514038086
Validation loss: 2.140734533468882

Epoch: 6| Step: 9
Training loss: 1.6887420415878296
Validation loss: 2.097530424594879

Epoch: 6| Step: 10
Training loss: 1.6843184232711792
Validation loss: 2.091406504313151

Epoch: 6| Step: 11
Training loss: 1.994671106338501
Validation loss: 2.0861969590187073

Epoch: 6| Step: 12
Training loss: 1.6308300495147705
Validation loss: 2.0522122979164124

Epoch: 6| Step: 13
Training loss: 2.471693277359009
Validation loss: 2.047084550062815

Epoch: 37| Step: 0
Training loss: 1.6152359247207642
Validation loss: 2.0147945284843445

Epoch: 6| Step: 1
Training loss: 1.9171195030212402
Validation loss: 2.0356751481691995

Epoch: 6| Step: 2
Training loss: 2.022197723388672
Validation loss: 2.0538308024406433

Epoch: 6| Step: 3
Training loss: 2.3693559169769287
Validation loss: 2.046772837638855

Epoch: 6| Step: 4
Training loss: 1.818601369857788
Validation loss: 2.03040877978007

Epoch: 6| Step: 5
Training loss: 2.0989298820495605
Validation loss: 2.034684975941976

Epoch: 6| Step: 6
Training loss: 2.0677499771118164
Validation loss: 2.035620709260305

Epoch: 6| Step: 7
Training loss: 2.7572684288024902
Validation loss: 2.0168727238972983

Epoch: 6| Step: 8
Training loss: 1.4334594011306763
Validation loss: 2.0258758068084717

Epoch: 6| Step: 9
Training loss: 2.2382266521453857
Validation loss: 2.0263400872548423

Epoch: 6| Step: 10
Training loss: 1.8912044763565063
Validation loss: 2.033694585164388

Epoch: 6| Step: 11
Training loss: 1.8919217586517334
Validation loss: 2.0319311022758484

Epoch: 6| Step: 12
Training loss: 1.8030039072036743
Validation loss: 2.0252110958099365

Epoch: 6| Step: 13
Training loss: 1.2336616516113281
Validation loss: 2.032639722029368

Epoch: 38| Step: 0
Training loss: 1.957960844039917
Validation loss: 2.043389896551768

Epoch: 6| Step: 1
Training loss: 2.4024033546447754
Validation loss: 2.0327131946881614

Epoch: 6| Step: 2
Training loss: 1.3802273273468018
Validation loss: 2.014409065246582

Epoch: 6| Step: 3
Training loss: 1.8530924320220947
Validation loss: 2.0323853890101113

Epoch: 6| Step: 4
Training loss: 2.067668914794922
Validation loss: 2.042867382367452

Epoch: 6| Step: 5
Training loss: 1.8711875677108765
Validation loss: 2.0316802660624185

Epoch: 6| Step: 6
Training loss: 1.949560523033142
Validation loss: 2.059447010358175

Epoch: 6| Step: 7
Training loss: 2.3273990154266357
Validation loss: 2.0291574796040854

Epoch: 6| Step: 8
Training loss: 1.8046079874038696
Validation loss: 2.0195956428845725

Epoch: 6| Step: 9
Training loss: 1.7988080978393555
Validation loss: 2.0506190856297812

Epoch: 6| Step: 10
Training loss: 2.1690220832824707
Validation loss: 2.0273025830586753

Epoch: 6| Step: 11
Training loss: 1.2280292510986328
Validation loss: 2.0426836013793945

Epoch: 6| Step: 12
Training loss: 2.470187187194824
Validation loss: 2.024636705716451

Epoch: 6| Step: 13
Training loss: 1.99092698097229
Validation loss: 2.020061413447062

Epoch: 39| Step: 0
Training loss: 1.442443609237671
Validation loss: 2.051517128944397

Epoch: 6| Step: 1
Training loss: 1.6529279947280884
Validation loss: 2.0316342314084372

Epoch: 6| Step: 2
Training loss: 2.687185049057007
Validation loss: 2.04178778330485

Epoch: 6| Step: 3
Training loss: 1.9878219366073608
Validation loss: 2.028728405634562

Epoch: 6| Step: 4
Training loss: 1.7263695001602173
Validation loss: 2.0658000707626343

Epoch: 6| Step: 5
Training loss: 2.0179436206817627
Validation loss: 2.057684858640035

Epoch: 6| Step: 6
Training loss: 1.8883166313171387
Validation loss: 2.064200758934021

Epoch: 6| Step: 7
Training loss: 1.5265896320343018
Validation loss: 2.0290483832359314

Epoch: 6| Step: 8
Training loss: 2.6189582347869873
Validation loss: 2.0575501720110574

Epoch: 6| Step: 9
Training loss: 1.6385618448257446
Validation loss: 2.0147830049196878

Epoch: 6| Step: 10
Training loss: 2.211068630218506
Validation loss: 2.0359474420547485

Epoch: 6| Step: 11
Training loss: 1.451873540878296
Validation loss: 2.0319278240203857

Epoch: 6| Step: 12
Training loss: 2.037686824798584
Validation loss: 2.045526146888733

Epoch: 6| Step: 13
Training loss: 2.2297298908233643
Validation loss: 2.014982263247172

Epoch: 40| Step: 0
Training loss: 1.9212380647659302
Validation loss: 2.0246962110201516

Epoch: 6| Step: 1
Training loss: 1.8086700439453125
Validation loss: 2.0472307006518045

Epoch: 6| Step: 2
Training loss: 2.1689507961273193
Validation loss: 2.0439868569374084

Epoch: 6| Step: 3
Training loss: 1.5685285329818726
Validation loss: 2.036395172278086

Epoch: 6| Step: 4
Training loss: 1.1605722904205322
Validation loss: 2.019440253575643

Epoch: 6| Step: 5
Training loss: 2.3012804985046387
Validation loss: 2.04367858171463

Epoch: 6| Step: 6
Training loss: 2.6452765464782715
Validation loss: 2.0495166579882302

Epoch: 6| Step: 7
Training loss: 1.7974660396575928
Validation loss: 2.0779546896616616

Epoch: 6| Step: 8
Training loss: 2.3253936767578125
Validation loss: 2.037076155344645

Epoch: 6| Step: 9
Training loss: 2.122342348098755
Validation loss: 2.0610166788101196

Epoch: 6| Step: 10
Training loss: 1.5309596061706543
Validation loss: 2.0513731638590493

Epoch: 6| Step: 11
Training loss: 2.279298782348633
Validation loss: 2.053143858909607

Epoch: 6| Step: 12
Training loss: 2.0232861042022705
Validation loss: 2.0264004667599997

Epoch: 6| Step: 13
Training loss: 1.329863429069519
Validation loss: 2.037712315718333

Epoch: 41| Step: 0
Training loss: 1.789322018623352
Validation loss: 2.036204000314077

Epoch: 6| Step: 1
Training loss: 1.7935742139816284
Validation loss: 1.9908705949783325

Epoch: 6| Step: 2
Training loss: 1.634202480316162
Validation loss: 2.0213076074918113

Epoch: 6| Step: 3
Training loss: 2.2996699810028076
Validation loss: 2.0161070426305137

Epoch: 6| Step: 4
Training loss: 2.2286128997802734
Validation loss: 2.026192088921865

Epoch: 6| Step: 5
Training loss: 1.9099427461624146
Validation loss: 2.025829017162323

Epoch: 6| Step: 6
Training loss: 1.2824081182479858
Validation loss: 2.0418012936909995

Epoch: 6| Step: 7
Training loss: 1.8183646202087402
Validation loss: 2.026302138964335

Epoch: 6| Step: 8
Training loss: 1.8542348146438599
Validation loss: 2.0407222906748452

Epoch: 6| Step: 9
Training loss: 1.965367317199707
Validation loss: 2.033068140347799

Epoch: 6| Step: 10
Training loss: 2.009413480758667
Validation loss: 2.03661439816157

Epoch: 6| Step: 11
Training loss: 1.9708740711212158
Validation loss: 2.0543831984202066

Epoch: 6| Step: 12
Training loss: 2.274916172027588
Validation loss: 2.066498041152954

Epoch: 6| Step: 13
Training loss: 2.3905258178710938
Validation loss: 2.0440165400505066

Epoch: 42| Step: 0
Training loss: 1.326601505279541
Validation loss: 2.038681745529175

Epoch: 6| Step: 1
Training loss: 1.6506651639938354
Validation loss: 2.0322450200716653

Epoch: 6| Step: 2
Training loss: 2.1002588272094727
Validation loss: 2.0539231101671853

Epoch: 6| Step: 3
Training loss: 2.0460710525512695
Validation loss: 2.024911562601725

Epoch: 6| Step: 4
Training loss: 1.7986706495285034
Validation loss: 2.044862767060598

Epoch: 6| Step: 5
Training loss: 1.9758497476577759
Validation loss: 2.053449034690857

Epoch: 6| Step: 6
Training loss: 1.75492262840271
Validation loss: 2.0393349130948386

Epoch: 6| Step: 7
Training loss: 1.8950238227844238
Validation loss: 2.0352102716763816

Epoch: 6| Step: 8
Training loss: 2.3056416511535645
Validation loss: 2.0558378100395203

Epoch: 6| Step: 9
Training loss: 2.438277244567871
Validation loss: 2.0596529642740884

Epoch: 6| Step: 10
Training loss: 1.7629536390304565
Validation loss: 2.053966244061788

Epoch: 6| Step: 11
Training loss: 2.6611900329589844
Validation loss: 2.0305039485295615

Epoch: 6| Step: 12
Training loss: 1.3004839420318604
Validation loss: 2.0379685362180076

Epoch: 6| Step: 13
Training loss: 1.7222654819488525
Validation loss: 2.0457271337509155

Epoch: 43| Step: 0
Training loss: 2.0910449028015137
Validation loss: 2.037893990675608

Epoch: 6| Step: 1
Training loss: 2.203706979751587
Validation loss: 2.0216336846351624

Epoch: 6| Step: 2
Training loss: 1.9511089324951172
Validation loss: 2.0220230420430503

Epoch: 6| Step: 3
Training loss: 1.9672702550888062
Validation loss: 2.015838921070099

Epoch: 6| Step: 4
Training loss: 1.544743537902832
Validation loss: 2.038546323776245

Epoch: 6| Step: 5
Training loss: 2.3531785011291504
Validation loss: 2.0207097133000693

Epoch: 6| Step: 6
Training loss: 2.137721061706543
Validation loss: 2.0236356258392334

Epoch: 6| Step: 7
Training loss: 1.4659066200256348
Validation loss: 2.0218583146731057

Epoch: 6| Step: 8
Training loss: 1.9873578548431396
Validation loss: 2.0141409635543823

Epoch: 6| Step: 9
Training loss: 2.4132165908813477
Validation loss: 2.025724152723948

Epoch: 6| Step: 10
Training loss: 1.8033219575881958
Validation loss: 2.025638520717621

Epoch: 6| Step: 11
Training loss: 1.7416876554489136
Validation loss: 2.0096129377683005

Epoch: 6| Step: 12
Training loss: 1.7719441652297974
Validation loss: 2.04306823015213

Epoch: 6| Step: 13
Training loss: 1.597710371017456
Validation loss: 2.0479804277420044

Epoch: 44| Step: 0
Training loss: 1.3059866428375244
Validation loss: 2.0389643907546997

Epoch: 6| Step: 1
Training loss: 1.6542153358459473
Validation loss: 2.104514797528585

Epoch: 6| Step: 2
Training loss: 1.8442959785461426
Validation loss: 2.0952171683311462

Epoch: 6| Step: 3
Training loss: 1.809020757675171
Validation loss: 2.121264855066935

Epoch: 6| Step: 4
Training loss: 2.3937201499938965
Validation loss: 2.119371175765991

Epoch: 6| Step: 5
Training loss: 2.116328239440918
Validation loss: 2.1464592615763345

Epoch: 6| Step: 6
Training loss: 2.281751871109009
Validation loss: 2.149951179822286

Epoch: 6| Step: 7
Training loss: 2.193408966064453
Validation loss: 2.1365853349367776

Epoch: 6| Step: 8
Training loss: 1.979000449180603
Validation loss: 2.1040754318237305

Epoch: 6| Step: 9
Training loss: 1.7414594888687134
Validation loss: 2.076455851395925

Epoch: 6| Step: 10
Training loss: 2.2569050788879395
Validation loss: 2.0660261710484824

Epoch: 6| Step: 11
Training loss: 1.7594046592712402
Validation loss: 2.049302061398824

Epoch: 6| Step: 12
Training loss: 1.861478328704834
Validation loss: 2.0342470606168113

Epoch: 6| Step: 13
Training loss: 2.235826015472412
Validation loss: 2.0285200079282126

Epoch: 45| Step: 0
Training loss: 1.5708796977996826
Validation loss: 2.0364639163017273

Epoch: 6| Step: 1
Training loss: 1.8586091995239258
Validation loss: 2.0198668837547302

Epoch: 6| Step: 2
Training loss: 1.9777201414108276
Validation loss: 2.035004119078318

Epoch: 6| Step: 3
Training loss: 2.227062463760376
Validation loss: 2.0501551826794944

Epoch: 6| Step: 4
Training loss: 1.7269469499588013
Validation loss: 2.0389294028282166

Epoch: 6| Step: 5
Training loss: 1.669334888458252
Validation loss: 2.0293792883555093

Epoch: 6| Step: 6
Training loss: 2.8622961044311523
Validation loss: 2.0336199204126992

Epoch: 6| Step: 7
Training loss: 1.5885319709777832
Validation loss: 1.9950305223464966

Epoch: 6| Step: 8
Training loss: 1.1858210563659668
Validation loss: 2.0267420212427774

Epoch: 6| Step: 9
Training loss: 2.182539939880371
Validation loss: 2.0315948724746704

Epoch: 6| Step: 10
Training loss: 1.6385560035705566
Validation loss: 2.041457196076711

Epoch: 6| Step: 11
Training loss: 2.2507987022399902
Validation loss: 2.025056620438894

Epoch: 6| Step: 12
Training loss: 2.4497947692871094
Validation loss: 2.059590458869934

Epoch: 6| Step: 13
Training loss: 2.2786619663238525
Validation loss: 2.033835232257843

Epoch: 46| Step: 0
Training loss: 2.0397300720214844
Validation loss: 2.0706329147020974

Epoch: 6| Step: 1
Training loss: 1.637838363647461
Validation loss: 2.069990615049998

Epoch: 6| Step: 2
Training loss: 1.8952131271362305
Validation loss: 2.0684099594751992

Epoch: 6| Step: 3
Training loss: 2.0013699531555176
Validation loss: 2.0662065943082175

Epoch: 6| Step: 4
Training loss: 2.4271583557128906
Validation loss: 2.0869267185529075

Epoch: 6| Step: 5
Training loss: 1.4312338829040527
Validation loss: 2.0658040245374045

Epoch: 6| Step: 6
Training loss: 1.460059404373169
Validation loss: 2.037674864133199

Epoch: 6| Step: 7
Training loss: 2.284740447998047
Validation loss: 2.085419853528341

Epoch: 6| Step: 8
Training loss: 1.4528546333312988
Validation loss: 2.0820847352345786

Epoch: 6| Step: 9
Training loss: 2.5026302337646484
Validation loss: 2.0445443391799927

Epoch: 6| Step: 10
Training loss: 1.9744980335235596
Validation loss: 2.033014496167501

Epoch: 6| Step: 11
Training loss: 1.8916847705841064
Validation loss: 2.0375441710154214

Epoch: 6| Step: 12
Training loss: 1.5616929531097412
Validation loss: 2.0299024184544883

Epoch: 6| Step: 13
Training loss: 1.914006233215332
Validation loss: 2.044236938158671

Epoch: 47| Step: 0
Training loss: 1.7174478769302368
Validation loss: 2.027537445227305

Epoch: 6| Step: 1
Training loss: 1.8232108354568481
Validation loss: 2.0082852641741433

Epoch: 6| Step: 2
Training loss: 1.4343267679214478
Validation loss: 2.019591470559438

Epoch: 6| Step: 3
Training loss: 1.8133647441864014
Validation loss: 2.016396979490916

Epoch: 6| Step: 4
Training loss: 2.020720958709717
Validation loss: 2.023016075293223

Epoch: 6| Step: 5
Training loss: 1.8138103485107422
Validation loss: 2.030887941519419

Epoch: 6| Step: 6
Training loss: 1.8036538362503052
Validation loss: 2.034542183081309

Epoch: 6| Step: 7
Training loss: 2.717799663543701
Validation loss: 1.98939710855484

Epoch: 6| Step: 8
Training loss: 2.2142913341522217
Validation loss: 2.014896015326182

Epoch: 6| Step: 9
Training loss: 2.0186684131622314
Validation loss: 2.0334956844647727

Epoch: 6| Step: 10
Training loss: 2.030971050262451
Validation loss: 2.007997373739878

Epoch: 6| Step: 11
Training loss: 1.870293140411377
Validation loss: 2.016225496927897

Epoch: 6| Step: 12
Training loss: 2.1285109519958496
Validation loss: 2.0189327398935952

Epoch: 6| Step: 13
Training loss: 1.5996500253677368
Validation loss: 2.015228748321533

Epoch: 48| Step: 0
Training loss: 2.1378285884857178
Validation loss: 2.0137513875961304

Epoch: 6| Step: 1
Training loss: 1.6747891902923584
Validation loss: 2.0095037817955017

Epoch: 6| Step: 2
Training loss: 2.133533000946045
Validation loss: 2.0621517499287925

Epoch: 6| Step: 3
Training loss: 2.050978660583496
Validation loss: 2.02342281738917

Epoch: 6| Step: 4
Training loss: 2.1546545028686523
Validation loss: 2.051476220289866

Epoch: 6| Step: 5
Training loss: 1.7016346454620361
Validation loss: 2.0595749616622925

Epoch: 6| Step: 6
Training loss: 1.8516614437103271
Validation loss: 2.0640044609705606

Epoch: 6| Step: 7
Training loss: 2.5295662879943848
Validation loss: 2.1122615536053977

Epoch: 6| Step: 8
Training loss: 1.1433417797088623
Validation loss: 2.0787318547566733

Epoch: 6| Step: 9
Training loss: 1.4758415222167969
Validation loss: 2.0762223402659097

Epoch: 6| Step: 10
Training loss: 2.2559661865234375
Validation loss: 2.0812209049860635

Epoch: 6| Step: 11
Training loss: 1.5455390214920044
Validation loss: 2.050944129625956

Epoch: 6| Step: 12
Training loss: 2.667937994003296
Validation loss: 2.0355032881100974

Epoch: 6| Step: 13
Training loss: 1.30430269241333
Validation loss: 1.9953368306159973

Epoch: 49| Step: 0
Training loss: 2.4794650077819824
Validation loss: 2.0044111410776773

Epoch: 6| Step: 1
Training loss: 1.621649146080017
Validation loss: 1.9982439676920574

Epoch: 6| Step: 2
Training loss: 1.4258263111114502
Validation loss: 2.0290573636690774

Epoch: 6| Step: 3
Training loss: 2.1757335662841797
Validation loss: 2.0082944432894387

Epoch: 6| Step: 4
Training loss: 1.5798332691192627
Validation loss: 2.0236180623372397

Epoch: 6| Step: 5
Training loss: 1.9699621200561523
Validation loss: 2.0151489774386087

Epoch: 6| Step: 6
Training loss: 1.9434771537780762
Validation loss: 2.0053202509880066

Epoch: 6| Step: 7
Training loss: 2.041090726852417
Validation loss: 2.0040169954299927

Epoch: 6| Step: 8
Training loss: 1.900048851966858
Validation loss: 2.0348582665125527

Epoch: 6| Step: 9
Training loss: 2.5595388412475586
Validation loss: 2.019883453845978

Epoch: 6| Step: 10
Training loss: 1.8244521617889404
Validation loss: 2.0276170571645102

Epoch: 6| Step: 11
Training loss: 1.4918689727783203
Validation loss: 2.0381550987561545

Epoch: 6| Step: 12
Training loss: 2.1235227584838867
Validation loss: 2.026308317979177

Epoch: 6| Step: 13
Training loss: 1.4896007776260376
Validation loss: 2.0123159686724343

Epoch: 50| Step: 0
Training loss: 1.639398217201233
Validation loss: 2.02714071671168

Epoch: 6| Step: 1
Training loss: 2.3809750080108643
Validation loss: 2.0408628980318704

Epoch: 6| Step: 2
Training loss: 1.5342925786972046
Validation loss: 2.0582927068074546

Epoch: 6| Step: 3
Training loss: 2.1325416564941406
Validation loss: 2.065760691960653

Epoch: 6| Step: 4
Training loss: 1.7813459634780884
Validation loss: 2.02451099952062

Epoch: 6| Step: 5
Training loss: 2.779633045196533
Validation loss: 2.0551632046699524

Epoch: 6| Step: 6
Training loss: 1.235490322113037
Validation loss: 2.0360535979270935

Epoch: 6| Step: 7
Training loss: 1.8824024200439453
Validation loss: 2.040099104245504

Epoch: 6| Step: 8
Training loss: 1.8618628978729248
Validation loss: 2.04009340206782

Epoch: 6| Step: 9
Training loss: 1.8019050359725952
Validation loss: 2.015184779961904

Epoch: 6| Step: 10
Training loss: 2.4031362533569336
Validation loss: 2.0272536079088845

Epoch: 6| Step: 11
Training loss: 1.6442608833312988
Validation loss: 2.0334686040878296

Epoch: 6| Step: 12
Training loss: 1.7128806114196777
Validation loss: 2.032704253991445

Epoch: 6| Step: 13
Training loss: 1.7980377674102783
Validation loss: 2.0255615512530007

Epoch: 51| Step: 0
Training loss: 2.0295748710632324
Validation loss: 2.0451120336850486

Epoch: 6| Step: 1
Training loss: 1.6292939186096191
Validation loss: 2.0417287349700928

Epoch: 6| Step: 2
Training loss: 1.8437306880950928
Validation loss: 2.04098904132843

Epoch: 6| Step: 3
Training loss: 1.3544209003448486
Validation loss: 2.058468818664551

Epoch: 6| Step: 4
Training loss: 1.8357454538345337
Validation loss: 2.0321206053098044

Epoch: 6| Step: 5
Training loss: 1.995756983757019
Validation loss: 2.041120409965515

Epoch: 6| Step: 6
Training loss: 1.8038302659988403
Validation loss: 2.0075513124465942

Epoch: 6| Step: 7
Training loss: 1.6894958019256592
Validation loss: 2.0591883063316345

Epoch: 6| Step: 8
Training loss: 2.192492961883545
Validation loss: 2.0163190166155496

Epoch: 6| Step: 9
Training loss: 2.0668997764587402
Validation loss: 2.0273221731185913

Epoch: 6| Step: 10
Training loss: 2.0364646911621094
Validation loss: 2.067217985788981

Epoch: 6| Step: 11
Training loss: 1.994950532913208
Validation loss: 2.0248416860898337

Epoch: 6| Step: 12
Training loss: 1.933597207069397
Validation loss: 2.033692399660746

Epoch: 6| Step: 13
Training loss: 1.934928059577942
Validation loss: 2.0295668244361877

Epoch: 52| Step: 0
Training loss: 2.209339141845703
Validation loss: 2.031670033931732

Epoch: 6| Step: 1
Training loss: 1.688859462738037
Validation loss: 2.022764205932617

Epoch: 6| Step: 2
Training loss: 1.5843250751495361
Validation loss: 2.0193941593170166

Epoch: 6| Step: 3
Training loss: 2.529599905014038
Validation loss: 2.0298147201538086

Epoch: 6| Step: 4
Training loss: 1.870724081993103
Validation loss: 2.0237178007761636

Epoch: 6| Step: 5
Training loss: 1.8380482196807861
Validation loss: 2.035285770893097

Epoch: 6| Step: 6
Training loss: 1.5390123128890991
Validation loss: 2.026251951853434

Epoch: 6| Step: 7
Training loss: 1.588639736175537
Validation loss: 2.0547154545783997

Epoch: 6| Step: 8
Training loss: 2.396674633026123
Validation loss: 2.076431612173716

Epoch: 6| Step: 9
Training loss: 1.9390451908111572
Validation loss: 2.076401472091675

Epoch: 6| Step: 10
Training loss: 1.919192910194397
Validation loss: 2.0305362939834595

Epoch: 6| Step: 11
Training loss: 1.861208200454712
Validation loss: 2.023049612840017

Epoch: 6| Step: 12
Training loss: 1.6078128814697266
Validation loss: 2.025255580743154

Epoch: 6| Step: 13
Training loss: 1.7809995412826538
Validation loss: 2.0344547430674234

Epoch: 53| Step: 0
Training loss: 2.20736026763916
Validation loss: 2.023084123929342

Epoch: 6| Step: 1
Training loss: 2.362595558166504
Validation loss: 2.0466445088386536

Epoch: 6| Step: 2
Training loss: 1.0394055843353271
Validation loss: 2.0055306553840637

Epoch: 6| Step: 3
Training loss: 2.004004955291748
Validation loss: 2.0136242707570395

Epoch: 6| Step: 4
Training loss: 1.9040379524230957
Validation loss: 2.0273062189420066

Epoch: 6| Step: 5
Training loss: 2.0355770587921143
Validation loss: 2.0112067461013794

Epoch: 6| Step: 6
Training loss: 1.2363567352294922
Validation loss: 2.0434756676355996

Epoch: 6| Step: 7
Training loss: 1.8629480600357056
Validation loss: 2.0238742232322693

Epoch: 6| Step: 8
Training loss: 2.0324301719665527
Validation loss: 1.9935692151387532

Epoch: 6| Step: 9
Training loss: 1.249794840812683
Validation loss: 2.021770437558492

Epoch: 6| Step: 10
Training loss: 1.782333254814148
Validation loss: 2.014527201652527

Epoch: 6| Step: 11
Training loss: 1.5506653785705566
Validation loss: 2.0134544372558594

Epoch: 6| Step: 12
Training loss: 2.4817633628845215
Validation loss: 2.044193168481191

Epoch: 6| Step: 13
Training loss: 2.6492996215820312
Validation loss: 2.053012251853943

Epoch: 54| Step: 0
Training loss: 1.405303955078125
Validation loss: 2.1023001670837402

Epoch: 6| Step: 1
Training loss: 2.093933582305908
Validation loss: 2.0924413601557412

Epoch: 6| Step: 2
Training loss: 1.9937509298324585
Validation loss: 2.1106337110201516

Epoch: 6| Step: 3
Training loss: 1.6446418762207031
Validation loss: 2.1411691109339395

Epoch: 6| Step: 4
Training loss: 2.7465641498565674
Validation loss: 2.120980739593506

Epoch: 6| Step: 5
Training loss: 2.299868583679199
Validation loss: 2.0716150601704917

Epoch: 6| Step: 6
Training loss: 1.2267768383026123
Validation loss: 2.085051735242208

Epoch: 6| Step: 7
Training loss: 1.8764238357543945
Validation loss: 2.023705840110779

Epoch: 6| Step: 8
Training loss: 2.1140525341033936
Validation loss: 2.033898492654165

Epoch: 6| Step: 9
Training loss: 2.0277979373931885
Validation loss: 2.032495160897573

Epoch: 6| Step: 10
Training loss: 1.7596148252487183
Validation loss: 2.001519759496053

Epoch: 6| Step: 11
Training loss: 1.8960357904434204
Validation loss: 2.0036414861679077

Epoch: 6| Step: 12
Training loss: 2.3156208992004395
Validation loss: 2.0034382740656533

Epoch: 6| Step: 13
Training loss: 1.471235990524292
Validation loss: 2.033636967341105

Epoch: 55| Step: 0
Training loss: 1.429740071296692
Validation loss: 2.0090476473172507

Epoch: 6| Step: 1
Training loss: 1.653004765510559
Validation loss: 1.995896339416504

Epoch: 6| Step: 2
Training loss: 1.9637072086334229
Validation loss: 2.0130791664123535

Epoch: 6| Step: 3
Training loss: 1.7545242309570312
Validation loss: 2.031383196512858

Epoch: 6| Step: 4
Training loss: 2.154449224472046
Validation loss: 2.027489503224691

Epoch: 6| Step: 5
Training loss: 1.9539999961853027
Validation loss: 2.0436482628186545

Epoch: 6| Step: 6
Training loss: 1.8662889003753662
Validation loss: 2.0313515861829123

Epoch: 6| Step: 7
Training loss: 2.4598774909973145
Validation loss: 2.0514115492502847

Epoch: 6| Step: 8
Training loss: 1.3421117067337036
Validation loss: 2.065981308619181

Epoch: 6| Step: 9
Training loss: 1.7117501497268677
Validation loss: 2.079668124516805

Epoch: 6| Step: 10
Training loss: 2.810344696044922
Validation loss: 2.0663536190986633

Epoch: 6| Step: 11
Training loss: 1.756507158279419
Validation loss: 2.050130466620127

Epoch: 6| Step: 12
Training loss: 1.1577637195587158
Validation loss: 2.0120203495025635

Epoch: 6| Step: 13
Training loss: 2.3189663887023926
Validation loss: 2.0118205149968467

Epoch: 56| Step: 0
Training loss: 1.6425648927688599
Validation loss: 2.0458319981892905

Epoch: 6| Step: 1
Training loss: 1.2922265529632568
Validation loss: 2.060638984044393

Epoch: 6| Step: 2
Training loss: 1.6790924072265625
Validation loss: 2.063197394212087

Epoch: 6| Step: 3
Training loss: 2.0718581676483154
Validation loss: 2.020619968573252

Epoch: 6| Step: 4
Training loss: 1.899590253829956
Validation loss: 2.0053541461626687

Epoch: 6| Step: 5
Training loss: 2.0378074645996094
Validation loss: 2.015972356001536

Epoch: 6| Step: 6
Training loss: 1.8422410488128662
Validation loss: 2.041254540284475

Epoch: 6| Step: 7
Training loss: 1.920558214187622
Validation loss: 2.036690056324005

Epoch: 6| Step: 8
Training loss: 1.931837558746338
Validation loss: 2.0471373796463013

Epoch: 6| Step: 9
Training loss: 1.748034954071045
Validation loss: 2.0676072438557944

Epoch: 6| Step: 10
Training loss: 1.9789624214172363
Validation loss: 2.0641111930211387

Epoch: 6| Step: 11
Training loss: 2.48618221282959
Validation loss: 2.0345392425855002

Epoch: 6| Step: 12
Training loss: 2.1512045860290527
Validation loss: 2.0736305316289267

Epoch: 6| Step: 13
Training loss: 1.614171028137207
Validation loss: 2.0498081843058267

Epoch: 57| Step: 0
Training loss: 1.3973718881607056
Validation loss: 2.039553940296173

Epoch: 6| Step: 1
Training loss: 1.9523922204971313
Validation loss: 2.033639212449392

Epoch: 6| Step: 2
Training loss: 2.479888916015625
Validation loss: 2.044304688771566

Epoch: 6| Step: 3
Training loss: 1.488621711730957
Validation loss: 2.028901219367981

Epoch: 6| Step: 4
Training loss: 1.3094370365142822
Validation loss: 2.0378362933794656

Epoch: 6| Step: 5
Training loss: 2.1868739128112793
Validation loss: 2.0173736810684204

Epoch: 6| Step: 6
Training loss: 1.4476873874664307
Validation loss: 2.0135119756062827

Epoch: 6| Step: 7
Training loss: 2.4424147605895996
Validation loss: 2.0331674615542092

Epoch: 6| Step: 8
Training loss: 2.019761323928833
Validation loss: 2.0249709486961365

Epoch: 6| Step: 9
Training loss: 1.5412588119506836
Validation loss: 2.00657985607783

Epoch: 6| Step: 10
Training loss: 1.8948203325271606
Validation loss: 2.026326298713684

Epoch: 6| Step: 11
Training loss: 1.652773380279541
Validation loss: 2.007647395133972

Epoch: 6| Step: 12
Training loss: 2.519987106323242
Validation loss: 2.0732606252034507

Epoch: 6| Step: 13
Training loss: 1.9951765537261963
Validation loss: 2.044416069984436

Epoch: 58| Step: 0
Training loss: 1.6704847812652588
Validation loss: 2.070270856221517

Epoch: 6| Step: 1
Training loss: 1.9976437091827393
Validation loss: 2.045846700668335

Epoch: 6| Step: 2
Training loss: 1.4875082969665527
Validation loss: 2.023642877737681

Epoch: 6| Step: 3
Training loss: 1.1713969707489014
Validation loss: 2.0195523500442505

Epoch: 6| Step: 4
Training loss: 2.679316997528076
Validation loss: 2.0283027489980063

Epoch: 6| Step: 5
Training loss: 1.8498449325561523
Validation loss: 2.051177144050598

Epoch: 6| Step: 6
Training loss: 1.700869083404541
Validation loss: 2.07169900337855

Epoch: 6| Step: 7
Training loss: 2.3418314456939697
Validation loss: 2.0585143168767295

Epoch: 6| Step: 8
Training loss: 2.1260766983032227
Validation loss: 2.057107369105021

Epoch: 6| Step: 9
Training loss: 2.412440299987793
Validation loss: 2.034867783387502

Epoch: 6| Step: 10
Training loss: 2.0049099922180176
Validation loss: 2.030719598134359

Epoch: 6| Step: 11
Training loss: 1.3811349868774414
Validation loss: 2.0097895661989846

Epoch: 6| Step: 12
Training loss: 1.3444615602493286
Validation loss: 2.028100550174713

Epoch: 6| Step: 13
Training loss: 2.2795920372009277
Validation loss: 2.0072162747383118

Epoch: 59| Step: 0
Training loss: 2.1353530883789062
Validation loss: 2.01438037554423

Epoch: 6| Step: 1
Training loss: 1.8783659934997559
Validation loss: 2.0103291670481362

Epoch: 6| Step: 2
Training loss: 2.2669239044189453
Validation loss: 2.0212746063868203

Epoch: 6| Step: 3
Training loss: 1.446169376373291
Validation loss: 2.033371011416117

Epoch: 6| Step: 4
Training loss: 1.657329797744751
Validation loss: 2.0279038349787393

Epoch: 6| Step: 5
Training loss: 2.017120599746704
Validation loss: 2.0290429989496865

Epoch: 6| Step: 6
Training loss: 1.5598211288452148
Validation loss: 2.0530848701794944

Epoch: 6| Step: 7
Training loss: 2.370349407196045
Validation loss: 2.0423616568247476

Epoch: 6| Step: 8
Training loss: 1.4920400381088257
Validation loss: 2.0271870295206704

Epoch: 6| Step: 9
Training loss: 1.5858012437820435
Validation loss: 2.049589773019155

Epoch: 6| Step: 10
Training loss: 1.8438063859939575
Validation loss: 2.0272483428319297

Epoch: 6| Step: 11
Training loss: 1.8866167068481445
Validation loss: 2.0319944421450296

Epoch: 6| Step: 12
Training loss: 1.6675163507461548
Validation loss: 2.0451508363087973

Epoch: 6| Step: 13
Training loss: 2.264198064804077
Validation loss: 2.0338672200838723

Epoch: 60| Step: 0
Training loss: 2.3815221786499023
Validation loss: 2.018276790777842

Epoch: 6| Step: 1
Training loss: 2.2703394889831543
Validation loss: 2.0277435382207236

Epoch: 6| Step: 2
Training loss: 1.3361855745315552
Validation loss: 2.0458497405052185

Epoch: 6| Step: 3
Training loss: 2.4943742752075195
Validation loss: 2.0165847142537436

Epoch: 6| Step: 4
Training loss: 1.9926843643188477
Validation loss: 2.0328386227289834

Epoch: 6| Step: 5
Training loss: 1.3702936172485352
Validation loss: 2.0102340380350747

Epoch: 6| Step: 6
Training loss: 2.0029940605163574
Validation loss: 2.040294607480367

Epoch: 6| Step: 7
Training loss: 1.3045973777770996
Validation loss: 2.039306024710337

Epoch: 6| Step: 8
Training loss: 1.7667897939682007
Validation loss: 2.069698174794515

Epoch: 6| Step: 9
Training loss: 1.6540488004684448
Validation loss: 2.0902462005615234

Epoch: 6| Step: 10
Training loss: 1.6279170513153076
Validation loss: 2.0495678981145224

Epoch: 6| Step: 11
Training loss: 1.9738112688064575
Validation loss: 2.0701431035995483

Epoch: 6| Step: 12
Training loss: 2.0718040466308594
Validation loss: 2.0623783667882285

Epoch: 6| Step: 13
Training loss: 1.7602484226226807
Validation loss: 2.0390623211860657

Epoch: 61| Step: 0
Training loss: 1.7458548545837402
Validation loss: 2.041027784347534

Epoch: 6| Step: 1
Training loss: 1.5779647827148438
Validation loss: 2.042768736680349

Epoch: 6| Step: 2
Training loss: 2.057460069656372
Validation loss: 2.068806529045105

Epoch: 6| Step: 3
Training loss: 2.064880847930908
Validation loss: 2.0387837092081704

Epoch: 6| Step: 4
Training loss: 2.0323190689086914
Validation loss: 2.039169708887736

Epoch: 6| Step: 5
Training loss: 1.2701547145843506
Validation loss: 2.063468337059021

Epoch: 6| Step: 6
Training loss: 2.3404452800750732
Validation loss: 2.013388375441233

Epoch: 6| Step: 7
Training loss: 1.6227223873138428
Validation loss: 1.9974952737490337

Epoch: 6| Step: 8
Training loss: 1.8066209554672241
Validation loss: 2.0306695898373923

Epoch: 6| Step: 9
Training loss: 2.0981054306030273
Validation loss: 2.0413028796513877

Epoch: 6| Step: 10
Training loss: 1.7483150959014893
Validation loss: 2.0400394002596536

Epoch: 6| Step: 11
Training loss: 1.91633939743042
Validation loss: 2.063763161500295

Epoch: 6| Step: 12
Training loss: 1.5251009464263916
Validation loss: 2.038081963857015

Epoch: 6| Step: 13
Training loss: 2.131471872329712
Validation loss: 2.041109482447306

Epoch: 62| Step: 0
Training loss: 1.6787387132644653
Validation loss: 2.062621772289276

Epoch: 6| Step: 1
Training loss: 1.5220272541046143
Validation loss: 2.05807888507843

Epoch: 6| Step: 2
Training loss: 2.07304048538208
Validation loss: 2.044033646583557

Epoch: 6| Step: 3
Training loss: 2.1143627166748047
Validation loss: 2.056971808274587

Epoch: 6| Step: 4
Training loss: 1.771660566329956
Validation loss: 2.06510728597641

Epoch: 6| Step: 5
Training loss: 1.7238279581069946
Validation loss: 2.0705406069755554

Epoch: 6| Step: 6
Training loss: 1.3494305610656738
Validation loss: 2.0470502972602844

Epoch: 6| Step: 7
Training loss: 1.9027094841003418
Validation loss: 2.0263802210489907

Epoch: 6| Step: 8
Training loss: 1.8297204971313477
Validation loss: 2.0584535002708435

Epoch: 6| Step: 9
Training loss: 1.9928851127624512
Validation loss: 2.0281171003977456

Epoch: 6| Step: 10
Training loss: 1.589526653289795
Validation loss: 2.013834595680237

Epoch: 6| Step: 11
Training loss: 2.21010684967041
Validation loss: 1.9956410725911458

Epoch: 6| Step: 12
Training loss: 2.3458428382873535
Validation loss: 2.013177772363027

Epoch: 6| Step: 13
Training loss: 1.699812650680542
Validation loss: 2.0104941725730896

Epoch: 63| Step: 0
Training loss: 1.4747308492660522
Validation loss: 2.0054471095403037

Epoch: 6| Step: 1
Training loss: 1.5944631099700928
Validation loss: 2.0186666448911033

Epoch: 6| Step: 2
Training loss: 1.7760860919952393
Validation loss: 2.0384485920270285

Epoch: 6| Step: 3
Training loss: 1.2281826734542847
Validation loss: 2.0385632514953613

Epoch: 6| Step: 4
Training loss: 2.206926107406616
Validation loss: 2.0308063626289368

Epoch: 6| Step: 5
Training loss: 1.438165545463562
Validation loss: 2.0476373036702475

Epoch: 6| Step: 6
Training loss: 2.389226198196411
Validation loss: 2.0653590758641562

Epoch: 6| Step: 7
Training loss: 1.5349094867706299
Validation loss: 2.057567218939463

Epoch: 6| Step: 8
Training loss: 2.030172824859619
Validation loss: 2.042640268802643

Epoch: 6| Step: 9
Training loss: 2.2822461128234863
Validation loss: 2.0581977168718972

Epoch: 6| Step: 10
Training loss: 1.8251423835754395
Validation loss: 2.0666094621022544

Epoch: 6| Step: 11
Training loss: 1.9171342849731445
Validation loss: 2.0318307280540466

Epoch: 6| Step: 12
Training loss: 1.6979246139526367
Validation loss: 2.030035217603048

Epoch: 6| Step: 13
Training loss: 2.2539491653442383
Validation loss: 2.045803348223368

Epoch: 64| Step: 0
Training loss: 1.732551097869873
Validation loss: 2.0021517276763916

Epoch: 6| Step: 1
Training loss: 2.573692560195923
Validation loss: 1.996200680732727

Epoch: 6| Step: 2
Training loss: 1.7489492893218994
Validation loss: 2.010978658994039

Epoch: 6| Step: 3
Training loss: 2.136540412902832
Validation loss: 2.0169310172398887

Epoch: 6| Step: 4
Training loss: 1.7132364511489868
Validation loss: 2.0146241784095764

Epoch: 6| Step: 5
Training loss: 1.3391977548599243
Validation loss: 1.9936917225519817

Epoch: 6| Step: 6
Training loss: 1.7215067148208618
Validation loss: 2.0194769501686096

Epoch: 6| Step: 7
Training loss: 2.1918787956237793
Validation loss: 2.018429179986318

Epoch: 6| Step: 8
Training loss: 1.8323137760162354
Validation loss: 2.013487716515859

Epoch: 6| Step: 9
Training loss: 2.120959997177124
Validation loss: 2.0166884660720825

Epoch: 6| Step: 10
Training loss: 1.98453950881958
Validation loss: 2.0328107277552285

Epoch: 6| Step: 11
Training loss: 1.4586316347122192
Validation loss: 2.0335370302200317

Epoch: 6| Step: 12
Training loss: 1.6475664377212524
Validation loss: 2.0578537583351135

Epoch: 6| Step: 13
Training loss: 1.5914545059204102
Validation loss: 2.0801660418510437

Epoch: 65| Step: 0
Training loss: 2.222975492477417
Validation loss: 2.0546250343322754

Epoch: 6| Step: 1
Training loss: 1.9544174671173096
Validation loss: 2.0754149556159973

Epoch: 6| Step: 2
Training loss: 1.6334574222564697
Validation loss: 2.090925375620524

Epoch: 6| Step: 3
Training loss: 2.247034788131714
Validation loss: 2.0897658665974936

Epoch: 6| Step: 4
Training loss: 1.8118559122085571
Validation loss: 2.080187360445658

Epoch: 6| Step: 5
Training loss: 1.8367727994918823
Validation loss: 2.101886212825775

Epoch: 6| Step: 6
Training loss: 1.7223076820373535
Validation loss: 2.068739036719004

Epoch: 6| Step: 7
Training loss: 1.8266106843948364
Validation loss: 2.0304556488990784

Epoch: 6| Step: 8
Training loss: 1.6101224422454834
Validation loss: 2.0341499050458274

Epoch: 6| Step: 9
Training loss: 1.4403326511383057
Validation loss: 2.018602728843689

Epoch: 6| Step: 10
Training loss: 2.3828771114349365
Validation loss: 2.0073127150535583

Epoch: 6| Step: 11
Training loss: 1.8863576650619507
Validation loss: 2.020958960056305

Epoch: 6| Step: 12
Training loss: 1.562136173248291
Validation loss: 2.0128742257754006

Epoch: 6| Step: 13
Training loss: 1.5939831733703613
Validation loss: 2.013434569040934

Epoch: 66| Step: 0
Training loss: 1.6710721254348755
Validation loss: 2.0251386761665344

Epoch: 6| Step: 1
Training loss: 1.7458953857421875
Validation loss: 2.010365386803945

Epoch: 6| Step: 2
Training loss: 1.2185544967651367
Validation loss: 2.0334459940592446

Epoch: 6| Step: 3
Training loss: 1.9436339139938354
Validation loss: 2.026495377222697

Epoch: 6| Step: 4
Training loss: 2.064507007598877
Validation loss: 2.0579473972320557

Epoch: 6| Step: 5
Training loss: 1.3069157600402832
Validation loss: 2.0520517826080322

Epoch: 6| Step: 6
Training loss: 2.2670767307281494
Validation loss: 2.058318793773651

Epoch: 6| Step: 7
Training loss: 1.5470945835113525
Validation loss: 2.0551820397377014

Epoch: 6| Step: 8
Training loss: 1.8667140007019043
Validation loss: 2.0994980732599893

Epoch: 6| Step: 9
Training loss: 1.7116283178329468
Validation loss: 2.0815094113349915

Epoch: 6| Step: 10
Training loss: 1.674092411994934
Validation loss: 2.0898176630338035

Epoch: 6| Step: 11
Training loss: 2.537400484085083
Validation loss: 2.07621161142985

Epoch: 6| Step: 12
Training loss: 2.2500460147857666
Validation loss: 2.0820516546567283

Epoch: 6| Step: 13
Training loss: 1.7738780975341797
Validation loss: 2.0473734736442566

Epoch: 67| Step: 0
Training loss: 1.884582281112671
Validation loss: 2.034234603246053

Epoch: 6| Step: 1
Training loss: 1.9253979921340942
Validation loss: 2.02606870730718

Epoch: 6| Step: 2
Training loss: 1.9009939432144165
Validation loss: 2.015810489654541

Epoch: 6| Step: 3
Training loss: 2.101044178009033
Validation loss: 2.0028136173884072

Epoch: 6| Step: 4
Training loss: 1.4218478202819824
Validation loss: 2.004122734069824

Epoch: 6| Step: 5
Training loss: 2.0260729789733887
Validation loss: 1.9983740250269573

Epoch: 6| Step: 6
Training loss: 2.1875219345092773
Validation loss: 2.037156641483307

Epoch: 6| Step: 7
Training loss: 1.6689798831939697
Validation loss: 2.0172841946283975

Epoch: 6| Step: 8
Training loss: 1.49722421169281
Validation loss: 2.012312908967336

Epoch: 6| Step: 9
Training loss: 1.8756530284881592
Validation loss: 2.0331536134084067

Epoch: 6| Step: 10
Training loss: 1.5617729425430298
Validation loss: 2.0449408094088235

Epoch: 6| Step: 11
Training loss: 2.2161383628845215
Validation loss: 2.051158527533213

Epoch: 6| Step: 12
Training loss: 2.048121690750122
Validation loss: 2.0393373568852744

Epoch: 6| Step: 13
Training loss: 1.1879684925079346
Validation loss: 2.0585168401400247

Epoch: 68| Step: 0
Training loss: 1.826628565788269
Validation loss: 2.0348257621129355

Epoch: 6| Step: 1
Training loss: 1.8181331157684326
Validation loss: 2.042676270008087

Epoch: 6| Step: 2
Training loss: 2.272890329360962
Validation loss: 2.0379263957341514

Epoch: 6| Step: 3
Training loss: 1.7139413356781006
Validation loss: 2.0197721322377524

Epoch: 6| Step: 4
Training loss: 1.6298846006393433
Validation loss: 2.031247138977051

Epoch: 6| Step: 5
Training loss: 1.4512310028076172
Validation loss: 2.0344448685646057

Epoch: 6| Step: 6
Training loss: 2.0075907707214355
Validation loss: 2.0271045366923013

Epoch: 6| Step: 7
Training loss: 1.699925184249878
Validation loss: 2.0572983026504517

Epoch: 6| Step: 8
Training loss: 1.694779872894287
Validation loss: 2.0490975975990295

Epoch: 6| Step: 9
Training loss: 1.1196918487548828
Validation loss: 2.0460559328397117

Epoch: 6| Step: 10
Training loss: 2.361574172973633
Validation loss: 2.0481250286102295

Epoch: 6| Step: 11
Training loss: 2.078144073486328
Validation loss: 2.0350201527277627

Epoch: 6| Step: 12
Training loss: 1.814365267753601
Validation loss: 2.047196328639984

Epoch: 6| Step: 13
Training loss: 1.8388526439666748
Validation loss: 2.041592021783193

Epoch: 69| Step: 0
Training loss: 1.3110392093658447
Validation loss: 2.018499970436096

Epoch: 6| Step: 1
Training loss: 1.5117065906524658
Validation loss: 2.051701605319977

Epoch: 6| Step: 2
Training loss: 1.6714228391647339
Validation loss: 2.054927408695221

Epoch: 6| Step: 3
Training loss: 2.081237554550171
Validation loss: 2.0085144440333047

Epoch: 6| Step: 4
Training loss: 1.636075735092163
Validation loss: 2.038858413696289

Epoch: 6| Step: 5
Training loss: 2.2779488563537598
Validation loss: 2.022188186645508

Epoch: 6| Step: 6
Training loss: 1.9803845882415771
Validation loss: 2.016393303871155

Epoch: 6| Step: 7
Training loss: 1.551314115524292
Validation loss: 2.0687527457873025

Epoch: 6| Step: 8
Training loss: 2.159748077392578
Validation loss: 2.021906316280365

Epoch: 6| Step: 9
Training loss: 1.6596609354019165
Validation loss: 2.034741540749868

Epoch: 6| Step: 10
Training loss: 2.3104372024536133
Validation loss: 2.0344212651252747

Epoch: 6| Step: 11
Training loss: 1.6863927841186523
Validation loss: 2.011487821737925

Epoch: 6| Step: 12
Training loss: 1.7592148780822754
Validation loss: 2.043535272280375

Epoch: 6| Step: 13
Training loss: 1.739041805267334
Validation loss: 2.0555251439412436

Epoch: 70| Step: 0
Training loss: 1.6048518419265747
Validation loss: 2.0426939924558005

Epoch: 6| Step: 1
Training loss: 1.7180540561676025
Validation loss: 2.0249334971110025

Epoch: 6| Step: 2
Training loss: 1.9116618633270264
Validation loss: 2.032268981138865

Epoch: 6| Step: 3
Training loss: 1.6198084354400635
Validation loss: 2.0321213205655417

Epoch: 6| Step: 4
Training loss: 1.6974890232086182
Validation loss: 2.0247320334116616

Epoch: 6| Step: 5
Training loss: 1.9997310638427734
Validation loss: 2.04287459452947

Epoch: 6| Step: 6
Training loss: 1.1426432132720947
Validation loss: 2.013334413369497

Epoch: 6| Step: 7
Training loss: 2.1447625160217285
Validation loss: 2.0581396420796714

Epoch: 6| Step: 8
Training loss: 1.7549488544464111
Validation loss: 2.026079773902893

Epoch: 6| Step: 9
Training loss: 2.2717974185943604
Validation loss: 1.9957119822502136

Epoch: 6| Step: 10
Training loss: 1.7904078960418701
Validation loss: 2.0141416589419046

Epoch: 6| Step: 11
Training loss: 1.244332194328308
Validation loss: 2.0355029702186584

Epoch: 6| Step: 12
Training loss: 2.3545727729797363
Validation loss: 2.0432465275128684

Epoch: 6| Step: 13
Training loss: 1.9520180225372314
Validation loss: 2.049387792746226

Epoch: 71| Step: 0
Training loss: 1.0494778156280518
Validation loss: 2.0633527040481567

Epoch: 6| Step: 1
Training loss: 1.8450989723205566
Validation loss: 2.029224157333374

Epoch: 6| Step: 2
Training loss: 2.056342124938965
Validation loss: 2.0853331089019775

Epoch: 6| Step: 3
Training loss: 1.5497901439666748
Validation loss: 2.0701592763264975

Epoch: 6| Step: 4
Training loss: 1.8799049854278564
Validation loss: 2.0309150218963623

Epoch: 6| Step: 5
Training loss: 1.0629827976226807
Validation loss: 2.005693713823954

Epoch: 6| Step: 6
Training loss: 2.1957430839538574
Validation loss: 2.0589170853296914

Epoch: 6| Step: 7
Training loss: 1.654680609703064
Validation loss: 2.019873023033142

Epoch: 6| Step: 8
Training loss: 1.7235231399536133
Validation loss: 2.0165528059005737

Epoch: 6| Step: 9
Training loss: 1.9612478017807007
Validation loss: 2.0314316749572754

Epoch: 6| Step: 10
Training loss: 1.926912784576416
Validation loss: 2.0522467494010925

Epoch: 6| Step: 11
Training loss: 1.6452326774597168
Validation loss: 1.9988042116165161

Epoch: 6| Step: 12
Training loss: 2.134246826171875
Validation loss: 2.0045833587646484

Epoch: 6| Step: 13
Training loss: 2.3741722106933594
Validation loss: 2.074485182762146

Epoch: 72| Step: 0
Training loss: 1.3749299049377441
Validation loss: 2.03977378209432

Epoch: 6| Step: 1
Training loss: 1.7723098993301392
Validation loss: 2.035463054974874

Epoch: 6| Step: 2
Training loss: 1.6152706146240234
Validation loss: 2.059765577316284

Epoch: 6| Step: 3
Training loss: 2.2058043479919434
Validation loss: 2.0582111875216165

Epoch: 6| Step: 4
Training loss: 2.116753578186035
Validation loss: 2.033310651779175

Epoch: 6| Step: 5
Training loss: 1.4569108486175537
Validation loss: 2.0517167448997498

Epoch: 6| Step: 6
Training loss: 2.553182601928711
Validation loss: 2.056646704673767

Epoch: 6| Step: 7
Training loss: 1.7318050861358643
Validation loss: 2.0589258074760437

Epoch: 6| Step: 8
Training loss: 1.9665584564208984
Validation loss: 2.0525614817937217

Epoch: 6| Step: 9
Training loss: 1.8600658178329468
Validation loss: 2.0344512263933816

Epoch: 6| Step: 10
Training loss: 1.614485502243042
Validation loss: 2.009700059890747

Epoch: 6| Step: 11
Training loss: 1.5661301612854004
Validation loss: 2.0100042819976807

Epoch: 6| Step: 12
Training loss: 1.5881620645523071
Validation loss: 2.022620995839437

Epoch: 6| Step: 13
Training loss: 1.7906209230422974
Validation loss: 2.0383217533429465

Epoch: 73| Step: 0
Training loss: 1.645530343055725
Validation loss: 2.027195950349172

Epoch: 6| Step: 1
Training loss: 1.4101548194885254
Validation loss: 2.002521018187205

Epoch: 6| Step: 2
Training loss: 1.4874610900878906
Validation loss: 1.9994569023450215

Epoch: 6| Step: 3
Training loss: 1.8082579374313354
Validation loss: 2.0184353788693747

Epoch: 6| Step: 4
Training loss: 2.3534817695617676
Validation loss: 2.019302725791931

Epoch: 6| Step: 5
Training loss: 2.4154999256134033
Validation loss: 2.016375104586283

Epoch: 6| Step: 6
Training loss: 2.199451208114624
Validation loss: 2.0440810124079385

Epoch: 6| Step: 7
Training loss: 1.620171070098877
Validation loss: 2.0169177651405334

Epoch: 6| Step: 8
Training loss: 1.5001899003982544
Validation loss: 2.0533915758132935

Epoch: 6| Step: 9
Training loss: 1.7672370672225952
Validation loss: 2.0747726360956826

Epoch: 6| Step: 10
Training loss: 1.4307221174240112
Validation loss: 2.052406966686249

Epoch: 6| Step: 11
Training loss: 1.8476920127868652
Validation loss: 2.0290055672327676

Epoch: 6| Step: 12
Training loss: 2.018489360809326
Validation loss: 2.041632274786631

Epoch: 6| Step: 13
Training loss: 1.556368112564087
Validation loss: 2.048029581705729

Epoch: 74| Step: 0
Training loss: 1.7568855285644531
Validation loss: 2.0532588164011636

Epoch: 6| Step: 1
Training loss: 1.2339329719543457
Validation loss: 2.034344792366028

Epoch: 6| Step: 2
Training loss: 1.8931121826171875
Validation loss: 2.0188488761583963

Epoch: 6| Step: 3
Training loss: 2.05993914604187
Validation loss: 2.015994131565094

Epoch: 6| Step: 4
Training loss: 1.1958361864089966
Validation loss: 2.00047759215037

Epoch: 6| Step: 5
Training loss: 2.187751054763794
Validation loss: 2.0341820319493613

Epoch: 6| Step: 6
Training loss: 1.5195426940917969
Validation loss: 2.006129960219065

Epoch: 6| Step: 7
Training loss: 2.675710916519165
Validation loss: 2.028418242931366

Epoch: 6| Step: 8
Training loss: 1.5512257814407349
Validation loss: 2.042215128739675

Epoch: 6| Step: 9
Training loss: 1.6971467733383179
Validation loss: 2.016515771547953

Epoch: 6| Step: 10
Training loss: 1.4887322187423706
Validation loss: 2.039243698120117

Epoch: 6| Step: 11
Training loss: 1.6261847019195557
Validation loss: 2.0246113340059915

Epoch: 6| Step: 12
Training loss: 1.3973939418792725
Validation loss: 2.056423604488373

Epoch: 6| Step: 13
Training loss: 2.8125016689300537
Validation loss: 2.048759698867798

Epoch: 75| Step: 0
Training loss: 1.613633632659912
Validation loss: 2.0302505095799765

Epoch: 6| Step: 1
Training loss: 2.2578916549682617
Validation loss: 2.048717657725016

Epoch: 6| Step: 2
Training loss: 1.6802456378936768
Validation loss: 2.004633605480194

Epoch: 6| Step: 3
Training loss: 2.1152071952819824
Validation loss: 2.027704397837321

Epoch: 6| Step: 4
Training loss: 1.1378039121627808
Validation loss: 2.003718157609304

Epoch: 6| Step: 5
Training loss: 2.575061321258545
Validation loss: 2.0212350686391196

Epoch: 6| Step: 6
Training loss: 1.3936322927474976
Validation loss: 2.0231892267862954

Epoch: 6| Step: 7
Training loss: 1.9863988161087036
Validation loss: 2.0337041219075522

Epoch: 6| Step: 8
Training loss: 2.3167057037353516
Validation loss: 2.009005546569824

Epoch: 6| Step: 9
Training loss: 1.4428560733795166
Validation loss: 2.0019989013671875

Epoch: 6| Step: 10
Training loss: 1.48090398311615
Validation loss: 2.025964081287384

Epoch: 6| Step: 11
Training loss: 2.3613548278808594
Validation loss: 2.022839685281118

Epoch: 6| Step: 12
Training loss: 1.135009527206421
Validation loss: 2.0563751260439553

Epoch: 6| Step: 13
Training loss: 1.7656587362289429
Validation loss: 2.0608641107877097

Epoch: 76| Step: 0
Training loss: 1.3470488786697388
Validation loss: 2.0637285312016806

Epoch: 6| Step: 1
Training loss: 1.4979079961776733
Validation loss: 2.1058563192685447

Epoch: 6| Step: 2
Training loss: 1.9850149154663086
Validation loss: 2.1748477617899575

Epoch: 6| Step: 3
Training loss: 1.1260366439819336
Validation loss: 2.1631804704666138

Epoch: 6| Step: 4
Training loss: 1.7369019985198975
Validation loss: 2.1492462158203125

Epoch: 6| Step: 5
Training loss: 1.6452116966247559
Validation loss: 2.1088713010152182

Epoch: 6| Step: 6
Training loss: 1.9428167343139648
Validation loss: 2.07887601852417

Epoch: 6| Step: 7
Training loss: 1.906807541847229
Validation loss: 2.0568787256876626

Epoch: 6| Step: 8
Training loss: 1.6150660514831543
Validation loss: 2.0445387164751687

Epoch: 6| Step: 9
Training loss: 2.0346291065216064
Validation loss: 2.033349931240082

Epoch: 6| Step: 10
Training loss: 1.756333589553833
Validation loss: 2.0206549366315207

Epoch: 6| Step: 11
Training loss: 2.1174092292785645
Validation loss: 1.9960749348004658

Epoch: 6| Step: 12
Training loss: 1.8242278099060059
Validation loss: 2.029033044974009

Epoch: 6| Step: 13
Training loss: 2.3762972354888916
Validation loss: 2.0162330269813538

Epoch: 77| Step: 0
Training loss: 1.5138142108917236
Validation loss: 2.023550013701121

Epoch: 6| Step: 1
Training loss: 1.8271615505218506
Validation loss: 2.025710860888163

Epoch: 6| Step: 2
Training loss: 1.7301621437072754
Validation loss: 2.0142894784609475

Epoch: 6| Step: 3
Training loss: 1.6052980422973633
Validation loss: 2.032107094923655

Epoch: 6| Step: 4
Training loss: 1.6713502407073975
Validation loss: 1.9982314308484395

Epoch: 6| Step: 5
Training loss: 1.9334442615509033
Validation loss: 2.0197971065839133

Epoch: 6| Step: 6
Training loss: 1.189283847808838
Validation loss: 2.0585345228513083

Epoch: 6| Step: 7
Training loss: 1.8603496551513672
Validation loss: 2.062707463900248

Epoch: 6| Step: 8
Training loss: 1.3957418203353882
Validation loss: 2.0914383133252463

Epoch: 6| Step: 9
Training loss: 2.1368486881256104
Validation loss: 2.0805897315343223

Epoch: 6| Step: 10
Training loss: 1.4007039070129395
Validation loss: 2.0980562567710876

Epoch: 6| Step: 11
Training loss: 2.2312264442443848
Validation loss: 2.0851062734921775

Epoch: 6| Step: 12
Training loss: 3.0308563709259033
Validation loss: 2.095789829889933

Epoch: 6| Step: 13
Training loss: 1.4724922180175781
Validation loss: 2.0668668150901794

Epoch: 78| Step: 0
Training loss: 1.958852767944336
Validation loss: 2.0191002090771994

Epoch: 6| Step: 1
Training loss: 1.3601455688476562
Validation loss: 2.0390512148539224

Epoch: 6| Step: 2
Training loss: 1.5553874969482422
Validation loss: 2.0219369530677795

Epoch: 6| Step: 3
Training loss: 2.549084186553955
Validation loss: 2.033796032269796

Epoch: 6| Step: 4
Training loss: 0.8109448552131653
Validation loss: 2.030110001564026

Epoch: 6| Step: 5
Training loss: 2.0242953300476074
Validation loss: 2.060517112414042

Epoch: 6| Step: 6
Training loss: 2.4914770126342773
Validation loss: 2.0367335875829062

Epoch: 6| Step: 7
Training loss: 2.2532637119293213
Validation loss: 2.0130807956059775

Epoch: 6| Step: 8
Training loss: 1.5423495769500732
Validation loss: 2.0600373347600303

Epoch: 6| Step: 9
Training loss: 1.9600486755371094
Validation loss: 2.045928438504537

Epoch: 6| Step: 10
Training loss: 1.4809250831604004
Validation loss: 2.0513686537742615

Epoch: 6| Step: 11
Training loss: 1.450366735458374
Validation loss: 2.0106669664382935

Epoch: 6| Step: 12
Training loss: 1.373746395111084
Validation loss: 2.0106546878814697

Epoch: 6| Step: 13
Training loss: 1.8700653314590454
Validation loss: 2.0188922683397927

Epoch: 79| Step: 0
Training loss: 2.0842766761779785
Validation loss: 2.0261492331822715

Epoch: 6| Step: 1
Training loss: 1.1993954181671143
Validation loss: 2.045519928137461

Epoch: 6| Step: 2
Training loss: 1.2963255643844604
Validation loss: 2.0532150268554688

Epoch: 6| Step: 3
Training loss: 1.735514760017395
Validation loss: 2.0578737457593284

Epoch: 6| Step: 4
Training loss: 1.9095709323883057
Validation loss: 2.0233985980351767

Epoch: 6| Step: 5
Training loss: 2.317490577697754
Validation loss: 2.0113136172294617

Epoch: 6| Step: 6
Training loss: 1.6109721660614014
Validation loss: 2.058742562929789

Epoch: 6| Step: 7
Training loss: 1.9513695240020752
Validation loss: 2.040818989276886

Epoch: 6| Step: 8
Training loss: 1.931168556213379
Validation loss: 2.023918012777964

Epoch: 6| Step: 9
Training loss: 1.3255665302276611
Validation loss: 2.013539711634318

Epoch: 6| Step: 10
Training loss: 1.971649169921875
Validation loss: 2.058403253555298

Epoch: 6| Step: 11
Training loss: 1.9470397233963013
Validation loss: 2.0211114287376404

Epoch: 6| Step: 12
Training loss: 1.1639052629470825
Validation loss: 2.020232359568278

Epoch: 6| Step: 13
Training loss: 2.0064444541931152
Validation loss: 2.0462485949198403

Epoch: 80| Step: 0
Training loss: 1.9658803939819336
Validation loss: 2.038664996623993

Epoch: 6| Step: 1
Training loss: 1.6528801918029785
Validation loss: 2.049468219280243

Epoch: 6| Step: 2
Training loss: 1.6672391891479492
Validation loss: 2.059718132019043

Epoch: 6| Step: 3
Training loss: 1.521982192993164
Validation loss: 2.0767441391944885

Epoch: 6| Step: 4
Training loss: 1.4191516637802124
Validation loss: 2.062480350335439

Epoch: 6| Step: 5
Training loss: 1.3685652017593384
Validation loss: 2.0450420578320823

Epoch: 6| Step: 6
Training loss: 1.5784450769424438
Validation loss: 2.0551539063453674

Epoch: 6| Step: 7
Training loss: 1.3416080474853516
Validation loss: 2.040895402431488

Epoch: 6| Step: 8
Training loss: 1.903977632522583
Validation loss: 2.0377105673154197

Epoch: 6| Step: 9
Training loss: 2.421980142593384
Validation loss: 2.0284500122070312

Epoch: 6| Step: 10
Training loss: 1.5837465524673462
Validation loss: 2.0460994243621826

Epoch: 6| Step: 11
Training loss: 1.8898818492889404
Validation loss: 2.0196953614552817

Epoch: 6| Step: 12
Training loss: 2.0243449211120605
Validation loss: 2.0315799713134766

Epoch: 6| Step: 13
Training loss: 2.3756167888641357
Validation loss: 2.0402194261550903

Epoch: 81| Step: 0
Training loss: 1.448543667793274
Validation loss: 2.020642578601837

Epoch: 6| Step: 1
Training loss: 1.780388593673706
Validation loss: 2.0240168968836465

Epoch: 6| Step: 2
Training loss: 1.7808711528778076
Validation loss: 2.049944500128428

Epoch: 6| Step: 3
Training loss: 2.0596799850463867
Validation loss: 2.082780102888743

Epoch: 6| Step: 4
Training loss: 1.2777080535888672
Validation loss: 2.064911961555481

Epoch: 6| Step: 5
Training loss: 2.0269088745117188
Validation loss: 2.096532920996348

Epoch: 6| Step: 6
Training loss: 2.260268211364746
Validation loss: 2.1000596086184182

Epoch: 6| Step: 7
Training loss: 2.349228620529175
Validation loss: 2.0536195039749146

Epoch: 6| Step: 8
Training loss: 1.5956220626831055
Validation loss: 2.053581714630127

Epoch: 6| Step: 9
Training loss: 1.6756378412246704
Validation loss: 2.0439459880193076

Epoch: 6| Step: 10
Training loss: 1.6402912139892578
Validation loss: 2.024141311645508

Epoch: 6| Step: 11
Training loss: 1.5528287887573242
Validation loss: 2.030099550882975

Epoch: 6| Step: 12
Training loss: 1.8702616691589355
Validation loss: 2.06586092710495

Epoch: 6| Step: 13
Training loss: 1.4341769218444824
Validation loss: 2.0417403976122537

Epoch: 82| Step: 0
Training loss: 1.7025415897369385
Validation loss: 2.0381771127382913

Epoch: 6| Step: 1
Training loss: 2.0224835872650146
Validation loss: 2.0368475914001465

Epoch: 6| Step: 2
Training loss: 1.478333830833435
Validation loss: 2.050318400065104

Epoch: 6| Step: 3
Training loss: 1.551384687423706
Validation loss: 2.032990316549937

Epoch: 6| Step: 4
Training loss: 1.5986878871917725
Validation loss: 2.030303875605265

Epoch: 6| Step: 5
Training loss: 1.87751305103302
Validation loss: 2.08707058429718

Epoch: 6| Step: 6
Training loss: 1.129401683807373
Validation loss: 2.0472530921300254

Epoch: 6| Step: 7
Training loss: 1.5990605354309082
Validation loss: 2.04279488325119

Epoch: 6| Step: 8
Training loss: 2.2205231189727783
Validation loss: 2.099565029144287

Epoch: 6| Step: 9
Training loss: 1.8780187368392944
Validation loss: 2.0424779852231345

Epoch: 6| Step: 10
Training loss: 1.9294822216033936
Validation loss: 2.054285148779551

Epoch: 6| Step: 11
Training loss: 1.6630020141601562
Validation loss: 2.087988634904226

Epoch: 6| Step: 12
Training loss: 2.0617082118988037
Validation loss: 2.051234165827433

Epoch: 6| Step: 13
Training loss: 1.5682860612869263
Validation loss: 2.072026491165161

Epoch: 83| Step: 0
Training loss: 1.3849782943725586
Validation loss: 2.0655324260393777

Epoch: 6| Step: 1
Training loss: 2.0173094272613525
Validation loss: 2.033670405546824

Epoch: 6| Step: 2
Training loss: 1.8964760303497314
Validation loss: 2.0199387272198996

Epoch: 6| Step: 3
Training loss: 1.8434162139892578
Validation loss: 2.030236780643463

Epoch: 6| Step: 4
Training loss: 1.4695630073547363
Validation loss: 2.034079829851786

Epoch: 6| Step: 5
Training loss: 1.331959843635559
Validation loss: 2.0338663458824158

Epoch: 6| Step: 6
Training loss: 2.168238639831543
Validation loss: 2.062604010105133

Epoch: 6| Step: 7
Training loss: 1.3284261226654053
Validation loss: 2.0295436779658

Epoch: 6| Step: 8
Training loss: 1.7918161153793335
Validation loss: 2.003500064214071

Epoch: 6| Step: 9
Training loss: 2.054837465286255
Validation loss: 2.0344002842903137

Epoch: 6| Step: 10
Training loss: 1.660232424736023
Validation loss: 2.024400293827057

Epoch: 6| Step: 11
Training loss: 2.0595550537109375
Validation loss: 2.02740607659022

Epoch: 6| Step: 12
Training loss: 1.1462905406951904
Validation loss: 2.067978541056315

Epoch: 6| Step: 13
Training loss: 1.9517313241958618
Validation loss: 2.042189141114553

Epoch: 84| Step: 0
Training loss: 1.6808017492294312
Validation loss: 2.0400091211001077

Epoch: 6| Step: 1
Training loss: 1.4287694692611694
Validation loss: 2.03163476785024

Epoch: 6| Step: 2
Training loss: 1.606002926826477
Validation loss: 2.0636698404947915

Epoch: 6| Step: 3
Training loss: 2.3958659172058105
Validation loss: 2.0748260617256165

Epoch: 6| Step: 4
Training loss: 1.5171444416046143
Validation loss: 2.057790478070577

Epoch: 6| Step: 5
Training loss: 1.7467947006225586
Validation loss: 2.100622077782949

Epoch: 6| Step: 6
Training loss: 1.7914276123046875
Validation loss: 2.0918485522270203

Epoch: 6| Step: 7
Training loss: 1.9051153659820557
Validation loss: 2.068089485168457

Epoch: 6| Step: 8
Training loss: 2.20900821685791
Validation loss: 2.0760453939437866

Epoch: 6| Step: 9
Training loss: 1.6508513689041138
Validation loss: 2.0618707736333213

Epoch: 6| Step: 10
Training loss: 0.9787915349006653
Validation loss: 2.0525848666826882

Epoch: 6| Step: 11
Training loss: 1.1468918323516846
Validation loss: 2.0283478697141013

Epoch: 6| Step: 12
Training loss: 1.9562444686889648
Validation loss: 2.0413015484809875

Epoch: 6| Step: 13
Training loss: 2.014462947845459
Validation loss: 2.045094668865204

Epoch: 85| Step: 0
Training loss: 2.1867892742156982
Validation loss: 2.0454911589622498

Epoch: 6| Step: 1
Training loss: 2.108743190765381
Validation loss: 2.0491089622179666

Epoch: 6| Step: 2
Training loss: 1.23171067237854
Validation loss: 2.042180319627126

Epoch: 6| Step: 3
Training loss: 1.6984994411468506
Validation loss: 2.0176439682642617

Epoch: 6| Step: 4
Training loss: 1.9511213302612305
Validation loss: 2.0434712568918862

Epoch: 6| Step: 5
Training loss: 1.7643364667892456
Validation loss: 2.0470139582951865

Epoch: 6| Step: 6
Training loss: 1.4910175800323486
Validation loss: 2.038928190867106

Epoch: 6| Step: 7
Training loss: 1.159860610961914
Validation loss: 2.041929026444753

Epoch: 6| Step: 8
Training loss: 1.6785858869552612
Validation loss: 2.065625309944153

Epoch: 6| Step: 9
Training loss: 2.291264057159424
Validation loss: 2.065225581328074

Epoch: 6| Step: 10
Training loss: 1.8445427417755127
Validation loss: 2.0599021514256797

Epoch: 6| Step: 11
Training loss: 1.3872082233428955
Validation loss: 2.075463116168976

Epoch: 6| Step: 12
Training loss: 1.6022181510925293
Validation loss: 2.041366537412008

Epoch: 6| Step: 13
Training loss: 1.273164987564087
Validation loss: 2.0658005475997925

Epoch: 86| Step: 0
Training loss: 1.7934541702270508
Validation loss: 2.0544747908910117

Epoch: 6| Step: 1
Training loss: 1.4389619827270508
Validation loss: 2.0287997722625732

Epoch: 6| Step: 2
Training loss: 2.0386910438537598
Validation loss: 2.051495611667633

Epoch: 6| Step: 3
Training loss: 1.927880048751831
Validation loss: 2.0254448652267456

Epoch: 6| Step: 4
Training loss: 1.8499683141708374
Validation loss: 2.042396306991577

Epoch: 6| Step: 5
Training loss: 1.8669503927230835
Validation loss: 2.0239979028701782

Epoch: 6| Step: 6
Training loss: 1.1572606563568115
Validation loss: 2.034664789835612

Epoch: 6| Step: 7
Training loss: 1.5921555757522583
Validation loss: 2.0190321803092957

Epoch: 6| Step: 8
Training loss: 1.5574769973754883
Validation loss: 2.017724871635437

Epoch: 6| Step: 9
Training loss: 1.7824586629867554
Validation loss: 2.043198068936666

Epoch: 6| Step: 10
Training loss: 1.546303391456604
Validation loss: 2.012347916762034

Epoch: 6| Step: 11
Training loss: 2.0490150451660156
Validation loss: 2.0560309886932373

Epoch: 6| Step: 12
Training loss: 2.336369514465332
Validation loss: 2.031591296195984

Epoch: 6| Step: 13
Training loss: 1.0815962553024292
Validation loss: 2.055600424607595

Epoch: 87| Step: 0
Training loss: 1.7787175178527832
Validation loss: 2.0266447265942893

Epoch: 6| Step: 1
Training loss: 1.7253961563110352
Validation loss: 2.0757626493771872

Epoch: 6| Step: 2
Training loss: 1.3139619827270508
Validation loss: 2.0312735438346863

Epoch: 6| Step: 3
Training loss: 2.1875252723693848
Validation loss: 2.057448128859202

Epoch: 6| Step: 4
Training loss: 2.1956989765167236
Validation loss: 2.0565144618352256

Epoch: 6| Step: 5
Training loss: 1.5243581533432007
Validation loss: 2.1011500358581543

Epoch: 6| Step: 6
Training loss: 1.3625478744506836
Validation loss: 2.069896618525187

Epoch: 6| Step: 7
Training loss: 1.5887393951416016
Validation loss: 2.0695146322250366

Epoch: 6| Step: 8
Training loss: 2.184807300567627
Validation loss: 2.049184958140055

Epoch: 6| Step: 9
Training loss: 1.3657500743865967
Validation loss: 2.0130109985669455

Epoch: 6| Step: 10
Training loss: 1.6124193668365479
Validation loss: 2.0032835006713867

Epoch: 6| Step: 11
Training loss: 1.767320990562439
Validation loss: 2.045925478140513

Epoch: 6| Step: 12
Training loss: 1.4694952964782715
Validation loss: 2.0579238136609397

Epoch: 6| Step: 13
Training loss: 1.484784722328186
Validation loss: 2.0169153412183127

Epoch: 88| Step: 0
Training loss: 1.6987144947052002
Validation loss: 2.0336506764094033

Epoch: 6| Step: 1
Training loss: 2.178776264190674
Validation loss: 2.051176428794861

Epoch: 6| Step: 2
Training loss: 1.3333394527435303
Validation loss: 2.0487854282061257

Epoch: 6| Step: 3
Training loss: 1.9511981010437012
Validation loss: 2.0484827359517417

Epoch: 6| Step: 4
Training loss: 1.640053629875183
Validation loss: 2.0541797478993735

Epoch: 6| Step: 5
Training loss: 2.140994071960449
Validation loss: 2.046614150206248

Epoch: 6| Step: 6
Training loss: 1.3100292682647705
Validation loss: 2.048624595006307

Epoch: 6| Step: 7
Training loss: 1.9164947271347046
Validation loss: 2.030014157295227

Epoch: 6| Step: 8
Training loss: 1.5471125841140747
Validation loss: 2.025368650754293

Epoch: 6| Step: 9
Training loss: 1.5801565647125244
Validation loss: 2.0460211038589478

Epoch: 6| Step: 10
Training loss: 1.1566729545593262
Validation loss: 2.033147871494293

Epoch: 6| Step: 11
Training loss: 1.8431710004806519
Validation loss: 2.044825712839762

Epoch: 6| Step: 12
Training loss: 1.375183343887329
Validation loss: 2.0678958694140115

Epoch: 6| Step: 13
Training loss: 1.863570213317871
Validation loss: 2.07855087518692

Epoch: 89| Step: 0
Training loss: 1.3943147659301758
Validation loss: 2.113276640574137

Epoch: 6| Step: 1
Training loss: 1.8304479122161865
Validation loss: 2.0987084905306497

Epoch: 6| Step: 2
Training loss: 1.768489122390747
Validation loss: 2.0774887601534524

Epoch: 6| Step: 3
Training loss: 1.732229232788086
Validation loss: 2.0976152420043945

Epoch: 6| Step: 4
Training loss: 1.4206931591033936
Validation loss: 2.045967916647593

Epoch: 6| Step: 5
Training loss: 1.6964771747589111
Validation loss: 2.019070585568746

Epoch: 6| Step: 6
Training loss: 2.041222095489502
Validation loss: 2.0347245136896768

Epoch: 6| Step: 7
Training loss: 1.667992353439331
Validation loss: 2.0341987212498984

Epoch: 6| Step: 8
Training loss: 1.8356635570526123
Validation loss: 2.0237481395403543

Epoch: 6| Step: 9
Training loss: 1.5059211254119873
Validation loss: 2.0222429235776267

Epoch: 6| Step: 10
Training loss: 2.1982383728027344
Validation loss: 2.017451524734497

Epoch: 6| Step: 11
Training loss: 1.2971045970916748
Validation loss: 2.0231685837109885

Epoch: 6| Step: 12
Training loss: 1.2658100128173828
Validation loss: 2.0618818203608194

Epoch: 6| Step: 13
Training loss: 1.8088246583938599
Validation loss: 2.042654196421305

Epoch: 90| Step: 0
Training loss: 1.4789981842041016
Validation loss: 2.0546316703160605

Epoch: 6| Step: 1
Training loss: 2.192896842956543
Validation loss: 2.0711663961410522

Epoch: 6| Step: 2
Training loss: 1.620850682258606
Validation loss: 2.046960492928823

Epoch: 6| Step: 3
Training loss: 1.4688844680786133
Validation loss: 2.0604228576024375

Epoch: 6| Step: 4
Training loss: 1.1155184507369995
Validation loss: 2.05469012260437

Epoch: 6| Step: 5
Training loss: 1.545257806777954
Validation loss: 2.0661620696385703

Epoch: 6| Step: 6
Training loss: 1.932918667793274
Validation loss: 2.0639482537905374

Epoch: 6| Step: 7
Training loss: 1.5889650583267212
Validation loss: 2.014389435450236

Epoch: 6| Step: 8
Training loss: 1.1869276762008667
Validation loss: 2.043100436528524

Epoch: 6| Step: 9
Training loss: 2.2585604190826416
Validation loss: 2.018164416154226

Epoch: 6| Step: 10
Training loss: 1.949051856994629
Validation loss: 2.0313012997309365

Epoch: 6| Step: 11
Training loss: 1.3238940238952637
Validation loss: 2.03309957186381

Epoch: 6| Step: 12
Training loss: 2.0754051208496094
Validation loss: 2.0453341404596963

Epoch: 6| Step: 13
Training loss: 1.5030354261398315
Validation loss: 2.0556208292643228

Epoch: 91| Step: 0
Training loss: 1.6171311140060425
Validation loss: 2.0810544888178506

Epoch: 6| Step: 1
Training loss: 1.868033528327942
Validation loss: 2.078337331612905

Epoch: 6| Step: 2
Training loss: 1.5037283897399902
Validation loss: 2.0339209040006003

Epoch: 6| Step: 3
Training loss: 1.2949023246765137
Validation loss: 2.0987863739331565

Epoch: 6| Step: 4
Training loss: 1.4624217748641968
Validation loss: 2.029399335384369

Epoch: 6| Step: 5
Training loss: 1.8721733093261719
Validation loss: 2.020842989285787

Epoch: 6| Step: 6
Training loss: 2.5168912410736084
Validation loss: 2.0531978805859885

Epoch: 6| Step: 7
Training loss: 1.7007596492767334
Validation loss: 2.0413999358812966

Epoch: 6| Step: 8
Training loss: 1.66530179977417
Validation loss: 2.075571854909261

Epoch: 6| Step: 9
Training loss: 1.5488495826721191
Validation loss: 2.063262621561686

Epoch: 6| Step: 10
Training loss: 1.2613277435302734
Validation loss: 2.054467419783274

Epoch: 6| Step: 11
Training loss: 1.9182753562927246
Validation loss: 2.013087272644043

Epoch: 6| Step: 12
Training loss: 1.38898503780365
Validation loss: 2.033610006173452

Epoch: 6| Step: 13
Training loss: 1.579310655593872
Validation loss: 2.0419668753941855

Epoch: 92| Step: 0
Training loss: 1.3905677795410156
Validation loss: 2.0168543656667075

Epoch: 6| Step: 1
Training loss: 1.2299237251281738
Validation loss: 2.056206981341044

Epoch: 6| Step: 2
Training loss: 1.649950385093689
Validation loss: 2.059366544087728

Epoch: 6| Step: 3
Training loss: 1.6760072708129883
Validation loss: 2.068020284175873

Epoch: 6| Step: 4
Training loss: 2.45124888420105
Validation loss: 2.062064786752065

Epoch: 6| Step: 5
Training loss: 1.3337197303771973
Validation loss: 2.070436875025431

Epoch: 6| Step: 6
Training loss: 1.2647759914398193
Validation loss: 2.03766131401062

Epoch: 6| Step: 7
Training loss: 1.4575045108795166
Validation loss: 2.032813847064972

Epoch: 6| Step: 8
Training loss: 1.6282894611358643
Validation loss: 2.0805500547091165

Epoch: 6| Step: 9
Training loss: 1.4627740383148193
Validation loss: 2.066382129987081

Epoch: 6| Step: 10
Training loss: 1.6509639024734497
Validation loss: 2.042542497316996

Epoch: 6| Step: 11
Training loss: 2.324171543121338
Validation loss: 2.0495089292526245

Epoch: 6| Step: 12
Training loss: 1.3329843282699585
Validation loss: 2.050827364126841

Epoch: 6| Step: 13
Training loss: 2.5263218879699707
Validation loss: 2.003737489382426

Epoch: 93| Step: 0
Training loss: 1.425797939300537
Validation loss: 2.059194028377533

Epoch: 6| Step: 1
Training loss: 2.324019432067871
Validation loss: 2.0359230836232505

Epoch: 6| Step: 2
Training loss: 1.802120327949524
Validation loss: 2.067090153694153

Epoch: 6| Step: 3
Training loss: 1.7695690393447876
Validation loss: 2.0680720011393228

Epoch: 6| Step: 4
Training loss: 2.0249390602111816
Validation loss: 2.0637932419776917

Epoch: 6| Step: 5
Training loss: 1.2837743759155273
Validation loss: 2.045909861723582

Epoch: 6| Step: 6
Training loss: 1.8957126140594482
Validation loss: 2.08551953236262

Epoch: 6| Step: 7
Training loss: 1.3205540180206299
Validation loss: 2.073300917943319

Epoch: 6| Step: 8
Training loss: 1.4300593137741089
Validation loss: 2.091797868410746

Epoch: 6| Step: 9
Training loss: 1.272965431213379
Validation loss: 2.0917029778162637

Epoch: 6| Step: 10
Training loss: 1.826197862625122
Validation loss: 2.041427512963613

Epoch: 6| Step: 11
Training loss: 1.8881289958953857
Validation loss: 2.0402254859606423

Epoch: 6| Step: 12
Training loss: 1.3862147331237793
Validation loss: 2.076750874519348

Epoch: 6| Step: 13
Training loss: 1.2472145557403564
Validation loss: 2.0920356909434

Epoch: 94| Step: 0
Training loss: 1.4816701412200928
Validation loss: 2.069778303305308

Epoch: 6| Step: 1
Training loss: 2.0504188537597656
Validation loss: 2.063059687614441

Epoch: 6| Step: 2
Training loss: 1.3386402130126953
Validation loss: 2.0513325532277427

Epoch: 6| Step: 3
Training loss: 1.8288910388946533
Validation loss: 2.04020231962204

Epoch: 6| Step: 4
Training loss: 1.5527780055999756
Validation loss: 2.0374714533487954

Epoch: 6| Step: 5
Training loss: 1.8436863422393799
Validation loss: 2.049658934275309

Epoch: 6| Step: 6
Training loss: 1.9675499200820923
Validation loss: 2.075180947780609

Epoch: 6| Step: 7
Training loss: 1.3024911880493164
Validation loss: 2.0592614014943442

Epoch: 6| Step: 8
Training loss: 1.4039089679718018
Validation loss: 2.070186952749888

Epoch: 6| Step: 9
Training loss: 1.6766278743743896
Validation loss: 2.0542611479759216

Epoch: 6| Step: 10
Training loss: 1.592733383178711
Validation loss: 2.064150114854177

Epoch: 6| Step: 11
Training loss: 1.743977427482605
Validation loss: 2.0758163134256997

Epoch: 6| Step: 12
Training loss: 1.905578374862671
Validation loss: 2.041143298149109

Epoch: 6| Step: 13
Training loss: 1.075091004371643
Validation loss: 2.0854176680246987

Epoch: 95| Step: 0
Training loss: 2.799926280975342
Validation loss: 2.081294516722361

Epoch: 6| Step: 1
Training loss: 2.2827069759368896
Validation loss: 1.9990528027216594

Epoch: 6| Step: 2
Training loss: 1.5025274753570557
Validation loss: 2.0683960715929666

Epoch: 6| Step: 3
Training loss: 1.6468417644500732
Validation loss: 2.0751145283381143

Epoch: 6| Step: 4
Training loss: 1.8910707235336304
Validation loss: 2.067516545454661

Epoch: 6| Step: 5
Training loss: 1.7479934692382812
Validation loss: 2.018308699131012

Epoch: 6| Step: 6
Training loss: 1.2169736623764038
Validation loss: 2.0933446884155273

Epoch: 6| Step: 7
Training loss: 1.6013693809509277
Validation loss: 2.0523372888565063

Epoch: 6| Step: 8
Training loss: 1.662980079650879
Validation loss: 2.0621560414632163

Epoch: 6| Step: 9
Training loss: 1.5357227325439453
Validation loss: 2.0804709792137146

Epoch: 6| Step: 10
Training loss: 1.2344908714294434
Validation loss: 2.073583443959554

Epoch: 6| Step: 11
Training loss: 1.2447497844696045
Validation loss: 2.0470659136772156

Epoch: 6| Step: 12
Training loss: 1.7797300815582275
Validation loss: 2.060293177763621

Epoch: 6| Step: 13
Training loss: 0.9536754488945007
Validation loss: 2.074400623639425

Epoch: 96| Step: 0
Training loss: 2.085266351699829
Validation loss: 2.0544283390045166

Epoch: 6| Step: 1
Training loss: 1.6315830945968628
Validation loss: 2.047368029753367

Epoch: 6| Step: 2
Training loss: 1.620637059211731
Validation loss: 2.0806480844815574

Epoch: 6| Step: 3
Training loss: 1.5494024753570557
Validation loss: 2.066875159740448

Epoch: 6| Step: 4
Training loss: 1.2687218189239502
Validation loss: 2.06934247414271

Epoch: 6| Step: 5
Training loss: 1.3202356100082397
Validation loss: 2.049074033896128

Epoch: 6| Step: 6
Training loss: 1.4045228958129883
Validation loss: 2.044435441493988

Epoch: 6| Step: 7
Training loss: 2.110382556915283
Validation loss: 2.072754720846812

Epoch: 6| Step: 8
Training loss: 2.107708692550659
Validation loss: 2.072775741418203

Epoch: 6| Step: 9
Training loss: 2.1410374641418457
Validation loss: 2.069699227809906

Epoch: 6| Step: 10
Training loss: 1.8011473417282104
Validation loss: 2.0876834789911904

Epoch: 6| Step: 11
Training loss: 1.1610875129699707
Validation loss: 2.072455366452535

Epoch: 6| Step: 12
Training loss: 1.6906113624572754
Validation loss: 2.0619082848230996

Epoch: 6| Step: 13
Training loss: 1.3682794570922852
Validation loss: 2.064244508743286

Epoch: 97| Step: 0
Training loss: 1.8723986148834229
Validation loss: 2.094594160715739

Epoch: 6| Step: 1
Training loss: 0.8937910199165344
Validation loss: 2.041883965333303

Epoch: 6| Step: 2
Training loss: 2.4650163650512695
Validation loss: 2.080086886882782

Epoch: 6| Step: 3
Training loss: 0.9507705569267273
Validation loss: 2.039442698160807

Epoch: 6| Step: 4
Training loss: 1.8460922241210938
Validation loss: 2.032719631989797

Epoch: 6| Step: 5
Training loss: 0.9635286331176758
Validation loss: 2.0371901790301004

Epoch: 6| Step: 6
Training loss: 1.6626849174499512
Validation loss: 2.048906624317169

Epoch: 6| Step: 7
Training loss: 1.724347710609436
Validation loss: 2.0456057588259378

Epoch: 6| Step: 8
Training loss: 1.4026734828948975
Validation loss: 2.0294445753097534

Epoch: 6| Step: 9
Training loss: 1.184214472770691
Validation loss: 2.059925138950348

Epoch: 6| Step: 10
Training loss: 1.9024776220321655
Validation loss: 2.0483158429463706

Epoch: 6| Step: 11
Training loss: 1.5564229488372803
Validation loss: 2.086112678050995

Epoch: 6| Step: 12
Training loss: 1.6916980743408203
Validation loss: 2.067743440469106

Epoch: 6| Step: 13
Training loss: 2.3025691509246826
Validation loss: 2.0677072008450827

Epoch: 98| Step: 0
Training loss: 1.9136581420898438
Validation loss: 2.08312859137853

Epoch: 6| Step: 1
Training loss: 1.8762558698654175
Validation loss: 2.085523168245951

Epoch: 6| Step: 2
Training loss: 1.396527886390686
Validation loss: 2.107389509677887

Epoch: 6| Step: 3
Training loss: 2.1472880840301514
Validation loss: 2.0895958145459494

Epoch: 6| Step: 4
Training loss: 1.429306149482727
Validation loss: 2.0595001777013144

Epoch: 6| Step: 5
Training loss: 1.4910998344421387
Validation loss: 2.035491426785787

Epoch: 6| Step: 6
Training loss: 1.4758778810501099
Validation loss: 2.0610880057017007

Epoch: 6| Step: 7
Training loss: 1.3743836879730225
Validation loss: 2.058655877908071

Epoch: 6| Step: 8
Training loss: 1.383334755897522
Validation loss: 2.033944328625997

Epoch: 6| Step: 9
Training loss: 1.9057154655456543
Validation loss: 2.0385735432306924

Epoch: 6| Step: 10
Training loss: 1.1803094148635864
Validation loss: 2.03711199760437

Epoch: 6| Step: 11
Training loss: 1.7458491325378418
Validation loss: 2.067392567793528

Epoch: 6| Step: 12
Training loss: 1.799170732498169
Validation loss: 2.0431000192960105

Epoch: 6| Step: 13
Training loss: 1.0190659761428833
Validation loss: 2.0157673358917236

Epoch: 99| Step: 0
Training loss: 1.386006236076355
Validation loss: 2.0782505671183267

Epoch: 6| Step: 1
Training loss: 1.8772919178009033
Validation loss: 2.074385941028595

Epoch: 6| Step: 2
Training loss: 1.6304526329040527
Validation loss: 2.0789371728897095

Epoch: 6| Step: 3
Training loss: 1.0358806848526
Validation loss: 2.046486516793569

Epoch: 6| Step: 4
Training loss: 1.1771742105484009
Validation loss: 2.075344145298004

Epoch: 6| Step: 5
Training loss: 1.3475955724716187
Validation loss: 2.100138028462728

Epoch: 6| Step: 6
Training loss: 2.3358139991760254
Validation loss: 2.053446372350057

Epoch: 6| Step: 7
Training loss: 1.483299970626831
Validation loss: 2.1051998933156333

Epoch: 6| Step: 8
Training loss: 1.9877078533172607
Validation loss: 2.0925169388453164

Epoch: 6| Step: 9
Training loss: 1.4721181392669678
Validation loss: 2.0597774585088096

Epoch: 6| Step: 10
Training loss: 1.789362907409668
Validation loss: 2.112153629461924

Epoch: 6| Step: 11
Training loss: 1.478783369064331
Validation loss: 2.0943085749944053

Epoch: 6| Step: 12
Training loss: 1.9070309400558472
Validation loss: 2.106880565484365

Epoch: 6| Step: 13
Training loss: 1.647871971130371
Validation loss: 2.1023941040039062

Epoch: 100| Step: 0
Training loss: 1.4728052616119385
Validation loss: 2.061004956563314

Epoch: 6| Step: 1
Training loss: 1.5825352668762207
Validation loss: 2.069230377674103

Epoch: 6| Step: 2
Training loss: 1.7610585689544678
Validation loss: 2.1031603614489236

Epoch: 6| Step: 3
Training loss: 0.9025571346282959
Validation loss: 2.0460753043492637

Epoch: 6| Step: 4
Training loss: 1.542747139930725
Validation loss: 2.036153495311737

Epoch: 6| Step: 5
Training loss: 1.5517737865447998
Validation loss: 2.082399090131124

Epoch: 6| Step: 6
Training loss: 1.689813256263733
Validation loss: 2.0684115489323935

Epoch: 6| Step: 7
Training loss: 1.665097951889038
Validation loss: 2.0960447589556375

Epoch: 6| Step: 8
Training loss: 1.2603282928466797
Validation loss: 2.108329733212789

Epoch: 6| Step: 9
Training loss: 1.5434906482696533
Validation loss: 2.0780223409334817

Epoch: 6| Step: 10
Training loss: 2.177619695663452
Validation loss: 2.0718818505605063

Epoch: 6| Step: 11
Training loss: 1.2968380451202393
Validation loss: 2.0494563579559326

Epoch: 6| Step: 12
Training loss: 1.7219157218933105
Validation loss: 2.0461186369260154

Epoch: 6| Step: 13
Training loss: 1.9946882724761963
Validation loss: 2.0430204470952353

Epoch: 101| Step: 0
Training loss: 1.7268112897872925
Validation loss: 2.053354541460673

Epoch: 6| Step: 1
Training loss: 1.132889986038208
Validation loss: 2.0321833292643228

Epoch: 6| Step: 2
Training loss: 1.9964909553527832
Validation loss: 2.046997904777527

Epoch: 6| Step: 3
Training loss: 1.5842056274414062
Validation loss: 2.031290868918101

Epoch: 6| Step: 4
Training loss: 1.3926379680633545
Validation loss: 2.0349032282829285

Epoch: 6| Step: 5
Training loss: 1.5310572385787964
Validation loss: 2.0717219909032187

Epoch: 6| Step: 6
Training loss: 1.7872344255447388
Validation loss: 2.0587462186813354

Epoch: 6| Step: 7
Training loss: 1.00118887424469
Validation loss: 2.065492828687032

Epoch: 6| Step: 8
Training loss: 2.591226577758789
Validation loss: 2.0432968537012735

Epoch: 6| Step: 9
Training loss: 1.6363898515701294
Validation loss: 2.099453548590342

Epoch: 6| Step: 10
Training loss: 1.0524466037750244
Validation loss: 2.040740509827932

Epoch: 6| Step: 11
Training loss: 1.3147529363632202
Validation loss: 2.0733032822608948

Epoch: 6| Step: 12
Training loss: 1.6913070678710938
Validation loss: 2.0059834917386374

Epoch: 6| Step: 13
Training loss: 1.7589458227157593
Validation loss: 2.0371598998705545

Epoch: 102| Step: 0
Training loss: 1.2892483472824097
Validation loss: 2.042774200439453

Epoch: 6| Step: 1
Training loss: 1.7644538879394531
Validation loss: 2.049459000428518

Epoch: 6| Step: 2
Training loss: 1.321282148361206
Validation loss: 2.043077806631724

Epoch: 6| Step: 3
Training loss: 1.5758845806121826
Validation loss: 2.065556307633718

Epoch: 6| Step: 4
Training loss: 1.8607099056243896
Validation loss: 2.0707184274991355

Epoch: 6| Step: 5
Training loss: 1.583680272102356
Validation loss: 2.0589610735575357

Epoch: 6| Step: 6
Training loss: 1.613927960395813
Validation loss: 2.096823831399282

Epoch: 6| Step: 7
Training loss: 1.8715730905532837
Validation loss: 2.097838799158732

Epoch: 6| Step: 8
Training loss: 1.9076097011566162
Validation loss: 2.1185545325279236

Epoch: 6| Step: 9
Training loss: 1.6667191982269287
Validation loss: 2.091496209303538

Epoch: 6| Step: 10
Training loss: 2.3324689865112305
Validation loss: 2.071318964163462

Epoch: 6| Step: 11
Training loss: 0.8678218126296997
Validation loss: 2.0424121419588723

Epoch: 6| Step: 12
Training loss: 0.9110037088394165
Validation loss: 2.059069196383158

Epoch: 6| Step: 13
Training loss: 1.6013104915618896
Validation loss: 2.0384095509847007

Epoch: 103| Step: 0
Training loss: 1.892331600189209
Validation loss: 2.0377939343452454

Epoch: 6| Step: 1
Training loss: 1.242995023727417
Validation loss: 2.0028112530708313

Epoch: 6| Step: 2
Training loss: 1.8774549961090088
Validation loss: 2.0338491002718606

Epoch: 6| Step: 3
Training loss: 2.135429859161377
Validation loss: 2.0134536623954773

Epoch: 6| Step: 4
Training loss: 1.3319905996322632
Validation loss: 2.0832156936327615

Epoch: 6| Step: 5
Training loss: 0.8097546696662903
Validation loss: 2.0889292558034263

Epoch: 6| Step: 6
Training loss: 1.9076595306396484
Validation loss: 2.0330137809117637

Epoch: 6| Step: 7
Training loss: 1.2960078716278076
Validation loss: 2.0817339619000754

Epoch: 6| Step: 8
Training loss: 1.7065966129302979
Validation loss: 2.110491156578064

Epoch: 6| Step: 9
Training loss: 1.7558704614639282
Validation loss: 2.0590136647224426

Epoch: 6| Step: 10
Training loss: 1.540226697921753
Validation loss: 2.0624132553736367

Epoch: 6| Step: 11
Training loss: 1.5877959728240967
Validation loss: 2.054981609185537

Epoch: 6| Step: 12
Training loss: 1.086960792541504
Validation loss: 2.045746922492981

Epoch: 6| Step: 13
Training loss: 1.8164536952972412
Validation loss: 2.061155637105306

Epoch: 104| Step: 0
Training loss: 1.5270147323608398
Validation loss: 2.0303110678990683

Epoch: 6| Step: 1
Training loss: 1.9478988647460938
Validation loss: 2.0340173641840615

Epoch: 6| Step: 2
Training loss: 1.5320029258728027
Validation loss: 2.0636176665623984

Epoch: 6| Step: 3
Training loss: 2.027538299560547
Validation loss: 2.0626145799954734

Epoch: 6| Step: 4
Training loss: 1.2894740104675293
Validation loss: 2.0311866799990335

Epoch: 6| Step: 5
Training loss: 1.6814188957214355
Validation loss: 2.0397629737854004

Epoch: 6| Step: 6
Training loss: 1.1737515926361084
Validation loss: 2.097151438395182

Epoch: 6| Step: 7
Training loss: 1.7709723711013794
Validation loss: 2.0922455191612244

Epoch: 6| Step: 8
Training loss: 1.4650166034698486
Validation loss: 2.0996230840682983

Epoch: 6| Step: 9
Training loss: 1.7176246643066406
Validation loss: 2.119672159353892

Epoch: 6| Step: 10
Training loss: 1.2535438537597656
Validation loss: 2.1128554542859397

Epoch: 6| Step: 11
Training loss: 1.5029674768447876
Validation loss: 2.1214512983957925

Epoch: 6| Step: 12
Training loss: 1.7064067125320435
Validation loss: 2.054043928782145

Epoch: 6| Step: 13
Training loss: 1.4880261421203613
Validation loss: 2.0673125783602395

Epoch: 105| Step: 0
Training loss: 1.2675719261169434
Validation loss: 2.0426814357439675

Epoch: 6| Step: 1
Training loss: 2.103410243988037
Validation loss: 2.04643980662028

Epoch: 6| Step: 2
Training loss: 1.5823765993118286
Validation loss: 2.040111462275187

Epoch: 6| Step: 3
Training loss: 1.2459681034088135
Validation loss: 2.016148050626119

Epoch: 6| Step: 4
Training loss: 2.0361783504486084
Validation loss: 2.018617630004883

Epoch: 6| Step: 5
Training loss: 1.259669303894043
Validation loss: 2.0283788243929544

Epoch: 6| Step: 6
Training loss: 1.3186867237091064
Validation loss: 2.0552114844322205

Epoch: 6| Step: 7
Training loss: 1.3230335712432861
Validation loss: 2.0297707319259644

Epoch: 6| Step: 8
Training loss: 1.5555453300476074
Validation loss: 2.0659228761990867

Epoch: 6| Step: 9
Training loss: 1.4601082801818848
Validation loss: 2.061636527379354

Epoch: 6| Step: 10
Training loss: 2.017578601837158
Validation loss: 2.0852327148119607

Epoch: 6| Step: 11
Training loss: 1.1624476909637451
Validation loss: 2.078549345334371

Epoch: 6| Step: 12
Training loss: 2.0343589782714844
Validation loss: 2.096854647000631

Epoch: 6| Step: 13
Training loss: 1.6372219324111938
Validation loss: 2.108360528945923

Epoch: 106| Step: 0
Training loss: 1.3021368980407715
Validation loss: 2.0974736412366233

Epoch: 6| Step: 1
Training loss: 1.6049737930297852
Validation loss: 2.0941834449768066

Epoch: 6| Step: 2
Training loss: 1.214860439300537
Validation loss: 2.1352468927701316

Epoch: 6| Step: 3
Training loss: 1.4174119234085083
Validation loss: 2.1329516967137656

Epoch: 6| Step: 4
Training loss: 1.9761736392974854
Validation loss: 2.090648969014486

Epoch: 6| Step: 5
Training loss: 1.942082405090332
Validation loss: 2.070440351963043

Epoch: 6| Step: 6
Training loss: 1.5949325561523438
Validation loss: 2.0797536969184875

Epoch: 6| Step: 7
Training loss: 1.9696893692016602
Validation loss: 2.055724859237671

Epoch: 6| Step: 8
Training loss: 1.8661738634109497
Validation loss: 2.042165835698446

Epoch: 6| Step: 9
Training loss: 0.9734370708465576
Validation loss: 2.059951980908712

Epoch: 6| Step: 10
Training loss: 1.2459782361984253
Validation loss: 2.0964571634928384

Epoch: 6| Step: 11
Training loss: 1.990602731704712
Validation loss: 2.0513888398806253

Epoch: 6| Step: 12
Training loss: 1.518351674079895
Validation loss: 2.074335296948751

Epoch: 6| Step: 13
Training loss: 1.468272089958191
Validation loss: 2.031260589758555

Epoch: 107| Step: 0
Training loss: 1.295825719833374
Validation loss: 2.029051740964254

Epoch: 6| Step: 1
Training loss: 0.9184103012084961
Validation loss: 2.046487251917521

Epoch: 6| Step: 2
Training loss: 1.6678478717803955
Validation loss: 2.0279561082522073

Epoch: 6| Step: 3
Training loss: 1.2083215713500977
Validation loss: 2.080277224381765

Epoch: 6| Step: 4
Training loss: 1.795767903327942
Validation loss: 2.0802917877833047

Epoch: 6| Step: 5
Training loss: 1.3546955585479736
Validation loss: 2.1067392230033875

Epoch: 6| Step: 6
Training loss: 1.5110297203063965
Validation loss: 2.0929492513338723

Epoch: 6| Step: 7
Training loss: 1.779280185699463
Validation loss: 2.1437359054883323

Epoch: 6| Step: 8
Training loss: 1.3843083381652832
Validation loss: 2.125244895617167

Epoch: 6| Step: 9
Training loss: 1.516502857208252
Validation loss: 2.1128161946932473

Epoch: 6| Step: 10
Training loss: 1.6453125476837158
Validation loss: 2.1136801838874817

Epoch: 6| Step: 11
Training loss: 2.1619114875793457
Validation loss: 2.0536978443463645

Epoch: 6| Step: 12
Training loss: 1.52957284450531
Validation loss: 2.034248391787211

Epoch: 6| Step: 13
Training loss: 1.5580854415893555
Validation loss: 2.0514755249023438

Epoch: 108| Step: 0
Training loss: 1.7427165508270264
Validation loss: 2.059951663017273

Epoch: 6| Step: 1
Training loss: 1.802076816558838
Validation loss: 2.048413713773092

Epoch: 6| Step: 2
Training loss: 1.7709765434265137
Validation loss: 2.0659525394439697

Epoch: 6| Step: 3
Training loss: 1.735511302947998
Validation loss: 2.0465298096338906

Epoch: 6| Step: 4
Training loss: 1.7612277269363403
Validation loss: 2.064819653828939

Epoch: 6| Step: 5
Training loss: 1.8362538814544678
Validation loss: 2.0444769859313965

Epoch: 6| Step: 6
Training loss: 1.4371038675308228
Validation loss: 2.0809454321861267

Epoch: 6| Step: 7
Training loss: 1.1528300046920776
Validation loss: 2.0632979472478232

Epoch: 6| Step: 8
Training loss: 1.1288626194000244
Validation loss: 2.0938695867856345

Epoch: 6| Step: 9
Training loss: 1.722705602645874
Validation loss: 2.0685426394144693

Epoch: 6| Step: 10
Training loss: 1.818172574043274
Validation loss: 2.13514777024587

Epoch: 6| Step: 11
Training loss: 1.3480874300003052
Validation loss: 2.1666696071624756

Epoch: 6| Step: 12
Training loss: 1.444467544555664
Validation loss: 2.0958207050959268

Epoch: 6| Step: 13
Training loss: 0.8636480569839478
Validation loss: 2.072243253389994

Epoch: 109| Step: 0
Training loss: 1.5763437747955322
Validation loss: 2.062003791332245

Epoch: 6| Step: 1
Training loss: 1.0250368118286133
Validation loss: 2.062030474344889

Epoch: 6| Step: 2
Training loss: 1.787207841873169
Validation loss: 2.002294143040975

Epoch: 6| Step: 3
Training loss: 1.3693478107452393
Validation loss: 2.0756083925565085

Epoch: 6| Step: 4
Training loss: 2.6812491416931152
Validation loss: 2.0585758487383523

Epoch: 6| Step: 5
Training loss: 1.2180362939834595
Validation loss: 2.0260205268859863

Epoch: 6| Step: 6
Training loss: 1.857470154762268
Validation loss: 2.0526829957962036

Epoch: 6| Step: 7
Training loss: 1.2431275844573975
Validation loss: 2.0335620443026223

Epoch: 6| Step: 8
Training loss: 1.9279944896697998
Validation loss: 2.04580291112264

Epoch: 6| Step: 9
Training loss: 1.3922892808914185
Validation loss: 2.067522486050924

Epoch: 6| Step: 10
Training loss: 1.0527913570404053
Validation loss: 2.0523343682289124

Epoch: 6| Step: 11
Training loss: 1.4440977573394775
Validation loss: 2.0718065897623696

Epoch: 6| Step: 12
Training loss: 1.363229751586914
Validation loss: 2.0532662868499756

Epoch: 6| Step: 13
Training loss: 1.2250467538833618
Validation loss: 2.0735355615615845

Epoch: 110| Step: 0
Training loss: 2.0494136810302734
Validation loss: 2.1014615297317505

Epoch: 6| Step: 1
Training loss: 1.1624771356582642
Validation loss: 2.116841276486715

Epoch: 6| Step: 2
Training loss: 1.5679024457931519
Validation loss: 2.136484920978546

Epoch: 6| Step: 3
Training loss: 1.6640465259552002
Validation loss: 2.1304585933685303

Epoch: 6| Step: 4
Training loss: 1.048999547958374
Validation loss: 2.152608335018158

Epoch: 6| Step: 5
Training loss: 1.4563839435577393
Validation loss: 2.138176421324412

Epoch: 6| Step: 6
Training loss: 2.2009658813476562
Validation loss: 2.1476889650026956

Epoch: 6| Step: 7
Training loss: 1.854553461074829
Validation loss: 2.089633524417877

Epoch: 6| Step: 8
Training loss: 1.476572871208191
Validation loss: 2.0794604420661926

Epoch: 6| Step: 9
Training loss: 1.1985039710998535
Validation loss: 2.0387261509895325

Epoch: 6| Step: 10
Training loss: 1.482041358947754
Validation loss: 2.0239001512527466

Epoch: 6| Step: 11
Training loss: 1.6582584381103516
Validation loss: 2.0255658825238547

Epoch: 6| Step: 12
Training loss: 1.3771836757659912
Validation loss: 2.051456113656362

Epoch: 6| Step: 13
Training loss: 1.41949462890625
Validation loss: 2.068138360977173

Epoch: 111| Step: 0
Training loss: 2.0435233116149902
Validation loss: 2.059123476346334

Epoch: 6| Step: 1
Training loss: 1.1103055477142334
Validation loss: 2.065905272960663

Epoch: 6| Step: 2
Training loss: 1.6136761903762817
Validation loss: 2.1017528573671975

Epoch: 6| Step: 3
Training loss: 0.8004193305969238
Validation loss: 2.046224296092987

Epoch: 6| Step: 4
Training loss: 1.4858357906341553
Validation loss: 2.067586064338684

Epoch: 6| Step: 5
Training loss: 1.7189443111419678
Validation loss: 2.04372908671697

Epoch: 6| Step: 6
Training loss: 1.749734878540039
Validation loss: 2.076264182726542

Epoch: 6| Step: 7
Training loss: 1.290356993675232
Validation loss: 2.05682639280955

Epoch: 6| Step: 8
Training loss: 1.5327478647232056
Validation loss: 2.0777321259180703

Epoch: 6| Step: 9
Training loss: 1.9311954975128174
Validation loss: 2.0402944485346475

Epoch: 6| Step: 10
Training loss: 1.3544445037841797
Validation loss: 2.0276609460512796

Epoch: 6| Step: 11
Training loss: 1.4163503646850586
Validation loss: 2.02056086063385

Epoch: 6| Step: 12
Training loss: 1.7920334339141846
Validation loss: 2.057030737400055

Epoch: 6| Step: 13
Training loss: 1.0165998935699463
Validation loss: 2.0480764905611673

Epoch: 112| Step: 0
Training loss: 2.02480149269104
Validation loss: 2.0555936296780906

Epoch: 6| Step: 1
Training loss: 1.6197317838668823
Validation loss: 2.106690446535746

Epoch: 6| Step: 2
Training loss: 1.027005910873413
Validation loss: 2.0608919262886047

Epoch: 6| Step: 3
Training loss: 1.2849245071411133
Validation loss: 2.0672828555107117

Epoch: 6| Step: 4
Training loss: 2.0644237995147705
Validation loss: 2.0726340810457864

Epoch: 6| Step: 5
Training loss: 1.964205265045166
Validation loss: 2.1241102814674377

Epoch: 6| Step: 6
Training loss: 1.8884397745132446
Validation loss: 2.128066976865133

Epoch: 6| Step: 7
Training loss: 1.7603092193603516
Validation loss: 2.084277927875519

Epoch: 6| Step: 8
Training loss: 1.2552909851074219
Validation loss: 2.071482797463735

Epoch: 6| Step: 9
Training loss: 1.3465979099273682
Validation loss: 2.0742027759552

Epoch: 6| Step: 10
Training loss: 1.3158403635025024
Validation loss: 2.044268329938253

Epoch: 6| Step: 11
Training loss: 1.3416811227798462
Validation loss: 2.055235286553701

Epoch: 6| Step: 12
Training loss: 1.1478971242904663
Validation loss: 2.0527460177739463

Epoch: 6| Step: 13
Training loss: 1.2864692211151123
Validation loss: 2.0723554293314614

Epoch: 113| Step: 0
Training loss: 1.9890174865722656
Validation loss: 2.03118360042572

Epoch: 6| Step: 1
Training loss: 1.5114696025848389
Validation loss: 2.0560817321141562

Epoch: 6| Step: 2
Training loss: 0.6774610877037048
Validation loss: 2.0528436303138733

Epoch: 6| Step: 3
Training loss: 1.4019938707351685
Validation loss: 2.0242361426353455

Epoch: 6| Step: 4
Training loss: 1.6065192222595215
Validation loss: 2.0419497887293496

Epoch: 6| Step: 5
Training loss: 1.64765465259552
Validation loss: 2.0861902038256326

Epoch: 6| Step: 6
Training loss: 2.172199249267578
Validation loss: 2.0945461789766946

Epoch: 6| Step: 7
Training loss: 1.4377243518829346
Validation loss: 2.04899392525355

Epoch: 6| Step: 8
Training loss: 1.0922167301177979
Validation loss: 2.0904114842414856

Epoch: 6| Step: 9
Training loss: 1.3251519203186035
Validation loss: 2.069084664185842

Epoch: 6| Step: 10
Training loss: 1.7851186990737915
Validation loss: 2.0878790815671286

Epoch: 6| Step: 11
Training loss: 1.4615240097045898
Validation loss: 2.0750887791315713

Epoch: 6| Step: 12
Training loss: 1.5978844165802002
Validation loss: 2.0383639534314475

Epoch: 6| Step: 13
Training loss: 1.0769325494766235
Validation loss: 2.0678627689679465

Epoch: 114| Step: 0
Training loss: 1.585321307182312
Validation loss: 2.0360299348831177

Epoch: 6| Step: 1
Training loss: 1.489696741104126
Validation loss: 2.0764060417811074

Epoch: 6| Step: 2
Training loss: 1.2032341957092285
Validation loss: 2.0688462058703103

Epoch: 6| Step: 3
Training loss: 1.5325500965118408
Validation loss: 2.0739808479944863

Epoch: 6| Step: 4
Training loss: 1.7291830778121948
Validation loss: 2.0610323349634805

Epoch: 6| Step: 5
Training loss: 1.2105942964553833
Validation loss: 2.090390423933665

Epoch: 6| Step: 6
Training loss: 1.1502128839492798
Validation loss: 2.071407417456309

Epoch: 6| Step: 7
Training loss: 1.748410940170288
Validation loss: 2.0707250833511353

Epoch: 6| Step: 8
Training loss: 1.4630762338638306
Validation loss: 2.08902100721995

Epoch: 6| Step: 9
Training loss: 1.3892593383789062
Validation loss: 2.0874920090039573

Epoch: 6| Step: 10
Training loss: 1.3922568559646606
Validation loss: 2.1339539289474487

Epoch: 6| Step: 11
Training loss: 1.4256457090377808
Validation loss: 2.0461453000704446

Epoch: 6| Step: 12
Training loss: 1.5282702445983887
Validation loss: 2.0467244386672974

Epoch: 6| Step: 13
Training loss: 1.603209376335144
Validation loss: 2.0882293581962585

Epoch: 115| Step: 0
Training loss: 1.7697526216506958
Validation loss: 2.0508066415786743

Epoch: 6| Step: 1
Training loss: 1.1587713956832886
Validation loss: 2.043193260828654

Epoch: 6| Step: 2
Training loss: 1.5928945541381836
Validation loss: 2.040130694707235

Epoch: 6| Step: 3
Training loss: 0.6630783081054688
Validation loss: 2.0557497143745422

Epoch: 6| Step: 4
Training loss: 1.369009256362915
Validation loss: 2.069865047931671

Epoch: 6| Step: 5
Training loss: 1.4793519973754883
Validation loss: 2.1232627034187317

Epoch: 6| Step: 6
Training loss: 2.392594337463379
Validation loss: 2.119473377863566

Epoch: 6| Step: 7
Training loss: 1.722837209701538
Validation loss: 2.100723703702291

Epoch: 6| Step: 8
Training loss: 1.6653852462768555
Validation loss: 2.0902869502703347

Epoch: 6| Step: 9
Training loss: 1.2862074375152588
Validation loss: 2.074871997038523

Epoch: 6| Step: 10
Training loss: 1.4561011791229248
Validation loss: 2.0562596917152405

Epoch: 6| Step: 11
Training loss: 0.8256292343139648
Validation loss: 2.1242783466974893

Epoch: 6| Step: 12
Training loss: 1.1940383911132812
Validation loss: 2.0668257673581443

Epoch: 6| Step: 13
Training loss: 1.4697415828704834
Validation loss: 2.050123453140259

Epoch: 116| Step: 0
Training loss: 1.2551100254058838
Validation loss: 2.076031227906545

Epoch: 6| Step: 1
Training loss: 1.6581366062164307
Validation loss: 2.081211050351461

Epoch: 6| Step: 2
Training loss: 1.579424500465393
Validation loss: 2.059080719947815

Epoch: 6| Step: 3
Training loss: 1.520425796508789
Validation loss: 2.0570602814356485

Epoch: 6| Step: 4
Training loss: 1.0759309530258179
Validation loss: 2.0635761817296348

Epoch: 6| Step: 5
Training loss: 1.57155442237854
Validation loss: 2.0560532410939536

Epoch: 6| Step: 6
Training loss: 0.8815436363220215
Validation loss: 2.052873651186625

Epoch: 6| Step: 7
Training loss: 0.7935954332351685
Validation loss: 2.0905346075693765

Epoch: 6| Step: 8
Training loss: 1.392496109008789
Validation loss: 2.0647866328557334

Epoch: 6| Step: 9
Training loss: 1.5431272983551025
Validation loss: 2.1082327365875244

Epoch: 6| Step: 10
Training loss: 1.4145557880401611
Validation loss: 2.1074149211247764

Epoch: 6| Step: 11
Training loss: 1.6350319385528564
Validation loss: 2.1083478530248008

Epoch: 6| Step: 12
Training loss: 0.9692131280899048
Validation loss: 2.0659947395324707

Epoch: 6| Step: 13
Training loss: 2.463932514190674
Validation loss: 2.057472586631775

Epoch: 117| Step: 0
Training loss: 1.14923095703125
Validation loss: 2.060310165087382

Epoch: 6| Step: 1
Training loss: 2.0759637355804443
Validation loss: 2.048712650934855

Epoch: 6| Step: 2
Training loss: 1.9821338653564453
Validation loss: 2.0568897128105164

Epoch: 6| Step: 3
Training loss: 1.3855890035629272
Validation loss: 2.081552823384603

Epoch: 6| Step: 4
Training loss: 1.354681372642517
Validation loss: 2.0506017009417215

Epoch: 6| Step: 5
Training loss: 1.281845211982727
Validation loss: 2.044491986433665

Epoch: 6| Step: 6
Training loss: 1.575058937072754
Validation loss: 2.0133257110913596

Epoch: 6| Step: 7
Training loss: 1.4656927585601807
Validation loss: 2.1177287896474204

Epoch: 6| Step: 8
Training loss: 1.426109790802002
Validation loss: 2.019952416419983

Epoch: 6| Step: 9
Training loss: 0.9824164509773254
Validation loss: 2.0680531660715737

Epoch: 6| Step: 10
Training loss: 0.7936222553253174
Validation loss: 2.0205668807029724

Epoch: 6| Step: 11
Training loss: 1.5746030807495117
Validation loss: 2.033384919166565

Epoch: 6| Step: 12
Training loss: 1.3958402872085571
Validation loss: 2.1155998905499778

Epoch: 6| Step: 13
Training loss: 1.1956863403320312
Validation loss: 2.084035257498423

Epoch: 118| Step: 0
Training loss: 1.1943415403366089
Validation loss: 2.0790551900863647

Epoch: 6| Step: 1
Training loss: 2.005859851837158
Validation loss: 2.075367490450541

Epoch: 6| Step: 2
Training loss: 1.031716227531433
Validation loss: 2.1180646419525146

Epoch: 6| Step: 3
Training loss: 1.3343844413757324
Validation loss: 2.108485539754232

Epoch: 6| Step: 4
Training loss: 1.492716670036316
Validation loss: 2.1024328072865806

Epoch: 6| Step: 5
Training loss: 1.715883493423462
Validation loss: 2.1188225547472634

Epoch: 6| Step: 6
Training loss: 2.393789768218994
Validation loss: 2.093664904435476

Epoch: 6| Step: 7
Training loss: 1.3631768226623535
Validation loss: 2.1130834023157754

Epoch: 6| Step: 8
Training loss: 1.0232179164886475
Validation loss: 2.056130905946096

Epoch: 6| Step: 9
Training loss: 1.0072357654571533
Validation loss: 2.0818129777908325

Epoch: 6| Step: 10
Training loss: 1.6600589752197266
Validation loss: 2.057944734891256

Epoch: 6| Step: 11
Training loss: 1.2214275598526
Validation loss: 2.064659357070923

Epoch: 6| Step: 12
Training loss: 0.864422082901001
Validation loss: 2.05629825592041

Epoch: 6| Step: 13
Training loss: 1.6620867252349854
Validation loss: 2.0462051232655845

Epoch: 119| Step: 0
Training loss: 1.1612155437469482
Validation loss: 2.0896847446759543

Epoch: 6| Step: 1
Training loss: 1.4595370292663574
Validation loss: 2.0642475287119546

Epoch: 6| Step: 2
Training loss: 0.8182547092437744
Validation loss: 2.0650864640871682

Epoch: 6| Step: 3
Training loss: 1.6398513317108154
Validation loss: 2.1078377763430276

Epoch: 6| Step: 4
Training loss: 1.0920946598052979
Validation loss: 2.0724374850591025

Epoch: 6| Step: 5
Training loss: 1.2165687084197998
Validation loss: 2.084987203280131

Epoch: 6| Step: 6
Training loss: 1.4155738353729248
Validation loss: 2.1044816374778748

Epoch: 6| Step: 7
Training loss: 1.5887067317962646
Validation loss: 2.1023473938306174

Epoch: 6| Step: 8
Training loss: 0.8684217929840088
Validation loss: 2.0850117206573486

Epoch: 6| Step: 9
Training loss: 1.880316138267517
Validation loss: 2.081260840098063

Epoch: 6| Step: 10
Training loss: 1.4438750743865967
Validation loss: 2.0479069352149963

Epoch: 6| Step: 11
Training loss: 1.909807801246643
Validation loss: 2.0754049817721048

Epoch: 6| Step: 12
Training loss: 2.1006197929382324
Validation loss: 2.044679562250773

Epoch: 6| Step: 13
Training loss: 1.1499700546264648
Validation loss: 2.038631101449331

Epoch: 120| Step: 0
Training loss: 1.697974443435669
Validation loss: 2.0513570308685303

Epoch: 6| Step: 1
Training loss: 1.171210765838623
Validation loss: 2.0561994711558023

Epoch: 6| Step: 2
Training loss: 1.8276593685150146
Validation loss: 2.0870699882507324

Epoch: 6| Step: 3
Training loss: 1.1538281440734863
Validation loss: 2.0602856477101645

Epoch: 6| Step: 4
Training loss: 1.113411545753479
Validation loss: 2.086527725060781

Epoch: 6| Step: 5
Training loss: 0.9473262429237366
Validation loss: 2.075232903162638

Epoch: 6| Step: 6
Training loss: 1.6044795513153076
Validation loss: 2.1300549109776816

Epoch: 6| Step: 7
Training loss: 1.8044211864471436
Validation loss: 2.1221724351247153

Epoch: 6| Step: 8
Training loss: 1.525442361831665
Validation loss: 2.0970677733421326

Epoch: 6| Step: 9
Training loss: 2.095980405807495
Validation loss: 2.121342897415161

Epoch: 6| Step: 10
Training loss: 1.8863462209701538
Validation loss: 2.1399985949198403

Epoch: 6| Step: 11
Training loss: 1.1737509965896606
Validation loss: 2.1121270656585693

Epoch: 6| Step: 12
Training loss: 0.9132498502731323
Validation loss: 2.0693921645482383

Epoch: 6| Step: 13
Training loss: 0.9069477319717407
Validation loss: 2.0689759850502014

Epoch: 121| Step: 0
Training loss: 1.6376464366912842
Validation loss: 2.050281365712484

Epoch: 6| Step: 1
Training loss: 1.010973572731018
Validation loss: 2.0641091664632163

Epoch: 6| Step: 2
Training loss: 1.2513773441314697
Validation loss: 2.0423205693562827

Epoch: 6| Step: 3
Training loss: 1.6310617923736572
Validation loss: 2.0771849751472473

Epoch: 6| Step: 4
Training loss: 0.7922337055206299
Validation loss: 2.0711693167686462

Epoch: 6| Step: 5
Training loss: 1.682604432106018
Validation loss: 2.082644005616506

Epoch: 6| Step: 6
Training loss: 1.558729648590088
Validation loss: 2.0570998191833496

Epoch: 6| Step: 7
Training loss: 1.3233451843261719
Validation loss: 2.0626980861028037

Epoch: 6| Step: 8
Training loss: 1.2495934963226318
Validation loss: 2.0603515903155007

Epoch: 6| Step: 9
Training loss: 1.9265958070755005
Validation loss: 2.051785866419474

Epoch: 6| Step: 10
Training loss: 0.8337575197219849
Validation loss: 2.0683345397313437

Epoch: 6| Step: 11
Training loss: 1.8453471660614014
Validation loss: 2.053320566813151

Epoch: 6| Step: 12
Training loss: 1.6378332376480103
Validation loss: 2.0923291444778442

Epoch: 6| Step: 13
Training loss: 0.7819250822067261
Validation loss: 2.0500937700271606

Epoch: 122| Step: 0
Training loss: 2.3230154514312744
Validation loss: 2.0900440216064453

Epoch: 6| Step: 1
Training loss: 1.0462334156036377
Validation loss: 2.0583438078562417

Epoch: 6| Step: 2
Training loss: 1.2767207622528076
Validation loss: 2.0571823914845786

Epoch: 6| Step: 3
Training loss: 1.0026652812957764
Validation loss: 2.038824458916982

Epoch: 6| Step: 4
Training loss: 1.103547215461731
Validation loss: 2.0596251090367637

Epoch: 6| Step: 5
Training loss: 0.9929182529449463
Validation loss: 2.114158352216085

Epoch: 6| Step: 6
Training loss: 1.835810899734497
Validation loss: 2.1066867113113403

Epoch: 6| Step: 7
Training loss: 1.3282454013824463
Validation loss: 2.0863888263702393

Epoch: 6| Step: 8
Training loss: 1.201094388961792
Validation loss: 2.1216880480448403

Epoch: 6| Step: 9
Training loss: 0.9895299077033997
Validation loss: 2.105443219343821

Epoch: 6| Step: 10
Training loss: 1.6091116666793823
Validation loss: 2.1110100547472634

Epoch: 6| Step: 11
Training loss: 1.1993892192840576
Validation loss: 2.0816680192947388

Epoch: 6| Step: 12
Training loss: 1.571716070175171
Validation loss: 2.0636396606763205

Epoch: 6| Step: 13
Training loss: 1.7235310077667236
Validation loss: 2.047601878643036

Epoch: 123| Step: 0
Training loss: 1.4943050146102905
Validation loss: 2.0489649176597595

Epoch: 6| Step: 1
Training loss: 1.657989501953125
Validation loss: 2.0506450136502585

Epoch: 6| Step: 2
Training loss: 1.5014137029647827
Validation loss: 2.0216285387674966

Epoch: 6| Step: 3
Training loss: 1.4884474277496338
Validation loss: 2.0751413901646933

Epoch: 6| Step: 4
Training loss: 1.2921565771102905
Validation loss: 2.0794809261957803

Epoch: 6| Step: 5
Training loss: 1.4064894914627075
Validation loss: 2.0751572251319885

Epoch: 6| Step: 6
Training loss: 1.1709301471710205
Validation loss: 2.059133013089498

Epoch: 6| Step: 7
Training loss: 0.9244138598442078
Validation loss: 2.064665675163269

Epoch: 6| Step: 8
Training loss: 1.4736980199813843
Validation loss: 2.0745683511098227

Epoch: 6| Step: 9
Training loss: 1.1907243728637695
Validation loss: 2.075239638487498

Epoch: 6| Step: 10
Training loss: 1.9175963401794434
Validation loss: 2.0884082317352295

Epoch: 6| Step: 11
Training loss: 1.3650860786437988
Validation loss: 2.057467520236969

Epoch: 6| Step: 12
Training loss: 0.9166246056556702
Validation loss: 2.0955381989479065

Epoch: 6| Step: 13
Training loss: 1.1895662546157837
Validation loss: 2.0533057848612466

Epoch: 124| Step: 0
Training loss: 1.464766502380371
Validation loss: 2.03581432501475

Epoch: 6| Step: 1
Training loss: 1.2190287113189697
Validation loss: 2.0191057920455933

Epoch: 6| Step: 2
Training loss: 1.2181745767593384
Validation loss: 2.045862376689911

Epoch: 6| Step: 3
Training loss: 1.4319450855255127
Validation loss: 2.077817181746165

Epoch: 6| Step: 4
Training loss: 1.7156366109848022
Validation loss: 2.0585169196128845

Epoch: 6| Step: 5
Training loss: 1.3207732439041138
Validation loss: 2.1069753170013428

Epoch: 6| Step: 6
Training loss: 1.8106025457382202
Validation loss: 2.0643851359685264

Epoch: 6| Step: 7
Training loss: 1.928812026977539
Validation loss: 2.0579684178034463

Epoch: 6| Step: 8
Training loss: 1.1827144622802734
Validation loss: 2.0479716062545776

Epoch: 6| Step: 9
Training loss: 1.27754545211792
Validation loss: 2.085801661014557

Epoch: 6| Step: 10
Training loss: 0.6988450884819031
Validation loss: 2.073735555013021

Epoch: 6| Step: 11
Training loss: 1.3952455520629883
Validation loss: 2.061284283796946

Epoch: 6| Step: 12
Training loss: 1.3560351133346558
Validation loss: 2.0188252528508506

Epoch: 6| Step: 13
Training loss: 0.8981049060821533
Validation loss: 2.056985000769297

Epoch: 125| Step: 0
Training loss: 1.0646650791168213
Validation loss: 2.078364849090576

Epoch: 6| Step: 1
Training loss: 1.538788080215454
Validation loss: 2.0383108854293823

Epoch: 6| Step: 2
Training loss: 1.237322211265564
Validation loss: 2.0737324357032776

Epoch: 6| Step: 3
Training loss: 0.8239144086837769
Validation loss: 2.1135117212931314

Epoch: 6| Step: 4
Training loss: 1.5235681533813477
Validation loss: 2.101289451122284

Epoch: 6| Step: 5
Training loss: 1.8007110357284546
Validation loss: 2.109044353167216

Epoch: 6| Step: 6
Training loss: 0.8217755556106567
Validation loss: 2.109553873538971

Epoch: 6| Step: 7
Training loss: 1.074438452720642
Validation loss: 2.1076770027478537

Epoch: 6| Step: 8
Training loss: 1.5905598402023315
Validation loss: 2.0290355881055198

Epoch: 6| Step: 9
Training loss: 1.2488313913345337
Validation loss: 2.0703999201456704

Epoch: 6| Step: 10
Training loss: 1.6274693012237549
Validation loss: 2.0408790707588196

Epoch: 6| Step: 11
Training loss: 1.8113656044006348
Validation loss: 2.057719051837921

Epoch: 6| Step: 12
Training loss: 1.2512166500091553
Validation loss: 2.0256062944730124

Epoch: 6| Step: 13
Training loss: 1.6754233837127686
Validation loss: 2.060105303923289

Epoch: 126| Step: 0
Training loss: 1.1428704261779785
Validation loss: 2.081812580426534

Epoch: 6| Step: 1
Training loss: 1.2631200551986694
Validation loss: 2.0583730141321817

Epoch: 6| Step: 2
Training loss: 1.0953798294067383
Validation loss: 2.0359670321146646

Epoch: 6| Step: 3
Training loss: 1.4081612825393677
Validation loss: 2.0539838671684265

Epoch: 6| Step: 4
Training loss: 2.0091004371643066
Validation loss: 2.073889672756195

Epoch: 6| Step: 5
Training loss: 1.5530556440353394
Validation loss: 2.0197748939196267

Epoch: 6| Step: 6
Training loss: 1.474277377128601
Validation loss: 2.0484562118848166

Epoch: 6| Step: 7
Training loss: 0.7585688829421997
Validation loss: 2.1164448062578836

Epoch: 6| Step: 8
Training loss: 1.2915912866592407
Validation loss: 2.0904144446055093

Epoch: 6| Step: 9
Training loss: 1.254235029220581
Validation loss: 2.115153133869171

Epoch: 6| Step: 10
Training loss: 1.3455524444580078
Validation loss: 2.1585681438446045

Epoch: 6| Step: 11
Training loss: 1.8906618356704712
Validation loss: 2.1252453327178955

Epoch: 6| Step: 12
Training loss: 1.069756269454956
Validation loss: 2.0940431555112204

Epoch: 6| Step: 13
Training loss: 0.7814469933509827
Validation loss: 2.091611365477244

Epoch: 127| Step: 0
Training loss: 1.4294847249984741
Validation loss: 2.0904107093811035

Epoch: 6| Step: 1
Training loss: 1.025813341140747
Validation loss: 2.147411863009135

Epoch: 6| Step: 2
Training loss: 1.042378544807434
Validation loss: 2.068038582801819

Epoch: 6| Step: 3
Training loss: 0.8252750635147095
Validation loss: 2.095099925994873

Epoch: 6| Step: 4
Training loss: 0.9819568395614624
Validation loss: 2.0506722927093506

Epoch: 6| Step: 5
Training loss: 1.5110207796096802
Validation loss: 2.071971595287323

Epoch: 6| Step: 6
Training loss: 1.5973461866378784
Validation loss: 2.0630301237106323

Epoch: 6| Step: 7
Training loss: 1.1124413013458252
Validation loss: 2.0637799898783364

Epoch: 6| Step: 8
Training loss: 1.447472095489502
Validation loss: 2.070227841536204

Epoch: 6| Step: 9
Training loss: 1.451779842376709
Validation loss: 2.0706551472345986

Epoch: 6| Step: 10
Training loss: 1.3873072862625122
Validation loss: 2.070594390233358

Epoch: 6| Step: 11
Training loss: 1.2407176494598389
Validation loss: 2.051073213418325

Epoch: 6| Step: 12
Training loss: 1.7882225513458252
Validation loss: 2.12281596660614

Epoch: 6| Step: 13
Training loss: 1.2535247802734375
Validation loss: 2.1219520966211953

Epoch: 128| Step: 0
Training loss: 1.4366947412490845
Validation loss: 2.1331539154052734

Epoch: 6| Step: 1
Training loss: 1.509308099746704
Validation loss: 2.1037646333376565

Epoch: 6| Step: 2
Training loss: 1.26273512840271
Validation loss: 2.088183045387268

Epoch: 6| Step: 3
Training loss: 1.8358287811279297
Validation loss: 2.0608004331588745

Epoch: 6| Step: 4
Training loss: 1.2037992477416992
Validation loss: 2.055231789747874

Epoch: 6| Step: 5
Training loss: 1.2376877069473267
Validation loss: 2.0969595313072205

Epoch: 6| Step: 6
Training loss: 2.0459423065185547
Validation loss: 2.092295825481415

Epoch: 6| Step: 7
Training loss: 1.0011969804763794
Validation loss: 2.067056576410929

Epoch: 6| Step: 8
Training loss: 1.4874643087387085
Validation loss: 2.054661750793457

Epoch: 6| Step: 9
Training loss: 1.4017382860183716
Validation loss: 2.066580375035604

Epoch: 6| Step: 10
Training loss: 0.6222003698348999
Validation loss: 2.1151151855786643

Epoch: 6| Step: 11
Training loss: 1.167148470878601
Validation loss: 2.1090862353642783

Epoch: 6| Step: 12
Training loss: 1.0734065771102905
Validation loss: 2.160681366920471

Epoch: 6| Step: 13
Training loss: 1.0657413005828857
Validation loss: 2.106293201446533

Epoch: 129| Step: 0
Training loss: 1.2366852760314941
Validation loss: 2.0694284041722617

Epoch: 6| Step: 1
Training loss: 1.1525859832763672
Validation loss: 2.0781948963801065

Epoch: 6| Step: 2
Training loss: 1.6324560642242432
Validation loss: 2.0638093749682107

Epoch: 6| Step: 3
Training loss: 1.1601297855377197
Validation loss: 2.0756038824717202

Epoch: 6| Step: 4
Training loss: 1.7458986043930054
Validation loss: 2.075746695200602

Epoch: 6| Step: 5
Training loss: 1.3980371952056885
Validation loss: 2.0471951762835183

Epoch: 6| Step: 6
Training loss: 1.1608343124389648
Validation loss: 2.0516929626464844

Epoch: 6| Step: 7
Training loss: 0.8807037472724915
Validation loss: 2.0936283469200134

Epoch: 6| Step: 8
Training loss: 1.1339699029922485
Validation loss: 2.089379608631134

Epoch: 6| Step: 9
Training loss: 1.0898973941802979
Validation loss: 2.1170623103777566

Epoch: 6| Step: 10
Training loss: 1.8725064992904663
Validation loss: 2.091918468475342

Epoch: 6| Step: 11
Training loss: 1.5445518493652344
Validation loss: 2.1021323800086975

Epoch: 6| Step: 12
Training loss: 0.7323099374771118
Validation loss: 2.1093586683273315

Epoch: 6| Step: 13
Training loss: 1.5182909965515137
Validation loss: 2.058069666226705

Epoch: 130| Step: 0
Training loss: 1.6331435441970825
Validation loss: 2.099360207716624

Epoch: 6| Step: 1
Training loss: 1.038180947303772
Validation loss: 2.059313476085663

Epoch: 6| Step: 2
Training loss: 1.3926697969436646
Validation loss: 2.032325585683187

Epoch: 6| Step: 3
Training loss: 1.2810941934585571
Validation loss: 2.087785462538401

Epoch: 6| Step: 4
Training loss: 0.8277837634086609
Validation loss: 2.1010831197102866

Epoch: 6| Step: 5
Training loss: 1.3396236896514893
Validation loss: 2.102072775363922

Epoch: 6| Step: 6
Training loss: 1.2524665594100952
Validation loss: 2.0796433091163635

Epoch: 6| Step: 7
Training loss: 1.800971269607544
Validation loss: 2.1036593119303384

Epoch: 6| Step: 8
Training loss: 1.548433780670166
Validation loss: 2.0697211225827536

Epoch: 6| Step: 9
Training loss: 1.136422872543335
Validation loss: 2.1647752126057944

Epoch: 6| Step: 10
Training loss: 0.9509751796722412
Validation loss: 2.137681464354197

Epoch: 6| Step: 11
Training loss: 1.31099271774292
Validation loss: 2.121390958627065

Epoch: 6| Step: 12
Training loss: 1.4518976211547852
Validation loss: 2.1362412770589194

Epoch: 6| Step: 13
Training loss: 1.0380752086639404
Validation loss: 2.05049463113149

Epoch: 131| Step: 0
Training loss: 1.3132708072662354
Validation loss: 2.054277777671814

Epoch: 6| Step: 1
Training loss: 0.9434986114501953
Validation loss: 2.0979734857877097

Epoch: 6| Step: 2
Training loss: 1.1425111293792725
Validation loss: 2.0646647612253823

Epoch: 6| Step: 3
Training loss: 1.9952318668365479
Validation loss: 2.089470167954763

Epoch: 6| Step: 4
Training loss: 0.7988824844360352
Validation loss: 2.064058542251587

Epoch: 6| Step: 5
Training loss: 1.6666432619094849
Validation loss: 2.051610012849172

Epoch: 6| Step: 6
Training loss: 1.5439399480819702
Validation loss: 2.066983997821808

Epoch: 6| Step: 7
Training loss: 1.0798192024230957
Validation loss: 2.0771889090538025

Epoch: 6| Step: 8
Training loss: 1.498684048652649
Validation loss: 2.1049147248268127

Epoch: 6| Step: 9
Training loss: 1.379459261894226
Validation loss: 2.088448445002238

Epoch: 6| Step: 10
Training loss: 1.0577895641326904
Validation loss: 2.092837472756704

Epoch: 6| Step: 11
Training loss: 1.7810022830963135
Validation loss: 2.109399934609731

Epoch: 6| Step: 12
Training loss: 0.982447624206543
Validation loss: 2.075425108273824

Epoch: 6| Step: 13
Training loss: 1.2128872871398926
Validation loss: 2.0529357194900513

Epoch: 132| Step: 0
Training loss: 1.1752064228057861
Validation loss: 2.080193042755127

Epoch: 6| Step: 1
Training loss: 0.7479888200759888
Validation loss: 2.060976227124532

Epoch: 6| Step: 2
Training loss: 1.243149995803833
Validation loss: 2.0519901712735495

Epoch: 6| Step: 3
Training loss: 1.1356265544891357
Validation loss: 2.1154176394144693

Epoch: 6| Step: 4
Training loss: 1.298423409461975
Validation loss: 2.0881318847338357

Epoch: 6| Step: 5
Training loss: 1.1920206546783447
Validation loss: 2.063840091228485

Epoch: 6| Step: 6
Training loss: 1.287308692932129
Validation loss: 2.0647094448407493

Epoch: 6| Step: 7
Training loss: 1.3795664310455322
Validation loss: 2.1048300663630166

Epoch: 6| Step: 8
Training loss: 1.4875798225402832
Validation loss: 2.114094694455465

Epoch: 6| Step: 9
Training loss: 1.5241385698318481
Validation loss: 2.116172512372335

Epoch: 6| Step: 10
Training loss: 1.074453592300415
Validation loss: 2.0692699551582336

Epoch: 6| Step: 11
Training loss: 1.0234954357147217
Validation loss: 2.0448763569196067

Epoch: 6| Step: 12
Training loss: 1.590116262435913
Validation loss: 2.0926173528035483

Epoch: 6| Step: 13
Training loss: 1.4291419982910156
Validation loss: 2.063162704308828

Epoch: 133| Step: 0
Training loss: 1.143096685409546
Validation loss: 2.09667706489563

Epoch: 6| Step: 1
Training loss: 1.3177211284637451
Validation loss: 2.07318647702535

Epoch: 6| Step: 2
Training loss: 1.1372263431549072
Validation loss: 2.0693060954411826

Epoch: 6| Step: 3
Training loss: 0.9816473126411438
Validation loss: 2.053371787071228

Epoch: 6| Step: 4
Training loss: 0.9355145692825317
Validation loss: 2.049922506014506

Epoch: 6| Step: 5
Training loss: 1.463631510734558
Validation loss: 2.0919228394826255

Epoch: 6| Step: 6
Training loss: 1.6421868801116943
Validation loss: 2.1160405476888022

Epoch: 6| Step: 7
Training loss: 0.982576310634613
Validation loss: 2.0354420940081277

Epoch: 6| Step: 8
Training loss: 0.9850894212722778
Validation loss: 2.0596593817075095

Epoch: 6| Step: 9
Training loss: 1.4175437688827515
Validation loss: 2.0989768703778586

Epoch: 6| Step: 10
Training loss: 0.7901280522346497
Validation loss: 2.0671088298161826

Epoch: 6| Step: 11
Training loss: 1.0853192806243896
Validation loss: 2.053341289361318

Epoch: 6| Step: 12
Training loss: 1.8970988988876343
Validation loss: 2.10244874159495

Epoch: 6| Step: 13
Training loss: 1.7167699337005615
Validation loss: 2.09324183066686

Epoch: 134| Step: 0
Training loss: 0.9171067476272583
Validation loss: 1.986549178759257

Epoch: 6| Step: 1
Training loss: 1.0566391944885254
Validation loss: 2.1163387099901834

Epoch: 6| Step: 2
Training loss: 1.7259176969528198
Validation loss: 2.0320785442988076

Epoch: 6| Step: 3
Training loss: 1.4438605308532715
Validation loss: 2.1135478218396506

Epoch: 6| Step: 4
Training loss: 1.2784706354141235
Validation loss: 2.0956883827845254

Epoch: 6| Step: 5
Training loss: 1.9773380756378174
Validation loss: 2.099729915459951

Epoch: 6| Step: 6
Training loss: 1.1639676094055176
Validation loss: 2.1335360010464988

Epoch: 6| Step: 7
Training loss: 1.6649284362792969
Validation loss: 2.104215403397878

Epoch: 6| Step: 8
Training loss: 0.6951256990432739
Validation loss: 2.1337417364120483

Epoch: 6| Step: 9
Training loss: 0.7003679275512695
Validation loss: 2.0970762173334756

Epoch: 6| Step: 10
Training loss: 1.001603603363037
Validation loss: 2.06290469566981

Epoch: 6| Step: 11
Training loss: 0.8053574562072754
Validation loss: 2.0622543891270957

Epoch: 6| Step: 12
Training loss: 0.9614261388778687
Validation loss: 2.057360053062439

Epoch: 6| Step: 13
Training loss: 1.645949363708496
Validation loss: 2.0957955718040466

Epoch: 135| Step: 0
Training loss: 1.0927523374557495
Validation loss: 2.068787455558777

Epoch: 6| Step: 1
Training loss: 1.0671651363372803
Validation loss: 2.088892340660095

Epoch: 6| Step: 2
Training loss: 1.2662360668182373
Validation loss: 2.070682406425476

Epoch: 6| Step: 3
Training loss: 1.4297218322753906
Validation loss: 2.1283492048581443

Epoch: 6| Step: 4
Training loss: 1.0020065307617188
Validation loss: 2.098389724890391

Epoch: 6| Step: 5
Training loss: 1.0234813690185547
Validation loss: 2.109147628148397

Epoch: 6| Step: 6
Training loss: 1.1812900304794312
Validation loss: 2.050543963909149

Epoch: 6| Step: 7
Training loss: 1.278376817703247
Validation loss: 2.1142017046610513

Epoch: 6| Step: 8
Training loss: 1.0173522233963013
Validation loss: 2.132711629072825

Epoch: 6| Step: 9
Training loss: 1.3515957593917847
Validation loss: 2.0735946695009866

Epoch: 6| Step: 10
Training loss: 1.048813819885254
Validation loss: 2.102488378683726

Epoch: 6| Step: 11
Training loss: 1.3906867504119873
Validation loss: 2.1015537778536477

Epoch: 6| Step: 12
Training loss: 0.8788140416145325
Validation loss: 2.1331990162531533

Epoch: 6| Step: 13
Training loss: 2.019721746444702
Validation loss: 2.1717663009961448

Epoch: 136| Step: 0
Training loss: 0.9466738104820251
Validation loss: 2.087127149105072

Epoch: 6| Step: 1
Training loss: 0.9645329713821411
Validation loss: 2.194298565387726

Epoch: 6| Step: 2
Training loss: 1.234150767326355
Validation loss: 2.0548744996388755

Epoch: 6| Step: 3
Training loss: 0.8302233219146729
Validation loss: 2.0833463271458945

Epoch: 6| Step: 4
Training loss: 1.6314234733581543
Validation loss: 2.0757459004720054

Epoch: 6| Step: 5
Training loss: 1.1843266487121582
Validation loss: 2.097686688105265

Epoch: 6| Step: 6
Training loss: 1.4099570512771606
Validation loss: 2.072124501069387

Epoch: 6| Step: 7
Training loss: 1.5088571310043335
Validation loss: 2.043881098429362

Epoch: 6| Step: 8
Training loss: 1.0107221603393555
Validation loss: 2.056004583835602

Epoch: 6| Step: 9
Training loss: 1.1336650848388672
Validation loss: 2.1101855635643005

Epoch: 6| Step: 10
Training loss: 2.0170035362243652
Validation loss: 2.118401885032654

Epoch: 6| Step: 11
Training loss: 0.850900411605835
Validation loss: 2.0742401679356894

Epoch: 6| Step: 12
Training loss: 1.0255534648895264
Validation loss: 2.0100285609563193

Epoch: 6| Step: 13
Training loss: 1.0564080476760864
Validation loss: 2.1026227275530496

Epoch: 137| Step: 0
Training loss: 1.8312764167785645
Validation loss: 2.060855249563853

Epoch: 6| Step: 1
Training loss: 1.3069615364074707
Validation loss: 2.056751827398936

Epoch: 6| Step: 2
Training loss: 1.1966817378997803
Validation loss: 2.101393759250641

Epoch: 6| Step: 3
Training loss: 1.8246924877166748
Validation loss: 2.1224159797032676

Epoch: 6| Step: 4
Training loss: 0.9582406282424927
Validation loss: 2.077672223250071

Epoch: 6| Step: 5
Training loss: 0.9029949903488159
Validation loss: 2.135559320449829

Epoch: 6| Step: 6
Training loss: 0.7973742485046387
Validation loss: 2.06735622882843

Epoch: 6| Step: 7
Training loss: 1.0611281394958496
Validation loss: 2.104875385761261

Epoch: 6| Step: 8
Training loss: 1.5489498376846313
Validation loss: 2.108087340990702

Epoch: 6| Step: 9
Training loss: 1.1635258197784424
Validation loss: 2.071654975414276

Epoch: 6| Step: 10
Training loss: 1.2449591159820557
Validation loss: 2.084539234638214

Epoch: 6| Step: 11
Training loss: 0.7985074520111084
Validation loss: 2.0852017402648926

Epoch: 6| Step: 12
Training loss: 1.6731817722320557
Validation loss: 2.1285889943440757

Epoch: 6| Step: 13
Training loss: 0.8619601726531982
Validation loss: 2.1041391293207803

Epoch: 138| Step: 0
Training loss: 1.0859190225601196
Validation loss: 2.0892725785573325

Epoch: 6| Step: 1
Training loss: 1.2967488765716553
Validation loss: 2.115094780921936

Epoch: 6| Step: 2
Training loss: 0.9550272822380066
Validation loss: 2.13487180074056

Epoch: 6| Step: 3
Training loss: 1.5381081104278564
Validation loss: 2.1229965686798096

Epoch: 6| Step: 4
Training loss: 0.7339081764221191
Validation loss: 2.11954398949941

Epoch: 6| Step: 5
Training loss: 0.9347237348556519
Validation loss: 2.103790044784546

Epoch: 6| Step: 6
Training loss: 0.9354041814804077
Validation loss: 2.085003892580668

Epoch: 6| Step: 7
Training loss: 1.3820300102233887
Validation loss: 2.14373517036438

Epoch: 6| Step: 8
Training loss: 1.2567722797393799
Validation loss: 2.1486920515696206

Epoch: 6| Step: 9
Training loss: 1.2527945041656494
Validation loss: 2.1509891351064048

Epoch: 6| Step: 10
Training loss: 1.5659494400024414
Validation loss: 2.0891234278678894

Epoch: 6| Step: 11
Training loss: 1.0449068546295166
Validation loss: 2.0803993940353394

Epoch: 6| Step: 12
Training loss: 1.1840872764587402
Validation loss: 2.068911373615265

Epoch: 6| Step: 13
Training loss: 1.2676304578781128
Validation loss: 2.072921395301819

Epoch: 139| Step: 0
Training loss: 1.1719090938568115
Validation loss: 2.0992785493532815

Epoch: 6| Step: 1
Training loss: 0.8507868647575378
Validation loss: 2.048777401447296

Epoch: 6| Step: 2
Training loss: 0.7278934717178345
Validation loss: 2.1068952878316245

Epoch: 6| Step: 3
Training loss: 1.249816656112671
Validation loss: 2.079082945982615

Epoch: 6| Step: 4
Training loss: 1.1329023838043213
Validation loss: 2.164551595846812

Epoch: 6| Step: 5
Training loss: 1.5252611637115479
Validation loss: 2.154913306236267

Epoch: 6| Step: 6
Training loss: 1.7907588481903076
Validation loss: 2.2298304041226706

Epoch: 6| Step: 7
Training loss: 1.3517462015151978
Validation loss: 2.1778523524602256

Epoch: 6| Step: 8
Training loss: 1.1829077005386353
Validation loss: 2.1443806290626526

Epoch: 6| Step: 9
Training loss: 0.680931806564331
Validation loss: 2.138434668382009

Epoch: 6| Step: 10
Training loss: 0.9172827005386353
Validation loss: 2.0707298119862876

Epoch: 6| Step: 11
Training loss: 1.2540218830108643
Validation loss: 2.057906210422516

Epoch: 6| Step: 12
Training loss: 1.5105171203613281
Validation loss: 2.05665655930837

Epoch: 6| Step: 13
Training loss: 1.656769871711731
Validation loss: 2.07530270020167

Epoch: 140| Step: 0
Training loss: 1.1914557218551636
Validation loss: 2.1058786511421204

Epoch: 6| Step: 1
Training loss: 0.8599143028259277
Validation loss: 2.06706710656484

Epoch: 6| Step: 2
Training loss: 1.150026559829712
Validation loss: 2.042494237422943

Epoch: 6| Step: 3
Training loss: 1.2090705633163452
Validation loss: 2.0461320082346597

Epoch: 6| Step: 4
Training loss: 0.8388036489486694
Validation loss: 2.0730103651682534

Epoch: 6| Step: 5
Training loss: 1.2140932083129883
Validation loss: 2.1217901905377707

Epoch: 6| Step: 6
Training loss: 1.0721569061279297
Validation loss: 2.113481104373932

Epoch: 6| Step: 7
Training loss: 1.4703123569488525
Validation loss: 2.1848409374554953

Epoch: 6| Step: 8
Training loss: 1.4684172868728638
Validation loss: 2.133953114350637

Epoch: 6| Step: 9
Training loss: 1.614527702331543
Validation loss: 2.106511910756429

Epoch: 6| Step: 10
Training loss: 1.4214344024658203
Validation loss: 2.0954373280207315

Epoch: 6| Step: 11
Training loss: 1.5433286428451538
Validation loss: 2.031810979048411

Epoch: 6| Step: 12
Training loss: 0.7920587062835693
Validation loss: 2.1344582041104636

Epoch: 6| Step: 13
Training loss: 1.0703579187393188
Validation loss: 2.107467472553253

Epoch: 141| Step: 0
Training loss: 0.8729773163795471
Validation loss: 2.073232054710388

Epoch: 6| Step: 1
Training loss: 1.3603562116622925
Validation loss: 2.103501637776693

Epoch: 6| Step: 2
Training loss: 0.9556382894515991
Validation loss: 2.0736932158470154

Epoch: 6| Step: 3
Training loss: 0.7642022371292114
Validation loss: 2.125946561495463

Epoch: 6| Step: 4
Training loss: 1.5774768590927124
Validation loss: 2.0780876676241555

Epoch: 6| Step: 5
Training loss: 1.5829501152038574
Validation loss: 2.0635974605878196

Epoch: 6| Step: 6
Training loss: 1.6037447452545166
Validation loss: 2.060292959213257

Epoch: 6| Step: 7
Training loss: 0.950935959815979
Validation loss: 2.0903824170430503

Epoch: 6| Step: 8
Training loss: 1.2101631164550781
Validation loss: 2.08733077843984

Epoch: 6| Step: 9
Training loss: 0.6676517724990845
Validation loss: 2.1160046656926474

Epoch: 6| Step: 10
Training loss: 1.3408812284469604
Validation loss: 2.0779788295427957

Epoch: 6| Step: 11
Training loss: 0.5821870565414429
Validation loss: 2.0931528210639954

Epoch: 6| Step: 12
Training loss: 1.2218207120895386
Validation loss: 2.1238253315289817

Epoch: 6| Step: 13
Training loss: 1.0826596021652222
Validation loss: 2.1206835905710855

Epoch: 142| Step: 0
Training loss: 1.6151175498962402
Validation loss: 2.1213826537132263

Epoch: 6| Step: 1
Training loss: 1.0284161567687988
Validation loss: 2.1261996229489646

Epoch: 6| Step: 2
Training loss: 1.0845130681991577
Validation loss: 2.0919875502586365

Epoch: 6| Step: 3
Training loss: 1.5022494792938232
Validation loss: 2.100968321164449

Epoch: 6| Step: 4
Training loss: 0.886821985244751
Validation loss: 2.080104410648346

Epoch: 6| Step: 5
Training loss: 0.8996307849884033
Validation loss: 2.0951656500498452

Epoch: 6| Step: 6
Training loss: 0.9092588424682617
Validation loss: 2.0856601198514304

Epoch: 6| Step: 7
Training loss: 0.9361304640769958
Validation loss: 2.0900059938430786

Epoch: 6| Step: 8
Training loss: 0.8528939485549927
Validation loss: 2.067996064821879

Epoch: 6| Step: 9
Training loss: 1.5592930316925049
Validation loss: 2.049595852692922

Epoch: 6| Step: 10
Training loss: 0.8321793079376221
Validation loss: 2.0931052565574646

Epoch: 6| Step: 11
Training loss: 1.237808108329773
Validation loss: 2.1390854318936667

Epoch: 6| Step: 12
Training loss: 1.8758978843688965
Validation loss: 2.082493007183075

Epoch: 6| Step: 13
Training loss: 0.8873398303985596
Validation loss: 2.1121503710746765

Epoch: 143| Step: 0
Training loss: 0.9254283308982849
Validation loss: 2.0887181162834167

Epoch: 6| Step: 1
Training loss: 1.1065367460250854
Validation loss: 2.0925803780555725

Epoch: 6| Step: 2
Training loss: 0.9701003432273865
Validation loss: 2.0864210526148477

Epoch: 6| Step: 3
Training loss: 0.8680826425552368
Validation loss: 2.0629188219706216

Epoch: 6| Step: 4
Training loss: 1.2547917366027832
Validation loss: 2.0851341684659324

Epoch: 6| Step: 5
Training loss: 1.9047342538833618
Validation loss: 2.05867334206899

Epoch: 6| Step: 6
Training loss: 1.4795095920562744
Validation loss: 2.0664758483568826

Epoch: 6| Step: 7
Training loss: 0.7941461801528931
Validation loss: 2.0763012965520224

Epoch: 6| Step: 8
Training loss: 0.9357277750968933
Validation loss: 2.0361299316088357

Epoch: 6| Step: 9
Training loss: 0.9541300535202026
Validation loss: 2.117840846379598

Epoch: 6| Step: 10
Training loss: 0.7429426312446594
Validation loss: 2.157207707564036

Epoch: 6| Step: 11
Training loss: 1.7856999635696411
Validation loss: 2.110994736353556

Epoch: 6| Step: 12
Training loss: 1.2384268045425415
Validation loss: 2.1298324267069497

Epoch: 6| Step: 13
Training loss: 0.895857572555542
Validation loss: 2.1406522591908774

Epoch: 144| Step: 0
Training loss: 1.4254786968231201
Validation loss: 2.152715583642324

Epoch: 6| Step: 1
Training loss: 0.7596795558929443
Validation loss: 2.0782684087753296

Epoch: 6| Step: 2
Training loss: 1.4085137844085693
Validation loss: 2.1072542468706765

Epoch: 6| Step: 3
Training loss: 1.1347261667251587
Validation loss: 2.0753798882166543

Epoch: 6| Step: 4
Training loss: 1.1159536838531494
Validation loss: 2.0799816052118936

Epoch: 6| Step: 5
Training loss: 0.8377512693405151
Validation loss: 2.0799898306528726

Epoch: 6| Step: 6
Training loss: 1.1830254793167114
Validation loss: 2.0829453667004905

Epoch: 6| Step: 7
Training loss: 0.9409999847412109
Validation loss: 2.0580128033955893

Epoch: 6| Step: 8
Training loss: 1.330637812614441
Validation loss: 2.077881336212158

Epoch: 6| Step: 9
Training loss: 1.5450682640075684
Validation loss: 2.111478885014852

Epoch: 6| Step: 10
Training loss: 0.6505332589149475
Validation loss: 2.121284087498983

Epoch: 6| Step: 11
Training loss: 0.9220800399780273
Validation loss: 2.136345148086548

Epoch: 6| Step: 12
Training loss: 1.0522781610488892
Validation loss: 2.1189990838368735

Epoch: 6| Step: 13
Training loss: 0.9483584761619568
Validation loss: 2.124949296315511

Epoch: 145| Step: 0
Training loss: 1.4698508977890015
Validation loss: 2.074165165424347

Epoch: 6| Step: 1
Training loss: 1.222263216972351
Validation loss: 2.067381978034973

Epoch: 6| Step: 2
Training loss: 1.1394449472427368
Validation loss: 2.1208901604016623

Epoch: 6| Step: 3
Training loss: 0.897666335105896
Validation loss: 2.094894746939341

Epoch: 6| Step: 4
Training loss: 1.670210599899292
Validation loss: 2.0739649136861167

Epoch: 6| Step: 5
Training loss: 1.2914097309112549
Validation loss: 2.0559072295824685

Epoch: 6| Step: 6
Training loss: 1.0833961963653564
Validation loss: 2.0829447905222573

Epoch: 6| Step: 7
Training loss: 0.8957608342170715
Validation loss: 2.1195183396339417

Epoch: 6| Step: 8
Training loss: 1.111603021621704
Validation loss: 2.074983775615692

Epoch: 6| Step: 9
Training loss: 0.9694637060165405
Validation loss: 2.1752755840619407

Epoch: 6| Step: 10
Training loss: 0.9658987522125244
Validation loss: 2.142724871635437

Epoch: 6| Step: 11
Training loss: 1.0647186040878296
Validation loss: 2.1278682549794516

Epoch: 6| Step: 12
Training loss: 0.9778317213058472
Validation loss: 2.1775506734848022

Epoch: 6| Step: 13
Training loss: 1.0864596366882324
Validation loss: 2.0809327363967896

Epoch: 146| Step: 0
Training loss: 1.169938325881958
Validation loss: 2.0892030000686646

Epoch: 6| Step: 1
Training loss: 0.7114129066467285
Validation loss: 2.0517290035883584

Epoch: 6| Step: 2
Training loss: 1.3070614337921143
Validation loss: 2.066240688165029

Epoch: 6| Step: 3
Training loss: 1.2366697788238525
Validation loss: 2.091031233469645

Epoch: 6| Step: 4
Training loss: 1.1327488422393799
Validation loss: 2.049199640750885

Epoch: 6| Step: 5
Training loss: 1.5631433725357056
Validation loss: 2.0928714076677957

Epoch: 6| Step: 6
Training loss: 1.5348118543624878
Validation loss: 2.0907378594080606

Epoch: 6| Step: 7
Training loss: 0.7704796195030212
Validation loss: 2.1354265213012695

Epoch: 6| Step: 8
Training loss: 1.0557818412780762
Validation loss: 2.1179023583730063

Epoch: 6| Step: 9
Training loss: 0.8019933104515076
Validation loss: 2.1343271732330322

Epoch: 6| Step: 10
Training loss: 0.5883541107177734
Validation loss: 2.1634970903396606

Epoch: 6| Step: 11
Training loss: 1.2677001953125
Validation loss: 2.1750153501828513

Epoch: 6| Step: 12
Training loss: 1.3143069744110107
Validation loss: 2.1788182059923806

Epoch: 6| Step: 13
Training loss: 1.126285433769226
Validation loss: 2.141459365685781

Epoch: 147| Step: 0
Training loss: 0.9087939262390137
Validation loss: 2.150255044301351

Epoch: 6| Step: 1
Training loss: 0.8976593613624573
Validation loss: 2.07668403784434

Epoch: 6| Step: 2
Training loss: 1.486753225326538
Validation loss: 2.1434887448946633

Epoch: 6| Step: 3
Training loss: 1.3689924478530884
Validation loss: 2.105495731035868

Epoch: 6| Step: 4
Training loss: 0.9745407104492188
Validation loss: 2.1178283294041953

Epoch: 6| Step: 5
Training loss: 0.8895814418792725
Validation loss: 2.0734846591949463

Epoch: 6| Step: 6
Training loss: 1.6701300144195557
Validation loss: 2.106994152069092

Epoch: 6| Step: 7
Training loss: 0.8235745429992676
Validation loss: 2.13069619735082

Epoch: 6| Step: 8
Training loss: 1.2357747554779053
Validation loss: 2.1036657094955444

Epoch: 6| Step: 9
Training loss: 1.0626826286315918
Validation loss: 2.086324175198873

Epoch: 6| Step: 10
Training loss: 0.7264747619628906
Validation loss: 2.1604204972585044

Epoch: 6| Step: 11
Training loss: 1.4594407081604004
Validation loss: 2.102246046066284

Epoch: 6| Step: 12
Training loss: 0.8010920882225037
Validation loss: 2.1542118191719055

Epoch: 6| Step: 13
Training loss: 0.7817882895469666
Validation loss: 2.093246579170227

Epoch: 148| Step: 0
Training loss: 1.2333757877349854
Validation loss: 2.0920788248380027

Epoch: 6| Step: 1
Training loss: 1.030774474143982
Validation loss: 2.118902107079824

Epoch: 6| Step: 2
Training loss: 0.6711363792419434
Validation loss: 2.0982630054155984

Epoch: 6| Step: 3
Training loss: 0.6348316669464111
Validation loss: 2.089109241962433

Epoch: 6| Step: 4
Training loss: 1.2228808403015137
Validation loss: 2.127419114112854

Epoch: 6| Step: 5
Training loss: 1.297983169555664
Validation loss: 2.1137684186299643

Epoch: 6| Step: 6
Training loss: 1.2636303901672363
Validation loss: 2.075716574986776

Epoch: 6| Step: 7
Training loss: 1.3811979293823242
Validation loss: 2.033919175465902

Epoch: 6| Step: 8
Training loss: 0.7345440983772278
Validation loss: 2.109290063381195

Epoch: 6| Step: 9
Training loss: 0.8744876384735107
Validation loss: 2.111546059449514

Epoch: 6| Step: 10
Training loss: 0.6837663650512695
Validation loss: 2.130991518497467

Epoch: 6| Step: 11
Training loss: 1.0718938112258911
Validation loss: 2.100259800752004

Epoch: 6| Step: 12
Training loss: 1.0443167686462402
Validation loss: 2.0979556838671365

Epoch: 6| Step: 13
Training loss: 1.5217199325561523
Validation loss: 2.1335928042729697

Epoch: 149| Step: 0
Training loss: 1.2152392864227295
Validation loss: 2.137522121270498

Epoch: 6| Step: 1
Training loss: 0.9155512452125549
Validation loss: 2.061417500178019

Epoch: 6| Step: 2
Training loss: 0.5354741215705872
Validation loss: 2.111710031827291

Epoch: 6| Step: 3
Training loss: 0.9747867584228516
Validation loss: 2.073066234588623

Epoch: 6| Step: 4
Training loss: 1.2218818664550781
Validation loss: 2.0490737557411194

Epoch: 6| Step: 5
Training loss: 0.8257835507392883
Validation loss: 2.056906819343567

Epoch: 6| Step: 6
Training loss: 0.8165686130523682
Validation loss: 2.097337464491526

Epoch: 6| Step: 7
Training loss: 1.189267635345459
Validation loss: 2.120292067527771

Epoch: 6| Step: 8
Training loss: 1.4385267496109009
Validation loss: 2.0293797850608826

Epoch: 6| Step: 9
Training loss: 0.5083151459693909
Validation loss: 2.0629723072052

Epoch: 6| Step: 10
Training loss: 1.043607473373413
Validation loss: 2.058902641137441

Epoch: 6| Step: 11
Training loss: 1.1322081089019775
Validation loss: 2.1212180256843567

Epoch: 6| Step: 12
Training loss: 1.0345377922058105
Validation loss: 2.118338425954183

Epoch: 6| Step: 13
Training loss: 1.8060154914855957
Validation loss: 2.115609327952067

Epoch: 150| Step: 0
Training loss: 1.2892510890960693
Validation loss: 2.047176162401835

Epoch: 6| Step: 1
Training loss: 0.6077096462249756
Validation loss: 2.0975794792175293

Epoch: 6| Step: 2
Training loss: 1.1604863405227661
Validation loss: 2.1097347935040793

Epoch: 6| Step: 3
Training loss: 0.8921983242034912
Validation loss: 2.1279004017512

Epoch: 6| Step: 4
Training loss: 1.5193867683410645
Validation loss: 2.067212224006653

Epoch: 6| Step: 5
Training loss: 1.353435754776001
Validation loss: 2.0809128085772195

Epoch: 6| Step: 6
Training loss: 0.8386255502700806
Validation loss: 2.0940762162208557

Epoch: 6| Step: 7
Training loss: 0.8251718282699585
Validation loss: 2.109779159228007

Epoch: 6| Step: 8
Training loss: 0.969036340713501
Validation loss: 2.134308477242788

Epoch: 6| Step: 9
Training loss: 1.3514318466186523
Validation loss: 2.074316382408142

Epoch: 6| Step: 10
Training loss: 0.772039532661438
Validation loss: 2.1268816788991294

Epoch: 6| Step: 11
Training loss: 1.401529312133789
Validation loss: 2.0641469160715737

Epoch: 6| Step: 12
Training loss: 0.9110348224639893
Validation loss: 2.0643158555030823

Epoch: 6| Step: 13
Training loss: 0.8529225587844849
Validation loss: 2.082542300224304

Epoch: 151| Step: 0
Training loss: 0.9122748374938965
Validation loss: 2.059062441190084

Epoch: 6| Step: 1
Training loss: 0.8883931636810303
Validation loss: 2.114084839820862

Epoch: 6| Step: 2
Training loss: 0.9584869146347046
Validation loss: 2.1369449496269226

Epoch: 6| Step: 3
Training loss: 1.2361093759536743
Validation loss: 2.1262040932973227

Epoch: 6| Step: 4
Training loss: 1.3853895664215088
Validation loss: 2.1036412119865417

Epoch: 6| Step: 5
Training loss: 1.1357249021530151
Validation loss: 2.1019680301348367

Epoch: 6| Step: 6
Training loss: 0.5438098907470703
Validation loss: 2.071503221988678

Epoch: 6| Step: 7
Training loss: 1.0441075563430786
Validation loss: 2.0595619281133017

Epoch: 6| Step: 8
Training loss: 1.150431752204895
Validation loss: 2.0585421919822693

Epoch: 6| Step: 9
Training loss: 1.4332098960876465
Validation loss: 2.1018908619880676

Epoch: 6| Step: 10
Training loss: 0.7065649032592773
Validation loss: 2.1317879954973855

Epoch: 6| Step: 11
Training loss: 1.3625333309173584
Validation loss: 2.091852525870005

Epoch: 6| Step: 12
Training loss: 1.1780307292938232
Validation loss: 2.1138357520103455

Epoch: 6| Step: 13
Training loss: 0.8746054172515869
Validation loss: 2.116955320040385

Epoch: 152| Step: 0
Training loss: 1.003289818763733
Validation loss: 2.117698391278585

Epoch: 6| Step: 1
Training loss: 1.0838313102722168
Validation loss: 2.0739657282829285

Epoch: 6| Step: 2
Training loss: 0.7410894632339478
Validation loss: 2.107828656832377

Epoch: 6| Step: 3
Training loss: 0.8905173540115356
Validation loss: 2.1331287821133933

Epoch: 6| Step: 4
Training loss: 0.8677666187286377
Validation loss: 2.115198810895284

Epoch: 6| Step: 5
Training loss: 1.5870823860168457
Validation loss: 2.084915737311045

Epoch: 6| Step: 6
Training loss: 0.8421907424926758
Validation loss: 2.0869534810384116

Epoch: 6| Step: 7
Training loss: 0.886029839515686
Validation loss: 2.1085607608159385

Epoch: 6| Step: 8
Training loss: 0.7227943539619446
Validation loss: 2.0693780183792114

Epoch: 6| Step: 9
Training loss: 1.0863701105117798
Validation loss: 2.124498208363851

Epoch: 6| Step: 10
Training loss: 0.8511356115341187
Validation loss: 2.132061223189036

Epoch: 6| Step: 11
Training loss: 1.514343500137329
Validation loss: 2.138204058011373

Epoch: 6| Step: 12
Training loss: 1.7008404731750488
Validation loss: 2.077640930811564

Epoch: 6| Step: 13
Training loss: 0.6565463542938232
Validation loss: 2.0884652137756348

Epoch: 153| Step: 0
Training loss: 0.563587486743927
Validation loss: 2.130691428979238

Epoch: 6| Step: 1
Training loss: 1.0725996494293213
Validation loss: 2.0888599157333374

Epoch: 6| Step: 2
Training loss: 0.9957531690597534
Validation loss: 2.106748898824056

Epoch: 6| Step: 3
Training loss: 1.2964680194854736
Validation loss: 2.1205286184946694

Epoch: 6| Step: 4
Training loss: 0.9548568725585938
Validation loss: 2.165031452973684

Epoch: 6| Step: 5
Training loss: 0.7634633183479309
Validation loss: 2.107078035672506

Epoch: 6| Step: 6
Training loss: 0.9008556008338928
Validation loss: 2.080885648727417

Epoch: 6| Step: 7
Training loss: 0.9114953279495239
Validation loss: 2.068686525026957

Epoch: 6| Step: 8
Training loss: 1.135284185409546
Validation loss: 2.063829521338145

Epoch: 6| Step: 9
Training loss: 1.4131731986999512
Validation loss: 2.0603745778401694

Epoch: 6| Step: 10
Training loss: 1.492801308631897
Validation loss: 2.0766587257385254

Epoch: 6| Step: 11
Training loss: 1.006332516670227
Validation loss: 2.083633601665497

Epoch: 6| Step: 12
Training loss: 0.9315999150276184
Validation loss: 2.112082560857137

Epoch: 6| Step: 13
Training loss: 1.1836107969284058
Validation loss: 2.0468433499336243

Epoch: 154| Step: 0
Training loss: 1.571336030960083
Validation loss: 2.0784855484962463

Epoch: 6| Step: 1
Training loss: 1.3352704048156738
Validation loss: 2.1919254461924234

Epoch: 6| Step: 2
Training loss: 1.0178275108337402
Validation loss: 2.1560407479604087

Epoch: 6| Step: 3
Training loss: 1.119242548942566
Validation loss: 2.133314828077952

Epoch: 6| Step: 4
Training loss: 1.2031583786010742
Validation loss: 2.1760295232137046

Epoch: 6| Step: 5
Training loss: 0.6410520672798157
Validation loss: 2.1284037828445435

Epoch: 6| Step: 6
Training loss: 0.8401044607162476
Validation loss: 2.0698389212290444

Epoch: 6| Step: 7
Training loss: 1.1641788482666016
Validation loss: 2.0616201758384705

Epoch: 6| Step: 8
Training loss: 1.0408515930175781
Validation loss: 2.0822630723317466

Epoch: 6| Step: 9
Training loss: 1.1075170040130615
Validation loss: 2.1304898063341775

Epoch: 6| Step: 10
Training loss: 1.018638014793396
Validation loss: 2.029161791006724

Epoch: 6| Step: 11
Training loss: 0.8902748823165894
Validation loss: 2.084501047929128

Epoch: 6| Step: 12
Training loss: 1.0252301692962646
Validation loss: 2.1430673003196716

Epoch: 6| Step: 13
Training loss: 0.8789763450622559
Validation loss: 2.1472220420837402

Epoch: 155| Step: 0
Training loss: 1.5839585065841675
Validation loss: 2.125620643297831

Epoch: 6| Step: 1
Training loss: 0.6902163028717041
Validation loss: 2.163256665070852

Epoch: 6| Step: 2
Training loss: 0.6979531645774841
Validation loss: 2.0637476444244385

Epoch: 6| Step: 3
Training loss: 0.9786773920059204
Validation loss: 2.1321449081103006

Epoch: 6| Step: 4
Training loss: 0.5928195714950562
Validation loss: 2.0852842728296914

Epoch: 6| Step: 5
Training loss: 0.9458640217781067
Validation loss: 2.0944172938664756

Epoch: 6| Step: 6
Training loss: 0.6407129764556885
Validation loss: 2.0834374825159707

Epoch: 6| Step: 7
Training loss: 0.837081789970398
Validation loss: 2.0576012134552

Epoch: 6| Step: 8
Training loss: 1.1874810457229614
Validation loss: 2.086827258268992

Epoch: 6| Step: 9
Training loss: 0.8238518238067627
Validation loss: 2.1097846825917563

Epoch: 6| Step: 10
Training loss: 1.3554915189743042
Validation loss: 2.081530133883158

Epoch: 6| Step: 11
Training loss: 1.063523292541504
Validation loss: 2.115112622578939

Epoch: 6| Step: 12
Training loss: 1.1058623790740967
Validation loss: 2.123292009035746

Epoch: 6| Step: 13
Training loss: 1.2169969081878662
Validation loss: 2.189481198787689

Epoch: 156| Step: 0
Training loss: 0.7347270250320435
Validation loss: 2.138515611489614

Epoch: 6| Step: 1
Training loss: 1.0695892572402954
Validation loss: 2.146162132422129

Epoch: 6| Step: 2
Training loss: 1.2577486038208008
Validation loss: 2.1448052326838174

Epoch: 6| Step: 3
Training loss: 1.002134084701538
Validation loss: 2.1351317962010703

Epoch: 6| Step: 4
Training loss: 0.8606497049331665
Validation loss: 2.0941691199938455

Epoch: 6| Step: 5
Training loss: 1.161841869354248
Validation loss: 2.074100454648336

Epoch: 6| Step: 6
Training loss: 0.566614031791687
Validation loss: 2.1175732016563416

Epoch: 6| Step: 7
Training loss: 0.7641388177871704
Validation loss: 2.1292335192362466

Epoch: 6| Step: 8
Training loss: 1.1440469026565552
Validation loss: 2.0753408471743264

Epoch: 6| Step: 9
Training loss: 1.1647992134094238
Validation loss: 2.10952091217041

Epoch: 6| Step: 10
Training loss: 1.4835772514343262
Validation loss: 2.0745000640551248

Epoch: 6| Step: 11
Training loss: 1.5594903230667114
Validation loss: 2.0952813625335693

Epoch: 6| Step: 12
Training loss: 0.9666803479194641
Validation loss: 2.160010596116384

Epoch: 6| Step: 13
Training loss: 0.9935072660446167
Validation loss: 2.176327089468638

Epoch: 157| Step: 0
Training loss: 1.4240987300872803
Validation loss: 2.1968624194463096

Epoch: 6| Step: 1
Training loss: 0.8556827306747437
Validation loss: 2.2538750370343528

Epoch: 6| Step: 2
Training loss: 1.4367280006408691
Validation loss: 2.190024475256602

Epoch: 6| Step: 3
Training loss: 0.9306882619857788
Validation loss: 2.051523268222809

Epoch: 6| Step: 4
Training loss: 0.8800172805786133
Validation loss: 2.1074812412261963

Epoch: 6| Step: 5
Training loss: 0.7690035104751587
Validation loss: 2.0883260369300842

Epoch: 6| Step: 6
Training loss: 1.020101547241211
Validation loss: 2.113363822301229

Epoch: 6| Step: 7
Training loss: 1.3666679859161377
Validation loss: 2.121872127056122

Epoch: 6| Step: 8
Training loss: 1.6332347393035889
Validation loss: 2.1046905517578125

Epoch: 6| Step: 9
Training loss: 1.4895178079605103
Validation loss: 2.1290372411410012

Epoch: 6| Step: 10
Training loss: 0.559184730052948
Validation loss: 2.1364275217056274

Epoch: 6| Step: 11
Training loss: 1.4244840145111084
Validation loss: 2.0828481912612915

Epoch: 6| Step: 12
Training loss: 1.162456750869751
Validation loss: 2.1229925950368247

Epoch: 6| Step: 13
Training loss: 1.2052350044250488
Validation loss: 2.1408039728800454

Epoch: 158| Step: 0
Training loss: 0.8221613168716431
Validation loss: 2.143338680267334

Epoch: 6| Step: 1
Training loss: 0.7070532441139221
Validation loss: 2.143158237139384

Epoch: 6| Step: 2
Training loss: 1.028714656829834
Validation loss: 2.1729256312052407

Epoch: 6| Step: 3
Training loss: 1.0305529832839966
Validation loss: 2.094852070013682

Epoch: 6| Step: 4
Training loss: 1.6097626686096191
Validation loss: 2.0878429412841797

Epoch: 6| Step: 5
Training loss: 0.9957394003868103
Validation loss: 2.1359071135520935

Epoch: 6| Step: 6
Training loss: 1.2620480060577393
Validation loss: 2.1213217775026956

Epoch: 6| Step: 7
Training loss: 1.2973209619522095
Validation loss: 2.1042277415593467

Epoch: 6| Step: 8
Training loss: 0.5374360084533691
Validation loss: 2.091309607028961

Epoch: 6| Step: 9
Training loss: 0.7860694527626038
Validation loss: 2.0792385935783386

Epoch: 6| Step: 10
Training loss: 1.4451998472213745
Validation loss: 2.128944238026937

Epoch: 6| Step: 11
Training loss: 0.9931927919387817
Validation loss: 2.108855903148651

Epoch: 6| Step: 12
Training loss: 0.4546242952346802
Validation loss: 2.1331408818562827

Epoch: 6| Step: 13
Training loss: 1.3428186178207397
Validation loss: 2.1503866712252298

Epoch: 159| Step: 0
Training loss: 0.5595785975456238
Validation loss: 2.2007698019345603

Epoch: 6| Step: 1
Training loss: 1.0389182567596436
Validation loss: 2.1521551410357156

Epoch: 6| Step: 2
Training loss: 0.9575873613357544
Validation loss: 2.2062728007634482

Epoch: 6| Step: 3
Training loss: 1.315733551979065
Validation loss: 2.1561959385871887

Epoch: 6| Step: 4
Training loss: 0.9072476625442505
Validation loss: 2.111313978830973

Epoch: 6| Step: 5
Training loss: 0.5653578639030457
Validation loss: 2.137408435344696

Epoch: 6| Step: 6
Training loss: 0.9053860306739807
Validation loss: 2.0944881439208984

Epoch: 6| Step: 7
Training loss: 1.3279213905334473
Validation loss: 2.108983039855957

Epoch: 6| Step: 8
Training loss: 0.8143224120140076
Validation loss: 2.140027324358622

Epoch: 6| Step: 9
Training loss: 1.0417344570159912
Validation loss: 2.11289381980896

Epoch: 6| Step: 10
Training loss: 1.420941710472107
Validation loss: 2.1038146018981934

Epoch: 6| Step: 11
Training loss: 0.8832815885543823
Validation loss: 2.162340839703878

Epoch: 6| Step: 12
Training loss: 1.2744888067245483
Validation loss: 2.091843525568644

Epoch: 6| Step: 13
Training loss: 0.9121680855751038
Validation loss: 2.1336797078450522

Epoch: 160| Step: 0
Training loss: 0.9101019501686096
Validation loss: 2.133181711037954

Epoch: 6| Step: 1
Training loss: 0.6183430552482605
Validation loss: 2.100971301396688

Epoch: 6| Step: 2
Training loss: 1.0024511814117432
Validation loss: 2.074667970339457

Epoch: 6| Step: 3
Training loss: 0.6582022905349731
Validation loss: 2.0771578351656594

Epoch: 6| Step: 4
Training loss: 1.611011266708374
Validation loss: 2.0759772857030234

Epoch: 6| Step: 5
Training loss: 1.097957968711853
Validation loss: 2.110513905684153

Epoch: 6| Step: 6
Training loss: 0.8832136988639832
Validation loss: 2.126297732194265

Epoch: 6| Step: 7
Training loss: 0.6238278746604919
Validation loss: 2.126370449860891

Epoch: 6| Step: 8
Training loss: 1.1002062559127808
Validation loss: 2.120655337969462

Epoch: 6| Step: 9
Training loss: 0.8751382827758789
Validation loss: 2.095990777015686

Epoch: 6| Step: 10
Training loss: 1.1448471546173096
Validation loss: 2.1409528652826944

Epoch: 6| Step: 11
Training loss: 0.901404082775116
Validation loss: 2.0797132651011148

Epoch: 6| Step: 12
Training loss: 0.5062491297721863
Validation loss: 2.0819324453671775

Epoch: 6| Step: 13
Training loss: 1.1416244506835938
Validation loss: 2.11776594320933

Epoch: 161| Step: 0
Training loss: 1.4414547681808472
Validation loss: 2.0825337767601013

Epoch: 6| Step: 1
Training loss: 0.5297024250030518
Validation loss: 2.1083216071128845

Epoch: 6| Step: 2
Training loss: 0.9051871299743652
Validation loss: 2.165626108646393

Epoch: 6| Step: 3
Training loss: 1.0624208450317383
Validation loss: 2.1376612186431885

Epoch: 6| Step: 4
Training loss: 0.8370722532272339
Validation loss: 2.068323294321696

Epoch: 6| Step: 5
Training loss: 0.7517611980438232
Validation loss: 2.0501447121302285

Epoch: 6| Step: 6
Training loss: 1.682796835899353
Validation loss: 2.0814345876375833

Epoch: 6| Step: 7
Training loss: 0.5279388427734375
Validation loss: 2.145116368929545

Epoch: 6| Step: 8
Training loss: 0.8360180258750916
Validation loss: 2.0672620733579

Epoch: 6| Step: 9
Training loss: 1.2565841674804688
Validation loss: 2.095322291056315

Epoch: 6| Step: 10
Training loss: 0.8299890756607056
Validation loss: 2.1143628358840942

Epoch: 6| Step: 11
Training loss: 0.5235264301300049
Validation loss: 2.1421773433685303

Epoch: 6| Step: 12
Training loss: 1.3306792974472046
Validation loss: 2.1454201539357505

Epoch: 6| Step: 13
Training loss: 0.8729352355003357
Validation loss: 2.124849538008372

Epoch: 162| Step: 0
Training loss: 1.0467720031738281
Validation loss: 2.107782304286957

Epoch: 6| Step: 1
Training loss: 1.3466377258300781
Validation loss: 2.148001472155253

Epoch: 6| Step: 2
Training loss: 0.8046106696128845
Validation loss: 2.121267239252726

Epoch: 6| Step: 3
Training loss: 0.810728907585144
Validation loss: 2.1154112021128335

Epoch: 6| Step: 4
Training loss: 0.6319440007209778
Validation loss: 2.1061971386273703

Epoch: 6| Step: 5
Training loss: 0.8404020667076111
Validation loss: 2.094958941141764

Epoch: 6| Step: 6
Training loss: 0.8057187795639038
Validation loss: 2.1308252612749734

Epoch: 6| Step: 7
Training loss: 0.6016959547996521
Validation loss: 2.12911186615626

Epoch: 6| Step: 8
Training loss: 1.774215817451477
Validation loss: 2.102015217145284

Epoch: 6| Step: 9
Training loss: 0.3918763995170593
Validation loss: 2.1134979923566184

Epoch: 6| Step: 10
Training loss: 1.2884118556976318
Validation loss: 2.1216783920923867

Epoch: 6| Step: 11
Training loss: 1.1964640617370605
Validation loss: 2.0964301228523254

Epoch: 6| Step: 12
Training loss: 0.7756702899932861
Validation loss: 2.115407923857371

Epoch: 6| Step: 13
Training loss: 0.9594774842262268
Validation loss: 2.1107214093208313

Epoch: 163| Step: 0
Training loss: 0.7051742076873779
Validation loss: 2.133837103843689

Epoch: 6| Step: 1
Training loss: 0.7346923351287842
Validation loss: 2.165128767490387

Epoch: 6| Step: 2
Training loss: 1.1696217060089111
Validation loss: 2.127606511116028

Epoch: 6| Step: 3
Training loss: 1.0098345279693604
Validation loss: 2.0570332407951355

Epoch: 6| Step: 4
Training loss: 0.6243693828582764
Validation loss: 2.1519543329874673

Epoch: 6| Step: 5
Training loss: 0.6871974468231201
Validation loss: 2.11305699745814

Epoch: 6| Step: 6
Training loss: 0.619993269443512
Validation loss: 2.1050844192504883

Epoch: 6| Step: 7
Training loss: 1.5573513507843018
Validation loss: 2.124337077140808

Epoch: 6| Step: 8
Training loss: 0.9939315319061279
Validation loss: 2.1218260725339255

Epoch: 6| Step: 9
Training loss: 1.3344056606292725
Validation loss: 2.09280135234197

Epoch: 6| Step: 10
Training loss: 0.8035666942596436
Validation loss: 2.0766806403795877

Epoch: 6| Step: 11
Training loss: 1.0159540176391602
Validation loss: 2.084816118081411

Epoch: 6| Step: 12
Training loss: 0.7790084481239319
Validation loss: 2.100773255030314

Epoch: 6| Step: 13
Training loss: 1.0042424201965332
Validation loss: 2.129376769065857

Epoch: 164| Step: 0
Training loss: 1.321518898010254
Validation loss: 2.0789939959843955

Epoch: 6| Step: 1
Training loss: 0.6500613689422607
Validation loss: 2.1086896856625876

Epoch: 6| Step: 2
Training loss: 1.2409019470214844
Validation loss: 2.125663240750631

Epoch: 6| Step: 3
Training loss: 0.9480529427528381
Validation loss: 2.0556622544924417

Epoch: 6| Step: 4
Training loss: 0.704616367816925
Validation loss: 2.1301313042640686

Epoch: 6| Step: 5
Training loss: 1.0312259197235107
Validation loss: 2.1824490626653037

Epoch: 6| Step: 6
Training loss: 0.760267972946167
Validation loss: 2.1602157751719155

Epoch: 6| Step: 7
Training loss: 0.98795485496521
Validation loss: 2.161196311314901

Epoch: 6| Step: 8
Training loss: 0.8631528615951538
Validation loss: 2.0710250536600747

Epoch: 6| Step: 9
Training loss: 0.7275218367576599
Validation loss: 2.1151010990142822

Epoch: 6| Step: 10
Training loss: 1.27459716796875
Validation loss: 2.1163953145345054

Epoch: 6| Step: 11
Training loss: 1.2085304260253906
Validation loss: 2.093796690305074

Epoch: 6| Step: 12
Training loss: 0.899639368057251
Validation loss: 2.114568849404653

Epoch: 6| Step: 13
Training loss: 0.7002596259117126
Validation loss: 2.1020800272623696

Epoch: 165| Step: 0
Training loss: 1.3796651363372803
Validation loss: 2.068667471408844

Epoch: 6| Step: 1
Training loss: 1.035130262374878
Validation loss: 2.080100119113922

Epoch: 6| Step: 2
Training loss: 1.0526342391967773
Validation loss: 2.0886165301005044

Epoch: 6| Step: 3
Training loss: 0.4686131179332733
Validation loss: 2.1136825482050576

Epoch: 6| Step: 4
Training loss: 0.6034769415855408
Validation loss: 2.0424848198890686

Epoch: 6| Step: 5
Training loss: 0.7873015999794006
Validation loss: 2.1430586179097495

Epoch: 6| Step: 6
Training loss: 1.0463480949401855
Validation loss: 2.0678646763165793

Epoch: 6| Step: 7
Training loss: 0.9349914789199829
Validation loss: 2.1507630546887717

Epoch: 6| Step: 8
Training loss: 1.10416841506958
Validation loss: 2.1195080081621804

Epoch: 6| Step: 9
Training loss: 1.0570019483566284
Validation loss: 2.05792369445165

Epoch: 6| Step: 10
Training loss: 0.8258591294288635
Validation loss: 2.016189535458883

Epoch: 6| Step: 11
Training loss: 1.1628844738006592
Validation loss: 2.086972157160441

Epoch: 6| Step: 12
Training loss: 0.834237813949585
Validation loss: 2.005338986714681

Epoch: 6| Step: 13
Training loss: 0.7754077911376953
Validation loss: 2.0872653921445212

Epoch: 166| Step: 0
Training loss: 1.1821147203445435
Validation loss: 2.0834098855654397

Epoch: 6| Step: 1
Training loss: 0.8814989328384399
Validation loss: 2.1031277577082315

Epoch: 6| Step: 2
Training loss: 1.0049066543579102
Validation loss: 2.0613532861073813

Epoch: 6| Step: 3
Training loss: 0.7378101348876953
Validation loss: 2.090802272160848

Epoch: 6| Step: 4
Training loss: 1.2194269895553589
Validation loss: 2.1111770470937095

Epoch: 6| Step: 5
Training loss: 0.7464574575424194
Validation loss: 2.115120053291321

Epoch: 6| Step: 6
Training loss: 0.6423813104629517
Validation loss: 2.169884184996287

Epoch: 6| Step: 7
Training loss: 0.9058724045753479
Validation loss: 2.1013750036557517

Epoch: 6| Step: 8
Training loss: 1.1092623472213745
Validation loss: 2.0871084531148276

Epoch: 6| Step: 9
Training loss: 1.259779453277588
Validation loss: 2.101138929526011

Epoch: 6| Step: 10
Training loss: 0.7502874135971069
Validation loss: 2.0934109489123025

Epoch: 6| Step: 11
Training loss: 0.936396598815918
Validation loss: 2.0949795842170715

Epoch: 6| Step: 12
Training loss: 0.7955543398857117
Validation loss: 2.0968904296557107

Epoch: 6| Step: 13
Training loss: 0.535653293132782
Validation loss: 2.0891486605008445

Epoch: 167| Step: 0
Training loss: 1.1776542663574219
Validation loss: 2.036790589491526

Epoch: 6| Step: 1
Training loss: 0.7070214152336121
Validation loss: 2.160615563392639

Epoch: 6| Step: 2
Training loss: 1.2707970142364502
Validation loss: 2.152442971865336

Epoch: 6| Step: 3
Training loss: 1.2092485427856445
Validation loss: 2.1309042970339456

Epoch: 6| Step: 4
Training loss: 0.7057600617408752
Validation loss: 2.092586636543274

Epoch: 6| Step: 5
Training loss: 1.1366047859191895
Validation loss: 2.031026323636373

Epoch: 6| Step: 6
Training loss: 1.1768410205841064
Validation loss: 2.137112299601237

Epoch: 6| Step: 7
Training loss: 0.6481244564056396
Validation loss: 2.0856992403666177

Epoch: 6| Step: 8
Training loss: 0.8075005412101746
Validation loss: 2.0934645334879556

Epoch: 6| Step: 9
Training loss: 0.7967204451560974
Validation loss: 2.05042165517807

Epoch: 6| Step: 10
Training loss: 0.8297614455223083
Validation loss: 2.1419569651285806

Epoch: 6| Step: 11
Training loss: 0.7352738976478577
Validation loss: 2.2181984186172485

Epoch: 6| Step: 12
Training loss: 1.1259416341781616
Validation loss: 2.126117169857025

Epoch: 6| Step: 13
Training loss: 0.8908144235610962
Validation loss: 2.142101764678955

Epoch: 168| Step: 0
Training loss: 0.8248708844184875
Validation loss: 2.1624969641367593

Epoch: 6| Step: 1
Training loss: 1.3954864740371704
Validation loss: 2.1548094153404236

Epoch: 6| Step: 2
Training loss: 1.1730841398239136
Validation loss: 2.1669047673543296

Epoch: 6| Step: 3
Training loss: 0.9182201623916626
Validation loss: 2.125848412513733

Epoch: 6| Step: 4
Training loss: 1.1634137630462646
Validation loss: 2.1552706162134805

Epoch: 6| Step: 5
Training loss: 1.2101399898529053
Validation loss: 2.098650336265564

Epoch: 6| Step: 6
Training loss: 0.7366794347763062
Validation loss: 2.1249785820643106

Epoch: 6| Step: 7
Training loss: 0.910731852054596
Validation loss: 2.131470799446106

Epoch: 6| Step: 8
Training loss: 0.33646640181541443
Validation loss: 2.0671022733052573

Epoch: 6| Step: 9
Training loss: 0.4207580089569092
Validation loss: 2.0897733767827353

Epoch: 6| Step: 10
Training loss: 1.0470064878463745
Validation loss: 2.097527245680491

Epoch: 6| Step: 11
Training loss: 0.4802969694137573
Validation loss: 2.143496513366699

Epoch: 6| Step: 12
Training loss: 0.6986500024795532
Validation loss: 2.085640768210093

Epoch: 6| Step: 13
Training loss: 1.3051884174346924
Validation loss: 2.0431485970815024

Epoch: 169| Step: 0
Training loss: 1.218773365020752
Validation loss: 2.0737844904263816

Epoch: 6| Step: 1
Training loss: 0.7543860673904419
Validation loss: 2.1232540607452393

Epoch: 6| Step: 2
Training loss: 0.6778244972229004
Validation loss: 2.085002621014913

Epoch: 6| Step: 3
Training loss: 0.9529345035552979
Validation loss: 2.084840099016825

Epoch: 6| Step: 4
Training loss: 1.0105535984039307
Validation loss: 2.1418017148971558

Epoch: 6| Step: 5
Training loss: 1.1098148822784424
Validation loss: 2.1538460850715637

Epoch: 6| Step: 6
Training loss: 0.5180364847183228
Validation loss: 2.095479885737101

Epoch: 6| Step: 7
Training loss: 0.6201443076133728
Validation loss: 2.1200461387634277

Epoch: 6| Step: 8
Training loss: 1.0369815826416016
Validation loss: 2.154492219289144

Epoch: 6| Step: 9
Training loss: 0.7017480731010437
Validation loss: 2.0954275727272034

Epoch: 6| Step: 10
Training loss: 0.7454073429107666
Validation loss: 2.1290714542071023

Epoch: 6| Step: 11
Training loss: 1.0569744110107422
Validation loss: 2.0994176665941873

Epoch: 6| Step: 12
Training loss: 1.387245774269104
Validation loss: 2.1464046041170755

Epoch: 6| Step: 13
Training loss: 1.0373377799987793
Validation loss: 2.1174073815345764

Epoch: 170| Step: 0
Training loss: 0.9231966733932495
Validation loss: 2.1228487292925515

Epoch: 6| Step: 1
Training loss: 0.8204491138458252
Validation loss: 2.118817230065664

Epoch: 6| Step: 2
Training loss: 0.8364577293395996
Validation loss: 2.0983214378356934

Epoch: 6| Step: 3
Training loss: 0.820665717124939
Validation loss: 2.113197147846222

Epoch: 6| Step: 4
Training loss: 1.0641822814941406
Validation loss: 2.1401854753494263

Epoch: 6| Step: 5
Training loss: 1.2821428775787354
Validation loss: 2.1933889190355935

Epoch: 6| Step: 6
Training loss: 1.0266664028167725
Validation loss: 2.1484301686286926

Epoch: 6| Step: 7
Training loss: 0.5418293476104736
Validation loss: 2.13839124639829

Epoch: 6| Step: 8
Training loss: 0.7213174104690552
Validation loss: 2.114837924639384

Epoch: 6| Step: 9
Training loss: 0.9331220388412476
Validation loss: 2.1008407870928445

Epoch: 6| Step: 10
Training loss: 0.7817925214767456
Validation loss: 2.100518842538198

Epoch: 6| Step: 11
Training loss: 1.057248592376709
Validation loss: 2.150212268034617

Epoch: 6| Step: 12
Training loss: 0.8051214218139648
Validation loss: 2.102358261744181

Epoch: 6| Step: 13
Training loss: 0.7111913561820984
Validation loss: 2.1235222021738687

Epoch: 171| Step: 0
Training loss: 0.9874251484870911
Validation loss: 2.0753686825434365

Epoch: 6| Step: 1
Training loss: 0.5097878575325012
Validation loss: 2.1384825309117637

Epoch: 6| Step: 2
Training loss: 0.9856651425361633
Validation loss: 2.0896401604016623

Epoch: 6| Step: 3
Training loss: 1.0934213399887085
Validation loss: 2.1428893208503723

Epoch: 6| Step: 4
Training loss: 0.8617340326309204
Validation loss: 2.1302334467569985

Epoch: 6| Step: 5
Training loss: 1.1257545948028564
Validation loss: 2.1874213020006814

Epoch: 6| Step: 6
Training loss: 1.2582919597625732
Validation loss: 2.1560871601104736

Epoch: 6| Step: 7
Training loss: 1.1267728805541992
Validation loss: 2.13002602259318

Epoch: 6| Step: 8
Training loss: 0.5949172973632812
Validation loss: 2.116060197353363

Epoch: 6| Step: 9
Training loss: 1.0442073345184326
Validation loss: 2.0981869101524353

Epoch: 6| Step: 10
Training loss: 0.8581162095069885
Validation loss: 2.094561298688253

Epoch: 6| Step: 11
Training loss: 0.6509600877761841
Validation loss: 2.1342949867248535

Epoch: 6| Step: 12
Training loss: 0.9228508472442627
Validation loss: 2.109442889690399

Epoch: 6| Step: 13
Training loss: 0.4334849417209625
Validation loss: 2.102029283841451

Epoch: 172| Step: 0
Training loss: 0.6610321998596191
Validation loss: 2.0759034951527915

Epoch: 6| Step: 1
Training loss: 0.761616587638855
Validation loss: 2.0419070521990457

Epoch: 6| Step: 2
Training loss: 0.7963019013404846
Validation loss: 2.1182264486948648

Epoch: 6| Step: 3
Training loss: 0.4311193525791168
Validation loss: 2.1482764879862466

Epoch: 6| Step: 4
Training loss: 1.37118399143219
Validation loss: 2.1215102275212607

Epoch: 6| Step: 5
Training loss: 1.6859114170074463
Validation loss: 2.1459970672925315

Epoch: 6| Step: 6
Training loss: 0.9348017573356628
Validation loss: 2.141882042090098

Epoch: 6| Step: 7
Training loss: 1.1235724687576294
Validation loss: 2.1053121288617453

Epoch: 6| Step: 8
Training loss: 1.0539770126342773
Validation loss: 2.1218019127845764

Epoch: 6| Step: 9
Training loss: 0.5996302366256714
Validation loss: 2.0840315222740173

Epoch: 6| Step: 10
Training loss: 0.9386313557624817
Validation loss: 2.1144980986913047

Epoch: 6| Step: 11
Training loss: 0.7794920206069946
Validation loss: 2.1336455742518106

Epoch: 6| Step: 12
Training loss: 0.48520782589912415
Validation loss: 2.082340578238169

Epoch: 6| Step: 13
Training loss: 0.5708933472633362
Validation loss: 2.1523569424947104

Epoch: 173| Step: 0
Training loss: 0.48702502250671387
Validation loss: 2.1354063749313354

Epoch: 6| Step: 1
Training loss: 0.7834916710853577
Validation loss: 2.155132273832957

Epoch: 6| Step: 2
Training loss: 1.3026617765426636
Validation loss: 2.108409027258555

Epoch: 6| Step: 3
Training loss: 0.5793218016624451
Validation loss: 2.1422324776649475

Epoch: 6| Step: 4
Training loss: 0.8485116958618164
Validation loss: 2.15498153368632

Epoch: 6| Step: 5
Training loss: 0.8113611936569214
Validation loss: 2.11197421948115

Epoch: 6| Step: 6
Training loss: 0.9977230429649353
Validation loss: 2.07747346162796

Epoch: 6| Step: 7
Training loss: 0.7309029698371887
Validation loss: 2.0719517866770425

Epoch: 6| Step: 8
Training loss: 0.5790301561355591
Validation loss: 2.123229185740153

Epoch: 6| Step: 9
Training loss: 0.7782617211341858
Validation loss: 2.1314550638198853

Epoch: 6| Step: 10
Training loss: 1.1336688995361328
Validation loss: 2.1065024932225547

Epoch: 6| Step: 11
Training loss: 1.7581251859664917
Validation loss: 2.0852051973342896

Epoch: 6| Step: 12
Training loss: 0.8024381399154663
Validation loss: 2.0769731601079306

Epoch: 6| Step: 13
Training loss: 0.9487327337265015
Validation loss: 2.115953485171

Epoch: 174| Step: 0
Training loss: 0.8258178234100342
Validation loss: 2.1324119170506797

Epoch: 6| Step: 1
Training loss: 0.890918493270874
Validation loss: 2.145423392454783

Epoch: 6| Step: 2
Training loss: 0.8771194219589233
Validation loss: 2.1415675481160483

Epoch: 6| Step: 3
Training loss: 0.43857431411743164
Validation loss: 2.129883964856466

Epoch: 6| Step: 4
Training loss: 0.6976603269577026
Validation loss: 2.0887641509373984

Epoch: 6| Step: 5
Training loss: 0.7191182374954224
Validation loss: 2.103990614414215

Epoch: 6| Step: 6
Training loss: 0.5162514448165894
Validation loss: 2.1293685833613076

Epoch: 6| Step: 7
Training loss: 0.5629011392593384
Validation loss: 2.1566078066825867

Epoch: 6| Step: 8
Training loss: 0.5824681520462036
Validation loss: 2.108916242917379

Epoch: 6| Step: 9
Training loss: 1.1052371263504028
Validation loss: 2.133815348148346

Epoch: 6| Step: 10
Training loss: 1.2504150867462158
Validation loss: 2.1360125144322715

Epoch: 6| Step: 11
Training loss: 1.044052243232727
Validation loss: 2.0829469561576843

Epoch: 6| Step: 12
Training loss: 1.131653904914856
Validation loss: 2.075380106767019

Epoch: 6| Step: 13
Training loss: 1.2600558996200562
Validation loss: 2.1309318939844766

Epoch: 175| Step: 0
Training loss: 0.9185081720352173
Validation loss: 2.153126140435537

Epoch: 6| Step: 1
Training loss: 0.867628812789917
Validation loss: 2.106210231781006

Epoch: 6| Step: 2
Training loss: 0.6473541259765625
Validation loss: 2.16977588335673

Epoch: 6| Step: 3
Training loss: 0.8762597441673279
Validation loss: 2.226295073827108

Epoch: 6| Step: 4
Training loss: 0.7747921943664551
Validation loss: 2.1501699884732566

Epoch: 6| Step: 5
Training loss: 1.2919502258300781
Validation loss: 2.0888576904932656

Epoch: 6| Step: 6
Training loss: 0.8721538782119751
Validation loss: 2.1910436352094016

Epoch: 6| Step: 7
Training loss: 1.2818024158477783
Validation loss: 2.089764138062795

Epoch: 6| Step: 8
Training loss: 0.8983792066574097
Validation loss: 2.100870052973429

Epoch: 6| Step: 9
Training loss: 1.24470853805542
Validation loss: 2.102849006652832

Epoch: 6| Step: 10
Training loss: 0.819101095199585
Validation loss: 2.075231611728668

Epoch: 6| Step: 11
Training loss: 0.6629384756088257
Validation loss: 2.100539485613505

Epoch: 6| Step: 12
Training loss: 0.41526198387145996
Validation loss: 2.0910781820615134

Epoch: 6| Step: 13
Training loss: 0.6644439697265625
Validation loss: 2.131256560484568

Epoch: 176| Step: 0
Training loss: 0.9310688972473145
Validation loss: 2.0395673712094626

Epoch: 6| Step: 1
Training loss: 0.8628199100494385
Validation loss: 2.0709069768587747

Epoch: 6| Step: 2
Training loss: 0.9060975313186646
Validation loss: 2.136632740497589

Epoch: 6| Step: 3
Training loss: 0.8953707814216614
Validation loss: 2.0844733913739524

Epoch: 6| Step: 4
Training loss: 0.5346956253051758
Validation loss: 2.1117889285087585

Epoch: 6| Step: 5
Training loss: 1.2196829319000244
Validation loss: 2.0895031690597534

Epoch: 6| Step: 6
Training loss: 1.2451995611190796
Validation loss: 2.0986324350039163

Epoch: 6| Step: 7
Training loss: 0.7663536071777344
Validation loss: 2.0973939895629883

Epoch: 6| Step: 8
Training loss: 0.9732468128204346
Validation loss: 2.1417134602864585

Epoch: 6| Step: 9
Training loss: 0.536301851272583
Validation loss: 2.1045985023180642

Epoch: 6| Step: 10
Training loss: 0.8073346018791199
Validation loss: 2.130818764368693

Epoch: 6| Step: 11
Training loss: 0.7462571263313293
Validation loss: 2.131044069925944

Epoch: 6| Step: 12
Training loss: 0.5978703498840332
Validation loss: 2.1172015269597373

Epoch: 6| Step: 13
Training loss: 0.6560976505279541
Validation loss: 2.1404159665107727

Epoch: 177| Step: 0
Training loss: 0.9384444355964661
Validation loss: 2.151469628016154

Epoch: 6| Step: 1
Training loss: 0.7427417039871216
Validation loss: 2.142747481664022

Epoch: 6| Step: 2
Training loss: 0.4246861934661865
Validation loss: 2.14951225121816

Epoch: 6| Step: 3
Training loss: 0.9939538240432739
Validation loss: 2.1768518884976706

Epoch: 6| Step: 4
Training loss: 0.6307658553123474
Validation loss: 2.072360098361969

Epoch: 6| Step: 5
Training loss: 0.6408801078796387
Validation loss: 2.0900532801946006

Epoch: 6| Step: 6
Training loss: 0.849749743938446
Validation loss: 2.1027337511380515

Epoch: 6| Step: 7
Training loss: 0.931694507598877
Validation loss: 2.097160220146179

Epoch: 6| Step: 8
Training loss: 0.6284691095352173
Validation loss: 2.1271530787150064

Epoch: 6| Step: 9
Training loss: 1.6143380403518677
Validation loss: 2.1195054054260254

Epoch: 6| Step: 10
Training loss: 0.6770256161689758
Validation loss: 2.065083622932434

Epoch: 6| Step: 11
Training loss: 1.1244986057281494
Validation loss: 2.1077260176340737

Epoch: 6| Step: 12
Training loss: 0.7342406511306763
Validation loss: 2.1138383547465005

Epoch: 6| Step: 13
Training loss: 0.5279680490493774
Validation loss: 2.1034972866376243

Epoch: 178| Step: 0
Training loss: 1.0325839519500732
Validation loss: 2.1460058887799582

Epoch: 6| Step: 1
Training loss: 0.76386559009552
Validation loss: 2.098523517449697

Epoch: 6| Step: 2
Training loss: 0.8734652996063232
Validation loss: 2.142733712991079

Epoch: 6| Step: 3
Training loss: 1.3008850812911987
Validation loss: 2.089969019095103

Epoch: 6| Step: 4
Training loss: 0.785825252532959
Validation loss: 2.107879380385081

Epoch: 6| Step: 5
Training loss: 1.1507028341293335
Validation loss: 2.124986410140991

Epoch: 6| Step: 6
Training loss: 0.9776270389556885
Validation loss: 2.1569018761316934

Epoch: 6| Step: 7
Training loss: 0.6201187372207642
Validation loss: 2.154472986857096

Epoch: 6| Step: 8
Training loss: 0.5562300086021423
Validation loss: 2.17229296763738

Epoch: 6| Step: 9
Training loss: 0.3827707767486572
Validation loss: 2.145430783430735

Epoch: 6| Step: 10
Training loss: 0.6810005903244019
Validation loss: 2.078897754351298

Epoch: 6| Step: 11
Training loss: 0.7742807269096375
Validation loss: 2.0707268714904785

Epoch: 6| Step: 12
Training loss: 1.0638889074325562
Validation loss: 2.123898724714915

Epoch: 6| Step: 13
Training loss: 0.8069167137145996
Validation loss: 2.057480732599894

Epoch: 179| Step: 0
Training loss: 1.0909487009048462
Validation loss: 2.129637837409973

Epoch: 6| Step: 1
Training loss: 1.3523187637329102
Validation loss: 2.093462328116099

Epoch: 6| Step: 2
Training loss: 0.9076751470565796
Validation loss: 2.0782366196314492

Epoch: 6| Step: 3
Training loss: 0.7242637872695923
Validation loss: 2.1204737226168313

Epoch: 6| Step: 4
Training loss: 0.7523255348205566
Validation loss: 2.170408328374227

Epoch: 6| Step: 5
Training loss: 0.6444215774536133
Validation loss: 2.047506868839264

Epoch: 6| Step: 6
Training loss: 0.4171202778816223
Validation loss: 2.092485010623932

Epoch: 6| Step: 7
Training loss: 0.5319691896438599
Validation loss: 2.08275298277537

Epoch: 6| Step: 8
Training loss: 1.0358078479766846
Validation loss: 2.129670202732086

Epoch: 6| Step: 9
Training loss: 0.6240956783294678
Validation loss: 2.1824552615483603

Epoch: 6| Step: 10
Training loss: 0.6231780648231506
Validation loss: 2.1436524391174316

Epoch: 6| Step: 11
Training loss: 0.999970555305481
Validation loss: 2.131479561328888

Epoch: 6| Step: 12
Training loss: 1.0587050914764404
Validation loss: 2.1282623410224915

Epoch: 6| Step: 13
Training loss: 0.8287829160690308
Validation loss: 2.0956507126490274

Epoch: 180| Step: 0
Training loss: 0.6379789113998413
Validation loss: 2.061327358086904

Epoch: 6| Step: 1
Training loss: 0.8562099933624268
Validation loss: 2.151434858640035

Epoch: 6| Step: 2
Training loss: 0.7338206768035889
Validation loss: 2.1803958813349404

Epoch: 6| Step: 3
Training loss: 1.242483139038086
Validation loss: 2.1209198037783303

Epoch: 6| Step: 4
Training loss: 0.6833439469337463
Validation loss: 2.1317312717437744

Epoch: 6| Step: 5
Training loss: 0.6115705966949463
Validation loss: 2.125583827495575

Epoch: 6| Step: 6
Training loss: 0.9027690887451172
Validation loss: 2.1296544273694358

Epoch: 6| Step: 7
Training loss: 0.59928297996521
Validation loss: 2.124908367792765

Epoch: 6| Step: 8
Training loss: 0.4658161401748657
Validation loss: 2.1489667296409607

Epoch: 6| Step: 9
Training loss: 1.3926002979278564
Validation loss: 2.1438852349917092

Epoch: 6| Step: 10
Training loss: 0.6498410105705261
Validation loss: 2.1430428425470986

Epoch: 6| Step: 11
Training loss: 0.8578236103057861
Validation loss: 2.121541182200114

Epoch: 6| Step: 12
Training loss: 0.9381306171417236
Validation loss: 2.1173134247461953

Epoch: 6| Step: 13
Training loss: 0.8296152353286743
Validation loss: 2.1008107662200928

Epoch: 181| Step: 0
Training loss: 1.0964078903198242
Validation loss: 2.153942823410034

Epoch: 6| Step: 1
Training loss: 0.896349310874939
Validation loss: 2.094293713569641

Epoch: 6| Step: 2
Training loss: 0.732403039932251
Validation loss: 2.1298188964525857

Epoch: 6| Step: 3
Training loss: 0.5763518810272217
Validation loss: 2.091682235399882

Epoch: 6| Step: 4
Training loss: 1.0306129455566406
Validation loss: 2.135659714539846

Epoch: 6| Step: 5
Training loss: 0.9119335412979126
Validation loss: 2.1989470720291138

Epoch: 6| Step: 6
Training loss: 0.7689142823219299
Validation loss: 2.1016286810239158

Epoch: 6| Step: 7
Training loss: 0.6949173808097839
Validation loss: 2.057865262031555

Epoch: 6| Step: 8
Training loss: 0.4367868900299072
Validation loss: 2.121815105279287

Epoch: 6| Step: 9
Training loss: 0.8121278882026672
Validation loss: 2.0838612715403237

Epoch: 6| Step: 10
Training loss: 0.8530824184417725
Validation loss: 2.1338807940483093

Epoch: 6| Step: 11
Training loss: 0.9513883590698242
Validation loss: 2.0686100920041404

Epoch: 6| Step: 12
Training loss: 0.708587110042572
Validation loss: 2.131722390651703

Epoch: 6| Step: 13
Training loss: 0.6719979643821716
Validation loss: 2.1272414724032083

Epoch: 182| Step: 0
Training loss: 0.49702829122543335
Validation loss: 2.1299777030944824

Epoch: 6| Step: 1
Training loss: 0.7311733961105347
Validation loss: 2.1544889211654663

Epoch: 6| Step: 2
Training loss: 1.3833494186401367
Validation loss: 2.177166442076365

Epoch: 6| Step: 3
Training loss: 1.0027354955673218
Validation loss: 2.1289409399032593

Epoch: 6| Step: 4
Training loss: 0.7115460634231567
Validation loss: 2.1146934827168784

Epoch: 6| Step: 5
Training loss: 1.162161111831665
Validation loss: 2.115875701109568

Epoch: 6| Step: 6
Training loss: 0.8756640553474426
Validation loss: 2.0800939003626504

Epoch: 6| Step: 7
Training loss: 0.5825510621070862
Validation loss: 2.136728882789612

Epoch: 6| Step: 8
Training loss: 1.1494041681289673
Validation loss: 2.130090653896332

Epoch: 6| Step: 9
Training loss: 0.8762385249137878
Validation loss: 2.117479463418325

Epoch: 6| Step: 10
Training loss: 0.5730521082878113
Validation loss: 2.1210593978563943

Epoch: 6| Step: 11
Training loss: 0.6682206392288208
Validation loss: 2.1270413200060525

Epoch: 6| Step: 12
Training loss: 0.5121158361434937
Validation loss: 2.1542235612869263

Epoch: 6| Step: 13
Training loss: 0.8330526947975159
Validation loss: 2.162217398484548

Epoch: 183| Step: 0
Training loss: 1.5888898372650146
Validation loss: 2.1279932459195456

Epoch: 6| Step: 1
Training loss: 0.8798677921295166
Validation loss: 2.128082513809204

Epoch: 6| Step: 2
Training loss: 0.6511332392692566
Validation loss: 2.173689325650533

Epoch: 6| Step: 3
Training loss: 0.8506202697753906
Validation loss: 2.109307607014974

Epoch: 6| Step: 4
Training loss: 0.7385042309761047
Validation loss: 2.125065286954244

Epoch: 6| Step: 5
Training loss: 0.900079607963562
Validation loss: 2.101216197013855

Epoch: 6| Step: 6
Training loss: 1.088248372077942
Validation loss: 2.0992263356844583

Epoch: 6| Step: 7
Training loss: 0.5147619843482971
Validation loss: 2.0914875268936157

Epoch: 6| Step: 8
Training loss: 0.7174879312515259
Validation loss: 2.131316324075063

Epoch: 6| Step: 9
Training loss: 0.9970059394836426
Validation loss: 2.0749171574910483

Epoch: 6| Step: 10
Training loss: 0.6669410467147827
Validation loss: 2.1181132793426514

Epoch: 6| Step: 11
Training loss: 0.763664960861206
Validation loss: 2.097746471563975

Epoch: 6| Step: 12
Training loss: 0.8959436416625977
Validation loss: 2.1655010183652244

Epoch: 6| Step: 13
Training loss: 0.5466411113739014
Validation loss: 2.1677567958831787

Epoch: 184| Step: 0
Training loss: 0.9702713489532471
Validation loss: 2.159443438053131

Epoch: 6| Step: 1
Training loss: 0.7574703693389893
Validation loss: 2.17762299378713

Epoch: 6| Step: 2
Training loss: 1.0556466579437256
Validation loss: 2.1121790409088135

Epoch: 6| Step: 3
Training loss: 0.9085091352462769
Validation loss: 2.0870344241460166

Epoch: 6| Step: 4
Training loss: 0.8145900964736938
Validation loss: 2.1085626085599265

Epoch: 6| Step: 5
Training loss: 0.5715310573577881
Validation loss: 2.083249052365621

Epoch: 6| Step: 6
Training loss: 0.7613950967788696
Validation loss: 2.120631198088328

Epoch: 6| Step: 7
Training loss: 0.3666802644729614
Validation loss: 2.1094859639803567

Epoch: 6| Step: 8
Training loss: 0.8050447702407837
Validation loss: 2.145999550819397

Epoch: 6| Step: 9
Training loss: 0.8912257552146912
Validation loss: 2.128316084543864

Epoch: 6| Step: 10
Training loss: 0.8876479864120483
Validation loss: 2.18455308675766

Epoch: 6| Step: 11
Training loss: 0.7519009709358215
Validation loss: 2.1848594148953757

Epoch: 6| Step: 12
Training loss: 1.3920166492462158
Validation loss: 2.182667056719462

Epoch: 6| Step: 13
Training loss: 0.8313612341880798
Validation loss: 2.183660328388214

Epoch: 185| Step: 0
Training loss: 0.5697742700576782
Validation loss: 2.082354267438253

Epoch: 6| Step: 1
Training loss: 0.6813206672668457
Validation loss: 2.113807499408722

Epoch: 6| Step: 2
Training loss: 0.6744092702865601
Validation loss: 2.108936528364817

Epoch: 6| Step: 3
Training loss: 1.6332550048828125
Validation loss: 2.130086382230123

Epoch: 6| Step: 4
Training loss: 0.9059684872627258
Validation loss: 2.093114455540975

Epoch: 6| Step: 5
Training loss: 0.5270000100135803
Validation loss: 2.157460550467173

Epoch: 6| Step: 6
Training loss: 0.7824004888534546
Validation loss: 2.1180982987085977

Epoch: 6| Step: 7
Training loss: 0.6749571561813354
Validation loss: 2.135104556878408

Epoch: 6| Step: 8
Training loss: 0.8005664348602295
Validation loss: 2.131848613421122

Epoch: 6| Step: 9
Training loss: 0.7692124843597412
Validation loss: 2.1204694708188376

Epoch: 6| Step: 10
Training loss: 0.5313782691955566
Validation loss: 2.123794138431549

Epoch: 6| Step: 11
Training loss: 0.7985954284667969
Validation loss: 2.1477988362312317

Epoch: 6| Step: 12
Training loss: 0.8479384779930115
Validation loss: 2.1224470734596252

Epoch: 6| Step: 13
Training loss: 0.6703704595565796
Validation loss: 2.1554006735483804

Epoch: 186| Step: 0
Training loss: 0.6150628328323364
Validation loss: 2.118092159430186

Epoch: 6| Step: 1
Training loss: 1.0335267782211304
Validation loss: 2.1038366556167603

Epoch: 6| Step: 2
Training loss: 1.0301859378814697
Validation loss: 2.105554521083832

Epoch: 6| Step: 3
Training loss: 0.8875682353973389
Validation loss: 2.1352357467015586

Epoch: 6| Step: 4
Training loss: 0.688784122467041
Validation loss: 2.12294735511144

Epoch: 6| Step: 5
Training loss: 0.570970356464386
Validation loss: 2.113958775997162

Epoch: 6| Step: 6
Training loss: 0.56642746925354
Validation loss: 2.164529025554657

Epoch: 6| Step: 7
Training loss: 0.8424583673477173
Validation loss: 2.1654732624689736

Epoch: 6| Step: 8
Training loss: 0.9811535477638245
Validation loss: 2.1987932523091636

Epoch: 6| Step: 9
Training loss: 1.1952569484710693
Validation loss: 2.1811290979385376

Epoch: 6| Step: 10
Training loss: 0.5725374221801758
Validation loss: 2.179608384768168

Epoch: 6| Step: 11
Training loss: 0.8714955449104309
Validation loss: 2.1085493763287864

Epoch: 6| Step: 12
Training loss: 0.6537126898765564
Validation loss: 2.148905078570048

Epoch: 6| Step: 13
Training loss: 0.7259972095489502
Validation loss: 2.128204902013143

Epoch: 187| Step: 0
Training loss: 1.1136890649795532
Validation loss: 2.122182627518972

Epoch: 6| Step: 1
Training loss: 0.689203143119812
Validation loss: 2.152641495068868

Epoch: 6| Step: 2
Training loss: 1.1652097702026367
Validation loss: 2.1071614424387612

Epoch: 6| Step: 3
Training loss: 0.6332041025161743
Validation loss: 2.089911937713623

Epoch: 6| Step: 4
Training loss: 0.37173992395401
Validation loss: 2.1415751377741494

Epoch: 6| Step: 5
Training loss: 0.8045990467071533
Validation loss: 2.1155253251393638

Epoch: 6| Step: 6
Training loss: 0.522507905960083
Validation loss: 2.110411822795868

Epoch: 6| Step: 7
Training loss: 0.34433209896087646
Validation loss: 2.1129038532574973

Epoch: 6| Step: 8
Training loss: 1.033706545829773
Validation loss: 2.1484734614690146

Epoch: 6| Step: 9
Training loss: 1.1588261127471924
Validation loss: 2.1709481477737427

Epoch: 6| Step: 10
Training loss: 0.755446195602417
Validation loss: 2.1438077688217163

Epoch: 6| Step: 11
Training loss: 0.3903588652610779
Validation loss: 2.1276235779126487

Epoch: 6| Step: 12
Training loss: 0.7411261200904846
Validation loss: 2.0985734264055886

Epoch: 6| Step: 13
Training loss: 0.7207217216491699
Validation loss: 2.0750858585039773

Epoch: 188| Step: 0
Training loss: 0.6288067102432251
Validation loss: 2.1264055569966636

Epoch: 6| Step: 1
Training loss: 0.47237318754196167
Validation loss: 2.111364483833313

Epoch: 6| Step: 2
Training loss: 0.5683228373527527
Validation loss: 2.1091052492459617

Epoch: 6| Step: 3
Training loss: 0.6353013515472412
Validation loss: 2.1138559778531394

Epoch: 6| Step: 4
Training loss: 0.44216984510421753
Validation loss: 2.178408682346344

Epoch: 6| Step: 5
Training loss: 0.6105766296386719
Validation loss: 2.1658181150754294

Epoch: 6| Step: 6
Training loss: 1.6086034774780273
Validation loss: 2.159438947836558

Epoch: 6| Step: 7
Training loss: 1.1924960613250732
Validation loss: 2.1516223748524985

Epoch: 6| Step: 8
Training loss: 0.5688833594322205
Validation loss: 2.154076854387919

Epoch: 6| Step: 9
Training loss: 0.9395462870597839
Validation loss: 2.0804697275161743

Epoch: 6| Step: 10
Training loss: 0.7991161346435547
Validation loss: 2.1205007036527

Epoch: 6| Step: 11
Training loss: 0.9309091567993164
Validation loss: 2.1153391202290854

Epoch: 6| Step: 12
Training loss: 0.6200110912322998
Validation loss: 2.1694639523824057

Epoch: 6| Step: 13
Training loss: 0.8091800212860107
Validation loss: 2.130959451198578

Epoch: 189| Step: 0
Training loss: 0.8228106498718262
Validation loss: 2.170920709768931

Epoch: 6| Step: 1
Training loss: 1.010360836982727
Validation loss: 2.1912788550059

Epoch: 6| Step: 2
Training loss: 0.9355103969573975
Validation loss: 2.2233620087305703

Epoch: 6| Step: 3
Training loss: 1.0133728981018066
Validation loss: 2.1901735266049704

Epoch: 6| Step: 4
Training loss: 0.5532960891723633
Validation loss: 2.1843281189600625

Epoch: 6| Step: 5
Training loss: 1.1523185968399048
Validation loss: 2.1335508823394775

Epoch: 6| Step: 6
Training loss: 0.6125590205192566
Validation loss: 2.060618837674459

Epoch: 6| Step: 7
Training loss: 0.5448625087738037
Validation loss: 2.1269319653511047

Epoch: 6| Step: 8
Training loss: 0.7802460193634033
Validation loss: 2.0722184975941977

Epoch: 6| Step: 9
Training loss: 0.8550429940223694
Validation loss: 2.1171832283337912

Epoch: 6| Step: 10
Training loss: 0.5619715452194214
Validation loss: 2.1323999961217246

Epoch: 6| Step: 11
Training loss: 0.883756697177887
Validation loss: 2.073936144510905

Epoch: 6| Step: 12
Training loss: 0.5759037733078003
Validation loss: 2.079751491546631

Epoch: 6| Step: 13
Training loss: 1.0449143648147583
Validation loss: 2.1533691684405007

Epoch: 190| Step: 0
Training loss: 1.0380064249038696
Validation loss: 2.158246318499247

Epoch: 6| Step: 1
Training loss: 0.4917142391204834
Validation loss: 2.120352586110433

Epoch: 6| Step: 2
Training loss: 0.9693197011947632
Validation loss: 2.1378483176231384

Epoch: 6| Step: 3
Training loss: 0.6958261132240295
Validation loss: 2.1153488953908286

Epoch: 6| Step: 4
Training loss: 0.7905963063240051
Validation loss: 2.1389352083206177

Epoch: 6| Step: 5
Training loss: 0.9140682220458984
Validation loss: 2.1302457253138223

Epoch: 6| Step: 6
Training loss: 0.7890918254852295
Validation loss: 2.0952755014101663

Epoch: 6| Step: 7
Training loss: 0.6419080495834351
Validation loss: 2.128693997859955

Epoch: 6| Step: 8
Training loss: 0.5306832194328308
Validation loss: 2.163062413533529

Epoch: 6| Step: 9
Training loss: 0.869255542755127
Validation loss: 2.172023872534434

Epoch: 6| Step: 10
Training loss: 0.4799329340457916
Validation loss: 2.1185829043388367

Epoch: 6| Step: 11
Training loss: 1.1541612148284912
Validation loss: 2.1846062938372293

Epoch: 6| Step: 12
Training loss: 0.5928979516029358
Validation loss: 2.1859087347984314

Epoch: 6| Step: 13
Training loss: 0.9247437119483948
Validation loss: 2.1856327454249063

Epoch: 191| Step: 0
Training loss: 0.6708216667175293
Validation loss: 2.1358695228894553

Epoch: 6| Step: 1
Training loss: 0.3645714819431305
Validation loss: 2.0884823203086853

Epoch: 6| Step: 2
Training loss: 0.5542449951171875
Validation loss: 2.1415592432022095

Epoch: 6| Step: 3
Training loss: 0.5893764495849609
Validation loss: 2.0697599252065024

Epoch: 6| Step: 4
Training loss: 1.5045840740203857
Validation loss: 2.1542702317237854

Epoch: 6| Step: 5
Training loss: 0.6618437767028809
Validation loss: 2.0700730880101523

Epoch: 6| Step: 6
Training loss: 0.6720795631408691
Validation loss: 2.1867650349934897

Epoch: 6| Step: 7
Training loss: 0.5804188251495361
Validation loss: 2.1078895926475525

Epoch: 6| Step: 8
Training loss: 0.9072954058647156
Validation loss: 2.1568044225374856

Epoch: 6| Step: 9
Training loss: 0.8789599537849426
Validation loss: 2.1313711404800415

Epoch: 6| Step: 10
Training loss: 0.5710526704788208
Validation loss: 2.1288185914357505

Epoch: 6| Step: 11
Training loss: 0.6836928725242615
Validation loss: 2.1584592461586

Epoch: 6| Step: 12
Training loss: 0.8488181829452515
Validation loss: 2.1043188174565635

Epoch: 6| Step: 13
Training loss: 1.0789344310760498
Validation loss: 2.108909328778585

Epoch: 192| Step: 0
Training loss: 0.7001879811286926
Validation loss: 2.0971945325533548

Epoch: 6| Step: 1
Training loss: 0.5134390592575073
Validation loss: 2.109747668107351

Epoch: 6| Step: 2
Training loss: 0.5882480144500732
Validation loss: 2.143799622853597

Epoch: 6| Step: 3
Training loss: 1.1354737281799316
Validation loss: 2.1638999581336975

Epoch: 6| Step: 4
Training loss: 0.4222172796726227
Validation loss: 2.087061107158661

Epoch: 6| Step: 5
Training loss: 1.1385265588760376
Validation loss: 2.1573172410329184

Epoch: 6| Step: 6
Training loss: 0.4494625926017761
Validation loss: 2.1263857881228128

Epoch: 6| Step: 7
Training loss: 0.9191246032714844
Validation loss: 2.1578506032625833

Epoch: 6| Step: 8
Training loss: 0.6269577145576477
Validation loss: 2.194624940554301

Epoch: 6| Step: 9
Training loss: 0.883915901184082
Validation loss: 2.121579905351003

Epoch: 6| Step: 10
Training loss: 0.5560628175735474
Validation loss: 2.201067864894867

Epoch: 6| Step: 11
Training loss: 0.8234330415725708
Validation loss: 2.101689418156942

Epoch: 6| Step: 12
Training loss: 0.7712529301643372
Validation loss: 2.203032910823822

Epoch: 6| Step: 13
Training loss: 0.6038293838500977
Validation loss: 2.125650942325592

Epoch: 193| Step: 0
Training loss: 0.5205508470535278
Validation loss: 2.085912744204203

Epoch: 6| Step: 1
Training loss: 0.8233703374862671
Validation loss: 2.181316832701365

Epoch: 6| Step: 2
Training loss: 0.7068358063697815
Validation loss: 2.159284551938375

Epoch: 6| Step: 3
Training loss: 0.9087232351303101
Validation loss: 2.0981944799423218

Epoch: 6| Step: 4
Training loss: 0.7371688485145569
Validation loss: 2.151596963405609

Epoch: 6| Step: 5
Training loss: 0.6665226221084595
Validation loss: 2.144401967525482

Epoch: 6| Step: 6
Training loss: 0.9191815853118896
Validation loss: 2.165047347545624

Epoch: 6| Step: 7
Training loss: 0.7076753377914429
Validation loss: 2.1746692657470703

Epoch: 6| Step: 8
Training loss: 0.3913482129573822
Validation loss: 2.194259603818258

Epoch: 6| Step: 9
Training loss: 0.9683192372322083
Validation loss: 2.1517005562782288

Epoch: 6| Step: 10
Training loss: 1.1063522100448608
Validation loss: 2.1584050258000693

Epoch: 6| Step: 11
Training loss: 0.5993058681488037
Validation loss: 2.1756935516993203

Epoch: 6| Step: 12
Training loss: 0.9011688828468323
Validation loss: 2.141539374987284

Epoch: 6| Step: 13
Training loss: 0.5404198169708252
Validation loss: 2.156786024570465

Epoch: 194| Step: 0
Training loss: 0.4039098918437958
Validation loss: 2.1060102184613547

Epoch: 6| Step: 1
Training loss: 1.2580143213272095
Validation loss: 2.122495492299398

Epoch: 6| Step: 2
Training loss: 0.43223655223846436
Validation loss: 2.08399905761083

Epoch: 6| Step: 3
Training loss: 0.7481517791748047
Validation loss: 2.1313835779825845

Epoch: 6| Step: 4
Training loss: 0.9159151315689087
Validation loss: 2.1485241452852883

Epoch: 6| Step: 5
Training loss: 1.025331735610962
Validation loss: 2.1413034995396933

Epoch: 6| Step: 6
Training loss: 0.6881868839263916
Validation loss: 2.100292960802714

Epoch: 6| Step: 7
Training loss: 1.0928884744644165
Validation loss: 2.1517015298207602

Epoch: 6| Step: 8
Training loss: 0.4474446475505829
Validation loss: 2.2096073627471924

Epoch: 6| Step: 9
Training loss: 0.7241718769073486
Validation loss: 2.157123307387034

Epoch: 6| Step: 10
Training loss: 0.8160348534584045
Validation loss: 2.217904190222422

Epoch: 6| Step: 11
Training loss: 0.6552135944366455
Validation loss: 2.2114622990290322

Epoch: 6| Step: 12
Training loss: 0.8739749789237976
Validation loss: 2.185357371966044

Epoch: 6| Step: 13
Training loss: 1.054969310760498
Validation loss: 2.1815122167269387

Epoch: 195| Step: 0
Training loss: 0.807923436164856
Validation loss: 2.136551300684611

Epoch: 6| Step: 1
Training loss: 0.564471960067749
Validation loss: 2.072224954764048

Epoch: 6| Step: 2
Training loss: 0.7663100361824036
Validation loss: 2.148659368356069

Epoch: 6| Step: 3
Training loss: 0.5792534351348877
Validation loss: 2.0703157583872476

Epoch: 6| Step: 4
Training loss: 0.8529487252235413
Validation loss: 2.1068979303042092

Epoch: 6| Step: 5
Training loss: 1.2761117219924927
Validation loss: 2.101596494515737

Epoch: 6| Step: 6
Training loss: 0.8572335839271545
Validation loss: 2.084890921910604

Epoch: 6| Step: 7
Training loss: 0.41849178075790405
Validation loss: 2.184270143508911

Epoch: 6| Step: 8
Training loss: 1.0501586198806763
Validation loss: 2.131780763467153

Epoch: 6| Step: 9
Training loss: 0.6767133474349976
Validation loss: 2.1516688466072083

Epoch: 6| Step: 10
Training loss: 0.36514514684677124
Validation loss: 2.167194187641144

Epoch: 6| Step: 11
Training loss: 0.5670865774154663
Validation loss: 2.151977082093557

Epoch: 6| Step: 12
Training loss: 0.8151013255119324
Validation loss: 2.17897762854894

Epoch: 6| Step: 13
Training loss: 0.848461389541626
Validation loss: 2.0941473841667175

Epoch: 196| Step: 0
Training loss: 0.951203465461731
Validation loss: 2.124849279721578

Epoch: 6| Step: 1
Training loss: 0.7456292510032654
Validation loss: 2.108601967493693

Epoch: 6| Step: 2
Training loss: 0.5278598070144653
Validation loss: 2.1086008151372275

Epoch: 6| Step: 3
Training loss: 0.49530279636383057
Validation loss: 2.1042179067929587

Epoch: 6| Step: 4
Training loss: 0.9391241669654846
Validation loss: 2.1624263525009155

Epoch: 6| Step: 5
Training loss: 0.7080990076065063
Validation loss: 2.1729888121287027

Epoch: 6| Step: 6
Training loss: 0.8938316702842712
Validation loss: 2.176781256993612

Epoch: 6| Step: 7
Training loss: 0.5943329334259033
Validation loss: 2.1618868112564087

Epoch: 6| Step: 8
Training loss: 1.2090303897857666
Validation loss: 2.222325563430786

Epoch: 6| Step: 9
Training loss: 1.1716375350952148
Validation loss: 2.1428658763567605

Epoch: 6| Step: 10
Training loss: 0.5733011960983276
Validation loss: 2.1187451481819153

Epoch: 6| Step: 11
Training loss: 0.8628463745117188
Validation loss: 2.115489443143209

Epoch: 6| Step: 12
Training loss: 0.5270265340805054
Validation loss: 2.1189301013946533

Epoch: 6| Step: 13
Training loss: 1.0374315977096558
Validation loss: 2.097394565741221

Epoch: 197| Step: 0
Training loss: 0.6866270303726196
Validation loss: 2.0968918204307556

Epoch: 6| Step: 1
Training loss: 0.44792482256889343
Validation loss: 2.1313475966453552

Epoch: 6| Step: 2
Training loss: 0.36599379777908325
Validation loss: 2.1153375109036765

Epoch: 6| Step: 3
Training loss: 1.147658348083496
Validation loss: 2.115833103656769

Epoch: 6| Step: 4
Training loss: 0.6876353025436401
Validation loss: 2.1812008023262024

Epoch: 6| Step: 5
Training loss: 0.5884310603141785
Validation loss: 2.117750823497772

Epoch: 6| Step: 6
Training loss: 0.8367108106613159
Validation loss: 2.1163512070973716

Epoch: 6| Step: 7
Training loss: 0.9940326809883118
Validation loss: 2.112876812616984

Epoch: 6| Step: 8
Training loss: 0.7278324961662292
Validation loss: 2.068585216999054

Epoch: 6| Step: 9
Training loss: 1.2803572416305542
Validation loss: 2.146531959374746

Epoch: 6| Step: 10
Training loss: 0.7485086917877197
Validation loss: 2.1655861536661782

Epoch: 6| Step: 11
Training loss: 0.9628684520721436
Validation loss: 2.1520973841349282

Epoch: 6| Step: 12
Training loss: 0.5595636963844299
Validation loss: 2.1245399912198386

Epoch: 6| Step: 13
Training loss: 0.40018925070762634
Validation loss: 2.1536060770352683

Epoch: 198| Step: 0
Training loss: 0.9530571103096008
Validation loss: 2.132930636405945

Epoch: 6| Step: 1
Training loss: 0.627031683921814
Validation loss: 2.142177700996399

Epoch: 6| Step: 2
Training loss: 0.9475986361503601
Validation loss: 2.177025020122528

Epoch: 6| Step: 3
Training loss: 0.38908669352531433
Validation loss: 2.197451094786326

Epoch: 6| Step: 4
Training loss: 0.2962803244590759
Validation loss: 2.182174344857534

Epoch: 6| Step: 5
Training loss: 1.0124925374984741
Validation loss: 2.2024524013201394

Epoch: 6| Step: 6
Training loss: 0.7207736968994141
Validation loss: 2.183288594086965

Epoch: 6| Step: 7
Training loss: 0.438653826713562
Validation loss: 2.1445146799087524

Epoch: 6| Step: 8
Training loss: 0.6521512269973755
Validation loss: 2.1201727986335754

Epoch: 6| Step: 9
Training loss: 0.7496575117111206
Validation loss: 2.109280228614807

Epoch: 6| Step: 10
Training loss: 0.6868888735771179
Validation loss: 2.0926113526026406

Epoch: 6| Step: 11
Training loss: 0.5987433195114136
Validation loss: 2.114720602830251

Epoch: 6| Step: 12
Training loss: 0.7771285772323608
Validation loss: 2.1521039803822837

Epoch: 6| Step: 13
Training loss: 1.039001226425171
Validation loss: 2.173616647720337

Epoch: 199| Step: 0
Training loss: 0.48422229290008545
Validation loss: 2.1069907943407693

Epoch: 6| Step: 1
Training loss: 0.7043055891990662
Validation loss: 2.1750622590382895

Epoch: 6| Step: 2
Training loss: 0.7430286407470703
Validation loss: 2.1850027044614158

Epoch: 6| Step: 3
Training loss: 0.7489703893661499
Validation loss: 2.1845879356066384

Epoch: 6| Step: 4
Training loss: 0.45290711522102356
Validation loss: 2.112803876399994

Epoch: 6| Step: 5
Training loss: 0.7275087833404541
Validation loss: 2.1266161998113

Epoch: 6| Step: 6
Training loss: 0.5677163600921631
Validation loss: 2.11291633049647

Epoch: 6| Step: 7
Training loss: 0.6046687960624695
Validation loss: 2.092764735221863

Epoch: 6| Step: 8
Training loss: 0.7782135009765625
Validation loss: 2.171230673789978

Epoch: 6| Step: 9
Training loss: 0.7440954446792603
Validation loss: 2.179690420627594

Epoch: 6| Step: 10
Training loss: 0.840685248374939
Validation loss: 2.1803646286328635

Epoch: 6| Step: 11
Training loss: 0.7598876953125
Validation loss: 2.1666930119196572

Epoch: 6| Step: 12
Training loss: 0.9416345357894897
Validation loss: 2.133132735888163

Epoch: 6| Step: 13
Training loss: 0.9846988916397095
Validation loss: 2.1172868609428406

Epoch: 200| Step: 0
Training loss: 0.48002099990844727
Validation loss: 2.13486655553182

Epoch: 6| Step: 1
Training loss: 0.6367676854133606
Validation loss: 2.1494645873705545

Epoch: 6| Step: 2
Training loss: 0.5184995532035828
Validation loss: 2.162626306215922

Epoch: 6| Step: 3
Training loss: 0.57659912109375
Validation loss: 2.146939198176066

Epoch: 6| Step: 4
Training loss: 0.5605663061141968
Validation loss: 2.1525551080703735

Epoch: 6| Step: 5
Training loss: 0.4207651615142822
Validation loss: 2.2164944609006247

Epoch: 6| Step: 6
Training loss: 0.7667216658592224
Validation loss: 2.14884877204895

Epoch: 6| Step: 7
Training loss: 0.9434211850166321
Validation loss: 2.2006141344706216

Epoch: 6| Step: 8
Training loss: 0.5135276317596436
Validation loss: 2.159061928590139

Epoch: 6| Step: 9
Training loss: 0.8641639351844788
Validation loss: 2.1742461721102395

Epoch: 6| Step: 10
Training loss: 1.4012858867645264
Validation loss: 2.179453273614248

Epoch: 6| Step: 11
Training loss: 0.910723090171814
Validation loss: 2.1814635396003723

Epoch: 6| Step: 12
Training loss: 0.5388092994689941
Validation loss: 2.1604332526524863

Epoch: 6| Step: 13
Training loss: 0.6504514217376709
Validation loss: 2.1455127596855164

Testing loss: 2.1554178556949974
