Epoch: 1| Step: 0
Training loss: 5.096513271331787
Validation loss: 5.12678044476955
Epoch: 5| Step: 1
Training loss: 5.712167739868164
Validation loss: 5.12350822352677
Epoch: 5| Step: 2
Training loss: 4.396693706512451
Validation loss: 5.117200316285058
Epoch: 5| Step: 3
Training loss: 5.317196846008301
Validation loss: 5.114878579009351
Epoch: 5| Step: 4
Training loss: 4.326131343841553
Validation loss: 5.108516048184402
Epoch: 5| Step: 5
Training loss: 5.374617099761963
Validation loss: 5.10544110030579
Epoch: 5| Step: 6
Training loss: 5.597552299499512
Validation loss: 5.100393991676166
Epoch: 5| Step: 7
Training loss: 5.34816312789917
Validation loss: 5.100374990229984
Epoch: 5| Step: 8
Training loss: 5.550790786743164
Validation loss: 5.0953633802400216
Epoch: 5| Step: 9
Training loss: 5.822487831115723
Validation loss: 5.094404546476954
Epoch: 2| Step: 0
Training loss: 5.320749282836914
Validation loss: 5.089165059782618
Epoch: 5| Step: 1
Training loss: 5.168625831604004
Validation loss: 5.082133560729542
Epoch: 5| Step: 2
Training loss: 4.959871292114258
Validation loss: 5.07980065380069
Epoch: 5| Step: 3
Training loss: 4.885512351989746
Validation loss: 5.0780454059298945
Epoch: 5| Step: 4
Training loss: 4.969757080078125
Validation loss: 5.073368899256206
Epoch: 5| Step: 5
Training loss: 4.968782901763916
Validation loss: 5.07205322663561
Epoch: 5| Step: 6
Training loss: 5.525083541870117
Validation loss: 5.064566780337326
Epoch: 5| Step: 7
Training loss: 5.82852840423584
Validation loss: 5.0643690095531
Epoch: 5| Step: 8
Training loss: 5.08648681640625
Validation loss: 5.058723885378392
Epoch: 5| Step: 9
Training loss: 5.461996078491211
Validation loss: 5.053943023407202
Epoch: 3| Step: 0
Training loss: 5.80790376663208
Validation loss: 5.053750576732828
Epoch: 5| Step: 1
Training loss: 5.246463775634766
Validation loss: 5.046572177530193
Epoch: 5| Step: 2
Training loss: 5.526961326599121
Validation loss: 5.042790087006932
Epoch: 5| Step: 3
Training loss: 4.682615280151367
Validation loss: 5.0415312815055575
Epoch: 5| Step: 4
Training loss: 5.1188201904296875
Validation loss: 5.036916015817107
Epoch: 5| Step: 5
Training loss: 5.147110939025879
Validation loss: 5.033203550379911
Epoch: 5| Step: 6
Training loss: 6.281048774719238
Validation loss: 5.029377069404657
Epoch: 5| Step: 7
Training loss: 4.381425857543945
Validation loss: 5.026041655231722
Epoch: 5| Step: 8
Training loss: 4.385014533996582
Validation loss: 5.023686275207739
Epoch: 5| Step: 9
Training loss: 5.26584529876709
Validation loss: 5.017192233380654
Epoch: 4| Step: 0
Training loss: 5.303459167480469
Validation loss: 5.014775927975881
Epoch: 5| Step: 1
Training loss: 4.994894981384277
Validation loss: 5.010742021121567
Epoch: 5| Step: 2
Training loss: 5.206986904144287
Validation loss: 5.005464224506625
Epoch: 5| Step: 3
Training loss: 5.627277851104736
Validation loss: 5.004180090032893
Epoch: 5| Step: 4
Training loss: 5.0567097663879395
Validation loss: 4.99928224687096
Epoch: 5| Step: 5
Training loss: 4.726354598999023
Validation loss: 4.992205558063315
Epoch: 5| Step: 6
Training loss: 5.11712646484375
Validation loss: 4.990174828673438
Epoch: 5| Step: 7
Training loss: 5.49094820022583
Validation loss: 4.984976089257988
Epoch: 5| Step: 8
Training loss: 4.4035491943359375
Validation loss: 4.981671045152403
Epoch: 5| Step: 9
Training loss: 5.556387901306152
Validation loss: 4.978416082670363
Epoch: 5| Step: 0
Training loss: 4.159774303436279
Validation loss: 4.974093035828296
Epoch: 5| Step: 1
Training loss: 5.238099098205566
Validation loss: 4.968812294143567
Epoch: 5| Step: 2
Training loss: 4.249346733093262
Validation loss: 4.9654334174643315
Epoch: 5| Step: 3
Training loss: 5.554508209228516
Validation loss: 4.963223350991448
Epoch: 5| Step: 4
Training loss: 5.689316749572754
Validation loss: 4.956366449808903
Epoch: 5| Step: 5
Training loss: 5.317643642425537
Validation loss: 4.954696494040729
Epoch: 5| Step: 6
Training loss: 5.4030656814575195
Validation loss: 4.949759510781267
Epoch: 5| Step: 7
Training loss: 4.894391059875488
Validation loss: 4.945362190548464
Epoch: 5| Step: 8
Training loss: 5.321200370788574
Validation loss: 4.941074498265767
Epoch: 5| Step: 9
Training loss: 5.267306804656982
Validation loss: 4.9344331926579095
Epoch: 6| Step: 0
Training loss: 4.990187168121338
Validation loss: 4.933445076290652
Epoch: 5| Step: 1
Training loss: 4.45353889465332
Validation loss: 4.924701676951895
Epoch: 5| Step: 2
Training loss: 5.965073108673096
Validation loss: 4.924218116046713
Epoch: 5| Step: 3
Training loss: 4.672387599945068
Validation loss: 4.916118638978587
Epoch: 5| Step: 4
Training loss: 4.318412780761719
Validation loss: 4.9130069094596145
Epoch: 5| Step: 5
Training loss: 5.699518203735352
Validation loss: 4.908470493426426
Epoch: 5| Step: 6
Training loss: 4.940715789794922
Validation loss: 4.904101207101945
Epoch: 5| Step: 7
Training loss: 4.471269130706787
Validation loss: 4.897756230059287
Epoch: 5| Step: 8
Training loss: 5.3517255783081055
Validation loss: 4.895546631847354
Epoch: 5| Step: 9
Training loss: 5.811741828918457
Validation loss: 4.892161396767595
Epoch: 7| Step: 0
Training loss: 4.06528377532959
Validation loss: 4.887493943138946
Epoch: 5| Step: 1
Training loss: 6.105874061584473
Validation loss: 4.883421571992284
Epoch: 5| Step: 2
Training loss: 5.5376057624816895
Validation loss: 4.8761923707646435
Epoch: 5| Step: 3
Training loss: 5.146636009216309
Validation loss: 4.869000510346118
Epoch: 5| Step: 4
Training loss: 4.207550525665283
Validation loss: 4.864302806717029
Epoch: 5| Step: 5
Training loss: 4.893558502197266
Validation loss: 4.860344262431852
Epoch: 5| Step: 6
Training loss: 5.336966514587402
Validation loss: 4.853744328450814
Epoch: 5| Step: 7
Training loss: 5.61624813079834
Validation loss: 4.8514216820970715
Epoch: 5| Step: 8
Training loss: 5.282463073730469
Validation loss: 4.845523504902133
Epoch: 5| Step: 9
Training loss: 4.028909683227539
Validation loss: 4.83686263612706
Epoch: 8| Step: 0
Training loss: 5.238001346588135
Validation loss: 4.834262244135356
Epoch: 5| Step: 1
Training loss: 4.909476280212402
Validation loss: 4.8269524780108775
Epoch: 5| Step: 2
Training loss: 5.142497539520264
Validation loss: 4.821929204378197
Epoch: 5| Step: 3
Training loss: 5.544082164764404
Validation loss: 4.8165465155951415
Epoch: 5| Step: 4
Training loss: 4.874342918395996
Validation loss: 4.8138569344719535
Epoch: 5| Step: 5
Training loss: 5.520083427429199
Validation loss: 4.805023018404734
Epoch: 5| Step: 6
Training loss: 4.140902519226074
Validation loss: 4.801092857937161
Epoch: 5| Step: 7
Training loss: 5.233983993530273
Validation loss: 4.7950408235728315
Epoch: 5| Step: 8
Training loss: 5.224310874938965
Validation loss: 4.790043724526604
Epoch: 5| Step: 9
Training loss: 3.92398738861084
Validation loss: 4.78459927332487
Epoch: 9| Step: 0
Training loss: 5.293772220611572
Validation loss: 4.77780294418335
Epoch: 5| Step: 1
Training loss: 5.109303951263428
Validation loss: 4.771550799445283
Epoch: 5| Step: 2
Training loss: 4.624845504760742
Validation loss: 4.765969842457943
Epoch: 5| Step: 3
Training loss: 5.258969306945801
Validation loss: 4.759389908193684
Epoch: 5| Step: 4
Training loss: 4.720322132110596
Validation loss: 4.752841753925351
Epoch: 5| Step: 5
Training loss: 5.2402544021606445
Validation loss: 4.743340893615064
Epoch: 5| Step: 6
Training loss: 4.694675922393799
Validation loss: 4.743331466647361
Epoch: 5| Step: 7
Training loss: 4.992227554321289
Validation loss: 4.732479116041883
Epoch: 5| Step: 8
Training loss: 4.844033241271973
Validation loss: 4.730754972361832
Epoch: 5| Step: 9
Training loss: 4.424917697906494
Validation loss: 4.719272579220559
Epoch: 10| Step: 0
Training loss: 5.079288482666016
Validation loss: 4.7133509718256885
Epoch: 5| Step: 1
Training loss: 5.705350875854492
Validation loss: 4.710959362469131
Epoch: 5| Step: 2
Training loss: 4.2876996994018555
Validation loss: 4.700478980867125
Epoch: 5| Step: 3
Training loss: 4.623025417327881
Validation loss: 4.695461854660254
Epoch: 5| Step: 4
Training loss: 4.253572463989258
Validation loss: 4.687849552511311
Epoch: 5| Step: 5
Training loss: 5.068552017211914
Validation loss: 4.682063106152651
Epoch: 5| Step: 6
Training loss: 5.001761436462402
Validation loss: 4.672901872250674
Epoch: 5| Step: 7
Training loss: 4.982088088989258
Validation loss: 4.663144735981234
Epoch: 5| Step: 8
Training loss: 4.4080119132995605
Validation loss: 4.656002892007073
Epoch: 5| Step: 9
Training loss: 5.153212070465088
Validation loss: 4.65242938858142
Epoch: 11| Step: 0
Training loss: 5.097562789916992
Validation loss: 4.641880838133448
Epoch: 5| Step: 1
Training loss: 4.890700817108154
Validation loss: 4.6347038865947034
Epoch: 5| Step: 2
Training loss: 4.829965114593506
Validation loss: 4.630855138353307
Epoch: 5| Step: 3
Training loss: 4.218221187591553
Validation loss: 4.622991109065873
Epoch: 5| Step: 4
Training loss: 4.930784225463867
Validation loss: 4.616719870258578
Epoch: 5| Step: 5
Training loss: 5.700935363769531
Validation loss: 4.606232667140824
Epoch: 5| Step: 6
Training loss: 4.209200859069824
Validation loss: 4.596771631309454
Epoch: 5| Step: 7
Training loss: 4.214556694030762
Validation loss: 4.5906987910648045
Epoch: 5| Step: 8
Training loss: 4.822835922241211
Validation loss: 4.581759308739532
Epoch: 5| Step: 9
Training loss: 4.965710639953613
Validation loss: 4.575025503583949
Epoch: 12| Step: 0
Training loss: 4.2333149909973145
Validation loss: 4.563276458987229
Epoch: 5| Step: 1
Training loss: 5.273830890655518
Validation loss: 4.558079877345682
Epoch: 5| Step: 2
Training loss: 4.509512901306152
Validation loss: 4.549072028921662
Epoch: 5| Step: 3
Training loss: 4.66848087310791
Validation loss: 4.54438931650395
Epoch: 5| Step: 4
Training loss: 5.1125593185424805
Validation loss: 4.533059312285279
Epoch: 5| Step: 5
Training loss: 4.091777801513672
Validation loss: 4.521250122742687
Epoch: 5| Step: 6
Training loss: 5.035155296325684
Validation loss: 4.509924151056962
Epoch: 5| Step: 7
Training loss: 4.839582443237305
Validation loss: 4.503415961917356
Epoch: 5| Step: 8
Training loss: 4.096674919128418
Validation loss: 4.495165149084956
Epoch: 5| Step: 9
Training loss: 5.289290904998779
Validation loss: 4.488896747287229
Epoch: 13| Step: 0
Training loss: 5.4011688232421875
Validation loss: 4.477177872074594
Epoch: 5| Step: 1
Training loss: 3.377145528793335
Validation loss: 4.46623453304922
Epoch: 5| Step: 2
Training loss: 5.093783378601074
Validation loss: 4.45725642348365
Epoch: 5| Step: 3
Training loss: 4.905855178833008
Validation loss: 4.453882001286788
Epoch: 5| Step: 4
Training loss: 4.453526496887207
Validation loss: 4.439594505502166
Epoch: 5| Step: 5
Training loss: 4.994091987609863
Validation loss: 4.427471013377897
Epoch: 5| Step: 6
Training loss: 4.205295085906982
Validation loss: 4.416302761585593
Epoch: 5| Step: 7
Training loss: 5.14238166809082
Validation loss: 4.407401879056752
Epoch: 5| Step: 8
Training loss: 4.07121467590332
Validation loss: 4.396998439761375
Epoch: 5| Step: 9
Training loss: 4.6456522941589355
Validation loss: 4.384995834432917
Epoch: 14| Step: 0
Training loss: 5.018019676208496
Validation loss: 4.370886891865902
Epoch: 5| Step: 1
Training loss: 4.721334457397461
Validation loss: 4.361316814697046
Epoch: 5| Step: 2
Training loss: 4.576369285583496
Validation loss: 4.349338891694871
Epoch: 5| Step: 3
Training loss: 3.867664337158203
Validation loss: 4.33933699216774
Epoch: 5| Step: 4
Training loss: 4.946649551391602
Validation loss: 4.327110456905777
Epoch: 5| Step: 5
Training loss: 4.487893104553223
Validation loss: 4.316368868025087
Epoch: 5| Step: 6
Training loss: 4.907572269439697
Validation loss: 4.29773888313513
Epoch: 5| Step: 7
Training loss: 4.484903335571289
Validation loss: 4.286555351970865
Epoch: 5| Step: 8
Training loss: 4.314203262329102
Validation loss: 4.275817703000076
Epoch: 5| Step: 9
Training loss: 4.007829666137695
Validation loss: 4.268264729342015
Epoch: 15| Step: 0
Training loss: 4.503639221191406
Validation loss: 4.2476367127123495
Epoch: 5| Step: 1
Training loss: 4.1746439933776855
Validation loss: 4.238227343387741
Epoch: 5| Step: 2
Training loss: 3.379136085510254
Validation loss: 4.219563813518278
Epoch: 5| Step: 3
Training loss: 4.903159141540527
Validation loss: 4.214619964146785
Epoch: 5| Step: 4
Training loss: 5.079428672790527
Validation loss: 4.204707656832908
Epoch: 5| Step: 5
Training loss: 4.4679646492004395
Validation loss: 4.182991532113054
Epoch: 5| Step: 6
Training loss: 4.22969388961792
Validation loss: 4.170962316526784
Epoch: 5| Step: 7
Training loss: 4.175775527954102
Validation loss: 4.161006285989885
Epoch: 5| Step: 8
Training loss: 4.50495719909668
Validation loss: 4.147525807936415
Epoch: 5| Step: 9
Training loss: 4.7739057540893555
Validation loss: 4.130239435237089
Epoch: 16| Step: 0
Training loss: 4.593610763549805
Validation loss: 4.121503504060155
Epoch: 5| Step: 1
Training loss: 3.8635802268981934
Validation loss: 4.106098325990087
Epoch: 5| Step: 2
Training loss: 4.24903678894043
Validation loss: 4.088413543838391
Epoch: 5| Step: 3
Training loss: 4.46083927154541
Validation loss: 4.077548783460109
Epoch: 5| Step: 4
Training loss: 4.388105392456055
Validation loss: 4.050728303923024
Epoch: 5| Step: 5
Training loss: 4.832034111022949
Validation loss: 4.034005141086715
Epoch: 5| Step: 6
Training loss: 4.136014938354492
Validation loss: 4.029351080064293
Epoch: 5| Step: 7
Training loss: 4.6544036865234375
Validation loss: 4.008780904811063
Epoch: 5| Step: 8
Training loss: 4.039806842803955
Validation loss: 3.98916872456777
Epoch: 5| Step: 9
Training loss: 3.8162622451782227
Validation loss: 3.9769961062095147
Epoch: 17| Step: 0
Training loss: 4.072943687438965
Validation loss: 3.9518701206865927
Epoch: 5| Step: 1
Training loss: 4.524613857269287
Validation loss: 3.944350590808786
Epoch: 5| Step: 2
Training loss: 4.474986553192139
Validation loss: 3.931799300282979
Epoch: 5| Step: 3
Training loss: 4.021745681762695
Validation loss: 3.913213657818252
Epoch: 5| Step: 4
Training loss: 3.332345724105835
Validation loss: 3.894861114968499
Epoch: 5| Step: 5
Training loss: 4.028810977935791
Validation loss: 3.8785249552280785
Epoch: 5| Step: 6
Training loss: 3.9392871856689453
Validation loss: 3.8582785026632624
Epoch: 5| Step: 7
Training loss: 4.58329963684082
Validation loss: 3.8315446222428795
Epoch: 5| Step: 8
Training loss: 4.4503936767578125
Validation loss: 3.8250254401200108
Epoch: 5| Step: 9
Training loss: 4.198451995849609
Validation loss: 3.8027269857392896
Epoch: 18| Step: 0
Training loss: 4.078876495361328
Validation loss: 3.7839889011794714
Epoch: 5| Step: 1
Training loss: 3.2309045791625977
Validation loss: 3.7636564018057403
Epoch: 5| Step: 2
Training loss: 4.580018997192383
Validation loss: 3.7414846831946065
Epoch: 5| Step: 3
Training loss: 3.40310001373291
Validation loss: 3.72056587479955
Epoch: 5| Step: 4
Training loss: 4.043813705444336
Validation loss: 3.7024127184915887
Epoch: 5| Step: 5
Training loss: 3.5462088584899902
Validation loss: 3.687760835071262
Epoch: 5| Step: 6
Training loss: 4.487774848937988
Validation loss: 3.657483903624171
Epoch: 5| Step: 7
Training loss: 4.1853227615356445
Validation loss: 3.637491972326375
Epoch: 5| Step: 8
Training loss: 4.000217437744141
Validation loss: 3.621097542399125
Epoch: 5| Step: 9
Training loss: 4.485950469970703
Validation loss: 3.601495199066272
Epoch: 19| Step: 0
Training loss: 3.4849119186401367
Validation loss: 3.576257453547965
Epoch: 5| Step: 1
Training loss: 4.485874176025391
Validation loss: 3.5525948812635684
Epoch: 5| Step: 2
Training loss: 3.609691619873047
Validation loss: 3.5429729266132384
Epoch: 5| Step: 3
Training loss: 4.338324546813965
Validation loss: 3.509578610495698
Epoch: 5| Step: 4
Training loss: 3.473097324371338
Validation loss: 3.4835179349501355
Epoch: 5| Step: 5
Training loss: 3.7643637657165527
Validation loss: 3.4610094783975067
Epoch: 5| Step: 6
Training loss: 3.2675061225891113
Validation loss: 3.44636947817082
Epoch: 5| Step: 7
Training loss: 3.8164753913879395
Validation loss: 3.428076797252079
Epoch: 5| Step: 8
Training loss: 4.405889511108398
Validation loss: 3.401311419850631
Epoch: 5| Step: 9
Training loss: 3.6910741329193115
Validation loss: 3.3578624742494214
Epoch: 20| Step: 0
Training loss: 3.6583776473999023
Validation loss: 3.347785733586593
Epoch: 5| Step: 1
Training loss: 3.862543821334839
Validation loss: 3.325880702450979
Epoch: 5| Step: 2
Training loss: 3.804611921310425
Validation loss: 3.301680427661045
Epoch: 5| Step: 3
Training loss: 3.329742908477783
Validation loss: 3.292312507149127
Epoch: 5| Step: 4
Training loss: 3.5309958457946777
Validation loss: 3.252762211312493
Epoch: 5| Step: 5
Training loss: 3.5899887084960938
Validation loss: 3.22615878015971
Epoch: 5| Step: 6
Training loss: 3.603853702545166
Validation loss: 3.1998398664186327
Epoch: 5| Step: 7
Training loss: 3.5663797855377197
Validation loss: 3.1832814834100738
Epoch: 5| Step: 8
Training loss: 3.9580228328704834
Validation loss: 3.1647496309211784
Epoch: 5| Step: 9
Training loss: 3.7051944732666016
Validation loss: 3.1319200598078667
Epoch: 21| Step: 0
Training loss: 3.2928309440612793
Validation loss: 3.0971730921765883
Epoch: 5| Step: 1
Training loss: 4.095154762268066
Validation loss: 3.085391370512599
Epoch: 5| Step: 2
Training loss: 3.421757221221924
Validation loss: 3.044600454165781
Epoch: 5| Step: 3
Training loss: 3.4678382873535156
Validation loss: 3.0310569838654224
Epoch: 5| Step: 4
Training loss: 3.2736051082611084
Validation loss: 2.9906254346422156
Epoch: 5| Step: 5
Training loss: 3.884676456451416
Validation loss: 2.985718677369811
Epoch: 5| Step: 6
Training loss: 3.2515156269073486
Validation loss: 2.957992742387511
Epoch: 5| Step: 7
Training loss: 3.787444591522217
Validation loss: 2.927964050992787
Epoch: 5| Step: 8
Training loss: 3.134483814239502
Validation loss: 2.8956879574617895
Epoch: 5| Step: 9
Training loss: 2.7570886611938477
Validation loss: 2.8576733208388734
Epoch: 22| Step: 0
Training loss: 3.4546172618865967
Validation loss: 2.839572059164802
Epoch: 5| Step: 1
Training loss: 2.7075071334838867
Validation loss: 2.824860497344312
Epoch: 5| Step: 2
Training loss: 3.2171173095703125
Validation loss: 2.784063551923354
Epoch: 5| Step: 3
Training loss: 3.4146313667297363
Validation loss: 2.7562716659024464
Epoch: 5| Step: 4
Training loss: 3.100527763366699
Validation loss: 2.7293731360126743
Epoch: 5| Step: 5
Training loss: 2.8615736961364746
Validation loss: 2.7030238642109383
Epoch: 5| Step: 6
Training loss: 2.8897156715393066
Validation loss: 2.7050758240034254
Epoch: 5| Step: 7
Training loss: 3.593505859375
Validation loss: 2.6854113503325756
Epoch: 5| Step: 8
Training loss: 2.8482697010040283
Validation loss: 2.6249199376689445
Epoch: 5| Step: 9
Training loss: 4.163986682891846
Validation loss: 2.6342625429304385
Epoch: 23| Step: 0
Training loss: 3.1053104400634766
Validation loss: 2.5911273887689164
Epoch: 5| Step: 1
Training loss: 2.8160247802734375
Validation loss: 2.580288149470048
Epoch: 5| Step: 2
Training loss: 2.9972949028015137
Validation loss: 2.5493781600924703
Epoch: 5| Step: 3
Training loss: 2.6509110927581787
Validation loss: 2.5212327284778624
Epoch: 5| Step: 4
Training loss: 3.0764026641845703
Validation loss: 2.4646041616261436
Epoch: 5| Step: 5
Training loss: 2.7478156089782715
Validation loss: 2.457155207078234
Epoch: 5| Step: 6
Training loss: 3.219730854034424
Validation loss: 2.4737665395942523
Epoch: 5| Step: 7
Training loss: 3.1679282188415527
Validation loss: 2.430311516892138
Epoch: 5| Step: 8
Training loss: 3.138786554336548
Validation loss: 2.4188049354141565
Epoch: 5| Step: 9
Training loss: 3.0583388805389404
Validation loss: 2.367943583632545
Epoch: 24| Step: 0
Training loss: 3.248134136199951
Validation loss: 2.329515503464843
Epoch: 5| Step: 1
Training loss: 2.2502729892730713
Validation loss: 2.3122928382681427
Epoch: 5| Step: 2
Training loss: 2.7720694541931152
Validation loss: 2.2967144370936663
Epoch: 5| Step: 3
Training loss: 3.360729694366455
Validation loss: 2.2855538275602054
Epoch: 5| Step: 4
Training loss: 2.765721321105957
Validation loss: 2.2486573046059917
Epoch: 5| Step: 5
Training loss: 2.8914918899536133
Validation loss: 2.2393952633837144
Epoch: 5| Step: 6
Training loss: 2.7570552825927734
Validation loss: 2.2299524502788515
Epoch: 5| Step: 7
Training loss: 2.6824631690979004
Validation loss: 2.1801141148848497
Epoch: 5| Step: 8
Training loss: 2.7969236373901367
Validation loss: 2.1611741283814685
Epoch: 5| Step: 9
Training loss: 2.056215286254883
Validation loss: 2.1295540555775596
Epoch: 25| Step: 0
Training loss: 2.5433218479156494
Validation loss: 2.128516891877428
Epoch: 5| Step: 1
Training loss: 3.0045876502990723
Validation loss: 2.1018923169417345
Epoch: 5| Step: 2
Training loss: 2.6818838119506836
Validation loss: 2.068931955227749
Epoch: 5| Step: 3
Training loss: 2.6767940521240234
Validation loss: 2.068561720333511
Epoch: 5| Step: 4
Training loss: 2.339951992034912
Validation loss: 2.0054168658290834
Epoch: 5| Step: 5
Training loss: 2.552389144897461
Validation loss: 2.0248366122623143
Epoch: 5| Step: 6
Training loss: 1.9277100563049316
Validation loss: 1.9880168540872258
Epoch: 5| Step: 7
Training loss: 2.330453634262085
Validation loss: 1.9531102797967925
Epoch: 5| Step: 8
Training loss: 2.760720729827881
Validation loss: 1.9514125920028138
Epoch: 5| Step: 9
Training loss: 2.633603572845459
Validation loss: 1.9699133368704815
Epoch: 26| Step: 0
Training loss: 2.382326126098633
Validation loss: 1.929624731592137
Epoch: 5| Step: 1
Training loss: 2.6164968013763428
Validation loss: 1.9387218540520976
Epoch: 5| Step: 2
Training loss: 2.5372426509857178
Validation loss: 1.9393990777379317
Epoch: 5| Step: 3
Training loss: 2.6227126121520996
Validation loss: 1.9196434226825083
Epoch: 5| Step: 4
Training loss: 2.0623583793640137
Validation loss: 1.917841999650859
Epoch: 5| Step: 5
Training loss: 2.9672188758850098
Validation loss: 1.8942815725751918
Epoch: 5| Step: 6
Training loss: 2.1938934326171875
Validation loss: 1.8791811560555327
Epoch: 5| Step: 7
Training loss: 1.7941703796386719
Validation loss: 1.9284825530841196
Epoch: 5| Step: 8
Training loss: 2.517326593399048
Validation loss: 1.8996986776804752
Epoch: 5| Step: 9
Training loss: 2.070159435272217
Validation loss: 1.8945621260636145
Epoch: 27| Step: 0
Training loss: 2.5654125213623047
Validation loss: 1.8393886063596327
Epoch: 5| Step: 1
Training loss: 2.065882444381714
Validation loss: 1.8936146592064727
Epoch: 5| Step: 2
Training loss: 2.460482597351074
Validation loss: 1.843995460503393
Epoch: 5| Step: 3
Training loss: 2.0127594470977783
Validation loss: 1.862843244195842
Epoch: 5| Step: 4
Training loss: 2.2138781547546387
Validation loss: 1.881439941392528
Epoch: 5| Step: 5
Training loss: 2.198303699493408
Validation loss: 1.842822989113897
Epoch: 5| Step: 6
Training loss: 2.0579614639282227
Validation loss: 1.8903754366387566
Epoch: 5| Step: 7
Training loss: 2.1024937629699707
Validation loss: 1.9092519051737065
Epoch: 5| Step: 8
Training loss: 2.600524663925171
Validation loss: 1.912619174813195
Epoch: 5| Step: 9
Training loss: 2.550370693206787
Validation loss: 1.9259978095404535
Epoch: 28| Step: 0
Training loss: 2.543745994567871
Validation loss: 1.9361588037271293
Epoch: 5| Step: 1
Training loss: 2.266068458557129
Validation loss: 1.9235964781946415
Epoch: 5| Step: 2
Training loss: 1.7082505226135254
Validation loss: 1.8700952564212059
Epoch: 5| Step: 3
Training loss: 1.6337709426879883
Validation loss: 1.906235261786756
Epoch: 5| Step: 4
Training loss: 2.6909098625183105
Validation loss: 1.916402586072469
Epoch: 5| Step: 5
Training loss: 2.8374738693237305
Validation loss: 1.9195069340493183
Epoch: 5| Step: 6
Training loss: 2.5359222888946533
Validation loss: 1.9360871186359323
Epoch: 5| Step: 7
Training loss: 1.715591549873352
Validation loss: 1.92578254500739
Epoch: 5| Step: 8
Training loss: 2.061925172805786
Validation loss: 1.933078918525641
Epoch: 5| Step: 9
Training loss: 2.2511048316955566
Validation loss: 1.9493869002774464
Epoch: 29| Step: 0
Training loss: 2.799623727798462
Validation loss: 1.9372195194093444
Epoch: 5| Step: 1
Training loss: 1.705309510231018
Validation loss: 1.9557223954646707
Epoch: 5| Step: 2
Training loss: 2.2477688789367676
Validation loss: 1.9751250186412455
Epoch: 5| Step: 3
Training loss: 2.176017999649048
Validation loss: 1.9825880930578108
Epoch: 5| Step: 4
Training loss: 2.423680543899536
Validation loss: 1.9844487596758835
Epoch: 5| Step: 5
Training loss: 2.466918468475342
Validation loss: 1.9574729487192717
Epoch: 5| Step: 6
Training loss: 2.1074106693267822
Validation loss: 1.958804956443018
Epoch: 5| Step: 7
Training loss: 1.8841440677642822
Validation loss: 1.9739595360035518
Epoch: 5| Step: 8
Training loss: 1.9047820568084717
Validation loss: 1.972173679646828
Epoch: 5| Step: 9
Training loss: 2.4178590774536133
Validation loss: 1.9504060882458585
Epoch: 30| Step: 0
Training loss: 2.3778257369995117
Validation loss: 1.9345691349866578
Epoch: 5| Step: 1
Training loss: 2.3434271812438965
Validation loss: 1.9736191557465697
Epoch: 5| Step: 2
Training loss: 2.3566665649414062
Validation loss: 2.0290929970981404
Epoch: 5| Step: 3
Training loss: 2.616548538208008
Validation loss: 2.005992994034033
Epoch: 5| Step: 4
Training loss: 2.30694842338562
Validation loss: 1.9960771756206486
Epoch: 5| Step: 5
Training loss: 1.8392332792282104
Validation loss: 1.9906655935932407
Epoch: 5| Step: 6
Training loss: 2.3500542640686035
Validation loss: 1.9693279780929895
Epoch: 5| Step: 7
Training loss: 1.7476338148117065
Validation loss: 1.964669833080374
Epoch: 5| Step: 8
Training loss: 2.2262768745422363
Validation loss: 1.9387424909811226
Epoch: 5| Step: 9
Training loss: 2.088853359222412
Validation loss: 1.9785072306077258
Epoch: 31| Step: 0
Training loss: 2.1723227500915527
Validation loss: 2.013394124216313
Epoch: 5| Step: 1
Training loss: 2.2090015411376953
Validation loss: 1.9646562552280564
Epoch: 5| Step: 2
Training loss: 2.848132610321045
Validation loss: 2.0234457717525016
Epoch: 5| Step: 3
Training loss: 1.952089786529541
Validation loss: 1.963374316263542
Epoch: 5| Step: 4
Training loss: 1.9460129737854004
Validation loss: 1.9742795503396782
Epoch: 5| Step: 5
Training loss: 2.1597788333892822
Validation loss: 1.969200967027129
Epoch: 5| Step: 6
Training loss: 2.02605938911438
Validation loss: 2.018797366739177
Epoch: 5| Step: 7
Training loss: 2.4022045135498047
Validation loss: 1.9690267164930164
Epoch: 5| Step: 8
Training loss: 2.0581631660461426
Validation loss: 2.012087022657875
Epoch: 5| Step: 9
Training loss: 2.2669107913970947
Validation loss: 1.9496232639971396
Epoch: 32| Step: 0
Training loss: 2.9292187690734863
Validation loss: 1.9603983472577102
Epoch: 5| Step: 1
Training loss: 2.18890380859375
Validation loss: 1.9378322328594948
Epoch: 5| Step: 2
Training loss: 1.7240147590637207
Validation loss: 1.954835069265297
Epoch: 5| Step: 3
Training loss: 2.0742626190185547
Validation loss: 1.9693423852646093
Epoch: 5| Step: 4
Training loss: 2.1470253467559814
Validation loss: 1.9645947432346482
Epoch: 5| Step: 5
Training loss: 1.8635776042938232
Validation loss: 1.951405818513829
Epoch: 5| Step: 6
Training loss: 2.432543992996216
Validation loss: 1.9605173078372324
Epoch: 5| Step: 7
Training loss: 2.6696524620056152
Validation loss: 1.976685043719175
Epoch: 5| Step: 8
Training loss: 2.297614574432373
Validation loss: 1.932018178830044
Epoch: 5| Step: 9
Training loss: 1.8970792293548584
Validation loss: 1.9809679967893972
Epoch: 33| Step: 0
Training loss: 1.8914425373077393
Validation loss: 1.963533934929388
Epoch: 5| Step: 1
Training loss: 2.1392126083374023
Validation loss: 1.946089983844071
Epoch: 5| Step: 2
Training loss: 2.589003562927246
Validation loss: 1.934178691973789
Epoch: 5| Step: 3
Training loss: 2.1020994186401367
Validation loss: 1.928977799930161
Epoch: 5| Step: 4
Training loss: 2.4052391052246094
Validation loss: 1.910718802925494
Epoch: 5| Step: 5
Training loss: 2.207859992980957
Validation loss: 1.927936846403767
Epoch: 5| Step: 6
Training loss: 2.0476856231689453
Validation loss: 1.947894689848097
Epoch: 5| Step: 7
Training loss: 2.3706064224243164
Validation loss: 1.9282748236073006
Epoch: 5| Step: 8
Training loss: 1.9522945880889893
Validation loss: 1.945584883792795
Epoch: 5| Step: 9
Training loss: 2.3811182975769043
Validation loss: 1.9642929507674074
Epoch: 34| Step: 0
Training loss: 2.123795509338379
Validation loss: 1.9168302275294022
Epoch: 5| Step: 1
Training loss: 2.1064374446868896
Validation loss: 1.9110413961273303
Epoch: 5| Step: 2
Training loss: 2.0553557872772217
Validation loss: 1.9776108230618263
Epoch: 5| Step: 3
Training loss: 2.946288585662842
Validation loss: 1.9480135389369169
Epoch: 5| Step: 4
Training loss: 1.7493069171905518
Validation loss: 1.9492535436753746
Epoch: 5| Step: 5
Training loss: 2.062722682952881
Validation loss: 1.940396178540566
Epoch: 5| Step: 6
Training loss: 2.2142863273620605
Validation loss: 1.9364451950402568
Epoch: 5| Step: 7
Training loss: 2.2900948524475098
Validation loss: 1.9596741542541722
Epoch: 5| Step: 8
Training loss: 1.6889965534210205
Validation loss: 1.9607231376840055
Epoch: 5| Step: 9
Training loss: 2.8533952236175537
Validation loss: 1.9482299561123195
Epoch: 35| Step: 0
Training loss: 2.0755531787872314
Validation loss: 1.9768213779806234
Epoch: 5| Step: 1
Training loss: 2.238588809967041
Validation loss: 1.9668571880395465
Epoch: 5| Step: 2
Training loss: 2.2999091148376465
Validation loss: 1.983287608880791
Epoch: 5| Step: 3
Training loss: 2.175713539123535
Validation loss: 1.9710692510330419
Epoch: 5| Step: 4
Training loss: 2.0731916427612305
Validation loss: 1.9524202363954173
Epoch: 5| Step: 5
Training loss: 1.9153985977172852
Validation loss: 1.949622773438049
Epoch: 5| Step: 6
Training loss: 2.4310264587402344
Validation loss: 1.9675034121643724
Epoch: 5| Step: 7
Training loss: 2.292088508605957
Validation loss: 1.9323843914827854
Epoch: 5| Step: 8
Training loss: 2.0896637439727783
Validation loss: 1.964049390751681
Epoch: 5| Step: 9
Training loss: 2.37100887298584
Validation loss: 1.9186152682887565
Epoch: 36| Step: 0
Training loss: 2.3096542358398438
Validation loss: 2.0040461305234074
Epoch: 5| Step: 1
Training loss: 2.3653676509857178
Validation loss: 1.9666561137000433
Epoch: 5| Step: 2
Training loss: 2.158400058746338
Validation loss: 1.9186615961061106
Epoch: 5| Step: 3
Training loss: 1.9248533248901367
Validation loss: 1.918196366845275
Epoch: 5| Step: 4
Training loss: 2.307067394256592
Validation loss: 1.979771723850168
Epoch: 5| Step: 5
Training loss: 2.152921438217163
Validation loss: 1.9533950930876698
Epoch: 5| Step: 6
Training loss: 2.587930202484131
Validation loss: 1.9747854231072843
Epoch: 5| Step: 7
Training loss: 2.5770092010498047
Validation loss: 1.9772658665403187
Epoch: 5| Step: 8
Training loss: 1.7704546451568604
Validation loss: 1.945795741870249
Epoch: 5| Step: 9
Training loss: 1.9209418296813965
Validation loss: 1.9397630828747647
Epoch: 37| Step: 0
Training loss: 1.782960295677185
Validation loss: 1.9589364974618815
Epoch: 5| Step: 1
Training loss: 2.158635139465332
Validation loss: 1.9908079886607986
Epoch: 5| Step: 2
Training loss: 2.440384864807129
Validation loss: 1.9612908963676836
Epoch: 5| Step: 3
Training loss: 2.0376219749450684
Validation loss: 1.9912890221575181
Epoch: 5| Step: 4
Training loss: 2.29095458984375
Validation loss: 1.9648813086447956
Epoch: 5| Step: 5
Training loss: 2.5435853004455566
Validation loss: 2.0097199464015825
Epoch: 5| Step: 6
Training loss: 2.0984280109405518
Validation loss: 1.9762768470983711
Epoch: 5| Step: 7
Training loss: 2.6701626777648926
Validation loss: 1.9747987402428826
Epoch: 5| Step: 8
Training loss: 1.927812099456787
Validation loss: 1.9441246832017418
Epoch: 5| Step: 9
Training loss: 2.100398063659668
Validation loss: 1.9816162003030022
Epoch: 38| Step: 0
Training loss: 2.247004985809326
Validation loss: 1.9835928481259792
Epoch: 5| Step: 1
Training loss: 2.304192066192627
Validation loss: 1.9827810457284503
Epoch: 5| Step: 2
Training loss: 2.2619690895080566
Validation loss: 2.0093910848494057
Epoch: 5| Step: 3
Training loss: 1.9922481775283813
Validation loss: 1.9820996445717571
Epoch: 5| Step: 4
Training loss: 2.307485818862915
Validation loss: 1.9653731807530355
Epoch: 5| Step: 5
Training loss: 2.2259912490844727
Validation loss: 1.9845824275943016
Epoch: 5| Step: 6
Training loss: 2.396512985229492
Validation loss: 1.9971652605550752
Epoch: 5| Step: 7
Training loss: 2.277462959289551
Validation loss: 2.0254461439393405
Epoch: 5| Step: 8
Training loss: 2.2319681644439697
Validation loss: 2.002805422535903
Epoch: 5| Step: 9
Training loss: 1.7760636806488037
Validation loss: 1.9906947115342395
Epoch: 39| Step: 0
Training loss: 1.9776438474655151
Validation loss: 1.971752554392643
Epoch: 5| Step: 1
Training loss: 2.209075927734375
Validation loss: 1.9477167935680142
Epoch: 5| Step: 2
Training loss: 2.142691135406494
Validation loss: 1.9559685412070733
Epoch: 5| Step: 3
Training loss: 2.1882996559143066
Validation loss: 1.9888886333369522
Epoch: 5| Step: 4
Training loss: 2.346388578414917
Validation loss: 1.9932510681289564
Epoch: 5| Step: 5
Training loss: 2.1931405067443848
Validation loss: 1.9672742172968474
Epoch: 5| Step: 6
Training loss: 2.648191213607788
Validation loss: 1.9943530671030498
Epoch: 5| Step: 7
Training loss: 2.092564582824707
Validation loss: 1.9658788631288269
Epoch: 5| Step: 8
Training loss: 1.7084968090057373
Validation loss: 1.9894305424724552
Epoch: 5| Step: 9
Training loss: 2.271860122680664
Validation loss: 1.9652898200124287
Epoch: 40| Step: 0
Training loss: 2.6995961666107178
Validation loss: 1.9600284305407847
Epoch: 5| Step: 1
Training loss: 2.004868984222412
Validation loss: 1.9836504931072536
Epoch: 5| Step: 2
Training loss: 1.9783620834350586
Validation loss: 1.9897387936818514
Epoch: 5| Step: 3
Training loss: 2.8480477333068848
Validation loss: 1.9662283195866097
Epoch: 5| Step: 4
Training loss: 2.4151172637939453
Validation loss: 1.9437619027473945
Epoch: 5| Step: 5
Training loss: 1.6868860721588135
Validation loss: 1.9578948912860679
Epoch: 5| Step: 6
Training loss: 2.3768134117126465
Validation loss: 1.9646171374286678
Epoch: 5| Step: 7
Training loss: 1.7559970617294312
Validation loss: 2.0018655704937394
Epoch: 5| Step: 8
Training loss: 1.9615778923034668
Validation loss: 1.9426874771392604
Epoch: 5| Step: 9
Training loss: 2.137543201446533
Validation loss: 1.9374850773982863
Epoch: 41| Step: 0
Training loss: 2.1609630584716797
Validation loss: 1.9981036872314892
Epoch: 5| Step: 1
Training loss: 2.438258647918701
Validation loss: 1.9611203902059322
Epoch: 5| Step: 2
Training loss: 1.9885789155960083
Validation loss: 1.9890168553633656
Epoch: 5| Step: 3
Training loss: 2.696352958679199
Validation loss: 1.9665843685753912
Epoch: 5| Step: 4
Training loss: 1.747166395187378
Validation loss: 1.9498640504672373
Epoch: 5| Step: 5
Training loss: 1.7545915842056274
Validation loss: 1.9522552318710218
Epoch: 5| Step: 6
Training loss: 2.7757019996643066
Validation loss: 1.9974728385321527
Epoch: 5| Step: 7
Training loss: 2.141688585281372
Validation loss: 1.952089417752602
Epoch: 5| Step: 8
Training loss: 1.7607319355010986
Validation loss: 1.941799091778213
Epoch: 5| Step: 9
Training loss: 2.3390142917633057
Validation loss: 1.9680539120873102
Epoch: 42| Step: 0
Training loss: 2.4196276664733887
Validation loss: 1.9806155849703782
Epoch: 5| Step: 1
Training loss: 1.6986802816390991
Validation loss: 1.9325871124542018
Epoch: 5| Step: 2
Training loss: 1.9501692056655884
Validation loss: 1.998001448542094
Epoch: 5| Step: 3
Training loss: 1.8542487621307373
Validation loss: 1.9565452997633022
Epoch: 5| Step: 4
Training loss: 1.8189053535461426
Validation loss: 1.967734564980157
Epoch: 5| Step: 5
Training loss: 2.753237009048462
Validation loss: 1.957145362449207
Epoch: 5| Step: 6
Training loss: 2.012436866760254
Validation loss: 1.9463211049278863
Epoch: 5| Step: 7
Training loss: 2.1480705738067627
Validation loss: 1.9310717788531626
Epoch: 5| Step: 8
Training loss: 2.934340000152588
Validation loss: 1.9308687748668862
Epoch: 5| Step: 9
Training loss: 2.226637363433838
Validation loss: 1.9458709655048179
Epoch: 43| Step: 0
Training loss: 1.8556712865829468
Validation loss: 1.9756737038385954
Epoch: 5| Step: 1
Training loss: 2.533108711242676
Validation loss: 1.9707732423603963
Epoch: 5| Step: 2
Training loss: 1.8041799068450928
Validation loss: 1.95447147321358
Epoch: 5| Step: 3
Training loss: 2.065871477127075
Validation loss: 1.9733695958158095
Epoch: 5| Step: 4
Training loss: 2.1339292526245117
Validation loss: 1.9739119123211868
Epoch: 5| Step: 5
Training loss: 2.4394476413726807
Validation loss: 1.973046595244099
Epoch: 5| Step: 6
Training loss: 2.2436211109161377
Validation loss: 1.948206910126501
Epoch: 5| Step: 7
Training loss: 2.2711198329925537
Validation loss: 2.0456749483835783
Epoch: 5| Step: 8
Training loss: 2.1168410778045654
Validation loss: 1.9915271988875574
Epoch: 5| Step: 9
Training loss: 2.417781114578247
Validation loss: 2.004121949346803
Epoch: 44| Step: 0
Training loss: 1.9271742105484009
Validation loss: 2.00218388159498
Epoch: 5| Step: 1
Training loss: 1.9953728914260864
Validation loss: 1.9703407253292824
Epoch: 5| Step: 2
Training loss: 2.268803119659424
Validation loss: 1.9814178960786448
Epoch: 5| Step: 3
Training loss: 1.5333572626113892
Validation loss: 1.9821141486545262
Epoch: 5| Step: 4
Training loss: 2.7708218097686768
Validation loss: 1.9769231921477284
Epoch: 5| Step: 5
Training loss: 2.402045488357544
Validation loss: 1.9574937974806312
Epoch: 5| Step: 6
Training loss: 2.5513107776641846
Validation loss: 1.9840000764929133
Epoch: 5| Step: 7
Training loss: 1.9707763195037842
Validation loss: 1.944516759982212
Epoch: 5| Step: 8
Training loss: 1.9085283279418945
Validation loss: 1.966564400590581
Epoch: 5| Step: 9
Training loss: 2.483664035797119
Validation loss: 1.9671389790747662
Epoch: 45| Step: 0
Training loss: 2.3812992572784424
Validation loss: 1.970068756624949
Epoch: 5| Step: 1
Training loss: 2.2646937370300293
Validation loss: 2.0008170913449295
Epoch: 5| Step: 2
Training loss: 2.393963575363159
Validation loss: 1.9881499396811286
Epoch: 5| Step: 3
Training loss: 1.9660959243774414
Validation loss: 1.946497933470088
Epoch: 5| Step: 4
Training loss: 1.8098119497299194
Validation loss: 1.9485304870193811
Epoch: 5| Step: 5
Training loss: 2.131472587585449
Validation loss: 1.9303295363625177
Epoch: 5| Step: 6
Training loss: 2.141657590866089
Validation loss: 1.9535639071636062
Epoch: 5| Step: 7
Training loss: 2.132584810256958
Validation loss: 1.952306246585983
Epoch: 5| Step: 8
Training loss: 2.1093766689300537
Validation loss: 1.9631345006201764
Epoch: 5| Step: 9
Training loss: 2.3863003253936768
Validation loss: 1.9624689551566143
Epoch: 46| Step: 0
Training loss: 2.005220890045166
Validation loss: 1.9756849575385773
Epoch: 5| Step: 1
Training loss: 2.124103307723999
Validation loss: 1.995706546220848
Epoch: 5| Step: 2
Training loss: 2.2589914798736572
Validation loss: 1.9593038576112376
Epoch: 5| Step: 3
Training loss: 2.1764466762542725
Validation loss: 1.9687523747519624
Epoch: 5| Step: 4
Training loss: 2.0112688541412354
Validation loss: 1.9759513019657822
Epoch: 5| Step: 5
Training loss: 2.156846523284912
Validation loss: 1.9790371304793324
Epoch: 5| Step: 6
Training loss: 2.816828489303589
Validation loss: 1.9769444757228276
Epoch: 5| Step: 7
Training loss: 1.9251682758331299
Validation loss: 1.9723788851456676
Epoch: 5| Step: 8
Training loss: 2.2439498901367188
Validation loss: 1.9459906010319004
Epoch: 5| Step: 9
Training loss: 2.055431842803955
Validation loss: 1.9260200699456305
Epoch: 47| Step: 0
Training loss: 2.139946460723877
Validation loss: 1.9950442134047583
Epoch: 5| Step: 1
Training loss: 2.3031983375549316
Validation loss: 1.9645746354576494
Epoch: 5| Step: 2
Training loss: 2.1927924156188965
Validation loss: 1.961870389018985
Epoch: 5| Step: 3
Training loss: 1.772755742073059
Validation loss: 1.951339812587491
Epoch: 5| Step: 4
Training loss: 2.77121639251709
Validation loss: 1.9531206021205985
Epoch: 5| Step: 5
Training loss: 1.7198132276535034
Validation loss: 1.9272501039848053
Epoch: 5| Step: 6
Training loss: 2.5853259563446045
Validation loss: 1.9452636121845932
Epoch: 5| Step: 7
Training loss: 1.8549740314483643
Validation loss: 1.9409408157677959
Epoch: 5| Step: 8
Training loss: 1.8765449523925781
Validation loss: 1.9309956684386989
Epoch: 5| Step: 9
Training loss: 2.4931282997131348
Validation loss: 1.947181415214813
Epoch: 48| Step: 0
Training loss: 2.245638370513916
Validation loss: 1.9709682327380282
Epoch: 5| Step: 1
Training loss: 2.1007308959960938
Validation loss: 1.9329195211259582
Epoch: 5| Step: 2
Training loss: 2.4515297412872314
Validation loss: 1.954563070544236
Epoch: 5| Step: 3
Training loss: 2.008115291595459
Validation loss: 1.945375336159905
Epoch: 5| Step: 4
Training loss: 2.033851385116577
Validation loss: 1.9422911860102372
Epoch: 5| Step: 5
Training loss: 1.8935959339141846
Validation loss: 1.959512370953457
Epoch: 5| Step: 6
Training loss: 2.0672497749328613
Validation loss: 1.9464654622318076
Epoch: 5| Step: 7
Training loss: 2.2520036697387695
Validation loss: 1.935944210711143
Epoch: 5| Step: 8
Training loss: 2.079346179962158
Validation loss: 1.9404872227058136
Epoch: 5| Step: 9
Training loss: 2.6655101776123047
Validation loss: 1.9474581325654503
Epoch: 49| Step: 0
Training loss: 1.8728562593460083
Validation loss: 1.9521751403808594
Epoch: 5| Step: 1
Training loss: 1.7693769931793213
Validation loss: 1.938775618299306
Epoch: 5| Step: 2
Training loss: 2.1975159645080566
Validation loss: 1.9781921467335104
Epoch: 5| Step: 3
Training loss: 2.4834115505218506
Validation loss: 1.9125571662573506
Epoch: 5| Step: 4
Training loss: 2.270327091217041
Validation loss: 1.962427935154318
Epoch: 5| Step: 5
Training loss: 2.057657241821289
Validation loss: 1.920346513926554
Epoch: 5| Step: 6
Training loss: 2.05741548538208
Validation loss: 1.967559733836771
Epoch: 5| Step: 7
Training loss: 2.268925666809082
Validation loss: 1.9516192237250238
Epoch: 5| Step: 8
Training loss: 2.1690709590911865
Validation loss: 1.9778997366376918
Epoch: 5| Step: 9
Training loss: 2.597099542617798
Validation loss: 1.9713958150191273
Epoch: 50| Step: 0
Training loss: 1.985575795173645
Validation loss: 1.9763243232699608
Epoch: 5| Step: 1
Training loss: 1.8152575492858887
Validation loss: 1.9465964895358188
Epoch: 5| Step: 2
Training loss: 2.0033812522888184
Validation loss: 1.9778007577649124
Epoch: 5| Step: 3
Training loss: 2.6323962211608887
Validation loss: 1.95785702561303
Epoch: 5| Step: 4
Training loss: 2.1833672523498535
Validation loss: 1.991326308078903
Epoch: 5| Step: 5
Training loss: 2.290024995803833
Validation loss: 1.9686846561569105
Epoch: 5| Step: 6
Training loss: 2.102400302886963
Validation loss: 1.9567698711971584
Epoch: 5| Step: 7
Training loss: 2.356027603149414
Validation loss: 1.9546013290075948
Epoch: 5| Step: 8
Training loss: 2.218825340270996
Validation loss: 1.9533458596510853
Epoch: 5| Step: 9
Training loss: 2.1723084449768066
Validation loss: 1.9178222803760776
Epoch: 51| Step: 0
Training loss: 2.3814010620117188
Validation loss: 1.982208988649382
Epoch: 5| Step: 1
Training loss: 2.0556724071502686
Validation loss: 1.9825002675433812
Epoch: 5| Step: 2
Training loss: 2.0030853748321533
Validation loss: 1.9913241743183823
Epoch: 5| Step: 3
Training loss: 2.2979736328125
Validation loss: 1.9579926883574013
Epoch: 5| Step: 4
Training loss: 1.9296016693115234
Validation loss: 1.9542632197304595
Epoch: 5| Step: 5
Training loss: 2.124276876449585
Validation loss: 1.9807118752019868
Epoch: 5| Step: 6
Training loss: 2.3799853324890137
Validation loss: 1.9689842368201387
Epoch: 5| Step: 7
Training loss: 1.9140307903289795
Validation loss: 1.944516557583706
Epoch: 5| Step: 8
Training loss: 2.444754123687744
Validation loss: 1.9357073375647016
Epoch: 5| Step: 9
Training loss: 1.946268081665039
Validation loss: 1.9692999218865264
Epoch: 52| Step: 0
Training loss: 2.116966724395752
Validation loss: 1.9200947207512615
Epoch: 5| Step: 1
Training loss: 1.726059913635254
Validation loss: 1.9491360384783298
Epoch: 5| Step: 2
Training loss: 1.9200725555419922
Validation loss: 1.972657982393992
Epoch: 5| Step: 3
Training loss: 2.1106061935424805
Validation loss: 1.9741153948598629
Epoch: 5| Step: 4
Training loss: 2.432392120361328
Validation loss: 1.9335150427097896
Epoch: 5| Step: 5
Training loss: 2.1863107681274414
Validation loss: 1.954768917543425
Epoch: 5| Step: 6
Training loss: 2.8374476432800293
Validation loss: 1.9466108984226802
Epoch: 5| Step: 7
Training loss: 2.360990047454834
Validation loss: 1.9799262774076394
Epoch: 5| Step: 8
Training loss: 1.9735589027404785
Validation loss: 1.9051188547834217
Epoch: 5| Step: 9
Training loss: 1.97172212600708
Validation loss: 1.9524948253906032
Epoch: 53| Step: 0
Training loss: 2.1376280784606934
Validation loss: 1.9679608207812411
Epoch: 5| Step: 1
Training loss: 2.122067451477051
Validation loss: 1.930228881698718
Epoch: 5| Step: 2
Training loss: 2.901825428009033
Validation loss: 1.9672380196962425
Epoch: 5| Step: 3
Training loss: 1.9657821655273438
Validation loss: 1.9224106167717803
Epoch: 5| Step: 4
Training loss: 2.069849967956543
Validation loss: 1.9231027596288448
Epoch: 5| Step: 5
Training loss: 2.123706102371216
Validation loss: 1.9360544475720083
Epoch: 5| Step: 6
Training loss: 1.9782822132110596
Validation loss: 1.9367174347527594
Epoch: 5| Step: 7
Training loss: 2.261744976043701
Validation loss: 1.9576397902673954
Epoch: 5| Step: 8
Training loss: 2.356720447540283
Validation loss: 1.9371633255224434
Epoch: 5| Step: 9
Training loss: 1.859922170639038
Validation loss: 1.9689900489162198
Epoch: 54| Step: 0
Training loss: 1.5414258241653442
Validation loss: 1.9619609460556249
Epoch: 5| Step: 1
Training loss: 2.5534067153930664
Validation loss: 1.936996149502212
Epoch: 5| Step: 2
Training loss: 2.5000128746032715
Validation loss: 1.9085508550671364
Epoch: 5| Step: 3
Training loss: 2.2083687782287598
Validation loss: 1.9182005340246846
Epoch: 5| Step: 4
Training loss: 2.371605396270752
Validation loss: 1.9519726089436373
Epoch: 5| Step: 5
Training loss: 1.8422660827636719
Validation loss: 1.98635908339521
Epoch: 5| Step: 6
Training loss: 2.071840286254883
Validation loss: 1.9415048163571804
Epoch: 5| Step: 7
Training loss: 2.2205333709716797
Validation loss: 1.9197486493227294
Epoch: 5| Step: 8
Training loss: 1.9742141962051392
Validation loss: 1.9603514345429784
Epoch: 5| Step: 9
Training loss: 2.296417713165283
Validation loss: 1.9448184761212026
Epoch: 55| Step: 0
Training loss: 2.3087615966796875
Validation loss: 1.933698657605288
Epoch: 5| Step: 1
Training loss: 2.6132798194885254
Validation loss: 1.9201901139115258
Epoch: 5| Step: 2
Training loss: 2.136784791946411
Validation loss: 1.9808304875874692
Epoch: 5| Step: 3
Training loss: 2.017451047897339
Validation loss: 1.9208822181756549
Epoch: 5| Step: 4
Training loss: 2.3731231689453125
Validation loss: 1.9305616985979697
Epoch: 5| Step: 5
Training loss: 2.251858711242676
Validation loss: 1.908547557515206
Epoch: 5| Step: 6
Training loss: 1.5934010744094849
Validation loss: 1.9344735162721263
Epoch: 5| Step: 7
Training loss: 2.0504307746887207
Validation loss: 1.9255368923969407
Epoch: 5| Step: 8
Training loss: 2.0517935752868652
Validation loss: 1.9571962631006035
Epoch: 5| Step: 9
Training loss: 2.3020877838134766
Validation loss: 1.9421982688011883
Epoch: 56| Step: 0
Training loss: 2.0349221229553223
Validation loss: 1.9453572069140648
Epoch: 5| Step: 1
Training loss: 2.363508462905884
Validation loss: 1.9135965048838004
Epoch: 5| Step: 2
Training loss: 1.7814626693725586
Validation loss: 1.9316051640956522
Epoch: 5| Step: 3
Training loss: 2.013145923614502
Validation loss: 1.9158569394255713
Epoch: 5| Step: 4
Training loss: 2.135108470916748
Validation loss: 1.948891189458559
Epoch: 5| Step: 5
Training loss: 2.351372718811035
Validation loss: 1.9424867012517915
Epoch: 5| Step: 6
Training loss: 1.9051519632339478
Validation loss: 1.943998333361509
Epoch: 5| Step: 7
Training loss: 2.609412431716919
Validation loss: 1.927375486428789
Epoch: 5| Step: 8
Training loss: 2.128795862197876
Validation loss: 1.8961725312171223
Epoch: 5| Step: 9
Training loss: 2.2594716548919678
Validation loss: 1.9517990342147058
Epoch: 57| Step: 0
Training loss: 1.8310922384262085
Validation loss: 1.9216859349243933
Epoch: 5| Step: 1
Training loss: 1.9562416076660156
Validation loss: 1.9464789714744624
Epoch: 5| Step: 2
Training loss: 2.076505661010742
Validation loss: 1.8926909930414433
Epoch: 5| Step: 3
Training loss: 1.758758544921875
Validation loss: 1.9624607168513237
Epoch: 5| Step: 4
Training loss: 2.730780601501465
Validation loss: 1.9697640593960988
Epoch: 5| Step: 5
Training loss: 2.1110167503356934
Validation loss: 1.9503177378675063
Epoch: 5| Step: 6
Training loss: 2.4255189895629883
Validation loss: 1.9657003982461614
Epoch: 5| Step: 7
Training loss: 1.735912799835205
Validation loss: 1.962789135013553
Epoch: 5| Step: 8
Training loss: 2.3611221313476562
Validation loss: 1.966015140787303
Epoch: 5| Step: 9
Training loss: 2.640122652053833
Validation loss: 1.930090729281199
Epoch: 58| Step: 0
Training loss: 1.9005510807037354
Validation loss: 1.9244282897427785
Epoch: 5| Step: 1
Training loss: 2.0683038234710693
Validation loss: 1.9700064967862136
Epoch: 5| Step: 2
Training loss: 2.3159055709838867
Validation loss: 1.944838172240223
Epoch: 5| Step: 3
Training loss: 2.2732887268066406
Validation loss: 1.9285110629719795
Epoch: 5| Step: 4
Training loss: 1.9068983793258667
Validation loss: 1.9488703981577922
Epoch: 5| Step: 5
Training loss: 2.3646702766418457
Validation loss: 1.9674378436246365
Epoch: 5| Step: 6
Training loss: 2.019071578979492
Validation loss: 1.9538383861239865
Epoch: 5| Step: 7
Training loss: 2.723489284515381
Validation loss: 1.9905250295460652
Epoch: 5| Step: 8
Training loss: 2.012704849243164
Validation loss: 1.9235548544273102
Epoch: 5| Step: 9
Training loss: 1.89613938331604
Validation loss: 1.9472295963506905
Epoch: 59| Step: 0
Training loss: 1.829864740371704
Validation loss: 1.9596934181323153
Epoch: 5| Step: 1
Training loss: 1.847712755203247
Validation loss: 1.960365599865536
Epoch: 5| Step: 2
Training loss: 1.9312782287597656
Validation loss: 1.9690358432934438
Epoch: 5| Step: 3
Training loss: 2.017188787460327
Validation loss: 1.9687199206660977
Epoch: 5| Step: 4
Training loss: 2.744751453399658
Validation loss: 1.9259543899151919
Epoch: 5| Step: 5
Training loss: 1.7928467988967896
Validation loss: 1.9563577878389427
Epoch: 5| Step: 6
Training loss: 2.517885446548462
Validation loss: 1.959775278036543
Epoch: 5| Step: 7
Training loss: 2.4657833576202393
Validation loss: 1.9204444473595927
Epoch: 5| Step: 8
Training loss: 2.5060343742370605
Validation loss: 1.9661433490917837
Epoch: 5| Step: 9
Training loss: 1.8512141704559326
Validation loss: 1.9351407846958517
Epoch: 60| Step: 0
Training loss: 2.4265518188476562
Validation loss: 1.9505572902212898
Epoch: 5| Step: 1
Training loss: 2.019979953765869
Validation loss: 1.9433164416457251
Epoch: 5| Step: 2
Training loss: 2.1854071617126465
Validation loss: 1.9988963981326535
Epoch: 5| Step: 3
Training loss: 2.380707263946533
Validation loss: 1.9629788836129278
Epoch: 5| Step: 4
Training loss: 2.063308000564575
Validation loss: 1.9288314023463846
Epoch: 5| Step: 5
Training loss: 1.8851678371429443
Validation loss: 1.9339046821319799
Epoch: 5| Step: 6
Training loss: 2.0024001598358154
Validation loss: 1.9759531389895102
Epoch: 5| Step: 7
Training loss: 2.016416072845459
Validation loss: 1.9715215353657016
Epoch: 5| Step: 8
Training loss: 2.8076744079589844
Validation loss: 1.9468647533183476
Epoch: 5| Step: 9
Training loss: 1.8393747806549072
Validation loss: 1.9714067188098277
Epoch: 61| Step: 0
Training loss: 1.8334968090057373
Validation loss: 1.9480935472378629
Epoch: 5| Step: 1
Training loss: 2.19533109664917
Validation loss: 1.931467975643899
Epoch: 5| Step: 2
Training loss: 1.9519973993301392
Validation loss: 1.9647429855607397
Epoch: 5| Step: 3
Training loss: 2.2359113693237305
Validation loss: 1.927036138747236
Epoch: 5| Step: 4
Training loss: 2.4110567569732666
Validation loss: 1.961779241081622
Epoch: 5| Step: 5
Training loss: 2.1844029426574707
Validation loss: 1.9369385894253957
Epoch: 5| Step: 6
Training loss: 2.40283465385437
Validation loss: 1.9245961672968144
Epoch: 5| Step: 7
Training loss: 2.192537784576416
Validation loss: 1.9224048689972582
Epoch: 5| Step: 8
Training loss: 1.9705135822296143
Validation loss: 1.9356557105084975
Epoch: 5| Step: 9
Training loss: 2.104218006134033
Validation loss: 1.9143366058953375
Epoch: 62| Step: 0
Training loss: 2.0975756645202637
Validation loss: 1.992405454031855
Epoch: 5| Step: 1
Training loss: 1.9831708669662476
Validation loss: 1.9443222284317017
Epoch: 5| Step: 2
Training loss: 1.9423811435699463
Validation loss: 1.9522167418500502
Epoch: 5| Step: 3
Training loss: 2.264993190765381
Validation loss: 1.9478831033912494
Epoch: 5| Step: 4
Training loss: 2.14631986618042
Validation loss: 1.9414058108981564
Epoch: 5| Step: 5
Training loss: 1.9962313175201416
Validation loss: 1.9824778004515944
Epoch: 5| Step: 6
Training loss: 2.001798152923584
Validation loss: 1.9678062243427303
Epoch: 5| Step: 7
Training loss: 2.0401523113250732
Validation loss: 1.9668097907690694
Epoch: 5| Step: 8
Training loss: 2.3643264770507812
Validation loss: 1.9198431728555143
Epoch: 5| Step: 9
Training loss: 2.4612836837768555
Validation loss: 1.9949455964479514
Epoch: 63| Step: 0
Training loss: 2.2611300945281982
Validation loss: 1.956213978554705
Epoch: 5| Step: 1
Training loss: 1.8968324661254883
Validation loss: 1.9587391632066355
Epoch: 5| Step: 2
Training loss: 2.180419921875
Validation loss: 2.0110872932475248
Epoch: 5| Step: 3
Training loss: 2.291059970855713
Validation loss: 1.9712589164432004
Epoch: 5| Step: 4
Training loss: 2.5938053131103516
Validation loss: 1.9512975335978775
Epoch: 5| Step: 5
Training loss: 2.079960346221924
Validation loss: 1.949437983602071
Epoch: 5| Step: 6
Training loss: 1.964656114578247
Validation loss: 1.9653404650928306
Epoch: 5| Step: 7
Training loss: 2.080806016921997
Validation loss: 1.9678438327295318
Epoch: 5| Step: 8
Training loss: 1.961991548538208
Validation loss: 1.9381937697636995
Epoch: 5| Step: 9
Training loss: 2.1047909259796143
Validation loss: 1.919910374305231
Epoch: 64| Step: 0
Training loss: 1.9924125671386719
Validation loss: 1.9748317629313297
Epoch: 5| Step: 1
Training loss: 1.7893705368041992
Validation loss: 1.9503415591425175
Epoch: 5| Step: 2
Training loss: 1.876706838607788
Validation loss: 1.9724360155544693
Epoch: 5| Step: 3
Training loss: 2.079124689102173
Validation loss: 1.9494835095439884
Epoch: 5| Step: 4
Training loss: 2.115063190460205
Validation loss: 1.955069631981335
Epoch: 5| Step: 5
Training loss: 1.8997931480407715
Validation loss: 1.9627650118560243
Epoch: 5| Step: 6
Training loss: 2.1189723014831543
Validation loss: 1.967953697382975
Epoch: 5| Step: 7
Training loss: 2.357898235321045
Validation loss: 1.950623599745387
Epoch: 5| Step: 8
Training loss: 2.4624056816101074
Validation loss: 1.9612763528343584
Epoch: 5| Step: 9
Training loss: 2.866910457611084
Validation loss: 1.9707632150581416
Epoch: 65| Step: 0
Training loss: 2.1992578506469727
Validation loss: 1.9108003283576143
Epoch: 5| Step: 1
Training loss: 1.9735877513885498
Validation loss: 1.957829426518447
Epoch: 5| Step: 2
Training loss: 2.120934009552002
Validation loss: 1.9623615724577321
Epoch: 5| Step: 3
Training loss: 1.6215708255767822
Validation loss: 1.952768233182619
Epoch: 5| Step: 4
Training loss: 2.246898889541626
Validation loss: 1.943173314170014
Epoch: 5| Step: 5
Training loss: 1.903688907623291
Validation loss: 1.973608634454741
Epoch: 5| Step: 6
Training loss: 2.4760243892669678
Validation loss: 1.9632054129950434
Epoch: 5| Step: 7
Training loss: 2.426562786102295
Validation loss: 1.9255382191362997
Epoch: 5| Step: 8
Training loss: 2.16353440284729
Validation loss: 1.9640071469245197
Epoch: 5| Step: 9
Training loss: 2.1716134548187256
Validation loss: 1.9560952220889305
Epoch: 66| Step: 0
Training loss: 2.642554998397827
Validation loss: 1.9268693683816374
Epoch: 5| Step: 1
Training loss: 1.6841191053390503
Validation loss: 1.9232369301130445
Epoch: 5| Step: 2
Training loss: 2.0640478134155273
Validation loss: 1.9917258950446148
Epoch: 5| Step: 3
Training loss: 2.1678099632263184
Validation loss: 1.932510466884366
Epoch: 5| Step: 4
Training loss: 2.057420492172241
Validation loss: 1.9529025700452516
Epoch: 5| Step: 5
Training loss: 2.3201122283935547
Validation loss: 1.941890304894756
Epoch: 5| Step: 6
Training loss: 2.3477931022644043
Validation loss: 1.9472638943212495
Epoch: 5| Step: 7
Training loss: 1.7704893350601196
Validation loss: 1.9520692525150107
Epoch: 5| Step: 8
Training loss: 2.3054070472717285
Validation loss: 1.9127265326410747
Epoch: 5| Step: 9
Training loss: 2.0649895668029785
Validation loss: 1.9523919048926812
Epoch: 67| Step: 0
Training loss: 2.257871627807617
Validation loss: 1.9242001523216852
Epoch: 5| Step: 1
Training loss: 2.406992197036743
Validation loss: 1.9176618229571005
Epoch: 5| Step: 2
Training loss: 1.5070240497589111
Validation loss: 1.9456707333489287
Epoch: 5| Step: 3
Training loss: 2.0326905250549316
Validation loss: 1.9128874789039008
Epoch: 5| Step: 4
Training loss: 1.7472000122070312
Validation loss: 1.9474390950991953
Epoch: 5| Step: 5
Training loss: 1.6113145351409912
Validation loss: 1.9130476515927761
Epoch: 5| Step: 6
Training loss: 2.8052666187286377
Validation loss: 1.9156991294819674
Epoch: 5| Step: 7
Training loss: 2.539885997772217
Validation loss: 1.8899013207113142
Epoch: 5| Step: 8
Training loss: 2.282459259033203
Validation loss: 1.926762561146304
Epoch: 5| Step: 9
Training loss: 2.1048147678375244
Validation loss: 1.9055740001390307
Epoch: 68| Step: 0
Training loss: 1.7755622863769531
Validation loss: 1.8830060624390197
Epoch: 5| Step: 1
Training loss: 2.4259090423583984
Validation loss: 1.9085317241202155
Epoch: 5| Step: 2
Training loss: 2.040661573410034
Validation loss: 1.9233597585623212
Epoch: 5| Step: 3
Training loss: 1.787198543548584
Validation loss: 1.8877646888760353
Epoch: 5| Step: 4
Training loss: 1.9293127059936523
Validation loss: 1.902049244736596
Epoch: 5| Step: 5
Training loss: 2.407622814178467
Validation loss: 1.9309325698468325
Epoch: 5| Step: 6
Training loss: 2.507572650909424
Validation loss: 1.9034220649184084
Epoch: 5| Step: 7
Training loss: 1.9509403705596924
Validation loss: 1.9160348254142048
Epoch: 5| Step: 8
Training loss: 2.663224697113037
Validation loss: 1.8771819330805497
Epoch: 5| Step: 9
Training loss: 1.7141602039337158
Validation loss: 1.895504663316466
Epoch: 69| Step: 0
Training loss: 2.1563618183135986
Validation loss: 1.9297845638055595
Epoch: 5| Step: 1
Training loss: 2.564700126647949
Validation loss: 1.9279978421094606
Epoch: 5| Step: 2
Training loss: 2.0926644802093506
Validation loss: 1.9174909908994495
Epoch: 5| Step: 3
Training loss: 2.3832781314849854
Validation loss: 1.9287465527760896
Epoch: 5| Step: 4
Training loss: 2.102818012237549
Validation loss: 1.9362343704100136
Epoch: 5| Step: 5
Training loss: 2.1389846801757812
Validation loss: 1.93564608285753
Epoch: 5| Step: 6
Training loss: 1.9766713380813599
Validation loss: 1.8968307980530554
Epoch: 5| Step: 7
Training loss: 2.3462066650390625
Validation loss: 1.9370208764247756
Epoch: 5| Step: 8
Training loss: 1.7440026998519897
Validation loss: 1.8912379930345276
Epoch: 5| Step: 9
Training loss: 1.995641827583313
Validation loss: 1.927093166241543
Epoch: 70| Step: 0
Training loss: 1.6323167085647583
Validation loss: 1.9274691017411596
Epoch: 5| Step: 1
Training loss: 2.4362680912017822
Validation loss: 1.91024928813358
Epoch: 5| Step: 2
Training loss: 2.088353157043457
Validation loss: 1.959542957141245
Epoch: 5| Step: 3
Training loss: 1.8672914505004883
Validation loss: 1.8958506395490906
Epoch: 5| Step: 4
Training loss: 1.8905596733093262
Validation loss: 1.914292193145203
Epoch: 5| Step: 5
Training loss: 1.9734667539596558
Validation loss: 1.9749462458727172
Epoch: 5| Step: 6
Training loss: 2.8008570671081543
Validation loss: 1.9332254173086703
Epoch: 5| Step: 7
Training loss: 2.2261619567871094
Validation loss: 1.9315075857176198
Epoch: 5| Step: 8
Training loss: 2.1917402744293213
Validation loss: 1.9270247641227227
Epoch: 5| Step: 9
Training loss: 2.2140953540802
Validation loss: 1.9352151584282196
Epoch: 71| Step: 0
Training loss: 2.032701253890991
Validation loss: 1.9477718288092305
Epoch: 5| Step: 1
Training loss: 2.021242618560791
Validation loss: 1.9633035968533523
Epoch: 5| Step: 2
Training loss: 2.3091487884521484
Validation loss: 1.9414456876919424
Epoch: 5| Step: 3
Training loss: 2.244286060333252
Validation loss: 1.9114104397862934
Epoch: 5| Step: 4
Training loss: 2.2466938495635986
Validation loss: 1.9561049620882214
Epoch: 5| Step: 5
Training loss: 2.2842791080474854
Validation loss: 1.933657246527912
Epoch: 5| Step: 6
Training loss: 1.9701354503631592
Validation loss: 1.9310306576516132
Epoch: 5| Step: 7
Training loss: 2.0261478424072266
Validation loss: 1.9505452269272838
Epoch: 5| Step: 8
Training loss: 2.0271687507629395
Validation loss: 1.9539676930406968
Epoch: 5| Step: 9
Training loss: 2.288635492324829
Validation loss: 1.9460699712629799
Epoch: 72| Step: 0
Training loss: 1.779123067855835
Validation loss: 1.9180261025325858
Epoch: 5| Step: 1
Training loss: 2.6719717979431152
Validation loss: 1.9203113634809315
Epoch: 5| Step: 2
Training loss: 2.427332878112793
Validation loss: 1.9371712224946604
Epoch: 5| Step: 3
Training loss: 2.2618489265441895
Validation loss: 1.9382625432323208
Epoch: 5| Step: 4
Training loss: 1.6066232919692993
Validation loss: 1.9270767736777985
Epoch: 5| Step: 5
Training loss: 2.1891932487487793
Validation loss: 1.9317913201215455
Epoch: 5| Step: 6
Training loss: 1.892377257347107
Validation loss: 1.9014691448897767
Epoch: 5| Step: 7
Training loss: 2.2344882488250732
Validation loss: 1.9410035953247289
Epoch: 5| Step: 8
Training loss: 2.102581739425659
Validation loss: 1.9508980212451743
Epoch: 5| Step: 9
Training loss: 2.2034006118774414
Validation loss: 1.960622597083771
Epoch: 73| Step: 0
Training loss: 1.6407724618911743
Validation loss: 1.9234636601784247
Epoch: 5| Step: 1
Training loss: 2.3830652236938477
Validation loss: 1.8852479123383117
Epoch: 5| Step: 2
Training loss: 2.1262412071228027
Validation loss: 1.9376659230362596
Epoch: 5| Step: 3
Training loss: 2.1796231269836426
Validation loss: 1.9347483339927178
Epoch: 5| Step: 4
Training loss: 1.9245939254760742
Validation loss: 1.91860879753991
Epoch: 5| Step: 5
Training loss: 1.8008464574813843
Validation loss: 1.9448371345190694
Epoch: 5| Step: 6
Training loss: 2.5557780265808105
Validation loss: 1.9723138929271011
Epoch: 5| Step: 7
Training loss: 2.3440606594085693
Validation loss: 1.9274498507273283
Epoch: 5| Step: 8
Training loss: 1.9008815288543701
Validation loss: 1.9556360639256538
Epoch: 5| Step: 9
Training loss: 2.2505762577056885
Validation loss: 1.9805891127895108
Epoch: 74| Step: 0
Training loss: 1.6908841133117676
Validation loss: 1.9403365087166107
Epoch: 5| Step: 1
Training loss: 2.0681986808776855
Validation loss: 1.961535055860341
Epoch: 5| Step: 2
Training loss: 2.133793830871582
Validation loss: 1.9216864572154533
Epoch: 5| Step: 3
Training loss: 1.9188181161880493
Validation loss: 1.9500333688241973
Epoch: 5| Step: 4
Training loss: 2.220871925354004
Validation loss: 1.9838649591953634
Epoch: 5| Step: 5
Training loss: 2.299537420272827
Validation loss: 1.984125139044343
Epoch: 5| Step: 6
Training loss: 2.5055742263793945
Validation loss: 1.9583376345874595
Epoch: 5| Step: 7
Training loss: 2.3370413780212402
Validation loss: 1.9423446295072706
Epoch: 5| Step: 8
Training loss: 2.038005828857422
Validation loss: 1.938642225677161
Epoch: 5| Step: 9
Training loss: 2.076231002807617
Validation loss: 1.8985506887916181
Epoch: 75| Step: 0
Training loss: 2.2898755073547363
Validation loss: 1.9287315444122972
Epoch: 5| Step: 1
Training loss: 2.0128636360168457
Validation loss: 1.93930404649364
Epoch: 5| Step: 2
Training loss: 1.8920482397079468
Validation loss: 1.9447026141255879
Epoch: 5| Step: 3
Training loss: 2.471984386444092
Validation loss: 1.9322147060641282
Epoch: 5| Step: 4
Training loss: 2.183469295501709
Validation loss: 1.9405412845474352
Epoch: 5| Step: 5
Training loss: 2.0918445587158203
Validation loss: 1.9412872208108147
Epoch: 5| Step: 6
Training loss: 1.784517526626587
Validation loss: 1.9438282277086656
Epoch: 5| Step: 7
Training loss: 2.5052597522735596
Validation loss: 1.9000651158874842
Epoch: 5| Step: 8
Training loss: 2.484720230102539
Validation loss: 1.9206011972839026
Epoch: 5| Step: 9
Training loss: 1.6355223655700684
Validation loss: 1.909929081690397
Epoch: 76| Step: 0
Training loss: 2.5171546936035156
Validation loss: 1.9127800215920099
Epoch: 5| Step: 1
Training loss: 2.173928737640381
Validation loss: 1.9202862875067073
Epoch: 5| Step: 2
Training loss: 1.9534742832183838
Validation loss: 1.8939848632263623
Epoch: 5| Step: 3
Training loss: 2.477752208709717
Validation loss: 1.9340245406404675
Epoch: 5| Step: 4
Training loss: 1.9397118091583252
Validation loss: 1.9097327963053752
Epoch: 5| Step: 5
Training loss: 1.7771546840667725
Validation loss: 1.912173401537559
Epoch: 5| Step: 6
Training loss: 2.4354217052459717
Validation loss: 1.922739191020993
Epoch: 5| Step: 7
Training loss: 2.2917819023132324
Validation loss: 1.941055214662346
Epoch: 5| Step: 8
Training loss: 1.8094273805618286
Validation loss: 1.8943576744134478
Epoch: 5| Step: 9
Training loss: 1.8270313739776611
Validation loss: 1.9049449635924196
Epoch: 77| Step: 0
Training loss: 2.333531618118286
Validation loss: 1.9157214559239448
Epoch: 5| Step: 1
Training loss: 2.3392045497894287
Validation loss: 1.9136365875065755
Epoch: 5| Step: 2
Training loss: 1.7549641132354736
Validation loss: 1.8923723286004375
Epoch: 5| Step: 3
Training loss: 1.9446172714233398
Validation loss: 1.9156203046977092
Epoch: 5| Step: 4
Training loss: 2.2405266761779785
Validation loss: 1.9447423211104578
Epoch: 5| Step: 5
Training loss: 1.7994968891143799
Validation loss: 1.9521068857728148
Epoch: 5| Step: 6
Training loss: 1.9406135082244873
Validation loss: 1.9134381006089904
Epoch: 5| Step: 7
Training loss: 2.3980774879455566
Validation loss: 1.9343050563935753
Epoch: 5| Step: 8
Training loss: 2.2504630088806152
Validation loss: 1.8977886378336295
Epoch: 5| Step: 9
Training loss: 2.0416266918182373
Validation loss: 1.9136354545895145
Epoch: 78| Step: 0
Training loss: 1.9203596115112305
Validation loss: 1.935869626861682
Epoch: 5| Step: 1
Training loss: 2.087934732437134
Validation loss: 1.9556342843625185
Epoch: 5| Step: 2
Training loss: 2.0441880226135254
Validation loss: 1.953741523859312
Epoch: 5| Step: 3
Training loss: 2.192164897918701
Validation loss: 1.909578909119256
Epoch: 5| Step: 4
Training loss: 1.7319883108139038
Validation loss: 1.9257900320368706
Epoch: 5| Step: 5
Training loss: 1.7588341236114502
Validation loss: 1.9297148615336246
Epoch: 5| Step: 6
Training loss: 2.791855812072754
Validation loss: 1.9378915930823457
Epoch: 5| Step: 7
Training loss: 2.4578073024749756
Validation loss: 1.9721518523401493
Epoch: 5| Step: 8
Training loss: 2.3391566276550293
Validation loss: 1.9254337952291365
Epoch: 5| Step: 9
Training loss: 1.9949617385864258
Validation loss: 1.9105741077189824
Epoch: 79| Step: 0
Training loss: 2.1401586532592773
Validation loss: 1.9556159149828574
Epoch: 5| Step: 1
Training loss: 2.097378969192505
Validation loss: 1.9543226845830464
Epoch: 5| Step: 2
Training loss: 2.3708627223968506
Validation loss: 1.9216174967855
Epoch: 5| Step: 3
Training loss: 2.28757905960083
Validation loss: 1.8812818630136174
Epoch: 5| Step: 4
Training loss: 1.6849026679992676
Validation loss: 1.9495580084889912
Epoch: 5| Step: 5
Training loss: 2.2362308502197266
Validation loss: 1.9564975697359592
Epoch: 5| Step: 6
Training loss: 2.232259750366211
Validation loss: 1.9609480950472167
Epoch: 5| Step: 7
Training loss: 2.1040384769439697
Validation loss: 1.9506963500016028
Epoch: 5| Step: 8
Training loss: 1.857856273651123
Validation loss: 1.9684435077708402
Epoch: 5| Step: 9
Training loss: 2.0164361000061035
Validation loss: 1.9499834407147745
Epoch: 80| Step: 0
Training loss: 1.7585164308547974
Validation loss: 1.9239808981367152
Epoch: 5| Step: 1
Training loss: 1.9812026023864746
Validation loss: 1.9595890971396466
Epoch: 5| Step: 2
Training loss: 1.8181647062301636
Validation loss: 1.9288124180526185
Epoch: 5| Step: 3
Training loss: 1.9553756713867188
Validation loss: 1.9305246974066865
Epoch: 5| Step: 4
Training loss: 2.057218551635742
Validation loss: 1.9548135129667872
Epoch: 5| Step: 5
Training loss: 2.1354691982269287
Validation loss: 1.9056749438210356
Epoch: 5| Step: 6
Training loss: 2.1231279373168945
Validation loss: 1.9155579693883442
Epoch: 5| Step: 7
Training loss: 2.2244014739990234
Validation loss: 1.9375865347951435
Epoch: 5| Step: 8
Training loss: 2.03291916847229
Validation loss: 1.9485196123877875
Epoch: 5| Step: 9
Training loss: 2.9295806884765625
Validation loss: 1.9355102580228298
Epoch: 81| Step: 0
Training loss: 2.4579765796661377
Validation loss: 1.923907056129236
Epoch: 5| Step: 1
Training loss: 1.7722036838531494
Validation loss: 1.9173915780705513
Epoch: 5| Step: 2
Training loss: 2.454777240753174
Validation loss: 1.923755889316257
Epoch: 5| Step: 3
Training loss: 1.599616527557373
Validation loss: 1.901987359678145
Epoch: 5| Step: 4
Training loss: 1.9146389961242676
Validation loss: 1.9420261751833579
Epoch: 5| Step: 5
Training loss: 2.162179470062256
Validation loss: 1.939524668583767
Epoch: 5| Step: 6
Training loss: 2.519005060195923
Validation loss: 1.93513683277926
Epoch: 5| Step: 7
Training loss: 2.2804975509643555
Validation loss: 1.9556000790150045
Epoch: 5| Step: 8
Training loss: 2.070634603500366
Validation loss: 1.9327529780298687
Epoch: 5| Step: 9
Training loss: 1.9509551525115967
Validation loss: 1.9317104799284353
Epoch: 82| Step: 0
Training loss: 1.7183140516281128
Validation loss: 1.9273422682028023
Epoch: 5| Step: 1
Training loss: 2.251011848449707
Validation loss: 1.9653830519683069
Epoch: 5| Step: 2
Training loss: 2.65177321434021
Validation loss: 1.9047182060831742
Epoch: 5| Step: 3
Training loss: 1.7232418060302734
Validation loss: 1.9182612681560378
Epoch: 5| Step: 4
Training loss: 2.111130714416504
Validation loss: 1.917320326935473
Epoch: 5| Step: 5
Training loss: 2.398773670196533
Validation loss: 1.940352914144667
Epoch: 5| Step: 6
Training loss: 2.470428466796875
Validation loss: 1.9404955793627732
Epoch: 5| Step: 7
Training loss: 2.0776121616363525
Validation loss: 1.945013226365014
Epoch: 5| Step: 8
Training loss: 1.7174346446990967
Validation loss: 1.9177400739930517
Epoch: 5| Step: 9
Training loss: 2.142632484436035
Validation loss: 1.9147466481160775
Epoch: 83| Step: 0
Training loss: 2.0224995613098145
Validation loss: 1.9254049002695426
Epoch: 5| Step: 1
Training loss: 2.2179462909698486
Validation loss: 1.9403794274913322
Epoch: 5| Step: 2
Training loss: 2.2143490314483643
Validation loss: 1.9598173066008864
Epoch: 5| Step: 3
Training loss: 1.9563730955123901
Validation loss: 1.9114520995736979
Epoch: 5| Step: 4
Training loss: 2.037135601043701
Validation loss: 1.945820154903604
Epoch: 5| Step: 5
Training loss: 1.9910584688186646
Validation loss: 1.9373844373140403
Epoch: 5| Step: 6
Training loss: 1.7455356121063232
Validation loss: 1.9177515017900535
Epoch: 5| Step: 7
Training loss: 1.8194516897201538
Validation loss: 1.9454477502287721
Epoch: 5| Step: 8
Training loss: 2.3860576152801514
Validation loss: 1.9126070540585964
Epoch: 5| Step: 9
Training loss: 2.547062635421753
Validation loss: 1.937048579291474
Epoch: 84| Step: 0
Training loss: 2.2198333740234375
Validation loss: 1.9364051252817935
Epoch: 5| Step: 1
Training loss: 2.0383498668670654
Validation loss: 1.9429755451010287
Epoch: 5| Step: 2
Training loss: 2.2015552520751953
Validation loss: 1.938731895076285
Epoch: 5| Step: 3
Training loss: 2.001295328140259
Validation loss: 1.9356796329827617
Epoch: 5| Step: 4
Training loss: 2.4769229888916016
Validation loss: 1.9372063660793166
Epoch: 5| Step: 5
Training loss: 1.7994003295898438
Validation loss: 1.9510592290823408
Epoch: 5| Step: 6
Training loss: 2.1822431087493896
Validation loss: 1.964069532833511
Epoch: 5| Step: 7
Training loss: 2.1396923065185547
Validation loss: 1.9432598412465707
Epoch: 5| Step: 8
Training loss: 1.973538875579834
Validation loss: 1.939104769727309
Epoch: 5| Step: 9
Training loss: 1.991834044456482
Validation loss: 1.9237716146510282
Epoch: 85| Step: 0
Training loss: 2.415987491607666
Validation loss: 1.9228930636275587
Epoch: 5| Step: 1
Training loss: 1.9415087699890137
Validation loss: 1.9358827090091844
Epoch: 5| Step: 2
Training loss: 2.125211000442505
Validation loss: 1.9634584068394394
Epoch: 5| Step: 3
Training loss: 2.132441282272339
Validation loss: 1.956591224498886
Epoch: 5| Step: 4
Training loss: 2.092627763748169
Validation loss: 1.948063389002848
Epoch: 5| Step: 5
Training loss: 1.7753647565841675
Validation loss: 1.9417015760064982
Epoch: 5| Step: 6
Training loss: 2.119054079055786
Validation loss: 1.9081605595650433
Epoch: 5| Step: 7
Training loss: 1.9653379917144775
Validation loss: 1.9590052554933288
Epoch: 5| Step: 8
Training loss: 2.22946834564209
Validation loss: 1.948551621368463
Epoch: 5| Step: 9
Training loss: 2.3433926105499268
Validation loss: 1.9436315495333225
Epoch: 86| Step: 0
Training loss: 2.304103374481201
Validation loss: 1.9169175136003562
Epoch: 5| Step: 1
Training loss: 1.8420698642730713
Validation loss: 1.9419010088598128
Epoch: 5| Step: 2
Training loss: 2.7895946502685547
Validation loss: 1.9456058217467165
Epoch: 5| Step: 3
Training loss: 2.1775565147399902
Validation loss: 1.9202826065982845
Epoch: 5| Step: 4
Training loss: 2.0722625255584717
Validation loss: 1.9412349917048173
Epoch: 5| Step: 5
Training loss: 1.9896382093429565
Validation loss: 1.9401822424621034
Epoch: 5| Step: 6
Training loss: 2.1033174991607666
Validation loss: 1.9272125350485603
Epoch: 5| Step: 7
Training loss: 1.7283813953399658
Validation loss: 1.9000280272188803
Epoch: 5| Step: 8
Training loss: 1.9103972911834717
Validation loss: 1.9361322526451494
Epoch: 5| Step: 9
Training loss: 1.9358644485473633
Validation loss: 1.9468632121737912
Epoch: 87| Step: 0
Training loss: 2.085530996322632
Validation loss: 1.9027434630359676
Epoch: 5| Step: 1
Training loss: 2.209426164627075
Validation loss: 1.8962557984770632
Epoch: 5| Step: 2
Training loss: 2.4287467002868652
Validation loss: 1.9471306586437087
Epoch: 5| Step: 3
Training loss: 2.0951085090637207
Validation loss: 1.9008625437029831
Epoch: 5| Step: 4
Training loss: 1.9774158000946045
Validation loss: 1.9604055684247463
Epoch: 5| Step: 5
Training loss: 2.4389448165893555
Validation loss: 1.9256086298030057
Epoch: 5| Step: 6
Training loss: 1.5654466152191162
Validation loss: 1.93459396911182
Epoch: 5| Step: 7
Training loss: 2.1528282165527344
Validation loss: 1.9086874852077567
Epoch: 5| Step: 8
Training loss: 2.016033172607422
Validation loss: 1.9290223113066858
Epoch: 5| Step: 9
Training loss: 1.9980021715164185
Validation loss: 1.8959208984169171
Epoch: 88| Step: 0
Training loss: 1.718321442604065
Validation loss: 1.9293279544912654
Epoch: 5| Step: 1
Training loss: 2.0660793781280518
Validation loss: 1.8931205993076023
Epoch: 5| Step: 2
Training loss: 2.2574877738952637
Validation loss: 1.937305119397829
Epoch: 5| Step: 3
Training loss: 1.9339423179626465
Validation loss: 1.919231633488223
Epoch: 5| Step: 4
Training loss: 1.9731619358062744
Validation loss: 1.9244286893940659
Epoch: 5| Step: 5
Training loss: 2.1072137355804443
Validation loss: 1.979675888157577
Epoch: 5| Step: 6
Training loss: 2.338876724243164
Validation loss: 1.9272353769206314
Epoch: 5| Step: 7
Training loss: 2.4336910247802734
Validation loss: 1.9648885280965902
Epoch: 5| Step: 8
Training loss: 2.193209171295166
Validation loss: 1.9400863664613353
Epoch: 5| Step: 9
Training loss: 2.2458157539367676
Validation loss: 1.9198200068027853
Epoch: 89| Step: 0
Training loss: 1.9592483043670654
Validation loss: 1.9752528744635822
Epoch: 5| Step: 1
Training loss: 2.1713521480560303
Validation loss: 1.9762013919061894
Epoch: 5| Step: 2
Training loss: 2.4576244354248047
Validation loss: 2.001037074507569
Epoch: 5| Step: 3
Training loss: 2.036550998687744
Validation loss: 1.982980939124128
Epoch: 5| Step: 4
Training loss: 1.8647291660308838
Validation loss: 1.9718209479352553
Epoch: 5| Step: 5
Training loss: 1.9767520427703857
Validation loss: 1.9924561805862318
Epoch: 5| Step: 6
Training loss: 2.0329675674438477
Validation loss: 1.9891067391676869
Epoch: 5| Step: 7
Training loss: 2.1535122394561768
Validation loss: 1.9505258575617839
Epoch: 5| Step: 8
Training loss: 2.1297407150268555
Validation loss: 1.9758890301203555
Epoch: 5| Step: 9
Training loss: 2.2107737064361572
Validation loss: 1.9692168158592938
Epoch: 90| Step: 0
Training loss: 2.3981125354766846
Validation loss: 1.9407037539447811
Epoch: 5| Step: 1
Training loss: 1.8314611911773682
Validation loss: 1.976026630230087
Epoch: 5| Step: 2
Training loss: 2.183044910430908
Validation loss: 1.9500882977204357
Epoch: 5| Step: 3
Training loss: 2.019044876098633
Validation loss: 1.9451679823209913
Epoch: 5| Step: 4
Training loss: 1.9249157905578613
Validation loss: 1.9439354457443567
Epoch: 5| Step: 5
Training loss: 1.6000690460205078
Validation loss: 1.964338705694075
Epoch: 5| Step: 6
Training loss: 2.278400421142578
Validation loss: 1.946881125299193
Epoch: 5| Step: 7
Training loss: 2.446563243865967
Validation loss: 1.9693291547487108
Epoch: 5| Step: 8
Training loss: 2.503690242767334
Validation loss: 1.909771843779859
Epoch: 5| Step: 9
Training loss: 1.6552696228027344
Validation loss: 1.9420455231083382
Epoch: 91| Step: 0
Training loss: 2.1581690311431885
Validation loss: 1.9448603717543238
Epoch: 5| Step: 1
Training loss: 1.901108741760254
Validation loss: 1.9551665071103213
Epoch: 5| Step: 2
Training loss: 2.2444252967834473
Validation loss: 1.9480020596826677
Epoch: 5| Step: 3
Training loss: 2.2339766025543213
Validation loss: 1.9172104228314737
Epoch: 5| Step: 4
Training loss: 1.9533491134643555
Validation loss: 1.9556002479662997
Epoch: 5| Step: 5
Training loss: 2.101365089416504
Validation loss: 1.9776312310061008
Epoch: 5| Step: 6
Training loss: 1.808204174041748
Validation loss: 1.9558298905118763
Epoch: 5| Step: 7
Training loss: 2.2536606788635254
Validation loss: 1.9611055945320952
Epoch: 5| Step: 8
Training loss: 2.0159993171691895
Validation loss: 1.937110477214237
Epoch: 5| Step: 9
Training loss: 2.4274206161499023
Validation loss: 1.9708759167211518
Epoch: 92| Step: 0
Training loss: 2.244982957839966
Validation loss: 1.937753831739906
Epoch: 5| Step: 1
Training loss: 1.9683189392089844
Validation loss: 1.946176108696478
Epoch: 5| Step: 2
Training loss: 2.257629156112671
Validation loss: 1.9410667144994942
Epoch: 5| Step: 3
Training loss: 1.8468438386917114
Validation loss: 1.927524981738852
Epoch: 5| Step: 4
Training loss: 2.3772053718566895
Validation loss: 1.957131728851538
Epoch: 5| Step: 5
Training loss: 1.7245397567749023
Validation loss: 1.9403615495283826
Epoch: 5| Step: 6
Training loss: 2.4518327713012695
Validation loss: 1.9439097857303758
Epoch: 5| Step: 7
Training loss: 2.158329963684082
Validation loss: 1.9579260752355452
Epoch: 5| Step: 8
Training loss: 2.1380178928375244
Validation loss: 1.9478632717681446
Epoch: 5| Step: 9
Training loss: 1.7495710849761963
Validation loss: 1.9130183947172097
Epoch: 93| Step: 0
Training loss: 2.190397262573242
Validation loss: 1.9190411464773494
Epoch: 5| Step: 1
Training loss: 2.051652669906616
Validation loss: 1.9154671722178838
Epoch: 5| Step: 2
Training loss: 2.062770366668701
Validation loss: 1.9624349281942244
Epoch: 5| Step: 3
Training loss: 1.8076727390289307
Validation loss: 1.9789995864140901
Epoch: 5| Step: 4
Training loss: 1.9540759325027466
Validation loss: 1.92040735954861
Epoch: 5| Step: 5
Training loss: 2.034214973449707
Validation loss: 1.9105400301569657
Epoch: 5| Step: 6
Training loss: 2.3011651039123535
Validation loss: 1.9266518843259743
Epoch: 5| Step: 7
Training loss: 2.3163747787475586
Validation loss: 1.9303536012018327
Epoch: 5| Step: 8
Training loss: 2.1032283306121826
Validation loss: 1.9353953608506018
Epoch: 5| Step: 9
Training loss: 1.9703657627105713
Validation loss: 1.9442759555020779
Epoch: 94| Step: 0
Training loss: 1.8669852018356323
Validation loss: 1.9087431679526679
Epoch: 5| Step: 1
Training loss: 2.095884084701538
Validation loss: 1.9328102087803025
Epoch: 5| Step: 2
Training loss: 2.2889773845672607
Validation loss: 1.900375805312781
Epoch: 5| Step: 3
Training loss: 2.1859824657440186
Validation loss: 1.9277696540887408
Epoch: 5| Step: 4
Training loss: 2.2883095741271973
Validation loss: 1.9181212830028946
Epoch: 5| Step: 5
Training loss: 1.986948013305664
Validation loss: 1.923280253684778
Epoch: 5| Step: 6
Training loss: 1.9889788627624512
Validation loss: 1.8925480671066175
Epoch: 5| Step: 7
Training loss: 1.644153118133545
Validation loss: 1.895313274946144
Epoch: 5| Step: 8
Training loss: 2.2150778770446777
Validation loss: 1.8754110979519303
Epoch: 5| Step: 9
Training loss: 2.2286133766174316
Validation loss: 1.908759156577021
Epoch: 95| Step: 0
Training loss: 2.1129376888275146
Validation loss: 1.8981415753741917
Epoch: 5| Step: 1
Training loss: 1.8721011877059937
Validation loss: 1.8906997708107929
Epoch: 5| Step: 2
Training loss: 2.347116470336914
Validation loss: 1.9526317068141141
Epoch: 5| Step: 3
Training loss: 2.0416417121887207
Validation loss: 1.954153570339834
Epoch: 5| Step: 4
Training loss: 2.174805164337158
Validation loss: 1.8769466456749457
Epoch: 5| Step: 5
Training loss: 1.791483759880066
Validation loss: 1.8907010418048007
Epoch: 5| Step: 6
Training loss: 2.0750865936279297
Validation loss: 1.9362766348200737
Epoch: 5| Step: 7
Training loss: 2.2282707691192627
Validation loss: 1.9473674803329029
Epoch: 5| Step: 8
Training loss: 1.963366985321045
Validation loss: 1.8976562023162842
Epoch: 5| Step: 9
Training loss: 1.9741215705871582
Validation loss: 1.8910665872285692
Epoch: 96| Step: 0
Training loss: 2.4161314964294434
Validation loss: 1.9129198480853074
Epoch: 5| Step: 1
Training loss: 2.028921604156494
Validation loss: 1.9352652186112438
Epoch: 5| Step: 2
Training loss: 2.271256923675537
Validation loss: 1.920896547303783
Epoch: 5| Step: 3
Training loss: 1.676909327507019
Validation loss: 1.9168738564141363
Epoch: 5| Step: 4
Training loss: 2.0831613540649414
Validation loss: 1.9345687481996825
Epoch: 5| Step: 5
Training loss: 2.16701602935791
Validation loss: 1.8951982679984551
Epoch: 5| Step: 6
Training loss: 2.3665342330932617
Validation loss: 1.9215630370078327
Epoch: 5| Step: 7
Training loss: 2.0413060188293457
Validation loss: 1.953895965926081
Epoch: 5| Step: 8
Training loss: 2.072357654571533
Validation loss: 1.9272097289133414
Epoch: 5| Step: 9
Training loss: 1.7834115028381348
Validation loss: 1.9208556833884698
Epoch: 97| Step: 0
Training loss: 1.8616397380828857
Validation loss: 1.9533363151893341
Epoch: 5| Step: 1
Training loss: 1.9108213186264038
Validation loss: 1.927815528224698
Epoch: 5| Step: 2
Training loss: 2.1799399852752686
Validation loss: 1.9307576923919239
Epoch: 5| Step: 3
Training loss: 1.9800523519515991
Validation loss: 1.9656071860155613
Epoch: 5| Step: 4
Training loss: 2.4324989318847656
Validation loss: 1.9212139407507807
Epoch: 5| Step: 5
Training loss: 2.1309008598327637
Validation loss: 1.946113340288615
Epoch: 5| Step: 6
Training loss: 2.464564561843872
Validation loss: 1.956978096378793
Epoch: 5| Step: 7
Training loss: 1.8247629404067993
Validation loss: 1.9684568677874779
Epoch: 5| Step: 8
Training loss: 2.236804962158203
Validation loss: 1.967633090430884
Epoch: 5| Step: 9
Training loss: 1.6995368003845215
Validation loss: 1.9066102178834325
Epoch: 98| Step: 0
Training loss: 2.1885852813720703
Validation loss: 1.921280310308333
Epoch: 5| Step: 1
Training loss: 1.854682207107544
Validation loss: 1.9660736511079528
Epoch: 5| Step: 2
Training loss: 2.1764636039733887
Validation loss: 1.9121392716606744
Epoch: 5| Step: 3
Training loss: 2.543917179107666
Validation loss: 1.889469501783522
Epoch: 5| Step: 4
Training loss: 2.2484099864959717
Validation loss: 1.937105405244896
Epoch: 5| Step: 5
Training loss: 1.4950308799743652
Validation loss: 1.9099900019254616
Epoch: 5| Step: 6
Training loss: 2.5679280757904053
Validation loss: 1.9330871508275862
Epoch: 5| Step: 7
Training loss: 1.7995645999908447
Validation loss: 1.9124714993744445
Epoch: 5| Step: 8
Training loss: 2.1493308544158936
Validation loss: 1.9024475058205694
Epoch: 5| Step: 9
Training loss: 1.7380495071411133
Validation loss: 1.88193857326782
Epoch: 99| Step: 0
Training loss: 1.8332998752593994
Validation loss: 1.9436150823565697
Epoch: 5| Step: 1
Training loss: 1.7733526229858398
Validation loss: 1.9000773841528584
Epoch: 5| Step: 2
Training loss: 2.0039517879486084
Validation loss: 1.9314036497966849
Epoch: 5| Step: 3
Training loss: 2.2398433685302734
Validation loss: 1.9391845456130212
Epoch: 5| Step: 4
Training loss: 2.0957679748535156
Validation loss: 1.912770200976365
Epoch: 5| Step: 5
Training loss: 2.216554641723633
Validation loss: 1.8843341182461746
Epoch: 5| Step: 6
Training loss: 1.9824148416519165
Validation loss: 1.95961835058473
Epoch: 5| Step: 7
Training loss: 2.070812463760376
Validation loss: 1.8730769260324163
Epoch: 5| Step: 8
Training loss: 2.1715035438537598
Validation loss: 1.8893563112766623
Epoch: 5| Step: 9
Training loss: 2.286997079849243
Validation loss: 1.9375113000115045
Epoch: 100| Step: 0
Training loss: 1.7828871011734009
Validation loss: 1.9368459097773052
Epoch: 5| Step: 1
Training loss: 2.137648820877075
Validation loss: 1.9246312457022907
Epoch: 5| Step: 2
Training loss: 2.043488025665283
Validation loss: 1.9066720823589847
Epoch: 5| Step: 3
Training loss: 1.9011284112930298
Validation loss: 1.913866453033557
Epoch: 5| Step: 4
Training loss: 2.398632049560547
Validation loss: 1.868989959895182
Epoch: 5| Step: 5
Training loss: 1.9173139333724976
Validation loss: 1.9199204127565563
Epoch: 5| Step: 6
Training loss: 2.197500467300415
Validation loss: 1.9346130383100442
Epoch: 5| Step: 7
Training loss: 2.137439250946045
Validation loss: 1.9423437547340667
Epoch: 5| Step: 8
Training loss: 2.3334884643554688
Validation loss: 1.9150399321274791
Epoch: 5| Step: 9
Training loss: 1.8164952993392944
Validation loss: 1.940000158419712
