Epoch: 1| Step: 0
Training loss: 4.605617046356201
Validation loss: 4.360508918762207

Epoch: 6| Step: 1
Training loss: 5.455787181854248
Validation loss: 4.340475598971049

Epoch: 6| Step: 2
Training loss: 4.716340065002441
Validation loss: 4.321786483128865

Epoch: 6| Step: 3
Training loss: 4.411679744720459
Validation loss: 4.2998586893081665

Epoch: 6| Step: 4
Training loss: 3.935410499572754
Validation loss: 4.279903014500936

Epoch: 6| Step: 5
Training loss: 4.6085052490234375
Validation loss: 4.261971791585286

Epoch: 6| Step: 6
Training loss: 4.440276145935059
Validation loss: 4.244584600130717

Epoch: 6| Step: 7
Training loss: 4.053091049194336
Validation loss: 4.2266636689503985

Epoch: 6| Step: 8
Training loss: 5.162538528442383
Validation loss: 4.209618171056111

Epoch: 6| Step: 9
Training loss: 4.995927333831787
Validation loss: 4.190169294675191

Epoch: 6| Step: 10
Training loss: 4.49629020690918
Validation loss: 4.167923291524251

Epoch: 6| Step: 11
Training loss: 3.027769088745117
Validation loss: 4.146756529808044

Epoch: 6| Step: 12
Training loss: 3.811177968978882
Validation loss: 4.123214999834697

Epoch: 6| Step: 13
Training loss: 3.3136606216430664
Validation loss: 4.095680197079976

Epoch: 2| Step: 0
Training loss: 3.370152473449707
Validation loss: 4.071332534154256

Epoch: 6| Step: 1
Training loss: 3.7090094089508057
Validation loss: 4.046280185381572

Epoch: 6| Step: 2
Training loss: 3.8653807640075684
Validation loss: 4.015286366144816

Epoch: 6| Step: 3
Training loss: 5.080048084259033
Validation loss: 3.989950974782308

Epoch: 6| Step: 4
Training loss: 5.01220178604126
Validation loss: 3.9604122241338096

Epoch: 6| Step: 5
Training loss: 4.429970741271973
Validation loss: 3.925814390182495

Epoch: 6| Step: 6
Training loss: 4.132767677307129
Validation loss: 3.8944433530171714

Epoch: 6| Step: 7
Training loss: 3.9962854385375977
Validation loss: 3.864558974901835

Epoch: 6| Step: 8
Training loss: 3.6510939598083496
Validation loss: 3.8256211280822754

Epoch: 6| Step: 9
Training loss: 4.047205448150635
Validation loss: 3.7891443570454917

Epoch: 6| Step: 10
Training loss: 3.1573452949523926
Validation loss: 3.7504663864771524

Epoch: 6| Step: 11
Training loss: 3.559514045715332
Validation loss: 3.7106366952260337

Epoch: 6| Step: 12
Training loss: 4.940003871917725
Validation loss: 3.6751332680384317

Epoch: 6| Step: 13
Training loss: 3.014716148376465
Validation loss: 3.6273062229156494

Epoch: 3| Step: 0
Training loss: 3.6191678047180176
Validation loss: 3.585340976715088

Epoch: 6| Step: 1
Training loss: 3.626370668411255
Validation loss: 3.5447086493174234

Epoch: 6| Step: 2
Training loss: 3.0360827445983887
Validation loss: 3.4932740132013955

Epoch: 6| Step: 3
Training loss: 3.710561513900757
Validation loss: 3.454684774080912

Epoch: 6| Step: 4
Training loss: 4.009185791015625
Validation loss: 3.4082797368367515

Epoch: 6| Step: 5
Training loss: 3.7752997875213623
Validation loss: 3.361729900042216

Epoch: 6| Step: 6
Training loss: 3.401461362838745
Validation loss: 3.3074924548467

Epoch: 6| Step: 7
Training loss: 3.2757105827331543
Validation loss: 3.2538471619288125

Epoch: 6| Step: 8
Training loss: 3.325843572616577
Validation loss: 3.195761283238729

Epoch: 6| Step: 9
Training loss: 3.7779693603515625
Validation loss: 3.1426956256230674

Epoch: 6| Step: 10
Training loss: 2.2025036811828613
Validation loss: 3.085220774014791

Epoch: 6| Step: 11
Training loss: 2.8738574981689453
Validation loss: 3.0239337682724

Epoch: 6| Step: 12
Training loss: 3.9216325283050537
Validation loss: 2.954062819480896

Epoch: 6| Step: 13
Training loss: 2.437769889831543
Validation loss: 2.897393743197123

Epoch: 4| Step: 0
Training loss: 2.883056163787842
Validation loss: 2.8331768910090127

Epoch: 6| Step: 1
Training loss: 2.360520362854004
Validation loss: 2.7751750548680625

Epoch: 6| Step: 2
Training loss: 2.2364258766174316
Validation loss: 2.70591402053833

Epoch: 6| Step: 3
Training loss: 2.330002546310425
Validation loss: 2.6586548884709678

Epoch: 6| Step: 4
Training loss: 2.9679465293884277
Validation loss: 2.599942445755005

Epoch: 6| Step: 5
Training loss: 2.747620105743408
Validation loss: 2.5515172481536865

Epoch: 6| Step: 6
Training loss: 2.9031410217285156
Validation loss: 2.4946178992589316

Epoch: 6| Step: 7
Training loss: 2.435943365097046
Validation loss: 2.4265064001083374

Epoch: 6| Step: 8
Training loss: 1.7861863374710083
Validation loss: 2.374168356259664

Epoch: 6| Step: 9
Training loss: 2.7771990299224854
Validation loss: 2.308293600877126

Epoch: 6| Step: 10
Training loss: 1.946831226348877
Validation loss: 2.2875001231829324

Epoch: 6| Step: 11
Training loss: 2.5260510444641113
Validation loss: 2.232422888278961

Epoch: 6| Step: 12
Training loss: 1.653136968612671
Validation loss: 2.19795686006546

Epoch: 6| Step: 13
Training loss: 1.9269659519195557
Validation loss: 2.146055022875468

Epoch: 5| Step: 0
Training loss: 1.7775956392288208
Validation loss: 2.149147013823191

Epoch: 6| Step: 1
Training loss: 2.2052390575408936
Validation loss: 2.1761651039123535

Epoch: 6| Step: 2
Training loss: 2.1424505710601807
Validation loss: 2.1677430868148804

Epoch: 6| Step: 3
Training loss: 1.8789011240005493
Validation loss: 2.2042158047358194

Epoch: 6| Step: 4
Training loss: 2.1831650733947754
Validation loss: 2.1757205526034036

Epoch: 6| Step: 5
Training loss: 2.025022506713867
Validation loss: 2.208225647608439

Epoch: 6| Step: 6
Training loss: 1.5740699768066406
Validation loss: 2.2165677150090537

Epoch: 6| Step: 7
Training loss: 2.6566920280456543
Validation loss: 2.254774808883667

Epoch: 6| Step: 8
Training loss: 1.870156168937683
Validation loss: 2.2379996180534363

Epoch: 6| Step: 9
Training loss: 2.7834548950195312
Validation loss: 2.272675116856893

Epoch: 6| Step: 10
Training loss: 2.0220375061035156
Validation loss: 2.239707072575887

Epoch: 6| Step: 11
Training loss: 2.4850878715515137
Validation loss: 2.2398263216018677

Epoch: 6| Step: 12
Training loss: 2.150332450866699
Validation loss: 2.2305867870648703

Epoch: 6| Step: 13
Training loss: 2.60097599029541
Validation loss: 2.164494514465332

Epoch: 6| Step: 0
Training loss: 2.153371810913086
Validation loss: 2.184794068336487

Epoch: 6| Step: 1
Training loss: 1.7763715982437134
Validation loss: 2.1913362542788186

Epoch: 6| Step: 2
Training loss: 2.368712902069092
Validation loss: 2.1435392101605735

Epoch: 6| Step: 3
Training loss: 3.2146358489990234
Validation loss: 2.1441860795021057

Epoch: 6| Step: 4
Training loss: 2.3365519046783447
Validation loss: 2.1434470216433206

Epoch: 6| Step: 5
Training loss: 1.5766562223434448
Validation loss: 2.1596572001775107

Epoch: 6| Step: 6
Training loss: 1.6372334957122803
Validation loss: 2.1769869327545166

Epoch: 6| Step: 7
Training loss: 2.1698036193847656
Validation loss: 2.198334832986196

Epoch: 6| Step: 8
Training loss: 1.9015536308288574
Validation loss: 2.188858687877655

Epoch: 6| Step: 9
Training loss: 2.1609714031219482
Validation loss: 2.200654168923696

Epoch: 6| Step: 10
Training loss: 2.5029873847961426
Validation loss: 2.190940578778585

Epoch: 6| Step: 11
Training loss: 2.462775707244873
Validation loss: 2.19148180882136

Epoch: 6| Step: 12
Training loss: 2.0731616020202637
Validation loss: 2.177468419075012

Epoch: 6| Step: 13
Training loss: 2.4186978340148926
Validation loss: 2.164031704266866

Epoch: 7| Step: 0
Training loss: 2.45084810256958
Validation loss: 2.166358689467112

Epoch: 6| Step: 1
Training loss: 1.9634222984313965
Validation loss: 2.143211563428243

Epoch: 6| Step: 2
Training loss: 1.7787184715270996
Validation loss: 2.150032023588816

Epoch: 6| Step: 3
Training loss: 1.7936251163482666
Validation loss: 2.146174132823944

Epoch: 6| Step: 4
Training loss: 2.399071216583252
Validation loss: 2.1321078141530356

Epoch: 6| Step: 5
Training loss: 1.8266152143478394
Validation loss: 2.1395649115244546

Epoch: 6| Step: 6
Training loss: 2.47782301902771
Validation loss: 2.1405633886655173

Epoch: 6| Step: 7
Training loss: 2.4909682273864746
Validation loss: 2.1424052715301514

Epoch: 6| Step: 8
Training loss: 1.4633941650390625
Validation loss: 2.139936645825704

Epoch: 6| Step: 9
Training loss: 2.1059703826904297
Validation loss: 2.1467925707499185

Epoch: 6| Step: 10
Training loss: 3.0268783569335938
Validation loss: 2.157688001791636

Epoch: 6| Step: 11
Training loss: 1.0745465755462646
Validation loss: 2.14499968290329

Epoch: 6| Step: 12
Training loss: 2.6082794666290283
Validation loss: 2.1552880803743997

Epoch: 6| Step: 13
Training loss: 2.4840664863586426
Validation loss: 2.1757393876711526

Epoch: 8| Step: 0
Training loss: 2.3768534660339355
Validation loss: 2.1641109784444175

Epoch: 6| Step: 1
Training loss: 1.8561939001083374
Validation loss: 2.1485302448272705

Epoch: 6| Step: 2
Training loss: 2.6331753730773926
Validation loss: 2.1490517059961953

Epoch: 6| Step: 3
Training loss: 2.103717088699341
Validation loss: 2.1483974059422812

Epoch: 6| Step: 4
Training loss: 2.132669448852539
Validation loss: 2.1565027634302774

Epoch: 6| Step: 5
Training loss: 2.24713134765625
Validation loss: 2.1549317042032876

Epoch: 6| Step: 6
Training loss: 2.289134979248047
Validation loss: 2.1251336534818015

Epoch: 6| Step: 7
Training loss: 2.129051446914673
Validation loss: 2.144255598386129

Epoch: 6| Step: 8
Training loss: 1.932603120803833
Validation loss: 2.1461195945739746

Epoch: 6| Step: 9
Training loss: 2.009120464324951
Validation loss: 2.1227400302886963

Epoch: 6| Step: 10
Training loss: 1.8095942735671997
Validation loss: 2.1086127758026123

Epoch: 6| Step: 11
Training loss: 1.608813762664795
Validation loss: 2.1237822771072388

Epoch: 6| Step: 12
Training loss: 1.8873190879821777
Validation loss: 2.1083210905392966

Epoch: 6| Step: 13
Training loss: 1.9013805389404297
Validation loss: 2.1559819181760154

Epoch: 9| Step: 0
Training loss: 1.4352691173553467
Validation loss: 2.139938235282898

Epoch: 6| Step: 1
Training loss: 1.656446933746338
Validation loss: 2.144153118133545

Epoch: 6| Step: 2
Training loss: 2.0330636501312256
Validation loss: 2.133281191190084

Epoch: 6| Step: 3
Training loss: 1.518918514251709
Validation loss: 2.1079734762509665

Epoch: 6| Step: 4
Training loss: 2.8198230266571045
Validation loss: 2.1125852465629578

Epoch: 6| Step: 5
Training loss: 1.8252551555633545
Validation loss: 2.137313743432363

Epoch: 6| Step: 6
Training loss: 2.3161463737487793
Validation loss: 2.1483564972877502

Epoch: 6| Step: 7
Training loss: 1.764993667602539
Validation loss: 2.139108876387278

Epoch: 6| Step: 8
Training loss: 1.864652156829834
Validation loss: 2.121865431467692

Epoch: 6| Step: 9
Training loss: 2.6296205520629883
Validation loss: 2.1221695939699807

Epoch: 6| Step: 10
Training loss: 1.961746096611023
Validation loss: 2.110492527484894

Epoch: 6| Step: 11
Training loss: 2.1174840927124023
Validation loss: 2.126142740249634

Epoch: 6| Step: 12
Training loss: 2.7416579723358154
Validation loss: 2.134319523970286

Epoch: 6| Step: 13
Training loss: 2.5200095176696777
Validation loss: 2.137999653816223

Epoch: 10| Step: 0
Training loss: 1.898303508758545
Validation loss: 2.152638336022695

Epoch: 6| Step: 1
Training loss: 2.040421485900879
Validation loss: 2.1289258201917014

Epoch: 6| Step: 2
Training loss: 2.0684711933135986
Validation loss: 2.1407350103060403

Epoch: 6| Step: 3
Training loss: 2.3829660415649414
Validation loss: 2.1298840641975403

Epoch: 6| Step: 4
Training loss: 1.9011921882629395
Validation loss: 2.130521516005198

Epoch: 6| Step: 5
Training loss: 1.5463981628417969
Validation loss: 2.1586115956306458

Epoch: 6| Step: 6
Training loss: 2.2011661529541016
Validation loss: 2.134935816129049

Epoch: 6| Step: 7
Training loss: 1.918915033340454
Validation loss: 2.139314273993174

Epoch: 6| Step: 8
Training loss: 2.2290186882019043
Validation loss: 2.1544614831606546

Epoch: 6| Step: 9
Training loss: 2.0470759868621826
Validation loss: 2.130228817462921

Epoch: 6| Step: 10
Training loss: 2.872648000717163
Validation loss: 2.1269461512565613

Epoch: 6| Step: 11
Training loss: 1.6996315717697144
Validation loss: 2.1329236030578613

Epoch: 6| Step: 12
Training loss: 2.121516227722168
Validation loss: 2.113544245560964

Epoch: 6| Step: 13
Training loss: 2.0127885341644287
Validation loss: 2.1179760495821633

Epoch: 11| Step: 0
Training loss: 2.232623815536499
Validation loss: 2.1295052766799927

Epoch: 6| Step: 1
Training loss: 1.8331942558288574
Validation loss: 2.104740937550863

Epoch: 6| Step: 2
Training loss: 1.9881339073181152
Validation loss: 2.1252260208129883

Epoch: 6| Step: 3
Training loss: 1.8261300325393677
Validation loss: 2.115396281083425

Epoch: 6| Step: 4
Training loss: 1.812875747680664
Validation loss: 2.100471258163452

Epoch: 6| Step: 5
Training loss: 2.243767499923706
Validation loss: 2.103627363840739

Epoch: 6| Step: 6
Training loss: 1.6055322885513306
Validation loss: 2.1077258388201394

Epoch: 6| Step: 7
Training loss: 2.3563082218170166
Validation loss: 2.11327064037323

Epoch: 6| Step: 8
Training loss: 2.230689287185669
Validation loss: 2.1085126996040344

Epoch: 6| Step: 9
Training loss: 2.0301432609558105
Validation loss: 2.125557541847229

Epoch: 6| Step: 10
Training loss: 1.9756182432174683
Validation loss: 2.12447851896286

Epoch: 6| Step: 11
Training loss: 1.944618582725525
Validation loss: 2.1120518247286477

Epoch: 6| Step: 12
Training loss: 2.104487895965576
Validation loss: 2.1195051670074463

Epoch: 6| Step: 13
Training loss: 2.5051777362823486
Validation loss: 2.1011914014816284

Epoch: 12| Step: 0
Training loss: 1.866926908493042
Validation loss: 2.095745245615641

Epoch: 6| Step: 1
Training loss: 1.898301124572754
Validation loss: 2.1027604738871255

Epoch: 6| Step: 2
Training loss: 2.149198055267334
Validation loss: 2.1328167716662088

Epoch: 6| Step: 3
Training loss: 1.6510099172592163
Validation loss: 2.123346447944641

Epoch: 6| Step: 4
Training loss: 1.8272066116333008
Validation loss: 2.108985424041748

Epoch: 6| Step: 5
Training loss: 2.437511682510376
Validation loss: 2.129554291566213

Epoch: 6| Step: 6
Training loss: 2.3526978492736816
Validation loss: 2.114869256814321

Epoch: 6| Step: 7
Training loss: 1.8278892040252686
Validation loss: 2.129704217116038

Epoch: 6| Step: 8
Training loss: 2.5956315994262695
Validation loss: 2.1231425603230796

Epoch: 6| Step: 9
Training loss: 1.8790109157562256
Validation loss: 2.1214837630589805

Epoch: 6| Step: 10
Training loss: 1.7167315483093262
Validation loss: 2.1175409952799478

Epoch: 6| Step: 11
Training loss: 2.539665937423706
Validation loss: 2.1110812425613403

Epoch: 6| Step: 12
Training loss: 2.4020185470581055
Validation loss: 2.1075560450553894

Epoch: 6| Step: 13
Training loss: 1.8048086166381836
Validation loss: 2.096146603425344

Epoch: 13| Step: 0
Training loss: 1.9462764263153076
Validation loss: 2.1001972953478494

Epoch: 6| Step: 1
Training loss: 2.4948718547821045
Validation loss: 2.121752619743347

Epoch: 6| Step: 2
Training loss: 2.2949554920196533
Validation loss: 2.0804832776387534

Epoch: 6| Step: 3
Training loss: 1.502181887626648
Validation loss: 2.0921722451845803

Epoch: 6| Step: 4
Training loss: 2.119994878768921
Validation loss: 2.101275384426117

Epoch: 6| Step: 5
Training loss: 2.3133420944213867
Validation loss: 2.12120658159256

Epoch: 6| Step: 6
Training loss: 2.0530953407287598
Validation loss: 2.1242703596750894

Epoch: 6| Step: 7
Training loss: 1.549626111984253
Validation loss: 2.1002375880877175

Epoch: 6| Step: 8
Training loss: 2.0140902996063232
Validation loss: 2.0945997834205627

Epoch: 6| Step: 9
Training loss: 2.325779914855957
Validation loss: 2.119061211744944

Epoch: 6| Step: 10
Training loss: 1.5432201623916626
Validation loss: 2.1034011046091714

Epoch: 6| Step: 11
Training loss: 2.2379462718963623
Validation loss: 2.098679860432943

Epoch: 6| Step: 12
Training loss: 2.2344493865966797
Validation loss: 2.1141683061917624

Epoch: 6| Step: 13
Training loss: 2.179436206817627
Validation loss: 2.1161396702130637

Epoch: 14| Step: 0
Training loss: 2.026940107345581
Validation loss: 2.1033319234848022

Epoch: 6| Step: 1
Training loss: 1.398162841796875
Validation loss: 2.0665547847747803

Epoch: 6| Step: 2
Training loss: 2.3353002071380615
Validation loss: 2.106712063153585

Epoch: 6| Step: 3
Training loss: 1.9483492374420166
Validation loss: 2.113293727238973

Epoch: 6| Step: 4
Training loss: 1.7639747858047485
Validation loss: 2.1090140541394553

Epoch: 6| Step: 5
Training loss: 2.358142137527466
Validation loss: 2.104084610939026

Epoch: 6| Step: 6
Training loss: 2.0330848693847656
Validation loss: 2.0984149177869162

Epoch: 6| Step: 7
Training loss: 2.0352444648742676
Validation loss: 2.094097137451172

Epoch: 6| Step: 8
Training loss: 2.227419853210449
Validation loss: 2.091244379679362

Epoch: 6| Step: 9
Training loss: 2.047498941421509
Validation loss: 2.097315231959025

Epoch: 6| Step: 10
Training loss: 2.078723192214966
Validation loss: 2.0827866792678833

Epoch: 6| Step: 11
Training loss: 1.8367912769317627
Validation loss: 2.1108775536219277

Epoch: 6| Step: 12
Training loss: 2.356320381164551
Validation loss: 2.0954328179359436

Epoch: 6| Step: 13
Training loss: 1.8794547319412231
Validation loss: 2.1194515426953635

Epoch: 15| Step: 0
Training loss: 2.1997568607330322
Validation loss: 2.107829511165619

Epoch: 6| Step: 1
Training loss: 2.1342010498046875
Validation loss: 2.111072818438212

Epoch: 6| Step: 2
Training loss: 2.2363102436065674
Validation loss: 2.1029242277145386

Epoch: 6| Step: 3
Training loss: 2.2189488410949707
Validation loss: 2.093968689441681

Epoch: 6| Step: 4
Training loss: 1.9402340650558472
Validation loss: 2.085041125615438

Epoch: 6| Step: 5
Training loss: 2.1938276290893555
Validation loss: 2.092197279135386

Epoch: 6| Step: 6
Training loss: 2.0985207557678223
Validation loss: 2.0905736486117044

Epoch: 6| Step: 7
Training loss: 1.499780297279358
Validation loss: 2.094895124435425

Epoch: 6| Step: 8
Training loss: 2.0005040168762207
Validation loss: 2.094878673553467

Epoch: 6| Step: 9
Training loss: 2.164168119430542
Validation loss: 2.065917730331421

Epoch: 6| Step: 10
Training loss: 1.7597594261169434
Validation loss: 2.1080007553100586

Epoch: 6| Step: 11
Training loss: 1.946121335029602
Validation loss: 2.0924247105916343

Epoch: 6| Step: 12
Training loss: 1.9260469675064087
Validation loss: 2.0795403718948364

Epoch: 6| Step: 13
Training loss: 2.179055690765381
Validation loss: 2.0846901734670005

Epoch: 16| Step: 0
Training loss: 2.1814301013946533
Validation loss: 2.0698703130086265

Epoch: 6| Step: 1
Training loss: 2.037111282348633
Validation loss: 2.074009974797567

Epoch: 6| Step: 2
Training loss: 2.5458407402038574
Validation loss: 2.088185509045919

Epoch: 6| Step: 3
Training loss: 1.9822444915771484
Validation loss: 2.0844505230585733

Epoch: 6| Step: 4
Training loss: 1.783667802810669
Validation loss: 2.1036056677500405

Epoch: 6| Step: 5
Training loss: 2.354003667831421
Validation loss: 2.0778292616208396

Epoch: 6| Step: 6
Training loss: 2.6689586639404297
Validation loss: 2.080060442288717

Epoch: 6| Step: 7
Training loss: 1.7715404033660889
Validation loss: 2.089832862218221

Epoch: 6| Step: 8
Training loss: 2.3130974769592285
Validation loss: 2.0834319988886514

Epoch: 6| Step: 9
Training loss: 2.1119227409362793
Validation loss: 2.0644774039586387

Epoch: 6| Step: 10
Training loss: 1.8256503343582153
Validation loss: 2.0789530277252197

Epoch: 6| Step: 11
Training loss: 1.5936756134033203
Validation loss: 2.079420268535614

Epoch: 6| Step: 12
Training loss: 1.4172853231430054
Validation loss: 2.0893221298853555

Epoch: 6| Step: 13
Training loss: 1.7305793762207031
Validation loss: 2.092256247997284

Epoch: 17| Step: 0
Training loss: 2.118166923522949
Validation loss: 2.0893527269363403

Epoch: 6| Step: 1
Training loss: 1.8781464099884033
Validation loss: 2.096745193004608

Epoch: 6| Step: 2
Training loss: 1.7891963720321655
Validation loss: 2.0948237578074136

Epoch: 6| Step: 3
Training loss: 2.3789591789245605
Validation loss: 2.0852577288945517

Epoch: 6| Step: 4
Training loss: 1.6015806198120117
Validation loss: 2.080277601877848

Epoch: 6| Step: 5
Training loss: 2.186762571334839
Validation loss: 2.0891130367914834

Epoch: 6| Step: 6
Training loss: 2.1876912117004395
Validation loss: 2.0702255169550576

Epoch: 6| Step: 7
Training loss: 1.6684765815734863
Validation loss: 2.1025545795758567

Epoch: 6| Step: 8
Training loss: 1.894650936126709
Validation loss: 2.088995079199473

Epoch: 6| Step: 9
Training loss: 2.022977352142334
Validation loss: 2.077854891618093

Epoch: 6| Step: 10
Training loss: 2.156062364578247
Validation loss: 2.0687095324198403

Epoch: 6| Step: 11
Training loss: 2.174832344055176
Validation loss: 2.069056510925293

Epoch: 6| Step: 12
Training loss: 2.4968788623809814
Validation loss: 2.0796783367792764

Epoch: 6| Step: 13
Training loss: 1.8962085247039795
Validation loss: 2.0756197770436606

Epoch: 18| Step: 0
Training loss: 2.0241353511810303
Validation loss: 2.105450987815857

Epoch: 6| Step: 1
Training loss: 2.162827968597412
Validation loss: 2.0705928603808084

Epoch: 6| Step: 2
Training loss: 2.2528085708618164
Validation loss: 2.0821786721547446

Epoch: 6| Step: 3
Training loss: 2.5702157020568848
Validation loss: 2.0804530580838523

Epoch: 6| Step: 4
Training loss: 1.5337071418762207
Validation loss: 2.0647037823994956

Epoch: 6| Step: 5
Training loss: 2.388279438018799
Validation loss: 2.065613607565562

Epoch: 6| Step: 6
Training loss: 2.221759557723999
Validation loss: 2.060896337032318

Epoch: 6| Step: 7
Training loss: 1.4961962699890137
Validation loss: 2.06932000319163

Epoch: 6| Step: 8
Training loss: 1.7854986190795898
Validation loss: 2.0583332180976868

Epoch: 6| Step: 9
Training loss: 2.36215877532959
Validation loss: 2.0558799505233765

Epoch: 6| Step: 10
Training loss: 1.8803043365478516
Validation loss: 2.0689761638641357

Epoch: 6| Step: 11
Training loss: 2.1655218601226807
Validation loss: 2.0481925209363303

Epoch: 6| Step: 12
Training loss: 1.476412296295166
Validation loss: 2.090714673201243

Epoch: 6| Step: 13
Training loss: 1.7648615837097168
Validation loss: 2.0804596145947776

Epoch: 19| Step: 0
Training loss: 1.7624328136444092
Validation loss: 2.067008157571157

Epoch: 6| Step: 1
Training loss: 2.3376986980438232
Validation loss: 2.0735384623209634

Epoch: 6| Step: 2
Training loss: 1.2918064594268799
Validation loss: 2.077092488606771

Epoch: 6| Step: 3
Training loss: 2.0075788497924805
Validation loss: 2.0893117785453796

Epoch: 6| Step: 4
Training loss: 2.357875347137451
Validation loss: 2.094989538192749

Epoch: 6| Step: 5
Training loss: 3.0354814529418945
Validation loss: 2.1227259039878845

Epoch: 6| Step: 6
Training loss: 2.486464500427246
Validation loss: 2.098311483860016

Epoch: 6| Step: 7
Training loss: 2.2832183837890625
Validation loss: 2.1077410181363425

Epoch: 6| Step: 8
Training loss: 1.758385181427002
Validation loss: 2.1161556442578635

Epoch: 6| Step: 9
Training loss: 1.4153120517730713
Validation loss: 2.1209362149238586

Epoch: 6| Step: 10
Training loss: 1.2251067161560059
Validation loss: 2.077876349290212

Epoch: 6| Step: 11
Training loss: 1.533172369003296
Validation loss: 2.1052350997924805

Epoch: 6| Step: 12
Training loss: 2.4399914741516113
Validation loss: 2.062278707822164

Epoch: 6| Step: 13
Training loss: 2.370126247406006
Validation loss: 2.097971578439077

Epoch: 20| Step: 0
Training loss: 1.9730184078216553
Validation loss: 2.0660964051882424

Epoch: 6| Step: 1
Training loss: 2.250962972640991
Validation loss: 2.0549820264180503

Epoch: 6| Step: 2
Training loss: 2.489915370941162
Validation loss: 2.0790754556655884

Epoch: 6| Step: 3
Training loss: 1.123337745666504
Validation loss: 2.0568334460258484

Epoch: 6| Step: 4
Training loss: 1.8077964782714844
Validation loss: 2.0651833613713584

Epoch: 6| Step: 5
Training loss: 2.411436080932617
Validation loss: 2.0712953011194863

Epoch: 6| Step: 6
Training loss: 1.4578893184661865
Validation loss: 2.074148635069529

Epoch: 6| Step: 7
Training loss: 2.343968391418457
Validation loss: 2.0484225352605185

Epoch: 6| Step: 8
Training loss: 2.1250452995300293
Validation loss: 2.057330846786499

Epoch: 6| Step: 9
Training loss: 1.8375335931777954
Validation loss: 2.0684505303700766

Epoch: 6| Step: 10
Training loss: 2.4462528228759766
Validation loss: 2.063770850499471

Epoch: 6| Step: 11
Training loss: 1.5817551612854004
Validation loss: 2.063944717248281

Epoch: 6| Step: 12
Training loss: 2.0662152767181396
Validation loss: 2.050919751326243

Epoch: 6| Step: 13
Training loss: 2.3409860134124756
Validation loss: 2.0622266928354898

Epoch: 21| Step: 0
Training loss: 2.187588691711426
Validation loss: 2.0664098461469016

Epoch: 6| Step: 1
Training loss: 1.407697081565857
Validation loss: 2.031651258468628

Epoch: 6| Step: 2
Training loss: 2.3372280597686768
Validation loss: 2.043433924516042

Epoch: 6| Step: 3
Training loss: 2.2064807415008545
Validation loss: 2.0553174018859863

Epoch: 6| Step: 4
Training loss: 2.063185214996338
Validation loss: 2.0456034938494363

Epoch: 6| Step: 5
Training loss: 1.9521845579147339
Validation loss: 2.0579349199930825

Epoch: 6| Step: 6
Training loss: 1.8487108945846558
Validation loss: 2.062739630540212

Epoch: 6| Step: 7
Training loss: 1.9689503908157349
Validation loss: 2.063583334287008

Epoch: 6| Step: 8
Training loss: 2.189383029937744
Validation loss: 2.0571856101353965

Epoch: 6| Step: 9
Training loss: 2.522311210632324
Validation loss: 2.055753509203593

Epoch: 6| Step: 10
Training loss: 2.063450336456299
Validation loss: 2.071617384751638

Epoch: 6| Step: 11
Training loss: 1.728040337562561
Validation loss: 2.0637728373209634

Epoch: 6| Step: 12
Training loss: 2.1034555435180664
Validation loss: 2.0584147572517395

Epoch: 6| Step: 13
Training loss: 1.5055251121520996
Validation loss: 2.068700889746348

Epoch: 22| Step: 0
Training loss: 1.355380892753601
Validation loss: 2.0561463435490928

Epoch: 6| Step: 1
Training loss: 1.6927440166473389
Validation loss: 2.053264935811361

Epoch: 6| Step: 2
Training loss: 1.4461123943328857
Validation loss: 2.044816513856252

Epoch: 6| Step: 3
Training loss: 1.9108786582946777
Validation loss: 2.0546741684277854

Epoch: 6| Step: 4
Training loss: 2.1833155155181885
Validation loss: 2.0725881656010947

Epoch: 6| Step: 5
Training loss: 2.6519312858581543
Validation loss: 2.0713698466618857

Epoch: 6| Step: 6
Training loss: 2.3367996215820312
Validation loss: 2.048214534918467

Epoch: 6| Step: 7
Training loss: 2.7301950454711914
Validation loss: 2.07998995979627

Epoch: 6| Step: 8
Training loss: 2.4151036739349365
Validation loss: 2.086399873097738

Epoch: 6| Step: 9
Training loss: 1.905808448791504
Validation loss: 2.087484876314799

Epoch: 6| Step: 10
Training loss: 1.6839914321899414
Validation loss: 2.0581454833348594

Epoch: 6| Step: 11
Training loss: 2.232422113418579
Validation loss: 2.071174760659536

Epoch: 6| Step: 12
Training loss: 1.8728241920471191
Validation loss: 2.0675636331240335

Epoch: 6| Step: 13
Training loss: 1.6559593677520752
Validation loss: 2.070704221725464

Epoch: 23| Step: 0
Training loss: 1.8167297840118408
Validation loss: 2.0464069644610086

Epoch: 6| Step: 1
Training loss: 1.746809959411621
Validation loss: 2.0494744777679443

Epoch: 6| Step: 2
Training loss: 1.444706916809082
Validation loss: 2.0329620440800986

Epoch: 6| Step: 3
Training loss: 1.9611093997955322
Validation loss: 2.0458486874898276

Epoch: 6| Step: 4
Training loss: 2.058746576309204
Validation loss: 2.0637041330337524

Epoch: 6| Step: 5
Training loss: 2.705812454223633
Validation loss: 2.0428582231203714

Epoch: 6| Step: 6
Training loss: 2.6797127723693848
Validation loss: 2.062977989514669

Epoch: 6| Step: 7
Training loss: 2.293260335922241
Validation loss: 2.0710593263308206

Epoch: 6| Step: 8
Training loss: 1.4264265298843384
Validation loss: 2.076781392097473

Epoch: 6| Step: 9
Training loss: 1.957930088043213
Validation loss: 2.064076085885366

Epoch: 6| Step: 10
Training loss: 1.8851099014282227
Validation loss: 2.0722516775131226

Epoch: 6| Step: 11
Training loss: 2.221644639968872
Validation loss: 2.071345786253611

Epoch: 6| Step: 12
Training loss: 2.186965227127075
Validation loss: 2.07827760775884

Epoch: 6| Step: 13
Training loss: 2.4493038654327393
Validation loss: 2.071222404638926

Epoch: 24| Step: 0
Training loss: 1.7620402574539185
Validation loss: 2.0612001617749534

Epoch: 6| Step: 1
Training loss: 1.9324333667755127
Validation loss: 2.0457818508148193

Epoch: 6| Step: 2
Training loss: 2.5044050216674805
Validation loss: 2.056526323159536

Epoch: 6| Step: 3
Training loss: 2.753993034362793
Validation loss: 2.020962357521057

Epoch: 6| Step: 4
Training loss: 2.01114559173584
Validation loss: 2.04861448208491

Epoch: 6| Step: 5
Training loss: 1.470019817352295
Validation loss: 2.0576276183128357

Epoch: 6| Step: 6
Training loss: 1.918398141860962
Validation loss: 2.0348739425341287

Epoch: 6| Step: 7
Training loss: 1.589600920677185
Validation loss: 2.077651043732961

Epoch: 6| Step: 8
Training loss: 2.44793701171875
Validation loss: 2.0712992350260415

Epoch: 6| Step: 9
Training loss: 2.1677212715148926
Validation loss: 2.073417862256368

Epoch: 6| Step: 10
Training loss: 2.1609113216400146
Validation loss: 2.087880571683248

Epoch: 6| Step: 11
Training loss: 2.0943117141723633
Validation loss: 2.0896612803141275

Epoch: 6| Step: 12
Training loss: 1.3773547410964966
Validation loss: 2.066771845022837

Epoch: 6| Step: 13
Training loss: 2.25551176071167
Validation loss: 2.0463643272717795

Epoch: 25| Step: 0
Training loss: 2.7558908462524414
Validation loss: 2.0677423675855002

Epoch: 6| Step: 1
Training loss: 1.652980089187622
Validation loss: 2.016136348247528

Epoch: 6| Step: 2
Training loss: 2.0117788314819336
Validation loss: 2.031818389892578

Epoch: 6| Step: 3
Training loss: 1.7128911018371582
Validation loss: 2.029628356297811

Epoch: 6| Step: 4
Training loss: 1.6537257432937622
Validation loss: 2.0260765751202903

Epoch: 6| Step: 5
Training loss: 1.855851411819458
Validation loss: 2.022667864958445

Epoch: 6| Step: 6
Training loss: 1.8195756673812866
Validation loss: 2.0233784317970276

Epoch: 6| Step: 7
Training loss: 1.7490267753601074
Validation loss: 2.016820947329203

Epoch: 6| Step: 8
Training loss: 1.5495396852493286
Validation loss: 2.031386395295461

Epoch: 6| Step: 9
Training loss: 1.9200828075408936
Validation loss: 2.0406499902407327

Epoch: 6| Step: 10
Training loss: 2.5831480026245117
Validation loss: 2.0473540226618447

Epoch: 6| Step: 11
Training loss: 2.619922637939453
Validation loss: 2.0391408999760947

Epoch: 6| Step: 12
Training loss: 1.9278099536895752
Validation loss: 2.048836807409922

Epoch: 6| Step: 13
Training loss: 1.9270068407058716
Validation loss: 2.0370222131411233

Epoch: 26| Step: 0
Training loss: 1.5876080989837646
Validation loss: 2.0146564841270447

Epoch: 6| Step: 1
Training loss: 1.8565950393676758
Validation loss: 2.0170576175053916

Epoch: 6| Step: 2
Training loss: 2.1994547843933105
Validation loss: 2.039193550745646

Epoch: 6| Step: 3
Training loss: 2.288586139678955
Validation loss: 2.0580636064211526

Epoch: 6| Step: 4
Training loss: 2.232729434967041
Validation loss: 2.0358936389287314

Epoch: 6| Step: 5
Training loss: 1.2911027669906616
Validation loss: 2.019438068072001

Epoch: 6| Step: 6
Training loss: 1.8912265300750732
Validation loss: 2.050909241040548

Epoch: 6| Step: 7
Training loss: 1.8950330018997192
Validation loss: 2.054688890775045

Epoch: 6| Step: 8
Training loss: 2.0032646656036377
Validation loss: 2.0505318442980447

Epoch: 6| Step: 9
Training loss: 1.9168219566345215
Validation loss: 2.0313185453414917

Epoch: 6| Step: 10
Training loss: 2.3533499240875244
Validation loss: 2.063329041004181

Epoch: 6| Step: 11
Training loss: 1.9799338579177856
Validation loss: 2.0348812341690063

Epoch: 6| Step: 12
Training loss: 2.7307791709899902
Validation loss: 2.069614311059316

Epoch: 6| Step: 13
Training loss: 1.6313869953155518
Validation loss: 2.023843685785929

Epoch: 27| Step: 0
Training loss: 1.9246550798416138
Validation loss: 2.0510244170824685

Epoch: 6| Step: 1
Training loss: 2.26298189163208
Validation loss: 2.043633838494619

Epoch: 6| Step: 2
Training loss: 2.7066121101379395
Validation loss: 2.0126655300458274

Epoch: 6| Step: 3
Training loss: 1.5771713256835938
Validation loss: 2.0372197031974792

Epoch: 6| Step: 4
Training loss: 2.1135127544403076
Validation loss: 2.0364877184232077

Epoch: 6| Step: 5
Training loss: 2.4563775062561035
Validation loss: 2.0228647788365683

Epoch: 6| Step: 6
Training loss: 2.570432424545288
Validation loss: 2.0054398576418557

Epoch: 6| Step: 7
Training loss: 1.1737217903137207
Validation loss: 2.0269332925478616

Epoch: 6| Step: 8
Training loss: 2.1427111625671387
Validation loss: 2.036245365937551

Epoch: 6| Step: 9
Training loss: 1.7565326690673828
Validation loss: 2.0445406635602317

Epoch: 6| Step: 10
Training loss: 2.307607889175415
Validation loss: 2.019308308760325

Epoch: 6| Step: 11
Training loss: 1.5778698921203613
Validation loss: 2.042965292930603

Epoch: 6| Step: 12
Training loss: 1.4292254447937012
Validation loss: 2.0177328983942666

Epoch: 6| Step: 13
Training loss: 1.7663605213165283
Validation loss: 2.019331216812134

Epoch: 28| Step: 0
Training loss: 2.085141181945801
Validation loss: 2.0134716033935547

Epoch: 6| Step: 1
Training loss: 1.992046594619751
Validation loss: 2.0393634835879006

Epoch: 6| Step: 2
Training loss: 1.9618546962738037
Validation loss: 2.0258241097132363

Epoch: 6| Step: 3
Training loss: 3.1589884757995605
Validation loss: 2.037999391555786

Epoch: 6| Step: 4
Training loss: 1.8434042930603027
Validation loss: 2.0334123969078064

Epoch: 6| Step: 5
Training loss: 1.6095483303070068
Validation loss: 2.0347098112106323

Epoch: 6| Step: 6
Training loss: 1.5144257545471191
Validation loss: 2.0310415228207908

Epoch: 6| Step: 7
Training loss: 1.9910435676574707
Validation loss: 2.0380306442578635

Epoch: 6| Step: 8
Training loss: 1.8780076503753662
Validation loss: 2.0608983437220254

Epoch: 6| Step: 9
Training loss: 1.702430009841919
Validation loss: 2.0368695060412088

Epoch: 6| Step: 10
Training loss: 1.814026117324829
Validation loss: 2.041550318400065

Epoch: 6| Step: 11
Training loss: 2.0718746185302734
Validation loss: 2.031287511189779

Epoch: 6| Step: 12
Training loss: 2.6196160316467285
Validation loss: 2.026050011316935

Epoch: 6| Step: 13
Training loss: 1.3822687864303589
Validation loss: 1.9929085572560628

Epoch: 29| Step: 0
Training loss: 2.2174291610717773
Validation loss: 2.0346047083536782

Epoch: 6| Step: 1
Training loss: 2.1862375736236572
Validation loss: 2.041925589243571

Epoch: 6| Step: 2
Training loss: 2.500746488571167
Validation loss: 2.0117222468058267

Epoch: 6| Step: 3
Training loss: 2.265069007873535
Validation loss: 2.0431637366612754

Epoch: 6| Step: 4
Training loss: 2.108116388320923
Validation loss: 2.0213128129641214

Epoch: 6| Step: 5
Training loss: 1.6985695362091064
Validation loss: 2.0249849756558738

Epoch: 6| Step: 6
Training loss: 1.888698935508728
Validation loss: 2.055553992589315

Epoch: 6| Step: 7
Training loss: 1.8495993614196777
Validation loss: 2.0263131856918335

Epoch: 6| Step: 8
Training loss: 2.2778525352478027
Validation loss: 2.0401410659154258

Epoch: 6| Step: 9
Training loss: 1.9661132097244263
Validation loss: 2.0130064686139426

Epoch: 6| Step: 10
Training loss: 1.370955467224121
Validation loss: 2.0306809345881143

Epoch: 6| Step: 11
Training loss: 1.7512842416763306
Validation loss: 2.033336619536082

Epoch: 6| Step: 12
Training loss: 1.7120485305786133
Validation loss: 2.0440207521120706

Epoch: 6| Step: 13
Training loss: 1.4926707744598389
Validation loss: 2.0021310846010842

Epoch: 30| Step: 0
Training loss: 2.5507750511169434
Validation loss: 2.0302963058153787

Epoch: 6| Step: 1
Training loss: 1.9233903884887695
Validation loss: 2.0141005913416543

Epoch: 6| Step: 2
Training loss: 2.1553702354431152
Validation loss: 2.0292928218841553

Epoch: 6| Step: 3
Training loss: 1.837302327156067
Validation loss: 2.0436643163363137

Epoch: 6| Step: 4
Training loss: 1.8772847652435303
Validation loss: 2.037292460600535

Epoch: 6| Step: 5
Training loss: 1.8836798667907715
Validation loss: 2.041956086953481

Epoch: 6| Step: 6
Training loss: 3.2836873531341553
Validation loss: 2.0283069213231406

Epoch: 6| Step: 7
Training loss: 1.7976820468902588
Validation loss: 2.0239429275194802

Epoch: 6| Step: 8
Training loss: 1.4239434003829956
Validation loss: 2.0288909673690796

Epoch: 6| Step: 9
Training loss: 1.8434816598892212
Validation loss: 2.0347349445025125

Epoch: 6| Step: 10
Training loss: 1.6014097929000854
Validation loss: 2.0315930048624673

Epoch: 6| Step: 11
Training loss: 1.6660596132278442
Validation loss: 2.0322936375935874

Epoch: 6| Step: 12
Training loss: 1.8106880187988281
Validation loss: 2.033642331759135

Epoch: 6| Step: 13
Training loss: 1.818847894668579
Validation loss: 2.0231595039367676

Epoch: 31| Step: 0
Training loss: 1.5854642391204834
Validation loss: 2.0148210922876992

Epoch: 6| Step: 1
Training loss: 1.9849121570587158
Validation loss: 2.016604741414388

Epoch: 6| Step: 2
Training loss: 2.6329116821289062
Validation loss: 2.0219659407933555

Epoch: 6| Step: 3
Training loss: 1.164071798324585
Validation loss: 2.037829637527466

Epoch: 6| Step: 4
Training loss: 2.820319414138794
Validation loss: 2.030348459879557

Epoch: 6| Step: 5
Training loss: 1.995063066482544
Validation loss: 2.0469000538190207

Epoch: 6| Step: 6
Training loss: 2.2764453887939453
Validation loss: 2.0485642155011496

Epoch: 6| Step: 7
Training loss: 2.0438413619995117
Validation loss: 2.0237123370170593

Epoch: 6| Step: 8
Training loss: 2.7322487831115723
Validation loss: 2.0518245299657187

Epoch: 6| Step: 9
Training loss: 2.0229880809783936
Validation loss: 2.0406310757001243

Epoch: 6| Step: 10
Training loss: 1.193268060684204
Validation loss: 2.00831147034963

Epoch: 6| Step: 11
Training loss: 1.5472402572631836
Validation loss: 2.00129642089208

Epoch: 6| Step: 12
Training loss: 2.2075185775756836
Validation loss: 2.011445959409078

Epoch: 6| Step: 13
Training loss: 1.281318187713623
Validation loss: 2.03182452917099

Epoch: 32| Step: 0
Training loss: 1.9214367866516113
Validation loss: 2.0147117575009665

Epoch: 6| Step: 1
Training loss: 2.37777042388916
Validation loss: 2.024134119351705

Epoch: 6| Step: 2
Training loss: 2.063127040863037
Validation loss: 2.0048792362213135

Epoch: 6| Step: 3
Training loss: 1.671778678894043
Validation loss: 2.0086864034334817

Epoch: 6| Step: 4
Training loss: 1.2988312244415283
Validation loss: 2.027511239051819

Epoch: 6| Step: 5
Training loss: 1.690721035003662
Validation loss: 2.0136337677637735

Epoch: 6| Step: 6
Training loss: 1.5349154472351074
Validation loss: 2.0157623489697776

Epoch: 6| Step: 7
Training loss: 2.2718405723571777
Validation loss: 2.0034372011820474

Epoch: 6| Step: 8
Training loss: 2.127847909927368
Validation loss: 2.021677017211914

Epoch: 6| Step: 9
Training loss: 1.8371050357818604
Validation loss: 2.0179653565088906

Epoch: 6| Step: 10
Training loss: 1.6523361206054688
Validation loss: 2.0144352316856384

Epoch: 6| Step: 11
Training loss: 2.859447717666626
Validation loss: 2.0128398140271506

Epoch: 6| Step: 12
Training loss: 2.1912341117858887
Validation loss: 2.0299031138420105

Epoch: 6| Step: 13
Training loss: 1.6864688396453857
Validation loss: 2.0412365198135376

Epoch: 33| Step: 0
Training loss: 1.4962791204452515
Validation loss: 2.04919163386027

Epoch: 6| Step: 1
Training loss: 1.505797028541565
Validation loss: 2.0337722301483154

Epoch: 6| Step: 2
Training loss: 1.9116153717041016
Validation loss: 2.0337135394414267

Epoch: 6| Step: 3
Training loss: 2.936450719833374
Validation loss: 2.04191662867864

Epoch: 6| Step: 4
Training loss: 2.2246289253234863
Validation loss: 2.0144065022468567

Epoch: 6| Step: 5
Training loss: 1.3659167289733887
Validation loss: 2.0337876677513123

Epoch: 6| Step: 6
Training loss: 1.9305100440979004
Validation loss: 1.995771547158559

Epoch: 6| Step: 7
Training loss: 2.069375514984131
Validation loss: 2.015231947104136

Epoch: 6| Step: 8
Training loss: 2.456392765045166
Validation loss: 2.006173292795817

Epoch: 6| Step: 9
Training loss: 1.9493448734283447
Validation loss: 2.004509965578715

Epoch: 6| Step: 10
Training loss: 1.704223871231079
Validation loss: 2.0213737885157266

Epoch: 6| Step: 11
Training loss: 2.404841184616089
Validation loss: 2.0250813364982605

Epoch: 6| Step: 12
Training loss: 1.6572322845458984
Validation loss: 2.0057643055915833

Epoch: 6| Step: 13
Training loss: 2.1274232864379883
Validation loss: 2.0119988719622293

Epoch: 34| Step: 0
Training loss: 1.4072442054748535
Validation loss: 2.0088822642962136

Epoch: 6| Step: 1
Training loss: 2.341046094894409
Validation loss: 2.0167451898256936

Epoch: 6| Step: 2
Training loss: 1.8706175088882446
Validation loss: 2.0090829928716025

Epoch: 6| Step: 3
Training loss: 2.148341417312622
Validation loss: 2.027683138847351

Epoch: 6| Step: 4
Training loss: 1.3993524312973022
Validation loss: 2.0235207080841064

Epoch: 6| Step: 5
Training loss: 1.7519142627716064
Validation loss: 2.0031566818555198

Epoch: 6| Step: 6
Training loss: 2.086759328842163
Validation loss: 2.0294403036435447

Epoch: 6| Step: 7
Training loss: 1.8581475019454956
Validation loss: 2.040028929710388

Epoch: 6| Step: 8
Training loss: 2.6579456329345703
Validation loss: 2.0505152344703674

Epoch: 6| Step: 9
Training loss: 1.6631709337234497
Validation loss: 2.0721784631411233

Epoch: 6| Step: 10
Training loss: 1.7356255054473877
Validation loss: 2.0425268411636353

Epoch: 6| Step: 11
Training loss: 2.297441005706787
Validation loss: 2.026556134223938

Epoch: 6| Step: 12
Training loss: 1.5071945190429688
Validation loss: 2.0394235452016196

Epoch: 6| Step: 13
Training loss: 2.693669319152832
Validation loss: 2.044784963130951

Epoch: 35| Step: 0
Training loss: 1.901971459388733
Validation loss: 2.01913454135259

Epoch: 6| Step: 1
Training loss: 2.219707489013672
Validation loss: 2.046036163965861

Epoch: 6| Step: 2
Training loss: 1.9540756940841675
Validation loss: 2.0124735633532205

Epoch: 6| Step: 3
Training loss: 1.2768992185592651
Validation loss: 2.006931563218435

Epoch: 6| Step: 4
Training loss: 1.5929144620895386
Validation loss: 2.0177637736002603

Epoch: 6| Step: 5
Training loss: 2.0428812503814697
Validation loss: 2.017801026503245

Epoch: 6| Step: 6
Training loss: 1.677324652671814
Validation loss: 1.9973157445589702

Epoch: 6| Step: 7
Training loss: 2.3004565238952637
Validation loss: 2.0217975775400796

Epoch: 6| Step: 8
Training loss: 2.2498092651367188
Validation loss: 1.9933337966601055

Epoch: 6| Step: 9
Training loss: 2.355497360229492
Validation loss: 2.011169672012329

Epoch: 6| Step: 10
Training loss: 2.202758312225342
Validation loss: 2.0248079697291055

Epoch: 6| Step: 11
Training loss: 2.137911081314087
Validation loss: 2.009790062904358

Epoch: 6| Step: 12
Training loss: 2.0084877014160156
Validation loss: 2.0316227277119956

Epoch: 6| Step: 13
Training loss: 1.4706447124481201
Validation loss: 2.015574117501577

Epoch: 36| Step: 0
Training loss: 1.3875243663787842
Validation loss: 2.040660818417867

Epoch: 6| Step: 1
Training loss: 2.2138118743896484
Validation loss: 2.021880269050598

Epoch: 6| Step: 2
Training loss: 2.472407579421997
Validation loss: 1.9997799793879192

Epoch: 6| Step: 3
Training loss: 2.0973124504089355
Validation loss: 2.031144400437673

Epoch: 6| Step: 4
Training loss: 1.77190101146698
Validation loss: 2.0298201640446982

Epoch: 6| Step: 5
Training loss: 1.5046029090881348
Validation loss: 2.014235277970632

Epoch: 6| Step: 6
Training loss: 1.767474889755249
Validation loss: 1.9852375785509746

Epoch: 6| Step: 7
Training loss: 2.546504020690918
Validation loss: 1.991421898206075

Epoch: 6| Step: 8
Training loss: 1.8097097873687744
Validation loss: 1.9967596133550007

Epoch: 6| Step: 9
Training loss: 1.636440396308899
Validation loss: 2.0202638705571494

Epoch: 6| Step: 10
Training loss: 1.6007335186004639
Validation loss: 2.0059403578440347

Epoch: 6| Step: 11
Training loss: 2.1014997959136963
Validation loss: 2.0357688864072165

Epoch: 6| Step: 12
Training loss: 2.2469141483306885
Validation loss: 2.0272722840309143

Epoch: 6| Step: 13
Training loss: 2.0500128269195557
Validation loss: 2.04205314318339

Epoch: 37| Step: 0
Training loss: 1.8375637531280518
Validation loss: 2.0422125260035195

Epoch: 6| Step: 1
Training loss: 2.3788726329803467
Validation loss: 2.048829197883606

Epoch: 6| Step: 2
Training loss: 1.051950216293335
Validation loss: 2.0296996434529624

Epoch: 6| Step: 3
Training loss: 3.0486388206481934
Validation loss: 2.0422679583231607

Epoch: 6| Step: 4
Training loss: 2.184156894683838
Validation loss: 2.045049548149109

Epoch: 6| Step: 5
Training loss: 1.6161048412322998
Validation loss: 2.0189072688420615

Epoch: 6| Step: 6
Training loss: 1.5758659839630127
Validation loss: 2.0323980847994485

Epoch: 6| Step: 7
Training loss: 2.1213221549987793
Validation loss: 2.0015833179155984

Epoch: 6| Step: 8
Training loss: 1.9526904821395874
Validation loss: 2.010908563931783

Epoch: 6| Step: 9
Training loss: 2.2549867630004883
Validation loss: 2.026206115881602

Epoch: 6| Step: 10
Training loss: 2.016488790512085
Validation loss: 2.0317665735880532

Epoch: 6| Step: 11
Training loss: 1.3082890510559082
Validation loss: 1.9959513147672017

Epoch: 6| Step: 12
Training loss: 1.8981690406799316
Validation loss: 1.9965420365333557

Epoch: 6| Step: 13
Training loss: 1.9843418598175049
Validation loss: 1.9932373563448589

Epoch: 38| Step: 0
Training loss: 2.3120017051696777
Validation loss: 2.0125614404678345

Epoch: 6| Step: 1
Training loss: 1.8462849855422974
Validation loss: 1.9839454392592113

Epoch: 6| Step: 2
Training loss: 1.9445507526397705
Validation loss: 2.017716705799103

Epoch: 6| Step: 3
Training loss: 1.8309215307235718
Validation loss: 2.0264782110850015

Epoch: 6| Step: 4
Training loss: 2.028228282928467
Validation loss: 2.0222941239674888

Epoch: 6| Step: 5
Training loss: 1.890860915184021
Validation loss: 2.0409897565841675

Epoch: 6| Step: 6
Training loss: 1.438063383102417
Validation loss: 2.018920123577118

Epoch: 6| Step: 7
Training loss: 1.7823262214660645
Validation loss: 2.023763418197632

Epoch: 6| Step: 8
Training loss: 2.043593406677246
Validation loss: 2.0282146334648132

Epoch: 6| Step: 9
Training loss: 1.9305475950241089
Validation loss: 2.0145090619723

Epoch: 6| Step: 10
Training loss: 1.4402215480804443
Validation loss: 2.0582998792330423

Epoch: 6| Step: 11
Training loss: 2.823883533477783
Validation loss: 2.0434113343556723

Epoch: 6| Step: 12
Training loss: 1.9445476531982422
Validation loss: 2.0568564732869468

Epoch: 6| Step: 13
Training loss: 1.8575153350830078
Validation loss: 2.022587537765503

Epoch: 39| Step: 0
Training loss: 2.4025299549102783
Validation loss: 2.0188817779223123

Epoch: 6| Step: 1
Training loss: 2.020671844482422
Validation loss: 2.000628193219503

Epoch: 6| Step: 2
Training loss: 1.942991852760315
Validation loss: 2.021477202574412

Epoch: 6| Step: 3
Training loss: 1.9594769477844238
Validation loss: 2.0047082901000977

Epoch: 6| Step: 4
Training loss: 1.4442646503448486
Validation loss: 2.01232773065567

Epoch: 6| Step: 5
Training loss: 1.7896995544433594
Validation loss: 2.0308918952941895

Epoch: 6| Step: 6
Training loss: 2.048692226409912
Validation loss: 2.004294494787852

Epoch: 6| Step: 7
Training loss: 2.0002260208129883
Validation loss: 1.9822506705919902

Epoch: 6| Step: 8
Training loss: 1.8767929077148438
Validation loss: 1.999545435110728

Epoch: 6| Step: 9
Training loss: 1.6994564533233643
Validation loss: 2.002939144770304

Epoch: 6| Step: 10
Training loss: 1.8892743587493896
Validation loss: 2.0051783323287964

Epoch: 6| Step: 11
Training loss: 2.0436553955078125
Validation loss: 2.017868399620056

Epoch: 6| Step: 12
Training loss: 1.7591438293457031
Validation loss: 2.0173680981000266

Epoch: 6| Step: 13
Training loss: 2.2953948974609375
Validation loss: 2.0385638078053794

Epoch: 40| Step: 0
Training loss: 1.7618093490600586
Validation loss: 2.04618771870931

Epoch: 6| Step: 1
Training loss: 2.229959011077881
Validation loss: 2.043242653210958

Epoch: 6| Step: 2
Training loss: 1.9217134714126587
Validation loss: 2.0541638135910034

Epoch: 6| Step: 3
Training loss: 2.2295312881469727
Validation loss: 2.0430760979652405

Epoch: 6| Step: 4
Training loss: 1.87602698802948
Validation loss: 2.0481984416643777

Epoch: 6| Step: 5
Training loss: 1.347419023513794
Validation loss: 2.0440263152122498

Epoch: 6| Step: 6
Training loss: 1.891090750694275
Validation loss: 2.028436521689097

Epoch: 6| Step: 7
Training loss: 2.3908028602600098
Validation loss: 2.02444318930308

Epoch: 6| Step: 8
Training loss: 2.0830368995666504
Validation loss: 2.002643128236135

Epoch: 6| Step: 9
Training loss: 1.6923162937164307
Validation loss: 2.0271679957707724

Epoch: 6| Step: 10
Training loss: 1.9325168132781982
Validation loss: 2.019092301527659

Epoch: 6| Step: 11
Training loss: 1.8847326040267944
Validation loss: 2.02381839354833

Epoch: 6| Step: 12
Training loss: 2.494830369949341
Validation loss: 2.0051998694737754

Epoch: 6| Step: 13
Training loss: 1.4042258262634277
Validation loss: 2.028415044148763

Epoch: 41| Step: 0
Training loss: 1.747590184211731
Validation loss: 2.006570319334666

Epoch: 6| Step: 1
Training loss: 1.4813377857208252
Validation loss: 2.005130708217621

Epoch: 6| Step: 2
Training loss: 2.3670482635498047
Validation loss: 2.027441998322805

Epoch: 6| Step: 3
Training loss: 2.1011390686035156
Validation loss: 1.9862908720970154

Epoch: 6| Step: 4
Training loss: 2.602790355682373
Validation loss: 1.9945706923802693

Epoch: 6| Step: 5
Training loss: 2.0099220275878906
Validation loss: 2.00396591424942

Epoch: 6| Step: 6
Training loss: 1.6077897548675537
Validation loss: 1.9835771520932515

Epoch: 6| Step: 7
Training loss: 2.416205406188965
Validation loss: 1.9914402961730957

Epoch: 6| Step: 8
Training loss: 1.476264238357544
Validation loss: 1.9980195760726929

Epoch: 6| Step: 9
Training loss: 1.8679282665252686
Validation loss: 2.004576881726583

Epoch: 6| Step: 10
Training loss: 1.772737979888916
Validation loss: 1.9968701402346294

Epoch: 6| Step: 11
Training loss: 1.7166085243225098
Validation loss: 1.9858057300249736

Epoch: 6| Step: 12
Training loss: 1.8111047744750977
Validation loss: 2.026860773563385

Epoch: 6| Step: 13
Training loss: 1.9148752689361572
Validation loss: 2.008485515912374

Epoch: 42| Step: 0
Training loss: 1.4642176628112793
Validation loss: 2.025630017121633

Epoch: 6| Step: 1
Training loss: 1.6377043724060059
Validation loss: 2.0237069129943848

Epoch: 6| Step: 2
Training loss: 1.6881580352783203
Validation loss: 1.9906758069992065

Epoch: 6| Step: 3
Training loss: 1.9246973991394043
Validation loss: 2.0235544443130493

Epoch: 6| Step: 4
Training loss: 1.9680023193359375
Validation loss: 2.0338756839434304

Epoch: 6| Step: 5
Training loss: 2.5487003326416016
Validation loss: 2.0259756445884705

Epoch: 6| Step: 6
Training loss: 1.607632040977478
Validation loss: 1.9870617588361104

Epoch: 6| Step: 7
Training loss: 1.9392244815826416
Validation loss: 2.022737522919973

Epoch: 6| Step: 8
Training loss: 1.4545985460281372
Validation loss: 2.0187306006749473

Epoch: 6| Step: 9
Training loss: 2.0923500061035156
Validation loss: 2.003117402394613

Epoch: 6| Step: 10
Training loss: 1.4690849781036377
Validation loss: 2.010886232058207

Epoch: 6| Step: 11
Training loss: 2.246206521987915
Validation loss: 2.0041233897209167

Epoch: 6| Step: 12
Training loss: 2.4241974353790283
Validation loss: 1.9921608368555705

Epoch: 6| Step: 13
Training loss: 2.044238567352295
Validation loss: 1.9818161129951477

Epoch: 43| Step: 0
Training loss: 2.126847267150879
Validation loss: 1.993493338425954

Epoch: 6| Step: 1
Training loss: 1.7881920337677002
Validation loss: 1.986947735150655

Epoch: 6| Step: 2
Training loss: 1.8385286331176758
Validation loss: 1.985702892144521

Epoch: 6| Step: 3
Training loss: 2.131835699081421
Validation loss: 1.9923449158668518

Epoch: 6| Step: 4
Training loss: 2.2641444206237793
Validation loss: 1.9811600248018901

Epoch: 6| Step: 5
Training loss: 2.176325798034668
Validation loss: 1.9997603098551433

Epoch: 6| Step: 6
Training loss: 1.8679472208023071
Validation loss: 2.0218122800191245

Epoch: 6| Step: 7
Training loss: 1.9889192581176758
Validation loss: 2.0131543080012

Epoch: 6| Step: 8
Training loss: 1.839730978012085
Validation loss: 2.0221200982729592

Epoch: 6| Step: 9
Training loss: 1.6925848722457886
Validation loss: 2.029231528441111

Epoch: 6| Step: 10
Training loss: 1.2774726152420044
Validation loss: 2.045995831489563

Epoch: 6| Step: 11
Training loss: 1.827953577041626
Validation loss: 2.0347559452056885

Epoch: 6| Step: 12
Training loss: 2.9080374240875244
Validation loss: 2.010530690352122

Epoch: 6| Step: 13
Training loss: 1.342383861541748
Validation loss: 2.0083848436673484

Epoch: 44| Step: 0
Training loss: 1.7407701015472412
Validation loss: 2.0409027338027954

Epoch: 6| Step: 1
Training loss: 2.099426031112671
Validation loss: 2.0281090339024863

Epoch: 6| Step: 2
Training loss: 1.5537197589874268
Validation loss: 1.9979440967241924

Epoch: 6| Step: 3
Training loss: 2.055588722229004
Validation loss: 2.009512801965078

Epoch: 6| Step: 4
Training loss: 2.090451240539551
Validation loss: 2.017255445321401

Epoch: 6| Step: 5
Training loss: 2.416890859603882
Validation loss: 2.010071416695913

Epoch: 6| Step: 6
Training loss: 1.624707818031311
Validation loss: 2.032496194044749

Epoch: 6| Step: 7
Training loss: 1.6629388332366943
Validation loss: 1.993746777375539

Epoch: 6| Step: 8
Training loss: 0.9763497114181519
Validation loss: 1.999962051709493

Epoch: 6| Step: 9
Training loss: 2.2742066383361816
Validation loss: 1.9904560049374898

Epoch: 6| Step: 10
Training loss: 2.31533145904541
Validation loss: 1.98785134156545

Epoch: 6| Step: 11
Training loss: 1.6987853050231934
Validation loss: 2.0026167829831443

Epoch: 6| Step: 12
Training loss: 1.7584713697433472
Validation loss: 1.9877997239430745

Epoch: 6| Step: 13
Training loss: 2.539273500442505
Validation loss: 1.9946569204330444

Epoch: 45| Step: 0
Training loss: 2.267092704772949
Validation loss: 1.9713335831960042

Epoch: 6| Step: 1
Training loss: 1.8441452980041504
Validation loss: 1.9766237338383992

Epoch: 6| Step: 2
Training loss: 1.7888710498809814
Validation loss: 2.0033650199572244

Epoch: 6| Step: 3
Training loss: 1.852221965789795
Validation loss: 1.9600878357887268

Epoch: 6| Step: 4
Training loss: 2.1352503299713135
Validation loss: 2.0094629724820456

Epoch: 6| Step: 5
Training loss: 1.5271406173706055
Validation loss: 1.9873636960983276

Epoch: 6| Step: 6
Training loss: 1.9839239120483398
Validation loss: 2.034499923388163

Epoch: 6| Step: 7
Training loss: 2.565138816833496
Validation loss: 2.0393356879552207

Epoch: 6| Step: 8
Training loss: 2.3564248085021973
Validation loss: 2.0523916482925415

Epoch: 6| Step: 9
Training loss: 1.780096173286438
Validation loss: 2.069435954093933

Epoch: 6| Step: 10
Training loss: 1.8580007553100586
Validation loss: 2.0921717484792075

Epoch: 6| Step: 11
Training loss: 1.7695527076721191
Validation loss: 2.082420229911804

Epoch: 6| Step: 12
Training loss: 1.5190391540527344
Validation loss: 2.0449030995368958

Epoch: 6| Step: 13
Training loss: 1.5924776792526245
Validation loss: 2.063365618387858

Epoch: 46| Step: 0
Training loss: 1.6375597715377808
Validation loss: 2.0396708647410073

Epoch: 6| Step: 1
Training loss: 1.7830243110656738
Validation loss: 2.015005091826121

Epoch: 6| Step: 2
Training loss: 1.7181286811828613
Validation loss: 2.0091567238171897

Epoch: 6| Step: 3
Training loss: 1.892348051071167
Validation loss: 2.006686270236969

Epoch: 6| Step: 4
Training loss: 1.8076870441436768
Validation loss: 1.9804330070813496

Epoch: 6| Step: 5
Training loss: 2.014662265777588
Validation loss: 1.992078383763631

Epoch: 6| Step: 6
Training loss: 1.7737152576446533
Validation loss: 2.0048603415489197

Epoch: 6| Step: 7
Training loss: 1.3340247869491577
Validation loss: 1.986851433912913

Epoch: 6| Step: 8
Training loss: 2.5196542739868164
Validation loss: 1.993381639321645

Epoch: 6| Step: 9
Training loss: 1.7714968919754028
Validation loss: 1.987148900826772

Epoch: 6| Step: 10
Training loss: 2.40640926361084
Validation loss: 1.996668517589569

Epoch: 6| Step: 11
Training loss: 2.2410542964935303
Validation loss: 1.9805063207944233

Epoch: 6| Step: 12
Training loss: 1.7705965042114258
Validation loss: 1.9859730799992878

Epoch: 6| Step: 13
Training loss: 1.6791114807128906
Validation loss: 2.0059710144996643

Epoch: 47| Step: 0
Training loss: 2.6327853202819824
Validation loss: 1.9826138416926067

Epoch: 6| Step: 1
Training loss: 2.064851760864258
Validation loss: 2.002197782198588

Epoch: 6| Step: 2
Training loss: 2.0622129440307617
Validation loss: 1.996155043443044

Epoch: 6| Step: 3
Training loss: 2.2686116695404053
Validation loss: 2.015484094619751

Epoch: 6| Step: 4
Training loss: 1.3783386945724487
Validation loss: 2.022344728310903

Epoch: 6| Step: 5
Training loss: 1.95542573928833
Validation loss: 2.019272486368815

Epoch: 6| Step: 6
Training loss: 2.029768466949463
Validation loss: 2.0035155216852822

Epoch: 6| Step: 7
Training loss: 1.8533337116241455
Validation loss: 1.995864709218343

Epoch: 6| Step: 8
Training loss: 2.071753740310669
Validation loss: 1.9951250751813252

Epoch: 6| Step: 9
Training loss: 1.761415719985962
Validation loss: 2.003748377164205

Epoch: 6| Step: 10
Training loss: 1.597266674041748
Validation loss: 1.99623304605484

Epoch: 6| Step: 11
Training loss: 1.5883901119232178
Validation loss: 1.9984032114346821

Epoch: 6| Step: 12
Training loss: 2.1223697662353516
Validation loss: 1.9808242321014404

Epoch: 6| Step: 13
Training loss: 1.2734402418136597
Validation loss: 2.011316239833832

Epoch: 48| Step: 0
Training loss: 1.8799431324005127
Validation loss: 2.0025470852851868

Epoch: 6| Step: 1
Training loss: 1.9085967540740967
Validation loss: 2.005745848019918

Epoch: 6| Step: 2
Training loss: 2.0433168411254883
Validation loss: 2.020264665285746

Epoch: 6| Step: 3
Training loss: 2.8887641429901123
Validation loss: 2.0068676471710205

Epoch: 6| Step: 4
Training loss: 1.8707642555236816
Validation loss: 2.000238279501597

Epoch: 6| Step: 5
Training loss: 2.0687103271484375
Validation loss: 2.0064467191696167

Epoch: 6| Step: 6
Training loss: 1.8376052379608154
Validation loss: 1.9971405267715454

Epoch: 6| Step: 7
Training loss: 1.5342220067977905
Validation loss: 2.015770177046458

Epoch: 6| Step: 8
Training loss: 1.9414806365966797
Validation loss: 2.001719295978546

Epoch: 6| Step: 9
Training loss: 2.1857447624206543
Validation loss: 2.020844558874766

Epoch: 6| Step: 10
Training loss: 1.430854320526123
Validation loss: 1.9914983908335369

Epoch: 6| Step: 11
Training loss: 1.4361430406570435
Validation loss: 1.9995129108428955

Epoch: 6| Step: 12
Training loss: 1.646933674812317
Validation loss: 1.9870633085568745

Epoch: 6| Step: 13
Training loss: 1.9335136413574219
Validation loss: 1.9818449417750041

Epoch: 49| Step: 0
Training loss: 1.5140689611434937
Validation loss: 2.0132727225621543

Epoch: 6| Step: 1
Training loss: 2.1848442554473877
Validation loss: 2.0150097409884133

Epoch: 6| Step: 2
Training loss: 1.8025181293487549
Validation loss: 2.009492019812266

Epoch: 6| Step: 3
Training loss: 1.8691033124923706
Validation loss: 2.0097762743631997

Epoch: 6| Step: 4
Training loss: 2.126727819442749
Validation loss: 2.019786993662516

Epoch: 6| Step: 5
Training loss: 1.5160393714904785
Validation loss: 2.0019986629486084

Epoch: 6| Step: 6
Training loss: 1.703816533088684
Validation loss: 2.0204543670018515

Epoch: 6| Step: 7
Training loss: 1.4772224426269531
Validation loss: 2.012734512488047

Epoch: 6| Step: 8
Training loss: 1.9404584169387817
Validation loss: 2.0459916591644287

Epoch: 6| Step: 9
Training loss: 1.2752323150634766
Validation loss: 2.0394957065582275

Epoch: 6| Step: 10
Training loss: 2.6612942218780518
Validation loss: 2.052199145158132

Epoch: 6| Step: 11
Training loss: 2.390018939971924
Validation loss: 2.0553079644838967

Epoch: 6| Step: 12
Training loss: 1.1913033723831177
Validation loss: 2.057437022527059

Epoch: 6| Step: 13
Training loss: 3.036200523376465
Validation loss: 2.0364776452382407

Epoch: 50| Step: 0
Training loss: 2.0722720623016357
Validation loss: 2.0262521505355835

Epoch: 6| Step: 1
Training loss: 1.4934827089309692
Validation loss: 2.0095990697542825

Epoch: 6| Step: 2
Training loss: 2.4770641326904297
Validation loss: 1.9841019908587139

Epoch: 6| Step: 3
Training loss: 1.802589774131775
Validation loss: 1.9999936819076538

Epoch: 6| Step: 4
Training loss: 1.6703805923461914
Validation loss: 1.9689120451609294

Epoch: 6| Step: 5
Training loss: 2.028557300567627
Validation loss: 1.9854231079419453

Epoch: 6| Step: 6
Training loss: 2.172968626022339
Validation loss: 1.976122538248698

Epoch: 6| Step: 7
Training loss: 1.500211477279663
Validation loss: 1.9692990978558857

Epoch: 6| Step: 8
Training loss: 1.9888724088668823
Validation loss: 1.9924814105033875

Epoch: 6| Step: 9
Training loss: 2.066260814666748
Validation loss: 2.024549901485443

Epoch: 6| Step: 10
Training loss: 2.419602632522583
Validation loss: 1.98195485273997

Epoch: 6| Step: 11
Training loss: 1.6239523887634277
Validation loss: 1.9868393143018086

Epoch: 6| Step: 12
Training loss: 2.1086039543151855
Validation loss: 1.9659738739331563

Epoch: 6| Step: 13
Training loss: 1.4050488471984863
Validation loss: 1.9821494619051616

Epoch: 51| Step: 0
Training loss: 2.7515816688537598
Validation loss: 1.991778552532196

Epoch: 6| Step: 1
Training loss: 1.8953580856323242
Validation loss: 2.0013928214708963

Epoch: 6| Step: 2
Training loss: 1.4467670917510986
Validation loss: 1.9891354044278462

Epoch: 6| Step: 3
Training loss: 1.8160688877105713
Validation loss: 1.9851710398991902

Epoch: 6| Step: 4
Training loss: 1.266827940940857
Validation loss: 2.0026828050613403

Epoch: 6| Step: 5
Training loss: 1.6912338733673096
Validation loss: 2.0168108344078064

Epoch: 6| Step: 6
Training loss: 1.8448529243469238
Validation loss: 2.0012512604395547

Epoch: 6| Step: 7
Training loss: 1.9276721477508545
Validation loss: 2.0136131048202515

Epoch: 6| Step: 8
Training loss: 2.20793080329895
Validation loss: 2.0300308068593345

Epoch: 6| Step: 9
Training loss: 1.4319539070129395
Validation loss: 2.047680695851644

Epoch: 6| Step: 10
Training loss: 2.3742575645446777
Validation loss: 2.0312794844309487

Epoch: 6| Step: 11
Training loss: 1.7586495876312256
Validation loss: 2.029869476954142

Epoch: 6| Step: 12
Training loss: 1.7531278133392334
Validation loss: 2.0597185492515564

Epoch: 6| Step: 13
Training loss: 2.1472928524017334
Validation loss: 2.06553852558136

Epoch: 52| Step: 0
Training loss: 1.3838218450546265
Validation loss: 2.042541186014811

Epoch: 6| Step: 1
Training loss: 1.826659917831421
Validation loss: 2.0385488073031106

Epoch: 6| Step: 2
Training loss: 2.0877442359924316
Validation loss: 2.018586536248525

Epoch: 6| Step: 3
Training loss: 2.386108160018921
Validation loss: 2.0185596545537314

Epoch: 6| Step: 4
Training loss: 1.3821629285812378
Validation loss: 2.0104495882987976

Epoch: 6| Step: 5
Training loss: 2.010728359222412
Validation loss: 2.000368595123291

Epoch: 6| Step: 6
Training loss: 1.8168801069259644
Validation loss: 1.9979846874872844

Epoch: 6| Step: 7
Training loss: 1.9153505563735962
Validation loss: 2.012600898742676

Epoch: 6| Step: 8
Training loss: 1.9508508443832397
Validation loss: 2.006792962551117

Epoch: 6| Step: 9
Training loss: 1.6590616703033447
Validation loss: 1.9917561213175456

Epoch: 6| Step: 10
Training loss: 2.127833843231201
Validation loss: 1.9822070995966594

Epoch: 6| Step: 11
Training loss: 2.16188383102417
Validation loss: 1.9763666192690532

Epoch: 6| Step: 12
Training loss: 1.5920624732971191
Validation loss: 1.984317163626353

Epoch: 6| Step: 13
Training loss: 2.0559239387512207
Validation loss: 1.991380472977956

Epoch: 53| Step: 0
Training loss: 2.0842528343200684
Validation loss: 1.9823978543281555

Epoch: 6| Step: 1
Training loss: 2.087324857711792
Validation loss: 2.009975850582123

Epoch: 6| Step: 2
Training loss: 1.8321415185928345
Validation loss: 1.9999833703041077

Epoch: 6| Step: 3
Training loss: 2.1466574668884277
Validation loss: 2.002715786298116

Epoch: 6| Step: 4
Training loss: 1.9331247806549072
Validation loss: 2.016834318637848

Epoch: 6| Step: 5
Training loss: 2.149831771850586
Validation loss: 1.9903186957041423

Epoch: 6| Step: 6
Training loss: 2.0847795009613037
Validation loss: 2.0078448057174683

Epoch: 6| Step: 7
Training loss: 2.24647855758667
Validation loss: 2.0060582160949707

Epoch: 6| Step: 8
Training loss: 1.1762596368789673
Validation loss: 2.0073757568995156

Epoch: 6| Step: 9
Training loss: 1.538888931274414
Validation loss: 1.988149642944336

Epoch: 6| Step: 10
Training loss: 1.9202969074249268
Validation loss: 2.0049427350362143

Epoch: 6| Step: 11
Training loss: 2.0533766746520996
Validation loss: 2.015250086784363

Epoch: 6| Step: 12
Training loss: 1.7902028560638428
Validation loss: 1.9991416931152344

Epoch: 6| Step: 13
Training loss: 1.4006197452545166
Validation loss: 1.987382709980011

Epoch: 54| Step: 0
Training loss: 2.485870599746704
Validation loss: 2.0239606698354087

Epoch: 6| Step: 1
Training loss: 1.6753458976745605
Validation loss: 2.0191696286201477

Epoch: 6| Step: 2
Training loss: 2.483417510986328
Validation loss: 2.0455737908681235

Epoch: 6| Step: 3
Training loss: 1.7748708724975586
Validation loss: 2.0145274003346763

Epoch: 6| Step: 4
Training loss: 2.0305728912353516
Validation loss: 2.00696470340093

Epoch: 6| Step: 5
Training loss: 1.6286462545394897
Validation loss: 2.0252229372660318

Epoch: 6| Step: 6
Training loss: 2.2523553371429443
Validation loss: 2.0308161775271096

Epoch: 6| Step: 7
Training loss: 1.4076530933380127
Validation loss: 2.0208048025767007

Epoch: 6| Step: 8
Training loss: 2.0049185752868652
Validation loss: 2.0388286312421164

Epoch: 6| Step: 9
Training loss: 2.2697014808654785
Validation loss: 2.0432703097661338

Epoch: 6| Step: 10
Training loss: 1.5438899993896484
Validation loss: 2.040831506252289

Epoch: 6| Step: 11
Training loss: 1.7816433906555176
Validation loss: 2.039060433705648

Epoch: 6| Step: 12
Training loss: 1.8217610120773315
Validation loss: 2.012220799922943

Epoch: 6| Step: 13
Training loss: 1.213161587715149
Validation loss: 1.9866014917691548

Epoch: 55| Step: 0
Training loss: 1.5893117189407349
Validation loss: 1.9995400706926982

Epoch: 6| Step: 1
Training loss: 1.6104254722595215
Validation loss: 1.975345214207967

Epoch: 6| Step: 2
Training loss: 2.001866340637207
Validation loss: 2.014540751775106

Epoch: 6| Step: 3
Training loss: 2.188486099243164
Validation loss: 2.0116156935691833

Epoch: 6| Step: 4
Training loss: 2.4783825874328613
Validation loss: 1.979422648747762

Epoch: 6| Step: 5
Training loss: 1.5028319358825684
Validation loss: 1.977670709292094

Epoch: 6| Step: 6
Training loss: 1.9526515007019043
Validation loss: 2.008415440718333

Epoch: 6| Step: 7
Training loss: 2.2894959449768066
Validation loss: 2.0041691859563193

Epoch: 6| Step: 8
Training loss: 2.2289609909057617
Validation loss: 2.0450704296429953

Epoch: 6| Step: 9
Training loss: 1.8413021564483643
Validation loss: 2.041138927141825

Epoch: 6| Step: 10
Training loss: 1.6712371110916138
Validation loss: 2.011845648288727

Epoch: 6| Step: 11
Training loss: 1.4107551574707031
Validation loss: 2.0135860244433084

Epoch: 6| Step: 12
Training loss: 2.323467254638672
Validation loss: 2.0136008858680725

Epoch: 6| Step: 13
Training loss: 1.4036731719970703
Validation loss: 2.0172756910324097

Epoch: 56| Step: 0
Training loss: 2.119051933288574
Validation loss: 2.014171600341797

Epoch: 6| Step: 1
Training loss: 1.9228911399841309
Validation loss: 2.023598035176595

Epoch: 6| Step: 2
Training loss: 1.5378673076629639
Validation loss: 2.007388095060984

Epoch: 6| Step: 3
Training loss: 1.998003602027893
Validation loss: 2.004040479660034

Epoch: 6| Step: 4
Training loss: 1.9135494232177734
Validation loss: 2.018024206161499

Epoch: 6| Step: 5
Training loss: 1.7297494411468506
Validation loss: 1.9976470867792766

Epoch: 6| Step: 6
Training loss: 2.0454461574554443
Validation loss: 1.9880515535672505

Epoch: 6| Step: 7
Training loss: 1.4329514503479004
Validation loss: 1.957103391488393

Epoch: 6| Step: 8
Training loss: 1.8089985847473145
Validation loss: 1.9946349263191223

Epoch: 6| Step: 9
Training loss: 1.9211177825927734
Validation loss: 1.982010841369629

Epoch: 6| Step: 10
Training loss: 1.8220596313476562
Validation loss: 1.9833786884943645

Epoch: 6| Step: 11
Training loss: 1.7643557786941528
Validation loss: 1.9842867056528728

Epoch: 6| Step: 12
Training loss: 1.927098035812378
Validation loss: 1.9924401640892029

Epoch: 6| Step: 13
Training loss: 2.4048287868499756
Validation loss: 2.004107197125753

Epoch: 57| Step: 0
Training loss: 2.2720789909362793
Validation loss: 1.9871679345766704

Epoch: 6| Step: 1
Training loss: 1.696828007698059
Validation loss: 1.975496808687846

Epoch: 6| Step: 2
Training loss: 1.943555235862732
Validation loss: 1.9916326403617859

Epoch: 6| Step: 3
Training loss: 1.46506667137146
Validation loss: 2.011962890625

Epoch: 6| Step: 4
Training loss: 2.097991704940796
Validation loss: 2.0268255472183228

Epoch: 6| Step: 5
Training loss: 1.9750310182571411
Validation loss: 2.004384179910024

Epoch: 6| Step: 6
Training loss: 1.8798284530639648
Validation loss: 2.0286106864611306

Epoch: 6| Step: 7
Training loss: 1.9768985509872437
Validation loss: 2.010942220687866

Epoch: 6| Step: 8
Training loss: 1.9559457302093506
Validation loss: 2.022071897983551

Epoch: 6| Step: 9
Training loss: 1.6133679151535034
Validation loss: 2.00888462861379

Epoch: 6| Step: 10
Training loss: 1.9403530359268188
Validation loss: 2.016323208808899

Epoch: 6| Step: 11
Training loss: 2.218411445617676
Validation loss: 1.9862223664919536

Epoch: 6| Step: 12
Training loss: 2.0005955696105957
Validation loss: 1.9988208214441936

Epoch: 6| Step: 13
Training loss: 1.3079168796539307
Validation loss: 1.9755334854125977

Epoch: 58| Step: 0
Training loss: 1.8394124507904053
Validation loss: 1.9882726271947224

Epoch: 6| Step: 1
Training loss: 1.145858645439148
Validation loss: 1.9937150080998738

Epoch: 6| Step: 2
Training loss: 2.407388210296631
Validation loss: 2.007978677749634

Epoch: 6| Step: 3
Training loss: 1.9004473686218262
Validation loss: 1.9936396479606628

Epoch: 6| Step: 4
Training loss: 1.9154081344604492
Validation loss: 1.9747601548830669

Epoch: 6| Step: 5
Training loss: 1.2765758037567139
Validation loss: 1.9737092057863872

Epoch: 6| Step: 6
Training loss: 2.020167112350464
Validation loss: 1.9849861860275269

Epoch: 6| Step: 7
Training loss: 2.036557674407959
Validation loss: 2.000150144100189

Epoch: 6| Step: 8
Training loss: 2.196268081665039
Validation loss: 1.9841578404108684

Epoch: 6| Step: 9
Training loss: 2.0244107246398926
Validation loss: 1.995250145594279

Epoch: 6| Step: 10
Training loss: 1.1881580352783203
Validation loss: 1.9862364133199055

Epoch: 6| Step: 11
Training loss: 2.1060733795166016
Validation loss: 2.00073113044103

Epoch: 6| Step: 12
Training loss: 1.9782482385635376
Validation loss: 2.018728574117025

Epoch: 6| Step: 13
Training loss: 1.9146925210952759
Validation loss: 1.9968206286430359

Epoch: 59| Step: 0
Training loss: 1.4092046022415161
Validation loss: 1.9875898162523906

Epoch: 6| Step: 1
Training loss: 1.7325148582458496
Validation loss: 2.0056018829345703

Epoch: 6| Step: 2
Training loss: 1.8181047439575195
Validation loss: 1.9995148181915283

Epoch: 6| Step: 3
Training loss: 1.6127740144729614
Validation loss: 2.015372375647227

Epoch: 6| Step: 4
Training loss: 2.520961284637451
Validation loss: 2.033734460671743

Epoch: 6| Step: 5
Training loss: 1.3559448719024658
Validation loss: 2.0409706234931946

Epoch: 6| Step: 6
Training loss: 1.6065409183502197
Validation loss: 2.0592702627182007

Epoch: 6| Step: 7
Training loss: 1.91721773147583
Validation loss: 2.052100718021393

Epoch: 6| Step: 8
Training loss: 2.591188669204712
Validation loss: 2.0296261509259543

Epoch: 6| Step: 9
Training loss: 1.8061039447784424
Validation loss: 2.0113417704900107

Epoch: 6| Step: 10
Training loss: 2.258756160736084
Validation loss: 2.0032901962598166

Epoch: 6| Step: 11
Training loss: 2.1208858489990234
Validation loss: 2.001075108846029

Epoch: 6| Step: 12
Training loss: 1.699257731437683
Validation loss: 1.992931028207143

Epoch: 6| Step: 13
Training loss: 1.5578529834747314
Validation loss: 1.994431495666504

Epoch: 60| Step: 0
Training loss: 2.2371044158935547
Validation loss: 1.979448934396108

Epoch: 6| Step: 1
Training loss: 1.9122092723846436
Validation loss: 1.9702105522155762

Epoch: 6| Step: 2
Training loss: 1.4583256244659424
Validation loss: 1.9817773699760437

Epoch: 6| Step: 3
Training loss: 1.5407943725585938
Validation loss: 1.9848777055740356

Epoch: 6| Step: 4
Training loss: 1.4380054473876953
Validation loss: 1.966270426909129

Epoch: 6| Step: 5
Training loss: 2.324357509613037
Validation loss: 1.9895302454630535

Epoch: 6| Step: 6
Training loss: 2.266639232635498
Validation loss: 1.9939357837041218

Epoch: 6| Step: 7
Training loss: 1.5900402069091797
Validation loss: 1.9745009144147236

Epoch: 6| Step: 8
Training loss: 2.232022285461426
Validation loss: 1.9863881866137187

Epoch: 6| Step: 9
Training loss: 2.1050546169281006
Validation loss: 1.991944928963979

Epoch: 6| Step: 10
Training loss: 1.5374594926834106
Validation loss: 1.9889985124270122

Epoch: 6| Step: 11
Training loss: 1.7645642757415771
Validation loss: 1.9942794839541118

Epoch: 6| Step: 12
Training loss: 2.0328710079193115
Validation loss: 1.9935620625813801

Epoch: 6| Step: 13
Training loss: 1.56399405002594
Validation loss: 2.0016906460126243

Epoch: 61| Step: 0
Training loss: 1.5056203603744507
Validation loss: 2.0058119694391885

Epoch: 6| Step: 1
Training loss: 1.9841537475585938
Validation loss: 2.0258629322052

Epoch: 6| Step: 2
Training loss: 2.212818145751953
Validation loss: 2.0270681579907737

Epoch: 6| Step: 3
Training loss: 2.391676664352417
Validation loss: 2.0381189584732056

Epoch: 6| Step: 4
Training loss: 1.68949294090271
Validation loss: 2.0292968153953552

Epoch: 6| Step: 5
Training loss: 1.379831075668335
Validation loss: 2.054057538509369

Epoch: 6| Step: 6
Training loss: 2.343320369720459
Validation loss: 2.041011929512024

Epoch: 6| Step: 7
Training loss: 1.6652259826660156
Validation loss: 2.0324833393096924

Epoch: 6| Step: 8
Training loss: 1.0698301792144775
Validation loss: 2.0390478372573853

Epoch: 6| Step: 9
Training loss: 2.149020195007324
Validation loss: 2.0316667556762695

Epoch: 6| Step: 10
Training loss: 2.2555465698242188
Validation loss: 2.0115582942962646

Epoch: 6| Step: 11
Training loss: 1.8642761707305908
Validation loss: 2.011922279993693

Epoch: 6| Step: 12
Training loss: 2.3339788913726807
Validation loss: 1.999818742275238

Epoch: 6| Step: 13
Training loss: 1.3088946342468262
Validation loss: 1.9910411834716797

Epoch: 62| Step: 0
Training loss: 2.179295063018799
Validation loss: 1.9675650199254353

Epoch: 6| Step: 1
Training loss: 1.2116615772247314
Validation loss: 1.977033833662669

Epoch: 6| Step: 2
Training loss: 2.0328636169433594
Validation loss: 1.9871789614359539

Epoch: 6| Step: 3
Training loss: 1.1508276462554932
Validation loss: 1.9578192631403606

Epoch: 6| Step: 4
Training loss: 1.0034781694412231
Validation loss: 1.9694920976956685

Epoch: 6| Step: 5
Training loss: 1.6968836784362793
Validation loss: 1.9796377420425415

Epoch: 6| Step: 6
Training loss: 1.4947365522384644
Validation loss: 2.0198632081349692

Epoch: 6| Step: 7
Training loss: 1.7869735956192017
Validation loss: 2.0480332374572754

Epoch: 6| Step: 8
Training loss: 2.4850873947143555
Validation loss: 2.029939293861389

Epoch: 6| Step: 9
Training loss: 3.0600743293762207
Validation loss: 2.047082265218099

Epoch: 6| Step: 10
Training loss: 1.5277819633483887
Validation loss: 2.0479273796081543

Epoch: 6| Step: 11
Training loss: 2.054983139038086
Validation loss: 2.068967878818512

Epoch: 6| Step: 12
Training loss: 2.3228237628936768
Validation loss: 2.099343220392863

Epoch: 6| Step: 13
Training loss: 2.0013084411621094
Validation loss: 2.079138537247976

Epoch: 63| Step: 0
Training loss: 1.2098157405853271
Validation loss: 2.0868860681851706

Epoch: 6| Step: 1
Training loss: 1.59001886844635
Validation loss: 2.0903990467389426

Epoch: 6| Step: 2
Training loss: 2.4639527797698975
Validation loss: 2.0670285820961

Epoch: 6| Step: 3
Training loss: 1.9578416347503662
Validation loss: 2.0335449973742166

Epoch: 6| Step: 4
Training loss: 1.8371690511703491
Validation loss: 1.9906950394312541

Epoch: 6| Step: 5
Training loss: 1.8826069831848145
Validation loss: 2.0175265272458396

Epoch: 6| Step: 6
Training loss: 1.4088330268859863
Validation loss: 2.0001514752705893

Epoch: 6| Step: 7
Training loss: 1.693644642829895
Validation loss: 1.9916690985361736

Epoch: 6| Step: 8
Training loss: 1.9387273788452148
Validation loss: 1.9913392663002014

Epoch: 6| Step: 9
Training loss: 1.6175363063812256
Validation loss: 1.9831340114275615

Epoch: 6| Step: 10
Training loss: 1.2233960628509521
Validation loss: 1.9643749594688416

Epoch: 6| Step: 11
Training loss: 2.1394896507263184
Validation loss: 1.9937086701393127

Epoch: 6| Step: 12
Training loss: 2.3360071182250977
Validation loss: 2.0049728751182556

Epoch: 6| Step: 13
Training loss: 2.400696277618408
Validation loss: 1.9911677837371826

Epoch: 64| Step: 0
Training loss: 1.7806310653686523
Validation loss: 1.9853626092274983

Epoch: 6| Step: 1
Training loss: 1.7000945806503296
Validation loss: 1.9910117586453755

Epoch: 6| Step: 2
Training loss: 1.5383481979370117
Validation loss: 2.0036588509877524

Epoch: 6| Step: 3
Training loss: 1.806308388710022
Validation loss: 1.9966854254404705

Epoch: 6| Step: 4
Training loss: 1.9194731712341309
Validation loss: 2.003121316432953

Epoch: 6| Step: 5
Training loss: 1.594102144241333
Validation loss: 2.005761961142222

Epoch: 6| Step: 6
Training loss: 1.984196662902832
Validation loss: 1.9978569348653157

Epoch: 6| Step: 7
Training loss: 2.20282244682312
Validation loss: 2.0071284770965576

Epoch: 6| Step: 8
Training loss: 1.6180195808410645
Validation loss: 1.995769460995992

Epoch: 6| Step: 9
Training loss: 1.80997633934021
Validation loss: 1.9887076020240784

Epoch: 6| Step: 10
Training loss: 1.9595088958740234
Validation loss: 1.992453356583913

Epoch: 6| Step: 11
Training loss: 1.4159069061279297
Validation loss: 2.022044519583384

Epoch: 6| Step: 12
Training loss: 1.8871104717254639
Validation loss: 1.9859282573064168

Epoch: 6| Step: 13
Training loss: 2.424065113067627
Validation loss: 2.026938498020172

Epoch: 65| Step: 0
Training loss: 2.2996273040771484
Validation loss: 1.9704030950864155

Epoch: 6| Step: 1
Training loss: 2.3522214889526367
Validation loss: 2.0256523489952087

Epoch: 6| Step: 2
Training loss: 2.1824052333831787
Validation loss: 2.0132294495900473

Epoch: 6| Step: 3
Training loss: 1.9649018049240112
Validation loss: 1.9975983301798503

Epoch: 6| Step: 4
Training loss: 1.0295255184173584
Validation loss: 1.9875076810518901

Epoch: 6| Step: 5
Training loss: 2.1022889614105225
Validation loss: 1.9975903232892354

Epoch: 6| Step: 6
Training loss: 1.9292957782745361
Validation loss: 1.9947835206985474

Epoch: 6| Step: 7
Training loss: 2.160592555999756
Validation loss: 2.0073096553484597

Epoch: 6| Step: 8
Training loss: 1.4893896579742432
Validation loss: 2.0171581705411277

Epoch: 6| Step: 9
Training loss: 1.7461864948272705
Validation loss: 2.003401776154836

Epoch: 6| Step: 10
Training loss: 1.6086623668670654
Validation loss: 1.9975757598876953

Epoch: 6| Step: 11
Training loss: 1.2802928686141968
Validation loss: 1.971717099348704

Epoch: 6| Step: 12
Training loss: 1.3366118669509888
Validation loss: 1.9878244201342266

Epoch: 6| Step: 13
Training loss: 2.0135724544525146
Validation loss: 1.99370938539505

Epoch: 66| Step: 0
Training loss: 2.66696834564209
Validation loss: 1.9997647007306416

Epoch: 6| Step: 1
Training loss: 1.9811216592788696
Validation loss: 1.9893949627876282

Epoch: 6| Step: 2
Training loss: 2.0343496799468994
Validation loss: 1.9697296420733135

Epoch: 6| Step: 3
Training loss: 1.8146419525146484
Validation loss: 2.0119961897532144

Epoch: 6| Step: 4
Training loss: 1.5227911472320557
Validation loss: 1.9843261043230693

Epoch: 6| Step: 5
Training loss: 1.5112102031707764
Validation loss: 2.010935286680857

Epoch: 6| Step: 6
Training loss: 1.7738003730773926
Validation loss: 1.98611052831014

Epoch: 6| Step: 7
Training loss: 2.1415891647338867
Validation loss: 2.009945889314016

Epoch: 6| Step: 8
Training loss: 1.6166133880615234
Validation loss: 2.0051240722338357

Epoch: 6| Step: 9
Training loss: 1.4598171710968018
Validation loss: 2.036659300327301

Epoch: 6| Step: 10
Training loss: 1.98282790184021
Validation loss: 2.0206135710080466

Epoch: 6| Step: 11
Training loss: 1.3896982669830322
Validation loss: 2.0220751563707986

Epoch: 6| Step: 12
Training loss: 2.2612950801849365
Validation loss: 2.0480569998423257

Epoch: 6| Step: 13
Training loss: 1.4855449199676514
Validation loss: 2.0297727386156716

Epoch: 67| Step: 0
Training loss: 1.7833935022354126
Validation loss: 2.031268755594889

Epoch: 6| Step: 1
Training loss: 1.6199204921722412
Validation loss: 2.023236095905304

Epoch: 6| Step: 2
Training loss: 1.3764110803604126
Validation loss: 2.017720023790995

Epoch: 6| Step: 3
Training loss: 2.1152572631835938
Validation loss: 2.0213568806648254

Epoch: 6| Step: 4
Training loss: 2.125502586364746
Validation loss: 2.0070318380991616

Epoch: 6| Step: 5
Training loss: 1.9908759593963623
Validation loss: 2.0060261289278665

Epoch: 6| Step: 6
Training loss: 2.1998674869537354
Validation loss: 1.9977190891901653

Epoch: 6| Step: 7
Training loss: 1.8541547060012817
Validation loss: 1.9723812540372212

Epoch: 6| Step: 8
Training loss: 1.7142105102539062
Validation loss: 1.9907461802164714

Epoch: 6| Step: 9
Training loss: 2.069680690765381
Validation loss: 1.9907894531885784

Epoch: 6| Step: 10
Training loss: 1.7868008613586426
Validation loss: 1.9740888476371765

Epoch: 6| Step: 11
Training loss: 2.147404193878174
Validation loss: 1.9666614135106404

Epoch: 6| Step: 12
Training loss: 1.478560447692871
Validation loss: 1.9824344515800476

Epoch: 6| Step: 13
Training loss: 1.1205110549926758
Validation loss: 1.9835826357205708

Epoch: 68| Step: 0
Training loss: 1.304740071296692
Validation loss: 1.995667298634847

Epoch: 6| Step: 1
Training loss: 1.9570955038070679
Validation loss: 2.0198253194491067

Epoch: 6| Step: 2
Training loss: 1.362364411354065
Validation loss: 2.016436298688253

Epoch: 6| Step: 3
Training loss: 1.893515944480896
Validation loss: 2.0418772300084433

Epoch: 6| Step: 4
Training loss: 1.258737325668335
Validation loss: 2.0347546537717185

Epoch: 6| Step: 5
Training loss: 2.0477895736694336
Validation loss: 2.085772752761841

Epoch: 6| Step: 6
Training loss: 1.600113868713379
Validation loss: 2.1146461963653564

Epoch: 6| Step: 7
Training loss: 2.130939483642578
Validation loss: 2.0922080278396606

Epoch: 6| Step: 8
Training loss: 2.2094993591308594
Validation loss: 2.072292923927307

Epoch: 6| Step: 9
Training loss: 1.4079668521881104
Validation loss: 2.0373715360959372

Epoch: 6| Step: 10
Training loss: 2.786398410797119
Validation loss: 2.0427135229110718

Epoch: 6| Step: 11
Training loss: 1.929047703742981
Validation loss: 2.0118032495180764

Epoch: 6| Step: 12
Training loss: 2.062505006790161
Validation loss: 1.9941289226214092

Epoch: 6| Step: 13
Training loss: 1.8036068677902222
Validation loss: 1.9958659807840984

Epoch: 69| Step: 0
Training loss: 2.0591158866882324
Validation loss: 1.9858689904212952

Epoch: 6| Step: 1
Training loss: 2.154609441757202
Validation loss: 1.9958001573880513

Epoch: 6| Step: 2
Training loss: 2.183513641357422
Validation loss: 1.9679957032203674

Epoch: 6| Step: 3
Training loss: 1.7380599975585938
Validation loss: 2.0110748410224915

Epoch: 6| Step: 4
Training loss: 1.6748900413513184
Validation loss: 2.0085503458976746

Epoch: 6| Step: 5
Training loss: 1.981661319732666
Validation loss: 1.9708655675252278

Epoch: 6| Step: 6
Training loss: 1.865535020828247
Validation loss: 1.982686718304952

Epoch: 6| Step: 7
Training loss: 1.6438707113265991
Validation loss: 1.9938492178916931

Epoch: 6| Step: 8
Training loss: 1.9012048244476318
Validation loss: 1.9749001860618591

Epoch: 6| Step: 9
Training loss: 1.338430643081665
Validation loss: 1.9656365712483723

Epoch: 6| Step: 10
Training loss: 1.8737990856170654
Validation loss: 1.9910200436909993

Epoch: 6| Step: 11
Training loss: 1.8379669189453125
Validation loss: 2.0108895500501

Epoch: 6| Step: 12
Training loss: 1.2192456722259521
Validation loss: 2.032078186670939

Epoch: 6| Step: 13
Training loss: 1.9512324333190918
Validation loss: 2.0569226344426474

Epoch: 70| Step: 0
Training loss: 1.217968463897705
Validation loss: 2.0681805411974588

Epoch: 6| Step: 1
Training loss: 1.5423672199249268
Validation loss: 2.0809030334154763

Epoch: 6| Step: 2
Training loss: 1.6983269453048706
Validation loss: 2.099727193514506

Epoch: 6| Step: 3
Training loss: 1.8665531873703003
Validation loss: 2.1343657970428467

Epoch: 6| Step: 4
Training loss: 1.8255383968353271
Validation loss: 2.10303795337677

Epoch: 6| Step: 5
Training loss: 1.884478211402893
Validation loss: 2.096298118432363

Epoch: 6| Step: 6
Training loss: 1.3452993631362915
Validation loss: 2.0864917834599814

Epoch: 6| Step: 7
Training loss: 2.521303653717041
Validation loss: 2.0522752602895102

Epoch: 6| Step: 8
Training loss: 1.7172372341156006
Validation loss: 2.0400898257891336

Epoch: 6| Step: 9
Training loss: 2.4482150077819824
Validation loss: 2.019641896088918

Epoch: 6| Step: 10
Training loss: 1.565413475036621
Validation loss: 1.9727333784103394

Epoch: 6| Step: 11
Training loss: 1.7102152109146118
Validation loss: 1.999361236890157

Epoch: 6| Step: 12
Training loss: 2.1608386039733887
Validation loss: 1.9922725955645244

Epoch: 6| Step: 13
Training loss: 1.8187434673309326
Validation loss: 1.9985364476839702

Epoch: 71| Step: 0
Training loss: 1.788711667060852
Validation loss: 2.0008299350738525

Epoch: 6| Step: 1
Training loss: 2.3856210708618164
Validation loss: 1.9895307421684265

Epoch: 6| Step: 2
Training loss: 1.5829585790634155
Validation loss: 2.0014687379201255

Epoch: 6| Step: 3
Training loss: 2.193206548690796
Validation loss: 1.9885420401891072

Epoch: 6| Step: 4
Training loss: 1.5052366256713867
Validation loss: 1.9826536178588867

Epoch: 6| Step: 5
Training loss: 1.9108672142028809
Validation loss: 1.9974337220191956

Epoch: 6| Step: 6
Training loss: 1.7886393070220947
Validation loss: 2.010587692260742

Epoch: 6| Step: 7
Training loss: 1.1818212270736694
Validation loss: 2.0369191765785217

Epoch: 6| Step: 8
Training loss: 1.9731521606445312
Validation loss: 2.020094414552053

Epoch: 6| Step: 9
Training loss: 1.4179699420928955
Validation loss: 2.0272294680277505

Epoch: 6| Step: 10
Training loss: 1.647573709487915
Validation loss: 2.040397306283315

Epoch: 6| Step: 11
Training loss: 2.1532583236694336
Validation loss: 2.032050132751465

Epoch: 6| Step: 12
Training loss: 1.832958459854126
Validation loss: 2.0447278221448264

Epoch: 6| Step: 13
Training loss: 2.0075933933258057
Validation loss: 2.055631697177887

Epoch: 72| Step: 0
Training loss: 1.4291950464248657
Validation loss: 2.0495211283365884

Epoch: 6| Step: 1
Training loss: 1.6690860986709595
Validation loss: 2.046180307865143

Epoch: 6| Step: 2
Training loss: 1.7846788167953491
Validation loss: 2.0367191632588706

Epoch: 6| Step: 3
Training loss: 1.7189944982528687
Validation loss: 2.022815386454264

Epoch: 6| Step: 4
Training loss: 1.9249242544174194
Validation loss: 2.021049757798513

Epoch: 6| Step: 5
Training loss: 1.6233729124069214
Validation loss: 2.0369161566098533

Epoch: 6| Step: 6
Training loss: 1.6911497116088867
Validation loss: 2.0447755257288613

Epoch: 6| Step: 7
Training loss: 1.8630146980285645
Validation loss: 2.036509891351064

Epoch: 6| Step: 8
Training loss: 1.5139907598495483
Validation loss: 2.0280240376790366

Epoch: 6| Step: 9
Training loss: 1.472442626953125
Validation loss: 2.010805288950602

Epoch: 6| Step: 10
Training loss: 2.257401466369629
Validation loss: 1.983901063601176

Epoch: 6| Step: 11
Training loss: 1.999102234840393
Validation loss: 2.001607080300649

Epoch: 6| Step: 12
Training loss: 2.055894374847412
Validation loss: 1.9959652026494343

Epoch: 6| Step: 13
Training loss: 1.9642479419708252
Validation loss: 1.9947011073430378

Epoch: 73| Step: 0
Training loss: 2.0244319438934326
Validation loss: 1.991777817408244

Epoch: 6| Step: 1
Training loss: 2.1794800758361816
Validation loss: 2.000923732916514

Epoch: 6| Step: 2
Training loss: 2.6230123043060303
Validation loss: 2.0065504908561707

Epoch: 6| Step: 3
Training loss: 1.5504266023635864
Validation loss: 2.001743197441101

Epoch: 6| Step: 4
Training loss: 1.7443156242370605
Validation loss: 1.97946830590566

Epoch: 6| Step: 5
Training loss: 1.267514944076538
Validation loss: 2.0034213860829673

Epoch: 6| Step: 6
Training loss: 1.8365498781204224
Validation loss: 1.9788905183474224

Epoch: 6| Step: 7
Training loss: 1.401630163192749
Validation loss: 1.9911442001660664

Epoch: 6| Step: 8
Training loss: 1.8960492610931396
Validation loss: 1.9788931608200073

Epoch: 6| Step: 9
Training loss: 1.117997169494629
Validation loss: 2.0046282013257346

Epoch: 6| Step: 10
Training loss: 1.9902045726776123
Validation loss: 2.014852225780487

Epoch: 6| Step: 11
Training loss: 1.2114812135696411
Validation loss: 2.0331209301948547

Epoch: 6| Step: 12
Training loss: 2.135831117630005
Validation loss: 2.0246240496635437

Epoch: 6| Step: 13
Training loss: 1.8466194868087769
Validation loss: 2.0458250443140664

Epoch: 74| Step: 0
Training loss: 1.8742302656173706
Validation loss: 2.0491241614023843

Epoch: 6| Step: 1
Training loss: 1.5201900005340576
Validation loss: 2.0591933329900107

Epoch: 6| Step: 2
Training loss: 1.7882030010223389
Validation loss: 2.0381658474604287

Epoch: 6| Step: 3
Training loss: 1.8671754598617554
Validation loss: 2.010704517364502

Epoch: 6| Step: 4
Training loss: 1.5792219638824463
Validation loss: 2.028348684310913

Epoch: 6| Step: 5
Training loss: 1.7097434997558594
Validation loss: 2.0256922443707785

Epoch: 6| Step: 6
Training loss: 1.4942125082015991
Validation loss: 2.0159448981285095

Epoch: 6| Step: 7
Training loss: 1.641777753829956
Validation loss: 2.033279081185659

Epoch: 6| Step: 8
Training loss: 2.2964868545532227
Validation loss: 2.0299247105916343

Epoch: 6| Step: 9
Training loss: 1.4641878604888916
Validation loss: 2.0365283091863

Epoch: 6| Step: 10
Training loss: 1.7703200578689575
Validation loss: 2.032170057296753

Epoch: 6| Step: 11
Training loss: 2.0610766410827637
Validation loss: 2.0150139331817627

Epoch: 6| Step: 12
Training loss: 1.5229436159133911
Validation loss: 1.9963680704434712

Epoch: 6| Step: 13
Training loss: 2.068636417388916
Validation loss: 1.9961036841074626

Epoch: 75| Step: 0
Training loss: 1.506481647491455
Validation loss: 1.9734266599019368

Epoch: 6| Step: 1
Training loss: 2.055020809173584
Validation loss: 1.979868511358897

Epoch: 6| Step: 2
Training loss: 1.2513508796691895
Validation loss: 1.98847629626592

Epoch: 6| Step: 3
Training loss: 1.9102541208267212
Validation loss: 1.9951491554578145

Epoch: 6| Step: 4
Training loss: 2.405043601989746
Validation loss: 1.9990457097689311

Epoch: 6| Step: 5
Training loss: 1.5697524547576904
Validation loss: 1.995905915896098

Epoch: 6| Step: 6
Training loss: 1.8466148376464844
Validation loss: 1.9801071683565776

Epoch: 6| Step: 7
Training loss: 1.4701745510101318
Validation loss: 2.0051929553349814

Epoch: 6| Step: 8
Training loss: 1.557221531867981
Validation loss: 2.020128846168518

Epoch: 6| Step: 9
Training loss: 2.048297882080078
Validation loss: 2.0454294681549072

Epoch: 6| Step: 10
Training loss: 1.5138015747070312
Validation loss: 2.034282922744751

Epoch: 6| Step: 11
Training loss: 1.6171847581863403
Validation loss: 2.0218228300412497

Epoch: 6| Step: 12
Training loss: 1.8080723285675049
Validation loss: 2.057660927375158

Epoch: 6| Step: 13
Training loss: 2.174394130706787
Validation loss: 2.068132241566976

Epoch: 76| Step: 0
Training loss: 2.026872396469116
Validation loss: 2.059041142463684

Epoch: 6| Step: 1
Training loss: 1.7543542385101318
Validation loss: 2.056455592314402

Epoch: 6| Step: 2
Training loss: 1.3486360311508179
Validation loss: 2.0308053692181907

Epoch: 6| Step: 3
Training loss: 1.863358497619629
Validation loss: 2.01343842347463

Epoch: 6| Step: 4
Training loss: 2.3269035816192627
Validation loss: 2.032630463441213

Epoch: 6| Step: 5
Training loss: 1.74770987033844
Validation loss: 2.025756319363912

Epoch: 6| Step: 6
Training loss: 1.1680498123168945
Validation loss: 2.0138808488845825

Epoch: 6| Step: 7
Training loss: 2.2995834350585938
Validation loss: 2.0131141543388367

Epoch: 6| Step: 8
Training loss: 1.2925033569335938
Validation loss: 1.9871524969736736

Epoch: 6| Step: 9
Training loss: 2.115473747253418
Validation loss: 1.97845725218455

Epoch: 6| Step: 10
Training loss: 2.196711778640747
Validation loss: 2.0038743813832602

Epoch: 6| Step: 11
Training loss: 1.4639105796813965
Validation loss: 1.9815203348795574

Epoch: 6| Step: 12
Training loss: 1.7001304626464844
Validation loss: 2.017081876595815

Epoch: 6| Step: 13
Training loss: 1.3025171756744385
Validation loss: 2.0137863556543985

Epoch: 77| Step: 0
Training loss: 1.5837448835372925
Validation loss: 2.0242454608281455

Epoch: 6| Step: 1
Training loss: 1.1746056079864502
Validation loss: 2.0256025791168213

Epoch: 6| Step: 2
Training loss: 1.3790040016174316
Validation loss: 2.020457684993744

Epoch: 6| Step: 3
Training loss: 1.7883236408233643
Validation loss: 2.0412663221359253

Epoch: 6| Step: 4
Training loss: 1.9173290729522705
Validation loss: 2.035987377166748

Epoch: 6| Step: 5
Training loss: 2.111773729324341
Validation loss: 2.048304319381714

Epoch: 6| Step: 6
Training loss: 2.0454511642456055
Validation loss: 2.0277167161305747

Epoch: 6| Step: 7
Training loss: 1.9831668138504028
Validation loss: 2.015787581602732

Epoch: 6| Step: 8
Training loss: 1.7662947177886963
Validation loss: 2.0359593828519187

Epoch: 6| Step: 9
Training loss: 2.205629825592041
Validation loss: 2.020896037419637

Epoch: 6| Step: 10
Training loss: 1.9548523426055908
Validation loss: 2.0117308497428894

Epoch: 6| Step: 11
Training loss: 1.4597752094268799
Validation loss: 1.9924796024958293

Epoch: 6| Step: 12
Training loss: 1.7280914783477783
Validation loss: 2.02327698469162

Epoch: 6| Step: 13
Training loss: 1.4308233261108398
Validation loss: 1.9884055852890015

Epoch: 78| Step: 0
Training loss: 1.6793599128723145
Validation loss: 1.9983127514521282

Epoch: 6| Step: 1
Training loss: 1.693411946296692
Validation loss: 2.005022406578064

Epoch: 6| Step: 2
Training loss: 1.400773525238037
Validation loss: 1.9962336619695027

Epoch: 6| Step: 3
Training loss: 1.7291779518127441
Validation loss: 2.0108959078788757

Epoch: 6| Step: 4
Training loss: 1.288418173789978
Validation loss: 2.009808878103892

Epoch: 6| Step: 5
Training loss: 1.9975024461746216
Validation loss: 2.020067512989044

Epoch: 6| Step: 6
Training loss: 1.0092837810516357
Validation loss: 2.0191282828648887

Epoch: 6| Step: 7
Training loss: 1.8578519821166992
Validation loss: 2.0140206615130105

Epoch: 6| Step: 8
Training loss: 1.3370254039764404
Validation loss: 2.0075178941090903

Epoch: 6| Step: 9
Training loss: 1.9408831596374512
Validation loss: 2.020105520884196

Epoch: 6| Step: 10
Training loss: 2.3938021659851074
Validation loss: 2.0313182274500527

Epoch: 6| Step: 11
Training loss: 1.8787654638290405
Validation loss: 2.0403265754381814

Epoch: 6| Step: 12
Training loss: 1.9804959297180176
Validation loss: 2.0346240798632302

Epoch: 6| Step: 13
Training loss: 2.5725948810577393
Validation loss: 2.0705092350641885

Epoch: 79| Step: 0
Training loss: 2.499422073364258
Validation loss: 2.055628716945648

Epoch: 6| Step: 1
Training loss: 1.5410234928131104
Validation loss: 2.037637492020925

Epoch: 6| Step: 2
Training loss: 1.3042315244674683
Validation loss: 2.0209161043167114

Epoch: 6| Step: 3
Training loss: 1.4023640155792236
Validation loss: 2.0090349316596985

Epoch: 6| Step: 4
Training loss: 1.186408519744873
Validation loss: 2.014871140321096

Epoch: 6| Step: 5
Training loss: 2.416029453277588
Validation loss: 2.0013710061709085

Epoch: 6| Step: 6
Training loss: 1.7029201984405518
Validation loss: 2.007170557975769

Epoch: 6| Step: 7
Training loss: 1.1453852653503418
Validation loss: 2.024369716644287

Epoch: 6| Step: 8
Training loss: 1.555293321609497
Validation loss: 1.9870105385780334

Epoch: 6| Step: 9
Training loss: 1.5361735820770264
Validation loss: 2.002531905968984

Epoch: 6| Step: 10
Training loss: 2.256030321121216
Validation loss: 1.9981342355410259

Epoch: 6| Step: 11
Training loss: 1.6267956495285034
Validation loss: 1.997465709845225

Epoch: 6| Step: 12
Training loss: 2.125331163406372
Validation loss: 1.9833781123161316

Epoch: 6| Step: 13
Training loss: 2.1096346378326416
Validation loss: 1.994433303674062

Epoch: 80| Step: 0
Training loss: 1.7577346563339233
Validation loss: 1.9918973445892334

Epoch: 6| Step: 1
Training loss: 1.080454707145691
Validation loss: 1.9981937011082966

Epoch: 6| Step: 2
Training loss: 2.053884983062744
Validation loss: 1.9864244659741719

Epoch: 6| Step: 3
Training loss: 1.9809166193008423
Validation loss: 2.0091211398442588

Epoch: 6| Step: 4
Training loss: 1.7206264734268188
Validation loss: 2.021688401699066

Epoch: 6| Step: 5
Training loss: 1.6946274042129517
Validation loss: 2.035371780395508

Epoch: 6| Step: 6
Training loss: 1.0719937086105347
Validation loss: 2.019498606522878

Epoch: 6| Step: 7
Training loss: 1.5773576498031616
Validation loss: 2.0318149526913962

Epoch: 6| Step: 8
Training loss: 1.6952476501464844
Validation loss: 2.0115568240483603

Epoch: 6| Step: 9
Training loss: 1.6037548780441284
Validation loss: 2.0371121168136597

Epoch: 6| Step: 10
Training loss: 1.7361313104629517
Validation loss: 2.0345410108566284

Epoch: 6| Step: 11
Training loss: 1.6705422401428223
Validation loss: 2.057421704133352

Epoch: 6| Step: 12
Training loss: 2.4356260299682617
Validation loss: 2.0424797932306924

Epoch: 6| Step: 13
Training loss: 1.9584059715270996
Validation loss: 2.0283925930658975

Epoch: 81| Step: 0
Training loss: 1.460723638534546
Validation loss: 2.024329404036204

Epoch: 6| Step: 1
Training loss: 1.8311583995819092
Validation loss: 2.015345056851705

Epoch: 6| Step: 2
Training loss: 1.370333194732666
Validation loss: 2.0064940055211387

Epoch: 6| Step: 3
Training loss: 1.3159170150756836
Validation loss: 2.022459864616394

Epoch: 6| Step: 4
Training loss: 1.6961398124694824
Validation loss: 2.000834842522939

Epoch: 6| Step: 5
Training loss: 1.752515435218811
Validation loss: 1.9784131050109863

Epoch: 6| Step: 6
Training loss: 1.538365364074707
Validation loss: 1.9889759222666423

Epoch: 6| Step: 7
Training loss: 1.727458119392395
Validation loss: 2.0165575544039407

Epoch: 6| Step: 8
Training loss: 1.437469482421875
Validation loss: 2.0040605068206787

Epoch: 6| Step: 9
Training loss: 2.0359129905700684
Validation loss: 2.0500229001045227

Epoch: 6| Step: 10
Training loss: 2.230269432067871
Validation loss: 2.029535710811615

Epoch: 6| Step: 11
Training loss: 2.18630313873291
Validation loss: 2.002439260482788

Epoch: 6| Step: 12
Training loss: 1.8241822719573975
Validation loss: 2.0116770267486572

Epoch: 6| Step: 13
Training loss: 1.9445362091064453
Validation loss: 2.0313040614128113

Epoch: 82| Step: 0
Training loss: 1.908141016960144
Validation loss: 2.0172978043556213

Epoch: 6| Step: 1
Training loss: 2.1209022998809814
Validation loss: 1.994093398253123

Epoch: 6| Step: 2
Training loss: 1.542881965637207
Validation loss: 2.0109885136286416

Epoch: 6| Step: 3
Training loss: 1.3199493885040283
Validation loss: 1.9964967370033264

Epoch: 6| Step: 4
Training loss: 2.0396437644958496
Validation loss: 2.0240993102391562

Epoch: 6| Step: 5
Training loss: 1.3780279159545898
Validation loss: 2.0173296133677163

Epoch: 6| Step: 6
Training loss: 1.6184309720993042
Validation loss: 2.030185560385386

Epoch: 6| Step: 7
Training loss: 1.9732921123504639
Validation loss: 2.0092857281366983

Epoch: 6| Step: 8
Training loss: 0.9661364555358887
Validation loss: 2.0144986112912497

Epoch: 6| Step: 9
Training loss: 1.908727765083313
Validation loss: 2.0406116445859275

Epoch: 6| Step: 10
Training loss: 1.9331690073013306
Validation loss: 2.02275158961614

Epoch: 6| Step: 11
Training loss: 1.7738651037216187
Validation loss: 2.078611592451731

Epoch: 6| Step: 12
Training loss: 2.0425972938537598
Validation loss: 2.0563358465830484

Epoch: 6| Step: 13
Training loss: 1.6204603910446167
Validation loss: 2.054753045241038

Epoch: 83| Step: 0
Training loss: 1.4342812299728394
Validation loss: 2.067889908949534

Epoch: 6| Step: 1
Training loss: 1.6983091831207275
Validation loss: 2.0642864306767783

Epoch: 6| Step: 2
Training loss: 2.015247344970703
Validation loss: 2.059329390525818

Epoch: 6| Step: 3
Training loss: 1.6826220750808716
Validation loss: 2.025076985359192

Epoch: 6| Step: 4
Training loss: 1.4714782238006592
Validation loss: 2.0281457702318826

Epoch: 6| Step: 5
Training loss: 0.9832562804222107
Validation loss: 2.0356112718582153

Epoch: 6| Step: 6
Training loss: 1.5111005306243896
Validation loss: 2.0508363445599875

Epoch: 6| Step: 7
Training loss: 1.934102177619934
Validation loss: 2.033183534940084

Epoch: 6| Step: 8
Training loss: 1.7576050758361816
Validation loss: 2.0544514656066895

Epoch: 6| Step: 9
Training loss: 2.7272825241088867
Validation loss: 2.0387096007665

Epoch: 6| Step: 10
Training loss: 1.1040081977844238
Validation loss: 2.0436005194981894

Epoch: 6| Step: 11
Training loss: 1.7167913913726807
Validation loss: 2.034484883149465

Epoch: 6| Step: 12
Training loss: 2.2761733531951904
Validation loss: 2.03373920917511

Epoch: 6| Step: 13
Training loss: 1.844951868057251
Validation loss: 2.019908388455709

Epoch: 84| Step: 0
Training loss: 1.6047286987304688
Validation loss: 2.030199706554413

Epoch: 6| Step: 1
Training loss: 1.3839082717895508
Validation loss: 2.052809755007426

Epoch: 6| Step: 2
Training loss: 1.6969677209854126
Validation loss: 2.025774300098419

Epoch: 6| Step: 3
Training loss: 1.1636734008789062
Validation loss: 2.013225555419922

Epoch: 6| Step: 4
Training loss: 1.4794139862060547
Validation loss: 2.0227315624554953

Epoch: 6| Step: 5
Training loss: 2.3216934204101562
Validation loss: 2.039503534634908

Epoch: 6| Step: 6
Training loss: 1.9483669996261597
Validation loss: 2.0535165468851724

Epoch: 6| Step: 7
Training loss: 1.918649673461914
Validation loss: 2.0399231712023416

Epoch: 6| Step: 8
Training loss: 1.3848166465759277
Validation loss: 2.058636804421743

Epoch: 6| Step: 9
Training loss: 1.6376042366027832
Validation loss: 2.043007791042328

Epoch: 6| Step: 10
Training loss: 1.5159887075424194
Validation loss: 2.0356545646985373

Epoch: 6| Step: 11
Training loss: 2.2978177070617676
Validation loss: 2.017150580883026

Epoch: 6| Step: 12
Training loss: 1.6500093936920166
Validation loss: 2.001272122065226

Epoch: 6| Step: 13
Training loss: 1.4943009614944458
Validation loss: 2.0111807386080423

Epoch: 85| Step: 0
Training loss: 1.175425410270691
Validation loss: 1.985858678817749

Epoch: 6| Step: 1
Training loss: 2.0853312015533447
Validation loss: 2.022937019666036

Epoch: 6| Step: 2
Training loss: 1.319122314453125
Validation loss: 2.017087976137797

Epoch: 6| Step: 3
Training loss: 1.3659521341323853
Validation loss: 2.0114930073420205

Epoch: 6| Step: 4
Training loss: 1.6709508895874023
Validation loss: 2.0020530621210733

Epoch: 6| Step: 5
Training loss: 2.062331199645996
Validation loss: 1.9989564021428425

Epoch: 6| Step: 6
Training loss: 1.6407139301300049
Validation loss: 2.0232969522476196

Epoch: 6| Step: 7
Training loss: 1.8490722179412842
Validation loss: 2.0125792026519775

Epoch: 6| Step: 8
Training loss: 1.6494554281234741
Validation loss: 2.027002135912577

Epoch: 6| Step: 9
Training loss: 1.822009563446045
Validation loss: 2.018191397190094

Epoch: 6| Step: 10
Training loss: 1.8972151279449463
Validation loss: 2.0252596934636435

Epoch: 6| Step: 11
Training loss: 1.4621585607528687
Validation loss: 2.03096866607666

Epoch: 6| Step: 12
Training loss: 1.4688386917114258
Validation loss: 2.021572172641754

Epoch: 6| Step: 13
Training loss: 1.9119683504104614
Validation loss: 2.026808420817057

Epoch: 86| Step: 0
Training loss: 2.217038631439209
Validation loss: 2.0300987164179483

Epoch: 6| Step: 1
Training loss: 2.4137439727783203
Validation loss: 2.0533673763275146

Epoch: 6| Step: 2
Training loss: 1.2965989112854004
Validation loss: 2.023622473080953

Epoch: 6| Step: 3
Training loss: 1.3160760402679443
Validation loss: 2.048492709795634

Epoch: 6| Step: 4
Training loss: 1.6293323040008545
Validation loss: 2.0563953518867493

Epoch: 6| Step: 5
Training loss: 1.9554208517074585
Validation loss: 2.054686407248179

Epoch: 6| Step: 6
Training loss: 1.3713388442993164
Validation loss: 2.0128321846326194

Epoch: 6| Step: 7
Training loss: 1.8523857593536377
Validation loss: 1.9970081249872844

Epoch: 6| Step: 8
Training loss: 1.704917073249817
Validation loss: 1.9978655179341633

Epoch: 6| Step: 9
Training loss: 1.7076131105422974
Validation loss: 2.0114983518918357

Epoch: 6| Step: 10
Training loss: 1.1877968311309814
Validation loss: 2.0023430585861206

Epoch: 6| Step: 11
Training loss: 1.1916214227676392
Validation loss: 1.9880841771761577

Epoch: 6| Step: 12
Training loss: 1.9520868062973022
Validation loss: 2.0265875657399497

Epoch: 6| Step: 13
Training loss: 1.6874881982803345
Validation loss: 2.0690307219823203

Epoch: 87| Step: 0
Training loss: 1.1739271879196167
Validation loss: 2.05264546473821

Epoch: 6| Step: 1
Training loss: 1.3378186225891113
Validation loss: 2.0371551314989724

Epoch: 6| Step: 2
Training loss: 1.7469570636749268
Validation loss: 2.033511459827423

Epoch: 6| Step: 3
Training loss: 1.8034484386444092
Validation loss: 2.048732419808706

Epoch: 6| Step: 4
Training loss: 2.47409725189209
Validation loss: 2.0599132974942527

Epoch: 6| Step: 5
Training loss: 1.6341874599456787
Validation loss: 2.015734593073527

Epoch: 6| Step: 6
Training loss: 1.3546998500823975
Validation loss: 2.017424742380778

Epoch: 6| Step: 7
Training loss: 1.87095308303833
Validation loss: 2.032884200414022

Epoch: 6| Step: 8
Training loss: 1.3613353967666626
Validation loss: 2.0182824532190957

Epoch: 6| Step: 9
Training loss: 1.5136713981628418
Validation loss: 2.009654680887858

Epoch: 6| Step: 10
Training loss: 1.8231816291809082
Validation loss: 2.0030876795450845

Epoch: 6| Step: 11
Training loss: 1.587296962738037
Validation loss: 2.0145014921824136

Epoch: 6| Step: 12
Training loss: 1.4152476787567139
Validation loss: 2.0310481588045755

Epoch: 6| Step: 13
Training loss: 2.03610897064209
Validation loss: 2.031046748161316

Epoch: 88| Step: 0
Training loss: 1.0018916130065918
Validation loss: 2.016480326652527

Epoch: 6| Step: 1
Training loss: 2.095489025115967
Validation loss: 2.0396910111109414

Epoch: 6| Step: 2
Training loss: 1.867584466934204
Validation loss: 2.0355847676595054

Epoch: 6| Step: 3
Training loss: 1.2759857177734375
Validation loss: 2.0400025248527527

Epoch: 6| Step: 4
Training loss: 0.9918503761291504
Validation loss: 2.039856751759847

Epoch: 6| Step: 5
Training loss: 2.0158817768096924
Validation loss: 2.047537167867025

Epoch: 6| Step: 6
Training loss: 1.655462622642517
Validation loss: 2.042858819166819

Epoch: 6| Step: 7
Training loss: 1.8604410886764526
Validation loss: 2.003406306107839

Epoch: 6| Step: 8
Training loss: 2.0235984325408936
Validation loss: 2.0109321673711142

Epoch: 6| Step: 9
Training loss: 1.0920641422271729
Validation loss: 2.021969437599182

Epoch: 6| Step: 10
Training loss: 1.5161842107772827
Validation loss: 2.0328946908315024

Epoch: 6| Step: 11
Training loss: 1.8267369270324707
Validation loss: 2.0397210319836936

Epoch: 6| Step: 12
Training loss: 2.109346389770508
Validation loss: 2.0108100175857544

Epoch: 6| Step: 13
Training loss: 1.8240517377853394
Validation loss: 2.011104106903076

Epoch: 89| Step: 0
Training loss: 1.4032340049743652
Validation loss: 2.0130604902903237

Epoch: 6| Step: 1
Training loss: 1.324599027633667
Validation loss: 1.9968393246332805

Epoch: 6| Step: 2
Training loss: 1.9536819458007812
Validation loss: 2.0196242133776345

Epoch: 6| Step: 3
Training loss: 1.2239093780517578
Validation loss: 1.9870017965634663

Epoch: 6| Step: 4
Training loss: 1.5963022708892822
Validation loss: 2.008407930533091

Epoch: 6| Step: 5
Training loss: 1.9084669351577759
Validation loss: 2.0226997335751853

Epoch: 6| Step: 6
Training loss: 1.4047232866287231
Validation loss: 2.029913047949473

Epoch: 6| Step: 7
Training loss: 1.5522202253341675
Validation loss: 1.980796456336975

Epoch: 6| Step: 8
Training loss: 2.1842398643493652
Validation loss: 2.0245648622512817

Epoch: 6| Step: 9
Training loss: 1.3727411031723022
Validation loss: 1.9825512369473774

Epoch: 6| Step: 10
Training loss: 1.0101306438446045
Validation loss: 2.035674512386322

Epoch: 6| Step: 11
Training loss: 2.174746513366699
Validation loss: 1.9985750118891399

Epoch: 6| Step: 12
Training loss: 1.8662983179092407
Validation loss: 2.044474999109904

Epoch: 6| Step: 13
Training loss: 2.103435516357422
Validation loss: 2.073899507522583

Epoch: 90| Step: 0
Training loss: 2.111328125
Validation loss: 2.101799190044403

Epoch: 6| Step: 1
Training loss: 1.6507561206817627
Validation loss: 2.061777969201406

Epoch: 6| Step: 2
Training loss: 1.7083033323287964
Validation loss: 2.011720279852549

Epoch: 6| Step: 3
Training loss: 1.7846403121948242
Validation loss: 2.0379223823547363

Epoch: 6| Step: 4
Training loss: 1.75336754322052
Validation loss: 2.036619265874227

Epoch: 6| Step: 5
Training loss: 1.549923062324524
Validation loss: 2.019167641798655

Epoch: 6| Step: 6
Training loss: 1.5177828073501587
Validation loss: 2.0383339722951255

Epoch: 6| Step: 7
Training loss: 1.5215630531311035
Validation loss: 2.0581279595692954

Epoch: 6| Step: 8
Training loss: 2.1484928131103516
Validation loss: 2.070790648460388

Epoch: 6| Step: 9
Training loss: 1.2826261520385742
Validation loss: 2.049352467060089

Epoch: 6| Step: 10
Training loss: 1.861051082611084
Validation loss: 2.039114793141683

Epoch: 6| Step: 11
Training loss: 1.4957990646362305
Validation loss: 2.0301679174105325

Epoch: 6| Step: 12
Training loss: 1.8689048290252686
Validation loss: 2.0274126728375754

Epoch: 6| Step: 13
Training loss: 1.9974544048309326
Validation loss: 2.040431340535482

Epoch: 91| Step: 0
Training loss: 1.3826615810394287
Validation loss: 2.0708068211873374

Epoch: 6| Step: 1
Training loss: 1.6655937433242798
Validation loss: 2.12741881608963

Epoch: 6| Step: 2
Training loss: 2.2413437366485596
Validation loss: 2.1617325941721597

Epoch: 6| Step: 3
Training loss: 2.1295673847198486
Validation loss: 2.1878955364227295

Epoch: 6| Step: 4
Training loss: 1.439536452293396
Validation loss: 2.1439528862635293

Epoch: 6| Step: 5
Training loss: 2.0972557067871094
Validation loss: 2.103968063990275

Epoch: 6| Step: 6
Training loss: 2.0599801540374756
Validation loss: 2.062725245952606

Epoch: 6| Step: 7
Training loss: 1.0286492109298706
Validation loss: 2.0271397034327188

Epoch: 6| Step: 8
Training loss: 1.9669480323791504
Validation loss: 2.0296001633008323

Epoch: 6| Step: 9
Training loss: 2.0290372371673584
Validation loss: 1.9871551394462585

Epoch: 6| Step: 10
Training loss: 1.6645927429199219
Validation loss: 2.0302603046099343

Epoch: 6| Step: 11
Training loss: 1.4760754108428955
Validation loss: 1.996763288974762

Epoch: 6| Step: 12
Training loss: 1.340120553970337
Validation loss: 2.0076058308283486

Epoch: 6| Step: 13
Training loss: 2.0007922649383545
Validation loss: 2.005009094874064

Epoch: 92| Step: 0
Training loss: 1.5511740446090698
Validation loss: 2.0087930560112

Epoch: 6| Step: 1
Training loss: 1.2573931217193604
Validation loss: 2.016301234563192

Epoch: 6| Step: 2
Training loss: 1.5830060243606567
Validation loss: 2.0321316520373025

Epoch: 6| Step: 3
Training loss: 1.5626561641693115
Validation loss: 2.0175158778826394

Epoch: 6| Step: 4
Training loss: 1.1733589172363281
Validation loss: 2.0052181283632913

Epoch: 6| Step: 5
Training loss: 1.450732946395874
Validation loss: 2.0230397979418435

Epoch: 6| Step: 6
Training loss: 1.242048740386963
Validation loss: 2.0142369071642556

Epoch: 6| Step: 7
Training loss: 2.3295936584472656
Validation loss: 2.000996192296346

Epoch: 6| Step: 8
Training loss: 1.6224364042282104
Validation loss: 2.021677613258362

Epoch: 6| Step: 9
Training loss: 1.296531319618225
Validation loss: 2.023103952407837

Epoch: 6| Step: 10
Training loss: 1.771348476409912
Validation loss: 2.0605252583821616

Epoch: 6| Step: 11
Training loss: 2.056523323059082
Validation loss: 2.021507203578949

Epoch: 6| Step: 12
Training loss: 1.8950284719467163
Validation loss: 2.0446497797966003

Epoch: 6| Step: 13
Training loss: 1.7130926847457886
Validation loss: 2.0573310454686484

Epoch: 93| Step: 0
Training loss: 1.8702139854431152
Validation loss: 2.0722448428471885

Epoch: 6| Step: 1
Training loss: 2.2358787059783936
Validation loss: 2.0285337766011557

Epoch: 6| Step: 2
Training loss: 1.2007629871368408
Validation loss: 2.0364288687705994

Epoch: 6| Step: 3
Training loss: 1.508507490158081
Validation loss: 2.0037227074305215

Epoch: 6| Step: 4
Training loss: 1.515906572341919
Validation loss: 2.013001799583435

Epoch: 6| Step: 5
Training loss: 1.8523460626602173
Validation loss: 2.015059848626455

Epoch: 6| Step: 6
Training loss: 1.6062465906143188
Validation loss: 2.017674446105957

Epoch: 6| Step: 7
Training loss: 1.8611140251159668
Validation loss: 2.0032787521680198

Epoch: 6| Step: 8
Training loss: 1.3157830238342285
Validation loss: 2.031377057234446

Epoch: 6| Step: 9
Training loss: 1.523971676826477
Validation loss: 2.034110685189565

Epoch: 6| Step: 10
Training loss: 1.5540897846221924
Validation loss: 2.0242597262064614

Epoch: 6| Step: 11
Training loss: 2.1686043739318848
Validation loss: 2.0150919755299888

Epoch: 6| Step: 12
Training loss: 1.0655171871185303
Validation loss: 2.0206232269605002

Epoch: 6| Step: 13
Training loss: 1.3958004713058472
Validation loss: 2.029387275377909

Epoch: 94| Step: 0
Training loss: 2.141702651977539
Validation loss: 2.0372451543807983

Epoch: 6| Step: 1
Training loss: 1.7311174869537354
Validation loss: 2.05532306432724

Epoch: 6| Step: 2
Training loss: 2.5169334411621094
Validation loss: 2.056389490763346

Epoch: 6| Step: 3
Training loss: 2.3612051010131836
Validation loss: 2.0412185192108154

Epoch: 6| Step: 4
Training loss: 1.159395456314087
Validation loss: 2.0446016589800515

Epoch: 6| Step: 5
Training loss: 1.0340673923492432
Validation loss: 2.019067903359731

Epoch: 6| Step: 6
Training loss: 1.2615203857421875
Validation loss: 2.048240145047506

Epoch: 6| Step: 7
Training loss: 1.0630587339401245
Validation loss: 2.036091903845469

Epoch: 6| Step: 8
Training loss: 1.5063469409942627
Validation loss: 2.0295549432436624

Epoch: 6| Step: 9
Training loss: 1.6881200075149536
Validation loss: 2.041584014892578

Epoch: 6| Step: 10
Training loss: 1.2938169240951538
Validation loss: 1.9964149991671245

Epoch: 6| Step: 11
Training loss: 1.391786813735962
Validation loss: 2.0055994192759194

Epoch: 6| Step: 12
Training loss: 1.7814340591430664
Validation loss: 2.03170116742452

Epoch: 6| Step: 13
Training loss: 1.4015041589736938
Validation loss: 2.0127245783805847

Epoch: 95| Step: 0
Training loss: 1.5594055652618408
Validation loss: 2.040548245112101

Epoch: 6| Step: 1
Training loss: 1.497729778289795
Validation loss: 2.012723465760549

Epoch: 6| Step: 2
Training loss: 1.966321587562561
Validation loss: 2.0473370353380838

Epoch: 6| Step: 3
Training loss: 1.0105156898498535
Validation loss: 2.039495507876078

Epoch: 6| Step: 4
Training loss: 1.4169533252716064
Validation loss: 2.060957372188568

Epoch: 6| Step: 5
Training loss: 1.4302213191986084
Validation loss: 1.993520160516103

Epoch: 6| Step: 6
Training loss: 1.3129370212554932
Validation loss: 2.033027231693268

Epoch: 6| Step: 7
Training loss: 2.1833040714263916
Validation loss: 2.0486403703689575

Epoch: 6| Step: 8
Training loss: 1.306097388267517
Validation loss: 2.0115158557891846

Epoch: 6| Step: 9
Training loss: 2.2049832344055176
Validation loss: 2.018297771612803

Epoch: 6| Step: 10
Training loss: 1.3347792625427246
Validation loss: 2.017284631729126

Epoch: 6| Step: 11
Training loss: 2.1189193725585938
Validation loss: 2.014338751633962

Epoch: 6| Step: 12
Training loss: 1.1968188285827637
Validation loss: 2.02276881535848

Epoch: 6| Step: 13
Training loss: 1.4755170345306396
Validation loss: 2.0137181878089905

Epoch: 96| Step: 0
Training loss: 1.163249135017395
Validation loss: 2.0487716794013977

Epoch: 6| Step: 1
Training loss: 1.9285147190093994
Validation loss: 2.029610057671865

Epoch: 6| Step: 2
Training loss: 1.2414993047714233
Validation loss: 2.028783857822418

Epoch: 6| Step: 3
Training loss: 1.4140841960906982
Validation loss: 2.0274150172869363

Epoch: 6| Step: 4
Training loss: 1.7373311519622803
Validation loss: 2.042925238609314

Epoch: 6| Step: 5
Training loss: 1.4796431064605713
Validation loss: 2.029593586921692

Epoch: 6| Step: 6
Training loss: 1.647841453552246
Validation loss: 2.024359345436096

Epoch: 6| Step: 7
Training loss: 1.6338248252868652
Validation loss: 2.0339275598526

Epoch: 6| Step: 8
Training loss: 1.6065397262573242
Validation loss: 2.064815123875936

Epoch: 6| Step: 9
Training loss: 1.8733129501342773
Validation loss: 2.063148339589437

Epoch: 6| Step: 10
Training loss: 1.224914789199829
Validation loss: 2.0648080706596375

Epoch: 6| Step: 11
Training loss: 1.4829740524291992
Validation loss: 2.0420878728230796

Epoch: 6| Step: 12
Training loss: 2.329780340194702
Validation loss: 2.0467366178830466

Epoch: 6| Step: 13
Training loss: 1.4886394739151
Validation loss: 2.0104281902313232

Epoch: 97| Step: 0
Training loss: 1.741176724433899
Validation loss: 2.0355129837989807

Epoch: 6| Step: 1
Training loss: 1.3480737209320068
Validation loss: 2.009862939516703

Epoch: 6| Step: 2
Training loss: 1.5142030715942383
Validation loss: 2.0401928424835205

Epoch: 6| Step: 3
Training loss: 1.2840148210525513
Validation loss: 2.0456591844558716

Epoch: 6| Step: 4
Training loss: 2.344123363494873
Validation loss: 2.0276251236597695

Epoch: 6| Step: 5
Training loss: 1.6190730333328247
Validation loss: 2.036592741807302

Epoch: 6| Step: 6
Training loss: 1.8327221870422363
Validation loss: 2.033943752447764

Epoch: 6| Step: 7
Training loss: 1.4110552072525024
Validation loss: 2.0389410058657327

Epoch: 6| Step: 8
Training loss: 1.86958909034729
Validation loss: 2.0495935678482056

Epoch: 6| Step: 9
Training loss: 1.312476396560669
Validation loss: 2.026313583056132

Epoch: 6| Step: 10
Training loss: 0.9795506000518799
Validation loss: 2.0178574323654175

Epoch: 6| Step: 11
Training loss: 1.431628942489624
Validation loss: 2.0467589696248374

Epoch: 6| Step: 12
Training loss: 1.8670861721038818
Validation loss: 2.064686417579651

Epoch: 6| Step: 13
Training loss: 1.984645962715149
Validation loss: 2.123601734638214

Epoch: 98| Step: 0
Training loss: 1.6148362159729004
Validation loss: 2.128314654032389

Epoch: 6| Step: 1
Training loss: 1.542868733406067
Validation loss: 2.104455312093099

Epoch: 6| Step: 2
Training loss: 2.029839038848877
Validation loss: 2.1242775519688926

Epoch: 6| Step: 3
Training loss: 2.25880765914917
Validation loss: 2.1175618171691895

Epoch: 6| Step: 4
Training loss: 1.4742743968963623
Validation loss: 2.069688320159912

Epoch: 6| Step: 5
Training loss: 1.3398966789245605
Validation loss: 2.042513052622477

Epoch: 6| Step: 6
Training loss: 1.6870150566101074
Validation loss: 2.034703850746155

Epoch: 6| Step: 7
Training loss: 1.5658559799194336
Validation loss: 2.034269332885742

Epoch: 6| Step: 8
Training loss: 1.2305175065994263
Validation loss: 2.0296925703684487

Epoch: 6| Step: 9
Training loss: 1.139806866645813
Validation loss: 1.9989312489827473

Epoch: 6| Step: 10
Training loss: 1.8064920902252197
Validation loss: 2.01143471399943

Epoch: 6| Step: 11
Training loss: 0.9212561845779419
Validation loss: 2.0017700592676797

Epoch: 6| Step: 12
Training loss: 1.8970441818237305
Validation loss: 2.0292129715283713

Epoch: 6| Step: 13
Training loss: 1.5578808784484863
Validation loss: 2.0118750731150308

Epoch: 99| Step: 0
Training loss: 1.48832106590271
Validation loss: 2.0210801362991333

Epoch: 6| Step: 1
Training loss: 1.8741651773452759
Validation loss: 2.017577350139618

Epoch: 6| Step: 2
Training loss: 1.2483834028244019
Validation loss: 2.035367747147878

Epoch: 6| Step: 3
Training loss: 1.0351181030273438
Validation loss: 2.0481903354326882

Epoch: 6| Step: 4
Training loss: 0.9312390685081482
Validation loss: 2.011221706867218

Epoch: 6| Step: 5
Training loss: 2.066664934158325
Validation loss: 2.0372890631357827

Epoch: 6| Step: 6
Training loss: 1.5701444149017334
Validation loss: 2.022455851236979

Epoch: 6| Step: 7
Training loss: 1.9105212688446045
Validation loss: 2.036041557788849

Epoch: 6| Step: 8
Training loss: 1.3440104722976685
Validation loss: 2.0374820232391357

Epoch: 6| Step: 9
Training loss: 1.802889108657837
Validation loss: 2.0645808378855386

Epoch: 6| Step: 10
Training loss: 1.7329084873199463
Validation loss: 2.0936242739359536

Epoch: 6| Step: 11
Training loss: 1.5641348361968994
Validation loss: 2.086301068464915

Epoch: 6| Step: 12
Training loss: 1.507385492324829
Validation loss: 2.1203665733337402

Epoch: 6| Step: 13
Training loss: 1.8740289211273193
Validation loss: 2.0864146947860718

Epoch: 100| Step: 0
Training loss: 1.0942209959030151
Validation loss: 2.078681786855062

Epoch: 6| Step: 1
Training loss: 1.1039409637451172
Validation loss: 2.0391869147618613

Epoch: 6| Step: 2
Training loss: 1.7368650436401367
Validation loss: 2.0365365743637085

Epoch: 6| Step: 3
Training loss: 2.219979763031006
Validation loss: 2.041433056195577

Epoch: 6| Step: 4
Training loss: 1.1073107719421387
Validation loss: 2.0336413780848184

Epoch: 6| Step: 5
Training loss: 1.850258708000183
Validation loss: 2.0487488309542337

Epoch: 6| Step: 6
Training loss: 1.6248440742492676
Validation loss: 2.0576562682787576

Epoch: 6| Step: 7
Training loss: 1.6286358833312988
Validation loss: 2.028380552927653

Epoch: 6| Step: 8
Training loss: 1.9587383270263672
Validation loss: 2.0632754365603128

Epoch: 6| Step: 9
Training loss: 1.567147135734558
Validation loss: 2.039404511451721

Epoch: 6| Step: 10
Training loss: 1.8290389776229858
Validation loss: 2.017796357472738

Epoch: 6| Step: 11
Training loss: 2.0459649562835693
Validation loss: 2.0166202584902444

Epoch: 6| Step: 12
Training loss: 0.8374927043914795
Validation loss: 2.050869802633921

Epoch: 6| Step: 13
Training loss: 1.665602445602417
Validation loss: 2.043071707089742

Epoch: 101| Step: 0
Training loss: 1.9614770412445068
Validation loss: 2.0673563281695047

Epoch: 6| Step: 1
Training loss: 1.1178889274597168
Validation loss: 2.0750988523165383

Epoch: 6| Step: 2
Training loss: 1.390840768814087
Validation loss: 2.0757410327593484

Epoch: 6| Step: 3
Training loss: 1.043952226638794
Validation loss: 2.048473338286082

Epoch: 6| Step: 4
Training loss: 1.6351966857910156
Validation loss: 2.063506801923116

Epoch: 6| Step: 5
Training loss: 1.2338824272155762
Validation loss: 2.0214160680770874

Epoch: 6| Step: 6
Training loss: 1.3370375633239746
Validation loss: 2.0348445773124695

Epoch: 6| Step: 7
Training loss: 1.7658135890960693
Validation loss: 2.0173720916112265

Epoch: 6| Step: 8
Training loss: 1.0660204887390137
Validation loss: 2.0014249682426453

Epoch: 6| Step: 9
Training loss: 1.3639696836471558
Validation loss: 2.024098972479502

Epoch: 6| Step: 10
Training loss: 2.4940829277038574
Validation loss: 2.0326085289319358

Epoch: 6| Step: 11
Training loss: 1.361715316772461
Validation loss: 2.040941079457601

Epoch: 6| Step: 12
Training loss: 1.885650634765625
Validation loss: 2.0516828099886575

Epoch: 6| Step: 13
Training loss: 1.9060600996017456
Validation loss: 2.0436421434084573

Epoch: 102| Step: 0
Training loss: 1.1611404418945312
Validation loss: 2.018409272034963

Epoch: 6| Step: 1
Training loss: 1.4533624649047852
Validation loss: 1.9891238808631897

Epoch: 6| Step: 2
Training loss: 1.6500195264816284
Validation loss: 2.040802796681722

Epoch: 6| Step: 3
Training loss: 1.309587001800537
Validation loss: 2.0351630647977195

Epoch: 6| Step: 4
Training loss: 1.5588951110839844
Validation loss: 2.0269996325174966

Epoch: 6| Step: 5
Training loss: 1.5610103607177734
Validation loss: 2.069496671358744

Epoch: 6| Step: 6
Training loss: 1.7738007307052612
Validation loss: 2.0693114002545676

Epoch: 6| Step: 7
Training loss: 1.5382602214813232
Validation loss: 2.044236719608307

Epoch: 6| Step: 8
Training loss: 1.1628084182739258
Validation loss: 2.0195082823435464

Epoch: 6| Step: 9
Training loss: 1.483322024345398
Validation loss: 2.036662499109904

Epoch: 6| Step: 10
Training loss: 1.4990122318267822
Validation loss: 2.0255010525385537

Epoch: 6| Step: 11
Training loss: 2.2524008750915527
Validation loss: 2.0521655877431235

Epoch: 6| Step: 12
Training loss: 1.3180363178253174
Validation loss: 2.0863074461619058

Epoch: 6| Step: 13
Training loss: 1.795857548713684
Validation loss: 2.0565507809321084

Epoch: 103| Step: 0
Training loss: 1.7419241666793823
Validation loss: 2.070916732152303

Epoch: 6| Step: 1
Training loss: 2.461015224456787
Validation loss: 2.043530225753784

Epoch: 6| Step: 2
Training loss: 0.8861146569252014
Validation loss: 2.068415959676107

Epoch: 6| Step: 3
Training loss: 1.3506702184677124
Validation loss: 2.046960731347402

Epoch: 6| Step: 4
Training loss: 1.1201540231704712
Validation loss: 2.030570367972056

Epoch: 6| Step: 5
Training loss: 1.1615180969238281
Validation loss: 2.029366433620453

Epoch: 6| Step: 6
Training loss: 1.4933066368103027
Validation loss: 2.033163050810496

Epoch: 6| Step: 7
Training loss: 1.4377808570861816
Validation loss: 2.0349025328954062

Epoch: 6| Step: 8
Training loss: 1.3383218050003052
Validation loss: 2.047485371430715

Epoch: 6| Step: 9
Training loss: 1.388271450996399
Validation loss: 2.024206578731537

Epoch: 6| Step: 10
Training loss: 0.9352219104766846
Validation loss: 2.02082359790802

Epoch: 6| Step: 11
Training loss: 2.0367605686187744
Validation loss: 2.0307308435440063

Epoch: 6| Step: 12
Training loss: 1.7905901670455933
Validation loss: 2.0441535115242004

Epoch: 6| Step: 13
Training loss: 1.869797706604004
Validation loss: 2.0109509428342185

Epoch: 104| Step: 0
Training loss: 1.585928201675415
Validation loss: 2.0463322401046753

Epoch: 6| Step: 1
Training loss: 1.6397639513015747
Validation loss: 2.0223815043767295

Epoch: 6| Step: 2
Training loss: 1.3868558406829834
Validation loss: 2.032040596008301

Epoch: 6| Step: 3
Training loss: 1.6970255374908447
Validation loss: 2.0259465177853904

Epoch: 6| Step: 4
Training loss: 1.1997005939483643
Validation loss: 2.057989537715912

Epoch: 6| Step: 5
Training loss: 1.1451677083969116
Validation loss: 2.0231460332870483

Epoch: 6| Step: 6
Training loss: 1.636603832244873
Validation loss: 2.049066344896952

Epoch: 6| Step: 7
Training loss: 1.8259135484695435
Validation loss: 2.0101444919904075

Epoch: 6| Step: 8
Training loss: 1.5186421871185303
Validation loss: 2.0373719930648804

Epoch: 6| Step: 9
Training loss: 1.9698622226715088
Validation loss: 2.0301466981569924

Epoch: 6| Step: 10
Training loss: 1.271615982055664
Validation loss: 2.0241998632748923

Epoch: 6| Step: 11
Training loss: 1.4850139617919922
Validation loss: 2.049607515335083

Epoch: 6| Step: 12
Training loss: 0.9885961413383484
Validation loss: 2.0399319330851235

Epoch: 6| Step: 13
Training loss: 1.2882418632507324
Validation loss: 2.038753390312195

Epoch: 105| Step: 0
Training loss: 1.3311119079589844
Validation loss: 2.0725195010503135

Epoch: 6| Step: 1
Training loss: 1.983323335647583
Validation loss: 2.0765408277511597

Epoch: 6| Step: 2
Training loss: 1.022263526916504
Validation loss: 2.015408674875895

Epoch: 6| Step: 3
Training loss: 1.0277879238128662
Validation loss: 2.0048237641652427

Epoch: 6| Step: 4
Training loss: 2.056795597076416
Validation loss: 2.0068864623705545

Epoch: 6| Step: 5
Training loss: 1.4247677326202393
Validation loss: 2.0325844486554465

Epoch: 6| Step: 6
Training loss: 1.6808415651321411
Validation loss: 2.0258918007214866

Epoch: 6| Step: 7
Training loss: 1.9356625080108643
Validation loss: 2.0208277304967246

Epoch: 6| Step: 8
Training loss: 0.9645736217498779
Validation loss: 2.0185925563176474

Epoch: 6| Step: 9
Training loss: 1.953513503074646
Validation loss: 2.052013655503591

Epoch: 6| Step: 10
Training loss: 2.0333685874938965
Validation loss: 2.0270347197850547

Epoch: 6| Step: 11
Training loss: 1.3836948871612549
Validation loss: 2.030309518178304

Epoch: 6| Step: 12
Training loss: 1.7679452896118164
Validation loss: 2.040991723537445

Epoch: 6| Step: 13
Training loss: 0.7736318111419678
Validation loss: 2.0165822505950928

Epoch: 106| Step: 0
Training loss: 1.514510154724121
Validation loss: 2.033178448677063

Epoch: 6| Step: 1
Training loss: 1.0030570030212402
Validation loss: 2.0117693146069846

Epoch: 6| Step: 2
Training loss: 0.9878784418106079
Validation loss: 2.051636199156443

Epoch: 6| Step: 3
Training loss: 1.7603652477264404
Validation loss: 2.02204167842865

Epoch: 6| Step: 4
Training loss: 2.2357542514801025
Validation loss: 2.0376289089520774

Epoch: 6| Step: 5
Training loss: 1.2667856216430664
Validation loss: 2.011517643928528

Epoch: 6| Step: 6
Training loss: 1.428992748260498
Validation loss: 2.0291680693626404

Epoch: 6| Step: 7
Training loss: 2.1526412963867188
Validation loss: 2.038260519504547

Epoch: 6| Step: 8
Training loss: 0.9873641729354858
Validation loss: 2.066035350163778

Epoch: 6| Step: 9
Training loss: 1.0962162017822266
Validation loss: 2.017619252204895

Epoch: 6| Step: 10
Training loss: 1.2334864139556885
Validation loss: 1.9850512742996216

Epoch: 6| Step: 11
Training loss: 1.4938793182373047
Validation loss: 2.039344012737274

Epoch: 6| Step: 12
Training loss: 1.4258322715759277
Validation loss: 2.0313175121943154

Epoch: 6| Step: 13
Training loss: 1.7678427696228027
Validation loss: 2.0443268616994223

Epoch: 107| Step: 0
Training loss: 1.4363360404968262
Validation loss: 1.9993858337402344

Epoch: 6| Step: 1
Training loss: 0.5336896777153015
Validation loss: 2.034704625606537

Epoch: 6| Step: 2
Training loss: 1.6554590463638306
Validation loss: 2.0313262939453125

Epoch: 6| Step: 3
Training loss: 1.0782582759857178
Validation loss: 2.0321465730667114

Epoch: 6| Step: 4
Training loss: 1.8377087116241455
Validation loss: 2.0395463705062866

Epoch: 6| Step: 5
Training loss: 1.8247803449630737
Validation loss: 2.0734216372172036

Epoch: 6| Step: 6
Training loss: 1.4610929489135742
Validation loss: 2.0466946562131247

Epoch: 6| Step: 7
Training loss: 1.4438233375549316
Validation loss: 2.092457334200541

Epoch: 6| Step: 8
Training loss: 1.8487591743469238
Validation loss: 2.0819252332051597

Epoch: 6| Step: 9
Training loss: 1.2560374736785889
Validation loss: 2.0355496803919473

Epoch: 6| Step: 10
Training loss: 1.4697251319885254
Validation loss: 2.0327547589937844

Epoch: 6| Step: 11
Training loss: 1.1427674293518066
Validation loss: 2.0281471411387124

Epoch: 6| Step: 12
Training loss: 1.7121281623840332
Validation loss: 1.988344411055247

Epoch: 6| Step: 13
Training loss: 1.7217724323272705
Validation loss: 1.9783636331558228

Epoch: 108| Step: 0
Training loss: 1.438205361366272
Validation loss: 2.0152037541071572

Epoch: 6| Step: 1
Training loss: 1.2665529251098633
Validation loss: 2.0315961241722107

Epoch: 6| Step: 2
Training loss: 1.4437534809112549
Validation loss: 2.0479002396265664

Epoch: 6| Step: 3
Training loss: 1.392094612121582
Validation loss: 2.06316085656484

Epoch: 6| Step: 4
Training loss: 1.798419713973999
Validation loss: 2.0598422487576804

Epoch: 6| Step: 5
Training loss: 1.3500233888626099
Validation loss: 2.0151455402374268

Epoch: 6| Step: 6
Training loss: 1.468332290649414
Validation loss: 2.0296706557273865

Epoch: 6| Step: 7
Training loss: 2.0889840126037598
Validation loss: 2.0414045453071594

Epoch: 6| Step: 8
Training loss: 1.3592780828475952
Validation loss: 2.0339661240577698

Epoch: 6| Step: 9
Training loss: 0.9549323916435242
Validation loss: 2.0669676860173545

Epoch: 6| Step: 10
Training loss: 1.1631629467010498
Validation loss: 2.0440816283226013

Epoch: 6| Step: 11
Training loss: 1.8070154190063477
Validation loss: 2.0655572414398193

Epoch: 6| Step: 12
Training loss: 1.8821675777435303
Validation loss: 2.0861202478408813

Epoch: 6| Step: 13
Training loss: 1.631034255027771
Validation loss: 2.0887742837270102

Epoch: 109| Step: 0
Training loss: 1.7440727949142456
Validation loss: 2.0542418162027993

Epoch: 6| Step: 1
Training loss: 0.9935266971588135
Validation loss: 2.034446934858958

Epoch: 6| Step: 2
Training loss: 1.8265233039855957
Validation loss: 2.03525181611379

Epoch: 6| Step: 3
Training loss: 1.7525832653045654
Validation loss: 2.0529818336168923

Epoch: 6| Step: 4
Training loss: 1.5077629089355469
Validation loss: 2.038739264011383

Epoch: 6| Step: 5
Training loss: 1.4363785982131958
Validation loss: 2.0368616183598838

Epoch: 6| Step: 6
Training loss: 2.321636199951172
Validation loss: 2.0088276465733848

Epoch: 6| Step: 7
Training loss: 1.427689790725708
Validation loss: 2.0558427373568215

Epoch: 6| Step: 8
Training loss: 1.216374397277832
Validation loss: 2.05274490515391

Epoch: 6| Step: 9
Training loss: 1.6044552326202393
Validation loss: 2.066618541876475

Epoch: 6| Step: 10
Training loss: 1.1795746088027954
Validation loss: 2.041283905506134

Epoch: 6| Step: 11
Training loss: 1.591352939605713
Validation loss: 2.0398268500963845

Epoch: 6| Step: 12
Training loss: 1.4964585304260254
Validation loss: 2.0253566106160483

Epoch: 6| Step: 13
Training loss: 0.7279279232025146
Validation loss: 2.058704654375712

Epoch: 110| Step: 0
Training loss: 0.891932487487793
Validation loss: 2.059201459089915

Epoch: 6| Step: 1
Training loss: 1.735854983329773
Validation loss: 2.0997292399406433

Epoch: 6| Step: 2
Training loss: 1.1709256172180176
Validation loss: 2.0595157543818154

Epoch: 6| Step: 3
Training loss: 1.69265615940094
Validation loss: 2.087485353151957

Epoch: 6| Step: 4
Training loss: 1.7761355638504028
Validation loss: 2.093410094579061

Epoch: 6| Step: 5
Training loss: 1.5835436582565308
Validation loss: 2.050692856311798

Epoch: 6| Step: 6
Training loss: 1.9070544242858887
Validation loss: 2.042443116505941

Epoch: 6| Step: 7
Training loss: 1.6544888019561768
Validation loss: 2.029020587603251

Epoch: 6| Step: 8
Training loss: 1.1160094738006592
Validation loss: 2.026824394861857

Epoch: 6| Step: 9
Training loss: 1.7196404933929443
Validation loss: 2.0341402888298035

Epoch: 6| Step: 10
Training loss: 1.3055217266082764
Validation loss: 2.0623628894488015

Epoch: 6| Step: 11
Training loss: 1.387994647026062
Validation loss: 2.0318456093470254

Epoch: 6| Step: 12
Training loss: 1.015648603439331
Validation loss: 2.014272391796112

Epoch: 6| Step: 13
Training loss: 1.620764970779419
Validation loss: 2.015135884284973

Epoch: 111| Step: 0
Training loss: 1.93913996219635
Validation loss: 2.0416828393936157

Epoch: 6| Step: 1
Training loss: 1.3301193714141846
Validation loss: 2.0234289367993674

Epoch: 6| Step: 2
Training loss: 2.0308825969696045
Validation loss: 2.0406715273857117

Epoch: 6| Step: 3
Training loss: 2.017195701599121
Validation loss: 2.0243451595306396

Epoch: 6| Step: 4
Training loss: 0.676353394985199
Validation loss: 2.0198733607927957

Epoch: 6| Step: 5
Training loss: 1.1844618320465088
Validation loss: 2.0057148536046348

Epoch: 6| Step: 6
Training loss: 1.4196548461914062
Validation loss: 2.006661375363668

Epoch: 6| Step: 7
Training loss: 1.4822027683258057
Validation loss: 2.0156486431757608

Epoch: 6| Step: 8
Training loss: 1.359739899635315
Validation loss: 2.0413459738095603

Epoch: 6| Step: 9
Training loss: 1.3766024112701416
Validation loss: 2.057625671227773

Epoch: 6| Step: 10
Training loss: 1.3627815246582031
Validation loss: 2.0300254821777344

Epoch: 6| Step: 11
Training loss: 1.2039653062820435
Validation loss: 2.0307841499646506

Epoch: 6| Step: 12
Training loss: 1.2161908149719238
Validation loss: 2.0223559737205505

Epoch: 6| Step: 13
Training loss: 1.313977599143982
Validation loss: 2.0359809199968972

Epoch: 112| Step: 0
Training loss: 2.1420774459838867
Validation loss: 2.0434553225835166

Epoch: 6| Step: 1
Training loss: 1.337078332901001
Validation loss: 2.058113475640615

Epoch: 6| Step: 2
Training loss: 1.17362380027771
Validation loss: 2.0300080378850303

Epoch: 6| Step: 3
Training loss: 1.714672565460205
Validation loss: 2.046896457672119

Epoch: 6| Step: 4
Training loss: 1.0394079685211182
Validation loss: 2.0565292636553445

Epoch: 6| Step: 5
Training loss: 1.9854174852371216
Validation loss: 2.016675651073456

Epoch: 6| Step: 6
Training loss: 1.2577412128448486
Validation loss: 2.018190344174703

Epoch: 6| Step: 7
Training loss: 1.4219752550125122
Validation loss: 2.0442533691724143

Epoch: 6| Step: 8
Training loss: 1.43766188621521
Validation loss: 2.043659766515096

Epoch: 6| Step: 9
Training loss: 1.2145575284957886
Validation loss: 2.0227402249972024

Epoch: 6| Step: 10
Training loss: 1.0565900802612305
Validation loss: 2.0245595971743264

Epoch: 6| Step: 11
Training loss: 0.9514062404632568
Validation loss: 2.0171236594518027

Epoch: 6| Step: 12
Training loss: 1.2140107154846191
Validation loss: 2.066860238711039

Epoch: 6| Step: 13
Training loss: 1.3557515144348145
Validation loss: 2.038564383983612

Epoch: 113| Step: 0
Training loss: 1.3829995393753052
Validation loss: 2.0708360274632773

Epoch: 6| Step: 1
Training loss: 1.7943603992462158
Validation loss: 2.086964805920919

Epoch: 6| Step: 2
Training loss: 1.7843083143234253
Validation loss: 2.0595179994901023

Epoch: 6| Step: 3
Training loss: 0.9645755290985107
Validation loss: 2.0080994764963784

Epoch: 6| Step: 4
Training loss: 1.2816739082336426
Validation loss: 2.057141919930776

Epoch: 6| Step: 5
Training loss: 1.2972016334533691
Validation loss: 2.0675153732299805

Epoch: 6| Step: 6
Training loss: 1.8700425624847412
Validation loss: 2.0382251938184104

Epoch: 6| Step: 7
Training loss: 1.0649583339691162
Validation loss: 2.048779288927714

Epoch: 6| Step: 8
Training loss: 1.2897582054138184
Validation loss: 2.0191912055015564

Epoch: 6| Step: 9
Training loss: 1.5397491455078125
Validation loss: 2.0145311752955117

Epoch: 6| Step: 10
Training loss: 1.6419631242752075
Validation loss: 2.007031261920929

Epoch: 6| Step: 11
Training loss: 1.4623196125030518
Validation loss: 2.0220890442530313

Epoch: 6| Step: 12
Training loss: 1.4691414833068848
Validation loss: 2.0417719086011252

Epoch: 6| Step: 13
Training loss: 1.3085862398147583
Validation loss: 2.0088684360186257

Epoch: 114| Step: 0
Training loss: 1.4236488342285156
Validation loss: 2.0139657258987427

Epoch: 6| Step: 1
Training loss: 0.968948245048523
Validation loss: 2.011093318462372

Epoch: 6| Step: 2
Training loss: 1.3737750053405762
Validation loss: 2.013643423716227

Epoch: 6| Step: 3
Training loss: 1.8238565921783447
Validation loss: 2.02166340748469

Epoch: 6| Step: 4
Training loss: 1.3919485807418823
Validation loss: 2.011214276154836

Epoch: 6| Step: 5
Training loss: 1.1846320629119873
Validation loss: 2.039059340953827

Epoch: 6| Step: 6
Training loss: 1.361229419708252
Validation loss: 2.0281220078468323

Epoch: 6| Step: 7
Training loss: 0.9613053202629089
Validation loss: 2.005824605623881

Epoch: 6| Step: 8
Training loss: 1.3587236404418945
Validation loss: 2.008399546146393

Epoch: 6| Step: 9
Training loss: 1.7591320276260376
Validation loss: 1.9954030712445576

Epoch: 6| Step: 10
Training loss: 1.5596122741699219
Validation loss: 2.0405453046162925

Epoch: 6| Step: 11
Training loss: 1.5436084270477295
Validation loss: 2.0335721572240195

Epoch: 6| Step: 12
Training loss: 1.3932256698608398
Validation loss: 2.046237051486969

Epoch: 6| Step: 13
Training loss: 1.3526277542114258
Validation loss: 2.0325440963109336

Epoch: 115| Step: 0
Training loss: 1.446345329284668
Validation loss: 2.039750794569651

Epoch: 6| Step: 1
Training loss: 1.297421932220459
Validation loss: 2.017186443010966

Epoch: 6| Step: 2
Training loss: 1.5907771587371826
Validation loss: 2.0559774239857993

Epoch: 6| Step: 3
Training loss: 1.6723562479019165
Validation loss: 2.0382633407910666

Epoch: 6| Step: 4
Training loss: 1.59382963180542
Validation loss: 2.1053722302118936

Epoch: 6| Step: 5
Training loss: 1.2591999769210815
Validation loss: 2.113143265247345

Epoch: 6| Step: 6
Training loss: 1.4283941984176636
Validation loss: 2.081925928592682

Epoch: 6| Step: 7
Training loss: 0.9888800978660583
Validation loss: 2.0521064003308616

Epoch: 6| Step: 8
Training loss: 1.3866512775421143
Validation loss: 2.0326798359553018

Epoch: 6| Step: 9
Training loss: 1.2949577569961548
Validation loss: 2.046683053175608

Epoch: 6| Step: 10
Training loss: 1.7819492816925049
Validation loss: 2.0344656507174173

Epoch: 6| Step: 11
Training loss: 1.1860501766204834
Validation loss: 2.0066948731740317

Epoch: 6| Step: 12
Training loss: 1.3187975883483887
Validation loss: 2.009732723236084

Epoch: 6| Step: 13
Training loss: 1.201826572418213
Validation loss: 2.0279399156570435

Epoch: 116| Step: 0
Training loss: 1.1298983097076416
Validation loss: 2.024588108062744

Epoch: 6| Step: 1
Training loss: 1.5371112823486328
Validation loss: 2.035905381043752

Epoch: 6| Step: 2
Training loss: 1.2152330875396729
Validation loss: 2.044701258341471

Epoch: 6| Step: 3
Training loss: 0.8084878325462341
Validation loss: 2.008364737033844

Epoch: 6| Step: 4
Training loss: 2.2371792793273926
Validation loss: 2.0129890044530234

Epoch: 6| Step: 5
Training loss: 1.0390710830688477
Validation loss: 2.006772001584371

Epoch: 6| Step: 6
Training loss: 0.9678207635879517
Validation loss: 2.0101635456085205

Epoch: 6| Step: 7
Training loss: 1.9939792156219482
Validation loss: 2.0412793159484863

Epoch: 6| Step: 8
Training loss: 1.3484270572662354
Validation loss: 2.04720010360082

Epoch: 6| Step: 9
Training loss: 1.4511215686798096
Validation loss: 2.0353815158208213

Epoch: 6| Step: 10
Training loss: 1.4635848999023438
Validation loss: 1.9924340446790059

Epoch: 6| Step: 11
Training loss: 1.301560640335083
Validation loss: 2.044555385907491

Epoch: 6| Step: 12
Training loss: 1.3339817523956299
Validation loss: 2.0483149886131287

Epoch: 6| Step: 13
Training loss: 1.1672825813293457
Validation loss: 2.055152257283529

Epoch: 117| Step: 0
Training loss: 1.4513628482818604
Validation loss: 2.0518327752749124

Epoch: 6| Step: 1
Training loss: 1.017986536026001
Validation loss: 2.0227968295415244

Epoch: 6| Step: 2
Training loss: 1.6599290370941162
Validation loss: 2.0390623609224954

Epoch: 6| Step: 3
Training loss: 1.2604584693908691
Validation loss: 2.0334921876589456

Epoch: 6| Step: 4
Training loss: 0.6973167657852173
Validation loss: 2.0102349122365317

Epoch: 6| Step: 5
Training loss: 1.3246867656707764
Validation loss: 2.037304480870565

Epoch: 6| Step: 6
Training loss: 1.4585363864898682
Validation loss: 2.0293445189793906

Epoch: 6| Step: 7
Training loss: 1.561509132385254
Validation loss: 2.0404555598894754

Epoch: 6| Step: 8
Training loss: 1.1070443391799927
Validation loss: 2.0385316610336304

Epoch: 6| Step: 9
Training loss: 1.4286203384399414
Validation loss: 2.046620706717173

Epoch: 6| Step: 10
Training loss: 2.303797721862793
Validation loss: 2.0123631755510965

Epoch: 6| Step: 11
Training loss: 1.119606375694275
Validation loss: 2.0262347062428794

Epoch: 6| Step: 12
Training loss: 1.0428218841552734
Validation loss: 2.0034595330556235

Epoch: 6| Step: 13
Training loss: 1.2238051891326904
Validation loss: 2.052336831887563

Epoch: 118| Step: 0
Training loss: 1.3814400434494019
Validation loss: 2.0083130399386087

Epoch: 6| Step: 1
Training loss: 1.141431450843811
Validation loss: 2.0175156792004905

Epoch: 6| Step: 2
Training loss: 1.4417396783828735
Validation loss: 2.039492348829905

Epoch: 6| Step: 3
Training loss: 1.4607216119766235
Validation loss: 2.0152968764305115

Epoch: 6| Step: 4
Training loss: 0.7866590023040771
Validation loss: 2.0177028576533

Epoch: 6| Step: 5
Training loss: 1.5034539699554443
Validation loss: 2.0142499804496765

Epoch: 6| Step: 6
Training loss: 1.626355767250061
Validation loss: 1.9931039611498516

Epoch: 6| Step: 7
Training loss: 1.20357346534729
Validation loss: 2.027213374773661

Epoch: 6| Step: 8
Training loss: 1.9681296348571777
Validation loss: 2.0084943373998008

Epoch: 6| Step: 9
Training loss: 1.164355993270874
Validation loss: 1.9882413546244304

Epoch: 6| Step: 10
Training loss: 1.2792994976043701
Validation loss: 2.015547593434652

Epoch: 6| Step: 11
Training loss: 1.2119027376174927
Validation loss: 2.01471745967865

Epoch: 6| Step: 12
Training loss: 1.2215687036514282
Validation loss: 2.045933206876119

Epoch: 6| Step: 13
Training loss: 1.4144587516784668
Validation loss: 2.0112374424934387

Epoch: 119| Step: 0
Training loss: 0.7156355381011963
Validation loss: 2.025027334690094

Epoch: 6| Step: 1
Training loss: 1.4243438243865967
Validation loss: 2.0284301241238913

Epoch: 6| Step: 2
Training loss: 1.568392276763916
Validation loss: 2.007586340109507

Epoch: 6| Step: 3
Training loss: 1.1590830087661743
Validation loss: 2.0260623494784036

Epoch: 6| Step: 4
Training loss: 1.5395057201385498
Validation loss: 2.0376992424329123

Epoch: 6| Step: 5
Training loss: 1.5729389190673828
Validation loss: 2.020926594734192

Epoch: 6| Step: 6
Training loss: 0.7952357530593872
Validation loss: 2.049835205078125

Epoch: 6| Step: 7
Training loss: 1.1606976985931396
Validation loss: 2.0468700925509133

Epoch: 6| Step: 8
Training loss: 1.314352035522461
Validation loss: 2.0226739247639975

Epoch: 6| Step: 9
Training loss: 1.6523839235305786
Validation loss: 1.9984788298606873

Epoch: 6| Step: 10
Training loss: 1.4653708934783936
Validation loss: 2.002919693787893

Epoch: 6| Step: 11
Training loss: 1.6036059856414795
Validation loss: 1.9903603394826253

Epoch: 6| Step: 12
Training loss: 1.2442898750305176
Validation loss: 2.0236137906710305

Epoch: 6| Step: 13
Training loss: 1.4190502166748047
Validation loss: 2.0282220443089805

Epoch: 120| Step: 0
Training loss: 0.9837481379508972
Validation loss: 2.019816815853119

Epoch: 6| Step: 1
Training loss: 1.0307462215423584
Validation loss: 2.0094619592030845

Epoch: 6| Step: 2
Training loss: 1.1833131313323975
Validation loss: 1.99405441681544

Epoch: 6| Step: 3
Training loss: 1.6219022274017334
Validation loss: 2.039237995942434

Epoch: 6| Step: 4
Training loss: 1.2736515998840332
Validation loss: 1.977582573890686

Epoch: 6| Step: 5
Training loss: 0.8787497878074646
Validation loss: 2.003808379173279

Epoch: 6| Step: 6
Training loss: 1.4604378938674927
Validation loss: 2.020458201567332

Epoch: 6| Step: 7
Training loss: 1.4940779209136963
Validation loss: 2.0393183628718057

Epoch: 6| Step: 8
Training loss: 1.6942861080169678
Validation loss: 2.0044267972310386

Epoch: 6| Step: 9
Training loss: 0.9810762405395508
Validation loss: 2.051863650480906

Epoch: 6| Step: 10
Training loss: 1.457963466644287
Validation loss: 2.03530345360438

Epoch: 6| Step: 11
Training loss: 1.284924030303955
Validation loss: 2.039253572622935

Epoch: 6| Step: 12
Training loss: 1.763017177581787
Validation loss: 2.067336122194926

Epoch: 6| Step: 13
Training loss: 1.0821928977966309
Validation loss: 1.9990271131197612

Epoch: 121| Step: 0
Training loss: 0.7034115195274353
Validation loss: 1.9911738435427349

Epoch: 6| Step: 1
Training loss: 1.3554010391235352
Validation loss: 2.039341628551483

Epoch: 6| Step: 2
Training loss: 1.7279373407363892
Validation loss: 2.0419231255849204

Epoch: 6| Step: 3
Training loss: 1.1343092918395996
Validation loss: 2.0429532329241433

Epoch: 6| Step: 4
Training loss: 1.3041937351226807
Validation loss: 1.9965321222941081

Epoch: 6| Step: 5
Training loss: 2.2515411376953125
Validation loss: 2.0358957846959433

Epoch: 6| Step: 6
Training loss: 1.4042580127716064
Validation loss: 2.0773218274116516

Epoch: 6| Step: 7
Training loss: 1.2660905122756958
Validation loss: 2.015425364176432

Epoch: 6| Step: 8
Training loss: 0.8395496010780334
Validation loss: 2.001838743686676

Epoch: 6| Step: 9
Training loss: 0.9404182434082031
Validation loss: 2.038731793562571

Epoch: 6| Step: 10
Training loss: 1.1170839071273804
Validation loss: 2.0688565770785012

Epoch: 6| Step: 11
Training loss: 1.410783290863037
Validation loss: 2.0574084321657815

Epoch: 6| Step: 12
Training loss: 0.9774477481842041
Validation loss: 2.0650946299235025

Epoch: 6| Step: 13
Training loss: 1.6807515621185303
Validation loss: 2.112762173016866

Epoch: 122| Step: 0
Training loss: 1.6079607009887695
Validation loss: 2.1400848825772605

Epoch: 6| Step: 1
Training loss: 1.5296568870544434
Validation loss: 2.0976373751958213

Epoch: 6| Step: 2
Training loss: 1.563517689704895
Validation loss: 2.0975027084350586

Epoch: 6| Step: 3
Training loss: 1.3630216121673584
Validation loss: 2.0518598755200705

Epoch: 6| Step: 4
Training loss: 0.9853737354278564
Validation loss: 2.018111268679301

Epoch: 6| Step: 5
Training loss: 0.8231260776519775
Validation loss: 2.023240844408671

Epoch: 6| Step: 6
Training loss: 1.3852577209472656
Validation loss: 2.0322928031285605

Epoch: 6| Step: 7
Training loss: 1.1924171447753906
Validation loss: 2.0138548016548157

Epoch: 6| Step: 8
Training loss: 1.9918277263641357
Validation loss: 2.017088254292806

Epoch: 6| Step: 9
Training loss: 1.3564163446426392
Validation loss: 2.008603096008301

Epoch: 6| Step: 10
Training loss: 1.3513127565383911
Validation loss: 2.013090113798777

Epoch: 6| Step: 11
Training loss: 1.2032911777496338
Validation loss: 2.0175276398658752

Epoch: 6| Step: 12
Training loss: 0.8748776912689209
Validation loss: 2.0266226530075073

Epoch: 6| Step: 13
Training loss: 1.2900720834732056
Validation loss: 2.0560961961746216

Epoch: 123| Step: 0
Training loss: 0.882702112197876
Validation loss: 2.0028876066207886

Epoch: 6| Step: 1
Training loss: 1.248085618019104
Validation loss: 1.996542493502299

Epoch: 6| Step: 2
Training loss: 1.5960272550582886
Validation loss: 2.039895931879679

Epoch: 6| Step: 3
Training loss: 1.6020382642745972
Validation loss: 2.029695292313894

Epoch: 6| Step: 4
Training loss: 1.3299226760864258
Validation loss: 2.049635648727417

Epoch: 6| Step: 5
Training loss: 1.2486323118209839
Validation loss: 2.020695765813192

Epoch: 6| Step: 6
Training loss: 1.67097806930542
Validation loss: 2.056950251261393

Epoch: 6| Step: 7
Training loss: 0.8600506782531738
Validation loss: 2.010320862134298

Epoch: 6| Step: 8
Training loss: 1.1705236434936523
Validation loss: 2.0101834734280906

Epoch: 6| Step: 9
Training loss: 1.081498622894287
Validation loss: 2.0440494815508523

Epoch: 6| Step: 10
Training loss: 0.6522259712219238
Validation loss: 2.0395679672559104

Epoch: 6| Step: 11
Training loss: 1.74537992477417
Validation loss: 2.003068188826243

Epoch: 6| Step: 12
Training loss: 1.5774667263031006
Validation loss: 2.0025490125020347

Epoch: 6| Step: 13
Training loss: 1.328658938407898
Validation loss: 1.9928012887636821

Epoch: 124| Step: 0
Training loss: 1.601257562637329
Validation loss: 2.037247637907664

Epoch: 6| Step: 1
Training loss: 1.1926374435424805
Validation loss: 2.043056229750315

Epoch: 6| Step: 2
Training loss: 1.6637377738952637
Validation loss: 2.007649521032969

Epoch: 6| Step: 3
Training loss: 1.5622063875198364
Validation loss: 2.0125274658203125

Epoch: 6| Step: 4
Training loss: 1.3166166543960571
Validation loss: 2.000765860080719

Epoch: 6| Step: 5
Training loss: 0.8821989297866821
Validation loss: 2.0643290082613626

Epoch: 6| Step: 6
Training loss: 0.9721906185150146
Validation loss: 2.061098317305247

Epoch: 6| Step: 7
Training loss: 1.021597146987915
Validation loss: 2.0531654953956604

Epoch: 6| Step: 8
Training loss: 1.6848325729370117
Validation loss: 2.0888732274373374

Epoch: 6| Step: 9
Training loss: 1.360974907875061
Validation loss: 2.062689185142517

Epoch: 6| Step: 10
Training loss: 1.1994438171386719
Validation loss: 2.0583785573641458

Epoch: 6| Step: 11
Training loss: 1.0912806987762451
Validation loss: 2.037510553995768

Epoch: 6| Step: 12
Training loss: 1.0881118774414062
Validation loss: 2.033365627129873

Epoch: 6| Step: 13
Training loss: 1.5884690284729004
Validation loss: 2.008821129798889

Epoch: 125| Step: 0
Training loss: 0.9512420892715454
Validation loss: 2.0109390219052634

Epoch: 6| Step: 1
Training loss: 1.7719959020614624
Validation loss: 2.0461296240488687

Epoch: 6| Step: 2
Training loss: 1.7688223123550415
Validation loss: 2.0449881553649902

Epoch: 6| Step: 3
Training loss: 0.808249831199646
Validation loss: 2.0307846864064536

Epoch: 6| Step: 4
Training loss: 1.376434564590454
Validation loss: 2.041520655155182

Epoch: 6| Step: 5
Training loss: 1.0614750385284424
Validation loss: 2.070060153802236

Epoch: 6| Step: 6
Training loss: 1.5525555610656738
Validation loss: 2.0724592208862305

Epoch: 6| Step: 7
Training loss: 1.800705909729004
Validation loss: 1.9993102550506592

Epoch: 6| Step: 8
Training loss: 1.7849074602127075
Validation loss: 2.052367111047109

Epoch: 6| Step: 9
Training loss: 1.173901081085205
Validation loss: 2.0802207787831626

Epoch: 6| Step: 10
Training loss: 0.9937660694122314
Validation loss: 2.0622355937957764

Epoch: 6| Step: 11
Training loss: 0.9439821839332581
Validation loss: 2.0124412775039673

Epoch: 6| Step: 12
Training loss: 0.7600780725479126
Validation loss: 2.017858068148295

Epoch: 6| Step: 13
Training loss: 0.9358426928520203
Validation loss: 2.003192742665609

Epoch: 126| Step: 0
Training loss: 1.3969407081604004
Validation loss: 2.006824870904287

Epoch: 6| Step: 1
Training loss: 1.737569808959961
Validation loss: 2.020543376604716

Epoch: 6| Step: 2
Training loss: 1.1033196449279785
Validation loss: 2.015321413675944

Epoch: 6| Step: 3
Training loss: 1.3304332494735718
Validation loss: 2.0345762968063354

Epoch: 6| Step: 4
Training loss: 1.5471794605255127
Validation loss: 2.0239341855049133

Epoch: 6| Step: 5
Training loss: 1.134439468383789
Validation loss: 2.0463271737098694

Epoch: 6| Step: 6
Training loss: 1.1610536575317383
Validation loss: 1.9959024985631306

Epoch: 6| Step: 7
Training loss: 1.1506227254867554
Validation loss: 2.052580734093984

Epoch: 6| Step: 8
Training loss: 1.1269252300262451
Validation loss: 2.042181452115377

Epoch: 6| Step: 9
Training loss: 1.3892533779144287
Validation loss: 2.071499486764272

Epoch: 6| Step: 10
Training loss: 1.0304138660430908
Validation loss: 2.074160655339559

Epoch: 6| Step: 11
Training loss: 1.1965975761413574
Validation loss: 2.0730790495872498

Epoch: 6| Step: 12
Training loss: 1.1697579622268677
Validation loss: 2.035839398701986

Epoch: 6| Step: 13
Training loss: 1.2590795755386353
Validation loss: 1.9694767395655315

Epoch: 127| Step: 0
Training loss: 1.263817548751831
Validation loss: 2.0095543265342712

Epoch: 6| Step: 1
Training loss: 0.8792784810066223
Validation loss: 2.022375504175822

Epoch: 6| Step: 2
Training loss: 1.5810576677322388
Validation loss: 2.0486772457758584

Epoch: 6| Step: 3
Training loss: 1.3576942682266235
Validation loss: 2.019346614678701

Epoch: 6| Step: 4
Training loss: 1.1494953632354736
Validation loss: 2.0587790409723916

Epoch: 6| Step: 5
Training loss: 1.08414888381958
Validation loss: 2.0339942971865335

Epoch: 6| Step: 6
Training loss: 1.0667285919189453
Validation loss: 2.040533741315206

Epoch: 6| Step: 7
Training loss: 0.8368330001831055
Validation loss: 2.0015692710876465

Epoch: 6| Step: 8
Training loss: 1.12925124168396
Validation loss: 2.028068701426188

Epoch: 6| Step: 9
Training loss: 1.337066411972046
Validation loss: 2.0423779090245566

Epoch: 6| Step: 10
Training loss: 1.2048622369766235
Validation loss: 2.0053806702295938

Epoch: 6| Step: 11
Training loss: 1.2241806983947754
Validation loss: 2.044522702693939

Epoch: 6| Step: 12
Training loss: 1.8734667301177979
Validation loss: 2.041904409726461

Epoch: 6| Step: 13
Training loss: 1.306860327720642
Validation loss: 2.019839644432068

Epoch: 128| Step: 0
Training loss: 1.2721613645553589
Validation loss: 2.015073080857595

Epoch: 6| Step: 1
Training loss: 0.9852293729782104
Validation loss: 1.9992067615191143

Epoch: 6| Step: 2
Training loss: 1.3538427352905273
Validation loss: 2.0259732802708945

Epoch: 6| Step: 3
Training loss: 0.7569786310195923
Validation loss: 1.9926933248837788

Epoch: 6| Step: 4
Training loss: 0.6721486449241638
Validation loss: 2.0398311217625937

Epoch: 6| Step: 5
Training loss: 1.3569471836090088
Validation loss: 2.0420364141464233

Epoch: 6| Step: 6
Training loss: 1.2575538158416748
Validation loss: 2.0189635356267295

Epoch: 6| Step: 7
Training loss: 1.390912413597107
Validation loss: 2.038391351699829

Epoch: 6| Step: 8
Training loss: 1.2353368997573853
Validation loss: 2.0322169264157615

Epoch: 6| Step: 9
Training loss: 2.046327590942383
Validation loss: 2.038764794667562

Epoch: 6| Step: 10
Training loss: 1.4340428113937378
Validation loss: 2.0557457407315574

Epoch: 6| Step: 11
Training loss: 0.6957897543907166
Validation loss: 2.036322514216105

Epoch: 6| Step: 12
Training loss: 1.5280934572219849
Validation loss: 2.061919848124186

Epoch: 6| Step: 13
Training loss: 0.934807300567627
Validation loss: 2.0786349972089133

Epoch: 129| Step: 0
Training loss: 0.7206416130065918
Validation loss: 2.0511863430341086

Epoch: 6| Step: 1
Training loss: 1.2431774139404297
Validation loss: 2.03929469982783

Epoch: 6| Step: 2
Training loss: 1.1213715076446533
Validation loss: 2.0315013329188027

Epoch: 6| Step: 3
Training loss: 1.406977891921997
Validation loss: 2.006381412347158

Epoch: 6| Step: 4
Training loss: 0.8459434509277344
Validation loss: 2.0688925782839456

Epoch: 6| Step: 5
Training loss: 1.127927541732788
Validation loss: 2.074435830116272

Epoch: 6| Step: 6
Training loss: 1.4410895109176636
Validation loss: 2.034686108430227

Epoch: 6| Step: 7
Training loss: 1.1403344869613647
Validation loss: 2.056610941886902

Epoch: 6| Step: 8
Training loss: 1.5651543140411377
Validation loss: 2.0853784879048667

Epoch: 6| Step: 9
Training loss: 1.4075013399124146
Validation loss: 2.0931986371676126

Epoch: 6| Step: 10
Training loss: 1.452751874923706
Validation loss: 2.063542584578196

Epoch: 6| Step: 11
Training loss: 1.2018566131591797
Validation loss: 2.044930318991343

Epoch: 6| Step: 12
Training loss: 1.4005913734436035
Validation loss: 2.04562779267629

Epoch: 6| Step: 13
Training loss: 1.2309691905975342
Validation loss: 2.084199051062266

Epoch: 130| Step: 0
Training loss: 0.7025550603866577
Validation loss: 2.0223461786905923

Epoch: 6| Step: 1
Training loss: 1.5270088911056519
Validation loss: 2.0274691383043923

Epoch: 6| Step: 2
Training loss: 1.210773229598999
Validation loss: 2.0266307592391968

Epoch: 6| Step: 3
Training loss: 1.3380459547042847
Validation loss: 1.9896838466326396

Epoch: 6| Step: 4
Training loss: 1.3908801078796387
Validation loss: 2.0425689220428467

Epoch: 6| Step: 5
Training loss: 1.467149257659912
Validation loss: 2.027132034301758

Epoch: 6| Step: 6
Training loss: 1.4747352600097656
Validation loss: 2.062713146209717

Epoch: 6| Step: 7
Training loss: 1.1135517358779907
Validation loss: 2.057552436987559

Epoch: 6| Step: 8
Training loss: 0.6556143164634705
Validation loss: 2.0445544123649597

Epoch: 6| Step: 9
Training loss: 0.8392106294631958
Validation loss: 2.075151960055033

Epoch: 6| Step: 10
Training loss: 0.8182275295257568
Validation loss: 2.0440327525138855

Epoch: 6| Step: 11
Training loss: 1.7205517292022705
Validation loss: 2.038749396800995

Epoch: 6| Step: 12
Training loss: 0.9515766501426697
Validation loss: 2.0454047322273254

Epoch: 6| Step: 13
Training loss: 1.6233049631118774
Validation loss: 2.0162391861279807

Epoch: 131| Step: 0
Training loss: 1.365602970123291
Validation loss: 2.052899201711019

Epoch: 6| Step: 1
Training loss: 1.1967891454696655
Validation loss: 2.0497267643610635

Epoch: 6| Step: 2
Training loss: 1.1071584224700928
Validation loss: 2.061986784140269

Epoch: 6| Step: 3
Training loss: 1.1812543869018555
Validation loss: 2.074763536453247

Epoch: 6| Step: 4
Training loss: 1.2913703918457031
Validation loss: 2.0426262418429055

Epoch: 6| Step: 5
Training loss: 1.0768370628356934
Validation loss: 2.0635802348454795

Epoch: 6| Step: 6
Training loss: 0.9058139324188232
Validation loss: 2.03493469953537

Epoch: 6| Step: 7
Training loss: 1.1125712394714355
Validation loss: 2.0558555722236633

Epoch: 6| Step: 8
Training loss: 1.4035491943359375
Validation loss: 2.0112986167271933

Epoch: 6| Step: 9
Training loss: 1.2090356349945068
Validation loss: 2.0284658869107566

Epoch: 6| Step: 10
Training loss: 0.747122049331665
Validation loss: 2.0580732027689614

Epoch: 6| Step: 11
Training loss: 1.0708129405975342
Validation loss: 2.048047105471293

Epoch: 6| Step: 12
Training loss: 1.6302332878112793
Validation loss: 2.108326017856598

Epoch: 6| Step: 13
Training loss: 1.1075365543365479
Validation loss: 2.0534161726633706

Epoch: 132| Step: 0
Training loss: 0.7433432936668396
Validation loss: 2.079935053984324

Epoch: 6| Step: 1
Training loss: 0.9981439113616943
Validation loss: 2.0772327184677124

Epoch: 6| Step: 2
Training loss: 1.2031214237213135
Validation loss: 2.0550090074539185

Epoch: 6| Step: 3
Training loss: 1.2904653549194336
Validation loss: 2.0667545398076377

Epoch: 6| Step: 4
Training loss: 0.9555928707122803
Validation loss: 2.0615877707799277

Epoch: 6| Step: 5
Training loss: 1.3254039287567139
Validation loss: 2.0520660082499185

Epoch: 6| Step: 6
Training loss: 0.8229745030403137
Validation loss: 2.0160262982050576

Epoch: 6| Step: 7
Training loss: 1.664158582687378
Validation loss: 2.0062938928604126

Epoch: 6| Step: 8
Training loss: 0.6679791212081909
Validation loss: 2.0329660773277283

Epoch: 6| Step: 9
Training loss: 1.1561861038208008
Validation loss: 2.0459460020065308

Epoch: 6| Step: 10
Training loss: 1.496756672859192
Validation loss: 2.017382800579071

Epoch: 6| Step: 11
Training loss: 1.0934325456619263
Validation loss: 2.0447842876116433

Epoch: 6| Step: 12
Training loss: 1.6051945686340332
Validation loss: 2.045010725657145

Epoch: 6| Step: 13
Training loss: 1.2146506309509277
Validation loss: 2.0298710664113364

Epoch: 133| Step: 0
Training loss: 1.1481952667236328
Validation loss: 2.0639870166778564

Epoch: 6| Step: 1
Training loss: 1.1868633031845093
Validation loss: 2.0204517443974814

Epoch: 6| Step: 2
Training loss: 1.8581000566482544
Validation loss: 2.0127150217692056

Epoch: 6| Step: 3
Training loss: 0.6886863708496094
Validation loss: 2.042089521884918

Epoch: 6| Step: 4
Training loss: 1.083277702331543
Validation loss: 2.0657286643981934

Epoch: 6| Step: 5
Training loss: 1.2654913663864136
Validation loss: 2.0087641874949136

Epoch: 6| Step: 6
Training loss: 1.233973741531372
Validation loss: 2.0420769651730857

Epoch: 6| Step: 7
Training loss: 0.5561493039131165
Validation loss: 2.0340932408968606

Epoch: 6| Step: 8
Training loss: 1.5823670625686646
Validation loss: 2.0659689704577127

Epoch: 6| Step: 9
Training loss: 1.0884597301483154
Validation loss: 2.039087394873301

Epoch: 6| Step: 10
Training loss: 1.0125432014465332
Validation loss: 2.027658224105835

Epoch: 6| Step: 11
Training loss: 1.6120936870574951
Validation loss: 2.003413816293081

Epoch: 6| Step: 12
Training loss: 0.8393329381942749
Validation loss: 2.0600189765294394

Epoch: 6| Step: 13
Training loss: 0.903465986251831
Validation loss: 2.03781928618749

Epoch: 134| Step: 0
Training loss: 1.2638697624206543
Validation loss: 1.9924073417981465

Epoch: 6| Step: 1
Training loss: 0.8250958919525146
Validation loss: 2.0072575211524963

Epoch: 6| Step: 2
Training loss: 0.9324322938919067
Validation loss: 2.032594402631124

Epoch: 6| Step: 3
Training loss: 1.1459382772445679
Validation loss: 2.0302743713061013

Epoch: 6| Step: 4
Training loss: 1.2700244188308716
Validation loss: 2.0550171931584678

Epoch: 6| Step: 5
Training loss: 1.4807991981506348
Validation loss: 2.0425991217295327

Epoch: 6| Step: 6
Training loss: 1.7888972759246826
Validation loss: 2.0411424040794373

Epoch: 6| Step: 7
Training loss: 1.6780133247375488
Validation loss: 2.045729160308838

Epoch: 6| Step: 8
Training loss: 1.0972820520401
Validation loss: 2.0176839431126914

Epoch: 6| Step: 9
Training loss: 0.7682889699935913
Validation loss: 2.032474378744761

Epoch: 6| Step: 10
Training loss: 0.7390632629394531
Validation loss: 2.0526552200317383

Epoch: 6| Step: 11
Training loss: 0.8693314790725708
Validation loss: 2.0186253786087036

Epoch: 6| Step: 12
Training loss: 0.42386722564697266
Validation loss: 2.0301407972971597

Epoch: 6| Step: 13
Training loss: 1.4702820777893066
Validation loss: 2.059522489706675

Epoch: 135| Step: 0
Training loss: 0.9108061790466309
Validation loss: 2.0703540643056235

Epoch: 6| Step: 1
Training loss: 0.6140022277832031
Validation loss: 2.0231948494911194

Epoch: 6| Step: 2
Training loss: 0.8409734964370728
Validation loss: 2.047176798184713

Epoch: 6| Step: 3
Training loss: 0.9707939028739929
Validation loss: 2.039853811264038

Epoch: 6| Step: 4
Training loss: 1.151849389076233
Validation loss: 2.0602641900380454

Epoch: 6| Step: 5
Training loss: 1.2709686756134033
Validation loss: 2.0190556049346924

Epoch: 6| Step: 6
Training loss: 1.1709129810333252
Validation loss: 2.0564674536387124

Epoch: 6| Step: 7
Training loss: 1.2802371978759766
Validation loss: 2.009053111076355

Epoch: 6| Step: 8
Training loss: 1.3912746906280518
Validation loss: 2.0680399338404336

Epoch: 6| Step: 9
Training loss: 1.2817792892456055
Validation loss: 2.0528149803479514

Epoch: 6| Step: 10
Training loss: 1.4765232801437378
Validation loss: 2.0345032811164856

Epoch: 6| Step: 11
Training loss: 1.2525516748428345
Validation loss: 2.050764481226603

Epoch: 6| Step: 12
Training loss: 0.6895955801010132
Validation loss: 1.9899543921152751

Epoch: 6| Step: 13
Training loss: 1.0344111919403076
Validation loss: 1.9829736550649006

Epoch: 136| Step: 0
Training loss: 0.7353340983390808
Validation loss: 2.020844042301178

Epoch: 6| Step: 1
Training loss: 1.1427216529846191
Validation loss: 2.0110188523928323

Epoch: 6| Step: 2
Training loss: 1.1677074432373047
Validation loss: 2.0251060326894126

Epoch: 6| Step: 3
Training loss: 1.349015712738037
Validation loss: 2.0456328789393106

Epoch: 6| Step: 4
Training loss: 0.9994881749153137
Validation loss: 2.043063541253408

Epoch: 6| Step: 5
Training loss: 1.0405521392822266
Validation loss: 1.9980558355649312

Epoch: 6| Step: 6
Training loss: 1.4736504554748535
Validation loss: 2.04325799147288

Epoch: 6| Step: 7
Training loss: 1.522648811340332
Validation loss: 2.0322000781695047

Epoch: 6| Step: 8
Training loss: 1.369673490524292
Validation loss: 2.0387455026308694

Epoch: 6| Step: 9
Training loss: 1.0059126615524292
Validation loss: 2.0678860743840537

Epoch: 6| Step: 10
Training loss: 0.7347198724746704
Validation loss: 2.0017780860265098

Epoch: 6| Step: 11
Training loss: 0.9919144511222839
Validation loss: 2.0535056789716086

Epoch: 6| Step: 12
Training loss: 1.1235897541046143
Validation loss: 2.028617739677429

Epoch: 6| Step: 13
Training loss: 1.3946489095687866
Validation loss: 2.080070455869039

Epoch: 137| Step: 0
Training loss: 1.4124672412872314
Validation loss: 2.071161230405172

Epoch: 6| Step: 1
Training loss: 1.0733051300048828
Validation loss: 2.0844451785087585

Epoch: 6| Step: 2
Training loss: 1.1278026103973389
Validation loss: 2.0437222123146057

Epoch: 6| Step: 3
Training loss: 1.5511374473571777
Validation loss: 2.0178733269373574

Epoch: 6| Step: 4
Training loss: 1.2408409118652344
Validation loss: 2.001088639100393

Epoch: 6| Step: 5
Training loss: 1.0606160163879395
Validation loss: 2.024808406829834

Epoch: 6| Step: 6
Training loss: 1.0056320428848267
Validation loss: 2.0401177406311035

Epoch: 6| Step: 7
Training loss: 0.8781110644340515
Validation loss: 2.022686262925466

Epoch: 6| Step: 8
Training loss: 0.9844246506690979
Validation loss: 2.0602502822875977

Epoch: 6| Step: 9
Training loss: 1.1397567987442017
Validation loss: 2.020230690638224

Epoch: 6| Step: 10
Training loss: 0.9764699935913086
Validation loss: 2.0498307943344116

Epoch: 6| Step: 11
Training loss: 0.8597488403320312
Validation loss: 2.0387089252471924

Epoch: 6| Step: 12
Training loss: 1.0261495113372803
Validation loss: 2.068566838900248

Epoch: 6| Step: 13
Training loss: 1.67335844039917
Validation loss: 2.0395872990290322

Epoch: 138| Step: 0
Training loss: 0.9249400496482849
Validation loss: 2.044726610183716

Epoch: 6| Step: 1
Training loss: 1.0666863918304443
Validation loss: 2.0821033318837485

Epoch: 6| Step: 2
Training loss: 1.1638720035552979
Validation loss: 2.057682752609253

Epoch: 6| Step: 3
Training loss: 1.3367724418640137
Validation loss: 2.0412174264589944

Epoch: 6| Step: 4
Training loss: 1.217448115348816
Validation loss: 2.0289024313290915

Epoch: 6| Step: 5
Training loss: 1.4045231342315674
Validation loss: 2.0776137908299765

Epoch: 6| Step: 6
Training loss: 1.5180249214172363
Validation loss: 1.9925198554992676

Epoch: 6| Step: 7
Training loss: 1.2891104221343994
Validation loss: 2.0313209295272827

Epoch: 6| Step: 8
Training loss: 0.7099742293357849
Validation loss: 2.0405733386675515

Epoch: 6| Step: 9
Training loss: 0.8898882865905762
Validation loss: 2.0231228272120156

Epoch: 6| Step: 10
Training loss: 0.5910487771034241
Validation loss: 2.0429416497548423

Epoch: 6| Step: 11
Training loss: 0.991496741771698
Validation loss: 2.0534246365229287

Epoch: 6| Step: 12
Training loss: 1.5338170528411865
Validation loss: 2.0575059056282043

Epoch: 6| Step: 13
Training loss: 1.2581653594970703
Validation loss: 2.0435839891433716

Epoch: 139| Step: 0
Training loss: 1.127718448638916
Validation loss: 2.0807387232780457

Epoch: 6| Step: 1
Training loss: 0.5727301836013794
Validation loss: 2.1084110736846924

Epoch: 6| Step: 2
Training loss: 1.206482172012329
Validation loss: 2.092441141605377

Epoch: 6| Step: 3
Training loss: 1.0575143098831177
Validation loss: 2.0621506373087564

Epoch: 6| Step: 4
Training loss: 1.7659335136413574
Validation loss: 2.0531322360038757

Epoch: 6| Step: 5
Training loss: 1.0830448865890503
Validation loss: 2.051225562890371

Epoch: 6| Step: 6
Training loss: 1.5461429357528687
Validation loss: 2.027108907699585

Epoch: 6| Step: 7
Training loss: 1.2469788789749146
Validation loss: 2.0407311717669168

Epoch: 6| Step: 8
Training loss: 1.1347217559814453
Validation loss: 2.044651826222738

Epoch: 6| Step: 9
Training loss: 1.0256462097167969
Validation loss: 2.028072456518809

Epoch: 6| Step: 10
Training loss: 1.5030012130737305
Validation loss: 2.054835617542267

Epoch: 6| Step: 11
Training loss: 1.2697752714157104
Validation loss: 1.9920064608256023

Epoch: 6| Step: 12
Training loss: 0.8237892389297485
Validation loss: 2.034944176673889

Epoch: 6| Step: 13
Training loss: 0.8507760763168335
Validation loss: 2.0278802514076233

Epoch: 140| Step: 0
Training loss: 1.263150691986084
Validation loss: 2.046731173992157

Epoch: 6| Step: 1
Training loss: 1.5896210670471191
Validation loss: 2.0333160758018494

Epoch: 6| Step: 2
Training loss: 0.851744532585144
Validation loss: 2.0594497124354043

Epoch: 6| Step: 3
Training loss: 1.3365545272827148
Validation loss: 2.0209138790766397

Epoch: 6| Step: 4
Training loss: 0.7606452703475952
Validation loss: 2.0297102530797324

Epoch: 6| Step: 5
Training loss: 1.0984606742858887
Validation loss: 2.0016201734542847

Epoch: 6| Step: 6
Training loss: 1.4295389652252197
Validation loss: 2.012019375960032

Epoch: 6| Step: 7
Training loss: 1.0099601745605469
Validation loss: 2.0172688563664756

Epoch: 6| Step: 8
Training loss: 0.7724950313568115
Validation loss: 2.078179101149241

Epoch: 6| Step: 9
Training loss: 1.2735732793807983
Validation loss: 2.0652078787485757

Epoch: 6| Step: 10
Training loss: 1.1662468910217285
Validation loss: 1.9889337023099263

Epoch: 6| Step: 11
Training loss: 1.0477995872497559
Validation loss: 2.060564080874125

Epoch: 6| Step: 12
Training loss: 1.0887073278427124
Validation loss: 2.0244088768959045

Epoch: 6| Step: 13
Training loss: 0.676604688167572
Validation loss: 2.0511159896850586

Epoch: 141| Step: 0
Training loss: 0.8706965446472168
Validation loss: 2.0478797356287637

Epoch: 6| Step: 1
Training loss: 1.051718831062317
Validation loss: 2.0398067235946655

Epoch: 6| Step: 2
Training loss: 0.8598840236663818
Validation loss: 2.027511239051819

Epoch: 6| Step: 3
Training loss: 1.079067349433899
Validation loss: 2.085391362508138

Epoch: 6| Step: 4
Training loss: 1.2688685655593872
Validation loss: 2.0013517141342163

Epoch: 6| Step: 5
Training loss: 1.3690850734710693
Validation loss: 2.002453923225403

Epoch: 6| Step: 6
Training loss: 1.5844385623931885
Validation loss: 2.036149799823761

Epoch: 6| Step: 7
Training loss: 0.7998600602149963
Validation loss: 2.0393341978391013

Epoch: 6| Step: 8
Training loss: 0.7156273126602173
Validation loss: 2.0427983005841575

Epoch: 6| Step: 9
Training loss: 0.47995662689208984
Validation loss: 2.0224883556365967

Epoch: 6| Step: 10
Training loss: 1.8707168102264404
Validation loss: 2.0139715671539307

Epoch: 6| Step: 11
Training loss: 1.061633825302124
Validation loss: 2.0174331267674765

Epoch: 6| Step: 12
Training loss: 0.661630392074585
Validation loss: 2.0195717414220176

Epoch: 6| Step: 13
Training loss: 1.3511532545089722
Validation loss: 2.0393941402435303

Epoch: 142| Step: 0
Training loss: 1.1514759063720703
Validation loss: 1.9980510274569194

Epoch: 6| Step: 1
Training loss: 1.3177390098571777
Validation loss: 2.033738116423289

Epoch: 6| Step: 2
Training loss: 0.7224044799804688
Validation loss: 2.0546447038650513

Epoch: 6| Step: 3
Training loss: 1.8744828701019287
Validation loss: 2.057357927163442

Epoch: 6| Step: 4
Training loss: 0.8727726340293884
Validation loss: 2.114589790503184

Epoch: 6| Step: 5
Training loss: 0.7832443714141846
Validation loss: 2.04821648200353

Epoch: 6| Step: 6
Training loss: 1.1075630187988281
Validation loss: 2.053925712903341

Epoch: 6| Step: 7
Training loss: 1.3754222393035889
Validation loss: 2.01903243859609

Epoch: 6| Step: 8
Training loss: 0.7058675289154053
Validation loss: 2.0296250581741333

Epoch: 6| Step: 9
Training loss: 1.0737109184265137
Validation loss: 2.009609321753184

Epoch: 6| Step: 10
Training loss: 0.6959985494613647
Validation loss: 1.9804317553838093

Epoch: 6| Step: 11
Training loss: 0.9772945642471313
Validation loss: 2.0350259939829507

Epoch: 6| Step: 12
Training loss: 1.0980823040008545
Validation loss: 2.052874207496643

Epoch: 6| Step: 13
Training loss: 1.142942190170288
Validation loss: 2.002414067586263

Epoch: 143| Step: 0
Training loss: 0.7447938919067383
Validation loss: 2.041808287302653

Epoch: 6| Step: 1
Training loss: 1.4787178039550781
Validation loss: 1.9994615316390991

Epoch: 6| Step: 2
Training loss: 1.458083152770996
Validation loss: 1.971333642800649

Epoch: 6| Step: 3
Training loss: 0.9559924602508545
Validation loss: 2.061365842819214

Epoch: 6| Step: 4
Training loss: 0.841641366481781
Validation loss: 2.0166917045911155

Epoch: 6| Step: 5
Training loss: 1.3828465938568115
Validation loss: 2.0469220678011575

Epoch: 6| Step: 6
Training loss: 1.152050256729126
Validation loss: 2.021985093752543

Epoch: 6| Step: 7
Training loss: 0.9835696816444397
Validation loss: 2.0700450340906777

Epoch: 6| Step: 8
Training loss: 0.8778883218765259
Validation loss: 2.03905842701594

Epoch: 6| Step: 9
Training loss: 1.4222694635391235
Validation loss: 2.049219489097595

Epoch: 6| Step: 10
Training loss: 0.9079722166061401
Validation loss: 2.0640124082565308

Epoch: 6| Step: 11
Training loss: 0.759979248046875
Validation loss: 2.026139477888743

Epoch: 6| Step: 12
Training loss: 1.19157075881958
Validation loss: 2.0473425587018332

Epoch: 6| Step: 13
Training loss: 0.9826575517654419
Validation loss: 1.991159200668335

Epoch: 144| Step: 0
Training loss: 1.0085633993148804
Validation loss: 2.0234247048695884

Epoch: 6| Step: 1
Training loss: 0.9119418859481812
Validation loss: 2.0825459957122803

Epoch: 6| Step: 2
Training loss: 0.8353292942047119
Validation loss: 2.0007739464441934

Epoch: 6| Step: 3
Training loss: 1.4090956449508667
Validation loss: 2.0483019749323526

Epoch: 6| Step: 4
Training loss: 1.1278021335601807
Validation loss: 2.0353244145711265

Epoch: 6| Step: 5
Training loss: 0.8489113450050354
Validation loss: 2.0486870805422464

Epoch: 6| Step: 6
Training loss: 1.1310960054397583
Validation loss: 2.102155029773712

Epoch: 6| Step: 7
Training loss: 0.62644362449646
Validation loss: 2.069676140944163

Epoch: 6| Step: 8
Training loss: 1.8498547077178955
Validation loss: 2.058760484059652

Epoch: 6| Step: 9
Training loss: 0.8085024356842041
Validation loss: 2.0455772280693054

Epoch: 6| Step: 10
Training loss: 0.8154309391975403
Validation loss: 2.029447873433431

Epoch: 6| Step: 11
Training loss: 0.9922953844070435
Validation loss: 2.0675869385401406

Epoch: 6| Step: 12
Training loss: 0.8258653879165649
Validation loss: 2.022714694341024

Epoch: 6| Step: 13
Training loss: 1.0150407552719116
Validation loss: 2.0256892244021096

Epoch: 145| Step: 0
Training loss: 1.0160439014434814
Validation loss: 2.065865139166514

Epoch: 6| Step: 1
Training loss: 0.8856251835823059
Validation loss: 2.0123992363611856

Epoch: 6| Step: 2
Training loss: 1.0547930002212524
Validation loss: 2.0989232261975608

Epoch: 6| Step: 3
Training loss: 0.9326428174972534
Validation loss: 2.0411882996559143

Epoch: 6| Step: 4
Training loss: 1.1286964416503906
Validation loss: 2.012055973211924

Epoch: 6| Step: 5
Training loss: 1.1538901329040527
Validation loss: 2.0460909008979797

Epoch: 6| Step: 6
Training loss: 0.9918192625045776
Validation loss: 2.0400232871373496

Epoch: 6| Step: 7
Training loss: 0.8503669500350952
Validation loss: 2.0371842781702676

Epoch: 6| Step: 8
Training loss: 1.0862069129943848
Validation loss: 2.0589087208112082

Epoch: 6| Step: 9
Training loss: 1.092423439025879
Validation loss: 2.0614863435427346

Epoch: 6| Step: 10
Training loss: 0.781023383140564
Validation loss: 2.0505845149358115

Epoch: 6| Step: 11
Training loss: 1.1063740253448486
Validation loss: 2.044731100400289

Epoch: 6| Step: 12
Training loss: 0.8536489009857178
Validation loss: 2.0385989348093667

Epoch: 6| Step: 13
Training loss: 0.9228096604347229
Validation loss: 2.074051002661387

Epoch: 146| Step: 0
Training loss: 0.7935456037521362
Validation loss: 2.0061422983805337

Epoch: 6| Step: 1
Training loss: 1.3697364330291748
Validation loss: 2.0655240416526794

Epoch: 6| Step: 2
Training loss: 0.8737302422523499
Validation loss: 2.078743636608124

Epoch: 6| Step: 3
Training loss: 1.0864613056182861
Validation loss: 2.031765321890513

Epoch: 6| Step: 4
Training loss: 1.21125066280365
Validation loss: 2.0394004384676614

Epoch: 6| Step: 5
Training loss: 0.7432200908660889
Validation loss: 2.0240864952405295

Epoch: 6| Step: 6
Training loss: 1.192997932434082
Validation loss: 2.07647051413854

Epoch: 6| Step: 7
Training loss: 1.38364839553833
Validation loss: 2.0384803215662637

Epoch: 6| Step: 8
Training loss: 0.8112689852714539
Validation loss: 2.014869530995687

Epoch: 6| Step: 9
Training loss: 0.8062974810600281
Validation loss: 2.020017127195994

Epoch: 6| Step: 10
Training loss: 1.4110000133514404
Validation loss: 2.047755181789398

Epoch: 6| Step: 11
Training loss: 0.7300499677658081
Validation loss: 2.003802220026652

Epoch: 6| Step: 12
Training loss: 0.6135492324829102
Validation loss: 1.9781609376271565

Epoch: 6| Step: 13
Training loss: 0.9934412837028503
Validation loss: 2.0292396346728006

Epoch: 147| Step: 0
Training loss: 0.5957084894180298
Validation loss: 1.9852060675621033

Epoch: 6| Step: 1
Training loss: 0.5108627676963806
Validation loss: 2.017188628514608

Epoch: 6| Step: 2
Training loss: 1.099229335784912
Validation loss: 2.0813167889912925

Epoch: 6| Step: 3
Training loss: 1.0008357763290405
Validation loss: 2.0391425689061484

Epoch: 6| Step: 4
Training loss: 0.8856141567230225
Validation loss: 1.985965649286906

Epoch: 6| Step: 5
Training loss: 2.034538507461548
Validation loss: 1.99675852060318

Epoch: 6| Step: 6
Training loss: 0.7544217109680176
Validation loss: 2.037306567033132

Epoch: 6| Step: 7
Training loss: 1.481008768081665
Validation loss: 1.9921570022900899

Epoch: 6| Step: 8
Training loss: 0.8668349981307983
Validation loss: 1.9701832135518391

Epoch: 6| Step: 9
Training loss: 0.9250648021697998
Validation loss: 1.9879109064737956

Epoch: 6| Step: 10
Training loss: 0.6267450451850891
Validation loss: 2.0388930837313333

Epoch: 6| Step: 11
Training loss: 1.0605542659759521
Validation loss: 2.0478339393933616

Epoch: 6| Step: 12
Training loss: 0.826687216758728
Validation loss: 2.0645535786946616

Epoch: 6| Step: 13
Training loss: 1.4391298294067383
Validation loss: 2.032486001650492

Epoch: 148| Step: 0
Training loss: 1.0674314498901367
Validation loss: 2.0371379256248474

Epoch: 6| Step: 1
Training loss: 1.0378084182739258
Validation loss: 2.0208263198534646

Epoch: 6| Step: 2
Training loss: 0.9210391044616699
Validation loss: 1.998508056004842

Epoch: 6| Step: 3
Training loss: 0.6295428276062012
Validation loss: 2.0291517972946167

Epoch: 6| Step: 4
Training loss: 0.8212951421737671
Validation loss: 2.0268681049346924

Epoch: 6| Step: 5
Training loss: 1.0755841732025146
Validation loss: 2.019973854223887

Epoch: 6| Step: 6
Training loss: 1.3232476711273193
Validation loss: 2.013658106327057

Epoch: 6| Step: 7
Training loss: 0.9296351671218872
Validation loss: 2.040147920449575

Epoch: 6| Step: 8
Training loss: 1.715678095817566
Validation loss: 2.0353742837905884

Epoch: 6| Step: 9
Training loss: 0.6450579166412354
Validation loss: 2.0312746167182922

Epoch: 6| Step: 10
Training loss: 0.9765487909317017
Validation loss: 2.0075095891952515

Epoch: 6| Step: 11
Training loss: 0.7278724908828735
Validation loss: 2.0244188706080117

Epoch: 6| Step: 12
Training loss: 0.6188194751739502
Validation loss: 2.028039892514547

Epoch: 6| Step: 13
Training loss: 0.835406482219696
Validation loss: 2.0580161015192666

Epoch: 149| Step: 0
Training loss: 1.4508479833602905
Validation loss: 2.0282216668128967

Epoch: 6| Step: 1
Training loss: 1.102020263671875
Validation loss: 2.0079010923703513

Epoch: 6| Step: 2
Training loss: 0.44148707389831543
Validation loss: 2.0188376903533936

Epoch: 6| Step: 3
Training loss: 0.5561867952346802
Validation loss: 1.9923760096232097

Epoch: 6| Step: 4
Training loss: 1.0303651094436646
Validation loss: 2.026238441467285

Epoch: 6| Step: 5
Training loss: 0.9766027331352234
Validation loss: 2.070921162764231

Epoch: 6| Step: 6
Training loss: 1.06825852394104
Validation loss: 2.0193217396736145

Epoch: 6| Step: 7
Training loss: 0.7511070966720581
Validation loss: 2.021718998750051

Epoch: 6| Step: 8
Training loss: 1.3836849927902222
Validation loss: 2.0194301207860312

Epoch: 6| Step: 9
Training loss: 1.3985365629196167
Validation loss: 2.00929989417394

Epoch: 6| Step: 10
Training loss: 0.7245245575904846
Validation loss: 2.019059697786967

Epoch: 6| Step: 11
Training loss: 1.3146858215332031
Validation loss: 2.1086214184761047

Epoch: 6| Step: 12
Training loss: 0.5847039222717285
Validation loss: 2.0458622574806213

Epoch: 6| Step: 13
Training loss: 0.8819570541381836
Validation loss: 2.041085739930471

Epoch: 150| Step: 0
Training loss: 0.5207511186599731
Validation loss: 2.0259465177853904

Epoch: 6| Step: 1
Training loss: 0.6895245313644409
Validation loss: 2.042256474494934

Epoch: 6| Step: 2
Training loss: 1.1936172246932983
Validation loss: 2.006808042526245

Epoch: 6| Step: 3
Training loss: 0.7970268726348877
Validation loss: 2.030525326728821

Epoch: 6| Step: 4
Training loss: 1.0346226692199707
Validation loss: 2.0369184017181396

Epoch: 6| Step: 5
Training loss: 0.7145559191703796
Validation loss: 2.008565386136373

Epoch: 6| Step: 6
Training loss: 0.950251579284668
Validation loss: 2.0501550833384194

Epoch: 6| Step: 7
Training loss: 1.102091908454895
Validation loss: 2.0294573505719504

Epoch: 6| Step: 8
Training loss: 1.2954163551330566
Validation loss: 2.0414214730262756

Epoch: 6| Step: 9
Training loss: 0.8225065469741821
Validation loss: 2.044289509455363

Epoch: 6| Step: 10
Training loss: 0.738020658493042
Validation loss: 2.0211175282796225

Epoch: 6| Step: 11
Training loss: 0.8970014452934265
Validation loss: 2.0467026432355246

Epoch: 6| Step: 12
Training loss: 1.4430845975875854
Validation loss: 2.034067392349243

Epoch: 6| Step: 13
Training loss: 1.2418789863586426
Validation loss: 1.9940839608510335

Epoch: 151| Step: 0
Training loss: 1.2038285732269287
Validation loss: 2.060706396897634

Epoch: 6| Step: 1
Training loss: 0.9674538373947144
Validation loss: 2.0258258978525796

Epoch: 6| Step: 2
Training loss: 1.2496165037155151
Validation loss: 2.006063441435496

Epoch: 6| Step: 3
Training loss: 0.934989333152771
Validation loss: 2.014667332172394

Epoch: 6| Step: 4
Training loss: 0.766389012336731
Validation loss: 2.0545575618743896

Epoch: 6| Step: 5
Training loss: 1.3719696998596191
Validation loss: 2.0270523031552634

Epoch: 6| Step: 6
Training loss: 0.8123281002044678
Validation loss: 2.0126765966415405

Epoch: 6| Step: 7
Training loss: 0.5013270378112793
Validation loss: 2.0351462960243225

Epoch: 6| Step: 8
Training loss: 1.1592406034469604
Validation loss: 1.989369809627533

Epoch: 6| Step: 9
Training loss: 1.0847141742706299
Validation loss: 2.0291007359822593

Epoch: 6| Step: 10
Training loss: 0.596338152885437
Validation loss: 2.0071640809377036

Epoch: 6| Step: 11
Training loss: 0.5487978458404541
Validation loss: 1.9984187285105388

Epoch: 6| Step: 12
Training loss: 0.9714170694351196
Validation loss: 2.0427460074424744

Epoch: 6| Step: 13
Training loss: 1.049884557723999
Validation loss: 2.0492056409517923

Epoch: 152| Step: 0
Training loss: 1.1432677507400513
Validation loss: 2.072739541530609

Epoch: 6| Step: 1
Training loss: 0.5604671835899353
Validation loss: 2.0522952874501548

Epoch: 6| Step: 2
Training loss: 1.4019896984100342
Validation loss: 2.0588523149490356

Epoch: 6| Step: 3
Training loss: 0.6724979877471924
Validation loss: 2.0093708634376526

Epoch: 6| Step: 4
Training loss: 0.7677301168441772
Validation loss: 2.060745199521383

Epoch: 6| Step: 5
Training loss: 0.8266786336898804
Validation loss: 2.0509811441103616

Epoch: 6| Step: 6
Training loss: 1.2654874324798584
Validation loss: 2.0520514647165933

Epoch: 6| Step: 7
Training loss: 0.9549911022186279
Validation loss: 2.027226706345876

Epoch: 6| Step: 8
Training loss: 1.455080509185791
Validation loss: 2.007308622201284

Epoch: 6| Step: 9
Training loss: 0.8035609722137451
Validation loss: 2.0921247402826944

Epoch: 6| Step: 10
Training loss: 1.2835302352905273
Validation loss: 2.036653300126394

Epoch: 6| Step: 11
Training loss: 0.685219407081604
Validation loss: 2.0372305711110434

Epoch: 6| Step: 12
Training loss: 0.6102129220962524
Validation loss: 2.0807945330937705

Epoch: 6| Step: 13
Training loss: 0.938909649848938
Validation loss: 2.0394159158070884

Epoch: 153| Step: 0
Training loss: 1.0147051811218262
Validation loss: 2.0332565704981485

Epoch: 6| Step: 1
Training loss: 0.7076584100723267
Validation loss: 2.061896800994873

Epoch: 6| Step: 2
Training loss: 0.6456071138381958
Validation loss: 2.04949422677358

Epoch: 6| Step: 3
Training loss: 0.9291799664497375
Validation loss: 2.0496710538864136

Epoch: 6| Step: 4
Training loss: 1.0808043479919434
Validation loss: 2.078272044658661

Epoch: 6| Step: 5
Training loss: 1.112471580505371
Validation loss: 2.0145175059636435

Epoch: 6| Step: 6
Training loss: 1.1819047927856445
Validation loss: 2.038378417491913

Epoch: 6| Step: 7
Training loss: 1.2716249227523804
Validation loss: 2.0118075609207153

Epoch: 6| Step: 8
Training loss: 0.8228935599327087
Validation loss: 2.05328635374705

Epoch: 6| Step: 9
Training loss: 0.6700668334960938
Validation loss: 2.029993176460266

Epoch: 6| Step: 10
Training loss: 1.1108367443084717
Validation loss: 2.041232188542684

Epoch: 6| Step: 11
Training loss: 0.9540072679519653
Validation loss: 2.003525137901306

Epoch: 6| Step: 12
Training loss: 0.7733355760574341
Validation loss: 2.0413705507914224

Epoch: 6| Step: 13
Training loss: 1.0060276985168457
Validation loss: 1.988133708635966

Epoch: 154| Step: 0
Training loss: 0.8257523775100708
Validation loss: 2.049546758333842

Epoch: 6| Step: 1
Training loss: 0.7011969089508057
Validation loss: 2.0083958506584167

Epoch: 6| Step: 2
Training loss: 1.3301103115081787
Validation loss: 2.0307826598485312

Epoch: 6| Step: 3
Training loss: 1.01747465133667
Validation loss: 2.0324711004892984

Epoch: 6| Step: 4
Training loss: 0.9645097255706787
Validation loss: 1.9940998752911885

Epoch: 6| Step: 5
Training loss: 1.0994850397109985
Validation loss: 2.0237967371940613

Epoch: 6| Step: 6
Training loss: 1.0166571140289307
Validation loss: 2.007654865582784

Epoch: 6| Step: 7
Training loss: 1.1190054416656494
Validation loss: 2.036157409350077

Epoch: 6| Step: 8
Training loss: 0.5961965322494507
Validation loss: 2.041514058907827

Epoch: 6| Step: 9
Training loss: 0.6897264719009399
Validation loss: 1.9799394408861797

Epoch: 6| Step: 10
Training loss: 0.5099847316741943
Validation loss: 2.007664461930593

Epoch: 6| Step: 11
Training loss: 0.9432952404022217
Validation loss: 2.0557497342427573

Epoch: 6| Step: 12
Training loss: 0.931438684463501
Validation loss: 1.9953688581784566

Epoch: 6| Step: 13
Training loss: 1.042486310005188
Validation loss: 2.015218734741211

Epoch: 155| Step: 0
Training loss: 0.5662384033203125
Validation loss: 2.028274893760681

Epoch: 6| Step: 1
Training loss: 0.8821846842765808
Validation loss: 2.0082781314849854

Epoch: 6| Step: 2
Training loss: 1.4806783199310303
Validation loss: 1.9499032894770305

Epoch: 6| Step: 3
Training loss: 0.9870085716247559
Validation loss: 2.0553525487581887

Epoch: 6| Step: 4
Training loss: 1.0731440782546997
Validation loss: 2.0518736441930137

Epoch: 6| Step: 5
Training loss: 0.7717195749282837
Validation loss: 1.9677913188934326

Epoch: 6| Step: 6
Training loss: 0.9137243628501892
Validation loss: 2.01451708873113

Epoch: 6| Step: 7
Training loss: 0.6984912157058716
Validation loss: 2.020954112211863

Epoch: 6| Step: 8
Training loss: 0.8125168681144714
Validation loss: 2.0651080211003623

Epoch: 6| Step: 9
Training loss: 0.6565089821815491
Validation loss: 2.014903704325358

Epoch: 6| Step: 10
Training loss: 1.5148051977157593
Validation loss: 1.9968992471694946

Epoch: 6| Step: 11
Training loss: 1.160110354423523
Validation loss: 2.029652794202169

Epoch: 6| Step: 12
Training loss: 0.6616254448890686
Validation loss: 1.9901664853096008

Epoch: 6| Step: 13
Training loss: 1.021111011505127
Validation loss: 2.0409261186917624

Epoch: 156| Step: 0
Training loss: 0.8722670078277588
Validation loss: 2.01961612701416

Epoch: 6| Step: 1
Training loss: 1.0523163080215454
Validation loss: 2.0152343114217124

Epoch: 6| Step: 2
Training loss: 1.1432480812072754
Validation loss: 2.0387627482414246

Epoch: 6| Step: 3
Training loss: 0.9411776065826416
Validation loss: 2.0780247251192727

Epoch: 6| Step: 4
Training loss: 0.8557465076446533
Validation loss: 2.053195893764496

Epoch: 6| Step: 5
Training loss: 0.9236925840377808
Validation loss: 2.035407622655233

Epoch: 6| Step: 6
Training loss: 1.079803705215454
Validation loss: 2.0876317024230957

Epoch: 6| Step: 7
Training loss: 0.7856429815292358
Validation loss: 2.053392231464386

Epoch: 6| Step: 8
Training loss: 1.1776617765426636
Validation loss: 2.033855934937795

Epoch: 6| Step: 9
Training loss: 1.405573844909668
Validation loss: 2.0281306306521096

Epoch: 6| Step: 10
Training loss: 0.6590077877044678
Validation loss: 2.0434771180152893

Epoch: 6| Step: 11
Training loss: 0.7363283634185791
Validation loss: 2.0072028636932373

Epoch: 6| Step: 12
Training loss: 0.9144632816314697
Validation loss: 2.004624684651693

Epoch: 6| Step: 13
Training loss: 0.972277045249939
Validation loss: 2.0171101689338684

Epoch: 157| Step: 0
Training loss: 0.9400346875190735
Validation loss: 2.020085573196411

Epoch: 6| Step: 1
Training loss: 0.9497770071029663
Validation loss: 2.018462856610616

Epoch: 6| Step: 2
Training loss: 0.9871115684509277
Validation loss: 2.0267600615819297

Epoch: 6| Step: 3
Training loss: 1.2994320392608643
Validation loss: 2.0548638105392456

Epoch: 6| Step: 4
Training loss: 1.2935255765914917
Validation loss: 1.986114541689555

Epoch: 6| Step: 5
Training loss: 1.0765724182128906
Validation loss: 2.055506189664205

Epoch: 6| Step: 6
Training loss: 0.977163553237915
Validation loss: 2.029001315434774

Epoch: 6| Step: 7
Training loss: 0.6271468997001648
Validation loss: 2.0299428502718606

Epoch: 6| Step: 8
Training loss: 0.33941635489463806
Validation loss: 1.9947582284609477

Epoch: 6| Step: 9
Training loss: 0.8814294338226318
Validation loss: 1.9899911483128865

Epoch: 6| Step: 10
Training loss: 0.4427521228790283
Validation loss: 1.988996426264445

Epoch: 6| Step: 11
Training loss: 0.418893039226532
Validation loss: 1.9701431393623352

Epoch: 6| Step: 12
Training loss: 1.040431022644043
Validation loss: 2.0287236173947654

Epoch: 6| Step: 13
Training loss: 1.0675091743469238
Validation loss: 2.000419636567434

Epoch: 158| Step: 0
Training loss: 0.9598007202148438
Validation loss: 2.024520297845205

Epoch: 6| Step: 1
Training loss: 1.0876792669296265
Validation loss: 2.081290145715078

Epoch: 6| Step: 2
Training loss: 0.6648784875869751
Validation loss: 2.045268177986145

Epoch: 6| Step: 3
Training loss: 0.5120595693588257
Validation loss: 1.992037038008372

Epoch: 6| Step: 4
Training loss: 0.9197888374328613
Validation loss: 2.016589939594269

Epoch: 6| Step: 5
Training loss: 1.0027918815612793
Validation loss: 2.0208621621131897

Epoch: 6| Step: 6
Training loss: 0.8218454718589783
Validation loss: 1.9939250548680623

Epoch: 6| Step: 7
Training loss: 1.0680656433105469
Validation loss: 1.9878604412078857

Epoch: 6| Step: 8
Training loss: 0.7879303693771362
Validation loss: 2.033985515435537

Epoch: 6| Step: 9
Training loss: 0.5094670057296753
Validation loss: 2.0479971170425415

Epoch: 6| Step: 10
Training loss: 0.782963216304779
Validation loss: 2.0787893533706665

Epoch: 6| Step: 11
Training loss: 0.8540303111076355
Validation loss: 2.037234286467234

Epoch: 6| Step: 12
Training loss: 0.957879900932312
Validation loss: 2.0239861806233725

Epoch: 6| Step: 13
Training loss: 1.7369239330291748
Validation loss: 2.047843416531881

Epoch: 159| Step: 0
Training loss: 0.7278249263763428
Validation loss: 2.0540234446525574

Epoch: 6| Step: 1
Training loss: 1.0149705410003662
Validation loss: 2.0034892161687217

Epoch: 6| Step: 2
Training loss: 0.6118605732917786
Validation loss: 2.047136644522349

Epoch: 6| Step: 3
Training loss: 1.1385483741760254
Validation loss: 2.041701932748159

Epoch: 6| Step: 4
Training loss: 0.6650670766830444
Validation loss: 2.061508079369863

Epoch: 6| Step: 5
Training loss: 0.566136360168457
Validation loss: 1.9819352428118389

Epoch: 6| Step: 6
Training loss: 0.8176795244216919
Validation loss: 2.020242234071096

Epoch: 6| Step: 7
Training loss: 0.8266236186027527
Validation loss: 2.044038554032644

Epoch: 6| Step: 8
Training loss: 0.6601171493530273
Validation loss: 1.9846036434173584

Epoch: 6| Step: 9
Training loss: 0.6666197776794434
Validation loss: 2.021530350049337

Epoch: 6| Step: 10
Training loss: 0.7327532172203064
Validation loss: 2.006531238555908

Epoch: 6| Step: 11
Training loss: 1.6924147605895996
Validation loss: 2.041554609934489

Epoch: 6| Step: 12
Training loss: 0.941145122051239
Validation loss: 2.0549177726109824

Epoch: 6| Step: 13
Training loss: 1.2590925693511963
Validation loss: 2.036419451236725

Epoch: 160| Step: 0
Training loss: 0.5911706686019897
Validation loss: 2.0076457063357034

Epoch: 6| Step: 1
Training loss: 0.6005358695983887
Validation loss: 2.020691712697347

Epoch: 6| Step: 2
Training loss: 1.3469231128692627
Validation loss: 1.9938149849573772

Epoch: 6| Step: 3
Training loss: 0.8589873313903809
Validation loss: 2.006810168425242

Epoch: 6| Step: 4
Training loss: 0.7190283536911011
Validation loss: 1.9967901508013408

Epoch: 6| Step: 5
Training loss: 0.4159218370914459
Validation loss: 2.033620297908783

Epoch: 6| Step: 6
Training loss: 0.6492302417755127
Validation loss: 2.061609983444214

Epoch: 6| Step: 7
Training loss: 0.7319108247756958
Validation loss: 2.0262763102849326

Epoch: 6| Step: 8
Training loss: 1.3182227611541748
Validation loss: 2.045554300149282

Epoch: 6| Step: 9
Training loss: 0.942704439163208
Validation loss: 2.037396550178528

Epoch: 6| Step: 10
Training loss: 1.2608535289764404
Validation loss: 2.0548055768013

Epoch: 6| Step: 11
Training loss: 1.338205099105835
Validation loss: 2.0016680558522544

Epoch: 6| Step: 12
Training loss: 0.7655324935913086
Validation loss: 2.091764748096466

Epoch: 6| Step: 13
Training loss: 0.7529720067977905
Validation loss: 2.039521316687266

Epoch: 161| Step: 0
Training loss: 0.6653949618339539
Validation loss: 2.041456083456675

Epoch: 6| Step: 1
Training loss: 1.31107759475708
Validation loss: 2.0263532996177673

Epoch: 6| Step: 2
Training loss: 1.320842981338501
Validation loss: 2.059740940729777

Epoch: 6| Step: 3
Training loss: 0.642274022102356
Validation loss: 2.006786505381266

Epoch: 6| Step: 4
Training loss: 0.44876614212989807
Validation loss: 2.047132730484009

Epoch: 6| Step: 5
Training loss: 1.2422587871551514
Validation loss: 2.0422906080881753

Epoch: 6| Step: 6
Training loss: 0.7729670405387878
Validation loss: 1.977781891822815

Epoch: 6| Step: 7
Training loss: 0.6451915502548218
Validation loss: 2.0195486148198447

Epoch: 6| Step: 8
Training loss: 1.1681430339813232
Validation loss: 2.0225142439206443

Epoch: 6| Step: 9
Training loss: 1.0023250579833984
Validation loss: 2.020928382873535

Epoch: 6| Step: 10
Training loss: 0.7562863826751709
Validation loss: 2.0445151329040527

Epoch: 6| Step: 11
Training loss: 0.8488296270370483
Validation loss: 2.002151926358541

Epoch: 6| Step: 12
Training loss: 0.44668012857437134
Validation loss: 2.052416185537974

Epoch: 6| Step: 13
Training loss: 0.8034119606018066
Validation loss: 2.0467459559440613

Epoch: 162| Step: 0
Training loss: 1.6174417734146118
Validation loss: 2.0032777786254883

Epoch: 6| Step: 1
Training loss: 0.9559105634689331
Validation loss: 2.0676406820615134

Epoch: 6| Step: 2
Training loss: 0.8326447606086731
Validation loss: 2.027322292327881

Epoch: 6| Step: 3
Training loss: 0.6745189428329468
Validation loss: 2.060707231362661

Epoch: 6| Step: 4
Training loss: 0.7985068559646606
Validation loss: 2.0242740710576377

Epoch: 6| Step: 5
Training loss: 1.105911135673523
Validation loss: 2.045456131299337

Epoch: 6| Step: 6
Training loss: 0.8440067172050476
Validation loss: 2.0493969122568765

Epoch: 6| Step: 7
Training loss: 0.8178912997245789
Validation loss: 1.9731809496879578

Epoch: 6| Step: 8
Training loss: 0.6211983561515808
Validation loss: 2.032399813334147

Epoch: 6| Step: 9
Training loss: 0.362831175327301
Validation loss: 1.9723429679870605

Epoch: 6| Step: 10
Training loss: 0.7364087104797363
Validation loss: 2.0184202194213867

Epoch: 6| Step: 11
Training loss: 1.2130872011184692
Validation loss: 1.967176576455434

Epoch: 6| Step: 12
Training loss: 0.7570622563362122
Validation loss: 2.014719287554423

Epoch: 6| Step: 13
Training loss: 0.9700772762298584
Validation loss: 1.9557552933692932

Epoch: 163| Step: 0
Training loss: 0.5432721376419067
Validation loss: 2.003145138422648

Epoch: 6| Step: 1
Training loss: 0.9499766230583191
Validation loss: 1.9865742325782776

Epoch: 6| Step: 2
Training loss: 0.6958736777305603
Validation loss: 1.9820838967959087

Epoch: 6| Step: 3
Training loss: 0.9135953187942505
Validation loss: 2.0270299911499023

Epoch: 6| Step: 4
Training loss: 1.3588035106658936
Validation loss: 1.9887993931770325

Epoch: 6| Step: 5
Training loss: 1.0311833620071411
Validation loss: 1.9945680101712544

Epoch: 6| Step: 6
Training loss: 0.8558052778244019
Validation loss: 2.029157896836599

Epoch: 6| Step: 7
Training loss: 0.42441317439079285
Validation loss: 2.0141080617904663

Epoch: 6| Step: 8
Training loss: 0.9144083857536316
Validation loss: 2.0552949706713357

Epoch: 6| Step: 9
Training loss: 0.7931420207023621
Validation loss: 2.0257798035939536

Epoch: 6| Step: 10
Training loss: 0.7522655129432678
Validation loss: 2.043541590372721

Epoch: 6| Step: 11
Training loss: 0.7740640044212341
Validation loss: 2.025591333707174

Epoch: 6| Step: 12
Training loss: 1.0579804182052612
Validation loss: 2.000518341859182

Epoch: 6| Step: 13
Training loss: 0.7156615257263184
Validation loss: 2.0453848044077554

Epoch: 164| Step: 0
Training loss: 0.7194515466690063
Validation loss: 1.9647114475568135

Epoch: 6| Step: 1
Training loss: 0.8056407570838928
Validation loss: 2.0287561217943826

Epoch: 6| Step: 2
Training loss: 0.7748996615409851
Validation loss: 1.9485546549161274

Epoch: 6| Step: 3
Training loss: 0.9462525844573975
Validation loss: 1.9811547597249348

Epoch: 6| Step: 4
Training loss: 0.7191969156265259
Validation loss: 2.0025822122891745

Epoch: 6| Step: 5
Training loss: 0.9810165762901306
Validation loss: 1.9816324313481648

Epoch: 6| Step: 6
Training loss: 1.1254929304122925
Validation loss: 1.9770846764246623

Epoch: 6| Step: 7
Training loss: 0.510668158531189
Validation loss: 2.0132544239362082

Epoch: 6| Step: 8
Training loss: 0.7453543543815613
Validation loss: 2.014028569062551

Epoch: 6| Step: 9
Training loss: 0.8301001787185669
Validation loss: 2.0146278738975525

Epoch: 6| Step: 10
Training loss: 0.8948357105255127
Validation loss: 2.0105199217796326

Epoch: 6| Step: 11
Training loss: 1.05027174949646
Validation loss: 2.0035706957181296

Epoch: 6| Step: 12
Training loss: 1.0318067073822021
Validation loss: 2.0214277704556785

Epoch: 6| Step: 13
Training loss: 1.1997452974319458
Validation loss: 2.0054805477460227

Epoch: 165| Step: 0
Training loss: 0.9716284871101379
Validation loss: 2.0343218247095742

Epoch: 6| Step: 1
Training loss: 0.5810350179672241
Validation loss: 2.0140979886054993

Epoch: 6| Step: 2
Training loss: 1.0875217914581299
Validation loss: 2.0745794574419656

Epoch: 6| Step: 3
Training loss: 0.6136229038238525
Validation loss: 2.0492346485455832

Epoch: 6| Step: 4
Training loss: 1.3434514999389648
Validation loss: 1.9893969297409058

Epoch: 6| Step: 5
Training loss: 1.098650574684143
Validation loss: 2.0019006927808127

Epoch: 6| Step: 6
Training loss: 0.7982165813446045
Validation loss: 2.022289832433065

Epoch: 6| Step: 7
Training loss: 0.7898982167243958
Validation loss: 2.002094050248464

Epoch: 6| Step: 8
Training loss: 0.6427643299102783
Validation loss: 1.995424250761668

Epoch: 6| Step: 9
Training loss: 0.9810900688171387
Validation loss: 2.0439830819765725

Epoch: 6| Step: 10
Training loss: 1.0353171825408936
Validation loss: 2.019672214984894

Epoch: 6| Step: 11
Training loss: 1.0631966590881348
Validation loss: 1.991131862004598

Epoch: 6| Step: 12
Training loss: 0.5928657054901123
Validation loss: 2.0278135538101196

Epoch: 6| Step: 13
Training loss: 0.7039875388145447
Validation loss: 1.98581196864446

Epoch: 166| Step: 0
Training loss: 0.894558310508728
Validation loss: 2.010469933350881

Epoch: 6| Step: 1
Training loss: 0.6485340595245361
Validation loss: 1.9883795380592346

Epoch: 6| Step: 2
Training loss: 0.803230881690979
Validation loss: 2.0036376317342124

Epoch: 6| Step: 3
Training loss: 0.9827437400817871
Validation loss: 2.0066998402277627

Epoch: 6| Step: 4
Training loss: 0.6059112548828125
Validation loss: 2.0541563431421914

Epoch: 6| Step: 5
Training loss: 0.8119040727615356
Validation loss: 2.0150570074717202

Epoch: 6| Step: 6
Training loss: 0.6060099601745605
Validation loss: 2.070434272289276

Epoch: 6| Step: 7
Training loss: 0.7873924970626831
Validation loss: 2.008534034093221

Epoch: 6| Step: 8
Training loss: 0.9356515407562256
Validation loss: 2.0607484777768454

Epoch: 6| Step: 9
Training loss: 0.9020057916641235
Validation loss: 2.016582409540812

Epoch: 6| Step: 10
Training loss: 1.086348533630371
Validation loss: 2.04301647345225

Epoch: 6| Step: 11
Training loss: 0.5772273540496826
Validation loss: 2.0536786317825317

Epoch: 6| Step: 12
Training loss: 0.6673620939254761
Validation loss: 2.0317787726720176

Epoch: 6| Step: 13
Training loss: 1.4698009490966797
Validation loss: 2.1080950498580933

Epoch: 167| Step: 0
Training loss: 1.0819902420043945
Validation loss: 1.9894225001335144

Epoch: 6| Step: 1
Training loss: 0.9775570631027222
Validation loss: 2.045647144317627

Epoch: 6| Step: 2
Training loss: 1.0188599824905396
Validation loss: 2.032246947288513

Epoch: 6| Step: 3
Training loss: 0.8442870378494263
Validation loss: 2.0110100905100503

Epoch: 6| Step: 4
Training loss: 0.5340160131454468
Validation loss: 2.054874837398529

Epoch: 6| Step: 5
Training loss: 0.5728611350059509
Validation loss: 2.0330291787783303

Epoch: 6| Step: 6
Training loss: 0.9658364057540894
Validation loss: 2.024913191795349

Epoch: 6| Step: 7
Training loss: 1.3386449813842773
Validation loss: 1.9820119142532349

Epoch: 6| Step: 8
Training loss: 0.5646148920059204
Validation loss: 2.0271565119425454

Epoch: 6| Step: 9
Training loss: 0.6010839939117432
Validation loss: 1.983447015285492

Epoch: 6| Step: 10
Training loss: 0.3311574459075928
Validation loss: 2.0025777022043862

Epoch: 6| Step: 11
Training loss: 0.9889746308326721
Validation loss: 2.052186588446299

Epoch: 6| Step: 12
Training loss: 1.10928213596344
Validation loss: 1.9725882013638814

Epoch: 6| Step: 13
Training loss: 0.5080615878105164
Validation loss: 2.020240863164266

Epoch: 168| Step: 0
Training loss: 1.058295726776123
Validation loss: 2.0292875170707703

Epoch: 6| Step: 1
Training loss: 0.6877400279045105
Validation loss: 2.035195449988047

Epoch: 6| Step: 2
Training loss: 0.8723177909851074
Validation loss: 1.9855145812034607

Epoch: 6| Step: 3
Training loss: 0.49007323384284973
Validation loss: 2.0180813868840537

Epoch: 6| Step: 4
Training loss: 0.7642043232917786
Validation loss: 2.014518757661184

Epoch: 6| Step: 5
Training loss: 0.8453730344772339
Validation loss: 2.0099200010299683

Epoch: 6| Step: 6
Training loss: 1.0121186971664429
Validation loss: 1.998758316040039

Epoch: 6| Step: 7
Training loss: 0.6663463115692139
Validation loss: 2.008701821168264

Epoch: 6| Step: 8
Training loss: 1.1728037595748901
Validation loss: 2.0181466142336526

Epoch: 6| Step: 9
Training loss: 0.33949708938598633
Validation loss: 2.042494237422943

Epoch: 6| Step: 10
Training loss: 1.160077691078186
Validation loss: 1.9542417128880818

Epoch: 6| Step: 11
Training loss: 0.9534914493560791
Validation loss: 1.9895702401796977

Epoch: 6| Step: 12
Training loss: 0.6126241683959961
Validation loss: 2.034287432829539

Epoch: 6| Step: 13
Training loss: 0.7339390516281128
Validation loss: 2.0416524012883506

Epoch: 169| Step: 0
Training loss: 0.4877798557281494
Validation loss: 2.01098370552063

Epoch: 6| Step: 1
Training loss: 0.5817426443099976
Validation loss: 1.9898465275764465

Epoch: 6| Step: 2
Training loss: 0.5277985334396362
Validation loss: 1.9792607227961223

Epoch: 6| Step: 3
Training loss: 1.0844478607177734
Validation loss: 2.0290831526120505

Epoch: 6| Step: 4
Training loss: 0.7762010097503662
Validation loss: 2.026710549990336

Epoch: 6| Step: 5
Training loss: 0.8994343280792236
Validation loss: 1.9669159452120464

Epoch: 6| Step: 6
Training loss: 1.2856597900390625
Validation loss: 2.0368045568466187

Epoch: 6| Step: 7
Training loss: 1.1730515956878662
Validation loss: 1.9949078559875488

Epoch: 6| Step: 8
Training loss: 0.9097195267677307
Validation loss: 1.9990219275156658

Epoch: 6| Step: 9
Training loss: 0.4529687762260437
Validation loss: 1.966021736462911

Epoch: 6| Step: 10
Training loss: 1.3683749437332153
Validation loss: 1.9639987349510193

Epoch: 6| Step: 11
Training loss: 0.7748292684555054
Validation loss: 1.9825958609580994

Epoch: 6| Step: 12
Training loss: 0.38371971249580383
Validation loss: 1.9690663019816081

Epoch: 6| Step: 13
Training loss: 0.6610187292098999
Validation loss: 2.043441633383433

Epoch: 170| Step: 0
Training loss: 0.5873340964317322
Validation loss: 2.0170685251553855

Epoch: 6| Step: 1
Training loss: 0.5898652076721191
Validation loss: 1.999142626921336

Epoch: 6| Step: 2
Training loss: 1.21343994140625
Validation loss: 1.9777165452639263

Epoch: 6| Step: 3
Training loss: 1.0749611854553223
Validation loss: 1.9953686197598774

Epoch: 6| Step: 4
Training loss: 0.5884085297584534
Validation loss: 2.013736069202423

Epoch: 6| Step: 5
Training loss: 1.0281507968902588
Validation loss: 2.015895207722982

Epoch: 6| Step: 6
Training loss: 1.2462172508239746
Validation loss: 1.9951703349749248

Epoch: 6| Step: 7
Training loss: 0.7197355031967163
Validation loss: 2.047780712445577

Epoch: 6| Step: 8
Training loss: 0.6153334975242615
Validation loss: 2.0206034580866494

Epoch: 6| Step: 9
Training loss: 0.9758793115615845
Validation loss: 2.016224483648936

Epoch: 6| Step: 10
Training loss: 0.606340229511261
Validation loss: 1.9757551749547322

Epoch: 6| Step: 11
Training loss: 0.5534969568252563
Validation loss: 1.9898887872695923

Epoch: 6| Step: 12
Training loss: 0.6339050531387329
Validation loss: 2.0624791979789734

Epoch: 6| Step: 13
Training loss: 0.47670993208885193
Validation loss: 1.9716793497403462

Epoch: 171| Step: 0
Training loss: 0.8411080241203308
Validation loss: 2.0088337461153665

Epoch: 6| Step: 1
Training loss: 0.4651775360107422
Validation loss: 2.0419082840283713

Epoch: 6| Step: 2
Training loss: 0.8468023538589478
Validation loss: 1.9794597427050273

Epoch: 6| Step: 3
Training loss: 0.6759096384048462
Validation loss: 2.008765757083893

Epoch: 6| Step: 4
Training loss: 0.7318800687789917
Validation loss: 2.032847781976064

Epoch: 6| Step: 5
Training loss: 1.0060155391693115
Validation loss: 2.0294692317644754

Epoch: 6| Step: 6
Training loss: 0.5505158305168152
Validation loss: 2.031867583592733

Epoch: 6| Step: 7
Training loss: 0.7747526168823242
Validation loss: 2.026406745115916

Epoch: 6| Step: 8
Training loss: 0.6097655296325684
Validation loss: 2.0371515353520713

Epoch: 6| Step: 9
Training loss: 0.8344260454177856
Validation loss: 2.019124666849772

Epoch: 6| Step: 10
Training loss: 0.6166461706161499
Validation loss: 1.9644539952278137

Epoch: 6| Step: 11
Training loss: 0.6691757440567017
Validation loss: 2.004678726196289

Epoch: 6| Step: 12
Training loss: 0.9275943040847778
Validation loss: 2.0589730938275657

Epoch: 6| Step: 13
Training loss: 1.201988935470581
Validation loss: 2.04798557360967

Epoch: 172| Step: 0
Training loss: 1.0229825973510742
Validation loss: 2.037403106689453

Epoch: 6| Step: 1
Training loss: 0.664788007736206
Validation loss: 2.007585644721985

Epoch: 6| Step: 2
Training loss: 0.8436301946640015
Validation loss: 2.0084179242451987

Epoch: 6| Step: 3
Training loss: 0.8832882642745972
Validation loss: 2.01273512840271

Epoch: 6| Step: 4
Training loss: 0.723966121673584
Validation loss: 2.050231079260508

Epoch: 6| Step: 5
Training loss: 0.7286248207092285
Validation loss: 2.0204821030298867

Epoch: 6| Step: 6
Training loss: 0.5711760520935059
Validation loss: 2.011652151743571

Epoch: 6| Step: 7
Training loss: 0.9756984114646912
Validation loss: 1.997058669726054

Epoch: 6| Step: 8
Training loss: 0.7111956477165222
Validation loss: 2.0424031813939414

Epoch: 6| Step: 9
Training loss: 0.9117358922958374
Validation loss: 1.988416890303294

Epoch: 6| Step: 10
Training loss: 0.530522346496582
Validation loss: 2.0192458430926004

Epoch: 6| Step: 11
Training loss: 0.8088670372962952
Validation loss: 1.977713902791341

Epoch: 6| Step: 12
Training loss: 0.9147111773490906
Validation loss: 1.970724066098531

Epoch: 6| Step: 13
Training loss: 0.8221843242645264
Validation loss: 2.0064952770868936

Epoch: 173| Step: 0
Training loss: 0.7387569546699524
Validation loss: 1.998812238375346

Epoch: 6| Step: 1
Training loss: 0.5605575442314148
Validation loss: 1.9993132750193279

Epoch: 6| Step: 2
Training loss: 1.2632906436920166
Validation loss: 1.9819838007291157

Epoch: 6| Step: 3
Training loss: 1.0074188709259033
Validation loss: 2.000954190889994

Epoch: 6| Step: 4
Training loss: 0.35019558668136597
Validation loss: 2.0229044556617737

Epoch: 6| Step: 5
Training loss: 0.9788808226585388
Validation loss: 2.0226888060569763

Epoch: 6| Step: 6
Training loss: 0.7212311029434204
Validation loss: 2.013943870862325

Epoch: 6| Step: 7
Training loss: 0.8880553245544434
Validation loss: 2.005488475163778

Epoch: 6| Step: 8
Training loss: 0.4048599600791931
Validation loss: 2.011779467264811

Epoch: 6| Step: 9
Training loss: 0.7051391005516052
Validation loss: 1.9883195956548054

Epoch: 6| Step: 10
Training loss: 1.3261921405792236
Validation loss: 2.048162281513214

Epoch: 6| Step: 11
Training loss: 0.5820746421813965
Validation loss: 2.032507538795471

Epoch: 6| Step: 12
Training loss: 1.0399402379989624
Validation loss: 2.021536191304525

Epoch: 6| Step: 13
Training loss: 0.5687321424484253
Validation loss: 2.0426809986432395

Epoch: 174| Step: 0
Training loss: 0.9496949315071106
Validation loss: 2.0570262471834817

Epoch: 6| Step: 1
Training loss: 0.8084338903427124
Validation loss: 2.010815223058065

Epoch: 6| Step: 2
Training loss: 0.9546651840209961
Validation loss: 2.013083815574646

Epoch: 6| Step: 3
Training loss: 0.8753399848937988
Validation loss: 2.0448501904805503

Epoch: 6| Step: 4
Training loss: 0.7454213500022888
Validation loss: 2.0183996160825095

Epoch: 6| Step: 5
Training loss: 0.6727023720741272
Validation loss: 1.9792774319648743

Epoch: 6| Step: 6
Training loss: 0.8604644536972046
Validation loss: 2.014353354771932

Epoch: 6| Step: 7
Training loss: 0.4634951949119568
Validation loss: 2.02848615248998

Epoch: 6| Step: 8
Training loss: 0.9044926166534424
Validation loss: 2.018174091974894

Epoch: 6| Step: 9
Training loss: 0.6825947165489197
Validation loss: 2.0357531110445657

Epoch: 6| Step: 10
Training loss: 0.6011125445365906
Validation loss: 1.9941930969556172

Epoch: 6| Step: 11
Training loss: 1.1716160774230957
Validation loss: 2.040956219037374

Epoch: 6| Step: 12
Training loss: 0.7116487622261047
Validation loss: 2.0592189828554788

Epoch: 6| Step: 13
Training loss: 0.5205357670783997
Validation loss: 1.9936102430025737

Epoch: 175| Step: 0
Training loss: 0.5942857265472412
Validation loss: 2.049441675345103

Epoch: 6| Step: 1
Training loss: 0.5491276383399963
Validation loss: 2.0203495025634766

Epoch: 6| Step: 2
Training loss: 1.1277844905853271
Validation loss: 2.012441873550415

Epoch: 6| Step: 3
Training loss: 0.30653858184814453
Validation loss: 2.001531263192495

Epoch: 6| Step: 4
Training loss: 0.8783978223800659
Validation loss: 2.0360456903775535

Epoch: 6| Step: 5
Training loss: 0.9550212621688843
Validation loss: 2.0243035753568015

Epoch: 6| Step: 6
Training loss: 0.732807993888855
Validation loss: 2.0159562627474465

Epoch: 6| Step: 7
Training loss: 0.796495258808136
Validation loss: 2.0560543735822043

Epoch: 6| Step: 8
Training loss: 0.8969332575798035
Validation loss: 2.0341786543528237

Epoch: 6| Step: 9
Training loss: 0.3654656708240509
Validation loss: 2.011001547177633

Epoch: 6| Step: 10
Training loss: 0.654952883720398
Validation loss: 1.9728727142016094

Epoch: 6| Step: 11
Training loss: 0.8143470287322998
Validation loss: 1.9834888974825542

Epoch: 6| Step: 12
Training loss: 1.0536736249923706
Validation loss: 2.0489112933476767

Epoch: 6| Step: 13
Training loss: 1.4188461303710938
Validation loss: 2.038170119126638

Epoch: 176| Step: 0
Training loss: 0.8662762641906738
Validation loss: 2.0065701802571616

Epoch: 6| Step: 1
Training loss: 1.011974573135376
Validation loss: 2.02441014846166

Epoch: 6| Step: 2
Training loss: 0.5033993721008301
Validation loss: 2.0618250966072083

Epoch: 6| Step: 3
Training loss: 0.6199738383293152
Validation loss: 1.9961382150650024

Epoch: 6| Step: 4
Training loss: 0.6298502683639526
Validation loss: 2.0518772999445596

Epoch: 6| Step: 5
Training loss: 0.6775858998298645
Validation loss: 2.042063573996226

Epoch: 6| Step: 6
Training loss: 0.892260730266571
Validation loss: 2.077080508073171

Epoch: 6| Step: 7
Training loss: 0.993982195854187
Validation loss: 2.0189345479011536

Epoch: 6| Step: 8
Training loss: 1.1494382619857788
Validation loss: 2.021458685398102

Epoch: 6| Step: 9
Training loss: 0.4515590965747833
Validation loss: 2.011675536632538

Epoch: 6| Step: 10
Training loss: 0.637136697769165
Validation loss: 2.0644803643226624

Epoch: 6| Step: 11
Training loss: 0.9744237065315247
Validation loss: 1.9766778548558552

Epoch: 6| Step: 12
Training loss: 0.6323766708374023
Validation loss: 1.9996047218640645

Epoch: 6| Step: 13
Training loss: 0.6317397356033325
Validation loss: 1.9850938717524211

Epoch: 177| Step: 0
Training loss: 0.39495784044265747
Validation loss: 2.049919545650482

Epoch: 6| Step: 1
Training loss: 0.6927769780158997
Validation loss: 1.9599546392758687

Epoch: 6| Step: 2
Training loss: 0.6599255800247192
Validation loss: 2.0170820554097495

Epoch: 6| Step: 3
Training loss: 0.6276795268058777
Validation loss: 2.062765061855316

Epoch: 6| Step: 4
Training loss: 1.2340174913406372
Validation loss: 2.023713250954946

Epoch: 6| Step: 5
Training loss: 0.352420449256897
Validation loss: 2.0131993691126504

Epoch: 6| Step: 6
Training loss: 0.5590041279792786
Validation loss: 1.949660102526347

Epoch: 6| Step: 7
Training loss: 1.1819288730621338
Validation loss: 2.035603483517965

Epoch: 6| Step: 8
Training loss: 1.6929643154144287
Validation loss: 2.045270323753357

Epoch: 6| Step: 9
Training loss: 1.0580615997314453
Validation loss: 2.0541088581085205

Epoch: 6| Step: 10
Training loss: 1.069583535194397
Validation loss: 2.0067903995513916

Epoch: 6| Step: 11
Training loss: 0.7605899572372437
Validation loss: 2.0458189249038696

Epoch: 6| Step: 12
Training loss: 0.5063233375549316
Validation loss: 2.064334213733673

Epoch: 6| Step: 13
Training loss: 0.39225637912750244
Validation loss: 1.998658796151479

Epoch: 178| Step: 0
Training loss: 0.5726165771484375
Validation loss: 2.0285005370775857

Epoch: 6| Step: 1
Training loss: 0.6636767983436584
Validation loss: 1.9935596982638042

Epoch: 6| Step: 2
Training loss: 0.7549488544464111
Validation loss: 2.062646051247915

Epoch: 6| Step: 3
Training loss: 1.0212277173995972
Validation loss: 2.0093570947647095

Epoch: 6| Step: 4
Training loss: 1.048677921295166
Validation loss: 2.0115207036336265

Epoch: 6| Step: 5
Training loss: 0.6146595478057861
Validation loss: 2.0193283955256143

Epoch: 6| Step: 6
Training loss: 0.45720571279525757
Validation loss: 2.01597394545873

Epoch: 6| Step: 7
Training loss: 0.6584553718566895
Validation loss: 2.0024418433507285

Epoch: 6| Step: 8
Training loss: 0.9418020248413086
Validation loss: 2.035881737867991

Epoch: 6| Step: 9
Training loss: 0.5836591124534607
Validation loss: 2.0134742657343545

Epoch: 6| Step: 10
Training loss: 0.35556560754776
Validation loss: 1.991800328095754

Epoch: 6| Step: 11
Training loss: 0.7014902830123901
Validation loss: 2.010042369365692

Epoch: 6| Step: 12
Training loss: 1.2469383478164673
Validation loss: 2.0035468339920044

Epoch: 6| Step: 13
Training loss: 0.85457843542099
Validation loss: 1.9897321065266926

Epoch: 179| Step: 0
Training loss: 1.0431021451950073
Validation loss: 1.9876879056294758

Epoch: 6| Step: 1
Training loss: 0.4665448069572449
Validation loss: 2.0313748518625894

Epoch: 6| Step: 2
Training loss: 0.7275449633598328
Validation loss: 2.00530078013738

Epoch: 6| Step: 3
Training loss: 0.6924603581428528
Validation loss: 2.036098301410675

Epoch: 6| Step: 4
Training loss: 0.8523417711257935
Validation loss: 1.9918443163235982

Epoch: 6| Step: 5
Training loss: 1.0394196510314941
Validation loss: 2.008844474951426

Epoch: 6| Step: 6
Training loss: 0.9692173600196838
Validation loss: 2.0290342370669046

Epoch: 6| Step: 7
Training loss: 0.7973309755325317
Validation loss: 2.007922967274984

Epoch: 6| Step: 8
Training loss: 0.8417469263076782
Validation loss: 2.004804094632467

Epoch: 6| Step: 9
Training loss: 0.5999871492385864
Validation loss: 1.9652138749758403

Epoch: 6| Step: 10
Training loss: 0.49640747904777527
Validation loss: 1.963969846566518

Epoch: 6| Step: 11
Training loss: 0.5797282457351685
Validation loss: 2.013446013132731

Epoch: 6| Step: 12
Training loss: 1.17437744140625
Validation loss: 1.990763505299886

Epoch: 6| Step: 13
Training loss: 0.4479658603668213
Validation loss: 2.020138204097748

Epoch: 180| Step: 0
Training loss: 0.7656248807907104
Validation loss: 1.9991865356763203

Epoch: 6| Step: 1
Training loss: 0.3787626028060913
Validation loss: 2.0322272578875222

Epoch: 6| Step: 2
Training loss: 0.9786161184310913
Validation loss: 2.031820813814799

Epoch: 6| Step: 3
Training loss: 0.8384329080581665
Validation loss: 1.978381355603536

Epoch: 6| Step: 4
Training loss: 1.1302719116210938
Validation loss: 1.9898957014083862

Epoch: 6| Step: 5
Training loss: 1.1266230344772339
Validation loss: 2.003997544447581

Epoch: 6| Step: 6
Training loss: 0.8297625184059143
Validation loss: 2.0101818442344666

Epoch: 6| Step: 7
Training loss: 0.5587076544761658
Validation loss: 1.9720403750737507

Epoch: 6| Step: 8
Training loss: 0.45345813035964966
Validation loss: 2.0302483439445496

Epoch: 6| Step: 9
Training loss: 0.4286409914493561
Validation loss: 2.0058088302612305

Epoch: 6| Step: 10
Training loss: 0.7771546840667725
Validation loss: 1.9845133225123088

Epoch: 6| Step: 11
Training loss: 0.8020259141921997
Validation loss: 1.999700943628947

Epoch: 6| Step: 12
Training loss: 0.464300274848938
Validation loss: 2.0198922157287598

Epoch: 6| Step: 13
Training loss: 0.7230721712112427
Validation loss: 2.03005317846934

Epoch: 181| Step: 0
Training loss: 0.670502245426178
Validation loss: 2.0670985778172812

Epoch: 6| Step: 1
Training loss: 0.8024229407310486
Validation loss: 2.0079413652420044

Epoch: 6| Step: 2
Training loss: 0.7863562107086182
Validation loss: 2.004652500152588

Epoch: 6| Step: 3
Training loss: 0.8685750365257263
Validation loss: 2.0062511960665383

Epoch: 6| Step: 4
Training loss: 0.4716939926147461
Validation loss: 2.053350806236267

Epoch: 6| Step: 5
Training loss: 0.4467441439628601
Validation loss: 2.0010923941930137

Epoch: 6| Step: 6
Training loss: 0.803368866443634
Validation loss: 2.030687948067983

Epoch: 6| Step: 7
Training loss: 0.5491999983787537
Validation loss: 2.0279555122057595

Epoch: 6| Step: 8
Training loss: 1.0650253295898438
Validation loss: 2.002513885498047

Epoch: 6| Step: 9
Training loss: 0.9374175667762756
Validation loss: 2.04090408484141

Epoch: 6| Step: 10
Training loss: 0.6850286722183228
Validation loss: 1.9908773303031921

Epoch: 6| Step: 11
Training loss: 0.6324897408485413
Validation loss: 2.025948941707611

Epoch: 6| Step: 12
Training loss: 0.9140878915786743
Validation loss: 2.0214253862698874

Epoch: 6| Step: 13
Training loss: 0.5740317702293396
Validation loss: 2.04760205745697

Epoch: 182| Step: 0
Training loss: 0.7158526182174683
Validation loss: 2.0345717668533325

Epoch: 6| Step: 1
Training loss: 0.89339280128479
Validation loss: 2.047708590825399

Epoch: 6| Step: 2
Training loss: 0.6817427277565002
Validation loss: 2.005135099093119

Epoch: 6| Step: 3
Training loss: 0.45509254932403564
Validation loss: 2.0351428985595703

Epoch: 6| Step: 4
Training loss: 0.53738933801651
Validation loss: 1.9966936310132344

Epoch: 6| Step: 5
Training loss: 0.5284433364868164
Validation loss: 2.008190333843231

Epoch: 6| Step: 6
Training loss: 0.9707683324813843
Validation loss: 2.0108173886934915

Epoch: 6| Step: 7
Training loss: 0.6140645146369934
Validation loss: 2.084898213545481

Epoch: 6| Step: 8
Training loss: 0.9778359532356262
Validation loss: 2.0290069778760276

Epoch: 6| Step: 9
Training loss: 0.6237454414367676
Validation loss: 2.063279906908671

Epoch: 6| Step: 10
Training loss: 0.4469127058982849
Validation loss: 1.9913501540819805

Epoch: 6| Step: 11
Training loss: 1.1109747886657715
Validation loss: 2.0306819677352905

Epoch: 6| Step: 12
Training loss: 0.7056150436401367
Validation loss: 2.0129167437553406

Epoch: 6| Step: 13
Training loss: 0.47472020983695984
Validation loss: 2.0447720487912497

Epoch: 183| Step: 0
Training loss: 0.6493654251098633
Validation loss: 1.9772620995839436

Epoch: 6| Step: 1
Training loss: 0.43557822704315186
Validation loss: 1.9800644715627034

Epoch: 6| Step: 2
Training loss: 0.706230878829956
Validation loss: 2.0332108537356057

Epoch: 6| Step: 3
Training loss: 0.39111173152923584
Validation loss: 1.9853015343348186

Epoch: 6| Step: 4
Training loss: 1.0614385604858398
Validation loss: 2.0054630438486734

Epoch: 6| Step: 5
Training loss: 0.31658536195755005
Validation loss: 2.0403199990590415

Epoch: 6| Step: 6
Training loss: 1.0081913471221924
Validation loss: 2.046418011188507

Epoch: 6| Step: 7
Training loss: 1.3963017463684082
Validation loss: 1.9983426531155903

Epoch: 6| Step: 8
Training loss: 0.6429622173309326
Validation loss: 1.9618040124575298

Epoch: 6| Step: 9
Training loss: 0.6363816857337952
Validation loss: 1.996846338113149

Epoch: 6| Step: 10
Training loss: 0.4952327013015747
Validation loss: 2.034430146217346

Epoch: 6| Step: 11
Training loss: 0.518083393573761
Validation loss: 2.0193807085355124

Epoch: 6| Step: 12
Training loss: 0.7508734464645386
Validation loss: 2.05664853254954

Epoch: 6| Step: 13
Training loss: 1.0315194129943848
Validation loss: 1.981617530186971

Epoch: 184| Step: 0
Training loss: 1.0906729698181152
Validation loss: 2.0356585582097373

Epoch: 6| Step: 1
Training loss: 0.6262940168380737
Validation loss: 1.9964851935704548

Epoch: 6| Step: 2
Training loss: 0.3657592535018921
Validation loss: 1.987213095029195

Epoch: 6| Step: 3
Training loss: 0.8685241937637329
Validation loss: 1.990003804365794

Epoch: 6| Step: 4
Training loss: 0.8873882293701172
Validation loss: 2.0292635758717856

Epoch: 6| Step: 5
Training loss: 0.8529290556907654
Validation loss: 2.030666987101237

Epoch: 6| Step: 6
Training loss: 1.1188558340072632
Validation loss: 2.027350823084513

Epoch: 6| Step: 7
Training loss: 0.42623963952064514
Validation loss: 2.033231516679128

Epoch: 6| Step: 8
Training loss: 0.9136697053909302
Validation loss: 1.994807521502177

Epoch: 6| Step: 9
Training loss: 0.751486599445343
Validation loss: 2.0516194899876914

Epoch: 6| Step: 10
Training loss: 0.6666080355644226
Validation loss: 2.0440068443616233

Epoch: 6| Step: 11
Training loss: 0.7129408717155457
Validation loss: 2.0083407362302146

Epoch: 6| Step: 12
Training loss: 0.3925293982028961
Validation loss: 2.0105879505475364

Epoch: 6| Step: 13
Training loss: 0.7801945209503174
Validation loss: 2.0269506573677063

Epoch: 185| Step: 0
Training loss: 1.0275956392288208
Validation loss: 2.022649566332499

Epoch: 6| Step: 1
Training loss: 0.4194928705692291
Validation loss: 2.000055114428202

Epoch: 6| Step: 2
Training loss: 0.6821173429489136
Validation loss: 2.030891239643097

Epoch: 6| Step: 3
Training loss: 0.7388564944267273
Validation loss: 2.004022200902303

Epoch: 6| Step: 4
Training loss: 1.1842619180679321
Validation loss: 2.069035311539968

Epoch: 6| Step: 5
Training loss: 0.4961299002170563
Validation loss: 2.0109705130259194

Epoch: 6| Step: 6
Training loss: 0.3761278986930847
Validation loss: 2.0040980776151023

Epoch: 6| Step: 7
Training loss: 0.6263871192932129
Validation loss: 1.9954352974891663

Epoch: 6| Step: 8
Training loss: 0.6999934315681458
Validation loss: 1.9816534320513408

Epoch: 6| Step: 9
Training loss: 0.698182225227356
Validation loss: 1.9827852249145508

Epoch: 6| Step: 10
Training loss: 0.4555584192276001
Validation loss: 2.0213296016057334

Epoch: 6| Step: 11
Training loss: 1.190441370010376
Validation loss: 2.0155394474665322

Epoch: 6| Step: 12
Training loss: 0.35732725262641907
Validation loss: 1.9981252153714497

Epoch: 6| Step: 13
Training loss: 1.0192105770111084
Validation loss: 2.044678827126821

Epoch: 186| Step: 0
Training loss: 0.5480219125747681
Validation loss: 2.030744512875875

Epoch: 6| Step: 1
Training loss: 0.7584099769592285
Validation loss: 1.9854235649108887

Epoch: 6| Step: 2
Training loss: 0.5713140964508057
Validation loss: 2.0182504455248513

Epoch: 6| Step: 3
Training loss: 0.8580601215362549
Validation loss: 2.0261535048484802

Epoch: 6| Step: 4
Training loss: 1.0277210474014282
Validation loss: 2.007994552453359

Epoch: 6| Step: 5
Training loss: 0.39081907272338867
Validation loss: 1.988945464293162

Epoch: 6| Step: 6
Training loss: 0.7155839204788208
Validation loss: 2.001299719015757

Epoch: 6| Step: 7
Training loss: 0.9122719764709473
Validation loss: 2.008657077948252

Epoch: 6| Step: 8
Training loss: 0.44247227907180786
Validation loss: 2.019777258237203

Epoch: 6| Step: 9
Training loss: 0.7062910795211792
Validation loss: 2.0309224724769592

Epoch: 6| Step: 10
Training loss: 0.5656347274780273
Validation loss: 2.035086472829183

Epoch: 6| Step: 11
Training loss: 0.5505176782608032
Validation loss: 2.0435381531715393

Epoch: 6| Step: 12
Training loss: 1.203405737876892
Validation loss: 2.08089941740036

Epoch: 6| Step: 13
Training loss: 1.044400930404663
Validation loss: 2.0329463283220925

Epoch: 187| Step: 0
Training loss: 0.8671520948410034
Validation loss: 2.0078694025675454

Epoch: 6| Step: 1
Training loss: 0.6343647241592407
Validation loss: 2.006922642389933

Epoch: 6| Step: 2
Training loss: 0.7542426586151123
Validation loss: 2.0134269992510476

Epoch: 6| Step: 3
Training loss: 0.9378776550292969
Validation loss: 1.979913095633189

Epoch: 6| Step: 4
Training loss: 0.8468155264854431
Validation loss: 1.9909509619077046

Epoch: 6| Step: 5
Training loss: 0.692150354385376
Validation loss: 2.070976177851359

Epoch: 6| Step: 6
Training loss: 0.7862904071807861
Validation loss: 2.0250543554623923

Epoch: 6| Step: 7
Training loss: 0.7686060667037964
Validation loss: 1.9960718552271526

Epoch: 6| Step: 8
Training loss: 0.6021023988723755
Validation loss: 1.9867329597473145

Epoch: 6| Step: 9
Training loss: 0.4809144139289856
Validation loss: 2.059487044811249

Epoch: 6| Step: 10
Training loss: 0.3348820209503174
Validation loss: 2.0466843048731485

Epoch: 6| Step: 11
Training loss: 0.6587183475494385
Validation loss: 2.0298714637756348

Epoch: 6| Step: 12
Training loss: 0.8030237555503845
Validation loss: 2.048340936501821

Epoch: 6| Step: 13
Training loss: 0.9343328475952148
Validation loss: 2.013819694519043

Epoch: 188| Step: 0
Training loss: 1.2282263040542603
Validation loss: 2.0705449183781943

Epoch: 6| Step: 1
Training loss: 0.7183500528335571
Validation loss: 2.0308823386828103

Epoch: 6| Step: 2
Training loss: 0.7677284479141235
Validation loss: 1.9998533725738525

Epoch: 6| Step: 3
Training loss: 0.47739022970199585
Validation loss: 2.008810738722483

Epoch: 6| Step: 4
Training loss: 0.7385251522064209
Validation loss: 2.0098021229108176

Epoch: 6| Step: 5
Training loss: 0.9846671223640442
Validation loss: 2.0543407201766968

Epoch: 6| Step: 6
Training loss: 0.9538595080375671
Validation loss: 2.030252973238627

Epoch: 6| Step: 7
Training loss: 0.5253852605819702
Validation loss: 1.9643079042434692

Epoch: 6| Step: 8
Training loss: 0.457144558429718
Validation loss: 1.9783312479654949

Epoch: 6| Step: 9
Training loss: 0.83570796251297
Validation loss: 2.038348913192749

Epoch: 6| Step: 10
Training loss: 0.6912770867347717
Validation loss: 1.9564470847447712

Epoch: 6| Step: 11
Training loss: 0.34417086839675903
Validation loss: 2.0157655080159507

Epoch: 6| Step: 12
Training loss: 0.45292794704437256
Validation loss: 1.9809948404630024

Epoch: 6| Step: 13
Training loss: 0.5814987421035767
Validation loss: 2.018645246823629

Epoch: 189| Step: 0
Training loss: 0.5576095581054688
Validation loss: 1.986337165037791

Epoch: 6| Step: 1
Training loss: 0.9094707369804382
Validation loss: 2.0044514735539756

Epoch: 6| Step: 2
Training loss: 0.9081935882568359
Validation loss: 2.0239564975102744

Epoch: 6| Step: 3
Training loss: 0.7745496034622192
Validation loss: 1.9846452474594116

Epoch: 6| Step: 4
Training loss: 0.8151721358299255
Validation loss: 1.9726083079973857

Epoch: 6| Step: 5
Training loss: 0.8373441696166992
Validation loss: 1.999935766061147

Epoch: 6| Step: 6
Training loss: 0.6950666308403015
Validation loss: 2.037702282269796

Epoch: 6| Step: 7
Training loss: 0.4528927803039551
Validation loss: 2.032001495361328

Epoch: 6| Step: 8
Training loss: 0.3530903458595276
Validation loss: 2.0108874440193176

Epoch: 6| Step: 9
Training loss: 0.5759783387184143
Validation loss: 2.0023053089777627

Epoch: 6| Step: 10
Training loss: 0.5146694183349609
Validation loss: 2.023998200893402

Epoch: 6| Step: 11
Training loss: 0.556717574596405
Validation loss: 2.018846054871877

Epoch: 6| Step: 12
Training loss: 0.7332044839859009
Validation loss: 2.0470937689145408

Epoch: 6| Step: 13
Training loss: 0.8873457908630371
Validation loss: 2.0184415181477866

Epoch: 190| Step: 0
Training loss: 1.0009970664978027
Validation loss: 2.0330997308095298

Epoch: 6| Step: 1
Training loss: 0.9582496881484985
Validation loss: 2.0200828115145364

Epoch: 6| Step: 2
Training loss: 0.6708400249481201
Validation loss: 2.0445785919825235

Epoch: 6| Step: 3
Training loss: 0.9861629605293274
Validation loss: 2.0083746910095215

Epoch: 6| Step: 4
Training loss: 0.864778459072113
Validation loss: 2.019392490386963

Epoch: 6| Step: 5
Training loss: 0.6111329793930054
Validation loss: 1.9996574521064758

Epoch: 6| Step: 6
Training loss: 0.4583698511123657
Validation loss: 2.0128771662712097

Epoch: 6| Step: 7
Training loss: 0.5073250532150269
Validation loss: 1.9661695957183838

Epoch: 6| Step: 8
Training loss: 0.46353042125701904
Validation loss: 2.01826548576355

Epoch: 6| Step: 9
Training loss: 0.9510450959205627
Validation loss: 2.0101081132888794

Epoch: 6| Step: 10
Training loss: 0.5370556116104126
Validation loss: 2.022844135761261

Epoch: 6| Step: 11
Training loss: 0.37469497323036194
Validation loss: 2.011505941549937

Epoch: 6| Step: 12
Training loss: 0.7909324169158936
Validation loss: 2.019989331563314

Epoch: 6| Step: 13
Training loss: 0.6002776026725769
Validation loss: 1.9935692151387532

Epoch: 191| Step: 0
Training loss: 0.4581121504306793
Validation loss: 2.003591259320577

Epoch: 6| Step: 1
Training loss: 0.836272120475769
Validation loss: 1.985351820786794

Epoch: 6| Step: 2
Training loss: 0.34780341386795044
Validation loss: 2.0161378979682922

Epoch: 6| Step: 3
Training loss: 0.7722777724266052
Validation loss: 1.993122359116872

Epoch: 6| Step: 4
Training loss: 0.5226330161094666
Validation loss: 2.023017466068268

Epoch: 6| Step: 5
Training loss: 0.8322973251342773
Validation loss: 1.9981011350949605

Epoch: 6| Step: 6
Training loss: 0.76172935962677
Validation loss: 1.9768754839897156

Epoch: 6| Step: 7
Training loss: 0.7405869960784912
Validation loss: 2.0565272172292075

Epoch: 6| Step: 8
Training loss: 0.5422374606132507
Validation loss: 1.974055806795756

Epoch: 6| Step: 9
Training loss: 0.6502763032913208
Validation loss: 2.0223862727483115

Epoch: 6| Step: 10
Training loss: 1.048000693321228
Validation loss: 2.0193363626797995

Epoch: 6| Step: 11
Training loss: 0.5057220458984375
Validation loss: 2.0459931095441184

Epoch: 6| Step: 12
Training loss: 0.8304626941680908
Validation loss: 2.021519124507904

Epoch: 6| Step: 13
Training loss: 0.4928363263607025
Validation loss: 2.1088154117266336

Epoch: 192| Step: 0
Training loss: 0.6077052354812622
Validation loss: 2.0258749127388

Epoch: 6| Step: 1
Training loss: 0.5854801535606384
Validation loss: 2.0526835521062217

Epoch: 6| Step: 2
Training loss: 0.7942749261856079
Validation loss: 2.0170363187789917

Epoch: 6| Step: 3
Training loss: 0.31655263900756836
Validation loss: 2.0237284104029336

Epoch: 6| Step: 4
Training loss: 1.3416409492492676
Validation loss: 1.972674290339152

Epoch: 6| Step: 5
Training loss: 0.9040908217430115
Validation loss: 2.033970753351847

Epoch: 6| Step: 6
Training loss: 0.48214268684387207
Validation loss: 1.9717650214831035

Epoch: 6| Step: 7
Training loss: 0.3910292088985443
Validation loss: 2.03971399863561

Epoch: 6| Step: 8
Training loss: 0.5273183584213257
Validation loss: 2.0555188258488974

Epoch: 6| Step: 9
Training loss: 0.9739835858345032
Validation loss: 2.011807103951772

Epoch: 6| Step: 10
Training loss: 0.35845381021499634
Validation loss: 2.0311710039774575

Epoch: 6| Step: 11
Training loss: 0.6942733526229858
Validation loss: 2.0327032009760537

Epoch: 6| Step: 12
Training loss: 0.9412117004394531
Validation loss: 2.034999191761017

Epoch: 6| Step: 13
Training loss: 0.5670657157897949
Validation loss: 1.996366024017334

Epoch: 193| Step: 0
Training loss: 0.4598512649536133
Validation loss: 2.0251927971839905

Epoch: 6| Step: 1
Training loss: 0.5056871175765991
Validation loss: 1.9786114692687988

Epoch: 6| Step: 2
Training loss: 0.8902073502540588
Validation loss: 2.030929903189341

Epoch: 6| Step: 3
Training loss: 0.38832372426986694
Validation loss: 2.0400886138280234

Epoch: 6| Step: 4
Training loss: 0.6096558570861816
Validation loss: 2.0030384063720703

Epoch: 6| Step: 5
Training loss: 0.8530206680297852
Validation loss: 1.9946626424789429

Epoch: 6| Step: 6
Training loss: 0.6219412088394165
Validation loss: 1.982500712076823

Epoch: 6| Step: 7
Training loss: 0.8735815286636353
Validation loss: 1.993110179901123

Epoch: 6| Step: 8
Training loss: 0.7871438264846802
Validation loss: 1.9600392778714497

Epoch: 6| Step: 9
Training loss: 0.47651273012161255
Validation loss: 2.027251581350962

Epoch: 6| Step: 10
Training loss: 1.2504806518554688
Validation loss: 2.0304086208343506

Epoch: 6| Step: 11
Training loss: 0.717387855052948
Validation loss: 2.029273529847463

Epoch: 6| Step: 12
Training loss: 0.9902042746543884
Validation loss: 2.0018183390299478

Epoch: 6| Step: 13
Training loss: 0.4613195061683655
Validation loss: 1.9734307527542114

Epoch: 194| Step: 0
Training loss: 0.9648328423500061
Validation loss: 2.0518224636713662

Epoch: 6| Step: 1
Training loss: 0.6838332414627075
Validation loss: 2.0502312580744424

Epoch: 6| Step: 2
Training loss: 0.42535680532455444
Validation loss: 2.016385793685913

Epoch: 6| Step: 3
Training loss: 0.7553155422210693
Validation loss: 2.026953637599945

Epoch: 6| Step: 4
Training loss: 0.5724243521690369
Validation loss: 2.052206019560496

Epoch: 6| Step: 5
Training loss: 0.43842509388923645
Validation loss: 1.9957957863807678

Epoch: 6| Step: 6
Training loss: 0.437864750623703
Validation loss: 2.045498232046763

Epoch: 6| Step: 7
Training loss: 1.1071836948394775
Validation loss: 2.0265565713246665

Epoch: 6| Step: 8
Training loss: 0.9932061433792114
Validation loss: 2.047636091709137

Epoch: 6| Step: 9
Training loss: 0.4549781084060669
Validation loss: 2.1285001238187156

Epoch: 6| Step: 10
Training loss: 0.6723895072937012
Validation loss: 2.012681563695272

Epoch: 6| Step: 11
Training loss: 1.5004926919937134
Validation loss: 2.0216771562894187

Epoch: 6| Step: 12
Training loss: 0.4803606867790222
Validation loss: 1.9696885347366333

Epoch: 6| Step: 13
Training loss: 0.5510405898094177
Validation loss: 2.0598670840263367

Epoch: 195| Step: 0
Training loss: 0.7051565647125244
Validation loss: 2.015080471833547

Epoch: 6| Step: 1
Training loss: 0.7273827791213989
Validation loss: 2.0176172057787576

Epoch: 6| Step: 2
Training loss: 0.4377608597278595
Validation loss: 1.9934447209040325

Epoch: 6| Step: 3
Training loss: 0.42125439643859863
Validation loss: 1.983729104200999

Epoch: 6| Step: 4
Training loss: 0.6364179849624634
Validation loss: 1.9719792207082112

Epoch: 6| Step: 5
Training loss: 0.9133775234222412
Validation loss: 2.005483090877533

Epoch: 6| Step: 6
Training loss: 0.9868326187133789
Validation loss: 2.0421440601348877

Epoch: 6| Step: 7
Training loss: 0.6483300924301147
Validation loss: 1.9646095236142476

Epoch: 6| Step: 8
Training loss: 0.9567092657089233
Validation loss: 1.9824313322703044

Epoch: 6| Step: 9
Training loss: 0.45757004618644714
Validation loss: 2.029795527458191

Epoch: 6| Step: 10
Training loss: 0.9287542104721069
Validation loss: 2.023923416932424

Epoch: 6| Step: 11
Training loss: 0.33503374457359314
Validation loss: 1.9950245420138042

Epoch: 6| Step: 12
Training loss: 1.0535273551940918
Validation loss: 1.982956091562907

Epoch: 6| Step: 13
Training loss: 0.27567896246910095
Validation loss: 1.987597405910492

Epoch: 196| Step: 0
Training loss: 0.708202600479126
Validation loss: 2.01792178551356

Epoch: 6| Step: 1
Training loss: 0.26873302459716797
Validation loss: 2.006336490313212

Epoch: 6| Step: 2
Training loss: 0.35781216621398926
Validation loss: 2.0067022244135537

Epoch: 6| Step: 3
Training loss: 1.0242561101913452
Validation loss: 2.06468798716863

Epoch: 6| Step: 4
Training loss: 0.7286053895950317
Validation loss: 2.022069732348124

Epoch: 6| Step: 5
Training loss: 0.7935205101966858
Validation loss: 2.004401703675588

Epoch: 6| Step: 6
Training loss: 0.5959769487380981
Validation loss: 2.0895042419433594

Epoch: 6| Step: 7
Training loss: 0.7415839433670044
Validation loss: 2.0518526633580527

Epoch: 6| Step: 8
Training loss: 1.0276994705200195
Validation loss: 1.9823821584383647

Epoch: 6| Step: 9
Training loss: 0.420712947845459
Validation loss: 2.0213714440663657

Epoch: 6| Step: 10
Training loss: 0.434226393699646
Validation loss: 2.032277305920919

Epoch: 6| Step: 11
Training loss: 0.8555518388748169
Validation loss: 2.0220702290534973

Epoch: 6| Step: 12
Training loss: 0.718858540058136
Validation loss: 2.0548097093900046

Epoch: 6| Step: 13
Training loss: 0.5382452011108398
Validation loss: 1.9979904492696126

Epoch: 197| Step: 0
Training loss: 0.5097794532775879
Validation loss: 1.9915061593055725

Epoch: 6| Step: 1
Training loss: 1.0182626247406006
Validation loss: 2.02198988199234

Epoch: 6| Step: 2
Training loss: 0.6841608285903931
Validation loss: 2.0020991365114846

Epoch: 6| Step: 3
Training loss: 0.6727126836776733
Validation loss: 2.016165097554525

Epoch: 6| Step: 4
Training loss: 0.6112425327301025
Validation loss: 1.952836314837138

Epoch: 6| Step: 5
Training loss: 1.1842111349105835
Validation loss: 1.9456806580225627

Epoch: 6| Step: 6
Training loss: 0.6250834465026855
Validation loss: 1.9773648977279663

Epoch: 6| Step: 7
Training loss: 0.6854747533798218
Validation loss: 1.971433202425639

Epoch: 6| Step: 8
Training loss: 0.5002204775810242
Validation loss: 1.995357056458791

Epoch: 6| Step: 9
Training loss: 0.6372509598731995
Validation loss: 2.0148298740386963

Epoch: 6| Step: 10
Training loss: 0.6315356492996216
Validation loss: 2.0041932463645935

Epoch: 6| Step: 11
Training loss: 0.5818292498588562
Validation loss: 1.9784439007441204

Epoch: 6| Step: 12
Training loss: 0.5021563768386841
Validation loss: 2.051129380861918

Epoch: 6| Step: 13
Training loss: 0.6144144535064697
Validation loss: 1.954323132832845

Epoch: 198| Step: 0
Training loss: 0.5878636837005615
Validation loss: 2.0214914083480835

Epoch: 6| Step: 1
Training loss: 0.5101080536842346
Validation loss: 1.9997595151265461

Epoch: 6| Step: 2
Training loss: 0.9723565578460693
Validation loss: 2.064059833685557

Epoch: 6| Step: 3
Training loss: 0.4466685652732849
Validation loss: 2.016364256540934

Epoch: 6| Step: 4
Training loss: 0.36251676082611084
Validation loss: 2.029932975769043

Epoch: 6| Step: 5
Training loss: 0.38532036542892456
Validation loss: 1.9933876196543376

Epoch: 6| Step: 6
Training loss: 0.6092621088027954
Validation loss: 2.0188801288604736

Epoch: 6| Step: 7
Training loss: 0.9759570360183716
Validation loss: 1.9958088596661885

Epoch: 6| Step: 8
Training loss: 1.1023037433624268
Validation loss: 2.0508387883504233

Epoch: 6| Step: 9
Training loss: 0.5082294940948486
Validation loss: 2.0262094140052795

Epoch: 6| Step: 10
Training loss: 0.4421534836292267
Validation loss: 2.000812292098999

Epoch: 6| Step: 11
Training loss: 0.4442272186279297
Validation loss: 2.0291624466578164

Epoch: 6| Step: 12
Training loss: 1.236192226409912
Validation loss: 2.0470930139223733

Epoch: 6| Step: 13
Training loss: 0.5206038951873779
Validation loss: 2.028542439142863

Epoch: 199| Step: 0
Training loss: 0.5708911418914795
Validation loss: 1.9752941926320393

Epoch: 6| Step: 1
Training loss: 0.5152835249900818
Validation loss: 2.0374345779418945

Epoch: 6| Step: 2
Training loss: 0.9308950304985046
Validation loss: 2.0367106000582376

Epoch: 6| Step: 3
Training loss: 0.5895354747772217
Validation loss: 1.9986477891604106

Epoch: 6| Step: 4
Training loss: 0.8252655267715454
Validation loss: 2.0023273825645447

Epoch: 6| Step: 5
Training loss: 0.68311607837677
Validation loss: 2.04761532942454

Epoch: 6| Step: 6
Training loss: 0.5534791350364685
Validation loss: 2.0337323745091758

Epoch: 6| Step: 7
Training loss: 0.45812782645225525
Validation loss: 1.9646285772323608

Epoch: 6| Step: 8
Training loss: 0.7231075763702393
Validation loss: 2.054669141769409

Epoch: 6| Step: 9
Training loss: 0.5406475067138672
Validation loss: 2.0273160139719644

Epoch: 6| Step: 10
Training loss: 0.6400334239006042
Validation loss: 2.0546738107999167

Epoch: 6| Step: 11
Training loss: 0.5747150182723999
Validation loss: 2.0594515204429626

Epoch: 6| Step: 12
Training loss: 0.6270774602890015
Validation loss: 2.0573537349700928

Epoch: 6| Step: 13
Training loss: 0.604988694190979
Validation loss: 1.9624951680501301

Epoch: 200| Step: 0
Training loss: 0.9062715172767639
Validation loss: 1.9645016193389893

Epoch: 6| Step: 1
Training loss: 0.5004796981811523
Validation loss: 2.0038145383199057

Epoch: 6| Step: 2
Training loss: 0.3646506667137146
Validation loss: 2.0053565303484597

Epoch: 6| Step: 3
Training loss: 0.6036176681518555
Validation loss: 2.0461711486180625

Epoch: 6| Step: 4
Training loss: 1.0834342241287231
Validation loss: 2.000418504079183

Epoch: 6| Step: 5
Training loss: 0.6196049451828003
Validation loss: 1.9889694849650066

Epoch: 6| Step: 6
Training loss: 0.5218721628189087
Validation loss: 1.9736379384994507

Epoch: 6| Step: 7
Training loss: 0.2940100431442261
Validation loss: 1.983797272046407

Epoch: 6| Step: 8
Training loss: 0.8100823163986206
Validation loss: 2.0459712545077005

Epoch: 6| Step: 9
Training loss: 0.7146270275115967
Validation loss: 2.0023594895998635

Epoch: 6| Step: 10
Training loss: 0.6412395238876343
Validation loss: 2.0043182571729026

Epoch: 6| Step: 11
Training loss: 0.40095582604408264
Validation loss: 1.9913316766421

Epoch: 6| Step: 12
Training loss: 0.4330750107765198
Validation loss: 1.9909319877624512

Epoch: 6| Step: 13
Training loss: 1.0467565059661865
Validation loss: 2.0154414971669516

Epoch: 201| Step: 0
Training loss: 0.8628101944923401
Validation loss: 2.0302105943361917

Epoch: 6| Step: 1
Training loss: 0.35493066906929016
Validation loss: 1.9993700782457988

Epoch: 6| Step: 2
Training loss: 0.2795569896697998
Validation loss: 2.0307836731274924

Epoch: 6| Step: 3
Training loss: 0.9825664758682251
Validation loss: 2.0213771859804788

Epoch: 6| Step: 4
Training loss: 0.5974032878875732
Validation loss: 1.9976213574409485

Epoch: 6| Step: 5
Training loss: 0.5775834321975708
Validation loss: 2.0349205136299133

Epoch: 6| Step: 6
Training loss: 1.2025413513183594
Validation loss: 2.021111309528351

Epoch: 6| Step: 7
Training loss: 0.6742098927497864
Validation loss: 2.034542500972748

Epoch: 6| Step: 8
Training loss: 0.6944828033447266
Validation loss: 2.0101450284322104

Epoch: 6| Step: 9
Training loss: 0.2384112924337387
Validation loss: 2.0315112670262656

Epoch: 6| Step: 10
Training loss: 0.47138869762420654
Validation loss: 2.023376981417338

Epoch: 6| Step: 11
Training loss: 0.7775436639785767
Validation loss: 1.96108744541804

Epoch: 6| Step: 12
Training loss: 0.48675602674484253
Validation loss: 1.9821833372116089

Epoch: 6| Step: 13
Training loss: 0.5111862421035767
Validation loss: 1.9903141458829243

Epoch: 202| Step: 0
Training loss: 0.5760354995727539
Validation loss: 2.0134865045547485

Epoch: 6| Step: 1
Training loss: 0.45708563923835754
Validation loss: 2.045576592286428

Epoch: 6| Step: 2
Training loss: 0.7578483819961548
Validation loss: 2.029519816239675

Epoch: 6| Step: 3
Training loss: 0.6777099967002869
Validation loss: 2.053173383076986

Epoch: 6| Step: 4
Training loss: 0.515231728553772
Validation loss: 1.9934996366500854

Epoch: 6| Step: 5
Training loss: 0.4989232122898102
Validation loss: 2.0582377711931863

Epoch: 6| Step: 6
Training loss: 0.7488077282905579
Validation loss: 2.0063889821370444

Epoch: 6| Step: 7
Training loss: 0.962711751461029
Validation loss: 2.016003648440043

Epoch: 6| Step: 8
Training loss: 0.5337831377983093
Validation loss: 1.9740576148033142

Epoch: 6| Step: 9
Training loss: 0.688277006149292
Validation loss: 2.102268119653066

Epoch: 6| Step: 10
Training loss: 1.1995651721954346
Validation loss: 2.026145060857137

Epoch: 6| Step: 11
Training loss: 0.6062517166137695
Validation loss: 2.0130585034688315

Epoch: 6| Step: 12
Training loss: 0.3717239499092102
Validation loss: 1.9717177748680115

Epoch: 6| Step: 13
Training loss: 0.5640015602111816
Validation loss: 2.040376087029775

Epoch: 203| Step: 0
Training loss: 0.6214307546615601
Validation loss: 1.9629331827163696

Epoch: 6| Step: 1
Training loss: 0.43312162160873413
Validation loss: 2.057738641897837

Epoch: 6| Step: 2
Training loss: 0.7967991828918457
Validation loss: 1.9996291399002075

Epoch: 6| Step: 3
Training loss: 0.8456436395645142
Validation loss: 2.0335350235303244

Epoch: 6| Step: 4
Training loss: 0.48717382550239563
Validation loss: 1.9979827404022217

Epoch: 6| Step: 5
Training loss: 0.7781155109405518
Validation loss: 1.9958116014798482

Epoch: 6| Step: 6
Training loss: 1.041277527809143
Validation loss: 2.0130247871081033

Epoch: 6| Step: 7
Training loss: 0.4705219268798828
Validation loss: 2.0335613091786704

Epoch: 6| Step: 8
Training loss: 0.39910784363746643
Validation loss: 1.9887224237124126

Epoch: 6| Step: 9
Training loss: 0.6716038584709167
Validation loss: 2.0356446305910745

Epoch: 6| Step: 10
Training loss: 0.5966137051582336
Validation loss: 1.9997634291648865

Epoch: 6| Step: 11
Training loss: 0.480825275182724
Validation loss: 2.0123051404953003

Epoch: 6| Step: 12
Training loss: 0.5857049226760864
Validation loss: 2.0166441798210144

Epoch: 6| Step: 13
Training loss: 0.6328492164611816
Validation loss: 2.0066710313161216

Epoch: 204| Step: 0
Training loss: 0.35078489780426025
Validation loss: 2.0045109192530313

Epoch: 6| Step: 1
Training loss: 0.6879044771194458
Validation loss: 2.062934398651123

Epoch: 6| Step: 2
Training loss: 0.6033310890197754
Validation loss: 1.9852629105250041

Epoch: 6| Step: 3
Training loss: 0.6606080532073975
Validation loss: 2.0248093207677207

Epoch: 6| Step: 4
Training loss: 0.5403261780738831
Validation loss: 2.0274110436439514

Epoch: 6| Step: 5
Training loss: 0.6171340942382812
Validation loss: 2.0126285950342813

Epoch: 6| Step: 6
Training loss: 0.7089134454727173
Validation loss: 2.013882259527842

Epoch: 6| Step: 7
Training loss: 0.6823433041572571
Validation loss: 2.019710898399353

Epoch: 6| Step: 8
Training loss: 1.22000253200531
Validation loss: 1.9963055054346721

Epoch: 6| Step: 9
Training loss: 0.7109864354133606
Validation loss: 2.01188196738561

Epoch: 6| Step: 10
Training loss: 0.7407084703445435
Validation loss: 2.0014119148254395

Epoch: 6| Step: 11
Training loss: 0.4852956533432007
Validation loss: 2.0100245475769043

Epoch: 6| Step: 12
Training loss: 0.4186137318611145
Validation loss: 1.9916042288144429

Epoch: 6| Step: 13
Training loss: 0.6517319679260254
Validation loss: 2.0367449720700583

Epoch: 205| Step: 0
Training loss: 0.5000925660133362
Validation loss: 2.0202148159344993

Epoch: 6| Step: 1
Training loss: 0.34816932678222656
Validation loss: 1.9492222269376118

Epoch: 6| Step: 2
Training loss: 0.5550041794776917
Validation loss: 1.9511489470799763

Epoch: 6| Step: 3
Training loss: 0.4324619174003601
Validation loss: 2.034922937552134

Epoch: 6| Step: 4
Training loss: 0.676101565361023
Validation loss: 1.9861124952634175

Epoch: 6| Step: 5
Training loss: 0.42517611384391785
Validation loss: 1.9801596999168396

Epoch: 6| Step: 6
Training loss: 0.8169316053390503
Validation loss: 1.9612890481948853

Epoch: 6| Step: 7
Training loss: 0.419941246509552
Validation loss: 1.9822043975194295

Epoch: 6| Step: 8
Training loss: 0.9138252139091492
Validation loss: 2.006792108217875

Epoch: 6| Step: 9
Training loss: 0.6248047947883606
Validation loss: 1.9801188309987385

Epoch: 6| Step: 10
Training loss: 0.6612038612365723
Validation loss: 1.975095530351003

Epoch: 6| Step: 11
Training loss: 1.0823042392730713
Validation loss: 1.9487756888071697

Epoch: 6| Step: 12
Training loss: 0.6814876794815063
Validation loss: 1.9768460591634114

Epoch: 6| Step: 13
Training loss: 0.42624568939208984
Validation loss: 1.9973103006680806

Epoch: 206| Step: 0
Training loss: 1.136086344718933
Validation loss: 1.9809773961702983

Epoch: 6| Step: 1
Training loss: 0.6463263034820557
Validation loss: 1.9615203738212585

Epoch: 6| Step: 2
Training loss: 0.32309988141059875
Validation loss: 1.9483882983525593

Epoch: 6| Step: 3
Training loss: 0.9835389852523804
Validation loss: 1.9799342354138691

Epoch: 6| Step: 4
Training loss: 0.2767660617828369
Validation loss: 1.966143508752187

Epoch: 6| Step: 5
Training loss: 0.6068940758705139
Validation loss: 1.9729164838790894

Epoch: 6| Step: 6
Training loss: 0.7638436555862427
Validation loss: 2.0288173158963523

Epoch: 6| Step: 7
Training loss: 0.3026786148548126
Validation loss: 2.052802860736847

Epoch: 6| Step: 8
Training loss: 0.8958901166915894
Validation loss: 1.9989057580629985

Epoch: 6| Step: 9
Training loss: 0.550018310546875
Validation loss: 1.9745572209358215

Epoch: 6| Step: 10
Training loss: 0.48697084188461304
Validation loss: 1.9890361825625102

Epoch: 6| Step: 11
Training loss: 0.34201759099960327
Validation loss: 2.021188755830129

Epoch: 6| Step: 12
Training loss: 0.4918972849845886
Validation loss: 1.9849786957105

Epoch: 6| Step: 13
Training loss: 0.538208544254303
Validation loss: 1.9684240023295085

Epoch: 207| Step: 0
Training loss: 0.6487537622451782
Validation loss: 1.9990033904711406

Epoch: 6| Step: 1
Training loss: 0.7160134315490723
Validation loss: 1.980570097764333

Epoch: 6| Step: 2
Training loss: 0.6334007382392883
Validation loss: 2.0119557976722717

Epoch: 6| Step: 3
Training loss: 0.7038344144821167
Validation loss: 2.01565287510554

Epoch: 6| Step: 4
Training loss: 0.8445514440536499
Validation loss: 2.014517684777578

Epoch: 6| Step: 5
Training loss: 0.5805827379226685
Validation loss: 2.0426488320032754

Epoch: 6| Step: 6
Training loss: 0.5511673092842102
Validation loss: 2.0662381251653037

Epoch: 6| Step: 7
Training loss: 0.8716593980789185
Validation loss: 2.023590346177419

Epoch: 6| Step: 8
Training loss: 0.20524537563323975
Validation loss: 2.017628292242686

Epoch: 6| Step: 9
Training loss: 0.984692394733429
Validation loss: 1.9594906171162922

Epoch: 6| Step: 10
Training loss: 0.5251693725585938
Validation loss: 1.978834589322408

Epoch: 6| Step: 11
Training loss: 0.3184928894042969
Validation loss: 1.9722888271013896

Epoch: 6| Step: 12
Training loss: 0.26294463872909546
Validation loss: 2.007914880911509

Epoch: 6| Step: 13
Training loss: 0.33798614144325256
Validation loss: 2.0128923257191977

Epoch: 208| Step: 0
Training loss: 0.416760116815567
Validation loss: 1.9971724549929302

Epoch: 6| Step: 1
Training loss: 0.429002046585083
Validation loss: 1.9839160839716594

Epoch: 6| Step: 2
Training loss: 0.5499569177627563
Validation loss: 1.990692953268687

Epoch: 6| Step: 3
Training loss: 0.8546587228775024
Validation loss: 1.9933492143948872

Epoch: 6| Step: 4
Training loss: 0.5547118186950684
Validation loss: 1.9635134935379028

Epoch: 6| Step: 5
Training loss: 0.8693030476570129
Validation loss: 1.9802908301353455

Epoch: 6| Step: 6
Training loss: 0.4226665794849396
Validation loss: 1.9904782176017761

Epoch: 6| Step: 7
Training loss: 0.39412829279899597
Validation loss: 1.9950997233390808

Epoch: 6| Step: 8
Training loss: 0.7455991506576538
Validation loss: 1.9778704245885212

Epoch: 6| Step: 9
Training loss: 0.7232893705368042
Validation loss: 1.969915469487508

Epoch: 6| Step: 10
Training loss: 0.5682272911071777
Validation loss: 1.9945618708928425

Epoch: 6| Step: 11
Training loss: 0.3298857808113098
Validation loss: 1.9959291021029155

Epoch: 6| Step: 12
Training loss: 0.47542381286621094
Validation loss: 2.0226531426111856

Epoch: 6| Step: 13
Training loss: 0.9552873373031616
Validation loss: 2.0042125384012857

Epoch: 209| Step: 0
Training loss: 0.4893101155757904
Validation loss: 1.992267330487569

Epoch: 6| Step: 1
Training loss: 0.3004719018936157
Validation loss: 2.0316200653711953

Epoch: 6| Step: 2
Training loss: 0.47265487909317017
Validation loss: 2.018667161464691

Epoch: 6| Step: 3
Training loss: 0.3398933708667755
Validation loss: 1.982351005077362

Epoch: 6| Step: 4
Training loss: 0.47443050146102905
Validation loss: 2.040224572022756

Epoch: 6| Step: 5
Training loss: 0.43342524766921997
Validation loss: 2.024240493774414

Epoch: 6| Step: 6
Training loss: 0.7291547060012817
Validation loss: 2.0604339838027954

Epoch: 6| Step: 7
Training loss: 0.550823450088501
Validation loss: 2.070378541946411

Epoch: 6| Step: 8
Training loss: 0.4288557469844818
Validation loss: 1.984740972518921

Epoch: 6| Step: 9
Training loss: 1.1169123649597168
Validation loss: 2.0069663325945535

Epoch: 6| Step: 10
Training loss: 0.6169727444648743
Validation loss: 1.9512879053751628

Epoch: 6| Step: 11
Training loss: 1.0145517587661743
Validation loss: 2.0698638955752053

Epoch: 6| Step: 12
Training loss: 0.38496047258377075
Validation loss: 1.9542983373006184

Epoch: 6| Step: 13
Training loss: 0.6677529215812683
Validation loss: 2.011179586251577

Epoch: 210| Step: 0
Training loss: 0.6453649997711182
Validation loss: 2.028101861476898

Epoch: 6| Step: 1
Training loss: 0.6269082427024841
Validation loss: 2.01972230275472

Epoch: 6| Step: 2
Training loss: 0.4230709671974182
Validation loss: 1.9853164354960124

Epoch: 6| Step: 3
Training loss: 0.45994770526885986
Validation loss: 1.9807960589726765

Epoch: 6| Step: 4
Training loss: 0.9010316729545593
Validation loss: 2.007705807685852

Epoch: 6| Step: 5
Training loss: 0.7263436317443848
Validation loss: 1.9997128248214722

Epoch: 6| Step: 6
Training loss: 0.5838847160339355
Validation loss: 1.960182507832845

Epoch: 6| Step: 7
Training loss: 0.6657136678695679
Validation loss: 2.0215549866358438

Epoch: 6| Step: 8
Training loss: 0.5790728330612183
Validation loss: 2.0252663493156433

Epoch: 6| Step: 9
Training loss: 0.6423923969268799
Validation loss: 2.0143386721611023

Epoch: 6| Step: 10
Training loss: 0.591052770614624
Validation loss: 1.9962592522303264

Epoch: 6| Step: 11
Training loss: 0.6646934747695923
Validation loss: 1.950601597627004

Epoch: 6| Step: 12
Training loss: 0.8535739183425903
Validation loss: 1.955415407816569

Epoch: 6| Step: 13
Training loss: 0.26116451621055603
Validation loss: 2.007438878218333

Epoch: 211| Step: 0
Training loss: 0.39807674288749695
Validation loss: 1.944029947121938

Epoch: 6| Step: 1
Training loss: 0.7520100474357605
Validation loss: 1.992994745572408

Epoch: 6| Step: 2
Training loss: 1.0448449850082397
Validation loss: 1.9470452070236206

Epoch: 6| Step: 3
Training loss: 0.5006358623504639
Validation loss: 1.9528250495592754

Epoch: 6| Step: 4
Training loss: 0.47320565581321716
Validation loss: 1.9923179745674133

Epoch: 6| Step: 5
Training loss: 0.5588690042495728
Validation loss: 1.978109618028005

Epoch: 6| Step: 6
Training loss: 0.5738744735717773
Validation loss: 2.0217361450195312

Epoch: 6| Step: 7
Training loss: 0.4301187992095947
Validation loss: 1.9859086473782857

Epoch: 6| Step: 8
Training loss: 0.6775760054588318
Validation loss: 2.0229307810465493

Epoch: 6| Step: 9
Training loss: 0.8298937082290649
Validation loss: 2.036672612031301

Epoch: 6| Step: 10
Training loss: 0.3005977272987366
Validation loss: 1.978378673394521

Epoch: 6| Step: 11
Training loss: 0.497466504573822
Validation loss: 2.0030659834543862

Epoch: 6| Step: 12
Training loss: 0.7894295454025269
Validation loss: 1.9879858493804932

Epoch: 6| Step: 13
Training loss: 0.6182891726493835
Validation loss: 2.0092025796572366

Epoch: 212| Step: 0
Training loss: 0.6494998931884766
Validation loss: 2.0411375761032104

Epoch: 6| Step: 1
Training loss: 0.7924569249153137
Validation loss: 2.046910603841146

Epoch: 6| Step: 2
Training loss: 0.4732447862625122
Validation loss: 2.0106914043426514

Epoch: 6| Step: 3
Training loss: 0.4827125668525696
Validation loss: 2.0299778381983438

Epoch: 6| Step: 4
Training loss: 0.49805518984794617
Validation loss: 1.9604638020197551

Epoch: 6| Step: 5
Training loss: 0.704358696937561
Validation loss: 1.9871831734975178

Epoch: 6| Step: 6
Training loss: 0.4867412745952606
Validation loss: 2.0262209375699363

Epoch: 6| Step: 7
Training loss: 0.554884672164917
Validation loss: 2.0517172813415527

Epoch: 6| Step: 8
Training loss: 0.8439466953277588
Validation loss: 2.02390589316686

Epoch: 6| Step: 9
Training loss: 0.42226460576057434
Validation loss: 2.027211765448252

Epoch: 6| Step: 10
Training loss: 0.49043038487434387
Validation loss: 2.0270758867263794

Epoch: 6| Step: 11
Training loss: 0.9907541275024414
Validation loss: 2.0130534966786704

Epoch: 6| Step: 12
Training loss: 0.4457958936691284
Validation loss: 2.0173569321632385

Epoch: 6| Step: 13
Training loss: 0.4190075993537903
Validation loss: 2.014087677001953

Epoch: 213| Step: 0
Training loss: 0.6131835579872131
Validation loss: 1.973143498102824

Epoch: 6| Step: 1
Training loss: 0.8424113988876343
Validation loss: 2.0200407902399697

Epoch: 6| Step: 2
Training loss: 0.882821798324585
Validation loss: 1.9991784691810608

Epoch: 6| Step: 3
Training loss: 0.45040327310562134
Validation loss: 1.9864683747291565

Epoch: 6| Step: 4
Training loss: 0.3731631636619568
Validation loss: 2.0009761651357016

Epoch: 6| Step: 5
Training loss: 0.35245952010154724
Validation loss: 2.0010640223821006

Epoch: 6| Step: 6
Training loss: 0.44713544845581055
Validation loss: 1.9901491403579712

Epoch: 6| Step: 7
Training loss: 0.5387741327285767
Validation loss: 1.9577841758728027

Epoch: 6| Step: 8
Training loss: 0.6606575846672058
Validation loss: 2.023872435092926

Epoch: 6| Step: 9
Training loss: 0.5401000380516052
Validation loss: 2.032803952693939

Epoch: 6| Step: 10
Training loss: 0.7574163675308228
Validation loss: 1.9857817888259888

Epoch: 6| Step: 11
Training loss: 1.0832984447479248
Validation loss: 2.020780165990194

Epoch: 6| Step: 12
Training loss: 0.366835355758667
Validation loss: 2.0258068243662515

Epoch: 6| Step: 13
Training loss: 0.296549916267395
Validation loss: 1.9343950152397156

Epoch: 214| Step: 0
Training loss: 0.4618815779685974
Validation loss: 2.0139138102531433

Epoch: 6| Step: 1
Training loss: 0.3402465283870697
Validation loss: 2.0033199191093445

Epoch: 6| Step: 2
Training loss: 0.5337872505187988
Validation loss: 1.9653127392133076

Epoch: 6| Step: 3
Training loss: 0.8690271377563477
Validation loss: 2.002225915590922

Epoch: 6| Step: 4
Training loss: 0.3337811827659607
Validation loss: 1.9937845667203267

Epoch: 6| Step: 5
Training loss: 0.45878326892852783
Validation loss: 2.0182520945866904

Epoch: 6| Step: 6
Training loss: 0.8280760049819946
Validation loss: 2.016936997572581

Epoch: 6| Step: 7
Training loss: 0.5892907977104187
Validation loss: 1.9623786409695942

Epoch: 6| Step: 8
Training loss: 0.8205076456069946
Validation loss: 2.0216615994771323

Epoch: 6| Step: 9
Training loss: 0.5942824482917786
Validation loss: 1.9608041048049927

Epoch: 6| Step: 10
Training loss: 0.4963451623916626
Validation loss: 1.9771464864412944

Epoch: 6| Step: 11
Training loss: 0.8809404373168945
Validation loss: 1.9561048944791157

Epoch: 6| Step: 12
Training loss: 0.4856894016265869
Validation loss: 2.01264222462972

Epoch: 6| Step: 13
Training loss: 0.8501901626586914
Validation loss: 1.9999958475430806

Epoch: 215| Step: 0
Training loss: 0.634300708770752
Validation loss: 2.032815098762512

Epoch: 6| Step: 1
Training loss: 0.6858168840408325
Validation loss: 1.9976399739583333

Epoch: 6| Step: 2
Training loss: 0.7706567049026489
Validation loss: 1.9664916396141052

Epoch: 6| Step: 3
Training loss: 0.3399028182029724
Validation loss: 1.9926698406537373

Epoch: 6| Step: 4
Training loss: 0.5007863640785217
Validation loss: 2.0262113014856973

Epoch: 6| Step: 5
Training loss: 0.6956359148025513
Validation loss: 2.0077503323554993

Epoch: 6| Step: 6
Training loss: 0.5314685106277466
Validation loss: 2.0054670174916587

Epoch: 6| Step: 7
Training loss: 0.3825340270996094
Validation loss: 2.025888899962107

Epoch: 6| Step: 8
Training loss: 0.47642144560813904
Validation loss: 1.984805981318156

Epoch: 6| Step: 9
Training loss: 0.5058437585830688
Validation loss: 2.0031035939852395

Epoch: 6| Step: 10
Training loss: 0.6179706454277039
Validation loss: 2.0159836808840432

Epoch: 6| Step: 11
Training loss: 1.33005952835083
Validation loss: 2.0091559688250222

Epoch: 6| Step: 12
Training loss: 0.38220614194869995
Validation loss: 2.014613091945648

Epoch: 6| Step: 13
Training loss: 0.6067051887512207
Validation loss: 2.0134065747261047

Epoch: 216| Step: 0
Training loss: 0.7948321104049683
Validation loss: 1.9541073242823284

Epoch: 6| Step: 1
Training loss: 0.2862493097782135
Validation loss: 2.0346244176228843

Epoch: 6| Step: 2
Training loss: 0.30154508352279663
Validation loss: 2.036062022050222

Epoch: 6| Step: 3
Training loss: 0.663113534450531
Validation loss: 2.0126092235247293

Epoch: 6| Step: 4
Training loss: 0.538458526134491
Validation loss: 2.0057930747667947

Epoch: 6| Step: 5
Training loss: 0.46834468841552734
Validation loss: 2.0088019371032715

Epoch: 6| Step: 6
Training loss: 0.44483911991119385
Validation loss: 2.03360923131307

Epoch: 6| Step: 7
Training loss: 0.4144039452075958
Validation loss: 2.0214668114980063

Epoch: 6| Step: 8
Training loss: 0.598319411277771
Validation loss: 1.9610566298166912

Epoch: 6| Step: 9
Training loss: 0.8134740591049194
Validation loss: 2.0537511308987937

Epoch: 6| Step: 10
Training loss: 1.0072542428970337
Validation loss: 2.0317801038424173

Epoch: 6| Step: 11
Training loss: 0.52978515625
Validation loss: 1.9918991525967915

Epoch: 6| Step: 12
Training loss: 0.4495948553085327
Validation loss: 1.9880733092625935

Epoch: 6| Step: 13
Training loss: 0.7389580607414246
Validation loss: 1.988877534866333

Epoch: 217| Step: 0
Training loss: 0.9729225039482117
Validation loss: 1.9772875507672627

Epoch: 6| Step: 1
Training loss: 0.8219627141952515
Validation loss: 2.029338995615641

Epoch: 6| Step: 2
Training loss: 0.4814334511756897
Validation loss: 2.0471251010894775

Epoch: 6| Step: 3
Training loss: 0.4997789263725281
Validation loss: 1.9774603645006816

Epoch: 6| Step: 4
Training loss: 0.6785488724708557
Validation loss: 1.9674769242604573

Epoch: 6| Step: 5
Training loss: 0.4510519206523895
Validation loss: 2.0321967403093972

Epoch: 6| Step: 6
Training loss: 0.2415197193622589
Validation loss: 1.9862894018491108

Epoch: 6| Step: 7
Training loss: 0.4289289116859436
Validation loss: 2.008802056312561

Epoch: 6| Step: 8
Training loss: 0.6363345980644226
Validation loss: 2.0269647439320884

Epoch: 6| Step: 9
Training loss: 0.7316063642501831
Validation loss: 2.027581771214803

Epoch: 6| Step: 10
Training loss: 0.6589114665985107
Validation loss: 1.9826215902964275

Epoch: 6| Step: 11
Training loss: 0.46261176466941833
Validation loss: 2.0567636092503867

Epoch: 6| Step: 12
Training loss: 0.7423796653747559
Validation loss: 1.9939505656560261

Epoch: 6| Step: 13
Training loss: 0.5896735191345215
Validation loss: 2.0262658397356668

Epoch: 218| Step: 0
Training loss: 0.5637151002883911
Validation loss: 1.9982736706733704

Epoch: 6| Step: 1
Training loss: 0.7022360563278198
Validation loss: 1.9669679800669353

Epoch: 6| Step: 2
Training loss: 0.6726597547531128
Validation loss: 1.945003867149353

Epoch: 6| Step: 3
Training loss: 0.34968334436416626
Validation loss: 1.9997999668121338

Epoch: 6| Step: 4
Training loss: 0.5740519165992737
Validation loss: 1.9856096307436626

Epoch: 6| Step: 5
Training loss: 0.6183003187179565
Validation loss: 1.9163424372673035

Epoch: 6| Step: 6
Training loss: 0.3186764419078827
Validation loss: 1.9623107711474101

Epoch: 6| Step: 7
Training loss: 0.2989822030067444
Validation loss: 1.9202868938446045

Epoch: 6| Step: 8
Training loss: 0.6079633831977844
Validation loss: 2.0138293306032815

Epoch: 6| Step: 9
Training loss: 0.8380654454231262
Validation loss: 1.9894097844759624

Epoch: 6| Step: 10
Training loss: 1.1698412895202637
Validation loss: 1.9841208656628926

Epoch: 6| Step: 11
Training loss: 0.5471101999282837
Validation loss: 2.029253045717875

Epoch: 6| Step: 12
Training loss: 0.5031282305717468
Validation loss: 1.9802095890045166

Epoch: 6| Step: 13
Training loss: 0.5130554437637329
Validation loss: 2.0040784080823264

Epoch: 219| Step: 0
Training loss: 0.5307588577270508
Validation loss: 1.9770730137825012

Epoch: 6| Step: 1
Training loss: 0.8941828012466431
Validation loss: 1.9809836347897847

Epoch: 6| Step: 2
Training loss: 0.5269680619239807
Validation loss: 1.9885468085606892

Epoch: 6| Step: 3
Training loss: 0.4369831383228302
Validation loss: 1.986578106880188

Epoch: 6| Step: 4
Training loss: 0.5308372974395752
Validation loss: 2.014759878317515

Epoch: 6| Step: 5
Training loss: 0.5934257507324219
Validation loss: 1.952079991499583

Epoch: 6| Step: 6
Training loss: 0.44128769636154175
Validation loss: 1.9870990713437398

Epoch: 6| Step: 7
Training loss: 0.16423124074935913
Validation loss: 1.9756146272023518

Epoch: 6| Step: 8
Training loss: 0.5839202404022217
Validation loss: 2.0115934014320374

Epoch: 6| Step: 9
Training loss: 0.47540149092674255
Validation loss: 2.004577616850535

Epoch: 6| Step: 10
Training loss: 0.37866878509521484
Validation loss: 1.9806278546651204

Epoch: 6| Step: 11
Training loss: 1.140786051750183
Validation loss: 2.010571002960205

Epoch: 6| Step: 12
Training loss: 0.7323488593101501
Validation loss: 1.9534353613853455

Epoch: 6| Step: 13
Training loss: 0.36064180731773376
Validation loss: 2.003978987534841

Epoch: 220| Step: 0
Training loss: 0.5245117545127869
Validation loss: 2.0058164993921914

Epoch: 6| Step: 1
Training loss: 0.3356379270553589
Validation loss: 1.9773265520731609

Epoch: 6| Step: 2
Training loss: 0.7104028463363647
Validation loss: 2.035426398118337

Epoch: 6| Step: 3
Training loss: 0.7107069492340088
Validation loss: 2.002263526121775

Epoch: 6| Step: 4
Training loss: 0.25065064430236816
Validation loss: 2.0714239875475564

Epoch: 6| Step: 5
Training loss: 0.4825827181339264
Validation loss: 2.0575907230377197

Epoch: 6| Step: 6
Training loss: 0.5038661956787109
Validation loss: 2.0660516818364463

Epoch: 6| Step: 7
Training loss: 0.58357834815979
Validation loss: 1.96822851896286

Epoch: 6| Step: 8
Training loss: 0.42509740591049194
Validation loss: 1.9727999369303386

Epoch: 6| Step: 9
Training loss: 0.7489644289016724
Validation loss: 1.994787295659383

Epoch: 6| Step: 10
Training loss: 0.31031960248947144
Validation loss: 1.9964810808499653

Epoch: 6| Step: 11
Training loss: 1.1832146644592285
Validation loss: 1.9710238178571065

Epoch: 6| Step: 12
Training loss: 0.2690720856189728
Validation loss: 2.007857064406077

Epoch: 6| Step: 13
Training loss: 0.9688899517059326
Validation loss: 1.9869142174720764

Epoch: 221| Step: 0
Training loss: 0.42079663276672363
Validation loss: 2.0397175550460815

Epoch: 6| Step: 1
Training loss: 0.8615404367446899
Validation loss: 1.9947208762168884

Epoch: 6| Step: 2
Training loss: 0.6556478142738342
Validation loss: 2.0283148288726807

Epoch: 6| Step: 3
Training loss: 0.9443260431289673
Validation loss: 1.9820655584335327

Epoch: 6| Step: 4
Training loss: 0.2828214168548584
Validation loss: 2.055025279521942

Epoch: 6| Step: 5
Training loss: 0.5394524335861206
Validation loss: 2.0153164863586426

Epoch: 6| Step: 6
Training loss: 0.361224889755249
Validation loss: 1.9961346586545308

Epoch: 6| Step: 7
Training loss: 0.5689151883125305
Validation loss: 2.012018839518229

Epoch: 6| Step: 8
Training loss: 0.5441442728042603
Validation loss: 2.064899663130442

Epoch: 6| Step: 9
Training loss: 0.26911699771881104
Validation loss: 1.9848536451657612

Epoch: 6| Step: 10
Training loss: 0.7211185693740845
Validation loss: 1.9569383263587952

Epoch: 6| Step: 11
Training loss: 0.5533770322799683
Validation loss: 1.9461662769317627

Epoch: 6| Step: 12
Training loss: 0.5411819219589233
Validation loss: 2.028219719727834

Epoch: 6| Step: 13
Training loss: 0.6267610788345337
Validation loss: 2.0071894923845925

Epoch: 222| Step: 0
Training loss: 0.71396404504776
Validation loss: 1.9549375176429749

Epoch: 6| Step: 1
Training loss: 0.39606544375419617
Validation loss: 1.986973524093628

Epoch: 6| Step: 2
Training loss: 0.7173573970794678
Validation loss: 1.9811379512151082

Epoch: 6| Step: 3
Training loss: 0.447706401348114
Validation loss: 2.013392905394236

Epoch: 6| Step: 4
Training loss: 0.5925942659378052
Validation loss: 2.0465412537256875

Epoch: 6| Step: 5
Training loss: 0.3787071704864502
Validation loss: 2.026844402154287

Epoch: 6| Step: 6
Training loss: 0.5553739070892334
Validation loss: 1.9813228050867717

Epoch: 6| Step: 7
Training loss: 0.789899468421936
Validation loss: 1.999975601832072

Epoch: 6| Step: 8
Training loss: 0.5067430734634399
Validation loss: 1.986978828907013

Epoch: 6| Step: 9
Training loss: 0.45438525080680847
Validation loss: 1.9994215766588848

Epoch: 6| Step: 10
Training loss: 0.9402357935905457
Validation loss: 2.0130555828412375

Epoch: 6| Step: 11
Training loss: 0.4894140362739563
Validation loss: 1.9951028227806091

Epoch: 6| Step: 12
Training loss: 0.39272335171699524
Validation loss: 1.9897136092185974

Epoch: 6| Step: 13
Training loss: 0.3106735646724701
Validation loss: 1.9856446584065754

Epoch: 223| Step: 0
Training loss: 0.5918205976486206
Validation loss: 2.008122444152832

Epoch: 6| Step: 1
Training loss: 0.5015931725502014
Validation loss: 2.0349097649256387

Epoch: 6| Step: 2
Training loss: 0.9421228766441345
Validation loss: 1.9947348237037659

Epoch: 6| Step: 3
Training loss: 0.4307710528373718
Validation loss: 1.9984474778175354

Epoch: 6| Step: 4
Training loss: 0.5797708034515381
Validation loss: 1.991978148619334

Epoch: 6| Step: 5
Training loss: 0.7156850099563599
Validation loss: 2.029249091943105

Epoch: 6| Step: 6
Training loss: 0.6515907049179077
Validation loss: 2.0103547175725303

Epoch: 6| Step: 7
Training loss: 0.5367647409439087
Validation loss: 2.005646765232086

Epoch: 6| Step: 8
Training loss: 0.55122971534729
Validation loss: 2.04611998796463

Epoch: 6| Step: 9
Training loss: 0.5445220470428467
Validation loss: 2.030570904413859

Epoch: 6| Step: 10
Training loss: 0.5039038062095642
Validation loss: 2.0115791956583657

Epoch: 6| Step: 11
Training loss: 0.544093668460846
Validation loss: 1.9322440425554912

Epoch: 6| Step: 12
Training loss: 0.7073044180870056
Validation loss: 1.983256220817566

Epoch: 6| Step: 13
Training loss: 0.46114975214004517
Validation loss: 2.0086296796798706

Epoch: 224| Step: 0
Training loss: 0.5707473158836365
Validation loss: 1.9843177596728008

Epoch: 6| Step: 1
Training loss: 0.607765793800354
Validation loss: 2.0571549932161965

Epoch: 6| Step: 2
Training loss: 0.9739962816238403
Validation loss: 2.001869857311249

Epoch: 6| Step: 3
Training loss: 0.4636346995830536
Validation loss: 2.0130951404571533

Epoch: 6| Step: 4
Training loss: 0.7802302837371826
Validation loss: 2.033880571524302

Epoch: 6| Step: 5
Training loss: 0.4488656222820282
Validation loss: 2.0541967153549194

Epoch: 6| Step: 6
Training loss: 0.28220558166503906
Validation loss: 1.9991365273793538

Epoch: 6| Step: 7
Training loss: 0.8016297817230225
Validation loss: 2.0124139984448752

Epoch: 6| Step: 8
Training loss: 0.27972355484962463
Validation loss: 2.0110512375831604

Epoch: 6| Step: 9
Training loss: 0.7765620350837708
Validation loss: 2.0467554132143655

Epoch: 6| Step: 10
Training loss: 0.6950668692588806
Validation loss: 2.017669439315796

Epoch: 6| Step: 11
Training loss: 0.37420254945755005
Validation loss: 2.0310837030410767

Epoch: 6| Step: 12
Training loss: 0.34882327914237976
Validation loss: 1.986547311147054

Epoch: 6| Step: 13
Training loss: 0.38633841276168823
Validation loss: 2.0312536160151162

Epoch: 225| Step: 0
Training loss: 0.33235305547714233
Validation loss: 2.022693117459615

Epoch: 6| Step: 1
Training loss: 0.6219791173934937
Validation loss: 2.0200018286705017

Epoch: 6| Step: 2
Training loss: 0.4035137891769409
Validation loss: 2.006416916847229

Epoch: 6| Step: 3
Training loss: 0.7000255584716797
Validation loss: 2.0428967475891113

Epoch: 6| Step: 4
Training loss: 0.6050857901573181
Validation loss: 2.0423529942830405

Epoch: 6| Step: 5
Training loss: 0.7498297691345215
Validation loss: 2.0094302694002786

Epoch: 6| Step: 6
Training loss: 0.5892963409423828
Validation loss: 2.0079582730929055

Epoch: 6| Step: 7
Training loss: 0.4444858133792877
Validation loss: 1.9533487558364868

Epoch: 6| Step: 8
Training loss: 0.7772544622421265
Validation loss: 2.016910413901011

Epoch: 6| Step: 9
Training loss: 0.7601425051689148
Validation loss: 2.033467253049215

Epoch: 6| Step: 10
Training loss: 0.3324931859970093
Validation loss: 2.0105970899264016

Epoch: 6| Step: 11
Training loss: 0.2755042314529419
Validation loss: 2.081642190615336

Epoch: 6| Step: 12
Training loss: 0.45072489976882935
Validation loss: 2.0243076284726462

Epoch: 6| Step: 13
Training loss: 0.5246344208717346
Validation loss: 2.0010523796081543

Epoch: 226| Step: 0
Training loss: 0.6365267634391785
Validation loss: 1.9732945958773296

Epoch: 6| Step: 1
Training loss: 0.9269719123840332
Validation loss: 2.0025344689687095

Epoch: 6| Step: 2
Training loss: 0.5066799521446228
Validation loss: 2.0033804178237915

Epoch: 6| Step: 3
Training loss: 0.46701836585998535
Validation loss: 2.019814153512319

Epoch: 6| Step: 4
Training loss: 0.6093720197677612
Validation loss: 1.9789445400238037

Epoch: 6| Step: 5
Training loss: 0.6425046920776367
Validation loss: 2.0681779781977334

Epoch: 6| Step: 6
Training loss: 0.5126806497573853
Validation loss: 2.0468077063560486

Epoch: 6| Step: 7
Training loss: 0.3557758629322052
Validation loss: 2.035380760828654

Epoch: 6| Step: 8
Training loss: 0.7094351649284363
Validation loss: 2.0555071036020913

Epoch: 6| Step: 9
Training loss: 0.2418403923511505
Validation loss: 2.048698822657267

Epoch: 6| Step: 10
Training loss: 0.5440602898597717
Validation loss: 1.9853979150454204

Epoch: 6| Step: 11
Training loss: 0.45937639474868774
Validation loss: 2.058886229991913

Epoch: 6| Step: 12
Training loss: 0.46207642555236816
Validation loss: 2.0285327633221946

Epoch: 6| Step: 13
Training loss: 0.5638643503189087
Validation loss: 2.0736889640490213

Epoch: 227| Step: 0
Training loss: 0.4896257221698761
Validation loss: 1.988962213198344

Epoch: 6| Step: 1
Training loss: 0.6244592070579529
Validation loss: 2.0445530811945596

Epoch: 6| Step: 2
Training loss: 0.5304363369941711
Validation loss: 2.024802088737488

Epoch: 6| Step: 3
Training loss: 0.6225364208221436
Validation loss: 2.0139071146647134

Epoch: 6| Step: 4
Training loss: 0.25936806201934814
Validation loss: 2.0089241663614907

Epoch: 6| Step: 5
Training loss: 0.402681827545166
Validation loss: 1.9752888282140095

Epoch: 6| Step: 6
Training loss: 0.7083572745323181
Validation loss: 2.0536461075146994

Epoch: 6| Step: 7
Training loss: 0.4665302038192749
Validation loss: 2.0193453232447305

Epoch: 6| Step: 8
Training loss: 0.40301668643951416
Validation loss: 2.0219951272010803

Epoch: 6| Step: 9
Training loss: 0.8032119274139404
Validation loss: 2.0278637409210205

Epoch: 6| Step: 10
Training loss: 0.3026959002017975
Validation loss: 2.033639430999756

Epoch: 6| Step: 11
Training loss: 0.6950491666793823
Validation loss: 1.999321420987447

Epoch: 6| Step: 12
Training loss: 0.42213743925094604
Validation loss: 2.0310731728871665

Epoch: 6| Step: 13
Training loss: 0.9634954929351807
Validation loss: 2.045873244603475

Epoch: 228| Step: 0
Training loss: 0.7366483807563782
Validation loss: 2.0172313849131265

Epoch: 6| Step: 1
Training loss: 0.6558541059494019
Validation loss: 2.031314810117086

Epoch: 6| Step: 2
Training loss: 0.5072213411331177
Validation loss: 2.0146230459213257

Epoch: 6| Step: 3
Training loss: 0.39278513193130493
Validation loss: 2.0539799133936563

Epoch: 6| Step: 4
Training loss: 0.6586014032363892
Validation loss: 2.0185420910517373

Epoch: 6| Step: 5
Training loss: 0.6978347897529602
Validation loss: 1.9924894372622173

Epoch: 6| Step: 6
Training loss: 0.5672080516815186
Validation loss: 2.0195188919703164

Epoch: 6| Step: 7
Training loss: 0.2689899802207947
Validation loss: 2.010386347770691

Epoch: 6| Step: 8
Training loss: 0.5630530714988708
Validation loss: 2.00285134712855

Epoch: 6| Step: 9
Training loss: 0.5708266496658325
Validation loss: 1.9538207252820332

Epoch: 6| Step: 10
Training loss: 0.5000552535057068
Validation loss: 2.0279812018076577

Epoch: 6| Step: 11
Training loss: 0.7064117789268494
Validation loss: 2.0388458967208862

Epoch: 6| Step: 12
Training loss: 0.5365945100784302
Validation loss: 2.0065870682398477

Epoch: 6| Step: 13
Training loss: 0.514514684677124
Validation loss: 2.0219667156537375

Epoch: 229| Step: 0
Training loss: 0.5131862163543701
Validation loss: 1.9663037657737732

Epoch: 6| Step: 1
Training loss: 1.141603708267212
Validation loss: 2.0021085937817893

Epoch: 6| Step: 2
Training loss: 0.637594997882843
Validation loss: 1.9728469848632812

Epoch: 6| Step: 3
Training loss: 0.2709014117717743
Validation loss: 2.071954150994619

Epoch: 6| Step: 4
Training loss: 0.29968157410621643
Validation loss: 2.012592156728109

Epoch: 6| Step: 5
Training loss: 0.6049063801765442
Validation loss: 2.0180381536483765

Epoch: 6| Step: 6
Training loss: 1.1422256231307983
Validation loss: 1.986588180065155

Epoch: 6| Step: 7
Training loss: 0.4622896909713745
Validation loss: 2.0236162543296814

Epoch: 6| Step: 8
Training loss: 0.3086113929748535
Validation loss: 1.9846153060595195

Epoch: 6| Step: 9
Training loss: 0.45983338356018066
Validation loss: 2.001319726308187

Epoch: 6| Step: 10
Training loss: 0.35679078102111816
Validation loss: 1.9670170148213704

Epoch: 6| Step: 11
Training loss: 0.39642107486724854
Validation loss: 2.021053751309713

Epoch: 6| Step: 12
Training loss: 0.5688501596450806
Validation loss: 2.0301323731740317

Epoch: 6| Step: 13
Training loss: 0.4175432324409485
Validation loss: 2.0015624165534973

Epoch: 230| Step: 0
Training loss: 0.4616684317588806
Validation loss: 2.0266597469647727

Epoch: 6| Step: 1
Training loss: 0.38825851678848267
Validation loss: 1.9884376525878906

Epoch: 6| Step: 2
Training loss: 0.6549093723297119
Validation loss: 2.048418919245402

Epoch: 6| Step: 3
Training loss: 0.9109628200531006
Validation loss: 2.011746903260549

Epoch: 6| Step: 4
Training loss: 0.5833959579467773
Validation loss: 2.0411274830500283

Epoch: 6| Step: 5
Training loss: 0.6674618721008301
Validation loss: 2.061599294344584

Epoch: 6| Step: 6
Training loss: 0.4141315817832947
Validation loss: 2.022402067979177

Epoch: 6| Step: 7
Training loss: 0.6639156341552734
Validation loss: 2.0025338331858316

Epoch: 6| Step: 8
Training loss: 0.47950130701065063
Validation loss: 2.0265700022379556

Epoch: 6| Step: 9
Training loss: 0.6665036082267761
Validation loss: 2.0481151938438416

Epoch: 6| Step: 10
Training loss: 0.21791589260101318
Validation loss: 1.9909562667210896

Epoch: 6| Step: 11
Training loss: 0.25419265031814575
Validation loss: 1.993780493736267

Epoch: 6| Step: 12
Training loss: 0.5159285068511963
Validation loss: 1.9934856692949932

Epoch: 6| Step: 13
Training loss: 0.45460447669029236
Validation loss: 1.9828108350435893

Epoch: 231| Step: 0
Training loss: 0.6603797674179077
Validation loss: 1.9911051789919536

Epoch: 6| Step: 1
Training loss: 0.44110918045043945
Validation loss: 1.9724177320798237

Epoch: 6| Step: 2
Training loss: 0.4641895294189453
Validation loss: 2.0306820273399353

Epoch: 6| Step: 3
Training loss: 0.48311328887939453
Validation loss: 2.0128196676572165

Epoch: 6| Step: 4
Training loss: 0.5403070449829102
Validation loss: 2.016672730445862

Epoch: 6| Step: 5
Training loss: 0.36298856139183044
Validation loss: 2.0427643060684204

Epoch: 6| Step: 6
Training loss: 0.30266669392585754
Validation loss: 2.0261578361193338

Epoch: 6| Step: 7
Training loss: 0.20834121108055115
Validation loss: 1.993857781092326

Epoch: 6| Step: 8
Training loss: 0.5395236015319824
Validation loss: 2.0202680230140686

Epoch: 6| Step: 9
Training loss: 0.5231685638427734
Validation loss: 2.0053054094314575

Epoch: 6| Step: 10
Training loss: 0.7527864575386047
Validation loss: 2.0129133264223733

Epoch: 6| Step: 11
Training loss: 0.9642457365989685
Validation loss: 1.979748785495758

Epoch: 6| Step: 12
Training loss: 0.2579769790172577
Validation loss: 1.9968161384264629

Epoch: 6| Step: 13
Training loss: 0.8276087045669556
Validation loss: 2.0103052854537964

Epoch: 232| Step: 0
Training loss: 0.7745437026023865
Validation loss: 1.97934228181839

Epoch: 6| Step: 1
Training loss: 0.23515111207962036
Validation loss: 2.0121616323788962

Epoch: 6| Step: 2
Training loss: 0.5445671677589417
Validation loss: 1.9636415839195251

Epoch: 6| Step: 3
Training loss: 0.3400711417198181
Validation loss: 2.0142714579900107

Epoch: 6| Step: 4
Training loss: 0.42273011803627014
Validation loss: 1.9524386723836262

Epoch: 6| Step: 5
Training loss: 0.5952783823013306
Validation loss: 1.9891351858774822

Epoch: 6| Step: 6
Training loss: 0.42270922660827637
Validation loss: 1.9765037298202515

Epoch: 6| Step: 7
Training loss: 0.8258345127105713
Validation loss: 1.976787010828654

Epoch: 6| Step: 8
Training loss: 0.3795304298400879
Validation loss: 1.9850768844286601

Epoch: 6| Step: 9
Training loss: 0.24002918601036072
Validation loss: 2.0587024490038552

Epoch: 6| Step: 10
Training loss: 0.42955413460731506
Validation loss: 2.0070936481157937

Epoch: 6| Step: 11
Training loss: 0.5209407806396484
Validation loss: 1.9999894897143047

Epoch: 6| Step: 12
Training loss: 0.42261287569999695
Validation loss: 2.0743794441223145

Epoch: 6| Step: 13
Training loss: 0.9279428720474243
Validation loss: 2.006934424241384

Epoch: 233| Step: 0
Training loss: 0.8663354516029358
Validation loss: 2.0545989274978638

Epoch: 6| Step: 1
Training loss: 1.03941011428833
Validation loss: 2.038453777631124

Epoch: 6| Step: 2
Training loss: 0.46994656324386597
Validation loss: 2.0025072495142617

Epoch: 6| Step: 3
Training loss: 0.9362425208091736
Validation loss: 2.0421993335088096

Epoch: 6| Step: 4
Training loss: 0.4402446746826172
Validation loss: 2.020299196243286

Epoch: 6| Step: 5
Training loss: 0.31078100204467773
Validation loss: 1.9965681036313374

Epoch: 6| Step: 6
Training loss: 0.3154395818710327
Validation loss: 1.987408181031545

Epoch: 6| Step: 7
Training loss: 0.5516024827957153
Validation loss: 2.026335676511129

Epoch: 6| Step: 8
Training loss: 0.32409316301345825
Validation loss: 2.022532602151235

Epoch: 6| Step: 9
Training loss: 0.382043719291687
Validation loss: 2.022794862588247

Epoch: 6| Step: 10
Training loss: 0.4269450008869171
Validation loss: 1.985308567682902

Epoch: 6| Step: 11
Training loss: 0.37205079197883606
Validation loss: 1.9656245708465576

Epoch: 6| Step: 12
Training loss: 0.3848836421966553
Validation loss: 2.030380884806315

Epoch: 6| Step: 13
Training loss: 0.4529673457145691
Validation loss: 1.9719911615053813

Epoch: 234| Step: 0
Training loss: 0.5898495316505432
Validation loss: 2.0491943955421448

Epoch: 6| Step: 1
Training loss: 0.3227042555809021
Validation loss: 2.016262670358022

Epoch: 6| Step: 2
Training loss: 0.5035516023635864
Validation loss: 1.98508220911026

Epoch: 6| Step: 3
Training loss: 0.3139272928237915
Validation loss: 1.9878559509913127

Epoch: 6| Step: 4
Training loss: 0.48785361647605896
Validation loss: 1.9893221855163574

Epoch: 6| Step: 5
Training loss: 0.5985344648361206
Validation loss: 2.00635435183843

Epoch: 6| Step: 6
Training loss: 0.2541758418083191
Validation loss: 2.0169090032577515

Epoch: 6| Step: 7
Training loss: 0.715402364730835
Validation loss: 1.974459946155548

Epoch: 6| Step: 8
Training loss: 0.9123460054397583
Validation loss: 2.0117563009262085

Epoch: 6| Step: 9
Training loss: 0.43990838527679443
Validation loss: 1.994629482428233

Epoch: 6| Step: 10
Training loss: 0.7388285398483276
Validation loss: 2.0200884143511453

Epoch: 6| Step: 11
Training loss: 0.38403356075286865
Validation loss: 2.0112809936205545

Epoch: 6| Step: 12
Training loss: 0.4717170000076294
Validation loss: 2.0082188049952188

Epoch: 6| Step: 13
Training loss: 0.4114953279495239
Validation loss: 1.9657405416170757

Epoch: 235| Step: 0
Training loss: 0.8097443580627441
Validation loss: 2.0066735545794168

Epoch: 6| Step: 1
Training loss: 0.3769323229789734
Validation loss: 1.9685089985529582

Epoch: 6| Step: 2
Training loss: 0.3395259380340576
Validation loss: 1.992723782857259

Epoch: 6| Step: 3
Training loss: 0.5024994611740112
Validation loss: 2.0286818544069924

Epoch: 6| Step: 4
Training loss: 0.6321141123771667
Validation loss: 2.0407478411992392

Epoch: 6| Step: 5
Training loss: 0.37309569120407104
Validation loss: 2.0357651909192405

Epoch: 6| Step: 6
Training loss: 0.6324298977851868
Validation loss: 2.018605351448059

Epoch: 6| Step: 7
Training loss: 0.6212208271026611
Validation loss: 1.9728187719980876

Epoch: 6| Step: 8
Training loss: 0.6094143390655518
Validation loss: 1.9886864225069683

Epoch: 6| Step: 9
Training loss: 0.746385395526886
Validation loss: 1.9839916030565898

Epoch: 6| Step: 10
Training loss: 0.6252387762069702
Validation loss: 2.018557091554006

Epoch: 6| Step: 11
Training loss: 0.42236262559890747
Validation loss: 2.049052039782206

Epoch: 6| Step: 12
Training loss: 0.40347498655319214
Validation loss: 1.9904181162516277

Epoch: 6| Step: 13
Training loss: 0.8197500705718994
Validation loss: 1.9982749422391255

Epoch: 236| Step: 0
Training loss: 0.3851059377193451
Validation loss: 2.0128734906514487

Epoch: 6| Step: 1
Training loss: 0.5428367853164673
Validation loss: 2.0291161139806113

Epoch: 6| Step: 2
Training loss: 0.2883145213127136
Validation loss: 2.021516581376394

Epoch: 6| Step: 3
Training loss: 0.38960182666778564
Validation loss: 1.9966361125310261

Epoch: 6| Step: 4
Training loss: 0.42392945289611816
Validation loss: 2.012324571609497

Epoch: 6| Step: 5
Training loss: 0.830528736114502
Validation loss: 2.0025455156962075

Epoch: 6| Step: 6
Training loss: 0.42025408148765564
Validation loss: 1.985487937927246

Epoch: 6| Step: 7
Training loss: 0.894974410533905
Validation loss: 2.002529044946035

Epoch: 6| Step: 8
Training loss: 0.463417649269104
Validation loss: 1.9735036094983418

Epoch: 6| Step: 9
Training loss: 0.7820966839790344
Validation loss: 1.9960688352584839

Epoch: 6| Step: 10
Training loss: 0.4759698212146759
Validation loss: 1.994013508160909

Epoch: 6| Step: 11
Training loss: 0.46065324544906616
Validation loss: 2.0178725918134055

Epoch: 6| Step: 12
Training loss: 0.6485623121261597
Validation loss: 2.0213003953297934

Epoch: 6| Step: 13
Training loss: 0.2730024456977844
Validation loss: 2.0545207262039185

Epoch: 237| Step: 0
Training loss: 0.40337008237838745
Validation loss: 1.9865070184071858

Epoch: 6| Step: 1
Training loss: 0.41242605447769165
Validation loss: 1.9780880411465962

Epoch: 6| Step: 2
Training loss: 0.2765108346939087
Validation loss: 2.0029175678888955

Epoch: 6| Step: 3
Training loss: 0.7104980945587158
Validation loss: 2.02587753534317

Epoch: 6| Step: 4
Training loss: 0.46376001834869385
Validation loss: 1.9912929932276409

Epoch: 6| Step: 5
Training loss: 0.24894636869430542
Validation loss: 1.9976307153701782

Epoch: 6| Step: 6
Training loss: 0.7979808449745178
Validation loss: 1.9732571840286255

Epoch: 6| Step: 7
Training loss: 1.1133880615234375
Validation loss: 1.9827370842297871

Epoch: 6| Step: 8
Training loss: 0.18597407639026642
Validation loss: 1.988485852877299

Epoch: 6| Step: 9
Training loss: 1.0336947441101074
Validation loss: 1.9600941737492878

Epoch: 6| Step: 10
Training loss: 0.5527515411376953
Validation loss: 2.0186747511227927

Epoch: 6| Step: 11
Training loss: 0.36111390590667725
Validation loss: 2.0314781268437705

Epoch: 6| Step: 12
Training loss: 0.4169100821018219
Validation loss: 2.0252500772476196

Epoch: 6| Step: 13
Training loss: 0.5354387760162354
Validation loss: 1.960503061612447

Epoch: 238| Step: 0
Training loss: 0.3457135558128357
Validation loss: 2.023729999860128

Epoch: 6| Step: 1
Training loss: 0.561987042427063
Validation loss: 2.042593995730082

Epoch: 6| Step: 2
Training loss: 0.6385155916213989
Validation loss: 2.0098710854848227

Epoch: 6| Step: 3
Training loss: 0.23791038990020752
Validation loss: 1.9866841236750286

Epoch: 6| Step: 4
Training loss: 1.1295251846313477
Validation loss: 1.9953816930452983

Epoch: 6| Step: 5
Training loss: 0.5401507019996643
Validation loss: 1.9919116497039795

Epoch: 6| Step: 6
Training loss: 0.3710330128669739
Validation loss: 1.9905293782552083

Epoch: 6| Step: 7
Training loss: 0.8276845216751099
Validation loss: 2.024074693520864

Epoch: 6| Step: 8
Training loss: 0.5590137839317322
Validation loss: 2.045528511206309

Epoch: 6| Step: 9
Training loss: 0.6137943267822266
Validation loss: 2.015552580356598

Epoch: 6| Step: 10
Training loss: 0.42335957288742065
Validation loss: 2.0660359064737954

Epoch: 6| Step: 11
Training loss: 0.4500340223312378
Validation loss: 1.9944408138593037

Epoch: 6| Step: 12
Training loss: 0.6127278804779053
Validation loss: 1.966991623242696

Epoch: 6| Step: 13
Training loss: 0.47739261388778687
Validation loss: 2.0348225633303323

Epoch: 239| Step: 0
Training loss: 0.627495288848877
Validation loss: 2.031063139438629

Epoch: 6| Step: 1
Training loss: 0.909620463848114
Validation loss: 1.9881949226061504

Epoch: 6| Step: 2
Training loss: 0.9582764506340027
Validation loss: 2.04533588886261

Epoch: 6| Step: 3
Training loss: 0.9548212289810181
Validation loss: 2.0846444765726724

Epoch: 6| Step: 4
Training loss: 0.5068166255950928
Validation loss: 2.0314658880233765

Epoch: 6| Step: 5
Training loss: 0.4740850329399109
Validation loss: 2.0164352456728616

Epoch: 6| Step: 6
Training loss: 0.5032882690429688
Validation loss: 2.054282784461975

Epoch: 6| Step: 7
Training loss: 0.5622566938400269
Validation loss: 2.0069226821263633

Epoch: 6| Step: 8
Training loss: 0.605888843536377
Validation loss: 2.1026076277097068

Epoch: 6| Step: 9
Training loss: 0.3306269645690918
Validation loss: 2.0465288162231445

Epoch: 6| Step: 10
Training loss: 0.5165411233901978
Validation loss: 2.0834370851516724

Epoch: 6| Step: 11
Training loss: 0.8095477819442749
Validation loss: 2.1185552875200906

Epoch: 6| Step: 12
Training loss: 0.372150182723999
Validation loss: 2.0643232067426047

Epoch: 6| Step: 13
Training loss: 0.3758935034275055
Validation loss: 2.029582599798838

Epoch: 240| Step: 0
Training loss: 0.6207591891288757
Validation loss: 2.039762874444326

Epoch: 6| Step: 1
Training loss: 0.332192063331604
Validation loss: 2.056307852268219

Epoch: 6| Step: 2
Training loss: 0.7894812822341919
Validation loss: 2.0397137999534607

Epoch: 6| Step: 3
Training loss: 0.8364789485931396
Validation loss: 2.0456660787264505

Epoch: 6| Step: 4
Training loss: 0.6192563772201538
Validation loss: 2.051250179608663

Epoch: 6| Step: 5
Training loss: 0.7028879523277283
Validation loss: 2.0733330051104226

Epoch: 6| Step: 6
Training loss: 0.48077452182769775
Validation loss: 2.0435447096824646

Epoch: 6| Step: 7
Training loss: 0.341052770614624
Validation loss: 1.9675140778223674

Epoch: 6| Step: 8
Training loss: 0.8644700050354004
Validation loss: 2.043984810511271

Epoch: 6| Step: 9
Training loss: 0.3900342881679535
Validation loss: 1.9929251670837402

Epoch: 6| Step: 10
Training loss: 0.6018967628479004
Validation loss: 2.033023238182068

Epoch: 6| Step: 11
Training loss: 0.5134698748588562
Validation loss: 2.07015726963679

Epoch: 6| Step: 12
Training loss: 0.7152618765830994
Validation loss: 2.0358347296714783

Epoch: 6| Step: 13
Training loss: 0.8785600066184998
Validation loss: 2.017884989579519

Epoch: 241| Step: 0
Training loss: 0.7029590606689453
Validation loss: 2.0246419111887612

Epoch: 6| Step: 1
Training loss: 0.9434024095535278
Validation loss: 2.026640256245931

Epoch: 6| Step: 2
Training loss: 0.32445085048675537
Validation loss: 2.0053141117095947

Epoch: 6| Step: 3
Training loss: 0.4912515878677368
Validation loss: 2.0036369959513345

Epoch: 6| Step: 4
Training loss: 0.6154237985610962
Validation loss: 2.0374452273050943

Epoch: 6| Step: 5
Training loss: 0.6537038087844849
Validation loss: 2.0233208934466043

Epoch: 6| Step: 6
Training loss: 0.5552903413772583
Validation loss: 2.032107949256897

Epoch: 6| Step: 7
Training loss: 0.3850133419036865
Validation loss: 2.0027098258336387

Epoch: 6| Step: 8
Training loss: 0.27504265308380127
Validation loss: 2.006481945514679

Epoch: 6| Step: 9
Training loss: 0.4242519736289978
Validation loss: 2.0387717684110007

Epoch: 6| Step: 10
Training loss: 0.5270240306854248
Validation loss: 2.0057015419006348

Epoch: 6| Step: 11
Training loss: 0.19490143656730652
Validation loss: 1.9630667964617412

Epoch: 6| Step: 12
Training loss: 0.5948233008384705
Validation loss: 2.0361130634943643

Epoch: 6| Step: 13
Training loss: 0.7019495964050293
Validation loss: 2.0135992765426636

Epoch: 242| Step: 0
Training loss: 0.2615017294883728
Validation loss: 2.002808610598246

Epoch: 6| Step: 1
Training loss: 0.40862539410591125
Validation loss: 2.0374803940455117

Epoch: 6| Step: 2
Training loss: 0.44222748279571533
Validation loss: 1.990571141242981

Epoch: 6| Step: 3
Training loss: 0.49250006675720215
Validation loss: 2.0616251826286316

Epoch: 6| Step: 4
Training loss: 0.23388725519180298
Validation loss: 2.0403518080711365

Epoch: 6| Step: 5
Training loss: 0.41907164454460144
Validation loss: 1.997429370880127

Epoch: 6| Step: 6
Training loss: 0.4119246006011963
Validation loss: 2.004962464173635

Epoch: 6| Step: 7
Training loss: 0.3865768313407898
Validation loss: 2.0016097823778787

Epoch: 6| Step: 8
Training loss: 0.43399184942245483
Validation loss: 2.0060581962267556

Epoch: 6| Step: 9
Training loss: 1.037766933441162
Validation loss: 1.9980769554773967

Epoch: 6| Step: 10
Training loss: 0.6186120510101318
Validation loss: 1.9930021166801453

Epoch: 6| Step: 11
Training loss: 0.7725838422775269
Validation loss: 1.999973475933075

Epoch: 6| Step: 12
Training loss: 0.6916998624801636
Validation loss: 2.0569427808125815

Epoch: 6| Step: 13
Training loss: 0.18809746205806732
Validation loss: 2.0070333083470664

Epoch: 243| Step: 0
Training loss: 0.4536074101924896
Validation loss: 1.9923468033472698

Epoch: 6| Step: 1
Training loss: 0.5804466009140015
Validation loss: 2.083931306997935

Epoch: 6| Step: 2
Training loss: 0.4103475511074066
Validation loss: 2.0129043062527976

Epoch: 6| Step: 3
Training loss: 0.5879871249198914
Validation loss: 2.0157828529675803

Epoch: 6| Step: 4
Training loss: 0.4362699091434479
Validation loss: 2.028232216835022

Epoch: 6| Step: 5
Training loss: 0.5490524768829346
Validation loss: 2.0336953997612

Epoch: 6| Step: 6
Training loss: 0.44223979115486145
Validation loss: 2.0427799820899963

Epoch: 6| Step: 7
Training loss: 0.3791797161102295
Validation loss: 2.0706668297449746

Epoch: 6| Step: 8
Training loss: 0.7985205054283142
Validation loss: 1.9927968581517537

Epoch: 6| Step: 9
Training loss: 0.5330923795700073
Validation loss: 1.9544145067532857

Epoch: 6| Step: 10
Training loss: 0.3441445231437683
Validation loss: 2.0567250847816467

Epoch: 6| Step: 11
Training loss: 0.4000150263309479
Validation loss: 1.9909446239471436

Epoch: 6| Step: 12
Training loss: 0.8343148827552795
Validation loss: 2.0187902450561523

Epoch: 6| Step: 13
Training loss: 0.5726568102836609
Validation loss: 1.9906489451726277

Epoch: 244| Step: 0
Training loss: 0.6951706409454346
Validation loss: 2.0292006134986877

Epoch: 6| Step: 1
Training loss: 0.4798518121242523
Validation loss: 2.0239058335622153

Epoch: 6| Step: 2
Training loss: 0.5211740732192993
Validation loss: 1.9970868428548176

Epoch: 6| Step: 3
Training loss: 0.27135908603668213
Validation loss: 2.017808814843496

Epoch: 6| Step: 4
Training loss: 0.751474142074585
Validation loss: 2.0252209305763245

Epoch: 6| Step: 5
Training loss: 0.5433358550071716
Validation loss: 1.9825663765271504

Epoch: 6| Step: 6
Training loss: 0.5063300132751465
Validation loss: 1.994557003180186

Epoch: 6| Step: 7
Training loss: 0.22308266162872314
Validation loss: 2.041494886080424

Epoch: 6| Step: 8
Training loss: 0.5361610651016235
Validation loss: 2.0365803241729736

Epoch: 6| Step: 9
Training loss: 0.40931448340415955
Validation loss: 1.9986119667689006

Epoch: 6| Step: 10
Training loss: 0.40236133337020874
Validation loss: 2.089825749397278

Epoch: 6| Step: 11
Training loss: 0.6271094083786011
Validation loss: 2.0391299525896707

Epoch: 6| Step: 12
Training loss: 0.281943142414093
Validation loss: 2.0327639977137246

Epoch: 6| Step: 13
Training loss: 0.9628493785858154
Validation loss: 1.990926722685496

Epoch: 245| Step: 0
Training loss: 0.8316107988357544
Validation loss: 1.994500199953715

Epoch: 6| Step: 1
Training loss: 0.775536298751831
Validation loss: 2.0358017086982727

Epoch: 6| Step: 2
Training loss: 0.26332396268844604
Validation loss: 2.0315863291422525

Epoch: 6| Step: 3
Training loss: 0.6511761546134949
Validation loss: 2.024287780125936

Epoch: 6| Step: 4
Training loss: 0.4348243474960327
Validation loss: 1.9996894995371501

Epoch: 6| Step: 5
Training loss: 0.23976071178913116
Validation loss: 2.0061609148979187

Epoch: 6| Step: 6
Training loss: 0.33890822529792786
Validation loss: 2.0349855621655784

Epoch: 6| Step: 7
Training loss: 0.2876700758934021
Validation loss: 2.003635664780935

Epoch: 6| Step: 8
Training loss: 0.33217766880989075
Validation loss: 2.0338592529296875

Epoch: 6| Step: 9
Training loss: 0.5964748859405518
Validation loss: 1.9966697494188945

Epoch: 6| Step: 10
Training loss: 0.22052964568138123
Validation loss: 2.0282786091168723

Epoch: 6| Step: 11
Training loss: 0.8283858299255371
Validation loss: 2.0170422792434692

Epoch: 6| Step: 12
Training loss: 0.30571848154067993
Validation loss: 2.0710026621818542

Epoch: 6| Step: 13
Training loss: 0.7407418489456177
Validation loss: 2.0708006819089255

Epoch: 246| Step: 0
Training loss: 0.6560876369476318
Validation loss: 2.0150511860847473

Epoch: 6| Step: 1
Training loss: 0.3827281594276428
Validation loss: 2.0711940924326577

Epoch: 6| Step: 2
Training loss: 0.31467118859291077
Validation loss: 2.019042690594991

Epoch: 6| Step: 3
Training loss: 1.1289589405059814
Validation loss: 1.9893664717674255

Epoch: 6| Step: 4
Training loss: 0.7630823850631714
Validation loss: 1.979845106601715

Epoch: 6| Step: 5
Training loss: 0.32837286591529846
Validation loss: 2.0161672234535217

Epoch: 6| Step: 6
Training loss: 0.44242796301841736
Validation loss: 2.031063973903656

Epoch: 6| Step: 7
Training loss: 0.2502897381782532
Validation loss: 2.0126567482948303

Epoch: 6| Step: 8
Training loss: 0.5019363164901733
Validation loss: 2.0031766494115195

Epoch: 6| Step: 9
Training loss: 0.5774718523025513
Validation loss: 2.037932495276133

Epoch: 6| Step: 10
Training loss: 0.42772597074508667
Validation loss: 2.003218114376068

Epoch: 6| Step: 11
Training loss: 0.3220313787460327
Validation loss: 2.0728667775789895

Epoch: 6| Step: 12
Training loss: 0.5697242021560669
Validation loss: 2.0208876530329385

Epoch: 6| Step: 13
Training loss: 0.5922538638114929
Validation loss: 1.99195396900177

Epoch: 247| Step: 0
Training loss: 0.4215873181819916
Validation loss: 1.9975730776786804

Epoch: 6| Step: 1
Training loss: 0.2163509875535965
Validation loss: 1.9876368641853333

Epoch: 6| Step: 2
Training loss: 0.5383848547935486
Validation loss: 2.026369253794352

Epoch: 6| Step: 3
Training loss: 0.3210124373435974
Validation loss: 2.024820705254873

Epoch: 6| Step: 4
Training loss: 0.3618832230567932
Validation loss: 2.015132784843445

Epoch: 6| Step: 5
Training loss: 0.3085393011569977
Validation loss: 1.9726033012072246

Epoch: 6| Step: 6
Training loss: 0.4984096586704254
Validation loss: 2.050843139489492

Epoch: 6| Step: 7
Training loss: 0.46907323598861694
Validation loss: 1.9767195383707683

Epoch: 6| Step: 8
Training loss: 0.40984395146369934
Validation loss: 1.98310520251592

Epoch: 6| Step: 9
Training loss: 1.2351634502410889
Validation loss: 2.032564719518026

Epoch: 6| Step: 10
Training loss: 0.4011056125164032
Validation loss: 1.9918837745984395

Epoch: 6| Step: 11
Training loss: 0.41986045241355896
Validation loss: 2.028628329435984

Epoch: 6| Step: 12
Training loss: 0.5970835089683533
Validation loss: 1.9725380738576253

Epoch: 6| Step: 13
Training loss: 0.2584399878978729
Validation loss: 2.047430237134298

Epoch: 248| Step: 0
Training loss: 0.4396708309650421
Validation loss: 2.0067741870880127

Epoch: 6| Step: 1
Training loss: 0.34527382254600525
Validation loss: 2.005188008149465

Epoch: 6| Step: 2
Training loss: 0.40959542989730835
Validation loss: 2.0048017104466758

Epoch: 6| Step: 3
Training loss: 0.44886934757232666
Validation loss: 2.0325164198875427

Epoch: 6| Step: 4
Training loss: 0.43845275044441223
Validation loss: 1.9473472634951274

Epoch: 6| Step: 5
Training loss: 0.2590464949607849
Validation loss: 1.9897728562355042

Epoch: 6| Step: 6
Training loss: 0.13419711589813232
Validation loss: 2.0263604521751404

Epoch: 6| Step: 7
Training loss: 0.4468892514705658
Validation loss: 2.040990094343821

Epoch: 6| Step: 8
Training loss: 0.4422209858894348
Validation loss: 2.0390981237093606

Epoch: 6| Step: 9
Training loss: 0.550667941570282
Validation loss: 2.012941896915436

Epoch: 6| Step: 10
Training loss: 0.4944949746131897
Validation loss: 2.0209083358446756

Epoch: 6| Step: 11
Training loss: 0.6908094882965088
Validation loss: 2.0192737181981406

Epoch: 6| Step: 12
Training loss: 0.6064346432685852
Validation loss: 1.9939212203025818

Epoch: 6| Step: 13
Training loss: 0.9393436908721924
Validation loss: 2.029133915901184

Epoch: 249| Step: 0
Training loss: 0.4224516749382019
Validation loss: 2.0191365281740823

Epoch: 6| Step: 1
Training loss: 0.4535500407218933
Validation loss: 2.0304612716039023

Epoch: 6| Step: 2
Training loss: 0.33883607387542725
Validation loss: 1.9922619462013245

Epoch: 6| Step: 3
Training loss: 0.5474098920822144
Validation loss: 2.0161693890889487

Epoch: 6| Step: 4
Training loss: 0.45132046937942505
Validation loss: 1.990180790424347

Epoch: 6| Step: 5
Training loss: 0.20109298825263977
Validation loss: 2.001500209172567

Epoch: 6| Step: 6
Training loss: 0.24800756573677063
Validation loss: 2.0070904890696206

Epoch: 6| Step: 7
Training loss: 1.0947226285934448
Validation loss: 1.982635259628296

Epoch: 6| Step: 8
Training loss: 0.36446723341941833
Validation loss: 1.987679084142049

Epoch: 6| Step: 9
Training loss: 0.23310856521129608
Validation loss: 1.9625284075737

Epoch: 6| Step: 10
Training loss: 0.5459742546081543
Validation loss: 2.0075643261273703

Epoch: 6| Step: 11
Training loss: 0.3056441843509674
Validation loss: 1.9964122772216797

Epoch: 6| Step: 12
Training loss: 0.5108584761619568
Validation loss: 2.0348990758260093

Epoch: 6| Step: 13
Training loss: 0.8194383382797241
Validation loss: 2.0220837394396463

Epoch: 250| Step: 0
Training loss: 0.42021167278289795
Validation loss: 2.0147863229115806

Epoch: 6| Step: 1
Training loss: 0.32871806621551514
Validation loss: 1.975647747516632

Epoch: 6| Step: 2
Training loss: 0.6525818705558777
Validation loss: 1.9946100115776062

Epoch: 6| Step: 3
Training loss: 0.41491538286209106
Validation loss: 1.9924137194951375

Epoch: 6| Step: 4
Training loss: 1.1409261226654053
Validation loss: 1.9747035106023152

Epoch: 6| Step: 5
Training loss: 0.5359441041946411
Validation loss: 2.045383095741272

Epoch: 6| Step: 6
Training loss: 0.30256187915802
Validation loss: 2.0362764795621238

Epoch: 6| Step: 7
Training loss: 0.3687498867511749
Validation loss: 1.9957980513572693

Epoch: 6| Step: 8
Training loss: 0.37260252237319946
Validation loss: 2.012102166811625

Epoch: 6| Step: 9
Training loss: 0.32904523611068726
Validation loss: 2.0495747327804565

Epoch: 6| Step: 10
Training loss: 0.3425825834274292
Validation loss: 2.015716830889384

Epoch: 6| Step: 11
Training loss: 0.39776670932769775
Validation loss: 2.010138432184855

Epoch: 6| Step: 12
Training loss: 0.9847303628921509
Validation loss: 2.027179459730784

Epoch: 6| Step: 13
Training loss: 0.47382912039756775
Validation loss: 1.9898671507835388

Epoch: 251| Step: 0
Training loss: 0.30067703127861023
Validation loss: 2.0215592781702676

Epoch: 6| Step: 1
Training loss: 0.7599306106567383
Validation loss: 2.0303564270337424

Epoch: 6| Step: 2
Training loss: 0.5089391469955444
Validation loss: 2.0068971316019693

Epoch: 6| Step: 3
Training loss: 0.48611778020858765
Validation loss: 2.0465309421221414

Epoch: 6| Step: 4
Training loss: 0.9162358045578003
Validation loss: 1.9942679405212402

Epoch: 6| Step: 5
Training loss: 0.472440630197525
Validation loss: 2.051161011060079

Epoch: 6| Step: 6
Training loss: 0.4669156074523926
Validation loss: 2.0345755219459534

Epoch: 6| Step: 7
Training loss: 0.29556310176849365
Validation loss: 2.025712311267853

Epoch: 6| Step: 8
Training loss: 0.5609642267227173
Validation loss: 2.007797678311666

Epoch: 6| Step: 9
Training loss: 0.8124138712882996
Validation loss: 2.024517754713694

Epoch: 6| Step: 10
Training loss: 0.5035268068313599
Validation loss: 2.0554436246554055

Epoch: 6| Step: 11
Training loss: 0.414876252412796
Validation loss: 2.0541983445485434

Epoch: 6| Step: 12
Training loss: 0.4445298910140991
Validation loss: 1.9968249400456746

Epoch: 6| Step: 13
Training loss: 0.2769235074520111
Validation loss: 2.0284380515416465

Epoch: 252| Step: 0
Training loss: 0.33364349603652954
Validation loss: 2.015990654627482

Epoch: 6| Step: 1
Training loss: 1.0021939277648926
Validation loss: 1.998523235321045

Epoch: 6| Step: 2
Training loss: 0.5603504776954651
Validation loss: 2.039457698663076

Epoch: 6| Step: 3
Training loss: 0.2199753075838089
Validation loss: 2.035127421220144

Epoch: 6| Step: 4
Training loss: 0.6593103408813477
Validation loss: 2.0555335680643716

Epoch: 6| Step: 5
Training loss: 0.46683287620544434
Validation loss: 1.9955159425735474

Epoch: 6| Step: 6
Training loss: 0.5438655614852905
Validation loss: 2.061442255973816

Epoch: 6| Step: 7
Training loss: 0.4169157147407532
Validation loss: 2.0089993476867676

Epoch: 6| Step: 8
Training loss: 0.6493804454803467
Validation loss: 2.0225022037823996

Epoch: 6| Step: 9
Training loss: 0.4491577744483948
Validation loss: 1.9919321338335674

Epoch: 6| Step: 10
Training loss: 0.4069654941558838
Validation loss: 2.0164992610613504

Epoch: 6| Step: 11
Training loss: 0.667251467704773
Validation loss: 2.0192010005315146

Epoch: 6| Step: 12
Training loss: 0.5634000897407532
Validation loss: 2.028991997241974

Epoch: 6| Step: 13
Training loss: 0.4940083622932434
Validation loss: 2.05687548716863

Epoch: 253| Step: 0
Training loss: 0.5887874364852905
Validation loss: 2.0973457296689353

Epoch: 6| Step: 1
Training loss: 0.5639623403549194
Validation loss: 2.0271236101786294

Epoch: 6| Step: 2
Training loss: 0.33287814259529114
Validation loss: 2.065931419531504

Epoch: 6| Step: 3
Training loss: 0.40364399552345276
Validation loss: 2.0167523622512817

Epoch: 6| Step: 4
Training loss: 0.38283571600914
Validation loss: 2.021125912666321

Epoch: 6| Step: 5
Training loss: 0.43964987993240356
Validation loss: 2.0351601243019104

Epoch: 6| Step: 6
Training loss: 0.4756428897380829
Validation loss: 2.018864075342814

Epoch: 6| Step: 7
Training loss: 0.28389549255371094
Validation loss: 2.0873427192370095

Epoch: 6| Step: 8
Training loss: 0.6223429441452026
Validation loss: 1.9726040363311768

Epoch: 6| Step: 9
Training loss: 0.4141477346420288
Validation loss: 1.9924779733022053

Epoch: 6| Step: 10
Training loss: 0.37274086475372314
Validation loss: 1.9976860483487446

Epoch: 6| Step: 11
Training loss: 0.5353096723556519
Validation loss: 1.9642911354700725

Epoch: 6| Step: 12
Training loss: 0.44033879041671753
Validation loss: 2.000407079855601

Epoch: 6| Step: 13
Training loss: 0.9229668974876404
Validation loss: 2.0154531598091125

Epoch: 254| Step: 0
Training loss: 0.47984206676483154
Validation loss: 1.9788626432418823

Epoch: 6| Step: 1
Training loss: 0.2715708017349243
Validation loss: 1.9942301114400227

Epoch: 6| Step: 2
Training loss: 0.3423316180706024
Validation loss: 1.9831804235776265

Epoch: 6| Step: 3
Training loss: 0.30616694688796997
Validation loss: 1.9658977190653484

Epoch: 6| Step: 4
Training loss: 0.41882652044296265
Validation loss: 2.033309837182363

Epoch: 6| Step: 5
Training loss: 1.1168169975280762
Validation loss: 2.0391366283098855

Epoch: 6| Step: 6
Training loss: 0.3700284957885742
Validation loss: 2.0502790808677673

Epoch: 6| Step: 7
Training loss: 0.38747718930244446
Validation loss: 2.0602080623308816

Epoch: 6| Step: 8
Training loss: 0.7398020029067993
Validation loss: 1.9669377009073894

Epoch: 6| Step: 9
Training loss: 0.2460905909538269
Validation loss: 2.0392969846725464

Epoch: 6| Step: 10
Training loss: 0.4885372221469879
Validation loss: 1.9920330444971721

Epoch: 6| Step: 11
Training loss: 0.5315446853637695
Validation loss: 2.019424875577291

Epoch: 6| Step: 12
Training loss: 0.2508127689361572
Validation loss: 2.025725801785787

Epoch: 6| Step: 13
Training loss: 0.6571903228759766
Validation loss: 1.9665583769480388

Epoch: 255| Step: 0
Training loss: 0.6078028082847595
Validation loss: 2.009787301222483

Epoch: 6| Step: 1
Training loss: 0.3650686740875244
Validation loss: 2.0244609117507935

Epoch: 6| Step: 2
Training loss: 0.41694068908691406
Validation loss: 1.9605636994043987

Epoch: 6| Step: 3
Training loss: 0.38577574491500854
Validation loss: 1.9835561315218608

Epoch: 6| Step: 4
Training loss: 0.385608434677124
Validation loss: 2.005256434281667

Epoch: 6| Step: 5
Training loss: 0.26728904247283936
Validation loss: 2.0135974486668906

Epoch: 6| Step: 6
Training loss: 0.2566981911659241
Validation loss: 2.0128236413002014

Epoch: 6| Step: 7
Training loss: 0.7051175236701965
Validation loss: 2.00795449813207

Epoch: 6| Step: 8
Training loss: 0.9326977729797363
Validation loss: 1.9883358081181843

Epoch: 6| Step: 9
Training loss: 0.652070164680481
Validation loss: 1.9608885645866394

Epoch: 6| Step: 10
Training loss: 0.5103662014007568
Validation loss: 2.0405476689338684

Epoch: 6| Step: 11
Training loss: 0.41405028104782104
Validation loss: 1.9766687750816345

Epoch: 6| Step: 12
Training loss: 0.3214452564716339
Validation loss: 2.0228068033854165

Epoch: 6| Step: 13
Training loss: 0.2774900197982788
Validation loss: 2.029374877611796

Epoch: 256| Step: 0
Training loss: 0.5447620153427124
Validation loss: 2.0151411096254983

Epoch: 6| Step: 1
Training loss: 0.3516651391983032
Validation loss: 2.0184524854024253

Epoch: 6| Step: 2
Training loss: 0.4387610852718353
Validation loss: 2.0144402186075845

Epoch: 6| Step: 3
Training loss: 0.4132564663887024
Validation loss: 1.9855016469955444

Epoch: 6| Step: 4
Training loss: 0.5724637508392334
Validation loss: 2.0182806650797525

Epoch: 6| Step: 5
Training loss: 0.5739110112190247
Validation loss: 2.025816877683004

Epoch: 6| Step: 6
Training loss: 0.2941632866859436
Validation loss: 2.0062782764434814

Epoch: 6| Step: 7
Training loss: 0.6418867111206055
Validation loss: 1.9630751212437947

Epoch: 6| Step: 8
Training loss: 0.9710124135017395
Validation loss: 2.033699373404185

Epoch: 6| Step: 9
Training loss: 0.3686433732509613
Validation loss: 1.9882906675338745

Epoch: 6| Step: 10
Training loss: 0.27788636088371277
Validation loss: 2.005728244781494

Epoch: 6| Step: 11
Training loss: 0.47501271963119507
Validation loss: 2.0008583863576255

Epoch: 6| Step: 12
Training loss: 0.4512535035610199
Validation loss: 2.042056898276011

Epoch: 6| Step: 13
Training loss: 0.6434990167617798
Validation loss: 1.9918157656987507

Epoch: 257| Step: 0
Training loss: 0.3338553309440613
Validation loss: 2.0116596023241677

Epoch: 6| Step: 1
Training loss: 0.5731837749481201
Validation loss: 2.0283705790837607

Epoch: 6| Step: 2
Training loss: 0.17242002487182617
Validation loss: 2.036501963933309

Epoch: 6| Step: 3
Training loss: 0.3920450508594513
Validation loss: 2.0188458363215127

Epoch: 6| Step: 4
Training loss: 0.2986987233161926
Validation loss: 1.9658232132593791

Epoch: 6| Step: 5
Training loss: 0.30438339710235596
Validation loss: 2.0126659075419107

Epoch: 6| Step: 6
Training loss: 0.3595777451992035
Validation loss: 2.0046870907147727

Epoch: 6| Step: 7
Training loss: 0.645322322845459
Validation loss: 2.0144827365875244

Epoch: 6| Step: 8
Training loss: 0.3424198031425476
Validation loss: 1.9701006213823955

Epoch: 6| Step: 9
Training loss: 0.9237896203994751
Validation loss: 2.0452038049697876

Epoch: 6| Step: 10
Training loss: 0.5022808909416199
Validation loss: 2.018557071685791

Epoch: 6| Step: 11
Training loss: 0.3443892002105713
Validation loss: 1.983518163363139

Epoch: 6| Step: 12
Training loss: 0.5017048120498657
Validation loss: 2.0325843493143716

Epoch: 6| Step: 13
Training loss: 0.6639981865882874
Validation loss: 2.0079924861590066

Epoch: 258| Step: 0
Training loss: 0.4886113405227661
Validation loss: 1.9916948080062866

Epoch: 6| Step: 1
Training loss: 0.22783386707305908
Validation loss: 2.0262907346089682

Epoch: 6| Step: 2
Training loss: 0.3957585096359253
Validation loss: 1.9958364566167195

Epoch: 6| Step: 3
Training loss: 0.3654218316078186
Validation loss: 2.0583829085032144

Epoch: 6| Step: 4
Training loss: 0.5216513872146606
Validation loss: 2.031630595525106

Epoch: 6| Step: 5
Training loss: 0.7537819743156433
Validation loss: 2.0198378761609397

Epoch: 6| Step: 6
Training loss: 0.4577561616897583
Validation loss: 1.9955237905184429

Epoch: 6| Step: 7
Training loss: 0.36173179745674133
Validation loss: 2.011519451936086

Epoch: 6| Step: 8
Training loss: 0.4330141544342041
Validation loss: 1.979504942893982

Epoch: 6| Step: 9
Training loss: 0.5603971481323242
Validation loss: 2.026902178923289

Epoch: 6| Step: 10
Training loss: 0.8444840908050537
Validation loss: 2.0394494930903115

Epoch: 6| Step: 11
Training loss: 0.34755846858024597
Validation loss: 2.0203131437301636

Epoch: 6| Step: 12
Training loss: 0.43272078037261963
Validation loss: 2.0005856355031333

Epoch: 6| Step: 13
Training loss: 0.41021597385406494
Validation loss: 1.989169180393219

Epoch: 259| Step: 0
Training loss: 0.4767785668373108
Validation loss: 2.026117424170176

Epoch: 6| Step: 1
Training loss: 0.33727169036865234
Validation loss: 2.0068319439888

Epoch: 6| Step: 2
Training loss: 0.3064737319946289
Validation loss: 1.9741774996121724

Epoch: 6| Step: 3
Training loss: 0.44018688797950745
Validation loss: 2.0022900700569153

Epoch: 6| Step: 4
Training loss: 1.0194252729415894
Validation loss: 1.9978944460550945

Epoch: 6| Step: 5
Training loss: 0.368353009223938
Validation loss: 2.024000644683838

Epoch: 6| Step: 6
Training loss: 0.6115847229957581
Validation loss: 2.024756689866384

Epoch: 6| Step: 7
Training loss: 0.3671821355819702
Validation loss: 1.9982190330823262

Epoch: 6| Step: 8
Training loss: 0.37642568349838257
Validation loss: 2.042734464009603

Epoch: 6| Step: 9
Training loss: 0.47473210096359253
Validation loss: 1.9878450632095337

Epoch: 6| Step: 10
Training loss: 0.6095425486564636
Validation loss: 2.0981860558191934

Epoch: 6| Step: 11
Training loss: 0.2883613705635071
Validation loss: 2.0141323804855347

Epoch: 6| Step: 12
Training loss: 0.4932752847671509
Validation loss: 2.006723463535309

Epoch: 6| Step: 13
Training loss: 0.567268967628479
Validation loss: 1.991633653640747

Epoch: 260| Step: 0
Training loss: 0.5251529216766357
Validation loss: 1.9844075640042622

Epoch: 6| Step: 1
Training loss: 0.4621467590332031
Validation loss: 2.048251529534658

Epoch: 6| Step: 2
Training loss: 0.34004032611846924
Validation loss: 2.0523215532302856

Epoch: 6| Step: 3
Training loss: 0.26317137479782104
Validation loss: 1.985959768295288

Epoch: 6| Step: 4
Training loss: 0.43820512294769287
Validation loss: 2.0092636545499167

Epoch: 6| Step: 5
Training loss: 0.27545490860939026
Validation loss: 1.968606948852539

Epoch: 6| Step: 6
Training loss: 0.432582825422287
Validation loss: 1.990788181622823

Epoch: 6| Step: 7
Training loss: 0.696711540222168
Validation loss: 2.014368017514547

Epoch: 6| Step: 8
Training loss: 0.23611876368522644
Validation loss: 1.986979603767395

Epoch: 6| Step: 9
Training loss: 0.45392146706581116
Validation loss: 2.0099295179049173

Epoch: 6| Step: 10
Training loss: 0.6792566776275635
Validation loss: 2.0160540541013083

Epoch: 6| Step: 11
Training loss: 0.5502392649650574
Validation loss: 1.9713136156400044

Epoch: 6| Step: 12
Training loss: 0.4214591383934021
Validation loss: 1.9960697293281555

Epoch: 6| Step: 13
Training loss: 0.7415021657943726
Validation loss: 1.9968386093775432

Epoch: 261| Step: 0
Training loss: 0.8894702196121216
Validation loss: 1.9943981568018596

Epoch: 6| Step: 1
Training loss: 0.5183851718902588
Validation loss: 2.011464854081472

Epoch: 6| Step: 2
Training loss: 0.31416282057762146
Validation loss: 2.010144750277201

Epoch: 6| Step: 3
Training loss: 0.1878332644701004
Validation loss: 2.0130579471588135

Epoch: 6| Step: 4
Training loss: 0.49057793617248535
Validation loss: 2.0207939942677817

Epoch: 6| Step: 5
Training loss: 0.4103121757507324
Validation loss: 1.9637336730957031

Epoch: 6| Step: 6
Training loss: 0.4469095468521118
Validation loss: 2.020195206006368

Epoch: 6| Step: 7
Training loss: 0.804911732673645
Validation loss: 2.0081612269083657

Epoch: 6| Step: 8
Training loss: 0.5725672841072083
Validation loss: 2.0397263367970786

Epoch: 6| Step: 9
Training loss: 0.853509783744812
Validation loss: 2.0087436636288962

Epoch: 6| Step: 10
Training loss: 0.2381829470396042
Validation loss: 2.013557414213816

Epoch: 6| Step: 11
Training loss: 0.2876685559749603
Validation loss: 2.055889348189036

Epoch: 6| Step: 12
Training loss: 0.17431436479091644
Validation loss: 1.984381894270579

Epoch: 6| Step: 13
Training loss: 0.25924408435821533
Validation loss: 1.995689292748769

Epoch: 262| Step: 0
Training loss: 0.5577630400657654
Validation loss: 2.0322535832722983

Epoch: 6| Step: 1
Training loss: 0.33050960302352905
Validation loss: 2.023075262705485

Epoch: 6| Step: 2
Training loss: 0.4632539749145508
Validation loss: 1.984179933865865

Epoch: 6| Step: 3
Training loss: 0.33360743522644043
Validation loss: 2.0485007762908936

Epoch: 6| Step: 4
Training loss: 0.5299824476242065
Validation loss: 1.9733779430389404

Epoch: 6| Step: 5
Training loss: 0.3212910592556
Validation loss: 1.9879947702089946

Epoch: 6| Step: 6
Training loss: 0.2872046232223511
Validation loss: 2.0320807695388794

Epoch: 6| Step: 7
Training loss: 0.4004055857658386
Validation loss: 1.973539113998413

Epoch: 6| Step: 8
Training loss: 0.618376612663269
Validation loss: 2.0229679544766745

Epoch: 6| Step: 9
Training loss: 0.5725380182266235
Validation loss: 2.015772819519043

Epoch: 6| Step: 10
Training loss: 0.7186675071716309
Validation loss: 1.9947343269983928

Epoch: 6| Step: 11
Training loss: 0.3803728222846985
Validation loss: 2.0255850354830423

Epoch: 6| Step: 12
Training loss: 0.41097766160964966
Validation loss: 2.0230537056922913

Epoch: 6| Step: 13
Training loss: 0.7121217250823975
Validation loss: 1.9859993855158489

Epoch: 263| Step: 0
Training loss: 0.43743985891342163
Validation loss: 1.961595853169759

Epoch: 6| Step: 1
Training loss: 0.7667597532272339
Validation loss: 2.043351670106252

Epoch: 6| Step: 2
Training loss: 0.6875353455543518
Validation loss: 2.0051262180010476

Epoch: 6| Step: 3
Training loss: 0.682421088218689
Validation loss: 1.9951091806093852

Epoch: 6| Step: 4
Training loss: 0.49076035618782043
Validation loss: 2.048819442590078

Epoch: 6| Step: 5
Training loss: 0.5956531763076782
Validation loss: 2.0019216934839883

Epoch: 6| Step: 6
Training loss: 0.3831707835197449
Validation loss: 2.0545767148335776

Epoch: 6| Step: 7
Training loss: 0.45040470361709595
Validation loss: 1.990727722644806

Epoch: 6| Step: 8
Training loss: 0.7157863974571228
Validation loss: 2.0077773332595825

Epoch: 6| Step: 9
Training loss: 0.40143728256225586
Validation loss: 2.026428461074829

Epoch: 6| Step: 10
Training loss: 0.26642829179763794
Validation loss: 2.0691229899724326

Epoch: 6| Step: 11
Training loss: 0.40896785259246826
Validation loss: 1.9974306623140972

Epoch: 6| Step: 12
Training loss: 0.30055564641952515
Validation loss: 2.005704343318939

Epoch: 6| Step: 13
Training loss: 0.5049030780792236
Validation loss: 2.0326868891716003

Epoch: 264| Step: 0
Training loss: 0.26592230796813965
Validation loss: 2.047907809416453

Epoch: 6| Step: 1
Training loss: 0.40149426460266113
Validation loss: 2.0021071632703147

Epoch: 6| Step: 2
Training loss: 0.8258036375045776
Validation loss: 1.990401069323222

Epoch: 6| Step: 3
Training loss: 0.6050338745117188
Validation loss: 2.0389665365219116

Epoch: 6| Step: 4
Training loss: 0.5066952109336853
Validation loss: 2.033351023991903

Epoch: 6| Step: 5
Training loss: 0.31303268671035767
Validation loss: 1.998640815416972

Epoch: 6| Step: 6
Training loss: 0.42443975806236267
Validation loss: 2.042730450630188

Epoch: 6| Step: 7
Training loss: 0.618520975112915
Validation loss: 2.0088887810707092

Epoch: 6| Step: 8
Training loss: 0.6171146631240845
Validation loss: 1.9909917712211609

Epoch: 6| Step: 9
Training loss: 0.5675251483917236
Validation loss: 2.0329606533050537

Epoch: 6| Step: 10
Training loss: 0.3135888874530792
Validation loss: 2.0337939858436584

Epoch: 6| Step: 11
Training loss: 0.4543249011039734
Validation loss: 2.0395334164301553

Epoch: 6| Step: 12
Training loss: 0.46824347972869873
Validation loss: 2.0391384164492288

Epoch: 6| Step: 13
Training loss: 0.48162171244621277
Validation loss: 2.0134053230285645

Epoch: 265| Step: 0
Training loss: 0.4391863942146301
Validation loss: 2.038484513759613

Epoch: 6| Step: 1
Training loss: 0.19439385831356049
Validation loss: 1.9986811478932698

Epoch: 6| Step: 2
Training loss: 0.3238253891468048
Validation loss: 1.9938780665397644

Epoch: 6| Step: 3
Training loss: 0.40680593252182007
Validation loss: 2.0548042257626853

Epoch: 6| Step: 4
Training loss: 0.4855871796607971
Validation loss: 1.993736724058787

Epoch: 6| Step: 5
Training loss: 0.2479960024356842
Validation loss: 2.0526010394096375

Epoch: 6| Step: 6
Training loss: 0.27432385087013245
Validation loss: 2.0217451453208923

Epoch: 6| Step: 7
Training loss: 0.38772904872894287
Validation loss: 2.018325845400492

Epoch: 6| Step: 8
Training loss: 0.4040350317955017
Validation loss: 2.0484682520230613

Epoch: 6| Step: 9
Training loss: 0.6603407859802246
Validation loss: 1.9874529639879863

Epoch: 6| Step: 10
Training loss: 0.8105584383010864
Validation loss: 2.030240774154663

Epoch: 6| Step: 11
Training loss: 0.6641706824302673
Validation loss: 2.020959655443827

Epoch: 6| Step: 12
Training loss: 0.23479688167572021
Validation loss: 2.033429503440857

Epoch: 6| Step: 13
Training loss: 0.817421555519104
Validation loss: 2.0281087358792624

Epoch: 266| Step: 0
Training loss: 0.39271795749664307
Validation loss: 2.021273930867513

Epoch: 6| Step: 1
Training loss: 0.34311801195144653
Validation loss: 2.045663058757782

Epoch: 6| Step: 2
Training loss: 0.6235766410827637
Validation loss: 1.9852303465207417

Epoch: 6| Step: 3
Training loss: 0.8570200800895691
Validation loss: 2.027362128098806

Epoch: 6| Step: 4
Training loss: 0.3589116930961609
Validation loss: 2.0454454819361367

Epoch: 6| Step: 5
Training loss: 0.3000046908855438
Validation loss: 2.0246655146280923

Epoch: 6| Step: 6
Training loss: 0.43411195278167725
Validation loss: 1.9947246114412944

Epoch: 6| Step: 7
Training loss: 0.43025389313697815
Validation loss: 2.0455913146336875

Epoch: 6| Step: 8
Training loss: 0.9225943088531494
Validation loss: 2.010348995526632

Epoch: 6| Step: 9
Training loss: 0.4402792453765869
Validation loss: 2.020291268825531

Epoch: 6| Step: 10
Training loss: 0.6240116953849792
Validation loss: 2.0261997183163962

Epoch: 6| Step: 11
Training loss: 0.4074785113334656
Validation loss: 2.044893185297648

Epoch: 6| Step: 12
Training loss: 0.37073203921318054
Validation loss: 1.9680996735890706

Epoch: 6| Step: 13
Training loss: 0.34288185834884644
Validation loss: 2.031019945939382

Epoch: 267| Step: 0
Training loss: 0.6536468863487244
Validation loss: 2.0273783604303994

Epoch: 6| Step: 1
Training loss: 0.30935898423194885
Validation loss: 1.9977786143620808

Epoch: 6| Step: 2
Training loss: 0.3744320869445801
Validation loss: 1.9917889634768169

Epoch: 6| Step: 3
Training loss: 0.36198270320892334
Validation loss: 1.9809385935465496

Epoch: 6| Step: 4
Training loss: 0.430651992559433
Validation loss: 2.0061585307121277

Epoch: 6| Step: 5
Training loss: 0.254855215549469
Validation loss: 2.0223852594693503

Epoch: 6| Step: 6
Training loss: 0.3927227258682251
Validation loss: 2.0256534417470298

Epoch: 6| Step: 7
Training loss: 0.6248105764389038
Validation loss: 2.006782134373983

Epoch: 6| Step: 8
Training loss: 0.5359486937522888
Validation loss: 2.0093754529953003

Epoch: 6| Step: 9
Training loss: 0.8987884521484375
Validation loss: 2.0803916255633035

Epoch: 6| Step: 10
Training loss: 0.2578694224357605
Validation loss: 2.028066178162893

Epoch: 6| Step: 11
Training loss: 0.27754104137420654
Validation loss: 1.9959084788958232

Epoch: 6| Step: 12
Training loss: 0.356625497341156
Validation loss: 1.9794819156328838

Epoch: 6| Step: 13
Training loss: 0.5743887424468994
Validation loss: 2.0302669405937195

Epoch: 268| Step: 0
Training loss: 0.7353670597076416
Validation loss: 2.000336766242981

Epoch: 6| Step: 1
Training loss: 0.7997025847434998
Validation loss: 2.026114543279012

Epoch: 6| Step: 2
Training loss: 0.5299452543258667
Validation loss: 2.0634804169336953

Epoch: 6| Step: 3
Training loss: 0.2679942846298218
Validation loss: 1.9959329962730408

Epoch: 6| Step: 4
Training loss: 0.39288926124572754
Validation loss: 2.038263519605001

Epoch: 6| Step: 5
Training loss: 0.28616219758987427
Validation loss: 1.9977899591128032

Epoch: 6| Step: 6
Training loss: 0.6830183267593384
Validation loss: 2.0039602518081665

Epoch: 6| Step: 7
Training loss: 0.45828330516815186
Validation loss: 1.9798344175020854

Epoch: 6| Step: 8
Training loss: 0.45515045523643494
Validation loss: 1.9932547410329182

Epoch: 6| Step: 9
Training loss: 0.3687664866447449
Validation loss: 1.9678372740745544

Epoch: 6| Step: 10
Training loss: 0.47228506207466125
Validation loss: 2.028560479482015

Epoch: 6| Step: 11
Training loss: 0.29206374287605286
Validation loss: 2.0245997508366904

Epoch: 6| Step: 12
Training loss: 0.29326310753822327
Validation loss: 2.011095345020294

Epoch: 6| Step: 13
Training loss: 0.19163647294044495
Validation loss: 2.014859914779663

Epoch: 269| Step: 0
Training loss: 0.36755383014678955
Validation loss: 1.9915698568026226

Epoch: 6| Step: 1
Training loss: 0.1999710202217102
Validation loss: 1.9917176961898804

Epoch: 6| Step: 2
Training loss: 0.44573068618774414
Validation loss: 2.0277084906895957

Epoch: 6| Step: 3
Training loss: 0.41997432708740234
Validation loss: 2.001614212989807

Epoch: 6| Step: 4
Training loss: 0.4024517238140106
Validation loss: 1.9925363858540852

Epoch: 6| Step: 5
Training loss: 0.296713650226593
Validation loss: 2.0187370975812278

Epoch: 6| Step: 6
Training loss: 0.5800317525863647
Validation loss: 2.0153209964434304

Epoch: 6| Step: 7
Training loss: 0.7575024962425232
Validation loss: 2.0378469228744507

Epoch: 6| Step: 8
Training loss: 0.43244612216949463
Validation loss: 1.998148222764333

Epoch: 6| Step: 9
Training loss: 0.5798498392105103
Validation loss: 2.0291723012924194

Epoch: 6| Step: 10
Training loss: 0.3871661126613617
Validation loss: 2.0316662987073264

Epoch: 6| Step: 11
Training loss: 0.718870997428894
Validation loss: 1.9817564090092976

Epoch: 6| Step: 12
Training loss: 0.26017409563064575
Validation loss: 1.997358759244283

Epoch: 6| Step: 13
Training loss: 0.3204859495162964
Validation loss: 2.0258204340934753

Epoch: 270| Step: 0
Training loss: 0.517781138420105
Validation loss: 2.0219720005989075

Epoch: 6| Step: 1
Training loss: 0.4509306252002716
Validation loss: 2.0601608554522195

Epoch: 6| Step: 2
Training loss: 0.1905118227005005
Validation loss: 2.0331542094548545

Epoch: 6| Step: 3
Training loss: 0.24494360387325287
Validation loss: 2.005807022253672

Epoch: 6| Step: 4
Training loss: 0.5214488506317139
Validation loss: 2.026479264100393

Epoch: 6| Step: 5
Training loss: 0.39630627632141113
Validation loss: 2.0365580320358276

Epoch: 6| Step: 6
Training loss: 0.29101499915122986
Validation loss: 2.043877104918162

Epoch: 6| Step: 7
Training loss: 0.3784772753715515
Validation loss: 2.0399361848831177

Epoch: 6| Step: 8
Training loss: 0.6466562151908875
Validation loss: 2.001554091771444

Epoch: 6| Step: 9
Training loss: 0.9017369151115417
Validation loss: 2.028372863928477

Epoch: 6| Step: 10
Training loss: 0.3764164447784424
Validation loss: 2.0520056088765464

Epoch: 6| Step: 11
Training loss: 0.5448079109191895
Validation loss: 2.0142955382665

Epoch: 6| Step: 12
Training loss: 0.33791008591651917
Validation loss: 2.0440093080202737

Epoch: 6| Step: 13
Training loss: 0.2793295383453369
Validation loss: 1.9983513951301575

Epoch: 271| Step: 0
Training loss: 0.4441918134689331
Validation loss: 2.0330488681793213

Epoch: 6| Step: 1
Training loss: 0.2702968716621399
Validation loss: 2.003392299016317

Epoch: 6| Step: 2
Training loss: 0.19487649202346802
Validation loss: 2.0435450077056885

Epoch: 6| Step: 3
Training loss: 0.19070696830749512
Validation loss: 1.9954274694124858

Epoch: 6| Step: 4
Training loss: 0.4600664973258972
Validation loss: 2.02923591931661

Epoch: 6| Step: 5
Training loss: 0.5091311931610107
Validation loss: 2.0076747139294944

Epoch: 6| Step: 6
Training loss: 0.4797864854335785
Validation loss: 2.013811449209849

Epoch: 6| Step: 7
Training loss: 0.5617872476577759
Validation loss: 1.9925981163978577

Epoch: 6| Step: 8
Training loss: 0.6295506954193115
Validation loss: 2.052743216355642

Epoch: 6| Step: 9
Training loss: 0.49300989508628845
Validation loss: 2.0240877668062844

Epoch: 6| Step: 10
Training loss: 0.7537463903427124
Validation loss: 2.013942082722982

Epoch: 6| Step: 11
Training loss: 0.32665371894836426
Validation loss: 2.022467573483785

Epoch: 6| Step: 12
Training loss: 0.7499473094940186
Validation loss: 2.0134390195210776

Epoch: 6| Step: 13
Training loss: 0.3479691743850708
Validation loss: 2.0167986949284873

Epoch: 272| Step: 0
Training loss: 0.34265103936195374
Validation loss: 2.048500140508016

Epoch: 6| Step: 1
Training loss: 0.2487257719039917
Validation loss: 2.0484286149342856

Epoch: 6| Step: 2
Training loss: 0.5862476229667664
Validation loss: 1.9821845889091492

Epoch: 6| Step: 3
Training loss: 0.7357174158096313
Validation loss: 2.0322563846906028

Epoch: 6| Step: 4
Training loss: 0.17133215069770813
Validation loss: 2.0130951205889382

Epoch: 6| Step: 5
Training loss: 0.4426969885826111
Validation loss: 2.0356074968973794

Epoch: 6| Step: 6
Training loss: 0.34245359897613525
Validation loss: 1.9875638882319133

Epoch: 6| Step: 7
Training loss: 0.3899611234664917
Validation loss: 1.991694688796997

Epoch: 6| Step: 8
Training loss: 0.4475528597831726
Validation loss: 2.033139626185099

Epoch: 6| Step: 9
Training loss: 0.6012153625488281
Validation loss: 2.0002644658088684

Epoch: 6| Step: 10
Training loss: 0.2771921157836914
Validation loss: 2.076104780038198

Epoch: 6| Step: 11
Training loss: 0.27696895599365234
Validation loss: 2.0057679414749146

Epoch: 6| Step: 12
Training loss: 0.6074548959732056
Validation loss: 2.0036778450012207

Epoch: 6| Step: 13
Training loss: 0.8686285018920898
Validation loss: 2.0250036319096885

Epoch: 273| Step: 0
Training loss: 0.25541985034942627
Validation loss: 2.037026266256968

Epoch: 6| Step: 1
Training loss: 0.46317800879478455
Validation loss: 2.027909517288208

Epoch: 6| Step: 2
Training loss: 0.2863020896911621
Validation loss: 1.9992573857307434

Epoch: 6| Step: 3
Training loss: 0.2861396074295044
Validation loss: 1.993997852007548

Epoch: 6| Step: 4
Training loss: 0.3877115249633789
Validation loss: 2.0013919472694397

Epoch: 6| Step: 5
Training loss: 0.6684684157371521
Validation loss: 1.9811631441116333

Epoch: 6| Step: 6
Training loss: 0.4176100790500641
Validation loss: 2.047502358754476

Epoch: 6| Step: 7
Training loss: 0.34917008876800537
Validation loss: 2.0397161841392517

Epoch: 6| Step: 8
Training loss: 0.4768950343132019
Validation loss: 1.9904574553171794

Epoch: 6| Step: 9
Training loss: 0.43213123083114624
Validation loss: 2.013040820757548

Epoch: 6| Step: 10
Training loss: 0.5088136196136475
Validation loss: 2.0076958338419595

Epoch: 6| Step: 11
Training loss: 0.8007528781890869
Validation loss: 2.001347621281942

Epoch: 6| Step: 12
Training loss: 0.5323102474212646
Validation loss: 2.0180105368296304

Epoch: 6| Step: 13
Training loss: 0.3825607895851135
Validation loss: 1.998980442682902

Epoch: 274| Step: 0
Training loss: 0.3975837230682373
Validation loss: 2.0325094858805337

Epoch: 6| Step: 1
Training loss: 0.40023618936538696
Validation loss: 2.026116152604421

Epoch: 6| Step: 2
Training loss: 0.4266761839389801
Validation loss: 1.9791125853856404

Epoch: 6| Step: 3
Training loss: 0.6222553849220276
Validation loss: 2.004062513510386

Epoch: 6| Step: 4
Training loss: 0.5882823467254639
Validation loss: 2.0724575519561768

Epoch: 6| Step: 5
Training loss: 0.5292154550552368
Validation loss: 1.9756320118904114

Epoch: 6| Step: 6
Training loss: 0.6781476736068726
Validation loss: 1.99203626314799

Epoch: 6| Step: 7
Training loss: 0.4580092430114746
Validation loss: 2.005920946598053

Epoch: 6| Step: 8
Training loss: 0.2776787281036377
Validation loss: 1.9874090949694316

Epoch: 6| Step: 9
Training loss: 0.39830923080444336
Validation loss: 2.0118877291679382

Epoch: 6| Step: 10
Training loss: 0.9098376035690308
Validation loss: 2.0106178522109985

Epoch: 6| Step: 11
Training loss: 0.26987603306770325
Validation loss: 2.049046436945597

Epoch: 6| Step: 12
Training loss: 0.5006166100502014
Validation loss: 2.0345656673113504

Epoch: 6| Step: 13
Training loss: 0.5625152587890625
Validation loss: 2.0387393037478128

Epoch: 275| Step: 0
Training loss: 0.4769463539123535
Validation loss: 2.0297398765881858

Epoch: 6| Step: 1
Training loss: 0.341407835483551
Validation loss: 2.0048921704292297

Epoch: 6| Step: 2
Training loss: 0.668553352355957
Validation loss: 1.9883538087209065

Epoch: 6| Step: 3
Training loss: 0.7757976055145264
Validation loss: 2.034042557080587

Epoch: 6| Step: 4
Training loss: 0.8949719667434692
Validation loss: 2.0347312490145364

Epoch: 6| Step: 5
Training loss: 0.3339971899986267
Validation loss: 2.026031017303467

Epoch: 6| Step: 6
Training loss: 0.31401729583740234
Validation loss: 2.0061438282330832

Epoch: 6| Step: 7
Training loss: 0.4260316491127014
Validation loss: 2.0243048071861267

Epoch: 6| Step: 8
Training loss: 0.3572038412094116
Validation loss: 2.0039746165275574

Epoch: 6| Step: 9
Training loss: 0.5114150047302246
Validation loss: 2.0355103413263955

Epoch: 6| Step: 10
Training loss: 0.6466869115829468
Validation loss: 1.9906024932861328

Epoch: 6| Step: 11
Training loss: 0.45160457491874695
Validation loss: 2.003169814745585

Epoch: 6| Step: 12
Training loss: 0.151303231716156
Validation loss: 1.9930378595987956

Epoch: 6| Step: 13
Training loss: 0.31927287578582764
Validation loss: 1.9894912441571553

Epoch: 276| Step: 0
Training loss: 0.3694504499435425
Validation loss: 1.9824324647585552

Epoch: 6| Step: 1
Training loss: 0.3828777074813843
Validation loss: 2.0424216985702515

Epoch: 6| Step: 2
Training loss: 0.3073349595069885
Validation loss: 1.9804636240005493

Epoch: 6| Step: 3
Training loss: 0.3278583288192749
Validation loss: 2.0153695742289224

Epoch: 6| Step: 4
Training loss: 0.3285454511642456
Validation loss: 2.0488091905911765

Epoch: 6| Step: 5
Training loss: 0.4049212336540222
Validation loss: 1.9903932015101116

Epoch: 6| Step: 6
Training loss: 0.2958142161369324
Validation loss: 2.0312691728274026

Epoch: 6| Step: 7
Training loss: 0.5459351539611816
Validation loss: 2.03182045618693

Epoch: 6| Step: 8
Training loss: 0.9486197233200073
Validation loss: 2.031863550345103

Epoch: 6| Step: 9
Training loss: 0.2252446860074997
Validation loss: 2.0016225377718606

Epoch: 6| Step: 10
Training loss: 0.30340132117271423
Validation loss: 2.0613617300987244

Epoch: 6| Step: 11
Training loss: 0.6694774627685547
Validation loss: 2.0250654220581055

Epoch: 6| Step: 12
Training loss: 0.5391096472740173
Validation loss: 2.0270003279050193

Epoch: 6| Step: 13
Training loss: 0.5975533723831177
Validation loss: 2.007543464501699

Epoch: 277| Step: 0
Training loss: 0.47442927956581116
Validation loss: 2.067876656850179

Epoch: 6| Step: 1
Training loss: 0.7186606526374817
Validation loss: 2.028097629547119

Epoch: 6| Step: 2
Training loss: 0.45512938499450684
Validation loss: 2.028654913107554

Epoch: 6| Step: 3
Training loss: 0.6619988083839417
Validation loss: 2.06326824426651

Epoch: 6| Step: 4
Training loss: 0.36989274621009827
Validation loss: 1.9859915574391682

Epoch: 6| Step: 5
Training loss: 0.3587382137775421
Validation loss: 1.9878018101056416

Epoch: 6| Step: 6
Training loss: 0.2950679361820221
Validation loss: 2.0048936208089194

Epoch: 6| Step: 7
Training loss: 0.31979191303253174
Validation loss: 2.0013864437739053

Epoch: 6| Step: 8
Training loss: 0.4760936200618744
Validation loss: 2.0243701736132302

Epoch: 6| Step: 9
Training loss: 0.71283358335495
Validation loss: 1.977862278620402

Epoch: 6| Step: 10
Training loss: 0.3550645112991333
Validation loss: 1.968333085378011

Epoch: 6| Step: 11
Training loss: 0.33170223236083984
Validation loss: 1.9935086170832317

Epoch: 6| Step: 12
Training loss: 0.3620625138282776
Validation loss: 2.0282435019810996

Epoch: 6| Step: 13
Training loss: 0.23881098628044128
Validation loss: 1.9996906518936157

Epoch: 278| Step: 0
Training loss: 0.6338268518447876
Validation loss: 1.9884904424349468

Epoch: 6| Step: 1
Training loss: 0.3573998212814331
Validation loss: 2.019711216290792

Epoch: 6| Step: 2
Training loss: 0.46499666571617126
Validation loss: 2.022903402646383

Epoch: 6| Step: 3
Training loss: 1.0498137474060059
Validation loss: 1.9815225799878438

Epoch: 6| Step: 4
Training loss: 0.33968520164489746
Validation loss: 2.004962762196859

Epoch: 6| Step: 5
Training loss: 0.31215760111808777
Validation loss: 1.9898371299107869

Epoch: 6| Step: 6
Training loss: 0.3335852026939392
Validation loss: 1.9767383734385173

Epoch: 6| Step: 7
Training loss: 0.4925372004508972
Validation loss: 2.0343480507532754

Epoch: 6| Step: 8
Training loss: 0.20421183109283447
Validation loss: 2.0369472106297812

Epoch: 6| Step: 9
Training loss: 0.5474532842636108
Validation loss: 1.996336321036021

Epoch: 6| Step: 10
Training loss: 0.29712975025177
Validation loss: 2.041783173878988

Epoch: 6| Step: 11
Training loss: 0.29851385951042175
Validation loss: 2.015574296315511

Epoch: 6| Step: 12
Training loss: 0.33881083130836487
Validation loss: 2.049842635790507

Epoch: 6| Step: 13
Training loss: 0.30181464552879333
Validation loss: 1.9850449959437053

Epoch: 279| Step: 0
Training loss: 0.30495572090148926
Validation loss: 2.0239659945170083

Epoch: 6| Step: 1
Training loss: 0.3928418457508087
Validation loss: 1.9879924257596333

Epoch: 6| Step: 2
Training loss: 0.29191499948501587
Validation loss: 1.970979909102122

Epoch: 6| Step: 3
Training loss: 0.3060716986656189
Validation loss: 2.029187877972921

Epoch: 6| Step: 4
Training loss: 0.5961511731147766
Validation loss: 1.9972954789797466

Epoch: 6| Step: 5
Training loss: 0.4493039548397064
Validation loss: 2.021344085534414

Epoch: 6| Step: 6
Training loss: 0.45857134461402893
Validation loss: 2.0151692032814026

Epoch: 6| Step: 7
Training loss: 0.3929216265678406
Validation loss: 2.0495876471201577

Epoch: 6| Step: 8
Training loss: 0.5432993769645691
Validation loss: 2.020020604133606

Epoch: 6| Step: 9
Training loss: 0.9508752226829529
Validation loss: 2.0457383394241333

Epoch: 6| Step: 10
Training loss: 0.4866153299808502
Validation loss: 2.0480991204579673

Epoch: 6| Step: 11
Training loss: 0.3842809200286865
Validation loss: 1.9983534812927246

Epoch: 6| Step: 12
Training loss: 0.4282481074333191
Validation loss: 1.9776575167973836

Epoch: 6| Step: 13
Training loss: 0.18860062956809998
Validation loss: 2.043707331021627

Epoch: 280| Step: 0
Training loss: 0.5866727232933044
Validation loss: 2.007041811943054

Epoch: 6| Step: 1
Training loss: 0.3845103979110718
Validation loss: 1.9935827453931172

Epoch: 6| Step: 2
Training loss: 0.4222433865070343
Validation loss: 1.9880749384562175

Epoch: 6| Step: 3
Training loss: 0.4809556007385254
Validation loss: 2.0078330437342324

Epoch: 6| Step: 4
Training loss: 0.2575695812702179
Validation loss: 2.0121559699376426

Epoch: 6| Step: 5
Training loss: 0.5053218603134155
Validation loss: 1.989864706993103

Epoch: 6| Step: 6
Training loss: 0.2603146433830261
Validation loss: 2.0336381594340005

Epoch: 6| Step: 7
Training loss: 0.31804490089416504
Validation loss: 2.011931618054708

Epoch: 6| Step: 8
Training loss: 0.9593172073364258
Validation loss: 1.9932183225949605

Epoch: 6| Step: 9
Training loss: 0.3705187737941742
Validation loss: 1.9879745841026306

Epoch: 6| Step: 10
Training loss: 0.2727663218975067
Validation loss: 1.9730108976364136

Epoch: 6| Step: 11
Training loss: 0.5863522291183472
Validation loss: 1.9984765251477559

Epoch: 6| Step: 12
Training loss: 0.2566492557525635
Validation loss: 2.0236584742863974

Epoch: 6| Step: 13
Training loss: 0.3010656237602234
Validation loss: 2.0624053279558816

Epoch: 281| Step: 0
Training loss: 0.5207812786102295
Validation loss: 2.061407824357351

Epoch: 6| Step: 1
Training loss: 0.404768168926239
Validation loss: 2.04748926560084

Epoch: 6| Step: 2
Training loss: 0.17296531796455383
Validation loss: 2.0484407345453897

Epoch: 6| Step: 3
Training loss: 0.28371289372444153
Validation loss: 2.00764133532842

Epoch: 6| Step: 4
Training loss: 0.5471694469451904
Validation loss: 1.9872794548670452

Epoch: 6| Step: 5
Training loss: 0.30653536319732666
Validation loss: 2.024223029613495

Epoch: 6| Step: 6
Training loss: 0.602666974067688
Validation loss: 2.0268171628316245

Epoch: 6| Step: 7
Training loss: 0.3199438154697418
Validation loss: 1.9931261738141377

Epoch: 6| Step: 8
Training loss: 0.32703861594200134
Validation loss: 2.0310005942980447

Epoch: 6| Step: 9
Training loss: 0.4285862445831299
Validation loss: 2.025089701016744

Epoch: 6| Step: 10
Training loss: 0.3557369112968445
Validation loss: 1.9947746396064758

Epoch: 6| Step: 11
Training loss: 0.2592657804489136
Validation loss: 1.9887792666753132

Epoch: 6| Step: 12
Training loss: 1.3165581226348877
Validation loss: 2.0259834925333657

Epoch: 6| Step: 13
Training loss: 0.2927256226539612
Validation loss: 1.9988545378049214

Epoch: 282| Step: 0
Training loss: 0.7792211771011353
Validation loss: 2.016309460004171

Epoch: 6| Step: 1
Training loss: 0.23134803771972656
Validation loss: 2.0353822708129883

Epoch: 6| Step: 2
Training loss: 0.47396063804626465
Validation loss: 2.0384198824564614

Epoch: 6| Step: 3
Training loss: 0.6936366558074951
Validation loss: 1.989823301633199

Epoch: 6| Step: 4
Training loss: 0.35416656732559204
Validation loss: 1.9687373836835225

Epoch: 6| Step: 5
Training loss: 0.26338714361190796
Validation loss: 1.992169161637624

Epoch: 6| Step: 6
Training loss: 0.2883198857307434
Validation loss: 2.0395992199579873

Epoch: 6| Step: 7
Training loss: 0.581720232963562
Validation loss: 2.0162039399147034

Epoch: 6| Step: 8
Training loss: 0.2791934907436371
Validation loss: 2.0107795198758445

Epoch: 6| Step: 9
Training loss: 0.3033391237258911
Validation loss: 1.976148744424184

Epoch: 6| Step: 10
Training loss: 0.5381453037261963
Validation loss: 1.959717591603597

Epoch: 6| Step: 11
Training loss: 0.2764120101928711
Validation loss: 2.0405001640319824

Epoch: 6| Step: 12
Training loss: 0.2717592120170593
Validation loss: 2.036824564139048

Epoch: 6| Step: 13
Training loss: 0.4072314500808716
Validation loss: 2.0035137931505838

Epoch: 283| Step: 0
Training loss: 0.6878830194473267
Validation loss: 2.0133561491966248

Epoch: 6| Step: 1
Training loss: 0.694352924823761
Validation loss: 2.0050132870674133

Epoch: 6| Step: 2
Training loss: 0.3747812807559967
Validation loss: 2.04103946685791

Epoch: 6| Step: 3
Training loss: 0.30759334564208984
Validation loss: 1.9720193147659302

Epoch: 6| Step: 4
Training loss: 0.4468832015991211
Validation loss: 2.060284594694773

Epoch: 6| Step: 5
Training loss: 0.7593059539794922
Validation loss: 1.9919535319010417

Epoch: 6| Step: 6
Training loss: 0.33384621143341064
Validation loss: 2.02842124303182

Epoch: 6| Step: 7
Training loss: 0.24580547213554382
Validation loss: 2.045158644517263

Epoch: 6| Step: 8
Training loss: 0.30512869358062744
Validation loss: 1.9654087821642559

Epoch: 6| Step: 9
Training loss: 0.18968839943408966
Validation loss: 2.0183754762013755

Epoch: 6| Step: 10
Training loss: 0.27188560366630554
Validation loss: 2.0236869851748147

Epoch: 6| Step: 11
Training loss: 0.4767773449420929
Validation loss: 1.9894988139470418

Epoch: 6| Step: 12
Training loss: 0.4039514362812042
Validation loss: 1.9950519800186157

Epoch: 6| Step: 13
Training loss: 0.2669423818588257
Validation loss: 1.9920950134595234

Epoch: 284| Step: 0
Training loss: 0.3023395240306854
Validation loss: 2.002675553162893

Epoch: 6| Step: 1
Training loss: 0.376693993806839
Validation loss: 1.9959213733673096

Epoch: 6| Step: 2
Training loss: 0.8952876329421997
Validation loss: 2.0037596027056375

Epoch: 6| Step: 3
Training loss: 0.33385828137397766
Validation loss: 2.0260478059450784

Epoch: 6| Step: 4
Training loss: 0.2108357548713684
Validation loss: 1.9815845688184102

Epoch: 6| Step: 5
Training loss: 0.25687700510025024
Validation loss: 2.0022572676340737

Epoch: 6| Step: 6
Training loss: 0.8429292440414429
Validation loss: 2.041377147038778

Epoch: 6| Step: 7
Training loss: 0.22868792712688446
Validation loss: 1.9933765729268391

Epoch: 6| Step: 8
Training loss: 0.5169681310653687
Validation loss: 2.005366047223409

Epoch: 6| Step: 9
Training loss: 0.4711250066757202
Validation loss: 2.0558578968048096

Epoch: 6| Step: 10
Training loss: 0.3680838644504547
Validation loss: 2.0154101649920144

Epoch: 6| Step: 11
Training loss: 0.5307652950286865
Validation loss: 2.00179394086202

Epoch: 6| Step: 12
Training loss: 0.3585532009601593
Validation loss: 2.00078417857488

Epoch: 6| Step: 13
Training loss: 0.3352818489074707
Validation loss: 2.0103365778923035

Epoch: 285| Step: 0
Training loss: 0.2876889109611511
Validation loss: 2.0150500933329263

Epoch: 6| Step: 1
Training loss: 0.2750588059425354
Validation loss: 2.0121285716692605

Epoch: 6| Step: 2
Training loss: 0.2417258620262146
Validation loss: 1.9878629247347515

Epoch: 6| Step: 3
Training loss: 0.7456637620925903
Validation loss: 2.0433666706085205

Epoch: 6| Step: 4
Training loss: 0.3212416172027588
Validation loss: 1.9961929321289062

Epoch: 6| Step: 5
Training loss: 0.26830703020095825
Validation loss: 2.0016757448514304

Epoch: 6| Step: 6
Training loss: 0.39897748827934265
Validation loss: 2.048405905564626

Epoch: 6| Step: 7
Training loss: 0.7211617231369019
Validation loss: 2.018764873345693

Epoch: 6| Step: 8
Training loss: 0.31033843755722046
Validation loss: 2.014830728371938

Epoch: 6| Step: 9
Training loss: 1.0674450397491455
Validation loss: 1.9884026845296223

Epoch: 6| Step: 10
Training loss: 0.3395587205886841
Validation loss: 2.038518269856771

Epoch: 6| Step: 11
Training loss: 0.44783803820610046
Validation loss: 2.0053988099098206

Epoch: 6| Step: 12
Training loss: 0.36770254373550415
Validation loss: 2.0416671435038247

Epoch: 6| Step: 13
Training loss: 0.38858431577682495
Validation loss: 2.038508872191111

Epoch: 286| Step: 0
Training loss: 0.17437341809272766
Validation loss: 2.03066353003184

Epoch: 6| Step: 1
Training loss: 0.6881872415542603
Validation loss: 2.0009135405222573

Epoch: 6| Step: 2
Training loss: 0.6056692004203796
Validation loss: 1.9941938718159993

Epoch: 6| Step: 3
Training loss: 0.3202452063560486
Validation loss: 1.9873406092325847

Epoch: 6| Step: 4
Training loss: 0.6698601245880127
Validation loss: 1.9905151724815369

Epoch: 6| Step: 5
Training loss: 0.44185006618499756
Validation loss: 2.0348376035690308

Epoch: 6| Step: 6
Training loss: 0.5615864396095276
Validation loss: 2.0569302439689636

Epoch: 6| Step: 7
Training loss: 0.4932076334953308
Validation loss: 2.0556445916493735

Epoch: 6| Step: 8
Training loss: 0.36016833782196045
Validation loss: 2.0611044565836587

Epoch: 6| Step: 9
Training loss: 0.19519047439098358
Validation loss: 2.0537099043528237

Epoch: 6| Step: 10
Training loss: 0.4399227499961853
Validation loss: 1.9637970924377441

Epoch: 6| Step: 11
Training loss: 0.42351233959198
Validation loss: 2.043154239654541

Epoch: 6| Step: 12
Training loss: 0.2091745138168335
Validation loss: 2.009035329023997

Epoch: 6| Step: 13
Training loss: 0.3136542737483978
Validation loss: 2.0187483628590903

Epoch: 287| Step: 0
Training loss: 0.22956298291683197
Validation loss: 2.0289953152338662

Epoch: 6| Step: 1
Training loss: 0.22054138779640198
Validation loss: 1.991491397221883

Epoch: 6| Step: 2
Training loss: 0.22373881936073303
Validation loss: 2.026380101839701

Epoch: 6| Step: 3
Training loss: 0.38191527128219604
Validation loss: 2.064640442530314

Epoch: 6| Step: 4
Training loss: 0.40389686822891235
Validation loss: 1.9993805487950642

Epoch: 6| Step: 5
Training loss: 0.3460928797721863
Validation loss: 2.026788671811422

Epoch: 6| Step: 6
Training loss: 0.31010356545448303
Validation loss: 2.041185677051544

Epoch: 6| Step: 7
Training loss: 0.8059476613998413
Validation loss: 2.0378857851028442

Epoch: 6| Step: 8
Training loss: 0.41196608543395996
Validation loss: 2.0389989415804544

Epoch: 6| Step: 9
Training loss: 0.6804566979408264
Validation loss: 2.0493560234705606

Epoch: 6| Step: 10
Training loss: 0.4991196095943451
Validation loss: 2.06557289759318

Epoch: 6| Step: 11
Training loss: 0.4031663239002228
Validation loss: 1.9916868408521016

Epoch: 6| Step: 12
Training loss: 0.5408029556274414
Validation loss: 2.0337942242622375

Epoch: 6| Step: 13
Training loss: 0.4790770411491394
Validation loss: 1.9964120388031006

Epoch: 288| Step: 0
Training loss: 0.2667909264564514
Validation loss: 2.045600195725759

Epoch: 6| Step: 1
Training loss: 0.41626155376434326
Validation loss: 2.0045401453971863

Epoch: 6| Step: 2
Training loss: 0.40916264057159424
Validation loss: 1.9993966023127239

Epoch: 6| Step: 3
Training loss: 0.6992210149765015
Validation loss: 2.021378676096598

Epoch: 6| Step: 4
Training loss: 0.4337635040283203
Validation loss: 2.0161959330240884

Epoch: 6| Step: 5
Training loss: 0.3606249988079071
Validation loss: 1.979246993859609

Epoch: 6| Step: 6
Training loss: 0.3526152968406677
Validation loss: 2.025006413459778

Epoch: 6| Step: 7
Training loss: 0.7522850632667542
Validation loss: 2.0104109048843384

Epoch: 6| Step: 8
Training loss: 0.3640708327293396
Validation loss: 2.011135379473368

Epoch: 6| Step: 9
Training loss: 0.17170920968055725
Validation loss: 1.9807049036026

Epoch: 6| Step: 10
Training loss: 0.4502687156200409
Validation loss: 1.9775755604108174

Epoch: 6| Step: 11
Training loss: 0.20306581258773804
Validation loss: 1.9970773657162983

Epoch: 6| Step: 12
Training loss: 0.4227423071861267
Validation loss: 1.998684565226237

Epoch: 6| Step: 13
Training loss: 0.7487233877182007
Validation loss: 2.002585848172506

Epoch: 289| Step: 0
Training loss: 0.18060468137264252
Validation loss: 1.9931325515111287

Epoch: 6| Step: 1
Training loss: 0.2788197994232178
Validation loss: 2.029945731163025

Epoch: 6| Step: 2
Training loss: 0.31896692514419556
Validation loss: 2.0379685163497925

Epoch: 6| Step: 3
Training loss: 0.9055134057998657
Validation loss: 1.9931307037671406

Epoch: 6| Step: 4
Training loss: 0.47304409742355347
Validation loss: 1.9921944538752239

Epoch: 6| Step: 5
Training loss: 0.5864336490631104
Validation loss: 2.0233525037765503

Epoch: 6| Step: 6
Training loss: 0.27788567543029785
Validation loss: 2.0125606854756675

Epoch: 6| Step: 7
Training loss: 0.272858589887619
Validation loss: 1.9922143419583638

Epoch: 6| Step: 8
Training loss: 0.38329148292541504
Validation loss: 2.039997180302938

Epoch: 6| Step: 9
Training loss: 0.3230418860912323
Validation loss: 1.9921855529149373

Epoch: 6| Step: 10
Training loss: 0.4574027359485626
Validation loss: 2.013905624548594

Epoch: 6| Step: 11
Training loss: 0.4394921064376831
Validation loss: 2.0010520021120706

Epoch: 6| Step: 12
Training loss: 0.6272987127304077
Validation loss: 1.989054540793101

Epoch: 6| Step: 13
Training loss: 0.41858983039855957
Validation loss: 2.0208202401796975

Epoch: 290| Step: 0
Training loss: 0.35794514417648315
Validation loss: 2.026847163836161

Epoch: 6| Step: 1
Training loss: 0.24535000324249268
Validation loss: 2.0473329226175943

Epoch: 6| Step: 2
Training loss: 0.6408921480178833
Validation loss: 1.9814407229423523

Epoch: 6| Step: 3
Training loss: 0.4098697602748871
Validation loss: 1.9701953530311584

Epoch: 6| Step: 4
Training loss: 0.30436521768569946
Validation loss: 2.0696891148885093

Epoch: 6| Step: 5
Training loss: 0.7396889925003052
Validation loss: 2.0357110699017844

Epoch: 6| Step: 6
Training loss: 0.33787068724632263
Validation loss: 2.0139072140057883

Epoch: 6| Step: 7
Training loss: 0.22414946556091309
Validation loss: 2.02496608098348

Epoch: 6| Step: 8
Training loss: 0.7145934104919434
Validation loss: 1.9736528396606445

Epoch: 6| Step: 9
Training loss: 0.45951777696609497
Validation loss: 2.0474798480669656

Epoch: 6| Step: 10
Training loss: 0.23107574880123138
Validation loss: 2.0140288869539895

Epoch: 6| Step: 11
Training loss: 0.5163655281066895
Validation loss: 2.0063440998395285

Epoch: 6| Step: 12
Training loss: 0.2417331039905548
Validation loss: 2.0017042756080627

Epoch: 6| Step: 13
Training loss: 0.3340332508087158
Validation loss: 2.0630866289138794

Epoch: 291| Step: 0
Training loss: 0.243520125746727
Validation loss: 1.9714139103889465

Epoch: 6| Step: 1
Training loss: 0.571140468120575
Validation loss: 1.9998340408007305

Epoch: 6| Step: 2
Training loss: 0.24828457832336426
Validation loss: 2.02006334066391

Epoch: 6| Step: 3
Training loss: 0.19595462083816528
Validation loss: 2.02010448773702

Epoch: 6| Step: 4
Training loss: 0.29340267181396484
Validation loss: 2.055199444293976

Epoch: 6| Step: 5
Training loss: 0.24664731323719025
Validation loss: 2.01751846075058

Epoch: 6| Step: 6
Training loss: 0.677095890045166
Validation loss: 2.026446203390757

Epoch: 6| Step: 7
Training loss: 0.4608181118965149
Validation loss: 1.9763944546381633

Epoch: 6| Step: 8
Training loss: 0.45119160413742065
Validation loss: 1.9753865202267964

Epoch: 6| Step: 9
Training loss: 0.2999260127544403
Validation loss: 1.9901095231374104

Epoch: 6| Step: 10
Training loss: 0.9202440977096558
Validation loss: 2.026699205239614

Epoch: 6| Step: 11
Training loss: 0.5320128202438354
Validation loss: 2.0593910614649453

Epoch: 6| Step: 12
Training loss: 0.36076462268829346
Validation loss: 1.9807477792104085

Epoch: 6| Step: 13
Training loss: 0.24679748713970184
Validation loss: 2.0219114422798157

Epoch: 292| Step: 0
Training loss: 0.3329215347766876
Validation loss: 2.0282095273335776

Epoch: 6| Step: 1
Training loss: 0.41515398025512695
Validation loss: 2.036927044391632

Epoch: 6| Step: 2
Training loss: 0.29239723086357117
Validation loss: 2.0609606504440308

Epoch: 6| Step: 3
Training loss: 0.46048325300216675
Validation loss: 2.0324161450068154

Epoch: 6| Step: 4
Training loss: 0.576305627822876
Validation loss: 2.0163581470648446

Epoch: 6| Step: 5
Training loss: 0.2682068347930908
Validation loss: 2.0497141679128013

Epoch: 6| Step: 6
Training loss: 1.0170478820800781
Validation loss: 2.038850943247477

Epoch: 6| Step: 7
Training loss: 0.4970664978027344
Validation loss: 2.057520866394043

Epoch: 6| Step: 8
Training loss: 0.1816665083169937
Validation loss: 2.044256309668223

Epoch: 6| Step: 9
Training loss: 0.41393205523490906
Validation loss: 2.02194090684255

Epoch: 6| Step: 10
Training loss: 0.16493549942970276
Validation loss: 2.0219323436419168

Epoch: 6| Step: 11
Training loss: 0.24670633673667908
Validation loss: 2.015360494454702

Epoch: 6| Step: 12
Training loss: 0.6249166131019592
Validation loss: 2.0006410479545593

Epoch: 6| Step: 13
Training loss: 0.3506302833557129
Validation loss: 2.0537712574005127

Epoch: 293| Step: 0
Training loss: 0.2953519821166992
Validation loss: 2.053510387738546

Epoch: 6| Step: 1
Training loss: 0.7603731155395508
Validation loss: 2.041195491949717

Epoch: 6| Step: 2
Training loss: 0.16952499747276306
Validation loss: 2.0232601364453635

Epoch: 6| Step: 3
Training loss: 0.3345400393009186
Validation loss: 2.0544397632280984

Epoch: 6| Step: 4
Training loss: 0.6429855823516846
Validation loss: 2.015841066837311

Epoch: 6| Step: 5
Training loss: 0.36339667439460754
Validation loss: 2.0166015227635703

Epoch: 6| Step: 6
Training loss: 0.20912030339241028
Validation loss: 1.9814085563023884

Epoch: 6| Step: 7
Training loss: 0.4901583790779114
Validation loss: 2.00701242685318

Epoch: 6| Step: 8
Training loss: 0.23414240777492523
Validation loss: 2.0422849655151367

Epoch: 6| Step: 9
Training loss: 0.4077633023262024
Validation loss: 2.015236179033915

Epoch: 6| Step: 10
Training loss: 0.882489025592804
Validation loss: 2.0056232213974

Epoch: 6| Step: 11
Training loss: 0.32667237520217896
Validation loss: 2.039545019467672

Epoch: 6| Step: 12
Training loss: 0.5413323044776917
Validation loss: 2.0090746680895486

Epoch: 6| Step: 13
Training loss: 0.5492038130760193
Validation loss: 2.0328624645868936

Epoch: 294| Step: 0
Training loss: 0.46011051535606384
Validation loss: 2.017262816429138

Epoch: 6| Step: 1
Training loss: 0.33967024087905884
Validation loss: 2.0200063784917197

Epoch: 6| Step: 2
Training loss: 0.7731708884239197
Validation loss: 2.0468051433563232

Epoch: 6| Step: 3
Training loss: 0.3127283453941345
Validation loss: 2.0045512318611145

Epoch: 6| Step: 4
Training loss: 0.2227572351694107
Validation loss: 2.0296356678009033

Epoch: 6| Step: 5
Training loss: 0.2821003496646881
Validation loss: 1.98259832461675

Epoch: 6| Step: 6
Training loss: 0.36829590797424316
Validation loss: 1.9853769540786743

Epoch: 6| Step: 7
Training loss: 0.2215161770582199
Validation loss: 2.0059091647466025

Epoch: 6| Step: 8
Training loss: 0.35192185640335083
Validation loss: 1.999027927716573

Epoch: 6| Step: 9
Training loss: 0.5354410409927368
Validation loss: 2.051220734914144

Epoch: 6| Step: 10
Training loss: 0.28113430738449097
Validation loss: 2.0364542404810586

Epoch: 6| Step: 11
Training loss: 0.4035395681858063
Validation loss: 2.040411631266276

Epoch: 6| Step: 12
Training loss: 0.4462592601776123
Validation loss: 2.1082458893458047

Epoch: 6| Step: 13
Training loss: 0.5621894001960754
Validation loss: 2.082882523536682

Epoch: 295| Step: 0
Training loss: 0.3848176896572113
Validation loss: 2.030189553896586

Epoch: 6| Step: 1
Training loss: 0.22814419865608215
Validation loss: 2.043243865172068

Epoch: 6| Step: 2
Training loss: 0.5076285004615784
Validation loss: 2.03363303343455

Epoch: 6| Step: 3
Training loss: 0.36596494913101196
Validation loss: 2.0202271938323975

Epoch: 6| Step: 4
Training loss: 0.19294175505638123
Validation loss: 2.034886916478475

Epoch: 6| Step: 5
Training loss: 0.4998213052749634
Validation loss: 2.026474118232727

Epoch: 6| Step: 6
Training loss: 0.41893815994262695
Validation loss: 2.037133773167928

Epoch: 6| Step: 7
Training loss: 0.24742817878723145
Validation loss: 2.038569152355194

Epoch: 6| Step: 8
Training loss: 0.5805220007896423
Validation loss: 2.031687160332998

Epoch: 6| Step: 9
Training loss: 0.28399431705474854
Validation loss: 1.983721931775411

Epoch: 6| Step: 10
Training loss: 0.5112866163253784
Validation loss: 1.997900386651357

Epoch: 6| Step: 11
Training loss: 0.4419609606266022
Validation loss: 2.0380153258641562

Epoch: 6| Step: 12
Training loss: 0.6458204388618469
Validation loss: 2.0125409166018167

Epoch: 6| Step: 13
Training loss: 0.3756680190563202
Validation loss: 2.034204602241516

Epoch: 296| Step: 0
Training loss: 0.38529422879219055
Validation loss: 2.0061076084772744

Epoch: 6| Step: 1
Training loss: 0.34201744198799133
Validation loss: 2.0018781820933023

Epoch: 6| Step: 2
Training loss: 0.4464651048183441
Validation loss: 2.049450616041819

Epoch: 6| Step: 3
Training loss: 0.3568379282951355
Validation loss: 2.0337238907814026

Epoch: 6| Step: 4
Training loss: 0.5326275825500488
Validation loss: 1.978103498617808

Epoch: 6| Step: 5
Training loss: 0.8113030791282654
Validation loss: 2.0074181159337363

Epoch: 6| Step: 6
Training loss: 0.4896434545516968
Validation loss: 2.0254507462183633

Epoch: 6| Step: 7
Training loss: 0.5114656090736389
Validation loss: 1.9994906783103943

Epoch: 6| Step: 8
Training loss: 0.3231154978275299
Validation loss: 2.0035316348075867

Epoch: 6| Step: 9
Training loss: 0.21300099790096283
Validation loss: 2.0464435617129006

Epoch: 6| Step: 10
Training loss: 0.34162014722824097
Validation loss: 2.0023962457974753

Epoch: 6| Step: 11
Training loss: 0.4145151376724243
Validation loss: 1.997567057609558

Epoch: 6| Step: 12
Training loss: 0.3023228645324707
Validation loss: 1.971028467019399

Epoch: 6| Step: 13
Training loss: 0.28772079944610596
Validation loss: 2.0166802406311035

Epoch: 297| Step: 0
Training loss: 0.396498441696167
Validation loss: 2.0307735006014505

Epoch: 6| Step: 1
Training loss: 0.21469418704509735
Validation loss: 1.9764536221822102

Epoch: 6| Step: 2
Training loss: 0.48267772793769836
Validation loss: 1.9677323698997498

Epoch: 6| Step: 3
Training loss: 0.27578237652778625
Validation loss: 2.006909747918447

Epoch: 6| Step: 4
Training loss: 0.20008626580238342
Validation loss: 2.0413186152776084

Epoch: 6| Step: 5
Training loss: 0.5220744609832764
Validation loss: 2.0090039372444153

Epoch: 6| Step: 6
Training loss: 0.4574078619480133
Validation loss: 2.039015511671702

Epoch: 6| Step: 7
Training loss: 0.2432008683681488
Validation loss: 2.0379404028256736

Epoch: 6| Step: 8
Training loss: 0.3526883125305176
Validation loss: 2.032870332400004

Epoch: 6| Step: 9
Training loss: 0.5789753794670105
Validation loss: 2.0075876712799072

Epoch: 6| Step: 10
Training loss: 0.4264152944087982
Validation loss: 2.0223175684611

Epoch: 6| Step: 11
Training loss: 0.4044303297996521
Validation loss: 2.00389971335729

Epoch: 6| Step: 12
Training loss: 0.8091520071029663
Validation loss: 1.9972926775614421

Epoch: 6| Step: 13
Training loss: 0.25773751735687256
Validation loss: 2.030037999153137

Epoch: 298| Step: 0
Training loss: 0.28428566455841064
Validation loss: 2.0477790037790933

Epoch: 6| Step: 1
Training loss: 0.6786072850227356
Validation loss: 2.0019190112749734

Epoch: 6| Step: 2
Training loss: 0.3262498080730438
Validation loss: 1.98723703622818

Epoch: 6| Step: 3
Training loss: 0.3609602451324463
Validation loss: 1.9918678402900696

Epoch: 6| Step: 4
Training loss: 0.32436466217041016
Validation loss: 1.9650785525639851

Epoch: 6| Step: 5
Training loss: 0.27869683504104614
Validation loss: 2.0382145643234253

Epoch: 6| Step: 6
Training loss: 0.2539764940738678
Validation loss: 2.0095879634221396

Epoch: 6| Step: 7
Training loss: 0.5718446969985962
Validation loss: 2.079518516858419

Epoch: 6| Step: 8
Training loss: 0.40454089641571045
Validation loss: 2.0535277128219604

Epoch: 6| Step: 9
Training loss: 0.6143935918807983
Validation loss: 2.0094329913457236

Epoch: 6| Step: 10
Training loss: 0.2467823177576065
Validation loss: 2.0254173477490744

Epoch: 6| Step: 11
Training loss: 0.41955214738845825
Validation loss: 1.9912903308868408

Epoch: 6| Step: 12
Training loss: 0.5903173089027405
Validation loss: 2.0538163781166077

Epoch: 6| Step: 13
Training loss: 0.4728540778160095
Validation loss: 2.03261391321818

Epoch: 299| Step: 0
Training loss: 0.46423283219337463
Validation loss: 2.055955946445465

Epoch: 6| Step: 1
Training loss: 0.4781777858734131
Validation loss: 2.038043200969696

Epoch: 6| Step: 2
Training loss: 0.17348632216453552
Validation loss: 2.0214669505755105

Epoch: 6| Step: 3
Training loss: 0.5639967918395996
Validation loss: 1.963704228401184

Epoch: 6| Step: 4
Training loss: 0.2997726500034332
Validation loss: 2.0122541586558023

Epoch: 6| Step: 5
Training loss: 0.2653774321079254
Validation loss: 2.0363325277964273

Epoch: 6| Step: 6
Training loss: 0.47949302196502686
Validation loss: 2.005841871102651

Epoch: 6| Step: 7
Training loss: 0.5136747360229492
Validation loss: 1.9789308309555054

Epoch: 6| Step: 8
Training loss: 0.2934940457344055
Validation loss: 2.0139006773630777

Epoch: 6| Step: 9
Training loss: 0.8044961094856262
Validation loss: 2.0113136172294617

Epoch: 6| Step: 10
Training loss: 0.3994722068309784
Validation loss: 1.9935349623362224

Epoch: 6| Step: 11
Training loss: 0.25255540013313293
Validation loss: 2.0344746311505637

Epoch: 6| Step: 12
Training loss: 0.33807191252708435
Validation loss: 2.024653116861979

Epoch: 6| Step: 13
Training loss: 0.5230062007904053
Validation loss: 2.0282327135403952

Epoch: 300| Step: 0
Training loss: 0.21461786329746246
Validation loss: 1.9857038656870525

Epoch: 6| Step: 1
Training loss: 0.39485087990760803
Validation loss: 2.0050289829572043

Epoch: 6| Step: 2
Training loss: 0.5249797105789185
Validation loss: 2.03344319264094

Epoch: 6| Step: 3
Training loss: 0.5867559313774109
Validation loss: 1.9757503271102905

Epoch: 6| Step: 4
Training loss: 0.40967118740081787
Validation loss: 2.0429186820983887

Epoch: 6| Step: 5
Training loss: 0.23981040716171265
Validation loss: 2.0475619236628213

Epoch: 6| Step: 6
Training loss: 0.4292072057723999
Validation loss: 2.036077558994293

Epoch: 6| Step: 7
Training loss: 0.350944459438324
Validation loss: 1.9791329304377239

Epoch: 6| Step: 8
Training loss: 0.16888855397701263
Validation loss: 2.017862617969513

Epoch: 6| Step: 9
Training loss: 0.3536231517791748
Validation loss: 2.006416300932566

Epoch: 6| Step: 10
Training loss: 0.5015912652015686
Validation loss: 2.0701365073521933

Epoch: 6| Step: 11
Training loss: 0.5719155073165894
Validation loss: 2.0087597568829856

Epoch: 6| Step: 12
Training loss: 0.8308246731758118
Validation loss: 2.0075121323267617

Epoch: 6| Step: 13
Training loss: 0.3438364565372467
Validation loss: 1.9933570623397827

Epoch: 301| Step: 0
Training loss: 0.46445605158805847
Validation loss: 2.0201761523882547

Epoch: 6| Step: 1
Training loss: 0.23793712258338928
Validation loss: 2.0314305623372397

Epoch: 6| Step: 2
Training loss: 0.3816222548484802
Validation loss: 2.022950530052185

Epoch: 6| Step: 3
Training loss: 0.501553475856781
Validation loss: 2.0233989159266152

Epoch: 6| Step: 4
Training loss: 0.33966362476348877
Validation loss: 2.0268832047780356

Epoch: 6| Step: 5
Training loss: 0.3049611449241638
Validation loss: 2.0194859504699707

Epoch: 6| Step: 6
Training loss: 0.2854052186012268
Validation loss: 2.023258090019226

Epoch: 6| Step: 7
Training loss: 0.2644141614437103
Validation loss: 2.0482136408487954

Epoch: 6| Step: 8
Training loss: 0.39719584584236145
Validation loss: 1.9858543078104656

Epoch: 6| Step: 9
Training loss: 0.8475439548492432
Validation loss: 1.9989572763442993

Epoch: 6| Step: 10
Training loss: 0.26877909898757935
Validation loss: 1.9897635976473491

Epoch: 6| Step: 11
Training loss: 0.6114349961280823
Validation loss: 2.020912230014801

Epoch: 6| Step: 12
Training loss: 0.5538724660873413
Validation loss: 2.0140101512273154

Epoch: 6| Step: 13
Training loss: 0.5611627697944641
Validation loss: 2.0377316077550254

Epoch: 302| Step: 0
Training loss: 0.19239525496959686
Validation loss: 1.978530486424764

Epoch: 6| Step: 1
Training loss: 0.31080636382102966
Validation loss: 2.021212100982666

Epoch: 6| Step: 2
Training loss: 0.520853579044342
Validation loss: 2.0174466967582703

Epoch: 6| Step: 3
Training loss: 0.3588389456272125
Validation loss: 1.9843732118606567

Epoch: 6| Step: 4
Training loss: 0.24152779579162598
Validation loss: 2.014626145362854

Epoch: 6| Step: 5
Training loss: 0.6540631651878357
Validation loss: 2.0309664209683738

Epoch: 6| Step: 6
Training loss: 0.3299829959869385
Validation loss: 1.9827360312143962

Epoch: 6| Step: 7
Training loss: 0.31851673126220703
Validation loss: 2.0350353717803955

Epoch: 6| Step: 8
Training loss: 0.36767131090164185
Validation loss: 1.9671016732851665

Epoch: 6| Step: 9
Training loss: 0.6285936236381531
Validation loss: 1.9869494835535686

Epoch: 6| Step: 10
Training loss: 0.4299439787864685
Validation loss: 1.979267140229543

Epoch: 6| Step: 11
Training loss: 0.4148305654525757
Validation loss: 1.980186363061269

Epoch: 6| Step: 12
Training loss: 0.457351416349411
Validation loss: 2.0035555164019265

Epoch: 6| Step: 13
Training loss: 0.5921351909637451
Validation loss: 2.0331768790880838

Epoch: 303| Step: 0
Training loss: 0.30997997522354126
Validation loss: 2.0157214204470315

Epoch: 6| Step: 1
Training loss: 0.38491445779800415
Validation loss: 2.0491174856821694

Epoch: 6| Step: 2
Training loss: 0.5123404264450073
Validation loss: 2.0105661948521933

Epoch: 6| Step: 3
Training loss: 0.21491660177707672
Validation loss: 1.991988758246104

Epoch: 6| Step: 4
Training loss: 0.37738656997680664
Validation loss: 1.9906623562177022

Epoch: 6| Step: 5
Training loss: 0.6092542409896851
Validation loss: 1.9904104272524517

Epoch: 6| Step: 6
Training loss: 0.39212143421173096
Validation loss: 1.974741538365682

Epoch: 6| Step: 7
Training loss: 0.3687942922115326
Validation loss: 1.9878053863843281

Epoch: 6| Step: 8
Training loss: 0.6791939735412598
Validation loss: 2.02813192208608

Epoch: 6| Step: 9
Training loss: 0.30012720823287964
Validation loss: 2.0266916751861572

Epoch: 6| Step: 10
Training loss: 0.43243277072906494
Validation loss: 2.0204515854517617

Epoch: 6| Step: 11
Training loss: 0.2206662893295288
Validation loss: 1.978745440642039

Epoch: 6| Step: 12
Training loss: 0.4204339385032654
Validation loss: 2.05530575911204

Epoch: 6| Step: 13
Training loss: 0.3568495512008667
Validation loss: 1.9821814099947612

Epoch: 304| Step: 0
Training loss: 0.2504701316356659
Validation loss: 2.0164314111073813

Epoch: 6| Step: 1
Training loss: 0.2555120885372162
Validation loss: 1.9936888217926025

Epoch: 6| Step: 2
Training loss: 0.3727865219116211
Validation loss: 1.9886858264605205

Epoch: 6| Step: 3
Training loss: 0.3597865402698517
Validation loss: 2.0021353363990784

Epoch: 6| Step: 4
Training loss: 0.3081408143043518
Validation loss: 1.9356616139411926

Epoch: 6| Step: 5
Training loss: 0.4790663421154022
Validation loss: 2.0006427566210427

Epoch: 6| Step: 6
Training loss: 0.3607625961303711
Validation loss: 1.996838092803955

Epoch: 6| Step: 7
Training loss: 0.2750978171825409
Validation loss: 1.9728731513023376

Epoch: 6| Step: 8
Training loss: 0.4181878864765167
Validation loss: 2.0106035272280374

Epoch: 6| Step: 9
Training loss: 0.42388641834259033
Validation loss: 1.9619950254758198

Epoch: 6| Step: 10
Training loss: 0.3209863603115082
Validation loss: 1.9835448463757832

Epoch: 6| Step: 11
Training loss: 0.9088706970214844
Validation loss: 2.061763902505239

Epoch: 6| Step: 12
Training loss: 0.781883955001831
Validation loss: 2.001882314682007

Epoch: 6| Step: 13
Training loss: 0.5362119078636169
Validation loss: 1.9743969837824504

Epoch: 305| Step: 0
Training loss: 0.9004108309745789
Validation loss: 2.029956022898356

Epoch: 6| Step: 1
Training loss: 0.7591056823730469
Validation loss: 1.9929959575335185

Epoch: 6| Step: 2
Training loss: 0.19928008317947388
Validation loss: 1.9874207178751628

Epoch: 6| Step: 3
Training loss: 0.37856701016426086
Validation loss: 1.9992181956768036

Epoch: 6| Step: 4
Training loss: 0.4719388484954834
Validation loss: 1.9895165363947551

Epoch: 6| Step: 5
Training loss: 0.22038313746452332
Validation loss: 2.066955049832662

Epoch: 6| Step: 6
Training loss: 0.5468698740005493
Validation loss: 1.9764052430788677

Epoch: 6| Step: 7
Training loss: 0.2982555627822876
Validation loss: 1.9767459829648335

Epoch: 6| Step: 8
Training loss: 0.5561637878417969
Validation loss: 2.0460734168688455

Epoch: 6| Step: 9
Training loss: 0.6522464752197266
Validation loss: 1.9809368054072063

Epoch: 6| Step: 10
Training loss: 0.2980261445045471
Validation loss: 2.0318507750829062

Epoch: 6| Step: 11
Training loss: 0.24920403957366943
Validation loss: 2.017439285914103

Epoch: 6| Step: 12
Training loss: 0.2890733778476715
Validation loss: 2.0250724951426187

Epoch: 6| Step: 13
Training loss: 0.1679573804140091
Validation loss: 1.985407292842865

Epoch: 306| Step: 0
Training loss: 0.22962439060211182
Validation loss: 1.9951187173525493

Epoch: 6| Step: 1
Training loss: 0.24179042875766754
Validation loss: 2.0259376764297485

Epoch: 6| Step: 2
Training loss: 0.7077900171279907
Validation loss: 1.9918859004974365

Epoch: 6| Step: 3
Training loss: 0.30980050563812256
Validation loss: 2.0347026586532593

Epoch: 6| Step: 4
Training loss: 0.328000009059906
Validation loss: 2.017890433470408

Epoch: 6| Step: 5
Training loss: 0.650915265083313
Validation loss: 2.063912868499756

Epoch: 6| Step: 6
Training loss: 0.3029138445854187
Validation loss: 2.0326068798700967

Epoch: 6| Step: 7
Training loss: 0.23377279937267303
Validation loss: 1.98056960105896

Epoch: 6| Step: 8
Training loss: 0.30641669034957886
Validation loss: 2.021726965904236

Epoch: 6| Step: 9
Training loss: 0.3218637704849243
Validation loss: 2.017288605372111

Epoch: 6| Step: 10
Training loss: 0.44310712814331055
Validation loss: 2.019555230935415

Epoch: 6| Step: 11
Training loss: 0.2344343066215515
Validation loss: 1.9406484365463257

Epoch: 6| Step: 12
Training loss: 0.5671260952949524
Validation loss: 2.0278219978014627

Epoch: 6| Step: 13
Training loss: 0.5189012289047241
Validation loss: 1.9867502649625142

Epoch: 307| Step: 0
Training loss: 0.673132061958313
Validation loss: 1.9893523852030437

Epoch: 6| Step: 1
Training loss: 0.3790653944015503
Validation loss: 1.979860524336497

Epoch: 6| Step: 2
Training loss: 0.3237675428390503
Validation loss: 2.017473896344503

Epoch: 6| Step: 3
Training loss: 0.402091920375824
Validation loss: 1.9826263785362244

Epoch: 6| Step: 4
Training loss: 0.26761651039123535
Validation loss: 2.0257506171862283

Epoch: 6| Step: 5
Training loss: 0.8454835414886475
Validation loss: 1.9843613902727764

Epoch: 6| Step: 6
Training loss: 0.4650252163410187
Validation loss: 1.9793727397918701

Epoch: 6| Step: 7
Training loss: 0.6574480533599854
Validation loss: 1.9919120073318481

Epoch: 6| Step: 8
Training loss: 0.3232496678829193
Validation loss: 2.0407063166300454

Epoch: 6| Step: 9
Training loss: 0.2572137117385864
Validation loss: 2.021420419216156

Epoch: 6| Step: 10
Training loss: 0.3300294876098633
Validation loss: 2.0125977993011475

Epoch: 6| Step: 11
Training loss: 0.32910072803497314
Validation loss: 1.9925641417503357

Epoch: 6| Step: 12
Training loss: 0.4540792405605316
Validation loss: 2.056836406389872

Epoch: 6| Step: 13
Training loss: 0.1924583613872528
Validation loss: 1.9740124146143596

Epoch: 308| Step: 0
Training loss: 0.49120911955833435
Validation loss: 1.9924094478289287

Epoch: 6| Step: 1
Training loss: 0.2334960550069809
Validation loss: 1.9515679279963176

Epoch: 6| Step: 2
Training loss: 0.38202551007270813
Validation loss: 2.02869321902593

Epoch: 6| Step: 3
Training loss: 0.5610618591308594
Validation loss: 2.010671238104502

Epoch: 6| Step: 4
Training loss: 0.8793611526489258
Validation loss: 2.021970212459564

Epoch: 6| Step: 5
Training loss: 0.3815779685974121
Validation loss: 2.0105976661046348

Epoch: 6| Step: 6
Training loss: 0.3412720263004303
Validation loss: 2.0188763538996377

Epoch: 6| Step: 7
Training loss: 0.30996909737586975
Validation loss: 1.9974313179651897

Epoch: 6| Step: 8
Training loss: 0.374999076128006
Validation loss: 2.0502724250157676

Epoch: 6| Step: 9
Training loss: 0.3490642011165619
Validation loss: 2.025459031263987

Epoch: 6| Step: 10
Training loss: 0.2970912456512451
Validation loss: 2.0761730869611106

Epoch: 6| Step: 11
Training loss: 0.6708608865737915
Validation loss: 1.9871837099393208

Epoch: 6| Step: 12
Training loss: 0.24101313948631287
Validation loss: 1.9987683097521465

Epoch: 6| Step: 13
Training loss: 0.4558093547821045
Validation loss: 2.018999536832174

Epoch: 309| Step: 0
Training loss: 0.5471878051757812
Validation loss: 2.007217506567637

Epoch: 6| Step: 1
Training loss: 0.5331786870956421
Validation loss: 2.0301120281219482

Epoch: 6| Step: 2
Training loss: 0.9182491898536682
Validation loss: 2.0027499397595725

Epoch: 6| Step: 3
Training loss: 0.4132145643234253
Validation loss: 2.0403363505999246

Epoch: 6| Step: 4
Training loss: 0.20715942978858948
Validation loss: 2.0157361229260764

Epoch: 6| Step: 5
Training loss: 0.312883198261261
Validation loss: 2.0058827797571817

Epoch: 6| Step: 6
Training loss: 0.24840287864208221
Validation loss: 2.0185368061065674

Epoch: 6| Step: 7
Training loss: 0.27999693155288696
Validation loss: 2.016338527202606

Epoch: 6| Step: 8
Training loss: 0.17069777846336365
Validation loss: 2.0122254490852356

Epoch: 6| Step: 9
Training loss: 0.35140615701675415
Validation loss: 1.96525177359581

Epoch: 6| Step: 10
Training loss: 0.4106161594390869
Validation loss: 1.9889000455538433

Epoch: 6| Step: 11
Training loss: 0.30995577573776245
Validation loss: 2.0184038082758584

Epoch: 6| Step: 12
Training loss: 0.19794389605522156
Validation loss: 2.0080121954282126

Epoch: 6| Step: 13
Training loss: 0.34333181381225586
Validation loss: 2.0075357953707376

Epoch: 310| Step: 0
Training loss: 0.3298772871494293
Validation loss: 1.9727308750152588

Epoch: 6| Step: 1
Training loss: 0.24866139888763428
Validation loss: 1.9928991397221882

Epoch: 6| Step: 2
Training loss: 0.6025641560554504
Validation loss: 1.971992055575053

Epoch: 6| Step: 3
Training loss: 0.654534637928009
Validation loss: 2.031005024909973

Epoch: 6| Step: 4
Training loss: 0.22680367529392242
Validation loss: 2.016730705897013

Epoch: 6| Step: 5
Training loss: 0.5024711489677429
Validation loss: 2.0144023100535073

Epoch: 6| Step: 6
Training loss: 0.33269202709198
Validation loss: 2.008297324180603

Epoch: 6| Step: 7
Training loss: 0.15794417262077332
Validation loss: 2.0318464040756226

Epoch: 6| Step: 8
Training loss: 0.28262031078338623
Validation loss: 2.00556751092275

Epoch: 6| Step: 9
Training loss: 0.16726943850517273
Validation loss: 2.0293065905570984

Epoch: 6| Step: 10
Training loss: 0.24826975166797638
Validation loss: 2.0636382897694907

Epoch: 6| Step: 11
Training loss: 0.2635917663574219
Validation loss: 2.0091639955838523

Epoch: 6| Step: 12
Training loss: 0.45024359226226807
Validation loss: 2.0547738671302795

Epoch: 6| Step: 13
Training loss: 0.626076340675354
Validation loss: 2.044823388258616

Epoch: 311| Step: 0
Training loss: 0.47334542870521545
Validation loss: 2.0148062109947205

Epoch: 6| Step: 1
Training loss: 0.371612548828125
Validation loss: 2.0042562087376914

Epoch: 6| Step: 2
Training loss: 1.0799665451049805
Validation loss: 1.970892330010732

Epoch: 6| Step: 3
Training loss: 0.24171552062034607
Validation loss: 2.0129260818163552

Epoch: 6| Step: 4
Training loss: 0.5304810404777527
Validation loss: 2.0243714849154153

Epoch: 6| Step: 5
Training loss: 0.2593512535095215
Validation loss: 1.9926942586898804

Epoch: 6| Step: 6
Training loss: 0.2996537387371063
Validation loss: 2.0026583472887673

Epoch: 6| Step: 7
Training loss: 0.4847242832183838
Validation loss: 2.039793908596039

Epoch: 6| Step: 8
Training loss: 0.43313658237457275
Validation loss: 2.013652781645457

Epoch: 6| Step: 9
Training loss: 0.23497064411640167
Validation loss: 2.0209259192148843

Epoch: 6| Step: 10
Training loss: 0.2608528733253479
Validation loss: 2.0143781105677285

Epoch: 6| Step: 11
Training loss: 0.2326623946428299
Validation loss: 1.9973281621932983

Epoch: 6| Step: 12
Training loss: 0.301505982875824
Validation loss: 2.002524216969808

Epoch: 6| Step: 13
Training loss: 0.26402050256729126
Validation loss: 2.029167334238688

Epoch: 312| Step: 0
Training loss: 0.4714370369911194
Validation loss: 2.006133556365967

Epoch: 6| Step: 1
Training loss: 0.452684611082077
Validation loss: 2.0143407384554544

Epoch: 6| Step: 2
Training loss: 0.36983150243759155
Validation loss: 2.017005125681559

Epoch: 6| Step: 3
Training loss: 0.47987425327301025
Validation loss: 2.0366031924883523

Epoch: 6| Step: 4
Training loss: 0.2620754837989807
Validation loss: 1.9927947918574016

Epoch: 6| Step: 5
Training loss: 0.2457175850868225
Validation loss: 1.9779228568077087

Epoch: 6| Step: 6
Training loss: 0.24590423703193665
Validation loss: 1.9897826711336772

Epoch: 6| Step: 7
Training loss: 0.5012320280075073
Validation loss: 2.0150648951530457

Epoch: 6| Step: 8
Training loss: 0.5521396398544312
Validation loss: 2.005716403325399

Epoch: 6| Step: 9
Training loss: 0.4503432512283325
Validation loss: 2.005354026953379

Epoch: 6| Step: 10
Training loss: 0.46588408946990967
Validation loss: 2.00023623307546

Epoch: 6| Step: 11
Training loss: 0.2628152668476105
Validation loss: 2.0259756445884705

Epoch: 6| Step: 12
Training loss: 0.32063883543014526
Validation loss: 1.9749138156572978

Epoch: 6| Step: 13
Training loss: 0.2432256042957306
Validation loss: 1.9700493415196736

Epoch: 313| Step: 0
Training loss: 0.2526373863220215
Validation loss: 1.9658225576082866

Epoch: 6| Step: 1
Training loss: 0.2296408712863922
Validation loss: 1.993401050567627

Epoch: 6| Step: 2
Training loss: 0.2741695046424866
Validation loss: 1.99410347143809

Epoch: 6| Step: 3
Training loss: 0.2582553029060364
Validation loss: 1.936638871828715

Epoch: 6| Step: 4
Training loss: 0.203515887260437
Validation loss: 2.001207113265991

Epoch: 6| Step: 5
Training loss: 0.7328720092773438
Validation loss: 2.0051724314689636

Epoch: 6| Step: 6
Training loss: 0.4392649829387665
Validation loss: 2.0094831784566245

Epoch: 6| Step: 7
Training loss: 0.49507570266723633
Validation loss: 1.992207447687785

Epoch: 6| Step: 8
Training loss: 0.48988473415374756
Validation loss: 1.9620229204495747

Epoch: 6| Step: 9
Training loss: 0.4634011685848236
Validation loss: 1.9585842092831929

Epoch: 6| Step: 10
Training loss: 0.27285802364349365
Validation loss: 1.958831548690796

Epoch: 6| Step: 11
Training loss: 0.3960992097854614
Validation loss: 1.9921865065892537

Epoch: 6| Step: 12
Training loss: 0.5268128514289856
Validation loss: 2.0230266451835632

Epoch: 6| Step: 13
Training loss: 0.301695317029953
Validation loss: 1.951563020547231

Epoch: 314| Step: 0
Training loss: 0.6819621324539185
Validation loss: 1.9998883803685505

Epoch: 6| Step: 1
Training loss: 0.2983439564704895
Validation loss: 2.00620170434316

Epoch: 6| Step: 2
Training loss: 0.29321062564849854
Validation loss: 2.0552108685175576

Epoch: 6| Step: 3
Training loss: 0.38428303599357605
Validation loss: 2.01993590593338

Epoch: 6| Step: 4
Training loss: 0.16313989460468292
Validation loss: 2.004968047142029

Epoch: 6| Step: 5
Training loss: 0.34760719537734985
Validation loss: 2.0091048081715903

Epoch: 6| Step: 6
Training loss: 0.477184921503067
Validation loss: 2.0321188966433206

Epoch: 6| Step: 7
Training loss: 0.37548553943634033
Validation loss: 2.0321778655052185

Epoch: 6| Step: 8
Training loss: 0.3079688549041748
Validation loss: 2.034308433532715

Epoch: 6| Step: 9
Training loss: 0.4940018057823181
Validation loss: 2.070502281188965

Epoch: 6| Step: 10
Training loss: 0.4204501807689667
Validation loss: 1.9861331383387248

Epoch: 6| Step: 11
Training loss: 0.4701257050037384
Validation loss: 1.984402020772298

Epoch: 6| Step: 12
Training loss: 0.4387650191783905
Validation loss: 2.027811328570048

Epoch: 6| Step: 13
Training loss: 0.2389020025730133
Validation loss: 1.9866774876912434

Epoch: 315| Step: 0
Training loss: 0.2390815168619156
Validation loss: 1.9518782297770183

Epoch: 6| Step: 1
Training loss: 0.19209259748458862
Validation loss: 1.975455363591512

Epoch: 6| Step: 2
Training loss: 0.5032179951667786
Validation loss: 2.0093029936154685

Epoch: 6| Step: 3
Training loss: 0.29212868213653564
Validation loss: 2.049465537071228

Epoch: 6| Step: 4
Training loss: 0.2864767014980316
Validation loss: 2.0511419971783957

Epoch: 6| Step: 5
Training loss: 0.19526109099388123
Validation loss: 2.0445117553075156

Epoch: 6| Step: 6
Training loss: 0.9173634648323059
Validation loss: 2.0067750016848245

Epoch: 6| Step: 7
Training loss: 0.390647828578949
Validation loss: 2.037520190080007

Epoch: 6| Step: 8
Training loss: 0.4629850387573242
Validation loss: 1.9851923783620198

Epoch: 6| Step: 9
Training loss: 0.21764135360717773
Validation loss: 2.0236070354779563

Epoch: 6| Step: 10
Training loss: 0.6081027984619141
Validation loss: 1.982343892256419

Epoch: 6| Step: 11
Training loss: 0.3634277582168579
Validation loss: 2.023278454939524

Epoch: 6| Step: 12
Training loss: 0.2201356589794159
Validation loss: 2.021142323811849

Epoch: 6| Step: 13
Training loss: 0.18315888941287994
Validation loss: 1.9910669922828674

Epoch: 316| Step: 0
Training loss: 0.21198537945747375
Validation loss: 2.0055640737215676

Epoch: 6| Step: 1
Training loss: 0.291842520236969
Validation loss: 1.9665176471074421

Epoch: 6| Step: 2
Training loss: 0.42610427737236023
Validation loss: 1.992310603459676

Epoch: 6| Step: 3
Training loss: 0.2261219024658203
Validation loss: 1.9856759905815125

Epoch: 6| Step: 4
Training loss: 0.21829771995544434
Validation loss: 1.9941129088401794

Epoch: 6| Step: 5
Training loss: 0.5231294631958008
Validation loss: 2.0012177427609763

Epoch: 6| Step: 6
Training loss: 0.6331909894943237
Validation loss: 2.0193389455477395

Epoch: 6| Step: 7
Training loss: 0.39495164155960083
Validation loss: 2.0471323331197104

Epoch: 6| Step: 8
Training loss: 0.32242533564567566
Validation loss: 2.0113481481870017

Epoch: 6| Step: 9
Training loss: 0.7094796895980835
Validation loss: 1.991605281829834

Epoch: 6| Step: 10
Training loss: 0.45760297775268555
Validation loss: 2.0232114593187966

Epoch: 6| Step: 11
Training loss: 0.46431469917297363
Validation loss: 1.9905537565549214

Epoch: 6| Step: 12
Training loss: 0.3315432667732239
Validation loss: 2.0199107925097146

Epoch: 6| Step: 13
Training loss: 0.2707030773162842
Validation loss: 1.9856393933296204

Epoch: 317| Step: 0
Training loss: 0.5600569844245911
Validation loss: 1.980054756005605

Epoch: 6| Step: 1
Training loss: 0.3416648507118225
Validation loss: 2.007992466290792

Epoch: 6| Step: 2
Training loss: 0.2528172731399536
Validation loss: 2.018226146697998

Epoch: 6| Step: 3
Training loss: 0.33930012583732605
Validation loss: 1.9895611604054768

Epoch: 6| Step: 4
Training loss: 0.25615373253822327
Validation loss: 2.0449105898539224

Epoch: 6| Step: 5
Training loss: 0.3089161515235901
Validation loss: 2.0174777706464133

Epoch: 6| Step: 6
Training loss: 0.30316320061683655
Validation loss: 1.9503632187843323

Epoch: 6| Step: 7
Training loss: 0.29576146602630615
Validation loss: 2.0406137108802795

Epoch: 6| Step: 8
Training loss: 0.28021955490112305
Validation loss: 2.0630475282669067

Epoch: 6| Step: 9
Training loss: 0.24812878668308258
Validation loss: 2.0387179056803384

Epoch: 6| Step: 10
Training loss: 0.26765599846839905
Validation loss: 2.0315167903900146

Epoch: 6| Step: 11
Training loss: 0.4365169405937195
Validation loss: 2.050165315469106

Epoch: 6| Step: 12
Training loss: 0.8895027041435242
Validation loss: 1.994035502274831

Epoch: 6| Step: 13
Training loss: 0.3773832321166992
Validation loss: 1.9712249437967937

Epoch: 318| Step: 0
Training loss: 0.4067651033401489
Validation loss: 2.0217626094818115

Epoch: 6| Step: 1
Training loss: 0.7758537530899048
Validation loss: 1.9958887100219727

Epoch: 6| Step: 2
Training loss: 0.19150346517562866
Validation loss: 2.0111136039098105

Epoch: 6| Step: 3
Training loss: 0.31948673725128174
Validation loss: 2.0321314930915833

Epoch: 6| Step: 4
Training loss: 0.39580830931663513
Validation loss: 1.9959568977355957

Epoch: 6| Step: 5
Training loss: 0.3993918001651764
Validation loss: 1.9971965551376343

Epoch: 6| Step: 6
Training loss: 0.3638198971748352
Validation loss: 1.9791027704874675

Epoch: 6| Step: 7
Training loss: 0.43514466285705566
Validation loss: 2.0374938249588013

Epoch: 6| Step: 8
Training loss: 0.2720319926738739
Validation loss: 2.001183867454529

Epoch: 6| Step: 9
Training loss: 0.2999469041824341
Validation loss: 2.0597352385520935

Epoch: 6| Step: 10
Training loss: 0.406959593296051
Validation loss: 1.9768502314885457

Epoch: 6| Step: 11
Training loss: 0.4684690535068512
Validation loss: 2.0387651920318604

Epoch: 6| Step: 12
Training loss: 0.24711427092552185
Validation loss: 1.9797255992889404

Epoch: 6| Step: 13
Training loss: 0.31580185890197754
Validation loss: 1.9511025945345561

Epoch: 319| Step: 0
Training loss: 0.4527043104171753
Validation loss: 1.971572458744049

Epoch: 6| Step: 1
Training loss: 0.6217763423919678
Validation loss: 2.0082967480023703

Epoch: 6| Step: 2
Training loss: 0.4630458354949951
Validation loss: 1.9731481671333313

Epoch: 6| Step: 3
Training loss: 0.7410128712654114
Validation loss: 1.9890224536259968

Epoch: 6| Step: 4
Training loss: 0.4383273422718048
Validation loss: 1.9846600492795308

Epoch: 6| Step: 5
Training loss: 0.34243375062942505
Validation loss: 2.017954965432485

Epoch: 6| Step: 6
Training loss: 0.3704008162021637
Validation loss: 1.9926639199256897

Epoch: 6| Step: 7
Training loss: 0.22697371244430542
Validation loss: 1.976927936077118

Epoch: 6| Step: 8
Training loss: 0.54940265417099
Validation loss: 1.9726622303326924

Epoch: 6| Step: 9
Training loss: 0.20974910259246826
Validation loss: 1.9825329979260762

Epoch: 6| Step: 10
Training loss: 0.2771112620830536
Validation loss: 2.0118501583735147

Epoch: 6| Step: 11
Training loss: 0.21551193296909332
Validation loss: 1.9671989281972249

Epoch: 6| Step: 12
Training loss: 0.23000653088092804
Validation loss: 1.9893719752629597

Epoch: 6| Step: 13
Training loss: 0.1998550146818161
Validation loss: 2.0117942293485007

Epoch: 320| Step: 0
Training loss: 0.2719816565513611
Validation loss: 1.9772863984107971

Epoch: 6| Step: 1
Training loss: 0.7110543847084045
Validation loss: 1.9585752487182617

Epoch: 6| Step: 2
Training loss: 0.5931492447853088
Validation loss: 2.004263003667196

Epoch: 6| Step: 3
Training loss: 0.2874920070171356
Validation loss: 2.001802901426951

Epoch: 6| Step: 4
Training loss: 0.22755245864391327
Validation loss: 2.010078807671865

Epoch: 6| Step: 5
Training loss: 0.43849557638168335
Validation loss: 2.002018173535665

Epoch: 6| Step: 6
Training loss: 0.5091368556022644
Validation loss: 2.018674651781718

Epoch: 6| Step: 7
Training loss: 0.7395485639572144
Validation loss: 2.0122717221577964

Epoch: 6| Step: 8
Training loss: 0.2433144599199295
Validation loss: 1.978036344051361

Epoch: 6| Step: 9
Training loss: 0.3133423924446106
Validation loss: 2.046733339627584

Epoch: 6| Step: 10
Training loss: 0.3294319808483124
Validation loss: 2.0084521969159446

Epoch: 6| Step: 11
Training loss: 0.2723004221916199
Validation loss: 1.95789631207784

Epoch: 6| Step: 12
Training loss: 0.22498682141304016
Validation loss: 2.0157456398010254

Epoch: 6| Step: 13
Training loss: 0.2531947195529938
Validation loss: 1.946056326230367

Epoch: 321| Step: 0
Training loss: 0.258342444896698
Validation loss: 2.020790974299113

Epoch: 6| Step: 1
Training loss: 0.4120252728462219
Validation loss: 1.975887417793274

Epoch: 6| Step: 2
Training loss: 0.3337176442146301
Validation loss: 1.9871700406074524

Epoch: 6| Step: 3
Training loss: 0.20740360021591187
Validation loss: 1.9816516041755676

Epoch: 6| Step: 4
Training loss: 0.2081720232963562
Validation loss: 1.9895752469698589

Epoch: 6| Step: 5
Training loss: 0.35933539271354675
Validation loss: 1.9838494261105855

Epoch: 6| Step: 6
Training loss: 0.2346564382314682
Validation loss: 1.974462588628133

Epoch: 6| Step: 7
Training loss: 0.33068299293518066
Validation loss: 2.005046010017395

Epoch: 6| Step: 8
Training loss: 0.26129579544067383
Validation loss: 1.9684423208236694

Epoch: 6| Step: 9
Training loss: 0.7450708746910095
Validation loss: 1.9835739930470784

Epoch: 6| Step: 10
Training loss: 0.4100289046764374
Validation loss: 1.9470426042874653

Epoch: 6| Step: 11
Training loss: 0.5391913652420044
Validation loss: 2.006966690222422

Epoch: 6| Step: 12
Training loss: 0.36954188346862793
Validation loss: 1.9764313300450642

Epoch: 6| Step: 13
Training loss: 0.9256567358970642
Validation loss: 1.97381458679835

Epoch: 322| Step: 0
Training loss: 0.29508161544799805
Validation loss: 1.9589586853981018

Epoch: 6| Step: 1
Training loss: 0.4146531820297241
Validation loss: 1.969081421693166

Epoch: 6| Step: 2
Training loss: 0.21502891182899475
Validation loss: 1.9512638648351033

Epoch: 6| Step: 3
Training loss: 0.33013051748275757
Validation loss: 1.9637009302775066

Epoch: 6| Step: 4
Training loss: 0.4724791944026947
Validation loss: 2.0026248693466187

Epoch: 6| Step: 5
Training loss: 0.1950959861278534
Validation loss: 1.9765546520551045

Epoch: 6| Step: 6
Training loss: 0.5250119566917419
Validation loss: 2.0244675477345786

Epoch: 6| Step: 7
Training loss: 0.2348892092704773
Validation loss: 1.9755212664604187

Epoch: 6| Step: 8
Training loss: 0.3938252329826355
Validation loss: 2.0156855980555215

Epoch: 6| Step: 9
Training loss: 0.5056512951850891
Validation loss: 2.0239338874816895

Epoch: 6| Step: 10
Training loss: 0.763225257396698
Validation loss: 2.0017118056615195

Epoch: 6| Step: 11
Training loss: 0.25914520025253296
Validation loss: 1.986546774705251

Epoch: 6| Step: 12
Training loss: 0.4854995310306549
Validation loss: 1.994642714659373

Epoch: 6| Step: 13
Training loss: 0.29430413246154785
Validation loss: 1.954233964284261

Epoch: 323| Step: 0
Training loss: 0.3991296887397766
Validation loss: 2.0078560511271157

Epoch: 6| Step: 1
Training loss: 0.20581093430519104
Validation loss: 1.9914500713348389

Epoch: 6| Step: 2
Training loss: 0.5675477385520935
Validation loss: 2.02413676182429

Epoch: 6| Step: 3
Training loss: 0.414060115814209
Validation loss: 1.9858805139859517

Epoch: 6| Step: 4
Training loss: 0.2421082705259323
Validation loss: 1.966977834701538

Epoch: 6| Step: 5
Training loss: 0.30984634160995483
Validation loss: 1.973138689994812

Epoch: 6| Step: 6
Training loss: 0.2881796360015869
Validation loss: 1.9881462057431538

Epoch: 6| Step: 7
Training loss: 0.2842407822608948
Validation loss: 2.002299169699351

Epoch: 6| Step: 8
Training loss: 0.6133813858032227
Validation loss: 2.020563860734304

Epoch: 6| Step: 9
Training loss: 0.22613434493541718
Validation loss: 1.9675761858622234

Epoch: 6| Step: 10
Training loss: 0.6986490488052368
Validation loss: 2.0084696412086487

Epoch: 6| Step: 11
Training loss: 0.2586436867713928
Validation loss: 1.998016079266866

Epoch: 6| Step: 12
Training loss: 0.2654988765716553
Validation loss: 1.992997666200002

Epoch: 6| Step: 13
Training loss: 0.3138095736503601
Validation loss: 2.012207567691803

Epoch: 324| Step: 0
Training loss: 0.398318350315094
Validation loss: 2.021711806456248

Epoch: 6| Step: 1
Training loss: 0.23280802369117737
Validation loss: 2.0307042996088662

Epoch: 6| Step: 2
Training loss: 0.3606927990913391
Validation loss: 1.976893921693166

Epoch: 6| Step: 3
Training loss: 0.3902862071990967
Validation loss: 1.9840965072313945

Epoch: 6| Step: 4
Training loss: 0.3891463875770569
Validation loss: 1.9880943695704143

Epoch: 6| Step: 5
Training loss: 0.22367073595523834
Validation loss: 1.959256152311961

Epoch: 6| Step: 6
Training loss: 0.3430149257183075
Validation loss: 2.0012972950935364

Epoch: 6| Step: 7
Training loss: 0.4807080030441284
Validation loss: 1.9747392137845357

Epoch: 6| Step: 8
Training loss: 0.3379583954811096
Validation loss: 1.9676440159479778

Epoch: 6| Step: 9
Training loss: 0.4078890085220337
Validation loss: 1.9795299371083577

Epoch: 6| Step: 10
Training loss: 0.5995803475379944
Validation loss: 2.0127989053726196

Epoch: 6| Step: 11
Training loss: 0.24543601274490356
Validation loss: 1.9780431588490803

Epoch: 6| Step: 12
Training loss: 0.6084692478179932
Validation loss: 2.0143865744272866

Epoch: 6| Step: 13
Training loss: 0.6808785796165466
Validation loss: 2.020700693130493

Epoch: 325| Step: 0
Training loss: 0.45898598432540894
Validation loss: 2.056333839893341

Epoch: 6| Step: 1
Training loss: 0.7302267551422119
Validation loss: 2.028362214565277

Epoch: 6| Step: 2
Training loss: 0.48724910616874695
Validation loss: 2.0466153621673584

Epoch: 6| Step: 3
Training loss: 0.5039839744567871
Validation loss: 2.052606920401255

Epoch: 6| Step: 4
Training loss: 0.5696691274642944
Validation loss: 1.9782752792040508

Epoch: 6| Step: 5
Training loss: 0.28805944323539734
Validation loss: 2.0401991804440818

Epoch: 6| Step: 6
Training loss: 0.3224732279777527
Validation loss: 2.0428109963734946

Epoch: 6| Step: 7
Training loss: 0.30497705936431885
Validation loss: 2.0350077152252197

Epoch: 6| Step: 8
Training loss: 0.29014578461647034
Validation loss: 2.0024065176645913

Epoch: 6| Step: 9
Training loss: 0.5385347604751587
Validation loss: 2.0525588393211365

Epoch: 6| Step: 10
Training loss: 0.3011886477470398
Validation loss: 2.0005295077959695

Epoch: 6| Step: 11
Training loss: 0.3332381546497345
Validation loss: 2.020398656527201

Epoch: 6| Step: 12
Training loss: 0.3311268389225006
Validation loss: 2.0131465593973794

Epoch: 6| Step: 13
Training loss: 0.27230820059776306
Validation loss: 2.030443569024404

Epoch: 326| Step: 0
Training loss: 0.42756733298301697
Validation loss: 2.01807169119517

Epoch: 6| Step: 1
Training loss: 0.2530445158481598
Validation loss: 1.9706624348958333

Epoch: 6| Step: 2
Training loss: 0.32583853602409363
Validation loss: 1.9998457034428914

Epoch: 6| Step: 3
Training loss: 0.6095872521400452
Validation loss: 2.041661500930786

Epoch: 6| Step: 4
Training loss: 0.49178171157836914
Validation loss: 2.025368611017863

Epoch: 6| Step: 5
Training loss: 0.3534640669822693
Validation loss: 2.044103503227234

Epoch: 6| Step: 6
Training loss: 0.22522784769535065
Validation loss: 2.1052988370259604

Epoch: 6| Step: 7
Training loss: 0.7114588022232056
Validation loss: 2.042397975921631

Epoch: 6| Step: 8
Training loss: 0.6092760562896729
Validation loss: 1.9523986180623372

Epoch: 6| Step: 9
Training loss: 0.331601619720459
Validation loss: 2.008603016535441

Epoch: 6| Step: 10
Training loss: 0.25536686182022095
Validation loss: 1.9931796590487163

Epoch: 6| Step: 11
Training loss: 0.24431981146335602
Validation loss: 2.006083607673645

Epoch: 6| Step: 12
Training loss: 0.31090855598449707
Validation loss: 2.043083687623342

Epoch: 6| Step: 13
Training loss: 0.5380265712738037
Validation loss: 1.9973986744880676

Epoch: 327| Step: 0
Training loss: 0.22831422090530396
Validation loss: 2.0151211619377136

Epoch: 6| Step: 1
Training loss: 0.3050118684768677
Validation loss: 2.0516295631726584

Epoch: 6| Step: 2
Training loss: 0.3221909701824188
Validation loss: 2.044150948524475

Epoch: 6| Step: 3
Training loss: 0.2856746315956116
Validation loss: 2.0081292589505515

Epoch: 6| Step: 4
Training loss: 0.7602015733718872
Validation loss: 2.0171882708867392

Epoch: 6| Step: 5
Training loss: 0.5236436724662781
Validation loss: 2.0428057312965393

Epoch: 6| Step: 6
Training loss: 0.32477277517318726
Validation loss: 2.0593040386835733

Epoch: 6| Step: 7
Training loss: 0.21153175830841064
Validation loss: 2.0096484820048013

Epoch: 6| Step: 8
Training loss: 0.2587352991104126
Validation loss: 2.016445795694987

Epoch: 6| Step: 9
Training loss: 0.4442715048789978
Validation loss: 1.990481396516164

Epoch: 6| Step: 10
Training loss: 0.5023942589759827
Validation loss: 2.0203272700309753

Epoch: 6| Step: 11
Training loss: 0.2870551347732544
Validation loss: 1.9743361075719197

Epoch: 6| Step: 12
Training loss: 0.5276592373847961
Validation loss: 1.9897143443425496

Epoch: 6| Step: 13
Training loss: 0.23982718586921692
Validation loss: 1.984513024489085

Epoch: 328| Step: 0
Training loss: 0.26618796586990356
Validation loss: 1.986945648988088

Epoch: 6| Step: 1
Training loss: 0.1904384046792984
Validation loss: 2.0253313779830933

Epoch: 6| Step: 2
Training loss: 0.7928547859191895
Validation loss: 2.0168976187705994

Epoch: 6| Step: 3
Training loss: 0.30752062797546387
Validation loss: 2.033169706662496

Epoch: 6| Step: 4
Training loss: 0.527366578578949
Validation loss: 2.0289549032847085

Epoch: 6| Step: 5
Training loss: 0.3041410446166992
Validation loss: 2.0215569337209067

Epoch: 6| Step: 6
Training loss: 0.3466264307498932
Validation loss: 1.9932844241460164

Epoch: 6| Step: 7
Training loss: 0.381709486246109
Validation loss: 2.0032458106676736

Epoch: 6| Step: 8
Training loss: 0.211607426404953
Validation loss: 2.0056594212849936

Epoch: 6| Step: 9
Training loss: 0.403716117143631
Validation loss: 2.0093090335528054

Epoch: 6| Step: 10
Training loss: 0.29667481780052185
Validation loss: 2.041990260283152

Epoch: 6| Step: 11
Training loss: 0.18005633354187012
Validation loss: 1.9953560034434001

Epoch: 6| Step: 12
Training loss: 0.34926095604896545
Validation loss: 2.006292740503947

Epoch: 6| Step: 13
Training loss: 0.315595418214798
Validation loss: 2.0120014746983848

Epoch: 329| Step: 0
Training loss: 0.3536406457424164
Validation loss: 2.001307805379232

Epoch: 6| Step: 1
Training loss: 0.31790947914123535
Validation loss: 2.0283700029055276

Epoch: 6| Step: 2
Training loss: 0.5866935849189758
Validation loss: 2.048949360847473

Epoch: 6| Step: 3
Training loss: 0.29629892110824585
Validation loss: 1.9820131659507751

Epoch: 6| Step: 4
Training loss: 0.41682571172714233
Validation loss: 1.9944162766138713

Epoch: 6| Step: 5
Training loss: 0.5626473426818848
Validation loss: 2.032961626847585

Epoch: 6| Step: 6
Training loss: 0.17282447218894958
Validation loss: 2.032699485619863

Epoch: 6| Step: 7
Training loss: 0.23466609418392181
Validation loss: 2.020861585934957

Epoch: 6| Step: 8
Training loss: 0.22415344417095184
Validation loss: 1.982231597105662

Epoch: 6| Step: 9
Training loss: 0.4847278892993927
Validation loss: 2.012188891569773

Epoch: 6| Step: 10
Training loss: 0.5924776792526245
Validation loss: 2.0054713090260825

Epoch: 6| Step: 11
Training loss: 0.35629037022590637
Validation loss: 2.015559653441111

Epoch: 6| Step: 12
Training loss: 0.2724687457084656
Validation loss: 2.0435009797414145

Epoch: 6| Step: 13
Training loss: 0.36151230335235596
Validation loss: 2.016432503859202

Epoch: 330| Step: 0
Training loss: 0.40659695863723755
Validation loss: 2.010594050089518

Epoch: 6| Step: 1
Training loss: 0.6128779649734497
Validation loss: 2.014468550682068

Epoch: 6| Step: 2
Training loss: 0.32161059975624084
Validation loss: 1.983569343884786

Epoch: 6| Step: 3
Training loss: 0.6006063222885132
Validation loss: 1.9959064523379009

Epoch: 6| Step: 4
Training loss: 0.39984461665153503
Validation loss: 1.9908785621325176

Epoch: 6| Step: 5
Training loss: 0.2676926553249359
Validation loss: 2.0249918500582376

Epoch: 6| Step: 6
Training loss: 0.30168354511260986
Validation loss: 2.003903349240621

Epoch: 6| Step: 7
Training loss: 0.4321492314338684
Validation loss: 1.9556700189908345

Epoch: 6| Step: 8
Training loss: 0.6051428318023682
Validation loss: 1.9901788433392842

Epoch: 6| Step: 9
Training loss: 0.37771159410476685
Validation loss: 2.012801229953766

Epoch: 6| Step: 10
Training loss: 0.32194745540618896
Validation loss: 2.0233280857404075

Epoch: 6| Step: 11
Training loss: 0.20277723670005798
Validation loss: 1.9783846139907837

Epoch: 6| Step: 12
Training loss: 0.22309355437755585
Validation loss: 1.99401060740153

Epoch: 6| Step: 13
Training loss: 0.1765255481004715
Validation loss: 2.005251467227936

Epoch: 331| Step: 0
Training loss: 0.6184189915657043
Validation loss: 1.9446743528048198

Epoch: 6| Step: 1
Training loss: 0.33366912603378296
Validation loss: 2.0161137779553733

Epoch: 6| Step: 2
Training loss: 0.5289619565010071
Validation loss: 1.9645268718401592

Epoch: 6| Step: 3
Training loss: 0.3402310013771057
Validation loss: 2.035569111506144

Epoch: 6| Step: 4
Training loss: 0.46860653162002563
Validation loss: 1.9963702360788982

Epoch: 6| Step: 5
Training loss: 0.28060460090637207
Validation loss: 1.9802368382612865

Epoch: 6| Step: 6
Training loss: 0.2328481674194336
Validation loss: 1.9999323884646099

Epoch: 6| Step: 7
Training loss: 0.1932167410850525
Validation loss: 2.0320301055908203

Epoch: 6| Step: 8
Training loss: 0.3518105149269104
Validation loss: 2.0590908328692117

Epoch: 6| Step: 9
Training loss: 0.27821820974349976
Validation loss: 1.980431854724884

Epoch: 6| Step: 10
Training loss: 0.41252368688583374
Validation loss: 2.0015034675598145

Epoch: 6| Step: 11
Training loss: 0.21331018209457397
Validation loss: 1.9605060815811157

Epoch: 6| Step: 12
Training loss: 0.26317718625068665
Validation loss: 1.968356152375539

Epoch: 6| Step: 13
Training loss: 0.4856424331665039
Validation loss: 2.0261765917142234

Epoch: 332| Step: 0
Training loss: 0.46152886748313904
Validation loss: 2.0326905051867166

Epoch: 6| Step: 1
Training loss: 0.18854081630706787
Validation loss: 2.009600361188253

Epoch: 6| Step: 2
Training loss: 0.21557235717773438
Validation loss: 1.9549137751261394

Epoch: 6| Step: 3
Training loss: 0.41830503940582275
Validation loss: 2.0152583916982016

Epoch: 6| Step: 4
Training loss: 0.6507437825202942
Validation loss: 1.96549787123998

Epoch: 6| Step: 5
Training loss: 0.2928777039051056
Validation loss: 2.041061520576477

Epoch: 6| Step: 6
Training loss: 0.30999699234962463
Validation loss: 2.0475531419118247

Epoch: 6| Step: 7
Training loss: 0.37908023595809937
Validation loss: 1.9967573881149292

Epoch: 6| Step: 8
Training loss: 0.27781355381011963
Validation loss: 2.0155102411905923

Epoch: 6| Step: 9
Training loss: 0.3962624669075012
Validation loss: 1.9627503355344136

Epoch: 6| Step: 10
Training loss: 0.19028863310813904
Validation loss: 1.968960702419281

Epoch: 6| Step: 11
Training loss: 0.29526305198669434
Validation loss: 1.9829390247662861

Epoch: 6| Step: 12
Training loss: 0.41672131419181824
Validation loss: 2.019969125588735

Epoch: 6| Step: 13
Training loss: 0.798219621181488
Validation loss: 1.9969451030095418

Epoch: 333| Step: 0
Training loss: 0.5888998508453369
Validation loss: 1.9748763640721638

Epoch: 6| Step: 1
Training loss: 0.2939321994781494
Validation loss: 1.9995531638463337

Epoch: 6| Step: 2
Training loss: 0.42989581823349
Validation loss: 2.010256052017212

Epoch: 6| Step: 3
Training loss: 0.3076085150241852
Validation loss: 2.0235401590665183

Epoch: 6| Step: 4
Training loss: 0.31223106384277344
Validation loss: 1.9854576190312703

Epoch: 6| Step: 5
Training loss: 0.42864570021629333
Validation loss: 1.977807919184367

Epoch: 6| Step: 6
Training loss: 0.3496468663215637
Validation loss: 2.000217159589132

Epoch: 6| Step: 7
Training loss: 0.3119135797023773
Validation loss: 2.0288641452789307

Epoch: 6| Step: 8
Training loss: 0.2731093168258667
Validation loss: 1.9770451386769612

Epoch: 6| Step: 9
Training loss: 0.27500858902931213
Validation loss: 2.0332076152165732

Epoch: 6| Step: 10
Training loss: 0.2532728910446167
Validation loss: 2.0185686349868774

Epoch: 6| Step: 11
Training loss: 0.5293996930122375
Validation loss: 1.9770577947298686

Epoch: 6| Step: 12
Training loss: 0.33137455582618713
Validation loss: 2.065941651662191

Epoch: 6| Step: 13
Training loss: 0.6415596008300781
Validation loss: 1.965531011422475

Epoch: 334| Step: 0
Training loss: 0.24822913110256195
Validation loss: 2.0599684516588845

Epoch: 6| Step: 1
Training loss: 0.3089175820350647
Validation loss: 1.9978371461232503

Epoch: 6| Step: 2
Training loss: 0.3533429801464081
Validation loss: 2.0224547187487283

Epoch: 6| Step: 3
Training loss: 0.35089731216430664
Validation loss: 2.023950695991516

Epoch: 6| Step: 4
Training loss: 0.4741940498352051
Validation loss: 2.0227392514546714

Epoch: 6| Step: 5
Training loss: 0.16082614660263062
Validation loss: 2.024191935857137

Epoch: 6| Step: 6
Training loss: 0.3084036707878113
Validation loss: 2.040726681550344

Epoch: 6| Step: 7
Training loss: 0.8730872869491577
Validation loss: 2.045299847920736

Epoch: 6| Step: 8
Training loss: 0.4369259774684906
Validation loss: 2.0458971659342446

Epoch: 6| Step: 9
Training loss: 0.68205326795578
Validation loss: 2.07663502295812

Epoch: 6| Step: 10
Training loss: 0.40034544467926025
Validation loss: 2.0171789129575095

Epoch: 6| Step: 11
Training loss: 0.5166527628898621
Validation loss: 2.021845042705536

Epoch: 6| Step: 12
Training loss: 0.4534701108932495
Validation loss: 2.034548024336497

Epoch: 6| Step: 13
Training loss: 0.5255581140518188
Validation loss: 2.0085315505663552

Epoch: 335| Step: 0
Training loss: 0.41037631034851074
Validation loss: 2.0404259165128074

Epoch: 6| Step: 1
Training loss: 0.36429718136787415
Validation loss: 1.9936307271321614

Epoch: 6| Step: 2
Training loss: 0.3038348853588104
Validation loss: 2.0611839493115744

Epoch: 6| Step: 3
Training loss: 0.4499938488006592
Validation loss: 2.0311816930770874

Epoch: 6| Step: 4
Training loss: 0.28373318910598755
Validation loss: 1.9878073732058208

Epoch: 6| Step: 5
Training loss: 0.613412082195282
Validation loss: 2.0040390491485596

Epoch: 6| Step: 6
Training loss: 0.28823322057724
Validation loss: 2.005616307258606

Epoch: 6| Step: 7
Training loss: 0.376703143119812
Validation loss: 2.012675642967224

Epoch: 6| Step: 8
Training loss: 0.3748937249183655
Validation loss: 2.024181584517161

Epoch: 6| Step: 9
Training loss: 0.4481622874736786
Validation loss: 2.017501791318258

Epoch: 6| Step: 10
Training loss: 0.4601016044616699
Validation loss: 1.9689894318580627

Epoch: 6| Step: 11
Training loss: 0.5006558895111084
Validation loss: 1.9929207762082417

Epoch: 6| Step: 12
Training loss: 0.38410621881484985
Validation loss: 2.036147872606913

Epoch: 6| Step: 13
Training loss: 0.1779196560382843
Validation loss: 2.0204100410143533

Epoch: 336| Step: 0
Training loss: 0.4709639251232147
Validation loss: 2.0339963833491006

Epoch: 6| Step: 1
Training loss: 0.17755669355392456
Validation loss: 1.9706953366597493

Epoch: 6| Step: 2
Training loss: 0.29214054346084595
Validation loss: 1.9861783186594646

Epoch: 6| Step: 3
Training loss: 0.30938297510147095
Validation loss: 2.0063933730125427

Epoch: 6| Step: 4
Training loss: 0.4696223735809326
Validation loss: 1.9827256600062053

Epoch: 6| Step: 5
Training loss: 0.46086183190345764
Validation loss: 1.9953818519910176

Epoch: 6| Step: 6
Training loss: 0.4370012581348419
Validation loss: 2.0113773147265115

Epoch: 6| Step: 7
Training loss: 0.2269708216190338
Validation loss: 2.0024085442225137

Epoch: 6| Step: 8
Training loss: 0.2101859301328659
Validation loss: 1.976139505704244

Epoch: 6| Step: 9
Training loss: 0.45803117752075195
Validation loss: 1.9878002603848774

Epoch: 6| Step: 10
Training loss: 0.7785055637359619
Validation loss: 1.9846412936846416

Epoch: 6| Step: 11
Training loss: 0.44304725527763367
Validation loss: 2.04362024863561

Epoch: 6| Step: 12
Training loss: 0.45633018016815186
Validation loss: 1.995310366153717

Epoch: 6| Step: 13
Training loss: 0.4424102306365967
Validation loss: 2.018860101699829

Epoch: 337| Step: 0
Training loss: 0.49911558628082275
Validation loss: 2.008979062239329

Epoch: 6| Step: 1
Training loss: 0.2724226117134094
Validation loss: 2.011143207550049

Epoch: 6| Step: 2
Training loss: 0.45021533966064453
Validation loss: 2.0295925537745156

Epoch: 6| Step: 3
Training loss: 0.36155956983566284
Validation loss: 2.021813710530599

Epoch: 6| Step: 4
Training loss: 0.31092312932014465
Validation loss: 2.070004085699717

Epoch: 6| Step: 5
Training loss: 0.4049624800682068
Validation loss: 1.9689716498057048

Epoch: 6| Step: 6
Training loss: 0.3671957850456238
Validation loss: 2.0320644974708557

Epoch: 6| Step: 7
Training loss: 0.5228122472763062
Validation loss: 2.019105911254883

Epoch: 6| Step: 8
Training loss: 0.23848402500152588
Validation loss: 2.0079930226008096

Epoch: 6| Step: 9
Training loss: 0.29447776079177856
Validation loss: 1.9821810324986775

Epoch: 6| Step: 10
Training loss: 0.3626166880130768
Validation loss: 2.0055893063545227

Epoch: 6| Step: 11
Training loss: 0.32017412781715393
Validation loss: 1.9960847695668538

Epoch: 6| Step: 12
Training loss: 0.7078921794891357
Validation loss: 1.997824231783549

Epoch: 6| Step: 13
Training loss: 0.2530551552772522
Validation loss: 2.0011298060417175

Epoch: 338| Step: 0
Training loss: 0.8144577741622925
Validation loss: 2.006767193476359

Epoch: 6| Step: 1
Training loss: 0.16888593137264252
Validation loss: 2.0503424406051636

Epoch: 6| Step: 2
Training loss: 0.3093697428703308
Validation loss: 2.00231142838796

Epoch: 6| Step: 3
Training loss: 0.17898401618003845
Validation loss: 1.9756290117899578

Epoch: 6| Step: 4
Training loss: 0.6015442609786987
Validation loss: 2.006883422533671

Epoch: 6| Step: 5
Training loss: 0.3254571557044983
Validation loss: 2.0343332489331565

Epoch: 6| Step: 6
Training loss: 0.37344908714294434
Validation loss: 1.9844911495844524

Epoch: 6| Step: 7
Training loss: 0.26487237215042114
Validation loss: 2.021657347679138

Epoch: 6| Step: 8
Training loss: 0.34229233860969543
Validation loss: 2.0074268579483032

Epoch: 6| Step: 9
Training loss: 0.23941874504089355
Validation loss: 2.0152170856793723

Epoch: 6| Step: 10
Training loss: 0.38164544105529785
Validation loss: 2.0026928583780923

Epoch: 6| Step: 11
Training loss: 0.4098700284957886
Validation loss: 1.9914872447649639

Epoch: 6| Step: 12
Training loss: 0.4241447150707245
Validation loss: 2.0362902681032815

Epoch: 6| Step: 13
Training loss: 0.3666554093360901
Validation loss: 2.054508606592814

Epoch: 339| Step: 0
Training loss: 0.16310210525989532
Validation loss: 2.037656585375468

Epoch: 6| Step: 1
Training loss: 0.33076733350753784
Validation loss: 2.0248865286509194

Epoch: 6| Step: 2
Training loss: 0.4231654405593872
Validation loss: 1.9946765899658203

Epoch: 6| Step: 3
Training loss: 0.45500749349594116
Validation loss: 2.022823909918467

Epoch: 6| Step: 4
Training loss: 0.4969593286514282
Validation loss: 1.9715606371561687

Epoch: 6| Step: 5
Training loss: 0.16984522342681885
Validation loss: 1.970633864402771

Epoch: 6| Step: 6
Training loss: 0.25605589151382446
Validation loss: 2.0149135986963906

Epoch: 6| Step: 7
Training loss: 0.3029310405254364
Validation loss: 2.0086352229118347

Epoch: 6| Step: 8
Training loss: 0.7546308636665344
Validation loss: 2.0331416726112366

Epoch: 6| Step: 9
Training loss: 0.4132254123687744
Validation loss: 2.0397265553474426

Epoch: 6| Step: 10
Training loss: 0.569734513759613
Validation loss: 2.035719414552053

Epoch: 6| Step: 11
Training loss: 0.21809400618076324
Validation loss: 2.0510350267092385

Epoch: 6| Step: 12
Training loss: 0.2274794727563858
Validation loss: 2.008861800034841

Epoch: 6| Step: 13
Training loss: 0.4238063097000122
Validation loss: 1.9964284300804138

Epoch: 340| Step: 0
Training loss: 0.3991559147834778
Validation loss: 2.026653786500295

Epoch: 6| Step: 1
Training loss: 0.2957717776298523
Validation loss: 2.0049038926760354

Epoch: 6| Step: 2
Training loss: 0.2097301483154297
Validation loss: 2.0220796863238015

Epoch: 6| Step: 3
Training loss: 0.401591420173645
Validation loss: 2.016145129998525

Epoch: 6| Step: 4
Training loss: 0.3716898560523987
Validation loss: 2.013671875

Epoch: 6| Step: 5
Training loss: 0.3812514543533325
Validation loss: 1.9926501115163167

Epoch: 6| Step: 6
Training loss: 0.5059319138526917
Validation loss: 2.0325849254926047

Epoch: 6| Step: 7
Training loss: 0.33752354979515076
Validation loss: 2.0108984311421714

Epoch: 6| Step: 8
Training loss: 0.3949849307537079
Validation loss: 2.0123841563860574

Epoch: 6| Step: 9
Training loss: 0.290940523147583
Validation loss: 2.036643087863922

Epoch: 6| Step: 10
Training loss: 0.6394423246383667
Validation loss: 1.9800714254379272

Epoch: 6| Step: 11
Training loss: 0.31120872497558594
Validation loss: 2.0282529989878335

Epoch: 6| Step: 12
Training loss: 0.3242952823638916
Validation loss: 2.031110465526581

Epoch: 6| Step: 13
Training loss: 0.4954279661178589
Validation loss: 2.01823498805364

Epoch: 341| Step: 0
Training loss: 0.3073061406612396
Validation loss: 2.0108622113863626

Epoch: 6| Step: 1
Training loss: 0.23813414573669434
Validation loss: 2.0015501777331033

Epoch: 6| Step: 2
Training loss: 0.2871956527233124
Validation loss: 2.029779930909475

Epoch: 6| Step: 3
Training loss: 0.24119415879249573
Validation loss: 2.018015364805857

Epoch: 6| Step: 4
Training loss: 0.9568774700164795
Validation loss: 2.0349485675493875

Epoch: 6| Step: 5
Training loss: 0.4695817828178406
Validation loss: 2.0348209142684937

Epoch: 6| Step: 6
Training loss: 0.2825867533683777
Validation loss: 2.024890919526418

Epoch: 6| Step: 7
Training loss: 0.23272766172885895
Validation loss: 1.989757279555003

Epoch: 6| Step: 8
Training loss: 0.4538743197917938
Validation loss: 2.0071259339650473

Epoch: 6| Step: 9
Training loss: 0.30163806676864624
Validation loss: 1.9534873167673747

Epoch: 6| Step: 10
Training loss: 0.3143501281738281
Validation loss: 2.013417661190033

Epoch: 6| Step: 11
Training loss: 0.4723310172557831
Validation loss: 2.007940649986267

Epoch: 6| Step: 12
Training loss: 0.25913044810295105
Validation loss: 2.033920725186666

Epoch: 6| Step: 13
Training loss: 0.41595157980918884
Validation loss: 2.0174124042193093

Epoch: 342| Step: 0
Training loss: 0.19579744338989258
Validation loss: 2.011630634466807

Epoch: 6| Step: 1
Training loss: 0.34605902433395386
Validation loss: 1.9642253319422405

Epoch: 6| Step: 2
Training loss: 0.2830195724964142
Validation loss: 2.0127369165420532

Epoch: 6| Step: 3
Training loss: 0.27423274517059326
Validation loss: 2.0016058484713235

Epoch: 6| Step: 4
Training loss: 0.22203543782234192
Validation loss: 2.0049277941385903

Epoch: 6| Step: 5
Training loss: 0.5428268909454346
Validation loss: 2.001003384590149

Epoch: 6| Step: 6
Training loss: 0.2744271457195282
Validation loss: 2.011037051677704

Epoch: 6| Step: 7
Training loss: 0.25127559900283813
Validation loss: 1.9643463492393494

Epoch: 6| Step: 8
Training loss: 0.44112056493759155
Validation loss: 2.015539507071177

Epoch: 6| Step: 9
Training loss: 0.5934692621231079
Validation loss: 2.006925423940023

Epoch: 6| Step: 10
Training loss: 0.6285318732261658
Validation loss: 1.9688337842623393

Epoch: 6| Step: 11
Training loss: 0.2824400067329407
Validation loss: 2.0215939482053122

Epoch: 6| Step: 12
Training loss: 0.2597027122974396
Validation loss: 2.0425973733266196

Epoch: 6| Step: 13
Training loss: 0.3185245096683502
Validation loss: 2.085596024990082

Epoch: 343| Step: 0
Training loss: 0.2800995707511902
Validation loss: 1.9871291518211365

Epoch: 6| Step: 1
Training loss: 0.5244348049163818
Validation loss: 2.006764074166616

Epoch: 6| Step: 2
Training loss: 0.2786693274974823
Validation loss: 2.0329830845197043

Epoch: 6| Step: 3
Training loss: 0.30907392501831055
Validation loss: 2.0179653565088906

Epoch: 6| Step: 4
Training loss: 0.34804701805114746
Validation loss: 2.0215607484181723

Epoch: 6| Step: 5
Training loss: 0.28560328483581543
Validation loss: 2.0177329381306968

Epoch: 6| Step: 6
Training loss: 0.15843522548675537
Validation loss: 1.9599808255831401

Epoch: 6| Step: 7
Training loss: 0.6439141631126404
Validation loss: 2.054900328318278

Epoch: 6| Step: 8
Training loss: 0.37678828835487366
Validation loss: 1.9745025237401326

Epoch: 6| Step: 9
Training loss: 0.33388063311576843
Validation loss: 2.007140636444092

Epoch: 6| Step: 10
Training loss: 0.38135823607444763
Validation loss: 2.013733367125193

Epoch: 6| Step: 11
Training loss: 0.33142969012260437
Validation loss: 2.024515668551127

Epoch: 6| Step: 12
Training loss: 0.2147940844297409
Validation loss: 2.02840393781662

Epoch: 6| Step: 13
Training loss: 0.41643810272216797
Validation loss: 2.0622819860776267

Epoch: 344| Step: 0
Training loss: 0.1839783489704132
Validation loss: 2.027920444806417

Epoch: 6| Step: 1
Training loss: 0.2519996166229248
Validation loss: 2.013681968053182

Epoch: 6| Step: 2
Training loss: 0.3828679919242859
Validation loss: 2.0007121562957764

Epoch: 6| Step: 3
Training loss: 0.33946168422698975
Validation loss: 2.0396975676218667

Epoch: 6| Step: 4
Training loss: 0.4704415202140808
Validation loss: 2.0078935623168945

Epoch: 6| Step: 5
Training loss: 0.5716860294342041
Validation loss: 1.9797254999478657

Epoch: 6| Step: 6
Training loss: 0.33262842893600464
Validation loss: 2.0204050739606223

Epoch: 6| Step: 7
Training loss: 0.3365655243396759
Validation loss: 2.013436257839203

Epoch: 6| Step: 8
Training loss: 0.27508044242858887
Validation loss: 1.9738519589106243

Epoch: 6| Step: 9
Training loss: 0.5811276435852051
Validation loss: 1.978544016679128

Epoch: 6| Step: 10
Training loss: 0.3270849585533142
Validation loss: 1.9784391522407532

Epoch: 6| Step: 11
Training loss: 0.3722880482673645
Validation loss: 2.0307204524676004

Epoch: 6| Step: 12
Training loss: 0.21899887919425964
Validation loss: 1.9784412582715352

Epoch: 6| Step: 13
Training loss: 0.24822959303855896
Validation loss: 2.0716558694839478

Epoch: 345| Step: 0
Training loss: 0.6647822260856628
Validation loss: 2.028495967388153

Epoch: 6| Step: 1
Training loss: 0.17320871353149414
Validation loss: 2.0098506609598794

Epoch: 6| Step: 2
Training loss: 0.2833032011985779
Validation loss: 2.0137940645217896

Epoch: 6| Step: 3
Training loss: 0.48067009449005127
Validation loss: 2.0206539233525596

Epoch: 6| Step: 4
Training loss: 0.31943172216415405
Validation loss: 2.029494603474935

Epoch: 6| Step: 5
Training loss: 0.1629427671432495
Validation loss: 1.9901321927706401

Epoch: 6| Step: 6
Training loss: 0.2205195277929306
Validation loss: 2.017738958199819

Epoch: 6| Step: 7
Training loss: 0.662851095199585
Validation loss: 2.008034427960714

Epoch: 6| Step: 8
Training loss: 0.4694225788116455
Validation loss: 2.0052099029223123

Epoch: 6| Step: 9
Training loss: 0.2676648795604706
Validation loss: 2.0475676457087197

Epoch: 6| Step: 10
Training loss: 0.22111862897872925
Validation loss: 2.022426942984263

Epoch: 6| Step: 11
Training loss: 0.6248689293861389
Validation loss: 2.055170993010203

Epoch: 6| Step: 12
Training loss: 0.2345401793718338
Validation loss: 2.0003664096196494

Epoch: 6| Step: 13
Training loss: 0.30775249004364014
Validation loss: 2.03170112768809

Epoch: 346| Step: 0
Training loss: 0.4585370421409607
Validation loss: 2.0251697500546775

Epoch: 6| Step: 1
Training loss: 0.25069165229797363
Validation loss: 2.0425702730814614

Epoch: 6| Step: 2
Training loss: 0.582071840763092
Validation loss: 2.0549217462539673

Epoch: 6| Step: 3
Training loss: 0.26724010705947876
Validation loss: 2.016668657461802

Epoch: 6| Step: 4
Training loss: 0.35306674242019653
Validation loss: 2.0347097317377725

Epoch: 6| Step: 5
Training loss: 0.574301540851593
Validation loss: 2.0180742939313254

Epoch: 6| Step: 6
Training loss: 0.2546970248222351
Validation loss: 2.032771110534668

Epoch: 6| Step: 7
Training loss: 0.18150341510772705
Validation loss: 2.0237651069959006

Epoch: 6| Step: 8
Training loss: 0.24887609481811523
Validation loss: 2.0182169874509177

Epoch: 6| Step: 9
Training loss: 0.19640211760997772
Validation loss: 1.9586413304011028

Epoch: 6| Step: 10
Training loss: 0.35558435320854187
Validation loss: 2.0171873370806375

Epoch: 6| Step: 11
Training loss: 0.41498637199401855
Validation loss: 2.01230796178182

Epoch: 6| Step: 12
Training loss: 0.22327283024787903
Validation loss: 1.9813214143117268

Epoch: 6| Step: 13
Training loss: 0.5202722549438477
Validation loss: 2.0386348764101663

Epoch: 347| Step: 0
Training loss: 0.34823787212371826
Validation loss: 1.9822233120600383

Epoch: 6| Step: 1
Training loss: 0.2567247748374939
Validation loss: 1.9810517032941182

Epoch: 6| Step: 2
Training loss: 0.48691070079803467
Validation loss: 1.9744166135787964

Epoch: 6| Step: 3
Training loss: 0.18602141737937927
Validation loss: 2.007051944732666

Epoch: 6| Step: 4
Training loss: 0.15497247874736786
Validation loss: 2.012603282928467

Epoch: 6| Step: 5
Training loss: 0.23560799658298492
Validation loss: 2.0467899243036904

Epoch: 6| Step: 6
Training loss: 0.2981666326522827
Validation loss: 2.0116944114367166

Epoch: 6| Step: 7
Training loss: 0.5900285840034485
Validation loss: 1.98405917485555

Epoch: 6| Step: 8
Training loss: 0.31799301505088806
Validation loss: 2.0402103662490845

Epoch: 6| Step: 9
Training loss: 0.17358015477657318
Validation loss: 2.0660847226778665

Epoch: 6| Step: 10
Training loss: 0.7685462832450867
Validation loss: 1.9501705567042034

Epoch: 6| Step: 11
Training loss: 0.376232385635376
Validation loss: 1.9993890126546223

Epoch: 6| Step: 12
Training loss: 0.43852269649505615
Validation loss: 1.9766335288683574

Epoch: 6| Step: 13
Training loss: 0.4048948287963867
Validation loss: 1.9606130123138428

Epoch: 348| Step: 0
Training loss: 0.23987698554992676
Validation loss: 1.984733243783315

Epoch: 6| Step: 1
Training loss: 0.3492703437805176
Validation loss: 2.0143075386683145

Epoch: 6| Step: 2
Training loss: 0.29562050104141235
Validation loss: 1.976490040620168

Epoch: 6| Step: 3
Training loss: 0.1845816969871521
Validation loss: 1.9914618333180745

Epoch: 6| Step: 4
Training loss: 0.20999106764793396
Validation loss: 1.9976508617401123

Epoch: 6| Step: 5
Training loss: 0.1806497871875763
Validation loss: 2.047087550163269

Epoch: 6| Step: 6
Training loss: 0.19844232499599457
Validation loss: 2.025090754032135

Epoch: 6| Step: 7
Training loss: 0.3410704731941223
Validation loss: 1.9912195205688477

Epoch: 6| Step: 8
Training loss: 0.7472293376922607
Validation loss: 1.9900991717974346

Epoch: 6| Step: 9
Training loss: 0.3985055685043335
Validation loss: 2.038114309310913

Epoch: 6| Step: 10
Training loss: 0.17866292595863342
Validation loss: 2.0049972534179688

Epoch: 6| Step: 11
Training loss: 0.47267746925354004
Validation loss: 1.9750556349754333

Epoch: 6| Step: 12
Training loss: 0.5285934209823608
Validation loss: 2.0445064306259155

Epoch: 6| Step: 13
Training loss: 0.5616398453712463
Validation loss: 2.01449187596639

Epoch: 349| Step: 0
Training loss: 0.2786736786365509
Validation loss: 1.993774672349294

Epoch: 6| Step: 1
Training loss: 0.630923330783844
Validation loss: 1.998833437760671

Epoch: 6| Step: 2
Training loss: 0.424987256526947
Validation loss: 1.9799480438232422

Epoch: 6| Step: 3
Training loss: 0.24738648533821106
Validation loss: 1.969993233680725

Epoch: 6| Step: 4
Training loss: 0.19743351638317108
Validation loss: 2.0266404151916504

Epoch: 6| Step: 5
Training loss: 0.42989596724510193
Validation loss: 1.965638776620229

Epoch: 6| Step: 6
Training loss: 0.5653808116912842
Validation loss: 2.0849385460217795

Epoch: 6| Step: 7
Training loss: 0.43913954496383667
Validation loss: 1.9949855009714763

Epoch: 6| Step: 8
Training loss: 0.2588597536087036
Validation loss: 2.0019450585047402

Epoch: 6| Step: 9
Training loss: 0.37880396842956543
Validation loss: 2.024340867996216

Epoch: 6| Step: 10
Training loss: 0.16898101568222046
Validation loss: 1.9810484051704407

Epoch: 6| Step: 11
Training loss: 0.37786680459976196
Validation loss: 1.991982062657674

Epoch: 6| Step: 12
Training loss: 0.1623450368642807
Validation loss: 1.9889824191729228

Epoch: 6| Step: 13
Training loss: 0.2794656455516815
Validation loss: 1.990088442961375

Epoch: 350| Step: 0
Training loss: 0.43277305364608765
Validation loss: 2.0090149641036987

Epoch: 6| Step: 1
Training loss: 1.1095521450042725
Validation loss: 1.9756558338801067

Epoch: 6| Step: 2
Training loss: 0.2584042549133301
Validation loss: 1.9838581681251526

Epoch: 6| Step: 3
Training loss: 0.2110816091299057
Validation loss: 2.006714860598246

Epoch: 6| Step: 4
Training loss: 0.2710039019584656
Validation loss: 1.9960736831029255

Epoch: 6| Step: 5
Training loss: 0.31763458251953125
Validation loss: 2.0187893907229104

Epoch: 6| Step: 6
Training loss: 0.22464676201343536
Validation loss: 1.9940715829531352

Epoch: 6| Step: 7
Training loss: 0.33299458026885986
Validation loss: 2.0046849052111306

Epoch: 6| Step: 8
Training loss: 0.20034486055374146
Validation loss: 1.9812332391738892

Epoch: 6| Step: 9
Training loss: 0.3897518217563629
Validation loss: 2.0357515017191568

Epoch: 6| Step: 10
Training loss: 0.3335811495780945
Validation loss: 2.0167022148768106

Epoch: 6| Step: 11
Training loss: 0.2903019189834595
Validation loss: 1.9612019658088684

Epoch: 6| Step: 12
Training loss: 0.21182793378829956
Validation loss: 2.0184556245803833

Epoch: 6| Step: 13
Training loss: 0.5082739591598511
Validation loss: 1.9870924949645996

Epoch: 351| Step: 0
Training loss: 0.3378809988498688
Validation loss: 2.00262858470281

Epoch: 6| Step: 1
Training loss: 0.49079447984695435
Validation loss: 1.9858235915501912

Epoch: 6| Step: 2
Training loss: 0.4189507067203522
Validation loss: 2.054261267185211

Epoch: 6| Step: 3
Training loss: 0.4972614347934723
Validation loss: 1.9726964831352234

Epoch: 6| Step: 4
Training loss: 0.2242729663848877
Validation loss: 1.9522566397984822

Epoch: 6| Step: 5
Training loss: 0.28287258744239807
Validation loss: 1.9438819885253906

Epoch: 6| Step: 6
Training loss: 0.31554001569747925
Validation loss: 1.9592891931533813

Epoch: 6| Step: 7
Training loss: 0.24632079899311066
Validation loss: 2.0213814775149026

Epoch: 6| Step: 8
Training loss: 0.18448132276535034
Validation loss: 2.020732283592224

Epoch: 6| Step: 9
Training loss: 0.5756296515464783
Validation loss: 1.992750108242035

Epoch: 6| Step: 10
Training loss: 0.2796509563922882
Validation loss: 1.9952490329742432

Epoch: 6| Step: 11
Training loss: 0.23191115260124207
Validation loss: 2.0024173657099404

Epoch: 6| Step: 12
Training loss: 0.31654617190361023
Validation loss: 2.018328229586283

Epoch: 6| Step: 13
Training loss: 0.335274875164032
Validation loss: 1.9974971016248066

Epoch: 352| Step: 0
Training loss: 0.17437848448753357
Validation loss: 2.0108373562494912

Epoch: 6| Step: 1
Training loss: 0.3873927891254425
Validation loss: 2.008166174093882

Epoch: 6| Step: 2
Training loss: 0.46724560856819153
Validation loss: 1.9953288833300273

Epoch: 6| Step: 3
Training loss: 0.7104635238647461
Validation loss: 1.9818575183550518

Epoch: 6| Step: 4
Training loss: 0.34679561853408813
Validation loss: 1.9844021598498027

Epoch: 6| Step: 5
Training loss: 0.2930070757865906
Validation loss: 1.9814097086588542

Epoch: 6| Step: 6
Training loss: 0.2563782334327698
Validation loss: 1.9840920567512512

Epoch: 6| Step: 7
Training loss: 0.272411584854126
Validation loss: 1.9596222043037415

Epoch: 6| Step: 8
Training loss: 0.41593873500823975
Validation loss: 2.0347314874331155

Epoch: 6| Step: 9
Training loss: 0.2469801902770996
Validation loss: 1.9800410469373066

Epoch: 6| Step: 10
Training loss: 0.3195829391479492
Validation loss: 2.0046711961428323

Epoch: 6| Step: 11
Training loss: 0.18214626610279083
Validation loss: 1.9855346878369649

Epoch: 6| Step: 12
Training loss: 0.4953339099884033
Validation loss: 1.989267885684967

Epoch: 6| Step: 13
Training loss: 0.40505313873291016
Validation loss: 2.0409016807874045

Epoch: 353| Step: 0
Training loss: 0.3491382896900177
Validation loss: 2.00564835468928

Epoch: 6| Step: 1
Training loss: 0.5227295160293579
Validation loss: 2.0151849587758384

Epoch: 6| Step: 2
Training loss: 0.19355790317058563
Validation loss: 1.9915829102198284

Epoch: 6| Step: 3
Training loss: 0.5848055481910706
Validation loss: 2.055669903755188

Epoch: 6| Step: 4
Training loss: 0.31375589966773987
Validation loss: 2.013344724973043

Epoch: 6| Step: 5
Training loss: 0.3555925786495209
Validation loss: 2.031270186106364

Epoch: 6| Step: 6
Training loss: 0.38281354308128357
Validation loss: 1.98485400279363

Epoch: 6| Step: 7
Training loss: 0.411478728055954
Validation loss: 2.0100324551264444

Epoch: 6| Step: 8
Training loss: 0.22740870714187622
Validation loss: 2.023840367794037

Epoch: 6| Step: 9
Training loss: 0.2674940526485443
Validation loss: 1.9781675338745117

Epoch: 6| Step: 10
Training loss: 0.22180673480033875
Validation loss: 2.0499419371287027

Epoch: 6| Step: 11
Training loss: 0.42373865842819214
Validation loss: 2.0196810563405356

Epoch: 6| Step: 12
Training loss: 0.2125144749879837
Validation loss: 2.021431008974711

Epoch: 6| Step: 13
Training loss: 0.28370073437690735
Validation loss: 2.036502957344055

Epoch: 354| Step: 0
Training loss: 0.3528650403022766
Validation loss: 2.014145016670227

Epoch: 6| Step: 1
Training loss: 0.2382093220949173
Validation loss: 2.014253318309784

Epoch: 6| Step: 2
Training loss: 0.25294190645217896
Validation loss: 1.9952992002169292

Epoch: 6| Step: 3
Training loss: 0.7717196941375732
Validation loss: 2.0542178948720298

Epoch: 6| Step: 4
Training loss: 0.23604997992515564
Validation loss: 1.9705410401026409

Epoch: 6| Step: 5
Training loss: 0.26520276069641113
Validation loss: 2.027266045411428

Epoch: 6| Step: 6
Training loss: 0.2845562994480133
Validation loss: 2.002769708633423

Epoch: 6| Step: 7
Training loss: 0.38773447275161743
Validation loss: 1.9946736892064412

Epoch: 6| Step: 8
Training loss: 0.17213541269302368
Validation loss: 1.9728129108746846

Epoch: 6| Step: 9
Training loss: 0.2810397148132324
Validation loss: 2.0096205870310464

Epoch: 6| Step: 10
Training loss: 0.35402894020080566
Validation loss: 1.9720317522684734

Epoch: 6| Step: 11
Training loss: 0.24153931438922882
Validation loss: 1.9826012055079143

Epoch: 6| Step: 12
Training loss: 0.5978778600692749
Validation loss: 1.9914505084355671

Epoch: 6| Step: 13
Training loss: 0.6078298091888428
Validation loss: 2.0538191000620523

Epoch: 355| Step: 0
Training loss: 0.2457997351884842
Validation loss: 2.0174361069997153

Epoch: 6| Step: 1
Training loss: 0.2630314826965332
Validation loss: 1.9925545652707417

Epoch: 6| Step: 2
Training loss: 0.3980596661567688
Validation loss: 2.003383199373881

Epoch: 6| Step: 3
Training loss: 0.49064546823501587
Validation loss: 1.9889254570007324

Epoch: 6| Step: 4
Training loss: 0.3378901183605194
Validation loss: 1.9935206770896912

Epoch: 6| Step: 5
Training loss: 0.45657092332839966
Validation loss: 1.9873494903246562

Epoch: 6| Step: 6
Training loss: 0.846185564994812
Validation loss: 2.004183769226074

Epoch: 6| Step: 7
Training loss: 0.18893662095069885
Validation loss: 2.010920226573944

Epoch: 6| Step: 8
Training loss: 0.1583578884601593
Validation loss: 1.9550259510676067

Epoch: 6| Step: 9
Training loss: 0.21186406910419464
Validation loss: 2.0187782645225525

Epoch: 6| Step: 10
Training loss: 0.34707608819007874
Validation loss: 2.021826684474945

Epoch: 6| Step: 11
Training loss: 0.4110458493232727
Validation loss: 2.0437145829200745

Epoch: 6| Step: 12
Training loss: 0.1797693967819214
Validation loss: 1.9795615871747334

Epoch: 6| Step: 13
Training loss: 0.27067410945892334
Validation loss: 2.0229846437772117

Epoch: 356| Step: 0
Training loss: 0.6250318288803101
Validation loss: 1.9966281453768413

Epoch: 6| Step: 1
Training loss: 0.33172592520713806
Validation loss: 1.9847917358080547

Epoch: 6| Step: 2
Training loss: 0.37875205278396606
Validation loss: 1.9965694348017375

Epoch: 6| Step: 3
Training loss: 0.2174551784992218
Validation loss: 2.0398163000742593

Epoch: 6| Step: 4
Training loss: 0.20224882662296295
Validation loss: 1.9872557719548543

Epoch: 6| Step: 5
Training loss: 0.29618725180625916
Validation loss: 2.000062942504883

Epoch: 6| Step: 6
Training loss: 0.18825311958789825
Validation loss: 1.9695701797803242

Epoch: 6| Step: 7
Training loss: 0.20783179998397827
Validation loss: 1.9969310363133748

Epoch: 6| Step: 8
Training loss: 0.2686901390552521
Validation loss: 1.9577518105506897

Epoch: 6| Step: 9
Training loss: 0.42982518672943115
Validation loss: 2.0097540616989136

Epoch: 6| Step: 10
Training loss: 0.3556348979473114
Validation loss: 1.984007755915324

Epoch: 6| Step: 11
Training loss: 0.2830201983451843
Validation loss: 2.044339577356974

Epoch: 6| Step: 12
Training loss: 0.836441695690155
Validation loss: 2.009988089402517

Epoch: 6| Step: 13
Training loss: 0.3577800989151001
Validation loss: 1.9660871028900146

Epoch: 357| Step: 0
Training loss: 0.24102403223514557
Validation loss: 2.019067704677582

Epoch: 6| Step: 1
Training loss: 0.5564971566200256
Validation loss: 1.9680982033411663

Epoch: 6| Step: 2
Training loss: 0.27608823776245117
Validation loss: 1.993600348631541

Epoch: 6| Step: 3
Training loss: 0.3197740912437439
Validation loss: 1.9824613730112712

Epoch: 6| Step: 4
Training loss: 0.34952670335769653
Validation loss: 2.011217216650645

Epoch: 6| Step: 5
Training loss: 0.6615161895751953
Validation loss: 2.024653514226278

Epoch: 6| Step: 6
Training loss: 0.4371553361415863
Validation loss: 1.9892183939615886

Epoch: 6| Step: 7
Training loss: 0.41722196340560913
Validation loss: 2.00627871354421

Epoch: 6| Step: 8
Training loss: 0.2774147391319275
Validation loss: 1.9852650165557861

Epoch: 6| Step: 9
Training loss: 0.29598939418792725
Validation loss: 1.9955146511395772

Epoch: 6| Step: 10
Training loss: 0.3339914083480835
Validation loss: 1.983577013015747

Epoch: 6| Step: 11
Training loss: 0.32721829414367676
Validation loss: 2.0049922863642373

Epoch: 6| Step: 12
Training loss: 0.3297749161720276
Validation loss: 2.0201923847198486

Epoch: 6| Step: 13
Training loss: 0.3095467686653137
Validation loss: 2.016277631123861

Epoch: 358| Step: 0
Training loss: 0.2076750546693802
Validation loss: 1.9958813786506653

Epoch: 6| Step: 1
Training loss: 0.16914886236190796
Validation loss: 1.987365464369456

Epoch: 6| Step: 2
Training loss: 0.6358742117881775
Validation loss: 2.005942940711975

Epoch: 6| Step: 3
Training loss: 0.4215962588787079
Validation loss: 2.0008814930915833

Epoch: 6| Step: 4
Training loss: 0.4439898133277893
Validation loss: 2.021045168240865

Epoch: 6| Step: 5
Training loss: 0.1956041306257248
Validation loss: 2.011416574319204

Epoch: 6| Step: 6
Training loss: 0.5086382031440735
Validation loss: 1.9751976132392883

Epoch: 6| Step: 7
Training loss: 0.2780912518501282
Validation loss: 2.0380223194758096

Epoch: 6| Step: 8
Training loss: 0.3074272871017456
Validation loss: 2.0194980104764304

Epoch: 6| Step: 9
Training loss: 0.47365546226501465
Validation loss: 1.9838151534398396

Epoch: 6| Step: 10
Training loss: 0.26812744140625
Validation loss: 1.9854511618614197

Epoch: 6| Step: 11
Training loss: 0.25761038064956665
Validation loss: 2.0041953722635903

Epoch: 6| Step: 12
Training loss: 0.282716304063797
Validation loss: 2.0338602860768638

Epoch: 6| Step: 13
Training loss: 0.3652196228504181
Validation loss: 2.047159214814504

Epoch: 359| Step: 0
Training loss: 0.4214628338813782
Validation loss: 1.9743967453638713

Epoch: 6| Step: 1
Training loss: 0.24219056963920593
Validation loss: 2.0281423528989158

Epoch: 6| Step: 2
Training loss: 0.24748246371746063
Validation loss: 2.0401345690091452

Epoch: 6| Step: 3
Training loss: 0.47800755500793457
Validation loss: 2.026408632596334

Epoch: 6| Step: 4
Training loss: 0.2374076545238495
Validation loss: 2.017018715540568

Epoch: 6| Step: 5
Training loss: 0.4781109690666199
Validation loss: 2.040957053502401

Epoch: 6| Step: 6
Training loss: 0.519980788230896
Validation loss: 1.9858208298683167

Epoch: 6| Step: 7
Training loss: 0.18787293136119843
Validation loss: 2.0147703687349954

Epoch: 6| Step: 8
Training loss: 0.23586949706077576
Validation loss: 1.9875590999921162

Epoch: 6| Step: 9
Training loss: 0.6336281299591064
Validation loss: 1.9878569046656291

Epoch: 6| Step: 10
Training loss: 0.2681865096092224
Validation loss: 2.0491063396135965

Epoch: 6| Step: 11
Training loss: 0.25525104999542236
Validation loss: 2.039355476697286

Epoch: 6| Step: 12
Training loss: 0.14433106780052185
Validation loss: 2.019996404647827

Epoch: 6| Step: 13
Training loss: 0.20249946415424347
Validation loss: 1.9532289902369182

Epoch: 360| Step: 0
Training loss: 0.21866586804389954
Validation loss: 2.003171463807424

Epoch: 6| Step: 1
Training loss: 0.27965450286865234
Validation loss: 2.008002281188965

Epoch: 6| Step: 2
Training loss: 0.39263269305229187
Validation loss: 2.032207727432251

Epoch: 6| Step: 3
Training loss: 0.43052515387535095
Validation loss: 1.9767481883366902

Epoch: 6| Step: 4
Training loss: 0.3453443646430969
Validation loss: 2.029069940249125

Epoch: 6| Step: 5
Training loss: 0.29595085978507996
Validation loss: 1.984679361184438

Epoch: 6| Step: 6
Training loss: 0.5113840103149414
Validation loss: 1.9521580934524536

Epoch: 6| Step: 7
Training loss: 0.5824841260910034
Validation loss: 1.968068500359853

Epoch: 6| Step: 8
Training loss: 0.1706952005624771
Validation loss: 1.9810530145963032

Epoch: 6| Step: 9
Training loss: 0.6571453213691711
Validation loss: 2.0132700204849243

Epoch: 6| Step: 10
Training loss: 0.2439126819372177
Validation loss: 1.9840023318926494

Epoch: 6| Step: 11
Training loss: 0.23326745629310608
Validation loss: 1.9901569088300068

Epoch: 6| Step: 12
Training loss: 0.2591931223869324
Validation loss: 1.9609258969624836

Epoch: 6| Step: 13
Training loss: 0.3295842111110687
Validation loss: 2.026180644830068

Epoch: 361| Step: 0
Training loss: 0.3044220805168152
Validation loss: 2.016356031099955

Epoch: 6| Step: 1
Training loss: 0.6537618637084961
Validation loss: 2.0031535824139914

Epoch: 6| Step: 2
Training loss: 0.2842179536819458
Validation loss: 1.9935913681983948

Epoch: 6| Step: 3
Training loss: 0.40065324306488037
Validation loss: 1.981143017609914

Epoch: 6| Step: 4
Training loss: 0.23846745491027832
Validation loss: 2.0035636027654014

Epoch: 6| Step: 5
Training loss: 0.20952783524990082
Validation loss: 1.9571808179219563

Epoch: 6| Step: 6
Training loss: 0.3413477838039398
Validation loss: 2.0224057038625083

Epoch: 6| Step: 7
Training loss: 0.19045239686965942
Validation loss: 2.0148394306500754

Epoch: 6| Step: 8
Training loss: 0.21932803094387054
Validation loss: 1.9748490850130718

Epoch: 6| Step: 9
Training loss: 0.47866183519363403
Validation loss: 1.9864116708437602

Epoch: 6| Step: 10
Training loss: 0.5114747285842896
Validation loss: 1.9979068239529927

Epoch: 6| Step: 11
Training loss: 0.32631051540374756
Validation loss: 2.001741270224253

Epoch: 6| Step: 12
Training loss: 0.22690948843955994
Validation loss: 1.993560294310252

Epoch: 6| Step: 13
Training loss: 0.5888693332672119
Validation loss: 1.973385790983836

Epoch: 362| Step: 0
Training loss: 0.6687446236610413
Validation loss: 2.0014502803484597

Epoch: 6| Step: 1
Training loss: 0.29588282108306885
Validation loss: 2.0084153612454734

Epoch: 6| Step: 2
Training loss: 0.3157418370246887
Validation loss: 1.9743133385976155

Epoch: 6| Step: 3
Training loss: 0.3217117190361023
Validation loss: 2.0439891815185547

Epoch: 6| Step: 4
Training loss: 0.4102041721343994
Validation loss: 2.006069759527842

Epoch: 6| Step: 5
Training loss: 0.39148783683776855
Validation loss: 2.0131796002388

Epoch: 6| Step: 6
Training loss: 0.2778284549713135
Validation loss: 2.0032601952552795

Epoch: 6| Step: 7
Training loss: 0.30021411180496216
Validation loss: 2.033954620361328

Epoch: 6| Step: 8
Training loss: 0.4647822082042694
Validation loss: 1.966487963994344

Epoch: 6| Step: 9
Training loss: 0.3966882824897766
Validation loss: 2.006527006626129

Epoch: 6| Step: 10
Training loss: 0.6481064558029175
Validation loss: 1.995724121729533

Epoch: 6| Step: 11
Training loss: 0.3237925171852112
Validation loss: 1.980552891890208

Epoch: 6| Step: 12
Training loss: 0.3296183943748474
Validation loss: 1.977474530537923

Epoch: 6| Step: 13
Training loss: 0.23140880465507507
Validation loss: 2.0011640389760337

Epoch: 363| Step: 0
Training loss: 0.28917112946510315
Validation loss: 1.9765808582305908

Epoch: 6| Step: 1
Training loss: 0.23567715287208557
Validation loss: 1.9820282657941182

Epoch: 6| Step: 2
Training loss: 0.21598263084888458
Validation loss: 2.0229447881380715

Epoch: 6| Step: 3
Training loss: 0.2729300260543823
Validation loss: 2.0189213951428733

Epoch: 6| Step: 4
Training loss: 0.3114469647407532
Validation loss: 2.047399361928304

Epoch: 6| Step: 5
Training loss: 0.2739209532737732
Validation loss: 1.9954701860745747

Epoch: 6| Step: 6
Training loss: 0.3164375424385071
Validation loss: 2.0573758482933044

Epoch: 6| Step: 7
Training loss: 0.40303754806518555
Validation loss: 1.9801608721415203

Epoch: 6| Step: 8
Training loss: 0.26116496324539185
Validation loss: 1.9932829936345418

Epoch: 6| Step: 9
Training loss: 0.356791615486145
Validation loss: 2.001570483048757

Epoch: 6| Step: 10
Training loss: 0.21934494376182556
Validation loss: 2.0129859844843545

Epoch: 6| Step: 11
Training loss: 0.873035192489624
Validation loss: 2.0177964766820273

Epoch: 6| Step: 12
Training loss: 0.4031370282173157
Validation loss: 2.047571897506714

Epoch: 6| Step: 13
Training loss: 0.3460867404937744
Validation loss: 2.025604705015818

Epoch: 364| Step: 0
Training loss: 0.3749564290046692
Validation loss: 1.9814274311065674

Epoch: 6| Step: 1
Training loss: 0.5752148032188416
Validation loss: 1.9950772523880005

Epoch: 6| Step: 2
Training loss: 0.3578527569770813
Validation loss: 1.9745895465215046

Epoch: 6| Step: 3
Training loss: 0.2700909376144409
Validation loss: 2.0046979586283364

Epoch: 6| Step: 4
Training loss: 0.3411601185798645
Validation loss: 1.9883047342300415

Epoch: 6| Step: 5
Training loss: 0.26682889461517334
Validation loss: 2.0167287985483804

Epoch: 6| Step: 6
Training loss: 0.23482760787010193
Validation loss: 2.0397944847742715

Epoch: 6| Step: 7
Training loss: 0.24830493330955505
Validation loss: 1.954767386118571

Epoch: 6| Step: 8
Training loss: 0.3280169665813446
Validation loss: 2.028564234574636

Epoch: 6| Step: 9
Training loss: 0.4949967563152313
Validation loss: 2.0177095333735147

Epoch: 6| Step: 10
Training loss: 0.48988884687423706
Validation loss: 2.0574073791503906

Epoch: 6| Step: 11
Training loss: 0.6060283780097961
Validation loss: 2.0195731123288474

Epoch: 6| Step: 12
Training loss: 0.47647595405578613
Validation loss: 1.9961666266123455

Epoch: 6| Step: 13
Training loss: 0.20382913947105408
Validation loss: 2.0400774280230203

Epoch: 365| Step: 0
Training loss: 0.1984645128250122
Validation loss: 2.0108474493026733

Epoch: 6| Step: 1
Training loss: 0.4193570613861084
Validation loss: 2.0561861793200173

Epoch: 6| Step: 2
Training loss: 0.3170451819896698
Validation loss: 1.9970613718032837

Epoch: 6| Step: 3
Training loss: 0.4038836658000946
Validation loss: 2.0062756141026816

Epoch: 6| Step: 4
Training loss: 0.3156144618988037
Validation loss: 2.0215201576550803

Epoch: 6| Step: 5
Training loss: 0.37366268038749695
Validation loss: 1.9758938948313396

Epoch: 6| Step: 6
Training loss: 0.6620190143585205
Validation loss: 2.0265695055325827

Epoch: 6| Step: 7
Training loss: 0.34393250942230225
Validation loss: 1.9994534651438396

Epoch: 6| Step: 8
Training loss: 0.3657912611961365
Validation loss: 2.007152815659841

Epoch: 6| Step: 9
Training loss: 0.13113737106323242
Validation loss: 2.024862547715505

Epoch: 6| Step: 10
Training loss: 0.6174420714378357
Validation loss: 1.9733984271685283

Epoch: 6| Step: 11
Training loss: 0.26776760816574097
Validation loss: 2.022884488105774

Epoch: 6| Step: 12
Training loss: 0.2984168529510498
Validation loss: 2.0246582627296448

Epoch: 6| Step: 13
Training loss: 0.18232016265392303
Validation loss: 1.998734752337138

Epoch: 366| Step: 0
Training loss: 0.44489914178848267
Validation loss: 1.9985730648040771

Epoch: 6| Step: 1
Training loss: 0.4987143278121948
Validation loss: 1.9940435886383057

Epoch: 6| Step: 2
Training loss: 0.2440013885498047
Validation loss: 1.9967825214068096

Epoch: 6| Step: 3
Training loss: 0.33025458455085754
Validation loss: 2.005335013071696

Epoch: 6| Step: 4
Training loss: 0.6380664706230164
Validation loss: 2.0074314077695212

Epoch: 6| Step: 5
Training loss: 0.2935582995414734
Validation loss: 2.047712206840515

Epoch: 6| Step: 6
Training loss: 0.2858632206916809
Validation loss: 1.9973892172177632

Epoch: 6| Step: 7
Training loss: 0.1692083775997162
Validation loss: 1.9687586426734924

Epoch: 6| Step: 8
Training loss: 0.26998192071914673
Validation loss: 1.951406975587209

Epoch: 6| Step: 9
Training loss: 0.36114776134490967
Validation loss: 2.0130425691604614

Epoch: 6| Step: 10
Training loss: 0.24428150057792664
Validation loss: 2.005802889664968

Epoch: 6| Step: 11
Training loss: 0.40716177225112915
Validation loss: 2.016837775707245

Epoch: 6| Step: 12
Training loss: 0.15052983164787292
Validation loss: 1.9722705284754436

Epoch: 6| Step: 13
Training loss: 0.3344804644584656
Validation loss: 1.9931934277216594

Epoch: 367| Step: 0
Training loss: 0.24890640377998352
Validation loss: 1.963598867257436

Epoch: 6| Step: 1
Training loss: 0.24877558648586273
Validation loss: 2.015141010284424

Epoch: 6| Step: 2
Training loss: 0.3535250425338745
Validation loss: 1.9815529982248943

Epoch: 6| Step: 3
Training loss: 0.23983940482139587
Validation loss: 2.035062034924825

Epoch: 6| Step: 4
Training loss: 0.5603954792022705
Validation loss: 1.9818940957387288

Epoch: 6| Step: 5
Training loss: 0.2277979552745819
Validation loss: 1.9920762181282043

Epoch: 6| Step: 6
Training loss: 0.22778567671775818
Validation loss: 2.0389061768849692

Epoch: 6| Step: 7
Training loss: 0.3133348226547241
Validation loss: 2.0057611068089805

Epoch: 6| Step: 8
Training loss: 0.3292831480503082
Validation loss: 1.9922545552253723

Epoch: 6| Step: 9
Training loss: 0.3020186722278595
Validation loss: 2.018209397792816

Epoch: 6| Step: 10
Training loss: 0.6200247406959534
Validation loss: 1.9686787525812786

Epoch: 6| Step: 11
Training loss: 0.3734636604785919
Validation loss: 1.9895718296368916

Epoch: 6| Step: 12
Training loss: 0.34557825326919556
Validation loss: 2.020636002222697

Epoch: 6| Step: 13
Training loss: 0.44321146607398987
Validation loss: 1.9925140937169392

Epoch: 368| Step: 0
Training loss: 0.5014797449111938
Validation loss: 1.9801773428916931

Epoch: 6| Step: 1
Training loss: 0.27292752265930176
Validation loss: 2.0022295713424683

Epoch: 6| Step: 2
Training loss: 0.7165062427520752
Validation loss: 1.9995742042859395

Epoch: 6| Step: 3
Training loss: 0.3093606233596802
Validation loss: 1.96396799882253

Epoch: 6| Step: 4
Training loss: 0.23156960308551788
Validation loss: 1.9903682470321655

Epoch: 6| Step: 5
Training loss: 0.2805914580821991
Validation loss: 1.9889648755391438

Epoch: 6| Step: 6
Training loss: 0.23718224465847015
Validation loss: 1.9809473156929016

Epoch: 6| Step: 7
Training loss: 0.31982308626174927
Validation loss: 2.022394041220347

Epoch: 6| Step: 8
Training loss: 0.3268192410469055
Validation loss: 2.0005451440811157

Epoch: 6| Step: 9
Training loss: 0.5804126858711243
Validation loss: 1.9534612496693928

Epoch: 6| Step: 10
Training loss: 0.2761886715888977
Validation loss: 2.0156379540761313

Epoch: 6| Step: 11
Training loss: 0.24984197318553925
Validation loss: 2.0032928188641868

Epoch: 6| Step: 12
Training loss: 0.23168347775936127
Validation loss: 2.0075695315996804

Epoch: 6| Step: 13
Training loss: 0.2539665699005127
Validation loss: 1.9811989665031433

Epoch: 369| Step: 0
Training loss: 0.29474732279777527
Validation loss: 2.0052459438641868

Epoch: 6| Step: 1
Training loss: 0.19323837757110596
Validation loss: 2.0052490234375

Epoch: 6| Step: 2
Training loss: 0.2843855023384094
Validation loss: 1.9521268606185913

Epoch: 6| Step: 3
Training loss: 0.2529791593551636
Validation loss: 1.9736179113388062

Epoch: 6| Step: 4
Training loss: 0.30159568786621094
Validation loss: 1.9885773460070293

Epoch: 6| Step: 5
Training loss: 0.31981223821640015
Validation loss: 2.015722334384918

Epoch: 6| Step: 6
Training loss: 0.5764997601509094
Validation loss: 2.0243695179621377

Epoch: 6| Step: 7
Training loss: 0.44343262910842896
Validation loss: 2.018943170706431

Epoch: 6| Step: 8
Training loss: 0.4990558922290802
Validation loss: 2.0130032300949097

Epoch: 6| Step: 9
Training loss: 0.34251415729522705
Validation loss: 1.990155021349589

Epoch: 6| Step: 10
Training loss: 0.39576417207717896
Validation loss: 1.964256723721822

Epoch: 6| Step: 11
Training loss: 0.2719883322715759
Validation loss: 1.9831604758898418

Epoch: 6| Step: 12
Training loss: 0.16952750086784363
Validation loss: 1.9866484800974529

Epoch: 6| Step: 13
Training loss: 0.46682411432266235
Validation loss: 2.023924728234609

Epoch: 370| Step: 0
Training loss: 0.17864197492599487
Validation loss: 2.0000170270601907

Epoch: 6| Step: 1
Training loss: 0.16954687237739563
Validation loss: 2.0035215616226196

Epoch: 6| Step: 2
Training loss: 0.2231547236442566
Validation loss: 1.9646336038907368

Epoch: 6| Step: 3
Training loss: 0.29302847385406494
Validation loss: 2.017117182413737

Epoch: 6| Step: 4
Training loss: 0.5316039323806763
Validation loss: 1.9789655605951946

Epoch: 6| Step: 5
Training loss: 0.608936071395874
Validation loss: 2.0349963108698526

Epoch: 6| Step: 6
Training loss: 0.44964736700057983
Validation loss: 1.9781453212102253

Epoch: 6| Step: 7
Training loss: 0.29482313990592957
Validation loss: 1.9944432775179546

Epoch: 6| Step: 8
Training loss: 0.15717071294784546
Validation loss: 2.0120147864023843

Epoch: 6| Step: 9
Training loss: 0.2889290750026703
Validation loss: 1.9957586924235027

Epoch: 6| Step: 10
Training loss: 0.4393092691898346
Validation loss: 2.014677266279856

Epoch: 6| Step: 11
Training loss: 0.25627151131629944
Validation loss: 2.064460575580597

Epoch: 6| Step: 12
Training loss: 0.691825807094574
Validation loss: 1.9873789548873901

Epoch: 6| Step: 13
Training loss: 0.30088669061660767
Validation loss: 1.9903216163317363

Epoch: 371| Step: 0
Training loss: 0.455289751291275
Validation loss: 2.002081652482351

Epoch: 6| Step: 1
Training loss: 0.36833953857421875
Validation loss: 2.0205465952555337

Epoch: 6| Step: 2
Training loss: 0.32094520330429077
Validation loss: 1.9907431999842327

Epoch: 6| Step: 3
Training loss: 0.2411910444498062
Validation loss: 1.9520326654116313

Epoch: 6| Step: 4
Training loss: 0.6007333993911743
Validation loss: 2.0491674145062766

Epoch: 6| Step: 5
Training loss: 0.16523046791553497
Validation loss: 2.039867361386617

Epoch: 6| Step: 6
Training loss: 0.36712509393692017
Validation loss: 2.030947744846344

Epoch: 6| Step: 7
Training loss: 0.1351010799407959
Validation loss: 1.994281828403473

Epoch: 6| Step: 8
Training loss: 0.2682534158229828
Validation loss: 1.9995154937108357

Epoch: 6| Step: 9
Training loss: 0.360889196395874
Validation loss: 2.016019821166992

Epoch: 6| Step: 10
Training loss: 0.3149866461753845
Validation loss: 1.985455572605133

Epoch: 6| Step: 11
Training loss: 0.35141098499298096
Validation loss: 2.0108805298805237

Epoch: 6| Step: 12
Training loss: 0.4311903417110443
Validation loss: 1.9652376174926758

Epoch: 6| Step: 13
Training loss: 0.2406250685453415
Validation loss: 1.9998823205629985

Epoch: 372| Step: 0
Training loss: 0.1813381314277649
Validation loss: 2.033515691757202

Epoch: 6| Step: 1
Training loss: 0.5849957466125488
Validation loss: 1.9746468663215637

Epoch: 6| Step: 2
Training loss: 0.36912286281585693
Validation loss: 1.9789573351542156

Epoch: 6| Step: 3
Training loss: 0.2172888219356537
Validation loss: 1.9901070594787598

Epoch: 6| Step: 4
Training loss: 0.24551033973693848
Validation loss: 2.0124013225237527

Epoch: 6| Step: 5
Training loss: 0.2945576310157776
Validation loss: 1.998788595199585

Epoch: 6| Step: 6
Training loss: 0.11247554421424866
Validation loss: 2.0112881461779275

Epoch: 6| Step: 7
Training loss: 0.29308268427848816
Validation loss: 1.9960281252861023

Epoch: 6| Step: 8
Training loss: 0.31326690316200256
Validation loss: 2.01206245024999

Epoch: 6| Step: 9
Training loss: 0.30694398283958435
Validation loss: 2.0346723000208535

Epoch: 6| Step: 10
Training loss: 0.6831916570663452
Validation loss: 2.038025160630544

Epoch: 6| Step: 11
Training loss: 0.19153743982315063
Validation loss: 2.010717829068502

Epoch: 6| Step: 12
Training loss: 0.302435964345932
Validation loss: 2.0032872756322226

Epoch: 6| Step: 13
Training loss: 0.22236508131027222
Validation loss: 1.9702876210212708

Epoch: 373| Step: 0
Training loss: 0.4171997308731079
Validation loss: 2.015420118967692

Epoch: 6| Step: 1
Training loss: 0.2605472207069397
Validation loss: 2.062296291192373

Epoch: 6| Step: 2
Training loss: 0.26098716259002686
Validation loss: 1.9783784945805867

Epoch: 6| Step: 3
Training loss: 0.2298632562160492
Validation loss: 2.0148503184318542

Epoch: 6| Step: 4
Training loss: 0.20936261117458344
Validation loss: 1.999289294083913

Epoch: 6| Step: 5
Training loss: 0.7364733219146729
Validation loss: 1.979943295319875

Epoch: 6| Step: 6
Training loss: 0.2258279025554657
Validation loss: 2.015819867451986

Epoch: 6| Step: 7
Training loss: 0.3717569410800934
Validation loss: 2.017831861972809

Epoch: 6| Step: 8
Training loss: 0.4171754717826843
Validation loss: 1.972418765227

Epoch: 6| Step: 9
Training loss: 0.388068288564682
Validation loss: 2.0096630851427713

Epoch: 6| Step: 10
Training loss: 0.4196852445602417
Validation loss: 2.030119697252909

Epoch: 6| Step: 11
Training loss: 0.22896626591682434
Validation loss: 1.9990349014600117

Epoch: 6| Step: 12
Training loss: 0.23760852217674255
Validation loss: 2.0139434933662415

Epoch: 6| Step: 13
Training loss: 0.36173591017723083
Validation loss: 2.007004459698995

Epoch: 374| Step: 0
Training loss: 0.3117694854736328
Validation loss: 1.9839396278063457

Epoch: 6| Step: 1
Training loss: 0.4656941294670105
Validation loss: 1.9761067827542622

Epoch: 6| Step: 2
Training loss: 0.17545980215072632
Validation loss: 2.0229032039642334

Epoch: 6| Step: 3
Training loss: 0.2939438223838806
Validation loss: 1.9939198891321819

Epoch: 6| Step: 4
Training loss: 0.5360437631607056
Validation loss: 1.9758965571721394

Epoch: 6| Step: 5
Training loss: 0.21607723832130432
Validation loss: 1.985762119293213

Epoch: 6| Step: 6
Training loss: 0.23309293389320374
Validation loss: 1.9715518752733867

Epoch: 6| Step: 7
Training loss: 0.4339292049407959
Validation loss: 1.997754156589508

Epoch: 6| Step: 8
Training loss: 0.4881702661514282
Validation loss: 1.9665361046791077

Epoch: 6| Step: 9
Training loss: 0.30740886926651
Validation loss: 2.0499557852745056

Epoch: 6| Step: 10
Training loss: 0.5218738317489624
Validation loss: 2.0413276155789695

Epoch: 6| Step: 11
Training loss: 0.3235434293746948
Validation loss: 2.0105536778767905

Epoch: 6| Step: 12
Training loss: 0.6656908988952637
Validation loss: 1.9652748306592305

Epoch: 6| Step: 13
Training loss: 0.22949965298175812
Validation loss: 1.9667083024978638

Epoch: 375| Step: 0
Training loss: 0.442637175321579
Validation loss: 2.033263305823008

Epoch: 6| Step: 1
Training loss: 0.72320157289505
Validation loss: 1.9911240537961323

Epoch: 6| Step: 2
Training loss: 0.33318161964416504
Validation loss: 1.984822193781535

Epoch: 6| Step: 3
Training loss: 0.6302049160003662
Validation loss: 1.9828054706255596

Epoch: 6| Step: 4
Training loss: 0.24259468913078308
Validation loss: 1.979595681031545

Epoch: 6| Step: 5
Training loss: 0.25985047221183777
Validation loss: 1.9698184728622437

Epoch: 6| Step: 6
Training loss: 0.26685699820518494
Validation loss: 1.956384281317393

Epoch: 6| Step: 7
Training loss: 0.2062310427427292
Validation loss: 2.0087252060572305

Epoch: 6| Step: 8
Training loss: 0.418322890996933
Validation loss: 2.0584170619646707

Epoch: 6| Step: 9
Training loss: 0.2689386010169983
Validation loss: 2.0178470810254416

Epoch: 6| Step: 10
Training loss: 0.2299775928258896
Validation loss: 2.01717076698939

Epoch: 6| Step: 11
Training loss: 0.3587726354598999
Validation loss: 2.0348345239957175

Epoch: 6| Step: 12
Training loss: 0.3390006721019745
Validation loss: 2.0268162886301675

Epoch: 6| Step: 13
Training loss: 0.3004786968231201
Validation loss: 1.972645342350006

Epoch: 376| Step: 0
Training loss: 0.3643588423728943
Validation loss: 2.0293995340665183

Epoch: 6| Step: 1
Training loss: 0.2836141586303711
Validation loss: 2.0263355573018393

Epoch: 6| Step: 2
Training loss: 0.22178784012794495
Validation loss: 2.0068432092666626

Epoch: 6| Step: 3
Training loss: 0.6027660965919495
Validation loss: 2.0108325481414795

Epoch: 6| Step: 4
Training loss: 0.2355584055185318
Validation loss: 1.997261603673299

Epoch: 6| Step: 5
Training loss: 0.5667364597320557
Validation loss: 1.9786461194356282

Epoch: 6| Step: 6
Training loss: 0.24379810690879822
Validation loss: 2.013571480909983

Epoch: 6| Step: 7
Training loss: 0.21079273521900177
Validation loss: 1.9925862550735474

Epoch: 6| Step: 8
Training loss: 0.3164024353027344
Validation loss: 2.0201401313145957

Epoch: 6| Step: 9
Training loss: 0.27026891708374023
Validation loss: 1.9710198243459065

Epoch: 6| Step: 10
Training loss: 0.5330468416213989
Validation loss: 1.9616412719090779

Epoch: 6| Step: 11
Training loss: 0.21228355169296265
Validation loss: 1.9551655252774556

Epoch: 6| Step: 12
Training loss: 0.17840257287025452
Validation loss: 1.95526518424352

Epoch: 6| Step: 13
Training loss: 0.3189656436443329
Validation loss: 2.019229312737783

Epoch: 377| Step: 0
Training loss: 0.3381955027580261
Validation loss: 2.0109903812408447

Epoch: 6| Step: 1
Training loss: 0.1909894347190857
Validation loss: 1.9994728167851765

Epoch: 6| Step: 2
Training loss: 0.32785624265670776
Validation loss: 1.9727553526560466

Epoch: 6| Step: 3
Training loss: 0.1729513257741928
Validation loss: 1.9944863319396973

Epoch: 6| Step: 4
Training loss: 0.3233848810195923
Validation loss: 2.0204235514005027

Epoch: 6| Step: 5
Training loss: 0.3462151288986206
Validation loss: 1.9964009722073872

Epoch: 6| Step: 6
Training loss: 0.3181559145450592
Validation loss: 1.9707147876421611

Epoch: 6| Step: 7
Training loss: 0.40023157000541687
Validation loss: 1.9930309057235718

Epoch: 6| Step: 8
Training loss: 0.2231757491827011
Validation loss: 2.008691966533661

Epoch: 6| Step: 9
Training loss: 0.2595878839492798
Validation loss: 2.0235259930292764

Epoch: 6| Step: 10
Training loss: 0.29078352451324463
Validation loss: 1.9614920020103455

Epoch: 6| Step: 11
Training loss: 0.30662769079208374
Validation loss: 2.041419744491577

Epoch: 6| Step: 12
Training loss: 0.7026082277297974
Validation loss: 2.0205195347468057

Epoch: 6| Step: 13
Training loss: 0.5765753984451294
Validation loss: 1.9857946236928303

Epoch: 378| Step: 0
Training loss: 0.5886074304580688
Validation loss: 2.0357759594917297

Epoch: 6| Step: 1
Training loss: 0.31531620025634766
Validation loss: 1.9724936087926228

Epoch: 6| Step: 2
Training loss: 0.16513359546661377
Validation loss: 2.0212465127309165

Epoch: 6| Step: 3
Training loss: 0.28647851943969727
Validation loss: 2.0415155490239463

Epoch: 6| Step: 4
Training loss: 0.27317965030670166
Validation loss: 1.9945220748583476

Epoch: 6| Step: 5
Training loss: 0.2763572633266449
Validation loss: 1.9971654415130615

Epoch: 6| Step: 6
Training loss: 0.2245696783065796
Validation loss: 2.0070990522702536

Epoch: 6| Step: 7
Training loss: 0.23961415886878967
Validation loss: 2.0073211391766868

Epoch: 6| Step: 8
Training loss: 0.25668132305145264
Validation loss: 2.0367980003356934

Epoch: 6| Step: 9
Training loss: 0.6643403768539429
Validation loss: 2.038967410723368

Epoch: 6| Step: 10
Training loss: 0.3186149597167969
Validation loss: 2.057903528213501

Epoch: 6| Step: 11
Training loss: 0.5200985670089722
Validation loss: 2.023670713106791

Epoch: 6| Step: 12
Training loss: 0.40369680523872375
Validation loss: 1.9837839206059773

Epoch: 6| Step: 13
Training loss: 0.22702261805534363
Validation loss: 2.0359845757484436

Epoch: 379| Step: 0
Training loss: 0.4739023447036743
Validation loss: 2.010783572991689

Epoch: 6| Step: 1
Training loss: 0.2094452828168869
Validation loss: 2.025198737780253

Epoch: 6| Step: 2
Training loss: 0.30814117193222046
Validation loss: 1.9577594796816509

Epoch: 6| Step: 3
Training loss: 0.41065844893455505
Validation loss: 2.014148771762848

Epoch: 6| Step: 4
Training loss: 0.227717787027359
Validation loss: 2.0241129795710244

Epoch: 6| Step: 5
Training loss: 0.308073490858078
Validation loss: 2.0503372152646384

Epoch: 6| Step: 6
Training loss: 0.3545864522457123
Validation loss: 1.9601568380991619

Epoch: 6| Step: 7
Training loss: 0.7210924029350281
Validation loss: 2.0291284124056497

Epoch: 6| Step: 8
Training loss: 0.20900392532348633
Validation loss: 2.050467868645986

Epoch: 6| Step: 9
Training loss: 0.2363802045583725
Validation loss: 1.9612499872843425

Epoch: 6| Step: 10
Training loss: 0.47067421674728394
Validation loss: 2.0284546613693237

Epoch: 6| Step: 11
Training loss: 0.2690999209880829
Validation loss: 2.013628840446472

Epoch: 6| Step: 12
Training loss: 0.25322508811950684
Validation loss: 2.0351268649101257

Epoch: 6| Step: 13
Training loss: 0.3219360113143921
Validation loss: 2.027305761973063

Epoch: 380| Step: 0
Training loss: 0.3079919219017029
Validation loss: 1.998715837796529

Epoch: 6| Step: 1
Training loss: 0.17317014932632446
Validation loss: 2.0078678131103516

Epoch: 6| Step: 2
Training loss: 0.3627743124961853
Validation loss: 2.0074950456619263

Epoch: 6| Step: 3
Training loss: 0.4670116901397705
Validation loss: 1.9836639165878296

Epoch: 6| Step: 4
Training loss: 0.3815052807331085
Validation loss: 1.9736495614051819

Epoch: 6| Step: 5
Training loss: 0.43548905849456787
Validation loss: 2.01540740331014

Epoch: 6| Step: 6
Training loss: 0.3683732748031616
Validation loss: 1.9987771113713582

Epoch: 6| Step: 7
Training loss: 0.3758399486541748
Validation loss: 1.9688265323638916

Epoch: 6| Step: 8
Training loss: 0.6943111419677734
Validation loss: 2.0262911319732666

Epoch: 6| Step: 9
Training loss: 0.5170551538467407
Validation loss: 2.020508885383606

Epoch: 6| Step: 10
Training loss: 0.3080081343650818
Validation loss: 1.985530932744344

Epoch: 6| Step: 11
Training loss: 0.3146415948867798
Validation loss: 1.9646941026051838

Epoch: 6| Step: 12
Training loss: 0.2514309883117676
Validation loss: 1.9903892079989116

Epoch: 6| Step: 13
Training loss: 0.19377973675727844
Validation loss: 1.994613488515218

Epoch: 381| Step: 0
Training loss: 0.3051373362541199
Validation loss: 1.9646706382433574

Epoch: 6| Step: 1
Training loss: 0.7662376165390015
Validation loss: 1.9829787413279216

Epoch: 6| Step: 2
Training loss: 0.26758915185928345
Validation loss: 2.0036538441975913

Epoch: 6| Step: 3
Training loss: 0.4301624298095703
Validation loss: 1.998012860616048

Epoch: 6| Step: 4
Training loss: 0.27626150846481323
Validation loss: 1.9961122473080952

Epoch: 6| Step: 5
Training loss: 0.3307737112045288
Validation loss: 1.9943684935569763

Epoch: 6| Step: 6
Training loss: 0.3762510418891907
Validation loss: 1.975444753964742

Epoch: 6| Step: 7
Training loss: 0.2219618260860443
Validation loss: 2.010902682940165

Epoch: 6| Step: 8
Training loss: 0.26389065384864807
Validation loss: 1.9840368231137593

Epoch: 6| Step: 9
Training loss: 0.3400678336620331
Validation loss: 1.9881967306137085

Epoch: 6| Step: 10
Training loss: 0.3360423743724823
Validation loss: 1.9902154207229614

Epoch: 6| Step: 11
Training loss: 0.41532251238822937
Validation loss: 2.0118531386057534

Epoch: 6| Step: 12
Training loss: 0.2395503669977188
Validation loss: 2.035999814669291

Epoch: 6| Step: 13
Training loss: 0.6257817149162292
Validation loss: 1.9656906326611836

Epoch: 382| Step: 0
Training loss: 0.33509278297424316
Validation loss: 1.9575393199920654

Epoch: 6| Step: 1
Training loss: 0.37668949365615845
Validation loss: 1.9497625827789307

Epoch: 6| Step: 2
Training loss: 0.29014572501182556
Validation loss: 2.0260608196258545

Epoch: 6| Step: 3
Training loss: 0.29866668581962585
Validation loss: 2.0093711217244468

Epoch: 6| Step: 4
Training loss: 0.38545697927474976
Validation loss: 1.985931356747945

Epoch: 6| Step: 5
Training loss: 0.20110517740249634
Validation loss: 1.9932066202163696

Epoch: 6| Step: 6
Training loss: 0.4598909020423889
Validation loss: 1.9880946079889934

Epoch: 6| Step: 7
Training loss: 0.351065993309021
Validation loss: 2.0392878651618958

Epoch: 6| Step: 8
Training loss: 0.3984396755695343
Validation loss: 2.035563309987386

Epoch: 6| Step: 9
Training loss: 0.6298955082893372
Validation loss: 2.0253778100013733

Epoch: 6| Step: 10
Training loss: 0.5651661157608032
Validation loss: 1.9939895470937092

Epoch: 6| Step: 11
Training loss: 0.2517198920249939
Validation loss: 2.009391109148661

Epoch: 6| Step: 12
Training loss: 0.26290321350097656
Validation loss: 2.0128798683484397

Epoch: 6| Step: 13
Training loss: 0.3627859950065613
Validation loss: 2.0368762612342834

Epoch: 383| Step: 0
Training loss: 0.5061175227165222
Validation loss: 2.0146616101264954

Epoch: 6| Step: 1
Training loss: 0.3290039300918579
Validation loss: 2.0000120202700296

Epoch: 6| Step: 2
Training loss: 0.2119954526424408
Validation loss: 1.988241195678711

Epoch: 6| Step: 3
Training loss: 0.23661386966705322
Validation loss: 2.0012797911961875

Epoch: 6| Step: 4
Training loss: 0.29095369577407837
Validation loss: 2.0194111466407776

Epoch: 6| Step: 5
Training loss: 0.5233253240585327
Validation loss: 2.0479589303334556

Epoch: 6| Step: 6
Training loss: 0.30963134765625
Validation loss: 2.017775297164917

Epoch: 6| Step: 7
Training loss: 0.7347711324691772
Validation loss: 2.1057567397753396

Epoch: 6| Step: 8
Training loss: 0.29060637950897217
Validation loss: 2.0538615783055625

Epoch: 6| Step: 9
Training loss: 0.23590731620788574
Validation loss: 1.969716211160024

Epoch: 6| Step: 10
Training loss: 0.6261756420135498
Validation loss: 2.0533341566721597

Epoch: 6| Step: 11
Training loss: 0.4496164917945862
Validation loss: 2.0333069562911987

Epoch: 6| Step: 12
Training loss: 0.21534696221351624
Validation loss: 2.023394604523977

Epoch: 6| Step: 13
Training loss: 0.45214933156967163
Validation loss: 2.0391376415888467

Epoch: 384| Step: 0
Training loss: 0.4177495837211609
Validation loss: 2.019576132297516

Epoch: 6| Step: 1
Training loss: 0.38575905561447144
Validation loss: 2.0579514503479004

Epoch: 6| Step: 2
Training loss: 0.41857844591140747
Validation loss: 2.0047088662783303

Epoch: 6| Step: 3
Training loss: 0.6602522134780884
Validation loss: 2.013482689857483

Epoch: 6| Step: 4
Training loss: 0.29491734504699707
Validation loss: 1.9697937965393066

Epoch: 6| Step: 5
Training loss: 0.4732133746147156
Validation loss: 2.0309016903241477

Epoch: 6| Step: 6
Training loss: 0.45711249113082886
Validation loss: 2.026178260644277

Epoch: 6| Step: 7
Training loss: 0.1869962513446808
Validation loss: 2.0053425828615823

Epoch: 6| Step: 8
Training loss: 0.2178172469139099
Validation loss: 2.0325578451156616

Epoch: 6| Step: 9
Training loss: 0.21805840730667114
Validation loss: 2.0171953638394675

Epoch: 6| Step: 10
Training loss: 0.2995387613773346
Validation loss: 2.028045197327932

Epoch: 6| Step: 11
Training loss: 0.15334010124206543
Validation loss: 1.997972587744395

Epoch: 6| Step: 12
Training loss: 0.30949079990386963
Validation loss: 2.008482356866201

Epoch: 6| Step: 13
Training loss: 0.12997117638587952
Validation loss: 2.04796302318573

Epoch: 385| Step: 0
Training loss: 0.22254106402397156
Validation loss: 2.003598133722941

Epoch: 6| Step: 1
Training loss: 0.25977277755737305
Validation loss: 2.0299097498257956

Epoch: 6| Step: 2
Training loss: 0.24511155486106873
Validation loss: 1.992005705833435

Epoch: 6| Step: 3
Training loss: 0.47151923179626465
Validation loss: 1.9718169768651326

Epoch: 6| Step: 4
Training loss: 0.17515899240970612
Validation loss: 1.9838321208953857

Epoch: 6| Step: 5
Training loss: 0.39799928665161133
Validation loss: 1.9979599714279175

Epoch: 6| Step: 6
Training loss: 0.28119152784347534
Validation loss: 2.0166074434916177

Epoch: 6| Step: 7
Training loss: 0.3804111182689667
Validation loss: 2.0592618584632874

Epoch: 6| Step: 8
Training loss: 0.7202568054199219
Validation loss: 2.030259112517039

Epoch: 6| Step: 9
Training loss: 0.4068068861961365
Validation loss: 1.9884357452392578

Epoch: 6| Step: 10
Training loss: 0.2155698835849762
Validation loss: 2.01633628209432

Epoch: 6| Step: 11
Training loss: 0.41341549158096313
Validation loss: 2.021388053894043

Epoch: 6| Step: 12
Training loss: 0.2753770649433136
Validation loss: 2.010119001070658

Epoch: 6| Step: 13
Training loss: 0.24153873324394226
Validation loss: 2.0028669834136963

Epoch: 386| Step: 0
Training loss: 0.6103790998458862
Validation loss: 2.023350715637207

Epoch: 6| Step: 1
Training loss: 0.46807897090911865
Validation loss: 1.9531699816385906

Epoch: 6| Step: 2
Training loss: 0.3614705204963684
Validation loss: 1.991735299428304

Epoch: 6| Step: 3
Training loss: 0.22506585717201233
Validation loss: 1.9601723949114482

Epoch: 6| Step: 4
Training loss: 0.33515989780426025
Validation loss: 2.0134159127871194

Epoch: 6| Step: 5
Training loss: 0.18191561102867126
Validation loss: 1.987405796845754

Epoch: 6| Step: 6
Training loss: 0.30852606892585754
Validation loss: 1.9706963499387105

Epoch: 6| Step: 7
Training loss: 0.3654138743877411
Validation loss: 2.015756626923879

Epoch: 6| Step: 8
Training loss: 0.2297394573688507
Validation loss: 2.00233523050944

Epoch: 6| Step: 9
Training loss: 0.28412577509880066
Validation loss: 1.957654893398285

Epoch: 6| Step: 10
Training loss: 0.15179377794265747
Validation loss: 2.0226736267407737

Epoch: 6| Step: 11
Training loss: 0.43671631813049316
Validation loss: 2.0050414403279624

Epoch: 6| Step: 12
Training loss: 0.2680063843727112
Validation loss: 2.0184611876805625

Epoch: 6| Step: 13
Training loss: 0.14828845858573914
Validation loss: 2.016641060511271

Epoch: 387| Step: 0
Training loss: 0.28880995512008667
Validation loss: 2.0103513995806375

Epoch: 6| Step: 1
Training loss: 0.3748478889465332
Validation loss: 1.9985074202219646

Epoch: 6| Step: 2
Training loss: 0.4356153607368469
Validation loss: 2.007008890310923

Epoch: 6| Step: 3
Training loss: 0.4007890522480011
Validation loss: 1.9991032282511394

Epoch: 6| Step: 4
Training loss: 0.1878613531589508
Validation loss: 2.053819795449575

Epoch: 6| Step: 5
Training loss: 0.4332430362701416
Validation loss: 1.9822625517845154

Epoch: 6| Step: 6
Training loss: 0.5610414147377014
Validation loss: 1.988799810409546

Epoch: 6| Step: 7
Training loss: 0.3114320635795593
Validation loss: 2.036406715710958

Epoch: 6| Step: 8
Training loss: 0.1750030517578125
Validation loss: 2.007955014705658

Epoch: 6| Step: 9
Training loss: 0.20361775159835815
Validation loss: 1.9909028609593709

Epoch: 6| Step: 10
Training loss: 0.2544417381286621
Validation loss: 1.9734990000724792

Epoch: 6| Step: 11
Training loss: 0.2603790760040283
Validation loss: 1.989070971806844

Epoch: 6| Step: 12
Training loss: 0.24797353148460388
Validation loss: 2.067645271619161

Epoch: 6| Step: 13
Training loss: 0.3044086694717407
Validation loss: 1.9465747674306233

Epoch: 388| Step: 0
Training loss: 0.37254369258880615
Validation loss: 2.0080732703208923

Epoch: 6| Step: 1
Training loss: 0.36324912309646606
Validation loss: 2.0086238185564675

Epoch: 6| Step: 2
Training loss: 0.21249474585056305
Validation loss: 2.033090273539225

Epoch: 6| Step: 3
Training loss: 0.2590274214744568
Validation loss: 1.979654590288798

Epoch: 6| Step: 4
Training loss: 0.20173195004463196
Validation loss: 1.971723735332489

Epoch: 6| Step: 5
Training loss: 0.3467406630516052
Validation loss: 1.971838355064392

Epoch: 6| Step: 6
Training loss: 0.34223437309265137
Validation loss: 1.9812549153963726

Epoch: 6| Step: 7
Training loss: 0.3375416398048401
Validation loss: 1.965139627456665

Epoch: 6| Step: 8
Training loss: 0.3029143512248993
Validation loss: 1.9874860843022664

Epoch: 6| Step: 9
Training loss: 0.3039330244064331
Validation loss: 2.030668099721273

Epoch: 6| Step: 10
Training loss: 0.2605074644088745
Validation loss: 1.992855151494344

Epoch: 6| Step: 11
Training loss: 0.3041003346443176
Validation loss: 2.013301412264506

Epoch: 6| Step: 12
Training loss: 0.6902229189872742
Validation loss: 1.9729214509328206

Epoch: 6| Step: 13
Training loss: 0.4073730409145355
Validation loss: 1.9873074690500896

Epoch: 389| Step: 0
Training loss: 0.2063826620578766
Validation loss: 2.030915141105652

Epoch: 6| Step: 1
Training loss: 0.44477584958076477
Validation loss: 2.0337733825047812

Epoch: 6| Step: 2
Training loss: 0.3129793703556061
Validation loss: 2.0100380579630532

Epoch: 6| Step: 3
Training loss: 0.2937408685684204
Validation loss: 1.9630837639172871

Epoch: 6| Step: 4
Training loss: 0.1203230768442154
Validation loss: 1.9929418166478474

Epoch: 6| Step: 5
Training loss: 0.27404236793518066
Validation loss: 1.9468616445859273

Epoch: 6| Step: 6
Training loss: 0.1958373486995697
Validation loss: 1.9858869910240173

Epoch: 6| Step: 7
Training loss: 0.573760986328125
Validation loss: 1.9971761306126912

Epoch: 6| Step: 8
Training loss: 0.22522389888763428
Validation loss: 1.9874235391616821

Epoch: 6| Step: 9
Training loss: 0.5176351070404053
Validation loss: 2.0093687772750854

Epoch: 6| Step: 10
Training loss: 0.26468878984451294
Validation loss: 1.9886450568834941

Epoch: 6| Step: 11
Training loss: 0.1791597604751587
Validation loss: 1.9741294781366985

Epoch: 6| Step: 12
Training loss: 0.1943199336528778
Validation loss: 1.9964953263600667

Epoch: 6| Step: 13
Training loss: 0.6273380517959595
Validation loss: 1.9609225789705913

Epoch: 390| Step: 0
Training loss: 0.42081159353256226
Validation loss: 1.9458486835161846

Epoch: 6| Step: 1
Training loss: 0.2430160641670227
Validation loss: 1.9877426226933796

Epoch: 6| Step: 2
Training loss: 0.18394657969474792
Validation loss: 1.9818006952603657

Epoch: 6| Step: 3
Training loss: 0.39596033096313477
Validation loss: 2.029947559038798

Epoch: 6| Step: 4
Training loss: 0.1924329698085785
Validation loss: 2.0072338779767356

Epoch: 6| Step: 5
Training loss: 0.4281814396381378
Validation loss: 1.9909303387006123

Epoch: 6| Step: 6
Training loss: 0.4641103148460388
Validation loss: 1.9869462251663208

Epoch: 6| Step: 7
Training loss: 0.3215935528278351
Validation loss: 1.9744629263877869

Epoch: 6| Step: 8
Training loss: 0.25241994857788086
Validation loss: 2.06109885374705

Epoch: 6| Step: 9
Training loss: 0.14435255527496338
Validation loss: 2.014359970887502

Epoch: 6| Step: 10
Training loss: 0.20632076263427734
Validation loss: 1.980013370513916

Epoch: 6| Step: 11
Training loss: 0.6336889266967773
Validation loss: 1.9553164045015972

Epoch: 6| Step: 12
Training loss: 0.1834738850593567
Validation loss: 1.9627004861831665

Epoch: 6| Step: 13
Training loss: 0.22574743628501892
Validation loss: 2.011010388533274

Epoch: 391| Step: 0
Training loss: 0.25659656524658203
Validation loss: 1.9750489195187886

Epoch: 6| Step: 1
Training loss: 0.26793259382247925
Validation loss: 1.9703844388326008

Epoch: 6| Step: 2
Training loss: 0.16621743142604828
Validation loss: 1.9449939131736755

Epoch: 6| Step: 3
Training loss: 0.21789127588272095
Validation loss: 1.9692014455795288

Epoch: 6| Step: 4
Training loss: 0.6401018500328064
Validation loss: 2.0036360025405884

Epoch: 6| Step: 5
Training loss: 0.28398364782333374
Validation loss: 2.0025322635968528

Epoch: 6| Step: 6
Training loss: 0.3014354109764099
Validation loss: 2.001751879851023

Epoch: 6| Step: 7
Training loss: 0.23544833064079285
Validation loss: 1.9485762317975361

Epoch: 6| Step: 8
Training loss: 0.4091311991214752
Validation loss: 1.9497275352478027

Epoch: 6| Step: 9
Training loss: 0.3563607931137085
Validation loss: 2.0107930501302085

Epoch: 6| Step: 10
Training loss: 0.3297322988510132
Validation loss: 1.9963181614875793

Epoch: 6| Step: 11
Training loss: 0.234434112906456
Validation loss: 2.000100553035736

Epoch: 6| Step: 12
Training loss: 0.2531786262989044
Validation loss: 2.0189087788263955

Epoch: 6| Step: 13
Training loss: 0.2815204858779907
Validation loss: 1.986781080563863

Epoch: 392| Step: 0
Training loss: 0.16869348287582397
Validation loss: 2.011463483174642

Epoch: 6| Step: 1
Training loss: 0.19580475986003876
Validation loss: 1.981429636478424

Epoch: 6| Step: 2
Training loss: 0.45060595870018005
Validation loss: 1.997587005297343

Epoch: 6| Step: 3
Training loss: 0.29812145233154297
Validation loss: 2.000721573829651

Epoch: 6| Step: 4
Training loss: 0.24824713170528412
Validation loss: 1.9616753061612446

Epoch: 6| Step: 5
Training loss: 0.26507437229156494
Validation loss: 2.0038246711095176

Epoch: 6| Step: 6
Training loss: 0.35422468185424805
Validation loss: 2.0268813570340476

Epoch: 6| Step: 7
Training loss: 0.23819607496261597
Validation loss: 1.9848677515983582

Epoch: 6| Step: 8
Training loss: 0.2501506507396698
Validation loss: 1.9991658329963684

Epoch: 6| Step: 9
Training loss: 0.2203364074230194
Validation loss: 2.007134437561035

Epoch: 6| Step: 10
Training loss: 0.7370332479476929
Validation loss: 1.9665281971295674

Epoch: 6| Step: 11
Training loss: 0.36737629771232605
Validation loss: 1.9925647179285686

Epoch: 6| Step: 12
Training loss: 0.22576549649238586
Validation loss: 1.9794492324193318

Epoch: 6| Step: 13
Training loss: 0.3388599157333374
Validation loss: 1.989205261071523

Epoch: 393| Step: 0
Training loss: 0.2783178985118866
Validation loss: 1.9670823613802593

Epoch: 6| Step: 1
Training loss: 0.15701115131378174
Validation loss: 1.9559465448061626

Epoch: 6| Step: 2
Training loss: 0.3641660511493683
Validation loss: 1.9534627596537273

Epoch: 6| Step: 3
Training loss: 0.2722729742527008
Validation loss: 1.9671056667963664

Epoch: 6| Step: 4
Training loss: 0.24718070030212402
Validation loss: 1.9857579072316487

Epoch: 6| Step: 5
Training loss: 0.23155340552330017
Validation loss: 1.9974045753479004

Epoch: 6| Step: 6
Training loss: 0.38661736249923706
Validation loss: 1.9839862982432048

Epoch: 6| Step: 7
Training loss: 0.3060990571975708
Validation loss: 1.9903262456258137

Epoch: 6| Step: 8
Training loss: 0.5351760387420654
Validation loss: 1.997977574666341

Epoch: 6| Step: 9
Training loss: 0.27228987216949463
Validation loss: 1.957589328289032

Epoch: 6| Step: 10
Training loss: 0.19713377952575684
Validation loss: 2.011627813180288

Epoch: 6| Step: 11
Training loss: 0.30031782388687134
Validation loss: 1.9792941013971965

Epoch: 6| Step: 12
Training loss: 0.39339685440063477
Validation loss: 1.985219140847524

Epoch: 6| Step: 13
Training loss: 0.5488362312316895
Validation loss: 1.9886723160743713

Epoch: 394| Step: 0
Training loss: 0.38089719414711
Validation loss: 2.0103288491566977

Epoch: 6| Step: 1
Training loss: 0.6044609546661377
Validation loss: 1.9747300545374553

Epoch: 6| Step: 2
Training loss: 0.20011679828166962
Validation loss: 1.9952813784281414

Epoch: 6| Step: 3
Training loss: 0.32732319831848145
Validation loss: 2.0039259990056357

Epoch: 6| Step: 4
Training loss: 0.13848483562469482
Validation loss: 1.986784279346466

Epoch: 6| Step: 5
Training loss: 0.16479724645614624
Validation loss: 1.9475160241127014

Epoch: 6| Step: 6
Training loss: 0.5117476582527161
Validation loss: 1.968326985836029

Epoch: 6| Step: 7
Training loss: 0.19589950144290924
Validation loss: 1.9849735697110493

Epoch: 6| Step: 8
Training loss: 0.12066943943500519
Validation loss: 2.0003949403762817

Epoch: 6| Step: 9
Training loss: 0.37887483835220337
Validation loss: 2.0234144727389016

Epoch: 6| Step: 10
Training loss: 0.28117743134498596
Validation loss: 2.013540804386139

Epoch: 6| Step: 11
Training loss: 0.19621562957763672
Validation loss: 1.9701388478279114

Epoch: 6| Step: 12
Training loss: 0.149740070104599
Validation loss: 2.0221142967542014

Epoch: 6| Step: 13
Training loss: 0.5387320518493652
Validation loss: 1.998579462369283

Epoch: 395| Step: 0
Training loss: 0.21312472224235535
Validation loss: 1.9842021862665813

Epoch: 6| Step: 1
Training loss: 0.38500863313674927
Validation loss: 2.0112290581067405

Epoch: 6| Step: 2
Training loss: 0.2807607054710388
Validation loss: 2.0153215328852334

Epoch: 6| Step: 3
Training loss: 0.3598560094833374
Validation loss: 1.9608179330825806

Epoch: 6| Step: 4
Training loss: 0.23396991193294525
Validation loss: 1.9920889337857564

Epoch: 6| Step: 5
Training loss: 0.2152027189731598
Validation loss: 2.0375797351201377

Epoch: 6| Step: 6
Training loss: 0.5288830995559692
Validation loss: 2.029097596804301

Epoch: 6| Step: 7
Training loss: 0.2780848741531372
Validation loss: 1.9711057146390278

Epoch: 6| Step: 8
Training loss: 0.3614128828048706
Validation loss: 2.0125083327293396

Epoch: 6| Step: 9
Training loss: 0.68635094165802
Validation loss: 1.9701537489891052

Epoch: 6| Step: 10
Training loss: 0.3245757818222046
Validation loss: 2.0469388564427695

Epoch: 6| Step: 11
Training loss: 0.3328048586845398
Validation loss: 2.003912111123403

Epoch: 6| Step: 12
Training loss: 0.2284761220216751
Validation loss: 1.9959579308827717

Epoch: 6| Step: 13
Training loss: 0.30112379789352417
Validation loss: 2.0120351115862527

Epoch: 396| Step: 0
Training loss: 0.32389408349990845
Validation loss: 1.989649514357249

Epoch: 6| Step: 1
Training loss: 0.25913745164871216
Validation loss: 1.9953960378964741

Epoch: 6| Step: 2
Training loss: 0.22823664546012878
Validation loss: 1.995921830336253

Epoch: 6| Step: 3
Training loss: 0.2223946452140808
Validation loss: 1.96296630303065

Epoch: 6| Step: 4
Training loss: 0.1895005851984024
Validation loss: 1.9981967608133953

Epoch: 6| Step: 5
Training loss: 0.5985698103904724
Validation loss: 1.9982033769289653

Epoch: 6| Step: 6
Training loss: 0.33667516708374023
Validation loss: 1.9904193878173828

Epoch: 6| Step: 7
Training loss: 0.4445665776729584
Validation loss: 1.9707832137743633

Epoch: 6| Step: 8
Training loss: 0.2548116147518158
Validation loss: 1.9651959737141926

Epoch: 6| Step: 9
Training loss: 0.4258328080177307
Validation loss: 1.9944435358047485

Epoch: 6| Step: 10
Training loss: 0.19615736603736877
Validation loss: 1.9475821654001872

Epoch: 6| Step: 11
Training loss: 0.3762601315975189
Validation loss: 2.0087131460507712

Epoch: 6| Step: 12
Training loss: 0.31453946232795715
Validation loss: 2.0195239186286926

Epoch: 6| Step: 13
Training loss: 0.4851246774196625
Validation loss: 1.996651033560435

Epoch: 397| Step: 0
Training loss: 0.29849839210510254
Validation loss: 1.9669426679611206

Epoch: 6| Step: 1
Training loss: 0.32033437490463257
Validation loss: 1.9772336880366008

Epoch: 6| Step: 2
Training loss: 0.2874836027622223
Validation loss: 1.9794497688611348

Epoch: 6| Step: 3
Training loss: 0.37036532163619995
Validation loss: 1.9576134085655212

Epoch: 6| Step: 4
Training loss: 0.1977096050977707
Validation loss: 1.9901458621025085

Epoch: 6| Step: 5
Training loss: 0.5345935821533203
Validation loss: 1.9921166896820068

Epoch: 6| Step: 6
Training loss: 0.2587936818599701
Validation loss: 1.9481673836708069

Epoch: 6| Step: 7
Training loss: 0.3530499339103699
Validation loss: 1.9297369519869487

Epoch: 6| Step: 8
Training loss: 0.2241242378950119
Validation loss: 2.004233102003733

Epoch: 6| Step: 9
Training loss: 0.28929635882377625
Validation loss: 1.9963540236155193

Epoch: 6| Step: 10
Training loss: 0.6362140774726868
Validation loss: 1.9816646377245586

Epoch: 6| Step: 11
Training loss: 0.1990540623664856
Validation loss: 2.0258540511131287

Epoch: 6| Step: 12
Training loss: 0.18082450330257416
Validation loss: 2.003697454929352

Epoch: 6| Step: 13
Training loss: 0.26172250509262085
Validation loss: 2.0104187528292337

Epoch: 398| Step: 0
Training loss: 0.30235686898231506
Validation loss: 2.015459934870402

Epoch: 6| Step: 1
Training loss: 0.38194453716278076
Validation loss: 1.9961072603861492

Epoch: 6| Step: 2
Training loss: 0.38441845774650574
Validation loss: 2.0299965143203735

Epoch: 6| Step: 3
Training loss: 0.20284582674503326
Validation loss: 2.0146659215291343

Epoch: 6| Step: 4
Training loss: 0.8813216090202332
Validation loss: 2.0197293758392334

Epoch: 6| Step: 5
Training loss: 0.24978718161582947
Validation loss: 2.020868957042694

Epoch: 6| Step: 6
Training loss: 0.24414542317390442
Validation loss: 1.9316308895746868

Epoch: 6| Step: 7
Training loss: 0.196013405919075
Validation loss: 1.9876263737678528

Epoch: 6| Step: 8
Training loss: 0.299448698759079
Validation loss: 1.972253680229187

Epoch: 6| Step: 9
Training loss: 0.33094272017478943
Validation loss: 1.9838181932767232

Epoch: 6| Step: 10
Training loss: 0.2615686058998108
Validation loss: 2.008144736289978

Epoch: 6| Step: 11
Training loss: 0.2635417878627777
Validation loss: 2.0099417765935264

Epoch: 6| Step: 12
Training loss: 0.25291264057159424
Validation loss: 1.9962995251019795

Epoch: 6| Step: 13
Training loss: 0.3448411226272583
Validation loss: 2.005281925201416

Epoch: 399| Step: 0
Training loss: 0.33704519271850586
Validation loss: 1.9714941382408142

Epoch: 6| Step: 1
Training loss: 0.5268095135688782
Validation loss: 2.008046249548594

Epoch: 6| Step: 2
Training loss: 0.3846750259399414
Validation loss: 1.9707853396733601

Epoch: 6| Step: 3
Training loss: 0.18641704320907593
Validation loss: 1.9563354849815369

Epoch: 6| Step: 4
Training loss: 0.2567256689071655
Validation loss: 1.943533718585968

Epoch: 6| Step: 5
Training loss: 0.25458472967147827
Validation loss: 1.987950086593628

Epoch: 6| Step: 6
Training loss: 0.1759551614522934
Validation loss: 1.9679494102795918

Epoch: 6| Step: 7
Training loss: 0.3787088692188263
Validation loss: 1.9762683312098186

Epoch: 6| Step: 8
Training loss: 0.26167023181915283
Validation loss: 1.967303951581319

Epoch: 6| Step: 9
Training loss: 0.3762425482273102
Validation loss: 1.9627257585525513

Epoch: 6| Step: 10
Training loss: 0.6234920024871826
Validation loss: 1.9485211372375488

Epoch: 6| Step: 11
Training loss: 0.3597080409526825
Validation loss: 2.023239254951477

Epoch: 6| Step: 12
Training loss: 0.26161637902259827
Validation loss: 1.9781481623649597

Epoch: 6| Step: 13
Training loss: 0.3894304931163788
Validation loss: 1.97566952308019

Epoch: 400| Step: 0
Training loss: 0.42454177141189575
Validation loss: 1.9988211592038472

Epoch: 6| Step: 1
Training loss: 0.1992424726486206
Validation loss: 1.9841725428899128

Epoch: 6| Step: 2
Training loss: 0.2806839942932129
Validation loss: 2.018319527308146

Epoch: 6| Step: 3
Training loss: 0.387485533952713
Validation loss: 1.9992218613624573

Epoch: 6| Step: 4
Training loss: 0.2638527750968933
Validation loss: 1.9377286632855732

Epoch: 6| Step: 5
Training loss: 0.6340599060058594
Validation loss: 1.9928618868192036

Epoch: 6| Step: 6
Training loss: 0.31026214361190796
Validation loss: 1.9546053409576416

Epoch: 6| Step: 7
Training loss: 0.23885677754878998
Validation loss: 1.973485251267751

Epoch: 6| Step: 8
Training loss: 0.3053658604621887
Validation loss: 1.9847193161646526

Epoch: 6| Step: 9
Training loss: 0.27892130613327026
Validation loss: 1.9919628302256267

Epoch: 6| Step: 10
Training loss: 0.2227470874786377
Validation loss: 1.9612520337104797

Epoch: 6| Step: 11
Training loss: 0.33010390400886536
Validation loss: 2.032918632030487

Epoch: 6| Step: 12
Training loss: 0.40114128589630127
Validation loss: 1.9861832459767659

Epoch: 6| Step: 13
Training loss: 0.1556200087070465
Validation loss: 1.9372406005859375

Epoch: 401| Step: 0
Training loss: 0.2815825343132019
Validation loss: 1.9729924599329631

Epoch: 6| Step: 1
Training loss: 0.46835532784461975
Validation loss: 1.9706762035687764

Epoch: 6| Step: 2
Training loss: 0.15983377397060394
Validation loss: 1.9801794687906902

Epoch: 6| Step: 3
Training loss: 0.36844050884246826
Validation loss: 1.9379881024360657

Epoch: 6| Step: 4
Training loss: 0.2275296151638031
Validation loss: 1.9821982582410176

Epoch: 6| Step: 5
Training loss: 0.2920810282230377
Validation loss: 2.003603935241699

Epoch: 6| Step: 6
Training loss: 0.2889726758003235
Validation loss: 2.022675633430481

Epoch: 6| Step: 7
Training loss: 0.245123490691185
Validation loss: 2.0022350549697876

Epoch: 6| Step: 8
Training loss: 0.27684998512268066
Validation loss: 1.9810489813486736

Epoch: 6| Step: 9
Training loss: 0.7159754037857056
Validation loss: 1.987434943517049

Epoch: 6| Step: 10
Training loss: 0.2688882350921631
Validation loss: 1.9701040983200073

Epoch: 6| Step: 11
Training loss: 0.4543960988521576
Validation loss: 1.9901352326075237

Epoch: 6| Step: 12
Training loss: 0.19045408070087433
Validation loss: 1.9450252056121826

Epoch: 6| Step: 13
Training loss: 0.15665021538734436
Validation loss: 1.992358962694804

Epoch: 402| Step: 0
Training loss: 0.18653196096420288
Validation loss: 1.9784077604611714

Epoch: 6| Step: 1
Training loss: 0.2937162518501282
Validation loss: 2.0305057168006897

Epoch: 6| Step: 2
Training loss: 0.3572944104671478
Validation loss: 1.9949159224828084

Epoch: 6| Step: 3
Training loss: 0.20672404766082764
Validation loss: 2.01143878698349

Epoch: 6| Step: 4
Training loss: 0.23058518767356873
Validation loss: 1.9936918218930562

Epoch: 6| Step: 5
Training loss: 0.21179983019828796
Validation loss: 1.99677308400472

Epoch: 6| Step: 6
Training loss: 0.34319594502449036
Validation loss: 2.0000714858373008

Epoch: 6| Step: 7
Training loss: 0.2848797142505646
Validation loss: 2.0215948820114136

Epoch: 6| Step: 8
Training loss: 0.40779048204421997
Validation loss: 1.9790867169698079

Epoch: 6| Step: 9
Training loss: 0.3338865637779236
Validation loss: 1.99095219373703

Epoch: 6| Step: 10
Training loss: 0.15874770283699036
Validation loss: 1.990738054116567

Epoch: 6| Step: 11
Training loss: 0.7513331174850464
Validation loss: 1.95662917693456

Epoch: 6| Step: 12
Training loss: 0.4079606831073761
Validation loss: 1.9948769609133403

Epoch: 6| Step: 13
Training loss: 0.28622111678123474
Validation loss: 2.0065423250198364

Epoch: 403| Step: 0
Training loss: 0.2038797289133072
Validation loss: 2.014160633087158

Epoch: 6| Step: 1
Training loss: 0.3364790678024292
Validation loss: 1.9866236249605815

Epoch: 6| Step: 2
Training loss: 0.24581538140773773
Validation loss: 1.9848608771959941

Epoch: 6| Step: 3
Training loss: 0.26146671175956726
Validation loss: 2.0152178605397544

Epoch: 6| Step: 4
Training loss: 0.2571367919445038
Validation loss: 2.0201262633005777

Epoch: 6| Step: 5
Training loss: 0.20561249554157257
Validation loss: 2.029959738254547

Epoch: 6| Step: 6
Training loss: 0.7079669833183289
Validation loss: 2.0273895859718323

Epoch: 6| Step: 7
Training loss: 0.44467541575431824
Validation loss: 1.976483941078186

Epoch: 6| Step: 8
Training loss: 0.4903106689453125
Validation loss: 1.9605164130528767

Epoch: 6| Step: 9
Training loss: 0.19216656684875488
Validation loss: 1.9980280200640361

Epoch: 6| Step: 10
Training loss: 0.35685813426971436
Validation loss: 2.0091015497843423

Epoch: 6| Step: 11
Training loss: 0.4412400424480438
Validation loss: 1.9944297671318054

Epoch: 6| Step: 12
Training loss: 0.3546191453933716
Validation loss: 2.010649561882019

Epoch: 6| Step: 13
Training loss: 0.6403887271881104
Validation loss: 2.025054931640625

Epoch: 404| Step: 0
Training loss: 0.5432929396629333
Validation loss: 1.9927632808685303

Epoch: 6| Step: 1
Training loss: 0.22950437664985657
Validation loss: 2.013693690299988

Epoch: 6| Step: 2
Training loss: 0.23316074907779694
Validation loss: 2.0136379996935525

Epoch: 6| Step: 3
Training loss: 0.30154868960380554
Validation loss: 2.025515158971151

Epoch: 6| Step: 4
Training loss: 0.2779664993286133
Validation loss: 2.0267320672671

Epoch: 6| Step: 5
Training loss: 0.6712504029273987
Validation loss: 2.016311784585317

Epoch: 6| Step: 6
Training loss: 0.3558729290962219
Validation loss: 2.0459383726119995

Epoch: 6| Step: 7
Training loss: 0.26434409618377686
Validation loss: 2.0226377646128335

Epoch: 6| Step: 8
Training loss: 0.33237940073013306
Validation loss: 2.0331839323043823

Epoch: 6| Step: 9
Training loss: 0.24153143167495728
Validation loss: 1.999844253063202

Epoch: 6| Step: 10
Training loss: 0.28528833389282227
Validation loss: 2.030672232309977

Epoch: 6| Step: 11
Training loss: 0.44294273853302
Validation loss: 2.0143529574076333

Epoch: 6| Step: 12
Training loss: 0.30602318048477173
Validation loss: 2.0184659361839294

Epoch: 6| Step: 13
Training loss: 0.5378438830375671
Validation loss: 1.9694623549779255

Epoch: 405| Step: 0
Training loss: 0.618965744972229
Validation loss: 2.033387780189514

Epoch: 6| Step: 1
Training loss: 0.3441529870033264
Validation loss: 1.9877695043881733

Epoch: 6| Step: 2
Training loss: 0.23703259229660034
Validation loss: 2.025268077850342

Epoch: 6| Step: 3
Training loss: 0.40267834067344666
Validation loss: 2.018897990385691

Epoch: 6| Step: 4
Training loss: 0.6317549347877502
Validation loss: 2.0228618582089744

Epoch: 6| Step: 5
Training loss: 0.36747023463249207
Validation loss: 1.9584220846494038

Epoch: 6| Step: 6
Training loss: 0.30265694856643677
Validation loss: 1.995833655198415

Epoch: 6| Step: 7
Training loss: 0.3344944417476654
Validation loss: 1.9945829312006633

Epoch: 6| Step: 8
Training loss: 0.23481275141239166
Validation loss: 1.9973522027333577

Epoch: 6| Step: 9
Training loss: 0.15930497646331787
Validation loss: 2.0107210874557495

Epoch: 6| Step: 10
Training loss: 0.3010405898094177
Validation loss: 2.00681342681249

Epoch: 6| Step: 11
Training loss: 0.34469571709632874
Validation loss: 2.001013398170471

Epoch: 6| Step: 12
Training loss: 0.5057694315910339
Validation loss: 2.0667550365130105

Epoch: 6| Step: 13
Training loss: 0.38913196325302124
Validation loss: 2.029051721096039

Epoch: 406| Step: 0
Training loss: 0.3260771334171295
Validation loss: 2.017850677172343

Epoch: 6| Step: 1
Training loss: 0.28234797716140747
Validation loss: 1.9907907247543335

Epoch: 6| Step: 2
Training loss: 0.2801399827003479
Validation loss: 2.0213459730148315

Epoch: 6| Step: 3
Training loss: 0.2859043478965759
Validation loss: 1.9867873191833496

Epoch: 6| Step: 4
Training loss: 0.40883201360702515
Validation loss: 1.995524565378825

Epoch: 6| Step: 5
Training loss: 0.23236076533794403
Validation loss: 2.0516424576441445

Epoch: 6| Step: 6
Training loss: 0.2509543299674988
Validation loss: 2.005375345547994

Epoch: 6| Step: 7
Training loss: 0.18601901829242706
Validation loss: 1.9911765456199646

Epoch: 6| Step: 8
Training loss: 0.39443376660346985
Validation loss: 2.0085623462994895

Epoch: 6| Step: 9
Training loss: 0.4476695656776428
Validation loss: 2.001866559187571

Epoch: 6| Step: 10
Training loss: 0.36498841643333435
Validation loss: 2.0762923757235208

Epoch: 6| Step: 11
Training loss: 0.2938319444656372
Validation loss: 2.0057714184125266

Epoch: 6| Step: 12
Training loss: 0.343084454536438
Validation loss: 2.033186376094818

Epoch: 6| Step: 13
Training loss: 0.717753529548645
Validation loss: 1.9757156372070312

Epoch: 407| Step: 0
Training loss: 0.2632552981376648
Validation loss: 2.005939523379008

Epoch: 6| Step: 1
Training loss: 0.21199820935726166
Validation loss: 2.0133617321650186

Epoch: 6| Step: 2
Training loss: 0.2360927164554596
Validation loss: 1.9897127548853557

Epoch: 6| Step: 3
Training loss: 0.8888806104660034
Validation loss: 2.0025003949801126

Epoch: 6| Step: 4
Training loss: 0.26726043224334717
Validation loss: 2.0105517705281577

Epoch: 6| Step: 5
Training loss: 0.34224361181259155
Validation loss: 1.9973655740420024

Epoch: 6| Step: 6
Training loss: 0.21564635634422302
Validation loss: 1.9719847838083904

Epoch: 6| Step: 7
Training loss: 0.4823257327079773
Validation loss: 1.9529166221618652

Epoch: 6| Step: 8
Training loss: 0.2244652509689331
Validation loss: 1.9954031904538472

Epoch: 6| Step: 9
Training loss: 0.2672017812728882
Validation loss: 1.9874157706896465

Epoch: 6| Step: 10
Training loss: 0.3717502951622009
Validation loss: 1.972247044245402

Epoch: 6| Step: 11
Training loss: 0.37813547253608704
Validation loss: 1.9635950128237407

Epoch: 6| Step: 12
Training loss: 0.3019242286682129
Validation loss: 1.9775209625562031

Epoch: 6| Step: 13
Training loss: 0.6464847326278687
Validation loss: 1.990908920764923

Epoch: 408| Step: 0
Training loss: 0.15016107261180878
Validation loss: 2.0393648743629456

Epoch: 6| Step: 1
Training loss: 0.2359568476676941
Validation loss: 1.9939762353897095

Epoch: 6| Step: 2
Training loss: 0.22567278146743774
Validation loss: 1.944415032863617

Epoch: 6| Step: 3
Training loss: 0.31553417444229126
Validation loss: 1.9962779680887859

Epoch: 6| Step: 4
Training loss: 0.5941298604011536
Validation loss: 1.961924413839976

Epoch: 6| Step: 5
Training loss: 0.12684956192970276
Validation loss: 1.969477355480194

Epoch: 6| Step: 6
Training loss: 0.1715858280658722
Validation loss: 1.9627734621365864

Epoch: 6| Step: 7
Training loss: 0.3415851593017578
Validation loss: 1.9949480096499126

Epoch: 6| Step: 8
Training loss: 0.2639029324054718
Validation loss: 1.9685522119204204

Epoch: 6| Step: 9
Training loss: 0.6640974283218384
Validation loss: 1.9532034794489543

Epoch: 6| Step: 10
Training loss: 0.46288955211639404
Validation loss: 1.9956225355466206

Epoch: 6| Step: 11
Training loss: 0.25503242015838623
Validation loss: 2.0059648950894675

Epoch: 6| Step: 12
Training loss: 0.27491486072540283
Validation loss: 1.9879925449689229

Epoch: 6| Step: 13
Training loss: 0.19868621230125427
Validation loss: 2.0031455556551614

Epoch: 409| Step: 0
Training loss: 0.22303998470306396
Validation loss: 2.055694341659546

Epoch: 6| Step: 1
Training loss: 0.13527819514274597
Validation loss: 2.021372656027476

Epoch: 6| Step: 2
Training loss: 0.499861478805542
Validation loss: 2.0286258459091187

Epoch: 6| Step: 3
Training loss: 0.37645137310028076
Validation loss: 1.9870147506395976

Epoch: 6| Step: 4
Training loss: 0.5573105812072754
Validation loss: 2.0255274971326194

Epoch: 6| Step: 5
Training loss: 0.2630922794342041
Validation loss: 1.9603611032168071

Epoch: 6| Step: 6
Training loss: 0.40821748971939087
Validation loss: 2.0072723031044006

Epoch: 6| Step: 7
Training loss: 0.48857930302619934
Validation loss: 1.9584593176841736

Epoch: 6| Step: 8
Training loss: 0.22952985763549805
Validation loss: 1.9584540526072185

Epoch: 6| Step: 9
Training loss: 0.21383686363697052
Validation loss: 1.9877566893895466

Epoch: 6| Step: 10
Training loss: 0.21031787991523743
Validation loss: 1.938370903333028

Epoch: 6| Step: 11
Training loss: 0.1814163774251938
Validation loss: 1.9822965463002522

Epoch: 6| Step: 12
Training loss: 0.2116795778274536
Validation loss: 1.9776697556177776

Epoch: 6| Step: 13
Training loss: 0.14595326781272888
Validation loss: 1.9639472365379333

Epoch: 410| Step: 0
Training loss: 0.4502093195915222
Validation loss: 1.982144872347514

Epoch: 6| Step: 1
Training loss: 0.3618738055229187
Validation loss: 1.9433800180753071

Epoch: 6| Step: 2
Training loss: 0.27907854318618774
Validation loss: 1.9972300132115681

Epoch: 6| Step: 3
Training loss: 0.32513439655303955
Validation loss: 1.9049763480822246

Epoch: 6| Step: 4
Training loss: 0.23739545047283173
Validation loss: 1.9767915805180867

Epoch: 6| Step: 5
Training loss: 0.6379438638687134
Validation loss: 2.004784564177195

Epoch: 6| Step: 6
Training loss: 0.27636027336120605
Validation loss: 2.009732166926066

Epoch: 6| Step: 7
Training loss: 0.31950053572654724
Validation loss: 1.9586073160171509

Epoch: 6| Step: 8
Training loss: 0.2991676330566406
Validation loss: 1.9725445707639058

Epoch: 6| Step: 9
Training loss: 0.2212601900100708
Validation loss: 1.9865802725156148

Epoch: 6| Step: 10
Training loss: 0.20282241702079773
Validation loss: 1.972248951594035

Epoch: 6| Step: 11
Training loss: 0.24008436501026154
Validation loss: 1.977955162525177

Epoch: 6| Step: 12
Training loss: 0.24679887294769287
Validation loss: 1.9944202899932861

Epoch: 6| Step: 13
Training loss: 0.20898659527301788
Validation loss: 1.959868888060252

Epoch: 411| Step: 0
Training loss: 0.22711092233657837
Validation loss: 1.9865725835164387

Epoch: 6| Step: 1
Training loss: 0.17495682835578918
Validation loss: 1.9659835894902546

Epoch: 6| Step: 2
Training loss: 0.5316352844238281
Validation loss: 2.0011231104532876

Epoch: 6| Step: 3
Training loss: 0.2921890318393707
Validation loss: 1.9980667233467102

Epoch: 6| Step: 4
Training loss: 0.31566184759140015
Validation loss: 2.0153994957605996

Epoch: 6| Step: 5
Training loss: 0.256219744682312
Validation loss: 1.9665594895680745

Epoch: 6| Step: 6
Training loss: 0.2737821340560913
Validation loss: 1.9745686848958333

Epoch: 6| Step: 7
Training loss: 0.23245951533317566
Validation loss: 1.97364075978597

Epoch: 6| Step: 8
Training loss: 0.3861154317855835
Validation loss: 1.9815614223480225

Epoch: 6| Step: 9
Training loss: 0.282595157623291
Validation loss: 1.9910118182500203

Epoch: 6| Step: 10
Training loss: 0.2701590657234192
Validation loss: 1.9760555227597554

Epoch: 6| Step: 11
Training loss: 0.24021995067596436
Validation loss: 1.9917115966478984

Epoch: 6| Step: 12
Training loss: 0.15575453639030457
Validation loss: 1.9929109414418538

Epoch: 6| Step: 13
Training loss: 0.6079020500183105
Validation loss: 1.988966445128123

Epoch: 412| Step: 0
Training loss: 0.3238479495048523
Validation loss: 2.0208725333213806

Epoch: 6| Step: 1
Training loss: 0.19267985224723816
Validation loss: 2.0521293679873147

Epoch: 6| Step: 2
Training loss: 0.21866169571876526
Validation loss: 2.01405131816864

Epoch: 6| Step: 3
Training loss: 0.2530454695224762
Validation loss: 2.00627609093984

Epoch: 6| Step: 4
Training loss: 0.2976358234882355
Validation loss: 2.0177165269851685

Epoch: 6| Step: 5
Training loss: 0.28205177187919617
Validation loss: 1.9281544089317322

Epoch: 6| Step: 6
Training loss: 0.3556000590324402
Validation loss: 1.9910653034845989

Epoch: 6| Step: 7
Training loss: 0.3380957245826721
Validation loss: 1.9759103059768677

Epoch: 6| Step: 8
Training loss: 0.22923991084098816
Validation loss: 2.008660395940145

Epoch: 6| Step: 9
Training loss: 0.6069328188896179
Validation loss: 2.0048433939615884

Epoch: 6| Step: 10
Training loss: 0.3778161406517029
Validation loss: 1.9549741546312969

Epoch: 6| Step: 11
Training loss: 0.41800326108932495
Validation loss: 1.9589741826057434

Epoch: 6| Step: 12
Training loss: 0.2974168062210083
Validation loss: 1.962065875530243

Epoch: 6| Step: 13
Training loss: 0.3267001509666443
Validation loss: 1.9871972600619

Epoch: 413| Step: 0
Training loss: 0.235354483127594
Validation loss: 1.9780180255572002

Epoch: 6| Step: 1
Training loss: 0.29031258821487427
Validation loss: 1.9793160756429036

Epoch: 6| Step: 2
Training loss: 0.2460843324661255
Validation loss: 2.00710662206014

Epoch: 6| Step: 3
Training loss: 0.22815977036952972
Validation loss: 2.027823289235433

Epoch: 6| Step: 4
Training loss: 0.252894788980484
Validation loss: 1.9851412971814473

Epoch: 6| Step: 5
Training loss: 0.5139978528022766
Validation loss: 2.020456155141195

Epoch: 6| Step: 6
Training loss: 0.16564685106277466
Validation loss: 1.987171749273936

Epoch: 6| Step: 7
Training loss: 0.21532967686653137
Validation loss: 1.9747843543688457

Epoch: 6| Step: 8
Training loss: 0.5233443379402161
Validation loss: 1.9830676317214966

Epoch: 6| Step: 9
Training loss: 0.2085544764995575
Validation loss: 2.0026437838872275

Epoch: 6| Step: 10
Training loss: 0.7349051237106323
Validation loss: 2.0300771792729697

Epoch: 6| Step: 11
Training loss: 0.23327985405921936
Validation loss: 1.979047695795695

Epoch: 6| Step: 12
Training loss: 0.33184516429901123
Validation loss: 1.963232437769572

Epoch: 6| Step: 13
Training loss: 0.27454662322998047
Validation loss: 1.966248055299123

Epoch: 414| Step: 0
Training loss: 0.26604634523391724
Validation loss: 1.9622645179430644

Epoch: 6| Step: 1
Training loss: 0.259161114692688
Validation loss: 1.9869391520818074

Epoch: 6| Step: 2
Training loss: 0.23834747076034546
Validation loss: 2.0047935247421265

Epoch: 6| Step: 3
Training loss: 0.23420760035514832
Validation loss: 1.9844541152318318

Epoch: 6| Step: 4
Training loss: 0.6584722399711609
Validation loss: 1.9879188140233357

Epoch: 6| Step: 5
Training loss: 0.24648280441761017
Validation loss: 1.9693411191304524

Epoch: 6| Step: 6
Training loss: 0.18112552165985107
Validation loss: 2.0061764121055603

Epoch: 6| Step: 7
Training loss: 0.19910186529159546
Validation loss: 2.004808227221171

Epoch: 6| Step: 8
Training loss: 0.22978883981704712
Validation loss: 1.947558323542277

Epoch: 6| Step: 9
Training loss: 0.5716589689254761
Validation loss: 2.015554666519165

Epoch: 6| Step: 10
Training loss: 0.22394424676895142
Validation loss: 2.0220426321029663

Epoch: 6| Step: 11
Training loss: 0.29065799713134766
Validation loss: 2.051034410794576

Epoch: 6| Step: 12
Training loss: 0.5281511545181274
Validation loss: 2.026867469151815

Epoch: 6| Step: 13
Training loss: 0.43492045998573303
Validation loss: 2.044404367605845

Epoch: 415| Step: 0
Training loss: 0.35445091128349304
Validation loss: 1.9921898245811462

Epoch: 6| Step: 1
Training loss: 0.31058934330940247
Validation loss: 2.0348392128944397

Epoch: 6| Step: 2
Training loss: 0.1951063871383667
Validation loss: 1.967725137869517

Epoch: 6| Step: 3
Training loss: 0.23672540485858917
Validation loss: 1.9869439999262493

Epoch: 6| Step: 4
Training loss: 0.4852001368999481
Validation loss: 1.9728745818138123

Epoch: 6| Step: 5
Training loss: 0.19953477382659912
Validation loss: 1.9900754690170288

Epoch: 6| Step: 6
Training loss: 0.3263399004936218
Validation loss: 1.983940303325653

Epoch: 6| Step: 7
Training loss: 0.42261576652526855
Validation loss: 2.004940072695414

Epoch: 6| Step: 8
Training loss: 0.6997671127319336
Validation loss: 1.96287606159846

Epoch: 6| Step: 9
Training loss: 0.15892884135246277
Validation loss: 1.9853580792744954

Epoch: 6| Step: 10
Training loss: 0.377076655626297
Validation loss: 1.9569436311721802

Epoch: 6| Step: 11
Training loss: 0.2716754376888275
Validation loss: 1.963532308737437

Epoch: 6| Step: 12
Training loss: 0.23251454532146454
Validation loss: 1.9694688717524211

Epoch: 6| Step: 13
Training loss: 0.1772335022687912
Validation loss: 1.9640361666679382

Epoch: 416| Step: 0
Training loss: 0.23325824737548828
Validation loss: 1.9903552134831746

Epoch: 6| Step: 1
Training loss: 0.3918476700782776
Validation loss: 2.000553031762441

Epoch: 6| Step: 2
Training loss: 0.2749738395214081
Validation loss: 2.032881021499634

Epoch: 6| Step: 3
Training loss: 0.29159611463546753
Validation loss: 2.003820021947225

Epoch: 6| Step: 4
Training loss: 0.20449061691761017
Validation loss: 1.9804495175679524

Epoch: 6| Step: 5
Training loss: 0.8002309799194336
Validation loss: 1.979404052098592

Epoch: 6| Step: 6
Training loss: 0.47408154606819153
Validation loss: 1.961950143178304

Epoch: 6| Step: 7
Training loss: 0.26410186290740967
Validation loss: 1.9831620653470357

Epoch: 6| Step: 8
Training loss: 0.19274765253067017
Validation loss: 1.9830154180526733

Epoch: 6| Step: 9
Training loss: 0.2831941843032837
Validation loss: 1.993347942829132

Epoch: 6| Step: 10
Training loss: 0.416146844625473
Validation loss: 1.9796822468439739

Epoch: 6| Step: 11
Training loss: 0.2879219651222229
Validation loss: 1.9293453693389893

Epoch: 6| Step: 12
Training loss: 0.18890684843063354
Validation loss: 1.9719500541687012

Epoch: 6| Step: 13
Training loss: 0.2442704141139984
Validation loss: 1.972192645072937

Epoch: 417| Step: 0
Training loss: 0.7278515696525574
Validation loss: 1.9874804417292278

Epoch: 6| Step: 1
Training loss: 0.22492747008800507
Validation loss: 1.9670416514078777

Epoch: 6| Step: 2
Training loss: 0.21927300095558167
Validation loss: 1.9643336335817974

Epoch: 6| Step: 3
Training loss: 0.4644981026649475
Validation loss: 1.9785165389378865

Epoch: 6| Step: 4
Training loss: 0.4877566993236542
Validation loss: 1.9163589477539062

Epoch: 6| Step: 5
Training loss: 0.32365548610687256
Validation loss: 1.973052402337392

Epoch: 6| Step: 6
Training loss: 0.3194199204444885
Validation loss: 1.95671280225118

Epoch: 6| Step: 7
Training loss: 0.26764243841171265
Validation loss: 1.9791395664215088

Epoch: 6| Step: 8
Training loss: 0.1312757432460785
Validation loss: 2.004118720690409

Epoch: 6| Step: 9
Training loss: 0.31992655992507935
Validation loss: 2.029339691003164

Epoch: 6| Step: 10
Training loss: 0.2836490571498871
Validation loss: 1.9614771207173665

Epoch: 6| Step: 11
Training loss: 0.23583060503005981
Validation loss: 1.989665428797404

Epoch: 6| Step: 12
Training loss: 0.31573429703712463
Validation loss: 2.001226266225179

Epoch: 6| Step: 13
Training loss: 0.28723835945129395
Validation loss: 1.9989012082417805

Epoch: 418| Step: 0
Training loss: 0.2311980277299881
Validation loss: 1.9848532478014629

Epoch: 6| Step: 1
Training loss: 0.3884836435317993
Validation loss: 1.9907313386599224

Epoch: 6| Step: 2
Training loss: 0.3667083978652954
Validation loss: 1.9748400847117107

Epoch: 6| Step: 3
Training loss: 0.1851205825805664
Validation loss: 1.9750331838925679

Epoch: 6| Step: 4
Training loss: 0.2238565981388092
Validation loss: 2.0311467051506042

Epoch: 6| Step: 5
Training loss: 0.16802698373794556
Validation loss: 1.9805354475975037

Epoch: 6| Step: 6
Training loss: 0.23371651768684387
Validation loss: 2.020781675974528

Epoch: 6| Step: 7
Training loss: 0.24724137783050537
Validation loss: 2.0094528992970786

Epoch: 6| Step: 8
Training loss: 0.31797337532043457
Validation loss: 1.9786012768745422

Epoch: 6| Step: 9
Training loss: 0.23936530947685242
Validation loss: 2.0319946010907493

Epoch: 6| Step: 10
Training loss: 0.8019707798957825
Validation loss: 1.9809378385543823

Epoch: 6| Step: 11
Training loss: 0.2072995901107788
Validation loss: 1.9638782342274983

Epoch: 6| Step: 12
Training loss: 0.4372442066669464
Validation loss: 1.976503034432729

Epoch: 6| Step: 13
Training loss: 0.2571018934249878
Validation loss: 1.9790870348612468

Epoch: 419| Step: 0
Training loss: 0.3637799620628357
Validation loss: 1.9785907467206318

Epoch: 6| Step: 1
Training loss: 0.24526113271713257
Validation loss: 1.9964364171028137

Epoch: 6| Step: 2
Training loss: 0.2701975107192993
Validation loss: 2.0110063354174295

Epoch: 6| Step: 3
Training loss: 0.22278596460819244
Validation loss: 2.0036911567052207

Epoch: 6| Step: 4
Training loss: 0.3292805552482605
Validation loss: 2.015020410219828

Epoch: 6| Step: 5
Training loss: 0.160011887550354
Validation loss: 1.9813029567400615

Epoch: 6| Step: 6
Training loss: 0.23253178596496582
Validation loss: 1.9471311171849568

Epoch: 6| Step: 7
Training loss: 0.276637464761734
Validation loss: 2.0017122427622476

Epoch: 6| Step: 8
Training loss: 0.4824534058570862
Validation loss: 2.0070850451787314

Epoch: 6| Step: 9
Training loss: 0.17407849431037903
Validation loss: 2.0394191344579062

Epoch: 6| Step: 10
Training loss: 0.26968157291412354
Validation loss: 2.007166882356008

Epoch: 6| Step: 11
Training loss: 0.563908040523529
Validation loss: 1.9950714111328125

Epoch: 6| Step: 12
Training loss: 0.11959873139858246
Validation loss: 1.9705666899681091

Epoch: 6| Step: 13
Training loss: 0.3109586238861084
Validation loss: 1.9904242952664692

Epoch: 420| Step: 0
Training loss: 0.34151798486709595
Validation loss: 1.9920035203297932

Epoch: 6| Step: 1
Training loss: 0.36479032039642334
Validation loss: 1.9999590714772542

Epoch: 6| Step: 2
Training loss: 0.2909483313560486
Validation loss: 2.0039956172307334

Epoch: 6| Step: 3
Training loss: 0.3044605851173401
Validation loss: 2.0061452190081277

Epoch: 6| Step: 4
Training loss: 0.21033889055252075
Validation loss: 1.9957358638445537

Epoch: 6| Step: 5
Training loss: 0.5896278619766235
Validation loss: 1.9963258703549702

Epoch: 6| Step: 6
Training loss: 0.2685004472732544
Validation loss: 1.9792176485061646

Epoch: 6| Step: 7
Training loss: 0.4472450911998749
Validation loss: 1.9681629141171773

Epoch: 6| Step: 8
Training loss: 0.34300220012664795
Validation loss: 1.9870392084121704

Epoch: 6| Step: 9
Training loss: 0.19359347224235535
Validation loss: 1.993381102879842

Epoch: 6| Step: 10
Training loss: 0.2501503527164459
Validation loss: 1.9654625058174133

Epoch: 6| Step: 11
Training loss: 0.2796625792980194
Validation loss: 2.0034061272939048

Epoch: 6| Step: 12
Training loss: 0.27885371446609497
Validation loss: 1.9583455721537273

Epoch: 6| Step: 13
Training loss: 0.3114033341407776
Validation loss: 1.9579580823580425

Epoch: 421| Step: 0
Training loss: 0.3627920150756836
Validation loss: 1.9925219813982646

Epoch: 6| Step: 1
Training loss: 0.3430671691894531
Validation loss: 1.984973132610321

Epoch: 6| Step: 2
Training loss: 0.20107749104499817
Validation loss: 1.9654880166053772

Epoch: 6| Step: 3
Training loss: 0.34964561462402344
Validation loss: 1.9572752714157104

Epoch: 6| Step: 4
Training loss: 0.21193960309028625
Validation loss: 1.982539216677348

Epoch: 6| Step: 5
Training loss: 0.2759672999382019
Validation loss: 1.9674182931582134

Epoch: 6| Step: 6
Training loss: 0.29483285546302795
Validation loss: 1.9949597716331482

Epoch: 6| Step: 7
Training loss: 0.17612075805664062
Validation loss: 2.031855881214142

Epoch: 6| Step: 8
Training loss: 0.2637288570404053
Validation loss: 1.9914007981618245

Epoch: 6| Step: 9
Training loss: 0.4409008324146271
Validation loss: 2.010950485865275

Epoch: 6| Step: 10
Training loss: 0.29090434312820435
Validation loss: 1.9755538900693257

Epoch: 6| Step: 11
Training loss: 0.28211671113967896
Validation loss: 1.9855643113454182

Epoch: 6| Step: 12
Training loss: 0.6535094380378723
Validation loss: 1.976677676041921

Epoch: 6| Step: 13
Training loss: 0.1325429379940033
Validation loss: 2.0040449698766074

Epoch: 422| Step: 0
Training loss: 0.3641592264175415
Validation loss: 2.013976573944092

Epoch: 6| Step: 1
Training loss: 0.28113532066345215
Validation loss: 1.9709902207056682

Epoch: 6| Step: 2
Training loss: 0.7072261571884155
Validation loss: 1.9681243499120076

Epoch: 6| Step: 3
Training loss: 0.35310855507850647
Validation loss: 1.9474393924077351

Epoch: 6| Step: 4
Training loss: 0.3185960650444031
Validation loss: 1.9715444644292195

Epoch: 6| Step: 5
Training loss: 0.23198311030864716
Validation loss: 1.9575048883756

Epoch: 6| Step: 6
Training loss: 0.2815564274787903
Validation loss: 1.985879083474477

Epoch: 6| Step: 7
Training loss: 0.43852585554122925
Validation loss: 1.9865400989850361

Epoch: 6| Step: 8
Training loss: 0.11477123945951462
Validation loss: 1.9766710599263508

Epoch: 6| Step: 9
Training loss: 0.21808978915214539
Validation loss: 2.046917279561361

Epoch: 6| Step: 10
Training loss: 0.32483506202697754
Validation loss: 1.955370823542277

Epoch: 6| Step: 11
Training loss: 0.21092170476913452
Validation loss: 1.9871502717336018

Epoch: 6| Step: 12
Training loss: 0.21613453328609467
Validation loss: 2.0227091312408447

Epoch: 6| Step: 13
Training loss: 0.27572447061538696
Validation loss: 1.9962010582288106

Epoch: 423| Step: 0
Training loss: 0.2694815695285797
Validation loss: 1.9925198157628377

Epoch: 6| Step: 1
Training loss: 0.4633064568042755
Validation loss: 1.9935128887494404

Epoch: 6| Step: 2
Training loss: 0.2956699728965759
Validation loss: 2.0140596628189087

Epoch: 6| Step: 3
Training loss: 0.1414790153503418
Validation loss: 1.9932586550712585

Epoch: 6| Step: 4
Training loss: 0.28820180892944336
Validation loss: 2.048972725868225

Epoch: 6| Step: 5
Training loss: 0.6473994255065918
Validation loss: 2.0125351548194885

Epoch: 6| Step: 6
Training loss: 0.2491653859615326
Validation loss: 2.0218677322069802

Epoch: 6| Step: 7
Training loss: 0.4821833670139313
Validation loss: 1.9932655692100525

Epoch: 6| Step: 8
Training loss: 0.4662688970565796
Validation loss: 2.0343851447105408

Epoch: 6| Step: 9
Training loss: 0.2381572723388672
Validation loss: 2.007507006327311

Epoch: 6| Step: 10
Training loss: 0.17544373869895935
Validation loss: 1.992543339729309

Epoch: 6| Step: 11
Training loss: 0.4248625636100769
Validation loss: 2.021146237850189

Epoch: 6| Step: 12
Training loss: 0.27414700388908386
Validation loss: 2.0225187142690024

Epoch: 6| Step: 13
Training loss: 0.2287309169769287
Validation loss: 1.987448553244273

Epoch: 424| Step: 0
Training loss: 0.37630826234817505
Validation loss: 2.002077261606852

Epoch: 6| Step: 1
Training loss: 0.21774674952030182
Validation loss: 2.0342662731806436

Epoch: 6| Step: 2
Training loss: 0.3481183350086212
Validation loss: 2.0061647295951843

Epoch: 6| Step: 3
Training loss: 0.3378497362136841
Validation loss: 1.992042322953542

Epoch: 6| Step: 4
Training loss: 0.2010432481765747
Validation loss: 2.0106719732284546

Epoch: 6| Step: 5
Training loss: 0.47161248326301575
Validation loss: 2.0216493209203086

Epoch: 6| Step: 6
Training loss: 0.28910088539123535
Validation loss: 1.995528777440389

Epoch: 6| Step: 7
Training loss: 0.1991504728794098
Validation loss: 1.9793225924173992

Epoch: 6| Step: 8
Training loss: 0.424075722694397
Validation loss: 2.0349552035331726

Epoch: 6| Step: 9
Training loss: 0.2728680372238159
Validation loss: 2.0243346293767295

Epoch: 6| Step: 10
Training loss: 0.1840471774339676
Validation loss: 2.034731924533844

Epoch: 6| Step: 11
Training loss: 0.25560885667800903
Validation loss: 1.9881766835848491

Epoch: 6| Step: 12
Training loss: 0.1969970166683197
Validation loss: 1.9722793499628704

Epoch: 6| Step: 13
Training loss: 0.6784948706626892
Validation loss: 2.025129020214081

Epoch: 425| Step: 0
Training loss: 0.20264016091823578
Validation loss: 2.0413484374682107

Epoch: 6| Step: 1
Training loss: 0.15655864775180817
Validation loss: 1.9725405375162761

Epoch: 6| Step: 2
Training loss: 0.3097638785839081
Validation loss: 1.983173171679179

Epoch: 6| Step: 3
Training loss: 0.25071853399276733
Validation loss: 1.9778155883153279

Epoch: 6| Step: 4
Training loss: 0.21636679768562317
Validation loss: 2.0009127060572305

Epoch: 6| Step: 5
Training loss: 0.27010005712509155
Validation loss: 1.997977117697398

Epoch: 6| Step: 6
Training loss: 0.2035869061946869
Validation loss: 1.9952977498372395

Epoch: 6| Step: 7
Training loss: 0.2228735387325287
Validation loss: 1.9912570317586262

Epoch: 6| Step: 8
Training loss: 0.6452541947364807
Validation loss: 1.9830057621002197

Epoch: 6| Step: 9
Training loss: 0.3349383473396301
Validation loss: 1.9738558133443196

Epoch: 6| Step: 10
Training loss: 0.22922278940677643
Validation loss: 1.9816699822743733

Epoch: 6| Step: 11
Training loss: 0.3394107222557068
Validation loss: 1.9988354444503784

Epoch: 6| Step: 12
Training loss: 0.3353046476840973
Validation loss: 2.0002294977506003

Epoch: 6| Step: 13
Training loss: 0.23995116353034973
Validation loss: 1.9966381788253784

Epoch: 426| Step: 0
Training loss: 0.339746356010437
Validation loss: 2.0299325188001

Epoch: 6| Step: 1
Training loss: 0.2865687906742096
Validation loss: 1.99764084815979

Epoch: 6| Step: 2
Training loss: 0.21620365977287292
Validation loss: 1.9887638092041016

Epoch: 6| Step: 3
Training loss: 0.36684197187423706
Validation loss: 1.9820220271746318

Epoch: 6| Step: 4
Training loss: 0.26071467995643616
Validation loss: 2.0057444969813027

Epoch: 6| Step: 5
Training loss: 0.1635672003030777
Validation loss: 1.9846401611963909

Epoch: 6| Step: 6
Training loss: 0.17611795663833618
Validation loss: 2.003707706928253

Epoch: 6| Step: 7
Training loss: 0.14859019219875336
Validation loss: 1.9735970894495647

Epoch: 6| Step: 8
Training loss: 0.6778962016105652
Validation loss: 1.9822559158007305

Epoch: 6| Step: 9
Training loss: 0.23701846599578857
Validation loss: 2.0058787862459817

Epoch: 6| Step: 10
Training loss: 0.5279501676559448
Validation loss: 1.9913053115208943

Epoch: 6| Step: 11
Training loss: 0.13745741546154022
Validation loss: 2.0021362702051797

Epoch: 6| Step: 12
Training loss: 0.26564234495162964
Validation loss: 1.9983481963475545

Epoch: 6| Step: 13
Training loss: 0.3469734191894531
Validation loss: 2.0150162974993386

Epoch: 427| Step: 0
Training loss: 0.24935747683048248
Validation loss: 2.014036695162455

Epoch: 6| Step: 1
Training loss: 0.3472527265548706
Validation loss: 2.023172934850057

Epoch: 6| Step: 2
Training loss: 0.20004525780677795
Validation loss: 1.9860794146855671

Epoch: 6| Step: 3
Training loss: 0.20334722101688385
Validation loss: 1.9996221661567688

Epoch: 6| Step: 4
Training loss: 0.6226251125335693
Validation loss: 1.9536720911661785

Epoch: 6| Step: 5
Training loss: 0.23755131661891937
Validation loss: 1.9792774518330891

Epoch: 6| Step: 6
Training loss: 0.35792165994644165
Validation loss: 1.9970173438390095

Epoch: 6| Step: 7
Training loss: 0.2698242962360382
Validation loss: 2.0510648290316262

Epoch: 6| Step: 8
Training loss: 0.6107105016708374
Validation loss: 1.973047176996867

Epoch: 6| Step: 9
Training loss: 0.2986779808998108
Validation loss: 1.9551507234573364

Epoch: 6| Step: 10
Training loss: 0.16699734330177307
Validation loss: 2.0225825707117715

Epoch: 6| Step: 11
Training loss: 0.282036155462265
Validation loss: 1.9901096423467

Epoch: 6| Step: 12
Training loss: 0.2744100093841553
Validation loss: 1.975386381149292

Epoch: 6| Step: 13
Training loss: 0.2612345516681671
Validation loss: 2.0044265190760293

Epoch: 428| Step: 0
Training loss: 0.20598343014717102
Validation loss: 2.004113773504893

Epoch: 6| Step: 1
Training loss: 0.2591053247451782
Validation loss: 2.038410405317942

Epoch: 6| Step: 2
Training loss: 0.1475105881690979
Validation loss: 2.014283458391825

Epoch: 6| Step: 3
Training loss: 0.20365557074546814
Validation loss: 1.9814984202384949

Epoch: 6| Step: 4
Training loss: 0.356190025806427
Validation loss: 2.014351725578308

Epoch: 6| Step: 5
Training loss: 0.4472775459289551
Validation loss: 2.014056921005249

Epoch: 6| Step: 6
Training loss: 0.2242146134376526
Validation loss: 2.011390427748362

Epoch: 6| Step: 7
Training loss: 0.6116838455200195
Validation loss: 1.997612198193868

Epoch: 6| Step: 8
Training loss: 0.1594299077987671
Validation loss: 2.033320585886637

Epoch: 6| Step: 9
Training loss: 0.29900598526000977
Validation loss: 2.013164738814036

Epoch: 6| Step: 10
Training loss: 0.3790229558944702
Validation loss: 2.027113914489746

Epoch: 6| Step: 11
Training loss: 0.27523180842399597
Validation loss: 2.0260124802589417

Epoch: 6| Step: 12
Training loss: 0.5205552577972412
Validation loss: 2.0121766328811646

Epoch: 6| Step: 13
Training loss: 0.2226870208978653
Validation loss: 1.9948285420735676

Epoch: 429| Step: 0
Training loss: 0.5405094623565674
Validation loss: 2.007339676221212

Epoch: 6| Step: 1
Training loss: 0.2956938147544861
Validation loss: 2.0267882148424783

Epoch: 6| Step: 2
Training loss: 0.32735174894332886
Validation loss: 2.0203558206558228

Epoch: 6| Step: 3
Training loss: 0.30240732431411743
Validation loss: 2.0110528469085693

Epoch: 6| Step: 4
Training loss: 0.33147597312927246
Validation loss: 2.0151033202807107

Epoch: 6| Step: 5
Training loss: 0.24926981329917908
Validation loss: 2.0404849847157798

Epoch: 6| Step: 6
Training loss: 0.30413562059402466
Validation loss: 2.029105246067047

Epoch: 6| Step: 7
Training loss: 0.6523635387420654
Validation loss: 2.018889009952545

Epoch: 6| Step: 8
Training loss: 0.2182520031929016
Validation loss: 2.0268261432647705

Epoch: 6| Step: 9
Training loss: 0.2043314278125763
Validation loss: 2.0123590429623923

Epoch: 6| Step: 10
Training loss: 0.1802307516336441
Validation loss: 2.043006102244059

Epoch: 6| Step: 11
Training loss: 0.21473506093025208
Validation loss: 2.0137344002723694

Epoch: 6| Step: 12
Training loss: 0.34723204374313354
Validation loss: 2.046671152114868

Epoch: 6| Step: 13
Training loss: 0.15541742742061615
Validation loss: 1.9914445678393047

Epoch: 430| Step: 0
Training loss: 0.39355143904685974
Validation loss: 2.0337573885917664

Epoch: 6| Step: 1
Training loss: 0.2263110876083374
Validation loss: 2.027887503306071

Epoch: 6| Step: 2
Training loss: 0.7202756404876709
Validation loss: 2.028715888659159

Epoch: 6| Step: 3
Training loss: 0.25903332233428955
Validation loss: 2.0078179041544595

Epoch: 6| Step: 4
Training loss: 0.35403549671173096
Validation loss: 1.9798334042231243

Epoch: 6| Step: 5
Training loss: 0.4003157913684845
Validation loss: 1.9858669837315877

Epoch: 6| Step: 6
Training loss: 0.2412179410457611
Validation loss: 1.9994757572809856

Epoch: 6| Step: 7
Training loss: 0.14613516628742218
Validation loss: 2.008608857790629

Epoch: 6| Step: 8
Training loss: 0.246360182762146
Validation loss: 2.0156430204709372

Epoch: 6| Step: 9
Training loss: 0.24024708569049835
Validation loss: 2.0033952792485556

Epoch: 6| Step: 10
Training loss: 0.17870484292507172
Validation loss: 1.9720911979675293

Epoch: 6| Step: 11
Training loss: 0.4974747896194458
Validation loss: 2.009710967540741

Epoch: 6| Step: 12
Training loss: 0.20502512156963348
Validation loss: 1.9894034663836162

Epoch: 6| Step: 13
Training loss: 0.38261979818344116
Validation loss: 1.9769029815991719

Epoch: 431| Step: 0
Training loss: 0.2921092212200165
Validation loss: 2.00590048233668

Epoch: 6| Step: 1
Training loss: 0.41083019971847534
Validation loss: 1.9679035345713298

Epoch: 6| Step: 2
Training loss: 0.17665813863277435
Validation loss: 2.0108909606933594

Epoch: 6| Step: 3
Training loss: 0.6130179166793823
Validation loss: 1.9394514759381611

Epoch: 6| Step: 4
Training loss: 0.34367138147354126
Validation loss: 2.019567847251892

Epoch: 6| Step: 5
Training loss: 0.3747069835662842
Validation loss: 2.0050694942474365

Epoch: 6| Step: 6
Training loss: 0.28597694635391235
Validation loss: 1.9929599364598591

Epoch: 6| Step: 7
Training loss: 0.19214299321174622
Validation loss: 2.029642164707184

Epoch: 6| Step: 8
Training loss: 0.20229440927505493
Validation loss: 1.9801668524742126

Epoch: 6| Step: 9
Training loss: 0.16332273185253143
Validation loss: 1.9870683153470357

Epoch: 6| Step: 10
Training loss: 0.3074676990509033
Validation loss: 2.012977143128713

Epoch: 6| Step: 11
Training loss: 0.2428005486726761
Validation loss: 1.9859216610590618

Epoch: 6| Step: 12
Training loss: 0.2080906331539154
Validation loss: 2.008336067199707

Epoch: 6| Step: 13
Training loss: 0.3891863524913788
Validation loss: 1.987383206685384

Epoch: 432| Step: 0
Training loss: 0.41687625646591187
Validation loss: 1.9697965582211812

Epoch: 6| Step: 1
Training loss: 0.3070260286331177
Validation loss: 2.0223601857821145

Epoch: 6| Step: 2
Training loss: 0.36196640133857727
Validation loss: 2.007406731446584

Epoch: 6| Step: 3
Training loss: 0.2542971968650818
Validation loss: 2.0015809535980225

Epoch: 6| Step: 4
Training loss: 0.3932758867740631
Validation loss: 2.018732269605001

Epoch: 6| Step: 5
Training loss: 0.2691895365715027
Validation loss: 1.9801224271456401

Epoch: 6| Step: 6
Training loss: 0.624752402305603
Validation loss: 2.023471792538961

Epoch: 6| Step: 7
Training loss: 0.21390649676322937
Validation loss: 1.9689605037371318

Epoch: 6| Step: 8
Training loss: 0.2899625897407532
Validation loss: 1.9807735085487366

Epoch: 6| Step: 9
Training loss: 0.17302757501602173
Validation loss: 2.005740761756897

Epoch: 6| Step: 10
Training loss: 0.21230758726596832
Validation loss: 1.9468727906545003

Epoch: 6| Step: 11
Training loss: 0.34465405344963074
Validation loss: 1.9714927673339844

Epoch: 6| Step: 12
Training loss: 0.2485983818769455
Validation loss: 2.031865874926249

Epoch: 6| Step: 13
Training loss: 0.26170945167541504
Validation loss: 2.046160101890564

Epoch: 433| Step: 0
Training loss: 0.17901141941547394
Validation loss: 2.0276987751324973

Epoch: 6| Step: 1
Training loss: 0.350879430770874
Validation loss: 2.00822377204895

Epoch: 6| Step: 2
Training loss: 0.1957697868347168
Validation loss: 1.999735673268636

Epoch: 6| Step: 3
Training loss: 0.32829010486602783
Validation loss: 2.002166827519735

Epoch: 6| Step: 4
Training loss: 0.17067600786685944
Validation loss: 2.0033594171206155

Epoch: 6| Step: 5
Training loss: 0.2680201232433319
Validation loss: 2.0193766951560974

Epoch: 6| Step: 6
Training loss: 0.21593739092350006
Validation loss: 2.0319827795028687

Epoch: 6| Step: 7
Training loss: 0.3253166675567627
Validation loss: 1.989235778649648

Epoch: 6| Step: 8
Training loss: 0.6010729670524597
Validation loss: 1.9840759833653767

Epoch: 6| Step: 9
Training loss: 0.3355201780796051
Validation loss: 2.0051560203234353

Epoch: 6| Step: 10
Training loss: 0.28975996375083923
Validation loss: 2.0121508836746216

Epoch: 6| Step: 11
Training loss: 0.18930336833000183
Validation loss: 1.9979433019955952

Epoch: 6| Step: 12
Training loss: 0.4000472128391266
Validation loss: 2.0250989198684692

Epoch: 6| Step: 13
Training loss: 0.20388947427272797
Validation loss: 2.0083201130231223

Epoch: 434| Step: 0
Training loss: 0.6104608178138733
Validation loss: 2.0001710057258606

Epoch: 6| Step: 1
Training loss: 0.31125885248184204
Validation loss: 2.0121850768725076

Epoch: 6| Step: 2
Training loss: 0.2244177609682083
Validation loss: 2.01507576306661

Epoch: 6| Step: 3
Training loss: 0.28709542751312256
Validation loss: 2.0047019720077515

Epoch: 6| Step: 4
Training loss: 0.3795892894268036
Validation loss: 2.064584950606028

Epoch: 6| Step: 5
Training loss: 0.31388264894485474
Validation loss: 2.0069310665130615

Epoch: 6| Step: 6
Training loss: 0.5551812648773193
Validation loss: 2.080833673477173

Epoch: 6| Step: 7
Training loss: 0.26829418540000916
Validation loss: 1.9910892645517986

Epoch: 6| Step: 8
Training loss: 0.2542053461074829
Validation loss: 1.9989131490389507

Epoch: 6| Step: 9
Training loss: 0.20176269114017487
Validation loss: 1.9999799132347107

Epoch: 6| Step: 10
Training loss: 0.14294597506523132
Validation loss: 1.9948535958925884

Epoch: 6| Step: 11
Training loss: 0.16807320713996887
Validation loss: 2.0046010414759317

Epoch: 6| Step: 12
Training loss: 0.2820964455604553
Validation loss: 1.9782926241556804

Epoch: 6| Step: 13
Training loss: 0.3765798509120941
Validation loss: 1.9823183417320251

Epoch: 435| Step: 0
Training loss: 0.309710294008255
Validation loss: 2.017242352167765

Epoch: 6| Step: 1
Training loss: 0.5255805253982544
Validation loss: 1.9880003333091736

Epoch: 6| Step: 2
Training loss: 0.2799893021583557
Validation loss: 1.9828680753707886

Epoch: 6| Step: 3
Training loss: 0.23033133149147034
Validation loss: 1.9822459022204082

Epoch: 6| Step: 4
Training loss: 0.21794918179512024
Validation loss: 1.939047594865163

Epoch: 6| Step: 5
Training loss: 0.2677944004535675
Validation loss: 1.9901663859685261

Epoch: 6| Step: 6
Training loss: 0.2201235592365265
Validation loss: 1.976424237092336

Epoch: 6| Step: 7
Training loss: 0.2662234306335449
Validation loss: 2.0198650558789573

Epoch: 6| Step: 8
Training loss: 0.6717372536659241
Validation loss: 1.980729619661967

Epoch: 6| Step: 9
Training loss: 0.30132681131362915
Validation loss: 1.9728080828984578

Epoch: 6| Step: 10
Training loss: 0.38377106189727783
Validation loss: 1.9707269271214802

Epoch: 6| Step: 11
Training loss: 0.2038983553647995
Validation loss: 1.9920919140179951

Epoch: 6| Step: 12
Training loss: 0.22519159317016602
Validation loss: 1.9897388815879822

Epoch: 6| Step: 13
Training loss: 0.34799864888191223
Validation loss: 2.027390937010447

Epoch: 436| Step: 0
Training loss: 0.40015164017677307
Validation loss: 2.012682537237803

Epoch: 6| Step: 1
Training loss: 0.2614246606826782
Validation loss: 2.003688116868337

Epoch: 6| Step: 2
Training loss: 0.19215498864650726
Validation loss: 2.0047672589619956

Epoch: 6| Step: 3
Training loss: 0.1710757613182068
Validation loss: 2.0447162985801697

Epoch: 6| Step: 4
Training loss: 0.35269278287887573
Validation loss: 2.019843498865763

Epoch: 6| Step: 5
Training loss: 0.47950875759124756
Validation loss: 1.9824493130048115

Epoch: 6| Step: 6
Training loss: 0.3514644503593445
Validation loss: 2.0256135861078897

Epoch: 6| Step: 7
Training loss: 0.30196845531463623
Validation loss: 1.9880491693814595

Epoch: 6| Step: 8
Training loss: 0.7000123262405396
Validation loss: 1.9604803522427876

Epoch: 6| Step: 9
Training loss: 0.30832403898239136
Validation loss: 2.009001394112905

Epoch: 6| Step: 10
Training loss: 0.17458923161029816
Validation loss: 1.9721320271492004

Epoch: 6| Step: 11
Training loss: 0.21001094579696655
Validation loss: 2.000190019607544

Epoch: 6| Step: 12
Training loss: 0.25405728816986084
Validation loss: 1.996448040008545

Epoch: 6| Step: 13
Training loss: 0.33127927780151367
Validation loss: 2.00168506304423

Epoch: 437| Step: 0
Training loss: 0.48619282245635986
Validation loss: 2.031757334868113

Epoch: 6| Step: 1
Training loss: 0.35777610540390015
Validation loss: 2.0025052626927695

Epoch: 6| Step: 2
Training loss: 0.26158958673477173
Validation loss: 1.9973904887835185

Epoch: 6| Step: 3
Training loss: 0.19545647501945496
Validation loss: 1.9905627568562825

Epoch: 6| Step: 4
Training loss: 0.2426663637161255
Validation loss: 2.0134682655334473

Epoch: 6| Step: 5
Training loss: 0.2246880680322647
Validation loss: 1.9909009138743083

Epoch: 6| Step: 6
Training loss: 0.29152780771255493
Validation loss: 1.9941206971804302

Epoch: 6| Step: 7
Training loss: 0.24995136260986328
Validation loss: 1.9964086214701335

Epoch: 6| Step: 8
Training loss: 0.6182412505149841
Validation loss: 2.041205406188965

Epoch: 6| Step: 9
Training loss: 0.5507220029830933
Validation loss: 1.9827859997749329

Epoch: 6| Step: 10
Training loss: 0.21934282779693604
Validation loss: 2.0209640860557556

Epoch: 6| Step: 11
Training loss: 0.40064406394958496
Validation loss: 1.986370364824931

Epoch: 6| Step: 12
Training loss: 0.2612721920013428
Validation loss: 2.0043744444847107

Epoch: 6| Step: 13
Training loss: 0.2442086786031723
Validation loss: 1.9859262506167095

Epoch: 438| Step: 0
Training loss: 0.18913879990577698
Validation loss: 1.967163364092509

Epoch: 6| Step: 1
Training loss: 0.38035666942596436
Validation loss: 1.9837643504142761

Epoch: 6| Step: 2
Training loss: 0.2731417119503021
Validation loss: 1.9715561668078105

Epoch: 6| Step: 3
Training loss: 0.19280403852462769
Validation loss: 1.9641276399294536

Epoch: 6| Step: 4
Training loss: 0.25520360469818115
Validation loss: 2.0045646031697593

Epoch: 6| Step: 5
Training loss: 0.258176326751709
Validation loss: 1.9794698357582092

Epoch: 6| Step: 6
Training loss: 0.38618725538253784
Validation loss: 2.0036269625027976

Epoch: 6| Step: 7
Training loss: 0.32851263880729675
Validation loss: 1.9913113315900166

Epoch: 6| Step: 8
Training loss: 0.1757926642894745
Validation loss: 2.023305614789327

Epoch: 6| Step: 9
Training loss: 0.3200957775115967
Validation loss: 1.9755014578501384

Epoch: 6| Step: 10
Training loss: 0.22895166277885437
Validation loss: 1.9833251039187114

Epoch: 6| Step: 11
Training loss: 0.1934296041727066
Validation loss: 1.99373060464859

Epoch: 6| Step: 12
Training loss: 0.6281442046165466
Validation loss: 1.961309015750885

Epoch: 6| Step: 13
Training loss: 0.27676844596862793
Validation loss: 1.9621107180913289

Epoch: 439| Step: 0
Training loss: 0.20073005557060242
Validation loss: 1.9531827370325725

Epoch: 6| Step: 1
Training loss: 0.25210440158843994
Validation loss: 1.9893129269282024

Epoch: 6| Step: 2
Training loss: 0.3817054033279419
Validation loss: 2.023220340410868

Epoch: 6| Step: 3
Training loss: 0.2632242441177368
Validation loss: 1.996093471844991

Epoch: 6| Step: 4
Training loss: 0.3334888815879822
Validation loss: 1.9850550293922424

Epoch: 6| Step: 5
Training loss: 0.23682838678359985
Validation loss: 1.9878226319948833

Epoch: 6| Step: 6
Training loss: 0.37064507603645325
Validation loss: 1.9638684789339702

Epoch: 6| Step: 7
Training loss: 0.24740415811538696
Validation loss: 1.9698812663555145

Epoch: 6| Step: 8
Training loss: 0.24691925942897797
Validation loss: 2.0120541055997214

Epoch: 6| Step: 9
Training loss: 0.8731340765953064
Validation loss: 2.0288042426109314

Epoch: 6| Step: 10
Training loss: 0.23009778559207916
Validation loss: 1.9978652199109395

Epoch: 6| Step: 11
Training loss: 0.23811230063438416
Validation loss: 2.0197286208470664

Epoch: 6| Step: 12
Training loss: 0.1764741986989975
Validation loss: 2.0166879693667092

Epoch: 6| Step: 13
Training loss: 0.22731512784957886
Validation loss: 1.972156822681427

Epoch: 440| Step: 0
Training loss: 0.12546618282794952
Validation loss: 2.0239535371462503

Epoch: 6| Step: 1
Training loss: 0.3404720425605774
Validation loss: 1.9794402321179707

Epoch: 6| Step: 2
Training loss: 0.40953463315963745
Validation loss: 1.9960204561551411

Epoch: 6| Step: 3
Training loss: 0.39346843957901
Validation loss: 1.9961129228274028

Epoch: 6| Step: 4
Training loss: 0.4801757335662842
Validation loss: 2.027363975842794

Epoch: 6| Step: 5
Training loss: 0.3389156460762024
Validation loss: 1.969357172648112

Epoch: 6| Step: 6
Training loss: 0.2567620277404785
Validation loss: 2.0012551148732505

Epoch: 6| Step: 7
Training loss: 0.2056969404220581
Validation loss: 2.011359175046285

Epoch: 6| Step: 8
Training loss: 0.5384534597396851
Validation loss: 2.0626818537712097

Epoch: 6| Step: 9
Training loss: 0.7571272850036621
Validation loss: 2.008519192536672

Epoch: 6| Step: 10
Training loss: 0.4553755223751068
Validation loss: 2.0237247149149575

Epoch: 6| Step: 11
Training loss: 0.24870866537094116
Validation loss: 2.0074480374654136

Epoch: 6| Step: 12
Training loss: 0.22667057812213898
Validation loss: 2.0138033429781594

Epoch: 6| Step: 13
Training loss: 0.35977181792259216
Validation loss: 1.9878594676653545

Epoch: 441| Step: 0
Training loss: 0.22808018326759338
Validation loss: 2.0112311045328775

Epoch: 6| Step: 1
Training loss: 0.40738075971603394
Validation loss: 2.0244529843330383

Epoch: 6| Step: 2
Training loss: 0.46850818395614624
Validation loss: 2.039656698703766

Epoch: 6| Step: 3
Training loss: 0.3380543291568756
Validation loss: 2.0349305073420205

Epoch: 6| Step: 4
Training loss: 0.412173867225647
Validation loss: 1.991137941678365

Epoch: 6| Step: 5
Training loss: 0.31861841678619385
Validation loss: 2.0312403440475464

Epoch: 6| Step: 6
Training loss: 0.13761436939239502
Validation loss: 1.9846864740053813

Epoch: 6| Step: 7
Training loss: 0.27469074726104736
Validation loss: 2.020383834838867

Epoch: 6| Step: 8
Training loss: 0.4110258221626282
Validation loss: 1.9931116898854573

Epoch: 6| Step: 9
Training loss: 0.7694511413574219
Validation loss: 2.011845330397288

Epoch: 6| Step: 10
Training loss: 0.5456198453903198
Validation loss: 2.0135487715403237

Epoch: 6| Step: 11
Training loss: 0.3071048855781555
Validation loss: 1.9883925517400105

Epoch: 6| Step: 12
Training loss: 0.154745951294899
Validation loss: 1.9749573667844136

Epoch: 6| Step: 13
Training loss: 0.23652058839797974
Validation loss: 1.9944385290145874

Epoch: 442| Step: 0
Training loss: 0.31157171726226807
Validation loss: 1.9612489938735962

Epoch: 6| Step: 1
Training loss: 0.636626660823822
Validation loss: 1.9881223440170288

Epoch: 6| Step: 2
Training loss: 0.34977537393569946
Validation loss: 1.9699942072232564

Epoch: 6| Step: 3
Training loss: 0.2373526692390442
Validation loss: 2.0400108098983765

Epoch: 6| Step: 4
Training loss: 0.19231048226356506
Validation loss: 1.9567220012346904

Epoch: 6| Step: 5
Training loss: 0.3480481505393982
Validation loss: 1.9762430389722188

Epoch: 6| Step: 6
Training loss: 0.21126389503479004
Validation loss: 1.9518747528394063

Epoch: 6| Step: 7
Training loss: 0.19655801355838776
Validation loss: 1.9811492959658306

Epoch: 6| Step: 8
Training loss: 0.21822525560855865
Validation loss: 1.981219967206319

Epoch: 6| Step: 9
Training loss: 0.2158495932817459
Validation loss: 1.9739457766215007

Epoch: 6| Step: 10
Training loss: 0.2100180983543396
Validation loss: 1.9920459191004436

Epoch: 6| Step: 11
Training loss: 0.15057989954948425
Validation loss: 2.009786864121755

Epoch: 6| Step: 12
Training loss: 0.41839587688446045
Validation loss: 1.9560072024663289

Epoch: 6| Step: 13
Training loss: 0.24924519658088684
Validation loss: 1.9505125880241394

Epoch: 443| Step: 0
Training loss: 0.29036444425582886
Validation loss: 1.9914870460828145

Epoch: 6| Step: 1
Training loss: 0.6764370203018188
Validation loss: 2.022434651851654

Epoch: 6| Step: 2
Training loss: 0.36564913392066956
Validation loss: 1.9721294244130452

Epoch: 6| Step: 3
Training loss: 0.24295510351657867
Validation loss: 1.965092917283376

Epoch: 6| Step: 4
Training loss: 0.1675812304019928
Validation loss: 1.989011247952779

Epoch: 6| Step: 5
Training loss: 0.13471652567386627
Validation loss: 2.007150193055471

Epoch: 6| Step: 6
Training loss: 0.2209710031747818
Validation loss: 1.9330877463022869

Epoch: 6| Step: 7
Training loss: 0.32518792152404785
Validation loss: 1.9762980937957764

Epoch: 6| Step: 8
Training loss: 0.26002010703086853
Validation loss: 1.995996395746867

Epoch: 6| Step: 9
Training loss: 0.24613897502422333
Validation loss: 1.9944544434547424

Epoch: 6| Step: 10
Training loss: 0.4378936290740967
Validation loss: 1.9920791387557983

Epoch: 6| Step: 11
Training loss: 0.25705599784851074
Validation loss: 2.021097421646118

Epoch: 6| Step: 12
Training loss: 0.2291979193687439
Validation loss: 2.0506469011306763

Epoch: 6| Step: 13
Training loss: 0.2215033769607544
Validation loss: 2.0255412260691323

Epoch: 444| Step: 0
Training loss: 0.4474240243434906
Validation loss: 1.9506472945213318

Epoch: 6| Step: 1
Training loss: 0.26858949661254883
Validation loss: 1.9864956140518188

Epoch: 6| Step: 2
Training loss: 0.48962339758872986
Validation loss: 1.9761159817377727

Epoch: 6| Step: 3
Training loss: 0.14209502935409546
Validation loss: 2.002730210622152

Epoch: 6| Step: 4
Training loss: 0.15696659684181213
Validation loss: 1.9428273638089497

Epoch: 6| Step: 5
Training loss: 0.22091303765773773
Validation loss: 1.9768840670585632

Epoch: 6| Step: 6
Training loss: 0.5239354372024536
Validation loss: 1.9869181116422017

Epoch: 6| Step: 7
Training loss: 0.6102477312088013
Validation loss: 1.9798036019007366

Epoch: 6| Step: 8
Training loss: 0.21547169983386993
Validation loss: 1.9789394934972127

Epoch: 6| Step: 9
Training loss: 0.22360849380493164
Validation loss: 1.9832369089126587

Epoch: 6| Step: 10
Training loss: 0.33038467168807983
Validation loss: 1.9709248741467793

Epoch: 6| Step: 11
Training loss: 0.13666635751724243
Validation loss: 2.0016126235326133

Epoch: 6| Step: 12
Training loss: 0.3057608902454376
Validation loss: 2.0033134818077087

Epoch: 6| Step: 13
Training loss: 0.19824673235416412
Validation loss: 2.0005789001782737

Epoch: 445| Step: 0
Training loss: 0.5657894611358643
Validation loss: 1.9751875599225361

Epoch: 6| Step: 1
Training loss: 0.19307903945446014
Validation loss: 2.0267236034075418

Epoch: 6| Step: 2
Training loss: 0.7077634334564209
Validation loss: 1.9773496389389038

Epoch: 6| Step: 3
Training loss: 0.20088019967079163
Validation loss: 1.9963688055674236

Epoch: 6| Step: 4
Training loss: 0.24338975548744202
Validation loss: 2.037949780623118

Epoch: 6| Step: 5
Training loss: 0.3083193302154541
Validation loss: 2.0053160587946572

Epoch: 6| Step: 6
Training loss: 0.22333788871765137
Validation loss: 2.0068193078041077

Epoch: 6| Step: 7
Training loss: 0.21957182884216309
Validation loss: 2.002785841623942

Epoch: 6| Step: 8
Training loss: 0.3235010802745819
Validation loss: 1.9999288320541382

Epoch: 6| Step: 9
Training loss: 0.3301278352737427
Validation loss: 1.9712478717168171

Epoch: 6| Step: 10
Training loss: 0.22577543556690216
Validation loss: 1.9774003227551777

Epoch: 6| Step: 11
Training loss: 0.20168308913707733
Validation loss: 2.0212207436561584

Epoch: 6| Step: 12
Training loss: 0.16199713945388794
Validation loss: 1.9817320505777996

Epoch: 6| Step: 13
Training loss: 0.25476574897766113
Validation loss: 2.0030960043271384

Epoch: 446| Step: 0
Training loss: 0.2665788531303406
Validation loss: 2.0288824836413064

Epoch: 6| Step: 1
Training loss: 0.30705326795578003
Validation loss: 2.0105700890223184

Epoch: 6| Step: 2
Training loss: 0.19300726056098938
Validation loss: 1.9921204646428425

Epoch: 6| Step: 3
Training loss: 0.6050163507461548
Validation loss: 2.0097193519274392

Epoch: 6| Step: 4
Training loss: 0.24606063961982727
Validation loss: 1.9946044087409973

Epoch: 6| Step: 5
Training loss: 0.20084121823310852
Validation loss: 2.0265195767084756

Epoch: 6| Step: 6
Training loss: 0.5098981261253357
Validation loss: 1.9746921857198079

Epoch: 6| Step: 7
Training loss: 0.23227454721927643
Validation loss: 1.9972057143847148

Epoch: 6| Step: 8
Training loss: 0.17839309573173523
Validation loss: 2.008489271004995

Epoch: 6| Step: 9
Training loss: 0.188121497631073
Validation loss: 1.9920812249183655

Epoch: 6| Step: 10
Training loss: 0.4538428783416748
Validation loss: 2.0088458259900412

Epoch: 6| Step: 11
Training loss: 0.3301088809967041
Validation loss: 2.027039130528768

Epoch: 6| Step: 12
Training loss: 0.3525366485118866
Validation loss: 1.9675845901171367

Epoch: 6| Step: 13
Training loss: 0.17187337577342987
Validation loss: 2.010226229826609

Epoch: 447| Step: 0
Training loss: 0.2245391309261322
Validation loss: 2.003525753815969

Epoch: 6| Step: 1
Training loss: 0.1926543414592743
Validation loss: 1.9983214537302654

Epoch: 6| Step: 2
Training loss: 0.18924197554588318
Validation loss: 2.0040184458096824

Epoch: 6| Step: 3
Training loss: 0.6501255035400391
Validation loss: 2.002822697162628

Epoch: 6| Step: 4
Training loss: 0.26146239042282104
Validation loss: 1.997238318125407

Epoch: 6| Step: 5
Training loss: 0.25716230273246765
Validation loss: 1.961561421553294

Epoch: 6| Step: 6
Training loss: 0.19648748636245728
Validation loss: 2.031244695186615

Epoch: 6| Step: 7
Training loss: 0.25350502133369446
Validation loss: 1.992972989877065

Epoch: 6| Step: 8
Training loss: 0.20355185866355896
Validation loss: 2.0247826178868613

Epoch: 6| Step: 9
Training loss: 0.3134985864162445
Validation loss: 2.0078192353248596

Epoch: 6| Step: 10
Training loss: 0.2140907198190689
Validation loss: 1.981297234694163

Epoch: 6| Step: 11
Training loss: 0.2917017340660095
Validation loss: 2.010467787583669

Epoch: 6| Step: 12
Training loss: 0.46396711468696594
Validation loss: 1.972316602865855

Epoch: 6| Step: 13
Training loss: 0.45264267921447754
Validation loss: 1.9806720813115437

Epoch: 448| Step: 0
Training loss: 0.21256965398788452
Validation loss: 1.999582548936208

Epoch: 6| Step: 1
Training loss: 0.7083038091659546
Validation loss: 2.020367980003357

Epoch: 6| Step: 2
Training loss: 0.48552119731903076
Validation loss: 1.9727895657221477

Epoch: 6| Step: 3
Training loss: 0.14740023016929626
Validation loss: 1.971074144045512

Epoch: 6| Step: 4
Training loss: 0.2488642930984497
Validation loss: 1.9726452827453613

Epoch: 6| Step: 5
Training loss: 0.2932620644569397
Validation loss: 2.0387719670931497

Epoch: 6| Step: 6
Training loss: 0.18948093056678772
Validation loss: 1.986461102962494

Epoch: 6| Step: 7
Training loss: 0.4651583433151245
Validation loss: 1.976443847020467

Epoch: 6| Step: 8
Training loss: 0.2734640836715698
Validation loss: 1.9790220061937969

Epoch: 6| Step: 9
Training loss: 0.20924422144889832
Validation loss: 1.9807282487551372

Epoch: 6| Step: 10
Training loss: 0.20948944985866547
Validation loss: 1.9919373194376628

Epoch: 6| Step: 11
Training loss: 0.29241394996643066
Validation loss: 1.988948921362559

Epoch: 6| Step: 12
Training loss: 0.26413801312446594
Validation loss: 2.009581506252289

Epoch: 6| Step: 13
Training loss: 0.19997665286064148
Validation loss: 2.022156377633413

Epoch: 449| Step: 0
Training loss: 0.4404427409172058
Validation loss: 1.9893797238667805

Epoch: 6| Step: 1
Training loss: 0.19338691234588623
Validation loss: 2.012285053730011

Epoch: 6| Step: 2
Training loss: 0.17067323625087738
Validation loss: 2.010372777779897

Epoch: 6| Step: 3
Training loss: 0.3047821521759033
Validation loss: 2.002959052721659

Epoch: 6| Step: 4
Training loss: 0.35811805725097656
Validation loss: 1.996100127696991

Epoch: 6| Step: 5
Training loss: 0.14729948341846466
Validation loss: 1.9940654238065083

Epoch: 6| Step: 6
Training loss: 0.21937638521194458
Validation loss: 2.032682557900747

Epoch: 6| Step: 7
Training loss: 0.6000860929489136
Validation loss: 1.9640984336535137

Epoch: 6| Step: 8
Training loss: 0.12354251742362976
Validation loss: 1.9656959970792134

Epoch: 6| Step: 9
Training loss: 0.22476962208747864
Validation loss: 1.979538122812907

Epoch: 6| Step: 10
Training loss: 0.22299551963806152
Validation loss: 2.0120742519696555

Epoch: 6| Step: 11
Training loss: 0.35240793228149414
Validation loss: 2.0209517081578574

Epoch: 6| Step: 12
Training loss: 0.21753241121768951
Validation loss: 2.010343054930369

Epoch: 6| Step: 13
Training loss: 0.2892586588859558
Validation loss: 1.9795928398768108

Epoch: 450| Step: 0
Training loss: 0.2015988677740097
Validation loss: 2.013184110323588

Epoch: 6| Step: 1
Training loss: 0.4747081995010376
Validation loss: 2.005281706651052

Epoch: 6| Step: 2
Training loss: 0.38659244775772095
Validation loss: 2.014681100845337

Epoch: 6| Step: 3
Training loss: 0.24416249990463257
Validation loss: 2.010703901449839

Epoch: 6| Step: 4
Training loss: 0.1849890649318695
Validation loss: 1.9414457082748413

Epoch: 6| Step: 5
Training loss: 0.27286940813064575
Validation loss: 1.9329095284144084

Epoch: 6| Step: 6
Training loss: 0.15171247720718384
Validation loss: 1.9728450576464336

Epoch: 6| Step: 7
Training loss: 0.5854838490486145
Validation loss: 1.9720420837402344

Epoch: 6| Step: 8
Training loss: 0.4086052179336548
Validation loss: 1.9706703027089436

Epoch: 6| Step: 9
Training loss: 0.19779589772224426
Validation loss: 1.9809436003367107

Epoch: 6| Step: 10
Training loss: 0.20723778009414673
Validation loss: 1.9907992680867512

Epoch: 6| Step: 11
Training loss: 0.19128766655921936
Validation loss: 1.994580825169881

Epoch: 6| Step: 12
Training loss: 0.3132288455963135
Validation loss: 2.0404068430264792

Epoch: 6| Step: 13
Training loss: 0.2207001894712448
Validation loss: 1.9624575575192769

Epoch: 451| Step: 0
Training loss: 0.39212292432785034
Validation loss: 1.979596237341563

Epoch: 6| Step: 1
Training loss: 0.13188783824443817
Validation loss: 1.9634177486101787

Epoch: 6| Step: 2
Training loss: 0.2209412157535553
Validation loss: 2.021418035030365

Epoch: 6| Step: 3
Training loss: 0.18569108843803406
Validation loss: 1.9900065263112385

Epoch: 6| Step: 4
Training loss: 0.33382362127304077
Validation loss: 1.9985101620356243

Epoch: 6| Step: 5
Training loss: 0.2874818444252014
Validation loss: 2.009915590286255

Epoch: 6| Step: 6
Training loss: 0.5498947501182556
Validation loss: 1.998801827430725

Epoch: 6| Step: 7
Training loss: 0.1889398694038391
Validation loss: 2.005846937497457

Epoch: 6| Step: 8
Training loss: 0.21076682209968567
Validation loss: 2.010829230149587

Epoch: 6| Step: 9
Training loss: 0.29698628187179565
Validation loss: 1.9820349216461182

Epoch: 6| Step: 10
Training loss: 0.22376659512519836
Validation loss: 2.016231338183085

Epoch: 6| Step: 11
Training loss: 0.21128322184085846
Validation loss: 2.00565105676651

Epoch: 6| Step: 12
Training loss: 0.684190034866333
Validation loss: 1.9939952691396077

Epoch: 6| Step: 13
Training loss: 0.18864449858665466
Validation loss: 2.0061121781667075

Epoch: 452| Step: 0
Training loss: 0.46407753229141235
Validation loss: 2.003361403942108

Epoch: 6| Step: 1
Training loss: 0.658471941947937
Validation loss: 1.9926376938819885

Epoch: 6| Step: 2
Training loss: 0.1856604516506195
Validation loss: 2.0180699825286865

Epoch: 6| Step: 3
Training loss: 0.2821810841560364
Validation loss: 2.007058401902517

Epoch: 6| Step: 4
Training loss: 0.29469823837280273
Validation loss: 1.9849960009257

Epoch: 6| Step: 5
Training loss: 0.20424281060695648
Validation loss: 2.004550794760386

Epoch: 6| Step: 6
Training loss: 0.3552302122116089
Validation loss: 1.9641751448313396

Epoch: 6| Step: 7
Training loss: 0.15533611178398132
Validation loss: 1.9848121007283528

Epoch: 6| Step: 8
Training loss: 0.2886664569377899
Validation loss: 2.02292537689209

Epoch: 6| Step: 9
Training loss: 0.3253781795501709
Validation loss: 1.993045727411906

Epoch: 6| Step: 10
Training loss: 0.21079766750335693
Validation loss: 1.9841575225194295

Epoch: 6| Step: 11
Training loss: 0.24143825471401215
Validation loss: 1.9990197817484539

Epoch: 6| Step: 12
Training loss: 0.3519112169742584
Validation loss: 1.9952136476834614

Epoch: 6| Step: 13
Training loss: 0.19434133172035217
Validation loss: 1.9910513957341511

Epoch: 453| Step: 0
Training loss: 0.22300615906715393
Validation loss: 1.9385021130243938

Epoch: 6| Step: 1
Training loss: 0.23864082992076874
Validation loss: 1.9881500601768494

Epoch: 6| Step: 2
Training loss: 0.17548257112503052
Validation loss: 1.9705296158790588

Epoch: 6| Step: 3
Training loss: 0.1886603832244873
Validation loss: 1.9775912364323933

Epoch: 6| Step: 4
Training loss: 0.35758376121520996
Validation loss: 1.9801738063494365

Epoch: 6| Step: 5
Training loss: 0.3743475079536438
Validation loss: 1.9939164519309998

Epoch: 6| Step: 6
Training loss: 0.29958653450012207
Validation loss: 2.0338534712791443

Epoch: 6| Step: 7
Training loss: 0.23879972100257874
Validation loss: 1.9951664805412292

Epoch: 6| Step: 8
Training loss: 0.5814923644065857
Validation loss: 2.007479508717855

Epoch: 6| Step: 9
Training loss: 0.19547931849956512
Validation loss: 1.9937900304794312

Epoch: 6| Step: 10
Training loss: 0.26308974623680115
Validation loss: 1.9838730891545613

Epoch: 6| Step: 11
Training loss: 0.37802553176879883
Validation loss: 1.985443651676178

Epoch: 6| Step: 12
Training loss: 0.3153548836708069
Validation loss: 1.9855901002883911

Epoch: 6| Step: 13
Training loss: 0.2615445852279663
Validation loss: 1.9951687653859456

Epoch: 454| Step: 0
Training loss: 0.22284787893295288
Validation loss: 1.9950284361839294

Epoch: 6| Step: 1
Training loss: 0.23294387757778168
Validation loss: 1.9939350485801697

Epoch: 6| Step: 2
Training loss: 0.539310097694397
Validation loss: 2.0164758761723838

Epoch: 6| Step: 3
Training loss: 0.18158058822155
Validation loss: 1.975741485754649

Epoch: 6| Step: 4
Training loss: 0.16923809051513672
Validation loss: 1.9617096781730652

Epoch: 6| Step: 5
Training loss: 0.2241063416004181
Validation loss: 2.004510819911957

Epoch: 6| Step: 6
Training loss: 0.2276073694229126
Validation loss: 2.0115655064582825

Epoch: 6| Step: 7
Training loss: 0.3553430736064911
Validation loss: 1.9713257352511089

Epoch: 6| Step: 8
Training loss: 0.4243573546409607
Validation loss: 2.0325100223223367

Epoch: 6| Step: 9
Training loss: 0.23763859272003174
Validation loss: 2.0176690220832825

Epoch: 6| Step: 10
Training loss: 0.3959549367427826
Validation loss: 2.0038282672564187

Epoch: 6| Step: 11
Training loss: 0.42760318517684937
Validation loss: 1.97615251938502

Epoch: 6| Step: 12
Training loss: 0.2704313397407532
Validation loss: 1.995091199874878

Epoch: 6| Step: 13
Training loss: 0.38631463050842285
Validation loss: 2.011602063973745

Epoch: 455| Step: 0
Training loss: 0.23539961874485016
Validation loss: 2.008556842803955

Epoch: 6| Step: 1
Training loss: 0.2017490118741989
Validation loss: 1.9854815701643627

Epoch: 6| Step: 2
Training loss: 0.3135918378829956
Validation loss: 2.001741429169973

Epoch: 6| Step: 3
Training loss: 0.23120109736919403
Validation loss: 1.994455595811208

Epoch: 6| Step: 4
Training loss: 0.31172358989715576
Validation loss: 2.0292405486106873

Epoch: 6| Step: 5
Training loss: 0.22300323843955994
Validation loss: 2.0129598577817283

Epoch: 6| Step: 6
Training loss: 0.26071032881736755
Validation loss: 2.051462729771932

Epoch: 6| Step: 7
Training loss: 0.5120660066604614
Validation loss: 2.0264377991358438

Epoch: 6| Step: 8
Training loss: 0.7298132181167603
Validation loss: 2.0214312275250754

Epoch: 6| Step: 9
Training loss: 0.31426191329956055
Validation loss: 2.014970143636068

Epoch: 6| Step: 10
Training loss: 0.26724013686180115
Validation loss: 2.0109813610712686

Epoch: 6| Step: 11
Training loss: 0.22350257635116577
Validation loss: 2.006393551826477

Epoch: 6| Step: 12
Training loss: 0.22486045956611633
Validation loss: 2.028933127721151

Epoch: 6| Step: 13
Training loss: 0.25242364406585693
Validation loss: 2.033821721871694

Epoch: 456| Step: 0
Training loss: 0.27137839794158936
Validation loss: 2.008522888024648

Epoch: 6| Step: 1
Training loss: 0.21369515359401703
Validation loss: 1.994677722454071

Epoch: 6| Step: 2
Training loss: 0.28777581453323364
Validation loss: 1.9733132123947144

Epoch: 6| Step: 3
Training loss: 0.3900162875652313
Validation loss: 1.9899094303448994

Epoch: 6| Step: 4
Training loss: 0.6975011825561523
Validation loss: 2.0382907390594482

Epoch: 6| Step: 5
Training loss: 0.43410420417785645
Validation loss: 1.983024815718333

Epoch: 6| Step: 6
Training loss: 0.14217649400234222
Validation loss: 1.9999156991640727

Epoch: 6| Step: 7
Training loss: 0.17565307021141052
Validation loss: 1.977020502090454

Epoch: 6| Step: 8
Training loss: 0.28177106380462646
Validation loss: 2.0056549310684204

Epoch: 6| Step: 9
Training loss: 0.4145110845565796
Validation loss: 1.9787416855494182

Epoch: 6| Step: 10
Training loss: 0.1830160766839981
Validation loss: 1.9922252893447876

Epoch: 6| Step: 11
Training loss: 0.16581116616725922
Validation loss: 1.9752566814422607

Epoch: 6| Step: 12
Training loss: 0.19031073153018951
Validation loss: 1.9959559837977092

Epoch: 6| Step: 13
Training loss: 0.25092554092407227
Validation loss: 1.997791866461436

Epoch: 457| Step: 0
Training loss: 0.2767879068851471
Validation loss: 1.9798510670661926

Epoch: 6| Step: 1
Training loss: 0.3852887749671936
Validation loss: 1.9913536508878071

Epoch: 6| Step: 2
Training loss: 0.19600173830986023
Validation loss: 2.0483328302701316

Epoch: 6| Step: 3
Training loss: 0.3235931396484375
Validation loss: 2.009040633837382

Epoch: 6| Step: 4
Training loss: 0.33668702840805054
Validation loss: 1.9847092032432556

Epoch: 6| Step: 5
Training loss: 0.24825377762317657
Validation loss: 2.0358675122261047

Epoch: 6| Step: 6
Training loss: 0.2754895091056824
Validation loss: 1.9886354207992554

Epoch: 6| Step: 7
Training loss: 0.3307308554649353
Validation loss: 1.9998392661412556

Epoch: 6| Step: 8
Training loss: 0.25964611768722534
Validation loss: 2.0071230133374534

Epoch: 6| Step: 9
Training loss: 0.24219290912151337
Validation loss: 2.043467362721761

Epoch: 6| Step: 10
Training loss: 0.42926692962646484
Validation loss: 2.0114195148150125

Epoch: 6| Step: 11
Training loss: 0.6128164529800415
Validation loss: 1.976152817408244

Epoch: 6| Step: 12
Training loss: 0.2698236405849457
Validation loss: 2.0479398369789124

Epoch: 6| Step: 13
Training loss: 0.291268527507782
Validation loss: 1.995975911617279

Epoch: 458| Step: 0
Training loss: 0.3916807770729065
Validation loss: 2.023426651954651

Epoch: 6| Step: 1
Training loss: 0.29784029722213745
Validation loss: 1.99651437997818

Epoch: 6| Step: 2
Training loss: 0.3066568374633789
Validation loss: 1.9877980748812358

Epoch: 6| Step: 3
Training loss: 0.19231882691383362
Validation loss: 2.082603633403778

Epoch: 6| Step: 4
Training loss: 0.1907501518726349
Validation loss: 2.030062119166056

Epoch: 6| Step: 5
Training loss: 0.31596797704696655
Validation loss: 2.0347352027893066

Epoch: 6| Step: 6
Training loss: 0.25679826736450195
Validation loss: 2.0339680910110474

Epoch: 6| Step: 7
Training loss: 0.23268119990825653
Validation loss: 2.022590935230255

Epoch: 6| Step: 8
Training loss: 0.25645267963409424
Validation loss: 2.0395646890004477

Epoch: 6| Step: 9
Training loss: 0.8000548481941223
Validation loss: 2.025454600652059

Epoch: 6| Step: 10
Training loss: 0.23379915952682495
Validation loss: 2.031196673711141

Epoch: 6| Step: 11
Training loss: 0.3489716649055481
Validation loss: 2.0359040101369223

Epoch: 6| Step: 12
Training loss: 0.23360775411128998
Validation loss: 1.9889175295829773

Epoch: 6| Step: 13
Training loss: 0.5503107309341431
Validation loss: 2.0012486577033997

Epoch: 459| Step: 0
Training loss: 0.27164357900619507
Validation loss: 2.004186471303304

Epoch: 6| Step: 1
Training loss: 0.31651628017425537
Validation loss: 1.9724084337552388

Epoch: 6| Step: 2
Training loss: 0.2310487926006317
Validation loss: 2.0140936573346457

Epoch: 6| Step: 3
Training loss: 0.4989759027957916
Validation loss: 1.9656427502632141

Epoch: 6| Step: 4
Training loss: 0.2860451340675354
Validation loss: 1.9979836344718933

Epoch: 6| Step: 5
Training loss: 0.16684424877166748
Validation loss: 2.0007064739863076

Epoch: 6| Step: 6
Training loss: 0.16797521710395813
Validation loss: 1.9941960573196411

Epoch: 6| Step: 7
Training loss: 0.6114181876182556
Validation loss: 1.9674044450124104

Epoch: 6| Step: 8
Training loss: 0.27516236901283264
Validation loss: 1.9610034028689067

Epoch: 6| Step: 9
Training loss: 0.2890419661998749
Validation loss: 1.9815070231755574

Epoch: 6| Step: 10
Training loss: 0.42014703154563904
Validation loss: 1.9724066257476807

Epoch: 6| Step: 11
Training loss: 0.2087402641773224
Validation loss: 1.9928114414215088

Epoch: 6| Step: 12
Training loss: 0.15897676348686218
Validation loss: 1.9714369575182598

Epoch: 6| Step: 13
Training loss: 0.3522091507911682
Validation loss: 1.9810237089792888

Epoch: 460| Step: 0
Training loss: 0.18376553058624268
Validation loss: 1.9929392735163372

Epoch: 6| Step: 1
Training loss: 0.29837891459465027
Validation loss: 1.940983255704244

Epoch: 6| Step: 2
Training loss: 0.3238184154033661
Validation loss: 1.9931385318438213

Epoch: 6| Step: 3
Training loss: 0.3170692026615143
Validation loss: 1.9829302032788594

Epoch: 6| Step: 4
Training loss: 0.14029595255851746
Validation loss: 2.0009445548057556

Epoch: 6| Step: 5
Training loss: 0.4510036110877991
Validation loss: 1.9578140775362651

Epoch: 6| Step: 6
Training loss: 0.2932059168815613
Validation loss: 1.9534554084142048

Epoch: 6| Step: 7
Training loss: 0.24262240529060364
Validation loss: 1.9879822134971619

Epoch: 6| Step: 8
Training loss: 0.23474746942520142
Validation loss: 1.9792691469192505

Epoch: 6| Step: 9
Training loss: 0.20980775356292725
Validation loss: 1.9637324412663777

Epoch: 6| Step: 10
Training loss: 0.2007247805595398
Validation loss: 1.9782141049702961

Epoch: 6| Step: 11
Training loss: 0.2442067563533783
Validation loss: 1.9811603625615437

Epoch: 6| Step: 12
Training loss: 0.32584089040756226
Validation loss: 2.003785192966461

Epoch: 6| Step: 13
Training loss: 0.6162609457969666
Validation loss: 2.0059399008750916

Epoch: 461| Step: 0
Training loss: 0.7477220892906189
Validation loss: 2.0120769739151

Epoch: 6| Step: 1
Training loss: 0.2224225252866745
Validation loss: 2.0203064481417337

Epoch: 6| Step: 2
Training loss: 0.29155808687210083
Validation loss: 1.973228653271993

Epoch: 6| Step: 3
Training loss: 0.41520956158638
Validation loss: 1.998405635356903

Epoch: 6| Step: 4
Training loss: 0.13611625134944916
Validation loss: 2.004984696706136

Epoch: 6| Step: 5
Training loss: 0.239805206656456
Validation loss: 1.963197112083435

Epoch: 6| Step: 6
Training loss: 0.40781986713409424
Validation loss: 1.983101983865102

Epoch: 6| Step: 7
Training loss: 0.3515406548976898
Validation loss: 1.983748455842336

Epoch: 6| Step: 8
Training loss: 0.2752538323402405
Validation loss: 1.995471676190694

Epoch: 6| Step: 9
Training loss: 0.3043178915977478
Validation loss: 1.9834909439086914

Epoch: 6| Step: 10
Training loss: 0.20149582624435425
Validation loss: 2.034924070040385

Epoch: 6| Step: 11
Training loss: 0.18718218803405762
Validation loss: 2.006332596143087

Epoch: 6| Step: 12
Training loss: 0.2665407955646515
Validation loss: 1.9786038001378377

Epoch: 6| Step: 13
Training loss: 0.13072258234024048
Validation loss: 1.9947813749313354

Epoch: 462| Step: 0
Training loss: 0.40095385909080505
Validation loss: 1.9937247435251872

Epoch: 6| Step: 1
Training loss: 0.1938473880290985
Validation loss: 1.9929139216740925

Epoch: 6| Step: 2
Training loss: 0.20539110898971558
Validation loss: 1.9990208745002747

Epoch: 6| Step: 3
Training loss: 0.24562478065490723
Validation loss: 1.997718334197998

Epoch: 6| Step: 4
Training loss: 0.3680558502674103
Validation loss: 1.988627811272939

Epoch: 6| Step: 5
Training loss: 0.16062553226947784
Validation loss: 2.022792935371399

Epoch: 6| Step: 6
Training loss: 0.3612491488456726
Validation loss: 1.9924832383791606

Epoch: 6| Step: 7
Training loss: 0.5741786360740662
Validation loss: 1.9785562753677368

Epoch: 6| Step: 8
Training loss: 0.2117190659046173
Validation loss: 1.9845158060391743

Epoch: 6| Step: 9
Training loss: 0.23375293612480164
Validation loss: 2.0425270994504294

Epoch: 6| Step: 10
Training loss: 0.3065027892589569
Validation loss: 1.992064376672109

Epoch: 6| Step: 11
Training loss: 0.19604170322418213
Validation loss: 2.0051562388738

Epoch: 6| Step: 12
Training loss: 0.18936294317245483
Validation loss: 1.9843800067901611

Epoch: 6| Step: 13
Training loss: 0.32017385959625244
Validation loss: 1.9781232078870137

Epoch: 463| Step: 0
Training loss: 0.49944859743118286
Validation loss: 2.0067255894343057

Epoch: 6| Step: 1
Training loss: 0.2696528136730194
Validation loss: 1.9705087939898174

Epoch: 6| Step: 2
Training loss: 0.19427435100078583
Validation loss: 1.9854573607444763

Epoch: 6| Step: 3
Training loss: 0.14397850632667542
Validation loss: 1.98860369126002

Epoch: 6| Step: 4
Training loss: 0.2315378040075302
Validation loss: 1.9817065993944805

Epoch: 6| Step: 5
Training loss: 0.2756558358669281
Validation loss: 2.0225151975949607

Epoch: 6| Step: 6
Training loss: 0.2263704240322113
Validation loss: 1.9744666814804077

Epoch: 6| Step: 7
Training loss: 0.18925687670707703
Validation loss: 1.9982735912005107

Epoch: 6| Step: 8
Training loss: 0.7506420612335205
Validation loss: 1.9799441297849019

Epoch: 6| Step: 9
Training loss: 0.22172480821609497
Validation loss: 1.9537427028020222

Epoch: 6| Step: 10
Training loss: 0.232195183634758
Validation loss: 1.9693440993626912

Epoch: 6| Step: 11
Training loss: 0.235172301530838
Validation loss: 1.9871039787928264

Epoch: 6| Step: 12
Training loss: 0.4435943365097046
Validation loss: 1.9989796082178752

Epoch: 6| Step: 13
Training loss: 0.2751864790916443
Validation loss: 2.014254649480184

Epoch: 464| Step: 0
Training loss: 0.34554848074913025
Validation loss: 1.9473902781804402

Epoch: 6| Step: 1
Training loss: 0.3015541434288025
Validation loss: 2.0292986830075583

Epoch: 6| Step: 2
Training loss: 0.26291242241859436
Validation loss: 1.9858938852945964

Epoch: 6| Step: 3
Training loss: 0.5317776203155518
Validation loss: 2.00183767080307

Epoch: 6| Step: 4
Training loss: 0.33674389123916626
Validation loss: 2.0278384685516357

Epoch: 6| Step: 5
Training loss: 0.22394713759422302
Validation loss: 2.0031418005625405

Epoch: 6| Step: 6
Training loss: 0.2567061185836792
Validation loss: 1.9849353432655334

Epoch: 6| Step: 7
Training loss: 0.17701506614685059
Validation loss: 1.9876152674357097

Epoch: 6| Step: 8
Training loss: 0.189825639128685
Validation loss: 1.9632088144620259

Epoch: 6| Step: 9
Training loss: 0.3699144423007965
Validation loss: 1.9969484408696492

Epoch: 6| Step: 10
Training loss: 0.22137823700904846
Validation loss: 1.9702223141988118

Epoch: 6| Step: 11
Training loss: 0.5399729013442993
Validation loss: 1.9979602893193562

Epoch: 6| Step: 12
Training loss: 0.2268032282590866
Validation loss: 1.9996828238169353

Epoch: 6| Step: 13
Training loss: 0.2906233072280884
Validation loss: 1.9576011896133423

Epoch: 465| Step: 0
Training loss: 0.2800477147102356
Validation loss: 2.020679990450541

Epoch: 6| Step: 1
Training loss: 0.3532881736755371
Validation loss: 2.021193265914917

Epoch: 6| Step: 2
Training loss: 0.36858272552490234
Validation loss: 1.9768763184547424

Epoch: 6| Step: 3
Training loss: 0.2447408139705658
Validation loss: 1.962705671787262

Epoch: 6| Step: 4
Training loss: 0.254122793674469
Validation loss: 1.9803625146547954

Epoch: 6| Step: 5
Training loss: 0.24485017359256744
Validation loss: 1.9644048015276592

Epoch: 6| Step: 6
Training loss: 0.6607562899589539
Validation loss: 2.000083267688751

Epoch: 6| Step: 7
Training loss: 0.2118179053068161
Validation loss: 1.9380856951077778

Epoch: 6| Step: 8
Training loss: 0.18814806640148163
Validation loss: 1.9975444078445435

Epoch: 6| Step: 9
Training loss: 0.23220263421535492
Validation loss: 1.997279127438863

Epoch: 6| Step: 10
Training loss: 0.2215028703212738
Validation loss: 1.9966745376586914

Epoch: 6| Step: 11
Training loss: 0.31758570671081543
Validation loss: 1.9961163798967998

Epoch: 6| Step: 12
Training loss: 0.24498498439788818
Validation loss: 1.9943735599517822

Epoch: 6| Step: 13
Training loss: 0.3983759880065918
Validation loss: 2.0145115653673806

Epoch: 466| Step: 0
Training loss: 0.4977845847606659
Validation loss: 1.9649621844291687

Epoch: 6| Step: 1
Training loss: 0.5734426975250244
Validation loss: 1.9753366311391194

Epoch: 6| Step: 2
Training loss: 0.3071213662624359
Validation loss: 2.0051806569099426

Epoch: 6| Step: 3
Training loss: 0.24746806919574738
Validation loss: 2.0176562468210855

Epoch: 6| Step: 4
Training loss: 0.23915380239486694
Validation loss: 2.0087199608484902

Epoch: 6| Step: 5
Training loss: 0.28965750336647034
Validation loss: 1.9898285865783691

Epoch: 6| Step: 6
Training loss: 0.1937173306941986
Validation loss: 1.9902971386909485

Epoch: 6| Step: 7
Training loss: 0.26993393898010254
Validation loss: 1.9802868167559307

Epoch: 6| Step: 8
Training loss: 0.268696665763855
Validation loss: 1.9907304644584656

Epoch: 6| Step: 9
Training loss: 0.23176757991313934
Validation loss: 2.006586730480194

Epoch: 6| Step: 10
Training loss: 0.4001314043998718
Validation loss: 2.0122371912002563

Epoch: 6| Step: 11
Training loss: 0.22312472760677338
Validation loss: 2.002844234307607

Epoch: 6| Step: 12
Training loss: 0.30553174018859863
Validation loss: 2.0121566454569497

Epoch: 6| Step: 13
Training loss: 0.24018903076648712
Validation loss: 1.9725718100865681

Epoch: 467| Step: 0
Training loss: 0.20210963487625122
Validation loss: 1.9917922218640645

Epoch: 6| Step: 1
Training loss: 0.23691804707050323
Validation loss: 1.9740983843803406

Epoch: 6| Step: 2
Training loss: 0.2692878246307373
Validation loss: 1.9980313380559285

Epoch: 6| Step: 3
Training loss: 0.23867979645729065
Validation loss: 1.9709437787532806

Epoch: 6| Step: 4
Training loss: 0.1635628491640091
Validation loss: 1.9690792163213093

Epoch: 6| Step: 5
Training loss: 0.2821735739707947
Validation loss: 1.9347198804219563

Epoch: 6| Step: 6
Training loss: 0.38510262966156006
Validation loss: 1.9911091327667236

Epoch: 6| Step: 7
Training loss: 0.7475225925445557
Validation loss: 2.0027687549591064

Epoch: 6| Step: 8
Training loss: 0.37001389265060425
Validation loss: 1.9478266040484111

Epoch: 6| Step: 9
Training loss: 0.2694844603538513
Validation loss: 1.9806497891743977

Epoch: 6| Step: 10
Training loss: 0.23142778873443604
Validation loss: 1.9826009472211201

Epoch: 6| Step: 11
Training loss: 0.20098745822906494
Validation loss: 2.0240429639816284

Epoch: 6| Step: 12
Training loss: 0.40300390124320984
Validation loss: 1.9885923465092976

Epoch: 6| Step: 13
Training loss: 0.34624534845352173
Validation loss: 2.025444428126017

Epoch: 468| Step: 0
Training loss: 0.47434762120246887
Validation loss: 2.0164341926574707

Epoch: 6| Step: 1
Training loss: 0.2922826409339905
Validation loss: 2.0095116098721824

Epoch: 6| Step: 2
Training loss: 0.34382277727127075
Validation loss: 2.003318647543589

Epoch: 6| Step: 3
Training loss: 0.21720951795578003
Validation loss: 1.9945828318595886

Epoch: 6| Step: 4
Training loss: 0.3726751506328583
Validation loss: 1.9830073316891987

Epoch: 6| Step: 5
Training loss: 0.19129008054733276
Validation loss: 2.0038138031959534

Epoch: 6| Step: 6
Training loss: 0.26418647170066833
Validation loss: 2.0107444524765015

Epoch: 6| Step: 7
Training loss: 0.17630425095558167
Validation loss: 2.056320627530416

Epoch: 6| Step: 8
Training loss: 0.1462906152009964
Validation loss: 2.0373435020446777

Epoch: 6| Step: 9
Training loss: 0.15565788745880127
Validation loss: 1.9877742131551106

Epoch: 6| Step: 10
Training loss: 0.19035591185092926
Validation loss: 1.9729676047960918

Epoch: 6| Step: 11
Training loss: 0.3247872591018677
Validation loss: 2.0156413912773132

Epoch: 6| Step: 12
Training loss: 0.1624171882867813
Validation loss: 2.0432109038035073

Epoch: 6| Step: 13
Training loss: 0.7030761241912842
Validation loss: 2.006666382153829

Epoch: 469| Step: 0
Training loss: 0.30147242546081543
Validation loss: 2.001280347506205

Epoch: 6| Step: 1
Training loss: 0.165572851896286
Validation loss: 1.961824615796407

Epoch: 6| Step: 2
Training loss: 0.3228951096534729
Validation loss: 1.9976006547609966

Epoch: 6| Step: 3
Training loss: 0.33559170365333557
Validation loss: 2.0032041470209756

Epoch: 6| Step: 4
Training loss: 0.6088900566101074
Validation loss: 1.9499955375989277

Epoch: 6| Step: 5
Training loss: 0.33217063546180725
Validation loss: 2.0260956088701882

Epoch: 6| Step: 6
Training loss: 0.2782543897628784
Validation loss: 1.9844573140144348

Epoch: 6| Step: 7
Training loss: 0.2859036326408386
Validation loss: 1.9817437728246052

Epoch: 6| Step: 8
Training loss: 0.26477062702178955
Validation loss: 1.9688564737637837

Epoch: 6| Step: 9
Training loss: 0.19875967502593994
Validation loss: 1.9964965184529622

Epoch: 6| Step: 10
Training loss: 0.1832738220691681
Validation loss: 1.989371915658315

Epoch: 6| Step: 11
Training loss: 0.2936832904815674
Validation loss: 2.014387309551239

Epoch: 6| Step: 12
Training loss: 0.21746033430099487
Validation loss: 1.9928173422813416

Epoch: 6| Step: 13
Training loss: 0.3074922561645508
Validation loss: 1.9684527119000752

Epoch: 470| Step: 0
Training loss: 0.2011629343032837
Validation loss: 2.0205249190330505

Epoch: 6| Step: 1
Training loss: 0.3851289749145508
Validation loss: 1.9912036061286926

Epoch: 6| Step: 2
Training loss: 0.3520660400390625
Validation loss: 1.9860215385754902

Epoch: 6| Step: 3
Training loss: 0.301830530166626
Validation loss: 1.98728742202123

Epoch: 6| Step: 4
Training loss: 0.2401949167251587
Validation loss: 1.9843244751294453

Epoch: 6| Step: 5
Training loss: 0.27724766731262207
Validation loss: 1.9958072304725647

Epoch: 6| Step: 6
Training loss: 0.23132744431495667
Validation loss: 1.9798152446746826

Epoch: 6| Step: 7
Training loss: 0.27315235137939453
Validation loss: 1.9966766039530437

Epoch: 6| Step: 8
Training loss: 0.2175464779138565
Validation loss: 2.0258032083511353

Epoch: 6| Step: 9
Training loss: 0.6440704464912415
Validation loss: 2.0201884508132935

Epoch: 6| Step: 10
Training loss: 0.33266887068748474
Validation loss: 1.9980741540590923

Epoch: 6| Step: 11
Training loss: 0.18763981759548187
Validation loss: 1.9660626848538716

Epoch: 6| Step: 12
Training loss: 0.37036746740341187
Validation loss: 2.014649589856466

Epoch: 6| Step: 13
Training loss: 0.21537774801254272
Validation loss: 1.9876715540885925

Epoch: 471| Step: 0
Training loss: 0.598084568977356
Validation loss: 2.009502728780111

Epoch: 6| Step: 1
Training loss: 0.4217516779899597
Validation loss: 1.9630363980929058

Epoch: 6| Step: 2
Training loss: 0.2128077745437622
Validation loss: 1.9809085726737976

Epoch: 6| Step: 3
Training loss: 0.3638846278190613
Validation loss: 1.9714916348457336

Epoch: 6| Step: 4
Training loss: 0.19494843482971191
Validation loss: 1.974941869576772

Epoch: 6| Step: 5
Training loss: 0.34933269023895264
Validation loss: 2.005803108215332

Epoch: 6| Step: 6
Training loss: 0.26150205731391907
Validation loss: 1.9686229825019836

Epoch: 6| Step: 7
Training loss: 0.202276811003685
Validation loss: 1.9629258910814922

Epoch: 6| Step: 8
Training loss: 0.19021055102348328
Validation loss: 2.0014967918395996

Epoch: 6| Step: 9
Training loss: 0.29049405455589294
Validation loss: 1.9959920644760132

Epoch: 6| Step: 10
Training loss: 0.21347041428089142
Validation loss: 2.020192325115204

Epoch: 6| Step: 11
Training loss: 0.24738281965255737
Validation loss: 1.970353364944458

Epoch: 6| Step: 12
Training loss: 0.3143094778060913
Validation loss: 1.9703019261360168

Epoch: 6| Step: 13
Training loss: 0.217673197388649
Validation loss: 1.9906038840611775

Epoch: 472| Step: 0
Training loss: 0.16391593217849731
Validation loss: 1.9727773070335388

Epoch: 6| Step: 1
Training loss: 0.33631932735443115
Validation loss: 1.9465049306551616

Epoch: 6| Step: 2
Training loss: 0.24074092507362366
Validation loss: 1.9912627935409546

Epoch: 6| Step: 3
Training loss: 0.7861478328704834
Validation loss: 1.9966087341308594

Epoch: 6| Step: 4
Training loss: 0.24134600162506104
Validation loss: 2.0516138474146524

Epoch: 6| Step: 5
Training loss: 0.23954840004444122
Validation loss: 1.9870526989301045

Epoch: 6| Step: 6
Training loss: 0.12454422563314438
Validation loss: 1.9679543574651082

Epoch: 6| Step: 7
Training loss: 0.26243317127227783
Validation loss: 1.9764891862869263

Epoch: 6| Step: 8
Training loss: 0.22790592908859253
Validation loss: 1.9879857699076335

Epoch: 6| Step: 9
Training loss: 0.2867300808429718
Validation loss: 1.986223618189494

Epoch: 6| Step: 10
Training loss: 0.2542751133441925
Validation loss: 1.9595632155736287

Epoch: 6| Step: 11
Training loss: 0.1988416165113449
Validation loss: 1.9729917446772258

Epoch: 6| Step: 12
Training loss: 0.3094480037689209
Validation loss: 1.9891762733459473

Epoch: 6| Step: 13
Training loss: 0.24438753724098206
Validation loss: 1.9718032280604045

Epoch: 473| Step: 0
Training loss: 0.25900426506996155
Validation loss: 1.9922900994618733

Epoch: 6| Step: 1
Training loss: 0.26561662554740906
Validation loss: 2.028062184651693

Epoch: 6| Step: 2
Training loss: 0.30761802196502686
Validation loss: 1.9974435369173686

Epoch: 6| Step: 3
Training loss: 0.66927170753479
Validation loss: 1.9881491859753926

Epoch: 6| Step: 4
Training loss: 0.1441011130809784
Validation loss: 1.9722676475842793

Epoch: 6| Step: 5
Training loss: 0.26922911405563354
Validation loss: 1.9966427683830261

Epoch: 6| Step: 6
Training loss: 0.32669511437416077
Validation loss: 1.9837686419487

Epoch: 6| Step: 7
Training loss: 0.26594221591949463
Validation loss: 1.9795228441556294

Epoch: 6| Step: 8
Training loss: 0.19208431243896484
Validation loss: 1.9902677337328594

Epoch: 6| Step: 9
Training loss: 0.2231869101524353
Validation loss: 1.9661394556363423

Epoch: 6| Step: 10
Training loss: 0.19725987315177917
Validation loss: 2.0168451070785522

Epoch: 6| Step: 11
Training loss: 0.19699813425540924
Validation loss: 2.0054824352264404

Epoch: 6| Step: 12
Training loss: 0.1690765917301178
Validation loss: 1.9712709188461304

Epoch: 6| Step: 13
Training loss: 0.17806962132453918
Validation loss: 2.0124797026316323

Epoch: 474| Step: 0
Training loss: 0.2651047706604004
Validation loss: 1.9883851607640584

Epoch: 6| Step: 1
Training loss: 0.28640633821487427
Validation loss: 2.0042787392934165

Epoch: 6| Step: 2
Training loss: 0.14825887978076935
Validation loss: 1.9653711915016174

Epoch: 6| Step: 3
Training loss: 0.1861218810081482
Validation loss: 2.000230848789215

Epoch: 6| Step: 4
Training loss: 0.6387920379638672
Validation loss: 2.004995862642924

Epoch: 6| Step: 5
Training loss: 0.4041542410850525
Validation loss: 2.0096456011136374

Epoch: 6| Step: 6
Training loss: 0.3524189889431
Validation loss: 2.0250388781229653

Epoch: 6| Step: 7
Training loss: 0.3385170102119446
Validation loss: 2.0144848028818765

Epoch: 6| Step: 8
Training loss: 0.24609063565731049
Validation loss: 2.007872144381205

Epoch: 6| Step: 9
Training loss: 0.34967240691185
Validation loss: 2.0111671884854636

Epoch: 6| Step: 10
Training loss: 0.2347402721643448
Validation loss: 2.0040127635002136

Epoch: 6| Step: 11
Training loss: 0.18331219255924225
Validation loss: 1.9918657143910725

Epoch: 6| Step: 12
Training loss: 0.18453237414360046
Validation loss: 1.9917498032251995

Epoch: 6| Step: 13
Training loss: 0.24241694808006287
Validation loss: 1.9840018153190613

Epoch: 475| Step: 0
Training loss: 0.1558251678943634
Validation loss: 1.9826314449310303

Epoch: 6| Step: 1
Training loss: 0.26293304562568665
Validation loss: 2.0019524693489075

Epoch: 6| Step: 2
Training loss: 0.1795998215675354
Validation loss: 2.009004215399424

Epoch: 6| Step: 3
Training loss: 0.3267679810523987
Validation loss: 1.957275927066803

Epoch: 6| Step: 4
Training loss: 0.19233663380146027
Validation loss: 1.9875388344128926

Epoch: 6| Step: 5
Training loss: 0.20756475627422333
Validation loss: 1.95415461063385

Epoch: 6| Step: 6
Training loss: 0.3044380247592926
Validation loss: 1.9986069798469543

Epoch: 6| Step: 7
Training loss: 0.2318226397037506
Validation loss: 1.9786953528722127

Epoch: 6| Step: 8
Training loss: 0.23589776456356049
Validation loss: 1.9970083236694336

Epoch: 6| Step: 9
Training loss: 0.26062414050102234
Validation loss: 1.9480389555295308

Epoch: 6| Step: 10
Training loss: 0.18557029962539673
Validation loss: 2.0169115463892617

Epoch: 6| Step: 11
Training loss: 0.2974207401275635
Validation loss: 1.967224399248759

Epoch: 6| Step: 12
Training loss: 0.19347354769706726
Validation loss: 1.9868069887161255

Epoch: 6| Step: 13
Training loss: 0.6918325424194336
Validation loss: 1.9813876350720723

Epoch: 476| Step: 0
Training loss: 0.21597528457641602
Validation loss: 1.9848655263582866

Epoch: 6| Step: 1
Training loss: 0.2841450572013855
Validation loss: 2.0052993496259055

Epoch: 6| Step: 2
Training loss: 0.21621711552143097
Validation loss: 2.0017983516057334

Epoch: 6| Step: 3
Training loss: 0.48431891202926636
Validation loss: 1.986699064572652

Epoch: 6| Step: 4
Training loss: 0.6193797588348389
Validation loss: 1.985529085000356

Epoch: 6| Step: 5
Training loss: 0.15474224090576172
Validation loss: 1.9587158759435017

Epoch: 6| Step: 6
Training loss: 0.36150914430618286
Validation loss: 1.9823522965113323

Epoch: 6| Step: 7
Training loss: 0.18641941249370575
Validation loss: 1.9956063826878865

Epoch: 6| Step: 8
Training loss: 0.21084345877170563
Validation loss: 2.0065662463506064

Epoch: 6| Step: 9
Training loss: 0.3204612135887146
Validation loss: 1.9902350703875225

Epoch: 6| Step: 10
Training loss: 0.14128881692886353
Validation loss: 2.0057429869969687

Epoch: 6| Step: 11
Training loss: 0.24327196180820465
Validation loss: 2.007392485936483

Epoch: 6| Step: 12
Training loss: 0.14358869194984436
Validation loss: 1.985396405061086

Epoch: 6| Step: 13
Training loss: 0.13447488844394684
Validation loss: 1.9698992570241292

Epoch: 477| Step: 0
Training loss: 0.7093378305435181
Validation loss: 1.939040203889211

Epoch: 6| Step: 1
Training loss: 0.1648375391960144
Validation loss: 2.0113027890523276

Epoch: 6| Step: 2
Training loss: 0.24018938839435577
Validation loss: 1.9898686806360881

Epoch: 6| Step: 3
Training loss: 0.37545353174209595
Validation loss: 1.9560932517051697

Epoch: 6| Step: 4
Training loss: 0.21205657720565796
Validation loss: 2.0024940172831216

Epoch: 6| Step: 5
Training loss: 0.20409739017486572
Validation loss: 1.9663510918617249

Epoch: 6| Step: 6
Training loss: 0.19032767415046692
Validation loss: 1.9655937552452087

Epoch: 6| Step: 7
Training loss: 0.36387279629707336
Validation loss: 2.0234153469403586

Epoch: 6| Step: 8
Training loss: 0.2315773367881775
Validation loss: 2.0040424267450967

Epoch: 6| Step: 9
Training loss: 0.1955568939447403
Validation loss: 1.9632023771603901

Epoch: 6| Step: 10
Training loss: 0.3226620554924011
Validation loss: 2.01122784614563

Epoch: 6| Step: 11
Training loss: 0.22432415187358856
Validation loss: 1.9960866371790569

Epoch: 6| Step: 12
Training loss: 0.3441741466522217
Validation loss: 2.001006007194519

Epoch: 6| Step: 13
Training loss: 0.2477247714996338
Validation loss: 1.9811578194300334

Epoch: 478| Step: 0
Training loss: 0.3462718725204468
Validation loss: 2.0055115620295205

Epoch: 6| Step: 1
Training loss: 0.41372352838516235
Validation loss: 1.9754600326220195

Epoch: 6| Step: 2
Training loss: 0.40149039030075073
Validation loss: 1.9748136202494304

Epoch: 6| Step: 3
Training loss: 0.23297835886478424
Validation loss: 1.9865266680717468

Epoch: 6| Step: 4
Training loss: 0.20973807573318481
Validation loss: 1.994016448656718

Epoch: 6| Step: 5
Training loss: 0.1730242669582367
Validation loss: 1.9674440423647563

Epoch: 6| Step: 6
Training loss: 0.1830410212278366
Validation loss: 1.9668769836425781

Epoch: 6| Step: 7
Training loss: 0.30640169978141785
Validation loss: 1.9741438627243042

Epoch: 6| Step: 8
Training loss: 0.2697707712650299
Validation loss: 1.943217655022939

Epoch: 6| Step: 9
Training loss: 0.17084643244743347
Validation loss: 2.009844978650411

Epoch: 6| Step: 10
Training loss: 0.2710435390472412
Validation loss: 2.018112858136495

Epoch: 6| Step: 11
Training loss: 0.2339784801006317
Validation loss: 1.9831581910451253

Epoch: 6| Step: 12
Training loss: 0.3616190552711487
Validation loss: 2.0266188383102417

Epoch: 6| Step: 13
Training loss: 0.7988626956939697
Validation loss: 2.0032772620519004

Epoch: 479| Step: 0
Training loss: 0.41982656717300415
Validation loss: 1.9448000987370808

Epoch: 6| Step: 1
Training loss: 0.3966621160507202
Validation loss: 1.9831949472427368

Epoch: 6| Step: 2
Training loss: 0.2146795690059662
Validation loss: 1.9960030515988667

Epoch: 6| Step: 3
Training loss: 0.22393977642059326
Validation loss: 1.9958508213361104

Epoch: 6| Step: 4
Training loss: 0.20797783136367798
Validation loss: 1.968269685904185

Epoch: 6| Step: 5
Training loss: 0.3744223713874817
Validation loss: 1.9943567117055256

Epoch: 6| Step: 6
Training loss: 0.2391931414604187
Validation loss: 1.9529748161633809

Epoch: 6| Step: 7
Training loss: 0.24077127873897552
Validation loss: 1.9660568237304688

Epoch: 6| Step: 8
Training loss: 0.13255630433559418
Validation loss: 1.98286368449529

Epoch: 6| Step: 9
Training loss: 0.5466293096542358
Validation loss: 1.9800057609875996

Epoch: 6| Step: 10
Training loss: 0.20607712864875793
Validation loss: 2.019966801007589

Epoch: 6| Step: 11
Training loss: 0.28121164441108704
Validation loss: 1.9787450432777405

Epoch: 6| Step: 12
Training loss: 0.2993525266647339
Validation loss: 2.0138443311055503

Epoch: 6| Step: 13
Training loss: 0.40574073791503906
Validation loss: 1.9910605351130168

Epoch: 480| Step: 0
Training loss: 0.20781686902046204
Validation loss: 1.986717164516449

Epoch: 6| Step: 1
Training loss: 0.24888525903224945
Validation loss: 1.9706888596216838

Epoch: 6| Step: 2
Training loss: 0.21485649049282074
Validation loss: 1.9832539955774944

Epoch: 6| Step: 3
Training loss: 0.16584967076778412
Validation loss: 1.9761907458305359

Epoch: 6| Step: 4
Training loss: 0.33561915159225464
Validation loss: 2.030517578125

Epoch: 6| Step: 5
Training loss: 0.2595745623111725
Validation loss: 1.9652724464734395

Epoch: 6| Step: 6
Training loss: 0.655617356300354
Validation loss: 2.0073054234186807

Epoch: 6| Step: 7
Training loss: 0.3792942762374878
Validation loss: 2.0036126176516214

Epoch: 6| Step: 8
Training loss: 0.17530187964439392
Validation loss: 1.9615671237309773

Epoch: 6| Step: 9
Training loss: 0.44754329323768616
Validation loss: 1.994945228099823

Epoch: 6| Step: 10
Training loss: 0.35344964265823364
Validation loss: 2.004811147848765

Epoch: 6| Step: 11
Training loss: 0.27026301622390747
Validation loss: 2.0100821455319724

Epoch: 6| Step: 12
Training loss: 0.2505854666233063
Validation loss: 2.016492942969004

Epoch: 6| Step: 13
Training loss: 0.3009641170501709
Validation loss: 1.9791539311408997

Epoch: 481| Step: 0
Training loss: 0.5763987302780151
Validation loss: 1.9886680046717327

Epoch: 6| Step: 1
Training loss: 0.34763962030410767
Validation loss: 2.0144102573394775

Epoch: 6| Step: 2
Training loss: 0.2429763674736023
Validation loss: 1.9911609292030334

Epoch: 6| Step: 3
Training loss: 0.22835710644721985
Validation loss: 2.0086154540379844

Epoch: 6| Step: 4
Training loss: 0.27752307057380676
Validation loss: 1.9798363248507183

Epoch: 6| Step: 5
Training loss: 0.32080477476119995
Validation loss: 1.983109712600708

Epoch: 6| Step: 6
Training loss: 0.2161644995212555
Validation loss: 1.991073191165924

Epoch: 6| Step: 7
Training loss: 0.21017807722091675
Validation loss: 2.0225411454836526

Epoch: 6| Step: 8
Training loss: 0.20781216025352478
Validation loss: 1.970962941646576

Epoch: 6| Step: 9
Training loss: 0.21352560818195343
Validation loss: 2.000727335611979

Epoch: 6| Step: 10
Training loss: 0.27083900570869446
Validation loss: 2.0231643517812095

Epoch: 6| Step: 11
Training loss: 0.32178252935409546
Validation loss: 1.9718055923779805

Epoch: 6| Step: 12
Training loss: 0.32098686695098877
Validation loss: 2.0073415835698447

Epoch: 6| Step: 13
Training loss: 0.3367617130279541
Validation loss: 1.9872484405835469

Epoch: 482| Step: 0
Training loss: 0.44027891755104065
Validation loss: 2.0303882559140525

Epoch: 6| Step: 1
Training loss: 0.1951385736465454
Validation loss: 1.9624894460042317

Epoch: 6| Step: 2
Training loss: 0.16586408019065857
Validation loss: 1.9610284169514973

Epoch: 6| Step: 3
Training loss: 0.2510486841201782
Validation loss: 1.9991904099782307

Epoch: 6| Step: 4
Training loss: 0.21317172050476074
Validation loss: 2.008558670679728

Epoch: 6| Step: 5
Training loss: 0.3880707621574402
Validation loss: 1.9608999689420064

Epoch: 6| Step: 6
Training loss: 0.3241490125656128
Validation loss: 1.978082537651062

Epoch: 6| Step: 7
Training loss: 0.1885421872138977
Validation loss: 1.9768749276796977

Epoch: 6| Step: 8
Training loss: 0.5441443920135498
Validation loss: 1.9961580236752827

Epoch: 6| Step: 9
Training loss: 0.3462890386581421
Validation loss: 1.998871346314748

Epoch: 6| Step: 10
Training loss: 0.36550456285476685
Validation loss: 2.013546109199524

Epoch: 6| Step: 11
Training loss: 0.2871013581752777
Validation loss: 2.000082790851593

Epoch: 6| Step: 12
Training loss: 0.2410091757774353
Validation loss: 2.0161243081092834

Epoch: 6| Step: 13
Training loss: 0.19296537339687347
Validation loss: 2.0036648909250894

Epoch: 483| Step: 0
Training loss: 0.18557702004909515
Validation loss: 1.9861398736635845

Epoch: 6| Step: 1
Training loss: 0.32786381244659424
Validation loss: 1.951925257841746

Epoch: 6| Step: 2
Training loss: 0.19712956249713898
Validation loss: 2.0356472730636597

Epoch: 6| Step: 3
Training loss: 0.18959692120552063
Validation loss: 1.984883983929952

Epoch: 6| Step: 4
Training loss: 0.16267484426498413
Validation loss: 2.004051764806112

Epoch: 6| Step: 5
Training loss: 0.27358824014663696
Validation loss: 1.9454290270805359

Epoch: 6| Step: 6
Training loss: 0.41584354639053345
Validation loss: 2.0262455344200134

Epoch: 6| Step: 7
Training loss: 0.7633238434791565
Validation loss: 2.0093600153923035

Epoch: 6| Step: 8
Training loss: 0.29433995485305786
Validation loss: 1.9998149077097576

Epoch: 6| Step: 9
Training loss: 0.1875045895576477
Validation loss: 1.97080663839976

Epoch: 6| Step: 10
Training loss: 0.37916845083236694
Validation loss: 1.9816417694091797

Epoch: 6| Step: 11
Training loss: 0.1764371693134308
Validation loss: 1.9785112539927165

Epoch: 6| Step: 12
Training loss: 0.29561012983322144
Validation loss: 1.9855464696884155

Epoch: 6| Step: 13
Training loss: 0.2530921995639801
Validation loss: 1.965267022450765

Epoch: 484| Step: 0
Training loss: 0.20103837549686432
Validation loss: 1.997220238049825

Epoch: 6| Step: 1
Training loss: 0.29770880937576294
Validation loss: 1.980858604113261

Epoch: 6| Step: 2
Training loss: 0.5659789443016052
Validation loss: 1.9733306169509888

Epoch: 6| Step: 3
Training loss: 0.2266291081905365
Validation loss: 1.9688899715741475

Epoch: 6| Step: 4
Training loss: 0.40223589539527893
Validation loss: 1.9958021839459736

Epoch: 6| Step: 5
Training loss: 0.21081072092056274
Validation loss: 1.9912964304288228

Epoch: 6| Step: 6
Training loss: 0.1741255819797516
Validation loss: 2.001048723856608

Epoch: 6| Step: 7
Training loss: 0.19048112630844116
Validation loss: 1.9900469183921814

Epoch: 6| Step: 8
Training loss: 0.1513870507478714
Validation loss: 1.958473026752472

Epoch: 6| Step: 9
Training loss: 0.3947015404701233
Validation loss: 2.00715833902359

Epoch: 6| Step: 10
Training loss: 0.19207456707954407
Validation loss: 1.9825214346249898

Epoch: 6| Step: 11
Training loss: 0.2622101306915283
Validation loss: 1.9930312633514404

Epoch: 6| Step: 12
Training loss: 0.3628282845020294
Validation loss: 2.0077674786249795

Epoch: 6| Step: 13
Training loss: 0.24970963597297668
Validation loss: 2.0002527634302774

Epoch: 485| Step: 0
Training loss: 0.16132321953773499
Validation loss: 1.9782154560089111

Epoch: 6| Step: 1
Training loss: 0.23527365922927856
Validation loss: 2.0161394278208413

Epoch: 6| Step: 2
Training loss: 0.18246203660964966
Validation loss: 2.0514989495277405

Epoch: 6| Step: 3
Training loss: 0.23157915472984314
Validation loss: 1.9870500365893047

Epoch: 6| Step: 4
Training loss: 0.3295735716819763
Validation loss: 1.9895191192626953

Epoch: 6| Step: 5
Training loss: 0.2353096306324005
Validation loss: 2.015820880730947

Epoch: 6| Step: 6
Training loss: 0.6441006660461426
Validation loss: 1.994462509950002

Epoch: 6| Step: 7
Training loss: 0.4489891529083252
Validation loss: 2.0110970735549927

Epoch: 6| Step: 8
Training loss: 0.29892247915267944
Validation loss: 1.9505812724431355

Epoch: 6| Step: 9
Training loss: 0.23754307627677917
Validation loss: 1.9826282660166423

Epoch: 6| Step: 10
Training loss: 0.19792094826698303
Validation loss: 1.996582607428233

Epoch: 6| Step: 11
Training loss: 0.18586137890815735
Validation loss: 2.015447437763214

Epoch: 6| Step: 12
Training loss: 0.3368270695209503
Validation loss: 2.0111212929089866

Epoch: 6| Step: 13
Training loss: 0.1923639327287674
Validation loss: 2.016553362210592

Epoch: 486| Step: 0
Training loss: 0.16865107417106628
Validation loss: 2.000168204307556

Epoch: 6| Step: 1
Training loss: 0.6913886070251465
Validation loss: 1.97868408759435

Epoch: 6| Step: 2
Training loss: 0.22512611746788025
Validation loss: 2.0243226885795593

Epoch: 6| Step: 3
Training loss: 0.1766161024570465
Validation loss: 1.9569814403851826

Epoch: 6| Step: 4
Training loss: 0.16050812602043152
Validation loss: 2.0515048503875732

Epoch: 6| Step: 5
Training loss: 0.18122990429401398
Validation loss: 2.023276925086975

Epoch: 6| Step: 6
Training loss: 0.19622763991355896
Validation loss: 1.9663137793540955

Epoch: 6| Step: 7
Training loss: 0.4839921295642853
Validation loss: 1.9890806873639424

Epoch: 6| Step: 8
Training loss: 0.247062087059021
Validation loss: 2.028473675251007

Epoch: 6| Step: 9
Training loss: 0.2030574083328247
Validation loss: 2.008280257383982

Epoch: 6| Step: 10
Training loss: 0.22517091035842896
Validation loss: 2.0181819200515747

Epoch: 6| Step: 11
Training loss: 0.17046572268009186
Validation loss: 2.008382340272268

Epoch: 6| Step: 12
Training loss: 0.20322754979133606
Validation loss: 1.9906303882598877

Epoch: 6| Step: 13
Training loss: 0.3625061511993408
Validation loss: 1.9477147062619526

Epoch: 487| Step: 0
Training loss: 0.29990488290786743
Validation loss: 2.0026673674583435

Epoch: 6| Step: 1
Training loss: 0.17552919685840607
Validation loss: 2.030451556046804

Epoch: 6| Step: 2
Training loss: 0.23026657104492188
Validation loss: 2.001102844874064

Epoch: 6| Step: 3
Training loss: 0.6543446779251099
Validation loss: 1.9849066535631816

Epoch: 6| Step: 4
Training loss: 0.20048514008522034
Validation loss: 1.9717363516489665

Epoch: 6| Step: 5
Training loss: 0.14685699343681335
Validation loss: 1.9693342844645183

Epoch: 6| Step: 6
Training loss: 0.24714502692222595
Validation loss: 1.9871589541435242

Epoch: 6| Step: 7
Training loss: 0.1839321255683899
Validation loss: 2.0158561070760093

Epoch: 6| Step: 8
Training loss: 0.28262853622436523
Validation loss: 1.9853880405426025

Epoch: 6| Step: 9
Training loss: 0.24217043817043304
Validation loss: 2.004737595717112

Epoch: 6| Step: 10
Training loss: 0.22862866520881653
Validation loss: 2.0206159353256226

Epoch: 6| Step: 11
Training loss: 0.3690430819988251
Validation loss: 2.036277453104655

Epoch: 6| Step: 12
Training loss: 0.22460675239562988
Validation loss: 2.056287149588267

Epoch: 6| Step: 13
Training loss: 0.3358427584171295
Validation loss: 2.0070454478263855

Epoch: 488| Step: 0
Training loss: 0.21218907833099365
Validation loss: 1.9906537334124248

Epoch: 6| Step: 1
Training loss: 0.2562447786331177
Validation loss: 1.983235279719035

Epoch: 6| Step: 2
Training loss: 0.19314983487129211
Validation loss: 2.0075512329737344

Epoch: 6| Step: 3
Training loss: 0.1813727617263794
Validation loss: 1.9849915107091267

Epoch: 6| Step: 4
Training loss: 0.34496015310287476
Validation loss: 2.050857186317444

Epoch: 6| Step: 5
Training loss: 0.35878822207450867
Validation loss: 2.0464752515157065

Epoch: 6| Step: 6
Training loss: 0.3488693833351135
Validation loss: 2.0437596837679544

Epoch: 6| Step: 7
Training loss: 0.26525217294692993
Validation loss: 1.975753366947174

Epoch: 6| Step: 8
Training loss: 0.5715212225914001
Validation loss: 1.9771251678466797

Epoch: 6| Step: 9
Training loss: 0.23803852498531342
Validation loss: 1.9798953135808308

Epoch: 6| Step: 10
Training loss: 0.19474899768829346
Validation loss: 1.9853603045145671

Epoch: 6| Step: 11
Training loss: 0.16406647861003876
Validation loss: 1.9955950578053792

Epoch: 6| Step: 12
Training loss: 0.5496994853019714
Validation loss: 1.9882629911104839

Epoch: 6| Step: 13
Training loss: 0.40949878096580505
Validation loss: 1.9708904425303142

Epoch: 489| Step: 0
Training loss: 0.28763920068740845
Validation loss: 2.0069427490234375

Epoch: 6| Step: 1
Training loss: 0.28148627281188965
Validation loss: 1.9781351288159688

Epoch: 6| Step: 2
Training loss: 0.21446414291858673
Validation loss: 2.0005738536516824

Epoch: 6| Step: 3
Training loss: 0.15440456569194794
Validation loss: 1.9906965891520183

Epoch: 6| Step: 4
Training loss: 0.29574912786483765
Validation loss: 2.000313460826874

Epoch: 6| Step: 5
Training loss: 0.1973091959953308
Validation loss: 1.9903401732444763

Epoch: 6| Step: 6
Training loss: 0.3783310055732727
Validation loss: 1.9707276821136475

Epoch: 6| Step: 7
Training loss: 0.5521095395088196
Validation loss: 2.011434316635132

Epoch: 6| Step: 8
Training loss: 0.25801557302474976
Validation loss: 1.9968997637430828

Epoch: 6| Step: 9
Training loss: 0.22099681198596954
Validation loss: 1.9946532249450684

Epoch: 6| Step: 10
Training loss: 0.2272438406944275
Validation loss: 2.0579862793286643

Epoch: 6| Step: 11
Training loss: 0.36042889952659607
Validation loss: 1.9993825356165569

Epoch: 6| Step: 12
Training loss: 0.43423333764076233
Validation loss: 1.9906983375549316

Epoch: 6| Step: 13
Training loss: 0.2174142301082611
Validation loss: 2.023430128892263

Epoch: 490| Step: 0
Training loss: 0.20621861517429352
Validation loss: 1.9963840246200562

Epoch: 6| Step: 1
Training loss: 0.22269102931022644
Validation loss: 2.007149577140808

Epoch: 6| Step: 2
Training loss: 0.3606671690940857
Validation loss: 2.021686295668284

Epoch: 6| Step: 3
Training loss: 0.18870073556900024
Validation loss: 1.995802601178487

Epoch: 6| Step: 4
Training loss: 0.21922022104263306
Validation loss: 2.0034290552139282

Epoch: 6| Step: 5
Training loss: 0.23558899760246277
Validation loss: 1.9889016151428223

Epoch: 6| Step: 6
Training loss: 0.23923556506633759
Validation loss: 2.0186855594317117

Epoch: 6| Step: 7
Training loss: 0.17382937669754028
Validation loss: 2.000472366809845

Epoch: 6| Step: 8
Training loss: 0.30323272943496704
Validation loss: 1.9685406684875488

Epoch: 6| Step: 9
Training loss: 0.18678921461105347
Validation loss: 1.9889764785766602

Epoch: 6| Step: 10
Training loss: 0.5708385109901428
Validation loss: 2.0005184213320413

Epoch: 6| Step: 11
Training loss: 0.2861652374267578
Validation loss: 2.013787011305491

Epoch: 6| Step: 12
Training loss: 0.492904931306839
Validation loss: 1.9504086375236511

Epoch: 6| Step: 13
Training loss: 0.1976393610239029
Validation loss: 2.0171520709991455

Epoch: 491| Step: 0
Training loss: 0.28922703862190247
Validation loss: 1.9906729459762573

Epoch: 6| Step: 1
Training loss: 0.14442318677902222
Validation loss: 1.9650836785634358

Epoch: 6| Step: 2
Training loss: 0.15714114904403687
Validation loss: 1.9799694617589314

Epoch: 6| Step: 3
Training loss: 0.48428845405578613
Validation loss: 2.0200157960255942

Epoch: 6| Step: 4
Training loss: 0.16652676463127136
Validation loss: 2.0148537357648215

Epoch: 6| Step: 5
Training loss: 0.38240641355514526
Validation loss: 2.0273567040761313

Epoch: 6| Step: 6
Training loss: 0.15908491611480713
Validation loss: 1.9779104987780254

Epoch: 6| Step: 7
Training loss: 0.155477374792099
Validation loss: 1.9953245123227437

Epoch: 6| Step: 8
Training loss: 0.22883951663970947
Validation loss: 2.002033313115438

Epoch: 6| Step: 9
Training loss: 0.257750004529953
Validation loss: 1.9528984824816387

Epoch: 6| Step: 10
Training loss: 0.2141309380531311
Validation loss: 1.9667208592096965

Epoch: 6| Step: 11
Training loss: 0.24330753087997437
Validation loss: 2.0056190689404807

Epoch: 6| Step: 12
Training loss: 0.254827082157135
Validation loss: 1.9982965191205342

Epoch: 6| Step: 13
Training loss: 0.587541937828064
Validation loss: 1.9949958125750225

Epoch: 492| Step: 0
Training loss: 0.17490461468696594
Validation loss: 1.9900754292805989

Epoch: 6| Step: 1
Training loss: 0.723292350769043
Validation loss: 2.003702243169149

Epoch: 6| Step: 2
Training loss: 0.2165583223104477
Validation loss: 2.018142342567444

Epoch: 6| Step: 3
Training loss: 0.23208537697792053
Validation loss: 1.9683332641919453

Epoch: 6| Step: 4
Training loss: 0.1725538671016693
Validation loss: 1.9957858522733052

Epoch: 6| Step: 5
Training loss: 0.1839960813522339
Validation loss: 1.999856432278951

Epoch: 6| Step: 6
Training loss: 0.3559625446796417
Validation loss: 1.979438066482544

Epoch: 6| Step: 7
Training loss: 0.2386305034160614
Validation loss: 2.0141589840253196

Epoch: 6| Step: 8
Training loss: 0.39299914240837097
Validation loss: 1.988703687985738

Epoch: 6| Step: 9
Training loss: 0.260459840297699
Validation loss: 2.0251686573028564

Epoch: 6| Step: 10
Training loss: 0.2133210003376007
Validation loss: 1.9891120195388794

Epoch: 6| Step: 11
Training loss: 0.24658609926700592
Validation loss: 1.9929168423016865

Epoch: 6| Step: 12
Training loss: 0.22823479771614075
Validation loss: 1.9853283166885376

Epoch: 6| Step: 13
Training loss: 0.318521648645401
Validation loss: 1.9831598003705342

Epoch: 493| Step: 0
Training loss: 0.18724508583545685
Validation loss: 1.979035218556722

Epoch: 6| Step: 1
Training loss: 0.25431811809539795
Validation loss: 2.0051822662353516

Epoch: 6| Step: 2
Training loss: 0.1753423810005188
Validation loss: 1.9607763886451721

Epoch: 6| Step: 3
Training loss: 0.2211911380290985
Validation loss: 2.0026875535647073

Epoch: 6| Step: 4
Training loss: 0.16328978538513184
Validation loss: 2.004416584968567

Epoch: 6| Step: 5
Training loss: 0.3545861840248108
Validation loss: 1.9569316109021504

Epoch: 6| Step: 6
Training loss: 0.28082743287086487
Validation loss: 1.95779550075531

Epoch: 6| Step: 7
Training loss: 0.241796612739563
Validation loss: 2.012596686681112

Epoch: 6| Step: 8
Training loss: 0.32838189601898193
Validation loss: 1.9893534382184346

Epoch: 6| Step: 9
Training loss: 0.3904857039451599
Validation loss: 2.0031936168670654

Epoch: 6| Step: 10
Training loss: 0.2013946771621704
Validation loss: 1.9961662888526917

Epoch: 6| Step: 11
Training loss: 0.346754789352417
Validation loss: 1.9612405896186829

Epoch: 6| Step: 12
Training loss: 0.5683718323707581
Validation loss: 1.9834259748458862

Epoch: 6| Step: 13
Training loss: 0.31938058137893677
Validation loss: 2.017791191736857

Epoch: 494| Step: 0
Training loss: 0.22196152806282043
Validation loss: 1.998045305411021

Epoch: 6| Step: 1
Training loss: 0.6165999174118042
Validation loss: 1.9724209904670715

Epoch: 6| Step: 2
Training loss: 0.25684183835983276
Validation loss: 1.9823963244756062

Epoch: 6| Step: 3
Training loss: 0.3960909843444824
Validation loss: 1.9891748627026875

Epoch: 6| Step: 4
Training loss: 0.24047991633415222
Validation loss: 2.0450961788495383

Epoch: 6| Step: 5
Training loss: 0.2078036367893219
Validation loss: 1.9944031238555908

Epoch: 6| Step: 6
Training loss: 0.17559105157852173
Validation loss: 2.0160425702730813

Epoch: 6| Step: 7
Training loss: 0.23514056205749512
Validation loss: 1.9801894426345825

Epoch: 6| Step: 8
Training loss: 0.31876394152641296
Validation loss: 1.9795212546984355

Epoch: 6| Step: 9
Training loss: 0.3202669024467468
Validation loss: 1.995954116185506

Epoch: 6| Step: 10
Training loss: 0.10406320542097092
Validation loss: 1.9704899390538533

Epoch: 6| Step: 11
Training loss: 0.2865802049636841
Validation loss: 1.9979335467020671

Epoch: 6| Step: 12
Training loss: 0.3369709849357605
Validation loss: 1.9967059691747029

Epoch: 6| Step: 13
Training loss: 0.3224153518676758
Validation loss: 1.9968673785527546

Epoch: 495| Step: 0
Training loss: 0.19888263940811157
Validation loss: 1.9873231450716655

Epoch: 6| Step: 1
Training loss: 0.2642335891723633
Validation loss: 1.9787663022677104

Epoch: 6| Step: 2
Training loss: 0.6185400485992432
Validation loss: 1.9422246217727661

Epoch: 6| Step: 3
Training loss: 0.23347878456115723
Validation loss: 1.9430434306462605

Epoch: 6| Step: 4
Training loss: 0.20851591229438782
Validation loss: 1.984476923942566

Epoch: 6| Step: 5
Training loss: 0.33277902007102966
Validation loss: 2.0153077642122903

Epoch: 6| Step: 6
Training loss: 0.28034719824790955
Validation loss: 2.0066274801890054

Epoch: 6| Step: 7
Training loss: 0.20055456459522247
Validation loss: 1.999686559041341

Epoch: 6| Step: 8
Training loss: 0.19696223735809326
Validation loss: 2.025083303451538

Epoch: 6| Step: 9
Training loss: 0.2800113558769226
Validation loss: 1.9764826496442158

Epoch: 6| Step: 10
Training loss: 0.21848829090595245
Validation loss: 2.0103328824043274

Epoch: 6| Step: 11
Training loss: 0.3625830411911011
Validation loss: 1.9968682328859966

Epoch: 6| Step: 12
Training loss: 0.21488720178604126
Validation loss: 1.996693213780721

Epoch: 6| Step: 13
Training loss: 0.2666938006877899
Validation loss: 1.965910275777181

Epoch: 496| Step: 0
Training loss: 0.2971315085887909
Validation loss: 1.990890125433604

Epoch: 6| Step: 1
Training loss: 0.29090139269828796
Validation loss: 1.976338307062785

Epoch: 6| Step: 2
Training loss: 0.17701967060565948
Validation loss: 1.987821102142334

Epoch: 6| Step: 3
Training loss: 0.147026926279068
Validation loss: 2.0041088263193765

Epoch: 6| Step: 4
Training loss: 0.28976893424987793
Validation loss: 1.9865647753079732

Epoch: 6| Step: 5
Training loss: 0.34786954522132874
Validation loss: 1.975631852944692

Epoch: 6| Step: 6
Training loss: 0.2422923743724823
Validation loss: 1.9750933051109314

Epoch: 6| Step: 7
Training loss: 0.3130453824996948
Validation loss: 1.9915969967842102

Epoch: 6| Step: 8
Training loss: 0.18757787346839905
Validation loss: 2.0102350314458213

Epoch: 6| Step: 9
Training loss: 0.20434801280498505
Validation loss: 1.980995277563731

Epoch: 6| Step: 10
Training loss: 0.6832207441329956
Validation loss: 1.9674002329508464

Epoch: 6| Step: 11
Training loss: 0.25687313079833984
Validation loss: 2.002409815788269

Epoch: 6| Step: 12
Training loss: 0.17465975880622864
Validation loss: 1.9770695169766743

Epoch: 6| Step: 13
Training loss: 0.23777005076408386
Validation loss: 1.9913821617762248

Epoch: 497| Step: 0
Training loss: 0.3253988027572632
Validation loss: 1.996586799621582

Epoch: 6| Step: 1
Training loss: 0.16439463198184967
Validation loss: 1.9585220615069072

Epoch: 6| Step: 2
Training loss: 0.25455552339553833
Validation loss: 2.016507943471273

Epoch: 6| Step: 3
Training loss: 0.5682047605514526
Validation loss: 1.9665746688842773

Epoch: 6| Step: 4
Training loss: 0.20597636699676514
Validation loss: 1.9815293153127034

Epoch: 6| Step: 5
Training loss: 0.23317137360572815
Validation loss: 1.9616814454396565

Epoch: 6| Step: 6
Training loss: 0.3723183572292328
Validation loss: 1.996338466803233

Epoch: 6| Step: 7
Training loss: 0.20097212493419647
Validation loss: 2.0094117720921836

Epoch: 6| Step: 8
Training loss: 0.3114345073699951
Validation loss: 1.9627082347869873

Epoch: 6| Step: 9
Training loss: 0.24809777736663818
Validation loss: 1.970407783985138

Epoch: 6| Step: 10
Training loss: 0.21657992899417877
Validation loss: 1.98913570245107

Epoch: 6| Step: 11
Training loss: 0.1663135588169098
Validation loss: 1.9833375215530396

Epoch: 6| Step: 12
Training loss: 0.38744544982910156
Validation loss: 1.964974284172058

Epoch: 6| Step: 13
Training loss: 0.3912608027458191
Validation loss: 2.0172093907992044

Epoch: 498| Step: 0
Training loss: 0.3884565830230713
Validation loss: 2.016529103120168

Epoch: 6| Step: 1
Training loss: 0.186812162399292
Validation loss: 1.9620651205380757

Epoch: 6| Step: 2
Training loss: 0.3679095208644867
Validation loss: 1.9862100680669148

Epoch: 6| Step: 3
Training loss: 0.1793038249015808
Validation loss: 1.9956764976183574

Epoch: 6| Step: 4
Training loss: 0.26705533266067505
Validation loss: 1.9589077234268188

Epoch: 6| Step: 5
Training loss: 0.6143935918807983
Validation loss: 1.9975510636965434

Epoch: 6| Step: 6
Training loss: 0.20641520619392395
Validation loss: 2.0155171553293862

Epoch: 6| Step: 7
Training loss: 0.2528141140937805
Validation loss: 1.9966270327568054

Epoch: 6| Step: 8
Training loss: 0.14510288834571838
Validation loss: 1.9994952082633972

Epoch: 6| Step: 9
Training loss: 0.22368182241916656
Validation loss: 1.95079771677653

Epoch: 6| Step: 10
Training loss: 0.38819482922554016
Validation loss: 1.984571595986684

Epoch: 6| Step: 11
Training loss: 0.4104987382888794
Validation loss: 2.0093520085016885

Epoch: 6| Step: 12
Training loss: 0.26056596636772156
Validation loss: 1.99285888671875

Epoch: 6| Step: 13
Training loss: 0.26152023673057556
Validation loss: 2.0064319570859275

Epoch: 499| Step: 0
Training loss: 0.22735410928726196
Validation loss: 2.0242514411608377

Epoch: 6| Step: 1
Training loss: 0.11753401905298233
Validation loss: 1.9702026844024658

Epoch: 6| Step: 2
Training loss: 0.38494232296943665
Validation loss: 2.004729151725769

Epoch: 6| Step: 3
Training loss: 0.4401613473892212
Validation loss: 1.9707645972569783

Epoch: 6| Step: 4
Training loss: 0.20327623188495636
Validation loss: 1.9814757704734802

Epoch: 6| Step: 5
Training loss: 0.31780317425727844
Validation loss: 2.0017402172088623

Epoch: 6| Step: 6
Training loss: 0.22064118087291718
Validation loss: 1.9865014553070068

Epoch: 6| Step: 7
Training loss: 0.2247961163520813
Validation loss: 1.9748562574386597

Epoch: 6| Step: 8
Training loss: 0.2143440991640091
Validation loss: 2.0031305948893228

Epoch: 6| Step: 9
Training loss: 0.30935508012771606
Validation loss: 1.9961264332135518

Epoch: 6| Step: 10
Training loss: 0.18099552392959595
Validation loss: 1.953924298286438

Epoch: 6| Step: 11
Training loss: 0.19273000955581665
Validation loss: 1.9667673707008362

Epoch: 6| Step: 12
Training loss: 0.15868063271045685
Validation loss: 1.9976292252540588

Epoch: 6| Step: 13
Training loss: 0.513645350933075
Validation loss: 2.000303347905477

Epoch: 500| Step: 0
Training loss: 0.32619768381118774
Validation loss: 1.9656536380449932

Epoch: 6| Step: 1
Training loss: 0.6715639233589172
Validation loss: 1.9902751843134563

Epoch: 6| Step: 2
Training loss: 0.2831336259841919
Validation loss: 2.0225396354993186

Epoch: 6| Step: 3
Training loss: 0.2632901072502136
Validation loss: 2.0076248248418174

Epoch: 6| Step: 4
Training loss: 0.25513431429862976
Validation loss: 1.977851410706838

Epoch: 6| Step: 5
Training loss: 0.24371473491191864
Validation loss: 1.9985893964767456

Epoch: 6| Step: 6
Training loss: 0.19807681441307068
Validation loss: 1.9995745619138081

Epoch: 6| Step: 7
Training loss: 0.13497956097126007
Validation loss: 2.0279499689737954

Epoch: 6| Step: 8
Training loss: 0.3819143772125244
Validation loss: 2.0111095309257507

Epoch: 6| Step: 9
Training loss: 0.20184597373008728
Validation loss: 1.9697656432787578

Epoch: 6| Step: 10
Training loss: 0.4252564609050751
Validation loss: 2.0075069864590964

Epoch: 6| Step: 11
Training loss: 0.25044772028923035
Validation loss: 1.9676100611686707

Epoch: 6| Step: 12
Training loss: 0.12215042859315872
Validation loss: 2.018046776453654

Epoch: 6| Step: 13
Training loss: 0.2089763730764389
Validation loss: 1.9600696762402852

Testing loss: 1.847221166967488
