Epoch: 1| Step: 0
Training loss: 2.9180542143085764
Validation loss: 3.0988360319393737

Epoch: 5| Step: 1
Training loss: 3.3225242518565317
Validation loss: 3.090472717184891

Epoch: 5| Step: 2
Training loss: 3.0538728608233257
Validation loss: 3.0821552066348237

Epoch: 5| Step: 3
Training loss: 3.1330493257196856
Validation loss: 3.078141278580482

Epoch: 5| Step: 4
Training loss: 2.750993202492273
Validation loss: 3.072318498399392

Epoch: 5| Step: 5
Training loss: 3.5459467139460137
Validation loss: 3.068223541898703

Epoch: 5| Step: 6
Training loss: 3.1937816282374705
Validation loss: 3.0651978721760775

Epoch: 5| Step: 7
Training loss: 3.957438411269555
Validation loss: 3.062009188189135

Epoch: 5| Step: 8
Training loss: 3.4929239405430725
Validation loss: 3.057983061397179

Epoch: 5| Step: 9
Training loss: 2.8210930840389254
Validation loss: 3.0531876923636254

Epoch: 5| Step: 10
Training loss: 2.649835178359806
Validation loss: 3.049365370810087

Epoch: 5| Step: 11
Training loss: 4.270967484514975
Validation loss: 3.048082591659951

Epoch: 2| Step: 0
Training loss: 3.293355355697494
Validation loss: 3.042530385714331

Epoch: 5| Step: 1
Training loss: 2.929794919905671
Validation loss: 3.037320452486841

Epoch: 5| Step: 2
Training loss: 3.0226516688103366
Validation loss: 3.0334432539219365

Epoch: 5| Step: 3
Training loss: 2.857674014582595
Validation loss: 3.027477879988117

Epoch: 5| Step: 4
Training loss: 3.6816388117535324
Validation loss: 3.023784344843307

Epoch: 5| Step: 5
Training loss: 3.103225684861493
Validation loss: 3.0175076605049833

Epoch: 5| Step: 6
Training loss: 3.186283402984314
Validation loss: 3.0120780390769735

Epoch: 5| Step: 7
Training loss: 3.110893607105361
Validation loss: 3.0052974242563804

Epoch: 5| Step: 8
Training loss: 2.931023458417545
Validation loss: 3.000074206864969

Epoch: 5| Step: 9
Training loss: 3.298695283228543
Validation loss: 2.9916574159672207

Epoch: 5| Step: 10
Training loss: 3.244555975537108
Validation loss: 2.986481008364857

Epoch: 5| Step: 11
Training loss: 2.860568938586306
Validation loss: 2.9772385124106426

Epoch: 3| Step: 0
Training loss: 3.572549665785201
Validation loss: 2.9702140176397642

Epoch: 5| Step: 1
Training loss: 2.8007610751267356
Validation loss: 2.962835379688782

Epoch: 5| Step: 2
Training loss: 3.0549252312683755
Validation loss: 2.9536416276338913

Epoch: 5| Step: 3
Training loss: 3.381252290227823
Validation loss: 2.943602547053895

Epoch: 5| Step: 4
Training loss: 3.0489618441908295
Validation loss: 2.9343317206742072

Epoch: 5| Step: 5
Training loss: 2.9941398287160554
Validation loss: 2.9243234959264446

Epoch: 5| Step: 6
Training loss: 2.7246476146790113
Validation loss: 2.9131382967226624

Epoch: 5| Step: 7
Training loss: 3.0757959529727796
Validation loss: 2.8990724181794767

Epoch: 5| Step: 8
Training loss: 2.4098789543999133
Validation loss: 2.8894689430490423

Epoch: 5| Step: 9
Training loss: 3.4849272833397853
Validation loss: 2.876885680292727

Epoch: 5| Step: 10
Training loss: 3.0058925297168426
Validation loss: 2.8628403105972677

Epoch: 5| Step: 11
Training loss: 2.4899600607185226
Validation loss: 2.8507025828666746

Epoch: 4| Step: 0
Training loss: 2.770423390363166
Validation loss: 2.8425721709137632

Epoch: 5| Step: 1
Training loss: 2.7054325904379524
Validation loss: 2.8246987912281227

Epoch: 5| Step: 2
Training loss: 2.736502816765993
Validation loss: 2.822422752714255

Epoch: 5| Step: 3
Training loss: 2.733210724507532
Validation loss: 2.8062407532378897

Epoch: 5| Step: 4
Training loss: 3.3252918201395367
Validation loss: 2.7941274271366727

Epoch: 5| Step: 5
Training loss: 2.90190373778055
Validation loss: 2.7828512404335317

Epoch: 5| Step: 6
Training loss: 3.4959995022648997
Validation loss: 2.7681315139575577

Epoch: 5| Step: 7
Training loss: 3.1469204941977416
Validation loss: 2.7607781059628222

Epoch: 5| Step: 8
Training loss: 2.738034834501535
Validation loss: 2.7399647680451538

Epoch: 5| Step: 9
Training loss: 2.5482264016742024
Validation loss: 2.719991648897272

Epoch: 5| Step: 10
Training loss: 2.425275126315358
Validation loss: 2.708058373847829

Epoch: 5| Step: 11
Training loss: 3.242738975594979
Validation loss: 2.689067882242086

Epoch: 5| Step: 0
Training loss: 2.8110377431131703
Validation loss: 2.6686038801406466

Epoch: 5| Step: 1
Training loss: 2.7135957113340066
Validation loss: 2.6565207025554254

Epoch: 5| Step: 2
Training loss: 2.7787576716665057
Validation loss: 2.629333582283586

Epoch: 5| Step: 3
Training loss: 2.7093901601893027
Validation loss: 2.61698645963046

Epoch: 5| Step: 4
Training loss: 2.7300582380685308
Validation loss: 2.5868316633427475

Epoch: 5| Step: 5
Training loss: 2.745179980688569
Validation loss: 2.573162462228797

Epoch: 5| Step: 6
Training loss: 2.0760107543093453
Validation loss: 2.5603159885979476

Epoch: 5| Step: 7
Training loss: 2.5743666564406116
Validation loss: 2.541987017209704

Epoch: 5| Step: 8
Training loss: 2.271692399317456
Validation loss: 2.526903179903835

Epoch: 5| Step: 9
Training loss: 3.154029896305993
Validation loss: 2.510824417039765

Epoch: 5| Step: 10
Training loss: 2.60923318991528
Validation loss: 2.502549639586478

Epoch: 5| Step: 11
Training loss: 2.4873723596384125
Validation loss: 2.495717634699321

Epoch: 6| Step: 0
Training loss: 2.4316818049976927
Validation loss: 2.491151177678858

Epoch: 5| Step: 1
Training loss: 2.5562287793759317
Validation loss: 2.4933155380874505

Epoch: 5| Step: 2
Training loss: 2.397013785311861
Validation loss: 2.486318276089412

Epoch: 5| Step: 3
Training loss: 2.417050583259211
Validation loss: 2.503092986341487

Epoch: 5| Step: 4
Training loss: 2.444478730722281
Validation loss: 2.4986808912774943

Epoch: 5| Step: 5
Training loss: 2.4308790615289326
Validation loss: 2.494892947876029

Epoch: 5| Step: 6
Training loss: 2.5334961897386803
Validation loss: 2.507239612017325

Epoch: 5| Step: 7
Training loss: 2.505427382020311
Validation loss: 2.5083302847684243

Epoch: 5| Step: 8
Training loss: 2.6123842715681063
Validation loss: 2.503125494021503

Epoch: 5| Step: 9
Training loss: 2.4116578208411363
Validation loss: 2.5021700222827405

Epoch: 5| Step: 10
Training loss: 2.78459232394133
Validation loss: 2.506729244571714

Epoch: 5| Step: 11
Training loss: 3.458870505166215
Validation loss: 2.5211179246857562

Epoch: 7| Step: 0
Training loss: 2.6086430236787463
Validation loss: 2.510950745296616

Epoch: 5| Step: 1
Training loss: 2.3304060443827286
Validation loss: 2.5027689500768995

Epoch: 5| Step: 2
Training loss: 2.5505544845005295
Validation loss: 2.5042085073363984

Epoch: 5| Step: 3
Training loss: 2.369126737322754
Validation loss: 2.499496880211727

Epoch: 5| Step: 4
Training loss: 2.3334843949964386
Validation loss: 2.5019625986928893

Epoch: 5| Step: 5
Training loss: 3.0215721191606635
Validation loss: 2.4945535539521413

Epoch: 5| Step: 6
Training loss: 2.6156648220371577
Validation loss: 2.4956596805001223

Epoch: 5| Step: 7
Training loss: 2.0845050822649203
Validation loss: 2.486565857474663

Epoch: 5| Step: 8
Training loss: 2.038365855275945
Validation loss: 2.496388421452718

Epoch: 5| Step: 9
Training loss: 2.9359129818902066
Validation loss: 2.482094427722955

Epoch: 5| Step: 10
Training loss: 2.5489704896184655
Validation loss: 2.4901896533814893

Epoch: 5| Step: 11
Training loss: 3.062972985935926
Validation loss: 2.4899501563545074

Epoch: 8| Step: 0
Training loss: 2.3351655532993627
Validation loss: 2.4885246800550425

Epoch: 5| Step: 1
Training loss: 2.4680760103388346
Validation loss: 2.4916435273849222

Epoch: 5| Step: 2
Training loss: 2.3156403534620895
Validation loss: 2.4810154630250123

Epoch: 5| Step: 3
Training loss: 3.1166512929227816
Validation loss: 2.487255881262137

Epoch: 5| Step: 4
Training loss: 2.542599136985405
Validation loss: 2.488360493035447

Epoch: 5| Step: 5
Training loss: 2.112300285514657
Validation loss: 2.482306629049905

Epoch: 5| Step: 6
Training loss: 2.570910723328731
Validation loss: 2.4875282733275297

Epoch: 5| Step: 7
Training loss: 2.7431912663578566
Validation loss: 2.475082958321031

Epoch: 5| Step: 8
Training loss: 2.3019929295621013
Validation loss: 2.489137491236775

Epoch: 5| Step: 9
Training loss: 2.4790553113361185
Validation loss: 2.496860042267813

Epoch: 5| Step: 10
Training loss: 2.4171788122394577
Validation loss: 2.4864625017961948

Epoch: 5| Step: 11
Training loss: 2.9203503552672863
Validation loss: 2.478170157891402

Epoch: 9| Step: 0
Training loss: 2.4063017207940867
Validation loss: 2.480092986873419

Epoch: 5| Step: 1
Training loss: 2.7866848767368526
Validation loss: 2.4866761800270383

Epoch: 5| Step: 2
Training loss: 2.119543250022183
Validation loss: 2.47742827090935

Epoch: 5| Step: 3
Training loss: 2.4663432497781645
Validation loss: 2.485976520698032

Epoch: 5| Step: 4
Training loss: 2.407007073538212
Validation loss: 2.4931906711041525

Epoch: 5| Step: 5
Training loss: 2.564980957376983
Validation loss: 2.4932622037289467

Epoch: 5| Step: 6
Training loss: 2.5554931490184387
Validation loss: 2.4907506629452616

Epoch: 5| Step: 7
Training loss: 2.427029741429571
Validation loss: 2.483279560507538

Epoch: 5| Step: 8
Training loss: 2.535556755699002
Validation loss: 2.4972810264719913

Epoch: 5| Step: 9
Training loss: 2.957125260384319
Validation loss: 2.499970030604974

Epoch: 5| Step: 10
Training loss: 2.5067483420795953
Validation loss: 2.4885331470018457

Epoch: 5| Step: 11
Training loss: 1.6980553162801313
Validation loss: 2.4979589355833345

Epoch: 10| Step: 0
Training loss: 1.9655123534317762
Validation loss: 2.4924783287840766

Epoch: 5| Step: 1
Training loss: 3.1837745287534047
Validation loss: 2.4763837964458477

Epoch: 5| Step: 2
Training loss: 2.4035653334693983
Validation loss: 2.484021455572288

Epoch: 5| Step: 3
Training loss: 2.584062616918231
Validation loss: 2.4798723359858226

Epoch: 5| Step: 4
Training loss: 2.6159645981274298
Validation loss: 2.4805491196635634

Epoch: 5| Step: 5
Training loss: 2.034331346737869
Validation loss: 2.4826414709959557

Epoch: 5| Step: 6
Training loss: 2.7168925287011643
Validation loss: 2.4854108222536713

Epoch: 5| Step: 7
Training loss: 2.499155569515117
Validation loss: 2.4913341890992364

Epoch: 5| Step: 8
Training loss: 2.2093979290712604
Validation loss: 2.4869956663426547

Epoch: 5| Step: 9
Training loss: 3.0843201853665216
Validation loss: 2.485372938702482

Epoch: 5| Step: 10
Training loss: 1.952058913147021
Validation loss: 2.4866840660144436

Epoch: 5| Step: 11
Training loss: 2.2668836583260603
Validation loss: 2.4882577269204296

Epoch: 11| Step: 0
Training loss: 2.4973334396465474
Validation loss: 2.4798715227890638

Epoch: 5| Step: 1
Training loss: 2.2183491519370664
Validation loss: 2.4772336112707807

Epoch: 5| Step: 2
Training loss: 2.452567942355795
Validation loss: 2.48421370984382

Epoch: 5| Step: 3
Training loss: 2.6034040834953855
Validation loss: 2.487553680262437

Epoch: 5| Step: 4
Training loss: 2.727892269943899
Validation loss: 2.4822646480684805

Epoch: 5| Step: 5
Training loss: 2.275849416427559
Validation loss: 2.477271575181124

Epoch: 5| Step: 6
Training loss: 2.3760423882424946
Validation loss: 2.4924374717105873

Epoch: 5| Step: 7
Training loss: 2.5765809955476717
Validation loss: 2.4867097392444784

Epoch: 5| Step: 8
Training loss: 2.472905102782835
Validation loss: 2.4891030328439285

Epoch: 5| Step: 9
Training loss: 2.7126612391210925
Validation loss: 2.492686286528018

Epoch: 5| Step: 10
Training loss: 2.642752067215071
Validation loss: 2.4853078182545216

Epoch: 5| Step: 11
Training loss: 2.2285878389578744
Validation loss: 2.4908775067573554

Epoch: 12| Step: 0
Training loss: 2.558048475562263
Validation loss: 2.493855037086496

Epoch: 5| Step: 1
Training loss: 2.413779035301742
Validation loss: 2.4921896644511135

Epoch: 5| Step: 2
Training loss: 2.5274563842390942
Validation loss: 2.4807756149030333

Epoch: 5| Step: 3
Training loss: 1.8516389211343673
Validation loss: 2.489146686446521

Epoch: 5| Step: 4
Training loss: 2.5330889579793414
Validation loss: 2.4789276221510472

Epoch: 5| Step: 5
Training loss: 2.5583529526479074
Validation loss: 2.4859221177631254

Epoch: 5| Step: 6
Training loss: 2.313332588221332
Validation loss: 2.4934666339558533

Epoch: 5| Step: 7
Training loss: 2.9998992267213573
Validation loss: 2.4885335102695456

Epoch: 5| Step: 8
Training loss: 2.4401682407973424
Validation loss: 2.48236419266565

Epoch: 5| Step: 9
Training loss: 2.6907543616482354
Validation loss: 2.4872174586564615

Epoch: 5| Step: 10
Training loss: 2.6876736074751717
Validation loss: 2.4973895550523957

Epoch: 5| Step: 11
Training loss: 1.349391538758053
Validation loss: 2.4980196659295433

Epoch: 13| Step: 0
Training loss: 2.60901579982876
Validation loss: 2.4926885422078886

Epoch: 5| Step: 1
Training loss: 2.9112215895554314
Validation loss: 2.4832166134416593

Epoch: 5| Step: 2
Training loss: 2.516880456631024
Validation loss: 2.4937860948377226

Epoch: 5| Step: 3
Training loss: 2.5741292796121833
Validation loss: 2.484292266875659

Epoch: 5| Step: 4
Training loss: 2.594851891732331
Validation loss: 2.488267492299196

Epoch: 5| Step: 5
Training loss: 2.4272729584015478
Validation loss: 2.4793957930291506

Epoch: 5| Step: 6
Training loss: 2.5882630738766697
Validation loss: 2.484097059365159

Epoch: 5| Step: 7
Training loss: 1.8411548259970525
Validation loss: 2.4840513174458203

Epoch: 5| Step: 8
Training loss: 2.1008751181119396
Validation loss: 2.485478857711352

Epoch: 5| Step: 9
Training loss: 3.0613475888991424
Validation loss: 2.4809463201435635

Epoch: 5| Step: 10
Training loss: 2.0655649704513683
Validation loss: 2.4771269306509573

Epoch: 5| Step: 11
Training loss: 2.2167008299334148
Validation loss: 2.4793030971098227

Epoch: 14| Step: 0
Training loss: 3.0235939478256872
Validation loss: 2.483257858251644

Epoch: 5| Step: 1
Training loss: 2.6921450371916507
Validation loss: 2.4871356868255794

Epoch: 5| Step: 2
Training loss: 1.992538840036182
Validation loss: 2.4849078968410643

Epoch: 5| Step: 3
Training loss: 1.8185135625417912
Validation loss: 2.477409506760872

Epoch: 5| Step: 4
Training loss: 2.606438269092909
Validation loss: 2.4949581048247236

Epoch: 5| Step: 5
Training loss: 2.3456341100445197
Validation loss: 2.4882939097323473

Epoch: 5| Step: 6
Training loss: 2.445434567265769
Validation loss: 2.4977909858801914

Epoch: 5| Step: 7
Training loss: 2.8486932402208356
Validation loss: 2.497169887490321

Epoch: 5| Step: 8
Training loss: 2.3204355945752466
Validation loss: 2.50800862243606

Epoch: 5| Step: 9
Training loss: 3.0331246782857244
Validation loss: 2.508706263344823

Epoch: 5| Step: 10
Training loss: 2.2343319975442872
Validation loss: 2.5010121402694954

Epoch: 5| Step: 11
Training loss: 1.5667658747381168
Validation loss: 2.5056910231568046

Epoch: 15| Step: 0
Training loss: 3.139979661523347
Validation loss: 2.5008633513610325

Epoch: 5| Step: 1
Training loss: 2.202795991612492
Validation loss: 2.4963574456752418

Epoch: 5| Step: 2
Training loss: 2.295708600190744
Validation loss: 2.50493474538407

Epoch: 5| Step: 3
Training loss: 2.6522248231633303
Validation loss: 2.5050252376961444

Epoch: 5| Step: 4
Training loss: 2.086155569271885
Validation loss: 2.5145037148319824

Epoch: 5| Step: 5
Training loss: 2.2485891793354154
Validation loss: 2.518438302277553

Epoch: 5| Step: 6
Training loss: 2.585592010560534
Validation loss: 2.5118402992528917

Epoch: 5| Step: 7
Training loss: 2.0336984989184543
Validation loss: 2.5096891478131456

Epoch: 5| Step: 8
Training loss: 2.7668462955424067
Validation loss: 2.5040503394474576

Epoch: 5| Step: 9
Training loss: 2.8286498199268095
Validation loss: 2.5186510662971795

Epoch: 5| Step: 10
Training loss: 2.4657096007014805
Validation loss: 2.5038314665340273

Epoch: 5| Step: 11
Training loss: 2.22874413404479
Validation loss: 2.502793956206354

Epoch: 16| Step: 0
Training loss: 2.643666158298124
Validation loss: 2.49420359907157

Epoch: 5| Step: 1
Training loss: 1.7242579204636812
Validation loss: 2.495740484432817

Epoch: 5| Step: 2
Training loss: 2.4894410309497044
Validation loss: 2.4886437016855707

Epoch: 5| Step: 3
Training loss: 2.76681251677643
Validation loss: 2.492519663456088

Epoch: 5| Step: 4
Training loss: 2.3761332970164846
Validation loss: 2.4755692199905006

Epoch: 5| Step: 5
Training loss: 2.5200037786667364
Validation loss: 2.48204516281953

Epoch: 5| Step: 6
Training loss: 2.303576599318065
Validation loss: 2.483369567839295

Epoch: 5| Step: 7
Training loss: 2.9928180239410263
Validation loss: 2.4689117612033455

Epoch: 5| Step: 8
Training loss: 1.9226654412128565
Validation loss: 2.4727264000622613

Epoch: 5| Step: 9
Training loss: 2.63608788749274
Validation loss: 2.4930716991934947

Epoch: 5| Step: 10
Training loss: 2.5104151260139096
Validation loss: 2.475534538623302

Epoch: 5| Step: 11
Training loss: 3.1670712329693735
Validation loss: 2.4728312578586173

Epoch: 17| Step: 0
Training loss: 2.4847989470357437
Validation loss: 2.475546739858564

Epoch: 5| Step: 1
Training loss: 2.010982045211575
Validation loss: 2.4803793943635655

Epoch: 5| Step: 2
Training loss: 2.7914604756138073
Validation loss: 2.478714883067909

Epoch: 5| Step: 3
Training loss: 2.011839631532029
Validation loss: 2.4809658083165775

Epoch: 5| Step: 4
Training loss: 2.8560267788996643
Validation loss: 2.472896996098233

Epoch: 5| Step: 5
Training loss: 2.824110944492184
Validation loss: 2.482991033016431

Epoch: 5| Step: 6
Training loss: 2.697590625361334
Validation loss: 2.4686861794507795

Epoch: 5| Step: 7
Training loss: 2.3368992691432626
Validation loss: 2.4722508906251193

Epoch: 5| Step: 8
Training loss: 2.555055830881133
Validation loss: 2.4670714253006834

Epoch: 5| Step: 9
Training loss: 2.3173123367852337
Validation loss: 2.4744690632250874

Epoch: 5| Step: 10
Training loss: 2.406473223748278
Validation loss: 2.4720270683173315

Epoch: 5| Step: 11
Training loss: 1.7768937767450954
Validation loss: 2.4729702164128677

Epoch: 18| Step: 0
Training loss: 2.4432723337064317
Validation loss: 2.487946707904529

Epoch: 5| Step: 1
Training loss: 2.07966866201672
Validation loss: 2.4815567353889443

Epoch: 5| Step: 2
Training loss: 2.4889298436602423
Validation loss: 2.4701035326135905

Epoch: 5| Step: 3
Training loss: 2.7344484155880884
Validation loss: 2.48506140873225

Epoch: 5| Step: 4
Training loss: 2.731250132685119
Validation loss: 2.483647905871055

Epoch: 5| Step: 5
Training loss: 2.4511843251675844
Validation loss: 2.4961335164595253

Epoch: 5| Step: 6
Training loss: 2.3939475114975215
Validation loss: 2.488761799559378

Epoch: 5| Step: 7
Training loss: 2.3429061387750605
Validation loss: 2.488925756548498

Epoch: 5| Step: 8
Training loss: 3.20309686415806
Validation loss: 2.4950626175717807

Epoch: 5| Step: 9
Training loss: 2.1282571625527953
Validation loss: 2.492695253441227

Epoch: 5| Step: 10
Training loss: 2.041625418213909
Validation loss: 2.4847948611252173

Epoch: 5| Step: 11
Training loss: 2.217422087976838
Validation loss: 2.500239555484558

Epoch: 19| Step: 0
Training loss: 2.5021445612810016
Validation loss: 2.4944140016340213

Epoch: 5| Step: 1
Training loss: 3.0141030063151826
Validation loss: 2.491367857031047

Epoch: 5| Step: 2
Training loss: 2.170631986080123
Validation loss: 2.4931298828969735

Epoch: 5| Step: 3
Training loss: 2.0439251325971686
Validation loss: 2.4965393631769026

Epoch: 5| Step: 4
Training loss: 2.5946887052657948
Validation loss: 2.495144698954961

Epoch: 5| Step: 5
Training loss: 1.9418384830711173
Validation loss: 2.4998022160176485

Epoch: 5| Step: 6
Training loss: 2.3044642453439903
Validation loss: 2.4851266135869343

Epoch: 5| Step: 7
Training loss: 2.4946782690940896
Validation loss: 2.4903537257895687

Epoch: 5| Step: 8
Training loss: 2.7962913543548966
Validation loss: 2.478378163827765

Epoch: 5| Step: 9
Training loss: 2.3286252092474697
Validation loss: 2.4988413748509877

Epoch: 5| Step: 10
Training loss: 2.9184612384553286
Validation loss: 2.482756649387044

Epoch: 5| Step: 11
Training loss: 1.499047930887028
Validation loss: 2.481463787916338

Epoch: 20| Step: 0
Training loss: 2.3860894355287776
Validation loss: 2.4752062945976516

Epoch: 5| Step: 1
Training loss: 2.0071690340958095
Validation loss: 2.4758215115612794

Epoch: 5| Step: 2
Training loss: 2.6838463188267383
Validation loss: 2.489646481201252

Epoch: 5| Step: 3
Training loss: 2.9229440620282308
Validation loss: 2.4792821654228043

Epoch: 5| Step: 4
Training loss: 2.1237320202385757
Validation loss: 2.4760672618638093

Epoch: 5| Step: 5
Training loss: 2.3681510751899033
Validation loss: 2.479592672713015

Epoch: 5| Step: 6
Training loss: 1.8519519766478327
Validation loss: 2.468589250344898

Epoch: 5| Step: 7
Training loss: 2.696775089327208
Validation loss: 2.4873960109041646

Epoch: 5| Step: 8
Training loss: 2.160936873319346
Validation loss: 2.4726168974385967

Epoch: 5| Step: 9
Training loss: 2.885589006879874
Validation loss: 2.4590448640226583

Epoch: 5| Step: 10
Training loss: 2.887307898006062
Validation loss: 2.476158903430687

Epoch: 5| Step: 11
Training loss: 1.6166675118644052
Validation loss: 2.4683064814834283

Epoch: 21| Step: 0
Training loss: 2.1636487654832512
Validation loss: 2.4728113560694216

Epoch: 5| Step: 1
Training loss: 2.679639632350801
Validation loss: 2.46423817655205

Epoch: 5| Step: 2
Training loss: 2.6164488703803666
Validation loss: 2.469823483171399

Epoch: 5| Step: 3
Training loss: 1.9500442622125305
Validation loss: 2.4694411360588937

Epoch: 5| Step: 4
Training loss: 2.3799433209378043
Validation loss: 2.4747296078042775

Epoch: 5| Step: 5
Training loss: 2.6725932265776127
Validation loss: 2.483586064115097

Epoch: 5| Step: 6
Training loss: 2.136268247433804
Validation loss: 2.4745316185862336

Epoch: 5| Step: 7
Training loss: 2.1619118701076943
Validation loss: 2.476957279673687

Epoch: 5| Step: 8
Training loss: 2.742971976464921
Validation loss: 2.467753567381009

Epoch: 5| Step: 9
Training loss: 2.8320233364652365
Validation loss: 2.473815726469955

Epoch: 5| Step: 10
Training loss: 2.5583333822078473
Validation loss: 2.487801152678491

Epoch: 5| Step: 11
Training loss: 3.0689594888757252
Validation loss: 2.4735105624626588

Epoch: 22| Step: 0
Training loss: 2.480265739723959
Validation loss: 2.4649367559249646

Epoch: 5| Step: 1
Training loss: 2.110150230085591
Validation loss: 2.481606490360133

Epoch: 5| Step: 2
Training loss: 2.190122286025733
Validation loss: 2.477082692256638

Epoch: 5| Step: 3
Training loss: 2.2646314876130997
Validation loss: 2.4834288468863575

Epoch: 5| Step: 4
Training loss: 2.374029362748416
Validation loss: 2.4805710098133575

Epoch: 5| Step: 5
Training loss: 2.508602790257866
Validation loss: 2.467870885718593

Epoch: 5| Step: 6
Training loss: 2.9306573915389755
Validation loss: 2.4544676935021967

Epoch: 5| Step: 7
Training loss: 2.4456121974018217
Validation loss: 2.4635487583910516

Epoch: 5| Step: 8
Training loss: 2.4640721293704524
Validation loss: 2.467617402844304

Epoch: 5| Step: 9
Training loss: 2.8776832995458954
Validation loss: 2.4680571287986517

Epoch: 5| Step: 10
Training loss: 2.443672580907316
Validation loss: 2.4640843127794425

Epoch: 5| Step: 11
Training loss: 1.7603548780202882
Validation loss: 2.4704917405160325

Epoch: 23| Step: 0
Training loss: 2.8098199578977976
Validation loss: 2.471816472237949

Epoch: 5| Step: 1
Training loss: 2.8602657077312315
Validation loss: 2.4854841015842584

Epoch: 5| Step: 2
Training loss: 2.6563936082503146
Validation loss: 2.474740911820133

Epoch: 5| Step: 3
Training loss: 2.082706993046376
Validation loss: 2.484428745064307

Epoch: 5| Step: 4
Training loss: 2.51216645944826
Validation loss: 2.4787510208240637

Epoch: 5| Step: 5
Training loss: 2.9354994434375006
Validation loss: 2.4943422790116965

Epoch: 5| Step: 6
Training loss: 2.456929457940868
Validation loss: 2.4875103980634607

Epoch: 5| Step: 7
Training loss: 2.2495088041107394
Validation loss: 2.4943754821945103

Epoch: 5| Step: 8
Training loss: 2.3044307242418007
Validation loss: 2.5056487758323898

Epoch: 5| Step: 9
Training loss: 2.2578223205141636
Validation loss: 2.492938387964937

Epoch: 5| Step: 10
Training loss: 1.8830431405148202
Validation loss: 2.4827791222548794

Epoch: 5| Step: 11
Training loss: 1.1226518284465707
Validation loss: 2.500209668427221

Epoch: 24| Step: 0
Training loss: 2.812955268463526
Validation loss: 2.4917032853649697

Epoch: 5| Step: 1
Training loss: 2.571509456497716
Validation loss: 2.501738595413456

Epoch: 5| Step: 2
Training loss: 2.875334678740982
Validation loss: 2.498071990037242

Epoch: 5| Step: 3
Training loss: 2.0585129086801075
Validation loss: 2.4955138804995474

Epoch: 5| Step: 4
Training loss: 2.2188439147845145
Validation loss: 2.4822900928700964

Epoch: 5| Step: 5
Training loss: 2.8716557166860692
Validation loss: 2.497314484948329

Epoch: 5| Step: 6
Training loss: 2.0689289580326897
Validation loss: 2.4983038830967086

Epoch: 5| Step: 7
Training loss: 2.1001852407952724
Validation loss: 2.4971506292092136

Epoch: 5| Step: 8
Training loss: 2.792554619237038
Validation loss: 2.505078553600702

Epoch: 5| Step: 9
Training loss: 2.2635654954377245
Validation loss: 2.4900967069981017

Epoch: 5| Step: 10
Training loss: 2.2170217526013514
Validation loss: 2.474905954205372

Epoch: 5| Step: 11
Training loss: 1.9052976511907997
Validation loss: 2.4853324764495643

Epoch: 25| Step: 0
Training loss: 2.7562058391190587
Validation loss: 2.473739623725388

Epoch: 5| Step: 1
Training loss: 2.5165842253295416
Validation loss: 2.4733133753599392

Epoch: 5| Step: 2
Training loss: 2.3164849871011657
Validation loss: 2.458969007084995

Epoch: 5| Step: 3
Training loss: 2.369931786275787
Validation loss: 2.4641230436864396

Epoch: 5| Step: 4
Training loss: 2.8253786019009186
Validation loss: 2.4610517969786527

Epoch: 5| Step: 5
Training loss: 2.514535798448144
Validation loss: 2.4598533139392935

Epoch: 5| Step: 6
Training loss: 2.5805117569751475
Validation loss: 2.4708290198697482

Epoch: 5| Step: 7
Training loss: 2.2865539971037516
Validation loss: 2.4735788288493326

Epoch: 5| Step: 8
Training loss: 2.2368934150101936
Validation loss: 2.4573280628242347

Epoch: 5| Step: 9
Training loss: 2.2777210269877712
Validation loss: 2.471701616008844

Epoch: 5| Step: 10
Training loss: 2.4850084948634397
Validation loss: 2.470538187866874

Epoch: 5| Step: 11
Training loss: 1.0864606735969908
Validation loss: 2.4664749454940194

Epoch: 26| Step: 0
Training loss: 2.046262110614301
Validation loss: 2.4630440874158874

Epoch: 5| Step: 1
Training loss: 2.637342771933046
Validation loss: 2.45845465980322

Epoch: 5| Step: 2
Training loss: 2.61193767500707
Validation loss: 2.475062946199868

Epoch: 5| Step: 3
Training loss: 1.7959946175687886
Validation loss: 2.465330387204839

Epoch: 5| Step: 4
Training loss: 2.4463094318326113
Validation loss: 2.466797817347838

Epoch: 5| Step: 5
Training loss: 2.331652024200178
Validation loss: 2.466742028930204

Epoch: 5| Step: 6
Training loss: 2.672795990271074
Validation loss: 2.473913944582334

Epoch: 5| Step: 7
Training loss: 2.536153964371989
Validation loss: 2.468918243341089

Epoch: 5| Step: 8
Training loss: 2.2444297929585635
Validation loss: 2.4704125878110625

Epoch: 5| Step: 9
Training loss: 2.6550812786757607
Validation loss: 2.4762544330041814

Epoch: 5| Step: 10
Training loss: 2.5854405965832385
Validation loss: 2.471199936604872

Epoch: 5| Step: 11
Training loss: 3.2286070472064257
Validation loss: 2.4742477943667796

Epoch: 27| Step: 0
Training loss: 3.063233890960261
Validation loss: 2.463846898811218

Epoch: 5| Step: 1
Training loss: 2.7411527501784336
Validation loss: 2.466736688833591

Epoch: 5| Step: 2
Training loss: 1.8251806169778582
Validation loss: 2.4581640610904048

Epoch: 5| Step: 3
Training loss: 2.38899225065588
Validation loss: 2.4721843918097814

Epoch: 5| Step: 4
Training loss: 2.3793032961583234
Validation loss: 2.478711219967731

Epoch: 5| Step: 5
Training loss: 3.067283475737485
Validation loss: 2.474609768412578

Epoch: 5| Step: 6
Training loss: 1.9365222063315553
Validation loss: 2.462557256584833

Epoch: 5| Step: 7
Training loss: 2.2711356658794273
Validation loss: 2.4543197379007906

Epoch: 5| Step: 8
Training loss: 2.4366533814297244
Validation loss: 2.4647761686786485

Epoch: 5| Step: 9
Training loss: 2.341146930924874
Validation loss: 2.463492456849281

Epoch: 5| Step: 10
Training loss: 2.3928988743866237
Validation loss: 2.483531436816431

Epoch: 5| Step: 11
Training loss: 1.4846152663278362
Validation loss: 2.4615332714872022

Epoch: 28| Step: 0
Training loss: 2.4703350531786934
Validation loss: 2.468996631197706

Epoch: 5| Step: 1
Training loss: 2.3056110148162126
Validation loss: 2.4832162333941534

Epoch: 5| Step: 2
Training loss: 2.1000530962816506
Validation loss: 2.4681179106613667

Epoch: 5| Step: 3
Training loss: 1.7857809830879923
Validation loss: 2.464554299650837

Epoch: 5| Step: 4
Training loss: 2.5304200495443894
Validation loss: 2.458552562238112

Epoch: 5| Step: 5
Training loss: 2.601188014115441
Validation loss: 2.4767709177047172

Epoch: 5| Step: 6
Training loss: 3.0037055971671265
Validation loss: 2.4679012529659428

Epoch: 5| Step: 7
Training loss: 2.376982213064108
Validation loss: 2.4659179829305438

Epoch: 5| Step: 8
Training loss: 2.905597080187654
Validation loss: 2.459407726524114

Epoch: 5| Step: 9
Training loss: 2.1568476636464724
Validation loss: 2.4677576815071105

Epoch: 5| Step: 10
Training loss: 2.3021129646523133
Validation loss: 2.4631288046728015

Epoch: 5| Step: 11
Training loss: 2.7985755396481515
Validation loss: 2.4713043968942734

Epoch: 29| Step: 0
Training loss: 2.62567802028793
Validation loss: 2.4569752357781285

Epoch: 5| Step: 1
Training loss: 1.8770008855135765
Validation loss: 2.460245780006234

Epoch: 5| Step: 2
Training loss: 2.519245835335929
Validation loss: 2.4750772910460217

Epoch: 5| Step: 3
Training loss: 2.623378979755563
Validation loss: 2.4594705397497263

Epoch: 5| Step: 4
Training loss: 2.814304705272884
Validation loss: 2.465703984402801

Epoch: 5| Step: 5
Training loss: 2.6513826541906154
Validation loss: 2.456226862085803

Epoch: 5| Step: 6
Training loss: 2.1914721800326222
Validation loss: 2.4559276105541916

Epoch: 5| Step: 7
Training loss: 2.297230699465372
Validation loss: 2.449748090035342

Epoch: 5| Step: 8
Training loss: 2.253994151604553
Validation loss: 2.4606838842427106

Epoch: 5| Step: 9
Training loss: 2.7446760313708056
Validation loss: 2.460615788982638

Epoch: 5| Step: 10
Training loss: 2.185531275252917
Validation loss: 2.4590780590290855

Epoch: 5| Step: 11
Training loss: 1.4151201034095922
Validation loss: 2.465640435535124

Epoch: 30| Step: 0
Training loss: 2.259059258185723
Validation loss: 2.479638765301266

Epoch: 5| Step: 1
Training loss: 2.732832119120453
Validation loss: 2.4656830702254036

Epoch: 5| Step: 2
Training loss: 2.1006780982804614
Validation loss: 2.4696144570292957

Epoch: 5| Step: 3
Training loss: 2.399687897733945
Validation loss: 2.4781630084605366

Epoch: 5| Step: 4
Training loss: 1.9854382647540099
Validation loss: 2.477466927534427

Epoch: 5| Step: 5
Training loss: 2.640195913270305
Validation loss: 2.4572742707877997

Epoch: 5| Step: 6
Training loss: 2.8951863359692256
Validation loss: 2.4739893794203134

Epoch: 5| Step: 7
Training loss: 2.5055042708007855
Validation loss: 2.4668308556744023

Epoch: 5| Step: 8
Training loss: 2.3794179281536163
Validation loss: 2.4630833146308153

Epoch: 5| Step: 9
Training loss: 2.4465251998991255
Validation loss: 2.465840492291859

Epoch: 5| Step: 10
Training loss: 2.296121071324883
Validation loss: 2.474837162460152

Epoch: 5| Step: 11
Training loss: 2.733021079424938
Validation loss: 2.4688614123994177

Epoch: 31| Step: 0
Training loss: 2.4215082690774965
Validation loss: 2.449981134773465

Epoch: 5| Step: 1
Training loss: 2.4121760926691644
Validation loss: 2.4652748536971636

Epoch: 5| Step: 2
Training loss: 2.6653155738686714
Validation loss: 2.4607777659735706

Epoch: 5| Step: 3
Training loss: 2.0304976023509793
Validation loss: 2.458374351762714

Epoch: 5| Step: 4
Training loss: 2.1124133797668065
Validation loss: 2.4772457620310697

Epoch: 5| Step: 5
Training loss: 2.338873813436596
Validation loss: 2.4761408056735252

Epoch: 5| Step: 6
Training loss: 2.5172473107116256
Validation loss: 2.4833746361551325

Epoch: 5| Step: 7
Training loss: 2.8269129732471407
Validation loss: 2.46617234137581

Epoch: 5| Step: 8
Training loss: 2.3265393893270607
Validation loss: 2.4781324502737547

Epoch: 5| Step: 9
Training loss: 2.5455655903560386
Validation loss: 2.4613694755431887

Epoch: 5| Step: 10
Training loss: 2.3505880675169513
Validation loss: 2.467745097573389

Epoch: 5| Step: 11
Training loss: 2.8670366543787456
Validation loss: 2.444180227459463

Epoch: 32| Step: 0
Training loss: 2.885802829576443
Validation loss: 2.455301878005814

Epoch: 5| Step: 1
Training loss: 2.155424761764021
Validation loss: 2.452561603327219

Epoch: 5| Step: 2
Training loss: 2.1953265098043295
Validation loss: 2.452911108455729

Epoch: 5| Step: 3
Training loss: 2.2862742240544294
Validation loss: 2.4497541220705203

Epoch: 5| Step: 4
Training loss: 1.9320796085881449
Validation loss: 2.4541631676455187

Epoch: 5| Step: 5
Training loss: 2.879551311880284
Validation loss: 2.4503422441312304

Epoch: 5| Step: 6
Training loss: 2.405703693152344
Validation loss: 2.459668311563336

Epoch: 5| Step: 7
Training loss: 2.475645647701997
Validation loss: 2.463310385419924

Epoch: 5| Step: 8
Training loss: 2.514363985732094
Validation loss: 2.4486981111811947

Epoch: 5| Step: 9
Training loss: 2.276349172762265
Validation loss: 2.4421816843085216

Epoch: 5| Step: 10
Training loss: 2.245730057171845
Validation loss: 2.474588359451478

Epoch: 5| Step: 11
Training loss: 3.5767089173830597
Validation loss: 2.449432643573215

Epoch: 33| Step: 0
Training loss: 2.8967871067247954
Validation loss: 2.456145676329822

Epoch: 5| Step: 1
Training loss: 2.2841154940009716
Validation loss: 2.4560517955077925

Epoch: 5| Step: 2
Training loss: 2.348879478016293
Validation loss: 2.45111737235015

Epoch: 5| Step: 3
Training loss: 2.3726899808785236
Validation loss: 2.4578541083834557

Epoch: 5| Step: 4
Training loss: 2.447498453546957
Validation loss: 2.4430958325959495

Epoch: 5| Step: 5
Training loss: 2.075120173272022
Validation loss: 2.4666434889963145

Epoch: 5| Step: 6
Training loss: 2.4737121352448956
Validation loss: 2.459171727370361

Epoch: 5| Step: 7
Training loss: 2.4442636598820053
Validation loss: 2.4544223141139043

Epoch: 5| Step: 8
Training loss: 2.741560209424001
Validation loss: 2.4669327505932452

Epoch: 5| Step: 9
Training loss: 2.6114610568259216
Validation loss: 2.4554627409847414

Epoch: 5| Step: 10
Training loss: 2.2651891881149533
Validation loss: 2.4493586750205174

Epoch: 5| Step: 11
Training loss: 1.52265925947805
Validation loss: 2.4448565889885545

Epoch: 34| Step: 0
Training loss: 2.509913244989852
Validation loss: 2.453486122391658

Epoch: 5| Step: 1
Training loss: 2.6224029955092165
Validation loss: 2.459510914505809

Epoch: 5| Step: 2
Training loss: 1.9650098605308937
Validation loss: 2.4641846804905905

Epoch: 5| Step: 3
Training loss: 2.2507713902901996
Validation loss: 2.477922000243166

Epoch: 5| Step: 4
Training loss: 3.1945559625003264
Validation loss: 2.5146209893071148

Epoch: 5| Step: 5
Training loss: 2.4934192830161455
Validation loss: 2.4982163086219513

Epoch: 5| Step: 6
Training loss: 1.8835725002284736
Validation loss: 2.5032774799812922

Epoch: 5| Step: 7
Training loss: 2.8306170701353617
Validation loss: 2.5060782491825853

Epoch: 5| Step: 8
Training loss: 2.4832328234137733
Validation loss: 2.52763827620755

Epoch: 5| Step: 9
Training loss: 2.0918621833073554
Validation loss: 2.5082375076171948

Epoch: 5| Step: 10
Training loss: 1.998935714310107
Validation loss: 2.497187745325774

Epoch: 5| Step: 11
Training loss: 2.561130716088376
Validation loss: 2.4932756748859495

Epoch: 35| Step: 0
Training loss: 2.2374804064356293
Validation loss: 2.4959085999753166

Epoch: 5| Step: 1
Training loss: 2.1235499202787804
Validation loss: 2.4900086224520304

Epoch: 5| Step: 2
Training loss: 2.5658772241204866
Validation loss: 2.485661607350763

Epoch: 5| Step: 3
Training loss: 2.284312870208778
Validation loss: 2.4838191436220285

Epoch: 5| Step: 4
Training loss: 2.470114608453228
Validation loss: 2.484985764320068

Epoch: 5| Step: 5
Training loss: 2.8495672064648967
Validation loss: 2.48520949881384

Epoch: 5| Step: 6
Training loss: 2.6853808542432906
Validation loss: 2.4701232712212953

Epoch: 5| Step: 7
Training loss: 2.639145114795828
Validation loss: 2.4629732179116184

Epoch: 5| Step: 8
Training loss: 2.357267335189367
Validation loss: 2.459407411464344

Epoch: 5| Step: 9
Training loss: 2.25611385875189
Validation loss: 2.4391971654411226

Epoch: 5| Step: 10
Training loss: 2.261878763972047
Validation loss: 2.4617156115590304

Epoch: 5| Step: 11
Training loss: 1.2299043360004003
Validation loss: 2.4405434510579966

Epoch: 36| Step: 0
Training loss: 1.9744596490588808
Validation loss: 2.4438955327087952

Epoch: 5| Step: 1
Training loss: 2.5434414238248584
Validation loss: 2.4524832815558986

Epoch: 5| Step: 2
Training loss: 2.4050950089878573
Validation loss: 2.457974896054591

Epoch: 5| Step: 3
Training loss: 2.2423438040984727
Validation loss: 2.4588584857577644

Epoch: 5| Step: 4
Training loss: 1.75879997491496
Validation loss: 2.4378931775838915

Epoch: 5| Step: 5
Training loss: 3.007421532524497
Validation loss: 2.4566164460045963

Epoch: 5| Step: 6
Training loss: 2.2047099371186754
Validation loss: 2.4451553732995794

Epoch: 5| Step: 7
Training loss: 2.628291836227361
Validation loss: 2.459885540925274

Epoch: 5| Step: 8
Training loss: 2.5125005048305327
Validation loss: 2.4728349678332995

Epoch: 5| Step: 9
Training loss: 2.7159289928474664
Validation loss: 2.4613410578451873

Epoch: 5| Step: 10
Training loss: 2.553341478861008
Validation loss: 2.4730480420042524

Epoch: 5| Step: 11
Training loss: 0.7977606769470108
Validation loss: 2.47280242150397

Epoch: 37| Step: 0
Training loss: 2.439672822122652
Validation loss: 2.4501125442839338

Epoch: 5| Step: 1
Training loss: 2.287226334341312
Validation loss: 2.4570457365076943

Epoch: 5| Step: 2
Training loss: 1.8516017732599799
Validation loss: 2.464673023789981

Epoch: 5| Step: 3
Training loss: 2.549558664913153
Validation loss: 2.456142553902716

Epoch: 5| Step: 4
Training loss: 2.610384443185169
Validation loss: 2.465299389898162

Epoch: 5| Step: 5
Training loss: 1.8936391716180718
Validation loss: 2.4576802409923495

Epoch: 5| Step: 6
Training loss: 2.22281950500234
Validation loss: 2.467699112934639

Epoch: 5| Step: 7
Training loss: 2.805618854056238
Validation loss: 2.4566479552249545

Epoch: 5| Step: 8
Training loss: 1.8513868546369396
Validation loss: 2.4429914043414267

Epoch: 5| Step: 9
Training loss: 3.1257881696491454
Validation loss: 2.45102629412883

Epoch: 5| Step: 10
Training loss: 2.567174601972316
Validation loss: 2.4371714655862324

Epoch: 5| Step: 11
Training loss: 1.661866005496231
Validation loss: 2.4413655147968827

Epoch: 38| Step: 0
Training loss: 2.378263339656975
Validation loss: 2.462456641001049

Epoch: 5| Step: 1
Training loss: 2.8172724604688333
Validation loss: 2.441688749118022

Epoch: 5| Step: 2
Training loss: 1.8508345706162088
Validation loss: 2.4379693582000197

Epoch: 5| Step: 3
Training loss: 2.9921331575005743
Validation loss: 2.437610911022323

Epoch: 5| Step: 4
Training loss: 2.68963024079786
Validation loss: 2.433565412083894

Epoch: 5| Step: 5
Training loss: 2.3575005569538257
Validation loss: 2.4498627063014498

Epoch: 5| Step: 6
Training loss: 2.412605907902429
Validation loss: 2.438728666787405

Epoch: 5| Step: 7
Training loss: 2.2804311040245517
Validation loss: 2.4318266934005774

Epoch: 5| Step: 8
Training loss: 1.9148007584550613
Validation loss: 2.4510837128730936

Epoch: 5| Step: 9
Training loss: 2.264649806118873
Validation loss: 2.4410249946452263

Epoch: 5| Step: 10
Training loss: 2.380680618898301
Validation loss: 2.4358154695329777

Epoch: 5| Step: 11
Training loss: 1.8516483850317726
Validation loss: 2.4556668894945743

Epoch: 39| Step: 0
Training loss: 2.6586162125644326
Validation loss: 2.442913812699316

Epoch: 5| Step: 1
Training loss: 2.7222781910840963
Validation loss: 2.4522254088107944

Epoch: 5| Step: 2
Training loss: 2.176152360315425
Validation loss: 2.467330778188223

Epoch: 5| Step: 3
Training loss: 2.799187753576553
Validation loss: 2.479123945963383

Epoch: 5| Step: 4
Training loss: 2.0756162256953066
Validation loss: 2.474796297138771

Epoch: 5| Step: 5
Training loss: 2.1029503079509944
Validation loss: 2.4674483259833138

Epoch: 5| Step: 6
Training loss: 1.9811146903539076
Validation loss: 2.470015977841281

Epoch: 5| Step: 7
Training loss: 1.7921492422023044
Validation loss: 2.4778644777592955

Epoch: 5| Step: 8
Training loss: 2.415544863379588
Validation loss: 2.5193859482299166

Epoch: 5| Step: 9
Training loss: 3.0472961134767407
Validation loss: 2.5127626566455707

Epoch: 5| Step: 10
Training loss: 2.480254396803636
Validation loss: 2.5179411648809413

Epoch: 5| Step: 11
Training loss: 1.6180497234423108
Validation loss: 2.493812844194448

Epoch: 40| Step: 0
Training loss: 2.1385068786239327
Validation loss: 2.4723909224648994

Epoch: 5| Step: 1
Training loss: 2.7217245382248176
Validation loss: 2.4685798377131083

Epoch: 5| Step: 2
Training loss: 2.1595644700746806
Validation loss: 2.4662894650572595

Epoch: 5| Step: 3
Training loss: 2.1396898886331734
Validation loss: 2.4511752084250915

Epoch: 5| Step: 4
Training loss: 2.8505461253215056
Validation loss: 2.4349202438735635

Epoch: 5| Step: 5
Training loss: 2.1277450334349575
Validation loss: 2.438239792285252

Epoch: 5| Step: 6
Training loss: 2.622460181094886
Validation loss: 2.4427284952943444

Epoch: 5| Step: 7
Training loss: 2.1818973181923593
Validation loss: 2.4371749832412988

Epoch: 5| Step: 8
Training loss: 2.484450141202249
Validation loss: 2.430397101792823

Epoch: 5| Step: 9
Training loss: 2.364682121285862
Validation loss: 2.43488988144635

Epoch: 5| Step: 10
Training loss: 2.4635782272712117
Validation loss: 2.4371066142801974

Epoch: 5| Step: 11
Training loss: 2.049791893049041
Validation loss: 2.4552902821937166

Epoch: 41| Step: 0
Training loss: 2.3223503232096916
Validation loss: 2.4337388715341013

Epoch: 5| Step: 1
Training loss: 2.3739166800669618
Validation loss: 2.445718703083004

Epoch: 5| Step: 2
Training loss: 2.486687022254544
Validation loss: 2.4442569172759265

Epoch: 5| Step: 3
Training loss: 2.679563647374705
Validation loss: 2.461035025142641

Epoch: 5| Step: 4
Training loss: 1.9914524293007163
Validation loss: 2.471000132846198

Epoch: 5| Step: 5
Training loss: 1.8037224373195264
Validation loss: 2.459355226103586

Epoch: 5| Step: 6
Training loss: 2.293278583863724
Validation loss: 2.4766645540856924

Epoch: 5| Step: 7
Training loss: 2.207490640276964
Validation loss: 2.4924160963110515

Epoch: 5| Step: 8
Training loss: 2.895954724152859
Validation loss: 2.508773651214302

Epoch: 5| Step: 9
Training loss: 2.5577469450904693
Validation loss: 2.5093114102969536

Epoch: 5| Step: 10
Training loss: 2.7162600109549597
Validation loss: 2.495684915092947

Epoch: 5| Step: 11
Training loss: 2.078300526025303
Validation loss: 2.4837060983531494

Epoch: 42| Step: 0
Training loss: 2.4741131436280646
Validation loss: 2.491297324714127

Epoch: 5| Step: 1
Training loss: 2.2949793252450013
Validation loss: 2.475058009370126

Epoch: 5| Step: 2
Training loss: 2.5123624317977087
Validation loss: 2.469917021527485

Epoch: 5| Step: 3
Training loss: 2.556593064695613
Validation loss: 2.4604094852167204

Epoch: 5| Step: 4
Training loss: 2.8689378597939994
Validation loss: 2.450478614554252

Epoch: 5| Step: 5
Training loss: 1.9221961520686666
Validation loss: 2.457865174754282

Epoch: 5| Step: 6
Training loss: 2.0672098194627235
Validation loss: 2.4519509484479585

Epoch: 5| Step: 7
Training loss: 2.3966949793169463
Validation loss: 2.4471346086126795

Epoch: 5| Step: 8
Training loss: 2.140394546466767
Validation loss: 2.4474654424368816

Epoch: 5| Step: 9
Training loss: 2.046799985952491
Validation loss: 2.4399731063793784

Epoch: 5| Step: 10
Training loss: 2.8327184645735857
Validation loss: 2.443585034466738

Epoch: 5| Step: 11
Training loss: 1.7857993405385637
Validation loss: 2.4326021328499423

Epoch: 43| Step: 0
Training loss: 3.0603475986596003
Validation loss: 2.412091616257586

Epoch: 5| Step: 1
Training loss: 2.7193225827663525
Validation loss: 2.4413889078160103

Epoch: 5| Step: 2
Training loss: 1.5695158802455282
Validation loss: 2.451930008121358

Epoch: 5| Step: 3
Training loss: 2.215797716734173
Validation loss: 2.432321835534316

Epoch: 5| Step: 4
Training loss: 2.3374225909629387
Validation loss: 2.444391156257564

Epoch: 5| Step: 5
Training loss: 2.408393202656808
Validation loss: 2.460229372141373

Epoch: 5| Step: 6
Training loss: 2.5401955292001843
Validation loss: 2.458959981824109

Epoch: 5| Step: 7
Training loss: 2.1024585501160433
Validation loss: 2.468822912757098

Epoch: 5| Step: 8
Training loss: 2.3593292231887295
Validation loss: 2.468539076055856

Epoch: 5| Step: 9
Training loss: 2.207940000617246
Validation loss: 2.4695085816719233

Epoch: 5| Step: 10
Training loss: 2.0225968547777353
Validation loss: 2.4731494678825876

Epoch: 5| Step: 11
Training loss: 3.157700460297089
Validation loss: 2.464247702518649

Epoch: 44| Step: 0
Training loss: 2.609450744625993
Validation loss: 2.4725922851967

Epoch: 5| Step: 1
Training loss: 2.3405094377946356
Validation loss: 2.450457181249127

Epoch: 5| Step: 2
Training loss: 2.3024089347069534
Validation loss: 2.4572809736324532

Epoch: 5| Step: 3
Training loss: 2.2492835705643133
Validation loss: 2.4366613049639496

Epoch: 5| Step: 4
Training loss: 2.353022226873068
Validation loss: 2.4591290403861708

Epoch: 5| Step: 5
Training loss: 2.041858145110335
Validation loss: 2.44114148955016

Epoch: 5| Step: 6
Training loss: 2.6182371852841255
Validation loss: 2.4371623840616143

Epoch: 5| Step: 7
Training loss: 2.3051715924322513
Validation loss: 2.429804828750646

Epoch: 5| Step: 8
Training loss: 2.299587179536593
Validation loss: 2.4359948980792674

Epoch: 5| Step: 9
Training loss: 2.4179066294145635
Validation loss: 2.4276074892676207

Epoch: 5| Step: 10
Training loss: 2.442428887385277
Validation loss: 2.425723654144646

Epoch: 5| Step: 11
Training loss: 2.9795152331335877
Validation loss: 2.434486482587021

Epoch: 45| Step: 0
Training loss: 2.4446860781605384
Validation loss: 2.4485366658389296

Epoch: 5| Step: 1
Training loss: 2.180300718617112
Validation loss: 2.4420081574105623

Epoch: 5| Step: 2
Training loss: 1.8744168328338975
Validation loss: 2.432832585592622

Epoch: 5| Step: 3
Training loss: 2.495341060620688
Validation loss: 2.4378566440275304

Epoch: 5| Step: 4
Training loss: 2.7743412748118708
Validation loss: 2.4359052833349963

Epoch: 5| Step: 5
Training loss: 2.413775281887317
Validation loss: 2.440019141269345

Epoch: 5| Step: 6
Training loss: 2.3628512409022497
Validation loss: 2.4585393493342305

Epoch: 5| Step: 7
Training loss: 2.4318749494903096
Validation loss: 2.442325604081587

Epoch: 5| Step: 8
Training loss: 2.084855273961888
Validation loss: 2.437475937944636

Epoch: 5| Step: 9
Training loss: 2.131765255212806
Validation loss: 2.4317558945549442

Epoch: 5| Step: 10
Training loss: 2.67271526129907
Validation loss: 2.438518099621406

Epoch: 5| Step: 11
Training loss: 2.2829638797143335
Validation loss: 2.4497114554939268

Epoch: 46| Step: 0
Training loss: 2.4024958864746444
Validation loss: 2.4404577584628404

Epoch: 5| Step: 1
Training loss: 2.123840801235563
Validation loss: 2.451488917137757

Epoch: 5| Step: 2
Training loss: 2.2411066833050564
Validation loss: 2.441255472232111

Epoch: 5| Step: 3
Training loss: 2.1978786037337206
Validation loss: 2.437679950478349

Epoch: 5| Step: 4
Training loss: 2.812213544032962
Validation loss: 2.425331035039051

Epoch: 5| Step: 5
Training loss: 1.9748751105887925
Validation loss: 2.4279418021946193

Epoch: 5| Step: 6
Training loss: 2.051628824107611
Validation loss: 2.427723703235629

Epoch: 5| Step: 7
Training loss: 2.180074896619519
Validation loss: 2.4422862956507476

Epoch: 5| Step: 8
Training loss: 2.2362700209086546
Validation loss: 2.4471576115791573

Epoch: 5| Step: 9
Training loss: 2.5124618831039593
Validation loss: 2.427443642674134

Epoch: 5| Step: 10
Training loss: 2.7282155444663587
Validation loss: 2.434261089691072

Epoch: 5| Step: 11
Training loss: 3.1080808773932316
Validation loss: 2.427028791827124

Epoch: 47| Step: 0
Training loss: 2.2769450497905357
Validation loss: 2.4536021187751373

Epoch: 5| Step: 1
Training loss: 2.1690832624058642
Validation loss: 2.4505952681216887

Epoch: 5| Step: 2
Training loss: 3.0367058488960907
Validation loss: 2.4276573125956356

Epoch: 5| Step: 3
Training loss: 2.4818730261551543
Validation loss: 2.432825815388544

Epoch: 5| Step: 4
Training loss: 2.6962212398942316
Validation loss: 2.457458414487164

Epoch: 5| Step: 5
Training loss: 2.297891923685323
Validation loss: 2.4487128173759896

Epoch: 5| Step: 6
Training loss: 2.33201836817265
Validation loss: 2.4460819890241

Epoch: 5| Step: 7
Training loss: 2.0180932833960576
Validation loss: 2.435496525778107

Epoch: 5| Step: 8
Training loss: 2.022860529468032
Validation loss: 2.4458297694265294

Epoch: 5| Step: 9
Training loss: 2.2831032945722196
Validation loss: 2.4532290434590633

Epoch: 5| Step: 10
Training loss: 2.172975659202058
Validation loss: 2.4441722653018454

Epoch: 5| Step: 11
Training loss: 1.7290134898288834
Validation loss: 2.4629514012613773

Epoch: 48| Step: 0
Training loss: 2.3094273335433693
Validation loss: 2.4487114704950645

Epoch: 5| Step: 1
Training loss: 2.172217472436541
Validation loss: 2.433919208249917

Epoch: 5| Step: 2
Training loss: 2.3553809913494677
Validation loss: 2.443342127994497

Epoch: 5| Step: 3
Training loss: 2.1772114352513086
Validation loss: 2.4223543820675535

Epoch: 5| Step: 4
Training loss: 2.5871018845203357
Validation loss: 2.4393902646576833

Epoch: 5| Step: 5
Training loss: 2.464905268026883
Validation loss: 2.444524571039933

Epoch: 5| Step: 6
Training loss: 2.2741504088878717
Validation loss: 2.4248816459652915

Epoch: 5| Step: 7
Training loss: 2.5431709736521464
Validation loss: 2.4320610489792953

Epoch: 5| Step: 8
Training loss: 2.1990225180964416
Validation loss: 2.435175259854238

Epoch: 5| Step: 9
Training loss: 2.4716584661771726
Validation loss: 2.4344590283159233

Epoch: 5| Step: 10
Training loss: 2.214528756053793
Validation loss: 2.438059732368169

Epoch: 5| Step: 11
Training loss: 2.243103478244222
Validation loss: 2.4384268930163664

Epoch: 49| Step: 0
Training loss: 2.2487333759162005
Validation loss: 2.432997649425422

Epoch: 5| Step: 1
Training loss: 2.347925256433037
Validation loss: 2.451268200039187

Epoch: 5| Step: 2
Training loss: 2.0950403365301185
Validation loss: 2.454961595422646

Epoch: 5| Step: 3
Training loss: 2.5112076353503303
Validation loss: 2.463084734316783

Epoch: 5| Step: 4
Training loss: 1.8343014184078357
Validation loss: 2.457703753581874

Epoch: 5| Step: 5
Training loss: 2.727236339297444
Validation loss: 2.437606878464288

Epoch: 5| Step: 6
Training loss: 2.29431476760233
Validation loss: 2.4576792951485595

Epoch: 5| Step: 7
Training loss: 2.536877346220997
Validation loss: 2.4618736989093

Epoch: 5| Step: 8
Training loss: 2.527914227539549
Validation loss: 2.45876490043

Epoch: 5| Step: 9
Training loss: 2.2650451970590915
Validation loss: 2.4501725022577094

Epoch: 5| Step: 10
Training loss: 2.221161512373716
Validation loss: 2.4309439972395386

Epoch: 5| Step: 11
Training loss: 1.665447965736158
Validation loss: 2.437749703161687

Epoch: 50| Step: 0
Training loss: 2.301324284819005
Validation loss: 2.432159529833153

Epoch: 5| Step: 1
Training loss: 2.3610318663020724
Validation loss: 2.4415532670578246

Epoch: 5| Step: 2
Training loss: 2.492879167678854
Validation loss: 2.4341982340264914

Epoch: 5| Step: 3
Training loss: 2.094778918343375
Validation loss: 2.412430920707212

Epoch: 5| Step: 4
Training loss: 1.8691512120504112
Validation loss: 2.427708337940345

Epoch: 5| Step: 5
Training loss: 2.5887920378804217
Validation loss: 2.430964560534038

Epoch: 5| Step: 6
Training loss: 2.0634973599874784
Validation loss: 2.427036192167396

Epoch: 5| Step: 7
Training loss: 2.3180979426232704
Validation loss: 2.4277209902757813

Epoch: 5| Step: 8
Training loss: 2.128348685228886
Validation loss: 2.440876277112982

Epoch: 5| Step: 9
Training loss: 2.4270208020538875
Validation loss: 2.4350108005628806

Epoch: 5| Step: 10
Training loss: 2.9403439005357805
Validation loss: 2.4201720865004748

Epoch: 5| Step: 11
Training loss: 2.500386875735599
Validation loss: 2.4312220834961487

Epoch: 51| Step: 0
Training loss: 2.0888502950462358
Validation loss: 2.457034419815291

Epoch: 5| Step: 1
Training loss: 1.8037039318268795
Validation loss: 2.428808476445487

Epoch: 5| Step: 2
Training loss: 2.3531915338641793
Validation loss: 2.425615596797245

Epoch: 5| Step: 3
Training loss: 2.7367377835634685
Validation loss: 2.4361655340008297

Epoch: 5| Step: 4
Training loss: 2.3179399581782176
Validation loss: 2.4256839415300435

Epoch: 5| Step: 5
Training loss: 1.7055880034373725
Validation loss: 2.4337674196831682

Epoch: 5| Step: 6
Training loss: 2.4782860952500356
Validation loss: 2.414575141704138

Epoch: 5| Step: 7
Training loss: 2.5000791537151996
Validation loss: 2.4254415932598667

Epoch: 5| Step: 8
Training loss: 2.615090968079655
Validation loss: 2.4147045141843115

Epoch: 5| Step: 9
Training loss: 2.555117229750873
Validation loss: 2.4160825513997812

Epoch: 5| Step: 10
Training loss: 2.0934757793256282
Validation loss: 2.4149821195407783

Epoch: 5| Step: 11
Training loss: 2.5593733902810873
Validation loss: 2.4129553872371456

Epoch: 52| Step: 0
Training loss: 2.8257299577288606
Validation loss: 2.416135587106567

Epoch: 5| Step: 1
Training loss: 2.5620983088062874
Validation loss: 2.4281471128696492

Epoch: 5| Step: 2
Training loss: 2.0089257860921292
Validation loss: 2.4275796298249483

Epoch: 5| Step: 3
Training loss: 2.0008317886636795
Validation loss: 2.4278000945210776

Epoch: 5| Step: 4
Training loss: 1.9188593954406417
Validation loss: 2.434975200862309

Epoch: 5| Step: 5
Training loss: 2.341893592599813
Validation loss: 2.416423776494987

Epoch: 5| Step: 6
Training loss: 2.3267203580386964
Validation loss: 2.422957033021722

Epoch: 5| Step: 7
Training loss: 2.3381539230780706
Validation loss: 2.4415785502351306

Epoch: 5| Step: 8
Training loss: 2.4009839186822965
Validation loss: 2.441947547414883

Epoch: 5| Step: 9
Training loss: 2.159949073720979
Validation loss: 2.4225935864619714

Epoch: 5| Step: 10
Training loss: 2.5478091720733373
Validation loss: 2.440110194722278

Epoch: 5| Step: 11
Training loss: 1.0535464861136432
Validation loss: 2.4198776458647475

Epoch: 53| Step: 0
Training loss: 1.8828481457133723
Validation loss: 2.467776583453318

Epoch: 5| Step: 1
Training loss: 2.165007126864713
Validation loss: 2.4452038457453966

Epoch: 5| Step: 2
Training loss: 2.071588777820562
Validation loss: 2.4608706914320466

Epoch: 5| Step: 3
Training loss: 1.9305348871650891
Validation loss: 2.4743663906401467

Epoch: 5| Step: 4
Training loss: 2.3663040375824087
Validation loss: 2.480975634430003

Epoch: 5| Step: 5
Training loss: 2.5078298978112934
Validation loss: 2.504781168461148

Epoch: 5| Step: 6
Training loss: 3.0831374200663166
Validation loss: 2.4999764600281305

Epoch: 5| Step: 7
Training loss: 2.9236908028665756
Validation loss: 2.4625387522751305

Epoch: 5| Step: 8
Training loss: 2.494830126588716
Validation loss: 2.467372703244672

Epoch: 5| Step: 9
Training loss: 1.9305223520047536
Validation loss: 2.424667667937612

Epoch: 5| Step: 10
Training loss: 1.9953159078331435
Validation loss: 2.4247016449551873

Epoch: 5| Step: 11
Training loss: 2.1933830715132454
Validation loss: 2.4103956716728194

Epoch: 54| Step: 0
Training loss: 2.232109361669722
Validation loss: 2.4250785968929534

Epoch: 5| Step: 1
Training loss: 2.0402065297840766
Validation loss: 2.423037703145845

Epoch: 5| Step: 2
Training loss: 2.915565246427656
Validation loss: 2.4301427760127066

Epoch: 5| Step: 3
Training loss: 2.2899179780422023
Validation loss: 2.3887673309791375

Epoch: 5| Step: 4
Training loss: 2.437092086698878
Validation loss: 2.419716276969647

Epoch: 5| Step: 5
Training loss: 2.5236686860466397
Validation loss: 2.4074853186722547

Epoch: 5| Step: 6
Training loss: 2.258218590142836
Validation loss: 2.4304751379848146

Epoch: 5| Step: 7
Training loss: 2.7231958804078102
Validation loss: 2.4012580920229856

Epoch: 5| Step: 8
Training loss: 2.1276070926666373
Validation loss: 2.4091730899872505

Epoch: 5| Step: 9
Training loss: 1.650202091441056
Validation loss: 2.4185830867783724

Epoch: 5| Step: 10
Training loss: 2.075178768316405
Validation loss: 2.426994953811203

Epoch: 5| Step: 11
Training loss: 2.0518097541839744
Validation loss: 2.412123569132732

Epoch: 55| Step: 0
Training loss: 2.3110704900868226
Validation loss: 2.4593752388022994

Epoch: 5| Step: 1
Training loss: 2.970342590404366
Validation loss: 2.473752490397866

Epoch: 5| Step: 2
Training loss: 1.8354805235591884
Validation loss: 2.5029017972390704

Epoch: 5| Step: 3
Training loss: 2.471357200199968
Validation loss: 2.5263628090239414

Epoch: 5| Step: 4
Training loss: 1.9171375718956567
Validation loss: 2.5019189781143814

Epoch: 5| Step: 5
Training loss: 2.266843060567422
Validation loss: 2.48241941390377

Epoch: 5| Step: 6
Training loss: 1.992432403470821
Validation loss: 2.508844585108713

Epoch: 5| Step: 7
Training loss: 2.251809769870683
Validation loss: 2.490670510789238

Epoch: 5| Step: 8
Training loss: 2.708434430705253
Validation loss: 2.4404863867674083

Epoch: 5| Step: 9
Training loss: 2.2046678700374107
Validation loss: 2.460352429470075

Epoch: 5| Step: 10
Training loss: 2.465725458416934
Validation loss: 2.4317641220495827

Epoch: 5| Step: 11
Training loss: 1.723007339373348
Validation loss: 2.426093858938468

Epoch: 56| Step: 0
Training loss: 1.9954888011261607
Validation loss: 2.4032651752056435

Epoch: 5| Step: 1
Training loss: 2.152016838156757
Validation loss: 2.4099285073776016

Epoch: 5| Step: 2
Training loss: 2.2326326846413425
Validation loss: 2.4448903727966504

Epoch: 5| Step: 3
Training loss: 2.919264335976731
Validation loss: 2.4272339055147913

Epoch: 5| Step: 4
Training loss: 1.961350477281576
Validation loss: 2.4218620710130367

Epoch: 5| Step: 5
Training loss: 2.507579091461097
Validation loss: 2.407869046137458

Epoch: 5| Step: 6
Training loss: 2.55087490406411
Validation loss: 2.42560480103654

Epoch: 5| Step: 7
Training loss: 1.9902634847831289
Validation loss: 2.4125190417867466

Epoch: 5| Step: 8
Training loss: 2.2629237415716106
Validation loss: 2.419541483762911

Epoch: 5| Step: 9
Training loss: 2.7862572333001108
Validation loss: 2.430155164270807

Epoch: 5| Step: 10
Training loss: 2.2384883125755
Validation loss: 2.4112806289043265

Epoch: 5| Step: 11
Training loss: 1.3495933432392824
Validation loss: 2.41895652812544

Epoch: 57| Step: 0
Training loss: 2.414959984520894
Validation loss: 2.4183321480996796

Epoch: 5| Step: 1
Training loss: 2.4197012713775843
Validation loss: 2.434156949680013

Epoch: 5| Step: 2
Training loss: 3.0571725400800225
Validation loss: 2.4621093059243027

Epoch: 5| Step: 3
Training loss: 2.311894517967252
Validation loss: 2.424971752067768

Epoch: 5| Step: 4
Training loss: 2.306266218092217
Validation loss: 2.421825658644252

Epoch: 5| Step: 5
Training loss: 2.192806021235152
Validation loss: 2.438577226468872

Epoch: 5| Step: 6
Training loss: 2.003781677300305
Validation loss: 2.426819694236638

Epoch: 5| Step: 7
Training loss: 2.755920020178977
Validation loss: 2.434498424363816

Epoch: 5| Step: 8
Training loss: 1.7356012494251742
Validation loss: 2.4223124365406754

Epoch: 5| Step: 9
Training loss: 1.7252207241650626
Validation loss: 2.432747758638066

Epoch: 5| Step: 10
Training loss: 1.9570742543381965
Validation loss: 2.430515405837977

Epoch: 5| Step: 11
Training loss: 2.230449402519799
Validation loss: 2.4354760823264154

Epoch: 58| Step: 0
Training loss: 2.816438587442214
Validation loss: 2.451843262984903

Epoch: 5| Step: 1
Training loss: 2.409089431958539
Validation loss: 2.4275248225586776

Epoch: 5| Step: 2
Training loss: 1.619906880327952
Validation loss: 2.452574690466613

Epoch: 5| Step: 3
Training loss: 2.3920105552886985
Validation loss: 2.455588049827045

Epoch: 5| Step: 4
Training loss: 2.2052550063301832
Validation loss: 2.438734540735542

Epoch: 5| Step: 5
Training loss: 2.2164924849527576
Validation loss: 2.4493657645476214

Epoch: 5| Step: 6
Training loss: 2.6597480628803183
Validation loss: 2.4610917623298465

Epoch: 5| Step: 7
Training loss: 1.8340020549600418
Validation loss: 2.4345755803367073

Epoch: 5| Step: 8
Training loss: 1.9557836519077099
Validation loss: 2.4299322456822354

Epoch: 5| Step: 9
Training loss: 2.686377002381792
Validation loss: 2.438389273575659

Epoch: 5| Step: 10
Training loss: 1.8004555231780603
Validation loss: 2.457940196806126

Epoch: 5| Step: 11
Training loss: 2.8390511058522043
Validation loss: 2.4344321123833508

Epoch: 59| Step: 0
Training loss: 2.1430457690643108
Validation loss: 2.4416613392126227

Epoch: 5| Step: 1
Training loss: 1.8128928712396528
Validation loss: 2.430076386055025

Epoch: 5| Step: 2
Training loss: 2.6542448666089884
Validation loss: 2.4128566063311894

Epoch: 5| Step: 3
Training loss: 1.9550455645156395
Validation loss: 2.412814306297922

Epoch: 5| Step: 4
Training loss: 2.1431170805447963
Validation loss: 2.415369204836363

Epoch: 5| Step: 5
Training loss: 1.6884786805492065
Validation loss: 2.456713430998214

Epoch: 5| Step: 6
Training loss: 2.199911384531768
Validation loss: 2.419855986676473

Epoch: 5| Step: 7
Training loss: 2.620816939585184
Validation loss: 2.467545581719982

Epoch: 5| Step: 8
Training loss: 2.5825746919478916
Validation loss: 2.4736311860197784

Epoch: 5| Step: 9
Training loss: 3.018048039361784
Validation loss: 2.448018410103631

Epoch: 5| Step: 10
Training loss: 1.867459712276958
Validation loss: 2.420708668749493

Epoch: 5| Step: 11
Training loss: 2.685972533738171
Validation loss: 2.409473975919778

Epoch: 60| Step: 0
Training loss: 2.7037766393300617
Validation loss: 2.4030357087953806

Epoch: 5| Step: 1
Training loss: 2.087288751021085
Validation loss: 2.4195330135218733

Epoch: 5| Step: 2
Training loss: 2.038890612142714
Validation loss: 2.4328142757813547

Epoch: 5| Step: 3
Training loss: 2.2471242116525767
Validation loss: 2.4306484010916534

Epoch: 5| Step: 4
Training loss: 2.1534063412874547
Validation loss: 2.4452453254678685

Epoch: 5| Step: 5
Training loss: 2.645672730705377
Validation loss: 2.4402033494939537

Epoch: 5| Step: 6
Training loss: 2.5380985249423342
Validation loss: 2.436280640435039

Epoch: 5| Step: 7
Training loss: 1.955774935725644
Validation loss: 2.432480836709817

Epoch: 5| Step: 8
Training loss: 2.3818016034131055
Validation loss: 2.391616748550279

Epoch: 5| Step: 9
Training loss: 2.6655183544940244
Validation loss: 2.4234885798403543

Epoch: 5| Step: 10
Training loss: 2.0512601747324397
Validation loss: 2.4136287501175935

Epoch: 5| Step: 11
Training loss: 1.8954419021899978
Validation loss: 2.424011108803133

Epoch: 61| Step: 0
Training loss: 2.1385969593043246
Validation loss: 2.4266463624472454

Epoch: 5| Step: 1
Training loss: 2.2754682666809747
Validation loss: 2.468637343141952

Epoch: 5| Step: 2
Training loss: 2.2705517048848862
Validation loss: 2.453912768455996

Epoch: 5| Step: 3
Training loss: 2.658962166610649
Validation loss: 2.4509699258276982

Epoch: 5| Step: 4
Training loss: 2.3861262058860717
Validation loss: 2.458772318379469

Epoch: 5| Step: 5
Training loss: 2.36528830305341
Validation loss: 2.4617758438106065

Epoch: 5| Step: 6
Training loss: 2.160755481349777
Validation loss: 2.434620197354798

Epoch: 5| Step: 7
Training loss: 1.6046792569640553
Validation loss: 2.4496022582768173

Epoch: 5| Step: 8
Training loss: 2.383043521875868
Validation loss: 2.423033189199368

Epoch: 5| Step: 9
Training loss: 2.31314552164032
Validation loss: 2.4243738962190453

Epoch: 5| Step: 10
Training loss: 2.287305554740037
Validation loss: 2.4682149427983058

Epoch: 5| Step: 11
Training loss: 2.0568794191557
Validation loss: 2.44319222801214

Epoch: 62| Step: 0
Training loss: 2.036497058809153
Validation loss: 2.3990391609289277

Epoch: 5| Step: 1
Training loss: 2.2095574159329283
Validation loss: 2.408041159408488

Epoch: 5| Step: 2
Training loss: 2.4639219564488446
Validation loss: 2.392102042859636

Epoch: 5| Step: 3
Training loss: 2.070125931304654
Validation loss: 2.4005482981136907

Epoch: 5| Step: 4
Training loss: 2.745013223835095
Validation loss: 2.4137810992656297

Epoch: 5| Step: 5
Training loss: 1.6757390654974167
Validation loss: 2.4213039791501805

Epoch: 5| Step: 6
Training loss: 2.681854706267165
Validation loss: 2.4057769723290825

Epoch: 5| Step: 7
Training loss: 2.1407992995088514
Validation loss: 2.403465104394887

Epoch: 5| Step: 8
Training loss: 2.413997908533639
Validation loss: 2.407384755557494

Epoch: 5| Step: 9
Training loss: 1.857237220033144
Validation loss: 2.4148658024943015

Epoch: 5| Step: 10
Training loss: 1.8110167913053408
Validation loss: 2.4120144144534796

Epoch: 5| Step: 11
Training loss: 3.872311797915855
Validation loss: 2.399392694717879

Epoch: 63| Step: 0
Training loss: 2.013178086811077
Validation loss: 2.418304789769273

Epoch: 5| Step: 1
Training loss: 2.1691323946359256
Validation loss: 2.4197391238825534

Epoch: 5| Step: 2
Training loss: 2.3021513869869543
Validation loss: 2.430398622320813

Epoch: 5| Step: 3
Training loss: 2.6473730418137094
Validation loss: 2.44359739319782

Epoch: 5| Step: 4
Training loss: 1.7251163139381647
Validation loss: 2.4725700833461857

Epoch: 5| Step: 5
Training loss: 2.32667137695681
Validation loss: 2.4919023061620735

Epoch: 5| Step: 6
Training loss: 2.8244481079337254
Validation loss: 2.5126004132564783

Epoch: 5| Step: 7
Training loss: 2.5201068072920862
Validation loss: 2.4888503752743834

Epoch: 5| Step: 8
Training loss: 1.6862705131623428
Validation loss: 2.4351882527785595

Epoch: 5| Step: 9
Training loss: 2.4610139380800087
Validation loss: 2.4423478246168426

Epoch: 5| Step: 10
Training loss: 1.9960723696644227
Validation loss: 2.43089623758134

Epoch: 5| Step: 11
Training loss: 2.6776631441109386
Validation loss: 2.3856527192262087

Epoch: 64| Step: 0
Training loss: 2.181336247616308
Validation loss: 2.391741971636943

Epoch: 5| Step: 1
Training loss: 2.225405101116358
Validation loss: 2.4067352577645034

Epoch: 5| Step: 2
Training loss: 2.177389813864246
Validation loss: 2.386354663172829

Epoch: 5| Step: 3
Training loss: 2.8465431664840826
Validation loss: 2.4135792278340973

Epoch: 5| Step: 4
Training loss: 2.11963312429392
Validation loss: 2.419948701912512

Epoch: 5| Step: 5
Training loss: 1.8094787409794004
Validation loss: 2.3993872192189585

Epoch: 5| Step: 6
Training loss: 2.128954293645106
Validation loss: 2.401604999372189

Epoch: 5| Step: 7
Training loss: 2.0472334919099846
Validation loss: 2.4073766778923273

Epoch: 5| Step: 8
Training loss: 2.341713287414341
Validation loss: 2.4164773884729676

Epoch: 5| Step: 9
Training loss: 1.9724133634699024
Validation loss: 2.4043066715110104

Epoch: 5| Step: 10
Training loss: 2.585558076895633
Validation loss: 2.423815206431293

Epoch: 5| Step: 11
Training loss: 1.5023102453565385
Validation loss: 2.4009685725893704

Epoch: 65| Step: 0
Training loss: 2.6817249971079296
Validation loss: 2.413811885660053

Epoch: 5| Step: 1
Training loss: 2.20583474463156
Validation loss: 2.4072959348265774

Epoch: 5| Step: 2
Training loss: 2.31535719585488
Validation loss: 2.4068392284003157

Epoch: 5| Step: 3
Training loss: 2.17334955230855
Validation loss: 2.402175992571984

Epoch: 5| Step: 4
Training loss: 1.670872896000358
Validation loss: 2.398231058420848

Epoch: 5| Step: 5
Training loss: 2.4324622302048784
Validation loss: 2.420818418324452

Epoch: 5| Step: 6
Training loss: 2.0189680424617755
Validation loss: 2.40056677540038

Epoch: 5| Step: 7
Training loss: 2.2292289962848586
Validation loss: 2.408970644772406

Epoch: 5| Step: 8
Training loss: 2.5090435488506966
Validation loss: 2.405914023091945

Epoch: 5| Step: 9
Training loss: 2.2787598906536224
Validation loss: 2.4004280743368978

Epoch: 5| Step: 10
Training loss: 2.060345188774327
Validation loss: 2.3998115302464083

Epoch: 5| Step: 11
Training loss: 1.3758214317575646
Validation loss: 2.416741132959139

Epoch: 66| Step: 0
Training loss: 2.128787312116232
Validation loss: 2.415018112682028

Epoch: 5| Step: 1
Training loss: 1.764558926007823
Validation loss: 2.4000602020885524

Epoch: 5| Step: 2
Training loss: 2.419145682841021
Validation loss: 2.4214339275082515

Epoch: 5| Step: 3
Training loss: 2.0528443630961064
Validation loss: 2.434042959049519

Epoch: 5| Step: 4
Training loss: 2.021412900683893
Validation loss: 2.4345717977781187

Epoch: 5| Step: 5
Training loss: 2.674552512842366
Validation loss: 2.4346459177179534

Epoch: 5| Step: 6
Training loss: 2.3160412454177224
Validation loss: 2.4414545812273354

Epoch: 5| Step: 7
Training loss: 2.5425229949061356
Validation loss: 2.414237047981607

Epoch: 5| Step: 8
Training loss: 2.4773945177952093
Validation loss: 2.404088643216721

Epoch: 5| Step: 9
Training loss: 2.010616022480662
Validation loss: 2.412530752588843

Epoch: 5| Step: 10
Training loss: 1.98845265667031
Validation loss: 2.395874451547031

Epoch: 5| Step: 11
Training loss: 1.877893123181478
Validation loss: 2.409675888259793

Epoch: 67| Step: 0
Training loss: 1.856081955621213
Validation loss: 2.402718094603296

Epoch: 5| Step: 1
Training loss: 2.335583305936075
Validation loss: 2.410925723278054

Epoch: 5| Step: 2
Training loss: 2.7143521748917547
Validation loss: 2.386793719174071

Epoch: 5| Step: 3
Training loss: 2.0806306346978585
Validation loss: 2.3794996151107215

Epoch: 5| Step: 4
Training loss: 1.774703124565804
Validation loss: 2.411575744330216

Epoch: 5| Step: 5
Training loss: 2.2382239422610173
Validation loss: 2.359427672549789

Epoch: 5| Step: 6
Training loss: 2.374716089244481
Validation loss: 2.3965548106244405

Epoch: 5| Step: 7
Training loss: 2.0323335545177734
Validation loss: 2.412425666283212

Epoch: 5| Step: 8
Training loss: 2.202463794804704
Validation loss: 2.394396406300566

Epoch: 5| Step: 9
Training loss: 2.0629057051705715
Validation loss: 2.410005858441905

Epoch: 5| Step: 10
Training loss: 2.5000739086670234
Validation loss: 2.4182786840468076

Epoch: 5| Step: 11
Training loss: 2.871107866940209
Validation loss: 2.418515453252975

Epoch: 68| Step: 0
Training loss: 2.7675218704310556
Validation loss: 2.419234540740338

Epoch: 5| Step: 1
Training loss: 2.2216237759104653
Validation loss: 2.38040973025535

Epoch: 5| Step: 2
Training loss: 2.1163290049839665
Validation loss: 2.409306084108641

Epoch: 5| Step: 3
Training loss: 2.0757634792062523
Validation loss: 2.3951725435520865

Epoch: 5| Step: 4
Training loss: 2.4686730288324763
Validation loss: 2.4162085827946593

Epoch: 5| Step: 5
Training loss: 1.8799020265860606
Validation loss: 2.431408153283388

Epoch: 5| Step: 6
Training loss: 2.0594840685104816
Validation loss: 2.4253435216020005

Epoch: 5| Step: 7
Training loss: 2.7341924115935443
Validation loss: 2.430470641938694

Epoch: 5| Step: 8
Training loss: 2.1137130775588164
Validation loss: 2.4073723450339433

Epoch: 5| Step: 9
Training loss: 2.213096292606334
Validation loss: 2.415619322444006

Epoch: 5| Step: 10
Training loss: 2.023876010112547
Validation loss: 2.397942731192545

Epoch: 5| Step: 11
Training loss: 2.4744870126244294
Validation loss: 2.424154025578468

Epoch: 69| Step: 0
Training loss: 1.7865461618911824
Validation loss: 2.4358809506367503

Epoch: 5| Step: 1
Training loss: 2.2819928566622782
Validation loss: 2.48453539804379

Epoch: 5| Step: 2
Training loss: 2.4500803914796623
Validation loss: 2.53077232892953

Epoch: 5| Step: 3
Training loss: 2.1181086827131104
Validation loss: 2.5517512760694223

Epoch: 5| Step: 4
Training loss: 2.610686560761839
Validation loss: 2.5589864492565684

Epoch: 5| Step: 5
Training loss: 2.3776257706517514
Validation loss: 2.558225606199304

Epoch: 5| Step: 6
Training loss: 2.4343083344367358
Validation loss: 2.5077143300332225

Epoch: 5| Step: 7
Training loss: 1.5138364640859785
Validation loss: 2.4705553576040886

Epoch: 5| Step: 8
Training loss: 2.3053240398104196
Validation loss: 2.4390052891338034

Epoch: 5| Step: 9
Training loss: 2.5132620950952527
Validation loss: 2.45400993519181

Epoch: 5| Step: 10
Training loss: 2.1204930925029637
Validation loss: 2.4089144821176443

Epoch: 5| Step: 11
Training loss: 2.1022003226968704
Validation loss: 2.4199327782156175

Epoch: 70| Step: 0
Training loss: 2.0827728153234197
Validation loss: 2.4137194656213428

Epoch: 5| Step: 1
Training loss: 2.324361434531778
Validation loss: 2.4003068553936164

Epoch: 5| Step: 2
Training loss: 1.9327243892782253
Validation loss: 2.391189606175269

Epoch: 5| Step: 3
Training loss: 2.1220866034593846
Validation loss: 2.402203803392744

Epoch: 5| Step: 4
Training loss: 2.3357535707662245
Validation loss: 2.407499531814857

Epoch: 5| Step: 5
Training loss: 1.8966607464573362
Validation loss: 2.4020536624921

Epoch: 5| Step: 6
Training loss: 2.1820525870695273
Validation loss: 2.4173709436471325

Epoch: 5| Step: 7
Training loss: 1.8618151256797983
Validation loss: 2.386174033147901

Epoch: 5| Step: 8
Training loss: 2.3200061737175717
Validation loss: 2.382897155592016

Epoch: 5| Step: 9
Training loss: 2.3257935390077273
Validation loss: 2.404118173601617

Epoch: 5| Step: 10
Training loss: 2.6151674588269715
Validation loss: 2.3852394793362746

Epoch: 5| Step: 11
Training loss: 0.8533669348771881
Validation loss: 2.399923363428952

Epoch: 71| Step: 0
Training loss: 1.8397906836370757
Validation loss: 2.3926846455846467

Epoch: 5| Step: 1
Training loss: 2.661487845439486
Validation loss: 2.405587460185418

Epoch: 5| Step: 2
Training loss: 1.6130587445161095
Validation loss: 2.4016488473592066

Epoch: 5| Step: 3
Training loss: 2.6060243211549605
Validation loss: 2.4205982657684086

Epoch: 5| Step: 4
Training loss: 2.457187471745139
Validation loss: 2.412156098153935

Epoch: 5| Step: 5
Training loss: 2.529808293192426
Validation loss: 2.4183540879425256

Epoch: 5| Step: 6
Training loss: 2.5335690271592877
Validation loss: 2.4165069647889315

Epoch: 5| Step: 7
Training loss: 1.551142960266659
Validation loss: 2.3943320020842522

Epoch: 5| Step: 8
Training loss: 1.8935289386102263
Validation loss: 2.418199097852223

Epoch: 5| Step: 9
Training loss: 2.12660448423896
Validation loss: 2.4143099899749663

Epoch: 5| Step: 10
Training loss: 1.9608272810276632
Validation loss: 2.391725108355301

Epoch: 5| Step: 11
Training loss: 0.8963708743382269
Validation loss: 2.4013903889382644

Epoch: 72| Step: 0
Training loss: 2.290951727116703
Validation loss: 2.4014326544038163

Epoch: 5| Step: 1
Training loss: 2.2992075798963607
Validation loss: 2.4120966037098115

Epoch: 5| Step: 2
Training loss: 1.5651901737728464
Validation loss: 2.405777579331988

Epoch: 5| Step: 3
Training loss: 2.14368048018569
Validation loss: 2.4041155269765877

Epoch: 5| Step: 4
Training loss: 2.3815444323719466
Validation loss: 2.4198941651759838

Epoch: 5| Step: 5
Training loss: 2.195253744730586
Validation loss: 2.4020628974312137

Epoch: 5| Step: 6
Training loss: 1.6822437795273741
Validation loss: 2.380894396521476

Epoch: 5| Step: 7
Training loss: 2.4732833958885854
Validation loss: 2.3983352631059014

Epoch: 5| Step: 8
Training loss: 2.072921663466778
Validation loss: 2.4113042725908107

Epoch: 5| Step: 9
Training loss: 2.4229819444526015
Validation loss: 2.3823935301942214

Epoch: 5| Step: 10
Training loss: 2.1394042829448034
Validation loss: 2.380147930411114

Epoch: 5| Step: 11
Training loss: 2.4297290074767948
Validation loss: 2.365248999535992

Epoch: 73| Step: 0
Training loss: 2.097511442787503
Validation loss: 2.389563509740531

Epoch: 5| Step: 1
Training loss: 2.1334435504019003
Validation loss: 2.4562306153403677

Epoch: 5| Step: 2
Training loss: 2.1283716492974056
Validation loss: 2.4852377235307137

Epoch: 5| Step: 3
Training loss: 2.1881928572801472
Validation loss: 2.476082499585591

Epoch: 5| Step: 4
Training loss: 2.2884645690108827
Validation loss: 2.5207469875480752

Epoch: 5| Step: 5
Training loss: 2.9416353052933233
Validation loss: 2.5306547312687027

Epoch: 5| Step: 6
Training loss: 2.216399438664025
Validation loss: 2.5044636475432958

Epoch: 5| Step: 7
Training loss: 2.2141903513927903
Validation loss: 2.452903077440142

Epoch: 5| Step: 8
Training loss: 1.735770549008051
Validation loss: 2.4488818004293638

Epoch: 5| Step: 9
Training loss: 2.3021299492674623
Validation loss: 2.4156577344537755

Epoch: 5| Step: 10
Training loss: 1.6759233036610084
Validation loss: 2.390541008697599

Epoch: 5| Step: 11
Training loss: 1.4698027226685364
Validation loss: 2.3736529545685476

Epoch: 74| Step: 0
Training loss: 1.6762887324126032
Validation loss: 2.4152395738741825

Epoch: 5| Step: 1
Training loss: 1.6438723442468663
Validation loss: 2.403116568131819

Epoch: 5| Step: 2
Training loss: 2.661417344307092
Validation loss: 2.426097355803038

Epoch: 5| Step: 3
Training loss: 2.4695649552330536
Validation loss: 2.4450729118681878

Epoch: 5| Step: 4
Training loss: 1.7277475148269914
Validation loss: 2.429339699828522

Epoch: 5| Step: 5
Training loss: 1.9881701485221246
Validation loss: 2.4499209876197607

Epoch: 5| Step: 6
Training loss: 2.14192961873346
Validation loss: 2.414854070105993

Epoch: 5| Step: 7
Training loss: 2.0157099269747594
Validation loss: 2.398287057041328

Epoch: 5| Step: 8
Training loss: 2.607598710939335
Validation loss: 2.394439674771223

Epoch: 5| Step: 9
Training loss: 2.5235005184843478
Validation loss: 2.3792467212959707

Epoch: 5| Step: 10
Training loss: 2.4778172536403376
Validation loss: 2.4033806235382422

Epoch: 5| Step: 11
Training loss: 2.028758354804416
Validation loss: 2.4099124020502325

Epoch: 75| Step: 0
Training loss: 1.9798607730080962
Validation loss: 2.4456753202623815

Epoch: 5| Step: 1
Training loss: 1.4756862724925641
Validation loss: 2.4660658549814722

Epoch: 5| Step: 2
Training loss: 1.8789427946030248
Validation loss: 2.499227217603964

Epoch: 5| Step: 3
Training loss: 2.227869018574054
Validation loss: 2.5234672064356363

Epoch: 5| Step: 4
Training loss: 2.5055476624373196
Validation loss: 2.5429673631921164

Epoch: 5| Step: 5
Training loss: 2.2155406467752803
Validation loss: 2.5293875934528316

Epoch: 5| Step: 6
Training loss: 2.370986659539774
Validation loss: 2.498038802184819

Epoch: 5| Step: 7
Training loss: 2.021130163147108
Validation loss: 2.4650020800408283

Epoch: 5| Step: 8
Training loss: 2.0433720323757276
Validation loss: 2.4362036954538357

Epoch: 5| Step: 9
Training loss: 2.968539742503008
Validation loss: 2.387964062170181

Epoch: 5| Step: 10
Training loss: 2.151693311605595
Validation loss: 2.3817127754303162

Epoch: 5| Step: 11
Training loss: 2.4125732964168147
Validation loss: 2.3733685624719465

Epoch: 76| Step: 0
Training loss: 2.2444700525520447
Validation loss: 2.4195955727172778

Epoch: 5| Step: 1
Training loss: 2.645709227607433
Validation loss: 2.4164899886156945

Epoch: 5| Step: 2
Training loss: 2.433593652030245
Validation loss: 2.396414563261454

Epoch: 5| Step: 3
Training loss: 2.0193298357461735
Validation loss: 2.419263173814248

Epoch: 5| Step: 4
Training loss: 2.469074469381505
Validation loss: 2.395830072870662

Epoch: 5| Step: 5
Training loss: 1.7467235137822623
Validation loss: 2.4086843496039214

Epoch: 5| Step: 6
Training loss: 2.57257731641241
Validation loss: 2.3950772350124763

Epoch: 5| Step: 7
Training loss: 1.8780003384111483
Validation loss: 2.3897800282012667

Epoch: 5| Step: 8
Training loss: 2.0906518817536153
Validation loss: 2.387483252721238

Epoch: 5| Step: 9
Training loss: 1.2037191038831119
Validation loss: 2.4001987795499877

Epoch: 5| Step: 10
Training loss: 2.399622919341557
Validation loss: 2.408316587656095

Epoch: 5| Step: 11
Training loss: 1.6142615048827251
Validation loss: 2.3872705561549528

Epoch: 77| Step: 0
Training loss: 2.54669581994085
Validation loss: 2.42539414303017

Epoch: 5| Step: 1
Training loss: 2.6716265646561763
Validation loss: 2.4820328714559348

Epoch: 5| Step: 2
Training loss: 2.2655706991068203
Validation loss: 2.5230968115448333

Epoch: 5| Step: 3
Training loss: 2.201058141956932
Validation loss: 2.522321523175276

Epoch: 5| Step: 4
Training loss: 1.9700822712328603
Validation loss: 2.4932339104763397

Epoch: 5| Step: 5
Training loss: 2.3173589435928363
Validation loss: 2.4891033162076868

Epoch: 5| Step: 6
Training loss: 1.9265640246407694
Validation loss: 2.431789188366121

Epoch: 5| Step: 7
Training loss: 2.1037322121478454
Validation loss: 2.437511859767134

Epoch: 5| Step: 8
Training loss: 1.4584134579400099
Validation loss: 2.3972291750221997

Epoch: 5| Step: 9
Training loss: 2.130503428071672
Validation loss: 2.3754148664692383

Epoch: 5| Step: 10
Training loss: 2.0160394286886714
Validation loss: 2.393280723329145

Epoch: 5| Step: 11
Training loss: 2.1659745675986435
Validation loss: 2.382664910420242

Epoch: 78| Step: 0
Training loss: 2.063512033644191
Validation loss: 2.3891642560260355

Epoch: 5| Step: 1
Training loss: 2.0737735248907585
Validation loss: 2.3751814442474832

Epoch: 5| Step: 2
Training loss: 2.4587982083022575
Validation loss: 2.3732252182159064

Epoch: 5| Step: 3
Training loss: 2.3675600268640378
Validation loss: 2.3716405398318585

Epoch: 5| Step: 4
Training loss: 2.1229735417058215
Validation loss: 2.43658689774285

Epoch: 5| Step: 5
Training loss: 2.502752695958773
Validation loss: 2.3793220386334135

Epoch: 5| Step: 6
Training loss: 1.9519397038152388
Validation loss: 2.3813592575319404

Epoch: 5| Step: 7
Training loss: 1.8679181189796963
Validation loss: 2.3642213239011434

Epoch: 5| Step: 8
Training loss: 1.8650993897491304
Validation loss: 2.388205016066152

Epoch: 5| Step: 9
Training loss: 1.7866455810403408
Validation loss: 2.3500351365486005

Epoch: 5| Step: 10
Training loss: 2.4408807051535253
Validation loss: 2.365779050634484

Epoch: 5| Step: 11
Training loss: 1.4714656641301935
Validation loss: 2.3626813268961033

Epoch: 79| Step: 0
Training loss: 2.042948910560337
Validation loss: 2.378054219352613

Epoch: 5| Step: 1
Training loss: 2.151074154464548
Validation loss: 2.39337344698066

Epoch: 5| Step: 2
Training loss: 2.626547039651387
Validation loss: 2.3695755968347125

Epoch: 5| Step: 3
Training loss: 1.9260839259241456
Validation loss: 2.4112042086498184

Epoch: 5| Step: 4
Training loss: 2.254174704076102
Validation loss: 2.378808489848997

Epoch: 5| Step: 5
Training loss: 1.9043170947444166
Validation loss: 2.3785678975770366

Epoch: 5| Step: 6
Training loss: 1.5851615172440134
Validation loss: 2.3688216742925556

Epoch: 5| Step: 7
Training loss: 1.919071478736495
Validation loss: 2.393835231070415

Epoch: 5| Step: 8
Training loss: 1.8541920978073683
Validation loss: 2.370559963283261

Epoch: 5| Step: 9
Training loss: 2.5365334459863567
Validation loss: 2.4000693950289627

Epoch: 5| Step: 10
Training loss: 2.0992392706143117
Validation loss: 2.434057547683043

Epoch: 5| Step: 11
Training loss: 2.089569701292603
Validation loss: 2.4235528527817674

Epoch: 80| Step: 0
Training loss: 2.1388885806305016
Validation loss: 2.4160852527582057

Epoch: 5| Step: 1
Training loss: 2.266016433050192
Validation loss: 2.4029589002408085

Epoch: 5| Step: 2
Training loss: 2.634584820809448
Validation loss: 2.4161670650715075

Epoch: 5| Step: 3
Training loss: 1.5760078202987904
Validation loss: 2.399703757062971

Epoch: 5| Step: 4
Training loss: 1.9023102868992803
Validation loss: 2.4140586318033415

Epoch: 5| Step: 5
Training loss: 2.2070272530038473
Validation loss: 2.38490731966266

Epoch: 5| Step: 6
Training loss: 1.9021373848339875
Validation loss: 2.3989876521035116

Epoch: 5| Step: 7
Training loss: 1.9507250880481917
Validation loss: 2.3838691661502565

Epoch: 5| Step: 8
Training loss: 2.1141548536925683
Validation loss: 2.383079995321397

Epoch: 5| Step: 9
Training loss: 2.3813528123822842
Validation loss: 2.349770962937096

Epoch: 5| Step: 10
Training loss: 1.7545448958620178
Validation loss: 2.3477571014052088

Epoch: 5| Step: 11
Training loss: 2.490211779922002
Validation loss: 2.375065104110898

Epoch: 81| Step: 0
Training loss: 1.5391860370143424
Validation loss: 2.3581876482857735

Epoch: 5| Step: 1
Training loss: 2.045793087233879
Validation loss: 2.3945852484119308

Epoch: 5| Step: 2
Training loss: 1.9969847719111418
Validation loss: 2.386103582524522

Epoch: 5| Step: 3
Training loss: 1.8434997647406621
Validation loss: 2.387912445492847

Epoch: 5| Step: 4
Training loss: 2.0807263147925803
Validation loss: 2.414870792444422

Epoch: 5| Step: 5
Training loss: 2.3313831853789866
Validation loss: 2.4122440151264626

Epoch: 5| Step: 6
Training loss: 1.5116942253390604
Validation loss: 2.4087725046423314

Epoch: 5| Step: 7
Training loss: 2.7076664519284277
Validation loss: 2.3692110642929047

Epoch: 5| Step: 8
Training loss: 2.262883072769203
Validation loss: 2.379178307755869

Epoch: 5| Step: 9
Training loss: 1.9679432987325542
Validation loss: 2.3524620219836248

Epoch: 5| Step: 10
Training loss: 2.2929706216053902
Validation loss: 2.390902929003329

Epoch: 5| Step: 11
Training loss: 2.360176607086466
Validation loss: 2.3831873030930106

Epoch: 82| Step: 0
Training loss: 2.1433691548408875
Validation loss: 2.391748530009193

Epoch: 5| Step: 1
Training loss: 2.231405565838575
Validation loss: 2.3842985553411173

Epoch: 5| Step: 2
Training loss: 1.3321535384350052
Validation loss: 2.372667514111499

Epoch: 5| Step: 3
Training loss: 1.9664650024318218
Validation loss: 2.38691154779297

Epoch: 5| Step: 4
Training loss: 2.683373143708352
Validation loss: 2.419546098656358

Epoch: 5| Step: 5
Training loss: 2.1639349173385622
Validation loss: 2.4080769675222022

Epoch: 5| Step: 6
Training loss: 1.635101466165627
Validation loss: 2.408205694943367

Epoch: 5| Step: 7
Training loss: 2.585259847216642
Validation loss: 2.4413917642799423

Epoch: 5| Step: 8
Training loss: 1.9338712859138734
Validation loss: 2.422089675905078

Epoch: 5| Step: 9
Training loss: 1.8112724356515568
Validation loss: 2.401940236925823

Epoch: 5| Step: 10
Training loss: 1.9555941423789935
Validation loss: 2.3979462318243865

Epoch: 5| Step: 11
Training loss: 2.4422383347661363
Validation loss: 2.3896403975741887

Epoch: 83| Step: 0
Training loss: 2.7883566596345104
Validation loss: 2.3591185466175677

Epoch: 5| Step: 1
Training loss: 2.262910255624868
Validation loss: 2.4067664727476457

Epoch: 5| Step: 2
Training loss: 1.463631171298604
Validation loss: 2.389456802206519

Epoch: 5| Step: 3
Training loss: 2.1555733102654977
Validation loss: 2.3709314574622224

Epoch: 5| Step: 4
Training loss: 2.100955804656856
Validation loss: 2.3653426540631752

Epoch: 5| Step: 5
Training loss: 1.9721090332050297
Validation loss: 2.37994915214017

Epoch: 5| Step: 6
Training loss: 1.9284232627628692
Validation loss: 2.39112825436377

Epoch: 5| Step: 7
Training loss: 1.9441171060265867
Validation loss: 2.369709077730387

Epoch: 5| Step: 8
Training loss: 1.8058380818829012
Validation loss: 2.3927795740553877

Epoch: 5| Step: 9
Training loss: 2.126527013209316
Validation loss: 2.3894026837386204

Epoch: 5| Step: 10
Training loss: 1.9859364891499873
Validation loss: 2.4147923589442195

Epoch: 5| Step: 11
Training loss: 2.3751088167659797
Validation loss: 2.389122883724053

Epoch: 84| Step: 0
Training loss: 2.423232553302562
Validation loss: 2.3998988087169835

Epoch: 5| Step: 1
Training loss: 2.0126638025948074
Validation loss: 2.4050914485434927

Epoch: 5| Step: 2
Training loss: 2.164384838569877
Validation loss: 2.3645810254683695

Epoch: 5| Step: 3
Training loss: 1.6674184136970718
Validation loss: 2.361012936558142

Epoch: 5| Step: 4
Training loss: 1.3384492250971447
Validation loss: 2.36579151348611

Epoch: 5| Step: 5
Training loss: 2.2295503612920693
Validation loss: 2.3962899491653626

Epoch: 5| Step: 6
Training loss: 2.8873326703093367
Validation loss: 2.400648123429416

Epoch: 5| Step: 7
Training loss: 2.01610790057029
Validation loss: 2.37205473746972

Epoch: 5| Step: 8
Training loss: 1.916970049302251
Validation loss: 2.383964756095209

Epoch: 5| Step: 9
Training loss: 1.5127017745685893
Validation loss: 2.360889325680248

Epoch: 5| Step: 10
Training loss: 2.069011005635995
Validation loss: 2.401303330159702

Epoch: 5| Step: 11
Training loss: 1.5418116613026485
Validation loss: 2.3791244064381356

Epoch: 85| Step: 0
Training loss: 1.8452578052809963
Validation loss: 2.3886227648165943

Epoch: 5| Step: 1
Training loss: 1.5644312558211253
Validation loss: 2.3870920158899063

Epoch: 5| Step: 2
Training loss: 2.3602947943240653
Validation loss: 2.388341423876365

Epoch: 5| Step: 3
Training loss: 1.9602469638041513
Validation loss: 2.424731790811885

Epoch: 5| Step: 4
Training loss: 2.08333067575921
Validation loss: 2.380749293873514

Epoch: 5| Step: 5
Training loss: 1.6968464042825333
Validation loss: 2.4027641817552268

Epoch: 5| Step: 6
Training loss: 1.9699843639392265
Validation loss: 2.368607501169915

Epoch: 5| Step: 7
Training loss: 2.4298950302936646
Validation loss: 2.4061891374693665

Epoch: 5| Step: 8
Training loss: 2.0642560938823387
Validation loss: 2.402718423298323

Epoch: 5| Step: 9
Training loss: 2.3997853620236453
Validation loss: 2.3844703618582908

Epoch: 5| Step: 10
Training loss: 1.8455994592043279
Validation loss: 2.374832996553466

Epoch: 5| Step: 11
Training loss: 2.004155372170117
Validation loss: 2.371294912805429

Epoch: 86| Step: 0
Training loss: 2.017979510873421
Validation loss: 2.3724172879423846

Epoch: 5| Step: 1
Training loss: 2.03322845355261
Validation loss: 2.3770361086283103

Epoch: 5| Step: 2
Training loss: 2.282730040474148
Validation loss: 2.409227914769452

Epoch: 5| Step: 3
Training loss: 1.7947723691688475
Validation loss: 2.43144601964939

Epoch: 5| Step: 4
Training loss: 2.006101718069392
Validation loss: 2.4139466242463583

Epoch: 5| Step: 5
Training loss: 2.1461096897373446
Validation loss: 2.41032143247817

Epoch: 5| Step: 6
Training loss: 1.8889792349034016
Validation loss: 2.3824653956344295

Epoch: 5| Step: 7
Training loss: 2.1203804291966724
Validation loss: 2.39741696526524

Epoch: 5| Step: 8
Training loss: 2.125347109101824
Validation loss: 2.382829505567893

Epoch: 5| Step: 9
Training loss: 1.8313637759957186
Validation loss: 2.3684083079855895

Epoch: 5| Step: 10
Training loss: 1.9231941224111535
Validation loss: 2.399782298731265

Epoch: 5| Step: 11
Training loss: 2.5610332478097035
Validation loss: 2.387755340050444

Epoch: 87| Step: 0
Training loss: 2.1732789037281646
Validation loss: 2.3806017683368994

Epoch: 5| Step: 1
Training loss: 2.1125798498106936
Validation loss: 2.3697266866697078

Epoch: 5| Step: 2
Training loss: 1.825132545465522
Validation loss: 2.3781180117250043

Epoch: 5| Step: 3
Training loss: 2.0270131453476945
Validation loss: 2.3860230126386304

Epoch: 5| Step: 4
Training loss: 2.1674801937549106
Validation loss: 2.372424992627451

Epoch: 5| Step: 5
Training loss: 2.2367303344980853
Validation loss: 2.3986951128425207

Epoch: 5| Step: 6
Training loss: 1.8312318273690684
Validation loss: 2.3780461444053844

Epoch: 5| Step: 7
Training loss: 1.6857228281206464
Validation loss: 2.387447616325363

Epoch: 5| Step: 8
Training loss: 2.266827073685734
Validation loss: 2.379646649576726

Epoch: 5| Step: 9
Training loss: 2.060513319854154
Validation loss: 2.3816003186314414

Epoch: 5| Step: 10
Training loss: 2.1314565519324757
Validation loss: 2.3735769551074535

Epoch: 5| Step: 11
Training loss: 0.8148492449011004
Validation loss: 2.3873006274743727

Epoch: 88| Step: 0
Training loss: 1.75257452551918
Validation loss: 2.4013796269902725

Epoch: 5| Step: 1
Training loss: 2.1683255838445783
Validation loss: 2.3775001884751856

Epoch: 5| Step: 2
Training loss: 1.8816204175285727
Validation loss: 2.3742801052047415

Epoch: 5| Step: 3
Training loss: 2.09152992176427
Validation loss: 2.4143125246150956

Epoch: 5| Step: 4
Training loss: 2.214048427841274
Validation loss: 2.4194088551898614

Epoch: 5| Step: 5
Training loss: 1.6131261423100267
Validation loss: 2.3938998602893125

Epoch: 5| Step: 6
Training loss: 1.6193782691819507
Validation loss: 2.429194689671369

Epoch: 5| Step: 7
Training loss: 1.8783779868860373
Validation loss: 2.3977920293246964

Epoch: 5| Step: 8
Training loss: 1.824470714999991
Validation loss: 2.3955143564152745

Epoch: 5| Step: 9
Training loss: 2.6308274752149186
Validation loss: 2.4168174870608174

Epoch: 5| Step: 10
Training loss: 2.153900525040848
Validation loss: 2.373459299509349

Epoch: 5| Step: 11
Training loss: 2.0118865600519276
Validation loss: 2.3611663518938504

Epoch: 89| Step: 0
Training loss: 2.0143146839396913
Validation loss: 2.377655155488891

Epoch: 5| Step: 1
Training loss: 2.1755745753642164
Validation loss: 2.3758398085400794

Epoch: 5| Step: 2
Training loss: 1.7886297377192308
Validation loss: 2.39796904587619

Epoch: 5| Step: 3
Training loss: 2.1175516526228773
Validation loss: 2.3809694635539094

Epoch: 5| Step: 4
Training loss: 2.253455264029806
Validation loss: 2.3834683125515976

Epoch: 5| Step: 5
Training loss: 2.2415701518027227
Validation loss: 2.372100578608148

Epoch: 5| Step: 6
Training loss: 2.2752850029133542
Validation loss: 2.380291515096077

Epoch: 5| Step: 7
Training loss: 2.010066092434119
Validation loss: 2.369240259988092

Epoch: 5| Step: 8
Training loss: 1.7889866042384592
Validation loss: 2.3751654609130335

Epoch: 5| Step: 9
Training loss: 2.00141701567869
Validation loss: 2.3550912777070527

Epoch: 5| Step: 10
Training loss: 1.5013894162964736
Validation loss: 2.3657147155775426

Epoch: 5| Step: 11
Training loss: 1.717556764644654
Validation loss: 2.4294496319646104

Epoch: 90| Step: 0
Training loss: 1.9169149514417145
Validation loss: 2.4281766800063123

Epoch: 5| Step: 1
Training loss: 1.329801331790298
Validation loss: 2.4638449755703253

Epoch: 5| Step: 2
Training loss: 2.3466705436385524
Validation loss: 2.450135144249697

Epoch: 5| Step: 3
Training loss: 2.0889154672059087
Validation loss: 2.373838416688174

Epoch: 5| Step: 4
Training loss: 1.7698447516078073
Validation loss: 2.414615423753416

Epoch: 5| Step: 5
Training loss: 2.1382528931058387
Validation loss: 2.3985791614956833

Epoch: 5| Step: 6
Training loss: 2.0539374197143356
Validation loss: 2.3971538422121763

Epoch: 5| Step: 7
Training loss: 2.2495474890151734
Validation loss: 2.3861414392727585

Epoch: 5| Step: 8
Training loss: 2.5019609390124855
Validation loss: 2.37770314061098

Epoch: 5| Step: 9
Training loss: 2.191046210919014
Validation loss: 2.3762458285984573

Epoch: 5| Step: 10
Training loss: 1.8797055009723578
Validation loss: 2.386736356230134

Epoch: 5| Step: 11
Training loss: 0.9600129680949745
Validation loss: 2.396476229503813

Epoch: 91| Step: 0
Training loss: 2.2654362040814973
Validation loss: 2.3686742866111534

Epoch: 5| Step: 1
Training loss: 2.117085584601642
Validation loss: 2.363704237902612

Epoch: 5| Step: 2
Training loss: 2.0384853905609717
Validation loss: 2.390776760295803

Epoch: 5| Step: 3
Training loss: 1.7429628571291436
Validation loss: 2.351681491887084

Epoch: 5| Step: 4
Training loss: 2.0148171868705083
Validation loss: 2.368332018582299

Epoch: 5| Step: 5
Training loss: 1.6895807647999135
Validation loss: 2.3767631599039474

Epoch: 5| Step: 6
Training loss: 2.3642621487400857
Validation loss: 2.385065197906537

Epoch: 5| Step: 7
Training loss: 1.3616867578176766
Validation loss: 2.3584331122903834

Epoch: 5| Step: 8
Training loss: 1.8049177543098738
Validation loss: 2.3841490285577205

Epoch: 5| Step: 9
Training loss: 1.7879021892377809
Validation loss: 2.39193753963726

Epoch: 5| Step: 10
Training loss: 2.291148618462435
Validation loss: 2.383786445396411

Epoch: 5| Step: 11
Training loss: 2.310868899427879
Validation loss: 2.4128245170026226

Epoch: 92| Step: 0
Training loss: 1.9898090001559046
Validation loss: 2.3905648034854847

Epoch: 5| Step: 1
Training loss: 1.9175349908493435
Validation loss: 2.4032150177286074

Epoch: 5| Step: 2
Training loss: 2.281556827343225
Validation loss: 2.4110035944721604

Epoch: 5| Step: 3
Training loss: 2.023651111771511
Validation loss: 2.383945475063058

Epoch: 5| Step: 4
Training loss: 2.4920306978554567
Validation loss: 2.41127115323742

Epoch: 5| Step: 5
Training loss: 1.491757795366876
Validation loss: 2.3593816399217693

Epoch: 5| Step: 6
Training loss: 1.9647142735436773
Validation loss: 2.3679484286894685

Epoch: 5| Step: 7
Training loss: 2.2262431668621665
Validation loss: 2.402340644482929

Epoch: 5| Step: 8
Training loss: 2.102682276205606
Validation loss: 2.381691878663402

Epoch: 5| Step: 9
Training loss: 1.3204676971413294
Validation loss: 2.3789266701308907

Epoch: 5| Step: 10
Training loss: 1.9357871205789496
Validation loss: 2.3457835848283466

Epoch: 5| Step: 11
Training loss: 1.3381995965083888
Validation loss: 2.37037087303443

Epoch: 93| Step: 0
Training loss: 2.0165795719896638
Validation loss: 2.3737157352606664

Epoch: 5| Step: 1
Training loss: 1.710088161962049
Validation loss: 2.371980251059437

Epoch: 5| Step: 2
Training loss: 2.135760718440984
Validation loss: 2.3413143005407617

Epoch: 5| Step: 3
Training loss: 2.4610109348542455
Validation loss: 2.381247313857545

Epoch: 5| Step: 4
Training loss: 1.7753013193899467
Validation loss: 2.3925005987153987

Epoch: 5| Step: 5
Training loss: 1.8366687373561
Validation loss: 2.398905547921343

Epoch: 5| Step: 6
Training loss: 1.5442157583295526
Validation loss: 2.411742637852916

Epoch: 5| Step: 7
Training loss: 1.785100556220599
Validation loss: 2.418462991402271

Epoch: 5| Step: 8
Training loss: 1.7043665988604557
Validation loss: 2.3737703787658915

Epoch: 5| Step: 9
Training loss: 2.3157315743203486
Validation loss: 2.406032616427644

Epoch: 5| Step: 10
Training loss: 2.2991872553948
Validation loss: 2.4006925309738536

Epoch: 5| Step: 11
Training loss: 2.1716453375931435
Validation loss: 2.3801890455225476

Epoch: 94| Step: 0
Training loss: 1.899664023458705
Validation loss: 2.4023420152942214

Epoch: 5| Step: 1
Training loss: 2.1174919782214126
Validation loss: 2.3786749077419054

Epoch: 5| Step: 2
Training loss: 2.4486987765116393
Validation loss: 2.3608324378869536

Epoch: 5| Step: 3
Training loss: 1.7454481190008648
Validation loss: 2.353651054991633

Epoch: 5| Step: 4
Training loss: 1.7911031487398092
Validation loss: 2.3567764886328075

Epoch: 5| Step: 5
Training loss: 2.2482640669408176
Validation loss: 2.384858575582519

Epoch: 5| Step: 6
Training loss: 1.7006802992853176
Validation loss: 2.371282638073154

Epoch: 5| Step: 7
Training loss: 1.6048412721050431
Validation loss: 2.4039677328273155

Epoch: 5| Step: 8
Training loss: 1.570570359955089
Validation loss: 2.3839135299624465

Epoch: 5| Step: 9
Training loss: 2.1702234589098843
Validation loss: 2.409163375116838

Epoch: 5| Step: 10
Training loss: 2.16701364184259
Validation loss: 2.383815587599558

Epoch: 5| Step: 11
Training loss: 1.7922325201790446
Validation loss: 2.389447346010402

Epoch: 95| Step: 0
Training loss: 2.295876318315132
Validation loss: 2.3880081023886035

Epoch: 5| Step: 1
Training loss: 1.786172389806361
Validation loss: 2.3772023847914716

Epoch: 5| Step: 2
Training loss: 1.7522229653448738
Validation loss: 2.3690729637369463

Epoch: 5| Step: 3
Training loss: 1.746175333118381
Validation loss: 2.38032017840846

Epoch: 5| Step: 4
Training loss: 2.24279649286297
Validation loss: 2.3802650467162945

Epoch: 5| Step: 5
Training loss: 1.6624704544769109
Validation loss: 2.3693140170347173

Epoch: 5| Step: 6
Training loss: 2.028047472584384
Validation loss: 2.3801371078908478

Epoch: 5| Step: 7
Training loss: 1.8175548572473386
Validation loss: 2.3764190408151458

Epoch: 5| Step: 8
Training loss: 1.3410417633665028
Validation loss: 2.3768911152474823

Epoch: 5| Step: 9
Training loss: 1.9909016367565702
Validation loss: 2.3586909458265928

Epoch: 5| Step: 10
Training loss: 2.642093227696618
Validation loss: 2.337619086919247

Epoch: 5| Step: 11
Training loss: 0.26226845701959584
Validation loss: 2.394111820594762

Epoch: 96| Step: 0
Training loss: 1.7300174718867574
Validation loss: 2.3569539049958133

Epoch: 5| Step: 1
Training loss: 1.8490491459712257
Validation loss: 2.3856183213921742

Epoch: 5| Step: 2
Training loss: 1.7597120406008397
Validation loss: 2.3904616480848437

Epoch: 5| Step: 3
Training loss: 2.0173683611385167
Validation loss: 2.3852155772799506

Epoch: 5| Step: 4
Training loss: 1.8398627990902796
Validation loss: 2.3712406144386238

Epoch: 5| Step: 5
Training loss: 1.5907919865399427
Validation loss: 2.383931313176872

Epoch: 5| Step: 6
Training loss: 2.3463898097530054
Validation loss: 2.410460767669494

Epoch: 5| Step: 7
Training loss: 1.9933404914489279
Validation loss: 2.4158787216998943

Epoch: 5| Step: 8
Training loss: 2.2030584447019796
Validation loss: 2.3560090676261636

Epoch: 5| Step: 9
Training loss: 2.073980687734802
Validation loss: 2.3752989120773944

Epoch: 5| Step: 10
Training loss: 1.7397221112050334
Validation loss: 2.3542345650482805

Epoch: 5| Step: 11
Training loss: 1.5845742967448062
Validation loss: 2.389594080173856

Epoch: 97| Step: 0
Training loss: 1.5671159083253359
Validation loss: 2.3780326303997668

Epoch: 5| Step: 1
Training loss: 2.0594411188142265
Validation loss: 2.3735222485537992

Epoch: 5| Step: 2
Training loss: 1.8242259382804706
Validation loss: 2.3426422722711

Epoch: 5| Step: 3
Training loss: 1.8259504377777354
Validation loss: 2.4048337525493766

Epoch: 5| Step: 4
Training loss: 1.7815836543747814
Validation loss: 2.3893540521545447

Epoch: 5| Step: 5
Training loss: 2.0655451171941395
Validation loss: 2.408478646090866

Epoch: 5| Step: 6
Training loss: 1.992121138121883
Validation loss: 2.4004200787931915

Epoch: 5| Step: 7
Training loss: 1.9043195361231793
Validation loss: 2.3999194476066927

Epoch: 5| Step: 8
Training loss: 2.4624132363772313
Validation loss: 2.40935786917765

Epoch: 5| Step: 9
Training loss: 2.20376382859122
Validation loss: 2.408121978555898

Epoch: 5| Step: 10
Training loss: 1.6309894075920948
Validation loss: 2.41469134110302

Epoch: 5| Step: 11
Training loss: 1.514736268911347
Validation loss: 2.381346112745446

Epoch: 98| Step: 0
Training loss: 1.5555728710815424
Validation loss: 2.360045493560955

Epoch: 5| Step: 1
Training loss: 1.7350450888059996
Validation loss: 2.404322103723854

Epoch: 5| Step: 2
Training loss: 2.5188950792657328
Validation loss: 2.3956059299575485

Epoch: 5| Step: 3
Training loss: 2.095230034920022
Validation loss: 2.3931337378358895

Epoch: 5| Step: 4
Training loss: 1.6674678863452808
Validation loss: 2.3803026666179785

Epoch: 5| Step: 5
Training loss: 1.6991816374134985
Validation loss: 2.363373746716966

Epoch: 5| Step: 6
Training loss: 2.169138659739622
Validation loss: 2.3532097835388943

Epoch: 5| Step: 7
Training loss: 2.236307122410929
Validation loss: 2.358630915649377

Epoch: 5| Step: 8
Training loss: 1.5365640722409875
Validation loss: 2.3605517722169553

Epoch: 5| Step: 9
Training loss: 1.8950991064642326
Validation loss: 2.3881765035449796

Epoch: 5| Step: 10
Training loss: 1.9181775758261652
Validation loss: 2.4013394910971533

Epoch: 5| Step: 11
Training loss: 0.7064436267329598
Validation loss: 2.377380512382457

Epoch: 99| Step: 0
Training loss: 2.098779132724886
Validation loss: 2.395410514231321

Epoch: 5| Step: 1
Training loss: 2.1206330700087523
Validation loss: 2.4131606103429544

Epoch: 5| Step: 2
Training loss: 2.194587995230776
Validation loss: 2.407440811537485

Epoch: 5| Step: 3
Training loss: 1.877963775468213
Validation loss: 2.3847997102168277

Epoch: 5| Step: 4
Training loss: 2.3570380352707794
Validation loss: 2.407820946366903

Epoch: 5| Step: 5
Training loss: 1.7758404421056164
Validation loss: 2.4061307505994147

Epoch: 5| Step: 6
Training loss: 1.2417429962421493
Validation loss: 2.3932732269138683

Epoch: 5| Step: 7
Training loss: 1.9729029737223607
Validation loss: 2.4136861941996366

Epoch: 5| Step: 8
Training loss: 1.3313602312325605
Validation loss: 2.388765713253936

Epoch: 5| Step: 9
Training loss: 1.940532034645172
Validation loss: 2.4171636532160177

Epoch: 5| Step: 10
Training loss: 1.5072867311907856
Validation loss: 2.394405496519745

Epoch: 5| Step: 11
Training loss: 2.0345508458423023
Validation loss: 2.359626596606441

Epoch: 100| Step: 0
Training loss: 1.7254864545813877
Validation loss: 2.3576607402737095

Epoch: 5| Step: 1
Training loss: 1.9489791814632658
Validation loss: 2.3914816865152693

Epoch: 5| Step: 2
Training loss: 1.5338574222169619
Validation loss: 2.398211090551525

Epoch: 5| Step: 3
Training loss: 2.608678119365542
Validation loss: 2.387312574336378

Epoch: 5| Step: 4
Training loss: 2.0847729350250095
Validation loss: 2.387926669051305

Epoch: 5| Step: 5
Training loss: 1.680026636707221
Validation loss: 2.389145418203907

Epoch: 5| Step: 6
Training loss: 1.841537052731563
Validation loss: 2.4291764362742905

Epoch: 5| Step: 7
Training loss: 1.5612958464293418
Validation loss: 2.396862063482819

Epoch: 5| Step: 8
Training loss: 1.8602904302209717
Validation loss: 2.431095208173865

Epoch: 5| Step: 9
Training loss: 2.2381979509069003
Validation loss: 2.4163725909719243

Epoch: 5| Step: 10
Training loss: 1.6664941062605567
Validation loss: 2.3766754707072595

Epoch: 5| Step: 11
Training loss: 1.449419609195946
Validation loss: 2.373201036089929

Epoch: 101| Step: 0
Training loss: 1.5559627344430014
Validation loss: 2.3411220249468956

Epoch: 5| Step: 1
Training loss: 2.303674093601091
Validation loss: 2.3649226917020414

Epoch: 5| Step: 2
Training loss: 2.0701933052730874
Validation loss: 2.378425988137014

Epoch: 5| Step: 3
Training loss: 1.7431264493928713
Validation loss: 2.3658567408305906

Epoch: 5| Step: 4
Training loss: 1.6882631907276102
Validation loss: 2.3772020588367107

Epoch: 5| Step: 5
Training loss: 1.8614606299774854
Validation loss: 2.3855749782907614

Epoch: 5| Step: 6
Training loss: 2.2599354830959992
Validation loss: 2.3896228418407155

Epoch: 5| Step: 7
Training loss: 1.2441475237740443
Validation loss: 2.41607417593597

Epoch: 5| Step: 8
Training loss: 2.285618818367038
Validation loss: 2.46605541959112

Epoch: 5| Step: 9
Training loss: 1.8945545942303719
Validation loss: 2.4393636922780284

Epoch: 5| Step: 10
Training loss: 2.055437074574505
Validation loss: 2.4285148211134193

Epoch: 5| Step: 11
Training loss: 1.5528769373675533
Validation loss: 2.3795443004387464

Epoch: 102| Step: 0
Training loss: 1.87478318550313
Validation loss: 2.3891442934600216

Epoch: 5| Step: 1
Training loss: 1.9711650991208076
Validation loss: 2.3378777180939245

Epoch: 5| Step: 2
Training loss: 1.8586104287629432
Validation loss: 2.3674206844418695

Epoch: 5| Step: 3
Training loss: 2.283636751921764
Validation loss: 2.396986044823477

Epoch: 5| Step: 4
Training loss: 1.930356546782246
Validation loss: 2.3771656560949395

Epoch: 5| Step: 5
Training loss: 1.6867944867373947
Validation loss: 2.369527053032728

Epoch: 5| Step: 6
Training loss: 1.8699986193646725
Validation loss: 2.4083088162988107

Epoch: 5| Step: 7
Training loss: 2.1715931881086505
Validation loss: 2.361785150289195

Epoch: 5| Step: 8
Training loss: 1.816511056809148
Validation loss: 2.4052027326551424

Epoch: 5| Step: 9
Training loss: 2.118112284694494
Validation loss: 2.3804971337491123

Epoch: 5| Step: 10
Training loss: 1.5246188547326904
Validation loss: 2.390277513169929

Epoch: 5| Step: 11
Training loss: 0.9841169291489601
Validation loss: 2.41629389787304

Epoch: 103| Step: 0
Training loss: 1.5192684936854155
Validation loss: 2.4150548580407425

Epoch: 5| Step: 1
Training loss: 2.5726427454960334
Validation loss: 2.447517526159247

Epoch: 5| Step: 2
Training loss: 2.4126634216300826
Validation loss: 2.439593671217031

Epoch: 5| Step: 3
Training loss: 1.5937844067019813
Validation loss: 2.399467810263124

Epoch: 5| Step: 4
Training loss: 1.6448558930928747
Validation loss: 2.391225577317951

Epoch: 5| Step: 5
Training loss: 1.7313140113647425
Validation loss: 2.4037121728825883

Epoch: 5| Step: 6
Training loss: 2.321042854626755
Validation loss: 2.405291320924285

Epoch: 5| Step: 7
Training loss: 1.6313853620586354
Validation loss: 2.3953770797394793

Epoch: 5| Step: 8
Training loss: 1.836700280995975
Validation loss: 2.3889468459250156

Epoch: 5| Step: 9
Training loss: 1.696693174621016
Validation loss: 2.3694075863535327

Epoch: 5| Step: 10
Training loss: 1.3728912829694548
Validation loss: 2.3569882765019705

Epoch: 5| Step: 11
Training loss: 1.8952494410302791
Validation loss: 2.3820505268421672

Epoch: 104| Step: 0
Training loss: 1.9857541795782898
Validation loss: 2.413082263284539

Epoch: 5| Step: 1
Training loss: 1.6464268141489784
Validation loss: 2.3715604127010232

Epoch: 5| Step: 2
Training loss: 1.7379237118034572
Validation loss: 2.3759365159420325

Epoch: 5| Step: 3
Training loss: 1.7665246342599543
Validation loss: 2.3732897724438353

Epoch: 5| Step: 4
Training loss: 1.566782461445794
Validation loss: 2.390258224874533

Epoch: 5| Step: 5
Training loss: 2.468533566802053
Validation loss: 2.3537378525450032

Epoch: 5| Step: 6
Training loss: 1.6867107382332738
Validation loss: 2.3727869590048827

Epoch: 5| Step: 7
Training loss: 2.008945486814946
Validation loss: 2.3868785311444802

Epoch: 5| Step: 8
Training loss: 1.3094161452791238
Validation loss: 2.382456072221888

Epoch: 5| Step: 9
Training loss: 1.9131655712991351
Validation loss: 2.377054283896253

Epoch: 5| Step: 10
Training loss: 1.9835394354194256
Validation loss: 2.3992283208008773

Epoch: 5| Step: 11
Training loss: 2.9714715629653465
Validation loss: 2.3773715618176943

Epoch: 105| Step: 0
Training loss: 2.023781529935532
Validation loss: 2.3976333918703623

Epoch: 5| Step: 1
Training loss: 1.8072273909895566
Validation loss: 2.3896498592420805

Epoch: 5| Step: 2
Training loss: 1.991263201347121
Validation loss: 2.3680221546560785

Epoch: 5| Step: 3
Training loss: 2.299260153156247
Validation loss: 2.330670663252104

Epoch: 5| Step: 4
Training loss: 1.3736857288657596
Validation loss: 2.360617889206404

Epoch: 5| Step: 5
Training loss: 1.9662304453717119
Validation loss: 2.382526476427063

Epoch: 5| Step: 6
Training loss: 1.6032190455165833
Validation loss: 2.370979050737748

Epoch: 5| Step: 7
Training loss: 2.0399869379859568
Validation loss: 2.3584847360095056

Epoch: 5| Step: 8
Training loss: 1.345960838765624
Validation loss: 2.4007857980053013

Epoch: 5| Step: 9
Training loss: 1.7167303530289741
Validation loss: 2.37581340764268

Epoch: 5| Step: 10
Training loss: 2.0538312048712832
Validation loss: 2.3782987147683

Epoch: 5| Step: 11
Training loss: 1.4670915371160682
Validation loss: 2.3892660038932196

Epoch: 106| Step: 0
Training loss: 2.1353469713204096
Validation loss: 2.4570153725600807

Epoch: 5| Step: 1
Training loss: 2.1419956246553076
Validation loss: 2.4676979374428396

Epoch: 5| Step: 2
Training loss: 1.5242302030429282
Validation loss: 2.5048445432836726

Epoch: 5| Step: 3
Training loss: 1.7686825500136474
Validation loss: 2.4931278666921846

Epoch: 5| Step: 4
Training loss: 1.8826836506295417
Validation loss: 2.418307451674472

Epoch: 5| Step: 5
Training loss: 1.5377864291720114
Validation loss: 2.422402146098189

Epoch: 5| Step: 6
Training loss: 2.244981573322348
Validation loss: 2.3882375942570753

Epoch: 5| Step: 7
Training loss: 2.1649617554279845
Validation loss: 2.370350607605705

Epoch: 5| Step: 8
Training loss: 1.9779944980957531
Validation loss: 2.3716251085848636

Epoch: 5| Step: 9
Training loss: 1.5602295210303765
Validation loss: 2.384473107362346

Epoch: 5| Step: 10
Training loss: 1.5327311767407872
Validation loss: 2.3840316405244817

Epoch: 5| Step: 11
Training loss: 1.474338046747226
Validation loss: 2.3959743140384995

Epoch: 107| Step: 0
Training loss: 1.8686277827992963
Validation loss: 2.38933722606951

Epoch: 5| Step: 1
Training loss: 1.6596490062630316
Validation loss: 2.3795542468648585

Epoch: 5| Step: 2
Training loss: 2.173826589523829
Validation loss: 2.4121497476470655

Epoch: 5| Step: 3
Training loss: 2.1550330445838393
Validation loss: 2.3739824938803533

Epoch: 5| Step: 4
Training loss: 1.8278357774227652
Validation loss: 2.365119870409606

Epoch: 5| Step: 5
Training loss: 2.036750974060028
Validation loss: 2.356289283634088

Epoch: 5| Step: 6
Training loss: 1.4821686258226237
Validation loss: 2.419825213546402

Epoch: 5| Step: 7
Training loss: 1.8197135758599334
Validation loss: 2.431166518640526

Epoch: 5| Step: 8
Training loss: 1.950483687640882
Validation loss: 2.4046110500042035

Epoch: 5| Step: 9
Training loss: 2.003472770222178
Validation loss: 2.417056624969641

Epoch: 5| Step: 10
Training loss: 1.6004718323230716
Validation loss: 2.3955224367574743

Epoch: 5| Step: 11
Training loss: 2.598580332286683
Validation loss: 2.3551837965980504

Epoch: 108| Step: 0
Training loss: 1.9731734702506953
Validation loss: 2.387767846293579

Epoch: 5| Step: 1
Training loss: 1.6336998239647293
Validation loss: 2.403175499480141

Epoch: 5| Step: 2
Training loss: 1.2939870460545793
Validation loss: 2.3597223560896277

Epoch: 5| Step: 3
Training loss: 2.310271761873156
Validation loss: 2.3715325399387917

Epoch: 5| Step: 4
Training loss: 1.7513715274093797
Validation loss: 2.375522694039503

Epoch: 5| Step: 5
Training loss: 1.6211147812547653
Validation loss: 2.36507469203123

Epoch: 5| Step: 6
Training loss: 1.8437091370273153
Validation loss: 2.3658988936856913

Epoch: 5| Step: 7
Training loss: 1.9318037282433627
Validation loss: 2.390749980011566

Epoch: 5| Step: 8
Training loss: 1.8398767942146028
Validation loss: 2.3817917018242816

Epoch: 5| Step: 9
Training loss: 1.7887413702862578
Validation loss: 2.3665161397797188

Epoch: 5| Step: 10
Training loss: 1.679085344123321
Validation loss: 2.35940327743191

Epoch: 5| Step: 11
Training loss: 2.5279376173893433
Validation loss: 2.4000781905828417

Epoch: 109| Step: 0
Training loss: 1.7481926713378548
Validation loss: 2.4146560198584526

Epoch: 5| Step: 1
Training loss: 1.7011529546970954
Validation loss: 2.381039661385821

Epoch: 5| Step: 2
Training loss: 2.229759945457734
Validation loss: 2.4202259499737657

Epoch: 5| Step: 3
Training loss: 1.631365851603669
Validation loss: 2.4318615650880075

Epoch: 5| Step: 4
Training loss: 1.7914575262504482
Validation loss: 2.3734679530092175

Epoch: 5| Step: 5
Training loss: 1.4248020938172503
Validation loss: 2.3820843569001746

Epoch: 5| Step: 6
Training loss: 2.0341371411852176
Validation loss: 2.391707547156314

Epoch: 5| Step: 7
Training loss: 1.927051055912823
Validation loss: 2.366502484371134

Epoch: 5| Step: 8
Training loss: 1.9684131879163573
Validation loss: 2.369317583025539

Epoch: 5| Step: 9
Training loss: 1.8096012744838366
Validation loss: 2.3614883221266125

Epoch: 5| Step: 10
Training loss: 1.850759146845412
Validation loss: 2.387244042395537

Epoch: 5| Step: 11
Training loss: 1.9489924542206125
Validation loss: 2.402524838949328

Epoch: 110| Step: 0
Training loss: 1.8221998785491793
Validation loss: 2.3721598868315943

Epoch: 5| Step: 1
Training loss: 1.6780243912698447
Validation loss: 2.4209660865202545

Epoch: 5| Step: 2
Training loss: 1.1788249114778566
Validation loss: 2.4341678095389034

Epoch: 5| Step: 3
Training loss: 2.000470225369303
Validation loss: 2.443369035221461

Epoch: 5| Step: 4
Training loss: 1.9391272079896844
Validation loss: 2.429745488430534

Epoch: 5| Step: 5
Training loss: 1.9066678199008753
Validation loss: 2.4250015709403283

Epoch: 5| Step: 6
Training loss: 2.272782169025839
Validation loss: 2.390850415957127

Epoch: 5| Step: 7
Training loss: 1.468364340288434
Validation loss: 2.395651357761032

Epoch: 5| Step: 8
Training loss: 1.936575884548863
Validation loss: 2.3635613856047146

Epoch: 5| Step: 9
Training loss: 1.672697061239482
Validation loss: 2.3800899773907864

Epoch: 5| Step: 10
Training loss: 1.6763646104106809
Validation loss: 2.3696030314618213

Epoch: 5| Step: 11
Training loss: 2.551865351703314
Validation loss: 2.3679241591126985

Epoch: 111| Step: 0
Training loss: 1.3002575344138043
Validation loss: 2.355390320711583

Epoch: 5| Step: 1
Training loss: 1.7826112598509969
Validation loss: 2.3767988436469585

Epoch: 5| Step: 2
Training loss: 2.0192909909444996
Validation loss: 2.3717604050326124

Epoch: 5| Step: 3
Training loss: 1.7739271924669242
Validation loss: 2.3758172314842048

Epoch: 5| Step: 4
Training loss: 1.4832295063556988
Validation loss: 2.4054430933913142

Epoch: 5| Step: 5
Training loss: 1.8494969689312653
Validation loss: 2.363271665947767

Epoch: 5| Step: 6
Training loss: 1.5530894899050616
Validation loss: 2.3936345099933027

Epoch: 5| Step: 7
Training loss: 2.2394511575655276
Validation loss: 2.4186992168434656

Epoch: 5| Step: 8
Training loss: 1.7334577867260588
Validation loss: 2.3690052753812174

Epoch: 5| Step: 9
Training loss: 1.8149041640776455
Validation loss: 2.3958509541292012

Epoch: 5| Step: 10
Training loss: 1.6627551750592386
Validation loss: 2.429515959315205

Epoch: 5| Step: 11
Training loss: 2.529613860898102
Validation loss: 2.446685060491291

Epoch: 112| Step: 0
Training loss: 1.4615307587640693
Validation loss: 2.4276804653329296

Epoch: 5| Step: 1
Training loss: 1.8141035681518973
Validation loss: 2.484026574547578

Epoch: 5| Step: 2
Training loss: 1.77605913289749
Validation loss: 2.4363072199370817

Epoch: 5| Step: 3
Training loss: 1.869153189143542
Validation loss: 2.41504719063491

Epoch: 5| Step: 4
Training loss: 2.1609699724009706
Validation loss: 2.411333972094304

Epoch: 5| Step: 5
Training loss: 1.6545183738317697
Validation loss: 2.3696897226281526

Epoch: 5| Step: 6
Training loss: 1.8014020201512366
Validation loss: 2.346302558311602

Epoch: 5| Step: 7
Training loss: 1.8228586750797096
Validation loss: 2.399686630970176

Epoch: 5| Step: 8
Training loss: 1.681547545582946
Validation loss: 2.383540529023488

Epoch: 5| Step: 9
Training loss: 1.8562938261156616
Validation loss: 2.348984226893267

Epoch: 5| Step: 10
Training loss: 1.6288743416201799
Validation loss: 2.3608527408367235

Epoch: 5| Step: 11
Training loss: 2.0536408169793408
Validation loss: 2.400699826287443

Epoch: 113| Step: 0
Training loss: 1.6172780182057094
Validation loss: 2.393162077142221

Epoch: 5| Step: 1
Training loss: 2.0603138290162604
Validation loss: 2.4310259837589125

Epoch: 5| Step: 2
Training loss: 1.7608729867702297
Validation loss: 2.4404077263055504

Epoch: 5| Step: 3
Training loss: 1.7724233407901344
Validation loss: 2.463429871187258

Epoch: 5| Step: 4
Training loss: 1.6738178693530623
Validation loss: 2.4619946969090347

Epoch: 5| Step: 5
Training loss: 1.9530421735367516
Validation loss: 2.4263057704754356

Epoch: 5| Step: 6
Training loss: 1.5959414207301281
Validation loss: 2.4288654060974624

Epoch: 5| Step: 7
Training loss: 1.8646960375376056
Validation loss: 2.3882253171730827

Epoch: 5| Step: 8
Training loss: 1.7822697046362224
Validation loss: 2.3738871568892757

Epoch: 5| Step: 9
Training loss: 1.678438085691939
Validation loss: 2.3929201963694124

Epoch: 5| Step: 10
Training loss: 1.7245544908717974
Validation loss: 2.3730618595440345

Epoch: 5| Step: 11
Training loss: 0.2511364171702047
Validation loss: 2.379228842524678

Epoch: 114| Step: 0
Training loss: 1.8918207974036907
Validation loss: 2.3677365638827768

Epoch: 5| Step: 1
Training loss: 1.9281258383676447
Validation loss: 2.386520315059446

Epoch: 5| Step: 2
Training loss: 2.2159366232488726
Validation loss: 2.394400878808884

Epoch: 5| Step: 3
Training loss: 1.741837675956024
Validation loss: 2.383147450653221

Epoch: 5| Step: 4
Training loss: 1.2095771285495929
Validation loss: 2.382267273607179

Epoch: 5| Step: 5
Training loss: 1.5626767630728302
Validation loss: 2.3910614604240896

Epoch: 5| Step: 6
Training loss: 1.8510217963593876
Validation loss: 2.351830396463271

Epoch: 5| Step: 7
Training loss: 1.5876096732635174
Validation loss: 2.3894752613252286

Epoch: 5| Step: 8
Training loss: 1.2947641682281428
Validation loss: 2.3899932641635395

Epoch: 5| Step: 9
Training loss: 1.8957731915111427
Validation loss: 2.420098155417884

Epoch: 5| Step: 10
Training loss: 1.5504468273799237
Validation loss: 2.4465621420190504

Epoch: 5| Step: 11
Training loss: 2.8326932146613886
Validation loss: 2.437709041337044

Epoch: 115| Step: 0
Training loss: 1.4137553940593375
Validation loss: 2.3678268391772153

Epoch: 5| Step: 1
Training loss: 1.3018184799400567
Validation loss: 2.394967118835909

Epoch: 5| Step: 2
Training loss: 1.9966820971423944
Validation loss: 2.3815886517844005

Epoch: 5| Step: 3
Training loss: 1.7625375270230217
Validation loss: 2.3801109842193897

Epoch: 5| Step: 4
Training loss: 1.2549281724383397
Validation loss: 2.381629975607777

Epoch: 5| Step: 5
Training loss: 2.0862339680617388
Validation loss: 2.378641265158669

Epoch: 5| Step: 6
Training loss: 2.0281763149640857
Validation loss: 2.423115500778432

Epoch: 5| Step: 7
Training loss: 1.841054853882986
Validation loss: 2.431478504664545

Epoch: 5| Step: 8
Training loss: 1.9034715634449673
Validation loss: 2.3779598623211142

Epoch: 5| Step: 9
Training loss: 1.4778692528290998
Validation loss: 2.386926699172781

Epoch: 5| Step: 10
Training loss: 1.7837950610836126
Validation loss: 2.403716601194123

Epoch: 5| Step: 11
Training loss: 1.7518305060472388
Validation loss: 2.409222756443972

Epoch: 116| Step: 0
Training loss: 1.965780107112607
Validation loss: 2.40465330430492

Epoch: 5| Step: 1
Training loss: 1.6628358286637224
Validation loss: 2.4937013873124045

Epoch: 5| Step: 2
Training loss: 1.7319490804697717
Validation loss: 2.443521365684341

Epoch: 5| Step: 3
Training loss: 1.4605747527333695
Validation loss: 2.4991920596167554

Epoch: 5| Step: 4
Training loss: 1.545719447229298
Validation loss: 2.480207632743761

Epoch: 5| Step: 5
Training loss: 1.5423705667756167
Validation loss: 2.4383095106194017

Epoch: 5| Step: 6
Training loss: 1.6568612464267756
Validation loss: 2.4326472066800653

Epoch: 5| Step: 7
Training loss: 1.5906436042222267
Validation loss: 2.429317343953222

Epoch: 5| Step: 8
Training loss: 1.4245294797986132
Validation loss: 2.3985344145472007

Epoch: 5| Step: 9
Training loss: 1.7580505888021185
Validation loss: 2.3906474725336055

Epoch: 5| Step: 10
Training loss: 2.2593330094483655
Validation loss: 2.4100176061881458

Epoch: 5| Step: 11
Training loss: 2.7613872237362984
Validation loss: 2.376056440364046

Epoch: 117| Step: 0
Training loss: 2.4040451847723756
Validation loss: 2.421468983733752

Epoch: 5| Step: 1
Training loss: 1.909681889271847
Validation loss: 2.4327692805905983

Epoch: 5| Step: 2
Training loss: 1.5465644755941472
Validation loss: 2.4402023683788427

Epoch: 5| Step: 3
Training loss: 2.00686718250464
Validation loss: 2.4346901254236237

Epoch: 5| Step: 4
Training loss: 1.5735689625375338
Validation loss: 2.3695944497903225

Epoch: 5| Step: 5
Training loss: 1.3916467063675422
Validation loss: 2.3756944996162486

Epoch: 5| Step: 6
Training loss: 1.5710018030516866
Validation loss: 2.400845936860521

Epoch: 5| Step: 7
Training loss: 1.9901829227164503
Validation loss: 2.3553114206416974

Epoch: 5| Step: 8
Training loss: 1.8081893963229774
Validation loss: 2.4073749942682814

Epoch: 5| Step: 9
Training loss: 1.620095922550128
Validation loss: 2.409248362411434

Epoch: 5| Step: 10
Training loss: 1.716261293022637
Validation loss: 2.443400552648123

Epoch: 5| Step: 11
Training loss: 0.9551490804140131
Validation loss: 2.438477232656309

Epoch: 118| Step: 0
Training loss: 1.3045439955316842
Validation loss: 2.434818235306617

Epoch: 5| Step: 1
Training loss: 2.134417031629688
Validation loss: 2.4290840855188245

Epoch: 5| Step: 2
Training loss: 1.556141082751654
Validation loss: 2.3941665296978307

Epoch: 5| Step: 3
Training loss: 1.7018627423795187
Validation loss: 2.4197462303985398

Epoch: 5| Step: 4
Training loss: 1.5659542049810327
Validation loss: 2.3624650770125766

Epoch: 5| Step: 5
Training loss: 1.3747796402264667
Validation loss: 2.336877563548614

Epoch: 5| Step: 6
Training loss: 1.3912106255977206
Validation loss: 2.3640545507256623

Epoch: 5| Step: 7
Training loss: 1.9850411085585196
Validation loss: 2.414003729490656

Epoch: 5| Step: 8
Training loss: 2.129028428797667
Validation loss: 2.4000250566684533

Epoch: 5| Step: 9
Training loss: 1.3638681716838914
Validation loss: 2.3851584679295157

Epoch: 5| Step: 10
Training loss: 2.139311784439393
Validation loss: 2.3810235108524926

Epoch: 5| Step: 11
Training loss: 1.9276307299423472
Validation loss: 2.3787986175625675

Epoch: 119| Step: 0
Training loss: 1.7212264513276219
Validation loss: 2.394516484856524

Epoch: 5| Step: 1
Training loss: 2.0029407577171523
Validation loss: 2.370010602011219

Epoch: 5| Step: 2
Training loss: 1.4558730853279331
Validation loss: 2.451115378327785

Epoch: 5| Step: 3
Training loss: 1.396946159786185
Validation loss: 2.4236059832465555

Epoch: 5| Step: 4
Training loss: 1.4922724195353323
Validation loss: 2.3975355583433933

Epoch: 5| Step: 5
Training loss: 1.5673011259379785
Validation loss: 2.4549320514350153

Epoch: 5| Step: 6
Training loss: 2.112550958323532
Validation loss: 2.4163401701038434

Epoch: 5| Step: 7
Training loss: 1.7075919271496771
Validation loss: 2.4160544542149265

Epoch: 5| Step: 8
Training loss: 1.317820120833074
Validation loss: 2.371914109455017

Epoch: 5| Step: 9
Training loss: 1.8219468797797749
Validation loss: 2.384504665850394

Epoch: 5| Step: 10
Training loss: 2.00209341162435
Validation loss: 2.3849424566868556

Epoch: 5| Step: 11
Training loss: 1.245189374439307
Validation loss: 2.413309113471419

Epoch: 120| Step: 0
Training loss: 1.8399373737333737
Validation loss: 2.3865738870015156

Epoch: 5| Step: 1
Training loss: 1.5634315002924073
Validation loss: 2.3596361870436926

Epoch: 5| Step: 2
Training loss: 1.637829169465314
Validation loss: 2.366677908187907

Epoch: 5| Step: 3
Training loss: 1.614918835965443
Validation loss: 2.372697165509779

Epoch: 5| Step: 4
Training loss: 1.4548016791190568
Validation loss: 2.3687911440212557

Epoch: 5| Step: 5
Training loss: 2.041118535271903
Validation loss: 2.3898976119041655

Epoch: 5| Step: 6
Training loss: 1.939437697119686
Validation loss: 2.3923243734519195

Epoch: 5| Step: 7
Training loss: 1.5308082098950795
Validation loss: 2.400495969169457

Epoch: 5| Step: 8
Training loss: 1.594252114579149
Validation loss: 2.455629750596135

Epoch: 5| Step: 9
Training loss: 1.2455056934479238
Validation loss: 2.3981435100618853

Epoch: 5| Step: 10
Training loss: 1.9021345646265464
Validation loss: 2.417350891417028

Epoch: 5| Step: 11
Training loss: 1.8100552349198333
Validation loss: 2.3730285392649395

Epoch: 121| Step: 0
Training loss: 1.1889666986157246
Validation loss: 2.377639374710793

Epoch: 5| Step: 1
Training loss: 1.6994386727967108
Validation loss: 2.398682522761447

Epoch: 5| Step: 2
Training loss: 1.36025867021767
Validation loss: 2.4078395390627194

Epoch: 5| Step: 3
Training loss: 1.5778707167216661
Validation loss: 2.3986399851928017

Epoch: 5| Step: 4
Training loss: 1.939165076678774
Validation loss: 2.37326209579756

Epoch: 5| Step: 5
Training loss: 1.5928554642428363
Validation loss: 2.385624140805163

Epoch: 5| Step: 6
Training loss: 1.924483227413644
Validation loss: 2.3867054182929985

Epoch: 5| Step: 7
Training loss: 1.4567250602476653
Validation loss: 2.3758437515060695

Epoch: 5| Step: 8
Training loss: 1.9621393540537742
Validation loss: 2.4103843255429984

Epoch: 5| Step: 9
Training loss: 1.5173746608397818
Validation loss: 2.381678906725839

Epoch: 5| Step: 10
Training loss: 1.538621558523734
Validation loss: 2.400757817655631

Epoch: 5| Step: 11
Training loss: 2.4034765534531988
Validation loss: 2.406850843015293

Epoch: 122| Step: 0
Training loss: 1.3306742717172668
Validation loss: 2.4027111031047106

Epoch: 5| Step: 1
Training loss: 1.382641323723345
Validation loss: 2.405359894157255

Epoch: 5| Step: 2
Training loss: 1.4217245839803474
Validation loss: 2.3946618816676883

Epoch: 5| Step: 3
Training loss: 2.35985656270058
Validation loss: 2.385114514622677

Epoch: 5| Step: 4
Training loss: 1.8249952472990676
Validation loss: 2.3575553087230485

Epoch: 5| Step: 5
Training loss: 1.480578818545029
Validation loss: 2.3673054505224185

Epoch: 5| Step: 6
Training loss: 1.6319795519071363
Validation loss: 2.369650131582242

Epoch: 5| Step: 7
Training loss: 1.9403079205393066
Validation loss: 2.355387857628611

Epoch: 5| Step: 8
Training loss: 1.8108040339976703
Validation loss: 2.384197412146157

Epoch: 5| Step: 9
Training loss: 1.3582736848633448
Validation loss: 2.408339220972575

Epoch: 5| Step: 10
Training loss: 1.2015404608680842
Validation loss: 2.38564539871909

Epoch: 5| Step: 11
Training loss: 1.9745840189859403
Validation loss: 2.4125510569425646

Epoch: 123| Step: 0
Training loss: 2.244279689480676
Validation loss: 2.345328363258614

Epoch: 5| Step: 1
Training loss: 1.4484866367470282
Validation loss: 2.3438091948769304

Epoch: 5| Step: 2
Training loss: 1.625921061717
Validation loss: 2.39075014829823

Epoch: 5| Step: 3
Training loss: 1.4072760335683123
Validation loss: 2.389399299474739

Epoch: 5| Step: 4
Training loss: 1.8103773908082421
Validation loss: 2.358409094407966

Epoch: 5| Step: 5
Training loss: 1.2152203040686302
Validation loss: 2.3897833080033055

Epoch: 5| Step: 6
Training loss: 1.6889049191857441
Validation loss: 2.383127248019147

Epoch: 5| Step: 7
Training loss: 1.9134180346403307
Validation loss: 2.356084925420012

Epoch: 5| Step: 8
Training loss: 1.0804582309831468
Validation loss: 2.3453361611694405

Epoch: 5| Step: 9
Training loss: 1.4346401127505088
Validation loss: 2.397010552702565

Epoch: 5| Step: 10
Training loss: 2.031686823898514
Validation loss: 2.384314508699867

Epoch: 5| Step: 11
Training loss: 1.8326063087300668
Validation loss: 2.365814356278212

Epoch: 124| Step: 0
Training loss: 1.5056253491342282
Validation loss: 2.3889431491377127

Epoch: 5| Step: 1
Training loss: 1.7151833026452228
Validation loss: 2.379011117412123

Epoch: 5| Step: 2
Training loss: 1.2942311097259196
Validation loss: 2.4193096807924426

Epoch: 5| Step: 3
Training loss: 1.3216952695473427
Validation loss: 2.4491536052178615

Epoch: 5| Step: 4
Training loss: 1.5247126011425116
Validation loss: 2.387450637190577

Epoch: 5| Step: 5
Training loss: 2.1526367209651305
Validation loss: 2.4150199637433603

Epoch: 5| Step: 6
Training loss: 1.700784317175045
Validation loss: 2.4195719607833563

Epoch: 5| Step: 7
Training loss: 1.3155575515238624
Validation loss: 2.3925375092880192

Epoch: 5| Step: 8
Training loss: 1.6535089951816428
Validation loss: 2.3638762594628515

Epoch: 5| Step: 9
Training loss: 2.1790617451351233
Validation loss: 2.3449555793206986

Epoch: 5| Step: 10
Training loss: 1.426275799824679
Validation loss: 2.405071072952483

Epoch: 5| Step: 11
Training loss: 0.711773307710762
Validation loss: 2.361056139405785

Epoch: 125| Step: 0
Training loss: 1.3755266741458057
Validation loss: 2.384687338587294

Epoch: 5| Step: 1
Training loss: 1.5144640221842038
Validation loss: 2.365405386536727

Epoch: 5| Step: 2
Training loss: 1.919203102714508
Validation loss: 2.3678632994853754

Epoch: 5| Step: 3
Training loss: 1.3086218076516323
Validation loss: 2.3938027643342883

Epoch: 5| Step: 4
Training loss: 1.4032368485829934
Validation loss: 2.3839338321944106

Epoch: 5| Step: 5
Training loss: 1.4007334695167784
Validation loss: 2.3714694710547346

Epoch: 5| Step: 6
Training loss: 1.6194994336769406
Validation loss: 2.3966361953494295

Epoch: 5| Step: 7
Training loss: 1.3449225078651077
Validation loss: 2.4342975200945762

Epoch: 5| Step: 8
Training loss: 2.0225162249882143
Validation loss: 2.4066587736690708

Epoch: 5| Step: 9
Training loss: 1.9309638123047626
Validation loss: 2.409471574308249

Epoch: 5| Step: 10
Training loss: 1.8793878711276184
Validation loss: 2.378438129938704

Epoch: 5| Step: 11
Training loss: 1.946725477719395
Validation loss: 2.345192272621183

Testing loss: 1.93497062024983
