Epoch: 1| Step: 0
Training loss: 6.527724779423412
Validation loss: 5.835558632644015
Epoch: 5| Step: 1
Training loss: 6.792310563283008
Validation loss: 5.850121436464969
Epoch: 5| Step: 2
Training loss: 6.086162518906554
Validation loss: 5.8462281784786665
Epoch: 5| Step: 3
Training loss: 6.7845436922148465
Validation loss: 5.843103614333214
Epoch: 5| Step: 4
Training loss: 5.751287233314633
Validation loss: 5.835148319890917
Epoch: 5| Step: 5
Training loss: 5.607163017035386
Validation loss: 5.8326716535542005
Epoch: 5| Step: 6
Training loss: 5.545183638480574
Validation loss: 5.831821218955865
Epoch: 5| Step: 7
Training loss: 7.050120619154605
Validation loss: 5.821014344107633
Epoch: 5| Step: 8
Training loss: 5.82600851210376
Validation loss: 5.82076306362648
Epoch: 5| Step: 9
Training loss: 5.621236092870677
Validation loss: 5.820447850630547
Epoch: 2| Step: 0
Training loss: 5.228774077533073
Validation loss: 5.804214613445426
Epoch: 5| Step: 1
Training loss: 6.1930415451797405
Validation loss: 5.802413494571362
Epoch: 5| Step: 2
Training loss: 6.912267488566693
Validation loss: 5.8095170442270785
Epoch: 5| Step: 3
Training loss: 5.789955307124235
Validation loss: 5.802090645331282
Epoch: 5| Step: 4
Training loss: 6.100223174468317
Validation loss: 5.801844036246167
Epoch: 5| Step: 5
Training loss: 6.014964198690083
Validation loss: 5.775900566696651
Epoch: 5| Step: 6
Training loss: 6.4762191037205135
Validation loss: 5.788435135524241
Epoch: 5| Step: 7
Training loss: 5.934851125828026
Validation loss: 5.785718344953663
Epoch: 5| Step: 8
Training loss: 6.401232433864847
Validation loss: 5.785458646831449
Epoch: 5| Step: 9
Training loss: 6.291081112861566
Validation loss: 5.773751741160053
Epoch: 3| Step: 0
Training loss: 6.7860349306915895
Validation loss: 5.7773631939792995
Epoch: 5| Step: 1
Training loss: 6.719142316852731
Validation loss: 5.772122651862855
Epoch: 5| Step: 2
Training loss: 6.549954293360923
Validation loss: 5.7655881156314255
Epoch: 5| Step: 3
Training loss: 5.595817993476314
Validation loss: 5.758994994752792
Epoch: 5| Step: 4
Training loss: 5.6650268575599005
Validation loss: 5.7645459650198
Epoch: 5| Step: 5
Training loss: 5.408686623498438
Validation loss: 5.754154001949147
Epoch: 5| Step: 6
Training loss: 6.0986546267874475
Validation loss: 5.7557630740065
Epoch: 5| Step: 7
Training loss: 6.429692839646933
Validation loss: 5.742162573771728
Epoch: 5| Step: 8
Training loss: 5.576965382463591
Validation loss: 5.753213576157965
Epoch: 5| Step: 9
Training loss: 6.117847860070144
Validation loss: 5.747544035289768
Epoch: 4| Step: 0
Training loss: 6.3937670158391
Validation loss: 5.728599816563206
Epoch: 5| Step: 1
Training loss: 6.38590429870024
Validation loss: 5.73257870791246
Epoch: 5| Step: 2
Training loss: 6.198991065840876
Validation loss: 5.730853815656848
Epoch: 5| Step: 3
Training loss: 6.548775990975754
Validation loss: 5.725991417074912
Epoch: 5| Step: 4
Training loss: 5.989331933979019
Validation loss: 5.726177188396305
Epoch: 5| Step: 5
Training loss: 5.978704809057532
Validation loss: 5.713381597028493
Epoch: 5| Step: 6
Training loss: 5.962009318572564
Validation loss: 5.721825255808715
Epoch: 5| Step: 7
Training loss: 5.38054459719028
Validation loss: 5.709626186694565
Epoch: 5| Step: 8
Training loss: 6.51551405265627
Validation loss: 5.711777095426729
Epoch: 5| Step: 9
Training loss: 5.287018824838741
Validation loss: 5.705769145052709
Epoch: 5| Step: 0
Training loss: 5.74855520921633
Validation loss: 5.69562793243481
Epoch: 5| Step: 1
Training loss: 5.845848645031381
Validation loss: 5.693885062907863
Epoch: 5| Step: 2
Training loss: 6.448531097405748
Validation loss: 5.6862931458081825
Epoch: 5| Step: 3
Training loss: 6.185197189752566
Validation loss: 5.6846529487521975
Epoch: 5| Step: 4
Training loss: 6.335498272479892
Validation loss: 5.683458931912795
Epoch: 5| Step: 5
Training loss: 5.920234070351771
Validation loss: 5.679356805672566
Epoch: 5| Step: 6
Training loss: 6.064746558420318
Validation loss: 5.66502595457322
Epoch: 5| Step: 7
Training loss: 6.401904013650939
Validation loss: 5.673080399322884
Epoch: 5| Step: 8
Training loss: 5.856335800340316
Validation loss: 5.661001936258928
Epoch: 5| Step: 9
Training loss: 5.516027333225748
Validation loss: 5.664782520195941
Epoch: 6| Step: 0
Training loss: 6.0122460325536435
Validation loss: 5.657271619819311
Epoch: 5| Step: 1
Training loss: 6.020436450940617
Validation loss: 5.634009925155931
Epoch: 5| Step: 2
Training loss: 5.98663207833565
Validation loss: 5.642010903111544
Epoch: 5| Step: 3
Training loss: 6.39148510505536
Validation loss: 5.6454330122296605
Epoch: 5| Step: 4
Training loss: 5.663487309156485
Validation loss: 5.634143751861212
Epoch: 5| Step: 5
Training loss: 5.721094203408763
Validation loss: 5.625784842869185
Epoch: 5| Step: 6
Training loss: 5.868937834474961
Validation loss: 5.619856360219244
Epoch: 5| Step: 7
Training loss: 5.995199190191943
Validation loss: 5.617997149917575
Epoch: 5| Step: 8
Training loss: 6.330116391912257
Validation loss: 5.610754116738316
Epoch: 5| Step: 9
Training loss: 5.876237454866555
Validation loss: 5.605516578946938
Epoch: 7| Step: 0
Training loss: 5.6076924555384915
Validation loss: 5.600800155707285
Epoch: 5| Step: 1
Training loss: 6.2658237796749
Validation loss: 5.5977967954730135
Epoch: 5| Step: 2
Training loss: 5.1162883871368665
Validation loss: 5.585395356392989
Epoch: 5| Step: 3
Training loss: 6.41407201582729
Validation loss: 5.579904152345322
Epoch: 5| Step: 4
Training loss: 6.4800048809268604
Validation loss: 5.564453479155833
Epoch: 5| Step: 5
Training loss: 6.124621944048426
Validation loss: 5.563263124247129
Epoch: 5| Step: 6
Training loss: 6.254490574279411
Validation loss: 5.56683895660761
Epoch: 5| Step: 7
Training loss: 5.527758342169881
Validation loss: 5.555935835963902
Epoch: 5| Step: 8
Training loss: 5.4931106768239175
Validation loss: 5.5338418608177316
Epoch: 5| Step: 9
Training loss: 5.920022075715016
Validation loss: 5.5334929715228744
Epoch: 8| Step: 0
Training loss: 6.429730513696493
Validation loss: 5.531773870502307
Epoch: 5| Step: 1
Training loss: 5.929332375729581
Validation loss: 5.5195100934453
Epoch: 5| Step: 2
Training loss: 6.194069813498407
Validation loss: 5.525612858453592
Epoch: 5| Step: 3
Training loss: 6.3667180736656634
Validation loss: 5.510264614753066
Epoch: 5| Step: 4
Training loss: 5.776346632597621
Validation loss: 5.500766697018691
Epoch: 5| Step: 5
Training loss: 6.229748378711659
Validation loss: 5.490079941997076
Epoch: 5| Step: 6
Training loss: 5.411557453362657
Validation loss: 5.491312368916681
Epoch: 5| Step: 7
Training loss: 5.27119074678939
Validation loss: 5.4871789836949505
Epoch: 5| Step: 8
Training loss: 5.299941354103232
Validation loss: 5.479725773594905
Epoch: 5| Step: 9
Training loss: 5.6704543675418995
Validation loss: 5.475950019077003
Epoch: 9| Step: 0
Training loss: 5.662709294171207
Validation loss: 5.464054960278845
Epoch: 5| Step: 1
Training loss: 5.983528097200701
Validation loss: 5.447549311425485
Epoch: 5| Step: 2
Training loss: 5.702377813853936
Validation loss: 5.446681703935855
Epoch: 5| Step: 3
Training loss: 5.79076299775698
Validation loss: 5.446743607140991
Epoch: 5| Step: 4
Training loss: 5.862102229892527
Validation loss: 5.413693546828771
Epoch: 5| Step: 5
Training loss: 6.138004743716538
Validation loss: 5.419245591483922
Epoch: 5| Step: 6
Training loss: 5.078595230632341
Validation loss: 5.403522724555112
Epoch: 5| Step: 7
Training loss: 6.017374948391637
Validation loss: 5.411343894227224
Epoch: 5| Step: 8
Training loss: 5.600585341515879
Validation loss: 5.39289777147326
Epoch: 5| Step: 9
Training loss: 6.125144489686039
Validation loss: 5.3904194009408535
Epoch: 10| Step: 0
Training loss: 5.731479839013614
Validation loss: 5.379774334522209
Epoch: 5| Step: 1
Training loss: 5.999709440189518
Validation loss: 5.375102597238492
Epoch: 5| Step: 2
Training loss: 5.556565451490625
Validation loss: 5.361651325449214
Epoch: 5| Step: 3
Training loss: 6.38640188195221
Validation loss: 5.360816654492501
Epoch: 5| Step: 4
Training loss: 5.615815187353111
Validation loss: 5.348880015816791
Epoch: 5| Step: 5
Training loss: 4.931383424604981
Validation loss: 5.348544490311555
Epoch: 5| Step: 6
Training loss: 5.969710187922292
Validation loss: 5.336265756465558
Epoch: 5| Step: 7
Training loss: 5.870403683248442
Validation loss: 5.325255600171429
Epoch: 5| Step: 8
Training loss: 6.01527621756747
Validation loss: 5.300373475015405
Epoch: 5| Step: 9
Training loss: 4.995154130636847
Validation loss: 5.3076353090258355
Epoch: 11| Step: 0
Training loss: 5.565180786157552
Validation loss: 5.296419726504987
Epoch: 5| Step: 1
Training loss: 5.990180881934285
Validation loss: 5.29046588525545
Epoch: 5| Step: 2
Training loss: 5.903072087549057
Validation loss: 5.2842620833922656
Epoch: 5| Step: 3
Training loss: 5.439303745704693
Validation loss: 5.274184953554407
Epoch: 5| Step: 4
Training loss: 6.002135214757367
Validation loss: 5.252045063651512
Epoch: 5| Step: 5
Training loss: 5.436332138749686
Validation loss: 5.247546571052988
Epoch: 5| Step: 6
Training loss: 5.514615493332843
Validation loss: 5.240061888361837
Epoch: 5| Step: 7
Training loss: 5.399918393118895
Validation loss: 5.2141609415311025
Epoch: 5| Step: 8
Training loss: 5.327352786668351
Validation loss: 5.201320215467343
Epoch: 5| Step: 9
Training loss: 5.752899765586971
Validation loss: 5.192184682765073
Epoch: 12| Step: 0
Training loss: 5.673026312213129
Validation loss: 5.192781026058253
Epoch: 5| Step: 1
Training loss: 5.427781814856553
Validation loss: 5.184016601309675
Epoch: 5| Step: 2
Training loss: 5.4720788905719875
Validation loss: 5.185973507776427
Epoch: 5| Step: 3
Training loss: 5.065751338562277
Validation loss: 5.173027769321075
Epoch: 5| Step: 4
Training loss: 6.26600428929138
Validation loss: 5.1635557017071845
Epoch: 5| Step: 5
Training loss: 5.438084011942742
Validation loss: 5.146613291524533
Epoch: 5| Step: 6
Training loss: 5.708108642314102
Validation loss: 5.132633452797443
Epoch: 5| Step: 7
Training loss: 5.657465514357342
Validation loss: 5.125925973103239
Epoch: 5| Step: 8
Training loss: 5.359168579752921
Validation loss: 5.099406053725144
Epoch: 5| Step: 9
Training loss: 5.259648675535608
Validation loss: 5.100136070439297
Epoch: 13| Step: 0
Training loss: 5.813701874544651
Validation loss: 5.0781194450713505
Epoch: 5| Step: 1
Training loss: 5.952274932643761
Validation loss: 5.081854624656436
Epoch: 5| Step: 2
Training loss: 5.538836777234787
Validation loss: 5.044835457465959
Epoch: 5| Step: 3
Training loss: 5.766057026708451
Validation loss: 5.04339309348275
Epoch: 5| Step: 4
Training loss: 4.891053982284103
Validation loss: 5.044325343745326
Epoch: 5| Step: 5
Training loss: 5.114279350161113
Validation loss: 5.025601372413699
Epoch: 5| Step: 6
Training loss: 5.395479797014371
Validation loss: 5.002581099968137
Epoch: 5| Step: 7
Training loss: 5.57186820842267
Validation loss: 5.009724233672277
Epoch: 5| Step: 8
Training loss: 5.481068888926788
Validation loss: 4.9847796291220225
Epoch: 5| Step: 9
Training loss: 4.679599665611954
Validation loss: 4.982525656371204
Epoch: 14| Step: 0
Training loss: 5.367232276696409
Validation loss: 4.973113204675514
Epoch: 5| Step: 1
Training loss: 5.5041890230766795
Validation loss: 4.9468206118939
Epoch: 5| Step: 2
Training loss: 4.875231028242185
Validation loss: 4.939901827766567
Epoch: 5| Step: 3
Training loss: 6.09928509634723
Validation loss: 4.928599113936741
Epoch: 5| Step: 4
Training loss: 5.095961763391216
Validation loss: 4.9116037067762734
Epoch: 5| Step: 5
Training loss: 5.6037477622707375
Validation loss: 4.902649468769921
Epoch: 5| Step: 6
Training loss: 5.352264224636361
Validation loss: 4.871709134124514
Epoch: 5| Step: 7
Training loss: 5.268943578528415
Validation loss: 4.873457095863942
Epoch: 5| Step: 8
Training loss: 5.023466736039535
Validation loss: 4.8329706790413685
Epoch: 5| Step: 9
Training loss: 4.800520614365208
Validation loss: 4.829807614934298
Epoch: 15| Step: 0
Training loss: 5.191009988580072
Validation loss: 4.8296789711929415
Epoch: 5| Step: 1
Training loss: 5.253895358957113
Validation loss: 4.81653177894454
Epoch: 5| Step: 2
Training loss: 4.9818368984799815
Validation loss: 4.79202267226821
Epoch: 5| Step: 3
Training loss: 5.358116068768619
Validation loss: 4.784354369455054
Epoch: 5| Step: 4
Training loss: 5.449186897868377
Validation loss: 4.775562565878651
Epoch: 5| Step: 5
Training loss: 5.09277222030786
Validation loss: 4.749498054607366
Epoch: 5| Step: 6
Training loss: 5.257396573851093
Validation loss: 4.731815790660044
Epoch: 5| Step: 7
Training loss: 4.3112516946145005
Validation loss: 4.7049027655973195
Epoch: 5| Step: 8
Training loss: 5.090873233557419
Validation loss: 4.697570844302276
Epoch: 5| Step: 9
Training loss: 5.659658848486364
Validation loss: 4.67107607995587
Epoch: 16| Step: 0
Training loss: 5.125849211512191
Validation loss: 4.667458711670614
Epoch: 5| Step: 1
Training loss: 5.12435164653669
Validation loss: 4.649699514599907
Epoch: 5| Step: 2
Training loss: 4.9599773769478
Validation loss: 4.6428605372881036
Epoch: 5| Step: 3
Training loss: 5.377746589997567
Validation loss: 4.616157167785198
Epoch: 5| Step: 4
Training loss: 5.438073840499645
Validation loss: 4.606926801742713
Epoch: 5| Step: 5
Training loss: 5.024889793895573
Validation loss: 4.580208299859712
Epoch: 5| Step: 6
Training loss: 4.363180707492009
Validation loss: 4.561985279051818
Epoch: 5| Step: 7
Training loss: 4.991038875342064
Validation loss: 4.51884481015483
Epoch: 5| Step: 8
Training loss: 5.233533740407843
Validation loss: 4.520121717964697
Epoch: 5| Step: 9
Training loss: 4.478596543098028
Validation loss: 4.493705671856038
Epoch: 17| Step: 0
Training loss: 4.548867539545857
Validation loss: 4.463926292803292
Epoch: 5| Step: 1
Training loss: 5.539218141766066
Validation loss: 4.475248845423203
Epoch: 5| Step: 2
Training loss: 4.931060841537977
Validation loss: 4.450376049830655
Epoch: 5| Step: 3
Training loss: 5.052094869174437
Validation loss: 4.433386118236796
Epoch: 5| Step: 4
Training loss: 4.9327729207560465
Validation loss: 4.411027220517331
Epoch: 5| Step: 5
Training loss: 4.443470551493752
Validation loss: 4.390120919129112
Epoch: 5| Step: 6
Training loss: 4.99877437828856
Validation loss: 4.369946754905897
Epoch: 5| Step: 7
Training loss: 5.171627534322224
Validation loss: 4.35825683672598
Epoch: 5| Step: 8
Training loss: 4.211022653939562
Validation loss: 4.32150921337638
Epoch: 5| Step: 9
Training loss: 4.4857726361451356
Validation loss: 4.310372723091892
Epoch: 18| Step: 0
Training loss: 5.036102229734317
Validation loss: 4.303930880776112
Epoch: 5| Step: 1
Training loss: 4.132151790655869
Validation loss: 4.272555081591499
Epoch: 5| Step: 2
Training loss: 5.130096320722224
Validation loss: 4.248642565720986
Epoch: 5| Step: 3
Training loss: 4.666615463157581
Validation loss: 4.201843131326268
Epoch: 5| Step: 4
Training loss: 4.11691138483523
Validation loss: 4.210133991528461
Epoch: 5| Step: 5
Training loss: 4.925628296718261
Validation loss: 4.1772069337476845
Epoch: 5| Step: 6
Training loss: 5.090228214806149
Validation loss: 4.1659878664524985
Epoch: 5| Step: 7
Training loss: 4.619513479269895
Validation loss: 4.142048221749596
Epoch: 5| Step: 8
Training loss: 4.428934561436566
Validation loss: 4.113810463584874
Epoch: 5| Step: 9
Training loss: 4.334000878390728
Validation loss: 4.1033385994654825
Epoch: 19| Step: 0
Training loss: 4.824922456266461
Validation loss: 4.082711508059905
Epoch: 5| Step: 1
Training loss: 4.20686939321305
Validation loss: 4.062515659917886
Epoch: 5| Step: 2
Training loss: 4.134559882103677
Validation loss: 4.035544141814424
Epoch: 5| Step: 3
Training loss: 4.54761113765526
Validation loss: 4.018297617896387
Epoch: 5| Step: 4
Training loss: 4.231362710688401
Validation loss: 3.9532474274092793
Epoch: 5| Step: 5
Training loss: 5.049440469998492
Validation loss: 3.9673008528012317
Epoch: 5| Step: 6
Training loss: 4.695041947019999
Validation loss: 3.9345396764065463
Epoch: 5| Step: 7
Training loss: 4.228715668983485
Validation loss: 3.9015006285240994
Epoch: 5| Step: 8
Training loss: 4.55407082519943
Validation loss: 3.8998551125055725
Epoch: 5| Step: 9
Training loss: 3.957112348201843
Validation loss: 3.864454176162282
Epoch: 20| Step: 0
Training loss: 4.399837508235612
Validation loss: 3.843376810784817
Epoch: 5| Step: 1
Training loss: 4.453842801249522
Validation loss: 3.810269421262882
Epoch: 5| Step: 2
Training loss: 4.037553693573773
Validation loss: 3.7812485454003104
Epoch: 5| Step: 3
Training loss: 3.9298561621204477
Validation loss: 3.7810151824325198
Epoch: 5| Step: 4
Training loss: 4.158871390494755
Validation loss: 3.7535686255000345
Epoch: 5| Step: 5
Training loss: 4.97444296934085
Validation loss: 3.718195226472296
Epoch: 5| Step: 6
Training loss: 3.48815206905785
Validation loss: 3.6747916047749727
Epoch: 5| Step: 7
Training loss: 4.632894222574424
Validation loss: 3.6582948750058084
Epoch: 5| Step: 8
Training loss: 3.9303844281354574
Validation loss: 3.650305196748815
Epoch: 5| Step: 9
Training loss: 4.047540440584141
Validation loss: 3.6235424786539254
Epoch: 21| Step: 0
Training loss: 3.9805722508624233
Validation loss: 3.588413497684155
Epoch: 5| Step: 1
Training loss: 4.451275571960165
Validation loss: 3.5625361699284683
Epoch: 5| Step: 2
Training loss: 3.430803469315659
Validation loss: 3.5553383953560207
Epoch: 5| Step: 3
Training loss: 3.807784494352606
Validation loss: 3.4825769451178004
Epoch: 5| Step: 4
Training loss: 4.014373227956026
Validation loss: 3.4968520385141693
Epoch: 5| Step: 5
Training loss: 4.261600146579472
Validation loss: 3.4081523191420153
Epoch: 5| Step: 6
Training loss: 4.283459837909467
Validation loss: 3.427891086919693
Epoch: 5| Step: 7
Training loss: 3.906924502312844
Validation loss: 3.40020158749513
Epoch: 5| Step: 8
Training loss: 3.9129964933937793
Validation loss: 3.3878182683432008
Epoch: 5| Step: 9
Training loss: 3.6926498659542224
Validation loss: 3.3487624785756718
Epoch: 22| Step: 0
Training loss: 3.8507181909668065
Validation loss: 3.3165738493505317
Epoch: 5| Step: 1
Training loss: 3.6356459201934177
Validation loss: 3.279891205085917
Epoch: 5| Step: 2
Training loss: 4.013666172441204
Validation loss: 3.272385475422613
Epoch: 5| Step: 3
Training loss: 2.8999121685539286
Validation loss: 3.2567316116290232
Epoch: 5| Step: 4
Training loss: 3.7187288427953162
Validation loss: 3.2330425956402333
Epoch: 5| Step: 5
Training loss: 3.7124567716502868
Validation loss: 3.1924985669003036
Epoch: 5| Step: 6
Training loss: 3.833058941737014
Validation loss: 3.147603132216538
Epoch: 5| Step: 7
Training loss: 3.9989410429164467
Validation loss: 3.1309979375965415
Epoch: 5| Step: 8
Training loss: 3.8327186893345964
Validation loss: 3.1107842867655373
Epoch: 5| Step: 9
Training loss: 3.8171287329104895
Validation loss: 3.0721091261443143
Epoch: 23| Step: 0
Training loss: 3.2574749595634067
Validation loss: 3.061268033779029
Epoch: 5| Step: 1
Training loss: 3.4065197479110134
Validation loss: 3.0018849023407337
Epoch: 5| Step: 2
Training loss: 3.028490206305363
Validation loss: 3.012861940308297
Epoch: 5| Step: 3
Training loss: 3.8482005087783198
Validation loss: 2.9530049625204873
Epoch: 5| Step: 4
Training loss: 3.9045561513068927
Validation loss: 2.95791593130443
Epoch: 5| Step: 5
Training loss: 3.663183436244115
Validation loss: 2.943378566320359
Epoch: 5| Step: 6
Training loss: 3.195798655043697
Validation loss: 2.8873504180763683
Epoch: 5| Step: 7
Training loss: 3.3497104462703247
Validation loss: 2.880171292008785
Epoch: 5| Step: 8
Training loss: 3.4656191606532607
Validation loss: 2.8487969163306834
Epoch: 5| Step: 9
Training loss: 3.637183662633431
Validation loss: 2.8504489203960532
Epoch: 24| Step: 0
Training loss: 3.271240954096892
Validation loss: 2.773448898872238
Epoch: 5| Step: 1
Training loss: 3.6387169549005676
Validation loss: 2.780002268626539
Epoch: 5| Step: 2
Training loss: 3.274748837689873
Validation loss: 2.7590407668099526
Epoch: 5| Step: 3
Training loss: 3.660821909103323
Validation loss: 2.741878781583927
Epoch: 5| Step: 4
Training loss: 3.401639986009893
Validation loss: 2.689167978499632
Epoch: 5| Step: 5
Training loss: 3.1531920774676547
Validation loss: 2.6973096869004984
Epoch: 5| Step: 6
Training loss: 3.2642842876196294
Validation loss: 2.652660615586353
Epoch: 5| Step: 7
Training loss: 2.6711210559075194
Validation loss: 2.644451375736995
Epoch: 5| Step: 8
Training loss: 3.0439183684041695
Validation loss: 2.6176537604353367
Epoch: 5| Step: 9
Training loss: 3.1002378926212626
Validation loss: 2.5963583083511814
Epoch: 25| Step: 0
Training loss: 3.313418710812387
Validation loss: 2.586586996557472
Epoch: 5| Step: 1
Training loss: 3.041939675259034
Validation loss: 2.5813123486981184
Epoch: 5| Step: 2
Training loss: 3.149186795336826
Validation loss: 2.543328691235451
Epoch: 5| Step: 3
Training loss: 2.838858621149356
Validation loss: 2.528717066962271
Epoch: 5| Step: 4
Training loss: 3.046233437312717
Validation loss: 2.501531220025091
Epoch: 5| Step: 5
Training loss: 2.9626611207051163
Validation loss: 2.475844625715496
Epoch: 5| Step: 6
Training loss: 3.210751864596631
Validation loss: 2.4616155368997794
Epoch: 5| Step: 7
Training loss: 3.052332289678863
Validation loss: 2.4518748327323863
Epoch: 5| Step: 8
Training loss: 2.5835044455514926
Validation loss: 2.4285645411093144
Epoch: 5| Step: 9
Training loss: 3.2409259593854887
Validation loss: 2.409004864838616
Epoch: 26| Step: 0
Training loss: 2.5118119621482253
Validation loss: 2.4005275939738717
Epoch: 5| Step: 1
Training loss: 2.802922195361825
Validation loss: 2.386467508621061
Epoch: 5| Step: 2
Training loss: 2.359021394012451
Validation loss: 2.3898601245980076
Epoch: 5| Step: 3
Training loss: 3.1842726282018208
Validation loss: 2.3530120384165008
Epoch: 5| Step: 4
Training loss: 2.548592392116155
Validation loss: 2.3547780213575207
Epoch: 5| Step: 5
Training loss: 3.26596987422731
Validation loss: 2.3361736325558553
Epoch: 5| Step: 6
Training loss: 3.177974905185036
Validation loss: 2.3241470181565025
Epoch: 5| Step: 7
Training loss: 3.2217027768004076
Validation loss: 2.295564301248341
Epoch: 5| Step: 8
Training loss: 3.072835492285014
Validation loss: 2.297372665716261
Epoch: 5| Step: 9
Training loss: 2.7358378829554146
Validation loss: 2.2624139937844006
Epoch: 27| Step: 0
Training loss: 3.108500755512452
Validation loss: 2.2852596206980267
Epoch: 5| Step: 1
Training loss: 2.9208137094343636
Validation loss: 2.296651433011357
Epoch: 5| Step: 2
Training loss: 2.8897705464864045
Validation loss: 2.2874115522152927
Epoch: 5| Step: 3
Training loss: 3.093345384437282
Validation loss: 2.259315621666294
Epoch: 5| Step: 4
Training loss: 2.5975002155909666
Validation loss: 2.2608132901635623
Epoch: 5| Step: 5
Training loss: 2.432013964813695
Validation loss: 2.2569346144076006
Epoch: 5| Step: 6
Training loss: 2.5436101476666955
Validation loss: 2.2494431162226696
Epoch: 5| Step: 7
Training loss: 2.86159708366896
Validation loss: 2.275353340624287
Epoch: 5| Step: 8
Training loss: 2.7387574743589354
Validation loss: 2.2555331009947746
Epoch: 5| Step: 9
Training loss: 2.81021279476186
Validation loss: 2.2332667791990035
Epoch: 28| Step: 0
Training loss: 2.6177589817412175
Validation loss: 2.248718045621761
Epoch: 5| Step: 1
Training loss: 2.6284409631314682
Validation loss: 2.2362435494218693
Epoch: 5| Step: 2
Training loss: 2.6147276292677883
Validation loss: 2.230568418759259
Epoch: 5| Step: 3
Training loss: 2.5683400664673446
Validation loss: 2.2444734913829856
Epoch: 5| Step: 4
Training loss: 3.040246571027831
Validation loss: 2.2318062479300322
Epoch: 5| Step: 5
Training loss: 2.685439983668186
Validation loss: 2.2268274331683404
Epoch: 5| Step: 6
Training loss: 2.4913540107080614
Validation loss: 2.2268947995077415
Epoch: 5| Step: 7
Training loss: 2.9937767011690104
Validation loss: 2.23922202084975
Epoch: 5| Step: 8
Training loss: 2.948297662456305
Validation loss: 2.2319497427954973
Epoch: 5| Step: 9
Training loss: 2.8581091575091726
Validation loss: 2.2360919988401022
Epoch: 29| Step: 0
Training loss: 2.4828366489088234
Validation loss: 2.235303427256737
Epoch: 5| Step: 1
Training loss: 3.3292744402256544
Validation loss: 2.223867329546835
Epoch: 5| Step: 2
Training loss: 2.7061750370770232
Validation loss: 2.256887827482426
Epoch: 5| Step: 3
Training loss: 2.1025440518983993
Validation loss: 2.2594593278828707
Epoch: 5| Step: 4
Training loss: 2.5587998634776046
Validation loss: 2.250050530932394
Epoch: 5| Step: 5
Training loss: 2.521676975875459
Validation loss: 2.197802632534683
Epoch: 5| Step: 6
Training loss: 3.251272392621158
Validation loss: 2.2454082207926023
Epoch: 5| Step: 7
Training loss: 2.6324539619615237
Validation loss: 2.236060939465152
Epoch: 5| Step: 8
Training loss: 3.049564680707935
Validation loss: 2.2359194998663243
Epoch: 5| Step: 9
Training loss: 2.18886458205375
Validation loss: 2.259935545059909
Epoch: 30| Step: 0
Training loss: 2.4117279121761195
Validation loss: 2.206775972698917
Epoch: 5| Step: 1
Training loss: 2.65428681473443
Validation loss: 2.245144960386223
Epoch: 5| Step: 2
Training loss: 2.3504904904736126
Validation loss: 2.240306352720667
Epoch: 5| Step: 3
Training loss: 2.771135003057353
Validation loss: 2.2337585356623877
Epoch: 5| Step: 4
Training loss: 2.7164327458342092
Validation loss: 2.271120455973835
Epoch: 5| Step: 5
Training loss: 2.775013134899499
Validation loss: 2.230615550578365
Epoch: 5| Step: 6
Training loss: 2.74706840311656
Validation loss: 2.2582523181833993
Epoch: 5| Step: 7
Training loss: 2.9825075708054976
Validation loss: 2.246678045691213
Epoch: 5| Step: 8
Training loss: 2.707404040804999
Validation loss: 2.249047372010264
Epoch: 5| Step: 9
Training loss: 2.885016697086563
Validation loss: 2.2370698839974197
Epoch: 31| Step: 0
Training loss: 2.7205604576063385
Validation loss: 2.2414133691656164
Epoch: 5| Step: 1
Training loss: 2.7847714365613454
Validation loss: 2.2436281211735887
Epoch: 5| Step: 2
Training loss: 2.9373131550554525
Validation loss: 2.258430467714699
Epoch: 5| Step: 3
Training loss: 2.709904630608728
Validation loss: 2.2532753728686536
Epoch: 5| Step: 4
Training loss: 2.757056718958897
Validation loss: 2.266652250101817
Epoch: 5| Step: 5
Training loss: 2.3556172338344035
Validation loss: 2.2516802917885794
Epoch: 5| Step: 6
Training loss: 3.0253732876561013
Validation loss: 2.2477362701977968
Epoch: 5| Step: 7
Training loss: 2.4347630320081852
Validation loss: 2.267840369288945
Epoch: 5| Step: 8
Training loss: 2.648478099770621
Validation loss: 2.2719829896458528
Epoch: 5| Step: 9
Training loss: 2.6695211649797157
Validation loss: 2.2576890560008613
Epoch: 32| Step: 0
Training loss: 2.645378754580899
Validation loss: 2.2574629187599595
Epoch: 5| Step: 1
Training loss: 2.340286849771858
Validation loss: 2.237883468480135
Epoch: 5| Step: 2
Training loss: 2.483958851250767
Validation loss: 2.251530840603642
Epoch: 5| Step: 3
Training loss: 2.8528864047343125
Validation loss: 2.2674926361270997
Epoch: 5| Step: 4
Training loss: 2.630257563869919
Validation loss: 2.230333079714669
Epoch: 5| Step: 5
Training loss: 2.56512075247784
Validation loss: 2.2393928067476634
Epoch: 5| Step: 6
Training loss: 2.9821655722895932
Validation loss: 2.2531206306228126
Epoch: 5| Step: 7
Training loss: 3.013625040141583
Validation loss: 2.270520404630247
Epoch: 5| Step: 8
Training loss: 2.7802004601910335
Validation loss: 2.268922950004607
Epoch: 5| Step: 9
Training loss: 2.663096591213334
Validation loss: 2.279440656030521
Epoch: 33| Step: 0
Training loss: 2.824831483253994
Validation loss: 2.2648732176526725
Epoch: 5| Step: 1
Training loss: 2.7012051506502903
Validation loss: 2.261462071064722
Epoch: 5| Step: 2
Training loss: 2.73804040739394
Validation loss: 2.2624099851395756
Epoch: 5| Step: 3
Training loss: 2.2811956529806325
Validation loss: 2.243348810188172
Epoch: 5| Step: 4
Training loss: 3.105503144463621
Validation loss: 2.2649983655026396
Epoch: 5| Step: 5
Training loss: 2.149463977086833
Validation loss: 2.268311431964324
Epoch: 5| Step: 6
Training loss: 2.8161573577827546
Validation loss: 2.2597341487253417
Epoch: 5| Step: 7
Training loss: 2.317878242579691
Validation loss: 2.228150701042831
Epoch: 5| Step: 8
Training loss: 2.7703640953978117
Validation loss: 2.234497009596569
Epoch: 5| Step: 9
Training loss: 3.110471599184911
Validation loss: 2.283770466325191
Epoch: 34| Step: 0
Training loss: 2.522929326431764
Validation loss: 2.2787775324149004
Epoch: 5| Step: 1
Training loss: 2.968715306129514
Validation loss: 2.261732462890848
Epoch: 5| Step: 2
Training loss: 2.7245598463800254
Validation loss: 2.2631296196148023
Epoch: 5| Step: 3
Training loss: 2.327622941946459
Validation loss: 2.280362636920817
Epoch: 5| Step: 4
Training loss: 2.463361823605908
Validation loss: 2.2714329052472677
Epoch: 5| Step: 5
Training loss: 2.935705245384959
Validation loss: 2.2678070842044735
Epoch: 5| Step: 6
Training loss: 3.2061079324698345
Validation loss: 2.254078074929672
Epoch: 5| Step: 7
Training loss: 2.5699962664922174
Validation loss: 2.2656208657860373
Epoch: 5| Step: 8
Training loss: 2.379725924186053
Validation loss: 2.2571580103263695
Epoch: 5| Step: 9
Training loss: 2.8112800495446506
Validation loss: 2.233697687565255
Epoch: 35| Step: 0
Training loss: 2.580882868855436
Validation loss: 2.2625806595713205
Epoch: 5| Step: 1
Training loss: 2.585810632273091
Validation loss: 2.2389399747100502
Epoch: 5| Step: 2
Training loss: 3.5391476517763736
Validation loss: 2.2647115532288113
Epoch: 5| Step: 3
Training loss: 2.6545065150724367
Validation loss: 2.270924390659552
Epoch: 5| Step: 4
Training loss: 2.8386261440387175
Validation loss: 2.277421218455888
Epoch: 5| Step: 5
Training loss: 2.5663371316320385
Validation loss: 2.2573064693049374
Epoch: 5| Step: 6
Training loss: 2.6743612935142234
Validation loss: 2.2434382267343276
Epoch: 5| Step: 7
Training loss: 2.288898865771643
Validation loss: 2.2477387353097957
Epoch: 5| Step: 8
Training loss: 2.4495950558827424
Validation loss: 2.2702579081116347
Epoch: 5| Step: 9
Training loss: 2.618016809052549
Validation loss: 2.262937721433217
Epoch: 36| Step: 0
Training loss: 3.005225240482436
Validation loss: 2.242195731014336
Epoch: 5| Step: 1
Training loss: 2.7535788916415482
Validation loss: 2.260445560612488
Epoch: 5| Step: 2
Training loss: 2.9045309910052537
Validation loss: 2.267300292321005
Epoch: 5| Step: 3
Training loss: 2.3451442386213612
Validation loss: 2.2497268559545196
Epoch: 5| Step: 4
Training loss: 2.6332228705822125
Validation loss: 2.240073481354663
Epoch: 5| Step: 5
Training loss: 2.5620025524093935
Validation loss: 2.2387266102947416
Epoch: 5| Step: 6
Training loss: 2.468107115660704
Validation loss: 2.2360496702652983
Epoch: 5| Step: 7
Training loss: 2.605241070683662
Validation loss: 2.2214743593250117
Epoch: 5| Step: 8
Training loss: 2.8892974279355865
Validation loss: 2.2536324804261776
Epoch: 5| Step: 9
Training loss: 2.6522315651900805
Validation loss: 2.241440648941859
Epoch: 37| Step: 0
Training loss: 2.7494870487732928
Validation loss: 2.2392159146668473
Epoch: 5| Step: 1
Training loss: 2.1850753425510323
Validation loss: 2.251466468985229
Epoch: 5| Step: 2
Training loss: 2.172710450122897
Validation loss: 2.2536280462894327
Epoch: 5| Step: 3
Training loss: 2.8031694559678066
Validation loss: 2.2394484150375673
Epoch: 5| Step: 4
Training loss: 2.7395792237070875
Validation loss: 2.2571532328313197
Epoch: 5| Step: 5
Training loss: 2.612470241541414
Validation loss: 2.2516339708290443
Epoch: 5| Step: 6
Training loss: 2.7424225883025453
Validation loss: 2.238843124582983
Epoch: 5| Step: 7
Training loss: 2.5513416276445904
Validation loss: 2.23532087304625
Epoch: 5| Step: 8
Training loss: 2.8020200663140096
Validation loss: 2.2520701531108496
Epoch: 5| Step: 9
Training loss: 3.3739789195236014
Validation loss: 2.2290459434998793
Epoch: 38| Step: 0
Training loss: 2.686474892924049
Validation loss: 2.233444005783288
Epoch: 5| Step: 1
Training loss: 2.442648121648185
Validation loss: 2.2157896658741962
Epoch: 5| Step: 2
Training loss: 2.951879652521625
Validation loss: 2.239847706346404
Epoch: 5| Step: 3
Training loss: 2.2081079068077014
Validation loss: 2.2483842173778967
Epoch: 5| Step: 4
Training loss: 2.9406299554537814
Validation loss: 2.248955655951994
Epoch: 5| Step: 5
Training loss: 2.391915764502399
Validation loss: 2.2535528291731888
Epoch: 5| Step: 6
Training loss: 3.0814256351082285
Validation loss: 2.26291921608193
Epoch: 5| Step: 7
Training loss: 2.3446485704243023
Validation loss: 2.2353662225551694
Epoch: 5| Step: 8
Training loss: 2.974191597488187
Validation loss: 2.2483611371498675
Epoch: 5| Step: 9
Training loss: 2.684595357001677
Validation loss: 2.242513330114318
Epoch: 39| Step: 0
Training loss: 2.7288825976823543
Validation loss: 2.2387643145350338
Epoch: 5| Step: 1
Training loss: 2.153413316443917
Validation loss: 2.221446651624514
Epoch: 5| Step: 2
Training loss: 2.917198314350436
Validation loss: 2.2365858998470487
Epoch: 5| Step: 3
Training loss: 3.18922437512135
Validation loss: 2.244721260470507
Epoch: 5| Step: 4
Training loss: 2.6911771590974736
Validation loss: 2.2246378966968456
Epoch: 5| Step: 5
Training loss: 2.9500879888828533
Validation loss: 2.23966708679125
Epoch: 5| Step: 6
Training loss: 2.5907126417623974
Validation loss: 2.2380332777283525
Epoch: 5| Step: 7
Training loss: 2.563195762150484
Validation loss: 2.2409687317744984
Epoch: 5| Step: 8
Training loss: 2.6983700424094366
Validation loss: 2.2405512557843066
Epoch: 5| Step: 9
Training loss: 2.1968560816247344
Validation loss: 2.242918007220321
Epoch: 40| Step: 0
Training loss: 2.6903080132139396
Validation loss: 2.211346209967591
Epoch: 5| Step: 1
Training loss: 2.8903503287470507
Validation loss: 2.2501291903467133
Epoch: 5| Step: 2
Training loss: 2.1741998976651904
Validation loss: 2.2353635628417776
Epoch: 5| Step: 3
Training loss: 2.423400595289905
Validation loss: 2.258403789329166
Epoch: 5| Step: 4
Training loss: 3.3010664054896184
Validation loss: 2.240124226046747
Epoch: 5| Step: 5
Training loss: 2.5914151816894146
Validation loss: 2.2328921570841076
Epoch: 5| Step: 6
Training loss: 2.3293468162278876
Validation loss: 2.254361914920946
Epoch: 5| Step: 7
Training loss: 3.19997522821375
Validation loss: 2.2467046890417777
Epoch: 5| Step: 8
Training loss: 2.793639117265702
Validation loss: 2.2528177942301464
Epoch: 5| Step: 9
Training loss: 2.258926064195324
Validation loss: 2.273818275671481
Epoch: 41| Step: 0
Training loss: 2.6873818305006965
Validation loss: 2.222263905046432
Epoch: 5| Step: 1
Training loss: 3.0978769846676917
Validation loss: 2.2501554835184834
Epoch: 5| Step: 2
Training loss: 2.030726438685037
Validation loss: 2.2565146148671196
Epoch: 5| Step: 3
Training loss: 2.597181050138023
Validation loss: 2.2367669402028896
Epoch: 5| Step: 4
Training loss: 2.5626978914096563
Validation loss: 2.236605107747452
Epoch: 5| Step: 5
Training loss: 2.865314422716612
Validation loss: 2.2327381815234424
Epoch: 5| Step: 6
Training loss: 2.909042165629631
Validation loss: 2.21868651748432
Epoch: 5| Step: 7
Training loss: 2.293740761553794
Validation loss: 2.2534608273033925
Epoch: 5| Step: 8
Training loss: 3.0351691325539023
Validation loss: 2.239926378336577
Epoch: 5| Step: 9
Training loss: 2.537132961994621
Validation loss: 2.244866067893353
Epoch: 42| Step: 0
Training loss: 2.5719955175072986
Validation loss: 2.2298031227986996
Epoch: 5| Step: 1
Training loss: 2.494971176623124
Validation loss: 2.2308040152855635
Epoch: 5| Step: 2
Training loss: 3.1348833578942834
Validation loss: 2.2381031015197603
Epoch: 5| Step: 3
Training loss: 2.7515454717972445
Validation loss: 2.2720072175813737
Epoch: 5| Step: 4
Training loss: 2.748182476415192
Validation loss: 2.221630256095492
Epoch: 5| Step: 5
Training loss: 2.563749334445906
Validation loss: 2.20963676333804
Epoch: 5| Step: 6
Training loss: 3.016963681375089
Validation loss: 2.254579185414976
Epoch: 5| Step: 7
Training loss: 2.487215062216485
Validation loss: 2.2364491279367655
Epoch: 5| Step: 8
Training loss: 2.580431282309639
Validation loss: 2.2336391727485347
Epoch: 5| Step: 9
Training loss: 2.3600412400731883
Validation loss: 2.2251794027514435
Epoch: 43| Step: 0
Training loss: 2.445958841234892
Validation loss: 2.2376751972845526
Epoch: 5| Step: 1
Training loss: 2.6557613147665853
Validation loss: 2.2075632830998737
Epoch: 5| Step: 2
Training loss: 2.968852633659708
Validation loss: 2.242307991885602
Epoch: 5| Step: 3
Training loss: 2.6919061780567244
Validation loss: 2.253763908124782
Epoch: 5| Step: 4
Training loss: 2.4089461245468398
Validation loss: 2.239710039468458
Epoch: 5| Step: 5
Training loss: 2.8922559930985114
Validation loss: 2.2329226386666594
Epoch: 5| Step: 6
Training loss: 3.0599195547063673
Validation loss: 2.2466170820423335
Epoch: 5| Step: 7
Training loss: 2.3317293262401595
Validation loss: 2.213398535636879
Epoch: 5| Step: 8
Training loss: 2.6606753118774895
Validation loss: 2.215028493696123
Epoch: 5| Step: 9
Training loss: 2.4886342132166357
Validation loss: 2.2296828751669726
Epoch: 44| Step: 0
Training loss: 2.575421019273096
Validation loss: 2.2254826987276943
Epoch: 5| Step: 1
Training loss: 2.541620931578678
Validation loss: 2.2375626828508315
Epoch: 5| Step: 2
Training loss: 2.71698352822487
Validation loss: 2.2483156198174656
Epoch: 5| Step: 3
Training loss: 3.2376085417826874
Validation loss: 2.237883290909735
Epoch: 5| Step: 4
Training loss: 2.7744590919436263
Validation loss: 2.2396062595969988
Epoch: 5| Step: 5
Training loss: 2.380362229550803
Validation loss: 2.2460152893796463
Epoch: 5| Step: 6
Training loss: 2.3844089850607277
Validation loss: 2.2036140782602702
Epoch: 5| Step: 7
Training loss: 3.1995195147274957
Validation loss: 2.2506130342003936
Epoch: 5| Step: 8
Training loss: 2.506878164817697
Validation loss: 2.2377267522687885
Epoch: 5| Step: 9
Training loss: 2.3509044043196465
Validation loss: 2.222804284780342
Epoch: 45| Step: 0
Training loss: 2.9911537077756534
Validation loss: 2.2421448383061846
Epoch: 5| Step: 1
Training loss: 2.739908254716332
Validation loss: 2.214802039922412
Epoch: 5| Step: 2
Training loss: 2.6286368834301173
Validation loss: 2.2444677562156623
Epoch: 5| Step: 3
Training loss: 3.0629894877473514
Validation loss: 2.251602016393587
Epoch: 5| Step: 4
Training loss: 2.0473641546362615
Validation loss: 2.2314613317206096
Epoch: 5| Step: 5
Training loss: 2.4113420385629487
Validation loss: 2.223106611678015
Epoch: 5| Step: 6
Training loss: 2.8292975761078796
Validation loss: 2.209345187630986
Epoch: 5| Step: 7
Training loss: 2.5901103393145664
Validation loss: 2.222132206382181
Epoch: 5| Step: 8
Training loss: 2.7332133414129482
Validation loss: 2.2164191161211786
Epoch: 5| Step: 9
Training loss: 2.529893582333721
Validation loss: 2.2467489199187893
Epoch: 46| Step: 0
Training loss: 2.89223472519563
Validation loss: 2.2649304606900156
Epoch: 5| Step: 1
Training loss: 2.73466725558692
Validation loss: 2.1972249074481973
Epoch: 5| Step: 2
Training loss: 2.6675694447481044
Validation loss: 2.2575691669391578
Epoch: 5| Step: 3
Training loss: 2.6037859422214713
Validation loss: 2.2266354478688597
Epoch: 5| Step: 4
Training loss: 2.8089903231841484
Validation loss: 2.2026573837457315
Epoch: 5| Step: 5
Training loss: 2.9904332210073172
Validation loss: 2.217931509545934
Epoch: 5| Step: 6
Training loss: 2.16049451059334
Validation loss: 2.242270107169591
Epoch: 5| Step: 7
Training loss: 2.6383763055279914
Validation loss: 2.2221131414936575
Epoch: 5| Step: 8
Training loss: 2.771905352266088
Validation loss: 2.224710227995178
Epoch: 5| Step: 9
Training loss: 2.4150353110438916
Validation loss: 2.248274447337376
Epoch: 47| Step: 0
Training loss: 2.509002118179321
Validation loss: 2.240002752053074
Epoch: 5| Step: 1
Training loss: 2.2674871750104058
Validation loss: 2.2504105084497597
Epoch: 5| Step: 2
Training loss: 2.7531057506498864
Validation loss: 2.249637598311636
Epoch: 5| Step: 3
Training loss: 2.7676061226364803
Validation loss: 2.233596329003234
Epoch: 5| Step: 4
Training loss: 2.6204815077031847
Validation loss: 2.2238597489237417
Epoch: 5| Step: 5
Training loss: 2.6377405969884022
Validation loss: 2.197348407836637
Epoch: 5| Step: 6
Training loss: 2.3967338749247724
Validation loss: 2.2096814349045215
Epoch: 5| Step: 7
Training loss: 2.840364893722669
Validation loss: 2.231136065908101
Epoch: 5| Step: 8
Training loss: 2.793386660167748
Validation loss: 2.2051483507859038
Epoch: 5| Step: 9
Training loss: 3.0663707949781482
Validation loss: 2.2354132359910825
Epoch: 48| Step: 0
Training loss: 2.7301098501720307
Validation loss: 2.213901250215875
Epoch: 5| Step: 1
Training loss: 2.8961524696046763
Validation loss: 2.240252387899672
Epoch: 5| Step: 2
Training loss: 3.100916720790377
Validation loss: 2.222837867695479
Epoch: 5| Step: 3
Training loss: 2.6829666226728324
Validation loss: 2.220964607273696
Epoch: 5| Step: 4
Training loss: 2.354897298497008
Validation loss: 2.215180824991143
Epoch: 5| Step: 5
Training loss: 1.9333674751204852
Validation loss: 2.2283965739630527
Epoch: 5| Step: 6
Training loss: 2.6438461610877693
Validation loss: 2.2304913915600966
Epoch: 5| Step: 7
Training loss: 2.528023912745262
Validation loss: 2.2014922401508183
Epoch: 5| Step: 8
Training loss: 2.932272297245826
Validation loss: 2.228180898128941
Epoch: 5| Step: 9
Training loss: 2.6411775992671074
Validation loss: 2.220542585227624
Epoch: 49| Step: 0
Training loss: 2.1261161789895864
Validation loss: 2.228548277418139
Epoch: 5| Step: 1
Training loss: 3.083170981042058
Validation loss: 2.2423631418818406
Epoch: 5| Step: 2
Training loss: 2.662350817875324
Validation loss: 2.2449626463528136
Epoch: 5| Step: 3
Training loss: 2.7168167080624928
Validation loss: 2.2451925918896856
Epoch: 5| Step: 4
Training loss: 2.834157674211165
Validation loss: 2.237542328551886
Epoch: 5| Step: 5
Training loss: 2.2894435734623633
Validation loss: 2.2336216560678914
Epoch: 5| Step: 6
Training loss: 2.44466062394224
Validation loss: 2.2183637095320172
Epoch: 5| Step: 7
Training loss: 2.4333723282846633
Validation loss: 2.2181275534669638
Epoch: 5| Step: 8
Training loss: 2.6970180256955114
Validation loss: 2.2230949879134934
Epoch: 5| Step: 9
Training loss: 3.3034408779197384
Validation loss: 2.230419126298926
Epoch: 50| Step: 0
Training loss: 2.957756487703435
Validation loss: 2.2294389799638705
Epoch: 5| Step: 1
Training loss: 2.8796447055263465
Validation loss: 2.2092167849867046
Epoch: 5| Step: 2
Training loss: 2.119301054195224
Validation loss: 2.2351239378469194
Epoch: 5| Step: 3
Training loss: 2.4012633336504723
Validation loss: 2.2347470367958513
Epoch: 5| Step: 4
Training loss: 3.0200567540779035
Validation loss: 2.2249347879147967
Epoch: 5| Step: 5
Training loss: 2.258426463985755
Validation loss: 2.230497901846055
Epoch: 5| Step: 6
Training loss: 2.8669514987703
Validation loss: 2.2287704634235137
Epoch: 5| Step: 7
Training loss: 2.371440931163232
Validation loss: 2.2139075142635836
Epoch: 5| Step: 8
Training loss: 2.6907200706778807
Validation loss: 2.218748815944029
Epoch: 5| Step: 9
Training loss: 2.9061146366220596
Validation loss: 2.205668912685046
Epoch: 51| Step: 0
Training loss: 2.6419972121680986
Validation loss: 2.2252774461143714
Epoch: 5| Step: 1
Training loss: 2.442124406093524
Validation loss: 2.22687117127342
Epoch: 5| Step: 2
Training loss: 2.548497250883832
Validation loss: 2.2260736236209953
Epoch: 5| Step: 3
Training loss: 2.6082062987896295
Validation loss: 2.214976207158406
Epoch: 5| Step: 4
Training loss: 2.5842223227259584
Validation loss: 2.212391181862437
Epoch: 5| Step: 5
Training loss: 2.726005081866111
Validation loss: 2.213352068693629
Epoch: 5| Step: 6
Training loss: 2.96332721347699
Validation loss: 2.2116764710224985
Epoch: 5| Step: 7
Training loss: 2.719651785187236
Validation loss: 2.19846983652176
Epoch: 5| Step: 8
Training loss: 2.8342507130081156
Validation loss: 2.220082357052158
Epoch: 5| Step: 9
Training loss: 2.397178095586652
Validation loss: 2.210381202548822
Epoch: 52| Step: 0
Training loss: 2.214520573795858
Validation loss: 2.231965838312034
Epoch: 5| Step: 1
Training loss: 2.9571760537737175
Validation loss: 2.2207948585268116
Epoch: 5| Step: 2
Training loss: 3.1787979418776597
Validation loss: 2.221809482814632
Epoch: 5| Step: 3
Training loss: 2.693286963935514
Validation loss: 2.210988047500357
Epoch: 5| Step: 4
Training loss: 2.0795611244971903
Validation loss: 2.221069122111607
Epoch: 5| Step: 5
Training loss: 2.2549339873469645
Validation loss: 2.228028489029034
Epoch: 5| Step: 6
Training loss: 2.6540136459850676
Validation loss: 2.2036456558538995
Epoch: 5| Step: 7
Training loss: 2.452464604020243
Validation loss: 2.210481170393532
Epoch: 5| Step: 8
Training loss: 2.9148776062384827
Validation loss: 2.233748675113622
Epoch: 5| Step: 9
Training loss: 2.9441153524335726
Validation loss: 2.223972307409823
Epoch: 53| Step: 0
Training loss: 2.760558320255609
Validation loss: 2.2255169334340636
Epoch: 5| Step: 1
Training loss: 2.7262497861950425
Validation loss: 2.2155111729814805
Epoch: 5| Step: 2
Training loss: 2.54348069998526
Validation loss: 2.2224060740084894
Epoch: 5| Step: 3
Training loss: 2.8097266192508403
Validation loss: 2.241617840651504
Epoch: 5| Step: 4
Training loss: 3.101016364070718
Validation loss: 2.2134554835160154
Epoch: 5| Step: 5
Training loss: 2.3933425118244673
Validation loss: 2.2036537407100303
Epoch: 5| Step: 6
Training loss: 2.450407041096075
Validation loss: 2.209106817783919
Epoch: 5| Step: 7
Training loss: 2.8063961339338896
Validation loss: 2.178411762999626
Epoch: 5| Step: 8
Training loss: 2.2372139987689694
Validation loss: 2.2310680267632463
Epoch: 5| Step: 9
Training loss: 2.5832628322538436
Validation loss: 2.2413753237722456
Epoch: 54| Step: 0
Training loss: 2.9070292422854864
Validation loss: 2.182452718156696
Epoch: 5| Step: 1
Training loss: 2.3007630119183764
Validation loss: 2.186659936645644
Epoch: 5| Step: 2
Training loss: 2.9054462593030768
Validation loss: 2.2317322890419837
Epoch: 5| Step: 3
Training loss: 2.8260819447833376
Validation loss: 2.232207706354169
Epoch: 5| Step: 4
Training loss: 2.4801947975563703
Validation loss: 2.2397099962218694
Epoch: 5| Step: 5
Training loss: 2.3895963562596947
Validation loss: 2.215302744866341
Epoch: 5| Step: 6
Training loss: 2.656203774442677
Validation loss: 2.2216793591170365
Epoch: 5| Step: 7
Training loss: 2.4219271746522124
Validation loss: 2.2166271889562594
Epoch: 5| Step: 8
Training loss: 3.0183185150552276
Validation loss: 2.2222235736277853
Epoch: 5| Step: 9
Training loss: 2.392610112190513
Validation loss: 2.219010731399839
Epoch: 55| Step: 0
Training loss: 2.296928768436877
Validation loss: 2.204705672119536
Epoch: 5| Step: 1
Training loss: 2.5534060002569974
Validation loss: 2.17023543163304
Epoch: 5| Step: 2
Training loss: 2.7968758524461865
Validation loss: 2.211103578519963
Epoch: 5| Step: 3
Training loss: 2.7531411697657604
Validation loss: 2.2163942099126137
Epoch: 5| Step: 4
Training loss: 3.164912055603149
Validation loss: 2.202013763422946
Epoch: 5| Step: 5
Training loss: 2.711249605621126
Validation loss: 2.232968930889954
Epoch: 5| Step: 6
Training loss: 2.406384055626834
Validation loss: 2.195917173118003
Epoch: 5| Step: 7
Training loss: 2.7142129508282595
Validation loss: 2.206803502626203
Epoch: 5| Step: 8
Training loss: 2.4729301698654003
Validation loss: 2.2225558142953643
Epoch: 5| Step: 9
Training loss: 2.508017653395536
Validation loss: 2.2175823520351035
Epoch: 56| Step: 0
Training loss: 2.9143566975109874
Validation loss: 2.2253323133498766
Epoch: 5| Step: 1
Training loss: 2.72599563608359
Validation loss: 2.2086144791412354
Epoch: 5| Step: 2
Training loss: 2.25593821730459
Validation loss: 2.2332587729943083
Epoch: 5| Step: 3
Training loss: 2.709477451943742
Validation loss: 2.210414638017008
Epoch: 5| Step: 4
Training loss: 3.2456395167674943
Validation loss: 2.177732391168417
Epoch: 5| Step: 5
Training loss: 2.3341104257933822
Validation loss: 2.223157604740799
Epoch: 5| Step: 6
Training loss: 2.5355043804090993
Validation loss: 2.2103487042939056
Epoch: 5| Step: 7
Training loss: 2.592892056785174
Validation loss: 2.235802293659899
Epoch: 5| Step: 8
Training loss: 2.7059757437284935
Validation loss: 2.224408068047872
Epoch: 5| Step: 9
Training loss: 2.4175182902799084
Validation loss: 2.2200875008462915
Epoch: 57| Step: 0
Training loss: 2.433598256604475
Validation loss: 2.185154504732531
Epoch: 5| Step: 1
Training loss: 2.839299502686286
Validation loss: 2.2029747707417306
Epoch: 5| Step: 2
Training loss: 2.7476635457479732
Validation loss: 2.2118111533704563
Epoch: 5| Step: 3
Training loss: 1.982024354964049
Validation loss: 2.2293718793250017
Epoch: 5| Step: 4
Training loss: 2.657219205072964
Validation loss: 2.1830218827922336
Epoch: 5| Step: 5
Training loss: 2.6875970512431873
Validation loss: 2.2199038196302388
Epoch: 5| Step: 6
Training loss: 2.560406643936078
Validation loss: 2.211484595167606
Epoch: 5| Step: 7
Training loss: 3.0192514070275585
Validation loss: 2.220225594300868
Epoch: 5| Step: 8
Training loss: 2.907451750337741
Validation loss: 2.226660020887971
Epoch: 5| Step: 9
Training loss: 2.4883190014429206
Validation loss: 2.224032733385761
Epoch: 58| Step: 0
Training loss: 2.9182628805071853
Validation loss: 2.20766151451502
Epoch: 5| Step: 1
Training loss: 2.8842475441393765
Validation loss: 2.215199521289598
Epoch: 5| Step: 2
Training loss: 2.099587799671124
Validation loss: 2.2332078918205904
Epoch: 5| Step: 3
Training loss: 2.4255009241961476
Validation loss: 2.2151765790809486
Epoch: 5| Step: 4
Training loss: 2.6943304511882347
Validation loss: 2.208393069275176
Epoch: 5| Step: 5
Training loss: 2.0621558393535704
Validation loss: 2.213959246258781
Epoch: 5| Step: 6
Training loss: 2.8026361215628612
Validation loss: 2.1895182773652753
Epoch: 5| Step: 7
Training loss: 3.192742916415643
Validation loss: 2.208184731938809
Epoch: 5| Step: 8
Training loss: 2.617907524702094
Validation loss: 2.215259408755839
Epoch: 5| Step: 9
Training loss: 2.650404927967809
Validation loss: 2.1941955099029493
Epoch: 59| Step: 0
Training loss: 2.6890644576637994
Validation loss: 2.2276247029750893
Epoch: 5| Step: 1
Training loss: 2.51806020449292
Validation loss: 2.2021055755541528
Epoch: 5| Step: 2
Training loss: 2.857087768296079
Validation loss: 2.217164429942101
Epoch: 5| Step: 3
Training loss: 2.7130414290563953
Validation loss: 2.2253287008487024
Epoch: 5| Step: 4
Training loss: 2.7495065593179926
Validation loss: 2.21642128138662
Epoch: 5| Step: 5
Training loss: 2.9497828064183818
Validation loss: 2.214908346632477
Epoch: 5| Step: 6
Training loss: 2.592371470871229
Validation loss: 2.21053734832306
Epoch: 5| Step: 7
Training loss: 2.7468715559207646
Validation loss: 2.2119265356475943
Epoch: 5| Step: 8
Training loss: 1.8756070743709674
Validation loss: 2.1813264695587167
Epoch: 5| Step: 9
Training loss: 2.5530933691000754
Validation loss: 2.2152859853429634
Epoch: 60| Step: 0
Training loss: 2.2066276248731946
Validation loss: 2.225418792774091
Epoch: 5| Step: 1
Training loss: 2.981240588799103
Validation loss: 2.2071729519066934
Epoch: 5| Step: 2
Training loss: 2.536313584810519
Validation loss: 2.2009760480315137
Epoch: 5| Step: 3
Training loss: 2.002559930902311
Validation loss: 2.207340971422946
Epoch: 5| Step: 4
Training loss: 2.504928594397654
Validation loss: 2.21344460722883
Epoch: 5| Step: 5
Training loss: 2.4719692438922096
Validation loss: 2.191784315890469
Epoch: 5| Step: 6
Training loss: 2.852752687995359
Validation loss: 2.192021080252377
Epoch: 5| Step: 7
Training loss: 2.673379218103302
Validation loss: 2.2130056789618386
Epoch: 5| Step: 8
Training loss: 3.1453618249943576
Validation loss: 2.2166551609766207
Epoch: 5| Step: 9
Training loss: 2.8310754044279074
Validation loss: 2.1913187477150267
Epoch: 61| Step: 0
Training loss: 3.376140825525395
Validation loss: 2.193485620268591
Epoch: 5| Step: 1
Training loss: 2.457871625398877
Validation loss: 2.1890508761372174
Epoch: 5| Step: 2
Training loss: 1.7805004215813094
Validation loss: 2.1866930786570067
Epoch: 5| Step: 3
Training loss: 2.7045081684640135
Validation loss: 2.2113104457677424
Epoch: 5| Step: 4
Training loss: 3.041225732345122
Validation loss: 2.2028087697976244
Epoch: 5| Step: 5
Training loss: 2.7990432944048287
Validation loss: 2.221639186399356
Epoch: 5| Step: 6
Training loss: 2.3643326367367754
Validation loss: 2.1914508475178995
Epoch: 5| Step: 7
Training loss: 2.3489420031017256
Validation loss: 2.2169713990740947
Epoch: 5| Step: 8
Training loss: 2.7093024256224862
Validation loss: 2.1867067760375587
Epoch: 5| Step: 9
Training loss: 2.5013397441665277
Validation loss: 2.195354652062889
Epoch: 62| Step: 0
Training loss: 2.0612187885537794
Validation loss: 2.1741079612255105
Epoch: 5| Step: 1
Training loss: 3.104695695348865
Validation loss: 2.1583028633421346
Epoch: 5| Step: 2
Training loss: 2.791388047012437
Validation loss: 2.191574008878366
Epoch: 5| Step: 3
Training loss: 2.4981323895644554
Validation loss: 2.1956688089120586
Epoch: 5| Step: 4
Training loss: 2.449850435946713
Validation loss: 2.1964545699796996
Epoch: 5| Step: 5
Training loss: 2.692566465161357
Validation loss: 2.1992068237372466
Epoch: 5| Step: 6
Training loss: 2.8660568793775947
Validation loss: 2.1914342493346113
Epoch: 5| Step: 7
Training loss: 2.4681807235876287
Validation loss: 2.2106974866370988
Epoch: 5| Step: 8
Training loss: 2.598899692849817
Validation loss: 2.172502469457729
Epoch: 5| Step: 9
Training loss: 2.6457900596944626
Validation loss: 2.1859282120974597
Epoch: 63| Step: 0
Training loss: 2.7714833426927252
Validation loss: 2.1810254842712298
Epoch: 5| Step: 1
Training loss: 2.9189092098490828
Validation loss: 2.239262504725094
Epoch: 5| Step: 2
Training loss: 2.7348994160903963
Validation loss: 2.180123066653102
Epoch: 5| Step: 3
Training loss: 2.44141621091718
Validation loss: 2.2194147638097927
Epoch: 5| Step: 4
Training loss: 2.3914621919246963
Validation loss: 2.1699057705844753
Epoch: 5| Step: 5
Training loss: 2.274935199527305
Validation loss: 2.188917858982047
Epoch: 5| Step: 6
Training loss: 2.5972780798505704
Validation loss: 2.2108872913413196
Epoch: 5| Step: 7
Training loss: 2.518140778803393
Validation loss: 2.2002148144630445
Epoch: 5| Step: 8
Training loss: 2.9534298371104697
Validation loss: 2.2222837974611935
Epoch: 5| Step: 9
Training loss: 2.5914756271096437
Validation loss: 2.207590637119342
Epoch: 64| Step: 0
Training loss: 2.469490616200721
Validation loss: 2.1950681277733204
Epoch: 5| Step: 1
Training loss: 2.09537773059234
Validation loss: 2.223190917409355
Epoch: 5| Step: 2
Training loss: 2.5650761378478695
Validation loss: 2.223496065039814
Epoch: 5| Step: 3
Training loss: 2.872992934518711
Validation loss: 2.218868014059092
Epoch: 5| Step: 4
Training loss: 2.6102773054287876
Validation loss: 2.210997186675999
Epoch: 5| Step: 5
Training loss: 2.734381975437531
Validation loss: 2.196796765004787
Epoch: 5| Step: 6
Training loss: 2.8078281170766823
Validation loss: 2.211849138461679
Epoch: 5| Step: 7
Training loss: 2.567150826636257
Validation loss: 2.201949808865955
Epoch: 5| Step: 8
Training loss: 2.69688179660617
Validation loss: 2.1986329168215826
Epoch: 5| Step: 9
Training loss: 2.807895536473891
Validation loss: 2.1964476821870176
Epoch: 65| Step: 0
Training loss: 2.788493207857924
Validation loss: 2.199756170037431
Epoch: 5| Step: 1
Training loss: 2.095169838551106
Validation loss: 2.1951269572173016
Epoch: 5| Step: 2
Training loss: 2.8247046257147277
Validation loss: 2.195080712027226
Epoch: 5| Step: 3
Training loss: 2.186461283800068
Validation loss: 2.1963245704009218
Epoch: 5| Step: 4
Training loss: 2.4238993398331448
Validation loss: 2.2102847020442464
Epoch: 5| Step: 5
Training loss: 2.4999736784503024
Validation loss: 2.2028346811112924
Epoch: 5| Step: 6
Training loss: 2.873147118619994
Validation loss: 2.1925697298762543
Epoch: 5| Step: 7
Training loss: 2.8251409647382357
Validation loss: 2.2048741455926613
Epoch: 5| Step: 8
Training loss: 2.677201254853747
Validation loss: 2.1993139417501535
Epoch: 5| Step: 9
Training loss: 2.88709270032223
Validation loss: 2.2015156271061276
Epoch: 66| Step: 0
Training loss: 2.9016260258258644
Validation loss: 2.187902183101112
Epoch: 5| Step: 1
Training loss: 2.7105698569830223
Validation loss: 2.1766586291524566
Epoch: 5| Step: 2
Training loss: 2.6752197567522793
Validation loss: 2.1920038890586424
Epoch: 5| Step: 3
Training loss: 2.24876783328913
Validation loss: 2.2055589214469133
Epoch: 5| Step: 4
Training loss: 2.5142326529743566
Validation loss: 2.177066006177755
Epoch: 5| Step: 5
Training loss: 2.6802109632443334
Validation loss: 2.199564230447552
Epoch: 5| Step: 6
Training loss: 2.852667273147898
Validation loss: 2.1677658015105212
Epoch: 5| Step: 7
Training loss: 2.3769341674149005
Validation loss: 2.19243858605061
Epoch: 5| Step: 8
Training loss: 2.448725259762032
Validation loss: 2.171364125290208
Epoch: 5| Step: 9
Training loss: 2.726951680649551
Validation loss: 2.2058024885783563
Epoch: 67| Step: 0
Training loss: 2.7317512349073305
Validation loss: 2.1844402099119047
Epoch: 5| Step: 1
Training loss: 2.7938908688661748
Validation loss: 2.168274046498311
Epoch: 5| Step: 2
Training loss: 2.038086405426396
Validation loss: 2.1788865465607317
Epoch: 5| Step: 3
Training loss: 2.4781887358927217
Validation loss: 2.1911276774879385
Epoch: 5| Step: 4
Training loss: 2.435889567942918
Validation loss: 2.184878960225311
Epoch: 5| Step: 5
Training loss: 2.7069413251376613
Validation loss: 2.206937011464088
Epoch: 5| Step: 6
Training loss: 2.6212541101920994
Validation loss: 2.20391309149671
Epoch: 5| Step: 7
Training loss: 2.8777341695334697
Validation loss: 2.1770133425419194
Epoch: 5| Step: 8
Training loss: 2.639412144321218
Validation loss: 2.1861565340458227
Epoch: 5| Step: 9
Training loss: 2.7374187858065704
Validation loss: 2.193171405858915
Epoch: 68| Step: 0
Training loss: 3.5241809407436198
Validation loss: 2.2082504001448426
Epoch: 5| Step: 1
Training loss: 2.9471882885189737
Validation loss: 2.1931962517358143
Epoch: 5| Step: 2
Training loss: 2.4343327216221997
Validation loss: 2.2004743959026754
Epoch: 5| Step: 3
Training loss: 2.5550382880759215
Validation loss: 2.171735725222657
Epoch: 5| Step: 4
Training loss: 2.486858158596216
Validation loss: 2.1896914330441124
Epoch: 5| Step: 5
Training loss: 2.4314759960899814
Validation loss: 2.2044874284539184
Epoch: 5| Step: 6
Training loss: 2.068325254971172
Validation loss: 2.200153908760995
Epoch: 5| Step: 7
Training loss: 2.6523160638052428
Validation loss: 2.206849275402705
Epoch: 5| Step: 8
Training loss: 2.458032546527075
Validation loss: 2.2015036929001095
Epoch: 5| Step: 9
Training loss: 2.2749780632889727
Validation loss: 2.1919969534251424
Epoch: 69| Step: 0
Training loss: 2.418171666124666
Validation loss: 2.1532615887301816
Epoch: 5| Step: 1
Training loss: 2.616253951097504
Validation loss: 2.1899721603799533
Epoch: 5| Step: 2
Training loss: 2.822012011474741
Validation loss: 2.1628196441713006
Epoch: 5| Step: 3
Training loss: 2.5859776980684166
Validation loss: 2.1497599640481635
Epoch: 5| Step: 4
Training loss: 2.9461027749671165
Validation loss: 2.177370872664544
Epoch: 5| Step: 5
Training loss: 2.1146813230563835
Validation loss: 2.1678661735517513
Epoch: 5| Step: 6
Training loss: 2.500862163651662
Validation loss: 2.2022711630709995
Epoch: 5| Step: 7
Training loss: 2.667173387147096
Validation loss: 2.1948109137363767
Epoch: 5| Step: 8
Training loss: 2.735138181720973
Validation loss: 2.188571368191027
Epoch: 5| Step: 9
Training loss: 2.7048634137486744
Validation loss: 2.203952904245676
Epoch: 70| Step: 0
Training loss: 3.002357510275356
Validation loss: 2.1988629147025276
Epoch: 5| Step: 1
Training loss: 2.455199512524648
Validation loss: 2.1702485835624485
Epoch: 5| Step: 2
Training loss: 2.301506303876804
Validation loss: 2.1945378174566317
Epoch: 5| Step: 3
Training loss: 2.8001102085222653
Validation loss: 2.195963581874829
Epoch: 5| Step: 4
Training loss: 2.6982508468350916
Validation loss: 2.1894274939564564
Epoch: 5| Step: 5
Training loss: 2.7599816801320087
Validation loss: 2.201533619658022
Epoch: 5| Step: 6
Training loss: 2.8240371582407104
Validation loss: 2.198284517691958
Epoch: 5| Step: 7
Training loss: 2.160445071566755
Validation loss: 2.174325814727924
Epoch: 5| Step: 8
Training loss: 2.7320958693566135
Validation loss: 2.1892897835007283
Epoch: 5| Step: 9
Training loss: 2.3596209467344678
Validation loss: 2.1858461537492055
Epoch: 71| Step: 0
Training loss: 2.377643419145768
Validation loss: 2.175507043325695
Epoch: 5| Step: 1
Training loss: 2.912061397942733
Validation loss: 2.1791315549956183
Epoch: 5| Step: 2
Training loss: 2.635348493777395
Validation loss: 2.1900354145073506
Epoch: 5| Step: 3
Training loss: 2.782024832816946
Validation loss: 2.2047902294869943
Epoch: 5| Step: 4
Training loss: 2.70751041723838
Validation loss: 2.1758698083199786
Epoch: 5| Step: 5
Training loss: 2.6574915957385263
Validation loss: 2.1762713529034783
Epoch: 5| Step: 6
Training loss: 2.24564215059258
Validation loss: 2.167621424456977
Epoch: 5| Step: 7
Training loss: 1.9804016944623744
Validation loss: 2.182670976135655
Epoch: 5| Step: 8
Training loss: 2.7119803497817863
Validation loss: 2.189492602463476
Epoch: 5| Step: 9
Training loss: 2.890572377318732
Validation loss: 2.1797658998599423
Epoch: 72| Step: 0
Training loss: 2.3042395204841943
Validation loss: 2.2046113668524807
Epoch: 5| Step: 1
Training loss: 2.66846324085794
Validation loss: 2.1764077100598067
Epoch: 5| Step: 2
Training loss: 2.5048842402225464
Validation loss: 2.198676123834699
Epoch: 5| Step: 3
Training loss: 2.2434657902414386
Validation loss: 2.196173187232851
Epoch: 5| Step: 4
Training loss: 2.8379954707920745
Validation loss: 2.169884426143216
Epoch: 5| Step: 5
Training loss: 2.543760208746743
Validation loss: 2.1781128148805724
Epoch: 5| Step: 6
Training loss: 2.8259796941936135
Validation loss: 2.2180291782610286
Epoch: 5| Step: 7
Training loss: 2.951993210699446
Validation loss: 2.1842140979667994
Epoch: 5| Step: 8
Training loss: 2.4569021897617644
Validation loss: 2.1679492468736905
Epoch: 5| Step: 9
Training loss: 2.6262692607189697
Validation loss: 2.1493692303444116
Epoch: 73| Step: 0
Training loss: 2.9785831831477636
Validation loss: 2.159699007382594
Epoch: 5| Step: 1
Training loss: 2.646639503352424
Validation loss: 2.168648704539353
Epoch: 5| Step: 2
Training loss: 3.0087679843975255
Validation loss: 2.192806755377103
Epoch: 5| Step: 3
Training loss: 2.451867625672479
Validation loss: 2.1846004489065374
Epoch: 5| Step: 4
Training loss: 2.068315456885897
Validation loss: 2.175562973034502
Epoch: 5| Step: 5
Training loss: 2.6992546995559628
Validation loss: 2.1882059912819107
Epoch: 5| Step: 6
Training loss: 2.5312707217274895
Validation loss: 2.1599780262663533
Epoch: 5| Step: 7
Training loss: 2.7696657134693488
Validation loss: 2.1678167660262395
Epoch: 5| Step: 8
Training loss: 2.3779284843426116
Validation loss: 2.190466280452172
Epoch: 5| Step: 9
Training loss: 2.4828968569118994
Validation loss: 2.1820087806013873
Epoch: 74| Step: 0
Training loss: 2.7325761382025973
Validation loss: 2.1652732843575015
Epoch: 5| Step: 1
Training loss: 2.830369090621919
Validation loss: 2.176408260533064
Epoch: 5| Step: 2
Training loss: 2.5262782874168144
Validation loss: 2.1636119092735915
Epoch: 5| Step: 3
Training loss: 2.071774639385903
Validation loss: 2.1571701135107886
Epoch: 5| Step: 4
Training loss: 2.429302810683776
Validation loss: 2.1889818251871316
Epoch: 5| Step: 5
Training loss: 2.8168961817061597
Validation loss: 2.179021952168762
Epoch: 5| Step: 6
Training loss: 2.579864839665517
Validation loss: 2.182723466516595
Epoch: 5| Step: 7
Training loss: 2.528034475471722
Validation loss: 2.1921647650458125
Epoch: 5| Step: 8
Training loss: 2.8823847259472535
Validation loss: 2.1794105967510555
Epoch: 5| Step: 9
Training loss: 2.461318213668844
Validation loss: 2.1900908049001746
Epoch: 75| Step: 0
Training loss: 2.7271175311464892
Validation loss: 2.165636069635305
Epoch: 5| Step: 1
Training loss: 2.727789223054112
Validation loss: 2.184644905609616
Epoch: 5| Step: 2
Training loss: 2.4891817628266266
Validation loss: 2.198732933806626
Epoch: 5| Step: 3
Training loss: 2.4406293685815377
Validation loss: 2.1798725263155054
Epoch: 5| Step: 4
Training loss: 2.5603372704839398
Validation loss: 2.1881112882541043
Epoch: 5| Step: 5
Training loss: 2.3523225791584066
Validation loss: 2.1755906975249304
Epoch: 5| Step: 6
Training loss: 2.826557209606713
Validation loss: 2.1806300776609135
Epoch: 5| Step: 7
Training loss: 2.7917591383312956
Validation loss: 2.1625877228577193
Epoch: 5| Step: 8
Training loss: 2.2188108194101503
Validation loss: 2.193342117420983
Epoch: 5| Step: 9
Training loss: 2.8821504654583863
Validation loss: 2.1645792394824652
Epoch: 76| Step: 0
Training loss: 2.684620756505881
Validation loss: 2.1928317646246573
Epoch: 5| Step: 1
Training loss: 2.4734423504201692
Validation loss: 2.1690104993188988
Epoch: 5| Step: 2
Training loss: 2.6916446220353434
Validation loss: 2.1966183629895504
Epoch: 5| Step: 3
Training loss: 2.4891975667913093
Validation loss: 2.1690669000989393
Epoch: 5| Step: 4
Training loss: 2.3269335879302484
Validation loss: 2.1795834418037012
Epoch: 5| Step: 5
Training loss: 2.6955481384767928
Validation loss: 2.1778699883887507
Epoch: 5| Step: 6
Training loss: 3.145246758415893
Validation loss: 2.187979264347396
Epoch: 5| Step: 7
Training loss: 2.1494947017117227
Validation loss: 2.1742150413404144
Epoch: 5| Step: 8
Training loss: 2.4223413818206065
Validation loss: 2.168417580270342
Epoch: 5| Step: 9
Training loss: 2.6438732145558714
Validation loss: 2.194353339030636
Epoch: 77| Step: 0
Training loss: 2.57781684652224
Validation loss: 2.215847646604419
Epoch: 5| Step: 1
Training loss: 2.3564485501687247
Validation loss: 2.1862614577051396
Epoch: 5| Step: 2
Training loss: 2.622588457737593
Validation loss: 2.1719735702550724
Epoch: 5| Step: 3
Training loss: 2.6277308110598137
Validation loss: 2.198594769680335
Epoch: 5| Step: 4
Training loss: 2.0388517892056717
Validation loss: 2.1702217343196595
Epoch: 5| Step: 5
Training loss: 2.9107341013442
Validation loss: 2.178617203689559
Epoch: 5| Step: 6
Training loss: 3.1119815501865
Validation loss: 2.1795253118260214
Epoch: 5| Step: 7
Training loss: 2.4160256905989796
Validation loss: 2.1514730823414716
Epoch: 5| Step: 8
Training loss: 2.873883901482316
Validation loss: 2.178654549591331
Epoch: 5| Step: 9
Training loss: 2.1421526727272977
Validation loss: 2.1576891284021125
Epoch: 78| Step: 0
Training loss: 3.212390283276969
Validation loss: 2.1824511100878086
Epoch: 5| Step: 1
Training loss: 2.4400928107573825
Validation loss: 2.1984631942965724
Epoch: 5| Step: 2
Training loss: 2.6213073188652496
Validation loss: 2.1711652952677905
Epoch: 5| Step: 3
Training loss: 2.179134941477963
Validation loss: 2.169597544773837
Epoch: 5| Step: 4
Training loss: 2.1379703294284984
Validation loss: 2.1796018765766245
Epoch: 5| Step: 5
Training loss: 2.4464711134854324
Validation loss: 2.1697676708017775
Epoch: 5| Step: 6
Training loss: 2.7974433534561336
Validation loss: 2.156075909840052
Epoch: 5| Step: 7
Training loss: 2.459152785541789
Validation loss: 2.158272959546542
Epoch: 5| Step: 8
Training loss: 2.835549572350711
Validation loss: 2.187512887709062
Epoch: 5| Step: 9
Training loss: 2.547260653077497
Validation loss: 2.1608907381268962
Epoch: 79| Step: 0
Training loss: 2.2949131482546843
Validation loss: 2.161166510778128
Epoch: 5| Step: 1
Training loss: 2.9378937802261675
Validation loss: 2.1715183695732225
Epoch: 5| Step: 2
Training loss: 2.799009733836648
Validation loss: 2.164937782979279
Epoch: 5| Step: 3
Training loss: 2.885949389769346
Validation loss: 2.1626262111931855
Epoch: 5| Step: 4
Training loss: 2.569384932186794
Validation loss: 2.1647341746651994
Epoch: 5| Step: 5
Training loss: 2.368898384056521
Validation loss: 2.177074988792531
Epoch: 5| Step: 6
Training loss: 2.2684673501066213
Validation loss: 2.121570891280222
Epoch: 5| Step: 7
Training loss: 1.9238753414653171
Validation loss: 2.171660331236121
Epoch: 5| Step: 8
Training loss: 2.6855660510679007
Validation loss: 2.17890286776826
Epoch: 5| Step: 9
Training loss: 2.9865958852838843
Validation loss: 2.174329360458709
Epoch: 80| Step: 0
Training loss: 2.455300599475135
Validation loss: 2.1652677540249905
Epoch: 5| Step: 1
Training loss: 2.65066038936061
Validation loss: 2.1588957975266343
Epoch: 5| Step: 2
Training loss: 2.584399177779513
Validation loss: 2.1526935841853905
Epoch: 5| Step: 3
Training loss: 1.9877577656510377
Validation loss: 2.1599351534364275
Epoch: 5| Step: 4
Training loss: 2.3422517183647487
Validation loss: 2.1585092592372246
Epoch: 5| Step: 5
Training loss: 2.438262428961524
Validation loss: 2.1729271128400716
Epoch: 5| Step: 6
Training loss: 3.1446991111543285
Validation loss: 2.1799010756315855
Epoch: 5| Step: 7
Training loss: 2.6418716828447484
Validation loss: 2.157869618155945
Epoch: 5| Step: 8
Training loss: 2.8295581200362516
Validation loss: 2.188502479050783
Epoch: 5| Step: 9
Training loss: 2.6662319444920457
Validation loss: 2.161400619137297
Epoch: 81| Step: 0
Training loss: 2.3166619042363603
Validation loss: 2.179968768894487
Epoch: 5| Step: 1
Training loss: 2.407961645340496
Validation loss: 2.1502413560896296
Epoch: 5| Step: 2
Training loss: 2.889187842167605
Validation loss: 2.184970707425322
Epoch: 5| Step: 3
Training loss: 2.8224894820930473
Validation loss: 2.182433241001977
Epoch: 5| Step: 4
Training loss: 2.334351680695314
Validation loss: 2.146027752020862
Epoch: 5| Step: 5
Training loss: 2.4532271442893894
Validation loss: 2.177025904898227
Epoch: 5| Step: 6
Training loss: 2.4386318219995906
Validation loss: 2.1508136844131567
Epoch: 5| Step: 7
Training loss: 2.9083979062961203
Validation loss: 2.165281341736184
Epoch: 5| Step: 8
Training loss: 2.087965076286009
Validation loss: 2.1420586844535374
Epoch: 5| Step: 9
Training loss: 3.0176267947126876
Validation loss: 2.164529731622045
Epoch: 82| Step: 0
Training loss: 2.418178370545668
Validation loss: 2.1389179526709516
Epoch: 5| Step: 1
Training loss: 2.743093053075898
Validation loss: 2.1499378006416716
Epoch: 5| Step: 2
Training loss: 2.645646957281111
Validation loss: 2.18139323571526
Epoch: 5| Step: 3
Training loss: 2.5677949118316508
Validation loss: 2.151925489718719
Epoch: 5| Step: 4
Training loss: 2.450524379120929
Validation loss: 2.1623595968952536
Epoch: 5| Step: 5
Training loss: 2.40592439108093
Validation loss: 2.1854384261332362
Epoch: 5| Step: 6
Training loss: 2.765550256785951
Validation loss: 2.172429429904912
Epoch: 5| Step: 7
Training loss: 2.2134299096711545
Validation loss: 2.1724992596257025
Epoch: 5| Step: 8
Training loss: 3.2704362243490057
Validation loss: 2.193313388381686
Epoch: 5| Step: 9
Training loss: 2.1989889075609663
Validation loss: 2.1525440158051974
Epoch: 83| Step: 0
Training loss: 2.4787416708263326
Validation loss: 2.149517469177231
Epoch: 5| Step: 1
Training loss: 2.4943734749617534
Validation loss: 2.155842193135647
Epoch: 5| Step: 2
Training loss: 2.3782018862111705
Validation loss: 2.1452484035603985
Epoch: 5| Step: 3
Training loss: 2.564832044906469
Validation loss: 2.1476394225493474
Epoch: 5| Step: 4
Training loss: 2.705535695731791
Validation loss: 2.171405811746402
Epoch: 5| Step: 5
Training loss: 2.6898318088520163
Validation loss: 2.1631684979524066
Epoch: 5| Step: 6
Training loss: 2.4249880564287367
Validation loss: 2.162861741447314
Epoch: 5| Step: 7
Training loss: 2.4336365624055696
Validation loss: 2.161186006788329
Epoch: 5| Step: 8
Training loss: 2.9494218162706005
Validation loss: 2.180216746036875
Epoch: 5| Step: 9
Training loss: 2.5306310956697353
Validation loss: 2.159156913317381
Epoch: 84| Step: 0
Training loss: 2.5073352014882393
Validation loss: 2.185584299887773
Epoch: 5| Step: 1
Training loss: 2.7029619994658898
Validation loss: 2.176367321320202
Epoch: 5| Step: 2
Training loss: 1.9304065677349294
Validation loss: 2.1642139415470334
Epoch: 5| Step: 3
Training loss: 2.7590971378040723
Validation loss: 2.16046544676747
Epoch: 5| Step: 4
Training loss: 2.565807719815715
Validation loss: 2.167049917024509
Epoch: 5| Step: 5
Training loss: 2.702277960394144
Validation loss: 2.1574067253410423
Epoch: 5| Step: 6
Training loss: 2.9362100244287963
Validation loss: 2.1435686524641264
Epoch: 5| Step: 7
Training loss: 2.388962710026052
Validation loss: 2.1816425251777094
Epoch: 5| Step: 8
Training loss: 2.55419879870301
Validation loss: 2.1651027739595516
Epoch: 5| Step: 9
Training loss: 2.382647199056314
Validation loss: 2.165559304599716
Epoch: 85| Step: 0
Training loss: 2.474651766852763
Validation loss: 2.165875159191467
Epoch: 5| Step: 1
Training loss: 2.503792746793649
Validation loss: 2.1647327245696966
Epoch: 5| Step: 2
Training loss: 2.7172688801595877
Validation loss: 2.13041490534135
Epoch: 5| Step: 3
Training loss: 2.2485287412537427
Validation loss: 2.145291601117655
Epoch: 5| Step: 4
Training loss: 3.001036147157006
Validation loss: 2.1824075077100984
Epoch: 5| Step: 5
Training loss: 2.9558259429996987
Validation loss: 2.1735786246598674
Epoch: 5| Step: 6
Training loss: 2.322287800829779
Validation loss: 2.132368729429342
Epoch: 5| Step: 7
Training loss: 2.4651674762341336
Validation loss: 2.1241958147462596
Epoch: 5| Step: 8
Training loss: 2.279021964864097
Validation loss: 2.132524962380718
Epoch: 5| Step: 9
Training loss: 2.5956118232508327
Validation loss: 2.1516979415383166
Epoch: 86| Step: 0
Training loss: 2.1348048256279
Validation loss: 2.1627157501289016
Epoch: 5| Step: 1
Training loss: 2.133783922691178
Validation loss: 2.147753619202783
Epoch: 5| Step: 2
Training loss: 2.382526518122748
Validation loss: 2.1764927049454412
Epoch: 5| Step: 3
Training loss: 2.5280133499746684
Validation loss: 2.1335220486881665
Epoch: 5| Step: 4
Training loss: 2.379000857622041
Validation loss: 2.1723278507255035
Epoch: 5| Step: 5
Training loss: 3.1053875222769194
Validation loss: 2.1519851594915034
Epoch: 5| Step: 6
Training loss: 2.2272850604237804
Validation loss: 2.156918810926928
Epoch: 5| Step: 7
Training loss: 3.194407887641231
Validation loss: 2.153517020170903
Epoch: 5| Step: 8
Training loss: 2.7603360914070616
Validation loss: 2.1713995483157658
Epoch: 5| Step: 9
Training loss: 2.6485017751810562
Validation loss: 2.182010341538377
Epoch: 87| Step: 0
Training loss: 2.6983922198041213
Validation loss: 2.1509954967819738
Epoch: 5| Step: 1
Training loss: 1.9554167462824505
Validation loss: 2.1561182983237805
Epoch: 5| Step: 2
Training loss: 2.55206350721067
Validation loss: 2.124202523683467
Epoch: 5| Step: 3
Training loss: 2.5814843687935984
Validation loss: 2.1656618077133003
Epoch: 5| Step: 4
Training loss: 2.8291644299085834
Validation loss: 2.1408071784855487
Epoch: 5| Step: 5
Training loss: 2.514290781604317
Validation loss: 2.1731957374199125
Epoch: 5| Step: 6
Training loss: 2.4519646688532624
Validation loss: 2.147915038361002
Epoch: 5| Step: 7
Training loss: 2.615891776386516
Validation loss: 2.1648732350385678
Epoch: 5| Step: 8
Training loss: 2.956731299805251
Validation loss: 2.1131331027577622
Epoch: 5| Step: 9
Training loss: 2.429086298019298
Validation loss: 2.164316600084473
Epoch: 88| Step: 0
Training loss: 2.784530933265161
Validation loss: 2.1487314302168428
Epoch: 5| Step: 1
Training loss: 2.3382110248679364
Validation loss: 2.140950244942676
Epoch: 5| Step: 2
Training loss: 2.3203568887799553
Validation loss: 2.139492383171867
Epoch: 5| Step: 3
Training loss: 2.747114922262657
Validation loss: 2.1543861328427987
Epoch: 5| Step: 4
Training loss: 2.509527552849975
Validation loss: 2.1633778842276015
Epoch: 5| Step: 5
Training loss: 2.463638518824206
Validation loss: 2.1435320733761625
Epoch: 5| Step: 6
Training loss: 2.389763371393168
Validation loss: 2.124949425606268
Epoch: 5| Step: 7
Training loss: 2.4746918457548026
Validation loss: 2.128993542106702
Epoch: 5| Step: 8
Training loss: 2.9824931817564364
Validation loss: 2.160509656020026
Epoch: 5| Step: 9
Training loss: 2.4356543571537346
Validation loss: 2.168214306148206
Epoch: 89| Step: 0
Training loss: 2.5493828531580576
Validation loss: 2.1669150205862846
Epoch: 5| Step: 1
Training loss: 2.4807345991270715
Validation loss: 2.1393532149312344
Epoch: 5| Step: 2
Training loss: 2.9703063097893807
Validation loss: 2.1531918599632167
Epoch: 5| Step: 3
Training loss: 2.366251341773538
Validation loss: 2.1679260855551044
Epoch: 5| Step: 4
Training loss: 2.9939552443834385
Validation loss: 2.1419173359426753
Epoch: 5| Step: 5
Training loss: 2.6763811984235173
Validation loss: 2.1571851810624865
Epoch: 5| Step: 6
Training loss: 2.4218239071286525
Validation loss: 2.1564092623091695
Epoch: 5| Step: 7
Training loss: 2.701996937245314
Validation loss: 2.163221474744219
Epoch: 5| Step: 8
Training loss: 2.3641987178307535
Validation loss: 2.1149383523134406
Epoch: 5| Step: 9
Training loss: 2.0164438403060965
Validation loss: 2.1452600125589396
Epoch: 90| Step: 0
Training loss: 2.683222182757786
Validation loss: 2.1548688119740045
Epoch: 5| Step: 1
Training loss: 2.85614064213858
Validation loss: 2.168854019560647
Epoch: 5| Step: 2
Training loss: 2.2716294272662028
Validation loss: 2.130115557358346
Epoch: 5| Step: 3
Training loss: 2.2631031602312954
Validation loss: 2.1719107462116534
Epoch: 5| Step: 4
Training loss: 2.322578428358811
Validation loss: 2.1580607285093665
Epoch: 5| Step: 5
Training loss: 2.771456846674419
Validation loss: 2.151284544114016
Epoch: 5| Step: 6
Training loss: 2.347669655353782
Validation loss: 2.160960054874609
Epoch: 5| Step: 7
Training loss: 2.6073919744598784
Validation loss: 2.1633621499282856
Epoch: 5| Step: 8
Training loss: 2.2129059241389717
Validation loss: 2.1499019187429282
Epoch: 5| Step: 9
Training loss: 3.069843130173278
Validation loss: 2.1642222090437917
Epoch: 91| Step: 0
Training loss: 2.5088816232560114
Validation loss: 2.1783283228786465
Epoch: 5| Step: 1
Training loss: 2.751241490421541
Validation loss: 2.149901994720057
Epoch: 5| Step: 2
Training loss: 2.3414491676875033
Validation loss: 2.15937767405044
Epoch: 5| Step: 3
Training loss: 1.7750891166129448
Validation loss: 2.1389111143174997
Epoch: 5| Step: 4
Training loss: 2.77577493518183
Validation loss: 2.1488101284263394
Epoch: 5| Step: 5
Training loss: 2.572087194094924
Validation loss: 2.1410215317230397
Epoch: 5| Step: 6
Training loss: 3.101169359480259
Validation loss: 2.163698795868332
Epoch: 5| Step: 7
Training loss: 2.3802556562553825
Validation loss: 2.1535447209761003
Epoch: 5| Step: 8
Training loss: 2.9254125711680143
Validation loss: 2.132836609130365
Epoch: 5| Step: 9
Training loss: 2.257154322589913
Validation loss: 2.1294632182449953
Epoch: 92| Step: 0
Training loss: 2.6636706648584836
Validation loss: 2.1340616157684384
Epoch: 5| Step: 1
Training loss: 2.4291576531462735
Validation loss: 2.148128793236406
Epoch: 5| Step: 2
Training loss: 2.5279701553285174
Validation loss: 2.162595193423592
Epoch: 5| Step: 3
Training loss: 2.7882921880805176
Validation loss: 2.105318868108025
Epoch: 5| Step: 4
Training loss: 2.806321117290106
Validation loss: 2.1438475160768613
Epoch: 5| Step: 5
Training loss: 2.0834546117450365
Validation loss: 2.130715499553237
Epoch: 5| Step: 6
Training loss: 2.5270595950914085
Validation loss: 2.148033701662193
Epoch: 5| Step: 7
Training loss: 3.1711372306720493
Validation loss: 2.1534987044969105
Epoch: 5| Step: 8
Training loss: 2.3200447107808015
Validation loss: 2.141255180004954
Epoch: 5| Step: 9
Training loss: 2.121699968402792
Validation loss: 2.1268431476065777
Epoch: 93| Step: 0
Training loss: 2.1837712797493927
Validation loss: 2.1442025786622687
Epoch: 5| Step: 1
Training loss: 2.8634932414808225
Validation loss: 2.1361220429269165
Epoch: 5| Step: 2
Training loss: 2.412248442189254
Validation loss: 2.13940522345786
Epoch: 5| Step: 3
Training loss: 2.853736863642838
Validation loss: 2.1540537181778725
Epoch: 5| Step: 4
Training loss: 2.6887843589414047
Validation loss: 2.168059183268182
Epoch: 5| Step: 5
Training loss: 2.6546785979769996
Validation loss: 2.1207280127733776
Epoch: 5| Step: 6
Training loss: 2.832122674979029
Validation loss: 2.1399727524520675
Epoch: 5| Step: 7
Training loss: 2.0312184257987727
Validation loss: 2.145749558913001
Epoch: 5| Step: 8
Training loss: 2.413142451786621
Validation loss: 2.129721986365427
Epoch: 5| Step: 9
Training loss: 2.4100515877675073
Validation loss: 2.1629905837451058
Epoch: 94| Step: 0
Training loss: 2.247313060687544
Validation loss: 2.1424024005398143
Epoch: 5| Step: 1
Training loss: 2.422151020687315
Validation loss: 2.138787528291767
Epoch: 5| Step: 2
Training loss: 2.3285849712088345
Validation loss: 2.147037255752595
Epoch: 5| Step: 3
Training loss: 2.67885583366774
Validation loss: 2.1515127026121403
Epoch: 5| Step: 4
Training loss: 2.7007923976766337
Validation loss: 2.1429184271671433
Epoch: 5| Step: 5
Training loss: 2.6186465623042414
Validation loss: 2.143154110213281
Epoch: 5| Step: 6
Training loss: 2.5364056111103888
Validation loss: 2.148528106640665
Epoch: 5| Step: 7
Training loss: 2.700138890261551
Validation loss: 2.1198446252328886
Epoch: 5| Step: 8
Training loss: 3.0321671189825543
Validation loss: 2.1253425331204814
Epoch: 5| Step: 9
Training loss: 2.183033770717209
Validation loss: 2.125139073797324
Epoch: 95| Step: 0
Training loss: 2.82055865875201
Validation loss: 2.1623478882395
Epoch: 5| Step: 1
Training loss: 2.4538703320730737
Validation loss: 2.1391668156664863
Epoch: 5| Step: 2
Training loss: 2.285426875334768
Validation loss: 2.1439036580253323
Epoch: 5| Step: 3
Training loss: 2.604643043179862
Validation loss: 2.1577911151661753
Epoch: 5| Step: 4
Training loss: 2.1038320546005673
Validation loss: 2.152202317369625
Epoch: 5| Step: 5
Training loss: 2.6097195335032812
Validation loss: 2.1431584689375165
Epoch: 5| Step: 6
Training loss: 3.099148442610637
Validation loss: 2.135819616630749
Epoch: 5| Step: 7
Training loss: 2.736888580323418
Validation loss: 2.119487170835581
Epoch: 5| Step: 8
Training loss: 2.2549377936941357
Validation loss: 2.1575024435958694
Epoch: 5| Step: 9
Training loss: 2.2080615854105656
Validation loss: 2.1328516838312983
Epoch: 96| Step: 0
Training loss: 2.349463251378935
Validation loss: 2.1382484705974845
Epoch: 5| Step: 1
Training loss: 2.5897711143837094
Validation loss: 2.147781980300724
Epoch: 5| Step: 2
Training loss: 2.4657412193379473
Validation loss: 2.1579817119974862
Epoch: 5| Step: 3
Training loss: 1.9625056710130917
Validation loss: 2.143923073072472
Epoch: 5| Step: 4
Training loss: 2.7300736956028957
Validation loss: 2.155188242810021
Epoch: 5| Step: 5
Training loss: 2.73494047584826
Validation loss: 2.178180862705359
Epoch: 5| Step: 6
Training loss: 2.5614606098435377
Validation loss: 2.1378951091690173
Epoch: 5| Step: 7
Training loss: 3.115796383474293
Validation loss: 2.131153664302847
Epoch: 5| Step: 8
Training loss: 2.694313284269575
Validation loss: 2.1276582108701256
Epoch: 5| Step: 9
Training loss: 2.164591920729765
Validation loss: 2.1408333874356114
Epoch: 97| Step: 0
Training loss: 2.350336610751296
Validation loss: 2.1329658868872743
Epoch: 5| Step: 1
Training loss: 2.252905664865694
Validation loss: 2.1312111482345197
Epoch: 5| Step: 2
Training loss: 2.7821334121658507
Validation loss: 2.1233863602817236
Epoch: 5| Step: 3
Training loss: 3.013713646016414
Validation loss: 2.143228375745068
Epoch: 5| Step: 4
Training loss: 2.3512504091723834
Validation loss: 2.137771195788294
Epoch: 5| Step: 5
Training loss: 2.4647891949935263
Validation loss: 2.1590604180936124
Epoch: 5| Step: 6
Training loss: 2.2947298789367685
Validation loss: 2.146291614495542
Epoch: 5| Step: 7
Training loss: 2.385600475797855
Validation loss: 2.144317204026228
Epoch: 5| Step: 8
Training loss: 2.6688965375277
Validation loss: 2.1344591673455953
Epoch: 5| Step: 9
Training loss: 2.675156301762774
Validation loss: 2.151236891089478
Epoch: 98| Step: 0
Training loss: 2.35589788016742
Validation loss: 2.1395719494282637
Epoch: 5| Step: 1
Training loss: 2.234083463415991
Validation loss: 2.1360022463874477
Epoch: 5| Step: 2
Training loss: 2.7436382227485203
Validation loss: 2.1310785218149957
Epoch: 5| Step: 3
Training loss: 2.902048498977486
Validation loss: 2.1504693127980548
Epoch: 5| Step: 4
Training loss: 2.4538706235537138
Validation loss: 2.1231279375139294
Epoch: 5| Step: 5
Training loss: 2.202461954539476
Validation loss: 2.1456172846376997
Epoch: 5| Step: 6
Training loss: 2.564424118029018
Validation loss: 2.1324738340906553
Epoch: 5| Step: 7
Training loss: 2.66194771424841
Validation loss: 2.13648844819626
Epoch: 5| Step: 8
Training loss: 2.8265326638067796
Validation loss: 2.1495317378242613
Epoch: 5| Step: 9
Training loss: 2.343811237806756
Validation loss: 2.1426391554086295
Epoch: 99| Step: 0
Training loss: 2.7878294711563334
Validation loss: 2.139999929497437
Epoch: 5| Step: 1
Training loss: 2.3142132984921613
Validation loss: 2.1285200242945224
Epoch: 5| Step: 2
Training loss: 2.5993027595815033
Validation loss: 2.1074414839657125
Epoch: 5| Step: 3
Training loss: 2.4829460208969483
Validation loss: 2.1258488102223274
Epoch: 5| Step: 4
Training loss: 2.3131230520195376
Validation loss: 2.124959017169894
Epoch: 5| Step: 5
Training loss: 2.990010478023682
Validation loss: 2.129906554580281
Epoch: 5| Step: 6
Training loss: 2.5025110032242703
Validation loss: 2.15542484378133
Epoch: 5| Step: 7
Training loss: 2.071324284751796
Validation loss: 2.1335521534384476
Epoch: 5| Step: 8
Training loss: 2.644974957295293
Validation loss: 2.139856880409491
Epoch: 5| Step: 9
Training loss: 2.6172651137045784
Validation loss: 2.1324834372337746
Epoch: 100| Step: 0
Training loss: 2.3294915406613295
Validation loss: 2.1270990553429825
Epoch: 5| Step: 1
Training loss: 2.4805125795832406
Validation loss: 2.1146725211406645
Epoch: 5| Step: 2
Training loss: 2.489633525092381
Validation loss: 2.1079000452189827
Epoch: 5| Step: 3
Training loss: 2.4013900228301206
Validation loss: 2.1393663353604437
Epoch: 5| Step: 4
Training loss: 2.5237562610081876
Validation loss: 2.140362582907805
Epoch: 5| Step: 5
Training loss: 3.0587178445052627
Validation loss: 2.131619228362942
Epoch: 5| Step: 6
Training loss: 2.6160167295930083
Validation loss: 2.141575229990609
Epoch: 5| Step: 7
Training loss: 2.1496283542655465
Validation loss: 2.100568018057231
Epoch: 5| Step: 8
Training loss: 2.5374582710029534
Validation loss: 2.109817932921976
Epoch: 5| Step: 9
Training loss: 2.7224808448979365
Validation loss: 2.1080867764789986
