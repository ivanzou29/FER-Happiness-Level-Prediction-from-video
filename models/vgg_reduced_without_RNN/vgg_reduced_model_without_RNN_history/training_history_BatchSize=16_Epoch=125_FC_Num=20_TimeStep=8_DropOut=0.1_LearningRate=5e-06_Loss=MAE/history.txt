Epoch: 1| Step: 0
Training loss: 3.204085350036621
Validation loss: 3.6934357484181723

Epoch: 6| Step: 1
Training loss: 4.012913703918457
Validation loss: 3.675959348678589

Epoch: 6| Step: 2
Training loss: 3.283020496368408
Validation loss: 3.655150214831034

Epoch: 6| Step: 3
Training loss: 3.3065924644470215
Validation loss: 3.639820416768392

Epoch: 6| Step: 4
Training loss: 3.230578899383545
Validation loss: 3.6212777296702066

Epoch: 6| Step: 5
Training loss: 3.8834619522094727
Validation loss: 3.608926256497701

Epoch: 6| Step: 6
Training loss: 4.01383638381958
Validation loss: 3.593484083811442

Epoch: 6| Step: 7
Training loss: 4.649125099182129
Validation loss: 3.581471880276998

Epoch: 6| Step: 8
Training loss: 3.718261241912842
Validation loss: 3.5633941094080606

Epoch: 6| Step: 9
Training loss: 3.6970055103302
Validation loss: 3.5509679317474365

Epoch: 6| Step: 10
Training loss: 4.461787223815918
Validation loss: 3.5358756383260093

Epoch: 6| Step: 11
Training loss: 3.8225314617156982
Validation loss: 3.522600849469503

Epoch: 6| Step: 12
Training loss: 4.224884033203125
Validation loss: 3.507233818372091

Epoch: 6| Step: 13
Training loss: 3.0440566539764404
Validation loss: 3.4947107632954917

Epoch: 2| Step: 0
Training loss: 3.331935167312622
Validation loss: 3.4787792762120566

Epoch: 6| Step: 1
Training loss: 4.894585132598877
Validation loss: 3.4624506632486978

Epoch: 6| Step: 2
Training loss: 3.5699191093444824
Validation loss: 3.447549025217692

Epoch: 6| Step: 3
Training loss: 3.052520751953125
Validation loss: 3.432994763056437

Epoch: 6| Step: 4
Training loss: 3.4320735931396484
Validation loss: 3.4164316256841025

Epoch: 6| Step: 5
Training loss: 3.7215983867645264
Validation loss: 3.3974761962890625

Epoch: 6| Step: 6
Training loss: 3.829174041748047
Validation loss: 3.377852121988932

Epoch: 6| Step: 7
Training loss: 2.762134552001953
Validation loss: 3.3589551051457724

Epoch: 6| Step: 8
Training loss: 3.3835411071777344
Validation loss: 3.3447185754776

Epoch: 6| Step: 9
Training loss: 3.4828572273254395
Validation loss: 3.32760759194692

Epoch: 6| Step: 10
Training loss: 2.9715499877929688
Validation loss: 3.3035999139149985

Epoch: 6| Step: 11
Training loss: 3.5836637020111084
Validation loss: 3.2800780137379966

Epoch: 6| Step: 12
Training loss: 3.3294248580932617
Validation loss: 3.2620726823806763

Epoch: 6| Step: 13
Training loss: 3.893024444580078
Validation loss: 3.2343698740005493

Epoch: 3| Step: 0
Training loss: 3.8490705490112305
Validation loss: 3.2126036882400513

Epoch: 6| Step: 1
Training loss: 3.0390625
Validation loss: 3.184858202934265

Epoch: 6| Step: 2
Training loss: 3.650122880935669
Validation loss: 3.1571516195933023

Epoch: 6| Step: 3
Training loss: 4.449620246887207
Validation loss: 3.1281638542811074

Epoch: 6| Step: 4
Training loss: 3.1465322971343994
Validation loss: 3.092820882797241

Epoch: 6| Step: 5
Training loss: 3.5107011795043945
Validation loss: 3.0649805466334024

Epoch: 6| Step: 6
Training loss: 2.812434434890747
Validation loss: 3.039356787999471

Epoch: 6| Step: 7
Training loss: 3.09367299079895
Validation loss: 3.001058657964071

Epoch: 6| Step: 8
Training loss: 3.1531267166137695
Validation loss: 2.9707882404327393

Epoch: 6| Step: 9
Training loss: 2.5215253829956055
Validation loss: 2.9340192476908364

Epoch: 6| Step: 10
Training loss: 2.8148248195648193
Validation loss: 2.904103954633077

Epoch: 6| Step: 11
Training loss: 3.169724941253662
Validation loss: 2.8676639795303345

Epoch: 6| Step: 12
Training loss: 2.2927958965301514
Validation loss: 2.8331775267918906

Epoch: 6| Step: 13
Training loss: 2.724799156188965
Validation loss: 2.787817637125651

Epoch: 4| Step: 0
Training loss: 3.4908478260040283
Validation loss: 2.7465585470199585

Epoch: 6| Step: 1
Training loss: 3.5176024436950684
Validation loss: 2.7112924655278525

Epoch: 6| Step: 2
Training loss: 3.0967001914978027
Validation loss: 2.6705539226531982

Epoch: 6| Step: 3
Training loss: 2.722923755645752
Validation loss: 2.6254241466522217

Epoch: 6| Step: 4
Training loss: 2.7352852821350098
Validation loss: 2.5699303150177

Epoch: 6| Step: 5
Training loss: 1.9390087127685547
Validation loss: 2.5325340032577515

Epoch: 6| Step: 6
Training loss: 2.6138288974761963
Validation loss: 2.483334561189016

Epoch: 6| Step: 7
Training loss: 2.5754990577697754
Validation loss: 2.4353660345077515

Epoch: 6| Step: 8
Training loss: 2.4007718563079834
Validation loss: 2.381667375564575

Epoch: 6| Step: 9
Training loss: 2.258507251739502
Validation loss: 2.3474891781806946

Epoch: 6| Step: 10
Training loss: 2.4643397331237793
Validation loss: 2.2921459873517356

Epoch: 6| Step: 11
Training loss: 1.9536216259002686
Validation loss: 2.2779099543889365

Epoch: 6| Step: 12
Training loss: 1.8761568069458008
Validation loss: 2.2377047538757324

Epoch: 6| Step: 13
Training loss: 1.8377175331115723
Validation loss: 2.1960689624150596

Epoch: 5| Step: 0
Training loss: 1.7790499925613403
Validation loss: 2.192888538042704

Epoch: 6| Step: 1
Training loss: 1.86561918258667
Validation loss: 2.1611112356185913

Epoch: 6| Step: 2
Training loss: 1.7903046607971191
Validation loss: 2.141857326030731

Epoch: 6| Step: 3
Training loss: 2.061875343322754
Validation loss: 2.1155089735984802

Epoch: 6| Step: 4
Training loss: 1.8152704238891602
Validation loss: 2.108232061068217

Epoch: 6| Step: 5
Training loss: 2.7619452476501465
Validation loss: 2.1158838868141174

Epoch: 6| Step: 6
Training loss: 2.1114628314971924
Validation loss: 2.098686615626017

Epoch: 6| Step: 7
Training loss: 2.4764392375946045
Validation loss: 2.1072607040405273

Epoch: 6| Step: 8
Training loss: 2.10185170173645
Validation loss: 2.1302979389826455

Epoch: 6| Step: 9
Training loss: 2.2127652168273926
Validation loss: 2.158350725968679

Epoch: 6| Step: 10
Training loss: 2.786046266555786
Validation loss: 2.1438764929771423

Epoch: 6| Step: 11
Training loss: 2.7049131393432617
Validation loss: 2.158391217390696

Epoch: 6| Step: 12
Training loss: 1.8506464958190918
Validation loss: 2.1614209016164145

Epoch: 6| Step: 13
Training loss: 1.546419620513916
Validation loss: 2.181095560391744

Epoch: 6| Step: 0
Training loss: 1.7756376266479492
Validation loss: 2.1877615650494895

Epoch: 6| Step: 1
Training loss: 1.809239149093628
Validation loss: 2.1684722900390625

Epoch: 6| Step: 2
Training loss: 2.0360889434814453
Validation loss: 2.1622330149014792

Epoch: 6| Step: 3
Training loss: 2.415966749191284
Validation loss: 2.1764626502990723

Epoch: 6| Step: 4
Training loss: 1.921627402305603
Validation loss: 2.161391874154409

Epoch: 6| Step: 5
Training loss: 2.189368486404419
Validation loss: 2.1400283773740134

Epoch: 6| Step: 6
Training loss: 1.749631404876709
Validation loss: 2.15854142109553

Epoch: 6| Step: 7
Training loss: 2.202052354812622
Validation loss: 2.127351462841034

Epoch: 6| Step: 8
Training loss: 1.7258269786834717
Validation loss: 2.1153249939282737

Epoch: 6| Step: 9
Training loss: 2.61030650138855
Validation loss: 2.105468769868215

Epoch: 6| Step: 10
Training loss: 2.134733200073242
Validation loss: 2.093004047870636

Epoch: 6| Step: 11
Training loss: 2.546450614929199
Validation loss: 2.0782048106193542

Epoch: 6| Step: 12
Training loss: 2.006333827972412
Validation loss: 2.087648888429006

Epoch: 6| Step: 13
Training loss: 2.2476375102996826
Validation loss: 2.0813241799672446

Epoch: 7| Step: 0
Training loss: 2.5235700607299805
Validation loss: 2.107516050338745

Epoch: 6| Step: 1
Training loss: 1.3966293334960938
Validation loss: 2.1044836044311523

Epoch: 6| Step: 2
Training loss: 1.968779444694519
Validation loss: 2.0849883755048118

Epoch: 6| Step: 3
Training loss: 2.1174325942993164
Validation loss: 2.08110374212265

Epoch: 6| Step: 4
Training loss: 1.9666457176208496
Validation loss: 2.1138002475102744

Epoch: 6| Step: 5
Training loss: 2.100180149078369
Validation loss: 2.098789115746816

Epoch: 6| Step: 6
Training loss: 2.2634177207946777
Validation loss: 2.0733208060264587

Epoch: 6| Step: 7
Training loss: 2.350842237472534
Validation loss: 2.0768375794092813

Epoch: 6| Step: 8
Training loss: 2.120802640914917
Validation loss: 2.1046422322591147

Epoch: 6| Step: 9
Training loss: 1.5002989768981934
Validation loss: 2.09341569741567

Epoch: 6| Step: 10
Training loss: 2.254244327545166
Validation loss: 2.087612768014272

Epoch: 6| Step: 11
Training loss: 2.484754800796509
Validation loss: 2.0842082699139914

Epoch: 6| Step: 12
Training loss: 1.8377628326416016
Validation loss: 2.096477687358856

Epoch: 6| Step: 13
Training loss: 2.391815662384033
Validation loss: 2.0877751111984253

Epoch: 8| Step: 0
Training loss: 1.7520713806152344
Validation loss: 2.0883561174074807

Epoch: 6| Step: 1
Training loss: 2.1384360790252686
Validation loss: 2.068113168080648

Epoch: 6| Step: 2
Training loss: 1.8360439538955688
Validation loss: 2.093528091907501

Epoch: 6| Step: 3
Training loss: 1.5816758871078491
Validation loss: 2.0777948101361594

Epoch: 6| Step: 4
Training loss: 1.8294670581817627
Validation loss: 2.103153169155121

Epoch: 6| Step: 5
Training loss: 2.2756450176239014
Validation loss: 2.129492402076721

Epoch: 6| Step: 6
Training loss: 2.414473056793213
Validation loss: 2.1371715664863586

Epoch: 6| Step: 7
Training loss: 1.8333407640457153
Validation loss: 2.1004601319630942

Epoch: 6| Step: 8
Training loss: 2.271124839782715
Validation loss: 2.108896772066752

Epoch: 6| Step: 9
Training loss: 2.643321990966797
Validation loss: 2.148354450861613

Epoch: 6| Step: 10
Training loss: 2.358983039855957
Validation loss: 2.1126251022020974

Epoch: 6| Step: 11
Training loss: 1.809592843055725
Validation loss: 2.128541668256124

Epoch: 6| Step: 12
Training loss: 1.6349973678588867
Validation loss: 2.1132020552953086

Epoch: 6| Step: 13
Training loss: 2.708552360534668
Validation loss: 2.1109039982159934

Epoch: 9| Step: 0
Training loss: 2.0567946434020996
Validation loss: 2.1145761410395303

Epoch: 6| Step: 1
Training loss: 1.3529784679412842
Validation loss: 2.091210663318634

Epoch: 6| Step: 2
Training loss: 2.634212017059326
Validation loss: 2.1168068448702493

Epoch: 6| Step: 3
Training loss: 2.8475570678710938
Validation loss: 2.1016736030578613

Epoch: 6| Step: 4
Training loss: 1.3441007137298584
Validation loss: 2.0821584264437356

Epoch: 6| Step: 5
Training loss: 1.729975938796997
Validation loss: 2.0996363759040833

Epoch: 6| Step: 6
Training loss: 2.6216564178466797
Validation loss: 2.0724337697029114

Epoch: 6| Step: 7
Training loss: 2.581272602081299
Validation loss: 2.08486678202947

Epoch: 6| Step: 8
Training loss: 1.2793951034545898
Validation loss: 2.0826186736424765

Epoch: 6| Step: 9
Training loss: 1.3962594270706177
Validation loss: 2.083725651105245

Epoch: 6| Step: 10
Training loss: 2.123438835144043
Validation loss: 2.07304455836614

Epoch: 6| Step: 11
Training loss: 2.491523027420044
Validation loss: 2.0723337729771933

Epoch: 6| Step: 12
Training loss: 1.9743356704711914
Validation loss: 2.0894161065419516

Epoch: 6| Step: 13
Training loss: 2.5229880809783936
Validation loss: 2.072712222735087

Epoch: 10| Step: 0
Training loss: 2.0053787231445312
Validation loss: 2.046983778476715

Epoch: 6| Step: 1
Training loss: 1.740906000137329
Validation loss: 2.074238101641337

Epoch: 6| Step: 2
Training loss: 1.7913150787353516
Validation loss: 2.0867319107055664

Epoch: 6| Step: 3
Training loss: 1.8533343076705933
Validation loss: 2.069175879160563

Epoch: 6| Step: 4
Training loss: 2.6610920429229736
Validation loss: 2.0618791778882346

Epoch: 6| Step: 5
Training loss: 1.9730830192565918
Validation loss: 2.070620119571686

Epoch: 6| Step: 6
Training loss: 2.080291509628296
Validation loss: 2.0671474734942117

Epoch: 6| Step: 7
Training loss: 2.0311269760131836
Validation loss: 2.0649656653404236

Epoch: 6| Step: 8
Training loss: 1.7492237091064453
Validation loss: 2.0718145767847695

Epoch: 6| Step: 9
Training loss: 2.2420334815979004
Validation loss: 2.091162363688151

Epoch: 6| Step: 10
Training loss: 2.461482524871826
Validation loss: 2.0750362277030945

Epoch: 6| Step: 11
Training loss: 1.708587408065796
Validation loss: 2.0489115715026855

Epoch: 6| Step: 12
Training loss: 2.565204381942749
Validation loss: 2.086236218611399

Epoch: 6| Step: 13
Training loss: 2.109107255935669
Validation loss: 2.088355521361033

Epoch: 11| Step: 0
Training loss: 2.235245704650879
Validation loss: 2.0762137373288474

Epoch: 6| Step: 1
Training loss: 1.5752079486846924
Validation loss: 2.067052185535431

Epoch: 6| Step: 2
Training loss: 2.665982723236084
Validation loss: 2.0922122796376548

Epoch: 6| Step: 3
Training loss: 1.5491628646850586
Validation loss: 2.084347426891327

Epoch: 6| Step: 4
Training loss: 2.177450656890869
Validation loss: 2.0837970773379006

Epoch: 6| Step: 5
Training loss: 2.026765823364258
Validation loss: 2.0923818747202554

Epoch: 6| Step: 6
Training loss: 2.3352293968200684
Validation loss: 2.0935662587483725

Epoch: 6| Step: 7
Training loss: 2.471376419067383
Validation loss: 2.0817962884902954

Epoch: 6| Step: 8
Training loss: 2.502039909362793
Validation loss: 2.0848398208618164

Epoch: 6| Step: 9
Training loss: 1.343976616859436
Validation loss: 2.089407444000244

Epoch: 6| Step: 10
Training loss: 1.8919442892074585
Validation loss: 2.052621841430664

Epoch: 6| Step: 11
Training loss: 1.780043363571167
Validation loss: 2.0702905654907227

Epoch: 6| Step: 12
Training loss: 1.90096116065979
Validation loss: 2.0738900303840637

Epoch: 6| Step: 13
Training loss: 2.1814608573913574
Validation loss: 2.040306051572164

Epoch: 12| Step: 0
Training loss: 1.6994988918304443
Validation loss: 2.0720707376797995

Epoch: 6| Step: 1
Training loss: 2.326277017593384
Validation loss: 2.0524024963378906

Epoch: 6| Step: 2
Training loss: 1.7797669172286987
Validation loss: 2.0864078601201377

Epoch: 6| Step: 3
Training loss: 1.893561840057373
Validation loss: 2.0621557235717773

Epoch: 6| Step: 4
Training loss: 1.6337604522705078
Validation loss: 2.083016037940979

Epoch: 6| Step: 5
Training loss: 2.104740619659424
Validation loss: 2.0766589641571045

Epoch: 6| Step: 6
Training loss: 2.064171314239502
Validation loss: 2.0722041924794516

Epoch: 6| Step: 7
Training loss: 2.1458346843719482
Validation loss: 2.071333130200704

Epoch: 6| Step: 8
Training loss: 1.839742660522461
Validation loss: 2.077755351861318

Epoch: 6| Step: 9
Training loss: 2.6230075359344482
Validation loss: 2.0871233145395913

Epoch: 6| Step: 10
Training loss: 2.433149814605713
Validation loss: 2.0844135681788125

Epoch: 6| Step: 11
Training loss: 1.6223281621932983
Validation loss: 2.0939329067866006

Epoch: 6| Step: 12
Training loss: 2.8346595764160156
Validation loss: 2.078062951564789

Epoch: 6| Step: 13
Training loss: 1.7095434665679932
Validation loss: 2.0949628750483194

Epoch: 13| Step: 0
Training loss: 2.13954758644104
Validation loss: 2.0854140520095825

Epoch: 6| Step: 1
Training loss: 2.238525867462158
Validation loss: 2.08304363489151

Epoch: 6| Step: 2
Training loss: 2.1677746772766113
Validation loss: 2.071699321269989

Epoch: 6| Step: 3
Training loss: 2.1452271938323975
Validation loss: 2.0577768683433533

Epoch: 6| Step: 4
Training loss: 2.060161590576172
Validation loss: 2.057742436726888

Epoch: 6| Step: 5
Training loss: 1.5853703022003174
Validation loss: 2.05869730313619

Epoch: 6| Step: 6
Training loss: 2.2845458984375
Validation loss: 2.0584810177485147

Epoch: 6| Step: 7
Training loss: 1.7682886123657227
Validation loss: 2.0721397002538047

Epoch: 6| Step: 8
Training loss: 1.8406238555908203
Validation loss: 2.0565587679545083

Epoch: 6| Step: 9
Training loss: 2.567706346511841
Validation loss: 2.0607629219690957

Epoch: 6| Step: 10
Training loss: 2.2585272789001465
Validation loss: 2.055869738260905

Epoch: 6| Step: 11
Training loss: 1.9790558815002441
Validation loss: 2.0541451374689736

Epoch: 6| Step: 12
Training loss: 1.9538512229919434
Validation loss: 2.065969705581665

Epoch: 6| Step: 13
Training loss: 2.097545623779297
Validation loss: 2.0550780296325684

Epoch: 14| Step: 0
Training loss: 2.369501829147339
Validation loss: 2.052374223868052

Epoch: 6| Step: 1
Training loss: 2.069268226623535
Validation loss: 2.0454928278923035

Epoch: 6| Step: 2
Training loss: 2.0472559928894043
Validation loss: 2.0693001747131348

Epoch: 6| Step: 3
Training loss: 1.8442983627319336
Validation loss: 2.0463199615478516

Epoch: 6| Step: 4
Training loss: 1.8442847728729248
Validation loss: 2.0561986168225608

Epoch: 6| Step: 5
Training loss: 1.6982338428497314
Validation loss: 2.0406813422838845

Epoch: 6| Step: 6
Training loss: 2.790933609008789
Validation loss: 2.0623940229415894

Epoch: 6| Step: 7
Training loss: 1.4403852224349976
Validation loss: 2.0365168849627175

Epoch: 6| Step: 8
Training loss: 2.6659765243530273
Validation loss: 2.0632806619008384

Epoch: 6| Step: 9
Training loss: 1.6034166812896729
Validation loss: 2.063927630583445

Epoch: 6| Step: 10
Training loss: 1.8048429489135742
Validation loss: 2.0453242460886636

Epoch: 6| Step: 11
Training loss: 1.8865982294082642
Validation loss: 2.0411706368128457

Epoch: 6| Step: 12
Training loss: 1.8685518503189087
Validation loss: 2.046732544898987

Epoch: 6| Step: 13
Training loss: 2.5049853324890137
Validation loss: 2.057910124460856

Epoch: 15| Step: 0
Training loss: 2.553285598754883
Validation loss: 2.0674787561098733

Epoch: 6| Step: 1
Training loss: 1.8923982381820679
Validation loss: 2.071364939212799

Epoch: 6| Step: 2
Training loss: 2.033356189727783
Validation loss: 2.060316264629364

Epoch: 6| Step: 3
Training loss: 1.859227180480957
Validation loss: 2.08889768520991

Epoch: 6| Step: 4
Training loss: 2.1467247009277344
Validation loss: 2.0778389970461526

Epoch: 6| Step: 5
Training loss: 2.3473026752471924
Validation loss: 2.0466121435165405

Epoch: 6| Step: 6
Training loss: 1.9279365539550781
Validation loss: 2.0534922083218894

Epoch: 6| Step: 7
Training loss: 1.785194754600525
Validation loss: 2.0662702520688376

Epoch: 6| Step: 8
Training loss: 2.4815673828125
Validation loss: 2.043504516283671

Epoch: 6| Step: 9
Training loss: 2.7520337104797363
Validation loss: 2.0251980423927307

Epoch: 6| Step: 10
Training loss: 1.6878745555877686
Validation loss: 2.0513675808906555

Epoch: 6| Step: 11
Training loss: 1.7137885093688965
Validation loss: 2.0484100381533303

Epoch: 6| Step: 12
Training loss: 1.686187982559204
Validation loss: 2.038605570793152

Epoch: 6| Step: 13
Training loss: 1.443359375
Validation loss: 2.0838216741879783

Epoch: 16| Step: 0
Training loss: 2.0010952949523926
Validation loss: 2.06861674785614

Epoch: 6| Step: 1
Training loss: 1.7352187633514404
Validation loss: 2.058173974355062

Epoch: 6| Step: 2
Training loss: 1.9039944410324097
Validation loss: 2.066956798235575

Epoch: 6| Step: 3
Training loss: 2.9483141899108887
Validation loss: 2.1049079298973083

Epoch: 6| Step: 4
Training loss: 2.2562713623046875
Validation loss: 2.0919838349024453

Epoch: 6| Step: 5
Training loss: 2.5019783973693848
Validation loss: 2.118922472000122

Epoch: 6| Step: 6
Training loss: 1.734168529510498
Validation loss: 2.119838019212087

Epoch: 6| Step: 7
Training loss: 2.3963205814361572
Validation loss: 2.1048704187075296

Epoch: 6| Step: 8
Training loss: 1.6178696155548096
Validation loss: 2.086516479651133

Epoch: 6| Step: 9
Training loss: 2.537141799926758
Validation loss: 2.091485540072123

Epoch: 6| Step: 10
Training loss: 1.6066365242004395
Validation loss: 2.0706450939178467

Epoch: 6| Step: 11
Training loss: 2.0090909004211426
Validation loss: 2.0474105874697366

Epoch: 6| Step: 12
Training loss: 1.3462547063827515
Validation loss: 2.0646168986956277

Epoch: 6| Step: 13
Training loss: 2.064310312271118
Validation loss: 2.034063676993052

Epoch: 17| Step: 0
Training loss: 2.1047401428222656
Validation loss: 2.0606552958488464

Epoch: 6| Step: 1
Training loss: 1.8834766149520874
Validation loss: 2.036863406499227

Epoch: 6| Step: 2
Training loss: 2.131720781326294
Validation loss: 2.0437039335568747

Epoch: 6| Step: 3
Training loss: 1.874570608139038
Validation loss: 2.0550492803255715

Epoch: 6| Step: 4
Training loss: 2.205174446105957
Validation loss: 2.0437179803848267

Epoch: 6| Step: 5
Training loss: 1.627918004989624
Validation loss: 2.0548897782961526

Epoch: 6| Step: 6
Training loss: 1.812410593032837
Validation loss: 2.051844755808512

Epoch: 6| Step: 7
Training loss: 2.249401807785034
Validation loss: 2.0231225887934365

Epoch: 6| Step: 8
Training loss: 1.4066574573516846
Validation loss: 2.0249914129575095

Epoch: 6| Step: 9
Training loss: 2.0497775077819824
Validation loss: 2.0405245820681253

Epoch: 6| Step: 10
Training loss: 2.3496766090393066
Validation loss: 1.9962315360705059

Epoch: 6| Step: 11
Training loss: 2.314504384994507
Validation loss: 2.0323420763015747

Epoch: 6| Step: 12
Training loss: 2.667236328125
Validation loss: 2.03224911292394

Epoch: 6| Step: 13
Training loss: 1.9741688966751099
Validation loss: 2.0396746397018433

Epoch: 18| Step: 0
Training loss: 2.582717180252075
Validation loss: 2.034442643324534

Epoch: 6| Step: 1
Training loss: 2.2689504623413086
Validation loss: 2.0211875438690186

Epoch: 6| Step: 2
Training loss: 2.052569627761841
Validation loss: 2.0538410544395447

Epoch: 6| Step: 3
Training loss: 1.5043553113937378
Validation loss: 2.038513203461965

Epoch: 6| Step: 4
Training loss: 2.5618410110473633
Validation loss: 2.040692408879598

Epoch: 6| Step: 5
Training loss: 2.133655309677124
Validation loss: 2.030179262161255

Epoch: 6| Step: 6
Training loss: 1.714574933052063
Validation loss: 2.0434830586115518

Epoch: 6| Step: 7
Training loss: 2.093860149383545
Validation loss: 2.027612805366516

Epoch: 6| Step: 8
Training loss: 1.2320446968078613
Validation loss: 2.0302115281422934

Epoch: 6| Step: 9
Training loss: 1.603823184967041
Validation loss: 2.036575118700663

Epoch: 6| Step: 10
Training loss: 2.1370949745178223
Validation loss: 2.02465691169103

Epoch: 6| Step: 11
Training loss: 2.1820430755615234
Validation loss: 2.027917762597402

Epoch: 6| Step: 12
Training loss: 1.5382165908813477
Validation loss: 2.022041896979014

Epoch: 6| Step: 13
Training loss: 2.501614570617676
Validation loss: 2.0418527722358704

Epoch: 19| Step: 0
Training loss: 1.7014130353927612
Validation loss: 2.050654967625936

Epoch: 6| Step: 1
Training loss: 1.466526746749878
Validation loss: 2.035358190536499

Epoch: 6| Step: 2
Training loss: 2.2213125228881836
Validation loss: 2.037441849708557

Epoch: 6| Step: 3
Training loss: 1.6294267177581787
Validation loss: 2.039379119873047

Epoch: 6| Step: 4
Training loss: 1.9377176761627197
Validation loss: 2.044810930887858

Epoch: 6| Step: 5
Training loss: 2.2194039821624756
Validation loss: 2.05946018298467

Epoch: 6| Step: 6
Training loss: 1.9032126665115356
Validation loss: 2.032916863759359

Epoch: 6| Step: 7
Training loss: 3.0012929439544678
Validation loss: 2.026855786641439

Epoch: 6| Step: 8
Training loss: 2.0764734745025635
Validation loss: 2.035314440727234

Epoch: 6| Step: 9
Training loss: 2.6103198528289795
Validation loss: 2.0295554200808206

Epoch: 6| Step: 10
Training loss: 2.235262870788574
Validation loss: 2.031687597433726

Epoch: 6| Step: 11
Training loss: 1.4515918493270874
Validation loss: 2.0318893591562905

Epoch: 6| Step: 12
Training loss: 1.073028564453125
Validation loss: 2.011335094769796

Epoch: 6| Step: 13
Training loss: 2.3856892585754395
Validation loss: 2.0160711805025735

Epoch: 20| Step: 0
Training loss: 1.3331084251403809
Validation loss: 2.026217977205912

Epoch: 6| Step: 1
Training loss: 2.4765872955322266
Validation loss: 2.0173867543538413

Epoch: 6| Step: 2
Training loss: 2.639129638671875
Validation loss: 2.038973311583201

Epoch: 6| Step: 3
Training loss: 2.251757860183716
Validation loss: 2.0475146770477295

Epoch: 6| Step: 4
Training loss: 1.760678768157959
Validation loss: 2.068067729473114

Epoch: 6| Step: 5
Training loss: 2.3921940326690674
Validation loss: 2.027550379435221

Epoch: 6| Step: 6
Training loss: 2.1910245418548584
Validation loss: 2.0334901809692383

Epoch: 6| Step: 7
Training loss: 1.7593845129013062
Validation loss: 2.0451435248057046

Epoch: 6| Step: 8
Training loss: 2.380955696105957
Validation loss: 2.030583620071411

Epoch: 6| Step: 9
Training loss: 1.5878857374191284
Validation loss: 2.0423338413238525

Epoch: 6| Step: 10
Training loss: 1.9155678749084473
Validation loss: 2.0368659297625222

Epoch: 6| Step: 11
Training loss: 1.3101511001586914
Validation loss: 2.0327868461608887

Epoch: 6| Step: 12
Training loss: 1.518494963645935
Validation loss: 2.018458386262258

Epoch: 6| Step: 13
Training loss: 2.440741539001465
Validation loss: 2.0325832962989807

Epoch: 21| Step: 0
Training loss: 1.799842119216919
Validation loss: 1.9981359442075093

Epoch: 6| Step: 1
Training loss: 2.0564968585968018
Validation loss: 2.02284308274587

Epoch: 6| Step: 2
Training loss: 1.8292725086212158
Validation loss: 2.018102467060089

Epoch: 6| Step: 3
Training loss: 1.677980899810791
Validation loss: 2.0471879839897156

Epoch: 6| Step: 4
Training loss: 2.7369565963745117
Validation loss: 2.042189915974935

Epoch: 6| Step: 5
Training loss: 1.8341668844223022
Validation loss: 2.0147022008895874

Epoch: 6| Step: 6
Training loss: 1.6070303916931152
Validation loss: 2.0332764387130737

Epoch: 6| Step: 7
Training loss: 2.1344759464263916
Validation loss: 2.032564640045166

Epoch: 6| Step: 8
Training loss: 1.9715145826339722
Validation loss: 2.0315422813097634

Epoch: 6| Step: 9
Training loss: 1.2230356931686401
Validation loss: 2.0274601181348166

Epoch: 6| Step: 10
Training loss: 2.4788241386413574
Validation loss: 2.025969902674357

Epoch: 6| Step: 11
Training loss: 2.065018653869629
Validation loss: 1.9848172664642334

Epoch: 6| Step: 12
Training loss: 2.311211109161377
Validation loss: 2.0209351181983948

Epoch: 6| Step: 13
Training loss: 2.0802435874938965
Validation loss: 2.0262794494628906

Epoch: 22| Step: 0
Training loss: 2.2891993522644043
Validation loss: 1.995003600915273

Epoch: 6| Step: 1
Training loss: 1.547563076019287
Validation loss: 2.019425908724467

Epoch: 6| Step: 2
Training loss: 2.2106235027313232
Validation loss: 2.0179297725359597

Epoch: 6| Step: 3
Training loss: 2.177281379699707
Validation loss: 2.0062696238358817

Epoch: 6| Step: 4
Training loss: 1.1996186971664429
Validation loss: 2.0086125334103904

Epoch: 6| Step: 5
Training loss: 2.1760644912719727
Validation loss: 2.002882500489553

Epoch: 6| Step: 6
Training loss: 1.3201634883880615
Validation loss: 1.9928586681683857

Epoch: 6| Step: 7
Training loss: 2.0148978233337402
Validation loss: 2.000250498453776

Epoch: 6| Step: 8
Training loss: 1.7728155851364136
Validation loss: 2.004680097103119

Epoch: 6| Step: 9
Training loss: 2.5968518257141113
Validation loss: 1.99293452501297

Epoch: 6| Step: 10
Training loss: 1.6906520128250122
Validation loss: 2.0196788907051086

Epoch: 6| Step: 11
Training loss: 2.2877070903778076
Validation loss: 2.04047954082489

Epoch: 6| Step: 12
Training loss: 2.296830892562866
Validation loss: 2.024072587490082

Epoch: 6| Step: 13
Training loss: 2.149315357208252
Validation loss: 2.0480316281318665

Epoch: 23| Step: 0
Training loss: 2.1865599155426025
Validation loss: 2.0477656920750937

Epoch: 6| Step: 1
Training loss: 1.7614444494247437
Validation loss: 2.051542421181997

Epoch: 6| Step: 2
Training loss: 1.400573492050171
Validation loss: 2.0693811972935996

Epoch: 6| Step: 3
Training loss: 2.2008395195007324
Validation loss: 2.0205461382865906

Epoch: 6| Step: 4
Training loss: 2.4832534790039062
Validation loss: 2.0041160186131797

Epoch: 6| Step: 5
Training loss: 1.5220088958740234
Validation loss: 1.997730294863383

Epoch: 6| Step: 6
Training loss: 1.6106555461883545
Validation loss: 2.0080323815345764

Epoch: 6| Step: 7
Training loss: 2.0301034450531006
Validation loss: 2.0383538802464805

Epoch: 6| Step: 8
Training loss: 2.1361780166625977
Validation loss: 2.008465886116028

Epoch: 6| Step: 9
Training loss: 2.29409122467041
Validation loss: 2.0049444834391275

Epoch: 6| Step: 10
Training loss: 1.8391525745391846
Validation loss: 1.9898515144983928

Epoch: 6| Step: 11
Training loss: 2.151782512664795
Validation loss: 2.010889013608297

Epoch: 6| Step: 12
Training loss: 2.383326530456543
Validation loss: 2.005133847395579

Epoch: 6| Step: 13
Training loss: 1.9970616102218628
Validation loss: 2.019860843817393

Epoch: 24| Step: 0
Training loss: 1.2568650245666504
Validation loss: 1.9962854186693828

Epoch: 6| Step: 1
Training loss: 1.365431308746338
Validation loss: 2.0030635595321655

Epoch: 6| Step: 2
Training loss: 2.293550491333008
Validation loss: 2.0252724091211953

Epoch: 6| Step: 3
Training loss: 1.7163569927215576
Validation loss: 2.0136541724205017

Epoch: 6| Step: 4
Training loss: 1.7631371021270752
Validation loss: 1.9966784715652466

Epoch: 6| Step: 5
Training loss: 2.2250914573669434
Validation loss: 2.0064289768536887

Epoch: 6| Step: 6
Training loss: 1.932386040687561
Validation loss: 2.007918973763784

Epoch: 6| Step: 7
Training loss: 2.3694589138031006
Validation loss: 2.0108484029769897

Epoch: 6| Step: 8
Training loss: 1.9631990194320679
Validation loss: 2.007061799367269

Epoch: 6| Step: 9
Training loss: 2.384248971939087
Validation loss: 2.0055857499440513

Epoch: 6| Step: 10
Training loss: 1.8683476448059082
Validation loss: 2.014255960782369

Epoch: 6| Step: 11
Training loss: 1.175627589225769
Validation loss: 2.0248457193374634

Epoch: 6| Step: 12
Training loss: 2.404601573944092
Validation loss: 2.035758455594381

Epoch: 6| Step: 13
Training loss: 2.892857313156128
Validation loss: 2.0277084708213806

Epoch: 25| Step: 0
Training loss: 1.6075035333633423
Validation loss: 2.047858019669851

Epoch: 6| Step: 1
Training loss: 1.058799386024475
Validation loss: 2.0385630329449973

Epoch: 6| Step: 2
Training loss: 2.461904287338257
Validation loss: 2.046579341093699

Epoch: 6| Step: 3
Training loss: 2.0979132652282715
Validation loss: 2.0733195145924888

Epoch: 6| Step: 4
Training loss: 1.8844783306121826
Validation loss: 2.065481682618459

Epoch: 6| Step: 5
Training loss: 1.9959897994995117
Validation loss: 2.083022395769755

Epoch: 6| Step: 6
Training loss: 1.9884873628616333
Validation loss: 2.0703659852345786

Epoch: 6| Step: 7
Training loss: 2.0015478134155273
Validation loss: 2.067103683948517

Epoch: 6| Step: 8
Training loss: 2.288008213043213
Validation loss: 2.0561172564824424

Epoch: 6| Step: 9
Training loss: 2.4936869144439697
Validation loss: 2.0374266703923545

Epoch: 6| Step: 10
Training loss: 1.539891242980957
Validation loss: 2.0428707599639893

Epoch: 6| Step: 11
Training loss: 2.291813373565674
Validation loss: 2.015868922074636

Epoch: 6| Step: 12
Training loss: 1.6550345420837402
Validation loss: 2.0027779738108316

Epoch: 6| Step: 13
Training loss: 2.2975497245788574
Validation loss: 1.971984068552653

Epoch: 26| Step: 0
Training loss: 1.6351689100265503
Validation loss: 1.997947335243225

Epoch: 6| Step: 1
Training loss: 2.2020516395568848
Validation loss: 1.9886159896850586

Epoch: 6| Step: 2
Training loss: 2.522291898727417
Validation loss: 1.9937100807825725

Epoch: 6| Step: 3
Training loss: 2.0083775520324707
Validation loss: 1.9974946180979412

Epoch: 6| Step: 4
Training loss: 2.2163047790527344
Validation loss: 2.016161878903707

Epoch: 6| Step: 5
Training loss: 1.6244041919708252
Validation loss: 2.001081347465515

Epoch: 6| Step: 6
Training loss: 2.1420302391052246
Validation loss: 1.997175971666972

Epoch: 6| Step: 7
Training loss: 1.9295103549957275
Validation loss: 2.0031121373176575

Epoch: 6| Step: 8
Training loss: 2.0648131370544434
Validation loss: 1.998212734858195

Epoch: 6| Step: 9
Training loss: 2.040041923522949
Validation loss: 2.0144949356714883

Epoch: 6| Step: 10
Training loss: 1.755232334136963
Validation loss: 1.9919045170148213

Epoch: 6| Step: 11
Training loss: 1.932747721672058
Validation loss: 2.0016677578290305

Epoch: 6| Step: 12
Training loss: 2.301752805709839
Validation loss: 1.9864266117413838

Epoch: 6| Step: 13
Training loss: 1.7677364349365234
Validation loss: 2.0370455781618753

Epoch: 27| Step: 0
Training loss: 2.0279691219329834
Validation loss: 1.9882957140604656

Epoch: 6| Step: 1
Training loss: 1.102100133895874
Validation loss: 1.9691861073176067

Epoch: 6| Step: 2
Training loss: 2.079461097717285
Validation loss: 1.9875644445419312

Epoch: 6| Step: 3
Training loss: 1.6764196157455444
Validation loss: 1.9691953659057617

Epoch: 6| Step: 4
Training loss: 1.6655919551849365
Validation loss: 2.0071951746940613

Epoch: 6| Step: 5
Training loss: 1.943926215171814
Validation loss: 1.9930664499600728

Epoch: 6| Step: 6
Training loss: 2.1763014793395996
Validation loss: 2.0235008001327515

Epoch: 6| Step: 7
Training loss: 1.881453275680542
Validation loss: 2.010485569636027

Epoch: 6| Step: 8
Training loss: 1.2813045978546143
Validation loss: 2.031490703423818

Epoch: 6| Step: 9
Training loss: 1.8692431449890137
Validation loss: 2.0153868993123374

Epoch: 6| Step: 10
Training loss: 2.4727978706359863
Validation loss: 2.036914308865865

Epoch: 6| Step: 11
Training loss: 2.719374418258667
Validation loss: 2.0731998284657798

Epoch: 6| Step: 12
Training loss: 2.0102481842041016
Validation loss: 2.080820401509603

Epoch: 6| Step: 13
Training loss: 2.5794296264648438
Validation loss: 2.0736627777417502

Epoch: 28| Step: 0
Training loss: 2.0286927223205566
Validation loss: 2.059958338737488

Epoch: 6| Step: 1
Training loss: 2.0239994525909424
Validation loss: 2.0504831870396933

Epoch: 6| Step: 2
Training loss: 1.531783103942871
Validation loss: 2.0479209820429483

Epoch: 6| Step: 3
Training loss: 1.9268450736999512
Validation loss: 2.024990121523539

Epoch: 6| Step: 4
Training loss: 1.5566495656967163
Validation loss: 2.013742963473002

Epoch: 6| Step: 5
Training loss: 2.669245719909668
Validation loss: 1.991941750049591

Epoch: 6| Step: 6
Training loss: 2.1595160961151123
Validation loss: 1.9874101479848225

Epoch: 6| Step: 7
Training loss: 2.1954457759857178
Validation loss: 1.9941562016805012

Epoch: 6| Step: 8
Training loss: 2.097877025604248
Validation loss: 1.9827816287676494

Epoch: 6| Step: 9
Training loss: 1.492781162261963
Validation loss: 1.9789408047993977

Epoch: 6| Step: 10
Training loss: 2.2420620918273926
Validation loss: 1.9802751938501995

Epoch: 6| Step: 11
Training loss: 2.0340969562530518
Validation loss: 1.9701747298240662

Epoch: 6| Step: 12
Training loss: 1.633324384689331
Validation loss: 1.987675428390503

Epoch: 6| Step: 13
Training loss: 1.8189549446105957
Validation loss: 1.990732769171397

Epoch: 29| Step: 0
Training loss: 1.4752109050750732
Validation loss: 1.9819869995117188

Epoch: 6| Step: 1
Training loss: 1.8926293849945068
Validation loss: 1.9726860920588176

Epoch: 6| Step: 2
Training loss: 2.1122474670410156
Validation loss: 2.0031275351842246

Epoch: 6| Step: 3
Training loss: 1.8609124422073364
Validation loss: 1.984662393728892

Epoch: 6| Step: 4
Training loss: 2.172090768814087
Validation loss: 1.9634943008422852

Epoch: 6| Step: 5
Training loss: 1.2575513124465942
Validation loss: 1.992060124874115

Epoch: 6| Step: 6
Training loss: 2.027475357055664
Validation loss: 1.9958310921986897

Epoch: 6| Step: 7
Training loss: 2.135885715484619
Validation loss: 1.980553150177002

Epoch: 6| Step: 8
Training loss: 2.036849021911621
Validation loss: 1.9877414504686992

Epoch: 6| Step: 9
Training loss: 1.8471441268920898
Validation loss: 1.9925480286280315

Epoch: 6| Step: 10
Training loss: 1.5527026653289795
Validation loss: 1.991266926129659

Epoch: 6| Step: 11
Training loss: 2.4365432262420654
Validation loss: 2.0011896093686423

Epoch: 6| Step: 12
Training loss: 1.689667820930481
Validation loss: 2.04733673731486

Epoch: 6| Step: 13
Training loss: 3.1839237213134766
Validation loss: 2.0457328061262765

Epoch: 30| Step: 0
Training loss: 2.598320960998535
Validation loss: 2.0365588665008545

Epoch: 6| Step: 1
Training loss: 2.2949411869049072
Validation loss: 2.0134766697883606

Epoch: 6| Step: 2
Training loss: 1.8737822771072388
Validation loss: 2.020605127016703

Epoch: 6| Step: 3
Training loss: 1.5714221000671387
Validation loss: 2.0265596310297647

Epoch: 6| Step: 4
Training loss: 1.7830930948257446
Validation loss: 2.0265695254007974

Epoch: 6| Step: 5
Training loss: 2.262767791748047
Validation loss: 1.9989118576049805

Epoch: 6| Step: 6
Training loss: 1.3069932460784912
Validation loss: 2.0087876319885254

Epoch: 6| Step: 7
Training loss: 1.779511570930481
Validation loss: 1.980553964773814

Epoch: 6| Step: 8
Training loss: 1.6069175004959106
Validation loss: 1.9909534255663555

Epoch: 6| Step: 9
Training loss: 2.0116379261016846
Validation loss: 2.013724664847056

Epoch: 6| Step: 10
Training loss: 2.123892068862915
Validation loss: 1.99542232354482

Epoch: 6| Step: 11
Training loss: 1.8702588081359863
Validation loss: 2.014199952284495

Epoch: 6| Step: 12
Training loss: 1.998949646949768
Validation loss: 1.9957529505093892

Epoch: 6| Step: 13
Training loss: 2.307105779647827
Validation loss: 2.0125407377878823

Epoch: 31| Step: 0
Training loss: 1.4228665828704834
Validation loss: 2.0046323935190835

Epoch: 6| Step: 1
Training loss: 2.230020046234131
Validation loss: 1.9982186357180278

Epoch: 6| Step: 2
Training loss: 1.5449882745742798
Validation loss: 1.99375315507253

Epoch: 6| Step: 3
Training loss: 2.192070484161377
Validation loss: 2.0072012742360434

Epoch: 6| Step: 4
Training loss: 2.410447120666504
Validation loss: 1.9873294432957966

Epoch: 6| Step: 5
Training loss: 2.199061870574951
Validation loss: 1.978765070438385

Epoch: 6| Step: 6
Training loss: 1.7178282737731934
Validation loss: 2.005130330721537

Epoch: 6| Step: 7
Training loss: 2.1497116088867188
Validation loss: 2.0242023269335427

Epoch: 6| Step: 8
Training loss: 1.762770414352417
Validation loss: 1.9939362406730652

Epoch: 6| Step: 9
Training loss: 1.754448413848877
Validation loss: 1.983726402123769

Epoch: 6| Step: 10
Training loss: 1.7814459800720215
Validation loss: 2.0144766569137573

Epoch: 6| Step: 11
Training loss: 2.1484358310699463
Validation loss: 2.02446711063385

Epoch: 6| Step: 12
Training loss: 1.8028771877288818
Validation loss: 2.0215769608815513

Epoch: 6| Step: 13
Training loss: 2.0547101497650146
Validation loss: 2.0129458705584207

Epoch: 32| Step: 0
Training loss: 2.4259183406829834
Validation loss: 2.041460394859314

Epoch: 6| Step: 1
Training loss: 1.6036138534545898
Validation loss: 2.017064650853475

Epoch: 6| Step: 2
Training loss: 1.7920928001403809
Validation loss: 2.0435486833254495

Epoch: 6| Step: 3
Training loss: 1.95664644241333
Validation loss: 2.0436903635660806

Epoch: 6| Step: 4
Training loss: 1.7641738653182983
Validation loss: 2.0535364151000977

Epoch: 6| Step: 5
Training loss: 1.9043617248535156
Validation loss: 2.0487318634986877

Epoch: 6| Step: 6
Training loss: 3.404543876647949
Validation loss: 2.0465822219848633

Epoch: 6| Step: 7
Training loss: 1.5142414569854736
Validation loss: 2.0267229874928794

Epoch: 6| Step: 8
Training loss: 1.1525276899337769
Validation loss: 2.014087120691935

Epoch: 6| Step: 9
Training loss: 2.04190731048584
Validation loss: 1.9830752611160278

Epoch: 6| Step: 10
Training loss: 2.0921692848205566
Validation loss: 1.980204959710439

Epoch: 6| Step: 11
Training loss: 2.0223288536071777
Validation loss: 2.0004706581433616

Epoch: 6| Step: 12
Training loss: 1.7718936204910278
Validation loss: 1.9904101888338726

Epoch: 6| Step: 13
Training loss: 1.8016865253448486
Validation loss: 2.007661978403727

Epoch: 33| Step: 0
Training loss: 2.1173510551452637
Validation loss: 2.0166749159495034

Epoch: 6| Step: 1
Training loss: 1.8514676094055176
Validation loss: 2.00999383131663

Epoch: 6| Step: 2
Training loss: 1.9164491891860962
Validation loss: 2.0048730969429016

Epoch: 6| Step: 3
Training loss: 2.064121723175049
Validation loss: 2.0092936754226685

Epoch: 6| Step: 4
Training loss: 1.7611234188079834
Validation loss: 2.0119149883588157

Epoch: 6| Step: 5
Training loss: 2.208804130554199
Validation loss: 2.003797729810079

Epoch: 6| Step: 6
Training loss: 2.4392952919006348
Validation loss: 1.9795902967453003

Epoch: 6| Step: 7
Training loss: 2.2755274772644043
Validation loss: 2.000580926736196

Epoch: 6| Step: 8
Training loss: 1.5472509860992432
Validation loss: 2.003888746102651

Epoch: 6| Step: 9
Training loss: 1.6968605518341064
Validation loss: 1.9827136596043904

Epoch: 6| Step: 10
Training loss: 1.757662296295166
Validation loss: 1.9937913815180461

Epoch: 6| Step: 11
Training loss: 1.9653704166412354
Validation loss: 1.9866137703259785

Epoch: 6| Step: 12
Training loss: 1.5362037420272827
Validation loss: 1.9768723448117573

Epoch: 6| Step: 13
Training loss: 1.9014081954956055
Validation loss: 1.9965447783470154

Epoch: 34| Step: 0
Training loss: 2.1364474296569824
Validation loss: 1.9954146941502888

Epoch: 6| Step: 1
Training loss: 2.0651347637176514
Validation loss: 1.9996254642804463

Epoch: 6| Step: 2
Training loss: 2.302389144897461
Validation loss: 1.9892515937487285

Epoch: 6| Step: 3
Training loss: 1.9447128772735596
Validation loss: 2.0141393542289734

Epoch: 6| Step: 4
Training loss: 2.0633583068847656
Validation loss: 2.001473903656006

Epoch: 6| Step: 5
Training loss: 1.908738613128662
Validation loss: 1.991626222928365

Epoch: 6| Step: 6
Training loss: 1.720439076423645
Validation loss: 2.0021348198254905

Epoch: 6| Step: 7
Training loss: 2.2219955921173096
Validation loss: 2.033916711807251

Epoch: 6| Step: 8
Training loss: 1.2352046966552734
Validation loss: 2.012303670247396

Epoch: 6| Step: 9
Training loss: 1.9480643272399902
Validation loss: 2.015389303366343

Epoch: 6| Step: 10
Training loss: 1.5084004402160645
Validation loss: 2.023761967817942

Epoch: 6| Step: 11
Training loss: 1.7946913242340088
Validation loss: 2.013420363267263

Epoch: 6| Step: 12
Training loss: 2.1665492057800293
Validation loss: 2.039326826731364

Epoch: 6| Step: 13
Training loss: 1.9879419803619385
Validation loss: 2.0282182693481445

Epoch: 35| Step: 0
Training loss: 1.51953125
Validation loss: 2.030139446258545

Epoch: 6| Step: 1
Training loss: 1.6974585056304932
Validation loss: 1.994625409444173

Epoch: 6| Step: 2
Training loss: 2.0255231857299805
Validation loss: 2.0136785904566445

Epoch: 6| Step: 3
Training loss: 2.255632162094116
Validation loss: 1.9992314378420513

Epoch: 6| Step: 4
Training loss: 1.6084911823272705
Validation loss: 1.9674188892046611

Epoch: 6| Step: 5
Training loss: 1.305745005607605
Validation loss: 2.0162620147069297

Epoch: 6| Step: 6
Training loss: 2.685126304626465
Validation loss: 1.9723771611849468

Epoch: 6| Step: 7
Training loss: 1.5983046293258667
Validation loss: 1.994441529115041

Epoch: 6| Step: 8
Training loss: 2.078333854675293
Validation loss: 1.9762250979741414

Epoch: 6| Step: 9
Training loss: 1.949439287185669
Validation loss: 1.9549317558606465

Epoch: 6| Step: 10
Training loss: 2.0343704223632812
Validation loss: 2.000931143760681

Epoch: 6| Step: 11
Training loss: 1.8519372940063477
Validation loss: 1.9673334956169128

Epoch: 6| Step: 12
Training loss: 1.7588510513305664
Validation loss: 1.9670281608899434

Epoch: 6| Step: 13
Training loss: 2.7306504249572754
Validation loss: 1.98286239306132

Epoch: 36| Step: 0
Training loss: 2.0596256256103516
Validation loss: 2.0043296813964844

Epoch: 6| Step: 1
Training loss: 1.4557454586029053
Validation loss: 1.9917344252268474

Epoch: 6| Step: 2
Training loss: 2.277312755584717
Validation loss: 2.0099170804023743

Epoch: 6| Step: 3
Training loss: 1.8246688842773438
Validation loss: 2.0331945419311523

Epoch: 6| Step: 4
Training loss: 1.9334467649459839
Validation loss: 2.0303064386049905

Epoch: 6| Step: 5
Training loss: 2.306483268737793
Validation loss: 2.027081867059072

Epoch: 6| Step: 6
Training loss: 2.358797788619995
Validation loss: 2.02791965007782

Epoch: 6| Step: 7
Training loss: 1.5671204328536987
Validation loss: 2.029660403728485

Epoch: 6| Step: 8
Training loss: 2.207044839859009
Validation loss: 2.0262581507364907

Epoch: 6| Step: 9
Training loss: 2.128493309020996
Validation loss: 2.0318037470181785

Epoch: 6| Step: 10
Training loss: 1.8268802165985107
Validation loss: 2.0263853867848716

Epoch: 6| Step: 11
Training loss: 2.260547399520874
Validation loss: 2.009527266025543

Epoch: 6| Step: 12
Training loss: 1.289286732673645
Validation loss: 1.991680343945821

Epoch: 6| Step: 13
Training loss: 1.7422449588775635
Validation loss: 1.997844159603119

Epoch: 37| Step: 0
Training loss: 2.2541558742523193
Validation loss: 1.9856504400571187

Epoch: 6| Step: 1
Training loss: 1.538175344467163
Validation loss: 1.9733151197433472

Epoch: 6| Step: 2
Training loss: 1.491762399673462
Validation loss: 1.967950960000356

Epoch: 6| Step: 3
Training loss: 1.6707868576049805
Validation loss: 1.9590341051419575

Epoch: 6| Step: 4
Training loss: 1.6141759157180786
Validation loss: 1.9679897824923198

Epoch: 6| Step: 5
Training loss: 1.7433984279632568
Validation loss: 1.9695539871851604

Epoch: 6| Step: 6
Training loss: 2.1009202003479004
Validation loss: 1.9897541205088298

Epoch: 6| Step: 7
Training loss: 1.5979506969451904
Validation loss: 1.9678698976834614

Epoch: 6| Step: 8
Training loss: 2.476004123687744
Validation loss: 1.9774926900863647

Epoch: 6| Step: 9
Training loss: 2.5610342025756836
Validation loss: 1.966526746749878

Epoch: 6| Step: 10
Training loss: 2.001915454864502
Validation loss: 1.9501981337865193

Epoch: 6| Step: 11
Training loss: 2.7006139755249023
Validation loss: 1.971522827943166

Epoch: 6| Step: 12
Training loss: 1.2259488105773926
Validation loss: 1.9830270210901897

Epoch: 6| Step: 13
Training loss: 2.054720878601074
Validation loss: 1.9793618718783061

Epoch: 38| Step: 0
Training loss: 1.8271737098693848
Validation loss: 1.9887113968531291

Epoch: 6| Step: 1
Training loss: 2.3679163455963135
Validation loss: 2.001155912876129

Epoch: 6| Step: 2
Training loss: 2.1350769996643066
Validation loss: 1.9847638010978699

Epoch: 6| Step: 3
Training loss: 1.5545799732208252
Validation loss: 2.0193326671918235

Epoch: 6| Step: 4
Training loss: 2.432189464569092
Validation loss: 2.0248146255811057

Epoch: 6| Step: 5
Training loss: 1.3915925025939941
Validation loss: 2.028402308622996

Epoch: 6| Step: 6
Training loss: 1.4837803840637207
Validation loss: 2.024979372819265

Epoch: 6| Step: 7
Training loss: 1.9905205965042114
Validation loss: 2.0469435850779214

Epoch: 6| Step: 8
Training loss: 1.6639258861541748
Validation loss: 2.001459280649821

Epoch: 6| Step: 9
Training loss: 1.9499415159225464
Validation loss: 2.0037993788719177

Epoch: 6| Step: 10
Training loss: 2.0889830589294434
Validation loss: 2.0285673340161643

Epoch: 6| Step: 11
Training loss: 1.7262399196624756
Validation loss: 2.0277428229649863

Epoch: 6| Step: 12
Training loss: 2.0348567962646484
Validation loss: 1.9981170892715454

Epoch: 6| Step: 13
Training loss: 1.9383108615875244
Validation loss: 2.0112510919570923

Epoch: 39| Step: 0
Training loss: 1.1627824306488037
Validation loss: 2.009593447049459

Epoch: 6| Step: 1
Training loss: 2.033623695373535
Validation loss: 2.0006312131881714

Epoch: 6| Step: 2
Training loss: 1.937692642211914
Validation loss: 1.9663079579671223

Epoch: 6| Step: 3
Training loss: 2.1118807792663574
Validation loss: 1.9630315899848938

Epoch: 6| Step: 4
Training loss: 2.935025215148926
Validation loss: 1.9617597063382466

Epoch: 6| Step: 5
Training loss: 2.324108600616455
Validation loss: 1.9762792388598125

Epoch: 6| Step: 6
Training loss: 2.230647087097168
Validation loss: 1.9720597863197327

Epoch: 6| Step: 7
Training loss: 1.4453299045562744
Validation loss: 1.9620351990063984

Epoch: 6| Step: 8
Training loss: 1.5559543371200562
Validation loss: 1.9487606287002563

Epoch: 6| Step: 9
Training loss: 1.7199037075042725
Validation loss: 1.9431730508804321

Epoch: 6| Step: 10
Training loss: 1.8814064264297485
Validation loss: 1.9511265357335408

Epoch: 6| Step: 11
Training loss: 1.1816318035125732
Validation loss: 1.9636096755663555

Epoch: 6| Step: 12
Training loss: 2.2053017616271973
Validation loss: 1.984704573949178

Epoch: 6| Step: 13
Training loss: 1.9166933298110962
Validation loss: 1.9778663118680317

Epoch: 40| Step: 0
Training loss: 1.9988561868667603
Validation loss: 1.9853808283805847

Epoch: 6| Step: 1
Training loss: 1.7577329874038696
Validation loss: 2.0003828605016074

Epoch: 6| Step: 2
Training loss: 1.8071986436843872
Validation loss: 1.9973754088083904

Epoch: 6| Step: 3
Training loss: 1.8388173580169678
Validation loss: 1.9861284494400024

Epoch: 6| Step: 4
Training loss: 1.5301772356033325
Validation loss: 1.9929554065068562

Epoch: 6| Step: 5
Training loss: 1.5044292211532593
Validation loss: 2.011644204457601

Epoch: 6| Step: 6
Training loss: 1.656315803527832
Validation loss: 2.022865653038025

Epoch: 6| Step: 7
Training loss: 1.4282987117767334
Validation loss: 2.0326938231786094

Epoch: 6| Step: 8
Training loss: 2.0589210987091064
Validation loss: 2.0001415610313416

Epoch: 6| Step: 9
Training loss: 1.9701732397079468
Validation loss: 2.0213334361712136

Epoch: 6| Step: 10
Training loss: 3.0137557983398438
Validation loss: 2.0287568966547647

Epoch: 6| Step: 11
Training loss: 1.7528865337371826
Validation loss: 2.0195088386535645

Epoch: 6| Step: 12
Training loss: 2.009493350982666
Validation loss: 2.025576730569204

Epoch: 6| Step: 13
Training loss: 2.0069241523742676
Validation loss: 1.9972891410191853

Epoch: 41| Step: 0
Training loss: 0.9172147512435913
Validation loss: 2.040524164835612

Epoch: 6| Step: 1
Training loss: 1.9998632669448853
Validation loss: 2.034955402215322

Epoch: 6| Step: 2
Training loss: 1.9518375396728516
Validation loss: 2.054420312245687

Epoch: 6| Step: 3
Training loss: 1.853098750114441
Validation loss: 2.0402122934659324

Epoch: 6| Step: 4
Training loss: 2.326892375946045
Validation loss: 2.0613864262898765

Epoch: 6| Step: 5
Training loss: 1.5275628566741943
Validation loss: 2.068774461746216

Epoch: 6| Step: 6
Training loss: 2.350184440612793
Validation loss: 2.032337208588918

Epoch: 6| Step: 7
Training loss: 2.4657323360443115
Validation loss: 2.0380712151527405

Epoch: 6| Step: 8
Training loss: 1.782219648361206
Validation loss: 2.0225194692611694

Epoch: 6| Step: 9
Training loss: 1.8024604320526123
Validation loss: 2.020300288995107

Epoch: 6| Step: 10
Training loss: 1.5910530090332031
Validation loss: 2.0178996324539185

Epoch: 6| Step: 11
Training loss: 1.969801425933838
Validation loss: 1.9843659400939941

Epoch: 6| Step: 12
Training loss: 1.952617883682251
Validation loss: 2.0044713219006858

Epoch: 6| Step: 13
Training loss: 2.2215499877929688
Validation loss: 1.9836018681526184

Epoch: 42| Step: 0
Training loss: 1.7619779109954834
Validation loss: 2.0013298789660134

Epoch: 6| Step: 1
Training loss: 1.7833505868911743
Validation loss: 1.959723452727

Epoch: 6| Step: 2
Training loss: 2.383725881576538
Validation loss: 1.9972290992736816

Epoch: 6| Step: 3
Training loss: 2.278341054916382
Validation loss: 1.9691786170005798

Epoch: 6| Step: 4
Training loss: 1.7879886627197266
Validation loss: 1.981597940127055

Epoch: 6| Step: 5
Training loss: 1.5478107929229736
Validation loss: 1.9978613257408142

Epoch: 6| Step: 6
Training loss: 1.8003510236740112
Validation loss: 1.9803741176923115

Epoch: 6| Step: 7
Training loss: 1.244552731513977
Validation loss: 1.9844245115915935

Epoch: 6| Step: 8
Training loss: 1.596160888671875
Validation loss: 2.0308058857917786

Epoch: 6| Step: 9
Training loss: 2.281566858291626
Validation loss: 2.0359802643458047

Epoch: 6| Step: 10
Training loss: 2.419724941253662
Validation loss: 2.0320282578468323

Epoch: 6| Step: 11
Training loss: 2.082341194152832
Validation loss: 2.0466702580451965

Epoch: 6| Step: 12
Training loss: 1.721455693244934
Validation loss: 2.017618934313456

Epoch: 6| Step: 13
Training loss: 1.8201735019683838
Validation loss: 2.0147149761517844

Epoch: 43| Step: 0
Training loss: 1.8078839778900146
Validation loss: 2.010116616884867

Epoch: 6| Step: 1
Training loss: 1.901108741760254
Validation loss: 2.010144054889679

Epoch: 6| Step: 2
Training loss: 1.5606014728546143
Validation loss: 2.0086971322695413

Epoch: 6| Step: 3
Training loss: 1.9182219505310059
Validation loss: 1.9869640270868938

Epoch: 6| Step: 4
Training loss: 2.159712314605713
Validation loss: 1.9866307775179546

Epoch: 6| Step: 5
Training loss: 2.0308525562286377
Validation loss: 1.9609463214874268

Epoch: 6| Step: 6
Training loss: 2.4119672775268555
Validation loss: 1.9579980969429016

Epoch: 6| Step: 7
Training loss: 1.2285172939300537
Validation loss: 1.9662173787752788

Epoch: 6| Step: 8
Training loss: 1.5950993299484253
Validation loss: 1.9644534190495808

Epoch: 6| Step: 9
Training loss: 2.049295663833618
Validation loss: 1.9696325461069744

Epoch: 6| Step: 10
Training loss: 1.844842553138733
Validation loss: 1.9894164005915325

Epoch: 6| Step: 11
Training loss: 2.3145365715026855
Validation loss: 1.9699758092562358

Epoch: 6| Step: 12
Training loss: 2.0904033184051514
Validation loss: 1.9880690574645996

Epoch: 6| Step: 13
Training loss: 1.8022345304489136
Validation loss: 1.9621170163154602

Epoch: 44| Step: 0
Training loss: 2.3147947788238525
Validation loss: 1.975646734237671

Epoch: 6| Step: 1
Training loss: 1.402818202972412
Validation loss: 2.0121867259343467

Epoch: 6| Step: 2
Training loss: 1.6736167669296265
Validation loss: 2.0419824520746865

Epoch: 6| Step: 3
Training loss: 1.620595932006836
Validation loss: 2.0266583959261575

Epoch: 6| Step: 4
Training loss: 1.1116211414337158
Validation loss: 2.01608008146286

Epoch: 6| Step: 5
Training loss: 2.3381142616271973
Validation loss: 2.0613771279652915

Epoch: 6| Step: 6
Training loss: 2.1612491607666016
Validation loss: 2.0374911228815713

Epoch: 6| Step: 7
Training loss: 1.2692656517028809
Validation loss: 2.0413496494293213

Epoch: 6| Step: 8
Training loss: 2.3580760955810547
Validation loss: 2.0550904075304666

Epoch: 6| Step: 9
Training loss: 2.093467950820923
Validation loss: 2.0262491106987

Epoch: 6| Step: 10
Training loss: 2.0905308723449707
Validation loss: 1.967861811319987

Epoch: 6| Step: 11
Training loss: 2.0261282920837402
Validation loss: 1.9928014278411865

Epoch: 6| Step: 12
Training loss: 1.788118839263916
Validation loss: 1.991126298904419

Epoch: 6| Step: 13
Training loss: 2.253729820251465
Validation loss: 1.9520554741223652

Epoch: 45| Step: 0
Training loss: 1.6317775249481201
Validation loss: 1.9720101753870647

Epoch: 6| Step: 1
Training loss: 1.9101800918579102
Validation loss: 1.9717073837916057

Epoch: 6| Step: 2
Training loss: 2.1880061626434326
Validation loss: 1.9784413774808247

Epoch: 6| Step: 3
Training loss: 1.962592601776123
Validation loss: 1.9707318345705669

Epoch: 6| Step: 4
Training loss: 2.048527240753174
Validation loss: 1.9624803463617961

Epoch: 6| Step: 5
Training loss: 2.0450730323791504
Validation loss: 1.9749308228492737

Epoch: 6| Step: 6
Training loss: 1.3133389949798584
Validation loss: 1.9938830335934956

Epoch: 6| Step: 7
Training loss: 1.3956248760223389
Validation loss: 1.9836403330167134

Epoch: 6| Step: 8
Training loss: 1.7751022577285767
Validation loss: 1.9810189803441365

Epoch: 6| Step: 9
Training loss: 1.6526007652282715
Validation loss: 2.0004049142201743

Epoch: 6| Step: 10
Training loss: 2.666369676589966
Validation loss: 2.027317146460215

Epoch: 6| Step: 11
Training loss: 1.7196626663208008
Validation loss: 2.012055218219757

Epoch: 6| Step: 12
Training loss: 1.88948655128479
Validation loss: 2.0175193349520364

Epoch: 6| Step: 13
Training loss: 2.3601279258728027
Validation loss: 2.001150588194529

Epoch: 46| Step: 0
Training loss: 1.9860851764678955
Validation loss: 2.006884495417277

Epoch: 6| Step: 1
Training loss: 1.7774734497070312
Validation loss: 2.0026477177937827

Epoch: 6| Step: 2
Training loss: 1.897080421447754
Validation loss: 1.9761804739634197

Epoch: 6| Step: 3
Training loss: 1.9624714851379395
Validation loss: 1.9789046049118042

Epoch: 6| Step: 4
Training loss: 2.1152143478393555
Validation loss: 1.9776252110799153

Epoch: 6| Step: 5
Training loss: 1.8056870698928833
Validation loss: 1.9847423235575359

Epoch: 6| Step: 6
Training loss: 2.351081371307373
Validation loss: 1.9709784587224324

Epoch: 6| Step: 7
Training loss: 1.8033738136291504
Validation loss: 1.9697794516881306

Epoch: 6| Step: 8
Training loss: 2.258105754852295
Validation loss: 1.9778416554133098

Epoch: 6| Step: 9
Training loss: 2.0244922637939453
Validation loss: 1.9772655566533406

Epoch: 6| Step: 10
Training loss: 1.7025032043457031
Validation loss: 1.976888120174408

Epoch: 6| Step: 11
Training loss: 1.6201300621032715
Validation loss: 1.968776285648346

Epoch: 6| Step: 12
Training loss: 1.2051167488098145
Validation loss: 1.9765731692314148

Epoch: 6| Step: 13
Training loss: 2.3002777099609375
Validation loss: 1.9535892804463704

Epoch: 47| Step: 0
Training loss: 1.5330548286437988
Validation loss: 1.9719103177388508

Epoch: 6| Step: 1
Training loss: 1.676977276802063
Validation loss: 1.975235362847646

Epoch: 6| Step: 2
Training loss: 1.5839745998382568
Validation loss: 1.9977743029594421

Epoch: 6| Step: 3
Training loss: 2.1301965713500977
Validation loss: 2.004750430583954

Epoch: 6| Step: 4
Training loss: 2.157646656036377
Validation loss: 2.041419744491577

Epoch: 6| Step: 5
Training loss: 1.740661382675171
Validation loss: 2.020577689011892

Epoch: 6| Step: 6
Training loss: 1.7737690210342407
Validation loss: 2.063334027926127

Epoch: 6| Step: 7
Training loss: 2.2696011066436768
Validation loss: 2.0690102179845176

Epoch: 6| Step: 8
Training loss: 1.5127723217010498
Validation loss: 2.0456231435139975

Epoch: 6| Step: 9
Training loss: 2.128739356994629
Validation loss: 2.06064639488856

Epoch: 6| Step: 10
Training loss: 1.7085950374603271
Validation loss: 2.0684215426445007

Epoch: 6| Step: 11
Training loss: 2.242161273956299
Validation loss: 2.0424672762552896

Epoch: 6| Step: 12
Training loss: 1.7032690048217773
Validation loss: 2.0381826162338257

Epoch: 6| Step: 13
Training loss: 2.1029348373413086
Validation loss: 2.021106004714966

Epoch: 48| Step: 0
Training loss: 2.708688974380493
Validation loss: 1.999277134736379

Epoch: 6| Step: 1
Training loss: 1.5863620042800903
Validation loss: 2.0003371834754944

Epoch: 6| Step: 2
Training loss: 1.8001446723937988
Validation loss: 1.9904241760571797

Epoch: 6| Step: 3
Training loss: 2.324425458908081
Validation loss: 1.9773027102152507

Epoch: 6| Step: 4
Training loss: 1.8098607063293457
Validation loss: 2.010479728380839

Epoch: 6| Step: 5
Training loss: 1.1021876335144043
Validation loss: 1.9842996795972188

Epoch: 6| Step: 6
Training loss: 1.725407361984253
Validation loss: 1.9832829435666401

Epoch: 6| Step: 7
Training loss: 1.7425792217254639
Validation loss: 1.968015432357788

Epoch: 6| Step: 8
Training loss: 2.429276466369629
Validation loss: 1.9896406730016072

Epoch: 6| Step: 9
Training loss: 2.2646701335906982
Validation loss: 1.9918560981750488

Epoch: 6| Step: 10
Training loss: 1.5331207513809204
Validation loss: 1.9859692653020222

Epoch: 6| Step: 11
Training loss: 1.6485230922698975
Validation loss: 2.017590125401815

Epoch: 6| Step: 12
Training loss: 2.10129976272583
Validation loss: 2.0076409578323364

Epoch: 6| Step: 13
Training loss: 1.3273255825042725
Validation loss: 1.9879764715830486

Epoch: 49| Step: 0
Training loss: 2.2890474796295166
Validation loss: 2.001005550225576

Epoch: 6| Step: 1
Training loss: 1.963294267654419
Validation loss: 2.003056764602661

Epoch: 6| Step: 2
Training loss: 2.06257963180542
Validation loss: 1.97409588098526

Epoch: 6| Step: 3
Training loss: 1.3513209819793701
Validation loss: 1.9878616134325664

Epoch: 6| Step: 4
Training loss: 2.334427833557129
Validation loss: 2.001106023788452

Epoch: 6| Step: 5
Training loss: 1.546349048614502
Validation loss: 2.002123216787974

Epoch: 6| Step: 6
Training loss: 1.5702975988388062
Validation loss: 2.0156859954198203

Epoch: 6| Step: 7
Training loss: 2.2271242141723633
Validation loss: 2.0404504934946694

Epoch: 6| Step: 8
Training loss: 2.219367027282715
Validation loss: 2.0291409889856973

Epoch: 6| Step: 9
Training loss: 1.7413361072540283
Validation loss: 2.0241475900014243

Epoch: 6| Step: 10
Training loss: 1.6320221424102783
Validation loss: 2.010407110055288

Epoch: 6| Step: 11
Training loss: 1.5447406768798828
Validation loss: 2.0203163226445517

Epoch: 6| Step: 12
Training loss: 2.03812837600708
Validation loss: 2.0035261114438376

Epoch: 6| Step: 13
Training loss: 1.488081693649292
Validation loss: 2.013455410798391

Epoch: 50| Step: 0
Training loss: 1.4644235372543335
Validation loss: 2.0283541679382324

Epoch: 6| Step: 1
Training loss: 1.786189317703247
Validation loss: 2.0120224952697754

Epoch: 6| Step: 2
Training loss: 1.5481510162353516
Validation loss: 2.0182288686434426

Epoch: 6| Step: 3
Training loss: 1.7024142742156982
Validation loss: 2.000877539316813

Epoch: 6| Step: 4
Training loss: 1.7564406394958496
Validation loss: 2.0367893179257712

Epoch: 6| Step: 5
Training loss: 2.2890024185180664
Validation loss: 2.0389260252316794

Epoch: 6| Step: 6
Training loss: 2.112154722213745
Validation loss: 2.033071597417196

Epoch: 6| Step: 7
Training loss: 1.7030292749404907
Validation loss: 2.043790419896444

Epoch: 6| Step: 8
Training loss: 1.9628294706344604
Validation loss: 2.018246591091156

Epoch: 6| Step: 9
Training loss: 1.82077956199646
Validation loss: 2.020362595717112

Epoch: 6| Step: 10
Training loss: 2.0443549156188965
Validation loss: 2.0293123920758567

Epoch: 6| Step: 11
Training loss: 2.1005477905273438
Validation loss: 2.00840030113856

Epoch: 6| Step: 12
Training loss: 1.9160794019699097
Validation loss: 2.0140000581741333

Epoch: 6| Step: 13
Training loss: 1.8031193017959595
Validation loss: 2.0037956635157266

Epoch: 51| Step: 0
Training loss: 2.020650863647461
Validation loss: 1.9764124155044556

Epoch: 6| Step: 1
Training loss: 2.3694007396698
Validation loss: 2.0175611774126687

Epoch: 6| Step: 2
Training loss: 1.4084173440933228
Validation loss: 1.9639956156412761

Epoch: 6| Step: 3
Training loss: 1.4285826683044434
Validation loss: 1.9857941071192424

Epoch: 6| Step: 4
Training loss: 2.4314379692077637
Validation loss: 1.994438072045644

Epoch: 6| Step: 5
Training loss: 1.6877827644348145
Validation loss: 2.014578382174174

Epoch: 6| Step: 6
Training loss: 1.764961838722229
Validation loss: 2.0031179189682007

Epoch: 6| Step: 7
Training loss: 2.072511911392212
Validation loss: 2.0166117548942566

Epoch: 6| Step: 8
Training loss: 1.5415606498718262
Validation loss: 2.052816609541575

Epoch: 6| Step: 9
Training loss: 1.8888719081878662
Validation loss: 2.014094094435374

Epoch: 6| Step: 10
Training loss: 1.3128358125686646
Validation loss: 2.0098691980044046

Epoch: 6| Step: 11
Training loss: 1.5882381200790405
Validation loss: 2.0076534946759543

Epoch: 6| Step: 12
Training loss: 2.458606243133545
Validation loss: 1.9981361031532288

Epoch: 6| Step: 13
Training loss: 1.684159755706787
Validation loss: 2.020891527334849

Epoch: 52| Step: 0
Training loss: 1.8305338621139526
Validation loss: 2.029227336247762

Epoch: 6| Step: 1
Training loss: 1.651409387588501
Validation loss: 2.023221949736277

Epoch: 6| Step: 2
Training loss: 2.587580919265747
Validation loss: 2.022032300631205

Epoch: 6| Step: 3
Training loss: 1.3787221908569336
Validation loss: 1.9940899809201558

Epoch: 6| Step: 4
Training loss: 1.805977702140808
Validation loss: 2.0071048935254416

Epoch: 6| Step: 5
Training loss: 1.5812652111053467
Validation loss: 2.029955724875132

Epoch: 6| Step: 6
Training loss: 1.7224721908569336
Validation loss: 2.0205690066019693

Epoch: 6| Step: 7
Training loss: 1.9708061218261719
Validation loss: 1.9914562702178955

Epoch: 6| Step: 8
Training loss: 1.9074718952178955
Validation loss: 2.0272164344787598

Epoch: 6| Step: 9
Training loss: 1.3537880182266235
Validation loss: 2.026898761590322

Epoch: 6| Step: 10
Training loss: 1.563143014907837
Validation loss: 1.9940598408381145

Epoch: 6| Step: 11
Training loss: 2.776130199432373
Validation loss: 2.0212746063868203

Epoch: 6| Step: 12
Training loss: 1.8696218729019165
Validation loss: 2.011285205682119

Epoch: 6| Step: 13
Training loss: 1.7483539581298828
Validation loss: 1.9900747338930767

Epoch: 53| Step: 0
Training loss: 2.2482872009277344
Validation loss: 2.0045719146728516

Epoch: 6| Step: 1
Training loss: 1.3735346794128418
Validation loss: 1.9988788763682048

Epoch: 6| Step: 2
Training loss: 2.269571304321289
Validation loss: 1.988758663336436

Epoch: 6| Step: 3
Training loss: 1.2241262197494507
Validation loss: 1.9875469009081523

Epoch: 6| Step: 4
Training loss: 1.9396241903305054
Validation loss: 1.9932988087336223

Epoch: 6| Step: 5
Training loss: 1.854395866394043
Validation loss: 2.0041322708129883

Epoch: 6| Step: 6
Training loss: 1.3369559049606323
Validation loss: 1.991434653600057

Epoch: 6| Step: 7
Training loss: 1.7047460079193115
Validation loss: 2.0052242477734885

Epoch: 6| Step: 8
Training loss: 1.7013821601867676
Validation loss: 2.0320090452829995

Epoch: 6| Step: 9
Training loss: 2.1869025230407715
Validation loss: 2.033117691675822

Epoch: 6| Step: 10
Training loss: 1.8359572887420654
Validation loss: 2.031220634778341

Epoch: 6| Step: 11
Training loss: 1.540095567703247
Validation loss: 2.0473758578300476

Epoch: 6| Step: 12
Training loss: 2.5140719413757324
Validation loss: 2.033455193042755

Epoch: 6| Step: 13
Training loss: 1.9853724241256714
Validation loss: 2.0362560749053955

Epoch: 54| Step: 0
Training loss: 1.7371196746826172
Validation loss: 2.0201028982798257

Epoch: 6| Step: 1
Training loss: 0.9772396087646484
Validation loss: 2.0100067257881165

Epoch: 6| Step: 2
Training loss: 2.700460433959961
Validation loss: 2.0086891055107117

Epoch: 6| Step: 3
Training loss: 1.865770936012268
Validation loss: 2.0254439314206443

Epoch: 6| Step: 4
Training loss: 1.711256504058838
Validation loss: 2.0028533140818277

Epoch: 6| Step: 5
Training loss: 1.3923163414001465
Validation loss: 2.003786305586497

Epoch: 6| Step: 6
Training loss: 1.7364044189453125
Validation loss: 2.009998857975006

Epoch: 6| Step: 7
Training loss: 1.9089919328689575
Validation loss: 2.005931079387665

Epoch: 6| Step: 8
Training loss: 1.7360877990722656
Validation loss: 1.9970081051190693

Epoch: 6| Step: 9
Training loss: 2.1817500591278076
Validation loss: 2.002747356891632

Epoch: 6| Step: 10
Training loss: 1.6887233257293701
Validation loss: 1.9669870734214783

Epoch: 6| Step: 11
Training loss: 1.9602768421173096
Validation loss: 1.9723957180976868

Epoch: 6| Step: 12
Training loss: 2.003330707550049
Validation loss: 1.9741239547729492

Epoch: 6| Step: 13
Training loss: 1.9713597297668457
Validation loss: 1.9841585159301758

Epoch: 55| Step: 0
Training loss: 1.596632719039917
Validation loss: 1.9804486433664958

Epoch: 6| Step: 1
Training loss: 1.9561532735824585
Validation loss: 1.968457281589508

Epoch: 6| Step: 2
Training loss: 1.7115447521209717
Validation loss: 1.9844177961349487

Epoch: 6| Step: 3
Training loss: 2.086902618408203
Validation loss: 2.0056543350219727

Epoch: 6| Step: 4
Training loss: 1.8831868171691895
Validation loss: 1.9926294684410095

Epoch: 6| Step: 5
Training loss: 1.6457490921020508
Validation loss: 2.0092285871505737

Epoch: 6| Step: 6
Training loss: 1.8120789527893066
Validation loss: 2.019483268260956

Epoch: 6| Step: 7
Training loss: 1.0955708026885986
Validation loss: 2.0165834029515586

Epoch: 6| Step: 8
Training loss: 1.6683969497680664
Validation loss: 2.016440471013387

Epoch: 6| Step: 9
Training loss: 2.1433305740356445
Validation loss: 2.007933338483175

Epoch: 6| Step: 10
Training loss: 1.7343249320983887
Validation loss: 2.0324040055274963

Epoch: 6| Step: 11
Training loss: 2.066723585128784
Validation loss: 2.0283673206965127

Epoch: 6| Step: 12
Training loss: 1.935023546218872
Validation loss: 2.025928715864817

Epoch: 6| Step: 13
Training loss: 2.048825263977051
Validation loss: 2.0333586931228638

Epoch: 56| Step: 0
Training loss: 1.7731972932815552
Validation loss: 2.021225114663442

Epoch: 6| Step: 1
Training loss: 2.179074287414551
Validation loss: 2.034791866938273

Epoch: 6| Step: 2
Training loss: 1.6306769847869873
Validation loss: 2.02223672469457

Epoch: 6| Step: 3
Training loss: 2.117663860321045
Validation loss: 2.0332327087720237

Epoch: 6| Step: 4
Training loss: 1.8266371488571167
Validation loss: 2.0540398160616555

Epoch: 6| Step: 5
Training loss: 1.4148802757263184
Validation loss: 2.021948277950287

Epoch: 6| Step: 6
Training loss: 1.7025866508483887
Validation loss: 1.9963754614194233

Epoch: 6| Step: 7
Training loss: 2.0200328826904297
Validation loss: 2.0491401155789695

Epoch: 6| Step: 8
Training loss: 2.2421135902404785
Validation loss: 2.025983134905497

Epoch: 6| Step: 9
Training loss: 2.215682029724121
Validation loss: 2.021929224332174

Epoch: 6| Step: 10
Training loss: 2.064466714859009
Validation loss: 2.0212701559066772

Epoch: 6| Step: 11
Training loss: 1.1201294660568237
Validation loss: 2.0242669383684793

Epoch: 6| Step: 12
Training loss: 1.7605812549591064
Validation loss: 2.042496661345164

Epoch: 6| Step: 13
Training loss: 1.3700895309448242
Validation loss: 2.021536628405253

Epoch: 57| Step: 0
Training loss: 2.3354649543762207
Validation loss: 2.0140538215637207

Epoch: 6| Step: 1
Training loss: 2.071357011795044
Validation loss: 2.010228157043457

Epoch: 6| Step: 2
Training loss: 1.419559121131897
Validation loss: 1.9930363694826763

Epoch: 6| Step: 3
Training loss: 2.416038751602173
Validation loss: 1.986388107140859

Epoch: 6| Step: 4
Training loss: 1.752440333366394
Validation loss: 1.977420171101888

Epoch: 6| Step: 5
Training loss: 1.8292268514633179
Validation loss: 1.9819371898969014

Epoch: 6| Step: 6
Training loss: 1.941144347190857
Validation loss: 1.9973682363828023

Epoch: 6| Step: 7
Training loss: 1.7828387022018433
Validation loss: 1.9952655831972759

Epoch: 6| Step: 8
Training loss: 1.7214548587799072
Validation loss: 1.9851363102595012

Epoch: 6| Step: 9
Training loss: 1.7949837446212769
Validation loss: 2.018578072388967

Epoch: 6| Step: 10
Training loss: 1.156552791595459
Validation loss: 2.0286409854888916

Epoch: 6| Step: 11
Training loss: 1.6169021129608154
Validation loss: 1.9937108159065247

Epoch: 6| Step: 12
Training loss: 1.2553895711898804
Validation loss: 2.0213137666384378

Epoch: 6| Step: 13
Training loss: 2.1372177600860596
Validation loss: 1.9998519817988079

Epoch: 58| Step: 0
Training loss: 1.997959852218628
Validation loss: 2.0093999902407327

Epoch: 6| Step: 1
Training loss: 1.683365821838379
Validation loss: 2.0098052620887756

Epoch: 6| Step: 2
Training loss: 2.502270460128784
Validation loss: 1.9995369116465251

Epoch: 6| Step: 3
Training loss: 1.3212816715240479
Validation loss: 2.0043751200040183

Epoch: 6| Step: 4
Training loss: 1.823918104171753
Validation loss: 2.00052672624588

Epoch: 6| Step: 5
Training loss: 1.6393311023712158
Validation loss: 1.9966793258984883

Epoch: 6| Step: 6
Training loss: 1.027302622795105
Validation loss: 1.995999534924825

Epoch: 6| Step: 7
Training loss: 2.1825203895568848
Validation loss: 1.9950397213300068

Epoch: 6| Step: 8
Training loss: 2.5654296875
Validation loss: 2.000026762485504

Epoch: 6| Step: 9
Training loss: 1.5906850099563599
Validation loss: 1.9904057780901592

Epoch: 6| Step: 10
Training loss: 1.2287001609802246
Validation loss: 1.9986005624135335

Epoch: 6| Step: 11
Training loss: 2.2589476108551025
Validation loss: 2.001675009727478

Epoch: 6| Step: 12
Training loss: 2.0856902599334717
Validation loss: 2.022744655609131

Epoch: 6| Step: 13
Training loss: 1.6599671840667725
Validation loss: 2.051432450612386

Epoch: 59| Step: 0
Training loss: 1.6445581912994385
Validation loss: 2.0689183870951333

Epoch: 6| Step: 1
Training loss: 1.8481203317642212
Validation loss: 2.114704747994741

Epoch: 6| Step: 2
Training loss: 1.5415889024734497
Validation loss: 2.097660263379415

Epoch: 6| Step: 3
Training loss: 2.021206855773926
Validation loss: 2.116902311642965

Epoch: 6| Step: 4
Training loss: 1.490099310874939
Validation loss: 2.124312996864319

Epoch: 6| Step: 5
Training loss: 2.5588672161102295
Validation loss: 2.083480874697367

Epoch: 6| Step: 6
Training loss: 1.8473799228668213
Validation loss: 2.0846826434135437

Epoch: 6| Step: 7
Training loss: 1.8812605142593384
Validation loss: 2.0909522573153176

Epoch: 6| Step: 8
Training loss: 2.4461019039154053
Validation loss: 2.0407015482584634

Epoch: 6| Step: 9
Training loss: 1.7674437761306763
Validation loss: 2.0193853179613748

Epoch: 6| Step: 10
Training loss: 2.0307679176330566
Validation loss: 1.9953814148902893

Epoch: 6| Step: 11
Training loss: 1.1666769981384277
Validation loss: 2.005301058292389

Epoch: 6| Step: 12
Training loss: 2.1145918369293213
Validation loss: 1.9918316801389058

Epoch: 6| Step: 13
Training loss: 1.3055086135864258
Validation loss: 2.0038366317749023

Epoch: 60| Step: 0
Training loss: 1.4540178775787354
Validation loss: 2.0040589968363443

Epoch: 6| Step: 1
Training loss: 1.404003620147705
Validation loss: 1.986818830172221

Epoch: 6| Step: 2
Training loss: 1.5713024139404297
Validation loss: 2.0117477774620056

Epoch: 6| Step: 3
Training loss: 2.8976902961730957
Validation loss: 1.9874610702196758

Epoch: 6| Step: 4
Training loss: 1.5721700191497803
Validation loss: 2.002741058667501

Epoch: 6| Step: 5
Training loss: 2.1913251876831055
Validation loss: 2.009092708428701

Epoch: 6| Step: 6
Training loss: 2.004826545715332
Validation loss: 2.0056807001431785

Epoch: 6| Step: 7
Training loss: 1.176269292831421
Validation loss: 1.9773891766866047

Epoch: 6| Step: 8
Training loss: 1.3597216606140137
Validation loss: 2.003275990486145

Epoch: 6| Step: 9
Training loss: 1.805411458015442
Validation loss: 2.0102782050768533

Epoch: 6| Step: 10
Training loss: 1.5763832330703735
Validation loss: 1.9670517643292744

Epoch: 6| Step: 11
Training loss: 1.7619330883026123
Validation loss: 2.030091861883799

Epoch: 6| Step: 12
Training loss: 2.213696002960205
Validation loss: 2.0457528233528137

Epoch: 6| Step: 13
Training loss: 2.1109461784362793
Validation loss: 2.06010111172994

Epoch: 61| Step: 0
Training loss: 1.40838623046875
Validation loss: 2.066215395927429

Epoch: 6| Step: 1
Training loss: 2.250183582305908
Validation loss: 2.0670923391977944

Epoch: 6| Step: 2
Training loss: 1.7929356098175049
Validation loss: 2.044343948364258

Epoch: 6| Step: 3
Training loss: 2.2227418422698975
Validation loss: 2.0740426778793335

Epoch: 6| Step: 4
Training loss: 2.218921184539795
Validation loss: 2.0649388432502747

Epoch: 6| Step: 5
Training loss: 1.4989876747131348
Validation loss: 2.0219544768333435

Epoch: 6| Step: 6
Training loss: 1.1427080631256104
Validation loss: 2.0173232158025107

Epoch: 6| Step: 7
Training loss: 2.0745368003845215
Validation loss: 2.0329837799072266

Epoch: 6| Step: 8
Training loss: 1.8077648878097534
Validation loss: 2.017228682835897

Epoch: 6| Step: 9
Training loss: 1.8569695949554443
Validation loss: 1.9940867225329082

Epoch: 6| Step: 10
Training loss: 2.0412566661834717
Validation loss: 2.004564642906189

Epoch: 6| Step: 11
Training loss: 1.6392678022384644
Validation loss: 2.031266450881958

Epoch: 6| Step: 12
Training loss: 1.6245627403259277
Validation loss: 2.0133070747057595

Epoch: 6| Step: 13
Training loss: 1.5448143482208252
Validation loss: 2.021970272064209

Epoch: 62| Step: 0
Training loss: 1.3374576568603516
Validation loss: 2.0255287488301597

Epoch: 6| Step: 1
Training loss: 2.1878368854522705
Validation loss: 2.0264951586723328

Epoch: 6| Step: 2
Training loss: 2.001383066177368
Validation loss: 2.0272211829821267

Epoch: 6| Step: 3
Training loss: 1.551213026046753
Validation loss: 2.0163655082384744

Epoch: 6| Step: 4
Training loss: 1.731954574584961
Validation loss: 2.015893359978994

Epoch: 6| Step: 5
Training loss: 1.4441593885421753
Validation loss: 2.0202492078145347

Epoch: 6| Step: 6
Training loss: 2.0956199169158936
Validation loss: 2.010841687520345

Epoch: 6| Step: 7
Training loss: 1.7295444011688232
Validation loss: 2.0054606596628823

Epoch: 6| Step: 8
Training loss: 1.2189257144927979
Validation loss: 2.0165059566497803

Epoch: 6| Step: 9
Training loss: 1.8526582717895508
Validation loss: 2.008573035399119

Epoch: 6| Step: 10
Training loss: 1.345618486404419
Validation loss: 1.9987297058105469

Epoch: 6| Step: 11
Training loss: 2.619208335876465
Validation loss: 1.9982911149660747

Epoch: 6| Step: 12
Training loss: 1.5151622295379639
Validation loss: 2.0110365748405457

Epoch: 6| Step: 13
Training loss: 2.0883641242980957
Validation loss: 2.008486886819204

Epoch: 63| Step: 0
Training loss: 1.7772527933120728
Validation loss: 2.0258423686027527

Epoch: 6| Step: 1
Training loss: 1.2934954166412354
Validation loss: 2.0422651966412864

Epoch: 6| Step: 2
Training loss: 2.030017375946045
Validation loss: 2.008301317691803

Epoch: 6| Step: 3
Training loss: 1.830962061882019
Validation loss: 2.040481984615326

Epoch: 6| Step: 4
Training loss: 1.559417724609375
Validation loss: 2.0113427440325418

Epoch: 6| Step: 5
Training loss: 1.5937650203704834
Validation loss: 2.0312443176905313

Epoch: 6| Step: 6
Training loss: 2.278319835662842
Validation loss: 2.009871164957682

Epoch: 6| Step: 7
Training loss: 2.5700531005859375
Validation loss: 2.025449554125468

Epoch: 6| Step: 8
Training loss: 1.1771163940429688
Validation loss: 1.9875720342000325

Epoch: 6| Step: 9
Training loss: 2.1000590324401855
Validation loss: 1.9983623623847961

Epoch: 6| Step: 10
Training loss: 1.2905761003494263
Validation loss: 2.0197900931040444

Epoch: 6| Step: 11
Training loss: 2.0134520530700684
Validation loss: 1.990523358186086

Epoch: 6| Step: 12
Training loss: 2.0859007835388184
Validation loss: 1.993912696838379

Epoch: 6| Step: 13
Training loss: 1.3278460502624512
Validation loss: 2.022652824719747

Epoch: 64| Step: 0
Training loss: 1.880397081375122
Validation loss: 2.009667177995046

Epoch: 6| Step: 1
Training loss: 1.842644453048706
Validation loss: 2.0305235187212625

Epoch: 6| Step: 2
Training loss: 2.046844005584717
Validation loss: 2.033407509326935

Epoch: 6| Step: 3
Training loss: 1.9305682182312012
Validation loss: 2.0687889059384665

Epoch: 6| Step: 4
Training loss: 2.2975075244903564
Validation loss: 2.0483254194259644

Epoch: 6| Step: 5
Training loss: 2.113706111907959
Validation loss: 2.0943492650985718

Epoch: 6| Step: 6
Training loss: 1.8920514583587646
Validation loss: 2.0788071552912393

Epoch: 6| Step: 7
Training loss: 1.4731183052062988
Validation loss: 2.0631133317947388

Epoch: 6| Step: 8
Training loss: 1.7787866592407227
Validation loss: 2.0316007932027182

Epoch: 6| Step: 9
Training loss: 2.0425221920013428
Validation loss: 2.042401929696401

Epoch: 6| Step: 10
Training loss: 2.0295724868774414
Validation loss: 2.0425005555152893

Epoch: 6| Step: 11
Training loss: 1.0909900665283203
Validation loss: 2.0148717363675437

Epoch: 6| Step: 12
Training loss: 1.1107382774353027
Validation loss: 2.0251349409421286

Epoch: 6| Step: 13
Training loss: 1.338305950164795
Validation loss: 2.0229817430178323

Epoch: 65| Step: 0
Training loss: 1.8379161357879639
Validation loss: 1.9929012854894002

Epoch: 6| Step: 1
Training loss: 1.5479538440704346
Validation loss: 1.9995828866958618

Epoch: 6| Step: 2
Training loss: 2.0490143299102783
Validation loss: 2.0040677587191262

Epoch: 6| Step: 3
Training loss: 2.1248281002044678
Validation loss: 1.9867506623268127

Epoch: 6| Step: 4
Training loss: 1.200242042541504
Validation loss: 1.9988242983818054

Epoch: 6| Step: 5
Training loss: 1.9989211559295654
Validation loss: 1.9921738107999165

Epoch: 6| Step: 6
Training loss: 1.6609156131744385
Validation loss: 2.017378012339274

Epoch: 6| Step: 7
Training loss: 1.4842090606689453
Validation loss: 2.000295102596283

Epoch: 6| Step: 8
Training loss: 1.4317495822906494
Validation loss: 2.005746046702067

Epoch: 6| Step: 9
Training loss: 1.7195746898651123
Validation loss: 1.9982054829597473

Epoch: 6| Step: 10
Training loss: 1.7935616970062256
Validation loss: 2.0300890803337097

Epoch: 6| Step: 11
Training loss: 1.7976690530776978
Validation loss: 2.0377767284711203

Epoch: 6| Step: 12
Training loss: 2.06575345993042
Validation loss: 2.059450308481852

Epoch: 6| Step: 13
Training loss: 1.4467313289642334
Validation loss: 2.0390840570131936

Epoch: 66| Step: 0
Training loss: 1.9958754777908325
Validation loss: 2.0830617348353067

Epoch: 6| Step: 1
Training loss: 1.8750479221343994
Validation loss: 2.0727704763412476

Epoch: 6| Step: 2
Training loss: 1.6465058326721191
Validation loss: 2.0805214246114097

Epoch: 6| Step: 3
Training loss: 1.7805105447769165
Validation loss: 2.062325417995453

Epoch: 6| Step: 4
Training loss: 1.372438907623291
Validation loss: 2.0456498066584268

Epoch: 6| Step: 5
Training loss: 1.4653013944625854
Validation loss: 2.0519134203592935

Epoch: 6| Step: 6
Training loss: 1.5795905590057373
Validation loss: 2.0685829321543374

Epoch: 6| Step: 7
Training loss: 1.5057458877563477
Validation loss: 2.0458709001541138

Epoch: 6| Step: 8
Training loss: 1.2082183361053467
Validation loss: 2.0168639620145163

Epoch: 6| Step: 9
Training loss: 1.6829864978790283
Validation loss: 2.0256235003471375

Epoch: 6| Step: 10
Training loss: 1.577378273010254
Validation loss: 2.011372168858846

Epoch: 6| Step: 11
Training loss: 2.510254144668579
Validation loss: 1.9974108537038167

Epoch: 6| Step: 12
Training loss: 1.8842136859893799
Validation loss: 2.0089327096939087

Epoch: 6| Step: 13
Training loss: 2.6197431087493896
Validation loss: 1.9872525533040364

Epoch: 67| Step: 0
Training loss: 2.3351027965545654
Validation loss: 1.996690034866333

Epoch: 6| Step: 1
Training loss: 1.6777567863464355
Validation loss: 2.0295344591140747

Epoch: 6| Step: 2
Training loss: 1.5980892181396484
Validation loss: 2.0410717924435935

Epoch: 6| Step: 3
Training loss: 1.6044745445251465
Validation loss: 2.02181742588679

Epoch: 6| Step: 4
Training loss: 1.8451769351959229
Validation loss: 2.078053116798401

Epoch: 6| Step: 5
Training loss: 0.9098294973373413
Validation loss: 2.0478882590929666

Epoch: 6| Step: 6
Training loss: 2.0796749591827393
Validation loss: 2.039550999800364

Epoch: 6| Step: 7
Training loss: 1.8379833698272705
Validation loss: 2.0363569259643555

Epoch: 6| Step: 8
Training loss: 1.969926118850708
Validation loss: 2.0214175979296365

Epoch: 6| Step: 9
Training loss: 1.5637264251708984
Validation loss: 2.0232337514559426

Epoch: 6| Step: 10
Training loss: 2.6652462482452393
Validation loss: 2.0199636022249856

Epoch: 6| Step: 11
Training loss: 1.7585748434066772
Validation loss: 2.0351155002911887

Epoch: 6| Step: 12
Training loss: 1.7056541442871094
Validation loss: 2.0001617868741355

Epoch: 6| Step: 13
Training loss: 0.9554137587547302
Validation loss: 2.06201434135437

Epoch: 68| Step: 0
Training loss: 1.7722792625427246
Validation loss: 2.048461119333903

Epoch: 6| Step: 1
Training loss: 1.3791265487670898
Validation loss: 2.0443390210469565

Epoch: 6| Step: 2
Training loss: 2.0804219245910645
Validation loss: 2.0304627815882363

Epoch: 6| Step: 3
Training loss: 1.8909142017364502
Validation loss: 2.046843469142914

Epoch: 6| Step: 4
Training loss: 1.838239312171936
Validation loss: 2.0483651955922446

Epoch: 6| Step: 5
Training loss: 1.8287854194641113
Validation loss: 2.026137431462606

Epoch: 6| Step: 6
Training loss: 1.5621181726455688
Validation loss: 2.0360803405443826

Epoch: 6| Step: 7
Training loss: 2.108153820037842
Validation loss: 2.0501497387886047

Epoch: 6| Step: 8
Training loss: 1.4244349002838135
Validation loss: 2.0393992265065513

Epoch: 6| Step: 9
Training loss: 1.9225332736968994
Validation loss: 2.058805843194326

Epoch: 6| Step: 10
Training loss: 1.9742063283920288
Validation loss: 2.0360748370488486

Epoch: 6| Step: 11
Training loss: 1.1620185375213623
Validation loss: 2.0350460012753806

Epoch: 6| Step: 12
Training loss: 1.3784719705581665
Validation loss: 2.027509093284607

Epoch: 6| Step: 13
Training loss: 1.967524766921997
Validation loss: 2.0488654573758445

Epoch: 69| Step: 0
Training loss: 1.6359628438949585
Validation loss: 2.0437758366266885

Epoch: 6| Step: 1
Training loss: 1.6586852073669434
Validation loss: 2.056376338005066

Epoch: 6| Step: 2
Training loss: 1.9514718055725098
Validation loss: 2.0735167066256204

Epoch: 6| Step: 3
Training loss: 1.237074375152588
Validation loss: 2.100275993347168

Epoch: 6| Step: 4
Training loss: 1.6977360248565674
Validation loss: 2.0741089582443237

Epoch: 6| Step: 5
Training loss: 2.159485340118408
Validation loss: 2.076778988043467

Epoch: 6| Step: 6
Training loss: 2.1931557655334473
Validation loss: 2.0686914920806885

Epoch: 6| Step: 7
Training loss: 2.341986656188965
Validation loss: 2.0837908188501992

Epoch: 6| Step: 8
Training loss: 1.445981502532959
Validation loss: 2.0515750646591187

Epoch: 6| Step: 9
Training loss: 1.4510114192962646
Validation loss: 2.048595408598582

Epoch: 6| Step: 10
Training loss: 1.469644546508789
Validation loss: 2.0232515136400857

Epoch: 6| Step: 11
Training loss: 1.3094120025634766
Validation loss: 2.007347881793976

Epoch: 6| Step: 12
Training loss: 1.9802433252334595
Validation loss: 2.000794847806295

Epoch: 6| Step: 13
Training loss: 1.9049100875854492
Validation loss: 2.0243917107582092

Epoch: 70| Step: 0
Training loss: 1.4099981784820557
Validation loss: 2.0064356327056885

Epoch: 6| Step: 1
Training loss: 1.5072633028030396
Validation loss: 2.002341151237488

Epoch: 6| Step: 2
Training loss: 2.3549880981445312
Validation loss: 2.000173509120941

Epoch: 6| Step: 3
Training loss: 1.4119439125061035
Validation loss: 2.004158536593119

Epoch: 6| Step: 4
Training loss: 1.344465970993042
Validation loss: 2.002594510714213

Epoch: 6| Step: 5
Training loss: 1.885765552520752
Validation loss: 1.9975440899531047

Epoch: 6| Step: 6
Training loss: 2.571084976196289
Validation loss: 2.0118879675865173

Epoch: 6| Step: 7
Training loss: 1.4642715454101562
Validation loss: 2.033777912457784

Epoch: 6| Step: 8
Training loss: 1.814010500907898
Validation loss: 2.0110912124315896

Epoch: 6| Step: 9
Training loss: 1.5443633794784546
Validation loss: 2.0034505128860474

Epoch: 6| Step: 10
Training loss: 1.710436224937439
Validation loss: 2.0247488021850586

Epoch: 6| Step: 11
Training loss: 1.7455759048461914
Validation loss: 2.027866840362549

Epoch: 6| Step: 12
Training loss: 2.026336193084717
Validation loss: 2.0290220578511557

Epoch: 6| Step: 13
Training loss: 1.2490324974060059
Validation loss: 2.000135362148285

Epoch: 71| Step: 0
Training loss: 1.3414487838745117
Validation loss: 2.0424128770828247

Epoch: 6| Step: 1
Training loss: 1.6428031921386719
Validation loss: 2.041871746381124

Epoch: 6| Step: 2
Training loss: 1.2643972635269165
Validation loss: 2.081347127755483

Epoch: 6| Step: 3
Training loss: 1.920424461364746
Validation loss: 2.0845195849736533

Epoch: 6| Step: 4
Training loss: 1.5997095108032227
Validation loss: 2.067708750565847

Epoch: 6| Step: 5
Training loss: 1.7803540229797363
Validation loss: 2.059479534626007

Epoch: 6| Step: 6
Training loss: 1.683390498161316
Validation loss: 2.0367225209871926

Epoch: 6| Step: 7
Training loss: 1.811645746231079
Validation loss: 2.0342209339141846

Epoch: 6| Step: 8
Training loss: 1.925144076347351
Validation loss: 2.03028670946757

Epoch: 6| Step: 9
Training loss: 1.3169529438018799
Validation loss: 2.026368021965027

Epoch: 6| Step: 10
Training loss: 2.099022388458252
Validation loss: 2.023440341154734

Epoch: 6| Step: 11
Training loss: 2.208322048187256
Validation loss: 2.033102035522461

Epoch: 6| Step: 12
Training loss: 1.9673062562942505
Validation loss: 1.992197831471761

Epoch: 6| Step: 13
Training loss: 1.4795727729797363
Validation loss: 2.044588049252828

Epoch: 72| Step: 0
Training loss: 1.9601097106933594
Validation loss: 2.0258415937423706

Epoch: 6| Step: 1
Training loss: 1.3449451923370361
Validation loss: 2.040489117304484

Epoch: 6| Step: 2
Training loss: 1.9496098756790161
Validation loss: 2.0057384371757507

Epoch: 6| Step: 3
Training loss: 2.0626220703125
Validation loss: 2.05687423547109

Epoch: 6| Step: 4
Training loss: 1.7086557149887085
Validation loss: 2.0291573206583657

Epoch: 6| Step: 5
Training loss: 1.3825578689575195
Validation loss: 2.0444873372713723

Epoch: 6| Step: 6
Training loss: 1.578492522239685
Validation loss: 2.062500317891439

Epoch: 6| Step: 7
Training loss: 1.7055703401565552
Validation loss: 2.0337647795677185

Epoch: 6| Step: 8
Training loss: 1.6255496740341187
Validation loss: 2.10153329372406

Epoch: 6| Step: 9
Training loss: 1.1061089038848877
Validation loss: 2.077548603216807

Epoch: 6| Step: 10
Training loss: 1.3675849437713623
Validation loss: 2.0656632582346597

Epoch: 6| Step: 11
Training loss: 2.323225736618042
Validation loss: 2.060651183128357

Epoch: 6| Step: 12
Training loss: 1.5265007019042969
Validation loss: 2.030017614364624

Epoch: 6| Step: 13
Training loss: 2.037963628768921
Validation loss: 2.0489925344785056

Epoch: 73| Step: 0
Training loss: 1.2527060508728027
Validation loss: 2.0355873505274453

Epoch: 6| Step: 1
Training loss: 1.3867888450622559
Validation loss: 2.0121553937594094

Epoch: 6| Step: 2
Training loss: 1.9671920537948608
Validation loss: 2.0130210717519126

Epoch: 6| Step: 3
Training loss: 2.266427993774414
Validation loss: 2.024361729621887

Epoch: 6| Step: 4
Training loss: 2.122244119644165
Validation loss: 2.0302019317944846

Epoch: 6| Step: 5
Training loss: 1.7635821104049683
Validation loss: 2.0152397553126016

Epoch: 6| Step: 6
Training loss: 1.3761287927627563
Validation loss: 2.041387657324473

Epoch: 6| Step: 7
Training loss: 0.9761608839035034
Validation loss: 2.040294965108236

Epoch: 6| Step: 8
Training loss: 1.395583152770996
Validation loss: 2.0405696034431458

Epoch: 6| Step: 9
Training loss: 1.4281342029571533
Validation loss: 2.064499318599701

Epoch: 6| Step: 10
Training loss: 1.676440715789795
Validation loss: 2.060636818408966

Epoch: 6| Step: 11
Training loss: 2.0194883346557617
Validation loss: 2.0478368004163108

Epoch: 6| Step: 12
Training loss: 1.548261046409607
Validation loss: 2.070012013117472

Epoch: 6| Step: 13
Training loss: 2.1244101524353027
Validation loss: 2.062474489212036

Epoch: 74| Step: 0
Training loss: 0.9591575860977173
Validation loss: 2.102688491344452

Epoch: 6| Step: 1
Training loss: 2.09206485748291
Validation loss: 2.10497784614563

Epoch: 6| Step: 2
Training loss: 1.3080356121063232
Validation loss: 2.0755100647608438

Epoch: 6| Step: 3
Training loss: 1.3999958038330078
Validation loss: 2.08553018172582

Epoch: 6| Step: 4
Training loss: 1.8722026348114014
Validation loss: 2.0739908814430237

Epoch: 6| Step: 5
Training loss: 2.4610934257507324
Validation loss: 2.0242438316345215

Epoch: 6| Step: 6
Training loss: 2.039224147796631
Validation loss: 2.0230175654093423

Epoch: 6| Step: 7
Training loss: 1.6010749340057373
Validation loss: 2.031836688518524

Epoch: 6| Step: 8
Training loss: 1.0211358070373535
Validation loss: 2.0417917172114053

Epoch: 6| Step: 9
Training loss: 2.1453495025634766
Validation loss: 2.0237565636634827

Epoch: 6| Step: 10
Training loss: 1.658416509628296
Validation loss: 2.0612979332605996

Epoch: 6| Step: 11
Training loss: 1.8454258441925049
Validation loss: 2.050755500793457

Epoch: 6| Step: 12
Training loss: 1.7496660947799683
Validation loss: 2.0624809662501016

Epoch: 6| Step: 13
Training loss: 1.4127800464630127
Validation loss: 2.040587544441223

Epoch: 75| Step: 0
Training loss: 1.8474390506744385
Validation loss: 2.001692553361257

Epoch: 6| Step: 1
Training loss: 1.835378885269165
Validation loss: 2.04443887869517

Epoch: 6| Step: 2
Training loss: 2.432335615158081
Validation loss: 2.051363984743754

Epoch: 6| Step: 3
Training loss: 1.4983315467834473
Validation loss: 2.062581241130829

Epoch: 6| Step: 4
Training loss: 1.6028516292572021
Validation loss: 2.0204493006070456

Epoch: 6| Step: 5
Training loss: 2.126206874847412
Validation loss: 2.03654146194458

Epoch: 6| Step: 6
Training loss: 1.495826244354248
Validation loss: 2.0679951111475625

Epoch: 6| Step: 7
Training loss: 1.3377338647842407
Validation loss: 2.0202258825302124

Epoch: 6| Step: 8
Training loss: 1.8291385173797607
Validation loss: 2.0527551770210266

Epoch: 6| Step: 9
Training loss: 1.9640613794326782
Validation loss: 2.0602485140164695

Epoch: 6| Step: 10
Training loss: 1.6272523403167725
Validation loss: 2.071536143620809

Epoch: 6| Step: 11
Training loss: 0.975233793258667
Validation loss: 2.0663679440816245

Epoch: 6| Step: 12
Training loss: 1.3713898658752441
Validation loss: 2.0707455476125083

Epoch: 6| Step: 13
Training loss: 1.392001986503601
Validation loss: 2.029561936855316

Epoch: 76| Step: 0
Training loss: 1.7710368633270264
Validation loss: 2.067761401335398

Epoch: 6| Step: 1
Training loss: 1.207716464996338
Validation loss: 2.050665636857351

Epoch: 6| Step: 2
Training loss: 1.780218243598938
Validation loss: 2.0499215722084045

Epoch: 6| Step: 3
Training loss: 1.5132412910461426
Validation loss: 2.0674434701601663

Epoch: 6| Step: 4
Training loss: 1.4846768379211426
Validation loss: 2.106413165728251

Epoch: 6| Step: 5
Training loss: 1.5956361293792725
Validation loss: 2.104002356529236

Epoch: 6| Step: 6
Training loss: 1.5851413011550903
Validation loss: 2.0831982294718423

Epoch: 6| Step: 7
Training loss: 1.9466526508331299
Validation loss: 2.1067444682121277

Epoch: 6| Step: 8
Training loss: 1.5633113384246826
Validation loss: 2.1359158555666604

Epoch: 6| Step: 9
Training loss: 1.6039185523986816
Validation loss: 2.1129109064737954

Epoch: 6| Step: 10
Training loss: 1.738548755645752
Validation loss: 2.1077831387519836

Epoch: 6| Step: 11
Training loss: 1.9352385997772217
Validation loss: 2.073999762535095

Epoch: 6| Step: 12
Training loss: 2.133798122406006
Validation loss: 2.0756715337435403

Epoch: 6| Step: 13
Training loss: 1.454035997390747
Validation loss: 2.0640419125556946

Epoch: 77| Step: 0
Training loss: 1.8810839653015137
Validation loss: 2.056700110435486

Epoch: 6| Step: 1
Training loss: 1.7743167877197266
Validation loss: 2.0158176024754844

Epoch: 6| Step: 2
Training loss: 1.9096295833587646
Validation loss: 2.024637301762899

Epoch: 6| Step: 3
Training loss: 1.9901716709136963
Validation loss: 2.017554442087809

Epoch: 6| Step: 4
Training loss: 1.6595462560653687
Validation loss: 1.995192249615987

Epoch: 6| Step: 5
Training loss: 1.7603310346603394
Validation loss: 2.016237258911133

Epoch: 6| Step: 6
Training loss: 2.0184953212738037
Validation loss: 2.0276390512784324

Epoch: 6| Step: 7
Training loss: 1.1785459518432617
Validation loss: 2.0229055881500244

Epoch: 6| Step: 8
Training loss: 1.3859636783599854
Validation loss: 2.026920278867086

Epoch: 6| Step: 9
Training loss: 1.611976146697998
Validation loss: 2.063447634379069

Epoch: 6| Step: 10
Training loss: 1.9919450283050537
Validation loss: 2.047888239224752

Epoch: 6| Step: 11
Training loss: 1.5240429639816284
Validation loss: 2.0640013019243875

Epoch: 6| Step: 12
Training loss: 1.4986168146133423
Validation loss: 2.074217200279236

Epoch: 6| Step: 13
Training loss: 1.471639633178711
Validation loss: 2.1106454133987427

Epoch: 78| Step: 0
Training loss: 1.824620246887207
Validation loss: 2.104977607727051

Epoch: 6| Step: 1
Training loss: 1.4288675785064697
Validation loss: 2.1227017839749656

Epoch: 6| Step: 2
Training loss: 1.624996304512024
Validation loss: 2.0853447119394937

Epoch: 6| Step: 3
Training loss: 1.4996654987335205
Validation loss: 2.0964221159617105

Epoch: 6| Step: 4
Training loss: 1.5199930667877197
Validation loss: 2.0747880339622498

Epoch: 6| Step: 5
Training loss: 1.3500440120697021
Validation loss: 2.0614850521087646

Epoch: 6| Step: 6
Training loss: 1.8176963329315186
Validation loss: 2.0392639438311257

Epoch: 6| Step: 7
Training loss: 2.039743423461914
Validation loss: 2.012904167175293

Epoch: 6| Step: 8
Training loss: 1.526105523109436
Validation loss: 2.041209578514099

Epoch: 6| Step: 9
Training loss: 1.7564787864685059
Validation loss: 2.017747978369395

Epoch: 6| Step: 10
Training loss: 1.5932567119598389
Validation loss: 2.048567056655884

Epoch: 6| Step: 11
Training loss: 1.9375665187835693
Validation loss: 2.0435600876808167

Epoch: 6| Step: 12
Training loss: 1.8812109231948853
Validation loss: 2.020696143309275

Epoch: 6| Step: 13
Training loss: 1.4072182178497314
Validation loss: 2.022425413131714

Epoch: 79| Step: 0
Training loss: 1.5242137908935547
Validation loss: 2.038680692513784

Epoch: 6| Step: 1
Training loss: 1.3241335153579712
Validation loss: 2.044854760169983

Epoch: 6| Step: 2
Training loss: 1.546796441078186
Validation loss: 2.0378872950871787

Epoch: 6| Step: 3
Training loss: 1.3506879806518555
Validation loss: 2.0536608695983887

Epoch: 6| Step: 4
Training loss: 1.768733024597168
Validation loss: 2.04155961672465

Epoch: 6| Step: 5
Training loss: 2.0110557079315186
Validation loss: 2.011052946249644

Epoch: 6| Step: 6
Training loss: 1.6691675186157227
Validation loss: 2.0409998893737793

Epoch: 6| Step: 7
Training loss: 1.350245714187622
Validation loss: 2.0327992836634317

Epoch: 6| Step: 8
Training loss: 1.4741466045379639
Validation loss: 2.0187405546506247

Epoch: 6| Step: 9
Training loss: 1.8367273807525635
Validation loss: 2.0471351941426597

Epoch: 6| Step: 10
Training loss: 1.198772668838501
Validation loss: 2.0513709584871926

Epoch: 6| Step: 11
Training loss: 1.470706820487976
Validation loss: 2.055474023024241

Epoch: 6| Step: 12
Training loss: 2.094053268432617
Validation loss: 2.050911545753479

Epoch: 6| Step: 13
Training loss: 2.117358684539795
Validation loss: 2.0589479207992554

Epoch: 80| Step: 0
Training loss: 1.6746124029159546
Validation loss: 2.0346970558166504

Epoch: 6| Step: 1
Training loss: 1.9954593181610107
Validation loss: 2.0427034894625344

Epoch: 6| Step: 2
Training loss: 1.3124749660491943
Validation loss: 2.0557214419047036

Epoch: 6| Step: 3
Training loss: 1.8210965394973755
Validation loss: 2.0827521681785583

Epoch: 6| Step: 4
Training loss: 1.305214285850525
Validation loss: 2.0888699094454446

Epoch: 6| Step: 5
Training loss: 0.9495149254798889
Validation loss: 2.0919705629348755

Epoch: 6| Step: 6
Training loss: 2.384129524230957
Validation loss: 2.0762502749760947

Epoch: 6| Step: 7
Training loss: 2.041808843612671
Validation loss: 2.0903259913126626

Epoch: 6| Step: 8
Training loss: 2.0498666763305664
Validation loss: 2.0983035564422607

Epoch: 6| Step: 9
Training loss: 1.5857572555541992
Validation loss: 2.073555668195089

Epoch: 6| Step: 10
Training loss: 1.332134485244751
Validation loss: 2.056634227434794

Epoch: 6| Step: 11
Training loss: 1.4806487560272217
Validation loss: 2.052717407544454

Epoch: 6| Step: 12
Training loss: 1.643642783164978
Validation loss: 2.039592981338501

Epoch: 6| Step: 13
Training loss: 1.2811462879180908
Validation loss: 2.0352864066759744

Epoch: 81| Step: 0
Training loss: 1.5988941192626953
Validation loss: 2.033834437529246

Epoch: 6| Step: 1
Training loss: 1.0886777639389038
Validation loss: 2.053245186805725

Epoch: 6| Step: 2
Training loss: 2.062403440475464
Validation loss: 2.053021013736725

Epoch: 6| Step: 3
Training loss: 2.502058982849121
Validation loss: 2.0459333062171936

Epoch: 6| Step: 4
Training loss: 1.5701525211334229
Validation loss: 2.036603808403015

Epoch: 6| Step: 5
Training loss: 1.1734404563903809
Validation loss: 2.081977625687917

Epoch: 6| Step: 6
Training loss: 1.7955766916275024
Validation loss: 2.098037083943685

Epoch: 6| Step: 7
Training loss: 1.701891303062439
Validation loss: 2.073258022467295

Epoch: 6| Step: 8
Training loss: 1.5073976516723633
Validation loss: 2.091534992059072

Epoch: 6| Step: 9
Training loss: 1.3393863439559937
Validation loss: 2.0745803713798523

Epoch: 6| Step: 10
Training loss: 1.4257198572158813
Validation loss: 2.105078339576721

Epoch: 6| Step: 11
Training loss: 1.2584948539733887
Validation loss: 2.0970800121625266

Epoch: 6| Step: 12
Training loss: 1.4500727653503418
Validation loss: 2.0998093485832214

Epoch: 6| Step: 13
Training loss: 1.9467275142669678
Validation loss: 2.0841824809710183

Epoch: 82| Step: 0
Training loss: 1.9939959049224854
Validation loss: 2.0634514689445496

Epoch: 6| Step: 1
Training loss: 1.6497344970703125
Validation loss: 2.038625399271647

Epoch: 6| Step: 2
Training loss: 2.0455737113952637
Validation loss: 2.0420360763867698

Epoch: 6| Step: 3
Training loss: 1.2247366905212402
Validation loss: 2.0640202363332114

Epoch: 6| Step: 4
Training loss: 1.069011926651001
Validation loss: 2.0108171502749124

Epoch: 6| Step: 5
Training loss: 1.2667555809020996
Validation loss: 2.043648103872935

Epoch: 6| Step: 6
Training loss: 1.5035812854766846
Validation loss: 2.0148528814315796

Epoch: 6| Step: 7
Training loss: 1.8950669765472412
Validation loss: 2.052500863869985

Epoch: 6| Step: 8
Training loss: 1.900841474533081
Validation loss: 2.0504148602485657

Epoch: 6| Step: 9
Training loss: 1.6175942420959473
Validation loss: 2.068480590979258

Epoch: 6| Step: 10
Training loss: 1.884075403213501
Validation loss: 2.0976085861523948

Epoch: 6| Step: 11
Training loss: 1.6899521350860596
Validation loss: 2.1076422731081643

Epoch: 6| Step: 12
Training loss: 1.7999483346939087
Validation loss: 2.1102418502171836

Epoch: 6| Step: 13
Training loss: 1.5168794393539429
Validation loss: 2.126859883467356

Epoch: 83| Step: 0
Training loss: 1.5536549091339111
Validation loss: 2.102734704812368

Epoch: 6| Step: 1
Training loss: 1.0738234519958496
Validation loss: 2.068101406097412

Epoch: 6| Step: 2
Training loss: 1.2210562229156494
Validation loss: 2.0549020767211914

Epoch: 6| Step: 3
Training loss: 2.145972728729248
Validation loss: 2.0571436484654746

Epoch: 6| Step: 4
Training loss: 2.1070334911346436
Validation loss: 2.081641733646393

Epoch: 6| Step: 5
Training loss: 1.9607906341552734
Validation loss: 2.0664742390314736

Epoch: 6| Step: 6
Training loss: 1.3063902854919434
Validation loss: 2.050073285897573

Epoch: 6| Step: 7
Training loss: 1.8613336086273193
Validation loss: 2.0318576097488403

Epoch: 6| Step: 8
Training loss: 1.4842822551727295
Validation loss: 2.0337128043174744

Epoch: 6| Step: 9
Training loss: 1.0943011045455933
Validation loss: 2.050035854180654

Epoch: 6| Step: 10
Training loss: 0.9738416075706482
Validation loss: 2.0862600008646646

Epoch: 6| Step: 11
Training loss: 2.2901127338409424
Validation loss: 2.087345520655314

Epoch: 6| Step: 12
Training loss: 1.5721380710601807
Validation loss: 2.1613622506459556

Epoch: 6| Step: 13
Training loss: 2.5180904865264893
Validation loss: 2.1471529801686606

Epoch: 84| Step: 0
Training loss: 1.7531932592391968
Validation loss: 2.1623446544011435

Epoch: 6| Step: 1
Training loss: 1.3392255306243896
Validation loss: 2.1630114118258157

Epoch: 6| Step: 2
Training loss: 1.9305180311203003
Validation loss: 2.123035411039988

Epoch: 6| Step: 3
Training loss: 1.3803215026855469
Validation loss: 2.092554807662964

Epoch: 6| Step: 4
Training loss: 1.1978182792663574
Validation loss: 2.061716854572296

Epoch: 6| Step: 5
Training loss: 1.581240177154541
Validation loss: 2.057654023170471

Epoch: 6| Step: 6
Training loss: 2.3991611003875732
Validation loss: 2.0475573738416037

Epoch: 6| Step: 7
Training loss: 1.564860224723816
Validation loss: 2.015959541002909

Epoch: 6| Step: 8
Training loss: 1.5884833335876465
Validation loss: 2.0492616097132363

Epoch: 6| Step: 9
Training loss: 1.3515655994415283
Validation loss: 2.00947368144989

Epoch: 6| Step: 10
Training loss: 2.119919538497925
Validation loss: 2.0402236580848694

Epoch: 6| Step: 11
Training loss: 1.725588083267212
Validation loss: 2.061087191104889

Epoch: 6| Step: 12
Training loss: 1.9573945999145508
Validation loss: 2.0682921210924783

Epoch: 6| Step: 13
Training loss: 1.1572556495666504
Validation loss: 2.0469672679901123

Epoch: 85| Step: 0
Training loss: 1.9997763633728027
Validation loss: 2.1136788924535117

Epoch: 6| Step: 1
Training loss: 1.5982327461242676
Validation loss: 2.1008543570836387

Epoch: 6| Step: 2
Training loss: 2.026049852371216
Validation loss: 2.130598763624827

Epoch: 6| Step: 3
Training loss: 1.775529146194458
Validation loss: 2.095787247021993

Epoch: 6| Step: 4
Training loss: 1.498793125152588
Validation loss: 2.1014340122540793

Epoch: 6| Step: 5
Training loss: 1.1499602794647217
Validation loss: 2.059758186340332

Epoch: 6| Step: 6
Training loss: 1.4636757373809814
Validation loss: 2.0492063959439597

Epoch: 6| Step: 7
Training loss: 1.31295907497406
Validation loss: 2.056655168533325

Epoch: 6| Step: 8
Training loss: 1.8237062692642212
Validation loss: 2.0604066252708435

Epoch: 6| Step: 9
Training loss: 1.439460277557373
Validation loss: 2.0518510739008584

Epoch: 6| Step: 10
Training loss: 1.125664234161377
Validation loss: 2.0574209094047546

Epoch: 6| Step: 11
Training loss: 1.9245238304138184
Validation loss: 2.0916466315587363

Epoch: 6| Step: 12
Training loss: 1.4406225681304932
Validation loss: 2.0642980337142944

Epoch: 6| Step: 13
Training loss: 1.8112025260925293
Validation loss: 2.0589605371157327

Epoch: 86| Step: 0
Training loss: 1.238668441772461
Validation loss: 2.132875680923462

Epoch: 6| Step: 1
Training loss: 1.969881296157837
Validation loss: 2.088319996992747

Epoch: 6| Step: 2
Training loss: 1.280110239982605
Validation loss: 2.0734928846359253

Epoch: 6| Step: 3
Training loss: 1.601945161819458
Validation loss: 2.0899793903032937

Epoch: 6| Step: 4
Training loss: 1.169407844543457
Validation loss: 2.0949052969614663

Epoch: 6| Step: 5
Training loss: 1.5588490962982178
Validation loss: 2.0845161080360413

Epoch: 6| Step: 6
Training loss: 1.3726545572280884
Validation loss: 2.058475355307261

Epoch: 6| Step: 7
Training loss: 1.4920486211776733
Validation loss: 2.070662200450897

Epoch: 6| Step: 8
Training loss: 2.2676620483398438
Validation loss: 2.050727923711141

Epoch: 6| Step: 9
Training loss: 1.1765204668045044
Validation loss: 2.0708496967951455

Epoch: 6| Step: 10
Training loss: 1.932844877243042
Validation loss: 2.040438175201416

Epoch: 6| Step: 11
Training loss: 2.045151710510254
Validation loss: 2.061951160430908

Epoch: 6| Step: 12
Training loss: 1.60688054561615
Validation loss: 2.0547293225924173

Epoch: 6| Step: 13
Training loss: 1.1464654207229614
Validation loss: 2.0240891377131143

Epoch: 87| Step: 0
Training loss: 1.56627357006073
Validation loss: 2.0352131923039756

Epoch: 6| Step: 1
Training loss: 1.4551763534545898
Validation loss: 2.0772711435953775

Epoch: 6| Step: 2
Training loss: 1.5895164012908936
Validation loss: 2.080258846282959

Epoch: 6| Step: 3
Training loss: 1.507462978363037
Validation loss: 2.086636781692505

Epoch: 6| Step: 4
Training loss: 2.053494930267334
Validation loss: 2.1050452987353006

Epoch: 6| Step: 5
Training loss: 1.594731330871582
Validation loss: 2.0815436641375222

Epoch: 6| Step: 6
Training loss: 1.5608779191970825
Validation loss: 2.1244262059529624

Epoch: 6| Step: 7
Training loss: 1.8333826065063477
Validation loss: 2.134475906689962

Epoch: 6| Step: 8
Training loss: 1.9645576477050781
Validation loss: 2.1018378337224326

Epoch: 6| Step: 9
Training loss: 1.4182510375976562
Validation loss: 2.1132720510164895

Epoch: 6| Step: 10
Training loss: 1.657863974571228
Validation loss: 2.0761760473251343

Epoch: 6| Step: 11
Training loss: 1.0985207557678223
Validation loss: 2.08757613102595

Epoch: 6| Step: 12
Training loss: 1.408459186553955
Validation loss: 2.0637816985448203

Epoch: 6| Step: 13
Training loss: 1.4878193140029907
Validation loss: 2.069347620010376

Epoch: 88| Step: 0
Training loss: 1.8359026908874512
Validation loss: 2.061291535695394

Epoch: 6| Step: 1
Training loss: 0.8878682851791382
Validation loss: 2.087124228477478

Epoch: 6| Step: 2
Training loss: 2.0276217460632324
Validation loss: 2.046937425931295

Epoch: 6| Step: 3
Training loss: 1.8555779457092285
Validation loss: 2.084968944390615

Epoch: 6| Step: 4
Training loss: 1.197142481803894
Validation loss: 2.052932540575663

Epoch: 6| Step: 5
Training loss: 1.188918113708496
Validation loss: 2.0845428506533303

Epoch: 6| Step: 6
Training loss: 1.9437322616577148
Validation loss: 2.0780156453450522

Epoch: 6| Step: 7
Training loss: 1.7113794088363647
Validation loss: 2.0951536893844604

Epoch: 6| Step: 8
Training loss: 1.3373832702636719
Validation loss: 2.089378813902537

Epoch: 6| Step: 9
Training loss: 1.5667121410369873
Validation loss: 2.101803739865621

Epoch: 6| Step: 10
Training loss: 1.2057799100875854
Validation loss: 2.077650805314382

Epoch: 6| Step: 11
Training loss: 2.269726276397705
Validation loss: 2.089429259300232

Epoch: 6| Step: 12
Training loss: 1.3345857858657837
Validation loss: 2.105619728565216

Epoch: 6| Step: 13
Training loss: 0.9806802272796631
Validation loss: 2.0820193688074746

Epoch: 89| Step: 0
Training loss: 1.1489322185516357
Validation loss: 2.0676856637001038

Epoch: 6| Step: 1
Training loss: 1.8474562168121338
Validation loss: 2.0970590114593506

Epoch: 6| Step: 2
Training loss: 1.0774950981140137
Validation loss: 2.092739204565684

Epoch: 6| Step: 3
Training loss: 2.223236322402954
Validation loss: 2.116365353266398

Epoch: 6| Step: 4
Training loss: 1.1180959939956665
Validation loss: 2.0920872688293457

Epoch: 6| Step: 5
Training loss: 1.1514487266540527
Validation loss: 2.0512224435806274

Epoch: 6| Step: 6
Training loss: 1.0423253774642944
Validation loss: 2.0882674058278403

Epoch: 6| Step: 7
Training loss: 1.7380200624465942
Validation loss: 2.070128341515859

Epoch: 6| Step: 8
Training loss: 1.3666982650756836
Validation loss: 2.0431993206342063

Epoch: 6| Step: 9
Training loss: 1.952887773513794
Validation loss: 2.0852772196133933

Epoch: 6| Step: 10
Training loss: 1.6520147323608398
Validation loss: 2.0777830481529236

Epoch: 6| Step: 11
Training loss: 1.8162293434143066
Validation loss: 2.0460448265075684

Epoch: 6| Step: 12
Training loss: 1.1740081310272217
Validation loss: 2.0451257824897766

Epoch: 6| Step: 13
Training loss: 1.9733890295028687
Validation loss: 2.034562269846598

Epoch: 90| Step: 0
Training loss: 1.4217849969863892
Validation loss: 2.0608067512512207

Epoch: 6| Step: 1
Training loss: 1.4642326831817627
Validation loss: 2.067338307698568

Epoch: 6| Step: 2
Training loss: 1.8989019393920898
Validation loss: 2.067026197910309

Epoch: 6| Step: 3
Training loss: 1.9219310283660889
Validation loss: 2.081822375456492

Epoch: 6| Step: 4
Training loss: 1.651538372039795
Validation loss: 2.104720711708069

Epoch: 6| Step: 5
Training loss: 1.4257328510284424
Validation loss: 2.1210825045903525

Epoch: 6| Step: 6
Training loss: 1.6771576404571533
Validation loss: 2.1364708145459494

Epoch: 6| Step: 7
Training loss: 2.003757953643799
Validation loss: 2.1304274201393127

Epoch: 6| Step: 8
Training loss: 0.8925140500068665
Validation loss: 2.0876874923706055

Epoch: 6| Step: 9
Training loss: 1.2825689315795898
Validation loss: 2.103268881638845

Epoch: 6| Step: 10
Training loss: 1.5566315650939941
Validation loss: 2.0718809763590493

Epoch: 6| Step: 11
Training loss: 1.594022274017334
Validation loss: 2.0855711897214255

Epoch: 6| Step: 12
Training loss: 1.1359543800354004
Validation loss: 2.038783331712087

Epoch: 6| Step: 13
Training loss: 1.396730899810791
Validation loss: 2.052981734275818

Epoch: 91| Step: 0
Training loss: 1.2571736574172974
Validation loss: 2.0667057832082114

Epoch: 6| Step: 1
Training loss: 0.8695614337921143
Validation loss: 2.0478287736574807

Epoch: 6| Step: 2
Training loss: 1.407416820526123
Validation loss: 2.0632923245429993

Epoch: 6| Step: 3
Training loss: 1.965414047241211
Validation loss: 2.0826534231503806

Epoch: 6| Step: 4
Training loss: 1.5588161945343018
Validation loss: 2.0682836373647056

Epoch: 6| Step: 5
Training loss: 1.637746810913086
Validation loss: 2.101096491018931

Epoch: 6| Step: 6
Training loss: 1.3625411987304688
Validation loss: 2.0918631156285605

Epoch: 6| Step: 7
Training loss: 1.0616424083709717
Validation loss: 2.097957710425059

Epoch: 6| Step: 8
Training loss: 2.0486230850219727
Validation loss: 2.084795296192169

Epoch: 6| Step: 9
Training loss: 1.3395347595214844
Validation loss: 2.092592775821686

Epoch: 6| Step: 10
Training loss: 1.5205963850021362
Validation loss: 2.104954779148102

Epoch: 6| Step: 11
Training loss: 1.1351902484893799
Validation loss: 2.1189515193303428

Epoch: 6| Step: 12
Training loss: 1.9094949960708618
Validation loss: 2.079929749170939

Epoch: 6| Step: 13
Training loss: 2.2071781158447266
Validation loss: 2.080477694670359

Epoch: 92| Step: 0
Training loss: 1.2961273193359375
Validation loss: 2.0808797478675842

Epoch: 6| Step: 1
Training loss: 1.3701413869857788
Validation loss: 2.060965915520986

Epoch: 6| Step: 2
Training loss: 1.6250157356262207
Validation loss: 2.0807982285817466

Epoch: 6| Step: 3
Training loss: 0.9344598650932312
Validation loss: 2.12718133131663

Epoch: 6| Step: 4
Training loss: 1.3495529890060425
Validation loss: 2.090224266052246

Epoch: 6| Step: 5
Training loss: 1.46152925491333
Validation loss: 2.0906320810317993

Epoch: 6| Step: 6
Training loss: 2.320614814758301
Validation loss: 2.0979949235916138

Epoch: 6| Step: 7
Training loss: 1.103874921798706
Validation loss: 2.091841479142507

Epoch: 6| Step: 8
Training loss: 1.7805837392807007
Validation loss: 2.069831351439158

Epoch: 6| Step: 9
Training loss: 1.895709753036499
Validation loss: 2.0941170851389566

Epoch: 6| Step: 10
Training loss: 1.180337905883789
Validation loss: 2.0805811087290444

Epoch: 6| Step: 11
Training loss: 1.1265170574188232
Validation loss: 2.078676780064901

Epoch: 6| Step: 12
Training loss: 1.498309850692749
Validation loss: 2.094526012738546

Epoch: 6| Step: 13
Training loss: 1.8839980363845825
Validation loss: 2.0649855534235635

Epoch: 93| Step: 0
Training loss: 1.0450383424758911
Validation loss: 2.0715891321500144

Epoch: 6| Step: 1
Training loss: 1.1452369689941406
Validation loss: 2.0601807634035745

Epoch: 6| Step: 2
Training loss: 1.5652315616607666
Validation loss: 2.1149283250172934

Epoch: 6| Step: 3
Training loss: 1.4138576984405518
Validation loss: 2.076421320438385

Epoch: 6| Step: 4
Training loss: 1.3281704187393188
Validation loss: 2.084977408250173

Epoch: 6| Step: 5
Training loss: 1.8366906642913818
Validation loss: 2.095952868461609

Epoch: 6| Step: 6
Training loss: 2.685350179672241
Validation loss: 2.112372954686483

Epoch: 6| Step: 7
Training loss: 1.4884684085845947
Validation loss: 2.135710616906484

Epoch: 6| Step: 8
Training loss: 1.4450958967208862
Validation loss: 2.120181083679199

Epoch: 6| Step: 9
Training loss: 1.5157585144042969
Validation loss: 2.1280317306518555

Epoch: 6| Step: 10
Training loss: 1.2342625856399536
Validation loss: 2.095981160799662

Epoch: 6| Step: 11
Training loss: 1.3834640979766846
Validation loss: 2.052190979321798

Epoch: 6| Step: 12
Training loss: 1.579360008239746
Validation loss: 2.056653141975403

Epoch: 6| Step: 13
Training loss: 1.806013822555542
Validation loss: 2.048636178175608

Epoch: 94| Step: 0
Training loss: 1.8133158683776855
Validation loss: 2.054823716481527

Epoch: 6| Step: 1
Training loss: 1.2085375785827637
Validation loss: 2.0663277904192605

Epoch: 6| Step: 2
Training loss: 1.1554770469665527
Validation loss: 2.0462100903193154

Epoch: 6| Step: 3
Training loss: 1.2419124841690063
Validation loss: 2.086040278275808

Epoch: 6| Step: 4
Training loss: 1.714827537536621
Validation loss: 2.062986115614573

Epoch: 6| Step: 5
Training loss: 1.5758368968963623
Validation loss: 2.06086673339208

Epoch: 6| Step: 6
Training loss: 1.0648157596588135
Validation loss: 2.119703769683838

Epoch: 6| Step: 7
Training loss: 2.0695719718933105
Validation loss: 2.1475510001182556

Epoch: 6| Step: 8
Training loss: 1.4514517784118652
Validation loss: 2.144026776154836

Epoch: 6| Step: 9
Training loss: 1.7701008319854736
Validation loss: 2.141216595967611

Epoch: 6| Step: 10
Training loss: 1.4035122394561768
Validation loss: 2.177052895228068

Epoch: 6| Step: 11
Training loss: 1.139103889465332
Validation loss: 2.1183350682258606

Epoch: 6| Step: 12
Training loss: 1.284938097000122
Validation loss: 2.122022271156311

Epoch: 6| Step: 13
Training loss: 1.7044010162353516
Validation loss: 2.060121993223826

Epoch: 95| Step: 0
Training loss: 1.1957718133926392
Validation loss: 2.0491650899251304

Epoch: 6| Step: 1
Training loss: 2.0255465507507324
Validation loss: 2.0749924977620444

Epoch: 6| Step: 2
Training loss: 1.6595135927200317
Validation loss: 2.0922951300938926

Epoch: 6| Step: 3
Training loss: 0.7696375846862793
Validation loss: 2.0678000847498574

Epoch: 6| Step: 4
Training loss: 2.00766658782959
Validation loss: 2.087410549322764

Epoch: 6| Step: 5
Training loss: 1.3081471920013428
Validation loss: 2.077996810277303

Epoch: 6| Step: 6
Training loss: 1.0468380451202393
Validation loss: 2.1058809955914817

Epoch: 6| Step: 7
Training loss: 1.298604965209961
Validation loss: 2.092923879623413

Epoch: 6| Step: 8
Training loss: 1.9883726835250854
Validation loss: 2.106499354044596

Epoch: 6| Step: 9
Training loss: 1.9825177192687988
Validation loss: 2.11395670970281

Epoch: 6| Step: 10
Training loss: 0.9645384550094604
Validation loss: 2.0993959307670593

Epoch: 6| Step: 11
Training loss: 1.6388895511627197
Validation loss: 2.071835378805796

Epoch: 6| Step: 12
Training loss: 1.4612571001052856
Validation loss: 2.0641029278437295

Epoch: 6| Step: 13
Training loss: 1.294712781906128
Validation loss: 2.0786137779553733

Epoch: 96| Step: 0
Training loss: 2.0233397483825684
Validation loss: 2.0619386235872903

Epoch: 6| Step: 1
Training loss: 1.858783483505249
Validation loss: 2.085570236047109

Epoch: 6| Step: 2
Training loss: 1.0100443363189697
Validation loss: 2.0865890979766846

Epoch: 6| Step: 3
Training loss: 1.7237141132354736
Validation loss: 2.075916131337484

Epoch: 6| Step: 4
Training loss: 1.1362024545669556
Validation loss: 2.0578808387120566

Epoch: 6| Step: 5
Training loss: 0.9581284523010254
Validation loss: 2.090014318625132

Epoch: 6| Step: 6
Training loss: 1.285273551940918
Validation loss: 2.0598504344622293

Epoch: 6| Step: 7
Training loss: 1.6853291988372803
Validation loss: 2.0696818232536316

Epoch: 6| Step: 8
Training loss: 1.4531651735305786
Validation loss: 2.124868392944336

Epoch: 6| Step: 9
Training loss: 1.3604795932769775
Validation loss: 2.1180954376856485

Epoch: 6| Step: 10
Training loss: 1.591475486755371
Validation loss: 2.1630248626073203

Epoch: 6| Step: 11
Training loss: 1.9207813739776611
Validation loss: 2.092290242513021

Epoch: 6| Step: 12
Training loss: 1.0948593616485596
Validation loss: 2.1199477712313333

Epoch: 6| Step: 13
Training loss: 1.3995416164398193
Validation loss: 2.1056244373321533

Epoch: 97| Step: 0
Training loss: 1.5715734958648682
Validation loss: 2.0981728235880532

Epoch: 6| Step: 1
Training loss: 1.8360867500305176
Validation loss: 2.095856726169586

Epoch: 6| Step: 2
Training loss: 2.0549540519714355
Validation loss: 2.0885072350502014

Epoch: 6| Step: 3
Training loss: 1.3884124755859375
Validation loss: 2.0775950153668723

Epoch: 6| Step: 4
Training loss: 1.9342944622039795
Validation loss: 2.1092946529388428

Epoch: 6| Step: 5
Training loss: 1.0760918855667114
Validation loss: 2.0797698895136514

Epoch: 6| Step: 6
Training loss: 1.061509609222412
Validation loss: 2.1002028783162436

Epoch: 6| Step: 7
Training loss: 1.3032050132751465
Validation loss: 2.090156376361847

Epoch: 6| Step: 8
Training loss: 1.3382736444473267
Validation loss: 2.073616107304891

Epoch: 6| Step: 9
Training loss: 1.191978096961975
Validation loss: 2.120154400666555

Epoch: 6| Step: 10
Training loss: 0.65767502784729
Validation loss: 2.1426058212916055

Epoch: 6| Step: 11
Training loss: 1.7524845600128174
Validation loss: 2.1257214347521463

Epoch: 6| Step: 12
Training loss: 1.7882578372955322
Validation loss: 2.0961950620015464

Epoch: 6| Step: 13
Training loss: 1.425423502922058
Validation loss: 2.158973217010498

Epoch: 98| Step: 0
Training loss: 1.3085463047027588
Validation loss: 2.0951345364252725

Epoch: 6| Step: 1
Training loss: 1.3256009817123413
Validation loss: 2.1101835568745932

Epoch: 6| Step: 2
Training loss: 1.7346258163452148
Validation loss: 2.1009909907976785

Epoch: 6| Step: 3
Training loss: 1.4132843017578125
Validation loss: 2.0960746010144553

Epoch: 6| Step: 4
Training loss: 1.3903602361679077
Validation loss: 2.107359449068705

Epoch: 6| Step: 5
Training loss: 1.3042634725570679
Validation loss: 2.0881272355715432

Epoch: 6| Step: 6
Training loss: 1.7551982402801514
Validation loss: 2.0903320709864297

Epoch: 6| Step: 7
Training loss: 1.0885940790176392
Validation loss: 2.079933285713196

Epoch: 6| Step: 8
Training loss: 1.7200164794921875
Validation loss: 2.0560659368832908

Epoch: 6| Step: 9
Training loss: 1.3506433963775635
Validation loss: 2.0613133112589517

Epoch: 6| Step: 10
Training loss: 1.1919207572937012
Validation loss: 2.0665545662244162

Epoch: 6| Step: 11
Training loss: 1.9694068431854248
Validation loss: 2.05331156651179

Epoch: 6| Step: 12
Training loss: 1.011443853378296
Validation loss: 2.109926482041677

Epoch: 6| Step: 13
Training loss: 1.5209681987762451
Validation loss: 2.0585100054740906

Epoch: 99| Step: 0
Training loss: 0.8211130499839783
Validation loss: 2.103608012199402

Epoch: 6| Step: 1
Training loss: 1.8109925985336304
Validation loss: 2.085068464279175

Epoch: 6| Step: 2
Training loss: 1.6167042255401611
Validation loss: 2.1241055130958557

Epoch: 6| Step: 3
Training loss: 1.5844179391860962
Validation loss: 2.143316904703776

Epoch: 6| Step: 4
Training loss: 2.3491907119750977
Validation loss: 2.217613776524862

Epoch: 6| Step: 5
Training loss: 1.783339023590088
Validation loss: 2.1810137828191123

Epoch: 6| Step: 6
Training loss: 1.522797703742981
Validation loss: 2.157506227493286

Epoch: 6| Step: 7
Training loss: 1.2869526147842407
Validation loss: 2.1390753984451294

Epoch: 6| Step: 8
Training loss: 0.9711310863494873
Validation loss: 2.0871477524439492

Epoch: 6| Step: 9
Training loss: 0.8379747867584229
Validation loss: 2.0731986363728843

Epoch: 6| Step: 10
Training loss: 1.5072875022888184
Validation loss: 2.0444175799687705

Epoch: 6| Step: 11
Training loss: 1.8037636280059814
Validation loss: 2.087563455104828

Epoch: 6| Step: 12
Training loss: 1.6921201944351196
Validation loss: 2.0490890940030417

Epoch: 6| Step: 13
Training loss: 1.4986720085144043
Validation loss: 2.064084271589915

Epoch: 100| Step: 0
Training loss: 1.759520411491394
Validation loss: 2.0429693460464478

Epoch: 6| Step: 1
Training loss: 1.2730273008346558
Validation loss: 2.0370059808095298

Epoch: 6| Step: 2
Training loss: 1.4618815183639526
Validation loss: 2.0603084166844687

Epoch: 6| Step: 3
Training loss: 1.5645545721054077
Validation loss: 2.0573407808939614

Epoch: 6| Step: 4
Training loss: 1.1620510816574097
Validation loss: 2.080713987350464

Epoch: 6| Step: 5
Training loss: 1.2164075374603271
Validation loss: 2.0568665266036987

Epoch: 6| Step: 6
Training loss: 1.8129782676696777
Validation loss: 2.1466250816980996

Epoch: 6| Step: 7
Training loss: 1.4064254760742188
Validation loss: 2.0984277725219727

Epoch: 6| Step: 8
Training loss: 1.322821855545044
Validation loss: 2.138369560241699

Epoch: 6| Step: 9
Training loss: 1.2706613540649414
Validation loss: 2.135274648666382

Epoch: 6| Step: 10
Training loss: 1.4157147407531738
Validation loss: 2.1262444257736206

Epoch: 6| Step: 11
Training loss: 2.0504794120788574
Validation loss: 2.0957470536231995

Epoch: 6| Step: 12
Training loss: 1.0893205404281616
Validation loss: 2.092896302541097

Epoch: 6| Step: 13
Training loss: 1.3779935836791992
Validation loss: 2.0888521869977317

Epoch: 101| Step: 0
Training loss: 1.096582293510437
Validation loss: 2.064276874065399

Epoch: 6| Step: 1
Training loss: 2.0941367149353027
Validation loss: 2.082521895567576

Epoch: 6| Step: 2
Training loss: 1.447064757347107
Validation loss: 2.081380029519399

Epoch: 6| Step: 3
Training loss: 0.917170524597168
Validation loss: 2.051863690217336

Epoch: 6| Step: 4
Training loss: 1.1740977764129639
Validation loss: 2.078874925772349

Epoch: 6| Step: 5
Training loss: 1.4339122772216797
Validation loss: 2.0657806396484375

Epoch: 6| Step: 6
Training loss: 1.4048035144805908
Validation loss: 2.0754464070002236

Epoch: 6| Step: 7
Training loss: 1.3019996881484985
Validation loss: 2.060979962348938

Epoch: 6| Step: 8
Training loss: 1.6824462413787842
Validation loss: 2.1011140942573547

Epoch: 6| Step: 9
Training loss: 1.9625086784362793
Validation loss: 2.104724923769633

Epoch: 6| Step: 10
Training loss: 1.7925636768341064
Validation loss: 2.090260326862335

Epoch: 6| Step: 11
Training loss: 1.3854670524597168
Validation loss: 2.0874401926994324

Epoch: 6| Step: 12
Training loss: 1.2048676013946533
Validation loss: 2.0909206668535867

Epoch: 6| Step: 13
Training loss: 1.0207514762878418
Validation loss: 2.1508905490239463

Epoch: 102| Step: 0
Training loss: 1.2414166927337646
Validation loss: 2.1305553714434304

Epoch: 6| Step: 1
Training loss: 1.8207072019577026
Validation loss: 2.1097915172576904

Epoch: 6| Step: 2
Training loss: 1.4414864778518677
Validation loss: 2.1029469768206277

Epoch: 6| Step: 3
Training loss: 1.9770398139953613
Validation loss: 2.056264857451121

Epoch: 6| Step: 4
Training loss: 1.3917646408081055
Validation loss: 2.0780010422070823

Epoch: 6| Step: 5
Training loss: 1.4059712886810303
Validation loss: 2.1020864049593606

Epoch: 6| Step: 6
Training loss: 1.1973240375518799
Validation loss: 2.116372068723043

Epoch: 6| Step: 7
Training loss: 0.7523120641708374
Validation loss: 2.058595597743988

Epoch: 6| Step: 8
Training loss: 1.5361998081207275
Validation loss: 2.046628932158152

Epoch: 6| Step: 9
Training loss: 1.1873202323913574
Validation loss: 2.1159889499346414

Epoch: 6| Step: 10
Training loss: 1.0480693578720093
Validation loss: 2.1235573291778564

Epoch: 6| Step: 11
Training loss: 1.729635238647461
Validation loss: 2.1466237505277

Epoch: 6| Step: 12
Training loss: 1.4485670328140259
Validation loss: 2.1235692699750266

Epoch: 6| Step: 13
Training loss: 1.5630675554275513
Validation loss: 2.1469819148381553

Epoch: 103| Step: 0
Training loss: 1.2207825183868408
Validation loss: 2.1113704641660056

Epoch: 6| Step: 1
Training loss: 1.4852468967437744
Validation loss: 2.129305839538574

Epoch: 6| Step: 2
Training loss: 0.8444027900695801
Validation loss: 2.102289835611979

Epoch: 6| Step: 3
Training loss: 1.2552486658096313
Validation loss: 2.174725592136383

Epoch: 6| Step: 4
Training loss: 2.2846755981445312
Validation loss: 2.1181381344795227

Epoch: 6| Step: 5
Training loss: 1.2459583282470703
Validation loss: 2.0867576797803244

Epoch: 6| Step: 6
Training loss: 1.521194338798523
Validation loss: 2.068365474541982

Epoch: 6| Step: 7
Training loss: 0.9273442029953003
Validation loss: 2.0735504229863486

Epoch: 6| Step: 8
Training loss: 1.3141530752182007
Validation loss: 2.090405444304148

Epoch: 6| Step: 9
Training loss: 1.9466694593429565
Validation loss: 2.084462821483612

Epoch: 6| Step: 10
Training loss: 1.433374285697937
Validation loss: 2.089117924372355

Epoch: 6| Step: 11
Training loss: 1.3945860862731934
Validation loss: 2.0756033062934875

Epoch: 6| Step: 12
Training loss: 1.2856674194335938
Validation loss: 2.090768655141195

Epoch: 6| Step: 13
Training loss: 1.4140772819519043
Validation loss: 2.0582706928253174

Epoch: 104| Step: 0
Training loss: 1.5069003105163574
Validation loss: 2.0760770042737327

Epoch: 6| Step: 1
Training loss: 1.4227339029312134
Validation loss: 2.115238149960836

Epoch: 6| Step: 2
Training loss: 1.0144786834716797
Validation loss: 2.0977500478426614

Epoch: 6| Step: 3
Training loss: 1.0503276586532593
Validation loss: 2.062131702899933

Epoch: 6| Step: 4
Training loss: 1.2805137634277344
Validation loss: 2.0957109332084656

Epoch: 6| Step: 5
Training loss: 1.158116102218628
Validation loss: 2.07500022649765

Epoch: 6| Step: 6
Training loss: 1.5814142227172852
Validation loss: 2.0663309494654336

Epoch: 6| Step: 7
Training loss: 1.3213860988616943
Validation loss: 2.101896643638611

Epoch: 6| Step: 8
Training loss: 1.4012198448181152
Validation loss: 2.1446064909299216

Epoch: 6| Step: 9
Training loss: 0.9367493391036987
Validation loss: 2.1032109459241233

Epoch: 6| Step: 10
Training loss: 1.3302472829818726
Validation loss: 2.1127981146176658

Epoch: 6| Step: 11
Training loss: 1.72337007522583
Validation loss: 2.057389756043752

Epoch: 6| Step: 12
Training loss: 1.756572961807251
Validation loss: 2.0490251580874124

Epoch: 6| Step: 13
Training loss: 2.075068235397339
Validation loss: 2.080280085404714

Epoch: 105| Step: 0
Training loss: 1.2032651901245117
Validation loss: 2.081778029600779

Epoch: 6| Step: 1
Training loss: 2.13132905960083
Validation loss: 2.0829046964645386

Epoch: 6| Step: 2
Training loss: 1.7013285160064697
Validation loss: 2.078374922275543

Epoch: 6| Step: 3
Training loss: 1.042105793952942
Validation loss: 2.123852769533793

Epoch: 6| Step: 4
Training loss: 1.3960461616516113
Validation loss: 2.076718886693319

Epoch: 6| Step: 5
Training loss: 1.133653163909912
Validation loss: 2.1373515725135803

Epoch: 6| Step: 6
Training loss: 1.329716444015503
Validation loss: 2.095782518386841

Epoch: 6| Step: 7
Training loss: 1.0518336296081543
Validation loss: 2.101584037144979

Epoch: 6| Step: 8
Training loss: 0.7317458391189575
Validation loss: 2.128861943880717

Epoch: 6| Step: 9
Training loss: 1.725461483001709
Validation loss: 2.069210112094879

Epoch: 6| Step: 10
Training loss: 1.6746431589126587
Validation loss: 2.092066546281179

Epoch: 6| Step: 11
Training loss: 1.289038896560669
Validation loss: 2.103764533996582

Epoch: 6| Step: 12
Training loss: 1.2872179746627808
Validation loss: 2.085740248362223

Epoch: 6| Step: 13
Training loss: 0.9958339929580688
Validation loss: 2.0970803101857505

Epoch: 106| Step: 0
Training loss: 1.2170932292938232
Validation loss: 2.077941656112671

Epoch: 6| Step: 1
Training loss: 1.1887706518173218
Validation loss: 2.072264234224955

Epoch: 6| Step: 2
Training loss: 1.6096552610397339
Validation loss: 2.070830504099528

Epoch: 6| Step: 3
Training loss: 0.881447970867157
Validation loss: 2.0993221402168274

Epoch: 6| Step: 4
Training loss: 1.0803332328796387
Validation loss: 2.118538796901703

Epoch: 6| Step: 5
Training loss: 1.491626501083374
Validation loss: 2.0936745405197144

Epoch: 6| Step: 6
Training loss: 1.0440781116485596
Validation loss: 2.121224661668142

Epoch: 6| Step: 7
Training loss: 1.4600783586502075
Validation loss: 2.0872148871421814

Epoch: 6| Step: 8
Training loss: 1.0912508964538574
Validation loss: 2.111282686392466

Epoch: 6| Step: 9
Training loss: 2.157723903656006
Validation loss: 2.090564787387848

Epoch: 6| Step: 10
Training loss: 1.4618356227874756
Validation loss: 2.0453752676645913

Epoch: 6| Step: 11
Training loss: 1.8994009494781494
Validation loss: 2.060862958431244

Epoch: 6| Step: 12
Training loss: 1.7666091918945312
Validation loss: 2.0678900480270386

Epoch: 6| Step: 13
Training loss: 0.8077676296234131
Validation loss: 2.073120951652527

Epoch: 107| Step: 0
Training loss: 1.3245205879211426
Validation loss: 2.05909796555837

Epoch: 6| Step: 1
Training loss: 1.3918921947479248
Validation loss: 2.074473758538564

Epoch: 6| Step: 2
Training loss: 1.3746097087860107
Validation loss: 2.080415348211924

Epoch: 6| Step: 3
Training loss: 1.2675955295562744
Validation loss: 2.073453644911448

Epoch: 6| Step: 4
Training loss: 0.8954477310180664
Validation loss: 2.1248808105786643

Epoch: 6| Step: 5
Training loss: 1.2908998727798462
Validation loss: 2.0635211070378623

Epoch: 6| Step: 6
Training loss: 1.367857575416565
Validation loss: 2.075423757235209

Epoch: 6| Step: 7
Training loss: 1.0923155546188354
Validation loss: 2.1187365651130676

Epoch: 6| Step: 8
Training loss: 1.1063232421875
Validation loss: 2.081194758415222

Epoch: 6| Step: 9
Training loss: 1.3231055736541748
Validation loss: 2.133304476737976

Epoch: 6| Step: 10
Training loss: 1.0091185569763184
Validation loss: 2.1302282015482583

Epoch: 6| Step: 11
Training loss: 1.74678373336792
Validation loss: 2.0917043884595237

Epoch: 6| Step: 12
Training loss: 1.5664266347885132
Validation loss: 2.080160915851593

Epoch: 6| Step: 13
Training loss: 1.6926120519638062
Validation loss: 2.09277480840683

Epoch: 108| Step: 0
Training loss: 1.656428337097168
Validation loss: 2.0530282060305276

Epoch: 6| Step: 1
Training loss: 1.5360796451568604
Validation loss: 2.0636228919029236

Epoch: 6| Step: 2
Training loss: 2.1970295906066895
Validation loss: 2.094683289527893

Epoch: 6| Step: 3
Training loss: 1.4452276229858398
Validation loss: 2.058694084485372

Epoch: 6| Step: 4
Training loss: 1.2208189964294434
Validation loss: 2.08949742714564

Epoch: 6| Step: 5
Training loss: 1.1229486465454102
Validation loss: 2.0754926999409995

Epoch: 6| Step: 6
Training loss: 1.2402472496032715
Validation loss: 2.0655122796694436

Epoch: 6| Step: 7
Training loss: 1.295697569847107
Validation loss: 2.0926908453305564

Epoch: 6| Step: 8
Training loss: 1.3699235916137695
Validation loss: 2.1037471095720925

Epoch: 6| Step: 9
Training loss: 1.3429813385009766
Validation loss: 2.1266321341196694

Epoch: 6| Step: 10
Training loss: 0.7860983610153198
Validation loss: 2.0915732185045877

Epoch: 6| Step: 11
Training loss: 0.9964059591293335
Validation loss: 2.097481290499369

Epoch: 6| Step: 12
Training loss: 1.1066186428070068
Validation loss: 2.096130132675171

Epoch: 6| Step: 13
Training loss: 1.2864553928375244
Validation loss: 2.153528412183126

Epoch: 109| Step: 0
Training loss: 1.4242885112762451
Validation loss: 2.0654297272364297

Epoch: 6| Step: 1
Training loss: 0.7784900665283203
Validation loss: 2.087916533152262

Epoch: 6| Step: 2
Training loss: 1.4520974159240723
Validation loss: 2.1000152428944907

Epoch: 6| Step: 3
Training loss: 1.0715805292129517
Validation loss: 2.0664513309796653

Epoch: 6| Step: 4
Training loss: 1.3845587968826294
Validation loss: 2.0878056287765503

Epoch: 6| Step: 5
Training loss: 1.1158257722854614
Validation loss: 2.0655556122461953

Epoch: 6| Step: 6
Training loss: 1.3012847900390625
Validation loss: 2.0991510351498923

Epoch: 6| Step: 7
Training loss: 1.756765604019165
Validation loss: 2.08654131491979

Epoch: 6| Step: 8
Training loss: 1.1493127346038818
Validation loss: 2.098717431227366

Epoch: 6| Step: 9
Training loss: 1.7023701667785645
Validation loss: 2.09703266620636

Epoch: 6| Step: 10
Training loss: 1.648308515548706
Validation loss: 2.1363503336906433

Epoch: 6| Step: 11
Training loss: 1.2867351770401
Validation loss: 2.151718497276306

Epoch: 6| Step: 12
Training loss: 0.5831696391105652
Validation loss: 2.1051796873410544

Epoch: 6| Step: 13
Training loss: 1.7609920501708984
Validation loss: 2.108382523059845

Epoch: 110| Step: 0
Training loss: 1.8333079814910889
Validation loss: 2.081633746623993

Epoch: 6| Step: 1
Training loss: 0.9932316541671753
Validation loss: 2.084783991177877

Epoch: 6| Step: 2
Training loss: 1.4435396194458008
Validation loss: 2.0520272056261697

Epoch: 6| Step: 3
Training loss: 1.0443644523620605
Validation loss: 2.066097676753998

Epoch: 6| Step: 4
Training loss: 1.4084982872009277
Validation loss: 2.086426337560018

Epoch: 6| Step: 5
Training loss: 1.2711650133132935
Validation loss: 2.105772773424784

Epoch: 6| Step: 6
Training loss: 1.0368849039077759
Validation loss: 2.0981974403063455

Epoch: 6| Step: 7
Training loss: 1.2919577360153198
Validation loss: 2.1262871821721396

Epoch: 6| Step: 8
Training loss: 2.0654046535491943
Validation loss: 2.1084635655085244

Epoch: 6| Step: 9
Training loss: 1.3341867923736572
Validation loss: 2.107362449169159

Epoch: 6| Step: 10
Training loss: 0.649445652961731
Validation loss: 2.0913060704867044

Epoch: 6| Step: 11
Training loss: 1.6780599355697632
Validation loss: 2.1232974926630654

Epoch: 6| Step: 12
Training loss: 0.8451694250106812
Validation loss: 2.1267878214518228

Epoch: 6| Step: 13
Training loss: 1.4715715646743774
Validation loss: 2.101202448209127

Epoch: 111| Step: 0
Training loss: 1.9150760173797607
Validation loss: 2.126892864704132

Epoch: 6| Step: 1
Training loss: 0.9421207308769226
Validation loss: 2.108867108821869

Epoch: 6| Step: 2
Training loss: 1.3493404388427734
Validation loss: 2.09157387415568

Epoch: 6| Step: 3
Training loss: 1.4901782274246216
Validation loss: 2.0774064461390176

Epoch: 6| Step: 4
Training loss: 1.0691900253295898
Validation loss: 2.1126830180486045

Epoch: 6| Step: 5
Training loss: 1.608734369277954
Validation loss: 2.1033673087755838

Epoch: 6| Step: 6
Training loss: 1.1596258878707886
Validation loss: 2.1002355019251504

Epoch: 6| Step: 7
Training loss: 1.7261197566986084
Validation loss: 2.109648823738098

Epoch: 6| Step: 8
Training loss: 0.8409285545349121
Validation loss: 2.1026900808016458

Epoch: 6| Step: 9
Training loss: 1.5203711986541748
Validation loss: 2.1167136629422507

Epoch: 6| Step: 10
Training loss: 1.369958519935608
Validation loss: 2.1267838875452676

Epoch: 6| Step: 11
Training loss: 0.819212794303894
Validation loss: 2.1463610331217446

Epoch: 6| Step: 12
Training loss: 1.190004587173462
Validation loss: 2.115165968736013

Epoch: 6| Step: 13
Training loss: 1.4024908542633057
Validation loss: 2.124277949333191

Epoch: 112| Step: 0
Training loss: 1.4015562534332275
Validation loss: 2.106205105781555

Epoch: 6| Step: 1
Training loss: 0.9067442417144775
Validation loss: 2.0626651446024575

Epoch: 6| Step: 2
Training loss: 1.2585837841033936
Validation loss: 2.0844972729682922

Epoch: 6| Step: 3
Training loss: 1.8013124465942383
Validation loss: 2.1033475399017334

Epoch: 6| Step: 4
Training loss: 1.4671053886413574
Validation loss: 2.0619470278422036

Epoch: 6| Step: 5
Training loss: 1.1792619228363037
Validation loss: 2.060868283112844

Epoch: 6| Step: 6
Training loss: 1.1298795938491821
Validation loss: 2.117805997530619

Epoch: 6| Step: 7
Training loss: 1.1662112474441528
Validation loss: 2.1519177556037903

Epoch: 6| Step: 8
Training loss: 0.775269627571106
Validation loss: 2.1425777872403464

Epoch: 6| Step: 9
Training loss: 1.5681664943695068
Validation loss: 2.1251914699872336

Epoch: 6| Step: 10
Training loss: 2.133786678314209
Validation loss: 2.1447769006093345

Epoch: 6| Step: 11
Training loss: 1.60386323928833
Validation loss: 2.1080970565478006

Epoch: 6| Step: 12
Training loss: 0.9151167869567871
Validation loss: 2.0860305229822793

Epoch: 6| Step: 13
Training loss: 0.8289856910705566
Validation loss: 2.1630098819732666

Epoch: 113| Step: 0
Training loss: 1.7852652072906494
Validation loss: 2.129683514436086

Epoch: 6| Step: 1
Training loss: 1.238396406173706
Validation loss: 2.108409861723582

Epoch: 6| Step: 2
Training loss: 0.9819614887237549
Validation loss: 2.089375098546346

Epoch: 6| Step: 3
Training loss: 1.3937160968780518
Validation loss: 2.0559302965799966

Epoch: 6| Step: 4
Training loss: 1.2513642311096191
Validation loss: 2.09139347076416

Epoch: 6| Step: 5
Training loss: 1.548933744430542
Validation loss: 2.0881603360176086

Epoch: 6| Step: 6
Training loss: 1.0450544357299805
Validation loss: 2.1076377431551614

Epoch: 6| Step: 7
Training loss: 1.4387184381484985
Validation loss: 2.0796344677607217

Epoch: 6| Step: 8
Training loss: 1.4833320379257202
Validation loss: 2.084704577922821

Epoch: 6| Step: 9
Training loss: 1.2277047634124756
Validation loss: 2.126512626806895

Epoch: 6| Step: 10
Training loss: 1.2054802179336548
Validation loss: 2.156047602494558

Epoch: 6| Step: 11
Training loss: 1.3596580028533936
Validation loss: 2.0810468395551047

Epoch: 6| Step: 12
Training loss: 0.9875378012657166
Validation loss: 2.128352642059326

Epoch: 6| Step: 13
Training loss: 0.9368163347244263
Validation loss: 2.121419290701548

Epoch: 114| Step: 0
Training loss: 1.8581005334854126
Validation loss: 2.0866955320040383

Epoch: 6| Step: 1
Training loss: 1.0077483654022217
Validation loss: 2.1379376649856567

Epoch: 6| Step: 2
Training loss: 1.3425202369689941
Validation loss: 2.1445703506469727

Epoch: 6| Step: 3
Training loss: 1.7519830465316772
Validation loss: 2.133767386277517

Epoch: 6| Step: 4
Training loss: 1.2595317363739014
Validation loss: 2.082895795504252

Epoch: 6| Step: 5
Training loss: 1.2091602087020874
Validation loss: 2.117867946624756

Epoch: 6| Step: 6
Training loss: 1.5018748044967651
Validation loss: 2.083461582660675

Epoch: 6| Step: 7
Training loss: 1.0519956350326538
Validation loss: 2.1198476552963257

Epoch: 6| Step: 8
Training loss: 0.8895544409751892
Validation loss: 2.1173985997835794

Epoch: 6| Step: 9
Training loss: 1.0104159116744995
Validation loss: 2.100994030634562

Epoch: 6| Step: 10
Training loss: 1.153050184249878
Validation loss: 2.09658149878184

Epoch: 6| Step: 11
Training loss: 1.7279900312423706
Validation loss: 2.098097324371338

Epoch: 6| Step: 12
Training loss: 1.1267969608306885
Validation loss: 2.080255925655365

Epoch: 6| Step: 13
Training loss: 1.0228569507598877
Validation loss: 2.11107861995697

Epoch: 115| Step: 0
Training loss: 1.290400505065918
Validation loss: 2.0926942825317383

Epoch: 6| Step: 1
Training loss: 1.1695427894592285
Validation loss: 2.137460390726725

Epoch: 6| Step: 2
Training loss: 1.2497683763504028
Validation loss: 2.087403118610382

Epoch: 6| Step: 3
Training loss: 1.7479299306869507
Validation loss: 2.050662120183309

Epoch: 6| Step: 4
Training loss: 1.0393081903457642
Validation loss: 2.068191627661387

Epoch: 6| Step: 5
Training loss: 0.7201392650604248
Validation loss: 2.115217407544454

Epoch: 6| Step: 6
Training loss: 1.5638107061386108
Validation loss: 2.0844667752583823

Epoch: 6| Step: 7
Training loss: 0.8869683742523193
Validation loss: 2.072961151599884

Epoch: 6| Step: 8
Training loss: 0.8225465416908264
Validation loss: 2.0947340528170266

Epoch: 6| Step: 9
Training loss: 1.407165765762329
Validation loss: 2.1134287317593894

Epoch: 6| Step: 10
Training loss: 1.120021104812622
Validation loss: 2.1217177311579385

Epoch: 6| Step: 11
Training loss: 1.345685362815857
Validation loss: 2.1314600904782615

Epoch: 6| Step: 12
Training loss: 1.1748472452163696
Validation loss: 2.1362707018852234

Epoch: 6| Step: 13
Training loss: 1.557013750076294
Validation loss: 2.095486362775167

Epoch: 116| Step: 0
Training loss: 1.300389051437378
Validation loss: 2.092417041460673

Epoch: 6| Step: 1
Training loss: 1.0447187423706055
Validation loss: 2.104770064353943

Epoch: 6| Step: 2
Training loss: 1.1996906995773315
Validation loss: 2.068617343902588

Epoch: 6| Step: 3
Training loss: 0.9413008689880371
Validation loss: 2.053640286127726

Epoch: 6| Step: 4
Training loss: 1.3780266046524048
Validation loss: 2.115045885245005

Epoch: 6| Step: 5
Training loss: 1.4643683433532715
Validation loss: 2.098246971766154

Epoch: 6| Step: 6
Training loss: 1.6477229595184326
Validation loss: 2.0762869914372764

Epoch: 6| Step: 7
Training loss: 1.179307460784912
Validation loss: 2.1025603612264

Epoch: 6| Step: 8
Training loss: 1.190454363822937
Validation loss: 2.087368647257487

Epoch: 6| Step: 9
Training loss: 1.5938289165496826
Validation loss: 2.1029067635536194

Epoch: 6| Step: 10
Training loss: 1.229550838470459
Validation loss: 2.124292314052582

Epoch: 6| Step: 11
Training loss: 1.187026023864746
Validation loss: 2.1151429414749146

Epoch: 6| Step: 12
Training loss: 0.5410583019256592
Validation loss: 2.0806470115979514

Epoch: 6| Step: 13
Training loss: 1.3968919515609741
Validation loss: 2.0926151474316916

Epoch: 117| Step: 0
Training loss: 1.0537391901016235
Validation loss: 2.1386375228563943

Epoch: 6| Step: 1
Training loss: 1.4087450504302979
Validation loss: 2.124979555606842

Epoch: 6| Step: 2
Training loss: 1.4045076370239258
Validation loss: 2.056865076224009

Epoch: 6| Step: 3
Training loss: 0.916965901851654
Validation loss: 2.0870155692100525

Epoch: 6| Step: 4
Training loss: 1.021232008934021
Validation loss: 2.0606109301249185

Epoch: 6| Step: 5
Training loss: 1.9092057943344116
Validation loss: 2.045301636060079

Epoch: 6| Step: 6
Training loss: 1.0524272918701172
Validation loss: 2.0663360754648843

Epoch: 6| Step: 7
Training loss: 1.017852544784546
Validation loss: 2.077481289704641

Epoch: 6| Step: 8
Training loss: 1.0665525197982788
Validation loss: 2.0558212995529175

Epoch: 6| Step: 9
Training loss: 1.3594920635223389
Validation loss: 2.0747989217440286

Epoch: 6| Step: 10
Training loss: 0.8082829713821411
Validation loss: 2.089512526988983

Epoch: 6| Step: 11
Training loss: 1.40598726272583
Validation loss: 2.1048851807912192

Epoch: 6| Step: 12
Training loss: 1.4997869729995728
Validation loss: 2.13936847448349

Epoch: 6| Step: 13
Training loss: 1.305907964706421
Validation loss: 2.146671414375305

Epoch: 118| Step: 0
Training loss: 0.7615410089492798
Validation loss: 2.1079593300819397

Epoch: 6| Step: 1
Training loss: 1.3810617923736572
Validation loss: 2.0741086999575296

Epoch: 6| Step: 2
Training loss: 0.726011335849762
Validation loss: 2.0608869393666587

Epoch: 6| Step: 3
Training loss: 0.962124228477478
Validation loss: 2.0926213463147483

Epoch: 6| Step: 4
Training loss: 1.6323788166046143
Validation loss: 2.0700897177060447

Epoch: 6| Step: 5
Training loss: 1.6075692176818848
Validation loss: 2.0612656275431314

Epoch: 6| Step: 6
Training loss: 1.4444084167480469
Validation loss: 2.057615498701731

Epoch: 6| Step: 7
Training loss: 1.575071096420288
Validation loss: 2.0516380866368613

Epoch: 6| Step: 8
Training loss: 0.847403883934021
Validation loss: 2.090746819972992

Epoch: 6| Step: 9
Training loss: 1.473783016204834
Validation loss: 2.0959366957346597

Epoch: 6| Step: 10
Training loss: 1.427765130996704
Validation loss: 2.0494545499483743

Epoch: 6| Step: 11
Training loss: 1.4069387912750244
Validation loss: 2.040884256362915

Epoch: 6| Step: 12
Training loss: 1.0426902770996094
Validation loss: 2.0637958645820618

Epoch: 6| Step: 13
Training loss: 0.7859447002410889
Validation loss: 2.0675047636032104

Epoch: 119| Step: 0
Training loss: 0.9036878943443298
Validation loss: 2.0804034074147544

Epoch: 6| Step: 1
Training loss: 0.8218649625778198
Validation loss: 2.096350908279419

Epoch: 6| Step: 2
Training loss: 1.4582364559173584
Validation loss: 2.1334970196088157

Epoch: 6| Step: 3
Training loss: 1.4922847747802734
Validation loss: 2.1531877319018045

Epoch: 6| Step: 4
Training loss: 1.08768630027771
Validation loss: 2.062613785266876

Epoch: 6| Step: 5
Training loss: 1.6109603643417358
Validation loss: 2.082764526208242

Epoch: 6| Step: 6
Training loss: 0.8462308645248413
Validation loss: 2.06351230541865

Epoch: 6| Step: 7
Training loss: 1.5921339988708496
Validation loss: 2.0780561566352844

Epoch: 6| Step: 8
Training loss: 0.8875588774681091
Validation loss: 2.072218736012777

Epoch: 6| Step: 9
Training loss: 1.6705496311187744
Validation loss: 2.0674113233884177

Epoch: 6| Step: 10
Training loss: 1.4508167505264282
Validation loss: 2.0416797598203025

Epoch: 6| Step: 11
Training loss: 1.0350563526153564
Validation loss: 2.0932436188062034

Epoch: 6| Step: 12
Training loss: 0.7727451324462891
Validation loss: 2.0751572450002036

Epoch: 6| Step: 13
Training loss: 1.6353516578674316
Validation loss: 2.0744533936182656

Epoch: 120| Step: 0
Training loss: 0.8887702226638794
Validation loss: 2.0879311760266623

Epoch: 6| Step: 1
Training loss: 1.607377290725708
Validation loss: 2.056418557961782

Epoch: 6| Step: 2
Training loss: 1.4403116703033447
Validation loss: 2.039774020512899

Epoch: 6| Step: 3
Training loss: 1.4758659601211548
Validation loss: 2.0777774453163147

Epoch: 6| Step: 4
Training loss: 1.3497227430343628
Validation loss: 2.0806103348731995

Epoch: 6| Step: 5
Training loss: 1.063011646270752
Validation loss: 2.0681277910868325

Epoch: 6| Step: 6
Training loss: 1.1616113185882568
Validation loss: 2.11251171429952

Epoch: 6| Step: 7
Training loss: 1.54633367061615
Validation loss: 2.150442679723104

Epoch: 6| Step: 8
Training loss: 0.977917492389679
Validation loss: 2.0685435136159263

Epoch: 6| Step: 9
Training loss: 1.2365894317626953
Validation loss: 2.0971721609433494

Epoch: 6| Step: 10
Training loss: 1.1715896129608154
Validation loss: 2.129859189192454

Epoch: 6| Step: 11
Training loss: 1.137244701385498
Validation loss: 2.08148185412089

Epoch: 6| Step: 12
Training loss: 0.5388919115066528
Validation loss: 2.082913855711619

Epoch: 6| Step: 13
Training loss: 1.0745010375976562
Validation loss: 2.1005624532699585

Epoch: 121| Step: 0
Training loss: 1.3718600273132324
Validation loss: 2.1144783894220986

Epoch: 6| Step: 1
Training loss: 0.9805045127868652
Validation loss: 2.0696573654810586

Epoch: 6| Step: 2
Training loss: 0.8409099578857422
Validation loss: 2.1087612311045327

Epoch: 6| Step: 3
Training loss: 1.4664268493652344
Validation loss: 2.132571538289388

Epoch: 6| Step: 4
Training loss: 0.9703847169876099
Validation loss: 2.1175366242726645

Epoch: 6| Step: 5
Training loss: 1.154163122177124
Validation loss: 2.0861802895863852

Epoch: 6| Step: 6
Training loss: 1.1905139684677124
Validation loss: 2.078027625878652

Epoch: 6| Step: 7
Training loss: 1.6953623294830322
Validation loss: 2.104356904824575

Epoch: 6| Step: 8
Training loss: 0.800411581993103
Validation loss: 2.0679850975672402

Epoch: 6| Step: 9
Training loss: 1.4466915130615234
Validation loss: 2.089711904525757

Epoch: 6| Step: 10
Training loss: 0.6466495990753174
Validation loss: 2.05186136563619

Epoch: 6| Step: 11
Training loss: 1.1379284858703613
Validation loss: 2.059780557950338

Epoch: 6| Step: 12
Training loss: 1.854029655456543
Validation loss: 2.0523493687311807

Epoch: 6| Step: 13
Training loss: 0.8860448002815247
Validation loss: 2.0916872024536133

Epoch: 122| Step: 0
Training loss: 1.1509382724761963
Validation loss: 2.0632887482643127

Epoch: 6| Step: 1
Training loss: 1.4668159484863281
Validation loss: 2.0816720128059387

Epoch: 6| Step: 2
Training loss: 1.1837005615234375
Validation loss: 2.105319380760193

Epoch: 6| Step: 3
Training loss: 0.9880872368812561
Validation loss: 2.0721157987912497

Epoch: 6| Step: 4
Training loss: 1.523353934288025
Validation loss: 2.089596172173818

Epoch: 6| Step: 5
Training loss: 0.7977876663208008
Validation loss: 2.1070615450541177

Epoch: 6| Step: 6
Training loss: 1.1923222541809082
Validation loss: 2.0751073161760965

Epoch: 6| Step: 7
Training loss: 1.210371494293213
Validation loss: 2.098935544490814

Epoch: 6| Step: 8
Training loss: 0.6649308204650879
Validation loss: 2.074174483617147

Epoch: 6| Step: 9
Training loss: 1.095447063446045
Validation loss: 2.0808032155036926

Epoch: 6| Step: 10
Training loss: 1.5872743129730225
Validation loss: 2.0472874840100608

Epoch: 6| Step: 11
Training loss: 0.9093455076217651
Validation loss: 2.0825958251953125

Epoch: 6| Step: 12
Training loss: 1.8537393808364868
Validation loss: 2.092440684636434

Epoch: 6| Step: 13
Training loss: 0.6627853512763977
Validation loss: 2.0879973570505777

Epoch: 123| Step: 0
Training loss: 1.445584774017334
Validation loss: 2.072742154200872

Epoch: 6| Step: 1
Training loss: 1.1625159978866577
Validation loss: 2.0805256962776184

Epoch: 6| Step: 2
Training loss: 0.922501802444458
Validation loss: 2.0859500567118325

Epoch: 6| Step: 3
Training loss: 1.3479628562927246
Validation loss: 2.1258800625801086

Epoch: 6| Step: 4
Training loss: 1.24830961227417
Validation loss: 2.092900017897288

Epoch: 6| Step: 5
Training loss: 1.1601548194885254
Validation loss: 2.0870718955993652

Epoch: 6| Step: 6
Training loss: 1.2847867012023926
Validation loss: 2.0949264566103616

Epoch: 6| Step: 7
Training loss: 1.2699711322784424
Validation loss: 2.076927065849304

Epoch: 6| Step: 8
Training loss: 0.8397625088691711
Validation loss: 2.0984898805618286

Epoch: 6| Step: 9
Training loss: 1.483251690864563
Validation loss: 2.0566009084383645

Epoch: 6| Step: 10
Training loss: 1.1479225158691406
Validation loss: 2.105473359425863

Epoch: 6| Step: 11
Training loss: 0.794124186038971
Validation loss: 2.0438857674598694

Epoch: 6| Step: 12
Training loss: 1.361689567565918
Validation loss: 2.060605605443319

Epoch: 6| Step: 13
Training loss: 1.1115065813064575
Validation loss: 2.094588836034139

Epoch: 124| Step: 0
Training loss: 1.0901484489440918
Validation loss: 2.0881636142730713

Epoch: 6| Step: 1
Training loss: 1.019446611404419
Validation loss: 2.1184306939442954

Epoch: 6| Step: 2
Training loss: 1.3413033485412598
Validation loss: 2.0826580921808877

Epoch: 6| Step: 3
Training loss: 1.1694284677505493
Validation loss: 2.0619479020436606

Epoch: 6| Step: 4
Training loss: 1.1411964893341064
Validation loss: 2.075910051663717

Epoch: 6| Step: 5
Training loss: 0.9461193084716797
Validation loss: 2.046684285004934

Epoch: 6| Step: 6
Training loss: 1.238948106765747
Validation loss: 2.034266491731008

Epoch: 6| Step: 7
Training loss: 1.4103398323059082
Validation loss: 2.066706379254659

Epoch: 6| Step: 8
Training loss: 1.12892746925354
Validation loss: 2.105756163597107

Epoch: 6| Step: 9
Training loss: 1.1664775609970093
Validation loss: 2.094807744026184

Epoch: 6| Step: 10
Training loss: 1.5397605895996094
Validation loss: 2.0784150759379068

Epoch: 6| Step: 11
Training loss: 1.4101557731628418
Validation loss: 2.144552926222483

Epoch: 6| Step: 12
Training loss: 1.4921526908874512
Validation loss: 2.1612714727719626

Epoch: 6| Step: 13
Training loss: 0.8760927319526672
Validation loss: 2.09945676724116

Epoch: 125| Step: 0
Training loss: 1.107935905456543
Validation loss: 2.091089963912964

Epoch: 6| Step: 1
Training loss: 1.022910714149475
Validation loss: 2.0693687995274863

Epoch: 6| Step: 2
Training loss: 0.9397779703140259
Validation loss: 2.042494277159373

Epoch: 6| Step: 3
Training loss: 0.9315638542175293
Validation loss: 2.0611886978149414

Epoch: 6| Step: 4
Training loss: 0.7194470167160034
Validation loss: 2.0464801589647927

Epoch: 6| Step: 5
Training loss: 1.0616343021392822
Validation loss: 2.012212951978048

Epoch: 6| Step: 6
Training loss: 1.6005103588104248
Validation loss: 2.092232326666514

Epoch: 6| Step: 7
Training loss: 0.9374097585678101
Validation loss: 2.0543525218963623

Epoch: 6| Step: 8
Training loss: 1.2716004848480225
Validation loss: 2.084980030854543

Epoch: 6| Step: 9
Training loss: 0.8486539125442505
Validation loss: 2.099941154321035

Epoch: 6| Step: 10
Training loss: 1.5097296237945557
Validation loss: 2.099452873071035

Epoch: 6| Step: 11
Training loss: 1.793961763381958
Validation loss: 2.094562908013662

Epoch: 6| Step: 12
Training loss: 0.9190784692764282
Validation loss: 2.1202988624572754

Epoch: 6| Step: 13
Training loss: 1.7932584285736084
Validation loss: 2.1037173867225647

Testing loss: 1.89391106152706
