Epoch: 1| Step: 0
Training loss: 7.037274360656738
Validation loss: 5.966255724430084

Epoch: 5| Step: 1
Training loss: 5.123032093048096
Validation loss: 5.95543376604716

Epoch: 5| Step: 2
Training loss: 6.074491024017334
Validation loss: 5.939489424228668

Epoch: 5| Step: 3
Training loss: 6.231829643249512
Validation loss: 5.929908196131389

Epoch: 5| Step: 4
Training loss: 6.414056301116943
Validation loss: 5.917371014753978

Epoch: 5| Step: 5
Training loss: 6.2748236656188965
Validation loss: 5.90138594309489

Epoch: 5| Step: 6
Training loss: 6.325078010559082
Validation loss: 5.890183448791504

Epoch: 5| Step: 7
Training loss: 5.536706924438477
Validation loss: 5.875044723351796

Epoch: 5| Step: 8
Training loss: 5.52236270904541
Validation loss: 5.8601770003636675

Epoch: 5| Step: 9
Training loss: 4.983856678009033
Validation loss: 5.840750495592753

Epoch: 5| Step: 10
Training loss: 6.069403648376465
Validation loss: 5.825908402601878

Epoch: 5| Step: 11
Training loss: 6.18950891494751
Validation loss: 5.811645766099294

Epoch: 2| Step: 0
Training loss: 5.96337890625
Validation loss: 5.791612803936005

Epoch: 5| Step: 1
Training loss: 5.666536331176758
Validation loss: 5.773951232433319

Epoch: 5| Step: 2
Training loss: 6.203980922698975
Validation loss: 5.756208697954814

Epoch: 5| Step: 3
Training loss: 5.550933837890625
Validation loss: 5.735629022121429

Epoch: 5| Step: 4
Training loss: 5.373277187347412
Validation loss: 5.716511766115825

Epoch: 5| Step: 5
Training loss: 5.740996837615967
Validation loss: 5.6938667098681135

Epoch: 5| Step: 6
Training loss: 6.507937431335449
Validation loss: 5.672427654266357

Epoch: 5| Step: 7
Training loss: 6.041492938995361
Validation loss: 5.652648289998372

Epoch: 5| Step: 8
Training loss: 5.055665016174316
Validation loss: 5.625239372253418

Epoch: 5| Step: 9
Training loss: 5.543143272399902
Validation loss: 5.603580077489217

Epoch: 5| Step: 10
Training loss: 5.8345627784729
Validation loss: 5.575464427471161

Epoch: 5| Step: 11
Training loss: 4.5293049812316895
Validation loss: 5.547727127869924

Epoch: 3| Step: 0
Training loss: 5.473498344421387
Validation loss: 5.515549858411153

Epoch: 5| Step: 1
Training loss: 5.212732791900635
Validation loss: 5.489264448483785

Epoch: 5| Step: 2
Training loss: 5.141589164733887
Validation loss: 5.4582293232282

Epoch: 5| Step: 3
Training loss: 5.739083766937256
Validation loss: 5.425530731678009

Epoch: 5| Step: 4
Training loss: 5.687647342681885
Validation loss: 5.3882938623428345

Epoch: 5| Step: 5
Training loss: 5.171311855316162
Validation loss: 5.3541280428568525

Epoch: 5| Step: 6
Training loss: 5.303868770599365
Validation loss: 5.309889217217763

Epoch: 5| Step: 7
Training loss: 5.931487083435059
Validation loss: 5.2705637613932295

Epoch: 5| Step: 8
Training loss: 5.757988929748535
Validation loss: 5.230459590752919

Epoch: 5| Step: 9
Training loss: 4.279702663421631
Validation loss: 5.183162788550059

Epoch: 5| Step: 10
Training loss: 6.1532135009765625
Validation loss: 5.137663125991821

Epoch: 5| Step: 11
Training loss: 2.809641122817993
Validation loss: 5.091665029525757

Epoch: 4| Step: 0
Training loss: 4.946307182312012
Validation loss: 5.037954151630402

Epoch: 5| Step: 1
Training loss: 4.1736040115356445
Validation loss: 4.984100580215454

Epoch: 5| Step: 2
Training loss: 5.280455112457275
Validation loss: 4.928854256868362

Epoch: 5| Step: 3
Training loss: 4.388018608093262
Validation loss: 4.87519234418869

Epoch: 5| Step: 4
Training loss: 4.51481294631958
Validation loss: 4.818478465080261

Epoch: 5| Step: 5
Training loss: 4.734968662261963
Validation loss: 4.759467403093974

Epoch: 5| Step: 6
Training loss: 5.198461055755615
Validation loss: 4.69020543495814

Epoch: 5| Step: 7
Training loss: 5.949207782745361
Validation loss: 4.609653611977895

Epoch: 5| Step: 8
Training loss: 5.504342079162598
Validation loss: 4.5482279260953264

Epoch: 5| Step: 9
Training loss: 4.0971574783325195
Validation loss: 4.466825723648071

Epoch: 5| Step: 10
Training loss: 3.750192165374756
Validation loss: 4.375836839278539

Epoch: 5| Step: 11
Training loss: 5.241191387176514
Validation loss: 4.30804826815923

Epoch: 5| Step: 0
Training loss: 3.4980902671813965
Validation loss: 4.22847393155098

Epoch: 5| Step: 1
Training loss: 4.018805503845215
Validation loss: 4.133357604344686

Epoch: 5| Step: 2
Training loss: 4.548235893249512
Validation loss: 4.045672605435054

Epoch: 5| Step: 3
Training loss: 4.460680961608887
Validation loss: 3.9836300710837045

Epoch: 5| Step: 4
Training loss: 3.6303913593292236
Validation loss: 3.887092173099518

Epoch: 5| Step: 5
Training loss: 3.2447311878204346
Validation loss: 3.8050067126750946

Epoch: 5| Step: 6
Training loss: 4.105102062225342
Validation loss: 3.7202212810516357

Epoch: 5| Step: 7
Training loss: 3.7977547645568848
Validation loss: 3.613177925348282

Epoch: 5| Step: 8
Training loss: 3.0272011756896973
Validation loss: 3.5267194906870523

Epoch: 5| Step: 9
Training loss: 3.6868839263916016
Validation loss: 3.4432727098464966

Epoch: 5| Step: 10
Training loss: 4.527100563049316
Validation loss: 3.3330380618572235

Epoch: 5| Step: 11
Training loss: 2.6910858154296875
Validation loss: 3.2466189364592233

Epoch: 6| Step: 0
Training loss: 3.8742306232452393
Validation loss: 3.1471333106358848

Epoch: 5| Step: 1
Training loss: 3.116611957550049
Validation loss: 3.0595255692799888

Epoch: 5| Step: 2
Training loss: 2.4892640113830566
Validation loss: 2.9640685617923737

Epoch: 5| Step: 3
Training loss: 2.842236042022705
Validation loss: 2.8978375494480133

Epoch: 5| Step: 4
Training loss: 3.08258056640625
Validation loss: 2.8187767366568246

Epoch: 5| Step: 5
Training loss: 2.6763854026794434
Validation loss: 2.7288818260033927

Epoch: 5| Step: 6
Training loss: 2.722729444503784
Validation loss: 2.6766440073649087

Epoch: 5| Step: 7
Training loss: 2.156047821044922
Validation loss: 2.560662825902303

Epoch: 5| Step: 8
Training loss: 2.8213703632354736
Validation loss: 2.4874252875645957

Epoch: 5| Step: 9
Training loss: 1.9450395107269287
Validation loss: 2.475273996591568

Epoch: 5| Step: 10
Training loss: 2.16131329536438
Validation loss: 2.4085623572270074

Epoch: 5| Step: 11
Training loss: 1.8019187450408936
Validation loss: 2.3415699899196625

Epoch: 7| Step: 0
Training loss: 1.9932851791381836
Validation loss: 2.3319026629130044

Epoch: 5| Step: 1
Training loss: 2.6836535930633545
Validation loss: 2.3316364188989005

Epoch: 5| Step: 2
Training loss: 2.4815268516540527
Validation loss: 2.338381345073382

Epoch: 5| Step: 3
Training loss: 2.824827194213867
Validation loss: 2.3799368838469186

Epoch: 5| Step: 4
Training loss: 2.135978937149048
Validation loss: 2.3522959649562836

Epoch: 5| Step: 5
Training loss: 2.4880166053771973
Validation loss: 2.362142433722814

Epoch: 5| Step: 6
Training loss: 2.28680157661438
Validation loss: 2.3969191014766693

Epoch: 5| Step: 7
Training loss: 1.91300368309021
Validation loss: 2.4180748611688614

Epoch: 5| Step: 8
Training loss: 1.717702865600586
Validation loss: 2.421772147218386

Epoch: 5| Step: 9
Training loss: 2.4370477199554443
Validation loss: 2.395539959271749

Epoch: 5| Step: 10
Training loss: 2.2632322311401367
Validation loss: 2.4145605713129044

Epoch: 5| Step: 11
Training loss: 3.1822991371154785
Validation loss: 2.3996567328770957

Epoch: 8| Step: 0
Training loss: 2.7535560131073
Validation loss: 2.3208295156558356

Epoch: 5| Step: 1
Training loss: 2.286876916885376
Validation loss: 2.3505358397960663

Epoch: 5| Step: 2
Training loss: 1.7058961391448975
Validation loss: 2.319552650054296

Epoch: 5| Step: 3
Training loss: 2.1308202743530273
Validation loss: 2.2925114780664444

Epoch: 5| Step: 4
Training loss: 2.088956832885742
Validation loss: 2.3118715484937034

Epoch: 5| Step: 5
Training loss: 1.9822943210601807
Validation loss: 2.299944500128428

Epoch: 5| Step: 6
Training loss: 2.747612476348877
Validation loss: 2.3369916627804437

Epoch: 5| Step: 7
Training loss: 2.1477913856506348
Validation loss: 2.338675836722056

Epoch: 5| Step: 8
Training loss: 2.2989609241485596
Validation loss: 2.2939666310946145

Epoch: 5| Step: 9
Training loss: 2.0972962379455566
Validation loss: 2.3227017720540366

Epoch: 5| Step: 10
Training loss: 2.142580509185791
Validation loss: 2.2514277398586273

Epoch: 5| Step: 11
Training loss: 2.9746618270874023
Validation loss: 2.3134935100873313

Epoch: 9| Step: 0
Training loss: 2.3323256969451904
Validation loss: 2.3243298530578613

Epoch: 5| Step: 1
Training loss: 1.8553926944732666
Validation loss: 2.28521791100502

Epoch: 5| Step: 2
Training loss: 2.1188576221466064
Validation loss: 2.2812817096710205

Epoch: 5| Step: 3
Training loss: 2.7257542610168457
Validation loss: 2.2844907641410828

Epoch: 5| Step: 4
Training loss: 2.617793321609497
Validation loss: 2.289459149042765

Epoch: 5| Step: 5
Training loss: 2.2753541469573975
Validation loss: 2.2971240182717643

Epoch: 5| Step: 6
Training loss: 2.053126335144043
Validation loss: 2.298429479201635

Epoch: 5| Step: 7
Training loss: 2.7058234214782715
Validation loss: 2.2937896947065988

Epoch: 5| Step: 8
Training loss: 2.55363392829895
Validation loss: 2.266531750559807

Epoch: 5| Step: 9
Training loss: 2.417220115661621
Validation loss: 2.27616548538208

Epoch: 5| Step: 10
Training loss: 1.2153338193893433
Validation loss: 2.266081546743711

Epoch: 5| Step: 11
Training loss: 1.3031188249588013
Validation loss: 2.290435234705607

Epoch: 10| Step: 0
Training loss: 2.240281581878662
Validation loss: 2.2741378992795944

Epoch: 5| Step: 1
Training loss: 2.09378719329834
Validation loss: 2.2708919048309326

Epoch: 5| Step: 2
Training loss: 1.80081307888031
Validation loss: 2.3010521481434503

Epoch: 5| Step: 3
Training loss: 2.168628215789795
Validation loss: 2.2772864202658334

Epoch: 5| Step: 4
Training loss: 2.1293201446533203
Validation loss: 2.2762118875980377

Epoch: 5| Step: 5
Training loss: 2.431525707244873
Validation loss: 2.277272899945577

Epoch: 5| Step: 6
Training loss: 2.038890838623047
Validation loss: 2.266470824678739

Epoch: 5| Step: 7
Training loss: 2.1007091999053955
Validation loss: 2.2994520465532937

Epoch: 5| Step: 8
Training loss: 2.2313780784606934
Validation loss: 2.289553791284561

Epoch: 5| Step: 9
Training loss: 2.963181734085083
Validation loss: 2.2939358949661255

Epoch: 5| Step: 10
Training loss: 2.1053786277770996
Validation loss: 2.25759327908357

Epoch: 5| Step: 11
Training loss: 2.4023399353027344
Validation loss: 2.247174382209778

Epoch: 11| Step: 0
Training loss: 2.5910778045654297
Validation loss: 2.270794227719307

Epoch: 5| Step: 1
Training loss: 2.5891942977905273
Validation loss: 2.2607750644286475

Epoch: 5| Step: 2
Training loss: 1.8741397857666016
Validation loss: 2.2916035254796348

Epoch: 5| Step: 3
Training loss: 2.0430850982666016
Validation loss: 2.2624154587586722

Epoch: 5| Step: 4
Training loss: 2.635561227798462
Validation loss: 2.294229875008265

Epoch: 5| Step: 5
Training loss: 2.3674514293670654
Validation loss: 2.2669035295645394

Epoch: 5| Step: 6
Training loss: 2.095956325531006
Validation loss: 2.2818596760431924

Epoch: 5| Step: 7
Training loss: 1.674613356590271
Validation loss: 2.2524888068437576

Epoch: 5| Step: 8
Training loss: 2.0643322467803955
Validation loss: 2.2322845458984375

Epoch: 5| Step: 9
Training loss: 2.2942066192626953
Validation loss: 2.218233128388723

Epoch: 5| Step: 10
Training loss: 1.925154447555542
Validation loss: 2.279872789978981

Epoch: 5| Step: 11
Training loss: 2.158696413040161
Validation loss: 2.2134018937746682

Epoch: 12| Step: 0
Training loss: 2.3153014183044434
Validation loss: 2.2793029894431434

Epoch: 5| Step: 1
Training loss: 2.3829803466796875
Validation loss: 2.26092267036438

Epoch: 5| Step: 2
Training loss: 2.2521183490753174
Validation loss: 2.230538954337438

Epoch: 5| Step: 3
Training loss: 1.942627191543579
Validation loss: 2.2418810526529946

Epoch: 5| Step: 4
Training loss: 2.236088991165161
Validation loss: 2.2830579529205957

Epoch: 5| Step: 5
Training loss: 2.148817539215088
Validation loss: 2.266727695862452

Epoch: 5| Step: 6
Training loss: 1.9718024730682373
Validation loss: 2.2334980914990106

Epoch: 5| Step: 7
Training loss: 2.088536024093628
Validation loss: 2.2487556586662927

Epoch: 5| Step: 8
Training loss: 2.424736499786377
Validation loss: 2.2252355019251504

Epoch: 5| Step: 9
Training loss: 2.0210821628570557
Validation loss: 2.204547976454099

Epoch: 5| Step: 10
Training loss: 2.0906193256378174
Validation loss: 2.2402151226997375

Epoch: 5| Step: 11
Training loss: 2.0942091941833496
Validation loss: 2.2684484074513116

Epoch: 13| Step: 0
Training loss: 1.900618314743042
Validation loss: 2.241324558854103

Epoch: 5| Step: 1
Training loss: 2.6056838035583496
Validation loss: 2.239025339484215

Epoch: 5| Step: 2
Training loss: 1.736881971359253
Validation loss: 2.2590340425570807

Epoch: 5| Step: 3
Training loss: 2.416604995727539
Validation loss: 2.216950371861458

Epoch: 5| Step: 4
Training loss: 2.135545253753662
Validation loss: 2.223228226105372

Epoch: 5| Step: 5
Training loss: 1.8999855518341064
Validation loss: 2.24564998348554

Epoch: 5| Step: 6
Training loss: 2.236060619354248
Validation loss: 2.2081147829691568

Epoch: 5| Step: 7
Training loss: 2.386276960372925
Validation loss: 2.2543654094139733

Epoch: 5| Step: 8
Training loss: 2.408263683319092
Validation loss: 2.253325199087461

Epoch: 5| Step: 9
Training loss: 2.1192100048065186
Validation loss: 2.2567468037207923

Epoch: 5| Step: 10
Training loss: 1.850665807723999
Validation loss: 2.244221414128939

Epoch: 5| Step: 11
Training loss: 2.6509289741516113
Validation loss: 2.255462944507599

Epoch: 14| Step: 0
Training loss: 2.659872531890869
Validation loss: 2.1746804316838584

Epoch: 5| Step: 1
Training loss: 1.790419340133667
Validation loss: 2.242093965411186

Epoch: 5| Step: 2
Training loss: 2.0776963233947754
Validation loss: 2.2650115936994553

Epoch: 5| Step: 3
Training loss: 2.099533796310425
Validation loss: 2.192736725012461

Epoch: 5| Step: 4
Training loss: 2.4384536743164062
Validation loss: 2.2273842493693032

Epoch: 5| Step: 5
Training loss: 1.7706120014190674
Validation loss: 2.2064131448666253

Epoch: 5| Step: 6
Training loss: 2.2948460578918457
Validation loss: 2.221439798672994

Epoch: 5| Step: 7
Training loss: 2.2715892791748047
Validation loss: 2.243919978539149

Epoch: 5| Step: 8
Training loss: 2.0611562728881836
Validation loss: 2.209397186835607

Epoch: 5| Step: 9
Training loss: 1.9970118999481201
Validation loss: 2.1895784636338553

Epoch: 5| Step: 10
Training loss: 1.9658466577529907
Validation loss: 2.233360434571902

Epoch: 5| Step: 11
Training loss: 2.0681967735290527
Validation loss: 2.1958835422992706

Epoch: 15| Step: 0
Training loss: 2.4368185997009277
Validation loss: 2.1795194347699485

Epoch: 5| Step: 1
Training loss: 2.1695663928985596
Validation loss: 2.2424959739049277

Epoch: 5| Step: 2
Training loss: 2.1677029132843018
Validation loss: 2.2283114989598594

Epoch: 5| Step: 3
Training loss: 2.2673051357269287
Validation loss: 2.2186153680086136

Epoch: 5| Step: 4
Training loss: 2.1372742652893066
Validation loss: 2.2414362132549286

Epoch: 5| Step: 5
Training loss: 1.598118543624878
Validation loss: 2.264323110381762

Epoch: 5| Step: 6
Training loss: 3.091855049133301
Validation loss: 2.2245624711116156

Epoch: 5| Step: 7
Training loss: 2.3521580696105957
Validation loss: 2.2328175455331802

Epoch: 5| Step: 8
Training loss: 1.948624610900879
Validation loss: 2.1883647243181863

Epoch: 5| Step: 9
Training loss: 1.7373857498168945
Validation loss: 2.1920081973075867

Epoch: 5| Step: 10
Training loss: 1.8116989135742188
Validation loss: 2.18217063943545

Epoch: 5| Step: 11
Training loss: 2.562591314315796
Validation loss: 2.184820910294851

Epoch: 16| Step: 0
Training loss: 2.5560061931610107
Validation loss: 2.2043867061535516

Epoch: 5| Step: 1
Training loss: 2.4162309169769287
Validation loss: 2.197201430797577

Epoch: 5| Step: 2
Training loss: 2.005370616912842
Validation loss: 2.2170346081256866

Epoch: 5| Step: 3
Training loss: 2.050837278366089
Validation loss: 2.2076620062192283

Epoch: 5| Step: 4
Training loss: 2.365586042404175
Validation loss: 2.209018195668856

Epoch: 5| Step: 5
Training loss: 2.4716382026672363
Validation loss: 2.202857027451197

Epoch: 5| Step: 6
Training loss: 2.1538009643554688
Validation loss: 2.207229276498159

Epoch: 5| Step: 7
Training loss: 2.078481435775757
Validation loss: 2.2298732300599418

Epoch: 5| Step: 8
Training loss: 1.8449327945709229
Validation loss: 2.2611359457174935

Epoch: 5| Step: 9
Training loss: 1.826686143875122
Validation loss: 2.211087246735891

Epoch: 5| Step: 10
Training loss: 2.044420003890991
Validation loss: 2.217113802830378

Epoch: 5| Step: 11
Training loss: 2.1195077896118164
Validation loss: 2.2213655511538186

Epoch: 17| Step: 0
Training loss: 1.814518928527832
Validation loss: 2.2047390192747116

Epoch: 5| Step: 1
Training loss: 1.8684145212173462
Validation loss: 2.210315187772115

Epoch: 5| Step: 2
Training loss: 1.8705393075942993
Validation loss: 2.1567681431770325

Epoch: 5| Step: 3
Training loss: 3.241352081298828
Validation loss: 2.164553145567576

Epoch: 5| Step: 4
Training loss: 2.0245683193206787
Validation loss: 2.2007378141085305

Epoch: 5| Step: 5
Training loss: 1.7079432010650635
Validation loss: 2.15519509712855

Epoch: 5| Step: 6
Training loss: 1.5671306848526
Validation loss: 2.1668893645207086

Epoch: 5| Step: 7
Training loss: 2.6614203453063965
Validation loss: 2.20474182566007

Epoch: 5| Step: 8
Training loss: 2.2204861640930176
Validation loss: 2.1625530272722244

Epoch: 5| Step: 9
Training loss: 2.4068195819854736
Validation loss: 2.166345397631327

Epoch: 5| Step: 10
Training loss: 1.782874345779419
Validation loss: 2.168714096148809

Epoch: 5| Step: 11
Training loss: 3.1609110832214355
Validation loss: 2.2231156677007675

Epoch: 18| Step: 0
Training loss: 2.372373580932617
Validation loss: 2.1592177748680115

Epoch: 5| Step: 1
Training loss: 2.289750337600708
Validation loss: 2.1691916485627494

Epoch: 5| Step: 2
Training loss: 1.678951621055603
Validation loss: 2.2100056558847427

Epoch: 5| Step: 3
Training loss: 2.010366678237915
Validation loss: 2.1845800479253135

Epoch: 5| Step: 4
Training loss: 1.4954779148101807
Validation loss: 2.1759719202915826

Epoch: 5| Step: 5
Training loss: 1.6744235754013062
Validation loss: 2.143084009488424

Epoch: 5| Step: 6
Training loss: 2.411238431930542
Validation loss: 2.1986977954705558

Epoch: 5| Step: 7
Training loss: 2.6244912147521973
Validation loss: 2.148478170235952

Epoch: 5| Step: 8
Training loss: 2.019824504852295
Validation loss: 2.159283851583799

Epoch: 5| Step: 9
Training loss: 2.281672954559326
Validation loss: 2.166015088558197

Epoch: 5| Step: 10
Training loss: 2.2408194541931152
Validation loss: 2.177122419079145

Epoch: 5| Step: 11
Training loss: 3.4808201789855957
Validation loss: 2.206265320380529

Epoch: 19| Step: 0
Training loss: 2.0367588996887207
Validation loss: 2.170818308989207

Epoch: 5| Step: 1
Training loss: 2.2690229415893555
Validation loss: 2.1828794280687966

Epoch: 5| Step: 2
Training loss: 2.1148388385772705
Validation loss: 2.1787786980470023

Epoch: 5| Step: 3
Training loss: 2.394326686859131
Validation loss: 2.165712441007296

Epoch: 5| Step: 4
Training loss: 2.1090550422668457
Validation loss: 2.1498425602912903

Epoch: 5| Step: 5
Training loss: 1.8589038848876953
Validation loss: 2.1615001360575357

Epoch: 5| Step: 6
Training loss: 1.9101343154907227
Validation loss: 2.1499043156703315

Epoch: 5| Step: 7
Training loss: 2.5107057094573975
Validation loss: 2.163701668381691

Epoch: 5| Step: 8
Training loss: 2.160297393798828
Validation loss: 2.1315409541130066

Epoch: 5| Step: 9
Training loss: 1.898392915725708
Validation loss: 2.1712580621242523

Epoch: 5| Step: 10
Training loss: 1.8649580478668213
Validation loss: 2.1744986474514008

Epoch: 5| Step: 11
Training loss: 2.542619466781616
Validation loss: 2.153705194592476

Epoch: 20| Step: 0
Training loss: 1.9659221172332764
Validation loss: 2.139533484975497

Epoch: 5| Step: 1
Training loss: 1.6974546909332275
Validation loss: 2.1258578648169837

Epoch: 5| Step: 2
Training loss: 2.594608783721924
Validation loss: 2.1334860026836395

Epoch: 5| Step: 3
Training loss: 1.928887963294983
Validation loss: 2.169682780901591

Epoch: 5| Step: 4
Training loss: 2.263378620147705
Validation loss: 2.134857103228569

Epoch: 5| Step: 5
Training loss: 2.298112392425537
Validation loss: 2.143242726723353

Epoch: 5| Step: 6
Training loss: 2.4427852630615234
Validation loss: 2.1766746441523233

Epoch: 5| Step: 7
Training loss: 2.406981945037842
Validation loss: 2.154274751742681

Epoch: 5| Step: 8
Training loss: 2.2685112953186035
Validation loss: 2.154670869310697

Epoch: 5| Step: 9
Training loss: 1.9575841426849365
Validation loss: 2.1593067149321237

Epoch: 5| Step: 10
Training loss: 1.6825683116912842
Validation loss: 2.179243187109629

Epoch: 5| Step: 11
Training loss: 0.690377950668335
Validation loss: 2.1597424993912377

Epoch: 21| Step: 0
Training loss: 1.7187020778656006
Validation loss: 2.1580232977867126

Epoch: 5| Step: 1
Training loss: 1.9615309238433838
Validation loss: 2.1229562759399414

Epoch: 5| Step: 2
Training loss: 2.027489423751831
Validation loss: 2.1323914428551993

Epoch: 5| Step: 3
Training loss: 2.328566074371338
Validation loss: 2.1537953515847525

Epoch: 5| Step: 4
Training loss: 1.9980802536010742
Validation loss: 2.144796455899874

Epoch: 5| Step: 5
Training loss: 1.9984960556030273
Validation loss: 2.179393713672956

Epoch: 5| Step: 6
Training loss: 2.4322586059570312
Validation loss: 2.163592129945755

Epoch: 5| Step: 7
Training loss: 2.0769894123077393
Validation loss: 2.1663659463326135

Epoch: 5| Step: 8
Training loss: 1.8463256359100342
Validation loss: 2.150924727320671

Epoch: 5| Step: 9
Training loss: 2.859829902648926
Validation loss: 2.1556095282236734

Epoch: 5| Step: 10
Training loss: 1.6110254526138306
Validation loss: 2.1514947017033896

Epoch: 5| Step: 11
Training loss: 3.1164112091064453
Validation loss: 2.1722979843616486

Epoch: 22| Step: 0
Training loss: 2.3202643394470215
Validation loss: 2.161812807122866

Epoch: 5| Step: 1
Training loss: 2.697478771209717
Validation loss: 2.15626589457194

Epoch: 5| Step: 2
Training loss: 1.9496266841888428
Validation loss: 2.1481240540742874

Epoch: 5| Step: 3
Training loss: 1.8177051544189453
Validation loss: 2.185658519466718

Epoch: 5| Step: 4
Training loss: 1.3936268091201782
Validation loss: 2.179033642013868

Epoch: 5| Step: 5
Training loss: 2.031345844268799
Validation loss: 2.138266627987226

Epoch: 5| Step: 6
Training loss: 1.5467143058776855
Validation loss: 2.161086837450663

Epoch: 5| Step: 7
Training loss: 2.9627628326416016
Validation loss: 2.1582220792770386

Epoch: 5| Step: 8
Training loss: 2.2736244201660156
Validation loss: 2.1708499640226364

Epoch: 5| Step: 9
Training loss: 2.0915579795837402
Validation loss: 2.1945035060246787

Epoch: 5| Step: 10
Training loss: 2.212686538696289
Validation loss: 2.1627722531557083

Epoch: 5| Step: 11
Training loss: 1.4657747745513916
Validation loss: 2.129133621851603

Epoch: 23| Step: 0
Training loss: 1.8635380268096924
Validation loss: 2.1628541350364685

Epoch: 5| Step: 1
Training loss: 2.077756881713867
Validation loss: 2.1642866333325705

Epoch: 5| Step: 2
Training loss: 1.8899335861206055
Validation loss: 2.137169122695923

Epoch: 5| Step: 3
Training loss: 1.5986725091934204
Validation loss: 2.15629435578982

Epoch: 5| Step: 4
Training loss: 1.8282639980316162
Validation loss: 2.1293842097123465

Epoch: 5| Step: 5
Training loss: 1.5250113010406494
Validation loss: 2.1063484052817025

Epoch: 5| Step: 6
Training loss: 2.0395216941833496
Validation loss: 2.1577413280804953

Epoch: 5| Step: 7
Training loss: 2.827284336090088
Validation loss: 2.1438271701335907

Epoch: 5| Step: 8
Training loss: 2.6195878982543945
Validation loss: 2.12888673444589

Epoch: 5| Step: 9
Training loss: 2.20284366607666
Validation loss: 2.1298148334026337

Epoch: 5| Step: 10
Training loss: 2.242579936981201
Validation loss: 2.1186208526293435

Epoch: 5| Step: 11
Training loss: 1.7028696537017822
Validation loss: 2.141954263051351

Epoch: 24| Step: 0
Training loss: 2.506765604019165
Validation loss: 2.1275752981503806

Epoch: 5| Step: 1
Training loss: 1.7444751262664795
Validation loss: 2.121242811282476

Epoch: 5| Step: 2
Training loss: 1.8780338764190674
Validation loss: 2.167146389683088

Epoch: 5| Step: 3
Training loss: 1.8161598443984985
Validation loss: 2.132739380002022

Epoch: 5| Step: 4
Training loss: 1.8360570669174194
Validation loss: 2.1210813323656716

Epoch: 5| Step: 5
Training loss: 1.946616768836975
Validation loss: 2.1402770976225534

Epoch: 5| Step: 6
Training loss: 2.728501796722412
Validation loss: 2.142195632060369

Epoch: 5| Step: 7
Training loss: 2.9533543586730957
Validation loss: 2.1143200546503067

Epoch: 5| Step: 8
Training loss: 1.9549916982650757
Validation loss: 2.158252716064453

Epoch: 5| Step: 9
Training loss: 1.4770915508270264
Validation loss: 2.12311053276062

Epoch: 5| Step: 10
Training loss: 1.9359443187713623
Validation loss: 2.126437629262606

Epoch: 5| Step: 11
Training loss: 2.555708169937134
Validation loss: 2.1491306126117706

Epoch: 25| Step: 0
Training loss: 2.165787696838379
Validation loss: 2.1398604015509286

Epoch: 5| Step: 1
Training loss: 1.572121024131775
Validation loss: 2.135242685675621

Epoch: 5| Step: 2
Training loss: 2.2060153484344482
Validation loss: 2.1430055300394693

Epoch: 5| Step: 3
Training loss: 2.4037375450134277
Validation loss: 2.1421435872713723

Epoch: 5| Step: 4
Training loss: 2.4459822177886963
Validation loss: 2.156996116042137

Epoch: 5| Step: 5
Training loss: 1.924384355545044
Validation loss: 2.183258901039759

Epoch: 5| Step: 6
Training loss: 2.307060480117798
Validation loss: 2.139154980580012

Epoch: 5| Step: 7
Training loss: 1.9295189380645752
Validation loss: 2.177323122819265

Epoch: 5| Step: 8
Training loss: 1.9252647161483765
Validation loss: 2.164227694272995

Epoch: 5| Step: 9
Training loss: 2.20701265335083
Validation loss: 2.1575430631637573

Epoch: 5| Step: 10
Training loss: 1.91178297996521
Validation loss: 2.12198144197464

Epoch: 5| Step: 11
Training loss: 0.8939265012741089
Validation loss: 2.1570686598618827

Epoch: 26| Step: 0
Training loss: 1.900234580039978
Validation loss: 2.1654850443204245

Epoch: 5| Step: 1
Training loss: 1.6751079559326172
Validation loss: 2.1210518926382065

Epoch: 5| Step: 2
Training loss: 2.496066093444824
Validation loss: 2.128182644645373

Epoch: 5| Step: 3
Training loss: 2.140448808670044
Validation loss: 2.1215943843126297

Epoch: 5| Step: 4
Training loss: 1.976025938987732
Validation loss: 2.164399817585945

Epoch: 5| Step: 5
Training loss: 1.3458240032196045
Validation loss: 2.103757366538048

Epoch: 5| Step: 6
Training loss: 2.03932785987854
Validation loss: 2.1169133484363556

Epoch: 5| Step: 7
Training loss: 1.99325692653656
Validation loss: 2.1456654320160546

Epoch: 5| Step: 8
Training loss: 2.583803415298462
Validation loss: 2.1065268367528915

Epoch: 5| Step: 9
Training loss: 1.8489586114883423
Validation loss: 2.134557103117307

Epoch: 5| Step: 10
Training loss: 2.0092580318450928
Validation loss: 2.1596504549185433

Epoch: 5| Step: 11
Training loss: 3.813267230987549
Validation loss: 2.1387193550666175

Epoch: 27| Step: 0
Training loss: 2.3946280479431152
Validation loss: 2.1485805412133536

Epoch: 5| Step: 1
Training loss: 1.8098323345184326
Validation loss: 2.146055435140928

Epoch: 5| Step: 2
Training loss: 1.7389566898345947
Validation loss: 2.1773939579725266

Epoch: 5| Step: 3
Training loss: 1.9784921407699585
Validation loss: 2.1291782756646476

Epoch: 5| Step: 4
Training loss: 2.0801804065704346
Validation loss: 2.1669636915127435

Epoch: 5| Step: 5
Training loss: 2.3394031524658203
Validation loss: 2.172725280125936

Epoch: 5| Step: 6
Training loss: 1.9156990051269531
Validation loss: 2.1694440146287284

Epoch: 5| Step: 7
Training loss: 2.5679078102111816
Validation loss: 2.1798749764760337

Epoch: 5| Step: 8
Training loss: 2.882838726043701
Validation loss: 2.1585720231135688

Epoch: 5| Step: 9
Training loss: 2.106856107711792
Validation loss: 2.1014134337504706

Epoch: 5| Step: 10
Training loss: 1.122277855873108
Validation loss: 2.1190421680609384

Epoch: 5| Step: 11
Training loss: 1.1014994382858276
Validation loss: 2.120412285129229

Epoch: 28| Step: 0
Training loss: 2.403873920440674
Validation loss: 2.142209604382515

Epoch: 5| Step: 1
Training loss: 2.3464949131011963
Validation loss: 2.151335577170054

Epoch: 5| Step: 2
Training loss: 1.8806235790252686
Validation loss: 2.117291991909345

Epoch: 5| Step: 3
Training loss: 1.6665652990341187
Validation loss: 2.1313744386037192

Epoch: 5| Step: 4
Training loss: 1.5953030586242676
Validation loss: 2.1091745446125665

Epoch: 5| Step: 5
Training loss: 2.0096325874328613
Validation loss: 2.1249087005853653

Epoch: 5| Step: 6
Training loss: 2.159893035888672
Validation loss: 2.1383776863416037

Epoch: 5| Step: 7
Training loss: 2.630585193634033
Validation loss: 2.135304013888041

Epoch: 5| Step: 8
Training loss: 2.0226023197174072
Validation loss: 2.119373470544815

Epoch: 5| Step: 9
Training loss: 1.8350307941436768
Validation loss: 2.1185034414132438

Epoch: 5| Step: 10
Training loss: 2.023475170135498
Validation loss: 2.09605265657107

Epoch: 5| Step: 11
Training loss: 1.1082406044006348
Validation loss: 2.1452278097470603

Epoch: 29| Step: 0
Training loss: 1.7136647701263428
Validation loss: 2.1591283281644187

Epoch: 5| Step: 1
Training loss: 2.0459084510803223
Validation loss: 2.1198829412460327

Epoch: 5| Step: 2
Training loss: 1.5632857084274292
Validation loss: 2.0987755209207535

Epoch: 5| Step: 3
Training loss: 2.1496996879577637
Validation loss: 2.101989304025968

Epoch: 5| Step: 4
Training loss: 2.6860039234161377
Validation loss: 2.1211109658082328

Epoch: 5| Step: 5
Training loss: 2.4722747802734375
Validation loss: 2.1212280790011087

Epoch: 5| Step: 6
Training loss: 2.3155627250671387
Validation loss: 2.1357536862293878

Epoch: 5| Step: 7
Training loss: 2.4316821098327637
Validation loss: 2.150652065873146

Epoch: 5| Step: 8
Training loss: 2.5096287727355957
Validation loss: 2.134316548705101

Epoch: 5| Step: 9
Training loss: 1.3342905044555664
Validation loss: 2.1116141279538474

Epoch: 5| Step: 10
Training loss: 1.5328662395477295
Validation loss: 2.1399279634157815

Epoch: 5| Step: 11
Training loss: 1.8899730443954468
Validation loss: 2.1568303356568017

Epoch: 30| Step: 0
Training loss: 2.052821636199951
Validation loss: 2.123935103416443

Epoch: 5| Step: 1
Training loss: 1.9411712884902954
Validation loss: 2.163072476784388

Epoch: 5| Step: 2
Training loss: 2.3821277618408203
Validation loss: 2.140940487384796

Epoch: 5| Step: 3
Training loss: 2.030550718307495
Validation loss: 2.0942667623360953

Epoch: 5| Step: 4
Training loss: 2.735175609588623
Validation loss: 2.1149216691652932

Epoch: 5| Step: 5
Training loss: 1.2652480602264404
Validation loss: 2.116237779458364

Epoch: 5| Step: 6
Training loss: 2.2853803634643555
Validation loss: 2.1282620628674827

Epoch: 5| Step: 7
Training loss: 2.377993106842041
Validation loss: 2.1286557018756866

Epoch: 5| Step: 8
Training loss: 1.7400104999542236
Validation loss: 2.1432932168245316

Epoch: 5| Step: 9
Training loss: 2.1416211128234863
Validation loss: 2.1154448240995407

Epoch: 5| Step: 10
Training loss: 1.7136809825897217
Validation loss: 2.127055118481318

Epoch: 5| Step: 11
Training loss: 2.5072388648986816
Validation loss: 2.1627303063869476

Epoch: 31| Step: 0
Training loss: 1.8840465545654297
Validation loss: 2.120947693785032

Epoch: 5| Step: 1
Training loss: 2.346400260925293
Validation loss: 2.126012106736501

Epoch: 5| Step: 2
Training loss: 2.397064685821533
Validation loss: 2.126342535018921

Epoch: 5| Step: 3
Training loss: 1.9113107919692993
Validation loss: 2.1301408112049103

Epoch: 5| Step: 4
Training loss: 2.268702268600464
Validation loss: 2.1057655612627664

Epoch: 5| Step: 5
Training loss: 1.3985391855239868
Validation loss: 2.150540997584661

Epoch: 5| Step: 6
Training loss: 1.9856021404266357
Validation loss: 2.14722216129303

Epoch: 5| Step: 7
Training loss: 2.017467498779297
Validation loss: 2.1540895104408264

Epoch: 5| Step: 8
Training loss: 2.1119027137756348
Validation loss: 2.1595614651838937

Epoch: 5| Step: 9
Training loss: 2.055309295654297
Validation loss: 2.1294454435507455

Epoch: 5| Step: 10
Training loss: 2.4340176582336426
Validation loss: 2.147767961025238

Epoch: 5| Step: 11
Training loss: 1.6709229946136475
Validation loss: 2.1342843919992447

Epoch: 32| Step: 0
Training loss: 1.480263113975525
Validation loss: 2.142209157347679

Epoch: 5| Step: 1
Training loss: 2.4728095531463623
Validation loss: 2.154882162809372

Epoch: 5| Step: 2
Training loss: 1.7655179500579834
Validation loss: 2.1713078320026398

Epoch: 5| Step: 3
Training loss: 2.2144577503204346
Validation loss: 2.1983874837557473

Epoch: 5| Step: 4
Training loss: 2.6462059020996094
Validation loss: 2.1634327371915183

Epoch: 5| Step: 5
Training loss: 2.1795995235443115
Validation loss: 2.1789443840583167

Epoch: 5| Step: 6
Training loss: 1.8870162963867188
Validation loss: 2.124983991185824

Epoch: 5| Step: 7
Training loss: 2.4826583862304688
Validation loss: 2.1339037815729776

Epoch: 5| Step: 8
Training loss: 1.9014265537261963
Validation loss: 2.15198844174544

Epoch: 5| Step: 9
Training loss: 1.5962159633636475
Validation loss: 2.1203538328409195

Epoch: 5| Step: 10
Training loss: 2.390650987625122
Validation loss: 2.1382348934809365

Epoch: 5| Step: 11
Training loss: 2.263331174850464
Validation loss: 2.1325951715310416

Epoch: 33| Step: 0
Training loss: 1.8361167907714844
Validation loss: 2.1177390764156976

Epoch: 5| Step: 1
Training loss: 1.3130162954330444
Validation loss: 2.1084875414768853

Epoch: 5| Step: 2
Training loss: 2.098912000656128
Validation loss: 2.1261601746082306

Epoch: 5| Step: 3
Training loss: 1.9066803455352783
Validation loss: 2.097971191008886

Epoch: 5| Step: 4
Training loss: 1.9280586242675781
Validation loss: 2.119053602218628

Epoch: 5| Step: 5
Training loss: 1.7622188329696655
Validation loss: 2.1091005504131317

Epoch: 5| Step: 6
Training loss: 2.656588077545166
Validation loss: 2.0919775714476905

Epoch: 5| Step: 7
Training loss: 1.8301712274551392
Validation loss: 2.137000391880671

Epoch: 5| Step: 8
Training loss: 1.9838006496429443
Validation loss: 2.105025887489319

Epoch: 5| Step: 9
Training loss: 2.5525784492492676
Validation loss: 2.1261360148588815

Epoch: 5| Step: 10
Training loss: 2.56042218208313
Validation loss: 2.1247852643330893

Epoch: 5| Step: 11
Training loss: 2.9376606941223145
Validation loss: 2.11166058977445

Epoch: 34| Step: 0
Training loss: 2.0678741931915283
Validation loss: 2.1030522833267846

Epoch: 5| Step: 1
Training loss: 2.1258161067962646
Validation loss: 2.1132815182209015

Epoch: 5| Step: 2
Training loss: 1.9598007202148438
Validation loss: 2.1313642809788385

Epoch: 5| Step: 3
Training loss: 2.1153342723846436
Validation loss: 2.1293701430161796

Epoch: 5| Step: 4
Training loss: 2.0440850257873535
Validation loss: 2.0932693680127463

Epoch: 5| Step: 5
Training loss: 1.8941090106964111
Validation loss: 2.11792853474617

Epoch: 5| Step: 6
Training loss: 1.535559892654419
Validation loss: 2.1042016545931497

Epoch: 5| Step: 7
Training loss: 1.8762397766113281
Validation loss: 2.0971747239430747

Epoch: 5| Step: 8
Training loss: 2.483625888824463
Validation loss: 2.067572961250941

Epoch: 5| Step: 9
Training loss: 2.153376340866089
Validation loss: 2.130475699901581

Epoch: 5| Step: 10
Training loss: 1.7902284860610962
Validation loss: 2.0847637901703515

Epoch: 5| Step: 11
Training loss: 3.2919111251831055
Validation loss: 2.129053458571434

Epoch: 35| Step: 0
Training loss: 1.8632398843765259
Validation loss: 2.1119764298200607

Epoch: 5| Step: 1
Training loss: 2.097043037414551
Validation loss: 2.120863268772761

Epoch: 5| Step: 2
Training loss: 2.155381441116333
Validation loss: 2.1140405982732773

Epoch: 5| Step: 3
Training loss: 1.5981839895248413
Validation loss: 2.096637179454168

Epoch: 5| Step: 4
Training loss: 2.0295581817626953
Validation loss: 2.090763842066129

Epoch: 5| Step: 5
Training loss: 1.909064531326294
Validation loss: 2.079334328571955

Epoch: 5| Step: 6
Training loss: 2.54763126373291
Validation loss: 2.091776659091314

Epoch: 5| Step: 7
Training loss: 1.5412929058074951
Validation loss: 2.1077565352121987

Epoch: 5| Step: 8
Training loss: 2.558316707611084
Validation loss: 2.1063098708788552

Epoch: 5| Step: 9
Training loss: 2.040889263153076
Validation loss: 2.1215245127677917

Epoch: 5| Step: 10
Training loss: 2.166858673095703
Validation loss: 2.14108374218146

Epoch: 5| Step: 11
Training loss: 1.0093107223510742
Validation loss: 2.1479314963022866

Epoch: 36| Step: 0
Training loss: 2.1534979343414307
Validation loss: 2.124518488844236

Epoch: 5| Step: 1
Training loss: 2.039508104324341
Validation loss: 2.1230854590733848

Epoch: 5| Step: 2
Training loss: 2.2107272148132324
Validation loss: 2.1160957515239716

Epoch: 5| Step: 3
Training loss: 2.4095849990844727
Validation loss: 2.1467322508494058

Epoch: 5| Step: 4
Training loss: 1.629492163658142
Validation loss: 2.148571193218231

Epoch: 5| Step: 5
Training loss: 1.760554552078247
Validation loss: 2.147072354952494

Epoch: 5| Step: 6
Training loss: 2.027972459793091
Validation loss: 2.155531292160352

Epoch: 5| Step: 7
Training loss: 2.3668997287750244
Validation loss: 2.1614103466272354

Epoch: 5| Step: 8
Training loss: 2.6123104095458984
Validation loss: 2.1875019868214927

Epoch: 5| Step: 9
Training loss: 1.7298072576522827
Validation loss: 2.147554119427999

Epoch: 5| Step: 10
Training loss: 1.7084585428237915
Validation loss: 2.117422337333361

Epoch: 5| Step: 11
Training loss: 1.254749059677124
Validation loss: 2.1276565541823707

Epoch: 37| Step: 0
Training loss: 2.604360580444336
Validation loss: 2.130244349439939

Epoch: 5| Step: 1
Training loss: 1.5028440952301025
Validation loss: 2.0853346288204193

Epoch: 5| Step: 2
Training loss: 1.8482780456542969
Validation loss: 2.0807453294595084

Epoch: 5| Step: 3
Training loss: 2.1189255714416504
Validation loss: 2.139040852586428

Epoch: 5| Step: 4
Training loss: 1.9625447988510132
Validation loss: 2.1299612522125244

Epoch: 5| Step: 5
Training loss: 2.1049251556396484
Validation loss: 2.09738456706206

Epoch: 5| Step: 6
Training loss: 2.5432252883911133
Validation loss: 2.1063122351964316

Epoch: 5| Step: 7
Training loss: 1.8348360061645508
Validation loss: 2.124818578362465

Epoch: 5| Step: 8
Training loss: 2.6158695220947266
Validation loss: 2.129779706398646

Epoch: 5| Step: 9
Training loss: 2.1780312061309814
Validation loss: 2.123872250318527

Epoch: 5| Step: 10
Training loss: 1.474088430404663
Validation loss: 2.1160180419683456

Epoch: 5| Step: 11
Training loss: 2.2683379650115967
Validation loss: 2.125113010406494

Epoch: 38| Step: 0
Training loss: 2.159406900405884
Validation loss: 2.120863492290179

Epoch: 5| Step: 1
Training loss: 1.6377027034759521
Validation loss: 2.089007794857025

Epoch: 5| Step: 2
Training loss: 2.567654848098755
Validation loss: 2.0933673481146493

Epoch: 5| Step: 3
Training loss: 1.9845082759857178
Validation loss: 2.132197827100754

Epoch: 5| Step: 4
Training loss: 1.7638492584228516
Validation loss: 2.1385904351870217

Epoch: 5| Step: 5
Training loss: 2.241175413131714
Validation loss: 2.143800968925158

Epoch: 5| Step: 6
Training loss: 2.3663887977600098
Validation loss: 2.1555584222078323

Epoch: 5| Step: 7
Training loss: 1.9231059551239014
Validation loss: 2.1193747321764627

Epoch: 5| Step: 8
Training loss: 2.1050472259521484
Validation loss: 2.1484451393286386

Epoch: 5| Step: 9
Training loss: 1.9871017932891846
Validation loss: 2.118065079053243

Epoch: 5| Step: 10
Training loss: 1.7431166172027588
Validation loss: 2.1080901324748993

Epoch: 5| Step: 11
Training loss: 1.746762752532959
Validation loss: 2.1291974435249963

Epoch: 39| Step: 0
Training loss: 1.74495530128479
Validation loss: 2.1298467566569648

Epoch: 5| Step: 1
Training loss: 2.0927224159240723
Validation loss: 2.1126221120357513

Epoch: 5| Step: 2
Training loss: 2.145747423171997
Validation loss: 2.104855770866076

Epoch: 5| Step: 3
Training loss: 1.880323052406311
Validation loss: 2.116026590267817

Epoch: 5| Step: 4
Training loss: 2.3954358100891113
Validation loss: 2.079958980282148

Epoch: 5| Step: 5
Training loss: 2.4224345684051514
Validation loss: 2.1015662848949432

Epoch: 5| Step: 6
Training loss: 2.5140373706817627
Validation loss: 2.1100232700506845

Epoch: 5| Step: 7
Training loss: 1.9422012567520142
Validation loss: 2.1163222640752792

Epoch: 5| Step: 8
Training loss: 1.7936553955078125
Validation loss: 2.1096049745877585

Epoch: 5| Step: 9
Training loss: 2.156428575515747
Validation loss: 2.076504240433375

Epoch: 5| Step: 10
Training loss: 1.3332138061523438
Validation loss: 2.1132814288139343

Epoch: 5| Step: 11
Training loss: 1.0205085277557373
Validation loss: 2.13584074874719

Epoch: 40| Step: 0
Training loss: 2.026078224182129
Validation loss: 2.0951596796512604

Epoch: 5| Step: 1
Training loss: 1.8110889196395874
Validation loss: 2.0879348715146384

Epoch: 5| Step: 2
Training loss: 1.734316110610962
Validation loss: 2.1066813369592032

Epoch: 5| Step: 3
Training loss: 1.9100799560546875
Validation loss: 2.0804723600546517

Epoch: 5| Step: 4
Training loss: 2.5498015880584717
Validation loss: 2.0942094127337136

Epoch: 5| Step: 5
Training loss: 2.559940814971924
Validation loss: 2.0862367947896323

Epoch: 5| Step: 6
Training loss: 2.3714518547058105
Validation loss: 2.14500925441583

Epoch: 5| Step: 7
Training loss: 2.1232407093048096
Validation loss: 2.089918792247772

Epoch: 5| Step: 8
Training loss: 1.8029447793960571
Validation loss: 2.1111943423748016

Epoch: 5| Step: 9
Training loss: 1.4308674335479736
Validation loss: 2.1086979657411575

Epoch: 5| Step: 10
Training loss: 1.9177939891815186
Validation loss: 2.1476272145907083

Epoch: 5| Step: 11
Training loss: 2.094027519226074
Validation loss: 2.1113842328389487

Epoch: 41| Step: 0
Training loss: 2.4173061847686768
Validation loss: 2.121699328223864

Epoch: 5| Step: 1
Training loss: 1.954655647277832
Validation loss: 2.134934534629186

Epoch: 5| Step: 2
Training loss: 2.578831195831299
Validation loss: 2.087151433030764

Epoch: 5| Step: 3
Training loss: 1.3536319732666016
Validation loss: 2.115005816022555

Epoch: 5| Step: 4
Training loss: 1.1813552379608154
Validation loss: 2.1601901849110923

Epoch: 5| Step: 5
Training loss: 1.9634599685668945
Validation loss: 2.118011678258578

Epoch: 5| Step: 6
Training loss: 2.5174050331115723
Validation loss: 2.0853343407313027

Epoch: 5| Step: 7
Training loss: 2.231433391571045
Validation loss: 2.1377814958492913

Epoch: 5| Step: 8
Training loss: 2.154412031173706
Validation loss: 2.1055995374917984

Epoch: 5| Step: 9
Training loss: 2.236581802368164
Validation loss: 2.087965498367945

Epoch: 5| Step: 10
Training loss: 1.6202328205108643
Validation loss: 2.0944585700829825

Epoch: 5| Step: 11
Training loss: 1.9874478578567505
Validation loss: 2.1403058419624963

Epoch: 42| Step: 0
Training loss: 1.911970853805542
Validation loss: 2.1005833049615226

Epoch: 5| Step: 1
Training loss: 2.1268463134765625
Validation loss: 2.1130614479382834

Epoch: 5| Step: 2
Training loss: 2.1344549655914307
Validation loss: 2.0762985746065774

Epoch: 5| Step: 3
Training loss: 2.105919599533081
Validation loss: 2.1067414780457816

Epoch: 5| Step: 4
Training loss: 2.03535795211792
Validation loss: 2.104729731877645

Epoch: 5| Step: 5
Training loss: 2.005763530731201
Validation loss: 2.1095347106456757

Epoch: 5| Step: 6
Training loss: 1.981675148010254
Validation loss: 2.11686564485232

Epoch: 5| Step: 7
Training loss: 2.172267436981201
Validation loss: 2.11644180615743

Epoch: 5| Step: 8
Training loss: 1.8973731994628906
Validation loss: 2.1272189617156982

Epoch: 5| Step: 9
Training loss: 1.9690297842025757
Validation loss: 2.081545889377594

Epoch: 5| Step: 10
Training loss: 1.9543060064315796
Validation loss: 2.1018885572751365

Epoch: 5| Step: 11
Training loss: 1.658088207244873
Validation loss: 2.105530316630999

Epoch: 43| Step: 0
Training loss: 1.5573557615280151
Validation loss: 2.105594048897425

Epoch: 5| Step: 1
Training loss: 1.980984091758728
Validation loss: 2.1042605688174567

Epoch: 5| Step: 2
Training loss: 2.0980687141418457
Validation loss: 2.1173063069581985

Epoch: 5| Step: 3
Training loss: 2.0002331733703613
Validation loss: 2.096376766761144

Epoch: 5| Step: 4
Training loss: 2.1907055377960205
Validation loss: 2.085228681564331

Epoch: 5| Step: 5
Training loss: 2.87109112739563
Validation loss: 2.1139863630135856

Epoch: 5| Step: 6
Training loss: 1.860767126083374
Validation loss: 2.155936231215795

Epoch: 5| Step: 7
Training loss: 1.4280275106430054
Validation loss: 2.1236185431480408

Epoch: 5| Step: 8
Training loss: 1.9090821743011475
Validation loss: 2.142765333255132

Epoch: 5| Step: 9
Training loss: 2.1407370567321777
Validation loss: 2.121938476959864

Epoch: 5| Step: 10
Training loss: 2.4436686038970947
Validation loss: 2.0848817775646844

Epoch: 5| Step: 11
Training loss: 1.7281213998794556
Validation loss: 2.102506453792254

Epoch: 44| Step: 0
Training loss: 1.7346713542938232
Validation loss: 2.103518391648928

Epoch: 5| Step: 1
Training loss: 2.024202823638916
Validation loss: 2.113597184419632

Epoch: 5| Step: 2
Training loss: 1.8498458862304688
Validation loss: 2.085822363694509

Epoch: 5| Step: 3
Training loss: 2.1866891384124756
Validation loss: 2.1085530817508698

Epoch: 5| Step: 4
Training loss: 2.379373550415039
Validation loss: 2.142201855778694

Epoch: 5| Step: 5
Training loss: 2.479846239089966
Validation loss: 2.071783408522606

Epoch: 5| Step: 6
Training loss: 1.894260048866272
Validation loss: 2.1379687239726386

Epoch: 5| Step: 7
Training loss: 2.1913466453552246
Validation loss: 2.0812040269374847

Epoch: 5| Step: 8
Training loss: 1.8782165050506592
Validation loss: 2.098348389069239

Epoch: 5| Step: 9
Training loss: 2.2380776405334473
Validation loss: 2.1331509997447333

Epoch: 5| Step: 10
Training loss: 1.651917815208435
Validation loss: 2.098722517490387

Epoch: 5| Step: 11
Training loss: 1.3993933200836182
Validation loss: 2.117608348528544

Epoch: 45| Step: 0
Training loss: 2.016165256500244
Validation loss: 2.085522805651029

Epoch: 5| Step: 1
Training loss: 2.3178293704986572
Validation loss: 2.0934366335471473

Epoch: 5| Step: 2
Training loss: 1.6935008764266968
Validation loss: 2.086419145266215

Epoch: 5| Step: 3
Training loss: 2.1543495655059814
Validation loss: 2.102017651001612

Epoch: 5| Step: 4
Training loss: 2.4126553535461426
Validation loss: 2.1226976762215295

Epoch: 5| Step: 5
Training loss: 2.020474910736084
Validation loss: 2.1578697164853415

Epoch: 5| Step: 6
Training loss: 1.4342687129974365
Validation loss: 2.13815804819266

Epoch: 5| Step: 7
Training loss: 2.7093148231506348
Validation loss: 2.105366140604019

Epoch: 5| Step: 8
Training loss: 1.5510103702545166
Validation loss: 2.0761314729849496

Epoch: 5| Step: 9
Training loss: 2.185870409011841
Validation loss: 2.128911559780439

Epoch: 5| Step: 10
Training loss: 1.8727163076400757
Validation loss: 2.092216129104296

Epoch: 5| Step: 11
Training loss: 2.1920342445373535
Validation loss: 2.0953508764505386

Epoch: 46| Step: 0
Training loss: 1.5159952640533447
Validation loss: 2.0769790560007095

Epoch: 5| Step: 1
Training loss: 2.0388152599334717
Validation loss: 2.1119912465413413

Epoch: 5| Step: 2
Training loss: 2.1290831565856934
Validation loss: 2.06870270272096

Epoch: 5| Step: 3
Training loss: 1.9794299602508545
Validation loss: 2.09140952428182

Epoch: 5| Step: 4
Training loss: 1.829402208328247
Validation loss: 2.089559485514959

Epoch: 5| Step: 5
Training loss: 2.426241874694824
Validation loss: 2.1238365272680917

Epoch: 5| Step: 6
Training loss: 2.6403892040252686
Validation loss: 2.116330544153849

Epoch: 5| Step: 7
Training loss: 1.5756349563598633
Validation loss: 2.123094121615092

Epoch: 5| Step: 8
Training loss: 1.8811960220336914
Validation loss: 2.056508402029673

Epoch: 5| Step: 9
Training loss: 1.9888813495635986
Validation loss: 2.0822891294956207

Epoch: 5| Step: 10
Training loss: 2.0337047576904297
Validation loss: 2.124979833761851

Epoch: 5| Step: 11
Training loss: 2.315633773803711
Validation loss: 2.0826011498769126

Epoch: 47| Step: 0
Training loss: 2.4530959129333496
Validation loss: 2.0804742674032846

Epoch: 5| Step: 1
Training loss: 1.426713228225708
Validation loss: 2.143506333231926

Epoch: 5| Step: 2
Training loss: 1.7607330083847046
Validation loss: 2.1366107861200967

Epoch: 5| Step: 3
Training loss: 3.3782501220703125
Validation loss: 2.147045453389486

Epoch: 5| Step: 4
Training loss: 1.5057334899902344
Validation loss: 2.1362393697102866

Epoch: 5| Step: 5
Training loss: 1.9063764810562134
Validation loss: 2.1217080702384314

Epoch: 5| Step: 6
Training loss: 2.3173627853393555
Validation loss: 2.1057829360167184

Epoch: 5| Step: 7
Training loss: 1.610457420349121
Validation loss: 2.1016977032025657

Epoch: 5| Step: 8
Training loss: 1.3575501441955566
Validation loss: 2.092596411705017

Epoch: 5| Step: 9
Training loss: 2.5524206161499023
Validation loss: 2.0603191951910653

Epoch: 5| Step: 10
Training loss: 1.8819820880889893
Validation loss: 2.0743882904450097

Epoch: 5| Step: 11
Training loss: 1.9137632846832275
Validation loss: 2.112998381257057

Epoch: 48| Step: 0
Training loss: 2.6688826084136963
Validation loss: 2.0971887012322745

Epoch: 5| Step: 1
Training loss: 1.535918116569519
Validation loss: 2.121216302116712

Epoch: 5| Step: 2
Training loss: 2.0773673057556152
Validation loss: 2.0911321540673575

Epoch: 5| Step: 3
Training loss: 1.9712005853652954
Validation loss: 2.13569741944472

Epoch: 5| Step: 4
Training loss: 1.8394886255264282
Validation loss: 2.1067506223917007

Epoch: 5| Step: 5
Training loss: 2.0536885261535645
Validation loss: 2.097584212819735

Epoch: 5| Step: 6
Training loss: 2.000791072845459
Validation loss: 2.076561654607455

Epoch: 5| Step: 7
Training loss: 1.7189624309539795
Validation loss: 2.084288646777471

Epoch: 5| Step: 8
Training loss: 1.8843920230865479
Validation loss: 2.112863446275393

Epoch: 5| Step: 9
Training loss: 1.904711127281189
Validation loss: 2.090721234679222

Epoch: 5| Step: 10
Training loss: 2.2953083515167236
Validation loss: 2.1048830648263297

Epoch: 5| Step: 11
Training loss: 1.9110270738601685
Validation loss: 2.1107406417528787

Epoch: 49| Step: 0
Training loss: 2.033247470855713
Validation loss: 2.0523163030544915

Epoch: 5| Step: 1
Training loss: 1.8915151357650757
Validation loss: 2.0727798541386924

Epoch: 5| Step: 2
Training loss: 1.9356555938720703
Validation loss: 2.098545437057813

Epoch: 5| Step: 3
Training loss: 1.2786052227020264
Validation loss: 2.12845009068648

Epoch: 5| Step: 4
Training loss: 2.582707643508911
Validation loss: 2.083233247200648

Epoch: 5| Step: 5
Training loss: 2.4365453720092773
Validation loss: 2.1014552464087806

Epoch: 5| Step: 6
Training loss: 1.8352928161621094
Validation loss: 2.13712606827418

Epoch: 5| Step: 7
Training loss: 2.263274669647217
Validation loss: 2.129160831371943

Epoch: 5| Step: 8
Training loss: 2.4156010150909424
Validation loss: 2.0984724114338555

Epoch: 5| Step: 9
Training loss: 1.6403192281723022
Validation loss: 2.1068719824155173

Epoch: 5| Step: 10
Training loss: 1.9087737798690796
Validation loss: 2.1022461503744125

Epoch: 5| Step: 11
Training loss: 1.2737255096435547
Validation loss: 2.116061106324196

Epoch: 50| Step: 0
Training loss: 1.6707217693328857
Validation loss: 2.086695005496343

Epoch: 5| Step: 1
Training loss: 2.3466145992279053
Validation loss: 2.0981624126434326

Epoch: 5| Step: 2
Training loss: 1.7932344675064087
Validation loss: 2.0936338206132254

Epoch: 5| Step: 3
Training loss: 1.8989120721817017
Validation loss: 2.099402070045471

Epoch: 5| Step: 4
Training loss: 2.032743215560913
Validation loss: 2.0635538399219513

Epoch: 5| Step: 5
Training loss: 2.3281431198120117
Validation loss: 2.064517855644226

Epoch: 5| Step: 6
Training loss: 2.125298023223877
Validation loss: 2.0624861667553582

Epoch: 5| Step: 7
Training loss: 2.3919436931610107
Validation loss: 2.1205324679613113

Epoch: 5| Step: 8
Training loss: 1.725311517715454
Validation loss: 2.0795767654975257

Epoch: 5| Step: 9
Training loss: 2.009154796600342
Validation loss: 2.110396837194761

Epoch: 5| Step: 10
Training loss: 2.2422242164611816
Validation loss: 2.072228411833445

Epoch: 5| Step: 11
Training loss: 1.012478232383728
Validation loss: 2.1063789625962577

Epoch: 51| Step: 0
Training loss: 2.0896520614624023
Validation loss: 2.103048468629519

Epoch: 5| Step: 1
Training loss: 2.7723946571350098
Validation loss: 2.115174820025762

Epoch: 5| Step: 2
Training loss: 2.209211826324463
Validation loss: 2.1196321497360864

Epoch: 5| Step: 3
Training loss: 2.2951343059539795
Validation loss: 2.108366976181666

Epoch: 5| Step: 4
Training loss: 2.208130359649658
Validation loss: 2.162636121114095

Epoch: 5| Step: 5
Training loss: 1.7930476665496826
Validation loss: 2.0722419073184333

Epoch: 5| Step: 6
Training loss: 2.4215304851531982
Validation loss: 2.108685463666916

Epoch: 5| Step: 7
Training loss: 1.2764196395874023
Validation loss: 2.1106726030508676

Epoch: 5| Step: 8
Training loss: 1.8140023946762085
Validation loss: 2.0766409089167914

Epoch: 5| Step: 9
Training loss: 1.195827603340149
Validation loss: 2.0913080970446267

Epoch: 5| Step: 10
Training loss: 1.9321895837783813
Validation loss: 2.0828231871128082

Epoch: 5| Step: 11
Training loss: 2.717226982116699
Validation loss: 2.0859199663003287

Epoch: 52| Step: 0
Training loss: 1.4633647203445435
Validation loss: 2.12437142431736

Epoch: 5| Step: 1
Training loss: 2.1509969234466553
Validation loss: 2.11269145210584

Epoch: 5| Step: 2
Training loss: 2.402390956878662
Validation loss: 2.1108098129431405

Epoch: 5| Step: 3
Training loss: 1.9606860876083374
Validation loss: 2.1099890371163688

Epoch: 5| Step: 4
Training loss: 1.5773879289627075
Validation loss: 2.0773560454448066

Epoch: 5| Step: 5
Training loss: 1.977919340133667
Validation loss: 2.0971842606862388

Epoch: 5| Step: 6
Training loss: 2.4232382774353027
Validation loss: 2.1608489652474723

Epoch: 5| Step: 7
Training loss: 2.306152582168579
Validation loss: 2.1206296235322952

Epoch: 5| Step: 8
Training loss: 1.894357681274414
Validation loss: 2.14876060684522

Epoch: 5| Step: 9
Training loss: 2.2238993644714355
Validation loss: 2.1201630433400473

Epoch: 5| Step: 10
Training loss: 2.0342705249786377
Validation loss: 2.1733877857526145

Epoch: 5| Step: 11
Training loss: 2.054028034210205
Validation loss: 2.145613670349121

Epoch: 53| Step: 0
Training loss: 1.9907281398773193
Validation loss: 2.1062981883684793

Epoch: 5| Step: 1
Training loss: 2.428818464279175
Validation loss: 2.09779059390227

Epoch: 5| Step: 2
Training loss: 1.6876084804534912
Validation loss: 2.1052953004837036

Epoch: 5| Step: 3
Training loss: 2.1361756324768066
Validation loss: 2.092865765094757

Epoch: 5| Step: 4
Training loss: 2.6215453147888184
Validation loss: 2.1057371497154236

Epoch: 5| Step: 5
Training loss: 1.9174392223358154
Validation loss: 2.1058396995067596

Epoch: 5| Step: 6
Training loss: 1.5882080793380737
Validation loss: 2.1001225113868713

Epoch: 5| Step: 7
Training loss: 1.3710529804229736
Validation loss: 2.0761380145947137

Epoch: 5| Step: 8
Training loss: 2.2175164222717285
Validation loss: 2.089636633793513

Epoch: 5| Step: 9
Training loss: 1.773002028465271
Validation loss: 2.096480498711268

Epoch: 5| Step: 10
Training loss: 2.25439715385437
Validation loss: 2.0861296703418097

Epoch: 5| Step: 11
Training loss: 1.3674089908599854
Validation loss: 2.09368563691775

Epoch: 54| Step: 0
Training loss: 1.8792235851287842
Validation loss: 2.0952088236808777

Epoch: 5| Step: 1
Training loss: 2.5361576080322266
Validation loss: 2.121610015630722

Epoch: 5| Step: 2
Training loss: 1.9996452331542969
Validation loss: 2.1043448944886527

Epoch: 5| Step: 3
Training loss: 2.2428677082061768
Validation loss: 2.099792098005613

Epoch: 5| Step: 4
Training loss: 2.5232479572296143
Validation loss: 2.104832927385966

Epoch: 5| Step: 5
Training loss: 2.110074043273926
Validation loss: 2.091679260134697

Epoch: 5| Step: 6
Training loss: 1.606874704360962
Validation loss: 2.1220485121011734

Epoch: 5| Step: 7
Training loss: 1.2761266231536865
Validation loss: 2.125973383585612

Epoch: 5| Step: 8
Training loss: 1.8096294403076172
Validation loss: 2.111276219288508

Epoch: 5| Step: 9
Training loss: 1.474624514579773
Validation loss: 2.1223553170760474

Epoch: 5| Step: 10
Training loss: 2.4980249404907227
Validation loss: 2.10650767882665

Epoch: 5| Step: 11
Training loss: 2.494194746017456
Validation loss: 2.1141447027524314

Epoch: 55| Step: 0
Training loss: 2.1342897415161133
Validation loss: 2.0906519293785095

Epoch: 5| Step: 1
Training loss: 1.8291950225830078
Validation loss: 2.066004211703936

Epoch: 5| Step: 2
Training loss: 2.426379680633545
Validation loss: 2.090520977973938

Epoch: 5| Step: 3
Training loss: 2.3936145305633545
Validation loss: 2.123174543182055

Epoch: 5| Step: 4
Training loss: 1.5610450506210327
Validation loss: 2.0991226732730865

Epoch: 5| Step: 5
Training loss: 1.9335600137710571
Validation loss: 2.051362787683805

Epoch: 5| Step: 6
Training loss: 2.7050490379333496
Validation loss: 2.0600479592879615

Epoch: 5| Step: 7
Training loss: 1.8771092891693115
Validation loss: 2.0816101084152856

Epoch: 5| Step: 8
Training loss: 1.6255638599395752
Validation loss: 2.038684993982315

Epoch: 5| Step: 9
Training loss: 1.8009636402130127
Validation loss: 2.101408531268438

Epoch: 5| Step: 10
Training loss: 1.6194467544555664
Validation loss: 2.063899646202723

Epoch: 5| Step: 11
Training loss: 2.8282175064086914
Validation loss: 2.0651717285315194

Epoch: 56| Step: 0
Training loss: 1.817457914352417
Validation loss: 2.117130915323893

Epoch: 5| Step: 1
Training loss: 1.698036551475525
Validation loss: 2.0746691524982452

Epoch: 5| Step: 2
Training loss: 1.846356987953186
Validation loss: 2.1050927191972733

Epoch: 5| Step: 3
Training loss: 1.0379050970077515
Validation loss: 2.106692135334015

Epoch: 5| Step: 4
Training loss: 2.8318119049072266
Validation loss: 2.079841981331507

Epoch: 5| Step: 5
Training loss: 2.122252941131592
Validation loss: 2.1017685929934182

Epoch: 5| Step: 6
Training loss: 1.8790000677108765
Validation loss: 2.0961128820975623

Epoch: 5| Step: 7
Training loss: 2.3680484294891357
Validation loss: 2.1111500759919486

Epoch: 5| Step: 8
Training loss: 1.7951889038085938
Validation loss: 2.0850706895192466

Epoch: 5| Step: 9
Training loss: 2.3767125606536865
Validation loss: 2.090986584623655

Epoch: 5| Step: 10
Training loss: 2.1570656299591064
Validation loss: 2.1122923642396927

Epoch: 5| Step: 11
Training loss: 1.6335021257400513
Validation loss: 2.1183789521455765

Epoch: 57| Step: 0
Training loss: 2.606196165084839
Validation loss: 2.074602703253428

Epoch: 5| Step: 1
Training loss: 1.6939103603363037
Validation loss: 2.074366956949234

Epoch: 5| Step: 2
Training loss: 1.675459861755371
Validation loss: 2.1228649268547692

Epoch: 5| Step: 3
Training loss: 2.7248454093933105
Validation loss: 2.093360587954521

Epoch: 5| Step: 4
Training loss: 1.9903767108917236
Validation loss: 2.1023360093434653

Epoch: 5| Step: 5
Training loss: 2.4926650524139404
Validation loss: 2.082494785388311

Epoch: 5| Step: 6
Training loss: 2.0711894035339355
Validation loss: 2.103512316942215

Epoch: 5| Step: 7
Training loss: 1.8335078954696655
Validation loss: 2.1096360832452774

Epoch: 5| Step: 8
Training loss: 1.439276933670044
Validation loss: 2.0640528947114944

Epoch: 5| Step: 9
Training loss: 1.9231212139129639
Validation loss: 2.130679582556089

Epoch: 5| Step: 10
Training loss: 1.2299764156341553
Validation loss: 2.0861676931381226

Epoch: 5| Step: 11
Training loss: 2.2493860721588135
Validation loss: 2.1012735863526664

Epoch: 58| Step: 0
Training loss: 1.9027513265609741
Validation loss: 2.09710423151652

Epoch: 5| Step: 1
Training loss: 2.5802149772644043
Validation loss: 2.1141652266184487

Epoch: 5| Step: 2
Training loss: 2.1239728927612305
Validation loss: 2.0928334842125573

Epoch: 5| Step: 3
Training loss: 1.7822444438934326
Validation loss: 2.094564934571584

Epoch: 5| Step: 4
Training loss: 1.9926397800445557
Validation loss: 2.1195905953645706

Epoch: 5| Step: 5
Training loss: 1.9704411029815674
Validation loss: 2.082611451546351

Epoch: 5| Step: 6
Training loss: 2.3103697299957275
Validation loss: 2.096771960457166

Epoch: 5| Step: 7
Training loss: 2.1127684116363525
Validation loss: 2.077170357108116

Epoch: 5| Step: 8
Training loss: 2.0506253242492676
Validation loss: 2.096493581930796

Epoch: 5| Step: 9
Training loss: 2.0974650382995605
Validation loss: 2.093844950199127

Epoch: 5| Step: 10
Training loss: 1.4560292959213257
Validation loss: 2.1017998407284417

Epoch: 5| Step: 11
Training loss: 1.8062808513641357
Validation loss: 2.122951661547025

Epoch: 59| Step: 0
Training loss: 2.2663731575012207
Validation loss: 2.080530285835266

Epoch: 5| Step: 1
Training loss: 1.9562294483184814
Validation loss: 2.053493012984594

Epoch: 5| Step: 2
Training loss: 2.158231258392334
Validation loss: 2.1017829875151315

Epoch: 5| Step: 3
Training loss: 1.5258724689483643
Validation loss: 2.110228185852369

Epoch: 5| Step: 4
Training loss: 2.0005290508270264
Validation loss: 2.120551476875941

Epoch: 5| Step: 5
Training loss: 2.049302577972412
Validation loss: 2.1275741159915924

Epoch: 5| Step: 6
Training loss: 1.7728887796401978
Validation loss: 2.118750512599945

Epoch: 5| Step: 7
Training loss: 1.8044542074203491
Validation loss: 2.130181004603704

Epoch: 5| Step: 8
Training loss: 2.272726535797119
Validation loss: 2.1307659248510995

Epoch: 5| Step: 9
Training loss: 2.0742759704589844
Validation loss: 2.1420842111110687

Epoch: 5| Step: 10
Training loss: 1.959468126296997
Validation loss: 2.1427824795246124

Epoch: 5| Step: 11
Training loss: 1.9144641160964966
Validation loss: 2.1440929720799127

Epoch: 60| Step: 0
Training loss: 1.8306505680084229
Validation loss: 2.1423583924770355

Epoch: 5| Step: 1
Training loss: 2.3310322761535645
Validation loss: 2.1406860997279487

Epoch: 5| Step: 2
Training loss: 1.3691368103027344
Validation loss: 2.126016249259313

Epoch: 5| Step: 3
Training loss: 1.9397579431533813
Validation loss: 2.1210707128047943

Epoch: 5| Step: 4
Training loss: 2.167685031890869
Validation loss: 2.1424617966016135

Epoch: 5| Step: 5
Training loss: 2.1491100788116455
Validation loss: 2.0935754229625068

Epoch: 5| Step: 6
Training loss: 1.6542737483978271
Validation loss: 2.1419828881820044

Epoch: 5| Step: 7
Training loss: 1.8654553890228271
Validation loss: 2.1162466257810593

Epoch: 5| Step: 8
Training loss: 2.0797030925750732
Validation loss: 2.097911313176155

Epoch: 5| Step: 9
Training loss: 1.7616071701049805
Validation loss: 2.1314182678858438

Epoch: 5| Step: 10
Training loss: 2.563870906829834
Validation loss: 2.104539434115092

Epoch: 5| Step: 11
Training loss: 1.9275776147842407
Validation loss: 2.1288736512263617

Epoch: 61| Step: 0
Training loss: 1.8684875965118408
Validation loss: 2.099002798398336

Epoch: 5| Step: 1
Training loss: 2.2820792198181152
Validation loss: 2.072878489891688

Epoch: 5| Step: 2
Training loss: 1.7411143779754639
Validation loss: 2.1178177247444787

Epoch: 5| Step: 3
Training loss: 1.86880362033844
Validation loss: 2.1300217360258102

Epoch: 5| Step: 4
Training loss: 1.964116096496582
Validation loss: 2.0886890490849814

Epoch: 5| Step: 5
Training loss: 1.3584610223770142
Validation loss: 2.074800059199333

Epoch: 5| Step: 6
Training loss: 2.5375149250030518
Validation loss: 2.0826838513215384

Epoch: 5| Step: 7
Training loss: 2.6127610206604004
Validation loss: 2.0809823175271354

Epoch: 5| Step: 8
Training loss: 2.0865120887756348
Validation loss: 2.0772024939457574

Epoch: 5| Step: 9
Training loss: 2.1095707416534424
Validation loss: 2.0887431104977927

Epoch: 5| Step: 10
Training loss: 1.517430067062378
Validation loss: 2.0594639033079147

Epoch: 5| Step: 11
Training loss: 1.636049509048462
Validation loss: 2.074258014559746

Epoch: 62| Step: 0
Training loss: 1.6047947406768799
Validation loss: 2.158517067631086

Epoch: 5| Step: 1
Training loss: 2.0048389434814453
Validation loss: 2.0592574030160904

Epoch: 5| Step: 2
Training loss: 1.5032376050949097
Validation loss: 2.086884821454684

Epoch: 5| Step: 3
Training loss: 1.7797962427139282
Validation loss: 2.0624819795290628

Epoch: 5| Step: 4
Training loss: 1.8088161945343018
Validation loss: 2.17093925178051

Epoch: 5| Step: 5
Training loss: 2.151824474334717
Validation loss: 2.103928804397583

Epoch: 5| Step: 6
Training loss: 2.697591781616211
Validation loss: 2.1310030420621238

Epoch: 5| Step: 7
Training loss: 2.3109889030456543
Validation loss: 2.1442141830921173

Epoch: 5| Step: 8
Training loss: 2.163966178894043
Validation loss: 2.061794618765513

Epoch: 5| Step: 9
Training loss: 1.958146095275879
Validation loss: 2.105298638343811

Epoch: 5| Step: 10
Training loss: 2.3156700134277344
Validation loss: 2.1320667415857315

Epoch: 5| Step: 11
Training loss: 0.8978527784347534
Validation loss: 2.072078987956047

Epoch: 63| Step: 0
Training loss: 1.7187252044677734
Validation loss: 2.0957383761803308

Epoch: 5| Step: 1
Training loss: 2.251121759414673
Validation loss: 2.1013294607400894

Epoch: 5| Step: 2
Training loss: 1.861355185508728
Validation loss: 2.1037719448407493

Epoch: 5| Step: 3
Training loss: 2.2346081733703613
Validation loss: 2.100106105208397

Epoch: 5| Step: 4
Training loss: 2.5601613521575928
Validation loss: 2.113608459631602

Epoch: 5| Step: 5
Training loss: 1.9435323476791382
Validation loss: 2.1214381754398346

Epoch: 5| Step: 6
Training loss: 1.9821065664291382
Validation loss: 2.0911810298760733

Epoch: 5| Step: 7
Training loss: 1.9553298950195312
Validation loss: 2.1292935063441596

Epoch: 5| Step: 8
Training loss: 1.6767380237579346
Validation loss: 2.141934116681417

Epoch: 5| Step: 9
Training loss: 2.2831122875213623
Validation loss: 2.107512285312017

Epoch: 5| Step: 10
Training loss: 1.5983859300613403
Validation loss: 2.1032992551724115

Epoch: 5| Step: 11
Training loss: 1.1616196632385254
Validation loss: 2.112324227889379

Epoch: 64| Step: 0
Training loss: 1.9043506383895874
Validation loss: 2.08898131052653

Epoch: 5| Step: 1
Training loss: 2.126732349395752
Validation loss: 2.102657457192739

Epoch: 5| Step: 2
Training loss: 2.380894184112549
Validation loss: 2.1001452654600143

Epoch: 5| Step: 3
Training loss: 2.497878313064575
Validation loss: 2.1023804595073066

Epoch: 5| Step: 4
Training loss: 1.9509754180908203
Validation loss: 2.055374657114347

Epoch: 5| Step: 5
Training loss: 1.961816430091858
Validation loss: 2.109601547320684

Epoch: 5| Step: 6
Training loss: 1.8055286407470703
Validation loss: 2.0775230477253595

Epoch: 5| Step: 7
Training loss: 1.7202320098876953
Validation loss: 2.0959819157918296

Epoch: 5| Step: 8
Training loss: 1.6554157733917236
Validation loss: 2.081665421525637

Epoch: 5| Step: 9
Training loss: 1.9605951309204102
Validation loss: 2.06888676683108

Epoch: 5| Step: 10
Training loss: 1.5361692905426025
Validation loss: 2.0691161851088204

Epoch: 5| Step: 11
Training loss: 2.730459213256836
Validation loss: 2.1051090161005654

Epoch: 65| Step: 0
Training loss: 1.9089090824127197
Validation loss: 2.1293942828973136

Epoch: 5| Step: 1
Training loss: 1.9342025518417358
Validation loss: 2.0645467142264047

Epoch: 5| Step: 2
Training loss: 1.793402910232544
Validation loss: 2.116595839460691

Epoch: 5| Step: 3
Training loss: 1.397798776626587
Validation loss: 2.141442984342575

Epoch: 5| Step: 4
Training loss: 2.2657124996185303
Validation loss: 2.0959017177422843

Epoch: 5| Step: 5
Training loss: 1.9280221462249756
Validation loss: 2.1393666565418243

Epoch: 5| Step: 6
Training loss: 1.6197929382324219
Validation loss: 2.0687984625498452

Epoch: 5| Step: 7
Training loss: 1.8329808712005615
Validation loss: 2.0460893511772156

Epoch: 5| Step: 8
Training loss: 2.555135488510132
Validation loss: 2.0741200894117355

Epoch: 5| Step: 9
Training loss: 2.6522936820983887
Validation loss: 2.0725220143795013

Epoch: 5| Step: 10
Training loss: 1.8690059185028076
Validation loss: 2.0941088100274405

Epoch: 5| Step: 11
Training loss: 1.407021403312683
Validation loss: 2.0645389606555304

Epoch: 66| Step: 0
Training loss: 1.9077138900756836
Validation loss: 2.1236873169740043

Epoch: 5| Step: 1
Training loss: 2.153290271759033
Validation loss: 2.0616832226514816

Epoch: 5| Step: 2
Training loss: 1.9524860382080078
Validation loss: 2.116491953531901

Epoch: 5| Step: 3
Training loss: 1.7677156925201416
Validation loss: 2.1211296121279397

Epoch: 5| Step: 4
Training loss: 1.4955353736877441
Validation loss: 2.094809651374817

Epoch: 5| Step: 5
Training loss: 2.5032660961151123
Validation loss: 2.1331162651379905

Epoch: 5| Step: 6
Training loss: 2.4355239868164062
Validation loss: 2.101380000511805

Epoch: 5| Step: 7
Training loss: 1.5038197040557861
Validation loss: 2.1150607665379844

Epoch: 5| Step: 8
Training loss: 2.1432137489318848
Validation loss: 2.070929229259491

Epoch: 5| Step: 9
Training loss: 2.1053876876831055
Validation loss: 2.053968151410421

Epoch: 5| Step: 10
Training loss: 1.6024720668792725
Validation loss: 2.1304916640122733

Epoch: 5| Step: 11
Training loss: 2.314272403717041
Validation loss: 2.0671142240365348

Epoch: 67| Step: 0
Training loss: 1.7077115774154663
Validation loss: 2.1437063813209534

Epoch: 5| Step: 1
Training loss: 2.237265110015869
Validation loss: 2.122222582499186

Epoch: 5| Step: 2
Training loss: 1.9329664707183838
Validation loss: 2.1281571785608926

Epoch: 5| Step: 3
Training loss: 1.4967994689941406
Validation loss: 2.0972354859113693

Epoch: 5| Step: 4
Training loss: 2.152280330657959
Validation loss: 2.09465059141318

Epoch: 5| Step: 5
Training loss: 1.516460657119751
Validation loss: 2.1336803336938224

Epoch: 5| Step: 6
Training loss: 1.8485486507415771
Validation loss: 2.108856831987699

Epoch: 5| Step: 7
Training loss: 1.3679102659225464
Validation loss: 2.1340099026759467

Epoch: 5| Step: 8
Training loss: 2.644456148147583
Validation loss: 2.154989113410314

Epoch: 5| Step: 9
Training loss: 2.3845572471618652
Validation loss: 2.1133388727903366

Epoch: 5| Step: 10
Training loss: 2.5352656841278076
Validation loss: 2.135462154944738

Epoch: 5| Step: 11
Training loss: 1.31508469581604
Validation loss: 2.125547622640928

Epoch: 68| Step: 0
Training loss: 2.17118501663208
Validation loss: 2.1257677475611367

Epoch: 5| Step: 1
Training loss: 2.272167444229126
Validation loss: 2.1249623944362006

Epoch: 5| Step: 2
Training loss: 1.3626806735992432
Validation loss: 2.1421647518873215

Epoch: 5| Step: 3
Training loss: 1.9377342462539673
Validation loss: 2.1421026289463043

Epoch: 5| Step: 4
Training loss: 1.6717075109481812
Validation loss: 2.1236321528752646

Epoch: 5| Step: 5
Training loss: 2.0470519065856934
Validation loss: 2.118687396248182

Epoch: 5| Step: 6
Training loss: 2.1845760345458984
Validation loss: 2.1382314761479697

Epoch: 5| Step: 7
Training loss: 1.765281081199646
Validation loss: 2.1171892235676446

Epoch: 5| Step: 8
Training loss: 1.8879592418670654
Validation loss: 2.1384755919377008

Epoch: 5| Step: 9
Training loss: 1.9593915939331055
Validation loss: 2.1476387480894723

Epoch: 5| Step: 10
Training loss: 2.376814365386963
Validation loss: 2.0898761302232742

Epoch: 5| Step: 11
Training loss: 2.5086355209350586
Validation loss: 2.087201088666916

Epoch: 69| Step: 0
Training loss: 2.494180202484131
Validation loss: 2.1119072437286377

Epoch: 5| Step: 1
Training loss: 2.2037158012390137
Validation loss: 2.117170770963033

Epoch: 5| Step: 2
Training loss: 1.9430118799209595
Validation loss: 2.0855447153250375

Epoch: 5| Step: 3
Training loss: 1.8363450765609741
Validation loss: 2.053111046552658

Epoch: 5| Step: 4
Training loss: 1.7579253911972046
Validation loss: 2.13602215051651

Epoch: 5| Step: 5
Training loss: 1.893408179283142
Validation loss: 2.0681882152954736

Epoch: 5| Step: 6
Training loss: 1.4714686870574951
Validation loss: 2.071928476293882

Epoch: 5| Step: 7
Training loss: 2.5566725730895996
Validation loss: 2.0957516680161157

Epoch: 5| Step: 8
Training loss: 1.6277977228164673
Validation loss: 2.0589344998200736

Epoch: 5| Step: 9
Training loss: 2.4991650581359863
Validation loss: 2.090215116739273

Epoch: 5| Step: 10
Training loss: 1.5435881614685059
Validation loss: 2.045838788151741

Epoch: 5| Step: 11
Training loss: 1.0701534748077393
Validation loss: 2.0591344237327576

Epoch: 70| Step: 0
Training loss: 2.2185261249542236
Validation loss: 2.0876776973406472

Epoch: 5| Step: 1
Training loss: 1.0914690494537354
Validation loss: 2.086383874217669

Epoch: 5| Step: 2
Training loss: 2.2471160888671875
Validation loss: 2.106952046354612

Epoch: 5| Step: 3
Training loss: 2.5405335426330566
Validation loss: 2.0627176562945047

Epoch: 5| Step: 4
Training loss: 1.644325852394104
Validation loss: 2.109002391497294

Epoch: 5| Step: 5
Training loss: 1.4008492231369019
Validation loss: 2.0982536921898522

Epoch: 5| Step: 6
Training loss: 2.2944722175598145
Validation loss: 2.0746046354373298

Epoch: 5| Step: 7
Training loss: 2.1000821590423584
Validation loss: 2.11201573908329

Epoch: 5| Step: 8
Training loss: 2.440101146697998
Validation loss: 2.079829732577006

Epoch: 5| Step: 9
Training loss: 1.6838343143463135
Validation loss: 2.0981841683387756

Epoch: 5| Step: 10
Training loss: 2.025101900100708
Validation loss: 2.080468773841858

Epoch: 5| Step: 11
Training loss: 1.5810072422027588
Validation loss: 2.1136558751265206

Epoch: 71| Step: 0
Training loss: 1.700657844543457
Validation loss: 2.1074765622615814

Epoch: 5| Step: 1
Training loss: 1.4884194135665894
Validation loss: 2.1132799237966537

Epoch: 5| Step: 2
Training loss: 1.8259613513946533
Validation loss: 2.086697449286779

Epoch: 5| Step: 3
Training loss: 2.572813034057617
Validation loss: 2.1063627948363624

Epoch: 5| Step: 4
Training loss: 1.991869568824768
Validation loss: 2.086166804035505

Epoch: 5| Step: 5
Training loss: 1.818467140197754
Validation loss: 2.0843797276417413

Epoch: 5| Step: 6
Training loss: 2.363365888595581
Validation loss: 2.1089971313873925

Epoch: 5| Step: 7
Training loss: 2.0128448009490967
Validation loss: 2.0608438154061637

Epoch: 5| Step: 8
Training loss: 2.2644410133361816
Validation loss: 2.088591848810514

Epoch: 5| Step: 9
Training loss: 2.206752300262451
Validation loss: 2.157116080323855

Epoch: 5| Step: 10
Training loss: 1.6273767948150635
Validation loss: 2.1252779265244803

Epoch: 5| Step: 11
Training loss: 1.4015264511108398
Validation loss: 2.068986182411512

Epoch: 72| Step: 0
Training loss: 2.348508358001709
Validation loss: 2.0896365145842233

Epoch: 5| Step: 1
Training loss: 1.5548460483551025
Validation loss: 2.0369612077871957

Epoch: 5| Step: 2
Training loss: 1.9199352264404297
Validation loss: 2.1085446774959564

Epoch: 5| Step: 3
Training loss: 1.86783766746521
Validation loss: 2.078484912713369

Epoch: 5| Step: 4
Training loss: 1.818113923072815
Validation loss: 2.114370475212733

Epoch: 5| Step: 5
Training loss: 1.696446180343628
Validation loss: 2.081000636021296

Epoch: 5| Step: 6
Training loss: 2.771444797515869
Validation loss: 2.099829991658529

Epoch: 5| Step: 7
Training loss: 1.8467082977294922
Validation loss: 2.109023089210192

Epoch: 5| Step: 8
Training loss: 1.7867870330810547
Validation loss: 2.100081577897072

Epoch: 5| Step: 9
Training loss: 1.580312728881836
Validation loss: 2.1274386197328568

Epoch: 5| Step: 10
Training loss: 2.0183520317077637
Validation loss: 2.109062592188517

Epoch: 5| Step: 11
Training loss: 2.7167720794677734
Validation loss: 2.0804242392381034

Epoch: 73| Step: 0
Training loss: 1.5380898714065552
Validation loss: 2.109881490468979

Epoch: 5| Step: 1
Training loss: 2.2542948722839355
Validation loss: 2.110585540533066

Epoch: 5| Step: 2
Training loss: 1.919978380203247
Validation loss: 2.0623932381471

Epoch: 5| Step: 3
Training loss: 2.302168369293213
Validation loss: 2.103041951855024

Epoch: 5| Step: 4
Training loss: 1.8593025207519531
Validation loss: 2.075741042693456

Epoch: 5| Step: 5
Training loss: 2.4423882961273193
Validation loss: 2.063382734855016

Epoch: 5| Step: 6
Training loss: 2.269578456878662
Validation loss: 2.06988317767779

Epoch: 5| Step: 7
Training loss: 1.713641881942749
Validation loss: 2.1126855611801147

Epoch: 5| Step: 8
Training loss: 1.8659662008285522
Validation loss: 2.102083131670952

Epoch: 5| Step: 9
Training loss: 1.219788670539856
Validation loss: 2.1076861172914505

Epoch: 5| Step: 10
Training loss: 2.006030559539795
Validation loss: 2.101060301065445

Epoch: 5| Step: 11
Training loss: 1.0567387342453003
Validation loss: 2.100976993640264

Epoch: 74| Step: 0
Training loss: 1.9950578212738037
Validation loss: 2.100833088159561

Epoch: 5| Step: 1
Training loss: 1.4347145557403564
Validation loss: 2.1002015322446823

Epoch: 5| Step: 2
Training loss: 2.6770212650299072
Validation loss: 2.074187710881233

Epoch: 5| Step: 3
Training loss: 1.7384843826293945
Validation loss: 2.0775236934423447

Epoch: 5| Step: 4
Training loss: 1.6628786325454712
Validation loss: 2.1104577283064523

Epoch: 5| Step: 5
Training loss: 1.7219107151031494
Validation loss: 2.107936511437098

Epoch: 5| Step: 6
Training loss: 1.892523169517517
Validation loss: 2.100713143746058

Epoch: 5| Step: 7
Training loss: 2.8811450004577637
Validation loss: 2.0876897275447845

Epoch: 5| Step: 8
Training loss: 1.847730278968811
Validation loss: 2.090229252974192

Epoch: 5| Step: 9
Training loss: 1.556317687034607
Validation loss: 2.126968115568161

Epoch: 5| Step: 10
Training loss: 2.2890350818634033
Validation loss: 2.0765198916196823

Epoch: 5| Step: 11
Training loss: 1.464516043663025
Validation loss: 2.071248302857081

Epoch: 75| Step: 0
Training loss: 1.7665002346038818
Validation loss: 2.1557520230611167

Epoch: 5| Step: 1
Training loss: 2.5944151878356934
Validation loss: 2.1522399435440698

Epoch: 5| Step: 2
Training loss: 2.141990900039673
Validation loss: 2.1475181529919305

Epoch: 5| Step: 3
Training loss: 2.15372896194458
Validation loss: 2.122647081812223

Epoch: 5| Step: 4
Training loss: 2.0256686210632324
Validation loss: 2.1699168185393014

Epoch: 5| Step: 5
Training loss: 2.1113901138305664
Validation loss: 2.158875490228335

Epoch: 5| Step: 6
Training loss: 1.55274498462677
Validation loss: 2.160550902287165

Epoch: 5| Step: 7
Training loss: 1.6047096252441406
Validation loss: 2.1348156283299127

Epoch: 5| Step: 8
Training loss: 1.4781866073608398
Validation loss: 2.1507184704144797

Epoch: 5| Step: 9
Training loss: 2.3448731899261475
Validation loss: 2.111014852921168

Epoch: 5| Step: 10
Training loss: 1.9773715734481812
Validation loss: 2.1042349537213645

Epoch: 5| Step: 11
Training loss: 0.8544511795043945
Validation loss: 2.131203904747963

Epoch: 76| Step: 0
Training loss: 1.86669921875
Validation loss: 2.1031395296255746

Epoch: 5| Step: 1
Training loss: 2.186166763305664
Validation loss: 2.1769255896409354

Epoch: 5| Step: 2
Training loss: 1.465131163597107
Validation loss: 2.142002979914347

Epoch: 5| Step: 3
Training loss: 1.9901111125946045
Validation loss: 2.0992404023806253

Epoch: 5| Step: 4
Training loss: 2.1403191089630127
Validation loss: 2.0830930968125663

Epoch: 5| Step: 5
Training loss: 1.3806226253509521
Validation loss: 2.096722717086474

Epoch: 5| Step: 6
Training loss: 1.7660408020019531
Validation loss: 2.082037538290024

Epoch: 5| Step: 7
Training loss: 2.3347408771514893
Validation loss: 2.0747975558042526

Epoch: 5| Step: 8
Training loss: 2.2461423873901367
Validation loss: 2.131707285841306

Epoch: 5| Step: 9
Training loss: 1.8300552368164062
Validation loss: 2.1230366875727973

Epoch: 5| Step: 10
Training loss: 2.250992774963379
Validation loss: 2.08031756679217

Epoch: 5| Step: 11
Training loss: 1.207149863243103
Validation loss: 2.073697865009308

Epoch: 77| Step: 0
Training loss: 1.3137648105621338
Validation loss: 2.0893830557664237

Epoch: 5| Step: 1
Training loss: 1.327437400817871
Validation loss: 2.0806778371334076

Epoch: 5| Step: 2
Training loss: 1.657781958580017
Validation loss: 2.069614435235659

Epoch: 5| Step: 3
Training loss: 2.040785789489746
Validation loss: 2.128288875023524

Epoch: 5| Step: 4
Training loss: 1.9638490676879883
Validation loss: 2.1225527226924896

Epoch: 5| Step: 5
Training loss: 2.0326523780822754
Validation loss: 2.102631171544393

Epoch: 5| Step: 6
Training loss: 1.6305195093154907
Validation loss: 2.141461397210757

Epoch: 5| Step: 7
Training loss: 2.482433795928955
Validation loss: 2.124772146344185

Epoch: 5| Step: 8
Training loss: 1.721989631652832
Validation loss: 2.143173038959503

Epoch: 5| Step: 9
Training loss: 2.7699122428894043
Validation loss: 2.112582872311274

Epoch: 5| Step: 10
Training loss: 2.103128433227539
Validation loss: 2.13724847137928

Epoch: 5| Step: 11
Training loss: 2.0217032432556152
Validation loss: 2.100444739063581

Epoch: 78| Step: 0
Training loss: 1.554134488105774
Validation loss: 2.143116682767868

Epoch: 5| Step: 1
Training loss: 2.0135369300842285
Validation loss: 2.1026393671830497

Epoch: 5| Step: 2
Training loss: 1.479306936264038
Validation loss: 2.1665564427773156

Epoch: 5| Step: 3
Training loss: 1.8196284770965576
Validation loss: 2.117348442475001

Epoch: 5| Step: 4
Training loss: 1.665661096572876
Validation loss: 2.1472532947858176

Epoch: 5| Step: 5
Training loss: 2.484780788421631
Validation loss: 2.1083414802948632

Epoch: 5| Step: 6
Training loss: 2.2996456623077393
Validation loss: 2.1281307439009347

Epoch: 5| Step: 7
Training loss: 1.9400724172592163
Validation loss: 2.1322024762630463

Epoch: 5| Step: 8
Training loss: 1.639573097229004
Validation loss: 2.078473299741745

Epoch: 5| Step: 9
Training loss: 1.8046897649765015
Validation loss: 2.088642045855522

Epoch: 5| Step: 10
Training loss: 2.3270182609558105
Validation loss: 2.1544869244098663

Epoch: 5| Step: 11
Training loss: 2.933730363845825
Validation loss: 2.1592887739340463

Epoch: 79| Step: 0
Training loss: 2.371936082839966
Validation loss: 2.1549302339553833

Epoch: 5| Step: 1
Training loss: 1.8090236186981201
Validation loss: 2.1762688159942627

Epoch: 5| Step: 2
Training loss: 2.037851095199585
Validation loss: 2.126522978146871

Epoch: 5| Step: 3
Training loss: 2.2276549339294434
Validation loss: 2.1392700721820197

Epoch: 5| Step: 4
Training loss: 1.189828634262085
Validation loss: 2.094959924618403

Epoch: 5| Step: 5
Training loss: 1.9768747091293335
Validation loss: 2.1215959240992865

Epoch: 5| Step: 6
Training loss: 1.8876914978027344
Validation loss: 2.1102242966492972

Epoch: 5| Step: 7
Training loss: 2.0245144367218018
Validation loss: 2.108486091097196

Epoch: 5| Step: 8
Training loss: 1.6627002954483032
Validation loss: 2.0634089410305023

Epoch: 5| Step: 9
Training loss: 2.431675434112549
Validation loss: 2.1088232547044754

Epoch: 5| Step: 10
Training loss: 1.4458105564117432
Validation loss: 2.0584251085917153

Epoch: 5| Step: 11
Training loss: 1.8170242309570312
Validation loss: 2.143703276912371

Epoch: 80| Step: 0
Training loss: 2.079051971435547
Validation loss: 2.113667165239652

Epoch: 5| Step: 1
Training loss: 1.7974731922149658
Validation loss: 2.1177628388007483

Epoch: 5| Step: 2
Training loss: 1.822024941444397
Validation loss: 2.080719143152237

Epoch: 5| Step: 3
Training loss: 2.178809642791748
Validation loss: 2.1072545796632767

Epoch: 5| Step: 4
Training loss: 2.21931791305542
Validation loss: 2.0733945121367774

Epoch: 5| Step: 5
Training loss: 1.807563066482544
Validation loss: 2.0707681079705558

Epoch: 5| Step: 6
Training loss: 1.3531320095062256
Validation loss: 2.113993674516678

Epoch: 5| Step: 7
Training loss: 2.359940767288208
Validation loss: 2.126238152384758

Epoch: 5| Step: 8
Training loss: 1.7238247394561768
Validation loss: 2.0895736068487167

Epoch: 5| Step: 9
Training loss: 1.4992318153381348
Validation loss: 2.1260134279727936

Epoch: 5| Step: 10
Training loss: 2.2526652812957764
Validation loss: 2.1132904390494027

Epoch: 5| Step: 11
Training loss: 3.17081356048584
Validation loss: 2.1238746692736945

Epoch: 81| Step: 0
Training loss: 1.9185012578964233
Validation loss: 2.125288888812065

Epoch: 5| Step: 1
Training loss: 2.016213893890381
Validation loss: 2.132167105873426

Epoch: 5| Step: 2
Training loss: 1.7584316730499268
Validation loss: 2.1542987624804177

Epoch: 5| Step: 3
Training loss: 2.494215250015259
Validation loss: 2.142283871769905

Epoch: 5| Step: 4
Training loss: 1.9798663854599
Validation loss: 2.1194956501324973

Epoch: 5| Step: 5
Training loss: 1.7877609729766846
Validation loss: 2.1392982403437295

Epoch: 5| Step: 6
Training loss: 1.8840347528457642
Validation loss: 2.102875659863154

Epoch: 5| Step: 7
Training loss: 1.9780805110931396
Validation loss: 2.123571957151095

Epoch: 5| Step: 8
Training loss: 1.9191516637802124
Validation loss: 2.154136379559835

Epoch: 5| Step: 9
Training loss: 1.4890024662017822
Validation loss: 2.1106712420781455

Epoch: 5| Step: 10
Training loss: 1.6617906093597412
Validation loss: 2.1523573895295462

Epoch: 5| Step: 11
Training loss: 2.0020530223846436
Validation loss: 2.1396399587392807

Epoch: 82| Step: 0
Training loss: 1.7137476205825806
Validation loss: 2.1011829872926078

Epoch: 5| Step: 1
Training loss: 1.5976247787475586
Validation loss: 2.123408888777097

Epoch: 5| Step: 2
Training loss: 2.1501033306121826
Validation loss: 2.1208012302716575

Epoch: 5| Step: 3
Training loss: 1.9109814167022705
Validation loss: 2.122302452723185

Epoch: 5| Step: 4
Training loss: 2.859694480895996
Validation loss: 2.0434058705965676

Epoch: 5| Step: 5
Training loss: 2.163245439529419
Validation loss: 2.0806172440449395

Epoch: 5| Step: 6
Training loss: 1.683501958847046
Validation loss: 2.098864441116651

Epoch: 5| Step: 7
Training loss: 1.961674451828003
Validation loss: 2.0969447741905847

Epoch: 5| Step: 8
Training loss: 1.4968860149383545
Validation loss: 2.087630738814672

Epoch: 5| Step: 9
Training loss: 1.8687961101531982
Validation loss: 2.086920047799746

Epoch: 5| Step: 10
Training loss: 1.8444874286651611
Validation loss: 2.1438264648119607

Epoch: 5| Step: 11
Training loss: 2.191009044647217
Validation loss: 2.120399847626686

Epoch: 83| Step: 0
Training loss: 1.4897019863128662
Validation loss: 2.1051657646894455

Epoch: 5| Step: 1
Training loss: 1.7634685039520264
Validation loss: 2.1276042511065802

Epoch: 5| Step: 2
Training loss: 1.7392231225967407
Validation loss: 2.112793728709221

Epoch: 5| Step: 3
Training loss: 1.3383088111877441
Validation loss: 2.079433793822924

Epoch: 5| Step: 4
Training loss: 2.547968864440918
Validation loss: 2.0956581979990005

Epoch: 5| Step: 5
Training loss: 2.0889179706573486
Validation loss: 2.0979656924804053

Epoch: 5| Step: 6
Training loss: 1.9572324752807617
Validation loss: 2.119555746515592

Epoch: 5| Step: 7
Training loss: 1.5361311435699463
Validation loss: 2.1174690077702203

Epoch: 5| Step: 8
Training loss: 2.9480509757995605
Validation loss: 2.13042018810908

Epoch: 5| Step: 9
Training loss: 1.62859308719635
Validation loss: 2.106028988957405

Epoch: 5| Step: 10
Training loss: 1.494438886642456
Validation loss: 2.0767545799414315

Epoch: 5| Step: 11
Training loss: 2.587557315826416
Validation loss: 2.0887314279874167

Epoch: 84| Step: 0
Training loss: 1.4815326929092407
Validation loss: 2.1442552556594214

Epoch: 5| Step: 1
Training loss: 2.0568530559539795
Validation loss: 2.087205241123835

Epoch: 5| Step: 2
Training loss: 2.192429780960083
Validation loss: 2.116772398352623

Epoch: 5| Step: 3
Training loss: 1.5329093933105469
Validation loss: 2.099396218856176

Epoch: 5| Step: 4
Training loss: 1.9218127727508545
Validation loss: 2.1155125200748444

Epoch: 5| Step: 5
Training loss: 1.8185008764266968
Validation loss: 2.1319466680288315

Epoch: 5| Step: 6
Training loss: 1.610020637512207
Validation loss: 2.1319192747275033

Epoch: 5| Step: 7
Training loss: 2.006679058074951
Validation loss: 2.0970791776974997

Epoch: 5| Step: 8
Training loss: 2.0883469581604004
Validation loss: 2.0854097455739975

Epoch: 5| Step: 9
Training loss: 1.3973534107208252
Validation loss: 2.1261546164751053

Epoch: 5| Step: 10
Training loss: 2.6292262077331543
Validation loss: 2.0980280488729477

Epoch: 5| Step: 11
Training loss: 2.4228739738464355
Validation loss: 2.1208516508340836

Epoch: 85| Step: 0
Training loss: 1.4675904512405396
Validation loss: 2.101419727007548

Epoch: 5| Step: 1
Training loss: 2.0039544105529785
Validation loss: 2.114400620261828

Epoch: 5| Step: 2
Training loss: 1.8453681468963623
Validation loss: 2.1350089261929193

Epoch: 5| Step: 3
Training loss: 1.5140715837478638
Validation loss: 2.0818592260281243

Epoch: 5| Step: 4
Training loss: 1.8414446115493774
Validation loss: 2.152254725495974

Epoch: 5| Step: 5
Training loss: 1.7532804012298584
Validation loss: 2.0901075899600983

Epoch: 5| Step: 6
Training loss: 1.9739116430282593
Validation loss: 2.110262950261434

Epoch: 5| Step: 7
Training loss: 1.764890432357788
Validation loss: 2.116712619860967

Epoch: 5| Step: 8
Training loss: 1.751245141029358
Validation loss: 2.145869255065918

Epoch: 5| Step: 9
Training loss: 2.4365415573120117
Validation loss: 2.1341153234243393

Epoch: 5| Step: 10
Training loss: 2.632690906524658
Validation loss: 2.142590860525767

Epoch: 5| Step: 11
Training loss: 0.7251007556915283
Validation loss: 2.1344509621461234

Epoch: 86| Step: 0
Training loss: 2.2669317722320557
Validation loss: 2.1102058241764703

Epoch: 5| Step: 1
Training loss: 2.3505923748016357
Validation loss: 2.0944440215826035

Epoch: 5| Step: 2
Training loss: 2.160198926925659
Validation loss: 2.0928764939308167

Epoch: 5| Step: 3
Training loss: 1.3380253314971924
Validation loss: 2.116563305258751

Epoch: 5| Step: 4
Training loss: 2.084998846054077
Validation loss: 2.0881520807743073

Epoch: 5| Step: 5
Training loss: 1.6856826543807983
Validation loss: 2.128166655699412

Epoch: 5| Step: 6
Training loss: 1.6921660900115967
Validation loss: 2.0638699332873025

Epoch: 5| Step: 7
Training loss: 2.6032862663269043
Validation loss: 2.0944454669952393

Epoch: 5| Step: 8
Training loss: 1.4376147985458374
Validation loss: 2.1441300362348557

Epoch: 5| Step: 9
Training loss: 1.1240108013153076
Validation loss: 2.1147572745879493

Epoch: 5| Step: 10
Training loss: 2.1402664184570312
Validation loss: 2.114781156182289

Epoch: 5| Step: 11
Training loss: 4.347530364990234
Validation loss: 2.1405935933192572

Epoch: 87| Step: 0
Training loss: 1.5016018152236938
Validation loss: 2.1388695935408273

Epoch: 5| Step: 1
Training loss: 1.4440276622772217
Validation loss: 2.131566653649012

Epoch: 5| Step: 2
Training loss: 1.7941806316375732
Validation loss: 2.1294151892264686

Epoch: 5| Step: 3
Training loss: 2.1011226177215576
Validation loss: 2.093516399463018

Epoch: 5| Step: 4
Training loss: 1.9552170038223267
Validation loss: 2.1167632192373276

Epoch: 5| Step: 5
Training loss: 2.6016745567321777
Validation loss: 2.1345841785271964

Epoch: 5| Step: 6
Training loss: 1.8739197254180908
Validation loss: 2.1766863067944846

Epoch: 5| Step: 7
Training loss: 1.8370864391326904
Validation loss: 2.1615554889043174

Epoch: 5| Step: 8
Training loss: 2.047128915786743
Validation loss: 2.175055518746376

Epoch: 5| Step: 9
Training loss: 1.8597371578216553
Validation loss: 2.1244974434375763

Epoch: 5| Step: 10
Training loss: 2.341972827911377
Validation loss: 2.1257627805074057

Epoch: 5| Step: 11
Training loss: 1.6701830625534058
Validation loss: 2.0894316335519156

Epoch: 88| Step: 0
Training loss: 1.5720800161361694
Validation loss: 2.098282883564631

Epoch: 5| Step: 1
Training loss: 2.5928640365600586
Validation loss: 2.1284180829922357

Epoch: 5| Step: 2
Training loss: 2.2174417972564697
Validation loss: 2.074008340636889

Epoch: 5| Step: 3
Training loss: 1.5835680961608887
Validation loss: 2.120757778485616

Epoch: 5| Step: 4
Training loss: 2.0231823921203613
Validation loss: 2.138263151049614

Epoch: 5| Step: 5
Training loss: 1.9856131076812744
Validation loss: 2.107808063427607

Epoch: 5| Step: 6
Training loss: 1.7480831146240234
Validation loss: 2.089997867743174

Epoch: 5| Step: 7
Training loss: 1.4942009449005127
Validation loss: 2.1282195150852203

Epoch: 5| Step: 8
Training loss: 1.92574942111969
Validation loss: 2.133537689844767

Epoch: 5| Step: 9
Training loss: 1.5538930892944336
Validation loss: 2.0883618940909705

Epoch: 5| Step: 10
Training loss: 2.364501714706421
Validation loss: 2.106527010599772

Epoch: 5| Step: 11
Training loss: 0.995858907699585
Validation loss: 2.1258335510889688

Epoch: 89| Step: 0
Training loss: 2.263338565826416
Validation loss: 2.116122747461001

Epoch: 5| Step: 1
Training loss: 2.0690670013427734
Validation loss: 2.0712543527285256

Epoch: 5| Step: 2
Training loss: 2.1471621990203857
Validation loss: 2.1460452179114022

Epoch: 5| Step: 3
Training loss: 1.3439794778823853
Validation loss: 2.132690022389094

Epoch: 5| Step: 4
Training loss: 1.5868173837661743
Validation loss: 2.141258825858434

Epoch: 5| Step: 5
Training loss: 1.9497013092041016
Validation loss: 2.134347975254059

Epoch: 5| Step: 6
Training loss: 2.107239246368408
Validation loss: 2.1282809227705

Epoch: 5| Step: 7
Training loss: 2.2295899391174316
Validation loss: 2.176907390356064

Epoch: 5| Step: 8
Training loss: 1.9151990413665771
Validation loss: 2.1297921737035117

Epoch: 5| Step: 9
Training loss: 1.5259770154953003
Validation loss: 2.0873417307933173

Epoch: 5| Step: 10
Training loss: 1.555095911026001
Validation loss: 2.136021137237549

Epoch: 5| Step: 11
Training loss: 2.81721830368042
Validation loss: 2.131412918368975

Epoch: 90| Step: 0
Training loss: 2.2585532665252686
Validation loss: 2.113826056321462

Epoch: 5| Step: 1
Training loss: 2.907435894012451
Validation loss: 2.1219343543052673

Epoch: 5| Step: 2
Training loss: 1.7484668493270874
Validation loss: 2.142813101410866

Epoch: 5| Step: 3
Training loss: 2.0276036262512207
Validation loss: 2.0935466289520264

Epoch: 5| Step: 4
Training loss: 1.2996184825897217
Validation loss: 2.1151123046875

Epoch: 5| Step: 5
Training loss: 2.3422927856445312
Validation loss: 2.1266523748636246

Epoch: 5| Step: 6
Training loss: 1.9122755527496338
Validation loss: 2.1467246959606805

Epoch: 5| Step: 7
Training loss: 1.673497200012207
Validation loss: 2.086996083458265

Epoch: 5| Step: 8
Training loss: 1.3935867547988892
Validation loss: 2.108066608508428

Epoch: 5| Step: 9
Training loss: 1.1963794231414795
Validation loss: 2.1257585485776267

Epoch: 5| Step: 10
Training loss: 2.0928831100463867
Validation loss: 2.1239982744057975

Epoch: 5| Step: 11
Training loss: 0.7626497745513916
Validation loss: 2.162851870059967

Epoch: 91| Step: 0
Training loss: 1.6245931386947632
Validation loss: 2.1669985105594

Epoch: 5| Step: 1
Training loss: 1.7665328979492188
Validation loss: 2.130088205138842

Epoch: 5| Step: 2
Training loss: 2.169343948364258
Validation loss: 2.1468789478143058

Epoch: 5| Step: 3
Training loss: 1.8131697177886963
Validation loss: 2.1315697878599167

Epoch: 5| Step: 4
Training loss: 1.4529144763946533
Validation loss: 2.1218153685331345

Epoch: 5| Step: 5
Training loss: 1.8595285415649414
Validation loss: 2.106459230184555

Epoch: 5| Step: 6
Training loss: 1.96160089969635
Validation loss: 2.1316446512937546

Epoch: 5| Step: 7
Training loss: 2.2965242862701416
Validation loss: 2.0901224464178085

Epoch: 5| Step: 8
Training loss: 1.9741771221160889
Validation loss: 2.1233459413051605

Epoch: 5| Step: 9
Training loss: 1.5953147411346436
Validation loss: 2.080485681692759

Epoch: 5| Step: 10
Training loss: 2.1422624588012695
Validation loss: 2.0882712403933206

Epoch: 5| Step: 11
Training loss: 3.136845111846924
Validation loss: 2.110126261909803

Epoch: 92| Step: 0
Training loss: 1.1759262084960938
Validation loss: 2.101745535929998

Epoch: 5| Step: 1
Training loss: 1.6691917181015015
Validation loss: 2.1364302585522332

Epoch: 5| Step: 2
Training loss: 2.036726713180542
Validation loss: 2.0992786437273026

Epoch: 5| Step: 3
Training loss: 1.5537351369857788
Validation loss: 2.1020325223604837

Epoch: 5| Step: 4
Training loss: 1.447163462638855
Validation loss: 2.1475511143604913

Epoch: 5| Step: 5
Training loss: 2.204343318939209
Validation loss: 2.0822182993094125

Epoch: 5| Step: 6
Training loss: 2.045759439468384
Validation loss: 2.106549804409345

Epoch: 5| Step: 7
Training loss: 2.269284725189209
Validation loss: 2.1643716792265573

Epoch: 5| Step: 8
Training loss: 1.1382149457931519
Validation loss: 2.145052527387937

Epoch: 5| Step: 9
Training loss: 2.5334837436676025
Validation loss: 2.1474680403868356

Epoch: 5| Step: 10
Training loss: 2.3376336097717285
Validation loss: 2.1272963931163154

Epoch: 5| Step: 11
Training loss: 3.3941893577575684
Validation loss: 2.156081805626551

Epoch: 93| Step: 0
Training loss: 1.9396721124649048
Validation loss: 2.1430559704701104

Epoch: 5| Step: 1
Training loss: 1.6465656757354736
Validation loss: 2.119634985923767

Epoch: 5| Step: 2
Training loss: 1.456789255142212
Validation loss: 2.1014914264281592

Epoch: 5| Step: 3
Training loss: 1.0401175022125244
Validation loss: 2.1624393860499063

Epoch: 5| Step: 4
Training loss: 1.7489324808120728
Validation loss: 2.130773658553759

Epoch: 5| Step: 5
Training loss: 1.5915374755859375
Validation loss: 2.1255551973978677

Epoch: 5| Step: 6
Training loss: 2.625073194503784
Validation loss: 2.120498165488243

Epoch: 5| Step: 7
Training loss: 2.2737650871276855
Validation loss: 2.112833797931671

Epoch: 5| Step: 8
Training loss: 1.8543964624404907
Validation loss: 2.1066584239403405

Epoch: 5| Step: 9
Training loss: 1.703956961631775
Validation loss: 2.080144246419271

Epoch: 5| Step: 10
Training loss: 2.094888925552368
Validation loss: 2.124490107099215

Epoch: 5| Step: 11
Training loss: 2.6416268348693848
Validation loss: 2.0543044408162436

Epoch: 94| Step: 0
Training loss: 2.4162821769714355
Validation loss: 2.1031038413445153

Epoch: 5| Step: 1
Training loss: 1.99740731716156
Validation loss: 2.130520522594452

Epoch: 5| Step: 2
Training loss: 2.235842704772949
Validation loss: 2.128975282112757

Epoch: 5| Step: 3
Training loss: 1.7362391948699951
Validation loss: 2.097404678662618

Epoch: 5| Step: 4
Training loss: 1.9365230798721313
Validation loss: 2.1348442236582437

Epoch: 5| Step: 5
Training loss: 1.6062450408935547
Validation loss: 2.1194281627734504

Epoch: 5| Step: 6
Training loss: 1.8888981342315674
Validation loss: 2.1125815014044442

Epoch: 5| Step: 7
Training loss: 1.5926029682159424
Validation loss: 2.0946386059125266

Epoch: 5| Step: 8
Training loss: 1.9426193237304688
Validation loss: 2.0857448677221933

Epoch: 5| Step: 9
Training loss: 1.809274673461914
Validation loss: 2.111761803428332

Epoch: 5| Step: 10
Training loss: 1.6521590948104858
Validation loss: 2.112698102990786

Epoch: 5| Step: 11
Training loss: 0.4066401720046997
Validation loss: 2.1416768779357276

Epoch: 95| Step: 0
Training loss: 1.8423900604248047
Validation loss: 2.1592088689406714

Epoch: 5| Step: 1
Training loss: 2.1359000205993652
Validation loss: 2.1397590190172195

Epoch: 5| Step: 2
Training loss: 2.3389346599578857
Validation loss: 2.096597875157992

Epoch: 5| Step: 3
Training loss: 1.758934736251831
Validation loss: 2.090644230445226

Epoch: 5| Step: 4
Training loss: 1.6157251596450806
Validation loss: 2.1143066038688025

Epoch: 5| Step: 5
Training loss: 2.4908525943756104
Validation loss: 2.0977082351843515

Epoch: 5| Step: 6
Training loss: 1.9159704446792603
Validation loss: 2.113133271535238

Epoch: 5| Step: 7
Training loss: 1.3169525861740112
Validation loss: 2.131240258614222

Epoch: 5| Step: 8
Training loss: 1.563992977142334
Validation loss: 2.0895099143187204

Epoch: 5| Step: 9
Training loss: 1.8086988925933838
Validation loss: 2.1420868138472238

Epoch: 5| Step: 10
Training loss: 1.563542366027832
Validation loss: 2.108554338415464

Epoch: 5| Step: 11
Training loss: 1.5655230283737183
Validation loss: 2.096104174852371

Epoch: 96| Step: 0
Training loss: 1.592137098312378
Validation loss: 2.149553894996643

Epoch: 5| Step: 1
Training loss: 1.7695751190185547
Validation loss: 2.162134349346161

Epoch: 5| Step: 2
Training loss: 2.026686906814575
Validation loss: 2.1682219008604684

Epoch: 5| Step: 3
Training loss: 2.269956350326538
Validation loss: 2.1763930519421897

Epoch: 5| Step: 4
Training loss: 1.7515723705291748
Validation loss: 2.151322692632675

Epoch: 5| Step: 5
Training loss: 2.2059779167175293
Validation loss: 2.127799555659294

Epoch: 5| Step: 6
Training loss: 2.1147875785827637
Validation loss: 2.166793038447698

Epoch: 5| Step: 7
Training loss: 1.9729259014129639
Validation loss: 2.1815362771352134

Epoch: 5| Step: 8
Training loss: 1.7016137838363647
Validation loss: 2.182598049441973

Epoch: 5| Step: 9
Training loss: 1.639444351196289
Validation loss: 2.1818765501181283

Epoch: 5| Step: 10
Training loss: 1.5404374599456787
Validation loss: 2.0905801306168237

Epoch: 5| Step: 11
Training loss: 2.227091073989868
Validation loss: 2.1235649238030114

Epoch: 97| Step: 0
Training loss: 2.266737461090088
Validation loss: 2.139742841323217

Epoch: 5| Step: 1
Training loss: 1.4194996356964111
Validation loss: 2.0927126904328666

Epoch: 5| Step: 2
Training loss: 1.4487818479537964
Validation loss: 2.1010855038960776

Epoch: 5| Step: 3
Training loss: 1.9027057886123657
Validation loss: 2.076469456156095

Epoch: 5| Step: 4
Training loss: 1.6453437805175781
Validation loss: 2.1128570834795632

Epoch: 5| Step: 5
Training loss: 2.157313108444214
Validation loss: 2.1144973586002984

Epoch: 5| Step: 6
Training loss: 2.111057758331299
Validation loss: 2.092400679985682

Epoch: 5| Step: 7
Training loss: 1.6456207036972046
Validation loss: 2.1016592780749

Epoch: 5| Step: 8
Training loss: 2.0915098190307617
Validation loss: 2.185732583204905

Epoch: 5| Step: 9
Training loss: 1.660678505897522
Validation loss: 2.113828589518865

Epoch: 5| Step: 10
Training loss: 2.042739152908325
Validation loss: 2.0957170724868774

Epoch: 5| Step: 11
Training loss: 1.231675624847412
Validation loss: 2.0898344665765762

Epoch: 98| Step: 0
Training loss: 2.381901264190674
Validation loss: 2.104471723238627

Epoch: 5| Step: 1
Training loss: 1.7398945093154907
Validation loss: 2.1352394372224808

Epoch: 5| Step: 2
Training loss: 1.0856174230575562
Validation loss: 2.17853090663751

Epoch: 5| Step: 3
Training loss: 1.8601850271224976
Validation loss: 2.145645558834076

Epoch: 5| Step: 4
Training loss: 2.270463466644287
Validation loss: 2.2097076127926507

Epoch: 5| Step: 5
Training loss: 1.5609689950942993
Validation loss: 2.2213346660137177

Epoch: 5| Step: 6
Training loss: 2.4416491985321045
Validation loss: 2.2631706347068152

Epoch: 5| Step: 7
Training loss: 1.888793706893921
Validation loss: 2.1707810262839

Epoch: 5| Step: 8
Training loss: 1.363560438156128
Validation loss: 2.1696738600730896

Epoch: 5| Step: 9
Training loss: 2.490661859512329
Validation loss: 2.1469023724397025

Epoch: 5| Step: 10
Training loss: 1.4643144607543945
Validation loss: 2.1536340018113456

Epoch: 5| Step: 11
Training loss: 1.255814552307129
Validation loss: 2.1615600834290185

Epoch: 99| Step: 0
Training loss: 1.333862066268921
Validation loss: 2.105745871861776

Epoch: 5| Step: 1
Training loss: 1.4686728715896606
Validation loss: 2.1695807178815207

Epoch: 5| Step: 2
Training loss: 2.10512113571167
Validation loss: 2.1104045857985816

Epoch: 5| Step: 3
Training loss: 2.304135799407959
Validation loss: 2.108911102016767

Epoch: 5| Step: 4
Training loss: 1.6903812885284424
Validation loss: 2.130108579993248

Epoch: 5| Step: 5
Training loss: 1.3720998764038086
Validation loss: 2.1328854660193124

Epoch: 5| Step: 6
Training loss: 2.2863192558288574
Validation loss: 2.1125812580188117

Epoch: 5| Step: 7
Training loss: 1.7383430004119873
Validation loss: 2.112607623140017

Epoch: 5| Step: 8
Training loss: 1.3703172206878662
Validation loss: 2.0799793154001236

Epoch: 5| Step: 9
Training loss: 2.178555965423584
Validation loss: 2.1051285713911057

Epoch: 5| Step: 10
Training loss: 2.5393078327178955
Validation loss: 2.1201083064079285

Epoch: 5| Step: 11
Training loss: 2.197941541671753
Validation loss: 2.1100612779458365

Epoch: 100| Step: 0
Training loss: 1.7879959344863892
Validation loss: 2.1035082091887793

Epoch: 5| Step: 1
Training loss: 2.1890878677368164
Validation loss: 2.080331658323606

Epoch: 5| Step: 2
Training loss: 1.744142770767212
Validation loss: 2.142052789529165

Epoch: 5| Step: 3
Training loss: 2.1712169647216797
Validation loss: 2.146066019932429

Epoch: 5| Step: 4
Training loss: 1.6276264190673828
Validation loss: 2.1980184515317283

Epoch: 5| Step: 5
Training loss: 1.5731292963027954
Validation loss: 2.1732326795657477

Epoch: 5| Step: 6
Training loss: 1.89712655544281
Validation loss: 2.193906764189402

Epoch: 5| Step: 7
Training loss: 1.916766881942749
Validation loss: 2.1108021984497705

Epoch: 5| Step: 8
Training loss: 1.8486535549163818
Validation loss: 2.1403477440277734

Epoch: 5| Step: 9
Training loss: 1.7091877460479736
Validation loss: 2.1193451484044394

Epoch: 5| Step: 10
Training loss: 1.552626371383667
Validation loss: 2.095951184630394

Epoch: 5| Step: 11
Training loss: 1.7514692544937134
Validation loss: 2.0988790740569434

Epoch: 101| Step: 0
Training loss: 2.570509195327759
Validation loss: 2.059553196032842

Epoch: 5| Step: 1
Training loss: 1.8038623332977295
Validation loss: 2.089031919836998

Epoch: 5| Step: 2
Training loss: 1.8892501592636108
Validation loss: 2.11975035071373

Epoch: 5| Step: 3
Training loss: 1.1949687004089355
Validation loss: 2.1111967265605927

Epoch: 5| Step: 4
Training loss: 2.0192418098449707
Validation loss: 2.0869813412427902

Epoch: 5| Step: 5
Training loss: 1.6764335632324219
Validation loss: 2.1068131426970163

Epoch: 5| Step: 6
Training loss: 2.3598694801330566
Validation loss: 2.128448153535525

Epoch: 5| Step: 7
Training loss: 1.5746476650238037
Validation loss: 2.094054867823919

Epoch: 5| Step: 8
Training loss: 1.6980829238891602
Validation loss: 2.1262678305308023

Epoch: 5| Step: 9
Training loss: 1.3467351198196411
Validation loss: 2.149678741892179

Epoch: 5| Step: 10
Training loss: 1.9055267572402954
Validation loss: 2.1256763339042664

Epoch: 5| Step: 11
Training loss: 2.3286995887756348
Validation loss: 2.120319123069445

Epoch: 102| Step: 0
Training loss: 1.5053679943084717
Validation loss: 2.1325204571088157

Epoch: 5| Step: 1
Training loss: 1.4047213792800903
Validation loss: 2.1091308196385703

Epoch: 5| Step: 2
Training loss: 1.8365293741226196
Validation loss: 2.11057056983312

Epoch: 5| Step: 3
Training loss: 1.8458547592163086
Validation loss: 2.120966225862503

Epoch: 5| Step: 4
Training loss: 2.0689234733581543
Validation loss: 2.128606448570887

Epoch: 5| Step: 5
Training loss: 1.866227388381958
Validation loss: 2.090828314423561

Epoch: 5| Step: 6
Training loss: 1.4314813613891602
Validation loss: 2.086311255892118

Epoch: 5| Step: 7
Training loss: 1.9335014820098877
Validation loss: 2.0715818802515664

Epoch: 5| Step: 8
Training loss: 2.371711015701294
Validation loss: 2.120037868618965

Epoch: 5| Step: 9
Training loss: 2.019455671310425
Validation loss: 2.127959822614988

Epoch: 5| Step: 10
Training loss: 1.8515522480010986
Validation loss: 2.1159681578477225

Epoch: 5| Step: 11
Training loss: 1.4378962516784668
Validation loss: 2.12187567849954

Epoch: 103| Step: 0
Training loss: 1.754920244216919
Validation loss: 2.122893810272217

Epoch: 5| Step: 1
Training loss: 1.4895694255828857
Validation loss: 2.1426720221837363

Epoch: 5| Step: 2
Training loss: 1.630279541015625
Validation loss: 2.158209611972173

Epoch: 5| Step: 3
Training loss: 1.7837274074554443
Validation loss: 2.1680592050155005

Epoch: 5| Step: 4
Training loss: 1.9711097478866577
Validation loss: 2.2043340702851615

Epoch: 5| Step: 5
Training loss: 1.5702072381973267
Validation loss: 2.175742675860723

Epoch: 5| Step: 6
Training loss: 1.9623782634735107
Validation loss: 2.26235963900884

Epoch: 5| Step: 7
Training loss: 1.6776540279388428
Validation loss: 2.2199203968048096

Epoch: 5| Step: 8
Training loss: 2.4318182468414307
Validation loss: 2.142570490638415

Epoch: 5| Step: 9
Training loss: 2.451615810394287
Validation loss: 2.1883720556894937

Epoch: 5| Step: 10
Training loss: 1.4748497009277344
Validation loss: 2.1332187354564667

Epoch: 5| Step: 11
Training loss: 2.4193062782287598
Validation loss: 2.1656258006890616

Epoch: 104| Step: 0
Training loss: 1.8085682392120361
Validation loss: 2.182308539748192

Epoch: 5| Step: 1
Training loss: 1.2060778141021729
Validation loss: 2.105991085370382

Epoch: 5| Step: 2
Training loss: 2.1676321029663086
Validation loss: 2.093828891714414

Epoch: 5| Step: 3
Training loss: 1.4836242198944092
Validation loss: 2.1437977800766626

Epoch: 5| Step: 4
Training loss: 1.5928874015808105
Validation loss: 2.1302187790473304

Epoch: 5| Step: 5
Training loss: 1.9993398189544678
Validation loss: 2.121254945794741

Epoch: 5| Step: 6
Training loss: 1.6441237926483154
Validation loss: 2.1363617380460105

Epoch: 5| Step: 7
Training loss: 1.727132797241211
Validation loss: 2.132529397805532

Epoch: 5| Step: 8
Training loss: 2.314249277114868
Validation loss: 2.1098676224549613

Epoch: 5| Step: 9
Training loss: 1.8912988901138306
Validation loss: 2.0889002134402594

Epoch: 5| Step: 10
Training loss: 2.4742233753204346
Validation loss: 2.190478344758352

Epoch: 5| Step: 11
Training loss: 0.9382455348968506
Validation loss: 2.135914519429207

Epoch: 105| Step: 0
Training loss: 1.6886619329452515
Validation loss: 2.109293043613434

Epoch: 5| Step: 1
Training loss: 2.095496892929077
Validation loss: 2.1431266317764917

Epoch: 5| Step: 2
Training loss: 2.1000475883483887
Validation loss: 2.1651128977537155

Epoch: 5| Step: 3
Training loss: 1.7554069757461548
Validation loss: 2.1290411899487176

Epoch: 5| Step: 4
Training loss: 2.2115542888641357
Validation loss: 2.186902398864428

Epoch: 5| Step: 5
Training loss: 2.0440917015075684
Validation loss: 2.2239166647195816

Epoch: 5| Step: 6
Training loss: 1.6342881917953491
Validation loss: 2.1739321798086166

Epoch: 5| Step: 7
Training loss: 1.6199867725372314
Validation loss: 2.1790867348512015

Epoch: 5| Step: 8
Training loss: 1.8742005825042725
Validation loss: 2.170626158515612

Epoch: 5| Step: 9
Training loss: 1.3280224800109863
Validation loss: 2.1654192904631295

Epoch: 5| Step: 10
Training loss: 1.6999610662460327
Validation loss: 2.185310035943985

Epoch: 5| Step: 11
Training loss: 1.2215449810028076
Validation loss: 2.117513502637545

Epoch: 106| Step: 0
Training loss: 1.7470670938491821
Validation loss: 2.081428458293279

Epoch: 5| Step: 1
Training loss: 1.5188404321670532
Validation loss: 2.1030658980210624

Epoch: 5| Step: 2
Training loss: 2.3158886432647705
Validation loss: 2.119221975406011

Epoch: 5| Step: 3
Training loss: 1.5276260375976562
Validation loss: 2.1204447746276855

Epoch: 5| Step: 4
Training loss: 1.4891541004180908
Validation loss: 2.084496965010961

Epoch: 5| Step: 5
Training loss: 1.4600694179534912
Validation loss: 2.073069011171659

Epoch: 5| Step: 6
Training loss: 2.228436231613159
Validation loss: 2.125295261542002

Epoch: 5| Step: 7
Training loss: 1.8328564167022705
Validation loss: 2.161957601706187

Epoch: 5| Step: 8
Training loss: 2.3382809162139893
Validation loss: 2.0831564168135324

Epoch: 5| Step: 9
Training loss: 1.8714519739151
Validation loss: 2.0690135608116784

Epoch: 5| Step: 10
Training loss: 1.5171914100646973
Validation loss: 2.133429244160652

Epoch: 5| Step: 11
Training loss: 3.63553786277771
Validation loss: 2.175367926557859

Epoch: 107| Step: 0
Training loss: 1.5552916526794434
Validation loss: 2.1714293708403907

Epoch: 5| Step: 1
Training loss: 1.50662100315094
Validation loss: 2.0934651593367257

Epoch: 5| Step: 2
Training loss: 1.5862665176391602
Validation loss: 2.1438880562782288

Epoch: 5| Step: 3
Training loss: 2.1396923065185547
Validation loss: 2.2406302640835443

Epoch: 5| Step: 4
Training loss: 1.8182862997055054
Validation loss: 2.238083908955256

Epoch: 5| Step: 5
Training loss: 2.1016509532928467
Validation loss: 2.235905036330223

Epoch: 5| Step: 6
Training loss: 2.1166138648986816
Validation loss: 2.2114003002643585

Epoch: 5| Step: 7
Training loss: 2.133701801300049
Validation loss: 2.167574574549993

Epoch: 5| Step: 8
Training loss: 2.1281790733337402
Validation loss: 2.1324148873488107

Epoch: 5| Step: 9
Training loss: 1.4973971843719482
Validation loss: 2.103701720635096

Epoch: 5| Step: 10
Training loss: 1.7625668048858643
Validation loss: 2.1576540817817054

Epoch: 5| Step: 11
Training loss: 0.6657219529151917
Validation loss: 2.0998380730549493

Epoch: 108| Step: 0
Training loss: 1.8537805080413818
Validation loss: 2.1826452364524207

Epoch: 5| Step: 1
Training loss: 1.7806079387664795
Validation loss: 2.1271275927623114

Epoch: 5| Step: 2
Training loss: 2.2575197219848633
Validation loss: 2.1592546800772348

Epoch: 5| Step: 3
Training loss: 2.2863616943359375
Validation loss: 2.094282418489456

Epoch: 5| Step: 4
Training loss: 1.3525311946868896
Validation loss: 2.119656672080358

Epoch: 5| Step: 5
Training loss: 1.2492717504501343
Validation loss: 2.0964365800221763

Epoch: 5| Step: 6
Training loss: 2.097489595413208
Validation loss: 2.1375292291243873

Epoch: 5| Step: 7
Training loss: 1.9195200204849243
Validation loss: 2.1465266197919846

Epoch: 5| Step: 8
Training loss: 1.8316551446914673
Validation loss: 2.136380508542061

Epoch: 5| Step: 9
Training loss: 1.427448034286499
Validation loss: 2.173660308122635

Epoch: 5| Step: 10
Training loss: 1.7829205989837646
Validation loss: 2.1274171670277915

Epoch: 5| Step: 11
Training loss: 1.9804052114486694
Validation loss: 2.179203743735949

Epoch: 109| Step: 0
Training loss: 1.531088948249817
Validation loss: 2.1920181612173715

Epoch: 5| Step: 1
Training loss: 1.7716881036758423
Validation loss: 2.1908209770917892

Epoch: 5| Step: 2
Training loss: 1.74606454372406
Validation loss: 2.181834653019905

Epoch: 5| Step: 3
Training loss: 1.8295414447784424
Validation loss: 2.165090342362722

Epoch: 5| Step: 4
Training loss: 1.8961061239242554
Validation loss: 2.1811148871978125

Epoch: 5| Step: 5
Training loss: 1.8218491077423096
Validation loss: 2.1806285430987677

Epoch: 5| Step: 6
Training loss: 1.939064383506775
Validation loss: 2.137099971373876

Epoch: 5| Step: 7
Training loss: 1.5323673486709595
Validation loss: 2.0927912245194116

Epoch: 5| Step: 8
Training loss: 1.931783676147461
Validation loss: 2.1204586724440255

Epoch: 5| Step: 9
Training loss: 1.5405288934707642
Validation loss: 2.1317047625780106

Epoch: 5| Step: 10
Training loss: 1.6516380310058594
Validation loss: 2.134733334183693

Epoch: 5| Step: 11
Training loss: 2.8136653900146484
Validation loss: 2.159281318386396

Epoch: 110| Step: 0
Training loss: 2.537811279296875
Validation loss: 2.1496994296709695

Epoch: 5| Step: 1
Training loss: 1.8859663009643555
Validation loss: 2.1581230610609055

Epoch: 5| Step: 2
Training loss: 1.3929414749145508
Validation loss: 2.1481762131055198

Epoch: 5| Step: 3
Training loss: 1.860512137413025
Validation loss: 2.15633953611056

Epoch: 5| Step: 4
Training loss: 1.8502041101455688
Validation loss: 2.126059114933014

Epoch: 5| Step: 5
Training loss: 1.6373870372772217
Validation loss: 2.117694929242134

Epoch: 5| Step: 6
Training loss: 1.3434789180755615
Validation loss: 2.169646476705869

Epoch: 5| Step: 7
Training loss: 1.8416904211044312
Validation loss: 2.1528619279464087

Epoch: 5| Step: 8
Training loss: 1.9280259609222412
Validation loss: 2.122604380051295

Epoch: 5| Step: 9
Training loss: 1.752910852432251
Validation loss: 2.1352583120266595

Epoch: 5| Step: 10
Training loss: 1.6242735385894775
Validation loss: 2.113177239894867

Epoch: 5| Step: 11
Training loss: 1.570267677307129
Validation loss: 2.1757005900144577

Epoch: 111| Step: 0
Training loss: 1.418007493019104
Validation loss: 2.150122116009394

Epoch: 5| Step: 1
Training loss: 2.2125988006591797
Validation loss: 2.1235943138599396

Epoch: 5| Step: 2
Training loss: 1.6467015743255615
Validation loss: 2.103165184458097

Epoch: 5| Step: 3
Training loss: 1.4352800846099854
Validation loss: 2.137954776485761

Epoch: 5| Step: 4
Training loss: 2.1316776275634766
Validation loss: 2.120831514398257

Epoch: 5| Step: 5
Training loss: 1.2352333068847656
Validation loss: 2.1295163879791894

Epoch: 5| Step: 6
Training loss: 1.8854347467422485
Validation loss: 2.0892569621404014

Epoch: 5| Step: 7
Training loss: 2.1805241107940674
Validation loss: 2.146262059609095

Epoch: 5| Step: 8
Training loss: 1.9507955312728882
Validation loss: 2.115186095237732

Epoch: 5| Step: 9
Training loss: 1.9082326889038086
Validation loss: 2.110338235894839

Epoch: 5| Step: 10
Training loss: 1.705137014389038
Validation loss: 2.1436227510372796

Epoch: 5| Step: 11
Training loss: 1.5402030944824219
Validation loss: 2.1496914525826774

Epoch: 112| Step: 0
Training loss: 1.7683556079864502
Validation loss: 2.1475336651007333

Epoch: 5| Step: 1
Training loss: 1.1788363456726074
Validation loss: 2.2103547751903534

Epoch: 5| Step: 2
Training loss: 2.3754448890686035
Validation loss: 2.1235204488039017

Epoch: 5| Step: 3
Training loss: 2.2578094005584717
Validation loss: 2.2026250759760537

Epoch: 5| Step: 4
Training loss: 1.655160903930664
Validation loss: 2.2075528701146445

Epoch: 5| Step: 5
Training loss: 1.6443580389022827
Validation loss: 2.170782208442688

Epoch: 5| Step: 6
Training loss: 1.5697115659713745
Validation loss: 2.1921098132928214

Epoch: 5| Step: 7
Training loss: 1.5863398313522339
Validation loss: 2.2289579113324485

Epoch: 5| Step: 8
Training loss: 2.0833778381347656
Validation loss: 2.2094291150569916

Epoch: 5| Step: 9
Training loss: 1.4747084379196167
Validation loss: 2.1617561181386313

Epoch: 5| Step: 10
Training loss: 2.0236639976501465
Validation loss: 2.2092274874448776

Epoch: 5| Step: 11
Training loss: 1.0739108324050903
Validation loss: 2.1283604005972543

Epoch: 113| Step: 0
Training loss: 1.1996591091156006
Validation loss: 2.1609689791997275

Epoch: 5| Step: 1
Training loss: 1.4665114879608154
Validation loss: 2.2045340140660605

Epoch: 5| Step: 2
Training loss: 1.3804956674575806
Validation loss: 2.1654953757921853

Epoch: 5| Step: 3
Training loss: 2.6730871200561523
Validation loss: 2.1440903594096503

Epoch: 5| Step: 4
Training loss: 1.919285535812378
Validation loss: 2.158656974633535

Epoch: 5| Step: 5
Training loss: 1.8797096014022827
Validation loss: 2.1486636300881705

Epoch: 5| Step: 6
Training loss: 2.436556100845337
Validation loss: 2.1855596949656806

Epoch: 5| Step: 7
Training loss: 1.4133820533752441
Validation loss: 2.1376439978679023

Epoch: 5| Step: 8
Training loss: 1.7245413064956665
Validation loss: 2.1354358792304993

Epoch: 5| Step: 9
Training loss: 1.6457809209823608
Validation loss: 2.1671179185311

Epoch: 5| Step: 10
Training loss: 1.7448879480361938
Validation loss: 2.151361882686615

Epoch: 5| Step: 11
Training loss: 0.9102346897125244
Validation loss: 2.086303323507309

Epoch: 114| Step: 0
Training loss: 1.5860660076141357
Validation loss: 2.1698313852151236

Epoch: 5| Step: 1
Training loss: 1.4819869995117188
Validation loss: 2.117067183057467

Epoch: 5| Step: 2
Training loss: 1.7597442865371704
Validation loss: 2.1614994506041207

Epoch: 5| Step: 3
Training loss: 1.9623314142227173
Validation loss: 2.140445033709208

Epoch: 5| Step: 4
Training loss: 1.4656779766082764
Validation loss: 2.165663222471873

Epoch: 5| Step: 5
Training loss: 2.0512022972106934
Validation loss: 2.0967909594376883

Epoch: 5| Step: 6
Training loss: 1.3979614973068237
Validation loss: 2.1081209033727646

Epoch: 5| Step: 7
Training loss: 1.56019127368927
Validation loss: 2.139524052540461

Epoch: 5| Step: 8
Training loss: 2.094998836517334
Validation loss: 2.1000191469987235

Epoch: 5| Step: 9
Training loss: 1.696528673171997
Validation loss: 2.141720548272133

Epoch: 5| Step: 10
Training loss: 2.365861177444458
Validation loss: 2.1414681772391

Epoch: 5| Step: 11
Training loss: 0.9066314697265625
Validation loss: 2.1015219688415527

Epoch: 115| Step: 0
Training loss: 2.4194114208221436
Validation loss: 2.15655018389225

Epoch: 5| Step: 1
Training loss: 1.7140085697174072
Validation loss: 2.1840090254942575

Epoch: 5| Step: 2
Training loss: 2.200535297393799
Validation loss: 2.1465928852558136

Epoch: 5| Step: 3
Training loss: 1.237510323524475
Validation loss: 2.1806468814611435

Epoch: 5| Step: 4
Training loss: 1.6844370365142822
Validation loss: 2.1475650618473687

Epoch: 5| Step: 5
Training loss: 1.4794470071792603
Validation loss: 2.170180747906367

Epoch: 5| Step: 6
Training loss: 1.657057762145996
Validation loss: 2.1613655984401703

Epoch: 5| Step: 7
Training loss: 1.5396910905838013
Validation loss: 2.1330319891373315

Epoch: 5| Step: 8
Training loss: 1.9542373418807983
Validation loss: 2.1527583648761115

Epoch: 5| Step: 9
Training loss: 1.6515929698944092
Validation loss: 2.1518337229887643

Epoch: 5| Step: 10
Training loss: 1.633508324623108
Validation loss: 2.080144226551056

Epoch: 5| Step: 11
Training loss: 1.2018804550170898
Validation loss: 2.15131605664889

Epoch: 116| Step: 0
Training loss: 2.1127102375030518
Validation loss: 2.140856479605039

Epoch: 5| Step: 1
Training loss: 1.7078311443328857
Validation loss: 2.0893014520406723

Epoch: 5| Step: 2
Training loss: 2.3789494037628174
Validation loss: 2.149082084496816

Epoch: 5| Step: 3
Training loss: 1.399096965789795
Validation loss: 2.137104426821073

Epoch: 5| Step: 4
Training loss: 1.9740817546844482
Validation loss: 2.1507246096928916

Epoch: 5| Step: 5
Training loss: 1.3634178638458252
Validation loss: 2.1450762897729874

Epoch: 5| Step: 6
Training loss: 1.8755683898925781
Validation loss: 2.144669532775879

Epoch: 5| Step: 7
Training loss: 1.972559928894043
Validation loss: 2.1250710586706796

Epoch: 5| Step: 8
Training loss: 1.683388113975525
Validation loss: 2.1600581804911294

Epoch: 5| Step: 9
Training loss: 1.745653510093689
Validation loss: 2.159663329521815

Epoch: 5| Step: 10
Training loss: 1.8294299840927124
Validation loss: 2.1432980547348657

Epoch: 5| Step: 11
Training loss: 1.9847183227539062
Validation loss: 2.145075738430023

Epoch: 117| Step: 0
Training loss: 2.130918502807617
Validation loss: 2.2003930707772574

Epoch: 5| Step: 1
Training loss: 1.8273370265960693
Validation loss: 2.178479770819346

Epoch: 5| Step: 2
Training loss: 1.975097417831421
Validation loss: 2.1766284803549447

Epoch: 5| Step: 3
Training loss: 1.399880051612854
Validation loss: 2.2180595099925995

Epoch: 5| Step: 4
Training loss: 1.6160213947296143
Validation loss: 2.2208004842201867

Epoch: 5| Step: 5
Training loss: 1.747388243675232
Validation loss: 2.159884035587311

Epoch: 5| Step: 6
Training loss: 1.626787543296814
Validation loss: 2.239553913474083

Epoch: 5| Step: 7
Training loss: 0.7755995988845825
Validation loss: 2.181723808248838

Epoch: 5| Step: 8
Training loss: 1.702878713607788
Validation loss: 2.1480414867401123

Epoch: 5| Step: 9
Training loss: 2.1938014030456543
Validation loss: 2.2283426076173782

Epoch: 5| Step: 10
Training loss: 1.980363130569458
Validation loss: 2.1321079979340234

Epoch: 5| Step: 11
Training loss: 3.4490742683410645
Validation loss: 2.206490774949392

Epoch: 118| Step: 0
Training loss: 2.053295850753784
Validation loss: 2.1231103390455246

Epoch: 5| Step: 1
Training loss: 1.9797542095184326
Validation loss: 2.112925181786219

Epoch: 5| Step: 2
Training loss: 1.8228785991668701
Validation loss: 2.0868925899267197

Epoch: 5| Step: 3
Training loss: 1.4954414367675781
Validation loss: 2.151036858558655

Epoch: 5| Step: 4
Training loss: 1.7337749004364014
Validation loss: 2.114035944143931

Epoch: 5| Step: 5
Training loss: 1.9882510900497437
Validation loss: 2.1286158114671707

Epoch: 5| Step: 6
Training loss: 1.3708324432373047
Validation loss: 2.175846720735232

Epoch: 5| Step: 7
Training loss: 1.6124041080474854
Validation loss: 2.185192177693049

Epoch: 5| Step: 8
Training loss: 1.1703214645385742
Validation loss: 2.1879338870445886

Epoch: 5| Step: 9
Training loss: 1.935956358909607
Validation loss: 2.2095118214686713

Epoch: 5| Step: 10
Training loss: 1.9235408306121826
Validation loss: 2.118509983023008

Epoch: 5| Step: 11
Training loss: 3.1326310634613037
Validation loss: 2.197154695789019

Epoch: 119| Step: 0
Training loss: 2.3968663215637207
Validation loss: 2.1603980362415314

Epoch: 5| Step: 1
Training loss: 2.3442602157592773
Validation loss: 2.1598575164874396

Epoch: 5| Step: 2
Training loss: 1.6034157276153564
Validation loss: 2.1527139941851297

Epoch: 5| Step: 3
Training loss: 1.831321358680725
Validation loss: 2.108174512783686

Epoch: 5| Step: 4
Training loss: 1.4926559925079346
Validation loss: 2.1716315547625222

Epoch: 5| Step: 5
Training loss: 1.5913878679275513
Validation loss: 2.1513073792060218

Epoch: 5| Step: 6
Training loss: 1.3431317806243896
Validation loss: 2.172336975733439

Epoch: 5| Step: 7
Training loss: 1.6037466526031494
Validation loss: 2.1403093338012695

Epoch: 5| Step: 8
Training loss: 2.0641236305236816
Validation loss: 2.1309294005235038

Epoch: 5| Step: 9
Training loss: 1.6679331064224243
Validation loss: 2.084636022647222

Epoch: 5| Step: 10
Training loss: 1.9245898723602295
Validation loss: 2.1667692810297012

Epoch: 5| Step: 11
Training loss: 1.002219796180725
Validation loss: 2.118534321586291

Epoch: 120| Step: 0
Training loss: 2.7584636211395264
Validation loss: 2.18606761097908

Epoch: 5| Step: 1
Training loss: 1.623788833618164
Validation loss: 2.1880572934945426

Epoch: 5| Step: 2
Training loss: 1.6970889568328857
Validation loss: 2.2119763096173606

Epoch: 5| Step: 3
Training loss: 1.6163380146026611
Validation loss: 2.1518498212099075

Epoch: 5| Step: 4
Training loss: 1.4765247106552124
Validation loss: 2.1950767735640206

Epoch: 5| Step: 5
Training loss: 1.564082384109497
Validation loss: 2.184117784102758

Epoch: 5| Step: 6
Training loss: 1.6975195407867432
Validation loss: 2.1399198323488235

Epoch: 5| Step: 7
Training loss: 1.6687514781951904
Validation loss: 2.162376880645752

Epoch: 5| Step: 8
Training loss: 1.9898710250854492
Validation loss: 2.1929944952329

Epoch: 5| Step: 9
Training loss: 1.5565524101257324
Validation loss: 2.1502212087313333

Epoch: 5| Step: 10
Training loss: 1.5265531539916992
Validation loss: 2.1692804396152496

Epoch: 5| Step: 11
Training loss: 1.2336604595184326
Validation loss: 2.1646122386058173

Epoch: 121| Step: 0
Training loss: 1.4962899684906006
Validation loss: 2.1407547841469445

Epoch: 5| Step: 1
Training loss: 1.5544965267181396
Validation loss: 2.1624931693077087

Epoch: 5| Step: 2
Training loss: 1.6214478015899658
Validation loss: 2.1236399660507836

Epoch: 5| Step: 3
Training loss: 1.405739188194275
Validation loss: 2.1652860194444656

Epoch: 5| Step: 4
Training loss: 1.4837831258773804
Validation loss: 2.078792388240496

Epoch: 5| Step: 5
Training loss: 1.731093168258667
Validation loss: 2.16464335223039

Epoch: 5| Step: 6
Training loss: 2.2084062099456787
Validation loss: 2.1092975238958993

Epoch: 5| Step: 7
Training loss: 1.926990270614624
Validation loss: 2.2041074633598328

Epoch: 5| Step: 8
Training loss: 2.180204391479492
Validation loss: 2.1476155519485474

Epoch: 5| Step: 9
Training loss: 1.7034618854522705
Validation loss: 2.142017513513565

Epoch: 5| Step: 10
Training loss: 1.674271583557129
Validation loss: 2.1203183382749557

Epoch: 5| Step: 11
Training loss: 1.4932752847671509
Validation loss: 2.1868304759263992

Epoch: 122| Step: 0
Training loss: 1.6587823629379272
Validation loss: 2.136044055223465

Epoch: 5| Step: 1
Training loss: 1.3079149723052979
Validation loss: 2.0966569582621255

Epoch: 5| Step: 2
Training loss: 2.510876178741455
Validation loss: 2.1712632973988852

Epoch: 5| Step: 3
Training loss: 1.435260534286499
Validation loss: 2.2253768742084503

Epoch: 5| Step: 4
Training loss: 1.836337685585022
Validation loss: 2.1597423404455185

Epoch: 5| Step: 5
Training loss: 1.4306745529174805
Validation loss: 2.172002067168554

Epoch: 5| Step: 6
Training loss: 1.9548101425170898
Validation loss: 2.1807797650496163

Epoch: 5| Step: 7
Training loss: 1.5600841045379639
Validation loss: 2.1614290177822113

Epoch: 5| Step: 8
Training loss: 1.7596848011016846
Validation loss: 2.202635645866394

Epoch: 5| Step: 9
Training loss: 1.597853660583496
Validation loss: 2.1718503882487616

Epoch: 5| Step: 10
Training loss: 1.8818957805633545
Validation loss: 2.206604023774465

Epoch: 5| Step: 11
Training loss: 0.8680475354194641
Validation loss: 2.162854492664337

Epoch: 123| Step: 0
Training loss: 1.3965654373168945
Validation loss: 2.180458426475525

Epoch: 5| Step: 1
Training loss: 1.0275262594223022
Validation loss: 2.1457826842864356

Epoch: 5| Step: 2
Training loss: 1.4886208772659302
Validation loss: 2.182730495929718

Epoch: 5| Step: 3
Training loss: 2.532120704650879
Validation loss: 2.1359204848607383

Epoch: 5| Step: 4
Training loss: 2.245856761932373
Validation loss: 2.1656577388445535

Epoch: 5| Step: 5
Training loss: 2.5199992656707764
Validation loss: 2.1455740133921304

Epoch: 5| Step: 6
Training loss: 1.1387097835540771
Validation loss: 2.145996277530988

Epoch: 5| Step: 7
Training loss: 1.5117582082748413
Validation loss: 2.1365243792533875

Epoch: 5| Step: 8
Training loss: 1.3486393690109253
Validation loss: 2.149247239033381

Epoch: 5| Step: 9
Training loss: 1.6413723230361938
Validation loss: 2.1206675420204797

Epoch: 5| Step: 10
Training loss: 1.6622146368026733
Validation loss: 2.1484576761722565

Epoch: 5| Step: 11
Training loss: 3.185382127761841
Validation loss: 2.193562696377436

Epoch: 124| Step: 0
Training loss: 1.081088662147522
Validation loss: 2.2050473441680274

Epoch: 5| Step: 1
Training loss: 2.0388875007629395
Validation loss: 2.1631744702657065

Epoch: 5| Step: 2
Training loss: 1.4367601871490479
Validation loss: 2.1880103001991906

Epoch: 5| Step: 3
Training loss: 2.3097927570343018
Validation loss: 2.1390180587768555

Epoch: 5| Step: 4
Training loss: 1.528051733970642
Validation loss: 2.150956799586614

Epoch: 5| Step: 5
Training loss: 1.5220869779586792
Validation loss: 2.189772829413414

Epoch: 5| Step: 6
Training loss: 1.945745825767517
Validation loss: 2.166332388917605

Epoch: 5| Step: 7
Training loss: 1.2672767639160156
Validation loss: 2.143727963169416

Epoch: 5| Step: 8
Training loss: 1.3338433504104614
Validation loss: 2.133349359035492

Epoch: 5| Step: 9
Training loss: 2.4205563068389893
Validation loss: 2.148553431034088

Epoch: 5| Step: 10
Training loss: 1.7855608463287354
Validation loss: 2.200642377138138

Epoch: 5| Step: 11
Training loss: 2.532770872116089
Validation loss: 2.1033834914366403

Epoch: 125| Step: 0
Training loss: 1.6459453105926514
Validation loss: 2.1289996902147927

Epoch: 5| Step: 1
Training loss: 1.2679601907730103
Validation loss: 2.112906644741694

Epoch: 5| Step: 2
Training loss: 2.0118930339813232
Validation loss: 2.131802573800087

Epoch: 5| Step: 3
Training loss: 1.3833543062210083
Validation loss: 2.1903961996237435

Epoch: 5| Step: 4
Training loss: 1.8401358127593994
Validation loss: 2.148667881886164

Epoch: 5| Step: 5
Training loss: 1.8980963230133057
Validation loss: 2.1619474043448768

Epoch: 5| Step: 6
Training loss: 2.178086757659912
Validation loss: 2.1168593764305115

Epoch: 5| Step: 7
Training loss: 1.8635631799697876
Validation loss: 2.1290890822807946

Epoch: 5| Step: 8
Training loss: 1.085652470588684
Validation loss: 2.143330454826355

Epoch: 5| Step: 9
Training loss: 1.8426927328109741
Validation loss: 2.104517807563146

Epoch: 5| Step: 10
Training loss: 1.30515718460083
Validation loss: 2.162460615237554

Epoch: 5| Step: 11
Training loss: 1.9174612760543823
Validation loss: 2.1657656778891883

Epoch: 126| Step: 0
Training loss: 1.4887611865997314
Validation loss: 2.1825281927982965

Epoch: 5| Step: 1
Training loss: 1.9975802898406982
Validation loss: 2.1372019549210868

Epoch: 5| Step: 2
Training loss: 1.6713800430297852
Validation loss: 2.189054474234581

Epoch: 5| Step: 3
Training loss: 2.1777234077453613
Validation loss: 2.130479554335276

Epoch: 5| Step: 4
Training loss: 1.5013142824172974
Validation loss: 2.101589868466059

Epoch: 5| Step: 5
Training loss: 1.5403131246566772
Validation loss: 2.13442533214887

Epoch: 5| Step: 6
Training loss: 1.7163928747177124
Validation loss: 2.1905156075954437

Epoch: 5| Step: 7
Training loss: 1.753267526626587
Validation loss: 2.1760913034280143

Epoch: 5| Step: 8
Training loss: 1.7203782796859741
Validation loss: 2.163363834222158

Epoch: 5| Step: 9
Training loss: 1.7692430019378662
Validation loss: 2.1794659992059073

Epoch: 5| Step: 10
Training loss: 1.1021867990493774
Validation loss: 2.1901486416657767

Epoch: 5| Step: 11
Training loss: 1.1189641952514648
Validation loss: 2.1569639494021735

Epoch: 127| Step: 0
Training loss: 1.2112963199615479
Validation loss: 2.204057037830353

Epoch: 5| Step: 1
Training loss: 1.7552201747894287
Validation loss: 2.2358877609173455

Epoch: 5| Step: 2
Training loss: 1.6440738439559937
Validation loss: 2.2370673467715583

Epoch: 5| Step: 3
Training loss: 1.5600812435150146
Validation loss: 2.165878857175509

Epoch: 5| Step: 4
Training loss: 1.985527753829956
Validation loss: 2.1663198371728263

Epoch: 5| Step: 5
Training loss: 1.3628084659576416
Validation loss: 2.1729922046264014

Epoch: 5| Step: 6
Training loss: 2.125868320465088
Validation loss: 2.1454894045988717

Epoch: 5| Step: 7
Training loss: 1.5578117370605469
Validation loss: 2.202585200468699

Epoch: 5| Step: 8
Training loss: 1.2076592445373535
Validation loss: 2.177300199866295

Epoch: 5| Step: 9
Training loss: 1.4374079704284668
Validation loss: 2.113099604845047

Epoch: 5| Step: 10
Training loss: 2.232558488845825
Validation loss: 2.156034658352534

Epoch: 5| Step: 11
Training loss: 2.2735416889190674
Validation loss: 2.1456706871589026

Epoch: 128| Step: 0
Training loss: 1.2002557516098022
Validation loss: 2.116636112332344

Epoch: 5| Step: 1
Training loss: 1.726198434829712
Validation loss: 2.1386946539084115

Epoch: 5| Step: 2
Training loss: 2.0440499782562256
Validation loss: 2.202158068617185

Epoch: 5| Step: 3
Training loss: 1.3946928977966309
Validation loss: 2.124064400792122

Epoch: 5| Step: 4
Training loss: 2.102801561355591
Validation loss: 2.116094926993052

Epoch: 5| Step: 5
Training loss: 1.9700958728790283
Validation loss: 2.1151233861843743

Epoch: 5| Step: 6
Training loss: 1.4253127574920654
Validation loss: 2.1889444092909494

Epoch: 5| Step: 7
Training loss: 1.2909669876098633
Validation loss: 2.1779287308454514

Epoch: 5| Step: 8
Training loss: 1.872450590133667
Validation loss: 2.1556552052497864

Epoch: 5| Step: 9
Training loss: 1.5445516109466553
Validation loss: 2.2130965342124305

Epoch: 5| Step: 10
Training loss: 1.1718311309814453
Validation loss: 2.225848679741224

Epoch: 5| Step: 11
Training loss: 2.9245200157165527
Validation loss: 2.127493515610695

Epoch: 129| Step: 0
Training loss: 2.121171474456787
Validation loss: 2.184966246287028

Epoch: 5| Step: 1
Training loss: 2.2607641220092773
Validation loss: 2.1582849323749542

Epoch: 5| Step: 2
Training loss: 1.550776481628418
Validation loss: 2.1961224476496377

Epoch: 5| Step: 3
Training loss: 1.7964798212051392
Validation loss: 2.1751260409752526

Epoch: 5| Step: 4
Training loss: 1.4499613046646118
Validation loss: 2.157592331369718

Epoch: 5| Step: 5
Training loss: 1.420015811920166
Validation loss: 2.1625199715296426

Epoch: 5| Step: 6
Training loss: 1.2882308959960938
Validation loss: 2.174216613173485

Epoch: 5| Step: 7
Training loss: 1.551298975944519
Validation loss: 2.1431172837813697

Epoch: 5| Step: 8
Training loss: 1.5093066692352295
Validation loss: 2.1435903708140054

Epoch: 5| Step: 9
Training loss: 1.8649787902832031
Validation loss: 2.218163008491198

Epoch: 5| Step: 10
Training loss: 1.9146592617034912
Validation loss: 2.15861847003301

Epoch: 5| Step: 11
Training loss: 0.7377350926399231
Validation loss: 2.2403737356265387

Epoch: 130| Step: 0
Training loss: 1.355270266532898
Validation loss: 2.149286851286888

Epoch: 5| Step: 1
Training loss: 1.8267593383789062
Validation loss: 2.2130735218524933

Epoch: 5| Step: 2
Training loss: 1.285537838935852
Validation loss: 2.201042373975118

Epoch: 5| Step: 3
Training loss: 1.7964630126953125
Validation loss: 2.219067166248957

Epoch: 5| Step: 4
Training loss: 1.654333472251892
Validation loss: 2.226513052980105

Epoch: 5| Step: 5
Training loss: 1.681667685508728
Validation loss: 2.2223873138427734

Epoch: 5| Step: 6
Training loss: 2.0069198608398438
Validation loss: 2.165729135274887

Epoch: 5| Step: 7
Training loss: 1.8689448833465576
Validation loss: 2.1800380051136017

Epoch: 5| Step: 8
Training loss: 1.716353178024292
Validation loss: 2.202652171254158

Epoch: 5| Step: 9
Training loss: 0.9204192161560059
Validation loss: 2.1529758324225745

Epoch: 5| Step: 10
Training loss: 2.3927295207977295
Validation loss: 2.097982476154963

Epoch: 5| Step: 11
Training loss: 1.4797295331954956
Validation loss: 2.150110900402069

Epoch: 131| Step: 0
Training loss: 1.4008691310882568
Validation loss: 2.1174460599819818

Epoch: 5| Step: 1
Training loss: 2.0079092979431152
Validation loss: 2.12940805653731

Epoch: 5| Step: 2
Training loss: 1.1707693338394165
Validation loss: 2.1208315988381705

Epoch: 5| Step: 3
Training loss: 1.4217150211334229
Validation loss: 2.1167876422405243

Epoch: 5| Step: 4
Training loss: 1.4400056600570679
Validation loss: 2.0845251033703485

Epoch: 5| Step: 5
Training loss: 1.5428228378295898
Validation loss: 2.1477412432432175

Epoch: 5| Step: 6
Training loss: 2.0679965019226074
Validation loss: 2.2364481637875238

Epoch: 5| Step: 7
Training loss: 1.6567052602767944
Validation loss: 2.1464765071868896

Epoch: 5| Step: 8
Training loss: 1.6157386302947998
Validation loss: 2.1454844027757645

Epoch: 5| Step: 9
Training loss: 2.494704484939575
Validation loss: 2.153718282779058

Epoch: 5| Step: 10
Training loss: 1.7423938512802124
Validation loss: 2.2233717143535614

Epoch: 5| Step: 11
Training loss: 1.1811630725860596
Validation loss: 2.187715709209442

Epoch: 132| Step: 0
Training loss: 1.6461193561553955
Validation loss: 2.117330104112625

Epoch: 5| Step: 1
Training loss: 1.8329375982284546
Validation loss: 2.157375747958819

Epoch: 5| Step: 2
Training loss: 0.8002708554267883
Validation loss: 2.138498196999232

Epoch: 5| Step: 3
Training loss: 2.1642138957977295
Validation loss: 2.151785542567571

Epoch: 5| Step: 4
Training loss: 1.5669729709625244
Validation loss: 2.143518775701523

Epoch: 5| Step: 5
Training loss: 1.9068222045898438
Validation loss: 2.1403607428073883

Epoch: 5| Step: 6
Training loss: 1.9981743097305298
Validation loss: 2.204452008008957

Epoch: 5| Step: 7
Training loss: 1.4747809171676636
Validation loss: 2.130706866582235

Epoch: 5| Step: 8
Training loss: 1.4303524494171143
Validation loss: 2.165805439154307

Epoch: 5| Step: 9
Training loss: 1.5447510480880737
Validation loss: 2.1556461999813714

Epoch: 5| Step: 10
Training loss: 1.6314010620117188
Validation loss: 2.1648876319328942

Epoch: 5| Step: 11
Training loss: 2.5324416160583496
Validation loss: 2.1756152361631393

Epoch: 133| Step: 0
Training loss: 1.8953752517700195
Validation loss: 2.1579898496468863

Epoch: 5| Step: 1
Training loss: 1.6648061275482178
Validation loss: 2.186031033595403

Epoch: 5| Step: 2
Training loss: 1.576729416847229
Validation loss: 2.2173655877510705

Epoch: 5| Step: 3
Training loss: 1.303582787513733
Validation loss: 2.1887752463420234

Epoch: 5| Step: 4
Training loss: 1.1988534927368164
Validation loss: 2.1820146987835565

Epoch: 5| Step: 5
Training loss: 1.537213683128357
Validation loss: 2.1442045867443085

Epoch: 5| Step: 6
Training loss: 2.087677001953125
Validation loss: 2.153419037659963

Epoch: 5| Step: 7
Training loss: 1.3290199041366577
Validation loss: 2.175914466381073

Epoch: 5| Step: 8
Training loss: 2.0263686180114746
Validation loss: 2.191881770888964

Epoch: 5| Step: 9
Training loss: 1.6931335926055908
Validation loss: 2.1432646214962006

Epoch: 5| Step: 10
Training loss: 1.5881824493408203
Validation loss: 2.153991311788559

Epoch: 5| Step: 11
Training loss: 1.8026726245880127
Validation loss: 2.167587454120318

Epoch: 134| Step: 0
Training loss: 1.6275399923324585
Validation loss: 2.1569302529096603

Epoch: 5| Step: 1
Training loss: 1.6473459005355835
Validation loss: 2.1786047716935477

Epoch: 5| Step: 2
Training loss: 1.3863890171051025
Validation loss: 2.1707147359848022

Epoch: 5| Step: 3
Training loss: 1.926262617111206
Validation loss: 2.145828584829966

Epoch: 5| Step: 4
Training loss: 1.684822678565979
Validation loss: 2.1531967471043267

Epoch: 5| Step: 5
Training loss: 1.7043654918670654
Validation loss: 2.142437845468521

Epoch: 5| Step: 6
Training loss: 1.5287269353866577
Validation loss: 2.143502632776896

Epoch: 5| Step: 7
Training loss: 2.1144962310791016
Validation loss: 2.105287844936053

Epoch: 5| Step: 8
Training loss: 1.9429283142089844
Validation loss: 2.112225115299225

Epoch: 5| Step: 9
Training loss: 1.532170057296753
Validation loss: 2.1578948497772217

Epoch: 5| Step: 10
Training loss: 1.6059097051620483
Validation loss: 2.217308913667997

Epoch: 5| Step: 11
Training loss: 1.527848482131958
Validation loss: 2.2460611760616302

Epoch: 135| Step: 0
Training loss: 2.0122385025024414
Validation loss: 2.231505572795868

Epoch: 5| Step: 1
Training loss: 1.2741587162017822
Validation loss: 2.2773949404557547

Epoch: 5| Step: 2
Training loss: 0.8974956274032593
Validation loss: 2.2668322175741196

Epoch: 5| Step: 3
Training loss: 1.5355008840560913
Validation loss: 2.2454516688982644

Epoch: 5| Step: 4
Training loss: 1.4954802989959717
Validation loss: 2.2566708823045096

Epoch: 5| Step: 5
Training loss: 1.4647552967071533
Validation loss: 2.1855889757474265

Epoch: 5| Step: 6
Training loss: 1.2379347085952759
Validation loss: 2.2150065352519355

Epoch: 5| Step: 7
Training loss: 2.0212647914886475
Validation loss: 2.1479859749476113

Epoch: 5| Step: 8
Training loss: 1.9962358474731445
Validation loss: 2.185532530148824

Epoch: 5| Step: 9
Training loss: 2.1387362480163574
Validation loss: 2.13667239745458

Epoch: 5| Step: 10
Training loss: 1.7921345233917236
Validation loss: 2.163353035847346

Epoch: 5| Step: 11
Training loss: 1.980773687362671
Validation loss: 2.172590951124827

Epoch: 136| Step: 0
Training loss: 1.3346281051635742
Validation loss: 2.1570494025945663

Epoch: 5| Step: 1
Training loss: 1.9419059753417969
Validation loss: 2.2039048969745636

Epoch: 5| Step: 2
Training loss: 1.9187119007110596
Validation loss: 2.1468494633833566

Epoch: 5| Step: 3
Training loss: 1.4699121713638306
Validation loss: 2.1806538005669913

Epoch: 5| Step: 4
Training loss: 1.941148042678833
Validation loss: 2.1335898290077844

Epoch: 5| Step: 5
Training loss: 1.209486484527588
Validation loss: 2.102460816502571

Epoch: 5| Step: 6
Training loss: 1.6160558462142944
Validation loss: 2.1710608104864755

Epoch: 5| Step: 7
Training loss: 1.908333420753479
Validation loss: 2.2028414656718573

Epoch: 5| Step: 8
Training loss: 1.6924965381622314
Validation loss: 2.1960511157910028

Epoch: 5| Step: 9
Training loss: 1.9281418323516846
Validation loss: 2.2109233985344567

Epoch: 5| Step: 10
Training loss: 1.799825668334961
Validation loss: 2.283341884613037

Epoch: 5| Step: 11
Training loss: 1.9246110916137695
Validation loss: 2.307157059510549

Epoch: 137| Step: 0
Training loss: 1.7143926620483398
Validation loss: 2.305514872074127

Epoch: 5| Step: 1
Training loss: 1.3039671182632446
Validation loss: 2.227025037010511

Epoch: 5| Step: 2
Training loss: 1.1616603136062622
Validation loss: 2.1461462328831353

Epoch: 5| Step: 3
Training loss: 1.454649567604065
Validation loss: 2.1518895030021667

Epoch: 5| Step: 4
Training loss: 2.1695640087127686
Validation loss: 2.1617044607798257

Epoch: 5| Step: 5
Training loss: 1.9163093566894531
Validation loss: 2.137754658857981

Epoch: 5| Step: 6
Training loss: 1.5745872259140015
Validation loss: 2.1640087266763053

Epoch: 5| Step: 7
Training loss: 1.7932708263397217
Validation loss: 2.14658060669899

Epoch: 5| Step: 8
Training loss: 1.3779960870742798
Validation loss: 2.1629991829395294

Epoch: 5| Step: 9
Training loss: 1.5475366115570068
Validation loss: 2.1562776317199073

Epoch: 5| Step: 10
Training loss: 1.956188440322876
Validation loss: 2.1616707891225815

Epoch: 5| Step: 11
Training loss: 1.2950663566589355
Validation loss: 2.171454042196274

Epoch: 138| Step: 0
Training loss: 1.7753181457519531
Validation loss: 2.13965834180514

Epoch: 5| Step: 1
Training loss: 1.7583398818969727
Validation loss: 2.181716506679853

Epoch: 5| Step: 2
Training loss: 2.2760300636291504
Validation loss: 2.2448489665985107

Epoch: 5| Step: 3
Training loss: 1.653740644454956
Validation loss: 2.232134456435839

Epoch: 5| Step: 4
Training loss: 1.6292623281478882
Validation loss: 2.1917515645424523

Epoch: 5| Step: 5
Training loss: 1.0758068561553955
Validation loss: 2.277134249607722

Epoch: 5| Step: 6
Training loss: 1.3676658868789673
Validation loss: 2.1906726906696954

Epoch: 5| Step: 7
Training loss: 1.7718040943145752
Validation loss: 2.203812008102735

Epoch: 5| Step: 8
Training loss: 1.9637998342514038
Validation loss: 2.19236122071743

Epoch: 5| Step: 9
Training loss: 1.4399776458740234
Validation loss: 2.1638801246881485

Epoch: 5| Step: 10
Training loss: 1.327477216720581
Validation loss: 2.2079447408517203

Epoch: 5| Step: 11
Training loss: 1.2603528499603271
Validation loss: 2.1868204971154532

Epoch: 139| Step: 0
Training loss: 1.6526581048965454
Validation loss: 2.1603665947914124

Epoch: 5| Step: 1
Training loss: 1.3071973323822021
Validation loss: 2.1827499121427536

Epoch: 5| Step: 2
Training loss: 1.4363319873809814
Validation loss: 2.1854159384965897

Epoch: 5| Step: 3
Training loss: 1.2261871099472046
Validation loss: 2.183295418818792

Epoch: 5| Step: 4
Training loss: 1.5717262029647827
Validation loss: 2.1028660982847214

Epoch: 5| Step: 5
Training loss: 1.7864856719970703
Validation loss: 2.163237119714419

Epoch: 5| Step: 6
Training loss: 2.3274989128112793
Validation loss: 2.140359322230021

Epoch: 5| Step: 7
Training loss: 1.0934537649154663
Validation loss: 2.1972196996212006

Epoch: 5| Step: 8
Training loss: 1.820457100868225
Validation loss: 2.19087353348732

Epoch: 5| Step: 9
Training loss: 2.061357259750366
Validation loss: 2.2122861742973328

Epoch: 5| Step: 10
Training loss: 1.7377159595489502
Validation loss: 2.173514465490977

Epoch: 5| Step: 11
Training loss: 1.1161749362945557
Validation loss: 2.212880492210388

Epoch: 140| Step: 0
Training loss: 1.923864722251892
Validation loss: 2.1971579988797507

Epoch: 5| Step: 1
Training loss: 2.016615390777588
Validation loss: 2.2460558911164603

Epoch: 5| Step: 2
Training loss: 1.3889223337173462
Validation loss: 2.221336394548416

Epoch: 5| Step: 3
Training loss: 1.4367831945419312
Validation loss: 2.1816567182540894

Epoch: 5| Step: 4
Training loss: 1.8658021688461304
Validation loss: 2.1998938669761023

Epoch: 5| Step: 5
Training loss: 2.1635582447052
Validation loss: 2.211139425635338

Epoch: 5| Step: 6
Training loss: 1.4152299165725708
Validation loss: 2.113961393634478

Epoch: 5| Step: 7
Training loss: 1.1246092319488525
Validation loss: 2.1399491926034293

Epoch: 5| Step: 8
Training loss: 1.0710136890411377
Validation loss: 2.179995814959208

Epoch: 5| Step: 9
Training loss: 1.1480085849761963
Validation loss: 2.1808535307645798

Epoch: 5| Step: 10
Training loss: 2.3386847972869873
Validation loss: 2.235725993911425

Epoch: 5| Step: 11
Training loss: 0.9610547423362732
Validation loss: 2.200459212064743

Epoch: 141| Step: 0
Training loss: 2.0002620220184326
Validation loss: 2.1527602275212607

Epoch: 5| Step: 1
Training loss: 1.4165905714035034
Validation loss: 2.1095811227957406

Epoch: 5| Step: 2
Training loss: 1.8692505359649658
Validation loss: 2.1736401418844857

Epoch: 5| Step: 3
Training loss: 1.9505221843719482
Validation loss: 2.155028074979782

Epoch: 5| Step: 4
Training loss: 1.8896572589874268
Validation loss: 2.129041224718094

Epoch: 5| Step: 5
Training loss: 1.0388110876083374
Validation loss: 2.1755316853523254

Epoch: 5| Step: 6
Training loss: 1.5051020383834839
Validation loss: 2.1163717110951743

Epoch: 5| Step: 7
Training loss: 1.5410048961639404
Validation loss: 2.176080644130707

Epoch: 5| Step: 8
Training loss: 2.1110658645629883
Validation loss: 2.1634613325198493

Epoch: 5| Step: 9
Training loss: 1.3059484958648682
Validation loss: 2.1743203351895013

Epoch: 5| Step: 10
Training loss: 1.2425897121429443
Validation loss: 2.1755960086981454

Epoch: 5| Step: 11
Training loss: 1.0426427125930786
Validation loss: 2.220379481712977

Epoch: 142| Step: 0
Training loss: 1.714820146560669
Validation loss: 2.2194479207197824

Epoch: 5| Step: 1
Training loss: 1.7728054523468018
Validation loss: 2.281593536337217

Epoch: 5| Step: 2
Training loss: 1.1818902492523193
Validation loss: 2.2308154702186584

Epoch: 5| Step: 3
Training loss: 1.7696828842163086
Validation loss: 2.268595337867737

Epoch: 5| Step: 4
Training loss: 1.671228051185608
Validation loss: 2.2888892889022827

Epoch: 5| Step: 5
Training loss: 1.890470266342163
Validation loss: 2.22468039393425

Epoch: 5| Step: 6
Training loss: 1.6292279958724976
Validation loss: 2.252677728732427

Epoch: 5| Step: 7
Training loss: 1.0627329349517822
Validation loss: 2.2239190886418023

Epoch: 5| Step: 8
Training loss: 1.5777738094329834
Validation loss: 2.2247627129157386

Epoch: 5| Step: 9
Training loss: 2.032834053039551
Validation loss: 2.136790702740351

Epoch: 5| Step: 10
Training loss: 1.403867244720459
Validation loss: 2.151243805885315

Epoch: 5| Step: 11
Training loss: 2.5812082290649414
Validation loss: 2.1662952303886414

Epoch: 143| Step: 0
Training loss: 1.8584887981414795
Validation loss: 2.1572235226631165

Epoch: 5| Step: 1
Training loss: 1.666175127029419
Validation loss: 2.18200454612573

Epoch: 5| Step: 2
Training loss: 1.8955409526824951
Validation loss: 2.163322150707245

Epoch: 5| Step: 3
Training loss: 2.118286609649658
Validation loss: 2.1688403387864432

Epoch: 5| Step: 4
Training loss: 1.3609232902526855
Validation loss: 2.149798552195231

Epoch: 5| Step: 5
Training loss: 1.2997000217437744
Validation loss: 2.119091292222341

Epoch: 5| Step: 6
Training loss: 1.8457072973251343
Validation loss: 2.1436187773942947

Epoch: 5| Step: 7
Training loss: 1.1416370868682861
Validation loss: 2.128540019194285

Epoch: 5| Step: 8
Training loss: 1.607789397239685
Validation loss: 2.126689006884893

Epoch: 5| Step: 9
Training loss: 1.3484152555465698
Validation loss: 2.184859976172447

Epoch: 5| Step: 10
Training loss: 1.6036186218261719
Validation loss: 2.1663489937782288

Epoch: 5| Step: 11
Training loss: 1.2169357538223267
Validation loss: 2.197064384818077

Epoch: 144| Step: 0
Training loss: 1.344381332397461
Validation loss: 2.2216379046440125

Epoch: 5| Step: 1
Training loss: 2.015800714492798
Validation loss: 2.2069198191165924

Epoch: 5| Step: 2
Training loss: 1.4394242763519287
Validation loss: 2.1981967786947885

Epoch: 5| Step: 3
Training loss: 1.455025553703308
Validation loss: 2.1771199852228165

Epoch: 5| Step: 4
Training loss: 1.2497119903564453
Validation loss: 2.1812169402837753

Epoch: 5| Step: 5
Training loss: 1.2815582752227783
Validation loss: 2.147798960407575

Epoch: 5| Step: 6
Training loss: 2.040703296661377
Validation loss: 2.1240921914577484

Epoch: 5| Step: 7
Training loss: 1.5470616817474365
Validation loss: 2.187426875034968

Epoch: 5| Step: 8
Training loss: 1.2699836492538452
Validation loss: 2.1509650399287543

Epoch: 5| Step: 9
Training loss: 1.8525400161743164
Validation loss: 2.0920178641875586

Epoch: 5| Step: 10
Training loss: 2.2132248878479004
Validation loss: 2.143939624230067

Epoch: 5| Step: 11
Training loss: 1.9206329584121704
Validation loss: 2.171860992908478

Epoch: 145| Step: 0
Training loss: 1.3803266286849976
Validation loss: 2.1728054334719977

Epoch: 5| Step: 1
Training loss: 2.322155475616455
Validation loss: 2.1465765237808228

Epoch: 5| Step: 2
Training loss: 1.2843554019927979
Validation loss: 2.161602874596914

Epoch: 5| Step: 3
Training loss: 1.214487910270691
Validation loss: 2.1517812808354697

Epoch: 5| Step: 4
Training loss: 1.7271602153778076
Validation loss: 2.1986267467339835

Epoch: 5| Step: 5
Training loss: 1.3662855625152588
Validation loss: 2.2030612329641976

Epoch: 5| Step: 6
Training loss: 1.3606081008911133
Validation loss: 2.234446500738462

Epoch: 5| Step: 7
Training loss: 1.3137342929840088
Validation loss: 2.149678627649943

Epoch: 5| Step: 8
Training loss: 1.5726757049560547
Validation loss: 2.2023669133583703

Epoch: 5| Step: 9
Training loss: 1.9005491733551025
Validation loss: 2.1882407863934836

Epoch: 5| Step: 10
Training loss: 1.3950560092926025
Validation loss: 2.2542579720417657

Epoch: 5| Step: 11
Training loss: 2.5046157836914062
Validation loss: 2.1957987844944

Epoch: 146| Step: 0
Training loss: 1.7034275531768799
Validation loss: 2.187672664721807

Epoch: 5| Step: 1
Training loss: 1.262294054031372
Validation loss: 2.1682049036026

Epoch: 5| Step: 2
Training loss: 1.3095381259918213
Validation loss: 2.185666337609291

Epoch: 5| Step: 3
Training loss: 1.9563102722167969
Validation loss: 2.1253265043099723

Epoch: 5| Step: 4
Training loss: 1.2134342193603516
Validation loss: 2.111679886778196

Epoch: 5| Step: 5
Training loss: 1.726316213607788
Validation loss: 2.1173917204141617

Epoch: 5| Step: 6
Training loss: 1.5207000970840454
Validation loss: 2.1803124099969864

Epoch: 5| Step: 7
Training loss: 2.002747058868408
Validation loss: 2.1573924273252487

Epoch: 5| Step: 8
Training loss: 1.9186859130859375
Validation loss: 2.1316640079021454

Epoch: 5| Step: 9
Training loss: 1.3544840812683105
Validation loss: 2.179068018992742

Epoch: 5| Step: 10
Training loss: 1.2801923751831055
Validation loss: 2.2001518607139587

Epoch: 5| Step: 11
Training loss: 1.1541990041732788
Validation loss: 2.1892792036135993

Epoch: 147| Step: 0
Training loss: 1.5790002346038818
Validation loss: 2.235754052797953

Epoch: 5| Step: 1
Training loss: 1.7557817697525024
Validation loss: 2.201912507414818

Epoch: 5| Step: 2
Training loss: 1.5524098873138428
Validation loss: 2.300922324260076

Epoch: 5| Step: 3
Training loss: 1.824989914894104
Validation loss: 2.210177297393481

Epoch: 5| Step: 4
Training loss: 1.6198279857635498
Validation loss: 2.223427027463913

Epoch: 5| Step: 5
Training loss: 1.4053595066070557
Validation loss: 2.292030562957128

Epoch: 5| Step: 6
Training loss: 1.2758756875991821
Validation loss: 2.2309945225715637

Epoch: 5| Step: 7
Training loss: 1.3675506114959717
Validation loss: 2.199765836199125

Epoch: 5| Step: 8
Training loss: 1.7849066257476807
Validation loss: 2.1707278887430825

Epoch: 5| Step: 9
Training loss: 1.1249415874481201
Validation loss: 2.1887464423974357

Epoch: 5| Step: 10
Training loss: 1.8358873128890991
Validation loss: 2.1959835986296334

Epoch: 5| Step: 11
Training loss: 2.399646759033203
Validation loss: 2.1355449855327606

Epoch: 148| Step: 0
Training loss: 1.1833715438842773
Validation loss: 2.139441246787707

Epoch: 5| Step: 1
Training loss: 1.4462580680847168
Validation loss: 2.173890620470047

Epoch: 5| Step: 2
Training loss: 2.1442759037017822
Validation loss: 2.180548002322515

Epoch: 5| Step: 3
Training loss: 1.838151216506958
Validation loss: 2.1920765986045203

Epoch: 5| Step: 4
Training loss: 1.3509632349014282
Validation loss: 2.16929230093956

Epoch: 5| Step: 5
Training loss: 1.1250879764556885
Validation loss: 2.1277357637882233

Epoch: 5| Step: 6
Training loss: 1.9209058284759521
Validation loss: 2.1886176665623984

Epoch: 5| Step: 7
Training loss: 1.4315614700317383
Validation loss: 2.174643168846766

Epoch: 5| Step: 8
Training loss: 1.5521559715270996
Validation loss: 2.1807392289241156

Epoch: 5| Step: 9
Training loss: 1.4627292156219482
Validation loss: 2.1887288937966027

Epoch: 5| Step: 10
Training loss: 1.6066596508026123
Validation loss: 2.210249046484629

Epoch: 5| Step: 11
Training loss: 2.149674892425537
Validation loss: 2.2047334015369415

Epoch: 149| Step: 0
Training loss: 1.340094804763794
Validation loss: 2.2247260361909866

Epoch: 5| Step: 1
Training loss: 1.1520925760269165
Validation loss: 2.226435581843058

Epoch: 5| Step: 2
Training loss: 1.5486524105072021
Validation loss: 2.2179463307062783

Epoch: 5| Step: 3
Training loss: 1.7736575603485107
Validation loss: 2.252179577946663

Epoch: 5| Step: 4
Training loss: 1.7058852910995483
Validation loss: 2.1757969905932746

Epoch: 5| Step: 5
Training loss: 2.2032086849212646
Validation loss: 2.200451652208964

Epoch: 5| Step: 6
Training loss: 1.2171343564987183
Validation loss: 2.230247919758161

Epoch: 5| Step: 7
Training loss: 1.2371487617492676
Validation loss: 2.188031847278277

Epoch: 5| Step: 8
Training loss: 1.5371867418289185
Validation loss: 2.1912146160999932

Epoch: 5| Step: 9
Training loss: 1.819698691368103
Validation loss: 2.1639260798692703

Epoch: 5| Step: 10
Training loss: 1.7801272869110107
Validation loss: 2.1739328106244407

Epoch: 5| Step: 11
Training loss: 1.368178129196167
Validation loss: 2.1318777054548264

Epoch: 150| Step: 0
Training loss: 1.6798279285430908
Validation loss: 2.118165463209152

Epoch: 5| Step: 1
Training loss: 2.0002341270446777
Validation loss: 2.151153087615967

Epoch: 5| Step: 2
Training loss: 1.863124132156372
Validation loss: 2.2018357813358307

Epoch: 5| Step: 3
Training loss: 1.3573448657989502
Validation loss: 2.1031632075707116

Epoch: 5| Step: 4
Training loss: 1.2721984386444092
Validation loss: 2.1490719467401505

Epoch: 5| Step: 5
Training loss: 1.1142094135284424
Validation loss: 2.1812253097693124

Epoch: 5| Step: 6
Training loss: 1.406380295753479
Validation loss: 2.162006437778473

Epoch: 5| Step: 7
Training loss: 1.0825254917144775
Validation loss: 2.1893353313207626

Epoch: 5| Step: 8
Training loss: 1.0652801990509033
Validation loss: 2.2222224374612174

Epoch: 5| Step: 9
Training loss: 2.247004747390747
Validation loss: 2.1521052370468774

Epoch: 5| Step: 10
Training loss: 1.2371677160263062
Validation loss: 2.2360496868689856

Epoch: 5| Step: 11
Training loss: 1.04859459400177
Validation loss: 2.2476250181595483

Epoch: 151| Step: 0
Training loss: 2.1977920532226562
Validation loss: 2.2452123363812766

Epoch: 5| Step: 1
Training loss: 1.4625297784805298
Validation loss: 2.293533464272817

Epoch: 5| Step: 2
Training loss: 1.0903130769729614
Validation loss: 2.307501326004664

Epoch: 5| Step: 3
Training loss: 1.4184000492095947
Validation loss: 2.258394201596578

Epoch: 5| Step: 4
Training loss: 1.5981749296188354
Validation loss: 2.2666680117448172

Epoch: 5| Step: 5
Training loss: 1.067856788635254
Validation loss: 2.2111725906531015

Epoch: 5| Step: 6
Training loss: 2.1466808319091797
Validation loss: 2.1578677048285804

Epoch: 5| Step: 7
Training loss: 1.5116252899169922
Validation loss: 2.216376086076101

Epoch: 5| Step: 8
Training loss: 1.3070460557937622
Validation loss: 2.208204304178556

Epoch: 5| Step: 9
Training loss: 1.3414100408554077
Validation loss: 2.2195556362469993

Epoch: 5| Step: 10
Training loss: 1.7219127416610718
Validation loss: 2.267893135547638

Epoch: 5| Step: 11
Training loss: 0.8911783695220947
Validation loss: 2.2054420709609985

Epoch: 152| Step: 0
Training loss: 1.673034429550171
Validation loss: 2.157948980728785

Epoch: 5| Step: 1
Training loss: 2.0979461669921875
Validation loss: 2.163696587085724

Epoch: 5| Step: 2
Training loss: 1.7083759307861328
Validation loss: 2.206269015868505

Epoch: 5| Step: 3
Training loss: 1.165827751159668
Validation loss: 2.206336905558904

Epoch: 5| Step: 4
Training loss: 1.0020397901535034
Validation loss: 2.1679129898548126

Epoch: 5| Step: 5
Training loss: 1.6511024236679077
Validation loss: 2.1731482297182083

Epoch: 5| Step: 6
Training loss: 1.2835290431976318
Validation loss: 2.16583381096522

Epoch: 5| Step: 7
Training loss: 1.8374744653701782
Validation loss: 2.180374100804329

Epoch: 5| Step: 8
Training loss: 1.5539391040802002
Validation loss: 2.195990135272344

Epoch: 5| Step: 9
Training loss: 0.9467002153396606
Validation loss: 2.218608245253563

Epoch: 5| Step: 10
Training loss: 1.7021284103393555
Validation loss: 2.257541313767433

Epoch: 5| Step: 11
Training loss: 0.4534372091293335
Validation loss: 2.190288151303927

Epoch: 153| Step: 0
Training loss: 1.5803298950195312
Validation loss: 2.2071501314640045

Epoch: 5| Step: 1
Training loss: 1.538691520690918
Validation loss: 2.197959537307421

Epoch: 5| Step: 2
Training loss: 1.8799612522125244
Validation loss: 2.2042451401551566

Epoch: 5| Step: 3
Training loss: 1.9121825695037842
Validation loss: 2.1817445357640586

Epoch: 5| Step: 4
Training loss: 1.4725168943405151
Validation loss: 2.211139291524887

Epoch: 5| Step: 5
Training loss: 1.0095072984695435
Validation loss: 2.2199468115965524

Epoch: 5| Step: 6
Training loss: 1.5734893083572388
Validation loss: 2.2065691153208413

Epoch: 5| Step: 7
Training loss: 1.6027793884277344
Validation loss: 2.1679547280073166

Epoch: 5| Step: 8
Training loss: 1.322411298751831
Validation loss: 2.1976896077394485

Epoch: 5| Step: 9
Training loss: 1.665043830871582
Validation loss: 2.1588069597880044

Epoch: 5| Step: 10
Training loss: 1.296376347541809
Validation loss: 2.1840590288241706

Epoch: 5| Step: 11
Training loss: 0.8157812356948853
Validation loss: 2.1566895047823587

Epoch: 154| Step: 0
Training loss: 1.4098070859909058
Validation loss: 2.17960195740064

Epoch: 5| Step: 1
Training loss: 2.1194252967834473
Validation loss: 2.1438809831937156

Epoch: 5| Step: 2
Training loss: 1.4651451110839844
Validation loss: 2.1946898301442466

Epoch: 5| Step: 3
Training loss: 1.4085180759429932
Validation loss: 2.2294269055128098

Epoch: 5| Step: 4
Training loss: 1.3717997074127197
Validation loss: 2.2036662250757217

Epoch: 5| Step: 5
Training loss: 1.5823724269866943
Validation loss: 2.2450544834136963

Epoch: 5| Step: 6
Training loss: 1.6751232147216797
Validation loss: 2.148728961745898

Epoch: 5| Step: 7
Training loss: 1.3428192138671875
Validation loss: 2.275746504465739

Epoch: 5| Step: 8
Training loss: 1.2857229709625244
Validation loss: 2.2080600609381995

Epoch: 5| Step: 9
Training loss: 1.4650585651397705
Validation loss: 2.1557668149471283

Epoch: 5| Step: 10
Training loss: 1.154165506362915
Validation loss: 2.188138301173846

Epoch: 5| Step: 11
Training loss: 2.629621982574463
Validation loss: 2.185989444454511

Epoch: 155| Step: 0
Training loss: 1.7950960397720337
Validation loss: 2.187357177337011

Epoch: 5| Step: 1
Training loss: 1.1115851402282715
Validation loss: 2.1765383084615073

Epoch: 5| Step: 2
Training loss: 1.74759042263031
Validation loss: 2.1835156430800757

Epoch: 5| Step: 3
Training loss: 1.660240888595581
Validation loss: 2.1645636012156806

Epoch: 5| Step: 4
Training loss: 1.5255765914916992
Validation loss: 2.178317606449127

Epoch: 5| Step: 5
Training loss: 1.0443289279937744
Validation loss: 2.1686607201894126

Epoch: 5| Step: 6
Training loss: 1.490739345550537
Validation loss: 2.162282387415568

Epoch: 5| Step: 7
Training loss: 1.2072137594223022
Validation loss: 2.162264813979467

Epoch: 5| Step: 8
Training loss: 1.477996826171875
Validation loss: 2.1929574807484946

Epoch: 5| Step: 9
Training loss: 1.5463110208511353
Validation loss: 2.187654713789622

Epoch: 5| Step: 10
Training loss: 1.5256496667861938
Validation loss: 2.2181030213832855

Epoch: 5| Step: 11
Training loss: 1.5353575944900513
Validation loss: 2.17600779235363

Epoch: 156| Step: 0
Training loss: 1.9754574298858643
Validation loss: 2.2509450217088065

Epoch: 5| Step: 1
Training loss: 1.257003903388977
Validation loss: 2.2191520829995475

Epoch: 5| Step: 2
Training loss: 1.3397079706192017
Validation loss: 2.1917875905831656

Epoch: 5| Step: 3
Training loss: 1.773916482925415
Validation loss: 2.200782130161921

Epoch: 5| Step: 4
Training loss: 1.7479438781738281
Validation loss: 2.1785933524370193

Epoch: 5| Step: 5
Training loss: 1.7652599811553955
Validation loss: 2.1856584548950195

Epoch: 5| Step: 6
Training loss: 1.6003414392471313
Validation loss: 2.181530311703682

Epoch: 5| Step: 7
Training loss: 1.3465096950531006
Validation loss: 2.196323518951734

Epoch: 5| Step: 8
Training loss: 0.920804500579834
Validation loss: 2.194046209255854

Epoch: 5| Step: 9
Training loss: 1.8450161218643188
Validation loss: 2.134648566444715

Epoch: 5| Step: 10
Training loss: 0.6618464589118958
Validation loss: 2.1915982166926065

Epoch: 5| Step: 11
Training loss: 1.5464909076690674
Validation loss: 2.1677842338879905

Epoch: 157| Step: 0
Training loss: 1.685547113418579
Validation loss: 2.1860020657380423

Epoch: 5| Step: 1
Training loss: 1.3361637592315674
Validation loss: 2.1587128241856894

Epoch: 5| Step: 2
Training loss: 1.456906795501709
Validation loss: 2.2494726876417794

Epoch: 5| Step: 3
Training loss: 0.9179298281669617
Validation loss: 2.147491455078125

Epoch: 5| Step: 4
Training loss: 1.9110914468765259
Validation loss: 2.2407704343398414

Epoch: 5| Step: 5
Training loss: 1.5925017595291138
Validation loss: 2.2404488623142242

Epoch: 5| Step: 6
Training loss: 1.2880796194076538
Validation loss: 2.214363137880961

Epoch: 5| Step: 7
Training loss: 1.1860730648040771
Validation loss: 2.1762541433175406

Epoch: 5| Step: 8
Training loss: 1.518115758895874
Validation loss: 2.1844799518585205

Epoch: 5| Step: 9
Training loss: 1.792132019996643
Validation loss: 2.1389629940191903

Epoch: 5| Step: 10
Training loss: 1.4641629457473755
Validation loss: 2.199490030606588

Epoch: 5| Step: 11
Training loss: 2.1643970012664795
Validation loss: 2.2228414565324783

Epoch: 158| Step: 0
Training loss: 1.7683197259902954
Validation loss: 2.181353588898977

Epoch: 5| Step: 1
Training loss: 1.2544583082199097
Validation loss: 2.137195368607839

Epoch: 5| Step: 2
Training loss: 1.6441714763641357
Validation loss: 2.1761864721775055

Epoch: 5| Step: 3
Training loss: 1.5425574779510498
Validation loss: 2.233318199714025

Epoch: 5| Step: 4
Training loss: 1.54032301902771
Validation loss: 2.128124490380287

Epoch: 5| Step: 5
Training loss: 1.3633136749267578
Validation loss: 2.1231554796298346

Epoch: 5| Step: 6
Training loss: 1.4461208581924438
Validation loss: 2.2021139512459436

Epoch: 5| Step: 7
Training loss: 1.2136958837509155
Validation loss: 2.1812678972880044

Epoch: 5| Step: 8
Training loss: 1.8001136779785156
Validation loss: 2.155647168556849

Epoch: 5| Step: 9
Training loss: 1.588819146156311
Validation loss: 2.2122217963139215

Epoch: 5| Step: 10
Training loss: 1.280661940574646
Validation loss: 2.182625338435173

Epoch: 5| Step: 11
Training loss: 0.9658454656600952
Validation loss: 2.1652438938617706

Epoch: 159| Step: 0
Training loss: 0.6987918615341187
Validation loss: 2.255375415086746

Epoch: 5| Step: 1
Training loss: 1.548015832901001
Validation loss: 2.245429108540217

Epoch: 5| Step: 2
Training loss: 1.5600285530090332
Validation loss: 2.198452264070511

Epoch: 5| Step: 3
Training loss: 1.5845801830291748
Validation loss: 2.1597080628077188

Epoch: 5| Step: 4
Training loss: 2.114500045776367
Validation loss: 2.1681393533945084

Epoch: 5| Step: 5
Training loss: 1.6345552206039429
Validation loss: 2.1646120846271515

Epoch: 5| Step: 6
Training loss: 1.4849357604980469
Validation loss: 2.113080640633901

Epoch: 5| Step: 7
Training loss: 1.5994372367858887
Validation loss: 2.128848815957705

Epoch: 5| Step: 8
Training loss: 1.2302435636520386
Validation loss: 2.143137435118357

Epoch: 5| Step: 9
Training loss: 1.3917638063430786
Validation loss: 2.1591733545064926

Epoch: 5| Step: 10
Training loss: 1.5051600933074951
Validation loss: 2.1077715158462524

Epoch: 5| Step: 11
Training loss: 0.7028434872627258
Validation loss: 2.181408479809761

Epoch: 160| Step: 0
Training loss: 1.285218596458435
Validation loss: 2.2208495487769446

Epoch: 5| Step: 1
Training loss: 1.59043288230896
Validation loss: 2.201391597588857

Epoch: 5| Step: 2
Training loss: 1.649237871170044
Validation loss: 2.22501610716184

Epoch: 5| Step: 3
Training loss: 1.4919793605804443
Validation loss: 2.2136172403891883

Epoch: 5| Step: 4
Training loss: 1.3140966892242432
Validation loss: 2.248175630966822

Epoch: 5| Step: 5
Training loss: 1.1598187685012817
Validation loss: 2.2094356367985406

Epoch: 5| Step: 6
Training loss: 1.1028660535812378
Validation loss: 2.198538954059283

Epoch: 5| Step: 7
Training loss: 1.4374629259109497
Validation loss: 2.1477873623371124

Epoch: 5| Step: 8
Training loss: 1.764243721961975
Validation loss: 2.1573182543118796

Epoch: 5| Step: 9
Training loss: 1.5326032638549805
Validation loss: 2.159548804163933

Epoch: 5| Step: 10
Training loss: 1.2655713558197021
Validation loss: 2.1784170965353646

Epoch: 5| Step: 11
Training loss: 2.870032787322998
Validation loss: 2.1327025393644967

Epoch: 161| Step: 0
Training loss: 1.5400387048721313
Validation loss: 2.176634053389231

Epoch: 5| Step: 1
Training loss: 1.2366507053375244
Validation loss: 2.1714187314112983

Epoch: 5| Step: 2
Training loss: 1.2839641571044922
Validation loss: 2.1903935919205346

Epoch: 5| Step: 3
Training loss: 1.3073716163635254
Validation loss: 2.194077342748642

Epoch: 5| Step: 4
Training loss: 1.7728893756866455
Validation loss: 2.166878571112951

Epoch: 5| Step: 5
Training loss: 1.212078332901001
Validation loss: 2.18512254456679

Epoch: 5| Step: 6
Training loss: 0.7934901714324951
Validation loss: 2.23069300254186

Epoch: 5| Step: 7
Training loss: 1.9675871133804321
Validation loss: 2.2330680241187415

Epoch: 5| Step: 8
Training loss: 1.298499345779419
Validation loss: 2.204142207900683

Epoch: 5| Step: 9
Training loss: 2.0140912532806396
Validation loss: 2.2008195221424103

Epoch: 5| Step: 10
Training loss: 2.016280174255371
Validation loss: 2.233631561199824

Epoch: 5| Step: 11
Training loss: 0.5560932159423828
Validation loss: 2.2111880828936896

Epoch: 162| Step: 0
Training loss: 0.5742070078849792
Validation loss: 2.1889172345399857

Epoch: 5| Step: 1
Training loss: 1.4446666240692139
Validation loss: 2.242031236489614

Epoch: 5| Step: 2
Training loss: 1.9237931966781616
Validation loss: 2.168129508694013

Epoch: 5| Step: 3
Training loss: 2.193915367126465
Validation loss: 2.134295403957367

Epoch: 5| Step: 4
Training loss: 1.9244582653045654
Validation loss: 2.136122445265452

Epoch: 5| Step: 5
Training loss: 1.3611221313476562
Validation loss: 2.210453152656555

Epoch: 5| Step: 6
Training loss: 1.4176912307739258
Validation loss: 2.173392027616501

Epoch: 5| Step: 7
Training loss: 0.8244741559028625
Validation loss: 2.1593368351459503

Epoch: 5| Step: 8
Training loss: 1.120672345161438
Validation loss: 2.18684713045756

Epoch: 5| Step: 9
Training loss: 1.1225754022598267
Validation loss: 2.174879233042399

Epoch: 5| Step: 10
Training loss: 1.7171344757080078
Validation loss: 2.230118920405706

Epoch: 5| Step: 11
Training loss: 1.9857370853424072
Validation loss: 2.209310998519262

Epoch: 163| Step: 0
Training loss: 1.3233742713928223
Validation loss: 2.2433650890986123

Epoch: 5| Step: 1
Training loss: 1.7373079061508179
Validation loss: 2.1207443873087564

Epoch: 5| Step: 2
Training loss: 1.5937706232070923
Validation loss: 2.1440504640340805

Epoch: 5| Step: 3
Training loss: 1.1029961109161377
Validation loss: 2.176534727215767

Epoch: 5| Step: 4
Training loss: 1.191170334815979
Validation loss: 2.1290000130732856

Epoch: 5| Step: 5
Training loss: 1.152877926826477
Validation loss: 2.1802390664815903

Epoch: 5| Step: 6
Training loss: 1.5626024007797241
Validation loss: 2.2136295586824417

Epoch: 5| Step: 7
Training loss: 1.5347318649291992
Validation loss: 2.170246491829554

Epoch: 5| Step: 8
Training loss: 1.4045313596725464
Validation loss: 2.1500053455432258

Epoch: 5| Step: 9
Training loss: 1.7988255023956299
Validation loss: 2.1616494556268058

Epoch: 5| Step: 10
Training loss: 1.2450902462005615
Validation loss: 2.1702946374813714

Epoch: 5| Step: 11
Training loss: 2.1239027976989746
Validation loss: 2.16849451760451

Epoch: 164| Step: 0
Training loss: 1.0211495161056519
Validation loss: 2.213076338171959

Epoch: 5| Step: 1
Training loss: 1.6065261363983154
Validation loss: 2.1420287986596427

Epoch: 5| Step: 2
Training loss: 2.310309648513794
Validation loss: 2.1738425294558206

Epoch: 5| Step: 3
Training loss: 1.3064969778060913
Validation loss: 2.2128216326236725

Epoch: 5| Step: 4
Training loss: 1.2188631296157837
Validation loss: 2.2100441455841064

Epoch: 5| Step: 5
Training loss: 1.4951146841049194
Validation loss: 2.2165251970291138

Epoch: 5| Step: 6
Training loss: 1.39285147190094
Validation loss: 2.1834440330664315

Epoch: 5| Step: 7
Training loss: 1.5478676557540894
Validation loss: 2.1626595854759216

Epoch: 5| Step: 8
Training loss: 1.0464906692504883
Validation loss: 2.205178439617157

Epoch: 5| Step: 9
Training loss: 1.2867023944854736
Validation loss: 2.178944488366445

Epoch: 5| Step: 10
Training loss: 1.3939367532730103
Validation loss: 2.219144264856974

Epoch: 5| Step: 11
Training loss: 1.3072614669799805
Validation loss: 2.2298479477564492

Epoch: 165| Step: 0
Training loss: 1.515805959701538
Validation loss: 2.2210114200909934

Epoch: 5| Step: 1
Training loss: 1.1326686143875122
Validation loss: 2.216891661286354

Epoch: 5| Step: 2
Training loss: 2.4413015842437744
Validation loss: 2.16990797718366

Epoch: 5| Step: 3
Training loss: 1.5033905506134033
Validation loss: 2.2824462254842124

Epoch: 5| Step: 4
Training loss: 1.1334306001663208
Validation loss: 2.169879913330078

Epoch: 5| Step: 5
Training loss: 1.285631775856018
Validation loss: 2.1996610164642334

Epoch: 5| Step: 6
Training loss: 1.6882705688476562
Validation loss: 2.2156470914681754

Epoch: 5| Step: 7
Training loss: 1.2281849384307861
Validation loss: 2.1599911898374557

Epoch: 5| Step: 8
Training loss: 0.9712575674057007
Validation loss: 2.169745604197184

Epoch: 5| Step: 9
Training loss: 1.2925854921340942
Validation loss: 2.192703425884247

Epoch: 5| Step: 10
Training loss: 1.0931113958358765
Validation loss: 2.142796670397123

Epoch: 5| Step: 11
Training loss: 2.5609116554260254
Validation loss: 2.19515368839105

Epoch: 166| Step: 0
Training loss: 1.7643553018569946
Validation loss: 2.212032382686933

Epoch: 5| Step: 1
Training loss: 1.0238783359527588
Validation loss: 2.210936595996221

Epoch: 5| Step: 2
Training loss: 0.8888095021247864
Validation loss: 2.211844816803932

Epoch: 5| Step: 3
Training loss: 1.7852897644042969
Validation loss: 2.199182386199633

Epoch: 5| Step: 4
Training loss: 1.3170700073242188
Validation loss: 2.1634929378827414

Epoch: 5| Step: 5
Training loss: 1.396024227142334
Validation loss: 2.217082699139913

Epoch: 5| Step: 6
Training loss: 1.0810773372650146
Validation loss: 2.178293764591217

Epoch: 5| Step: 7
Training loss: 1.3027057647705078
Validation loss: 2.236784726381302

Epoch: 5| Step: 8
Training loss: 1.4582182168960571
Validation loss: 2.2151232808828354

Epoch: 5| Step: 9
Training loss: 1.7896804809570312
Validation loss: 2.210510695974032

Epoch: 5| Step: 10
Training loss: 1.3798089027404785
Validation loss: 2.194213012854258

Epoch: 5| Step: 11
Training loss: 1.5111324787139893
Validation loss: 2.185129920641581

Epoch: 167| Step: 0
Training loss: 1.3304990530014038
Validation loss: 2.208534394701322

Epoch: 5| Step: 1
Training loss: 1.5178194046020508
Validation loss: 2.13703091442585

Epoch: 5| Step: 2
Training loss: 1.7895698547363281
Validation loss: 2.1571843971808753

Epoch: 5| Step: 3
Training loss: 1.4688061475753784
Validation loss: 2.1678493122259774

Epoch: 5| Step: 4
Training loss: 1.9918491840362549
Validation loss: 2.1206360260645547

Epoch: 5| Step: 5
Training loss: 1.3997538089752197
Validation loss: 2.1718403548002243

Epoch: 5| Step: 6
Training loss: 0.6418509483337402
Validation loss: 2.204544797539711

Epoch: 5| Step: 7
Training loss: 1.4196889400482178
Validation loss: 2.2323190569877625

Epoch: 5| Step: 8
Training loss: 1.2036774158477783
Validation loss: 2.2374828855196633

Epoch: 5| Step: 9
Training loss: 1.0824053287506104
Validation loss: 2.2235652655363083

Epoch: 5| Step: 10
Training loss: 2.0073447227478027
Validation loss: 2.2071150044600167

Epoch: 5| Step: 11
Training loss: 1.8418755531311035
Validation loss: 2.258935143550237

Epoch: 168| Step: 0
Training loss: 1.0616720914840698
Validation loss: 2.179606109857559

Epoch: 5| Step: 1
Training loss: 0.9036609530448914
Validation loss: 2.220413103699684

Epoch: 5| Step: 2
Training loss: 1.4324980974197388
Validation loss: 2.221741626660029

Epoch: 5| Step: 3
Training loss: 1.2934578657150269
Validation loss: 2.213675210873286

Epoch: 5| Step: 4
Training loss: 1.8085473775863647
Validation loss: 2.162570675214132

Epoch: 5| Step: 5
Training loss: 1.2705535888671875
Validation loss: 2.141012320915858

Epoch: 5| Step: 6
Training loss: 1.5864731073379517
Validation loss: 2.219564745823542

Epoch: 5| Step: 7
Training loss: 1.3277695178985596
Validation loss: 2.211766481399536

Epoch: 5| Step: 8
Training loss: 1.5741773843765259
Validation loss: 2.2527032494544983

Epoch: 5| Step: 9
Training loss: 1.7789218425750732
Validation loss: 2.1783054918050766

Epoch: 5| Step: 10
Training loss: 1.0257346630096436
Validation loss: 2.2279600302378335

Epoch: 5| Step: 11
Training loss: 0.9682819247245789
Validation loss: 2.3447586993376413

Epoch: 169| Step: 0
Training loss: 1.1742757558822632
Validation loss: 2.2010072668393454

Epoch: 5| Step: 1
Training loss: 1.8370609283447266
Validation loss: 2.195591097076734

Epoch: 5| Step: 2
Training loss: 1.6105066537857056
Validation loss: 2.169783686598142

Epoch: 5| Step: 3
Training loss: 1.6296488046646118
Validation loss: 2.1977719366550446

Epoch: 5| Step: 4
Training loss: 1.7235000133514404
Validation loss: 2.1733601142962775

Epoch: 5| Step: 5
Training loss: 0.9415366053581238
Validation loss: 2.2086720764636993

Epoch: 5| Step: 6
Training loss: 0.9446686506271362
Validation loss: 2.172190139691035

Epoch: 5| Step: 7
Training loss: 1.2446479797363281
Validation loss: 2.175687422355016

Epoch: 5| Step: 8
Training loss: 1.2475144863128662
Validation loss: 2.211555629968643

Epoch: 5| Step: 9
Training loss: 0.9069132804870605
Validation loss: 2.1692327658335366

Epoch: 5| Step: 10
Training loss: 1.7349739074707031
Validation loss: 2.1299623449643454

Epoch: 5| Step: 11
Training loss: 2.177751064300537
Validation loss: 2.184117406606674

Epoch: 170| Step: 0
Training loss: 1.2410428524017334
Validation loss: 2.1891241470972695

Epoch: 5| Step: 1
Training loss: 1.2587220668792725
Validation loss: 2.212919776638349

Epoch: 5| Step: 2
Training loss: 1.5540516376495361
Validation loss: 2.227017973860105

Epoch: 5| Step: 3
Training loss: 1.5862276554107666
Validation loss: 2.2125775863726935

Epoch: 5| Step: 4
Training loss: 1.1157357692718506
Validation loss: 2.197036638855934

Epoch: 5| Step: 5
Training loss: 1.5618469715118408
Validation loss: 2.20943146944046

Epoch: 5| Step: 6
Training loss: 0.8796510696411133
Validation loss: 2.2073967854181924

Epoch: 5| Step: 7
Training loss: 2.0118963718414307
Validation loss: 2.1388631612062454

Epoch: 5| Step: 8
Training loss: 0.8619222640991211
Validation loss: 2.120137338836988

Epoch: 5| Step: 9
Training loss: 1.3888792991638184
Validation loss: 2.195041080315908

Epoch: 5| Step: 10
Training loss: 1.3794902563095093
Validation loss: 2.1433865328629813

Epoch: 5| Step: 11
Training loss: 3.9869585037231445
Validation loss: 2.1984533816576004

Epoch: 171| Step: 0
Training loss: 1.0360908508300781
Validation loss: 2.2267721593379974

Epoch: 5| Step: 1
Training loss: 1.6307551860809326
Validation loss: 2.184079090754191

Epoch: 5| Step: 2
Training loss: 1.1153980493545532
Validation loss: 2.1629108985265098

Epoch: 5| Step: 3
Training loss: 1.101889967918396
Validation loss: 2.212634136279424

Epoch: 5| Step: 4
Training loss: 0.8681222200393677
Validation loss: 2.211435233553251

Epoch: 5| Step: 5
Training loss: 1.951136827468872
Validation loss: 2.1729378451903663

Epoch: 5| Step: 6
Training loss: 1.5280606746673584
Validation loss: 2.202473188440005

Epoch: 5| Step: 7
Training loss: 1.2680079936981201
Validation loss: 2.1939772069454193

Epoch: 5| Step: 8
Training loss: 1.1601142883300781
Validation loss: 2.207814539472262

Epoch: 5| Step: 9
Training loss: 1.3224583864212036
Validation loss: 2.193213368455569

Epoch: 5| Step: 10
Training loss: 1.4203459024429321
Validation loss: 2.2096145202716193

Epoch: 5| Step: 11
Training loss: 2.248917579650879
Validation loss: 2.1643622567256293

Epoch: 172| Step: 0
Training loss: 1.5448620319366455
Validation loss: 2.2325189312299094

Epoch: 5| Step: 1
Training loss: 1.6181472539901733
Validation loss: 2.1617631365855536

Epoch: 5| Step: 2
Training loss: 0.8905926942825317
Validation loss: 2.225874960422516

Epoch: 5| Step: 3
Training loss: 1.6209170818328857
Validation loss: 2.1612578382094703

Epoch: 5| Step: 4
Training loss: 1.0599124431610107
Validation loss: 2.198693096637726

Epoch: 5| Step: 5
Training loss: 1.2808449268341064
Validation loss: 2.2037589897712073

Epoch: 5| Step: 6
Training loss: 1.9291824102401733
Validation loss: 2.2201735377311707

Epoch: 5| Step: 7
Training loss: 0.615379810333252
Validation loss: 2.2700942953427634

Epoch: 5| Step: 8
Training loss: 1.4798519611358643
Validation loss: 2.1930456260840097

Epoch: 5| Step: 9
Training loss: 1.5458042621612549
Validation loss: 2.222423175970713

Epoch: 5| Step: 10
Training loss: 1.162253975868225
Validation loss: 2.2988820175329843

Epoch: 5| Step: 11
Training loss: 1.6836529970169067
Validation loss: 2.2555706103642783

Epoch: 173| Step: 0
Training loss: 1.350414514541626
Validation loss: 2.2355181078116098

Epoch: 5| Step: 1
Training loss: 1.1162309646606445
Validation loss: 2.2152234266201654

Epoch: 5| Step: 2
Training loss: 1.2292149066925049
Validation loss: 2.1923572719097137

Epoch: 5| Step: 3
Training loss: 1.2560083866119385
Validation loss: 2.169669439395269

Epoch: 5| Step: 4
Training loss: 1.0257678031921387
Validation loss: 2.1617238322893777

Epoch: 5| Step: 5
Training loss: 2.2220890522003174
Validation loss: 2.1862950871388116

Epoch: 5| Step: 6
Training loss: 1.3240422010421753
Validation loss: 2.123668144146601

Epoch: 5| Step: 7
Training loss: 1.2575913667678833
Validation loss: 2.160644749800364

Epoch: 5| Step: 8
Training loss: 1.236619234085083
Validation loss: 2.1786731829245887

Epoch: 5| Step: 9
Training loss: 1.223175048828125
Validation loss: 2.1831349233786264

Epoch: 5| Step: 10
Training loss: 1.0344401597976685
Validation loss: 2.182214712103208

Epoch: 5| Step: 11
Training loss: 1.0227241516113281
Validation loss: 2.1701348771651587

Epoch: 174| Step: 0
Training loss: 1.762711524963379
Validation loss: 2.153005927801132

Epoch: 5| Step: 1
Training loss: 0.9909808039665222
Validation loss: 2.2230896403392157

Epoch: 5| Step: 2
Training loss: 1.5707167387008667
Validation loss: 2.2043781330188117

Epoch: 5| Step: 3
Training loss: 1.5450080633163452
Validation loss: 2.169160192211469

Epoch: 5| Step: 4
Training loss: 1.4973955154418945
Validation loss: 2.2491635978221893

Epoch: 5| Step: 5
Training loss: 1.2724244594573975
Validation loss: 2.2139730751514435

Epoch: 5| Step: 6
Training loss: 1.5805598497390747
Validation loss: 2.180344839890798

Epoch: 5| Step: 7
Training loss: 1.275232195854187
Validation loss: 2.1547128160794577

Epoch: 5| Step: 8
Training loss: 1.4561811685562134
Validation loss: 2.180948610107104

Epoch: 5| Step: 9
Training loss: 0.9909886121749878
Validation loss: 2.142072935899099

Epoch: 5| Step: 10
Training loss: 0.8073194622993469
Validation loss: 2.2387348214785256

Epoch: 5| Step: 11
Training loss: 0.7541505694389343
Validation loss: 2.1371988356113434

Epoch: 175| Step: 0
Training loss: 0.961197018623352
Validation loss: 2.1938204169273376

Epoch: 5| Step: 1
Training loss: 1.6574556827545166
Validation loss: 2.1681836197773614

Epoch: 5| Step: 2
Training loss: 1.2324899435043335
Validation loss: 2.170596624414126

Epoch: 5| Step: 3
Training loss: 1.334816813468933
Validation loss: 2.17900957663854

Epoch: 5| Step: 4
Training loss: 0.844002366065979
Validation loss: 2.2154365330934525

Epoch: 5| Step: 5
Training loss: 1.2655103206634521
Validation loss: 2.2028672248125076

Epoch: 5| Step: 6
Training loss: 1.4212820529937744
Validation loss: 2.170963764190674

Epoch: 5| Step: 7
Training loss: 1.8061397075653076
Validation loss: 2.1630294620990753

Epoch: 5| Step: 8
Training loss: 1.1734110116958618
Validation loss: 2.2136809726556144

Epoch: 5| Step: 9
Training loss: 1.4347431659698486
Validation loss: 2.21993354956309

Epoch: 5| Step: 10
Training loss: 1.6180717945098877
Validation loss: 2.221342513958613

Epoch: 5| Step: 11
Training loss: 0.9352610111236572
Validation loss: 2.248651643594106

Epoch: 176| Step: 0
Training loss: 1.1828244924545288
Validation loss: 2.2796614517768226

Epoch: 5| Step: 1
Training loss: 1.0029523372650146
Validation loss: 2.2669483423233032

Epoch: 5| Step: 2
Training loss: 1.3039628267288208
Validation loss: 2.2057588448127112

Epoch: 5| Step: 3
Training loss: 1.7691081762313843
Validation loss: 2.1721039911111197

Epoch: 5| Step: 4
Training loss: 1.2052191495895386
Validation loss: 2.206830541292826

Epoch: 5| Step: 5
Training loss: 0.9258821606636047
Validation loss: 2.217111279567083

Epoch: 5| Step: 6
Training loss: 1.5372692346572876
Validation loss: 2.229360659917196

Epoch: 5| Step: 7
Training loss: 1.609678864479065
Validation loss: 2.181087851524353

Epoch: 5| Step: 8
Training loss: 1.349761724472046
Validation loss: 2.144062956174215

Epoch: 5| Step: 9
Training loss: 1.6179994344711304
Validation loss: 2.128800963362058

Epoch: 5| Step: 10
Training loss: 1.0041791200637817
Validation loss: 2.177336980899175

Epoch: 5| Step: 11
Training loss: 1.846318244934082
Validation loss: 2.1335268119970956

Epoch: 177| Step: 0
Training loss: 1.7015180587768555
Validation loss: 2.126901318629583

Epoch: 5| Step: 1
Training loss: 1.4310989379882812
Validation loss: 2.2059139907360077

Epoch: 5| Step: 2
Training loss: 0.9995788335800171
Validation loss: 2.237447957197825

Epoch: 5| Step: 3
Training loss: 1.201838731765747
Validation loss: 2.251671016216278

Epoch: 5| Step: 4
Training loss: 1.4598029851913452
Validation loss: 2.2246722678343454

Epoch: 5| Step: 5
Training loss: 1.2053825855255127
Validation loss: 2.1702464471260705

Epoch: 5| Step: 6
Training loss: 1.6885324716567993
Validation loss: 2.177092726031939

Epoch: 5| Step: 7
Training loss: 0.9630998373031616
Validation loss: 2.2068129579226174

Epoch: 5| Step: 8
Training loss: 1.1410757303237915
Validation loss: 2.217705398797989

Epoch: 5| Step: 9
Training loss: 1.2256526947021484
Validation loss: 2.1682105163733163

Epoch: 5| Step: 10
Training loss: 1.3755348920822144
Validation loss: 2.1376797556877136

Epoch: 5| Step: 11
Training loss: 0.9929341077804565
Validation loss: 2.194453994433085

Epoch: 178| Step: 0
Training loss: 1.1593878269195557
Validation loss: 2.2121757616599402

Epoch: 5| Step: 1
Training loss: 1.2306489944458008
Validation loss: 2.2194100519021354

Epoch: 5| Step: 2
Training loss: 0.9755817651748657
Validation loss: 2.1469389448563256

Epoch: 5| Step: 3
Training loss: 1.2876250743865967
Validation loss: 2.25285538037618

Epoch: 5| Step: 4
Training loss: 1.3771110773086548
Validation loss: 2.20079239209493

Epoch: 5| Step: 5
Training loss: 2.1430351734161377
Validation loss: 2.246294140815735

Epoch: 5| Step: 6
Training loss: 0.7036194801330566
Validation loss: 2.260955994327863

Epoch: 5| Step: 7
Training loss: 1.609811544418335
Validation loss: 2.1989768544832864

Epoch: 5| Step: 8
Training loss: 1.0422511100769043
Validation loss: 2.157278537750244

Epoch: 5| Step: 9
Training loss: 1.1558595895767212
Validation loss: 2.211025337378184

Epoch: 5| Step: 10
Training loss: 1.4646222591400146
Validation loss: 2.1991487244764962

Epoch: 5| Step: 11
Training loss: 1.7240612506866455
Validation loss: 2.217718462149302

Epoch: 179| Step: 0
Training loss: 0.9624677896499634
Validation loss: 2.2670958240826926

Epoch: 5| Step: 1
Training loss: 1.565716028213501
Validation loss: 2.1757915318012238

Epoch: 5| Step: 2
Training loss: 0.955173671245575
Validation loss: 2.219568113485972

Epoch: 5| Step: 3
Training loss: 1.2711423635482788
Validation loss: 2.166317939758301

Epoch: 5| Step: 4
Training loss: 1.2711658477783203
Validation loss: 2.172006592154503

Epoch: 5| Step: 5
Training loss: 1.186849594116211
Validation loss: 2.2270351548989615

Epoch: 5| Step: 6
Training loss: 1.0520074367523193
Validation loss: 2.189300388097763

Epoch: 5| Step: 7
Training loss: 1.315826416015625
Validation loss: 2.222400506337484

Epoch: 5| Step: 8
Training loss: 1.3241363763809204
Validation loss: 2.1751003662745156

Epoch: 5| Step: 9
Training loss: 1.7726268768310547
Validation loss: 2.139763668179512

Epoch: 5| Step: 10
Training loss: 1.164360761642456
Validation loss: 2.173093631863594

Epoch: 5| Step: 11
Training loss: 0.7044234871864319
Validation loss: 2.2138845523198447

Epoch: 180| Step: 0
Training loss: 1.3259021043777466
Validation loss: 2.149254987637202

Epoch: 5| Step: 1
Training loss: 0.9163223505020142
Validation loss: 2.1855861097574234

Epoch: 5| Step: 2
Training loss: 1.4367964267730713
Validation loss: 2.2122939229011536

Epoch: 5| Step: 3
Training loss: 1.113318920135498
Validation loss: 2.2215435206890106

Epoch: 5| Step: 4
Training loss: 1.2112189531326294
Validation loss: 2.2207269420226416

Epoch: 5| Step: 5
Training loss: 0.9961234927177429
Validation loss: 2.2097581972678504

Epoch: 5| Step: 6
Training loss: 1.507808804512024
Validation loss: 2.1751515368620553

Epoch: 5| Step: 7
Training loss: 0.853164553642273
Validation loss: 2.1838503827651343

Epoch: 5| Step: 8
Training loss: 1.6717363595962524
Validation loss: 2.1997187634309134

Epoch: 5| Step: 9
Training loss: 0.7945825457572937
Validation loss: 2.192335138718287

Epoch: 5| Step: 10
Training loss: 1.9520397186279297
Validation loss: 2.1802470485369363

Epoch: 5| Step: 11
Training loss: 0.6974088549613953
Validation loss: 2.224597215652466

Epoch: 181| Step: 0
Training loss: 1.243524432182312
Validation loss: 2.1806883364915848

Epoch: 5| Step: 1
Training loss: 1.7752768993377686
Validation loss: 2.1993782371282578

Epoch: 5| Step: 2
Training loss: 1.3948445320129395
Validation loss: 2.1783772806326547

Epoch: 5| Step: 3
Training loss: 1.070804476737976
Validation loss: 2.2470649580160775

Epoch: 5| Step: 4
Training loss: 0.5780676603317261
Validation loss: 2.2659463733434677

Epoch: 5| Step: 5
Training loss: 0.9485131502151489
Validation loss: 2.2286863774061203

Epoch: 5| Step: 6
Training loss: 1.7090225219726562
Validation loss: 2.2535630762577057

Epoch: 5| Step: 7
Training loss: 1.6800161600112915
Validation loss: 2.22838061551253

Epoch: 5| Step: 8
Training loss: 1.2769231796264648
Validation loss: 2.1698010762532554

Epoch: 5| Step: 9
Training loss: 0.8932601809501648
Validation loss: 2.1977051198482513

Epoch: 5| Step: 10
Training loss: 1.0770920515060425
Validation loss: 2.2169588953256607

Epoch: 5| Step: 11
Training loss: 0.8506778478622437
Validation loss: 2.2010195602973304

Epoch: 182| Step: 0
Training loss: 1.1343082189559937
Validation loss: 2.1691611806551614

Epoch: 5| Step: 1
Training loss: 1.5750586986541748
Validation loss: 2.1861094534397125

Epoch: 5| Step: 2
Training loss: 0.753289520740509
Validation loss: 2.221325844526291

Epoch: 5| Step: 3
Training loss: 1.560315489768982
Validation loss: 2.2130663792292276

Epoch: 5| Step: 4
Training loss: 0.885750412940979
Validation loss: 2.214397499958674

Epoch: 5| Step: 5
Training loss: 1.270056962966919
Validation loss: 2.159450968106588

Epoch: 5| Step: 6
Training loss: 1.3878060579299927
Validation loss: 2.1990340799093246

Epoch: 5| Step: 7
Training loss: 1.366556167602539
Validation loss: 2.175576319297155

Epoch: 5| Step: 8
Training loss: 1.0482852458953857
Validation loss: 2.1869404266277948

Epoch: 5| Step: 9
Training loss: 1.5266085863113403
Validation loss: 2.170595278342565

Epoch: 5| Step: 10
Training loss: 1.1178977489471436
Validation loss: 2.212602660059929

Epoch: 5| Step: 11
Training loss: 0.5089631080627441
Validation loss: 2.1742303917805352

Epoch: 183| Step: 0
Training loss: 1.3802661895751953
Validation loss: 2.2038779258728027

Epoch: 5| Step: 1
Training loss: 1.2559112310409546
Validation loss: 2.232746789852778

Epoch: 5| Step: 2
Training loss: 1.0893183946609497
Validation loss: 2.2417433063189187

Epoch: 5| Step: 3
Training loss: 1.1295613050460815
Validation loss: 2.243496855099996

Epoch: 5| Step: 4
Training loss: 1.295851707458496
Validation loss: 2.185508355498314

Epoch: 5| Step: 5
Training loss: 1.2564181089401245
Validation loss: 2.2112964391708374

Epoch: 5| Step: 6
Training loss: 1.1925971508026123
Validation loss: 2.135345925887426

Epoch: 5| Step: 7
Training loss: 0.9251135587692261
Validation loss: 2.2259099384148917

Epoch: 5| Step: 8
Training loss: 1.7565053701400757
Validation loss: 2.2122761607170105

Epoch: 5| Step: 9
Training loss: 1.5071300268173218
Validation loss: 2.204353988170624

Epoch: 5| Step: 10
Training loss: 1.2836520671844482
Validation loss: 2.1783349414666495

Epoch: 5| Step: 11
Training loss: 1.095123529434204
Validation loss: 2.1863933006922402

Epoch: 184| Step: 0
Training loss: 1.1481539011001587
Validation loss: 2.248494361837705

Epoch: 5| Step: 1
Training loss: 1.161965012550354
Validation loss: 2.162686049938202

Epoch: 5| Step: 2
Training loss: 1.2906430959701538
Validation loss: 2.1638593872388205

Epoch: 5| Step: 3
Training loss: 1.3958169221878052
Validation loss: 2.220598171154658

Epoch: 5| Step: 4
Training loss: 1.2478488683700562
Validation loss: 2.2051114588975906

Epoch: 5| Step: 5
Training loss: 1.4682600498199463
Validation loss: 2.2007699062426886

Epoch: 5| Step: 6
Training loss: 0.6661154627799988
Validation loss: 2.1867349793513617

Epoch: 5| Step: 7
Training loss: 1.7472082376480103
Validation loss: 2.181744302312533

Epoch: 5| Step: 8
Training loss: 0.9178851246833801
Validation loss: 2.2221956054369607

Epoch: 5| Step: 9
Training loss: 0.8330260515213013
Validation loss: 2.211828346053759

Epoch: 5| Step: 10
Training loss: 1.6815979480743408
Validation loss: 2.144594192504883

Epoch: 5| Step: 11
Training loss: 1.3716083765029907
Validation loss: 2.2305312951405845

Epoch: 185| Step: 0
Training loss: 1.1242295503616333
Validation loss: 2.2070619066556296

Epoch: 5| Step: 1
Training loss: 0.8450942039489746
Validation loss: 2.217885802189509

Epoch: 5| Step: 2
Training loss: 1.5241618156433105
Validation loss: 2.2583738217751184

Epoch: 5| Step: 3
Training loss: 1.1582276821136475
Validation loss: 2.269900014003118

Epoch: 5| Step: 4
Training loss: 0.6571152806282043
Validation loss: 2.3040354251861572

Epoch: 5| Step: 5
Training loss: 1.0062477588653564
Validation loss: 2.257312243183454

Epoch: 5| Step: 6
Training loss: 1.441367745399475
Validation loss: 2.220477730035782

Epoch: 5| Step: 7
Training loss: 1.9852039813995361
Validation loss: 2.237735132376353

Epoch: 5| Step: 8
Training loss: 0.7287640571594238
Validation loss: 2.1972168932358422

Epoch: 5| Step: 9
Training loss: 1.3287326097488403
Validation loss: 2.2249488731225333

Epoch: 5| Step: 10
Training loss: 1.790887475013733
Validation loss: 2.2034502029418945

Epoch: 5| Step: 11
Training loss: 1.1067047119140625
Validation loss: 2.203005055586497

Epoch: 186| Step: 0
Training loss: 0.9689229130744934
Validation loss: 2.205394426981608

Epoch: 5| Step: 1
Training loss: 1.347255825996399
Validation loss: 2.1401709616184235

Epoch: 5| Step: 2
Training loss: 1.3694673776626587
Validation loss: 2.1748072604338327

Epoch: 5| Step: 3
Training loss: 1.1508104801177979
Validation loss: 2.2267623047033944

Epoch: 5| Step: 4
Training loss: 1.1868458986282349
Validation loss: 2.221422870953878

Epoch: 5| Step: 5
Training loss: 0.9561115503311157
Validation loss: 2.180541897813479

Epoch: 5| Step: 6
Training loss: 1.3475559949874878
Validation loss: 2.2856476306915283

Epoch: 5| Step: 7
Training loss: 1.214994192123413
Validation loss: 2.185229559739431

Epoch: 5| Step: 8
Training loss: 1.1882855892181396
Validation loss: 2.232953523596128

Epoch: 5| Step: 9
Training loss: 0.9870203137397766
Validation loss: 2.231832593679428

Epoch: 5| Step: 10
Training loss: 1.366044044494629
Validation loss: 2.212513287862142

Epoch: 5| Step: 11
Training loss: 1.3058885335922241
Validation loss: 2.1962662239869437

Epoch: 187| Step: 0
Training loss: 1.2255277633666992
Validation loss: 2.1837984224160514

Epoch: 5| Step: 1
Training loss: 0.9460574388504028
Validation loss: 2.187997351090113

Epoch: 5| Step: 2
Training loss: 1.3680285215377808
Validation loss: 2.215072905023893

Epoch: 5| Step: 3
Training loss: 1.6593620777130127
Validation loss: 2.208003799120585

Epoch: 5| Step: 4
Training loss: 1.3475425243377686
Validation loss: 2.215492765108744

Epoch: 5| Step: 5
Training loss: 0.8129575848579407
Validation loss: 2.280873864889145

Epoch: 5| Step: 6
Training loss: 1.18950617313385
Validation loss: 2.2099150816599527

Epoch: 5| Step: 7
Training loss: 1.1502317190170288
Validation loss: 2.1818807721138

Epoch: 5| Step: 8
Training loss: 1.315950632095337
Validation loss: 2.2655275712410607

Epoch: 5| Step: 9
Training loss: 0.9053651094436646
Validation loss: 2.207407688101133

Epoch: 5| Step: 10
Training loss: 1.13919198513031
Validation loss: 2.244568645954132

Epoch: 5| Step: 11
Training loss: 1.4047791957855225
Validation loss: 2.2508728206157684

Epoch: 188| Step: 0
Training loss: 1.7186241149902344
Validation loss: 2.2404169092575708

Epoch: 5| Step: 1
Training loss: 0.9056843519210815
Validation loss: 2.1579850018024445

Epoch: 5| Step: 2
Training loss: 0.8433524966239929
Validation loss: 2.18375097711881

Epoch: 5| Step: 3
Training loss: 1.2680697441101074
Validation loss: 2.2129768331845603

Epoch: 5| Step: 4
Training loss: 0.8606915473937988
Validation loss: 2.216046313444773

Epoch: 5| Step: 5
Training loss: 1.8301423788070679
Validation loss: 2.215697874625524

Epoch: 5| Step: 6
Training loss: 0.9685143232345581
Validation loss: 2.2034781674544015

Epoch: 5| Step: 7
Training loss: 1.2807235717773438
Validation loss: 2.2169239272673926

Epoch: 5| Step: 8
Training loss: 1.4757335186004639
Validation loss: 2.1648096293210983

Epoch: 5| Step: 9
Training loss: 1.0089703798294067
Validation loss: 2.225143313407898

Epoch: 5| Step: 10
Training loss: 0.9016240835189819
Validation loss: 2.2462298572063446

Epoch: 5| Step: 11
Training loss: 0.6065626740455627
Validation loss: 2.177895719806353

Epoch: 189| Step: 0
Training loss: 1.510717749595642
Validation loss: 2.2586672008037567

Epoch: 5| Step: 1
Training loss: 1.2396043539047241
Validation loss: 2.170960858464241

Epoch: 5| Step: 2
Training loss: 1.4180852174758911
Validation loss: 2.1732172667980194

Epoch: 5| Step: 3
Training loss: 0.970367431640625
Validation loss: 2.1561853289604187

Epoch: 5| Step: 4
Training loss: 1.0641297101974487
Validation loss: 2.190760691960653

Epoch: 5| Step: 5
Training loss: 1.0297448635101318
Validation loss: 2.2071520934502282

Epoch: 5| Step: 6
Training loss: 1.4495086669921875
Validation loss: 2.2636627554893494

Epoch: 5| Step: 7
Training loss: 1.292956829071045
Validation loss: 2.277811119953791

Epoch: 5| Step: 8
Training loss: 1.2191210985183716
Validation loss: 2.261448139945666

Epoch: 5| Step: 9
Training loss: 0.8465520739555359
Validation loss: 2.2455157240231833

Epoch: 5| Step: 10
Training loss: 1.1471890211105347
Validation loss: 2.221390734116236

Epoch: 5| Step: 11
Training loss: 1.114369511604309
Validation loss: 2.2748732020457587

Epoch: 190| Step: 0
Training loss: 1.0393377542495728
Validation loss: 2.1865039567152658

Epoch: 5| Step: 1
Training loss: 1.2102550268173218
Validation loss: 2.219796026746432

Epoch: 5| Step: 2
Training loss: 1.2436304092407227
Validation loss: 2.1991883714993796

Epoch: 5| Step: 3
Training loss: 1.0230720043182373
Validation loss: 2.1849027077356973

Epoch: 5| Step: 4
Training loss: 1.326021432876587
Validation loss: 2.2565424839655557

Epoch: 5| Step: 5
Training loss: 0.6498697996139526
Validation loss: 2.2424045503139496

Epoch: 5| Step: 6
Training loss: 1.1900310516357422
Validation loss: 2.1914282788832984

Epoch: 5| Step: 7
Training loss: 1.3717632293701172
Validation loss: 2.201690802971522

Epoch: 5| Step: 8
Training loss: 1.1709470748901367
Validation loss: 2.1852525224288306

Epoch: 5| Step: 9
Training loss: 1.4098412990570068
Validation loss: 2.2041268249352775

Epoch: 5| Step: 10
Training loss: 1.142492651939392
Validation loss: 2.1622233241796494

Epoch: 5| Step: 11
Training loss: 1.1652143001556396
Validation loss: 2.211343308289846

Epoch: 191| Step: 0
Training loss: 1.414245843887329
Validation loss: 2.2681468625863395

Epoch: 5| Step: 1
Training loss: 0.9446800351142883
Validation loss: 2.1976639529069266

Epoch: 5| Step: 2
Training loss: 1.3955590724945068
Validation loss: 2.2458355675141015

Epoch: 5| Step: 3
Training loss: 1.3812497854232788
Validation loss: 2.2617099533478418

Epoch: 5| Step: 4
Training loss: 1.1695064306259155
Validation loss: 2.2501433740059533

Epoch: 5| Step: 5
Training loss: 1.7725074291229248
Validation loss: 2.240548253059387

Epoch: 5| Step: 6
Training loss: 1.223046064376831
Validation loss: 2.1783993939558663

Epoch: 5| Step: 7
Training loss: 0.7930642366409302
Validation loss: 2.168288086851438

Epoch: 5| Step: 8
Training loss: 0.985932469367981
Validation loss: 2.2008475810289383

Epoch: 5| Step: 9
Training loss: 1.1164135932922363
Validation loss: 2.202775796254476

Epoch: 5| Step: 10
Training loss: 0.9576774835586548
Validation loss: 2.1959487249453864

Epoch: 5| Step: 11
Training loss: 0.8223395347595215
Validation loss: 2.2002201477686563

Epoch: 192| Step: 0
Training loss: 1.3558568954467773
Validation loss: 2.141198347012202

Epoch: 5| Step: 1
Training loss: 1.2946383953094482
Validation loss: 2.139225830634435

Epoch: 5| Step: 2
Training loss: 0.8527681231498718
Validation loss: 2.2254037459691367

Epoch: 5| Step: 3
Training loss: 1.245751976966858
Validation loss: 2.2489291528860726

Epoch: 5| Step: 4
Training loss: 1.2350261211395264
Validation loss: 2.1858375469843545

Epoch: 5| Step: 5
Training loss: 0.9861158132553101
Validation loss: 2.258495936791102

Epoch: 5| Step: 6
Training loss: 1.2166191339492798
Validation loss: 2.2624103923638663

Epoch: 5| Step: 7
Training loss: 1.0589020252227783
Validation loss: 2.233843222260475

Epoch: 5| Step: 8
Training loss: 0.9150134325027466
Validation loss: 2.2697955469290414

Epoch: 5| Step: 9
Training loss: 1.3574273586273193
Validation loss: 2.20262602965037

Epoch: 5| Step: 10
Training loss: 0.9579551815986633
Validation loss: 2.196309278408686

Epoch: 5| Step: 11
Training loss: 1.5339000225067139
Validation loss: 2.1777925391991935

Epoch: 193| Step: 0
Training loss: 1.1444294452667236
Validation loss: 2.225955456495285

Epoch: 5| Step: 1
Training loss: 0.8948956727981567
Validation loss: 2.1688219954570136

Epoch: 5| Step: 2
Training loss: 1.3150898218154907
Validation loss: 2.194288263718287

Epoch: 5| Step: 3
Training loss: 1.7492420673370361
Validation loss: 2.1896115988492966

Epoch: 5| Step: 4
Training loss: 1.1815863847732544
Validation loss: 2.202052960793177

Epoch: 5| Step: 5
Training loss: 0.9639970064163208
Validation loss: 2.1409703195095062

Epoch: 5| Step: 6
Training loss: 1.1423556804656982
Validation loss: 2.248563289642334

Epoch: 5| Step: 7
Training loss: 1.0590156316757202
Validation loss: 2.230788826942444

Epoch: 5| Step: 8
Training loss: 1.6323394775390625
Validation loss: 2.1982437074184418

Epoch: 5| Step: 9
Training loss: 0.9888700246810913
Validation loss: 2.2081284523010254

Epoch: 5| Step: 10
Training loss: 1.6784048080444336
Validation loss: 2.250280718008677

Epoch: 5| Step: 11
Training loss: 0.3425510823726654
Validation loss: 2.2611518700917563

Epoch: 194| Step: 0
Training loss: 1.2377296686172485
Validation loss: 2.1719472209612527

Epoch: 5| Step: 1
Training loss: 1.1858313083648682
Validation loss: 2.236389880379041

Epoch: 5| Step: 2
Training loss: 0.7649986147880554
Validation loss: 2.277209535241127

Epoch: 5| Step: 3
Training loss: 1.4024813175201416
Validation loss: 2.2994343042373657

Epoch: 5| Step: 4
Training loss: 0.8490931391716003
Validation loss: 2.269529382387797

Epoch: 5| Step: 5
Training loss: 1.0022163391113281
Validation loss: 2.3132344186306

Epoch: 5| Step: 6
Training loss: 1.3758302927017212
Validation loss: 2.276172548532486

Epoch: 5| Step: 7
Training loss: 1.1162488460540771
Validation loss: 2.2073053369919458

Epoch: 5| Step: 8
Training loss: 1.6173473596572876
Validation loss: 2.231409639120102

Epoch: 5| Step: 9
Training loss: 0.8381755948066711
Validation loss: 2.217174490292867

Epoch: 5| Step: 10
Training loss: 1.0163743495941162
Validation loss: 2.128673623005549

Epoch: 5| Step: 11
Training loss: 1.5728108882904053
Validation loss: 2.187616065144539

Epoch: 195| Step: 0
Training loss: 1.3246362209320068
Validation loss: 2.2406702438990274

Epoch: 5| Step: 1
Training loss: 1.8082211017608643
Validation loss: 2.209542522827784

Epoch: 5| Step: 2
Training loss: 1.3283393383026123
Validation loss: 2.206652154525121

Epoch: 5| Step: 3
Training loss: 1.2198253870010376
Validation loss: 2.1985797683397927

Epoch: 5| Step: 4
Training loss: 1.021295428276062
Validation loss: 2.203323175509771

Epoch: 5| Step: 5
Training loss: 1.2742830514907837
Validation loss: 2.2635221779346466

Epoch: 5| Step: 6
Training loss: 1.3146908283233643
Validation loss: 2.3053258260091147

Epoch: 5| Step: 7
Training loss: 0.5281811952590942
Validation loss: 2.2252862006425858

Epoch: 5| Step: 8
Training loss: 0.9738976359367371
Validation loss: 2.3097863694032035

Epoch: 5| Step: 9
Training loss: 1.0486419200897217
Validation loss: 2.2497870872418084

Epoch: 5| Step: 10
Training loss: 1.0638281106948853
Validation loss: 2.2303530325492225

Epoch: 5| Step: 11
Training loss: 1.3150010108947754
Validation loss: 2.2505372762680054

Epoch: 196| Step: 0
Training loss: 1.0841106176376343
Validation loss: 2.225821698705355

Epoch: 5| Step: 1
Training loss: 1.1460294723510742
Validation loss: 2.2292700906594596

Epoch: 5| Step: 2
Training loss: 1.2632948160171509
Validation loss: 2.184277112285296

Epoch: 5| Step: 3
Training loss: 1.282918095588684
Validation loss: 2.225309665004412

Epoch: 5| Step: 4
Training loss: 1.1386576890945435
Validation loss: 2.203105390071869

Epoch: 5| Step: 5
Training loss: 1.5751451253890991
Validation loss: 2.1602058112621307

Epoch: 5| Step: 6
Training loss: 1.2021077871322632
Validation loss: 2.1674642910559974

Epoch: 5| Step: 7
Training loss: 1.0120114088058472
Validation loss: 2.198951482772827

Epoch: 5| Step: 8
Training loss: 1.7848316431045532
Validation loss: 2.228435436884562

Epoch: 5| Step: 9
Training loss: 0.5705028176307678
Validation loss: 2.2036721209685006

Epoch: 5| Step: 10
Training loss: 0.6643300652503967
Validation loss: 2.233458032210668

Epoch: 5| Step: 11
Training loss: 2.1371192932128906
Validation loss: 2.2842751890420914

Epoch: 197| Step: 0
Training loss: 0.9435634613037109
Validation loss: 2.2425217429796853

Epoch: 5| Step: 1
Training loss: 1.0864471197128296
Validation loss: 2.1500563820203147

Epoch: 5| Step: 2
Training loss: 0.6398816704750061
Validation loss: 2.2619038025538125

Epoch: 5| Step: 3
Training loss: 1.2037298679351807
Validation loss: 2.3019234091043472

Epoch: 5| Step: 4
Training loss: 1.448128342628479
Validation loss: 2.187536100546519

Epoch: 5| Step: 5
Training loss: 0.8221214413642883
Validation loss: 2.227331096927325

Epoch: 5| Step: 6
Training loss: 1.3824692964553833
Validation loss: 2.2193244993686676

Epoch: 5| Step: 7
Training loss: 1.0459892749786377
Validation loss: 2.2078351924816766

Epoch: 5| Step: 8
Training loss: 1.3984344005584717
Validation loss: 2.196386436621348

Epoch: 5| Step: 9
Training loss: 1.2830008268356323
Validation loss: 2.125421712795893

Epoch: 5| Step: 10
Training loss: 1.1816728115081787
Validation loss: 2.231801986694336

Epoch: 5| Step: 11
Training loss: 0.85340416431427
Validation loss: 2.2637588729461036

Epoch: 198| Step: 0
Training loss: 0.9998418688774109
Validation loss: 2.279446224371592

Epoch: 5| Step: 1
Training loss: 0.6823119521141052
Validation loss: 2.2179835041364035

Epoch: 5| Step: 2
Training loss: 1.6438356637954712
Validation loss: 2.2459170470635095

Epoch: 5| Step: 3
Training loss: 0.8131623268127441
Validation loss: 2.2579682221015296

Epoch: 5| Step: 4
Training loss: 0.7892230749130249
Validation loss: 2.262117067972819

Epoch: 5| Step: 5
Training loss: 1.3338663578033447
Validation loss: 2.263254299759865

Epoch: 5| Step: 6
Training loss: 1.2080192565917969
Validation loss: 2.2469343642393746

Epoch: 5| Step: 7
Training loss: 1.1082074642181396
Validation loss: 2.2605730344851813

Epoch: 5| Step: 8
Training loss: 1.1853625774383545
Validation loss: 2.221669207016627

Epoch: 5| Step: 9
Training loss: 1.2203508615493774
Validation loss: 2.1837623020013175

Epoch: 5| Step: 10
Training loss: 0.9059540033340454
Validation loss: 2.2096943904956183

Epoch: 5| Step: 11
Training loss: 1.8253395557403564
Validation loss: 2.188800866405169

Epoch: 199| Step: 0
Training loss: 1.003603219985962
Validation loss: 2.215763568878174

Epoch: 5| Step: 1
Training loss: 1.1503163576126099
Validation loss: 2.2478060126304626

Epoch: 5| Step: 2
Training loss: 1.2171016931533813
Validation loss: 2.220844730734825

Epoch: 5| Step: 3
Training loss: 1.42482590675354
Validation loss: 2.1697578132152557

Epoch: 5| Step: 4
Training loss: 1.1649806499481201
Validation loss: 2.2156789551178613

Epoch: 5| Step: 5
Training loss: 1.1472418308258057
Validation loss: 2.287229756514231

Epoch: 5| Step: 6
Training loss: 1.2400544881820679
Validation loss: 2.2688197592894235

Epoch: 5| Step: 7
Training loss: 1.3082653284072876
Validation loss: 2.2921800017356873

Epoch: 5| Step: 8
Training loss: 1.0202157497406006
Validation loss: 2.310362786054611

Epoch: 5| Step: 9
Training loss: 1.0185874700546265
Validation loss: 2.3201507727305093

Epoch: 5| Step: 10
Training loss: 1.2174469232559204
Validation loss: 2.292622814575831

Epoch: 5| Step: 11
Training loss: 0.4624630808830261
Validation loss: 2.184118698040644

Epoch: 200| Step: 0
Training loss: 0.8104904294013977
Validation loss: 2.2413168450196586

Epoch: 5| Step: 1
Training loss: 1.0792661905288696
Validation loss: 2.1439970831076303

Epoch: 5| Step: 2
Training loss: 1.2849664688110352
Validation loss: 2.120185042421023

Epoch: 5| Step: 3
Training loss: 1.4422693252563477
Validation loss: 2.176208476225535

Epoch: 5| Step: 4
Training loss: 0.9845523834228516
Validation loss: 2.242424259583155

Epoch: 5| Step: 5
Training loss: 1.0844166278839111
Validation loss: 2.218355397383372

Epoch: 5| Step: 6
Training loss: 0.8845620155334473
Validation loss: 2.19919715821743

Epoch: 5| Step: 7
Training loss: 1.040055751800537
Validation loss: 2.246107831597328

Epoch: 5| Step: 8
Training loss: 1.2073547840118408
Validation loss: 2.2817096610864005

Epoch: 5| Step: 9
Training loss: 1.1827741861343384
Validation loss: 2.2512179613113403

Epoch: 5| Step: 10
Training loss: 1.2007052898406982
Validation loss: 2.301364690065384

Epoch: 5| Step: 11
Training loss: 0.344663143157959
Validation loss: 2.2591594556967416

Epoch: 201| Step: 0
Training loss: 0.9045379757881165
Validation loss: 2.15202197432518

Epoch: 5| Step: 1
Training loss: 1.3464629650115967
Validation loss: 2.176113178332647

Epoch: 5| Step: 2
Training loss: 0.9236583709716797
Validation loss: 2.194037839770317

Epoch: 5| Step: 3
Training loss: 1.0116745233535767
Validation loss: 2.1617974837621055

Epoch: 5| Step: 4
Training loss: 1.3292162418365479
Validation loss: 2.1783586839834848

Epoch: 5| Step: 5
Training loss: 0.8768969774246216
Validation loss: 2.1658418625593185

Epoch: 5| Step: 6
Training loss: 0.8110355138778687
Validation loss: 2.2124202847480774

Epoch: 5| Step: 7
Training loss: 1.275085687637329
Validation loss: 2.1722188045581183

Epoch: 5| Step: 8
Training loss: 0.8585277795791626
Validation loss: 2.22955721616745

Epoch: 5| Step: 9
Training loss: 0.7914390563964844
Validation loss: 2.183356667558352

Epoch: 5| Step: 10
Training loss: 1.9612529277801514
Validation loss: 2.2530233412981033

Epoch: 5| Step: 11
Training loss: 0.11202442646026611
Validation loss: 2.212616706887881

Epoch: 202| Step: 0
Training loss: 1.0923583507537842
Validation loss: 2.2794637382030487

Epoch: 5| Step: 1
Training loss: 1.1799112558364868
Validation loss: 2.239949186642965

Epoch: 5| Step: 2
Training loss: 0.9211181402206421
Validation loss: 2.230006754398346

Epoch: 5| Step: 3
Training loss: 1.4363528490066528
Validation loss: 2.276894763112068

Epoch: 5| Step: 4
Training loss: 0.9356295466423035
Validation loss: 2.2238461871941886

Epoch: 5| Step: 5
Training loss: 0.9621964693069458
Validation loss: 2.1910507629315057

Epoch: 5| Step: 6
Training loss: 1.0734279155731201
Validation loss: 2.2389011283715567

Epoch: 5| Step: 7
Training loss: 1.4467495679855347
Validation loss: 2.2072936445474625

Epoch: 5| Step: 8
Training loss: 0.995570182800293
Validation loss: 2.173231601715088

Epoch: 5| Step: 9
Training loss: 1.0477126836776733
Validation loss: 2.204495668411255

Epoch: 5| Step: 10
Training loss: 1.6449816226959229
Validation loss: 2.1989281872908273

Epoch: 5| Step: 11
Training loss: 1.2824878692626953
Validation loss: 2.2655385732650757

Epoch: 203| Step: 0
Training loss: 1.7794418334960938
Validation loss: 2.299770876765251

Epoch: 5| Step: 1
Training loss: 0.9902197122573853
Validation loss: 2.245379090309143

Epoch: 5| Step: 2
Training loss: 1.5513018369674683
Validation loss: 2.265206207831701

Epoch: 5| Step: 3
Training loss: 1.005316138267517
Validation loss: 2.214591940244039

Epoch: 5| Step: 4
Training loss: 1.2060893774032593
Validation loss: 2.214144413669904

Epoch: 5| Step: 5
Training loss: 0.8663502931594849
Validation loss: 2.229773779710134

Epoch: 5| Step: 6
Training loss: 0.5947043299674988
Validation loss: 2.2850156724452972

Epoch: 5| Step: 7
Training loss: 1.0111420154571533
Validation loss: 2.250561237335205

Epoch: 5| Step: 8
Training loss: 0.9724662899971008
Validation loss: 2.250693048040072

Epoch: 5| Step: 9
Training loss: 0.9040546417236328
Validation loss: 2.185590257247289

Epoch: 5| Step: 10
Training loss: 1.1344473361968994
Validation loss: 2.2082544763882956

Epoch: 5| Step: 11
Training loss: 0.7615990042686462
Validation loss: 2.188607250650724

Epoch: 204| Step: 0
Training loss: 0.9973058700561523
Validation loss: 2.193136990070343

Epoch: 5| Step: 1
Training loss: 0.8130134344100952
Validation loss: 2.236426070332527

Epoch: 5| Step: 2
Training loss: 0.9950835108757019
Validation loss: 2.2100578794876733

Epoch: 5| Step: 3
Training loss: 1.4132564067840576
Validation loss: 2.270585228999456

Epoch: 5| Step: 4
Training loss: 1.3272812366485596
Validation loss: 2.232161949078242

Epoch: 5| Step: 5
Training loss: 1.3082201480865479
Validation loss: 2.33185883363088

Epoch: 5| Step: 6
Training loss: 0.9914954900741577
Validation loss: 2.3256380756696067

Epoch: 5| Step: 7
Training loss: 0.7236607670783997
Validation loss: 2.1914321333169937

Epoch: 5| Step: 8
Training loss: 1.1454036235809326
Validation loss: 2.265523135662079

Epoch: 5| Step: 9
Training loss: 0.9504419565200806
Validation loss: 2.174966504176458

Epoch: 5| Step: 10
Training loss: 1.0277283191680908
Validation loss: 2.2210265497366586

Epoch: 5| Step: 11
Training loss: 1.7757245302200317
Validation loss: 2.2052111327648163

Epoch: 205| Step: 0
Training loss: 1.2450025081634521
Validation loss: 2.1834393044312796

Epoch: 5| Step: 1
Training loss: 0.7990051507949829
Validation loss: 2.176385596394539

Epoch: 5| Step: 2
Training loss: 1.0460498332977295
Validation loss: 2.2129449347654977

Epoch: 5| Step: 3
Training loss: 0.9048048853874207
Validation loss: 2.207158625125885

Epoch: 5| Step: 4
Training loss: 1.4892958402633667
Validation loss: 2.2803430755933127

Epoch: 5| Step: 5
Training loss: 0.9273092150688171
Validation loss: 2.272545203566551

Epoch: 5| Step: 6
Training loss: 1.0058472156524658
Validation loss: 2.297185738881429

Epoch: 5| Step: 7
Training loss: 1.119081974029541
Validation loss: 2.2226612667242684

Epoch: 5| Step: 8
Training loss: 1.1873972415924072
Validation loss: 2.359587704141935

Epoch: 5| Step: 9
Training loss: 1.1561577320098877
Validation loss: 2.2217975159486136

Epoch: 5| Step: 10
Training loss: 1.1579633951187134
Validation loss: 2.2197253108024597

Epoch: 5| Step: 11
Training loss: 0.2858807444572449
Validation loss: 2.215817322333654

Epoch: 206| Step: 0
Training loss: 1.2084347009658813
Validation loss: 2.218320593237877

Epoch: 5| Step: 1
Training loss: 0.9953159093856812
Validation loss: 2.1708415945370994

Epoch: 5| Step: 2
Training loss: 0.7842652201652527
Validation loss: 2.2145478228727975

Epoch: 5| Step: 3
Training loss: 1.0024511814117432
Validation loss: 2.183085779349009

Epoch: 5| Step: 4
Training loss: 1.1982489824295044
Validation loss: 2.222493996222814

Epoch: 5| Step: 5
Training loss: 1.1190491914749146
Validation loss: 2.2023111631472907

Epoch: 5| Step: 6
Training loss: 0.9425603151321411
Validation loss: 2.244798560937246

Epoch: 5| Step: 7
Training loss: 0.6531730890274048
Validation loss: 2.1898873349030814

Epoch: 5| Step: 8
Training loss: 1.1698025465011597
Validation loss: 2.2370424270629883

Epoch: 5| Step: 9
Training loss: 1.513309121131897
Validation loss: 2.248741567134857

Epoch: 5| Step: 10
Training loss: 1.3366435766220093
Validation loss: 2.3313520352045694

Epoch: 5| Step: 11
Training loss: 0.6112509965896606
Validation loss: 2.218468055129051

Epoch: 207| Step: 0
Training loss: 0.8715873956680298
Validation loss: 2.2137764990329742

Epoch: 5| Step: 1
Training loss: 0.8946396112442017
Validation loss: 2.25100901722908

Epoch: 5| Step: 2
Training loss: 1.250866174697876
Validation loss: 2.2447998325030007

Epoch: 5| Step: 3
Training loss: 1.4039747714996338
Validation loss: 2.1732739408810935

Epoch: 5| Step: 4
Training loss: 1.335087776184082
Validation loss: 2.199085161089897

Epoch: 5| Step: 5
Training loss: 1.0667893886566162
Validation loss: 2.2011652489503226

Epoch: 5| Step: 6
Training loss: 1.0700178146362305
Validation loss: 2.154550979534785

Epoch: 5| Step: 7
Training loss: 1.052239179611206
Validation loss: 2.1967252840598426

Epoch: 5| Step: 8
Training loss: 0.8566182255744934
Validation loss: 2.2099517981211343

Epoch: 5| Step: 9
Training loss: 1.178502082824707
Validation loss: 2.231195097168287

Epoch: 5| Step: 10
Training loss: 1.021024465560913
Validation loss: 2.2268166293700538

Epoch: 5| Step: 11
Training loss: 1.9850010871887207
Validation loss: 2.2034068554639816

Epoch: 208| Step: 0
Training loss: 0.9673666954040527
Validation loss: 2.270929460724195

Epoch: 5| Step: 1
Training loss: 1.3879029750823975
Validation loss: 2.2907828042904534

Epoch: 5| Step: 2
Training loss: 1.2993632555007935
Validation loss: 2.3222520450750985

Epoch: 5| Step: 3
Training loss: 1.643155813217163
Validation loss: 2.3333300997813544

Epoch: 5| Step: 4
Training loss: 0.9991583824157715
Validation loss: 2.281559964021047

Epoch: 5| Step: 5
Training loss: 0.8353063464164734
Validation loss: 2.3080867727597556

Epoch: 5| Step: 6
Training loss: 1.0020415782928467
Validation loss: 2.206750770409902

Epoch: 5| Step: 7
Training loss: 1.194052815437317
Validation loss: 2.2225796232620874

Epoch: 5| Step: 8
Training loss: 1.257927417755127
Validation loss: 2.202624718348185

Epoch: 5| Step: 9
Training loss: 1.159346580505371
Validation loss: 2.1656851122776666

Epoch: 5| Step: 10
Training loss: 0.756331741809845
Validation loss: 2.1914044469594955

Epoch: 5| Step: 11
Training loss: 0.8396787047386169
Validation loss: 2.2140949418147406

Epoch: 209| Step: 0
Training loss: 1.2102200984954834
Validation loss: 2.2145935595035553

Epoch: 5| Step: 1
Training loss: 0.7950056791305542
Validation loss: 2.1887806554635367

Epoch: 5| Step: 2
Training loss: 1.05344557762146
Validation loss: 2.1953462908665338

Epoch: 5| Step: 3
Training loss: 0.6014955043792725
Validation loss: 2.283955862124761

Epoch: 5| Step: 4
Training loss: 0.8360637426376343
Validation loss: 2.2022460947434106

Epoch: 5| Step: 5
Training loss: 1.3765575885772705
Validation loss: 2.197209134697914

Epoch: 5| Step: 6
Training loss: 0.8466145396232605
Validation loss: 2.230598658323288

Epoch: 5| Step: 7
Training loss: 0.5552118420600891
Validation loss: 2.155619502067566

Epoch: 5| Step: 8
Training loss: 1.309034824371338
Validation loss: 2.2334707429011664

Epoch: 5| Step: 9
Training loss: 1.497321605682373
Validation loss: 2.227396453420321

Epoch: 5| Step: 10
Training loss: 1.2082656621932983
Validation loss: 2.2062698900699615

Epoch: 5| Step: 11
Training loss: 0.33329522609710693
Validation loss: 2.2514760146538415

Epoch: 210| Step: 0
Training loss: 1.5001919269561768
Validation loss: 2.2153129627307258

Epoch: 5| Step: 1
Training loss: 1.0756404399871826
Validation loss: 2.200110668937365

Epoch: 5| Step: 2
Training loss: 1.1010299921035767
Validation loss: 2.200225646297137

Epoch: 5| Step: 3
Training loss: 0.673747181892395
Validation loss: 2.1436534027258554

Epoch: 5| Step: 4
Training loss: 1.2852673530578613
Validation loss: 2.1682339012622833

Epoch: 5| Step: 5
Training loss: 0.9709442257881165
Validation loss: 2.12497678399086

Epoch: 5| Step: 6
Training loss: 0.7458520531654358
Validation loss: 2.2411033511161804

Epoch: 5| Step: 7
Training loss: 0.7800313234329224
Validation loss: 2.234643429517746

Epoch: 5| Step: 8
Training loss: 0.9631963968276978
Validation loss: 2.198371817668279

Epoch: 5| Step: 9
Training loss: 0.905746340751648
Validation loss: 2.2286969224611917

Epoch: 5| Step: 10
Training loss: 0.8951578140258789
Validation loss: 2.2240694761276245

Epoch: 5| Step: 11
Training loss: 0.46707093715667725
Validation loss: 2.1995529532432556

Epoch: 211| Step: 0
Training loss: 0.9201298952102661
Validation loss: 2.141987939675649

Epoch: 5| Step: 1
Training loss: 0.9632236361503601
Validation loss: 2.2354361613591514

Epoch: 5| Step: 2
Training loss: 0.9290261268615723
Validation loss: 2.2631002366542816

Epoch: 5| Step: 3
Training loss: 1.517991304397583
Validation loss: 2.275184243917465

Epoch: 5| Step: 4
Training loss: 1.0277681350708008
Validation loss: 2.2277404367923737

Epoch: 5| Step: 5
Training loss: 0.9876964688301086
Validation loss: 2.1663297216097512

Epoch: 5| Step: 6
Training loss: 1.0707772970199585
Validation loss: 2.1970862994591394

Epoch: 5| Step: 7
Training loss: 0.8362812995910645
Validation loss: 2.1639011601607003

Epoch: 5| Step: 8
Training loss: 0.638077437877655
Validation loss: 2.234614575902621

Epoch: 5| Step: 9
Training loss: 1.1089551448822021
Validation loss: 2.156378065546354

Epoch: 5| Step: 10
Training loss: 0.9012895822525024
Validation loss: 2.1988118290901184

Epoch: 5| Step: 11
Training loss: 1.1775553226470947
Validation loss: 2.237863043944041

Epoch: 212| Step: 0
Training loss: 0.6995539665222168
Validation loss: 2.189411739508311

Epoch: 5| Step: 1
Training loss: 0.9112812876701355
Validation loss: 2.174345095952352

Epoch: 5| Step: 2
Training loss: 1.0626646280288696
Validation loss: 2.1946222533782325

Epoch: 5| Step: 3
Training loss: 0.8846290707588196
Validation loss: 2.2581447859605155

Epoch: 5| Step: 4
Training loss: 1.1161245107650757
Validation loss: 2.2072162131468454

Epoch: 5| Step: 5
Training loss: 0.6937564015388489
Validation loss: 2.1937618354956308

Epoch: 5| Step: 6
Training loss: 0.7766169309616089
Validation loss: 2.1831080615520477

Epoch: 5| Step: 7
Training loss: 0.8903821706771851
Validation loss: 2.1700307776530585

Epoch: 5| Step: 8
Training loss: 1.4141557216644287
Validation loss: 2.2410243650277457

Epoch: 5| Step: 9
Training loss: 1.1746242046356201
Validation loss: 2.1619346340497336

Epoch: 5| Step: 10
Training loss: 1.071419596672058
Validation loss: 2.2402379661798477

Epoch: 5| Step: 11
Training loss: 2.7205309867858887
Validation loss: 2.2460327247778573

Epoch: 213| Step: 0
Training loss: 0.6823010444641113
Validation loss: 2.242932682236036

Epoch: 5| Step: 1
Training loss: 0.8141295313835144
Validation loss: 2.1898430585861206

Epoch: 5| Step: 2
Training loss: 0.8844993710517883
Validation loss: 2.274168163537979

Epoch: 5| Step: 3
Training loss: 1.4154168367385864
Validation loss: 2.1861866116523743

Epoch: 5| Step: 4
Training loss: 1.1260918378829956
Validation loss: 2.2292885134617486

Epoch: 5| Step: 5
Training loss: 1.2760144472122192
Validation loss: 2.2242575933535895

Epoch: 5| Step: 6
Training loss: 1.2610044479370117
Validation loss: 2.2584168513615928

Epoch: 5| Step: 7
Training loss: 0.8070955276489258
Validation loss: 2.237534706791242

Epoch: 5| Step: 8
Training loss: 0.6547712087631226
Validation loss: 2.2471442073583603

Epoch: 5| Step: 9
Training loss: 1.0089056491851807
Validation loss: 2.228352869550387

Epoch: 5| Step: 10
Training loss: 0.7729328274726868
Validation loss: 2.202979346116384

Epoch: 5| Step: 11
Training loss: 0.8626543283462524
Validation loss: 2.2156745294729867

Epoch: 214| Step: 0
Training loss: 0.8274315595626831
Validation loss: 2.2348198741674423

Epoch: 5| Step: 1
Training loss: 1.523917317390442
Validation loss: 2.2327002386252084

Epoch: 5| Step: 2
Training loss: 1.2356008291244507
Validation loss: 2.2406599819660187

Epoch: 5| Step: 3
Training loss: 1.206748604774475
Validation loss: 2.2310507049163184

Epoch: 5| Step: 4
Training loss: 1.3255250453948975
Validation loss: 2.229087715347608

Epoch: 5| Step: 5
Training loss: 0.8765541911125183
Validation loss: 2.2156683107217154

Epoch: 5| Step: 6
Training loss: 0.6362406015396118
Validation loss: 2.2060776948928833

Epoch: 5| Step: 7
Training loss: 1.15224289894104
Validation loss: 2.209868078430494

Epoch: 5| Step: 8
Training loss: 0.7055870294570923
Validation loss: 2.2054583628972373

Epoch: 5| Step: 9
Training loss: 0.8387201428413391
Validation loss: 2.2175796876351037

Epoch: 5| Step: 10
Training loss: 0.787657618522644
Validation loss: 2.231698140501976

Epoch: 5| Step: 11
Training loss: 0.5881215333938599
Validation loss: 2.2064088781674704

Epoch: 215| Step: 0
Training loss: 1.2346572875976562
Validation loss: 2.234611282745997

Epoch: 5| Step: 1
Training loss: 0.6721333265304565
Validation loss: 2.196221426129341

Epoch: 5| Step: 2
Training loss: 1.0232784748077393
Validation loss: 2.2006071408589682

Epoch: 5| Step: 3
Training loss: 0.7301514148712158
Validation loss: 2.1817253281672797

Epoch: 5| Step: 4
Training loss: 0.8825894594192505
Validation loss: 2.2544060001770654

Epoch: 5| Step: 5
Training loss: 1.308889389038086
Validation loss: 2.2013393292824426

Epoch: 5| Step: 6
Training loss: 0.7704577445983887
Validation loss: 2.2600217213233313

Epoch: 5| Step: 7
Training loss: 1.4401246309280396
Validation loss: 2.195715775092443

Epoch: 5| Step: 8
Training loss: 0.9533977508544922
Validation loss: 2.235991140206655

Epoch: 5| Step: 9
Training loss: 0.884292483329773
Validation loss: 2.2562094628810883

Epoch: 5| Step: 10
Training loss: 0.7034918665885925
Validation loss: 2.282202978928884

Epoch: 5| Step: 11
Training loss: 0.9323402047157288
Validation loss: 2.317013775308927

Epoch: 216| Step: 0
Training loss: 0.8126947283744812
Validation loss: 2.282595614592234

Epoch: 5| Step: 1
Training loss: 0.9878557324409485
Validation loss: 2.2609184086322784

Epoch: 5| Step: 2
Training loss: 1.2315948009490967
Validation loss: 2.231215645869573

Epoch: 5| Step: 3
Training loss: 1.136900544166565
Validation loss: 2.2350314408540726

Epoch: 5| Step: 4
Training loss: 1.1167539358139038
Validation loss: 2.171625087658564

Epoch: 5| Step: 5
Training loss: 0.886758029460907
Validation loss: 2.212387040257454

Epoch: 5| Step: 6
Training loss: 0.8513934016227722
Validation loss: 2.2404145946105323

Epoch: 5| Step: 7
Training loss: 1.301775574684143
Validation loss: 2.313695326447487

Epoch: 5| Step: 8
Training loss: 0.9475060701370239
Validation loss: 2.272575338681539

Epoch: 5| Step: 9
Training loss: 1.1026198863983154
Validation loss: 2.1590974082549415

Epoch: 5| Step: 10
Training loss: 1.1229698657989502
Validation loss: 2.2231469253698983

Epoch: 5| Step: 11
Training loss: 0.9586876630783081
Validation loss: 2.2307961334784827

Epoch: 217| Step: 0
Training loss: 0.8546249270439148
Validation loss: 2.2076584001382193

Epoch: 5| Step: 1
Training loss: 1.1132619380950928
Validation loss: 2.2089937925338745

Epoch: 5| Step: 2
Training loss: 0.6414698362350464
Validation loss: 2.2410531044006348

Epoch: 5| Step: 3
Training loss: 0.4416961669921875
Validation loss: 2.248165115714073

Epoch: 5| Step: 4
Training loss: 1.053424596786499
Validation loss: 2.2348158409198127

Epoch: 5| Step: 5
Training loss: 1.20787513256073
Validation loss: 2.2036314755678177

Epoch: 5| Step: 6
Training loss: 1.415930151939392
Validation loss: 2.2040535459915795

Epoch: 5| Step: 7
Training loss: 0.8283570408821106
Validation loss: 2.1903208841880164

Epoch: 5| Step: 8
Training loss: 1.1839736700057983
Validation loss: 2.278565908471743

Epoch: 5| Step: 9
Training loss: 0.7060199975967407
Validation loss: 2.2361246148745217

Epoch: 5| Step: 10
Training loss: 1.004488229751587
Validation loss: 2.243700290719668

Epoch: 5| Step: 11
Training loss: 0.7928804755210876
Validation loss: 2.183559109767278

Epoch: 218| Step: 0
Training loss: 1.1716220378875732
Validation loss: 2.216736684242884

Epoch: 5| Step: 1
Training loss: 0.9765787124633789
Validation loss: 2.1417990773916245

Epoch: 5| Step: 2
Training loss: 1.198277473449707
Validation loss: 2.2058285077412925

Epoch: 5| Step: 3
Training loss: 0.680457353591919
Validation loss: 2.191948970158895

Epoch: 5| Step: 4
Training loss: 0.7626144289970398
Validation loss: 2.2157590091228485

Epoch: 5| Step: 5
Training loss: 0.9001932144165039
Validation loss: 2.216254711151123

Epoch: 5| Step: 6
Training loss: 1.0281621217727661
Validation loss: 2.2165538916985192

Epoch: 5| Step: 7
Training loss: 0.8639690279960632
Validation loss: 2.1608279595772424

Epoch: 5| Step: 8
Training loss: 1.17239511013031
Validation loss: 2.2647283524274826

Epoch: 5| Step: 9
Training loss: 0.7610195875167847
Validation loss: 2.209181542197863

Epoch: 5| Step: 10
Training loss: 0.6504800915718079
Validation loss: 2.2592744727929435

Epoch: 5| Step: 11
Training loss: 1.1878671646118164
Validation loss: 2.2658949146668115

Epoch: 219| Step: 0
Training loss: 0.8069210052490234
Validation loss: 2.205568532148997

Epoch: 5| Step: 1
Training loss: 0.7495591044425964
Validation loss: 2.2793237467606864

Epoch: 5| Step: 2
Training loss: 0.8632396459579468
Validation loss: 2.3078759809335074

Epoch: 5| Step: 3
Training loss: 0.8519155383110046
Validation loss: 2.28073184688886

Epoch: 5| Step: 4
Training loss: 0.9694451093673706
Validation loss: 2.2348475257555642

Epoch: 5| Step: 5
Training loss: 1.1160366535186768
Validation loss: 2.225295434395472

Epoch: 5| Step: 6
Training loss: 0.8850768804550171
Validation loss: 2.2260284374157586

Epoch: 5| Step: 7
Training loss: 0.8773046731948853
Validation loss: 2.2289823244015374

Epoch: 5| Step: 8
Training loss: 1.2995349168777466
Validation loss: 2.2262264440457025

Epoch: 5| Step: 9
Training loss: 1.0717713832855225
Validation loss: 2.1939531912406287

Epoch: 5| Step: 10
Training loss: 0.6836479902267456
Validation loss: 2.1807564993699393

Epoch: 5| Step: 11
Training loss: 2.5480294227600098
Validation loss: 2.1923189659913382

Epoch: 220| Step: 0
Training loss: 0.410616010427475
Validation loss: 2.277789612611135

Epoch: 5| Step: 1
Training loss: 0.8559623956680298
Validation loss: 2.2227389762798944

Epoch: 5| Step: 2
Training loss: 0.8727814555168152
Validation loss: 2.2233825574318566

Epoch: 5| Step: 3
Training loss: 0.7942509651184082
Validation loss: 2.2834463516871133

Epoch: 5| Step: 4
Training loss: 0.9586132168769836
Validation loss: 2.2069673339525857

Epoch: 5| Step: 5
Training loss: 1.0661507844924927
Validation loss: 2.2214840153853097

Epoch: 5| Step: 6
Training loss: 0.3975655138492584
Validation loss: 2.2788680295149484

Epoch: 5| Step: 7
Training loss: 1.305171012878418
Validation loss: 2.2120245148738227

Epoch: 5| Step: 8
Training loss: 0.7912088632583618
Validation loss: 2.2236296832561493

Epoch: 5| Step: 9
Training loss: 1.263202428817749
Validation loss: 2.1393004010121026

Epoch: 5| Step: 10
Training loss: 1.3406622409820557
Validation loss: 2.191666916012764

Epoch: 5| Step: 11
Training loss: 0.8306662440299988
Validation loss: 2.216396321853002

Epoch: 221| Step: 0
Training loss: 0.8789372444152832
Validation loss: 2.27128466963768

Epoch: 5| Step: 1
Training loss: 1.1538752317428589
Validation loss: 2.220341513554255

Epoch: 5| Step: 2
Training loss: 0.6588822603225708
Validation loss: 2.227487877011299

Epoch: 5| Step: 3
Training loss: 0.9462084770202637
Validation loss: 2.2696339984734855

Epoch: 5| Step: 4
Training loss: 0.4678551256656647
Validation loss: 2.244596317410469

Epoch: 5| Step: 5
Training loss: 1.012498378753662
Validation loss: 2.282412270704905

Epoch: 5| Step: 6
Training loss: 1.0042340755462646
Validation loss: 2.2594148168961206

Epoch: 5| Step: 7
Training loss: 0.9164689183235168
Validation loss: 2.244694252808889

Epoch: 5| Step: 8
Training loss: 1.2080274820327759
Validation loss: 2.2764079670111337

Epoch: 5| Step: 9
Training loss: 1.536018967628479
Validation loss: 2.2318866550922394

Epoch: 5| Step: 10
Training loss: 0.6116030812263489
Validation loss: 2.2440858483314514

Epoch: 5| Step: 11
Training loss: 1.066843032836914
Validation loss: 2.298337608575821

Epoch: 222| Step: 0
Training loss: 0.5692516565322876
Validation loss: 2.2492405275503793

Epoch: 5| Step: 1
Training loss: 1.2568700313568115
Validation loss: 2.2274385889371238

Epoch: 5| Step: 2
Training loss: 0.6908572316169739
Validation loss: 2.202540934085846

Epoch: 5| Step: 3
Training loss: 1.0046460628509521
Validation loss: 2.2436575144529343

Epoch: 5| Step: 4
Training loss: 0.5502869486808777
Validation loss: 2.2716828087965646

Epoch: 5| Step: 5
Training loss: 0.8831806182861328
Validation loss: 2.2298897951841354

Epoch: 5| Step: 6
Training loss: 0.999370276927948
Validation loss: 2.2998004655043283

Epoch: 5| Step: 7
Training loss: 0.7553626298904419
Validation loss: 2.2286526213089624

Epoch: 5| Step: 8
Training loss: 0.9093902707099915
Validation loss: 2.2104398707548776

Epoch: 5| Step: 9
Training loss: 0.9982672929763794
Validation loss: 2.241818050543467

Epoch: 5| Step: 10
Training loss: 1.472654938697815
Validation loss: 2.2722399532794952

Epoch: 5| Step: 11
Training loss: 0.36692166328430176
Validation loss: 2.204166904091835

Epoch: 223| Step: 0
Training loss: 1.0034650564193726
Validation loss: 2.1814798216025033

Epoch: 5| Step: 1
Training loss: 0.8455648422241211
Validation loss: 2.1912661840518317

Epoch: 5| Step: 2
Training loss: 1.0255314111709595
Validation loss: 2.252551500995954

Epoch: 5| Step: 3
Training loss: 0.8596628308296204
Validation loss: 2.2258475720882416

Epoch: 5| Step: 4
Training loss: 0.8052489161491394
Validation loss: 2.2735574394464493

Epoch: 5| Step: 5
Training loss: 0.7501012086868286
Validation loss: 2.213874747355779

Epoch: 5| Step: 6
Training loss: 0.7179697155952454
Validation loss: 2.1753539045651755

Epoch: 5| Step: 7
Training loss: 1.3761118650436401
Validation loss: 2.225499843557676

Epoch: 5| Step: 8
Training loss: 1.4508395195007324
Validation loss: 2.27332670489947

Epoch: 5| Step: 9
Training loss: 0.8617719411849976
Validation loss: 2.210963547229767

Epoch: 5| Step: 10
Training loss: 0.81385737657547
Validation loss: 2.2745305448770523

Epoch: 5| Step: 11
Training loss: 1.4450373649597168
Validation loss: 2.269580622514089

Epoch: 224| Step: 0
Training loss: 0.8778852224349976
Validation loss: 2.1951624552408853

Epoch: 5| Step: 1
Training loss: 0.9363359212875366
Validation loss: 2.1708391110102334

Epoch: 5| Step: 2
Training loss: 1.588604211807251
Validation loss: 2.1539729982614517

Epoch: 5| Step: 3
Training loss: 0.9832788705825806
Validation loss: 2.22799181441466

Epoch: 5| Step: 4
Training loss: 0.7659169435501099
Validation loss: 2.190789133310318

Epoch: 5| Step: 5
Training loss: 1.199855923652649
Validation loss: 2.166972150405248

Epoch: 5| Step: 6
Training loss: 0.8992212414741516
Validation loss: 2.2116376757621765

Epoch: 5| Step: 7
Training loss: 0.7076572179794312
Validation loss: 2.2177554021279016

Epoch: 5| Step: 8
Training loss: 0.8267061114311218
Validation loss: 2.207940141359965

Epoch: 5| Step: 9
Training loss: 1.1300245523452759
Validation loss: 2.289968197544416

Epoch: 5| Step: 10
Training loss: 0.8359537124633789
Validation loss: 2.268698235352834

Epoch: 5| Step: 11
Training loss: 0.9582628607749939
Validation loss: 2.275267561276754

Epoch: 225| Step: 0
Training loss: 1.6516647338867188
Validation loss: 2.277744561433792

Epoch: 5| Step: 1
Training loss: 1.272123098373413
Validation loss: 2.2347009678681693

Epoch: 5| Step: 2
Training loss: 0.9264646768569946
Validation loss: 2.2311148842175803

Epoch: 5| Step: 3
Training loss: 0.6729326248168945
Validation loss: 2.1995069086551666

Epoch: 5| Step: 4
Training loss: 0.8799441456794739
Validation loss: 2.2111296902100244

Epoch: 5| Step: 5
Training loss: 0.9291123151779175
Validation loss: 2.2489863336086273

Epoch: 5| Step: 6
Training loss: 0.7285335659980774
Validation loss: 2.2723666628201804

Epoch: 5| Step: 7
Training loss: 0.518928050994873
Validation loss: 2.204883630077044

Epoch: 5| Step: 8
Training loss: 0.43341946601867676
Validation loss: 2.219599242011706

Epoch: 5| Step: 9
Training loss: 1.1774959564208984
Validation loss: 2.1690880954265594

Epoch: 5| Step: 10
Training loss: 1.1100528240203857
Validation loss: 2.2369120667378106

Epoch: 5| Step: 11
Training loss: 1.3199390172958374
Validation loss: 2.2223572731018066

Epoch: 226| Step: 0
Training loss: 0.913626492023468
Validation loss: 2.3061375319957733

Epoch: 5| Step: 1
Training loss: 1.1858900785446167
Validation loss: 2.272195135553678

Epoch: 5| Step: 2
Training loss: 0.8325287103652954
Validation loss: 2.276274691025416

Epoch: 5| Step: 3
Training loss: 0.8279523849487305
Validation loss: 2.2271844943364463

Epoch: 5| Step: 4
Training loss: 1.3707785606384277
Validation loss: 2.266163100798925

Epoch: 5| Step: 5
Training loss: 0.7726775407791138
Validation loss: 2.2635846634705863

Epoch: 5| Step: 6
Training loss: 0.5553978681564331
Validation loss: 2.2694746057192483

Epoch: 5| Step: 7
Training loss: 1.0894875526428223
Validation loss: 2.1633148739735284

Epoch: 5| Step: 8
Training loss: 1.1092735528945923
Validation loss: 2.2462783654530845

Epoch: 5| Step: 9
Training loss: 1.1715787649154663
Validation loss: 2.2248421957095466

Epoch: 5| Step: 10
Training loss: 0.7871686816215515
Validation loss: 2.20117841164271

Epoch: 5| Step: 11
Training loss: 0.3896383047103882
Validation loss: 2.1808283030986786

Epoch: 227| Step: 0
Training loss: 0.8960623741149902
Validation loss: 2.255675807595253

Epoch: 5| Step: 1
Training loss: 0.8060522079467773
Validation loss: 2.265759309132894

Epoch: 5| Step: 2
Training loss: 1.2281568050384521
Validation loss: 2.236737549304962

Epoch: 5| Step: 3
Training loss: 0.7875252962112427
Validation loss: 2.185198336839676

Epoch: 5| Step: 4
Training loss: 1.1063454151153564
Validation loss: 2.257745290795962

Epoch: 5| Step: 5
Training loss: 1.5367155075073242
Validation loss: 2.2280693699916205

Epoch: 5| Step: 6
Training loss: 0.6655601859092712
Validation loss: 2.196941763162613

Epoch: 5| Step: 7
Training loss: 0.6497162580490112
Validation loss: 2.2549368490775428

Epoch: 5| Step: 8
Training loss: 0.5608047246932983
Validation loss: 2.2413187424341836

Epoch: 5| Step: 9
Training loss: 0.6325527429580688
Validation loss: 2.238900274038315

Epoch: 5| Step: 10
Training loss: 1.2076534032821655
Validation loss: 2.153504783908526

Epoch: 5| Step: 11
Training loss: 0.4237106442451477
Validation loss: 2.1879108548164368

Epoch: 228| Step: 0
Training loss: 0.826058030128479
Validation loss: 2.204375594854355

Epoch: 5| Step: 1
Training loss: 0.5635362267494202
Validation loss: 2.2113276422023773

Epoch: 5| Step: 2
Training loss: 0.9876248240470886
Validation loss: 2.2057369351387024

Epoch: 5| Step: 3
Training loss: 1.5429913997650146
Validation loss: 2.2196737080812454

Epoch: 5| Step: 4
Training loss: 0.9717262387275696
Validation loss: 2.217246780792872

Epoch: 5| Step: 5
Training loss: 0.563919723033905
Validation loss: 2.260760491093

Epoch: 5| Step: 6
Training loss: 0.9512092471122742
Validation loss: 2.24421234925588

Epoch: 5| Step: 7
Training loss: 0.49979352951049805
Validation loss: 2.2497594157854715

Epoch: 5| Step: 8
Training loss: 0.9123881459236145
Validation loss: 2.2515465915203094

Epoch: 5| Step: 9
Training loss: 1.0935108661651611
Validation loss: 2.206741894284884

Epoch: 5| Step: 10
Training loss: 0.9643920660018921
Validation loss: 2.200669993956884

Epoch: 5| Step: 11
Training loss: 0.3264307975769043
Validation loss: 2.2056999752918878

Epoch: 229| Step: 0
Training loss: 0.7923482656478882
Validation loss: 2.1942444195350013

Epoch: 5| Step: 1
Training loss: 1.107348918914795
Validation loss: 2.1445739964644113

Epoch: 5| Step: 2
Training loss: 0.6323375701904297
Validation loss: 2.2373416473468146

Epoch: 5| Step: 3
Training loss: 1.414271354675293
Validation loss: 2.2439474860827127

Epoch: 5| Step: 4
Training loss: 0.6025158166885376
Validation loss: 2.198929652571678

Epoch: 5| Step: 5
Training loss: 1.1802703142166138
Validation loss: 2.195997799436251

Epoch: 5| Step: 6
Training loss: 0.45625582337379456
Validation loss: 2.184026305874189

Epoch: 5| Step: 7
Training loss: 1.0376787185668945
Validation loss: 2.2291549245516458

Epoch: 5| Step: 8
Training loss: 0.6322168111801147
Validation loss: 2.255293990174929

Epoch: 5| Step: 9
Training loss: 0.8659189343452454
Validation loss: 2.199707865715027

Epoch: 5| Step: 10
Training loss: 1.2418491840362549
Validation loss: 2.2657911529143653

Epoch: 5| Step: 11
Training loss: 0.5609424114227295
Validation loss: 2.226635535558065

Epoch: 230| Step: 0
Training loss: 0.9957464337348938
Validation loss: 2.294626216093699

Epoch: 5| Step: 1
Training loss: 1.0538839101791382
Validation loss: 2.221600284179052

Epoch: 5| Step: 2
Training loss: 0.7234862446784973
Validation loss: 2.2441116720438004

Epoch: 5| Step: 3
Training loss: 0.8155301213264465
Validation loss: 2.307468687494596

Epoch: 5| Step: 4
Training loss: 1.0467714071273804
Validation loss: 2.3190067211786904

Epoch: 5| Step: 5
Training loss: 0.7717344164848328
Validation loss: 2.2933945457140603

Epoch: 5| Step: 6
Training loss: 1.0306073427200317
Validation loss: 2.234029690424601

Epoch: 5| Step: 7
Training loss: 0.7927547693252563
Validation loss: 2.1941206951936087

Epoch: 5| Step: 8
Training loss: 1.2843921184539795
Validation loss: 2.235605299472809

Epoch: 5| Step: 9
Training loss: 0.7768058776855469
Validation loss: 2.1943505108356476

Epoch: 5| Step: 10
Training loss: 0.9539869427680969
Validation loss: 2.1797205358743668

Epoch: 5| Step: 11
Training loss: 0.3733419179916382
Validation loss: 2.1885323027769723

Epoch: 231| Step: 0
Training loss: 0.871527373790741
Validation loss: 2.2392946978410087

Epoch: 5| Step: 1
Training loss: 1.3577181100845337
Validation loss: 2.2353339145580926

Epoch: 5| Step: 2
Training loss: 1.0033063888549805
Validation loss: 2.2382052739461265

Epoch: 5| Step: 3
Training loss: 0.39122045040130615
Validation loss: 2.216229955355326

Epoch: 5| Step: 4
Training loss: 0.7962965965270996
Validation loss: 2.211984932422638

Epoch: 5| Step: 5
Training loss: 0.8108125925064087
Validation loss: 2.272300064563751

Epoch: 5| Step: 6
Training loss: 0.866290271282196
Validation loss: 2.2385694682598114

Epoch: 5| Step: 7
Training loss: 1.0380938053131104
Validation loss: 2.2725570797920227

Epoch: 5| Step: 8
Training loss: 1.1933362483978271
Validation loss: 2.2541807939608893

Epoch: 5| Step: 9
Training loss: 0.8103698492050171
Validation loss: 2.1821187188227973

Epoch: 5| Step: 10
Training loss: 0.6272835731506348
Validation loss: 2.2416920363903046

Epoch: 5| Step: 11
Training loss: 0.6482738852500916
Validation loss: 2.221045047044754

Epoch: 232| Step: 0
Training loss: 1.1838667392730713
Validation loss: 2.17977582414945

Epoch: 5| Step: 1
Training loss: 0.6095508337020874
Validation loss: 2.142751177151998

Epoch: 5| Step: 2
Training loss: 1.1759154796600342
Validation loss: 2.2660203327735267

Epoch: 5| Step: 3
Training loss: 1.2048118114471436
Validation loss: 2.2247756818930307

Epoch: 5| Step: 4
Training loss: 0.7228047847747803
Validation loss: 2.2153552571932473

Epoch: 5| Step: 5
Training loss: 0.6538851261138916
Validation loss: 2.20660192767779

Epoch: 5| Step: 6
Training loss: 0.9335795640945435
Validation loss: 2.2532004366318383

Epoch: 5| Step: 7
Training loss: 1.0522956848144531
Validation loss: 2.2380144397417703

Epoch: 5| Step: 8
Training loss: 0.7135785818099976
Validation loss: 2.2043252189954123

Epoch: 5| Step: 9
Training loss: 1.0907758474349976
Validation loss: 2.301356946428617

Epoch: 5| Step: 10
Training loss: 0.8448681831359863
Validation loss: 2.236016203959783

Epoch: 5| Step: 11
Training loss: 0.281551718711853
Validation loss: 2.2896506687005362

Epoch: 233| Step: 0
Training loss: 1.2179254293441772
Validation loss: 2.281602591276169

Epoch: 5| Step: 1
Training loss: 1.1959534883499146
Validation loss: 2.2579621076583862

Epoch: 5| Step: 2
Training loss: 0.7491990923881531
Validation loss: 2.2121232797702155

Epoch: 5| Step: 3
Training loss: 0.9309159517288208
Validation loss: 2.2256102611621222

Epoch: 5| Step: 4
Training loss: 0.3989195227622986
Validation loss: 2.256430814663569

Epoch: 5| Step: 5
Training loss: 0.92609041929245
Validation loss: 2.204506273070971

Epoch: 5| Step: 6
Training loss: 0.5609707236289978
Validation loss: 2.1839195241530738

Epoch: 5| Step: 7
Training loss: 0.8471345901489258
Validation loss: 2.196416586637497

Epoch: 5| Step: 8
Training loss: 0.8370242118835449
Validation loss: 2.1967076510190964

Epoch: 5| Step: 9
Training loss: 1.2619407176971436
Validation loss: 2.2478486796220145

Epoch: 5| Step: 10
Training loss: 0.7585185170173645
Validation loss: 2.204598973194758

Epoch: 5| Step: 11
Training loss: 0.461942195892334
Validation loss: 2.2449986338615417

Epoch: 234| Step: 0
Training loss: 0.7183742523193359
Validation loss: 2.2322721083958945

Epoch: 5| Step: 1
Training loss: 0.5842058062553406
Validation loss: 2.274184117714564

Epoch: 5| Step: 2
Training loss: 0.744775652885437
Validation loss: 2.2365588943163552

Epoch: 5| Step: 3
Training loss: 1.0151331424713135
Validation loss: 2.2439697980880737

Epoch: 5| Step: 4
Training loss: 0.8120933771133423
Validation loss: 2.2748053471247354

Epoch: 5| Step: 5
Training loss: 0.8101833462715149
Validation loss: 2.2647281140089035

Epoch: 5| Step: 6
Training loss: 0.9960403442382812
Validation loss: 2.293094332019488

Epoch: 5| Step: 7
Training loss: 1.2035645246505737
Validation loss: 2.2497939815123877

Epoch: 5| Step: 8
Training loss: 1.5118498802185059
Validation loss: 2.223542725046476

Epoch: 5| Step: 9
Training loss: 0.46864062547683716
Validation loss: 2.2441958288351693

Epoch: 5| Step: 10
Training loss: 0.8367921710014343
Validation loss: 2.27772855758667

Epoch: 5| Step: 11
Training loss: 1.0080468654632568
Validation loss: 2.2146614293257394

Epoch: 235| Step: 0
Training loss: 0.9130443334579468
Validation loss: 2.2209052542845407

Epoch: 5| Step: 1
Training loss: 0.8557899594306946
Validation loss: 2.197563573718071

Epoch: 5| Step: 2
Training loss: 1.083979845046997
Validation loss: 2.219146192073822

Epoch: 5| Step: 3
Training loss: 1.0988624095916748
Validation loss: 2.226948375503222

Epoch: 5| Step: 4
Training loss: 0.5215350389480591
Validation loss: 2.192769626776377

Epoch: 5| Step: 5
Training loss: 0.8595542907714844
Validation loss: 2.2425088038047156

Epoch: 5| Step: 6
Training loss: 0.5256125330924988
Validation loss: 2.227372427781423

Epoch: 5| Step: 7
Training loss: 1.1080973148345947
Validation loss: 2.3053046464920044

Epoch: 5| Step: 8
Training loss: 1.0775114297866821
Validation loss: 2.301388457417488

Epoch: 5| Step: 9
Training loss: 0.9386690258979797
Validation loss: 2.2493510097265244

Epoch: 5| Step: 10
Training loss: 0.4518098831176758
Validation loss: 2.2062284350395203

Epoch: 5| Step: 11
Training loss: 0.8836082220077515
Validation loss: 2.225672389070193

Epoch: 236| Step: 0
Training loss: 0.8377526998519897
Validation loss: 2.266263633966446

Epoch: 5| Step: 1
Training loss: 0.7418070435523987
Validation loss: 2.201508720715841

Epoch: 5| Step: 2
Training loss: 0.9895840883255005
Validation loss: 2.218240683277448

Epoch: 5| Step: 3
Training loss: 0.8623552322387695
Validation loss: 2.1775735119978585

Epoch: 5| Step: 4
Training loss: 0.7927919030189514
Validation loss: 2.2318360408147178

Epoch: 5| Step: 5
Training loss: 0.5748859643936157
Validation loss: 2.23240273197492

Epoch: 5| Step: 6
Training loss: 0.6551567316055298
Validation loss: 2.2312283317248025

Epoch: 5| Step: 7
Training loss: 0.8035343289375305
Validation loss: 2.2805606375137963

Epoch: 5| Step: 8
Training loss: 0.6889333724975586
Validation loss: 2.189376105864843

Epoch: 5| Step: 9
Training loss: 0.8855632543563843
Validation loss: 2.234671398997307

Epoch: 5| Step: 10
Training loss: 1.0816205739974976
Validation loss: 2.2655906130870185

Epoch: 5| Step: 11
Training loss: 0.640503466129303
Validation loss: 2.235107511281967

Epoch: 237| Step: 0
Training loss: 0.8114500045776367
Validation loss: 2.283560266097387

Epoch: 5| Step: 1
Training loss: 0.6246213912963867
Validation loss: 2.268058488766352

Epoch: 5| Step: 2
Training loss: 0.5737149715423584
Validation loss: 2.276877502600352

Epoch: 5| Step: 3
Training loss: 0.9578421711921692
Validation loss: 2.239231323202451

Epoch: 5| Step: 4
Training loss: 0.6171050667762756
Validation loss: 2.1518243650595346

Epoch: 5| Step: 5
Training loss: 1.317670226097107
Validation loss: 2.235227564970652

Epoch: 5| Step: 6
Training loss: 0.9340497851371765
Validation loss: 2.239897812406222

Epoch: 5| Step: 7
Training loss: 0.8614985346794128
Validation loss: 2.2126746078332267

Epoch: 5| Step: 8
Training loss: 1.1158486604690552
Validation loss: 2.187716379761696

Epoch: 5| Step: 9
Training loss: 0.8983537554740906
Validation loss: 2.2459614326556525

Epoch: 5| Step: 10
Training loss: 0.7880194187164307
Validation loss: 2.2080165445804596

Epoch: 5| Step: 11
Training loss: 0.8602489829063416
Validation loss: 2.1913903752962747

Epoch: 238| Step: 0
Training loss: 0.7675944566726685
Validation loss: 2.203615332643191

Epoch: 5| Step: 1
Training loss: 1.0852800607681274
Validation loss: 2.2626531571149826

Epoch: 5| Step: 2
Training loss: 0.4720875322818756
Validation loss: 2.2070756405591965

Epoch: 5| Step: 3
Training loss: 1.195509910583496
Validation loss: 2.2311059137185416

Epoch: 5| Step: 4
Training loss: 0.6067652106285095
Validation loss: 2.2072494328022003

Epoch: 5| Step: 5
Training loss: 0.9978009462356567
Validation loss: 2.2295325249433517

Epoch: 5| Step: 6
Training loss: 0.5587505102157593
Validation loss: 2.20814677576224

Epoch: 5| Step: 7
Training loss: 0.791354775428772
Validation loss: 2.243707130352656

Epoch: 5| Step: 8
Training loss: 0.6435051560401917
Validation loss: 2.2093865970770517

Epoch: 5| Step: 9
Training loss: 1.1101967096328735
Validation loss: 2.2564005156358085

Epoch: 5| Step: 10
Training loss: 0.9967588186264038
Validation loss: 2.2348462442557016

Epoch: 5| Step: 11
Training loss: 0.3900226354598999
Validation loss: 2.297650287548701

Epoch: 239| Step: 0
Training loss: 0.7522144317626953
Validation loss: 2.204373757044474

Epoch: 5| Step: 1
Training loss: 0.6929959058761597
Validation loss: 2.200918530424436

Epoch: 5| Step: 2
Training loss: 0.4657033085823059
Validation loss: 2.243395581841469

Epoch: 5| Step: 3
Training loss: 0.5988177061080933
Validation loss: 2.2458697259426117

Epoch: 5| Step: 4
Training loss: 0.9271098375320435
Validation loss: 2.1735149025917053

Epoch: 5| Step: 5
Training loss: 1.0632679462432861
Validation loss: 2.225640540321668

Epoch: 5| Step: 6
Training loss: 0.6836636662483215
Validation loss: 2.1315718988577523

Epoch: 5| Step: 7
Training loss: 0.9185556173324585
Validation loss: 2.2581791083017984

Epoch: 5| Step: 8
Training loss: 0.7052617073059082
Validation loss: 2.2136249591906867

Epoch: 5| Step: 9
Training loss: 0.6575520038604736
Validation loss: 2.235845004518827

Epoch: 5| Step: 10
Training loss: 1.3546234369277954
Validation loss: 2.260792722304662

Epoch: 5| Step: 11
Training loss: 0.7864959239959717
Validation loss: 2.230868677298228

Epoch: 240| Step: 0
Training loss: 0.7687240839004517
Validation loss: 2.219780385494232

Epoch: 5| Step: 1
Training loss: 0.7688440084457397
Validation loss: 2.242219001054764

Epoch: 5| Step: 2
Training loss: 0.499255508184433
Validation loss: 2.2278907845417657

Epoch: 5| Step: 3
Training loss: 0.7995120882987976
Validation loss: 2.260335306326548

Epoch: 5| Step: 4
Training loss: 0.8722065687179565
Validation loss: 2.2540349662303925

Epoch: 5| Step: 5
Training loss: 1.1080842018127441
Validation loss: 2.2338510354359946

Epoch: 5| Step: 6
Training loss: 1.1618597507476807
Validation loss: 2.2319566110769906

Epoch: 5| Step: 7
Training loss: 0.8325284719467163
Validation loss: 2.247330754995346

Epoch: 5| Step: 8
Training loss: 0.9158824682235718
Validation loss: 2.171155576904615

Epoch: 5| Step: 9
Training loss: 0.7696000337600708
Validation loss: 2.2664631803830466

Epoch: 5| Step: 10
Training loss: 0.48941031098365784
Validation loss: 2.2581398586432138

Epoch: 5| Step: 11
Training loss: 1.2851858139038086
Validation loss: 2.2608436892429986

Epoch: 241| Step: 0
Training loss: 1.1260185241699219
Validation loss: 2.277284493048986

Epoch: 5| Step: 1
Training loss: 0.9922907948493958
Validation loss: 2.217010756333669

Epoch: 5| Step: 2
Training loss: 1.0976746082305908
Validation loss: 2.190587376554807

Epoch: 5| Step: 3
Training loss: 0.811052680015564
Validation loss: 2.252278486887614

Epoch: 5| Step: 4
Training loss: 0.7878111004829407
Validation loss: 2.2324094623327255

Epoch: 5| Step: 5
Training loss: 0.8927295804023743
Validation loss: 2.2464959919452667

Epoch: 5| Step: 6
Training loss: 0.9172139167785645
Validation loss: 2.2681295573711395

Epoch: 5| Step: 7
Training loss: 0.7468118667602539
Validation loss: 2.2136631906032562

Epoch: 5| Step: 8
Training loss: 0.6356416940689087
Validation loss: 2.234723453720411

Epoch: 5| Step: 9
Training loss: 0.552283525466919
Validation loss: 2.249717821677526

Epoch: 5| Step: 10
Training loss: 0.7047661542892456
Validation loss: 2.239187180995941

Epoch: 5| Step: 11
Training loss: 0.8062155246734619
Validation loss: 2.2477287153402963

Epoch: 242| Step: 0
Training loss: 0.5480028390884399
Validation loss: 2.236150488257408

Epoch: 5| Step: 1
Training loss: 0.9636496305465698
Validation loss: 2.272440473238627

Epoch: 5| Step: 2
Training loss: 0.6677979230880737
Validation loss: 2.264249781767527

Epoch: 5| Step: 3
Training loss: 0.9087972640991211
Validation loss: 2.2912981609503427

Epoch: 5| Step: 4
Training loss: 0.6193200349807739
Validation loss: 2.3011348942915597

Epoch: 5| Step: 5
Training loss: 0.8673745393753052
Validation loss: 2.2082160065571466

Epoch: 5| Step: 6
Training loss: 1.1036373376846313
Validation loss: 2.295894672473272

Epoch: 5| Step: 7
Training loss: 0.5169069766998291
Validation loss: 2.283999736110369

Epoch: 5| Step: 8
Training loss: 1.245130181312561
Validation loss: 2.2334802945454917

Epoch: 5| Step: 9
Training loss: 0.6725847125053406
Validation loss: 2.2401818136374154

Epoch: 5| Step: 10
Training loss: 1.168241024017334
Validation loss: 2.238746260603269

Epoch: 5| Step: 11
Training loss: 0.46495890617370605
Validation loss: 2.282116631666819

Epoch: 243| Step: 0
Training loss: 1.1850231885910034
Validation loss: 2.2856984535853067

Epoch: 5| Step: 1
Training loss: 1.3793964385986328
Validation loss: 2.267835875352224

Epoch: 5| Step: 2
Training loss: 0.8508834838867188
Validation loss: 2.2518569429715476

Epoch: 5| Step: 3
Training loss: 0.6212023496627808
Validation loss: 2.274559418360392

Epoch: 5| Step: 4
Training loss: 0.5013012886047363
Validation loss: 2.26211708287398

Epoch: 5| Step: 5
Training loss: 0.5066970586776733
Validation loss: 2.2475490321715674

Epoch: 5| Step: 6
Training loss: 0.7390670776367188
Validation loss: 2.2124650379021964

Epoch: 5| Step: 7
Training loss: 0.6195193529129028
Validation loss: 2.2783370365699134

Epoch: 5| Step: 8
Training loss: 0.9031058549880981
Validation loss: 2.218768815199534

Epoch: 5| Step: 9
Training loss: 0.7545287013053894
Validation loss: 2.2268421600262323

Epoch: 5| Step: 10
Training loss: 0.6509848833084106
Validation loss: 2.221046810348829

Epoch: 5| Step: 11
Training loss: 1.2158539295196533
Validation loss: 2.229014257589976

Epoch: 244| Step: 0
Training loss: 0.6568397283554077
Validation loss: 2.2441200464963913

Epoch: 5| Step: 1
Training loss: 0.9757450222969055
Validation loss: 2.2691102723280587

Epoch: 5| Step: 2
Training loss: 0.6110069155693054
Validation loss: 2.2431913961966834

Epoch: 5| Step: 3
Training loss: 0.5307629704475403
Validation loss: 2.224994177619616

Epoch: 5| Step: 4
Training loss: 0.7472206354141235
Validation loss: 2.2978001783291497

Epoch: 5| Step: 5
Training loss: 0.8668549656867981
Validation loss: 2.2073651403188705

Epoch: 5| Step: 6
Training loss: 0.879479706287384
Validation loss: 2.1907135794560113

Epoch: 5| Step: 7
Training loss: 1.0029691457748413
Validation loss: 2.200294723113378

Epoch: 5| Step: 8
Training loss: 0.7127686738967896
Validation loss: 2.2374819219112396

Epoch: 5| Step: 9
Training loss: 1.168407917022705
Validation loss: 2.2769581576188407

Epoch: 5| Step: 10
Training loss: 0.9620318412780762
Validation loss: 2.2595848043759665

Epoch: 5| Step: 11
Training loss: 0.2122950553894043
Validation loss: 2.21951853732268

Epoch: 245| Step: 0
Training loss: 0.7523015737533569
Validation loss: 2.218163768450419

Epoch: 5| Step: 1
Training loss: 1.29120671749115
Validation loss: 2.2898816565672555

Epoch: 5| Step: 2
Training loss: 0.7277948260307312
Validation loss: 2.265317107240359

Epoch: 5| Step: 3
Training loss: 1.579027771949768
Validation loss: 2.219336062669754

Epoch: 5| Step: 4
Training loss: 0.6618814468383789
Validation loss: 2.3163206974665322

Epoch: 5| Step: 5
Training loss: 0.5642842054367065
Validation loss: 2.2911776502927146

Epoch: 5| Step: 6
Training loss: 0.9120581746101379
Validation loss: 2.242471923430761

Epoch: 5| Step: 7
Training loss: 0.821080207824707
Validation loss: 2.276401311159134

Epoch: 5| Step: 8
Training loss: 0.5819329023361206
Validation loss: 2.2734514574209848

Epoch: 5| Step: 9
Training loss: 0.5630241632461548
Validation loss: 2.3263154923915863

Epoch: 5| Step: 10
Training loss: 0.7052286863327026
Validation loss: 2.291828994949659

Epoch: 5| Step: 11
Training loss: 0.559391975402832
Validation loss: 2.2360194822152457

Epoch: 246| Step: 0
Training loss: 0.6714898347854614
Validation loss: 2.259473443031311

Epoch: 5| Step: 1
Training loss: 0.8085467219352722
Validation loss: 2.3004264483849206

Epoch: 5| Step: 2
Training loss: 1.1040303707122803
Validation loss: 2.2637174328168235

Epoch: 5| Step: 3
Training loss: 0.5950122475624084
Validation loss: 2.2582822740077972

Epoch: 5| Step: 4
Training loss: 0.9543203115463257
Validation loss: 2.3092116316159568

Epoch: 5| Step: 5
Training loss: 1.1296833753585815
Validation loss: 2.2567132264375687

Epoch: 5| Step: 6
Training loss: 0.5019203424453735
Validation loss: 2.2974736789862313

Epoch: 5| Step: 7
Training loss: 0.6624302864074707
Validation loss: 2.1910880158344903

Epoch: 5| Step: 8
Training loss: 0.6114466786384583
Validation loss: 2.2596548895041146

Epoch: 5| Step: 9
Training loss: 0.7829214930534363
Validation loss: 2.243918309609095

Epoch: 5| Step: 10
Training loss: 1.1153236627578735
Validation loss: 2.259811485807101

Epoch: 5| Step: 11
Training loss: 0.647101879119873
Validation loss: 2.20164688428243

Epoch: 247| Step: 0
Training loss: 0.687168300151825
Validation loss: 2.2570019563039145

Epoch: 5| Step: 1
Training loss: 0.757757306098938
Validation loss: 2.2740900268157325

Epoch: 5| Step: 2
Training loss: 0.8230162858963013
Validation loss: 2.273952474196752

Epoch: 5| Step: 3
Training loss: 0.703991174697876
Validation loss: 2.1965545316537223

Epoch: 5| Step: 4
Training loss: 0.8029365539550781
Validation loss: 2.288825968901316

Epoch: 5| Step: 5
Training loss: 0.7229382991790771
Validation loss: 2.2364621261755624

Epoch: 5| Step: 6
Training loss: 0.9384970664978027
Validation loss: 2.2095970263083777

Epoch: 5| Step: 7
Training loss: 1.130357265472412
Validation loss: 2.272150913874308

Epoch: 5| Step: 8
Training loss: 0.5115106701850891
Validation loss: 2.2760442197322845

Epoch: 5| Step: 9
Training loss: 1.1664378643035889
Validation loss: 2.266727864742279

Epoch: 5| Step: 10
Training loss: 0.830845832824707
Validation loss: 2.218811566630999

Epoch: 5| Step: 11
Training loss: 0.6799288988113403
Validation loss: 2.246113652984301

Epoch: 248| Step: 0
Training loss: 0.8592170476913452
Validation loss: 2.230545789003372

Epoch: 5| Step: 1
Training loss: 0.49668312072753906
Validation loss: 2.2366667886575065

Epoch: 5| Step: 2
Training loss: 0.9259023666381836
Validation loss: 2.2419048647085824

Epoch: 5| Step: 3
Training loss: 0.7700400352478027
Validation loss: 2.200985382000605

Epoch: 5| Step: 4
Training loss: 1.3333933353424072
Validation loss: 2.3214287757873535

Epoch: 5| Step: 5
Training loss: 0.7635728716850281
Validation loss: 2.295210048556328

Epoch: 5| Step: 6
Training loss: 0.600581169128418
Validation loss: 2.2799871067206063

Epoch: 5| Step: 7
Training loss: 0.7502108216285706
Validation loss: 2.2830080489317575

Epoch: 5| Step: 8
Training loss: 1.0867184400558472
Validation loss: 2.2793403367201486

Epoch: 5| Step: 9
Training loss: 0.686841607093811
Validation loss: 2.3010183771451316

Epoch: 5| Step: 10
Training loss: 0.6484817266464233
Validation loss: 2.245116581519445

Epoch: 5| Step: 11
Training loss: 0.9945204257965088
Validation loss: 2.2362575282653174

Epoch: 249| Step: 0
Training loss: 0.7986739873886108
Validation loss: 2.2304362654685974

Epoch: 5| Step: 1
Training loss: 0.8474828004837036
Validation loss: 2.2584758400917053

Epoch: 5| Step: 2
Training loss: 0.5765368342399597
Validation loss: 2.226253325740496

Epoch: 5| Step: 3
Training loss: 0.9217302203178406
Validation loss: 2.2363117784261703

Epoch: 5| Step: 4
Training loss: 0.7953367233276367
Validation loss: 2.295786847670873

Epoch: 5| Step: 5
Training loss: 0.9379429817199707
Validation loss: 2.211666837334633

Epoch: 5| Step: 6
Training loss: 1.0757585763931274
Validation loss: 2.2848474780718484

Epoch: 5| Step: 7
Training loss: 0.7352080345153809
Validation loss: 2.265385160843531

Epoch: 5| Step: 8
Training loss: 0.5866900086402893
Validation loss: 2.3407437006632485

Epoch: 5| Step: 9
Training loss: 0.7182139754295349
Validation loss: 2.251961270968119

Epoch: 5| Step: 10
Training loss: 0.8657798767089844
Validation loss: 2.235419442256292

Epoch: 5| Step: 11
Training loss: 2.058511734008789
Validation loss: 2.2678253054618835

Epoch: 250| Step: 0
Training loss: 0.9150390625
Validation loss: 2.2178019483884177

Epoch: 5| Step: 1
Training loss: 0.999430775642395
Validation loss: 2.2856107354164124

Epoch: 5| Step: 2
Training loss: 0.6368187665939331
Validation loss: 2.2176588475704193

Epoch: 5| Step: 3
Training loss: 1.0073144435882568
Validation loss: 2.230887154738108

Epoch: 5| Step: 4
Training loss: 0.6991251111030579
Validation loss: 2.2451008806626

Epoch: 5| Step: 5
Training loss: 0.5646287798881531
Validation loss: 2.277918110291163

Epoch: 5| Step: 6
Training loss: 0.5530917048454285
Validation loss: 2.2843429148197174

Epoch: 5| Step: 7
Training loss: 0.7863752245903015
Validation loss: 2.2864228636026382

Epoch: 5| Step: 8
Training loss: 0.8526400327682495
Validation loss: 2.239890977740288

Epoch: 5| Step: 9
Training loss: 1.175775408744812
Validation loss: 2.306643486022949

Epoch: 5| Step: 10
Training loss: 0.6823205947875977
Validation loss: 2.2959450036287308

Epoch: 5| Step: 11
Training loss: 1.4245426654815674
Validation loss: 2.3091172575950623

Testing loss: 1.9995458863621993
