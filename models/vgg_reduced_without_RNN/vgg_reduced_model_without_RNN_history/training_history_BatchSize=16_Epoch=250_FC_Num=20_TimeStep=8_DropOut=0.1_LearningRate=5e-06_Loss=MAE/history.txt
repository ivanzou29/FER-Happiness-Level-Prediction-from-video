Epoch: 1| Step: 0
Training loss: 5.039731025695801
Validation loss: 4.546789844830831

Epoch: 6| Step: 1
Training loss: 3.890723943710327
Validation loss: 4.531746705373128

Epoch: 6| Step: 2
Training loss: 5.109498023986816
Validation loss: 4.518275419871013

Epoch: 6| Step: 3
Training loss: 4.919912815093994
Validation loss: 4.505053838094075

Epoch: 6| Step: 4
Training loss: 4.732819557189941
Validation loss: 4.487894336382548

Epoch: 6| Step: 5
Training loss: 5.101491928100586
Validation loss: 4.472803195317586

Epoch: 6| Step: 6
Training loss: 3.8951377868652344
Validation loss: 4.4587801694869995

Epoch: 6| Step: 7
Training loss: 4.659769058227539
Validation loss: 4.441574414571126

Epoch: 6| Step: 8
Training loss: 5.643332004547119
Validation loss: 4.426279346148173

Epoch: 6| Step: 9
Training loss: 4.560244083404541
Validation loss: 4.410790681838989

Epoch: 6| Step: 10
Training loss: 4.001323699951172
Validation loss: 4.391864577929179

Epoch: 6| Step: 11
Training loss: 4.899508476257324
Validation loss: 4.373718897501628

Epoch: 6| Step: 12
Training loss: 3.6652607917785645
Validation loss: 4.356597622235616

Epoch: 6| Step: 13
Training loss: 3.7119274139404297
Validation loss: 4.333367625872294

Epoch: 2| Step: 0
Training loss: 5.023382186889648
Validation loss: 4.312105894088745

Epoch: 6| Step: 1
Training loss: 4.532414436340332
Validation loss: 4.289558410644531

Epoch: 6| Step: 2
Training loss: 3.709498167037964
Validation loss: 4.263539711634318

Epoch: 6| Step: 3
Training loss: 3.462873935699463
Validation loss: 4.234694004058838

Epoch: 6| Step: 4
Training loss: 3.8690929412841797
Validation loss: 4.208787401517232

Epoch: 6| Step: 5
Training loss: 4.235653400421143
Validation loss: 4.180447061856587

Epoch: 6| Step: 6
Training loss: 4.914895057678223
Validation loss: 4.150945107142131

Epoch: 6| Step: 7
Training loss: 5.054172992706299
Validation loss: 4.121796170870463

Epoch: 6| Step: 8
Training loss: 5.293360233306885
Validation loss: 4.088820854822795

Epoch: 6| Step: 9
Training loss: 4.230987071990967
Validation loss: 4.052851517995198

Epoch: 6| Step: 10
Training loss: 4.0746870040893555
Validation loss: 4.01609468460083

Epoch: 6| Step: 11
Training loss: 3.811854124069214
Validation loss: 3.9841408332188926

Epoch: 6| Step: 12
Training loss: 4.024787902832031
Validation loss: 3.9465126991271973

Epoch: 6| Step: 13
Training loss: 3.3727033138275146
Validation loss: 3.906367818514506

Epoch: 3| Step: 0
Training loss: 3.974576473236084
Validation loss: 3.8634320894877114

Epoch: 6| Step: 1
Training loss: 4.403916358947754
Validation loss: 3.8220905860265098

Epoch: 6| Step: 2
Training loss: 4.515003204345703
Validation loss: 3.778106451034546

Epoch: 6| Step: 3
Training loss: 3.0547218322753906
Validation loss: 3.7301514943440757

Epoch: 6| Step: 4
Training loss: 3.8813772201538086
Validation loss: 3.6730660597483316

Epoch: 6| Step: 5
Training loss: 4.072893142700195
Validation loss: 3.6275439262390137

Epoch: 6| Step: 6
Training loss: 3.171274185180664
Validation loss: 3.567615548769633

Epoch: 6| Step: 7
Training loss: 3.7119593620300293
Validation loss: 3.515652378400167

Epoch: 6| Step: 8
Training loss: 3.8656396865844727
Validation loss: 3.4535393714904785

Epoch: 6| Step: 9
Training loss: 2.8711555004119873
Validation loss: 3.390031576156616

Epoch: 6| Step: 10
Training loss: 3.583608627319336
Validation loss: 3.3272876342137656

Epoch: 6| Step: 11
Training loss: 2.9980061054229736
Validation loss: 3.267439325650533

Epoch: 6| Step: 12
Training loss: 3.48599910736084
Validation loss: 3.2046134869257608

Epoch: 6| Step: 13
Training loss: 3.5423319339752197
Validation loss: 3.1359723806381226

Epoch: 4| Step: 0
Training loss: 2.697136163711548
Validation loss: 3.0632445414861045

Epoch: 6| Step: 1
Training loss: 3.1775131225585938
Validation loss: 3.002281347910563

Epoch: 6| Step: 2
Training loss: 2.6826438903808594
Validation loss: 2.9289382696151733

Epoch: 6| Step: 3
Training loss: 3.036360502243042
Validation loss: 2.856280565261841

Epoch: 6| Step: 4
Training loss: 2.914687156677246
Validation loss: 2.7774800062179565

Epoch: 6| Step: 5
Training loss: 3.698652982711792
Validation loss: 2.69499933719635

Epoch: 6| Step: 6
Training loss: 2.6738853454589844
Validation loss: 2.5955969095230103

Epoch: 6| Step: 7
Training loss: 3.0908823013305664
Validation loss: 2.5129234790802

Epoch: 6| Step: 8
Training loss: 2.468553066253662
Validation loss: 2.4281011819839478

Epoch: 6| Step: 9
Training loss: 2.1153268814086914
Validation loss: 2.337241987387339

Epoch: 6| Step: 10
Training loss: 2.4692435264587402
Validation loss: 2.2783910234769187

Epoch: 6| Step: 11
Training loss: 2.4397530555725098
Validation loss: 2.226453979810079

Epoch: 6| Step: 12
Training loss: 2.083733558654785
Validation loss: 2.1933406988779702

Epoch: 6| Step: 13
Training loss: 1.9466986656188965
Validation loss: 2.1433077255884805

Epoch: 5| Step: 0
Training loss: 1.802686095237732
Validation loss: 2.1046336690584817

Epoch: 6| Step: 1
Training loss: 1.921167016029358
Validation loss: 2.0907883644104004

Epoch: 6| Step: 2
Training loss: 1.9902064800262451
Validation loss: 2.092236896355947

Epoch: 6| Step: 3
Training loss: 1.9499620199203491
Validation loss: 2.080899238586426

Epoch: 6| Step: 4
Training loss: 2.0934324264526367
Validation loss: 2.0964412490526834

Epoch: 6| Step: 5
Training loss: 1.3927615880966187
Validation loss: 2.0898709893226624

Epoch: 6| Step: 6
Training loss: 1.6111867427825928
Validation loss: 2.1135975122451782

Epoch: 6| Step: 7
Training loss: 2.4476311206817627
Validation loss: 2.140886147816976

Epoch: 6| Step: 8
Training loss: 2.9485669136047363
Validation loss: 2.145541469256083

Epoch: 6| Step: 9
Training loss: 1.6466233730316162
Validation loss: 2.1412177681922913

Epoch: 6| Step: 10
Training loss: 1.9708280563354492
Validation loss: 2.1605501572291055

Epoch: 6| Step: 11
Training loss: 2.4920918941497803
Validation loss: 2.1248870889345803

Epoch: 6| Step: 12
Training loss: 2.441878318786621
Validation loss: 2.149261554082235

Epoch: 6| Step: 13
Training loss: 2.466585874557495
Validation loss: 2.123457411924998

Epoch: 6| Step: 0
Training loss: 2.1736531257629395
Validation loss: 2.107608159383138

Epoch: 6| Step: 1
Training loss: 2.2388951778411865
Validation loss: 2.0974085330963135

Epoch: 6| Step: 2
Training loss: 2.163912296295166
Validation loss: 2.0851380228996277

Epoch: 6| Step: 3
Training loss: 2.133904218673706
Validation loss: 2.061582605044047

Epoch: 6| Step: 4
Training loss: 2.326500654220581
Validation loss: 2.080354650815328

Epoch: 6| Step: 5
Training loss: 1.6589939594268799
Validation loss: 2.083563248316447

Epoch: 6| Step: 6
Training loss: 1.9373310804367065
Validation loss: 2.062442402044932

Epoch: 6| Step: 7
Training loss: 2.305600643157959
Validation loss: 2.077687939008077

Epoch: 6| Step: 8
Training loss: 1.555051326751709
Validation loss: 2.078746199607849

Epoch: 6| Step: 9
Training loss: 1.9910845756530762
Validation loss: 2.0886035164197287

Epoch: 6| Step: 10
Training loss: 2.0139613151550293
Validation loss: 2.087999959786733

Epoch: 6| Step: 11
Training loss: 2.2294445037841797
Validation loss: 2.0764109094937644

Epoch: 6| Step: 12
Training loss: 1.9329806566238403
Validation loss: 2.0868189533551535

Epoch: 6| Step: 13
Training loss: 2.688878297805786
Validation loss: 2.064119875431061

Epoch: 7| Step: 0
Training loss: 1.5923712253570557
Validation loss: 2.077354907989502

Epoch: 6| Step: 1
Training loss: 1.91587495803833
Validation loss: 2.0505755146344504

Epoch: 6| Step: 2
Training loss: 2.7857325077056885
Validation loss: 2.074669679005941

Epoch: 6| Step: 3
Training loss: 2.816465377807617
Validation loss: 2.0554959575335183

Epoch: 6| Step: 4
Training loss: 2.050139904022217
Validation loss: 2.063920875390371

Epoch: 6| Step: 5
Training loss: 1.1927839517593384
Validation loss: 2.054171005884806

Epoch: 6| Step: 6
Training loss: 1.8051449060440063
Validation loss: 2.079075296719869

Epoch: 6| Step: 7
Training loss: 2.4104385375976562
Validation loss: 2.0880228678385415

Epoch: 6| Step: 8
Training loss: 2.6557044982910156
Validation loss: 2.087630053361257

Epoch: 6| Step: 9
Training loss: 2.137026071548462
Validation loss: 2.0671955744425454

Epoch: 6| Step: 10
Training loss: 2.326871395111084
Validation loss: 2.082063635190328

Epoch: 6| Step: 11
Training loss: 1.8169729709625244
Validation loss: 2.0747719605763755

Epoch: 6| Step: 12
Training loss: 1.6544265747070312
Validation loss: 2.073727627595266

Epoch: 6| Step: 13
Training loss: 1.479842185974121
Validation loss: 2.0581804315249124

Epoch: 8| Step: 0
Training loss: 1.9853088855743408
Validation loss: 2.067317843437195

Epoch: 6| Step: 1
Training loss: 1.5337369441986084
Validation loss: 2.0709676146507263

Epoch: 6| Step: 2
Training loss: 2.118605136871338
Validation loss: 2.06440403064092

Epoch: 6| Step: 3
Training loss: 1.854687213897705
Validation loss: 2.0823641419410706

Epoch: 6| Step: 4
Training loss: 2.0176634788513184
Validation loss: 2.0727295875549316

Epoch: 6| Step: 5
Training loss: 1.8122389316558838
Validation loss: 2.0747914711634317

Epoch: 6| Step: 6
Training loss: 1.7187952995300293
Validation loss: 2.0885788202285767

Epoch: 6| Step: 7
Training loss: 1.8336780071258545
Validation loss: 2.076327383518219

Epoch: 6| Step: 8
Training loss: 2.121485948562622
Validation loss: 2.085351129372915

Epoch: 6| Step: 9
Training loss: 2.2919259071350098
Validation loss: 2.08424703280131

Epoch: 6| Step: 10
Training loss: 2.6813814640045166
Validation loss: 2.0642815828323364

Epoch: 6| Step: 11
Training loss: 2.5747575759887695
Validation loss: 2.05287629365921

Epoch: 6| Step: 12
Training loss: 2.3328795433044434
Validation loss: 2.072892645994822

Epoch: 6| Step: 13
Training loss: 1.729618787765503
Validation loss: 2.0624507069587708

Epoch: 9| Step: 0
Training loss: 1.8595354557037354
Validation loss: 2.0579983393351235

Epoch: 6| Step: 1
Training loss: 2.076793670654297
Validation loss: 2.048410415649414

Epoch: 6| Step: 2
Training loss: 1.526352047920227
Validation loss: 2.0509007970492044

Epoch: 6| Step: 3
Training loss: 2.172963857650757
Validation loss: 2.049469212690989

Epoch: 6| Step: 4
Training loss: 2.3099894523620605
Validation loss: 2.048941175142924

Epoch: 6| Step: 5
Training loss: 2.5632612705230713
Validation loss: 2.039409259955088

Epoch: 6| Step: 6
Training loss: 2.361837863922119
Validation loss: 2.0443429350852966

Epoch: 6| Step: 7
Training loss: 2.0324490070343018
Validation loss: 2.0520485043525696

Epoch: 6| Step: 8
Training loss: 1.65244722366333
Validation loss: 2.0443390210469565

Epoch: 6| Step: 9
Training loss: 1.347277045249939
Validation loss: 2.0412950118382773

Epoch: 6| Step: 10
Training loss: 1.7455106973648071
Validation loss: 2.0418760577837625

Epoch: 6| Step: 11
Training loss: 2.3051717281341553
Validation loss: 2.0474512775739035

Epoch: 6| Step: 12
Training loss: 2.1824898719787598
Validation loss: 2.054489036401113

Epoch: 6| Step: 13
Training loss: 2.337456226348877
Validation loss: 2.036134342352549

Epoch: 10| Step: 0
Training loss: 2.014552593231201
Validation loss: 2.0393637220064798

Epoch: 6| Step: 1
Training loss: 2.32528018951416
Validation loss: 2.0234087109565735

Epoch: 6| Step: 2
Training loss: 2.4731526374816895
Validation loss: 2.0564451018969216

Epoch: 6| Step: 3
Training loss: 2.1388416290283203
Validation loss: 2.0527365803718567

Epoch: 6| Step: 4
Training loss: 1.533469319343567
Validation loss: 2.0443100531895957

Epoch: 6| Step: 5
Training loss: 2.390493154525757
Validation loss: 2.0444150964419046

Epoch: 6| Step: 6
Training loss: 1.8895477056503296
Validation loss: 2.0701741576194763

Epoch: 6| Step: 7
Training loss: 1.5044175386428833
Validation loss: 2.0686741272608438

Epoch: 6| Step: 8
Training loss: 1.8651463985443115
Validation loss: 2.06847216685613

Epoch: 6| Step: 9
Training loss: 2.0095396041870117
Validation loss: 2.0661369959513345

Epoch: 6| Step: 10
Training loss: 1.929619550704956
Validation loss: 2.061429440975189

Epoch: 6| Step: 11
Training loss: 3.0761446952819824
Validation loss: 2.050406893094381

Epoch: 6| Step: 12
Training loss: 2.1146020889282227
Validation loss: 2.035857637723287

Epoch: 6| Step: 13
Training loss: 1.4042460918426514
Validation loss: 2.0437437891960144

Epoch: 11| Step: 0
Training loss: 2.565054178237915
Validation loss: 2.031103471914927

Epoch: 6| Step: 1
Training loss: 2.4513778686523438
Validation loss: 2.0445244908332825

Epoch: 6| Step: 2
Training loss: 2.1865766048431396
Validation loss: 2.0225034952163696

Epoch: 6| Step: 3
Training loss: 1.8141427040100098
Validation loss: 2.0196532209714255

Epoch: 6| Step: 4
Training loss: 1.910440444946289
Validation loss: 2.0476189851760864

Epoch: 6| Step: 5
Training loss: 1.7536489963531494
Validation loss: 2.039691964785258

Epoch: 6| Step: 6
Training loss: 2.1547820568084717
Validation loss: 2.0346385637919107

Epoch: 6| Step: 7
Training loss: 1.947243332862854
Validation loss: 2.0374974807103476

Epoch: 6| Step: 8
Training loss: 1.9236321449279785
Validation loss: 2.051418344179789

Epoch: 6| Step: 9
Training loss: 2.3798933029174805
Validation loss: 2.051248788833618

Epoch: 6| Step: 10
Training loss: 2.3620641231536865
Validation loss: 2.059389352798462

Epoch: 6| Step: 11
Training loss: 1.6009840965270996
Validation loss: 2.0423447489738464

Epoch: 6| Step: 12
Training loss: 1.863945484161377
Validation loss: 2.0551071166992188

Epoch: 6| Step: 13
Training loss: 1.51492440700531
Validation loss: 2.0602471828460693

Epoch: 12| Step: 0
Training loss: 1.9136736392974854
Validation loss: 2.061926861604055

Epoch: 6| Step: 1
Training loss: 1.9544131755828857
Validation loss: 2.0516612927118936

Epoch: 6| Step: 2
Training loss: 2.1363892555236816
Validation loss: 2.071462094783783

Epoch: 6| Step: 3
Training loss: 2.0308823585510254
Validation loss: 2.0585752924283347

Epoch: 6| Step: 4
Training loss: 2.48577880859375
Validation loss: 2.0685530304908752

Epoch: 6| Step: 5
Training loss: 1.8315308094024658
Validation loss: 2.0522829492886863

Epoch: 6| Step: 6
Training loss: 2.894517421722412
Validation loss: 2.055029292901357

Epoch: 6| Step: 7
Training loss: 1.696731448173523
Validation loss: 2.0623477498690286

Epoch: 6| Step: 8
Training loss: 1.7682769298553467
Validation loss: 2.0600160360336304

Epoch: 6| Step: 9
Training loss: 1.6451822519302368
Validation loss: 2.0544396241505942

Epoch: 6| Step: 10
Training loss: 1.411224126815796
Validation loss: 2.0392074584960938

Epoch: 6| Step: 11
Training loss: 2.1423022747039795
Validation loss: 2.0442087848981223

Epoch: 6| Step: 12
Training loss: 2.3592076301574707
Validation loss: 2.0442203481992087

Epoch: 6| Step: 13
Training loss: 2.0193753242492676
Validation loss: 2.0426287253697715

Epoch: 13| Step: 0
Training loss: 2.315394401550293
Validation loss: 2.026061713695526

Epoch: 6| Step: 1
Training loss: 2.102649450302124
Validation loss: 2.056915005048116

Epoch: 6| Step: 2
Training loss: 1.8582613468170166
Validation loss: 2.0242421627044678

Epoch: 6| Step: 3
Training loss: 1.7122113704681396
Validation loss: 2.021081805229187

Epoch: 6| Step: 4
Training loss: 1.593505620956421
Validation loss: 2.0535247127215066

Epoch: 6| Step: 5
Training loss: 2.6907806396484375
Validation loss: 2.0181257128715515

Epoch: 6| Step: 6
Training loss: 1.839706540107727
Validation loss: 2.0687591632207236

Epoch: 6| Step: 7
Training loss: 1.725064754486084
Validation loss: 2.051873584588369

Epoch: 6| Step: 8
Training loss: 2.944230318069458
Validation loss: 2.0436293880144754

Epoch: 6| Step: 9
Training loss: 1.7633042335510254
Validation loss: 2.019375801086426

Epoch: 6| Step: 10
Training loss: 1.8931270837783813
Validation loss: 2.0204195380210876

Epoch: 6| Step: 11
Training loss: 1.60874605178833
Validation loss: 2.040952821572622

Epoch: 6| Step: 12
Training loss: 1.8127226829528809
Validation loss: 2.0233739018440247

Epoch: 6| Step: 13
Training loss: 2.4002652168273926
Validation loss: 2.0357700983683267

Epoch: 14| Step: 0
Training loss: 2.6079440116882324
Validation loss: 2.0208392341931662

Epoch: 6| Step: 1
Training loss: 1.7860941886901855
Validation loss: 2.032927850882212

Epoch: 6| Step: 2
Training loss: 1.6413285732269287
Validation loss: 2.03609565893809

Epoch: 6| Step: 3
Training loss: 1.8789719343185425
Validation loss: 2.0532227953275046

Epoch: 6| Step: 4
Training loss: 1.4833285808563232
Validation loss: 2.0525678992271423

Epoch: 6| Step: 5
Training loss: 1.4502787590026855
Validation loss: 2.049770712852478

Epoch: 6| Step: 6
Training loss: 2.5723202228546143
Validation loss: 2.05296661456426

Epoch: 6| Step: 7
Training loss: 3.104707956314087
Validation loss: 2.038041611512502

Epoch: 6| Step: 8
Training loss: 1.257596731185913
Validation loss: 2.0510384241739907

Epoch: 6| Step: 9
Training loss: 2.4552035331726074
Validation loss: 2.063898046811422

Epoch: 6| Step: 10
Training loss: 2.057832956314087
Validation loss: 2.057237168153127

Epoch: 6| Step: 11
Training loss: 1.6923948526382446
Validation loss: 2.0606443087259927

Epoch: 6| Step: 12
Training loss: 1.8607234954833984
Validation loss: 2.0589941342671714

Epoch: 6| Step: 13
Training loss: 2.5889430046081543
Validation loss: 2.043294449647268

Epoch: 15| Step: 0
Training loss: 1.9241328239440918
Validation loss: 2.051858921845754

Epoch: 6| Step: 1
Training loss: 1.7628440856933594
Validation loss: 2.0379467407862344

Epoch: 6| Step: 2
Training loss: 1.7368097305297852
Validation loss: 2.052002489566803

Epoch: 6| Step: 3
Training loss: 2.3776326179504395
Validation loss: 2.0340800484021506

Epoch: 6| Step: 4
Training loss: 2.601398229598999
Validation loss: 2.0328452388445535

Epoch: 6| Step: 5
Training loss: 1.4838900566101074
Validation loss: 2.032449464003245

Epoch: 6| Step: 6
Training loss: 2.394102096557617
Validation loss: 2.0217597285906472

Epoch: 6| Step: 7
Training loss: 1.8706696033477783
Validation loss: 2.0279432932535806

Epoch: 6| Step: 8
Training loss: 2.0396690368652344
Validation loss: 2.0273255507151284

Epoch: 6| Step: 9
Training loss: 1.9192219972610474
Validation loss: 2.0360547502835593

Epoch: 6| Step: 10
Training loss: 1.6034502983093262
Validation loss: 2.032737374305725

Epoch: 6| Step: 11
Training loss: 1.5883350372314453
Validation loss: 2.0284461180369058

Epoch: 6| Step: 12
Training loss: 2.7117457389831543
Validation loss: 2.028875450293223

Epoch: 6| Step: 13
Training loss: 2.412611961364746
Validation loss: 2.030579706033071

Epoch: 16| Step: 0
Training loss: 2.5718307495117188
Validation loss: 2.0143346587816873

Epoch: 6| Step: 1
Training loss: 2.480996608734131
Validation loss: 2.0338913997014365

Epoch: 6| Step: 2
Training loss: 1.9691039323806763
Validation loss: 2.0248515208562217

Epoch: 6| Step: 3
Training loss: 1.7151310443878174
Validation loss: 2.038318455219269

Epoch: 6| Step: 4
Training loss: 2.349196434020996
Validation loss: 2.0385985374450684

Epoch: 6| Step: 5
Training loss: 1.9317638874053955
Validation loss: 2.05105459690094

Epoch: 6| Step: 6
Training loss: 1.6445459127426147
Validation loss: 2.0531558990478516

Epoch: 6| Step: 7
Training loss: 2.14774751663208
Validation loss: 2.0632823705673218

Epoch: 6| Step: 8
Training loss: 1.7085853815078735
Validation loss: 2.0404163002967834

Epoch: 6| Step: 9
Training loss: 1.4564337730407715
Validation loss: 2.0466927886009216

Epoch: 6| Step: 10
Training loss: 2.1557531356811523
Validation loss: 2.042297581831614

Epoch: 6| Step: 11
Training loss: 2.1706602573394775
Validation loss: 2.066932658354441

Epoch: 6| Step: 12
Training loss: 1.953542947769165
Validation loss: 2.0543254017829895

Epoch: 6| Step: 13
Training loss: 2.216729164123535
Validation loss: 2.047110438346863

Epoch: 17| Step: 0
Training loss: 3.058602809906006
Validation loss: 2.0345728397369385

Epoch: 6| Step: 1
Training loss: 1.430424690246582
Validation loss: 2.022706607977549

Epoch: 6| Step: 2
Training loss: 2.146454334259033
Validation loss: 2.024028698603312

Epoch: 6| Step: 3
Training loss: 1.6850203275680542
Validation loss: 2.0215668082237244

Epoch: 6| Step: 4
Training loss: 2.4397659301757812
Validation loss: 2.017987012863159

Epoch: 6| Step: 5
Training loss: 1.6645455360412598
Validation loss: 2.0235758622487388

Epoch: 6| Step: 6
Training loss: 1.6758804321289062
Validation loss: 2.041465918223063

Epoch: 6| Step: 7
Training loss: 2.3884871006011963
Validation loss: 2.048475126425425

Epoch: 6| Step: 8
Training loss: 2.184105396270752
Validation loss: 2.0604092677434287

Epoch: 6| Step: 9
Training loss: 2.072871208190918
Validation loss: 2.0433501998583474

Epoch: 6| Step: 10
Training loss: 1.6792027950286865
Validation loss: 2.0378413001696267

Epoch: 6| Step: 11
Training loss: 2.442922830581665
Validation loss: 2.02434374888738

Epoch: 6| Step: 12
Training loss: 1.77610445022583
Validation loss: 2.030829071998596

Epoch: 6| Step: 13
Training loss: 2.087048053741455
Validation loss: 2.0230296651522317

Epoch: 18| Step: 0
Training loss: 1.672306776046753
Validation loss: 2.025140643119812

Epoch: 6| Step: 1
Training loss: 2.4512813091278076
Validation loss: 2.0193182229995728

Epoch: 6| Step: 2
Training loss: 1.9927184581756592
Validation loss: 2.015997886657715

Epoch: 6| Step: 3
Training loss: 1.691483497619629
Validation loss: 2.0225610931714377

Epoch: 6| Step: 4
Training loss: 2.0416791439056396
Validation loss: 2.0248940785725913

Epoch: 6| Step: 5
Training loss: 2.399418354034424
Validation loss: 2.03976837793986

Epoch: 6| Step: 6
Training loss: 1.572964072227478
Validation loss: 2.0424445271492004

Epoch: 6| Step: 7
Training loss: 1.5630120038986206
Validation loss: 2.0589406490325928

Epoch: 6| Step: 8
Training loss: 2.1455116271972656
Validation loss: 2.074705878893534

Epoch: 6| Step: 9
Training loss: 2.8799009323120117
Validation loss: 2.0702819228172302

Epoch: 6| Step: 10
Training loss: 1.98222017288208
Validation loss: 2.100998640060425

Epoch: 6| Step: 11
Training loss: 1.9642142057418823
Validation loss: 2.0910877188046775

Epoch: 6| Step: 12
Training loss: 2.193488121032715
Validation loss: 2.0947043697039285

Epoch: 6| Step: 13
Training loss: 1.6794253587722778
Validation loss: 2.0905521313349404

Epoch: 19| Step: 0
Training loss: 1.992942452430725
Validation loss: 2.071165402730306

Epoch: 6| Step: 1
Training loss: 2.6515727043151855
Validation loss: 2.0421087543169656

Epoch: 6| Step: 2
Training loss: 1.8910608291625977
Validation loss: 2.0524351994196572

Epoch: 6| Step: 3
Training loss: 2.304562568664551
Validation loss: 2.0426180958747864

Epoch: 6| Step: 4
Training loss: 2.631688117980957
Validation loss: 2.021216710408529

Epoch: 6| Step: 5
Training loss: 1.3553597927093506
Validation loss: 2.016026735305786

Epoch: 6| Step: 6
Training loss: 1.6237021684646606
Validation loss: 2.037644346555074

Epoch: 6| Step: 7
Training loss: 1.9488987922668457
Validation loss: 2.0270278056462607

Epoch: 6| Step: 8
Training loss: 1.6347180604934692
Validation loss: 2.0188862681388855

Epoch: 6| Step: 9
Training loss: 2.417348623275757
Validation loss: 2.036947508653005

Epoch: 6| Step: 10
Training loss: 2.3085036277770996
Validation loss: 2.034137030442556

Epoch: 6| Step: 11
Training loss: 2.1450953483581543
Validation loss: 2.0321515003840127

Epoch: 6| Step: 12
Training loss: 1.4071216583251953
Validation loss: 2.0172473192214966

Epoch: 6| Step: 13
Training loss: 1.9885205030441284
Validation loss: 2.029612382253011

Epoch: 20| Step: 0
Training loss: 1.717179298400879
Validation loss: 2.022321363290151

Epoch: 6| Step: 1
Training loss: 2.1538431644439697
Validation loss: 2.037184158960978

Epoch: 6| Step: 2
Training loss: 2.094728946685791
Validation loss: 2.0096020897229514

Epoch: 6| Step: 3
Training loss: 2.175243616104126
Validation loss: 2.0254246989885965

Epoch: 6| Step: 4
Training loss: 1.9760786294937134
Validation loss: 2.0145986676216125

Epoch: 6| Step: 5
Training loss: 2.109375238418579
Validation loss: 2.031033933162689

Epoch: 6| Step: 6
Training loss: 1.9563533067703247
Validation loss: 2.018461803595225

Epoch: 6| Step: 7
Training loss: 1.7043893337249756
Validation loss: 2.0360578298568726

Epoch: 6| Step: 8
Training loss: 1.5029796361923218
Validation loss: 2.0469582080841064

Epoch: 6| Step: 9
Training loss: 2.17783784866333
Validation loss: 2.043652832508087

Epoch: 6| Step: 10
Training loss: 1.543121337890625
Validation loss: 2.067258338133494

Epoch: 6| Step: 11
Training loss: 2.514404773712158
Validation loss: 2.06352162361145

Epoch: 6| Step: 12
Training loss: 2.687809467315674
Validation loss: 2.0768224596977234

Epoch: 6| Step: 13
Training loss: 1.9891173839569092
Validation loss: 2.1089428464571633

Epoch: 21| Step: 0
Training loss: 1.9287006855010986
Validation loss: 2.0907771587371826

Epoch: 6| Step: 1
Training loss: 1.9201388359069824
Validation loss: 2.064393679300944

Epoch: 6| Step: 2
Training loss: 1.415493130683899
Validation loss: 2.0429578026135764

Epoch: 6| Step: 3
Training loss: 1.7511485815048218
Validation loss: 2.041406810283661

Epoch: 6| Step: 4
Training loss: 2.0708112716674805
Validation loss: 2.0276918411254883

Epoch: 6| Step: 5
Training loss: 1.736351728439331
Validation loss: 2.045362194379171

Epoch: 6| Step: 6
Training loss: 2.125126600265503
Validation loss: 2.020444134871165

Epoch: 6| Step: 7
Training loss: 2.2018332481384277
Validation loss: 2.006436069806417

Epoch: 6| Step: 8
Training loss: 1.3912888765335083
Validation loss: 2.024002412954966

Epoch: 6| Step: 9
Training loss: 2.83416748046875
Validation loss: 2.0019134084383645

Epoch: 6| Step: 10
Training loss: 2.434415817260742
Validation loss: 2.0163604418436685

Epoch: 6| Step: 11
Training loss: 1.7890087366104126
Validation loss: 2.004234254360199

Epoch: 6| Step: 12
Training loss: 2.1132900714874268
Validation loss: 2.0229379733403525

Epoch: 6| Step: 13
Training loss: 2.2729039192199707
Validation loss: 2.002009948094686

Epoch: 22| Step: 0
Training loss: 2.3905858993530273
Validation loss: 2.032725989818573

Epoch: 6| Step: 1
Training loss: 1.2858895063400269
Validation loss: 2.008955975373586

Epoch: 6| Step: 2
Training loss: 1.7383415699005127
Validation loss: 2.027756154537201

Epoch: 6| Step: 3
Training loss: 1.4742155075073242
Validation loss: 2.0328750014305115

Epoch: 6| Step: 4
Training loss: 2.300323009490967
Validation loss: 2.0265159805615744

Epoch: 6| Step: 5
Training loss: 2.207502603530884
Validation loss: 2.0234881043434143

Epoch: 6| Step: 6
Training loss: 2.0297646522521973
Validation loss: 2.0207935174306235

Epoch: 6| Step: 7
Training loss: 1.9217857122421265
Validation loss: 2.033411979675293

Epoch: 6| Step: 8
Training loss: 3.2226009368896484
Validation loss: 2.045274257659912

Epoch: 6| Step: 9
Training loss: 1.9412022829055786
Validation loss: 2.0487990975379944

Epoch: 6| Step: 10
Training loss: 2.514505624771118
Validation loss: 2.047636568546295

Epoch: 6| Step: 11
Training loss: 1.3914594650268555
Validation loss: 2.039510508378347

Epoch: 6| Step: 12
Training loss: 1.7090626955032349
Validation loss: 2.023621459801992

Epoch: 6| Step: 13
Training loss: 2.032580614089966
Validation loss: 2.038649618625641

Epoch: 23| Step: 0
Training loss: 2.2719836235046387
Validation loss: 2.045818785826365

Epoch: 6| Step: 1
Training loss: 1.7839913368225098
Validation loss: 2.052957455317179

Epoch: 6| Step: 2
Training loss: 1.730392336845398
Validation loss: 2.033171276251475

Epoch: 6| Step: 3
Training loss: 1.7240540981292725
Validation loss: 2.064781824747721

Epoch: 6| Step: 4
Training loss: 1.908340334892273
Validation loss: 2.0445471008618674

Epoch: 6| Step: 5
Training loss: 2.11702299118042
Validation loss: 2.0539296666781106

Epoch: 6| Step: 6
Training loss: 1.926055908203125
Validation loss: 2.048792819182078

Epoch: 6| Step: 7
Training loss: 2.2827703952789307
Validation loss: 2.0486871798833213

Epoch: 6| Step: 8
Training loss: 2.5625064373016357
Validation loss: 2.053201675415039

Epoch: 6| Step: 9
Training loss: 2.030019521713257
Validation loss: 2.033845325311025

Epoch: 6| Step: 10
Training loss: 2.2822179794311523
Validation loss: 2.035995523134867

Epoch: 6| Step: 11
Training loss: 1.6526148319244385
Validation loss: 2.046728332837423

Epoch: 6| Step: 12
Training loss: 1.8054542541503906
Validation loss: 2.027091940244039

Epoch: 6| Step: 13
Training loss: 1.8162193298339844
Validation loss: 2.0219066540400186

Epoch: 24| Step: 0
Training loss: 1.607686996459961
Validation loss: 1.9928086002667744

Epoch: 6| Step: 1
Training loss: 1.717313528060913
Validation loss: 2.0053751468658447

Epoch: 6| Step: 2
Training loss: 2.1994996070861816
Validation loss: 2.0347971320152283

Epoch: 6| Step: 3
Training loss: 1.9816089868545532
Validation loss: 2.0300312439600625

Epoch: 6| Step: 4
Training loss: 1.7597897052764893
Validation loss: 2.024287243684133

Epoch: 6| Step: 5
Training loss: 2.1849365234375
Validation loss: 2.0176775455474854

Epoch: 6| Step: 6
Training loss: 1.7584872245788574
Validation loss: 2.034741202990214

Epoch: 6| Step: 7
Training loss: 1.998715877532959
Validation loss: 2.0195487340291343

Epoch: 6| Step: 8
Training loss: 1.9676141738891602
Validation loss: 2.017370621363322

Epoch: 6| Step: 9
Training loss: 1.7709319591522217
Validation loss: 2.02107697725296

Epoch: 6| Step: 10
Training loss: 2.0376665592193604
Validation loss: 2.0140390594800315

Epoch: 6| Step: 11
Training loss: 1.842969536781311
Validation loss: 2.0243073105812073

Epoch: 6| Step: 12
Training loss: 2.331111192703247
Validation loss: 2.0260507663091025

Epoch: 6| Step: 13
Training loss: 2.6906614303588867
Validation loss: 2.018991390864054

Epoch: 25| Step: 0
Training loss: 1.3654134273529053
Validation loss: 2.019643485546112

Epoch: 6| Step: 1
Training loss: 2.3457815647125244
Validation loss: 2.0189834237098694

Epoch: 6| Step: 2
Training loss: 1.7772085666656494
Validation loss: 2.0250112811724343

Epoch: 6| Step: 3
Training loss: 1.945013165473938
Validation loss: 2.019372582435608

Epoch: 6| Step: 4
Training loss: 2.1341843605041504
Validation loss: 2.0407651464144387

Epoch: 6| Step: 5
Training loss: 2.2820162773132324
Validation loss: 2.0260736544926963

Epoch: 6| Step: 6
Training loss: 2.295656442642212
Validation loss: 2.020593047142029

Epoch: 6| Step: 7
Training loss: 1.8977384567260742
Validation loss: 2.0282950003941855

Epoch: 6| Step: 8
Training loss: 2.152360439300537
Validation loss: 2.0245458483695984

Epoch: 6| Step: 9
Training loss: 1.5454168319702148
Validation loss: 2.027196705341339

Epoch: 6| Step: 10
Training loss: 2.1282410621643066
Validation loss: 2.022337476412455

Epoch: 6| Step: 11
Training loss: 1.894220232963562
Validation loss: 2.041058619817098

Epoch: 6| Step: 12
Training loss: 1.8425390720367432
Validation loss: 2.0250222086906433

Epoch: 6| Step: 13
Training loss: 1.9208896160125732
Validation loss: 2.0197736819585166

Epoch: 26| Step: 0
Training loss: 1.671241044998169
Validation loss: 2.030476371447245

Epoch: 6| Step: 1
Training loss: 1.5424623489379883
Validation loss: 2.044476250807444

Epoch: 6| Step: 2
Training loss: 1.3840749263763428
Validation loss: 2.021272301673889

Epoch: 6| Step: 3
Training loss: 1.7371892929077148
Validation loss: 2.047631561756134

Epoch: 6| Step: 4
Training loss: 2.0138356685638428
Validation loss: 2.0411345760027566

Epoch: 6| Step: 5
Training loss: 2.3812403678894043
Validation loss: 2.053048074245453

Epoch: 6| Step: 6
Training loss: 1.6879405975341797
Validation loss: 2.035962224006653

Epoch: 6| Step: 7
Training loss: 2.163699150085449
Validation loss: 2.056467036406199

Epoch: 6| Step: 8
Training loss: 2.214632987976074
Validation loss: 2.0625670552253723

Epoch: 6| Step: 9
Training loss: 2.1133193969726562
Validation loss: 2.0557977755864463

Epoch: 6| Step: 10
Training loss: 1.9030072689056396
Validation loss: 2.0386204520861306

Epoch: 6| Step: 11
Training loss: 2.182168960571289
Validation loss: 2.041027247905731

Epoch: 6| Step: 12
Training loss: 2.5648088455200195
Validation loss: 2.031392991542816

Epoch: 6| Step: 13
Training loss: 2.336564540863037
Validation loss: 2.0148370265960693

Epoch: 27| Step: 0
Training loss: 1.3663580417633057
Validation loss: 2.0219874382019043

Epoch: 6| Step: 1
Training loss: 1.9163821935653687
Validation loss: 2.0055747826894126

Epoch: 6| Step: 2
Training loss: 2.9996161460876465
Validation loss: 2.0079702536265054

Epoch: 6| Step: 3
Training loss: 1.9151458740234375
Validation loss: 2.0133769313494363

Epoch: 6| Step: 4
Training loss: 2.4004569053649902
Validation loss: 2.0232901175816855

Epoch: 6| Step: 5
Training loss: 1.5944762229919434
Validation loss: 2.0070804357528687

Epoch: 6| Step: 6
Training loss: 2.0131473541259766
Validation loss: 2.0120749473571777

Epoch: 6| Step: 7
Training loss: 2.329131841659546
Validation loss: 2.02262274424235

Epoch: 6| Step: 8
Training loss: 1.8800835609436035
Validation loss: 2.0066917538642883

Epoch: 6| Step: 9
Training loss: 2.237077474594116
Validation loss: 1.9946253498395283

Epoch: 6| Step: 10
Training loss: 2.2698137760162354
Validation loss: 2.0127221743265786

Epoch: 6| Step: 11
Training loss: 1.7810962200164795
Validation loss: 2.0081187884012857

Epoch: 6| Step: 12
Training loss: 1.8737351894378662
Validation loss: 2.0119357903798423

Epoch: 6| Step: 13
Training loss: 1.317170262336731
Validation loss: 2.034221967061361

Epoch: 28| Step: 0
Training loss: 1.622391939163208
Validation loss: 2.0212199290593467

Epoch: 6| Step: 1
Training loss: 1.6377925872802734
Validation loss: 2.022323807080587

Epoch: 6| Step: 2
Training loss: 1.6153764724731445
Validation loss: 2.0535660783449807

Epoch: 6| Step: 3
Training loss: 2.114339828491211
Validation loss: 2.0616758863131204

Epoch: 6| Step: 4
Training loss: 1.9241762161254883
Validation loss: 2.0812548796335855

Epoch: 6| Step: 5
Training loss: 2.1675026416778564
Validation loss: 2.077670077482859

Epoch: 6| Step: 6
Training loss: 1.872222661972046
Validation loss: 2.08162788550059

Epoch: 6| Step: 7
Training loss: 1.9446132183074951
Validation loss: 2.0949517488479614

Epoch: 6| Step: 8
Training loss: 2.3680315017700195
Validation loss: 2.0833137035369873

Epoch: 6| Step: 9
Training loss: 2.8269190788269043
Validation loss: 2.0493133266766868

Epoch: 6| Step: 10
Training loss: 2.2441000938415527
Validation loss: 2.045199195543925

Epoch: 6| Step: 11
Training loss: 1.6356920003890991
Validation loss: 2.013291041056315

Epoch: 6| Step: 12
Training loss: 1.722022294998169
Validation loss: 2.0204174319903054

Epoch: 6| Step: 13
Training loss: 2.2598342895507812
Validation loss: 2.0030495325724282

Epoch: 29| Step: 0
Training loss: 1.7525393962860107
Validation loss: 1.9918675820032756

Epoch: 6| Step: 1
Training loss: 1.8207776546478271
Validation loss: 2.017601509888967

Epoch: 6| Step: 2
Training loss: 1.267701268196106
Validation loss: 2.027144650618235

Epoch: 6| Step: 3
Training loss: 2.0079171657562256
Validation loss: 2.009202698866526

Epoch: 6| Step: 4
Training loss: 2.06200909614563
Validation loss: 2.0171642104784646

Epoch: 6| Step: 5
Training loss: 2.295130729675293
Validation loss: 2.0302547613779702

Epoch: 6| Step: 6
Training loss: 3.2997400760650635
Validation loss: 2.0206125179926553

Epoch: 6| Step: 7
Training loss: 1.248106837272644
Validation loss: 2.016858677069346

Epoch: 6| Step: 8
Training loss: 2.2602009773254395
Validation loss: 2.0462773640950522

Epoch: 6| Step: 9
Training loss: 2.3969264030456543
Validation loss: 2.027561585108439

Epoch: 6| Step: 10
Training loss: 1.801189661026001
Validation loss: 2.0230669180552163

Epoch: 6| Step: 11
Training loss: 2.1849169731140137
Validation loss: 2.027380645275116

Epoch: 6| Step: 12
Training loss: 2.0251412391662598
Validation loss: 2.0241765777269998

Epoch: 6| Step: 13
Training loss: 1.4052451848983765
Validation loss: 2.012115796407064

Epoch: 30| Step: 0
Training loss: 2.1608943939208984
Validation loss: 2.02430127064387

Epoch: 6| Step: 1
Training loss: 1.7281426191329956
Validation loss: 2.008428474267324

Epoch: 6| Step: 2
Training loss: 1.5865631103515625
Validation loss: 2.0130726297696433

Epoch: 6| Step: 3
Training loss: 1.7290120124816895
Validation loss: 2.004282553990682

Epoch: 6| Step: 4
Training loss: 2.3768415451049805
Validation loss: 2.0201727549235025

Epoch: 6| Step: 5
Training loss: 2.104790687561035
Validation loss: 2.020629326502482

Epoch: 6| Step: 6
Training loss: 1.876254677772522
Validation loss: 2.023760994275411

Epoch: 6| Step: 7
Training loss: 2.0019826889038086
Validation loss: 1.9960080583890278

Epoch: 6| Step: 8
Training loss: 2.5216574668884277
Validation loss: 2.019691507021586

Epoch: 6| Step: 9
Training loss: 1.374350905418396
Validation loss: 1.9987871646881104

Epoch: 6| Step: 10
Training loss: 2.163703203201294
Validation loss: 1.992663045724233

Epoch: 6| Step: 11
Training loss: 1.7680039405822754
Validation loss: 2.020963509877523

Epoch: 6| Step: 12
Training loss: 2.040869951248169
Validation loss: 2.005020181337992

Epoch: 6| Step: 13
Training loss: 2.15779972076416
Validation loss: 2.0261186957359314

Epoch: 31| Step: 0
Training loss: 1.9344308376312256
Validation loss: 2.0161028107007346

Epoch: 6| Step: 1
Training loss: 2.25108003616333
Validation loss: 2.0121616323788962

Epoch: 6| Step: 2
Training loss: 1.9775385856628418
Validation loss: 2.0078572432200112

Epoch: 6| Step: 3
Training loss: 1.9300222396850586
Validation loss: 2.041403114795685

Epoch: 6| Step: 4
Training loss: 2.069779872894287
Validation loss: 2.0173535148302713

Epoch: 6| Step: 5
Training loss: 1.782663106918335
Validation loss: 2.0352951685587564

Epoch: 6| Step: 6
Training loss: 2.5730416774749756
Validation loss: 2.059849957625071

Epoch: 6| Step: 7
Training loss: 1.4073944091796875
Validation loss: 2.045960625012716

Epoch: 6| Step: 8
Training loss: 2.359999179840088
Validation loss: 2.0377110044161477

Epoch: 6| Step: 9
Training loss: 1.6605405807495117
Validation loss: 2.036172012488047

Epoch: 6| Step: 10
Training loss: 2.3725411891937256
Validation loss: 2.043905556201935

Epoch: 6| Step: 11
Training loss: 1.7951245307922363
Validation loss: 2.0150244434674582

Epoch: 6| Step: 12
Training loss: 1.4702712297439575
Validation loss: 2.012640376885732

Epoch: 6| Step: 13
Training loss: 2.041391372680664
Validation loss: 2.032869199911753

Epoch: 32| Step: 0
Training loss: 2.262239456176758
Validation loss: 2.0309641559918723

Epoch: 6| Step: 1
Training loss: 2.199051856994629
Validation loss: 2.0321550965309143

Epoch: 6| Step: 2
Training loss: 2.0644125938415527
Validation loss: 2.0271743138631186

Epoch: 6| Step: 3
Training loss: 1.7663118839263916
Validation loss: 2.036755383014679

Epoch: 6| Step: 4
Training loss: 2.1304945945739746
Validation loss: 2.0324915647506714

Epoch: 6| Step: 5
Training loss: 2.352022171020508
Validation loss: 2.0280396540959678

Epoch: 6| Step: 6
Training loss: 1.761952519416809
Validation loss: 2.0124005675315857

Epoch: 6| Step: 7
Training loss: 1.4591848850250244
Validation loss: 2.0313414136568704

Epoch: 6| Step: 8
Training loss: 1.5351296663284302
Validation loss: 2.041793465614319

Epoch: 6| Step: 9
Training loss: 1.651235818862915
Validation loss: 2.047417084376017

Epoch: 6| Step: 10
Training loss: 2.5026822090148926
Validation loss: 2.068304975827535

Epoch: 6| Step: 11
Training loss: 2.0225987434387207
Validation loss: 2.038383742173513

Epoch: 6| Step: 12
Training loss: 2.3911309242248535
Validation loss: 2.0578942696253457

Epoch: 6| Step: 13
Training loss: 1.675910234451294
Validation loss: 2.031735062599182

Epoch: 33| Step: 0
Training loss: 1.995368242263794
Validation loss: 2.0328277349472046

Epoch: 6| Step: 1
Training loss: 1.8962209224700928
Validation loss: 2.017301003138224

Epoch: 6| Step: 2
Training loss: 2.1769964694976807
Validation loss: 2.0224128564198813

Epoch: 6| Step: 3
Training loss: 1.8669004440307617
Validation loss: 2.0014211535453796

Epoch: 6| Step: 4
Training loss: 2.522665023803711
Validation loss: 2.0061068137486777

Epoch: 6| Step: 5
Training loss: 1.5866897106170654
Validation loss: 2.0165041287740073

Epoch: 6| Step: 6
Training loss: 2.14345121383667
Validation loss: 1.9927417437235515

Epoch: 6| Step: 7
Training loss: 1.522414207458496
Validation loss: 2.004985531171163

Epoch: 6| Step: 8
Training loss: 1.9543540477752686
Validation loss: 2.0246785084406533

Epoch: 6| Step: 9
Training loss: 2.0450384616851807
Validation loss: 2.01617960135142

Epoch: 6| Step: 10
Training loss: 2.5110137462615967
Validation loss: 1.9992793202400208

Epoch: 6| Step: 11
Training loss: 2.0730817317962646
Validation loss: 2.011131683985392

Epoch: 6| Step: 12
Training loss: 1.445124864578247
Validation loss: 2.0092685222625732

Epoch: 6| Step: 13
Training loss: 1.803446888923645
Validation loss: 2.0155157446861267

Epoch: 34| Step: 0
Training loss: 2.3344264030456543
Validation loss: 1.9968410929044087

Epoch: 6| Step: 1
Training loss: 1.9699833393096924
Validation loss: 2.0320037206014

Epoch: 6| Step: 2
Training loss: 2.2631173133850098
Validation loss: 2.033031384150187

Epoch: 6| Step: 3
Training loss: 1.1830074787139893
Validation loss: 2.015731414159139

Epoch: 6| Step: 4
Training loss: 1.3800792694091797
Validation loss: 2.0389039715131125

Epoch: 6| Step: 5
Training loss: 1.5567755699157715
Validation loss: 2.0363791982332864

Epoch: 6| Step: 6
Training loss: 2.333033800125122
Validation loss: 2.0423087080319724

Epoch: 6| Step: 7
Training loss: 1.6743320226669312
Validation loss: 2.0316575368245444

Epoch: 6| Step: 8
Training loss: 2.00809383392334
Validation loss: 2.042213956514994

Epoch: 6| Step: 9
Training loss: 2.04042911529541
Validation loss: 2.0487339893976846

Epoch: 6| Step: 10
Training loss: 2.0020809173583984
Validation loss: 2.042575498421987

Epoch: 6| Step: 11
Training loss: 2.7324118614196777
Validation loss: 2.038252810637156

Epoch: 6| Step: 12
Training loss: 2.0477633476257324
Validation loss: 2.046751697858175

Epoch: 6| Step: 13
Training loss: 1.7171087265014648
Validation loss: 2.0460594097773233

Epoch: 35| Step: 0
Training loss: 1.9908595085144043
Validation loss: 2.02665122350057

Epoch: 6| Step: 1
Training loss: 1.8900139331817627
Validation loss: 2.0460935831069946

Epoch: 6| Step: 2
Training loss: 3.021144390106201
Validation loss: 2.0335532824198403

Epoch: 6| Step: 3
Training loss: 1.2574903964996338
Validation loss: 2.0332747300465903

Epoch: 6| Step: 4
Training loss: 1.9714186191558838
Validation loss: 2.0342758099238076

Epoch: 6| Step: 5
Training loss: 1.3572075366973877
Validation loss: 2.039869805177053

Epoch: 6| Step: 6
Training loss: 2.001044988632202
Validation loss: 2.053838014602661

Epoch: 6| Step: 7
Training loss: 2.1127243041992188
Validation loss: 2.0291086236635842

Epoch: 6| Step: 8
Training loss: 1.7183524370193481
Validation loss: 2.0285484790802

Epoch: 6| Step: 9
Training loss: 2.1347217559814453
Validation loss: 2.0155585408210754

Epoch: 6| Step: 10
Training loss: 2.2648873329162598
Validation loss: 2.004672427972158

Epoch: 6| Step: 11
Training loss: 1.8691731691360474
Validation loss: 2.028633793195089

Epoch: 6| Step: 12
Training loss: 1.653162956237793
Validation loss: 2.01822022596995

Epoch: 6| Step: 13
Training loss: 2.1195051670074463
Validation loss: 1.9929993549982707

Epoch: 36| Step: 0
Training loss: 2.057403564453125
Validation loss: 2.01207834482193

Epoch: 6| Step: 1
Training loss: 1.740079641342163
Validation loss: 2.000006457169851

Epoch: 6| Step: 2
Training loss: 1.9044164419174194
Validation loss: 2.0242093205451965

Epoch: 6| Step: 3
Training loss: 1.5769340991973877
Validation loss: 2.0187745292981467

Epoch: 6| Step: 4
Training loss: 1.7668213844299316
Validation loss: 2.01748255888621

Epoch: 6| Step: 5
Training loss: 2.0792672634124756
Validation loss: 2.034052232901255

Epoch: 6| Step: 6
Training loss: 1.5128138065338135
Validation loss: 2.016290823618571

Epoch: 6| Step: 7
Training loss: 2.206949234008789
Validation loss: 2.0250125328699746

Epoch: 6| Step: 8
Training loss: 2.539238452911377
Validation loss: 2.005583186944326

Epoch: 6| Step: 9
Training loss: 1.9884662628173828
Validation loss: 2.0147602756818137

Epoch: 6| Step: 10
Training loss: 1.5168638229370117
Validation loss: 2.0138391256332397

Epoch: 6| Step: 11
Training loss: 2.076901435852051
Validation loss: 2.008123815059662

Epoch: 6| Step: 12
Training loss: 2.6478209495544434
Validation loss: 2.027304768562317

Epoch: 6| Step: 13
Training loss: 1.7920973300933838
Validation loss: 2.0039048393567405

Epoch: 37| Step: 0
Training loss: 2.009739398956299
Validation loss: 2.012461543083191

Epoch: 6| Step: 1
Training loss: 1.6499277353286743
Validation loss: 2.0111794670422873

Epoch: 6| Step: 2
Training loss: 2.619418144226074
Validation loss: 2.0278077324231467

Epoch: 6| Step: 3
Training loss: 1.9965565204620361
Validation loss: 2.005801518758138

Epoch: 6| Step: 4
Training loss: 2.3171253204345703
Validation loss: 2.01543790102005

Epoch: 6| Step: 5
Training loss: 2.230318069458008
Validation loss: 2.017272710800171

Epoch: 6| Step: 6
Training loss: 1.4711508750915527
Validation loss: 2.0542167822519937

Epoch: 6| Step: 7
Training loss: 1.8318016529083252
Validation loss: 2.0215881864229837

Epoch: 6| Step: 8
Training loss: 1.7966264486312866
Validation loss: 2.037570516268412

Epoch: 6| Step: 9
Training loss: 1.422658920288086
Validation loss: 2.030052880446116

Epoch: 6| Step: 10
Training loss: 1.9301836490631104
Validation loss: 2.0329155723253884

Epoch: 6| Step: 11
Training loss: 2.381880283355713
Validation loss: 2.0630325277646384

Epoch: 6| Step: 12
Training loss: 1.892551064491272
Validation loss: 2.064298629760742

Epoch: 6| Step: 13
Training loss: 1.741258144378662
Validation loss: 2.061349074045817

Epoch: 38| Step: 0
Training loss: 1.2966418266296387
Validation loss: 2.0622183283170066

Epoch: 6| Step: 1
Training loss: 2.2902345657348633
Validation loss: 2.0635138750076294

Epoch: 6| Step: 2
Training loss: 1.455879807472229
Validation loss: 2.0360870957374573

Epoch: 6| Step: 3
Training loss: 2.6969141960144043
Validation loss: 2.0615100264549255

Epoch: 6| Step: 4
Training loss: 2.301605701446533
Validation loss: 2.0709652304649353

Epoch: 6| Step: 5
Training loss: 1.3911808729171753
Validation loss: 2.055703063805898

Epoch: 6| Step: 6
Training loss: 2.2645907402038574
Validation loss: 2.038383940855662

Epoch: 6| Step: 7
Training loss: 1.7739471197128296
Validation loss: 2.0165454546610513

Epoch: 6| Step: 8
Training loss: 2.2124645709991455
Validation loss: 2.015593687693278

Epoch: 6| Step: 9
Training loss: 1.8866298198699951
Validation loss: 2.0194810231526694

Epoch: 6| Step: 10
Training loss: 1.997978687286377
Validation loss: 2.0156832138697305

Epoch: 6| Step: 11
Training loss: 1.7278389930725098
Validation loss: 2.0201626420021057

Epoch: 6| Step: 12
Training loss: 2.0707385540008545
Validation loss: 2.0346995194753013

Epoch: 6| Step: 13
Training loss: 2.0288195610046387
Validation loss: 2.0333733757336936

Epoch: 39| Step: 0
Training loss: 2.198298454284668
Validation loss: 2.018018106619517

Epoch: 6| Step: 1
Training loss: 2.4918909072875977
Validation loss: 2.009551207224528

Epoch: 6| Step: 2
Training loss: 1.6407054662704468
Validation loss: 2.0047518412272134

Epoch: 6| Step: 3
Training loss: 2.418952465057373
Validation loss: 2.0085524916648865

Epoch: 6| Step: 4
Training loss: 1.8414020538330078
Validation loss: 2.0216733813285828

Epoch: 6| Step: 5
Training loss: 1.8910496234893799
Validation loss: 2.010071039199829

Epoch: 6| Step: 6
Training loss: 2.020033836364746
Validation loss: 2.0079368352890015

Epoch: 6| Step: 7
Training loss: 1.1048821210861206
Validation loss: 2.017534693082174

Epoch: 6| Step: 8
Training loss: 2.5102498531341553
Validation loss: 2.009441832701365

Epoch: 6| Step: 9
Training loss: 1.8038864135742188
Validation loss: 2.01114813486735

Epoch: 6| Step: 10
Training loss: 1.8646701574325562
Validation loss: 2.025066832701365

Epoch: 6| Step: 11
Training loss: 2.988865852355957
Validation loss: 2.054444114367167

Epoch: 6| Step: 12
Training loss: 1.5948667526245117
Validation loss: 2.050296107927958

Epoch: 6| Step: 13
Training loss: 1.1194102764129639
Validation loss: 2.044200281302134

Epoch: 40| Step: 0
Training loss: 2.9000186920166016
Validation loss: 2.0531688133875527

Epoch: 6| Step: 1
Training loss: 2.195056200027466
Validation loss: 2.0346392393112183

Epoch: 6| Step: 2
Training loss: 1.4883551597595215
Validation loss: 2.0177170832951865

Epoch: 6| Step: 3
Training loss: 1.4207979440689087
Validation loss: 2.026848057905833

Epoch: 6| Step: 4
Training loss: 1.7122986316680908
Validation loss: 2.011664569377899

Epoch: 6| Step: 5
Training loss: 1.8629682064056396
Validation loss: 2.0052972038586936

Epoch: 6| Step: 6
Training loss: 1.7427290678024292
Validation loss: 2.0080673694610596

Epoch: 6| Step: 7
Training loss: 2.3600244522094727
Validation loss: 2.0017383098602295

Epoch: 6| Step: 8
Training loss: 2.1115243434906006
Validation loss: 1.9967377583185832

Epoch: 6| Step: 9
Training loss: 2.400822639465332
Validation loss: 2.018823564052582

Epoch: 6| Step: 10
Training loss: 1.8649510145187378
Validation loss: 1.993433137734731

Epoch: 6| Step: 11
Training loss: 1.8733875751495361
Validation loss: 1.9833132425944011

Epoch: 6| Step: 12
Training loss: 1.4748389720916748
Validation loss: 1.9997467199961345

Epoch: 6| Step: 13
Training loss: 2.067904472351074
Validation loss: 2.021477460861206

Epoch: 41| Step: 0
Training loss: 1.8764653205871582
Validation loss: 2.0152066946029663

Epoch: 6| Step: 1
Training loss: 1.7337968349456787
Validation loss: 2.0077242255210876

Epoch: 6| Step: 2
Training loss: 2.0496878623962402
Validation loss: 2.0207106471061707

Epoch: 6| Step: 3
Training loss: 1.802869439125061
Validation loss: 2.0267428358395896

Epoch: 6| Step: 4
Training loss: 1.5685131549835205
Validation loss: 2.045091430346171

Epoch: 6| Step: 5
Training loss: 1.6448227167129517
Validation loss: 2.0704429944356284

Epoch: 6| Step: 6
Training loss: 1.9366697072982788
Validation loss: 2.0687086383501687

Epoch: 6| Step: 7
Training loss: 2.4433679580688477
Validation loss: 2.0969530741373696

Epoch: 6| Step: 8
Training loss: 1.6481618881225586
Validation loss: 2.08721653620402

Epoch: 6| Step: 9
Training loss: 2.3184494972229004
Validation loss: 2.091948469479879

Epoch: 6| Step: 10
Training loss: 2.6209869384765625
Validation loss: 2.0957128405570984

Epoch: 6| Step: 11
Training loss: 1.1827316284179688
Validation loss: 2.0651866594950357

Epoch: 6| Step: 12
Training loss: 2.1102352142333984
Validation loss: 2.0592954556147256

Epoch: 6| Step: 13
Training loss: 2.3765621185302734
Validation loss: 2.0603017807006836

Epoch: 42| Step: 0
Training loss: 2.557016611099243
Validation loss: 2.0352705121040344

Epoch: 6| Step: 1
Training loss: 2.3533196449279785
Validation loss: 2.012317637602488

Epoch: 6| Step: 2
Training loss: 2.223503351211548
Validation loss: 1.9972700874010723

Epoch: 6| Step: 3
Training loss: 1.9764986038208008
Validation loss: 1.980873127778371

Epoch: 6| Step: 4
Training loss: 2.4412670135498047
Validation loss: 2.0095754663149514

Epoch: 6| Step: 5
Training loss: 1.7585302591323853
Validation loss: 1.9924264152844746

Epoch: 6| Step: 6
Training loss: 1.9076166152954102
Validation loss: 1.9941447575887044

Epoch: 6| Step: 7
Training loss: 1.7352408170700073
Validation loss: 1.9990066687266033

Epoch: 6| Step: 8
Training loss: 1.5152097940444946
Validation loss: 1.9947513540585835

Epoch: 6| Step: 9
Training loss: 2.5259664058685303
Validation loss: 2.0055299003918967

Epoch: 6| Step: 10
Training loss: 2.1325674057006836
Validation loss: 2.026337762673696

Epoch: 6| Step: 11
Training loss: 1.3033502101898193
Validation loss: 1.9993363817532857

Epoch: 6| Step: 12
Training loss: 1.3733793497085571
Validation loss: 1.9925711154937744

Epoch: 6| Step: 13
Training loss: 1.9197285175323486
Validation loss: 2.0202890038490295

Epoch: 43| Step: 0
Training loss: 1.6505845785140991
Validation loss: 2.0413091580073037

Epoch: 6| Step: 1
Training loss: 2.444396495819092
Validation loss: 2.0632792909940085

Epoch: 6| Step: 2
Training loss: 2.3256642818450928
Validation loss: 2.05690465370814

Epoch: 6| Step: 3
Training loss: 1.7394031286239624
Validation loss: 2.0620723168055215

Epoch: 6| Step: 4
Training loss: 1.1821644306182861
Validation loss: 2.0409878293673196

Epoch: 6| Step: 5
Training loss: 2.3600127696990967
Validation loss: 2.053147812684377

Epoch: 6| Step: 6
Training loss: 2.2088680267333984
Validation loss: 2.0478978554407754

Epoch: 6| Step: 7
Training loss: 1.9566254615783691
Validation loss: 2.0212077498435974

Epoch: 6| Step: 8
Training loss: 1.8063316345214844
Validation loss: 2.0482114354769387

Epoch: 6| Step: 9
Training loss: 2.2737109661102295
Validation loss: 2.05323189496994

Epoch: 6| Step: 10
Training loss: 2.171510696411133
Validation loss: 2.0147432486216226

Epoch: 6| Step: 11
Training loss: 1.5794284343719482
Validation loss: 2.021808703740438

Epoch: 6| Step: 12
Training loss: 2.167102813720703
Validation loss: 2.005790372689565

Epoch: 6| Step: 13
Training loss: 1.5070040225982666
Validation loss: 2.030027429262797

Epoch: 44| Step: 0
Training loss: 2.2453184127807617
Validation loss: 2.0096434354782104

Epoch: 6| Step: 1
Training loss: 2.1347765922546387
Validation loss: 2.0268857876459756

Epoch: 6| Step: 2
Training loss: 1.4628607034683228
Validation loss: 2.017454286416372

Epoch: 6| Step: 3
Training loss: 2.1435914039611816
Validation loss: 2.028934597969055

Epoch: 6| Step: 4
Training loss: 1.4480688571929932
Validation loss: 2.0245281060536704

Epoch: 6| Step: 5
Training loss: 2.197572946548462
Validation loss: 2.032963454723358

Epoch: 6| Step: 6
Training loss: 1.8814921379089355
Validation loss: 2.024637003739675

Epoch: 6| Step: 7
Training loss: 1.5173120498657227
Validation loss: 2.0164029598236084

Epoch: 6| Step: 8
Training loss: 2.085498094558716
Validation loss: 2.010163406531016

Epoch: 6| Step: 9
Training loss: 1.9972237348556519
Validation loss: 2.0305221676826477

Epoch: 6| Step: 10
Training loss: 1.8150269985198975
Validation loss: 2.0504745046297708

Epoch: 6| Step: 11
Training loss: 2.2484097480773926
Validation loss: 2.0547810991605124

Epoch: 6| Step: 12
Training loss: 1.7773724794387817
Validation loss: 2.039800524711609

Epoch: 6| Step: 13
Training loss: 1.8895583152770996
Validation loss: 2.0255561073621116

Epoch: 45| Step: 0
Training loss: 1.7857295274734497
Validation loss: 2.0267138878504434

Epoch: 6| Step: 1
Training loss: 1.7623341083526611
Validation loss: 2.0345499515533447

Epoch: 6| Step: 2
Training loss: 1.6815080642700195
Validation loss: 2.040909250577291

Epoch: 6| Step: 3
Training loss: 1.5540392398834229
Validation loss: 2.031969447930654

Epoch: 6| Step: 4
Training loss: 2.3785147666931152
Validation loss: 2.04380863904953

Epoch: 6| Step: 5
Training loss: 1.7423995733261108
Validation loss: 2.0428163607915244

Epoch: 6| Step: 6
Training loss: 2.0693857669830322
Validation loss: 2.042763829231262

Epoch: 6| Step: 7
Training loss: 1.6027209758758545
Validation loss: 2.0456198255221048

Epoch: 6| Step: 8
Training loss: 2.1681151390075684
Validation loss: 2.036315302054087

Epoch: 6| Step: 9
Training loss: 1.6227749586105347
Validation loss: 2.022008240222931

Epoch: 6| Step: 10
Training loss: 2.7358577251434326
Validation loss: 2.0351940194765725

Epoch: 6| Step: 11
Training loss: 1.9191678762435913
Validation loss: 2.0278539458910623

Epoch: 6| Step: 12
Training loss: 2.0378775596618652
Validation loss: 2.0329865415891013

Epoch: 6| Step: 13
Training loss: 1.8891596794128418
Validation loss: 2.0244035522143045

Epoch: 46| Step: 0
Training loss: 1.8625223636627197
Validation loss: 2.0198541283607483

Epoch: 6| Step: 1
Training loss: 2.6423044204711914
Validation loss: 2.027080158392588

Epoch: 6| Step: 2
Training loss: 2.027553081512451
Validation loss: 2.0173235138257346

Epoch: 6| Step: 3
Training loss: 1.660768985748291
Validation loss: 2.040604809919993

Epoch: 6| Step: 4
Training loss: 1.1382648944854736
Validation loss: 2.0147207578023276

Epoch: 6| Step: 5
Training loss: 1.0074124336242676
Validation loss: 2.0308335622151694

Epoch: 6| Step: 6
Training loss: 1.711531639099121
Validation loss: 2.034864286581675

Epoch: 6| Step: 7
Training loss: 2.5273184776306152
Validation loss: 2.057162284851074

Epoch: 6| Step: 8
Training loss: 1.7161046266555786
Validation loss: 2.0647510091463723

Epoch: 6| Step: 9
Training loss: 1.566739797592163
Validation loss: 2.0607830286026

Epoch: 6| Step: 10
Training loss: 2.5695481300354004
Validation loss: 2.0535205403963723

Epoch: 6| Step: 11
Training loss: 2.2638258934020996
Validation loss: 2.0321820974349976

Epoch: 6| Step: 12
Training loss: 2.081861972808838
Validation loss: 2.0275705258051553

Epoch: 6| Step: 13
Training loss: 2.388606548309326
Validation loss: 2.042861759662628

Epoch: 47| Step: 0
Training loss: 2.0379443168640137
Validation loss: 2.0209717750549316

Epoch: 6| Step: 1
Training loss: 1.930250883102417
Validation loss: 2.012619972229004

Epoch: 6| Step: 2
Training loss: 1.9618127346038818
Validation loss: 1.997146487236023

Epoch: 6| Step: 3
Training loss: 2.279301166534424
Validation loss: 1.9859399199485779

Epoch: 6| Step: 4
Training loss: 1.94631826877594
Validation loss: 1.9925241072972615

Epoch: 6| Step: 5
Training loss: 1.5013176202774048
Validation loss: 1.9886005520820618

Epoch: 6| Step: 6
Training loss: 1.8080848455429077
Validation loss: 1.979174017906189

Epoch: 6| Step: 7
Training loss: 1.467703938484192
Validation loss: 2.0067997574806213

Epoch: 6| Step: 8
Training loss: 2.1145408153533936
Validation loss: 1.9936271111170452

Epoch: 6| Step: 9
Training loss: 1.9812109470367432
Validation loss: 2.007126748561859

Epoch: 6| Step: 10
Training loss: 2.7039058208465576
Validation loss: 2.023434321085612

Epoch: 6| Step: 11
Training loss: 1.6269385814666748
Validation loss: 2.0138006607691445

Epoch: 6| Step: 12
Training loss: 1.9797265529632568
Validation loss: 2.025611956914266

Epoch: 6| Step: 13
Training loss: 1.6742773056030273
Validation loss: 2.0404439568519592

Epoch: 48| Step: 0
Training loss: 1.7744686603546143
Validation loss: 2.051500757535299

Epoch: 6| Step: 1
Training loss: 1.6213548183441162
Validation loss: 2.048608640829722

Epoch: 6| Step: 2
Training loss: 1.7570151090621948
Validation loss: 2.0603842735290527

Epoch: 6| Step: 3
Training loss: 2.018505096435547
Validation loss: 2.0619575579961142

Epoch: 6| Step: 4
Training loss: 1.7338836193084717
Validation loss: 2.052364389101664

Epoch: 6| Step: 5
Training loss: 2.130007743835449
Validation loss: 2.0300705234209695

Epoch: 6| Step: 6
Training loss: 1.2898387908935547
Validation loss: 2.0742830435434976

Epoch: 6| Step: 7
Training loss: 1.834444522857666
Validation loss: 2.036639630794525

Epoch: 6| Step: 8
Training loss: 1.8932881355285645
Validation loss: 2.029654006163279

Epoch: 6| Step: 9
Training loss: 1.78110671043396
Validation loss: 2.0398587783177695

Epoch: 6| Step: 10
Training loss: 1.950432300567627
Validation loss: 2.004384915033976

Epoch: 6| Step: 11
Training loss: 2.0098884105682373
Validation loss: 2.0263055165608725

Epoch: 6| Step: 12
Training loss: 2.265026569366455
Validation loss: 2.021551251411438

Epoch: 6| Step: 13
Training loss: 2.5520665645599365
Validation loss: 2.0232560435930886

Epoch: 49| Step: 0
Training loss: 1.9958089590072632
Validation loss: 2.026980717976888

Epoch: 6| Step: 1
Training loss: 1.5602202415466309
Validation loss: 2.008233388264974

Epoch: 6| Step: 2
Training loss: 2.177186965942383
Validation loss: 2.002986470858256

Epoch: 6| Step: 3
Training loss: 1.353926420211792
Validation loss: 2.006225268046061

Epoch: 6| Step: 4
Training loss: 1.8749828338623047
Validation loss: 1.9919451872507732

Epoch: 6| Step: 5
Training loss: 2.047013282775879
Validation loss: 2.0002131263415017

Epoch: 6| Step: 6
Training loss: 2.361356735229492
Validation loss: 2.012627820173899

Epoch: 6| Step: 7
Training loss: 1.8783512115478516
Validation loss: 1.991845965385437

Epoch: 6| Step: 8
Training loss: 1.683309555053711
Validation loss: 1.9906359910964966

Epoch: 6| Step: 9
Training loss: 2.385606288909912
Validation loss: 2.0036577781041465

Epoch: 6| Step: 10
Training loss: 1.6327950954437256
Validation loss: 2.023512522379557

Epoch: 6| Step: 11
Training loss: 2.2280421257019043
Validation loss: 1.9957776268323262

Epoch: 6| Step: 12
Training loss: 1.6227333545684814
Validation loss: 1.993119517962138

Epoch: 6| Step: 13
Training loss: 2.09564208984375
Validation loss: 2.0002365907033286

Epoch: 50| Step: 0
Training loss: 1.9097497463226318
Validation loss: 2.0053771336873374

Epoch: 6| Step: 1
Training loss: 1.441091537475586
Validation loss: 2.0288936694463096

Epoch: 6| Step: 2
Training loss: 1.7120182514190674
Validation loss: 2.030717353026072

Epoch: 6| Step: 3
Training loss: 1.6964560747146606
Validation loss: 2.0526150266329446

Epoch: 6| Step: 4
Training loss: 1.9414721727371216
Validation loss: 2.0714176495869956

Epoch: 6| Step: 5
Training loss: 2.496112585067749
Validation loss: 2.0650112430254617

Epoch: 6| Step: 6
Training loss: 2.9630508422851562
Validation loss: 2.076350450515747

Epoch: 6| Step: 7
Training loss: 2.4367103576660156
Validation loss: 2.0538376768430076

Epoch: 6| Step: 8
Training loss: 1.3473842144012451
Validation loss: 2.046697815259298

Epoch: 6| Step: 9
Training loss: 2.1135811805725098
Validation loss: 2.03385458389918

Epoch: 6| Step: 10
Training loss: 2.2023181915283203
Validation loss: 2.032936970392863

Epoch: 6| Step: 11
Training loss: 2.134056568145752
Validation loss: 2.0241677165031433

Epoch: 6| Step: 12
Training loss: 1.4166300296783447
Validation loss: 2.0199332237243652

Epoch: 6| Step: 13
Training loss: 1.167062759399414
Validation loss: 2.0145158171653748

Epoch: 51| Step: 0
Training loss: 1.496266484260559
Validation loss: 2.0085975925127664

Epoch: 6| Step: 1
Training loss: 2.252906322479248
Validation loss: 2.012024998664856

Epoch: 6| Step: 2
Training loss: 1.994030475616455
Validation loss: 1.9879773259162903

Epoch: 6| Step: 3
Training loss: 1.1961040496826172
Validation loss: 2.011230985323588

Epoch: 6| Step: 4
Training loss: 1.572339415550232
Validation loss: 2.0274828672409058

Epoch: 6| Step: 5
Training loss: 2.302335500717163
Validation loss: 2.046592056751251

Epoch: 6| Step: 6
Training loss: 1.5244715213775635
Validation loss: 2.025114099184672

Epoch: 6| Step: 7
Training loss: 1.711355447769165
Validation loss: 2.042469064394633

Epoch: 6| Step: 8
Training loss: 2.54083514213562
Validation loss: 2.028692086537679

Epoch: 6| Step: 9
Training loss: 1.5740491151809692
Validation loss: 2.054680327574412

Epoch: 6| Step: 10
Training loss: 2.2624382972717285
Validation loss: 2.066986600557963

Epoch: 6| Step: 11
Training loss: 1.529885172843933
Validation loss: 2.0582056045532227

Epoch: 6| Step: 12
Training loss: 2.547231674194336
Validation loss: 2.0686628222465515

Epoch: 6| Step: 13
Training loss: 2.1500158309936523
Validation loss: 2.054790476957957

Epoch: 52| Step: 0
Training loss: 1.3302972316741943
Validation loss: 2.048032363255819

Epoch: 6| Step: 1
Training loss: 2.1273162364959717
Validation loss: 2.0321582754453025

Epoch: 6| Step: 2
Training loss: 2.208812713623047
Validation loss: 2.0395007928212485

Epoch: 6| Step: 3
Training loss: 2.0863869190216064
Validation loss: 2.0278610388437905

Epoch: 6| Step: 4
Training loss: 1.2613461017608643
Validation loss: 1.995465060075124

Epoch: 6| Step: 5
Training loss: 2.7840614318847656
Validation loss: 2.0191269516944885

Epoch: 6| Step: 6
Training loss: 2.164983034133911
Validation loss: 1.9963289499282837

Epoch: 6| Step: 7
Training loss: 1.6397464275360107
Validation loss: 2.0202732483545938

Epoch: 6| Step: 8
Training loss: 1.0861876010894775
Validation loss: 1.9820034106572468

Epoch: 6| Step: 9
Training loss: 1.7486557960510254
Validation loss: 2.0083308815956116

Epoch: 6| Step: 10
Training loss: 2.7821218967437744
Validation loss: 2.0261603593826294

Epoch: 6| Step: 11
Training loss: 1.467808485031128
Validation loss: 2.0421157081921897

Epoch: 6| Step: 12
Training loss: 1.632436990737915
Validation loss: 2.0290698409080505

Epoch: 6| Step: 13
Training loss: 2.5351974964141846
Validation loss: 2.044269561767578

Epoch: 53| Step: 0
Training loss: 1.7840901613235474
Validation loss: 2.060533563296

Epoch: 6| Step: 1
Training loss: 1.117104411125183
Validation loss: 2.067719320456187

Epoch: 6| Step: 2
Training loss: 2.7486438751220703
Validation loss: 2.059861938158671

Epoch: 6| Step: 3
Training loss: 1.57660710811615
Validation loss: 2.0880806843439736

Epoch: 6| Step: 4
Training loss: 1.785933017730713
Validation loss: 2.0722126762072244

Epoch: 6| Step: 5
Training loss: 2.2278385162353516
Validation loss: 2.0874213774998984

Epoch: 6| Step: 6
Training loss: 2.2423722743988037
Validation loss: 2.0723074674606323

Epoch: 6| Step: 7
Training loss: 1.6138372421264648
Validation loss: 2.0644142826398215

Epoch: 6| Step: 8
Training loss: 2.446467638015747
Validation loss: 2.0649960041046143

Epoch: 6| Step: 9
Training loss: 1.805436611175537
Validation loss: 2.0171770056088767

Epoch: 6| Step: 10
Training loss: 2.3158624172210693
Validation loss: 2.0160994132359824

Epoch: 6| Step: 11
Training loss: 1.2352447509765625
Validation loss: 2.0358211596806846

Epoch: 6| Step: 12
Training loss: 1.6928157806396484
Validation loss: 2.0331051548322043

Epoch: 6| Step: 13
Training loss: 2.0713272094726562
Validation loss: 2.0369821786880493

Epoch: 54| Step: 0
Training loss: 1.3745129108428955
Validation loss: 2.0080016255378723

Epoch: 6| Step: 1
Training loss: 1.8166627883911133
Validation loss: 2.020166019598643

Epoch: 6| Step: 2
Training loss: 1.9290406703948975
Validation loss: 2.010268827279409

Epoch: 6| Step: 3
Training loss: 1.8782129287719727
Validation loss: 2.0309351285298667

Epoch: 6| Step: 4
Training loss: 2.074958324432373
Validation loss: 2.039076328277588

Epoch: 6| Step: 5
Training loss: 2.366568088531494
Validation loss: 2.0523913304011026

Epoch: 6| Step: 6
Training loss: 1.5458290576934814
Validation loss: 2.0469355980555215

Epoch: 6| Step: 7
Training loss: 1.8605667352676392
Validation loss: 2.0554521878560386

Epoch: 6| Step: 8
Training loss: 2.0600485801696777
Validation loss: 2.0446061889330545

Epoch: 6| Step: 9
Training loss: 1.9391896724700928
Validation loss: 2.025899668534597

Epoch: 6| Step: 10
Training loss: 2.1267178058624268
Validation loss: 2.0347177187601724

Epoch: 6| Step: 11
Training loss: 1.7622063159942627
Validation loss: 2.0370296041170755

Epoch: 6| Step: 12
Training loss: 1.4293030500411987
Validation loss: 2.024509370326996

Epoch: 6| Step: 13
Training loss: 2.1032378673553467
Validation loss: 2.022321859995524

Epoch: 55| Step: 0
Training loss: 1.5595349073410034
Validation loss: 2.0060221751530967

Epoch: 6| Step: 1
Training loss: 2.7335033416748047
Validation loss: 2.0106449723243713

Epoch: 6| Step: 2
Training loss: 2.331846237182617
Validation loss: 1.9932876030604045

Epoch: 6| Step: 3
Training loss: 1.9567394256591797
Validation loss: 1.9995712836583455

Epoch: 6| Step: 4
Training loss: 1.678912878036499
Validation loss: 2.000871499379476

Epoch: 6| Step: 5
Training loss: 2.1519103050231934
Validation loss: 1.976941188176473

Epoch: 6| Step: 6
Training loss: 1.5845654010772705
Validation loss: 1.9882275462150574

Epoch: 6| Step: 7
Training loss: 1.3843538761138916
Validation loss: 1.9898536801338196

Epoch: 6| Step: 8
Training loss: 1.8332858085632324
Validation loss: 1.9795434673627217

Epoch: 6| Step: 9
Training loss: 2.511744976043701
Validation loss: 2.0062033931414285

Epoch: 6| Step: 10
Training loss: 1.4429250955581665
Validation loss: 2.0119362274805703

Epoch: 6| Step: 11
Training loss: 1.5126620531082153
Validation loss: 2.0139578183492026

Epoch: 6| Step: 12
Training loss: 1.5526500940322876
Validation loss: 2.032530128955841

Epoch: 6| Step: 13
Training loss: 2.478142261505127
Validation loss: 2.056536614894867

Epoch: 56| Step: 0
Training loss: 2.149150848388672
Validation loss: 2.049021621545156

Epoch: 6| Step: 1
Training loss: 1.240020990371704
Validation loss: 2.057128687699636

Epoch: 6| Step: 2
Training loss: 1.8027867078781128
Validation loss: 2.079411029815674

Epoch: 6| Step: 3
Training loss: 1.5089690685272217
Validation loss: 2.065425535043081

Epoch: 6| Step: 4
Training loss: 1.581256628036499
Validation loss: 2.069495459397634

Epoch: 6| Step: 5
Training loss: 2.3789892196655273
Validation loss: 2.0524735848108926

Epoch: 6| Step: 6
Training loss: 1.8132925033569336
Validation loss: 2.0604717135429382

Epoch: 6| Step: 7
Training loss: 1.749891757965088
Validation loss: 2.0397955179214478

Epoch: 6| Step: 8
Training loss: 2.1549227237701416
Validation loss: 2.0547791918118796

Epoch: 6| Step: 9
Training loss: 2.0379395484924316
Validation loss: 2.050646424293518

Epoch: 6| Step: 10
Training loss: 2.0734200477600098
Validation loss: 2.06604798634847

Epoch: 6| Step: 11
Training loss: 1.2678232192993164
Validation loss: 2.0446106791496277

Epoch: 6| Step: 12
Training loss: 2.1854801177978516
Validation loss: 2.032371401786804

Epoch: 6| Step: 13
Training loss: 2.2925527095794678
Validation loss: 2.046170790990194

Epoch: 57| Step: 0
Training loss: 2.741098642349243
Validation loss: 2.0064793030420938

Epoch: 6| Step: 1
Training loss: 1.6353119611740112
Validation loss: 2.0137226978937783

Epoch: 6| Step: 2
Training loss: 1.5609012842178345
Validation loss: 2.013990819454193

Epoch: 6| Step: 3
Training loss: 1.157660961151123
Validation loss: 2.0128488341967263

Epoch: 6| Step: 4
Training loss: 1.5508098602294922
Validation loss: 2.017214218775431

Epoch: 6| Step: 5
Training loss: 1.8741451501846313
Validation loss: 2.0076617201169333

Epoch: 6| Step: 6
Training loss: 2.0562386512756348
Validation loss: 2.017912964026133

Epoch: 6| Step: 7
Training loss: 2.134413003921509
Validation loss: 1.9948981205622356

Epoch: 6| Step: 8
Training loss: 2.1542181968688965
Validation loss: 2.0090234080950418

Epoch: 6| Step: 9
Training loss: 1.8434650897979736
Validation loss: 2.013047138849894

Epoch: 6| Step: 10
Training loss: 1.928941011428833
Validation loss: 1.9916166067123413

Epoch: 6| Step: 11
Training loss: 1.8984932899475098
Validation loss: 2.0303455193837485

Epoch: 6| Step: 12
Training loss: 1.6024975776672363
Validation loss: 2.029431859652201

Epoch: 6| Step: 13
Training loss: 2.284374237060547
Validation loss: 2.0425938169161477

Epoch: 58| Step: 0
Training loss: 2.220539093017578
Validation loss: 2.050187627474467

Epoch: 6| Step: 1
Training loss: 1.7768996953964233
Validation loss: 2.06527316570282

Epoch: 6| Step: 2
Training loss: 1.2085399627685547
Validation loss: 2.0745476484298706

Epoch: 6| Step: 3
Training loss: 2.946303367614746
Validation loss: 2.0779276291529336

Epoch: 6| Step: 4
Training loss: 2.0507404804229736
Validation loss: 2.0595621267954507

Epoch: 6| Step: 5
Training loss: 2.2678165435791016
Validation loss: 2.073693871498108

Epoch: 6| Step: 6
Training loss: 2.3574299812316895
Validation loss: 2.0477733810742698

Epoch: 6| Step: 7
Training loss: 1.5064029693603516
Validation loss: 2.047943631807963

Epoch: 6| Step: 8
Training loss: 1.3881597518920898
Validation loss: 2.044759770234426

Epoch: 6| Step: 9
Training loss: 1.6426825523376465
Validation loss: 2.040549377600352

Epoch: 6| Step: 10
Training loss: 1.9493077993392944
Validation loss: 2.035666604836782

Epoch: 6| Step: 11
Training loss: 1.6284763813018799
Validation loss: 2.038132588068644

Epoch: 6| Step: 12
Training loss: 1.4288880825042725
Validation loss: 2.0267279545466104

Epoch: 6| Step: 13
Training loss: 2.2977795600891113
Validation loss: 2.0174125035603843

Epoch: 59| Step: 0
Training loss: 2.3791956901550293
Validation loss: 2.0333132147789

Epoch: 6| Step: 1
Training loss: 0.9941966533660889
Validation loss: 2.053923765818278

Epoch: 6| Step: 2
Training loss: 2.050370693206787
Validation loss: 2.0238556464513144

Epoch: 6| Step: 3
Training loss: 1.5969325304031372
Validation loss: 2.044723073641459

Epoch: 6| Step: 4
Training loss: 1.7901307344436646
Validation loss: 2.045673966407776

Epoch: 6| Step: 5
Training loss: 1.7974720001220703
Validation loss: 2.020072857538859

Epoch: 6| Step: 6
Training loss: 1.8756263256072998
Validation loss: 2.021300514539083

Epoch: 6| Step: 7
Training loss: 1.8484454154968262
Validation loss: 2.032793164253235

Epoch: 6| Step: 8
Training loss: 1.4790916442871094
Validation loss: 2.025787134965261

Epoch: 6| Step: 9
Training loss: 2.183793783187866
Validation loss: 2.0265371799468994

Epoch: 6| Step: 10
Training loss: 2.0268802642822266
Validation loss: 2.0224016904830933

Epoch: 6| Step: 11
Training loss: 1.6849451065063477
Validation loss: 2.022124449412028

Epoch: 6| Step: 12
Training loss: 2.2114417552948
Validation loss: 2.040861705938975

Epoch: 6| Step: 13
Training loss: 2.334132671356201
Validation loss: 2.039307415485382

Epoch: 60| Step: 0
Training loss: 1.480018138885498
Validation loss: 2.0487093130747476

Epoch: 6| Step: 1
Training loss: 1.8639805316925049
Validation loss: 2.033580760161082

Epoch: 6| Step: 2
Training loss: 1.8413176536560059
Validation loss: 2.0637201269467673

Epoch: 6| Step: 3
Training loss: 1.7917819023132324
Validation loss: 2.023423413435618

Epoch: 6| Step: 4
Training loss: 2.355405807495117
Validation loss: 2.049999952316284

Epoch: 6| Step: 5
Training loss: 1.988385558128357
Validation loss: 2.0376959840456643

Epoch: 6| Step: 6
Training loss: 2.375241756439209
Validation loss: 2.0494913260142007

Epoch: 6| Step: 7
Training loss: 1.80128812789917
Validation loss: 2.0752367774645486

Epoch: 6| Step: 8
Training loss: 1.5336112976074219
Validation loss: 2.0489204128583274

Epoch: 6| Step: 9
Training loss: 1.9333603382110596
Validation loss: 2.0336925188700357

Epoch: 6| Step: 10
Training loss: 1.3647762537002563
Validation loss: 2.027130901813507

Epoch: 6| Step: 11
Training loss: 2.2626752853393555
Validation loss: 2.0293487906455994

Epoch: 6| Step: 12
Training loss: 1.9255105257034302
Validation loss: 2.015234967072805

Epoch: 6| Step: 13
Training loss: 1.4743038415908813
Validation loss: 2.004840632279714

Epoch: 61| Step: 0
Training loss: 2.244661808013916
Validation loss: 2.001176118850708

Epoch: 6| Step: 1
Training loss: 2.069394111633301
Validation loss: 2.0261839826901755

Epoch: 6| Step: 2
Training loss: 2.14970064163208
Validation loss: 2.0253082712491355

Epoch: 6| Step: 3
Training loss: 1.310844898223877
Validation loss: 2.007983148097992

Epoch: 6| Step: 4
Training loss: 1.8115204572677612
Validation loss: 2.0096168518066406

Epoch: 6| Step: 5
Training loss: 2.1466660499572754
Validation loss: 2.0282112757364907

Epoch: 6| Step: 6
Training loss: 1.5914340019226074
Validation loss: 2.029500166575114

Epoch: 6| Step: 7
Training loss: 2.540865182876587
Validation loss: 2.030660013357798

Epoch: 6| Step: 8
Training loss: 1.7201669216156006
Validation loss: 2.02924245595932

Epoch: 6| Step: 9
Training loss: 1.6349884271621704
Validation loss: 2.01767498254776

Epoch: 6| Step: 10
Training loss: 1.4843084812164307
Validation loss: 2.028012196222941

Epoch: 6| Step: 11
Training loss: 1.7453235387802124
Validation loss: 2.0588332414627075

Epoch: 6| Step: 12
Training loss: 1.446181058883667
Validation loss: 2.022839983304342

Epoch: 6| Step: 13
Training loss: 1.8780598640441895
Validation loss: 2.0577688415845237

Epoch: 62| Step: 0
Training loss: 1.6472957134246826
Validation loss: 2.0521292686462402

Epoch: 6| Step: 1
Training loss: 1.4096816778182983
Validation loss: 2.0764810840288797

Epoch: 6| Step: 2
Training loss: 1.594773769378662
Validation loss: 2.0548897782961526

Epoch: 6| Step: 3
Training loss: 2.011500835418701
Validation loss: 2.0477768977483115

Epoch: 6| Step: 4
Training loss: 2.1171653270721436
Validation loss: 2.058577557404836

Epoch: 6| Step: 5
Training loss: 1.5641334056854248
Validation loss: 2.0562026500701904

Epoch: 6| Step: 6
Training loss: 2.0200042724609375
Validation loss: 2.045159955819448

Epoch: 6| Step: 7
Training loss: 2.212251663208008
Validation loss: 2.030512273311615

Epoch: 6| Step: 8
Training loss: 1.3506721258163452
Validation loss: 2.0432573358217874

Epoch: 6| Step: 9
Training loss: 2.0725178718566895
Validation loss: 2.0328805247942605

Epoch: 6| Step: 10
Training loss: 2.1203389167785645
Validation loss: 2.0285100738207498

Epoch: 6| Step: 11
Training loss: 1.9262802600860596
Validation loss: 1.9911507964134216

Epoch: 6| Step: 12
Training loss: 1.6693687438964844
Validation loss: 2.020320196946462

Epoch: 6| Step: 13
Training loss: 2.3018991947174072
Validation loss: 2.0003428061803183

Epoch: 63| Step: 0
Training loss: 1.9028291702270508
Validation loss: 2.0190890034039817

Epoch: 6| Step: 1
Training loss: 1.1371413469314575
Validation loss: 1.9912639260292053

Epoch: 6| Step: 2
Training loss: 1.707524299621582
Validation loss: 1.9992883602778118

Epoch: 6| Step: 3
Training loss: 2.056084156036377
Validation loss: 2.0217076341311135

Epoch: 6| Step: 4
Training loss: 1.9651674032211304
Validation loss: 2.0054842829704285

Epoch: 6| Step: 5
Training loss: 2.2533700466156006
Validation loss: 2.0043543179829917

Epoch: 6| Step: 6
Training loss: 1.5779063701629639
Validation loss: 2.012358009815216

Epoch: 6| Step: 7
Training loss: 1.3989694118499756
Validation loss: 2.0200809240341187

Epoch: 6| Step: 8
Training loss: 1.6452058553695679
Validation loss: 2.006659666697184

Epoch: 6| Step: 9
Training loss: 1.8526087999343872
Validation loss: 2.0143113334973655

Epoch: 6| Step: 10
Training loss: 2.4032695293426514
Validation loss: 2.0466426014900208

Epoch: 6| Step: 11
Training loss: 1.8573150634765625
Validation loss: 2.0458913842837014

Epoch: 6| Step: 12
Training loss: 1.8000831604003906
Validation loss: 2.0438059369723

Epoch: 6| Step: 13
Training loss: 2.1220927238464355
Validation loss: 2.0541910926500955

Epoch: 64| Step: 0
Training loss: 1.973958969116211
Validation loss: 2.0809771617253623

Epoch: 6| Step: 1
Training loss: 1.6820350885391235
Validation loss: 2.0925572514533997

Epoch: 6| Step: 2
Training loss: 2.036332845687866
Validation loss: 2.0701573292414346

Epoch: 6| Step: 3
Training loss: 1.100916862487793
Validation loss: 2.1033325791358948

Epoch: 6| Step: 4
Training loss: 1.778134822845459
Validation loss: 2.0664967695871987

Epoch: 6| Step: 5
Training loss: 1.8794326782226562
Validation loss: 2.0650383035341897

Epoch: 6| Step: 6
Training loss: 1.7708454132080078
Validation loss: 2.052299976348877

Epoch: 6| Step: 7
Training loss: 2.0939998626708984
Validation loss: 2.050803820292155

Epoch: 6| Step: 8
Training loss: 2.0041441917419434
Validation loss: 2.031025528907776

Epoch: 6| Step: 9
Training loss: 2.0573365688323975
Validation loss: 2.027181009451548

Epoch: 6| Step: 10
Training loss: 1.7967758178710938
Validation loss: 2.045257290204366

Epoch: 6| Step: 11
Training loss: 1.7037293910980225
Validation loss: 2.036967396736145

Epoch: 6| Step: 12
Training loss: 1.6547819375991821
Validation loss: 2.0175159573554993

Epoch: 6| Step: 13
Training loss: 2.0646884441375732
Validation loss: 2.036509354909261

Epoch: 65| Step: 0
Training loss: 1.5121798515319824
Validation loss: 2.039065937201182

Epoch: 6| Step: 1
Training loss: 1.5290510654449463
Validation loss: 2.013778348763784

Epoch: 6| Step: 2
Training loss: 1.4297749996185303
Validation loss: 2.028027673562368

Epoch: 6| Step: 3
Training loss: 1.9533337354660034
Validation loss: 1.9855332374572754

Epoch: 6| Step: 4
Training loss: 1.8911104202270508
Validation loss: 2.022999326388041

Epoch: 6| Step: 5
Training loss: 1.3156105279922485
Validation loss: 1.9975544214248657

Epoch: 6| Step: 6
Training loss: 2.3825902938842773
Validation loss: 2.0088061889012656

Epoch: 6| Step: 7
Training loss: 1.4331187009811401
Validation loss: 2.0077980756759644

Epoch: 6| Step: 8
Training loss: 1.8484978675842285
Validation loss: 2.023385306199392

Epoch: 6| Step: 9
Training loss: 2.627141237258911
Validation loss: 2.0282615621884665

Epoch: 6| Step: 10
Training loss: 1.6309869289398193
Validation loss: 2.0265598694483438

Epoch: 6| Step: 11
Training loss: 1.5978777408599854
Validation loss: 2.0314782857894897

Epoch: 6| Step: 12
Training loss: 2.081984043121338
Validation loss: 2.030010998249054

Epoch: 6| Step: 13
Training loss: 2.452833652496338
Validation loss: 2.0270702640215554

Epoch: 66| Step: 0
Training loss: 1.8945358991622925
Validation loss: 2.048124690850576

Epoch: 6| Step: 1
Training loss: 1.537184715270996
Validation loss: 2.0343467593193054

Epoch: 6| Step: 2
Training loss: 2.562145948410034
Validation loss: 2.0531712770462036

Epoch: 6| Step: 3
Training loss: 1.8575830459594727
Validation loss: 2.051869531472524

Epoch: 6| Step: 4
Training loss: 2.0102272033691406
Validation loss: 2.057581146558126

Epoch: 6| Step: 5
Training loss: 2.2114455699920654
Validation loss: 2.042986830075582

Epoch: 6| Step: 6
Training loss: 2.1304354667663574
Validation loss: 2.066590110460917

Epoch: 6| Step: 7
Training loss: 1.5618295669555664
Validation loss: 2.0364893277486167

Epoch: 6| Step: 8
Training loss: 1.9165899753570557
Validation loss: 2.0274873971939087

Epoch: 6| Step: 9
Training loss: 1.9638563394546509
Validation loss: 2.0215224226315818

Epoch: 6| Step: 10
Training loss: 1.3263527154922485
Validation loss: 2.038290858268738

Epoch: 6| Step: 11
Training loss: 1.1773000955581665
Validation loss: 2.0243744254112244

Epoch: 6| Step: 12
Training loss: 1.5739604234695435
Validation loss: 2.043225189050039

Epoch: 6| Step: 13
Training loss: 1.9255805015563965
Validation loss: 2.0382179021835327

Epoch: 67| Step: 0
Training loss: 1.7672207355499268
Validation loss: 2.0445683797200522

Epoch: 6| Step: 1
Training loss: 1.0248451232910156
Validation loss: 2.038654704888662

Epoch: 6| Step: 2
Training loss: 1.9777971506118774
Validation loss: 2.0460195938746133

Epoch: 6| Step: 3
Training loss: 1.8833140134811401
Validation loss: 2.073352833588918

Epoch: 6| Step: 4
Training loss: 2.0960750579833984
Validation loss: 2.0928302804629006

Epoch: 6| Step: 5
Training loss: 1.339168667793274
Validation loss: 2.0920803944269815

Epoch: 6| Step: 6
Training loss: 1.5015342235565186
Validation loss: 2.100453734397888

Epoch: 6| Step: 7
Training loss: 1.8636770248413086
Validation loss: 2.065979520479838

Epoch: 6| Step: 8
Training loss: 1.628016471862793
Validation loss: 2.0622684160868325

Epoch: 6| Step: 9
Training loss: 2.72928786277771
Validation loss: 2.052162826061249

Epoch: 6| Step: 10
Training loss: 2.2632713317871094
Validation loss: 2.020737111568451

Epoch: 6| Step: 11
Training loss: 2.1745734214782715
Validation loss: 2.00879975159963

Epoch: 6| Step: 12
Training loss: 1.9810905456542969
Validation loss: 2.0014930168787637

Epoch: 6| Step: 13
Training loss: 1.4786975383758545
Validation loss: 2.0046170353889465

Epoch: 68| Step: 0
Training loss: 1.9035297632217407
Validation loss: 2.029407183329264

Epoch: 6| Step: 1
Training loss: 2.378416061401367
Validation loss: 2.0332965652147927

Epoch: 6| Step: 2
Training loss: 1.6451466083526611
Validation loss: 2.027530093987783

Epoch: 6| Step: 3
Training loss: 1.8047294616699219
Validation loss: 2.0304995576540628

Epoch: 6| Step: 4
Training loss: 1.567017912864685
Validation loss: 2.0220305720965066

Epoch: 6| Step: 5
Training loss: 1.7506003379821777
Validation loss: 2.014290908972422

Epoch: 6| Step: 6
Training loss: 1.7451869249343872
Validation loss: 2.008463184038798

Epoch: 6| Step: 7
Training loss: 2.0308780670166016
Validation loss: 2.012889544169108

Epoch: 6| Step: 8
Training loss: 1.9597983360290527
Validation loss: 2.0055538217226663

Epoch: 6| Step: 9
Training loss: 2.0973756313323975
Validation loss: 2.0091840823491416

Epoch: 6| Step: 10
Training loss: 1.4048140048980713
Validation loss: 2.0032344659169516

Epoch: 6| Step: 11
Training loss: 1.644611120223999
Validation loss: 2.0204288760821023

Epoch: 6| Step: 12
Training loss: 1.873451828956604
Validation loss: 2.011361539363861

Epoch: 6| Step: 13
Training loss: 2.4007349014282227
Validation loss: 2.0443175236384072

Epoch: 69| Step: 0
Training loss: 1.8184198141098022
Validation loss: 2.067382832368215

Epoch: 6| Step: 1
Training loss: 1.335376262664795
Validation loss: 2.0820834239323935

Epoch: 6| Step: 2
Training loss: 2.673623561859131
Validation loss: 2.1029169162114463

Epoch: 6| Step: 3
Training loss: 1.2781643867492676
Validation loss: 2.094801108042399

Epoch: 6| Step: 4
Training loss: 1.6660832166671753
Validation loss: 2.0836054484049478

Epoch: 6| Step: 5
Training loss: 1.849717617034912
Validation loss: 2.091890335083008

Epoch: 6| Step: 6
Training loss: 1.77524995803833
Validation loss: 2.0875444610913596

Epoch: 6| Step: 7
Training loss: 1.9860459566116333
Validation loss: 2.0550307432810464

Epoch: 6| Step: 8
Training loss: 1.8060534000396729
Validation loss: 2.0608596007029214

Epoch: 6| Step: 9
Training loss: 1.9035017490386963
Validation loss: 2.0410704811414084

Epoch: 6| Step: 10
Training loss: 1.9393436908721924
Validation loss: 2.033433119455973

Epoch: 6| Step: 11
Training loss: 1.8441213369369507
Validation loss: 2.024501403172811

Epoch: 6| Step: 12
Training loss: 1.9863536357879639
Validation loss: 2.015450596809387

Epoch: 6| Step: 13
Training loss: 1.5420305728912354
Validation loss: 2.02957954009374

Epoch: 70| Step: 0
Training loss: 1.5650749206542969
Validation loss: 2.010288139184316

Epoch: 6| Step: 1
Training loss: 1.85097074508667
Validation loss: 2.0152282317479453

Epoch: 6| Step: 2
Training loss: 1.4585800170898438
Validation loss: 2.010877311229706

Epoch: 6| Step: 3
Training loss: 2.331373691558838
Validation loss: 2.0077489217122397

Epoch: 6| Step: 4
Training loss: 2.232529640197754
Validation loss: 1.9924065272013347

Epoch: 6| Step: 5
Training loss: 2.482969284057617
Validation loss: 1.9997313022613525

Epoch: 6| Step: 6
Training loss: 2.091798782348633
Validation loss: 1.9991382559140523

Epoch: 6| Step: 7
Training loss: 1.8093750476837158
Validation loss: 2.0142966707547507

Epoch: 6| Step: 8
Training loss: 1.603005051612854
Validation loss: 2.0206342538197837

Epoch: 6| Step: 9
Training loss: 1.6904242038726807
Validation loss: 2.033481160799662

Epoch: 6| Step: 10
Training loss: 1.7218098640441895
Validation loss: 2.04049543539683

Epoch: 6| Step: 11
Training loss: 1.4936370849609375
Validation loss: 2.0488134622573853

Epoch: 6| Step: 12
Training loss: 1.696552038192749
Validation loss: 2.076232353846232

Epoch: 6| Step: 13
Training loss: 1.6160883903503418
Validation loss: 2.085477431615194

Epoch: 71| Step: 0
Training loss: 1.1704590320587158
Validation loss: 2.055918832619985

Epoch: 6| Step: 1
Training loss: 1.710601806640625
Validation loss: 2.0673077503840127

Epoch: 6| Step: 2
Training loss: 2.3173575401306152
Validation loss: 2.0612555344899497

Epoch: 6| Step: 3
Training loss: 1.713671326637268
Validation loss: 2.0461543599764505

Epoch: 6| Step: 4
Training loss: 1.8567312955856323
Validation loss: 2.0372344255447388

Epoch: 6| Step: 5
Training loss: 1.4675296545028687
Validation loss: 2.018198609352112

Epoch: 6| Step: 6
Training loss: 2.021146535873413
Validation loss: 2.039582073688507

Epoch: 6| Step: 7
Training loss: 1.1603295803070068
Validation loss: 2.0271924336751304

Epoch: 6| Step: 8
Training loss: 2.0681955814361572
Validation loss: 2.0290653506914773

Epoch: 6| Step: 9
Training loss: 1.4467923641204834
Validation loss: 2.022369702657064

Epoch: 6| Step: 10
Training loss: 1.4359965324401855
Validation loss: 2.001001298427582

Epoch: 6| Step: 11
Training loss: 2.6841912269592285
Validation loss: 2.004457116127014

Epoch: 6| Step: 12
Training loss: 1.9872854948043823
Validation loss: 2.0136556228001914

Epoch: 6| Step: 13
Training loss: 2.238020896911621
Validation loss: 2.0164438088734946

Epoch: 72| Step: 0
Training loss: 1.2081702947616577
Validation loss: 2.011889477570852

Epoch: 6| Step: 1
Training loss: 1.7469478845596313
Validation loss: 2.030201474825541

Epoch: 6| Step: 2
Training loss: 1.8529828786849976
Validation loss: 2.034738997618357

Epoch: 6| Step: 3
Training loss: 2.050590991973877
Validation loss: 2.056833187739054

Epoch: 6| Step: 4
Training loss: 1.4702095985412598
Validation loss: 2.056821902592977

Epoch: 6| Step: 5
Training loss: 1.9437379837036133
Validation loss: 2.0645726919174194

Epoch: 6| Step: 6
Training loss: 1.993030309677124
Validation loss: 2.0500121315320334

Epoch: 6| Step: 7
Training loss: 1.4744553565979004
Validation loss: 2.0679321686426797

Epoch: 6| Step: 8
Training loss: 2.072828531265259
Validation loss: 2.076095163822174

Epoch: 6| Step: 9
Training loss: 1.7602486610412598
Validation loss: 2.0441524982452393

Epoch: 6| Step: 10
Training loss: 1.8754528760910034
Validation loss: 2.0557937622070312

Epoch: 6| Step: 11
Training loss: 1.7872282266616821
Validation loss: 2.0526476899782815

Epoch: 6| Step: 12
Training loss: 1.8854650259017944
Validation loss: 2.016245941321055

Epoch: 6| Step: 13
Training loss: 2.0229885578155518
Validation loss: 2.0186927715937295

Epoch: 73| Step: 0
Training loss: 2.1113686561584473
Validation loss: 2.013562579949697

Epoch: 6| Step: 1
Training loss: 1.8368239402770996
Validation loss: 2.0229907830556235

Epoch: 6| Step: 2
Training loss: 1.6455192565917969
Validation loss: 2.025030036767324

Epoch: 6| Step: 3
Training loss: 2.022540330886841
Validation loss: 2.0224589705467224

Epoch: 6| Step: 4
Training loss: 1.497214436531067
Validation loss: 2.0165407061576843

Epoch: 6| Step: 5
Training loss: 1.9776415824890137
Validation loss: 2.0234772165616355

Epoch: 6| Step: 6
Training loss: 1.5468131303787231
Validation loss: 2.040479759375254

Epoch: 6| Step: 7
Training loss: 2.3709497451782227
Validation loss: 2.0477748910586038

Epoch: 6| Step: 8
Training loss: 2.468679428100586
Validation loss: 2.0539289911588035

Epoch: 6| Step: 9
Training loss: 1.7023956775665283
Validation loss: 2.076076785723368

Epoch: 6| Step: 10
Training loss: 1.9043056964874268
Validation loss: 2.090941369533539

Epoch: 6| Step: 11
Training loss: 2.321136951446533
Validation loss: 2.081007937590281

Epoch: 6| Step: 12
Training loss: 1.3268897533416748
Validation loss: 2.0780638058980307

Epoch: 6| Step: 13
Training loss: 0.9039977192878723
Validation loss: 2.0744487841924033

Epoch: 74| Step: 0
Training loss: 1.4175925254821777
Validation loss: 2.0672791600227356

Epoch: 6| Step: 1
Training loss: 2.1621923446655273
Validation loss: 2.0249564250310264

Epoch: 6| Step: 2
Training loss: 1.8543416261672974
Validation loss: 2.042661170164744

Epoch: 6| Step: 3
Training loss: 2.3789589405059814
Validation loss: 2.0106979608535767

Epoch: 6| Step: 4
Training loss: 1.5181488990783691
Validation loss: 1.9858011603355408

Epoch: 6| Step: 5
Training loss: 1.6088778972625732
Validation loss: 2.0025732119878135

Epoch: 6| Step: 6
Training loss: 1.437070369720459
Validation loss: 1.9877224961916606

Epoch: 6| Step: 7
Training loss: 1.8786847591400146
Validation loss: 1.9903761148452759

Epoch: 6| Step: 8
Training loss: 1.8039902448654175
Validation loss: 2.0224468310674033

Epoch: 6| Step: 9
Training loss: 2.0459651947021484
Validation loss: 2.010854482650757

Epoch: 6| Step: 10
Training loss: 1.1129590272903442
Validation loss: 2.0299323201179504

Epoch: 6| Step: 11
Training loss: 1.7483032941818237
Validation loss: 2.0247429609298706

Epoch: 6| Step: 12
Training loss: 1.3157384395599365
Validation loss: 1.9964649081230164

Epoch: 6| Step: 13
Training loss: 2.5681192874908447
Validation loss: 2.0144863526026406

Epoch: 75| Step: 0
Training loss: 2.0188114643096924
Validation loss: 2.042136867841085

Epoch: 6| Step: 1
Training loss: 1.6379647254943848
Validation loss: 2.0405408143997192

Epoch: 6| Step: 2
Training loss: 0.9810072183609009
Validation loss: 2.058882931868235

Epoch: 6| Step: 3
Training loss: 2.0849690437316895
Validation loss: 2.0711386799812317

Epoch: 6| Step: 4
Training loss: 2.1138010025024414
Validation loss: 2.058761994043986

Epoch: 6| Step: 5
Training loss: 1.9400256872177124
Validation loss: 2.0672272642453513

Epoch: 6| Step: 6
Training loss: 2.0020742416381836
Validation loss: 2.0752406120300293

Epoch: 6| Step: 7
Training loss: 1.5623784065246582
Validation loss: 2.0559390783309937

Epoch: 6| Step: 8
Training loss: 2.74259352684021
Validation loss: 2.031566878159841

Epoch: 6| Step: 9
Training loss: 0.9712291359901428
Validation loss: 2.0579305489857993

Epoch: 6| Step: 10
Training loss: 1.6051336526870728
Validation loss: 2.02824459473292

Epoch: 6| Step: 11
Training loss: 1.7092998027801514
Validation loss: 2.008353590965271

Epoch: 6| Step: 12
Training loss: 1.7930711507797241
Validation loss: 2.0093417167663574

Epoch: 6| Step: 13
Training loss: 1.9158434867858887
Validation loss: 1.992443859577179

Epoch: 76| Step: 0
Training loss: 1.7897858619689941
Validation loss: 2.003832737604777

Epoch: 6| Step: 1
Training loss: 2.1543025970458984
Validation loss: 2.022314469019572

Epoch: 6| Step: 2
Training loss: 2.1793203353881836
Validation loss: 2.039643863836924

Epoch: 6| Step: 3
Training loss: 1.1530792713165283
Validation loss: 2.039423088232676

Epoch: 6| Step: 4
Training loss: 1.5100998878479004
Validation loss: 2.059528191884359

Epoch: 6| Step: 5
Training loss: 1.518875002861023
Validation loss: 2.047830025355021

Epoch: 6| Step: 6
Training loss: 1.5310592651367188
Validation loss: 2.050748805205027

Epoch: 6| Step: 7
Training loss: 2.4382710456848145
Validation loss: 2.052970747152964

Epoch: 6| Step: 8
Training loss: 1.9778279066085815
Validation loss: 2.053605794906616

Epoch: 6| Step: 9
Training loss: 2.0473713874816895
Validation loss: 2.0150049130121865

Epoch: 6| Step: 10
Training loss: 1.7634778022766113
Validation loss: 2.0405872662862143

Epoch: 6| Step: 11
Training loss: 1.7167285680770874
Validation loss: 2.025564134120941

Epoch: 6| Step: 12
Training loss: 1.0766425132751465
Validation loss: 2.016331593195597

Epoch: 6| Step: 13
Training loss: 1.791048526763916
Validation loss: 2.018801987171173

Epoch: 77| Step: 0
Training loss: 2.06526517868042
Validation loss: 2.0358499685923257

Epoch: 6| Step: 1
Training loss: 1.7526321411132812
Validation loss: 2.0457882483800254

Epoch: 6| Step: 2
Training loss: 1.875359296798706
Validation loss: 2.044102350870768

Epoch: 6| Step: 3
Training loss: 2.1105942726135254
Validation loss: 2.0386505126953125

Epoch: 6| Step: 4
Training loss: 1.9800527095794678
Validation loss: 2.0388524532318115

Epoch: 6| Step: 5
Training loss: 1.4301843643188477
Validation loss: 2.069763441880544

Epoch: 6| Step: 6
Training loss: 1.6342072486877441
Validation loss: 2.041210174560547

Epoch: 6| Step: 7
Training loss: 1.1514551639556885
Validation loss: 2.0499607920646667

Epoch: 6| Step: 8
Training loss: 1.3934346437454224
Validation loss: 2.0534423192342124

Epoch: 6| Step: 9
Training loss: 1.7333341836929321
Validation loss: 2.0435506304105124

Epoch: 6| Step: 10
Training loss: 1.869317889213562
Validation loss: 2.0493402083714805

Epoch: 6| Step: 11
Training loss: 1.438323974609375
Validation loss: 2.059716045856476

Epoch: 6| Step: 12
Training loss: 1.7897158861160278
Validation loss: 2.0485466519991555

Epoch: 6| Step: 13
Training loss: 2.1155457496643066
Validation loss: 2.0392653743426004

Epoch: 78| Step: 0
Training loss: 1.5039637088775635
Validation loss: 2.0298675497372947

Epoch: 6| Step: 1
Training loss: 2.272373676300049
Validation loss: 2.0435284773508706

Epoch: 6| Step: 2
Training loss: 1.560265064239502
Validation loss: 2.0088378389676413

Epoch: 6| Step: 3
Training loss: 1.6725612878799438
Validation loss: 2.025587181250254

Epoch: 6| Step: 4
Training loss: 1.7815117835998535
Validation loss: 2.0320914586385093

Epoch: 6| Step: 5
Training loss: 1.5000896453857422
Validation loss: 2.039195795853933

Epoch: 6| Step: 6
Training loss: 2.4795992374420166
Validation loss: 2.0369646151860556

Epoch: 6| Step: 7
Training loss: 1.8252958059310913
Validation loss: 2.0444993575414023

Epoch: 6| Step: 8
Training loss: 1.88345468044281
Validation loss: 2.069025973478953

Epoch: 6| Step: 9
Training loss: 1.5445246696472168
Validation loss: 2.0505665938059487

Epoch: 6| Step: 10
Training loss: 2.0415399074554443
Validation loss: 2.048854887485504

Epoch: 6| Step: 11
Training loss: 1.831716775894165
Validation loss: 2.0526402990023294

Epoch: 6| Step: 12
Training loss: 1.5179517269134521
Validation loss: 2.0043186942736306

Epoch: 6| Step: 13
Training loss: 1.0279169082641602
Validation loss: 2.024842401345571

Epoch: 79| Step: 0
Training loss: 2.2689130306243896
Validation loss: 2.069614589214325

Epoch: 6| Step: 1
Training loss: 1.3695001602172852
Validation loss: 2.039305567741394

Epoch: 6| Step: 2
Training loss: 1.6441354751586914
Validation loss: 2.055229147275289

Epoch: 6| Step: 3
Training loss: 2.362704277038574
Validation loss: 2.0433364510536194

Epoch: 6| Step: 4
Training loss: 1.9886250495910645
Validation loss: 2.084462503592173

Epoch: 6| Step: 5
Training loss: 1.6116828918457031
Validation loss: 2.0720696250597634

Epoch: 6| Step: 6
Training loss: 1.3544121980667114
Validation loss: 2.0506879091262817

Epoch: 6| Step: 7
Training loss: 1.470456600189209
Validation loss: 2.018279731273651

Epoch: 6| Step: 8
Training loss: 2.1120800971984863
Validation loss: 2.020023504892985

Epoch: 6| Step: 9
Training loss: 1.9099721908569336
Validation loss: 2.0129231810569763

Epoch: 6| Step: 10
Training loss: 1.8361611366271973
Validation loss: 2.026062766710917

Epoch: 6| Step: 11
Training loss: 1.8362822532653809
Validation loss: 2.019184172153473

Epoch: 6| Step: 12
Training loss: 1.0558297634124756
Validation loss: 2.0513141552607217

Epoch: 6| Step: 13
Training loss: 1.689899206161499
Validation loss: 2.050129254659017

Epoch: 80| Step: 0
Training loss: 1.6363955736160278
Validation loss: 2.077855388323466

Epoch: 6| Step: 1
Training loss: 1.7870179414749146
Validation loss: 2.075655778249105

Epoch: 6| Step: 2
Training loss: 2.5711328983306885
Validation loss: 2.088810662428538

Epoch: 6| Step: 3
Training loss: 2.0169830322265625
Validation loss: 2.069338321685791

Epoch: 6| Step: 4
Training loss: 1.3421258926391602
Validation loss: 2.055636008580526

Epoch: 6| Step: 5
Training loss: 2.192633628845215
Validation loss: 2.0788756807645163

Epoch: 6| Step: 6
Training loss: 1.5935931205749512
Validation loss: 2.0742527643839517

Epoch: 6| Step: 7
Training loss: 1.2858598232269287
Validation loss: 2.0518083572387695

Epoch: 6| Step: 8
Training loss: 2.050663948059082
Validation loss: 2.055847783883413

Epoch: 6| Step: 9
Training loss: 1.2439641952514648
Validation loss: 2.044459640979767

Epoch: 6| Step: 10
Training loss: 1.4477176666259766
Validation loss: 2.0426822503407798

Epoch: 6| Step: 11
Training loss: 1.4450993537902832
Validation loss: 2.0385759472846985

Epoch: 6| Step: 12
Training loss: 1.6967999935150146
Validation loss: 2.028647005558014

Epoch: 6| Step: 13
Training loss: 1.685553789138794
Validation loss: 2.0387067000071206

Epoch: 81| Step: 0
Training loss: 2.1720123291015625
Validation loss: 2.0143863956133523

Epoch: 6| Step: 1
Training loss: 1.5695666074752808
Validation loss: 2.0234456260999045

Epoch: 6| Step: 2
Training loss: 1.9031651020050049
Validation loss: 2.0157262881596885

Epoch: 6| Step: 3
Training loss: 1.9074883460998535
Validation loss: 2.014750858147939

Epoch: 6| Step: 4
Training loss: 1.2707552909851074
Validation loss: 2.02769535779953

Epoch: 6| Step: 5
Training loss: 2.0275392532348633
Validation loss: 2.03403906027476

Epoch: 6| Step: 6
Training loss: 1.605729341506958
Validation loss: 2.0424145658810935

Epoch: 6| Step: 7
Training loss: 1.3943437337875366
Validation loss: 2.0266615748405457

Epoch: 6| Step: 8
Training loss: 2.149746894836426
Validation loss: 2.0183423360188804

Epoch: 6| Step: 9
Training loss: 1.860614538192749
Validation loss: 2.0246148109436035

Epoch: 6| Step: 10
Training loss: 1.9384435415267944
Validation loss: 2.0083670218785605

Epoch: 6| Step: 11
Training loss: 1.5458345413208008
Validation loss: 2.0503339370091758

Epoch: 6| Step: 12
Training loss: 1.069053053855896
Validation loss: 2.0376242796579995

Epoch: 6| Step: 13
Training loss: 1.9103102684020996
Validation loss: 2.0774018963178

Epoch: 82| Step: 0
Training loss: 2.1242852210998535
Validation loss: 2.06997017065684

Epoch: 6| Step: 1
Training loss: 1.7287324666976929
Validation loss: 2.0659062266349792

Epoch: 6| Step: 2
Training loss: 1.4235725402832031
Validation loss: 2.052718917528788

Epoch: 6| Step: 3
Training loss: 1.9088605642318726
Validation loss: 2.03778068224589

Epoch: 6| Step: 4
Training loss: 1.7491803169250488
Validation loss: 2.0457104245821633

Epoch: 6| Step: 5
Training loss: 1.530947208404541
Validation loss: 2.023329516251882

Epoch: 6| Step: 6
Training loss: 1.8388181924819946
Validation loss: 2.027011056741079

Epoch: 6| Step: 7
Training loss: 1.505139946937561
Validation loss: 2.0200978914896646

Epoch: 6| Step: 8
Training loss: 1.7858901023864746
Validation loss: 2.046179175376892

Epoch: 6| Step: 9
Training loss: 2.1479334831237793
Validation loss: 2.00338081518809

Epoch: 6| Step: 10
Training loss: 1.5524613857269287
Validation loss: 1.9971946080525715

Epoch: 6| Step: 11
Training loss: 1.8702466487884521
Validation loss: 1.9907763401667278

Epoch: 6| Step: 12
Training loss: 1.6564936637878418
Validation loss: 2.0139405727386475

Epoch: 6| Step: 13
Training loss: 1.638210415840149
Validation loss: 2.047589739163717

Epoch: 83| Step: 0
Training loss: 1.6959248781204224
Validation loss: 2.059288958708445

Epoch: 6| Step: 1
Training loss: 1.754827857017517
Validation loss: 2.1001432140668235

Epoch: 6| Step: 2
Training loss: 2.0329675674438477
Validation loss: 2.145079712073008

Epoch: 6| Step: 3
Training loss: 1.5645040273666382
Validation loss: 2.1785069902737937

Epoch: 6| Step: 4
Training loss: 1.4004487991333008
Validation loss: 2.136413117249807

Epoch: 6| Step: 5
Training loss: 2.142573833465576
Validation loss: 2.156745175520579

Epoch: 6| Step: 6
Training loss: 1.93974769115448
Validation loss: 2.1071458657582602

Epoch: 6| Step: 7
Training loss: 1.890730857849121
Validation loss: 2.0853543877601624

Epoch: 6| Step: 8
Training loss: 1.8696706295013428
Validation loss: 2.0614487131436667

Epoch: 6| Step: 9
Training loss: 1.578649878501892
Validation loss: 2.0153048833211265

Epoch: 6| Step: 10
Training loss: 1.3803602457046509
Validation loss: 2.026766836643219

Epoch: 6| Step: 11
Training loss: 1.7860989570617676
Validation loss: 2.0182441671689353

Epoch: 6| Step: 12
Training loss: 1.841760516166687
Validation loss: 2.0262492100397744

Epoch: 6| Step: 13
Training loss: 1.7120733261108398
Validation loss: 2.028374751408895

Epoch: 84| Step: 0
Training loss: 1.244086503982544
Validation loss: 2.0284893115361533

Epoch: 6| Step: 1
Training loss: 1.910646915435791
Validation loss: 2.01032026608785

Epoch: 6| Step: 2
Training loss: 2.0214953422546387
Validation loss: 2.007365127404531

Epoch: 6| Step: 3
Training loss: 2.130744695663452
Validation loss: 2.0094464222590127

Epoch: 6| Step: 4
Training loss: 1.1688945293426514
Validation loss: 2.018999675909678

Epoch: 6| Step: 5
Training loss: 2.6388068199157715
Validation loss: 2.028056879838308

Epoch: 6| Step: 6
Training loss: 2.009345531463623
Validation loss: 2.0585768818855286

Epoch: 6| Step: 7
Training loss: 1.271510362625122
Validation loss: 2.091629147529602

Epoch: 6| Step: 8
Training loss: 1.907206416130066
Validation loss: 2.0945078134536743

Epoch: 6| Step: 9
Training loss: 1.0108331441879272
Validation loss: 2.1179940700531006

Epoch: 6| Step: 10
Training loss: 2.313797950744629
Validation loss: 2.1326106190681458

Epoch: 6| Step: 11
Training loss: 1.8767715692520142
Validation loss: 2.1317220528920493

Epoch: 6| Step: 12
Training loss: 1.5616589784622192
Validation loss: 2.101826032002767

Epoch: 6| Step: 13
Training loss: 1.3538283109664917
Validation loss: 2.0686602195103965

Epoch: 85| Step: 0
Training loss: 2.414818286895752
Validation loss: 2.040971040725708

Epoch: 6| Step: 1
Training loss: 1.554687738418579
Validation loss: 2.0483748515446982

Epoch: 6| Step: 2
Training loss: 1.3629274368286133
Validation loss: 2.019765933354696

Epoch: 6| Step: 3
Training loss: 1.7244994640350342
Validation loss: 2.0343379378318787

Epoch: 6| Step: 4
Training loss: 1.5954911708831787
Validation loss: 2.0259320934613547

Epoch: 6| Step: 5
Training loss: 1.6697614192962646
Validation loss: 2.017136534055074

Epoch: 6| Step: 6
Training loss: 1.6052377223968506
Validation loss: 2.0341296990712485

Epoch: 6| Step: 7
Training loss: 2.133280038833618
Validation loss: 2.037989596525828

Epoch: 6| Step: 8
Training loss: 1.9688215255737305
Validation loss: 2.038723607858022

Epoch: 6| Step: 9
Training loss: 1.7343320846557617
Validation loss: 2.0425017873446145

Epoch: 6| Step: 10
Training loss: 1.5681493282318115
Validation loss: 2.0255969564119973

Epoch: 6| Step: 11
Training loss: 1.7517616748809814
Validation loss: 2.0402005712191262

Epoch: 6| Step: 12
Training loss: 1.2273199558258057
Validation loss: 2.0359438260396323

Epoch: 6| Step: 13
Training loss: 1.4619927406311035
Validation loss: 2.0533461570739746

Epoch: 86| Step: 0
Training loss: 1.7168924808502197
Validation loss: 2.048452834288279

Epoch: 6| Step: 1
Training loss: 1.2135157585144043
Validation loss: 2.0593945384025574

Epoch: 6| Step: 2
Training loss: 1.135636806488037
Validation loss: 2.0828400452931723

Epoch: 6| Step: 3
Training loss: 2.0845205783843994
Validation loss: 2.0948565006256104

Epoch: 6| Step: 4
Training loss: 1.2544442415237427
Validation loss: 2.079580624898275

Epoch: 6| Step: 5
Training loss: 1.7065190076828003
Validation loss: 2.094311475753784

Epoch: 6| Step: 6
Training loss: 1.7798807621002197
Validation loss: 2.0746311942736306

Epoch: 6| Step: 7
Training loss: 1.9977483749389648
Validation loss: 2.054065545399984

Epoch: 6| Step: 8
Training loss: 1.8189046382904053
Validation loss: 2.0723726749420166

Epoch: 6| Step: 9
Training loss: 1.8874475955963135
Validation loss: 2.015997290611267

Epoch: 6| Step: 10
Training loss: 2.061722993850708
Validation loss: 2.0245163838068643

Epoch: 6| Step: 11
Training loss: 1.7261954545974731
Validation loss: 2.036201218763987

Epoch: 6| Step: 12
Training loss: 1.7596538066864014
Validation loss: 2.026557226975759

Epoch: 6| Step: 13
Training loss: 1.4706048965454102
Validation loss: 2.0305766463279724

Epoch: 87| Step: 0
Training loss: 1.373749017715454
Validation loss: 2.0229843854904175

Epoch: 6| Step: 1
Training loss: 1.996212124824524
Validation loss: 2.0098772247632346

Epoch: 6| Step: 2
Training loss: 1.6511942148208618
Validation loss: 2.022744615872701

Epoch: 6| Step: 3
Training loss: 1.9300048351287842
Validation loss: 2.04861052831014

Epoch: 6| Step: 4
Training loss: 1.5795447826385498
Validation loss: 2.041179358959198

Epoch: 6| Step: 5
Training loss: 1.5630069971084595
Validation loss: 2.045291264851888

Epoch: 6| Step: 6
Training loss: 1.4305704832077026
Validation loss: 2.0404736002286277

Epoch: 6| Step: 7
Training loss: 2.372908115386963
Validation loss: 2.047653158505758

Epoch: 6| Step: 8
Training loss: 1.479635238647461
Validation loss: 2.055427531401316

Epoch: 6| Step: 9
Training loss: 1.029581069946289
Validation loss: 2.0545050303141275

Epoch: 6| Step: 10
Training loss: 1.651593565940857
Validation loss: 2.0534498492876687

Epoch: 6| Step: 11
Training loss: 1.7796900272369385
Validation loss: 2.0361608266830444

Epoch: 6| Step: 12
Training loss: 1.4693909883499146
Validation loss: 2.021409730116526

Epoch: 6| Step: 13
Training loss: 2.011956214904785
Validation loss: 2.030066649119059

Epoch: 88| Step: 0
Training loss: 1.6592938899993896
Validation loss: 2.008560359477997

Epoch: 6| Step: 1
Training loss: 1.1526720523834229
Validation loss: 2.014175057411194

Epoch: 6| Step: 2
Training loss: 1.9463105201721191
Validation loss: 2.019627829392751

Epoch: 6| Step: 3
Training loss: 1.7802603244781494
Validation loss: 2.0329683423042297

Epoch: 6| Step: 4
Training loss: 1.622942328453064
Validation loss: 2.0434000492095947

Epoch: 6| Step: 5
Training loss: 1.7549275159835815
Validation loss: 2.0420524875322976

Epoch: 6| Step: 6
Training loss: 1.767206072807312
Validation loss: 2.030854562918345

Epoch: 6| Step: 7
Training loss: 2.5900402069091797
Validation loss: 2.023094137509664

Epoch: 6| Step: 8
Training loss: 1.0956294536590576
Validation loss: 2.026616334915161

Epoch: 6| Step: 9
Training loss: 1.779517412185669
Validation loss: 2.0584808786710105

Epoch: 6| Step: 10
Training loss: 1.7701764106750488
Validation loss: 2.047963321208954

Epoch: 6| Step: 11
Training loss: 1.4910516738891602
Validation loss: 2.0853647788365683

Epoch: 6| Step: 12
Training loss: 1.4050809144973755
Validation loss: 2.0905582110087075

Epoch: 6| Step: 13
Training loss: 1.761906623840332
Validation loss: 2.105522632598877

Epoch: 89| Step: 0
Training loss: 1.9595298767089844
Validation loss: 2.097495118776957

Epoch: 6| Step: 1
Training loss: 1.7856206893920898
Validation loss: 2.076851487159729

Epoch: 6| Step: 2
Training loss: 1.6418793201446533
Validation loss: 2.071321129798889

Epoch: 6| Step: 3
Training loss: 1.759040355682373
Validation loss: 2.0523137847582498

Epoch: 6| Step: 4
Training loss: 1.066535234451294
Validation loss: 2.005935549736023

Epoch: 6| Step: 5
Training loss: 1.3407472372055054
Validation loss: 2.034855047861735

Epoch: 6| Step: 6
Training loss: 1.5329490900039673
Validation loss: 2.026429017384847

Epoch: 6| Step: 7
Training loss: 2.001361608505249
Validation loss: 2.03223983446757

Epoch: 6| Step: 8
Training loss: 1.418452262878418
Validation loss: 2.029690444469452

Epoch: 6| Step: 9
Training loss: 1.4454429149627686
Validation loss: 2.016580104827881

Epoch: 6| Step: 10
Training loss: 2.4922690391540527
Validation loss: 2.0229725440343223

Epoch: 6| Step: 11
Training loss: 1.613609790802002
Validation loss: 2.0316803057988486

Epoch: 6| Step: 12
Training loss: 1.3791393041610718
Validation loss: 2.0548481345176697

Epoch: 6| Step: 13
Training loss: 2.1294260025024414
Validation loss: 2.027278959751129

Epoch: 90| Step: 0
Training loss: 1.1898503303527832
Validation loss: 2.0865451097488403

Epoch: 6| Step: 1
Training loss: 2.2217204570770264
Validation loss: 2.0843912164370217

Epoch: 6| Step: 2
Training loss: 1.476770281791687
Validation loss: 2.078523794809977

Epoch: 6| Step: 3
Training loss: 1.6560698747634888
Validation loss: 2.075055718421936

Epoch: 6| Step: 4
Training loss: 1.626973271369934
Validation loss: 2.095020830631256

Epoch: 6| Step: 5
Training loss: 1.798764944076538
Validation loss: 2.0586933890978494

Epoch: 6| Step: 6
Training loss: 1.530441403388977
Validation loss: 2.038370211919149

Epoch: 6| Step: 7
Training loss: 1.985266923904419
Validation loss: 2.033670167128245

Epoch: 6| Step: 8
Training loss: 1.4519217014312744
Validation loss: 2.043551961580912

Epoch: 6| Step: 9
Training loss: 0.9869795441627502
Validation loss: 2.0076489647229514

Epoch: 6| Step: 10
Training loss: 1.4793720245361328
Validation loss: 2.025824228922526

Epoch: 6| Step: 11
Training loss: 2.2386105060577393
Validation loss: 2.0322132110595703

Epoch: 6| Step: 12
Training loss: 1.595942497253418
Validation loss: 2.047388434410095

Epoch: 6| Step: 13
Training loss: 1.932682991027832
Validation loss: 2.026278257369995

Epoch: 91| Step: 0
Training loss: 1.5402774810791016
Validation loss: 2.039685368537903

Epoch: 6| Step: 1
Training loss: 1.6347540616989136
Validation loss: 2.0453943014144897

Epoch: 6| Step: 2
Training loss: 2.137129306793213
Validation loss: 2.0638335148493447

Epoch: 6| Step: 3
Training loss: 1.8055716753005981
Validation loss: 2.0688364505767822

Epoch: 6| Step: 4
Training loss: 1.6252667903900146
Validation loss: 2.0969032645225525

Epoch: 6| Step: 5
Training loss: 2.022920846939087
Validation loss: 2.076177795728048

Epoch: 6| Step: 6
Training loss: 1.4596498012542725
Validation loss: 2.0866110722223916

Epoch: 6| Step: 7
Training loss: 1.1802273988723755
Validation loss: 2.085263808568319

Epoch: 6| Step: 8
Training loss: 1.3362244367599487
Validation loss: 2.061106006304423

Epoch: 6| Step: 9
Training loss: 1.8833959102630615
Validation loss: 2.0708393653233848

Epoch: 6| Step: 10
Training loss: 1.7938047647476196
Validation loss: 2.0608638723691306

Epoch: 6| Step: 11
Training loss: 1.7512637376785278
Validation loss: 2.0446272492408752

Epoch: 6| Step: 12
Training loss: 1.2774549722671509
Validation loss: 2.0206961234410605

Epoch: 6| Step: 13
Training loss: 1.5809993743896484
Validation loss: 2.016533613204956

Epoch: 92| Step: 0
Training loss: 1.4066288471221924
Validation loss: 2.0207560062408447

Epoch: 6| Step: 1
Training loss: 2.2449731826782227
Validation loss: 2.029689451058706

Epoch: 6| Step: 2
Training loss: 1.7732012271881104
Validation loss: 2.031354606151581

Epoch: 6| Step: 3
Training loss: 1.59014093875885
Validation loss: 2.0441736976305642

Epoch: 6| Step: 4
Training loss: 2.005737543106079
Validation loss: 2.03941543896993

Epoch: 6| Step: 5
Training loss: 1.6016279458999634
Validation loss: 2.037064333756765

Epoch: 6| Step: 6
Training loss: 2.096975326538086
Validation loss: 2.049158791700999

Epoch: 6| Step: 7
Training loss: 1.3743488788604736
Validation loss: 2.019714057445526

Epoch: 6| Step: 8
Training loss: 1.0433993339538574
Validation loss: 2.05760250488917

Epoch: 6| Step: 9
Training loss: 1.3080761432647705
Validation loss: 2.0161869327227273

Epoch: 6| Step: 10
Training loss: 0.9994164705276489
Validation loss: 2.032504677772522

Epoch: 6| Step: 11
Training loss: 1.7619538307189941
Validation loss: 2.0476925373077393

Epoch: 6| Step: 12
Training loss: 1.8851006031036377
Validation loss: 2.039069732030233

Epoch: 6| Step: 13
Training loss: 1.534112811088562
Validation loss: 2.0487470825513205

Epoch: 93| Step: 0
Training loss: 1.4086008071899414
Validation loss: 2.0501782099405923

Epoch: 6| Step: 1
Training loss: 1.3936562538146973
Validation loss: 2.0582242806752524

Epoch: 6| Step: 2
Training loss: 1.8644349575042725
Validation loss: 2.035326381524404

Epoch: 6| Step: 3
Training loss: 1.9753377437591553
Validation loss: 2.0665963292121887

Epoch: 6| Step: 4
Training loss: 1.8116891384124756
Validation loss: 2.0626833041508994

Epoch: 6| Step: 5
Training loss: 1.765183687210083
Validation loss: 2.047071615854899

Epoch: 6| Step: 6
Training loss: 1.6204652786254883
Validation loss: 2.0526397228240967

Epoch: 6| Step: 7
Training loss: 1.3358466625213623
Validation loss: 2.0464784105618796

Epoch: 6| Step: 8
Training loss: 1.8745100498199463
Validation loss: 2.024960537751516

Epoch: 6| Step: 9
Training loss: 1.0468041896820068
Validation loss: 2.0328591068585715

Epoch: 6| Step: 10
Training loss: 1.1870380640029907
Validation loss: 2.030208428700765

Epoch: 6| Step: 11
Training loss: 1.274150013923645
Validation loss: 2.0529216726620994

Epoch: 6| Step: 12
Training loss: 2.0445897579193115
Validation loss: 2.024257938067118

Epoch: 6| Step: 13
Training loss: 2.1089088916778564
Validation loss: 2.0199816823005676

Epoch: 94| Step: 0
Training loss: 1.5926569700241089
Validation loss: 2.0400683681170144

Epoch: 6| Step: 1
Training loss: 1.2616106271743774
Validation loss: 2.048220455646515

Epoch: 6| Step: 2
Training loss: 2.2417116165161133
Validation loss: 2.024179299672445

Epoch: 6| Step: 3
Training loss: 1.5181652307510376
Validation loss: 2.0289915601412454

Epoch: 6| Step: 4
Training loss: 1.5804331302642822
Validation loss: 2.0380051136016846

Epoch: 6| Step: 5
Training loss: 1.6050355434417725
Validation loss: 2.022547662258148

Epoch: 6| Step: 6
Training loss: 1.1714268922805786
Validation loss: 2.0279919306437173

Epoch: 6| Step: 7
Training loss: 2.310959577560425
Validation loss: 2.017093042532603

Epoch: 6| Step: 8
Training loss: 2.279726982116699
Validation loss: 2.012819488843282

Epoch: 6| Step: 9
Training loss: 1.9378679990768433
Validation loss: 2.013809939225515

Epoch: 6| Step: 10
Training loss: 1.407501459121704
Validation loss: 2.0218343138694763

Epoch: 6| Step: 11
Training loss: 1.4221872091293335
Validation loss: 2.074933489163717

Epoch: 6| Step: 12
Training loss: 1.1523067951202393
Validation loss: 2.111208995183309

Epoch: 6| Step: 13
Training loss: 1.4376838207244873
Validation loss: 2.0555331707000732

Epoch: 95| Step: 0
Training loss: 1.6578031778335571
Validation loss: 2.0741471449534097

Epoch: 6| Step: 1
Training loss: 1.4830390214920044
Validation loss: 2.0840694904327393

Epoch: 6| Step: 2
Training loss: 0.976094126701355
Validation loss: 2.075424393018087

Epoch: 6| Step: 3
Training loss: 2.3504393100738525
Validation loss: 2.0667534867922464

Epoch: 6| Step: 4
Training loss: 1.5575706958770752
Validation loss: 2.049995203812917

Epoch: 6| Step: 5
Training loss: 1.6414992809295654
Validation loss: 2.0564358830451965

Epoch: 6| Step: 6
Training loss: 1.081190586090088
Validation loss: 2.046557088692983

Epoch: 6| Step: 7
Training loss: 1.4463411569595337
Validation loss: 2.024490555127462

Epoch: 6| Step: 8
Training loss: 1.908450722694397
Validation loss: 2.029571016629537

Epoch: 6| Step: 9
Training loss: 1.9048733711242676
Validation loss: 2.0213604172070823

Epoch: 6| Step: 10
Training loss: 1.795532464981079
Validation loss: 2.022239645322164

Epoch: 6| Step: 11
Training loss: 1.9497859477996826
Validation loss: 2.0363836884498596

Epoch: 6| Step: 12
Training loss: 1.3227345943450928
Validation loss: 2.025663733482361

Epoch: 6| Step: 13
Training loss: 1.1871140003204346
Validation loss: 2.023338258266449

Epoch: 96| Step: 0
Training loss: 2.0024640560150146
Validation loss: 2.0398503144582114

Epoch: 6| Step: 1
Training loss: 1.0642601251602173
Validation loss: 2.0444188515345254

Epoch: 6| Step: 2
Training loss: 1.8671493530273438
Validation loss: 2.0454297065734863

Epoch: 6| Step: 3
Training loss: 1.9255163669586182
Validation loss: 2.0495858192443848

Epoch: 6| Step: 4
Training loss: 1.6196637153625488
Validation loss: 2.0478749672571817

Epoch: 6| Step: 5
Training loss: 1.3204916715621948
Validation loss: 2.072300990422567

Epoch: 6| Step: 6
Training loss: 1.08983314037323
Validation loss: 2.050877094268799

Epoch: 6| Step: 7
Training loss: 1.8133301734924316
Validation loss: 2.0599173108736673

Epoch: 6| Step: 8
Training loss: 1.559692621231079
Validation loss: 2.054651995499929

Epoch: 6| Step: 9
Training loss: 1.4858884811401367
Validation loss: 2.0219096541404724

Epoch: 6| Step: 10
Training loss: 1.5700887441635132
Validation loss: 2.049784700075785

Epoch: 6| Step: 11
Training loss: 1.3607542514801025
Validation loss: 2.035403927167257

Epoch: 6| Step: 12
Training loss: 1.6846799850463867
Validation loss: 2.038211007912954

Epoch: 6| Step: 13
Training loss: 1.8990421295166016
Validation loss: 2.0442245403925576

Epoch: 97| Step: 0
Training loss: 2.3622307777404785
Validation loss: 2.0374255180358887

Epoch: 6| Step: 1
Training loss: 1.8641051054000854
Validation loss: 2.046228289604187

Epoch: 6| Step: 2
Training loss: 2.355922222137451
Validation loss: 2.024946928024292

Epoch: 6| Step: 3
Training loss: 1.3643298149108887
Validation loss: 2.0474892258644104

Epoch: 6| Step: 4
Training loss: 0.9628952145576477
Validation loss: 2.0590917269388833

Epoch: 6| Step: 5
Training loss: 1.1559216976165771
Validation loss: 2.038841267426809

Epoch: 6| Step: 6
Training loss: 1.4297598600387573
Validation loss: 2.021545886993408

Epoch: 6| Step: 7
Training loss: 1.6355595588684082
Validation loss: 2.0249703923861184

Epoch: 6| Step: 8
Training loss: 2.0422778129577637
Validation loss: 2.0410321156183877

Epoch: 6| Step: 9
Training loss: 1.7182940244674683
Validation loss: 2.042014201482137

Epoch: 6| Step: 10
Training loss: 1.2465554475784302
Validation loss: 2.031496604283651

Epoch: 6| Step: 11
Training loss: 1.496227741241455
Validation loss: 2.0589393973350525

Epoch: 6| Step: 12
Training loss: 1.1867060661315918
Validation loss: 2.041626453399658

Epoch: 6| Step: 13
Training loss: 1.183444857597351
Validation loss: 2.0667041540145874

Epoch: 98| Step: 0
Training loss: 1.4940441846847534
Validation loss: 2.042669336001078

Epoch: 6| Step: 1
Training loss: 1.1763170957565308
Validation loss: 2.062352240085602

Epoch: 6| Step: 2
Training loss: 1.6382479667663574
Validation loss: 2.068971415360769

Epoch: 6| Step: 3
Training loss: 1.2435503005981445
Validation loss: 2.0524486899375916

Epoch: 6| Step: 4
Training loss: 2.151109218597412
Validation loss: 2.0400219758351645

Epoch: 6| Step: 5
Training loss: 1.8352594375610352
Validation loss: 2.0444644490877786

Epoch: 6| Step: 6
Training loss: 2.28941011428833
Validation loss: 2.038802166779836

Epoch: 6| Step: 7
Training loss: 1.3314213752746582
Validation loss: 2.031532367070516

Epoch: 6| Step: 8
Training loss: 1.222053050994873
Validation loss: 2.0306698282559714

Epoch: 6| Step: 9
Training loss: 2.5168542861938477
Validation loss: 2.044504682223002

Epoch: 6| Step: 10
Training loss: 1.5051969289779663
Validation loss: 2.0322399139404297

Epoch: 6| Step: 11
Training loss: 1.3851019144058228
Validation loss: 2.067778249581655

Epoch: 6| Step: 12
Training loss: 0.9194271564483643
Validation loss: 2.053512752056122

Epoch: 6| Step: 13
Training loss: 1.4727509021759033
Validation loss: 2.047682225704193

Epoch: 99| Step: 0
Training loss: 1.2208385467529297
Validation loss: 2.0276019970575967

Epoch: 6| Step: 1
Training loss: 1.3990464210510254
Validation loss: 2.050700843334198

Epoch: 6| Step: 2
Training loss: 1.683253288269043
Validation loss: 2.0215070843696594

Epoch: 6| Step: 3
Training loss: 2.0225987434387207
Validation loss: 2.0342360734939575

Epoch: 6| Step: 4
Training loss: 1.8480737209320068
Validation loss: 2.036238690217336

Epoch: 6| Step: 5
Training loss: 1.2412936687469482
Validation loss: 2.0341764291127524

Epoch: 6| Step: 6
Training loss: 1.5903384685516357
Validation loss: 2.0459040800730386

Epoch: 6| Step: 7
Training loss: 1.5793414115905762
Validation loss: 2.0194690227508545

Epoch: 6| Step: 8
Training loss: 1.6192255020141602
Validation loss: 2.017651359240214

Epoch: 6| Step: 9
Training loss: 0.8576861619949341
Validation loss: 2.0353897412618003

Epoch: 6| Step: 10
Training loss: 1.459944486618042
Validation loss: 2.0438210566838584

Epoch: 6| Step: 11
Training loss: 1.367689847946167
Validation loss: 2.0304119984308877

Epoch: 6| Step: 12
Training loss: 2.038429021835327
Validation loss: 2.0483439763387046

Epoch: 6| Step: 13
Training loss: 1.7927632331848145
Validation loss: 2.0358776251475015

Epoch: 100| Step: 0
Training loss: 1.4032893180847168
Validation loss: 2.019792119661967

Epoch: 6| Step: 1
Training loss: 1.3738452196121216
Validation loss: 2.0368996461232505

Epoch: 6| Step: 2
Training loss: 1.755463719367981
Validation loss: 2.0367979605992637

Epoch: 6| Step: 3
Training loss: 1.836490273475647
Validation loss: 2.0333823362986245

Epoch: 6| Step: 4
Training loss: 1.354260802268982
Validation loss: 2.0099076430002847

Epoch: 6| Step: 5
Training loss: 1.134793758392334
Validation loss: 2.0178737243016562

Epoch: 6| Step: 6
Training loss: 1.2612535953521729
Validation loss: 2.018084446589152

Epoch: 6| Step: 7
Training loss: 1.9810316562652588
Validation loss: 2.0514153639475503

Epoch: 6| Step: 8
Training loss: 1.7580597400665283
Validation loss: 2.0320017337799072

Epoch: 6| Step: 9
Training loss: 1.2171744108200073
Validation loss: 2.014229118824005

Epoch: 6| Step: 10
Training loss: 1.5518007278442383
Validation loss: 2.03997266292572

Epoch: 6| Step: 11
Training loss: 1.7934520244598389
Validation loss: 2.0268346865971885

Epoch: 6| Step: 12
Training loss: 0.9799319505691528
Validation loss: 2.058839420477549

Epoch: 6| Step: 13
Training loss: 1.9340431690216064
Validation loss: 2.046199917793274

Epoch: 101| Step: 0
Training loss: 1.0974993705749512
Validation loss: 2.0535507202148438

Epoch: 6| Step: 1
Training loss: 1.8770561218261719
Validation loss: 2.070797840754191

Epoch: 6| Step: 2
Training loss: 1.9942731857299805
Validation loss: 2.0634839137395224

Epoch: 6| Step: 3
Training loss: 1.5356457233428955
Validation loss: 2.039949973424276

Epoch: 6| Step: 4
Training loss: 1.092337727546692
Validation loss: 2.042369862397512

Epoch: 6| Step: 5
Training loss: 2.0988216400146484
Validation loss: 2.065693477789561

Epoch: 6| Step: 6
Training loss: 2.2718589305877686
Validation loss: 2.0275556445121765

Epoch: 6| Step: 7
Training loss: 0.7996525764465332
Validation loss: 2.0296838084856668

Epoch: 6| Step: 8
Training loss: 1.5559453964233398
Validation loss: 2.043108363946279

Epoch: 6| Step: 9
Training loss: 0.9436786770820618
Validation loss: 2.0518280069033303

Epoch: 6| Step: 10
Training loss: 1.1817550659179688
Validation loss: 2.049693842728933

Epoch: 6| Step: 11
Training loss: 1.6271613836288452
Validation loss: 2.0348748564720154

Epoch: 6| Step: 12
Training loss: 1.573933720588684
Validation loss: 2.0183502435684204

Epoch: 6| Step: 13
Training loss: 1.7865734100341797
Validation loss: 2.032567818959554

Epoch: 102| Step: 0
Training loss: 1.798170566558838
Validation loss: 2.0501015186309814

Epoch: 6| Step: 1
Training loss: 1.5430498123168945
Validation loss: 2.0631283124287925

Epoch: 6| Step: 2
Training loss: 1.1765382289886475
Validation loss: 2.0506500204404197

Epoch: 6| Step: 3
Training loss: 1.6820979118347168
Validation loss: 2.0416250228881836

Epoch: 6| Step: 4
Training loss: 1.1216237545013428
Validation loss: 2.052317281564077

Epoch: 6| Step: 5
Training loss: 1.5903639793395996
Validation loss: 2.0571189324061074

Epoch: 6| Step: 6
Training loss: 2.651705026626587
Validation loss: 2.0229558746019998

Epoch: 6| Step: 7
Training loss: 1.7563197612762451
Validation loss: 2.0458484093348184

Epoch: 6| Step: 8
Training loss: 2.0645880699157715
Validation loss: 2.037693738937378

Epoch: 6| Step: 9
Training loss: 1.2802999019622803
Validation loss: 2.0351066986719766

Epoch: 6| Step: 10
Training loss: 1.2938379049301147
Validation loss: 2.0414996345837912

Epoch: 6| Step: 11
Training loss: 1.3978022336959839
Validation loss: 2.0447060068448386

Epoch: 6| Step: 12
Training loss: 1.2649891376495361
Validation loss: 2.049515704313914

Epoch: 6| Step: 13
Training loss: 0.9082628488540649
Validation loss: 2.055848399798075

Epoch: 103| Step: 0
Training loss: 1.4351084232330322
Validation loss: 2.0637347300847373

Epoch: 6| Step: 1
Training loss: 1.6701536178588867
Validation loss: 2.0666162371635437

Epoch: 6| Step: 2
Training loss: 0.9910078644752502
Validation loss: 2.075551768143972

Epoch: 6| Step: 3
Training loss: 0.6906610727310181
Validation loss: 2.0855311950047812

Epoch: 6| Step: 4
Training loss: 1.4811166524887085
Validation loss: 2.09350715080897

Epoch: 6| Step: 5
Training loss: 0.7241220474243164
Validation loss: 2.074675679206848

Epoch: 6| Step: 6
Training loss: 1.3550915718078613
Validation loss: 2.0292205015818277

Epoch: 6| Step: 7
Training loss: 1.9114552736282349
Validation loss: 2.0461036761601767

Epoch: 6| Step: 8
Training loss: 1.6681468486785889
Validation loss: 2.0675204396247864

Epoch: 6| Step: 9
Training loss: 2.1935055255889893
Validation loss: 2.0535122553507485

Epoch: 6| Step: 10
Training loss: 1.592923641204834
Validation loss: 2.0424004197120667

Epoch: 6| Step: 11
Training loss: 2.294968843460083
Validation loss: 2.0454392631848655

Epoch: 6| Step: 12
Training loss: 1.6373435258865356
Validation loss: 2.0379016598065696

Epoch: 6| Step: 13
Training loss: 1.8347361087799072
Validation loss: 2.0407251914342246

Epoch: 104| Step: 0
Training loss: 1.7321457862854004
Validation loss: 2.0505900382995605

Epoch: 6| Step: 1
Training loss: 1.497975468635559
Validation loss: 2.0531861782073975

Epoch: 6| Step: 2
Training loss: 2.1791210174560547
Validation loss: 2.0340672930081687

Epoch: 6| Step: 3
Training loss: 1.6211494207382202
Validation loss: 2.0541502237319946

Epoch: 6| Step: 4
Training loss: 2.126896381378174
Validation loss: 2.0233894189198813

Epoch: 6| Step: 5
Training loss: 1.7737523317337036
Validation loss: 2.058671792348226

Epoch: 6| Step: 6
Training loss: 1.7169859409332275
Validation loss: 2.0955017606417337

Epoch: 6| Step: 7
Training loss: 1.6780390739440918
Validation loss: 2.092504858970642

Epoch: 6| Step: 8
Training loss: 0.9805554151535034
Validation loss: 2.087935467561086

Epoch: 6| Step: 9
Training loss: 1.220580816268921
Validation loss: 2.0832101106643677

Epoch: 6| Step: 10
Training loss: 1.0000593662261963
Validation loss: 2.0912073651949563

Epoch: 6| Step: 11
Training loss: 1.4070597887039185
Validation loss: 2.0107863744099936

Epoch: 6| Step: 12
Training loss: 1.4619386196136475
Validation loss: 2.0297033389409385

Epoch: 6| Step: 13
Training loss: 1.2482454776763916
Validation loss: 2.0655932823816934

Epoch: 105| Step: 0
Training loss: 1.4441814422607422
Validation loss: 2.061672270298004

Epoch: 6| Step: 1
Training loss: 1.704528570175171
Validation loss: 2.0439712405204773

Epoch: 6| Step: 2
Training loss: 1.4099360704421997
Validation loss: 2.022194743156433

Epoch: 6| Step: 3
Training loss: 0.8754521608352661
Validation loss: 2.0335429509480796

Epoch: 6| Step: 4
Training loss: 2.2297239303588867
Validation loss: 2.0202800035476685

Epoch: 6| Step: 5
Training loss: 1.5047245025634766
Validation loss: 2.0229989687601724

Epoch: 6| Step: 6
Training loss: 1.4703686237335205
Validation loss: 2.039547602335612

Epoch: 6| Step: 7
Training loss: 1.8360042572021484
Validation loss: 2.0506229201952615

Epoch: 6| Step: 8
Training loss: 1.0684177875518799
Validation loss: 2.0292922457059226

Epoch: 6| Step: 9
Training loss: 1.9859061241149902
Validation loss: 2.0745575030644736

Epoch: 6| Step: 10
Training loss: 1.362337589263916
Validation loss: 2.1008134484291077

Epoch: 6| Step: 11
Training loss: 1.170351266860962
Validation loss: 2.0775925517082214

Epoch: 6| Step: 12
Training loss: 1.3339285850524902
Validation loss: 2.0872551997502646

Epoch: 6| Step: 13
Training loss: 1.9470839500427246
Validation loss: 2.049561083316803

Epoch: 106| Step: 0
Training loss: 1.6940383911132812
Validation loss: 2.0457558631896973

Epoch: 6| Step: 1
Training loss: 1.9201611280441284
Validation loss: 2.0096882979075112

Epoch: 6| Step: 2
Training loss: 1.9055464267730713
Validation loss: 2.0247091253598533

Epoch: 6| Step: 3
Training loss: 1.1440043449401855
Validation loss: 2.0506399671236673

Epoch: 6| Step: 4
Training loss: 1.1126716136932373
Validation loss: 2.0547974507013955

Epoch: 6| Step: 5
Training loss: 1.5843546390533447
Validation loss: 2.0709431370099387

Epoch: 6| Step: 6
Training loss: 1.6805717945098877
Validation loss: 2.0597567558288574

Epoch: 6| Step: 7
Training loss: 1.3124949932098389
Validation loss: 2.0483208298683167

Epoch: 6| Step: 8
Training loss: 1.2665863037109375
Validation loss: 2.0181648333867392

Epoch: 6| Step: 9
Training loss: 1.816752552986145
Validation loss: 2.021493434906006

Epoch: 6| Step: 10
Training loss: 1.5000699758529663
Validation loss: 2.0401278734207153

Epoch: 6| Step: 11
Training loss: 1.734669804573059
Validation loss: 2.1043401956558228

Epoch: 6| Step: 12
Training loss: 1.337754726409912
Validation loss: 2.0882383982340493

Epoch: 6| Step: 13
Training loss: 1.4050248861312866
Validation loss: 2.1523465514183044

Epoch: 107| Step: 0
Training loss: 1.4400806427001953
Validation loss: 2.1324384411176047

Epoch: 6| Step: 1
Training loss: 1.9735708236694336
Validation loss: 2.0851147373517356

Epoch: 6| Step: 2
Training loss: 1.9252122640609741
Validation loss: 2.109348018964132

Epoch: 6| Step: 3
Training loss: 1.311103343963623
Validation loss: 2.046171943346659

Epoch: 6| Step: 4
Training loss: 1.5441569089889526
Validation loss: 2.039515415827433

Epoch: 6| Step: 5
Training loss: 1.1482584476470947
Validation loss: 2.0408637722333274

Epoch: 6| Step: 6
Training loss: 1.9677281379699707
Validation loss: 2.048666556676229

Epoch: 6| Step: 7
Training loss: 1.0850071907043457
Validation loss: 2.0568278233210244

Epoch: 6| Step: 8
Training loss: 1.4893598556518555
Validation loss: 2.074668010075887

Epoch: 6| Step: 9
Training loss: 1.4617869853973389
Validation loss: 2.070078194141388

Epoch: 6| Step: 10
Training loss: 1.5931477546691895
Validation loss: 2.0442538460095725

Epoch: 6| Step: 11
Training loss: 1.2338204383850098
Validation loss: 2.0509524941444397

Epoch: 6| Step: 12
Training loss: 1.2234036922454834
Validation loss: 2.0621174772580466

Epoch: 6| Step: 13
Training loss: 2.1196234226226807
Validation loss: 2.0765090783437095

Epoch: 108| Step: 0
Training loss: 1.9715715646743774
Validation loss: 2.055299441019694

Epoch: 6| Step: 1
Training loss: 2.2419936656951904
Validation loss: 2.078741133213043

Epoch: 6| Step: 2
Training loss: 1.388246774673462
Validation loss: 2.096866567929586

Epoch: 6| Step: 3
Training loss: 1.2324638366699219
Validation loss: 2.058975577354431

Epoch: 6| Step: 4
Training loss: 1.042456865310669
Validation loss: 2.062569479147593

Epoch: 6| Step: 5
Training loss: 1.9866975545883179
Validation loss: 2.0694199601809182

Epoch: 6| Step: 6
Training loss: 1.6903760433197021
Validation loss: 2.0647462606430054

Epoch: 6| Step: 7
Training loss: 1.2555280923843384
Validation loss: 2.044335722923279

Epoch: 6| Step: 8
Training loss: 1.1118099689483643
Validation loss: 2.038203001022339

Epoch: 6| Step: 9
Training loss: 1.14896821975708
Validation loss: 2.0228671431541443

Epoch: 6| Step: 10
Training loss: 1.3047921657562256
Validation loss: 2.0273184776306152

Epoch: 6| Step: 11
Training loss: 1.4083633422851562
Validation loss: 2.012634813785553

Epoch: 6| Step: 12
Training loss: 1.5438916683197021
Validation loss: 2.05090469121933

Epoch: 6| Step: 13
Training loss: 1.522580862045288
Validation loss: 2.049014131228129

Epoch: 109| Step: 0
Training loss: 1.1453118324279785
Validation loss: 2.0506821076075235

Epoch: 6| Step: 1
Training loss: 1.0755770206451416
Validation loss: 2.0303390423456826

Epoch: 6| Step: 2
Training loss: 2.1468286514282227
Validation loss: 2.047895630200704

Epoch: 6| Step: 3
Training loss: 1.4320077896118164
Validation loss: 2.0485108296076455

Epoch: 6| Step: 4
Training loss: 1.174836277961731
Validation loss: 2.0838772455851235

Epoch: 6| Step: 5
Training loss: 0.7456855177879333
Validation loss: 2.0536219278971353

Epoch: 6| Step: 6
Training loss: 1.803396224975586
Validation loss: 2.0335155526796975

Epoch: 6| Step: 7
Training loss: 1.4765589237213135
Validation loss: 2.038837750752767

Epoch: 6| Step: 8
Training loss: 1.1523497104644775
Validation loss: 2.0283246835072837

Epoch: 6| Step: 9
Training loss: 1.2470588684082031
Validation loss: 2.040686051050822

Epoch: 6| Step: 10
Training loss: 1.9275691509246826
Validation loss: 2.026382803916931

Epoch: 6| Step: 11
Training loss: 1.941472053527832
Validation loss: 2.0131301482518515

Epoch: 6| Step: 12
Training loss: 1.8916082382202148
Validation loss: 2.042811473210653

Epoch: 6| Step: 13
Training loss: 1.2146767377853394
Validation loss: 2.02980242172877

Epoch: 110| Step: 0
Training loss: 1.8369039297103882
Validation loss: 2.0655491749445596

Epoch: 6| Step: 1
Training loss: 0.9910657405853271
Validation loss: 2.059116085370382

Epoch: 6| Step: 2
Training loss: 1.4171886444091797
Validation loss: 2.056257704893748

Epoch: 6| Step: 3
Training loss: 1.8109984397888184
Validation loss: 2.0550856788953147

Epoch: 6| Step: 4
Training loss: 1.862023115158081
Validation loss: 2.0534682075182595

Epoch: 6| Step: 5
Training loss: 1.2659574747085571
Validation loss: 2.0389976104100547

Epoch: 6| Step: 6
Training loss: 0.9672929644584656
Validation loss: 2.049957831700643

Epoch: 6| Step: 7
Training loss: 1.2410417795181274
Validation loss: 2.0571370720863342

Epoch: 6| Step: 8
Training loss: 2.0021841526031494
Validation loss: 2.041487157344818

Epoch: 6| Step: 9
Training loss: 1.4689640998840332
Validation loss: 2.051189363002777

Epoch: 6| Step: 10
Training loss: 1.8060882091522217
Validation loss: 1.9980465173721313

Epoch: 6| Step: 11
Training loss: 1.4005100727081299
Validation loss: 2.0334167083104453

Epoch: 6| Step: 12
Training loss: 1.1947568655014038
Validation loss: 2.0342601537704468

Epoch: 6| Step: 13
Training loss: 0.9742844700813293
Validation loss: 2.04226815700531

Epoch: 111| Step: 0
Training loss: 1.5903589725494385
Validation loss: 2.040413200855255

Epoch: 6| Step: 1
Training loss: 1.1542131900787354
Validation loss: 2.0389382243156433

Epoch: 6| Step: 2
Training loss: 1.9441232681274414
Validation loss: 2.0193708539009094

Epoch: 6| Step: 3
Training loss: 1.5005167722702026
Validation loss: 2.0670734643936157

Epoch: 6| Step: 4
Training loss: 1.6525187492370605
Validation loss: 2.0292919278144836

Epoch: 6| Step: 5
Training loss: 0.8219441175460815
Validation loss: 2.0314847032229104

Epoch: 6| Step: 6
Training loss: 1.7119423151016235
Validation loss: 2.0185839931170144

Epoch: 6| Step: 7
Training loss: 1.5569807291030884
Validation loss: 2.012414495150248

Epoch: 6| Step: 8
Training loss: 1.3968698978424072
Validation loss: 2.018293102582296

Epoch: 6| Step: 9
Training loss: 1.586441993713379
Validation loss: 2.0472333232561746

Epoch: 6| Step: 10
Training loss: 1.7940456867218018
Validation loss: 2.018205006917318

Epoch: 6| Step: 11
Training loss: 1.494659423828125
Validation loss: 2.018618404865265

Epoch: 6| Step: 12
Training loss: 1.0954593420028687
Validation loss: 2.0256609121958413

Epoch: 6| Step: 13
Training loss: 1.1198443174362183
Validation loss: 2.024328668912252

Epoch: 112| Step: 0
Training loss: 1.396794319152832
Validation loss: 2.080369551976522

Epoch: 6| Step: 1
Training loss: 2.144315481185913
Validation loss: 2.09874435265859

Epoch: 6| Step: 2
Training loss: 1.4201292991638184
Validation loss: 2.1162039836247764

Epoch: 6| Step: 3
Training loss: 1.740151286125183
Validation loss: 2.125973165035248

Epoch: 6| Step: 4
Training loss: 1.1391804218292236
Validation loss: 2.0771247347195945

Epoch: 6| Step: 5
Training loss: 1.3891981840133667
Validation loss: 2.0594438115755715

Epoch: 6| Step: 6
Training loss: 0.9230679273605347
Validation loss: 2.0290406346321106

Epoch: 6| Step: 7
Training loss: 1.2681162357330322
Validation loss: 2.0058008432388306

Epoch: 6| Step: 8
Training loss: 1.056928277015686
Validation loss: 2.0234753489494324

Epoch: 6| Step: 9
Training loss: 1.9286916255950928
Validation loss: 2.021779219309489

Epoch: 6| Step: 10
Training loss: 0.9910758137702942
Validation loss: 2.053978363672892

Epoch: 6| Step: 11
Training loss: 1.7796416282653809
Validation loss: 2.0162676572799683

Epoch: 6| Step: 12
Training loss: 1.4004119634628296
Validation loss: 2.0199799140294394

Epoch: 6| Step: 13
Training loss: 1.876192569732666
Validation loss: 2.0401310523351035

Epoch: 113| Step: 0
Training loss: 1.0180180072784424
Validation loss: 2.038996934890747

Epoch: 6| Step: 1
Training loss: 1.4827529191970825
Validation loss: 2.0148759682973227

Epoch: 6| Step: 2
Training loss: 0.9810250401496887
Validation loss: 2.006341338157654

Epoch: 6| Step: 3
Training loss: 1.603718638420105
Validation loss: 2.0146902402242026

Epoch: 6| Step: 4
Training loss: 0.8711099624633789
Validation loss: 2.021447539329529

Epoch: 6| Step: 5
Training loss: 1.9052592515945435
Validation loss: 2.051340659459432

Epoch: 6| Step: 6
Training loss: 2.3563642501831055
Validation loss: 2.0508732398351035

Epoch: 6| Step: 7
Training loss: 1.443717122077942
Validation loss: 2.045841117699941

Epoch: 6| Step: 8
Training loss: 1.636929988861084
Validation loss: 2.066614270210266

Epoch: 6| Step: 9
Training loss: 1.325548768043518
Validation loss: 2.058951258659363

Epoch: 6| Step: 10
Training loss: 0.919413149356842
Validation loss: 2.0264862179756165

Epoch: 6| Step: 11
Training loss: 1.5928726196289062
Validation loss: 2.026352365811666

Epoch: 6| Step: 12
Training loss: 1.5121781826019287
Validation loss: 2.0193844636281333

Epoch: 6| Step: 13
Training loss: 1.8257896900177002
Validation loss: 2.0201314290364585

Epoch: 114| Step: 0
Training loss: 0.9665321707725525
Validation loss: 2.038296937942505

Epoch: 6| Step: 1
Training loss: 1.5735043287277222
Validation loss: 2.052686790625254

Epoch: 6| Step: 2
Training loss: 1.3169503211975098
Validation loss: 2.065680205821991

Epoch: 6| Step: 3
Training loss: 0.9975525140762329
Validation loss: 2.019897202650706

Epoch: 6| Step: 4
Training loss: 0.8553575277328491
Validation loss: 2.0339473287264505

Epoch: 6| Step: 5
Training loss: 1.6241940259933472
Validation loss: 2.048648774623871

Epoch: 6| Step: 6
Training loss: 1.0627944469451904
Validation loss: 2.053188900152842

Epoch: 6| Step: 7
Training loss: 1.7665588855743408
Validation loss: 2.029906153678894

Epoch: 6| Step: 8
Training loss: 1.9900801181793213
Validation loss: 2.036009192466736

Epoch: 6| Step: 9
Training loss: 1.2596075534820557
Validation loss: 2.062291959921519

Epoch: 6| Step: 10
Training loss: 1.6001191139221191
Validation loss: 2.0099037488301597

Epoch: 6| Step: 11
Training loss: 1.5631126165390015
Validation loss: 2.063533445199331

Epoch: 6| Step: 12
Training loss: 1.399867296218872
Validation loss: 2.054546674092611

Epoch: 6| Step: 13
Training loss: 1.7002290487289429
Validation loss: 2.0765761534372964

Epoch: 115| Step: 0
Training loss: 1.15423583984375
Validation loss: 2.0995487173398337

Epoch: 6| Step: 1
Training loss: 1.2310622930526733
Validation loss: 2.045982082684835

Epoch: 6| Step: 2
Training loss: 1.0811662673950195
Validation loss: 2.0536317229270935

Epoch: 6| Step: 3
Training loss: 1.4154553413391113
Validation loss: 2.0593039989471436

Epoch: 6| Step: 4
Training loss: 1.2192976474761963
Validation loss: 2.0453325112660727

Epoch: 6| Step: 5
Training loss: 0.9498021602630615
Validation loss: 2.05351851383845

Epoch: 6| Step: 6
Training loss: 2.0499534606933594
Validation loss: 2.0531258781751

Epoch: 6| Step: 7
Training loss: 1.3646135330200195
Validation loss: 2.003709355990092

Epoch: 6| Step: 8
Training loss: 1.5750435590744019
Validation loss: 2.057179888089498

Epoch: 6| Step: 9
Training loss: 1.8173547983169556
Validation loss: 2.0407666762669883

Epoch: 6| Step: 10
Training loss: 1.0876007080078125
Validation loss: 2.0374686320622764

Epoch: 6| Step: 11
Training loss: 1.2872209548950195
Validation loss: 2.0265103578567505

Epoch: 6| Step: 12
Training loss: 1.9392485618591309
Validation loss: 2.0322364370028176

Epoch: 6| Step: 13
Training loss: 1.4677739143371582
Validation loss: 2.044722537199656

Epoch: 116| Step: 0
Training loss: 1.846592903137207
Validation loss: 2.0282719930013022

Epoch: 6| Step: 1
Training loss: 0.9262679815292358
Validation loss: 2.093944509824117

Epoch: 6| Step: 2
Training loss: 1.3048765659332275
Validation loss: 2.0468329787254333

Epoch: 6| Step: 3
Training loss: 1.4032020568847656
Validation loss: 2.0732800165812173

Epoch: 6| Step: 4
Training loss: 1.8027530908584595
Validation loss: 2.0549846291542053

Epoch: 6| Step: 5
Training loss: 1.7525999546051025
Validation loss: 2.065222442150116

Epoch: 6| Step: 6
Training loss: 1.6654706001281738
Validation loss: 2.0305755337079368

Epoch: 6| Step: 7
Training loss: 1.2980873584747314
Validation loss: 2.01872311035792

Epoch: 6| Step: 8
Training loss: 1.049854040145874
Validation loss: 2.027608076731364

Epoch: 6| Step: 9
Training loss: 1.8354730606079102
Validation loss: 2.058476130167643

Epoch: 6| Step: 10
Training loss: 1.1722452640533447
Validation loss: 2.039070645968119

Epoch: 6| Step: 11
Training loss: 1.834336757659912
Validation loss: 2.036997159322103

Epoch: 6| Step: 12
Training loss: 0.912562370300293
Validation loss: 2.0416654547055564

Epoch: 6| Step: 13
Training loss: 0.987971305847168
Validation loss: 2.0413476824760437

Epoch: 117| Step: 0
Training loss: 1.3459219932556152
Validation loss: 2.040399193763733

Epoch: 6| Step: 1
Training loss: 1.1114860773086548
Validation loss: 2.0124709606170654

Epoch: 6| Step: 2
Training loss: 1.194179654121399
Validation loss: 2.0659692684809365

Epoch: 6| Step: 3
Training loss: 1.6300532817840576
Validation loss: 2.1010607878367105

Epoch: 6| Step: 4
Training loss: 1.7330882549285889
Validation loss: 2.0794049501419067

Epoch: 6| Step: 5
Training loss: 1.4162591695785522
Validation loss: 2.0733888943990073

Epoch: 6| Step: 6
Training loss: 1.8336560726165771
Validation loss: 2.0510136087735495

Epoch: 6| Step: 7
Training loss: 1.501058578491211
Validation loss: 2.042473872502645

Epoch: 6| Step: 8
Training loss: 1.1235295534133911
Validation loss: 2.0204677979151406

Epoch: 6| Step: 9
Training loss: 1.5038572549819946
Validation loss: 2.0662262241045632

Epoch: 6| Step: 10
Training loss: 1.2139229774475098
Validation loss: 2.021609048048655

Epoch: 6| Step: 11
Training loss: 1.6313564777374268
Validation loss: 2.0299495855967202

Epoch: 6| Step: 12
Training loss: 1.094560146331787
Validation loss: 2.022271911303202

Epoch: 6| Step: 13
Training loss: 1.2394781112670898
Validation loss: 2.0352890690167746

Epoch: 118| Step: 0
Training loss: 1.7260338068008423
Validation loss: 2.049684921900431

Epoch: 6| Step: 1
Training loss: 1.2242722511291504
Validation loss: 2.050171693166097

Epoch: 6| Step: 2
Training loss: 1.773883581161499
Validation loss: 2.0493320425351462

Epoch: 6| Step: 3
Training loss: 1.7730662822723389
Validation loss: 1.9875490268071492

Epoch: 6| Step: 4
Training loss: 0.8446095585823059
Validation loss: 2.028786559899648

Epoch: 6| Step: 5
Training loss: 1.4702240228652954
Validation loss: 2.0325239499409995

Epoch: 6| Step: 6
Training loss: 1.1783320903778076
Validation loss: 2.0423656702041626

Epoch: 6| Step: 7
Training loss: 1.6230738162994385
Validation loss: 2.0169116655985513

Epoch: 6| Step: 8
Training loss: 1.4311413764953613
Validation loss: 1.9987992644309998

Epoch: 6| Step: 9
Training loss: 0.8637486696243286
Validation loss: 2.029219706853231

Epoch: 6| Step: 10
Training loss: 0.9591698050498962
Validation loss: 2.04098912080129

Epoch: 6| Step: 11
Training loss: 1.8886116743087769
Validation loss: 2.0430160760879517

Epoch: 6| Step: 12
Training loss: 1.199131727218628
Validation loss: 2.04811030626297

Epoch: 6| Step: 13
Training loss: 1.0138673782348633
Validation loss: 2.058492044607798

Epoch: 119| Step: 0
Training loss: 0.8662450909614563
Validation loss: 2.0440704822540283

Epoch: 6| Step: 1
Training loss: 1.2295663356781006
Validation loss: 2.042167822519938

Epoch: 6| Step: 2
Training loss: 1.493273377418518
Validation loss: 2.0705648263295493

Epoch: 6| Step: 3
Training loss: 0.9203360080718994
Validation loss: 2.058450400829315

Epoch: 6| Step: 4
Training loss: 1.640626311302185
Validation loss: 2.018479883670807

Epoch: 6| Step: 5
Training loss: 1.1605195999145508
Validation loss: 2.0374826192855835

Epoch: 6| Step: 6
Training loss: 1.3881888389587402
Validation loss: 2.064823865890503

Epoch: 6| Step: 7
Training loss: 1.9986553192138672
Validation loss: 2.050801396369934

Epoch: 6| Step: 8
Training loss: 1.8038166761398315
Validation loss: 2.0408036510149636

Epoch: 6| Step: 9
Training loss: 1.6067997217178345
Validation loss: 2.0336540738741555

Epoch: 6| Step: 10
Training loss: 1.9777297973632812
Validation loss: 2.047883987426758

Epoch: 6| Step: 11
Training loss: 0.9285837411880493
Validation loss: 2.0620105465253196

Epoch: 6| Step: 12
Training loss: 0.9586049318313599
Validation loss: 2.0238863428433738

Epoch: 6| Step: 13
Training loss: 0.9474265575408936
Validation loss: 2.0482702056566873

Epoch: 120| Step: 0
Training loss: 1.2650117874145508
Validation loss: 2.0256518920262656

Epoch: 6| Step: 1
Training loss: 1.1274409294128418
Validation loss: 2.0494252840677896

Epoch: 6| Step: 2
Training loss: 1.5628471374511719
Validation loss: 2.0186844070752463

Epoch: 6| Step: 3
Training loss: 1.210276484489441
Validation loss: 2.0165743827819824

Epoch: 6| Step: 4
Training loss: 1.5233275890350342
Validation loss: 2.063475469748179

Epoch: 6| Step: 5
Training loss: 0.7561571598052979
Validation loss: 2.0328702529271445

Epoch: 6| Step: 6
Training loss: 1.1357347965240479
Validation loss: 2.0098435282707214

Epoch: 6| Step: 7
Training loss: 1.7385613918304443
Validation loss: 2.0302515427271524

Epoch: 6| Step: 8
Training loss: 0.932110071182251
Validation loss: 2.0222986340522766

Epoch: 6| Step: 9
Training loss: 1.6363545656204224
Validation loss: 2.036734481652578

Epoch: 6| Step: 10
Training loss: 1.775202989578247
Validation loss: 2.041774868965149

Epoch: 6| Step: 11
Training loss: 1.4908008575439453
Validation loss: 2.0661262472470603

Epoch: 6| Step: 12
Training loss: 1.5721445083618164
Validation loss: 2.0251818696657815

Epoch: 6| Step: 13
Training loss: 0.7465261220932007
Validation loss: 2.0247045159339905

Epoch: 121| Step: 0
Training loss: 1.2714645862579346
Validation loss: 2.0248133142789206

Epoch: 6| Step: 1
Training loss: 1.4421495199203491
Validation loss: 2.041463394959768

Epoch: 6| Step: 2
Training loss: 1.252750277519226
Validation loss: 2.000456134478251

Epoch: 6| Step: 3
Training loss: 1.258060097694397
Validation loss: 2.0396146376927695

Epoch: 6| Step: 4
Training loss: 0.6955596208572388
Validation loss: 2.0345890720685325

Epoch: 6| Step: 5
Training loss: 1.4489814043045044
Validation loss: 2.0248274207115173

Epoch: 6| Step: 6
Training loss: 1.8794498443603516
Validation loss: 2.024791677792867

Epoch: 6| Step: 7
Training loss: 1.4363481998443604
Validation loss: 2.008432606856028

Epoch: 6| Step: 8
Training loss: 1.9055664539337158
Validation loss: 2.0394540230433145

Epoch: 6| Step: 9
Training loss: 1.4013396501541138
Validation loss: 2.0158983866373696

Epoch: 6| Step: 10
Training loss: 1.3028106689453125
Validation loss: 2.0195383032162986

Epoch: 6| Step: 11
Training loss: 1.2454054355621338
Validation loss: 2.021406332651774

Epoch: 6| Step: 12
Training loss: 1.0304476022720337
Validation loss: 2.050175448258718

Epoch: 6| Step: 13
Training loss: 1.1015607118606567
Validation loss: 2.082744042078654

Epoch: 122| Step: 0
Training loss: 1.5606497526168823
Validation loss: 2.047301431496938

Epoch: 6| Step: 1
Training loss: 0.9877943992614746
Validation loss: 2.0559948682785034

Epoch: 6| Step: 2
Training loss: 1.1871731281280518
Validation loss: 2.045706848303477

Epoch: 6| Step: 3
Training loss: 1.649787425994873
Validation loss: 2.0501956939697266

Epoch: 6| Step: 4
Training loss: 1.4499430656433105
Validation loss: 2.0277861952781677

Epoch: 6| Step: 5
Training loss: 1.2127869129180908
Validation loss: 2.039206842581431

Epoch: 6| Step: 6
Training loss: 1.0341325998306274
Validation loss: 2.014695703983307

Epoch: 6| Step: 7
Training loss: 1.148258090019226
Validation loss: 2.029371678829193

Epoch: 6| Step: 8
Training loss: 1.3714535236358643
Validation loss: 2.0285720229148865

Epoch: 6| Step: 9
Training loss: 1.9533982276916504
Validation loss: 2.0265591939290366

Epoch: 6| Step: 10
Training loss: 1.2010787725448608
Validation loss: 2.0170710682868958

Epoch: 6| Step: 11
Training loss: 1.4870585203170776
Validation loss: 2.0365121960639954

Epoch: 6| Step: 12
Training loss: 1.0890100002288818
Validation loss: 2.011777321497599

Epoch: 6| Step: 13
Training loss: 1.3065226078033447
Validation loss: 2.077624519666036

Epoch: 123| Step: 0
Training loss: 1.0339956283569336
Validation loss: 2.053640822569529

Epoch: 6| Step: 1
Training loss: 1.5744267702102661
Validation loss: 2.099374294281006

Epoch: 6| Step: 2
Training loss: 1.398498773574829
Validation loss: 2.042698164780935

Epoch: 6| Step: 3
Training loss: 2.031271457672119
Validation loss: 2.0232227643330893

Epoch: 6| Step: 4
Training loss: 1.2541766166687012
Validation loss: 2.027829170227051

Epoch: 6| Step: 5
Training loss: 1.550926685333252
Validation loss: 2.0274768074353537

Epoch: 6| Step: 6
Training loss: 1.2133543491363525
Validation loss: 2.0171695152918496

Epoch: 6| Step: 7
Training loss: 1.5586274862289429
Validation loss: 2.0255079666773477

Epoch: 6| Step: 8
Training loss: 1.2412375211715698
Validation loss: 2.008022944132487

Epoch: 6| Step: 9
Training loss: 0.9739122986793518
Validation loss: 2.0168914794921875

Epoch: 6| Step: 10
Training loss: 1.062687873840332
Validation loss: 2.0222745140393577

Epoch: 6| Step: 11
Training loss: 0.9695942401885986
Validation loss: 2.0487490693728128

Epoch: 6| Step: 12
Training loss: 1.898720622062683
Validation loss: 2.0359050631523132

Epoch: 6| Step: 13
Training loss: 1.1906676292419434
Validation loss: 2.0596827268600464

Epoch: 124| Step: 0
Training loss: 1.0347262620925903
Validation loss: 2.033350865046183

Epoch: 6| Step: 1
Training loss: 1.6372649669647217
Validation loss: 2.0419765512148538

Epoch: 6| Step: 2
Training loss: 1.9958457946777344
Validation loss: 2.022979517777761

Epoch: 6| Step: 3
Training loss: 1.324100375175476
Validation loss: 2.010272979736328

Epoch: 6| Step: 4
Training loss: 1.0164648294448853
Validation loss: 2.004595716794332

Epoch: 6| Step: 5
Training loss: 1.2446770668029785
Validation loss: 2.0242114663124084

Epoch: 6| Step: 6
Training loss: 1.5302953720092773
Validation loss: 2.032638112703959

Epoch: 6| Step: 7
Training loss: 1.510180950164795
Validation loss: 2.041971981525421

Epoch: 6| Step: 8
Training loss: 0.9778096675872803
Validation loss: 2.0485006173451743

Epoch: 6| Step: 9
Training loss: 1.293633222579956
Validation loss: 1.991541902224223

Epoch: 6| Step: 10
Training loss: 1.0094950199127197
Validation loss: 2.028780976931254

Epoch: 6| Step: 11
Training loss: 1.024596095085144
Validation loss: 2.031668265660604

Epoch: 6| Step: 12
Training loss: 1.330939769744873
Validation loss: 2.03547994295756

Epoch: 6| Step: 13
Training loss: 1.4171061515808105
Validation loss: 2.025830864906311

Epoch: 125| Step: 0
Training loss: 1.570440649986267
Validation loss: 2.0048460364341736

Epoch: 6| Step: 1
Training loss: 1.827725887298584
Validation loss: 2.0086601773897805

Epoch: 6| Step: 2
Training loss: 1.1644647121429443
Validation loss: 2.061814228693644

Epoch: 6| Step: 3
Training loss: 0.9895616769790649
Validation loss: 2.0241978963216147

Epoch: 6| Step: 4
Training loss: 1.440077781677246
Validation loss: 2.0387678345044455

Epoch: 6| Step: 5
Training loss: 1.1144341230392456
Validation loss: 2.0550943414370217

Epoch: 6| Step: 6
Training loss: 1.060985803604126
Validation loss: 2.0229454040527344

Epoch: 6| Step: 7
Training loss: 1.371316909790039
Validation loss: 2.03290722767512

Epoch: 6| Step: 8
Training loss: 0.8643845319747925
Validation loss: 2.0179227590560913

Epoch: 6| Step: 9
Training loss: 1.572504997253418
Validation loss: 2.0255031983057656

Epoch: 6| Step: 10
Training loss: 1.3387303352355957
Validation loss: 2.0417996843655906

Epoch: 6| Step: 11
Training loss: 1.2162635326385498
Validation loss: 2.023574650287628

Epoch: 6| Step: 12
Training loss: 1.570112705230713
Validation loss: 2.0491756796836853

Epoch: 6| Step: 13
Training loss: 1.0922842025756836
Validation loss: 2.0651219884554544

Epoch: 126| Step: 0
Training loss: 1.4384799003601074
Validation loss: 2.0126370986302695

Epoch: 6| Step: 1
Training loss: 1.206464409828186
Validation loss: 2.0215391516685486

Epoch: 6| Step: 2
Training loss: 1.0130445957183838
Validation loss: 2.0185949405034385

Epoch: 6| Step: 3
Training loss: 1.5547271966934204
Validation loss: 2.000426967938741

Epoch: 6| Step: 4
Training loss: 1.3677057027816772
Validation loss: 2.029425005118052

Epoch: 6| Step: 5
Training loss: 1.4055588245391846
Validation loss: 2.080414970715841

Epoch: 6| Step: 6
Training loss: 1.7068893909454346
Validation loss: 2.062621057033539

Epoch: 6| Step: 7
Training loss: 1.234345555305481
Validation loss: 2.066264569759369

Epoch: 6| Step: 8
Training loss: 1.055802583694458
Validation loss: 2.0308702190717063

Epoch: 6| Step: 9
Training loss: 1.2361078262329102
Validation loss: 2.072578191757202

Epoch: 6| Step: 10
Training loss: 0.8275724649429321
Validation loss: 2.021040697892507

Epoch: 6| Step: 11
Training loss: 1.1527621746063232
Validation loss: 2.030215342839559

Epoch: 6| Step: 12
Training loss: 1.6480203866958618
Validation loss: 2.057475765546163

Epoch: 6| Step: 13
Training loss: 1.3575443029403687
Validation loss: 2.0473387042681375

Epoch: 127| Step: 0
Training loss: 1.090698480606079
Validation loss: 2.02786378065745

Epoch: 6| Step: 1
Training loss: 1.4009027481079102
Validation loss: 2.064000189304352

Epoch: 6| Step: 2
Training loss: 0.7831293344497681
Validation loss: 2.0256826480229697

Epoch: 6| Step: 3
Training loss: 1.072737216949463
Validation loss: 2.039060731728872

Epoch: 6| Step: 4
Training loss: 0.9613344073295593
Validation loss: 2.0535616079966226

Epoch: 6| Step: 5
Training loss: 1.434262752532959
Validation loss: 2.002165973186493

Epoch: 6| Step: 6
Training loss: 1.0855252742767334
Validation loss: 2.0697477062543235

Epoch: 6| Step: 7
Training loss: 1.544243574142456
Validation loss: 2.0178180734316506

Epoch: 6| Step: 8
Training loss: 1.1512315273284912
Validation loss: 2.025892496109009

Epoch: 6| Step: 9
Training loss: 1.2554266452789307
Validation loss: 2.0341721177101135

Epoch: 6| Step: 10
Training loss: 1.239349365234375
Validation loss: 2.0304002364476523

Epoch: 6| Step: 11
Training loss: 1.4663971662521362
Validation loss: 2.0740187962849936

Epoch: 6| Step: 12
Training loss: 1.8165709972381592
Validation loss: 2.027342359224955

Epoch: 6| Step: 13
Training loss: 1.5036780834197998
Validation loss: 2.0238888263702393

Epoch: 128| Step: 0
Training loss: 1.6671841144561768
Validation loss: 2.047094444433848

Epoch: 6| Step: 1
Training loss: 1.5276455879211426
Validation loss: 2.019567131996155

Epoch: 6| Step: 2
Training loss: 1.403306007385254
Validation loss: 2.0404168168703714

Epoch: 6| Step: 3
Training loss: 1.245271921157837
Validation loss: 2.029396573702494

Epoch: 6| Step: 4
Training loss: 1.1064738035202026
Validation loss: 2.067457934220632

Epoch: 6| Step: 5
Training loss: 0.654281735420227
Validation loss: 2.0813790957132974

Epoch: 6| Step: 6
Training loss: 1.290305733680725
Validation loss: 2.0503626664479575

Epoch: 6| Step: 7
Training loss: 1.245912790298462
Validation loss: 2.0245816508928933

Epoch: 6| Step: 8
Training loss: 1.081981897354126
Validation loss: 2.027676542599996

Epoch: 6| Step: 9
Training loss: 1.213597059249878
Validation loss: 2.014766196409861

Epoch: 6| Step: 10
Training loss: 0.9839888215065002
Validation loss: 2.0534258087476096

Epoch: 6| Step: 11
Training loss: 1.380699872970581
Validation loss: 2.054565946261088

Epoch: 6| Step: 12
Training loss: 1.6714143753051758
Validation loss: 2.0670544703801474

Epoch: 6| Step: 13
Training loss: 1.4107847213745117
Validation loss: 2.0816157460212708

Epoch: 129| Step: 0
Training loss: 1.5925430059432983
Validation loss: 2.0665368835131326

Epoch: 6| Step: 1
Training loss: 1.1747559309005737
Validation loss: 2.05053174495697

Epoch: 6| Step: 2
Training loss: 1.417080044746399
Validation loss: 2.110145608584086

Epoch: 6| Step: 3
Training loss: 1.0994181632995605
Validation loss: 2.0565505425135293

Epoch: 6| Step: 4
Training loss: 1.7792911529541016
Validation loss: 2.10907777150472

Epoch: 6| Step: 5
Training loss: 1.5201518535614014
Validation loss: 2.087477525075277

Epoch: 6| Step: 6
Training loss: 1.4173706769943237
Validation loss: 2.0625560681025186

Epoch: 6| Step: 7
Training loss: 0.9832160472869873
Validation loss: 2.0583008527755737

Epoch: 6| Step: 8
Training loss: 1.216360092163086
Validation loss: 2.018257439136505

Epoch: 6| Step: 9
Training loss: 0.8867387771606445
Validation loss: 2.0281158685684204

Epoch: 6| Step: 10
Training loss: 1.1285755634307861
Validation loss: 2.0481690565745034

Epoch: 6| Step: 11
Training loss: 1.953395962715149
Validation loss: 2.0716862082481384

Epoch: 6| Step: 12
Training loss: 1.105489730834961
Validation loss: 2.010978400707245

Epoch: 6| Step: 13
Training loss: 1.2518162727355957
Validation loss: 2.0482571919759116

Epoch: 130| Step: 0
Training loss: 1.445049524307251
Validation loss: 1.99622642993927

Epoch: 6| Step: 1
Training loss: 1.3153289556503296
Validation loss: 2.022446572780609

Epoch: 6| Step: 2
Training loss: 1.6993474960327148
Validation loss: 2.010829448699951

Epoch: 6| Step: 3
Training loss: 0.8962700366973877
Validation loss: 2.0163489977518716

Epoch: 6| Step: 4
Training loss: 1.223067045211792
Validation loss: 2.0345643162727356

Epoch: 6| Step: 5
Training loss: 0.6856275200843811
Validation loss: 2.1079461177190146

Epoch: 6| Step: 6
Training loss: 1.1639072895050049
Validation loss: 2.040675679842631

Epoch: 6| Step: 7
Training loss: 1.738525390625
Validation loss: 2.051365613937378

Epoch: 6| Step: 8
Training loss: 1.3974919319152832
Validation loss: 2.0427603721618652

Epoch: 6| Step: 9
Training loss: 1.1879278421401978
Validation loss: 2.037642240524292

Epoch: 6| Step: 10
Training loss: 1.5975215435028076
Validation loss: 2.0353562037150064

Epoch: 6| Step: 11
Training loss: 1.0210309028625488
Validation loss: 2.0155155460039773

Epoch: 6| Step: 12
Training loss: 1.0051336288452148
Validation loss: 2.0346405704816184

Epoch: 6| Step: 13
Training loss: 1.4518048763275146
Validation loss: 2.0571468472480774

Epoch: 131| Step: 0
Training loss: 1.7904530763626099
Validation loss: 2.0282615423202515

Epoch: 6| Step: 1
Training loss: 0.9554570913314819
Validation loss: 2.0588454802831015

Epoch: 6| Step: 2
Training loss: 0.8259772062301636
Validation loss: 2.0747937758763633

Epoch: 6| Step: 3
Training loss: 1.1109870672225952
Validation loss: 2.0488073031107583

Epoch: 6| Step: 4
Training loss: 1.0933616161346436
Validation loss: 2.0304373105367026

Epoch: 6| Step: 5
Training loss: 1.237012505531311
Validation loss: 2.0227388739585876

Epoch: 6| Step: 6
Training loss: 1.4751152992248535
Validation loss: 2.0315422415733337

Epoch: 6| Step: 7
Training loss: 1.314365029335022
Validation loss: 2.0584980845451355

Epoch: 6| Step: 8
Training loss: 1.1355396509170532
Validation loss: 2.1055243611335754

Epoch: 6| Step: 9
Training loss: 1.6107096672058105
Validation loss: 2.105108896891276

Epoch: 6| Step: 10
Training loss: 1.7506710290908813
Validation loss: 2.071183363596598

Epoch: 6| Step: 11
Training loss: 1.2212347984313965
Validation loss: 2.0628450314203897

Epoch: 6| Step: 12
Training loss: 1.1110296249389648
Validation loss: 2.022889276345571

Epoch: 6| Step: 13
Training loss: 1.2986811399459839
Validation loss: 2.0368854999542236

Epoch: 132| Step: 0
Training loss: 0.5450165271759033
Validation loss: 2.042859216531118

Epoch: 6| Step: 1
Training loss: 1.3245818614959717
Validation loss: 2.0414320627848306

Epoch: 6| Step: 2
Training loss: 1.1020519733428955
Validation loss: 2.07244211435318

Epoch: 6| Step: 3
Training loss: 1.5428160429000854
Validation loss: 2.048019746939341

Epoch: 6| Step: 4
Training loss: 1.0214263200759888
Validation loss: 2.0260488192240396

Epoch: 6| Step: 5
Training loss: 1.3117735385894775
Validation loss: 2.0589168270428977

Epoch: 6| Step: 6
Training loss: 1.3028974533081055
Validation loss: 2.0417373180389404

Epoch: 6| Step: 7
Training loss: 1.152318000793457
Validation loss: 1.9954837759335835

Epoch: 6| Step: 8
Training loss: 1.7624766826629639
Validation loss: 2.0352067152659097

Epoch: 6| Step: 9
Training loss: 1.0150728225708008
Validation loss: 2.033553103605906

Epoch: 6| Step: 10
Training loss: 1.1162693500518799
Validation loss: 2.0577187538146973

Epoch: 6| Step: 11
Training loss: 1.237912654876709
Validation loss: 2.0426263411839805

Epoch: 6| Step: 12
Training loss: 1.6367390155792236
Validation loss: 2.0713858008384705

Epoch: 6| Step: 13
Training loss: 1.1367595195770264
Validation loss: 2.0260864893595376

Epoch: 133| Step: 0
Training loss: 1.6013379096984863
Validation loss: 2.0449811617533364

Epoch: 6| Step: 1
Training loss: 1.518550157546997
Validation loss: 2.040786564350128

Epoch: 6| Step: 2
Training loss: 1.63290274143219
Validation loss: 2.0354401667912803

Epoch: 6| Step: 3
Training loss: 0.9053966403007507
Validation loss: 2.0059854785601297

Epoch: 6| Step: 4
Training loss: 0.7953143119812012
Validation loss: 1.9958962599436443

Epoch: 6| Step: 5
Training loss: 0.7135756015777588
Validation loss: 2.03712797164917

Epoch: 6| Step: 6
Training loss: 1.0027339458465576
Validation loss: 2.0309987465540567

Epoch: 6| Step: 7
Training loss: 1.4006948471069336
Validation loss: 2.0332517623901367

Epoch: 6| Step: 8
Training loss: 1.074180245399475
Validation loss: 2.021786868572235

Epoch: 6| Step: 9
Training loss: 0.7838104963302612
Validation loss: 2.019563138484955

Epoch: 6| Step: 10
Training loss: 1.107621431350708
Validation loss: 2.0475184520085654

Epoch: 6| Step: 11
Training loss: 1.626028060913086
Validation loss: 2.0648669799168906

Epoch: 6| Step: 12
Training loss: 2.354020357131958
Validation loss: 2.0347084403038025

Epoch: 6| Step: 13
Training loss: 0.6302378177642822
Validation loss: 2.031483769416809

Epoch: 134| Step: 0
Training loss: 0.7867691516876221
Validation loss: 2.0244730909665427

Epoch: 6| Step: 1
Training loss: 1.6787800788879395
Validation loss: 1.9830153783162434

Epoch: 6| Step: 2
Training loss: 1.3100898265838623
Validation loss: 2.0509040355682373

Epoch: 6| Step: 3
Training loss: 0.9189426898956299
Validation loss: 1.9904809196790059

Epoch: 6| Step: 4
Training loss: 2.055408477783203
Validation loss: 2.0078617533047995

Epoch: 6| Step: 5
Training loss: 1.4710509777069092
Validation loss: 2.0559591253598533

Epoch: 6| Step: 6
Training loss: 1.2222868204116821
Validation loss: 2.0544256965319314

Epoch: 6| Step: 7
Training loss: 1.2290401458740234
Validation loss: 2.037427226702372

Epoch: 6| Step: 8
Training loss: 0.9019411206245422
Validation loss: 2.025899509588877

Epoch: 6| Step: 9
Training loss: 1.3865442276000977
Validation loss: 2.041147987047831

Epoch: 6| Step: 10
Training loss: 0.8768063187599182
Validation loss: 2.0596923828125

Epoch: 6| Step: 11
Training loss: 1.184950590133667
Validation loss: 2.0398805141448975

Epoch: 6| Step: 12
Training loss: 0.7611642479896545
Validation loss: 2.0154732863108316

Epoch: 6| Step: 13
Training loss: 1.60244882106781
Validation loss: 2.0628358721733093

Epoch: 135| Step: 0
Training loss: 1.9533379077911377
Validation loss: 2.0197713375091553

Epoch: 6| Step: 1
Training loss: 1.0086480379104614
Validation loss: 2.029780626296997

Epoch: 6| Step: 2
Training loss: 1.291612148284912
Validation loss: 2.0362556179364524

Epoch: 6| Step: 3
Training loss: 1.9903743267059326
Validation loss: 2.021632492542267

Epoch: 6| Step: 4
Training loss: 1.687150478363037
Validation loss: 2.027642468611399

Epoch: 6| Step: 5
Training loss: 0.9473991394042969
Validation loss: 2.036183714866638

Epoch: 6| Step: 6
Training loss: 1.120146632194519
Validation loss: 2.0132603844006858

Epoch: 6| Step: 7
Training loss: 1.011080265045166
Validation loss: 2.0209367672602334

Epoch: 6| Step: 8
Training loss: 0.9796289205551147
Validation loss: 2.050298273563385

Epoch: 6| Step: 9
Training loss: 1.1632022857666016
Validation loss: 2.0436085065205893

Epoch: 6| Step: 10
Training loss: 0.8666367530822754
Validation loss: 2.049191435178121

Epoch: 6| Step: 11
Training loss: 0.9223292469978333
Validation loss: 2.025180757045746

Epoch: 6| Step: 12
Training loss: 1.1058021783828735
Validation loss: 2.050124923388163

Epoch: 6| Step: 13
Training loss: 0.806797981262207
Validation loss: 2.045607805252075

Epoch: 136| Step: 0
Training loss: 1.325788974761963
Validation loss: 2.02845029036204

Epoch: 6| Step: 1
Training loss: 0.47573092579841614
Validation loss: 2.0410938262939453

Epoch: 6| Step: 2
Training loss: 0.6873284578323364
Validation loss: 2.04040664434433

Epoch: 6| Step: 3
Training loss: 1.0048381090164185
Validation loss: 1.9969448447227478

Epoch: 6| Step: 4
Training loss: 1.625476598739624
Validation loss: 2.0149667660395303

Epoch: 6| Step: 5
Training loss: 1.2230935096740723
Validation loss: 2.017368217309316

Epoch: 6| Step: 6
Training loss: 0.9815933108329773
Validation loss: 2.011866052945455

Epoch: 6| Step: 7
Training loss: 1.3884057998657227
Validation loss: 2.0269556045532227

Epoch: 6| Step: 8
Training loss: 1.1292775869369507
Validation loss: 2.0003163814544678

Epoch: 6| Step: 9
Training loss: 1.1873180866241455
Validation loss: 2.042256494363149

Epoch: 6| Step: 10
Training loss: 1.2832062244415283
Validation loss: 2.071773409843445

Epoch: 6| Step: 11
Training loss: 1.5134711265563965
Validation loss: 2.021023074785868

Epoch: 6| Step: 12
Training loss: 1.4325590133666992
Validation loss: 2.012391686439514

Epoch: 6| Step: 13
Training loss: 0.9027518630027771
Validation loss: 2.013455629348755

Epoch: 137| Step: 0
Training loss: 0.944116473197937
Validation loss: 1.9881194829940796

Epoch: 6| Step: 1
Training loss: 0.9025701880455017
Validation loss: 2.0001564025878906

Epoch: 6| Step: 2
Training loss: 1.7599272727966309
Validation loss: 1.9976338148117065

Epoch: 6| Step: 3
Training loss: 0.9112621545791626
Validation loss: 2.0120579401652017

Epoch: 6| Step: 4
Training loss: 1.2659943103790283
Validation loss: 2.022511978944143

Epoch: 6| Step: 5
Training loss: 1.4240610599517822
Validation loss: 2.0358433723449707

Epoch: 6| Step: 6
Training loss: 0.5739433169364929
Validation loss: 2.026799519856771

Epoch: 6| Step: 7
Training loss: 1.506812572479248
Validation loss: 2.004045009613037

Epoch: 6| Step: 8
Training loss: 1.203505277633667
Validation loss: 2.0204199949900308

Epoch: 6| Step: 9
Training loss: 1.2681300640106201
Validation loss: 2.032950977484385

Epoch: 6| Step: 10
Training loss: 1.3095641136169434
Validation loss: 1.9919562141100566

Epoch: 6| Step: 11
Training loss: 1.3035560846328735
Validation loss: 2.0180976192156472

Epoch: 6| Step: 12
Training loss: 1.168006181716919
Validation loss: 2.0268571376800537

Epoch: 6| Step: 13
Training loss: 0.9834309816360474
Validation loss: 2.0044621427853904

Epoch: 138| Step: 0
Training loss: 0.7829012870788574
Validation loss: 2.03337828318278

Epoch: 6| Step: 1
Training loss: 0.5934956073760986
Validation loss: 1.984390377998352

Epoch: 6| Step: 2
Training loss: 1.0485587120056152
Validation loss: 1.985952377319336

Epoch: 6| Step: 3
Training loss: 1.4127272367477417
Validation loss: 2.0067660808563232

Epoch: 6| Step: 4
Training loss: 1.6506136655807495
Validation loss: 2.034693797429403

Epoch: 6| Step: 5
Training loss: 1.1468089818954468
Validation loss: 2.0163464744885764

Epoch: 6| Step: 6
Training loss: 0.9352003335952759
Validation loss: 1.9926772316296895

Epoch: 6| Step: 7
Training loss: 0.6999329924583435
Validation loss: 2.0161839922269187

Epoch: 6| Step: 8
Training loss: 1.1871743202209473
Validation loss: 2.00471293926239

Epoch: 6| Step: 9
Training loss: 1.6294324398040771
Validation loss: 2.008886476357778

Epoch: 6| Step: 10
Training loss: 1.605790615081787
Validation loss: 1.9940430323282878

Epoch: 6| Step: 11
Training loss: 1.0331294536590576
Validation loss: 2.0328715443611145

Epoch: 6| Step: 12
Training loss: 0.7791576981544495
Validation loss: 2.0443578362464905

Epoch: 6| Step: 13
Training loss: 1.6798648834228516
Validation loss: 2.003684322039286

Epoch: 139| Step: 0
Training loss: 1.1962451934814453
Validation loss: 2.028788904349009

Epoch: 6| Step: 1
Training loss: 0.8818246126174927
Validation loss: 2.0225176215171814

Epoch: 6| Step: 2
Training loss: 1.2624282836914062
Validation loss: 2.0146888891855874

Epoch: 6| Step: 3
Training loss: 0.8334125280380249
Validation loss: 2.023454785346985

Epoch: 6| Step: 4
Training loss: 1.195137858390808
Validation loss: 1.9981653292973836

Epoch: 6| Step: 5
Training loss: 1.1885077953338623
Validation loss: 2.0228756070137024

Epoch: 6| Step: 6
Training loss: 0.7002081871032715
Validation loss: 2.0299646059672036

Epoch: 6| Step: 7
Training loss: 1.480165719985962
Validation loss: 2.066088696320852

Epoch: 6| Step: 8
Training loss: 1.2510180473327637
Validation loss: 2.0607617696126304

Epoch: 6| Step: 9
Training loss: 1.0513596534729004
Validation loss: 2.0192535718282065

Epoch: 6| Step: 10
Training loss: 1.2246443033218384
Validation loss: 2.0260061621665955

Epoch: 6| Step: 11
Training loss: 1.6455492973327637
Validation loss: 1.995098849137624

Epoch: 6| Step: 12
Training loss: 1.2985371351242065
Validation loss: 2.0389470855394998

Epoch: 6| Step: 13
Training loss: 1.2240746021270752
Validation loss: 2.0201220512390137

Epoch: 140| Step: 0
Training loss: 1.088301420211792
Validation loss: 2.021310826142629

Epoch: 6| Step: 1
Training loss: 1.3301200866699219
Validation loss: 2.056027968724569

Epoch: 6| Step: 2
Training loss: 0.7357209920883179
Validation loss: 2.0031820138295493

Epoch: 6| Step: 3
Training loss: 1.1246373653411865
Validation loss: 2.0310176809628806

Epoch: 6| Step: 4
Training loss: 0.6785874366760254
Validation loss: 2.0772489309310913

Epoch: 6| Step: 5
Training loss: 0.9420894384384155
Validation loss: 2.0311147371927896

Epoch: 6| Step: 6
Training loss: 1.4248082637786865
Validation loss: 2.0344579219818115

Epoch: 6| Step: 7
Training loss: 1.4150704145431519
Validation loss: 2.0419647296269736

Epoch: 6| Step: 8
Training loss: 1.3783751726150513
Validation loss: 2.0103115836779275

Epoch: 6| Step: 9
Training loss: 1.4298131465911865
Validation loss: 2.044942776362101

Epoch: 6| Step: 10
Training loss: 0.7113991379737854
Validation loss: 2.033044775327047

Epoch: 6| Step: 11
Training loss: 1.0322428941726685
Validation loss: 1.995621959368388

Epoch: 6| Step: 12
Training loss: 1.2873929738998413
Validation loss: 2.0461275577545166

Epoch: 6| Step: 13
Training loss: 1.5628560781478882
Validation loss: 2.0714929501215615

Epoch: 141| Step: 0
Training loss: 1.0540688037872314
Validation loss: 2.036067763964335

Epoch: 6| Step: 1
Training loss: 1.036123275756836
Validation loss: 2.01123708486557

Epoch: 6| Step: 2
Training loss: 0.9331122636795044
Validation loss: 1.9961883028348286

Epoch: 6| Step: 3
Training loss: 0.762110710144043
Validation loss: 2.0185630718866983

Epoch: 6| Step: 4
Training loss: 1.3939974308013916
Validation loss: 2.016469935576121

Epoch: 6| Step: 5
Training loss: 1.0928294658660889
Validation loss: 2.005685567855835

Epoch: 6| Step: 6
Training loss: 1.297485589981079
Validation loss: 2.0243229468663535

Epoch: 6| Step: 7
Training loss: 0.8328837156295776
Validation loss: 2.0547887881596885

Epoch: 6| Step: 8
Training loss: 1.733018159866333
Validation loss: 2.0324496825536094

Epoch: 6| Step: 9
Training loss: 0.8042758107185364
Validation loss: 2.0077394247055054

Epoch: 6| Step: 10
Training loss: 1.364192247390747
Validation loss: 1.9890803694725037

Epoch: 6| Step: 11
Training loss: 0.9814093112945557
Validation loss: 2.0062867403030396

Epoch: 6| Step: 12
Training loss: 1.029790997505188
Validation loss: 2.0153358777364097

Epoch: 6| Step: 13
Training loss: 1.7017712593078613
Validation loss: 2.00419020652771

Epoch: 142| Step: 0
Training loss: 0.8505085706710815
Validation loss: 1.999537467956543

Epoch: 6| Step: 1
Training loss: 0.6652299761772156
Validation loss: 2.0401020844777427

Epoch: 6| Step: 2
Training loss: 0.4930045008659363
Validation loss: 2.0074696143468223

Epoch: 6| Step: 3
Training loss: 0.9757964611053467
Validation loss: 2.0005624492963157

Epoch: 6| Step: 4
Training loss: 0.9328520894050598
Validation loss: 2.034851590792338

Epoch: 6| Step: 5
Training loss: 1.2137209177017212
Validation loss: 1.9744367202123005

Epoch: 6| Step: 6
Training loss: 2.1445744037628174
Validation loss: 2.028413971265157

Epoch: 6| Step: 7
Training loss: 1.1278254985809326
Validation loss: 1.981733779112498

Epoch: 6| Step: 8
Training loss: 0.826525092124939
Validation loss: 1.9750605821609497

Epoch: 6| Step: 9
Training loss: 1.1055288314819336
Validation loss: 1.9957051475842793

Epoch: 6| Step: 10
Training loss: 0.9649920463562012
Validation loss: 1.991480032602946

Epoch: 6| Step: 11
Training loss: 1.5984594821929932
Validation loss: 1.9973612229029338

Epoch: 6| Step: 12
Training loss: 1.7039510011672974
Validation loss: 2.008972922960917

Epoch: 6| Step: 13
Training loss: 0.9121097922325134
Validation loss: 2.0158774058024087

Epoch: 143| Step: 0
Training loss: 1.9843645095825195
Validation loss: 1.984052876631419

Epoch: 6| Step: 1
Training loss: 1.1040387153625488
Validation loss: 1.9834921558698018

Epoch: 6| Step: 2
Training loss: 1.0556020736694336
Validation loss: 1.9824459354082744

Epoch: 6| Step: 3
Training loss: 0.6846627593040466
Validation loss: 1.9895877440770466

Epoch: 6| Step: 4
Training loss: 1.1994714736938477
Validation loss: 1.9833104610443115

Epoch: 6| Step: 5
Training loss: 1.193935751914978
Validation loss: 2.006617764631907

Epoch: 6| Step: 6
Training loss: 0.8018084764480591
Validation loss: 1.9776247143745422

Epoch: 6| Step: 7
Training loss: 1.4995474815368652
Validation loss: 1.9972705443700154

Epoch: 6| Step: 8
Training loss: 0.9623453617095947
Validation loss: 1.9750268856684368

Epoch: 6| Step: 9
Training loss: 1.2596784830093384
Validation loss: 1.990135669708252

Epoch: 6| Step: 10
Training loss: 0.7443653345108032
Validation loss: 1.9432014624277751

Epoch: 6| Step: 11
Training loss: 1.7721588611602783
Validation loss: 2.036587675412496

Epoch: 6| Step: 12
Training loss: 0.7470908761024475
Validation loss: 2.001241902510325

Epoch: 6| Step: 13
Training loss: 0.6426397562026978
Validation loss: 2.008518318335215

Epoch: 144| Step: 0
Training loss: 1.0335643291473389
Validation loss: 1.9940467675526936

Epoch: 6| Step: 1
Training loss: 1.0857796669006348
Validation loss: 2.014591415723165

Epoch: 6| Step: 2
Training loss: 0.7877260446548462
Validation loss: 2.0000345706939697

Epoch: 6| Step: 3
Training loss: 1.0839216709136963
Validation loss: 1.989270289738973

Epoch: 6| Step: 4
Training loss: 0.9038382768630981
Validation loss: 1.9800316294034321

Epoch: 6| Step: 5
Training loss: 1.0489211082458496
Validation loss: 2.0152531266212463

Epoch: 6| Step: 6
Training loss: 1.1499853134155273
Validation loss: 1.9811549584070842

Epoch: 6| Step: 7
Training loss: 1.1536474227905273
Validation loss: 2.0377294222513833

Epoch: 6| Step: 8
Training loss: 1.0646328926086426
Validation loss: 2.0196715195973716

Epoch: 6| Step: 9
Training loss: 1.3732523918151855
Validation loss: 2.019444525241852

Epoch: 6| Step: 10
Training loss: 1.0467134714126587
Validation loss: 1.974547843138377

Epoch: 6| Step: 11
Training loss: 0.9491151571273804
Validation loss: 2.0424768129984536

Epoch: 6| Step: 12
Training loss: 1.4934221506118774
Validation loss: 2.028484523296356

Epoch: 6| Step: 13
Training loss: 1.2405099868774414
Validation loss: 1.9914506077766418

Epoch: 145| Step: 0
Training loss: 1.0656232833862305
Validation loss: 2.0323880314826965

Epoch: 6| Step: 1
Training loss: 1.25242280960083
Validation loss: 1.9962982932726543

Epoch: 6| Step: 2
Training loss: 1.160210132598877
Validation loss: 2.019790768623352

Epoch: 6| Step: 3
Training loss: 0.4011542797088623
Validation loss: 1.9847910801569622

Epoch: 6| Step: 4
Training loss: 0.9452500939369202
Validation loss: 2.050387183825175

Epoch: 6| Step: 5
Training loss: 1.7249565124511719
Validation loss: 2.0065221389134726

Epoch: 6| Step: 6
Training loss: 0.8894826173782349
Validation loss: 2.016331513722738

Epoch: 6| Step: 7
Training loss: 1.0990557670593262
Validation loss: 2.004460791746775

Epoch: 6| Step: 8
Training loss: 1.0983539819717407
Validation loss: 2.0076716939608255

Epoch: 6| Step: 9
Training loss: 0.8387889862060547
Validation loss: 2.018224815527598

Epoch: 6| Step: 10
Training loss: 1.488440990447998
Validation loss: 2.0138791600863137

Epoch: 6| Step: 11
Training loss: 1.1952886581420898
Validation loss: 2.0324955383936563

Epoch: 6| Step: 12
Training loss: 1.0540497303009033
Validation loss: 1.9718663096427917

Epoch: 6| Step: 13
Training loss: 0.9897681474685669
Validation loss: 1.9982956449190776

Epoch: 146| Step: 0
Training loss: 1.8547251224517822
Validation loss: 2.0133940974871316

Epoch: 6| Step: 1
Training loss: 0.9454621076583862
Validation loss: 1.9899994134902954

Epoch: 6| Step: 2
Training loss: 1.2421066761016846
Validation loss: 2.0065059860547385

Epoch: 6| Step: 3
Training loss: 0.8564372062683105
Validation loss: 2.0077067414919534

Epoch: 6| Step: 4
Training loss: 1.4723881483078003
Validation loss: 2.0267441272735596

Epoch: 6| Step: 5
Training loss: 0.9921380281448364
Validation loss: 1.9822997252146404

Epoch: 6| Step: 6
Training loss: 1.050686240196228
Validation loss: 2.013392368952433

Epoch: 6| Step: 7
Training loss: 0.9355785250663757
Validation loss: 2.0198325912157693

Epoch: 6| Step: 8
Training loss: 0.9043774604797363
Validation loss: 1.9920969406763713

Epoch: 6| Step: 9
Training loss: 1.1530287265777588
Validation loss: 1.9939878185590107

Epoch: 6| Step: 10
Training loss: 1.085314393043518
Validation loss: 1.9747073650360107

Epoch: 6| Step: 11
Training loss: 0.8455604314804077
Validation loss: 1.9723581671714783

Epoch: 6| Step: 12
Training loss: 1.1454060077667236
Validation loss: 2.0174771745999656

Epoch: 6| Step: 13
Training loss: 0.9592891931533813
Validation loss: 2.0343037645022073

Epoch: 147| Step: 0
Training loss: 0.8093303442001343
Validation loss: 1.98600439230601

Epoch: 6| Step: 1
Training loss: 1.1770856380462646
Validation loss: 1.9961232940355937

Epoch: 6| Step: 2
Training loss: 0.9997372627258301
Validation loss: 2.0034675002098083

Epoch: 6| Step: 3
Training loss: 1.2181806564331055
Validation loss: 1.966355303923289

Epoch: 6| Step: 4
Training loss: 1.1746653318405151
Validation loss: 1.9996440211931865

Epoch: 6| Step: 5
Training loss: 1.156604290008545
Validation loss: 1.9824078281720479

Epoch: 6| Step: 6
Training loss: 0.8824321031570435
Validation loss: 1.99257888396581

Epoch: 6| Step: 7
Training loss: 1.5892448425292969
Validation loss: 2.011534492174784

Epoch: 6| Step: 8
Training loss: 1.1240365505218506
Validation loss: 2.0184335311253867

Epoch: 6| Step: 9
Training loss: 1.2043087482452393
Validation loss: 2.053902010122935

Epoch: 6| Step: 10
Training loss: 0.5703324675559998
Validation loss: 2.011819918950399

Epoch: 6| Step: 11
Training loss: 1.266064167022705
Validation loss: 1.9730401436487834

Epoch: 6| Step: 12
Training loss: 0.8579437732696533
Validation loss: 1.9638744195302327

Epoch: 6| Step: 13
Training loss: 1.130813717842102
Validation loss: 2.0150345961252847

Epoch: 148| Step: 0
Training loss: 0.7119801640510559
Validation loss: 2.014460305372874

Epoch: 6| Step: 1
Training loss: 1.0797830820083618
Validation loss: 1.9956423441569011

Epoch: 6| Step: 2
Training loss: 0.871381402015686
Validation loss: 2.0116084218025208

Epoch: 6| Step: 3
Training loss: 1.0572471618652344
Validation loss: 1.981457531452179

Epoch: 6| Step: 4
Training loss: 0.8584858179092407
Validation loss: 1.9704699913660686

Epoch: 6| Step: 5
Training loss: 1.0852404832839966
Validation loss: 1.9722238977750142

Epoch: 6| Step: 6
Training loss: 1.1446064710617065
Validation loss: 1.946227212746938

Epoch: 6| Step: 7
Training loss: 1.0867509841918945
Validation loss: 2.006076773007711

Epoch: 6| Step: 8
Training loss: 1.0389962196350098
Validation loss: 1.9952975312868755

Epoch: 6| Step: 9
Training loss: 1.4433045387268066
Validation loss: 1.999781310558319

Epoch: 6| Step: 10
Training loss: 1.188294529914856
Validation loss: 2.0069100658098855

Epoch: 6| Step: 11
Training loss: 1.581248164176941
Validation loss: 1.9926952521006267

Epoch: 6| Step: 12
Training loss: 0.8412767648696899
Validation loss: 2.0165257851282754

Epoch: 6| Step: 13
Training loss: 0.9418566823005676
Validation loss: 1.99314683675766

Epoch: 149| Step: 0
Training loss: 1.2095698118209839
Validation loss: 1.9843931794166565

Epoch: 6| Step: 1
Training loss: 0.8530653715133667
Validation loss: 2.0241264700889587

Epoch: 6| Step: 2
Training loss: 0.7737188935279846
Validation loss: 2.0237488746643066

Epoch: 6| Step: 3
Training loss: 0.9577137231826782
Validation loss: 2.0230729579925537

Epoch: 6| Step: 4
Training loss: 0.8478147387504578
Validation loss: 1.9853087266286213

Epoch: 6| Step: 5
Training loss: 0.9294977784156799
Validation loss: 1.9981910785039265

Epoch: 6| Step: 6
Training loss: 1.8689696788787842
Validation loss: 2.0530325174331665

Epoch: 6| Step: 7
Training loss: 0.8596950769424438
Validation loss: 1.9975236058235168

Epoch: 6| Step: 8
Training loss: 1.1641302108764648
Validation loss: 2.0386941035588584

Epoch: 6| Step: 9
Training loss: 1.1631805896759033
Validation loss: 2.0484694639841714

Epoch: 6| Step: 10
Training loss: 1.266832947731018
Validation loss: 2.0369818607966104

Epoch: 6| Step: 11
Training loss: 1.4343289136886597
Validation loss: 2.0064748724301658

Epoch: 6| Step: 12
Training loss: 1.112865924835205
Validation loss: 2.0031582713127136

Epoch: 6| Step: 13
Training loss: 1.1368534564971924
Validation loss: 2.006811738014221

Epoch: 150| Step: 0
Training loss: 0.8118047714233398
Validation loss: 2.019551952679952

Epoch: 6| Step: 1
Training loss: 1.4576821327209473
Validation loss: 2.0085530877113342

Epoch: 6| Step: 2
Training loss: 0.8770291209220886
Validation loss: 1.9942978819211323

Epoch: 6| Step: 3
Training loss: 0.9516327381134033
Validation loss: 2.04632705450058

Epoch: 6| Step: 4
Training loss: 1.108104944229126
Validation loss: 1.9985321164131165

Epoch: 6| Step: 5
Training loss: 1.1381347179412842
Validation loss: 2.000231385231018

Epoch: 6| Step: 6
Training loss: 0.40495622158050537
Validation loss: 1.977211356163025

Epoch: 6| Step: 7
Training loss: 1.1371335983276367
Validation loss: 2.0451837182044983

Epoch: 6| Step: 8
Training loss: 0.8565577268600464
Validation loss: 2.0165045460065207

Epoch: 6| Step: 9
Training loss: 1.4038194417953491
Validation loss: 1.969259222348531

Epoch: 6| Step: 10
Training loss: 0.9431849122047424
Validation loss: 1.994009017944336

Epoch: 6| Step: 11
Training loss: 1.337314486503601
Validation loss: 1.9726823170979817

Epoch: 6| Step: 12
Training loss: 1.2427589893341064
Validation loss: 1.9942584832509358

Epoch: 6| Step: 13
Training loss: 1.029261827468872
Validation loss: 2.007653216520945

Epoch: 151| Step: 0
Training loss: 0.7322057485580444
Validation loss: 1.9901608228683472

Epoch: 6| Step: 1
Training loss: 0.9741101264953613
Validation loss: 2.00968070824941

Epoch: 6| Step: 2
Training loss: 0.8823590278625488
Validation loss: 2.0270959734916687

Epoch: 6| Step: 3
Training loss: 1.505185842514038
Validation loss: 1.987200806538264

Epoch: 6| Step: 4
Training loss: 1.0409941673278809
Validation loss: 1.9680761694908142

Epoch: 6| Step: 5
Training loss: 1.058361530303955
Validation loss: 1.986273467540741

Epoch: 6| Step: 6
Training loss: 0.8709516525268555
Validation loss: 2.016316811243693

Epoch: 6| Step: 7
Training loss: 0.9890166521072388
Validation loss: 2.0100603898366294

Epoch: 6| Step: 8
Training loss: 0.6259646415710449
Validation loss: 2.002068042755127

Epoch: 6| Step: 9
Training loss: 1.2968920469284058
Validation loss: 1.9930886427561443

Epoch: 6| Step: 10
Training loss: 0.7606857419013977
Validation loss: 2.0430189967155457

Epoch: 6| Step: 11
Training loss: 1.07245671749115
Validation loss: 2.0155447522799173

Epoch: 6| Step: 12
Training loss: 1.3260703086853027
Validation loss: 2.0011251966158548

Epoch: 6| Step: 13
Training loss: 1.5846327543258667
Validation loss: 2.0471267302831015

Epoch: 152| Step: 0
Training loss: 0.5361450910568237
Validation loss: 2.0601168274879456

Epoch: 6| Step: 1
Training loss: 0.9465696215629578
Validation loss: 2.009860018889109

Epoch: 6| Step: 2
Training loss: 0.5152022242546082
Validation loss: 1.9829731782277424

Epoch: 6| Step: 3
Training loss: 1.1145949363708496
Validation loss: 2.023863693078359

Epoch: 6| Step: 4
Training loss: 0.8353381752967834
Validation loss: 2.0461310744285583

Epoch: 6| Step: 5
Training loss: 1.02335524559021
Validation loss: 1.9987264275550842

Epoch: 6| Step: 6
Training loss: 0.7218486070632935
Validation loss: 1.9834546049435933

Epoch: 6| Step: 7
Training loss: 1.794377326965332
Validation loss: 1.9887531399726868

Epoch: 6| Step: 8
Training loss: 0.8367815017700195
Validation loss: 1.9960917234420776

Epoch: 6| Step: 9
Training loss: 1.7098784446716309
Validation loss: 1.9877572456995647

Epoch: 6| Step: 10
Training loss: 0.8011136651039124
Validation loss: 2.0163872241973877

Epoch: 6| Step: 11
Training loss: 1.0221219062805176
Validation loss: 1.9998150269190471

Epoch: 6| Step: 12
Training loss: 1.01753568649292
Validation loss: 2.0220839381217957

Epoch: 6| Step: 13
Training loss: 1.403150200843811
Validation loss: 2.0196109612782798

Epoch: 153| Step: 0
Training loss: 0.6676070690155029
Validation loss: 1.997723678747813

Epoch: 6| Step: 1
Training loss: 1.1192741394042969
Validation loss: 2.0231708685557046

Epoch: 6| Step: 2
Training loss: 0.46477317810058594
Validation loss: 2.023120919863383

Epoch: 6| Step: 3
Training loss: 0.7821407914161682
Validation loss: 2.0182119011878967

Epoch: 6| Step: 4
Training loss: 0.9277086853981018
Validation loss: 2.0271636247634888

Epoch: 6| Step: 5
Training loss: 1.43158757686615
Validation loss: 1.9916094342867534

Epoch: 6| Step: 6
Training loss: 1.03525710105896
Validation loss: 2.0383559664090476

Epoch: 6| Step: 7
Training loss: 1.3190679550170898
Validation loss: 1.9842386841773987

Epoch: 6| Step: 8
Training loss: 1.0132648944854736
Validation loss: 2.020671864350637

Epoch: 6| Step: 9
Training loss: 1.1641405820846558
Validation loss: 1.9980400403340657

Epoch: 6| Step: 10
Training loss: 0.9811992645263672
Validation loss: 2.026725471019745

Epoch: 6| Step: 11
Training loss: 1.0197293758392334
Validation loss: 1.967958152294159

Epoch: 6| Step: 12
Training loss: 1.3824286460876465
Validation loss: 2.007435659567515

Epoch: 6| Step: 13
Training loss: 0.9530630707740784
Validation loss: 2.0036881367365518

Epoch: 154| Step: 0
Training loss: 1.1062242984771729
Validation loss: 2.030062754948934

Epoch: 6| Step: 1
Training loss: 1.1796208620071411
Validation loss: 2.0711548725763955

Epoch: 6| Step: 2
Training loss: 0.8128356337547302
Validation loss: 2.010657529036204

Epoch: 6| Step: 3
Training loss: 0.6309630870819092
Validation loss: 2.0053622325261435

Epoch: 6| Step: 4
Training loss: 1.230353593826294
Validation loss: 1.9448063174883525

Epoch: 6| Step: 5
Training loss: 1.1343309879302979
Validation loss: 1.992615779240926

Epoch: 6| Step: 6
Training loss: 1.69346284866333
Validation loss: 2.019189715385437

Epoch: 6| Step: 7
Training loss: 0.842796802520752
Validation loss: 2.0024927854537964

Epoch: 6| Step: 8
Training loss: 1.5540375709533691
Validation loss: 2.0246782501538596

Epoch: 6| Step: 9
Training loss: 0.864719569683075
Validation loss: 2.0340771476427713

Epoch: 6| Step: 10
Training loss: 0.5167044401168823
Validation loss: 1.9956190983454387

Epoch: 6| Step: 11
Training loss: 1.3707554340362549
Validation loss: 2.001284102598826

Epoch: 6| Step: 12
Training loss: 0.6203979253768921
Validation loss: 1.9985010226567586

Epoch: 6| Step: 13
Training loss: 0.8361144065856934
Validation loss: 1.953033685684204

Epoch: 155| Step: 0
Training loss: 1.130293369293213
Validation loss: 2.00271737575531

Epoch: 6| Step: 1
Training loss: 1.1855815649032593
Validation loss: 1.990040361881256

Epoch: 6| Step: 2
Training loss: 1.1910197734832764
Validation loss: 2.0275245308876038

Epoch: 6| Step: 3
Training loss: 0.8051548004150391
Validation loss: 2.0036346117655435

Epoch: 6| Step: 4
Training loss: 1.5887421369552612
Validation loss: 2.0037973721822104

Epoch: 6| Step: 5
Training loss: 0.9727417826652527
Validation loss: 1.9341002702713013

Epoch: 6| Step: 6
Training loss: 0.8981198072433472
Validation loss: 1.9637562036514282

Epoch: 6| Step: 7
Training loss: 0.6712239980697632
Validation loss: 1.995545248190562

Epoch: 6| Step: 8
Training loss: 1.5690186023712158
Validation loss: 1.9790911277135212

Epoch: 6| Step: 9
Training loss: 1.1058080196380615
Validation loss: 1.985968808333079

Epoch: 6| Step: 10
Training loss: 0.5984958410263062
Validation loss: 1.9474331537882488

Epoch: 6| Step: 11
Training loss: 1.336031198501587
Validation loss: 1.9779637257258098

Epoch: 6| Step: 12
Training loss: 0.9643059968948364
Validation loss: 1.986281971136729

Epoch: 6| Step: 13
Training loss: 0.7404149770736694
Validation loss: 1.980312963326772

Epoch: 156| Step: 0
Training loss: 1.0740056037902832
Validation loss: 2.000418245792389

Epoch: 6| Step: 1
Training loss: 0.5200321674346924
Validation loss: 2.0115372141202292

Epoch: 6| Step: 2
Training loss: 1.219719409942627
Validation loss: 1.9727341930071514

Epoch: 6| Step: 3
Training loss: 1.3106434345245361
Validation loss: 2.015892267227173

Epoch: 6| Step: 4
Training loss: 1.591301679611206
Validation loss: 1.996726115544637

Epoch: 6| Step: 5
Training loss: 1.378868579864502
Validation loss: 2.0188823541005454

Epoch: 6| Step: 6
Training loss: 0.9360135793685913
Validation loss: 2.022180457909902

Epoch: 6| Step: 7
Training loss: 1.0564987659454346
Validation loss: 2.01734858751297

Epoch: 6| Step: 8
Training loss: 0.7746817469596863
Validation loss: 2.0083788633346558

Epoch: 6| Step: 9
Training loss: 0.6560014486312866
Validation loss: 2.0040265719095864

Epoch: 6| Step: 10
Training loss: 0.6659791469573975
Validation loss: 1.9798156023025513

Epoch: 6| Step: 11
Training loss: 0.803847074508667
Validation loss: 1.975544532140096

Epoch: 6| Step: 12
Training loss: 1.0244187116622925
Validation loss: 1.9663034478823345

Epoch: 6| Step: 13
Training loss: 1.167797327041626
Validation loss: 1.9811577200889587

Epoch: 157| Step: 0
Training loss: 1.1227407455444336
Validation loss: 1.9788953860600789

Epoch: 6| Step: 1
Training loss: 1.425680160522461
Validation loss: 1.9680522084236145

Epoch: 6| Step: 2
Training loss: 1.1327590942382812
Validation loss: 1.9929166038831074

Epoch: 6| Step: 3
Training loss: 0.7374668121337891
Validation loss: 1.9766792853673298

Epoch: 6| Step: 4
Training loss: 1.2254526615142822
Validation loss: 1.9916879733403523

Epoch: 6| Step: 5
Training loss: 1.0299108028411865
Validation loss: 2.0031674901644387

Epoch: 6| Step: 6
Training loss: 0.880894660949707
Validation loss: 1.9915056228637695

Epoch: 6| Step: 7
Training loss: 0.7011823058128357
Validation loss: 2.017403264840444

Epoch: 6| Step: 8
Training loss: 1.0975373983383179
Validation loss: 1.9734616080919902

Epoch: 6| Step: 9
Training loss: 0.949127197265625
Validation loss: 1.998149573802948

Epoch: 6| Step: 10
Training loss: 0.9535471796989441
Validation loss: 2.023452858130137

Epoch: 6| Step: 11
Training loss: 0.7582060098648071
Validation loss: 2.0016371409098306

Epoch: 6| Step: 12
Training loss: 1.0204675197601318
Validation loss: 1.9740756154060364

Epoch: 6| Step: 13
Training loss: 0.7535847425460815
Validation loss: 1.9839645624160767

Epoch: 158| Step: 0
Training loss: 0.7473717927932739
Validation loss: 1.9512056907018025

Epoch: 6| Step: 1
Training loss: 1.1584670543670654
Validation loss: 1.9769189953804016

Epoch: 6| Step: 2
Training loss: 0.9815135598182678
Validation loss: 1.997547169526418

Epoch: 6| Step: 3
Training loss: 1.0050301551818848
Validation loss: 1.9523137211799622

Epoch: 6| Step: 4
Training loss: 0.8928405046463013
Validation loss: 1.969889481862386

Epoch: 6| Step: 5
Training loss: 1.00948965549469
Validation loss: 2.0337968468666077

Epoch: 6| Step: 6
Training loss: 1.606801986694336
Validation loss: 2.0127733747164407

Epoch: 6| Step: 7
Training loss: 1.269066333770752
Validation loss: 1.9554294347763062

Epoch: 6| Step: 8
Training loss: 0.953420877456665
Validation loss: 1.9811895688374836

Epoch: 6| Step: 9
Training loss: 1.0604064464569092
Validation loss: 1.9650291204452515

Epoch: 6| Step: 10
Training loss: 1.0541340112686157
Validation loss: 1.9765479564666748

Epoch: 6| Step: 11
Training loss: 0.5517178177833557
Validation loss: 1.9924833178520203

Epoch: 6| Step: 12
Training loss: 0.7318059206008911
Validation loss: 2.0084341565767923

Epoch: 6| Step: 13
Training loss: 0.9685230255126953
Validation loss: 1.9997708996136982

Epoch: 159| Step: 0
Training loss: 0.592582643032074
Validation loss: 1.9684558908144634

Epoch: 6| Step: 1
Training loss: 1.3417083024978638
Validation loss: 2.003967543443044

Epoch: 6| Step: 2
Training loss: 0.6805640459060669
Validation loss: 1.9876042405764263

Epoch: 6| Step: 3
Training loss: 1.5131723880767822
Validation loss: 1.9968779683113098

Epoch: 6| Step: 4
Training loss: 0.7650088667869568
Validation loss: 1.9884623885154724

Epoch: 6| Step: 5
Training loss: 0.7622429132461548
Validation loss: 2.022682229677836

Epoch: 6| Step: 6
Training loss: 0.9943057298660278
Validation loss: 2.0109783411026

Epoch: 6| Step: 7
Training loss: 0.61830073595047
Validation loss: 2.005233665307363

Epoch: 6| Step: 8
Training loss: 0.9722126722335815
Validation loss: 1.9699625968933105

Epoch: 6| Step: 9
Training loss: 1.3214547634124756
Validation loss: 1.9855610728263855

Epoch: 6| Step: 10
Training loss: 0.9691279530525208
Validation loss: 1.994464675585429

Epoch: 6| Step: 11
Training loss: 1.034864902496338
Validation loss: 2.0052588979403176

Epoch: 6| Step: 12
Training loss: 0.84168541431427
Validation loss: 2.0110100706418357

Epoch: 6| Step: 13
Training loss: 1.1280241012573242
Validation loss: 2.021223862965902

Epoch: 160| Step: 0
Training loss: 0.6960798501968384
Validation loss: 1.9699416359265645

Epoch: 6| Step: 1
Training loss: 1.1849547624588013
Validation loss: 2.017003357410431

Epoch: 6| Step: 2
Training loss: 1.1532037258148193
Validation loss: 1.9996294180552165

Epoch: 6| Step: 3
Training loss: 0.7429414987564087
Validation loss: 2.0007562041282654

Epoch: 6| Step: 4
Training loss: 1.2206838130950928
Validation loss: 1.9742374022801716

Epoch: 6| Step: 5
Training loss: 0.97551029920578
Validation loss: 2.0088008443514505

Epoch: 6| Step: 6
Training loss: 1.0280482769012451
Validation loss: 2.038192629814148

Epoch: 6| Step: 7
Training loss: 0.5024062991142273
Validation loss: 1.9694237907727559

Epoch: 6| Step: 8
Training loss: 0.8595101237297058
Validation loss: 1.979235291481018

Epoch: 6| Step: 9
Training loss: 0.8316718935966492
Validation loss: 1.9926604231198628

Epoch: 6| Step: 10
Training loss: 1.1148933172225952
Validation loss: 1.949157456556956

Epoch: 6| Step: 11
Training loss: 0.8570349216461182
Validation loss: 1.9878387848536174

Epoch: 6| Step: 12
Training loss: 1.268359899520874
Validation loss: 1.9706084728240967

Epoch: 6| Step: 13
Training loss: 1.0747628211975098
Validation loss: 1.9560311237970989

Epoch: 161| Step: 0
Training loss: 1.414351224899292
Validation loss: 1.9935877919197083

Epoch: 6| Step: 1
Training loss: 0.9010156393051147
Validation loss: 2.0289718906084695

Epoch: 6| Step: 2
Training loss: 1.1333212852478027
Validation loss: 1.9838085373242695

Epoch: 6| Step: 3
Training loss: 0.9778155088424683
Validation loss: 1.9499235550562541

Epoch: 6| Step: 4
Training loss: 1.5791138410568237
Validation loss: 1.9876861770947774

Epoch: 6| Step: 5
Training loss: 0.7698174715042114
Validation loss: 2.005264242490133

Epoch: 6| Step: 6
Training loss: 0.5799998641014099
Validation loss: 1.992111047108968

Epoch: 6| Step: 7
Training loss: 0.9358681440353394
Validation loss: 1.9727899034818013

Epoch: 6| Step: 8
Training loss: 0.9729470014572144
Validation loss: 1.9659810066223145

Epoch: 6| Step: 9
Training loss: 1.2017066478729248
Validation loss: 1.975487768650055

Epoch: 6| Step: 10
Training loss: 0.6502335667610168
Validation loss: 2.0063453912734985

Epoch: 6| Step: 11
Training loss: 0.5766981244087219
Validation loss: 2.0041804711023965

Epoch: 6| Step: 12
Training loss: 0.6252326965332031
Validation loss: 1.9909696578979492

Epoch: 6| Step: 13
Training loss: 0.960012674331665
Validation loss: 1.97977081934611

Epoch: 162| Step: 0
Training loss: 1.099865198135376
Validation loss: 2.028859317302704

Epoch: 6| Step: 1
Training loss: 0.7347940802574158
Validation loss: 2.015352805455526

Epoch: 6| Step: 2
Training loss: 0.6559666395187378
Validation loss: 1.9970019658406575

Epoch: 6| Step: 3
Training loss: 0.7480766177177429
Validation loss: 2.0100285609563193

Epoch: 6| Step: 4
Training loss: 0.663707435131073
Validation loss: 2.01681782801946

Epoch: 6| Step: 5
Training loss: 0.8929218053817749
Validation loss: 2.032597303390503

Epoch: 6| Step: 6
Training loss: 1.70538330078125
Validation loss: 2.0149145325024924

Epoch: 6| Step: 7
Training loss: 0.9968763589859009
Validation loss: 2.0372034509976706

Epoch: 6| Step: 8
Training loss: 0.9306004047393799
Validation loss: 2.0212151408195496

Epoch: 6| Step: 9
Training loss: 1.0248737335205078
Validation loss: 1.9717116951942444

Epoch: 6| Step: 10
Training loss: 0.9328429102897644
Validation loss: 1.9788711269696553

Epoch: 6| Step: 11
Training loss: 0.816677451133728
Validation loss: 1.981659432252248

Epoch: 6| Step: 12
Training loss: 1.4990413188934326
Validation loss: 1.983923335870107

Epoch: 6| Step: 13
Training loss: 0.8031835556030273
Validation loss: 2.0027582248051963

Epoch: 163| Step: 0
Training loss: 0.9159905910491943
Validation loss: 1.9822200139363606

Epoch: 6| Step: 1
Training loss: 0.9967530369758606
Validation loss: 1.9936677018801372

Epoch: 6| Step: 2
Training loss: 1.022368311882019
Validation loss: 1.9934919675191243

Epoch: 6| Step: 3
Training loss: 1.546717882156372
Validation loss: 1.990300754706065

Epoch: 6| Step: 4
Training loss: 1.0052320957183838
Validation loss: 1.990326960881551

Epoch: 6| Step: 5
Training loss: 0.5685053467750549
Validation loss: 2.0067939360936484

Epoch: 6| Step: 6
Training loss: 1.1947312355041504
Validation loss: 2.0017103155454

Epoch: 6| Step: 7
Training loss: 0.5176718235015869
Validation loss: 1.9985071221987407

Epoch: 6| Step: 8
Training loss: 1.3557208776474
Validation loss: 1.9623066782951355

Epoch: 6| Step: 9
Training loss: 0.7217667102813721
Validation loss: 1.9770933787027996

Epoch: 6| Step: 10
Training loss: 0.49133509397506714
Validation loss: 1.9769438902537029

Epoch: 6| Step: 11
Training loss: 1.3232073783874512
Validation loss: 1.98818701505661

Epoch: 6| Step: 12
Training loss: 0.9567537307739258
Validation loss: 1.9658381740252178

Epoch: 6| Step: 13
Training loss: 0.6786167621612549
Validation loss: 2.0205416679382324

Epoch: 164| Step: 0
Training loss: 0.768096387386322
Validation loss: 2.010724047819773

Epoch: 6| Step: 1
Training loss: 1.0602262020111084
Validation loss: 1.9824158747990925

Epoch: 6| Step: 2
Training loss: 0.8661661148071289
Validation loss: 1.9986674785614014

Epoch: 6| Step: 3
Training loss: 0.9175887107849121
Validation loss: 1.9931992888450623

Epoch: 6| Step: 4
Training loss: 0.9101766347885132
Validation loss: 1.993005096912384

Epoch: 6| Step: 5
Training loss: 0.8092818856239319
Validation loss: 1.9761021931966145

Epoch: 6| Step: 6
Training loss: 0.697639524936676
Validation loss: 1.980953296025594

Epoch: 6| Step: 7
Training loss: 0.9227687120437622
Validation loss: 1.940658171971639

Epoch: 6| Step: 8
Training loss: 0.66071617603302
Validation loss: 1.9542692303657532

Epoch: 6| Step: 9
Training loss: 0.8596298694610596
Validation loss: 2.0280616680781045

Epoch: 6| Step: 10
Training loss: 1.1506142616271973
Validation loss: 2.0292782386144004

Epoch: 6| Step: 11
Training loss: 0.8510569334030151
Validation loss: 1.964560906092326

Epoch: 6| Step: 12
Training loss: 1.0309948921203613
Validation loss: 2.0039113561312356

Epoch: 6| Step: 13
Training loss: 1.1213864088058472
Validation loss: 2.0341391960779824

Epoch: 165| Step: 0
Training loss: 1.118574857711792
Validation loss: 2.0112434029579163

Epoch: 6| Step: 1
Training loss: 1.0742300748825073
Validation loss: 2.0348046024640403

Epoch: 6| Step: 2
Training loss: 0.8417658805847168
Validation loss: 2.046749393145243

Epoch: 6| Step: 3
Training loss: 0.6879773139953613
Validation loss: 2.0339303811391196

Epoch: 6| Step: 4
Training loss: 0.9545526504516602
Validation loss: 2.0030774076779685

Epoch: 6| Step: 5
Training loss: 0.7631372213363647
Validation loss: 2.0101370215415955

Epoch: 6| Step: 6
Training loss: 1.365762710571289
Validation loss: 2.0440812905629477

Epoch: 6| Step: 7
Training loss: 0.4938312768936157
Validation loss: 2.0343170960744223

Epoch: 6| Step: 8
Training loss: 1.3708806037902832
Validation loss: 2.002562403678894

Epoch: 6| Step: 9
Training loss: 0.6341090202331543
Validation loss: 2.003652890523275

Epoch: 6| Step: 10
Training loss: 0.8965597748756409
Validation loss: 2.0091837644577026

Epoch: 6| Step: 11
Training loss: 0.8563852310180664
Validation loss: 2.0318383971850076

Epoch: 6| Step: 12
Training loss: 1.3729944229125977
Validation loss: 2.0229742924372354

Epoch: 6| Step: 13
Training loss: 0.9618678092956543
Validation loss: 2.0256009896596274

Epoch: 166| Step: 0
Training loss: 0.7389552593231201
Validation loss: 2.01340659459432

Epoch: 6| Step: 1
Training loss: 0.810950517654419
Validation loss: 1.9563813209533691

Epoch: 6| Step: 2
Training loss: 1.0961158275604248
Validation loss: 1.995705286661784

Epoch: 6| Step: 3
Training loss: 1.5008141994476318
Validation loss: 2.0177952647209167

Epoch: 6| Step: 4
Training loss: 0.34874823689460754
Validation loss: 1.991870939731598

Epoch: 6| Step: 5
Training loss: 0.7115548849105835
Validation loss: 2.035200575987498

Epoch: 6| Step: 6
Training loss: 1.101607084274292
Validation loss: 2.0004542072614035

Epoch: 6| Step: 7
Training loss: 1.3040543794631958
Validation loss: 2.045436124006907

Epoch: 6| Step: 8
Training loss: 1.265392541885376
Validation loss: 1.9771783550580342

Epoch: 6| Step: 9
Training loss: 0.5951812863349915
Validation loss: 2.014251430829366

Epoch: 6| Step: 10
Training loss: 1.018643856048584
Validation loss: 2.013960599899292

Epoch: 6| Step: 11
Training loss: 1.0305373668670654
Validation loss: 1.98976735273997

Epoch: 6| Step: 12
Training loss: 0.7810201048851013
Validation loss: 1.9657921195030212

Epoch: 6| Step: 13
Training loss: 0.5706349611282349
Validation loss: 2.0012913743654885

Epoch: 167| Step: 0
Training loss: 0.9995941519737244
Validation loss: 1.9956219991048176

Epoch: 6| Step: 1
Training loss: 0.8609964847564697
Validation loss: 2.0297439893086753

Epoch: 6| Step: 2
Training loss: 0.6540564298629761
Validation loss: 1.98079252243042

Epoch: 6| Step: 3
Training loss: 0.8186547756195068
Validation loss: 1.9998945593833923

Epoch: 6| Step: 4
Training loss: 1.0113756656646729
Validation loss: 2.0069653391838074

Epoch: 6| Step: 5
Training loss: 0.65532386302948
Validation loss: 1.9872107307116191

Epoch: 6| Step: 6
Training loss: 1.0061118602752686
Validation loss: 2.009152134259542

Epoch: 6| Step: 7
Training loss: 0.7091333866119385
Validation loss: 2.006693442662557

Epoch: 6| Step: 8
Training loss: 1.0546636581420898
Validation loss: 2.0082556207974753

Epoch: 6| Step: 9
Training loss: 1.2112621068954468
Validation loss: 1.984966774781545

Epoch: 6| Step: 10
Training loss: 1.122646689414978
Validation loss: 1.9777939716974895

Epoch: 6| Step: 11
Training loss: 0.8369203805923462
Validation loss: 2.0125635862350464

Epoch: 6| Step: 12
Training loss: 0.8109943866729736
Validation loss: 1.9942248264948528

Epoch: 6| Step: 13
Training loss: 0.4281581938266754
Validation loss: 2.020305554072062

Epoch: 168| Step: 0
Training loss: 0.571837306022644
Validation loss: 2.0314422647158303

Epoch: 6| Step: 1
Training loss: 0.7812038660049438
Validation loss: 1.9859244426091511

Epoch: 6| Step: 2
Training loss: 0.6623643040657043
Validation loss: 1.9767828981081645

Epoch: 6| Step: 3
Training loss: 0.8256932497024536
Validation loss: 1.961290756861369

Epoch: 6| Step: 4
Training loss: 0.7927008867263794
Validation loss: 2.024661103884379

Epoch: 6| Step: 5
Training loss: 0.8457377552986145
Validation loss: 2.0085507233937583

Epoch: 6| Step: 6
Training loss: 1.2825937271118164
Validation loss: 1.997693379720052

Epoch: 6| Step: 7
Training loss: 1.0233378410339355
Validation loss: 2.0184065103530884

Epoch: 6| Step: 8
Training loss: 0.830962061882019
Validation loss: 1.984578788280487

Epoch: 6| Step: 9
Training loss: 0.813620924949646
Validation loss: 2.013859510421753

Epoch: 6| Step: 10
Training loss: 0.8632348775863647
Validation loss: 2.0244306325912476

Epoch: 6| Step: 11
Training loss: 1.7110188007354736
Validation loss: 1.996071696281433

Epoch: 6| Step: 12
Training loss: 0.69185471534729
Validation loss: 1.9983888665835063

Epoch: 6| Step: 13
Training loss: 0.9323880076408386
Validation loss: 2.0196781158447266

Epoch: 169| Step: 0
Training loss: 0.6153494715690613
Validation loss: 2.023989458878835

Epoch: 6| Step: 1
Training loss: 0.7943506240844727
Validation loss: 2.012305716673533

Epoch: 6| Step: 2
Training loss: 0.9707745313644409
Validation loss: 1.994926889737447

Epoch: 6| Step: 3
Training loss: 0.5343193411827087
Validation loss: 1.9888054331143696

Epoch: 6| Step: 4
Training loss: 0.7521843314170837
Validation loss: 1.97838693857193

Epoch: 6| Step: 5
Training loss: 1.2410054206848145
Validation loss: 1.9976008137067158

Epoch: 6| Step: 6
Training loss: 0.9586735963821411
Validation loss: 1.9403218428293865

Epoch: 6| Step: 7
Training loss: 0.7044408321380615
Validation loss: 2.0299208760261536

Epoch: 6| Step: 8
Training loss: 1.0089967250823975
Validation loss: 1.9751730561256409

Epoch: 6| Step: 9
Training loss: 0.9935997724533081
Validation loss: 1.991038183371226

Epoch: 6| Step: 10
Training loss: 0.8666952848434448
Validation loss: 1.969824989636739

Epoch: 6| Step: 11
Training loss: 0.6814261078834534
Validation loss: 1.9690081278483074

Epoch: 6| Step: 12
Training loss: 1.3105814456939697
Validation loss: 1.9921288688977559

Epoch: 6| Step: 13
Training loss: 1.1394460201263428
Validation loss: 2.029020071029663

Epoch: 170| Step: 0
Training loss: 1.4002928733825684
Validation loss: 2.011258542537689

Epoch: 6| Step: 1
Training loss: 1.0624117851257324
Validation loss: 2.0067708094914756

Epoch: 6| Step: 2
Training loss: 1.467279076576233
Validation loss: 2.028485596179962

Epoch: 6| Step: 3
Training loss: 0.9106442332267761
Validation loss: 1.9730286796887715

Epoch: 6| Step: 4
Training loss: 0.8511064052581787
Validation loss: 1.9909723997116089

Epoch: 6| Step: 5
Training loss: 0.5956658720970154
Validation loss: 1.9798830946286519

Epoch: 6| Step: 6
Training loss: 0.6103218793869019
Validation loss: 2.0345230102539062

Epoch: 6| Step: 7
Training loss: 1.0118601322174072
Validation loss: 1.981597324212392

Epoch: 6| Step: 8
Training loss: 0.6777892708778381
Validation loss: 1.973541220029195

Epoch: 6| Step: 9
Training loss: 0.9835689067840576
Validation loss: 2.016821324825287

Epoch: 6| Step: 10
Training loss: 0.6989026069641113
Validation loss: 2.0058181087176004

Epoch: 6| Step: 11
Training loss: 0.8879382610321045
Validation loss: 2.0063103238741555

Epoch: 6| Step: 12
Training loss: 0.438956081867218
Validation loss: 1.997807999451955

Epoch: 6| Step: 13
Training loss: 1.0781515836715698
Validation loss: 1.9861108859380086

Epoch: 171| Step: 0
Training loss: 0.8186984658241272
Validation loss: 2.0010395646095276

Epoch: 6| Step: 1
Training loss: 0.9236489534378052
Validation loss: 2.011248548825582

Epoch: 6| Step: 2
Training loss: 0.8297499418258667
Validation loss: 1.9388295809427898

Epoch: 6| Step: 3
Training loss: 0.9941322207450867
Validation loss: 1.9767001469930012

Epoch: 6| Step: 4
Training loss: 0.5913914442062378
Validation loss: 1.9805752833684285

Epoch: 6| Step: 5
Training loss: 1.0865498781204224
Validation loss: 1.9712398648262024

Epoch: 6| Step: 6
Training loss: 0.9167829751968384
Validation loss: 1.9816619157791138

Epoch: 6| Step: 7
Training loss: 0.8855959177017212
Validation loss: 1.9878766536712646

Epoch: 6| Step: 8
Training loss: 1.3329410552978516
Validation loss: 1.9991342822710674

Epoch: 6| Step: 9
Training loss: 0.8895905613899231
Validation loss: 1.9597755471865337

Epoch: 6| Step: 10
Training loss: 0.9950681924819946
Validation loss: 1.9899861812591553

Epoch: 6| Step: 11
Training loss: 0.5489686727523804
Validation loss: 1.9964866240819295

Epoch: 6| Step: 12
Training loss: 0.9773737788200378
Validation loss: 1.9886120756467183

Epoch: 6| Step: 13
Training loss: 0.6986309289932251
Validation loss: 1.9811363220214844

Epoch: 172| Step: 0
Training loss: 0.42451900243759155
Validation loss: 2.0183981458346048

Epoch: 6| Step: 1
Training loss: 1.5219247341156006
Validation loss: 1.9888481895128887

Epoch: 6| Step: 2
Training loss: 0.8169248700141907
Validation loss: 1.951997697353363

Epoch: 6| Step: 3
Training loss: 1.3808475732803345
Validation loss: 1.9734679460525513

Epoch: 6| Step: 4
Training loss: 0.8995411992073059
Validation loss: 1.9594008326530457

Epoch: 6| Step: 5
Training loss: 1.0505659580230713
Validation loss: 1.9900014400482178

Epoch: 6| Step: 6
Training loss: 0.8256078958511353
Validation loss: 1.986652433872223

Epoch: 6| Step: 7
Training loss: 0.755704939365387
Validation loss: 2.00960503021876

Epoch: 6| Step: 8
Training loss: 0.5162222981452942
Validation loss: 1.993178387482961

Epoch: 6| Step: 9
Training loss: 1.2312490940093994
Validation loss: 1.9198482235272725

Epoch: 6| Step: 10
Training loss: 0.9536076188087463
Validation loss: 1.952868938446045

Epoch: 6| Step: 11
Training loss: 0.7428194284439087
Validation loss: 1.9866450826327007

Epoch: 6| Step: 12
Training loss: 0.5859216451644897
Validation loss: 1.9893360336621602

Epoch: 6| Step: 13
Training loss: 0.8120417594909668
Validation loss: 1.99294513463974

Epoch: 173| Step: 0
Training loss: 0.9848521947860718
Validation loss: 1.9758657217025757

Epoch: 6| Step: 1
Training loss: 1.0010157823562622
Validation loss: 2.0256535609563193

Epoch: 6| Step: 2
Training loss: 1.1178433895111084
Validation loss: 2.0620122154553733

Epoch: 6| Step: 3
Training loss: 0.7356853485107422
Validation loss: 2.028924564520518

Epoch: 6| Step: 4
Training loss: 0.9342744946479797
Validation loss: 2.0538841088612876

Epoch: 6| Step: 5
Training loss: 1.1252706050872803
Validation loss: 2.023120701313019

Epoch: 6| Step: 6
Training loss: 1.1240609884262085
Validation loss: 1.9972126285235088

Epoch: 6| Step: 7
Training loss: 0.9929765462875366
Validation loss: 2.006836752096812

Epoch: 6| Step: 8
Training loss: 1.0346530675888062
Validation loss: 1.9970741073290508

Epoch: 6| Step: 9
Training loss: 0.8139617443084717
Validation loss: 2.015373925367991

Epoch: 6| Step: 10
Training loss: 0.9117465019226074
Validation loss: 2.0280025601387024

Epoch: 6| Step: 11
Training loss: 0.641552209854126
Validation loss: 1.9731079737345378

Epoch: 6| Step: 12
Training loss: 0.7411806583404541
Validation loss: 1.980208694934845

Epoch: 6| Step: 13
Training loss: 0.7109471559524536
Validation loss: 1.992596983909607

Epoch: 174| Step: 0
Training loss: 1.307746171951294
Validation loss: 1.986746072769165

Epoch: 6| Step: 1
Training loss: 0.7064584493637085
Validation loss: 1.993481715520223

Epoch: 6| Step: 2
Training loss: 0.5819527506828308
Validation loss: 1.9436593651771545

Epoch: 6| Step: 3
Training loss: 0.9574764966964722
Validation loss: 1.9639419515927632

Epoch: 6| Step: 4
Training loss: 1.2297283411026
Validation loss: 1.97874649365743

Epoch: 6| Step: 5
Training loss: 0.4515995383262634
Validation loss: 1.9569476048151653

Epoch: 6| Step: 6
Training loss: 0.8001712560653687
Validation loss: 1.9730928341547649

Epoch: 6| Step: 7
Training loss: 0.9156528115272522
Validation loss: 1.9697973132133484

Epoch: 6| Step: 8
Training loss: 1.3542457818984985
Validation loss: 1.9590782324473064

Epoch: 6| Step: 9
Training loss: 0.9365247488021851
Validation loss: 1.9425631562868755

Epoch: 6| Step: 10
Training loss: 0.8023048043251038
Validation loss: 1.996686538060506

Epoch: 6| Step: 11
Training loss: 0.5448627471923828
Validation loss: 1.9309683044751484

Epoch: 6| Step: 12
Training loss: 0.7340372204780579
Validation loss: 1.9856102466583252

Epoch: 6| Step: 13
Training loss: 0.8415530920028687
Validation loss: 1.9826586643854778

Epoch: 175| Step: 0
Training loss: 0.5396546125411987
Validation loss: 1.9867508212725322

Epoch: 6| Step: 1
Training loss: 0.9415550827980042
Validation loss: 1.9971764485041301

Epoch: 6| Step: 2
Training loss: 0.8004781603813171
Validation loss: 1.9716489911079407

Epoch: 6| Step: 3
Training loss: 0.9247918725013733
Validation loss: 1.9943262537320454

Epoch: 6| Step: 4
Training loss: 0.9736579656600952
Validation loss: 1.9638903538386028

Epoch: 6| Step: 5
Training loss: 1.3966915607452393
Validation loss: 1.9849959015846252

Epoch: 6| Step: 6
Training loss: 0.5806640386581421
Validation loss: 1.9737973014513652

Epoch: 6| Step: 7
Training loss: 1.3591809272766113
Validation loss: 2.000744859377543

Epoch: 6| Step: 8
Training loss: 0.5094491243362427
Validation loss: 1.969464361667633

Epoch: 6| Step: 9
Training loss: 0.8356879949569702
Validation loss: 2.0281079411506653

Epoch: 6| Step: 10
Training loss: 0.7889132499694824
Validation loss: 2.0092198053995767

Epoch: 6| Step: 11
Training loss: 0.7053050398826599
Validation loss: 2.0135602951049805

Epoch: 6| Step: 12
Training loss: 0.984220027923584
Validation loss: 2.0266201297442117

Epoch: 6| Step: 13
Training loss: 0.7446626424789429
Validation loss: 2.000881473223368

Epoch: 176| Step: 0
Training loss: 0.9555920958518982
Validation loss: 1.9680687189102173

Epoch: 6| Step: 1
Training loss: 0.9491434097290039
Validation loss: 2.0311365922292075

Epoch: 6| Step: 2
Training loss: 0.8754859566688538
Validation loss: 1.9822390874226887

Epoch: 6| Step: 3
Training loss: 1.2144501209259033
Validation loss: 2.0136508345603943

Epoch: 6| Step: 4
Training loss: 1.144968032836914
Validation loss: 2.003563721974691

Epoch: 6| Step: 5
Training loss: 1.0560071468353271
Validation loss: 2.000336686770121

Epoch: 6| Step: 6
Training loss: 0.517028272151947
Validation loss: 2.016728679339091

Epoch: 6| Step: 7
Training loss: 0.7386621236801147
Validation loss: 1.959036151568095

Epoch: 6| Step: 8
Training loss: 0.5339854955673218
Validation loss: 1.9997193018595378

Epoch: 6| Step: 9
Training loss: 1.4631097316741943
Validation loss: 2.0314528147379556

Epoch: 6| Step: 10
Training loss: 0.9858059883117676
Validation loss: 2.0075424710909524

Epoch: 6| Step: 11
Training loss: 0.4418008327484131
Validation loss: 2.0361170967419944

Epoch: 6| Step: 12
Training loss: 0.32915452122688293
Validation loss: 1.9933610359827678

Epoch: 6| Step: 13
Training loss: 0.602091908454895
Validation loss: 1.9754120111465454

Epoch: 177| Step: 0
Training loss: 0.7978102564811707
Validation loss: 1.9422704180081685

Epoch: 6| Step: 1
Training loss: 0.7975566983222961
Validation loss: 1.9904986023902893

Epoch: 6| Step: 2
Training loss: 0.46144789457321167
Validation loss: 1.9450056552886963

Epoch: 6| Step: 3
Training loss: 0.7397452592849731
Validation loss: 1.9792782068252563

Epoch: 6| Step: 4
Training loss: 0.8859677314758301
Validation loss: 1.9792290131251018

Epoch: 6| Step: 5
Training loss: 0.8923866748809814
Validation loss: 1.9556662440299988

Epoch: 6| Step: 6
Training loss: 0.6537026166915894
Validation loss: 1.9772413969039917

Epoch: 6| Step: 7
Training loss: 0.6278320550918579
Validation loss: 1.9323113361994426

Epoch: 6| Step: 8
Training loss: 1.221773624420166
Validation loss: 1.939392666021983

Epoch: 6| Step: 9
Training loss: 1.08138108253479
Validation loss: 1.967419147491455

Epoch: 6| Step: 10
Training loss: 0.9179834127426147
Validation loss: 1.9976076086362202

Epoch: 6| Step: 11
Training loss: 0.9858356714248657
Validation loss: 1.9732836484909058

Epoch: 6| Step: 12
Training loss: 0.724249005317688
Validation loss: 1.9840530355771382

Epoch: 6| Step: 13
Training loss: 0.9060317277908325
Validation loss: 2.0079725782076516

Epoch: 178| Step: 0
Training loss: 0.5812856554985046
Validation loss: 1.9893550674120586

Epoch: 6| Step: 1
Training loss: 0.7409350275993347
Validation loss: 1.9602805376052856

Epoch: 6| Step: 2
Training loss: 0.6018612384796143
Validation loss: 2.001383662223816

Epoch: 6| Step: 3
Training loss: 0.9177060127258301
Validation loss: 2.01163250207901

Epoch: 6| Step: 4
Training loss: 0.4336080253124237
Validation loss: 1.964563012123108

Epoch: 6| Step: 5
Training loss: 0.7309261560440063
Validation loss: 1.99415119489034

Epoch: 6| Step: 6
Training loss: 1.0112824440002441
Validation loss: 2.011600991090139

Epoch: 6| Step: 7
Training loss: 0.9785157442092896
Validation loss: 1.9957024653752644

Epoch: 6| Step: 8
Training loss: 0.6596443057060242
Validation loss: 2.0490968823432922

Epoch: 6| Step: 9
Training loss: 1.3185547590255737
Validation loss: 2.013720174630483

Epoch: 6| Step: 10
Training loss: 1.1136143207550049
Validation loss: 1.9904362161954243

Epoch: 6| Step: 11
Training loss: 0.7746773958206177
Validation loss: 1.9844694932301838

Epoch: 6| Step: 12
Training loss: 0.9327272176742554
Validation loss: 1.965464433034261

Epoch: 6| Step: 13
Training loss: 1.441182017326355
Validation loss: 2.0408165653546653

Epoch: 179| Step: 0
Training loss: 0.5444946885108948
Validation loss: 2.040914078553518

Epoch: 6| Step: 1
Training loss: 0.9311068058013916
Validation loss: 1.9914989868799846

Epoch: 6| Step: 2
Training loss: 1.1701802015304565
Validation loss: 1.9898326992988586

Epoch: 6| Step: 3
Training loss: 0.7177117466926575
Validation loss: 1.9939268827438354

Epoch: 6| Step: 4
Training loss: 0.5453065037727356
Validation loss: 1.9676193992296855

Epoch: 6| Step: 5
Training loss: 0.8406672477722168
Validation loss: 2.0153071681658425

Epoch: 6| Step: 6
Training loss: 1.1244463920593262
Validation loss: 2.0130170981089273

Epoch: 6| Step: 7
Training loss: 0.8509214520454407
Validation loss: 2.0478035608927407

Epoch: 6| Step: 8
Training loss: 0.9885752201080322
Validation loss: 2.005218724409739

Epoch: 6| Step: 9
Training loss: 0.70623379945755
Validation loss: 1.9346794883410137

Epoch: 6| Step: 10
Training loss: 1.009770154953003
Validation loss: 1.9938303430875142

Epoch: 6| Step: 11
Training loss: 0.6057814955711365
Validation loss: 1.9952090978622437

Epoch: 6| Step: 12
Training loss: 0.8409575819969177
Validation loss: 2.0253159403800964

Epoch: 6| Step: 13
Training loss: 0.9937961101531982
Validation loss: 1.992309312025706

Epoch: 180| Step: 0
Training loss: 0.742685079574585
Validation loss: 1.9775681495666504

Epoch: 6| Step: 1
Training loss: 1.2532745599746704
Validation loss: 1.9882784684499104

Epoch: 6| Step: 2
Training loss: 0.8506827354431152
Validation loss: 2.0141589641571045

Epoch: 6| Step: 3
Training loss: 0.6868993043899536
Validation loss: 1.9816846648852031

Epoch: 6| Step: 4
Training loss: 0.5254034996032715
Validation loss: 1.9698702494303386

Epoch: 6| Step: 5
Training loss: 0.4656541347503662
Validation loss: 2.0004612604777017

Epoch: 6| Step: 6
Training loss: 0.658613920211792
Validation loss: 1.9761470556259155

Epoch: 6| Step: 7
Training loss: 0.6132223010063171
Validation loss: 1.98819100856781

Epoch: 6| Step: 8
Training loss: 1.0195910930633545
Validation loss: 1.9624859690666199

Epoch: 6| Step: 9
Training loss: 1.4125380516052246
Validation loss: 1.9690812826156616

Epoch: 6| Step: 10
Training loss: 1.0445705652236938
Validation loss: 1.993249773979187

Epoch: 6| Step: 11
Training loss: 1.2711243629455566
Validation loss: 1.9626431067784627

Epoch: 6| Step: 12
Training loss: 0.4287166893482208
Validation loss: 1.9951635996500652

Epoch: 6| Step: 13
Training loss: 0.678268313407898
Validation loss: 1.9930427273114522

Epoch: 181| Step: 0
Training loss: 0.7165414094924927
Validation loss: 1.967292328675588

Epoch: 6| Step: 1
Training loss: 0.7426566481590271
Validation loss: 1.9872363209724426

Epoch: 6| Step: 2
Training loss: 0.9182902574539185
Validation loss: 2.005607823530833

Epoch: 6| Step: 3
Training loss: 1.0429611206054688
Validation loss: 1.9770626624425252

Epoch: 6| Step: 4
Training loss: 0.9302884936332703
Validation loss: 1.9974060257275899

Epoch: 6| Step: 5
Training loss: 1.192099690437317
Validation loss: 2.0285781025886536

Epoch: 6| Step: 6
Training loss: 1.014411449432373
Validation loss: 1.964944581190745

Epoch: 6| Step: 7
Training loss: 0.5803364515304565
Validation loss: 2.0127711494763694

Epoch: 6| Step: 8
Training loss: 0.7346829771995544
Validation loss: 1.93588391939799

Epoch: 6| Step: 9
Training loss: 0.3017566204071045
Validation loss: 1.9968935052553813

Epoch: 6| Step: 10
Training loss: 0.4217086136341095
Validation loss: 1.9979340235392253

Epoch: 6| Step: 11
Training loss: 0.8877418041229248
Validation loss: 2.000965634981791

Epoch: 6| Step: 12
Training loss: 1.4707437753677368
Validation loss: 1.9839629729588826

Epoch: 6| Step: 13
Training loss: 0.5214782357215881
Validation loss: 1.998303492863973

Epoch: 182| Step: 0
Training loss: 0.7550772428512573
Validation loss: 1.9717320402463276

Epoch: 6| Step: 1
Training loss: 0.3085888922214508
Validation loss: 2.0008015831311545

Epoch: 6| Step: 2
Training loss: 0.8779418468475342
Validation loss: 1.9871092637379963

Epoch: 6| Step: 3
Training loss: 1.1204081773757935
Validation loss: 2.0125446716944375

Epoch: 6| Step: 4
Training loss: 0.9867727756500244
Validation loss: 2.025185247262319

Epoch: 6| Step: 5
Training loss: 0.8834131956100464
Validation loss: 1.9756728609402974

Epoch: 6| Step: 6
Training loss: 0.9463963508605957
Validation loss: 1.9651593565940857

Epoch: 6| Step: 7
Training loss: 0.7735605835914612
Validation loss: 2.008949081103007

Epoch: 6| Step: 8
Training loss: 0.6765044331550598
Validation loss: 1.9683208266894023

Epoch: 6| Step: 9
Training loss: 0.7267673015594482
Validation loss: 1.986074447631836

Epoch: 6| Step: 10
Training loss: 0.7694133520126343
Validation loss: 1.9858727653821309

Epoch: 6| Step: 11
Training loss: 0.6018775105476379
Validation loss: 1.9811185399691265

Epoch: 6| Step: 12
Training loss: 1.0246477127075195
Validation loss: 1.9883517026901245

Epoch: 6| Step: 13
Training loss: 1.2225770950317383
Validation loss: 1.98028165102005

Epoch: 183| Step: 0
Training loss: 0.8606786131858826
Validation loss: 1.956433375676473

Epoch: 6| Step: 1
Training loss: 0.8524933457374573
Validation loss: 1.9555014371871948

Epoch: 6| Step: 2
Training loss: 0.6647802591323853
Validation loss: 1.9875721136728923

Epoch: 6| Step: 3
Training loss: 0.767516553401947
Validation loss: 1.9676046172777812

Epoch: 6| Step: 4
Training loss: 0.6149526834487915
Validation loss: 2.035446564356486

Epoch: 6| Step: 5
Training loss: 0.9823804497718811
Validation loss: 1.9688994487126668

Epoch: 6| Step: 6
Training loss: 0.8859992027282715
Validation loss: 1.9843158721923828

Epoch: 6| Step: 7
Training loss: 0.7638891935348511
Validation loss: 1.960773229598999

Epoch: 6| Step: 8
Training loss: 0.720123291015625
Validation loss: 2.005456348260244

Epoch: 6| Step: 9
Training loss: 1.0036449432373047
Validation loss: 1.9631798664728801

Epoch: 6| Step: 10
Training loss: 0.8654640913009644
Validation loss: 1.9796311855316162

Epoch: 6| Step: 11
Training loss: 0.37368521094322205
Validation loss: 1.9765690763791401

Epoch: 6| Step: 12
Training loss: 0.8672406077384949
Validation loss: 1.9757823944091797

Epoch: 6| Step: 13
Training loss: 0.8314067125320435
Validation loss: 1.990431288878123

Epoch: 184| Step: 0
Training loss: 0.6993539929389954
Validation loss: 1.9603687922159831

Epoch: 6| Step: 1
Training loss: 1.0536984205245972
Validation loss: 1.944334367911021

Epoch: 6| Step: 2
Training loss: 0.570035457611084
Validation loss: 1.9844602942466736

Epoch: 6| Step: 3
Training loss: 0.7482800483703613
Validation loss: 1.9487595558166504

Epoch: 6| Step: 4
Training loss: 1.1805753707885742
Validation loss: 2.027543822924296

Epoch: 6| Step: 5
Training loss: 1.0057439804077148
Validation loss: 1.9719269474347432

Epoch: 6| Step: 6
Training loss: 0.7408345341682434
Validation loss: 2.005127946535746

Epoch: 6| Step: 7
Training loss: 0.7409523129463196
Validation loss: 1.965119461218516

Epoch: 6| Step: 8
Training loss: 0.2919146418571472
Validation loss: 2.0046952764193215

Epoch: 6| Step: 9
Training loss: 0.705507755279541
Validation loss: 2.0039650996526084

Epoch: 6| Step: 10
Training loss: 0.37769126892089844
Validation loss: 1.9944384098052979

Epoch: 6| Step: 11
Training loss: 1.2630348205566406
Validation loss: 1.9993858138720195

Epoch: 6| Step: 12
Training loss: 1.0154818296432495
Validation loss: 2.008236368497213

Epoch: 6| Step: 13
Training loss: 0.8078531622886658
Validation loss: 1.9953797062238057

Epoch: 185| Step: 0
Training loss: 0.3363203704357147
Validation loss: 2.0094610850016275

Epoch: 6| Step: 1
Training loss: 0.9183292388916016
Validation loss: 1.98307869831721

Epoch: 6| Step: 2
Training loss: 1.0110684633255005
Validation loss: 2.0160690943400064

Epoch: 6| Step: 3
Training loss: 0.7838977575302124
Validation loss: 2.0219273964564004

Epoch: 6| Step: 4
Training loss: 0.8351491689682007
Validation loss: 2.01260906457901

Epoch: 6| Step: 5
Training loss: 1.0877833366394043
Validation loss: 2.0053162574768066

Epoch: 6| Step: 6
Training loss: 1.0586607456207275
Validation loss: 2.0147435665130615

Epoch: 6| Step: 7
Training loss: 0.6206019520759583
Validation loss: 2.0289886196454368

Epoch: 6| Step: 8
Training loss: 0.8980936408042908
Validation loss: 1.9915576378504436

Epoch: 6| Step: 9
Training loss: 1.1586604118347168
Validation loss: 1.9646947979927063

Epoch: 6| Step: 10
Training loss: 0.8339943885803223
Validation loss: 1.994682212670644

Epoch: 6| Step: 11
Training loss: 0.48818159103393555
Validation loss: 1.967275321483612

Epoch: 6| Step: 12
Training loss: 0.8836898803710938
Validation loss: 1.9868404865264893

Epoch: 6| Step: 13
Training loss: 0.7976189255714417
Validation loss: 2.004933178424835

Epoch: 186| Step: 0
Training loss: 0.6364741325378418
Validation loss: 1.9474722544352214

Epoch: 6| Step: 1
Training loss: 0.6447142362594604
Validation loss: 1.967724323272705

Epoch: 6| Step: 2
Training loss: 1.259955644607544
Validation loss: 1.962463100751241

Epoch: 6| Step: 3
Training loss: 0.6917551755905151
Validation loss: 1.9142508506774902

Epoch: 6| Step: 4
Training loss: 1.0116221904754639
Validation loss: 1.9882570505142212

Epoch: 6| Step: 5
Training loss: 0.5164775848388672
Validation loss: 2.005388379096985

Epoch: 6| Step: 6
Training loss: 1.032894492149353
Validation loss: 1.9737954338391621

Epoch: 6| Step: 7
Training loss: 1.0765491724014282
Validation loss: 2.0079617698987327

Epoch: 6| Step: 8
Training loss: 0.4874427020549774
Validation loss: 1.9469353953997295

Epoch: 6| Step: 9
Training loss: 0.687382698059082
Validation loss: 2.0109110474586487

Epoch: 6| Step: 10
Training loss: 1.267729640007019
Validation loss: 1.9606309334437053

Epoch: 6| Step: 11
Training loss: 0.5900624990463257
Validation loss: 2.0246921380360923

Epoch: 6| Step: 12
Training loss: 0.5615049600601196
Validation loss: 1.9751621286074321

Epoch: 6| Step: 13
Training loss: 1.0812506675720215
Validation loss: 1.9622682929039001

Epoch: 187| Step: 0
Training loss: 0.9287282228469849
Validation loss: 1.9794806241989136

Epoch: 6| Step: 1
Training loss: 0.7240792512893677
Validation loss: 1.9838171203931172

Epoch: 6| Step: 2
Training loss: 0.6002751588821411
Validation loss: 1.9901639819145203

Epoch: 6| Step: 3
Training loss: 0.9565155506134033
Validation loss: 1.9740532636642456

Epoch: 6| Step: 4
Training loss: 1.012758493423462
Validation loss: 1.9942700465520222

Epoch: 6| Step: 5
Training loss: 0.9065462350845337
Validation loss: 1.9881003499031067

Epoch: 6| Step: 6
Training loss: 0.692598819732666
Validation loss: 1.9466124375661213

Epoch: 6| Step: 7
Training loss: 0.4584167003631592
Validation loss: 1.9709687034289043

Epoch: 6| Step: 8
Training loss: 0.47507303953170776
Validation loss: 1.9606880744298298

Epoch: 6| Step: 9
Training loss: 0.9481186270713806
Validation loss: 1.9642179210980732

Epoch: 6| Step: 10
Training loss: 0.8828285932540894
Validation loss: 1.9671493371327717

Epoch: 6| Step: 11
Training loss: 0.6588483452796936
Validation loss: 1.998640735944112

Epoch: 6| Step: 12
Training loss: 0.9756578207015991
Validation loss: 1.989745855331421

Epoch: 6| Step: 13
Training loss: 0.7401947379112244
Validation loss: 1.9917559226353962

Epoch: 188| Step: 0
Training loss: 1.0089304447174072
Validation loss: 1.98732328414917

Epoch: 6| Step: 1
Training loss: 1.1343836784362793
Validation loss: 1.9719025492668152

Epoch: 6| Step: 2
Training loss: 0.36240991950035095
Validation loss: 1.999648928642273

Epoch: 6| Step: 3
Training loss: 0.6310938596725464
Validation loss: 1.981264094511668

Epoch: 6| Step: 4
Training loss: 0.8319298624992371
Validation loss: 1.947394112745921

Epoch: 6| Step: 5
Training loss: 0.6846914291381836
Validation loss: 1.9608031312624614

Epoch: 6| Step: 6
Training loss: 0.46223771572113037
Validation loss: 1.9807397524515789

Epoch: 6| Step: 7
Training loss: 0.7698498964309692
Validation loss: 1.9467016458511353

Epoch: 6| Step: 8
Training loss: 0.6407307386398315
Validation loss: 1.9860044121742249

Epoch: 6| Step: 9
Training loss: 0.7992340326309204
Validation loss: 1.9760119120279949

Epoch: 6| Step: 10
Training loss: 0.9402567744255066
Validation loss: 1.9781198104222615

Epoch: 6| Step: 11
Training loss: 1.380016565322876
Validation loss: 2.0096687277158103

Epoch: 6| Step: 12
Training loss: 0.9635946154594421
Validation loss: 2.017286956310272

Epoch: 6| Step: 13
Training loss: 0.8213562369346619
Validation loss: 1.9608606497446697

Epoch: 189| Step: 0
Training loss: 0.4719820022583008
Validation loss: 1.959281583627065

Epoch: 6| Step: 1
Training loss: 0.7839559316635132
Validation loss: 1.9897199074427288

Epoch: 6| Step: 2
Training loss: 0.9389520883560181
Validation loss: 2.00168248017629

Epoch: 6| Step: 3
Training loss: 0.7589483261108398
Validation loss: 1.9588769276936848

Epoch: 6| Step: 4
Training loss: 0.7321736812591553
Validation loss: 1.9601304133733113

Epoch: 6| Step: 5
Training loss: 0.4578242301940918
Validation loss: 1.951971133550008

Epoch: 6| Step: 6
Training loss: 0.8665100336074829
Validation loss: 1.961079994837443

Epoch: 6| Step: 7
Training loss: 0.46193447709083557
Validation loss: 1.9576376080513

Epoch: 6| Step: 8
Training loss: 1.2707805633544922
Validation loss: 1.9522297779719036

Epoch: 6| Step: 9
Training loss: 0.9990507364273071
Validation loss: 1.9904521107673645

Epoch: 6| Step: 10
Training loss: 0.697554886341095
Validation loss: 1.979086995124817

Epoch: 6| Step: 11
Training loss: 1.0858445167541504
Validation loss: 1.9745054443677266

Epoch: 6| Step: 12
Training loss: 0.6004897952079773
Validation loss: 1.9891745845476787

Epoch: 6| Step: 13
Training loss: 0.7165055871009827
Validation loss: 1.9666736721992493

Epoch: 190| Step: 0
Training loss: 0.56638103723526
Validation loss: 2.008427540461222

Epoch: 6| Step: 1
Training loss: 1.3396754264831543
Validation loss: 1.98929101228714

Epoch: 6| Step: 2
Training loss: 0.8524996638298035
Validation loss: 1.9797597726186116

Epoch: 6| Step: 3
Training loss: 0.868665337562561
Validation loss: 1.9564271966616313

Epoch: 6| Step: 4
Training loss: 0.8609304428100586
Validation loss: 2.0069114168485007

Epoch: 6| Step: 5
Training loss: 0.9970850348472595
Validation loss: 2.02638179063797

Epoch: 6| Step: 6
Training loss: 0.5524224042892456
Validation loss: 2.000818133354187

Epoch: 6| Step: 7
Training loss: 0.8171700835227966
Validation loss: 2.0222517053286233

Epoch: 6| Step: 8
Training loss: 1.0422600507736206
Validation loss: 1.9616953134536743

Epoch: 6| Step: 9
Training loss: 0.6574294567108154
Validation loss: 1.9887111981709797

Epoch: 6| Step: 10
Training loss: 0.3323138654232025
Validation loss: 1.969404141108195

Epoch: 6| Step: 11
Training loss: 0.9035428166389465
Validation loss: 1.9248026410738628

Epoch: 6| Step: 12
Training loss: 0.4354567527770996
Validation loss: 1.9751061002413433

Epoch: 6| Step: 13
Training loss: 0.7730141878128052
Validation loss: 1.9850276708602905

Epoch: 191| Step: 0
Training loss: 0.7159022092819214
Validation loss: 1.9521785577138264

Epoch: 6| Step: 1
Training loss: 0.8816606998443604
Validation loss: 2.011625111103058

Epoch: 6| Step: 2
Training loss: 0.3988744616508484
Validation loss: 1.9628203511238098

Epoch: 6| Step: 3
Training loss: 0.6489619016647339
Validation loss: 2.0254961252212524

Epoch: 6| Step: 4
Training loss: 0.7829114198684692
Validation loss: 1.999355435371399

Epoch: 6| Step: 5
Training loss: 1.0489989519119263
Validation loss: 1.992647409439087

Epoch: 6| Step: 6
Training loss: 0.9289718270301819
Validation loss: 1.9590687155723572

Epoch: 6| Step: 7
Training loss: 1.0406849384307861
Validation loss: 1.9577471613883972

Epoch: 6| Step: 8
Training loss: 0.7918716073036194
Validation loss: 1.969454288482666

Epoch: 6| Step: 9
Training loss: 1.1215801239013672
Validation loss: 2.002226094404856

Epoch: 6| Step: 10
Training loss: 0.7382383346557617
Validation loss: 1.9721579551696777

Epoch: 6| Step: 11
Training loss: 0.9041668176651001
Validation loss: 2.0108720461527505

Epoch: 6| Step: 12
Training loss: 0.5813632607460022
Validation loss: 2.0218372543652854

Epoch: 6| Step: 13
Training loss: 0.6881275177001953
Validation loss: 1.9809150497118633

Epoch: 192| Step: 0
Training loss: 0.7158097624778748
Validation loss: 1.9849959810574849

Epoch: 6| Step: 1
Training loss: 0.9566948413848877
Validation loss: 2.0271456440289817

Epoch: 6| Step: 2
Training loss: 0.6656574010848999
Validation loss: 2.0108157992362976

Epoch: 6| Step: 3
Training loss: 1.0157053470611572
Validation loss: 1.929440399010976

Epoch: 6| Step: 4
Training loss: 0.8188676834106445
Validation loss: 1.9599823156992595

Epoch: 6| Step: 5
Training loss: 0.5596932172775269
Validation loss: 1.9425538778305054

Epoch: 6| Step: 6
Training loss: 0.9578955173492432
Validation loss: 1.9637394547462463

Epoch: 6| Step: 7
Training loss: 0.875403642654419
Validation loss: 2.0156389077504477

Epoch: 6| Step: 8
Training loss: 1.501307487487793
Validation loss: 2.0135549306869507

Epoch: 6| Step: 9
Training loss: 0.7627161741256714
Validation loss: 1.9790349801381428

Epoch: 6| Step: 10
Training loss: 1.0491899251937866
Validation loss: 1.979344328244527

Epoch: 6| Step: 11
Training loss: 0.4854063391685486
Validation loss: 1.9910428921381633

Epoch: 6| Step: 12
Training loss: 0.8055440783500671
Validation loss: 1.9774648547172546

Epoch: 6| Step: 13
Training loss: 0.8550481200218201
Validation loss: 2.0300259590148926

Epoch: 193| Step: 0
Training loss: 0.8146849274635315
Validation loss: 2.0613796512285867

Epoch: 6| Step: 1
Training loss: 1.035951852798462
Validation loss: 2.0597270727157593

Epoch: 6| Step: 2
Training loss: 0.9300900101661682
Validation loss: 2.0105607906977334

Epoch: 6| Step: 3
Training loss: 0.9773281812667847
Validation loss: 1.9630228678385417

Epoch: 6| Step: 4
Training loss: 1.2253365516662598
Validation loss: 2.0069448351860046

Epoch: 6| Step: 5
Training loss: 0.42408332228660583
Validation loss: 2.00484965244929

Epoch: 6| Step: 6
Training loss: 0.9518235921859741
Validation loss: 1.9874383012453716

Epoch: 6| Step: 7
Training loss: 0.7918838858604431
Validation loss: 1.9935787717501323

Epoch: 6| Step: 8
Training loss: 1.114736557006836
Validation loss: 2.0191108187039695

Epoch: 6| Step: 9
Training loss: 0.9683354496955872
Validation loss: 2.040188113848368

Epoch: 6| Step: 10
Training loss: 1.0923547744750977
Validation loss: 2.006503641605377

Epoch: 6| Step: 11
Training loss: 0.4536813795566559
Validation loss: 1.9957565069198608

Epoch: 6| Step: 12
Training loss: 0.6248016953468323
Validation loss: 1.9240922927856445

Epoch: 6| Step: 13
Training loss: 1.002389669418335
Validation loss: 1.9969725410143535

Epoch: 194| Step: 0
Training loss: 0.7428861856460571
Validation loss: 2.04847115278244

Epoch: 6| Step: 1
Training loss: 0.953811526298523
Validation loss: 2.0402657787005105

Epoch: 6| Step: 2
Training loss: 0.696765661239624
Validation loss: 2.044446031252543

Epoch: 6| Step: 3
Training loss: 1.1239235401153564
Validation loss: 2.032554546991984

Epoch: 6| Step: 4
Training loss: 0.5312474966049194
Validation loss: 1.9604549209276836

Epoch: 6| Step: 5
Training loss: 0.6991020441055298
Validation loss: 1.9803136189778645

Epoch: 6| Step: 6
Training loss: 0.4500354826450348
Validation loss: 1.976972798506419

Epoch: 6| Step: 7
Training loss: 1.0002456903457642
Validation loss: 2.0039822459220886

Epoch: 6| Step: 8
Training loss: 0.7653303146362305
Validation loss: 2.008605639139811

Epoch: 6| Step: 9
Training loss: 0.8362611532211304
Validation loss: 2.0204880833625793

Epoch: 6| Step: 10
Training loss: 0.9693679809570312
Validation loss: 1.9899381200472515

Epoch: 6| Step: 11
Training loss: 0.7859042882919312
Validation loss: 1.9801451166470845

Epoch: 6| Step: 12
Training loss: 1.0174167156219482
Validation loss: 1.9739347696304321

Epoch: 6| Step: 13
Training loss: 1.073228359222412
Validation loss: 1.9945471286773682

Epoch: 195| Step: 0
Training loss: 0.9498512148857117
Validation loss: 1.9955702622731526

Epoch: 6| Step: 1
Training loss: 0.7029582262039185
Validation loss: 2.0084393421808877

Epoch: 6| Step: 2
Training loss: 0.8116363286972046
Validation loss: 2.019879718621572

Epoch: 6| Step: 3
Training loss: 0.552841067314148
Validation loss: 1.9908846418062847

Epoch: 6| Step: 4
Training loss: 0.7172694206237793
Validation loss: 1.992764453093211

Epoch: 6| Step: 5
Training loss: 1.2100688219070435
Validation loss: 1.9530842701594036

Epoch: 6| Step: 6
Training loss: 1.3598418235778809
Validation loss: 1.9740447600682576

Epoch: 6| Step: 7
Training loss: 0.7196748852729797
Validation loss: 1.9731086095174153

Epoch: 6| Step: 8
Training loss: 0.3975520431995392
Validation loss: 1.9950696627298992

Epoch: 6| Step: 9
Training loss: 0.5754815936088562
Validation loss: 1.984206994374593

Epoch: 6| Step: 10
Training loss: 0.9197103977203369
Validation loss: 1.9721185962359111

Epoch: 6| Step: 11
Training loss: 0.41020864248275757
Validation loss: 2.0277782479921975

Epoch: 6| Step: 12
Training loss: 0.5903799533843994
Validation loss: 2.018183390299479

Epoch: 6| Step: 13
Training loss: 0.6726908683776855
Validation loss: 1.9981329639752705

Epoch: 196| Step: 0
Training loss: 0.7542089819908142
Validation loss: 1.9628389080365498

Epoch: 6| Step: 1
Training loss: 1.2003477811813354
Validation loss: 1.9730879068374634

Epoch: 6| Step: 2
Training loss: 0.6845322847366333
Validation loss: 1.9963999191919963

Epoch: 6| Step: 3
Training loss: 0.7146192789077759
Validation loss: 1.9681108593940735

Epoch: 6| Step: 4
Training loss: 0.616616427898407
Validation loss: 1.9837666551272075

Epoch: 6| Step: 5
Training loss: 0.44034039974212646
Validation loss: 1.9362844427426655

Epoch: 6| Step: 6
Training loss: 1.1366214752197266
Validation loss: 1.9673860470453899

Epoch: 6| Step: 7
Training loss: 0.9208160638809204
Validation loss: 1.9683074752489726

Epoch: 6| Step: 8
Training loss: 0.8165505528450012
Validation loss: 1.952376087506612

Epoch: 6| Step: 9
Training loss: 0.7088078260421753
Validation loss: 1.967400848865509

Epoch: 6| Step: 10
Training loss: 0.3120083808898926
Validation loss: 1.9778087337811787

Epoch: 6| Step: 11
Training loss: 0.6998090744018555
Validation loss: 1.9754961927731831

Epoch: 6| Step: 12
Training loss: 0.5166236758232117
Validation loss: 2.007662832736969

Epoch: 6| Step: 13
Training loss: 0.8364120125770569
Validation loss: 1.9962505102157593

Epoch: 197| Step: 0
Training loss: 0.6253296136856079
Validation loss: 2.0095632870992026

Epoch: 6| Step: 1
Training loss: 0.45400384068489075
Validation loss: 1.968898872534434

Epoch: 6| Step: 2
Training loss: 0.729375958442688
Validation loss: 1.9336557586987813

Epoch: 6| Step: 3
Training loss: 0.6248053312301636
Validation loss: 2.002482255299886

Epoch: 6| Step: 4
Training loss: 0.9505534172058105
Validation loss: 1.980874280134837

Epoch: 6| Step: 5
Training loss: 0.5925057530403137
Validation loss: 1.9776289065678914

Epoch: 6| Step: 6
Training loss: 0.9926750063896179
Validation loss: 2.01332688331604

Epoch: 6| Step: 7
Training loss: 0.5899109840393066
Validation loss: 1.9995445211728413

Epoch: 6| Step: 8
Training loss: 0.40602540969848633
Validation loss: 1.958211859067281

Epoch: 6| Step: 9
Training loss: 1.059613585472107
Validation loss: 1.9754763046900432

Epoch: 6| Step: 10
Training loss: 0.6107834577560425
Validation loss: 1.992142915725708

Epoch: 6| Step: 11
Training loss: 0.6017755270004272
Validation loss: 1.9310619235038757

Epoch: 6| Step: 12
Training loss: 0.9963393211364746
Validation loss: 1.9535850087801616

Epoch: 6| Step: 13
Training loss: 0.9755111932754517
Validation loss: 2.0095225175221763

Epoch: 198| Step: 0
Training loss: 0.35828322172164917
Validation loss: 1.9336799780527751

Epoch: 6| Step: 1
Training loss: 0.46668004989624023
Validation loss: 1.9365583459536235

Epoch: 6| Step: 2
Training loss: 0.8091822862625122
Validation loss: 1.981158932050069

Epoch: 6| Step: 3
Training loss: 0.9320224523544312
Validation loss: 1.986226995786031

Epoch: 6| Step: 4
Training loss: 1.0997395515441895
Validation loss: 1.9980132381121318

Epoch: 6| Step: 5
Training loss: 0.9293951988220215
Validation loss: 1.9873392581939697

Epoch: 6| Step: 6
Training loss: 1.3241465091705322
Validation loss: 1.996522347132365

Epoch: 6| Step: 7
Training loss: 0.664332389831543
Validation loss: 1.9536354740460713

Epoch: 6| Step: 8
Training loss: 0.5157693028450012
Validation loss: 1.9648059010505676

Epoch: 6| Step: 9
Training loss: 1.1103821992874146
Validation loss: 2.0038814743359885

Epoch: 6| Step: 10
Training loss: 0.6337987184524536
Validation loss: 1.9727273186047871

Epoch: 6| Step: 11
Training loss: 0.6746733784675598
Validation loss: 1.964015543460846

Epoch: 6| Step: 12
Training loss: 0.34757864475250244
Validation loss: 1.9938161969184875

Epoch: 6| Step: 13
Training loss: 0.2674869894981384
Validation loss: 1.9739809036254883

Epoch: 199| Step: 0
Training loss: 0.5929665565490723
Validation loss: 1.9962685704231262

Epoch: 6| Step: 1
Training loss: 1.0830045938491821
Validation loss: 1.9830421408017476

Epoch: 6| Step: 2
Training loss: 0.41104644536972046
Validation loss: 1.9852238496144612

Epoch: 6| Step: 3
Training loss: 0.5903441309928894
Validation loss: 1.9801148374875386

Epoch: 6| Step: 4
Training loss: 1.1092501878738403
Validation loss: 1.9776570598284404

Epoch: 6| Step: 5
Training loss: 0.38861799240112305
Validation loss: 1.9675964713096619

Epoch: 6| Step: 6
Training loss: 0.7163813710212708
Validation loss: 2.0329752961794534

Epoch: 6| Step: 7
Training loss: 0.900616466999054
Validation loss: 2.0111225644747415

Epoch: 6| Step: 8
Training loss: 0.6476094722747803
Validation loss: 2.058507959047953

Epoch: 6| Step: 9
Training loss: 1.1230566501617432
Validation loss: 2.02894260485967

Epoch: 6| Step: 10
Training loss: 1.1126995086669922
Validation loss: 2.0714757839838662

Epoch: 6| Step: 11
Training loss: 0.8964568376541138
Validation loss: 2.0245830416679382

Epoch: 6| Step: 12
Training loss: 0.9194155931472778
Validation loss: 1.980466365814209

Epoch: 6| Step: 13
Training loss: 0.8338310718536377
Validation loss: 1.9840511083602905

Epoch: 200| Step: 0
Training loss: 0.5848668813705444
Validation loss: 1.9566311637560527

Epoch: 6| Step: 1
Training loss: 0.9312986135482788
Validation loss: 2.026405076185862

Epoch: 6| Step: 2
Training loss: 0.6677334308624268
Validation loss: 1.9861971338589985

Epoch: 6| Step: 3
Training loss: 0.8809545040130615
Validation loss: 1.983039100964864

Epoch: 6| Step: 4
Training loss: 0.8264233469963074
Validation loss: 1.9624608357747395

Epoch: 6| Step: 5
Training loss: 1.1000983715057373
Validation loss: 1.9627222021420796

Epoch: 6| Step: 6
Training loss: 0.853908896446228
Validation loss: 2.014303684234619

Epoch: 6| Step: 7
Training loss: 0.6504815816879272
Validation loss: 2.004307965437571

Epoch: 6| Step: 8
Training loss: 0.6599762439727783
Validation loss: 1.9781724611918132

Epoch: 6| Step: 9
Training loss: 0.7146403789520264
Validation loss: 1.963098684946696

Epoch: 6| Step: 10
Training loss: 0.6192477941513062
Validation loss: 1.9941216111183167

Epoch: 6| Step: 11
Training loss: 0.5868983268737793
Validation loss: 1.9895472129185994

Epoch: 6| Step: 12
Training loss: 0.4427158236503601
Validation loss: 1.9697986443837483

Epoch: 6| Step: 13
Training loss: 0.7557429671287537
Validation loss: 1.953245182832082

Epoch: 201| Step: 0
Training loss: 1.0839052200317383
Validation loss: 1.977318028608958

Epoch: 6| Step: 1
Training loss: 0.5950013399124146
Validation loss: 1.9627787272135417

Epoch: 6| Step: 2
Training loss: 0.8437662124633789
Validation loss: 1.9518319169680278

Epoch: 6| Step: 3
Training loss: 0.8249409198760986
Validation loss: 1.9849317868550618

Epoch: 6| Step: 4
Training loss: 0.7182847261428833
Validation loss: 1.9525216023127239

Epoch: 6| Step: 5
Training loss: 0.5816136598587036
Validation loss: 1.9746251702308655

Epoch: 6| Step: 6
Training loss: 0.485077828168869
Validation loss: 1.9325663844744365

Epoch: 6| Step: 7
Training loss: 0.7980101108551025
Validation loss: 1.9563413461049397

Epoch: 6| Step: 8
Training loss: 0.8267068862915039
Validation loss: 2.0247999827067056

Epoch: 6| Step: 9
Training loss: 1.1097495555877686
Validation loss: 1.9872232675552368

Epoch: 6| Step: 10
Training loss: 0.46671974658966064
Validation loss: 2.0027794241905212

Epoch: 6| Step: 11
Training loss: 0.5464361906051636
Validation loss: 2.006156583627065

Epoch: 6| Step: 12
Training loss: 0.6061903238296509
Validation loss: 1.985028584798177

Epoch: 6| Step: 13
Training loss: 0.6064865589141846
Validation loss: 1.9559099276860554

Epoch: 202| Step: 0
Training loss: 0.7852660417556763
Validation loss: 1.960123876730601

Epoch: 6| Step: 1
Training loss: 0.44161170721054077
Validation loss: 2.023626208305359

Epoch: 6| Step: 2
Training loss: 0.7473734617233276
Validation loss: 2.011808454990387

Epoch: 6| Step: 3
Training loss: 0.8394958972930908
Validation loss: 1.9590113560358684

Epoch: 6| Step: 4
Training loss: 0.853973388671875
Validation loss: 2.0022739370663962

Epoch: 6| Step: 5
Training loss: 0.9257150888442993
Validation loss: 1.9801451365152996

Epoch: 6| Step: 6
Training loss: 0.690567672252655
Validation loss: 1.9751111070315044

Epoch: 6| Step: 7
Training loss: 0.6743502020835876
Validation loss: 2.0066974759101868

Epoch: 6| Step: 8
Training loss: 0.6316837072372437
Validation loss: 1.965807278951009

Epoch: 6| Step: 9
Training loss: 0.549209713935852
Validation loss: 2.026237110296885

Epoch: 6| Step: 10
Training loss: 0.5042667388916016
Validation loss: 2.004429280757904

Epoch: 6| Step: 11
Training loss: 0.546822190284729
Validation loss: 1.985305666923523

Epoch: 6| Step: 12
Training loss: 0.8383682370185852
Validation loss: 1.9472996195157368

Epoch: 6| Step: 13
Training loss: 0.7242177128791809
Validation loss: 1.925494650999705

Epoch: 203| Step: 0
Training loss: 1.2014917135238647
Validation loss: 1.9616492787996929

Epoch: 6| Step: 1
Training loss: 0.2941758632659912
Validation loss: 2.0057165026664734

Epoch: 6| Step: 2
Training loss: 0.45519915223121643
Validation loss: 2.0265175302823386

Epoch: 6| Step: 3
Training loss: 0.41558608412742615
Validation loss: 1.9832210540771484

Epoch: 6| Step: 4
Training loss: 0.6921527981758118
Validation loss: 2.025270462036133

Epoch: 6| Step: 5
Training loss: 0.609282374382019
Validation loss: 1.9771414597829182

Epoch: 6| Step: 6
Training loss: 0.7145830392837524
Validation loss: 1.9804474314053853

Epoch: 6| Step: 7
Training loss: 0.5179096460342407
Validation loss: 1.996086577574412

Epoch: 6| Step: 8
Training loss: 0.6340472102165222
Validation loss: 1.962090253829956

Epoch: 6| Step: 9
Training loss: 0.7080355882644653
Validation loss: 1.9870279630025227

Epoch: 6| Step: 10
Training loss: 1.3106025457382202
Validation loss: 2.0273742278416953

Epoch: 6| Step: 11
Training loss: 0.8426509499549866
Validation loss: 2.0043405095736184

Epoch: 6| Step: 12
Training loss: 1.2080862522125244
Validation loss: 2.0215219259262085

Epoch: 6| Step: 13
Training loss: 0.5507069826126099
Validation loss: 1.9724289973576863

Epoch: 204| Step: 0
Training loss: 0.7905990481376648
Validation loss: 1.9982683261235554

Epoch: 6| Step: 1
Training loss: 0.3701767325401306
Validation loss: 1.9819996356964111

Epoch: 6| Step: 2
Training loss: 0.8178231716156006
Validation loss: 2.066534996032715

Epoch: 6| Step: 3
Training loss: 0.5540735125541687
Validation loss: 2.051577389240265

Epoch: 6| Step: 4
Training loss: 0.4656780958175659
Validation loss: 2.0263066490491233

Epoch: 6| Step: 5
Training loss: 1.2023860216140747
Validation loss: 1.9973201950391133

Epoch: 6| Step: 6
Training loss: 0.3924578130245209
Validation loss: 1.9932056069374084

Epoch: 6| Step: 7
Training loss: 0.5345920324325562
Validation loss: 2.011183182398478

Epoch: 6| Step: 8
Training loss: 0.39925017952919006
Validation loss: 2.016368885835012

Epoch: 6| Step: 9
Training loss: 1.505226969718933
Validation loss: 2.0204466581344604

Epoch: 6| Step: 10
Training loss: 1.444528579711914
Validation loss: 1.9715032776196797

Epoch: 6| Step: 11
Training loss: 0.7296472191810608
Validation loss: 1.9553748567899067

Epoch: 6| Step: 12
Training loss: 0.5704643726348877
Validation loss: 1.99521537621816

Epoch: 6| Step: 13
Training loss: 0.29684412479400635
Validation loss: 1.973227063814799

Epoch: 205| Step: 0
Training loss: 0.785725474357605
Validation loss: 1.9742971460024517

Epoch: 6| Step: 1
Training loss: 0.9698037505149841
Validation loss: 1.9933751424153645

Epoch: 6| Step: 2
Training loss: 0.5567930936813354
Validation loss: 1.9621922771135967

Epoch: 6| Step: 3
Training loss: 0.6933186650276184
Validation loss: 1.9668736259142559

Epoch: 6| Step: 4
Training loss: 0.6120998859405518
Validation loss: 1.996805489063263

Epoch: 6| Step: 5
Training loss: 0.6282039880752563
Validation loss: 1.9672751228014629

Epoch: 6| Step: 6
Training loss: 0.9725086688995361
Validation loss: 1.990085283915202

Epoch: 6| Step: 7
Training loss: 0.7714110612869263
Validation loss: 1.963969846566518

Epoch: 6| Step: 8
Training loss: 0.7070978879928589
Validation loss: 1.985450029373169

Epoch: 6| Step: 9
Training loss: 0.5069513320922852
Validation loss: 1.9558787941932678

Epoch: 6| Step: 10
Training loss: 0.5879708528518677
Validation loss: 2.010814368724823

Epoch: 6| Step: 11
Training loss: 0.5182805061340332
Validation loss: 1.9543146689732869

Epoch: 6| Step: 12
Training loss: 0.6395893096923828
Validation loss: 1.948053002357483

Epoch: 6| Step: 13
Training loss: 0.9994699954986572
Validation loss: 2.000717560450236

Epoch: 206| Step: 0
Training loss: 0.6773629188537598
Validation loss: 1.9867396354675293

Epoch: 6| Step: 1
Training loss: 0.678748607635498
Validation loss: 2.003493865331014

Epoch: 6| Step: 2
Training loss: 0.43518972396850586
Validation loss: 1.9705923398335774

Epoch: 6| Step: 3
Training loss: 0.5563923120498657
Validation loss: 1.9728460907936096

Epoch: 6| Step: 4
Training loss: 0.48442506790161133
Validation loss: 2.0037415623664856

Epoch: 6| Step: 5
Training loss: 0.9418051838874817
Validation loss: 1.9940902988115947

Epoch: 6| Step: 6
Training loss: 0.4924532175064087
Validation loss: 1.996276577313741

Epoch: 6| Step: 7
Training loss: 0.774468719959259
Validation loss: 1.9943524400393169

Epoch: 6| Step: 8
Training loss: 0.495556503534317
Validation loss: 1.9704861839612324

Epoch: 6| Step: 9
Training loss: 0.9355061054229736
Validation loss: 1.9838764071464539

Epoch: 6| Step: 10
Training loss: 1.0091865062713623
Validation loss: 1.9916340907414753

Epoch: 6| Step: 11
Training loss: 0.7653670907020569
Validation loss: 2.0318490068117776

Epoch: 6| Step: 12
Training loss: 0.7886170148849487
Validation loss: 1.965316613515218

Epoch: 6| Step: 13
Training loss: 0.7353788018226624
Validation loss: 1.971813678741455

Epoch: 207| Step: 0
Training loss: 1.0823453664779663
Validation loss: 2.014999826749166

Epoch: 6| Step: 1
Training loss: 0.8707795143127441
Validation loss: 2.0041125218073526

Epoch: 6| Step: 2
Training loss: 0.7806658744812012
Validation loss: 2.0311084588368735

Epoch: 6| Step: 3
Training loss: 0.5622909665107727
Validation loss: 1.9785455862681072

Epoch: 6| Step: 4
Training loss: 0.6991004347801208
Validation loss: 1.981493393580119

Epoch: 6| Step: 5
Training loss: 0.6128252744674683
Validation loss: 1.9702021876970928

Epoch: 6| Step: 6
Training loss: 0.6689416170120239
Validation loss: 1.9576491713523865

Epoch: 6| Step: 7
Training loss: 0.7432668209075928
Validation loss: 1.9855554302533467

Epoch: 6| Step: 8
Training loss: 1.3291679620742798
Validation loss: 1.9857203364372253

Epoch: 6| Step: 9
Training loss: 0.5668796300888062
Validation loss: 1.976145366827647

Epoch: 6| Step: 10
Training loss: 0.6180005073547363
Validation loss: 1.9730465412139893

Epoch: 6| Step: 11
Training loss: 0.610491156578064
Validation loss: 1.9573650161425273

Epoch: 6| Step: 12
Training loss: 0.41675475239753723
Validation loss: 1.981792688369751

Epoch: 6| Step: 13
Training loss: 0.49641919136047363
Validation loss: 1.949199418226878

Epoch: 208| Step: 0
Training loss: 0.7784563302993774
Validation loss: 1.9962307810783386

Epoch: 6| Step: 1
Training loss: 0.6435397863388062
Validation loss: 1.9602230787277222

Epoch: 6| Step: 2
Training loss: 0.646354615688324
Validation loss: 1.970655123392741

Epoch: 6| Step: 3
Training loss: 0.8113025426864624
Validation loss: 1.9789130886395772

Epoch: 6| Step: 4
Training loss: 0.6138453483581543
Validation loss: 1.9481754104296367

Epoch: 6| Step: 5
Training loss: 0.9328612089157104
Validation loss: 1.9901792407035828

Epoch: 6| Step: 6
Training loss: 0.42560580372810364
Validation loss: 1.9731085896492004

Epoch: 6| Step: 7
Training loss: 0.8227394819259644
Validation loss: 2.020498355229696

Epoch: 6| Step: 8
Training loss: 1.2618932723999023
Validation loss: 2.0101002057393393

Epoch: 6| Step: 9
Training loss: 0.4702954888343811
Validation loss: 1.9646655718485515

Epoch: 6| Step: 10
Training loss: 0.2560594081878662
Validation loss: 1.9524701237678528

Epoch: 6| Step: 11
Training loss: 0.6780896186828613
Validation loss: 1.9671152035395305

Epoch: 6| Step: 12
Training loss: 0.743343710899353
Validation loss: 1.9598057866096497

Epoch: 6| Step: 13
Training loss: 0.6167517900466919
Validation loss: 1.9712777733802795

Epoch: 209| Step: 0
Training loss: 0.383535236120224
Validation loss: 2.009410858154297

Epoch: 6| Step: 1
Training loss: 0.7489290237426758
Validation loss: 1.9541631539662678

Epoch: 6| Step: 2
Training loss: 0.7097996473312378
Validation loss: 1.9420334299405415

Epoch: 6| Step: 3
Training loss: 0.5268059372901917
Validation loss: 2.0009520848592124

Epoch: 6| Step: 4
Training loss: 0.7673221230506897
Validation loss: 1.9738171100616455

Epoch: 6| Step: 5
Training loss: 1.2885057926177979
Validation loss: 2.0036827325820923

Epoch: 6| Step: 6
Training loss: 0.6609651446342468
Validation loss: 1.9969215591748555

Epoch: 6| Step: 7
Training loss: 0.9938469529151917
Validation loss: 2.0089783867200217

Epoch: 6| Step: 8
Training loss: 0.34553277492523193
Validation loss: 2.002086043357849

Epoch: 6| Step: 9
Training loss: 0.5712516903877258
Validation loss: 1.985854685306549

Epoch: 6| Step: 10
Training loss: 0.3803758919239044
Validation loss: 1.9572996894518535

Epoch: 6| Step: 11
Training loss: 0.9231572151184082
Validation loss: 1.963440438111623

Epoch: 6| Step: 12
Training loss: 0.5017783641815186
Validation loss: 1.9464585582415264

Epoch: 6| Step: 13
Training loss: 0.40610432624816895
Validation loss: 1.9815203150113423

Epoch: 210| Step: 0
Training loss: 1.0367003679275513
Validation loss: 1.9823883175849915

Epoch: 6| Step: 1
Training loss: 0.8101792931556702
Validation loss: 1.9780818819999695

Epoch: 6| Step: 2
Training loss: 0.6868990659713745
Validation loss: 2.0118945240974426

Epoch: 6| Step: 3
Training loss: 0.7826614379882812
Validation loss: 1.9491750995318096

Epoch: 6| Step: 4
Training loss: 0.6741275787353516
Validation loss: 1.9577311873435974

Epoch: 6| Step: 5
Training loss: 0.7215781211853027
Validation loss: 1.9458755453427632

Epoch: 6| Step: 6
Training loss: 0.49581965804100037
Validation loss: 1.9927725791931152

Epoch: 6| Step: 7
Training loss: 0.8096281886100769
Validation loss: 1.9847401976585388

Epoch: 6| Step: 8
Training loss: 0.36015570163726807
Validation loss: 2.0009446938832602

Epoch: 6| Step: 9
Training loss: 0.6177653670310974
Validation loss: 1.9629817406336467

Epoch: 6| Step: 10
Training loss: 0.6114961504936218
Validation loss: 1.980155110359192

Epoch: 6| Step: 11
Training loss: 0.6233642101287842
Validation loss: 2.0222194592158

Epoch: 6| Step: 12
Training loss: 0.6453493237495422
Validation loss: 1.9500858982404072

Epoch: 6| Step: 13
Training loss: 0.8114895820617676
Validation loss: 1.9808698296546936

Epoch: 211| Step: 0
Training loss: 0.5038789510726929
Validation loss: 2.0452632904052734

Epoch: 6| Step: 1
Training loss: 0.7145430445671082
Validation loss: 1.9735377430915833

Epoch: 6| Step: 2
Training loss: 1.0538933277130127
Validation loss: 1.9813813765843709

Epoch: 6| Step: 3
Training loss: 0.7595811486244202
Validation loss: 1.9896511038144429

Epoch: 6| Step: 4
Training loss: 0.6927300691604614
Validation loss: 1.9917962153752644

Epoch: 6| Step: 5
Training loss: 0.4071490168571472
Validation loss: 2.027418573697408

Epoch: 6| Step: 6
Training loss: 0.4948081374168396
Validation loss: 1.9683603644371033

Epoch: 6| Step: 7
Training loss: 0.44342291355133057
Validation loss: 1.9981395602226257

Epoch: 6| Step: 8
Training loss: 0.8599712252616882
Validation loss: 1.9892431100209553

Epoch: 6| Step: 9
Training loss: 0.5757226943969727
Validation loss: 1.9859817226727803

Epoch: 6| Step: 10
Training loss: 0.9458866119384766
Validation loss: 2.0094860593477883

Epoch: 6| Step: 11
Training loss: 1.0563442707061768
Validation loss: 1.9985634287198384

Epoch: 6| Step: 12
Training loss: 0.8085145950317383
Validation loss: 2.015073041121165

Epoch: 6| Step: 13
Training loss: 0.30491751432418823
Validation loss: 1.9899086554845173

Epoch: 212| Step: 0
Training loss: 0.4575828015804291
Validation loss: 1.9680197437604268

Epoch: 6| Step: 1
Training loss: 0.8377870917320251
Validation loss: 2.0002653201421103

Epoch: 6| Step: 2
Training loss: 0.4579107165336609
Validation loss: 2.0362106362978616

Epoch: 6| Step: 3
Training loss: 0.4660017490386963
Validation loss: 2.027324100335439

Epoch: 6| Step: 4
Training loss: 0.5977284908294678
Validation loss: 2.025765816370646

Epoch: 6| Step: 5
Training loss: 1.0026625394821167
Validation loss: 2.0001521905263266

Epoch: 6| Step: 6
Training loss: 0.4328136742115021
Validation loss: 2.0315282742182412

Epoch: 6| Step: 7
Training loss: 0.3966361880302429
Validation loss: 2.0089520613352456

Epoch: 6| Step: 8
Training loss: 0.654251217842102
Validation loss: 1.977097988128662

Epoch: 6| Step: 9
Training loss: 0.5850381255149841
Validation loss: 1.9928038914998372

Epoch: 6| Step: 10
Training loss: 1.1344385147094727
Validation loss: 1.9560133814811707

Epoch: 6| Step: 11
Training loss: 0.6090892553329468
Validation loss: 1.9947129487991333

Epoch: 6| Step: 12
Training loss: 0.5323904752731323
Validation loss: 1.9565548698107402

Epoch: 6| Step: 13
Training loss: 1.0519460439682007
Validation loss: 1.9873760143915813

Epoch: 213| Step: 0
Training loss: 0.40060728788375854
Validation loss: 1.9409424265225728

Epoch: 6| Step: 1
Training loss: 0.7122196555137634
Validation loss: 1.9842296640078227

Epoch: 6| Step: 2
Training loss: 0.5013741850852966
Validation loss: 2.001631796360016

Epoch: 6| Step: 3
Training loss: 0.6553255915641785
Validation loss: 2.0245348811149597

Epoch: 6| Step: 4
Training loss: 0.7025934457778931
Validation loss: 2.0145344734191895

Epoch: 6| Step: 5
Training loss: 0.8763495683670044
Validation loss: 1.9799957871437073

Epoch: 6| Step: 6
Training loss: 0.8435903191566467
Validation loss: 1.9944736957550049

Epoch: 6| Step: 7
Training loss: 0.6455317735671997
Validation loss: 1.966626485188802

Epoch: 6| Step: 8
Training loss: 0.7254259586334229
Validation loss: 1.9822992881139119

Epoch: 6| Step: 9
Training loss: 0.43223413825035095
Validation loss: 2.0082035660743713

Epoch: 6| Step: 10
Training loss: 1.4671339988708496
Validation loss: 1.9865317344665527

Epoch: 6| Step: 11
Training loss: 0.7035369873046875
Validation loss: 1.9852189620335896

Epoch: 6| Step: 12
Training loss: 0.39569470286369324
Validation loss: 1.9517011443773906

Epoch: 6| Step: 13
Training loss: 0.7576051950454712
Validation loss: 2.016575117905935

Epoch: 214| Step: 0
Training loss: 0.43748894333839417
Validation loss: 1.9560872117678325

Epoch: 6| Step: 1
Training loss: 0.6198538541793823
Validation loss: 1.9923609296480815

Epoch: 6| Step: 2
Training loss: 0.859959602355957
Validation loss: 1.9637375473976135

Epoch: 6| Step: 3
Training loss: 0.7198977470397949
Validation loss: 1.9748297731081645

Epoch: 6| Step: 4
Training loss: 0.4044122099876404
Validation loss: 2.0343894958496094

Epoch: 6| Step: 5
Training loss: 0.7091917395591736
Validation loss: 1.9710564414660137

Epoch: 6| Step: 6
Training loss: 0.362149715423584
Validation loss: 1.9676753083864849

Epoch: 6| Step: 7
Training loss: 0.3790198266506195
Validation loss: 1.9888478716214497

Epoch: 6| Step: 8
Training loss: 0.5220277905464172
Validation loss: 1.9669147729873657

Epoch: 6| Step: 9
Training loss: 0.9423614740371704
Validation loss: 2.0030033389727273

Epoch: 6| Step: 10
Training loss: 1.0801461935043335
Validation loss: 1.9791456858317058

Epoch: 6| Step: 11
Training loss: 1.2490675449371338
Validation loss: 1.978111704190572

Epoch: 6| Step: 12
Training loss: 0.43848520517349243
Validation loss: 1.9891725579897563

Epoch: 6| Step: 13
Training loss: 0.340742826461792
Validation loss: 1.9950682520866394

Epoch: 215| Step: 0
Training loss: 1.124521017074585
Validation loss: 1.9945821563402812

Epoch: 6| Step: 1
Training loss: 0.7943299412727356
Validation loss: 1.9829984704653423

Epoch: 6| Step: 2
Training loss: 0.5053977370262146
Validation loss: 1.9664291342099507

Epoch: 6| Step: 3
Training loss: 0.919973611831665
Validation loss: 1.9919984539349873

Epoch: 6| Step: 4
Training loss: 1.091972827911377
Validation loss: 1.9924680987993877

Epoch: 6| Step: 5
Training loss: 0.5675278306007385
Validation loss: 1.9570286870002747

Epoch: 6| Step: 6
Training loss: 0.5515177845954895
Validation loss: 1.9961612820625305

Epoch: 6| Step: 7
Training loss: 0.36930224299430847
Validation loss: 1.988959054152171

Epoch: 6| Step: 8
Training loss: 0.8080074787139893
Validation loss: 2.042975048224131

Epoch: 6| Step: 9
Training loss: 0.4512321352958679
Validation loss: 1.9886702100435893

Epoch: 6| Step: 10
Training loss: 0.7244979739189148
Validation loss: 2.0019131104151406

Epoch: 6| Step: 11
Training loss: 0.418877512216568
Validation loss: 2.0024141470591226

Epoch: 6| Step: 12
Training loss: 0.5159479379653931
Validation loss: 1.9608104825019836

Epoch: 6| Step: 13
Training loss: 0.5987868309020996
Validation loss: 1.9763675332069397

Epoch: 216| Step: 0
Training loss: 0.695551335811615
Validation loss: 2.0041369795799255

Epoch: 6| Step: 1
Training loss: 0.7689172029495239
Validation loss: 1.979931612809499

Epoch: 6| Step: 2
Training loss: 0.8683110475540161
Validation loss: 1.98220028479894

Epoch: 6| Step: 3
Training loss: 0.7782968282699585
Validation loss: 2.0034693082173667

Epoch: 6| Step: 4
Training loss: 0.4083026647567749
Validation loss: 1.983267883459727

Epoch: 6| Step: 5
Training loss: 0.8337252736091614
Validation loss: 2.021474043528239

Epoch: 6| Step: 6
Training loss: 0.5766531825065613
Validation loss: 1.9722445607185364

Epoch: 6| Step: 7
Training loss: 0.32789933681488037
Validation loss: 1.9532084465026855

Epoch: 6| Step: 8
Training loss: 1.0186207294464111
Validation loss: 1.9925140738487244

Epoch: 6| Step: 9
Training loss: 0.6576950550079346
Validation loss: 1.9713446895281475

Epoch: 6| Step: 10
Training loss: 0.40311408042907715
Validation loss: 1.9892364939053853

Epoch: 6| Step: 11
Training loss: 0.5451678037643433
Validation loss: 2.007166067759196

Epoch: 6| Step: 12
Training loss: 0.3542899489402771
Validation loss: 2.007707099119822

Epoch: 6| Step: 13
Training loss: 0.7225599884986877
Validation loss: 1.9683893322944641

Epoch: 217| Step: 0
Training loss: 0.7820723056793213
Validation loss: 1.958952526251475

Epoch: 6| Step: 1
Training loss: 0.632805347442627
Validation loss: 1.9610071380933125

Epoch: 6| Step: 2
Training loss: 0.7546319961547852
Validation loss: 1.98816579580307

Epoch: 6| Step: 3
Training loss: 0.4575308561325073
Validation loss: 1.9733933210372925

Epoch: 6| Step: 4
Training loss: 0.7339889407157898
Validation loss: 1.9544102152188618

Epoch: 6| Step: 5
Training loss: 0.8130914568901062
Validation loss: 2.006228446960449

Epoch: 6| Step: 6
Training loss: 0.38775721192359924
Validation loss: 1.9690767526626587

Epoch: 6| Step: 7
Training loss: 0.6133865118026733
Validation loss: 2.002733747164408

Epoch: 6| Step: 8
Training loss: 0.7972548007965088
Validation loss: 1.9781939188639324

Epoch: 6| Step: 9
Training loss: 0.7711960077285767
Validation loss: 1.9664594332377117

Epoch: 6| Step: 10
Training loss: 0.7537946105003357
Validation loss: 1.98617821931839

Epoch: 6| Step: 11
Training loss: 0.9724794626235962
Validation loss: 1.9934060374895732

Epoch: 6| Step: 12
Training loss: 0.7631121277809143
Validation loss: 2.008454362551371

Epoch: 6| Step: 13
Training loss: 0.46862488985061646
Validation loss: 1.9874637126922607

Epoch: 218| Step: 0
Training loss: 0.598024308681488
Validation loss: 1.9683637122313182

Epoch: 6| Step: 1
Training loss: 0.28911569714546204
Validation loss: 2.020141919453939

Epoch: 6| Step: 2
Training loss: 0.6629071235656738
Validation loss: 2.0086400707562766

Epoch: 6| Step: 3
Training loss: 0.36224403977394104
Validation loss: 1.9728593627611797

Epoch: 6| Step: 4
Training loss: 0.8734720945358276
Validation loss: 2.023625612258911

Epoch: 6| Step: 5
Training loss: 0.47487062215805054
Validation loss: 2.01150510708491

Epoch: 6| Step: 6
Training loss: 0.7041463851928711
Validation loss: 2.0383461117744446

Epoch: 6| Step: 7
Training loss: 0.5607298612594604
Validation loss: 2.0336961348851523

Epoch: 6| Step: 8
Training loss: 0.6349650025367737
Validation loss: 2.019978721936544

Epoch: 6| Step: 9
Training loss: 0.7316288948059082
Validation loss: 2.0250380833943686

Epoch: 6| Step: 10
Training loss: 0.8519020676612854
Validation loss: 2.0193941394488015

Epoch: 6| Step: 11
Training loss: 0.8596282005310059
Validation loss: 1.9948216279347737

Epoch: 6| Step: 12
Training loss: 0.6195473074913025
Validation loss: 2.0015941659609475

Epoch: 6| Step: 13
Training loss: 1.0727698802947998
Validation loss: 1.9618033369382222

Epoch: 219| Step: 0
Training loss: 0.5745315551757812
Validation loss: 1.9751927256584167

Epoch: 6| Step: 1
Training loss: 0.41829612851142883
Validation loss: 2.008508086204529

Epoch: 6| Step: 2
Training loss: 1.0689871311187744
Validation loss: 2.004049559434255

Epoch: 6| Step: 3
Training loss: 0.47789645195007324
Validation loss: 2.052525301774343

Epoch: 6| Step: 4
Training loss: 1.0036967992782593
Validation loss: 2.0235755443573

Epoch: 6| Step: 5
Training loss: 0.5521694421768188
Validation loss: 1.992863138516744

Epoch: 6| Step: 6
Training loss: 0.8119912147521973
Validation loss: 1.9821343223253887

Epoch: 6| Step: 7
Training loss: 0.5357273817062378
Validation loss: 2.001776397228241

Epoch: 6| Step: 8
Training loss: 0.6039946675300598
Validation loss: 1.9830411275227864

Epoch: 6| Step: 9
Training loss: 0.9565653800964355
Validation loss: 1.9780310988426208

Epoch: 6| Step: 10
Training loss: 0.8297261595726013
Validation loss: 2.0052042802174888

Epoch: 6| Step: 11
Training loss: 0.8210416436195374
Validation loss: 2.004765590031942

Epoch: 6| Step: 12
Training loss: 0.548992395401001
Validation loss: 1.981169621149699

Epoch: 6| Step: 13
Training loss: 0.4711941182613373
Validation loss: 2.0001386801401773

Epoch: 220| Step: 0
Training loss: 0.8443495035171509
Validation loss: 1.9548321962356567

Epoch: 6| Step: 1
Training loss: 0.7123185396194458
Validation loss: 1.9757971167564392

Epoch: 6| Step: 2
Training loss: 0.6993928551673889
Validation loss: 1.9959195057551067

Epoch: 6| Step: 3
Training loss: 0.6486300230026245
Validation loss: 2.0213943322499595

Epoch: 6| Step: 4
Training loss: 0.6153737306594849
Validation loss: 2.002078910668691

Epoch: 6| Step: 5
Training loss: 0.752017617225647
Validation loss: 1.982627272605896

Epoch: 6| Step: 6
Training loss: 0.4395667612552643
Validation loss: 2.041967729727427

Epoch: 6| Step: 7
Training loss: 0.3691076338291168
Validation loss: 1.9970842997233074

Epoch: 6| Step: 8
Training loss: 0.7512756586074829
Validation loss: 1.992030680179596

Epoch: 6| Step: 9
Training loss: 0.7877890467643738
Validation loss: 2.0022963484128318

Epoch: 6| Step: 10
Training loss: 0.9234599471092224
Validation loss: 1.9544686277707417

Epoch: 6| Step: 11
Training loss: 0.623721182346344
Validation loss: 1.9874845345815022

Epoch: 6| Step: 12
Training loss: 0.6810379028320312
Validation loss: 2.007594128449758

Epoch: 6| Step: 13
Training loss: 0.32223740220069885
Validation loss: 2.0050823092460632

Epoch: 221| Step: 0
Training loss: 0.39284372329711914
Validation loss: 1.9395228226979573

Epoch: 6| Step: 1
Training loss: 0.8204168081283569
Validation loss: 2.011887709299723

Epoch: 6| Step: 2
Training loss: 0.3743119239807129
Validation loss: 1.984527548154195

Epoch: 6| Step: 3
Training loss: 0.5449422597885132
Validation loss: 1.9774728020032246

Epoch: 6| Step: 4
Training loss: 1.060481309890747
Validation loss: 1.9680221279462178

Epoch: 6| Step: 5
Training loss: 0.3161148130893707
Validation loss: 2.005134125550588

Epoch: 6| Step: 6
Training loss: 1.0751196146011353
Validation loss: 1.9870062073071797

Epoch: 6| Step: 7
Training loss: 0.4697212874889374
Validation loss: 1.9862868984540303

Epoch: 6| Step: 8
Training loss: 0.8945091962814331
Validation loss: 2.022894819577535

Epoch: 6| Step: 9
Training loss: 0.7243651747703552
Validation loss: 2.011599898338318

Epoch: 6| Step: 10
Training loss: 0.7616098523139954
Validation loss: 2.0019795497258506

Epoch: 6| Step: 11
Training loss: 0.6563838124275208
Validation loss: 1.9812068144480388

Epoch: 6| Step: 12
Training loss: 0.2647241950035095
Validation loss: 2.0026397903760276

Epoch: 6| Step: 13
Training loss: 0.5263307094573975
Validation loss: 2.006281395753225

Epoch: 222| Step: 0
Training loss: 0.41991549730300903
Validation loss: 1.9984579682350159

Epoch: 6| Step: 1
Training loss: 0.35087665915489197
Validation loss: 2.002261300881704

Epoch: 6| Step: 2
Training loss: 0.36451077461242676
Validation loss: 1.9564911325772603

Epoch: 6| Step: 3
Training loss: 0.9036167860031128
Validation loss: 1.9903433918952942

Epoch: 6| Step: 4
Training loss: 0.6900969743728638
Validation loss: 1.9796743392944336

Epoch: 6| Step: 5
Training loss: 0.41067346930503845
Validation loss: 1.99427596728007

Epoch: 6| Step: 6
Training loss: 0.6579961180686951
Validation loss: 1.9689656694730122

Epoch: 6| Step: 7
Training loss: 0.7797605991363525
Validation loss: 1.9967612624168396

Epoch: 6| Step: 8
Training loss: 0.8764572143554688
Validation loss: 1.996079723040263

Epoch: 6| Step: 9
Training loss: 0.395813524723053
Validation loss: 1.973517378171285

Epoch: 6| Step: 10
Training loss: 0.653982400894165
Validation loss: 1.9655283689498901

Epoch: 6| Step: 11
Training loss: 0.8878265619277954
Validation loss: 1.965017855167389

Epoch: 6| Step: 12
Training loss: 0.6415595412254333
Validation loss: 1.940136472384135

Epoch: 6| Step: 13
Training loss: 0.5995939373970032
Validation loss: 1.983646313349406

Epoch: 223| Step: 0
Training loss: 0.6488912105560303
Validation loss: 1.967992107073466

Epoch: 6| Step: 1
Training loss: 0.7446712851524353
Validation loss: 2.017112155755361

Epoch: 6| Step: 2
Training loss: 0.7069681882858276
Validation loss: 1.989288568496704

Epoch: 6| Step: 3
Training loss: 0.4245908558368683
Validation loss: 1.9730360706647236

Epoch: 6| Step: 4
Training loss: 0.7698668837547302
Validation loss: 1.9843818545341492

Epoch: 6| Step: 5
Training loss: 0.3784406781196594
Validation loss: 1.9814268350601196

Epoch: 6| Step: 6
Training loss: 0.4980241060256958
Validation loss: 2.005033632119497

Epoch: 6| Step: 7
Training loss: 0.9526370763778687
Validation loss: 1.98630424340566

Epoch: 6| Step: 8
Training loss: 0.7519619464874268
Validation loss: 1.995297114054362

Epoch: 6| Step: 9
Training loss: 0.7600458264350891
Validation loss: 2.020634134610494

Epoch: 6| Step: 10
Training loss: 0.676348090171814
Validation loss: 1.984284500281016

Epoch: 6| Step: 11
Training loss: 0.8317636251449585
Validation loss: 2.0381340384483337

Epoch: 6| Step: 12
Training loss: 0.7394876480102539
Validation loss: 1.9733907580375671

Epoch: 6| Step: 13
Training loss: 0.4421783685684204
Validation loss: 1.9940760533014934

Epoch: 224| Step: 0
Training loss: 0.34342044591903687
Validation loss: 2.014556129773458

Epoch: 6| Step: 1
Training loss: 0.9773769974708557
Validation loss: 1.9447354475657146

Epoch: 6| Step: 2
Training loss: 0.44288718700408936
Validation loss: 2.0167312224706015

Epoch: 6| Step: 3
Training loss: 0.17004813253879547
Validation loss: 2.0391440391540527

Epoch: 6| Step: 4
Training loss: 0.7555167078971863
Validation loss: 1.9933842619260151

Epoch: 6| Step: 5
Training loss: 1.01333487033844
Validation loss: 2.054216424624125

Epoch: 6| Step: 6
Training loss: 0.7159322500228882
Validation loss: 2.000065545241038

Epoch: 6| Step: 7
Training loss: 0.8477344512939453
Validation loss: 2.0132741729418435

Epoch: 6| Step: 8
Training loss: 0.6865248680114746
Validation loss: 1.981263558069865

Epoch: 6| Step: 9
Training loss: 0.4470224976539612
Validation loss: 2.0088837146759033

Epoch: 6| Step: 10
Training loss: 0.6879305839538574
Validation loss: 2.0052826603253684

Epoch: 6| Step: 11
Training loss: 0.6418798565864563
Validation loss: 1.9898125330607097

Epoch: 6| Step: 12
Training loss: 0.49721845984458923
Validation loss: 1.9872556328773499

Epoch: 6| Step: 13
Training loss: 0.38455191254615784
Validation loss: 1.999823530515035

Epoch: 225| Step: 0
Training loss: 0.8013386726379395
Validation loss: 2.0114925305048623

Epoch: 6| Step: 1
Training loss: 0.6566197872161865
Validation loss: 1.9654762744903564

Epoch: 6| Step: 2
Training loss: 0.477883517742157
Validation loss: 2.02849143743515

Epoch: 6| Step: 3
Training loss: 0.5844085216522217
Validation loss: 1.9762235879898071

Epoch: 6| Step: 4
Training loss: 0.49574142694473267
Validation loss: 2.02675728003184

Epoch: 6| Step: 5
Training loss: 0.29260432720184326
Validation loss: 2.0024781028429666

Epoch: 6| Step: 6
Training loss: 0.6649584174156189
Validation loss: 1.98394380013148

Epoch: 6| Step: 7
Training loss: 0.4805419445037842
Validation loss: 1.9721424579620361

Epoch: 6| Step: 8
Training loss: 0.39765310287475586
Validation loss: 1.9654761751492817

Epoch: 6| Step: 9
Training loss: 0.5830185413360596
Validation loss: 2.0144115487734475

Epoch: 6| Step: 10
Training loss: 0.34699904918670654
Validation loss: 2.0025883118311563

Epoch: 6| Step: 11
Training loss: 1.0857075452804565
Validation loss: 1.9576095938682556

Epoch: 6| Step: 12
Training loss: 0.8526683449745178
Validation loss: 2.0158789356549582

Epoch: 6| Step: 13
Training loss: 0.6369612216949463
Validation loss: 1.9842829902966816

Epoch: 226| Step: 0
Training loss: 0.48484912514686584
Validation loss: 1.9705125490824382

Epoch: 6| Step: 1
Training loss: 0.46230196952819824
Validation loss: 1.9768484234809875

Epoch: 6| Step: 2
Training loss: 0.6115643978118896
Validation loss: 2.006891151269277

Epoch: 6| Step: 3
Training loss: 0.733630359172821
Validation loss: 1.998338222503662

Epoch: 6| Step: 4
Training loss: 0.6850425004959106
Validation loss: 1.9947219689687092

Epoch: 6| Step: 5
Training loss: 0.5290204882621765
Validation loss: 2.015179614226023

Epoch: 6| Step: 6
Training loss: 0.8192512392997742
Validation loss: 1.9649144411087036

Epoch: 6| Step: 7
Training loss: 0.7417895793914795
Validation loss: 1.9900062282880147

Epoch: 6| Step: 8
Training loss: 0.5862540006637573
Validation loss: 2.006348709265391

Epoch: 6| Step: 9
Training loss: 0.8849271535873413
Validation loss: 1.984337866306305

Epoch: 6| Step: 10
Training loss: 1.0276581048965454
Validation loss: 1.9837448596954346

Epoch: 6| Step: 11
Training loss: 0.43872714042663574
Validation loss: 1.991432011127472

Epoch: 6| Step: 12
Training loss: 0.571395754814148
Validation loss: 2.050083041191101

Epoch: 6| Step: 13
Training loss: 0.367869108915329
Validation loss: 2.0313724478085837

Epoch: 227| Step: 0
Training loss: 1.3618484735488892
Validation loss: 2.0237698753674827

Epoch: 6| Step: 1
Training loss: 0.6266977190971375
Validation loss: 2.0047436356544495

Epoch: 6| Step: 2
Training loss: 0.4437992572784424
Validation loss: 2.041004995505015

Epoch: 6| Step: 3
Training loss: 0.5236355066299438
Validation loss: 2.0230942964553833

Epoch: 6| Step: 4
Training loss: 0.44334137439727783
Validation loss: 2.0197903315226235

Epoch: 6| Step: 5
Training loss: 0.48276785016059875
Validation loss: 2.0276004870732627

Epoch: 6| Step: 6
Training loss: 0.192392960190773
Validation loss: 1.9705241719881694

Epoch: 6| Step: 7
Training loss: 0.6125270128250122
Validation loss: 2.0191824038823447

Epoch: 6| Step: 8
Training loss: 0.5029767155647278
Validation loss: 1.983477274576823

Epoch: 6| Step: 9
Training loss: 0.5585342049598694
Validation loss: 2.038359502951304

Epoch: 6| Step: 10
Training loss: 0.541230320930481
Validation loss: 1.96567306915919

Epoch: 6| Step: 11
Training loss: 0.4573790431022644
Validation loss: 2.02021187543869

Epoch: 6| Step: 12
Training loss: 0.8503866195678711
Validation loss: 2.0082506934801736

Epoch: 6| Step: 13
Training loss: 1.1882004737854004
Validation loss: 2.0241827170054116

Epoch: 228| Step: 0
Training loss: 0.539975106716156
Validation loss: 2.0326231519381204

Epoch: 6| Step: 1
Training loss: 0.5240176916122437
Validation loss: 1.9946267008781433

Epoch: 6| Step: 2
Training loss: 0.798308253288269
Validation loss: 2.002667943636576

Epoch: 6| Step: 3
Training loss: 0.6045772433280945
Validation loss: 2.0080447991689048

Epoch: 6| Step: 4
Training loss: 1.0459058284759521
Validation loss: 2.007713953653971

Epoch: 6| Step: 5
Training loss: 0.4998512268066406
Validation loss: 2.0082879662513733

Epoch: 6| Step: 6
Training loss: 0.9325324296951294
Validation loss: 1.99788498878479

Epoch: 6| Step: 7
Training loss: 0.7491147518157959
Validation loss: 2.0338423450787864

Epoch: 6| Step: 8
Training loss: 0.3922252058982849
Validation loss: 2.019930144151052

Epoch: 6| Step: 9
Training loss: 0.41587120294570923
Validation loss: 2.0222720901171365

Epoch: 6| Step: 10
Training loss: 0.621345579624176
Validation loss: 2.024485190709432

Epoch: 6| Step: 11
Training loss: 0.8314442038536072
Validation loss: 2.0615076422691345

Epoch: 6| Step: 12
Training loss: 0.931322455406189
Validation loss: 2.0660322308540344

Epoch: 6| Step: 13
Training loss: 0.8515922427177429
Validation loss: 2.022987425327301

Epoch: 229| Step: 0
Training loss: 0.8815889954566956
Validation loss: 2.064089755217234

Epoch: 6| Step: 1
Training loss: 0.33878618478775024
Validation loss: 1.9744554162025452

Epoch: 6| Step: 2
Training loss: 0.42439767718315125
Validation loss: 1.9766937295595806

Epoch: 6| Step: 3
Training loss: 0.4544144570827484
Validation loss: 2.0154578487078347

Epoch: 6| Step: 4
Training loss: 0.4840143918991089
Validation loss: 2.014829158782959

Epoch: 6| Step: 5
Training loss: 1.1159783601760864
Validation loss: 2.0393354495366416

Epoch: 6| Step: 6
Training loss: 0.694599986076355
Validation loss: 2.0071224570274353

Epoch: 6| Step: 7
Training loss: 1.1437444686889648
Validation loss: 2.004933555920919

Epoch: 6| Step: 8
Training loss: 0.741430401802063
Validation loss: 1.9790481925010681

Epoch: 6| Step: 9
Training loss: 0.6622238159179688
Validation loss: 1.989940881729126

Epoch: 6| Step: 10
Training loss: 0.45368099212646484
Validation loss: 2.018457074960073

Epoch: 6| Step: 11
Training loss: 0.5863815546035767
Validation loss: 1.9565019408861797

Epoch: 6| Step: 12
Training loss: 0.5914809107780457
Validation loss: 2.0024622082710266

Epoch: 6| Step: 13
Training loss: 0.5418151617050171
Validation loss: 1.962130347887675

Epoch: 230| Step: 0
Training loss: 0.40069711208343506
Validation loss: 2.0295846462249756

Epoch: 6| Step: 1
Training loss: 0.4361245632171631
Validation loss: 2.0013826886812844

Epoch: 6| Step: 2
Training loss: 0.6013078689575195
Validation loss: 1.9747694333394368

Epoch: 6| Step: 3
Training loss: 0.3973097801208496
Validation loss: 1.9876880645751953

Epoch: 6| Step: 4
Training loss: 0.5814945697784424
Validation loss: 1.9643778602282207

Epoch: 6| Step: 5
Training loss: 0.4579564929008484
Validation loss: 1.9970641732215881

Epoch: 6| Step: 6
Training loss: 0.688758373260498
Validation loss: 1.963765561580658

Epoch: 6| Step: 7
Training loss: 0.7793967723846436
Validation loss: 2.0059156020482383

Epoch: 6| Step: 8
Training loss: 0.5701674222946167
Validation loss: 1.9932337999343872

Epoch: 6| Step: 9
Training loss: 1.008967638015747
Validation loss: 1.990695635477702

Epoch: 6| Step: 10
Training loss: 0.436926931142807
Validation loss: 2.0049452980359397

Epoch: 6| Step: 11
Training loss: 0.5789741277694702
Validation loss: 2.0051308075586953

Epoch: 6| Step: 12
Training loss: 0.5873269438743591
Validation loss: 2.019416789213816

Epoch: 6| Step: 13
Training loss: 0.7547122240066528
Validation loss: 1.9925836722056072

Epoch: 231| Step: 0
Training loss: 0.27718842029571533
Validation loss: 1.994199554125468

Epoch: 6| Step: 1
Training loss: 0.339944064617157
Validation loss: 1.9375322461128235

Epoch: 6| Step: 2
Training loss: 1.0628318786621094
Validation loss: 2.01021401087443

Epoch: 6| Step: 3
Training loss: 0.8842818737030029
Validation loss: 1.98232505718867

Epoch: 6| Step: 4
Training loss: 0.8632130026817322
Validation loss: 2.0201223889986673

Epoch: 6| Step: 5
Training loss: 0.4105094075202942
Validation loss: 2.005155622959137

Epoch: 6| Step: 6
Training loss: 0.9509245157241821
Validation loss: 1.9879061579704285

Epoch: 6| Step: 7
Training loss: 0.630596399307251
Validation loss: 1.9929998517036438

Epoch: 6| Step: 8
Training loss: 0.29183340072631836
Validation loss: 1.9898166457811992

Epoch: 6| Step: 9
Training loss: 0.6049230098724365
Validation loss: 2.010436197121938

Epoch: 6| Step: 10
Training loss: 0.6051862835884094
Validation loss: 1.9709177017211914

Epoch: 6| Step: 11
Training loss: 0.48658162355422974
Validation loss: 2.045228679974874

Epoch: 6| Step: 12
Training loss: 0.5787129402160645
Validation loss: 1.9856655796368916

Epoch: 6| Step: 13
Training loss: 0.8986263871192932
Validation loss: 2.0110575954119363

Epoch: 232| Step: 0
Training loss: 0.6014759540557861
Validation loss: 1.9904865821202595

Epoch: 6| Step: 1
Training loss: 0.34120631217956543
Validation loss: 2.0226985613505044

Epoch: 6| Step: 2
Training loss: 0.4200446605682373
Validation loss: 2.0058090885480246

Epoch: 6| Step: 3
Training loss: 0.36739468574523926
Validation loss: 2.0279125968615213

Epoch: 6| Step: 4
Training loss: 0.6878767609596252
Validation loss: 1.98878409465154

Epoch: 6| Step: 5
Training loss: 0.5659959316253662
Validation loss: 2.01042640209198

Epoch: 6| Step: 6
Training loss: 0.621545672416687
Validation loss: 2.0084482630093894

Epoch: 6| Step: 7
Training loss: 0.6389815211296082
Validation loss: 2.0148523251215615

Epoch: 6| Step: 8
Training loss: 0.9316871762275696
Validation loss: 2.0241868694623313

Epoch: 6| Step: 9
Training loss: 0.39575010538101196
Validation loss: 1.9674689372380574

Epoch: 6| Step: 10
Training loss: 0.8687288165092468
Validation loss: 2.0589812596639

Epoch: 6| Step: 11
Training loss: 0.6985176801681519
Validation loss: 2.0055593450864158

Epoch: 6| Step: 12
Training loss: 0.7706954479217529
Validation loss: 2.01513801018397

Epoch: 6| Step: 13
Training loss: 0.6680853366851807
Validation loss: 2.0088303486506143

Epoch: 233| Step: 0
Training loss: 1.0577349662780762
Validation loss: 2.0467450618743896

Epoch: 6| Step: 1
Training loss: 0.3643428087234497
Validation loss: 1.9533384839693706

Epoch: 6| Step: 2
Training loss: 0.5774309039115906
Validation loss: 2.023771266142527

Epoch: 6| Step: 3
Training loss: 0.6773309707641602
Validation loss: 2.0006701946258545

Epoch: 6| Step: 4
Training loss: 0.30301231145858765
Validation loss: 1.9669589598973591

Epoch: 6| Step: 5
Training loss: 0.3933619260787964
Validation loss: 1.9904614289601643

Epoch: 6| Step: 6
Training loss: 0.535415530204773
Validation loss: 1.9826884865760803

Epoch: 6| Step: 7
Training loss: 0.22446608543395996
Validation loss: 1.9808090925216675

Epoch: 6| Step: 8
Training loss: 0.5444802641868591
Validation loss: 1.9886894822120667

Epoch: 6| Step: 9
Training loss: 1.273383378982544
Validation loss: 1.9967799385388691

Epoch: 6| Step: 10
Training loss: 0.3691108226776123
Validation loss: 2.019439915815989

Epoch: 6| Step: 11
Training loss: 0.7316575050354004
Validation loss: 2.0156251192092896

Epoch: 6| Step: 12
Training loss: 0.550292432308197
Validation loss: 2.0185928543408713

Epoch: 6| Step: 13
Training loss: 0.5508407950401306
Validation loss: 2.0262197653452554

Epoch: 234| Step: 0
Training loss: 0.7973686456680298
Validation loss: 2.0296459197998047

Epoch: 6| Step: 1
Training loss: 0.9519410133361816
Validation loss: 2.0191902120908103

Epoch: 6| Step: 2
Training loss: 0.6832318305969238
Validation loss: 1.994768758614858

Epoch: 6| Step: 3
Training loss: 0.8457512855529785
Validation loss: 2.0034489830334983

Epoch: 6| Step: 4
Training loss: 0.959578275680542
Validation loss: 2.012583593527476

Epoch: 6| Step: 5
Training loss: 0.3615606129169464
Validation loss: 2.0059893329938254

Epoch: 6| Step: 6
Training loss: 0.5687562823295593
Validation loss: 2.0196075240770974

Epoch: 6| Step: 7
Training loss: 0.6691710948944092
Validation loss: 2.0432594418525696

Epoch: 6| Step: 8
Training loss: 0.5472590327262878
Validation loss: 1.9861366947491963

Epoch: 6| Step: 9
Training loss: 0.3800537586212158
Validation loss: 1.9916745622952778

Epoch: 6| Step: 10
Training loss: 0.23322391510009766
Validation loss: 1.9888749718666077

Epoch: 6| Step: 11
Training loss: 0.3951432406902313
Validation loss: 1.9670383930206299

Epoch: 6| Step: 12
Training loss: 0.5011704564094543
Validation loss: 2.0133608182271323

Epoch: 6| Step: 13
Training loss: 0.5371690988540649
Validation loss: 1.972360650698344

Epoch: 235| Step: 0
Training loss: 0.3905760645866394
Validation loss: 1.9924681782722473

Epoch: 6| Step: 1
Training loss: 0.4955310821533203
Validation loss: 2.0222108562787375

Epoch: 6| Step: 2
Training loss: 0.8753241300582886
Validation loss: 1.9989664157231648

Epoch: 6| Step: 3
Training loss: 0.674155592918396
Validation loss: 1.9805629253387451

Epoch: 6| Step: 4
Training loss: 0.382024347782135
Validation loss: 1.997350851694743

Epoch: 6| Step: 5
Training loss: 0.359799325466156
Validation loss: 2.036088486512502

Epoch: 6| Step: 6
Training loss: 0.3261256217956543
Validation loss: 1.9601473410924275

Epoch: 6| Step: 7
Training loss: 0.6373939514160156
Validation loss: 2.0047341187795005

Epoch: 6| Step: 8
Training loss: 0.46346694231033325
Validation loss: 1.9769441684087117

Epoch: 6| Step: 9
Training loss: 0.47810035943984985
Validation loss: 1.9833239714304607

Epoch: 6| Step: 10
Training loss: 0.4719938635826111
Validation loss: 2.0566343863805137

Epoch: 6| Step: 11
Training loss: 0.8457757830619812
Validation loss: 2.011598289012909

Epoch: 6| Step: 12
Training loss: 0.47459593415260315
Validation loss: 1.9668542544047039

Epoch: 6| Step: 13
Training loss: 1.2852015495300293
Validation loss: 1.9744738340377808

Epoch: 236| Step: 0
Training loss: 0.5539122819900513
Validation loss: 2.0112706621487937

Epoch: 6| Step: 1
Training loss: 0.9635003805160522
Validation loss: 2.0109687646230063

Epoch: 6| Step: 2
Training loss: 0.5035998821258545
Validation loss: 1.9996559818585713

Epoch: 6| Step: 3
Training loss: 0.5234988331794739
Validation loss: 1.9934671719868977

Epoch: 6| Step: 4
Training loss: 0.4243677258491516
Validation loss: 2.0048418243726096

Epoch: 6| Step: 5
Training loss: 0.8046423196792603
Validation loss: 2.0116454362869263

Epoch: 6| Step: 6
Training loss: 0.38825035095214844
Validation loss: 2.013291339079539

Epoch: 6| Step: 7
Training loss: 0.46835726499557495
Validation loss: 1.9984612464904785

Epoch: 6| Step: 8
Training loss: 0.6206101179122925
Validation loss: 1.9940252304077148

Epoch: 6| Step: 9
Training loss: 0.6363168954849243
Validation loss: 1.9972375830014546

Epoch: 6| Step: 10
Training loss: 1.0246281623840332
Validation loss: 1.9866315722465515

Epoch: 6| Step: 11
Training loss: 0.5445671081542969
Validation loss: 2.022407829761505

Epoch: 6| Step: 12
Training loss: 0.4576666057109833
Validation loss: 2.018465499083201

Epoch: 6| Step: 13
Training loss: 0.6444839239120483
Validation loss: 1.984075168768565

Epoch: 237| Step: 0
Training loss: 0.44033336639404297
Validation loss: 1.9917487899462383

Epoch: 6| Step: 1
Training loss: 0.5773041844367981
Validation loss: 2.00210835536321

Epoch: 6| Step: 2
Training loss: 0.49518081545829773
Validation loss: 1.9940124154090881

Epoch: 6| Step: 3
Training loss: 0.4804924428462982
Validation loss: 2.038966715335846

Epoch: 6| Step: 4
Training loss: 0.5855298638343811
Validation loss: 1.9628260731697083

Epoch: 6| Step: 5
Training loss: 0.8210000991821289
Validation loss: 1.9904820322990417

Epoch: 6| Step: 6
Training loss: 0.767085075378418
Validation loss: 2.0136449933052063

Epoch: 6| Step: 7
Training loss: 0.9606339931488037
Validation loss: 2.020445466041565

Epoch: 6| Step: 8
Training loss: 0.5517961382865906
Validation loss: 2.0125439961751304

Epoch: 6| Step: 9
Training loss: 0.618309736251831
Validation loss: 1.999940554300944

Epoch: 6| Step: 10
Training loss: 0.9801569581031799
Validation loss: 2.006397803624471

Epoch: 6| Step: 11
Training loss: 0.3077603578567505
Validation loss: 2.0184926191965737

Epoch: 6| Step: 12
Training loss: 0.46930670738220215
Validation loss: 2.008871912956238

Epoch: 6| Step: 13
Training loss: 0.5174396634101868
Validation loss: 2.014209727446238

Epoch: 238| Step: 0
Training loss: 0.37067800760269165
Validation loss: 2.0411376357078552

Epoch: 6| Step: 1
Training loss: 0.7139402627944946
Validation loss: 2.0184961756070456

Epoch: 6| Step: 2
Training loss: 0.7552739381790161
Validation loss: 2.0386090874671936

Epoch: 6| Step: 3
Training loss: 0.6816956996917725
Validation loss: 2.052472730477651

Epoch: 6| Step: 4
Training loss: 0.5215985178947449
Validation loss: 2.071162462234497

Epoch: 6| Step: 5
Training loss: 0.3800843358039856
Validation loss: 2.018994609514872

Epoch: 6| Step: 6
Training loss: 0.5666553974151611
Validation loss: 2.013623595237732

Epoch: 6| Step: 7
Training loss: 0.5369094610214233
Validation loss: 2.0296905835469565

Epoch: 6| Step: 8
Training loss: 1.3221899271011353
Validation loss: 2.015296141306559

Epoch: 6| Step: 9
Training loss: 0.6527120471000671
Validation loss: 2.0598510106404624

Epoch: 6| Step: 10
Training loss: 0.5594844818115234
Validation loss: 2.0826838413874307

Epoch: 6| Step: 11
Training loss: 0.5447416305541992
Validation loss: 2.0270565350850425

Epoch: 6| Step: 12
Training loss: 0.620729923248291
Validation loss: 2.0464481711387634

Epoch: 6| Step: 13
Training loss: 0.5330111980438232
Validation loss: 2.01219379901886

Epoch: 239| Step: 0
Training loss: 0.6438906788825989
Validation loss: 2.052111784617106

Epoch: 6| Step: 1
Training loss: 0.6093201041221619
Validation loss: 2.0122153560320535

Epoch: 6| Step: 2
Training loss: 0.8152919411659241
Validation loss: 2.0066662430763245

Epoch: 6| Step: 3
Training loss: 0.5044158697128296
Validation loss: 2.011300504207611

Epoch: 6| Step: 4
Training loss: 0.782932460308075
Validation loss: 2.030915637811025

Epoch: 6| Step: 5
Training loss: 0.5126171112060547
Validation loss: 2.0403573513031006

Epoch: 6| Step: 6
Training loss: 0.8764021396636963
Validation loss: 2.038146495819092

Epoch: 6| Step: 7
Training loss: 0.9053115248680115
Validation loss: 1.9780333836873372

Epoch: 6| Step: 8
Training loss: 0.7143839597702026
Validation loss: 2.0276962717374167

Epoch: 6| Step: 9
Training loss: 0.4242195785045624
Validation loss: 2.0261066555976868

Epoch: 6| Step: 10
Training loss: 0.5890529155731201
Validation loss: 1.9869957566261292

Epoch: 6| Step: 11
Training loss: 0.3425150513648987
Validation loss: 2.0439796447753906

Epoch: 6| Step: 12
Training loss: 0.5007575750350952
Validation loss: 2.0378948052724204

Epoch: 6| Step: 13
Training loss: 0.6232465505599976
Validation loss: 2.0197875698407493

Epoch: 240| Step: 0
Training loss: 0.4504892826080322
Validation loss: 1.9918749729792278

Epoch: 6| Step: 1
Training loss: 0.6074148416519165
Validation loss: 1.9814963340759277

Epoch: 6| Step: 2
Training loss: 0.5102163553237915
Validation loss: 2.040246287981669

Epoch: 6| Step: 3
Training loss: 0.6342368721961975
Validation loss: 1.9953352808952332

Epoch: 6| Step: 4
Training loss: 0.4821830987930298
Validation loss: 1.9819959998130798

Epoch: 6| Step: 5
Training loss: 0.24304737150669098
Validation loss: 2.0304121375083923

Epoch: 6| Step: 6
Training loss: 0.5247197151184082
Validation loss: 1.993999977906545

Epoch: 6| Step: 7
Training loss: 0.6758871078491211
Validation loss: 1.9803135395050049

Epoch: 6| Step: 8
Training loss: 0.41690441966056824
Validation loss: 1.993228554725647

Epoch: 6| Step: 9
Training loss: 0.4599703550338745
Validation loss: 2.0174331267674765

Epoch: 6| Step: 10
Training loss: 0.8901125192642212
Validation loss: 2.045214315255483

Epoch: 6| Step: 11
Training loss: 0.8506327867507935
Validation loss: 2.01685893535614

Epoch: 6| Step: 12
Training loss: 0.7084430456161499
Validation loss: 2.0173263549804688

Epoch: 6| Step: 13
Training loss: 1.0315719842910767
Validation loss: 2.012330730756124

Epoch: 241| Step: 0
Training loss: 0.6287755370140076
Validation loss: 2.020428935686747

Epoch: 6| Step: 1
Training loss: 0.2034079134464264
Validation loss: 2.000537892182668

Epoch: 6| Step: 2
Training loss: 0.9470895528793335
Validation loss: 2.0003479719161987

Epoch: 6| Step: 3
Training loss: 0.361934632062912
Validation loss: 1.9672227104504902

Epoch: 6| Step: 4
Training loss: 0.2607903480529785
Validation loss: 2.0283265908559165

Epoch: 6| Step: 5
Training loss: 1.0385558605194092
Validation loss: 1.9732797940572102

Epoch: 6| Step: 6
Training loss: 0.6119731664657593
Validation loss: 2.0379426081975303

Epoch: 6| Step: 7
Training loss: 1.0178625583648682
Validation loss: 2.0261972546577454

Epoch: 6| Step: 8
Training loss: 0.3070887327194214
Validation loss: 2.034201721350352

Epoch: 6| Step: 9
Training loss: 0.7296043038368225
Validation loss: 2.0659390489260354

Epoch: 6| Step: 10
Training loss: 0.4435986876487732
Validation loss: 2.053825875123342

Epoch: 6| Step: 11
Training loss: 0.23878994584083557
Validation loss: 2.010874609152476

Epoch: 6| Step: 12
Training loss: 0.5037574768066406
Validation loss: 2.0308767755826316

Epoch: 6| Step: 13
Training loss: 0.5184651017189026
Validation loss: 2.0425047874450684

Epoch: 242| Step: 0
Training loss: 1.4299731254577637
Validation loss: 2.029758354028066

Epoch: 6| Step: 1
Training loss: 0.3839533030986786
Validation loss: 2.02870641152064

Epoch: 6| Step: 2
Training loss: 0.4513035714626312
Validation loss: 2.037662943204244

Epoch: 6| Step: 3
Training loss: 0.47945553064346313
Validation loss: 2.0380313396453857

Epoch: 6| Step: 4
Training loss: 0.476189523935318
Validation loss: 2.0314454634984336

Epoch: 6| Step: 5
Training loss: 0.5918900966644287
Validation loss: 2.005130132039388

Epoch: 6| Step: 6
Training loss: 0.2945367693901062
Validation loss: 1.9940211375554402

Epoch: 6| Step: 7
Training loss: 0.5021612644195557
Validation loss: 1.9842182199160259

Epoch: 6| Step: 8
Training loss: 0.5062873363494873
Validation loss: 1.973843256632487

Epoch: 6| Step: 9
Training loss: 1.088307499885559
Validation loss: 2.0481897989908853

Epoch: 6| Step: 10
Training loss: 0.5620988607406616
Validation loss: 1.9672208229700725

Epoch: 6| Step: 11
Training loss: 0.3677424192428589
Validation loss: 2.0061188538869223

Epoch: 6| Step: 12
Training loss: 0.6417878270149231
Validation loss: 2.0108390053113303

Epoch: 6| Step: 13
Training loss: 0.5085448026657104
Validation loss: 2.038039267063141

Epoch: 243| Step: 0
Training loss: 0.3932836949825287
Validation loss: 2.001697301864624

Epoch: 6| Step: 1
Training loss: 0.22887691855430603
Validation loss: 1.9937293926874797

Epoch: 6| Step: 2
Training loss: 0.5619252920150757
Validation loss: 2.0016699035962424

Epoch: 6| Step: 3
Training loss: 0.8057701587677002
Validation loss: 2.0151851574579873

Epoch: 6| Step: 4
Training loss: 0.7923405766487122
Validation loss: 1.9837148984273274

Epoch: 6| Step: 5
Training loss: 0.2891082465648651
Validation loss: 2.026656130949656

Epoch: 6| Step: 6
Training loss: 0.5149576663970947
Validation loss: 1.9757179021835327

Epoch: 6| Step: 7
Training loss: 0.2696787118911743
Validation loss: 2.0223191181818643

Epoch: 6| Step: 8
Training loss: 0.6534001231193542
Validation loss: 2.014071981112162

Epoch: 6| Step: 9
Training loss: 0.5503010153770447
Validation loss: 2.0279338359832764

Epoch: 6| Step: 10
Training loss: 0.4632796347141266
Validation loss: 2.0073474049568176

Epoch: 6| Step: 11
Training loss: 1.1621153354644775
Validation loss: 2.00613534450531

Epoch: 6| Step: 12
Training loss: 0.8176599740982056
Validation loss: 2.0085936188697815

Epoch: 6| Step: 13
Training loss: 0.38739120960235596
Validation loss: 2.0050754944483438

Epoch: 244| Step: 0
Training loss: 0.3326268792152405
Validation loss: 2.053260783354441

Epoch: 6| Step: 1
Training loss: 0.6354592442512512
Validation loss: 2.0412306586901345

Epoch: 6| Step: 2
Training loss: 0.5121409893035889
Validation loss: 2.01545516649882

Epoch: 6| Step: 3
Training loss: 0.8313502073287964
Validation loss: 1.9889394442240398

Epoch: 6| Step: 4
Training loss: 0.5340667963027954
Validation loss: 2.0439584652582803

Epoch: 6| Step: 5
Training loss: 0.2653631567955017
Validation loss: 2.0353784958521524

Epoch: 6| Step: 6
Training loss: 0.3346492648124695
Validation loss: 2.0407636364301047

Epoch: 6| Step: 7
Training loss: 0.6850967407226562
Validation loss: 2.0095852414766946

Epoch: 6| Step: 8
Training loss: 0.858903169631958
Validation loss: 2.0083073377609253

Epoch: 6| Step: 9
Training loss: 0.7142646312713623
Validation loss: 2.0234169165293374

Epoch: 6| Step: 10
Training loss: 0.519284188747406
Validation loss: 1.9964226881663005

Epoch: 6| Step: 11
Training loss: 0.7657210826873779
Validation loss: 1.995290219783783

Epoch: 6| Step: 12
Training loss: 0.5706319808959961
Validation loss: 1.9887542923291524

Epoch: 6| Step: 13
Training loss: 0.5531721115112305
Validation loss: 1.964704970518748

Epoch: 245| Step: 0
Training loss: 0.3330352008342743
Validation loss: 2.0065685510635376

Epoch: 6| Step: 1
Training loss: 0.7277912497520447
Validation loss: 2.010450621445974

Epoch: 6| Step: 2
Training loss: 0.6526198387145996
Validation loss: 1.9861517747243245

Epoch: 6| Step: 3
Training loss: 0.6542252898216248
Validation loss: 2.006139357884725

Epoch: 6| Step: 4
Training loss: 0.29480689764022827
Validation loss: 1.975111683209737

Epoch: 6| Step: 5
Training loss: 0.5625834465026855
Validation loss: 1.9945119619369507

Epoch: 6| Step: 6
Training loss: 0.9595330953598022
Validation loss: 2.01399956146876

Epoch: 6| Step: 7
Training loss: 0.6725939512252808
Validation loss: 1.951657811800639

Epoch: 6| Step: 8
Training loss: 0.6183279752731323
Validation loss: 1.98964923620224

Epoch: 6| Step: 9
Training loss: 0.4157750904560089
Validation loss: 1.98009196917216

Epoch: 6| Step: 10
Training loss: 0.39200785756111145
Validation loss: 1.9839828411738079

Epoch: 6| Step: 11
Training loss: 0.600130558013916
Validation loss: 1.967298448085785

Epoch: 6| Step: 12
Training loss: 0.33835262060165405
Validation loss: 2.038038949171702

Epoch: 6| Step: 13
Training loss: 0.734406590461731
Validation loss: 2.031507213910421

Epoch: 246| Step: 0
Training loss: 0.7384442090988159
Validation loss: 2.0047531525293985

Epoch: 6| Step: 1
Training loss: 0.4805530905723572
Validation loss: 1.9991272687911987

Epoch: 6| Step: 2
Training loss: 0.29245755076408386
Validation loss: 1.9768519004185994

Epoch: 6| Step: 3
Training loss: 0.7297095656394958
Validation loss: 1.9923576911290486

Epoch: 6| Step: 4
Training loss: 0.5173118710517883
Validation loss: 2.010782996813456

Epoch: 6| Step: 5
Training loss: 0.5539541244506836
Validation loss: 2.0236736138661704

Epoch: 6| Step: 6
Training loss: 0.3986256718635559
Validation loss: 1.9494956533114116

Epoch: 6| Step: 7
Training loss: 0.5646569132804871
Validation loss: 1.9975187182426453

Epoch: 6| Step: 8
Training loss: 0.49118122458457947
Validation loss: 2.029948910077413

Epoch: 6| Step: 9
Training loss: 0.7696152329444885
Validation loss: 2.0123649636904397

Epoch: 6| Step: 10
Training loss: 0.6790819764137268
Validation loss: 1.9930536150932312

Epoch: 6| Step: 11
Training loss: 0.6030653715133667
Validation loss: 1.988924245039622

Epoch: 6| Step: 12
Training loss: 0.18009278178215027
Validation loss: 2.013139565785726

Epoch: 6| Step: 13
Training loss: 0.5618503093719482
Validation loss: 2.003854751586914

Epoch: 247| Step: 0
Training loss: 0.8478145599365234
Validation loss: 2.013138214747111

Epoch: 6| Step: 1
Training loss: 0.25738975405693054
Validation loss: 1.9722796479860942

Epoch: 6| Step: 2
Training loss: 0.8546535968780518
Validation loss: 2.0016712745030723

Epoch: 6| Step: 3
Training loss: 0.6389349102973938
Validation loss: 1.986988087495168

Epoch: 6| Step: 4
Training loss: 0.6701778173446655
Validation loss: 1.9834719896316528

Epoch: 6| Step: 5
Training loss: 0.2646128535270691
Validation loss: 1.9493660529454548

Epoch: 6| Step: 6
Training loss: 0.2785804569721222
Validation loss: 1.9803745746612549

Epoch: 6| Step: 7
Training loss: 0.9750441908836365
Validation loss: 2.0029887358347573

Epoch: 6| Step: 8
Training loss: 0.4793129563331604
Validation loss: 2.0072877407073975

Epoch: 6| Step: 9
Training loss: 0.5284621119499207
Validation loss: 1.9964125553766887

Epoch: 6| Step: 10
Training loss: 0.598314642906189
Validation loss: 1.9942662715911865

Epoch: 6| Step: 11
Training loss: 0.4131329357624054
Validation loss: 2.003365953763326

Epoch: 6| Step: 12
Training loss: 0.680751383304596
Validation loss: 1.970028539498647

Epoch: 6| Step: 13
Training loss: 0.4546617865562439
Validation loss: 2.0225422978401184

Epoch: 248| Step: 0
Training loss: 0.9843026399612427
Validation loss: 1.9808082580566406

Epoch: 6| Step: 1
Training loss: 0.45392125844955444
Validation loss: 2.0150681734085083

Epoch: 6| Step: 2
Training loss: 0.6270685195922852
Validation loss: 1.979657252629598

Epoch: 6| Step: 3
Training loss: 1.2209888696670532
Validation loss: 2.006899893283844

Epoch: 6| Step: 4
Training loss: 0.3475976586341858
Validation loss: 2.019193867842356

Epoch: 6| Step: 5
Training loss: 0.40773943066596985
Validation loss: 2.0320010582605996

Epoch: 6| Step: 6
Training loss: 0.5261406302452087
Validation loss: 2.0005994041760764

Epoch: 6| Step: 7
Training loss: 0.6086990833282471
Validation loss: 2.037996451059977

Epoch: 6| Step: 8
Training loss: 0.6586349010467529
Validation loss: 1.9804169336954753

Epoch: 6| Step: 9
Training loss: 0.2846081852912903
Validation loss: 1.9938912789026897

Epoch: 6| Step: 10
Training loss: 0.2932621240615845
Validation loss: 1.999066948890686

Epoch: 6| Step: 11
Training loss: 0.655958890914917
Validation loss: 1.9833423693974812

Epoch: 6| Step: 12
Training loss: 0.519020140171051
Validation loss: 1.9954263965288799

Epoch: 6| Step: 13
Training loss: 0.41997310519218445
Validation loss: 1.9636120398839314

Epoch: 249| Step: 0
Training loss: 0.7036522626876831
Validation loss: 1.9866910576820374

Epoch: 6| Step: 1
Training loss: 0.46476030349731445
Validation loss: 1.9918155868848164

Epoch: 6| Step: 2
Training loss: 0.5686352849006653
Validation loss: 2.001015305519104

Epoch: 6| Step: 3
Training loss: 0.4367365837097168
Validation loss: 2.0069239934285483

Epoch: 6| Step: 4
Training loss: 0.4403690695762634
Validation loss: 2.0095528761545816

Epoch: 6| Step: 5
Training loss: 0.869114100933075
Validation loss: 1.9925954540570576

Epoch: 6| Step: 6
Training loss: 0.5236292481422424
Validation loss: 2.043639520804087

Epoch: 6| Step: 7
Training loss: 0.17769227921962738
Validation loss: 1.978619933128357

Epoch: 6| Step: 8
Training loss: 0.7861064076423645
Validation loss: 2.0052204529444375

Epoch: 6| Step: 9
Training loss: 0.6626490354537964
Validation loss: 1.943297545115153

Epoch: 6| Step: 10
Training loss: 0.7884407043457031
Validation loss: 2.060128688812256

Epoch: 6| Step: 11
Training loss: 0.28670167922973633
Validation loss: 2.0435095032056174

Epoch: 6| Step: 12
Training loss: 0.25040900707244873
Validation loss: 2.0147504011789956

Epoch: 6| Step: 13
Training loss: 0.37941041588783264
Validation loss: 2.027553975582123

Epoch: 250| Step: 0
Training loss: 0.6300181150436401
Validation loss: 2.02299427986145

Epoch: 6| Step: 1
Training loss: 0.6817934513092041
Validation loss: 2.0024943550427756

Epoch: 6| Step: 2
Training loss: 0.3611730635166168
Validation loss: 2.0181068976720176

Epoch: 6| Step: 3
Training loss: 0.31211456656455994
Validation loss: 2.011640429496765

Epoch: 6| Step: 4
Training loss: 0.47766202688217163
Validation loss: 1.9967902501424153

Epoch: 6| Step: 5
Training loss: 0.35425060987472534
Validation loss: 2.0258668065071106

Epoch: 6| Step: 6
Training loss: 0.22596558928489685
Validation loss: 2.0238354007403054

Epoch: 6| Step: 7
Training loss: 1.037771463394165
Validation loss: 2.055928329626719

Epoch: 6| Step: 8
Training loss: 0.5035396814346313
Validation loss: 1.9826440215110779

Epoch: 6| Step: 9
Training loss: 0.44454410672187805
Validation loss: 2.0403813123703003

Epoch: 6| Step: 10
Training loss: 0.752892255783081
Validation loss: 1.99331800142924

Epoch: 6| Step: 11
Training loss: 0.7311021089553833
Validation loss: 1.9648523529370625

Epoch: 6| Step: 12
Training loss: 0.6920228600502014
Validation loss: 2.034097174803416

Epoch: 6| Step: 13
Training loss: 0.2627967298030853
Validation loss: 2.0221964518229165

Testing loss: 1.8327424920720161
