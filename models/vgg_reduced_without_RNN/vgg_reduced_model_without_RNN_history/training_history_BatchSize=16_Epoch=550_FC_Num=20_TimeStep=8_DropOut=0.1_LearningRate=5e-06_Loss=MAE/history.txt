Epoch: 1| Step: 0
Training loss: 5.947327613830566
Validation loss: 6.232479254404704

Epoch: 6| Step: 1
Training loss: 6.251181602478027
Validation loss: 6.22105073928833

Epoch: 6| Step: 2
Training loss: 7.4308390617370605
Validation loss: 6.211729208628337

Epoch: 6| Step: 3
Training loss: 7.169236183166504
Validation loss: 6.200790166854858

Epoch: 6| Step: 4
Training loss: 6.357032775878906
Validation loss: 6.190954685211182

Epoch: 6| Step: 5
Training loss: 6.224348545074463
Validation loss: 6.178763151168823

Epoch: 6| Step: 6
Training loss: 5.5496673583984375
Validation loss: 6.166467984517415

Epoch: 6| Step: 7
Training loss: 5.96197509765625
Validation loss: 6.152468840281169

Epoch: 6| Step: 8
Training loss: 5.879913330078125
Validation loss: 6.140766779581706

Epoch: 6| Step: 9
Training loss: 6.406838417053223
Validation loss: 6.126171588897705

Epoch: 6| Step: 10
Training loss: 6.244726181030273
Validation loss: 6.114536603291829

Epoch: 6| Step: 11
Training loss: 5.999367713928223
Validation loss: 6.101350466410319

Epoch: 6| Step: 12
Training loss: 6.102313995361328
Validation loss: 6.086259285608928

Epoch: 6| Step: 13
Training loss: 5.642627716064453
Validation loss: 6.072533210118611

Epoch: 2| Step: 0
Training loss: 5.735304355621338
Validation loss: 6.056785901387532

Epoch: 6| Step: 1
Training loss: 5.352506637573242
Validation loss: 6.043771902720134

Epoch: 6| Step: 2
Training loss: 6.56638240814209
Validation loss: 6.026459852854411

Epoch: 6| Step: 3
Training loss: 5.752045154571533
Validation loss: 6.009009758631389

Epoch: 6| Step: 4
Training loss: 5.161588668823242
Validation loss: 5.992346525192261

Epoch: 6| Step: 5
Training loss: 6.398606300354004
Validation loss: 5.9736168384552

Epoch: 6| Step: 6
Training loss: 6.11146354675293
Validation loss: 5.956711371739705

Epoch: 6| Step: 7
Training loss: 5.818445205688477
Validation loss: 5.936367829640706

Epoch: 6| Step: 8
Training loss: 6.692746639251709
Validation loss: 5.913246552149455

Epoch: 6| Step: 9
Training loss: 5.432121276855469
Validation loss: 5.89151390393575

Epoch: 6| Step: 10
Training loss: 5.806366443634033
Validation loss: 5.869151592254639

Epoch: 6| Step: 11
Training loss: 5.099050521850586
Validation loss: 5.842231829961141

Epoch: 6| Step: 12
Training loss: 6.9291486740112305
Validation loss: 5.815700610478719

Epoch: 6| Step: 13
Training loss: 7.218229293823242
Validation loss: 5.786432186762492

Epoch: 3| Step: 0
Training loss: 6.352808475494385
Validation loss: 5.757157961527507

Epoch: 6| Step: 1
Training loss: 6.524504661560059
Validation loss: 5.72658634185791

Epoch: 6| Step: 2
Training loss: 5.1622314453125
Validation loss: 5.691210031509399

Epoch: 6| Step: 3
Training loss: 5.9350361824035645
Validation loss: 5.6612216631571455

Epoch: 6| Step: 4
Training loss: 4.897398948669434
Validation loss: 5.620105028152466

Epoch: 6| Step: 5
Training loss: 5.708638668060303
Validation loss: 5.586234887440999

Epoch: 6| Step: 6
Training loss: 5.10828971862793
Validation loss: 5.550810972849528

Epoch: 6| Step: 7
Training loss: 6.248129367828369
Validation loss: 5.511271158854167

Epoch: 6| Step: 8
Training loss: 5.3267502784729
Validation loss: 5.466384649276733

Epoch: 6| Step: 9
Training loss: 5.027859210968018
Validation loss: 5.419155200322469

Epoch: 6| Step: 10
Training loss: 6.614727020263672
Validation loss: 5.376686652501424

Epoch: 6| Step: 11
Training loss: 4.6012372970581055
Validation loss: 5.328249216079712

Epoch: 6| Step: 12
Training loss: 4.62188720703125
Validation loss: 5.280106544494629

Epoch: 6| Step: 13
Training loss: 5.9597697257995605
Validation loss: 5.221444050470988

Epoch: 4| Step: 0
Training loss: 6.046645641326904
Validation loss: 5.162876605987549

Epoch: 6| Step: 1
Training loss: 4.418868541717529
Validation loss: 5.108627239863078

Epoch: 6| Step: 2
Training loss: 5.848310470581055
Validation loss: 5.050997893015544

Epoch: 6| Step: 3
Training loss: 5.935746192932129
Validation loss: 4.987590630849202

Epoch: 6| Step: 4
Training loss: 4.941439628601074
Validation loss: 4.918549418449402

Epoch: 6| Step: 5
Training loss: 4.100241661071777
Validation loss: 4.854157050450643

Epoch: 6| Step: 6
Training loss: 3.783151626586914
Validation loss: 4.7835259437561035

Epoch: 6| Step: 7
Training loss: 4.527815818786621
Validation loss: 4.7180070877075195

Epoch: 6| Step: 8
Training loss: 4.776912212371826
Validation loss: 4.6395870844523115

Epoch: 6| Step: 9
Training loss: 4.136110305786133
Validation loss: 4.558873256047566

Epoch: 6| Step: 10
Training loss: 4.467177391052246
Validation loss: 4.4819921652476

Epoch: 6| Step: 11
Training loss: 5.282454490661621
Validation loss: 4.38774311542511

Epoch: 6| Step: 12
Training loss: 4.675204753875732
Validation loss: 4.300047039985657

Epoch: 6| Step: 13
Training loss: 4.179248332977295
Validation loss: 4.208389600118001

Epoch: 5| Step: 0
Training loss: 3.6462655067443848
Validation loss: 4.12346609433492

Epoch: 6| Step: 1
Training loss: 4.515632629394531
Validation loss: 4.0233579476674395

Epoch: 6| Step: 2
Training loss: 4.259825706481934
Validation loss: 3.9385321140289307

Epoch: 6| Step: 3
Training loss: 4.339136123657227
Validation loss: 3.853713790575663

Epoch: 6| Step: 4
Training loss: 2.483858108520508
Validation loss: 3.753408193588257

Epoch: 6| Step: 5
Training loss: 3.609219551086426
Validation loss: 3.6644675731658936

Epoch: 6| Step: 6
Training loss: 3.1419966220855713
Validation loss: 3.573837637901306

Epoch: 6| Step: 7
Training loss: 2.8087716102600098
Validation loss: 3.4484675327936807

Epoch: 6| Step: 8
Training loss: 2.849466323852539
Validation loss: 3.357685168584188

Epoch: 6| Step: 9
Training loss: 3.608705520629883
Validation loss: 3.2640110651652017

Epoch: 6| Step: 10
Training loss: 3.8261594772338867
Validation loss: 3.1853315035502114

Epoch: 6| Step: 11
Training loss: 3.888566493988037
Validation loss: 3.0808627605438232

Epoch: 6| Step: 12
Training loss: 3.259577751159668
Validation loss: 2.982510964075724

Epoch: 6| Step: 13
Training loss: 3.352972984313965
Validation loss: 2.8680111169815063

Epoch: 6| Step: 0
Training loss: 2.767918586730957
Validation loss: 2.7889187335968018

Epoch: 6| Step: 1
Training loss: 1.7125957012176514
Validation loss: 2.7025689284006753

Epoch: 6| Step: 2
Training loss: 2.831076145172119
Validation loss: 2.629246393839518

Epoch: 6| Step: 3
Training loss: 2.288997173309326
Validation loss: 2.5556467374165854

Epoch: 6| Step: 4
Training loss: 2.4131250381469727
Validation loss: 2.4581349889437356

Epoch: 6| Step: 5
Training loss: 2.756749153137207
Validation loss: 2.4060831467310586

Epoch: 6| Step: 6
Training loss: 3.4529008865356445
Validation loss: 2.3528172969818115

Epoch: 6| Step: 7
Training loss: 2.5265400409698486
Validation loss: 2.301697611808777

Epoch: 6| Step: 8
Training loss: 2.6393909454345703
Validation loss: 2.304590582847595

Epoch: 6| Step: 9
Training loss: 1.4081088304519653
Validation loss: 2.29989230632782

Epoch: 6| Step: 10
Training loss: 2.7076802253723145
Validation loss: 2.286346713701884

Epoch: 6| Step: 11
Training loss: 1.9059116840362549
Validation loss: 2.2949328422546387

Epoch: 6| Step: 12
Training loss: 1.8433959484100342
Validation loss: 2.315601170063019

Epoch: 6| Step: 13
Training loss: 1.0773546695709229
Validation loss: 2.348663886388143

Epoch: 7| Step: 0
Training loss: 2.475644588470459
Validation loss: 2.3370328744252524

Epoch: 6| Step: 1
Training loss: 1.9305188655853271
Validation loss: 2.3347171743710837

Epoch: 6| Step: 2
Training loss: 3.0690793991088867
Validation loss: 2.3256343007087708

Epoch: 6| Step: 3
Training loss: 1.9001903533935547
Validation loss: 2.3593242168426514

Epoch: 6| Step: 4
Training loss: 2.2485060691833496
Validation loss: 2.3581315875053406

Epoch: 6| Step: 5
Training loss: 1.9066052436828613
Validation loss: 2.388766666253408

Epoch: 6| Step: 6
Training loss: 3.331291675567627
Validation loss: 2.374990185101827

Epoch: 6| Step: 7
Training loss: 2.8534414768218994
Validation loss: 2.310734987258911

Epoch: 6| Step: 8
Training loss: 1.5159980058670044
Validation loss: 2.2992731730143228

Epoch: 6| Step: 9
Training loss: 1.1359241008758545
Validation loss: 2.260235091050466

Epoch: 6| Step: 10
Training loss: 2.204313278198242
Validation loss: 2.2684953212738037

Epoch: 6| Step: 11
Training loss: 2.0276970863342285
Validation loss: 2.2591712474823

Epoch: 6| Step: 12
Training loss: 2.7017414569854736
Validation loss: 2.2614667415618896

Epoch: 6| Step: 13
Training loss: 1.991586446762085
Validation loss: 2.2449108958244324

Epoch: 8| Step: 0
Training loss: 1.6833828687667847
Validation loss: 2.2633832693099976

Epoch: 6| Step: 1
Training loss: 2.089110851287842
Validation loss: 2.2650684912999473

Epoch: 6| Step: 2
Training loss: 2.467146396636963
Validation loss: 2.2259061336517334

Epoch: 6| Step: 3
Training loss: 1.5166637897491455
Validation loss: 2.235300620396932

Epoch: 6| Step: 4
Training loss: 2.823354721069336
Validation loss: 2.2216532230377197

Epoch: 6| Step: 5
Training loss: 2.928361415863037
Validation loss: 2.209898749987284

Epoch: 6| Step: 6
Training loss: 1.8632967472076416
Validation loss: 2.2262852589289346

Epoch: 6| Step: 7
Training loss: 2.162027359008789
Validation loss: 2.2392826080322266

Epoch: 6| Step: 8
Training loss: 1.9550241231918335
Validation loss: 2.2374496459960938

Epoch: 6| Step: 9
Training loss: 2.5390820503234863
Validation loss: 2.2003953655560813

Epoch: 6| Step: 10
Training loss: 1.6152279376983643
Validation loss: 2.20718777179718

Epoch: 6| Step: 11
Training loss: 2.0165963172912598
Validation loss: 2.234955688317617

Epoch: 6| Step: 12
Training loss: 1.679957389831543
Validation loss: 2.2370895743370056

Epoch: 6| Step: 13
Training loss: 2.554891586303711
Validation loss: 2.2397210200627646

Epoch: 9| Step: 0
Training loss: 1.7226946353912354
Validation loss: 2.233590583006541

Epoch: 6| Step: 1
Training loss: 2.2730798721313477
Validation loss: 2.2372339169184365

Epoch: 6| Step: 2
Training loss: 2.121870994567871
Validation loss: 2.2083999713261924

Epoch: 6| Step: 3
Training loss: 2.4912641048431396
Validation loss: 2.212639550367991

Epoch: 6| Step: 4
Training loss: 1.625935435295105
Validation loss: 2.231945554415385

Epoch: 6| Step: 5
Training loss: 2.3612241744995117
Validation loss: 2.259919265906016

Epoch: 6| Step: 6
Training loss: 2.009254217147827
Validation loss: 2.233395040035248

Epoch: 6| Step: 7
Training loss: 2.466190814971924
Validation loss: 2.229160249233246

Epoch: 6| Step: 8
Training loss: 1.701202154159546
Validation loss: 2.1907129883766174

Epoch: 6| Step: 9
Training loss: 1.8564903736114502
Validation loss: 2.206768890221914

Epoch: 6| Step: 10
Training loss: 2.7698042392730713
Validation loss: 2.22063018878301

Epoch: 6| Step: 11
Training loss: 2.2136664390563965
Validation loss: 2.2498491406440735

Epoch: 6| Step: 12
Training loss: 1.8310112953186035
Validation loss: 2.207644820213318

Epoch: 6| Step: 13
Training loss: 2.159615993499756
Validation loss: 2.2036379973093667

Epoch: 10| Step: 0
Training loss: 2.9673147201538086
Validation loss: 2.1997510194778442

Epoch: 6| Step: 1
Training loss: 1.6237741708755493
Validation loss: 2.2136053244272866

Epoch: 6| Step: 2
Training loss: 3.0550060272216797
Validation loss: 2.1859029730161033

Epoch: 6| Step: 3
Training loss: 1.9424138069152832
Validation loss: 2.2090901533762612

Epoch: 6| Step: 4
Training loss: 1.93070650100708
Validation loss: 2.1915496190389

Epoch: 6| Step: 5
Training loss: 1.4343050718307495
Validation loss: 2.208763281504313

Epoch: 6| Step: 6
Training loss: 1.8230043649673462
Validation loss: 2.2335760394732156

Epoch: 6| Step: 7
Training loss: 2.1088972091674805
Validation loss: 2.2223417361577353

Epoch: 6| Step: 8
Training loss: 2.045917272567749
Validation loss: 2.194967746734619

Epoch: 6| Step: 9
Training loss: 2.474740505218506
Validation loss: 2.212308645248413

Epoch: 6| Step: 10
Training loss: 1.9889752864837646
Validation loss: 2.1881913940111795

Epoch: 6| Step: 11
Training loss: 1.969679594039917
Validation loss: 2.184881349404653

Epoch: 6| Step: 12
Training loss: 2.298689842224121
Validation loss: 2.203744192918142

Epoch: 6| Step: 13
Training loss: 1.8189966678619385
Validation loss: 2.1998444398244223

Epoch: 11| Step: 0
Training loss: 1.7082254886627197
Validation loss: 2.2340763012568154

Epoch: 6| Step: 1
Training loss: 2.489109992980957
Validation loss: 2.2116602857907615

Epoch: 6| Step: 2
Training loss: 2.58713436126709
Validation loss: 2.19493160645167

Epoch: 6| Step: 3
Training loss: 1.5086122751235962
Validation loss: 2.2023098468780518

Epoch: 6| Step: 4
Training loss: 2.4974453449249268
Validation loss: 2.2021125753720603

Epoch: 6| Step: 5
Training loss: 1.4545550346374512
Validation loss: 2.195160965124766

Epoch: 6| Step: 6
Training loss: 1.5526902675628662
Validation loss: 2.186094582080841

Epoch: 6| Step: 7
Training loss: 2.021946907043457
Validation loss: 2.1667625308036804

Epoch: 6| Step: 8
Training loss: 1.767390489578247
Validation loss: 2.189972917238871

Epoch: 6| Step: 9
Training loss: 2.111687183380127
Validation loss: 2.163644015789032

Epoch: 6| Step: 10
Training loss: 2.7453389167785645
Validation loss: 2.1921286384264627

Epoch: 6| Step: 11
Training loss: 2.033224582672119
Validation loss: 2.1792897979418435

Epoch: 6| Step: 12
Training loss: 2.3146347999572754
Validation loss: 2.2159655690193176

Epoch: 6| Step: 13
Training loss: 2.3108463287353516
Validation loss: 2.1454774538675943

Epoch: 12| Step: 0
Training loss: 2.211418628692627
Validation loss: 2.2013968030611673

Epoch: 6| Step: 1
Training loss: 1.9976341724395752
Validation loss: 2.1754802465438843

Epoch: 6| Step: 2
Training loss: 2.2108254432678223
Validation loss: 2.1723557114601135

Epoch: 6| Step: 3
Training loss: 2.164263963699341
Validation loss: 2.170683224995931

Epoch: 6| Step: 4
Training loss: 2.4218852519989014
Validation loss: 2.1905029813448587

Epoch: 6| Step: 5
Training loss: 2.2199811935424805
Validation loss: 2.13441934188207

Epoch: 6| Step: 6
Training loss: 1.847733736038208
Validation loss: 2.1471615632375083

Epoch: 6| Step: 7
Training loss: 2.1276283264160156
Validation loss: 2.1970064441363015

Epoch: 6| Step: 8
Training loss: 1.7861928939819336
Validation loss: 2.168445070584615

Epoch: 6| Step: 9
Training loss: 2.521289825439453
Validation loss: 2.131949802239736

Epoch: 6| Step: 10
Training loss: 2.1547412872314453
Validation loss: 2.1629586617151895

Epoch: 6| Step: 11
Training loss: 1.4130980968475342
Validation loss: 2.165106455485026

Epoch: 6| Step: 12
Training loss: 1.938806176185608
Validation loss: 2.1717698176701865

Epoch: 6| Step: 13
Training loss: 1.9158382415771484
Validation loss: 2.1092381676038108

Epoch: 13| Step: 0
Training loss: 2.274661064147949
Validation loss: 2.1670461297035217

Epoch: 6| Step: 1
Training loss: 2.4316444396972656
Validation loss: 2.1704224348068237

Epoch: 6| Step: 2
Training loss: 2.051746368408203
Validation loss: 2.203804890314738

Epoch: 6| Step: 3
Training loss: 1.2697011232376099
Validation loss: 2.1620386640230813

Epoch: 6| Step: 4
Training loss: 2.060563564300537
Validation loss: 2.1648363868395486

Epoch: 6| Step: 5
Training loss: 2.0115041732788086
Validation loss: 2.152960240840912

Epoch: 6| Step: 6
Training loss: 1.8697272539138794
Validation loss: 2.1759692827860513

Epoch: 6| Step: 7
Training loss: 2.2984533309936523
Validation loss: 2.1635706027348838

Epoch: 6| Step: 8
Training loss: 2.3425745964050293
Validation loss: 2.1577278772989907

Epoch: 6| Step: 9
Training loss: 2.143963575363159
Validation loss: 2.1651909947395325

Epoch: 6| Step: 10
Training loss: 1.9670666456222534
Validation loss: 2.1507437229156494

Epoch: 6| Step: 11
Training loss: 2.165792942047119
Validation loss: 2.154998322327932

Epoch: 6| Step: 12
Training loss: 1.9559247493743896
Validation loss: 2.1687966187795005

Epoch: 6| Step: 13
Training loss: 2.198604106903076
Validation loss: 2.1853254040082297

Epoch: 14| Step: 0
Training loss: 2.307380199432373
Validation loss: 2.1483201583226523

Epoch: 6| Step: 1
Training loss: 1.9819316864013672
Validation loss: 2.148253242174784

Epoch: 6| Step: 2
Training loss: 1.5521140098571777
Validation loss: 2.1492252945899963

Epoch: 6| Step: 3
Training loss: 2.228139877319336
Validation loss: 2.17667684952418

Epoch: 6| Step: 4
Training loss: 2.134429454803467
Validation loss: 2.143202622731527

Epoch: 6| Step: 5
Training loss: 1.7109315395355225
Validation loss: 2.1450335582097373

Epoch: 6| Step: 6
Training loss: 2.1296300888061523
Validation loss: 2.148731847604116

Epoch: 6| Step: 7
Training loss: 2.123426914215088
Validation loss: 2.1583110690116882

Epoch: 6| Step: 8
Training loss: 1.8634482622146606
Validation loss: 2.163974662621816

Epoch: 6| Step: 9
Training loss: 2.1521782875061035
Validation loss: 2.1347614526748657

Epoch: 6| Step: 10
Training loss: 2.1327028274536133
Validation loss: 2.153665999571482

Epoch: 6| Step: 11
Training loss: 2.206357955932617
Validation loss: 2.140119751294454

Epoch: 6| Step: 12
Training loss: 2.2936482429504395
Validation loss: 2.145083785057068

Epoch: 6| Step: 13
Training loss: 2.0835318565368652
Validation loss: 2.1451247135798135

Epoch: 15| Step: 0
Training loss: 1.1632370948791504
Validation loss: 2.148422102133433

Epoch: 6| Step: 1
Training loss: 1.6884491443634033
Validation loss: 2.1741172075271606

Epoch: 6| Step: 2
Training loss: 2.5436854362487793
Validation loss: 2.1536853909492493

Epoch: 6| Step: 3
Training loss: 2.016693115234375
Validation loss: 2.1547469894091287

Epoch: 6| Step: 4
Training loss: 2.7600975036621094
Validation loss: 2.162856380144755

Epoch: 6| Step: 5
Training loss: 1.6855934858322144
Validation loss: 2.1306150555610657

Epoch: 6| Step: 6
Training loss: 2.1053147315979004
Validation loss: 2.1404948035875955

Epoch: 6| Step: 7
Training loss: 1.4874203205108643
Validation loss: 2.177460034688314

Epoch: 6| Step: 8
Training loss: 2.2806777954101562
Validation loss: 2.1446043848991394

Epoch: 6| Step: 9
Training loss: 2.018746852874756
Validation loss: 2.115780790646871

Epoch: 6| Step: 10
Training loss: 2.6317238807678223
Validation loss: 2.1301880478858948

Epoch: 6| Step: 11
Training loss: 2.0481598377227783
Validation loss: 2.1316837271054587

Epoch: 6| Step: 12
Training loss: 2.5257978439331055
Validation loss: 2.159931461016337

Epoch: 6| Step: 13
Training loss: 1.9206643104553223
Validation loss: 2.1644712686538696

Epoch: 16| Step: 0
Training loss: 1.5349924564361572
Validation loss: 2.1416648030281067

Epoch: 6| Step: 1
Training loss: 2.084000587463379
Validation loss: 2.1402170658111572

Epoch: 6| Step: 2
Training loss: 2.294260025024414
Validation loss: 2.1488505800565085

Epoch: 6| Step: 3
Training loss: 2.1755290031433105
Validation loss: 2.1298938989639282

Epoch: 6| Step: 4
Training loss: 2.1856515407562256
Validation loss: 2.114658017953237

Epoch: 6| Step: 5
Training loss: 2.2613701820373535
Validation loss: 2.1144073406855264

Epoch: 6| Step: 6
Training loss: 2.2608232498168945
Validation loss: 2.1549526254336038

Epoch: 6| Step: 7
Training loss: 2.4160327911376953
Validation loss: 2.1752468943595886

Epoch: 6| Step: 8
Training loss: 2.0133986473083496
Validation loss: 2.1145968437194824

Epoch: 6| Step: 9
Training loss: 1.8947287797927856
Validation loss: 2.1024279594421387

Epoch: 6| Step: 10
Training loss: 1.788900375366211
Validation loss: 2.1369558572769165

Epoch: 6| Step: 11
Training loss: 1.5412225723266602
Validation loss: 2.1353278358777366

Epoch: 6| Step: 12
Training loss: 2.229107141494751
Validation loss: 2.1546935637791953

Epoch: 6| Step: 13
Training loss: 2.2361438274383545
Validation loss: 2.1289223631223044

Epoch: 17| Step: 0
Training loss: 1.8551990985870361
Validation loss: 2.134513020515442

Epoch: 6| Step: 1
Training loss: 2.238309144973755
Validation loss: 2.1306041876475015

Epoch: 6| Step: 2
Training loss: 1.8409514427185059
Validation loss: 2.1240868171056113

Epoch: 6| Step: 3
Training loss: 1.5495226383209229
Validation loss: 2.133367339769999

Epoch: 6| Step: 4
Training loss: 2.0175862312316895
Validation loss: 2.1432308355967202

Epoch: 6| Step: 5
Training loss: 2.1714210510253906
Validation loss: 2.1099697748819985

Epoch: 6| Step: 6
Training loss: 2.132780075073242
Validation loss: 2.136850635210673

Epoch: 6| Step: 7
Training loss: 1.5152137279510498
Validation loss: 2.110647976398468

Epoch: 6| Step: 8
Training loss: 1.7357635498046875
Validation loss: 2.1341053446133933

Epoch: 6| Step: 9
Training loss: 2.377495050430298
Validation loss: 2.120325247446696

Epoch: 6| Step: 10
Training loss: 2.5922937393188477
Validation loss: 2.1481805642445884

Epoch: 6| Step: 11
Training loss: 2.7723517417907715
Validation loss: 2.1159041921297708

Epoch: 6| Step: 12
Training loss: 1.3229107856750488
Validation loss: 2.1109140714009604

Epoch: 6| Step: 13
Training loss: 2.5974550247192383
Validation loss: 2.1364879806836448

Epoch: 18| Step: 0
Training loss: 1.7348251342773438
Validation loss: 2.1696221828460693

Epoch: 6| Step: 1
Training loss: 1.9886733293533325
Validation loss: 2.1137362718582153

Epoch: 6| Step: 2
Training loss: 2.4123387336730957
Validation loss: 2.1355170607566833

Epoch: 6| Step: 3
Training loss: 2.5835530757904053
Validation loss: 2.1225550373395285

Epoch: 6| Step: 4
Training loss: 1.857340931892395
Validation loss: 2.0915865898132324

Epoch: 6| Step: 5
Training loss: 2.3443446159362793
Validation loss: 2.1419166326522827

Epoch: 6| Step: 6
Training loss: 2.676267147064209
Validation loss: 2.1287113626797995

Epoch: 6| Step: 7
Training loss: 1.9713603258132935
Validation loss: 2.1093478401501975

Epoch: 6| Step: 8
Training loss: 2.2436070442199707
Validation loss: 2.1103285948435464

Epoch: 6| Step: 9
Training loss: 1.9657427072525024
Validation loss: 2.08430552482605

Epoch: 6| Step: 10
Training loss: 1.3912875652313232
Validation loss: 2.1522388060887656

Epoch: 6| Step: 11
Training loss: 1.7072433233261108
Validation loss: 2.1188960472742715

Epoch: 6| Step: 12
Training loss: 1.8650740385055542
Validation loss: 2.0866848031679788

Epoch: 6| Step: 13
Training loss: 1.7403693199157715
Validation loss: 2.1054189801216125

Epoch: 19| Step: 0
Training loss: 1.9521243572235107
Validation loss: 2.1208932399749756

Epoch: 6| Step: 1
Training loss: 1.7471287250518799
Validation loss: 2.122268001238505

Epoch: 6| Step: 2
Training loss: 1.8845031261444092
Validation loss: 2.1436357498168945

Epoch: 6| Step: 3
Training loss: 2.3454270362854004
Validation loss: 2.066045085589091

Epoch: 6| Step: 4
Training loss: 2.005441665649414
Validation loss: 2.12363608678182

Epoch: 6| Step: 5
Training loss: 2.409730911254883
Validation loss: 2.120999018351237

Epoch: 6| Step: 6
Training loss: 1.6151442527770996
Validation loss: 2.1230660478274026

Epoch: 6| Step: 7
Training loss: 1.2033348083496094
Validation loss: 2.138761838277181

Epoch: 6| Step: 8
Training loss: 1.6417986154556274
Validation loss: 2.1352415879567466

Epoch: 6| Step: 9
Training loss: 2.62494158744812
Validation loss: 2.097108523050944

Epoch: 6| Step: 10
Training loss: 1.9636015892028809
Validation loss: 2.1217201550801597

Epoch: 6| Step: 11
Training loss: 2.5281805992126465
Validation loss: 2.1463278333346048

Epoch: 6| Step: 12
Training loss: 1.5171902179718018
Validation loss: 2.136998097101847

Epoch: 6| Step: 13
Training loss: 3.06903076171875
Validation loss: 2.114105701446533

Epoch: 20| Step: 0
Training loss: 1.6124053001403809
Validation loss: 2.1604437033335366

Epoch: 6| Step: 1
Training loss: 1.9625459909439087
Validation loss: 2.1745675802230835

Epoch: 6| Step: 2
Training loss: 2.113765001296997
Validation loss: 2.15375808874766

Epoch: 6| Step: 3
Training loss: 1.830654263496399
Validation loss: 2.193893313407898

Epoch: 6| Step: 4
Training loss: 2.71274733543396
Validation loss: 2.1831975181897483

Epoch: 6| Step: 5
Training loss: 2.2071216106414795
Validation loss: 2.153567910194397

Epoch: 6| Step: 6
Training loss: 2.2641687393188477
Validation loss: 2.128195583820343

Epoch: 6| Step: 7
Training loss: 1.9157294034957886
Validation loss: 2.114168107509613

Epoch: 6| Step: 8
Training loss: 1.787327527999878
Validation loss: 2.10043211778005

Epoch: 6| Step: 9
Training loss: 1.8188279867172241
Validation loss: 2.105130155881246

Epoch: 6| Step: 10
Training loss: 1.6507810354232788
Validation loss: 2.1067635218302407

Epoch: 6| Step: 11
Training loss: 2.263012647628784
Validation loss: 2.111407240231832

Epoch: 6| Step: 12
Training loss: 1.961247444152832
Validation loss: 2.1070660948753357

Epoch: 6| Step: 13
Training loss: 2.686222553253174
Validation loss: 2.1117748022079468

Epoch: 21| Step: 0
Training loss: 2.8857805728912354
Validation loss: 2.0905468265215554

Epoch: 6| Step: 1
Training loss: 1.9764673709869385
Validation loss: 2.137139320373535

Epoch: 6| Step: 2
Training loss: 2.2112698554992676
Validation loss: 2.118995984395345

Epoch: 6| Step: 3
Training loss: 1.8928700685501099
Validation loss: 2.1313156684239707

Epoch: 6| Step: 4
Training loss: 2.131516933441162
Validation loss: 2.111617902914683

Epoch: 6| Step: 5
Training loss: 1.9512138366699219
Validation loss: 2.14218799273173

Epoch: 6| Step: 6
Training loss: 1.8675241470336914
Validation loss: 2.0956323941548667

Epoch: 6| Step: 7
Training loss: 1.6865200996398926
Validation loss: 2.1073017915089927

Epoch: 6| Step: 8
Training loss: 2.8219456672668457
Validation loss: 2.1099181175231934

Epoch: 6| Step: 9
Training loss: 1.7359379529953003
Validation loss: 2.099926471710205

Epoch: 6| Step: 10
Training loss: 1.4579815864562988
Validation loss: 2.0922985076904297

Epoch: 6| Step: 11
Training loss: 2.028322696685791
Validation loss: 2.1213386058807373

Epoch: 6| Step: 12
Training loss: 2.2713284492492676
Validation loss: 2.125226934750875

Epoch: 6| Step: 13
Training loss: 1.802804946899414
Validation loss: 2.1271719535191855

Epoch: 22| Step: 0
Training loss: 2.207805633544922
Validation loss: 2.13362854719162

Epoch: 6| Step: 1
Training loss: 2.591869592666626
Validation loss: 2.1268075903256736

Epoch: 6| Step: 2
Training loss: 1.8457335233688354
Validation loss: 2.1272315780321756

Epoch: 6| Step: 3
Training loss: 1.3147553205490112
Validation loss: 2.132800738016764

Epoch: 6| Step: 4
Training loss: 1.7564525604248047
Validation loss: 2.1103371381759644

Epoch: 6| Step: 5
Training loss: 3.0355820655822754
Validation loss: 2.1104381680488586

Epoch: 6| Step: 6
Training loss: 1.931401014328003
Validation loss: 2.1202977498372397

Epoch: 6| Step: 7
Training loss: 1.3213900327682495
Validation loss: 2.1028069456418357

Epoch: 6| Step: 8
Training loss: 2.241516351699829
Validation loss: 2.097452978293101

Epoch: 6| Step: 9
Training loss: 1.7018604278564453
Validation loss: 2.147974193096161

Epoch: 6| Step: 10
Training loss: 2.1791129112243652
Validation loss: 2.101127823193868

Epoch: 6| Step: 11
Training loss: 2.389235496520996
Validation loss: 2.111531058947245

Epoch: 6| Step: 12
Training loss: 1.8663899898529053
Validation loss: 2.1400199135144553

Epoch: 6| Step: 13
Training loss: 1.9558278322219849
Validation loss: 2.1108110745747886

Epoch: 23| Step: 0
Training loss: 1.7326209545135498
Validation loss: 2.092497785886129

Epoch: 6| Step: 1
Training loss: 2.5996856689453125
Validation loss: 2.1349131067593894

Epoch: 6| Step: 2
Training loss: 1.3827242851257324
Validation loss: 2.0841769178708396

Epoch: 6| Step: 3
Training loss: 2.0357120037078857
Validation loss: 2.093337674935659

Epoch: 6| Step: 4
Training loss: 2.1082992553710938
Validation loss: 2.114890197912852

Epoch: 6| Step: 5
Training loss: 1.7771319150924683
Validation loss: 2.0791449745496116

Epoch: 6| Step: 6
Training loss: 2.1302249431610107
Validation loss: 2.1238222320874534

Epoch: 6| Step: 7
Training loss: 1.7520757913589478
Validation loss: 2.1029675602912903

Epoch: 6| Step: 8
Training loss: 1.6132683753967285
Validation loss: 2.1270696918169656

Epoch: 6| Step: 9
Training loss: 1.9873766899108887
Validation loss: 2.144178827603658

Epoch: 6| Step: 10
Training loss: 2.470073699951172
Validation loss: 2.1552143692970276

Epoch: 6| Step: 11
Training loss: 2.3657267093658447
Validation loss: 2.166412035624186

Epoch: 6| Step: 12
Training loss: 2.343787670135498
Validation loss: 2.1446438431739807

Epoch: 6| Step: 13
Training loss: 2.2747697830200195
Validation loss: 2.1348937352498374

Epoch: 24| Step: 0
Training loss: 1.258836030960083
Validation loss: 2.1403834422429404

Epoch: 6| Step: 1
Training loss: 2.024327039718628
Validation loss: 2.1279043157895408

Epoch: 6| Step: 2
Training loss: 2.410919427871704
Validation loss: 2.1358341177304587

Epoch: 6| Step: 3
Training loss: 1.7610454559326172
Validation loss: 2.143846869468689

Epoch: 6| Step: 4
Training loss: 2.3084397315979004
Validation loss: 2.1303081115086875

Epoch: 6| Step: 5
Training loss: 1.4646356105804443
Validation loss: 2.152531305948893

Epoch: 6| Step: 6
Training loss: 1.8297921419143677
Validation loss: 2.082773506641388

Epoch: 6| Step: 7
Training loss: 2.0623464584350586
Validation loss: 2.0924795071283975

Epoch: 6| Step: 8
Training loss: 2.4877219200134277
Validation loss: 2.0907526214917502

Epoch: 6| Step: 9
Training loss: 2.5062501430511475
Validation loss: 2.119363804658254

Epoch: 6| Step: 10
Training loss: 2.461981773376465
Validation loss: 2.1189768513043723

Epoch: 6| Step: 11
Training loss: 2.2194533348083496
Validation loss: 2.117141922314962

Epoch: 6| Step: 12
Training loss: 1.5501055717468262
Validation loss: 2.0786646405855813

Epoch: 6| Step: 13
Training loss: 2.2433791160583496
Validation loss: 2.112967610359192

Epoch: 25| Step: 0
Training loss: 2.3123092651367188
Validation loss: 2.0960148771603904

Epoch: 6| Step: 1
Training loss: 1.1284451484680176
Validation loss: 2.1231804490089417

Epoch: 6| Step: 2
Training loss: 1.8084700107574463
Validation loss: 2.122403939565023

Epoch: 6| Step: 3
Training loss: 2.8899641036987305
Validation loss: 2.115859309832255

Epoch: 6| Step: 4
Training loss: 1.8811266422271729
Validation loss: 2.1122088630994162

Epoch: 6| Step: 5
Training loss: 2.4987683296203613
Validation loss: 2.108343521753947

Epoch: 6| Step: 6
Training loss: 1.8574867248535156
Validation loss: 2.1593040227890015

Epoch: 6| Step: 7
Training loss: 2.3075876235961914
Validation loss: 2.1237966815630593

Epoch: 6| Step: 8
Training loss: 2.6141786575317383
Validation loss: 2.1166032751401267

Epoch: 6| Step: 9
Training loss: 1.6815441846847534
Validation loss: 2.128577987353007

Epoch: 6| Step: 10
Training loss: 1.9126240015029907
Validation loss: 2.131129264831543

Epoch: 6| Step: 11
Training loss: 2.2441439628601074
Validation loss: 2.0969329873720803

Epoch: 6| Step: 12
Training loss: 1.683239459991455
Validation loss: 2.1297799547513327

Epoch: 6| Step: 13
Training loss: 1.7759051322937012
Validation loss: 2.087968389193217

Epoch: 26| Step: 0
Training loss: 2.6848318576812744
Validation loss: 2.084555665651957

Epoch: 6| Step: 1
Training loss: 2.6634738445281982
Validation loss: 2.083553691705068

Epoch: 6| Step: 2
Training loss: 2.0654821395874023
Validation loss: 2.0885023077329

Epoch: 6| Step: 3
Training loss: 2.0547423362731934
Validation loss: 2.094925026098887

Epoch: 6| Step: 4
Training loss: 1.8866959810256958
Validation loss: 2.110530157883962

Epoch: 6| Step: 5
Training loss: 2.028724193572998
Validation loss: 2.141545315583547

Epoch: 6| Step: 6
Training loss: 2.275757074356079
Validation loss: 2.120310386021932

Epoch: 6| Step: 7
Training loss: 1.8107703924179077
Validation loss: 2.0814196268717446

Epoch: 6| Step: 8
Training loss: 2.113980770111084
Validation loss: 2.108871658643087

Epoch: 6| Step: 9
Training loss: 1.9768059253692627
Validation loss: 2.1290030280749

Epoch: 6| Step: 10
Training loss: 1.9306052923202515
Validation loss: 2.096787432829539

Epoch: 6| Step: 11
Training loss: 1.7421162128448486
Validation loss: 2.144442935784658

Epoch: 6| Step: 12
Training loss: 1.5974582433700562
Validation loss: 2.077993472417196

Epoch: 6| Step: 13
Training loss: 2.2328438758850098
Validation loss: 2.12400229771932

Epoch: 27| Step: 0
Training loss: 2.3461647033691406
Validation loss: 2.0784494876861572

Epoch: 6| Step: 1
Training loss: 2.015582323074341
Validation loss: 2.0750091473261514

Epoch: 6| Step: 2
Training loss: 1.7821305990219116
Validation loss: 2.092149257659912

Epoch: 6| Step: 3
Training loss: 2.212833881378174
Validation loss: 2.123321990172068

Epoch: 6| Step: 4
Training loss: 2.0324995517730713
Validation loss: 2.1147820353507996

Epoch: 6| Step: 5
Training loss: 2.445150136947632
Validation loss: 2.1254093448321023

Epoch: 6| Step: 6
Training loss: 1.829882025718689
Validation loss: 2.106620649496714

Epoch: 6| Step: 7
Training loss: 2.0368733406066895
Validation loss: 2.0961729884147644

Epoch: 6| Step: 8
Training loss: 1.8534997701644897
Validation loss: 2.093616525332133

Epoch: 6| Step: 9
Training loss: 2.2997090816497803
Validation loss: 2.1130215525627136

Epoch: 6| Step: 10
Training loss: 1.3585667610168457
Validation loss: 2.089539110660553

Epoch: 6| Step: 11
Training loss: 2.0114519596099854
Validation loss: 2.087597111860911

Epoch: 6| Step: 12
Training loss: 2.127502918243408
Validation loss: 2.144256591796875

Epoch: 6| Step: 13
Training loss: 2.2774367332458496
Validation loss: 2.107740044593811

Epoch: 28| Step: 0
Training loss: 1.8808151483535767
Validation loss: 2.125326633453369

Epoch: 6| Step: 1
Training loss: 2.0325076580047607
Validation loss: 2.115014652411143

Epoch: 6| Step: 2
Training loss: 1.9353351593017578
Validation loss: 2.104091246922811

Epoch: 6| Step: 3
Training loss: 2.08475923538208
Validation loss: 2.1861743728319802

Epoch: 6| Step: 4
Training loss: 2.6994030475616455
Validation loss: 2.1395916740099588

Epoch: 6| Step: 5
Training loss: 1.8716181516647339
Validation loss: 2.1225448648134866

Epoch: 6| Step: 6
Training loss: 2.0565345287323
Validation loss: 2.2088162700335183

Epoch: 6| Step: 7
Training loss: 2.976414680480957
Validation loss: 2.1676493883132935

Epoch: 6| Step: 8
Training loss: 1.9418331384658813
Validation loss: 2.1332290967305503

Epoch: 6| Step: 9
Training loss: 2.069392681121826
Validation loss: 2.121259252230326

Epoch: 6| Step: 10
Training loss: 1.78737473487854
Validation loss: 2.126981496810913

Epoch: 6| Step: 11
Training loss: 1.8662610054016113
Validation loss: 2.0776928265889487

Epoch: 6| Step: 12
Training loss: 1.9005863666534424
Validation loss: 2.116067945957184

Epoch: 6| Step: 13
Training loss: 1.6187529563903809
Validation loss: 2.1460447112719216

Epoch: 29| Step: 0
Training loss: 2.0428760051727295
Validation loss: 2.1108969251314798

Epoch: 6| Step: 1
Training loss: 2.0260629653930664
Validation loss: 2.122088293234507

Epoch: 6| Step: 2
Training loss: 1.8281453847885132
Validation loss: 2.0869200428326926

Epoch: 6| Step: 3
Training loss: 1.3961492776870728
Validation loss: 2.104241649309794

Epoch: 6| Step: 4
Training loss: 1.9188107252120972
Validation loss: 2.073392391204834

Epoch: 6| Step: 5
Training loss: 2.1557741165161133
Validation loss: 2.116832355658213

Epoch: 6| Step: 6
Training loss: 2.100874423980713
Validation loss: 2.103000064690908

Epoch: 6| Step: 7
Training loss: 2.125737190246582
Validation loss: 2.083654224872589

Epoch: 6| Step: 8
Training loss: 3.257500410079956
Validation loss: 2.101913253466288

Epoch: 6| Step: 9
Training loss: 1.7651880979537964
Validation loss: 2.079186817010244

Epoch: 6| Step: 10
Training loss: 1.9666903018951416
Validation loss: 2.0517503023147583

Epoch: 6| Step: 11
Training loss: 1.5385301113128662
Validation loss: 2.0704973141352334

Epoch: 6| Step: 12
Training loss: 2.467048168182373
Validation loss: 2.0899176597595215

Epoch: 6| Step: 13
Training loss: 2.0602915287017822
Validation loss: 2.093505303064982

Epoch: 30| Step: 0
Training loss: 1.7977628707885742
Validation loss: 2.1047609647115073

Epoch: 6| Step: 1
Training loss: 1.7571157217025757
Validation loss: 2.0692044496536255

Epoch: 6| Step: 2
Training loss: 1.9361085891723633
Validation loss: 2.1087263226509094

Epoch: 6| Step: 3
Training loss: 2.182605504989624
Validation loss: 2.105106751124064

Epoch: 6| Step: 4
Training loss: 1.9307690858840942
Validation loss: 2.0847460826238

Epoch: 6| Step: 5
Training loss: 2.0324270725250244
Validation loss: 2.1115872859954834

Epoch: 6| Step: 6
Training loss: 1.4012964963912964
Validation loss: 2.152807096640269

Epoch: 6| Step: 7
Training loss: 1.8331646919250488
Validation loss: 2.115564465522766

Epoch: 6| Step: 8
Training loss: 2.176161766052246
Validation loss: 2.1223553816477456

Epoch: 6| Step: 9
Training loss: 2.3432202339172363
Validation loss: 2.1084861159324646

Epoch: 6| Step: 10
Training loss: 2.164560317993164
Validation loss: 2.0999374389648438

Epoch: 6| Step: 11
Training loss: 1.8097947835922241
Validation loss: 2.1244025230407715

Epoch: 6| Step: 12
Training loss: 2.4186487197875977
Validation loss: 2.0770603815714517

Epoch: 6| Step: 13
Training loss: 2.381518840789795
Validation loss: 2.105993906656901

Epoch: 31| Step: 0
Training loss: 2.8492777347564697
Validation loss: 2.1335533062616983

Epoch: 6| Step: 1
Training loss: 1.6615302562713623
Validation loss: 2.0785422921180725

Epoch: 6| Step: 2
Training loss: 1.7230274677276611
Validation loss: 2.113414386908213

Epoch: 6| Step: 3
Training loss: 2.012673854827881
Validation loss: 2.1251271764437356

Epoch: 6| Step: 4
Training loss: 1.5442957878112793
Validation loss: 2.1024150053660073

Epoch: 6| Step: 5
Training loss: 2.101585865020752
Validation loss: 2.1101768414179483

Epoch: 6| Step: 6
Training loss: 2.3609564304351807
Validation loss: 2.092024862766266

Epoch: 6| Step: 7
Training loss: 2.182095527648926
Validation loss: 2.063066085179647

Epoch: 6| Step: 8
Training loss: 2.072075843811035
Validation loss: 2.0990779201189675

Epoch: 6| Step: 9
Training loss: 1.5088953971862793
Validation loss: 2.070207436879476

Epoch: 6| Step: 10
Training loss: 1.798888921737671
Validation loss: 2.0763535499572754

Epoch: 6| Step: 11
Training loss: 1.8315273523330688
Validation loss: 2.0486087997754416

Epoch: 6| Step: 12
Training loss: 2.318019390106201
Validation loss: 2.1120806336402893

Epoch: 6| Step: 13
Training loss: 2.0084986686706543
Validation loss: 2.1056732734044394

Epoch: 32| Step: 0
Training loss: 1.4146528244018555
Validation loss: 2.0822997291882834

Epoch: 6| Step: 1
Training loss: 1.7960002422332764
Validation loss: 2.1493865052858987

Epoch: 6| Step: 2
Training loss: 1.7607053518295288
Validation loss: 2.116043428579966

Epoch: 6| Step: 3
Training loss: 1.499757170677185
Validation loss: 2.09913835922877

Epoch: 6| Step: 4
Training loss: 2.1646981239318848
Validation loss: 2.0816149910291037

Epoch: 6| Step: 5
Training loss: 2.207822799682617
Validation loss: 2.0935069918632507

Epoch: 6| Step: 6
Training loss: 2.2440340518951416
Validation loss: 2.106884241104126

Epoch: 6| Step: 7
Training loss: 1.92649245262146
Validation loss: 2.111975391705831

Epoch: 6| Step: 8
Training loss: 2.408864974975586
Validation loss: 2.1104997992515564

Epoch: 6| Step: 9
Training loss: 2.3780202865600586
Validation loss: 2.120065450668335

Epoch: 6| Step: 10
Training loss: 1.4295436143875122
Validation loss: 2.1114397843678794

Epoch: 6| Step: 11
Training loss: 2.495206594467163
Validation loss: 2.123156507809957

Epoch: 6| Step: 12
Training loss: 2.171438217163086
Validation loss: 2.086691657702128

Epoch: 6| Step: 13
Training loss: 2.236372947692871
Validation loss: 2.083344340324402

Epoch: 33| Step: 0
Training loss: 2.3596885204315186
Validation loss: 2.1346433560053506

Epoch: 6| Step: 1
Training loss: 2.332155227661133
Validation loss: 2.110133330027262

Epoch: 6| Step: 2
Training loss: 2.4086289405822754
Validation loss: 2.110395590464274

Epoch: 6| Step: 3
Training loss: 2.2062370777130127
Validation loss: 2.0912752946217856

Epoch: 6| Step: 4
Training loss: 2.4894890785217285
Validation loss: 2.130462348461151

Epoch: 6| Step: 5
Training loss: 1.8922996520996094
Validation loss: 2.110223412513733

Epoch: 6| Step: 6
Training loss: 1.769845962524414
Validation loss: 2.1061129570007324

Epoch: 6| Step: 7
Training loss: 1.5464706420898438
Validation loss: 2.141500473022461

Epoch: 6| Step: 8
Training loss: 1.8932275772094727
Validation loss: 2.126500189304352

Epoch: 6| Step: 9
Training loss: 2.006178855895996
Validation loss: 2.0896671414375305

Epoch: 6| Step: 10
Training loss: 1.3618559837341309
Validation loss: 2.121231178442637

Epoch: 6| Step: 11
Training loss: 1.8392131328582764
Validation loss: 2.0885090231895447

Epoch: 6| Step: 12
Training loss: 1.6077618598937988
Validation loss: 2.1142629384994507

Epoch: 6| Step: 13
Training loss: 2.558750629425049
Validation loss: 2.0925681789716086

Epoch: 34| Step: 0
Training loss: 1.7527273893356323
Validation loss: 2.0943219463030496

Epoch: 6| Step: 1
Training loss: 1.9464826583862305
Validation loss: 2.0861336986223855

Epoch: 6| Step: 2
Training loss: 2.5981407165527344
Validation loss: 2.1039904157320657

Epoch: 6| Step: 3
Training loss: 1.607494592666626
Validation loss: 2.094486117362976

Epoch: 6| Step: 4
Training loss: 2.2871973514556885
Validation loss: 2.0806164145469666

Epoch: 6| Step: 5
Training loss: 2.158200263977051
Validation loss: 2.1310287912686667

Epoch: 6| Step: 6
Training loss: 1.8975846767425537
Validation loss: 2.0853254993756614

Epoch: 6| Step: 7
Training loss: 1.4724047183990479
Validation loss: 2.1099692384401956

Epoch: 6| Step: 8
Training loss: 1.9990568161010742
Validation loss: 2.0974156856536865

Epoch: 6| Step: 9
Training loss: 1.8066061735153198
Validation loss: 2.0969093243281045

Epoch: 6| Step: 10
Training loss: 2.2727952003479004
Validation loss: 2.0796701510747275

Epoch: 6| Step: 11
Training loss: 1.8647785186767578
Validation loss: 2.075208862622579

Epoch: 6| Step: 12
Training loss: 2.6691396236419678
Validation loss: 2.1348453362782798

Epoch: 6| Step: 13
Training loss: 1.6812524795532227
Validation loss: 2.0678292910257974

Epoch: 35| Step: 0
Training loss: 1.325018048286438
Validation loss: 2.1143744587898254

Epoch: 6| Step: 1
Training loss: 2.747997522354126
Validation loss: 2.090474764506022

Epoch: 6| Step: 2
Training loss: 2.004324436187744
Validation loss: 2.098759671052297

Epoch: 6| Step: 3
Training loss: 2.0543875694274902
Validation loss: 2.1169998248418174

Epoch: 6| Step: 4
Training loss: 1.666947603225708
Validation loss: 2.097618877887726

Epoch: 6| Step: 5
Training loss: 2.488036632537842
Validation loss: 2.1163388888041177

Epoch: 6| Step: 6
Training loss: 1.9353280067443848
Validation loss: 2.136716663837433

Epoch: 6| Step: 7
Training loss: 2.0626633167266846
Validation loss: 2.103921810785929

Epoch: 6| Step: 8
Training loss: 1.8982172012329102
Validation loss: 2.0854627887407937

Epoch: 6| Step: 9
Training loss: 1.947585105895996
Validation loss: 2.0940621495246887

Epoch: 6| Step: 10
Training loss: 1.6206811666488647
Validation loss: 2.0759345491727195

Epoch: 6| Step: 11
Training loss: 2.1719322204589844
Validation loss: 2.0777187744776406

Epoch: 6| Step: 12
Training loss: 2.497098445892334
Validation loss: 2.0975918769836426

Epoch: 6| Step: 13
Training loss: 1.5087170600891113
Validation loss: 2.08399905761083

Epoch: 36| Step: 0
Training loss: 1.1017624139785767
Validation loss: 2.106135070323944

Epoch: 6| Step: 1
Training loss: 2.1209936141967773
Validation loss: 2.089748958746592

Epoch: 6| Step: 2
Training loss: 2.2358298301696777
Validation loss: 2.1105031967163086

Epoch: 6| Step: 3
Training loss: 2.658622980117798
Validation loss: 2.100990911324819

Epoch: 6| Step: 4
Training loss: 3.0840816497802734
Validation loss: 2.101854165395101

Epoch: 6| Step: 5
Training loss: 1.916351079940796
Validation loss: 2.1231063405672708

Epoch: 6| Step: 6
Training loss: 1.9933174848556519
Validation loss: 2.0939433773358664

Epoch: 6| Step: 7
Training loss: 1.933257818222046
Validation loss: 2.1052337884902954

Epoch: 6| Step: 8
Training loss: 1.619714617729187
Validation loss: 2.0905860463778176

Epoch: 6| Step: 9
Training loss: 1.843275547027588
Validation loss: 2.1137566566467285

Epoch: 6| Step: 10
Training loss: 1.7478270530700684
Validation loss: 2.0775588154792786

Epoch: 6| Step: 11
Training loss: 2.0512466430664062
Validation loss: 2.1081471840540567

Epoch: 6| Step: 12
Training loss: 1.7099770307540894
Validation loss: 2.0791275898615518

Epoch: 6| Step: 13
Training loss: 2.1646385192871094
Validation loss: 2.0738871097564697

Epoch: 37| Step: 0
Training loss: 1.6838730573654175
Validation loss: 2.0913525422414145

Epoch: 6| Step: 1
Training loss: 1.0304276943206787
Validation loss: 2.100062370300293

Epoch: 6| Step: 2
Training loss: 1.6670286655426025
Validation loss: 2.125254293282827

Epoch: 6| Step: 3
Training loss: 1.5896257162094116
Validation loss: 2.144058048725128

Epoch: 6| Step: 4
Training loss: 2.7586398124694824
Validation loss: 2.116507112979889

Epoch: 6| Step: 5
Training loss: 2.0214931964874268
Validation loss: 2.102865715821584

Epoch: 6| Step: 6
Training loss: 2.013639211654663
Validation loss: 2.1238401730855307

Epoch: 6| Step: 7
Training loss: 2.4939680099487305
Validation loss: 2.1018903255462646

Epoch: 6| Step: 8
Training loss: 2.201035976409912
Validation loss: 2.1243918538093567

Epoch: 6| Step: 9
Training loss: 2.112658977508545
Validation loss: 2.066750645637512

Epoch: 6| Step: 10
Training loss: 2.0536563396453857
Validation loss: 2.1106156508127847

Epoch: 6| Step: 11
Training loss: 2.395510673522949
Validation loss: 2.127886096636454

Epoch: 6| Step: 12
Training loss: 2.3016819953918457
Validation loss: 2.160326381524404

Epoch: 6| Step: 13
Training loss: 2.1447582244873047
Validation loss: 2.090433955192566

Epoch: 38| Step: 0
Training loss: 1.8721084594726562
Validation loss: 2.1247665683428445

Epoch: 6| Step: 1
Training loss: 2.268651008605957
Validation loss: 2.0907000303268433

Epoch: 6| Step: 2
Training loss: 2.2641592025756836
Validation loss: 2.08915768067042

Epoch: 6| Step: 3
Training loss: 2.105164051055908
Validation loss: 2.0627041856447854

Epoch: 6| Step: 4
Training loss: 2.009148597717285
Validation loss: 2.089724361896515

Epoch: 6| Step: 5
Training loss: 1.9344828128814697
Validation loss: 2.1245113015174866

Epoch: 6| Step: 6
Training loss: 1.9003161191940308
Validation loss: 2.065984586874644

Epoch: 6| Step: 7
Training loss: 1.7708563804626465
Validation loss: 2.110511918862661

Epoch: 6| Step: 8
Training loss: 1.4256718158721924
Validation loss: 2.0632236997286477

Epoch: 6| Step: 9
Training loss: 1.9635728597640991
Validation loss: 2.096458454926809

Epoch: 6| Step: 10
Training loss: 2.4699037075042725
Validation loss: 2.0359705289204917

Epoch: 6| Step: 11
Training loss: 2.4489388465881348
Validation loss: 2.0947515765825906

Epoch: 6| Step: 12
Training loss: 2.012563943862915
Validation loss: 2.078389286994934

Epoch: 6| Step: 13
Training loss: 1.876569390296936
Validation loss: 2.0891489585240683

Epoch: 39| Step: 0
Training loss: 2.806297779083252
Validation loss: 2.084692418575287

Epoch: 6| Step: 1
Training loss: 1.8178898096084595
Validation loss: 2.090432862440745

Epoch: 6| Step: 2
Training loss: 1.606903076171875
Validation loss: 2.1106241742769876

Epoch: 6| Step: 3
Training loss: 2.244049549102783
Validation loss: 2.0866824984550476

Epoch: 6| Step: 4
Training loss: 2.0921757221221924
Validation loss: 2.0841156045595803

Epoch: 6| Step: 5
Training loss: 1.2387938499450684
Validation loss: 2.1013369957605996

Epoch: 6| Step: 6
Training loss: 1.7431166172027588
Validation loss: 2.076213300228119

Epoch: 6| Step: 7
Training loss: 1.5751333236694336
Validation loss: 2.0837834080060325

Epoch: 6| Step: 8
Training loss: 2.1574718952178955
Validation loss: 2.0537327329317727

Epoch: 6| Step: 9
Training loss: 1.8235729932785034
Validation loss: 2.0992038448651633

Epoch: 6| Step: 10
Training loss: 1.4999315738677979
Validation loss: 2.1003565390904746

Epoch: 6| Step: 11
Training loss: 2.241270065307617
Validation loss: 2.0982724825541177

Epoch: 6| Step: 12
Training loss: 2.2520010471343994
Validation loss: 2.0944177508354187

Epoch: 6| Step: 13
Training loss: 2.768178939819336
Validation loss: 2.1122027238210044

Epoch: 40| Step: 0
Training loss: 2.0904035568237305
Validation loss: 2.089553872744242

Epoch: 6| Step: 1
Training loss: 2.8425471782684326
Validation loss: 2.1165493528048196

Epoch: 6| Step: 2
Training loss: 1.5967676639556885
Validation loss: 2.1058849493662515

Epoch: 6| Step: 3
Training loss: 1.8603169918060303
Validation loss: 2.0763503313064575

Epoch: 6| Step: 4
Training loss: 1.5365756750106812
Validation loss: 2.120233178138733

Epoch: 6| Step: 5
Training loss: 1.7197468280792236
Validation loss: 2.145643472671509

Epoch: 6| Step: 6
Training loss: 2.00435733795166
Validation loss: 2.133616109689077

Epoch: 6| Step: 7
Training loss: 2.9092178344726562
Validation loss: 2.0979332526524863

Epoch: 6| Step: 8
Training loss: 2.112834930419922
Validation loss: 2.0964552958806357

Epoch: 6| Step: 9
Training loss: 2.3512744903564453
Validation loss: 2.033655305703481

Epoch: 6| Step: 10
Training loss: 1.3078553676605225
Validation loss: 2.0854344367980957

Epoch: 6| Step: 11
Training loss: 1.785092830657959
Validation loss: 2.0631211598714194

Epoch: 6| Step: 12
Training loss: 2.0818347930908203
Validation loss: 2.110416571299235

Epoch: 6| Step: 13
Training loss: 1.7535486221313477
Validation loss: 2.0936935941378274

Epoch: 41| Step: 0
Training loss: 3.018296241760254
Validation loss: 2.1102996269861856

Epoch: 6| Step: 1
Training loss: 1.8039852380752563
Validation loss: 2.0788211822509766

Epoch: 6| Step: 2
Training loss: 2.175128936767578
Validation loss: 2.0974443554878235

Epoch: 6| Step: 3
Training loss: 2.1664512157440186
Validation loss: 2.078555683294932

Epoch: 6| Step: 4
Training loss: 1.764370322227478
Validation loss: 2.084217627843221

Epoch: 6| Step: 5
Training loss: 1.673848271369934
Validation loss: 2.1006007194519043

Epoch: 6| Step: 6
Training loss: 2.3713245391845703
Validation loss: 2.084283947944641

Epoch: 6| Step: 7
Training loss: 2.1092686653137207
Validation loss: 2.0883824626604715

Epoch: 6| Step: 8
Training loss: 1.6590250730514526
Validation loss: 2.0834787487983704

Epoch: 6| Step: 9
Training loss: 2.2487974166870117
Validation loss: 2.0932350357373557

Epoch: 6| Step: 10
Training loss: 1.624409556388855
Validation loss: 2.098935862382253

Epoch: 6| Step: 11
Training loss: 1.9706286191940308
Validation loss: 2.043938159942627

Epoch: 6| Step: 12
Training loss: 1.8439180850982666
Validation loss: 2.083974599838257

Epoch: 6| Step: 13
Training loss: 1.3647100925445557
Validation loss: 2.102057615915934

Epoch: 42| Step: 0
Training loss: 2.0708141326904297
Validation loss: 2.079612672328949

Epoch: 6| Step: 1
Training loss: 2.1748061180114746
Validation loss: 2.1052581866582236

Epoch: 6| Step: 2
Training loss: 2.080425262451172
Validation loss: 2.113237281640371

Epoch: 6| Step: 3
Training loss: 2.1056466102600098
Validation loss: 2.0760801633199057

Epoch: 6| Step: 4
Training loss: 1.8340429067611694
Validation loss: 2.0725395480791726

Epoch: 6| Step: 5
Training loss: 1.5947904586791992
Validation loss: 2.132281263669332

Epoch: 6| Step: 6
Training loss: 2.610865831375122
Validation loss: 2.151415228843689

Epoch: 6| Step: 7
Training loss: 2.6400089263916016
Validation loss: 2.1509495973587036

Epoch: 6| Step: 8
Training loss: 1.5223134756088257
Validation loss: 2.113798518975576

Epoch: 6| Step: 9
Training loss: 1.932293176651001
Validation loss: 2.138134777545929

Epoch: 6| Step: 10
Training loss: 2.072352409362793
Validation loss: 2.114343007405599

Epoch: 6| Step: 11
Training loss: 1.5463026762008667
Validation loss: 2.0648857156435647

Epoch: 6| Step: 12
Training loss: 2.095224618911743
Validation loss: 2.115785797437032

Epoch: 6| Step: 13
Training loss: 2.445701837539673
Validation loss: 2.0524715383847556

Epoch: 43| Step: 0
Training loss: 2.786930799484253
Validation loss: 2.1002829869588218

Epoch: 6| Step: 1
Training loss: 2.546393394470215
Validation loss: 2.1071980198224387

Epoch: 6| Step: 2
Training loss: 1.7663452625274658
Validation loss: 2.082136253515879

Epoch: 6| Step: 3
Training loss: 1.888950228691101
Validation loss: 2.0672230323155723

Epoch: 6| Step: 4
Training loss: 2.0815775394439697
Validation loss: 2.101854423681895

Epoch: 6| Step: 5
Training loss: 1.9855680465698242
Validation loss: 2.0665679574012756

Epoch: 6| Step: 6
Training loss: 1.6139854192733765
Validation loss: 2.054541369279226

Epoch: 6| Step: 7
Training loss: 1.6709907054901123
Validation loss: 2.114821672439575

Epoch: 6| Step: 8
Training loss: 1.5694068670272827
Validation loss: 2.042701522509257

Epoch: 6| Step: 9
Training loss: 2.508519172668457
Validation loss: 2.0672401785850525

Epoch: 6| Step: 10
Training loss: 1.4527842998504639
Validation loss: 2.0635483066240945

Epoch: 6| Step: 11
Training loss: 2.35447359085083
Validation loss: 2.0834070642789206

Epoch: 6| Step: 12
Training loss: 2.4544949531555176
Validation loss: 2.1031171480814614

Epoch: 6| Step: 13
Training loss: 1.3409550189971924
Validation loss: 2.1069791515668235

Epoch: 44| Step: 0
Training loss: 2.769521713256836
Validation loss: 2.077339231967926

Epoch: 6| Step: 1
Training loss: 2.179992198944092
Validation loss: 2.106375515460968

Epoch: 6| Step: 2
Training loss: 1.4817404747009277
Validation loss: 2.1210386157035828

Epoch: 6| Step: 3
Training loss: 1.7324802875518799
Validation loss: 2.1229931314786277

Epoch: 6| Step: 4
Training loss: 1.7235333919525146
Validation loss: 2.1313766042391458

Epoch: 6| Step: 5
Training loss: 1.4417808055877686
Validation loss: 2.1389777461687722

Epoch: 6| Step: 6
Training loss: 2.0901947021484375
Validation loss: 2.0947165489196777

Epoch: 6| Step: 7
Training loss: 1.6493738889694214
Validation loss: 2.082136650880178

Epoch: 6| Step: 8
Training loss: 1.5926369428634644
Validation loss: 2.123973627885183

Epoch: 6| Step: 9
Training loss: 1.8645881414413452
Validation loss: 2.075570265452067

Epoch: 6| Step: 10
Training loss: 2.849041700363159
Validation loss: 2.1279950737953186

Epoch: 6| Step: 11
Training loss: 2.2244958877563477
Validation loss: 2.106198708216349

Epoch: 6| Step: 12
Training loss: 2.48819899559021
Validation loss: 2.0897935231526694

Epoch: 6| Step: 13
Training loss: 2.1510391235351562
Validation loss: 2.093221882979075

Epoch: 45| Step: 0
Training loss: 1.8931938409805298
Validation loss: 2.095568756262461

Epoch: 6| Step: 1
Training loss: 2.2038474082946777
Validation loss: 2.051137149333954

Epoch: 6| Step: 2
Training loss: 1.6714940071105957
Validation loss: 2.071676472822825

Epoch: 6| Step: 3
Training loss: 2.1126489639282227
Validation loss: 2.0718741416931152

Epoch: 6| Step: 4
Training loss: 2.0646681785583496
Validation loss: 2.093875825405121

Epoch: 6| Step: 5
Training loss: 1.4323163032531738
Validation loss: 2.1143239537874856

Epoch: 6| Step: 6
Training loss: 2.0779881477355957
Validation loss: 2.1070324778556824

Epoch: 6| Step: 7
Training loss: 2.1522305011749268
Validation loss: 2.093895137310028

Epoch: 6| Step: 8
Training loss: 1.756425380706787
Validation loss: 2.106788396835327

Epoch: 6| Step: 9
Training loss: 2.6334235668182373
Validation loss: 2.0845815738042197

Epoch: 6| Step: 10
Training loss: 1.8814692497253418
Validation loss: 2.103346029917399

Epoch: 6| Step: 11
Training loss: 1.9610329866409302
Validation loss: 2.1229577461878457

Epoch: 6| Step: 12
Training loss: 1.8316468000411987
Validation loss: 2.112000564734141

Epoch: 6| Step: 13
Training loss: 2.3449931144714355
Validation loss: 2.0508428812026978

Epoch: 46| Step: 0
Training loss: 2.072545051574707
Validation loss: 2.093339522679647

Epoch: 6| Step: 1
Training loss: 1.6132800579071045
Validation loss: 2.1142889658610025

Epoch: 6| Step: 2
Training loss: 1.9072660207748413
Validation loss: 2.1173555056254068

Epoch: 6| Step: 3
Training loss: 1.92979097366333
Validation loss: 2.093433956305186

Epoch: 6| Step: 4
Training loss: 2.3491885662078857
Validation loss: 2.0902353525161743

Epoch: 6| Step: 5
Training loss: 2.469381332397461
Validation loss: 2.1018230319023132

Epoch: 6| Step: 6
Training loss: 1.8377439975738525
Validation loss: 2.0862764716148376

Epoch: 6| Step: 7
Training loss: 2.3710527420043945
Validation loss: 2.08255406220754

Epoch: 6| Step: 8
Training loss: 1.547685146331787
Validation loss: 2.0655700961748757

Epoch: 6| Step: 9
Training loss: 2.2646753787994385
Validation loss: 2.1048310001691184

Epoch: 6| Step: 10
Training loss: 1.3319323062896729
Validation loss: 2.0548781553904214

Epoch: 6| Step: 11
Training loss: 2.3400518894195557
Validation loss: 2.0905881524086

Epoch: 6| Step: 12
Training loss: 1.4073545932769775
Validation loss: 2.0638232429822287

Epoch: 6| Step: 13
Training loss: 2.1670446395874023
Validation loss: 2.1044418017069497

Epoch: 47| Step: 0
Training loss: 2.1218411922454834
Validation loss: 2.078427016735077

Epoch: 6| Step: 1
Training loss: 1.4515016078948975
Validation loss: 2.0968185464541116

Epoch: 6| Step: 2
Training loss: 2.0233943462371826
Validation loss: 2.0566829641660056

Epoch: 6| Step: 3
Training loss: 2.1929585933685303
Validation loss: 2.0919517278671265

Epoch: 6| Step: 4
Training loss: 2.834075689315796
Validation loss: 2.1153350472450256

Epoch: 6| Step: 5
Training loss: 2.2936933040618896
Validation loss: 2.096247375011444

Epoch: 6| Step: 6
Training loss: 1.925913691520691
Validation loss: 2.0818005005518594

Epoch: 6| Step: 7
Training loss: 2.0581748485565186
Validation loss: 2.0769514640172324

Epoch: 6| Step: 8
Training loss: 1.250433325767517
Validation loss: 2.084770659605662

Epoch: 6| Step: 9
Training loss: 1.984102725982666
Validation loss: 2.0722002188364663

Epoch: 6| Step: 10
Training loss: 1.6034936904907227
Validation loss: 2.072701911131541

Epoch: 6| Step: 11
Training loss: 1.7819557189941406
Validation loss: 2.1048837900161743

Epoch: 6| Step: 12
Training loss: 2.141192674636841
Validation loss: 2.0963958700497947

Epoch: 6| Step: 13
Training loss: 2.118121385574341
Validation loss: 2.058092494805654

Epoch: 48| Step: 0
Training loss: 1.0606428384780884
Validation loss: 2.0874858498573303

Epoch: 6| Step: 1
Training loss: 2.3822357654571533
Validation loss: 2.159012039502462

Epoch: 6| Step: 2
Training loss: 2.3364548683166504
Validation loss: 2.152920881907145

Epoch: 6| Step: 3
Training loss: 2.3240370750427246
Validation loss: 2.165527582168579

Epoch: 6| Step: 4
Training loss: 2.46379017829895
Validation loss: 2.1721892754236856

Epoch: 6| Step: 5
Training loss: 1.6535923480987549
Validation loss: 2.165973126888275

Epoch: 6| Step: 6
Training loss: 1.7273938655853271
Validation loss: 2.147169570128123

Epoch: 6| Step: 7
Training loss: 1.318108081817627
Validation loss: 2.1439713637034097

Epoch: 6| Step: 8
Training loss: 2.389585256576538
Validation loss: 2.1175565123558044

Epoch: 6| Step: 9
Training loss: 1.892087697982788
Validation loss: 2.1268771290779114

Epoch: 6| Step: 10
Training loss: 1.6695805788040161
Validation loss: 2.087107320626577

Epoch: 6| Step: 11
Training loss: 2.2107737064361572
Validation loss: 2.0965227087338767

Epoch: 6| Step: 12
Training loss: 2.2549920082092285
Validation loss: 2.0778303146362305

Epoch: 6| Step: 13
Training loss: 2.2156453132629395
Validation loss: 2.0943830609321594

Epoch: 49| Step: 0
Training loss: 1.848451852798462
Validation loss: 2.092310984929403

Epoch: 6| Step: 1
Training loss: 2.5724451541900635
Validation loss: 2.092544655005137

Epoch: 6| Step: 2
Training loss: 1.43095064163208
Validation loss: 2.087415397167206

Epoch: 6| Step: 3
Training loss: 1.9452835321426392
Validation loss: 2.09538741906484

Epoch: 6| Step: 4
Training loss: 1.9641199111938477
Validation loss: 2.0997894207636514

Epoch: 6| Step: 5
Training loss: 1.7047756910324097
Validation loss: 2.061043898264567

Epoch: 6| Step: 6
Training loss: 1.8537086248397827
Validation loss: 2.0829571882883706

Epoch: 6| Step: 7
Training loss: 1.9019358158111572
Validation loss: 2.0815239946047464

Epoch: 6| Step: 8
Training loss: 1.840458631515503
Validation loss: 2.076545794804891

Epoch: 6| Step: 9
Training loss: 2.0722646713256836
Validation loss: 2.0722508231798806

Epoch: 6| Step: 10
Training loss: 2.8766403198242188
Validation loss: 2.0748020807902017

Epoch: 6| Step: 11
Training loss: 2.02470064163208
Validation loss: 2.0803608894348145

Epoch: 6| Step: 12
Training loss: 2.441977024078369
Validation loss: 2.064270039399465

Epoch: 6| Step: 13
Training loss: 1.2150838375091553
Validation loss: 2.118770976861318

Epoch: 50| Step: 0
Training loss: 1.3852458000183105
Validation loss: 2.0895435015360513

Epoch: 6| Step: 1
Training loss: 2.34287166595459
Validation loss: 2.085629642009735

Epoch: 6| Step: 2
Training loss: 1.2877323627471924
Validation loss: 2.1012847820917764

Epoch: 6| Step: 3
Training loss: 1.9640390872955322
Validation loss: 2.135094940662384

Epoch: 6| Step: 4
Training loss: 2.3760428428649902
Validation loss: 2.150063157081604

Epoch: 6| Step: 5
Training loss: 1.6127948760986328
Validation loss: 2.1191001335779824

Epoch: 6| Step: 6
Training loss: 2.1742422580718994
Validation loss: 2.0986203153928122

Epoch: 6| Step: 7
Training loss: 1.6328976154327393
Validation loss: 2.1540478269259133

Epoch: 6| Step: 8
Training loss: 2.4910953044891357
Validation loss: 2.1409344474474588

Epoch: 6| Step: 9
Training loss: 1.9706751108169556
Validation loss: 2.186542054017385

Epoch: 6| Step: 10
Training loss: 2.29941987991333
Validation loss: 2.1059347788492837

Epoch: 6| Step: 11
Training loss: 2.003542184829712
Validation loss: 2.170102616151174

Epoch: 6| Step: 12
Training loss: 2.1358907222747803
Validation loss: 2.1473004619280496

Epoch: 6| Step: 13
Training loss: 2.276524782180786
Validation loss: 2.1050044298171997

Epoch: 51| Step: 0
Training loss: 1.6958401203155518
Validation loss: 2.121348281701406

Epoch: 6| Step: 1
Training loss: 1.897222876548767
Validation loss: 2.1047877271970115

Epoch: 6| Step: 2
Training loss: 1.99215829372406
Validation loss: 2.0984911719957986

Epoch: 6| Step: 3
Training loss: 1.793381690979004
Validation loss: 2.065703491369883

Epoch: 6| Step: 4
Training loss: 1.9466687440872192
Validation loss: 2.1066884795824685

Epoch: 6| Step: 5
Training loss: 2.0528969764709473
Validation loss: 2.080249468485514

Epoch: 6| Step: 6
Training loss: 2.278940200805664
Validation loss: 2.084896763165792

Epoch: 6| Step: 7
Training loss: 2.1226143836975098
Validation loss: 2.0612632830937705

Epoch: 6| Step: 8
Training loss: 1.6534174680709839
Validation loss: 2.0780261754989624

Epoch: 6| Step: 9
Training loss: 1.713958978652954
Validation loss: 2.049653112888336

Epoch: 6| Step: 10
Training loss: 1.8808125257492065
Validation loss: 2.1087074875831604

Epoch: 6| Step: 11
Training loss: 1.6704559326171875
Validation loss: 2.0878268480300903

Epoch: 6| Step: 12
Training loss: 2.5196852684020996
Validation loss: 2.0787912011146545

Epoch: 6| Step: 13
Training loss: 2.403217077255249
Validation loss: 2.077561934789022

Epoch: 52| Step: 0
Training loss: 1.6119813919067383
Validation loss: 2.0933106342951455

Epoch: 6| Step: 1
Training loss: 2.214892625808716
Validation loss: 2.092778126398722

Epoch: 6| Step: 2
Training loss: 1.5218695402145386
Validation loss: 2.107470373312632

Epoch: 6| Step: 3
Training loss: 2.2482974529266357
Validation loss: 2.1270737648010254

Epoch: 6| Step: 4
Training loss: 2.1394834518432617
Validation loss: 2.077611525853475

Epoch: 6| Step: 5
Training loss: 2.018777847290039
Validation loss: 2.078577200571696

Epoch: 6| Step: 6
Training loss: 2.002011299133301
Validation loss: 2.0866005619366965

Epoch: 6| Step: 7
Training loss: 1.6026051044464111
Validation loss: 2.0984126726786294

Epoch: 6| Step: 8
Training loss: 2.217115879058838
Validation loss: 2.08413302898407

Epoch: 6| Step: 9
Training loss: 1.5677682161331177
Validation loss: 2.1168284018834433

Epoch: 6| Step: 10
Training loss: 1.5125799179077148
Validation loss: 2.0777393182118735

Epoch: 6| Step: 11
Training loss: 1.6985747814178467
Validation loss: 2.120094974835714

Epoch: 6| Step: 12
Training loss: 2.51072096824646
Validation loss: 2.097138206164042

Epoch: 6| Step: 13
Training loss: 2.4181642532348633
Validation loss: 2.060763736565908

Epoch: 53| Step: 0
Training loss: 2.024918556213379
Validation loss: 2.0644588073094687

Epoch: 6| Step: 1
Training loss: 2.3841710090637207
Validation loss: 2.0931435426076255

Epoch: 6| Step: 2
Training loss: 2.7856268882751465
Validation loss: 2.1048314968744912

Epoch: 6| Step: 3
Training loss: 1.950087547302246
Validation loss: 2.084525763988495

Epoch: 6| Step: 4
Training loss: 1.763569951057434
Validation loss: 2.0961838364601135

Epoch: 6| Step: 5
Training loss: 1.6924800872802734
Validation loss: 2.0981715520222983

Epoch: 6| Step: 6
Training loss: 2.064218759536743
Validation loss: 2.1007999976476035

Epoch: 6| Step: 7
Training loss: 2.2783470153808594
Validation loss: 2.082413375377655

Epoch: 6| Step: 8
Training loss: 1.837308645248413
Validation loss: 2.0539320906003318

Epoch: 6| Step: 9
Training loss: 2.0890233516693115
Validation loss: 2.089286506175995

Epoch: 6| Step: 10
Training loss: 1.7354907989501953
Validation loss: 2.0574440558751426

Epoch: 6| Step: 11
Training loss: 1.3073339462280273
Validation loss: 2.090327521165212

Epoch: 6| Step: 12
Training loss: 1.5428135395050049
Validation loss: 2.0748958587646484

Epoch: 6| Step: 13
Training loss: 2.1469531059265137
Validation loss: 2.0980447928110757

Epoch: 54| Step: 0
Training loss: 2.182513952255249
Validation loss: 2.1206751664479575

Epoch: 6| Step: 1
Training loss: 1.6302502155303955
Validation loss: 2.0768681367238364

Epoch: 6| Step: 2
Training loss: 1.423600196838379
Validation loss: 2.0897806882858276

Epoch: 6| Step: 3
Training loss: 2.4292941093444824
Validation loss: 2.0819254517555237

Epoch: 6| Step: 4
Training loss: 1.7786916494369507
Validation loss: 2.1059380372365317

Epoch: 6| Step: 5
Training loss: 1.903962254524231
Validation loss: 2.0920627117156982

Epoch: 6| Step: 6
Training loss: 1.9380961656570435
Validation loss: 2.115980585416158

Epoch: 6| Step: 7
Training loss: 2.6167099475860596
Validation loss: 2.0999473134676614

Epoch: 6| Step: 8
Training loss: 1.7032227516174316
Validation loss: 2.0934358636538186

Epoch: 6| Step: 9
Training loss: 2.2324767112731934
Validation loss: 2.0871110359827676

Epoch: 6| Step: 10
Training loss: 1.37119460105896
Validation loss: 2.077963650226593

Epoch: 6| Step: 11
Training loss: 2.3756840229034424
Validation loss: 2.1065885027249656

Epoch: 6| Step: 12
Training loss: 1.987916350364685
Validation loss: 2.0843496123949685

Epoch: 6| Step: 13
Training loss: 1.9697847366333008
Validation loss: 2.0662593245506287

Epoch: 55| Step: 0
Training loss: 1.8680285215377808
Validation loss: 2.0867228507995605

Epoch: 6| Step: 1
Training loss: 1.7376066446304321
Validation loss: 2.055541435877482

Epoch: 6| Step: 2
Training loss: 2.9274983406066895
Validation loss: 2.087054451306661

Epoch: 6| Step: 3
Training loss: 2.1853652000427246
Validation loss: 2.077307323614756

Epoch: 6| Step: 4
Training loss: 2.368445873260498
Validation loss: 2.0710840225219727

Epoch: 6| Step: 5
Training loss: 1.550653100013733
Validation loss: 2.1084515849749246

Epoch: 6| Step: 6
Training loss: 2.147972583770752
Validation loss: 2.085281789302826

Epoch: 6| Step: 7
Training loss: 1.1290417909622192
Validation loss: 2.073928117752075

Epoch: 6| Step: 8
Training loss: 1.9886959791183472
Validation loss: 2.115137298901876

Epoch: 6| Step: 9
Training loss: 2.428311824798584
Validation loss: 2.0766197045644126

Epoch: 6| Step: 10
Training loss: 2.1300368309020996
Validation loss: 2.067263344923655

Epoch: 6| Step: 11
Training loss: 1.6150381565093994
Validation loss: 2.0799226562182107

Epoch: 6| Step: 12
Training loss: 1.6927320957183838
Validation loss: 2.0800291498502097

Epoch: 6| Step: 13
Training loss: 1.686806082725525
Validation loss: 2.1213240027427673

Epoch: 56| Step: 0
Training loss: 1.2651824951171875
Validation loss: 2.12900173664093

Epoch: 6| Step: 1
Training loss: 2.208625316619873
Validation loss: 2.1212995251019797

Epoch: 6| Step: 2
Training loss: 2.3727293014526367
Validation loss: 2.140837768713633

Epoch: 6| Step: 3
Training loss: 1.696946144104004
Validation loss: 2.1542466282844543

Epoch: 6| Step: 4
Training loss: 1.706160306930542
Validation loss: 2.166863719622294

Epoch: 6| Step: 5
Training loss: 2.6083760261535645
Validation loss: 2.165176510810852

Epoch: 6| Step: 6
Training loss: 2.106900691986084
Validation loss: 2.1320634285608926

Epoch: 6| Step: 7
Training loss: 1.4555861949920654
Validation loss: 2.091030180454254

Epoch: 6| Step: 8
Training loss: 1.8926794528961182
Validation loss: 2.1253161231676736

Epoch: 6| Step: 9
Training loss: 2.331904411315918
Validation loss: 2.07427187760671

Epoch: 6| Step: 10
Training loss: 1.8114031553268433
Validation loss: 2.1123101711273193

Epoch: 6| Step: 11
Training loss: 2.622713565826416
Validation loss: 2.1036614179611206

Epoch: 6| Step: 12
Training loss: 1.5463074445724487
Validation loss: 2.0974419514338174

Epoch: 6| Step: 13
Training loss: 1.9250528812408447
Validation loss: 2.0751078128814697

Epoch: 57| Step: 0
Training loss: 2.3677005767822266
Validation loss: 2.1293880144755044

Epoch: 6| Step: 1
Training loss: 1.927841305732727
Validation loss: 2.0749059518178306

Epoch: 6| Step: 2
Training loss: 1.7454124689102173
Validation loss: 2.0770620306332908

Epoch: 6| Step: 3
Training loss: 2.1362862586975098
Validation loss: 2.0705137650171914

Epoch: 6| Step: 4
Training loss: 1.9303025007247925
Validation loss: 2.110157867272695

Epoch: 6| Step: 5
Training loss: 1.1036531925201416
Validation loss: 2.112586478392283

Epoch: 6| Step: 6
Training loss: 1.4444375038146973
Validation loss: 2.085143248240153

Epoch: 6| Step: 7
Training loss: 2.2632405757904053
Validation loss: 2.071662485599518

Epoch: 6| Step: 8
Training loss: 1.573108196258545
Validation loss: 2.13526044289271

Epoch: 6| Step: 9
Training loss: 2.127102851867676
Validation loss: 2.106634279092153

Epoch: 6| Step: 10
Training loss: 1.9818885326385498
Validation loss: 2.0449708302815757

Epoch: 6| Step: 11
Training loss: 2.3213977813720703
Validation loss: 2.0457356770833335

Epoch: 6| Step: 12
Training loss: 2.500060796737671
Validation loss: 2.122227410475413

Epoch: 6| Step: 13
Training loss: 1.9681535959243774
Validation loss: 2.0811321338017783

Epoch: 58| Step: 0
Training loss: 1.680687665939331
Validation loss: 2.139651636282603

Epoch: 6| Step: 1
Training loss: 2.119215965270996
Validation loss: 2.132670799891154

Epoch: 6| Step: 2
Training loss: 1.3485491275787354
Validation loss: 2.1758697231610618

Epoch: 6| Step: 3
Training loss: 2.5557541847229004
Validation loss: 2.189221998055776

Epoch: 6| Step: 4
Training loss: 2.2015559673309326
Validation loss: 2.20792422691981

Epoch: 6| Step: 5
Training loss: 2.0697360038757324
Validation loss: 2.178752581278483

Epoch: 6| Step: 6
Training loss: 1.9967641830444336
Validation loss: 2.178422510623932

Epoch: 6| Step: 7
Training loss: 2.1140856742858887
Validation loss: 2.132218360900879

Epoch: 6| Step: 8
Training loss: 2.430560827255249
Validation loss: 2.192190408706665

Epoch: 6| Step: 9
Training loss: 1.3484365940093994
Validation loss: 2.0988961259524026

Epoch: 6| Step: 10
Training loss: 1.9248310327529907
Validation loss: 2.0987480878829956

Epoch: 6| Step: 11
Training loss: 1.7152988910675049
Validation loss: 2.1020315289497375

Epoch: 6| Step: 12
Training loss: 1.815483808517456
Validation loss: 2.1008298794428506

Epoch: 6| Step: 13
Training loss: 2.2571463584899902
Validation loss: 2.0500165025393167

Epoch: 59| Step: 0
Training loss: 1.8241580724716187
Validation loss: 2.025472581386566

Epoch: 6| Step: 1
Training loss: 2.1145808696746826
Validation loss: 2.0929497679074607

Epoch: 6| Step: 2
Training loss: 2.642444610595703
Validation loss: 2.0947436094284058

Epoch: 6| Step: 3
Training loss: 2.083996534347534
Validation loss: 2.108133534590403

Epoch: 6| Step: 4
Training loss: 1.9024531841278076
Validation loss: 2.083552877108256

Epoch: 6| Step: 5
Training loss: 1.4283957481384277
Validation loss: 2.103907823562622

Epoch: 6| Step: 6
Training loss: 2.2277612686157227
Validation loss: 2.087455948193868

Epoch: 6| Step: 7
Training loss: 2.073029041290283
Validation loss: 2.0908656120300293

Epoch: 6| Step: 8
Training loss: 2.509502649307251
Validation loss: 2.0896859765052795

Epoch: 6| Step: 9
Training loss: 1.7687369585037231
Validation loss: 2.077832202116648

Epoch: 6| Step: 10
Training loss: 1.3959282636642456
Validation loss: 2.0846171975135803

Epoch: 6| Step: 11
Training loss: 2.0797905921936035
Validation loss: 2.058315654595693

Epoch: 6| Step: 12
Training loss: 1.6912481784820557
Validation loss: 2.075710117816925

Epoch: 6| Step: 13
Training loss: 1.9888936281204224
Validation loss: 2.0579325755437217

Epoch: 60| Step: 0
Training loss: 1.7009260654449463
Validation loss: 2.075052579243978

Epoch: 6| Step: 1
Training loss: 1.5403144359588623
Validation loss: 2.1245348850886026

Epoch: 6| Step: 2
Training loss: 2.105030059814453
Validation loss: 2.110392411549886

Epoch: 6| Step: 3
Training loss: 1.8875536918640137
Validation loss: 2.152642846107483

Epoch: 6| Step: 4
Training loss: 2.283027172088623
Validation loss: 2.1381874879201255

Epoch: 6| Step: 5
Training loss: 1.3169254064559937
Validation loss: 2.117425541083018

Epoch: 6| Step: 6
Training loss: 2.3460588455200195
Validation loss: 2.1321895917256675

Epoch: 6| Step: 7
Training loss: 2.1734654903411865
Validation loss: 2.138826827208201

Epoch: 6| Step: 8
Training loss: 1.8739560842514038
Validation loss: 2.115587532520294

Epoch: 6| Step: 9
Training loss: 1.6163723468780518
Validation loss: 2.079806387424469

Epoch: 6| Step: 10
Training loss: 2.3559138774871826
Validation loss: 2.096917986869812

Epoch: 6| Step: 11
Training loss: 2.5212340354919434
Validation loss: 2.08272918065389

Epoch: 6| Step: 12
Training loss: 1.8786979913711548
Validation loss: 2.1179616451263428

Epoch: 6| Step: 13
Training loss: 1.9510905742645264
Validation loss: 2.0574954748153687

Epoch: 61| Step: 0
Training loss: 2.0297975540161133
Validation loss: 2.0766464273134866

Epoch: 6| Step: 1
Training loss: 2.0327277183532715
Validation loss: 2.0515626271565757

Epoch: 6| Step: 2
Training loss: 1.6948182582855225
Validation loss: 2.0825671553611755

Epoch: 6| Step: 3
Training loss: 2.4483189582824707
Validation loss: 2.0746386647224426

Epoch: 6| Step: 4
Training loss: 1.4284398555755615
Validation loss: 2.08486545085907

Epoch: 6| Step: 5
Training loss: 1.7684605121612549
Validation loss: 2.0863945682843528

Epoch: 6| Step: 6
Training loss: 2.3139050006866455
Validation loss: 2.068546195824941

Epoch: 6| Step: 7
Training loss: 2.112302780151367
Validation loss: 2.0760032335917153

Epoch: 6| Step: 8
Training loss: 1.5417873859405518
Validation loss: 2.099446694056193

Epoch: 6| Step: 9
Training loss: 1.56131112575531
Validation loss: 2.0763031244277954

Epoch: 6| Step: 10
Training loss: 1.9024808406829834
Validation loss: 2.0495484471321106

Epoch: 6| Step: 11
Training loss: 2.145946741104126
Validation loss: 2.08055716753006

Epoch: 6| Step: 12
Training loss: 2.515665054321289
Validation loss: 2.076872229576111

Epoch: 6| Step: 13
Training loss: 1.8873262405395508
Validation loss: 2.0838797887166343

Epoch: 62| Step: 0
Training loss: 1.5847641229629517
Validation loss: 2.0886876583099365

Epoch: 6| Step: 1
Training loss: 2.059178352355957
Validation loss: 2.139980594317118

Epoch: 6| Step: 2
Training loss: 2.578390598297119
Validation loss: 2.1208016872406006

Epoch: 6| Step: 3
Training loss: 2.085104465484619
Validation loss: 2.1501710017522178

Epoch: 6| Step: 4
Training loss: 1.2369028329849243
Validation loss: 2.1756622791290283

Epoch: 6| Step: 5
Training loss: 1.7462306022644043
Validation loss: 2.1529537041982016

Epoch: 6| Step: 6
Training loss: 2.194169044494629
Validation loss: 2.170277734597524

Epoch: 6| Step: 7
Training loss: 1.728541374206543
Validation loss: 2.132865786552429

Epoch: 6| Step: 8
Training loss: 2.2020649909973145
Validation loss: 2.1374077995618186

Epoch: 6| Step: 9
Training loss: 1.9288301467895508
Validation loss: 2.130818565686544

Epoch: 6| Step: 10
Training loss: 1.7719981670379639
Validation loss: 2.110680321852366

Epoch: 6| Step: 11
Training loss: 2.9392333030700684
Validation loss: 2.0864793062210083

Epoch: 6| Step: 12
Training loss: 1.798587441444397
Validation loss: 2.127557078997294

Epoch: 6| Step: 13
Training loss: 1.7830092906951904
Validation loss: 2.0828116138776145

Epoch: 63| Step: 0
Training loss: 2.3006739616394043
Validation loss: 2.0933915972709656

Epoch: 6| Step: 1
Training loss: 1.6544079780578613
Validation loss: 2.0430789788564048

Epoch: 6| Step: 2
Training loss: 1.9244812726974487
Validation loss: 2.0747901598612466

Epoch: 6| Step: 3
Training loss: 1.3156378269195557
Validation loss: 2.105795959631602

Epoch: 6| Step: 4
Training loss: 2.0242409706115723
Validation loss: 2.1030686100323996

Epoch: 6| Step: 5
Training loss: 2.2338647842407227
Validation loss: 2.0932865937550864

Epoch: 6| Step: 6
Training loss: 1.849177360534668
Validation loss: 2.0871150890986123

Epoch: 6| Step: 7
Training loss: 2.195570945739746
Validation loss: 2.08115949233373

Epoch: 6| Step: 8
Training loss: 2.0550878047943115
Validation loss: 2.076924820741018

Epoch: 6| Step: 9
Training loss: 2.153716564178467
Validation loss: 2.077652414639791

Epoch: 6| Step: 10
Training loss: 1.648510456085205
Validation loss: 2.094865540663401

Epoch: 6| Step: 11
Training loss: 2.140458106994629
Validation loss: 2.087290406227112

Epoch: 6| Step: 12
Training loss: 2.1702232360839844
Validation loss: 2.0905832250912986

Epoch: 6| Step: 13
Training loss: 2.164879322052002
Validation loss: 2.0775302847226462

Epoch: 64| Step: 0
Training loss: 2.3667633533477783
Validation loss: 2.1029690702756247

Epoch: 6| Step: 1
Training loss: 2.0968430042266846
Validation loss: 2.0770625472068787

Epoch: 6| Step: 2
Training loss: 1.703908920288086
Validation loss: 2.114180644353231

Epoch: 6| Step: 3
Training loss: 2.859616279602051
Validation loss: 2.1284340620040894

Epoch: 6| Step: 4
Training loss: 2.9103410243988037
Validation loss: 2.078473766644796

Epoch: 6| Step: 5
Training loss: 1.403980016708374
Validation loss: 2.131772836049398

Epoch: 6| Step: 6
Training loss: 1.8620476722717285
Validation loss: 2.095710595448812

Epoch: 6| Step: 7
Training loss: 2.0703330039978027
Validation loss: 2.108662744363149

Epoch: 6| Step: 8
Training loss: 1.594506025314331
Validation loss: 2.1008626222610474

Epoch: 6| Step: 9
Training loss: 1.6925265789031982
Validation loss: 2.074121912320455

Epoch: 6| Step: 10
Training loss: 1.3929022550582886
Validation loss: 2.087280730406443

Epoch: 6| Step: 11
Training loss: 1.8175246715545654
Validation loss: 2.088223477204641

Epoch: 6| Step: 12
Training loss: 1.7433403730392456
Validation loss: 2.095039427280426

Epoch: 6| Step: 13
Training loss: 2.167247772216797
Validation loss: 2.0692859490712485

Epoch: 65| Step: 0
Training loss: 2.7393288612365723
Validation loss: 2.0912991166114807

Epoch: 6| Step: 1
Training loss: 2.394479274749756
Validation loss: 2.0997898976008096

Epoch: 6| Step: 2
Training loss: 1.8677741289138794
Validation loss: 2.068645497163137

Epoch: 6| Step: 3
Training loss: 1.8955471515655518
Validation loss: 2.100742518901825

Epoch: 6| Step: 4
Training loss: 1.560173749923706
Validation loss: 2.0897942582766214

Epoch: 6| Step: 5
Training loss: 1.5656737089157104
Validation loss: 2.063747525215149

Epoch: 6| Step: 6
Training loss: 1.632917881011963
Validation loss: 2.0986244281133017

Epoch: 6| Step: 7
Training loss: 1.7037895917892456
Validation loss: 2.075479745864868

Epoch: 6| Step: 8
Training loss: 1.817238450050354
Validation loss: 2.099190870920817

Epoch: 6| Step: 9
Training loss: 2.2433009147644043
Validation loss: 2.1095499793688455

Epoch: 6| Step: 10
Training loss: 1.6306796073913574
Validation loss: 2.0992095271746316

Epoch: 6| Step: 11
Training loss: 1.9881775379180908
Validation loss: 2.052099068959554

Epoch: 6| Step: 12
Training loss: 1.4733023643493652
Validation loss: 2.097422997156779

Epoch: 6| Step: 13
Training loss: 2.3619656562805176
Validation loss: 2.102537751197815

Epoch: 66| Step: 0
Training loss: 1.591036081314087
Validation loss: 2.0944803754488626

Epoch: 6| Step: 1
Training loss: 1.8333022594451904
Validation loss: 2.070387601852417

Epoch: 6| Step: 2
Training loss: 2.243691921234131
Validation loss: 2.061392068862915

Epoch: 6| Step: 3
Training loss: 2.0168042182922363
Validation loss: 2.1022886435190835

Epoch: 6| Step: 4
Training loss: 1.7356293201446533
Validation loss: 2.0892398158709207

Epoch: 6| Step: 5
Training loss: 1.9755191802978516
Validation loss: 2.1069339315096536

Epoch: 6| Step: 6
Training loss: 1.826706886291504
Validation loss: 2.1090453068415322

Epoch: 6| Step: 7
Training loss: 1.8486649990081787
Validation loss: 2.08430286248525

Epoch: 6| Step: 8
Training loss: 1.5650110244750977
Validation loss: 2.072827855745951

Epoch: 6| Step: 9
Training loss: 1.8270403146743774
Validation loss: 2.059246083100637

Epoch: 6| Step: 10
Training loss: 2.0192229747772217
Validation loss: 2.067360798517863

Epoch: 6| Step: 11
Training loss: 1.9555046558380127
Validation loss: 2.096626102924347

Epoch: 6| Step: 12
Training loss: 2.904024839401245
Validation loss: 2.1190499862035117

Epoch: 6| Step: 13
Training loss: 1.8144501447677612
Validation loss: 2.109439730644226

Epoch: 67| Step: 0
Training loss: 1.5311155319213867
Validation loss: 2.0810943047205606

Epoch: 6| Step: 1
Training loss: 1.7949270009994507
Validation loss: 2.1283393700917563

Epoch: 6| Step: 2
Training loss: 2.345062255859375
Validation loss: 2.111956218878428

Epoch: 6| Step: 3
Training loss: 2.253106117248535
Validation loss: 2.0861242413520813

Epoch: 6| Step: 4
Training loss: 1.8021018505096436
Validation loss: 2.1138610442479453

Epoch: 6| Step: 5
Training loss: 2.131075382232666
Validation loss: 2.1188300251960754

Epoch: 6| Step: 6
Training loss: 1.8153266906738281
Validation loss: 2.1067017912864685

Epoch: 6| Step: 7
Training loss: 2.3055410385131836
Validation loss: 2.0581738154093423

Epoch: 6| Step: 8
Training loss: 1.588663935661316
Validation loss: 2.0702054500579834

Epoch: 6| Step: 9
Training loss: 2.171858787536621
Validation loss: 2.1043527126312256

Epoch: 6| Step: 10
Training loss: 2.494259834289551
Validation loss: 2.0609906117121377

Epoch: 6| Step: 11
Training loss: 1.9543483257293701
Validation loss: 2.0911189715067544

Epoch: 6| Step: 12
Training loss: 1.5004676580429077
Validation loss: 2.113508403301239

Epoch: 6| Step: 13
Training loss: 1.5572011470794678
Validation loss: 2.0452985366185508

Epoch: 68| Step: 0
Training loss: 2.331455945968628
Validation loss: 2.085405170917511

Epoch: 6| Step: 1
Training loss: 1.9514012336730957
Validation loss: 2.090077598889669

Epoch: 6| Step: 2
Training loss: 1.9735734462738037
Validation loss: 2.0922087828318277

Epoch: 6| Step: 3
Training loss: 1.911426305770874
Validation loss: 2.064705272515615

Epoch: 6| Step: 4
Training loss: 1.9204881191253662
Validation loss: 2.0811593929926553

Epoch: 6| Step: 5
Training loss: 2.3574421405792236
Validation loss: 2.056451996167501

Epoch: 6| Step: 6
Training loss: 1.862289309501648
Validation loss: 2.0684624512990317

Epoch: 6| Step: 7
Training loss: 2.319462299346924
Validation loss: 2.0601609349250793

Epoch: 6| Step: 8
Training loss: 1.7595633268356323
Validation loss: 2.082404673099518

Epoch: 6| Step: 9
Training loss: 1.7912580966949463
Validation loss: 2.023824612299601

Epoch: 6| Step: 10
Training loss: 1.4798610210418701
Validation loss: 2.070268452167511

Epoch: 6| Step: 11
Training loss: 0.9562921524047852
Validation loss: 2.0279902815818787

Epoch: 6| Step: 12
Training loss: 2.0183026790618896
Validation loss: 2.0678954124450684

Epoch: 6| Step: 13
Training loss: 2.2609944343566895
Validation loss: 2.0734779834747314

Epoch: 69| Step: 0
Training loss: 1.8382728099822998
Validation loss: 2.0836863120396933

Epoch: 6| Step: 1
Training loss: 1.1406328678131104
Validation loss: 2.0912288824717202

Epoch: 6| Step: 2
Training loss: 1.7331435680389404
Validation loss: 2.1097031037012735

Epoch: 6| Step: 3
Training loss: 1.54740309715271
Validation loss: 2.118062416712443

Epoch: 6| Step: 4
Training loss: 2.2130939960479736
Validation loss: 2.127140442530314

Epoch: 6| Step: 5
Training loss: 1.601088047027588
Validation loss: 2.088142474492391

Epoch: 6| Step: 6
Training loss: 2.7263307571411133
Validation loss: 2.1347731153170266

Epoch: 6| Step: 7
Training loss: 1.7845559120178223
Validation loss: 2.1386139591534934

Epoch: 6| Step: 8
Training loss: 2.3218436241149902
Validation loss: 2.1098615527153015

Epoch: 6| Step: 9
Training loss: 2.201537847518921
Validation loss: 2.099288046360016

Epoch: 6| Step: 10
Training loss: 1.3777639865875244
Validation loss: 2.089265783627828

Epoch: 6| Step: 11
Training loss: 2.4662461280822754
Validation loss: 2.1185736656188965

Epoch: 6| Step: 12
Training loss: 1.67528235912323
Validation loss: 2.0862122972806296

Epoch: 6| Step: 13
Training loss: 2.451664686203003
Validation loss: 2.0807469288508096

Epoch: 70| Step: 0
Training loss: 1.404584288597107
Validation loss: 2.0495556791623435

Epoch: 6| Step: 1
Training loss: 2.2044553756713867
Validation loss: 2.0957547227541604

Epoch: 6| Step: 2
Training loss: 2.1101245880126953
Validation loss: 2.078102171421051

Epoch: 6| Step: 3
Training loss: 2.1496548652648926
Validation loss: 2.0977750023206077

Epoch: 6| Step: 4
Training loss: 1.3419609069824219
Validation loss: 2.0994017720222473

Epoch: 6| Step: 5
Training loss: 1.7382729053497314
Validation loss: 2.052710473537445

Epoch: 6| Step: 6
Training loss: 1.1645750999450684
Validation loss: 2.092516760031382

Epoch: 6| Step: 7
Training loss: 1.7571569681167603
Validation loss: 2.0813809037208557

Epoch: 6| Step: 8
Training loss: 2.2313127517700195
Validation loss: 2.0829070607821145

Epoch: 6| Step: 9
Training loss: 2.0041897296905518
Validation loss: 2.10847677787145

Epoch: 6| Step: 10
Training loss: 1.9653990268707275
Validation loss: 2.1174797813097634

Epoch: 6| Step: 11
Training loss: 2.35986590385437
Validation loss: 2.093963940938314

Epoch: 6| Step: 12
Training loss: 2.346035957336426
Validation loss: 2.1010623375574746

Epoch: 6| Step: 13
Training loss: 1.7220110893249512
Validation loss: 2.0514933665593467

Epoch: 71| Step: 0
Training loss: 2.158651351928711
Validation loss: 2.096057375272115

Epoch: 6| Step: 1
Training loss: 1.865921974182129
Validation loss: 2.0921457608540854

Epoch: 6| Step: 2
Training loss: 1.7727559804916382
Validation loss: 2.1084752082824707

Epoch: 6| Step: 3
Training loss: 1.4641344547271729
Validation loss: 2.1262570222218833

Epoch: 6| Step: 4
Training loss: 2.5381345748901367
Validation loss: 2.109123627344767

Epoch: 6| Step: 5
Training loss: 1.9217915534973145
Validation loss: 2.113844712575277

Epoch: 6| Step: 6
Training loss: 2.2003769874572754
Validation loss: 2.12372495730718

Epoch: 6| Step: 7
Training loss: 1.6467174291610718
Validation loss: 2.1141738295555115

Epoch: 6| Step: 8
Training loss: 2.0480892658233643
Validation loss: 2.118547558784485

Epoch: 6| Step: 9
Training loss: 1.7307066917419434
Validation loss: 2.088731507460276

Epoch: 6| Step: 10
Training loss: 2.0926718711853027
Validation loss: 2.1253020763397217

Epoch: 6| Step: 11
Training loss: 1.7250711917877197
Validation loss: 2.1154714822769165

Epoch: 6| Step: 12
Training loss: 1.9522451162338257
Validation loss: 2.1361615459124246

Epoch: 6| Step: 13
Training loss: 1.8856585025787354
Validation loss: 2.161662459373474

Epoch: 72| Step: 0
Training loss: 1.5265424251556396
Validation loss: 2.1204437216122947

Epoch: 6| Step: 1
Training loss: 2.1404099464416504
Validation loss: 2.109133223692576

Epoch: 6| Step: 2
Training loss: 2.455902099609375
Validation loss: 2.098077674706777

Epoch: 6| Step: 3
Training loss: 2.1503829956054688
Validation loss: 2.0321367581685386

Epoch: 6| Step: 4
Training loss: 1.6055409908294678
Validation loss: 2.046513040860494

Epoch: 6| Step: 5
Training loss: 1.8704864978790283
Validation loss: 2.0688971281051636

Epoch: 6| Step: 6
Training loss: 1.2994838953018188
Validation loss: 2.0679425597190857

Epoch: 6| Step: 7
Training loss: 2.1879124641418457
Validation loss: 2.0754992961883545

Epoch: 6| Step: 8
Training loss: 2.3504557609558105
Validation loss: 2.10101310412089

Epoch: 6| Step: 9
Training loss: 1.8236280679702759
Validation loss: 2.0881803234418235

Epoch: 6| Step: 10
Training loss: 1.8984935283660889
Validation loss: 2.103736460208893

Epoch: 6| Step: 11
Training loss: 1.6662206649780273
Validation loss: 2.103056232134501

Epoch: 6| Step: 12
Training loss: 1.3439496755599976
Validation loss: 2.095398406187693

Epoch: 6| Step: 13
Training loss: 2.5564234256744385
Validation loss: 2.0936336318651834

Epoch: 73| Step: 0
Training loss: 2.4874274730682373
Validation loss: 2.149458090464274

Epoch: 6| Step: 1
Training loss: 1.433452844619751
Validation loss: 2.115139047304789

Epoch: 6| Step: 2
Training loss: 2.608536720275879
Validation loss: 2.15168434381485

Epoch: 6| Step: 3
Training loss: 1.228875756263733
Validation loss: 2.1502497593561807

Epoch: 6| Step: 4
Training loss: 2.153207778930664
Validation loss: 2.0930082599322

Epoch: 6| Step: 5
Training loss: 1.6640384197235107
Validation loss: 2.1158310572306314

Epoch: 6| Step: 6
Training loss: 1.598142147064209
Validation loss: 2.1238088607788086

Epoch: 6| Step: 7
Training loss: 1.8111827373504639
Validation loss: 2.104659060637156

Epoch: 6| Step: 8
Training loss: 1.8141169548034668
Validation loss: 2.094497243563334

Epoch: 6| Step: 9
Training loss: 2.408681869506836
Validation loss: 2.1255111694335938

Epoch: 6| Step: 10
Training loss: 1.8276829719543457
Validation loss: 2.112242559591929

Epoch: 6| Step: 11
Training loss: 1.2316603660583496
Validation loss: 2.103353798389435

Epoch: 6| Step: 12
Training loss: 1.7451425790786743
Validation loss: 2.0581627090771994

Epoch: 6| Step: 13
Training loss: 2.385756015777588
Validation loss: 2.0762517054875693

Epoch: 74| Step: 0
Training loss: 2.2734479904174805
Validation loss: 2.072779138882955

Epoch: 6| Step: 1
Training loss: 2.0562796592712402
Validation loss: 2.106335540612539

Epoch: 6| Step: 2
Training loss: 1.8737995624542236
Validation loss: 2.0839718182881675

Epoch: 6| Step: 3
Training loss: 1.4456672668457031
Validation loss: 2.096911052862803

Epoch: 6| Step: 4
Training loss: 2.3070554733276367
Validation loss: 2.0841078956921897

Epoch: 6| Step: 5
Training loss: 1.9476759433746338
Validation loss: 2.105006436506907

Epoch: 6| Step: 6
Training loss: 1.4761550426483154
Validation loss: 2.0851460496584573

Epoch: 6| Step: 7
Training loss: 1.6446236371994019
Validation loss: 2.079161783059438

Epoch: 6| Step: 8
Training loss: 1.540931224822998
Validation loss: 2.08020689090093

Epoch: 6| Step: 9
Training loss: 1.7414315938949585
Validation loss: 2.0757927894592285

Epoch: 6| Step: 10
Training loss: 1.878774881362915
Validation loss: 2.0741606752077737

Epoch: 6| Step: 11
Training loss: 1.7927992343902588
Validation loss: 2.100957771142324

Epoch: 6| Step: 12
Training loss: 2.184459686279297
Validation loss: 2.049833099047343

Epoch: 6| Step: 13
Training loss: 2.6806857585906982
Validation loss: 2.0562392473220825

Epoch: 75| Step: 0
Training loss: 1.607619047164917
Validation loss: 2.1013064781824746

Epoch: 6| Step: 1
Training loss: 1.9069018363952637
Validation loss: 2.108199954032898

Epoch: 6| Step: 2
Training loss: 2.1548993587493896
Validation loss: 2.140802264213562

Epoch: 6| Step: 3
Training loss: 1.0272986888885498
Validation loss: 2.1432571013768515

Epoch: 6| Step: 4
Training loss: 1.8930189609527588
Validation loss: 2.169107755025228

Epoch: 6| Step: 5
Training loss: 2.3550853729248047
Validation loss: 2.188210984071096

Epoch: 6| Step: 6
Training loss: 1.8797340393066406
Validation loss: 2.185640335083008

Epoch: 6| Step: 7
Training loss: 1.546267032623291
Validation loss: 2.2208558718363443

Epoch: 6| Step: 8
Training loss: 1.6992549896240234
Validation loss: 2.125006377696991

Epoch: 6| Step: 9
Training loss: 2.4227027893066406
Validation loss: 2.1146366198857627

Epoch: 6| Step: 10
Training loss: 2.0980000495910645
Validation loss: 2.1411575078964233

Epoch: 6| Step: 11
Training loss: 1.9586220979690552
Validation loss: 2.129263420899709

Epoch: 6| Step: 12
Training loss: 2.353628635406494
Validation loss: 2.0781384905179343

Epoch: 6| Step: 13
Training loss: 1.8573839664459229
Validation loss: 2.10180656115214

Epoch: 76| Step: 0
Training loss: 1.4173051118850708
Validation loss: 2.0831870237986245

Epoch: 6| Step: 1
Training loss: 1.7631280422210693
Validation loss: 2.1001824339230857

Epoch: 6| Step: 2
Training loss: 1.1439900398254395
Validation loss: 2.0763489802678428

Epoch: 6| Step: 3
Training loss: 1.830683708190918
Validation loss: 2.127484937508901

Epoch: 6| Step: 4
Training loss: 1.7117245197296143
Validation loss: 2.110305150349935

Epoch: 6| Step: 5
Training loss: 2.36216139793396
Validation loss: 2.118171513080597

Epoch: 6| Step: 6
Training loss: 2.180821418762207
Validation loss: 2.122616946697235

Epoch: 6| Step: 7
Training loss: 2.139944076538086
Validation loss: 2.106222947438558

Epoch: 6| Step: 8
Training loss: 2.317214250564575
Validation loss: 2.0945671796798706

Epoch: 6| Step: 9
Training loss: 2.532939910888672
Validation loss: 2.0841617584228516

Epoch: 6| Step: 10
Training loss: 1.8866727352142334
Validation loss: 2.0671348571777344

Epoch: 6| Step: 11
Training loss: 2.4402236938476562
Validation loss: 2.070615033308665

Epoch: 6| Step: 12
Training loss: 2.1166603565216064
Validation loss: 2.111169079939524

Epoch: 6| Step: 13
Training loss: 1.7492649555206299
Validation loss: 2.0879645546277366

Epoch: 77| Step: 0
Training loss: 1.794797420501709
Validation loss: 2.0681857665379844

Epoch: 6| Step: 1
Training loss: 2.6510825157165527
Validation loss: 2.0681716402371726

Epoch: 6| Step: 2
Training loss: 1.512934923171997
Validation loss: 2.1019753217697144

Epoch: 6| Step: 3
Training loss: 1.7814351320266724
Validation loss: 2.0909016132354736

Epoch: 6| Step: 4
Training loss: 1.596205472946167
Validation loss: 2.0717062751452127

Epoch: 6| Step: 5
Training loss: 1.5697875022888184
Validation loss: 2.1341317693392434

Epoch: 6| Step: 6
Training loss: 1.4872874021530151
Validation loss: 2.152489940325419

Epoch: 6| Step: 7
Training loss: 2.2276999950408936
Validation loss: 2.155109783013662

Epoch: 6| Step: 8
Training loss: 2.73260498046875
Validation loss: 2.1375359296798706

Epoch: 6| Step: 9
Training loss: 2.2691779136657715
Validation loss: 2.1047664880752563

Epoch: 6| Step: 10
Training loss: 1.9285860061645508
Validation loss: 2.1496952374776206

Epoch: 6| Step: 11
Training loss: 1.893902063369751
Validation loss: 2.1320409774780273

Epoch: 6| Step: 12
Training loss: 1.8480896949768066
Validation loss: 2.175657629966736

Epoch: 6| Step: 13
Training loss: 1.377433180809021
Validation loss: 2.127780298391978

Epoch: 78| Step: 0
Training loss: 1.483830451965332
Validation loss: 2.1559009154637656

Epoch: 6| Step: 1
Training loss: 1.8241318464279175
Validation loss: 2.084411382675171

Epoch: 6| Step: 2
Training loss: 0.893890917301178
Validation loss: 2.0671693881352744

Epoch: 6| Step: 3
Training loss: 2.0922889709472656
Validation loss: 2.075483719507853

Epoch: 6| Step: 4
Training loss: 1.41190505027771
Validation loss: 2.088057577610016

Epoch: 6| Step: 5
Training loss: 1.9262385368347168
Validation loss: 2.0588762760162354

Epoch: 6| Step: 6
Training loss: 2.2561473846435547
Validation loss: 2.0556710163752236

Epoch: 6| Step: 7
Training loss: 2.0940165519714355
Validation loss: 2.085250417391459

Epoch: 6| Step: 8
Training loss: 1.94102144241333
Validation loss: 2.074889620145162

Epoch: 6| Step: 9
Training loss: 2.6300249099731445
Validation loss: 2.10603533188502

Epoch: 6| Step: 10
Training loss: 1.4562402963638306
Validation loss: 2.0871514876683555

Epoch: 6| Step: 11
Training loss: 2.426496982574463
Validation loss: 2.0808254281679788

Epoch: 6| Step: 12
Training loss: 2.0388853549957275
Validation loss: 2.1026151378949485

Epoch: 6| Step: 13
Training loss: 2.0072667598724365
Validation loss: 2.104395886262258

Epoch: 79| Step: 0
Training loss: 1.4342141151428223
Validation loss: 2.092798034350077

Epoch: 6| Step: 1
Training loss: 2.653304100036621
Validation loss: 2.0400904615720115

Epoch: 6| Step: 2
Training loss: 1.6674330234527588
Validation loss: 2.1061925888061523

Epoch: 6| Step: 3
Training loss: 2.043147325515747
Validation loss: 2.108302632967631

Epoch: 6| Step: 4
Training loss: 2.242483615875244
Validation loss: 2.0715721249580383

Epoch: 6| Step: 5
Training loss: 2.4304144382476807
Validation loss: 2.0735479394594827

Epoch: 6| Step: 6
Training loss: 1.833565354347229
Validation loss: 2.07479735215505

Epoch: 6| Step: 7
Training loss: 1.6872813701629639
Validation loss: 2.0549278060595193

Epoch: 6| Step: 8
Training loss: 1.865932822227478
Validation loss: 2.095565756162008

Epoch: 6| Step: 9
Training loss: 2.0065741539001465
Validation loss: 2.0579510927200317

Epoch: 6| Step: 10
Training loss: 1.8151506185531616
Validation loss: 2.061895469824473

Epoch: 6| Step: 11
Training loss: 1.9253625869750977
Validation loss: 2.0734533071517944

Epoch: 6| Step: 12
Training loss: 1.5317139625549316
Validation loss: 2.0984215140342712

Epoch: 6| Step: 13
Training loss: 1.3943238258361816
Validation loss: 2.068882942199707

Epoch: 80| Step: 0
Training loss: 1.6548293828964233
Validation loss: 2.1172897617022195

Epoch: 6| Step: 1
Training loss: 1.7832231521606445
Validation loss: 2.164671023686727

Epoch: 6| Step: 2
Training loss: 2.2835052013397217
Validation loss: 2.146645168463389

Epoch: 6| Step: 3
Training loss: 2.286856174468994
Validation loss: 2.1743934750556946

Epoch: 6| Step: 4
Training loss: 1.8317934274673462
Validation loss: 2.221405287583669

Epoch: 6| Step: 5
Training loss: 1.8017263412475586
Validation loss: 2.1641168196996055

Epoch: 6| Step: 6
Training loss: 2.8204751014709473
Validation loss: 2.215921421845754

Epoch: 6| Step: 7
Training loss: 1.8666765689849854
Validation loss: 2.168526808420817

Epoch: 6| Step: 8
Training loss: 2.086998462677002
Validation loss: 2.1833102703094482

Epoch: 6| Step: 9
Training loss: 1.6324042081832886
Validation loss: 2.092159330844879

Epoch: 6| Step: 10
Training loss: 1.3383066654205322
Validation loss: 2.1123417019844055

Epoch: 6| Step: 11
Training loss: 1.7739125490188599
Validation loss: 2.0884482065836587

Epoch: 6| Step: 12
Training loss: 2.1046721935272217
Validation loss: 2.0781280199686685

Epoch: 6| Step: 13
Training loss: 1.7424668073654175
Validation loss: 2.066790282726288

Epoch: 81| Step: 0
Training loss: 1.8470485210418701
Validation loss: 2.0759724378585815

Epoch: 6| Step: 1
Training loss: 1.7904564142227173
Validation loss: 2.08758137623469

Epoch: 6| Step: 2
Training loss: 1.4459452629089355
Validation loss: 2.0741867224375405

Epoch: 6| Step: 3
Training loss: 1.550488829612732
Validation loss: 2.063240567843119

Epoch: 6| Step: 4
Training loss: 1.9640053510665894
Validation loss: 2.0791053970654807

Epoch: 6| Step: 5
Training loss: 2.1032629013061523
Validation loss: 2.097028990586599

Epoch: 6| Step: 6
Training loss: 2.417290210723877
Validation loss: 2.0882597963015237

Epoch: 6| Step: 7
Training loss: 1.7883737087249756
Validation loss: 2.0761958360671997

Epoch: 6| Step: 8
Training loss: 1.8337554931640625
Validation loss: 2.054822325706482

Epoch: 6| Step: 9
Training loss: 1.533315658569336
Validation loss: 2.05799267689387

Epoch: 6| Step: 10
Training loss: 2.671973943710327
Validation loss: 2.053632974624634

Epoch: 6| Step: 11
Training loss: 2.0501976013183594
Validation loss: 2.0641512870788574

Epoch: 6| Step: 12
Training loss: 1.488716959953308
Validation loss: 2.1190877755482993

Epoch: 6| Step: 13
Training loss: 2.2218410968780518
Validation loss: 2.0940523743629456

Epoch: 82| Step: 0
Training loss: 2.19978666305542
Validation loss: 2.135160823663076

Epoch: 6| Step: 1
Training loss: 2.1234211921691895
Validation loss: 2.13213982184728

Epoch: 6| Step: 2
Training loss: 1.6287139654159546
Validation loss: 2.1562658747037253

Epoch: 6| Step: 3
Training loss: 1.7904797792434692
Validation loss: 2.1763886213302612

Epoch: 6| Step: 4
Training loss: 1.3778445720672607
Validation loss: 2.1715003649393716

Epoch: 6| Step: 5
Training loss: 1.548379898071289
Validation loss: 2.1433979868888855

Epoch: 6| Step: 6
Training loss: 2.328059434890747
Validation loss: 2.1526541312535605

Epoch: 6| Step: 7
Training loss: 2.101732015609741
Validation loss: 2.105485459168752

Epoch: 6| Step: 8
Training loss: 1.1821067333221436
Validation loss: 2.0635568499565125

Epoch: 6| Step: 9
Training loss: 2.355194568634033
Validation loss: 2.0803298155466714

Epoch: 6| Step: 10
Training loss: 2.170506238937378
Validation loss: 2.042317052682241

Epoch: 6| Step: 11
Training loss: 2.089247226715088
Validation loss: 2.12094654639562

Epoch: 6| Step: 12
Training loss: 2.0916900634765625
Validation loss: 2.0825127959251404

Epoch: 6| Step: 13
Training loss: 1.8711485862731934
Validation loss: 2.0985288421312966

Epoch: 83| Step: 0
Training loss: 1.6199997663497925
Validation loss: 2.058820605278015

Epoch: 6| Step: 1
Training loss: 1.5705652236938477
Validation loss: 2.0759540597597756

Epoch: 6| Step: 2
Training loss: 1.8860230445861816
Validation loss: 2.087536076704661

Epoch: 6| Step: 3
Training loss: 2.555656909942627
Validation loss: 2.0769506692886353

Epoch: 6| Step: 4
Training loss: 2.360774040222168
Validation loss: 2.0760878125826516

Epoch: 6| Step: 5
Training loss: 1.7319148778915405
Validation loss: 2.0638960003852844

Epoch: 6| Step: 6
Training loss: 2.045844078063965
Validation loss: 2.0392630298932395

Epoch: 6| Step: 7
Training loss: 1.8272122144699097
Validation loss: 2.018980781237284

Epoch: 6| Step: 8
Training loss: 1.742434024810791
Validation loss: 2.055592159430186

Epoch: 6| Step: 9
Training loss: 1.8613451719284058
Validation loss: 2.0655045906702676

Epoch: 6| Step: 10
Training loss: 2.576221466064453
Validation loss: 2.0733872453371682

Epoch: 6| Step: 11
Training loss: 1.7711427211761475
Validation loss: 2.0534911354382834

Epoch: 6| Step: 12
Training loss: 1.8935604095458984
Validation loss: 2.1092888911565146

Epoch: 6| Step: 13
Training loss: 0.8662551641464233
Validation loss: 2.077739636103312

Epoch: 84| Step: 0
Training loss: 1.86690092086792
Validation loss: 2.0786965688069663

Epoch: 6| Step: 1
Training loss: 1.6528373956680298
Validation loss: 2.1105536023775735

Epoch: 6| Step: 2
Training loss: 1.291078805923462
Validation loss: 2.0747243762016296

Epoch: 6| Step: 3
Training loss: 2.036733627319336
Validation loss: 2.1114625334739685

Epoch: 6| Step: 4
Training loss: 1.8421555757522583
Validation loss: 2.1166258653004966

Epoch: 6| Step: 5
Training loss: 1.876194953918457
Validation loss: 2.142821252346039

Epoch: 6| Step: 6
Training loss: 1.877339243888855
Validation loss: 2.1260154247283936

Epoch: 6| Step: 7
Training loss: 1.7630696296691895
Validation loss: 2.113212207953135

Epoch: 6| Step: 8
Training loss: 1.4984395503997803
Validation loss: 2.0918341676394143

Epoch: 6| Step: 9
Training loss: 2.176032543182373
Validation loss: 2.151726166407267

Epoch: 6| Step: 10
Training loss: 1.7499264478683472
Validation loss: 2.070039987564087

Epoch: 6| Step: 11
Training loss: 2.9962573051452637
Validation loss: 2.1057727932929993

Epoch: 6| Step: 12
Training loss: 2.052011251449585
Validation loss: 2.1057109236717224

Epoch: 6| Step: 13
Training loss: 1.380167007446289
Validation loss: 2.098036766052246

Epoch: 85| Step: 0
Training loss: 1.6695852279663086
Validation loss: 2.1101391315460205

Epoch: 6| Step: 1
Training loss: 2.0320615768432617
Validation loss: 2.0663317243258157

Epoch: 6| Step: 2
Training loss: 2.0390231609344482
Validation loss: 2.1068485577901206

Epoch: 6| Step: 3
Training loss: 1.7215290069580078
Validation loss: 2.110299209753672

Epoch: 6| Step: 4
Training loss: 2.1979188919067383
Validation loss: 2.055872102578481

Epoch: 6| Step: 5
Training loss: 2.1530795097351074
Validation loss: 2.1141237020492554

Epoch: 6| Step: 6
Training loss: 1.4061651229858398
Validation loss: 2.0763357083002725

Epoch: 6| Step: 7
Training loss: 1.3242435455322266
Validation loss: 2.0893876552581787

Epoch: 6| Step: 8
Training loss: 2.474515438079834
Validation loss: 2.0720988114674888

Epoch: 6| Step: 9
Training loss: 2.1607913970947266
Validation loss: 2.080465018749237

Epoch: 6| Step: 10
Training loss: 1.6357167959213257
Validation loss: 2.0985280474027

Epoch: 6| Step: 11
Training loss: 1.4605076313018799
Validation loss: 2.0621628165245056

Epoch: 6| Step: 12
Training loss: 2.3083086013793945
Validation loss: 2.069883326689402

Epoch: 6| Step: 13
Training loss: 1.5173131227493286
Validation loss: 2.118450164794922

Epoch: 86| Step: 0
Training loss: 1.810829997062683
Validation loss: 2.1076349218686423

Epoch: 6| Step: 1
Training loss: 1.7133630514144897
Validation loss: 2.0886337955792746

Epoch: 6| Step: 2
Training loss: 2.110300302505493
Validation loss: 2.130013863245646

Epoch: 6| Step: 3
Training loss: 2.0968098640441895
Validation loss: 2.119368573029836

Epoch: 6| Step: 4
Training loss: 2.031242609024048
Validation loss: 2.080868581930796

Epoch: 6| Step: 5
Training loss: 1.294878363609314
Validation loss: 2.082677642504374

Epoch: 6| Step: 6
Training loss: 2.0570716857910156
Validation loss: 2.0993855396906533

Epoch: 6| Step: 7
Training loss: 2.5647997856140137
Validation loss: 2.1191964745521545

Epoch: 6| Step: 8
Training loss: 1.6109397411346436
Validation loss: 2.059377451737722

Epoch: 6| Step: 9
Training loss: 1.5282199382781982
Validation loss: 2.0986740390459695

Epoch: 6| Step: 10
Training loss: 2.0679359436035156
Validation loss: 2.0574417312939963

Epoch: 6| Step: 11
Training loss: 1.8695790767669678
Validation loss: 2.04390549659729

Epoch: 6| Step: 12
Training loss: 2.1428444385528564
Validation loss: 2.0640326340993247

Epoch: 6| Step: 13
Training loss: 1.23288893699646
Validation loss: 2.052229940891266

Epoch: 87| Step: 0
Training loss: 2.5410656929016113
Validation loss: 2.0896361470222473

Epoch: 6| Step: 1
Training loss: 1.845727801322937
Validation loss: 2.083604395389557

Epoch: 6| Step: 2
Training loss: 1.6578176021575928
Validation loss: 2.078393300374349

Epoch: 6| Step: 3
Training loss: 1.395031452178955
Validation loss: 2.094869335492452

Epoch: 6| Step: 4
Training loss: 1.6948953866958618
Validation loss: 2.0550583600997925

Epoch: 6| Step: 5
Training loss: 1.963514804840088
Validation loss: 2.066657304763794

Epoch: 6| Step: 6
Training loss: 1.4350025653839111
Validation loss: 2.073483645915985

Epoch: 6| Step: 7
Training loss: 1.6818019151687622
Validation loss: 2.1115694443384805

Epoch: 6| Step: 8
Training loss: 2.521791458129883
Validation loss: 2.114100178082784

Epoch: 6| Step: 9
Training loss: 2.1647210121154785
Validation loss: 2.0991002917289734

Epoch: 6| Step: 10
Training loss: 2.1015634536743164
Validation loss: 2.0911694765090942

Epoch: 6| Step: 11
Training loss: 1.7770788669586182
Validation loss: 2.083508312702179

Epoch: 6| Step: 12
Training loss: 1.7474374771118164
Validation loss: 2.1074169079462686

Epoch: 6| Step: 13
Training loss: 1.4316065311431885
Validation loss: 2.0918733278910318

Epoch: 88| Step: 0
Training loss: 1.5255587100982666
Validation loss: 2.0876746575037637

Epoch: 6| Step: 1
Training loss: 1.8157240152359009
Validation loss: 2.0767890016237893

Epoch: 6| Step: 2
Training loss: 1.6638652086257935
Validation loss: 2.069982588291168

Epoch: 6| Step: 3
Training loss: 1.5966155529022217
Validation loss: 2.079352776209513

Epoch: 6| Step: 4
Training loss: 2.272386074066162
Validation loss: 2.101356824239095

Epoch: 6| Step: 5
Training loss: 1.7457853555679321
Validation loss: 2.0837982296943665

Epoch: 6| Step: 6
Training loss: 1.643337368965149
Validation loss: 2.086291710535685

Epoch: 6| Step: 7
Training loss: 2.066661834716797
Validation loss: 2.092229684193929

Epoch: 6| Step: 8
Training loss: 1.8751647472381592
Validation loss: 2.092202643553416

Epoch: 6| Step: 9
Training loss: 1.4641708135604858
Validation loss: 2.115327556927999

Epoch: 6| Step: 10
Training loss: 1.664762258529663
Validation loss: 2.148293972015381

Epoch: 6| Step: 11
Training loss: 1.6809279918670654
Validation loss: 2.1430259346961975

Epoch: 6| Step: 12
Training loss: 2.229678153991699
Validation loss: 2.152894934018453

Epoch: 6| Step: 13
Training loss: 2.4603800773620605
Validation loss: 2.139216184616089

Epoch: 89| Step: 0
Training loss: 2.090254783630371
Validation loss: 2.153465827306112

Epoch: 6| Step: 1
Training loss: 2.1069412231445312
Validation loss: 2.127801497777303

Epoch: 6| Step: 2
Training loss: 2.223637819290161
Validation loss: 2.0908493796984353

Epoch: 6| Step: 3
Training loss: 1.7536802291870117
Validation loss: 2.0965245962142944

Epoch: 6| Step: 4
Training loss: 2.0847342014312744
Validation loss: 2.0929596225420632

Epoch: 6| Step: 5
Training loss: 1.6129478216171265
Validation loss: 2.064348498980204

Epoch: 6| Step: 6
Training loss: 1.764463186264038
Validation loss: 2.0627671281496682

Epoch: 6| Step: 7
Training loss: 1.3575091361999512
Validation loss: 2.07710337638855

Epoch: 6| Step: 8
Training loss: 1.9092004299163818
Validation loss: 2.070353349049886

Epoch: 6| Step: 9
Training loss: 1.4137499332427979
Validation loss: 2.0840555230776467

Epoch: 6| Step: 10
Training loss: 2.4152040481567383
Validation loss: 2.1274211406707764

Epoch: 6| Step: 11
Training loss: 1.6443620920181274
Validation loss: 2.0613610545794168

Epoch: 6| Step: 12
Training loss: 2.4415392875671387
Validation loss: 2.0521825750668845

Epoch: 6| Step: 13
Training loss: 1.2241469621658325
Validation loss: 2.0946189959843955

Epoch: 90| Step: 0
Training loss: 1.6733323335647583
Validation loss: 2.1294992764790854

Epoch: 6| Step: 1
Training loss: 1.9344260692596436
Validation loss: 2.0549389322598777

Epoch: 6| Step: 2
Training loss: 2.4915332794189453
Validation loss: 2.0927855372428894

Epoch: 6| Step: 3
Training loss: 1.5812782049179077
Validation loss: 2.1468288699785867

Epoch: 6| Step: 4
Training loss: 1.2345192432403564
Validation loss: 2.1418065826098123

Epoch: 6| Step: 5
Training loss: 2.2251830101013184
Validation loss: 2.099397301673889

Epoch: 6| Step: 6
Training loss: 2.0780982971191406
Validation loss: 2.129080136617025

Epoch: 6| Step: 7
Training loss: 2.198648691177368
Validation loss: 2.1597797870635986

Epoch: 6| Step: 8
Training loss: 2.1726579666137695
Validation loss: 2.146630664666494

Epoch: 6| Step: 9
Training loss: 2.1065361499786377
Validation loss: 2.1115220189094543

Epoch: 6| Step: 10
Training loss: 2.3626151084899902
Validation loss: 2.137047549088796

Epoch: 6| Step: 11
Training loss: 1.2758187055587769
Validation loss: 2.0669691363970437

Epoch: 6| Step: 12
Training loss: 1.4681097269058228
Validation loss: 2.077194174130758

Epoch: 6| Step: 13
Training loss: 1.134483814239502
Validation loss: 2.1000006596247354

Epoch: 91| Step: 0
Training loss: 2.3226380348205566
Validation loss: 2.077331066131592

Epoch: 6| Step: 1
Training loss: 2.13989520072937
Validation loss: 2.080674191315969

Epoch: 6| Step: 2
Training loss: 2.399346351623535
Validation loss: 2.072748382886251

Epoch: 6| Step: 3
Training loss: 1.0296591520309448
Validation loss: 2.093907674153646

Epoch: 6| Step: 4
Training loss: 1.5725681781768799
Validation loss: 2.059672554334005

Epoch: 6| Step: 5
Training loss: 1.6010615825653076
Validation loss: 2.094020982583364

Epoch: 6| Step: 6
Training loss: 1.6986217498779297
Validation loss: 2.080061197280884

Epoch: 6| Step: 7
Training loss: 1.5866749286651611
Validation loss: 2.088544468084971

Epoch: 6| Step: 8
Training loss: 1.9746211767196655
Validation loss: 2.0726829965909324

Epoch: 6| Step: 9
Training loss: 1.5397934913635254
Validation loss: 2.0770851373672485

Epoch: 6| Step: 10
Training loss: 1.60062837600708
Validation loss: 2.101131717363993

Epoch: 6| Step: 11
Training loss: 1.8954792022705078
Validation loss: 2.1220619082450867

Epoch: 6| Step: 12
Training loss: 2.200998067855835
Validation loss: 2.0670459866523743

Epoch: 6| Step: 13
Training loss: 2.036776542663574
Validation loss: 2.077366054058075

Epoch: 92| Step: 0
Training loss: 2.37129545211792
Validation loss: 2.094105819861094

Epoch: 6| Step: 1
Training loss: 2.3886263370513916
Validation loss: 2.1276687383651733

Epoch: 6| Step: 2
Training loss: 2.3087048530578613
Validation loss: 2.114840487639109

Epoch: 6| Step: 3
Training loss: 2.0463852882385254
Validation loss: 2.0900703072547913

Epoch: 6| Step: 4
Training loss: 1.4854463338851929
Validation loss: 2.1390650868415833

Epoch: 6| Step: 5
Training loss: 1.3261882066726685
Validation loss: 2.0993431409200034

Epoch: 6| Step: 6
Training loss: 1.8516528606414795
Validation loss: 2.1151925325393677

Epoch: 6| Step: 7
Training loss: 1.3403162956237793
Validation loss: 2.1271902521451316

Epoch: 6| Step: 8
Training loss: 1.7367122173309326
Validation loss: 2.1061618526776633

Epoch: 6| Step: 9
Training loss: 1.605369210243225
Validation loss: 2.0822908878326416

Epoch: 6| Step: 10
Training loss: 1.572707176208496
Validation loss: 2.0791631738344827

Epoch: 6| Step: 11
Training loss: 1.7119815349578857
Validation loss: 2.082741399606069

Epoch: 6| Step: 12
Training loss: 1.9850488901138306
Validation loss: 2.0688393115997314

Epoch: 6| Step: 13
Training loss: 1.9581851959228516
Validation loss: 2.057049651940664

Epoch: 93| Step: 0
Training loss: 1.5875494480133057
Validation loss: 2.0728731552759805

Epoch: 6| Step: 1
Training loss: 1.953078269958496
Validation loss: 2.049321413040161

Epoch: 6| Step: 2
Training loss: 2.1601755619049072
Validation loss: 2.1064138213793435

Epoch: 6| Step: 3
Training loss: 1.5478838682174683
Validation loss: 2.116793692111969

Epoch: 6| Step: 4
Training loss: 2.280808448791504
Validation loss: 2.101101597150167

Epoch: 6| Step: 5
Training loss: 1.8416576385498047
Validation loss: 2.1078101992607117

Epoch: 6| Step: 6
Training loss: 2.167053699493408
Validation loss: 2.1681445439656577

Epoch: 6| Step: 7
Training loss: 2.1928021907806396
Validation loss: 2.1316140492757163

Epoch: 6| Step: 8
Training loss: 1.7925291061401367
Validation loss: 2.110553503036499

Epoch: 6| Step: 9
Training loss: 1.9935972690582275
Validation loss: 2.1262006759643555

Epoch: 6| Step: 10
Training loss: 1.1685664653778076
Validation loss: 2.1281937956809998

Epoch: 6| Step: 11
Training loss: 1.4938006401062012
Validation loss: 2.1523035168647766

Epoch: 6| Step: 12
Training loss: 1.6225430965423584
Validation loss: 2.130555272102356

Epoch: 6| Step: 13
Training loss: 1.5928776264190674
Validation loss: 2.132335086663564

Epoch: 94| Step: 0
Training loss: 1.4960435628890991
Validation loss: 2.071364084879557

Epoch: 6| Step: 1
Training loss: 1.4627318382263184
Validation loss: 2.1158531109491983

Epoch: 6| Step: 2
Training loss: 1.7859160900115967
Validation loss: 2.1447867155075073

Epoch: 6| Step: 3
Training loss: 1.5950908660888672
Validation loss: 2.1330893635749817

Epoch: 6| Step: 4
Training loss: 1.5991642475128174
Validation loss: 2.067632873853048

Epoch: 6| Step: 5
Training loss: 2.0524258613586426
Validation loss: 2.1494811177253723

Epoch: 6| Step: 6
Training loss: 1.7793965339660645
Validation loss: 2.143155594666799

Epoch: 6| Step: 7
Training loss: 1.9043021202087402
Validation loss: 2.0775973796844482

Epoch: 6| Step: 8
Training loss: 1.4282981157302856
Validation loss: 2.0861504475275674

Epoch: 6| Step: 9
Training loss: 2.022979736328125
Validation loss: 2.139999190966288

Epoch: 6| Step: 10
Training loss: 1.6104178428649902
Validation loss: 2.1260682543118796

Epoch: 6| Step: 11
Training loss: 1.8966789245605469
Validation loss: 2.0814808209737143

Epoch: 6| Step: 12
Training loss: 1.9363994598388672
Validation loss: 2.117573857307434

Epoch: 6| Step: 13
Training loss: 2.722144365310669
Validation loss: 2.0959668358167014

Epoch: 95| Step: 0
Training loss: 1.7672606706619263
Validation loss: 2.095027446746826

Epoch: 6| Step: 1
Training loss: 1.4836373329162598
Validation loss: 2.0857953627904258

Epoch: 6| Step: 2
Training loss: 2.1779603958129883
Validation loss: 2.0928598841031394

Epoch: 6| Step: 3
Training loss: 2.3304171562194824
Validation loss: 2.0800893902778625

Epoch: 6| Step: 4
Training loss: 2.7617268562316895
Validation loss: 2.0758546193440757

Epoch: 6| Step: 5
Training loss: 1.6833171844482422
Validation loss: 2.0725960532824197

Epoch: 6| Step: 6
Training loss: 1.6291470527648926
Validation loss: 2.049085477987925

Epoch: 6| Step: 7
Training loss: 1.6767356395721436
Validation loss: 2.104916969935099

Epoch: 6| Step: 8
Training loss: 1.7979086637496948
Validation loss: 2.104108512401581

Epoch: 6| Step: 9
Training loss: 1.970671534538269
Validation loss: 2.0744760036468506

Epoch: 6| Step: 10
Training loss: 1.6239756345748901
Validation loss: 2.0604292949040732

Epoch: 6| Step: 11
Training loss: 1.4698460102081299
Validation loss: 2.0671355923016868

Epoch: 6| Step: 12
Training loss: 1.8346037864685059
Validation loss: 2.114695688088735

Epoch: 6| Step: 13
Training loss: 1.3519915342330933
Validation loss: 2.093108375867208

Epoch: 96| Step: 0
Training loss: 1.4691693782806396
Validation loss: 2.1275569995244346

Epoch: 6| Step: 1
Training loss: 2.201965808868408
Validation loss: 2.1341227889060974

Epoch: 6| Step: 2
Training loss: 1.9941306114196777
Validation loss: 2.145534932613373

Epoch: 6| Step: 3
Training loss: 2.119826078414917
Validation loss: 2.1270833810170493

Epoch: 6| Step: 4
Training loss: 1.8470072746276855
Validation loss: 2.1236817836761475

Epoch: 6| Step: 5
Training loss: 1.1365288496017456
Validation loss: 2.1220113039016724

Epoch: 6| Step: 6
Training loss: 1.7395135164260864
Validation loss: 2.082488536834717

Epoch: 6| Step: 7
Training loss: 1.4879904985427856
Validation loss: 2.0751108129819236

Epoch: 6| Step: 8
Training loss: 2.043564796447754
Validation loss: 2.054961880048116

Epoch: 6| Step: 9
Training loss: 2.0613341331481934
Validation loss: 2.082970758279165

Epoch: 6| Step: 10
Training loss: 2.111600875854492
Validation loss: 2.0941946307818093

Epoch: 6| Step: 11
Training loss: 1.4640369415283203
Validation loss: 2.0599204699198403

Epoch: 6| Step: 12
Training loss: 2.0423364639282227
Validation loss: 2.108826736609141

Epoch: 6| Step: 13
Training loss: 2.015446186065674
Validation loss: 2.0615232388178506

Epoch: 97| Step: 0
Training loss: 1.5072344541549683
Validation loss: 2.0727008978525796

Epoch: 6| Step: 1
Training loss: 1.4102855920791626
Validation loss: 2.05647079149882

Epoch: 6| Step: 2
Training loss: 1.306525707244873
Validation loss: 2.126008669535319

Epoch: 6| Step: 3
Training loss: 1.89698326587677
Validation loss: 2.1214874585469565

Epoch: 6| Step: 4
Training loss: 1.8351762294769287
Validation loss: 2.1285762190818787

Epoch: 6| Step: 5
Training loss: 2.204949140548706
Validation loss: 2.1130590240160623

Epoch: 6| Step: 6
Training loss: 2.0474259853363037
Validation loss: 2.15477055311203

Epoch: 6| Step: 7
Training loss: 1.7159545421600342
Validation loss: 2.1562759280204773

Epoch: 6| Step: 8
Training loss: 1.788182020187378
Validation loss: 2.09375129143397

Epoch: 6| Step: 9
Training loss: 1.6972806453704834
Validation loss: 2.1266549030939736

Epoch: 6| Step: 10
Training loss: 2.2493643760681152
Validation loss: 2.0924219687779746

Epoch: 6| Step: 11
Training loss: 1.8684461116790771
Validation loss: 2.0756325721740723

Epoch: 6| Step: 12
Training loss: 1.9344733953475952
Validation loss: 2.1053489049275718

Epoch: 6| Step: 13
Training loss: 1.8887879848480225
Validation loss: 2.098274310429891

Epoch: 98| Step: 0
Training loss: 1.556644082069397
Validation loss: 2.0622109373410544

Epoch: 6| Step: 1
Training loss: 1.8456356525421143
Validation loss: 2.073400338490804

Epoch: 6| Step: 2
Training loss: 1.6417288780212402
Validation loss: 2.098441938559214

Epoch: 6| Step: 3
Training loss: 1.8838210105895996
Validation loss: 2.0986033280690513

Epoch: 6| Step: 4
Training loss: 1.5501573085784912
Validation loss: 2.1253145734469094

Epoch: 6| Step: 5
Training loss: 2.5397472381591797
Validation loss: 2.1685474117596946

Epoch: 6| Step: 6
Training loss: 1.229263186454773
Validation loss: 2.1500545144081116

Epoch: 6| Step: 7
Training loss: 2.6267080307006836
Validation loss: 2.199701209863027

Epoch: 6| Step: 8
Training loss: 2.0496068000793457
Validation loss: 2.163467268149058

Epoch: 6| Step: 9
Training loss: 1.7467560768127441
Validation loss: 2.1412214438120523

Epoch: 6| Step: 10
Training loss: 1.6372292041778564
Validation loss: 2.136265774567922

Epoch: 6| Step: 11
Training loss: 1.380100965499878
Validation loss: 2.109877586364746

Epoch: 6| Step: 12
Training loss: 1.83934485912323
Validation loss: 2.113522529602051

Epoch: 6| Step: 13
Training loss: 1.772765874862671
Validation loss: 2.0984302361806235

Epoch: 99| Step: 0
Training loss: 1.7633545398712158
Validation loss: 2.1257466673851013

Epoch: 6| Step: 1
Training loss: 1.9345875978469849
Validation loss: 2.1322949330012

Epoch: 6| Step: 2
Training loss: 1.286868929862976
Validation loss: 2.1079923709233603

Epoch: 6| Step: 3
Training loss: 2.072938919067383
Validation loss: 2.0959330797195435

Epoch: 6| Step: 4
Training loss: 2.202676296234131
Validation loss: 2.0757498939832053

Epoch: 6| Step: 5
Training loss: 1.9826701879501343
Validation loss: 2.1397737661997476

Epoch: 6| Step: 6
Training loss: 1.1274549961090088
Validation loss: 2.087003787358602

Epoch: 6| Step: 7
Training loss: 2.2649624347686768
Validation loss: 2.1029431223869324

Epoch: 6| Step: 8
Training loss: 1.6613835096359253
Validation loss: 2.129903773466746

Epoch: 6| Step: 9
Training loss: 1.3416285514831543
Validation loss: 2.1233657201131186

Epoch: 6| Step: 10
Training loss: 1.824790120124817
Validation loss: 2.1697452863057456

Epoch: 6| Step: 11
Training loss: 1.643502116203308
Validation loss: 2.090683420499166

Epoch: 6| Step: 12
Training loss: 1.9681750535964966
Validation loss: 2.0866756041844687

Epoch: 6| Step: 13
Training loss: 1.9517266750335693
Validation loss: 2.1204600731531777

Epoch: 100| Step: 0
Training loss: 1.741894245147705
Validation loss: 2.0940946340560913

Epoch: 6| Step: 1
Training loss: 2.182630777359009
Validation loss: 2.04510090748469

Epoch: 6| Step: 2
Training loss: 2.2244298458099365
Validation loss: 2.144822080930074

Epoch: 6| Step: 3
Training loss: 1.4437077045440674
Validation loss: 2.094157417615255

Epoch: 6| Step: 4
Training loss: 1.87234628200531
Validation loss: 2.0816873709360757

Epoch: 6| Step: 5
Training loss: 1.57779061794281
Validation loss: 2.1479437748591104

Epoch: 6| Step: 6
Training loss: 1.9795392751693726
Validation loss: 2.099165399869283

Epoch: 6| Step: 7
Training loss: 1.8775079250335693
Validation loss: 2.1513718167940774

Epoch: 6| Step: 8
Training loss: 1.9234931468963623
Validation loss: 2.1271337072054544

Epoch: 6| Step: 9
Training loss: 1.1651084423065186
Validation loss: 2.1279083093007407

Epoch: 6| Step: 10
Training loss: 1.7956180572509766
Validation loss: 2.130532999833425

Epoch: 6| Step: 11
Training loss: 2.095658779144287
Validation loss: 2.140794495741526

Epoch: 6| Step: 12
Training loss: 1.6825690269470215
Validation loss: 2.0974913239479065

Epoch: 6| Step: 13
Training loss: 1.3190404176712036
Validation loss: 2.074968079725901

Epoch: 101| Step: 0
Training loss: 1.2560064792633057
Validation loss: 2.0860407948493958

Epoch: 6| Step: 1
Training loss: 1.4402539730072021
Validation loss: 2.096726397673289

Epoch: 6| Step: 2
Training loss: 2.063727378845215
Validation loss: 2.131725629170736

Epoch: 6| Step: 3
Training loss: 1.8600845336914062
Validation loss: 2.0568731228510537

Epoch: 6| Step: 4
Training loss: 2.4011290073394775
Validation loss: 2.0616230567296348

Epoch: 6| Step: 5
Training loss: 1.4459816217422485
Validation loss: 2.060630182425181

Epoch: 6| Step: 6
Training loss: 2.30470871925354
Validation loss: 2.0852875113487244

Epoch: 6| Step: 7
Training loss: 1.559901475906372
Validation loss: 2.0564013918240867

Epoch: 6| Step: 8
Training loss: 1.3525499105453491
Validation loss: 2.0495826800664267

Epoch: 6| Step: 9
Training loss: 2.1158628463745117
Validation loss: 2.1182745695114136

Epoch: 6| Step: 10
Training loss: 2.3589837551116943
Validation loss: 2.0540568828582764

Epoch: 6| Step: 11
Training loss: 1.5006103515625
Validation loss: 2.0837594668070474

Epoch: 6| Step: 12
Training loss: 1.7424746751785278
Validation loss: 2.0943791468938193

Epoch: 6| Step: 13
Training loss: 1.6969468593597412
Validation loss: 2.1219430565834045

Epoch: 102| Step: 0
Training loss: 1.8540149927139282
Validation loss: 2.126315693060557

Epoch: 6| Step: 1
Training loss: 0.7640914916992188
Validation loss: 2.120871146519979

Epoch: 6| Step: 2
Training loss: 1.731052279472351
Validation loss: 2.141182243824005

Epoch: 6| Step: 3
Training loss: 1.480167269706726
Validation loss: 2.11877711613973

Epoch: 6| Step: 4
Training loss: 1.7964837551116943
Validation loss: 2.1128717263539634

Epoch: 6| Step: 5
Training loss: 2.1247973442077637
Validation loss: 2.108065744241079

Epoch: 6| Step: 6
Training loss: 2.002696990966797
Validation loss: 2.098566710948944

Epoch: 6| Step: 7
Training loss: 1.3757609128952026
Validation loss: 2.1680094798405967

Epoch: 6| Step: 8
Training loss: 1.4297999143600464
Validation loss: 2.1242051124572754

Epoch: 6| Step: 9
Training loss: 2.2647435665130615
Validation loss: 2.1385632753372192

Epoch: 6| Step: 10
Training loss: 1.6858329772949219
Validation loss: 2.1496086915334067

Epoch: 6| Step: 11
Training loss: 1.9474010467529297
Validation loss: 2.1308041413625083

Epoch: 6| Step: 12
Training loss: 2.122025489807129
Validation loss: 2.1256134311358132

Epoch: 6| Step: 13
Training loss: 2.3391942977905273
Validation loss: 2.154016931851705

Epoch: 103| Step: 0
Training loss: 1.8858215808868408
Validation loss: 2.1079640785853067

Epoch: 6| Step: 1
Training loss: 2.4509530067443848
Validation loss: 2.109753966331482

Epoch: 6| Step: 2
Training loss: 2.077805280685425
Validation loss: 2.145758350690206

Epoch: 6| Step: 3
Training loss: 1.8118517398834229
Validation loss: 2.0942936340967813

Epoch: 6| Step: 4
Training loss: 1.5902881622314453
Validation loss: 2.0956610441207886

Epoch: 6| Step: 5
Training loss: 1.3746874332427979
Validation loss: 2.0814965963363647

Epoch: 6| Step: 6
Training loss: 1.8928799629211426
Validation loss: 2.088749885559082

Epoch: 6| Step: 7
Training loss: 1.6604294776916504
Validation loss: 2.093645215034485

Epoch: 6| Step: 8
Training loss: 1.6929194927215576
Validation loss: 2.0977521538734436

Epoch: 6| Step: 9
Training loss: 2.03364634513855
Validation loss: 2.093083838621775

Epoch: 6| Step: 10
Training loss: 1.7264080047607422
Validation loss: 2.099311033884684

Epoch: 6| Step: 11
Training loss: 1.7311315536499023
Validation loss: 2.0798707803090415

Epoch: 6| Step: 12
Training loss: 1.4659254550933838
Validation loss: 2.073797106742859

Epoch: 6| Step: 13
Training loss: 1.4532594680786133
Validation loss: 2.1187791426976523

Epoch: 104| Step: 0
Training loss: 2.501771926879883
Validation loss: 2.1390859484672546

Epoch: 6| Step: 1
Training loss: 1.4283720254898071
Validation loss: 2.114744544029236

Epoch: 6| Step: 2
Training loss: 1.363626480102539
Validation loss: 2.1337568958600364

Epoch: 6| Step: 3
Training loss: 2.4441518783569336
Validation loss: 2.2047160267829895

Epoch: 6| Step: 4
Training loss: 2.0417237281799316
Validation loss: 2.1930642326672873

Epoch: 6| Step: 5
Training loss: 1.4557932615280151
Validation loss: 2.2049325903256736

Epoch: 6| Step: 6
Training loss: 1.7547656297683716
Validation loss: 2.1700216134389243

Epoch: 6| Step: 7
Training loss: 1.4348993301391602
Validation loss: 2.171458065509796

Epoch: 6| Step: 8
Training loss: 1.5987567901611328
Validation loss: 2.075266440709432

Epoch: 6| Step: 9
Training loss: 2.15766978263855
Validation loss: 2.0933136145273843

Epoch: 6| Step: 10
Training loss: 1.7135505676269531
Validation loss: 2.0721152822176614

Epoch: 6| Step: 11
Training loss: 1.1836609840393066
Validation loss: 2.056530793507894

Epoch: 6| Step: 12
Training loss: 2.256484031677246
Validation loss: 2.0515792965888977

Epoch: 6| Step: 13
Training loss: 1.8542652130126953
Validation loss: 2.113028347492218

Epoch: 105| Step: 0
Training loss: 1.3404161930084229
Validation loss: 2.0970320304234824

Epoch: 6| Step: 1
Training loss: 1.7138811349868774
Validation loss: 2.090384840965271

Epoch: 6| Step: 2
Training loss: 1.7263803482055664
Validation loss: 2.0486825108528137

Epoch: 6| Step: 3
Training loss: 1.3790221214294434
Validation loss: 2.1122214595476785

Epoch: 6| Step: 4
Training loss: 2.309176206588745
Validation loss: 2.102182924747467

Epoch: 6| Step: 5
Training loss: 2.35331654548645
Validation loss: 2.075201610724131

Epoch: 6| Step: 6
Training loss: 1.9176913499832153
Validation loss: 2.152631858984629

Epoch: 6| Step: 7
Training loss: 1.3905149698257446
Validation loss: 2.1287460327148438

Epoch: 6| Step: 8
Training loss: 1.712948203086853
Validation loss: 2.1137880086898804

Epoch: 6| Step: 9
Training loss: 1.3598854541778564
Validation loss: 2.1000768740971885

Epoch: 6| Step: 10
Training loss: 1.5258183479309082
Validation loss: 2.0997094909350076

Epoch: 6| Step: 11
Training loss: 1.945883870124817
Validation loss: 2.120378295580546

Epoch: 6| Step: 12
Training loss: 2.241426944732666
Validation loss: 2.062589685122172

Epoch: 6| Step: 13
Training loss: 1.7558115720748901
Validation loss: 2.110621233781179

Epoch: 106| Step: 0
Training loss: 1.3326188325881958
Validation loss: 2.0833200017611184

Epoch: 6| Step: 1
Training loss: 1.4422948360443115
Validation loss: 2.1466154058774314

Epoch: 6| Step: 2
Training loss: 1.532790184020996
Validation loss: 2.145253896713257

Epoch: 6| Step: 3
Training loss: 2.4846932888031006
Validation loss: 2.063099980354309

Epoch: 6| Step: 4
Training loss: 1.7507669925689697
Validation loss: 2.1046645442644754

Epoch: 6| Step: 5
Training loss: 1.7604025602340698
Validation loss: 2.0913593967755637

Epoch: 6| Step: 6
Training loss: 1.9954349994659424
Validation loss: 2.13129456837972

Epoch: 6| Step: 7
Training loss: 2.3505914211273193
Validation loss: 2.1064677635828652

Epoch: 6| Step: 8
Training loss: 1.5197093486785889
Validation loss: 2.0989701747894287

Epoch: 6| Step: 9
Training loss: 1.9103635549545288
Validation loss: 2.0858021179835

Epoch: 6| Step: 10
Training loss: 1.4903076887130737
Validation loss: 2.093677520751953

Epoch: 6| Step: 11
Training loss: 1.343921422958374
Validation loss: 2.113007922967275

Epoch: 6| Step: 12
Training loss: 1.7689837217330933
Validation loss: 2.0969618558883667

Epoch: 6| Step: 13
Training loss: 2.090047597885132
Validation loss: 2.096575061480204

Epoch: 107| Step: 0
Training loss: 2.2262978553771973
Validation loss: 2.044455885887146

Epoch: 6| Step: 1
Training loss: 1.9923888444900513
Validation loss: 2.1107513109842935

Epoch: 6| Step: 2
Training loss: 1.5765708684921265
Validation loss: 2.058760126431783

Epoch: 6| Step: 3
Training loss: 1.497318148612976
Validation loss: 2.0861584146817527

Epoch: 6| Step: 4
Training loss: 1.4050095081329346
Validation loss: 2.0887962579727173

Epoch: 6| Step: 5
Training loss: 1.456162691116333
Validation loss: 2.1262580156326294

Epoch: 6| Step: 6
Training loss: 1.602881669998169
Validation loss: 2.1322131355603537

Epoch: 6| Step: 7
Training loss: 1.6647984981536865
Validation loss: 2.1171278953552246

Epoch: 6| Step: 8
Training loss: 1.7763164043426514
Validation loss: 2.0890173514684043

Epoch: 6| Step: 9
Training loss: 1.921080470085144
Validation loss: 2.139523426691691

Epoch: 6| Step: 10
Training loss: 1.7909040451049805
Validation loss: 2.1758347551027932

Epoch: 6| Step: 11
Training loss: 2.195866584777832
Validation loss: 2.167515456676483

Epoch: 6| Step: 12
Training loss: 1.9523519277572632
Validation loss: 2.1712854305903115

Epoch: 6| Step: 13
Training loss: 1.4949932098388672
Validation loss: 2.178191145261129

Epoch: 108| Step: 0
Training loss: 1.8504080772399902
Validation loss: 2.1469576954841614

Epoch: 6| Step: 1
Training loss: 1.6848833560943604
Validation loss: 2.11545737584432

Epoch: 6| Step: 2
Training loss: 2.1876800060272217
Validation loss: 2.0739222168922424

Epoch: 6| Step: 3
Training loss: 1.625549554824829
Validation loss: 2.0993166168530784

Epoch: 6| Step: 4
Training loss: 1.7272778749465942
Validation loss: 2.08995254834493

Epoch: 6| Step: 5
Training loss: 1.0111383199691772
Validation loss: 2.0784975488980613

Epoch: 6| Step: 6
Training loss: 1.4020582437515259
Validation loss: 2.079209009806315

Epoch: 6| Step: 7
Training loss: 2.0047647953033447
Validation loss: 2.0826637744903564

Epoch: 6| Step: 8
Training loss: 1.4886136054992676
Validation loss: 2.042527457078298

Epoch: 6| Step: 9
Training loss: 1.9705256223678589
Validation loss: 2.077609419822693

Epoch: 6| Step: 10
Training loss: 1.6023446321487427
Validation loss: 2.113448897997538

Epoch: 6| Step: 11
Training loss: 1.7293708324432373
Validation loss: 2.120577613512675

Epoch: 6| Step: 12
Training loss: 2.228973627090454
Validation loss: 2.1526917219161987

Epoch: 6| Step: 13
Training loss: 1.9938613176345825
Validation loss: 2.1480005184809365

Epoch: 109| Step: 0
Training loss: 1.509802222251892
Validation loss: 2.186784485975901

Epoch: 6| Step: 1
Training loss: 2.391195297241211
Validation loss: 2.144986609617869

Epoch: 6| Step: 2
Training loss: 1.4705150127410889
Validation loss: 2.10435551404953

Epoch: 6| Step: 3
Training loss: 1.7712669372558594
Validation loss: 2.1090967655181885

Epoch: 6| Step: 4
Training loss: 1.0760513544082642
Validation loss: 2.120765805244446

Epoch: 6| Step: 5
Training loss: 1.5052608251571655
Validation loss: 2.051558534304301

Epoch: 6| Step: 6
Training loss: 1.9854164123535156
Validation loss: 2.0499198039372764

Epoch: 6| Step: 7
Training loss: 1.7395604848861694
Validation loss: 2.1088720162709556

Epoch: 6| Step: 8
Training loss: 1.9740092754364014
Validation loss: 2.089734971523285

Epoch: 6| Step: 9
Training loss: 1.6583170890808105
Validation loss: 2.0921295483907065

Epoch: 6| Step: 10
Training loss: 1.9948217868804932
Validation loss: 2.1001381476720176

Epoch: 6| Step: 11
Training loss: 1.7984020709991455
Validation loss: 2.083815813064575

Epoch: 6| Step: 12
Training loss: 1.9836511611938477
Validation loss: 2.1035871307055154

Epoch: 6| Step: 13
Training loss: 1.665712833404541
Validation loss: 2.088960071404775

Epoch: 110| Step: 0
Training loss: 1.581364393234253
Validation loss: 2.0876018603642783

Epoch: 6| Step: 1
Training loss: 1.923791766166687
Validation loss: 2.0936198433240256

Epoch: 6| Step: 2
Training loss: 1.9817277193069458
Validation loss: 2.091226041316986

Epoch: 6| Step: 3
Training loss: 1.7682039737701416
Validation loss: 2.0628815293312073

Epoch: 6| Step: 4
Training loss: 1.7511754035949707
Validation loss: 2.1228368481000266

Epoch: 6| Step: 5
Training loss: 2.098118305206299
Validation loss: 2.0814799666404724

Epoch: 6| Step: 6
Training loss: 1.3473773002624512
Validation loss: 2.148215432961782

Epoch: 6| Step: 7
Training loss: 1.7963145971298218
Validation loss: 2.1330291430155435

Epoch: 6| Step: 8
Training loss: 1.5292675495147705
Validation loss: 2.1395339171091714

Epoch: 6| Step: 9
Training loss: 1.1949340105056763
Validation loss: 2.1625924905141196

Epoch: 6| Step: 10
Training loss: 2.2287356853485107
Validation loss: 2.162543018658956

Epoch: 6| Step: 11
Training loss: 1.626129150390625
Validation loss: 2.1398565967877707

Epoch: 6| Step: 12
Training loss: 1.6695117950439453
Validation loss: 2.103390554587046

Epoch: 6| Step: 13
Training loss: 2.1742329597473145
Validation loss: 2.0811933279037476

Epoch: 111| Step: 0
Training loss: 2.452505588531494
Validation loss: 2.1244156757990518

Epoch: 6| Step: 1
Training loss: 2.392982006072998
Validation loss: 2.0729887286822

Epoch: 6| Step: 2
Training loss: 1.8986585140228271
Validation loss: 2.068973958492279

Epoch: 6| Step: 3
Training loss: 2.1883127689361572
Validation loss: 2.0646841327349343

Epoch: 6| Step: 4
Training loss: 1.349351406097412
Validation loss: 2.094282070795695

Epoch: 6| Step: 5
Training loss: 1.2102508544921875
Validation loss: 2.1126381357510886

Epoch: 6| Step: 6
Training loss: 1.7062489986419678
Validation loss: 2.0962892969449363

Epoch: 6| Step: 7
Training loss: 1.5749897956848145
Validation loss: 2.0690077741940818

Epoch: 6| Step: 8
Training loss: 1.5294079780578613
Validation loss: 2.0932941834131875

Epoch: 6| Step: 9
Training loss: 1.791596531867981
Validation loss: 2.102067708969116

Epoch: 6| Step: 10
Training loss: 1.5623987913131714
Validation loss: 2.12131001551946

Epoch: 6| Step: 11
Training loss: 1.5479673147201538
Validation loss: 2.101127028465271

Epoch: 6| Step: 12
Training loss: 1.453084945678711
Validation loss: 2.1118701895078025

Epoch: 6| Step: 13
Training loss: 1.418065071105957
Validation loss: 2.1414764324824014

Epoch: 112| Step: 0
Training loss: 1.3782682418823242
Validation loss: 2.168866594632467

Epoch: 6| Step: 1
Training loss: 1.725569486618042
Validation loss: 2.2608538468678794

Epoch: 6| Step: 2
Training loss: 2.4417881965637207
Validation loss: 2.2537593046824136

Epoch: 6| Step: 3
Training loss: 2.47328782081604
Validation loss: 2.2580028772354126

Epoch: 6| Step: 4
Training loss: 1.1989059448242188
Validation loss: 2.266642173131307

Epoch: 6| Step: 5
Training loss: 1.8060579299926758
Validation loss: 2.25164794921875

Epoch: 6| Step: 6
Training loss: 1.3358186483383179
Validation loss: 2.2227470676104226

Epoch: 6| Step: 7
Training loss: 1.8902804851531982
Validation loss: 2.177753448486328

Epoch: 6| Step: 8
Training loss: 2.1669421195983887
Validation loss: 2.149281362692515

Epoch: 6| Step: 9
Training loss: 1.1302920579910278
Validation loss: 2.1209444204966226

Epoch: 6| Step: 10
Training loss: 2.4437947273254395
Validation loss: 2.119278371334076

Epoch: 6| Step: 11
Training loss: 1.6503310203552246
Validation loss: 2.061856190363566

Epoch: 6| Step: 12
Training loss: 1.8175280094146729
Validation loss: 2.0953829884529114

Epoch: 6| Step: 13
Training loss: 1.4517464637756348
Validation loss: 2.0706438024838767

Epoch: 113| Step: 0
Training loss: 1.4513893127441406
Validation loss: 2.10944531361262

Epoch: 6| Step: 1
Training loss: 2.173640251159668
Validation loss: 2.077755411465963

Epoch: 6| Step: 2
Training loss: 1.8032253980636597
Validation loss: 2.144561310609182

Epoch: 6| Step: 3
Training loss: 2.0641603469848633
Validation loss: 2.1300139824549356

Epoch: 6| Step: 4
Training loss: 1.7710984945297241
Validation loss: 2.060129225254059

Epoch: 6| Step: 5
Training loss: 1.145353078842163
Validation loss: 2.071602443854014

Epoch: 6| Step: 6
Training loss: 2.2956135272979736
Validation loss: 2.1358598868052163

Epoch: 6| Step: 7
Training loss: 1.823473334312439
Validation loss: 2.090328017870585

Epoch: 6| Step: 8
Training loss: 1.474025845527649
Validation loss: 2.091358264287313

Epoch: 6| Step: 9
Training loss: 1.8709341287612915
Validation loss: 2.1238245169321694

Epoch: 6| Step: 10
Training loss: 2.0551674365997314
Validation loss: 2.1416738629341125

Epoch: 6| Step: 11
Training loss: 1.2256276607513428
Validation loss: 2.159540911515554

Epoch: 6| Step: 12
Training loss: 2.5746400356292725
Validation loss: 2.1401074330012

Epoch: 6| Step: 13
Training loss: 1.7635048627853394
Validation loss: 2.182817061742147

Epoch: 114| Step: 0
Training loss: 1.8229973316192627
Validation loss: 2.181902368863424

Epoch: 6| Step: 1
Training loss: 1.5820670127868652
Validation loss: 2.091300388177236

Epoch: 6| Step: 2
Training loss: 1.6881004571914673
Validation loss: 2.1053940455118814

Epoch: 6| Step: 3
Training loss: 2.249359607696533
Validation loss: 2.1326005260149636

Epoch: 6| Step: 4
Training loss: 1.8324413299560547
Validation loss: 2.065428137779236

Epoch: 6| Step: 5
Training loss: 1.6218899488449097
Validation loss: 2.0499890645345054

Epoch: 6| Step: 6
Training loss: 1.7499080896377563
Validation loss: 2.050004164377848

Epoch: 6| Step: 7
Training loss: 1.8568885326385498
Validation loss: 2.0718849500020347

Epoch: 6| Step: 8
Training loss: 1.4418634176254272
Validation loss: 2.116644283135732

Epoch: 6| Step: 9
Training loss: 1.5023822784423828
Validation loss: 2.066814740498861

Epoch: 6| Step: 10
Training loss: 2.1969385147094727
Validation loss: 2.0581626693407693

Epoch: 6| Step: 11
Training loss: 1.5645467042922974
Validation loss: 2.0768012007077536

Epoch: 6| Step: 12
Training loss: 1.547715187072754
Validation loss: 2.0448034207026162

Epoch: 6| Step: 13
Training loss: 1.2692298889160156
Validation loss: 2.071778098742167

Epoch: 115| Step: 0
Training loss: 1.3230600357055664
Validation loss: 2.091794749101003

Epoch: 6| Step: 1
Training loss: 2.261455535888672
Validation loss: 2.1000494360923767

Epoch: 6| Step: 2
Training loss: 1.05711030960083
Validation loss: 2.171407620112101

Epoch: 6| Step: 3
Training loss: 2.3690662384033203
Validation loss: 2.1379818320274353

Epoch: 6| Step: 4
Training loss: 1.3208236694335938
Validation loss: 2.15826682249705

Epoch: 6| Step: 5
Training loss: 1.7933857440948486
Validation loss: 2.175718903541565

Epoch: 6| Step: 6
Training loss: 1.8569700717926025
Validation loss: 2.1666683157285056

Epoch: 6| Step: 7
Training loss: 1.499058723449707
Validation loss: 2.2135140697161355

Epoch: 6| Step: 8
Training loss: 1.4596362113952637
Validation loss: 2.112251897652944

Epoch: 6| Step: 9
Training loss: 2.1115307807922363
Validation loss: 2.0723052819569907

Epoch: 6| Step: 10
Training loss: 1.926920771598816
Validation loss: 2.0978992780049643

Epoch: 6| Step: 11
Training loss: 1.3193039894104004
Validation loss: 2.1378334561983743

Epoch: 6| Step: 12
Training loss: 1.5482127666473389
Validation loss: 2.1038283308347068

Epoch: 6| Step: 13
Training loss: 1.7886934280395508
Validation loss: 2.059885084629059

Epoch: 116| Step: 0
Training loss: 2.146517753601074
Validation loss: 2.0816619793574014

Epoch: 6| Step: 1
Training loss: 1.8608229160308838
Validation loss: 2.0785917242368064

Epoch: 6| Step: 2
Training loss: 1.1463876962661743
Validation loss: 2.0932013591130576

Epoch: 6| Step: 3
Training loss: 1.8526463508605957
Validation loss: 2.107516884803772

Epoch: 6| Step: 4
Training loss: 1.4927247762680054
Validation loss: 2.1163355509440103

Epoch: 6| Step: 5
Training loss: 2.072300910949707
Validation loss: 2.0899598201115928

Epoch: 6| Step: 6
Training loss: 1.8944718837738037
Validation loss: 2.1244381268819175

Epoch: 6| Step: 7
Training loss: 1.8331434726715088
Validation loss: 2.1037633419036865

Epoch: 6| Step: 8
Training loss: 1.507434368133545
Validation loss: 2.112370808919271

Epoch: 6| Step: 9
Training loss: 1.5147242546081543
Validation loss: 2.1004569927851358

Epoch: 6| Step: 10
Training loss: 1.527599573135376
Validation loss: 2.1288167436917624

Epoch: 6| Step: 11
Training loss: 2.437584400177002
Validation loss: 2.1584074099858603

Epoch: 6| Step: 12
Training loss: 1.6255444288253784
Validation loss: 2.1630405386288962

Epoch: 6| Step: 13
Training loss: 1.3499352931976318
Validation loss: 2.166688084602356

Epoch: 117| Step: 0
Training loss: 1.9125049114227295
Validation loss: 2.1722819407780967

Epoch: 6| Step: 1
Training loss: 1.7946895360946655
Validation loss: 2.1541500886281333

Epoch: 6| Step: 2
Training loss: 1.8785594701766968
Validation loss: 2.132957716782888

Epoch: 6| Step: 3
Training loss: 1.0069869756698608
Validation loss: 2.1286167105038962

Epoch: 6| Step: 4
Training loss: 1.102639079093933
Validation loss: 2.1246010661125183

Epoch: 6| Step: 5
Training loss: 2.109127998352051
Validation loss: 2.1176167925198874

Epoch: 6| Step: 6
Training loss: 1.3802238702774048
Validation loss: 2.10635115702947

Epoch: 6| Step: 7
Training loss: 1.9684727191925049
Validation loss: 2.0816648801167807

Epoch: 6| Step: 8
Training loss: 1.36332106590271
Validation loss: 2.0989132126172385

Epoch: 6| Step: 9
Training loss: 1.0778980255126953
Validation loss: 2.1134960651397705

Epoch: 6| Step: 10
Training loss: 1.662390947341919
Validation loss: 2.110727330048879

Epoch: 6| Step: 11
Training loss: 1.8187816143035889
Validation loss: 2.0603391528129578

Epoch: 6| Step: 12
Training loss: 2.4774117469787598
Validation loss: 2.0896676182746887

Epoch: 6| Step: 13
Training loss: 1.960228681564331
Validation loss: 2.108561714490255

Epoch: 118| Step: 0
Training loss: 1.2256226539611816
Validation loss: 2.0391753911972046

Epoch: 6| Step: 1
Training loss: 2.420797348022461
Validation loss: 2.065643052260081

Epoch: 6| Step: 2
Training loss: 1.3715442419052124
Validation loss: 2.0766600569089255

Epoch: 6| Step: 3
Training loss: 1.7681522369384766
Validation loss: 2.1256622473398843

Epoch: 6| Step: 4
Training loss: 1.6286470890045166
Validation loss: 2.134079694747925

Epoch: 6| Step: 5
Training loss: 1.85063636302948
Validation loss: 2.1298813025156655

Epoch: 6| Step: 6
Training loss: 1.3259615898132324
Validation loss: 2.1102612217267356

Epoch: 6| Step: 7
Training loss: 1.5598132610321045
Validation loss: 2.1427958011627197

Epoch: 6| Step: 8
Training loss: 1.282422661781311
Validation loss: 2.0881868600845337

Epoch: 6| Step: 9
Training loss: 1.9998186826705933
Validation loss: 2.1510316530863443

Epoch: 6| Step: 10
Training loss: 1.0672852993011475
Validation loss: 2.090394218762716

Epoch: 6| Step: 11
Training loss: 1.7412803173065186
Validation loss: 2.1221426924069724

Epoch: 6| Step: 12
Training loss: 2.3518166542053223
Validation loss: 2.1068031191825867

Epoch: 6| Step: 13
Training loss: 1.9117308855056763
Validation loss: 2.1313445965449014

Epoch: 119| Step: 0
Training loss: 1.9126172065734863
Validation loss: 2.1044928431510925

Epoch: 6| Step: 1
Training loss: 2.0841660499572754
Validation loss: 2.1196178595225015

Epoch: 6| Step: 2
Training loss: 1.5081310272216797
Validation loss: 2.0432812174161277

Epoch: 6| Step: 3
Training loss: 1.3676888942718506
Validation loss: 2.085736572742462

Epoch: 6| Step: 4
Training loss: 2.1604018211364746
Validation loss: 2.067534108956655

Epoch: 6| Step: 5
Training loss: 1.116424798965454
Validation loss: 2.142623782157898

Epoch: 6| Step: 6
Training loss: 1.7870410680770874
Validation loss: 2.08496763308843

Epoch: 6| Step: 7
Training loss: 1.7559223175048828
Validation loss: 2.067250390847524

Epoch: 6| Step: 8
Training loss: 1.240136981010437
Validation loss: 2.1071121096611023

Epoch: 6| Step: 9
Training loss: 1.5390912294387817
Validation loss: 2.095951517422994

Epoch: 6| Step: 10
Training loss: 1.291642189025879
Validation loss: 2.114311675230662

Epoch: 6| Step: 11
Training loss: 1.7529915571212769
Validation loss: 2.142648975054423

Epoch: 6| Step: 12
Training loss: 2.166426181793213
Validation loss: 2.1695822874704995

Epoch: 6| Step: 13
Training loss: 1.6691608428955078
Validation loss: 2.0953674713770547

Epoch: 120| Step: 0
Training loss: 1.948626160621643
Validation loss: 2.1540562311808267

Epoch: 6| Step: 1
Training loss: 1.679206132888794
Validation loss: 2.1902327140172324

Epoch: 6| Step: 2
Training loss: 1.8922268152236938
Validation loss: 2.1875828901926675

Epoch: 6| Step: 3
Training loss: 1.6625885963439941
Validation loss: 2.1588420073191323

Epoch: 6| Step: 4
Training loss: 1.5734652280807495
Validation loss: 2.150379200776418

Epoch: 6| Step: 5
Training loss: 1.4082854986190796
Validation loss: 2.131541987260183

Epoch: 6| Step: 6
Training loss: 1.3679990768432617
Validation loss: 2.1237986087799072

Epoch: 6| Step: 7
Training loss: 1.5938827991485596
Validation loss: 2.121056914329529

Epoch: 6| Step: 8
Training loss: 2.266187906265259
Validation loss: 2.0978647271792092

Epoch: 6| Step: 9
Training loss: 1.5449479818344116
Validation loss: 2.1077216466267905

Epoch: 6| Step: 10
Training loss: 1.535529613494873
Validation loss: 2.118229925632477

Epoch: 6| Step: 11
Training loss: 1.9709906578063965
Validation loss: 2.0668946901957193

Epoch: 6| Step: 12
Training loss: 1.6379321813583374
Validation loss: 2.1281784971555076

Epoch: 6| Step: 13
Training loss: 1.6196026802062988
Validation loss: 2.09105251232783

Epoch: 121| Step: 0
Training loss: 2.1182007789611816
Validation loss: 2.1101735830307007

Epoch: 6| Step: 1
Training loss: 2.171915054321289
Validation loss: 2.088274836540222

Epoch: 6| Step: 2
Training loss: 1.7834434509277344
Validation loss: 2.1140419642130532

Epoch: 6| Step: 3
Training loss: 1.373767614364624
Validation loss: 2.126820127169291

Epoch: 6| Step: 4
Training loss: 1.366703987121582
Validation loss: 2.0900710225105286

Epoch: 6| Step: 5
Training loss: 1.171482801437378
Validation loss: 2.1007643739382424

Epoch: 6| Step: 6
Training loss: 1.8391051292419434
Validation loss: 2.0774060090382895

Epoch: 6| Step: 7
Training loss: 1.5132547616958618
Validation loss: 2.088812271753947

Epoch: 6| Step: 8
Training loss: 1.6995701789855957
Validation loss: 2.0790583888689675

Epoch: 6| Step: 9
Training loss: 1.215809941291809
Validation loss: 2.0826488534609475

Epoch: 6| Step: 10
Training loss: 1.3800523281097412
Validation loss: 2.0943716565767923

Epoch: 6| Step: 11
Training loss: 1.3189992904663086
Validation loss: 2.147967835267385

Epoch: 6| Step: 12
Training loss: 2.072598457336426
Validation loss: 2.1593939065933228

Epoch: 6| Step: 13
Training loss: 1.741222620010376
Validation loss: 2.142749806245168

Epoch: 122| Step: 0
Training loss: 1.6308672428131104
Validation loss: 2.187442978223165

Epoch: 6| Step: 1
Training loss: 2.022940158843994
Validation loss: 2.1527018547058105

Epoch: 6| Step: 2
Training loss: 1.7187327146530151
Validation loss: 2.1306865215301514

Epoch: 6| Step: 3
Training loss: 1.9904792308807373
Validation loss: 2.130461057027181

Epoch: 6| Step: 4
Training loss: 0.9053653478622437
Validation loss: 2.0921087662378945

Epoch: 6| Step: 5
Training loss: 1.7697691917419434
Validation loss: 2.078678528467814

Epoch: 6| Step: 6
Training loss: 1.4073293209075928
Validation loss: 2.104019820690155

Epoch: 6| Step: 7
Training loss: 1.5040051937103271
Validation loss: 2.061085879802704

Epoch: 6| Step: 8
Training loss: 1.6231346130371094
Validation loss: 2.0659916003545127

Epoch: 6| Step: 9
Training loss: 1.6332956552505493
Validation loss: 2.113304158051809

Epoch: 6| Step: 10
Training loss: 1.1530934572219849
Validation loss: 2.0583958427111306

Epoch: 6| Step: 11
Training loss: 2.0697648525238037
Validation loss: 2.0858920415242515

Epoch: 6| Step: 12
Training loss: 1.5398974418640137
Validation loss: 2.0869480768839517

Epoch: 6| Step: 13
Training loss: 2.105132579803467
Validation loss: 2.12552809715271

Epoch: 123| Step: 0
Training loss: 1.7255256175994873
Validation loss: 2.110526959101359

Epoch: 6| Step: 1
Training loss: 2.0275232791900635
Validation loss: 2.090748131275177

Epoch: 6| Step: 2
Training loss: 2.041116952896118
Validation loss: 2.1657060583432517

Epoch: 6| Step: 3
Training loss: 1.7810983657836914
Validation loss: 2.144054412841797

Epoch: 6| Step: 4
Training loss: 1.3195685148239136
Validation loss: 2.066875914732615

Epoch: 6| Step: 5
Training loss: 1.8645069599151611
Validation loss: 2.106256345907847

Epoch: 6| Step: 6
Training loss: 1.571911096572876
Validation loss: 2.0854048331578574

Epoch: 6| Step: 7
Training loss: 1.240535855293274
Validation loss: 2.0341344078381858

Epoch: 6| Step: 8
Training loss: 1.753507375717163
Validation loss: 2.136354843775431

Epoch: 6| Step: 9
Training loss: 1.3015594482421875
Validation loss: 2.1227760116259256

Epoch: 6| Step: 10
Training loss: 1.504209041595459
Validation loss: 2.1078364650408425

Epoch: 6| Step: 11
Training loss: 1.8172633647918701
Validation loss: 2.0905422369639077

Epoch: 6| Step: 12
Training loss: 1.078639268875122
Validation loss: 2.147678852081299

Epoch: 6| Step: 13
Training loss: 1.7025408744812012
Validation loss: 2.119856079419454

Epoch: 124| Step: 0
Training loss: 1.586685299873352
Validation loss: 2.13594788312912

Epoch: 6| Step: 1
Training loss: 1.0027194023132324
Validation loss: 2.148901720841726

Epoch: 6| Step: 2
Training loss: 2.1971435546875
Validation loss: 2.156294325987498

Epoch: 6| Step: 3
Training loss: 1.3010047674179077
Validation loss: 2.102793296178182

Epoch: 6| Step: 4
Training loss: 1.645353078842163
Validation loss: 2.0987188816070557

Epoch: 6| Step: 5
Training loss: 1.9808952808380127
Validation loss: 2.0819895267486572

Epoch: 6| Step: 6
Training loss: 1.1461305618286133
Validation loss: 2.107184131940206

Epoch: 6| Step: 7
Training loss: 1.6011399030685425
Validation loss: 2.0453288555145264

Epoch: 6| Step: 8
Training loss: 1.302160382270813
Validation loss: 2.085634628931681

Epoch: 6| Step: 9
Training loss: 1.3343956470489502
Validation loss: 2.075857142607371

Epoch: 6| Step: 10
Training loss: 1.9428077936172485
Validation loss: 2.1163188815116882

Epoch: 6| Step: 11
Training loss: 2.1046414375305176
Validation loss: 2.121436278025309

Epoch: 6| Step: 12
Training loss: 1.6844061613082886
Validation loss: 2.0882925987243652

Epoch: 6| Step: 13
Training loss: 1.9557725191116333
Validation loss: 2.1212953527768454

Epoch: 125| Step: 0
Training loss: 1.3535354137420654
Validation loss: 2.140308062235514

Epoch: 6| Step: 1
Training loss: 1.884962558746338
Validation loss: 2.102989753087362

Epoch: 6| Step: 2
Training loss: 1.522265911102295
Validation loss: 2.0951520999272666

Epoch: 6| Step: 3
Training loss: 2.226482391357422
Validation loss: 2.1331751942634583

Epoch: 6| Step: 4
Training loss: 1.4274024963378906
Validation loss: 2.2056944568951926

Epoch: 6| Step: 5
Training loss: 1.7688043117523193
Validation loss: 2.140981376171112

Epoch: 6| Step: 6
Training loss: 1.4404855966567993
Validation loss: 2.1389546990394592

Epoch: 6| Step: 7
Training loss: 1.5383882522583008
Validation loss: 2.106217165788015

Epoch: 6| Step: 8
Training loss: 1.5817269086837769
Validation loss: 2.13463302453359

Epoch: 6| Step: 9
Training loss: 0.8609199523925781
Validation loss: 2.1007915337880454

Epoch: 6| Step: 10
Training loss: 1.1853067874908447
Validation loss: 2.1272593339284263

Epoch: 6| Step: 11
Training loss: 2.348916530609131
Validation loss: 2.1246438225110373

Epoch: 6| Step: 12
Training loss: 1.9109623432159424
Validation loss: 2.080754518508911

Epoch: 6| Step: 13
Training loss: 1.7422473430633545
Validation loss: 2.087592522303263

Epoch: 126| Step: 0
Training loss: 0.9641830921173096
Validation loss: 2.116676847139994

Epoch: 6| Step: 1
Training loss: 1.7082594633102417
Validation loss: 2.1143268744150796

Epoch: 6| Step: 2
Training loss: 2.416998863220215
Validation loss: 2.0764660437901816

Epoch: 6| Step: 3
Training loss: 1.679848313331604
Validation loss: 2.1329347491264343

Epoch: 6| Step: 4
Training loss: 1.2650971412658691
Validation loss: 2.0957425832748413

Epoch: 6| Step: 5
Training loss: 1.687853455543518
Validation loss: 2.112968643506368

Epoch: 6| Step: 6
Training loss: 1.415309190750122
Validation loss: 2.0961196621259055

Epoch: 6| Step: 7
Training loss: 1.4754549264907837
Validation loss: 2.132330040136973

Epoch: 6| Step: 8
Training loss: 2.4565770626068115
Validation loss: 2.13030074040095

Epoch: 6| Step: 9
Training loss: 1.3350759744644165
Validation loss: 2.130029638608297

Epoch: 6| Step: 10
Training loss: 1.245018720626831
Validation loss: 2.1369513670603433

Epoch: 6| Step: 11
Training loss: 1.2202969789505005
Validation loss: 2.1118423541386924

Epoch: 6| Step: 12
Training loss: 2.125584602355957
Validation loss: 2.1315868894259133

Epoch: 6| Step: 13
Training loss: 1.4125579595565796
Validation loss: 2.14474223057429

Epoch: 127| Step: 0
Training loss: 1.8312139511108398
Validation loss: 2.1207926074663797

Epoch: 6| Step: 1
Training loss: 1.3265125751495361
Validation loss: 2.0949894984563193

Epoch: 6| Step: 2
Training loss: 2.089909076690674
Validation loss: 2.070500115553538

Epoch: 6| Step: 3
Training loss: 1.138627290725708
Validation loss: 2.1067160169283548

Epoch: 6| Step: 4
Training loss: 1.7930185794830322
Validation loss: 2.123836179574331

Epoch: 6| Step: 5
Training loss: 1.3732614517211914
Validation loss: 2.0817065238952637

Epoch: 6| Step: 6
Training loss: 1.4971154928207397
Validation loss: 2.1421656012535095

Epoch: 6| Step: 7
Training loss: 1.6014883518218994
Validation loss: 2.092118779818217

Epoch: 6| Step: 8
Training loss: 1.846076250076294
Validation loss: 2.110428194204966

Epoch: 6| Step: 9
Training loss: 1.4617236852645874
Validation loss: 2.1619791189829507

Epoch: 6| Step: 10
Training loss: 1.7982640266418457
Validation loss: 2.1077049175898233

Epoch: 6| Step: 11
Training loss: 0.7186169624328613
Validation loss: 2.145323852698008

Epoch: 6| Step: 12
Training loss: 2.2057785987854004
Validation loss: 2.151157796382904

Epoch: 6| Step: 13
Training loss: 1.3061349391937256
Validation loss: 2.148309508959452

Epoch: 128| Step: 0
Training loss: 1.4358785152435303
Validation loss: 2.1167025764783225

Epoch: 6| Step: 1
Training loss: 1.7830686569213867
Validation loss: 2.101954778035482

Epoch: 6| Step: 2
Training loss: 1.2595642805099487
Validation loss: 2.0768463214238486

Epoch: 6| Step: 3
Training loss: 0.8776636719703674
Validation loss: 2.1121931076049805

Epoch: 6| Step: 4
Training loss: 1.8382976055145264
Validation loss: 2.1291178862253823

Epoch: 6| Step: 5
Training loss: 1.2289906740188599
Validation loss: 2.1326476534207663

Epoch: 6| Step: 6
Training loss: 1.3658108711242676
Validation loss: 2.107534090677897

Epoch: 6| Step: 7
Training loss: 1.2089722156524658
Validation loss: 2.119409521420797

Epoch: 6| Step: 8
Training loss: 1.8157985210418701
Validation loss: 2.075167934099833

Epoch: 6| Step: 9
Training loss: 1.526332139968872
Validation loss: 2.1209150552749634

Epoch: 6| Step: 10
Training loss: 2.71000075340271
Validation loss: 2.132282833258311

Epoch: 6| Step: 11
Training loss: 1.6321799755096436
Validation loss: 2.0922878781954446

Epoch: 6| Step: 12
Training loss: 1.5701916217803955
Validation loss: 2.1280671755472818

Epoch: 6| Step: 13
Training loss: 1.5222395658493042
Validation loss: 2.0958757797876992

Epoch: 129| Step: 0
Training loss: 2.1351518630981445
Validation loss: 2.141514003276825

Epoch: 6| Step: 1
Training loss: 1.690775752067566
Validation loss: 2.0887301762898765

Epoch: 6| Step: 2
Training loss: 2.185030460357666
Validation loss: 2.1405892769495645

Epoch: 6| Step: 3
Training loss: 0.9964977502822876
Validation loss: 2.1079642375310264

Epoch: 6| Step: 4
Training loss: 2.2617263793945312
Validation loss: 2.1326722502708435

Epoch: 6| Step: 5
Training loss: 1.0963170528411865
Validation loss: 2.088247219721476

Epoch: 6| Step: 6
Training loss: 1.6614248752593994
Validation loss: 2.133999506632487

Epoch: 6| Step: 7
Training loss: 1.6072638034820557
Validation loss: 2.140596588452657

Epoch: 6| Step: 8
Training loss: 1.2516489028930664
Validation loss: 2.1216564575831094

Epoch: 6| Step: 9
Training loss: 1.5885484218597412
Validation loss: 2.1420831878980002

Epoch: 6| Step: 10
Training loss: 1.7222644090652466
Validation loss: 2.1438379685084024

Epoch: 6| Step: 11
Training loss: 0.7096683979034424
Validation loss: 2.186413844426473

Epoch: 6| Step: 12
Training loss: 1.9933804273605347
Validation loss: 2.171006719271342

Epoch: 6| Step: 13
Training loss: 1.612318515777588
Validation loss: 2.157944917678833

Epoch: 130| Step: 0
Training loss: 1.233067512512207
Validation loss: 2.1499547163645425

Epoch: 6| Step: 1
Training loss: 1.5455524921417236
Validation loss: 2.108485480149587

Epoch: 6| Step: 2
Training loss: 1.4550895690917969
Validation loss: 2.1652754147847495

Epoch: 6| Step: 3
Training loss: 2.0302186012268066
Validation loss: 2.095423102378845

Epoch: 6| Step: 4
Training loss: 1.964888095855713
Validation loss: 2.137723525365194

Epoch: 6| Step: 5
Training loss: 1.67243230342865
Validation loss: 2.1140024662017822

Epoch: 6| Step: 6
Training loss: 1.8291884660720825
Validation loss: 2.094648798306783

Epoch: 6| Step: 7
Training loss: 1.171165943145752
Validation loss: 2.1099232832590737

Epoch: 6| Step: 8
Training loss: 1.5634404420852661
Validation loss: 2.0407015681266785

Epoch: 6| Step: 9
Training loss: 2.110206365585327
Validation loss: 2.142289320627848

Epoch: 6| Step: 10
Training loss: 1.3781423568725586
Validation loss: 2.045793871084849

Epoch: 6| Step: 11
Training loss: 1.1397738456726074
Validation loss: 2.0383946299552917

Epoch: 6| Step: 12
Training loss: 1.7431641817092896
Validation loss: 2.1308905482292175

Epoch: 6| Step: 13
Training loss: 1.4212892055511475
Validation loss: 2.1407235860824585

Epoch: 131| Step: 0
Training loss: 1.3512142896652222
Validation loss: 2.1294854283332825

Epoch: 6| Step: 1
Training loss: 2.0852017402648926
Validation loss: 2.1507986386617026

Epoch: 6| Step: 2
Training loss: 1.2262804508209229
Validation loss: 2.164080182711283

Epoch: 6| Step: 3
Training loss: 1.0941338539123535
Validation loss: 2.1922717491785684

Epoch: 6| Step: 4
Training loss: 1.9126315116882324
Validation loss: 2.1728087663650513

Epoch: 6| Step: 5
Training loss: 0.5794004797935486
Validation loss: 2.0968952576319375

Epoch: 6| Step: 6
Training loss: 1.8967114686965942
Validation loss: 2.0884647568066916

Epoch: 6| Step: 7
Training loss: 2.0977303981781006
Validation loss: 2.036518653233846

Epoch: 6| Step: 8
Training loss: 1.8338212966918945
Validation loss: 2.1065407395362854

Epoch: 6| Step: 9
Training loss: 2.0505900382995605
Validation loss: 2.108490069707235

Epoch: 6| Step: 10
Training loss: 1.2086687088012695
Validation loss: 2.105599363644918

Epoch: 6| Step: 11
Training loss: 1.9706007242202759
Validation loss: 2.108792225519816

Epoch: 6| Step: 12
Training loss: 1.6142960786819458
Validation loss: 2.0790852506955466

Epoch: 6| Step: 13
Training loss: 1.760570764541626
Validation loss: 2.0777933398882547

Epoch: 132| Step: 0
Training loss: 1.857801914215088
Validation loss: 2.1150717735290527

Epoch: 6| Step: 1
Training loss: 1.816997766494751
Validation loss: 2.0653332471847534

Epoch: 6| Step: 2
Training loss: 1.0653152465820312
Validation loss: 2.159159223238627

Epoch: 6| Step: 3
Training loss: 1.3943692445755005
Validation loss: 2.145207464694977

Epoch: 6| Step: 4
Training loss: 1.9728628396987915
Validation loss: 2.1674821376800537

Epoch: 6| Step: 5
Training loss: 0.8293365240097046
Validation loss: 2.197266081968943

Epoch: 6| Step: 6
Training loss: 1.5717180967330933
Validation loss: 2.1321917374928794

Epoch: 6| Step: 7
Training loss: 1.5608127117156982
Validation loss: 2.183165351549784

Epoch: 6| Step: 8
Training loss: 1.6698713302612305
Validation loss: 2.188737710316976

Epoch: 6| Step: 9
Training loss: 1.525413990020752
Validation loss: 2.186127861340841

Epoch: 6| Step: 10
Training loss: 1.8420963287353516
Validation loss: 2.155411124229431

Epoch: 6| Step: 11
Training loss: 1.2302696704864502
Validation loss: 2.1392594377199807

Epoch: 6| Step: 12
Training loss: 1.9036743640899658
Validation loss: 2.145457108815511

Epoch: 6| Step: 13
Training loss: 1.6185498237609863
Validation loss: 2.1334383487701416

Epoch: 133| Step: 0
Training loss: 1.532690405845642
Validation loss: 2.129587173461914

Epoch: 6| Step: 1
Training loss: 1.039830207824707
Validation loss: 2.0841335455576577

Epoch: 6| Step: 2
Training loss: 1.5230743885040283
Validation loss: 2.080488363901774

Epoch: 6| Step: 3
Training loss: 1.5182396173477173
Validation loss: 2.1155718763669333

Epoch: 6| Step: 4
Training loss: 1.0915627479553223
Validation loss: 2.1098005374272666

Epoch: 6| Step: 5
Training loss: 1.6070384979248047
Validation loss: 2.073783059914907

Epoch: 6| Step: 6
Training loss: 1.9987287521362305
Validation loss: 2.139362374941508

Epoch: 6| Step: 7
Training loss: 1.1683299541473389
Validation loss: 2.1138278245925903

Epoch: 6| Step: 8
Training loss: 1.6113722324371338
Validation loss: 2.130656917889913

Epoch: 6| Step: 9
Training loss: 1.191423773765564
Validation loss: 2.0622774362564087

Epoch: 6| Step: 10
Training loss: 2.227661609649658
Validation loss: 2.0874574979146323

Epoch: 6| Step: 11
Training loss: 1.5552085638046265
Validation loss: 2.1364521980285645

Epoch: 6| Step: 12
Training loss: 1.7054237127304077
Validation loss: 2.0714957118034363

Epoch: 6| Step: 13
Training loss: 1.6271662712097168
Validation loss: 2.1322070956230164

Epoch: 134| Step: 0
Training loss: 1.6951971054077148
Validation loss: 2.102381408214569

Epoch: 6| Step: 1
Training loss: 1.8191605806350708
Validation loss: 2.11164120833079

Epoch: 6| Step: 2
Training loss: 1.533473014831543
Validation loss: 2.1096606254577637

Epoch: 6| Step: 3
Training loss: 1.329192876815796
Validation loss: 2.0793006221453347

Epoch: 6| Step: 4
Training loss: 1.2378787994384766
Validation loss: 2.1344952384630838

Epoch: 6| Step: 5
Training loss: 1.7100486755371094
Validation loss: 2.125593662261963

Epoch: 6| Step: 6
Training loss: 1.2561960220336914
Validation loss: 2.1439091761906943

Epoch: 6| Step: 7
Training loss: 1.1046178340911865
Validation loss: 2.1205581426620483

Epoch: 6| Step: 8
Training loss: 1.6366043090820312
Validation loss: 2.1370795170466104

Epoch: 6| Step: 9
Training loss: 1.17167067527771
Validation loss: 2.121628006299337

Epoch: 6| Step: 10
Training loss: 1.7205018997192383
Validation loss: 2.1073202093442283

Epoch: 6| Step: 11
Training loss: 1.4881070852279663
Validation loss: 2.123704274495443

Epoch: 6| Step: 12
Training loss: 1.0487875938415527
Validation loss: 2.0959844986597695

Epoch: 6| Step: 13
Training loss: 2.3570404052734375
Validation loss: 2.1014603972434998

Epoch: 135| Step: 0
Training loss: 1.7044795751571655
Validation loss: 2.1187697649002075

Epoch: 6| Step: 1
Training loss: 1.6766606569290161
Validation loss: 2.0796391367912292

Epoch: 6| Step: 2
Training loss: 1.2498987913131714
Validation loss: 2.13599294424057

Epoch: 6| Step: 3
Training loss: 1.3198094367980957
Validation loss: 2.1797288060188293

Epoch: 6| Step: 4
Training loss: 1.494598627090454
Validation loss: 2.177574396133423

Epoch: 6| Step: 5
Training loss: 1.9738599061965942
Validation loss: 2.1741108695665994

Epoch: 6| Step: 6
Training loss: 1.959767460823059
Validation loss: 2.1719515323638916

Epoch: 6| Step: 7
Training loss: 1.6057184934616089
Validation loss: 2.1602330605189004

Epoch: 6| Step: 8
Training loss: 1.7425925731658936
Validation loss: 2.1787414948145547

Epoch: 6| Step: 9
Training loss: 1.8552887439727783
Validation loss: 2.1708059708277383

Epoch: 6| Step: 10
Training loss: 1.0948703289031982
Validation loss: 2.1242653926213584

Epoch: 6| Step: 11
Training loss: 1.0074522495269775
Validation loss: 2.080970287322998

Epoch: 6| Step: 12
Training loss: 1.4583100080490112
Validation loss: 2.1276004910469055

Epoch: 6| Step: 13
Training loss: 1.2550604343414307
Validation loss: 2.0748207370440164

Epoch: 136| Step: 0
Training loss: 1.362055778503418
Validation loss: 2.093762735525767

Epoch: 6| Step: 1
Training loss: 1.8132967948913574
Validation loss: 2.1361738244692483

Epoch: 6| Step: 2
Training loss: 1.1197869777679443
Validation loss: 2.1421650846799216

Epoch: 6| Step: 3
Training loss: 1.5849499702453613
Validation loss: 2.1523581743240356

Epoch: 6| Step: 4
Training loss: 1.7818019390106201
Validation loss: 2.158058683077494

Epoch: 6| Step: 5
Training loss: 1.695772409439087
Validation loss: 2.125418404738108

Epoch: 6| Step: 6
Training loss: 1.6011520624160767
Validation loss: 2.114724278450012

Epoch: 6| Step: 7
Training loss: 1.3530375957489014
Validation loss: 2.103360931078593

Epoch: 6| Step: 8
Training loss: 1.3800568580627441
Validation loss: 2.138562182585398

Epoch: 6| Step: 9
Training loss: 1.261575698852539
Validation loss: 2.142178992430369

Epoch: 6| Step: 10
Training loss: 1.5157794952392578
Validation loss: 2.1445013284683228

Epoch: 6| Step: 11
Training loss: 1.3586030006408691
Validation loss: 2.1782979369163513

Epoch: 6| Step: 12
Training loss: 1.4582782983779907
Validation loss: 2.0777695576349893

Epoch: 6| Step: 13
Training loss: 1.4975347518920898
Validation loss: 2.105805436770121

Epoch: 137| Step: 0
Training loss: 0.9715580344200134
Validation loss: 2.115572690963745

Epoch: 6| Step: 1
Training loss: 1.9619653224945068
Validation loss: 2.1444555521011353

Epoch: 6| Step: 2
Training loss: 1.8471565246582031
Validation loss: 2.0972782373428345

Epoch: 6| Step: 3
Training loss: 1.6127543449401855
Validation loss: 2.1485413114229837

Epoch: 6| Step: 4
Training loss: 1.2021117210388184
Validation loss: 2.0998291770617166

Epoch: 6| Step: 5
Training loss: 1.2542572021484375
Validation loss: 2.121282935142517

Epoch: 6| Step: 6
Training loss: 1.3189160823822021
Validation loss: 2.1770838101704917

Epoch: 6| Step: 7
Training loss: 1.024291753768921
Validation loss: 2.1535146037737527

Epoch: 6| Step: 8
Training loss: 2.011674404144287
Validation loss: 2.168780267238617

Epoch: 6| Step: 9
Training loss: 1.044971227645874
Validation loss: 2.1080777049064636

Epoch: 6| Step: 10
Training loss: 1.9754714965820312
Validation loss: 2.1126961509386697

Epoch: 6| Step: 11
Training loss: 1.6052953004837036
Validation loss: 2.1355502605438232

Epoch: 6| Step: 12
Training loss: 1.6206045150756836
Validation loss: 2.1173136234283447

Epoch: 6| Step: 13
Training loss: 1.6024245023727417
Validation loss: 2.174907147884369

Epoch: 138| Step: 0
Training loss: 1.2061331272125244
Validation loss: 2.1062781612078347

Epoch: 6| Step: 1
Training loss: 2.2447965145111084
Validation loss: 2.1791930198669434

Epoch: 6| Step: 2
Training loss: 1.7051641941070557
Validation loss: 2.1625293095906577

Epoch: 6| Step: 3
Training loss: 1.7303211688995361
Validation loss: 2.20902951558431

Epoch: 6| Step: 4
Training loss: 1.256364345550537
Validation loss: 2.1619590322176614

Epoch: 6| Step: 5
Training loss: 1.9055559635162354
Validation loss: 2.196235477924347

Epoch: 6| Step: 6
Training loss: 1.2052494287490845
Validation loss: 2.1589640180269876

Epoch: 6| Step: 7
Training loss: 2.1296157836914062
Validation loss: 2.1845656832059226

Epoch: 6| Step: 8
Training loss: 0.712384819984436
Validation loss: 2.136649707953135

Epoch: 6| Step: 9
Training loss: 1.0163558721542358
Validation loss: 2.095364769299825

Epoch: 6| Step: 10
Training loss: 2.0238986015319824
Validation loss: 2.1109660069147744

Epoch: 6| Step: 11
Training loss: 0.9158945679664612
Validation loss: 2.1253402630488076

Epoch: 6| Step: 12
Training loss: 2.055243492126465
Validation loss: 2.1197403271993003

Epoch: 6| Step: 13
Training loss: 1.6716628074645996
Validation loss: 2.1038929224014282

Epoch: 139| Step: 0
Training loss: 1.3484625816345215
Validation loss: 2.1282755931218467

Epoch: 6| Step: 1
Training loss: 2.01231050491333
Validation loss: 2.086088458697001

Epoch: 6| Step: 2
Training loss: 1.7177287340164185
Validation loss: 2.1069602767626443

Epoch: 6| Step: 3
Training loss: 1.4416098594665527
Validation loss: 2.126000920931498

Epoch: 6| Step: 4
Training loss: 0.7215098142623901
Validation loss: 2.163164754708608

Epoch: 6| Step: 5
Training loss: 0.980799674987793
Validation loss: 2.1900184551874795

Epoch: 6| Step: 6
Training loss: 1.9457314014434814
Validation loss: 2.2333479126294455

Epoch: 6| Step: 7
Training loss: 1.587093710899353
Validation loss: 2.2396989266077676

Epoch: 6| Step: 8
Training loss: 1.5377825498580933
Validation loss: 2.165627419948578

Epoch: 6| Step: 9
Training loss: 2.024458408355713
Validation loss: 2.0953211585680642

Epoch: 6| Step: 10
Training loss: 1.1978106498718262
Validation loss: 2.118273297945658

Epoch: 6| Step: 11
Training loss: 0.9279897212982178
Validation loss: 2.1241919795672097

Epoch: 6| Step: 12
Training loss: 1.3649942874908447
Validation loss: 2.1282930771509805

Epoch: 6| Step: 13
Training loss: 1.752152681350708
Validation loss: 2.111144026120504

Epoch: 140| Step: 0
Training loss: 1.7103865146636963
Validation loss: 2.0267855723698935

Epoch: 6| Step: 1
Training loss: 1.2291524410247803
Validation loss: 2.1269564628601074

Epoch: 6| Step: 2
Training loss: 1.7976816892623901
Validation loss: 2.096421400705973

Epoch: 6| Step: 3
Training loss: 1.3450603485107422
Validation loss: 2.1016878684361777

Epoch: 6| Step: 4
Training loss: 1.5213630199432373
Validation loss: 2.1546890139579773

Epoch: 6| Step: 5
Training loss: 1.286884069442749
Validation loss: 2.129156529903412

Epoch: 6| Step: 6
Training loss: 1.1964828968048096
Validation loss: 2.137926757335663

Epoch: 6| Step: 7
Training loss: 2.062082529067993
Validation loss: 2.09992516040802

Epoch: 6| Step: 8
Training loss: 1.4726834297180176
Validation loss: 2.117613752683004

Epoch: 6| Step: 9
Training loss: 2.2662272453308105
Validation loss: 2.103620191415151

Epoch: 6| Step: 10
Training loss: 1.1109085083007812
Validation loss: 2.1065329710642495

Epoch: 6| Step: 11
Training loss: 0.9141408205032349
Validation loss: 2.1075308322906494

Epoch: 6| Step: 12
Training loss: 1.859342336654663
Validation loss: 2.125946581363678

Epoch: 6| Step: 13
Training loss: 1.5701611042022705
Validation loss: 2.1411774357159934

Epoch: 141| Step: 0
Training loss: 1.6825273036956787
Validation loss: 2.1338725090026855

Epoch: 6| Step: 1
Training loss: 1.6890590190887451
Validation loss: 2.1534915765126548

Epoch: 6| Step: 2
Training loss: 1.4755759239196777
Validation loss: 2.0801039338111877

Epoch: 6| Step: 3
Training loss: 0.9479767680168152
Validation loss: 2.141588111718496

Epoch: 6| Step: 4
Training loss: 0.9191498756408691
Validation loss: 2.122141202290853

Epoch: 6| Step: 5
Training loss: 1.3342368602752686
Validation loss: 2.0965042312939963

Epoch: 6| Step: 6
Training loss: 1.646738886833191
Validation loss: 2.08831650018692

Epoch: 6| Step: 7
Training loss: 2.1159744262695312
Validation loss: 2.1209505001703897

Epoch: 6| Step: 8
Training loss: 1.8903963565826416
Validation loss: 2.1603073279062905

Epoch: 6| Step: 9
Training loss: 0.9400652050971985
Validation loss: 2.1099931796391806

Epoch: 6| Step: 10
Training loss: 1.5237483978271484
Validation loss: 2.1413291494051614

Epoch: 6| Step: 11
Training loss: 1.4794193506240845
Validation loss: 2.158618370691935

Epoch: 6| Step: 12
Training loss: 0.9203078746795654
Validation loss: 2.1243769327799478

Epoch: 6| Step: 13
Training loss: 1.4663617610931396
Validation loss: 2.1074081460634866

Epoch: 142| Step: 0
Training loss: 0.973698079586029
Validation loss: 2.147963583469391

Epoch: 6| Step: 1
Training loss: 2.0477399826049805
Validation loss: 2.147933761278788

Epoch: 6| Step: 2
Training loss: 0.7198280096054077
Validation loss: 2.113386650880178

Epoch: 6| Step: 3
Training loss: 1.968785285949707
Validation loss: 2.1441481908162436

Epoch: 6| Step: 4
Training loss: 1.519151210784912
Validation loss: 2.12046887477239

Epoch: 6| Step: 5
Training loss: 1.4778796434402466
Validation loss: 2.144687016805013

Epoch: 6| Step: 6
Training loss: 1.0032355785369873
Validation loss: 2.139933705329895

Epoch: 6| Step: 7
Training loss: 1.2094485759735107
Validation loss: 2.1287485559781394

Epoch: 6| Step: 8
Training loss: 1.5142016410827637
Validation loss: 2.13806160291036

Epoch: 6| Step: 9
Training loss: 1.4603060483932495
Validation loss: 2.0747432311375937

Epoch: 6| Step: 10
Training loss: 0.9536349773406982
Validation loss: 2.160435597101847

Epoch: 6| Step: 11
Training loss: 1.2541906833648682
Validation loss: 2.174186885356903

Epoch: 6| Step: 12
Training loss: 2.172532796859741
Validation loss: 2.1099565823872886

Epoch: 6| Step: 13
Training loss: 1.9230499267578125
Validation loss: 2.091535449028015

Epoch: 143| Step: 0
Training loss: 2.2257778644561768
Validation loss: 2.1237179040908813

Epoch: 6| Step: 1
Training loss: 1.3963181972503662
Validation loss: 2.072488804658254

Epoch: 6| Step: 2
Training loss: 1.8282310962677002
Validation loss: 2.121089736620585

Epoch: 6| Step: 3
Training loss: 2.0212836265563965
Validation loss: 2.0998692909876504

Epoch: 6| Step: 4
Training loss: 1.1876813173294067
Validation loss: 2.053525686264038

Epoch: 6| Step: 5
Training loss: 1.54703950881958
Validation loss: 2.150605022907257

Epoch: 6| Step: 6
Training loss: 1.3064459562301636
Validation loss: 2.1659234364827475

Epoch: 6| Step: 7
Training loss: 1.1266684532165527
Validation loss: 2.160535534222921

Epoch: 6| Step: 8
Training loss: 1.252931833267212
Validation loss: 2.1409714420636496

Epoch: 6| Step: 9
Training loss: 1.0669821500778198
Validation loss: 2.1785797079404197

Epoch: 6| Step: 10
Training loss: 1.6401169300079346
Validation loss: 2.172359069188436

Epoch: 6| Step: 11
Training loss: 1.175182580947876
Validation loss: 2.1376473903656006

Epoch: 6| Step: 12
Training loss: 1.3414219617843628
Validation loss: 2.187038163344065

Epoch: 6| Step: 13
Training loss: 1.1698110103607178
Validation loss: 2.1318653225898743

Epoch: 144| Step: 0
Training loss: 1.4793176651000977
Validation loss: 2.097024162610372

Epoch: 6| Step: 1
Training loss: 1.8089356422424316
Validation loss: 2.1139519214630127

Epoch: 6| Step: 2
Training loss: 1.2432239055633545
Validation loss: 2.1486686070760093

Epoch: 6| Step: 3
Training loss: 0.9693450927734375
Validation loss: 2.098318099975586

Epoch: 6| Step: 4
Training loss: 2.2834737300872803
Validation loss: 2.148642122745514

Epoch: 6| Step: 5
Training loss: 1.0339305400848389
Validation loss: 2.122648994127909

Epoch: 6| Step: 6
Training loss: 1.7410495281219482
Validation loss: 2.1134870847066245

Epoch: 6| Step: 7
Training loss: 1.1587672233581543
Validation loss: 2.0769474307696023

Epoch: 6| Step: 8
Training loss: 0.999878466129303
Validation loss: 2.0690497954686484

Epoch: 6| Step: 9
Training loss: 1.7026242017745972
Validation loss: 2.1315526366233826

Epoch: 6| Step: 10
Training loss: 1.5302205085754395
Validation loss: 2.156554122765859

Epoch: 6| Step: 11
Training loss: 1.9111343622207642
Validation loss: 2.1500096917152405

Epoch: 6| Step: 12
Training loss: 1.8062278032302856
Validation loss: 2.179568648338318

Epoch: 6| Step: 13
Training loss: 1.0782136917114258
Validation loss: 2.1981670459111533

Epoch: 145| Step: 0
Training loss: 1.7568050622940063
Validation loss: 2.186332583427429

Epoch: 6| Step: 1
Training loss: 1.3900023698806763
Validation loss: 2.1594556172688804

Epoch: 6| Step: 2
Training loss: 1.2796283960342407
Validation loss: 2.1729671359062195

Epoch: 6| Step: 3
Training loss: 1.537980318069458
Validation loss: 2.1613433957099915

Epoch: 6| Step: 4
Training loss: 1.868560552597046
Validation loss: 2.1684379975001016

Epoch: 6| Step: 5
Training loss: 1.9385335445404053
Validation loss: 2.0982341170310974

Epoch: 6| Step: 6
Training loss: 1.4060873985290527
Validation loss: 2.0627208749453225

Epoch: 6| Step: 7
Training loss: 1.5675067901611328
Validation loss: 2.1400882999102273

Epoch: 6| Step: 8
Training loss: 1.1903102397918701
Validation loss: 2.1381887594858804

Epoch: 6| Step: 9
Training loss: 1.6326394081115723
Validation loss: 2.122148553530375

Epoch: 6| Step: 10
Training loss: 1.5904107093811035
Validation loss: 2.1346518198649087

Epoch: 6| Step: 11
Training loss: 0.6606457233428955
Validation loss: 2.064605255921682

Epoch: 6| Step: 12
Training loss: 1.226292371749878
Validation loss: 2.14309561252594

Epoch: 6| Step: 13
Training loss: 0.9835085272789001
Validation loss: 2.1419186194737754

Epoch: 146| Step: 0
Training loss: 1.5986591577529907
Validation loss: 2.1292499701182046

Epoch: 6| Step: 1
Training loss: 1.0674247741699219
Validation loss: 2.1438259283701577

Epoch: 6| Step: 2
Training loss: 1.7528711557388306
Validation loss: 2.174570143222809

Epoch: 6| Step: 3
Training loss: 1.287301778793335
Validation loss: 2.182433525721232

Epoch: 6| Step: 4
Training loss: 1.3226540088653564
Validation loss: 2.1150431831677756

Epoch: 6| Step: 5
Training loss: 1.9971959590911865
Validation loss: 2.1037056843439736

Epoch: 6| Step: 6
Training loss: 1.6463000774383545
Validation loss: 2.1083014210065207

Epoch: 6| Step: 7
Training loss: 1.3216456174850464
Validation loss: 2.162979086240133

Epoch: 6| Step: 8
Training loss: 1.7461676597595215
Validation loss: 2.1548360188802085

Epoch: 6| Step: 9
Training loss: 1.328033685684204
Validation loss: 2.1016547481218972

Epoch: 6| Step: 10
Training loss: 1.032318353652954
Validation loss: 2.1226526498794556

Epoch: 6| Step: 11
Training loss: 1.2903690338134766
Validation loss: 2.1308815280596414

Epoch: 6| Step: 12
Training loss: 1.4349806308746338
Validation loss: 2.101104438304901

Epoch: 6| Step: 13
Training loss: 1.3640711307525635
Validation loss: 2.1581769982973733

Epoch: 147| Step: 0
Training loss: 1.2142069339752197
Validation loss: 2.1142645478248596

Epoch: 6| Step: 1
Training loss: 1.3990488052368164
Validation loss: 2.0951701005299888

Epoch: 6| Step: 2
Training loss: 1.0581475496292114
Validation loss: 2.110390365123749

Epoch: 6| Step: 3
Training loss: 1.2763361930847168
Validation loss: 2.1115175088246665

Epoch: 6| Step: 4
Training loss: 1.5912353992462158
Validation loss: 2.1467812061309814

Epoch: 6| Step: 5
Training loss: 2.0087294578552246
Validation loss: 2.1367396910985312

Epoch: 6| Step: 6
Training loss: 1.6767780780792236
Validation loss: 2.1345293521881104

Epoch: 6| Step: 7
Training loss: 2.186448335647583
Validation loss: 2.103513777256012

Epoch: 6| Step: 8
Training loss: 1.1500442028045654
Validation loss: 2.155766944090525

Epoch: 6| Step: 9
Training loss: 1.1746935844421387
Validation loss: 2.09138560295105

Epoch: 6| Step: 10
Training loss: 1.6837704181671143
Validation loss: 2.1315460801124573

Epoch: 6| Step: 11
Training loss: 1.0597765445709229
Validation loss: 2.1155927181243896

Epoch: 6| Step: 12
Training loss: 1.1154687404632568
Validation loss: 2.1324743032455444

Epoch: 6| Step: 13
Training loss: 1.1846601963043213
Validation loss: 2.111125429471334

Epoch: 148| Step: 0
Training loss: 1.3877837657928467
Validation loss: 2.145656724770864

Epoch: 6| Step: 1
Training loss: 1.1562247276306152
Validation loss: 2.125197450319926

Epoch: 6| Step: 2
Training loss: 1.4880090951919556
Validation loss: 2.163127303123474

Epoch: 6| Step: 3
Training loss: 1.3622922897338867
Validation loss: 2.112515131632487

Epoch: 6| Step: 4
Training loss: 1.9498554468154907
Validation loss: 2.215399384498596

Epoch: 6| Step: 5
Training loss: 1.672016978263855
Validation loss: 2.236428419748942

Epoch: 6| Step: 6
Training loss: 1.6189426183700562
Validation loss: 2.157563308874766

Epoch: 6| Step: 7
Training loss: 1.1271612644195557
Validation loss: 2.166605591773987

Epoch: 6| Step: 8
Training loss: 1.1822845935821533
Validation loss: 2.1709722876548767

Epoch: 6| Step: 9
Training loss: 1.2173805236816406
Validation loss: 2.1422393719355264

Epoch: 6| Step: 10
Training loss: 1.32707941532135
Validation loss: 2.182384272416433

Epoch: 6| Step: 11
Training loss: 1.429174542427063
Validation loss: 2.183168053627014

Epoch: 6| Step: 12
Training loss: 1.2825840711593628
Validation loss: 2.1166215340296426

Epoch: 6| Step: 13
Training loss: 1.3469035625457764
Validation loss: 2.0769471526145935

Epoch: 149| Step: 0
Training loss: 1.1826399564743042
Validation loss: 2.112671196460724

Epoch: 6| Step: 1
Training loss: 1.769115924835205
Validation loss: 2.109136382738749

Epoch: 6| Step: 2
Training loss: 1.7914389371871948
Validation loss: 2.132577657699585

Epoch: 6| Step: 3
Training loss: 1.8881072998046875
Validation loss: 2.107937673727671

Epoch: 6| Step: 4
Training loss: 1.0609238147735596
Validation loss: 2.0850133895874023

Epoch: 6| Step: 5
Training loss: 0.7972647547721863
Validation loss: 2.130398154258728

Epoch: 6| Step: 6
Training loss: 1.2054293155670166
Validation loss: 2.122971455256144

Epoch: 6| Step: 7
Training loss: 1.236976146697998
Validation loss: 2.135586420694987

Epoch: 6| Step: 8
Training loss: 1.4894919395446777
Validation loss: 2.1398713986078897

Epoch: 6| Step: 9
Training loss: 1.224915623664856
Validation loss: 2.108284612496694

Epoch: 6| Step: 10
Training loss: 1.5070292949676514
Validation loss: 2.1747520367304483

Epoch: 6| Step: 11
Training loss: 1.732482671737671
Validation loss: 2.1787455479303994

Epoch: 6| Step: 12
Training loss: 1.4723560810089111
Validation loss: 2.1413768529891968

Epoch: 6| Step: 13
Training loss: 1.6268126964569092
Validation loss: 2.119902233282725

Epoch: 150| Step: 0
Training loss: 1.0448088645935059
Validation loss: 2.1150135000546775

Epoch: 6| Step: 1
Training loss: 1.6103260517120361
Validation loss: 2.1300847133000693

Epoch: 6| Step: 2
Training loss: 1.3543341159820557
Validation loss: 2.1235604286193848

Epoch: 6| Step: 3
Training loss: 1.7015843391418457
Validation loss: 2.0997968713442483

Epoch: 6| Step: 4
Training loss: 1.0346310138702393
Validation loss: 2.096088627974192

Epoch: 6| Step: 5
Training loss: 1.912746548652649
Validation loss: 2.1328998605410256

Epoch: 6| Step: 6
Training loss: 1.6633784770965576
Validation loss: 2.0969985127449036

Epoch: 6| Step: 7
Training loss: 0.7364598512649536
Validation loss: 2.1135924657185874

Epoch: 6| Step: 8
Training loss: 1.5835981369018555
Validation loss: 2.1312661369641623

Epoch: 6| Step: 9
Training loss: 1.1102614402770996
Validation loss: 2.1690611243247986

Epoch: 6| Step: 10
Training loss: 0.7942668199539185
Validation loss: 2.117025593916575

Epoch: 6| Step: 11
Training loss: 1.243454098701477
Validation loss: 2.1113401055336

Epoch: 6| Step: 12
Training loss: 1.6671371459960938
Validation loss: 2.0806427796681723

Epoch: 6| Step: 13
Training loss: 1.3930021524429321
Validation loss: 2.100974520047506

Epoch: 151| Step: 0
Training loss: 1.2722187042236328
Validation loss: 2.0667054255803428

Epoch: 6| Step: 1
Training loss: 1.454516887664795
Validation loss: 2.131347974141439

Epoch: 6| Step: 2
Training loss: 1.8040685653686523
Validation loss: 2.1409289042154946

Epoch: 6| Step: 3
Training loss: 0.6044923663139343
Validation loss: 2.1192397276560464

Epoch: 6| Step: 4
Training loss: 1.0246907472610474
Validation loss: 2.1030770738919577

Epoch: 6| Step: 5
Training loss: 0.8947193026542664
Validation loss: 2.0800070762634277

Epoch: 6| Step: 6
Training loss: 1.3023014068603516
Validation loss: 2.1563576459884644

Epoch: 6| Step: 7
Training loss: 1.2743799686431885
Validation loss: 2.1124496857325235

Epoch: 6| Step: 8
Training loss: 1.386727213859558
Validation loss: 2.162021577358246

Epoch: 6| Step: 9
Training loss: 1.7357614040374756
Validation loss: 2.1630388299624124

Epoch: 6| Step: 10
Training loss: 1.5506794452667236
Validation loss: 2.1442617376645408

Epoch: 6| Step: 11
Training loss: 1.83523690700531
Validation loss: 2.119206190109253

Epoch: 6| Step: 12
Training loss: 1.2048428058624268
Validation loss: 2.1051467855771384

Epoch: 6| Step: 13
Training loss: 1.9452928304672241
Validation loss: 2.15465517838796

Epoch: 152| Step: 0
Training loss: 1.493283748626709
Validation loss: 2.089403490225474

Epoch: 6| Step: 1
Training loss: 1.1118977069854736
Validation loss: 2.1113667488098145

Epoch: 6| Step: 2
Training loss: 1.4471020698547363
Validation loss: 2.105467935403188

Epoch: 6| Step: 3
Training loss: 1.2170660495758057
Validation loss: 2.0615633924802146

Epoch: 6| Step: 4
Training loss: 1.456647276878357
Validation loss: 2.0883684953053794

Epoch: 6| Step: 5
Training loss: 1.3720252513885498
Validation loss: 2.1046544710795083

Epoch: 6| Step: 6
Training loss: 2.0398316383361816
Validation loss: 2.11763467391332

Epoch: 6| Step: 7
Training loss: 1.3614163398742676
Validation loss: 2.094441076119741

Epoch: 6| Step: 8
Training loss: 1.0466639995574951
Validation loss: 2.1225799322128296

Epoch: 6| Step: 9
Training loss: 0.8262324333190918
Validation loss: 2.179775337378184

Epoch: 6| Step: 10
Training loss: 0.9485588669776917
Validation loss: 2.1113646229108176

Epoch: 6| Step: 11
Training loss: 1.3032240867614746
Validation loss: 2.13661128282547

Epoch: 6| Step: 12
Training loss: 2.151360273361206
Validation loss: 2.1269737482070923

Epoch: 6| Step: 13
Training loss: 1.0820881128311157
Validation loss: 2.105559786160787

Epoch: 153| Step: 0
Training loss: 1.8607579469680786
Validation loss: 2.142916719118754

Epoch: 6| Step: 1
Training loss: 1.2982616424560547
Validation loss: 2.0940747261047363

Epoch: 6| Step: 2
Training loss: 0.9823649525642395
Validation loss: 2.131857434908549

Epoch: 6| Step: 3
Training loss: 1.2118171453475952
Validation loss: 2.079515834649404

Epoch: 6| Step: 4
Training loss: 1.419116735458374
Validation loss: 2.1116997400919595

Epoch: 6| Step: 5
Training loss: 1.7266210317611694
Validation loss: 2.1049880981445312

Epoch: 6| Step: 6
Training loss: 0.9808757305145264
Validation loss: 2.1088695327440896

Epoch: 6| Step: 7
Training loss: 1.1869791746139526
Validation loss: 2.1368879874547324

Epoch: 6| Step: 8
Training loss: 1.2444465160369873
Validation loss: 2.1274808843930564

Epoch: 6| Step: 9
Training loss: 2.194974422454834
Validation loss: 2.1455023487408957

Epoch: 6| Step: 10
Training loss: 1.0292086601257324
Validation loss: 2.1483192245165506

Epoch: 6| Step: 11
Training loss: 1.2885453701019287
Validation loss: 2.105068882306417

Epoch: 6| Step: 12
Training loss: 1.3631129264831543
Validation loss: 2.0770208835601807

Epoch: 6| Step: 13
Training loss: 1.5223171710968018
Validation loss: 2.123846650123596

Epoch: 154| Step: 0
Training loss: 1.2562642097473145
Validation loss: 2.1022984981536865

Epoch: 6| Step: 1
Training loss: 1.1682626008987427
Validation loss: 2.1220940351486206

Epoch: 6| Step: 2
Training loss: 1.3006045818328857
Validation loss: 2.096332550048828

Epoch: 6| Step: 3
Training loss: 1.2827354669570923
Validation loss: 2.1222694913546243

Epoch: 6| Step: 4
Training loss: 1.4576644897460938
Validation loss: 2.108138064543406

Epoch: 6| Step: 5
Training loss: 1.0245656967163086
Validation loss: 2.1392140984535217

Epoch: 6| Step: 6
Training loss: 1.5545873641967773
Validation loss: 2.1656535267829895

Epoch: 6| Step: 7
Training loss: 1.6029062271118164
Validation loss: 2.154186209042867

Epoch: 6| Step: 8
Training loss: 1.0199923515319824
Validation loss: 2.214562197526296

Epoch: 6| Step: 9
Training loss: 1.2961050271987915
Validation loss: 2.2005550265312195

Epoch: 6| Step: 10
Training loss: 1.180285930633545
Validation loss: 2.123912215232849

Epoch: 6| Step: 11
Training loss: 1.99436616897583
Validation loss: 2.1252230207125344

Epoch: 6| Step: 12
Training loss: 1.624223232269287
Validation loss: 2.2002156376838684

Epoch: 6| Step: 13
Training loss: 1.178693413734436
Validation loss: 2.1094711820284524

Epoch: 155| Step: 0
Training loss: 1.638411045074463
Validation loss: 2.0741936365763345

Epoch: 6| Step: 1
Training loss: 1.2500263452529907
Validation loss: 2.1189415057500205

Epoch: 6| Step: 2
Training loss: 0.756351888179779
Validation loss: 2.141256550947825

Epoch: 6| Step: 3
Training loss: 1.589111089706421
Validation loss: 2.1102237502733865

Epoch: 6| Step: 4
Training loss: 1.3214030265808105
Validation loss: 2.1527424653371177

Epoch: 6| Step: 5
Training loss: 0.8993443250656128
Validation loss: 2.094330390294393

Epoch: 6| Step: 6
Training loss: 1.3214455842971802
Validation loss: 2.103524068991343

Epoch: 6| Step: 7
Training loss: 0.9897609353065491
Validation loss: 2.1673806508382163

Epoch: 6| Step: 8
Training loss: 1.6109163761138916
Validation loss: 2.1105872988700867

Epoch: 6| Step: 9
Training loss: 1.0758755207061768
Validation loss: 2.1515443325042725

Epoch: 6| Step: 10
Training loss: 1.9890313148498535
Validation loss: 2.1274786591529846

Epoch: 6| Step: 11
Training loss: 1.3537509441375732
Validation loss: 2.09871244430542

Epoch: 6| Step: 12
Training loss: 1.4382010698318481
Validation loss: 2.1433361967404685

Epoch: 6| Step: 13
Training loss: 1.4748152494430542
Validation loss: 2.122278372446696

Epoch: 156| Step: 0
Training loss: 1.1710177659988403
Validation loss: 2.1543560226758323

Epoch: 6| Step: 1
Training loss: 1.2160348892211914
Validation loss: 2.1635968883832297

Epoch: 6| Step: 2
Training loss: 1.9231057167053223
Validation loss: 2.138884405295054

Epoch: 6| Step: 3
Training loss: 1.0346455574035645
Validation loss: 2.1582040389378867

Epoch: 6| Step: 4
Training loss: 1.2685699462890625
Validation loss: 2.122827708721161

Epoch: 6| Step: 5
Training loss: 1.286696434020996
Validation loss: 2.1591124733289084

Epoch: 6| Step: 6
Training loss: 1.4328523874282837
Validation loss: 2.097247322400411

Epoch: 6| Step: 7
Training loss: 1.1998142004013062
Validation loss: 2.109130342801412

Epoch: 6| Step: 8
Training loss: 1.5474826097488403
Validation loss: 2.136424640814463

Epoch: 6| Step: 9
Training loss: 0.6961739659309387
Validation loss: 2.0953112840652466

Epoch: 6| Step: 10
Training loss: 1.4970296621322632
Validation loss: 2.1699456572532654

Epoch: 6| Step: 11
Training loss: 1.2792060375213623
Validation loss: 2.1925989985466003

Epoch: 6| Step: 12
Training loss: 1.2891027927398682
Validation loss: 2.14676433801651

Epoch: 6| Step: 13
Training loss: 1.6382694244384766
Validation loss: 2.1467973391215005

Epoch: 157| Step: 0
Training loss: 1.3056774139404297
Validation loss: 2.155413190523783

Epoch: 6| Step: 1
Training loss: 0.9075988531112671
Validation loss: 2.148052235444387

Epoch: 6| Step: 2
Training loss: 1.5205559730529785
Validation loss: 2.0947686036427817

Epoch: 6| Step: 3
Training loss: 1.1461502313613892
Validation loss: 2.1211119492848716

Epoch: 6| Step: 4
Training loss: 1.5358587503433228
Validation loss: 2.1027854879697165

Epoch: 6| Step: 5
Training loss: 1.604384183883667
Validation loss: 2.106934070587158

Epoch: 6| Step: 6
Training loss: 1.221709132194519
Validation loss: 2.099112252394358

Epoch: 6| Step: 7
Training loss: 1.3732109069824219
Validation loss: 2.1019585927327475

Epoch: 6| Step: 8
Training loss: 1.8437469005584717
Validation loss: 2.1018601258595786

Epoch: 6| Step: 9
Training loss: 1.0888420343399048
Validation loss: 2.0686551133791604

Epoch: 6| Step: 10
Training loss: 1.083742380142212
Validation loss: 2.1064474980036416

Epoch: 6| Step: 11
Training loss: 1.5399951934814453
Validation loss: 2.0803889830907187

Epoch: 6| Step: 12
Training loss: 1.1340761184692383
Validation loss: 2.164897700150808

Epoch: 6| Step: 13
Training loss: 0.9029605388641357
Validation loss: 2.144416650136312

Epoch: 158| Step: 0
Training loss: 1.2911266088485718
Validation loss: 2.2092780073483786

Epoch: 6| Step: 1
Training loss: 1.3264873027801514
Validation loss: 2.233725825945536

Epoch: 6| Step: 2
Training loss: 1.5407196283340454
Validation loss: 2.288663844267527

Epoch: 6| Step: 3
Training loss: 0.9374169111251831
Validation loss: 2.224243481953939

Epoch: 6| Step: 4
Training loss: 1.5096055269241333
Validation loss: 2.1445518930753074

Epoch: 6| Step: 5
Training loss: 1.537324070930481
Validation loss: 2.135827978452047

Epoch: 6| Step: 6
Training loss: 1.2012126445770264
Validation loss: 2.1356314023335776

Epoch: 6| Step: 7
Training loss: 1.245086431503296
Validation loss: 2.0970075130462646

Epoch: 6| Step: 8
Training loss: 1.0920064449310303
Validation loss: 2.102281610171

Epoch: 6| Step: 9
Training loss: 1.5357677936553955
Validation loss: 2.0829575061798096

Epoch: 6| Step: 10
Training loss: 1.2797986268997192
Validation loss: 2.12940780321757

Epoch: 6| Step: 11
Training loss: 1.5908012390136719
Validation loss: 2.0789852142333984

Epoch: 6| Step: 12
Training loss: 1.0481892824172974
Validation loss: 2.0923727552096048

Epoch: 6| Step: 13
Training loss: 1.6967079639434814
Validation loss: 2.1300514737764993

Epoch: 159| Step: 0
Training loss: 1.611432433128357
Validation loss: 2.1452632745107016

Epoch: 6| Step: 1
Training loss: 1.3400537967681885
Validation loss: 2.150297780831655

Epoch: 6| Step: 2
Training loss: 1.5471144914627075
Validation loss: 2.2183937629063926

Epoch: 6| Step: 3
Training loss: 0.9491105675697327
Validation loss: 2.1747867266337075

Epoch: 6| Step: 4
Training loss: 0.8938493728637695
Validation loss: 2.1995734373728433

Epoch: 6| Step: 5
Training loss: 1.4306695461273193
Validation loss: 2.135026474793752

Epoch: 6| Step: 6
Training loss: 1.1723679304122925
Validation loss: 2.2190617322921753

Epoch: 6| Step: 7
Training loss: 1.7720847129821777
Validation loss: 2.1782113313674927

Epoch: 6| Step: 8
Training loss: 1.1806482076644897
Validation loss: 2.116861899693807

Epoch: 6| Step: 9
Training loss: 0.8635642528533936
Validation loss: 2.098333259423574

Epoch: 6| Step: 10
Training loss: 1.6181995868682861
Validation loss: 2.141881744066874

Epoch: 6| Step: 11
Training loss: 1.3245304822921753
Validation loss: 2.1679192582766214

Epoch: 6| Step: 12
Training loss: 1.5929274559020996
Validation loss: 2.090179761250814

Epoch: 6| Step: 13
Training loss: 1.3218327760696411
Validation loss: 2.084338108698527

Epoch: 160| Step: 0
Training loss: 1.4343969821929932
Validation loss: 2.1320058504740396

Epoch: 6| Step: 1
Training loss: 0.8912071585655212
Validation loss: 2.1027672489484153

Epoch: 6| Step: 2
Training loss: 1.5019222497940063
Validation loss: 2.1046806971232095

Epoch: 6| Step: 3
Training loss: 1.7002677917480469
Validation loss: 2.1451900800069175

Epoch: 6| Step: 4
Training loss: 1.4175848960876465
Validation loss: 2.1027355194091797

Epoch: 6| Step: 5
Training loss: 0.9305424094200134
Validation loss: 2.163357456525167

Epoch: 6| Step: 6
Training loss: 1.1676201820373535
Validation loss: 2.117959717909495

Epoch: 6| Step: 7
Training loss: 0.8691083192825317
Validation loss: 2.155636727809906

Epoch: 6| Step: 8
Training loss: 2.1360177993774414
Validation loss: 2.131632606188456

Epoch: 6| Step: 9
Training loss: 0.9016443490982056
Validation loss: 2.1546539068222046

Epoch: 6| Step: 10
Training loss: 1.22492253780365
Validation loss: 2.157970647017161

Epoch: 6| Step: 11
Training loss: 1.411402940750122
Validation loss: 2.1597707668940225

Epoch: 6| Step: 12
Training loss: 1.3891481161117554
Validation loss: 2.138957381248474

Epoch: 6| Step: 13
Training loss: 1.1945985555648804
Validation loss: 2.1468677520751953

Epoch: 161| Step: 0
Training loss: 0.9499722719192505
Validation loss: 2.1576369603474936

Epoch: 6| Step: 1
Training loss: 1.509342908859253
Validation loss: 2.1518728534380593

Epoch: 6| Step: 2
Training loss: 1.0917762517929077
Validation loss: 2.1208354433377585

Epoch: 6| Step: 3
Training loss: 1.0740253925323486
Validation loss: 2.0699857076009116

Epoch: 6| Step: 4
Training loss: 1.0632904767990112
Validation loss: 2.108042041460673

Epoch: 6| Step: 5
Training loss: 0.9809784889221191
Validation loss: 2.139792184034983

Epoch: 6| Step: 6
Training loss: 1.1225254535675049
Validation loss: 2.195641497770945

Epoch: 6| Step: 7
Training loss: 1.647653341293335
Validation loss: 2.1542320052782693

Epoch: 6| Step: 8
Training loss: 1.065612554550171
Validation loss: 2.1994556983311973

Epoch: 6| Step: 9
Training loss: 1.7357481718063354
Validation loss: 2.1987368861834207

Epoch: 6| Step: 10
Training loss: 1.0277553796768188
Validation loss: 2.1641379793485007

Epoch: 6| Step: 11
Training loss: 1.3873573541641235
Validation loss: 2.1144770781199136

Epoch: 6| Step: 12
Training loss: 1.7520774602890015
Validation loss: 2.098028381665548

Epoch: 6| Step: 13
Training loss: 1.4015932083129883
Validation loss: 2.072235385576884

Epoch: 162| Step: 0
Training loss: 1.6074756383895874
Validation loss: 2.1277884046236673

Epoch: 6| Step: 1
Training loss: 0.8230279684066772
Validation loss: 2.120472510655721

Epoch: 6| Step: 2
Training loss: 1.3946630954742432
Validation loss: 2.084928552309672

Epoch: 6| Step: 3
Training loss: 0.9540826678276062
Validation loss: 2.098189095656077

Epoch: 6| Step: 4
Training loss: 1.9120080471038818
Validation loss: 2.1064623395601907

Epoch: 6| Step: 5
Training loss: 1.1015909910202026
Validation loss: 2.1376028259595237

Epoch: 6| Step: 6
Training loss: 1.0689948797225952
Validation loss: 2.1153551141421

Epoch: 6| Step: 7
Training loss: 1.3143911361694336
Validation loss: 2.141176422437032

Epoch: 6| Step: 8
Training loss: 1.2974343299865723
Validation loss: 2.128852923711141

Epoch: 6| Step: 9
Training loss: 1.3123903274536133
Validation loss: 2.159533977508545

Epoch: 6| Step: 10
Training loss: 1.5406544208526611
Validation loss: 2.1533910433451333

Epoch: 6| Step: 11
Training loss: 0.7604856491088867
Validation loss: 2.165876587231954

Epoch: 6| Step: 12
Training loss: 1.8170677423477173
Validation loss: 2.117806375026703

Epoch: 6| Step: 13
Training loss: 1.2995874881744385
Validation loss: 2.073707640171051

Epoch: 163| Step: 0
Training loss: 1.1129189729690552
Validation loss: 2.1126810908317566

Epoch: 6| Step: 1
Training loss: 1.6224502325057983
Validation loss: 2.1119619409243264

Epoch: 6| Step: 2
Training loss: 1.2774038314819336
Validation loss: 2.093081255753835

Epoch: 6| Step: 3
Training loss: 1.4584193229675293
Validation loss: 2.089381456375122

Epoch: 6| Step: 4
Training loss: 1.292870283126831
Validation loss: 2.1044973929723105

Epoch: 6| Step: 5
Training loss: 1.4201080799102783
Validation loss: 2.121443788210551

Epoch: 6| Step: 6
Training loss: 1.0776162147521973
Validation loss: 2.1346829334894815

Epoch: 6| Step: 7
Training loss: 1.1069650650024414
Validation loss: 2.1254937648773193

Epoch: 6| Step: 8
Training loss: 1.2030632495880127
Validation loss: 2.098533829053243

Epoch: 6| Step: 9
Training loss: 1.0082623958587646
Validation loss: 2.154342830181122

Epoch: 6| Step: 10
Training loss: 0.9077123999595642
Validation loss: 2.2240227858225503

Epoch: 6| Step: 11
Training loss: 1.1770663261413574
Validation loss: 2.1608463327089944

Epoch: 6| Step: 12
Training loss: 1.4273815155029297
Validation loss: 2.1165852546691895

Epoch: 6| Step: 13
Training loss: 1.5639781951904297
Validation loss: 2.1074813405672708

Epoch: 164| Step: 0
Training loss: 1.2244659662246704
Validation loss: 2.103456219037374

Epoch: 6| Step: 1
Training loss: 1.4017276763916016
Validation loss: 2.099884827931722

Epoch: 6| Step: 2
Training loss: 0.9895843863487244
Validation loss: 2.1072030266126

Epoch: 6| Step: 3
Training loss: 1.099718689918518
Validation loss: 2.1339370012283325

Epoch: 6| Step: 4
Training loss: 1.6246323585510254
Validation loss: 2.0867318709691367

Epoch: 6| Step: 5
Training loss: 1.8120050430297852
Validation loss: 2.0859512090682983

Epoch: 6| Step: 6
Training loss: 1.2861175537109375
Validation loss: 2.0936784148216248

Epoch: 6| Step: 7
Training loss: 1.6476590633392334
Validation loss: 2.0973418156305947

Epoch: 6| Step: 8
Training loss: 1.3731095790863037
Validation loss: 2.1438785791397095

Epoch: 6| Step: 9
Training loss: 1.2992390394210815
Validation loss: 2.1031784812609353

Epoch: 6| Step: 10
Training loss: 0.920245885848999
Validation loss: 2.1366942127545676

Epoch: 6| Step: 11
Training loss: 0.7234311103820801
Validation loss: 2.0800923109054565

Epoch: 6| Step: 12
Training loss: 0.983365535736084
Validation loss: 2.1365952491760254

Epoch: 6| Step: 13
Training loss: 1.315659761428833
Validation loss: 2.152760624885559

Epoch: 165| Step: 0
Training loss: 1.6312618255615234
Validation loss: 2.117506523927053

Epoch: 6| Step: 1
Training loss: 1.1785531044006348
Validation loss: 2.068341871102651

Epoch: 6| Step: 2
Training loss: 1.0888041257858276
Validation loss: 2.076637089252472

Epoch: 6| Step: 3
Training loss: 1.302673578262329
Validation loss: 2.0744051337242126

Epoch: 6| Step: 4
Training loss: 1.121427297592163
Validation loss: 2.14820130666097

Epoch: 6| Step: 5
Training loss: 0.8691083192825317
Validation loss: 2.12226939201355

Epoch: 6| Step: 6
Training loss: 1.3682868480682373
Validation loss: 2.0725031097730002

Epoch: 6| Step: 7
Training loss: 1.1764271259307861
Validation loss: 2.120794872442881

Epoch: 6| Step: 8
Training loss: 1.4212087392807007
Validation loss: 2.102987229824066

Epoch: 6| Step: 9
Training loss: 0.7225221395492554
Validation loss: 2.1476293802261353

Epoch: 6| Step: 10
Training loss: 1.28938627243042
Validation loss: 2.1886633038520813

Epoch: 6| Step: 11
Training loss: 1.3222335577011108
Validation loss: 2.1985164880752563

Epoch: 6| Step: 12
Training loss: 1.929405689239502
Validation loss: 2.252745429674784

Epoch: 6| Step: 13
Training loss: 1.5330724716186523
Validation loss: 2.292051076889038

Epoch: 166| Step: 0
Training loss: 1.6679342985153198
Validation loss: 2.20023383696874

Epoch: 6| Step: 1
Training loss: 1.000497579574585
Validation loss: 2.1403902967770896

Epoch: 6| Step: 2
Training loss: 1.5679446458816528
Validation loss: 2.1463998357454934

Epoch: 6| Step: 3
Training loss: 1.1550261974334717
Validation loss: 2.098893642425537

Epoch: 6| Step: 4
Training loss: 0.8822435736656189
Validation loss: 2.101583421230316

Epoch: 6| Step: 5
Training loss: 0.9962286949157715
Validation loss: 2.0503053069114685

Epoch: 6| Step: 6
Training loss: 0.9384293556213379
Validation loss: 2.1337735255559287

Epoch: 6| Step: 7
Training loss: 1.389740228652954
Validation loss: 2.0539954702059426

Epoch: 6| Step: 8
Training loss: 1.371762990951538
Validation loss: 2.066497802734375

Epoch: 6| Step: 9
Training loss: 1.7677109241485596
Validation loss: 2.1066842873891196

Epoch: 6| Step: 10
Training loss: 1.2979178428649902
Validation loss: 2.1033005714416504

Epoch: 6| Step: 11
Training loss: 1.4411509037017822
Validation loss: 2.1005038022994995

Epoch: 6| Step: 12
Training loss: 0.7638969421386719
Validation loss: 2.197789470354716

Epoch: 6| Step: 13
Training loss: 1.2317841053009033
Validation loss: 2.1240649620691934

Epoch: 167| Step: 0
Training loss: 1.3215641975402832
Validation loss: 2.210772156715393

Epoch: 6| Step: 1
Training loss: 1.4113328456878662
Validation loss: 2.160640815893809

Epoch: 6| Step: 2
Training loss: 0.921470046043396
Validation loss: 2.1683337489763894

Epoch: 6| Step: 3
Training loss: 0.8547621965408325
Validation loss: 2.1346036394437156

Epoch: 6| Step: 4
Training loss: 1.5184917449951172
Validation loss: 2.133383591969808

Epoch: 6| Step: 5
Training loss: 1.007859706878662
Validation loss: 2.16328759988149

Epoch: 6| Step: 6
Training loss: 1.2062342166900635
Validation loss: 2.1095495422681174

Epoch: 6| Step: 7
Training loss: 0.9924211502075195
Validation loss: 2.1043809254964194

Epoch: 6| Step: 8
Training loss: 0.7714420557022095
Validation loss: 2.0371015071868896

Epoch: 6| Step: 9
Training loss: 1.8075830936431885
Validation loss: 2.076668600241343

Epoch: 6| Step: 10
Training loss: 1.5380289554595947
Validation loss: 2.0730151732762656

Epoch: 6| Step: 11
Training loss: 1.054852843284607
Validation loss: 2.0850298404693604

Epoch: 6| Step: 12
Training loss: 1.5484263896942139
Validation loss: 2.0958057045936584

Epoch: 6| Step: 13
Training loss: 1.5008618831634521
Validation loss: 2.0391066869099936

Epoch: 168| Step: 0
Training loss: 1.6135014295578003
Validation loss: 2.0958332220713296

Epoch: 6| Step: 1
Training loss: 1.7934061288833618
Validation loss: 2.1250210801760354

Epoch: 6| Step: 2
Training loss: 1.137458324432373
Validation loss: 2.102848529815674

Epoch: 6| Step: 3
Training loss: 1.428013801574707
Validation loss: 2.0861990253130593

Epoch: 6| Step: 4
Training loss: 1.1132245063781738
Validation loss: 2.090526262919108

Epoch: 6| Step: 5
Training loss: 0.8690113425254822
Validation loss: 2.205354472001394

Epoch: 6| Step: 6
Training loss: 1.4275275468826294
Validation loss: 2.1565040349960327

Epoch: 6| Step: 7
Training loss: 0.9505397081375122
Validation loss: 2.182397504647573

Epoch: 6| Step: 8
Training loss: 1.3380506038665771
Validation loss: 2.1783075531323752

Epoch: 6| Step: 9
Training loss: 1.0484760999679565
Validation loss: 2.104447921117147

Epoch: 6| Step: 10
Training loss: 1.1836283206939697
Validation loss: 2.088448166847229

Epoch: 6| Step: 11
Training loss: 0.8647489547729492
Validation loss: 2.079988420009613

Epoch: 6| Step: 12
Training loss: 1.0335769653320312
Validation loss: 2.0973503788312278

Epoch: 6| Step: 13
Training loss: 1.6439330577850342
Validation loss: 2.142312208811442

Epoch: 169| Step: 0
Training loss: 1.6639323234558105
Validation loss: 2.1173111399014792

Epoch: 6| Step: 1
Training loss: 1.691194772720337
Validation loss: 2.158980985482534

Epoch: 6| Step: 2
Training loss: 0.9882209300994873
Validation loss: 2.108534872531891

Epoch: 6| Step: 3
Training loss: 1.221293568611145
Validation loss: 2.0904652873675027

Epoch: 6| Step: 4
Training loss: 0.9076588153839111
Validation loss: 2.1532668670018515

Epoch: 6| Step: 5
Training loss: 1.4328633546829224
Validation loss: 2.1176897088686624

Epoch: 6| Step: 6
Training loss: 1.0402777194976807
Validation loss: 2.1083205143610635

Epoch: 6| Step: 7
Training loss: 1.2111597061157227
Validation loss: 2.0920474926630654

Epoch: 6| Step: 8
Training loss: 1.4063005447387695
Validation loss: 2.2259332736333213

Epoch: 6| Step: 9
Training loss: 1.5422521829605103
Validation loss: 2.1884520848592124

Epoch: 6| Step: 10
Training loss: 1.1911299228668213
Validation loss: 2.2309881846110025

Epoch: 6| Step: 11
Training loss: 0.5919559001922607
Validation loss: 2.2061275641123452

Epoch: 6| Step: 12
Training loss: 1.0480151176452637
Validation loss: 2.1353920102119446

Epoch: 6| Step: 13
Training loss: 1.7763190269470215
Validation loss: 2.1134442488352456

Epoch: 170| Step: 0
Training loss: 0.6929102540016174
Validation loss: 2.1123612324396768

Epoch: 6| Step: 1
Training loss: 0.8565139770507812
Validation loss: 2.1358615954717

Epoch: 6| Step: 2
Training loss: 1.06240713596344
Validation loss: 2.1276519894599915

Epoch: 6| Step: 3
Training loss: 1.40382719039917
Validation loss: 2.1062808632850647

Epoch: 6| Step: 4
Training loss: 1.5712305307388306
Validation loss: 2.112996240456899

Epoch: 6| Step: 5
Training loss: 1.1875498294830322
Validation loss: 2.098899245262146

Epoch: 6| Step: 6
Training loss: 1.104736566543579
Validation loss: 2.0733847618103027

Epoch: 6| Step: 7
Training loss: 1.6622785329818726
Validation loss: 2.1428576906522117

Epoch: 6| Step: 8
Training loss: 0.8938157558441162
Validation loss: 2.103418548901876

Epoch: 6| Step: 9
Training loss: 1.44866943359375
Validation loss: 2.097774624824524

Epoch: 6| Step: 10
Training loss: 1.5237469673156738
Validation loss: 2.078737954298655

Epoch: 6| Step: 11
Training loss: 1.0887550115585327
Validation loss: 2.1343574126561484

Epoch: 6| Step: 12
Training loss: 1.1898627281188965
Validation loss: 2.105879763762156

Epoch: 6| Step: 13
Training loss: 0.9400705099105835
Validation loss: 2.2024566531181335

Epoch: 171| Step: 0
Training loss: 1.018042802810669
Validation loss: 2.2144495248794556

Epoch: 6| Step: 1
Training loss: 1.2621517181396484
Validation loss: 2.2292144695917764

Epoch: 6| Step: 2
Training loss: 1.4191980361938477
Validation loss: 2.2067196369171143

Epoch: 6| Step: 3
Training loss: 1.2948750257492065
Validation loss: 2.195431709289551

Epoch: 6| Step: 4
Training loss: 1.2661956548690796
Validation loss: 2.243231217066447

Epoch: 6| Step: 5
Training loss: 1.5290311574935913
Validation loss: 2.1940603852272034

Epoch: 6| Step: 6
Training loss: 0.965087890625
Validation loss: 2.1455915768941245

Epoch: 6| Step: 7
Training loss: 1.4611490964889526
Validation loss: 2.143938422203064

Epoch: 6| Step: 8
Training loss: 0.9767094254493713
Validation loss: 2.0994398991266885

Epoch: 6| Step: 9
Training loss: 1.1120229959487915
Validation loss: 2.148859182993571

Epoch: 6| Step: 10
Training loss: 1.3466709852218628
Validation loss: 2.105522394180298

Epoch: 6| Step: 11
Training loss: 1.1539002656936646
Validation loss: 2.1011385718981423

Epoch: 6| Step: 12
Training loss: 1.7614331245422363
Validation loss: 2.085250973701477

Epoch: 6| Step: 13
Training loss: 0.9944095611572266
Validation loss: 2.1400864322980246

Epoch: 172| Step: 0
Training loss: 1.3969244956970215
Validation loss: 2.160040855407715

Epoch: 6| Step: 1
Training loss: 1.448838472366333
Validation loss: 2.1905033191045127

Epoch: 6| Step: 2
Training loss: 1.366584062576294
Validation loss: 2.2436843713124595

Epoch: 6| Step: 3
Training loss: 1.444571614265442
Validation loss: 2.2336707711219788

Epoch: 6| Step: 4
Training loss: 1.3168914318084717
Validation loss: 2.2545727690060935

Epoch: 6| Step: 5
Training loss: 1.0876750946044922
Validation loss: 2.1332331895828247

Epoch: 6| Step: 6
Training loss: 1.0190311670303345
Validation loss: 2.11804207166036

Epoch: 6| Step: 7
Training loss: 0.6876589059829712
Validation loss: 2.119355400403341

Epoch: 6| Step: 8
Training loss: 1.65341317653656
Validation loss: 2.079622666041056

Epoch: 6| Step: 9
Training loss: 1.4575729370117188
Validation loss: 2.1286730766296387

Epoch: 6| Step: 10
Training loss: 1.2075409889221191
Validation loss: 2.1743581295013428

Epoch: 6| Step: 11
Training loss: 1.4948618412017822
Validation loss: 2.0927393039067588

Epoch: 6| Step: 12
Training loss: 1.3217802047729492
Validation loss: 2.0908671617507935

Epoch: 6| Step: 13
Training loss: 1.4361116886138916
Validation loss: 2.0953832268714905

Epoch: 173| Step: 0
Training loss: 1.3698115348815918
Validation loss: 2.135457376639048

Epoch: 6| Step: 1
Training loss: 0.975637674331665
Validation loss: 2.097336689631144

Epoch: 6| Step: 2
Training loss: 1.093498945236206
Validation loss: 2.1359447240829468

Epoch: 6| Step: 3
Training loss: 1.5905237197875977
Validation loss: 2.1760396162668862

Epoch: 6| Step: 4
Training loss: 1.1268469095230103
Validation loss: 2.2176218827565513

Epoch: 6| Step: 5
Training loss: 1.265724778175354
Validation loss: 2.2421048283576965

Epoch: 6| Step: 6
Training loss: 1.072596549987793
Validation loss: 2.2303220431009927

Epoch: 6| Step: 7
Training loss: 0.8708314895629883
Validation loss: 2.1526116132736206

Epoch: 6| Step: 8
Training loss: 2.030254602432251
Validation loss: 2.1452790896097818

Epoch: 6| Step: 9
Training loss: 1.2655173540115356
Validation loss: 2.0665054519971213

Epoch: 6| Step: 10
Training loss: 0.7424662113189697
Validation loss: 2.102258483568827

Epoch: 6| Step: 11
Training loss: 0.8195169568061829
Validation loss: 2.025483032067617

Epoch: 6| Step: 12
Training loss: 1.4086651802062988
Validation loss: 2.0244105060895285

Epoch: 6| Step: 13
Training loss: 1.3546311855316162
Validation loss: 2.135337213675181

Epoch: 174| Step: 0
Training loss: 1.3459899425506592
Validation loss: 2.0982224543889365

Epoch: 6| Step: 1
Training loss: 0.963381290435791
Validation loss: 2.0572360356648765

Epoch: 6| Step: 2
Training loss: 1.26865553855896
Validation loss: 2.1177209615707397

Epoch: 6| Step: 3
Training loss: 0.891649603843689
Validation loss: 2.116817275683085

Epoch: 6| Step: 4
Training loss: 0.9012671709060669
Validation loss: 2.1601178844769797

Epoch: 6| Step: 5
Training loss: 1.9507460594177246
Validation loss: 2.1484646002451577

Epoch: 6| Step: 6
Training loss: 1.6204705238342285
Validation loss: 2.222020069758097

Epoch: 6| Step: 7
Training loss: 1.3295247554779053
Validation loss: 2.1857467691103616

Epoch: 6| Step: 8
Training loss: 1.349745750427246
Validation loss: 2.185916225115458

Epoch: 6| Step: 9
Training loss: 1.0938878059387207
Validation loss: 2.2048338651657104

Epoch: 6| Step: 10
Training loss: 1.0026689767837524
Validation loss: 2.1518304546674094

Epoch: 6| Step: 11
Training loss: 0.784895658493042
Validation loss: 2.1226996183395386

Epoch: 6| Step: 12
Training loss: 1.168329119682312
Validation loss: 2.1277340054512024

Epoch: 6| Step: 13
Training loss: 0.7164297103881836
Validation loss: 2.1076428095499673

Epoch: 175| Step: 0
Training loss: 0.9561202526092529
Validation loss: 2.1455597480138144

Epoch: 6| Step: 1
Training loss: 0.8664418458938599
Validation loss: 2.115744670232137

Epoch: 6| Step: 2
Training loss: 1.2992737293243408
Validation loss: 2.0977167089780173

Epoch: 6| Step: 3
Training loss: 1.0600240230560303
Validation loss: 2.0812370975812278

Epoch: 6| Step: 4
Training loss: 0.8678792715072632
Validation loss: 2.1388461589813232

Epoch: 6| Step: 5
Training loss: 0.99365234375
Validation loss: 2.101646443208059

Epoch: 6| Step: 6
Training loss: 0.8982384204864502
Validation loss: 2.128955145676931

Epoch: 6| Step: 7
Training loss: 1.1486217975616455
Validation loss: 2.142699897289276

Epoch: 6| Step: 8
Training loss: 1.0453033447265625
Validation loss: 2.1554428736368814

Epoch: 6| Step: 9
Training loss: 1.7260792255401611
Validation loss: 2.1773305336634317

Epoch: 6| Step: 10
Training loss: 1.2944201231002808
Validation loss: 2.135717252890269

Epoch: 6| Step: 11
Training loss: 1.5698120594024658
Validation loss: 2.10424812634786

Epoch: 6| Step: 12
Training loss: 1.7285242080688477
Validation loss: 2.1038774649302163

Epoch: 6| Step: 13
Training loss: 1.3016166687011719
Validation loss: 2.1157529751459756

Epoch: 176| Step: 0
Training loss: 1.1016790866851807
Validation loss: 2.156494140625

Epoch: 6| Step: 1
Training loss: 1.1011972427368164
Validation loss: 2.0187750458717346

Epoch: 6| Step: 2
Training loss: 0.9181479215621948
Validation loss: 2.1309298276901245

Epoch: 6| Step: 3
Training loss: 1.3523759841918945
Validation loss: 2.116273562113444

Epoch: 6| Step: 4
Training loss: 0.9229536056518555
Validation loss: 2.1440623005231223

Epoch: 6| Step: 5
Training loss: 1.1297540664672852
Validation loss: 2.1747169295946756

Epoch: 6| Step: 6
Training loss: 1.3209593296051025
Validation loss: 2.203772803147634

Epoch: 6| Step: 7
Training loss: 1.5505356788635254
Validation loss: 2.225794772307078

Epoch: 6| Step: 8
Training loss: 1.074095606803894
Validation loss: 2.1244455575942993

Epoch: 6| Step: 9
Training loss: 1.203102707862854
Validation loss: 2.065530320008596

Epoch: 6| Step: 10
Training loss: 0.7387856245040894
Validation loss: 2.1196674903233848

Epoch: 6| Step: 11
Training loss: 1.3475326299667358
Validation loss: 2.137766718864441

Epoch: 6| Step: 12
Training loss: 1.0848324298858643
Validation loss: 2.098811467488607

Epoch: 6| Step: 13
Training loss: 1.2472745180130005
Validation loss: 2.151233971118927

Epoch: 177| Step: 0
Training loss: 0.7972644567489624
Validation loss: 2.1079487999280295

Epoch: 6| Step: 1
Training loss: 1.2018996477127075
Validation loss: 2.108054796854655

Epoch: 6| Step: 2
Training loss: 1.1880853176116943
Validation loss: 2.114377498626709

Epoch: 6| Step: 3
Training loss: 0.5704166889190674
Validation loss: 2.1463469664255777

Epoch: 6| Step: 4
Training loss: 1.1597299575805664
Validation loss: 2.111561596393585

Epoch: 6| Step: 5
Training loss: 1.3995561599731445
Validation loss: 2.1153031984965005

Epoch: 6| Step: 6
Training loss: 1.1762551069259644
Validation loss: 2.105105976263682

Epoch: 6| Step: 7
Training loss: 1.67617666721344
Validation loss: 2.1588792204856873

Epoch: 6| Step: 8
Training loss: 0.5152186751365662
Validation loss: 2.179052491982778

Epoch: 6| Step: 9
Training loss: 0.9282562136650085
Validation loss: 2.12373681863149

Epoch: 6| Step: 10
Training loss: 1.376765251159668
Validation loss: 2.103144407272339

Epoch: 6| Step: 11
Training loss: 1.0703723430633545
Validation loss: 2.1076815525690713

Epoch: 6| Step: 12
Training loss: 1.0445218086242676
Validation loss: 2.1171215375264487

Epoch: 6| Step: 13
Training loss: 1.5228554010391235
Validation loss: 2.077088197072347

Epoch: 178| Step: 0
Training loss: 1.0310810804367065
Validation loss: 2.1350152691205344

Epoch: 6| Step: 1
Training loss: 0.9570748805999756
Validation loss: 2.1343351205190024

Epoch: 6| Step: 2
Training loss: 1.0900168418884277
Validation loss: 2.0891106526056924

Epoch: 6| Step: 3
Training loss: 1.1000086069107056
Validation loss: 2.1089589595794678

Epoch: 6| Step: 4
Training loss: 0.6535910367965698
Validation loss: 2.1254894733428955

Epoch: 6| Step: 5
Training loss: 1.4448258876800537
Validation loss: 2.1582029859224954

Epoch: 6| Step: 6
Training loss: 1.2159308195114136
Validation loss: 2.134177049001058

Epoch: 6| Step: 7
Training loss: 1.3835970163345337
Validation loss: 2.1346563696861267

Epoch: 6| Step: 8
Training loss: 1.6266486644744873
Validation loss: 2.1573279897371926

Epoch: 6| Step: 9
Training loss: 1.1747844219207764
Validation loss: 2.1331327160199485

Epoch: 6| Step: 10
Training loss: 1.2150958776474
Validation loss: 2.1047463615735373

Epoch: 6| Step: 11
Training loss: 1.2810542583465576
Validation loss: 2.1547706524531045

Epoch: 6| Step: 12
Training loss: 1.0202580690383911
Validation loss: 2.1814294854799905

Epoch: 6| Step: 13
Training loss: 1.096296787261963
Validation loss: 2.1087437073389688

Epoch: 179| Step: 0
Training loss: 1.519451379776001
Validation loss: 2.0889488458633423

Epoch: 6| Step: 1
Training loss: 0.9356167316436768
Validation loss: 2.1506408055623374

Epoch: 6| Step: 2
Training loss: 0.9058910608291626
Validation loss: 2.1778687238693237

Epoch: 6| Step: 3
Training loss: 1.0918983221054077
Validation loss: 2.1360732316970825

Epoch: 6| Step: 4
Training loss: 0.9240800142288208
Validation loss: 2.1289892395337424

Epoch: 6| Step: 5
Training loss: 1.218855619430542
Validation loss: 2.181663473447164

Epoch: 6| Step: 6
Training loss: 1.0064109563827515
Validation loss: 2.1751888195673623

Epoch: 6| Step: 7
Training loss: 1.024794340133667
Validation loss: 2.133438766002655

Epoch: 6| Step: 8
Training loss: 0.9095609188079834
Validation loss: 2.1385786533355713

Epoch: 6| Step: 9
Training loss: 1.8824982643127441
Validation loss: 2.0962456663449607

Epoch: 6| Step: 10
Training loss: 1.058518409729004
Validation loss: 2.081621070702871

Epoch: 6| Step: 11
Training loss: 0.9769402742385864
Validation loss: 2.0790685216585794

Epoch: 6| Step: 12
Training loss: 1.1520339250564575
Validation loss: 2.097915748755137

Epoch: 6| Step: 13
Training loss: 1.6297321319580078
Validation loss: 2.064046263694763

Epoch: 180| Step: 0
Training loss: 1.74519944190979
Validation loss: 2.1411678393681846

Epoch: 6| Step: 1
Training loss: 1.3722691535949707
Validation loss: 2.1465662121772766

Epoch: 6| Step: 2
Training loss: 1.4242438077926636
Validation loss: 2.1674643556276956

Epoch: 6| Step: 3
Training loss: 0.7783491015434265
Validation loss: 2.1142829855283103

Epoch: 6| Step: 4
Training loss: 1.7525949478149414
Validation loss: 2.149897873401642

Epoch: 6| Step: 5
Training loss: 0.7217963933944702
Validation loss: 2.1085918148358664

Epoch: 6| Step: 6
Training loss: 0.8367562890052795
Validation loss: 2.059025287628174

Epoch: 6| Step: 7
Training loss: 0.8000680804252625
Validation loss: 2.1355722347895303

Epoch: 6| Step: 8
Training loss: 1.1821317672729492
Validation loss: 2.119016448656718

Epoch: 6| Step: 9
Training loss: 0.8809545040130615
Validation loss: 2.1658578316370645

Epoch: 6| Step: 10
Training loss: 1.1491392850875854
Validation loss: 2.1490179697672525

Epoch: 6| Step: 11
Training loss: 1.2578874826431274
Validation loss: 2.1766304175059

Epoch: 6| Step: 12
Training loss: 1.2664155960083008
Validation loss: 2.186928649743398

Epoch: 6| Step: 13
Training loss: 0.8222360610961914
Validation loss: 2.1678491036097207

Epoch: 181| Step: 0
Training loss: 0.5401174426078796
Validation loss: 2.090198298295339

Epoch: 6| Step: 1
Training loss: 1.17875075340271
Validation loss: 2.1283151110013327

Epoch: 6| Step: 2
Training loss: 0.8353636860847473
Validation loss: 2.094867984453837

Epoch: 6| Step: 3
Training loss: 1.102905511856079
Validation loss: 2.091224253177643

Epoch: 6| Step: 4
Training loss: 1.1900813579559326
Validation loss: 2.109363853931427

Epoch: 6| Step: 5
Training loss: 1.3170158863067627
Validation loss: 2.076592743396759

Epoch: 6| Step: 6
Training loss: 0.9660773873329163
Validation loss: 2.143235743045807

Epoch: 6| Step: 7
Training loss: 1.6970903873443604
Validation loss: 2.129946251710256

Epoch: 6| Step: 8
Training loss: 1.1174805164337158
Validation loss: 2.1220179398854575

Epoch: 6| Step: 9
Training loss: 1.4175822734832764
Validation loss: 2.1192322174708047

Epoch: 6| Step: 10
Training loss: 0.7676870822906494
Validation loss: 2.132376253604889

Epoch: 6| Step: 11
Training loss: 1.2118743658065796
Validation loss: 2.1401200890541077

Epoch: 6| Step: 12
Training loss: 0.9007816314697266
Validation loss: 2.1221386194229126

Epoch: 6| Step: 13
Training loss: 1.395370364189148
Validation loss: 2.1473228136698403

Epoch: 182| Step: 0
Training loss: 0.8693760633468628
Validation loss: 2.120037237803141

Epoch: 6| Step: 1
Training loss: 1.1406103372573853
Validation loss: 2.1397094329198203

Epoch: 6| Step: 2
Training loss: 1.210601568222046
Validation loss: 2.133719285329183

Epoch: 6| Step: 3
Training loss: 1.1210291385650635
Validation loss: 2.1739348570505777

Epoch: 6| Step: 4
Training loss: 0.9961369037628174
Validation loss: 2.112947702407837

Epoch: 6| Step: 5
Training loss: 1.2809982299804688
Validation loss: 2.113350967566172

Epoch: 6| Step: 6
Training loss: 1.081852912902832
Validation loss: 2.0645192662874856

Epoch: 6| Step: 7
Training loss: 1.248658537864685
Validation loss: 2.090565582116445

Epoch: 6| Step: 8
Training loss: 1.3905259370803833
Validation loss: 2.0779310862223306

Epoch: 6| Step: 9
Training loss: 0.38449180126190186
Validation loss: 2.079780717690786

Epoch: 6| Step: 10
Training loss: 1.077749252319336
Validation loss: 2.1365272998809814

Epoch: 6| Step: 11
Training loss: 1.4298455715179443
Validation loss: 2.16602752606074

Epoch: 6| Step: 12
Training loss: 1.1775397062301636
Validation loss: 2.1171659032503762

Epoch: 6| Step: 13
Training loss: 1.070342779159546
Validation loss: 2.2064388394355774

Epoch: 183| Step: 0
Training loss: 1.1795480251312256
Validation loss: 2.1250417629877725

Epoch: 6| Step: 1
Training loss: 0.9815734624862671
Validation loss: 2.105798383553823

Epoch: 6| Step: 2
Training loss: 1.3687002658843994
Validation loss: 2.078513264656067

Epoch: 6| Step: 3
Training loss: 1.3432395458221436
Validation loss: 2.139595707257589

Epoch: 6| Step: 4
Training loss: 1.467025876045227
Validation loss: 2.100330432256063

Epoch: 6| Step: 5
Training loss: 1.3663461208343506
Validation loss: 2.1086551348368325

Epoch: 6| Step: 6
Training loss: 1.2200486660003662
Validation loss: 2.1119473576545715

Epoch: 6| Step: 7
Training loss: 0.899498462677002
Validation loss: 2.082099179426829

Epoch: 6| Step: 8
Training loss: 1.0626975297927856
Validation loss: 2.0403321981430054

Epoch: 6| Step: 9
Training loss: 0.5550660490989685
Validation loss: 2.1749247511227927

Epoch: 6| Step: 10
Training loss: 0.6337469816207886
Validation loss: 2.1531166434288025

Epoch: 6| Step: 11
Training loss: 1.1893119812011719
Validation loss: 2.1291714708010354

Epoch: 6| Step: 12
Training loss: 1.276623249053955
Validation loss: 2.1786062518755593

Epoch: 6| Step: 13
Training loss: 0.9297960996627808
Validation loss: 2.211258371671041

Epoch: 184| Step: 0
Training loss: 0.5495172142982483
Validation loss: 2.144241154193878

Epoch: 6| Step: 1
Training loss: 1.2485946416854858
Validation loss: 2.1386577089627585

Epoch: 6| Step: 2
Training loss: 0.715638279914856
Validation loss: 2.126660148302714

Epoch: 6| Step: 3
Training loss: 0.5017038583755493
Validation loss: 2.147298057874044

Epoch: 6| Step: 4
Training loss: 1.2708854675292969
Validation loss: 2.0627425710360208

Epoch: 6| Step: 5
Training loss: 1.8552491664886475
Validation loss: 2.06258495648702

Epoch: 6| Step: 6
Training loss: 1.415930986404419
Validation loss: 2.1239153345425925

Epoch: 6| Step: 7
Training loss: 1.0238051414489746
Validation loss: 2.1120765606562295

Epoch: 6| Step: 8
Training loss: 1.5977755784988403
Validation loss: 2.101601302623749

Epoch: 6| Step: 9
Training loss: 0.9732583165168762
Validation loss: 2.100748360157013

Epoch: 6| Step: 10
Training loss: 1.2551169395446777
Validation loss: 2.1290271282196045

Epoch: 6| Step: 11
Training loss: 1.4054548740386963
Validation loss: 2.161648472150167

Epoch: 6| Step: 12
Training loss: 1.1921145915985107
Validation loss: 2.101139267285665

Epoch: 6| Step: 13
Training loss: 1.0976104736328125
Validation loss: 2.128057142098745

Epoch: 185| Step: 0
Training loss: 1.1255908012390137
Validation loss: 2.234613617261251

Epoch: 6| Step: 1
Training loss: 0.798015832901001
Validation loss: 2.244091510772705

Epoch: 6| Step: 2
Training loss: 1.0268878936767578
Validation loss: 2.1809787154197693

Epoch: 6| Step: 3
Training loss: 0.8633079528808594
Validation loss: 2.1747551361719766

Epoch: 6| Step: 4
Training loss: 1.1146928071975708
Validation loss: 2.1098296642303467

Epoch: 6| Step: 5
Training loss: 1.5090919733047485
Validation loss: 2.109086016813914

Epoch: 6| Step: 6
Training loss: 1.5288517475128174
Validation loss: 2.139591554800669

Epoch: 6| Step: 7
Training loss: 1.189426302909851
Validation loss: 2.1450679500897727

Epoch: 6| Step: 8
Training loss: 0.8304929733276367
Validation loss: 2.187531590461731

Epoch: 6| Step: 9
Training loss: 1.1600008010864258
Validation loss: 2.107596000035604

Epoch: 6| Step: 10
Training loss: 2.214684009552002
Validation loss: 2.1290199160575867

Epoch: 6| Step: 11
Training loss: 1.2987960577011108
Validation loss: 2.103115955988566

Epoch: 6| Step: 12
Training loss: 1.1354904174804688
Validation loss: 2.0895185669263205

Epoch: 6| Step: 13
Training loss: 0.9474214315414429
Validation loss: 2.0541591246922812

Epoch: 186| Step: 0
Training loss: 0.9570256471633911
Validation loss: 2.1071205735206604

Epoch: 6| Step: 1
Training loss: 0.7354179620742798
Validation loss: 2.1546919345855713

Epoch: 6| Step: 2
Training loss: 1.062972068786621
Validation loss: 2.2098583777745566

Epoch: 6| Step: 3
Training loss: 1.05369234085083
Validation loss: 2.1721532940864563

Epoch: 6| Step: 4
Training loss: 1.3725775480270386
Validation loss: 2.21242892742157

Epoch: 6| Step: 5
Training loss: 1.391861081123352
Validation loss: 2.196709314982096

Epoch: 6| Step: 6
Training loss: 0.9342232942581177
Validation loss: 2.186003009478251

Epoch: 6| Step: 7
Training loss: 1.4436554908752441
Validation loss: 2.1531532605489097

Epoch: 6| Step: 8
Training loss: 1.0969732999801636
Validation loss: 2.082315524419149

Epoch: 6| Step: 9
Training loss: 1.3693584203720093
Validation loss: 2.098515053590139

Epoch: 6| Step: 10
Training loss: 1.0027754306793213
Validation loss: 2.1103702584902444

Epoch: 6| Step: 11
Training loss: 1.1511974334716797
Validation loss: 2.1096898714701333

Epoch: 6| Step: 12
Training loss: 1.3874976634979248
Validation loss: 2.1177576184272766

Epoch: 6| Step: 13
Training loss: 1.0462228059768677
Validation loss: 2.082070529460907

Epoch: 187| Step: 0
Training loss: 0.9197995066642761
Validation loss: 2.120995879173279

Epoch: 6| Step: 1
Training loss: 1.3087058067321777
Validation loss: 2.098425348599752

Epoch: 6| Step: 2
Training loss: 1.0417720079421997
Validation loss: 2.1072813471158347

Epoch: 6| Step: 3
Training loss: 0.9128831624984741
Validation loss: 2.1431984106699624

Epoch: 6| Step: 4
Training loss: 1.0068354606628418
Validation loss: 2.120851695537567

Epoch: 6| Step: 5
Training loss: 1.1954526901245117
Validation loss: 2.1678088506062827

Epoch: 6| Step: 6
Training loss: 0.6855742931365967
Validation loss: 2.2283883690834045

Epoch: 6| Step: 7
Training loss: 1.228071928024292
Validation loss: 2.1075255274772644

Epoch: 6| Step: 8
Training loss: 1.4439055919647217
Validation loss: 2.0904261072476706

Epoch: 6| Step: 9
Training loss: 1.2169770002365112
Validation loss: 2.1363607247670493

Epoch: 6| Step: 10
Training loss: 0.68855881690979
Validation loss: 2.1038816769917807

Epoch: 6| Step: 11
Training loss: 1.2900080680847168
Validation loss: 2.128454605738322

Epoch: 6| Step: 12
Training loss: 0.7920616269111633
Validation loss: 2.136836310227712

Epoch: 6| Step: 13
Training loss: 1.3935929536819458
Validation loss: 2.093943397204081

Epoch: 188| Step: 0
Training loss: 1.241490125656128
Validation loss: 2.193510333697001

Epoch: 6| Step: 1
Training loss: 0.6442065238952637
Validation loss: 2.0914909839630127

Epoch: 6| Step: 2
Training loss: 1.0385463237762451
Validation loss: 2.1010611255963645

Epoch: 6| Step: 3
Training loss: 0.9463158845901489
Validation loss: 2.0475083589553833

Epoch: 6| Step: 4
Training loss: 0.900395393371582
Validation loss: 2.1314768195152283

Epoch: 6| Step: 5
Training loss: 0.9234530925750732
Validation loss: 2.119397441546122

Epoch: 6| Step: 6
Training loss: 0.9449241161346436
Validation loss: 2.1382938226064048

Epoch: 6| Step: 7
Training loss: 1.1083683967590332
Validation loss: 2.128129800160726

Epoch: 6| Step: 8
Training loss: 0.7236784100532532
Validation loss: 2.1269723773002625

Epoch: 6| Step: 9
Training loss: 1.1818610429763794
Validation loss: 2.1666003465652466

Epoch: 6| Step: 10
Training loss: 1.2253844738006592
Validation loss: 2.1023970246315002

Epoch: 6| Step: 11
Training loss: 1.243359088897705
Validation loss: 2.1551899115244546

Epoch: 6| Step: 12
Training loss: 1.7850170135498047
Validation loss: 2.1551321744918823

Epoch: 6| Step: 13
Training loss: 1.0267118215560913
Validation loss: 2.116318186124166

Epoch: 189| Step: 0
Training loss: 0.6922413110733032
Validation loss: 2.1100295782089233

Epoch: 6| Step: 1
Training loss: 1.47441565990448
Validation loss: 2.1522582372029624

Epoch: 6| Step: 2
Training loss: 1.1840285062789917
Validation loss: 2.107790390650431

Epoch: 6| Step: 3
Training loss: 0.910305917263031
Validation loss: 2.177419284979502

Epoch: 6| Step: 4
Training loss: 0.9189208149909973
Validation loss: 2.114494721094767

Epoch: 6| Step: 5
Training loss: 1.266781210899353
Validation loss: 2.105509638786316

Epoch: 6| Step: 6
Training loss: 1.3287744522094727
Validation loss: 2.0709511041641235

Epoch: 6| Step: 7
Training loss: 0.5964415073394775
Validation loss: 2.123525083065033

Epoch: 6| Step: 8
Training loss: 1.1747678518295288
Validation loss: 2.159145991007487

Epoch: 6| Step: 9
Training loss: 1.3201862573623657
Validation loss: 2.127020080884298

Epoch: 6| Step: 10
Training loss: 1.1498806476593018
Validation loss: 2.1642404794692993

Epoch: 6| Step: 11
Training loss: 0.7016078233718872
Validation loss: 2.14046049118042

Epoch: 6| Step: 12
Training loss: 0.612238347530365
Validation loss: 2.1420045296351113

Epoch: 6| Step: 13
Training loss: 1.2954702377319336
Validation loss: 2.1514042019844055

Epoch: 190| Step: 0
Training loss: 0.7492623925209045
Validation loss: 2.1270597179730735

Epoch: 6| Step: 1
Training loss: 0.7772012948989868
Validation loss: 2.1350362300872803

Epoch: 6| Step: 2
Training loss: 1.183974027633667
Validation loss: 2.1492954889933267

Epoch: 6| Step: 3
Training loss: 1.1915041208267212
Validation loss: 2.090304454167684

Epoch: 6| Step: 4
Training loss: 1.045897364616394
Validation loss: 2.106070021788279

Epoch: 6| Step: 5
Training loss: 0.6420648097991943
Validation loss: 2.1195199688275657

Epoch: 6| Step: 6
Training loss: 1.056331753730774
Validation loss: 2.0950079758961997

Epoch: 6| Step: 7
Training loss: 1.0316652059555054
Validation loss: 2.114793360233307

Epoch: 6| Step: 8
Training loss: 1.0816946029663086
Validation loss: 2.119509299596151

Epoch: 6| Step: 9
Training loss: 0.9988399744033813
Validation loss: 2.150451421737671

Epoch: 6| Step: 10
Training loss: 1.2342541217803955
Validation loss: 2.1748899022738137

Epoch: 6| Step: 11
Training loss: 1.7904525995254517
Validation loss: 2.129263003667196

Epoch: 6| Step: 12
Training loss: 1.1336286067962646
Validation loss: 2.0977365970611572

Epoch: 6| Step: 13
Training loss: 0.8362811803817749
Validation loss: 2.1637258728345237

Epoch: 191| Step: 0
Training loss: 1.0343931913375854
Validation loss: 2.129014313220978

Epoch: 6| Step: 1
Training loss: 0.7777822017669678
Validation loss: 2.0922656257947287

Epoch: 6| Step: 2
Training loss: 0.9754538536071777
Validation loss: 2.0922677516937256

Epoch: 6| Step: 3
Training loss: 0.7257723808288574
Validation loss: 2.138152519861857

Epoch: 6| Step: 4
Training loss: 1.0957581996917725
Validation loss: 2.128696699937185

Epoch: 6| Step: 5
Training loss: 1.0156984329223633
Validation loss: 2.16376527150472

Epoch: 6| Step: 6
Training loss: 0.94427889585495
Validation loss: 2.1326815485954285

Epoch: 6| Step: 7
Training loss: 0.6240400671958923
Validation loss: 2.156582295894623

Epoch: 6| Step: 8
Training loss: 1.4799240827560425
Validation loss: 2.1655959288279214

Epoch: 6| Step: 9
Training loss: 1.2320117950439453
Validation loss: 2.0483345786730447

Epoch: 6| Step: 10
Training loss: 1.4327003955841064
Validation loss: 2.0556610425313315

Epoch: 6| Step: 11
Training loss: 1.255312204360962
Validation loss: 2.1304566860198975

Epoch: 6| Step: 12
Training loss: 1.2637088298797607
Validation loss: 2.1837065021197

Epoch: 6| Step: 13
Training loss: 0.9543577432632446
Validation loss: 2.056508183479309

Epoch: 192| Step: 0
Training loss: 0.8400620222091675
Validation loss: 2.141765554745992

Epoch: 6| Step: 1
Training loss: 1.4678149223327637
Validation loss: 2.1025498310724893

Epoch: 6| Step: 2
Training loss: 1.3036489486694336
Validation loss: 2.1309751868247986

Epoch: 6| Step: 3
Training loss: 0.8094164729118347
Validation loss: 2.1977239648501077

Epoch: 6| Step: 4
Training loss: 0.9024980068206787
Validation loss: 2.211494207382202

Epoch: 6| Step: 5
Training loss: 0.5893479585647583
Validation loss: 2.222562789916992

Epoch: 6| Step: 6
Training loss: 1.2277381420135498
Validation loss: 2.2128050724665322

Epoch: 6| Step: 7
Training loss: 1.016136646270752
Validation loss: 2.177226940790812

Epoch: 6| Step: 8
Training loss: 1.3528013229370117
Validation loss: 2.1665823062260947

Epoch: 6| Step: 9
Training loss: 0.5372350215911865
Validation loss: 2.157824953397115

Epoch: 6| Step: 10
Training loss: 1.0910396575927734
Validation loss: 2.0877556006113687

Epoch: 6| Step: 11
Training loss: 1.0631952285766602
Validation loss: 2.0833757718404136

Epoch: 6| Step: 12
Training loss: 1.4074032306671143
Validation loss: 2.09297247727712

Epoch: 6| Step: 13
Training loss: 1.0657873153686523
Validation loss: 2.1356617212295532

Epoch: 193| Step: 0
Training loss: 1.0606573820114136
Validation loss: 2.133289317289988

Epoch: 6| Step: 1
Training loss: 1.170551061630249
Validation loss: 2.186935842037201

Epoch: 6| Step: 2
Training loss: 1.0839228630065918
Validation loss: 2.148823082447052

Epoch: 6| Step: 3
Training loss: 0.6288108825683594
Validation loss: 2.1390225489934287

Epoch: 6| Step: 4
Training loss: 0.7931563258171082
Validation loss: 2.207469960053762

Epoch: 6| Step: 5
Training loss: 1.3284889459609985
Validation loss: 2.219723343849182

Epoch: 6| Step: 6
Training loss: 1.2225919961929321
Validation loss: 2.335623105367025

Epoch: 6| Step: 7
Training loss: 1.3837854862213135
Validation loss: 2.308106780052185

Epoch: 6| Step: 8
Training loss: 1.2616710662841797
Validation loss: 2.2777779499689736

Epoch: 6| Step: 9
Training loss: 1.4723321199417114
Validation loss: 2.2916829586029053

Epoch: 6| Step: 10
Training loss: 1.1480753421783447
Validation loss: 2.2036479115486145

Epoch: 6| Step: 11
Training loss: 0.62936931848526
Validation loss: 2.1624932090441384

Epoch: 6| Step: 12
Training loss: 1.0285768508911133
Validation loss: 2.1062810023625693

Epoch: 6| Step: 13
Training loss: 1.4267789125442505
Validation loss: 2.148839851220449

Epoch: 194| Step: 0
Training loss: 0.9110613465309143
Validation loss: 2.1204079588254294

Epoch: 6| Step: 1
Training loss: 1.5751261711120605
Validation loss: 2.046113073825836

Epoch: 6| Step: 2
Training loss: 1.3422781229019165
Validation loss: 2.1039079427719116

Epoch: 6| Step: 3
Training loss: 0.689559280872345
Validation loss: 2.099923074245453

Epoch: 6| Step: 4
Training loss: 1.0602539777755737
Validation loss: 2.1213916142781577

Epoch: 6| Step: 5
Training loss: 0.5316423177719116
Validation loss: 2.0841636657714844

Epoch: 6| Step: 6
Training loss: 1.02149498462677
Validation loss: 2.1353789369265237

Epoch: 6| Step: 7
Training loss: 1.1876235008239746
Validation loss: 2.1660210688908896

Epoch: 6| Step: 8
Training loss: 0.9192091226577759
Validation loss: 2.267518162727356

Epoch: 6| Step: 9
Training loss: 1.4366421699523926
Validation loss: 2.245183289051056

Epoch: 6| Step: 10
Training loss: 0.7424808740615845
Validation loss: 2.204897185166677

Epoch: 6| Step: 11
Training loss: 1.109902024269104
Validation loss: 2.2064807415008545

Epoch: 6| Step: 12
Training loss: 1.8554096221923828
Validation loss: 2.1568245887756348

Epoch: 6| Step: 13
Training loss: 0.9377861022949219
Validation loss: 2.092468500137329

Epoch: 195| Step: 0
Training loss: 1.500671625137329
Validation loss: 2.081207036972046

Epoch: 6| Step: 1
Training loss: 0.6670354604721069
Validation loss: 2.0931917428970337

Epoch: 6| Step: 2
Training loss: 1.1535005569458008
Validation loss: 2.082053065299988

Epoch: 6| Step: 3
Training loss: 1.3084981441497803
Validation loss: 2.1104407707850137

Epoch: 6| Step: 4
Training loss: 0.9330411553382874
Validation loss: 2.085238973299662

Epoch: 6| Step: 5
Training loss: 0.6173290610313416
Validation loss: 2.1417065064112344

Epoch: 6| Step: 6
Training loss: 0.849052369594574
Validation loss: 2.111669639746348

Epoch: 6| Step: 7
Training loss: 0.5876631140708923
Validation loss: 2.132041335105896

Epoch: 6| Step: 8
Training loss: 1.0640645027160645
Validation loss: 2.1551212469736734

Epoch: 6| Step: 9
Training loss: 0.6167382001876831
Validation loss: 2.1457263827323914

Epoch: 6| Step: 10
Training loss: 1.1643837690353394
Validation loss: 2.103287855784098

Epoch: 6| Step: 11
Training loss: 1.2982465028762817
Validation loss: 2.0973491072654724

Epoch: 6| Step: 12
Training loss: 0.9074753522872925
Validation loss: 2.0980085134506226

Epoch: 6| Step: 13
Training loss: 1.3383550643920898
Validation loss: 2.150514324506124

Epoch: 196| Step: 0
Training loss: 1.3141580820083618
Validation loss: 2.121545910835266

Epoch: 6| Step: 1
Training loss: 1.6260015964508057
Validation loss: 2.1416263381640115

Epoch: 6| Step: 2
Training loss: 0.8115607500076294
Validation loss: 2.138180653254191

Epoch: 6| Step: 3
Training loss: 1.2293896675109863
Validation loss: 2.076277772585551

Epoch: 6| Step: 4
Training loss: 0.8343155384063721
Validation loss: 2.1428522070248923

Epoch: 6| Step: 5
Training loss: 1.0965865850448608
Validation loss: 2.152297576268514

Epoch: 6| Step: 6
Training loss: 0.909956693649292
Validation loss: 2.1733248829841614

Epoch: 6| Step: 7
Training loss: 1.2037405967712402
Validation loss: 2.1313299338022866

Epoch: 6| Step: 8
Training loss: 0.8133836388587952
Validation loss: 2.0998234152793884

Epoch: 6| Step: 9
Training loss: 0.7812225818634033
Validation loss: 2.136093854904175

Epoch: 6| Step: 10
Training loss: 0.5515671968460083
Validation loss: 2.141954799493154

Epoch: 6| Step: 11
Training loss: 0.609952449798584
Validation loss: 2.164372742176056

Epoch: 6| Step: 12
Training loss: 0.9824768304824829
Validation loss: 2.1285216410954795

Epoch: 6| Step: 13
Training loss: 1.0601906776428223
Validation loss: 2.105638027191162

Epoch: 197| Step: 0
Training loss: 1.0641436576843262
Validation loss: 2.142730474472046

Epoch: 6| Step: 1
Training loss: 0.8387624025344849
Validation loss: 2.057442367076874

Epoch: 6| Step: 2
Training loss: 1.3114670515060425
Validation loss: 2.119832475980123

Epoch: 6| Step: 3
Training loss: 1.4407881498336792
Validation loss: 2.1520702044169107

Epoch: 6| Step: 4
Training loss: 0.6063480377197266
Validation loss: 2.106985112031301

Epoch: 6| Step: 5
Training loss: 0.46615687012672424
Validation loss: 2.1358099977175393

Epoch: 6| Step: 6
Training loss: 0.9561307430267334
Validation loss: 2.142157196998596

Epoch: 6| Step: 7
Training loss: 1.2827141284942627
Validation loss: 2.118782917658488

Epoch: 6| Step: 8
Training loss: 1.5476070642471313
Validation loss: 2.112012803554535

Epoch: 6| Step: 9
Training loss: 0.8530868291854858
Validation loss: 2.0783705711364746

Epoch: 6| Step: 10
Training loss: 0.819223165512085
Validation loss: 2.102892259756724

Epoch: 6| Step: 11
Training loss: 0.9779189825057983
Validation loss: 2.1325977643330893

Epoch: 6| Step: 12
Training loss: 1.2083489894866943
Validation loss: 2.1629852453867593

Epoch: 6| Step: 13
Training loss: 0.5555787086486816
Validation loss: 2.101193904876709

Epoch: 198| Step: 0
Training loss: 1.372939109802246
Validation loss: 2.1541382471720376

Epoch: 6| Step: 1
Training loss: 1.1541370153427124
Validation loss: 2.1380244890848794

Epoch: 6| Step: 2
Training loss: 0.9452311992645264
Validation loss: 2.1114384531974792

Epoch: 6| Step: 3
Training loss: 0.6001112461090088
Validation loss: 2.1479641993840537

Epoch: 6| Step: 4
Training loss: 1.0874247550964355
Validation loss: 2.216595689455668

Epoch: 6| Step: 5
Training loss: 0.6653002500534058
Validation loss: 2.1750819087028503

Epoch: 6| Step: 6
Training loss: 1.1107511520385742
Validation loss: 2.1117546955744424

Epoch: 6| Step: 7
Training loss: 1.0932412147521973
Validation loss: 2.1544194420178733

Epoch: 6| Step: 8
Training loss: 0.8102167844772339
Validation loss: 2.13819420337677

Epoch: 6| Step: 9
Training loss: 0.751153826713562
Validation loss: 2.123913665612539

Epoch: 6| Step: 10
Training loss: 0.9985677003860474
Validation loss: 2.0766393343607583

Epoch: 6| Step: 11
Training loss: 0.8297035694122314
Validation loss: 2.148094137509664

Epoch: 6| Step: 12
Training loss: 1.2242212295532227
Validation loss: 2.1305060187975564

Epoch: 6| Step: 13
Training loss: 1.4593727588653564
Validation loss: 2.17129780848821

Epoch: 199| Step: 0
Training loss: 0.4292265474796295
Validation loss: 2.132352113723755

Epoch: 6| Step: 1
Training loss: 1.082306146621704
Validation loss: 2.1787211894989014

Epoch: 6| Step: 2
Training loss: 0.8174585103988647
Validation loss: 2.2019299268722534

Epoch: 6| Step: 3
Training loss: 1.1932436227798462
Validation loss: 2.1342540184656777

Epoch: 6| Step: 4
Training loss: 0.969188392162323
Validation loss: 2.036299784978231

Epoch: 6| Step: 5
Training loss: 0.9168801307678223
Validation loss: 2.1138184467951455

Epoch: 6| Step: 6
Training loss: 0.9559935927391052
Validation loss: 2.1042803724606833

Epoch: 6| Step: 7
Training loss: 1.1165380477905273
Validation loss: 2.0941925247510276

Epoch: 6| Step: 8
Training loss: 1.294975996017456
Validation loss: 2.0899637738863626

Epoch: 6| Step: 9
Training loss: 1.5276719331741333
Validation loss: 2.1510252356529236

Epoch: 6| Step: 10
Training loss: 0.870969295501709
Validation loss: 2.136843125025431

Epoch: 6| Step: 11
Training loss: 1.151478886604309
Validation loss: 2.166595240434011

Epoch: 6| Step: 12
Training loss: 0.9546041488647461
Validation loss: 2.1346665620803833

Epoch: 6| Step: 13
Training loss: 0.8283172249794006
Validation loss: 2.1296966075897217

Epoch: 200| Step: 0
Training loss: 0.8568472266197205
Validation loss: 2.179322083791097

Epoch: 6| Step: 1
Training loss: 0.7857149839401245
Validation loss: 2.1775293548901877

Epoch: 6| Step: 2
Training loss: 0.5996523499488831
Validation loss: 2.2324708302815757

Epoch: 6| Step: 3
Training loss: 0.9294625520706177
Validation loss: 2.245285471280416

Epoch: 6| Step: 4
Training loss: 1.460398554801941
Validation loss: 2.1977320512135825

Epoch: 6| Step: 5
Training loss: 1.2342073917388916
Validation loss: 2.1877353191375732

Epoch: 6| Step: 6
Training loss: 1.2237677574157715
Validation loss: 2.208927313486735

Epoch: 6| Step: 7
Training loss: 0.4910191595554352
Validation loss: 2.129402995109558

Epoch: 6| Step: 8
Training loss: 1.4668772220611572
Validation loss: 2.1218438943227134

Epoch: 6| Step: 9
Training loss: 0.8859997391700745
Validation loss: 2.127841353416443

Epoch: 6| Step: 10
Training loss: 1.240448236465454
Validation loss: 2.107280155022939

Epoch: 6| Step: 11
Training loss: 0.9302551746368408
Validation loss: 2.177493433157603

Epoch: 6| Step: 12
Training loss: 0.9481173753738403
Validation loss: 2.14348570505778

Epoch: 6| Step: 13
Training loss: 0.8943230509757996
Validation loss: 2.180519680182139

Epoch: 201| Step: 0
Training loss: 1.4260151386260986
Validation loss: 2.15514600276947

Epoch: 6| Step: 1
Training loss: 0.943981945514679
Validation loss: 2.136863112449646

Epoch: 6| Step: 2
Training loss: 0.5078864693641663
Validation loss: 2.1570341984430947

Epoch: 6| Step: 3
Training loss: 0.5798081755638123
Validation loss: 2.1818714141845703

Epoch: 6| Step: 4
Training loss: 1.1985522508621216
Validation loss: 2.094540536403656

Epoch: 6| Step: 5
Training loss: 1.0204870700836182
Validation loss: 2.095671792825063

Epoch: 6| Step: 6
Training loss: 0.8859935998916626
Validation loss: 2.180169185002645

Epoch: 6| Step: 7
Training loss: 1.4774434566497803
Validation loss: 2.125201423962911

Epoch: 6| Step: 8
Training loss: 0.6689350605010986
Validation loss: 2.0938450495402017

Epoch: 6| Step: 9
Training loss: 0.7910388112068176
Validation loss: 2.076301415761312

Epoch: 6| Step: 10
Training loss: 1.0548622608184814
Validation loss: 2.1714260578155518

Epoch: 6| Step: 11
Training loss: 1.047256350517273
Validation loss: 2.1483484506607056

Epoch: 6| Step: 12
Training loss: 0.704436182975769
Validation loss: 2.14896688858668

Epoch: 6| Step: 13
Training loss: 0.8971366286277771
Validation loss: 2.1899291276931763

Epoch: 202| Step: 0
Training loss: 0.8702342510223389
Validation loss: 2.1141392985979715

Epoch: 6| Step: 1
Training loss: 0.5774773955345154
Validation loss: 2.138631363709768

Epoch: 6| Step: 2
Training loss: 1.2223803997039795
Validation loss: 2.0925766825675964

Epoch: 6| Step: 3
Training loss: 0.6295733451843262
Validation loss: 2.145709196726481

Epoch: 6| Step: 4
Training loss: 0.7255978584289551
Validation loss: 2.0867311358451843

Epoch: 6| Step: 5
Training loss: 0.7970014810562134
Validation loss: 2.1064255436261496

Epoch: 6| Step: 6
Training loss: 0.8561482429504395
Validation loss: 2.0938833753267923

Epoch: 6| Step: 7
Training loss: 0.7376407980918884
Validation loss: 2.1189182798067727

Epoch: 6| Step: 8
Training loss: 1.0160707235336304
Validation loss: 2.1435523430506387

Epoch: 6| Step: 9
Training loss: 0.992662787437439
Validation loss: 2.1518481771151223

Epoch: 6| Step: 10
Training loss: 1.486833930015564
Validation loss: 2.1743121345837912

Epoch: 6| Step: 11
Training loss: 1.2941244840621948
Validation loss: 2.156575918197632

Epoch: 6| Step: 12
Training loss: 0.8024624586105347
Validation loss: 2.159490386644999

Epoch: 6| Step: 13
Training loss: 1.0595043897628784
Validation loss: 2.1818889379501343

Epoch: 203| Step: 0
Training loss: 1.346612811088562
Validation loss: 2.146643261114756

Epoch: 6| Step: 1
Training loss: 0.6329101920127869
Validation loss: 2.1168238520622253

Epoch: 6| Step: 2
Training loss: 1.5642107725143433
Validation loss: 2.0807552536328635

Epoch: 6| Step: 3
Training loss: 1.2299927473068237
Validation loss: 2.201301912466685

Epoch: 6| Step: 4
Training loss: 1.345527172088623
Validation loss: 2.1347322861353555

Epoch: 6| Step: 5
Training loss: 1.1828200817108154
Validation loss: 2.044160703818003

Epoch: 6| Step: 6
Training loss: 0.6126710772514343
Validation loss: 2.137074132760366

Epoch: 6| Step: 7
Training loss: 1.03976571559906
Validation loss: 2.146846294403076

Epoch: 6| Step: 8
Training loss: 1.0207866430282593
Validation loss: 2.1634514530499778

Epoch: 6| Step: 9
Training loss: 0.6970922946929932
Validation loss: 2.1645514766375222

Epoch: 6| Step: 10
Training loss: 0.532776415348053
Validation loss: 2.1006046533584595

Epoch: 6| Step: 11
Training loss: 1.1977394819259644
Validation loss: 2.149139086405436

Epoch: 6| Step: 12
Training loss: 0.9165241718292236
Validation loss: 2.157725751399994

Epoch: 6| Step: 13
Training loss: 0.6581410765647888
Validation loss: 2.1475563645362854

Epoch: 204| Step: 0
Training loss: 1.1450159549713135
Validation loss: 2.1445285876592

Epoch: 6| Step: 1
Training loss: 1.247769832611084
Validation loss: 2.1437252163887024

Epoch: 6| Step: 2
Training loss: 1.1717990636825562
Validation loss: 2.135359307130178

Epoch: 6| Step: 3
Training loss: 0.8777783513069153
Validation loss: 2.134650945663452

Epoch: 6| Step: 4
Training loss: 0.7013738751411438
Validation loss: 2.1600977182388306

Epoch: 6| Step: 5
Training loss: 0.6767714619636536
Validation loss: 2.1215862234433494

Epoch: 6| Step: 6
Training loss: 1.0724220275878906
Validation loss: 2.1009968717892966

Epoch: 6| Step: 7
Training loss: 1.1401739120483398
Validation loss: 2.0896124045054116

Epoch: 6| Step: 8
Training loss: 0.7996759414672852
Validation loss: 2.0961934526761374

Epoch: 6| Step: 9
Training loss: 1.0821551084518433
Validation loss: 2.153105318546295

Epoch: 6| Step: 10
Training loss: 1.069845199584961
Validation loss: 2.071342627207438

Epoch: 6| Step: 11
Training loss: 0.6543743014335632
Validation loss: 2.154713968435923

Epoch: 6| Step: 12
Training loss: 0.9643052220344543
Validation loss: 2.124617417653402

Epoch: 6| Step: 13
Training loss: 0.7948799133300781
Validation loss: 2.1462432742118835

Epoch: 205| Step: 0
Training loss: 0.7733328938484192
Validation loss: 2.117944916089376

Epoch: 6| Step: 1
Training loss: 0.8665803074836731
Validation loss: 2.10405965646108

Epoch: 6| Step: 2
Training loss: 1.0379314422607422
Validation loss: 2.0484502712885537

Epoch: 6| Step: 3
Training loss: 0.8174797296524048
Validation loss: 2.1303085486094155

Epoch: 6| Step: 4
Training loss: 1.236152172088623
Validation loss: 2.083675762017568

Epoch: 6| Step: 5
Training loss: 1.1220669746398926
Validation loss: 2.067146976788839

Epoch: 6| Step: 6
Training loss: 0.6882820129394531
Validation loss: 2.0730415185292563

Epoch: 6| Step: 7
Training loss: 0.8126240968704224
Validation loss: 2.1177551547686257

Epoch: 6| Step: 8
Training loss: 0.9446104168891907
Validation loss: 2.196539044380188

Epoch: 6| Step: 9
Training loss: 0.9489738941192627
Validation loss: 2.169857084751129

Epoch: 6| Step: 10
Training loss: 1.0748348236083984
Validation loss: 2.1791692972183228

Epoch: 6| Step: 11
Training loss: 1.2598652839660645
Validation loss: 2.17047909895579

Epoch: 6| Step: 12
Training loss: 1.086639165878296
Validation loss: 2.160561442375183

Epoch: 6| Step: 13
Training loss: 0.9951645135879517
Validation loss: 2.0975125829378762

Epoch: 206| Step: 0
Training loss: 1.10746169090271
Validation loss: 2.1637141903241477

Epoch: 6| Step: 1
Training loss: 0.3589957356452942
Validation loss: 2.100619395573934

Epoch: 6| Step: 2
Training loss: 0.908913254737854
Validation loss: 2.082063138484955

Epoch: 6| Step: 3
Training loss: 1.2849270105361938
Validation loss: 2.1284618973731995

Epoch: 6| Step: 4
Training loss: 1.3643531799316406
Validation loss: 2.0995521942774453

Epoch: 6| Step: 5
Training loss: 0.6811456084251404
Validation loss: 2.099226156870524

Epoch: 6| Step: 6
Training loss: 1.1948108673095703
Validation loss: 2.1213579972585044

Epoch: 6| Step: 7
Training loss: 1.2432876825332642
Validation loss: 2.0755603114763894

Epoch: 6| Step: 8
Training loss: 0.5735937356948853
Validation loss: 2.1384445230166116

Epoch: 6| Step: 9
Training loss: 0.803817868232727
Validation loss: 2.133997639020284

Epoch: 6| Step: 10
Training loss: 1.4158837795257568
Validation loss: 2.142291307449341

Epoch: 6| Step: 11
Training loss: 0.5509225726127625
Validation loss: 2.1926841139793396

Epoch: 6| Step: 12
Training loss: 1.035110592842102
Validation loss: 2.1450549761454263

Epoch: 6| Step: 13
Training loss: 0.9803419709205627
Validation loss: 2.1574422121047974

Epoch: 207| Step: 0
Training loss: 1.2688754796981812
Validation loss: 2.1876113017400107

Epoch: 6| Step: 1
Training loss: 1.5117113590240479
Validation loss: 2.189936935901642

Epoch: 6| Step: 2
Training loss: 0.9590902328491211
Validation loss: 2.126562317212423

Epoch: 6| Step: 3
Training loss: 0.6296625733375549
Validation loss: 2.1117226680119834

Epoch: 6| Step: 4
Training loss: 0.9256596565246582
Validation loss: 2.1187283794085183

Epoch: 6| Step: 5
Training loss: 0.690018892288208
Validation loss: 2.129143794377645

Epoch: 6| Step: 6
Training loss: 0.5590220093727112
Validation loss: 2.124927838643392

Epoch: 6| Step: 7
Training loss: 0.7499057054519653
Validation loss: 2.1630773742993674

Epoch: 6| Step: 8
Training loss: 0.6110824346542358
Validation loss: 2.131461421648661

Epoch: 6| Step: 9
Training loss: 1.1672054529190063
Validation loss: 2.117884874343872

Epoch: 6| Step: 10
Training loss: 1.3324602842330933
Validation loss: 2.120101531346639

Epoch: 6| Step: 11
Training loss: 0.9087645411491394
Validation loss: 2.1481510599454245

Epoch: 6| Step: 12
Training loss: 0.7088115215301514
Validation loss: 2.106963117917379

Epoch: 6| Step: 13
Training loss: 0.7357093095779419
Validation loss: 2.118264615535736

Epoch: 208| Step: 0
Training loss: 0.9502880573272705
Validation loss: 2.1849194765090942

Epoch: 6| Step: 1
Training loss: 1.0255144834518433
Validation loss: 2.1753623485565186

Epoch: 6| Step: 2
Training loss: 0.9457643032073975
Validation loss: 2.1123757362365723

Epoch: 6| Step: 3
Training loss: 1.0323500633239746
Validation loss: 2.1390249729156494

Epoch: 6| Step: 4
Training loss: 0.6173155903816223
Validation loss: 2.067116896311442

Epoch: 6| Step: 5
Training loss: 1.1321029663085938
Validation loss: 2.1061835289001465

Epoch: 6| Step: 6
Training loss: 0.8074377775192261
Validation loss: 2.14378289381663

Epoch: 6| Step: 7
Training loss: 0.43887317180633545
Validation loss: 2.1509146690368652

Epoch: 6| Step: 8
Training loss: 0.6789494752883911
Validation loss: 2.1612270871798196

Epoch: 6| Step: 9
Training loss: 0.9605230689048767
Validation loss: 2.1803370118141174

Epoch: 6| Step: 10
Training loss: 1.517848014831543
Validation loss: 2.089820226033529

Epoch: 6| Step: 11
Training loss: 0.726319432258606
Validation loss: 2.1424288551012673

Epoch: 6| Step: 12
Training loss: 1.0657240152359009
Validation loss: 2.1194171706835427

Epoch: 6| Step: 13
Training loss: 0.8887041807174683
Validation loss: 2.1093883911768594

Epoch: 209| Step: 0
Training loss: 0.8993912935256958
Validation loss: 2.1338340441385903

Epoch: 6| Step: 1
Training loss: 1.240709662437439
Validation loss: 2.125415543715159

Epoch: 6| Step: 2
Training loss: 1.3726539611816406
Validation loss: 2.159202436606089

Epoch: 6| Step: 3
Training loss: 0.9021657705307007
Validation loss: 2.1453558007876077

Epoch: 6| Step: 4
Training loss: 0.5949432849884033
Validation loss: 2.1470728715260825

Epoch: 6| Step: 5
Training loss: 0.752247154712677
Validation loss: 2.107836822668711

Epoch: 6| Step: 6
Training loss: 1.3117282390594482
Validation loss: 2.2128132979075112

Epoch: 6| Step: 7
Training loss: 0.9569302797317505
Validation loss: 2.2325737476348877

Epoch: 6| Step: 8
Training loss: 0.5312849283218384
Validation loss: 2.1298042933146157

Epoch: 6| Step: 9
Training loss: 1.1678024530410767
Validation loss: 2.168478508790334

Epoch: 6| Step: 10
Training loss: 0.8740235567092896
Validation loss: 2.179566979408264

Epoch: 6| Step: 11
Training loss: 1.094153881072998
Validation loss: 2.203117072582245

Epoch: 6| Step: 12
Training loss: 0.4448050856590271
Validation loss: 2.1474488377571106

Epoch: 6| Step: 13
Training loss: 0.7940585613250732
Validation loss: 2.1061399976412454

Epoch: 210| Step: 0
Training loss: 1.0005052089691162
Validation loss: 2.158576488494873

Epoch: 6| Step: 1
Training loss: 1.0128597021102905
Validation loss: 2.156273444493612

Epoch: 6| Step: 2
Training loss: 0.952911376953125
Validation loss: 2.130370239416758

Epoch: 6| Step: 3
Training loss: 0.96355140209198
Validation loss: 2.0514343976974487

Epoch: 6| Step: 4
Training loss: 0.539776623249054
Validation loss: 2.1669941345850625

Epoch: 6| Step: 5
Training loss: 0.7157706022262573
Validation loss: 2.117088476816813

Epoch: 6| Step: 6
Training loss: 1.4491748809814453
Validation loss: 2.129054586092631

Epoch: 6| Step: 7
Training loss: 0.6232887506484985
Validation loss: 2.030534327030182

Epoch: 6| Step: 8
Training loss: 0.8330846428871155
Validation loss: 2.0706907510757446

Epoch: 6| Step: 9
Training loss: 0.8661910891532898
Validation loss: 2.140293538570404

Epoch: 6| Step: 10
Training loss: 0.8448270559310913
Validation loss: 2.1050395568211875

Epoch: 6| Step: 11
Training loss: 1.2261276245117188
Validation loss: 2.1056348284085593

Epoch: 6| Step: 12
Training loss: 0.8805431127548218
Validation loss: 2.1629306077957153

Epoch: 6| Step: 13
Training loss: 1.0965427160263062
Validation loss: 2.1359233061472573

Epoch: 211| Step: 0
Training loss: 1.077009677886963
Validation loss: 2.114173630873362

Epoch: 6| Step: 1
Training loss: 0.9282115697860718
Validation loss: 2.1417234341303506

Epoch: 6| Step: 2
Training loss: 0.5828357934951782
Validation loss: 2.118469218413035

Epoch: 6| Step: 3
Training loss: 0.7170178890228271
Validation loss: 2.094613869984945

Epoch: 6| Step: 4
Training loss: 1.2812409400939941
Validation loss: 2.1406309405962625

Epoch: 6| Step: 5
Training loss: 0.4861830472946167
Validation loss: 2.132761220137278

Epoch: 6| Step: 6
Training loss: 0.6771622896194458
Validation loss: 2.1892542441685996

Epoch: 6| Step: 7
Training loss: 0.80299973487854
Validation loss: 2.1715904076894126

Epoch: 6| Step: 8
Training loss: 0.7291308641433716
Validation loss: 2.1731234590212503

Epoch: 6| Step: 9
Training loss: 1.3411054611206055
Validation loss: 2.147750278313955

Epoch: 6| Step: 10
Training loss: 0.4912033677101135
Validation loss: 2.1028374830881753

Epoch: 6| Step: 11
Training loss: 1.319242000579834
Validation loss: 2.162213663260142

Epoch: 6| Step: 12
Training loss: 1.214186191558838
Validation loss: 2.195202032725016

Epoch: 6| Step: 13
Training loss: 0.8440187573432922
Validation loss: 2.155027608076731

Epoch: 212| Step: 0
Training loss: 1.4753639698028564
Validation loss: 2.099441329638163

Epoch: 6| Step: 1
Training loss: 0.6680794358253479
Validation loss: 2.0855212012926736

Epoch: 6| Step: 2
Training loss: 0.5751908421516418
Validation loss: 2.118590990702311

Epoch: 6| Step: 3
Training loss: 0.5203991532325745
Validation loss: 2.172593832015991

Epoch: 6| Step: 4
Training loss: 0.7187613844871521
Validation loss: 2.1059648593266806

Epoch: 6| Step: 5
Training loss: 1.3377381563186646
Validation loss: 2.149023791154226

Epoch: 6| Step: 6
Training loss: 0.8703302145004272
Validation loss: 2.0926411747932434

Epoch: 6| Step: 7
Training loss: 0.9680856466293335
Validation loss: 2.105174442132314

Epoch: 6| Step: 8
Training loss: 1.5119140148162842
Validation loss: 2.1442102591196694

Epoch: 6| Step: 9
Training loss: 0.6576765775680542
Validation loss: 2.1058270931243896

Epoch: 6| Step: 10
Training loss: 1.0679347515106201
Validation loss: 2.121688644091288

Epoch: 6| Step: 11
Training loss: 0.8127548694610596
Validation loss: 2.1221789916356406

Epoch: 6| Step: 12
Training loss: 0.48973071575164795
Validation loss: 2.1683711608250937

Epoch: 6| Step: 13
Training loss: 0.5748669505119324
Validation loss: 2.115991711616516

Epoch: 213| Step: 0
Training loss: 0.8562401533126831
Validation loss: 2.195979634920756

Epoch: 6| Step: 1
Training loss: 1.1388013362884521
Validation loss: 2.164062738418579

Epoch: 6| Step: 2
Training loss: 1.3646495342254639
Validation loss: 2.1655848622322083

Epoch: 6| Step: 3
Training loss: 1.0638427734375
Validation loss: 2.145917514959971

Epoch: 6| Step: 4
Training loss: 0.9141919612884521
Validation loss: 2.0963703393936157

Epoch: 6| Step: 5
Training loss: 0.7689701914787292
Validation loss: 2.1295987168947854

Epoch: 6| Step: 6
Training loss: 0.5732491612434387
Validation loss: 2.1247555017471313

Epoch: 6| Step: 7
Training loss: 0.5550456643104553
Validation loss: 2.103948175907135

Epoch: 6| Step: 8
Training loss: 0.7027584910392761
Validation loss: 2.098684549331665

Epoch: 6| Step: 9
Training loss: 0.7075912952423096
Validation loss: 2.1582343379656472

Epoch: 6| Step: 10
Training loss: 0.773078203201294
Validation loss: 2.110434591770172

Epoch: 6| Step: 11
Training loss: 1.1116914749145508
Validation loss: 2.154943029085795

Epoch: 6| Step: 12
Training loss: 0.8906776309013367
Validation loss: 2.1265899538993835

Epoch: 6| Step: 13
Training loss: 0.8375743627548218
Validation loss: 2.1663800279299417

Epoch: 214| Step: 0
Training loss: 0.515200674533844
Validation loss: 2.1795848608016968

Epoch: 6| Step: 1
Training loss: 0.9889096021652222
Validation loss: 2.1763293544451394

Epoch: 6| Step: 2
Training loss: 0.810759425163269
Validation loss: 2.141966958840688

Epoch: 6| Step: 3
Training loss: 1.140801191329956
Validation loss: 2.1098239024480185

Epoch: 6| Step: 4
Training loss: 0.7110356688499451
Validation loss: 2.181759238243103

Epoch: 6| Step: 5
Training loss: 0.673293948173523
Validation loss: 2.1796592076619468

Epoch: 6| Step: 6
Training loss: 0.9303313493728638
Validation loss: 2.166375537713369

Epoch: 6| Step: 7
Training loss: 1.2331634759902954
Validation loss: 2.135144591331482

Epoch: 6| Step: 8
Training loss: 0.9910229444503784
Validation loss: 2.092627684275309

Epoch: 6| Step: 9
Training loss: 0.9145359992980957
Validation loss: 2.1316579778989158

Epoch: 6| Step: 10
Training loss: 0.8280752897262573
Validation loss: 2.1638219952583313

Epoch: 6| Step: 11
Training loss: 0.6274280548095703
Validation loss: 2.1558233499526978

Epoch: 6| Step: 12
Training loss: 0.7248931527137756
Validation loss: 2.170994977156321

Epoch: 6| Step: 13
Training loss: 1.3236960172653198
Validation loss: 2.1529735128084817

Epoch: 215| Step: 0
Training loss: 1.0668134689331055
Validation loss: 2.1300066113471985

Epoch: 6| Step: 1
Training loss: 1.1123735904693604
Validation loss: 2.1850174268086753

Epoch: 6| Step: 2
Training loss: 0.7857143878936768
Validation loss: 2.2169601917266846

Epoch: 6| Step: 3
Training loss: 0.7997252941131592
Validation loss: 2.1902935902277627

Epoch: 6| Step: 4
Training loss: 0.9198868274688721
Validation loss: 2.1426828900973

Epoch: 6| Step: 5
Training loss: 0.8353033661842346
Validation loss: 2.153084715207418

Epoch: 6| Step: 6
Training loss: 1.2521262168884277
Validation loss: 2.1276111205418906

Epoch: 6| Step: 7
Training loss: 0.660254716873169
Validation loss: 2.149915417035421

Epoch: 6| Step: 8
Training loss: 0.5941809415817261
Validation loss: 2.081538120905558

Epoch: 6| Step: 9
Training loss: 0.6639325618743896
Validation loss: 2.128552556037903

Epoch: 6| Step: 10
Training loss: 0.9354671239852905
Validation loss: 2.138023058573405

Epoch: 6| Step: 11
Training loss: 1.0613288879394531
Validation loss: 2.1059200763702393

Epoch: 6| Step: 12
Training loss: 0.9024837017059326
Validation loss: 2.1424946586290994

Epoch: 6| Step: 13
Training loss: 0.9041100740432739
Validation loss: 2.14211368560791

Epoch: 216| Step: 0
Training loss: 0.7568651437759399
Validation loss: 2.1853612860043845

Epoch: 6| Step: 1
Training loss: 0.8076385259628296
Validation loss: 2.2249093055725098

Epoch: 6| Step: 2
Training loss: 0.8619076013565063
Validation loss: 2.168454587459564

Epoch: 6| Step: 3
Training loss: 0.9633231163024902
Validation loss: 2.137866655985514

Epoch: 6| Step: 4
Training loss: 0.6496229767799377
Validation loss: 2.1389416257540383

Epoch: 6| Step: 5
Training loss: 0.6005563735961914
Validation loss: 2.110366622606913

Epoch: 6| Step: 6
Training loss: 0.9465214014053345
Validation loss: 2.178435424963633

Epoch: 6| Step: 7
Training loss: 0.7616033554077148
Validation loss: 2.179673751195272

Epoch: 6| Step: 8
Training loss: 1.1996586322784424
Validation loss: 2.1683977047602334

Epoch: 6| Step: 9
Training loss: 0.673791766166687
Validation loss: 2.1278538902600608

Epoch: 6| Step: 10
Training loss: 1.078080177307129
Validation loss: 2.1126173734664917

Epoch: 6| Step: 11
Training loss: 0.6272315979003906
Validation loss: 2.137588699658712

Epoch: 6| Step: 12
Training loss: 1.177802562713623
Validation loss: 2.197882970174154

Epoch: 6| Step: 13
Training loss: 1.2953588962554932
Validation loss: 2.1482455333073935

Epoch: 217| Step: 0
Training loss: 0.7394185066223145
Validation loss: 2.214133858680725

Epoch: 6| Step: 1
Training loss: 1.3164430856704712
Validation loss: 2.1752222180366516

Epoch: 6| Step: 2
Training loss: 0.7374545335769653
Validation loss: 2.133829712867737

Epoch: 6| Step: 3
Training loss: 1.6983187198638916
Validation loss: 2.155515750249227

Epoch: 6| Step: 4
Training loss: 0.6399708986282349
Validation loss: 2.1164452830950418

Epoch: 6| Step: 5
Training loss: 1.1079442501068115
Validation loss: 2.148817320664724

Epoch: 6| Step: 6
Training loss: 0.8445684909820557
Validation loss: 2.1071197191874185

Epoch: 6| Step: 7
Training loss: 0.5521331429481506
Validation loss: 2.136502424875895

Epoch: 6| Step: 8
Training loss: 0.908950686454773
Validation loss: 2.1196486949920654

Epoch: 6| Step: 9
Training loss: 0.7793557643890381
Validation loss: 2.067705452442169

Epoch: 6| Step: 10
Training loss: 0.8229356408119202
Validation loss: 2.0955336689949036

Epoch: 6| Step: 11
Training loss: 0.5609018802642822
Validation loss: 2.113751252492269

Epoch: 6| Step: 12
Training loss: 0.7902481555938721
Validation loss: 2.1249144077301025

Epoch: 6| Step: 13
Training loss: 0.8501249551773071
Validation loss: 2.1470258831977844

Epoch: 218| Step: 0
Training loss: 1.0698548555374146
Validation loss: 2.157101015249888

Epoch: 6| Step: 1
Training loss: 1.185876727104187
Validation loss: 2.186931053797404

Epoch: 6| Step: 2
Training loss: 1.2706351280212402
Validation loss: 2.1907779574394226

Epoch: 6| Step: 3
Training loss: 0.4480234384536743
Validation loss: 2.1765113274256387

Epoch: 6| Step: 4
Training loss: 1.2572839260101318
Validation loss: 2.1855974992116294

Epoch: 6| Step: 5
Training loss: 0.5596409440040588
Validation loss: 2.1562776962916055

Epoch: 6| Step: 6
Training loss: 0.9658327102661133
Validation loss: 2.146609663963318

Epoch: 6| Step: 7
Training loss: 0.5806428790092468
Validation loss: 2.136540412902832

Epoch: 6| Step: 8
Training loss: 0.7550890445709229
Validation loss: 2.1514039238293967

Epoch: 6| Step: 9
Training loss: 0.8992023468017578
Validation loss: 2.116034229596456

Epoch: 6| Step: 10
Training loss: 1.2858784198760986
Validation loss: 2.154305378595988

Epoch: 6| Step: 11
Training loss: 0.8582260608673096
Validation loss: 2.154072026411692

Epoch: 6| Step: 12
Training loss: 0.552871584892273
Validation loss: 2.131333669026693

Epoch: 6| Step: 13
Training loss: 0.5047270059585571
Validation loss: 2.1010477542877197

Epoch: 219| Step: 0
Training loss: 0.6956048011779785
Validation loss: 2.1161305904388428

Epoch: 6| Step: 1
Training loss: 0.9268389344215393
Validation loss: 2.122588356335958

Epoch: 6| Step: 2
Training loss: 0.9616550207138062
Validation loss: 2.2350589434305825

Epoch: 6| Step: 3
Training loss: 0.6318711638450623
Validation loss: 2.149429500102997

Epoch: 6| Step: 4
Training loss: 0.4515596926212311
Validation loss: 2.167910913626353

Epoch: 6| Step: 5
Training loss: 0.8924335837364197
Validation loss: 2.1450899640719094

Epoch: 6| Step: 6
Training loss: 0.9857738614082336
Validation loss: 2.1576450069745383

Epoch: 6| Step: 7
Training loss: 0.8557560443878174
Validation loss: 2.1504337390263877

Epoch: 6| Step: 8
Training loss: 1.0195951461791992
Validation loss: 2.104248265425364

Epoch: 6| Step: 9
Training loss: 0.9220511317253113
Validation loss: 2.0484607418378196

Epoch: 6| Step: 10
Training loss: 0.9249311685562134
Validation loss: 2.145200729370117

Epoch: 6| Step: 11
Training loss: 0.8252702951431274
Validation loss: 2.1149299144744873

Epoch: 6| Step: 12
Training loss: 1.2990949153900146
Validation loss: 2.145431160926819

Epoch: 6| Step: 13
Training loss: 0.7538715600967407
Validation loss: 2.0976961255073547

Epoch: 220| Step: 0
Training loss: 0.6637792587280273
Validation loss: 2.1951744755109153

Epoch: 6| Step: 1
Training loss: 0.8274705410003662
Validation loss: 2.2053675055503845

Epoch: 6| Step: 2
Training loss: 0.4437275528907776
Validation loss: 2.1275297005971274

Epoch: 6| Step: 3
Training loss: 0.6501522064208984
Validation loss: 2.1340166330337524

Epoch: 6| Step: 4
Training loss: 0.9663805961608887
Validation loss: 2.079276522000631

Epoch: 6| Step: 5
Training loss: 0.6210795640945435
Validation loss: 2.1325661540031433

Epoch: 6| Step: 6
Training loss: 0.5463201999664307
Validation loss: 2.130471388498942

Epoch: 6| Step: 7
Training loss: 0.8365815877914429
Validation loss: 2.0769165555636087

Epoch: 6| Step: 8
Training loss: 0.7234678864479065
Validation loss: 2.1251897613207498

Epoch: 6| Step: 9
Training loss: 0.9556317329406738
Validation loss: 2.1108864744504294

Epoch: 6| Step: 10
Training loss: 1.5279414653778076
Validation loss: 2.1778162519137063

Epoch: 6| Step: 11
Training loss: 0.8201335668563843
Validation loss: 2.121289153893789

Epoch: 6| Step: 12
Training loss: 1.072972297668457
Validation loss: 2.1319334705670676

Epoch: 6| Step: 13
Training loss: 0.6823099851608276
Validation loss: 2.185481071472168

Epoch: 221| Step: 0
Training loss: 0.7186197638511658
Validation loss: 2.232781410217285

Epoch: 6| Step: 1
Training loss: 0.8650431632995605
Validation loss: 2.1657166679700217

Epoch: 6| Step: 2
Training loss: 1.267173409461975
Validation loss: 2.15300190448761

Epoch: 6| Step: 3
Training loss: 0.7572857141494751
Validation loss: 2.199303150177002

Epoch: 6| Step: 4
Training loss: 0.8701614141464233
Validation loss: 2.171221395333608

Epoch: 6| Step: 5
Training loss: 0.8158556222915649
Validation loss: 2.1574820478757224

Epoch: 6| Step: 6
Training loss: 0.708781361579895
Validation loss: 2.109613617261251

Epoch: 6| Step: 7
Training loss: 1.143384575843811
Validation loss: 2.0724387566248574

Epoch: 6| Step: 8
Training loss: 0.830930769443512
Validation loss: 2.130001207192739

Epoch: 6| Step: 9
Training loss: 0.712303638458252
Validation loss: 2.136184811592102

Epoch: 6| Step: 10
Training loss: 0.5203315019607544
Validation loss: 2.0873599648475647

Epoch: 6| Step: 11
Training loss: 0.8779796361923218
Validation loss: 2.155456066131592

Epoch: 6| Step: 12
Training loss: 0.7626175880432129
Validation loss: 2.112897594769796

Epoch: 6| Step: 13
Training loss: 0.9528606534004211
Validation loss: 2.110585709412893

Epoch: 222| Step: 0
Training loss: 0.6919605135917664
Validation loss: 2.0588178435961404

Epoch: 6| Step: 1
Training loss: 0.5329791903495789
Validation loss: 2.0927885373433432

Epoch: 6| Step: 2
Training loss: 0.7495591640472412
Validation loss: 2.131071905295054

Epoch: 6| Step: 3
Training loss: 1.0228132009506226
Validation loss: 2.1387184460957847

Epoch: 6| Step: 4
Training loss: 0.8356132507324219
Validation loss: 2.1416582266489663

Epoch: 6| Step: 5
Training loss: 0.4488410949707031
Validation loss: 2.1668681303660073

Epoch: 6| Step: 6
Training loss: 1.1080800294876099
Validation loss: 2.1009902556737265

Epoch: 6| Step: 7
Training loss: 0.7980294227600098
Validation loss: 2.0724976460138955

Epoch: 6| Step: 8
Training loss: 0.9294342994689941
Validation loss: 2.1622157096862793

Epoch: 6| Step: 9
Training loss: 1.163012981414795
Validation loss: 2.0791297356287637

Epoch: 6| Step: 10
Training loss: 0.8073819875717163
Validation loss: 2.134010672569275

Epoch: 6| Step: 11
Training loss: 0.7423893809318542
Validation loss: 2.177421232064565

Epoch: 6| Step: 12
Training loss: 0.5619118213653564
Validation loss: 2.155259648958842

Epoch: 6| Step: 13
Training loss: 1.1784528493881226
Validation loss: 2.109148999055227

Epoch: 223| Step: 0
Training loss: 0.8265689015388489
Validation loss: 2.1409385005633035

Epoch: 6| Step: 1
Training loss: 0.6252644062042236
Validation loss: 2.182278871536255

Epoch: 6| Step: 2
Training loss: 1.5135456323623657
Validation loss: 2.092037002245585

Epoch: 6| Step: 3
Training loss: 1.10196852684021
Validation loss: 2.1945753693580627

Epoch: 6| Step: 4
Training loss: 0.6411613821983337
Validation loss: 2.107593615849813

Epoch: 6| Step: 5
Training loss: 0.8865693211555481
Validation loss: 2.102265218893687

Epoch: 6| Step: 6
Training loss: 0.645796537399292
Validation loss: 2.140775760014852

Epoch: 6| Step: 7
Training loss: 0.6975961327552795
Validation loss: 2.1101548274358115

Epoch: 6| Step: 8
Training loss: 0.7216784954071045
Validation loss: 2.09493358929952

Epoch: 6| Step: 9
Training loss: 1.3233304023742676
Validation loss: 2.198110580444336

Epoch: 6| Step: 10
Training loss: 1.0110504627227783
Validation loss: 2.119740088780721

Epoch: 6| Step: 11
Training loss: 0.7398058772087097
Validation loss: 2.178335984547933

Epoch: 6| Step: 12
Training loss: 0.5360179543495178
Validation loss: 2.154987315336863

Epoch: 6| Step: 13
Training loss: 0.807029664516449
Validation loss: 2.1607542037963867

Epoch: 224| Step: 0
Training loss: 1.0251975059509277
Validation loss: 2.1338443557421365

Epoch: 6| Step: 1
Training loss: 0.8496562838554382
Validation loss: 2.2160075108210244

Epoch: 6| Step: 2
Training loss: 0.7942934632301331
Validation loss: 2.1555961767832437

Epoch: 6| Step: 3
Training loss: 1.4701989889144897
Validation loss: 2.113577723503113

Epoch: 6| Step: 4
Training loss: 0.5301928520202637
Validation loss: 2.0723007122675576

Epoch: 6| Step: 5
Training loss: 0.8790358304977417
Validation loss: 2.113721172014872

Epoch: 6| Step: 6
Training loss: 0.4977465271949768
Validation loss: 2.1014565428098044

Epoch: 6| Step: 7
Training loss: 0.9840139150619507
Validation loss: 2.0914957920710244

Epoch: 6| Step: 8
Training loss: 0.8021862506866455
Validation loss: 2.1901283462842307

Epoch: 6| Step: 9
Training loss: 0.6976608037948608
Validation loss: 2.1474572022755942

Epoch: 6| Step: 10
Training loss: 0.8938160538673401
Validation loss: 2.19311793645223

Epoch: 6| Step: 11
Training loss: 0.6417449712753296
Validation loss: 2.135286351044973

Epoch: 6| Step: 12
Training loss: 0.5976942777633667
Validation loss: 2.134079317251841

Epoch: 6| Step: 13
Training loss: 1.2033777236938477
Validation loss: 2.196752369403839

Epoch: 225| Step: 0
Training loss: 1.1758501529693604
Validation loss: 2.1615238189697266

Epoch: 6| Step: 1
Training loss: 1.1249217987060547
Validation loss: 2.1298169096310935

Epoch: 6| Step: 2
Training loss: 0.8603662252426147
Validation loss: 2.1600168744723

Epoch: 6| Step: 3
Training loss: 1.3011914491653442
Validation loss: 2.141538838545481

Epoch: 6| Step: 4
Training loss: 0.5874558091163635
Validation loss: 2.1652477184931436

Epoch: 6| Step: 5
Training loss: 0.7058711051940918
Validation loss: 2.0655370553334556

Epoch: 6| Step: 6
Training loss: 1.4708271026611328
Validation loss: 2.093801478544871

Epoch: 6| Step: 7
Training loss: 0.8635827898979187
Validation loss: 2.0832838217417398

Epoch: 6| Step: 8
Training loss: 0.9258501529693604
Validation loss: 2.1455180446306863

Epoch: 6| Step: 9
Training loss: 0.6715611815452576
Validation loss: 2.106762190659841

Epoch: 6| Step: 10
Training loss: 1.1847535371780396
Validation loss: 2.1618125438690186

Epoch: 6| Step: 11
Training loss: 0.6604766845703125
Validation loss: 2.1551443139712014

Epoch: 6| Step: 12
Training loss: 0.7442029714584351
Validation loss: 2.2371567686398826

Epoch: 6| Step: 13
Training loss: 0.6905632615089417
Validation loss: 2.1806671222050986

Epoch: 226| Step: 0
Training loss: 0.9733917117118835
Validation loss: 2.1660408973693848

Epoch: 6| Step: 1
Training loss: 0.9279100298881531
Validation loss: 2.152884006500244

Epoch: 6| Step: 2
Training loss: 0.682029128074646
Validation loss: 2.1652709444363913

Epoch: 6| Step: 3
Training loss: 0.6929206848144531
Validation loss: 2.1999995907147727

Epoch: 6| Step: 4
Training loss: 0.9594377279281616
Validation loss: 2.1346481839815774

Epoch: 6| Step: 5
Training loss: 1.0810402631759644
Validation loss: 2.1574555039405823

Epoch: 6| Step: 6
Training loss: 0.8674285411834717
Validation loss: 2.1173507372538247

Epoch: 6| Step: 7
Training loss: 0.8048487305641174
Validation loss: 2.110646684964498

Epoch: 6| Step: 8
Training loss: 0.37145304679870605
Validation loss: 2.1543160676956177

Epoch: 6| Step: 9
Training loss: 0.8153124451637268
Validation loss: 2.145906448364258

Epoch: 6| Step: 10
Training loss: 1.050919532775879
Validation loss: 2.173731247584025

Epoch: 6| Step: 11
Training loss: 0.5429588556289673
Validation loss: 2.197768966356913

Epoch: 6| Step: 12
Training loss: 0.8223471641540527
Validation loss: 2.1882354418436685

Epoch: 6| Step: 13
Training loss: 0.9712588787078857
Validation loss: 2.2393142183621726

Epoch: 227| Step: 0
Training loss: 0.5754106640815735
Validation loss: 2.1914331118265786

Epoch: 6| Step: 1
Training loss: 0.41783225536346436
Validation loss: 2.14314599831899

Epoch: 6| Step: 2
Training loss: 0.6427225470542908
Validation loss: 2.16220885515213

Epoch: 6| Step: 3
Training loss: 0.9553879499435425
Validation loss: 2.088847557703654

Epoch: 6| Step: 4
Training loss: 0.6426007747650146
Validation loss: 2.06878662109375

Epoch: 6| Step: 5
Training loss: 0.8630001544952393
Validation loss: 2.173499862353007

Epoch: 6| Step: 6
Training loss: 0.5482882261276245
Validation loss: 2.14449934164683

Epoch: 6| Step: 7
Training loss: 1.1229292154312134
Validation loss: 2.081425726413727

Epoch: 6| Step: 8
Training loss: 1.2599678039550781
Validation loss: 2.0867852171262107

Epoch: 6| Step: 9
Training loss: 0.5588433742523193
Validation loss: 2.1589375138282776

Epoch: 6| Step: 10
Training loss: 0.6523114442825317
Validation loss: 2.1347087025642395

Epoch: 6| Step: 11
Training loss: 0.9713842272758484
Validation loss: 2.1655263900756836

Epoch: 6| Step: 12
Training loss: 0.7575779557228088
Validation loss: 2.180055638154348

Epoch: 6| Step: 13
Training loss: 1.5855004787445068
Validation loss: 2.1458821296691895

Epoch: 228| Step: 0
Training loss: 0.6172424554824829
Validation loss: 2.084724545478821

Epoch: 6| Step: 1
Training loss: 0.5657336115837097
Validation loss: 2.1231678128242493

Epoch: 6| Step: 2
Training loss: 1.351745843887329
Validation loss: 2.0768345395723977

Epoch: 6| Step: 3
Training loss: 0.9901010990142822
Validation loss: 2.0849552750587463

Epoch: 6| Step: 4
Training loss: 0.5074558258056641
Validation loss: 2.124841590722402

Epoch: 6| Step: 5
Training loss: 1.460951805114746
Validation loss: 2.150803824265798

Epoch: 6| Step: 6
Training loss: 1.0913608074188232
Validation loss: 2.1432124972343445

Epoch: 6| Step: 7
Training loss: 0.6094280481338501
Validation loss: 2.163263181845347

Epoch: 6| Step: 8
Training loss: 0.6136411428451538
Validation loss: 2.166717211405436

Epoch: 6| Step: 9
Training loss: 0.6577948927879333
Validation loss: 2.1274653673171997

Epoch: 6| Step: 10
Training loss: 0.4856136441230774
Validation loss: 2.0880966186523438

Epoch: 6| Step: 11
Training loss: 0.9724861979484558
Validation loss: 2.140045086542765

Epoch: 6| Step: 12
Training loss: 0.8167961835861206
Validation loss: 2.0966742833455405

Epoch: 6| Step: 13
Training loss: 0.6095609664916992
Validation loss: 2.175531188646952

Epoch: 229| Step: 0
Training loss: 0.9946407675743103
Validation loss: 2.153903683026632

Epoch: 6| Step: 1
Training loss: 0.8293570280075073
Validation loss: 2.110286593437195

Epoch: 6| Step: 2
Training loss: 1.105977177619934
Validation loss: 2.1372653245925903

Epoch: 6| Step: 3
Training loss: 0.6538692712783813
Validation loss: 2.0888128081957498

Epoch: 6| Step: 4
Training loss: 0.5171021819114685
Validation loss: 2.087055047353109

Epoch: 6| Step: 5
Training loss: 0.7190399169921875
Validation loss: 2.084010640780131

Epoch: 6| Step: 6
Training loss: 0.8791555762290955
Validation loss: 2.1496514479319253

Epoch: 6| Step: 7
Training loss: 0.6745495796203613
Validation loss: 2.1815810998280845

Epoch: 6| Step: 8
Training loss: 0.7278079986572266
Validation loss: 2.13266259431839

Epoch: 6| Step: 9
Training loss: 0.6022545695304871
Validation loss: 2.0933380722999573

Epoch: 6| Step: 10
Training loss: 0.8063108921051025
Validation loss: 2.1259944836298623

Epoch: 6| Step: 11
Training loss: 0.7608597278594971
Validation loss: 2.164174516995748

Epoch: 6| Step: 12
Training loss: 0.911011815071106
Validation loss: 2.1263295809427896

Epoch: 6| Step: 13
Training loss: 1.24918532371521
Validation loss: 2.095749338467916

Epoch: 230| Step: 0
Training loss: 0.9412551522254944
Validation loss: 2.143040438493093

Epoch: 6| Step: 1
Training loss: 0.8517024517059326
Validation loss: 2.083177367846171

Epoch: 6| Step: 2
Training loss: 0.8769583702087402
Validation loss: 2.1740348736445108

Epoch: 6| Step: 3
Training loss: 0.8268786668777466
Validation loss: 2.1480232874552407

Epoch: 6| Step: 4
Training loss: 0.5375155210494995
Validation loss: 2.176897724469503

Epoch: 6| Step: 5
Training loss: 1.0465583801269531
Validation loss: 2.0950117111206055

Epoch: 6| Step: 6
Training loss: 0.8026924133300781
Validation loss: 2.148783266544342

Epoch: 6| Step: 7
Training loss: 0.46485763788223267
Validation loss: 2.2326922615369162

Epoch: 6| Step: 8
Training loss: 1.2681355476379395
Validation loss: 2.2097432216008506

Epoch: 6| Step: 9
Training loss: 0.6497046947479248
Validation loss: 2.178849935531616

Epoch: 6| Step: 10
Training loss: 0.7020459175109863
Validation loss: 2.125878095626831

Epoch: 6| Step: 11
Training loss: 1.194805383682251
Validation loss: 2.196245471636454

Epoch: 6| Step: 12
Training loss: 1.0292247533798218
Validation loss: 2.1119088331858316

Epoch: 6| Step: 13
Training loss: 0.9333999752998352
Validation loss: 2.0882620215415955

Epoch: 231| Step: 0
Training loss: 0.6790846586227417
Validation loss: 2.155494232972463

Epoch: 6| Step: 1
Training loss: 0.7277724742889404
Validation loss: 2.103617469469706

Epoch: 6| Step: 2
Training loss: 0.7956008315086365
Validation loss: 2.153812845547994

Epoch: 6| Step: 3
Training loss: 0.7344809770584106
Validation loss: 2.202479283014933

Epoch: 6| Step: 4
Training loss: 1.207493782043457
Validation loss: 2.162011981010437

Epoch: 6| Step: 5
Training loss: 0.6703310012817383
Validation loss: 2.137586156527201

Epoch: 6| Step: 6
Training loss: 0.7544974684715271
Validation loss: 2.1622765262921653

Epoch: 6| Step: 7
Training loss: 0.4732462465763092
Validation loss: 2.1189584533373513

Epoch: 6| Step: 8
Training loss: 0.9446600675582886
Validation loss: 2.1531811157862344

Epoch: 6| Step: 9
Training loss: 0.7756034135818481
Validation loss: 2.1178646087646484

Epoch: 6| Step: 10
Training loss: 1.0830886363983154
Validation loss: 2.1242065032323203

Epoch: 6| Step: 11
Training loss: 0.6502537727355957
Validation loss: 2.1811463832855225

Epoch: 6| Step: 12
Training loss: 0.6972852945327759
Validation loss: 2.1646581888198853

Epoch: 6| Step: 13
Training loss: 0.5057324767112732
Validation loss: 2.1550018588701882

Epoch: 232| Step: 0
Training loss: 0.5292079448699951
Validation loss: 2.148197889328003

Epoch: 6| Step: 1
Training loss: 0.7597855925559998
Validation loss: 2.13641095161438

Epoch: 6| Step: 2
Training loss: 0.5031333565711975
Validation loss: 2.1126071413358054

Epoch: 6| Step: 3
Training loss: 0.9452292919158936
Validation loss: 2.1481658021608987

Epoch: 6| Step: 4
Training loss: 0.9925892353057861
Validation loss: 2.1724085410435996

Epoch: 6| Step: 5
Training loss: 0.8018879890441895
Validation loss: 2.1486916740735373

Epoch: 6| Step: 6
Training loss: 0.8366760015487671
Validation loss: 2.113604267438253

Epoch: 6| Step: 7
Training loss: 0.6888158321380615
Validation loss: 2.1207264065742493

Epoch: 6| Step: 8
Training loss: 0.5966728925704956
Validation loss: 2.1076446374257407

Epoch: 6| Step: 9
Training loss: 0.6924496293067932
Validation loss: 2.1476203997929892

Epoch: 6| Step: 10
Training loss: 1.0389119386672974
Validation loss: 2.1111919482549033

Epoch: 6| Step: 11
Training loss: 0.8853658437728882
Validation loss: 2.120668033758799

Epoch: 6| Step: 12
Training loss: 0.7707852125167847
Validation loss: 2.0953595836957297

Epoch: 6| Step: 13
Training loss: 1.3017094135284424
Validation loss: 2.1308413545290628

Epoch: 233| Step: 0
Training loss: 1.3116705417633057
Validation loss: 2.1107943455378213

Epoch: 6| Step: 1
Training loss: 0.5125159621238708
Validation loss: 2.126842121283213

Epoch: 6| Step: 2
Training loss: 0.6287397146224976
Validation loss: 2.0909577012062073

Epoch: 6| Step: 3
Training loss: 0.815889835357666
Validation loss: 2.1539684534072876

Epoch: 6| Step: 4
Training loss: 0.6579921245574951
Validation loss: 2.109159270922343

Epoch: 6| Step: 5
Training loss: 0.8197310566902161
Validation loss: 2.1099600593249

Epoch: 6| Step: 6
Training loss: 0.6369901895523071
Validation loss: 2.149647613366445

Epoch: 6| Step: 7
Training loss: 0.8071954846382141
Validation loss: 2.161788503328959

Epoch: 6| Step: 8
Training loss: 0.8887211084365845
Validation loss: 2.1324275732040405

Epoch: 6| Step: 9
Training loss: 0.9381996393203735
Validation loss: 2.1713908910751343

Epoch: 6| Step: 10
Training loss: 0.9134637117385864
Validation loss: 2.1561551094055176

Epoch: 6| Step: 11
Training loss: 0.4743703603744507
Validation loss: 2.1683794458707175

Epoch: 6| Step: 12
Training loss: 0.8968938589096069
Validation loss: 2.095896899700165

Epoch: 6| Step: 13
Training loss: 0.6596786379814148
Validation loss: 2.1156898736953735

Epoch: 234| Step: 0
Training loss: 0.6223409175872803
Validation loss: 2.097106635570526

Epoch: 6| Step: 1
Training loss: 0.5338624715805054
Validation loss: 2.1544219056765237

Epoch: 6| Step: 2
Training loss: 0.8574540019035339
Validation loss: 2.102698802947998

Epoch: 6| Step: 3
Training loss: 0.8640946745872498
Validation loss: 2.0695307652155557

Epoch: 6| Step: 4
Training loss: 0.7919303178787231
Validation loss: 2.1022971073786416

Epoch: 6| Step: 5
Training loss: 0.6820815205574036
Validation loss: 2.1751769383748374

Epoch: 6| Step: 6
Training loss: 1.0898133516311646
Validation loss: 2.115718940893809

Epoch: 6| Step: 7
Training loss: 0.7094221115112305
Validation loss: 2.136348843574524

Epoch: 6| Step: 8
Training loss: 0.9271121025085449
Validation loss: 2.1311272184054055

Epoch: 6| Step: 9
Training loss: 1.0069783926010132
Validation loss: 2.129750351111094

Epoch: 6| Step: 10
Training loss: 1.0081110000610352
Validation loss: 2.1208250919977822

Epoch: 6| Step: 11
Training loss: 0.713651180267334
Validation loss: 2.1628315250078836

Epoch: 6| Step: 12
Training loss: 0.3772008419036865
Validation loss: 2.144705832004547

Epoch: 6| Step: 13
Training loss: 0.873954176902771
Validation loss: 2.17050568262736

Epoch: 235| Step: 0
Training loss: 1.1026626825332642
Validation loss: 2.130465845266978

Epoch: 6| Step: 1
Training loss: 1.0612585544586182
Validation loss: 2.2107460300127664

Epoch: 6| Step: 2
Training loss: 0.9714093804359436
Validation loss: 2.148401161034902

Epoch: 6| Step: 3
Training loss: 0.8602086305618286
Validation loss: 2.1329867243766785

Epoch: 6| Step: 4
Training loss: 0.41693824529647827
Validation loss: 2.137257436911265

Epoch: 6| Step: 5
Training loss: 0.6317988038063049
Validation loss: 2.1301686763763428

Epoch: 6| Step: 6
Training loss: 0.5823192596435547
Validation loss: 2.1188513239224753

Epoch: 6| Step: 7
Training loss: 0.9604777097702026
Validation loss: 2.1519815325737

Epoch: 6| Step: 8
Training loss: 0.4425233006477356
Validation loss: 2.1515868306159973

Epoch: 6| Step: 9
Training loss: 1.3317842483520508
Validation loss: 2.1079440911610923

Epoch: 6| Step: 10
Training loss: 0.624106228351593
Validation loss: 2.126660923163096

Epoch: 6| Step: 11
Training loss: 0.7129871845245361
Validation loss: 2.151251435279846

Epoch: 6| Step: 12
Training loss: 0.201716810464859
Validation loss: 2.0938808917999268

Epoch: 6| Step: 13
Training loss: 0.7575615048408508
Validation loss: 2.1134080290794373

Epoch: 236| Step: 0
Training loss: 0.5604791641235352
Validation loss: 2.196585218111674

Epoch: 6| Step: 1
Training loss: 0.41963285207748413
Validation loss: 2.1430150866508484

Epoch: 6| Step: 2
Training loss: 0.8705061674118042
Validation loss: 2.173669079939524

Epoch: 6| Step: 3
Training loss: 0.5497747659683228
Validation loss: 2.1059482097625732

Epoch: 6| Step: 4
Training loss: 0.5733022093772888
Validation loss: 2.185457944869995

Epoch: 6| Step: 5
Training loss: 0.956831693649292
Validation loss: 2.150809188683828

Epoch: 6| Step: 6
Training loss: 0.48502159118652344
Validation loss: 2.1605905095736184

Epoch: 6| Step: 7
Training loss: 0.8865171074867249
Validation loss: 2.136971195538839

Epoch: 6| Step: 8
Training loss: 1.3639849424362183
Validation loss: 2.1620195706685386

Epoch: 6| Step: 9
Training loss: 0.5708609819412231
Validation loss: 2.1654958526293435

Epoch: 6| Step: 10
Training loss: 0.39728033542633057
Validation loss: 2.185278515021006

Epoch: 6| Step: 11
Training loss: 0.6396449208259583
Validation loss: 2.1562994718551636

Epoch: 6| Step: 12
Training loss: 1.4029853343963623
Validation loss: 2.185399850209554

Epoch: 6| Step: 13
Training loss: 0.914600133895874
Validation loss: 2.187135954697927

Epoch: 237| Step: 0
Training loss: 0.2759471535682678
Validation loss: 2.105456550916036

Epoch: 6| Step: 1
Training loss: 0.7440353035926819
Validation loss: 2.153830587863922

Epoch: 6| Step: 2
Training loss: 0.7642673254013062
Validation loss: 2.148817777633667

Epoch: 6| Step: 3
Training loss: 0.5176252126693726
Validation loss: 2.142062505086263

Epoch: 6| Step: 4
Training loss: 0.5342981815338135
Validation loss: 2.1655189593633017

Epoch: 6| Step: 5
Training loss: 0.7745437622070312
Validation loss: 2.1544950008392334

Epoch: 6| Step: 6
Training loss: 1.5146441459655762
Validation loss: 2.0836495955785117

Epoch: 6| Step: 7
Training loss: 1.0194745063781738
Validation loss: 2.102086385091146

Epoch: 6| Step: 8
Training loss: 0.588418185710907
Validation loss: 2.0955045421918235

Epoch: 6| Step: 9
Training loss: 1.3871545791625977
Validation loss: 2.164802392323812

Epoch: 6| Step: 10
Training loss: 0.871427059173584
Validation loss: 2.110255221525828

Epoch: 6| Step: 11
Training loss: 1.1985782384872437
Validation loss: 2.195595602194468

Epoch: 6| Step: 12
Training loss: 0.8019028902053833
Validation loss: 2.1786974668502808

Epoch: 6| Step: 13
Training loss: 0.6858549118041992
Validation loss: 2.1260109345118203

Epoch: 238| Step: 0
Training loss: 0.9792465567588806
Validation loss: 2.099710841973623

Epoch: 6| Step: 1
Training loss: 0.7104238271713257
Validation loss: 2.095074415206909

Epoch: 6| Step: 2
Training loss: 0.6266742944717407
Validation loss: 2.148307760556539

Epoch: 6| Step: 3
Training loss: 0.9004181027412415
Validation loss: 2.1544522047042847

Epoch: 6| Step: 4
Training loss: 0.8146613240242004
Validation loss: 2.1150313218434653

Epoch: 6| Step: 5
Training loss: 0.5193449854850769
Validation loss: 2.0885282357533774

Epoch: 6| Step: 6
Training loss: 0.5362458825111389
Validation loss: 2.137729605038961

Epoch: 6| Step: 7
Training loss: 0.8969142436981201
Validation loss: 2.181147356828054

Epoch: 6| Step: 8
Training loss: 0.7303111553192139
Validation loss: 2.1812111934026084

Epoch: 6| Step: 9
Training loss: 1.094093918800354
Validation loss: 2.2033381859461465

Epoch: 6| Step: 10
Training loss: 1.3700203895568848
Validation loss: 2.1780643264452615

Epoch: 6| Step: 11
Training loss: 0.7549713253974915
Validation loss: 2.120610018571218

Epoch: 6| Step: 12
Training loss: 0.8456943035125732
Validation loss: 2.1655333240826926

Epoch: 6| Step: 13
Training loss: 0.7792001962661743
Validation loss: 2.1159085830052695

Epoch: 239| Step: 0
Training loss: 0.7558286190032959
Validation loss: 2.1467625896135965

Epoch: 6| Step: 1
Training loss: 1.014208436012268
Validation loss: 2.09233687321345

Epoch: 6| Step: 2
Training loss: 0.6009663343429565
Validation loss: 2.085293193658193

Epoch: 6| Step: 3
Training loss: 0.9297100305557251
Validation loss: 2.092252711455027

Epoch: 6| Step: 4
Training loss: 0.6848537921905518
Validation loss: 2.0980714162190757

Epoch: 6| Step: 5
Training loss: 0.9294376373291016
Validation loss: 2.1162997484207153

Epoch: 6| Step: 6
Training loss: 1.1631907224655151
Validation loss: 2.108377913633982

Epoch: 6| Step: 7
Training loss: 0.672844648361206
Validation loss: 2.134563148021698

Epoch: 6| Step: 8
Training loss: 0.6621042490005493
Validation loss: 2.1328867077827454

Epoch: 6| Step: 9
Training loss: 1.163750410079956
Validation loss: 2.1429513096809387

Epoch: 6| Step: 10
Training loss: 0.5517762303352356
Validation loss: 2.145159145196279

Epoch: 6| Step: 11
Training loss: 1.1170166730880737
Validation loss: 2.169282853603363

Epoch: 6| Step: 12
Training loss: 0.415147989988327
Validation loss: 2.1330599387486777

Epoch: 6| Step: 13
Training loss: 0.592491865158081
Validation loss: 2.116752326488495

Epoch: 240| Step: 0
Training loss: 0.9426982998847961
Validation loss: 2.076103130976359

Epoch: 6| Step: 1
Training loss: 0.9407600164413452
Validation loss: 2.1529570817947388

Epoch: 6| Step: 2
Training loss: 0.33664512634277344
Validation loss: 2.165377696355184

Epoch: 6| Step: 3
Training loss: 0.9020823836326599
Validation loss: 2.0869230031967163

Epoch: 6| Step: 4
Training loss: 0.5029966235160828
Validation loss: 2.16997359196345

Epoch: 6| Step: 5
Training loss: 0.6509509086608887
Validation loss: 2.1400376558303833

Epoch: 6| Step: 6
Training loss: 1.2713149785995483
Validation loss: 2.150022288163503

Epoch: 6| Step: 7
Training loss: 0.7920594811439514
Validation loss: 2.095088799794515

Epoch: 6| Step: 8
Training loss: 0.44137442111968994
Validation loss: 2.1475994984308877

Epoch: 6| Step: 9
Training loss: 0.8478475213050842
Validation loss: 2.0912272135416665

Epoch: 6| Step: 10
Training loss: 0.5048201084136963
Validation loss: 2.1462318897247314

Epoch: 6| Step: 11
Training loss: 1.1236598491668701
Validation loss: 2.0928834875424704

Epoch: 6| Step: 12
Training loss: 1.2878340482711792
Validation loss: 2.0425472259521484

Epoch: 6| Step: 13
Training loss: 0.6403160691261292
Validation loss: 2.112203359603882

Epoch: 241| Step: 0
Training loss: 1.1314258575439453
Validation loss: 2.1772659619649253

Epoch: 6| Step: 1
Training loss: 0.6621663570404053
Validation loss: 2.141380170981089

Epoch: 6| Step: 2
Training loss: 0.5748330950737
Validation loss: 2.1125240524609885

Epoch: 6| Step: 3
Training loss: 0.7496113777160645
Validation loss: 2.161962389945984

Epoch: 6| Step: 4
Training loss: 0.7526533603668213
Validation loss: 2.1331296960512796

Epoch: 6| Step: 5
Training loss: 0.9216229915618896
Validation loss: 2.079431692759196

Epoch: 6| Step: 6
Training loss: 0.7295580506324768
Validation loss: 2.0961183508237204

Epoch: 6| Step: 7
Training loss: 0.5673714876174927
Validation loss: 2.1401522556940713

Epoch: 6| Step: 8
Training loss: 0.6519631147384644
Validation loss: 2.1054985324541726

Epoch: 6| Step: 9
Training loss: 1.5307074785232544
Validation loss: 2.1539528568585715

Epoch: 6| Step: 10
Training loss: 0.7727879285812378
Validation loss: 2.111839314301809

Epoch: 6| Step: 11
Training loss: 0.7348133325576782
Validation loss: 2.1343372464179993

Epoch: 6| Step: 12
Training loss: 0.5740719437599182
Validation loss: 2.125290095806122

Epoch: 6| Step: 13
Training loss: 0.4192275404930115
Validation loss: 2.096212685108185

Epoch: 242| Step: 0
Training loss: 1.08267080783844
Validation loss: 2.077268123626709

Epoch: 6| Step: 1
Training loss: 0.7254226803779602
Validation loss: 2.1268213589986167

Epoch: 6| Step: 2
Training loss: 0.6985766887664795
Validation loss: 2.1655909419059753

Epoch: 6| Step: 3
Training loss: 0.5988359451293945
Validation loss: 2.124963899453481

Epoch: 6| Step: 4
Training loss: 1.4633567333221436
Validation loss: 2.1990532279014587

Epoch: 6| Step: 5
Training loss: 0.6016103029251099
Validation loss: 2.219076414903005

Epoch: 6| Step: 6
Training loss: 0.8244511485099792
Validation loss: 2.119254211584727

Epoch: 6| Step: 7
Training loss: 1.5316884517669678
Validation loss: 2.132680654525757

Epoch: 6| Step: 8
Training loss: 0.6783291101455688
Validation loss: 2.12367312113444

Epoch: 6| Step: 9
Training loss: 0.3825790286064148
Validation loss: 2.1429043213526406

Epoch: 6| Step: 10
Training loss: 0.49980270862579346
Validation loss: 2.1916543443997702

Epoch: 6| Step: 11
Training loss: 0.4298698902130127
Validation loss: 2.197746455669403

Epoch: 6| Step: 12
Training loss: 0.3453872501850128
Validation loss: 2.1245219111442566

Epoch: 6| Step: 13
Training loss: 0.49512413144111633
Validation loss: 2.158675730228424

Epoch: 243| Step: 0
Training loss: 0.8847261667251587
Validation loss: 2.1541335185368857

Epoch: 6| Step: 1
Training loss: 0.7540106773376465
Validation loss: 2.166399876276652

Epoch: 6| Step: 2
Training loss: 0.5080200433731079
Validation loss: 2.1236581007639566

Epoch: 6| Step: 3
Training loss: 1.0099022388458252
Validation loss: 2.1028934915860495

Epoch: 6| Step: 4
Training loss: 1.12984037399292
Validation loss: 2.109003186225891

Epoch: 6| Step: 5
Training loss: 0.5807321071624756
Validation loss: 2.125749349594116

Epoch: 6| Step: 6
Training loss: 0.6578999757766724
Validation loss: 2.092366635799408

Epoch: 6| Step: 7
Training loss: 0.875105619430542
Validation loss: 2.116746962070465

Epoch: 6| Step: 8
Training loss: 0.9098079204559326
Validation loss: 2.102185924847921

Epoch: 6| Step: 9
Training loss: 0.8718699216842651
Validation loss: 2.1230921745300293

Epoch: 6| Step: 10
Training loss: 0.7343530654907227
Validation loss: 2.1622482538223267

Epoch: 6| Step: 11
Training loss: 0.5275906920433044
Validation loss: 2.151317278544108

Epoch: 6| Step: 12
Training loss: 0.9036164283752441
Validation loss: 2.136711915334066

Epoch: 6| Step: 13
Training loss: 0.6450154781341553
Validation loss: 2.1750706831614175

Epoch: 244| Step: 0
Training loss: 0.4395344853401184
Validation loss: 2.1628737847010293

Epoch: 6| Step: 1
Training loss: 0.7823255062103271
Validation loss: 2.213946064313253

Epoch: 6| Step: 2
Training loss: 1.1173574924468994
Validation loss: 2.1930299003918967

Epoch: 6| Step: 3
Training loss: 0.7614568471908569
Validation loss: 2.1602439284324646

Epoch: 6| Step: 4
Training loss: 1.1676673889160156
Validation loss: 2.1647183696428933

Epoch: 6| Step: 5
Training loss: 0.582434892654419
Validation loss: 2.2140650749206543

Epoch: 6| Step: 6
Training loss: 0.8417277336120605
Validation loss: 2.074608008066813

Epoch: 6| Step: 7
Training loss: 0.9146512150764465
Validation loss: 2.112894137700399

Epoch: 6| Step: 8
Training loss: 0.7311304211616516
Validation loss: 2.0988811254501343

Epoch: 6| Step: 9
Training loss: 0.8115164041519165
Validation loss: 2.152067482471466

Epoch: 6| Step: 10
Training loss: 0.6749621033668518
Validation loss: 2.1469563643137612

Epoch: 6| Step: 11
Training loss: 1.06553316116333
Validation loss: 2.140642543633779

Epoch: 6| Step: 12
Training loss: 0.26832181215286255
Validation loss: 2.1311686436335244

Epoch: 6| Step: 13
Training loss: 0.9925915598869324
Validation loss: 2.104010581970215

Epoch: 245| Step: 0
Training loss: 0.5149489045143127
Validation loss: 2.133526841799418

Epoch: 6| Step: 1
Training loss: 0.873389482498169
Validation loss: 2.199597477912903

Epoch: 6| Step: 2
Training loss: 0.8387361168861389
Validation loss: 2.0870174566904702

Epoch: 6| Step: 3
Training loss: 1.6023255586624146
Validation loss: 2.200242519378662

Epoch: 6| Step: 4
Training loss: 0.8801389336585999
Validation loss: 2.13371749718984

Epoch: 6| Step: 5
Training loss: 0.403885155916214
Validation loss: 2.116200804710388

Epoch: 6| Step: 6
Training loss: 0.5247206091880798
Validation loss: 2.113696356614431

Epoch: 6| Step: 7
Training loss: 0.41946345567703247
Validation loss: 2.1430044968922934

Epoch: 6| Step: 8
Training loss: 0.8938243389129639
Validation loss: 2.1100054581960044

Epoch: 6| Step: 9
Training loss: 0.9318197965621948
Validation loss: 2.1127055486043296

Epoch: 6| Step: 10
Training loss: 0.43403565883636475
Validation loss: 2.12024595340093

Epoch: 6| Step: 11
Training loss: 0.7900015115737915
Validation loss: 2.118058502674103

Epoch: 6| Step: 12
Training loss: 0.6665332317352295
Validation loss: 2.1085796554883323

Epoch: 6| Step: 13
Training loss: 0.9934135675430298
Validation loss: 2.139613389968872

Epoch: 246| Step: 0
Training loss: 0.45515334606170654
Validation loss: 2.1568618416786194

Epoch: 6| Step: 1
Training loss: 0.8239332437515259
Validation loss: 2.1858882109324136

Epoch: 6| Step: 2
Training loss: 1.217322826385498
Validation loss: 2.1109677950541177

Epoch: 6| Step: 3
Training loss: 0.9814143776893616
Validation loss: 2.123893598715464

Epoch: 6| Step: 4
Training loss: 0.33264052867889404
Validation loss: 2.082268158594767

Epoch: 6| Step: 5
Training loss: 0.6305351853370667
Validation loss: 2.1735878388086953

Epoch: 6| Step: 6
Training loss: 1.147367238998413
Validation loss: 2.136168281237284

Epoch: 6| Step: 7
Training loss: 0.7230088710784912
Validation loss: 2.1180097262064614

Epoch: 6| Step: 8
Training loss: 0.7569501399993896
Validation loss: 2.1161327163378396

Epoch: 6| Step: 9
Training loss: 1.345116138458252
Validation loss: 2.1687636971473694

Epoch: 6| Step: 10
Training loss: 0.7440143823623657
Validation loss: 2.1651405890782676

Epoch: 6| Step: 11
Training loss: 0.23405511677265167
Validation loss: 2.184171418348948

Epoch: 6| Step: 12
Training loss: 0.7934119701385498
Validation loss: 2.2066603104273477

Epoch: 6| Step: 13
Training loss: 1.1059037446975708
Validation loss: 2.179734547932943

Epoch: 247| Step: 0
Training loss: 0.3815195560455322
Validation loss: 2.176892638206482

Epoch: 6| Step: 1
Training loss: 0.6304850578308105
Validation loss: 2.147782345612844

Epoch: 6| Step: 2
Training loss: 0.8707920908927917
Validation loss: 2.18221922715505

Epoch: 6| Step: 3
Training loss: 0.46618854999542236
Validation loss: 2.0918455123901367

Epoch: 6| Step: 4
Training loss: 0.9863279461860657
Validation loss: 2.1016292373339334

Epoch: 6| Step: 5
Training loss: 0.9915096163749695
Validation loss: 2.1145896911621094

Epoch: 6| Step: 6
Training loss: 0.6380599737167358
Validation loss: 2.1137622197469077

Epoch: 6| Step: 7
Training loss: 1.130753993988037
Validation loss: 2.078813850879669

Epoch: 6| Step: 8
Training loss: 0.3903043270111084
Validation loss: 2.1262712478637695

Epoch: 6| Step: 9
Training loss: 0.9240524172782898
Validation loss: 2.10714328289032

Epoch: 6| Step: 10
Training loss: 0.5850433707237244
Validation loss: 2.162065784136454

Epoch: 6| Step: 11
Training loss: 0.8668721318244934
Validation loss: 2.1740849018096924

Epoch: 6| Step: 12
Training loss: 1.467461347579956
Validation loss: 2.2076868216196694

Epoch: 6| Step: 13
Training loss: 0.5908721089363098
Validation loss: 2.2007500330607095

Epoch: 248| Step: 0
Training loss: 0.7860524654388428
Validation loss: 2.174475530783335

Epoch: 6| Step: 1
Training loss: 0.5258119106292725
Validation loss: 2.1388471722602844

Epoch: 6| Step: 2
Training loss: 0.9940280318260193
Validation loss: 2.1825239857037864

Epoch: 6| Step: 3
Training loss: 0.6858236193656921
Validation loss: 2.121009051799774

Epoch: 6| Step: 4
Training loss: 0.7364051342010498
Validation loss: 2.1268721222877502

Epoch: 6| Step: 5
Training loss: 0.7636928558349609
Validation loss: 2.1811041235923767

Epoch: 6| Step: 6
Training loss: 0.6806255578994751
Validation loss: 2.1807989279429116

Epoch: 6| Step: 7
Training loss: 0.5964779853820801
Validation loss: 2.0951034228006997

Epoch: 6| Step: 8
Training loss: 0.8147889375686646
Validation loss: 2.117502808570862

Epoch: 6| Step: 9
Training loss: 0.9002425670623779
Validation loss: 2.1261164347330728

Epoch: 6| Step: 10
Training loss: 0.6682918071746826
Validation loss: 2.0971331000328064

Epoch: 6| Step: 11
Training loss: 1.0837594270706177
Validation loss: 2.0676530798276267

Epoch: 6| Step: 12
Training loss: 0.8952255845069885
Validation loss: 2.1381616791089377

Epoch: 6| Step: 13
Training loss: 0.7598139047622681
Validation loss: 2.098898629347483

Epoch: 249| Step: 0
Training loss: 1.0626323223114014
Validation loss: 2.1312485138575235

Epoch: 6| Step: 1
Training loss: 0.7788833379745483
Validation loss: 2.1159161726633706

Epoch: 6| Step: 2
Training loss: 0.4366530478000641
Validation loss: 2.1583624482154846

Epoch: 6| Step: 3
Training loss: 0.6724337935447693
Validation loss: 2.131251494089762

Epoch: 6| Step: 4
Training loss: 0.7110403776168823
Validation loss: 2.130881190299988

Epoch: 6| Step: 5
Training loss: 1.0107921361923218
Validation loss: 2.072579026222229

Epoch: 6| Step: 6
Training loss: 0.6848130822181702
Validation loss: 2.1125543316205344

Epoch: 6| Step: 7
Training loss: 0.444970965385437
Validation loss: 2.05975075562795

Epoch: 6| Step: 8
Training loss: 1.097570776939392
Validation loss: 2.128098944822947

Epoch: 6| Step: 9
Training loss: 1.0302133560180664
Validation loss: 2.1324983835220337

Epoch: 6| Step: 10
Training loss: 0.977385938167572
Validation loss: 2.06243097782135

Epoch: 6| Step: 11
Training loss: 0.5334033966064453
Validation loss: 2.120645523071289

Epoch: 6| Step: 12
Training loss: 0.5990241765975952
Validation loss: 2.141606410344442

Epoch: 6| Step: 13
Training loss: 0.806909441947937
Validation loss: 2.1177152196566262

Epoch: 250| Step: 0
Training loss: 0.7813339233398438
Validation loss: 2.1055544018745422

Epoch: 6| Step: 1
Training loss: 0.5642123222351074
Validation loss: 2.1134856939315796

Epoch: 6| Step: 2
Training loss: 1.1750586032867432
Validation loss: 2.150459627310435

Epoch: 6| Step: 3
Training loss: 1.0977959632873535
Validation loss: 2.1342145999272666

Epoch: 6| Step: 4
Training loss: 0.6676745414733887
Validation loss: 2.1420512596766152

Epoch: 6| Step: 5
Training loss: 0.7006732821464539
Validation loss: 2.085567593574524

Epoch: 6| Step: 6
Training loss: 0.610123872756958
Validation loss: 2.0958519776662192

Epoch: 6| Step: 7
Training loss: 0.8249177932739258
Validation loss: 2.1537782351175943

Epoch: 6| Step: 8
Training loss: 0.7322942018508911
Validation loss: 2.1227674086888633

Epoch: 6| Step: 9
Training loss: 1.0487192869186401
Validation loss: 2.142741878827413

Epoch: 6| Step: 10
Training loss: 0.5869922041893005
Validation loss: 2.15382719039917

Epoch: 6| Step: 11
Training loss: 0.5128995776176453
Validation loss: 2.0615508755048118

Epoch: 6| Step: 12
Training loss: 0.4839819669723511
Validation loss: 2.120330532391866

Epoch: 6| Step: 13
Training loss: 0.4234975576400757
Validation loss: 2.141807734966278

Epoch: 251| Step: 0
Training loss: 0.6421668529510498
Validation loss: 2.110856771469116

Epoch: 6| Step: 1
Training loss: 0.7707806825637817
Validation loss: 2.1391589045524597

Epoch: 6| Step: 2
Training loss: 0.43349915742874146
Validation loss: 2.160277247428894

Epoch: 6| Step: 3
Training loss: 0.41592714190483093
Validation loss: 2.12471737464269

Epoch: 6| Step: 4
Training loss: 0.7639589309692383
Validation loss: 2.1448077956835427

Epoch: 6| Step: 5
Training loss: 1.0794153213500977
Validation loss: 2.127094805240631

Epoch: 6| Step: 6
Training loss: 0.7137820720672607
Validation loss: 2.117007772127787

Epoch: 6| Step: 7
Training loss: 0.8762223124504089
Validation loss: 2.0780250430107117

Epoch: 6| Step: 8
Training loss: 0.9250479340553284
Validation loss: 2.117559870084127

Epoch: 6| Step: 9
Training loss: 0.7577289938926697
Validation loss: 2.1206728418668113

Epoch: 6| Step: 10
Training loss: 0.6416460871696472
Validation loss: 2.090048909187317

Epoch: 6| Step: 11
Training loss: 0.5761817693710327
Validation loss: 2.105916897455851

Epoch: 6| Step: 12
Training loss: 0.6256483793258667
Validation loss: 2.170353134473165

Epoch: 6| Step: 13
Training loss: 0.3036726713180542
Validation loss: 2.0768637657165527

Epoch: 252| Step: 0
Training loss: 0.9793448448181152
Validation loss: 2.191138486067454

Epoch: 6| Step: 1
Training loss: 0.30377650260925293
Validation loss: 2.133705953756968

Epoch: 6| Step: 2
Training loss: 0.4829680919647217
Validation loss: 2.120102365811666

Epoch: 6| Step: 3
Training loss: 1.3501946926116943
Validation loss: 2.1511563460032144

Epoch: 6| Step: 4
Training loss: 0.36593711376190186
Validation loss: 2.119451324144999

Epoch: 6| Step: 5
Training loss: 1.1027894020080566
Validation loss: 2.1369441151618958

Epoch: 6| Step: 6
Training loss: 0.39494097232818604
Validation loss: 2.121456503868103

Epoch: 6| Step: 7
Training loss: 0.5184093713760376
Validation loss: 2.0938853820165

Epoch: 6| Step: 8
Training loss: 1.0393273830413818
Validation loss: 2.1150512099266052

Epoch: 6| Step: 9
Training loss: 0.5474079847335815
Validation loss: 2.1422243316968284

Epoch: 6| Step: 10
Training loss: 0.5544390678405762
Validation loss: 2.114295403162638

Epoch: 6| Step: 11
Training loss: 0.6593247652053833
Validation loss: 2.117471973101298

Epoch: 6| Step: 12
Training loss: 0.6829712390899658
Validation loss: 2.169818083445231

Epoch: 6| Step: 13
Training loss: 1.3329546451568604
Validation loss: 2.165572206179301

Epoch: 253| Step: 0
Training loss: 0.48527097702026367
Validation loss: 2.204409599304199

Epoch: 6| Step: 1
Training loss: 0.768068790435791
Validation loss: 2.137227018674215

Epoch: 6| Step: 2
Training loss: 0.48688971996307373
Validation loss: 2.1370558937390647

Epoch: 6| Step: 3
Training loss: 0.6294300556182861
Validation loss: 2.164866586526235

Epoch: 6| Step: 4
Training loss: 0.6265150308609009
Validation loss: 2.09409632285436

Epoch: 6| Step: 5
Training loss: 1.0791739225387573
Validation loss: 2.225630243619283

Epoch: 6| Step: 6
Training loss: 0.7080912590026855
Validation loss: 2.104365865389506

Epoch: 6| Step: 7
Training loss: 0.8891696333885193
Validation loss: 2.1539711157480874

Epoch: 6| Step: 8
Training loss: 0.35729900002479553
Validation loss: 2.1600606640179953

Epoch: 6| Step: 9
Training loss: 1.6365286111831665
Validation loss: 2.13873553276062

Epoch: 6| Step: 10
Training loss: 0.501233696937561
Validation loss: 2.0895355145136514

Epoch: 6| Step: 11
Training loss: 0.31670308113098145
Validation loss: 2.0951635042826333

Epoch: 6| Step: 12
Training loss: 0.6547596454620361
Validation loss: 2.123388389746348

Epoch: 6| Step: 13
Training loss: 0.8072509169578552
Validation loss: 2.137426177660624

Epoch: 254| Step: 0
Training loss: 1.0791141986846924
Validation loss: 2.1661069790522256

Epoch: 6| Step: 1
Training loss: 0.6767220497131348
Validation loss: 2.1211705605189004

Epoch: 6| Step: 2
Training loss: 0.5665348172187805
Validation loss: 2.1185595790545144

Epoch: 6| Step: 3
Training loss: 0.8442004919052124
Validation loss: 2.1885444124539695

Epoch: 6| Step: 4
Training loss: 0.7495836019515991
Validation loss: 2.203314562638601

Epoch: 6| Step: 5
Training loss: 0.7063865661621094
Validation loss: 2.2060991128285727

Epoch: 6| Step: 6
Training loss: 0.5199217796325684
Validation loss: 2.1428287823994956

Epoch: 6| Step: 7
Training loss: 0.678006649017334
Validation loss: 2.177628437678019

Epoch: 6| Step: 8
Training loss: 0.8081571459770203
Validation loss: 2.1802304784456887

Epoch: 6| Step: 9
Training loss: 0.8488597869873047
Validation loss: 2.1592081586519876

Epoch: 6| Step: 10
Training loss: 1.525862216949463
Validation loss: 2.1782140533129373

Epoch: 6| Step: 11
Training loss: 0.7955489754676819
Validation loss: 2.1135719815889993

Epoch: 6| Step: 12
Training loss: 0.4431741237640381
Validation loss: 2.156840125719706

Epoch: 6| Step: 13
Training loss: 0.5952112674713135
Validation loss: 2.147970994313558

Epoch: 255| Step: 0
Training loss: 0.611111581325531
Validation loss: 2.1271745959917703

Epoch: 6| Step: 1
Training loss: 0.6156022548675537
Validation loss: 2.1088178753852844

Epoch: 6| Step: 2
Training loss: 0.5052489042282104
Validation loss: 2.1658122142155967

Epoch: 6| Step: 3
Training loss: 0.5426139831542969
Validation loss: 2.1545270681381226

Epoch: 6| Step: 4
Training loss: 0.37779781222343445
Validation loss: 2.1427257458368936

Epoch: 6| Step: 5
Training loss: 0.9019030928611755
Validation loss: 2.1871267358462014

Epoch: 6| Step: 6
Training loss: 0.5584768652915955
Validation loss: 2.131836175918579

Epoch: 6| Step: 7
Training loss: 1.145207405090332
Validation loss: 2.1419358253479004

Epoch: 6| Step: 8
Training loss: 0.9529598951339722
Validation loss: 2.13544354836146

Epoch: 6| Step: 9
Training loss: 0.8031870126724243
Validation loss: 2.1287837624549866

Epoch: 6| Step: 10
Training loss: 0.7754193544387817
Validation loss: 2.1834320227305093

Epoch: 6| Step: 11
Training loss: 0.7574547529220581
Validation loss: 2.088065266609192

Epoch: 6| Step: 12
Training loss: 0.8123093843460083
Validation loss: 2.064848800500234

Epoch: 6| Step: 13
Training loss: 0.8937079906463623
Validation loss: 2.147918919722239

Epoch: 256| Step: 0
Training loss: 0.5897523164749146
Validation loss: 2.1407463947931924

Epoch: 6| Step: 1
Training loss: 0.5691342949867249
Validation loss: 2.1348395148913064

Epoch: 6| Step: 2
Training loss: 0.6776845455169678
Validation loss: 2.1874293088912964

Epoch: 6| Step: 3
Training loss: 0.45085492730140686
Validation loss: 2.1354787349700928

Epoch: 6| Step: 4
Training loss: 0.5310751795768738
Validation loss: 2.119396766026815

Epoch: 6| Step: 5
Training loss: 0.5149463415145874
Validation loss: 2.1780869563420615

Epoch: 6| Step: 6
Training loss: 0.7999027967453003
Validation loss: 2.225987116495768

Epoch: 6| Step: 7
Training loss: 0.6613631844520569
Validation loss: 2.105169415473938

Epoch: 6| Step: 8
Training loss: 0.5659221410751343
Validation loss: 2.140105446179708

Epoch: 6| Step: 9
Training loss: 0.8127824068069458
Validation loss: 2.1026696960131326

Epoch: 6| Step: 10
Training loss: 0.5067358613014221
Validation loss: 2.1265666286150613

Epoch: 6| Step: 11
Training loss: 1.4533932209014893
Validation loss: 2.1473034620285034

Epoch: 6| Step: 12
Training loss: 0.5062021613121033
Validation loss: 2.089075764020284

Epoch: 6| Step: 13
Training loss: 0.6782588958740234
Validation loss: 2.0921415090560913

Epoch: 257| Step: 0
Training loss: 0.6993043422698975
Validation loss: 2.1136225859324136

Epoch: 6| Step: 1
Training loss: 0.4511150121688843
Validation loss: 2.14136532942454

Epoch: 6| Step: 2
Training loss: 0.48575645685195923
Validation loss: 2.109493891398112

Epoch: 6| Step: 3
Training loss: 0.8781284689903259
Validation loss: 2.17981747786204

Epoch: 6| Step: 4
Training loss: 0.39667701721191406
Validation loss: 2.12620480855306

Epoch: 6| Step: 5
Training loss: 0.4977254271507263
Validation loss: 2.142897069454193

Epoch: 6| Step: 6
Training loss: 1.6445212364196777
Validation loss: 2.1206255356470742

Epoch: 6| Step: 7
Training loss: 0.7159668207168579
Validation loss: 2.1251840194066367

Epoch: 6| Step: 8
Training loss: 0.3985905349254608
Validation loss: 2.138855000336965

Epoch: 6| Step: 9
Training loss: 0.860633134841919
Validation loss: 2.170409083366394

Epoch: 6| Step: 10
Training loss: 0.4854733347892761
Validation loss: 2.0883284211158752

Epoch: 6| Step: 11
Training loss: 0.35556793212890625
Validation loss: 2.0779101451238

Epoch: 6| Step: 12
Training loss: 1.082167625427246
Validation loss: 2.166752596696218

Epoch: 6| Step: 13
Training loss: 0.6878001689910889
Validation loss: 2.1272790233294168

Epoch: 258| Step: 0
Training loss: 0.7996516823768616
Validation loss: 2.079636832078298

Epoch: 6| Step: 1
Training loss: 0.29259616136550903
Validation loss: 2.1047732830047607

Epoch: 6| Step: 2
Training loss: 0.8356805443763733
Validation loss: 2.1400465965270996

Epoch: 6| Step: 3
Training loss: 0.4004790186882019
Validation loss: 2.1204660932223

Epoch: 6| Step: 4
Training loss: 1.0527973175048828
Validation loss: 2.142423152923584

Epoch: 6| Step: 5
Training loss: 0.5442637801170349
Validation loss: 2.1565547982851663

Epoch: 6| Step: 6
Training loss: 0.9236555099487305
Validation loss: 2.1812230944633484

Epoch: 6| Step: 7
Training loss: 1.1621644496917725
Validation loss: 2.1483023365338645

Epoch: 6| Step: 8
Training loss: 0.7479461431503296
Validation loss: 2.121657411257426

Epoch: 6| Step: 9
Training loss: 0.5376389622688293
Validation loss: 2.147671898206075

Epoch: 6| Step: 10
Training loss: 0.8911111950874329
Validation loss: 2.092626472314199

Epoch: 6| Step: 11
Training loss: 0.5353516936302185
Validation loss: 2.1593689918518066

Epoch: 6| Step: 12
Training loss: 0.4203598201274872
Validation loss: 2.145057956377665

Epoch: 6| Step: 13
Training loss: 0.6627507209777832
Validation loss: 2.138830324014028

Epoch: 259| Step: 0
Training loss: 0.8178706169128418
Validation loss: 2.1314790447553

Epoch: 6| Step: 1
Training loss: 0.8384029865264893
Validation loss: 2.0884485046068826

Epoch: 6| Step: 2
Training loss: 0.2997112274169922
Validation loss: 2.1448179284731546

Epoch: 6| Step: 3
Training loss: 0.48633435368537903
Validation loss: 2.095665991306305

Epoch: 6| Step: 4
Training loss: 0.43976831436157227
Validation loss: 2.0920374194780984

Epoch: 6| Step: 5
Training loss: 0.9592997431755066
Validation loss: 2.1337667107582092

Epoch: 6| Step: 6
Training loss: 0.6571672558784485
Validation loss: 2.1722466150919595

Epoch: 6| Step: 7
Training loss: 0.61757892370224
Validation loss: 2.168063839276632

Epoch: 6| Step: 8
Training loss: 0.6843830943107605
Validation loss: 2.140218754609426

Epoch: 6| Step: 9
Training loss: 0.645133376121521
Validation loss: 2.1521021127700806

Epoch: 6| Step: 10
Training loss: 0.7016421556472778
Validation loss: 2.142065087954203

Epoch: 6| Step: 11
Training loss: 1.159958839416504
Validation loss: 2.0906898975372314

Epoch: 6| Step: 12
Training loss: 0.6891908049583435
Validation loss: 2.1493003368377686

Epoch: 6| Step: 13
Training loss: 0.7313183546066284
Validation loss: 2.1238377690315247

Epoch: 260| Step: 0
Training loss: 0.714242696762085
Validation loss: 2.1422025163968406

Epoch: 6| Step: 1
Training loss: 0.7395151853561401
Validation loss: 2.1504656076431274

Epoch: 6| Step: 2
Training loss: 0.810614824295044
Validation loss: 2.104190985361735

Epoch: 6| Step: 3
Training loss: 1.0893057584762573
Validation loss: 2.1044676701227822

Epoch: 6| Step: 4
Training loss: 0.6372407674789429
Validation loss: 2.110201895236969

Epoch: 6| Step: 5
Training loss: 0.7198159098625183
Validation loss: 2.0933010578155518

Epoch: 6| Step: 6
Training loss: 0.4160042107105255
Validation loss: 2.135789434115092

Epoch: 6| Step: 7
Training loss: 0.5715000033378601
Validation loss: 2.1367685993512473

Epoch: 6| Step: 8
Training loss: 0.799845278263092
Validation loss: 2.1575474739074707

Epoch: 6| Step: 9
Training loss: 0.9359779953956604
Validation loss: 2.1288915475209556

Epoch: 6| Step: 10
Training loss: 0.9965750575065613
Validation loss: 2.1762368281682334

Epoch: 6| Step: 11
Training loss: 0.7149152755737305
Validation loss: 2.176602065563202

Epoch: 6| Step: 12
Training loss: 0.6455205082893372
Validation loss: 2.1208946307500205

Epoch: 6| Step: 13
Training loss: 0.2579565942287445
Validation loss: 2.1281987031300864

Epoch: 261| Step: 0
Training loss: 0.6449991464614868
Validation loss: 2.1171071926752725

Epoch: 6| Step: 1
Training loss: 0.8328964710235596
Validation loss: 2.104710658391317

Epoch: 6| Step: 2
Training loss: 1.1470942497253418
Validation loss: 2.12734184662501

Epoch: 6| Step: 3
Training loss: 0.2599024176597595
Validation loss: 2.1047931909561157

Epoch: 6| Step: 4
Training loss: 0.9229870438575745
Validation loss: 2.173249383767446

Epoch: 6| Step: 5
Training loss: 0.4339835047721863
Validation loss: 2.124568144480387

Epoch: 6| Step: 6
Training loss: 0.9760768413543701
Validation loss: 2.160522441069285

Epoch: 6| Step: 7
Training loss: 0.9830101132392883
Validation loss: 2.167459408442179

Epoch: 6| Step: 8
Training loss: 0.5176723003387451
Validation loss: 2.180227200190226

Epoch: 6| Step: 9
Training loss: 0.6977630257606506
Validation loss: 2.116525570551554

Epoch: 6| Step: 10
Training loss: 0.5119728446006775
Validation loss: 2.1627827088038125

Epoch: 6| Step: 11
Training loss: 0.5554789304733276
Validation loss: 2.1463073094685874

Epoch: 6| Step: 12
Training loss: 0.5514712929725647
Validation loss: 2.1175107757250466

Epoch: 6| Step: 13
Training loss: 0.6151692867279053
Validation loss: 2.1391745805740356

Epoch: 262| Step: 0
Training loss: 0.589676558971405
Validation loss: 2.0912628769874573

Epoch: 6| Step: 1
Training loss: 0.7785137891769409
Validation loss: 2.114659070968628

Epoch: 6| Step: 2
Training loss: 0.5279414653778076
Validation loss: 2.0824965238571167

Epoch: 6| Step: 3
Training loss: 0.4256212115287781
Validation loss: 2.0448283751805625

Epoch: 6| Step: 4
Training loss: 0.7758572697639465
Validation loss: 2.1074109276135764

Epoch: 6| Step: 5
Training loss: 0.6236826181411743
Validation loss: 2.1364163955052695

Epoch: 6| Step: 6
Training loss: 0.6571328639984131
Validation loss: 2.1203221877415976

Epoch: 6| Step: 7
Training loss: 0.7445484399795532
Validation loss: 2.12495364745458

Epoch: 6| Step: 8
Training loss: 0.6657717823982239
Validation loss: 2.108029762903849

Epoch: 6| Step: 9
Training loss: 0.7975168824195862
Validation loss: 2.173015832901001

Epoch: 6| Step: 10
Training loss: 0.52649986743927
Validation loss: 2.1472164591153464

Epoch: 6| Step: 11
Training loss: 0.8124005198478699
Validation loss: 2.0870975454648337

Epoch: 6| Step: 12
Training loss: 0.6066186428070068
Validation loss: 2.111258943875631

Epoch: 6| Step: 13
Training loss: 1.1734297275543213
Validation loss: 2.1180740197499595

Epoch: 263| Step: 0
Training loss: 0.5654422640800476
Validation loss: 2.1404460668563843

Epoch: 6| Step: 1
Training loss: 1.0835041999816895
Validation loss: 2.1411328117052713

Epoch: 6| Step: 2
Training loss: 0.5006134510040283
Validation loss: 2.1219261288642883

Epoch: 6| Step: 3
Training loss: 0.44011053442955017
Validation loss: 2.132920245329539

Epoch: 6| Step: 4
Training loss: 0.5002192258834839
Validation loss: 2.1311105291048684

Epoch: 6| Step: 5
Training loss: 0.8223429918289185
Validation loss: 2.198051869869232

Epoch: 6| Step: 6
Training loss: 1.0379533767700195
Validation loss: 2.169011910756429

Epoch: 6| Step: 7
Training loss: 0.6878546476364136
Validation loss: 2.2026925683021545

Epoch: 6| Step: 8
Training loss: 0.98557448387146
Validation loss: 2.1325000524520874

Epoch: 6| Step: 9
Training loss: 0.5687887668609619
Validation loss: 2.1348150968551636

Epoch: 6| Step: 10
Training loss: 0.9113856554031372
Validation loss: 2.1499760150909424

Epoch: 6| Step: 11
Training loss: 0.4089796543121338
Validation loss: 2.0815229614575705

Epoch: 6| Step: 12
Training loss: 0.8735655546188354
Validation loss: 2.080709437529246

Epoch: 6| Step: 13
Training loss: 0.3483754098415375
Validation loss: 2.1886213223139444

Epoch: 264| Step: 0
Training loss: 0.8842489123344421
Validation loss: 2.131163318951925

Epoch: 6| Step: 1
Training loss: 0.8547772169113159
Validation loss: 2.1170048912366233

Epoch: 6| Step: 2
Training loss: 0.5750609636306763
Validation loss: 2.0781152844429016

Epoch: 6| Step: 3
Training loss: 0.7992202639579773
Validation loss: 2.1126544872919717

Epoch: 6| Step: 4
Training loss: 0.31447142362594604
Validation loss: 2.2127350171407065

Epoch: 6| Step: 5
Training loss: 0.9394193887710571
Validation loss: 2.1436373392740884

Epoch: 6| Step: 6
Training loss: 0.6243152618408203
Validation loss: 2.1469821532567344

Epoch: 6| Step: 7
Training loss: 0.7791425585746765
Validation loss: 2.1504626075426736

Epoch: 6| Step: 8
Training loss: 0.3541196584701538
Validation loss: 2.1523187160491943

Epoch: 6| Step: 9
Training loss: 0.4476965069770813
Validation loss: 2.134900391101837

Epoch: 6| Step: 10
Training loss: 0.5751112699508667
Validation loss: 2.1100820501645408

Epoch: 6| Step: 11
Training loss: 0.5599789023399353
Validation loss: 2.085848391056061

Epoch: 6| Step: 12
Training loss: 1.036879301071167
Validation loss: 2.0583038330078125

Epoch: 6| Step: 13
Training loss: 1.3452954292297363
Validation loss: 2.125931143760681

Epoch: 265| Step: 0
Training loss: 0.9028149247169495
Validation loss: 2.1480205059051514

Epoch: 6| Step: 1
Training loss: 0.7249596118927002
Validation loss: 2.1646194458007812

Epoch: 6| Step: 2
Training loss: 0.8569319248199463
Validation loss: 2.1101707220077515

Epoch: 6| Step: 3
Training loss: 0.7818179130554199
Validation loss: 2.070674200852712

Epoch: 6| Step: 4
Training loss: 0.2680225670337677
Validation loss: 2.1715782086054483

Epoch: 6| Step: 5
Training loss: 0.7881187200546265
Validation loss: 2.1093033949534097

Epoch: 6| Step: 6
Training loss: 0.553894579410553
Validation loss: 2.087443749109904

Epoch: 6| Step: 7
Training loss: 0.772620439529419
Validation loss: 2.1638476252555847

Epoch: 6| Step: 8
Training loss: 0.5606544017791748
Validation loss: 2.1586397886276245

Epoch: 6| Step: 9
Training loss: 0.4590551257133484
Validation loss: 2.1202447017033896

Epoch: 6| Step: 10
Training loss: 0.44919222593307495
Validation loss: 2.122654676437378

Epoch: 6| Step: 11
Training loss: 0.7877117395401001
Validation loss: 2.1203597585360208

Epoch: 6| Step: 12
Training loss: 0.9274500608444214
Validation loss: 2.1367979645729065

Epoch: 6| Step: 13
Training loss: 0.47572779655456543
Validation loss: 2.114501098791758

Epoch: 266| Step: 0
Training loss: 0.9124295711517334
Validation loss: 2.0890974402427673

Epoch: 6| Step: 1
Training loss: 0.36408567428588867
Validation loss: 2.1488532225290933

Epoch: 6| Step: 2
Training loss: 0.17021948099136353
Validation loss: 2.1491861939430237

Epoch: 6| Step: 3
Training loss: 0.927398681640625
Validation loss: 2.115710198879242

Epoch: 6| Step: 4
Training loss: 0.4233560264110565
Validation loss: 2.141274849573771

Epoch: 6| Step: 5
Training loss: 0.976754903793335
Validation loss: 2.1351569096247354

Epoch: 6| Step: 6
Training loss: 0.623775064945221
Validation loss: 2.1197869976361594

Epoch: 6| Step: 7
Training loss: 0.9280513525009155
Validation loss: 2.0851000348726907

Epoch: 6| Step: 8
Training loss: 0.4627889096736908
Validation loss: 2.189907411734263

Epoch: 6| Step: 9
Training loss: 0.394665002822876
Validation loss: 2.1080411473910012

Epoch: 6| Step: 10
Training loss: 0.6391233205795288
Validation loss: 2.088110347588857

Epoch: 6| Step: 11
Training loss: 0.7348353266716003
Validation loss: 2.1092177033424377

Epoch: 6| Step: 12
Training loss: 1.0274019241333008
Validation loss: 2.166154384613037

Epoch: 6| Step: 13
Training loss: 0.6986701488494873
Validation loss: 2.1248603661855063

Epoch: 267| Step: 0
Training loss: 0.5345943570137024
Validation loss: 2.1229069431622825

Epoch: 6| Step: 1
Training loss: 0.6054062843322754
Validation loss: 2.0970070163408914

Epoch: 6| Step: 2
Training loss: 0.4528907537460327
Validation loss: 2.128660480181376

Epoch: 6| Step: 3
Training loss: 0.6340576410293579
Validation loss: 2.1791053414344788

Epoch: 6| Step: 4
Training loss: 0.49687570333480835
Validation loss: 2.1100368102391562

Epoch: 6| Step: 5
Training loss: 0.9991803169250488
Validation loss: 2.1658538977305093

Epoch: 6| Step: 6
Training loss: 0.8873185515403748
Validation loss: 2.096629500389099

Epoch: 6| Step: 7
Training loss: 1.1301209926605225
Validation loss: 2.119375010331472

Epoch: 6| Step: 8
Training loss: 0.8982596397399902
Validation loss: 2.116518974304199

Epoch: 6| Step: 9
Training loss: 0.7444236278533936
Validation loss: 2.1812398036321006

Epoch: 6| Step: 10
Training loss: 0.6411610245704651
Validation loss: 2.142535448074341

Epoch: 6| Step: 11
Training loss: 0.7492866516113281
Validation loss: 2.1793956955273948

Epoch: 6| Step: 12
Training loss: 0.3533429503440857
Validation loss: 2.2267183860143027

Epoch: 6| Step: 13
Training loss: 0.38218265771865845
Validation loss: 2.1850348909695945

Epoch: 268| Step: 0
Training loss: 0.4608840048313141
Validation loss: 2.1413864294687905

Epoch: 6| Step: 1
Training loss: 0.627106249332428
Validation loss: 2.0838800271352134

Epoch: 6| Step: 2
Training loss: 1.094588279724121
Validation loss: 2.1213016510009766

Epoch: 6| Step: 3
Training loss: 0.42952609062194824
Validation loss: 2.0882358153661094

Epoch: 6| Step: 4
Training loss: 0.5336405038833618
Validation loss: 2.1455456813176474

Epoch: 6| Step: 5
Training loss: 0.2966705560684204
Validation loss: 2.173466702302297

Epoch: 6| Step: 6
Training loss: 0.653592586517334
Validation loss: 2.1026477615038552

Epoch: 6| Step: 7
Training loss: 0.8421977758407593
Validation loss: 2.153445581595103

Epoch: 6| Step: 8
Training loss: 0.9389849305152893
Validation loss: 2.1363221208254495

Epoch: 6| Step: 9
Training loss: 0.9831626415252686
Validation loss: 2.1119085550308228

Epoch: 6| Step: 10
Training loss: 0.8811877369880676
Validation loss: 2.11830727259318

Epoch: 6| Step: 11
Training loss: 0.31399694085121155
Validation loss: 2.0966457525889077

Epoch: 6| Step: 12
Training loss: 0.7377289533615112
Validation loss: 2.081367313861847

Epoch: 6| Step: 13
Training loss: 0.6811752319335938
Validation loss: 2.136401891708374

Epoch: 269| Step: 0
Training loss: 0.7991089224815369
Validation loss: 2.16895059744517

Epoch: 6| Step: 1
Training loss: 0.9249311089515686
Validation loss: 2.109337786833445

Epoch: 6| Step: 2
Training loss: 0.606099009513855
Validation loss: 2.143618901570638

Epoch: 6| Step: 3
Training loss: 0.3253857493400574
Validation loss: 2.1486337979634604

Epoch: 6| Step: 4
Training loss: 0.8126556873321533
Validation loss: 2.0989344914754233

Epoch: 6| Step: 5
Training loss: 0.49511831998825073
Validation loss: 2.134341756502787

Epoch: 6| Step: 6
Training loss: 0.700529932975769
Validation loss: 2.1421552101771035

Epoch: 6| Step: 7
Training loss: 1.165475606918335
Validation loss: 2.147247552871704

Epoch: 6| Step: 8
Training loss: 0.5326032638549805
Validation loss: 2.1179866989453635

Epoch: 6| Step: 9
Training loss: 0.4930119514465332
Validation loss: 2.1012619137763977

Epoch: 6| Step: 10
Training loss: 0.5731366872787476
Validation loss: 2.1746202309926352

Epoch: 6| Step: 11
Training loss: 0.4812130630016327
Validation loss: 2.159129023551941

Epoch: 6| Step: 12
Training loss: 0.5680756568908691
Validation loss: 2.1720765431722007

Epoch: 6| Step: 13
Training loss: 0.7104372978210449
Validation loss: 2.1819093227386475

Epoch: 270| Step: 0
Training loss: 0.48429083824157715
Validation loss: 2.149370710055033

Epoch: 6| Step: 1
Training loss: 0.8984234929084778
Validation loss: 2.1877071857452393

Epoch: 6| Step: 2
Training loss: 0.6941813230514526
Validation loss: 2.120847205320994

Epoch: 6| Step: 3
Training loss: 0.8457136154174805
Validation loss: 2.133869230747223

Epoch: 6| Step: 4
Training loss: 0.7904797792434692
Validation loss: 2.17002002398173

Epoch: 6| Step: 5
Training loss: 0.9133408665657043
Validation loss: 2.0929871797561646

Epoch: 6| Step: 6
Training loss: 0.7451037168502808
Validation loss: 2.0772716403007507

Epoch: 6| Step: 7
Training loss: 0.3893864154815674
Validation loss: 2.095691760381063

Epoch: 6| Step: 8
Training loss: 0.4510948657989502
Validation loss: 2.1621115605036416

Epoch: 6| Step: 9
Training loss: 0.4262521266937256
Validation loss: 2.1096377770105996

Epoch: 6| Step: 10
Training loss: 0.5540406703948975
Validation loss: 2.148863434791565

Epoch: 6| Step: 11
Training loss: 0.3491748571395874
Validation loss: 2.103150804837545

Epoch: 6| Step: 12
Training loss: 0.5281787514686584
Validation loss: 2.1404267946879068

Epoch: 6| Step: 13
Training loss: 0.9297822117805481
Validation loss: 2.1670770843823752

Epoch: 271| Step: 0
Training loss: 0.6449389457702637
Validation loss: 2.1932797034581504

Epoch: 6| Step: 1
Training loss: 0.43940311670303345
Validation loss: 2.134696046511332

Epoch: 6| Step: 2
Training loss: 0.6091299653053284
Validation loss: 2.1176005403200784

Epoch: 6| Step: 3
Training loss: 0.7983259558677673
Validation loss: 2.2025752464930215

Epoch: 6| Step: 4
Training loss: 0.7982242107391357
Validation loss: 2.154696981112162

Epoch: 6| Step: 5
Training loss: 0.7684094905853271
Validation loss: 2.1440517902374268

Epoch: 6| Step: 6
Training loss: 0.7893900871276855
Validation loss: 2.0754015843073526

Epoch: 6| Step: 7
Training loss: 0.40116000175476074
Validation loss: 2.0908377369244895

Epoch: 6| Step: 8
Training loss: 0.4318442940711975
Validation loss: 2.1048444310824075

Epoch: 6| Step: 9
Training loss: 0.7296366691589355
Validation loss: 2.1603277921676636

Epoch: 6| Step: 10
Training loss: 1.0378286838531494
Validation loss: 2.1569974025090537

Epoch: 6| Step: 11
Training loss: 0.6044005751609802
Validation loss: 2.1601303021113076

Epoch: 6| Step: 12
Training loss: 0.7075382471084595
Validation loss: 2.2236368457476297

Epoch: 6| Step: 13
Training loss: 0.7814688682556152
Validation loss: 2.1357746918996177

Epoch: 272| Step: 0
Training loss: 0.8245210647583008
Validation loss: 2.1459047396977744

Epoch: 6| Step: 1
Training loss: 0.41456860303878784
Validation loss: 2.091044008731842

Epoch: 6| Step: 2
Training loss: 0.5162453651428223
Validation loss: 2.1184876362482705

Epoch: 6| Step: 3
Training loss: 0.7997355461120605
Validation loss: 2.1454318960507712

Epoch: 6| Step: 4
Training loss: 0.5239217877388
Validation loss: 2.052637040615082

Epoch: 6| Step: 5
Training loss: 1.1052510738372803
Validation loss: 2.1505947709083557

Epoch: 6| Step: 6
Training loss: 0.6183212995529175
Validation loss: 2.1818170150121055

Epoch: 6| Step: 7
Training loss: 0.556903600692749
Validation loss: 2.1334959864616394

Epoch: 6| Step: 8
Training loss: 0.8624953031539917
Validation loss: 2.14886208375295

Epoch: 6| Step: 9
Training loss: 0.2657007575035095
Validation loss: 2.0892207622528076

Epoch: 6| Step: 10
Training loss: 0.53438401222229
Validation loss: 2.103312373161316

Epoch: 6| Step: 11
Training loss: 0.6107823848724365
Validation loss: 2.1572046478589377

Epoch: 6| Step: 12
Training loss: 0.8603168725967407
Validation loss: 2.1125307281812034

Epoch: 6| Step: 13
Training loss: 0.751460075378418
Validation loss: 2.1009484926859536

Epoch: 273| Step: 0
Training loss: 0.7487447261810303
Validation loss: 2.1618533929189048

Epoch: 6| Step: 1
Training loss: 0.48114559054374695
Validation loss: 2.135519822438558

Epoch: 6| Step: 2
Training loss: 0.32677292823791504
Validation loss: 2.1230389873186746

Epoch: 6| Step: 3
Training loss: 1.0382575988769531
Validation loss: 2.138446847597758

Epoch: 6| Step: 4
Training loss: 0.3952486515045166
Validation loss: 2.106823444366455

Epoch: 6| Step: 5
Training loss: 0.43889153003692627
Validation loss: 2.121865709622701

Epoch: 6| Step: 6
Training loss: 0.3745637834072113
Validation loss: 2.0859612822532654

Epoch: 6| Step: 7
Training loss: 0.7248727083206177
Validation loss: 2.1459513107935586

Epoch: 6| Step: 8
Training loss: 0.3334946930408478
Validation loss: 2.141791264216105

Epoch: 6| Step: 9
Training loss: 1.1662299633026123
Validation loss: 2.1291739344596863

Epoch: 6| Step: 10
Training loss: 0.48867857456207275
Validation loss: 2.0875107447306314

Epoch: 6| Step: 11
Training loss: 0.44368523359298706
Validation loss: 2.0737236738204956

Epoch: 6| Step: 12
Training loss: 0.5767686367034912
Validation loss: 2.068313479423523

Epoch: 6| Step: 13
Training loss: 1.1339550018310547
Validation loss: 2.136882781982422

Epoch: 274| Step: 0
Training loss: 0.5235152840614319
Validation loss: 2.125319560368856

Epoch: 6| Step: 1
Training loss: 0.6971912384033203
Validation loss: 2.157445470492045

Epoch: 6| Step: 2
Training loss: 0.9061136245727539
Validation loss: 2.197666645050049

Epoch: 6| Step: 3
Training loss: 0.6758995652198792
Validation loss: 2.139179229736328

Epoch: 6| Step: 4
Training loss: 0.49425065517425537
Validation loss: 2.0920295317967734

Epoch: 6| Step: 5
Training loss: 0.8529587984085083
Validation loss: 2.117057224114736

Epoch: 6| Step: 6
Training loss: 0.5643865466117859
Validation loss: 2.097659726937612

Epoch: 6| Step: 7
Training loss: 1.1988710165023804
Validation loss: 2.0769105553627014

Epoch: 6| Step: 8
Training loss: 0.5210006833076477
Validation loss: 2.1117299596468606

Epoch: 6| Step: 9
Training loss: 0.4420021176338196
Validation loss: 2.166157901287079

Epoch: 6| Step: 10
Training loss: 0.9009038209915161
Validation loss: 2.0925895969072976

Epoch: 6| Step: 11
Training loss: 0.7034103870391846
Validation loss: 2.0790964563687644

Epoch: 6| Step: 12
Training loss: 0.252183735370636
Validation loss: 2.086878995100657

Epoch: 6| Step: 13
Training loss: 0.33104851841926575
Validation loss: 2.1234917442003884

Epoch: 275| Step: 0
Training loss: 0.8140035271644592
Validation loss: 2.142461836338043

Epoch: 6| Step: 1
Training loss: 0.7064952850341797
Validation loss: 2.193174401919047

Epoch: 6| Step: 2
Training loss: 0.761475145816803
Validation loss: 2.12789777914683

Epoch: 6| Step: 3
Training loss: 0.6452752947807312
Validation loss: 2.1615319649378457

Epoch: 6| Step: 4
Training loss: 0.7238068580627441
Validation loss: 2.117980718612671

Epoch: 6| Step: 5
Training loss: 0.671705424785614
Validation loss: 2.1618316173553467

Epoch: 6| Step: 6
Training loss: 0.5792992115020752
Validation loss: 2.11370583375295

Epoch: 6| Step: 7
Training loss: 0.6405054330825806
Validation loss: 2.1011516650517783

Epoch: 6| Step: 8
Training loss: 0.571102499961853
Validation loss: 2.137651801109314

Epoch: 6| Step: 9
Training loss: 0.3180767893791199
Validation loss: 2.0866219798723855

Epoch: 6| Step: 10
Training loss: 0.5880950689315796
Validation loss: 2.125422557195028

Epoch: 6| Step: 11
Training loss: 0.814487099647522
Validation loss: 2.0390246311823526

Epoch: 6| Step: 12
Training loss: 0.5063946843147278
Validation loss: 2.118084172407786

Epoch: 6| Step: 13
Training loss: 0.8005133867263794
Validation loss: 2.1400920947392783

Epoch: 276| Step: 0
Training loss: 0.7620630264282227
Validation loss: 2.123132308324178

Epoch: 6| Step: 1
Training loss: 0.6802429556846619
Validation loss: 2.112400392691294

Epoch: 6| Step: 2
Training loss: 0.36774760484695435
Validation loss: 2.0968007246653237

Epoch: 6| Step: 3
Training loss: 0.9255332350730896
Validation loss: 2.1425132950146994

Epoch: 6| Step: 4
Training loss: 0.4786399006843567
Validation loss: 2.111219267050425

Epoch: 6| Step: 5
Training loss: 0.6889597177505493
Validation loss: 2.0681963165601096

Epoch: 6| Step: 6
Training loss: 1.1857473850250244
Validation loss: 2.1376659274101257

Epoch: 6| Step: 7
Training loss: 0.5452300310134888
Validation loss: 2.1210146943728128

Epoch: 6| Step: 8
Training loss: 0.49169355630874634
Validation loss: 2.1391628781954446

Epoch: 6| Step: 9
Training loss: 0.9707058668136597
Validation loss: 2.1486865480740867

Epoch: 6| Step: 10
Training loss: 0.592138409614563
Validation loss: 2.1478196183840432

Epoch: 6| Step: 11
Training loss: 0.49664753675460815
Validation loss: 2.139267901579539

Epoch: 6| Step: 12
Training loss: 0.7094369530677795
Validation loss: 2.166611154874166

Epoch: 6| Step: 13
Training loss: 0.3170013427734375
Validation loss: 2.1295552849769592

Epoch: 277| Step: 0
Training loss: 0.8096082210540771
Validation loss: 2.1637359857559204

Epoch: 6| Step: 1
Training loss: 0.9013394117355347
Validation loss: 2.1404587626457214

Epoch: 6| Step: 2
Training loss: 0.8487898111343384
Validation loss: 2.1003501415252686

Epoch: 6| Step: 3
Training loss: 0.4192315340042114
Validation loss: 2.159941772619883

Epoch: 6| Step: 4
Training loss: 1.0552752017974854
Validation loss: 2.150488018989563

Epoch: 6| Step: 5
Training loss: 0.6307811737060547
Validation loss: 2.1370204289754233

Epoch: 6| Step: 6
Training loss: 0.2542114853858948
Validation loss: 2.1257336139678955

Epoch: 6| Step: 7
Training loss: 0.6908088326454163
Validation loss: 2.204577366511027

Epoch: 6| Step: 8
Training loss: 0.4342797100543976
Validation loss: 2.099711219469706

Epoch: 6| Step: 9
Training loss: 0.739384651184082
Validation loss: 2.142990787823995

Epoch: 6| Step: 10
Training loss: 0.4858652651309967
Validation loss: 2.1094847520192466

Epoch: 6| Step: 11
Training loss: 0.8244392275810242
Validation loss: 2.167773882548014

Epoch: 6| Step: 12
Training loss: 0.29400721192359924
Validation loss: 2.1376511255900064

Epoch: 6| Step: 13
Training loss: 0.4488973319530487
Validation loss: 2.0796876351038613

Epoch: 278| Step: 0
Training loss: 0.6550755500793457
Validation loss: 2.170176366964976

Epoch: 6| Step: 1
Training loss: 0.7194775342941284
Validation loss: 2.092058777809143

Epoch: 6| Step: 2
Training loss: 0.6717617511749268
Validation loss: 2.1252844532330832

Epoch: 6| Step: 3
Training loss: 0.38259458541870117
Validation loss: 2.1478704611460366

Epoch: 6| Step: 4
Training loss: 0.3178725838661194
Validation loss: 2.1825458804766336

Epoch: 6| Step: 5
Training loss: 0.6090371608734131
Validation loss: 2.1683873931566873

Epoch: 6| Step: 6
Training loss: 0.5144427418708801
Validation loss: 2.1454748113950095

Epoch: 6| Step: 7
Training loss: 0.9978036880493164
Validation loss: 2.0990583300590515

Epoch: 6| Step: 8
Training loss: 0.7518172860145569
Validation loss: 2.1081829269727073

Epoch: 6| Step: 9
Training loss: 0.8185142874717712
Validation loss: 2.1530814369519553

Epoch: 6| Step: 10
Training loss: 0.3093106746673584
Validation loss: 2.172306855519613

Epoch: 6| Step: 11
Training loss: 1.110274076461792
Validation loss: 2.108411987622579

Epoch: 6| Step: 12
Training loss: 0.5850398540496826
Validation loss: 2.1440232197443643

Epoch: 6| Step: 13
Training loss: 0.5625900030136108
Validation loss: 2.1213772098223367

Epoch: 279| Step: 0
Training loss: 0.5645435452461243
Validation loss: 2.12483541170756

Epoch: 6| Step: 1
Training loss: 0.4969528019428253
Validation loss: 2.1202345291773477

Epoch: 6| Step: 2
Training loss: 0.49799996614456177
Validation loss: 2.1369346181551614

Epoch: 6| Step: 3
Training loss: 0.6738486289978027
Validation loss: 2.116733968257904

Epoch: 6| Step: 4
Training loss: 1.184291124343872
Validation loss: 2.1717726786931357

Epoch: 6| Step: 5
Training loss: 0.2438925802707672
Validation loss: 2.1177340348561606

Epoch: 6| Step: 6
Training loss: 0.6874476075172424
Validation loss: 2.120323975880941

Epoch: 6| Step: 7
Training loss: 0.6480540633201599
Validation loss: 2.1483953992525735

Epoch: 6| Step: 8
Training loss: 0.549456000328064
Validation loss: 2.1538023153940835

Epoch: 6| Step: 9
Training loss: 1.267492651939392
Validation loss: 2.1306918462117515

Epoch: 6| Step: 10
Training loss: 0.43979859352111816
Validation loss: 2.125280261039734

Epoch: 6| Step: 11
Training loss: 0.579675555229187
Validation loss: 2.122591217358907

Epoch: 6| Step: 12
Training loss: 0.6347004175186157
Validation loss: 2.097079892953237

Epoch: 6| Step: 13
Training loss: 0.2668781876564026
Validation loss: 2.188294072945913

Epoch: 280| Step: 0
Training loss: 0.6452507376670837
Validation loss: 2.1134135524431863

Epoch: 6| Step: 1
Training loss: 0.41963881254196167
Validation loss: 2.0847267309824624

Epoch: 6| Step: 2
Training loss: 0.3624526262283325
Validation loss: 2.15256933371226

Epoch: 6| Step: 3
Training loss: 0.6143834590911865
Validation loss: 2.1383845806121826

Epoch: 6| Step: 4
Training loss: 0.5444728136062622
Validation loss: 2.101199467976888

Epoch: 6| Step: 5
Training loss: 0.7445606589317322
Validation loss: 2.191809137662252

Epoch: 6| Step: 6
Training loss: 1.0636913776397705
Validation loss: 2.124138037363688

Epoch: 6| Step: 7
Training loss: 0.8436248898506165
Validation loss: 2.140633463859558

Epoch: 6| Step: 8
Training loss: 1.0880932807922363
Validation loss: 2.190372347831726

Epoch: 6| Step: 9
Training loss: 0.6157312989234924
Validation loss: 2.2083869775136313

Epoch: 6| Step: 10
Training loss: 0.5830199718475342
Validation loss: 2.150834302107493

Epoch: 6| Step: 11
Training loss: 0.48003455996513367
Validation loss: 2.120511452356974

Epoch: 6| Step: 12
Training loss: 0.7621773481369019
Validation loss: 2.1309934258461

Epoch: 6| Step: 13
Training loss: 0.41476112604141235
Validation loss: 2.134667992591858

Epoch: 281| Step: 0
Training loss: 0.495770663022995
Validation loss: 2.1151696840922036

Epoch: 6| Step: 1
Training loss: 0.42982807755470276
Validation loss: 2.1197491884231567

Epoch: 6| Step: 2
Training loss: 0.8817726969718933
Validation loss: 2.1664554874102273

Epoch: 6| Step: 3
Training loss: 0.457584023475647
Validation loss: 2.1111661990483603

Epoch: 6| Step: 4
Training loss: 0.3218955993652344
Validation loss: 2.2161187132199607

Epoch: 6| Step: 5
Training loss: 1.0457137823104858
Validation loss: 2.225602408250173

Epoch: 6| Step: 6
Training loss: 0.821040153503418
Validation loss: 2.1728344360987344

Epoch: 6| Step: 7
Training loss: 0.738936185836792
Validation loss: 2.165169338385264

Epoch: 6| Step: 8
Training loss: 0.5947620868682861
Validation loss: 2.1121020913124084

Epoch: 6| Step: 9
Training loss: 0.26261401176452637
Validation loss: 2.186400055885315

Epoch: 6| Step: 10
Training loss: 1.2950098514556885
Validation loss: 2.1034829219182334

Epoch: 6| Step: 11
Training loss: 0.5900988578796387
Validation loss: 2.0870511730511985

Epoch: 6| Step: 12
Training loss: 0.48812663555145264
Validation loss: 2.164060811201731

Epoch: 6| Step: 13
Training loss: 0.6403636932373047
Validation loss: 2.130179981390635

Epoch: 282| Step: 0
Training loss: 0.9589218497276306
Validation loss: 2.13206418355306

Epoch: 6| Step: 1
Training loss: 1.2604092359542847
Validation loss: 2.159044623374939

Epoch: 6| Step: 2
Training loss: 0.32677701115608215
Validation loss: 2.2057065765062966

Epoch: 6| Step: 3
Training loss: 0.4122118651866913
Validation loss: 2.145708203315735

Epoch: 6| Step: 4
Training loss: 0.4692251682281494
Validation loss: 2.1304063399632773

Epoch: 6| Step: 5
Training loss: 0.8497576713562012
Validation loss: 2.1373352805773416

Epoch: 6| Step: 6
Training loss: 0.29731905460357666
Validation loss: 2.155526022116343

Epoch: 6| Step: 7
Training loss: 0.666502833366394
Validation loss: 2.167529503504435

Epoch: 6| Step: 8
Training loss: 0.6206210851669312
Validation loss: 2.1502060890197754

Epoch: 6| Step: 9
Training loss: 0.4246370792388916
Validation loss: 2.1965856552124023

Epoch: 6| Step: 10
Training loss: 0.7049861550331116
Validation loss: 2.1819900075594583

Epoch: 6| Step: 11
Training loss: 0.6256200075149536
Validation loss: 2.1193830569585166

Epoch: 6| Step: 12
Training loss: 0.4666685461997986
Validation loss: 2.1235529581705728

Epoch: 6| Step: 13
Training loss: 0.5828388929367065
Validation loss: 2.1581843296686807

Epoch: 283| Step: 0
Training loss: 0.4449988603591919
Validation loss: 2.179425756136576

Epoch: 6| Step: 1
Training loss: 1.0271583795547485
Validation loss: 2.1132090091705322

Epoch: 6| Step: 2
Training loss: 0.5768037438392639
Validation loss: 2.130077322324117

Epoch: 6| Step: 3
Training loss: 0.48999345302581787
Validation loss: 2.1562655369440713

Epoch: 6| Step: 4
Training loss: 0.6815673112869263
Validation loss: 2.112870713075002

Epoch: 6| Step: 5
Training loss: 0.5249923467636108
Validation loss: 2.1357836723327637

Epoch: 6| Step: 6
Training loss: 0.2796599566936493
Validation loss: 2.151258865992228

Epoch: 6| Step: 7
Training loss: 0.5777357220649719
Validation loss: 2.109127382437388

Epoch: 6| Step: 8
Training loss: 0.6660819053649902
Validation loss: 2.152178426583608

Epoch: 6| Step: 9
Training loss: 1.052467703819275
Validation loss: 2.192943572998047

Epoch: 6| Step: 10
Training loss: 0.6466884613037109
Validation loss: 2.1702287197113037

Epoch: 6| Step: 11
Training loss: 0.6214942932128906
Validation loss: 2.1695186694463096

Epoch: 6| Step: 12
Training loss: 0.5332317352294922
Validation loss: 2.1173035701115928

Epoch: 6| Step: 13
Training loss: 0.6430462598800659
Validation loss: 2.1301914850870767

Epoch: 284| Step: 0
Training loss: 0.7527081966400146
Validation loss: 2.156196971734365

Epoch: 6| Step: 1
Training loss: 0.2644345462322235
Validation loss: 2.1853493650754294

Epoch: 6| Step: 2
Training loss: 0.46056151390075684
Validation loss: 2.123885154724121

Epoch: 6| Step: 3
Training loss: 0.6935819387435913
Validation loss: 2.127074380715688

Epoch: 6| Step: 4
Training loss: 0.3557538688182831
Validation loss: 2.0743654370307922

Epoch: 6| Step: 5
Training loss: 0.5194381475448608
Validation loss: 2.1009220083554587

Epoch: 6| Step: 6
Training loss: 0.7139832973480225
Validation loss: 2.1671136021614075

Epoch: 6| Step: 7
Training loss: 0.6917487382888794
Validation loss: 2.1486403743426004

Epoch: 6| Step: 8
Training loss: 1.1238999366760254
Validation loss: 2.1747698386510215

Epoch: 6| Step: 9
Training loss: 0.692737877368927
Validation loss: 2.1250720222791037

Epoch: 6| Step: 10
Training loss: 0.7233003377914429
Validation loss: 2.1316709915796914

Epoch: 6| Step: 11
Training loss: 0.9380077719688416
Validation loss: 2.1035208304723105

Epoch: 6| Step: 12
Training loss: 0.4848114848136902
Validation loss: 2.1318187912305198

Epoch: 6| Step: 13
Training loss: 0.3505970239639282
Validation loss: 2.0874286890029907

Epoch: 285| Step: 0
Training loss: 0.5514231324195862
Validation loss: 2.1777358651161194

Epoch: 6| Step: 1
Training loss: 0.6162900924682617
Validation loss: 2.1267575224240622

Epoch: 6| Step: 2
Training loss: 0.9609448909759521
Validation loss: 2.1405292749404907

Epoch: 6| Step: 3
Training loss: 0.9781233668327332
Validation loss: 2.1337541540463767

Epoch: 6| Step: 4
Training loss: 0.4939188063144684
Validation loss: 2.160286545753479

Epoch: 6| Step: 5
Training loss: 0.4464774429798126
Validation loss: 2.0973225831985474

Epoch: 6| Step: 6
Training loss: 0.5384799242019653
Validation loss: 2.087555011113485

Epoch: 6| Step: 7
Training loss: 0.25791677832603455
Validation loss: 2.107455531756083

Epoch: 6| Step: 8
Training loss: 0.510106086730957
Validation loss: 2.1251505414644876

Epoch: 6| Step: 9
Training loss: 1.1111153364181519
Validation loss: 2.1311678091684976

Epoch: 6| Step: 10
Training loss: 0.5154252052307129
Validation loss: 2.0789410869280496

Epoch: 6| Step: 11
Training loss: 0.39157140254974365
Validation loss: 2.1040746569633484

Epoch: 6| Step: 12
Training loss: 0.6181248426437378
Validation loss: 2.122894903024038

Epoch: 6| Step: 13
Training loss: 0.5074805021286011
Validation loss: 2.1109691858291626

Epoch: 286| Step: 0
Training loss: 0.375052273273468
Validation loss: 2.1409629384676614

Epoch: 6| Step: 1
Training loss: 0.8393943905830383
Validation loss: 2.1513532201449075

Epoch: 6| Step: 2
Training loss: 0.9033219218254089
Validation loss: 2.173089245955149

Epoch: 6| Step: 3
Training loss: 0.7499303817749023
Validation loss: 2.156496504942576

Epoch: 6| Step: 4
Training loss: 0.7814380526542664
Validation loss: 2.0701900323232016

Epoch: 6| Step: 5
Training loss: 0.6147840023040771
Validation loss: 2.114868422349294

Epoch: 6| Step: 6
Training loss: 0.5109177231788635
Validation loss: 2.1063125332196555

Epoch: 6| Step: 7
Training loss: 0.6234309077262878
Validation loss: 2.0936383803685508

Epoch: 6| Step: 8
Training loss: 0.4481082558631897
Validation loss: 2.132062554359436

Epoch: 6| Step: 9
Training loss: 0.6504993438720703
Validation loss: 2.1767034331957498

Epoch: 6| Step: 10
Training loss: 0.5230612754821777
Validation loss: 2.206208328406016

Epoch: 6| Step: 11
Training loss: 0.4423893690109253
Validation loss: 2.1361725529034934

Epoch: 6| Step: 12
Training loss: 0.9712762236595154
Validation loss: 2.1493213375409446

Epoch: 6| Step: 13
Training loss: 0.5065631866455078
Validation loss: 2.13985941807429

Epoch: 287| Step: 0
Training loss: 0.6411449909210205
Validation loss: 2.1777075131734214

Epoch: 6| Step: 1
Training loss: 0.7866013050079346
Validation loss: 2.0789470871289573

Epoch: 6| Step: 2
Training loss: 0.512929379940033
Validation loss: 2.0792083541552224

Epoch: 6| Step: 3
Training loss: 0.7949483394622803
Validation loss: 2.074156721433004

Epoch: 6| Step: 4
Training loss: 0.7500268220901489
Validation loss: 2.10487029949824

Epoch: 6| Step: 5
Training loss: 0.38190674781799316
Validation loss: 2.11954273780187

Epoch: 6| Step: 6
Training loss: 0.47793328762054443
Validation loss: 2.135948141415914

Epoch: 6| Step: 7
Training loss: 0.3288919925689697
Validation loss: 2.0833309491475425

Epoch: 6| Step: 8
Training loss: 0.7716917395591736
Validation loss: 2.115913689136505

Epoch: 6| Step: 9
Training loss: 0.4029048681259155
Validation loss: 2.158316115538279

Epoch: 6| Step: 10
Training loss: 0.8377455472946167
Validation loss: 2.1623509724934897

Epoch: 6| Step: 11
Training loss: 0.4486998915672302
Validation loss: 2.1452236572901406

Epoch: 6| Step: 12
Training loss: 0.4769638776779175
Validation loss: 2.1271398067474365

Epoch: 6| Step: 13
Training loss: 0.9347546100616455
Validation loss: 2.1445010900497437

Epoch: 288| Step: 0
Training loss: 0.48803937435150146
Validation loss: 2.1385759313901267

Epoch: 6| Step: 1
Training loss: 0.7299323678016663
Validation loss: 2.081421415011088

Epoch: 6| Step: 2
Training loss: 0.8017797470092773
Validation loss: 2.1224411129951477

Epoch: 6| Step: 3
Training loss: 0.5303733944892883
Validation loss: 2.1128340562184653

Epoch: 6| Step: 4
Training loss: 0.9231162071228027
Validation loss: 2.088602840900421

Epoch: 6| Step: 5
Training loss: 0.2756444215774536
Validation loss: 2.124143362045288

Epoch: 6| Step: 6
Training loss: 0.42708665132522583
Validation loss: 2.1415525476137796

Epoch: 6| Step: 7
Training loss: 0.753585934638977
Validation loss: 2.1400602658589682

Epoch: 6| Step: 8
Training loss: 0.6341556310653687
Validation loss: 2.106350064277649

Epoch: 6| Step: 9
Training loss: 0.5849608182907104
Validation loss: 2.132804294427236

Epoch: 6| Step: 10
Training loss: 0.673940896987915
Validation loss: 2.139070451259613

Epoch: 6| Step: 11
Training loss: 0.5091825723648071
Validation loss: 2.1357645789782205

Epoch: 6| Step: 12
Training loss: 0.6148983836174011
Validation loss: 2.1216859221458435

Epoch: 6| Step: 13
Training loss: 0.8682091236114502
Validation loss: 2.104004720846812

Epoch: 289| Step: 0
Training loss: 0.25640183687210083
Validation loss: 2.093250115712484

Epoch: 6| Step: 1
Training loss: 0.735200047492981
Validation loss: 2.15738046169281

Epoch: 6| Step: 2
Training loss: 0.5633506774902344
Validation loss: 2.1387616793314614

Epoch: 6| Step: 3
Training loss: 0.6936091184616089
Validation loss: 2.149701019128164

Epoch: 6| Step: 4
Training loss: 0.20307303965091705
Validation loss: 2.091206192970276

Epoch: 6| Step: 5
Training loss: 0.5113581418991089
Validation loss: 2.1306521892547607

Epoch: 6| Step: 6
Training loss: 0.5477990508079529
Validation loss: 2.1255285342534385

Epoch: 6| Step: 7
Training loss: 0.391674280166626
Validation loss: 2.0911168853441873

Epoch: 6| Step: 8
Training loss: 0.5709713101387024
Validation loss: 2.175078014532725

Epoch: 6| Step: 9
Training loss: 0.517943799495697
Validation loss: 2.119117339452108

Epoch: 6| Step: 10
Training loss: 0.78750079870224
Validation loss: 2.12752765417099

Epoch: 6| Step: 11
Training loss: 0.6986852288246155
Validation loss: 2.1183199683825173

Epoch: 6| Step: 12
Training loss: 1.2341723442077637
Validation loss: 2.134717345237732

Epoch: 6| Step: 13
Training loss: 0.6616946458816528
Validation loss: 2.1545891165733337

Epoch: 290| Step: 0
Training loss: 0.6028290390968323
Validation loss: 2.133325775464376

Epoch: 6| Step: 1
Training loss: 0.45864811539649963
Validation loss: 2.174415568510691

Epoch: 6| Step: 2
Training loss: 0.7838438749313354
Validation loss: 2.11452708641688

Epoch: 6| Step: 3
Training loss: 0.3962622582912445
Validation loss: 2.179724852244059

Epoch: 6| Step: 4
Training loss: 0.3762857913970947
Validation loss: 2.1057206789652505

Epoch: 6| Step: 5
Training loss: 0.655422031879425
Validation loss: 2.1417694687843323

Epoch: 6| Step: 6
Training loss: 0.4680817127227783
Validation loss: 2.096356769402822

Epoch: 6| Step: 7
Training loss: 0.7282052040100098
Validation loss: 2.082338511943817

Epoch: 6| Step: 8
Training loss: 0.30458444356918335
Validation loss: 2.1097909609476724

Epoch: 6| Step: 9
Training loss: 1.3853919506072998
Validation loss: 2.1099231839179993

Epoch: 6| Step: 10
Training loss: 0.9728747606277466
Validation loss: 2.152212123076121

Epoch: 6| Step: 11
Training loss: 0.5182004570960999
Validation loss: 2.1477151910463967

Epoch: 6| Step: 12
Training loss: 0.502261757850647
Validation loss: 2.099821368853251

Epoch: 6| Step: 13
Training loss: 0.6523890495300293
Validation loss: 2.1724180380503335

Epoch: 291| Step: 0
Training loss: 0.6142324805259705
Validation loss: 2.138818701108297

Epoch: 6| Step: 1
Training loss: 0.9745400547981262
Validation loss: 2.1639097929000854

Epoch: 6| Step: 2
Training loss: 0.5444511771202087
Validation loss: 2.1200502713521323

Epoch: 6| Step: 3
Training loss: 0.6507007479667664
Validation loss: 2.1900781790415444

Epoch: 6| Step: 4
Training loss: 0.41289275884628296
Validation loss: 2.1114080349604287

Epoch: 6| Step: 5
Training loss: 0.49151161313056946
Validation loss: 2.1611945231755576

Epoch: 6| Step: 6
Training loss: 0.6241029500961304
Validation loss: 2.1275481979052224

Epoch: 6| Step: 7
Training loss: 0.929160475730896
Validation loss: 2.1377347707748413

Epoch: 6| Step: 8
Training loss: 0.8098726272583008
Validation loss: 2.1151402393976846

Epoch: 6| Step: 9
Training loss: 1.3377455472946167
Validation loss: 2.0972903768221536

Epoch: 6| Step: 10
Training loss: 0.64614337682724
Validation loss: 2.110875407854716

Epoch: 6| Step: 11
Training loss: 0.6144136786460876
Validation loss: 2.061554789543152

Epoch: 6| Step: 12
Training loss: 0.5219510197639465
Validation loss: 2.1440505981445312

Epoch: 6| Step: 13
Training loss: 0.3619052469730377
Validation loss: 2.08374430735906

Epoch: 292| Step: 0
Training loss: 0.620729923248291
Validation loss: 2.1609333157539368

Epoch: 6| Step: 1
Training loss: 0.5822873115539551
Validation loss: 2.1562503377596536

Epoch: 6| Step: 2
Training loss: 0.7082237601280212
Validation loss: 2.1326085329055786

Epoch: 6| Step: 3
Training loss: 1.093625783920288
Validation loss: 2.1498755613962808

Epoch: 6| Step: 4
Training loss: 0.6534058451652527
Validation loss: 2.1316929260889688

Epoch: 6| Step: 5
Training loss: 0.5521106719970703
Validation loss: 2.0628559986750283

Epoch: 6| Step: 6
Training loss: 0.8810889720916748
Validation loss: 2.122526446978251

Epoch: 6| Step: 7
Training loss: 0.3341791033744812
Validation loss: 2.1289967695871987

Epoch: 6| Step: 8
Training loss: 0.7539523839950562
Validation loss: 2.116699457168579

Epoch: 6| Step: 9
Training loss: 0.7272958755493164
Validation loss: 2.1732043027877808

Epoch: 6| Step: 10
Training loss: 0.3605721890926361
Validation loss: 2.14288858572642

Epoch: 6| Step: 11
Training loss: 0.5147063732147217
Validation loss: 2.1054527163505554

Epoch: 6| Step: 12
Training loss: 0.30566051602363586
Validation loss: 2.073166569073995

Epoch: 6| Step: 13
Training loss: 0.630652904510498
Validation loss: 2.138468325138092

Epoch: 293| Step: 0
Training loss: 0.5773332118988037
Validation loss: 2.1454504330952964

Epoch: 6| Step: 1
Training loss: 0.6434770822525024
Validation loss: 2.0899848143259683

Epoch: 6| Step: 2
Training loss: 0.6466107368469238
Validation loss: 2.1130677660306296

Epoch: 6| Step: 3
Training loss: 0.9140456318855286
Validation loss: 2.1136523286501565

Epoch: 6| Step: 4
Training loss: 0.4213848114013672
Validation loss: 2.147164046764374

Epoch: 6| Step: 5
Training loss: 0.5011327266693115
Validation loss: 2.1335411071777344

Epoch: 6| Step: 6
Training loss: 0.6923381090164185
Validation loss: 2.1418546040852866

Epoch: 6| Step: 7
Training loss: 0.4108802378177643
Validation loss: 2.131234029928843

Epoch: 6| Step: 8
Training loss: 0.9756251573562622
Validation loss: 2.1697797576586404

Epoch: 6| Step: 9
Training loss: 0.4667099416255951
Validation loss: 2.116565386454264

Epoch: 6| Step: 10
Training loss: 0.45312273502349854
Validation loss: 2.177085041999817

Epoch: 6| Step: 11
Training loss: 0.3535655736923218
Validation loss: 2.1295500993728638

Epoch: 6| Step: 12
Training loss: 0.5357180237770081
Validation loss: 2.1303839683532715

Epoch: 6| Step: 13
Training loss: 0.478621244430542
Validation loss: 2.0907435019810996

Epoch: 294| Step: 0
Training loss: 0.8293417096138
Validation loss: 2.166003863016764

Epoch: 6| Step: 1
Training loss: 0.5067855715751648
Validation loss: 2.1791892449061074

Epoch: 6| Step: 2
Training loss: 0.3517206013202667
Validation loss: 2.161644478638967

Epoch: 6| Step: 3
Training loss: 0.2904163599014282
Validation loss: 2.13601682583491

Epoch: 6| Step: 4
Training loss: 0.45145171880722046
Validation loss: 2.118481159210205

Epoch: 6| Step: 5
Training loss: 0.5993114709854126
Validation loss: 2.126069108645121

Epoch: 6| Step: 6
Training loss: 0.643587052822113
Validation loss: 2.109458943208059

Epoch: 6| Step: 7
Training loss: 0.3706357777118683
Validation loss: 2.1464691956837973

Epoch: 6| Step: 8
Training loss: 0.4933806359767914
Validation loss: 2.185616135597229

Epoch: 6| Step: 9
Training loss: 0.9187886118888855
Validation loss: 2.1423351963361106

Epoch: 6| Step: 10
Training loss: 0.5789033770561218
Validation loss: 2.1005987524986267

Epoch: 6| Step: 11
Training loss: 0.7911452054977417
Validation loss: 2.14851713180542

Epoch: 6| Step: 12
Training loss: 0.2399829924106598
Validation loss: 2.139273722966512

Epoch: 6| Step: 13
Training loss: 0.9919412136077881
Validation loss: 2.143315235773722

Epoch: 295| Step: 0
Training loss: 0.36770644783973694
Validation loss: 2.0997258027394614

Epoch: 6| Step: 1
Training loss: 0.6944321990013123
Validation loss: 2.0927924315134683

Epoch: 6| Step: 2
Training loss: 0.3755897879600525
Validation loss: 2.195729653040568

Epoch: 6| Step: 3
Training loss: 0.7950036525726318
Validation loss: 2.154840668042501

Epoch: 6| Step: 4
Training loss: 0.8011658191680908
Validation loss: 2.109841505686442

Epoch: 6| Step: 5
Training loss: 0.5371481776237488
Validation loss: 2.134669760862986

Epoch: 6| Step: 6
Training loss: 0.46846485137939453
Validation loss: 2.149128715197245

Epoch: 6| Step: 7
Training loss: 0.677989661693573
Validation loss: 2.1171162923177085

Epoch: 6| Step: 8
Training loss: 0.8524553775787354
Validation loss: 2.134233375390371

Epoch: 6| Step: 9
Training loss: 0.4902985990047455
Validation loss: 2.099127729733785

Epoch: 6| Step: 10
Training loss: 0.4239073693752289
Validation loss: 2.129052678743998

Epoch: 6| Step: 11
Training loss: 0.32731863856315613
Validation loss: 2.139815330505371

Epoch: 6| Step: 12
Training loss: 0.5843181014060974
Validation loss: 2.09210596481959

Epoch: 6| Step: 13
Training loss: 0.596868634223938
Validation loss: 2.135393500328064

Epoch: 296| Step: 0
Training loss: 0.5847048163414001
Validation loss: 2.0522029797236123

Epoch: 6| Step: 1
Training loss: 0.6746079921722412
Validation loss: 2.129486163457235

Epoch: 6| Step: 2
Training loss: 0.6852133274078369
Validation loss: 2.1293174028396606

Epoch: 6| Step: 3
Training loss: 0.5285240411758423
Validation loss: 2.1359382470448813

Epoch: 6| Step: 4
Training loss: 0.7459644079208374
Validation loss: 2.1993378599484763

Epoch: 6| Step: 5
Training loss: 0.5677052736282349
Validation loss: 2.123570958773295

Epoch: 6| Step: 6
Training loss: 0.17547829449176788
Validation loss: 2.117571691672007

Epoch: 6| Step: 7
Training loss: 0.4424402415752411
Validation loss: 2.0802046060562134

Epoch: 6| Step: 8
Training loss: 0.4235301613807678
Validation loss: 2.1465328137079873

Epoch: 6| Step: 9
Training loss: 0.2814893126487732
Validation loss: 2.155512352784475

Epoch: 6| Step: 10
Training loss: 0.7974832057952881
Validation loss: 2.1381993691126504

Epoch: 6| Step: 11
Training loss: 0.8346920013427734
Validation loss: 2.124406615893046

Epoch: 6| Step: 12
Training loss: 0.5302180647850037
Validation loss: 2.1551254391670227

Epoch: 6| Step: 13
Training loss: 0.4252776801586151
Validation loss: 2.1603357990582785

Epoch: 297| Step: 0
Training loss: 0.41780465841293335
Validation loss: 2.1048081119855246

Epoch: 6| Step: 1
Training loss: 0.7899307012557983
Validation loss: 2.13484517733256

Epoch: 6| Step: 2
Training loss: 0.6052312850952148
Validation loss: 2.1267606019973755

Epoch: 6| Step: 3
Training loss: 0.632882833480835
Validation loss: 2.129832069079081

Epoch: 6| Step: 4
Training loss: 0.7430001497268677
Validation loss: 2.134450534979502

Epoch: 6| Step: 5
Training loss: 0.7368289232254028
Validation loss: 2.1632285714149475

Epoch: 6| Step: 6
Training loss: 0.47979921102523804
Validation loss: 2.100358009338379

Epoch: 6| Step: 7
Training loss: 0.489230751991272
Validation loss: 2.1211836338043213

Epoch: 6| Step: 8
Training loss: 0.6724084615707397
Validation loss: 2.1739834745724997

Epoch: 6| Step: 9
Training loss: 0.47062981128692627
Validation loss: 2.164552609125773

Epoch: 6| Step: 10
Training loss: 0.4402765929698944
Validation loss: 2.1684980988502502

Epoch: 6| Step: 11
Training loss: 1.046684980392456
Validation loss: 2.0939822594324746

Epoch: 6| Step: 12
Training loss: 0.45655006170272827
Validation loss: 2.131517469882965

Epoch: 6| Step: 13
Training loss: 0.347120463848114
Validation loss: 2.124780615170797

Epoch: 298| Step: 0
Training loss: 0.267952561378479
Validation loss: 2.0730435450871787

Epoch: 6| Step: 1
Training loss: 0.43938738107681274
Validation loss: 2.1133973797162375

Epoch: 6| Step: 2
Training loss: 1.0484992265701294
Validation loss: 2.1297848224639893

Epoch: 6| Step: 3
Training loss: 0.6343021988868713
Validation loss: 2.105423887570699

Epoch: 6| Step: 4
Training loss: 0.5967913866043091
Validation loss: 2.111481487751007

Epoch: 6| Step: 5
Training loss: 0.3941269516944885
Validation loss: 2.200985928376516

Epoch: 6| Step: 6
Training loss: 0.8675087094306946
Validation loss: 2.110102971394857

Epoch: 6| Step: 7
Training loss: 0.648321270942688
Validation loss: 2.166433115800222

Epoch: 6| Step: 8
Training loss: 0.5120797157287598
Validation loss: 2.1081411838531494

Epoch: 6| Step: 9
Training loss: 0.8756355047225952
Validation loss: 2.1145503520965576

Epoch: 6| Step: 10
Training loss: 0.7378989458084106
Validation loss: 2.1438868045806885

Epoch: 6| Step: 11
Training loss: 0.23623888194561005
Validation loss: 2.08800075451533

Epoch: 6| Step: 12
Training loss: 0.34873414039611816
Validation loss: 2.0696789423624673

Epoch: 6| Step: 13
Training loss: 0.44720661640167236
Validation loss: 2.122209588686625

Epoch: 299| Step: 0
Training loss: 0.41105878353118896
Validation loss: 2.0950343012809753

Epoch: 6| Step: 1
Training loss: 0.41331255435943604
Validation loss: 2.102560520172119

Epoch: 6| Step: 2
Training loss: 0.3724015951156616
Validation loss: 2.1510625878969827

Epoch: 6| Step: 3
Training loss: 0.44593554735183716
Validation loss: 2.160452365875244

Epoch: 6| Step: 4
Training loss: 1.8315532207489014
Validation loss: 2.1790148417154946

Epoch: 6| Step: 5
Training loss: 0.46746474504470825
Validation loss: 2.178882916768392

Epoch: 6| Step: 6
Training loss: 0.5382093787193298
Validation loss: 2.1492557326952615

Epoch: 6| Step: 7
Training loss: 0.276900976896286
Validation loss: 2.102640132109324

Epoch: 6| Step: 8
Training loss: 0.36126434803009033
Validation loss: 2.18672114610672

Epoch: 6| Step: 9
Training loss: 0.8701602220535278
Validation loss: 2.1116347511609397

Epoch: 6| Step: 10
Training loss: 0.6075096130371094
Validation loss: 2.121415615081787

Epoch: 6| Step: 11
Training loss: 0.354758620262146
Validation loss: 2.1487916906674704

Epoch: 6| Step: 12
Training loss: 0.6759011149406433
Validation loss: 2.1521785060564675

Epoch: 6| Step: 13
Training loss: 0.6157790422439575
Validation loss: 2.083134114742279

Epoch: 300| Step: 0
Training loss: 0.6911428570747375
Validation loss: 2.1463700334231057

Epoch: 6| Step: 1
Training loss: 0.4940061867237091
Validation loss: 2.1323589086532593

Epoch: 6| Step: 2
Training loss: 0.2834976315498352
Validation loss: 2.1170630852381387

Epoch: 6| Step: 3
Training loss: 0.4155789315700531
Validation loss: 2.119751811027527

Epoch: 6| Step: 4
Training loss: 0.5425493717193604
Validation loss: 2.1557995478312173

Epoch: 6| Step: 5
Training loss: 0.4001010060310364
Validation loss: 2.1444247563680015

Epoch: 6| Step: 6
Training loss: 0.5244060754776001
Validation loss: 2.134556253751119

Epoch: 6| Step: 7
Training loss: 0.6768163442611694
Validation loss: 2.132146716117859

Epoch: 6| Step: 8
Training loss: 0.34010136127471924
Validation loss: 2.1672857205073037

Epoch: 6| Step: 9
Training loss: 0.8072289824485779
Validation loss: 2.160806179046631

Epoch: 6| Step: 10
Training loss: 0.7804795503616333
Validation loss: 2.142442762851715

Epoch: 6| Step: 11
Training loss: 0.6220153570175171
Validation loss: 2.1826396385828652

Epoch: 6| Step: 12
Training loss: 0.19972366094589233
Validation loss: 2.1335612138112388

Epoch: 6| Step: 13
Training loss: 1.1040000915527344
Validation loss: 2.1440073450406394

Epoch: 301| Step: 0
Training loss: 0.34706243872642517
Validation loss: 2.1637523571650186

Epoch: 6| Step: 1
Training loss: 0.5041832327842712
Validation loss: 2.191240827242533

Epoch: 6| Step: 2
Training loss: 0.9212646484375
Validation loss: 2.1341362396876016

Epoch: 6| Step: 3
Training loss: 0.561784029006958
Validation loss: 2.1416483720143638

Epoch: 6| Step: 4
Training loss: 0.3955731987953186
Validation loss: 2.1587520043055215

Epoch: 6| Step: 5
Training loss: 0.42575952410697937
Validation loss: 2.1329798499743142

Epoch: 6| Step: 6
Training loss: 0.3789865970611572
Validation loss: 2.1211679577827454

Epoch: 6| Step: 7
Training loss: 0.6356598138809204
Validation loss: 2.1170307795206704

Epoch: 6| Step: 8
Training loss: 0.460254430770874
Validation loss: 2.101757844289144

Epoch: 6| Step: 9
Training loss: 1.5154767036437988
Validation loss: 2.095338543256124

Epoch: 6| Step: 10
Training loss: 0.548965334892273
Validation loss: 2.0431580344835916

Epoch: 6| Step: 11
Training loss: 0.5610760450363159
Validation loss: 2.176118771235148

Epoch: 6| Step: 12
Training loss: 0.3802769184112549
Validation loss: 2.1510100762049356

Epoch: 6| Step: 13
Training loss: 0.525822639465332
Validation loss: 2.1742199460665383

Epoch: 302| Step: 0
Training loss: 0.5834671258926392
Validation loss: 2.060217559337616

Epoch: 6| Step: 1
Training loss: 0.37058010697364807
Validation loss: 2.1719202796618142

Epoch: 6| Step: 2
Training loss: 0.6446706056594849
Validation loss: 2.1207741300264993

Epoch: 6| Step: 3
Training loss: 0.7918944358825684
Validation loss: 2.1090586185455322

Epoch: 6| Step: 4
Training loss: 0.5105781555175781
Validation loss: 2.1693941354751587

Epoch: 6| Step: 5
Training loss: 0.4907234311103821
Validation loss: 2.1257603963216147

Epoch: 6| Step: 6
Training loss: 0.3490270674228668
Validation loss: 2.1426421801249185

Epoch: 6| Step: 7
Training loss: 0.5979219675064087
Validation loss: 2.11240017414093

Epoch: 6| Step: 8
Training loss: 0.34591975808143616
Validation loss: 2.1377428571383157

Epoch: 6| Step: 9
Training loss: 0.8423323035240173
Validation loss: 2.113354444503784

Epoch: 6| Step: 10
Training loss: 0.5713968276977539
Validation loss: 2.1762821078300476

Epoch: 6| Step: 11
Training loss: 0.7561328411102295
Validation loss: 2.1192970871925354

Epoch: 6| Step: 12
Training loss: 0.2706204652786255
Validation loss: 2.1760724782943726

Epoch: 6| Step: 13
Training loss: 0.9791377782821655
Validation loss: 2.093344529469808

Epoch: 303| Step: 0
Training loss: 0.24109402298927307
Validation loss: 2.1035404205322266

Epoch: 6| Step: 1
Training loss: 0.610899806022644
Validation loss: 2.119726916154226

Epoch: 6| Step: 2
Training loss: 0.38641080260276794
Validation loss: 2.1817164023717246

Epoch: 6| Step: 3
Training loss: 1.0626804828643799
Validation loss: 2.1297250588734946

Epoch: 6| Step: 4
Training loss: 0.3380953073501587
Validation loss: 2.1018872062365213

Epoch: 6| Step: 5
Training loss: 0.8557734489440918
Validation loss: 2.1082871556282043

Epoch: 6| Step: 6
Training loss: 0.699223518371582
Validation loss: 2.127260466416677

Epoch: 6| Step: 7
Training loss: 0.5903997421264648
Validation loss: 2.1214802265167236

Epoch: 6| Step: 8
Training loss: 0.5468094348907471
Validation loss: 2.096628030141195

Epoch: 6| Step: 9
Training loss: 0.622316837310791
Validation loss: 2.2058438062667847

Epoch: 6| Step: 10
Training loss: 0.5316581726074219
Validation loss: 2.1575626532236734

Epoch: 6| Step: 11
Training loss: 0.37972044944763184
Validation loss: 2.1225247581799827

Epoch: 6| Step: 12
Training loss: 0.6550209522247314
Validation loss: 2.1220128536224365

Epoch: 6| Step: 13
Training loss: 0.5110024809837341
Validation loss: 2.1469589869181314

Epoch: 304| Step: 0
Training loss: 0.7021497488021851
Validation loss: 2.115081230799357

Epoch: 6| Step: 1
Training loss: 0.5998536348342896
Validation loss: 2.107567230860392

Epoch: 6| Step: 2
Training loss: 0.6033231616020203
Validation loss: 2.121124565601349

Epoch: 6| Step: 3
Training loss: 0.4038681089878082
Validation loss: 2.1261744697888694

Epoch: 6| Step: 4
Training loss: 0.438798725605011
Validation loss: 2.126790781815847

Epoch: 6| Step: 5
Training loss: 0.47633635997772217
Validation loss: 2.1277156670888266

Epoch: 6| Step: 6
Training loss: 0.7190873622894287
Validation loss: 2.1027682622273765

Epoch: 6| Step: 7
Training loss: 0.2106211632490158
Validation loss: 2.1445342699686685

Epoch: 6| Step: 8
Training loss: 0.7557110786437988
Validation loss: 2.113781452178955

Epoch: 6| Step: 9
Training loss: 0.6909207105636597
Validation loss: 2.1242523392041526

Epoch: 6| Step: 10
Training loss: 0.3728579878807068
Validation loss: 2.1488544940948486

Epoch: 6| Step: 11
Training loss: 0.4040104150772095
Validation loss: 2.1863066951433816

Epoch: 6| Step: 12
Training loss: 0.40341004729270935
Validation loss: 2.1467294494311013

Epoch: 6| Step: 13
Training loss: 0.9237676858901978
Validation loss: 2.091103712717692

Epoch: 305| Step: 0
Training loss: 0.2841629087924957
Validation loss: 2.119052231311798

Epoch: 6| Step: 1
Training loss: 0.5285606384277344
Validation loss: 2.1589791576067605

Epoch: 6| Step: 2
Training loss: 0.5405623912811279
Validation loss: 2.109349767367045

Epoch: 6| Step: 3
Training loss: 0.23723918199539185
Validation loss: 2.125006675720215

Epoch: 6| Step: 4
Training loss: 0.8894028663635254
Validation loss: 2.153264323870341

Epoch: 6| Step: 5
Training loss: 0.9181901812553406
Validation loss: 2.1233900586764016

Epoch: 6| Step: 6
Training loss: 0.5172723531723022
Validation loss: 2.158263365427653

Epoch: 6| Step: 7
Training loss: 0.49855536222457886
Validation loss: 2.1279825369517007

Epoch: 6| Step: 8
Training loss: 0.6797680258750916
Validation loss: 2.138195355733236

Epoch: 6| Step: 9
Training loss: 0.2559688985347748
Validation loss: 2.167277197043101

Epoch: 6| Step: 10
Training loss: 1.024035930633545
Validation loss: 2.134389877319336

Epoch: 6| Step: 11
Training loss: 0.5089424848556519
Validation loss: 2.1509904861450195

Epoch: 6| Step: 12
Training loss: 0.5608067512512207
Validation loss: 2.1342642108599343

Epoch: 6| Step: 13
Training loss: 0.4996964633464813
Validation loss: 2.144420007864634

Epoch: 306| Step: 0
Training loss: 0.45640748739242554
Validation loss: 2.1119481523831687

Epoch: 6| Step: 1
Training loss: 0.4274222254753113
Validation loss: 2.1971253951390586

Epoch: 6| Step: 2
Training loss: 0.5163542032241821
Validation loss: 2.100801865259806

Epoch: 6| Step: 3
Training loss: 0.3262309432029724
Validation loss: 2.206792970498403

Epoch: 6| Step: 4
Training loss: 0.5168606638908386
Validation loss: 2.19432940085729

Epoch: 6| Step: 5
Training loss: 0.34439337253570557
Validation loss: 2.1229201555252075

Epoch: 6| Step: 6
Training loss: 1.1389347314834595
Validation loss: 2.1410505374272666

Epoch: 6| Step: 7
Training loss: 0.7038809061050415
Validation loss: 2.147885719935099

Epoch: 6| Step: 8
Training loss: 0.556456983089447
Validation loss: 2.1774054765701294

Epoch: 6| Step: 9
Training loss: 0.43396061658859253
Validation loss: 2.1056723395983377

Epoch: 6| Step: 10
Training loss: 0.536516547203064
Validation loss: 2.12097821633021

Epoch: 6| Step: 11
Training loss: 0.6567590832710266
Validation loss: 2.161112109820048

Epoch: 6| Step: 12
Training loss: 0.6587862372398376
Validation loss: 2.180218776067098

Epoch: 6| Step: 13
Training loss: 0.5658724308013916
Validation loss: 2.1414742469787598

Epoch: 307| Step: 0
Training loss: 0.796695351600647
Validation loss: 2.1486277182896933

Epoch: 6| Step: 1
Training loss: 0.6686596870422363
Validation loss: 2.1433849930763245

Epoch: 6| Step: 2
Training loss: 0.7420101165771484
Validation loss: 2.1550350189208984

Epoch: 6| Step: 3
Training loss: 0.41961997747421265
Validation loss: 2.1796775261561074

Epoch: 6| Step: 4
Training loss: 0.46322572231292725
Validation loss: 2.1119614839553833

Epoch: 6| Step: 5
Training loss: 0.34380537271499634
Validation loss: 2.131827175617218

Epoch: 6| Step: 6
Training loss: 0.4712963104248047
Validation loss: 2.111461639404297

Epoch: 6| Step: 7
Training loss: 0.8873485922813416
Validation loss: 2.115058978398641

Epoch: 6| Step: 8
Training loss: 0.4848743975162506
Validation loss: 2.1178137063980103

Epoch: 6| Step: 9
Training loss: 1.0293769836425781
Validation loss: 2.1180140574773154

Epoch: 6| Step: 10
Training loss: 0.6570101976394653
Validation loss: 2.165213962395986

Epoch: 6| Step: 11
Training loss: 0.31279444694519043
Validation loss: 2.143249968687693

Epoch: 6| Step: 12
Training loss: 0.5556873679161072
Validation loss: 2.127139925956726

Epoch: 6| Step: 13
Training loss: 0.5859438180923462
Validation loss: 2.180500566959381

Epoch: 308| Step: 0
Training loss: 0.4085194170475006
Validation loss: 2.1193689902623496

Epoch: 6| Step: 1
Training loss: 0.6653507947921753
Validation loss: 2.181191861629486

Epoch: 6| Step: 2
Training loss: 0.3376917839050293
Validation loss: 2.1745969454447427

Epoch: 6| Step: 3
Training loss: 0.6293485164642334
Validation loss: 2.1733404199282327

Epoch: 6| Step: 4
Training loss: 0.8731981515884399
Validation loss: 2.125876228014628

Epoch: 6| Step: 5
Training loss: 0.590379536151886
Validation loss: 2.138801554838816

Epoch: 6| Step: 6
Training loss: 0.4122501015663147
Validation loss: 2.0769997239112854

Epoch: 6| Step: 7
Training loss: 0.4955304265022278
Validation loss: 2.1175007820129395

Epoch: 6| Step: 8
Training loss: 0.3456202745437622
Validation loss: 2.115655223528544

Epoch: 6| Step: 9
Training loss: 0.7002224326133728
Validation loss: 2.1418490012486777

Epoch: 6| Step: 10
Training loss: 0.7902607321739197
Validation loss: 2.161419451236725

Epoch: 6| Step: 11
Training loss: 0.4431181848049164
Validation loss: 2.1435877084732056

Epoch: 6| Step: 12
Training loss: 0.452034056186676
Validation loss: 2.1386765042940774

Epoch: 6| Step: 13
Training loss: 0.6529098749160767
Validation loss: 2.1317410469055176

Epoch: 309| Step: 0
Training loss: 0.7234876751899719
Validation loss: 2.1366520722707114

Epoch: 6| Step: 1
Training loss: 0.5815048217773438
Validation loss: 2.113981862862905

Epoch: 6| Step: 2
Training loss: 0.44804275035858154
Validation loss: 2.162457287311554

Epoch: 6| Step: 3
Training loss: 0.7892534732818604
Validation loss: 2.1352457205454507

Epoch: 6| Step: 4
Training loss: 0.8239050507545471
Validation loss: 2.1850779056549072

Epoch: 6| Step: 5
Training loss: 0.707836925983429
Validation loss: 2.1617923577626548

Epoch: 6| Step: 6
Training loss: 0.4380483031272888
Validation loss: 2.1197582483291626

Epoch: 6| Step: 7
Training loss: 0.4743540287017822
Validation loss: 2.149228016535441

Epoch: 6| Step: 8
Training loss: 0.2989032566547394
Validation loss: 2.1256154775619507

Epoch: 6| Step: 9
Training loss: 0.3729900121688843
Validation loss: 2.1534741719563804

Epoch: 6| Step: 10
Training loss: 0.47882914543151855
Validation loss: 2.15360426902771

Epoch: 6| Step: 11
Training loss: 0.2560654282569885
Validation loss: 2.1111952861150107

Epoch: 6| Step: 12
Training loss: 0.6731969118118286
Validation loss: 2.084327499071757

Epoch: 6| Step: 13
Training loss: 0.6868696212768555
Validation loss: 2.1482533613840737

Epoch: 310| Step: 0
Training loss: 0.38589271903038025
Validation loss: 2.1227638125419617

Epoch: 6| Step: 1
Training loss: 0.5603309273719788
Validation loss: 2.1220194896062217

Epoch: 6| Step: 2
Training loss: 0.7119302153587341
Validation loss: 2.1296642621358237

Epoch: 6| Step: 3
Training loss: 1.0020722150802612
Validation loss: 2.129938860734304

Epoch: 6| Step: 4
Training loss: 0.5746665000915527
Validation loss: 2.1359703739484153

Epoch: 6| Step: 5
Training loss: 0.39258110523223877
Validation loss: 2.149468104044596

Epoch: 6| Step: 6
Training loss: 0.7161641120910645
Validation loss: 2.139861007531484

Epoch: 6| Step: 7
Training loss: 0.5629878044128418
Validation loss: 2.1043779452641806

Epoch: 6| Step: 8
Training loss: 0.39879491925239563
Validation loss: 2.133185545603434

Epoch: 6| Step: 9
Training loss: 0.5797532200813293
Validation loss: 2.0937873323758445

Epoch: 6| Step: 10
Training loss: 0.40941905975341797
Validation loss: 2.118366003036499

Epoch: 6| Step: 11
Training loss: 0.47356659173965454
Validation loss: 2.1729662815729776

Epoch: 6| Step: 12
Training loss: 0.6495183110237122
Validation loss: 2.088455299536387

Epoch: 6| Step: 13
Training loss: 0.32549935579299927
Validation loss: 2.129389524459839

Epoch: 311| Step: 0
Training loss: 0.4599786102771759
Validation loss: 2.221802373727163

Epoch: 6| Step: 1
Training loss: 0.9034396409988403
Validation loss: 2.146602193514506

Epoch: 6| Step: 2
Training loss: 0.7108628749847412
Validation loss: 2.1878392696380615

Epoch: 6| Step: 3
Training loss: 0.5175991058349609
Validation loss: 2.1358162562052407

Epoch: 6| Step: 4
Training loss: 0.7509174942970276
Validation loss: 2.1185636123021445

Epoch: 6| Step: 5
Training loss: 0.7119930386543274
Validation loss: 2.152632792790731

Epoch: 6| Step: 6
Training loss: 0.4868978261947632
Validation loss: 2.14235520362854

Epoch: 6| Step: 7
Training loss: 0.6522440314292908
Validation loss: 2.1282801429430642

Epoch: 6| Step: 8
Training loss: 0.2825486361980438
Validation loss: 2.1026427348454795

Epoch: 6| Step: 9
Training loss: 0.5055821537971497
Validation loss: 2.095700760682424

Epoch: 6| Step: 10
Training loss: 0.5698498487472534
Validation loss: 2.089158594608307

Epoch: 6| Step: 11
Training loss: 0.7078574895858765
Validation loss: 2.1883766452471414

Epoch: 6| Step: 12
Training loss: 0.3285013735294342
Validation loss: 2.128149708112081

Epoch: 6| Step: 13
Training loss: 0.3995150923728943
Validation loss: 2.1835155487060547

Epoch: 312| Step: 0
Training loss: 0.42958247661590576
Validation loss: 2.2048628330230713

Epoch: 6| Step: 1
Training loss: 0.38034000992774963
Validation loss: 2.2286609411239624

Epoch: 6| Step: 2
Training loss: 0.41046398878097534
Validation loss: 2.1058149337768555

Epoch: 6| Step: 3
Training loss: 0.5611151456832886
Validation loss: 2.18794051806132

Epoch: 6| Step: 4
Training loss: 0.42477887868881226
Validation loss: 2.1620307763417563

Epoch: 6| Step: 5
Training loss: 1.5920164585113525
Validation loss: 2.1426363786061606

Epoch: 6| Step: 6
Training loss: 0.6085190773010254
Validation loss: 2.1443317929903665

Epoch: 6| Step: 7
Training loss: 0.35225212574005127
Validation loss: 2.0946160356203714

Epoch: 6| Step: 8
Training loss: 0.3480687737464905
Validation loss: 2.077225168546041

Epoch: 6| Step: 9
Training loss: 0.6366831064224243
Validation loss: 2.117376724878947

Epoch: 6| Step: 10
Training loss: 0.3844631314277649
Validation loss: 2.132478495438894

Epoch: 6| Step: 11
Training loss: 0.3079747259616852
Validation loss: 2.098557929197947

Epoch: 6| Step: 12
Training loss: 0.48950478434562683
Validation loss: 2.0993432998657227

Epoch: 6| Step: 13
Training loss: 0.7635860443115234
Validation loss: 2.1335030595461526

Epoch: 313| Step: 0
Training loss: 0.6877108812332153
Validation loss: 2.147663414478302

Epoch: 6| Step: 1
Training loss: 0.431628942489624
Validation loss: 2.1724722385406494

Epoch: 6| Step: 2
Training loss: 0.45699357986450195
Validation loss: 2.150711397329966

Epoch: 6| Step: 3
Training loss: 0.3758772015571594
Validation loss: 2.1403555472691855

Epoch: 6| Step: 4
Training loss: 0.4103623330593109
Validation loss: 2.149911085764567

Epoch: 6| Step: 5
Training loss: 0.35379573702812195
Validation loss: 2.126792867978414

Epoch: 6| Step: 6
Training loss: 0.5160983800888062
Validation loss: 2.0941038926442466

Epoch: 6| Step: 7
Training loss: 0.5170628428459167
Validation loss: 2.131012797355652

Epoch: 6| Step: 8
Training loss: 1.154547929763794
Validation loss: 2.104493737220764

Epoch: 6| Step: 9
Training loss: 0.6183182001113892
Validation loss: 2.1116833488146463

Epoch: 6| Step: 10
Training loss: 0.6207348108291626
Validation loss: 2.124071399370829

Epoch: 6| Step: 11
Training loss: 0.4965800642967224
Validation loss: 2.09306134780248

Epoch: 6| Step: 12
Training loss: 0.4793979525566101
Validation loss: 2.1214078863461814

Epoch: 6| Step: 13
Training loss: 0.5096969604492188
Validation loss: 2.1138956546783447

Epoch: 314| Step: 0
Training loss: 0.4600212872028351
Validation loss: 2.149639368057251

Epoch: 6| Step: 1
Training loss: 0.440947949886322
Validation loss: 2.1405875285466514

Epoch: 6| Step: 2
Training loss: 0.503288209438324
Validation loss: 2.14718896150589

Epoch: 6| Step: 3
Training loss: 0.5631940364837646
Validation loss: 2.121402621269226

Epoch: 6| Step: 4
Training loss: 0.7839773893356323
Validation loss: 2.1192935903867087

Epoch: 6| Step: 5
Training loss: 0.6533336639404297
Validation loss: 2.0912224451700845

Epoch: 6| Step: 6
Training loss: 0.43150460720062256
Validation loss: 2.1555367708206177

Epoch: 6| Step: 7
Training loss: 0.3597143292427063
Validation loss: 2.1563185453414917

Epoch: 6| Step: 8
Training loss: 0.281912237405777
Validation loss: 2.16956889629364

Epoch: 6| Step: 9
Training loss: 1.3286182880401611
Validation loss: 2.1205876072247825

Epoch: 6| Step: 10
Training loss: 0.2697443962097168
Validation loss: 2.118490000565847

Epoch: 6| Step: 11
Training loss: 0.5039207339286804
Validation loss: 2.0977320273717246

Epoch: 6| Step: 12
Training loss: 0.6515359878540039
Validation loss: 2.1243644754091897

Epoch: 6| Step: 13
Training loss: 0.2807537615299225
Validation loss: 2.095687727133433

Epoch: 315| Step: 0
Training loss: 0.7870107293128967
Validation loss: 2.083330670992533

Epoch: 6| Step: 1
Training loss: 0.27837124466896057
Validation loss: 2.0992053747177124

Epoch: 6| Step: 2
Training loss: 0.5669185519218445
Validation loss: 2.197034180164337

Epoch: 6| Step: 3
Training loss: 0.5864159464836121
Validation loss: 2.1223572889963784

Epoch: 6| Step: 4
Training loss: 0.8368769288063049
Validation loss: 2.1413313945134482

Epoch: 6| Step: 5
Training loss: 0.6588699817657471
Validation loss: 2.1251266598701477

Epoch: 6| Step: 6
Training loss: 0.20017743110656738
Validation loss: 2.1075617472330728

Epoch: 6| Step: 7
Training loss: 0.6871334314346313
Validation loss: 2.0912601351737976

Epoch: 6| Step: 8
Training loss: 0.7039359211921692
Validation loss: 2.1355190674463906

Epoch: 6| Step: 9
Training loss: 0.36119401454925537
Validation loss: 2.1566630601882935

Epoch: 6| Step: 10
Training loss: 0.299725204706192
Validation loss: 2.128548820813497

Epoch: 6| Step: 11
Training loss: 0.39572399854660034
Validation loss: 2.12992533047994

Epoch: 6| Step: 12
Training loss: 0.49172812700271606
Validation loss: 2.11749005317688

Epoch: 6| Step: 13
Training loss: 0.3971078395843506
Validation loss: 2.111509601275126

Epoch: 316| Step: 0
Training loss: 0.2296207994222641
Validation loss: 2.109147310256958

Epoch: 6| Step: 1
Training loss: 0.3763265311717987
Validation loss: 2.0993263125419617

Epoch: 6| Step: 2
Training loss: 0.36613160371780396
Validation loss: 2.140957156817118

Epoch: 6| Step: 3
Training loss: 0.6501191854476929
Validation loss: 2.150551517804464

Epoch: 6| Step: 4
Training loss: 0.5224757194519043
Validation loss: 2.115659991900126

Epoch: 6| Step: 5
Training loss: 0.6137392520904541
Validation loss: 2.1123128533363342

Epoch: 6| Step: 6
Training loss: 0.6945598125457764
Validation loss: 2.080789029598236

Epoch: 6| Step: 7
Training loss: 0.5465896129608154
Validation loss: 2.124695817629496

Epoch: 6| Step: 8
Training loss: 0.5182023644447327
Validation loss: 2.1088579098383584

Epoch: 6| Step: 9
Training loss: 0.5632387399673462
Validation loss: 2.1224066019058228

Epoch: 6| Step: 10
Training loss: 1.0020146369934082
Validation loss: 2.149086574713389

Epoch: 6| Step: 11
Training loss: 0.22573739290237427
Validation loss: 2.130435605843862

Epoch: 6| Step: 12
Training loss: 0.6091548800468445
Validation loss: 2.1628581086794534

Epoch: 6| Step: 13
Training loss: 0.20219793915748596
Validation loss: 2.055612583955129

Epoch: 317| Step: 0
Training loss: 0.5467399954795837
Validation loss: 2.1128170092900596

Epoch: 6| Step: 1
Training loss: 0.6277227401733398
Validation loss: 2.1310118436813354

Epoch: 6| Step: 2
Training loss: 0.682318925857544
Validation loss: 2.1024620135625205

Epoch: 6| Step: 3
Training loss: 0.9129234552383423
Validation loss: 2.094585339228312

Epoch: 6| Step: 4
Training loss: 0.3856338858604431
Validation loss: 2.124079783757528

Epoch: 6| Step: 5
Training loss: 0.5697939991950989
Validation loss: 2.1258676052093506

Epoch: 6| Step: 6
Training loss: 0.4977501332759857
Validation loss: 2.138367454210917

Epoch: 6| Step: 7
Training loss: 0.7731810808181763
Validation loss: 2.0918345848719277

Epoch: 6| Step: 8
Training loss: 0.5116156339645386
Validation loss: 2.1148810187975564

Epoch: 6| Step: 9
Training loss: 0.38636401295661926
Validation loss: 2.1052923599878945

Epoch: 6| Step: 10
Training loss: 0.33303385972976685
Validation loss: 2.172965705394745

Epoch: 6| Step: 11
Training loss: 0.44197994470596313
Validation loss: 2.1522618929545083

Epoch: 6| Step: 12
Training loss: 0.2926809787750244
Validation loss: 2.1028835574785867

Epoch: 6| Step: 13
Training loss: 0.1874910593032837
Validation loss: 2.1448514064153037

Epoch: 318| Step: 0
Training loss: 0.28374308347702026
Validation loss: 2.124764382839203

Epoch: 6| Step: 1
Training loss: 0.9224725961685181
Validation loss: 2.1269874374071756

Epoch: 6| Step: 2
Training loss: 0.3951933979988098
Validation loss: 2.1732452511787415

Epoch: 6| Step: 3
Training loss: 0.31721532344818115
Validation loss: 2.111836036046346

Epoch: 6| Step: 4
Training loss: 0.38329964876174927
Validation loss: 2.140764315923055

Epoch: 6| Step: 5
Training loss: 0.5304792523384094
Validation loss: 2.099327027797699

Epoch: 6| Step: 6
Training loss: 0.37881964445114136
Validation loss: 2.1127274433771768

Epoch: 6| Step: 7
Training loss: 0.9577584266662598
Validation loss: 2.084025502204895

Epoch: 6| Step: 8
Training loss: 0.34550613164901733
Validation loss: 2.2007404963175454

Epoch: 6| Step: 9
Training loss: 0.43708229064941406
Validation loss: 2.178434153397878

Epoch: 6| Step: 10
Training loss: 0.7780159711837769
Validation loss: 2.1718446214993796

Epoch: 6| Step: 11
Training loss: 0.5477744340896606
Validation loss: 2.1316760977109275

Epoch: 6| Step: 12
Training loss: 0.6076258420944214
Validation loss: 2.117187817891439

Epoch: 6| Step: 13
Training loss: 0.47156086564064026
Validation loss: 2.1289324164390564

Epoch: 319| Step: 0
Training loss: 0.5609495639801025
Validation loss: 2.151265482107798

Epoch: 6| Step: 1
Training loss: 0.20285695791244507
Validation loss: 2.079869031906128

Epoch: 6| Step: 2
Training loss: 1.1087067127227783
Validation loss: 2.1387272477149963

Epoch: 6| Step: 3
Training loss: 0.4934491515159607
Validation loss: 2.136918624242147

Epoch: 6| Step: 4
Training loss: 0.40785542130470276
Validation loss: 2.1587975025177

Epoch: 6| Step: 5
Training loss: 0.504406213760376
Validation loss: 2.1805450518925986

Epoch: 6| Step: 6
Training loss: 0.4065561890602112
Validation loss: 2.098943571249644

Epoch: 6| Step: 7
Training loss: 0.3225865960121155
Validation loss: 2.1229884028434753

Epoch: 6| Step: 8
Training loss: 0.34049713611602783
Validation loss: 2.132736066977183

Epoch: 6| Step: 9
Training loss: 0.7113972306251526
Validation loss: 2.141649067401886

Epoch: 6| Step: 10
Training loss: 0.42968225479125977
Validation loss: 2.152209758758545

Epoch: 6| Step: 11
Training loss: 0.39165395498275757
Validation loss: 2.1201025446256003

Epoch: 6| Step: 12
Training loss: 0.6046977043151855
Validation loss: 2.1253045002619424

Epoch: 6| Step: 13
Training loss: 0.6044430136680603
Validation loss: 2.1814293265342712

Epoch: 320| Step: 0
Training loss: 0.5301761031150818
Validation loss: 2.166299899419149

Epoch: 6| Step: 1
Training loss: 0.42436155676841736
Validation loss: 2.1416486899058023

Epoch: 6| Step: 2
Training loss: 0.9194060564041138
Validation loss: 2.1674455205599465

Epoch: 6| Step: 3
Training loss: 0.4014783501625061
Validation loss: 2.122465988000234

Epoch: 6| Step: 4
Training loss: 0.36776015162467957
Validation loss: 2.124023993810018

Epoch: 6| Step: 5
Training loss: 1.0450671911239624
Validation loss: 2.1672704219818115

Epoch: 6| Step: 6
Training loss: 0.4036351442337036
Validation loss: 2.1750308672587075

Epoch: 6| Step: 7
Training loss: 0.5465359687805176
Validation loss: 2.160667916138967

Epoch: 6| Step: 8
Training loss: 0.2341909110546112
Validation loss: 2.194766958554586

Epoch: 6| Step: 9
Training loss: 0.5639593005180359
Validation loss: 2.174132784207662

Epoch: 6| Step: 10
Training loss: 0.4560707211494446
Validation loss: 2.105123599370321

Epoch: 6| Step: 11
Training loss: 0.43538159132003784
Validation loss: 2.196901321411133

Epoch: 6| Step: 12
Training loss: 0.3029121160507202
Validation loss: 2.1152385075887046

Epoch: 6| Step: 13
Training loss: 0.7691770195960999
Validation loss: 2.1463724772135415

Epoch: 321| Step: 0
Training loss: 0.4087720513343811
Validation loss: 2.1720974246660867

Epoch: 6| Step: 1
Training loss: 0.4114331603050232
Validation loss: 2.1566102703412375

Epoch: 6| Step: 2
Training loss: 0.6712124347686768
Validation loss: 2.1163535515467324

Epoch: 6| Step: 3
Training loss: 0.5979477763175964
Validation loss: 2.1563046177228293

Epoch: 6| Step: 4
Training loss: 0.5329880118370056
Validation loss: 2.1461915572484336

Epoch: 6| Step: 5
Training loss: 0.57086181640625
Validation loss: 2.1356958945592246

Epoch: 6| Step: 6
Training loss: 0.43904563784599304
Validation loss: 2.152837038040161

Epoch: 6| Step: 7
Training loss: 0.3604590892791748
Validation loss: 2.122719943523407

Epoch: 6| Step: 8
Training loss: 0.3196425139904022
Validation loss: 2.1116946736971536

Epoch: 6| Step: 9
Training loss: 0.4332003593444824
Validation loss: 2.137518843015035

Epoch: 6| Step: 10
Training loss: 0.425658643245697
Validation loss: 2.1376529733339944

Epoch: 6| Step: 11
Training loss: 1.0748481750488281
Validation loss: 2.1478924552599588

Epoch: 6| Step: 12
Training loss: 0.24408036470413208
Validation loss: 2.150144954522451

Epoch: 6| Step: 13
Training loss: 0.6003189086914062
Validation loss: 2.1798202991485596

Epoch: 322| Step: 0
Training loss: 0.8985027074813843
Validation loss: 2.142331580320994

Epoch: 6| Step: 1
Training loss: 0.2899695038795471
Validation loss: 2.1737778584162393

Epoch: 6| Step: 2
Training loss: 0.6328492164611816
Validation loss: 2.1416605710983276

Epoch: 6| Step: 3
Training loss: 0.6854482889175415
Validation loss: 2.202896853288015

Epoch: 6| Step: 4
Training loss: 0.5712298154830933
Validation loss: 2.160058379173279

Epoch: 6| Step: 5
Training loss: 0.3067103624343872
Validation loss: 2.156591792901357

Epoch: 6| Step: 6
Training loss: 0.3032129406929016
Validation loss: 2.1077439983685813

Epoch: 6| Step: 7
Training loss: 0.6050241589546204
Validation loss: 2.142695724964142

Epoch: 6| Step: 8
Training loss: 0.7426167130470276
Validation loss: 2.132923126220703

Epoch: 6| Step: 9
Training loss: 0.9135910272598267
Validation loss: 2.0903382897377014

Epoch: 6| Step: 10
Training loss: 0.35034340620040894
Validation loss: 2.042658189932505

Epoch: 6| Step: 11
Training loss: 0.6003153324127197
Validation loss: 2.1474430561065674

Epoch: 6| Step: 12
Training loss: 0.41414669156074524
Validation loss: 2.12995437781016

Epoch: 6| Step: 13
Training loss: 0.28845810890197754
Validation loss: 2.195918838183085

Epoch: 323| Step: 0
Training loss: 0.4959006905555725
Validation loss: 2.1384530067443848

Epoch: 6| Step: 1
Training loss: 0.6061149835586548
Validation loss: 2.158193588256836

Epoch: 6| Step: 2
Training loss: 0.8552271723747253
Validation loss: 2.140530745188395

Epoch: 6| Step: 3
Training loss: 0.5581601858139038
Validation loss: 2.1084060271581015

Epoch: 6| Step: 4
Training loss: 0.41128942370414734
Validation loss: 2.1454429229100547

Epoch: 6| Step: 5
Training loss: 0.5414242148399353
Validation loss: 2.0987760424613953

Epoch: 6| Step: 6
Training loss: 0.35792243480682373
Validation loss: 2.137334326903025

Epoch: 6| Step: 7
Training loss: 0.8822789192199707
Validation loss: 2.1193424264589944

Epoch: 6| Step: 8
Training loss: 0.5369999408721924
Validation loss: 2.1702693104743958

Epoch: 6| Step: 9
Training loss: 0.3052269518375397
Validation loss: 2.171275317668915

Epoch: 6| Step: 10
Training loss: 0.5029193758964539
Validation loss: 2.165730834007263

Epoch: 6| Step: 11
Training loss: 0.568587064743042
Validation loss: 2.098418335119883

Epoch: 6| Step: 12
Training loss: 0.502234935760498
Validation loss: 2.134169081846873

Epoch: 6| Step: 13
Training loss: 0.6175521612167358
Validation loss: 2.1630302468935647

Epoch: 324| Step: 0
Training loss: 0.8519556522369385
Validation loss: 2.208019256591797

Epoch: 6| Step: 1
Training loss: 0.5135859847068787
Validation loss: 2.182264427344004

Epoch: 6| Step: 2
Training loss: 0.5498876571655273
Validation loss: 2.1777263879776

Epoch: 6| Step: 3
Training loss: 0.848800003528595
Validation loss: 2.141051451365153

Epoch: 6| Step: 4
Training loss: 0.2264309823513031
Validation loss: 2.1612411538759866

Epoch: 6| Step: 5
Training loss: 0.8201149702072144
Validation loss: 2.1781184673309326

Epoch: 6| Step: 6
Training loss: 0.5639246702194214
Validation loss: 2.160954316457113

Epoch: 6| Step: 7
Training loss: 0.3565365672111511
Validation loss: 2.187714417775472

Epoch: 6| Step: 8
Training loss: 0.24236606061458588
Validation loss: 2.045383354028066

Epoch: 6| Step: 9
Training loss: 0.5954143404960632
Validation loss: 2.1606971422831216

Epoch: 6| Step: 10
Training loss: 0.4579210877418518
Validation loss: 2.1131834189097085

Epoch: 6| Step: 11
Training loss: 0.49857640266418457
Validation loss: 2.1267408529917398

Epoch: 6| Step: 12
Training loss: 0.4838416874408722
Validation loss: 2.1460380951563516

Epoch: 6| Step: 13
Training loss: 0.3912261724472046
Validation loss: 2.1084614197413125

Epoch: 325| Step: 0
Training loss: 0.5048407316207886
Validation loss: 2.1210342844327292

Epoch: 6| Step: 1
Training loss: 0.7193899154663086
Validation loss: 2.113731066385905

Epoch: 6| Step: 2
Training loss: 0.45950448513031006
Validation loss: 2.0669143199920654

Epoch: 6| Step: 3
Training loss: 0.5308305621147156
Validation loss: 2.1521129806836448

Epoch: 6| Step: 4
Training loss: 0.7320072054862976
Validation loss: 2.13624240954717

Epoch: 6| Step: 5
Training loss: 0.6120254993438721
Validation loss: 2.0834636290868125

Epoch: 6| Step: 6
Training loss: 0.8484359383583069
Validation loss: 2.1281500458717346

Epoch: 6| Step: 7
Training loss: 0.5325676798820496
Validation loss: 2.1236215829849243

Epoch: 6| Step: 8
Training loss: 0.44525256752967834
Validation loss: 2.1267348329226174

Epoch: 6| Step: 9
Training loss: 0.24846994876861572
Validation loss: 2.172674814860026

Epoch: 6| Step: 10
Training loss: 0.2708039879798889
Validation loss: 2.1260143717130027

Epoch: 6| Step: 11
Training loss: 0.5716971158981323
Validation loss: 2.109938124815623

Epoch: 6| Step: 12
Training loss: 0.293534517288208
Validation loss: 2.071315268675486

Epoch: 6| Step: 13
Training loss: 0.48454731702804565
Validation loss: 2.1105764706929526

Epoch: 326| Step: 0
Training loss: 0.35578829050064087
Validation loss: 2.1352583964665732

Epoch: 6| Step: 1
Training loss: 0.3918910026550293
Validation loss: 2.1578137079874673

Epoch: 6| Step: 2
Training loss: 0.5967388153076172
Validation loss: 2.0907649795214334

Epoch: 6| Step: 3
Training loss: 0.6819654107093811
Validation loss: 2.168682257334391

Epoch: 6| Step: 4
Training loss: 0.5711665153503418
Validation loss: 2.0792993704477944

Epoch: 6| Step: 5
Training loss: 0.5453086495399475
Validation loss: 2.1406322518984475

Epoch: 6| Step: 6
Training loss: 0.3858237862586975
Validation loss: 2.1548476417859397

Epoch: 6| Step: 7
Training loss: 1.036303997039795
Validation loss: 2.147975822289785

Epoch: 6| Step: 8
Training loss: 0.6650060415267944
Validation loss: 2.140979588031769

Epoch: 6| Step: 9
Training loss: 0.4766698181629181
Validation loss: 2.1036526759465537

Epoch: 6| Step: 10
Training loss: 0.35380589962005615
Validation loss: 2.058066666126251

Epoch: 6| Step: 11
Training loss: 0.5114133358001709
Validation loss: 2.088432947794596

Epoch: 6| Step: 12
Training loss: 0.4533398747444153
Validation loss: 2.1333866516749063

Epoch: 6| Step: 13
Training loss: 0.4674786925315857
Validation loss: 2.1208184957504272

Epoch: 327| Step: 0
Training loss: 0.6051741242408752
Validation loss: 2.143183430035909

Epoch: 6| Step: 1
Training loss: 0.39262157678604126
Validation loss: 2.204637030760447

Epoch: 6| Step: 2
Training loss: 0.3495452404022217
Validation loss: 2.163016597429911

Epoch: 6| Step: 3
Training loss: 0.5054372549057007
Validation loss: 2.1672325929005942

Epoch: 6| Step: 4
Training loss: 0.5361794233322144
Validation loss: 2.134423832098643

Epoch: 6| Step: 5
Training loss: 0.9218975305557251
Validation loss: 2.1535593072573342

Epoch: 6| Step: 6
Training loss: 0.683080792427063
Validation loss: 2.0369794766108194

Epoch: 6| Step: 7
Training loss: 0.49283528327941895
Validation loss: 2.1025354862213135

Epoch: 6| Step: 8
Training loss: 0.7400752305984497
Validation loss: 2.084329128265381

Epoch: 6| Step: 9
Training loss: 0.6548471450805664
Validation loss: 2.1084834734598794

Epoch: 6| Step: 10
Training loss: 0.3500935435295105
Validation loss: 2.1402958830197654

Epoch: 6| Step: 11
Training loss: 0.7217720746994019
Validation loss: 2.0899242758750916

Epoch: 6| Step: 12
Training loss: 0.5257418155670166
Validation loss: 2.1411835749944053

Epoch: 6| Step: 13
Training loss: 0.4498351514339447
Validation loss: 2.162786861260732

Epoch: 328| Step: 0
Training loss: 0.4738912582397461
Validation loss: 2.1436541080474854

Epoch: 6| Step: 1
Training loss: 0.3019477128982544
Validation loss: 2.2074769735336304

Epoch: 6| Step: 2
Training loss: 1.1542936563491821
Validation loss: 2.106244603792826

Epoch: 6| Step: 3
Training loss: 0.5861130952835083
Validation loss: 2.094184140364329

Epoch: 6| Step: 4
Training loss: 0.4953591823577881
Validation loss: 2.124722401301066

Epoch: 6| Step: 5
Training loss: 0.3803415894508362
Validation loss: 2.1073638995488486

Epoch: 6| Step: 6
Training loss: 0.6105508208274841
Validation loss: 2.0806014140446982

Epoch: 6| Step: 7
Training loss: 0.42599987983703613
Validation loss: 2.123879313468933

Epoch: 6| Step: 8
Training loss: 0.5612396597862244
Validation loss: 2.0622183084487915

Epoch: 6| Step: 9
Training loss: 0.16814112663269043
Validation loss: 2.074627677599589

Epoch: 6| Step: 10
Training loss: 0.3125467896461487
Validation loss: 2.10882035891215

Epoch: 6| Step: 11
Training loss: 0.5443074703216553
Validation loss: 2.1077018777529397

Epoch: 6| Step: 12
Training loss: 0.759238600730896
Validation loss: 2.138979117075602

Epoch: 6| Step: 13
Training loss: 0.622738778591156
Validation loss: 2.108450452486674

Epoch: 329| Step: 0
Training loss: 0.5770758390426636
Validation loss: 2.1752375960350037

Epoch: 6| Step: 1
Training loss: 0.6572837233543396
Validation loss: 2.124539097150167

Epoch: 6| Step: 2
Training loss: 0.458526074886322
Validation loss: 2.155773858229319

Epoch: 6| Step: 3
Training loss: 0.8688409924507141
Validation loss: 2.155443330605825

Epoch: 6| Step: 4
Training loss: 0.5184692740440369
Validation loss: 2.0933913787206015

Epoch: 6| Step: 5
Training loss: 0.5207158327102661
Validation loss: 2.1689797043800354

Epoch: 6| Step: 6
Training loss: 0.6134561896324158
Validation loss: 2.0750268697738647

Epoch: 6| Step: 7
Training loss: 0.351895272731781
Validation loss: 2.0992050766944885

Epoch: 6| Step: 8
Training loss: 0.4202686548233032
Validation loss: 2.098793705304464

Epoch: 6| Step: 9
Training loss: 0.47230592370033264
Validation loss: 2.0935824712117515

Epoch: 6| Step: 10
Training loss: 0.5819279551506042
Validation loss: 2.141987164815267

Epoch: 6| Step: 11
Training loss: 0.2610551118850708
Validation loss: 2.104714592297872

Epoch: 6| Step: 12
Training loss: 0.30057239532470703
Validation loss: 2.104757090409597

Epoch: 6| Step: 13
Training loss: 0.278689444065094
Validation loss: 2.085438887278239

Epoch: 330| Step: 0
Training loss: 0.4808814525604248
Validation loss: 2.1545984745025635

Epoch: 6| Step: 1
Training loss: 0.2887534499168396
Validation loss: 2.1110103726387024

Epoch: 6| Step: 2
Training loss: 0.2611025869846344
Validation loss: 2.092755456765493

Epoch: 6| Step: 3
Training loss: 0.4205988645553589
Validation loss: 2.1352226734161377

Epoch: 6| Step: 4
Training loss: 0.990638256072998
Validation loss: 2.084549387296041

Epoch: 6| Step: 5
Training loss: 1.0059359073638916
Validation loss: 2.0947961807250977

Epoch: 6| Step: 6
Training loss: 0.6893897652626038
Validation loss: 2.07303794225057

Epoch: 6| Step: 7
Training loss: 0.5485421419143677
Validation loss: 2.1320731043815613

Epoch: 6| Step: 8
Training loss: 0.6251992583274841
Validation loss: 2.0884548823038735

Epoch: 6| Step: 9
Training loss: 0.3405522108078003
Validation loss: 2.0870185693105063

Epoch: 6| Step: 10
Training loss: 0.3909553289413452
Validation loss: 2.075594882170359

Epoch: 6| Step: 11
Training loss: 0.6442250609397888
Validation loss: 2.1074018279711404

Epoch: 6| Step: 12
Training loss: 0.23126733303070068
Validation loss: 2.118141233921051

Epoch: 6| Step: 13
Training loss: 0.2608228027820587
Validation loss: 2.1054380734761557

Epoch: 331| Step: 0
Training loss: 0.3035702109336853
Validation loss: 2.128228743871053

Epoch: 6| Step: 1
Training loss: 0.515147864818573
Validation loss: 2.15693861246109

Epoch: 6| Step: 2
Training loss: 0.44434791803359985
Validation loss: 2.134861727555593

Epoch: 6| Step: 3
Training loss: 0.4313414990901947
Validation loss: 2.155810058116913

Epoch: 6| Step: 4
Training loss: 0.2510946989059448
Validation loss: 2.082049250602722

Epoch: 6| Step: 5
Training loss: 0.6699070930480957
Validation loss: 2.1729929645856223

Epoch: 6| Step: 6
Training loss: 0.32877224683761597
Validation loss: 2.090355614821116

Epoch: 6| Step: 7
Training loss: 0.8330039978027344
Validation loss: 2.209167242050171

Epoch: 6| Step: 8
Training loss: 0.6420400738716125
Validation loss: 2.1515443325042725

Epoch: 6| Step: 9
Training loss: 0.7015674114227295
Validation loss: 2.1167195439338684

Epoch: 6| Step: 10
Training loss: 0.5745805501937866
Validation loss: 2.113537351290385

Epoch: 6| Step: 11
Training loss: 0.49258995056152344
Validation loss: 2.1764910022417703

Epoch: 6| Step: 12
Training loss: 0.6318563222885132
Validation loss: 2.1372103492418923

Epoch: 6| Step: 13
Training loss: 0.44876012206077576
Validation loss: 2.1008898615837097

Epoch: 332| Step: 0
Training loss: 0.2520068883895874
Validation loss: 2.1530214746793113

Epoch: 6| Step: 1
Training loss: 0.43913787603378296
Validation loss: 2.108243147532145

Epoch: 6| Step: 2
Training loss: 0.26735013723373413
Validation loss: 2.147488753000895

Epoch: 6| Step: 3
Training loss: 0.4824957251548767
Validation loss: 2.132323443889618

Epoch: 6| Step: 4
Training loss: 0.38411861658096313
Validation loss: 2.196792483329773

Epoch: 6| Step: 5
Training loss: 1.0844228267669678
Validation loss: 2.1394240260124207

Epoch: 6| Step: 6
Training loss: 0.6726841926574707
Validation loss: 2.1901232600212097

Epoch: 6| Step: 7
Training loss: 0.36418402194976807
Validation loss: 2.173740824063619

Epoch: 6| Step: 8
Training loss: 0.5972998142242432
Validation loss: 2.152791917324066

Epoch: 6| Step: 9
Training loss: 0.38646167516708374
Validation loss: 2.198046545187632

Epoch: 6| Step: 10
Training loss: 0.8406736850738525
Validation loss: 2.1871965527534485

Epoch: 6| Step: 11
Training loss: 0.5222607254981995
Validation loss: 2.1424855391184487

Epoch: 6| Step: 12
Training loss: 0.22965607047080994
Validation loss: 2.1195122400919595

Epoch: 6| Step: 13
Training loss: 0.5610330104827881
Validation loss: 2.1000680923461914

Epoch: 333| Step: 0
Training loss: 0.3144204318523407
Validation loss: 2.1395487984021506

Epoch: 6| Step: 1
Training loss: 0.5259876251220703
Validation loss: 2.1241451700528464

Epoch: 6| Step: 2
Training loss: 0.25524741411209106
Validation loss: 2.1461856961250305

Epoch: 6| Step: 3
Training loss: 0.6492345333099365
Validation loss: 2.0966081619262695

Epoch: 6| Step: 4
Training loss: 0.648594856262207
Validation loss: 2.096952438354492

Epoch: 6| Step: 5
Training loss: 0.6919218301773071
Validation loss: 2.179960608482361

Epoch: 6| Step: 6
Training loss: 0.28735992312431335
Validation loss: 2.1508376200993857

Epoch: 6| Step: 7
Training loss: 0.3641701340675354
Validation loss: 2.1231138507525125

Epoch: 6| Step: 8
Training loss: 1.0567829608917236
Validation loss: 2.115383803844452

Epoch: 6| Step: 9
Training loss: 0.6004114151000977
Validation loss: 2.17627360423406

Epoch: 6| Step: 10
Training loss: 0.1808234304189682
Validation loss: 2.10609632730484

Epoch: 6| Step: 11
Training loss: 0.2563707232475281
Validation loss: 2.140964468320211

Epoch: 6| Step: 12
Training loss: 0.36026644706726074
Validation loss: 2.129968285560608

Epoch: 6| Step: 13
Training loss: 0.6147758960723877
Validation loss: 2.130217949549357

Epoch: 334| Step: 0
Training loss: 0.1897987425327301
Validation loss: 2.163053254286448

Epoch: 6| Step: 1
Training loss: 0.3430752754211426
Validation loss: 2.188639481862386

Epoch: 6| Step: 2
Training loss: 0.3941984474658966
Validation loss: 2.132265826066335

Epoch: 6| Step: 3
Training loss: 0.4364725351333618
Validation loss: 2.1921850442886353

Epoch: 6| Step: 4
Training loss: 0.9342883229255676
Validation loss: 2.1484398444493613

Epoch: 6| Step: 5
Training loss: 0.2391529232263565
Validation loss: 2.1180520057678223

Epoch: 6| Step: 6
Training loss: 0.6668267250061035
Validation loss: 2.100596805413564

Epoch: 6| Step: 7
Training loss: 0.28898435831069946
Validation loss: 2.0986833373705545

Epoch: 6| Step: 8
Training loss: 0.3950519561767578
Validation loss: 2.1340210835138955

Epoch: 6| Step: 9
Training loss: 0.47008374333381653
Validation loss: 2.1588591933250427

Epoch: 6| Step: 10
Training loss: 0.9444800615310669
Validation loss: 2.1484076579411826

Epoch: 6| Step: 11
Training loss: 0.7067577838897705
Validation loss: 2.153255502382914

Epoch: 6| Step: 12
Training loss: 0.6585273742675781
Validation loss: 2.127777894337972

Epoch: 6| Step: 13
Training loss: 0.5609100461006165
Validation loss: 2.1706043084462485

Epoch: 335| Step: 0
Training loss: 0.7111935615539551
Validation loss: 2.1393931905428567

Epoch: 6| Step: 1
Training loss: 0.3329582214355469
Validation loss: 2.1372973124186196

Epoch: 6| Step: 2
Training loss: 0.7077003121376038
Validation loss: 2.034593860308329

Epoch: 6| Step: 3
Training loss: 0.3310497999191284
Validation loss: 2.1185169418652854

Epoch: 6| Step: 4
Training loss: 0.2851172089576721
Validation loss: 2.0937694708506265

Epoch: 6| Step: 5
Training loss: 0.5590094923973083
Validation loss: 2.091127355893453

Epoch: 6| Step: 6
Training loss: 0.7716839909553528
Validation loss: 2.167168060938517

Epoch: 6| Step: 7
Training loss: 0.29369401931762695
Validation loss: 2.089310258626938

Epoch: 6| Step: 8
Training loss: 0.497200608253479
Validation loss: 2.1194759607315063

Epoch: 6| Step: 9
Training loss: 0.7559157609939575
Validation loss: 2.1452809770902

Epoch: 6| Step: 10
Training loss: 0.2942304015159607
Validation loss: 2.1296215653419495

Epoch: 6| Step: 11
Training loss: 0.2557004690170288
Validation loss: 2.1586097478866577

Epoch: 6| Step: 12
Training loss: 0.7092043161392212
Validation loss: 2.1333956122398376

Epoch: 6| Step: 13
Training loss: 0.5983269810676575
Validation loss: 2.1636047760645547

Epoch: 336| Step: 0
Training loss: 0.30825838446617126
Validation loss: 2.1187197963396707

Epoch: 6| Step: 1
Training loss: 0.6442751884460449
Validation loss: 2.06961190700531

Epoch: 6| Step: 2
Training loss: 0.6871969699859619
Validation loss: 2.0994021693865457

Epoch: 6| Step: 3
Training loss: 0.5489642024040222
Validation loss: 2.161353588104248

Epoch: 6| Step: 4
Training loss: 0.3060011863708496
Validation loss: 2.1408133506774902

Epoch: 6| Step: 5
Training loss: 0.4339669346809387
Validation loss: 2.1387165983517966

Epoch: 6| Step: 6
Training loss: 0.24084128439426422
Validation loss: 2.1754382650057473

Epoch: 6| Step: 7
Training loss: 0.5106526017189026
Validation loss: 2.1685936649640403

Epoch: 6| Step: 8
Training loss: 1.3421151638031006
Validation loss: 2.1494361956914267

Epoch: 6| Step: 9
Training loss: 0.5089479684829712
Validation loss: 2.1427047650019326

Epoch: 6| Step: 10
Training loss: 0.3079589009284973
Validation loss: 2.1544609467188516

Epoch: 6| Step: 11
Training loss: 0.4662782549858093
Validation loss: 2.153273046016693

Epoch: 6| Step: 12
Training loss: 0.29732799530029297
Validation loss: 2.1063660780588784

Epoch: 6| Step: 13
Training loss: 0.5437390208244324
Validation loss: 2.1396583914756775

Epoch: 337| Step: 0
Training loss: 0.29189303517341614
Validation loss: 2.126331011454264

Epoch: 6| Step: 1
Training loss: 0.371489554643631
Validation loss: 2.160033563772837

Epoch: 6| Step: 2
Training loss: 0.5987685918807983
Validation loss: 2.1313369472821555

Epoch: 6| Step: 3
Training loss: 1.007236123085022
Validation loss: 2.129123946030935

Epoch: 6| Step: 4
Training loss: 0.3420138955116272
Validation loss: 2.1158835887908936

Epoch: 6| Step: 5
Training loss: 0.5969159603118896
Validation loss: 2.1392446756362915

Epoch: 6| Step: 6
Training loss: 0.2859950065612793
Validation loss: 2.1237322092056274

Epoch: 6| Step: 7
Training loss: 0.4191034436225891
Validation loss: 2.114155570665995

Epoch: 6| Step: 8
Training loss: 0.3347150683403015
Validation loss: 2.131843388080597

Epoch: 6| Step: 9
Training loss: 0.7597754001617432
Validation loss: 2.129030247529348

Epoch: 6| Step: 10
Training loss: 0.3440786600112915
Validation loss: 2.1225430170694985

Epoch: 6| Step: 11
Training loss: 0.609699010848999
Validation loss: 2.120946725209554

Epoch: 6| Step: 12
Training loss: 0.45153307914733887
Validation loss: 2.1390119592348733

Epoch: 6| Step: 13
Training loss: 0.39252135157585144
Validation loss: 2.13894389073054

Epoch: 338| Step: 0
Training loss: 0.2636973261833191
Validation loss: 2.176163613796234

Epoch: 6| Step: 1
Training loss: 0.4438585340976715
Validation loss: 2.118878165880839

Epoch: 6| Step: 2
Training loss: 0.5548811554908752
Validation loss: 2.1378161112467446

Epoch: 6| Step: 3
Training loss: 0.4193659722805023
Validation loss: 2.1400479078292847

Epoch: 6| Step: 4
Training loss: 0.22422967851161957
Validation loss: 2.103569825490316

Epoch: 6| Step: 5
Training loss: 0.4528542757034302
Validation loss: 2.120298425356547

Epoch: 6| Step: 6
Training loss: 0.5175927877426147
Validation loss: 2.125380198160807

Epoch: 6| Step: 7
Training loss: 0.43236464262008667
Validation loss: 2.0902438163757324

Epoch: 6| Step: 8
Training loss: 0.5258277654647827
Validation loss: 2.1080804467201233

Epoch: 6| Step: 9
Training loss: 0.9170213341712952
Validation loss: 2.1386506954828897

Epoch: 6| Step: 10
Training loss: 0.6205046772956848
Validation loss: 2.127020239830017

Epoch: 6| Step: 11
Training loss: 0.2573357820510864
Validation loss: 2.0963284770647683

Epoch: 6| Step: 12
Training loss: 0.6545541882514954
Validation loss: 2.1211905280749

Epoch: 6| Step: 13
Training loss: 0.46365034580230713
Validation loss: 2.1009846329689026

Epoch: 339| Step: 0
Training loss: 0.44294992089271545
Validation loss: 2.115378121534983

Epoch: 6| Step: 1
Training loss: 0.47772467136383057
Validation loss: 2.1086870431900024

Epoch: 6| Step: 2
Training loss: 0.2458089292049408
Validation loss: 2.0964511036872864

Epoch: 6| Step: 3
Training loss: 0.49153798818588257
Validation loss: 2.1383766730626426

Epoch: 6| Step: 4
Training loss: 0.8244491219520569
Validation loss: 2.094050566355387

Epoch: 6| Step: 5
Training loss: 0.41550880670547485
Validation loss: 2.128296156724294

Epoch: 6| Step: 6
Training loss: 0.27649080753326416
Validation loss: 2.1386999090512595

Epoch: 6| Step: 7
Training loss: 0.7330654859542847
Validation loss: 2.156617601712545

Epoch: 6| Step: 8
Training loss: 0.6287145614624023
Validation loss: 2.1628117760022483

Epoch: 6| Step: 9
Training loss: 0.373639851808548
Validation loss: 2.1553117831548056

Epoch: 6| Step: 10
Training loss: 0.6019752025604248
Validation loss: 2.155437727769216

Epoch: 6| Step: 11
Training loss: 0.738408088684082
Validation loss: 2.2179914315541587

Epoch: 6| Step: 12
Training loss: 0.6993961930274963
Validation loss: 2.1133074363072715

Epoch: 6| Step: 13
Training loss: 0.4333387017250061
Validation loss: 2.1236943205197654

Epoch: 340| Step: 0
Training loss: 0.26887577772140503
Validation loss: 2.121510903040568

Epoch: 6| Step: 1
Training loss: 0.3692607879638672
Validation loss: 2.082348883152008

Epoch: 6| Step: 2
Training loss: 0.43842756748199463
Validation loss: 2.126825491587321

Epoch: 6| Step: 3
Training loss: 0.20843976736068726
Validation loss: 2.133623500665029

Epoch: 6| Step: 4
Training loss: 0.33765295147895813
Validation loss: 2.1317968169848123

Epoch: 6| Step: 5
Training loss: 0.3940120339393616
Validation loss: 2.1159939765930176

Epoch: 6| Step: 6
Training loss: 0.8881940841674805
Validation loss: 2.141386389732361

Epoch: 6| Step: 7
Training loss: 0.7606917023658752
Validation loss: 2.1523876388867698

Epoch: 6| Step: 8
Training loss: 0.29814958572387695
Validation loss: 2.119600852330526

Epoch: 6| Step: 9
Training loss: 0.8911645412445068
Validation loss: 2.1258549094200134

Epoch: 6| Step: 10
Training loss: 0.31959325075149536
Validation loss: 2.102246562639872

Epoch: 6| Step: 11
Training loss: 0.667906641960144
Validation loss: 2.1395716269810996

Epoch: 6| Step: 12
Training loss: 0.6080299615859985
Validation loss: 2.119392693042755

Epoch: 6| Step: 13
Training loss: 0.383430153131485
Validation loss: 2.1025710900624595

Epoch: 341| Step: 0
Training loss: 0.42084190249443054
Validation loss: 2.146235764026642

Epoch: 6| Step: 1
Training loss: 0.2320166677236557
Validation loss: 2.095212201277415

Epoch: 6| Step: 2
Training loss: 0.34212571382522583
Validation loss: 2.129843990008036

Epoch: 6| Step: 3
Training loss: 0.4050442576408386
Validation loss: 2.134588122367859

Epoch: 6| Step: 4
Training loss: 0.31976088881492615
Validation loss: 2.1512569586435952

Epoch: 6| Step: 5
Training loss: 0.42103415727615356
Validation loss: 2.0972169637680054

Epoch: 6| Step: 6
Training loss: 1.1256639957427979
Validation loss: 2.172800342241923

Epoch: 6| Step: 7
Training loss: 0.606827974319458
Validation loss: 2.115341087182363

Epoch: 6| Step: 8
Training loss: 0.45842352509498596
Validation loss: 2.1146467328071594

Epoch: 6| Step: 9
Training loss: 0.3277623951435089
Validation loss: 2.1288609306017556

Epoch: 6| Step: 10
Training loss: 0.6961338520050049
Validation loss: 2.14701376358668

Epoch: 6| Step: 11
Training loss: 0.7378926873207092
Validation loss: 2.1518921852111816

Epoch: 6| Step: 12
Training loss: 0.28527629375457764
Validation loss: 2.1147067546844482

Epoch: 6| Step: 13
Training loss: 0.21671448647975922
Validation loss: 2.137565275033315

Epoch: 342| Step: 0
Training loss: 0.3865375220775604
Validation loss: 2.09869392712911

Epoch: 6| Step: 1
Training loss: 0.30637267231941223
Validation loss: 2.072474161783854

Epoch: 6| Step: 2
Training loss: 0.3385606110095978
Validation loss: 2.153196314970652

Epoch: 6| Step: 3
Training loss: 0.38140013813972473
Validation loss: 2.1210180123647056

Epoch: 6| Step: 4
Training loss: 0.5618768930435181
Validation loss: 2.1074607173601785

Epoch: 6| Step: 5
Training loss: 0.36169034242630005
Validation loss: 2.051753282546997

Epoch: 6| Step: 6
Training loss: 0.7318192720413208
Validation loss: 2.1242860158284507

Epoch: 6| Step: 7
Training loss: 0.8453083634376526
Validation loss: 2.097393532594045

Epoch: 6| Step: 8
Training loss: 0.5329864621162415
Validation loss: 2.1490745544433594

Epoch: 6| Step: 9
Training loss: 0.2803410589694977
Validation loss: 2.0859474738438926

Epoch: 6| Step: 10
Training loss: 0.19293510913848877
Validation loss: 2.117705523967743

Epoch: 6| Step: 11
Training loss: 0.8557226657867432
Validation loss: 2.1246517300605774

Epoch: 6| Step: 12
Training loss: 0.5774290561676025
Validation loss: 2.100472887357076

Epoch: 6| Step: 13
Training loss: 0.7625735998153687
Validation loss: 2.121803085009257

Epoch: 343| Step: 0
Training loss: 0.4267615079879761
Validation loss: 2.094414472579956

Epoch: 6| Step: 1
Training loss: 0.2366519570350647
Validation loss: 2.161328593889872

Epoch: 6| Step: 2
Training loss: 0.8793887495994568
Validation loss: 2.1651728550593057

Epoch: 6| Step: 3
Training loss: 0.29778236150741577
Validation loss: 2.134481648604075

Epoch: 6| Step: 4
Training loss: 1.072150707244873
Validation loss: 2.2144600550333657

Epoch: 6| Step: 5
Training loss: 0.38867220282554626
Validation loss: 2.200514336427053

Epoch: 6| Step: 6
Training loss: 0.38988566398620605
Validation loss: 2.1629605690638223

Epoch: 6| Step: 7
Training loss: 0.7808444499969482
Validation loss: 2.145718773206075

Epoch: 6| Step: 8
Training loss: 0.24197226762771606
Validation loss: 2.129341721534729

Epoch: 6| Step: 9
Training loss: 0.3919770419597626
Validation loss: 2.0891268849372864

Epoch: 6| Step: 10
Training loss: 0.6829804182052612
Validation loss: 2.0939138730367026

Epoch: 6| Step: 11
Training loss: 0.3210402727127075
Validation loss: 2.0936332742373147

Epoch: 6| Step: 12
Training loss: 0.26416251063346863
Validation loss: 2.080941657225291

Epoch: 6| Step: 13
Training loss: 0.4476062059402466
Validation loss: 2.1429570515950522

Epoch: 344| Step: 0
Training loss: 0.8861863613128662
Validation loss: 2.141058703263601

Epoch: 6| Step: 1
Training loss: 0.53816819190979
Validation loss: 2.1347073713938394

Epoch: 6| Step: 2
Training loss: 0.36771607398986816
Validation loss: 2.127856691678365

Epoch: 6| Step: 3
Training loss: 0.3352939188480377
Validation loss: 2.0992359717686973

Epoch: 6| Step: 4
Training loss: 0.2307165265083313
Validation loss: 2.1939065059026084

Epoch: 6| Step: 5
Training loss: 0.7320381999015808
Validation loss: 2.107390801111857

Epoch: 6| Step: 6
Training loss: 0.429843544960022
Validation loss: 2.1328646143277488

Epoch: 6| Step: 7
Training loss: 0.6180830001831055
Validation loss: 2.1281954844792685

Epoch: 6| Step: 8
Training loss: 0.4352424740791321
Validation loss: 2.1025741497675576

Epoch: 6| Step: 9
Training loss: 0.6543790102005005
Validation loss: 2.1267887353897095

Epoch: 6| Step: 10
Training loss: 0.43395453691482544
Validation loss: 2.154627541700999

Epoch: 6| Step: 11
Training loss: 0.3801746070384979
Validation loss: 2.1547308564186096

Epoch: 6| Step: 12
Training loss: 0.26366472244262695
Validation loss: 2.1281991402308145

Epoch: 6| Step: 13
Training loss: 0.44627049565315247
Validation loss: 2.0879689852396646

Epoch: 345| Step: 0
Training loss: 0.5495958924293518
Validation loss: 2.1970614194869995

Epoch: 6| Step: 1
Training loss: 0.7530932426452637
Validation loss: 2.2104154427846274

Epoch: 6| Step: 2
Training loss: 0.7723628282546997
Validation loss: 2.151933789253235

Epoch: 6| Step: 3
Training loss: 0.35837477445602417
Validation loss: 2.1724029382069907

Epoch: 6| Step: 4
Training loss: 0.4771636128425598
Validation loss: 2.123307526111603

Epoch: 6| Step: 5
Training loss: 0.4458073377609253
Validation loss: 2.1300830245018005

Epoch: 6| Step: 6
Training loss: 0.6046115159988403
Validation loss: 2.161777754624685

Epoch: 6| Step: 7
Training loss: 0.8048826456069946
Validation loss: 2.067984660466512

Epoch: 6| Step: 8
Training loss: 0.2549474239349365
Validation loss: 2.1079635620117188

Epoch: 6| Step: 9
Training loss: 0.5403242707252502
Validation loss: 2.0974457263946533

Epoch: 6| Step: 10
Training loss: 0.541548490524292
Validation loss: 2.11214147011439

Epoch: 6| Step: 11
Training loss: 0.46063032746315
Validation loss: 2.184370299180349

Epoch: 6| Step: 12
Training loss: 0.39053937792778015
Validation loss: 2.135101238886515

Epoch: 6| Step: 13
Training loss: 0.47511664032936096
Validation loss: 2.1273500521977744

Epoch: 346| Step: 0
Training loss: 0.19181931018829346
Validation loss: 2.1229368448257446

Epoch: 6| Step: 1
Training loss: 0.6480590105056763
Validation loss: 2.181481957435608

Epoch: 6| Step: 2
Training loss: 0.5123529434204102
Validation loss: 2.123992383480072

Epoch: 6| Step: 3
Training loss: 0.5920868515968323
Validation loss: 2.123615086078644

Epoch: 6| Step: 4
Training loss: 0.6031945943832397
Validation loss: 2.084140181541443

Epoch: 6| Step: 5
Training loss: 0.7818402647972107
Validation loss: 2.1165574391682944

Epoch: 6| Step: 6
Training loss: 0.335063099861145
Validation loss: 2.158598840236664

Epoch: 6| Step: 7
Training loss: 0.5845864415168762
Validation loss: 2.1351129015286765

Epoch: 6| Step: 8
Training loss: 0.5178169012069702
Validation loss: 2.135630706946055

Epoch: 6| Step: 9
Training loss: 0.19637948274612427
Validation loss: 2.1690401434898376

Epoch: 6| Step: 10
Training loss: 0.2611151933670044
Validation loss: 2.1547221144040427

Epoch: 6| Step: 11
Training loss: 0.49315202236175537
Validation loss: 2.201694587866465

Epoch: 6| Step: 12
Training loss: 0.573157787322998
Validation loss: 2.1799355943997702

Epoch: 6| Step: 13
Training loss: 0.3660140633583069
Validation loss: 2.1276502211888633

Epoch: 347| Step: 0
Training loss: 0.21889734268188477
Validation loss: 2.1563121477762857

Epoch: 6| Step: 1
Training loss: 0.5863688588142395
Validation loss: 2.132771909236908

Epoch: 6| Step: 2
Training loss: 0.2917134463787079
Validation loss: 2.152404805024465

Epoch: 6| Step: 3
Training loss: 0.5400208830833435
Validation loss: 2.0833335518836975

Epoch: 6| Step: 4
Training loss: 0.36304187774658203
Validation loss: 2.076375881830851

Epoch: 6| Step: 5
Training loss: 0.4805009365081787
Validation loss: 2.154037356376648

Epoch: 6| Step: 6
Training loss: 0.21102455258369446
Validation loss: 2.150553584098816

Epoch: 6| Step: 7
Training loss: 0.7144353985786438
Validation loss: 2.160841464996338

Epoch: 6| Step: 8
Training loss: 0.6009520292282104
Validation loss: 2.134604593118032

Epoch: 6| Step: 9
Training loss: 0.7298376560211182
Validation loss: 2.1397223671277366

Epoch: 6| Step: 10
Training loss: 0.6151750087738037
Validation loss: 2.1545594731966653

Epoch: 6| Step: 11
Training loss: 0.5280383229255676
Validation loss: 2.165452222029368

Epoch: 6| Step: 12
Training loss: 0.3753063380718231
Validation loss: 2.160475512345632

Epoch: 6| Step: 13
Training loss: 0.6793330907821655
Validation loss: 2.1366911927858987

Epoch: 348| Step: 0
Training loss: 0.47666436433792114
Validation loss: 2.182360510031382

Epoch: 6| Step: 1
Training loss: 0.43773534893989563
Validation loss: 2.1176386078198752

Epoch: 6| Step: 2
Training loss: 0.3144947290420532
Validation loss: 2.175683001677195

Epoch: 6| Step: 3
Training loss: 0.5646668672561646
Validation loss: 2.1494298577308655

Epoch: 6| Step: 4
Training loss: 0.7097824811935425
Validation loss: 2.1401925484339395

Epoch: 6| Step: 5
Training loss: 0.2878284454345703
Validation loss: 2.114171028137207

Epoch: 6| Step: 6
Training loss: 0.3698452115058899
Validation loss: 2.1741034388542175

Epoch: 6| Step: 7
Training loss: 0.2519187927246094
Validation loss: 2.1457453966140747

Epoch: 6| Step: 8
Training loss: 0.6499977111816406
Validation loss: 2.166644831498464

Epoch: 6| Step: 9
Training loss: 0.26734697818756104
Validation loss: 2.149449626604716

Epoch: 6| Step: 10
Training loss: 0.6289552450180054
Validation loss: 2.167752742767334

Epoch: 6| Step: 11
Training loss: 0.47657275199890137
Validation loss: 2.1658501029014587

Epoch: 6| Step: 12
Training loss: 0.6269781589508057
Validation loss: 2.1367711424827576

Epoch: 6| Step: 13
Training loss: 0.8271567821502686
Validation loss: 2.1524442632993064

Epoch: 349| Step: 0
Training loss: 0.5765795111656189
Validation loss: 2.123286863168081

Epoch: 6| Step: 1
Training loss: 0.4254193902015686
Validation loss: 2.166077713171641

Epoch: 6| Step: 2
Training loss: 0.4691886603832245
Validation loss: 2.0664798816045127

Epoch: 6| Step: 3
Training loss: 0.9221436977386475
Validation loss: 2.1023496190706887

Epoch: 6| Step: 4
Training loss: 0.5093896389007568
Validation loss: 2.138334890206655

Epoch: 6| Step: 5
Training loss: 0.6080928444862366
Validation loss: 2.14910888671875

Epoch: 6| Step: 6
Training loss: 0.6754858493804932
Validation loss: 2.1328394214312234

Epoch: 6| Step: 7
Training loss: 0.41882792115211487
Validation loss: 2.175319333871206

Epoch: 6| Step: 8
Training loss: 0.40127190947532654
Validation loss: 2.1656829714775085

Epoch: 6| Step: 9
Training loss: 0.5131093859672546
Validation loss: 2.0838683446248374

Epoch: 6| Step: 10
Training loss: 0.2900182008743286
Validation loss: 2.1216681202252707

Epoch: 6| Step: 11
Training loss: 0.6574907302856445
Validation loss: 2.142273406187693

Epoch: 6| Step: 12
Training loss: 0.746514618396759
Validation loss: 2.072283089160919

Epoch: 6| Step: 13
Training loss: 0.5464556217193604
Validation loss: 2.138462404410044

Epoch: 350| Step: 0
Training loss: 0.19213345646858215
Validation loss: 2.115942120552063

Epoch: 6| Step: 1
Training loss: 0.28865256905555725
Validation loss: 2.108954886595408

Epoch: 6| Step: 2
Training loss: 0.6760722398757935
Validation loss: 2.13431982199351

Epoch: 6| Step: 3
Training loss: 0.255165159702301
Validation loss: 2.1246241331100464

Epoch: 6| Step: 4
Training loss: 0.28316646814346313
Validation loss: 2.1375847458839417

Epoch: 6| Step: 5
Training loss: 0.43310898542404175
Validation loss: 2.206909477710724

Epoch: 6| Step: 6
Training loss: 0.4090062379837036
Validation loss: 2.1395224730173745

Epoch: 6| Step: 7
Training loss: 0.5582869052886963
Validation loss: 2.1637668212254844

Epoch: 6| Step: 8
Training loss: 0.6092277765274048
Validation loss: 2.142278492450714

Epoch: 6| Step: 9
Training loss: 0.6139042377471924
Validation loss: 2.1385419964790344

Epoch: 6| Step: 10
Training loss: 0.5121269226074219
Validation loss: 2.1733179688453674

Epoch: 6| Step: 11
Training loss: 0.7436680197715759
Validation loss: 2.141444762547811

Epoch: 6| Step: 12
Training loss: 0.4533211290836334
Validation loss: 2.1745407780011496

Epoch: 6| Step: 13
Training loss: 0.56444251537323
Validation loss: 2.1854038635889688

Epoch: 351| Step: 0
Training loss: 0.6180974841117859
Validation loss: 2.0998241305351257

Epoch: 6| Step: 1
Training loss: 0.5049107074737549
Validation loss: 2.1614850560824075

Epoch: 6| Step: 2
Training loss: 0.5532858967781067
Validation loss: 2.1330591440200806

Epoch: 6| Step: 3
Training loss: 0.4261128902435303
Validation loss: 2.1681402126948037

Epoch: 6| Step: 4
Training loss: 0.44777241349220276
Validation loss: 2.131993075211843

Epoch: 6| Step: 5
Training loss: 0.34825366735458374
Validation loss: 2.1569411953290305

Epoch: 6| Step: 6
Training loss: 0.27347755432128906
Validation loss: 2.131075461705526

Epoch: 6| Step: 7
Training loss: 0.40803971886634827
Validation loss: 2.096866230169932

Epoch: 6| Step: 8
Training loss: 0.49985331296920776
Validation loss: 2.135230779647827

Epoch: 6| Step: 9
Training loss: 0.7850422859191895
Validation loss: 2.124885002772013

Epoch: 6| Step: 10
Training loss: 0.25334838032722473
Validation loss: 2.130756656328837

Epoch: 6| Step: 11
Training loss: 0.27688461542129517
Validation loss: 2.149733821551005

Epoch: 6| Step: 12
Training loss: 0.35021376609802246
Validation loss: 2.1636468172073364

Epoch: 6| Step: 13
Training loss: 0.8587800860404968
Validation loss: 2.1624629894892373

Epoch: 352| Step: 0
Training loss: 0.39674824476242065
Validation loss: 2.1694604953130088

Epoch: 6| Step: 1
Training loss: 0.26238787174224854
Validation loss: 2.1747442483901978

Epoch: 6| Step: 2
Training loss: 0.3645029067993164
Validation loss: 2.1745200157165527

Epoch: 6| Step: 3
Training loss: 0.5601806640625
Validation loss: 2.139107584953308

Epoch: 6| Step: 4
Training loss: 0.5789980888366699
Validation loss: 2.131733536720276

Epoch: 6| Step: 5
Training loss: 0.4631968140602112
Validation loss: 2.1279832323392234

Epoch: 6| Step: 6
Training loss: 0.7617434859275818
Validation loss: 2.1118882099787393

Epoch: 6| Step: 7
Training loss: 0.22754111886024475
Validation loss: 2.1429525017738342

Epoch: 6| Step: 8
Training loss: 0.21250233054161072
Validation loss: 2.129171450932821

Epoch: 6| Step: 9
Training loss: 0.5742115378379822
Validation loss: 2.143292466799418

Epoch: 6| Step: 10
Training loss: 0.8166000843048096
Validation loss: 2.1523438692092896

Epoch: 6| Step: 11
Training loss: 0.41015520691871643
Validation loss: 2.123556613922119

Epoch: 6| Step: 12
Training loss: 0.7877380847930908
Validation loss: 2.2222673495610556

Epoch: 6| Step: 13
Training loss: 0.43506112694740295
Validation loss: 2.164086719353994

Epoch: 353| Step: 0
Training loss: 0.4809280037879944
Validation loss: 2.1386980215708413

Epoch: 6| Step: 1
Training loss: 0.25515395402908325
Validation loss: 2.1661965250968933

Epoch: 6| Step: 2
Training loss: 0.9833789467811584
Validation loss: 2.121256470680237

Epoch: 6| Step: 3
Training loss: 0.3373134434223175
Validation loss: 2.1445748607317605

Epoch: 6| Step: 4
Training loss: 0.4429936707019806
Validation loss: 2.144417186578115

Epoch: 6| Step: 5
Training loss: 0.29130879044532776
Validation loss: 2.142505427201589

Epoch: 6| Step: 6
Training loss: 0.5371364951133728
Validation loss: 2.1593690315882363

Epoch: 6| Step: 7
Training loss: 0.6970949172973633
Validation loss: 2.1244754592577615

Epoch: 6| Step: 8
Training loss: 0.32520416378974915
Validation loss: 2.170305550098419

Epoch: 6| Step: 9
Training loss: 0.5975978374481201
Validation loss: 2.138801713784536

Epoch: 6| Step: 10
Training loss: 0.7671772241592407
Validation loss: 2.2017059922218323

Epoch: 6| Step: 11
Training loss: 0.3560067415237427
Validation loss: 2.1708944837252298

Epoch: 6| Step: 12
Training loss: 0.4884965419769287
Validation loss: 2.14475949605306

Epoch: 6| Step: 13
Training loss: 0.3446871042251587
Validation loss: 2.117982546488444

Epoch: 354| Step: 0
Training loss: 0.2272869348526001
Validation loss: 2.1159517963727317

Epoch: 6| Step: 1
Training loss: 0.7553043961524963
Validation loss: 2.1548182566960654

Epoch: 6| Step: 2
Training loss: 0.7128469944000244
Validation loss: 2.0773531198501587

Epoch: 6| Step: 3
Training loss: 0.5624286532402039
Validation loss: 2.064490536848704

Epoch: 6| Step: 4
Training loss: 0.28728100657463074
Validation loss: 2.1370763778686523

Epoch: 6| Step: 5
Training loss: 0.36439675092697144
Validation loss: 2.1555328369140625

Epoch: 6| Step: 6
Training loss: 0.5177978277206421
Validation loss: 2.1532812317212424

Epoch: 6| Step: 7
Training loss: 0.21737240254878998
Validation loss: 2.1471900145212808

Epoch: 6| Step: 8
Training loss: 0.5390318632125854
Validation loss: 2.1607365012168884

Epoch: 6| Step: 9
Training loss: 0.4511818289756775
Validation loss: 2.1550413568814597

Epoch: 6| Step: 10
Training loss: 0.4862081706523895
Validation loss: 2.1902639468510947

Epoch: 6| Step: 11
Training loss: 0.299723744392395
Validation loss: 2.1817623376846313

Epoch: 6| Step: 12
Training loss: 0.4751058518886566
Validation loss: 2.133391181627909

Epoch: 6| Step: 13
Training loss: 0.6199867725372314
Validation loss: 2.1883089542388916

Epoch: 355| Step: 0
Training loss: 0.5872507095336914
Validation loss: 2.1562843521436057

Epoch: 6| Step: 1
Training loss: 0.5662972331047058
Validation loss: 2.068218549092611

Epoch: 6| Step: 2
Training loss: 0.2397741675376892
Validation loss: 2.1723670959472656

Epoch: 6| Step: 3
Training loss: 0.35471057891845703
Validation loss: 2.1621501644452414

Epoch: 6| Step: 4
Training loss: 0.3491794466972351
Validation loss: 2.1208072106043496

Epoch: 6| Step: 5
Training loss: 0.444526731967926
Validation loss: 2.119424521923065

Epoch: 6| Step: 6
Training loss: 0.24415569007396698
Validation loss: 2.1610536575317383

Epoch: 6| Step: 7
Training loss: 0.4068561792373657
Validation loss: 2.1546221375465393

Epoch: 6| Step: 8
Training loss: 0.6251069903373718
Validation loss: 2.1922237078348794

Epoch: 6| Step: 9
Training loss: 0.8007616996765137
Validation loss: 2.170662522315979

Epoch: 6| Step: 10
Training loss: 0.8241411447525024
Validation loss: 2.1061954498291016

Epoch: 6| Step: 11
Training loss: 0.38738927245140076
Validation loss: 2.1453263759613037

Epoch: 6| Step: 12
Training loss: 0.5165835022926331
Validation loss: 2.1392699082692466

Epoch: 6| Step: 13
Training loss: 0.39092856645584106
Validation loss: 2.1345337430636087

Epoch: 356| Step: 0
Training loss: 0.7242206931114197
Validation loss: 2.164660612742106

Epoch: 6| Step: 1
Training loss: 0.25290951132774353
Validation loss: 2.137829899787903

Epoch: 6| Step: 2
Training loss: 0.3639755845069885
Validation loss: 2.1498162349065146

Epoch: 6| Step: 3
Training loss: 0.39241212606430054
Validation loss: 2.0864863991737366

Epoch: 6| Step: 4
Training loss: 0.6201333999633789
Validation loss: 2.1490019162495932

Epoch: 6| Step: 5
Training loss: 0.4813368022441864
Validation loss: 2.1371066570281982

Epoch: 6| Step: 6
Training loss: 0.28429681062698364
Validation loss: 2.142817576726278

Epoch: 6| Step: 7
Training loss: 0.33198702335357666
Validation loss: 2.1053805152575173

Epoch: 6| Step: 8
Training loss: 0.3073205351829529
Validation loss: 2.1279491583506265

Epoch: 6| Step: 9
Training loss: 0.301170289516449
Validation loss: 2.1149126092592874

Epoch: 6| Step: 10
Training loss: 0.7137123346328735
Validation loss: 2.1672857205073037

Epoch: 6| Step: 11
Training loss: 0.3459615707397461
Validation loss: 2.1567957401275635

Epoch: 6| Step: 12
Training loss: 0.5927362442016602
Validation loss: 2.1278331677118936

Epoch: 6| Step: 13
Training loss: 0.6624220013618469
Validation loss: 2.1195246974627175

Epoch: 357| Step: 0
Training loss: 0.272309273481369
Validation loss: 2.093193451563517

Epoch: 6| Step: 1
Training loss: 0.27879688143730164
Validation loss: 2.155277748902639

Epoch: 6| Step: 2
Training loss: 0.38106629252433777
Validation loss: 2.1074494123458862

Epoch: 6| Step: 3
Training loss: 0.7330793142318726
Validation loss: 2.118202487627665

Epoch: 6| Step: 4
Training loss: 0.1990700215101242
Validation loss: 2.1353931029637656

Epoch: 6| Step: 5
Training loss: 0.34369853138923645
Validation loss: 2.097055276234945

Epoch: 6| Step: 6
Training loss: 0.34455111622810364
Validation loss: 2.1780041456222534

Epoch: 6| Step: 7
Training loss: 0.864538848400116
Validation loss: 2.1057393153508506

Epoch: 6| Step: 8
Training loss: 0.7368708848953247
Validation loss: 2.1538369258244834

Epoch: 6| Step: 9
Training loss: 0.24787044525146484
Validation loss: 2.1261465152104697

Epoch: 6| Step: 10
Training loss: 0.7944685220718384
Validation loss: 2.1041646599769592

Epoch: 6| Step: 11
Training loss: 0.3469246029853821
Validation loss: 2.1217758655548096

Epoch: 6| Step: 12
Training loss: 0.739211916923523
Validation loss: 2.154497742652893

Epoch: 6| Step: 13
Training loss: 0.3521866202354431
Validation loss: 2.1408726374308267

Epoch: 358| Step: 0
Training loss: 0.31365615129470825
Validation loss: 2.173588991165161

Epoch: 6| Step: 1
Training loss: 0.33751678466796875
Validation loss: 2.1757564544677734

Epoch: 6| Step: 2
Training loss: 0.43237268924713135
Validation loss: 2.1035364071528115

Epoch: 6| Step: 3
Training loss: 0.4099311828613281
Validation loss: 2.169095993041992

Epoch: 6| Step: 4
Training loss: 0.43938642740249634
Validation loss: 2.1747878789901733

Epoch: 6| Step: 5
Training loss: 0.6632105708122253
Validation loss: 2.150114357471466

Epoch: 6| Step: 6
Training loss: 0.3928702473640442
Validation loss: 2.171374181906382

Epoch: 6| Step: 7
Training loss: 0.4955883324146271
Validation loss: 2.1858650048573813

Epoch: 6| Step: 8
Training loss: 0.4534410238265991
Validation loss: 2.134111702442169

Epoch: 6| Step: 9
Training loss: 0.5715188980102539
Validation loss: 2.1660573879877725

Epoch: 6| Step: 10
Training loss: 0.9331393837928772
Validation loss: 2.1039329369862876

Epoch: 6| Step: 11
Training loss: 0.3203842043876648
Validation loss: 2.162112911542257

Epoch: 6| Step: 12
Training loss: 0.6816960573196411
Validation loss: 2.1289150714874268

Epoch: 6| Step: 13
Training loss: 0.6167991757392883
Validation loss: 2.092635194460551

Epoch: 359| Step: 0
Training loss: 0.35869717597961426
Validation loss: 2.127178728580475

Epoch: 6| Step: 1
Training loss: 0.45913833379745483
Validation loss: 2.1217969258626304

Epoch: 6| Step: 2
Training loss: 0.2654925584793091
Validation loss: 2.1308353741963706

Epoch: 6| Step: 3
Training loss: 0.4677848219871521
Validation loss: 2.1712326407432556

Epoch: 6| Step: 4
Training loss: 0.38168537616729736
Validation loss: 2.1491509675979614

Epoch: 6| Step: 5
Training loss: 0.378510981798172
Validation loss: 2.103028178215027

Epoch: 6| Step: 6
Training loss: 0.44188791513442993
Validation loss: 2.1257646679878235

Epoch: 6| Step: 7
Training loss: 0.7450234889984131
Validation loss: 2.1454694668451944

Epoch: 6| Step: 8
Training loss: 0.4021456837654114
Validation loss: 2.127285659313202

Epoch: 6| Step: 9
Training loss: 0.37524616718292236
Validation loss: 2.139252026875814

Epoch: 6| Step: 10
Training loss: 0.3784481883049011
Validation loss: 2.1485402385393777

Epoch: 6| Step: 11
Training loss: 0.3886255919933319
Validation loss: 2.1378448406855264

Epoch: 6| Step: 12
Training loss: 0.9703284502029419
Validation loss: 2.127042313416799

Epoch: 6| Step: 13
Training loss: 0.34103429317474365
Validation loss: 2.1771424611409507

Epoch: 360| Step: 0
Training loss: 1.063153624534607
Validation loss: 2.1562270522117615

Epoch: 6| Step: 1
Training loss: 0.3213314414024353
Validation loss: 2.197230319182078

Epoch: 6| Step: 2
Training loss: 0.463985800743103
Validation loss: 2.116553564866384

Epoch: 6| Step: 3
Training loss: 0.3912298083305359
Validation loss: 2.170987923940023

Epoch: 6| Step: 4
Training loss: 0.38500890135765076
Validation loss: 2.0901134808858237

Epoch: 6| Step: 5
Training loss: 0.3755459785461426
Validation loss: 2.157655040423075

Epoch: 6| Step: 6
Training loss: 0.4605724811553955
Validation loss: 2.1825676361719766

Epoch: 6| Step: 7
Training loss: 0.4416590929031372
Validation loss: 2.1575583616892495

Epoch: 6| Step: 8
Training loss: 0.4056110382080078
Validation loss: 2.1894068121910095

Epoch: 6| Step: 9
Training loss: 0.2590388357639313
Validation loss: 2.1513162652651467

Epoch: 6| Step: 10
Training loss: 0.48920363187789917
Validation loss: 2.0990442434946694

Epoch: 6| Step: 11
Training loss: 0.37787652015686035
Validation loss: 2.1434712409973145

Epoch: 6| Step: 12
Training loss: 0.42279285192489624
Validation loss: 2.1549267172813416

Epoch: 6| Step: 13
Training loss: 0.38788190484046936
Validation loss: 2.189124365647634

Epoch: 361| Step: 0
Training loss: 0.338863730430603
Validation loss: 2.13192751010259

Epoch: 6| Step: 1
Training loss: 0.6734973788261414
Validation loss: 2.1575950384140015

Epoch: 6| Step: 2
Training loss: 0.47609958052635193
Validation loss: 2.119905412197113

Epoch: 6| Step: 3
Training loss: 0.7120526432991028
Validation loss: 2.1541860103607178

Epoch: 6| Step: 4
Training loss: 0.20694231986999512
Validation loss: 2.142184873421987

Epoch: 6| Step: 5
Training loss: 0.6351028084754944
Validation loss: 2.094287395477295

Epoch: 6| Step: 6
Training loss: 0.33760878443717957
Validation loss: 2.122265557448069

Epoch: 6| Step: 7
Training loss: 0.4521735906600952
Validation loss: 2.1457104682922363

Epoch: 6| Step: 8
Training loss: 0.4755374491214752
Validation loss: 2.138197660446167

Epoch: 6| Step: 9
Training loss: 0.4590756893157959
Validation loss: 2.1602079470952353

Epoch: 6| Step: 10
Training loss: 0.29071611166000366
Validation loss: 2.1317532857259116

Epoch: 6| Step: 11
Training loss: 0.7897354364395142
Validation loss: 2.108494977156321

Epoch: 6| Step: 12
Training loss: 0.3919526934623718
Validation loss: 2.1736064751942954

Epoch: 6| Step: 13
Training loss: 0.338776171207428
Validation loss: 2.141988436381022

Epoch: 362| Step: 0
Training loss: 0.5730923414230347
Validation loss: 2.1440818111101785

Epoch: 6| Step: 1
Training loss: 0.18211570382118225
Validation loss: 2.1238836447397866

Epoch: 6| Step: 2
Training loss: 0.4587043821811676
Validation loss: 2.109483301639557

Epoch: 6| Step: 3
Training loss: 0.779036283493042
Validation loss: 2.1275609334309897

Epoch: 6| Step: 4
Training loss: 0.3100927174091339
Validation loss: 2.1908698876698813

Epoch: 6| Step: 5
Training loss: 0.4645998477935791
Validation loss: 2.1387092669804892

Epoch: 6| Step: 6
Training loss: 0.35493385791778564
Validation loss: 2.1296763022740683

Epoch: 6| Step: 7
Training loss: 0.5458242893218994
Validation loss: 2.1408464908599854

Epoch: 6| Step: 8
Training loss: 0.2644699215888977
Validation loss: 2.17217610279719

Epoch: 6| Step: 9
Training loss: 0.3482416868209839
Validation loss: 2.169223745663961

Epoch: 6| Step: 10
Training loss: 0.26692095398902893
Validation loss: 2.1886061628659568

Epoch: 6| Step: 11
Training loss: 0.5421553254127502
Validation loss: 2.1237005392710366

Epoch: 6| Step: 12
Training loss: 0.3224391043186188
Validation loss: 2.1580389936765036

Epoch: 6| Step: 13
Training loss: 0.4465465545654297
Validation loss: 2.190919121106466

Epoch: 363| Step: 0
Training loss: 0.42969590425491333
Validation loss: 2.1970478693644204

Epoch: 6| Step: 1
Training loss: 0.35726165771484375
Validation loss: 2.1621787746747336

Epoch: 6| Step: 2
Training loss: 0.3441411554813385
Validation loss: 2.1789738535881042

Epoch: 6| Step: 3
Training loss: 0.20317618548870087
Validation loss: 2.144229551156362

Epoch: 6| Step: 4
Training loss: 0.15638884902000427
Validation loss: 2.169582724571228

Epoch: 6| Step: 5
Training loss: 0.5333016514778137
Validation loss: 2.1417928536732993

Epoch: 6| Step: 6
Training loss: 0.5681559443473816
Validation loss: 2.135383447011312

Epoch: 6| Step: 7
Training loss: 0.569998025894165
Validation loss: 2.170721173286438

Epoch: 6| Step: 8
Training loss: 0.5595144629478455
Validation loss: 2.136265277862549

Epoch: 6| Step: 9
Training loss: 0.2968074381351471
Validation loss: 2.1405296524365744

Epoch: 6| Step: 10
Training loss: 0.3601229190826416
Validation loss: 2.1634527444839478

Epoch: 6| Step: 11
Training loss: 0.47476086020469666
Validation loss: 2.1554731527964273

Epoch: 6| Step: 12
Training loss: 0.3939611613750458
Validation loss: 2.1232325633366904

Epoch: 6| Step: 13
Training loss: 1.240150809288025
Validation loss: 2.1039096117019653

Epoch: 364| Step: 0
Training loss: 0.42315739393234253
Validation loss: 2.1631173491477966

Epoch: 6| Step: 1
Training loss: 0.5982651710510254
Validation loss: 2.1411798199017844

Epoch: 6| Step: 2
Training loss: 0.3082612156867981
Validation loss: 2.144230842590332

Epoch: 6| Step: 3
Training loss: 0.3923300504684448
Validation loss: 2.1803969740867615

Epoch: 6| Step: 4
Training loss: 0.24052882194519043
Validation loss: 2.187912921110789

Epoch: 6| Step: 5
Training loss: 0.8969841599464417
Validation loss: 2.104742785294851

Epoch: 6| Step: 6
Training loss: 0.25247180461883545
Validation loss: 2.1320523818333945

Epoch: 6| Step: 7
Training loss: 0.4555903673171997
Validation loss: 2.1394822001457214

Epoch: 6| Step: 8
Training loss: 0.5054333806037903
Validation loss: 2.1351884603500366

Epoch: 6| Step: 9
Training loss: 0.6617037057876587
Validation loss: 2.1407443284988403

Epoch: 6| Step: 10
Training loss: 0.3682672381401062
Validation loss: 2.139641006787618

Epoch: 6| Step: 11
Training loss: 0.2500290274620056
Validation loss: 2.1393363873163858

Epoch: 6| Step: 12
Training loss: 0.4770424962043762
Validation loss: 2.144687235355377

Epoch: 6| Step: 13
Training loss: 0.5123010277748108
Validation loss: 2.0796431501706443

Epoch: 365| Step: 0
Training loss: 0.6963034868240356
Validation loss: 2.1863988439242044

Epoch: 6| Step: 1
Training loss: 0.44684091210365295
Validation loss: 2.1657660802205405

Epoch: 6| Step: 2
Training loss: 0.6094952821731567
Validation loss: 2.175694445768992

Epoch: 6| Step: 3
Training loss: 0.24596355855464935
Validation loss: 2.1612366835276284

Epoch: 6| Step: 4
Training loss: 0.5110777616500854
Validation loss: 2.1696829994519553

Epoch: 6| Step: 5
Training loss: 0.27448031306266785
Validation loss: 2.1533673206965127

Epoch: 6| Step: 6
Training loss: 0.3132725954055786
Validation loss: 2.174764076868693

Epoch: 6| Step: 7
Training loss: 0.2961582839488983
Validation loss: 2.1010419925053916

Epoch: 6| Step: 8
Training loss: 0.27140432596206665
Validation loss: 2.1789377331733704

Epoch: 6| Step: 9
Training loss: 0.2859117388725281
Validation loss: 2.1709561347961426

Epoch: 6| Step: 10
Training loss: 0.48597264289855957
Validation loss: 2.148141403992971

Epoch: 6| Step: 11
Training loss: 0.710547924041748
Validation loss: 2.129206438859304

Epoch: 6| Step: 12
Training loss: 0.49322766065597534
Validation loss: 2.17208464940389

Epoch: 6| Step: 13
Training loss: 0.41833415627479553
Validation loss: 2.1786484718322754

Epoch: 366| Step: 0
Training loss: 0.8241103887557983
Validation loss: 2.175625801086426

Epoch: 6| Step: 1
Training loss: 0.38924840092658997
Validation loss: 2.179246465365092

Epoch: 6| Step: 2
Training loss: 0.5271135568618774
Validation loss: 2.1520055135091147

Epoch: 6| Step: 3
Training loss: 0.583911657333374
Validation loss: 2.160105069478353

Epoch: 6| Step: 4
Training loss: 0.44507449865341187
Validation loss: 2.1574203968048096

Epoch: 6| Step: 5
Training loss: 0.4689527750015259
Validation loss: 2.1498828728993735

Epoch: 6| Step: 6
Training loss: 0.36351367831230164
Validation loss: 2.1080970764160156

Epoch: 6| Step: 7
Training loss: 0.3688954710960388
Validation loss: 2.151236971219381

Epoch: 6| Step: 8
Training loss: 0.3611215651035309
Validation loss: 2.1229468981424966

Epoch: 6| Step: 9
Training loss: 0.4980378746986389
Validation loss: 2.163419783115387

Epoch: 6| Step: 10
Training loss: 0.3289841413497925
Validation loss: 2.161711037158966

Epoch: 6| Step: 11
Training loss: 0.35817593336105347
Validation loss: 2.211359898249308

Epoch: 6| Step: 12
Training loss: 0.4820178151130676
Validation loss: 2.169494350751241

Epoch: 6| Step: 13
Training loss: 0.33346590399742126
Validation loss: 2.1614450017611184

Epoch: 367| Step: 0
Training loss: 0.39527440071105957
Validation loss: 2.145262837409973

Epoch: 6| Step: 1
Training loss: 0.3655076324939728
Validation loss: 2.1382839481035867

Epoch: 6| Step: 2
Training loss: 1.0554015636444092
Validation loss: 2.16072412331899

Epoch: 6| Step: 3
Training loss: 0.3816000819206238
Validation loss: 2.167256474494934

Epoch: 6| Step: 4
Training loss: 0.2880726158618927
Validation loss: 2.1103302041689553

Epoch: 6| Step: 5
Training loss: 0.5058234333992004
Validation loss: 2.19248636563619

Epoch: 6| Step: 6
Training loss: 0.6393164396286011
Validation loss: 2.168855826059977

Epoch: 6| Step: 7
Training loss: 0.3515107035636902
Validation loss: 2.1525261998176575

Epoch: 6| Step: 8
Training loss: 0.23497377336025238
Validation loss: 2.113337218761444

Epoch: 6| Step: 9
Training loss: 0.8461719751358032
Validation loss: 2.119653642177582

Epoch: 6| Step: 10
Training loss: 0.3270539939403534
Validation loss: 2.130526820818583

Epoch: 6| Step: 11
Training loss: 0.48430678248405457
Validation loss: 2.1792240738868713

Epoch: 6| Step: 12
Training loss: 0.19328603148460388
Validation loss: 2.174159288406372

Epoch: 6| Step: 13
Training loss: 0.38251468539237976
Validation loss: 2.160218298435211

Epoch: 368| Step: 0
Training loss: 0.38639718294143677
Validation loss: 2.154609978199005

Epoch: 6| Step: 1
Training loss: 0.8489863872528076
Validation loss: 2.2123098572095237

Epoch: 6| Step: 2
Training loss: 0.3720960021018982
Validation loss: 2.202887852986654

Epoch: 6| Step: 3
Training loss: 0.6310884952545166
Validation loss: 2.1529183983802795

Epoch: 6| Step: 4
Training loss: 0.7621945142745972
Validation loss: 2.18040269613266

Epoch: 6| Step: 5
Training loss: 0.2137967348098755
Validation loss: 2.1260419289271035

Epoch: 6| Step: 6
Training loss: 0.41913652420043945
Validation loss: 2.1391286849975586

Epoch: 6| Step: 7
Training loss: 0.5851353406906128
Validation loss: 2.150281627972921

Epoch: 6| Step: 8
Training loss: 0.3270445168018341
Validation loss: 2.1446346839269004

Epoch: 6| Step: 9
Training loss: 0.6117340922355652
Validation loss: 2.1608439882596335

Epoch: 6| Step: 10
Training loss: 0.2352888435125351
Validation loss: 2.1852834224700928

Epoch: 6| Step: 11
Training loss: 0.5537000298500061
Validation loss: 2.1226463317871094

Epoch: 6| Step: 12
Training loss: 0.5410804748535156
Validation loss: 2.1412611603736877

Epoch: 6| Step: 13
Training loss: 0.3575989603996277
Validation loss: 2.1700745026270547

Epoch: 369| Step: 0
Training loss: 0.5005678534507751
Validation loss: 2.201139748096466

Epoch: 6| Step: 1
Training loss: 0.4053882360458374
Validation loss: 2.1564797163009644

Epoch: 6| Step: 2
Training loss: 0.29541581869125366
Validation loss: 2.156644642353058

Epoch: 6| Step: 3
Training loss: 0.33075055480003357
Validation loss: 2.1090424259503684

Epoch: 6| Step: 4
Training loss: 0.4685211777687073
Validation loss: 2.1183972557385764

Epoch: 6| Step: 5
Training loss: 0.40143144130706787
Validation loss: 2.1798928578694663

Epoch: 6| Step: 6
Training loss: 0.5449826717376709
Validation loss: 2.1425089637438455

Epoch: 6| Step: 7
Training loss: 0.27747172117233276
Validation loss: 2.0963303049405417

Epoch: 6| Step: 8
Training loss: 0.9616900086402893
Validation loss: 2.170488715171814

Epoch: 6| Step: 9
Training loss: 0.4307202696800232
Validation loss: 2.125413199265798

Epoch: 6| Step: 10
Training loss: 0.4217810034751892
Validation loss: 2.1400213837623596

Epoch: 6| Step: 11
Training loss: 0.4122135639190674
Validation loss: 2.1727246840794883

Epoch: 6| Step: 12
Training loss: 0.7972298860549927
Validation loss: 2.1937893430391946

Epoch: 6| Step: 13
Training loss: 0.5640921592712402
Validation loss: 2.1894511183102927

Epoch: 370| Step: 0
Training loss: 0.34345829486846924
Validation loss: 2.151539663473765

Epoch: 6| Step: 1
Training loss: 0.3805311918258667
Validation loss: 2.1179850101470947

Epoch: 6| Step: 2
Training loss: 0.7956105470657349
Validation loss: 2.1530349254608154

Epoch: 6| Step: 3
Training loss: 0.44111955165863037
Validation loss: 2.1567450761795044

Epoch: 6| Step: 4
Training loss: 0.3991788625717163
Validation loss: 2.1986099680264792

Epoch: 6| Step: 5
Training loss: 0.30512142181396484
Validation loss: 2.0871551036834717

Epoch: 6| Step: 6
Training loss: 0.5221496820449829
Validation loss: 2.1379823684692383

Epoch: 6| Step: 7
Training loss: 0.6174492239952087
Validation loss: 2.151368955771128

Epoch: 6| Step: 8
Training loss: 0.6742914915084839
Validation loss: 2.08124703168869

Epoch: 6| Step: 9
Training loss: 0.5974180698394775
Validation loss: 2.1345170934995017

Epoch: 6| Step: 10
Training loss: 0.34070712327957153
Validation loss: 2.195533196131388

Epoch: 6| Step: 11
Training loss: 0.3044167757034302
Validation loss: 2.1743722359339395

Epoch: 6| Step: 12
Training loss: 0.3909345865249634
Validation loss: 2.175009767214457

Epoch: 6| Step: 13
Training loss: 0.5517178773880005
Validation loss: 2.1715099612871804

Epoch: 371| Step: 0
Training loss: 0.1925911158323288
Validation loss: 2.185127635796865

Epoch: 6| Step: 1
Training loss: 0.7009910345077515
Validation loss: 2.167702078819275

Epoch: 6| Step: 2
Training loss: 0.26344943046569824
Validation loss: 2.123185396194458

Epoch: 6| Step: 3
Training loss: 0.3813636302947998
Validation loss: 2.152083416779836

Epoch: 6| Step: 4
Training loss: 0.23222216963768005
Validation loss: 2.150609791278839

Epoch: 6| Step: 5
Training loss: 0.4717857837677002
Validation loss: 2.1315879623095193

Epoch: 6| Step: 6
Training loss: 0.4589725136756897
Validation loss: 2.1551562945048013

Epoch: 6| Step: 7
Training loss: 0.20964863896369934
Validation loss: 2.1106777588526406

Epoch: 6| Step: 8
Training loss: 0.5021523237228394
Validation loss: 2.1447341640790305

Epoch: 6| Step: 9
Training loss: 0.281818687915802
Validation loss: 2.172723333040873

Epoch: 6| Step: 10
Training loss: 0.7732738256454468
Validation loss: 2.164710521697998

Epoch: 6| Step: 11
Training loss: 0.45166462659835815
Validation loss: 2.170603613058726

Epoch: 6| Step: 12
Training loss: 0.41016483306884766
Validation loss: 2.129175066947937

Epoch: 6| Step: 13
Training loss: 0.5073753595352173
Validation loss: 2.1530031164487204

Epoch: 372| Step: 0
Training loss: 0.20647217333316803
Validation loss: 2.13230699300766

Epoch: 6| Step: 1
Training loss: 0.3410083055496216
Validation loss: 2.1594117482503257

Epoch: 6| Step: 2
Training loss: 0.962755560874939
Validation loss: 2.195958932240804

Epoch: 6| Step: 3
Training loss: 0.393282413482666
Validation loss: 2.132788340250651

Epoch: 6| Step: 4
Training loss: 0.3318908214569092
Validation loss: 2.113973557949066

Epoch: 6| Step: 5
Training loss: 0.5769485235214233
Validation loss: 2.1438215176264444

Epoch: 6| Step: 6
Training loss: 0.2772274613380432
Validation loss: 2.193902055422465

Epoch: 6| Step: 7
Training loss: 0.5043923854827881
Validation loss: 2.2201929092407227

Epoch: 6| Step: 8
Training loss: 0.2863232493400574
Validation loss: 2.1673890352249146

Epoch: 6| Step: 9
Training loss: 0.45369982719421387
Validation loss: 2.1938904921213784

Epoch: 6| Step: 10
Training loss: 0.3949730694293976
Validation loss: 2.143909454345703

Epoch: 6| Step: 11
Training loss: 0.5242711901664734
Validation loss: 2.135934591293335

Epoch: 6| Step: 12
Training loss: 0.698055624961853
Validation loss: 2.153250257174174

Epoch: 6| Step: 13
Training loss: 0.28326237201690674
Validation loss: 2.21522855758667

Epoch: 373| Step: 0
Training loss: 0.5301506519317627
Validation loss: 2.2124411861101785

Epoch: 6| Step: 1
Training loss: 0.3004838824272156
Validation loss: 2.1922101974487305

Epoch: 6| Step: 2
Training loss: 0.2438858151435852
Validation loss: 2.1890127062797546

Epoch: 6| Step: 3
Training loss: 0.4906308054924011
Validation loss: 2.2143569191296897

Epoch: 6| Step: 4
Training loss: 0.4659033715724945
Validation loss: 2.1736877163251243

Epoch: 6| Step: 5
Training loss: 0.2986820340156555
Validation loss: 2.16891747713089

Epoch: 6| Step: 6
Training loss: 1.0006940364837646
Validation loss: 2.1329304377237954

Epoch: 6| Step: 7
Training loss: 0.5380034446716309
Validation loss: 2.1673003832499185

Epoch: 6| Step: 8
Training loss: 0.4056205451488495
Validation loss: 2.18036154905955

Epoch: 6| Step: 9
Training loss: 0.49236786365509033
Validation loss: 2.1647274096806846

Epoch: 6| Step: 10
Training loss: 0.28859439492225647
Validation loss: 2.135808308919271

Epoch: 6| Step: 11
Training loss: 0.3260160982608795
Validation loss: 2.15431547164917

Epoch: 6| Step: 12
Training loss: 0.5047105550765991
Validation loss: 2.1816439827283225

Epoch: 6| Step: 13
Training loss: 0.44094792008399963
Validation loss: 2.2353522380193076

Epoch: 374| Step: 0
Training loss: 0.2522556781768799
Validation loss: 2.2130215764045715

Epoch: 6| Step: 1
Training loss: 0.785585880279541
Validation loss: 2.2269038558006287

Epoch: 6| Step: 2
Training loss: 0.44867706298828125
Validation loss: 2.1820289492607117

Epoch: 6| Step: 3
Training loss: 0.5074303150177002
Validation loss: 2.1821456948916116

Epoch: 6| Step: 4
Training loss: 0.7593916058540344
Validation loss: 2.165941596031189

Epoch: 6| Step: 5
Training loss: 0.23020599782466888
Validation loss: 2.1582971811294556

Epoch: 6| Step: 6
Training loss: 0.21785996854305267
Validation loss: 2.159705718358358

Epoch: 6| Step: 7
Training loss: 0.535552978515625
Validation loss: 2.1606393655141196

Epoch: 6| Step: 8
Training loss: 0.668979287147522
Validation loss: 2.1822503407796225

Epoch: 6| Step: 9
Training loss: 0.18426546454429626
Validation loss: 2.1728022495905557

Epoch: 6| Step: 10
Training loss: 0.28045105934143066
Validation loss: 2.1843419075012207

Epoch: 6| Step: 11
Training loss: 0.4210970401763916
Validation loss: 2.108067731062571

Epoch: 6| Step: 12
Training loss: 0.28353095054626465
Validation loss: 2.118455092112223

Epoch: 6| Step: 13
Training loss: 0.5146347284317017
Validation loss: 2.1589534878730774

Epoch: 375| Step: 0
Training loss: 0.3564699590206146
Validation loss: 2.089008351167043

Epoch: 6| Step: 1
Training loss: 0.5266006588935852
Validation loss: 2.142729560534159

Epoch: 6| Step: 2
Training loss: 0.461229145526886
Validation loss: 2.1623565355936685

Epoch: 6| Step: 3
Training loss: 0.7086336612701416
Validation loss: 2.1402260065078735

Epoch: 6| Step: 4
Training loss: 0.22719205915927887
Validation loss: 2.194046974182129

Epoch: 6| Step: 5
Training loss: 0.3615415096282959
Validation loss: 2.1476476391156516

Epoch: 6| Step: 6
Training loss: 0.5831679105758667
Validation loss: 2.1593377590179443

Epoch: 6| Step: 7
Training loss: 0.4150520861148834
Validation loss: 2.153632640838623

Epoch: 6| Step: 8
Training loss: 0.290230929851532
Validation loss: 2.1797173221906028

Epoch: 6| Step: 9
Training loss: 0.26172617077827454
Validation loss: 2.1483571330706277

Epoch: 6| Step: 10
Training loss: 0.49704205989837646
Validation loss: 2.156736413637797

Epoch: 6| Step: 11
Training loss: 0.5695563554763794
Validation loss: 2.1459432442982993

Epoch: 6| Step: 12
Training loss: 0.8554486036300659
Validation loss: 2.154581348101298

Epoch: 6| Step: 13
Training loss: 0.29298439621925354
Validation loss: 2.1652204394340515

Epoch: 376| Step: 0
Training loss: 0.4175277352333069
Validation loss: 2.2103573282559714

Epoch: 6| Step: 1
Training loss: 0.5262503623962402
Validation loss: 2.147511124610901

Epoch: 6| Step: 2
Training loss: 0.4663172960281372
Validation loss: 2.2112524708112082

Epoch: 6| Step: 3
Training loss: 0.7260664701461792
Validation loss: 2.1759398380915322

Epoch: 6| Step: 4
Training loss: 0.23762455582618713
Validation loss: 2.1397506992022195

Epoch: 6| Step: 5
Training loss: 0.2967234253883362
Validation loss: 2.2068393230438232

Epoch: 6| Step: 6
Training loss: 0.35821476578712463
Validation loss: 2.1502568324406943

Epoch: 6| Step: 7
Training loss: 0.30219709873199463
Validation loss: 2.1194977164268494

Epoch: 6| Step: 8
Training loss: 0.5114835500717163
Validation loss: 2.143966277440389

Epoch: 6| Step: 9
Training loss: 0.7572699785232544
Validation loss: 2.1496945222218833

Epoch: 6| Step: 10
Training loss: 0.8422373533248901
Validation loss: 2.1288857460021973

Epoch: 6| Step: 11
Training loss: 1.22455894947052
Validation loss: 2.1590095162391663

Epoch: 6| Step: 12
Training loss: 0.26932385563850403
Validation loss: 2.175426105658213

Epoch: 6| Step: 13
Training loss: 0.29682838916778564
Validation loss: 2.1963536938031516

Epoch: 377| Step: 0
Training loss: 0.8062931299209595
Validation loss: 2.1031091014544168

Epoch: 6| Step: 1
Training loss: 0.4310929477214813
Validation loss: 2.1752799352010093

Epoch: 6| Step: 2
Training loss: 0.23867294192314148
Validation loss: 2.17580113808314

Epoch: 6| Step: 3
Training loss: 0.37548887729644775
Validation loss: 2.2163532376289368

Epoch: 6| Step: 4
Training loss: 0.31060969829559326
Validation loss: 2.130489687124888

Epoch: 6| Step: 5
Training loss: 0.5876733660697937
Validation loss: 2.1162780125935874

Epoch: 6| Step: 6
Training loss: 0.6441079378128052
Validation loss: 2.1264180342356362

Epoch: 6| Step: 7
Training loss: 0.4087265133857727
Validation loss: 2.1587541103363037

Epoch: 6| Step: 8
Training loss: 0.4343218207359314
Validation loss: 2.129451354344686

Epoch: 6| Step: 9
Training loss: 0.3159576654434204
Validation loss: 2.1620096564292908

Epoch: 6| Step: 10
Training loss: 0.7640578150749207
Validation loss: 2.1453133821487427

Epoch: 6| Step: 11
Training loss: 0.47719866037368774
Validation loss: 2.1627219915390015

Epoch: 6| Step: 12
Training loss: 0.2701205611228943
Validation loss: 2.172982116540273

Epoch: 6| Step: 13
Training loss: 0.27241039276123047
Validation loss: 2.173900862534841

Epoch: 378| Step: 0
Training loss: 0.4152040481567383
Validation loss: 2.195721705754598

Epoch: 6| Step: 1
Training loss: 0.3925972282886505
Validation loss: 2.199354807535807

Epoch: 6| Step: 2
Training loss: 0.38598573207855225
Validation loss: 2.105752944946289

Epoch: 6| Step: 3
Training loss: 0.629679799079895
Validation loss: 2.1896971662839255

Epoch: 6| Step: 4
Training loss: 0.2559215724468231
Validation loss: 2.1685596307118735

Epoch: 6| Step: 5
Training loss: 0.3099847435951233
Validation loss: 2.123328228791555

Epoch: 6| Step: 6
Training loss: 0.5117248892784119
Validation loss: 2.1039716005325317

Epoch: 6| Step: 7
Training loss: 0.1663234680891037
Validation loss: 2.1613320310910544

Epoch: 6| Step: 8
Training loss: 0.3188650608062744
Validation loss: 2.185729682445526

Epoch: 6| Step: 9
Training loss: 1.0768325328826904
Validation loss: 2.196988344192505

Epoch: 6| Step: 10
Training loss: 0.40539616346359253
Validation loss: 2.122189203898112

Epoch: 6| Step: 11
Training loss: 0.5776439905166626
Validation loss: 2.1404102643330893

Epoch: 6| Step: 12
Training loss: 0.324546217918396
Validation loss: 2.1722599466641745

Epoch: 6| Step: 13
Training loss: 0.33309152722358704
Validation loss: 2.196797808011373

Epoch: 379| Step: 0
Training loss: 0.1856662631034851
Validation loss: 2.1552348931630454

Epoch: 6| Step: 1
Training loss: 0.4563124179840088
Validation loss: 2.2334805925687156

Epoch: 6| Step: 2
Training loss: 0.5524553060531616
Validation loss: 2.211398204167684

Epoch: 6| Step: 3
Training loss: 1.006546974182129
Validation loss: 2.254846215248108

Epoch: 6| Step: 4
Training loss: 0.2634061276912689
Validation loss: 2.2168269753456116

Epoch: 6| Step: 5
Training loss: 0.472084105014801
Validation loss: 2.2603952487309775

Epoch: 6| Step: 6
Training loss: 0.40629392862319946
Validation loss: 2.1251567006111145

Epoch: 6| Step: 7
Training loss: 0.42191576957702637
Validation loss: 2.1560237407684326

Epoch: 6| Step: 8
Training loss: 0.29723408818244934
Validation loss: 2.1946493784586587

Epoch: 6| Step: 9
Training loss: 0.48160624504089355
Validation loss: 2.180783768494924

Epoch: 6| Step: 10
Training loss: 0.4310569167137146
Validation loss: 2.186578929424286

Epoch: 6| Step: 11
Training loss: 0.4376083016395569
Validation loss: 2.1383379896481833

Epoch: 6| Step: 12
Training loss: 0.6096903681755066
Validation loss: 2.1895819107691445

Epoch: 6| Step: 13
Training loss: 0.850605845451355
Validation loss: 2.164975941181183

Epoch: 380| Step: 0
Training loss: 0.37963420152664185
Validation loss: 2.138965904712677

Epoch: 6| Step: 1
Training loss: 0.39961889386177063
Validation loss: 2.19545445839564

Epoch: 6| Step: 2
Training loss: 0.16959689557552338
Validation loss: 2.1446619431177774

Epoch: 6| Step: 3
Training loss: 0.4148845970630646
Validation loss: 2.220535933971405

Epoch: 6| Step: 4
Training loss: 0.4268816411495209
Validation loss: 2.1547244787216187

Epoch: 6| Step: 5
Training loss: 0.6581737995147705
Validation loss: 2.179871678352356

Epoch: 6| Step: 6
Training loss: 0.480923593044281
Validation loss: 2.1963147719701133

Epoch: 6| Step: 7
Training loss: 0.45459866523742676
Validation loss: 2.1666592558224997

Epoch: 6| Step: 8
Training loss: 0.5972294807434082
Validation loss: 2.1334183613459268

Epoch: 6| Step: 9
Training loss: 0.2934502363204956
Validation loss: 2.172450224558512

Epoch: 6| Step: 10
Training loss: 0.5054773092269897
Validation loss: 2.17067289352417

Epoch: 6| Step: 11
Training loss: 0.34885743260383606
Validation loss: 2.213151236375173

Epoch: 6| Step: 12
Training loss: 0.6798396110534668
Validation loss: 2.21249258518219

Epoch: 6| Step: 13
Training loss: 0.36172664165496826
Validation loss: 2.1459006865819297

Epoch: 381| Step: 0
Training loss: 0.5767995119094849
Validation loss: 2.186372935771942

Epoch: 6| Step: 1
Training loss: 0.28926438093185425
Validation loss: 2.175985852877299

Epoch: 6| Step: 2
Training loss: 0.3477391004562378
Validation loss: 2.173176030317942

Epoch: 6| Step: 3
Training loss: 0.33982372283935547
Validation loss: 2.17684676249822

Epoch: 6| Step: 4
Training loss: 0.3780209422111511
Validation loss: 2.2064318458239236

Epoch: 6| Step: 5
Training loss: 0.4900142252445221
Validation loss: 2.1624050736427307

Epoch: 6| Step: 6
Training loss: 0.7302737236022949
Validation loss: 2.1524866024653115

Epoch: 6| Step: 7
Training loss: 0.34333133697509766
Validation loss: 2.1044743259747825

Epoch: 6| Step: 8
Training loss: 0.5675550103187561
Validation loss: 2.1843012968699136

Epoch: 6| Step: 9
Training loss: 0.4404471516609192
Validation loss: 2.2106811006863913

Epoch: 6| Step: 10
Training loss: 0.2653343081474304
Validation loss: 2.1273430585861206

Epoch: 6| Step: 11
Training loss: 0.32287442684173584
Validation loss: 2.201331158479055

Epoch: 6| Step: 12
Training loss: 0.7566686868667603
Validation loss: 2.2112767497698465

Epoch: 6| Step: 13
Training loss: 0.27187579870224
Validation loss: 2.1610755920410156

Epoch: 382| Step: 0
Training loss: 0.36079293489456177
Validation loss: 2.1238555113474527

Epoch: 6| Step: 1
Training loss: 0.2692822813987732
Validation loss: 2.1533865531285605

Epoch: 6| Step: 2
Training loss: 0.3564454913139343
Validation loss: 2.1385589241981506

Epoch: 6| Step: 3
Training loss: 0.567625880241394
Validation loss: 2.148675541083018

Epoch: 6| Step: 4
Training loss: 0.6897686719894409
Validation loss: 2.115545948346456

Epoch: 6| Step: 5
Training loss: 0.49239659309387207
Validation loss: 2.1819157203038535

Epoch: 6| Step: 6
Training loss: 0.3011866807937622
Validation loss: 2.1521294116973877

Epoch: 6| Step: 7
Training loss: 0.7861800789833069
Validation loss: 2.204436202843984

Epoch: 6| Step: 8
Training loss: 0.5388273596763611
Validation loss: 2.124585211277008

Epoch: 6| Step: 9
Training loss: 0.6322057247161865
Validation loss: 2.1777451038360596

Epoch: 6| Step: 10
Training loss: 0.35910284519195557
Validation loss: 2.1773978074391684

Epoch: 6| Step: 11
Training loss: 0.3794495463371277
Validation loss: 2.1675260861714682

Epoch: 6| Step: 12
Training loss: 0.2518542408943176
Validation loss: 2.189101497332255

Epoch: 6| Step: 13
Training loss: 0.27218928933143616
Validation loss: 2.1417393883069358

Epoch: 383| Step: 0
Training loss: 0.8863857984542847
Validation loss: 2.197786351044973

Epoch: 6| Step: 1
Training loss: 0.372625470161438
Validation loss: 2.161610205968221

Epoch: 6| Step: 2
Training loss: 0.31824398040771484
Validation loss: 2.2335485418637595

Epoch: 6| Step: 3
Training loss: 0.2908715605735779
Validation loss: 2.1545555194218955

Epoch: 6| Step: 4
Training loss: 0.2987478971481323
Validation loss: 2.164919992287954

Epoch: 6| Step: 5
Training loss: 0.6138869524002075
Validation loss: 2.1877962152163186

Epoch: 6| Step: 6
Training loss: 0.34649986028671265
Validation loss: 2.2210713227589927

Epoch: 6| Step: 7
Training loss: 0.429638534784317
Validation loss: 2.2003480990727744

Epoch: 6| Step: 8
Training loss: 0.48883771896362305
Validation loss: 2.2030828396479287

Epoch: 6| Step: 9
Training loss: 0.6074260473251343
Validation loss: 2.1582959294319153

Epoch: 6| Step: 10
Training loss: 0.24586325883865356
Validation loss: 2.184464236100515

Epoch: 6| Step: 11
Training loss: 0.19629305601119995
Validation loss: 2.1653329730033875

Epoch: 6| Step: 12
Training loss: 0.7057861089706421
Validation loss: 2.1692997217178345

Epoch: 6| Step: 13
Training loss: 0.3666854202747345
Validation loss: 2.12485937277476

Epoch: 384| Step: 0
Training loss: 0.5588780641555786
Validation loss: 2.2267584204673767

Epoch: 6| Step: 1
Training loss: 0.3799465298652649
Validation loss: 2.1224823792775473

Epoch: 6| Step: 2
Training loss: 0.6242760419845581
Validation loss: 2.107822378476461

Epoch: 6| Step: 3
Training loss: 0.33937445282936096
Validation loss: 2.16267466545105

Epoch: 6| Step: 4
Training loss: 0.3958386182785034
Validation loss: 2.214196960131327

Epoch: 6| Step: 5
Training loss: 0.2867375612258911
Validation loss: 2.2050941785176597

Epoch: 6| Step: 6
Training loss: 0.3209632635116577
Validation loss: 2.164982557296753

Epoch: 6| Step: 7
Training loss: 0.8396207094192505
Validation loss: 2.184246997038523

Epoch: 6| Step: 8
Training loss: 0.23302678763866425
Validation loss: 2.110323210557302

Epoch: 6| Step: 9
Training loss: 0.5444148778915405
Validation loss: 2.1449480255444846

Epoch: 6| Step: 10
Training loss: 0.4088192880153656
Validation loss: 2.1281728744506836

Epoch: 6| Step: 11
Training loss: 0.7756367325782776
Validation loss: 2.1598178148269653

Epoch: 6| Step: 12
Training loss: 0.29406869411468506
Validation loss: 2.0951008399327598

Epoch: 6| Step: 13
Training loss: 0.16046397387981415
Validation loss: 2.1246229807535806

Epoch: 385| Step: 0
Training loss: 0.532612681388855
Validation loss: 2.0941325624783835

Epoch: 6| Step: 1
Training loss: 0.666475236415863
Validation loss: 2.1637659271558127

Epoch: 6| Step: 2
Training loss: 0.20975233614444733
Validation loss: 2.120072603225708

Epoch: 6| Step: 3
Training loss: 0.24686911702156067
Validation loss: 2.156405806541443

Epoch: 6| Step: 4
Training loss: 0.3188433051109314
Validation loss: 2.117521087328593

Epoch: 6| Step: 5
Training loss: 0.23174312710762024
Validation loss: 2.146358529726664

Epoch: 6| Step: 6
Training loss: 0.23898039758205414
Validation loss: 2.155856668949127

Epoch: 6| Step: 7
Training loss: 0.8446805477142334
Validation loss: 2.1229241291681924

Epoch: 6| Step: 8
Training loss: 0.28699570894241333
Validation loss: 2.116791288057963

Epoch: 6| Step: 9
Training loss: 0.5197307467460632
Validation loss: 2.1690306663513184

Epoch: 6| Step: 10
Training loss: 0.6744236946105957
Validation loss: 2.1714516480763755

Epoch: 6| Step: 11
Training loss: 0.46334677934646606
Validation loss: 2.185397466023763

Epoch: 6| Step: 12
Training loss: 0.34941911697387695
Validation loss: 2.147378663221995

Epoch: 6| Step: 13
Training loss: 0.5702952146530151
Validation loss: 2.178581873575846

Epoch: 386| Step: 0
Training loss: 0.3156728446483612
Validation loss: 2.17943412065506

Epoch: 6| Step: 1
Training loss: 0.6338164806365967
Validation loss: 2.192759891351064

Epoch: 6| Step: 2
Training loss: 0.3877391815185547
Validation loss: 2.203045964241028

Epoch: 6| Step: 3
Training loss: 0.21164992451667786
Validation loss: 2.127533753712972

Epoch: 6| Step: 4
Training loss: 0.5246402621269226
Validation loss: 2.1897704203923545

Epoch: 6| Step: 5
Training loss: 0.9670056104660034
Validation loss: 2.210017422835032

Epoch: 6| Step: 6
Training loss: 0.21522481739521027
Validation loss: 2.1564473112424216

Epoch: 6| Step: 7
Training loss: 0.46491074562072754
Validation loss: 2.1526091496149697

Epoch: 6| Step: 8
Training loss: 0.4702865481376648
Validation loss: 2.1449819604555764

Epoch: 6| Step: 9
Training loss: 0.4741045832633972
Validation loss: 2.169315993785858

Epoch: 6| Step: 10
Training loss: 0.3579410910606384
Validation loss: 2.1623289585113525

Epoch: 6| Step: 11
Training loss: 0.3319827616214752
Validation loss: 2.1544889012972512

Epoch: 6| Step: 12
Training loss: 0.24806681275367737
Validation loss: 2.140950540701548

Epoch: 6| Step: 13
Training loss: 0.3727926015853882
Validation loss: 2.172997852166494

Epoch: 387| Step: 0
Training loss: 0.7426226139068604
Validation loss: 2.150543987751007

Epoch: 6| Step: 1
Training loss: 0.35399091243743896
Validation loss: 2.118284980456034

Epoch: 6| Step: 2
Training loss: 0.3500295877456665
Validation loss: 2.1747700373331704

Epoch: 6| Step: 3
Training loss: 0.3957374691963196
Validation loss: 2.1482512950897217

Epoch: 6| Step: 4
Training loss: 0.5629482269287109
Validation loss: 2.1255852381388345

Epoch: 6| Step: 5
Training loss: 0.3097664713859558
Validation loss: 2.154013137022654

Epoch: 6| Step: 6
Training loss: 0.19891846179962158
Validation loss: 2.1543625593185425

Epoch: 6| Step: 7
Training loss: 0.25027894973754883
Validation loss: 2.1368995904922485

Epoch: 6| Step: 8
Training loss: 0.398050457239151
Validation loss: 2.1117027203241983

Epoch: 6| Step: 9
Training loss: 0.33798831701278687
Validation loss: 2.1566945711771646

Epoch: 6| Step: 10
Training loss: 0.3613826632499695
Validation loss: 2.099212944507599

Epoch: 6| Step: 11
Training loss: 0.5815008878707886
Validation loss: 2.156123777230581

Epoch: 6| Step: 12
Training loss: 0.8181959390640259
Validation loss: 2.190178553263346

Epoch: 6| Step: 13
Training loss: 0.21439193189144135
Validation loss: 2.156598170598348

Epoch: 388| Step: 0
Training loss: 0.3435041904449463
Validation loss: 2.1053929328918457

Epoch: 6| Step: 1
Training loss: 0.4408106803894043
Validation loss: 2.161178191502889

Epoch: 6| Step: 2
Training loss: 0.4264909029006958
Validation loss: 2.150070230166117

Epoch: 6| Step: 3
Training loss: 0.2912277579307556
Validation loss: 2.1393468777338662

Epoch: 6| Step: 4
Training loss: 0.5800421833992004
Validation loss: 2.1307909886042276

Epoch: 6| Step: 5
Training loss: 0.4947447180747986
Validation loss: 2.166495442390442

Epoch: 6| Step: 6
Training loss: 0.5104468464851379
Validation loss: 2.1441258986790976

Epoch: 6| Step: 7
Training loss: 0.4447918236255646
Validation loss: 2.121444741884867

Epoch: 6| Step: 8
Training loss: 0.2803584933280945
Validation loss: 2.1624415715535483

Epoch: 6| Step: 9
Training loss: 0.4311124086380005
Validation loss: 2.114578366279602

Epoch: 6| Step: 10
Training loss: 0.5486783385276794
Validation loss: 2.1443970799446106

Epoch: 6| Step: 11
Training loss: 0.24435366690158844
Validation loss: 2.193472425142924

Epoch: 6| Step: 12
Training loss: 0.2225293517112732
Validation loss: 2.166027049223582

Epoch: 6| Step: 13
Training loss: 0.6410609483718872
Validation loss: 2.162627398967743

Epoch: 389| Step: 0
Training loss: 0.32857149839401245
Validation loss: 2.1513726512591043

Epoch: 6| Step: 1
Training loss: 0.4438422620296478
Validation loss: 2.1390324433644614

Epoch: 6| Step: 2
Training loss: 0.5193684101104736
Validation loss: 2.160112500190735

Epoch: 6| Step: 3
Training loss: 0.3839540481567383
Validation loss: 2.1993857820828757

Epoch: 6| Step: 4
Training loss: 0.2671024799346924
Validation loss: 2.1565569639205933

Epoch: 6| Step: 5
Training loss: 0.45303916931152344
Validation loss: 2.1479469935099282

Epoch: 6| Step: 6
Training loss: 0.4270451068878174
Validation loss: 2.1995976765950522

Epoch: 6| Step: 7
Training loss: 0.5097593069076538
Validation loss: 2.103755474090576

Epoch: 6| Step: 8
Training loss: 0.18979555368423462
Validation loss: 2.117435316244761

Epoch: 6| Step: 9
Training loss: 0.8693727850914001
Validation loss: 2.194542557001114

Epoch: 6| Step: 10
Training loss: 0.3602699041366577
Validation loss: 2.1811920404434204

Epoch: 6| Step: 11
Training loss: 0.3818775415420532
Validation loss: 2.223414738972982

Epoch: 6| Step: 12
Training loss: 0.799053430557251
Validation loss: 2.25651482741038

Epoch: 6| Step: 13
Training loss: 0.7838209867477417
Validation loss: 2.1962788899739585

Epoch: 390| Step: 0
Training loss: 0.37502121925354004
Validation loss: 2.2209107478459678

Epoch: 6| Step: 1
Training loss: 0.29133015871047974
Validation loss: 2.1680532693862915

Epoch: 6| Step: 2
Training loss: 0.395102322101593
Validation loss: 2.2222942113876343

Epoch: 6| Step: 3
Training loss: 0.3954942226409912
Validation loss: 2.163137992223104

Epoch: 6| Step: 4
Training loss: 0.9093103408813477
Validation loss: 2.1604193846384683

Epoch: 6| Step: 5
Training loss: 0.3816024363040924
Validation loss: 2.1596454977989197

Epoch: 6| Step: 6
Training loss: 0.25797736644744873
Validation loss: 2.145276586214701

Epoch: 6| Step: 7
Training loss: 0.34920400381088257
Validation loss: 2.149879256884257

Epoch: 6| Step: 8
Training loss: 0.6563843488693237
Validation loss: 2.145612140496572

Epoch: 6| Step: 9
Training loss: 0.5594067573547363
Validation loss: 2.151281714439392

Epoch: 6| Step: 10
Training loss: 0.3767964839935303
Validation loss: 2.218284765879313

Epoch: 6| Step: 11
Training loss: 0.5850154757499695
Validation loss: 2.198997716108958

Epoch: 6| Step: 12
Training loss: 0.7258062362670898
Validation loss: 2.17011559009552

Epoch: 6| Step: 13
Training loss: 0.3052375018596649
Validation loss: 2.1607959866523743

Epoch: 391| Step: 0
Training loss: 0.43009790778160095
Validation loss: 2.1885860164960227

Epoch: 6| Step: 1
Training loss: 0.46446603536605835
Validation loss: 2.1643189787864685

Epoch: 6| Step: 2
Training loss: 0.37374430894851685
Validation loss: 2.179004351298014

Epoch: 6| Step: 3
Training loss: 0.38376563787460327
Validation loss: 2.1630391677220664

Epoch: 6| Step: 4
Training loss: 0.41546541452407837
Validation loss: 2.149621526400248

Epoch: 6| Step: 5
Training loss: 0.43880632519721985
Validation loss: 2.171985367933909

Epoch: 6| Step: 6
Training loss: 0.5300708413124084
Validation loss: 2.156714995702108

Epoch: 6| Step: 7
Training loss: 0.22895170748233795
Validation loss: 2.155003309249878

Epoch: 6| Step: 8
Training loss: 0.47186213731765747
Validation loss: 2.1896750728289285

Epoch: 6| Step: 9
Training loss: 1.1991114616394043
Validation loss: 2.201878627141317

Epoch: 6| Step: 10
Training loss: 0.27261197566986084
Validation loss: 2.158722400665283

Epoch: 6| Step: 11
Training loss: 0.3250850439071655
Validation loss: 2.1388529539108276

Epoch: 6| Step: 12
Training loss: 0.2953018546104431
Validation loss: 2.1535086234410605

Epoch: 6| Step: 13
Training loss: 0.2105925977230072
Validation loss: 2.195883631706238

Epoch: 392| Step: 0
Training loss: 0.5622603893280029
Validation loss: 2.1585523088773093

Epoch: 6| Step: 1
Training loss: 0.4109494984149933
Validation loss: 2.142703413963318

Epoch: 6| Step: 2
Training loss: 0.32929596304893494
Validation loss: 2.1556247075398765

Epoch: 6| Step: 3
Training loss: 0.4116678237915039
Validation loss: 2.1770722468694053

Epoch: 6| Step: 4
Training loss: 0.22204770147800446
Validation loss: 2.1909236907958984

Epoch: 6| Step: 5
Training loss: 0.6878005266189575
Validation loss: 2.2188150882720947

Epoch: 6| Step: 6
Training loss: 0.4891359508037567
Validation loss: 2.1987350583076477

Epoch: 6| Step: 7
Training loss: 0.355540931224823
Validation loss: 2.1821473836898804

Epoch: 6| Step: 8
Training loss: 0.5335766673088074
Validation loss: 2.1873935063680015

Epoch: 6| Step: 9
Training loss: 0.353417307138443
Validation loss: 2.1702526410420737

Epoch: 6| Step: 10
Training loss: 0.6430370807647705
Validation loss: 2.1562806169191995

Epoch: 6| Step: 11
Training loss: 0.20145153999328613
Validation loss: 2.1612417499224343

Epoch: 6| Step: 12
Training loss: 0.6011574268341064
Validation loss: 2.114370286464691

Epoch: 6| Step: 13
Training loss: 0.7270796895027161
Validation loss: 2.1829974253972373

Epoch: 393| Step: 0
Training loss: 0.6087526082992554
Validation loss: 2.1526538530985513

Epoch: 6| Step: 1
Training loss: 0.7043346166610718
Validation loss: 2.1641090710957847

Epoch: 6| Step: 2
Training loss: 0.34702640771865845
Validation loss: 2.2169723510742188

Epoch: 6| Step: 3
Training loss: 0.24932631850242615
Validation loss: 2.1498641769091287

Epoch: 6| Step: 4
Training loss: 0.4891941547393799
Validation loss: 2.1611383159955344

Epoch: 6| Step: 5
Training loss: 0.6788456439971924
Validation loss: 2.21617458264033

Epoch: 6| Step: 6
Training loss: 0.3957338333129883
Validation loss: 2.2244035402933755

Epoch: 6| Step: 7
Training loss: 0.43694740533828735
Validation loss: 2.188202699025472

Epoch: 6| Step: 8
Training loss: 0.45305708050727844
Validation loss: 2.2120431860287986

Epoch: 6| Step: 9
Training loss: 0.16567087173461914
Validation loss: 2.1576019128163657

Epoch: 6| Step: 10
Training loss: 0.40832918882369995
Validation loss: 2.1677831013997397

Epoch: 6| Step: 11
Training loss: 0.5026295185089111
Validation loss: 2.1368945042292276

Epoch: 6| Step: 12
Training loss: 0.2521602511405945
Validation loss: 2.1473195552825928

Epoch: 6| Step: 13
Training loss: 0.6317452192306519
Validation loss: 2.193265974521637

Epoch: 394| Step: 0
Training loss: 0.32396042346954346
Validation loss: 2.1621740261713662

Epoch: 6| Step: 1
Training loss: 0.6483679413795471
Validation loss: 2.1794140736262

Epoch: 6| Step: 2
Training loss: 0.5653440356254578
Validation loss: 2.213371455669403

Epoch: 6| Step: 3
Training loss: 0.7100024223327637
Validation loss: 2.1483606894810996

Epoch: 6| Step: 4
Training loss: 0.7899242043495178
Validation loss: 2.1261000831921897

Epoch: 6| Step: 5
Training loss: 0.3211883306503296
Validation loss: 2.1602566043535867

Epoch: 6| Step: 6
Training loss: 0.3122243881225586
Validation loss: 2.154261827468872

Epoch: 6| Step: 7
Training loss: 0.35883066058158875
Validation loss: 2.1585559050242105

Epoch: 6| Step: 8
Training loss: 0.6600819230079651
Validation loss: 2.211535394191742

Epoch: 6| Step: 9
Training loss: 0.43022871017456055
Validation loss: 2.152430752913157

Epoch: 6| Step: 10
Training loss: 0.5140734314918518
Validation loss: 2.186088959376017

Epoch: 6| Step: 11
Training loss: 0.48960310220718384
Validation loss: 2.1805349389712014

Epoch: 6| Step: 12
Training loss: 0.2514338493347168
Validation loss: 2.1867940028508506

Epoch: 6| Step: 13
Training loss: 0.38940948247909546
Validation loss: 2.2005775372187295

Epoch: 395| Step: 0
Training loss: 0.7606166005134583
Validation loss: 2.1851078867912292

Epoch: 6| Step: 1
Training loss: 0.37614187598228455
Validation loss: 2.2169034282366433

Epoch: 6| Step: 2
Training loss: 0.41484498977661133
Validation loss: 2.226611236731211

Epoch: 6| Step: 3
Training loss: 0.37991493940353394
Validation loss: 2.1911420623461404

Epoch: 6| Step: 4
Training loss: 0.2784634828567505
Validation loss: 2.226585328578949

Epoch: 6| Step: 5
Training loss: 0.8496148586273193
Validation loss: 2.1723623871803284

Epoch: 6| Step: 6
Training loss: 0.33044013381004333
Validation loss: 2.1525673468907676

Epoch: 6| Step: 7
Training loss: 0.2310648262500763
Validation loss: 2.1423981388409934

Epoch: 6| Step: 8
Training loss: 0.47712504863739014
Validation loss: 2.1644241213798523

Epoch: 6| Step: 9
Training loss: 0.6524441242218018
Validation loss: 2.1312297185262046

Epoch: 6| Step: 10
Training loss: 0.36853528022766113
Validation loss: 2.121366580327352

Epoch: 6| Step: 11
Training loss: 0.44387778639793396
Validation loss: 2.1552922328313193

Epoch: 6| Step: 12
Training loss: 0.4919484853744507
Validation loss: 2.1938994328180947

Epoch: 6| Step: 13
Training loss: 0.40226930379867554
Validation loss: 2.1357285380363464

Epoch: 396| Step: 0
Training loss: 0.2287309169769287
Validation loss: 2.181210915247599

Epoch: 6| Step: 1
Training loss: 0.3502865433692932
Validation loss: 2.2311717669169107

Epoch: 6| Step: 2
Training loss: 0.38815104961395264
Validation loss: 2.1861082315444946

Epoch: 6| Step: 3
Training loss: 0.5995470285415649
Validation loss: 2.18205996354421

Epoch: 6| Step: 4
Training loss: 0.36351972818374634
Validation loss: 2.2193955779075623

Epoch: 6| Step: 5
Training loss: 0.4095640182495117
Validation loss: 2.1273065408070884

Epoch: 6| Step: 6
Training loss: 0.40931469202041626
Validation loss: 2.1813915570576987

Epoch: 6| Step: 7
Training loss: 0.4836374521255493
Validation loss: 2.1336503426233926

Epoch: 6| Step: 8
Training loss: 0.9619816541671753
Validation loss: 2.16166615486145

Epoch: 6| Step: 9
Training loss: 0.9108973145484924
Validation loss: 2.2083184520403543

Epoch: 6| Step: 10
Training loss: 0.25911271572113037
Validation loss: 2.152787168820699

Epoch: 6| Step: 11
Training loss: 0.25776296854019165
Validation loss: 2.1694796284039817

Epoch: 6| Step: 12
Training loss: 0.3064284324645996
Validation loss: 2.1629499395688376

Epoch: 6| Step: 13
Training loss: 0.25765663385391235
Validation loss: 2.205097039540609

Epoch: 397| Step: 0
Training loss: 0.3274610936641693
Validation loss: 2.2155776023864746

Epoch: 6| Step: 1
Training loss: 0.481117308139801
Validation loss: 2.243108014265696

Epoch: 6| Step: 2
Training loss: 0.4093194603919983
Validation loss: 2.1842804153760276

Epoch: 6| Step: 3
Training loss: 0.6476399898529053
Validation loss: 2.1803249518076577

Epoch: 6| Step: 4
Training loss: 0.2530110776424408
Validation loss: 2.16918675104777

Epoch: 6| Step: 5
Training loss: 0.40242141485214233
Validation loss: 2.22144607702891

Epoch: 6| Step: 6
Training loss: 0.49691757559776306
Validation loss: 2.165067811806997

Epoch: 6| Step: 7
Training loss: 0.28426146507263184
Validation loss: 2.170459191004435

Epoch: 6| Step: 8
Training loss: 0.44862475991249084
Validation loss: 2.1342230240503945

Epoch: 6| Step: 9
Training loss: 0.3216897249221802
Validation loss: 2.200725277264913

Epoch: 6| Step: 10
Training loss: 0.42259830236434937
Validation loss: 2.1634767055511475

Epoch: 6| Step: 11
Training loss: 0.7534222602844238
Validation loss: 2.210666060447693

Epoch: 6| Step: 12
Training loss: 0.40262120962142944
Validation loss: 2.185973604520162

Epoch: 6| Step: 13
Training loss: 0.16431403160095215
Validation loss: 2.1758234103520713

Epoch: 398| Step: 0
Training loss: 0.31024879217147827
Validation loss: 2.1658587654431662

Epoch: 6| Step: 1
Training loss: 0.6849006414413452
Validation loss: 2.194093624750773

Epoch: 6| Step: 2
Training loss: 0.3425125777721405
Validation loss: 2.220432718594869

Epoch: 6| Step: 3
Training loss: 0.39428362250328064
Validation loss: 2.1906000773111978

Epoch: 6| Step: 4
Training loss: 0.23303857445716858
Validation loss: 2.155994455019633

Epoch: 6| Step: 5
Training loss: 0.430600106716156
Validation loss: 2.167324701944987

Epoch: 6| Step: 6
Training loss: 0.27741628885269165
Validation loss: 2.1636978586514792

Epoch: 6| Step: 7
Training loss: 0.3212879002094269
Validation loss: 2.168679893016815

Epoch: 6| Step: 8
Training loss: 0.3529285192489624
Validation loss: 2.154723346233368

Epoch: 6| Step: 9
Training loss: 0.9350540637969971
Validation loss: 2.1916836897532144

Epoch: 6| Step: 10
Training loss: 0.4341183006763458
Validation loss: 2.158155878384908

Epoch: 6| Step: 11
Training loss: 0.5357033610343933
Validation loss: 2.142633020877838

Epoch: 6| Step: 12
Training loss: 0.2534390389919281
Validation loss: 2.163692315419515

Epoch: 6| Step: 13
Training loss: 0.4868169128894806
Validation loss: 2.1462921698888144

Epoch: 399| Step: 0
Training loss: 0.25252097845077515
Validation loss: 2.1140405337015786

Epoch: 6| Step: 1
Training loss: 0.8335977792739868
Validation loss: 2.230442782243093

Epoch: 6| Step: 2
Training loss: 0.628974974155426
Validation loss: 2.145773768424988

Epoch: 6| Step: 3
Training loss: 0.244145929813385
Validation loss: 2.1641076803207397

Epoch: 6| Step: 4
Training loss: 0.5267452001571655
Validation loss: 2.1399663289388022

Epoch: 6| Step: 5
Training loss: 0.679561197757721
Validation loss: 2.1284919381141663

Epoch: 6| Step: 6
Training loss: 0.22564101219177246
Validation loss: 2.1491172711054483

Epoch: 6| Step: 7
Training loss: 0.29827696084976196
Validation loss: 2.141321043173472

Epoch: 6| Step: 8
Training loss: 0.3042723536491394
Validation loss: 2.1609665751457214

Epoch: 6| Step: 9
Training loss: 0.31818950176239014
Validation loss: 2.1602194706598916

Epoch: 6| Step: 10
Training loss: 0.35649174451828003
Validation loss: 2.15851100285848

Epoch: 6| Step: 11
Training loss: 0.41253116726875305
Validation loss: 2.168039699395498

Epoch: 6| Step: 12
Training loss: 0.46811118721961975
Validation loss: 2.15461935599645

Epoch: 6| Step: 13
Training loss: 0.5044084191322327
Validation loss: 2.151294747988383

Epoch: 400| Step: 0
Training loss: 0.48146262764930725
Validation loss: 2.181549370288849

Epoch: 6| Step: 1
Training loss: 0.27240192890167236
Validation loss: 2.17567777633667

Epoch: 6| Step: 2
Training loss: 0.9023475050926208
Validation loss: 2.195521116256714

Epoch: 6| Step: 3
Training loss: 0.31747299432754517
Validation loss: 2.1354735096295676

Epoch: 6| Step: 4
Training loss: 0.2997148931026459
Validation loss: 2.1376603643099465

Epoch: 6| Step: 5
Training loss: 0.6269571781158447
Validation loss: 2.1629619201024375

Epoch: 6| Step: 6
Training loss: 0.2763027250766754
Validation loss: 2.19662868976593

Epoch: 6| Step: 7
Training loss: 0.251583456993103
Validation loss: 2.125969191392263

Epoch: 6| Step: 8
Training loss: 0.35749852657318115
Validation loss: 2.204474230607351

Epoch: 6| Step: 9
Training loss: 0.26470112800598145
Validation loss: 2.1399492820103965

Epoch: 6| Step: 10
Training loss: 0.37535396218299866
Validation loss: 2.1547579964001975

Epoch: 6| Step: 11
Training loss: 0.32424262166023254
Validation loss: 2.1900787353515625

Epoch: 6| Step: 12
Training loss: 0.6111596822738647
Validation loss: 2.193035900592804

Epoch: 6| Step: 13
Training loss: 0.4473302662372589
Validation loss: 2.188557823499044

Epoch: 401| Step: 0
Training loss: 0.46953296661376953
Validation loss: 2.173877020676931

Epoch: 6| Step: 1
Training loss: 0.6723650693893433
Validation loss: 2.162776152292887

Epoch: 6| Step: 2
Training loss: 0.550542414188385
Validation loss: 2.186453024546305

Epoch: 6| Step: 3
Training loss: 0.31197190284729004
Validation loss: 2.167677660783132

Epoch: 6| Step: 4
Training loss: 0.5629413723945618
Validation loss: 2.193537871042887

Epoch: 6| Step: 5
Training loss: 0.23879486322402954
Validation loss: 2.2076022227605185

Epoch: 6| Step: 6
Training loss: 0.3509965240955353
Validation loss: 2.190630237261454

Epoch: 6| Step: 7
Training loss: 0.37227344512939453
Validation loss: 2.2121253410975137

Epoch: 6| Step: 8
Training loss: 0.21708516776561737
Validation loss: 2.2124829490979514

Epoch: 6| Step: 9
Training loss: 0.3662234842777252
Validation loss: 2.2131152550379434

Epoch: 6| Step: 10
Training loss: 0.3281702995300293
Validation loss: 2.185419956843058

Epoch: 6| Step: 11
Training loss: 0.511379599571228
Validation loss: 2.1639320850372314

Epoch: 6| Step: 12
Training loss: 0.24179872870445251
Validation loss: 2.156339466571808

Epoch: 6| Step: 13
Training loss: 0.8999848365783691
Validation loss: 2.1897366046905518

Epoch: 402| Step: 0
Training loss: 0.4888874888420105
Validation loss: 2.24099870522817

Epoch: 6| Step: 1
Training loss: 0.40357232093811035
Validation loss: 2.2141576210657754

Epoch: 6| Step: 2
Training loss: 0.47228705883026123
Validation loss: 2.205662171045939

Epoch: 6| Step: 3
Training loss: 0.5516096949577332
Validation loss: 2.1526448925336203

Epoch: 6| Step: 4
Training loss: 0.24395665526390076
Validation loss: 2.2262449860572815

Epoch: 6| Step: 5
Training loss: 0.552304744720459
Validation loss: 2.212795356909434

Epoch: 6| Step: 6
Training loss: 0.2613215446472168
Validation loss: 2.2115662693977356

Epoch: 6| Step: 7
Training loss: 0.3185907006263733
Validation loss: 2.103295008341471

Epoch: 6| Step: 8
Training loss: 0.2410065233707428
Validation loss: 2.181086460749308

Epoch: 6| Step: 9
Training loss: 0.3502568006515503
Validation loss: 2.1594030261039734

Epoch: 6| Step: 10
Training loss: 0.6099045276641846
Validation loss: 2.147921562194824

Epoch: 6| Step: 11
Training loss: 0.6776884198188782
Validation loss: 2.141338845094045

Epoch: 6| Step: 12
Training loss: 0.9120139479637146
Validation loss: 2.124299645423889

Epoch: 6| Step: 13
Training loss: 0.1863846331834793
Validation loss: 2.172083099683126

Epoch: 403| Step: 0
Training loss: 0.258494108915329
Validation loss: 2.1627431909243264

Epoch: 6| Step: 1
Training loss: 0.39388927817344666
Validation loss: 2.1655014753341675

Epoch: 6| Step: 2
Training loss: 0.5529557466506958
Validation loss: 2.2318554719289145

Epoch: 6| Step: 3
Training loss: 0.39958757162094116
Validation loss: 2.188115100065867

Epoch: 6| Step: 4
Training loss: 0.31735485792160034
Validation loss: 2.206255475680033

Epoch: 6| Step: 5
Training loss: 0.3336407542228699
Validation loss: 2.1974110205968223

Epoch: 6| Step: 6
Training loss: 0.2956400513648987
Validation loss: 2.1742886702219644

Epoch: 6| Step: 7
Training loss: 0.15640316903591156
Validation loss: 2.141155501206716

Epoch: 6| Step: 8
Training loss: 0.40611523389816284
Validation loss: 2.2098456422487893

Epoch: 6| Step: 9
Training loss: 0.6243544220924377
Validation loss: 2.157915552457174

Epoch: 6| Step: 10
Training loss: 0.4525381624698639
Validation loss: 2.1644248565038047

Epoch: 6| Step: 11
Training loss: 0.20463448762893677
Validation loss: 2.143899162610372

Epoch: 6| Step: 12
Training loss: 0.34014570713043213
Validation loss: 2.162197550137838

Epoch: 6| Step: 13
Training loss: 0.8211088180541992
Validation loss: 2.153969168663025

Epoch: 404| Step: 0
Training loss: 0.3086240589618683
Validation loss: 2.177877962589264

Epoch: 6| Step: 1
Training loss: 0.5881972908973694
Validation loss: 2.140600105126699

Epoch: 6| Step: 2
Training loss: 0.582243800163269
Validation loss: 2.1142383019129434

Epoch: 6| Step: 3
Training loss: 0.38541561365127563
Validation loss: 2.1274079084396362

Epoch: 6| Step: 4
Training loss: 0.48032146692276
Validation loss: 2.17359725634257

Epoch: 6| Step: 5
Training loss: 0.7652471661567688
Validation loss: 2.1505558490753174

Epoch: 6| Step: 6
Training loss: 0.461090624332428
Validation loss: 2.1278231143951416

Epoch: 6| Step: 7
Training loss: 0.3182728886604309
Validation loss: 2.156177361806234

Epoch: 6| Step: 8
Training loss: 0.38273099064826965
Validation loss: 2.105448087056478

Epoch: 6| Step: 9
Training loss: 0.334812194108963
Validation loss: 2.146286686261495

Epoch: 6| Step: 10
Training loss: 0.4444744288921356
Validation loss: 2.1439336935679116

Epoch: 6| Step: 11
Training loss: 0.28221946954727173
Validation loss: 2.183029075463613

Epoch: 6| Step: 12
Training loss: 0.366260826587677
Validation loss: 2.1658448378245034

Epoch: 6| Step: 13
Training loss: 0.21490269899368286
Validation loss: 2.1915858586629233

Epoch: 405| Step: 0
Training loss: 0.47979220747947693
Validation loss: 2.1585536003112793

Epoch: 6| Step: 1
Training loss: 0.5521460175514221
Validation loss: 2.1368082960446677

Epoch: 6| Step: 2
Training loss: 0.7698529362678528
Validation loss: 2.1233972907066345

Epoch: 6| Step: 3
Training loss: 0.2745235562324524
Validation loss: 2.1636938651402793

Epoch: 6| Step: 4
Training loss: 0.30462419986724854
Validation loss: 2.1528245011965432

Epoch: 6| Step: 5
Training loss: 0.5179176330566406
Validation loss: 2.1349308689435325

Epoch: 6| Step: 6
Training loss: 0.36171334981918335
Validation loss: 2.157317260901133

Epoch: 6| Step: 7
Training loss: 0.3405359983444214
Validation loss: 2.199069400628408

Epoch: 6| Step: 8
Training loss: 0.34176480770111084
Validation loss: 2.2004271745681763

Epoch: 6| Step: 9
Training loss: 0.35697266459465027
Validation loss: 2.1157108147939048

Epoch: 6| Step: 10
Training loss: 0.29089879989624023
Validation loss: 2.1112568974494934

Epoch: 6| Step: 11
Training loss: 0.41708904504776
Validation loss: 2.127257287502289

Epoch: 6| Step: 12
Training loss: 0.4138941168785095
Validation loss: 2.1114813089370728

Epoch: 6| Step: 13
Training loss: 0.5719645023345947
Validation loss: 2.116095542907715

Epoch: 406| Step: 0
Training loss: 0.37419381737709045
Validation loss: 2.1085230708122253

Epoch: 6| Step: 1
Training loss: 0.20655179023742676
Validation loss: 2.163465062777201

Epoch: 6| Step: 2
Training loss: 0.25541600584983826
Validation loss: 2.1531434257825217

Epoch: 6| Step: 3
Training loss: 0.8123377561569214
Validation loss: 2.162184715270996

Epoch: 6| Step: 4
Training loss: 0.40748029947280884
Validation loss: 2.2028483947118125

Epoch: 6| Step: 5
Training loss: 0.4184700548648834
Validation loss: 2.173361122608185

Epoch: 6| Step: 6
Training loss: 0.34746313095092773
Validation loss: 2.143842180569967

Epoch: 6| Step: 7
Training loss: 0.6393107175827026
Validation loss: 2.2093077103296914

Epoch: 6| Step: 8
Training loss: 0.37313032150268555
Validation loss: 2.1662757794062295

Epoch: 6| Step: 9
Training loss: 0.4729917645454407
Validation loss: 2.163309335708618

Epoch: 6| Step: 10
Training loss: 0.3687205910682678
Validation loss: 2.101253847281138

Epoch: 6| Step: 11
Training loss: 0.5239995718002319
Validation loss: 2.177689572175344

Epoch: 6| Step: 12
Training loss: 0.3810804486274719
Validation loss: 2.142987370491028

Epoch: 6| Step: 13
Training loss: 0.326515257358551
Validation loss: 2.176603297392527

Epoch: 407| Step: 0
Training loss: 0.4416714310646057
Validation loss: 2.1237629453341165

Epoch: 6| Step: 1
Training loss: 0.22731299698352814
Validation loss: 2.131524662176768

Epoch: 6| Step: 2
Training loss: 0.42884212732315063
Validation loss: 2.1685959100723267

Epoch: 6| Step: 3
Training loss: 0.23169615864753723
Validation loss: 2.146691918373108

Epoch: 6| Step: 4
Training loss: 0.8029158711433411
Validation loss: 2.128282149632772

Epoch: 6| Step: 5
Training loss: 0.44427913427352905
Validation loss: 2.196041703224182

Epoch: 6| Step: 6
Training loss: 0.240272656083107
Validation loss: 2.166139562924703

Epoch: 6| Step: 7
Training loss: 0.2690262198448181
Validation loss: 2.1575228571891785

Epoch: 6| Step: 8
Training loss: 0.4153991937637329
Validation loss: 2.161845028400421

Epoch: 6| Step: 9
Training loss: 0.715275764465332
Validation loss: 2.1661757429440818

Epoch: 6| Step: 10
Training loss: 0.26545286178588867
Validation loss: 2.155127386252085

Epoch: 6| Step: 11
Training loss: 0.2654859721660614
Validation loss: 2.149580160776774

Epoch: 6| Step: 12
Training loss: 0.33420413732528687
Validation loss: 2.170235057671865

Epoch: 6| Step: 13
Training loss: 0.6786293983459473
Validation loss: 2.1780984004338584

Epoch: 408| Step: 0
Training loss: 0.3751048445701599
Validation loss: 2.139967223008474

Epoch: 6| Step: 1
Training loss: 0.6535637378692627
Validation loss: 2.145057717959086

Epoch: 6| Step: 2
Training loss: 0.2503456771373749
Validation loss: 2.177409211794535

Epoch: 6| Step: 3
Training loss: 0.3694297671318054
Validation loss: 2.1307198206583657

Epoch: 6| Step: 4
Training loss: 0.34184151887893677
Validation loss: 2.155704081058502

Epoch: 6| Step: 5
Training loss: 0.6522727012634277
Validation loss: 2.1771450440088906

Epoch: 6| Step: 6
Training loss: 0.3548187017440796
Validation loss: 2.1915398438771567

Epoch: 6| Step: 7
Training loss: 0.21099844574928284
Validation loss: 2.2070601185162864

Epoch: 6| Step: 8
Training loss: 0.40806764364242554
Validation loss: 2.198673645655314

Epoch: 6| Step: 9
Training loss: 0.7456592917442322
Validation loss: 2.1598177552223206

Epoch: 6| Step: 10
Training loss: 0.35134607553482056
Validation loss: 2.1848652164141336

Epoch: 6| Step: 11
Training loss: 0.32790061831474304
Validation loss: 2.1825821797053018

Epoch: 6| Step: 12
Training loss: 0.2544802725315094
Validation loss: 2.2137664556503296

Epoch: 6| Step: 13
Training loss: 0.44063520431518555
Validation loss: 2.1825930873552957

Epoch: 409| Step: 0
Training loss: 0.29756245017051697
Validation loss: 2.2025229930877686

Epoch: 6| Step: 1
Training loss: 0.44779351353645325
Validation loss: 2.1679694851239524

Epoch: 6| Step: 2
Training loss: 0.44330599904060364
Validation loss: 2.181534707546234

Epoch: 6| Step: 3
Training loss: 0.4352009892463684
Validation loss: 2.184299906094869

Epoch: 6| Step: 4
Training loss: 0.23929348587989807
Validation loss: 2.194076875845591

Epoch: 6| Step: 5
Training loss: 0.39842408895492554
Validation loss: 2.220003088315328

Epoch: 6| Step: 6
Training loss: 0.5797158479690552
Validation loss: 2.1859548091888428

Epoch: 6| Step: 7
Training loss: 0.276682049036026
Validation loss: 2.1858228842417398

Epoch: 6| Step: 8
Training loss: 0.8951765298843384
Validation loss: 2.173272212346395

Epoch: 6| Step: 9
Training loss: 0.3473382890224457
Validation loss: 2.1956324577331543

Epoch: 6| Step: 10
Training loss: 0.3713317811489105
Validation loss: 2.178819715976715

Epoch: 6| Step: 11
Training loss: 0.2494804710149765
Validation loss: 2.1935353875160217

Epoch: 6| Step: 12
Training loss: 0.20095650851726532
Validation loss: 2.1649329463640847

Epoch: 6| Step: 13
Training loss: 0.4747024476528168
Validation loss: 2.148913820584615

Epoch: 410| Step: 0
Training loss: 0.2711983919143677
Validation loss: 2.1181096037228904

Epoch: 6| Step: 1
Training loss: 0.4291868209838867
Validation loss: 2.1114649971326194

Epoch: 6| Step: 2
Training loss: 0.3920397162437439
Validation loss: 2.1289246678352356

Epoch: 6| Step: 3
Training loss: 0.42638227343559265
Validation loss: 2.1259116331736245

Epoch: 6| Step: 4
Training loss: 0.9741851091384888
Validation loss: 2.1049898664156594

Epoch: 6| Step: 5
Training loss: 0.18149572610855103
Validation loss: 2.178769608338674

Epoch: 6| Step: 6
Training loss: 0.2490769624710083
Validation loss: 2.129928191502889

Epoch: 6| Step: 7
Training loss: 0.4106002748012543
Validation loss: 2.1626535654067993

Epoch: 6| Step: 8
Training loss: 0.6768267154693604
Validation loss: 2.154438396294912

Epoch: 6| Step: 9
Training loss: 0.41678386926651
Validation loss: 2.206955313682556

Epoch: 6| Step: 10
Training loss: 0.23667675256729126
Validation loss: 2.1752649744351706

Epoch: 6| Step: 11
Training loss: 0.23775982856750488
Validation loss: 2.2092859347661338

Epoch: 6| Step: 12
Training loss: 0.49605342745780945
Validation loss: 2.161345958709717

Epoch: 6| Step: 13
Training loss: 0.2554812729358673
Validation loss: 2.1724000771840415

Epoch: 411| Step: 0
Training loss: 0.30474722385406494
Validation loss: 2.1705585519472756

Epoch: 6| Step: 1
Training loss: 0.2959871292114258
Validation loss: 2.1775408387184143

Epoch: 6| Step: 2
Training loss: 0.2686040997505188
Validation loss: 2.1720637877782187

Epoch: 6| Step: 3
Training loss: 0.26231062412261963
Validation loss: 2.0946260690689087

Epoch: 6| Step: 4
Training loss: 0.34127557277679443
Validation loss: 2.1511377890904746

Epoch: 6| Step: 5
Training loss: 0.4809526205062866
Validation loss: 2.200906455516815

Epoch: 6| Step: 6
Training loss: 0.30621349811553955
Validation loss: 2.2219382723172507

Epoch: 6| Step: 7
Training loss: 0.7489633560180664
Validation loss: 2.1825137734413147

Epoch: 6| Step: 8
Training loss: 0.5388564467430115
Validation loss: 2.1708422700564065

Epoch: 6| Step: 9
Training loss: 0.34381499886512756
Validation loss: 2.1930213570594788

Epoch: 6| Step: 10
Training loss: 0.506244421005249
Validation loss: 2.1548137267430625

Epoch: 6| Step: 11
Training loss: 0.4489668905735016
Validation loss: 2.1778937379519143

Epoch: 6| Step: 12
Training loss: 0.2122873067855835
Validation loss: 2.180835704008738

Epoch: 6| Step: 13
Training loss: 1.0298876762390137
Validation loss: 2.153322776158651

Epoch: 412| Step: 0
Training loss: 0.44231000542640686
Validation loss: 2.158580501874288

Epoch: 6| Step: 1
Training loss: 0.23387233912944794
Validation loss: 2.16353174050649

Epoch: 6| Step: 2
Training loss: 0.720281720161438
Validation loss: 2.18228272596995

Epoch: 6| Step: 3
Training loss: 0.6908968687057495
Validation loss: 2.1335649689038596

Epoch: 6| Step: 4
Training loss: 0.3277582824230194
Validation loss: 2.1850533882776895

Epoch: 6| Step: 5
Training loss: 0.49289634823799133
Validation loss: 2.2096588214238486

Epoch: 6| Step: 6
Training loss: 0.5733164548873901
Validation loss: 2.107469101746877

Epoch: 6| Step: 7
Training loss: 0.29343801736831665
Validation loss: 2.1352429191271463

Epoch: 6| Step: 8
Training loss: 0.8242315649986267
Validation loss: 2.133839170138041

Epoch: 6| Step: 9
Training loss: 0.41127946972846985
Validation loss: 2.1307873328526816

Epoch: 6| Step: 10
Training loss: 0.2432677000761032
Validation loss: 2.1419812440872192

Epoch: 6| Step: 11
Training loss: 0.5106573700904846
Validation loss: 2.0995994806289673

Epoch: 6| Step: 12
Training loss: 0.30674615502357483
Validation loss: 2.1675514777501426

Epoch: 6| Step: 13
Training loss: 0.5020445585250854
Validation loss: 2.153491655985514

Epoch: 413| Step: 0
Training loss: 0.5337057113647461
Validation loss: 2.185972571372986

Epoch: 6| Step: 1
Training loss: 0.38542670011520386
Validation loss: 2.1757075786590576

Epoch: 6| Step: 2
Training loss: 0.370616614818573
Validation loss: 2.151163339614868

Epoch: 6| Step: 3
Training loss: 0.7085510492324829
Validation loss: 2.159326454003652

Epoch: 6| Step: 4
Training loss: 0.26095861196517944
Validation loss: 2.1415889660517373

Epoch: 6| Step: 5
Training loss: 0.7084424495697021
Validation loss: 2.2113344073295593

Epoch: 6| Step: 6
Training loss: 0.26478099822998047
Validation loss: 2.1335899035135903

Epoch: 6| Step: 7
Training loss: 0.2366626262664795
Validation loss: 2.122170925140381

Epoch: 6| Step: 8
Training loss: 0.8585127592086792
Validation loss: 2.1301612854003906

Epoch: 6| Step: 9
Training loss: 0.1144978404045105
Validation loss: 2.1591800451278687

Epoch: 6| Step: 10
Training loss: 0.29596275091171265
Validation loss: 2.1210986574490867

Epoch: 6| Step: 11
Training loss: 0.2684181034564972
Validation loss: 2.1209250887235007

Epoch: 6| Step: 12
Training loss: 0.44730669260025024
Validation loss: 2.1101661920547485

Epoch: 6| Step: 13
Training loss: 0.3987100124359131
Validation loss: 2.117087205251058

Epoch: 414| Step: 0
Training loss: 0.2676955461502075
Validation loss: 2.2038028836250305

Epoch: 6| Step: 1
Training loss: 0.2122349739074707
Validation loss: 2.202243983745575

Epoch: 6| Step: 2
Training loss: 0.28249457478523254
Validation loss: 2.212952891985575

Epoch: 6| Step: 3
Training loss: 0.5611540079116821
Validation loss: 2.19574103752772

Epoch: 6| Step: 4
Training loss: 0.3806300163269043
Validation loss: 2.207684357961019

Epoch: 6| Step: 5
Training loss: 0.5284340977668762
Validation loss: 2.2226902643839517

Epoch: 6| Step: 6
Training loss: 0.3730691373348236
Validation loss: 2.1385788917541504

Epoch: 6| Step: 7
Training loss: 0.43494898080825806
Validation loss: 2.150972565015157

Epoch: 6| Step: 8
Training loss: 0.8875495791435242
Validation loss: 2.1944160064061484

Epoch: 6| Step: 9
Training loss: 0.62245774269104
Validation loss: 2.1629990140597024

Epoch: 6| Step: 10
Training loss: 0.28817230463027954
Validation loss: 2.1364075938860574

Epoch: 6| Step: 11
Training loss: 0.405104398727417
Validation loss: 2.1451552907625833

Epoch: 6| Step: 12
Training loss: 0.3389214277267456
Validation loss: 2.151070992151896

Epoch: 6| Step: 13
Training loss: 0.41920793056488037
Validation loss: 2.187695781389872

Epoch: 415| Step: 0
Training loss: 0.25467410683631897
Validation loss: 2.148387293020884

Epoch: 6| Step: 1
Training loss: 0.37884581089019775
Validation loss: 2.0999231338500977

Epoch: 6| Step: 2
Training loss: 0.31202390789985657
Validation loss: 2.1679332852363586

Epoch: 6| Step: 3
Training loss: 0.37547069787979126
Validation loss: 2.159377853075663

Epoch: 6| Step: 4
Training loss: 0.39520278573036194
Validation loss: 2.1756425897280374

Epoch: 6| Step: 5
Training loss: 0.2558821141719818
Validation loss: 2.212031920750936

Epoch: 6| Step: 6
Training loss: 0.833473265171051
Validation loss: 2.228045701980591

Epoch: 6| Step: 7
Training loss: 0.3618941009044647
Validation loss: 2.1642680565516152

Epoch: 6| Step: 8
Training loss: 0.3913969397544861
Validation loss: 2.1273637612660727

Epoch: 6| Step: 9
Training loss: 0.40880316495895386
Validation loss: 2.1398989955584207

Epoch: 6| Step: 10
Training loss: 0.20185253024101257
Validation loss: 2.219582676887512

Epoch: 6| Step: 11
Training loss: 0.5310124158859253
Validation loss: 2.119716008504232

Epoch: 6| Step: 12
Training loss: 0.47521889209747314
Validation loss: 2.1295308272043862

Epoch: 6| Step: 13
Training loss: 0.3560386598110199
Validation loss: 2.167839507261912

Epoch: 416| Step: 0
Training loss: 0.37056195735931396
Validation loss: 2.1707586447397866

Epoch: 6| Step: 1
Training loss: 0.24084888398647308
Validation loss: 2.142702877521515

Epoch: 6| Step: 2
Training loss: 0.463392049074173
Validation loss: 2.1403008500734964

Epoch: 6| Step: 3
Training loss: 0.479219913482666
Validation loss: 2.1977566281954446

Epoch: 6| Step: 4
Training loss: 0.5975174307823181
Validation loss: 2.165569305419922

Epoch: 6| Step: 5
Training loss: 0.18017157912254333
Validation loss: 2.1775468389193215

Epoch: 6| Step: 6
Training loss: 0.3709490895271301
Validation loss: 2.151253263155619

Epoch: 6| Step: 7
Training loss: 0.5270359516143799
Validation loss: 2.136914392312368

Epoch: 6| Step: 8
Training loss: 0.3044162690639496
Validation loss: 2.19993656873703

Epoch: 6| Step: 9
Training loss: 0.24211876094341278
Validation loss: 2.173853278160095

Epoch: 6| Step: 10
Training loss: 0.21979065239429474
Validation loss: 2.1385914285977683

Epoch: 6| Step: 11
Training loss: 0.9739280343055725
Validation loss: 2.200514296690623

Epoch: 6| Step: 12
Training loss: 0.2671281695365906
Validation loss: 2.1708778738975525

Epoch: 6| Step: 13
Training loss: 0.3019699156284332
Validation loss: 2.0923052628835044

Epoch: 417| Step: 0
Training loss: 0.5817996263504028
Validation loss: 2.1740299463272095

Epoch: 6| Step: 1
Training loss: 0.5074957609176636
Validation loss: 2.154656410217285

Epoch: 6| Step: 2
Training loss: 0.4114558696746826
Validation loss: 2.187576691309611

Epoch: 6| Step: 3
Training loss: 0.1793757975101471
Validation loss: 2.183664778868357

Epoch: 6| Step: 4
Training loss: 0.4948786199092865
Validation loss: 2.1264787713686624

Epoch: 6| Step: 5
Training loss: 0.3297277092933655
Validation loss: 2.159793972969055

Epoch: 6| Step: 6
Training loss: 0.81465083360672
Validation loss: 2.1888425747553506

Epoch: 6| Step: 7
Training loss: 0.3997543156147003
Validation loss: 2.1878209908803306

Epoch: 6| Step: 8
Training loss: 0.3173677325248718
Validation loss: 2.098904768625895

Epoch: 6| Step: 9
Training loss: 0.456703782081604
Validation loss: 2.1505417823791504

Epoch: 6| Step: 10
Training loss: 0.2334444373846054
Validation loss: 2.1028605302174888

Epoch: 6| Step: 11
Training loss: 0.38988322019577026
Validation loss: 2.125456392765045

Epoch: 6| Step: 12
Training loss: 0.2797204554080963
Validation loss: 2.1801894505818686

Epoch: 6| Step: 13
Training loss: 0.256164014339447
Validation loss: 2.2209890286127725

Epoch: 418| Step: 0
Training loss: 0.2972148656845093
Validation loss: 2.2006697257359824

Epoch: 6| Step: 1
Training loss: 0.47051024436950684
Validation loss: 2.1975855827331543

Epoch: 6| Step: 2
Training loss: 0.2836795449256897
Validation loss: 2.1842492818832397

Epoch: 6| Step: 3
Training loss: 0.42025911808013916
Validation loss: 2.1830952962239585

Epoch: 6| Step: 4
Training loss: 0.8153008222579956
Validation loss: 2.1667728424072266

Epoch: 6| Step: 5
Training loss: 0.22645413875579834
Validation loss: 2.1452330946922302

Epoch: 6| Step: 6
Training loss: 0.40496665239334106
Validation loss: 2.0965699354807534

Epoch: 6| Step: 7
Training loss: 0.22240209579467773
Validation loss: 2.137076477209727

Epoch: 6| Step: 8
Training loss: 0.3572353422641754
Validation loss: 2.163404087225596

Epoch: 6| Step: 9
Training loss: 0.33576279878616333
Validation loss: 2.142802039782206

Epoch: 6| Step: 10
Training loss: 0.5611298680305481
Validation loss: 2.131138265132904

Epoch: 6| Step: 11
Training loss: 0.23201605677604675
Validation loss: 2.1215320428212485

Epoch: 6| Step: 12
Training loss: 0.3313951790332794
Validation loss: 2.165558397769928

Epoch: 6| Step: 13
Training loss: 0.3462514579296112
Validation loss: 2.161828597386678

Epoch: 419| Step: 0
Training loss: 0.265214741230011
Validation loss: 2.1804955999056497

Epoch: 6| Step: 1
Training loss: 0.5572994947433472
Validation loss: 2.1954644521077475

Epoch: 6| Step: 2
Training loss: 0.7744102478027344
Validation loss: 2.170786201953888

Epoch: 6| Step: 3
Training loss: 0.47148406505584717
Validation loss: 2.1952799757321677

Epoch: 6| Step: 4
Training loss: 0.3646736443042755
Validation loss: 2.174926300843557

Epoch: 6| Step: 5
Training loss: 0.3761562407016754
Validation loss: 2.1651113033294678

Epoch: 6| Step: 6
Training loss: 0.29851967096328735
Validation loss: 2.160284141699473

Epoch: 6| Step: 7
Training loss: 0.2681548595428467
Validation loss: 2.1568720936775208

Epoch: 6| Step: 8
Training loss: 0.23199152946472168
Validation loss: 2.160920282204946

Epoch: 6| Step: 9
Training loss: 0.3485948443412781
Validation loss: 2.1886074940363565

Epoch: 6| Step: 10
Training loss: 0.4671213626861572
Validation loss: 2.16620926062266

Epoch: 6| Step: 11
Training loss: 0.31699395179748535
Validation loss: 2.1950190663337708

Epoch: 6| Step: 12
Training loss: 0.33338457345962524
Validation loss: 2.2065004110336304

Epoch: 6| Step: 13
Training loss: 0.5609321594238281
Validation loss: 2.157796621322632

Epoch: 420| Step: 0
Training loss: 0.31520065665245056
Validation loss: 2.184746265411377

Epoch: 6| Step: 1
Training loss: 0.19246001541614532
Validation loss: 2.1237784028053284

Epoch: 6| Step: 2
Training loss: 0.8007334470748901
Validation loss: 2.187441865603129

Epoch: 6| Step: 3
Training loss: 0.28320345282554626
Validation loss: 2.1408929030100503

Epoch: 6| Step: 4
Training loss: 0.29010462760925293
Validation loss: 2.148756265640259

Epoch: 6| Step: 5
Training loss: 0.553865909576416
Validation loss: 2.186280528704325

Epoch: 6| Step: 6
Training loss: 0.2523832619190216
Validation loss: 2.2291628321011863

Epoch: 6| Step: 7
Training loss: 0.4233647584915161
Validation loss: 2.1826791167259216

Epoch: 6| Step: 8
Training loss: 0.19766519963741302
Validation loss: 2.2058189113934836

Epoch: 6| Step: 9
Training loss: 0.7105379104614258
Validation loss: 2.152503569920858

Epoch: 6| Step: 10
Training loss: 0.24858394265174866
Validation loss: 2.154046634833018

Epoch: 6| Step: 11
Training loss: 0.3063409924507141
Validation loss: 2.2358269691467285

Epoch: 6| Step: 12
Training loss: 0.43703949451446533
Validation loss: 2.1940844456354776

Epoch: 6| Step: 13
Training loss: 0.3696689307689667
Validation loss: 2.1603803038597107

Epoch: 421| Step: 0
Training loss: 0.46006113290786743
Validation loss: 2.2019285360972085

Epoch: 6| Step: 1
Training loss: 0.3359766900539398
Validation loss: 2.150127947330475

Epoch: 6| Step: 2
Training loss: 0.46474093198776245
Validation loss: 2.1401370565096536

Epoch: 6| Step: 3
Training loss: 0.3170469403266907
Validation loss: 2.1307144165039062

Epoch: 6| Step: 4
Training loss: 0.3909197449684143
Validation loss: 2.115330537160238

Epoch: 6| Step: 5
Training loss: 0.431532621383667
Validation loss: 2.1642343401908875

Epoch: 6| Step: 6
Training loss: 0.37200790643692017
Validation loss: 2.1150752703348794

Epoch: 6| Step: 7
Training loss: 0.2828187346458435
Validation loss: 2.1560468673706055

Epoch: 6| Step: 8
Training loss: 0.2848757207393646
Validation loss: 2.166723132133484

Epoch: 6| Step: 9
Training loss: 0.43439698219299316
Validation loss: 2.1657445430755615

Epoch: 6| Step: 10
Training loss: 0.37710854411125183
Validation loss: 2.156301995118459

Epoch: 6| Step: 11
Training loss: 0.2767833471298218
Validation loss: 2.1566054224967957

Epoch: 6| Step: 12
Training loss: 0.2777915596961975
Validation loss: 2.173477371533712

Epoch: 6| Step: 13
Training loss: 0.8416346907615662
Validation loss: 2.1366541186968484

Epoch: 422| Step: 0
Training loss: 0.6750435829162598
Validation loss: 2.15758353471756

Epoch: 6| Step: 1
Training loss: 0.4365329444408417
Validation loss: 2.161011596520742

Epoch: 6| Step: 2
Training loss: 0.40518641471862793
Validation loss: 2.1696821252504983

Epoch: 6| Step: 3
Training loss: 0.2858145534992218
Validation loss: 2.1489434838294983

Epoch: 6| Step: 4
Training loss: 0.1457376480102539
Validation loss: 2.14514829715093

Epoch: 6| Step: 5
Training loss: 0.5746850967407227
Validation loss: 2.190771679083506

Epoch: 6| Step: 6
Training loss: 0.26475071907043457
Validation loss: 2.1062055428822837

Epoch: 6| Step: 7
Training loss: 0.28828760981559753
Validation loss: 2.201553384462992

Epoch: 6| Step: 8
Training loss: 0.24798500537872314
Validation loss: 2.1721848845481873

Epoch: 6| Step: 9
Training loss: 0.478828489780426
Validation loss: 2.1932359536488852

Epoch: 6| Step: 10
Training loss: 0.2214793860912323
Validation loss: 2.207136313120524

Epoch: 6| Step: 11
Training loss: 0.25223249197006226
Validation loss: 2.165657858053843

Epoch: 6| Step: 12
Training loss: 0.5059025287628174
Validation loss: 2.1425890624523163

Epoch: 6| Step: 13
Training loss: 0.40855541825294495
Validation loss: 2.156586229801178

Epoch: 423| Step: 0
Training loss: 0.2460731416940689
Validation loss: 2.11171156167984

Epoch: 6| Step: 1
Training loss: 0.29715847969055176
Validation loss: 2.1581987539927163

Epoch: 6| Step: 2
Training loss: 0.43348681926727295
Validation loss: 2.1702375014623008

Epoch: 6| Step: 3
Training loss: 0.6386916637420654
Validation loss: 2.204499880472819

Epoch: 6| Step: 4
Training loss: 0.9382417798042297
Validation loss: 2.1905330816904702

Epoch: 6| Step: 5
Training loss: 0.32664236426353455
Validation loss: 2.2109588781992593

Epoch: 6| Step: 6
Training loss: 0.32375776767730713
Validation loss: 2.1582522988319397

Epoch: 6| Step: 7
Training loss: 0.2916177213191986
Validation loss: 2.160806099573771

Epoch: 6| Step: 8
Training loss: 0.17450228333473206
Validation loss: 2.16663251320521

Epoch: 6| Step: 9
Training loss: 0.27661722898483276
Validation loss: 2.1171091397603354

Epoch: 6| Step: 10
Training loss: 0.22637686133384705
Validation loss: 2.1090787649154663

Epoch: 6| Step: 11
Training loss: 0.3228115439414978
Validation loss: 2.09649650255839

Epoch: 6| Step: 12
Training loss: 0.5503726005554199
Validation loss: 2.1450513998667398

Epoch: 6| Step: 13
Training loss: 0.3509848713874817
Validation loss: 2.2138837774594626

Epoch: 424| Step: 0
Training loss: 0.2317599356174469
Validation loss: 2.1821282704671225

Epoch: 6| Step: 1
Training loss: 0.27059274911880493
Validation loss: 2.1387699842453003

Epoch: 6| Step: 2
Training loss: 0.4388871192932129
Validation loss: 2.1650923689206443

Epoch: 6| Step: 3
Training loss: 0.4136087894439697
Validation loss: 2.1527984142303467

Epoch: 6| Step: 4
Training loss: 0.19212841987609863
Validation loss: 2.1540298461914062

Epoch: 6| Step: 5
Training loss: 0.2425181269645691
Validation loss: 2.183364967505137

Epoch: 6| Step: 6
Training loss: 0.24527323246002197
Validation loss: 2.129192570845286

Epoch: 6| Step: 7
Training loss: 0.39707469940185547
Validation loss: 2.1855193376541138

Epoch: 6| Step: 8
Training loss: 0.9457247257232666
Validation loss: 2.1884679198265076

Epoch: 6| Step: 9
Training loss: 0.3680058717727661
Validation loss: 2.1588358879089355

Epoch: 6| Step: 10
Training loss: 0.8052442073822021
Validation loss: 2.1222148736317954

Epoch: 6| Step: 11
Training loss: 0.17853781580924988
Validation loss: 2.1155898173650107

Epoch: 6| Step: 12
Training loss: 0.22605493664741516
Validation loss: 2.1526674032211304

Epoch: 6| Step: 13
Training loss: 0.4301181435585022
Validation loss: 2.1532307465871177

Epoch: 425| Step: 0
Training loss: 0.5673837661743164
Validation loss: 2.1639530062675476

Epoch: 6| Step: 1
Training loss: 0.4315597414970398
Validation loss: 2.1732935508092246

Epoch: 6| Step: 2
Training loss: 0.7650425434112549
Validation loss: 2.1872517665227256

Epoch: 6| Step: 3
Training loss: 0.31845980882644653
Validation loss: 2.1622655987739563

Epoch: 6| Step: 4
Training loss: 0.5651875138282776
Validation loss: 2.161137501398722

Epoch: 6| Step: 5
Training loss: 0.3866851329803467
Validation loss: 2.206166625022888

Epoch: 6| Step: 6
Training loss: 0.22403794527053833
Validation loss: 2.195542891820272

Epoch: 6| Step: 7
Training loss: 0.26510000228881836
Validation loss: 2.1774163842201233

Epoch: 6| Step: 8
Training loss: 0.24777817726135254
Validation loss: 2.1156259377797446

Epoch: 6| Step: 9
Training loss: 0.6549170017242432
Validation loss: 2.1632182002067566

Epoch: 6| Step: 10
Training loss: 0.27406835556030273
Validation loss: 2.1916197538375854

Epoch: 6| Step: 11
Training loss: 0.3773886561393738
Validation loss: 2.1950730681419373

Epoch: 6| Step: 12
Training loss: 0.22519510984420776
Validation loss: 2.1876257260640464

Epoch: 6| Step: 13
Training loss: 0.2862922251224518
Validation loss: 2.1755056381225586

Epoch: 426| Step: 0
Training loss: 0.27170056104660034
Validation loss: 2.1606554985046387

Epoch: 6| Step: 1
Training loss: 0.3737245798110962
Validation loss: 2.16734371582667

Epoch: 6| Step: 2
Training loss: 0.3095313608646393
Validation loss: 2.1772034962972007

Epoch: 6| Step: 3
Training loss: 0.32835906744003296
Validation loss: 2.1462443470954895

Epoch: 6| Step: 4
Training loss: 0.3717586398124695
Validation loss: 2.1646880507469177

Epoch: 6| Step: 5
Training loss: 0.16873085498809814
Validation loss: 2.142394542694092

Epoch: 6| Step: 6
Training loss: 0.7186774611473083
Validation loss: 2.1698155403137207

Epoch: 6| Step: 7
Training loss: 0.6207303404808044
Validation loss: 2.165456930796305

Epoch: 6| Step: 8
Training loss: 0.29106101393699646
Validation loss: 2.1549094915390015

Epoch: 6| Step: 9
Training loss: 0.4968368709087372
Validation loss: 2.162523786226908

Epoch: 6| Step: 10
Training loss: 0.39906877279281616
Validation loss: 2.1814706722895303

Epoch: 6| Step: 11
Training loss: 0.5377179384231567
Validation loss: 2.2354391614596048

Epoch: 6| Step: 12
Training loss: 0.3566892147064209
Validation loss: 2.214151660601298

Epoch: 6| Step: 13
Training loss: 0.24026131629943848
Validation loss: 2.1758164763450623

Epoch: 427| Step: 0
Training loss: 0.3217872977256775
Validation loss: 2.186470548311869

Epoch: 6| Step: 1
Training loss: 0.2685922384262085
Validation loss: 2.185083508491516

Epoch: 6| Step: 2
Training loss: 0.3930199444293976
Validation loss: 2.170012354850769

Epoch: 6| Step: 3
Training loss: 0.7801824808120728
Validation loss: 2.134139617284139

Epoch: 6| Step: 4
Training loss: 0.35988539457321167
Validation loss: 2.120343049367269

Epoch: 6| Step: 5
Training loss: 0.747211754322052
Validation loss: 2.1491157611211142

Epoch: 6| Step: 6
Training loss: 0.3894475996494293
Validation loss: 2.169716755549113

Epoch: 6| Step: 7
Training loss: 0.2202461063861847
Validation loss: 2.126693765322367

Epoch: 6| Step: 8
Training loss: 0.36762481927871704
Validation loss: 2.122793356577555

Epoch: 6| Step: 9
Training loss: 0.6578952670097351
Validation loss: 2.138104955355326

Epoch: 6| Step: 10
Training loss: 0.2896274924278259
Validation loss: 2.104302982489268

Epoch: 6| Step: 11
Training loss: 0.22729316353797913
Validation loss: 2.236206074555715

Epoch: 6| Step: 12
Training loss: 0.3635135889053345
Validation loss: 2.230862617492676

Epoch: 6| Step: 13
Training loss: 0.3663354218006134
Validation loss: 2.168864905834198

Epoch: 428| Step: 0
Training loss: 0.8508663773536682
Validation loss: 2.218960185845693

Epoch: 6| Step: 1
Training loss: 0.3350962698459625
Validation loss: 2.2019490599632263

Epoch: 6| Step: 2
Training loss: 0.19619731605052948
Validation loss: 2.146536191304525

Epoch: 6| Step: 3
Training loss: 0.36733144521713257
Validation loss: 2.112822731335958

Epoch: 6| Step: 4
Training loss: 0.4136956036090851
Validation loss: 2.1536815563837686

Epoch: 6| Step: 5
Training loss: 0.4495164752006531
Validation loss: 2.1567118763923645

Epoch: 6| Step: 6
Training loss: 0.2329798936843872
Validation loss: 2.151340345541636

Epoch: 6| Step: 7
Training loss: 0.2708730101585388
Validation loss: 2.1408132314682007

Epoch: 6| Step: 8
Training loss: 0.32896095514297485
Validation loss: 2.1865132451057434

Epoch: 6| Step: 9
Training loss: 0.5641227960586548
Validation loss: 2.19022665421168

Epoch: 6| Step: 10
Training loss: 0.13420189917087555
Validation loss: 2.211505909760793

Epoch: 6| Step: 11
Training loss: 0.6368291974067688
Validation loss: 2.1550358732541404

Epoch: 6| Step: 12
Training loss: 0.328163743019104
Validation loss: 2.1599738001823425

Epoch: 6| Step: 13
Training loss: 0.39218443632125854
Validation loss: 2.1871168414751687

Epoch: 429| Step: 0
Training loss: 0.2582457661628723
Validation loss: 2.1944809754689536

Epoch: 6| Step: 1
Training loss: 0.2583494782447815
Validation loss: 2.1533766388893127

Epoch: 6| Step: 2
Training loss: 0.47214019298553467
Validation loss: 2.12052983045578

Epoch: 6| Step: 3
Training loss: 0.2811393141746521
Validation loss: 2.202990969022115

Epoch: 6| Step: 4
Training loss: 0.37284380197525024
Validation loss: 2.190018435319265

Epoch: 6| Step: 5
Training loss: 0.24426546692848206
Validation loss: 2.2142296632130942

Epoch: 6| Step: 6
Training loss: 0.24209703505039215
Validation loss: 2.188003500302633

Epoch: 6| Step: 7
Training loss: 0.4758537709712982
Validation loss: 2.174042503039042

Epoch: 6| Step: 8
Training loss: 0.4416220188140869
Validation loss: 2.1729673941930137

Epoch: 6| Step: 9
Training loss: 0.2187216877937317
Validation loss: 2.1923014521598816

Epoch: 6| Step: 10
Training loss: 0.9133745431900024
Validation loss: 2.169532895088196

Epoch: 6| Step: 11
Training loss: 0.42208045721054077
Validation loss: 2.079691926638285

Epoch: 6| Step: 12
Training loss: 0.35307419300079346
Validation loss: 2.1777671575546265

Epoch: 6| Step: 13
Training loss: 0.4316175878047943
Validation loss: 2.1630407571792603

Epoch: 430| Step: 0
Training loss: 0.5283750891685486
Validation loss: 2.1868701577186584

Epoch: 6| Step: 1
Training loss: 0.2832377851009369
Validation loss: 2.109062373638153

Epoch: 6| Step: 2
Training loss: 0.23903891444206238
Validation loss: 2.1390254696210227

Epoch: 6| Step: 3
Training loss: 0.9394198656082153
Validation loss: 2.1793100039164224

Epoch: 6| Step: 4
Training loss: 0.29666996002197266
Validation loss: 2.1722954312960305

Epoch: 6| Step: 5
Training loss: 0.2546841502189636
Validation loss: 2.1902910272280374

Epoch: 6| Step: 6
Training loss: 0.27151018381118774
Validation loss: 2.1835350592931113

Epoch: 6| Step: 7
Training loss: 0.25633668899536133
Validation loss: 2.1876202623049417

Epoch: 6| Step: 8
Training loss: 0.31686025857925415
Validation loss: 2.1569825808207193

Epoch: 6| Step: 9
Training loss: 0.19662538170814514
Validation loss: 2.1773350636164346

Epoch: 6| Step: 10
Training loss: 0.40025752782821655
Validation loss: 2.1972626447677612

Epoch: 6| Step: 11
Training loss: 0.35295218229293823
Validation loss: 2.155718366305033

Epoch: 6| Step: 12
Training loss: 0.41833510994911194
Validation loss: 2.183830221494039

Epoch: 6| Step: 13
Training loss: 0.7346247434616089
Validation loss: 2.1309149662653604

Epoch: 431| Step: 0
Training loss: 0.7233098745346069
Validation loss: 2.1713194052378335

Epoch: 6| Step: 1
Training loss: 0.3985403776168823
Validation loss: 2.163498878479004

Epoch: 6| Step: 2
Training loss: 0.40156465768814087
Validation loss: 2.2086480259895325

Epoch: 6| Step: 3
Training loss: 0.19860133528709412
Validation loss: 2.2207240064938865

Epoch: 6| Step: 4
Training loss: 0.5500519275665283
Validation loss: 2.232192099094391

Epoch: 6| Step: 5
Training loss: 0.2202141284942627
Validation loss: 2.203748643398285

Epoch: 6| Step: 6
Training loss: 0.31544846296310425
Validation loss: 2.145001232624054

Epoch: 6| Step: 7
Training loss: 0.5272241830825806
Validation loss: 2.2171480655670166

Epoch: 6| Step: 8
Training loss: 0.32258880138397217
Validation loss: 2.1305178006490073

Epoch: 6| Step: 9
Training loss: 0.41858500242233276
Validation loss: 2.1832125385602317

Epoch: 6| Step: 10
Training loss: 0.4366423189640045
Validation loss: 2.1702805956204734

Epoch: 6| Step: 11
Training loss: 0.46252620220184326
Validation loss: 2.2111011147499084

Epoch: 6| Step: 12
Training loss: 0.33457183837890625
Validation loss: 2.240949034690857

Epoch: 6| Step: 13
Training loss: 0.5086297392845154
Validation loss: 2.2014875610669455

Epoch: 432| Step: 0
Training loss: 0.5110912322998047
Validation loss: 2.234000007311503

Epoch: 6| Step: 1
Training loss: 0.23215660452842712
Validation loss: 2.180651605129242

Epoch: 6| Step: 2
Training loss: 0.3230679929256439
Validation loss: 2.2136476834615073

Epoch: 6| Step: 3
Training loss: 0.3125914931297302
Validation loss: 2.186685939629873

Epoch: 6| Step: 4
Training loss: 0.3182028830051422
Validation loss: 2.199105719725291

Epoch: 6| Step: 5
Training loss: 0.24767549335956573
Validation loss: 2.187006334463755

Epoch: 6| Step: 6
Training loss: 0.3078446090221405
Validation loss: 2.1757341623306274

Epoch: 6| Step: 7
Training loss: 0.7571536302566528
Validation loss: 2.165022830168406

Epoch: 6| Step: 8
Training loss: 0.6792624592781067
Validation loss: 2.1516289710998535

Epoch: 6| Step: 9
Training loss: 0.3941549062728882
Validation loss: 2.122922201951345

Epoch: 6| Step: 10
Training loss: 0.1648152470588684
Validation loss: 2.1893231670061746

Epoch: 6| Step: 11
Training loss: 0.5533980131149292
Validation loss: 2.2222594022750854

Epoch: 6| Step: 12
Training loss: 0.47796469926834106
Validation loss: 2.1685590744018555

Epoch: 6| Step: 13
Training loss: 0.38192716240882874
Validation loss: 2.1598550279935202

Epoch: 433| Step: 0
Training loss: 0.6827789545059204
Validation loss: 2.1814773082733154

Epoch: 6| Step: 1
Training loss: 0.2740303874015808
Validation loss: 2.151458183924357

Epoch: 6| Step: 2
Training loss: 0.24809060990810394
Validation loss: 2.136923591295878

Epoch: 6| Step: 3
Training loss: 0.18502989411354065
Validation loss: 2.1366101503372192

Epoch: 6| Step: 4
Training loss: 0.8000147342681885
Validation loss: 2.1355632543563843

Epoch: 6| Step: 5
Training loss: 0.27481821179389954
Validation loss: 2.1385453939437866

Epoch: 6| Step: 6
Training loss: 0.35120296478271484
Validation loss: 2.1482639710108438

Epoch: 6| Step: 7
Training loss: 0.46509507298469543
Validation loss: 2.16627166668574

Epoch: 6| Step: 8
Training loss: 0.4220050275325775
Validation loss: 2.207712550957998

Epoch: 6| Step: 9
Training loss: 0.41540294885635376
Validation loss: 2.1719491283098855

Epoch: 6| Step: 10
Training loss: 0.3099404573440552
Validation loss: 2.195274611314138

Epoch: 6| Step: 11
Training loss: 0.5822109580039978
Validation loss: 2.135949114958445

Epoch: 6| Step: 12
Training loss: 0.333792507648468
Validation loss: 2.1396867632865906

Epoch: 6| Step: 13
Training loss: 0.2450539469718933
Validation loss: 2.1717565059661865

Epoch: 434| Step: 0
Training loss: 0.22244760394096375
Validation loss: 2.1467270851135254

Epoch: 6| Step: 1
Training loss: 0.29226595163345337
Validation loss: 2.1117979288101196

Epoch: 6| Step: 2
Training loss: 0.4628007709980011
Validation loss: 2.163187841574351

Epoch: 6| Step: 3
Training loss: 0.17051060497760773
Validation loss: 2.136833608150482

Epoch: 6| Step: 4
Training loss: 0.3873249590396881
Validation loss: 2.144173562526703

Epoch: 6| Step: 5
Training loss: 0.4081249237060547
Validation loss: 2.1720371643702188

Epoch: 6| Step: 6
Training loss: 0.296364426612854
Validation loss: 2.142889599005381

Epoch: 6| Step: 7
Training loss: 0.5175526738166809
Validation loss: 2.1485493580500283

Epoch: 6| Step: 8
Training loss: 0.7071347236633301
Validation loss: 2.1357961098353067

Epoch: 6| Step: 9
Training loss: 0.8279190063476562
Validation loss: 2.120711545149485

Epoch: 6| Step: 10
Training loss: 0.33390289545059204
Validation loss: 2.1818043986956277

Epoch: 6| Step: 11
Training loss: 0.34417515993118286
Validation loss: 2.1542375485102334

Epoch: 6| Step: 12
Training loss: 0.3761565685272217
Validation loss: 2.20267391204834

Epoch: 6| Step: 13
Training loss: 0.23377566039562225
Validation loss: 2.1760897835095725

Epoch: 435| Step: 0
Training loss: 0.19543394446372986
Validation loss: 2.1625683307647705

Epoch: 6| Step: 1
Training loss: 0.45869022607803345
Validation loss: 2.162861466407776

Epoch: 6| Step: 2
Training loss: 0.35176515579223633
Validation loss: 2.1403828461964927

Epoch: 6| Step: 3
Training loss: 0.4123745560646057
Validation loss: 2.1402639547983804

Epoch: 6| Step: 4
Training loss: 0.27268582582473755
Validation loss: 2.1293568213780723

Epoch: 6| Step: 5
Training loss: 0.16142281889915466
Validation loss: 2.1777294079462686

Epoch: 6| Step: 6
Training loss: 0.24085478484630585
Validation loss: 2.15381650129954

Epoch: 6| Step: 7
Training loss: 0.470977783203125
Validation loss: 2.13466876745224

Epoch: 6| Step: 8
Training loss: 0.20379573106765747
Validation loss: 2.1750765641530356

Epoch: 6| Step: 9
Training loss: 0.9765770435333252
Validation loss: 2.208574096361796

Epoch: 6| Step: 10
Training loss: 0.4001774191856384
Validation loss: 2.167678634325663

Epoch: 6| Step: 11
Training loss: 0.3736923933029175
Validation loss: 2.13082226117452

Epoch: 6| Step: 12
Training loss: 0.43680161237716675
Validation loss: 2.1386647621790567

Epoch: 6| Step: 13
Training loss: 0.3974362313747406
Validation loss: 2.1165148417154946

Epoch: 436| Step: 0
Training loss: 0.4225711226463318
Validation loss: 2.1637669006983438

Epoch: 6| Step: 1
Training loss: 0.33408790826797485
Validation loss: 2.169237812360128

Epoch: 6| Step: 2
Training loss: 0.30086109042167664
Validation loss: 2.1579050620396933

Epoch: 6| Step: 3
Training loss: 0.5053749084472656
Validation loss: 2.168965975443522

Epoch: 6| Step: 4
Training loss: 0.2872585654258728
Validation loss: 2.168350120385488

Epoch: 6| Step: 5
Training loss: 0.5164894461631775
Validation loss: 2.128763715426127

Epoch: 6| Step: 6
Training loss: 0.7266159653663635
Validation loss: 2.177069346110026

Epoch: 6| Step: 7
Training loss: 0.28123730421066284
Validation loss: 2.2007780273755393

Epoch: 6| Step: 8
Training loss: 0.2612758278846741
Validation loss: 2.1503140926361084

Epoch: 6| Step: 9
Training loss: 0.578216552734375
Validation loss: 2.195070127646128

Epoch: 6| Step: 10
Training loss: 0.20811727643013
Validation loss: 2.2051598827044168

Epoch: 6| Step: 11
Training loss: 0.4684954583644867
Validation loss: 2.143617312113444

Epoch: 6| Step: 12
Training loss: 0.2551434636116028
Validation loss: 2.1424055298169455

Epoch: 6| Step: 13
Training loss: 0.3618619740009308
Validation loss: 2.204492171605428

Epoch: 437| Step: 0
Training loss: 1.0800267457962036
Validation loss: 2.167837699254354

Epoch: 6| Step: 1
Training loss: 0.5043982267379761
Validation loss: 2.1536309321721396

Epoch: 6| Step: 2
Training loss: 0.20914709568023682
Validation loss: 2.192331910133362

Epoch: 6| Step: 3
Training loss: 0.21419531106948853
Validation loss: 2.1688855290412903

Epoch: 6| Step: 4
Training loss: 0.5784350633621216
Validation loss: 2.1958117882410684

Epoch: 6| Step: 5
Training loss: 0.24512258172035217
Validation loss: 2.207436482111613

Epoch: 6| Step: 6
Training loss: 0.22716736793518066
Validation loss: 2.2240236600240073

Epoch: 6| Step: 7
Training loss: 0.14533844590187073
Validation loss: 2.2257710297902427

Epoch: 6| Step: 8
Training loss: 0.23675020039081573
Validation loss: 2.205141007900238

Epoch: 6| Step: 9
Training loss: 0.349711537361145
Validation loss: 2.213164806365967

Epoch: 6| Step: 10
Training loss: 0.44829264283180237
Validation loss: 2.2172409296035767

Epoch: 6| Step: 11
Training loss: 0.4856244921684265
Validation loss: 2.1808913151423135

Epoch: 6| Step: 12
Training loss: 0.2885284721851349
Validation loss: 2.1830573081970215

Epoch: 6| Step: 13
Training loss: 0.449313759803772
Validation loss: 2.225859800974528

Epoch: 438| Step: 0
Training loss: 0.7700002789497375
Validation loss: 2.12361470858256

Epoch: 6| Step: 1
Training loss: 0.5043612122535706
Validation loss: 2.1689263383547464

Epoch: 6| Step: 2
Training loss: 0.24278227984905243
Validation loss: 2.1807053287823996

Epoch: 6| Step: 3
Training loss: 0.8574991226196289
Validation loss: 2.1984200278917947

Epoch: 6| Step: 4
Training loss: 0.31752637028694153
Validation loss: 2.1663103302319846

Epoch: 6| Step: 5
Training loss: 0.341915488243103
Validation loss: 2.188651998837789

Epoch: 6| Step: 6
Training loss: 0.1847696304321289
Validation loss: 2.1397545536359153

Epoch: 6| Step: 7
Training loss: 0.30056315660476685
Validation loss: 2.199632783730825

Epoch: 6| Step: 8
Training loss: 0.31150078773498535
Validation loss: 2.1853660345077515

Epoch: 6| Step: 9
Training loss: 0.29319775104522705
Validation loss: 2.182740648587545

Epoch: 6| Step: 10
Training loss: 0.27573564648628235
Validation loss: 2.1896096666653952

Epoch: 6| Step: 11
Training loss: 0.32208603620529175
Validation loss: 2.2144450346628823

Epoch: 6| Step: 12
Training loss: 0.30770301818847656
Validation loss: 2.170117735862732

Epoch: 6| Step: 13
Training loss: 0.39015448093414307
Validation loss: 2.1752719283103943

Epoch: 439| Step: 0
Training loss: 0.21717415750026703
Validation loss: 2.2215049266815186

Epoch: 6| Step: 1
Training loss: 0.31036412715911865
Validation loss: 2.197343866030375

Epoch: 6| Step: 2
Training loss: 0.5811889171600342
Validation loss: 2.152563989162445

Epoch: 6| Step: 3
Training loss: 0.41200605034828186
Validation loss: 2.147120257218679

Epoch: 6| Step: 4
Training loss: 0.31224215030670166
Validation loss: 2.189637303352356

Epoch: 6| Step: 5
Training loss: 0.5096903443336487
Validation loss: 2.1311888098716736

Epoch: 6| Step: 6
Training loss: 0.4722156822681427
Validation loss: 2.173600494861603

Epoch: 6| Step: 7
Training loss: 0.19417527318000793
Validation loss: 2.1756507953008017

Epoch: 6| Step: 8
Training loss: 0.32288089394569397
Validation loss: 2.131574889024099

Epoch: 6| Step: 9
Training loss: 0.23629003763198853
Validation loss: 2.1530425747235618

Epoch: 6| Step: 10
Training loss: 0.9133247137069702
Validation loss: 2.163103540738424

Epoch: 6| Step: 11
Training loss: 0.4609623849391937
Validation loss: 2.19508828719457

Epoch: 6| Step: 12
Training loss: 0.3543657064437866
Validation loss: 2.1870254278182983

Epoch: 6| Step: 13
Training loss: 0.2539307177066803
Validation loss: 2.1767939726511636

Epoch: 440| Step: 0
Training loss: 0.2366088181734085
Validation loss: 2.2012017369270325

Epoch: 6| Step: 1
Training loss: 0.5245773792266846
Validation loss: 2.1342891256014505

Epoch: 6| Step: 2
Training loss: 0.2802790701389313
Validation loss: 2.2476887106895447

Epoch: 6| Step: 3
Training loss: 0.19695311784744263
Validation loss: 2.2243361274401345

Epoch: 6| Step: 4
Training loss: 0.3748088479042053
Validation loss: 2.21309502919515

Epoch: 6| Step: 5
Training loss: 0.38498589396476746
Validation loss: 2.1632713874181113

Epoch: 6| Step: 6
Training loss: 0.320893794298172
Validation loss: 2.218546986579895

Epoch: 6| Step: 7
Training loss: 0.2852649986743927
Validation loss: 2.187774419784546

Epoch: 6| Step: 8
Training loss: 0.23254847526550293
Validation loss: 2.1813133358955383

Epoch: 6| Step: 9
Training loss: 0.3147963285446167
Validation loss: 2.1753841241200766

Epoch: 6| Step: 10
Training loss: 0.619947612285614
Validation loss: 2.2223916252454123

Epoch: 6| Step: 11
Training loss: 0.311744749546051
Validation loss: 2.1789272824923196

Epoch: 6| Step: 12
Training loss: 0.7339074015617371
Validation loss: 2.2315950989723206

Epoch: 6| Step: 13
Training loss: 0.4572831988334656
Validation loss: 2.2294960618019104

Epoch: 441| Step: 0
Training loss: 0.20932690799236298
Validation loss: 2.208941698074341

Epoch: 6| Step: 1
Training loss: 0.24387864768505096
Validation loss: 2.201088309288025

Epoch: 6| Step: 2
Training loss: 0.7616380453109741
Validation loss: 2.198146720727285

Epoch: 6| Step: 3
Training loss: 0.2836565375328064
Validation loss: 2.205902338027954

Epoch: 6| Step: 4
Training loss: 0.27962201833724976
Validation loss: 2.190370500087738

Epoch: 6| Step: 5
Training loss: 0.43124592304229736
Validation loss: 2.164592921733856

Epoch: 6| Step: 6
Training loss: 0.8047535419464111
Validation loss: 2.168255547682444

Epoch: 6| Step: 7
Training loss: 0.46909263730049133
Validation loss: 2.1319921215375266

Epoch: 6| Step: 8
Training loss: 0.3331376910209656
Validation loss: 2.226179222265879

Epoch: 6| Step: 9
Training loss: 0.3028028607368469
Validation loss: 2.172101318836212

Epoch: 6| Step: 10
Training loss: 0.3066481649875641
Validation loss: 2.1627604365348816

Epoch: 6| Step: 11
Training loss: 0.2844826281070709
Validation loss: 2.2054646809895835

Epoch: 6| Step: 12
Training loss: 0.38356393575668335
Validation loss: 2.198744297027588

Epoch: 6| Step: 13
Training loss: 0.28129464387893677
Validation loss: 2.1820208032925925

Epoch: 442| Step: 0
Training loss: 0.59186190366745
Validation loss: 2.216320554415385

Epoch: 6| Step: 1
Training loss: 0.29369956254959106
Validation loss: 2.2193168997764587

Epoch: 6| Step: 2
Training loss: 0.23650377988815308
Validation loss: 2.249002834161123

Epoch: 6| Step: 3
Training loss: 0.33673012256622314
Validation loss: 2.2143694361050925

Epoch: 6| Step: 4
Training loss: 0.20522448420524597
Validation loss: 2.203599512577057

Epoch: 6| Step: 5
Training loss: 0.40984630584716797
Validation loss: 2.2297844688097634

Epoch: 6| Step: 6
Training loss: 0.6422137022018433
Validation loss: 2.1895898381868997

Epoch: 6| Step: 7
Training loss: 0.18386375904083252
Validation loss: 2.135596056779226

Epoch: 6| Step: 8
Training loss: 0.8608385920524597
Validation loss: 2.203679144382477

Epoch: 6| Step: 9
Training loss: 0.30559295415878296
Validation loss: 2.1632490356763205

Epoch: 6| Step: 10
Training loss: 0.1700153946876526
Validation loss: 2.1663241386413574

Epoch: 6| Step: 11
Training loss: 0.4115241765975952
Validation loss: 2.1224392453829446

Epoch: 6| Step: 12
Training loss: 0.4361504316329956
Validation loss: 2.1927163004875183

Epoch: 6| Step: 13
Training loss: 0.34199392795562744
Validation loss: 2.159513791402181

Epoch: 443| Step: 0
Training loss: 0.30898791551589966
Validation loss: 2.2519769271214805

Epoch: 6| Step: 1
Training loss: 0.4677639305591583
Validation loss: 2.214635213216146

Epoch: 6| Step: 2
Training loss: 0.3585911989212036
Validation loss: 2.1882280707359314

Epoch: 6| Step: 3
Training loss: 0.2327520251274109
Validation loss: 2.2414041558901467

Epoch: 6| Step: 4
Training loss: 0.2685920000076294
Validation loss: 2.155268688996633

Epoch: 6| Step: 5
Training loss: 0.16469484567642212
Validation loss: 2.137629191080729

Epoch: 6| Step: 6
Training loss: 0.5477608442306519
Validation loss: 2.19545716047287

Epoch: 6| Step: 7
Training loss: 0.4961232542991638
Validation loss: 2.1508756478627524

Epoch: 6| Step: 8
Training loss: 0.2755776643753052
Validation loss: 2.1776313384373984

Epoch: 6| Step: 9
Training loss: 0.7841700315475464
Validation loss: 2.168221871058146

Epoch: 6| Step: 10
Training loss: 0.31316936016082764
Validation loss: 2.1658584078152976

Epoch: 6| Step: 11
Training loss: 0.38884711265563965
Validation loss: 2.2057621280352273

Epoch: 6| Step: 12
Training loss: 0.6005322933197021
Validation loss: 2.152858555316925

Epoch: 6| Step: 13
Training loss: 0.2742078900337219
Validation loss: 2.188456137975057

Epoch: 444| Step: 0
Training loss: 0.4379884600639343
Validation loss: 2.158180683851242

Epoch: 6| Step: 1
Training loss: 0.2564789652824402
Validation loss: 2.205761810143789

Epoch: 6| Step: 2
Training loss: 0.5012120604515076
Validation loss: 2.230740944544474

Epoch: 6| Step: 3
Training loss: 0.6688095927238464
Validation loss: 2.1964417695999146

Epoch: 6| Step: 4
Training loss: 0.19171619415283203
Validation loss: 2.2438978155454

Epoch: 6| Step: 5
Training loss: 0.352756530046463
Validation loss: 2.1969147523244223

Epoch: 6| Step: 6
Training loss: 0.3679888844490051
Validation loss: 2.183188736438751

Epoch: 6| Step: 7
Training loss: 0.4272081255912781
Validation loss: 2.113605320453644

Epoch: 6| Step: 8
Training loss: 0.19516251981258392
Validation loss: 2.1550119519233704

Epoch: 6| Step: 9
Training loss: 1.05935800075531
Validation loss: 2.1482531825701394

Epoch: 6| Step: 10
Training loss: 0.5297768115997314
Validation loss: 2.1405892968177795

Epoch: 6| Step: 11
Training loss: 0.27623850107192993
Validation loss: 2.186764935652415

Epoch: 6| Step: 12
Training loss: 0.38198450207710266
Validation loss: 2.1757745146751404

Epoch: 6| Step: 13
Training loss: 0.28949037194252014
Validation loss: 2.2135881582895913

Epoch: 445| Step: 0
Training loss: 0.6029843091964722
Validation loss: 2.2462673584620156

Epoch: 6| Step: 1
Training loss: 0.3744781017303467
Validation loss: 2.2138496239980063

Epoch: 6| Step: 2
Training loss: 0.37077489495277405
Validation loss: 2.2092614571253457

Epoch: 6| Step: 3
Training loss: 0.48251205682754517
Validation loss: 2.2028512358665466

Epoch: 6| Step: 4
Training loss: 0.415158212184906
Validation loss: 2.162915289402008

Epoch: 6| Step: 5
Training loss: 0.33837297558784485
Validation loss: 2.1355026960372925

Epoch: 6| Step: 6
Training loss: 1.0905959606170654
Validation loss: 2.1327604055404663

Epoch: 6| Step: 7
Training loss: 0.30007320642471313
Validation loss: 2.1660567124684653

Epoch: 6| Step: 8
Training loss: 0.45023655891418457
Validation loss: 2.183414618174235

Epoch: 6| Step: 9
Training loss: 0.1957470327615738
Validation loss: 2.169880469640096

Epoch: 6| Step: 10
Training loss: 0.34453272819519043
Validation loss: 2.1234028935432434

Epoch: 6| Step: 11
Training loss: 0.23449423909187317
Validation loss: 2.2019382317860923

Epoch: 6| Step: 12
Training loss: 0.43639540672302246
Validation loss: 2.167959451675415

Epoch: 6| Step: 13
Training loss: 0.25837060809135437
Validation loss: 2.195488472779592

Epoch: 446| Step: 0
Training loss: 0.5115448236465454
Validation loss: 2.2171467940012612

Epoch: 6| Step: 1
Training loss: 0.22312721610069275
Validation loss: 2.1892547011375427

Epoch: 6| Step: 2
Training loss: 0.31575775146484375
Validation loss: 2.20685883363088

Epoch: 6| Step: 3
Training loss: 0.3306273818016052
Validation loss: 2.2138306895891824

Epoch: 6| Step: 4
Training loss: 0.44322270154953003
Validation loss: 2.1903023719787598

Epoch: 6| Step: 5
Training loss: 0.3686789870262146
Validation loss: 2.17688395579656

Epoch: 6| Step: 6
Training loss: 0.3895050287246704
Validation loss: 2.22402286529541

Epoch: 6| Step: 7
Training loss: 0.35571998357772827
Validation loss: 2.16769148906072

Epoch: 6| Step: 8
Training loss: 0.23706990480422974
Validation loss: 2.1862526138623557

Epoch: 6| Step: 9
Training loss: 0.46863019466400146
Validation loss: 2.1995630462964377

Epoch: 6| Step: 10
Training loss: 0.2959058880805969
Validation loss: 2.180317521095276

Epoch: 6| Step: 11
Training loss: 0.28722235560417175
Validation loss: 2.2138577103614807

Epoch: 6| Step: 12
Training loss: 1.0802481174468994
Validation loss: 2.2496912479400635

Epoch: 6| Step: 13
Training loss: 0.29092419147491455
Validation loss: 2.2019223173459372

Epoch: 447| Step: 0
Training loss: 0.4744441509246826
Validation loss: 2.2381897370020547

Epoch: 6| Step: 1
Training loss: 0.24657988548278809
Validation loss: 2.228996435801188

Epoch: 6| Step: 2
Training loss: 0.08048225939273834
Validation loss: 2.2033543984095254

Epoch: 6| Step: 3
Training loss: 0.2881929874420166
Validation loss: 2.2160832285881042

Epoch: 6| Step: 4
Training loss: 0.5529218912124634
Validation loss: 2.1265670458475747

Epoch: 6| Step: 5
Training loss: 0.5767077207565308
Validation loss: 2.1965077916781106

Epoch: 6| Step: 6
Training loss: 0.5244158506393433
Validation loss: 2.2188775142033896

Epoch: 6| Step: 7
Training loss: 0.42025700211524963
Validation loss: 2.1995341181755066

Epoch: 6| Step: 8
Training loss: 0.3824729323387146
Validation loss: 2.171817143758138

Epoch: 6| Step: 9
Training loss: 0.767620325088501
Validation loss: 2.1798545122146606

Epoch: 6| Step: 10
Training loss: 0.48835816979408264
Validation loss: 2.2501096725463867

Epoch: 6| Step: 11
Training loss: 0.22801530361175537
Validation loss: 2.1917133132616677

Epoch: 6| Step: 12
Training loss: 0.6512719988822937
Validation loss: 2.2249906261761985

Epoch: 6| Step: 13
Training loss: 0.2520999014377594
Validation loss: 2.1971885760625205

Epoch: 448| Step: 0
Training loss: 0.42585283517837524
Validation loss: 2.1753495136896768

Epoch: 6| Step: 1
Training loss: 0.9400885105133057
Validation loss: 2.186375598112742

Epoch: 6| Step: 2
Training loss: 0.29465192556381226
Validation loss: 2.2232184410095215

Epoch: 6| Step: 3
Training loss: 0.43465253710746765
Validation loss: 2.1851913730303445

Epoch: 6| Step: 4
Training loss: 0.35189390182495117
Validation loss: 2.1850435733795166

Epoch: 6| Step: 5
Training loss: 0.28403544425964355
Validation loss: 2.188961923122406

Epoch: 6| Step: 6
Training loss: 0.4612288475036621
Validation loss: 2.1708380381266275

Epoch: 6| Step: 7
Training loss: 0.1398899257183075
Validation loss: 2.1714634895324707

Epoch: 6| Step: 8
Training loss: 0.32413041591644287
Validation loss: 2.184861898422241

Epoch: 6| Step: 9
Training loss: 0.21296238899230957
Validation loss: 2.2242727478345237

Epoch: 6| Step: 10
Training loss: 0.18616028130054474
Validation loss: 2.218419353167216

Epoch: 6| Step: 11
Training loss: 0.2517198324203491
Validation loss: 2.2462385098139444

Epoch: 6| Step: 12
Training loss: 0.1529361754655838
Validation loss: 2.209782083829244

Epoch: 6| Step: 13
Training loss: 0.7205779552459717
Validation loss: 2.2105555136998496

Epoch: 449| Step: 0
Training loss: 1.0939435958862305
Validation loss: 2.2059741020202637

Epoch: 6| Step: 1
Training loss: 0.1694459170103073
Validation loss: 2.168687323729197

Epoch: 6| Step: 2
Training loss: 0.43595027923583984
Validation loss: 2.2148617704709372

Epoch: 6| Step: 3
Training loss: 0.30549508333206177
Validation loss: 2.1978419025739035

Epoch: 6| Step: 4
Training loss: 0.2197190672159195
Validation loss: 2.154413561026255

Epoch: 6| Step: 5
Training loss: 0.3262404799461365
Validation loss: 2.157012144724528

Epoch: 6| Step: 6
Training loss: 0.1722508668899536
Validation loss: 2.168429414431254

Epoch: 6| Step: 7
Training loss: 0.38268667459487915
Validation loss: 2.1653213103612265

Epoch: 6| Step: 8
Training loss: 0.46708980202674866
Validation loss: 2.11783496538798

Epoch: 6| Step: 9
Training loss: 0.28360283374786377
Validation loss: 2.1669148604075112

Epoch: 6| Step: 10
Training loss: 0.3092891573905945
Validation loss: 2.128080427646637

Epoch: 6| Step: 11
Training loss: 0.2885434925556183
Validation loss: 2.163032571474711

Epoch: 6| Step: 12
Training loss: 0.23251983523368835
Validation loss: 2.171884059906006

Epoch: 6| Step: 13
Training loss: 0.39211708307266235
Validation loss: 2.179572820663452

Epoch: 450| Step: 0
Training loss: 0.27659371495246887
Validation loss: 2.172065714995066

Epoch: 6| Step: 1
Training loss: 0.25278598070144653
Validation loss: 2.1326202948888144

Epoch: 6| Step: 2
Training loss: 0.3189311921596527
Validation loss: 2.160284161567688

Epoch: 6| Step: 3
Training loss: 0.41535013914108276
Validation loss: 2.1461181640625

Epoch: 6| Step: 4
Training loss: 0.4100368618965149
Validation loss: 2.2058627009391785

Epoch: 6| Step: 5
Training loss: 0.19434711337089539
Validation loss: 2.2055585185686746

Epoch: 6| Step: 6
Training loss: 0.20437678694725037
Validation loss: 2.192873160044352

Epoch: 6| Step: 7
Training loss: 0.8334860801696777
Validation loss: 2.143304189046224

Epoch: 6| Step: 8
Training loss: 0.25408241152763367
Validation loss: 2.1879202723503113

Epoch: 6| Step: 9
Training loss: 0.30058467388153076
Validation loss: 2.1592902541160583

Epoch: 6| Step: 10
Training loss: 0.3742855191230774
Validation loss: 2.2054656346639

Epoch: 6| Step: 11
Training loss: 0.3218037486076355
Validation loss: 2.218518058458964

Epoch: 6| Step: 12
Training loss: 0.22554510831832886
Validation loss: 2.2222781777381897

Epoch: 6| Step: 13
Training loss: 0.755100667476654
Validation loss: 2.1709886391957602

Epoch: 451| Step: 0
Training loss: 0.278634250164032
Validation loss: 2.1612828175226846

Epoch: 6| Step: 1
Training loss: 0.3391885459423065
Validation loss: 2.1711816787719727

Epoch: 6| Step: 2
Training loss: 0.37713682651519775
Validation loss: 2.184499224026998

Epoch: 6| Step: 3
Training loss: 0.5657365322113037
Validation loss: 2.2050271232922873

Epoch: 6| Step: 4
Training loss: 0.21730519831180573
Validation loss: 2.180796802043915

Epoch: 6| Step: 5
Training loss: 0.3010735511779785
Validation loss: 2.2175363898277283

Epoch: 6| Step: 6
Training loss: 0.40059134364128113
Validation loss: 2.225233733654022

Epoch: 6| Step: 7
Training loss: 0.36204463243484497
Validation loss: 2.2270403107007346

Epoch: 6| Step: 8
Training loss: 0.2790054380893707
Validation loss: 2.176083743572235

Epoch: 6| Step: 9
Training loss: 0.32559168338775635
Validation loss: 2.1632755200068154

Epoch: 6| Step: 10
Training loss: 0.5907067060470581
Validation loss: 2.1641376415888467

Epoch: 6| Step: 11
Training loss: 0.6655263900756836
Validation loss: 2.1755202809969583

Epoch: 6| Step: 12
Training loss: 0.5728497505187988
Validation loss: 2.1466139356295266

Epoch: 6| Step: 13
Training loss: 0.2470133900642395
Validation loss: 2.1553561091423035

Epoch: 452| Step: 0
Training loss: 0.24627576768398285
Validation loss: 2.111147403717041

Epoch: 6| Step: 1
Training loss: 0.46014952659606934
Validation loss: 2.1544483304023743

Epoch: 6| Step: 2
Training loss: 0.37597525119781494
Validation loss: 2.1975366274515786

Epoch: 6| Step: 3
Training loss: 0.4955674409866333
Validation loss: 2.192757805188497

Epoch: 6| Step: 4
Training loss: 0.3950578570365906
Validation loss: 2.1946776111920676

Epoch: 6| Step: 5
Training loss: 0.31467705965042114
Validation loss: 2.1976831356684365

Epoch: 6| Step: 6
Training loss: 0.31245750188827515
Validation loss: 2.167168438434601

Epoch: 6| Step: 7
Training loss: 0.3711068034172058
Validation loss: 2.1944625775019326

Epoch: 6| Step: 8
Training loss: 0.25243711471557617
Validation loss: 2.1831199328104653

Epoch: 6| Step: 9
Training loss: 0.47288185358047485
Validation loss: 2.165189544359843

Epoch: 6| Step: 10
Training loss: 0.30583471059799194
Validation loss: 2.1831425428390503

Epoch: 6| Step: 11
Training loss: 0.5548201203346252
Validation loss: 2.119515875975291

Epoch: 6| Step: 12
Training loss: 0.7087947130203247
Validation loss: 2.225348929564158

Epoch: 6| Step: 13
Training loss: 0.21733111143112183
Validation loss: 2.1802229285240173

Epoch: 453| Step: 0
Training loss: 0.32123813033103943
Validation loss: 2.21256947517395

Epoch: 6| Step: 1
Training loss: 0.5100634098052979
Validation loss: 2.2031186620394387

Epoch: 6| Step: 2
Training loss: 0.3538222312927246
Validation loss: 2.203145901362101

Epoch: 6| Step: 3
Training loss: 0.2065407782793045
Validation loss: 2.1117255290349326

Epoch: 6| Step: 4
Training loss: 0.3857346475124359
Validation loss: 2.2005197604497275

Epoch: 6| Step: 5
Training loss: 0.348385214805603
Validation loss: 2.1493728160858154

Epoch: 6| Step: 6
Training loss: 0.3826858699321747
Validation loss: 2.1725452542304993

Epoch: 6| Step: 7
Training loss: 0.39490455389022827
Validation loss: 2.1842083732287088

Epoch: 6| Step: 8
Training loss: 0.2736174464225769
Validation loss: 2.224743982156118

Epoch: 6| Step: 9
Training loss: 0.2909473776817322
Validation loss: 2.180404484272003

Epoch: 6| Step: 10
Training loss: 0.44070708751678467
Validation loss: 2.1368017196655273

Epoch: 6| Step: 11
Training loss: 0.2653181850910187
Validation loss: 2.1897109945615134

Epoch: 6| Step: 12
Training loss: 0.7373177409172058
Validation loss: 2.2081187963485718

Epoch: 6| Step: 13
Training loss: 0.2693115472793579
Validation loss: 2.2387402455012

Epoch: 454| Step: 0
Training loss: 0.3224075436592102
Validation loss: 2.156684100627899

Epoch: 6| Step: 1
Training loss: 0.22682540118694305
Validation loss: 2.161501963933309

Epoch: 6| Step: 2
Training loss: 0.30661487579345703
Validation loss: 2.1716575225194297

Epoch: 6| Step: 3
Training loss: 0.7585530281066895
Validation loss: 2.1796345114707947

Epoch: 6| Step: 4
Training loss: 0.31239399313926697
Validation loss: 2.1629584232966104

Epoch: 6| Step: 5
Training loss: 0.25414425134658813
Validation loss: 2.1657141049702964

Epoch: 6| Step: 6
Training loss: 0.19233444333076477
Validation loss: 2.1761162678400674

Epoch: 6| Step: 7
Training loss: 0.21657153964042664
Validation loss: 2.1828773021698

Epoch: 6| Step: 8
Training loss: 0.3089263141155243
Validation loss: 2.201574663321177

Epoch: 6| Step: 9
Training loss: 0.2627938985824585
Validation loss: 2.1339845061302185

Epoch: 6| Step: 10
Training loss: 0.43489980697631836
Validation loss: 2.1513506174087524

Epoch: 6| Step: 11
Training loss: 0.5499112010002136
Validation loss: 2.1643845240275064

Epoch: 6| Step: 12
Training loss: 0.8592684268951416
Validation loss: 2.1789535681406655

Epoch: 6| Step: 13
Training loss: 0.44435200095176697
Validation loss: 2.205517371495565

Epoch: 455| Step: 0
Training loss: 0.44037172198295593
Validation loss: 2.1743424336115518

Epoch: 6| Step: 1
Training loss: 0.3428799510002136
Validation loss: 2.2060264348983765

Epoch: 6| Step: 2
Training loss: 0.35829615592956543
Validation loss: 2.13658207654953

Epoch: 6| Step: 3
Training loss: 0.38728636503219604
Validation loss: 2.166370471318563

Epoch: 6| Step: 4
Training loss: 0.3431354761123657
Validation loss: 2.1604005694389343

Epoch: 6| Step: 5
Training loss: 0.16300641000270844
Validation loss: 2.201181491216024

Epoch: 6| Step: 6
Training loss: 0.7792484760284424
Validation loss: 2.1972909967104592

Epoch: 6| Step: 7
Training loss: 0.2296181470155716
Validation loss: 2.190852463245392

Epoch: 6| Step: 8
Training loss: 0.620790421962738
Validation loss: 2.2299728790918985

Epoch: 6| Step: 9
Training loss: 0.351346880197525
Validation loss: 2.1724583903948465

Epoch: 6| Step: 10
Training loss: 0.6441032886505127
Validation loss: 2.170187850793203

Epoch: 6| Step: 11
Training loss: 0.2731418013572693
Validation loss: 2.126728117465973

Epoch: 6| Step: 12
Training loss: 0.19651703536510468
Validation loss: 2.2268497546513877

Epoch: 6| Step: 13
Training loss: 0.2672213912010193
Validation loss: 2.1641976833343506

Epoch: 456| Step: 0
Training loss: 0.7549400329589844
Validation loss: 2.1306958397229514

Epoch: 6| Step: 1
Training loss: 0.5564329624176025
Validation loss: 2.127149005730947

Epoch: 6| Step: 2
Training loss: 0.2594432234764099
Validation loss: 2.1346591909726462

Epoch: 6| Step: 3
Training loss: 0.42249441146850586
Validation loss: 2.2058961391448975

Epoch: 6| Step: 4
Training loss: 0.2954600155353546
Validation loss: 2.222350319226583

Epoch: 6| Step: 5
Training loss: 0.24214152991771698
Validation loss: 2.2083933353424072

Epoch: 6| Step: 6
Training loss: 0.29003721475601196
Validation loss: 2.212917665640513

Epoch: 6| Step: 7
Training loss: 0.35660091042518616
Validation loss: 2.178479790687561

Epoch: 6| Step: 8
Training loss: 0.3172744810581207
Validation loss: 2.2324047088623047

Epoch: 6| Step: 9
Training loss: 0.3325868248939514
Validation loss: 2.1859540740648904

Epoch: 6| Step: 10
Training loss: 0.3229486346244812
Validation loss: 2.188196857770284

Epoch: 6| Step: 11
Training loss: 0.3777715265750885
Validation loss: 2.125757892926534

Epoch: 6| Step: 12
Training loss: 0.4612041115760803
Validation loss: 2.1668031016985574

Epoch: 6| Step: 13
Training loss: 0.2915922999382019
Validation loss: 2.165971656640371

Epoch: 457| Step: 0
Training loss: 0.40125566720962524
Validation loss: 2.1650357643763223

Epoch: 6| Step: 1
Training loss: 0.22553737461566925
Validation loss: 2.181592027346293

Epoch: 6| Step: 2
Training loss: 0.3189522624015808
Validation loss: 2.1715776920318604

Epoch: 6| Step: 3
Training loss: 0.23832181096076965
Validation loss: 2.184109548727671

Epoch: 6| Step: 4
Training loss: 0.36676156520843506
Validation loss: 2.1671893199284873

Epoch: 6| Step: 5
Training loss: 0.31780457496643066
Validation loss: 2.1834867199261985

Epoch: 6| Step: 6
Training loss: 0.2837756872177124
Validation loss: 2.214820623397827

Epoch: 6| Step: 7
Training loss: 0.34936726093292236
Validation loss: 2.1608492136001587

Epoch: 6| Step: 8
Training loss: 0.3946041762828827
Validation loss: 2.142566680908203

Epoch: 6| Step: 9
Training loss: 0.3669581115245819
Validation loss: 2.210724353790283

Epoch: 6| Step: 10
Training loss: 0.8464944958686829
Validation loss: 2.15972771247228

Epoch: 6| Step: 11
Training loss: 0.234482079744339
Validation loss: 2.186365524927775

Epoch: 6| Step: 12
Training loss: 0.5920975208282471
Validation loss: 2.1768569151560464

Epoch: 6| Step: 13
Training loss: 0.2723231911659241
Validation loss: 2.1616130471229553

Epoch: 458| Step: 0
Training loss: 0.22804668545722961
Validation loss: 2.184736748536428

Epoch: 6| Step: 1
Training loss: 0.42773330211639404
Validation loss: 2.1919955015182495

Epoch: 6| Step: 2
Training loss: 0.2985355854034424
Validation loss: 2.178019861380259

Epoch: 6| Step: 3
Training loss: 0.26605212688446045
Validation loss: 2.208755671977997

Epoch: 6| Step: 4
Training loss: 0.3754262924194336
Validation loss: 2.1681674122810364

Epoch: 6| Step: 5
Training loss: 0.7233648300170898
Validation loss: 2.180134574572245

Epoch: 6| Step: 6
Training loss: 0.3503158986568451
Validation loss: 2.2008872628211975

Epoch: 6| Step: 7
Training loss: 0.46205344796180725
Validation loss: 2.1895599166552224

Epoch: 6| Step: 8
Training loss: 0.39025503396987915
Validation loss: 2.127490838368734

Epoch: 6| Step: 9
Training loss: 0.21956227719783783
Validation loss: 2.209229528903961

Epoch: 6| Step: 10
Training loss: 0.2492087483406067
Validation loss: 2.196387688318888

Epoch: 6| Step: 11
Training loss: 0.8356902003288269
Validation loss: 2.16688734292984

Epoch: 6| Step: 12
Training loss: 0.5536353588104248
Validation loss: 2.173904597759247

Epoch: 6| Step: 13
Training loss: 0.25594523549079895
Validation loss: 2.2153393228848777

Epoch: 459| Step: 0
Training loss: 0.2378140240907669
Validation loss: 2.2003751397132874

Epoch: 6| Step: 1
Training loss: 0.2985779643058777
Validation loss: 2.213679611682892

Epoch: 6| Step: 2
Training loss: 0.6113265156745911
Validation loss: 2.2119052410125732

Epoch: 6| Step: 3
Training loss: 0.33737653493881226
Validation loss: 2.2147819995880127

Epoch: 6| Step: 4
Training loss: 0.19682416319847107
Validation loss: 2.219648241996765

Epoch: 6| Step: 5
Training loss: 0.3033820390701294
Validation loss: 2.2435690561930337

Epoch: 6| Step: 6
Training loss: 0.5291937589645386
Validation loss: 2.1901931166648865

Epoch: 6| Step: 7
Training loss: 0.5701714754104614
Validation loss: 2.192511002222697

Epoch: 6| Step: 8
Training loss: 0.5577231049537659
Validation loss: 2.2413314978281655

Epoch: 6| Step: 9
Training loss: 0.33480268716812134
Validation loss: 2.151431938012441

Epoch: 6| Step: 10
Training loss: 0.3772576153278351
Validation loss: 2.189541737238566

Epoch: 6| Step: 11
Training loss: 0.3746671676635742
Validation loss: 2.1678117314974465

Epoch: 6| Step: 12
Training loss: 0.23052804172039032
Validation loss: 2.1961651841799417

Epoch: 6| Step: 13
Training loss: 0.18254287540912628
Validation loss: 2.182016134262085

Epoch: 460| Step: 0
Training loss: 0.3755756616592407
Validation loss: 2.1616341272989907

Epoch: 6| Step: 1
Training loss: 0.29454505443573
Validation loss: 2.1920799215634665

Epoch: 6| Step: 2
Training loss: 0.25423043966293335
Validation loss: 2.253355880578359

Epoch: 6| Step: 3
Training loss: 0.18908047676086426
Validation loss: 2.2162766059239707

Epoch: 6| Step: 4
Training loss: 0.23446102440357208
Validation loss: 2.2084331115086875

Epoch: 6| Step: 5
Training loss: 0.5786964893341064
Validation loss: 2.21223521232605

Epoch: 6| Step: 6
Training loss: 0.3785540461540222
Validation loss: 2.214232246081034

Epoch: 6| Step: 7
Training loss: 0.23111802339553833
Validation loss: 2.232472042242686

Epoch: 6| Step: 8
Training loss: 0.3086989223957062
Validation loss: 2.193058411280314

Epoch: 6| Step: 9
Training loss: 0.3061220347881317
Validation loss: 2.2197351654370627

Epoch: 6| Step: 10
Training loss: 0.7520281076431274
Validation loss: 2.1976453065872192

Epoch: 6| Step: 11
Training loss: 0.2637619078159332
Validation loss: 2.167573392391205

Epoch: 6| Step: 12
Training loss: 0.38042759895324707
Validation loss: 2.246487478415171

Epoch: 6| Step: 13
Training loss: 0.31318944692611694
Validation loss: 2.192027469476064

Epoch: 461| Step: 0
Training loss: 0.31224915385246277
Validation loss: 2.1624704599380493

Epoch: 6| Step: 1
Training loss: 0.2534636855125427
Validation loss: 2.200179934501648

Epoch: 6| Step: 2
Training loss: 0.35886597633361816
Validation loss: 2.1761980652809143

Epoch: 6| Step: 3
Training loss: 0.22988861799240112
Validation loss: 2.190133968989054

Epoch: 6| Step: 4
Training loss: 0.47567787766456604
Validation loss: 2.1890867153803506

Epoch: 6| Step: 5
Training loss: 0.39404964447021484
Validation loss: 2.154420475165049

Epoch: 6| Step: 6
Training loss: 0.3133268356323242
Validation loss: 2.2208934823671975

Epoch: 6| Step: 7
Training loss: 0.5267045497894287
Validation loss: 2.1938037474950156

Epoch: 6| Step: 8
Training loss: 0.2079317271709442
Validation loss: 2.1935180028279624

Epoch: 6| Step: 9
Training loss: 0.3484216332435608
Validation loss: 2.2202918330828347

Epoch: 6| Step: 10
Training loss: 0.5370600819587708
Validation loss: 2.2388028303782144

Epoch: 6| Step: 11
Training loss: 0.5563614368438721
Validation loss: 2.211283107598623

Epoch: 6| Step: 12
Training loss: 0.3060474395751953
Validation loss: 2.2400710582733154

Epoch: 6| Step: 13
Training loss: 0.7168864011764526
Validation loss: 2.151829481124878

Epoch: 462| Step: 0
Training loss: 0.39941149950027466
Validation loss: 2.178567409515381

Epoch: 6| Step: 1
Training loss: 0.6850682497024536
Validation loss: 2.235184987386068

Epoch: 6| Step: 2
Training loss: 0.3667609393596649
Validation loss: 2.1943851709365845

Epoch: 6| Step: 3
Training loss: 0.23874878883361816
Validation loss: 2.1906859477361045

Epoch: 6| Step: 4
Training loss: 0.2938185930252075
Validation loss: 2.2179189125696817

Epoch: 6| Step: 5
Training loss: 0.3044564127922058
Validation loss: 2.1606152256329856

Epoch: 6| Step: 6
Training loss: 0.22405385971069336
Validation loss: 2.1687897443771362

Epoch: 6| Step: 7
Training loss: 0.49403300881385803
Validation loss: 2.196052670478821

Epoch: 6| Step: 8
Training loss: 0.19171053171157837
Validation loss: 2.113927662372589

Epoch: 6| Step: 9
Training loss: 0.7700888514518738
Validation loss: 2.1721484859784446

Epoch: 6| Step: 10
Training loss: 0.37651658058166504
Validation loss: 2.1754330595334372

Epoch: 6| Step: 11
Training loss: 0.45492005348205566
Validation loss: 2.1984220345815024

Epoch: 6| Step: 12
Training loss: 0.2789044976234436
Validation loss: 2.189434587955475

Epoch: 6| Step: 13
Training loss: 0.367338091135025
Validation loss: 2.175296723842621

Epoch: 463| Step: 0
Training loss: 0.30600082874298096
Validation loss: 2.185220698515574

Epoch: 6| Step: 1
Training loss: 0.29097485542297363
Validation loss: 2.2176180283228555

Epoch: 6| Step: 2
Training loss: 0.5869464874267578
Validation loss: 2.2081135908762612

Epoch: 6| Step: 3
Training loss: 0.3654186427593231
Validation loss: 2.1869208415349326

Epoch: 6| Step: 4
Training loss: 0.2409730851650238
Validation loss: 2.1626619497934976

Epoch: 6| Step: 5
Training loss: 0.19705213606357574
Validation loss: 2.1721112926801047

Epoch: 6| Step: 6
Training loss: 0.244737446308136
Validation loss: 2.2141255338986716

Epoch: 6| Step: 7
Training loss: 0.21898257732391357
Validation loss: 2.2015562057495117

Epoch: 6| Step: 8
Training loss: 0.2700834572315216
Validation loss: 2.190469264984131

Epoch: 6| Step: 9
Training loss: 0.3738716244697571
Validation loss: 2.2355077266693115

Epoch: 6| Step: 10
Training loss: 0.2544938921928406
Validation loss: 2.233803629875183

Epoch: 6| Step: 11
Training loss: 0.828228235244751
Validation loss: 2.1892119447390237

Epoch: 6| Step: 12
Training loss: 0.41463786363601685
Validation loss: 2.124142269293467

Epoch: 6| Step: 13
Training loss: 0.3028125464916229
Validation loss: 2.258106311162313

Epoch: 464| Step: 0
Training loss: 0.3051491975784302
Validation loss: 2.205725153287252

Epoch: 6| Step: 1
Training loss: 0.3479071855545044
Validation loss: 2.1734821796417236

Epoch: 6| Step: 2
Training loss: 0.4682044982910156
Validation loss: 2.2062313556671143

Epoch: 6| Step: 3
Training loss: 0.28889763355255127
Validation loss: 2.186555584271749

Epoch: 6| Step: 4
Training loss: 0.36236411333084106
Validation loss: 2.124362667401632

Epoch: 6| Step: 5
Training loss: 0.30179262161254883
Validation loss: 2.153696894645691

Epoch: 6| Step: 6
Training loss: 0.30568817257881165
Validation loss: 2.158134122689565

Epoch: 6| Step: 7
Training loss: 0.20617610216140747
Validation loss: 2.214806338151296

Epoch: 6| Step: 8
Training loss: 0.2508339583873749
Validation loss: 2.220531404018402

Epoch: 6| Step: 9
Training loss: 0.18370433151721954
Validation loss: 2.1851901610692344

Epoch: 6| Step: 10
Training loss: 0.2621943950653076
Validation loss: 2.1349883476893106

Epoch: 6| Step: 11
Training loss: 0.42326870560646057
Validation loss: 2.1791125337282815

Epoch: 6| Step: 12
Training loss: 0.6605592966079712
Validation loss: 2.1859846115112305

Epoch: 6| Step: 13
Training loss: 0.2585247755050659
Validation loss: 2.1792410612106323

Epoch: 465| Step: 0
Training loss: 0.2681189775466919
Validation loss: 2.189545452594757

Epoch: 6| Step: 1
Training loss: 0.33671334385871887
Validation loss: 2.1523263454437256

Epoch: 6| Step: 2
Training loss: 0.22567325830459595
Validation loss: 2.130404849847158

Epoch: 6| Step: 3
Training loss: 0.3595792055130005
Validation loss: 2.1333437959353128

Epoch: 6| Step: 4
Training loss: 0.3638782799243927
Validation loss: 2.198729236920675

Epoch: 6| Step: 5
Training loss: 0.43561193346977234
Validation loss: 2.1703940629959106

Epoch: 6| Step: 6
Training loss: 0.2744818925857544
Validation loss: 2.2106170058250427

Epoch: 6| Step: 7
Training loss: 0.24373653531074524
Validation loss: 2.1100284457206726

Epoch: 6| Step: 8
Training loss: 0.38005882501602173
Validation loss: 2.1712680657704673

Epoch: 6| Step: 9
Training loss: 0.16529932618141174
Validation loss: 2.2114429275194802

Epoch: 6| Step: 10
Training loss: 0.382926344871521
Validation loss: 2.2209452589352927

Epoch: 6| Step: 11
Training loss: 0.2654256820678711
Validation loss: 2.1615693171819053

Epoch: 6| Step: 12
Training loss: 1.0255993604660034
Validation loss: 2.1991941332817078

Epoch: 6| Step: 13
Training loss: 0.36589187383651733
Validation loss: 2.2317957679430642

Epoch: 466| Step: 0
Training loss: 0.2099756896495819
Validation loss: 2.1891645590464273

Epoch: 6| Step: 1
Training loss: 0.3291187286376953
Validation loss: 2.1975084145863852

Epoch: 6| Step: 2
Training loss: 0.19033491611480713
Validation loss: 2.1425704956054688

Epoch: 6| Step: 3
Training loss: 0.27242565155029297
Validation loss: 2.2289228240648904

Epoch: 6| Step: 4
Training loss: 0.3135794401168823
Validation loss: 2.220697542031606

Epoch: 6| Step: 5
Training loss: 0.20973429083824158
Validation loss: 2.174666464328766

Epoch: 6| Step: 6
Training loss: 0.6542947292327881
Validation loss: 2.1960694789886475

Epoch: 6| Step: 7
Training loss: 0.15206511318683624
Validation loss: 2.1899853547414145

Epoch: 6| Step: 8
Training loss: 0.25773343443870544
Validation loss: 2.1758813858032227

Epoch: 6| Step: 9
Training loss: 0.5670071244239807
Validation loss: 2.2211960554122925

Epoch: 6| Step: 10
Training loss: 0.34797319769859314
Validation loss: 2.146587908267975

Epoch: 6| Step: 11
Training loss: 0.7036758065223694
Validation loss: 2.1978752613067627

Epoch: 6| Step: 12
Training loss: 0.2988777160644531
Validation loss: 2.1651938557624817

Epoch: 6| Step: 13
Training loss: 0.5883054733276367
Validation loss: 2.206695338090261

Epoch: 467| Step: 0
Training loss: 0.36644208431243896
Validation loss: 2.2058012882868447

Epoch: 6| Step: 1
Training loss: 0.2394987940788269
Validation loss: 2.188908874988556

Epoch: 6| Step: 2
Training loss: 0.7157371044158936
Validation loss: 2.1806596517562866

Epoch: 6| Step: 3
Training loss: 0.3869156837463379
Validation loss: 2.185036579767863

Epoch: 6| Step: 4
Training loss: 0.5005558729171753
Validation loss: 2.180376966794332

Epoch: 6| Step: 5
Training loss: 0.41902682185173035
Validation loss: 2.1966413656870523

Epoch: 6| Step: 6
Training loss: 0.33768409490585327
Validation loss: 2.2196777860323587

Epoch: 6| Step: 7
Training loss: 0.4910522401332855
Validation loss: 2.207821329434713

Epoch: 6| Step: 8
Training loss: 0.3896253705024719
Validation loss: 2.1928154627482095

Epoch: 6| Step: 9
Training loss: 0.3897518515586853
Validation loss: 2.163884242375692

Epoch: 6| Step: 10
Training loss: 0.23895573616027832
Validation loss: 2.156532347202301

Epoch: 6| Step: 11
Training loss: 0.28573864698410034
Validation loss: 2.1398224433263144

Epoch: 6| Step: 12
Training loss: 0.22963830828666687
Validation loss: 2.1643741130828857

Epoch: 6| Step: 13
Training loss: 0.39439645409584045
Validation loss: 2.190372625986735

Epoch: 468| Step: 0
Training loss: 0.42538559436798096
Validation loss: 2.19561775525411

Epoch: 6| Step: 1
Training loss: 0.45972681045532227
Validation loss: 2.190969924132029

Epoch: 6| Step: 2
Training loss: 0.26268020272254944
Validation loss: 2.210086484750112

Epoch: 6| Step: 3
Training loss: 0.31094247102737427
Validation loss: 2.183157523473104

Epoch: 6| Step: 4
Training loss: 0.4113585650920868
Validation loss: 2.173725644747416

Epoch: 6| Step: 5
Training loss: 0.3087213933467865
Validation loss: 2.1741454799969993

Epoch: 6| Step: 6
Training loss: 0.34645432233810425
Validation loss: 2.130573332309723

Epoch: 6| Step: 7
Training loss: 0.26644787192344666
Validation loss: 2.155401090780894

Epoch: 6| Step: 8
Training loss: 0.42162612080574036
Validation loss: 2.167586863040924

Epoch: 6| Step: 9
Training loss: 0.24642236530780792
Validation loss: 2.1809046864509583

Epoch: 6| Step: 10
Training loss: 0.20784485340118408
Validation loss: 2.1806551814079285

Epoch: 6| Step: 11
Training loss: 0.2815701961517334
Validation loss: 2.196667194366455

Epoch: 6| Step: 12
Training loss: 0.22011540830135345
Validation loss: 2.219645321369171

Epoch: 6| Step: 13
Training loss: 0.830902636051178
Validation loss: 2.17375240723292

Epoch: 469| Step: 0
Training loss: 0.4361804127693176
Validation loss: 2.1931643883387246

Epoch: 6| Step: 1
Training loss: 0.3257424533367157
Validation loss: 2.1876745223999023

Epoch: 6| Step: 2
Training loss: 0.21157371997833252
Validation loss: 2.222068746884664

Epoch: 6| Step: 3
Training loss: 0.32647591829299927
Validation loss: 2.198121726512909

Epoch: 6| Step: 4
Training loss: 0.3264068365097046
Validation loss: 2.2653629382451377

Epoch: 6| Step: 5
Training loss: 0.43681764602661133
Validation loss: 2.185182491938273

Epoch: 6| Step: 6
Training loss: 0.21953906118869781
Validation loss: 2.186026692390442

Epoch: 6| Step: 7
Training loss: 0.46811428666114807
Validation loss: 2.183940052986145

Epoch: 6| Step: 8
Training loss: 0.252332478761673
Validation loss: 2.201058109601339

Epoch: 6| Step: 9
Training loss: 0.6874250769615173
Validation loss: 2.1984613140424094

Epoch: 6| Step: 10
Training loss: 0.6190259456634521
Validation loss: 2.2393295764923096

Epoch: 6| Step: 11
Training loss: 0.2751561403274536
Validation loss: 2.2697266141573587

Epoch: 6| Step: 12
Training loss: 0.46553853154182434
Validation loss: 2.2402873039245605

Epoch: 6| Step: 13
Training loss: 0.35387545824050903
Validation loss: 2.2713676293691

Epoch: 470| Step: 0
Training loss: 0.5831584930419922
Validation loss: 2.2794928749402366

Epoch: 6| Step: 1
Training loss: 0.2590521574020386
Validation loss: 2.186685343583425

Epoch: 6| Step: 2
Training loss: 0.17707836627960205
Validation loss: 2.1751002271970115

Epoch: 6| Step: 3
Training loss: 0.4558921754360199
Validation loss: 2.1366897026697793

Epoch: 6| Step: 4
Training loss: 0.48658424615859985
Validation loss: 2.145761410395304

Epoch: 6| Step: 5
Training loss: 0.5941836833953857
Validation loss: 2.169248898824056

Epoch: 6| Step: 6
Training loss: 0.7679417729377747
Validation loss: 2.178815007209778

Epoch: 6| Step: 7
Training loss: 0.4136631488800049
Validation loss: 2.138525108496348

Epoch: 6| Step: 8
Training loss: 0.3605445921421051
Validation loss: 2.189013421535492

Epoch: 6| Step: 9
Training loss: 0.47075438499450684
Validation loss: 2.148863693078359

Epoch: 6| Step: 10
Training loss: 0.41898012161254883
Validation loss: 2.1993874311447144

Epoch: 6| Step: 11
Training loss: 0.2858712077140808
Validation loss: 2.2391175031661987

Epoch: 6| Step: 12
Training loss: 0.4149931073188782
Validation loss: 2.2113657792409263

Epoch: 6| Step: 13
Training loss: 0.36408740282058716
Validation loss: 2.25811505317688

Epoch: 471| Step: 0
Training loss: 0.32038217782974243
Validation loss: 2.2394317388534546

Epoch: 6| Step: 1
Training loss: 0.29134252667427063
Validation loss: 2.2660229404767356

Epoch: 6| Step: 2
Training loss: 0.48870301246643066
Validation loss: 2.1579232017199197

Epoch: 6| Step: 3
Training loss: 0.18730492889881134
Validation loss: 2.1748336950937905

Epoch: 6| Step: 4
Training loss: 0.1597943753004074
Validation loss: 2.225376089413961

Epoch: 6| Step: 5
Training loss: 0.25706589221954346
Validation loss: 2.176450947920481

Epoch: 6| Step: 6
Training loss: 0.6993021368980408
Validation loss: 2.165192206700643

Epoch: 6| Step: 7
Training loss: 0.40569746494293213
Validation loss: 2.199259122212728

Epoch: 6| Step: 8
Training loss: 0.49370187520980835
Validation loss: 2.111002246538798

Epoch: 6| Step: 9
Training loss: 0.37569957971572876
Validation loss: 2.2382689317067466

Epoch: 6| Step: 10
Training loss: 0.27603596448898315
Validation loss: 2.232452074686686

Epoch: 6| Step: 11
Training loss: 0.3566834032535553
Validation loss: 2.2062005201975503

Epoch: 6| Step: 12
Training loss: 0.21854260563850403
Validation loss: 2.165395220120748

Epoch: 6| Step: 13
Training loss: 0.26367056369781494
Validation loss: 2.1919129888216653

Epoch: 472| Step: 0
Training loss: 0.6824780106544495
Validation loss: 2.1758257349332175

Epoch: 6| Step: 1
Training loss: 0.3979152739048004
Validation loss: 2.134088317553202

Epoch: 6| Step: 2
Training loss: 0.4092690050601959
Validation loss: 2.21173886458079

Epoch: 6| Step: 3
Training loss: 0.27078044414520264
Validation loss: 2.2630038460095725

Epoch: 6| Step: 4
Training loss: 0.4704677164554596
Validation loss: 2.1504290103912354

Epoch: 6| Step: 5
Training loss: 0.22562912106513977
Validation loss: 2.204002261161804

Epoch: 6| Step: 6
Training loss: 0.18139326572418213
Validation loss: 2.220484455426534

Epoch: 6| Step: 7
Training loss: 0.5433211922645569
Validation loss: 2.2085630297660828

Epoch: 6| Step: 8
Training loss: 0.5023636221885681
Validation loss: 2.165205637613932

Epoch: 6| Step: 9
Training loss: 0.25349974632263184
Validation loss: 2.2001787622769675

Epoch: 6| Step: 10
Training loss: 0.23495550453662872
Validation loss: 2.193072577317556

Epoch: 6| Step: 11
Training loss: 0.4378764033317566
Validation loss: 2.181988080342611

Epoch: 6| Step: 12
Training loss: 0.2580273747444153
Validation loss: 2.1920731465021768

Epoch: 6| Step: 13
Training loss: 0.5804189443588257
Validation loss: 2.1400422851244607

Epoch: 473| Step: 0
Training loss: 0.916528582572937
Validation loss: 2.2004404067993164

Epoch: 6| Step: 1
Training loss: 0.13838376104831696
Validation loss: 2.187302549680074

Epoch: 6| Step: 2
Training loss: 0.1788170039653778
Validation loss: 2.2239973545074463

Epoch: 6| Step: 3
Training loss: 0.3271980881690979
Validation loss: 2.2344863613446555

Epoch: 6| Step: 4
Training loss: 0.5138013362884521
Validation loss: 2.17292720079422

Epoch: 6| Step: 5
Training loss: 0.5685305595397949
Validation loss: 2.213318943977356

Epoch: 6| Step: 6
Training loss: 0.25421059131622314
Validation loss: 2.257672886053721

Epoch: 6| Step: 7
Training loss: 0.2822210192680359
Validation loss: 2.2154652873675027

Epoch: 6| Step: 8
Training loss: 0.3031332194805145
Validation loss: 2.157825291156769

Epoch: 6| Step: 9
Training loss: 0.3159457743167877
Validation loss: 2.209581116835276

Epoch: 6| Step: 10
Training loss: 0.23480358719825745
Validation loss: 2.178959290186564

Epoch: 6| Step: 11
Training loss: 0.31243377923965454
Validation loss: 2.159493843714396

Epoch: 6| Step: 12
Training loss: 0.2170574814081192
Validation loss: 2.228886524836222

Epoch: 6| Step: 13
Training loss: 0.18349426984786987
Validation loss: 2.232437868913015

Epoch: 474| Step: 0
Training loss: 0.35323452949523926
Validation loss: 2.169885277748108

Epoch: 6| Step: 1
Training loss: 0.2648703455924988
Validation loss: 2.229045033454895

Epoch: 6| Step: 2
Training loss: 0.2454259991645813
Validation loss: 2.206837773323059

Epoch: 6| Step: 3
Training loss: 0.38325899839401245
Validation loss: 2.2407655914624534

Epoch: 6| Step: 4
Training loss: 0.35502931475639343
Validation loss: 2.1918072501818338

Epoch: 6| Step: 5
Training loss: 0.3628510534763336
Validation loss: 2.2636237144470215

Epoch: 6| Step: 6
Training loss: 0.3645371198654175
Validation loss: 2.1903533339500427

Epoch: 6| Step: 7
Training loss: 0.47030943632125854
Validation loss: 2.2166173458099365

Epoch: 6| Step: 8
Training loss: 0.7386469841003418
Validation loss: 2.1652952829996743

Epoch: 6| Step: 9
Training loss: 0.4512348771095276
Validation loss: 2.1866406202316284

Epoch: 6| Step: 10
Training loss: 0.3096437454223633
Validation loss: 2.2217559019724527

Epoch: 6| Step: 11
Training loss: 0.5663050413131714
Validation loss: 2.152913232644399

Epoch: 6| Step: 12
Training loss: 0.2718711793422699
Validation loss: 2.2129187186559043

Epoch: 6| Step: 13
Training loss: 0.187034010887146
Validation loss: 2.2145472963651023

Epoch: 475| Step: 0
Training loss: 0.3957313299179077
Validation loss: 2.237984597682953

Epoch: 6| Step: 1
Training loss: 0.270122230052948
Validation loss: 2.177361170450846

Epoch: 6| Step: 2
Training loss: 0.29150718450546265
Validation loss: 2.232409119606018

Epoch: 6| Step: 3
Training loss: 0.2606602907180786
Validation loss: 2.2299954295158386

Epoch: 6| Step: 4
Training loss: 0.8004462718963623
Validation loss: 2.145051121711731

Epoch: 6| Step: 5
Training loss: 0.27349603176116943
Validation loss: 2.22441565990448

Epoch: 6| Step: 6
Training loss: 0.24856925010681152
Validation loss: 2.2179535627365112

Epoch: 6| Step: 7
Training loss: 0.3442978262901306
Validation loss: 2.1597529451052346

Epoch: 6| Step: 8
Training loss: 0.28036993741989136
Validation loss: 2.2000980377197266

Epoch: 6| Step: 9
Training loss: 0.5834782719612122
Validation loss: 2.2105791370073953

Epoch: 6| Step: 10
Training loss: 0.41888588666915894
Validation loss: 2.261300206184387

Epoch: 6| Step: 11
Training loss: 0.3676292896270752
Validation loss: 2.2052615880966187

Epoch: 6| Step: 12
Training loss: 0.3409173786640167
Validation loss: 2.221081793308258

Epoch: 6| Step: 13
Training loss: 0.18307070434093475
Validation loss: 2.206056217352549

Epoch: 476| Step: 0
Training loss: 0.21581444144248962
Validation loss: 2.2114725510279336

Epoch: 6| Step: 1
Training loss: 0.22020751237869263
Validation loss: 2.1953551967938743

Epoch: 6| Step: 2
Training loss: 0.17378810048103333
Validation loss: 2.1581658919652305

Epoch: 6| Step: 3
Training loss: 0.43688562512397766
Validation loss: 2.1937811772028604

Epoch: 6| Step: 4
Training loss: 0.3629542589187622
Validation loss: 2.182815651098887

Epoch: 6| Step: 5
Training loss: 1.0322755575180054
Validation loss: 2.20199316740036

Epoch: 6| Step: 6
Training loss: 0.2639833986759186
Validation loss: 2.1689270734786987

Epoch: 6| Step: 7
Training loss: 0.20430904626846313
Validation loss: 2.2210024992624917

Epoch: 6| Step: 8
Training loss: 0.36727237701416016
Validation loss: 2.172973871231079

Epoch: 6| Step: 9
Training loss: 0.2128722220659256
Validation loss: 2.193866193294525

Epoch: 6| Step: 10
Training loss: 0.47179898619651794
Validation loss: 2.1893795132637024

Epoch: 6| Step: 11
Training loss: 0.1854667067527771
Validation loss: 2.2106340328852334

Epoch: 6| Step: 12
Training loss: 0.21174944937229156
Validation loss: 2.216503858566284

Epoch: 6| Step: 13
Training loss: 0.2062852531671524
Validation loss: 2.2260093887646994

Epoch: 477| Step: 0
Training loss: 0.21006225049495697
Validation loss: 2.1753344933191934

Epoch: 6| Step: 1
Training loss: 0.4627593755722046
Validation loss: 2.2209931214650473

Epoch: 6| Step: 2
Training loss: 0.21545062959194183
Validation loss: 2.253854274749756

Epoch: 6| Step: 3
Training loss: 0.21560296416282654
Validation loss: 2.16335928440094

Epoch: 6| Step: 4
Training loss: 0.3222886025905609
Validation loss: 2.2466235955556235

Epoch: 6| Step: 5
Training loss: 0.3238966464996338
Validation loss: 2.228402058283488

Epoch: 6| Step: 6
Training loss: 0.45767778158187866
Validation loss: 2.2079381942749023

Epoch: 6| Step: 7
Training loss: 0.9362244606018066
Validation loss: 2.2210821509361267

Epoch: 6| Step: 8
Training loss: 0.3029167652130127
Validation loss: 2.244734982649485

Epoch: 6| Step: 9
Training loss: 0.23063334822654724
Validation loss: 2.2004910111427307

Epoch: 6| Step: 10
Training loss: 0.24293509125709534
Validation loss: 2.221620261669159

Epoch: 6| Step: 11
Training loss: 0.28085917234420776
Validation loss: 2.2115595936775208

Epoch: 6| Step: 12
Training loss: 0.5098109245300293
Validation loss: 2.2288896242777505

Epoch: 6| Step: 13
Training loss: 0.28230082988739014
Validation loss: 2.196515421072642

Epoch: 478| Step: 0
Training loss: 0.490611732006073
Validation loss: 2.2231563925743103

Epoch: 6| Step: 1
Training loss: 0.259921669960022
Validation loss: 2.197492003440857

Epoch: 6| Step: 2
Training loss: 0.30637282133102417
Validation loss: 2.21014670530955

Epoch: 6| Step: 3
Training loss: 0.24744954705238342
Validation loss: 2.2186050613721213

Epoch: 6| Step: 4
Training loss: 0.5072222352027893
Validation loss: 2.2288596828778586

Epoch: 6| Step: 5
Training loss: 0.21439731121063232
Validation loss: 2.2099366585413613

Epoch: 6| Step: 6
Training loss: 0.3634997606277466
Validation loss: 2.2254114747047424

Epoch: 6| Step: 7
Training loss: 0.28564968705177307
Validation loss: 2.2306572794914246

Epoch: 6| Step: 8
Training loss: 0.1389584243297577
Validation loss: 2.188468019167582

Epoch: 6| Step: 9
Training loss: 0.37149548530578613
Validation loss: 2.220766027768453

Epoch: 6| Step: 10
Training loss: 0.31081339716911316
Validation loss: 2.2006627917289734

Epoch: 6| Step: 11
Training loss: 0.3767947554588318
Validation loss: 2.212359925111135

Epoch: 6| Step: 12
Training loss: 0.6478946208953857
Validation loss: 2.212084690729777

Epoch: 6| Step: 13
Training loss: 0.2451094686985016
Validation loss: 2.1990152994791665

Epoch: 479| Step: 0
Training loss: 0.2011522501707077
Validation loss: 2.2555606961250305

Epoch: 6| Step: 1
Training loss: 0.296763151884079
Validation loss: 2.213545819123586

Epoch: 6| Step: 2
Training loss: 0.2916000485420227
Validation loss: 2.217677414417267

Epoch: 6| Step: 3
Training loss: 0.3909759521484375
Validation loss: 2.241289258003235

Epoch: 6| Step: 4
Training loss: 0.2731589078903198
Validation loss: 2.2205045024553933

Epoch: 6| Step: 5
Training loss: 0.23444300889968872
Validation loss: 2.208260198434194

Epoch: 6| Step: 6
Training loss: 0.31550154089927673
Validation loss: 2.216342866420746

Epoch: 6| Step: 7
Training loss: 0.18897902965545654
Validation loss: 2.125182886918386

Epoch: 6| Step: 8
Training loss: 0.47997140884399414
Validation loss: 2.275394320487976

Epoch: 6| Step: 9
Training loss: 0.4072962999343872
Validation loss: 2.183767875035604

Epoch: 6| Step: 10
Training loss: 0.6978762149810791
Validation loss: 2.1525248289108276

Epoch: 6| Step: 11
Training loss: 0.46539628505706787
Validation loss: 2.186044613520304

Epoch: 6| Step: 12
Training loss: 0.47753387689590454
Validation loss: 2.2375293970108032

Epoch: 6| Step: 13
Training loss: 0.18843555450439453
Validation loss: 2.209088901678721

Epoch: 480| Step: 0
Training loss: 0.26993611454963684
Validation loss: 2.210945169130961

Epoch: 6| Step: 1
Training loss: 0.4593392014503479
Validation loss: 2.1922107934951782

Epoch: 6| Step: 2
Training loss: 0.4852357804775238
Validation loss: 2.2161757548650107

Epoch: 6| Step: 3
Training loss: 0.2659495174884796
Validation loss: 2.223149617513021

Epoch: 6| Step: 4
Training loss: 0.3195432126522064
Validation loss: 2.214676837126414

Epoch: 6| Step: 5
Training loss: 0.15050628781318665
Validation loss: 2.2710602084795632

Epoch: 6| Step: 6
Training loss: 0.3979739844799042
Validation loss: 2.238969385623932

Epoch: 6| Step: 7
Training loss: 0.6109048128128052
Validation loss: 2.206048329671224

Epoch: 6| Step: 8
Training loss: 0.15376028418540955
Validation loss: 2.2087024251619973

Epoch: 6| Step: 9
Training loss: 0.30246520042419434
Validation loss: 2.215921918551127

Epoch: 6| Step: 10
Training loss: 0.2615737318992615
Validation loss: 2.17717578013738

Epoch: 6| Step: 11
Training loss: 0.4799017310142517
Validation loss: 2.220436950524648

Epoch: 6| Step: 12
Training loss: 0.22083131968975067
Validation loss: 2.212674339612325

Epoch: 6| Step: 13
Training loss: 0.4768502116203308
Validation loss: 2.2014609972635903

Epoch: 481| Step: 0
Training loss: 0.21647143363952637
Validation loss: 2.2520880897839866

Epoch: 6| Step: 1
Training loss: 0.22083862125873566
Validation loss: 2.2156386375427246

Epoch: 6| Step: 2
Training loss: 0.32677674293518066
Validation loss: 2.2532610297203064

Epoch: 6| Step: 3
Training loss: 0.8945660591125488
Validation loss: 2.218499481678009

Epoch: 6| Step: 4
Training loss: 0.3365403115749359
Validation loss: 2.162201166152954

Epoch: 6| Step: 5
Training loss: 0.286405086517334
Validation loss: 2.2068477471669516

Epoch: 6| Step: 6
Training loss: 0.38841938972473145
Validation loss: 2.1694974303245544

Epoch: 6| Step: 7
Training loss: 0.29519063234329224
Validation loss: 2.2200977007548013

Epoch: 6| Step: 8
Training loss: 0.17924639582633972
Validation loss: 2.176974972089132

Epoch: 6| Step: 9
Training loss: 0.38314932584762573
Validation loss: 2.2372852563858032

Epoch: 6| Step: 10
Training loss: 0.3973050117492676
Validation loss: 2.2067562143007913

Epoch: 6| Step: 11
Training loss: 0.42914897203445435
Validation loss: 2.2304012179374695

Epoch: 6| Step: 12
Training loss: 0.258417546749115
Validation loss: 2.2005790074666343

Epoch: 6| Step: 13
Training loss: 0.22984173893928528
Validation loss: 2.253194570541382

Epoch: 482| Step: 0
Training loss: 0.2627907693386078
Validation loss: 2.232226232687632

Epoch: 6| Step: 1
Training loss: 0.15845343470573425
Validation loss: 2.193633774916331

Epoch: 6| Step: 2
Training loss: 0.18772689998149872
Validation loss: 2.25343652566274

Epoch: 6| Step: 3
Training loss: 0.7180706858634949
Validation loss: 2.211920658747355

Epoch: 6| Step: 4
Training loss: 0.3284725546836853
Validation loss: 2.1859045028686523

Epoch: 6| Step: 5
Training loss: 0.3763190805912018
Validation loss: 2.251261750857035

Epoch: 6| Step: 6
Training loss: 0.1860787719488144
Validation loss: 2.251417597134908

Epoch: 6| Step: 7
Training loss: 0.3991655707359314
Validation loss: 2.211482842763265

Epoch: 6| Step: 8
Training loss: 0.3596169352531433
Validation loss: 2.2121381163597107

Epoch: 6| Step: 9
Training loss: 0.33071672916412354
Validation loss: 2.169362783432007

Epoch: 6| Step: 10
Training loss: 0.33334991335868835
Validation loss: 2.2145185470581055

Epoch: 6| Step: 11
Training loss: 0.44483357667922974
Validation loss: 2.2068925301233926

Epoch: 6| Step: 12
Training loss: 0.43132948875427246
Validation loss: 2.193719983100891

Epoch: 6| Step: 13
Training loss: 0.15145272016525269
Validation loss: 2.2200567722320557

Epoch: 483| Step: 0
Training loss: 0.5467386841773987
Validation loss: 2.1851131121317544

Epoch: 6| Step: 1
Training loss: 0.48720380663871765
Validation loss: 2.1984044114748635

Epoch: 6| Step: 2
Training loss: 0.448312908411026
Validation loss: 2.1669491728146872

Epoch: 6| Step: 3
Training loss: 0.20634478330612183
Validation loss: 2.170626918474833

Epoch: 6| Step: 4
Training loss: 0.32739871740341187
Validation loss: 2.2058269381523132

Epoch: 6| Step: 5
Training loss: 0.21931666135787964
Validation loss: 2.1827115615208945

Epoch: 6| Step: 6
Training loss: 0.2946532070636749
Validation loss: 2.2175569931666055

Epoch: 6| Step: 7
Training loss: 0.2954869270324707
Validation loss: 2.185251235961914

Epoch: 6| Step: 8
Training loss: 0.34004080295562744
Validation loss: 2.1704060435295105

Epoch: 6| Step: 9
Training loss: 0.28594136238098145
Validation loss: 2.19524077574412

Epoch: 6| Step: 10
Training loss: 0.22066417336463928
Validation loss: 2.217632790406545

Epoch: 6| Step: 11
Training loss: 0.6453250646591187
Validation loss: 2.177149514357249

Epoch: 6| Step: 12
Training loss: 0.3003021478652954
Validation loss: 2.1669912139574685

Epoch: 6| Step: 13
Training loss: 0.4056033492088318
Validation loss: 2.1628381609916687

Epoch: 484| Step: 0
Training loss: 0.2732553780078888
Validation loss: 2.20326429605484

Epoch: 6| Step: 1
Training loss: 0.28070956468582153
Validation loss: 2.2282304763793945

Epoch: 6| Step: 2
Training loss: 0.274142324924469
Validation loss: 2.2352089484532676

Epoch: 6| Step: 3
Training loss: 0.3592550754547119
Validation loss: 2.215510924657186

Epoch: 6| Step: 4
Training loss: 0.8052786588668823
Validation loss: 2.2177242437998452

Epoch: 6| Step: 5
Training loss: 0.3220076858997345
Validation loss: 2.1798144976298013

Epoch: 6| Step: 6
Training loss: 0.27283990383148193
Validation loss: 2.198414425055186

Epoch: 6| Step: 7
Training loss: 0.22946037352085114
Validation loss: 2.1786853671073914

Epoch: 6| Step: 8
Training loss: 0.3067701458930969
Validation loss: 2.1707801818847656

Epoch: 6| Step: 9
Training loss: 0.684390664100647
Validation loss: 2.208760221799215

Epoch: 6| Step: 10
Training loss: 0.25939327478408813
Validation loss: 2.193591376145681

Epoch: 6| Step: 11
Training loss: 0.2973101735115051
Validation loss: 2.1758118073145547

Epoch: 6| Step: 12
Training loss: 0.23993352055549622
Validation loss: 2.1918728351593018

Epoch: 6| Step: 13
Training loss: 0.19526278972625732
Validation loss: 2.1800737579663596

Epoch: 485| Step: 0
Training loss: 0.20808178186416626
Validation loss: 2.2169968485832214

Epoch: 6| Step: 1
Training loss: 0.3574156165122986
Validation loss: 2.21833872795105

Epoch: 6| Step: 2
Training loss: 0.44390442967414856
Validation loss: 2.1411497791608176

Epoch: 6| Step: 3
Training loss: 0.17999455332756042
Validation loss: 2.151262899239858

Epoch: 6| Step: 4
Training loss: 0.2820477783679962
Validation loss: 2.198458254337311

Epoch: 6| Step: 5
Training loss: 0.25791165232658386
Validation loss: 2.1612945397694907

Epoch: 6| Step: 6
Training loss: 0.3058795928955078
Validation loss: 2.1545804937680564

Epoch: 6| Step: 7
Training loss: 0.3499790132045746
Validation loss: 2.2186190088589988

Epoch: 6| Step: 8
Training loss: 0.450674444437027
Validation loss: 2.224611759185791

Epoch: 6| Step: 9
Training loss: 0.6296132802963257
Validation loss: 2.199558893839518

Epoch: 6| Step: 10
Training loss: 0.23381198942661285
Validation loss: 2.1603582302729287

Epoch: 6| Step: 11
Training loss: 0.3763408064842224
Validation loss: 2.1574069460233054

Epoch: 6| Step: 12
Training loss: 0.18640702962875366
Validation loss: 2.175269683202108

Epoch: 6| Step: 13
Training loss: 0.28889963030815125
Validation loss: 2.2145538528760276

Epoch: 486| Step: 0
Training loss: 0.25755608081817627
Validation loss: 2.131855845451355

Epoch: 6| Step: 1
Training loss: 0.18215563893318176
Validation loss: 2.1790977716445923

Epoch: 6| Step: 2
Training loss: 0.36608579754829407
Validation loss: 2.253898541132609

Epoch: 6| Step: 3
Training loss: 0.49704959988594055
Validation loss: 2.2189415295918784

Epoch: 6| Step: 4
Training loss: 0.6613715887069702
Validation loss: 2.240308860937754

Epoch: 6| Step: 5
Training loss: 0.2013532519340515
Validation loss: 2.2042356530825296

Epoch: 6| Step: 6
Training loss: 0.4003750681877136
Validation loss: 2.180772066116333

Epoch: 6| Step: 7
Training loss: 0.2687033712863922
Validation loss: 2.231083333492279

Epoch: 6| Step: 8
Training loss: 0.49846214056015015
Validation loss: 2.205402652422587

Epoch: 6| Step: 9
Training loss: 0.2787722945213318
Validation loss: 2.2067114313443503

Epoch: 6| Step: 10
Training loss: 0.2424735426902771
Validation loss: 2.19048273563385

Epoch: 6| Step: 11
Training loss: 0.4569830298423767
Validation loss: 2.18066668510437

Epoch: 6| Step: 12
Training loss: 0.30822110176086426
Validation loss: 2.1409945487976074

Epoch: 6| Step: 13
Training loss: 0.2770116329193115
Validation loss: 2.2378591895103455

Epoch: 487| Step: 0
Training loss: 0.2692790925502777
Validation loss: 2.2066619793574014

Epoch: 6| Step: 1
Training loss: 0.32325923442840576
Validation loss: 2.2571306228637695

Epoch: 6| Step: 2
Training loss: 0.4001632034778595
Validation loss: 2.215439756711324

Epoch: 6| Step: 3
Training loss: 0.35162150859832764
Validation loss: 2.202923278013865

Epoch: 6| Step: 4
Training loss: 0.29297393560409546
Validation loss: 2.213277538617452

Epoch: 6| Step: 5
Training loss: 0.3873274326324463
Validation loss: 2.1957900126775107

Epoch: 6| Step: 6
Training loss: 0.37568458914756775
Validation loss: 2.1585599184036255

Epoch: 6| Step: 7
Training loss: 0.29786184430122375
Validation loss: 2.156408747037252

Epoch: 6| Step: 8
Training loss: 0.3139941394329071
Validation loss: 2.228908677895864

Epoch: 6| Step: 9
Training loss: 0.3861258029937744
Validation loss: 2.202410340309143

Epoch: 6| Step: 10
Training loss: 0.19521558284759521
Validation loss: 2.1945353945096335

Epoch: 6| Step: 11
Training loss: 0.4436646103858948
Validation loss: 2.193474610646566

Epoch: 6| Step: 12
Training loss: 0.6191481947898865
Validation loss: 2.2115772565205893

Epoch: 6| Step: 13
Training loss: 0.1952235847711563
Validation loss: 2.160160462061564

Epoch: 488| Step: 0
Training loss: 0.3993130028247833
Validation loss: 2.2289004723230996

Epoch: 6| Step: 1
Training loss: 0.38970857858657837
Validation loss: 2.1691949566205344

Epoch: 6| Step: 2
Training loss: 0.36873096227645874
Validation loss: 2.1983180244763694

Epoch: 6| Step: 3
Training loss: 0.6441565752029419
Validation loss: 2.2206397453943887

Epoch: 6| Step: 4
Training loss: 0.19581244885921478
Validation loss: 2.181747853755951

Epoch: 6| Step: 5
Training loss: 0.21700015664100647
Validation loss: 2.167567253112793

Epoch: 6| Step: 6
Training loss: 0.4104986786842346
Validation loss: 2.1842636664708457

Epoch: 6| Step: 7
Training loss: 0.5729737877845764
Validation loss: 2.1715896129608154

Epoch: 6| Step: 8
Training loss: 0.27458667755126953
Validation loss: 2.2072166005770364

Epoch: 6| Step: 9
Training loss: 0.20086941123008728
Validation loss: 2.198828101158142

Epoch: 6| Step: 10
Training loss: 0.3228621482849121
Validation loss: 2.1952645579973855

Epoch: 6| Step: 11
Training loss: 0.19911310076713562
Validation loss: 2.169762214024862

Epoch: 6| Step: 12
Training loss: 0.19163759052753448
Validation loss: 2.2017911672592163

Epoch: 6| Step: 13
Training loss: 0.376076340675354
Validation loss: 2.190187652905782

Epoch: 489| Step: 0
Training loss: 0.3725939095020294
Validation loss: 2.2028329173723855

Epoch: 6| Step: 1
Training loss: 0.22140046954154968
Validation loss: 2.167977730433146

Epoch: 6| Step: 2
Training loss: 0.4302375316619873
Validation loss: 2.2006444533665976

Epoch: 6| Step: 3
Training loss: 0.34703826904296875
Validation loss: 2.180677811304728

Epoch: 6| Step: 4
Training loss: 0.7323851585388184
Validation loss: 2.1907885471979776

Epoch: 6| Step: 5
Training loss: 0.25225716829299927
Validation loss: 2.2113291025161743

Epoch: 6| Step: 6
Training loss: 0.32775819301605225
Validation loss: 2.216402769088745

Epoch: 6| Step: 7
Training loss: 0.2891315221786499
Validation loss: 2.2130744457244873

Epoch: 6| Step: 8
Training loss: 0.4262907803058624
Validation loss: 2.2013243238131204

Epoch: 6| Step: 9
Training loss: 0.3883756995201111
Validation loss: 2.1925816734631858

Epoch: 6| Step: 10
Training loss: 0.262265682220459
Validation loss: 2.1959611574808755

Epoch: 6| Step: 11
Training loss: 0.20334526896476746
Validation loss: 2.1601316928863525

Epoch: 6| Step: 12
Training loss: 0.29255443811416626
Validation loss: 2.2087029814720154

Epoch: 6| Step: 13
Training loss: 0.16471657156944275
Validation loss: 2.2463526725769043

Epoch: 490| Step: 0
Training loss: 0.24309496581554413
Validation loss: 2.1672715743382773

Epoch: 6| Step: 1
Training loss: 0.3159964978694916
Validation loss: 2.2055285771687827

Epoch: 6| Step: 2
Training loss: 0.4138493537902832
Validation loss: 2.190352121988932

Epoch: 6| Step: 3
Training loss: 0.16838738322257996
Validation loss: 2.1868799527486167

Epoch: 6| Step: 4
Training loss: 0.24757708609104156
Validation loss: 2.160514255364736

Epoch: 6| Step: 5
Training loss: 0.7678377032279968
Validation loss: 2.208577513694763

Epoch: 6| Step: 6
Training loss: 0.41490602493286133
Validation loss: 2.200356960296631

Epoch: 6| Step: 7
Training loss: 0.2951369285583496
Validation loss: 2.205244521299998

Epoch: 6| Step: 8
Training loss: 0.40960806608200073
Validation loss: 2.261686364809672

Epoch: 6| Step: 9
Training loss: 0.3064076900482178
Validation loss: 2.1964733799298606

Epoch: 6| Step: 10
Training loss: 0.40216970443725586
Validation loss: 2.1750686963399253

Epoch: 6| Step: 11
Training loss: 0.350712388753891
Validation loss: 2.173584441343943

Epoch: 6| Step: 12
Training loss: 0.23749059438705444
Validation loss: 2.200429062048594

Epoch: 6| Step: 13
Training loss: 0.2975291609764099
Validation loss: 2.2484742800394693

Epoch: 491| Step: 0
Training loss: 0.5142923593521118
Validation loss: 2.1930815974871316

Epoch: 6| Step: 1
Training loss: 0.2912599444389343
Validation loss: 2.2115392684936523

Epoch: 6| Step: 2
Training loss: 0.3810696601867676
Validation loss: 2.1563978592554727

Epoch: 6| Step: 3
Training loss: 0.19190868735313416
Validation loss: 2.236111283302307

Epoch: 6| Step: 4
Training loss: 0.16251423954963684
Validation loss: 2.225571036338806

Epoch: 6| Step: 5
Training loss: 0.4471377730369568
Validation loss: 2.1789066195487976

Epoch: 6| Step: 6
Training loss: 0.3040425777435303
Validation loss: 2.167948365211487

Epoch: 6| Step: 7
Training loss: 0.4244154095649719
Validation loss: 2.179254174232483

Epoch: 6| Step: 8
Training loss: 0.2898569107055664
Validation loss: 2.1726765433947244

Epoch: 6| Step: 9
Training loss: 0.17791476845741272
Validation loss: 2.185903231302897

Epoch: 6| Step: 10
Training loss: 0.9445798397064209
Validation loss: 2.166113475958506

Epoch: 6| Step: 11
Training loss: 0.3004881739616394
Validation loss: 2.20458984375

Epoch: 6| Step: 12
Training loss: 0.40911975502967834
Validation loss: 2.1847367684046426

Epoch: 6| Step: 13
Training loss: 0.28317973017692566
Validation loss: 2.1685508489608765

Epoch: 492| Step: 0
Training loss: 0.3618839383125305
Validation loss: 2.217184543609619

Epoch: 6| Step: 1
Training loss: 0.37843993306159973
Validation loss: 2.1677051981290183

Epoch: 6| Step: 2
Training loss: 0.277193158864975
Validation loss: 2.2241605520248413

Epoch: 6| Step: 3
Training loss: 0.43234166502952576
Validation loss: 2.1845977902412415

Epoch: 6| Step: 4
Training loss: 0.18671764433383942
Validation loss: 2.185218890508016

Epoch: 6| Step: 5
Training loss: 0.22358736395835876
Validation loss: 2.174626886844635

Epoch: 6| Step: 6
Training loss: 0.3347569704055786
Validation loss: 2.187683860460917

Epoch: 6| Step: 7
Training loss: 0.7478298544883728
Validation loss: 2.2002251744270325

Epoch: 6| Step: 8
Training loss: 0.23430293798446655
Validation loss: 2.1984821557998657

Epoch: 6| Step: 9
Training loss: 0.2076500952243805
Validation loss: 2.2507182161013284

Epoch: 6| Step: 10
Training loss: 0.18653574585914612
Validation loss: 2.1776346365610757

Epoch: 6| Step: 11
Training loss: 0.574609637260437
Validation loss: 2.212033232053121

Epoch: 6| Step: 12
Training loss: 0.20067119598388672
Validation loss: 2.1362727681795755

Epoch: 6| Step: 13
Training loss: 0.5020476579666138
Validation loss: 2.2157708207766214

Epoch: 493| Step: 0
Training loss: 0.6439659595489502
Validation loss: 2.2150718768437705

Epoch: 6| Step: 1
Training loss: 0.3407430350780487
Validation loss: 2.1856250365575156

Epoch: 6| Step: 2
Training loss: 0.14845937490463257
Validation loss: 2.208961466948191

Epoch: 6| Step: 3
Training loss: 0.5610513687133789
Validation loss: 2.2399097283681235

Epoch: 6| Step: 4
Training loss: 0.34366559982299805
Validation loss: 2.192434231440226

Epoch: 6| Step: 5
Training loss: 0.4453124403953552
Validation loss: 2.1515859564145408

Epoch: 6| Step: 6
Training loss: 0.19945146143436432
Validation loss: 2.1673699418703714

Epoch: 6| Step: 7
Training loss: 0.3093032240867615
Validation loss: 2.150061329205831

Epoch: 6| Step: 8
Training loss: 0.26260727643966675
Validation loss: 2.1869860092798867

Epoch: 6| Step: 9
Training loss: 0.40163642168045044
Validation loss: 2.221586585044861

Epoch: 6| Step: 10
Training loss: 0.2512558698654175
Validation loss: 2.1961326400438943

Epoch: 6| Step: 11
Training loss: 0.3315116763114929
Validation loss: 2.1860604087511697

Epoch: 6| Step: 12
Training loss: 0.5728542804718018
Validation loss: 2.1545196771621704

Epoch: 6| Step: 13
Training loss: 0.3123255968093872
Validation loss: 2.149156411488851

Epoch: 494| Step: 0
Training loss: 0.24789036810398102
Validation loss: 2.179033935070038

Epoch: 6| Step: 1
Training loss: 0.12045068293809891
Validation loss: 2.218445678551992

Epoch: 6| Step: 2
Training loss: 0.12720482051372528
Validation loss: 2.182247539361318

Epoch: 6| Step: 3
Training loss: 0.5780093669891357
Validation loss: 2.188182453314463

Epoch: 6| Step: 4
Training loss: 0.352115273475647
Validation loss: 2.2052505811055503

Epoch: 6| Step: 5
Training loss: 0.296949565410614
Validation loss: 2.1730127930641174

Epoch: 6| Step: 6
Training loss: 0.2767374515533447
Validation loss: 2.198391079902649

Epoch: 6| Step: 7
Training loss: 0.26034820079803467
Validation loss: 2.2033499677975974

Epoch: 6| Step: 8
Training loss: 0.18846262991428375
Validation loss: 2.210230767726898

Epoch: 6| Step: 9
Training loss: 0.22256013751029968
Validation loss: 2.1811986764272056

Epoch: 6| Step: 10
Training loss: 0.4735693335533142
Validation loss: 2.181192914644877

Epoch: 6| Step: 11
Training loss: 0.3150898814201355
Validation loss: 2.209848960240682

Epoch: 6| Step: 12
Training loss: 0.7877099514007568
Validation loss: 2.1762390534083047

Epoch: 6| Step: 13
Training loss: 0.3313186764717102
Validation loss: 2.236958086490631

Epoch: 495| Step: 0
Training loss: 0.35076186060905457
Validation loss: 2.187284310658773

Epoch: 6| Step: 1
Training loss: 0.48470377922058105
Validation loss: 2.179900864760081

Epoch: 6| Step: 2
Training loss: 0.31444236636161804
Validation loss: 2.1620116432507834

Epoch: 6| Step: 3
Training loss: 0.33662354946136475
Validation loss: 2.179970701535543

Epoch: 6| Step: 4
Training loss: 0.2856460213661194
Validation loss: 2.165641665458679

Epoch: 6| Step: 5
Training loss: 0.30429452657699585
Validation loss: 2.243418256441752

Epoch: 6| Step: 6
Training loss: 0.3170909881591797
Validation loss: 2.197730541229248

Epoch: 6| Step: 7
Training loss: 0.5946516990661621
Validation loss: 2.1924717823664346

Epoch: 6| Step: 8
Training loss: 0.5098792910575867
Validation loss: 2.1381839513778687

Epoch: 6| Step: 9
Training loss: 0.3581485450267792
Validation loss: 2.1845471262931824

Epoch: 6| Step: 10
Training loss: 0.2410777509212494
Validation loss: 2.2068514625231423

Epoch: 6| Step: 11
Training loss: 0.2082749307155609
Validation loss: 2.169439156850179

Epoch: 6| Step: 12
Training loss: 0.2759055197238922
Validation loss: 2.2177820007006326

Epoch: 6| Step: 13
Training loss: 0.24881921708583832
Validation loss: 2.2453425526618958

Epoch: 496| Step: 0
Training loss: 0.19256991147994995
Validation loss: 2.1660462617874146

Epoch: 6| Step: 1
Training loss: 0.19336408376693726
Validation loss: 2.234488030274709

Epoch: 6| Step: 2
Training loss: 0.2568146586418152
Validation loss: 2.185491700967153

Epoch: 6| Step: 3
Training loss: 0.25286442041397095
Validation loss: 2.23503186305364

Epoch: 6| Step: 4
Training loss: 0.3346533179283142
Validation loss: 2.1889048417409263

Epoch: 6| Step: 5
Training loss: 0.36916112899780273
Validation loss: 2.1649450063705444

Epoch: 6| Step: 6
Training loss: 0.2526289224624634
Validation loss: 2.1350855231285095

Epoch: 6| Step: 7
Training loss: 0.1572064757347107
Validation loss: 2.1853743195533752

Epoch: 6| Step: 8
Training loss: 0.10978060215711594
Validation loss: 2.2019442319869995

Epoch: 6| Step: 9
Training loss: 0.2536672353744507
Validation loss: 2.234553416570028

Epoch: 6| Step: 10
Training loss: 0.497149795293808
Validation loss: 2.2377477288246155

Epoch: 6| Step: 11
Training loss: 1.0823146104812622
Validation loss: 2.229755421479543

Epoch: 6| Step: 12
Training loss: 0.3370704650878906
Validation loss: 2.1626810431480408

Epoch: 6| Step: 13
Training loss: 0.3494768738746643
Validation loss: 2.1645647088686624

Epoch: 497| Step: 0
Training loss: 0.32305780053138733
Validation loss: 2.218572278817495

Epoch: 6| Step: 1
Training loss: 0.4041725993156433
Validation loss: 2.1730862061182656

Epoch: 6| Step: 2
Training loss: 0.23899951577186584
Validation loss: 2.207689086596171

Epoch: 6| Step: 3
Training loss: 0.30649733543395996
Validation loss: 2.213034907976786

Epoch: 6| Step: 4
Training loss: 0.32291263341903687
Validation loss: 2.1845303773880005

Epoch: 6| Step: 5
Training loss: 0.7431784868240356
Validation loss: 2.2073782881100974

Epoch: 6| Step: 6
Training loss: 0.7170183658599854
Validation loss: 2.217882295449575

Epoch: 6| Step: 7
Training loss: 0.25153428316116333
Validation loss: 2.22866952419281

Epoch: 6| Step: 8
Training loss: 0.5215656161308289
Validation loss: 2.2805296579996743

Epoch: 6| Step: 9
Training loss: 0.46287286281585693
Validation loss: 2.2486617962519326

Epoch: 6| Step: 10
Training loss: 0.3279153108596802
Validation loss: 2.237921178340912

Epoch: 6| Step: 11
Training loss: 0.22758468985557556
Validation loss: 2.221059044202169

Epoch: 6| Step: 12
Training loss: 0.3132902979850769
Validation loss: 2.2491565942764282

Epoch: 6| Step: 13
Training loss: 0.2880505323410034
Validation loss: 2.208152453104655

Epoch: 498| Step: 0
Training loss: 0.2736213207244873
Validation loss: 2.297338604927063

Epoch: 6| Step: 1
Training loss: 0.19975429773330688
Validation loss: 2.1711755792299905

Epoch: 6| Step: 2
Training loss: 0.38236719369888306
Validation loss: 2.2030011415481567

Epoch: 6| Step: 3
Training loss: 0.20046350359916687
Validation loss: 2.2187195420265198

Epoch: 6| Step: 4
Training loss: 0.7801987528800964
Validation loss: 2.2194793820381165

Epoch: 6| Step: 5
Training loss: 0.3744587004184723
Validation loss: 2.230444928010305

Epoch: 6| Step: 6
Training loss: 0.4651302099227905
Validation loss: 2.2204961578051248

Epoch: 6| Step: 7
Training loss: 0.34115591645240784
Validation loss: 2.2013649543126426

Epoch: 6| Step: 8
Training loss: 0.5895549058914185
Validation loss: 2.2013535300890603

Epoch: 6| Step: 9
Training loss: 0.2351073920726776
Validation loss: 2.1906410654385886

Epoch: 6| Step: 10
Training loss: 0.2997703552246094
Validation loss: 2.198136289914449

Epoch: 6| Step: 11
Training loss: 0.2960302233695984
Validation loss: 2.2042477130889893

Epoch: 6| Step: 12
Training loss: 0.32848939299583435
Validation loss: 2.182390789190928

Epoch: 6| Step: 13
Training loss: 0.24728283286094666
Validation loss: 2.1723108688990274

Epoch: 499| Step: 0
Training loss: 0.7264376878738403
Validation loss: 2.213263769944509

Epoch: 6| Step: 1
Training loss: 0.34216517210006714
Validation loss: 2.2087824741999307

Epoch: 6| Step: 2
Training loss: 0.5195552110671997
Validation loss: 2.219857851664225

Epoch: 6| Step: 3
Training loss: 0.3375832736492157
Validation loss: 2.206106106440226

Epoch: 6| Step: 4
Training loss: 0.30158495903015137
Validation loss: 2.208581566810608

Epoch: 6| Step: 5
Training loss: 0.2408931404352188
Validation loss: 2.2060356934865317

Epoch: 6| Step: 6
Training loss: 0.3017023503780365
Validation loss: 2.2330527702967324

Epoch: 6| Step: 7
Training loss: 0.4282999038696289
Validation loss: 2.237753450870514

Epoch: 6| Step: 8
Training loss: 0.22085757553577423
Validation loss: 2.266702731450399

Epoch: 6| Step: 9
Training loss: 0.3436792492866516
Validation loss: 2.187664051850637

Epoch: 6| Step: 10
Training loss: 0.23581308126449585
Validation loss: 2.215638359387716

Epoch: 6| Step: 11
Training loss: 0.17254036664962769
Validation loss: 2.2015503446261087

Epoch: 6| Step: 12
Training loss: 0.3265710175037384
Validation loss: 2.208151380221049

Epoch: 6| Step: 13
Training loss: 0.24699191749095917
Validation loss: 2.222728133201599

Epoch: 500| Step: 0
Training loss: 0.15912358462810516
Validation loss: 2.1815006136894226

Epoch: 6| Step: 1
Training loss: 0.351737916469574
Validation loss: 2.189989686012268

Epoch: 6| Step: 2
Training loss: 0.20237278938293457
Validation loss: 2.2060909469922385

Epoch: 6| Step: 3
Training loss: 0.18740391731262207
Validation loss: 2.234512527783712

Epoch: 6| Step: 4
Training loss: 0.6527628898620605
Validation loss: 2.22110915184021

Epoch: 6| Step: 5
Training loss: 0.24276098608970642
Validation loss: 2.2159039974212646

Epoch: 6| Step: 6
Training loss: 0.1625497043132782
Validation loss: 2.262631138165792

Epoch: 6| Step: 7
Training loss: 0.3183746933937073
Validation loss: 2.199857155481974

Epoch: 6| Step: 8
Training loss: 0.370994508266449
Validation loss: 2.208875060081482

Epoch: 6| Step: 9
Training loss: 0.29595160484313965
Validation loss: 2.1840025385220847

Epoch: 6| Step: 10
Training loss: 0.2890813946723938
Validation loss: 2.2043118476867676

Epoch: 6| Step: 11
Training loss: 0.3682311177253723
Validation loss: 2.1955686608950296

Epoch: 6| Step: 12
Training loss: 0.2551720142364502
Validation loss: 2.182833989461263

Epoch: 6| Step: 13
Training loss: 0.5444824695587158
Validation loss: 2.187232553958893

Epoch: 501| Step: 0
Training loss: 0.5106053352355957
Validation loss: 2.1852237383524575

Epoch: 6| Step: 1
Training loss: 0.4657670557498932
Validation loss: 2.210178017616272

Epoch: 6| Step: 2
Training loss: 0.19348445534706116
Validation loss: 2.2428523898124695

Epoch: 6| Step: 3
Training loss: 0.3940173387527466
Validation loss: 2.1911200881004333

Epoch: 6| Step: 4
Training loss: 0.2883146405220032
Validation loss: 2.2196909189224243

Epoch: 6| Step: 5
Training loss: 0.28805434703826904
Validation loss: 2.2212777535120645

Epoch: 6| Step: 6
Training loss: 0.35303157567977905
Validation loss: 2.2207919160525003

Epoch: 6| Step: 7
Training loss: 0.2742731273174286
Validation loss: 2.1988577842712402

Epoch: 6| Step: 8
Training loss: 0.27787572145462036
Validation loss: 2.2262951731681824

Epoch: 6| Step: 9
Training loss: 0.35482022166252136
Validation loss: 2.193323771158854

Epoch: 6| Step: 10
Training loss: 0.34863805770874023
Validation loss: 2.232084035873413

Epoch: 6| Step: 11
Training loss: 0.2857164144515991
Validation loss: 2.2190341552098594

Epoch: 6| Step: 12
Training loss: 0.919842004776001
Validation loss: 2.201036353905996

Epoch: 6| Step: 13
Training loss: 0.24759270250797272
Validation loss: 2.2479578852653503

Epoch: 502| Step: 0
Training loss: 0.19206492602825165
Validation loss: 2.2397088011105857

Epoch: 6| Step: 1
Training loss: 0.24824604392051697
Validation loss: 2.2509803771972656

Epoch: 6| Step: 2
Training loss: 0.3029559850692749
Validation loss: 2.2541697223981223

Epoch: 6| Step: 3
Training loss: 0.39435431361198425
Validation loss: 2.187977910041809

Epoch: 6| Step: 4
Training loss: 0.7216358780860901
Validation loss: 2.2567684253056846

Epoch: 6| Step: 5
Training loss: 0.30930638313293457
Validation loss: 2.2130483190218606

Epoch: 6| Step: 6
Training loss: 0.2735668420791626
Validation loss: 2.164099415143331

Epoch: 6| Step: 7
Training loss: 0.3147202134132385
Validation loss: 2.2208184202512107

Epoch: 6| Step: 8
Training loss: 0.26216405630111694
Validation loss: 2.1803354024887085

Epoch: 6| Step: 9
Training loss: 0.24641826748847961
Validation loss: 2.204710324605306

Epoch: 6| Step: 10
Training loss: 0.31564176082611084
Validation loss: 2.1891300479571023

Epoch: 6| Step: 11
Training loss: 0.26436513662338257
Validation loss: 2.2017958958943686

Epoch: 6| Step: 12
Training loss: 0.5594292879104614
Validation loss: 2.2235927979151406

Epoch: 6| Step: 13
Training loss: 0.4336942136287689
Validation loss: 2.254615306854248

Epoch: 503| Step: 0
Training loss: 0.12061005085706711
Validation loss: 2.2000818053881326

Epoch: 6| Step: 1
Training loss: 0.2810293138027191
Validation loss: 2.2150120536486306

Epoch: 6| Step: 2
Training loss: 0.3179283142089844
Validation loss: 2.185291608174642

Epoch: 6| Step: 3
Training loss: 0.3835257589817047
Validation loss: 2.2532979249954224

Epoch: 6| Step: 4
Training loss: 0.19358506798744202
Validation loss: 2.199222723642985

Epoch: 6| Step: 5
Training loss: 0.14379775524139404
Validation loss: 2.1891827980677285

Epoch: 6| Step: 6
Training loss: 0.17961713671684265
Validation loss: 2.184481422106425

Epoch: 6| Step: 7
Training loss: 0.22407767176628113
Validation loss: 2.1728179454803467

Epoch: 6| Step: 8
Training loss: 0.23270267248153687
Validation loss: 2.17727784315745

Epoch: 6| Step: 9
Training loss: 0.31004464626312256
Validation loss: 2.1758492986361184

Epoch: 6| Step: 10
Training loss: 0.4500781297683716
Validation loss: 2.222505768140157

Epoch: 6| Step: 11
Training loss: 0.3269820809364319
Validation loss: 2.2399070660273233

Epoch: 6| Step: 12
Training loss: 0.8154908418655396
Validation loss: 2.212980647881826

Epoch: 6| Step: 13
Training loss: 0.3981028199195862
Validation loss: 2.18210901816686

Epoch: 504| Step: 0
Training loss: 0.6027371287345886
Validation loss: 2.1751855611801147

Epoch: 6| Step: 1
Training loss: 0.76727694272995
Validation loss: 2.2221848567326865

Epoch: 6| Step: 2
Training loss: 0.2601161301136017
Validation loss: 2.216288765271505

Epoch: 6| Step: 3
Training loss: 0.3419201374053955
Validation loss: 2.183022658030192

Epoch: 6| Step: 4
Training loss: 0.3201257288455963
Validation loss: 2.2190635999043784

Epoch: 6| Step: 5
Training loss: 0.210492342710495
Validation loss: 2.2340780099232993

Epoch: 6| Step: 6
Training loss: 0.2698104977607727
Validation loss: 2.2292766769727073

Epoch: 6| Step: 7
Training loss: 0.3887101709842682
Validation loss: 2.2239334185918174

Epoch: 6| Step: 8
Training loss: 0.30295902490615845
Validation loss: 2.222474912802378

Epoch: 6| Step: 9
Training loss: 0.2952846884727478
Validation loss: 2.1758798956871033

Epoch: 6| Step: 10
Training loss: 0.6319997906684875
Validation loss: 2.18061625957489

Epoch: 6| Step: 11
Training loss: 0.16958585381507874
Validation loss: 2.2253376046816506

Epoch: 6| Step: 12
Training loss: 0.27723807096481323
Validation loss: 2.223206400871277

Epoch: 6| Step: 13
Training loss: 0.3252521753311157
Validation loss: 2.1916701594988504

Epoch: 505| Step: 0
Training loss: 0.24332714080810547
Validation loss: 2.2101727525393167

Epoch: 6| Step: 1
Training loss: 0.2290225625038147
Validation loss: 2.2075138092041016

Epoch: 6| Step: 2
Training loss: 0.2636564075946808
Validation loss: 2.1655742526054382

Epoch: 6| Step: 3
Training loss: 0.3971903622150421
Validation loss: 2.2211650609970093

Epoch: 6| Step: 4
Training loss: 0.2963600158691406
Validation loss: 2.189355790615082

Epoch: 6| Step: 5
Training loss: 0.33340054750442505
Validation loss: 2.2457990646362305

Epoch: 6| Step: 6
Training loss: 0.23167338967323303
Validation loss: 2.280709743499756

Epoch: 6| Step: 7
Training loss: 0.3581162095069885
Validation loss: 2.2735676765441895

Epoch: 6| Step: 8
Training loss: 0.6501455307006836
Validation loss: 2.18533863623937

Epoch: 6| Step: 9
Training loss: 0.23153197765350342
Validation loss: 2.2379374305407205

Epoch: 6| Step: 10
Training loss: 0.32237380743026733
Validation loss: 2.188078502813975

Epoch: 6| Step: 11
Training loss: 0.5160923600196838
Validation loss: 2.157867670059204

Epoch: 6| Step: 12
Training loss: 0.272346168756485
Validation loss: 2.245890498161316

Epoch: 6| Step: 13
Training loss: 0.6270239353179932
Validation loss: 2.162783145904541

Epoch: 506| Step: 0
Training loss: 0.22664688527584076
Validation loss: 2.2556009888648987

Epoch: 6| Step: 1
Training loss: 0.268097847700119
Validation loss: 2.165552775065104

Epoch: 6| Step: 2
Training loss: 0.22198736667633057
Validation loss: 2.2282625238100686

Epoch: 6| Step: 3
Training loss: 0.337683767080307
Validation loss: 2.238366405169169

Epoch: 6| Step: 4
Training loss: 0.2867913544178009
Validation loss: 2.208843688170115

Epoch: 6| Step: 5
Training loss: 0.17120443284511566
Validation loss: 2.225377877553304

Epoch: 6| Step: 6
Training loss: 0.46776407957077026
Validation loss: 2.2369985977808633

Epoch: 6| Step: 7
Training loss: 0.4308067560195923
Validation loss: 2.1747722228368125

Epoch: 6| Step: 8
Training loss: 0.7101100087165833
Validation loss: 2.25600798924764

Epoch: 6| Step: 9
Training loss: 0.37011295557022095
Validation loss: 2.234502832094828

Epoch: 6| Step: 10
Training loss: 0.26546427607536316
Validation loss: 2.164579768975576

Epoch: 6| Step: 11
Training loss: 0.2819569706916809
Validation loss: 2.2267377177874246

Epoch: 6| Step: 12
Training loss: 0.3453940749168396
Validation loss: 2.2364517052968345

Epoch: 6| Step: 13
Training loss: 0.20949740707874298
Validation loss: 2.1538466413815818

Epoch: 507| Step: 0
Training loss: 0.22819015383720398
Validation loss: 2.165571928024292

Epoch: 6| Step: 1
Training loss: 0.29153215885162354
Validation loss: 2.1795697013537088

Epoch: 6| Step: 2
Training loss: 0.5293939709663391
Validation loss: 2.1619271834691367

Epoch: 6| Step: 3
Training loss: 0.45370006561279297
Validation loss: 2.1803821325302124

Epoch: 6| Step: 4
Training loss: 0.26964128017425537
Validation loss: 2.1589680314064026

Epoch: 6| Step: 5
Training loss: 0.26956164836883545
Validation loss: 2.166531801223755

Epoch: 6| Step: 6
Training loss: 0.26032698154449463
Validation loss: 2.2094462513923645

Epoch: 6| Step: 7
Training loss: 0.3961479067802429
Validation loss: 2.174372752507528

Epoch: 6| Step: 8
Training loss: 0.830270528793335
Validation loss: 2.2135817209879556

Epoch: 6| Step: 9
Training loss: 0.5120878219604492
Validation loss: 2.213877578576406

Epoch: 6| Step: 10
Training loss: 0.5269027948379517
Validation loss: 2.213671843210856

Epoch: 6| Step: 11
Training loss: 0.22200441360473633
Validation loss: 2.168172915776571

Epoch: 6| Step: 12
Training loss: 0.17278681695461273
Validation loss: 2.222256084283193

Epoch: 6| Step: 13
Training loss: 0.36749517917633057
Validation loss: 2.1871477365493774

Epoch: 508| Step: 0
Training loss: 0.4118669331073761
Validation loss: 2.197554091612498

Epoch: 6| Step: 1
Training loss: 0.2285391241312027
Validation loss: 2.1893386443456015

Epoch: 6| Step: 2
Training loss: 0.255158007144928
Validation loss: 2.1553719639778137

Epoch: 6| Step: 3
Training loss: 0.7166919708251953
Validation loss: 2.1672478318214417

Epoch: 6| Step: 4
Training loss: 0.35486340522766113
Validation loss: 2.1911985278129578

Epoch: 6| Step: 5
Training loss: 0.3455612361431122
Validation loss: 2.1662644942601523

Epoch: 6| Step: 6
Training loss: 0.2208935022354126
Validation loss: 2.1927329897880554

Epoch: 6| Step: 7
Training loss: 0.21287614107131958
Validation loss: 2.218973696231842

Epoch: 6| Step: 8
Training loss: 0.36896729469299316
Validation loss: 2.2214579582214355

Epoch: 6| Step: 9
Training loss: 0.3503901958465576
Validation loss: 2.227967321872711

Epoch: 6| Step: 10
Training loss: 0.3808894753456116
Validation loss: 2.2475884556770325

Epoch: 6| Step: 11
Training loss: 0.3035793602466583
Validation loss: 2.216556708017985

Epoch: 6| Step: 12
Training loss: 0.2722108066082001
Validation loss: 2.246753454208374

Epoch: 6| Step: 13
Training loss: 0.18129903078079224
Validation loss: 2.185740848382314

Epoch: 509| Step: 0
Training loss: 0.17469027638435364
Validation loss: 2.2496398091316223

Epoch: 6| Step: 1
Training loss: 0.22764235734939575
Validation loss: 2.205087165037791

Epoch: 6| Step: 2
Training loss: 0.588716447353363
Validation loss: 2.190074384212494

Epoch: 6| Step: 3
Training loss: 0.24557477235794067
Validation loss: 2.1853176951408386

Epoch: 6| Step: 4
Training loss: 0.43304967880249023
Validation loss: 2.179651220639547

Epoch: 6| Step: 5
Training loss: 0.18495024740695953
Validation loss: 2.214826504389445

Epoch: 6| Step: 6
Training loss: 0.322494775056839
Validation loss: 2.231115221977234

Epoch: 6| Step: 7
Training loss: 0.3245457410812378
Validation loss: 2.1919735272725425

Epoch: 6| Step: 8
Training loss: 0.1957630217075348
Validation loss: 2.2157747944196067

Epoch: 6| Step: 9
Training loss: 0.25953978300094604
Validation loss: 2.200217684110006

Epoch: 6| Step: 10
Training loss: 0.5519447922706604
Validation loss: 2.2170820236206055

Epoch: 6| Step: 11
Training loss: 0.7694634199142456
Validation loss: 2.2493115663528442

Epoch: 6| Step: 12
Training loss: 0.2507973313331604
Validation loss: 2.2027424375216165

Epoch: 6| Step: 13
Training loss: 0.2256896197795868
Validation loss: 2.204437772432963

Epoch: 510| Step: 0
Training loss: 0.4773392975330353
Validation loss: 2.2203878362973533

Epoch: 6| Step: 1
Training loss: 0.6594311594963074
Validation loss: 2.2269684274991355

Epoch: 6| Step: 2
Training loss: 0.7151553630828857
Validation loss: 2.1893868843714395

Epoch: 6| Step: 3
Training loss: 0.26342064142227173
Validation loss: 2.1893171072006226

Epoch: 6| Step: 4
Training loss: 0.35923606157302856
Validation loss: 2.1876123348871865

Epoch: 6| Step: 5
Training loss: 0.24693909287452698
Validation loss: 2.195075968901316

Epoch: 6| Step: 6
Training loss: 0.2947848439216614
Validation loss: 2.1842172543207803

Epoch: 6| Step: 7
Training loss: 0.39687180519104004
Validation loss: 2.225471079349518

Epoch: 6| Step: 8
Training loss: 0.33549964427948
Validation loss: 2.1965670188268027

Epoch: 6| Step: 9
Training loss: 0.3162650465965271
Validation loss: 2.208376487096151

Epoch: 6| Step: 10
Training loss: 0.16957278549671173
Validation loss: 2.250342607498169

Epoch: 6| Step: 11
Training loss: 0.2545854449272156
Validation loss: 2.2535921732584634

Epoch: 6| Step: 12
Training loss: 0.38169553875923157
Validation loss: 2.2131641705830893

Epoch: 6| Step: 13
Training loss: 0.2722022235393524
Validation loss: 2.221422553062439

Epoch: 511| Step: 0
Training loss: 0.2547787129878998
Validation loss: 2.225727101167043

Epoch: 6| Step: 1
Training loss: 0.1964176595211029
Validation loss: 2.198045869668325

Epoch: 6| Step: 2
Training loss: 0.23468390107154846
Validation loss: 2.176925698916117

Epoch: 6| Step: 3
Training loss: 0.6928954720497131
Validation loss: 2.1697395046552024

Epoch: 6| Step: 4
Training loss: 0.5654522776603699
Validation loss: 2.2335713505744934

Epoch: 6| Step: 5
Training loss: 0.3183366060256958
Validation loss: 2.21502814690272

Epoch: 6| Step: 6
Training loss: 0.302284300327301
Validation loss: 2.25345645348231

Epoch: 6| Step: 7
Training loss: 0.13781508803367615
Validation loss: 2.1877693931261697

Epoch: 6| Step: 8
Training loss: 0.3105940520763397
Validation loss: 2.2008198499679565

Epoch: 6| Step: 9
Training loss: 0.3320276141166687
Validation loss: 2.2332054376602173

Epoch: 6| Step: 10
Training loss: 0.26971590518951416
Validation loss: 2.1777931253115335

Epoch: 6| Step: 11
Training loss: 0.2659885883331299
Validation loss: 2.217023471991221

Epoch: 6| Step: 12
Training loss: 0.4128059148788452
Validation loss: 2.204769492149353

Epoch: 6| Step: 13
Training loss: 0.432824045419693
Validation loss: 2.1657084226608276

Epoch: 512| Step: 0
Training loss: 0.6623055934906006
Validation loss: 2.1740261713663735

Epoch: 6| Step: 1
Training loss: 0.6719505190849304
Validation loss: 2.1970096429189048

Epoch: 6| Step: 2
Training loss: 0.1831965148448944
Validation loss: 2.2530845602353415

Epoch: 6| Step: 3
Training loss: 0.5806965231895447
Validation loss: 2.1803337931632996

Epoch: 6| Step: 4
Training loss: 0.40961378812789917
Validation loss: 2.1664108832677207

Epoch: 6| Step: 5
Training loss: 0.28853338956832886
Validation loss: 2.1919689774513245

Epoch: 6| Step: 6
Training loss: 0.32890835404396057
Validation loss: 2.2187934120496116

Epoch: 6| Step: 7
Training loss: 0.4278672933578491
Validation loss: 2.1926150918006897

Epoch: 6| Step: 8
Training loss: 0.46074700355529785
Validation loss: 2.1993876099586487

Epoch: 6| Step: 9
Training loss: 0.41013264656066895
Validation loss: 2.2494028011957803

Epoch: 6| Step: 10
Training loss: 0.3095436096191406
Validation loss: 2.232844829559326

Epoch: 6| Step: 11
Training loss: 0.2734922468662262
Validation loss: 2.2310055096944175

Epoch: 6| Step: 12
Training loss: 0.2617805600166321
Validation loss: 2.1725234587987265

Epoch: 6| Step: 13
Training loss: 0.3512033224105835
Validation loss: 2.1660432616869607

Epoch: 513| Step: 0
Training loss: 0.4419287145137787
Validation loss: 2.224491616090139

Epoch: 6| Step: 1
Training loss: 0.5750111937522888
Validation loss: 2.1878602306048074

Epoch: 6| Step: 2
Training loss: 0.21492256224155426
Validation loss: 2.168297072251638

Epoch: 6| Step: 3
Training loss: 0.2225394994020462
Validation loss: 2.188140392303467

Epoch: 6| Step: 4
Training loss: 0.22504962980747223
Validation loss: 2.189136783281962

Epoch: 6| Step: 5
Training loss: 0.3033571243286133
Validation loss: 2.258595903714498

Epoch: 6| Step: 6
Training loss: 0.22523419559001923
Validation loss: 2.2341296474138894

Epoch: 6| Step: 7
Training loss: 0.2747398614883423
Validation loss: 2.2473188241322837

Epoch: 6| Step: 8
Training loss: 0.2814652919769287
Validation loss: 2.20848556359609

Epoch: 6| Step: 9
Training loss: 0.3154081702232361
Validation loss: 2.2193711002667746

Epoch: 6| Step: 10
Training loss: 0.16940705478191376
Validation loss: 2.213755408922831

Epoch: 6| Step: 11
Training loss: 0.3767967224121094
Validation loss: 2.169094681739807

Epoch: 6| Step: 12
Training loss: 0.2778683304786682
Validation loss: 2.213835616906484

Epoch: 6| Step: 13
Training loss: 0.7859777212142944
Validation loss: 2.1911896665891013

Epoch: 514| Step: 0
Training loss: 0.24867680668830872
Validation loss: 2.1733025908470154

Epoch: 6| Step: 1
Training loss: 0.32922762632369995
Validation loss: 2.240802804629008

Epoch: 6| Step: 2
Training loss: 0.2475496232509613
Validation loss: 2.1832504868507385

Epoch: 6| Step: 3
Training loss: 0.18175926804542542
Validation loss: 2.1868353684743247

Epoch: 6| Step: 4
Training loss: 0.324362576007843
Validation loss: 2.2232104738553367

Epoch: 6| Step: 5
Training loss: 0.3504711389541626
Validation loss: 2.1804713805516562

Epoch: 6| Step: 6
Training loss: 0.2668730616569519
Validation loss: 2.2146145502726235

Epoch: 6| Step: 7
Training loss: 0.22918391227722168
Validation loss: 2.1979991793632507

Epoch: 6| Step: 8
Training loss: 0.4475030303001404
Validation loss: 2.2035022576649985

Epoch: 6| Step: 9
Training loss: 0.9592080116271973
Validation loss: 2.2071878910064697

Epoch: 6| Step: 10
Training loss: 0.1482817828655243
Validation loss: 2.205605963865916

Epoch: 6| Step: 11
Training loss: 0.3278030753135681
Validation loss: 2.2154969374338784

Epoch: 6| Step: 12
Training loss: 0.3352034389972687
Validation loss: 2.229671617348989

Epoch: 6| Step: 13
Training loss: 0.37086689472198486
Validation loss: 2.2192935943603516

Epoch: 515| Step: 0
Training loss: 0.206491619348526
Validation loss: 2.219579060872396

Epoch: 6| Step: 1
Training loss: 0.30766960978507996
Validation loss: 2.183848043282827

Epoch: 6| Step: 2
Training loss: 0.8508754968643188
Validation loss: 2.190910895665487

Epoch: 6| Step: 3
Training loss: 0.3605187237262726
Validation loss: 2.196097711722056

Epoch: 6| Step: 4
Training loss: 0.2465076893568039
Validation loss: 2.2051724990208945

Epoch: 6| Step: 5
Training loss: 0.31795936822891235
Validation loss: 2.227525750796

Epoch: 6| Step: 6
Training loss: 0.2976687550544739
Validation loss: 2.19022798538208

Epoch: 6| Step: 7
Training loss: 0.16089001297950745
Validation loss: 2.2209470868110657

Epoch: 6| Step: 8
Training loss: 0.17265331745147705
Validation loss: 2.217461625734965

Epoch: 6| Step: 9
Training loss: 0.19742810726165771
Validation loss: 2.206928769747416

Epoch: 6| Step: 10
Training loss: 0.39694660902023315
Validation loss: 2.156527896722158

Epoch: 6| Step: 11
Training loss: 0.35187166929244995
Validation loss: 2.1638077100118003

Epoch: 6| Step: 12
Training loss: 0.23781514167785645
Validation loss: 2.2114182710647583

Epoch: 6| Step: 13
Training loss: 0.4948350787162781
Validation loss: 2.1400192379951477

Epoch: 516| Step: 0
Training loss: 0.5248042941093445
Validation loss: 2.2175697088241577

Epoch: 6| Step: 1
Training loss: 0.5424082279205322
Validation loss: 2.19395919640859

Epoch: 6| Step: 2
Training loss: 0.43339699506759644
Validation loss: 2.1656595269838967

Epoch: 6| Step: 3
Training loss: 0.3908441662788391
Validation loss: 2.1964612205823264

Epoch: 6| Step: 4
Training loss: 0.3699986934661865
Validation loss: 2.224481741587321

Epoch: 6| Step: 5
Training loss: 0.24177105724811554
Validation loss: 2.19228196144104

Epoch: 6| Step: 6
Training loss: 0.20690298080444336
Validation loss: 2.2375792860984802

Epoch: 6| Step: 7
Training loss: 0.24390608072280884
Validation loss: 2.1816192666689553

Epoch: 6| Step: 8
Training loss: 0.19669507443904877
Validation loss: 2.170480410257975

Epoch: 6| Step: 9
Training loss: 0.3370410203933716
Validation loss: 2.22560187180837

Epoch: 6| Step: 10
Training loss: 0.47705018520355225
Validation loss: 2.1957903305689492

Epoch: 6| Step: 11
Training loss: 0.31035763025283813
Validation loss: 2.175060292085012

Epoch: 6| Step: 12
Training loss: 0.19581398367881775
Validation loss: 2.1652207573254905

Epoch: 6| Step: 13
Training loss: 0.6645806431770325
Validation loss: 2.155873696009318

Epoch: 517| Step: 0
Training loss: 0.34861379861831665
Validation loss: 2.2025461395581565

Epoch: 6| Step: 1
Training loss: 0.4163524806499481
Validation loss: 2.157530585924784

Epoch: 6| Step: 2
Training loss: 0.3612038195133209
Validation loss: 2.183417578538259

Epoch: 6| Step: 3
Training loss: 0.18898816406726837
Validation loss: 2.207108438014984

Epoch: 6| Step: 4
Training loss: 0.3486354947090149
Validation loss: 2.195140322049459

Epoch: 6| Step: 5
Training loss: 0.6709897518157959
Validation loss: 2.2693164547284446

Epoch: 6| Step: 6
Training loss: 0.2093581259250641
Validation loss: 2.2123825550079346

Epoch: 6| Step: 7
Training loss: 0.46606260538101196
Validation loss: 2.226287086804708

Epoch: 6| Step: 8
Training loss: 0.3078429400920868
Validation loss: 2.2160356640815735

Epoch: 6| Step: 9
Training loss: 0.2214428186416626
Validation loss: 2.248841087023417

Epoch: 6| Step: 10
Training loss: 0.21550071239471436
Validation loss: 2.1717119614283242

Epoch: 6| Step: 11
Training loss: 0.265854150056839
Validation loss: 2.2655975023905435

Epoch: 6| Step: 12
Training loss: 0.18575912714004517
Validation loss: 2.199825386206309

Epoch: 6| Step: 13
Training loss: 0.3011503219604492
Validation loss: 2.2069430351257324

Epoch: 518| Step: 0
Training loss: 0.45252525806427
Validation loss: 2.1982008814811707

Epoch: 6| Step: 1
Training loss: 0.2607206106185913
Validation loss: 2.2175058921178183

Epoch: 6| Step: 2
Training loss: 0.25361156463623047
Validation loss: 2.1991812586784363

Epoch: 6| Step: 3
Training loss: 0.21444019675254822
Validation loss: 2.2344287633895874

Epoch: 6| Step: 4
Training loss: 0.4857742488384247
Validation loss: 2.2448108196258545

Epoch: 6| Step: 5
Training loss: 0.532433032989502
Validation loss: 2.191426396369934

Epoch: 6| Step: 6
Training loss: 0.33326366543769836
Validation loss: 2.2466491063435874

Epoch: 6| Step: 7
Training loss: 0.30956706404685974
Validation loss: 2.1914763847986856

Epoch: 6| Step: 8
Training loss: 0.3353104889392853
Validation loss: 2.2020336190859475

Epoch: 6| Step: 9
Training loss: 0.2105235457420349
Validation loss: 2.2506898244222007

Epoch: 6| Step: 10
Training loss: 0.17030340433120728
Validation loss: 2.175066888332367

Epoch: 6| Step: 11
Training loss: 0.21688617765903473
Validation loss: 2.230892062187195

Epoch: 6| Step: 12
Training loss: 0.23665055632591248
Validation loss: 2.2095342675844827

Epoch: 6| Step: 13
Training loss: 0.650876522064209
Validation loss: 2.1963016192118325

Epoch: 519| Step: 0
Training loss: 0.2313038557767868
Validation loss: 2.243240793546041

Epoch: 6| Step: 1
Training loss: 0.2397700846195221
Validation loss: 2.189404229323069

Epoch: 6| Step: 2
Training loss: 0.5190287232398987
Validation loss: 2.2103733817736306

Epoch: 6| Step: 3
Training loss: 0.19357357919216156
Validation loss: 2.216735521952311

Epoch: 6| Step: 4
Training loss: 0.6526802182197571
Validation loss: 2.2094398538271585

Epoch: 6| Step: 5
Training loss: 0.18425516784191132
Validation loss: 2.2338453928629556

Epoch: 6| Step: 6
Training loss: 0.16357240080833435
Validation loss: 2.2137375275293985

Epoch: 6| Step: 7
Training loss: 0.19967158138751984
Validation loss: 2.2817558447519937

Epoch: 6| Step: 8
Training loss: 0.45108067989349365
Validation loss: 2.192486902077993

Epoch: 6| Step: 9
Training loss: 0.2504701018333435
Validation loss: 2.168597420056661

Epoch: 6| Step: 10
Training loss: 0.44744881987571716
Validation loss: 2.27787176767985

Epoch: 6| Step: 11
Training loss: 0.2897098660469055
Validation loss: 2.2315535147984824

Epoch: 6| Step: 12
Training loss: 0.3831750154495239
Validation loss: 2.206637700398763

Epoch: 6| Step: 13
Training loss: 0.16158542037010193
Validation loss: 2.1930611729621887

Epoch: 520| Step: 0
Training loss: 0.29890137910842896
Validation loss: 2.206940253575643

Epoch: 6| Step: 1
Training loss: 0.30824825167655945
Validation loss: 2.2096107800801597

Epoch: 6| Step: 2
Training loss: 0.24929054081439972
Validation loss: 2.2373664577802024

Epoch: 6| Step: 3
Training loss: 0.17586520314216614
Validation loss: 2.226248304049174

Epoch: 6| Step: 4
Training loss: 0.6837910413742065
Validation loss: 2.223917086919149

Epoch: 6| Step: 5
Training loss: 0.29919248819351196
Validation loss: 2.2340643803278604

Epoch: 6| Step: 6
Training loss: 0.3297588527202606
Validation loss: 2.188446819782257

Epoch: 6| Step: 7
Training loss: 0.4022362232208252
Validation loss: 2.2189478278160095

Epoch: 6| Step: 8
Training loss: 0.21615956723690033
Validation loss: 2.2005223830540976

Epoch: 6| Step: 9
Training loss: 0.467678427696228
Validation loss: 2.186342477798462

Epoch: 6| Step: 10
Training loss: 0.29758042097091675
Validation loss: 2.1756819089253745

Epoch: 6| Step: 11
Training loss: 0.4190087914466858
Validation loss: 2.212116797765096

Epoch: 6| Step: 12
Training loss: 0.36590951681137085
Validation loss: 2.2068047722180686

Epoch: 6| Step: 13
Training loss: 0.23374643921852112
Validation loss: 2.20978981256485

Epoch: 521| Step: 0
Training loss: 0.23068663477897644
Validation loss: 2.217860678831736

Epoch: 6| Step: 1
Training loss: 0.27651533484458923
Validation loss: 2.2410877545674643

Epoch: 6| Step: 2
Training loss: 0.4465697705745697
Validation loss: 2.2224923968315125

Epoch: 6| Step: 3
Training loss: 0.34841063618659973
Validation loss: 2.2169373432795205

Epoch: 6| Step: 4
Training loss: 0.41289132833480835
Validation loss: 2.1985166470209756

Epoch: 6| Step: 5
Training loss: 0.16690488159656525
Validation loss: 2.228136897087097

Epoch: 6| Step: 6
Training loss: 0.435893177986145
Validation loss: 2.225854734579722

Epoch: 6| Step: 7
Training loss: 0.16650307178497314
Validation loss: 2.24132764339447

Epoch: 6| Step: 8
Training loss: 0.7394778728485107
Validation loss: 2.229001601537069

Epoch: 6| Step: 9
Training loss: 0.22849978506565094
Validation loss: 2.1962205370267234

Epoch: 6| Step: 10
Training loss: 0.4166199862957001
Validation loss: 2.1923282742500305

Epoch: 6| Step: 11
Training loss: 0.19283679127693176
Validation loss: 2.2258063157399497

Epoch: 6| Step: 12
Training loss: 0.18840447068214417
Validation loss: 2.2021555503209433

Epoch: 6| Step: 13
Training loss: 0.24835631251335144
Validation loss: 2.153558671474457

Epoch: 522| Step: 0
Training loss: 0.4864695966243744
Validation loss: 2.1777515610059104

Epoch: 6| Step: 1
Training loss: 0.16151310503482819
Validation loss: 2.249272326628367

Epoch: 6| Step: 2
Training loss: 0.30567994713783264
Validation loss: 2.2490223248799643

Epoch: 6| Step: 3
Training loss: 0.29573094844818115
Validation loss: 2.2406596342722573

Epoch: 6| Step: 4
Training loss: 0.39165544509887695
Validation loss: 2.1892357071240744

Epoch: 6| Step: 5
Training loss: 0.21471497416496277
Validation loss: 2.183418790499369

Epoch: 6| Step: 6
Training loss: 0.4422873854637146
Validation loss: 2.184912999471029

Epoch: 6| Step: 7
Training loss: 0.22805559635162354
Validation loss: 2.1623589793841043

Epoch: 6| Step: 8
Training loss: 0.6539620757102966
Validation loss: 2.138613522052765

Epoch: 6| Step: 9
Training loss: 0.25738954544067383
Validation loss: 2.2409844199816384

Epoch: 6| Step: 10
Training loss: 0.4705105423927307
Validation loss: 2.2255703608194985

Epoch: 6| Step: 11
Training loss: 0.18168070912361145
Validation loss: 2.2494212786356607

Epoch: 6| Step: 12
Training loss: 0.24318501353263855
Validation loss: 2.2080198725064597

Epoch: 6| Step: 13
Training loss: 0.237264946103096
Validation loss: 2.174209495385488

Epoch: 523| Step: 0
Training loss: 0.23533211648464203
Validation loss: 2.218704402446747

Epoch: 6| Step: 1
Training loss: 0.1496712565422058
Validation loss: 2.2080040176709494

Epoch: 6| Step: 2
Training loss: 0.1764533817768097
Validation loss: 2.19590163230896

Epoch: 6| Step: 3
Training loss: 0.20827150344848633
Validation loss: 2.205601612726847

Epoch: 6| Step: 4
Training loss: 0.4905698597431183
Validation loss: 2.1587495605150857

Epoch: 6| Step: 5
Training loss: 0.2449883222579956
Validation loss: 2.175277511278788

Epoch: 6| Step: 6
Training loss: 0.19008049368858337
Validation loss: 2.2099406321843467

Epoch: 6| Step: 7
Training loss: 0.19876554608345032
Validation loss: 2.2102760076522827

Epoch: 6| Step: 8
Training loss: 0.34785938262939453
Validation loss: 2.207033356030782

Epoch: 6| Step: 9
Training loss: 0.1877322793006897
Validation loss: 2.211193879445394

Epoch: 6| Step: 10
Training loss: 0.31630533933639526
Validation loss: 2.187926451365153

Epoch: 6| Step: 11
Training loss: 0.8832831382751465
Validation loss: 2.2023328145345054

Epoch: 6| Step: 12
Training loss: 0.22414624691009521
Validation loss: 2.184794803460439

Epoch: 6| Step: 13
Training loss: 0.3405994176864624
Validation loss: 2.198197523752848

Epoch: 524| Step: 0
Training loss: 0.40931588411331177
Validation loss: 2.220050652821859

Epoch: 6| Step: 1
Training loss: 0.8812087178230286
Validation loss: 2.1750629941622415

Epoch: 6| Step: 2
Training loss: 0.24846521019935608
Validation loss: 2.2338227232297263

Epoch: 6| Step: 3
Training loss: 0.28448259830474854
Validation loss: 2.217281679312388

Epoch: 6| Step: 4
Training loss: 0.2034563571214676
Validation loss: 2.231725593407949

Epoch: 6| Step: 5
Training loss: 0.18356747925281525
Validation loss: 2.1925830046335855

Epoch: 6| Step: 6
Training loss: 0.3357522487640381
Validation loss: 2.1559274196624756

Epoch: 6| Step: 7
Training loss: 0.38880425691604614
Validation loss: 2.1949846347173056

Epoch: 6| Step: 8
Training loss: 0.1638408601284027
Validation loss: 2.218784272670746

Epoch: 6| Step: 9
Training loss: 0.3128943145275116
Validation loss: 2.194982945919037

Epoch: 6| Step: 10
Training loss: 0.30772626399993896
Validation loss: 2.188402752081553

Epoch: 6| Step: 11
Training loss: 0.322210431098938
Validation loss: 2.2108941276868186

Epoch: 6| Step: 12
Training loss: 0.2707059383392334
Validation loss: 2.254856844743093

Epoch: 6| Step: 13
Training loss: 0.2712627053260803
Validation loss: 2.2008164525032043

Epoch: 525| Step: 0
Training loss: 0.21993662416934967
Validation loss: 2.1985835234324136

Epoch: 6| Step: 1
Training loss: 0.27689534425735474
Validation loss: 2.2013212045033774

Epoch: 6| Step: 2
Training loss: 0.36122775077819824
Validation loss: 2.193468928337097

Epoch: 6| Step: 3
Training loss: 0.3547511398792267
Validation loss: 2.22163987159729

Epoch: 6| Step: 4
Training loss: 0.18440057337284088
Validation loss: 2.2065310875574746

Epoch: 6| Step: 5
Training loss: 0.28995171189308167
Validation loss: 2.220235288143158

Epoch: 6| Step: 6
Training loss: 0.3033217489719391
Validation loss: 2.206458628177643

Epoch: 6| Step: 7
Training loss: 0.3649638891220093
Validation loss: 2.2272764643033347

Epoch: 6| Step: 8
Training loss: 0.2037796974182129
Validation loss: 2.221389730771383

Epoch: 6| Step: 9
Training loss: 0.694699764251709
Validation loss: 2.2294965187708535

Epoch: 6| Step: 10
Training loss: 0.513947606086731
Validation loss: 2.1960386435190835

Epoch: 6| Step: 11
Training loss: 0.29336604475975037
Validation loss: 2.2163410782814026

Epoch: 6| Step: 12
Training loss: 0.23377329111099243
Validation loss: 2.158275604248047

Epoch: 6| Step: 13
Training loss: 0.4702467918395996
Validation loss: 2.1696168382962546

Epoch: 526| Step: 0
Training loss: 0.3154705762863159
Validation loss: 2.1914652387301126

Epoch: 6| Step: 1
Training loss: 0.33783429861068726
Validation loss: 2.144762635231018

Epoch: 6| Step: 2
Training loss: 0.3177911043167114
Validation loss: 2.173480987548828

Epoch: 6| Step: 3
Training loss: 0.26260891556739807
Validation loss: 2.1796235044797263

Epoch: 6| Step: 4
Training loss: 0.347763329744339
Validation loss: 2.158148984114329

Epoch: 6| Step: 5
Training loss: 0.32486045360565186
Validation loss: 2.216608723004659

Epoch: 6| Step: 6
Training loss: 0.35704323649406433
Validation loss: 2.1906901597976685

Epoch: 6| Step: 7
Training loss: 0.31470343470573425
Validation loss: 2.1712438662846885

Epoch: 6| Step: 8
Training loss: 0.8572100400924683
Validation loss: 2.222299794356028

Epoch: 6| Step: 9
Training loss: 0.16575811803340912
Validation loss: 2.203186869621277

Epoch: 6| Step: 10
Training loss: 0.3528439998626709
Validation loss: 2.1579425732294717

Epoch: 6| Step: 11
Training loss: 0.1526658833026886
Validation loss: 2.1177369952201843

Epoch: 6| Step: 12
Training loss: 0.32541415095329285
Validation loss: 2.165072043736776

Epoch: 6| Step: 13
Training loss: 0.32175976037979126
Validation loss: 2.171337445576986

Epoch: 527| Step: 0
Training loss: 0.34901803731918335
Validation loss: 2.142119506994883

Epoch: 6| Step: 1
Training loss: 0.33437681198120117
Validation loss: 2.1655133962631226

Epoch: 6| Step: 2
Training loss: 0.38996559381484985
Validation loss: 2.1668240626653037

Epoch: 6| Step: 3
Training loss: 0.2364434003829956
Validation loss: 2.1888477404912314

Epoch: 6| Step: 4
Training loss: 0.2536531090736389
Validation loss: 2.1973135471343994

Epoch: 6| Step: 5
Training loss: 0.21469196677207947
Validation loss: 2.185414413611094

Epoch: 6| Step: 6
Training loss: 0.7106276750564575
Validation loss: 2.2272849480311074

Epoch: 6| Step: 7
Training loss: 0.3976881206035614
Validation loss: 2.238568603992462

Epoch: 6| Step: 8
Training loss: 0.21611832082271576
Validation loss: 2.23791366815567

Epoch: 6| Step: 9
Training loss: 0.23905368149280548
Validation loss: 2.2398439844449363

Epoch: 6| Step: 10
Training loss: 0.34514904022216797
Validation loss: 2.2298911412556968

Epoch: 6| Step: 11
Training loss: 0.3243793249130249
Validation loss: 2.2193284034729004

Epoch: 6| Step: 12
Training loss: 0.2991786599159241
Validation loss: 2.2220392425855002

Epoch: 6| Step: 13
Training loss: 0.34095707535743713
Validation loss: 2.236234108606974

Epoch: 528| Step: 0
Training loss: 0.496320903301239
Validation loss: 2.195044835408529

Epoch: 6| Step: 1
Training loss: 0.2772834897041321
Validation loss: 2.1942652662595115

Epoch: 6| Step: 2
Training loss: 0.40088382363319397
Validation loss: 2.185364226500193

Epoch: 6| Step: 3
Training loss: 0.40070289373397827
Validation loss: 2.2089922428131104

Epoch: 6| Step: 4
Training loss: 0.7302674651145935
Validation loss: 2.2190412481625876

Epoch: 6| Step: 5
Training loss: 0.14607155323028564
Validation loss: 2.229137380917867

Epoch: 6| Step: 6
Training loss: 0.22769387066364288
Validation loss: 2.1985424359639487

Epoch: 6| Step: 7
Training loss: 0.3900735676288605
Validation loss: 2.214599072933197

Epoch: 6| Step: 8
Training loss: 0.22849921882152557
Validation loss: 2.23535825808843

Epoch: 6| Step: 9
Training loss: 0.2700271010398865
Validation loss: 2.2766932447751365

Epoch: 6| Step: 10
Training loss: 0.24444523453712463
Validation loss: 2.176977813243866

Epoch: 6| Step: 11
Training loss: 0.4691687822341919
Validation loss: 2.227582355340322

Epoch: 6| Step: 12
Training loss: 0.25499358773231506
Validation loss: 2.1650205850601196

Epoch: 6| Step: 13
Training loss: 0.24417681992053986
Validation loss: 2.193785230318705

Epoch: 529| Step: 0
Training loss: 0.21477314829826355
Validation loss: 2.1759591698646545

Epoch: 6| Step: 1
Training loss: 0.1784944236278534
Validation loss: 2.213003079096476

Epoch: 6| Step: 2
Training loss: 0.3128701448440552
Validation loss: 2.246129631996155

Epoch: 6| Step: 3
Training loss: 0.35631170868873596
Validation loss: 2.226943055788676

Epoch: 6| Step: 4
Training loss: 0.21613195538520813
Validation loss: 2.2071904937426248

Epoch: 6| Step: 5
Training loss: 0.29914456605911255
Validation loss: 2.214392105738322

Epoch: 6| Step: 6
Training loss: 0.2797420024871826
Validation loss: 2.2549192706743875

Epoch: 6| Step: 7
Training loss: 0.21763446927070618
Validation loss: 2.216290374596914

Epoch: 6| Step: 8
Training loss: 0.17428243160247803
Validation loss: 2.1649643182754517

Epoch: 6| Step: 9
Training loss: 0.16331619024276733
Validation loss: 2.1882445017496743

Epoch: 6| Step: 10
Training loss: 0.28078389167785645
Validation loss: 2.151690403620402

Epoch: 6| Step: 11
Training loss: 0.7097519636154175
Validation loss: 2.154687205950419

Epoch: 6| Step: 12
Training loss: 0.6103092432022095
Validation loss: 2.1781714955965676

Epoch: 6| Step: 13
Training loss: 0.42514392733573914
Validation loss: 2.2267695665359497

Epoch: 530| Step: 0
Training loss: 0.5355737209320068
Validation loss: 2.2173620462417603

Epoch: 6| Step: 1
Training loss: 0.2462805211544037
Validation loss: 2.2325304547945657

Epoch: 6| Step: 2
Training loss: 0.20510591566562653
Validation loss: 2.1846413612365723

Epoch: 6| Step: 3
Training loss: 0.28169575333595276
Validation loss: 2.2583013772964478

Epoch: 6| Step: 4
Training loss: 0.2705594599246979
Validation loss: 2.2015042503674827

Epoch: 6| Step: 5
Training loss: 0.3106965720653534
Validation loss: 2.202118476231893

Epoch: 6| Step: 6
Training loss: 0.14344456791877747
Validation loss: 2.207477311293284

Epoch: 6| Step: 7
Training loss: 0.2074614018201828
Validation loss: 2.207306385040283

Epoch: 6| Step: 8
Training loss: 0.10527826845645905
Validation loss: 2.199986298878988

Epoch: 6| Step: 9
Training loss: 0.2638842463493347
Validation loss: 2.2239323258399963

Epoch: 6| Step: 10
Training loss: 0.6643353700637817
Validation loss: 2.1972791155179343

Epoch: 6| Step: 11
Training loss: 0.3315519094467163
Validation loss: 2.203325351079305

Epoch: 6| Step: 12
Training loss: 0.5010834336280823
Validation loss: 2.2148659030596414

Epoch: 6| Step: 13
Training loss: 0.21742628514766693
Validation loss: 2.1580315033594766

Epoch: 531| Step: 0
Training loss: 0.2105296552181244
Validation loss: 2.2495681842168174

Epoch: 6| Step: 1
Training loss: 0.19458287954330444
Validation loss: 2.243852416674296

Epoch: 6| Step: 2
Training loss: 0.25363630056381226
Validation loss: 2.1943823099136353

Epoch: 6| Step: 3
Training loss: 0.7958436012268066
Validation loss: 2.230556845664978

Epoch: 6| Step: 4
Training loss: 0.26730555295944214
Validation loss: 2.2582130829493203

Epoch: 6| Step: 5
Training loss: 0.14332261681556702
Validation loss: 2.234734356403351

Epoch: 6| Step: 6
Training loss: 0.23299670219421387
Validation loss: 2.2043310403823853

Epoch: 6| Step: 7
Training loss: 0.3470779359340668
Validation loss: 2.2246008117993674

Epoch: 6| Step: 8
Training loss: 0.2705595791339874
Validation loss: 2.231499711672465

Epoch: 6| Step: 9
Training loss: 0.28172051906585693
Validation loss: 2.2758846282958984

Epoch: 6| Step: 10
Training loss: 0.3405717611312866
Validation loss: 2.2609145243962607

Epoch: 6| Step: 11
Training loss: 0.24749521911144257
Validation loss: 2.1824782689412436

Epoch: 6| Step: 12
Training loss: 0.2751218378543854
Validation loss: 2.15275377035141

Epoch: 6| Step: 13
Training loss: 0.434834361076355
Validation loss: 2.216683109601339

Epoch: 532| Step: 0
Training loss: 0.2581007480621338
Validation loss: 2.2129467527071633

Epoch: 6| Step: 1
Training loss: 0.2081403136253357
Validation loss: 2.1646910905838013

Epoch: 6| Step: 2
Training loss: 0.3482232093811035
Validation loss: 2.2508515318234763

Epoch: 6| Step: 3
Training loss: 0.23324911296367645
Validation loss: 2.202991565068563

Epoch: 6| Step: 4
Training loss: 0.23278263211250305
Validation loss: 2.2114097674687705

Epoch: 6| Step: 5
Training loss: 0.4428836703300476
Validation loss: 2.2051527897516885

Epoch: 6| Step: 6
Training loss: 0.6415724754333496
Validation loss: 2.2234397729237876

Epoch: 6| Step: 7
Training loss: 0.6323222517967224
Validation loss: 2.2195627888043723

Epoch: 6| Step: 8
Training loss: 0.41858944296836853
Validation loss: 2.211471915245056

Epoch: 6| Step: 9
Training loss: 0.21132247149944305
Validation loss: 2.176926056543986

Epoch: 6| Step: 10
Training loss: 0.22672967612743378
Validation loss: 2.1844807465871177

Epoch: 6| Step: 11
Training loss: 0.17970618605613708
Validation loss: 2.22670571009318

Epoch: 6| Step: 12
Training loss: 0.1622483879327774
Validation loss: 2.1901756525039673

Epoch: 6| Step: 13
Training loss: 0.2375401258468628
Validation loss: 2.191979388395945

Epoch: 533| Step: 0
Training loss: 0.37482932209968567
Validation loss: 2.194709002971649

Epoch: 6| Step: 1
Training loss: 0.2932753264904022
Validation loss: 2.206938107808431

Epoch: 6| Step: 2
Training loss: 0.19707584381103516
Validation loss: 2.170748551686605

Epoch: 6| Step: 3
Training loss: 0.2091953456401825
Validation loss: 2.197754164536794

Epoch: 6| Step: 4
Training loss: 0.28733018040657043
Validation loss: 2.2075441678365073

Epoch: 6| Step: 5
Training loss: 0.178794264793396
Validation loss: 2.171148439248403

Epoch: 6| Step: 6
Training loss: 0.6413816809654236
Validation loss: 2.221596380074819

Epoch: 6| Step: 7
Training loss: 0.20471704006195068
Validation loss: 2.1703375379244485

Epoch: 6| Step: 8
Training loss: 0.39763832092285156
Validation loss: 2.1910135547320047

Epoch: 6| Step: 9
Training loss: 0.3693407475948334
Validation loss: 2.191150883833567

Epoch: 6| Step: 10
Training loss: 0.10508817434310913
Validation loss: 2.2106104493141174

Epoch: 6| Step: 11
Training loss: 0.6728172302246094
Validation loss: 2.205451707045237

Epoch: 6| Step: 12
Training loss: 0.18312066793441772
Validation loss: 2.1671648820241294

Epoch: 6| Step: 13
Training loss: 0.3247670531272888
Validation loss: 2.1684096256891885

Epoch: 534| Step: 0
Training loss: 0.797227144241333
Validation loss: 2.1793440183003745

Epoch: 6| Step: 1
Training loss: 0.30700427293777466
Validation loss: 2.1394989291826882

Epoch: 6| Step: 2
Training loss: 0.25816354155540466
Validation loss: 2.136787454287211

Epoch: 6| Step: 3
Training loss: 0.19225144386291504
Validation loss: 2.183830897013346

Epoch: 6| Step: 4
Training loss: 0.2838868498802185
Validation loss: 2.20976984500885

Epoch: 6| Step: 5
Training loss: 0.4923432767391205
Validation loss: 2.237723648548126

Epoch: 6| Step: 6
Training loss: 0.3293216824531555
Validation loss: 2.2303168972333274

Epoch: 6| Step: 7
Training loss: 0.43812429904937744
Validation loss: 2.236406922340393

Epoch: 6| Step: 8
Training loss: 0.4552571177482605
Validation loss: 2.280515114466349

Epoch: 6| Step: 9
Training loss: 0.34504497051239014
Validation loss: 2.2285650968551636

Epoch: 6| Step: 10
Training loss: 0.20827911794185638
Validation loss: 2.2267399628957114

Epoch: 6| Step: 11
Training loss: 0.5198149681091309
Validation loss: 2.2157167394955954

Epoch: 6| Step: 12
Training loss: 0.14677748084068298
Validation loss: 2.2637647787729898

Epoch: 6| Step: 13
Training loss: 0.3033911883831024
Validation loss: 2.237347880999247

Epoch: 535| Step: 0
Training loss: 0.4033213257789612
Validation loss: 2.189229885737101

Epoch: 6| Step: 1
Training loss: 0.29045671224594116
Validation loss: 2.2495013078053794

Epoch: 6| Step: 2
Training loss: 0.33736395835876465
Validation loss: 2.2676459749539695

Epoch: 6| Step: 3
Training loss: 0.42233800888061523
Validation loss: 2.258602261543274

Epoch: 6| Step: 4
Training loss: 0.20299872756004333
Validation loss: 2.2508793274561563

Epoch: 6| Step: 5
Training loss: 0.4064422845840454
Validation loss: 2.2196252147356668

Epoch: 6| Step: 6
Training loss: 0.26983749866485596
Validation loss: 2.231507579485575

Epoch: 6| Step: 7
Training loss: 0.24473586678504944
Validation loss: 2.2242352962493896

Epoch: 6| Step: 8
Training loss: 0.235298752784729
Validation loss: 2.195197264353434

Epoch: 6| Step: 9
Training loss: 0.5341439843177795
Validation loss: 2.1943057974179587

Epoch: 6| Step: 10
Training loss: 0.31406259536743164
Validation loss: 2.1836381554603577

Epoch: 6| Step: 11
Training loss: 0.8031394481658936
Validation loss: 2.197599013646444

Epoch: 6| Step: 12
Training loss: 0.2663021683692932
Validation loss: 2.2033138076464334

Epoch: 6| Step: 13
Training loss: 0.194693922996521
Validation loss: 2.1956452131271362

Epoch: 536| Step: 0
Training loss: 0.26160794496536255
Validation loss: 2.193923592567444

Epoch: 6| Step: 1
Training loss: 0.25427407026290894
Validation loss: 2.238987445831299

Epoch: 6| Step: 2
Training loss: 0.43648403882980347
Validation loss: 2.2293264667193093

Epoch: 6| Step: 3
Training loss: 0.25232285261154175
Validation loss: 2.2074958880742392

Epoch: 6| Step: 4
Training loss: 0.4714716970920563
Validation loss: 2.155935744444529

Epoch: 6| Step: 5
Training loss: 0.3074262738227844
Validation loss: 2.230007588863373

Epoch: 6| Step: 6
Training loss: 0.1836342215538025
Validation loss: 2.213477452596029

Epoch: 6| Step: 7
Training loss: 0.27386006712913513
Validation loss: 2.186683416366577

Epoch: 6| Step: 8
Training loss: 0.45992106199264526
Validation loss: 2.255267302195231

Epoch: 6| Step: 9
Training loss: 0.36475199460983276
Validation loss: 2.212262809276581

Epoch: 6| Step: 10
Training loss: 0.2043892741203308
Validation loss: 2.1999478737513223

Epoch: 6| Step: 11
Training loss: 0.7252815365791321
Validation loss: 2.226385176181793

Epoch: 6| Step: 12
Training loss: 0.32288026809692383
Validation loss: 2.174063046773275

Epoch: 6| Step: 13
Training loss: 0.24297472834587097
Validation loss: 2.156741519769033

Epoch: 537| Step: 0
Training loss: 0.2989010810852051
Validation loss: 2.201903541882833

Epoch: 6| Step: 1
Training loss: 0.3833230137825012
Validation loss: 2.184402366479238

Epoch: 6| Step: 2
Training loss: 0.8849313855171204
Validation loss: 2.185596446196238

Epoch: 6| Step: 3
Training loss: 0.31000053882598877
Validation loss: 2.2406547466913858

Epoch: 6| Step: 4
Training loss: 0.40493136644363403
Validation loss: 2.230560004711151

Epoch: 6| Step: 5
Training loss: 0.30027467012405396
Validation loss: 2.2367743651072183

Epoch: 6| Step: 6
Training loss: 0.3190992474555969
Validation loss: 2.2830801804860434

Epoch: 6| Step: 7
Training loss: 0.2949139475822449
Validation loss: 2.224480152130127

Epoch: 6| Step: 8
Training loss: 0.11847804486751556
Validation loss: 2.1970791816711426

Epoch: 6| Step: 9
Training loss: 0.28705036640167236
Validation loss: 2.2126090129216514

Epoch: 6| Step: 10
Training loss: 0.3291672468185425
Validation loss: 2.1967004338900247

Epoch: 6| Step: 11
Training loss: 0.245690256357193
Validation loss: 2.2370384335517883

Epoch: 6| Step: 12
Training loss: 0.26589763164520264
Validation loss: 2.1796705524126687

Epoch: 6| Step: 13
Training loss: 0.25718751549720764
Validation loss: 2.2263797322909036

Epoch: 538| Step: 0
Training loss: 0.5568351745605469
Validation loss: 2.2150681416193643

Epoch: 6| Step: 1
Training loss: 0.2585875391960144
Validation loss: 2.217028796672821

Epoch: 6| Step: 2
Training loss: 0.3149283230304718
Validation loss: 2.2203200459480286

Epoch: 6| Step: 3
Training loss: 0.3519061803817749
Validation loss: 2.218686898549398

Epoch: 6| Step: 4
Training loss: 0.20047718286514282
Validation loss: 2.2015499671300254

Epoch: 6| Step: 5
Training loss: 0.2989286482334137
Validation loss: 2.1999712785085044

Epoch: 6| Step: 6
Training loss: 0.2663300037384033
Validation loss: 2.2367457151412964

Epoch: 6| Step: 7
Training loss: 0.8464075326919556
Validation loss: 2.206496238708496

Epoch: 6| Step: 8
Training loss: 0.286579430103302
Validation loss: 2.242241303126017

Epoch: 6| Step: 9
Training loss: 0.3613671064376831
Validation loss: 2.178757150967916

Epoch: 6| Step: 10
Training loss: 0.26834797859191895
Validation loss: 2.2463634411493936

Epoch: 6| Step: 11
Training loss: 0.21722090244293213
Validation loss: 2.203023076057434

Epoch: 6| Step: 12
Training loss: 0.23191161453723907
Validation loss: 2.1961685617764792

Epoch: 6| Step: 13
Training loss: 0.20655834674835205
Validation loss: 2.2309094270070395

Epoch: 539| Step: 0
Training loss: 0.6976635456085205
Validation loss: 2.209144910176595

Epoch: 6| Step: 1
Training loss: 0.4574357569217682
Validation loss: 2.1762439211209617

Epoch: 6| Step: 2
Training loss: 0.32956862449645996
Validation loss: 2.1873326698939004

Epoch: 6| Step: 3
Training loss: 0.3131828308105469
Validation loss: 2.2429916063944497

Epoch: 6| Step: 4
Training loss: 0.18152156472206116
Validation loss: 2.222192366917928

Epoch: 6| Step: 5
Training loss: 0.13843020796775818
Validation loss: 2.200407862663269

Epoch: 6| Step: 6
Training loss: 0.3171285390853882
Validation loss: 2.210237205028534

Epoch: 6| Step: 7
Training loss: 0.3599134683609009
Validation loss: 2.2297386527061462

Epoch: 6| Step: 8
Training loss: 0.204612597823143
Validation loss: 2.1995965242385864

Epoch: 6| Step: 9
Training loss: 0.23597213625907898
Validation loss: 2.2138458093007407

Epoch: 6| Step: 10
Training loss: 0.3082490563392639
Validation loss: 2.233417510986328

Epoch: 6| Step: 11
Training loss: 0.40113502740859985
Validation loss: 2.2092350920041404

Epoch: 6| Step: 12
Training loss: 0.33559203147888184
Validation loss: 2.2041330337524414

Epoch: 6| Step: 13
Training loss: 0.2818412482738495
Validation loss: 2.2203328212102256

Epoch: 540| Step: 0
Training loss: 0.2283838391304016
Validation loss: 2.191887935002645

Epoch: 6| Step: 1
Training loss: 0.2226318120956421
Validation loss: 2.1300341486930847

Epoch: 6| Step: 2
Training loss: 0.2901543974876404
Validation loss: 2.202001412709554

Epoch: 6| Step: 3
Training loss: 0.639358639717102
Validation loss: 2.1998509963353476

Epoch: 6| Step: 4
Training loss: 0.27253520488739014
Validation loss: 2.194963971773783

Epoch: 6| Step: 5
Training loss: 0.35008758306503296
Validation loss: 2.261588176091512

Epoch: 6| Step: 6
Training loss: 0.4223519265651703
Validation loss: 2.243738055229187

Epoch: 6| Step: 7
Training loss: 0.24953654408454895
Validation loss: 2.219902594884237

Epoch: 6| Step: 8
Training loss: 0.27947017550468445
Validation loss: 2.2247695525487265

Epoch: 6| Step: 9
Training loss: 0.37380722165107727
Validation loss: 2.2221556504567466

Epoch: 6| Step: 10
Training loss: 0.4320108890533447
Validation loss: 2.214960813522339

Epoch: 6| Step: 11
Training loss: 0.1670634001493454
Validation loss: 2.181850711504618

Epoch: 6| Step: 12
Training loss: 0.34666094183921814
Validation loss: 2.1996291875839233

Epoch: 6| Step: 13
Training loss: 0.21251952648162842
Validation loss: 2.2190086245536804

Epoch: 541| Step: 0
Training loss: 0.12320457398891449
Validation loss: 2.222982088724772

Epoch: 6| Step: 1
Training loss: 0.19352269172668457
Validation loss: 2.2295029759407043

Epoch: 6| Step: 2
Training loss: 0.32647550106048584
Validation loss: 2.1813855369885764

Epoch: 6| Step: 3
Training loss: 0.31271010637283325
Validation loss: 2.2134708960851035

Epoch: 6| Step: 4
Training loss: 0.1941056102514267
Validation loss: 2.2235702673594155

Epoch: 6| Step: 5
Training loss: 0.3964921236038208
Validation loss: 2.1786062320073447

Epoch: 6| Step: 6
Training loss: 0.20110468566417694
Validation loss: 2.2345935304959617

Epoch: 6| Step: 7
Training loss: 0.2464296519756317
Validation loss: 2.187676211198171

Epoch: 6| Step: 8
Training loss: 0.34613168239593506
Validation loss: 2.1538726886113486

Epoch: 6| Step: 9
Training loss: 0.29389047622680664
Validation loss: 2.227305213610331

Epoch: 6| Step: 10
Training loss: 1.0073894262313843
Validation loss: 2.2075053254763284

Epoch: 6| Step: 11
Training loss: 0.33541208505630493
Validation loss: 2.2318421403566995

Epoch: 6| Step: 12
Training loss: 0.37611445784568787
Validation loss: 2.191952625910441

Epoch: 6| Step: 13
Training loss: 0.27306532859802246
Validation loss: 2.177878479162852

Epoch: 542| Step: 0
Training loss: 0.2860197126865387
Validation loss: 2.162033279736837

Epoch: 6| Step: 1
Training loss: 0.3082866668701172
Validation loss: 2.181709031263987

Epoch: 6| Step: 2
Training loss: 0.18777954578399658
Validation loss: 2.1719910303751626

Epoch: 6| Step: 3
Training loss: 0.4239063560962677
Validation loss: 2.1858831644058228

Epoch: 6| Step: 4
Training loss: 0.4134151339530945
Validation loss: 2.189305146535238

Epoch: 6| Step: 5
Training loss: 0.1658942997455597
Validation loss: 2.201445460319519

Epoch: 6| Step: 6
Training loss: 0.2498112916946411
Validation loss: 2.200382947921753

Epoch: 6| Step: 7
Training loss: 0.33234408497810364
Validation loss: 2.2131133476893106

Epoch: 6| Step: 8
Training loss: 0.2283528447151184
Validation loss: 2.159490247567495

Epoch: 6| Step: 9
Training loss: 0.1453498899936676
Validation loss: 2.1765061418215432

Epoch: 6| Step: 10
Training loss: 0.9436825513839722
Validation loss: 2.182983418305715

Epoch: 6| Step: 11
Training loss: 0.26227474212646484
Validation loss: 2.170023520787557

Epoch: 6| Step: 12
Training loss: 0.1840195506811142
Validation loss: 2.2051288882891336

Epoch: 6| Step: 13
Training loss: 0.2583143413066864
Validation loss: 2.1776998241742453

Epoch: 543| Step: 0
Training loss: 0.21668948233127594
Validation loss: 2.217881917953491

Epoch: 6| Step: 1
Training loss: 0.2925739288330078
Validation loss: 2.2008737126986184

Epoch: 6| Step: 2
Training loss: 0.5192382335662842
Validation loss: 2.158542732397715

Epoch: 6| Step: 3
Training loss: 0.23251065611839294
Validation loss: 2.1966635386149087

Epoch: 6| Step: 4
Training loss: 0.23493695259094238
Validation loss: 2.176102042198181

Epoch: 6| Step: 5
Training loss: 0.27336153388023376
Validation loss: 2.23521488904953

Epoch: 6| Step: 6
Training loss: 0.269250750541687
Validation loss: 2.224629004796346

Epoch: 6| Step: 7
Training loss: 0.8688347339630127
Validation loss: 2.1792526642481485

Epoch: 6| Step: 8
Training loss: 0.16158296167850494
Validation loss: 2.2198160886764526

Epoch: 6| Step: 9
Training loss: 0.26103055477142334
Validation loss: 2.2335017720858255

Epoch: 6| Step: 10
Training loss: 0.2563132047653198
Validation loss: 2.1907450358072915

Epoch: 6| Step: 11
Training loss: 0.18917827308177948
Validation loss: 2.2094942132631936

Epoch: 6| Step: 12
Training loss: 0.4120979905128479
Validation loss: 2.197053849697113

Epoch: 6| Step: 13
Training loss: 0.22626779973506927
Validation loss: 2.1838154991467795

Epoch: 544| Step: 0
Training loss: 0.1660170555114746
Validation loss: 2.207464555899302

Epoch: 6| Step: 1
Training loss: 0.4272322654724121
Validation loss: 2.1853365500768027

Epoch: 6| Step: 2
Training loss: 0.29092222452163696
Validation loss: 2.2333608071009317

Epoch: 6| Step: 3
Training loss: 0.30437955260276794
Validation loss: 2.173308471838633

Epoch: 6| Step: 4
Training loss: 0.25028133392333984
Validation loss: 2.1898687879244485

Epoch: 6| Step: 5
Training loss: 0.2681451439857483
Validation loss: 2.1825631658236184

Epoch: 6| Step: 6
Training loss: 0.47531524300575256
Validation loss: 2.1635026137034097

Epoch: 6| Step: 7
Training loss: 0.7865889668464661
Validation loss: 2.145995318889618

Epoch: 6| Step: 8
Training loss: 0.19001193344593048
Validation loss: 2.1717528700828552

Epoch: 6| Step: 9
Training loss: 0.4113979935646057
Validation loss: 2.2047616839408875

Epoch: 6| Step: 10
Training loss: 0.18624663352966309
Validation loss: 2.226797600587209

Epoch: 6| Step: 11
Training loss: 0.27182650566101074
Validation loss: 2.1836727460225425

Epoch: 6| Step: 12
Training loss: 0.20061153173446655
Validation loss: 2.185705383618673

Epoch: 6| Step: 13
Training loss: 0.3777516186237335
Validation loss: 2.1976199944814048

Epoch: 545| Step: 0
Training loss: 0.25025737285614014
Validation loss: 2.1826817989349365

Epoch: 6| Step: 1
Training loss: 0.21303164958953857
Validation loss: 2.224597930908203

Epoch: 6| Step: 2
Training loss: 0.2730926275253296
Validation loss: 2.297539214293162

Epoch: 6| Step: 3
Training loss: 0.21674677729606628
Validation loss: 2.2279594341913858

Epoch: 6| Step: 4
Training loss: 0.7467187643051147
Validation loss: 2.1925135254859924

Epoch: 6| Step: 5
Training loss: 0.4554101526737213
Validation loss: 2.1731280088424683

Epoch: 6| Step: 6
Training loss: 0.5462682843208313
Validation loss: 2.164554317792257

Epoch: 6| Step: 7
Training loss: 0.2936130464076996
Validation loss: 2.1615992983182273

Epoch: 6| Step: 8
Training loss: 0.2509651184082031
Validation loss: 2.2231889764467874

Epoch: 6| Step: 9
Training loss: 0.27128341794013977
Validation loss: 2.2225183844566345

Epoch: 6| Step: 10
Training loss: 0.14327692985534668
Validation loss: 2.155357380708059

Epoch: 6| Step: 11
Training loss: 0.2238292396068573
Validation loss: 2.191760500272115

Epoch: 6| Step: 12
Training loss: 0.3282509446144104
Validation loss: 2.209027886390686

Epoch: 6| Step: 13
Training loss: 0.4573177993297577
Validation loss: 2.238361179828644

Epoch: 546| Step: 0
Training loss: 0.24664539098739624
Validation loss: 2.183532158533732

Epoch: 6| Step: 1
Training loss: 0.1918383538722992
Validation loss: 2.244045615196228

Epoch: 6| Step: 2
Training loss: 0.263272762298584
Validation loss: 2.2012634873390198

Epoch: 6| Step: 3
Training loss: 0.43381261825561523
Validation loss: 2.269681771596273

Epoch: 6| Step: 4
Training loss: 0.33092164993286133
Validation loss: 2.2099566062291465

Epoch: 6| Step: 5
Training loss: 0.32990071177482605
Validation loss: 2.2023691534996033

Epoch: 6| Step: 6
Training loss: 0.26743364334106445
Validation loss: 2.190821627775828

Epoch: 6| Step: 7
Training loss: 0.6403800845146179
Validation loss: 2.1875489354133606

Epoch: 6| Step: 8
Training loss: 0.3412495255470276
Validation loss: 2.2439005970954895

Epoch: 6| Step: 9
Training loss: 0.24671629071235657
Validation loss: 2.184402863184611

Epoch: 6| Step: 10
Training loss: 0.23099276423454285
Validation loss: 2.1953882575035095

Epoch: 6| Step: 11
Training loss: 0.30329281091690063
Validation loss: 2.2351982990900674

Epoch: 6| Step: 12
Training loss: 0.4471706748008728
Validation loss: 2.1792664527893066

Epoch: 6| Step: 13
Training loss: 0.327239453792572
Validation loss: 2.2006675799687705

Epoch: 547| Step: 0
Training loss: 0.23320183157920837
Validation loss: 2.2111013333002725

Epoch: 6| Step: 1
Training loss: 0.2688513398170471
Validation loss: 2.250124990940094

Epoch: 6| Step: 2
Training loss: 0.20275452733039856
Validation loss: 2.245615820089976

Epoch: 6| Step: 3
Training loss: 0.29820865392684937
Validation loss: 2.1983636617660522

Epoch: 6| Step: 4
Training loss: 0.38308048248291016
Validation loss: 2.2173479398091636

Epoch: 6| Step: 5
Training loss: 0.2617644667625427
Validation loss: 2.255590319633484

Epoch: 6| Step: 6
Training loss: 0.24537640810012817
Validation loss: 2.2089346051216125

Epoch: 6| Step: 7
Training loss: 0.42812246084213257
Validation loss: 2.2443403402964273

Epoch: 6| Step: 8
Training loss: 0.6673753261566162
Validation loss: 2.292141238848368

Epoch: 6| Step: 9
Training loss: 0.2642402946949005
Validation loss: 2.262084503968557

Epoch: 6| Step: 10
Training loss: 0.2865297198295593
Validation loss: 2.2568254272143045

Epoch: 6| Step: 11
Training loss: 0.4548743665218353
Validation loss: 2.254315892855326

Epoch: 6| Step: 12
Training loss: 0.2867274284362793
Validation loss: 2.2295696139335632

Epoch: 6| Step: 13
Training loss: 0.5665823817253113
Validation loss: 2.2129957477251687

Epoch: 548| Step: 0
Training loss: 0.27799296379089355
Validation loss: 2.2370736400286355

Epoch: 6| Step: 1
Training loss: 0.3541210889816284
Validation loss: 2.251002470652262

Epoch: 6| Step: 2
Training loss: 0.12516674399375916
Validation loss: 2.221040904521942

Epoch: 6| Step: 3
Training loss: 0.334428608417511
Validation loss: 2.176949759324392

Epoch: 6| Step: 4
Training loss: 0.25970518589019775
Validation loss: 2.2550577521324158

Epoch: 6| Step: 5
Training loss: 0.34576326608657837
Validation loss: 2.1987587412198386

Epoch: 6| Step: 6
Training loss: 0.4128227233886719
Validation loss: 2.1971398989359536

Epoch: 6| Step: 7
Training loss: 0.3671431243419647
Validation loss: 2.144680440425873

Epoch: 6| Step: 8
Training loss: 0.33555611968040466
Validation loss: 2.1918596227963767

Epoch: 6| Step: 9
Training loss: 0.21909625828266144
Validation loss: 2.2076079845428467

Epoch: 6| Step: 10
Training loss: 0.3095012605190277
Validation loss: 2.247454603513082

Epoch: 6| Step: 11
Training loss: 0.4099765717983246
Validation loss: 2.24198309580485

Epoch: 6| Step: 12
Training loss: 0.3114360570907593
Validation loss: 2.242536981900533

Epoch: 6| Step: 13
Training loss: 0.6851075887680054
Validation loss: 2.1946492989857993

Epoch: 549| Step: 0
Training loss: 0.33214670419692993
Validation loss: 2.252148747444153

Epoch: 6| Step: 1
Training loss: 0.9202696084976196
Validation loss: 2.2407337029774985

Epoch: 6| Step: 2
Training loss: 0.3577938377857208
Validation loss: 2.212451696395874

Epoch: 6| Step: 3
Training loss: 0.24975332617759705
Validation loss: 2.2049829165140786

Epoch: 6| Step: 4
Training loss: 0.27332302927970886
Validation loss: 2.216714560985565

Epoch: 6| Step: 5
Training loss: 0.23473399877548218
Validation loss: 2.2064253290494285

Epoch: 6| Step: 6
Training loss: 0.21127520501613617
Validation loss: 2.2220828533172607

Epoch: 6| Step: 7
Training loss: 0.2751882076263428
Validation loss: 2.2309305469195047

Epoch: 6| Step: 8
Training loss: 0.17860758304595947
Validation loss: 2.236152489980062

Epoch: 6| Step: 9
Training loss: 0.3370698392391205
Validation loss: 2.257949153582255

Epoch: 6| Step: 10
Training loss: 0.20054490864276886
Validation loss: 2.2420425613721213

Epoch: 6| Step: 11
Training loss: 0.295266330242157
Validation loss: 2.2259100675582886

Epoch: 6| Step: 12
Training loss: 0.23299665749073029
Validation loss: 2.244952082633972

Epoch: 6| Step: 13
Training loss: 0.3997076451778412
Validation loss: 2.2517919341723123

Epoch: 550| Step: 0
Training loss: 0.25214052200317383
Validation loss: 2.2243621349334717

Epoch: 6| Step: 1
Training loss: 0.20759797096252441
Validation loss: 2.17740527788798

Epoch: 6| Step: 2
Training loss: 0.35119545459747314
Validation loss: 2.273926337560018

Epoch: 6| Step: 3
Training loss: 0.25703856348991394
Validation loss: 2.223961432774862

Epoch: 6| Step: 4
Training loss: 0.24440227448940277
Validation loss: 2.250328024228414

Epoch: 6| Step: 5
Training loss: 0.39109721779823303
Validation loss: 2.2100879152615867

Epoch: 6| Step: 6
Training loss: 0.757405161857605
Validation loss: 2.1969274282455444

Epoch: 6| Step: 7
Training loss: 0.4304051399230957
Validation loss: 2.209215462207794

Epoch: 6| Step: 8
Training loss: 0.32767391204833984
Validation loss: 2.2326287825902305

Epoch: 6| Step: 9
Training loss: 0.2745990753173828
Validation loss: 2.18733811378479

Epoch: 6| Step: 10
Training loss: 0.32067519426345825
Validation loss: 2.2138884862264

Epoch: 6| Step: 11
Training loss: 0.20809262990951538
Validation loss: 2.236798405647278

Epoch: 6| Step: 12
Training loss: 0.30132797360420227
Validation loss: 2.2809011141459146

Epoch: 6| Step: 13
Training loss: 0.5887294411659241
Validation loss: 2.26192170381546

Testing loss: 2.1840368775155046
